# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation](https://rss.arxiv.org/abs/2402.01542) | 本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。 |
| [^2] | [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151) | 展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。 |
| [^3] | [Robustly estimating heterogeneity in factorial data using Rashomon Partitions](https://arxiv.org/abs/2404.02141) | 通过使用拉细孟划分集，我们能够在因子数据中稳健地估计异质性，并将因子空间划分成协变量组合的“池”，以便区分结果的差异。 |
| [^4] | [Topic-based Watermarks for LLM-Generated Text](https://arxiv.org/abs/2404.02138) | 提出了一种新的基于主题的水印算法，旨在解决当前水印方案的局限性，为区分LLM生成的文本和人类生成的文本提供了新的思路。 |
| [^5] | [FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning](https://arxiv.org/abs/2404.02127) | 本研究提出了一个名为LawInstruct的大型法律指导数据集，证明了领域特定的预训练和指导调整可以改善在LegalBench上的性能，为在法律领域开发具有更强信息处理和决策能力的模型提供了一个资源。 |
| [^6] | [GINopic: Topic Modeling with Graph Isomorphism Network](https://arxiv.org/abs/2404.02115) | GINopic是一种主题建模框架，利用图同构网络捕捉单词之间的相关性，相比于现有主题模型，展示了更好的有效性和推进主题建模的潜力。 |
| [^7] | [Tuning for the Unknown: Revisiting Evaluation Strategies for Lifelong RL](https://arxiv.org/abs/2404.02113) | 提出了一种新方法来调整和评估终身强化学习代理，在此方法中，只有实验数据的一小部分可用于超参数调整，针对终身强化学习的研究进展可能被不当的经验方法所阻碍 |
| [^8] | [ImageNot: A contrast with ImageNet preserves model rankings](https://arxiv.org/abs/2404.02112) | ImageNot数据集与ImageNet形成对比，展示了关键模型在两个数据集上的排名一致性，以及它们相对于先前模型的改进在两个数据集中都具有强相关性，表明了ImageNot对于迁移学习具有类似效用于ImageNet。 |
| [^9] | [Variance-Reduced Policy Gradient Approaches for Infinite Horizon Average Reward Markov Decision Processes](https://arxiv.org/abs/2404.02108) | 提出了两种基于策略梯度的方法，分别利用隐式梯度传输和基于Hessian的技术，分别确保了$\tilde{\mathcal{O}}(T^{3/5})$和$\tilde{\mathcal{O}}(\sqrt{T})$数量级的期望后悔。 |
| [^10] | [Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/abs/2404.02078) | 新推出的Eurus模型通过基于首选树的推理优化，在多项基准测试中取得了业界领先的成果，尤其在击败了GPT-3.5 Turbo的基准测试中表现突出。 |
| [^11] | [EGTR: Extracting Graph from Transformer for Scene Graph Generation](https://arxiv.org/abs/2404.02072) | 提出了一种从Transformer中提取图形以用于场景图生成的轻量级单阶段模型，有效地提取了关系图。 |
| [^12] | [Red-Teaming Segment Anything Model](https://arxiv.org/abs/2404.02067) | 本文对端分任意模型进行了多方面的红队分析，发现模型在应对风格迁移、隐私攻击和敌对攻击方面存在一些挑战 |
| [^13] | [Digital Forgetting in Large Language Models: A Survey of Unlearning Methods](https://arxiv.org/abs/2404.02062) | 本综述聚焦于大型语言模型中的数字遗忘，旨在获得一种遗忘方法，能有效地消除模型中的不良知识或行为，同时保留原始模型在理想任务上的性能，并具有可伸缩性。 |
| [^14] | [Generalizable, Fast, and Accurate DeepQSPR with fastprop Part 1: Framework and Benchmarks](https://arxiv.org/abs/2404.02058) | fastprop是一种DeepQSPR框架，通过使用分子级描述符，在极大缩短时间内，在多样数据集上达到并超越了学习表示的性能。 |
| [^15] | [Noise Masking Attacks and Defenses for Pretrained Speech Models](https://arxiv.org/abs/2404.02052) | 本研究提出了针对预训练语音编码器的噪声遮蔽攻击，并深入探讨了攻击的精度提升和反制措施。 |
| [^16] | [Universal representations for financial transactional data: embracing local, global, and external contexts](https://arxiv.org/abs/2404.02047) | 提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。 |
| [^17] | [Transformers as Transducers](https://arxiv.org/abs/2404.02040) | 通过将变压器与有限传感器联系起来，我们发现它们可以表达令人惊讶的大类传感，进一步扩展了RASP，推出了新的变体，并展示了掩码平均困难注意变压器可以模拟S-RASP. |
| [^18] | [AUTODIFF: Autoregressive Diffusion Modeling for Structure-based Drug Design](https://arxiv.org/abs/2404.02003) | 提出了一种基于扩散的分段自回归生成模型AUTODIFF，其中包括一种名为conformal motif的新型分子组装策略和SE(3)-等变卷积网络编码蛋白质-配体复合物相互作用的方法，能够解决结构基药物设计中的局部结构和构象问题。 |
| [^19] | [Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context](https://arxiv.org/abs/2404.02000) | 这项研究提出了首个仅在非洲语音上进行训练的自监督多语言语音模型，相比于常规方法，更高效并在ASR和LID任务中表现出竞争力。 |
| [^20] | [Emergence of Chemotactic Strategies with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2404.01999) | 强化学习在趋化方面的应用研究表明，智能体能够根据布朗运动物理约束快速实现趋化，同时发现新兴策略的效率和智能体大小、游泳速度的收敛。 |
| [^21] | [Specularity Factorization for Low-Light Enhancement](https://arxiv.org/abs/2404.01998) | 提出了一种新的加法图像分解技术，利用反光因子分解进行低光增强，无需配对或非配对监督训练，提高了低光增强性能并在多个数据集上实现更好的泛化。 |
| [^22] | [DELAN: Dual-Level Alignment for Vision-and-Language Navigation by Cross-Modal Contrastive Learning](https://arxiv.org/abs/2404.01994) | 通过跨模态对比学习实现的DELAN框架提出了双层对齐方法，以提升视觉与语言导航中的跨模态交互和行动决策。 |
| [^23] | [Predicting the Intention to Interact with a Service Robot:the Role of Gaze Cues](https://arxiv.org/abs/2404.01986) | 凝视线索的有效利用显著提高了服务机器人感知用户互动意图的性能，分类准确性和适应新环境能力。 |
| [^24] | [Zero-Shot Multi-Lingual Speaker Verification in Clinical Trials](https://arxiv.org/abs/2404.01981) | 提出在临床试验中利用患者语音数据进行多语言说话者验证，以应对身份验证和排除重复入组的挑战。 |
| [^25] | [Joint-Task Regularization for Partially Labeled Multi-Task Learning](https://arxiv.org/abs/2404.01976) | 提出了一种联合任务正则化（JTR）技术，通过在单个联合任务潜在空间中同时对所有任务进行正则化，改善了当数据未完全标记所有任务时的学习。 |
| [^26] | [DSGNN: A Dual-View Supergrid-Aware Graph Neural Network for Regional Air Quality Estimation](https://arxiv.org/abs/2404.01975) | DSGNN 提出了一种新的双视图超网格感知图神经网络，能够从卫星数据和气象数据中模拟远距离网格区域的空间依赖关系，以实现区域空气质量估计。 |
| [^27] | [Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks](https://arxiv.org/abs/2404.01965) | 该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。 |
| [^28] | [CAM-Based Methods Can See through Walls](https://arxiv.org/abs/2404.01964) | CAM-based方法解释图像分类模型的决策时，可能会错误地将模型无法看到的部分归因为重要，这可能导致对模型行为的误解释。 |
| [^29] | [Bi-LORA: A Vision-Language Approach for Synthetic Image Detection](https://arxiv.org/abs/2404.01959) | 基于视觉-语言方法，引入了Bi-LORA方法，通过结合VLMs和LORA调整技术，将合成图像检测转化为图像字幕任务，以提高对未见过的模型生成图像的精度。 |
| [^30] | [MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels](https://arxiv.org/abs/2404.01958) | 提出了MESEN，一个利用未标记多模态数据设计单模态人类活动识别的框架，通过多任务机制和特征学习实现了有效的单模态特征提取。 |
| [^31] | [Synthetic Data for Robust Stroke Segmentation](https://arxiv.org/abs/2404.01946) | 提出一种用于中风分割的合成框架，使用病变特定增强策略扩展了SynthSeg方法，通过训练深度学习模型实现对健康组织和病理病变的分割，无需特定序列的训练数据，在领域内和领域外数据集的评估中表现出鲁棒性能。 |
| [^32] | [Settling Time vs. Accuracy Tradeoffs for Clustering Big Data](https://arxiv.org/abs/2404.01936) | 在大数据聚类中，研究了时间和准确性的权衡，提出了一种可以在有效线性时间内获得核心集的算法。 |
| [^33] | [Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks](https://arxiv.org/abs/2404.01932) | 本研究探索了多模态VAE如何在无监督机器人操作任务中实现，提出了一个新的模型训练方法，可以使模拟器中的模型性能提高55%。 |
| [^34] | [Adaptive Combinatorial Maximization: Beyond Approximate Greedy Policies](https://arxiv.org/abs/2404.01930) | 提供了新的全面近似保证，支持最大增益比率和近似次模函数，包括基数约束下的最大化和最小成本覆盖保证，并且引入了自适应选择策略的新参数“最大增益比率”。 |
| [^35] | [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](https://arxiv.org/abs/2404.01907) | 本文提出了一个旨在对机器生成的文本进行微小扰动以规避检测的广泛对抗攻击框架，通过白盒和黑盒两种攻击设置以及对抗学习在动态场景中的应用，评估了当前检测模型对此类攻击的鲁棒性潜力增强 |
| [^36] | [Activation Steering for Robust Type Prediction in CodeLLMs](https://arxiv.org/abs/2404.01903) | 我们提出了一种激活导向技术，通过编辑模型内部激活来改善CodeLLMs在代码类型预测中对于语法干扰的鲁棒性，并成功应用于Python和TypeScript的类型预测，将类型误差率纠正高达90%。 |
| [^37] | [Continuous Spiking Graph Neural Networks](https://arxiv.org/abs/2404.01897) | COS-GNN将脉冲神经网络（SNNs）与连续图神经网络（CGNNs）结合在一起，以在每个时间步骤对图节点进行表示，并将其与时间一起集成到ODE过程中，以增强信息保存和解决在离散图神经网络中的问题。 |
| [^38] | [Adversarial Combinatorial Bandits with Switching Costs](https://arxiv.org/abs/2404.01883) | 研究了具有切换成本的对抗性组合赌博机问题，推导了极小后悔的下限并设计了逼近算法。 |
| [^39] | [Procedural Fairness in Machine Learning](https://arxiv.org/abs/2404.01877) | 本文定义了机器学习模型的程序公平性，提出了评估群体程序公平性的新度量标准$GPF_{FAE}$，并使用特征归因解释来捕捉决策过程，实验证实了其有效性，同时揭示了程序和分配公平性之间的关系，并提出了一种方法来识别导致程序性不公平的特征。 |
| [^40] | [Satellite Federated Edge Learning: Architecture Design and Convergence Analysis](https://arxiv.org/abs/2404.01875) | 本文引入了一种针对低地球轨道卫星网络的新型FEEL算法FEDMEGA，通过整合卫星间链接（ISL）进行轨道内模型聚合。 |
| [^41] | [Fast and Adaptive Questionnaires for Voting Advice Applications](https://arxiv.org/abs/2404.01872) | 该研究提出了一种自适应问卷方法，根据用户先前的回答选择后续的问题，旨在提高投票建议应用的推荐准确性同时减少给选民提问的问题数量。 |
| [^42] | [Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation](https://arxiv.org/abs/2404.01867) | 该论文提出了在机器人操作中基于贝叶斯模型的强化学习中通过主动探索改善模型质量和保持数据效率的方法。 |
| [^43] | [Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models](https://arxiv.org/abs/2404.01863) | 使用奖励函数训练的细化文本到图像模型可能会因为奖励过度优化而损害性能，为了解决这一问题，提出了一种基于奖励模型置信度的对齐性增强方法。 |
| [^44] | [Detecting Gender Bias in Course Evaluations](https://arxiv.org/abs/2404.01857) | 通过机器学习和自然语言处理，研究发现课程评价中的性别偏见，比较英语和瑞典课程数据，揭示了学生对课程的评价主观性因考官性别而存在差异。 |
| [^45] | [Pairwise Similarity Distribution Clustering for Noisy Label Learning](https://arxiv.org/abs/2404.01853) | 提出了成对相似度分布聚类（PSDC）算法，用于在噪声标签学习中选取干净样本集和嘈杂样本集，辅助进行半监督学习，从而进一步训练深度神经网络。 |
| [^46] | [Accelerating Transformer Pre-Training with 2:4 Sparsity](https://arxiv.org/abs/2404.01847) | 通过稀疏矩阵乘法，结合两种新技术和模型微调，研究了加速Transformer预训练中前馈网络的可行性，以及通过计算2:4掩码和减少GPU L2缓存来实现训练加速。 |
| [^47] | [When does Subagging Work?](https://arxiv.org/abs/2404.01832) | 研究展示了在机器学习中一种流行的非参数方法——回归树上，子抽样聚合（subagging）的有效性，并发现对于任何给定的分裂数，subagging都可以优于单棵树，并且在较多分裂的情况下改进更大。 |
| [^48] | [Doubly-Robust Off-Policy Evaluation with Estimated Logging Policy](https://arxiv.org/abs/2404.01830) | 提出了一种适用于未知记录策略和价值函数的双重稳健离线评估估计器DRUnknown，实现了最小渐近方差和半参数下界下最佳性能。 |
| [^49] | [Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay](https://arxiv.org/abs/2404.01828) | 持续对抗性防御概念下提出了各向异性和各向同性伪重演（AIR），通过各向同性重演保持模型一致性，在各向异性重演中学习折衷数据流形。 |
| [^50] | [A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection](https://arxiv.org/abs/2404.01822) | 提出了面向恶意内容检测社区模型泛化的更为现实的评估设置，通过少样本子图采样方法测试模型泛化能力。 |
| [^51] | [A neural network-based approach to hybrid systems identification for control](https://arxiv.org/abs/2404.01814) | 通过神经网络架构设计出的混合系统模型具有分段线性动力学，可以用于优化控制设计，并且在有限视野最优控制问题中计算出具有强局部最优性保证的最优解。 |
| [^52] | [Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification](https://arxiv.org/abs/2404.01805) | 使用两种情绪维度进行序数分类，从而改进文本情感预测，并提出了一种新方法来区分不同情绪之间的相似性和差异性 |
| [^53] | [Neuromorphic Wireless Device-Edge Co-Inference via the Directed Information Bottleneck](https://arxiv.org/abs/2404.01804) | 提出了一种新的系统解决方案，名为神经形态的无线设备-边缘协同推理，设备使用神经形态硬件进行数据处理，边缘服务器使用传统技术，以降低通信开销。 |
| [^54] | [Super-Resolution Analysis for Landfill Waste Classification](https://arxiv.org/abs/2404.01790) | 该研究使用超分辨率分析进行废物分类，提出跨域分类和超分辨率增强来评估不同图像分辨率对废物分类的影响，以应对非法填埋场的蔓延。 |
| [^55] | [A noisy elephant in the room: Is your out-of-distribution detector robust to label noise?](https://arxiv.org/abs/2404.01775) | 本研究探讨了当下训练分类器的标签不可靠时，20种最新OOD检测方法在离群检测中的表现，为了解类别标签噪音对OOD检测的影响提供了深入见解。 |
| [^56] | [Unifying Qualitative and Quantitative Safety Verification of DNN-Controlled Systems](https://arxiv.org/abs/2404.01769) | 本文提出了一个新的框架，用于统一DNN控制系统的定性和定量安全验证问题，通过构建有效神经障碍证书(NBCs)来实现几乎确定的安全保证 |
| [^57] | [Global Mapping of Exposure and Physical Vulnerability Dynamics in Least Developed Countries using Remote Sensing and Machine Learning](https://arxiv.org/abs/2404.01748) | 本文使用遥感和机器学习技术，在最不发达国家进行了全球曝光和物理脆弱性动态映射，旨在推动大规模灾害风险领域的发展。 |
| [^58] | [Towards Scalable & Efficient Interaction-Aware Planning in Autonomous Vehicles using Knowledge Distillation](https://arxiv.org/abs/2404.01746) | 引入了一种结合深度学习和约束优化的高效方法，利用知识蒸馏训练更小更高效的网络，从而减轻复杂性 |
| [^59] | [Asymptotics of Language Model Alignment](https://arxiv.org/abs/2404.01730) | 本文提供了对最优KL约束的强化学习解的闭合形式刻画，证明了实现KL散度和奖励之间权衡的对齐方法必须近似最优KL约束的RL解。 |
| [^60] | [Effective internal language model training and fusion for factorized transducer model](https://arxiv.org/abs/2404.01716) | 提出了一种对于分解转录模型的有效ILM训练和解码策略，能够显著改善与标准解码方法的性能，并在LibriSpeech数据集上取得了17%的相对改善。 |
| [^61] | [Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning](https://arxiv.org/abs/2404.01714) | 提出一种基于共轭梯度样式的新优化算法CG-like-Adam，用于深度学习，并在收敛分析和数值实验中展示了其优越性 |
| [^62] | [Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics](https://arxiv.org/abs/2404.01712) | 通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。 |
| [^63] | [Preventing Model Collapse in Gaussian Process Latent Variable Models](https://arxiv.org/abs/2404.01697) | 本文通过理论分析投影方差对高斯过程潜变量模型的影响，以及集成了谱混合（SM）核和可微随机傅立叶特征（RFF）核逼近来解决核灵活性不足问题，从而防止模型崩溃。 |
| [^64] | [Selective Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2404.01695) | 提出了一个适用于时态知识图推理的弃权机制，通过置信度估计帮助现有模型有选择性地预测未来事实，减少不确定性带来的风险。 |
| [^65] | [HeMeNet: Heterogeneous Multichannel Equivariant Network for Protein Multitask Learning](https://arxiv.org/abs/2404.01693) | 提出了HeMeNet模型，能够在输入蛋白质结构的基础上联合处理多个任务，解决了蛋白质多任务学习中的性能和泛化问题。 |
| [^66] | [A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling](https://arxiv.org/abs/2404.01685) | 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。 |
| [^67] | [Incentives in Private Collaborative Machine Learning](https://arxiv.org/abs/2404.01676) | 引入差分隐私作为激励机制，中介者通过贝叶斯惊讶值来价值化扰动的充分统计量，实现隐私-估值权衡，同时保护差分隐私和高度相似性。 |
| [^68] | [How COVID-19 has Impacted the Anti-Vaccine Discourse: A Large-Scale Twitter Study Spanning Pre-COVID and Post-COVID Era](https://arxiv.org/abs/2404.01669) | 通过大规模Twitter研究，本研究尝试理解COVID-19如何影响反疫苗言论，并且提出了两种新的方法去识别具体原因/关注点。 |
| [^69] | [Release of Pre-Trained Models for the Japanese Language](https://arxiv.org/abs/2404.01657) | 发布日语预训练模型以缩小非英语社区中的AI访问差距，促进AI民主化。 |
| [^70] | [Test-Time Model Adaptation with Only Forward Passes](https://arxiv.org/abs/2404.01650) | 提出了一种测试时间前向适应（FOA）方法，通过无导数的协方差矩阵适应进化策略仅学习新添加的提示，以在资源有限的设备上实现模型适应。 |
| [^71] | [Transformer meets wcDTW to improve real-time battery bids: A new approach to scenario selection](https://arxiv.org/abs/2404.01646) | 本文将Transformer-based预测与weighted constrained Dynamic Time Warping (wcDTW)相结合，改进了实时电池竞标中的场景选择方法，通过模拟展示了相较于传统方法约10%的收益增长。 |
| [^72] | [ContrastCAD: Contrastive Learning-based Representation Learning for Computer-Aided Design Models](https://arxiv.org/abs/2404.01645) | ContrastCAD提出了基于对比学习的方法，能够有效捕捉CAD模型构建序列中的语义信息，并使用RRE方法增强了训练性能。 |
| [^73] | [ADVREPAIR:Provable Repair of Adversarial Attack](https://arxiv.org/abs/2404.01642) | ADVREPAIR是一种利用有限数据进行对抗攻击的可证修复的新方法，通过形式验证构建补丁模块，在稳健邻域内提供可证和专门的修复，同时具有泛化到其他输入的防御能力。 |
| [^74] | [Learning to Control Camera Exposure via Reinforcement Learning](https://arxiv.org/abs/2404.01636) | 提出了一种通过深度强化学习快速控制摄像机曝光的新框架，具有简化训练场地、奖励设计和曝光调整能力逐步改善等四大创新贡献 |
| [^75] | [Enhancing Functional Safety in Automotive AMS Circuits through Unsupervised Machine Learning](https://arxiv.org/abs/2404.01632) | 通过无监督机器学习实现早期异常检测，以增强汽车AMS电路的功能安全性 |
| [^76] | [Learning Equi-angular Representations for Online Continual Learning](https://arxiv.org/abs/2404.01628) | 使用神经坍缩现象引入神经坍缩来形成表示空间中的等角紧框架结构，通过提出预备数据训练和残差修正，使得单周期学习的连续学习模型能更好地适应流数据，这种方法在在线连续学习中取得了明显的优势。 |
| [^77] | [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](https://arxiv.org/abs/2404.01617) | LLM-ABR利用大语言模型自主设计适用于各种网络特性的自适应码率算法，并在不同网络环境中表现优异。 |
| [^78] | [Audio Simulation for Sound Source Localization in Virtual Evironment](https://arxiv.org/abs/2404.01611) | 本研究通过音频模拟和机器学习方法，在虚拟环境中实现了声源定位到特定位置的准确性，有效克服了数据不足的问题。 |
| [^79] | [FAIRM: Learning invariant representations for algorithmic fairness and domain generalization with minimax optimality](https://arxiv.org/abs/2404.01608) | 提出了一种通过不变性原则解决公平和泛化机器学习问题的方法，包括基于训练环境的oracle FAIRM，以及在线性模型中实现FAIRM的高效算法，在实验中表现出极小最优性。 |
| [^80] | [What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks](https://arxiv.org/abs/2404.01601) | Transformer的深度对其进行不同任务的影响进行了系统评估，研究发现推理和泛化需要至少两个注意力层，而上下文泛化可能需要三个注意力层。通过组合简单操作和堆叠多个注意力层，复杂任务可以得到解决。 |
| [^81] | [Extremum-Seeking Action Selection for Accelerating Policy Optimization](https://arxiv.org/abs/2404.01598) | 提出了在无模型强化学习中改进动作选择的方法，通过引入极值寻找控制（ESC）进行自适应控制步骤，以加速策略优化。 |
| [^82] | [Propensity Score Alignment of Unpaired Multimodal Data](https://arxiv.org/abs/2404.01595) | 本文提出了一种解决多模态表示学习中对齐不配对样本挑战的方法，通过估计倾向得分来定义样本之间的距离。 |
| [^83] | [Hallucination Diversity-Aware Active Learning for Text Summarization](https://arxiv.org/abs/2404.01588) | 本文首次提出了一种基于幻觉多样性的主动学习框架，用于减轻大型语言模型（LLMs）在文本摘要中产生的幻觉，减少了昂贵的人类注释需求。 |
| [^84] | [GLEMOS: Benchmark for Instantaneous Graph Learning Model Selection](https://arxiv.org/abs/2404.01578) | GLEMOS提供了一个全面的基准评估，用于瞬时地选择有效的图学习模型，填补了之前缺乏的评估GL模型选择方法性能的空白。 |
| [^85] | [Multi-granular Adversarial Attacks against Black-box Neural Ranking Models](https://arxiv.org/abs/2404.01574) | 这项研究聚焦于利用多粒度扰动生成高质量的对抗性示例，通过转化为顺序决策过程来解决组合爆炸问题。 |
| [^86] | [Evaluating Large Language Models Using Contrast Sets: An Experimental Approach](https://arxiv.org/abs/2404.01569) | 介绍了一种为斯坦福自然语言推断（SNLI）数据集生成对比集的创新技术，通过自动替换动词、副词和形容词为同义词来评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。 |
| [^87] | [Distributed Autonomous Swarm Formation for Dynamic Network Bridging](https://arxiv.org/abs/2404.01557) | 提出了一种用于动态网络桥接的新颖分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，以及基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法。 |
| [^88] | [Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging](https://arxiv.org/abs/2404.01551) | 将多智能体强化学习与控制理论相结合，提出了一种新的设定点更新算法，以确保安全条件并实现良好的任务目标性能。 |
| [^89] | [Predicting the Performance of Foundation Models via Agreement-on-the-Line](https://arxiv.org/abs/2404.01542) | 本研究发现，通过对来自单个基础模型的多次运行进行轻微微调，可以通过训练期间的随机性选择来显著影响最终集合中的一致性。 |
| [^90] | [Laying Anchors: Semantically Priming Numerals in Language Modeling](https://arxiv.org/abs/2404.01536) | 通过生成受数字分布规律控制的锚点，我们引入了一种在语义上引导数字的策略，在广泛范围的数字任务上实现了数学基础表示的显著改进。 |
| [^91] | [ML KPI Prediction in 5G and B5G Networks](https://arxiv.org/abs/2404.01530) | 本文引入了一种用于估算5G和B5G网络中端到端（E2E）网络切片吞吐量的机器学习（ML）模型，并将预测的吞吐量与当前网络状态结合起来，以推导出一个步                                                                                                                                                                                                  en_tdlr: Introducing a machine learning model for estimating throughput in 5G and B5G networks with network slices, and combining predicted throughput with current network state for performance optimization. |
| [^92] | [Fair MP-BOOST: Fair and Interpretable Minipatch Boosting](https://arxiv.org/abs/2404.01521) | Fair MP-Boost是一种旨在平衡公平性和准确性的Boosting方法，通过自适应学习特征和观测来选择小批量，以同时提高预测准确性和公平性。 |
| [^93] | [Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation](https://arxiv.org/abs/2404.01518) | 提出了一种基于解决最优传输问题的动作分割方法，通过在Gromov-Wasserstein问题中编码时间一致性先验来实现从视频帧和动作类别之间的噪声成本中解码时间一致的分割。 |
| [^94] | [Addressing Heterogeneity in Federated Load Forecasting with Personalization Layers](https://arxiv.org/abs/2404.01517) | 提出了在负载预测中使用个性化层的通用框架PL-FL，通过研究表明PL-FL在低通信带宽要求下优于FL和纯本地训练。 |
| [^95] | [Can Biases in ImageNet Models Explain Generalization?](https://arxiv.org/abs/2404.01509) | 图像网模型的偏见是否能够解释模型的泛化问题，对此进行了大规模研究。 |
| [^96] | [MosquitoFusion: A Multiclass Dataset for Real-Time Detection of Mosquitoes, Swarms, and Breeding Sites Using Deep Learning](https://arxiv.org/abs/2404.01501) | 该论文提出了一个整合方法，使用MosquitoFusion数据集和深度学习技术实现对蚊子、蚊群和繁殖地的实时检测，同时结合地理信息系统(GIS)进一步丰富了空间模式分析的深度。 |
| [^97] | [Explainable AI Integrated Feature Engineering for Wildfire Prediction](https://arxiv.org/abs/2404.01487) | 本研究通过评估各种机器学习算法，发现XGBoost模型在森林火灾分类中具有更好的准确性和随机森林回归模型在预测火灾范围方面表现出色。同时，我们还开发了一种集成数值数据和图像信息的混合神经网络模型。 |
| [^98] | [QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving](https://arxiv.org/abs/2404.01486) | 提出了一个新的自动驾驶神经运动规划框架，通过查询感兴趣的时空点的占据信息，避免了传统对象检测和密集占据栅格地图方法中的信息丢失和计算浪费。 |
| [^99] | [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](https://arxiv.org/abs/2404.01476) | TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题 |
| [^100] | [Are large language models superhuman chemists?](https://arxiv.org/abs/2404.01475) | 介绍了一个自动化框架“ChemBench”，旨在评估最先进的大型语言模型（LLMs）在化学知识和推理能力方面与人类化学家专业知识的对比。 |
| [^101] | [TS-CausalNN: Learning Temporal Causal Relations from Non-linear Non-stationary Time Series Data](https://arxiv.org/abs/2404.01466) | TS-CausalNN提出了一种新的深度学习技术，可以同时发现时间序列数据中的同时发生和滞后的因果关系 |
| [^102] | [Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images](https://arxiv.org/abs/2404.01464) | 该论文提出了一种简单而有效的无监督三维插值框架UVI-Net，能够在4D医学图像中实现无需中间帧的时间插值，取得了显着的性能改善。 |
| [^103] | [OpenChemIE: An Information Extraction Toolkit For Chemistry Literature](https://arxiv.org/abs/2404.01462) | OpenChemIE提出了一种用于从化学文献中提取反应数据的工具包，通过整合文本、表格和图像信息以及使用专门神经模型和算法，实现了在文档级别的反应数据提取。 |
| [^104] | [Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers](https://arxiv.org/abs/2404.01459) | 结合博弈论和深度强化学习优化地理分布式数据中心中AI推断工作负载的分布，以降低碳排放和运营成本。 |
| [^105] | [Prior Frequency Guided Diffusion Model for Limited Angle (LA)-CBCT Reconstruction](https://arxiv.org/abs/2404.01448) | 本研究提出了一种基于扩散模型的先验频率引导扩散模型（PFGDM）框架，用于稳健且保持结构的有限角度CBCT重建。 |
| [^106] | [Creating emoji lexica from unsupervised sentiment analysis of their descriptions](https://arxiv.org/abs/2404.01439) | 该论文提出了一种从在线文本消息中预测表情符号所表达情感的新方法，无需人工标注数据，节省了宝贵时间。 |
| [^107] | [Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance](https://arxiv.org/abs/2404.01436) | 本文提出了对于RMSProp和Adam在非凸优化中的紧致收敛性分析，首次展示了在最宽松的假设下的收敛性结果，并展示了RMSProp和Adam的迭代复杂度分别为$\mathcal O(\epsilon^{-4})$。 |
| [^108] | [Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs](https://arxiv.org/abs/2404.01430) | 本研究发现LLMs的位置偏差主要源于不同模型的固有位置偏好，并提出了一种面向位置的参数高效微调方法来解决这一问题。 |
| [^109] | [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/abs/2404.01413) | 本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。 |
| [^110] | [Bigger is not Always Better: Scaling Properties of Latent Diffusion Models](https://arxiv.org/abs/2404.01367) | 在研究潜在扩散模型的规模特性时发现，较小的模型在相同推理预算下往往比较大的模型更有效地生成高质量结果。 |
| [^111] | [Prompt-prompted Mixture of Experts for Efficient LLM Generation](https://arxiv.org/abs/2404.01365) | 提出了一种名为GRIFFIN的训练-free MoE，能够在各种LLM模型中选择唯一的FF专家以实现高效生成。 |
| [^112] | [Information Plane Analysis Visualization in Deep Learning via Transfer Entropy](https://arxiv.org/abs/2404.01364) | 通过转移熵进行信息平面分析可视化揭示了信息瓶颈方法中压缩和信息保留的权衡，以及信息论压缩与泛化之间存在的关系。 |
| [^113] | [LLM Attributor: Interactive Visual Attribution for LLM Generation](https://arxiv.org/abs/2404.01361) | LLM Attributor是一个Python库，提供了交互式可视化方式用于将LLM的文本生成结果归因到训练数据点，帮助用户检查模型行为、增强可信度，并与用户提供的文本进行比较。 |
| [^114] | [Harnessing Data and Physics for Deep Learning Phase Recovery](https://arxiv.org/abs/2404.01360) | 本论文全面比较了数据驱动和物理驱动两种深度学习相位恢复策略，在时间消耗、准确性、泛化能力、适应病态问题和先验能力等方面的差异。 |
| [^115] | [Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists](https://arxiv.org/abs/2404.01358) | 通过利用人工智能驱动的社交媒体分析，我们开发了一种数字健康方法，成功检测出与GLP-1受体激动剂相关的21种潜在不良副作用，包括易怒和麻木感，从而革新了对新部署药物未报告ASEs的检测。 |
| [^116] | [The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness](https://arxiv.org/abs/2404.01356) | 该论文研究了深度神经网络对敌对输入扰动的敏感性，提出了新的鲁棒准确公平性定义，并介绍了一种敌对攻击方法和相应的解决方案。 |
| [^117] | [Efficiently Distilling LLMs for Edge Applications](https://arxiv.org/abs/2404.01353) | 提出了一种名为MLFS的新方法，用于高效参数的超网络训练，可以获得适用于商业边缘应用的高质量编码器模型，并有效地减少训练时间。 |
| [^118] | [AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation](https://arxiv.org/abs/2404.01351) | 提出了AETTA，一种用于测试时适应的无标签准确性估计算法，通过预测不一致性来改进准确性估计并在适应失败情况下展现更高的准确性估计。 |
| [^119] | [Enhancing Bangla Fake News Detection Using Bidirectional Gated Recurrent Units and Deep Learning Techniques](https://arxiv.org/abs/2404.01345) | 使用深度学习技术中的双向门控循环单元，在孟加拉语中识别虚假新闻，准确率达到99.16% |
| [^120] | [Block-Diagonal Guided DBSCAN Clustering](https://arxiv.org/abs/2404.01341) | 该研究提出了一种改进版本的DBSCAN，利用相似性图的块对角属性引导聚类过程，通过构建块对角图并进行聚类排序，易于确定聚类结构。 |
| [^121] | [From Similarity to Superiority: Channel Clustering for Time Series Forecasting](https://arxiv.org/abs/2404.01340) | 通过对通道进行聚类，实现了一种新颖的通道策略，有效平衡了个体通道处理和通道之间必要交互作用，从而提高了时间序列预测性能。 |
| [^122] | [Automatic detection of relevant information, predictions and forecasts in financial news through topic modelling with Latent Dirichlet Allocation](https://arxiv.org/abs/2404.01338) | 该研究提出了一种新颖的自然语言处理系统，通过Latent Dirichlet Allocation (LDA)进行相关的主题建模，帮助投资者从非结构化文本源中检测财经事件中的相关信息、预测和预测 |
| [^123] | [Detection of Temporality at Discourse Level on Financial News by Combining Natural Language Processing and Machine Learning](https://arxiv.org/abs/2404.01337) | 通过结合自然语言处理和机器学习技术，提出了一种新颖的系统，旨在在金融新闻中检测篇章级别的关键声明的时间性，以分析句法和语义依赖关系，区分上下文信息和有价值的预测。 |
| [^124] | [Generative AI for Architectural Design: A Literature Review](https://arxiv.org/abs/2404.01335) | 生成式人工智能在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率，通过广泛应用生成式AI技术和深度生成模型生成2D图像、视频和3D模型，并审视其在不同阶段的影响趋势。 |
| [^125] | [Augmenting NER Datasets with LLMs: Towards Automated and Refined Annotation](https://arxiv.org/abs/2404.01334) | 本研究引入了一种新颖的混合标注方法，将人力工作与大型语言模型相结合，旨在提高NER模型的性能，并以成本效益的方式实现这一目标。 |
| [^126] | [Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value](https://arxiv.org/abs/2404.01332) | 使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响 |
| [^127] | [Holo-VQVAE: VQ-VAE for phase-only holograms](https://arxiv.org/abs/2404.01330) | Holo-VQVAE是一种针对仅相位全息图的新型生成框架，结合了矢量量化变分自动编码器的结构，通过集成角谱方法来学习图像域，在全息图生成中实现了从复杂分布中直接生成多样化全息内容。 |
| [^128] | [Entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities](https://arxiv.org/abs/2404.01327) | EBER chatbot是一个旨在减少老年人数字鸿沟的娱乐聊天机器人，其创新之处在于其"智能电台"概念，根据用户的心情和需求提供相关信息。 |
| [^129] | [JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models](https://arxiv.org/abs/2404.01318) | JailbreakBench是一个用于对抗大型语言模型越狱的开放基准，提供新的数据集、对抗提示和评估框架。 |
| [^130] | [Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers](https://arxiv.org/abs/2404.01317) | 本文研究了在Transformer神经网络中的灾难性遗忘问题，通过智能学习率分布取得了比平坦学习率更好的性能，并在GLUE数据集中得到验证。 |
| [^131] | [Learning to Solve Job Shop Scheduling under Uncertainty](https://arxiv.org/abs/2404.01308) | 该论文利用深度强化学习技术解决了具有不确定性的作业车间调度问题，重点在于提出了一种新颖方法来处理具有不确定持续时间的JSSP。 |
| [^132] | [NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models](https://arxiv.org/abs/2404.01306) | 本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法 |
| [^133] | [Can LLMs get help from other LLMs without revealing private information?](https://arxiv.org/abs/2404.01041) | 本研究展示了在级联系统中运用隐私保护技术的可行性，以减少在查询远程模型时泄漏私人信息的风险，并引入了两个隐私度量。 |
| [^134] | [Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs](https://arxiv.org/abs/2404.00640) | 提出了一种基于LLM的两阶段策略，帮助终端用户通过日志定位配置错误的根本原因，并开发了相应工具LogConfigLocalizer，以帮助终端用户通过日志分析解决配置错误。 |
| [^135] | [CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz continuity constrAIned Normalization](https://arxiv.org/abs/2404.00521) | 通过引入CHAIN，该方法在数据有限的情况下，解决了GANs中鉴别器过拟合和训练不稳定的问题，提高了泛化能力和训练稳定性。 |
| [^136] | [Zero-shot Safety Prediction for Autonomous Robots with Foundation World Models](https://arxiv.org/abs/2404.00462) | 基于基础世界模型，提出了一种能够直接预测因果未来状态的方法，在安全预测任务中表现优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。 |
| [^137] | [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://arxiv.org/abs/2404.00450) | 该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。 |
| [^138] | [InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning](https://arxiv.org/abs/2404.00228) | InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。 |
| [^139] | [LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning](https://arxiv.org/abs/2404.00027) | 探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。 |
| [^140] | [Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs](https://arxiv.org/abs/2404.00026) | 研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。 |
| [^141] | [Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning](https://arxiv.org/abs/2404.00015) | 提出了一种名为Systemic Quantum Score (SQS)的新方法，展示在金融领域生产级应用案例中相比纯经典模型更有优势，能够从较少数据点中提取模式并表现出更好性能。 |
| [^142] | [FairRAG: Fair Human Generation via Fair Retrieval Augmentation](https://arxiv.org/abs/2403.19964) | FairRAG框架通过在外部图像数据库检索到的参考图像来提高人类生成中的公平性，并应用简单但有效的去偏策略，从而为生成过程提供来自不同人口统计组的图像。 |
| [^143] | [Concept-based Analysis of Neural Networks via Vision-Language Models](https://arxiv.org/abs/2403.19837) | 本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。 |
| [^144] | [ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2403.18807) | 通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。 |
| [^145] | [Long-form factuality in large language models](https://arxiv.org/abs/2403.18802) | 该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。 |
| [^146] | [Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation](https://arxiv.org/abs/2403.17886) | 基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。 |
| [^147] | [PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning](https://arxiv.org/abs/2403.17637) | 引入了 PeersimGym 环境，通过强化学习解决任务卸载问题，支持定制化仿真环境，有助于开发和优化计算网络中的任务卸载策略。 |
| [^148] | [Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens](https://arxiv.org/abs/2403.17407) | 通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。 |
| [^149] | [FLIGAN: Enhancing Federated Learning with Incomplete Data using GAN](https://arxiv.org/abs/2403.16930) | FLIGAN利用生成对抗网络（GAN）来生成合成数据，解决联邦学习中不完整数据的问题，提升模型的鲁棒性和完整性。 |
| [^150] | [Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy](https://arxiv.org/abs/2403.16591) | 论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。 |
| [^151] | [FusionINN: Invertible Image Fusion for Brain Tumor Monitoring](https://arxiv.org/abs/2403.15769) | FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。 |
| [^152] | [Foundation Models for Time Series Analysis: A Tutorial and Survey](https://arxiv.org/abs/2403.14735) | Foundation Models为时间序列分析带来创新，利用预训练或微调的模型来获得具体定制的广义知识，提升了实践中多个下游任务的效果。 |
| [^153] | [CICLe: Conformal In-Context Learning for Largescale Multi-Class Food Risk Classification](https://arxiv.org/abs/2403.11904) | 该论文提出了CICLe框架，基于适应上下文学习的方式，在大规模多类食品风险分类中取得了较好的效果，提出了基于符合预测的LLM-in-the-loop框架，可以提高基本分类器的性能，并减少能源消耗。 |
| [^154] | [Is Mamba Effective for Time Series Forecasting?](https://arxiv.org/abs/2403.11144) | Mamba模型作为一种状态空间模型在时间序列预测中具有捕捉复杂依赖关系、近线性复杂度以及性能优势的潜力。 |
| [^155] | [Twin Transformer using Gated Dynamic Learnable Attention mechanism for Fault Detection and Diagnosis in the Tennessee Eastman Process](https://arxiv.org/abs/2403.10842) | 本研究提出一种新颖的双Transformer模型，结合门控动态可学习注意机制，用于田纳西伊斯曼过程的故障检测与诊断，提高性能通过独立处理输入数据和提取多样化信息，以及动态学习适应性调整注意策略。 |
| [^156] | [Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain](https://arxiv.org/abs/2403.10576) | 利用非语言元素进行网络安全领域的预训练，提出了新的预训练方法并在网络安全领域中取得了优越表现 |
| [^157] | [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://arxiv.org/abs/2403.10516) | FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。 |
| [^158] | [Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild](https://arxiv.org/abs/2403.10488) | 该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。 |
| [^159] | [Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information](https://arxiv.org/abs/2403.09516) | 通过利用预定义的典型人口统计文本并在微调过程中加入正则化项，本文提出的方法有效减轻了语言模型中的社会偏见，同时不需要依赖显式的人口统计标签。 |
| [^160] | [Constrained Optimal Fuel Consumption of HEV: A Constrained Reinforcement Learning Approach](https://arxiv.org/abs/2403.07503) | 首次提出了从受约束强化学习的视角全球首次提供混合动力车辆的受约束最优燃料消耗的数学表达，并首次利用两种主流的受约束强化学习方法来获得车辆在电池电气平衡条件下的最小燃料消耗。 |
| [^161] | [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) | 本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。 |
| [^162] | [JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using in-context learning with GPT and instruction-tuned Llama models](https://arxiv.org/abs/2403.04798) | 本文介绍了针对SemEval-2024任务3开发的多模态情感因果分析系统，提出了通过两步框架解决多模态情感因果分析挑战的方法，并在实验中取得显著性能提升。 |
| [^163] | [Temporal Cross-Attention for Dynamic Embedding and Tokenization of Multimodal Electronic Health Records](https://arxiv.org/abs/2403.04012) | 提出了一种用于精确表示多模态临床时间序列的动态嵌入和标记框架 |
| [^164] | [3D Diffusion Policy](https://arxiv.org/abs/2403.03954) | 3D扩散策略（DP3）是一种新颖的视觉模仿学习方法，通过将3D视觉表示的强大性结合到扩散策略中，成功解决了学习复杂技能所需大量人类演示的问题。 |
| [^165] | [MedMamba: Vision Mamba for Medical Image Classification](https://arxiv.org/abs/2403.03849) | 提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。 |
| [^166] | [Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations](https://arxiv.org/abs/2403.02090) | 提出了三个新的具有挑战性的任务来模拟多人之间的细粒度动态，并为社交推理游戏设置提供了广泛的数据注释；同时提出了一种新颖的多模态基线方法，利用密集对齐的语言-视觉表示。 |
| [^167] | [Learning to Compress Prompt in Natural Language Formats](https://arxiv.org/abs/2402.18700) | 该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。 |
| [^168] | [Reinforcement Learning with Elastic Time Steps](https://arxiv.org/abs/2402.14961) | SEAC是一种弹性时间步长的离策略演员-评论家算法，通过可变持续时间的时间步长，使代理能够根据情况改变控制频率，在模拟环境中表现优异。 |
| [^169] | [Learning Memory Kernels in Generalized Langevin Equations](https://arxiv.org/abs/2402.11705) | 提出一种学习广义朗之万方程中记忆核的新方法，通过正则化Prony方法估计相关函数并在Sobolev范数Loss函数和RKHS正则化下实现回归，在指数加权的$L^2$空间内获得改进性能，对比其他回归估计器展示了其优越性。 |
| [^170] | [Online Local False Discovery Rate Control: A Resource Allocation Approach](https://arxiv.org/abs/2402.11425) | 该研究提出了一种在线局部虚发现率控制的资源分配方法，实现了$O(\sqrt{T})$的后悔率，并指出这种后悔率在一般情况下是不可改进的。 |
| [^171] | [Measuring and Controlling Persona Drift in Language Model Dialogs](https://arxiv.org/abs/2402.10962) | 提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移 |
| [^172] | [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://arxiv.org/abs/2402.07625) | 本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。 |
| [^173] | [Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data](https://arxiv.org/abs/2402.04498) | 本论文提出了一种名为路径空间卡尔曼滤波器（PKF）的扩展算法，可以动态跟踪数据和先前知识的不确定性，并用贝叶斯方法量化不同的不确定性来源。通过在合成数据集上进行数值实验，我们证明了PKF优于传统KF方法，并将该方法应用于生物时间序列数据集。 |
| [^174] | [Online Uniform Risk Times Sampling: First Approximation Algorithms, Learning Augmentation with Full Confidence Interval Integration](https://arxiv.org/abs/2402.01995) | 本文首次引入在线均匀风险时间抽样问题，并提出了两种在线近似算法，一种带有学习增强，一种没有学习增强。通过竞争比分析，我们提供了严格的理论性能保证。我们通过合成实验和实际案例研究评估了算法的性能。 |
| [^175] | [End-to-End Crystal Structure Prediction from Powder X-Ray Diffraction](https://arxiv.org/abs/2401.03862) | XtalNet是首个用于从粉末X射线衍射实现端到端晶体结构预测的等变深度生成模型，能够生成具有多达400个原子的有机结构。 |
| [^176] | [pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction](https://arxiv.org/abs/2312.12337) | 通过引入像素Splat，我们提出了一种学习从图像对中重建三维辐射场的模型，实现了内存高效渲染、高速3D重建，有效克服了稀疏表示的局部极小值问题，实现了优越的实时渲染性能。 |
| [^177] | [Large Human Language Models: A Need and the Challenges](https://arxiv.org/abs/2312.07751) | 大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。 |
| [^178] | [Large Language Models for Mathematicians](https://arxiv.org/abs/2312.04556) | 大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注，对数学家的潜在帮助和改变工作方式的影响进行了讨论。 |
| [^179] | [Classification for everyone : Building geography agnostic models for fairer recognition](https://arxiv.org/abs/2312.02957) | 本文分析了消除现有图像分类模型中地理偏见的方法，并探讨了如何使这些模型更加鲁棒到图像的地理位置。 |
| [^180] | [DiffiT: Diffusion Vision Transformers for Image Generation](https://arxiv.org/abs/2312.02139) | DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。 |
| [^181] | [Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking](https://arxiv.org/abs/2311.18817) | 通过早期和晚期隐性偏见的二分法，本文证明在训练同质神经网络时会出现从核预测器到最小范数/最大间隔预测器的急剧转变，从而引发测试准确性的显著变化。 |
| [^182] | [XLB: A differentiable massively parallel lattice Boltzmann library in Python](https://arxiv.org/abs/2311.16080) | XLB是一种基于Python的不同iable LBM库，优化了在不同硬件平台上的性能，并成功处理了数十亿个单元的模拟。 |
| [^183] | [Discovering Effective Policies for Land-Use Planning](https://arxiv.org/abs/2311.12304) | 通过学习代理模型并使用进化搜索过程，发现了可定制到不同位置的有效土地利用政策，为土地利用规划提供了一个潜在有用的工具。 |
| [^184] | [Low-Rank MDPs with Continuous Action Spaces](https://arxiv.org/abs/2311.03564) | 该研究通过探索多种方法，将针对低秩MDPs的现有方法扩展到连续动作空间，同时保持近似正确的学习保证。 |
| [^185] | [Separating and Learning Latent Confounders to Enhancing User Preferences Modeling](https://arxiv.org/abs/2311.03381) | 通过分离和学习潜在混淆因素，提高了用户偏好建模的准确性 |
| [^186] | [The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation](https://arxiv.org/abs/2310.20620) | 随机目标嵌入在连续输出神经机器翻译中表现出非理性有效性，尤其在较大的数据集上并且对罕见词效果最为显著。 |
| [^187] | [Affective and Dynamic Beam Search for Story Generation](https://arxiv.org/abs/2310.15079) | 本文提出了一种情感故事生成器AffGen，通过引入动态束调整和情感重新排名两种新技术，在叙事中注入“有趣的转折”，并在生成充满情感和有趣的叙事方面表现出优异性能。 |
| [^188] | [Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models](https://arxiv.org/abs/2310.05861) | 通过在输入中添加具有视觉基础的信息作为预防性澄清，可以提高模型性能，减少不充分性，并简化模型回答问题的方式。 |
| [^189] | [Investigating the Ability of PINNs To Solve Burgers' PDE Near Finite-Time BlowUp](https://arxiv.org/abs/2310.05169) | 通过理论分析和实验验证，研究者从严谨的视角探究了 PINNs 在接近有限时间爆炸的 Burgers' PDE 中的稳定性和泛化界限。 |
| [^190] | [Solving Attention Kernel Regression Problem via Pre-conditioner](https://arxiv.org/abs/2308.14304) | 本文通过定义两个问题，设计了用于注意力矩阵的代理快速算法及其回归问题求解算法。 |
| [^191] | [Traffic State Estimation from Vehicle Trajectories with Anisotropic Gaussian Processes](https://arxiv.org/abs/2303.02311) | 通过各向异性高斯过程的方法填补交通状态数据，提供更可靠的交通状态估计，具有统计不确定性量化。 |
| [^192] | [Robust One-Class Classification with Signed Distance Function using 1-Lipschitz Neural Networks](https://arxiv.org/abs/2303.01978) | 提出了一种新的方法OCSDF，通过学习带符号距离函数实现一类分类，提供鲁棒性边界对$l2$对抗攻击，竞争性能在表格和图像数据上，对抗攻击的鲁棒性强，连接OCC与图像生成和隐式神经表面参数。 |
| [^193] | [Benchmarking Model Predictive Control Algorithms in Building Optimization Testing Framework (BOPTEST)](https://arxiv.org/abs/2301.13447) | 提出了一个基于数据驱动的建模和控制框架，加速模型评估、提供成本效益的梯度，并在模型预测控制中保持良好的预测精度，同时通过建筑优化测试框架（BOPTEST）对建模和控制性能进行广泛评估 |
| [^194] | [BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations](https://arxiv.org/abs/2301.13418) | 本文提出了一种中间解决方案，即将训练构建为弱监督和半监督学习问题，以解决通过不完整注释数据检测恶性乳腺病变的困境 |
| [^195] | [A 65nm 8b-Activation 8b-Weight SRAM-Based Charge-Domain Computing-in-Memory Macro Using A Fully-Parallel Analog Adder Network and A Single-ADC Interface](https://arxiv.org/abs/2212.04320) | 提出了一种具有高吞吐量的SRAM ReLU优化CD-CiM宏，可以在一个CiM周期内完成两个8b向量的MAC和ReLU，仅需进行一次A/D转换。 |
| [^196] | [Interpretable Dimensionality Reduction by Feature Preserving Manifold Approximation and Projection](https://arxiv.org/abs/2211.09321) | featMAP方法通过保留源特征，利用切线空间嵌入和各向异性投影实现了可解释的降维，能够有效解释数字分类、目标检测和对抗样本的误分类。 |
| [^197] | [GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient Link Prediction](https://arxiv.org/abs/2210.01301) | GIDN模型通过创世模块在不同特征空间中泛化了图扩散，以达到更高的性能表现。 |
| [^198] | [From algorithms to action: improving patient care requires causality](https://arxiv.org/abs/2209.07397) | 改进患者护理需要考虑因果关系，建立和验证的预测模型必须对治疗决策的因果关系进行考虑，以避免在决策时造成伤害。 |
| [^199] | [Distributional Drift Adaptation with Temporal Conditional Variational Autoencoder for Multivariate Time Series Forecasting](https://arxiv.org/abs/2209.00654) | 提出了一种针对多变量时间序列预测中的分布漂移问题的解决方案，使用时间条件变分自动编码器（TCVAE）来模拟动态分布依赖关系，并利用潜在变量进行预测 |
| [^200] | [Bayesian Floor Field: Transferring people flow predictions across environments](https://arxiv.org/abs/2208.10851) | 提出了一种贝叶斯方法，能够结合环境几何知识和人类轨迹观察，学习人员动态，实现跨环境人流预测。 |
| [^201] | [Local and global topological complexity measures OF ReLU neural network functions](https://arxiv.org/abs/2204.06062) | 应用广义分段线性莫尔斯理论定义和研究了ReLU神经网络函数的局部和全局拓扑复杂度，提出了一个便于计算的紧凑模型，并证明局部复杂度可以任意高。 |
| [^202] | [Variational Dynamic for Self-Supervised Exploration in Deep Reinforcement Learning](https://arxiv.org/abs/2010.08755) | 该论文提出了一种基于条件变分推理的变分动态模型，用于在深度强化学习中解决自监督探索中的多模态性和随机性问题。 |
| [^203] | [VC dimension of Graph Neural Networks with Pfaffian activation functions.](http://arxiv.org/abs/2401.12362) | 本文分析了图神经网络（GNN）中使用不同常用激活函数（如sigmoid和双曲正切）时的VC维度，采用了Pfaffian函数理论框架，通过架构参数和合作数量提供了界限。 |
| [^204] | [Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats.](http://arxiv.org/abs/2401.10375) | 本文研究基于基础模型集成的联邦学习在敌对威胁下的漏洞，提出了一种新的攻击策略，揭示了该模型在不同配置的联邦学习下对敌对威胁的高敏感性。 |
| [^205] | [DEM: A Method for Certifying Deep Neural Network Classifier Outputs in Aerospace.](http://arxiv.org/abs/2401.02283) | 这项工作提出了一种新的、以输出为中心的方法，通过统计验证技术来认证深度神经网络(DNN)分类器的输出。该方法能够标记可能不可靠的特定输入，以便后续由人工专家检查。与现有技术相比，该方法主要关注单个输出而不是整个DNN的认证。 |
| [^206] | [Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning.](http://arxiv.org/abs/2311.09852) | 这项研究介绍了一种将短期计划生成和选择与分布式优化以及深度强化学习相结合的渐进方法，用于无人机的协调和规划。实验结果表明，与最先进的方法相比，该方法在动态环境中具有出色的性能。 |
| [^207] | [FedSN: A General Federated Learning Framework over LEO Satellite Networks.](http://arxiv.org/abs/2311.01483) | FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。 |
| [^208] | [Kiki or Bouba? Sound Symbolism in Vision-and-Language Models.](http://arxiv.org/abs/2310.16781) | 这项研究通过调查视觉与语言模型中的内在知识，发现它们显示了声音象征性的模式，进一步证实声音和意义之间的相关性在跨模态关联中得到了体现。 |
| [^209] | [Exploring the Relationship Between Model Architecture and In-Context Learning Ability.](http://arxiv.org/abs/2310.08049) | 现有的模型架构在上下文学习中表现最好，特别是在任务复杂性增加的情况下。不同架构对超参数设置的敏感度有所差异，且一些架构展现出平稳的学习轨迹。 |
| [^210] | [Hexa: Self-Improving for Knowledge-Grounded Dialogue System.](http://arxiv.org/abs/2310.06404) | 本论文提出了一种自我提升的方法，用于改进知识驱动对话生成的中间步骤的生成性能。通过引入引导提示和修改损失函数的自举策略，提高了生成自动生成回答的多样性，并在各种基准数据集上实验证明了该方法的有效性。 |
| [^211] | [TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting.](http://arxiv.org/abs/2310.04948) | 本文提出了一个新的框架 TEMPO，通过利用时间序列任务的两个重要归纳偏差，即将复杂交互分解和引入基于选择的提示来有效学习时间序列表示。 |
| [^212] | [On the Stability of Iterative Retraining of Generative Models on their own Data.](http://arxiv.org/abs/2310.00429) | 本文研究了生成模型在混合数据集上训练对稳定性的影响，通过证明初始生成模型足够接近数据分布并且数据比例适当，迭代训练是稳定的。 |
| [^213] | [Efficient tensor network simulation of IBM's largest quantum processors.](http://arxiv.org/abs/2309.15642) | 本文展示了如何使用量子启发的二维张量网络高效模拟IBM最大的量子处理器，通过简单的张量更新实现前所未有的准确度和极低的计算资源消耗，并为最新的IBM量子机器设立了基准。 |
| [^214] | [Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding.](http://arxiv.org/abs/2309.15028) | 本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。 |
| [^215] | [The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance.](http://arxiv.org/abs/2309.13775) | 提出了一种新的变量重要性框架，该框架在数据分布上是稳定的，并可以与现有的模型类和全局变量重要性指标结合使用。 |
| [^216] | [Gradient strikes back: How filtering out high frequencies improves explanations.](http://arxiv.org/abs/2307.09591) | 本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。 |
| [^217] | [Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation.](http://arxiv.org/abs/2307.05385) | 本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。 |
| [^218] | [Samplet basis pursuit.](http://arxiv.org/abs/2306.10180) | 本文提出了基于Samplet坐标下核学习的方法，其中引入l1正则化项可以增加系数的稀疏性。相比于单尺度基，Samplet基可以更好地表示更多类型的信号。作者提出了使用软阈值和半光滑牛顿法解决该问题的方法，并通过实验证明了其优越性。 |
| [^219] | [FasterViT: Fast Vision Transformers with Hierarchical Attention.](http://arxiv.org/abs/2306.06189) | 本研究设计了一种新型混合CNN-ViT神经网络FasterViT，引入了具有分层注意力的方法HAT，将全局自我注意力分解为多级注意力，实现了高效的跨窗口通信。 FasterViT在精度和图像吞吐量方面达到了SOTA前沿水平，并已在分类，物体检测和分割等CV任务中得到广泛验证。 |
| [^220] | [Few-shot Link Prediction on N-ary Facts.](http://arxiv.org/abs/2305.06104) | 本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。 |
| [^221] | [Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review.](http://arxiv.org/abs/2304.10550) | 本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。 |
| [^222] | [Bayesian neural networks via MCMC: a Python-based tutorial.](http://arxiv.org/abs/2304.02595) | 本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。 |
| [^223] | [Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights.](http://arxiv.org/abs/2303.07557) | 本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。 |
| [^224] | [Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time.](http://arxiv.org/abs/2302.11068) | 本论文提出了一种在几乎线性时间内用鲁棒交替最小化方法完成低秩矩阵补全的方法，并证明了观察几乎线性数量的条目即可恢复矩阵$M$，此方法克服了交替最小化方法需要精确计算的限制，更符合实际实现中对效率的要求。 |
| [^225] | [Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments.](http://arxiv.org/abs/2302.04823) | 本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。 |
| [^226] | [Estimating truncation effects of quantum bosonic systems using sampling algorithms.](http://arxiv.org/abs/2212.08546) | 本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。 |
| [^227] | [Contrastive Credibility Propagation for Reliable Semi-Supervised Learning.](http://arxiv.org/abs/2211.09929) | 对比可信度传播采用迭代的传导式伪标签细化，将半监督学习和嘈杂标签学习统一，可在各种数据场景中可靠地超过有监督基准。 |
| [^228] | [MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations.](http://arxiv.org/abs/2211.00713) | MAgNET是一个新颖的几何深度学习框架，基于MAg（多通道聚合）操作，采用图形U-Net架构处理任意结构（图形数据）的大维数据，能够高效地处理任意复杂的网格。 |
| [^229] | [On the Generalized Likelihood Ratio Test and One-Class Classifiers.](http://arxiv.org/abs/2210.12494) | 本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。 |
| [^230] | [CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty.](http://arxiv.org/abs/2208.08626) | 本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。 |
| [^231] | [Scalable Distributed Algorithms for Size-Constrained Submodular Maximization in the MapReduce and Adaptive Complexity Models.](http://arxiv.org/abs/2206.09563) | 本论文研究了在MapReduce和适应性复杂度模型中用于大小约束子模型最大化问题的可扩展分布式算法。通过使用几种次线性自适应算法，我们证明了这些算法满足在MR环境中所需的一致性特性，并且提出了世界首个具有恒定MR轮次的线性时间分布式算法。 |

# 详细

[^1]: 使用标记数据增强的测地插值方法学习蛋白质折叠的集体变量

    Learning Collective Variables for Protein Folding with Labeled Data Augmentation through Geodesic Interpolation

    [https://rss.arxiv.org/abs/2402.01542](https://rss.arxiv.org/abs/2402.01542)

    本实验提出了一种使用标记数据增强和测地插值方法学习蛋白质折叠的集体变量的策略，有效提高了采样效率，并在过渡态数据有限且嘈杂时表现优于基于分类器的方法。

    

    在分子动力学（MD）模拟中，通常通过增强采样技术来研究蛋白质折叠等罕见事件，其中大部分依赖于沿着加速发生的集体变量（CV）的定义。获得富有表达力的CV至关重要，但往往受到关于特定事件的信息不足的阻碍，例如从未折叠到折叠构象的转变。我们提出了一种模拟无关的数据增强策略，利用受物理启发的度量来生成类似蛋白质折叠转变的测地插值，从而提高采样效率，而无需真实的过渡态样本。通过利用插值进度参数，我们引入了基于回归的学习方案来构建CV模型，当过渡态数据有限且嘈杂时，该方法表现优于基于分类器的方法。

    In molecular dynamics (MD) simulations, rare events, such as protein folding, are typically studied by means of enhanced sampling techniques, most of which rely on the definition of a collective variable (CV) along which the acceleration occurs. Obtaining an expressive CV is crucial, but often hindered by the lack of information about the particular event, e.g., the transition from unfolded to folded conformation. We propose a simulation-free data augmentation strategy using physics-inspired metrics to generate geodesic interpolations resembling protein folding transitions, thereby improving sampling efficiency without true transition state samples. Leveraging interpolation progress parameters, we introduce a regression-based learning scheme for CV models, which outperforms classifier-based methods when transition state data is limited and noisy
    
[^2]: 用简单自适应攻击越狱功能对齐的LLM

    Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks

    [https://arxiv.org/abs/2404.02151](https://arxiv.org/abs/2404.02151)

    展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。

    

    我们展示了即使是最新的安全对齐的LLM也不具有抵抗简单自适应越狱攻击的稳健性。首先，我们展示了如何成功利用对logprobs的访问进行越狱：我们最初设计了一个对抗性提示模板（有时会适应目标LLM），然后我们在后缀上应用随机搜索以最大化目标logprob（例如token“Sure”），可能会进行多次重启。通过这种方式，我们实现了对GPT-3.5/4、Llama-2-Chat-7B/13B/70B、Gemma-7B和针对GCG攻击进行对抗训练的HarmBench上的R2D2等几乎100%的攻击成功率--根据GPT-4的评判。我们还展示了如何通过转移或预填充攻击以100%的成功率对所有不暴露logprobs的Claude模型进行越狱。此外，我们展示了如何在受污染的模型中使用对一组受限制的token执行随机搜索以查找木马字符串的方法--这项任务与许多其他任务共享相同的属性。

    arXiv:2404.02151v1 Announce Type: cross  Abstract: We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token "Sure"), potentially with multiple restarts. In this way, we achieve nearly 100\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many s
    
[^3]: 使用拉细孟划分在因子数据中稳健估计异质性

    Robustly estimating heterogeneity in factorial data using Rashomon Partitions

    [https://arxiv.org/abs/2404.02141](https://arxiv.org/abs/2404.02141)

    通过使用拉细孟划分集，我们能够在因子数据中稳健地估计异质性，并将因子空间划分成协变量组合的“池”，以便区分结果的差异。

    

    许多统计分析，无论是在观测数据还是随机对照试验中，都会问：感兴趣的结果如何随可观察协变量组合变化？不同的药物组合如何影响健康结果，科技采纳如何依赖激励和人口统计学？我们的目标是将这个因子空间划分成协变量组合的“池”，在这些池中结果会发生差异（但池内部不会发生），而现有方法要么寻找一个单一的“最优”分割，要么从可能分割的整个集合中抽样。这两种方法都忽视了这样一个事实：特别是在协变量之间存在相关结构的情况下，可能以许多种方式划分协变量空间，在统计上是无法区分的，尽管对政策或科学有着非常不同的影响。我们提出了一种名为拉细孟划分集的替代视角

    arXiv:2404.02141v1 Announce Type: cross  Abstract: Many statistical analyses, in both observational data and randomized control trials, ask: how does the outcome of interest vary with combinations of observable covariates? How do various drug combinations affect health outcomes, or how does technology adoption depend on incentives and demographics? Our goal is to partition this factorial space into ``pools'' of covariate combinations where the outcome differs across the pools (but not within a pool). Existing approaches (i) search for a single ``optimal'' partition under assumptions about the association between covariates or (ii) sample from the entire set of possible partitions. Both these approaches ignore the reality that, especially with correlation structure in covariates, many ways to partition the covariate space may be statistically indistinguishable, despite very different implications for policy or science. We develop an alternative perspective, called Rashomon Partition Set
    
[^4]: 基于主题的LLM生成文本的水印

    Topic-based Watermarks for LLM-Generated Text

    [https://arxiv.org/abs/2404.02138](https://arxiv.org/abs/2404.02138)

    提出了一种新的基于主题的水印算法，旨在解决当前水印方案的局限性，为区分LLM生成的文本和人类生成的文本提供了新的思路。

    

    大型语言模型（LLMs）的最新进展导致了生成的文本输出与人类生成的文本相似度难以分辨。水印算法是潜在工具，通过在LLM生成的输出中嵌入可检测的签名，可以区分LLM生成的文本和人类生成的文本。然而，当前的水印方案在已知攻击下缺乏健壮性。此外，考虑到LLM每天生成数万个文本输出，水印算法需要记忆每个输出才能让检测正常工作，这是不切实际的。本文针对当前水印方案的局限性，提出了针对LLMs的“基于主题的水印算法”概念。

    arXiv:2404.02138v1 Announce Type: cross  Abstract: Recent advancements of large language models (LLMs) have resulted in indistinguishable text outputs comparable to human-generated text. Watermarking algorithms are potential tools that offer a way to differentiate between LLM- and human-generated text by embedding detectable signatures within LLM-generated output. However, current watermarking schemes lack robustness against known attacks against watermarking algorithms. In addition, they are impractical considering an LLM generates tens of thousands of text outputs per day and the watermarking algorithm needs to memorize each output it generates for the detection to work. In this work, focusing on the limitations of current watermarking schemes, we propose the concept of a "topic-based watermarking algorithm" for LLMs. The proposed algorithm determines how to generate tokens for the watermarked LLM output based on extracted topics of an input prompt or the output of a non-watermarked 
    
[^5]: FLawN-T5: 有效指导调整数据混合在法律推理中的实证研究

    FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning

    [https://arxiv.org/abs/2404.02127](https://arxiv.org/abs/2404.02127)

    本研究提出了一个名为LawInstruct的大型法律指导数据集，证明了领域特定的预训练和指导调整可以改善在LegalBench上的性能，为在法律领域开发具有更强信息处理和决策能力的模型提供了一个资源。

    

    arXiv:2404.02127v1  公告类型: 跨领域  摘要: 指导调整是使语言模型对直接用户交互有效的重要步骤。然而，许多法律任务仍然超出了大多数开放式LLMs的范围，而且目前该领域还没有任何大规模的数据集。这严重限制了该应用领域的研究。在这项工作中，我们策划了一个名为LawInstruct的大型法律指导数据集，涵盖了17个司法管辖区、24种语言，总计1200万个示例。我们呈现证据表明，领域特定的预训练和指导调整能够改善在LegalBench上的性能，包括将Flan-T5 XL在基准线上提高8个点或16%。然而，该效应并不适用于所有任务、训练模式、模型大小和其他因素。LawInstruct是一个资源，可以加速在法律领域开发具有更强信息处理和决策能力的模型。

    arXiv:2404.02127v1 Announce Type: cross  Abstract: Instruction tuning is an important step in making language models useful for direct user interaction. However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain. This critically limits research in this application area. In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples. We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\% over the baseline. However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors. LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain.
    
[^6]: GINopic：利用图同构网络进行主题建模

    GINopic: Topic Modeling with Graph Isomorphism Network

    [https://arxiv.org/abs/2404.02115](https://arxiv.org/abs/2404.02115)

    GINopic是一种主题建模框架，利用图同构网络捕捉单词之间的相关性，相比于现有主题模型，展示了更好的有效性和推进主题建模的潜力。

    

    主题建模是分析和探索大型文档集合的广泛使用方法。 最近的研究工作将预训练的上下文化语言模型，如BERT嵌入，纳入主题建模中。 然而，它们通常忽略了单词之间相互依赖传达的固有信息价值。 本研究介绍了GINopic，一种基于图同构网络的主题建模框架，以捕捉单词之间的相关性。 通过在不同基准数据集上进行内在的（定量和定性）和外部的评估，我们展示了与现有主题模型相比，GINopic的有效性，并突出了其推进主题建模的潜力。

    arXiv:2404.02115v1 Announce Type: new  Abstract: Topic modeling is a widely used approach for analyzing and exploring large document collections. Recent research efforts have incorporated pre-trained contextualized language models, such as BERT embeddings, into topic modeling. However, they often neglect the intrinsic informational value conveyed by mutual dependencies between words. In this study, we introduce GINopic, a topic modeling framework based on graph isomorphism networks to capture the correlation between words. By conducting intrinsic (quantitative as well as qualitative) and extrinsic evaluations on diverse benchmark datasets, we demonstrate the effectiveness of GINopic compared to existing topic models and highlight its potential for advancing topic modeling.
    
[^7]: 针对未知进行调整：重新审视终身强化学习的评估策略

    Tuning for the Unknown: Revisiting Evaluation Strategies for Lifelong RL

    [https://arxiv.org/abs/2404.02113](https://arxiv.org/abs/2404.02113)

    提出了一种新方法来调整和评估终身强化学习代理，在此方法中，只有实验数据的一小部分可用于超参数调整，针对终身强化学习的研究进展可能被不当的经验方法所阻碍

    

    在继续或终身强化学习中，对环境的访问应该是有限的。如果我们希望设计的算法能够长时间运行，并不断适应新的、意想不到的情况，那么我们必须愿意在整个代理的整个生命周期内部署我们的代理而不调整它们的超参数。本文探讨了深度强化学习中 -- 甚至继续强化学习中 -- 具备对代理的部署环境具有无限制访问权的标准做法可能已经阻碍了对终身强化学习研究的进展。在本文中，我们提出了一种新的方法，用于调整和评估终身强化学习代理，其中只有实验数据的百分之一可以用于超参数调整。然后，我们对DQN和Soft Actor Critic在各种持续和非稳定领域进行了实证研究。我们发现这两种方法通常表现较好。

    arXiv:2404.02113v1 Announce Type: new  Abstract: In continual or lifelong reinforcement learning access to the environment should be limited. If we aspire to design algorithms that can run for long-periods of time, continually adapting to new, unexpected situations then we must be willing to deploy our agents without tuning their hyperparameters over the agent's entire lifetime. The standard practice in deep RL -- and even continual RL -- is to assume unfettered access to deployment environment for the full lifetime of the agent. This paper explores the notion that progress in lifelong RL research has been held back by inappropriate empirical methodologies. In this paper we propose a new approach for tuning and evaluating lifelong RL agents where only one percent of the experiment data can be used for hyperparameter tuning. We then conduct an empirical study of DQN and Soft Actor Critic across a variety of continuing and non-stationary domains. We find both methods generally perform po
    
[^8]: ImageNot：与ImageNet形成对比，保持模型排名

    ImageNot: A contrast with ImageNet preserves model rankings

    [https://arxiv.org/abs/2404.02112](https://arxiv.org/abs/2404.02112)

    ImageNot数据集与ImageNet形成对比，展示了关键模型在两个数据集上的排名一致性，以及它们相对于先前模型的改进在两个数据集中都具有强相关性，表明了ImageNot对于迁移学习具有类似效用于ImageNet。

    

    我们引入了ImageNot，这是一个旨在与ImageNet在规模上匹配但在其他方面有着显著差异的数据集。我们展示了多年来为ImageNet开发的关键模型架构在ImageNot上训练和评估时，其排名与它们在ImageNet上的排名完全相同。无论是从头开始训练模型还是微调模型，这一点都成立。此外，每个模型相对于先前模型的改进在两个数据集中都有很强的相关性。我们进一步提供证据表明，ImageNot在迁移学习目的上具有类似的效用于ImageNet。我们的工作展示了图像分类模型相对性能的惊人外部有效性。这与通常在数据集发生小变化时甚至细微改变时绝对准确度数字会急剧下降形成对比。

    arXiv:2404.02112v1 Announce Type: new  Abstract: We introduce ImageNot, a dataset designed to match the scale of ImageNet while differing drastically in other aspects. We show that key model architectures developed for ImageNet over the years rank identically when trained and evaluated on ImageNot to how they rank on ImageNet. This is true when training models from scratch or fine-tuning them. Moreover, the relative improvements of each model over earlier models strongly correlate in both datasets. We further give evidence that ImageNot has a similar utility as ImageNet for transfer learning purposes. Our work demonstrates a surprising degree of external validity in the relative performance of image classification models. This stands in contrast with absolute accuracy numbers that typically drop sharply even under small changes to a dataset.
    
[^9]: 适用于无限时域平均奖励马尔可夫决策过程的方差缩减策略梯度方法

    Variance-Reduced Policy Gradient Approaches for Infinite Horizon Average Reward Markov Decision Processes

    [https://arxiv.org/abs/2404.02108](https://arxiv.org/abs/2404.02108)

    提出了两种基于策略梯度的方法，分别利用隐式梯度传输和基于Hessian的技术，分别确保了$\tilde{\mathcal{O}}(T^{3/5})$和$\tilde{\mathcal{O}}(\sqrt{T})$数量级的期望后悔。

    

    我们在无限时域平均奖励马尔可夫决策过程的背景下，提出了两种基于策略梯度的方法，具有一般参数化。第一种方法使用隐式梯度传输进行方差缩减，确保期望后悔的数量级为$\tilde{\mathcal{O}}(T^{3/5})$。第二种方法，根植于基于Hessian的技术，确保期望后悔的数量级为$\tilde{\mathcal{O}}(\sqrt{T})$。这些结果显著改进了该问题的现有技术水平，其后悔率为$\tilde{\mathcal{O}}(T^{3/4})。

    arXiv:2404.02108v1 Announce Type: new  Abstract: We present two Policy Gradient-based methods with general parameterization in the context of infinite horizon average reward Markov Decision Processes. The first approach employs Implicit Gradient Transport for variance reduction, ensuring an expected regret of the order $\tilde{\mathcal{O}}(T^{3/5})$. The second approach, rooted in Hessian-based techniques, ensures an expected regret of the order $\tilde{\mathcal{O}}(\sqrt{T})$. These results significantly improve the state of the art of the problem, which achieves a regret of $\tilde{\mathcal{O}}(T^{3/4})$.
    
[^10]: 通过首选树推进LLM推理通用性

    Advancing LLM Reasoning Generalists with Preference Trees

    [https://arxiv.org/abs/2404.02078](https://arxiv.org/abs/2404.02078)

    新推出的Eurus模型通过基于首选树的推理优化，在多项基准测试中取得了业界领先的成果，尤其在击败了GPT-3.5 Turbo的基准测试中表现突出。

    

    我们介绍了Eurus，一套专为推理优化的大语言模型（LLMs）。经过Mistral-7B和CodeLlama-70B的微调，Eurus模型在涵盖数学、代码生成和逻辑推理问题的多样化基准测试中取得了业界领先的成果。值得注意的是，Eurus-70B在通过涵盖五项任务的12个测试的全面基准测试中击败了GPT-3.5 Turbo，并在LeetCode和TheoremQA两个具有挑战性的基准测试中分别实现了33.3%和32.6%的pass@1准确率，明显优于现有开源模型超过13.3%的边际。Eurus的强大性能主要归功于我们新设计的大规模、高质量对齐数据集UltraInteract，该数据集专门为复杂推理任务而设计。UltraInteract可用于监督微调和首选学习。对于每个指令，它包括一个首选树。

    arXiv:2404.02078v1 Announce Type: new  Abstract: We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a comprehensive benchmarking across 12 tests covering five tasks, and achieves a 33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging benchmarks, substantially outperforming existing open-source models by margins more than 13.3%. The strong performance of Eurus can be primarily attributed to UltraInteract, our newly-curated large-scale, high-quality alignment dataset specifically designed for complex reasoning tasks. UltraInteract can be used in both supervised fine-tuning and preference learning. For each instruction, it includes a preference tree consisting o
    
[^11]: 从Transformer中提取图形用于场景图生成

    EGTR: Extracting Graph from Transformer for Scene Graph Generation

    [https://arxiv.org/abs/2404.02072](https://arxiv.org/abs/2404.02072)

    提出了一种从Transformer中提取图形以用于场景图生成的轻量级单阶段模型，有效地提取了关系图。

    

    场景图生成（SGG）是一项具有挑战性的任务，涉及检测对象并预测对象之间的关系。提出了一个轻量级的单阶段SGG模型，它从DETR解码器的多头自注意力层中学习的各种关系中提取关系图。

    arXiv:2404.02072v1 Announce Type: cross  Abstract: Scene Graph Generation (SGG) is a challenging task of detecting objects and predicting relationships between objects. After DETR was developed, one-stage SGG models based on a one-stage object detector have been actively studied. However, complex modeling is used to predict the relationship between objects, and the inherent relationship between object queries learned in the multi-head self-attention of the object detector has been neglected. We propose a lightweight one-stage SGG model that extracts the relation graph from the various relationships learned in the multi-head self-attention layers of the DETR decoder. By fully utilizing the self-attention by-products, the relation graph can be extracted effectively with a shallow relation extraction head. Considering the dependency of the relation extraction task on the object detection task, we propose a novel relation smoothing technique that adjusts the relation label adaptively accor
    
[^12]: 红队测试端分任意模型

    Red-Teaming Segment Anything Model

    [https://arxiv.org/abs/2404.02067](https://arxiv.org/abs/2404.02067)

    本文对端分任意模型进行了多方面的红队分析，发现模型在应对风格迁移、隐私攻击和敌对攻击方面存在一些挑战

    

    基础模型已经成为重要的工具，通过在大量数据集上进行预训练，然后对特定应用进行微调，来解决许多复杂任务。端分任意模型是计算机视觉分割任务中第一个也是最知名的基础模型之一。本文提出了一个多方面的红队分析，测试了端分任意模型在挑战性任务上的表现：（1）我们分析了风格迁移对分割掩模的影响，证明将逆境天气条件和雨滴应用于城市道路仪表盘图像显著扭曲生成的掩模。（2）我们专注于评估模型是否可以用于攻击隐私，如识别名人的面孔，并显示出模型在这一任务上具有一些不良知识。（3）最后，我们检查模型在文本提示下对分割掩模的敌对攻击有多强大。我们不仅展示了

    arXiv:2404.02067v1 Announce Type: cross  Abstract: Foundation models have emerged as pivotal tools, tackling many complex tasks through pre-training on vast datasets and subsequent fine-tuning for specific applications. The Segment Anything Model is one of the first and most well-known foundation models for computer vision segmentation tasks. This work presents a multi-faceted red-teaming analysis that tests the Segment Anything Model against challenging tasks: (1) We analyze the impact of style transfer on segmentation masks, demonstrating that applying adverse weather conditions and raindrops to dashboard images of city roads significantly distorts generated masks. (2) We focus on assessing whether the model can be used for attacks on privacy, such as recognizing celebrities' faces, and show that the model possesses some undesired knowledge in this task. (3) Finally, we check how robust the model is to adversarial attacks on segmentation masks under text prompts. We not only show the
    
[^13]: 大规模语言模型中的数字遗忘：遗忘方法综述

    Digital Forgetting in Large Language Models: A Survey of Unlearning Methods

    [https://arxiv.org/abs/2404.02062](https://arxiv.org/abs/2404.02062)

    本综述聚焦于大型语言模型中的数字遗忘，旨在获得一种遗忘方法，能有效地消除模型中的不良知识或行为，同时保留原始模型在理想任务上的性能，并具有可伸缩性。

    

    数字遗忘的目标是，在给定一个存在不良知识或行为的模型的情况下，得到一个新模型，其中不再存在检测到的问题。遗忘的动机包括隐私保护、版权保护、消除偏见和歧视以及预防有害内容生成。有效的数字遗忘必须是有效的（即新模型多么好地遗忘了不良知识/行为），保留原始模型在理想任务上的性能，并且具有可伸缩性（特别是遗忘必须比仅重新训练要有效，仅重新训练需要保留的任务/数据）。本综述聚焦于大型语言模型（LLMs）中的遗忘。首先，我们介绍LLMs的背景，包括它们的组成部分、LLMs的类型以及它们通常的训练流程。其次，我们描述数字遗忘的动机、类型和期望的属性。

    arXiv:2404.02062v1 Announce Type: cross  Abstract: The objective of digital forgetting is, given a model with undesirable knowledge or behavior, obtain a new model where the detected issues are no longer present. The motivations for forgetting include privacy protection, copyright protection, elimination of biases and discrimination, and prevention of harmful content generation. Effective digital forgetting has to be effective (meaning how well the new model has forgotten the undesired knowledge/behavior), retain the performance of the original model on the desirable tasks, and be scalable (in particular forgetting has to be more efficient than retraining from scratch on just the tasks/data to be retained). This survey focuses on forgetting in large language models (LLMs). We first provide background on LLMs, including their components, the types of LLMs, and their usual training pipeline. Second, we describe the motivations, types, and desired properties of digital forgetting. Third, 
    
[^14]: 具有快速prop的可推广、快速和准确的DeepQSPR Part 1: 框架和基准测试

    Generalizable, Fast, and Accurate DeepQSPR with fastprop Part 1: Framework and Benchmarks

    [https://arxiv.org/abs/2404.02058](https://arxiv.org/abs/2404.02058)

    fastprop是一种DeepQSPR框架，通过使用分子级描述符，在极大缩短时间内，在多样数据集上达到并超越了学习表示的性能。

    

    量化结构-性质关系研究旨在定义分子结构与任意感兴趣的数量之间的映射。历史上，这是通过开发描述符来实现的，这需要显著的领域专业知识，并且难以泛化。因此，该领域已经演变为分子属性预测，并转为使用高度可推广的学习表示。该论文介绍了fastprop，一种DeepQSPR框架，使用一组明智的分子级描述符，在极大缩短的时间内满足并超越了多样数据集上学习表示的性能。fastprop可以在github上免费获取，网址为github.com/JacksonBurns/fastprop。

    arXiv:2404.02058v1 Announce Type: new  Abstract: Quantitative Structure Property Relationship studies aim to define a mapping between molecular structure and arbitrary quantities of interest. This was historically accomplished via the development of descriptors which requires significant domain expertise and struggles to generalize. Thus the field has morphed into Molecular Property Prediction and been given over to learned representations which are highly generalizable. The paper introduces fastprop, a DeepQSPR framework which uses a cogent set of molecular level descriptors to meet and exceed the performance of learned representations on diverse datasets in dramatically less time. fastprop is freely available on github at github.com/JacksonBurns/fastprop.
    
[^15]: 预训练语音模型的噪声遮蔽攻击与防御

    Noise Masking Attacks and Defenses for Pretrained Speech Models

    [https://arxiv.org/abs/2404.02052](https://arxiv.org/abs/2404.02052)

    本研究提出了针对预训练语音编码器的噪声遮蔽攻击，并深入探讨了攻击的精度提升和反制措施。

    

    语音模型经常在敏感数据上进行训练以提高模型性能，但这可能导致潜在的隐私泄露。在本工作中，我们考虑了Amid等人于2022年提出的噪声遮蔽攻击，这些攻击针对自动语音识别（ASR）模型，通过请求一段部分被噪声替换的话语的转录来实施攻击。他们表明，当训练时看到了一条记录，模型将用其记忆的敏感转录转录这个带有噪声的记录。在我们的工作中，我们将这些攻击扩展到预训练语音编码器，并且我们的方法微调编码器以生成一个ASR模型，然后在该模型上进行噪声遮蔽，我们发现这种方法可以从预训练数据中恢复私人信息，尽管模型在预训练时从未看过转录！我们展示了如何提高这些攻击的精度，并研究了一些针对我们攻击的对策。

    arXiv:2404.02052v1 Announce Type: new  Abstract: Speech models are often trained on sensitive data in order to improve model performance, leading to potential privacy leakage. Our work considers noise masking attacks, introduced by Amid et al. 2022, which attack automatic speech recognition (ASR) models by requesting a transcript of an utterance which is partially replaced with noise. They show that when a record has been seen at training time, the model will transcribe the noisy record with its memorized sensitive transcript. In our work, we extend these attacks beyond ASR models, to attack pretrained speech encoders. Our method fine-tunes the encoder to produce an ASR model, and then performs noise masking on this model, which we find recovers private information from the pretraining data, despite the model never having seen transcripts at pretraining time! We show how to improve the precision of these attacks and investigate a number of countermeasures to our attacks.
    
[^16]: 金融交易数据的通用表示：融合本地、全局和外部语境

    Universal representations for financial transactional data: embracing local, global, and external contexts

    [https://arxiv.org/abs/2404.02047](https://arxiv.org/abs/2404.02047)

    提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。

    

    金融交易的有效处理对银行数据分析至关重要。然而，在这一领域中，大多数方法专注于为独立问题提供专门化解决方案，而不是构建适用于许多问题的通用表示。我们提出了一个表示学习框架，旨在解决各种企业挑战。我们还提出了考虑数据特定性的新颖生成模型，并提出了一种整合外部信息到客户表示的方式，借鉴其他客户行动的见解。最后，我们提供了一个基准，描述了全球范围内的表示质量，涉及整个交易历史；本地范围内，反映客户当前状态；动态范围内，捕捉表示随时间演变的情况。我们的生成方法在本地任务中表现出色，对于下一个MCC预测任务的ROC-AUC提升高达14％，对于dow...

    arXiv:2404.02047v1 Announce Type: cross  Abstract: Effective processing of financial transactions is essential for banking data analysis. However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems. We present a representation learning framework that addresses diverse business challenges. We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions. Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time. Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\% for the next MCC prediction task and up to 46\% for dow
    
[^17]: 变压器作为传感器

    Transformers as Transducers

    [https://arxiv.org/abs/2404.02040](https://arxiv.org/abs/2404.02040)

    通过将变压器与有限传感器联系起来，我们发现它们可以表达令人惊讶的大类传感，进一步扩展了RASP，推出了新的变体，并展示了掩码平均困难注意变压器可以模拟S-RASP.

    

    我们通过将变压器与有限传感器联系起来，研究了变压器的序列到序列映射能力，并发现它们可以表达令人惊讶的大类传感。我们使用RASP的变体，这是一种旨在帮助人们“像变压器一样思考”的编程语言，作为中间表示。我们扩展了现有的布尔变体B-RASP到序列到序列函数，并展示了它确切计算了一阶有理函数（如字符串旋转）。然后，我们引入了两个新扩展。B-RASP[pos]允许在位置上进行计算（如复制字符串的前半部分），并包含所有一阶正则函数。S-RASP添加前缀和，可以进行额外的算术操作（如对字符串求平方），并包含所有一阶多正则函数。最后，我们展示了掩码平均困难注意变压器可以模拟S-RASP。我们结果的一个推论是n...

    arXiv:2404.02040v1 Announce Type: cross  Abstract: We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of transductions. We do so using variants of RASP, a programming language designed to help people "think like transformers," as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence functions and show that it computes exactly the first-order rational functions (such as string rotation). Then, we introduce two new extensions. B-RASP[pos] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular functions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular functions. Finally, we show that masked average-hard attention transformers can simulate S-RASP. A corollary of our results is a n
    
[^18]: AUTODIFF：基于结构的药物设计的自回归扩散建模

    AUTODIFF: Autoregressive Diffusion Modeling for Structure-based Drug Design

    [https://arxiv.org/abs/2404.02003](https://arxiv.org/abs/2404.02003)

    提出了一种基于扩散的分段自回归生成模型AUTODIFF，其中包括一种名为conformal motif的新型分子组装策略和SE(3)-等变卷积网络编码蛋白质-配体复合物相互作用的方法，能够解决结构基药物设计中的局部结构和构象问题。

    

    结构基药物设计（SBDD）旨在生成能够紧密结合靶蛋白的分子，是药物发现中的一个关键问题，先前的方法已经取得了初步成功。然而，大多数现有方法仍然存在无效的局部结构或不现实的构象问题，这主要是由于键角或扭转角度的倾斜不足造成的。为了缓解这些问题，我们提出了AUTODIFF，一种基于扩散的分段自回归生成模型。具体而言，我们设计了一种名为conformal motif的新型分子组装策略，首先保留分子的局部结构的构象，然后我们使用SE(3)-等变卷积网络编码蛋白质-配体复合物的相互作用，并通过扩散建模逐个motif生成分子。此外，我们还通过约束生成分子的分子质量改进了SBDD的评估框架。

    arXiv:2404.02003v1 Announce Type: new  Abstract: Structure-based drug design (SBDD), which aims to generate molecules that can bind tightly to the target protein, is an essential problem in drug discovery, and previous approaches have achieved initial success. However, most existing methods still suffer from invalid local structure or unrealistic conformation issues, which are mainly due to the poor leaning of bond angles or torsional angles. To alleviate these problems, we propose AUTODIFF, a diffusion-based fragment-wise autoregressive generation model. Specifically, we design a novel molecule assembly strategy named conformal motif that preserves the conformation of local structures of molecules first, then we encode the interaction of the protein-ligand complex with an SE(3)-equivariant convolutional network and generate molecules motif-by-motif with diffusion modeling. In addition, we also improve the evaluation framework of SBDD by constraining the molecular weights of the genera
    
[^19]: 非洲中心自监督预训练技术在撒哈拉以南地区的多语言语音表征中的应用

    Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context

    [https://arxiv.org/abs/2404.02000](https://arxiv.org/abs/2404.02000)

    这项研究提出了首个仅在非洲语音上进行训练的自监督多语言语音模型，相比于常规方法，更高效并在ASR和LID任务中表现出竞争力。

    

    我们提出了第一个仅在非洲语音上进行训练的自监督多语言语音模型。该模型从撒哈拉以南非洲地区讲话的21种语言和方言中学习了近60,000小时的未标记语音片段。在FLEURS-102数据集的SSA子集上，我们基于HuBERT$_{base}$ (0.09B) 架构的方法展现出了具有竞争力的结果，与FLEURS基准提出的w2v-bert-51 (0.6B) 预训练模型相比，在ASR下游任务中更加高效，使用的数据量少7倍，参数少6倍。此外，在LID下游任务中，我们的方法在准确率上超过FLEURS基线超过22%。

    arXiv:2404.02000v1 Announce Type: new  Abstract: We present the first self-supervised multilingual speech model trained exclusively on African speech. The model learned from nearly 60 000 hours of unlabeled speech segments in 21 languages and dialects spoken in sub-Saharan Africa. On the SSA subset of the FLEURS-102 dataset, our approach based on a HuBERT$_{base}$ (0.09B) architecture shows competitive results, for ASR downstream task, compared to the w2v-bert-51 (0.6B) pre-trained model proposed in the FLEURS benchmark, while being more efficient by using 7x less data and 6x less parameters. Furthermore, in the context of a LID downstream task, our approach outperforms FLEURS baselines accuracy by over 22\%.
    
[^20]: 利用多智能体强化学习实现趋化策略的出现

    Emergence of Chemotactic Strategies with Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2404.01999](https://arxiv.org/abs/2404.01999)

    强化学习在趋化方面的应用研究表明，智能体能够根据布朗运动物理约束快速实现趋化，同时发现新兴策略的效率和智能体大小、游泳速度的收敛。

    

    强化学习（RL）是一种在复杂环境中为微型机器人编程的灵活高效的方法。本文探讨了当强化学习被训练执行趋化时，是否能向生物系统提供洞察。具体而言，我们探究了智能体如何处理信息以朝向目标游动。我们进行了一系列模拟实验，涵盖了各种智能体形状、大小和游泳速度，以确定生物游泳者的物理约束，即布朗运动，是否导致强化学习者的训练失败。我们发现RL智能体可以在物理可能性范围内执行趋化，并且在某些情况下，甚至在主动游动压倒随机环境之前就能执行趋化。我们研究了新兴政策的效率，并确定了智能体大小和游泳速度的收敛。最后，我们研究了强化学习算法采用的策略。

    arXiv:2404.01999v1 Announce Type: cross  Abstract: Reinforcement learning (RL) is a flexible and efficient method for programming micro-robots in complex environments. Here we investigate whether reinforcement learning can provide insights into biological systems when trained to perform chemotaxis. Namely, whether we can learn about how intelligent agents process given information in order to swim towards a target. We run simulations covering a range of agent shapes, sizes, and swim speeds to determine if the physical constraints on biological swimmers, namely Brownian motion, lead to regions where reinforcement learners' training fails. We find that the RL agents can perform chemotaxis as soon as it is physically possible and, in some cases, even before the active swimming overpowers the stochastic environment. We study the efficiency of the emergent policy and identify convergence in agent size and swim speeds. Finally, we study the strategy adopted by the reinforcement learning algo
    
[^21]: 低光强度增强的反光因子分解

    Specularity Factorization for Low-Light Enhancement

    [https://arxiv.org/abs/2404.01998](https://arxiv.org/abs/2404.01998)

    提出了一种新的加法图像分解技术，利用反光因子分解进行低光增强，无需配对或非配对监督训练，提高了低光增强性能并在多个数据集上实现更好的泛化。

    

    我们提出了一种新的加法图像分解技术，将图像看作由多个潜在的反光组件组成，这些组件可以通过在分解过程中调制稀疏性来简单地递归估计。我们的模型驱动的RSFNet通过将优化展开成网络层来估计这些因子，仅需要学习少量标量。由设计可解释的结果因子可以通过网络融合用于不同的图像增强任务，或以用户可控的方式直接进行组合。基于RSFNet，我们详细介绍了一个无配对或非配对监督训练的零参考低光增强（LLE）应用。我们的系统提高了标准基准测试的最新性能，并在多个其他数据集上实现了更好的泛化。我们还将我们的因子与其他任务特定的融合网络集成，用于去雨、去模糊和去雾等应用。

    arXiv:2404.01998v1 Announce Type: cross  Abstract: We present a new additive image factorization technique that treats images to be composed of multiple latent specular components which can be simply estimated recursively by modulating the sparsity during decomposition. Our model-driven {\em RSFNet} estimates these factors by unrolling the optimization into network layers requiring only a few scalars to be learned. The resultant factors are interpretable by design and can be fused for different image enhancement tasks via a network or combined directly by the user in a controllable fashion. Based on RSFNet, we detail a zero-reference Low Light Enhancement (LLE) application trained without paired or unpaired supervision. Our system improves the state-of-the-art performance on standard benchmarks and achieves better generalization on multiple other datasets. We also integrate our factors with other task specific fusion networks for applications like deraining, deblurring and dehazing wit
    
[^22]: DELAN: 通过跨模态对比学习实现视觉与语言导航的双层对齐

    DELAN: Dual-Level Alignment for Vision-and-Language Navigation by Cross-Modal Contrastive Learning

    [https://arxiv.org/abs/2404.01994](https://arxiv.org/abs/2404.01994)

    通过跨模态对比学习实现的DELAN框架提出了双层对齐方法，以提升视觉与语言导航中的跨模态交互和行动决策。

    

    arXiv:2404.01994v1 公告类型: 交叉  摘要: 视觉与语言导航(VLN)要求代理根据自然语言指示在未知环境中导航。为了完成任务，代理需要对齐和整合各种导航模态，包括指示、观察和导航历史。现有研究主要集中在融合阶段的跨模态注意力，以实现这一目标。然而，由不同单一编码器生成的模态特征位于各自的空间中，导致跨模态融合和决策质量下降。为了解决这一问题，我们提出了通过跨模态对比学习实现的Dual-levEL AligNment (DELAN)框架。该框架旨在在融合之前对齐各种与导航相关的模态，从而增强跨模态交互和行动决策。具体而言，我们将预融合对齐分为两个层次: 指示-历史层和地标-观察

    arXiv:2404.01994v1 Announce Type: cross  Abstract: Vision-and-Language navigation (VLN) requires an agent to navigate in unseen environment by following natural language instruction. For task completion, the agent needs to align and integrate various navigation modalities, including instruction, observation and navigation history. Existing works primarily concentrate on cross-modal attention at the fusion stage to achieve this objective. Nevertheless, modality features generated by disparate uni-encoders reside in their own spaces, leading to a decline in the quality of cross-modal fusion and decision. To address this problem, we propose a Dual-levEL AligNment (DELAN) framework by cross-modal contrastive learning. This framework is designed to align various navigation-related modalities before fusion, thereby enhancing cross-modal interaction and action decision-making. Specifically, we divide the pre-fusion alignment into dual levels: instruction-history level and landmark-observation
    
[^23]: 预测与服务机器人互动意图：凝视线索的作用

    Predicting the Intention to Interact with a Service Robot:the Role of Gaze Cues

    [https://arxiv.org/abs/2404.01986](https://arxiv.org/abs/2404.01986)

    凝视线索的有效利用显著提高了服务机器人感知用户互动意图的性能，分类准确性和适应新环境能力。

    

    对于服务机器人来说，尽快感知一个接近的人是否有意互动至关重要：在这种情况下，它可以主动采取友好行为，从而提高用户体验。我们通过一个潜在用户互动意图的序列到序列分类器来解决这个感知任务，可以以自监督方式进行训练。我们的主要贡献在于研究在这一背景下代表个人凝视的特征的益处。对新颖数据集进行的大量实验证明了凝视线索的包含显著改善了分类器性能（AUROC从84.5%提高到91.2%）；可以实现准确分类的距离从2.4米提高到3.2米。我们还量化了系统在没有外部监督的情况下适应新环境的能力。定性实验展示了服务员机器人的实际应用。

    arXiv:2404.01986v1 Announce Type: cross  Abstract: For a service robot, it is crucial to perceive as early as possible that an approaching person intends to interact: in this case, it can proactively enact friendly behaviors that lead to an improved user experience. We solve this perception task with a sequence-to-sequence classifier of a potential user intention to interact, which can be trained in a self-supervised way. Our main contribution is a study of the benefit of features representing the person's gaze in this context. Extensive experiments on a novel dataset show that the inclusion of gaze cues significantly improves the classifier performance (AUROC increases from 84.5% to 91.2%); the distance at which an accurate classification can be achieved improves from 2.4 m to 3.2 m. We also quantify the system's ability to adapt to new environments without external supervision. Qualitative experiments show practical applications with a waiter robot.
    
[^24]: 临床试验中的零样本多语言说话者验证

    Zero-Shot Multi-Lingual Speaker Verification in Clinical Trials

    [https://arxiv.org/abs/2404.01981](https://arxiv.org/abs/2404.01981)

    提出在临床试验中利用患者语音数据进行多语言说话者验证，以应对身份验证和排除重复入组的挑战。

    

    由于临床试验涉及大量临床医生、患者和数据收集环境，获取高质量数据面临重大挑战。在临床试验中，患者根据其语音数据进行评估，以检测和监测认知和心理健康障碍。我们提出使用这些语音录音来验证已入组患者的身份，并识别和排除试图多次入组同一试验的个体。由于临床研究经常跨越不同国家进行，因此必须创建一个能够在不同语言中执行说话者验证的系统，而无需额外开发工作。我们通过招募和测试讲英语、德语、丹麦语、西班牙语和阿拉伯语的语音受损患者来评估预训练的TitaNet、ECAPA-TDNN和SpeakerNet模型。我们的结果表明，经过测试的模型能够有效泛化。

    arXiv:2404.01981v1 Announce Type: new  Abstract: Due to the substantial number of clinicians, patients, and data collection environments involved in clinical trials, gathering data of superior quality poses a significant challenge. In clinical trials, patients are assessed based on their speech data to detect and monitor cognitive and mental health disorders. We propose using these speech recordings to verify the identities of enrolled patients and identify and exclude the individuals who try to enroll multiple times in the same trial. Since clinical studies are often conducted across different countries, creating a system that can perform speaker verification in diverse languages without additional development effort is imperative. We evaluate pre-trained TitaNet, ECAPA-TDNN, and SpeakerNet models by enrolling and testing with speech-impaired patients speaking English, German, Danish, Spanish, and Arabic languages. Our results demonstrate that tested models can effectively generalize 
    
[^25]: 联合任务正则化用于部分标记的多任务学习

    Joint-Task Regularization for Partially Labeled Multi-Task Learning

    [https://arxiv.org/abs/2404.01976](https://arxiv.org/abs/2404.01976)

    提出了一种联合任务正则化（JTR）技术，通过在单个联合任务潜在空间中同时对所有任务进行正则化，改善了当数据未完全标记所有任务时的学习。

    

    多任务学习在机器学习领域变得越来越流行，但其实用性受到需要大量标记数据集的限制。大多数多任务学习方法依赖完全标记的数据集，其中每个输入示例都附带所有目标任务的地面真相标签。不幸的是，筛选这样的数据集可能会因为昂贵且不切实际，尤其是对于需要每个图像的每个像素标签的密集预测任务。基于此，我们提出了联合任务正则化（JTR），这是一种直观的技术，利用跨任务关系在单个联合任务潜在空间中同时对所有任务进行正则化，以改善在数据未完全标记所有任务时的学习。JTR与现有方法有所不同之处在于它同时对所有任务进行正则化而不是分别对每对任务进行，因此实现了相对于任务数量的线性复杂度，而以前的方法没有做到这一点。

    arXiv:2404.01976v1 Announce Type: cross  Abstract: Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets. Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks. Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image. With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks. JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous 
    
[^26]: DSGNN: 一种用于区域空气质量估计的双视图超网格感知图神经网络

    DSGNN: A Dual-View Supergrid-Aware Graph Neural Network for Regional Air Quality Estimation

    [https://arxiv.org/abs/2404.01975](https://arxiv.org/abs/2404.01975)

    DSGNN 提出了一种新的双视图超网格感知图神经网络，能够从卫星数据和气象数据中模拟远距离网格区域的空间依赖关系，以实现区域空气质量估计。

    

    空气质量估计可以为没有空气质量监测站的目标区域提供空气质量，对公众有用。 已有的空气质量估计方法将研究区域划分为不相交的网格区域，并应用二维卷积来根据地理学的第一定律模拟相邻网格区域的空间依赖关系，但未能模拟远距离网格区域的空间依赖关系。 为此，我们提出了一种用于区域空气质量估计的双视图超网格感知图神经网络（DSGNN），可以从双视图（即，卫星获取的气溶胶光学厚度（AOD）和气象学）模拟远距离网格区域的空间依赖关系。 具体来说，利用图像来表示区域数据（即，AOD数据和气象数据）。 引入双视图超网格学习模块以参数化方式生成超网格。 基于双视图超网格，双视图隐性相关性

    arXiv:2404.01975v1 Announce Type: new  Abstract: Air quality estimation can provide air quality for target regions without air quality stations, which is useful for the public. Existing air quality estimation methods divide the study area into disjointed grid regions, and apply 2D convolution to model the spatial dependencies of adjacent grid regions based on the first law of geography, failing to model the spatial dependencies of distant grid regions. To this end, we propose a Dual-view Supergrid-aware Graph Neural Network (DSGNN) for regional air quality estimation, which can model the spatial dependencies of distant grid regions from dual views (i.e., satellite-derived aerosol optical depth (AOD) and meteorology). Specifically, images are utilized to represent the regional data (i.e., AOD data and meteorology data). The dual-view supergrid learning module is introduced to generate supergrids in a parameterized way. Based on the dual-view supergrids, the dual-view implicit correlatio
    
[^27]: 旨在利用AutoML实现可持续深度学习：基于Deep Shift神经网络的多目标HPO方法

    Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks

    [https://arxiv.org/abs/2404.01965](https://arxiv.org/abs/2404.01965)

    该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。

    

    深度学习（DL）通过从大型数据集中提取复杂模式推动了各个领域的发展。然而，DL模型的计算需求带来了环境和资源挑战。Deep Shift神经网络（DSNN）利用shift操作减少推理时的计算复杂性，为此提供了解决方案。通过借鉴标准DNN的见解，我们有兴趣通过AutoML技术充分发挥DSNN的潜力。我们研究了超参数优化（HPO）对于最大化DSNN性能同时最小化资源消耗的影响。由于将准确性和能耗作为可能互补目标结合的多目标（MO）优化，我们建议将最先进的多保真度（MF）HPO与多目标优化相结合。实验结果证明了我们方法的有效性，得到了准确率超过80％且计算低耗的模型。

    arXiv:2404.01965v1 Announce Type: cross  Abstract: Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets. However, the computational demands of DL models pose environmental and resource challenges. Deep shift neural networks (DSNNs) offer a solution by leveraging shift operations to reduce computational complexity at inference. Following the insights from standard DNNs, we are interested in leveraging the full potential of DSNNs by means of AutoML techniques. We study the impact of hyperparameter optimization (HPO) to maximize DSNN performance while minimizing resource consumption. Since this combines multi-objective (MO) optimization with accuracy and energy consumption as potentially complementary objectives, we propose to combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization. Experimental results demonstrate the effectiveness of our approach, resulting in models with over 80\% in accuracy and low computational 
    
[^28]: 基于CAM的方法可以穿墙而过

    CAM-Based Methods Can See through Walls

    [https://arxiv.org/abs/2404.01964](https://arxiv.org/abs/2404.01964)

    CAM-based方法解释图像分类模型的决策时，可能会错误地将模型无法看到的部分归因为重要，这可能导致对模型行为的误解释。

    

    CAM-based方法是一种广泛使用的事后解释性方法，生成显著性地图来解释图像分类模型的决策。显著性地图突出显示与预测相关的图像重要区域。本文展示了大多数这些方法可能错误地将图像的某些部分归因为模型无法看到的重要得分。我们表明这种现象在理论和实验中均存在。理论上，我们分析了GradCAM在一个简单的掩膜CNN模型初始化时的行为。实验上，我们训练了一个类似VGG的模型，限制其不使用图像的下半部分，仍然观察到未见部分的正分数。这种行为在两个新数据集上进行了定量评估。我们认为这是有问题的，可能会导致对模型行为的错误解释。

    arXiv:2404.01964v1 Announce Type: cross  Abstract: CAM-based methods are widely-used post-hoc interpretability method that produce a saliency map to explain the decision of an image classification model. The saliency map highlights the important areas of the image relevant to the prediction. In this paper, we show that most of these methods can incorrectly attribute an important score to parts of the image that the model cannot see. We show that this phenomenon occurs both theoretically and experimentally. On the theory side, we analyze the behavior of GradCAM on a simple masked CNN model at initialization. Experimentally, we train a VGG-like model constrained to not use the lower part of the image and nevertheless observe positive scores in the unseen part of the image. This behavior is evaluated quantitatively on two new datasets. We believe that this is problematic, potentially leading to mis-interpretation of the model's behavior.
    
[^29]: Bi-LORA：一种用于合成图像检测的视觉-语言方法

    Bi-LORA: A Vision-Language Approach for Synthetic Image Detection

    [https://arxiv.org/abs/2404.01959](https://arxiv.org/abs/2404.01959)

    基于视觉-语言方法，引入了Bi-LORA方法，通过结合VLMs和LORA调整技术，将合成图像检测转化为图像字幕任务，以提高对未见过的模型生成图像的精度。

    

    深度图像合成技术的进步，如生成对抗网络（GAN）和扩散模型（DM），已经开启了一个生成高度逼真图像的时代。尽管这种技术进步引起了极大的兴趣，但也引发了对于区分真实图像和合成图像之间潜在难度的担忧。本文借鉴了视觉和语言之间强大的收敛能力，结合了视觉-语言模型（VLMs）的零次学习特性。我们引入了一种名为Bi-LORA的创新方法，利用VLMs，结合低秩适应（LORA）调整技术，增强了对未见过的模型生成图像的合成图像检测的精度。我们方法的关键概念转变在于将二分类重新构建为图像字幕任务，利用了尖端VLM的独特能力。

    arXiv:2404.01959v1 Announce Type: cross  Abstract: Advancements in deep image synthesis techniques, such as generative adversarial networks (GANs) and diffusion models (DMs), have ushered in an era of generating highly realistic images. While this technological progress has captured significant interest, it has also raised concerns about the potential difficulty in distinguishing real images from their synthetic counterparts. This paper takes inspiration from the potent convergence capabilities between vision and language, coupled with the zero-shot nature of vision-language models (VLMs). We introduce an innovative method called Bi-LORA that leverages VLMs, combined with low-rank adaptation (LORA) tuning techniques, to enhance the precision of synthetic image detection for unseen model-generated images. The pivotal conceptual shift in our methodology revolves around reframing binary classification as an image captioning task, leveraging the distinctive capabilities of cutting-edge VLM
    
[^30]: 利用多模态数据设计利用少量标签进行单模态人类活动识别的MESEN

    MESEN: Exploit Multimodal Data to Design Unimodal Human Activity Recognition with Few Labels

    [https://arxiv.org/abs/2404.01958](https://arxiv.org/abs/2404.01958)

    提出了MESEN，一个利用未标记多模态数据设计单模态人类活动识别的框架，通过多任务机制和特征学习实现了有效的单模态特征提取。

    

    人类活动识别（HAR）将成为各种新兴应用的重要功能。然而，HAR通常面临与模态限制和标签稀缺相关的挑战，导致当前解决方案与真实世界需求之间存在应用差距。在本研究中，我们提出了MESEN，一个多模态增强的单模态传感框架，用于利用HAR模型设计阶段可用的未标记多模态数据，以在部署阶段加强单模态HAR。通过对监督多模态融合对单模态特征提取的影响的研究，MESEN在多模态辅助预训练阶段设计了一个多任务机制。通过整合跨模态特征对比学习和多模态伪分类对齐的建议机制，MESEN利用未标记的多模态数据提取出每种模态的有效单模态特征。随后，MESEN可以适应

    arXiv:2404.01958v1 Announce Type: new  Abstract: Human activity recognition (HAR) will be an essential function of various emerging applications. However, HAR typically encounters challenges related to modality limitations and label scarcity, leading to an application gap between current solutions and real-world requirements. In this work, we propose MESEN, a multimodal-empowered unimodal sensing framework, to utilize unlabeled multimodal data available during the HAR model design phase for unimodal HAR enhancement during the deployment phase. From a study on the impact of supervised multimodal fusion on unimodal feature extraction, MESEN is designed to feature a multi-task mechanism during the multimodal-aided pre-training stage. With the proposed mechanism integrating cross-modal feature contrastive learning and multimodal pseudo-classification aligning, MESEN exploits unlabeled multimodal data to extract effective unimodal features for each modality. Subsequently, MESEN can adapt to
    
[^31]: 用于鲁棒性中风分割的合成数据

    Synthetic Data for Robust Stroke Segmentation

    [https://arxiv.org/abs/2404.01946](https://arxiv.org/abs/2404.01946)

    提出一种用于中风分割的合成框架，使用病变特定增强策略扩展了SynthSeg方法，通过训练深度学习模型实现对健康组织和病理病变的分割，无需特定序列的训练数据，在领域内和领域外数据集的评估中表现出鲁棒性能。

    

    arXiv:2404.01946v1 公告类型：交叉 摘要：目前基于深度学习的神经影像语义分割需要高分辨率扫描和大量注释数据集，这给临床适用性带来了显著障碍。我们提出了一种新颖的合成框架，用于病变分割任务，扩展了已建立的SynthSeg方法的能力，以适应具有病变特定增强策略的大型异质病变。我们的方法使用从健康和中风数据集派生的标签映射训练深度学习模型，在这里演示了UNet架构，促进了健康组织和病理病变的分割，而无需特定于序列的训练数据。针对领域内和领域外（OOD）数据集进行评估，我们的框架表现出鲁棒性能，与训练领域内的当前方法相媲美，并在OOD数据上显着优于它们。这一贡献有望推动医学...

    arXiv:2404.01946v1 Announce Type: cross  Abstract: Deep learning-based semantic segmentation in neuroimaging currently requires high-resolution scans and extensive annotated datasets, posing significant barriers to clinical applicability. We present a novel synthetic framework for the task of lesion segmentation, extending the capabilities of the established SynthSeg approach to accommodate large heterogeneous pathologies with lesion-specific augmentation strategies. Our method trains deep learning models, demonstrated here with the UNet architecture, using label maps derived from healthy and stroke datasets, facilitating the segmentation of both healthy tissue and pathological lesions without sequence-specific training data. Evaluated against in-domain and out-of-domain (OOD) datasets, our framework demonstrates robust performance, rivaling current methods within the training domain and significantly outperforming them on OOD data. This contribution holds promise for advancing medical
    
[^32]: 大数据聚类中的时间与准确性权衡

    Settling Time vs. Accuracy Tradeoffs for Clustering Big Data

    [https://arxiv.org/abs/2404.01936](https://arxiv.org/abs/2404.01936)

    在大数据聚类中，研究了时间和准确性的权衡，提出了一种可以在有效线性时间内获得核心集的算法。

    

    我们研究了在大型数据集上进行k-means和k-median聚类的理论和实际运行时限制。由于几乎所有的聚类方法都比读取数据集所需的时间更慢，最快的方法是快速压缩数据，并在压缩表示上执行聚类。不幸的是，并没有通用的最佳选择来压缩点数 - 尽管随机抽样的运行时间为次线性时间且核心集提供了理论保证，但前者并不强制准确性，而后者随着数据点数和聚类数的增长而太慢。实际上，人们推测任何基于灵敏性的核心集构建都需要超线性时间才能对数据集大小进行处理。我们首先证明存在一种算法，通过灵敏性抽样在有效线性时间内获得核心集 - 仅在读取数据所需时间的对数因子内。

    arXiv:2404.01936v1 Announce Type: new  Abstract: We study the theoretical and practical runtime limits of k-means and k-median clustering on large datasets. Since effectively all clustering methods are slower than the time it takes to read the dataset, the fastest approach is to quickly compress the data and perform the clustering on the compressed representation. Unfortunately, there is no universal best choice for compressing the number of points - while random sampling runs in sublinear time and coresets provide theoretical guarantees, the former does not enforce accuracy while the latter is too slow as the numbers of points and clusters grow. Indeed, it has been conjectured that any sensitivity-based coreset construction requires super-linear time in the dataset size. We examine this relationship by first showing that there does exist an algorithm that obtains coresets via sensitivity sampling in effectively linear time - within log-factors of the time it takes to read the data. An
    
[^33]: 跨越语言、视觉和行动：多模态VAE在机器人操作任务中的应用

    Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks

    [https://arxiv.org/abs/2404.01932](https://arxiv.org/abs/2404.01932)

    本研究探索了多模态VAE如何在无监督机器人操作任务中实现，提出了一个新的模型训练方法，可以使模拟器中的模型性能提高55%。

    

    在这项工作中，我们关注机器人操作领域中无监督的视觉-语言-动作映射。我们探讨了多模态变分自动编码器（VAE）在模拟环境中如何被应用于无监督机器人操作任务中，并提出了一个改进模型性能的模型不变式训练方法，可以使模拟器中的模型性能提高高达55%。

    arXiv:2404.01932v1 Announce Type: cross  Abstract: In this work, we focus on unsupervised vision-language-action mapping in the area of robotic manipulation. Recently, multiple approaches employing pre-trained large language and vision models have been proposed for this task. However, they are computationally demanding and require careful fine-tuning of the produced outputs. A more lightweight alternative would be the implementation of multimodal Variational Autoencoders (VAEs) which can extract the latent features of the data and integrate them into a joint representation, as has been demonstrated mostly on image-image or image-text data for the state-of-the-art models. Here we explore whether and how can multimodal VAEs be employed in unsupervised robotic manipulation tasks in a simulated environment. Based on the obtained results, we propose a model-invariant training alternative that improves the models' performance in a simulator by up to 55%. Moreover, we systematically evaluate 
    
[^34]: 自适应组合最大化：超越近似贪心策略

    Adaptive Combinatorial Maximization: Beyond Approximate Greedy Policies

    [https://arxiv.org/abs/2404.01930](https://arxiv.org/abs/2404.01930)

    提供了新的全面近似保证，支持最大增益比率和近似次模函数，包括基数约束下的最大化和最小成本覆盖保证，并且引入了自适应选择策略的新参数“最大增益比率”。

    

    我们研究自适应组合最大化，在机器学习中是一个核心挑战，应用于主动学习以及许多其他领域。我们研究贝叶斯设置，并考虑在基数约束和最小成本覆盖下的最大化目标。我们提供了新的全面近似保证，包含先前的结果，并对其进行了明显加强。我们的近似保证同时支持最大增益比率和近似次模函数，并包括基数约束下的最大化和最小成本覆盖保证。此外，我们为修改后的先验提供了一个近似保证，这对于获得不取决于先验中最小概率的主动学习保证至关重要。此外，我们发现了自适应选择策略的一个新参数，我们称之为“最大增益比率”。

    arXiv:2404.01930v1 Announce Type: new  Abstract: We study adaptive combinatorial maximization, which is a core challenge in machine learning, with applications in active learning as well as many other domains. We study the Bayesian setting, and consider the objectives of maximization under a cardinality constraint and minimum cost coverage. We provide new comprehensive approximation guarantees that subsume previous results, as well as considerably strengthen them. Our approximation guarantees simultaneously support the maximal gain ratio as well as near-submodular utility functions, and include both maximization under a cardinality constraint and a minimum cost coverage guarantee. In addition, we provided an approximation guarantee for a modified prior, which is crucial for obtaining active learning guarantees that do not depend on the smallest probability in the prior. Moreover, we discover a new parameter of adaptive selection policies, which we term the "maximal gain ratio". We show
    
[^35]: 人性化机器生成的内容：通过对抗攻击规避AI文本检测

    Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack

    [https://arxiv.org/abs/2404.01907](https://arxiv.org/abs/2404.01907)

    本文提出了一个旨在对机器生成的文本进行微小扰动以规避检测的广泛对抗攻击框架，通过白盒和黑盒两种攻击设置以及对抗学习在动态场景中的应用，评估了当前检测模型对此类攻击的鲁棒性潜力增强

    

    随着大型语言模型（LLMs）的发展，检测文本是否由机器生成在面对诸如误传信息、保护知识产权和预防学术抄袭等恶意用例时变得日益具有挑战性。虽然经过良好训练的文本检测器在未知测试数据上展现了有希望的性能，但最近的研究表明，这些检测器在处理对抗攻击（如释义）时存在漏洞。本文提出了一个更广泛类别的对抗攻击框架，旨在对机器生成的内容进行微小扰动以规避检测。我们考虑了两种攻击设置：白盒和黑盒，并在动态场景中采用对抗学习来评估当前检测模型对此类攻击的鲁棒性潜力增强。实证结果表明，目前的检测模型

    arXiv:2404.01907v1 Announce Type: new  Abstract: With the development of large language models (LLMs), detecting whether text is generated by a machine becomes increasingly challenging in the face of malicious use cases like the spread of false information, protection of intellectual property, and prevention of academic plagiarism. While well-trained text detectors have demonstrated promising performance on unseen test data, recent research suggests that these detectors have vulnerabilities when dealing with adversarial attacks such as paraphrasing. In this paper, we propose a framework for a broader class of adversarial attacks, designed to perform minor perturbations in machine-generated content to evade detection. We consider two attack settings: white-box and black-box, and employ adversarial learning in dynamic scenarios to assess the potential enhancement of the current detection model's robustness against such attacks. The empirical results reveal that the current detection mode
    
[^36]: 在CodeLLMs中实现类型预测的鲁棒激活导向技术

    Activation Steering for Robust Type Prediction in CodeLLMs

    [https://arxiv.org/abs/2404.01903](https://arxiv.org/abs/2404.01903)

    我们提出了一种激活导向技术，通过编辑模型内部激活来改善CodeLLMs在代码类型预测中对于语法干扰的鲁棒性，并成功应用于Python和TypeScript的类型预测，将类型误差率纠正高达90%。

    

    预训练在代码上的现代LLMs能够成功地完成各种编程任务。然而，它们的性能对语法特征非常敏感，例如变量和类型的名称、代码结构以及类型提示的存在。我们提出了一种推理时技术，使CodeLLMs更能抵御语法干扰因素，这些因素与语义无关。我们的方法依赖于激活导向，涉及编辑内部模型激活以将模型引导到正确的预测。我们通过从突变测试中汲取灵感构建激活向量的新方法，该方法构建最小的破坏语义的代码编辑。相比之下，我们从保留语义的代码编辑中构建激活向量。我们将我们的方法应用于逐渐类型化语言Python和TypeScript的类型预测任务。这种方法可以纠正高达90%的类型错误预测。

    arXiv:2404.01903v1 Announce Type: new  Abstract: Contemporary LLMs pretrained on code are capable of succeeding at a wide variety of programming tasks. However, their performance is very sensitive to syntactic features, such as the names of variables and types, the structure of code, and presence of type hints. We contribute an inference-time technique to make CodeLLMs more robust to syntactic distractors that are semantically irrelevant. Our methodology relies on activation steering, which involves editing internal model activations to steer the model towards the correct prediction. We contribute a novel way to construct steering vectors by taking inspiration from mutation testing, which constructs minimal semantics-breaking code edits. In contrast, we construct steering vectors from semantics-preserving code edits. We apply our approach to the task of type prediction for the gradually typed languages Python and TypeScript. This approach corrects up to 90% of type mispredictions. Fina
    
[^37]: 连续脉冲图神经网络

    Continuous Spiking Graph Neural Networks

    [https://arxiv.org/abs/2404.01897](https://arxiv.org/abs/2404.01897)

    COS-GNN将脉冲神经网络（SNNs）与连续图神经网络（CGNNs）结合在一起，以在每个时间步骤对图节点进行表示，并将其与时间一起集成到ODE过程中，以增强信息保存和解决在离散图神经网络中的问题。

    

    连续图神经网络（CGNNs）因引入连续动力学而引起了极大关注，能够推广现有的离散图神经网络（GNNs）。它们通常受扩散类方法启发，引入了一种新颖的传播方案，并使用常微分方程（ODE）进行分析。然而，CGNNs的实现需要大量计算能力，这使得它们难以部署在电池供电设备上。受最近脉冲神经网络（SNNs）的启发，SNNs模拟生物推理过程并提供一种节能的神经架构，我们将SNNs与CGNNs结合到一个统一框架中，命名为连续脉冲图神经网络（COS-GNN）。我们在每个时间步骤使用SNNs进行图节点表示，这些表示进一步与时间一起集成到ODE过程中，以增强信息保存和缓解...

    arXiv:2404.01897v1 Announce Type: cross  Abstract: Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics. They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE). However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices. Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN). We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time. To enhance information preservation and mitigate in
    
[^38]: 具有切换成本的对抗性组合赌博机问题

    Adversarial Combinatorial Bandits with Switching Costs

    [https://arxiv.org/abs/2404.01883](https://arxiv.org/abs/2404.01883)

    研究了具有切换成本的对抗性组合赌博机问题，推导了极小后悔的下限并设计了逼近算法。

    

    我们研究了具有切换成本$\lambda$的对抗性组合赌博机问题，考虑了赌博机反馈和半赌博机反馈设置。在忽视对手的情况下，我们推导了$K$个基本臂和时间跨度$T$的极小后悔的下限，并设计了算法来逼近这些下限。为了证明这些下限，我们为两种反馈设置设计了随机损失序列，借鉴了Dekel等人（2014年）之前工作中的一个思想。赌博机反馈的下限为$ \tilde{\Omega}\big( (\lambda K)^{\frac{1}{3}} (TI)^{\frac{2}{3}}\big)$，而半赌博机反馈的下限为$ \tilde{\Omega}\big( (\lambda K I)^{\frac{1}{3}} T^{\frac{2}{3}}\big)$，其中$I$是在每一轮中播放的组合臂中的基本臂数量。

    arXiv:2404.01883v1 Announce Type: cross  Abstract: We study the problem of adversarial combinatorial bandit with a switching cost $\lambda$ for a switch of each selected arm in each round, considering both the bandit feedback and semi-bandit feedback settings. In the oblivious adversarial case with $K$ base arms and time horizon $T$, we derive lower bounds for the minimax regret and design algorithms to approach them. To prove these lower bounds, we design stochastic loss sequences for both feedback settings, building on an idea from previous work in Dekel et al. (2014). The lower bound for bandit feedback is $ \tilde{\Omega}\big( (\lambda K)^{\frac{1}{3}} (TI)^{\frac{2}{3}}\big)$ while that for semi-bandit feedback is $ \tilde{\Omega}\big( (\lambda K I)^{\frac{1}{3}} T^{\frac{2}{3}}\big)$ where $I$ is the number of base arms in the combinatorial arm played in each round. To approach these lower bounds, we design algorithms that operate in batches by dividing the time horizon into batc
    
[^39]: 机器学习中的程序公平性

    Procedural Fairness in Machine Learning

    [https://arxiv.org/abs/2404.01877](https://arxiv.org/abs/2404.01877)

    本文定义了机器学习模型的程序公平性，提出了评估群体程序公平性的新度量标准$GPF_{FAE}$，并使用特征归因解释来捕捉决策过程，实验证实了其有效性，同时揭示了程序和分配公平性之间的关系，并提出了一种方法来识别导致程序性不公平的特征。

    

    机器学习中的公平性一直受到广泛关注，然而现有研究主要集中在模型的分配公平性上。另一个公平性维度，即程序公平性，却被忽视了。本文首先定义了机器学习模型的程序公平性，然后给出了个体和群体程序公平性的正式定义。我们提出了一个新的度量标准来评估机器学习模型的群体程序公平性，称为$GPF_{FAE}$，它利用了一个广泛使用的可解释人工智能技术，即特征归因解释（FAE），来捕捉机器学习模型的决策过程。我们在一个合成数据集和八个真实数据集上验证了$GPF_{FAE}$的有效性。我们的实验揭示了机器学习模型的程序和分配公平性之间的关系。基于我们的分析，我们提出了一种识别导致程序性不公平问题的特征的方法。

    arXiv:2404.01877v1 Announce Type: new  Abstract: Fairness in machine learning (ML) has received much attention. However, existing studies have mainly focused on the distributive fairness of ML models. The other dimension of fairness, i.e., procedural fairness, has been neglected. In this paper, we first define the procedural fairness of ML models, and then give formal definitions of individual and group procedural fairness. We propose a novel metric to evaluate the group procedural fairness of ML models, called $GPF_{FAE}$, which utilizes a widely used explainable artificial intelligence technique, namely feature attribution explanation (FAE), to capture the decision process of the ML models. We validate the effectiveness of $GPF_{FAE}$ on a synthetic dataset and eight real-world datasets. Our experiments reveal the relationship between procedural and distributive fairness of the ML model. Based on our analysis, we propose a method for identifying the features that lead to the procedur
    
[^40]: 卫星联合边缘学习：架构设计与收敛分析

    Satellite Federated Edge Learning: Architecture Design and Convergence Analysis

    [https://arxiv.org/abs/2404.01875](https://arxiv.org/abs/2404.01875)

    本文引入了一种针对低地球轨道卫星网络的新型FEEL算法FEDMEGA，通过整合卫星间链接（ISL）进行轨道内模型聚合。

    

    低地球轨道（LEO）卫星网络的大量增长导致产生大量遥感数据，传统上这些数据被传输到地面服务器进行集中处理，引发隐私和带宽问题。联合边缘学习（FEEL）作为一种分布式机器学习方法，有潜力通过仅分享模型参数而非原始数据来解决这些挑战。本文介绍了一种针对LEO超级星座网络量身定制的新型FEEL算法，名为FEDMEGA，通过整合卫星间链接（ISL）进行轨道内模型聚合。

    arXiv:2404.01875v1 Announce Type: cross  Abstract: The proliferation of low-earth-orbit (LEO) satellite networks leads to the generation of vast volumes of remote sensing data which is traditionally transferred to the ground server for centralized processing, raising privacy and bandwidth concerns. Federated edge learning (FEEL), as a distributed machine learning approach, has the potential to address these challenges by sharing only model parameters instead of raw data. Although promising, the dynamics of LEO networks, characterized by the high mobility of satellites and short ground-to-satellite link (GSL) duration, pose unique challenges for FEEL. Notably, frequent model transmission between the satellites and ground incurs prolonged waiting time and large transmission latency. This paper introduces a novel FEEL algorithm, named FEDMEGA, tailored to LEO mega-constellation networks. By integrating inter-satellite links (ISL) for intra-orbit model aggregation, the proposed algorithm s
    
[^41]: 快速自适应问卷用于投票建议应用

    Fast and Adaptive Questionnaires for Voting Advice Applications

    [https://arxiv.org/abs/2404.01872](https://arxiv.org/abs/2404.01872)

    该研究提出了一种自适应问卷方法，根据用户先前的回答选择后续的问题，旨在提高投票建议应用的推荐准确性同时减少给选民提问的问题数量。

    

    投票建议应用的有效性常常受其问卷长度的影响。为了解决用户疲劳和未完成回答的问题，一些应用（例如瑞士Smartvote）提供了其问卷的精简版本。然而，这些精简版本无法保证推荐的政党或候选人的准确性，我们发现其保持在40%以下。为了解决这些限制，本文引入了一种自适应问卷方法，根据用户先前的回答选择后续的问题，旨在提高推荐准确性同时减少提问给选民的问题数量。我们的方法使用编码器和解码器模块在任何完成阶段预测缺失值，利用两维潜在空间反映政治学传统方法，用于可视化政治取向。此外，提出了一个选择器模块用于确定最

    arXiv:2404.01872v1 Announce Type: new  Abstract: The effectiveness of Voting Advice Applications (VAA) is often compromised by the length of their questionnaires. To address user fatigue and incomplete responses, some applications (such as the Swiss Smartvote) offer a condensed version of their questionnaire. However, these condensed versions can not ensure the accuracy of recommended parties or candidates, which we show to remain below 40%. To tackle these limitations, this work introduces an adaptive questionnaire approach that selects subsequent questions based on users' previous answers, aiming to enhance recommendation accuracy while reducing the number of questions posed to the voters. Our method uses an encoder and decoder module to predict missing values at any completion stage, leveraging a two-dimensional latent space reflective of political science's traditional methods for visualizing political orientations. Additionally, a selector module is proposed to determine the most 
    
[^42]: 机器人操作中基于贝叶斯模型的强化学习中的主动探索

    Active Exploration in Bayesian Model-based Reinforcement Learning for Robot Manipulation

    [https://arxiv.org/abs/2404.01867](https://arxiv.org/abs/2404.01867)

    该论文提出了在机器人操作中基于贝叶斯模型的强化学习中通过主动探索改善模型质量和保持数据效率的方法。

    

    有效解决机器人操作等复杂环境中的多个任务仍然是机器人技术中的一个持续挑战，也是数据驱动解决方案（如强化学习（RL））的一个机会。模型驱动的RL通过构建机器人的动态模型，实现数据重用和在具有相同机器人和类似环境的任务之间进行迁移学习。此外，机器人学中的数据收集成本很高，我们必须依赖数据高效的方法，如基于模型的RL，在基于学习模型的廉价仿真中进行大部分策略学习。因此，模型的质量对于后续任务的性能至关重要。在这项工作中，我们致力于通过在初始探索阶段执行动态模型的主动学习，基于最大化信息收集，以提高模型的质量并保持数据效率。

    arXiv:2404.01867v1 Announce Type: cross  Abstract: Efficiently tackling multiple tasks within complex environment, such as those found in robot manipulation, remains an ongoing challenge in robotics and an opportunity for data-driven solutions, such as reinforcement learning (RL). Model-based RL, by building a dynamic model of the robot, enables data reuse and transfer learning between tasks with the same robot and similar environment. Furthermore, data gathering in robotics is expensive and we must rely on data efficient approaches such as model-based RL, where policy learning is mostly conducted on cheaper simulations based on the learned model. Therefore, the quality of the model is fundamental for the performance of the posterior tasks. In this work, we focus on improving the quality of the model and maintaining the data efficiency by performing active learning of the dynamic model during a preliminary exploration phase based on maximize information gathering. We employ Bayesian ne
    
[^43]: 面向细化文本到图像模型的置信度感知奖励优化

    Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models

    [https://arxiv.org/abs/2404.01863](https://arxiv.org/abs/2404.01863)

    使用奖励函数训练的细化文本到图像模型可能会因为奖励过度优化而损害性能，为了解决这一问题，提出了一种基于奖励模型置信度的对齐性增强方法。

    

    在人类反馈数据训练的奖励函数上对细化文本到图像模型进行微调已被证明可以有效地使模型行为与人类意图一致。然而，过度优化使用这些奖励模型，作为简单的替代目标，可能会损害细化模型的性能，这一现象被称为奖励过度优化。为深入研究这个问题，我们引入了Text-Image Alignment Assessment (TIA2)基准测试，它包括一系列文本提示、图像和人类注释。我们在该基准测试上评估了几种最先进的奖励模型，发现它们经常与人类评估不一致。我们从实证角度证明，当使用一个与人类评估不一致的奖励模型作为微调目标时，奖励过度优化尤为明显。为应对这个问题，我们提出了TextNorm，一种简单的方法，它基于估计的奖励模型置信度来增强对齐性。

    arXiv:2404.01863v1 Announce Type: cross  Abstract: Fine-tuning text-to-image models with reward functions trained on human feedback data has proven effective for aligning model behavior with human intent. However, excessive optimization with such reward models, which serve as mere proxy objectives, can compromise the performance of fine-tuned models, a phenomenon known as reward overoptimization. To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations. Our evaluation of several state-of-the-art reward models on this benchmark reveals their frequent misalignment with human assessment. We empirically demonstrate that overoptimization occurs notably when a poorly aligned reward model is used as the fine-tuning objective. To address this, we propose TextNorm, a simple method that enhances alignment based on a measure of reward model confidence estimated across 
    
[^44]: 在课程评价中检测性别偏见

    Detecting Gender Bias in Course Evaluations

    [https://arxiv.org/abs/2404.01857](https://arxiv.org/abs/2404.01857)

    通过机器学习和自然语言处理，研究发现课程评价中的性别偏见，比较英语和瑞典课程数据，揭示了学生对课程的评价主观性因考官性别而存在差异。

    

    这是一篇研究利用机器学习和自然语言处理从硕士论文研究中发现课程评价中性别偏见的截图。我们使用不同方法来检测和探索数据，发现学生对课程的评价会因考官的性别而有所不同。评估和比较了来自英语和瑞典课程的数据，以捕捉可能存在的性别偏见中更多的细微差别。我们在这里展示了到目前为止的工作结果，但这是一个正在进行的项目，还有更多的工作要做。

    arXiv:2404.01857v1 Announce Type: cross  Abstract: An outtake from the findnings of a master thesis studying gender bias in course evaluations through the lense of machine learning and nlp. We use different methods to examine and explore the data and find differences in what students write about courses depending on gender of the examiner. Data from English and Swedish courses are evaluated and compared, in order to capture more nuance in the gender bias that might be found. Here we present the results from the work so far, but this is an ongoing project and there is more work to do.
    
[^45]: 噪声标签学习的成对相似度分布聚类

    Pairwise Similarity Distribution Clustering for Noisy Label Learning

    [https://arxiv.org/abs/2404.01853](https://arxiv.org/abs/2404.01853)

    提出了成对相似度分布聚类（PSDC）算法，用于在噪声标签学习中选取干净样本集和嘈杂样本集，辅助进行半监督学习，从而进一步训练深度神经网络。

    

    噪声标签学习旨在使用大量带有错误标签的样本训练深度神经网络，其主要挑战在于如何处理由错误标签引起的不准确监督。本文提出了一种简单而有效的样本选择算法，称为成对相似度分布聚类（PSDC），将训练样本分为一个干净集和另一个嘈杂集，可以为任何现成的半监督学习方案提供动力，以进一步为不同下游任务训练网络。具体而言，我们采用样本对之间的成对相似度表示样本结构，并使用高斯混合模型（GMM）来建模属于同一嘈杂集的样本对之间的相似度分布，从而每个sa

    arXiv:2404.01853v1 Announce Type: new  Abstract: Noisy label learning aims to train deep neural networks using a large amount of samples with noisy labels, whose main challenge comes from how to deal with the inaccurate supervision caused by wrong labels. Existing works either take the label correction or sample selection paradigm to involve more samples with accurate labels into the training process. In this paper, we propose a simple yet effective sample selection algorithm, termed as Pairwise Similarity Distribution Clustering~(PSDC), to divide the training samples into one clean set and another noisy set, which can power any of the off-the-shelf semi-supervised learning regimes to further train networks for different downstream tasks. Specifically, we take the pairwise similarity between sample pairs to represent the sample structure, and the Gaussian Mixture Model~(GMM) to model the similarity distribution between sample pairs belonging to the same noisy cluster, therefore each sa
    
[^46]: 使用2:4稀疏性加速Transformer预训练

    Accelerating Transformer Pre-Training with 2:4 Sparsity

    [https://arxiv.org/abs/2404.01847](https://arxiv.org/abs/2404.01847)

    通过稀疏矩阵乘法，结合两种新技术和模型微调，研究了加速Transformer预训练中前馈网络的可行性，以及通过计算2:4掩码和减少GPU L2缓存来实现训练加速。

    

    训练大型Transformer很慢，但最近GPU架构的创新使我们占据优势。NVIDIA的Ampere GPU可以比其密集等价物快两倍的速度执行细粒度的2:4稀疏矩阵乘法。在此性质的基础上，我们全面调查了加速Transformer预训练中前馈网络（FFNs）的可行性。首先，我们定义了一个“翻转率”来监视2:4训练过程的稳定性。利用这一指标，我们提出了两种技术来保持准确性：通过在梯度上应用掩码衰减项修改稀疏精化的直通估计器，并通过在预训练结束时附近应用简单而有效的密集微调过程来提高模型质量。此外，我们设计了两种有效的技术来实际加速训练：通过卷积计算可转置的2:4掩码，以及通过减少GPU L2缓存来加速门控激活函数。

    arXiv:2404.01847v1 Announce Type: new  Abstract: Training large Transformers is slow, but recent innovations on GPU architecture gives us an advantage. NVIDIA Ampere GPUs can execute a fine-grained 2:4 sparse matrix multiplication twice as fast as its dense equivalent. In the light of this property, we comprehensively investigate the feasibility of accelerating feed-forward networks (FFNs) of Transformers in pre-training. First, we define a "flip rate" to monitor the stability of a 2:4 training process. Utilizing this metric, we suggest two techniques to preserve accuracy: to modify the sparse-refined straight-through estimator by applying the mask decay term on gradients, and to enhance the model's quality by a simple yet effective dense fine-tuning procedure near the end of pre-training. Besides, we devise two effective techniques to practically accelerate training: to calculate transposable 2:4 mask by convolution, and to accelerate gated activation functions by reducing GPU L2 cach
    
[^47]: 何时使用Subagging？

    When does Subagging Work?

    [https://arxiv.org/abs/2404.01832](https://arxiv.org/abs/2404.01832)

    研究展示了在机器学习中一种流行的非参数方法——回归树上，子抽样聚合（subagging）的有效性，并发现对于任何给定的分裂数，subagging都可以优于单棵树，并且在较多分裂的情况下改进更大。

    

    我们研究了在机器学习中一种流行的非参数方法——回归树上，子抽样聚合（subagging）的有效性。首先，我们给出了树的逐点一致性的充分条件。我们明确了（i）偏差取决于单元的直径，因此，具有少数分裂的树倾向于存在偏差，以及（ii）方差取决于单元中的观测数量，因此，具有许多分裂的树倾向于具有较大的方差。虽然这些关于偏差和方差的陈述在协变量空间中是全局适用的，我们展示了，在某些约束条件下，它们在局部也是成立的。第二，我们比较了子抽样聚合和具有不同分裂数的树的性能。我们发现，对于任何给定的分裂数，子抽样聚合都优于单棵树，并且这种改进在较多分裂的情况下比较少分裂的情况下更大。然而，一个以最佳大小生长的单棵树可以优于子抽样聚合。

    arXiv:2404.01832v1 Announce Type: cross  Abstract: We study the effectiveness of subagging, or subsample aggregating, on regression trees, a popular non-parametric method in machine learning. First, we give sufficient conditions for pointwise consistency of trees. We formalize that (i) the bias depends on the diameter of cells, hence trees with few splits tend to be biased, and (ii) the variance depends on the number of observations in cells, hence trees with many splits tend to have large variance. While these statements for bias and variance are known to hold globally in the covariate space, we show that, under some constraints, they are also true locally. Second, we compare the performance of subagging to that of trees across different numbers of splits. We find that (1) for any given number of splits, subagging improves upon a single tree, and (2) this improvement is larger for many splits than it is for few splits. However, (3) a single tree grown at optimal size can outperform su
    
[^48]: 估计记录策略的双重稳健离线评估

    Doubly-Robust Off-Policy Evaluation with Estimated Logging Policy

    [https://arxiv.org/abs/2404.01830](https://arxiv.org/abs/2404.01830)

    提出了一种适用于未知记录策略和价值函数的双重稳健离线评估估计器DRUnknown，实现了最小渐近方差和半参数下界下最佳性能。

    

    我们介绍了一种用于马尔可夫决策过程的新颖的双重稳健（DR）离线评估（OPE）估计器DRUnknown，旨在应对记录策略和价值函数均未知的情况。该估计器首先估计记录策略，然后通过最小化估计器的渐近方差来估计价值函数模型，同时考虑记录策略的估计效果。当记录策略模型正确指定时，DRUnknown在现有OPE估计器类中达到最小的渐近方差。当价值函数模型也被正确指定时，DRUnknown是最优的，因为它的渐近方差达到了半参数下界。我们在情境臂和强化学习中进行了实验结果，比较了DRUnknown与现有方法的性能。

    arXiv:2404.01830v1 Announce Type: cross  Abstract: We introduce a novel doubly-robust (DR) off-policy evaluation (OPE) estimator for Markov decision processes, DRUnknown, designed for situations where both the logging policy and the value function are unknown. The proposed estimator initially estimates the logging policy and then estimates the value function model by minimizing the asymptotic variance of the estimator while considering the estimating effect of the logging policy. When the logging policy model is correctly specified, DRUnknown achieves the smallest asymptotic variance within the class containing existing OPE estimators. When the value function model is also correctly specified, DRUnknown is optimal as its asymptotic variance reaches the semiparametric lower bound. We present experimental results conducted in contextual bandits and reinforcement learning to compare the performance of DRUnknown with that of existing methods.
    
[^49]: 不忘防御：各向异性与各向同性伪重演的持续对抗性防御

    Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay

    [https://arxiv.org/abs/2404.01828](https://arxiv.org/abs/2404.01828)

    持续对抗性防御概念下提出了各向异性和各向同性伪重演（AIR），通过各向同性重演保持模型一致性，在各向异性重演中学习折衷数据流形。

    

    深度神经网络已经表现出对抗性攻击的易受性。对抗性防御技术通常专注于一次性设置，以保持对抗攻击的稳健性。然而，在实际部署场景中，新的攻击可能会连续出现。因此，防御模型不断适应新的攻击是至关重要的，但适应过程可能会导致对先前进行防御的攻击的灾难性遗忘。在本文中，我们首次讨论了在一系列攻击下的持续对抗性防御的概念，并提出了一种名为各向异性与各向同性重演（AIR）的终身防御基线，具有三个优势：（1）各向同性重演确保模型在新数据的邻域分布中保持一致性，间接地对齐了旧任务和新任务之间的输出偏好。 (2) 各向异性重演使模型能够学习一个带有新混合语义的折衷数据流形

    arXiv:2404.01828v1 Announce Type: cross  Abstract: Deep neural networks have demonstrated susceptibility to adversarial attacks. Adversarial defense techniques often focus on one-shot setting to maintain robustness against attack. However, new attacks can emerge in sequences in real-world deployment scenarios. As a result, it is crucial for a defense model to constantly adapt to new attacks, but the adaptation process can lead to catastrophic forgetting of previously defended against attacks. In this paper, we discuss for the first time the concept of continual adversarial defense under a sequence of attacks, and propose a lifelong defense baseline called Anisotropic \& Isotropic Replay (AIR), which offers three advantages: (1) Isotropic replay ensures model consistency in the neighborhood distribution of new data, indirectly aligning the output preference between old and new tasks. (2) Anisotropic replay enables the model to learn a compromise data manifold with fresh mixed semantics 
    
[^50]: 面向恶意内容检测社区模型泛化的更为现实的评估设置

    A (More) Realistic Evaluation Setup for Generalisation of Community Models on Malicious Content Detection

    [https://arxiv.org/abs/2404.01822](https://arxiv.org/abs/2404.01822)

    提出了面向恶意内容检测社区模型泛化的更为现实的评估设置，通过少样本子图采样方法测试模型泛化能力。

    

    用于恶意内容检测的社区模型考虑社交图中的上下文以及内容本身，在基准数据集上表现出色。然而，虚假信息和仇恨言论仍在社交媒体网络上传播。本文提出了基于我们的少样本子图采样方法的模型泛化的新型评估设置。这个设置通过在更大图的局部探索中少量标记示例，模拟更为现实的应用场景，以测试泛化能力。

    arXiv:2404.01822v1 Announce Type: cross  Abstract: Community models for malicious content detection, which take into account the context from a social graph alongside the content itself, have shown remarkable performance on benchmark datasets. Yet, misinformation and hate speech continue to propagate on social media networks. This mismatch can be partially attributed to the limitations of current evaluation setups that neglect the rapid evolution of online content and the underlying social graph. In this paper, we propose a novel evaluation setup for model generalisation based on our few-shot subgraph sampling approach. This setup tests for generalisation through few labelled examples in local explorations of a larger graph, emulating more realistic application settings. We show this to be a challenging inductive setup, wherein strong performance on the training graph is not indicative of performance on unseen tasks, domains, or graph structures. Lastly, we show that graph meta-learner
    
[^51]: 一种基于神经网络的混合系统识别控制方法

    A neural network-based approach to hybrid systems identification for control

    [https://arxiv.org/abs/2404.01814](https://arxiv.org/abs/2404.01814)

    通过神经网络架构设计出的混合系统模型具有分段线性动力学，可以用于优化控制设计，并且在有限视野最优控制问题中计算出具有强局部最优性保证的最优解。

    

    我们考虑了设计一种基于机器学习的模型的问题，该模型可以从有限数量的(状态-输入)-后继状态数据点中识别未知动态系统，并且该模型适用于优化控制设计。我们提出了一种特定的神经网络(NN)架构，该架构产生具有分段线性动力学的混合系统，该系统对网络参数具有可微性，从而使得可以使用基于导数的训练过程。我们展示了我们的NN权重的精心选择可以产生具有非常有利结构属性的混合系统模型，当作为有限视野最优控制问题(OCP)的一部分使用时，具有很强的局部最优性保证。具体而言，我们展示了可以通过非线性规划计算具有强局部最优性保证的最优解，与通常需要混合整数优化的一般混合系统的经典OCP相比。另外，这些模型还可以被用于故障检测和故障处理。

    arXiv:2404.01814v1 Announce Type: cross  Abstract: We consider the problem of designing a machine learning-based model of an unknown dynamical system from a finite number of (state-input)-successor state data points, such that the model obtained is also suitable for optimal control design. We propose a specific neural network (NN) architecture that yields a hybrid system with piecewise-affine dynamics that is differentiable with respect to the network's parameters, thereby enabling the use of derivative-based training procedures. We show that a careful choice of our NN's weights produces a hybrid system model with structural properties that are highly favourable when used as part of a finite horizon optimal control problem (OCP). Specifically, we show that optimal solutions with strong local optimality guarantees can be computed via nonlinear programming, in contrast to classical OCPs for general hybrid systems which typically require mixed-integer optimization. In addition to being we
    
[^52]: 使用组合的valence和arousal序列分类改进文本情感预测

    Improved Text Emotion Prediction Using Combined Valence and Arousal Ordinal Classification

    [https://arxiv.org/abs/2404.01805](https://arxiv.org/abs/2404.01805)

    使用两种情绪维度进行序数分类，从而改进文本情感预测，并提出了一种新方法来区分不同情绪之间的相似性和差异性

    

    近年来，文本数据中的情感检测引起了越来越多的关注，因为这对于开发富有同理心的人机交互系统至关重要。本文介绍了一种从文本中对情感进行分类的方法，该方法认可并区分了各种情感之间的多样性相似性和差异性。我们首先通过训练基于transformer的模型来为标准情感分类建立了一个基线，实现了最先进的性能。我们认为，并非所有的错分都同等重要，因为情感类别之间存在知觉相似性。因此，我们通过将情感标记问题从传统分类模型转变为序数分类模型来重新定义，其中离散的情感根据其valence水平被排列成顺序。最后，我们提出了一种在二维情感空间中执行序数分类的方法

    arXiv:2404.01805v1 Announce Type: new  Abstract: Emotion detection in textual data has received growing interest in recent years, as it is pivotal for developing empathetic human-computer interaction systems. This paper introduces a method for categorizing emotions from text, which acknowledges and differentiates between the diversified similarities and distinctions of various emotions. Initially, we establish a baseline by training a transformer-based model for standard emotion classification, achieving state-of-the-art performance. We argue that not all misclassifications are of the same importance, as there are perceptual similarities among emotional classes. We thus redefine the emotion labeling problem by shifting it from a traditional classification model to an ordinal classification one, where discrete emotions are arranged in a sequential order according to their valence levels. Finally, we propose a method that performs ordinal classification in the two-dimensional emotion spa
    
[^53]: 通过有向信息瓶颈进行神经形态的无线设备-边缘协同推理

    Neuromorphic Wireless Device-Edge Co-Inference via the Directed Information Bottleneck

    [https://arxiv.org/abs/2404.01804](https://arxiv.org/abs/2404.01804)

    提出了一种新的系统解决方案，名为神经形态的无线设备-边缘协同推理，设备使用神经形态硬件进行数据处理，边缘服务器使用传统技术，以降低通信开销。

    

    下一代无线系统的一个重要用例是设备-边缘协同推理，其中语义任务在设备和边缘服务器之间划分。设备进行数据收集和数据的部分处理，远程服务器根据从设备接收的信息完成给定任务。通常要求在设备处尽可能高效地运行处理和通信，而在边缘有更多的计算资源可用。为了应对这种情况，我们引入了一种新的系统解决方案，称为神经形态的无线设备-边缘协同推理。根据这个系统，设备使用神经形态硬件运行感应、处理和通信单元，而服务器采用传统的无线电和计算技术。

    arXiv:2404.01804v1 Announce Type: new  Abstract: An important use case of next-generation wireless systems is device-edge co-inference, where a semantic task is partitioned between a device and an edge server. The device carries out data collection and partial processing of the data, while the remote server completes the given task based on information received from the device. It is often required that processing and communication be run as efficiently as possible at the device, while more computing resources are available at the edge. To address such scenarios, we introduce a new system solution, termed neuromorphic wireless device-edge co-inference. According to it, the device runs sensing, processing, and communication units using neuromorphic hardware, while the server employs conventional radio and computing technologies. The proposed system is designed using a transmitter-centric information-theoretic criterion that targets a reduction of the communication overhead, while retain
    
[^54]: 废物分类的超分辨率分析

    Super-Resolution Analysis for Landfill Waste Classification

    [https://arxiv.org/abs/2404.01790](https://arxiv.org/abs/2404.01790)

    该研究使用超分辨率分析进行废物分类，提出跨域分类和超分辨率增强来评估不同图像分辨率对废物分类的影响，以应对非法填埋场的蔓延。

    

    非法填埋场是一个关键问题，由于其对环境、经济和公共卫生的影响。本研究利用航空影像进行环境犯罪监测。虽然人工智能和计算机视觉的进展给人以希望，但挑战在于训练具有高分辨率文献数据集的模型，并将其适应于开放式低分辨率图像。鉴于质量差异巨大且注释有限，本研究探讨了模型在这些领域之间的适应性。出于对废物检测算法进行全面评估的必要性，本研究主张跨域分类和超分辨率增强，以分析不同图像分辨率对废物分类的影响，作为打击非法填埋场蔓延的评估。我们观察到通过提高图像质量可以改善性能，但注意到对模型敏感性的影响。

    arXiv:2404.01790v1 Announce Type: cross  Abstract: Illegal landfills are a critical issue due to their environmental, economic, and public health impacts. This study leverages aerial imagery for environmental crime monitoring. While advances in artificial intelligence and computer vision hold promise, the challenge lies in training models with high-resolution literature datasets and adapting them to open-access low-resolution images. Considering the substantial quality differences and limited annotation, this research explores the adaptability of models across these domains. Motivated by the necessity for a comprehensive evaluation of waste detection algorithms, it advocates cross-domain classification and super-resolution enhancement to analyze the impact of different image resolutions on waste classification as an evaluation to combat the proliferation of illegal landfills. We observed performance improvements by enhancing image quality but noted an influence on model sensitivity, ne
    
[^55]: 房间里的一只吵闹的大象：您的离群检测器对标签噪音鲁棒吗？

    A noisy elephant in the room: Is your out-of-distribution detector robust to label noise?

    [https://arxiv.org/abs/2404.01775](https://arxiv.org/abs/2404.01775)

    本研究探讨了当下训练分类器的标签不可靠时，20种最新OOD检测方法在离群检测中的表现，为了解类别标签噪音对OOD检测的影响提供了深入见解。

    

    多数情况下，检测计算机视觉系统中的陌生或意外图像是确保安全部署的关键。在分类领域，检测模型训练领域外图像的任务被称为离群检测（OOD检测）。尽管人们越来越关注发展事后OOD检测方法，但对于在基础分类器未经过干净、精心筛选数据集训练时这些方法表现如何的讨论相对较少。本研究在20种最新的OOD检测方法中更为现实的情况下进行了深入探讨，在此情况下，用于训练基础分类器的标签不可靠（例如，众包或网络抓取标签）。通过在不同数据集、噪音类型和级别、架构和检查点策略上进行广泛实验，我们研究了类别标签噪音对OOD检测的影响，并表明...

    arXiv:2404.01775v1 Announce Type: cross  Abstract: The ability to detect unfamiliar or unexpected images is essential for safe deployment of computer vision systems. In the context of classification, the task of detecting images outside of a model's training domain is known as out-of-distribution (OOD) detection. While there has been a growing research interest in developing post-hoc OOD detection methods, there has been comparably little discussion around how these methods perform when the underlying classifier is not trained on a clean, carefully curated dataset. In this work, we take a closer look at 20 state-of-the-art OOD detection methods in the (more realistic) scenario where the labels used to train the underlying classifier are unreliable (e.g. crowd-sourced or web-scraped labels). Extensive experiments across different datasets, noise types & levels, architectures and checkpointing strategies provide insights into the effect of class label noise on OOD detection, and show tha
    
[^56]: 统一DNN控制系统的定性和定量安全验证

    Unifying Qualitative and Quantitative Safety Verification of DNN-Controlled Systems

    [https://arxiv.org/abs/2404.01769](https://arxiv.org/abs/2404.01769)

    本文提出了一个新的框架，用于统一DNN控制系统的定性和定量安全验证问题，通过构建有效神经障碍证书(NBCs)来实现几乎确定的安全保证

    

    深度强化学习技术的快速发展使得可以通过利用深度神经网络(DNNs)监督安全关键系统，凸显了迅速建立这种DNN控制系统的认证安全保证的迫切需要。大多数现有的验证方法依赖于定性方法，主要采用可达性分析。然而，对于在开放和对抗环境中运行时其行为具有随机趋势的DNN控制系统而言，定性验证证明不足。本文提出了一个新的框架，用于统一DNN控制系统的定性和定量安全验证问题。这是通过将验证任务构建为有效神经障碍证书(NBCs)的综合来实现的。最初，该框架旨在通过定性验证建立几乎确定的安全保证

    arXiv:2404.01769v1 Announce Type: new  Abstract: The rapid advance of deep reinforcement learning techniques enables the oversight of safety-critical systems through the utilization of Deep Neural Networks (DNNs). This underscores the pressing need to promptly establish certified safety guarantees for such DNN-controlled systems. Most of the existing verification approaches rely on qualitative approaches, predominantly employing reachability analysis. However, qualitative verification proves inadequate for DNN-controlled systems as their behaviors exhibit stochastic tendencies when operating in open and adversarial environments. In this paper, we propose a novel framework for unifying both qualitative and quantitative safety verification problems of DNN-controlled systems. This is achieved by formulating the verification tasks as the synthesis of valid neural barrier certificates (NBCs). Initially, the framework seeks to establish almost-sure safety guarantees through qualitative verif
    
[^57]: 使用遥感和机器学习对最不发达国家的曝光和物理脆弱性动态全球映射

    Global Mapping of Exposure and Physical Vulnerability Dynamics in Least Developed Countries using Remote Sensing and Machine Learning

    [https://arxiv.org/abs/2404.01748](https://arxiv.org/abs/2404.01748)

    本文使用遥感和机器学习技术，在最不发达国家进行了全球曝光和物理脆弱性动态映射，旨在推动大规模灾害风险领域的发展。

    

    随着世界标记了《2015-2030年减少灾害风险差距框架》的中期，许多国家仍在努力监测其气候和灾害风险，因为大规模调查曝光和物理脆弱性分布昂贵，因此，在气候变化加剧的影响之下，这些国家在减少风险方面并不在轨道上。我们提出了使用机器学习和时间序列遥感从公开可用的Sentinel-1 SAR GRD和Sentinel-2 Harmonized MSI来映射这一重要信息的持续努力。我们引入了“OpenSendaiBench”的发展，其中包括47个国家，其中大多数是最不发达国家（LDCs），训练了ResNet-50深度学习模型，并通过映射孟加拉国达卡地区的非正式建筑的分布来展示。作为全球审计灾害风险随时间演变的开创性工作，本文旨在推进大规模区域的研究领域。

    arXiv:2404.01748v1 Announce Type: new  Abstract: As the world marked the midterm of the Sendai Framework for Disaster Risk Reduction 2015-2030, many countries are still struggling to monitor their climate and disaster risk because of the expensive large-scale survey of the distribution of exposure and physical vulnerability and, hence, are not on track in reducing risks amidst the intensifying effects of climate change. We present an ongoing effort in mapping this vital information using machine learning and time-series remote sensing from publicly available Sentinel-1 SAR GRD and Sentinel-2 Harmonized MSI. We introduce the development of "OpenSendaiBench" consisting of 47 countries wherein most are least developed (LDCs), trained ResNet-50 deep learning models, and demonstrated the region of Dhaka, Bangladesh by mapping the distribution of its informal constructions. As a pioneering effort in auditing global disaster risk over time, this paper aims to advance the area of large-scale r
    
[^58]: 面向自动驾驶车辆的可扩展高效交互感知规划使用知识蒸馏

    Towards Scalable & Efficient Interaction-Aware Planning in Autonomous Vehicles using Knowledge Distillation

    [https://arxiv.org/abs/2404.01746](https://arxiv.org/abs/2404.01746)

    引入了一种结合深度学习和约束优化的高效方法，利用知识蒸馏训练更小更高效的网络，从而减轻复杂性

    

    真实世界的驾驶涉及车辆在拥挤交通场景中相互复杂的互动。最近的研究关注于增强自动驾驶车辆的交互意识，以利用这些互动来进行决策制定。这些交互感知规划器依赖于基于神经网络的预测模型来捕获车辆间的相互作用，旨在将这些预测与传统控制技术如模型预测控制相整合。然而，深度学习模型与传统控制范式的整合往往导致计算密集型的优化问题，依赖于启发式方法。本研究引入了一种原则性和高效的方法，将深度学习与约束优化相结合，采用知识蒸馏来训练更小、更高效的网络，从而减轻复杂性。我们证明了这些优化后的网络能够维持问题的...

    arXiv:2404.01746v1 Announce Type: cross  Abstract: Real-world driving involves intricate interactions among vehicles navigating through dense traffic scenarios. Recent research focuses on enhancing the interaction awareness of autonomous vehicles to leverage these interactions in decision-making. These interaction-aware planners rely on neural-network-based prediction models to capture inter-vehicle interactions, aiming to integrate these predictions with traditional control techniques such as Model Predictive Control. However, this integration of deep learning-based models with traditional control paradigms often results in computationally demanding optimization problems, relying on heuristic methods. This study introduces a principled and efficient method for combining deep learning with constrained optimization, employing knowledge distillation to train smaller and more efficient networks, thereby mitigating complexity. We demonstrate that these refined networks maintain the problem
    
[^59]: 语言模型对齐的渐进研究

    Asymptotics of Language Model Alignment

    [https://arxiv.org/abs/2404.01730](https://arxiv.org/abs/2404.01730)

    本文提供了对最优KL约束的强化学习解的闭合形式刻画，证明了实现KL散度和奖励之间权衡的对齐方法必须近似最优KL约束的RL解。

    

    让$p$表示一个生成式语言模型。让$r$表示一个奖励模型，返回一个标量，捕捉从$p$中抽取的内容被偏好的程度。语言模型对齐的目标是改变$p$为一个新的分布$\phi$，使得期望奖励更高，同时保持$\phi$接近$p$。一种流行的对齐方法是KL约束的强化学习（RL），选择一个分布$\phi_\Delta$，最大化$E_{\phi_{\Delta}} r(y)$，同时满足相对熵约束$KL(\phi_\Delta || p) \leq \Delta$。另一种简单的对齐方法是最佳-$N$，从$p$中抽取$N$个样本，并选择奖励最高的一个。在本文中，我们提供了最优KL约束的RL解的闭合形式刻画。我们证明了任何实现KL散度和奖励之间可比较的权衡的对齐方法，必须近似最优KL约束的RL解。

    arXiv:2404.01730v1 Announce Type: new  Abstract: Let $p$ denote a generative language model. Let $r$ denote a reward model that returns a scalar that captures the degree at which a draw from $p$ is preferred. The goal of language model alignment is to alter $p$ to a new distribution $\phi$ that results in a higher expected reward while keeping $\phi$ close to $p.$ A popular alignment method is the KL-constrained reinforcement learning (RL), which chooses a distribution $\phi_\Delta$ that maximizes $E_{\phi_{\Delta}} r(y)$ subject to a relative entropy constraint $KL(\phi_\Delta || p) \leq \Delta.$ Another simple alignment method is best-of-$N$, where $N$ samples are drawn from $p$ and one with highest reward is selected. In this paper, we offer a closed-form characterization of the optimal KL-constrained RL solution. We demonstrate that any alignment method that achieves a comparable trade-off between KL divergence and reward must approximate the optimal KL-constrained RL solution in t
    
[^60]: 有效的内部语言模型训练和融合对于分解转录模型

    Effective internal language model training and fusion for factorized transducer model

    [https://arxiv.org/abs/2404.01716](https://arxiv.org/abs/2404.01716)

    提出了一种对于分解转录模型的有效ILM训练和解码策略，能够显著改善与标准解码方法的性能，并在LibriSpeech数据集上取得了17%的相对改善。

    

    神经转录器的内部语言模型（ILM）已被广泛研究。在大多数先前的工作中，它主要用于估计ILM分数，并在推理过程中随后被减去，以促进与外部语言模型更好的集成。最近，已提出了各种分解转录模型，明确采用独立的内部语言模型用于非空白令牌预测。然而，即使采用了分解转录模型，与浅层融合相比，改进仍然有限。在本文中，我们提出了一种新颖的ILM训练和解码策略，用于分解转录模型，有效地结合了空白、声学和ILM分数。我们的实验表明，在LibriSpeech数据集上利用经过良好训练的ILM和所提出的解码策略时，相对于标准解码方法，有17%的相对改善。此外，与强RNN-T ba相比

    arXiv:2404.01716v1 Announce Type: cross  Abstract: The internal language model (ILM) of the neural transducer has been widely studied. In most prior work, it is mainly used for estimating the ILM score and is subsequently subtracted during inference to facilitate improved integration with external language models. Recently, various of factorized transducer models have been proposed, which explicitly embrace a standalone internal language model for non-blank token prediction. However, even with the adoption of factorized transducer models, limited improvement has been observed compared to shallow fusion. In this paper, we propose a novel ILM training and decoding strategy for factorized transducer models, which effectively combines the blank, acoustic and ILM scores. Our experiments show a 17% relative improvement over the standard decoding method when utilizing a well-trained ILM and the proposed decoding strategy on LibriSpeech datasets. Furthermore, when compared to a strong RNN-T ba
    
[^61]: 基于共轭梯度的自适应矩估计优化算法用于深度学习

    Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning

    [https://arxiv.org/abs/2404.01714](https://arxiv.org/abs/2404.01714)

    提出一种基于共轭梯度样式的新优化算法CG-like-Adam，用于深度学习，并在收敛分析和数值实验中展示了其优越性

    

    训练深度神经网络是一项具有挑战性的任务。为加快培训速度并增强深度神经网络的性能，我们将传统的共轭梯度修正为共轭梯度样式，并将其并入通用Adam中，因此提出了一种名为CG-like-Adam的新优化算法用于深度学习。具体而言，通用Adam的一阶和二阶矩估计均由共轭梯度样式替换。收敛分析处理了一阶矩估计的指数移动平均系数为常数且一阶矩估计无偏的情况。数值实验显示了基于CIFAR10/100数据集的所提算法的优越性。

    arXiv:2404.01714v1 Announce Type: cross  Abstract: Training deep neural networks is a challenging task. In order to speed up training and enhance the performance of deep neural networks, we rectify the vanilla conjugate gradient as conjugate-gradient-like and incorporate it into the generic Adam, and thus propose a new optimization algorithm named CG-like-Adam for deep learning. Specifically, both the first-order and the second-order moment estimation of generic Adam are replaced by the conjugate-gradient-like. Convergence analysis handles the cases where the exponential moving average coefficient of the first-order moment estimation is constant and the first-order moment estimation is unbiased. Numerical experiments show the superiority of the proposed algorithm based on the CIFAR10/100 dataset.
    
[^62]: 通过免Hessian重新整合个体数据统计实现高效在线遗忘

    Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics

    [https://arxiv.org/abs/2404.01712](https://arxiv.org/abs/2404.01712)

    通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。

    

    机器遗忘旨在通过使模型能够选择性地忘记特定数据来维护数据所有者的被遗忘权利。最近的方法表明，一种数据遗忘的方法是通过预先计算和存储携带二阶信息的统计数据，以改进计算和内存效率。然而，它们依赖于苛刻的假设，而且计算/存储受到模型参数维度的诅咒，这使得难以应用到大多数深度神经网络中。在本工作中，我们提出了一种免Hessian在线遗忘方法。我们建议为每个数据点维护一个统计向量，通过重新训练和学习模型之间的差异的仿射随机递归逼近来计算。我们提出的算法实现了近乎瞬时的在线遗忘，因为它只需要进行矢量加法操作。基于重新收集遗忘数据统计的策略，

    arXiv:2404.01712v1 Announce Type: cross  Abstract: Machine unlearning strives to uphold the data owners' right to be forgotten by enabling models to selectively forget specific data. Recent methods suggest that one approach of data forgetting is by precomputing and storing statistics carrying second-order information to improve computational and memory efficiency. However, they rely on restrictive assumptions and the computation/storage suffer from the curse of model parameter dimensionality, making it challenging to apply to most deep neural networks. In this work, we propose a Hessian-free online unlearning method. We propose to maintain a statistical vector for each data point, computed through affine stochastic recursion approximation of the difference between retrained and learned models. Our proposed algorithm achieves near-instantaneous online unlearning as it only requires a vector addition operation. Based on the strategy that recollecting statistics for forgetting data, the p
    
[^63]: 防止高斯过程潜变量模型中的模型崩溃

    Preventing Model Collapse in Gaussian Process Latent Variable Models

    [https://arxiv.org/abs/2404.01697](https://arxiv.org/abs/2404.01697)

    本文通过理论分析投影方差对高斯过程潜变量模型的影响，以及集成了谱混合（SM）核和可微随机傅立叶特征（RFF）核逼近来解决核灵活性不足问题，从而防止模型崩溃。

    

    Gaussian process latent variable models (GPLVMs)是一类多才多艺的无监督学习模型，通常用于降维。然而，用GPLVMs对数据建模时常见的挑战包括核灵活性不足和投影噪声选择不当，导致了一种以模糊潜变量表示为主要特征的模型崩溃，这种表示不反映数据的潜在结构。本文首先从理论上通过线性GPLVM的视角研究了投影方差对模型崩溃的影响。其次，通过集成谱混合（SM）核和可微随机傅立叶特征（RFF）核逼近，解决了由于核灵活性不足导致的模型崩溃问题，从而保证了通过现成的自动微分工具实现学习核参数的计算可扩展性和效率。

    arXiv:2404.01697v1 Announce Type: cross  Abstract: Gaussian process latent variable models (GPLVMs) are a versatile family of unsupervised learning models, commonly used for dimensionality reduction. However, common challenges in modeling data with GPLVMs include inadequate kernel flexibility and improper selection of the projection noise, which leads to a type of model collapse characterized primarily by vague latent representations that do not reflect the underlying structure of the data. This paper addresses these issues by, first, theoretically examining the impact of the projection variance on model collapse through the lens of a linear GPLVM. Second, we address the problem of model collapse due to inadequate kernel flexibility by integrating the spectral mixture (SM) kernel and a differentiable random Fourier feature (RFF) kernel approximation, which ensures computational scalability and efficiency through off-the-shelf automatic differentiation tools for learning the kernel hype
    
[^64]: 选择性时态知识图推理

    Selective Temporal Knowledge Graph Reasoning

    [https://arxiv.org/abs/2404.01695](https://arxiv.org/abs/2404.01695)

    提出了一个适用于时态知识图推理的弃权机制，通过置信度估计帮助现有模型有选择性地预测未来事实，减少不确定性带来的风险。

    

    时间知识图（TKG）最近引起了广泛关注，它以（主体，关系，客体，时间戳）的形式描述了时间演变的事实。TKG推理旨在基于给定的历史事实预测未来事实。然而，现有的TKG推理模型无法避免对他们认为不确定的预测，这必然会在现实应用中带来风险。因此，在本文中，我们提出了一种适用于TKG推理的弃权机制，它可以帮助现有的模型进行选择性而非不加区别的预测。具体来说，我们开发了一种置信度估计器，称为带有历史信息的置信度估计器（CEHis），以使现有的TKG推理模型首先评估其在做出预测时的置信度，然后放弃那些置信度较低的预测。

    arXiv:2404.01695v1 Announce Type: new  Abstract: Temporal Knowledge Graph (TKG), which characterizes temporally evolving facts in the form of (subject, relation, object, timestamp), has attracted much attention recently. TKG reasoning aims to predict future facts based on given historical ones. However, existing TKG reasoning models are unable to abstain from predictions they are uncertain, which will inevitably bring risks in real-world applications. Thus, in this paper, we propose an abstention mechanism for TKG reasoning, which helps the existing models make selective, instead of indiscriminate, predictions. Specifically, we develop a confidence estimator, called Confidence Estimator with History (CEHis), to enable the existing TKG reasoning models to first estimate their confidence in making predictions, and then abstain from those with low confidence. To do so, CEHis takes two kinds of information into consideration, namely, the certainty of the current prediction and the accuracy
    
[^65]: HeMeNet：用于蛋白质多任务学习的异质多通道等变网络

    HeMeNet: Heterogeneous Multichannel Equivariant Network for Protein Multitask Learning

    [https://arxiv.org/abs/2404.01693](https://arxiv.org/abs/2404.01693)

    提出了HeMeNet模型，能够在输入蛋白质结构的基础上联合处理多个任务，解决了蛋白质多任务学习中的性能和泛化问题。

    

    理解和利用蛋白质的3D结构对于多种生物学和药物发现任务至关重要。深度学习已成功应用于基于蛋白结构的功能预测任务，但目前的方法通常为每个任务单独训练。然而，每个任务规模较小，这种单一任务策略限制了模型的性能和泛化能力。一些标记的3D蛋白数据集在生物上相关，将多源数据集组合用于更大规模的多任务学习是克服这一问题的一种方式。在本文中，我们提出了一个神经网络模型，以3D蛋白结构为输入共同处理多任务。

    arXiv:2404.01693v1 Announce Type: new  Abstract: Understanding and leveraging the 3D structures of proteins is central to a variety of biological and drug discovery tasks. While deep learning has been applied successfully for structure-based protein function prediction tasks, current methods usually employ distinct training for each task. However, each of the tasks is of small size, and such a single-task strategy hinders the models' performance and generalization ability. As some labeled 3D protein datasets are biologically related, combining multi-source datasets for larger-scale multi-task learning is one way to overcome this problem. In this paper, we propose a neural network model to address multiple tasks jointly upon the input of 3D protein structures. In particular, we first construct a standard structure-based multi-task benchmark called Protein-MT, consisting of 6 biologically relevant tasks, including affinity prediction and property prediction, integrated from 4 public data
    
[^66]: 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学

    A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling

    [https://arxiv.org/abs/2404.01685](https://arxiv.org/abs/2404.01685)

    通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。

    

    脉冲神经网络（SNNs）由于其稀疏的基于脉冲的操作而能为基于机器学习的应用提供超低功耗/能耗。目前，大多数SNN架构需要更大的模型大小才能实现更高的准确性，这对资源受限的嵌入式应用不太适合。因此，迫切需要开发能够以可接受的内存占用实现高准确性的SNNs。为此，我们提出了一种通过核大小缩放提高SNNs准确性的新方法学。其关键步骤包括调查不同核大小对准确性的影响，设计新的核大小集合，基于选定的核大小生成SNN架构，并分析SNN模型选择的准确性-内存折衷。实验结果表明，我们的方法学在准确性方面优于最先进的方法（对于CIFAR10有93.24%的准确度）

    arXiv:2404.01685v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNNs) can offer ultra low power/ energy consumption for machine learning-based applications due to their sparse spike-based operations. Currently, most of the SNN architectures need a significantly larger model size to achieve higher accuracy, which is not suitable for resource-constrained embedded applications. Therefore, developing SNNs that can achieve high accuracy with acceptable memory footprint is highly needed. Toward this, we propose a novel methodology that improves the accuracy of SNNs through kernel size scaling. Its key steps include investigating the impact of different kernel sizes on the accuracy, devising new sets of kernel sizes, generating SNN architectures based on the selected kernel sizes, and analyzing the accuracy-memory trade-offs for SNN model selection. The experimental results show that our methodology achieves higher accuracy than state-of-the-art (93.24% accuracy for CIFAR10 and 70
    
[^67]: 私人合作机器学习中的激励机制

    Incentives in Private Collaborative Machine Learning

    [https://arxiv.org/abs/2404.01676](https://arxiv.org/abs/2404.01676)

    引入差分隐私作为激励机制，中介者通过贝叶斯惊讶值来价值化扰动的充分统计量，实现隐私-估值权衡，同时保护差分隐私和高度相似性。

    

    协作机器学习涉及在来自多方数据的模型上训练，但必须激励各方参与。现有数据估值方法公平地根据共享数据或模型参数价值和奖励每个参与方，但忽视了涉及的隐私风险。为了解决这一问题，我们引入差分隐私（DP）作为一种激励机制。每个参与方可以选择其需要的DP保证，并相应地扰动其充分统计量（SS）。中介者通过模型参数所引发的贝叶斯惊讶值来价值化扰动的SS。由于我们的估值函数强制实施隐私-估值权衡，各方被阻止选择过高的DP保证，以减少大联盟模型的效用。最后，中介者用不同的后验模型参数样本奖励每个参与方。这种奖励仍然满足公平等现有激励要求，但另外还保护差分隐私和高度相似性。

    arXiv:2404.01676v1 Announce Type: new  Abstract: Collaborative machine learning involves training models on data from multiple parties but must incentivize their participation. Existing data valuation methods fairly value and reward each party based on shared data or model parameters but neglect the privacy risks involved. To address this, we introduce differential privacy (DP) as an incentive. Each party can select its required DP guarantee and perturb its sufficient statistic (SS) accordingly. The mediator values the perturbed SS by the Bayesian surprise it elicits about the model parameters. As our valuation function enforces a privacy-valuation trade-off, parties are deterred from selecting excessive DP guarantees that reduce the utility of the grand coalition's model. Finally, the mediator rewards each party with different posterior samples of the model parameters. Such rewards still satisfy existing incentives like fairness but additionally preserve DP and a high similarity to th
    
[^68]: COVID-19如何影响反疫苗言论：一个跨越疫情前后的大规模Twitter研究

    How COVID-19 has Impacted the Anti-Vaccine Discourse: A Large-Scale Twitter Study Spanning Pre-COVID and Post-COVID Era

    [https://arxiv.org/abs/2404.01669](https://arxiv.org/abs/2404.01669)

    通过大规模Twitter研究，本研究尝试理解COVID-19如何影响反疫苗言论，并且提出了两种新的方法去识别具体原因/关注点。

    

    关于疫苗的争论已经持续了几十年，但COVID-19大流行展示了理解和减少反疫苗情绪的重要性。尽管疫情可能已经结束，但仍然很重要理解疫情如何影响了反疫苗话语，并且在疫情结束后反对非COVID疫苗（如流感、麻疹、脊髓灰质炎、HPV疫苗）的论点是否也因疫情而改变。本研究试图通过对Twitter上的反疫苗帖子进行大规模研究来回答这些问题。几乎所有以社交媒体了解反疫苗观点的先前研究都只考虑反疫苗、赞成疫苗和中立三种广泛立场。迄今为止还没有努力在社交媒体上大规模识别反疫苗情绪背后的具体原因/关注点（如副作用、阴谋论、政治原因）。在这项工作中，我们提出了两种将推文分类为11种不同类型的新方法。

    arXiv:2404.01669v1 Announce Type: cross  Abstract: The debate around vaccines has been going on for decades, but the COVID-19 pandemic showed how crucial it is to understand and mitigate anti-vaccine sentiments. While the pandemic may be over, it is still important to understand how the pandemic affected the anti-vaccine discourse, and whether the arguments against non-COVID vaccines (e.g., Flu, MMR, IPV, HPV vaccines) have also changed due to the pandemic. This study attempts to answer these questions through a large-scale study of anti-vaccine posts on Twitter. Almost all prior works that utilized social media to understand anti-vaccine opinions considered only the three broad stances of Anti-Vax, Pro-Vax, and Neutral. There has not been any effort to identify the specific reasons/concerns behind the anti-vax sentiments (e.g., side-effects, conspiracy theories, political reasons) on social media at scale. In this work, we propose two novel methods for classifying tweets into 11 diffe
    
[^69]: 发布针对日语的预训练模型

    Release of Pre-Trained Models for the Japanese Language

    [https://arxiv.org/abs/2404.01657](https://arxiv.org/abs/2404.01657)

    发布日语预训练模型以缩小非英语社区中的AI访问差距，促进AI民主化。

    

    arXiv:2404.01657v1 公告类型:交叉摘要: AI民主化旨在创造一个普通人可以利用AI技术的世界。为了实现这一目标，许多研究机构已经试图让他们的结果对公众可及。特别是，基于大规模数据训练的大型预训练模型展现了前所未有的潜力，它们的发布产生了重大影响。然而，大多数发布的模型专门针对英语，因此，在非英语社区中，AI民主化存在明显滞后。为了缩小AI访问的差距，我们发布了用日语预先训练的生成式预训练转换器（GPT）、对比语言和图像预训练（CLIP）、稳定扩散和隐藏单元双向编码器表示来自变压器（HuBERT）。通过提供这些模型，用户可以自由地与符合日本文化价值观的AI进行交互，并确保日本文化的身份，从而增强

    arXiv:2404.01657v1 Announce Type: cross  Abstract: AI democratization aims to create a world in which the average person can utilize AI techniques. To achieve this goal, numerous research institutes have attempted to make their results accessible to the public. In particular, large pre-trained models trained on large-scale data have shown unprecedented potential, and their release has had a significant impact. However, most of the released models specialize in the English language, and thus, AI democratization in non-English-speaking communities is lagging significantly. To reduce this gap in AI access, we released Generative Pre-trained Transformer (GPT), Contrastive Language and Image Pre-training (CLIP), Stable Diffusion, and Hidden-unit Bidirectional Encoder Representations from Transformers (HuBERT) pre-trained in Japanese. By providing these models, users can freely interface with AI that aligns with Japanese cultural values and ensures the identity of Japanese culture, thus enha
    
[^70]: 仅使用前向传播的测试时间模型适应

    Test-Time Model Adaptation with Only Forward Passes

    [https://arxiv.org/abs/2404.01650](https://arxiv.org/abs/2404.01650)

    提出了一种测试时间前向适应（FOA）方法，通过无导数的协方差矩阵适应进化策略仅学习新添加的提示，以在资源有限的设备上实现模型适应。

    

    测试时间适应已被证明在适应给定训练模型到具有潜在分布转移的未见测试样本时是有效的。然而，在现实场景中，模型通常部署在资源有限的设备上，例如FPGA，并且通常被量化和硬编码为不可修改的参数以加速。鉴于此，由于现有方法严重依赖于计算密集型的反向传播进行模型更新，因此这些方法通常是不可行的。为了解决这个问题，我们提出了一种测试时间前向适应（FOA）方法。 在FOA中，我们试图通过一个无导数的协方差矩阵适应进化策略来仅学习新添加的提示（作为模型的输入）。 为了使这种策略在我们的在线无监督设置下稳定工作，我们设计了一种通过衡量测试训练统计差异和模型预测熵的新颖适应函数。此外，我们设计了一种激活移位方案。

    arXiv:2404.01650v1 Announce Type: new  Abstract: Test-time adaptation has proven effective in adapting a given trained model to unseen test samples with potential distribution shifts. However, in real-world scenarios, models are usually deployed on resource-limited devices, e.g., FPGAs, and are often quantized and hard-coded with non-modifiable parameters for acceleration. In light of this, existing methods are often infeasible since they heavily depend on computation-intensive backpropagation for model updating that may be not supported. To address this, we propose a test-time Forward-Only Adaptation (FOA) method. In FOA, we seek to solely learn a newly added prompt (as model's input) via a derivative-free covariance matrix adaptation evolution strategy. To make this strategy work stably under our online unsupervised setting, we devise a novel fitness function by measuring test-training statistic discrepancy and model prediction entropy. Moreover, we design an activation shifting sche
    
[^71]: Transformer遇见wcDTW以改进实时电池竞标：一种新的场景选择方法

    Transformer meets wcDTW to improve real-time battery bids: A new approach to scenario selection

    [https://arxiv.org/abs/2404.01646](https://arxiv.org/abs/2404.01646)

    本文将Transformer-based预测与weighted constrained Dynamic Time Warping (wcDTW)相结合，改进了实时电池竞标中的场景选择方法，通过模拟展示了相较于传统方法约10%的收益增长。

    

    实时能源市场中随机电池竞标是一个微妙的过程，其有效性取决于预测的准确性以及选择用于优化的代表性场景。在本文中，我们引入了一种先进的方法，将基于Transformer的预测与加权约束动态时间扭曲（wcDTW）相结合，以改进场景选择。我们的方法利用Transformer的预测能力来预测能源价格，而wcDTW通过维护多个不确定产品之间的一致性，确保选择相关的历史场景。通过在2023年7月的PJM市场进行广泛的模拟，我们的方法与传统方法相比收益增加了10％，突显了其有可能在实时市场中革新电池竞标策略的潜力。

    arXiv:2404.01646v1 Announce Type: new  Abstract: Stochastic battery bidding in real-time energy markets is a nuanced process, with its efficacy depending on the accuracy of forecasts and the representative scenarios chosen for optimization. In this paper, we introduce a pioneering methodology that amalgamates Transformer-based forecasting with weighted constrained Dynamic Time Warping (wcDTW) to refine scenario selection. Our approach harnesses the predictive capabilities of Transformers to foresee Energy prices, while wcDTW ensures the selection of pertinent historical scenarios by maintaining the coherence between multiple uncertain products. Through extensive simulations in the PJM market for July 2023, our method exhibited a 10% increase in revenue compared to the conventional method, highlighting its potential to revolutionize battery bidding strategies in real-time markets.
    
[^72]: ContrastCAD：基于对比学习的计算机辅助设计模型表示学习

    ContrastCAD: Contrastive Learning-based Representation Learning for Computer-Aided Design Models

    [https://arxiv.org/abs/2404.01645](https://arxiv.org/abs/2404.01645)

    ContrastCAD提出了基于对比学习的方法，能够有效捕捉CAD模型构建序列中的语义信息，并使用RRE方法增强了训练性能。

    

    Transformer-based模型的成功鼓舞了许多研究人员使用基于序列的方法学习CAD模型。然而，学习CAD模型仍然是一个挑战，因为它们可以被表示为具有长构建序列的复杂形状。此外，相同的CAD模型可以用不同的CAD构建序列来表示。我们提出了一种名为ContrastCAD的新颖基于对比学习的方法，该方法有效地捕捉CAD模型构建序列中的语义信息。ContrastCAD使用辍学技术生成增强视图而不改变CAD模型的形状。我们还提出了一种新的CAD数据增强方法，称为随机替换和挤出（RRE）方法，以增强模型在训练不平衡的训练CAD数据集时的学习性能。实验结果表明，所提出的RRE增强方法显着提高了学习性能。

    arXiv:2404.01645v1 Announce Type: cross  Abstract: The success of Transformer-based models has encouraged many researchers to learn CAD models using sequence-based approaches. However, learning CAD models is still a challenge, because they can be represented as complex shapes with long construction sequences. Furthermore, the same CAD model can be expressed using different CAD construction sequences. We propose a novel contrastive learning-based approach, named ContrastCAD, that effectively captures semantic information within the construction sequences of the CAD model. ContrastCAD generates augmented views using dropout techniques without altering the shape of the CAD model. We also propose a new CAD data augmentation method, called a Random Replace and Extrude (RRE) method, to enhance the learning performance of the model when training an imbalanced training CAD dataset. Experimental results show that the proposed RRE augmentation method significantly enhances the learning performan
    
[^73]: ADVREPAIR：对抗攻击的可证修复

    ADVREPAIR:Provable Repair of Adversarial Attack

    [https://arxiv.org/abs/2404.01642](https://arxiv.org/abs/2404.01642)

    ADVREPAIR是一种利用有限数据进行对抗攻击的可证修复的新方法，通过形式验证构建补丁模块，在稳健邻域内提供可证和专门的修复，同时具有泛化到其他输入的防御能力。

    

    深度神经网络(DNNs)在安全关键领域中的部署日益增加，但它们对抗性攻击的脆弱性构成严重的安全风险。现有的使用有限数据的神经元级方法在修复对手方面缺乏效力，因为对抗攻击机制的固有复杂性，而对抗训练，利用大量对抗样本增强鲁棒性，缺乏可证性。在本文中，我们提出了ADVREPAIR，一种利用有限数据进行对抗攻击的可证修复的新方法。通过利用形式验证，ADVREPAIR构建补丁模块，当与原始网络集成时，在稳健邻域内提供可证和专门的修复。此外，我们的方法还包括一种启发式机制来分配补丁模块，使得这种防御对抗攻击泛化到其他输入。ADVREPAIR展示了卓越的效率。

    arXiv:2404.01642v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are increasingly deployed in safety-critical domains, but their vulnerability to adversarial attacks poses serious safety risks. Existing neuron-level methods using limited data lack efficacy in fixing adversaries due to the inherent complexity of adversarial attack mechanisms, while adversarial training, leveraging a large number of adversarial samples to enhance robustness, lacks provability. In this paper, we propose ADVREPAIR, a novel approach for provable repair of adversarial attacks using limited data. By utilizing formal verification, ADVREPAIR constructs patch modules that, when integrated with the original network, deliver provable and specialized repairs within the robustness neighborhood. Additionally, our approach incorporates a heuristic mechanism for assigning patch modules, allowing this defense against adversarial attacks to generalize to other inputs. ADVREPAIR demonstrates superior efficienc
    
[^74]: 通过强化学习学习控制摄像机曝光

    Learning to Control Camera Exposure via Reinforcement Learning

    [https://arxiv.org/abs/2404.01636](https://arxiv.org/abs/2404.01636)

    提出了一种通过深度强化学习快速控制摄像机曝光的新框架，具有简化训练场地、奖励设计和曝光调整能力逐步改善等四大创新贡献

    

    调整摄像机曝光是确保计算机视觉应用功能的第一步。传统的摄像机曝光控制方法需要多次收敛和耗时的流程，使其不适用于动态照明条件。本文提出了一种利用深度强化学习快速控制摄像机曝光的新框架。该框架包括四个贡献：1）简化训练场地来模拟现实世界的多样化和动态照明变化，2）闪烁和图像属性感知奖励设计，以及轻量级状态设计以进行实时处理，3）静态到动态照明课程，逐步改善代理的曝光调整能力

    arXiv:2404.01636v1 Announce Type: cross  Abstract: Adjusting camera exposure in arbitrary lighting conditions is the first step to ensure the functionality of computer vision applications. Poorly adjusted camera exposure often leads to critical failure and performance degradation. Traditional camera exposure control methods require multiple convergence steps and time-consuming processes, making them unsuitable for dynamic lighting conditions. In this paper, we propose a new camera exposure control framework that rapidly controls camera exposure while performing real-time processing by exploiting deep reinforcement learning. The proposed framework consists of four contributions: 1) a simplified training ground to simulate real-world's diverse and dynamic lighting changes, 2) flickering and image attribute-aware reward design, along with lightweight state design for real-time processing, 3) a static-to-dynamic lighting curriculum to gradually improve the agent's exposure-adjusting capabi
    
[^75]: 通过无监督机器学习增强汽车AMS电路的功能安全性

    Enhancing Functional Safety in Automotive AMS Circuits through Unsupervised Machine Learning

    [https://arxiv.org/abs/2404.01632](https://arxiv.org/abs/2404.01632)

    通过无监督机器学习实现早期异常检测，以增强汽车AMS电路的功能安全性

    

    鉴于在汽车领域广泛使用安全关键应用程序，确保汽车系统内的电路和组件的功能安全（FuSa）至关重要。这些系统中普遍存在的模拟和混合信号（AMS）电路比它们的数字对应物更容易受到由参数扰动、噪声、环境压力和其他因素引起的故障影响。然而，它们的连续信号特性为早期异常检测提供了机会，从而实现了实施安全机制以防止系统故障。为了满足这种需求，我们提出了一种基于无监督机器学习的新型框架，用于AMS电路的早期异常检测。所提出的方法涉及在各种电路位置和单独组件注入异常，以创建多样化和全面的异常数据集，然后从观察到的电路中提取特征。

    arXiv:2404.01632v1 Announce Type: new  Abstract: Given the widespread use of safety-critical applications in the automotive field, it is crucial to ensure the Functional Safety (FuSa) of circuits and components within automotive systems. The Analog and Mixed-Signal (AMS) circuits prevalent in these systems are more vulnerable to faults induced by parametric perturbations, noise, environmental stress, and other factors, in comparison to their digital counterparts. However, their continuous signal characteristics present an opportunity for early anomaly detection, enabling the implementation of safety mechanisms to prevent system failure. To address this need, we propose a novel framework based on unsupervised machine learning for early anomaly detection in AMS circuits. The proposed approach involves injecting anomalies at various circuit locations and individual components to create a diverse and comprehensive anomaly dataset, followed by the extraction of features from the observed ci
    
[^76]: 学习等角表示进行在线连续学习

    Learning Equi-angular Representations for Online Continual Learning

    [https://arxiv.org/abs/2404.01628](https://arxiv.org/abs/2404.01628)

    使用神经坍缩现象引入神经坍缩来形成表示空间中的等角紧框架结构，通过提出预备数据训练和残差修正，使得单周期学习的连续学习模型能更好地适应流数据，这种方法在在线连续学习中取得了明显的优势。

    

    在线连续学习存在欠拟合解决方案的问题，因为由于不及时的模型更新培训不足（例如，单周期训练）。为了解决这一挑战，我们提出了一种有效的在线连续学习方法，利用神经坍缩现象。具体地，我们诱导神经坍缩形成表示空间中的单纯等角紧框架（ETF）结构，以便通过在表示空间中提出预备数据训练和残差修正来更好地使经过单周期学习的持续学习模型适应流媒体数据。通过使用CIFAR-10/100、TinyImageNet、ImageNet-200和ImageNet-1K进行大量实证验证，我们展示了我们提出的方法在各种在线连续学习场景（如不相交和高斯调度连续（即无边界）数据设置）中均较领先方法表现出显著优势。

    arXiv:2404.01628v1 Announce Type: cross  Abstract: Online continual learning suffers from an underfitted solution due to insufficient training for prompt model update (e.g., single-epoch training). To address the challenge, we propose an efficient online continual learning method using the neural collapse phenomenon. In particular, we induce neural collapse to form a simplex equiangular tight frame (ETF) structure in the representation space so that the continuously learned model with a single epoch can better fit to the streamed data by proposing preparatory data training and residual correction in the representation space. With an extensive set of empirical validations using CIFAR-10/100, TinyImageNet, ImageNet-200, and ImageNet-1K, we show that our proposed method outperforms state-of-the-art methods by a noticeable margin in various online continual learning scenarios such as disjoint and Gaussian scheduled continuous (i.e., boundary-free) data setups.
    
[^77]: 利用大语言模型设计自适应码率算法的LLM-ABR

    LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models

    [https://arxiv.org/abs/2404.01617](https://arxiv.org/abs/2404.01617)

    LLM-ABR利用大语言模型自主设计适用于各种网络特性的自适应码率算法，并在不同网络环境中表现优异。

    

    我们提出了LLM-ABR，这是第一个利用大语言模型（LLMs）的生成能力来自动设计适用于不同网络特性的自适应码率（ABR）算法的系统。LLM-ABR在强化学习框架内运行，赋予LLMs设计关键组件如状态和神经网络架构的能力。我们在包括宽带、卫星、4G和5G在内的不同网络设置中评估了LLM-ABR。LLM-ABR始终优于默认ABR算法。

    arXiv:2404.01617v1 Announce Type: cross  Abstract: We present LLM-ABR, the first system that utilizes the generative capabilities of large language models (LLMs) to autonomously design adaptive bitrate (ABR) algorithms tailored for diverse network characteristics. Operating within a reinforcement learning framework, LLM-ABR empowers LLMs to design key components such as states and neural network architectures. We evaluate LLM-ABR across diverse network settings, including broadband, satellite, 4G, and 5G. LLM-ABR consistently outperforms default ABR algorithms.
    
[^78]: 虚拟环境中声源定位的音频模拟

    Audio Simulation for Sound Source Localization in Virtual Evironment

    [https://arxiv.org/abs/2404.01611](https://arxiv.org/abs/2404.01611)

    本研究通过音频模拟和机器学习方法，在虚拟环境中实现了声源定位到特定位置的准确性，有效克服了数据不足的问题。

    

    非直射定位在信号匮乏的环境中是一个具有挑战性但又相关的问题。在主要为室内场景的这种情况下，声学方法遇到困难，这是由于反射的特性。本研究旨在通过利用物理基础的声传播模拟和机器学习方法，在虚拟环境中将声源定位到特定位置。该过程试图克服数据不足的问题，特别是在事件发生后的声源定位。我们使用音频变换器频谱图方法实现了0.786+/-0,0136的F1分数。

    arXiv:2404.01611v1 Announce Type: new  Abstract: Non-line-of-sight localization in signal-deprived environments is a challenging yet pertinent problem. Acoustic methods in such predominantly indoor scenarios encounter difficulty due to the reverberant nature. In this study, we aim to locate sound sources to specific locations within a virtual environment by leveraging physically grounded sound propagation simulations and machine learning methods. This process attempts to overcome the issue of data insufficiency to localize sound sources to their location of occurrence especially in post-event localization. We achieve 0.786+/- 0.0136 F1-score using an audio transformer spectrogram approach.
    
[^79]: FAIRM: 学习不变表示以实现算法公平性和域泛化的极小最优性

    FAIRM: Learning invariant representations for algorithmic fairness and domain generalization with minimax optimality

    [https://arxiv.org/abs/2404.01608](https://arxiv.org/abs/2404.01608)

    提出了一种通过不变性原则解决公平和泛化机器学习问题的方法，包括基于训练环境的oracle FAIRM，以及在线性模型中实现FAIRM的高效算法，在实验中表现出极小最优性。

    

    机器学习方法通常假设测试数据与训练数据具有相同的分布。然而，由于应用中存在多个层次的异质性，这一假设可能不成立，从而引发算法公平性和域泛化方面的问题。在这项工作中，我们通过不变性原则解决了公平且具有泛化能力的机器学习问题。我们提出了一个基于训练环境的oracle，FAIRM，它在多样性类型条件下具有理想的公平性和域泛化特性。然后，我们在弱分布假设下提供了一个具有有限样本理论保证的经验FAIRM。我们还开发了有效的算法来在线性模型中实现FAIRM，并展示了具有极小最优性的非渐近性能。我们在合成数据和MNIST数据的数值实验中评估了我们的方法，并展示了其优于对应方法的表现。

    arXiv:2404.01608v1 Announce Type: cross  Abstract: Machine learning methods often assume that the test data have the same distribution as the training data. However, this assumption may not hold due to multiple levels of heterogeneity in applications, raising issues in algorithmic fairness and domain generalization. In this work, we address the problem of fair and generalizable machine learning by invariant principles. We propose a training environment-based oracle, FAIRM, which has desirable fairness and domain generalization properties under a diversity-type condition. We then provide an empirical FAIRM with finite-sample theoretical guarantees under weak distributional assumptions. We then develop efficient algorithms to realize FAIRM in linear models and demonstrate the nonasymptotic performance with minimax optimality. We evaluate our method in numerical experiments with synthetic data and MNIST data and show that it outperforms its counterparts.
    
[^80]: 变深度Transformer能学到什么？序列学习任务的案例研究

    What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks

    [https://arxiv.org/abs/2404.01601](https://arxiv.org/abs/2404.01601)

    Transformer的深度对其进行不同任务的影响进行了系统评估，研究发现推理和泛化需要至少两个注意力层，而上下文泛化可能需要三个注意力层。通过组合简单操作和堆叠多个注意力层，复杂任务可以得到解决。

    

    我们研究了具有不同深度的Transformer架构的能力。具体来说，我们设计了一组新颖的序列学习任务，系统评估和理解了Transformer的深度如何影响其进行记忆、推理、泛化和上下文泛化的能力。我们展示了只有一个注意力层的Transformer可以在记忆方面表现出色，但在其他任务方面表现不佳。接着，我们展示了展示推理和泛化能力需要Transformer至少具有两个注意力层，而上下文泛化能力可能需要三个注意力层。此外，我们确定了单个注意力层可以执行的一类简单操作，并展示了复杂任务可以作为这些简单操作的组合来处理，因此可以通过堆叠多个注意力层来解决。这为研究更实际和复杂的问题提供了启示。

    arXiv:2404.01601v1 Announce Type: new  Abstract: We study the capabilities of the transformer architecture with varying depth. Specifically, we designed a novel set of sequence learning tasks to systematically evaluate and comprehend how the depth of transformer affects its ability to perform memorization, reasoning, generalization, and contextual generalization. We show a transformer with only one attention layer can excel in memorization but falls short in other tasks. Then, we show that exhibiting reasoning and generalization ability requires the transformer to have at least two attention layers, while context generalization ability may necessitate three attention layers. Additionally, we identify a class of simple operations that a single attention layer can execute, and show that the complex tasks can be approached as the combinations of these simple operations and thus can be resolved by stacking multiple attention layers. This sheds light on studying more practical and complex t
    
[^81]: 用于加速策略优化的极值寻找动作选择

    Extremum-Seeking Action Selection for Accelerating Policy Optimization

    [https://arxiv.org/abs/2404.01598](https://arxiv.org/abs/2404.01598)

    提出了在无模型强化学习中改进动作选择的方法，通过引入极值寻找控制（ESC）进行自适应控制步骤，以加速策略优化。

    

    在连续空间上进行控制的强化学习通常使用高熵的随机策略，如高斯分布，用于局部探索和估计策略梯度以优化性能。许多机器人控制问题涉及复杂不稳定的动力学，其中施加在可行控制流形之外的动作很快会导致不良发散。在这种情况下，大多数从环境动作空间中采样的样本生成的轨迹价值较低，几乎没有贡献于策略改进，导致学习缓慢或失败。我们提出在这种无模型RL设置中通过引入基于极值寻找控制（ESC）的附加自适应控制步骤来改善动作选择。对于从随机策略采样的每个动作，我们应用正弦扰动并查询估计的Q值作为响应信号。根据ESC，我们动态改进采样的动作以使之更接近理想动作。

    arXiv:2404.01598v1 Announce Type: cross  Abstract: Reinforcement learning for control over continuous spaces typically uses high-entropy stochastic policies, such as Gaussian distributions, for local exploration and estimating policy gradient to optimize performance. Many robotic control problems deal with complex unstable dynamics, where applying actions that are off the feasible control manifolds can quickly lead to undesirable divergence. In such cases, most samples taken from the ambient action space generate low-value trajectories that hardly contribute to policy improvement, resulting in slow or failed learning. We propose to improve action selection in this model-free RL setting by introducing additional adaptive control steps based on Extremum-Seeking Control (ESC). On each action sampled from stochastic policies, we apply sinusoidal perturbations and query for estimated Q-values as the response signal. Based on ESC, we then dynamically improve the sampled actions to be closer 
    
[^82]: 多模态数据无配对倾向得分对齐

    Propensity Score Alignment of Unpaired Multimodal Data

    [https://arxiv.org/abs/2404.01595](https://arxiv.org/abs/2404.01595)

    本文提出了一种解决多模态表示学习中对齐不配对样本挑战的方法，通过估计倾向得分来定义样本之间的距离。

    

    多模态表示学习技术通常依赖于配对样本来学习共同的表示，但在生物学等领域，往往难以收集配对样本，因为测量设备通常会破坏样本。本文介绍了一种解决多模态表示学习中对齐不配对样本的方法。我们将因果推断中的潜在结果与多模态观察中的潜在视图进行类比，这使我们能够使用Rubin的框架来估计一个共同的空间，以匹配样本。我们的方法假设我们收集了经过处理实验干扰的样本，并利用此来从每种模态中估计倾向得分，其中包括潜在状态和处理之间的所有共享信息，并可用于定义样本之间的距离。我们尝试了两种利用这一方法的对齐技术。

    arXiv:2404.01595v1 Announce Type: new  Abstract: Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this di
    
[^83]: 基于幻觉多样性的文本摘要主动学习

    Hallucination Diversity-Aware Active Learning for Text Summarization

    [https://arxiv.org/abs/2404.01588](https://arxiv.org/abs/2404.01588)

    本文首次提出了一种基于幻觉多样性的主动学习框架，用于减轻大型语言模型（LLMs）在文本摘要中产生的幻觉，减少了昂贵的人类注释需求。

    

    大型语言模型（LLMs）已经表现出生成幻觉输出的倾向，即在事实上不正确或不支持的文本。现有的减轻幻觉的方法通常需要昂贵的人类注释来识别和纠正LLMs输出中的幻觉。此外，大多数这些方法专注于特定类型的幻觉，例如实体或标记错误，这限制了它们在解决LLMs输出中展示的各种类型的幻觉方面的有效性。据我们所知，本文提出了第一个旨在减轻LLMs幻觉的主动学习框架，降低了对幻觉所需的昂贵人类注释。通过在文本摘要中衡量语义框架、议论和内容可验证性错误中的细粒度幻觉，我们提出了 HAllucination Diversity-Aware Sampling（HADAS）来选择多样化的幻觉，以供LLM微调的主动学习注释。

    arXiv:2404.01588v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown propensity to generate hallucinated outputs, i.e., texts that are factually incorrect or unsupported. Existing methods for alleviating hallucinations typically require costly human annotations to identify and correct hallucinations in LLM outputs. Moreover, most of these methods focus on a specific type of hallucination, e.g., entity or token errors, which limits their effectiveness in addressing various types of hallucinations exhibited in LLM outputs. To our best knowledge, in this paper we propose the first active learning framework to alleviate LLM hallucinations, reducing costly human annotations of hallucination needed. By measuring fine-grained hallucinations from errors in semantic frame, discourse and content verifiability in text summarization, we propose HAllucination Diversity-Aware Sampling (HADAS) to select diverse hallucinations for annotations in active learning for LLM finetuning
    
[^84]: GLEMOS：瞬时图学习模型选择的基准评估

    GLEMOS: Benchmark for Instantaneous Graph Learning Model Selection

    [https://arxiv.org/abs/2404.01578](https://arxiv.org/abs/2404.01578)

    GLEMOS提供了一个全面的基准评估，用于瞬时地选择有效的图学习模型，填补了之前缺乏的评估GL模型选择方法性能的空白。

    

    图学习（GL）模型（即GL算法及其超参数设置）的选择对下游任务的性能有重要影响。然而，随着越来越多的GL模型被开发出来，选择正确的GL模型变得越来越困难和耗时。因此，为GL的用户提供能够在没有手动干预的情况下执行有效GL模型的近乎瞬时选择的能力具有重要意义和实际价值。尽管近年来已经有尝试解决这一重要问题，但尚未有一个全面的基准环境来评估GL模型选择方法的性能。为弥补这一空白，本文提出了GLEMOS，一个用于瞬时GL模型选择的全面基准评估，其做出以下贡献。

    arXiv:2404.01578v1 Announce Type: new  Abstract: The choice of a graph learning (GL) model (i.e., a GL algorithm and its hyperparameter settings) has a significant impact on the performance of downstream tasks. However, selecting the right GL model becomes increasingly difficult and time consuming as more and more GL models are developed. Accordingly, it is of great significance and practical value to equip users of GL with the ability to perform a near-instantaneous selection of an effective GL model without manual intervention. Despite the recent attempts to tackle this important problem, there has been no comprehensive benchmark environment to evaluate the performance of GL model selection methods. To bridge this gap, we present GLEMOS in this work, a comprehensive benchmark for instantaneous GL model selection that makes the following contributions. (i) GLEMOS provides extensive benchmark data for fundamental GL tasks, i.e., link prediction and node classification, including the pe
    
[^85]: 目标黑盒神经排序模型的多粒度对抗攻击

    Multi-granular Adversarial Attacks against Black-box Neural Ranking Models

    [https://arxiv.org/abs/2404.01574](https://arxiv.org/abs/2404.01574)

    这项研究聚焦于利用多粒度扰动生成高质量的对抗性示例，通过转化为顺序决策过程来解决组合爆炸问题。

    

    对抗排序攻击由于在发现神经排序模型的脆弱性并增强其鲁棒性方面取得成功而受到越来越多的关注。传统的攻击方法仅在单一粒度上进行扰动，例如单词级或句子级，对目标文档进行攻击。然而，将扰动限制在单一粒度上可能会减少创造对抗性示例的灵活性，从而降低攻击的潜在威胁。因此，我们专注于通过结合不同粒度的扰动生成高质量的对抗性示例。实现这一目标涉及解决组合爆炸问题，需要识别出跨所有可能的粒度、位置和文本片段的最佳组合扰动。为了解决这一挑战，我们将多粒度对抗攻击转化为一个顺序决策过程，其中

    arXiv:2404.01574v1 Announce Type: cross  Abstract: Adversarial ranking attacks have gained increasing attention due to their success in probing vulnerabilities, and, hence, enhancing the robustness, of neural ranking models. Conventional attack methods employ perturbations at a single granularity, e.g., word-level or sentence-level, to a target document. However, limiting perturbations to a single level of granularity may reduce the flexibility of creating adversarial examples, thereby diminishing the potential threat of the attack. Therefore, we focus on generating high-quality adversarial examples by incorporating multi-granular perturbations. Achieving this objective involves tackling a combinatorial explosion problem, which requires identifying an optimal combination of perturbations across all possible levels of granularity, positions, and textual pieces. To address this challenge, we transform the multi-granular adversarial attack into a sequential decision-making process, where 
    
[^86]: 使用对比集评估大型语言模型：一种实验方法

    Evaluating Large Language Models Using Contrast Sets: An Experimental Approach

    [https://arxiv.org/abs/2404.01569](https://arxiv.org/abs/2404.01569)

    介绍了一种为斯坦福自然语言推断（SNLI）数据集生成对比集的创新技术，通过自动替换动词、副词和形容词为同义词来评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。

    

    在自然语言推断（NLI）领域，尤其是涉及多个输入文本分类的任务中，交叉熵损失度量被广泛应用作为错误度量的标准。然而，该度量在有效评估模型理解语句蕴涵能力方面存在不足。本研究引入了一种创新的技术，用于为斯坦福自然语言推断（SNLI）数据集生成对比集。我们的策略涉及自动将动词、副词和形容词替换为它们的同义词，以保留句子的原始含义。该方法旨在评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。我们使用ELECTRA-small模型进行了分析。该模型在传统的SNLI数据集上实现了89.9%的准确度，但在我们的对比集上显示出了72.5%的准确度，表明

    arXiv:2404.01569v1 Announce Type: cross  Abstract: In the domain of Natural Language Inference (NLI), especially in tasks involving the classification of multiple input texts, the Cross-Entropy Loss metric is widely employed as a standard for error measurement. However, this metric falls short in effectively evaluating a model's capacity to understand language entailments. In this study, we introduce an innovative technique for generating a contrast set for the Stanford Natural Language Inference (SNLI) dataset. Our strategy involves the automated substitution of verbs, adverbs, and adjectives with their synonyms to preserve the original meaning of sentences. This method aims to assess whether a model's performance is based on genuine language comprehension or simply on pattern recognition. We conducted our analysis using the ELECTRA-small model. The model achieved an accuracy of 89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5% on our contrast set, indicati
    
[^87]: 分布式自主群体形成动态网络桥接

    Distributed Autonomous Swarm Formation for Dynamic Network Bridging

    [https://arxiv.org/abs/2404.01557](https://arxiv.org/abs/2404.01557)

    提出了一种用于动态网络桥接的新颖分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，以及基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法。

    

    有效的机器人系统操作和无缝协作是下一代技术和应用的基本组成部分。在诸如灾难响应之类的情景中，群体操作需要协调的行为和移动控制以分布式方式处理，代理之间的通信以及底层网络质量对其行动的质量产生重大影响。本文针对动态网络桥接问题提出了一种新颖的分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，其中一群代理协作形成两个远距移动目标之间的连接。此外，我们提出了一种基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法，该方法自然适用于任务的网络化、分布式性质。所提出的方法在模拟环境中进行了评估，并与一个基于强化学习的中心化方法进行了比较。

    arXiv:2404.01557v1 Announce Type: cross  Abstract: Effective operation and seamless cooperation of robotic systems are a fundamental component of next-generation technologies and applications. In contexts such as disaster response, swarm operations require coordinated behavior and mobility control to be handled in a distributed manner, with the quality of the agents' actions heavily relying on the communication between them and the underlying network. In this paper, we formulate the problem of dynamic network bridging in a novel Decentralized Partially Observable Markov Decision Process (Dec-POMDP), where a swarm of agents cooperates to form a link between two distant moving targets. Furthermore, we propose a Multi-Agent Reinforcement Learning (MARL) approach for the problem based on Graph Convolutional Reinforcement Learning (DGN) which naturally applies to the networked, distributed nature of the task. The proposed method is evaluated in a simulated environment and compared to a cent
    
[^88]: 具有控制理论安全保证的动态网络桥接的多智能体强化学习

    Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging

    [https://arxiv.org/abs/2404.01551](https://arxiv.org/abs/2404.01551)

    将多智能体强化学习与控制理论相结合，提出了一种新的设定点更新算法，以确保安全条件并实现良好的任务目标性能。

    

    在安全关键环境下解决复杂的合作任务对多智能体系统提出了重大挑战，尤其在部分可观测条件下。本文引入了一种混合方法，将多智能体强化学习与控制理论方法相结合，以确保安全和高效的分布式策略。我们的贡献包括一种新颖的设定点更新算法，动态调整智能体位置，以保持安全条件而不影响任务目标。通过实验验证，我们证明相比传统的多智能体强化学习策略，我们取得了显著优势，实现了与零安全违规相比可比的任务性能。研究结果表明，将安全控制与学习方法相结合不仅增强了安全合规性，还实现了良好的任务目标性能。

    arXiv:2404.01551v1 Announce Type: cross  Abstract: Addressing complex cooperative tasks in safety-critical environments poses significant challenges for Multi-Agent Systems, especially under conditions of partial observability. This work introduces a hybrid approach that integrates Multi-Agent Reinforcement Learning with control-theoretic methods to ensure safe and efficient distributed strategies. Our contributions include a novel setpoint update algorithm that dynamically adjusts agents' positions to preserve safety conditions without compromising the mission's objectives. Through experimental validation, we demonstrate significant advantages over conventional MARL strategies, achieving comparable task performance with zero safety violations. Our findings indicate that integrating safe control with learning approaches not only enhances safety compliance but also achieves good performance in mission objectives.
    
[^89]: 通过线上的一致性预测基础模型的性能

    Predicting the Performance of Foundation Models via Agreement-on-the-Line

    [https://arxiv.org/abs/2404.01542](https://arxiv.org/abs/2404.01542)

    本研究发现，通过对来自单个基础模型的多次运行进行轻微微调，可以通过训练期间的随机性选择来显著影响最终集合中的一致性。

    

    估计标签稀缺情况下的外部分布性能对于安全部署基础模型至关重要。最近，人们发现神经网络集合观察到“线上一致性”现象，可以利用它可靠地预测无标签的外部分布性能。然而，与在分布数据上从头开始训练多次轮数的传统神经网络相比，基础模型经历了从预训练权重中进行最小微调，这可能会减少观察到线上一致性所需的集合多样性。在我们的工作中，我们展示出当轻微微调整来自$\textit{单个}$基础模型的多次运行时，训练期间的随机性选择（线性头初始化、数据排序和数据子集）可能导致不同程度的线上一致性的最终集合。令人惊讶的是，只有随机头初始化就能极大程度地影响集合中的一致性。ên初化就能使产生的集合中的一致性水平产生巨大差异。

    arXiv:2404.01542v1 Announce Type: new  Abstract: Estimating the out-of-distribution performance in regimes where labels are scarce is critical to safely deploy foundation models. Recently, it was shown that ensembles of neural networks observe the phenomena ``agreement-on-the-line'', which can be leveraged to reliably predict OOD performance without labels. However, in contrast to classical neural networks that are trained on in-distribution data from scratch for numerous epochs, foundation models undergo minimal finetuning from heavily pretrained weights, which may reduce the ensemble diversity needed to observe agreement-on-the-line. In our work, we demonstrate that when lightly finetuning multiple runs from a $\textit{single}$ foundation model, the choice of randomness during training (linear head initialization, data ordering, and data subsetting) can lead to drastically different levels of agreement-on-the-line in the resulting ensemble. Surprisingly, only random head initializati
    
[^90]: 放置锚点：在语言建模中给数字语义上的引导

    Laying Anchors: Semantically Priming Numerals in Language Modeling

    [https://arxiv.org/abs/2404.01536](https://arxiv.org/abs/2404.01536)

    通过生成受数字分布规律控制的锚点，我们引入了一种在语义上引导数字的策略，在广泛范围的数字任务上实现了数学基础表示的显著改进。

    

    现有大量预训练语言模型已成为自然语言处理管线中的事实标准，然而这些模型未能正确编码数字，限制了它们在需要数字理解的任务上的性能。我们引入了一种策略，通过在任何语料库中生成受数字分布规律控制的锚点来在语义上引导数字，从而实现这些数字标记的数学基础表示。我们通过对一系列数值任务进行评估，证明了我们提出的技术的优越性，对领域内（已见）和领域外（未见）的数字都适用。此外，我们将实证评估扩展到从1到10亿的数字范围，比以往相同类型研究的范围广得多，展示了我们学得的嵌入向数学上的显著改进。

    arXiv:2404.01536v1 Announce Type: cross  Abstract: Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks. However, the inability of these models to properly encode numerals limits their performance on tasks requiring numeric comprehension. We introduce strategies to semantically prime numerals in any corpus by generating anchors governed by the distribution of numerals in said corpus, thereby enabling mathematically grounded representations of these numeral tokens. We establish the superiority of our proposed techniques through evaluation on a range of numeracy tasks for both in-domain (seen) and out-domain (unseen) numerals. Further, we expand our empirical evaluations to numerals ranging from 1 to 10 billion, a significantly broader range compared to previous studies of the same nature, and we demonstrate significant improvements in the mathematical grounding of our learned embeddings.
    
[^91]: 5G和B5G网络中的ML关键绩效指标预测

    ML KPI Prediction in 5G and B5G Networks

    [https://arxiv.org/abs/2404.01530](https://arxiv.org/abs/2404.01530)

    本文引入了一种用于估算5G和B5G网络中端到端（E2E）网络切片吞吐量的机器学习（ML）模型，并将预测的吞吐量与当前网络状态结合起来，以推导出一个步                                                                                                                                                                                                  en_tdlr: Introducing a machine learning model for estimating throughput in 5G and B5G networks with network slices, and combining predicted throughput with current network state for performance optimization.

    

    网络运营商在满足客户需求时面临新挑战。这些挑战源于新服务的出现，如高清视频流媒体、物联网、自动驾驶等，以及网络流量的指数增长。在这种情况下，5G和B5G网络一直在发展，以适应各种应用和用例。此外，这种发展带来了新特性，如利用网络切片创建多个端到端隔离的虚拟网络的能力。然而，为了确保服务质量，运营商必须根据关键性能指标（KPI）和切片服务级别协议（SLA）来维护和优化他们的网络。

    arXiv:2404.01530v1 Announce Type: cross  Abstract: Network operators are facing new challenges when meeting the needs of their customers. The challenges arise due to the rise of new services, such as HD video streaming, IoT, autonomous driving, etc., and the exponential growth of network traffic. In this context, 5G and B5G networks have been evolving to accommodate a wide range of applications and use cases. Additionally, this evolution brings new features, like the ability to create multiple end-to-end isolated virtual networks using network slicing. Nevertheless, to ensure the quality of service, operators must maintain and optimize their networks in accordance with the key performance indicators (KPIs) and the slice service-level agreements (SLAs).   In this paper, we introduce a machine learning (ML) model used to estimate throughput in 5G and B5G networks with end-to-end (E2E) network slices. Then, we combine the predicted throughput with the current network state to derive an es
    
[^92]: 公平的MP-BOOST: 公平且可解释的小批量 Boosting

    Fair MP-BOOST: Fair and Interpretable Minipatch Boosting

    [https://arxiv.org/abs/2404.01521](https://arxiv.org/abs/2404.01521)

    Fair MP-Boost是一种旨在平衡公平性和准确性的Boosting方法，通过自适应学习特征和观测来选择小批量，以同时提高预测准确性和公平性。

    

    集成方法，特别是Boosting，在表格数据中已被证明是高效且广泛应用的机器学习技术。在本文中，我们旨在利用传统Boosting方法的稳健预测能力，同时增强公平性和可解释性。为实现这一目标，我们开发了Fair MP-Boost，这是一种平衡公平性和准确性的随机Boosting方案，通过在训练期间自适应学习特征和观察来实现。具体来说，Fair MP-Boost依据自适应学习的特征和观察采样概率，顺序抽取小批量观察和特征，被称为minipatches (MP)。我们通过结合损失函数或特征重要性分数来设计这些概率，以同时解决准确性和公平性问题。因此，Fair MP-Boost优先考虑重要且公平的特征以及具有挑战性的实例，从而选择最相关的小批量。

    arXiv:2404.01521v1 Announce Type: cross  Abstract: Ensemble methods, particularly boosting, have established themselves as highly effective and widely embraced machine learning techniques for tabular data. In this paper, we aim to leverage the robust predictive power of traditional boosting methods while enhancing fairness and interpretability. To achieve this, we develop Fair MP-Boost, a stochastic boosting scheme that balances fairness and accuracy by adaptively learning features and observations during training. Specifically, Fair MP-Boost sequentially samples small subsets of observations and features, termed minipatches (MP), according to adaptively learned feature and observation sampling probabilities. We devise these probabilities by combining loss functions, or by combining feature importance scores to address accuracy and fairness simultaneously. Hence, Fair MP-Boost prioritizes important and fair features along with challenging instances, to select the most relevant minipatc
    
[^93]: 一种用于无监督动作分割的临时一致不平衡最优传输方法

    Temporally Consistent Unbalanced Optimal Transport for Unsupervised Action Segmentation

    [https://arxiv.org/abs/2404.01518](https://arxiv.org/abs/2404.01518)

    提出了一种基于解决最优传输问题的动作分割方法，通过在Gromov-Wasserstein问题中编码时间一致性先验来实现从视频帧和动作类别之间的噪声成本中解码时间一致的分割。

    

    我们提出了一种针对长时间未修剪视频的动作分割任务的新方法，基于解决最优传输问题。通过将时间一致性先验编码到Gromov-Wasserstein问题中，我们能够从视频帧和动作类别之间的噪声关联/匹配成本矩阵中解码出一个时间一致的分割。与先前方法不同，我们的方法不需要知道视频的动作顺序来实现时间一致性。此外，我们的结果（融合）Gromov-Wasserstein问题可以在GPU上使用几次投影镜下降迭代高效求解。我们在无监督学习环境中展示了我们方法的有效性，其中我们的方法用于生成自训练的伪标签。我们在Breakfast、50-Salads、YouTube Instructions和Desktop Assembly数据集上评估了我们的分割方法和无监督学习流程，取得了最先进的结果。

    arXiv:2404.01518v1 Announce Type: cross  Abstract: We propose a novel approach to the action segmentation task for long, untrimmed videos, based on solving an optimal transport problem. By encoding a temporal consistency prior into a Gromov-Wasserstein problem, we are able to decode a temporally consistent segmentation from a noisy affinity/matching cost matrix between video frames and action classes. Unlike previous approaches, our method does not require knowing the action order for a video to attain temporal consistency. Furthermore, our resulting (fused) Gromov-Wasserstein problem can be efficiently solved on GPUs using a few iterations of projected mirror descent. We demonstrate the effectiveness of our method in an unsupervised learning setting, where our method is used to generate pseudo-labels for self-training. We evaluate our segmentation approach and unsupervised learning pipeline on the Breakfast, 50-Salads, YouTube Instructions and Desktop Assembly datasets, yielding state
    
[^94]: 使用个性化层解决联邦负载预测中的异质性问题

    Addressing Heterogeneity in Federated Load Forecasting with Personalization Layers

    [https://arxiv.org/abs/2404.01517](https://arxiv.org/abs/2404.01517)

    提出了在负载预测中使用个性化层的通用框架PL-FL，通过研究表明PL-FL在低通信带宽要求下优于FL和纯本地训练。

    

    智能电表的出现使得可以广泛收集用电数据来训练短期负载预测模型。为了应对隐私问题，提出了联邦学习（FL）作为训练的隐私保护方法，但随着客户数据的异质性增加，所训练模型的质量会下降。本文提出了在一个名为PL-FL的通用框架中使用个性化层进行负载预测。我们展示了PL-FL胜过FL和纯本地训练，同时还比FL需要更低的通信带宽。通过在来自NREL ComStock数据仓库的三个不同数据集上进行广泛的模拟完成了这一点。

    arXiv:2404.01517v1 Announce Type: new  Abstract: The advent of smart meters has enabled pervasive collection of energy consumption data for training short-term load forecasting models. In response to privacy concerns, federated learning (FL) has been proposed as a privacy-preserving approach for training, but the quality of trained models degrades as client data becomes heterogeneous. In this paper we propose the use of personalization layers for load forecasting in a general framework called PL-FL. We show that PL-FL outperforms FL and purely local training, while requiring lower communication bandwidth than FL. This is done through extensive simulations on three different datasets from the NREL ComStock repository.
    
[^95]: 图像网模型中的偏见能解释泛化吗？

    Can Biases in ImageNet Models Explain Generalization?

    [https://arxiv.org/abs/2404.01509](https://arxiv.org/abs/2404.01509)

    图像网模型的偏见是否能够解释模型的泛化问题，对此进行了大规模研究。

    

    深度学习方法面临的主要挑战之一是模型对来自训练分布长尾的稀有内部分布（ID）样本和训练分布之外（OOD）样本的强大泛化能力。对于图像分类，这体现在对扭曲图像的攻击、性能下降以及对概念（如草图）的泛化不足。目前对神经网络泛化的理解非常有限，但发现了一些区别模型与人类视觉的偏见，这些偏见可能导致这些限制。因此，已经尝试了多种不同成功程度的方法来减少这些训练中的偏见以改善泛化性能。我们在已建立的ResNet-50架构上进行大规模研究，在48个通过不同获取途径获得的ImageNet模型上进行了实验。

    arXiv:2404.01509v1 Announce Type: cross  Abstract: The robust generalization of models to rare, in-distribution (ID) samples drawn from the long tail of the training distribution and to out-of-training-distribution (OOD) samples is one of the major challenges of current deep learning methods. For image classification, this manifests in the existence of adversarial attacks, the performance drops on distorted images, and a lack of generalization to concepts such as sketches. The current understanding of generalization in neural networks is very limited, but some biases that differentiate models from human vision have been identified and might be causing these limitations. Consequently, several attempts with varying success have been made to reduce these biases during training to improve generalization. We take a step back and sanity-check these attempts. Fixing the architecture to the well-established ResNet-50, we perform a large-scale study on 48 ImageNet models obtained via different 
    
[^96]: MosquitoFusion：用深度学习实时检测蚊子、蚊群和繁殖地的多类数据集

    MosquitoFusion: A Multiclass Dataset for Real-Time Detection of Mosquitoes, Swarms, and Breeding Sites Using Deep Learning

    [https://arxiv.org/abs/2404.01501](https://arxiv.org/abs/2404.01501)

    该论文提出了一个整合方法，使用MosquitoFusion数据集和深度学习技术实现对蚊子、蚊群和繁殖地的实时检测，同时结合地理信息系统(GIS)进一步丰富了空间模式分析的深度。

    

    在本文中，我们提出了一种整合方法，使用我们的多类数据集（MosquitoFusion）中包含的1204张多样化图像以及利用最先进的技术，特别是计算机视觉，来自动化识别蚊子、蚊群和繁殖地的真实时间蚊子检测。在该数据集上训练的预训练YOLOv8模型达到了57.1%的平均精度（mAP@50），精确率为73.4%，召回率为50.5%。地理信息系统（GIS）的整合进一步丰富了我们分析的深度，提供了对空间模式的有价值见解。数据集和代码可在https://github.com/faiyazabdullah/MosquitoFusion获取。

    arXiv:2404.01501v1 Announce Type: cross  Abstract: In this paper, we present an integrated approach to real-time mosquito detection using our multiclass dataset (MosquitoFusion) containing 1204 diverse images and leverage cutting-edge technologies, specifically computer vision, to automate the identification of Mosquitoes, Swarms, and Breeding Sites. The pre-trained YOLOv8 model, trained on this dataset, achieved a mean Average Precision (mAP@50) of 57.1%, with precision at 73.4% and recall at 50.5%. The integration of Geographic Information Systems (GIS) further enriches the depth of our analysis, providing valuable insights into spatial patterns. The dataset and code are available at https://github.com/faiyazabdullah/MosquitoFusion.
    
[^97]: 可解释人工智能集成特征工程用于森林火灾预测

    Explainable AI Integrated Feature Engineering for Wildfire Prediction

    [https://arxiv.org/abs/2404.01487](https://arxiv.org/abs/2404.01487)

    本研究通过评估各种机器学习算法，发现XGBoost模型在森林火灾分类中具有更好的准确性和随机森林回归模型在预测火灾范围方面表现出色。同时，我们还开发了一种集成数值数据和图像信息的混合神经网络模型。

    

    森林火灾对预测提出了复杂的挑战，需要使用复杂的机器学习技术进行有效建模。在我们的研究中，我们对与预测森林火灾相关的分类和回归任务的各种机器学习算法进行了彻底评估。我们发现，对于分类不同类型或阶段的森林火灾，XGBoost模型在准确性和稳健性方面表现优异。与此同时，随机森林回归模型在预测受影响的森林火灾范围方面表现出色，同时在预测误差和解释方差方面都表现优秀。此外，我们开发了一种集成数值数据和图像信息的混合神经网络模型，用于同时进行分类和回归。为了更深入地了解这些模型的决策过程并识别关键的贡献特征，我们利用eX

    arXiv:2404.01487v1 Announce Type: new  Abstract: Wildfires present intricate challenges for prediction, necessitating the use of sophisticated machine learning techniques for effective modeling\cite{jain2020review}. In our research, we conducted a thorough assessment of various machine learning algorithms for both classification and regression tasks relevant to predicting wildfires. We found that for classifying different types or stages of wildfires, the XGBoost model outperformed others in terms of accuracy and robustness. Meanwhile, the Random Forest regression model showed superior results in predicting the extent of wildfire-affected areas, excelling in both prediction error and explained variance. Additionally, we developed a hybrid neural network model that integrates numerical data and image information for simultaneous classification and regression. To gain deeper insights into the decision-making processes of these models and identify key contributing features, we utilized eX
    
[^98]: QuAD: 基于查询的可解释的神经运动规划方法用于自动驾驶

    QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving

    [https://arxiv.org/abs/2404.01486](https://arxiv.org/abs/2404.01486)

    提出了一个新的自动驾驶神经运动规划框架，通过查询感兴趣的时空点的占据信息，避免了传统对象检测和密集占据栅格地图方法中的信息丢失和计算浪费。

    

    自动驾驶车辆必须了解其环境以确定适当的动作。传统自主系统依赖于对象检测来找到场景中的代理。然而，对象检测假设一组离散的对象，并丢失有关不确定性的信息，因此在预测这些代理未来行为时任何错误都会累积。与此相反，密集的占据栅格地图已被用于理解自由空间。然而，为整个场景预测网格是浪费的，因为只有某些时空区域是可到达的并且对自动驾驶车辆相关。我们提出了一个统一的、可解释的、高效的自主框架，摆脱了先感知、再预测，最后规划的级联模块的范式。相反，我们将规划者的重点转移到查询相关时空点的占据，限制计算在这些感兴趣的区域上。利用这种表示

    arXiv:2404.01486v1 Announce Type: cross  Abstract: A self-driving vehicle must understand its environment to determine the appropriate action. Traditional autonomy systems rely on object detection to find the agents in the scene. However, object detection assumes a discrete set of objects and loses information about uncertainty, so any errors compound when predicting the future behavior of those agents. Alternatively, dense occupancy grid maps have been utilized to understand free-space. However, predicting a grid for the entire scene is wasteful since only certain spatio-temporal regions are reachable and relevant to the self-driving vehicle. We present a unified, interpretable, and efficient autonomy framework that moves away from cascading modules that first perceive, then predict, and finally plan. Instead, we shift the paradigm to have the planner query occupancy at relevant spatio-temporal points, restricting the computation to those regions of interest. Exploiting this represent
    
[^99]: TraveLER：用于视频问答的多重LMM代理框架

    TraveLER: A Multi-LMM Agent Framework for Video Question-Answering

    [https://arxiv.org/abs/2404.01476](https://arxiv.org/abs/2404.01476)

    TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题

    

    最近，大型多模态模型（LMMs）在视频问答方面取得了重要进展，通过利用大规模、基于图像的预训练以零样本方式以帧为单位进行处理。虽然基于图像的视频方法展现了令人印象深刻的性能，但目前的局限是它们经常忽视了如何选择关键时间戳，并且无法在确定错误时间戳时进行调整。此外，它们无法提取与问题相关的细节，而是提供帧的一般描述。为了克服这一点，我们设计了一个多重LMM代理框架，它沿着视频进行移动，通过交互式提问的方式迭代地从关键帧收集相关信息，直到获得足够的信息来回答问题。具体来说，我们提出了TraveLER，这是一个可以制定“遍历”视频计划的模型，询问关于单个帧的问题以“定位”并存储关键信息

    arXiv:2404.01476v1 Announce Type: cross  Abstract: Recently, Large Multimodal Models (LMMs) have made significant progress in video question-answering using a frame-wise approach by leveraging large-scale, image-based pretraining in a zero-shot manner. While image-based methods for videos have shown impressive performance, a current limitation is that they often overlook how key timestamps are selected and cannot adjust when incorrect timestamps are identified. Moreover, they are unable to extract details relevant to the question, instead providing general descriptions of the frame. To overcome this, we design a multi-LMM agent framework that travels along the video, iteratively collecting relevant information from keyframes through interactive question-asking until there is sufficient information to answer the question. Specifically, we propose TraveLER, a model that can create a plan to "Traverse" through the video, ask questions about individual frames to "Locate" and store key info
    
[^100]: 大型语言模型是否是超人类化学家？

    Are large language models superhuman chemists?

    [https://arxiv.org/abs/2404.01475](https://arxiv.org/abs/2404.01475)

    介绍了一个自动化框架“ChemBench”，旨在评估最先进的大型语言模型（LLMs）在化学知识和推理能力方面与人类化学家专业知识的对比。

    

    大型语言模型（LLMs）因其处理人类语言并执行未经明确训练的任务的能力而引起了广泛关注。这对化学科学是相关的，因为化学面临着数据集小且多样的问题，这些数据集通常以文本形式呈现。 LLMs在解决这些问题方面表现出潜力，并且越来越多地被利用来预测化学性质，优化反应，甚至自主设计和进行实验。然而，我们对LLMs的化学推理能力仅有非常有限的系统性理解，这是改进模型和减轻潜在危害所必需的。在这里，我们介绍了“ChemBench”，这是一个自动化框架，旨在严格评估最先进的LLMs的化学知识和推理能力，以与人类化学家的专业知识相比较。

    arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce "ChemBench," an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a 
    
[^101]: TS-CausalNN: 从非线性非平稳时间序列数据中学习时间因果关系

    TS-CausalNN: Learning Temporal Causal Relations from Non-linear Non-stationary Time Series Data

    [https://arxiv.org/abs/2404.01466](https://arxiv.org/abs/2404.01466)

    TS-CausalNN提出了一种新的深度学习技术，可以同时发现时间序列数据中的同时发生和滞后的因果关系

    

    

    arXiv:2404.01466v1 Announce Type: new  Abstract: The growing availability and importance of time series data across various domains, including environmental science, epidemiology, and economics, has led to an increasing need for time-series causal discovery methods that can identify the intricate relationships in the non-stationary, non-linear, and often noisy real world data. However, the majority of current time series causal discovery methods assume stationarity and linear relations in data, making them infeasible for the task. Further, the recent deep learning-based methods rely on the traditional causal structure learning approaches making them computationally expensive. In this paper, we propose a Time-Series Causal Neural Network (TS-CausalNN) - a deep learning technique to discover contemporaneous and lagged causal relations simultaneously. Our proposed architecture comprises (i) convolutional blocks comprising parallel custom causal layers, (ii) acyclicity constraint, and (iii
    
[^102]: 4D医学图像的无监督插值方法：无需任何中间帧

    Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images

    [https://arxiv.org/abs/2404.01464](https://arxiv.org/abs/2404.01464)

    该论文提出了一种简单而有效的无监督三维插值框架UVI-Net，能够在4D医学图像中实现无需中间帧的时间插值，取得了显着的性能改善。

    

    4D医学图像在临床实践中至关重要，能够捕捉动态变化并监测长期疾病进展。然而，获取4D医学图像会面临挑战，如辐射暴露和成像时间，需要在实现高时间分辨率和减少不良影响之间取得平衡。在这种情况下，数据获取不仅具有挑战性，增加每个数据集的帧率也很困难。为解决这一挑战，本文提出了一种简单而有效的无监督三维插值框架，UVI-Net。该框架促进了时间插值而无需任何中间帧，与大多数现有无监督方法不同。对基准数据集的实验表明，在各种评估指标上都取得了显着进展。

    arXiv:2404.01464v1 Announce Type: cross  Abstract: 4D medical images, which represent 3D images with temporal information, are crucial in clinical practice for capturing dynamic changes and monitoring long-term disease progression. However, acquiring 4D medical images poses challenges due to factors such as radiation exposure and imaging duration, necessitating a balance between achieving high temporal resolution and minimizing adverse effects. Given these circumstances, not only is data acquisition challenging, but increasing the frame rate for each dataset also proves difficult. To address this challenge, this paper proposes a simple yet effective Unsupervised Volumetric Interpolation framework, UVI-Net. This framework facilitates temporal interpolation without the need for any intermediate frames, distinguishing it from the majority of other existing unsupervised methods. Experiments on benchmark datasets demonstrate significant improvements across diverse evaluation metrics compare
    
[^103]: OpenChemIE：用于化学文献信息提取的工具包

    OpenChemIE: An Information Extraction Toolkit For Chemistry Literature

    [https://arxiv.org/abs/2404.01462](https://arxiv.org/abs/2404.01462)

    OpenChemIE提出了一种用于从化学文献中提取反应数据的工具包，通过整合文本、表格和图像信息以及使用专门神经模型和算法，实现了在文档级别的反应数据提取。

    

    arXiv:2404.01462v1 公告类型：交叉  摘要：从化学文献中提取信息对于构建数据驱动化学的最新反应数据库至关重要。完整的信息提取需要结合文本、表格和图像中的信息，而以往的工作主要研究从单一方式提取反应。在本文中，我们提出了OpenChemIE来解决这一复杂挑战，实现在文档级别提取反应数据。OpenChemIE分两步解决问题：从各个方式中提取相关信息，然后整合结果得到最终的反应列表。对于第一步，我们采用专门的神经模型，每个模型处理化学信息提取的特定任务，比如从文本或图像中解析分子或反应。然后我们使用化学相关的算法整合这些模块的信息，实现精细化反应提取。

    arXiv:2404.01462v1 Announce Type: cross  Abstract: Information extraction from chemistry literature is vital for constructing up-to-date reaction databases for data-driven chemistry. Complete extraction requires combining information across text, tables, and figures, whereas prior work has mainly investigated extracting reactions from single modalities. In this paper, we present OpenChemIE to address this complex challenge and enable the extraction of reaction data at the document level. OpenChemIE approaches the problem in two steps: extracting relevant information from individual modalities and then integrating the results to obtain a final list of reactions. For the first step, we employ specialized neural models that each address a specific task for chemistry information extraction, such as parsing molecules or reactions from text or figures. We then integrate the information from these modules using chemistry-informed algorithms, allowing for the extraction of fine-grained reactio
    
[^104]: 游戏理论深度强化学习在地理分布式数据中心中最小化碳排放和能源成本的AI推断负载

    Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers

    [https://arxiv.org/abs/2404.01459](https://arxiv.org/abs/2404.01459)

    结合博弈论和深度强化学习优化地理分布式数据中心中AI推断工作负载的分布，以降低碳排放和运营成本。

    

    数据中心由于人工智能（AI）工作负载的增加而消耗更多能源，这对环境造成负面影响并提高运营成本。本文提出了一种独特的方法，将博弈论（GT）和深度强化学习（DRL）相结合，优化地理分布式数据中心中AI推断工作负载的分布，以减少碳排放和云运营（能源+数据传输）成本。

    arXiv:2404.01459v1 Announce Type: cross  Abstract: Data centers are increasingly using more energy due to the rise in Artificial Intelligence (AI) workloads, which negatively impacts the environment and raises operational costs. Reducing operating expenses and carbon emissions while maintaining performance in data centers is a challenging problem. This work introduces a unique approach combining Game Theory (GT) and Deep Reinforcement Learning (DRL) for optimizing the distribution of AI inference workloads in geo-distributed data centers to reduce carbon emissions and cloud operating (energy + data transfer) costs. The proposed technique integrates the principles of non-cooperative Game Theory into a DRL framework, enabling data centers to make intelligent decisions regarding workload allocation while considering the heterogeneity of hardware resources, the dynamic nature of electricity prices, inter-data center data transfer costs, and carbon footprints. We conducted extensive experim
    
[^105]: 有限角度(CBCT)重建的先验频率引导扩散模型

    Prior Frequency Guided Diffusion Model for Limited Angle (LA)-CBCT Reconstruction

    [https://arxiv.org/abs/2404.01448](https://arxiv.org/abs/2404.01448)

    本研究提出了一种基于扩散模型的先验频率引导扩散模型（PFGDM）框架，用于稳健且保持结构的有限角度CBCT重建。

    

    锥束计算机体层摄影（CBCT）广泛应用于图像引导放疗。从有限角度采集（LA-CBCT）重建CBCT对于提高成像效率、减少剂量以及更好的机械间隙清除至关重要。然而，LA-CBCT重建受到严重欠采样伪影的困扰，使其成为高度不适定的逆问题。扩散模型可以通过学习数据分布逆转数据加噪过程来生成数据/图像；并且可以作为LA-CBCT重建中的去噪器/正则化器。在这项研究中，我们为LA-CBCT重建开发了基于扩散模型的框架，即先验频率引导扩散模型（PFGDM），用于稳健且保持结构的LA-CBCT重建。PFGDM使用条件扩散模型作为LA-CBCT重建的正则化器，条件是基于从患者特定先前CT扫描中提取的高频信息，这提供了强大的

    arXiv:2404.01448v1 Announce Type: cross  Abstract: Cone-beam computed tomography (CBCT) is widely used in image-guided radiotherapy. Reconstructing CBCTs from limited-angle acquisitions (LA-CBCT) is highly desired for improved imaging efficiency, dose reduction, and better mechanical clearance. LA-CBCT reconstruction, however, suffers from severe under-sampling artifacts, making it a highly ill-posed inverse problem. Diffusion models can generate data/images by reversing a data-noising process through learned data distributions; and can be incorporated as a denoiser/regularizer in LA-CBCT reconstruction. In this study, we developed a diffusion model-based framework, prior frequency-guided diffusion model (PFGDM), for robust and structure-preserving LA-CBCT reconstruction. PFGDM uses a conditioned diffusion model as a regularizer for LA-CBCT reconstruction, and the condition is based on high-frequency information extracted from patient-specific prior CT scans which provides a strong ana
    
[^106]: 从描述中无监督地进行情感分析，创建表情符号词库

    Creating emoji lexica from unsupervised sentiment analysis of their descriptions

    [https://arxiv.org/abs/2404.01439](https://arxiv.org/abs/2404.01439)

    该论文提出了一种从在线文本消息中预测表情符号所表达情感的新方法，无需人工标注数据，节省了宝贵时间。

    

    线上媒体，如博客和社交网络网站，生成了大量非结构化数据供分析个人和组织的观点和情感之用。传统的自然语言处理方法已经不能很好地量化这些观点的极性度量，因此需要新颖的方法。迄今为止，表情符号所表达的情感得到的关注较少。然而，过去四年间，符号的使用量激增。如今，Twitter中每天会被输入大约两百亿个符号，并且每个新的Unicode版本都会增加新的表情符号，使得它们对情感分析任务越来越重要。这促使我们提出了一种新颖的方法来预测在线文本消息（如推文）中表情符号表达的情感，该方法不需要人工手动注释数据，以此节省宝贵的时间用于其他分析任务。为此，我们自动构建了一种新颖的表情符号情感词库。

    arXiv:2404.01439v1 Announce Type: cross  Abstract: Online media, such as blogs and social networking sites, generate massive volumes of unstructured data of great interest to analyze the opinions and sentiments of individuals and organizations. Novel approaches beyond Natural Language Processing are necessary to quantify these opinions with polarity metrics. So far, the sentiment expressed by emojis has received little attention. The use of symbols, however, has boomed in the past four years. About twenty billion are typed in Twitter nowadays, and new emojis keep appearing in each new Unicode version, making them increasingly relevant to sentiment analysis tasks. This has motivated us to propose a novel approach to predict the sentiments expressed by emojis in online textual messages, such as tweets, that does not require human effort to manually annotate data and saves valuable time for other analysis tasks. For this purpose, we automatically constructed a novel emoji sentiment lexico
    
[^107]: RMSProp和Adam在具有仿射噪声方差的广义光滑非凸优化中的收敛性保证

    Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance

    [https://arxiv.org/abs/2404.01436](https://arxiv.org/abs/2404.01436)

    本文提出了对于RMSProp和Adam在非凸优化中的紧致收敛性分析，首次展示了在最宽松的假设下的收敛性结果，并展示了RMSProp和Adam的迭代复杂度分别为$\mathcal O(\epsilon^{-4})$。

    

    本文在坐标级别广义光滑性和仿射噪声方差的最宽松假设下，为非凸优化中的RMSProp和Adam提供了首个收敛性分析。首先分析了RMSProp，它是一种具有自适应学习率但没有一阶动量的Adam的特例。具体地，为了解决自适应更新、无界梯度估计和Lipschitz常数之间的依赖挑战，我们证明了下降引理中的一阶项收敛，并且其分母由梯度范数的函数上界限制。基于这一结果，我们展示了使用适当的超参数的RMSProp收敛到一个$\epsilon$-稳定点，其迭代复杂度为$\mathcal O(\epsilon^{-4})$。然后，将我们的分析推广到Adam，额外的挑战是由于梯度与一阶动量之间的不匹配。我们提出了一个新的上界限制

    arXiv:2404.01436v1 Announce Type: cross  Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on
    
[^108]: 降低LLMs中位置偏差的面向位置的参数高效微调方法

    Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs

    [https://arxiv.org/abs/2404.01430](https://arxiv.org/abs/2404.01430)

    本研究发现LLMs的位置偏差主要源于不同模型的固有位置偏好，并提出了一种面向位置的参数高效微调方法来解决这一问题。

    

    大型语言模型（LLMs）的最新进展增强了它们处理长输入上下文的能力。对于涉及从外部数据存储库检索知识的任务，这一进展尤为关键，因为可能涉及长输入。然而，最近的研究显示LLMs存在位置偏差，表明其性能会根据输入序列中有用信息的位置而变化。本研究进行了大量实验，以调查位置偏差的根本原因。我们的发现表明，LLMs的位置偏差的主要贡献者源于不同模型的固有位置偏好。我们证明，仅仅采用基于提示的解决方案无法克服位置偏好。为了解决预训练LLMs的位置偏差问题，我们开发了一种面向位置的参数高效微调（PAPEFT）方法，该方法包含一个数据增广。

    arXiv:2404.01430v1 Announce Type: cross  Abstract: Recent advances in large language models (LLMs) have enhanced their ability to process long input contexts. This development is particularly crucial for tasks that involve retrieving knowledge from an external datastore, which can result in long inputs. However, recent studies show a positional bias in LLMs, demonstrating varying performance depending on the location of useful information within the input sequence. In this study, we conduct extensive experiments to investigate the root causes of positional bias. Our findings indicate that the primary contributor to LLM positional bias stems from the inherent positional preferences of different models. We demonstrate that merely employing prompt-based solutions is inadequate for overcoming the positional preferences. To address this positional bias issue of a pre-trained LLM, we developed a Position-Aware Parameter Efficient Fine-Tuning (PAPEFT) approach which is composed of a data augm
    
[^109]: 模型崩溃是否不可避免？通过累积真实和合成数据打破递归的诅咒

    Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data

    [https://arxiv.org/abs/2404.01413](https://arxiv.org/abs/2404.01413)

    本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。

    

    随着生成模型的激增，以及在网络规模数据上的预训练，一个及时的问题浮出水面：当这些模型被训练在它们自己生成的输出上时会发生什么？最近对模型数据反馈循环的研究发现，这样的循环可能导致模型崩溃，即性能随着每次模型拟合迭代逐渐下降，直到最新的模型变得无用。然而，最近几篇研究模型崩溃的论文都假设随着时间推移，新数据会取代旧数据，而不是假设数据会随时间累积。在本文中，我们比较了这两种情况，并表明积累数据可以防止模型崩溃。我们首先研究了一个解析可处理的设置，其中一系列线性模型拟合到先前模型的预测。先前的工作表明，如果数据被替换，测试误差会随着模型拟合迭代次数线性增加；我们扩展了这个研究探讨了数据逐渐累积的情况下会发生什么。

    arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
    
[^110]: 大并非总是更好：潜在扩散模型的规模特性

    Bigger is not Always Better: Scaling Properties of Latent Diffusion Models

    [https://arxiv.org/abs/2404.01367](https://arxiv.org/abs/2404.01367)

    在研究潜在扩散模型的规模特性时发现，较小的模型在相同推理预算下往往比较大的模型更有效地生成高质量结果。

    

    我们研究了潜在扩散模型（LDMs）的规模特性，重点关注它们的采样效率。尽管改进的网络架构和推理算法已经证明可以有效提升扩散模型的采样效率，但模型大小的作用——采样效率的关键决定因素——尚未受到彻底的审查。通过对已建立的文本到图像扩散模型的实证分析，我们进行了深入研究，探讨了模型大小如何影响在不同采样步骤下的采样效率。我们的发现揭示了一个令人惊讶的趋势：在给定推理预算下运行时，较小的模型经常胜过其较大的等价物在生成高质量结果上。此外，我们扩展了研究，通过应用各种扩散采样器，探索不同的下游任务，评估后精馏模型，以及进行比较，来展示这些发现的普适性。

    arXiv:2404.01367v1 Announce Type: cross  Abstract: We study the scaling properties of latent diffusion models (LDMs) with an emphasis on their sampling efficiency. While improved network architecture and inference algorithms have shown to effectively boost sampling efficiency of diffusion models, the role of model size -- a critical determinant of sampling efficiency -- has not been thoroughly examined. Through empirical analysis of established text-to-image diffusion models, we conduct an in-depth investigation into how model size influences sampling efficiency across varying sampling steps. Our findings unveil a surprising trend: when operating under a given inference budget, smaller models frequently outperform their larger equivalents in generating high-quality results. Moreover, we extend our study to demonstrate the generalizability of the these findings by applying various diffusion samplers, exploring diverse downstream tasks, evaluating post-distilled models, as well as compar
    
[^111]: 基于提示的混合专家模型用于高效生成LLM

    Prompt-prompted Mixture of Experts for Efficient LLM Generation

    [https://arxiv.org/abs/2404.01365](https://arxiv.org/abs/2404.01365)

    提出了一种名为GRIFFIN的训练-free MoE，能够在各种LLM模型中选择唯一的FF专家以实现高效生成。

    

    随着基于transformer的大规模语言模型（LLMs）的发展，由于其出色的实用性，它们已被应用于许多领域，但在部署时存在相当大的计算成本。幸运的是，一些方法，如修剪或构建混合专家（MoE），旨在利用transformer前馈（FF）块中的稀疏性，以提高速度并降低内存需求。但是，这些技术在实践中可能非常昂贵和不灵活，因为它们通常需要训练或仅限于特定类型的架构。为了解决这个问题，我们引入了GRIFFIN，一种新颖的无需训练的MoE，它在序列级别为不同非ReLU激活函数的大量LLMs选择独特的FF专家以实现高效生成。这是可能的，因为我们关键观察到，许多经过训练的LLMs在序列中自然产生高度结构化的FF激活模式，这

    arXiv:2404.01365v1 Announce Type: cross  Abstract: With the development of transformer-based large language models (LLMs), they have been applied to many fields due to their remarkable utility, but this comes at a considerable computational cost at deployment. Fortunately, some methods such as pruning or constructing a mixture of experts (MoE) aim at exploiting sparsity in transformer feedforward (FF) blocks to gain boosts in speed and reduction in memory requirements. However, these techniques can be very costly and inflexible in practice, as they often require training or are restricted to specific types of architectures. To address this, we introduce GRIFFIN, a novel training-free MoE that selects unique FF experts at the sequence level for efficient generation across a plethora of LLMs with different non-ReLU activation functions. This is possible due to a critical observation that many trained LLMs naturally produce highly structured FF activation patterns within a sequence, which
    
[^112]: 通过转移熵在深度学习中的信息平面分析可视化

    Information Plane Analysis Visualization in Deep Learning via Transfer Entropy

    [https://arxiv.org/abs/2404.01364](https://arxiv.org/abs/2404.01364)

    通过转移熵进行信息平面分析可视化揭示了信息瓶颈方法中压缩和信息保留的权衡，以及信息论压缩与泛化之间存在的关系。

    

    在前馈网络中，可以利用转移熵（TE）来衡量一层对另一层的影响，通过量化它们之间在训练期间的信息传递。根据信息瓶颈原理，神经模型的内部表示应尽可能压缩输入数据，同时仍保留足够的关于输出的信息。信息平面分析是一种可视化技术，用于通过绘制输入数据中的信息量与压缩表示之间的关系，来理解信息瓶颈方法中压缩和信息保留之间的权衡。声称信息论压缩和泛化之间存在因果联系，通过互信息来衡量是可信的，但不同研究的结果存在冲突。TE可以捕捉时间关系，与互信息相比，存在差异。

    arXiv:2404.01364v1 Announce Type: cross  Abstract: In a feedforward network, Transfer Entropy (TE) can be used to measure the influence that one layer has on another by quantifying the information transfer between them during training. According to the Information Bottleneck principle, a neural model's internal representation should compress the input data as much as possible while still retaining sufficient information about the output. Information Plane analysis is a visualization technique used to understand the trade-off between compression and information preservation in the context of the Information Bottleneck method by plotting the amount of information in the input data against the compressed representation. The claim that there is a causal link between information-theoretic compression and generalization, measured by mutual information, is plausible, but results from different studies are conflicting. In contrast to mutual information, TE can capture temporal relationships be
    
[^113]: LLM Attributor: 交互式可视化归因用于LLM生成

    LLM Attributor: Interactive Visual Attribution for LLM Generation

    [https://arxiv.org/abs/2404.01361](https://arxiv.org/abs/2404.01361)

    LLM Attributor是一个Python库，提供了交互式可视化方式用于将LLM的文本生成结果归因到训练数据点，帮助用户检查模型行为、增强可信度，并与用户提供的文本进行比较。

    

    虽然大型语言模型（LLMs）显示出在各个领域生成令人信服的文本的能力，但对其潜在风险的担忧凸显了了解文本生成背后原因的重要性。我们提出了LLM Attributor，一个提供LLM文本生成训练数据归因交互可视化的Python库。我们的库为快速将LLM的文本生成归因到训练数据点提供了一种新方式，以检查模型行为、增强其可信度，并将模型生成的文本与用户提供的文本进行比较。我们描述了工具的视觉和交互设计，并强调LLaMA2模型的使用场景，该模型通过两个不同数据集进行微调：关于最近灾难和金融相关问答对的在线文章。由于LLM Attributor对计算笔记本的广泛支持，用户可以轻松将其整合到他们的工作流程中。

    arXiv:2404.01361v1 Announce Type: cross  Abstract: While large language models (LLMs) have shown remarkable capability to generate convincing text across diverse domains, concerns around its potential risks have highlighted the importance of understanding the rationale behind text generation. We present LLM Attributor, a Python library that provides interactive visualizations for training data attribution of an LLM's text generation. Our library offers a new way to quickly attribute an LLM's text generation to training data points to inspect model behaviors, enhance its trustworthiness, and compare model-generated text with user-provided text. We describe the visual and interactive design of our tool and highlight usage scenarios for LLaMA2 models fine-tuned with two different datasets: online articles about recent disasters and finance-related question-answer pairs. Thanks to LLM Attributor's broad support for computational notebooks, users can easily integrate it into their workflow 
    
[^114]: 利用数据和物理学进行深度学习相位恢复

    Harnessing Data and Physics for Deep Learning Phase Recovery

    [https://arxiv.org/abs/2404.01360](https://arxiv.org/abs/2404.01360)

    本论文全面比较了数据驱动和物理驱动两种深度学习相位恢复策略，在时间消耗、准确性、泛化能力、适应病态问题和先验能力等方面的差异。

    

    相位恢复是从光强度测量中计算光波的相位，对于各种应用非常重要，例如相干衍射成像、自适应光学和生物医学成像。深度学习在解决相位恢复问题方面被证明非常有效。两种主要的深度学习相位恢复策略分别为数据驱动（DD）与监督学习模式以及物理驱动（PD）与自监督学习模式。DD和PD以不同方式实现相同目标，并缺乏必要的研究来揭示它们的相似性和差异。因此，在本文中，我们全面比较了这两种深度学习相位恢复策略在时间消耗、准确性、泛化能力、适应病态问题和先验能力方面的差异。

    arXiv:2404.01360v1 Announce Type: cross  Abstract: Phase recovery, calculating the phase of a light wave from its intensity measurements, is essential for various applications, such as coherent diffraction imaging, adaptive optics, and biomedical imaging. It enables the reconstruction of an object's refractive index distribution or topography as well as the correction of imaging system aberrations. In recent years, deep learning has been proven to be highly effective in addressing phase recovery problems. Two main deep learning phase recovery strategies are data-driven (DD) with supervised learning mode and physics-driven (PD) with self-supervised learning mode. DD and PD achieve the same goal in different ways and lack the necessary study to reveal similarities and differences. Therefore, in this paper, we comprehensively compare these two deep learning phase recovery strategies in terms of time consumption, accuracy, generalization ability, ill-posedness adaptability, and prior capac
    
[^115]: 利用人工智能和社交媒体分析发现GLP-1受体激动剂的不良副作用

    Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists

    [https://arxiv.org/abs/2404.01358](https://arxiv.org/abs/2404.01358)

    通过利用人工智能驱动的社交媒体分析，我们开发了一种数字健康方法，成功检测出与GLP-1受体激动剂相关的21种潜在不良副作用，包括易怒和麻木感，从而革新了对新部署药物未报告ASEs的检测。

    

    药物的不良副作用（ASEs）在FDA批准后被发现，对患者安全构成威胁。为了及时发现被忽视的ASEs，我们开发了一种数字健康方法，能够分析来自社交媒体、已发表的临床研究、制造商报告和ChatGPT等大量公开数据。我们发现了与肝素样肽1受体激动剂（GLP-1 RA）相关的ASEs，这一市场预计到2030年将呈指数增长至1335亿美元。利用命名实体识别（NER）模型，我们的方法成功检测出FDA批准时被忽视的21种潜在ASEs，包括易怒和麻木感。我们的数据分析方法彻底改变了对新部署药物相关未报告的ASEs的检测，利用前沿的人工智能驱动社交媒体分析。它可以通过释放社交媒体的力量来支持监管机构和制造商在市场上增加新药的安全性。

    arXiv:2404.01358v1 Announce Type: cross  Abstract: Adverse side effects (ASEs) of drugs, revealed after FDA approval, pose a threat to patient safety. To promptly detect overlooked ASEs, we developed a digital health methodology capable of analyzing massive public data from social media, published clinical research, manufacturers' reports, and ChatGPT. We uncovered ASEs associated with the glucagon-like peptide 1 receptor agonists (GLP-1 RA), a market expected to grow exponentially to $133.5 billion USD by 2030. Using a Named Entity Recognition (NER) model, our method successfully detected 21 potential ASEs overlooked upon FDA approval, including irritability and numbness. Our data-analytic approach revolutionizes the detection of unreported ASEs associated with newly deployed drugs, leveraging cutting-edge AI-driven social media analytics. It can increase the safety of new drugs in the marketplace by unlocking the power of social media to support regulators and manufacturers in the ra
    
[^116]: 输入扰动对鲁棒准确公平性的双刃剑

    The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness

    [https://arxiv.org/abs/2404.01356](https://arxiv.org/abs/2404.01356)

    该论文研究了深度神经网络对敌对输入扰动的敏感性，提出了新的鲁棒准确公平性定义，并介绍了一种敌对攻击方法和相应的解决方案。

    

    深度神经网络(DNNs)被认为对敌对输入扰动敏感，导致预测的准确性或个体公平性降低。为了共同表征预测准确性和个体公平性对敌对扰动的敏感性，我们引入了一个名为鲁棒准确公平性的新定义。鲁棒准确公平性要求当实例及其相似对应物受到输入扰动时，预测与地面事实一致。我们提出一种敌对攻击方法RAFair，以暴露DNN中的虚假或偏见敌对缺陷，这些缺陷会欺骗准确性或损害个体公平性。然后，我们展示这样的敌对实例可以通过精心设计的良性扰动有效地解决，从而使它们的预测准确而公平。我们的工作探讨了输入对准确公平性的双刃剑。

    arXiv:2404.01356v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) are known to be sensitive to adversarial input perturbations, leading to a reduction in either prediction accuracy or individual fairness. To jointly characterize the susceptibility of prediction accuracy and individual fairness to adversarial perturbations, we introduce a novel robustness definition termed robust accurate fairness. Informally, robust accurate fairness requires that predictions for an instance and its similar counterparts consistently align with the ground truth when subjected to input perturbations. We propose an adversarial attack approach dubbed RAFair to expose false or biased adversarial defects in DNN, which either deceive accuracy or compromise individual fairness. Then, we show that such adversarial instances can be effectively addressed by carefully designed benign perturbations, correcting their predictions to be accurate and fair. Our work explores the double-edged sword of input 
    
[^117]: 用于边缘应用的LLM高效提取方法

    Efficiently Distilling LLMs for Edge Applications

    [https://arxiv.org/abs/2404.01353](https://arxiv.org/abs/2404.01353)

    提出了一种名为MLFS的新方法，用于高效参数的超网络训练，可以获得适用于商业边缘应用的高质量编码器模型，并有效地减少训练时间。

    

    在工业应用中，LLMs的超网络训练具有很大的重要性，因为它赋予了以固定成本产生不同大小/延迟模型的能力。我们提出了一种名为MLFS的新方法，用于高效参数的超网络训练。我们展示了可以获得适用于商业边缘应用的高质量编码器模型，并且虽然仅解码器模型对压缩具有相当的抵抗力，但可以有效地对解码器进行切片以大幅减少训练时间。

    arXiv:2404.01353v1 Announce Type: cross  Abstract: Supernet training of LLMs is of great interest in industrial applications as it confers the ability to produce a palette of smaller models at constant cost, regardless of the number of models (of different size / latency) produced. We propose a new method called Multistage Low-rank Fine-tuning of Super-transformers (MLFS) for parameter-efficient supernet training. We show that it is possible to obtain high-quality encoder models that are suitable for commercial edge applications, and that while decoder-only models are resistant to a comparable degree of compression, decoders can be effectively sliced for a significant reduction in training time.
    
[^118]: AETTA: 无标签准确性估计用于测试时适应

    AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation

    [https://arxiv.org/abs/2404.01351](https://arxiv.org/abs/2404.01351)

    提出了AETTA，一种用于测试时适应的无标签准确性估计算法，通过预测不一致性来改进准确性估计并在适应失败情况下展现更高的准确性估计。

    

    测试时适应（TTA）已经成为一种可行的解决方案，利用无标签测试数据来使预训练模型适应领域偏移。然而，TTA面临着适应失败的挑战，因为在动态场景中它依赖于对未知测试样本的盲目适应。传统的用于评估检测性能的方法在TTA背景下受到限制，因为它们对于无标签数据或重新训练模型有着不切实际的假设。为了解决这个问题，我们提出了AETTA，一个用于TTA的无标签准确性估计算法。我们提出了预测不一致性作为准确性估计，通过比较目标模型预测和dropout推断来计算。然后，我们改进了预测不一致性以扩展AETTA在适应失败下的适用性。我们对四个基线和六种TTA方法进行了广泛评估，结果显示AETTA相比于其他方法平均提高了19.8%的准确性估计。

    arXiv:2404.01351v1 Announce Type: cross  Abstract: Test-time adaptation (TTA) has emerged as a viable solution to adapt pre-trained models to domain shifts using unlabeled test data. However, TTA faces challenges of adaptation failures due to its reliance on blind adaptation to unknown test samples in dynamic scenarios. Traditional methods for out-of-distribution performance estimation are limited by unrealistic assumptions in the TTA context, such as requiring labeled data or re-training models. To address this issue, we propose AETTA, a label-free accuracy estimation algorithm for TTA. We propose the prediction disagreement as the accuracy estimate, calculated by comparing the target model prediction with dropout inferences. We then improve the prediction disagreement to extend the applicability of AETTA under adaptation failures. Our extensive evaluation with four baselines and six TTA methods demonstrates that AETTA shows an average of 19.8%p more accurate estimation compared with 
    
[^119]: 利用双向门控循环单元和深度学习技术增强孟加拉虚假新闻检测

    Enhancing Bangla Fake News Detection Using Bidirectional Gated Recurrent Units and Deep Learning Techniques

    [https://arxiv.org/abs/2404.01345](https://arxiv.org/abs/2404.01345)

    使用深度学习技术中的双向门控循环单元，在孟加拉语中识别虚假新闻，准确率达到99.16%

    

    虚假新闻的兴起使得需要有效的检测方法变得越发重要，其中包括非英语语言。该研究旨在解决孟加拉语这种被认为不太重要的语言所面临的挑战。为此，提出了一个包含约50,000条新闻项目的完整数据集。在这个数据集上测试了几种深度学习模型，包括双向门控循环单元（GRU）、长短期记忆（LSTM）、一维卷积神经网络（CNN）和混合架构。对于这项研究，我们评估了利用一系列有用指标的模型的有效性，包括召回率、精确率、F1得分和准确度。通过使用一个大型应用程序来完成这项工作。我们进行了全面试验，展示了这些模型在识别孟加拉语中的虚假新闻方面的有效性，其中双向GRU模型的准确率达到了惊人的99.16%。我们的分析突出了这些模型在孟加拉语中识别虚假新闻的重要性

    arXiv:2404.01345v1 Announce Type: new  Abstract: The rise of fake news has made the need for effective detection methods, including in languages other than English, increasingly important. The study aims to address the challenges of Bangla which is considered a less important language. To this end, a complete dataset containing about 50,000 news items is proposed. Several deep learning models have been tested on this dataset, including the bidirectional gated recurrent unit (GRU), the long short-term memory (LSTM), the 1D convolutional neural network (CNN), and hybrid architectures. For this research, we assessed the efficacy of the model utilizing a range of useful measures, including recall, precision, F1 score, and accuracy. This was done by employing a big application. We carry out comprehensive trials to show the effectiveness of these models in identifying bogus news in Bangla, with the Bidirectional GRU model having a stunning accuracy of 99.16%. Our analysis highlights the impo
    
[^120]: 块对角引导的DBSCAN聚类

    Block-Diagonal Guided DBSCAN Clustering

    [https://arxiv.org/abs/2404.01341](https://arxiv.org/abs/2404.01341)

    该研究提出了一种改进版本的DBSCAN，利用相似性图的块对角属性引导聚类过程，通过构建块对角图并进行聚类排序，易于确定聚类结构。

    

    集群分析在数据库挖掘中起着至关重要的作用，而在这一领域中最广泛使用的算法之一是DBSCAN。然而，DBSCAN存在一些局限性，例如难以处理高维大规模数据、对输入参数敏感以及在产生聚类结果时缺乏稳健性。本文引入了一种改进版本的DBSCAN，利用了相似性图的块对角属性来引导DBSCAN的聚类过程。其关键思想是构建一个图，衡量高维大规模数据点之间的相似性，并有可能通过未知置换转换为块对角形式，随后通过一个聚类排序过程来生成期望的置换。聚类结构可以通过识别置换后图中的对角块来轻松确定。我们提出了一种基于梯度下降的方法来解决这个问题。

    arXiv:2404.01341v1 Announce Type: cross  Abstract: Cluster analysis plays a crucial role in database mining, and one of the most widely used algorithms in this field is DBSCAN. However, DBSCAN has several limitations, such as difficulty in handling high-dimensional large-scale data, sensitivity to input parameters, and lack of robustness in producing clustering results. This paper introduces an improved version of DBSCAN that leverages the block-diagonal property of the similarity graph to guide the clustering procedure of DBSCAN. The key idea is to construct a graph that measures the similarity between high-dimensional large-scale data points and has the potential to be transformed into a block-diagonal form through an unknown permutation, followed by a cluster-ordering procedure to generate the desired permutation. The clustering structure can be easily determined by identifying the diagonal blocks in the permuted graph. We propose a gradient descent-based method to solve the propose
    
[^121]: 从相似到优越：时间序列预测的通道聚类

    From Similarity to Superiority: Channel Clustering for Time Series Forecasting

    [https://arxiv.org/abs/2404.01340](https://arxiv.org/abs/2404.01340)

    通过对通道进行聚类，实现了一种新颖的通道策略，有效平衡了个体通道处理和通道之间必要交互作用，从而提高了时间序列预测性能。

    

    时间序列预测在最近几十年吸引了很多关注。先前的研究表明，独立通道策略通过单独处理不同通道来提高预测性能，但在未知实例上导致了差劲的泛化，并忽略了通道之间潜在的必要交互作用。相反，依赖通道策略将所有通道混合在一起，甚至包含无关紧要和随意的信息，然而这会导致过度平滑的问题并限制了预测的准确性。目前缺乏一种能够有效平衡个体通道处理以提高预测性能而又不忽视通道之间必要交互作用的通道策略。受到我们观察到的时间序列模型练习提高对混合通道的结果与一对通道之间本质相似性之间的关联的启发，我们开发了一种新颖且适应性的方法

    arXiv:2404.01340v1 Announce Type: cross  Abstract: Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adapt
    
[^122]: 通过Latent Dirichlet Allocation主题建模自动检测财经新闻中的相关信息、预测和预测

    Automatic detection of relevant information, predictions and forecasts in financial news through topic modelling with Latent Dirichlet Allocation

    [https://arxiv.org/abs/2404.01338](https://arxiv.org/abs/2404.01338)

    该研究提出了一种新颖的自然语言处理系统，通过Latent Dirichlet Allocation (LDA)进行相关的主题建模，帮助投资者从非结构化文本源中检测财经事件中的相关信息、预测和预测

    

    arXiv:2404.01338v1通告类型:新摘要:金融新闻是一种非结构化的信息源，可以开采以从中提取知识，用于市场筛选应用。从持续的金融新闻流中手动提取相关信息是繁琐的，超出了许多投资者的技能范围，他们最多只能关注几个来源和作者。因此，我们专注于对金融新闻的分析，以识别相关文本，并在该文本中进行预测和预测。我们提出了一种新颖的自然语言处理（NLP）系统，帮助投资者通过考虑话语层面上的相关性和时态性，从非结构化文本源中检测相关的财经事件。首先，我们将文本分割以将相关文本归为一组。其次，我们应用共指解析来发现段落内部的依赖关系。最后，我们利用Latent Dirichlet Allocation (LDA)进行相关主题建模。

    arXiv:2404.01338v1 Announce Type: new  Abstract: Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing (NLP) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation (LDA) to separ
    
[^123]: 结合自然语言处理和机器学习在金融新闻中检测篇章级别的时间性

    Detection of Temporality at Discourse Level on Financial News by Combining Natural Language Processing and Machine Learning

    [https://arxiv.org/abs/2404.01337](https://arxiv.org/abs/2404.01337)

    通过结合自然语言处理和机器学习技术，提出了一种新颖的系统，旨在在金融新闻中检测篇章级别的关键声明的时间性，以分析句法和语义依赖关系，区分上下文信息和有价值的预测。

    

    Finance-related news, such as Bloomberg News, CNN Business, and Forbes, provide valuable real data for market screening systems. Experts in these news articles not only provide technical analyses but also share opinions considering political, sociological, and cultural factors. We propose a novel system that utilizes Natural Language Processing and Machine Learning techniques to detect the temporality of key statements in finance-related news at the discourse level, aiming to differentiate between context information and valuable predictions by analyzing syntactic and semantic dependencies.

    arXiv:2404.01337v1 Announce Type: new  Abstract: Finance-related news such as Bloomberg News, CNN Business and Forbes are valuable sources of real data for market screening systems. In news, an expert shares opinions beyond plain technical analyses that include context such as political, sociological and cultural factors. In the same text, the expert often discusses the performance of different assets. Some key statements are mere descriptions of past events while others are predictions. Therefore, understanding the temporality of the key statements in a text is essential to separate context information from valuable predictions. We propose a novel system to detect the temporality of finance-related news at discourse level that combines Natural Language Processing and Machine Learning techniques, and exploits sophisticated features such as syntactic and semantic dependencies. More specifically, we seek to extract the dominant tenses of the main statements, which may be either explicit 
    
[^124]: 建筑设计的生成式人工智能：文献综述

    Generative AI for Architectural Design: A Literature Review

    [https://arxiv.org/abs/2404.01335](https://arxiv.org/abs/2404.01335)

    生成式人工智能在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率，通过广泛应用生成式AI技术和深度生成模型生成2D图像、视频和3D模型，并审视其在不同阶段的影响趋势。

    

    arXiv:2404.01335v1 公告类型：跨越 摘要：生成式人工智能（AI）在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率。本文探讨了生成式人工智能技术在建筑设计中的广泛应用，这一趋势受益于深度生成模型的快速发展。文章全面回顾了生成式人工智能和大规模模型的基本原理，并突出了在生成2D图像、视频和3D模型方面的应用。此外，通过审查来自2020年的最新文献，本文审视了生成式人工智能技术在建筑设计的不同阶段的影响，从生成初始建筑3D形式到生成最终建筑图像。研究增长的明显趋势表明建筑设计领域对生成式人工智能技术的倾向不断增长。

    arXiv:2404.01335v1 Announce Type: cross  Abstract: Generative Artificial Intelligence (AI) has pioneered new methodological paradigms in architectural design, significantly expanding the innovative potential and efficiency of the design process. This paper explores the extensive applications of generative AI technologies in architectural design, a trend that has benefited from the rapid development of deep generative models. This article provides a comprehensive review of the basic principles of generative AI and large-scale models and highlights the applications in the generation of 2D images, videos, and 3D models. In addition, by reviewing the latest literature from 2020, this paper scrutinizes the impact of generative AI technologies at different stages of architectural design, from generating initial architectural 3D forms to producing final architectural imagery. The marked trend of research growth indicates an increasing inclination within the architectural design community towa
    
[^125]: 使用LLMs增强NER数据集：迈向自动化和精细化标注

    Augmenting NER Datasets with LLMs: Towards Automated and Refined Annotation

    [https://arxiv.org/abs/2404.01334](https://arxiv.org/abs/2404.01334)

    本研究引入了一种新颖的混合标注方法，将人力工作与大型语言模型相结合，旨在提高NER模型的性能，并以成本效益的方式实现这一目标。

    

    在自然语言处理（NLP）领域，命名实体识别（NER）被认为是一项关键技术，在各种应用中被广泛应用。传统的用于为NER模型标注数据集的方法面临着高成本和数据集质量变化的挑战。本研究介绍了一种新型的混合标注方法，将人力工作与大型语言模型（LLMs）的能力相结合。这种方法不仅旨在改善手动注释中固有的噪音，如遗漏，从而提高NER模型的性能，而且还以一种具有成本效益的方式实现这一目标。此外，通过采用标签混合策略，它解决了LLM-based注释中遇到的类别不平衡问题。通过对多个数据集的分析，这种方法一直表现出比传统注释方法更优异的性能，即使在co

    arXiv:2404.01334v1 Announce Type: new  Abstract: In the field of Natural Language Processing (NLP), Named Entity Recognition (NER) is recognized as a critical technology, employed across a wide array of applications. Traditional methodologies for annotating datasets for NER models are challenged by high costs and variations in dataset quality. This research introduces a novel hybrid annotation approach that synergizes human effort with the capabilities of Large Language Models (LLMs). This approach not only aims to ameliorate the noise inherent in manual annotations, such as omissions, thereby enhancing the performance of NER models, but also achieves this in a cost-effective manner. Additionally, by employing a label mixing strategy, it addresses the issue of class imbalance encountered in LLM-based annotations. Through an analysis across multiple datasets, this method has been consistently shown to provide superior performance compared to traditional annotation methods, even under co
    
[^126]: 等等，这都是令牌噪音？一直就是吗：利用 Shapley 值解释 LLM 行为

    Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value

    [https://arxiv.org/abs/2404.01332](https://arxiv.org/abs/2404.01332)

    使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响

    

    大型语言模型（LLMs）的出现为模拟人类行为和认知过程开辟了新的可能性，潜在应用包括市场研究和消费者行为分析等各个领域。然而，由于LLMs的显著差异暗示了不同的基础过程在起作用，以及LLMs对提示变化的敏感性，利用LLMs作为人类主体的替代仍然存在不确定性。本文提出了一种基于合作博弈理论中Shapley值的新方法来解释LLM行为，并量化每个提示组件对模型输出的相对贡献。通过两个应用--一个离散选择实验和一个认知偏见调查，我们展示了Shapley值方法如何揭示我们所谓的“令牌噪音”效应，即LLM决策受到的影响严重偏向于

    arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
    
[^127]: Holo-VQVAE：用于仅相位全息图的VQ-VAE

    Holo-VQVAE: VQ-VAE for phase-only holograms

    [https://arxiv.org/abs/2404.01330](https://arxiv.org/abs/2404.01330)

    Holo-VQVAE是一种针对仅相位全息图的新型生成框架，结合了矢量量化变分自动编码器的结构，通过集成角谱方法来学习图像域，在全息图生成中实现了从复杂分布中直接生成多样化全息内容。

    

    Holography stands at the forefront of visual technology innovation, offering immersive, three-dimensional visualizations through the manipulation of light wave amplitude and phase. Contemporary research in hologram generation has predominantly focused on image-to-hologram conversion, producing holograms from existing images. These approaches, while effective, inherently limit the scope of innovation and creativity in hologram generation. In response to this limitation, we present Holo-VQVAE, a novel generative framework tailored for phase-only holograms (POHs). Holo-VQVAE leverages the architecture of Vector Quantized Variational AutoEncoders, enabling it to learn the complex distributions of POHs. Furthermore, it integrates the Angular Spectrum Method into the training process, facilitating learning in the image domain. This framework allows for the generation of unseen, diverse holographic content directly from its intricately learned distributions.

    arXiv:2404.01330v1 Announce Type: cross  Abstract: Holography stands at the forefront of visual technology innovation, offering immersive, three-dimensional visualizations through the manipulation of light wave amplitude and phase. Contemporary research in hologram generation has predominantly focused on image-to-hologram conversion, producing holograms from existing images. These approaches, while effective, inherently limit the scope of innovation and creativity in hologram generation. In response to this limitation, we present Holo-VQVAE, a novel generative framework tailored for phase-only holograms (POHs). Holo-VQVAE leverages the architecture of Vector Quantized Variational AutoEncoders, enabling it to learn the complex distributions of POHs. Furthermore, it integrates the Angular Spectrum Method into the training process, facilitating learning in the image domain. This framework allows for the generation of unseen, diverse holographic content directly from its intricately learne
    
[^128]: 无抽象能力的老年人数字包容娱乐聊天机器人

    Entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities

    [https://arxiv.org/abs/2404.01327](https://arxiv.org/abs/2404.01327)

    EBER chatbot是一个旨在减少老年人数字鸿沟的娱乐聊天机器人，其创新之处在于其"智能电台"概念，根据用户的心情和需求提供相关信息。

    

    当前的语言处理技术允许创建对话式聊天机器人平台。尽管人工智能在许多大众市场领域仍然过于不成熟，无法支持令人满意的用户体验，但对话式界面已经在临时应用中找到了自己的位置，比如电话中心和在线购物助手。然而，目前还没有将其应用于老年人的社会包容，老年人特别容易受到数字鸿沟的影响。许多老年人通过传统媒体如电视和广播来减轻孤独感，这些媒体被认为是创造陪伴感的方式。在本文中，我们介绍了旨在减少老年人数字鸿沟的EBER聊天机器人。EBER会在后台阅读新闻，并根据用户的心情调整回复。其创新之处在于“智能电台”概念，根据该概念，不是简化数字信息系统以使其易于访问，而是根据用户的心情和需求提供相关信息。

    arXiv:2404.01327v1 Announce Type: cross  Abstract: Current language processing technologies allow the creation of conversational chatbot platforms. Even though artificial intelligence is still too immature to support satisfactory user experience in many mass market domains, conversational interfaces have found their way into ad hoc applications such as call centres and online shopping assistants. However, they have not been applied so far to social inclusion of elderly people, who are particularly vulnerable to the digital divide. Many of them relieve their loneliness with traditional media such as TV and radio, which are known to create a feeling of companionship. In this paper we present the EBER chatbot, designed to reduce the digital gap for the elderly. EBER reads news in the background and adapts its responses to the user's mood. Its novelty lies in the concept of "intelligent radio", according to which, instead of simplifying a digital information system to make it accessible to
    
[^129]: JailbreakBench: 一个用于对抗大型语言模型越狱的开放鲁棒性基准

    JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models

    [https://arxiv.org/abs/2404.01318](https://arxiv.org/abs/2404.01318)

    JailbreakBench是一个用于对抗大型语言模型越狱的开放基准，提供新的数据集、对抗提示和评估框架。

    

    越狱攻击会导致大型语言模型生成有害、不道德或令人反感的内容。评估这些攻击存在许多挑战，当前的基准和评估技术并未充分解决。为了解决这些挑战，我们引入了JailbreakBench，一个开源基准，包括具有100个独特行为的新越狱数据集（称为JBB-Behaviors）、一组最先进的对抗提示（称为越狱工件）和一个标准化评估框架。

    arXiv:2404.01318v1 Announce Type: cross  Abstract: Jailbreak attacks cause large language models (LLMs) to generate harmful, unethical, or otherwise objectionable content. Evaluating these attacks presents a number of challenges, which the current collection of benchmarks and evaluation techniques do not adequately address. First, there is no clear standard of practice regarding jailbreaking evaluation. Second, existing works compute costs and success rates in incomparable ways. And third, numerous works are not reproducible, as they withhold adversarial prompts, involve closed-source code, or rely on evolving proprietary APIs. To address these challenges, we introduce JailbreakBench, an open-sourced benchmark with the following components: (1) a new jailbreaking dataset containing 100 unique behaviors, which we call JBB-Behaviors; (2) an evolving repository of state-of-the-art adversarial prompts, which we refer to as jailbreak artifacts; (3) a standardized evaluation framework that i
    
[^130]: 在Transformer中智能学习率分布以减少灾难性遗忘

    Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers

    [https://arxiv.org/abs/2404.01317](https://arxiv.org/abs/2404.01317)

    本文研究了在Transformer神经网络中的灾难性遗忘问题，通过智能学习率分布取得了比平坦学习率更好的性能，并在GLUE数据集中得到验证。

    

    在自然语言处理中，对大型文本语料库进行语言模型的预训练是一种常见做法。然后对这些模型进行微调以在各种任务上取得最佳结果。本文研究了Transformer神经网络中灾难性遗忘的问题，并质疑在这种情况下对整个网络采用相同学习率的微调常见做法。我们进行了超参数优化过程，找到了比平坦学习率更好的学习率分布。我们结合这些学习率分布，并展示它们对灾难性遗忘问题的性能表现更好。我们使用GLUE数据集中的各种自然语言处理基准验证了这些学习率分布。

    arXiv:2404.01317v1 Announce Type: cross  Abstract: Pretraining language models on large text corpora is a common practice in natural language processing. Fine-tuning of these models is then performed to achieve the best results on a variety of tasks. In this paper, we investigate the problem of catastrophic forgetting in transformer neural networks and question the common practice of fine-tuning with a flat learning rate for the entire network in this context. We perform a hyperparameter optimization process to find learning rate distributions that are better than a flat learning rate. We combine the learning rate distributions thus found and show that they generalize to better performance with respect to the problem of catastrophic forgetting. We validate these learning rate distributions with a variety of NLP benchmarks from the GLUE dataset.
    
[^131]: 学习在不确定性下解决作业车间调度问题

    Learning to Solve Job Shop Scheduling under Uncertainty

    [https://arxiv.org/abs/2404.01308](https://arxiv.org/abs/2404.01308)

    该论文利用深度强化学习技术解决了具有不确定性的作业车间调度问题，重点在于提出了一种新颖方法来处理具有不确定持续时间的JSSP。

    

    作业车间调度问题（JSSP）是一个组合优化问题，其中任务需要在机器上进行调度，以最小化诸如最大完工时间或延迟等标准。为了解决更加现实的场景，我们为每个任务的持续时间关联了一个概率分布。我们的目标是生成一个稳健的调度，即最小化平均完工时间。本文引入了一种新方法，利用深度强化学习（DRL）技术来寻找稳健的解决方案，重点关注具有不确定持续时间的JSSP。本研究的关键贡献包括：（1）DRL在JSSP应用中的进展，增强泛化性和可伸缩性，（2）一种新颖的方法来解决具有不确定持续时间的JSSP。 Wheatley方法，集成了图神经网络（GNNs）和DRL，已公开可用于进一步的研究和应用。

    arXiv:2404.01308v1 Announce Type: new  Abstract: Job-Shop Scheduling Problem (JSSP) is a combinatorial optimization problem where tasks need to be scheduled on machines in order to minimize criteria such as makespan or delay. To address more realistic scenarios, we associate a probability distribution with the duration of each task. Our objective is to generate a robust schedule, i.e. that minimizes the average makespan. This paper introduces a new approach that leverages Deep Reinforcement Learning (DRL) techniques to search for robust solutions, emphasizing JSSPs with uncertain durations. Key contributions of this research include: (1) advancements in DRL applications to JSSPs, enhancing generalization and scalability, (2) a novel method for addressing JSSPs with uncertain durations. The Wheatley approach, which integrates Graph Neural Networks (GNNs) and DRL, is made publicly available for further research and applications.
    
[^132]: NeuroPrune：一种受神经系统启发的用于大型语言模型的拓扑稀疏训练算法

    NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models

    [https://arxiv.org/abs/2404.01306](https://arxiv.org/abs/2404.01306)

    本研究受神经系统启发，通过神经网络拓扑的稀疏方法，探索类似于生物网络的机制，展示了对各种 NLP 任务都表现出色和高效的模型-不可知稀疏性方法

    

    基于 Transformer 的语言模型由于在各种任务上的出色性能而在自然语言处理（NLP）中变得普遍。然而，昂贵的训练以及推理仍然是它们广泛适用性的一个重要障碍。在模型架构的各个层次强制引入稀疏性已被证明有助于解决扩展性和效率问题，但稀疏性对网络拓扑的影响仍存在断裂。受大脑神经网络启发，我们通过网络拓扑的视角探索稀疏性方法。具体而言，我们利用在生物网络中观察到的机制，如优先附着和冗余突触修剪，并展示了基于原则的、与模型无关的稀疏性方法在跨越分类（如自然语言推理）和生成（摘要、机器翻译）的各种 NLP 任务上表现出色且高效，尽管 o

    arXiv:2404.01306v1 Announce Type: cross  Abstract: Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at various levels of the model architecture has found promise in addressing scaling and efficiency issues, there remains a disconnect between how sparsity affects network topology. Inspired by brain neuronal networks, we explore sparsity approaches through the lens of network topology. Specifically, we exploit mechanisms seen in biological networks, such as preferential attachment and redundant synapse pruning, and show that principled, model-agnostic sparsity approaches are performant and efficient across diverse NLP tasks, spanning both classification (such as natural language inference) and generation (summarization, machine translation), despite o
    
[^133]: LLM可以在不透露私人信息的情况下获得其他LLM的帮助吗？

    Can LLMs get help from other LLMs without revealing private information?

    [https://arxiv.org/abs/2404.01041](https://arxiv.org/abs/2404.01041)

    本研究展示了在级联系统中运用隐私保护技术的可行性，以减少在查询远程模型时泄漏私人信息的风险，并引入了两个隐私度量。

    

    级联是一种常见类型的机器学习系统，其中如果本地模型无法单独准确标记用户数据，则可以查询一个大型的远程模型。对于大型语言模型（LLMs），由于其在显著降低推断成本的同时保持任务性能的能力，服务堆栈越来越多地使用级联。然而，在本地模型可以访问敏感数据的情况下应用级联系统构成用户的重大隐私风险，因为这些数据可能被转发到远程模型。在这项工作中，我们展示了在此类设置中应用级联系统的可行性，方法是为本地模型配备隐私保护技术，从而减少访问远程模型时泄漏私人信息的风险。为了量化此类设置中的信息泄漏，我们引入了两个隐私度量。然后，我们提出了一个利用最近引入的社交学习范式的系统

    arXiv:2404.01041v1 Announce Type: cross  Abstract: Cascades are a common type of machine learning systems in which a large, remote model can be queried if a local model is not able to accurately label a user's data by itself. Serving stacks for large language models (LLMs) increasingly use cascades due to their ability to preserve task performance while dramatically reducing inference costs. However, applying cascade systems in situations where the local model has access to sensitive data constitutes a significant privacy risk for users since such data could be forwarded to the remote model. In this work, we show the feasibility of applying cascade systems in such setups by equipping the local model with privacy-preserving techniques that reduce the risk of leaking private information when querying the remote model. To quantify information leakage in such setups, we introduce two privacy measures. We then propose a system that leverages the recently introduced social learning paradigm 
    
[^134]: 《面对它们自己：基于LLM的两阶段策略通过日志定位配置错误》

    Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize Configuration Errors via Logs

    [https://arxiv.org/abs/2404.00640](https://arxiv.org/abs/2404.00640)

    提出了一种基于LLM的两阶段策略，帮助终端用户通过日志定位配置错误的根本原因，并开发了相应工具LogConfigLocalizer，以帮助终端用户通过日志分析解决配置错误。

    

    可配置软件系统容易出现配置错误，给公司带来重大损失。然而，由于庞大而复杂的配置空间，诊断这些错误具有挑战性。这些错误对有经验的维护者和没有软件系统源代码访问权限的新终端用户都构成重大挑战。鉴于日志对大多数终端用户来说易于访问，我们进行了初步研究，概述了利用日志定位配置错误的挑战和机遇。根据初步研究所得的见解，我们提出了基于LLM的两阶段策略，帮助终端用户通过日志定位配置错误的根本原因。我们进一步实现了一个工具LogConfigLocalizer，符合上述策略的设计，希望通过日志分析帮助终端用户应对配置错误。

    arXiv:2404.00640v1 Announce Type: cross  Abstract: Configurable software systems are prone to configuration errors, resulting in significant losses to companies. However, diagnosing these errors is challenging due to the vast and complex configuration space. These errors pose significant challenges for both experienced maintainers and new end-users, particularly those without access to the source code of the software systems. Given that logs are easily accessible to most end-users, we conduct a preliminary study to outline the challenges and opportunities of utilizing logs in localizing configuration errors. Based on the insights gained from the preliminary study, we propose an LLM-based two-stage strategy for end-users to localize the root-cause configuration properties based on logs. We further implement a tool, LogConfigLocalizer, aligned with the design of the aforementioned strategy, hoping to assist end-users in coping with configuration errors through log analysis.   To the best
    
[^135]: CHAIN：通过受限唯一性连续性规范化增强数据高效GANs的泛化能力

    CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz continuity constrAIned Normalization

    [https://arxiv.org/abs/2404.00521](https://arxiv.org/abs/2404.00521)

    通过引入CHAIN，该方法在数据有限的情况下，解决了GANs中鉴别器过拟合和训练不稳定的问题，提高了泛化能力和训练稳定性。

    

    生成对抗网络（GANs）显着推动了图像生成，但它们的性能严重依赖大量的训练数据。在数据有限的情况下，GANs经常面临鉴别器过拟合和训练不稳定的问题。我们的工作通过识别Batch Normalization（BN）中的关键缺陷来解决这一问题：在中心化和缩放步骤中梯度爆炸的倾向。为了解决这个问题，我们提出了CHAIN（受限唯一性连续性规范化），它将传统的中心化步骤替换为零均值正则化，并在缩放步骤中集成了Lipschitz连续性约束。CHAIN通过自适应插值归一化和非归一化特征进一步增强了GANs的训练，有效避免了鉴别器过拟合。

    arXiv:2404.00521v1 Announce Type: new  Abstract: Generative Adversarial Networks (GANs) significantly advanced image generation but their performance heavily depends on abundant training data. In scenarios with limited data, GANs often struggle with discriminator overfitting and unstable training. Batch Normalization (BN), despite being known for enhancing generalization and training stability, has rarely been used in the discriminator of Data-Efficient GANs. Our work addresses this gap by identifying a critical flaw in BN: the tendency for gradient explosion during the centering and scaling steps. To tackle this issue, we present CHAIN (lipsCHitz continuity constrAIned Normalization), which replaces the conventional centering step with zero-mean regularization and integrates a Lipschitz continuity constraint in the scaling step. CHAIN further enhances GAN training by adaptively interpolating the normalized and unnormalized features, effectively avoiding discriminator overfitting. Our 
    
[^136]: 具有基础世界模型的无人驾驶汽车零射击安全预测

    Zero-shot Safety Prediction for Autonomous Robots with Foundation World Models

    [https://arxiv.org/abs/2404.00462](https://arxiv.org/abs/2404.00462)

    基于基础世界模型，提出了一种能够直接预测因果未来状态的方法，在安全预测任务中表现优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。

    

    世界模型创造一个代理世界来训练控制器，并通过学习系统的内部动态模型来预测安全违规行为。然而，现有的世界模型仅依赖于统计学习如何观察随着行动而变化，缺乏对代理动态准确性的精确量化，这在安全关键系统中构成重大挑战。为了解决这一挑战，我们提出了将观察嵌入到有意义且因果潜在的表示中的基础世界模型。这使得代理动态能够通过利用无需训练的大型语言模型直接预测因果未来状态。在两个常见的基准测试中，这种新颖模型在安全预测任务中优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。我们通过比较更专业和系统相关的指标评估其性能。

    arXiv:2404.00462v1 Announce Type: new  Abstract: A world model creates a surrogate world to train a controller and predict safety violations by learning the internal dynamic model of systems. However, the existing world models rely solely on statistical learning of how observations change in response to actions, lacking precise quantification of how accurate the surrogate dynamics are, which poses a significant challenge in safety-critical systems. To address this challenge, we propose foundation world models that embed observations into meaningful and causally latent representations. This enables the surrogate dynamics to directly predict causal future states by leveraging a training-free large language model. In two common benchmarks, this novel model outperforms standard world models in the safety prediction task and has a performance comparable to supervised learning despite not using any data. We evaluate its performance with a more specialized and system-relevant metric by compar
    
[^137]: 规划和编辑检索以增强工具学习

    Planning and Editing What You Retrieve for Enhanced Tool Learning

    [https://arxiv.org/abs/2404.00450](https://arxiv.org/abs/2404.00450)

    该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。

    

    最近在将外部工具与大型语言模型（LLMs）集成方面取得的进展打开了新的领域，应用范围涵盖数学推理、代码生成器和智能助手。然而，现有方法依赖简单的一次性检索策略，无法有效准确地筛选相关工具。本文介绍了一种新颖的“规划与检索（P&R）”和“编辑与确认（E&G）”范式的模型，包括了神经检索模块和基于LLM的查询规划器，以增强工具利用的效果。

    arXiv:2404.00450v1 Announce Type: new  Abstract: Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel \modelname (\modelmeaning) approach, encompassing ``Plan-and-Retrieve (P\&R)'' and ``Edit-and-Ground (E\&G)'' paradigms. The P\&R paradigm consists of a neural retrieval module for shortlisting relevant tools and an LLM-based query planner that decomposes complex queries into actionable tasks, enhancing the effectiveness of tool utilization. The E\&G paradigm utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the gap between user queries and tool functionalities. Experiment results demonstrate that these paradigms significantly improve the recall an
    
[^138]: InfLoRA：无干扰的低秩自适应持续学习方法

    InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning

    [https://arxiv.org/abs/2404.00228](https://arxiv.org/abs/2404.00228)

    InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。

    

    持续学习要求模型依次学习多个任务。在持续学习中，模型应具备在旧任务上维持性能（稳定性）和不断适应新任务的能力（可塑性）。最近，基于参数高效微调（PEFT）的持续学习方法变得越来越受欢迎。尽管现有基于PEFT的持续学习方法表现出比非PEFT方法更优秀的性能，但大多数方法并未考虑如何消除新任务对旧任务的干扰，从而阻碍模型在稳定性和可塑性之间取得良好平衡。本文提出了一种新的PEFT方法，称为无干扰低秩自适应（InfLoRA）方法，用于持续学习。

    arXiv:2404.00228v1 Announce Type: cross  Abstract: Continual learning requires the model to learn multiple tasks sequentially. In continual learning, the model should possess the ability to maintain its performance on old tasks (stability) and the ability to adapt to new tasks continuously (plasticity). Recently, parameter-efficient fine-tuning (PEFT), which involves freezing a pre-trained model and injecting a small number of learnable parameters to adapt to downstream tasks, has gained increasing popularity in continual learning. Although existing continual learning methods based on PEFT have demonstrated superior performance compared to those not based on PEFT, most of them do not consider how to eliminate the interference of the new task on the old tasks, which inhibits the model from making a good trade-off between stability and plasticity. In this work, we propose a new PEFT method, called interference-free low-rank adaptation (InfLoRA), for continual learning. InfLoRA injects a 
    
[^139]: LLM作为写作助手：探讨所有权感和推理的视角

    LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning

    [https://arxiv.org/abs/2404.00027](https://arxiv.org/abs/2404.00027)

    探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。

    

    写作中的所有权感限制了我们对思想、时间和贡献的投入，导致对产出物的依恋。然而，使用写作助手引入了一种心理困境，因为一些内容并非直接我们的创作。我们往往更倾向于在创造性任务中更多地归功于大型语言模型（LLMs），尽管它们对所有任务都是平等的。此外，虽然我们可能不会完全声称对由LLM生成的内容拥有所有权，但却自由地声称作者身份。我们进行了一项简短调查来研究这些问题，并了解潜在的认知过程，以更好地了解人机交互在写作中的应用并改进写作辅助系统。

    arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
    
[^140]: 墨水与个性：在LLMs时代塑造个性化叙事

    Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs

    [https://arxiv.org/abs/2404.00026](https://arxiv.org/abs/2404.00026)

    研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。

    

    个性和个性化构成了使每个作家独特并影响其文字以有效吸引读者同时传达真实性的独特特征。然而，我们日益依赖基于LLM的写作助手可能会危及我们的创造力和个性。我们经常忽视这一趋势对我们的创造力和独特性的负面影响，尽管可能会造成后果。本研究通过进行简要调查探索不同的观点和概念，以及尝试理解人们的观点，结合以往在该领域的研究，来研究这些问题。解决这些问题对于改进人机交互系统和增强个性化和个性化写作助手至关重要。

    arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
    
[^141]: 利用量子增强机器学习赋能信用评分系统

    Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning

    [https://arxiv.org/abs/2404.00015](https://arxiv.org/abs/2404.00015)

    提出了一种名为Systemic Quantum Score (SQS)的新方法，展示在金融领域生产级应用案例中相比纯经典模型更有优势，能够从较少数据点中提取模式并表现出更好性能。

    

    Quantum Kernels被认为在量子机器学习的早期阶段提供了有用性。然而，在利用庞大数据集时，高度复杂的经典模型很难超越，特别是在理解力方面。尽管如此，一旦数据稀缺且倾斜，经典模型就会遇到困难。量子特征空间被预计在这样具有挑战性的情景中能够找到更好的数据特征和目标类别之间的联系，最重要的是增强了泛化能力。在这项工作中，我们提出了一种名为Systemic Quantum Score (SQS)的新方法，并提供了初步结果，表明在金融行业生产级应用案例中，SQS可能比纯经典模型具有优势。我们的具体研究表明，SQS能够从较少的数据点中提取出模式，并且在数据需求量大的算法（如XGBoost）上表现出更好的性能，带来优势。

    arXiv:2404.00015v1 Announce Type: cross  Abstract: Quantum Kernels are projected to provide early-stage usefulness for quantum machine learning. However, highly sophisticated classical models are hard to surpass without losing interpretability, particularly when vast datasets can be exploited. Nonetheless, classical models struggle once data is scarce and skewed. Quantum feature spaces are projected to find better links between data features and the target class to be predicted even in such challenging scenarios and most importantly, enhanced generalization capabilities. In this work, we propose a novel approach called Systemic Quantum Score (SQS) and provide preliminary results indicating potential advantage over purely classical models in a production grade use case for the Finance sector. SQS shows in our specific study an increased capacity to extract patterns out of fewer data points as well as improved performance over data-hungry algorithms such as XGBoost, providing advantage i
    
[^142]: FairRAG: 公平人类生成的公平检索增强

    FairRAG: Fair Human Generation via Fair Retrieval Augmentation

    [https://arxiv.org/abs/2403.19964](https://arxiv.org/abs/2403.19964)

    FairRAG框架通过在外部图像数据库检索到的参考图像来提高人类生成中的公平性，并应用简单但有效的去偏策略，从而为生成过程提供来自不同人口统计组的图像。

    

    存在的文本到图像生成模型反映甚至放大了其训练数据中根深蒂固的社会偏见。这对人类图像生成尤为令人担忧，因为模型偏向某些人口统计组。现有的纠正此问题的尝试受到预训练模型固有限制的影响，并未能在根本上改善人口多样性。在这项工作中，我们引入了公平检索增强生成（FairRAG），这是一个新颖的框架，通过在来自外部图像数据库的参考图像上进行条件化来提高人类生成中的公平性。FairRAG通过一个轻量级线性模块实现条件化，将参考图像投射到文本空间中。为了增强公平性，FairRAG应用了简单而有效的去偏方法，在生成过程中提供来自不同人口统计组的图像。大量实验展示

    arXiv:2403.19964v1 Announce Type: cross  Abstract: Existing text-to-image generative models reflect or even amplify societal biases ingrained in their training data. This is especially concerning for human image generation where models are biased against certain demographic groups. Existing attempts to rectify this issue are hindered by the inherent limitations of the pre-trained models and fail to substantially improve demographic diversity. In this work, we introduce Fair Retrieval Augmented Generation (FairRAG), a novel framework that conditions pre-trained generative models on reference images retrieved from an external image database to improve fairness in human generation. FairRAG enables conditioning through a lightweight linear module that projects reference images into the textual space. To enhance fairness, FairRAG applies simple-yet-effective debiasing strategies, providing images from diverse demographic groups during the generative process. Extensive experiments demonstrat
    
[^143]: 通过视觉语言模型对神经网络进行基于概念的分析

    Concept-based Analysis of Neural Networks via Vision-Language Models

    [https://arxiv.org/abs/2403.19837](https://arxiv.org/abs/2403.19837)

    本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。

    

    视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\texttt{Con}_{\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\texttt{Con}_{\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te

    arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\texttt{Con}_{\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\texttt{Con}_{\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te
    
[^144]: ECoDepth: 有效调整扩散模型以用于单目深度估计

    ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation

    [https://arxiv.org/abs/2403.18807](https://arxiv.org/abs/2403.18807)

    通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。

    

    在缺乏视差线索的情况下，基于学习的单图深度估计（SIDE）模型严重依赖图像中的阴影和上下文线索。我们从已有研究的启发中探讨使用从预训练的ViT模型生成的全局图像先验，以提供更详细的上下文信息。基于这一想法，我们提出了一种新的使用扩散骨干的SIDE模型，其受到ViT嵌入的条件约束。

    arXiv:2403.18807v1 Announce Type: cross  Abstract: In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embedding
    
[^145]: 大型语言模型中的长篇事实性

    Long-form factuality in large language models

    [https://arxiv.org/abs/2403.18802](https://arxiv.org/abs/2403.18802)

    该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。

    

    大型语言模型（LLMs）在回答开放性主题的事实性提示时，经常生成包含事实错误的内容。为了在开放领域中对模型的长篇事实性进行基准测试，我们首先使用GPT-4生成了一个名为LongFact的提示集，其中包含数千个囊括38个主题的问题。然后，我们提出LLM代理可以通过一种名为Search-Augmented Factuality Evaluator（SAFE）的方法作为长篇事实性的自动评估器。SAFE利用LLM将长篇回应分解为一组单独的事实，并通过发送搜索查询到Google搜索以及确定一个事实是否得到搜索结果支持的多步推理过程来评估每个事实的准确性。此外，我们还提议将F1分数扩展为长篇事实性的聚合度量。为此，我们平衡了回应中支持事实的百分比（精度）与

    arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
    
[^146]: 压缩多任务嵌入用于地球观测中数据高效下游训练和推断

    Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation

    [https://arxiv.org/abs/2403.17886](https://arxiv.org/abs/2403.17886)

    基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。

    

    随着地球观测（EO）中大规模数据的存储库增长，模型训练和推断的转移和存储成本也在增加，消耗了大量资源。我们引入了基于神经嵌入压缩（NEC）的方法，该方法基于对数据使用者传输压缩的嵌入而不是原始数据。我们通过学习神经压缩来调整基础模型（FM），生成多任务嵌入，同时在压缩率和嵌入效用之间进行权衡。我们仅针对FM参数的一小部分（10%）进行更新，进行短时间训练（预训练迭代的1%）。我们在两个EO任务上评估了NEC：场景分类和语义分割。与将传统压缩应用于原始数据相比，NEC在减少数据量方面可实现类似的准确性，降低了75%到90%的数据量。即使在99.7%的压缩下，在场景分类任务上性能仅下降了5%。总体而言，NEC是一种数据高效

    arXiv:2403.17886v1 Announce Type: new  Abstract: As repositories of large scale data in earth observation (EO) have grown, so have transfer and storage costs for model training and inference, expending significant resources. We introduce Neural Embedding Compression (NEC), based on the transfer of compressed embeddings to data consumers instead of raw data. We adapt foundation models (FM) through learned neural compression to generate multi-task embeddings while navigating the tradeoff between compression rate and embedding utility. We update only a small fraction of the FM parameters (10%) for a short training period (1% of the iterations of pre-training). We evaluate NEC on two EO tasks: scene classification and semantic segmentation. Compared with applying traditional compression to the raw data, NEC achieves similar accuracy with a 75% to 90% reduction in data. Even at 99.7% compression, performance drops by only 5% on the scene classification task. Overall, NEC is a data-efficient
    
[^147]: PeersimGym：用于通过强化学习解决任务卸载问题的环境

    PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning

    [https://arxiv.org/abs/2403.17637](https://arxiv.org/abs/2403.17637)

    引入了 PeersimGym 环境，通过强化学习解决任务卸载问题，支持定制化仿真环境，有助于开发和优化计算网络中的任务卸载策略。

    

    任务卸载对于在诸如物联网之类的网络中平衡设备的计算负载至关重要，但面临着诸如在严格的通信和存储约束下最小化延迟和能源使用等重要优化挑战。传统优化在可扩展性方面存在不足；启发式方法缺乏实现最佳结果，而强化学习（RL）通过允许通过迭代交互学习最佳卸载策略的方式提供了一种有前景的途径。然而，RL 的功效取决于对丰富数据集和定制的现实训练环境的访问。为解决这一问题，我们引入了 PeersimGym，这是一个开源的、可定制的仿真环境，旨在开发和优化计算网络中的任务卸载策略。PeersimGym 支持各种网络拓扑和计算约束，并整合了一种"PettingZo"方法，使用户能够轻松配置仿真参数和监控仿真过程。

    arXiv:2403.17637v1 Announce Type: cross  Abstract: Task offloading, crucial for balancing computational loads across devices in networks such as the Internet of Things, poses significant optimization challenges, including minimizing latency and energy usage under strict communication and storage constraints. While traditional optimization falls short in scalability; and heuristic approaches lack in achieving optimal outcomes, Reinforcement Learning (RL) offers a promising avenue by enabling the learning of optimal offloading strategies through iterative interactions. However, the efficacy of RL hinges on access to rich datasets and custom-tailored, realistic training environments. To address this, we introduce PeersimGym, an open-source, customizable simulation environment tailored for developing and optimizing task offloading strategies within computational networks. PeersimGym supports a wide range of network topologies and computational constraints and integrates a \textit{PettingZo
    
[^148]: 使用区域指导标记将孟加拉文本与地方方言转录为国际音标

    Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens

    [https://arxiv.org/abs/2403.17407](https://arxiv.org/abs/2403.17407)

    通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。

    

    孟加拉文本到国际音标（IPA）的准确转录是一项具有挑战性的任务，主要是由于语言的复杂音韵学和语境相关的音变。对于区域孟加拉方言来说，由于缺乏针对这些方言的标准拼写约定、当地和外语在这些地区中流行的词汇以及不同地区之间的音韵多样性，这一挑战甚至更为严峻。本文提出了一种方法来解决这个序列到序列的问题，即在覆盖孟加拉国六个地区的新数据集上引入“区域指导标记”（DGT）技术。其关键思想是在生成IPA转录之前向模型提供有关输入文本的区域方言或“地区”的明确信息。这通过在输入序列前添加一个地区标记来实现，有效地引导模型理解与每个地区相关的独特音韵模式。

    arXiv:2403.17407v1 Announce Type: cross  Abstract: Accurate transcription of Bengali text to the International Phonetic Alphabet (IPA) is a challenging task due to the complex phonology of the language and context-dependent sound changes. This challenge is even more for regional Bengali dialects due to unavailability of standardized spelling conventions for these dialects, presence of local and foreign words popular in those regions and phonological diversity across different regions. This paper presents an approach to this sequence-to-sequence problem by introducing the District Guided Tokens (DGT) technique on a new dataset spanning six districts of Bangladesh. The key idea is to provide the model with explicit information about the regional dialect or "district" of the input text before generating the IPA transcription. This is achieved by prepending a district token to the input sequence, effectively guiding the model to understand the unique phonetic patterns associated with each 
    
[^149]: FLIGAN: 使用 GAN 改进不完整数据的联邦学习

    FLIGAN: Enhancing Federated Learning with Incomplete Data using GAN

    [https://arxiv.org/abs/2403.16930](https://arxiv.org/abs/2403.16930)

    FLIGAN利用生成对抗网络（GAN）来生成合成数据，解决联邦学习中不完整数据的问题，提升模型的鲁棒性和完整性。

    

    联邦学习提供了一种隐私保护机制，用于在网络化设备（如移动设备、物联网边缘节点）上对机器学习模型进行分布式训练。它通过在网络上不共享实际数据来实现边缘的人工智能。现有研究通常侧重于非独立同分布数据的通用方面和客户系统特征的异质性，但他们常常忽视模型开发中不足的数据问题，这可能来自边缘节点上不均匀的类别标签分布，以及高度可变的数据容量。在这项工作中，我们提出了一种名为FLIGAN的创新方法来解决联邦学习中数据不完整性的问题。首先，我们利用生成对抗网络（GAN）来敏锐捕捉复杂数据分布，并生成与真实数据紧密相似的合成数据。然后，我们使用合成数据来增强模型的鲁棒性和完整性。

    arXiv:2403.16930v1 Announce Type: new  Abstract: Federated Learning (FL) provides a privacy-preserving mechanism for distributed training of machine learning models on networked devices (e.g., mobile devices, IoT edge nodes). It enables Artificial Intelligence (AI) at the edge by creating models without sharing the actual data across the network. Existing research works typically focus on generic aspects of non-IID data and heterogeneity in client's system characteristics, but they often neglect the issue of insufficient data for model development, which can arise from uneven class label distribution and highly variable data volumes across edge nodes. In this work, we propose FLIGAN, a novel approach to address the issue of data incompleteness in FL. First, we leverage Generative Adversarial Networks (GANs) to adeptly capture complex data distributions and generate synthetic data that closely resemble the real-world data. Then, we use synthetic data to enhance the robustness and comple
    
[^150]: 揭示本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用

    Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy

    [https://arxiv.org/abs/2403.16591](https://arxiv.org/abs/2403.16591)

    论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。

    

    机器学习的迅速发展导致了隐私定义的多样化，由于对隐私构成的威胁，包括本地差分隐私（LDP）的概念。虽然被广泛接受并在许多领域中被利用，但这种传统的隐私测量方法仍然存在一定限制，从无法防止推断披露到缺乏对对手背景知识的考虑。在这项全面研究中，我们引入贝叶斯隐私并深入探讨本地差分隐私和其贝叶斯对应物之间错综复杂的关系，揭示了关于效用-隐私权衡的新见解。我们引入了一个框架，概括了攻击和防御策略，突出它们之间的相互作用和效果。我们的理论贡献基于平均贝叶斯隐私（ABP）和最大贝叶斯隐私之间的严格定义和关系。

    arXiv:2403.16591v1 Announce Type: cross  Abstract: The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Max
    
[^151]: FusionINN：可逆图像融合用于脑肿瘤监测

    FusionINN: Invertible Image Fusion for Brain Tumor Monitoring

    [https://arxiv.org/abs/2403.15769](https://arxiv.org/abs/2403.15769)

    FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。

    

    图像融合通常使用不可逆神经网络将多个源图像合并为单个融合图像。然而，对于临床专家，仅依赖融合图像可能不足以做出诊断决策，因为融合机制混合了来自源图像的特征，从而难以解释潜在的肿瘤病理。我们引入了FusionINN，一种新颖的可逆图像融合框架，能够高效生成融合图像，并通过求解融合过程的逆过程将其分解回源图像。FusionINN通过整合一个正态分布的潜在图像与融合图像一起，以促进分解过程的生成建模，从而保证无损的一对一像素映射。据我们所知，我们是首次研究融合图像的可分解性，这对于生命敏感应用程序尤为关键。

    arXiv:2403.15769v1 Announce Type: cross  Abstract: Image fusion typically employs non-invertible neural networks to merge multiple source images into a single fused image. However, for clinical experts, solely relying on fused images may be insufficient for making diagnostic decisions, as the fusion mechanism blends features from source images, thereby making it difficult to interpret the underlying tumor pathology. We introduce FusionINN, a novel invertible image fusion framework, capable of efficiently generating fused images and also decomposing them back to the source images by solving the inverse of the fusion process. FusionINN guarantees lossless one-to-one pixel mapping by integrating a normally distributed latent image alongside the fused image to facilitate the generative modeling of the decomposition process. To the best of our knowledge, we are the first to investigate the decomposability of fused images, which is particularly crucial for life-sensitive applications such as
    
[^152]: 基于Foundation Models的时间序列分析：教程与调查

    Foundation Models for Time Series Analysis: A Tutorial and Survey

    [https://arxiv.org/abs/2403.14735](https://arxiv.org/abs/2403.14735)

    Foundation Models为时间序列分析带来创新，利用预训练或微调的模型来获得具体定制的广义知识，提升了实践中多个下游任务的效果。

    

    时间序列分析作为数据挖掘领域的焦点，是提取有价值见解的基石，对众多实际应用至关重要。最近Foundation Models（FMs）的发展根本性地改变了时间序列分析模型设计的范式，提升了实践中各种下游任务的效果。这些创新方法通常利用预训练或微调的FMs，以获取专门为时间序列分析量身定制的广义知识。在本调查中，我们旨在提供Foundation Models用于时间序列分析的全面和最新概述。尽管先前的调查主要集中在Foundation Models在时间序列分析中的应用或管道方面，但它们往往缺乏深入了解阐明Foundation Models如何受益时间序列分析的基本机制。为弥补这一空白，我们的调查采用了以模型为中心的分类

    arXiv:2403.14735v1 Announce Type: new  Abstract: Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric class
    
[^153]: CICLe: 适应上下文的大规模多类食品风险分类学习

    CICLe: Conformal In-Context Learning for Largescale Multi-Class Food Risk Classification

    [https://arxiv.org/abs/2403.11904](https://arxiv.org/abs/2403.11904)

    该论文提出了CICLe框架，基于适应上下文学习的方式，在大规模多类食品风险分类中取得了较好的效果，提出了基于符合预测的LLM-in-the-loop框架，可以提高基本分类器的性能，并减少能源消耗。

    

    受污染或掺假食品对人类健康构成重大风险。在给定了用于训练的标记网络文本集的情况下，可以应用机器学习和自然语言处理来自动检测这种风险。我们发布了一个包含7,546个描述公共食品召回公告的短文本数据集。每个文本都经过手动标记，分为两个粒度级别（粗粒度和细粒度），用于表示召回对应的食品产品和危害。我们描述了数据集并对朴素、传统和Transformer模型进行了基准测试。基于我们的分析，基于tf-idf表示的逻辑回归在支持较低的类别上优于RoBERTa和XLM-R。最后，我们讨论了不同的提示策略，并提出了一种基于符合预测的LLM-in-the-loop框架，这可以提高基本分类器的性能，同时减少了与普通提示相比的能源消耗。

    arXiv:2403.11904v1 Announce Type: new  Abstract: Contaminated or adulterated food poses a substantial risk to human health. Given sets of labeled web texts for training, Machine Learning and Natural Language Processing can be applied to automatically detect such risks. We publish a dataset of 7,546 short texts describing public food recall announcements. Each text is manually labeled, on two granularity levels (coarse and fine), for food products and hazards that the recall corresponds to. We describe the dataset and benchmark naive, traditional, and Transformer models. Based on our analysis, Logistic Regression based on a tf-idf representation outperforms RoBERTa and XLM-R on classes with low support. Finally, we discuss different prompting strategies and present an LLM-in-the-loop framework, based on Conformal Prediction, which boosts the performance of the base classifier while reducing energy consumption compared to normal prompting.
    
[^154]: Mamba在时间序列预测中的有效性如何？

    Is Mamba Effective for Time Series Forecasting?

    [https://arxiv.org/abs/2403.11144](https://arxiv.org/abs/2403.11144)

    Mamba模型作为一种状态空间模型在时间序列预测中具有捕捉复杂依赖关系、近线性复杂度以及性能优势的潜力。

    

    在时间序列预测（TSF）领域中，由于Transformer模型能够聚焦全局环境，有效捕捉时间序列中长距离依赖关系以及辨别多变量之间的相关性，因此它一直展现出强大的性能。然而，由于Transformer模型的低效率和关于其捕捉依赖关系能力的质疑，对Transformer架构的不断完善工作仍在进行中。最近，状态空间模型（SSMs）如Mamba因其能够像Transformer一样捕捉序列中的复杂依赖关系，同时又保持近线性的复杂度而备受推崇。在文本和图像任务中，基于Mamba的模型可以提高性能并节约成本，实现双赢局面。这引起了我们对探索SSM在TSF任务中潜力的兴趣。在本文中，我们介绍了两种基于SSM的简单模型，S-Mamba和......

    arXiv:2403.11144v1 Announce Type: new  Abstract: In the realm of time series forecasting (TSF), the Transformer has consistently demonstrated robust performance due to its ability to focus on the global context and effectively capture long-range dependencies within time, as well as discern correlations between multiple variables. However, due to the inefficiencies of the Transformer model and questions surrounding its ability to capture dependencies, ongoing efforts to refine the Transformer architecture persist. Recently, state space models (SSMs), e.g. Mamba, have gained traction due to their ability to capture complex dependencies in sequences, similar to the Transformer, while maintaining near-linear complexity. In text and image tasks, Mamba-based models can improve performance and cost savings, creating a win-win situation. This has piqued our interest in exploring SSM's potential in TSF tasks. In this paper, we introduce two straightforward SSM-based models for TSF, S-Mamba and 
    
[^155]: 使用门控动态可学习注意机制的双Transformer在田纳西伊斯曼过程中进行故障检测与诊断

    Twin Transformer using Gated Dynamic Learnable Attention mechanism for Fault Detection and Diagnosis in the Tennessee Eastman Process

    [https://arxiv.org/abs/2403.10842](https://arxiv.org/abs/2403.10842)

    本研究提出一种新颖的双Transformer模型，结合门控动态可学习注意机制，用于田纳西伊斯曼过程的故障检测与诊断，提高性能通过独立处理输入数据和提取多样化信息，以及动态学习适应性调整注意策略。

    

    故障检测和诊断（FDD）对于确保工业过程的安全性和效率至关重要。我们提出了一种新颖的FDD方法，适用于田纳西伊斯曼过程（TEP），这是化工过程控制中广泛使用的基准。该模型采用两个独立的Transformer分支，能够独立处理输入数据并提取多样化的信息。引入了一种新颖的注意机制，即门控动态可学习注意（GDLAttention），它集成了门控机制和动态学习能力。门控机制调节注意权重，使模型能够关注输入的最相关部分。动态学习方法在训练过程中调整注意策略，有可能提高性能。注意机制使用双线性相似性函数，提供更大的灵活性来捕捉查询和输入之间的复杂关系。

    arXiv:2403.10842v1 Announce Type: cross  Abstract: Fault detection and diagnosis (FDD) is a crucial task for ensuring the safety and efficiency of industrial processes. We propose a novel FDD methodology for the Tennessee Eastman Process (TEP), a widely used benchmark for chemical process control. The model employs two separate Transformer branches, enabling independent processing of input data and potential extraction of diverse information. A novel attention mechanism, Gated Dynamic Learnable Attention (GDLAttention), is introduced which integrates a gating mechanism and dynamic learning capabilities. The gating mechanism modulates the attention weights, allowing the model to focus on the most relevant parts of the input. The dynamic learning approach adapts the attention strategy during training, potentially leading to improved performance. The attention mechanism uses a bilinear similarity function, providing greater flexibility in capturing complex relationships between query and 
    
[^156]: 忽略我但不要替代我：利用非语言元素进行网络安全领域的预训练

    Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for Pretraining on the Cybersecurity Domain

    [https://arxiv.org/abs/2403.10576](https://arxiv.org/abs/2403.10576)

    利用非语言元素进行网络安全领域的预训练，提出了新的预训练方法并在网络安全领域中取得了优越表现

    

    针对网络安全信息通常技术复杂且通过非结构化文本传递，使得自动化处理网络威胁情报变得极具挑战性。针对涉及高度专业知识的文本领域，基于领域语料库的预训练一直是语言模型获取领域专业知识的一种常见方法。然而，网络安全文本通常包含非语言元素（如URL和哈希值），这可能与现有的预训练方法不适用。先前在其他领域的工作中，已将此类文本视为噪音进行移除或过滤，但这些方法的有效性尚未得到调查，特别是在网络安全领域。我们提出了不同的预训练方法，并通过下游任务和探测任务评估了它们的有效性。我们提出的策略（选择性MLM和联合训练NLE标记分类）优于常用的替换非

    arXiv:2403.10576v1 Announce Type: cross  Abstract: Cybersecurity information is often technically complex and relayed through unstructured text, making automation of cyber threat intelligence highly challenging. For such text domains that involve high levels of expertise, pretraining on in-domain corpora has been a popular method for language models to obtain domain expertise. However, cybersecurity texts often contain non-linguistic elements (such as URLs and hash values) that could be unsuitable with the established pretraining methodologies. Previous work in other domains have removed or filtered such text as noise, but the effectiveness of these methods have not been investigated, especially in the cybersecurity domain. We propose different pretraining methodologies and evaluate their effectiveness through downstream tasks and probing tasks. Our proposed strategy (selective MLM and jointly training NLE token classification) outperforms the commonly taken approach of replacing non-l
    
[^157]: FeatUp: 一个与模型无关的特征任意分辨率框架

    FeatUp: A Model-Agnostic Framework for Features at Any Resolution

    [https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)

    FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。

    

    深度特征是计算机视觉研究的基石，捕捉图像语义并使社区能够解决下游任务，即使在零或少样本情况下也能做到。然而，这些特征通常缺乏空间分辨率，无法直接执行像分割和深度预测这样的稠密预测任务，因为模型会过于聚合大范围的信息。在这项工作中，我们介绍了FeatUp，一个任务和模型无关的框架，用于恢复深度特征中丢失的空间信息。我们介绍了FeatUp的两个变体：一个在单次前向传递中引导具有高分辨率信号的特征，另一个适应单个图像并以任何分辨率重构特征的隐式模型。这两种方法都使用了一个具有与 NeRF 类似的深度类比的多视图一致性损失。我们的特征保留其原始语义，并可以替换现有应用程序，即使不重新

    arXiv:2403.10516v1 Announce Type: cross  Abstract: Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-
    
[^158]: 野外情感维度识别的联合多模态Transformer

    Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild

    [https://arxiv.org/abs/2403.10488](https://arxiv.org/abs/2403.10488)

    该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。

    

    在视频中进行音视频情感识别对于单模性能具有巨大潜力。它有效地利用了视觉和听觉模态之间以及模态内部的依赖关系。本工作提出了一种利用关键交叉注意力的联合多模态Transformer架构的音视频情感识别系统。该框架旨在利用视频中音频和视觉线索（面部表情和语音模式）的互补性，相较于仅依赖于单一模态，实现了更优越的性能。所提出的模型利用单独的主干网络来捕获每种模态（音频和视觉）内部的时间依赖关系。随后，一个联合多模态Transformer架构集成了各自模态的嵌入，使该模型能够有效地捕获模态间（音频和视觉之间）和模态内部（每种模态内部）的关系。

    arXiv:2403.10488v1 Announce Type: cross  Abstract: Audiovisual emotion recognition (ER) in videos has immense potential over unimodal performance. It effectively leverages the inter- and intra-modal dependencies between visual and auditory modalities. This work proposes a novel audio-visual emotion recognition system utilizing a joint multimodal transformer architecture with key-based cross-attention. This framework aims to exploit the complementary nature of audio and visual cues (facial expressions and vocal patterns) in videos, leading to superior performance compared to solely relying on a single modality. The proposed model leverages separate backbones for capturing intra-modal temporal dependencies within each modality (audio and visual). Subsequently, a joint multimodal transformer architecture integrates the individual modality embeddings, enabling the model to effectively capture inter-modal (between audio and visual) and intra-modal (within each modality) relationships. Exten
    
[^159]: 利用典型表示减轻社会偏见而不使用人口统计信息

    Leveraging Prototypical Representations for Mitigating Social Bias without Demographic Information

    [https://arxiv.org/abs/2403.09516](https://arxiv.org/abs/2403.09516)

    通过利用预定义的典型人口统计文本并在微调过程中加入正则化项，本文提出的方法有效减轻了语言模型中的社会偏见，同时不需要依赖显式的人口统计标签。

    

    减轻社会偏见通常需要识别与每个数据样本相关联的社会群体。在本文中，我们提出了DAFair，一种新颖的方法来解决语言模型中的社会偏见问题。与依赖显式人口统计标签的传统方法不同，我们的方法不需要任何此类信息。相反，我们利用预定义的人口统计典型文本，并在微调过程中加入一个正则化项来减轻模型表示中的偏见。我们在两个任务和两个模型上的实证结果展示了我们的方法相对于之前不依赖标记数据的方法的有效性。此外，即使使用有限的人口统计标注数据，我们的方法也优于常见的去偏见方法。

    arXiv:2403.09516v1 Announce Type: new  Abstract: Mitigating social biases typically requires identifying the social groups associated with each data sample. In this paper, we present DAFair, a novel approach to address social bias in language models. Unlike traditional methods that rely on explicit demographic labels, our approach does not require any such information. Instead, we leverage predefined prototypical demographic texts and incorporate a regularization term during the fine-tuning process to mitigate bias in the model's representations. Our empirical results across two tasks and two models demonstrate the effectiveness of our method compared to previous approaches that do not rely on labeled data. Moreover, with limited demographic-annotated data, our approach outperforms common debiasing approaches.
    
[^160]: 受约束的混合动力车辆的最优燃料消耗：一种受约束的强化学习方法

    Constrained Optimal Fuel Consumption of HEV: A Constrained Reinforcement Learning Approach

    [https://arxiv.org/abs/2403.07503](https://arxiv.org/abs/2403.07503)

    首次提出了从受约束强化学习的视角全球首次提供混合动力车辆的受约束最优燃料消耗的数学表达，并首次利用两种主流的受约束强化学习方法来获得车辆在电池电气平衡条件下的最小燃料消耗。

    

    混合动力车辆（HEVs）因能更好地结合内燃机和电动机的工作特性而日益受欢迎。然而，在特定装配条件和特定速度曲线下，HEV的最小燃料消耗对于电池电气平衡情况仍需在学术界和工业界进一步阐明。针对这一问题，本工作首次从受约束强化学习（CRL）的视角提供了受约束的最优燃料消耗（COFC）的数学表达。同时，首次利用了两种主流的CRL方法，即受约束变分策略优化（CVPO）和基于拉格朗日的方法，以在电池电气平衡条件下获得车辆的最小燃料消耗。我们在知名的普锐斯丰田混合系统（THS）下NEDC条件下进行案例研究；我们g

    arXiv:2403.07503v1 Announce Type: new  Abstract: Hybrid electric vehicles (HEVs) are becoming increasingly popular because they can better combine the working characteristics of internal combustion engines and electric motors. However, the minimum fuel consumption of an HEV for a battery electrical balance case under a specific assembly condition and a specific speed curve still needs to be clarified in academia and industry. Regarding this problem, this work provides the mathematical expression of constrained optimal fuel consumption (COFC) from the perspective of constrained reinforcement learning (CRL) for the first time globally. Also, two mainstream approaches of CRL, constrained variational policy optimization (CVPO) and Lagrangian-based approaches, are utilized for the first time to obtain the vehicle's minimum fuel consumption under the battery electrical balance condition. We conduct case studies on the well-known Prius TOYOTA hybrid system (THS) under the NEDC condition; we g
    
[^161]: 利用潜在对抗训练防御未预见的故障模式

    Defending Against Unforeseen Failure Modes with Latent Adversarial Training

    [https://arxiv.org/abs/2403.05030](https://arxiv.org/abs/2403.05030)

    本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。

    

    人工智能系统有时在部署后会展示出有害的意外行为。尽管开发人员进行了大量诊断和调试，这种情况经常发生。由于攻击面非常广泛，从模型中减少风险具有挑战性。耗尽地搜索可能导致模型失败的输入是不可行的。红队和对抗训练（AT）通常用于使人工智能系统更加健壮。然而，它们并不足以避免许多与对抗训练不同的真实世界故障模式。在这项工作中，我们利用潜在对抗训练（LAT）来防御漏洞，而无需生成引发这些漏洞的输入。LAT利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示。我们使用LAT来清除恶意软件并防御针对保留类别的对抗性攻击。我们展示在图像分类、文本分类

    arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
    
[^162]: JMI在SemEval 2024任务3中的应用：使用GPT和instruction-tuned Llama模型进行多模态情感因果分析的两步法

    JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using in-context learning with GPT and instruction-tuned Llama models

    [https://arxiv.org/abs/2403.04798](https://arxiv.org/abs/2403.04798)

    本文介绍了针对SemEval-2024任务3开发的多模态情感因果分析系统，提出了通过两步框架解决多模态情感因果分析挑战的方法，并在实验中取得显著性能提升。

    

    本文介绍了我们针对SemEval-2024任务3：“对话中的多模态情感因果分析竞赛”开发的系统。有效捕捉人类对话中的情感需要整合文本、音频和视频等多种模态。然而，这些多样性模态的复杂性给开发高效的多模态情感因果分析系统带来了挑战。我们提出的方法通过两步框架来解决这些挑战。我们在实现中采用了两种不同的方法。在方法1中，我们使用两个单独的Llama 2模型进行情感和原因预测的instruction-tuning。在方法2中，我们使用GPT-4V进行会话级视频描述，并使用带有GPT 3.5的上下文学习对注释对话进行处理。我们的系统获得了第4名，系统消融实验表明，我们提出的解决方案取得了显著的性能增益。

    arXiv:2403.04798v1 Announce Type: new  Abstract: This paper presents our system development for SemEval-2024 Task 3: "The Competition of Multimodal Emotion Cause Analysis in Conversations". Effectively capturing emotions in human conversations requires integrating multiple modalities such as text, audio, and video. However, the complexities of these diverse modalities pose challenges for developing an efficient multimodal emotion cause analysis (ECA) system. Our proposed approach addresses these challenges by a two-step framework. We adopt two different approaches in our implementation. In Approach 1, we employ instruction-tuning with two separate Llama 2 models for emotion and cause prediction. In Approach 2, we use GPT-4V for conversation-level video description and employ in-context learning with annotated conversation using GPT 3.5. Our system wins rank 4, and system ablation experiments demonstrate that our proposed solutions achieve significant performance gains. All the experime
    
[^163]: 用于多模态电子健康记录动态嵌入和标记的时间交叉注意力

    Temporal Cross-Attention for Dynamic Embedding and Tokenization of Multimodal Electronic Health Records

    [https://arxiv.org/abs/2403.04012](https://arxiv.org/abs/2403.04012)

    提出了一种用于精确表示多模态临床时间序列的动态嵌入和标记框架

    

    现代电子健康记录（EHR）系统的广度、规模和时间粒度为使用顺序深度学习估计个性化和背景患者健康轨迹提供了巨大潜力。然而，由于其高维度、稀疏性、多模态性、不规则和变量特定的记录频率以及在同时记录多个测量时戳重复，学习有用的EHR数据表示具有挑战性。尽管最近的努力将结构化EHR和非结构化临床笔记融合，表明了更准确预测临床结果的潜力，但对直接解决时间EHR挑战的EHR嵌入方法的关注较少——即通过学习来自多模态患者时间序列的具有时间感知的表示。在本文中，我们介绍了一个用于精确表示多模态临床时间序列的动态嵌入和标记框架

    arXiv:2403.04012v1 Announce Type: new  Abstract: The breadth, scale, and temporal granularity of modern electronic health records (EHR) systems offers great potential for estimating personalized and contextual patient health trajectories using sequential deep learning. However, learning useful representations of EHR data is challenging due to its high dimensionality, sparsity, multimodality, irregular and variable-specific recording frequency, and timestamp duplication when multiple measurements are recorded simultaneously. Although recent efforts to fuse structured EHR and unstructured clinical notes suggest the potential for more accurate prediction of clinical outcomes, less focus has been placed on EHR embedding approaches that directly address temporal EHR challenges by learning time-aware representations from multimodal patient time series. In this paper, we introduce a dynamic embedding and tokenization framework for precise representation of multimodal clinical time series that
    
[^164]: 3D扩散策略

    3D Diffusion Policy

    [https://arxiv.org/abs/2403.03954](https://arxiv.org/abs/2403.03954)

    3D扩散策略（DP3）是一种新颖的视觉模仿学习方法，通过将3D视觉表示的强大性结合到扩散策略中，成功解决了学习复杂技能所需大量人类演示的问题。

    

    模仿学习为教授机器人灵巧技能提供了一种高效的方式；然而，学习复杂而具有通用性的技能通常需要大量的人类演示。为了解决这一具有挑战性的问题，我们提出了3D扩散策略（DP3），这是一种将3D视觉表示的强大性融入到扩散策略中的新颖视觉模仿学习方法，扩散策略是一类有条件的动作生成模型。DP3的核心设计是利用一个紧凑的3D视觉表示，该表示是从稀疏点云中提取出来的，使用高效的点编码器。在我们涵盖了72个仿真任务的实验中，DP3仅需要10个演示就可以成功处理大多数任务，并且比基线模型提高了55.3%。在4个真实机器人任务中，DP3表现出了高成功率的精确控制，每项任务仅需40次演示即可成功率为85%，在不同领域展现了出色的泛化能力。

    arXiv:2403.03954v1 Announce Type: cross  Abstract: Imitation learning provides an efficient way to teach robots dexterous skills; however, learning complex skills robustly and generalizablely usually consumes large amounts of human demonstrations. To tackle this challenging problem, we present 3D Diffusion Policy (DP3), a novel visual imitation learning approach that incorporates the power of 3D visual representations into diffusion policies, a class of conditional action generative models. The core design of DP3 is the utilization of a compact 3D visual representation, extracted from sparse point clouds with an efficient point encoder. In our experiments involving 72 simulation tasks, DP3 successfully handles most tasks with just 10 demonstrations and surpasses baselines with a 55.3% relative improvement. In 4 real robot tasks, DP3 demonstrates precise control with a high success rate of 85%, given only 40 demonstrations of each task, and shows excellent generalization abilities in di
    
[^165]: MedMamba: 用于医学图像分类的Vision Mamba

    MedMamba: Vision Mamba for Medical Image Classification

    [https://arxiv.org/abs/2403.03849](https://arxiv.org/abs/2403.03849)

    提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。

    

    医学图像分类是计算机视觉领域中非常基础和关键的任务。近年来，基于CNN和Transformer的模型被广泛应用于分类各种医学图像。不幸的是，CNN在长距离建模能力方面存在局限，无法有效提取医学图像中的细粒度特征，而Transformers受到二次计算复杂度的阻碍。最近的研究表明，由Mamba表示的状态空间模型（SSM）可以高效地建模长距离交互作用同时保持线性计算复杂度。受此启发，我们提出了用于医学图像分类的Vision Mamba（MedMamba）。更具体地，我们引入了一个新颖的Conv-SSM模块，将卷积层的局部特征提取能力与SSM捕捉长距离依赖性的能力结合在一起。为了展示MedMamba的潜力，我们进行了

    arXiv:2403.03849v1 Announce Type: cross  Abstract: Medical image classification is a very fundamental and crucial task in the field of computer vision. These years, CNN-based and Transformer-based models are widely used in classifying various medical images. Unfortunately, The limitation of CNNs in long-range modeling capabilities prevent them from effectively extracting fine-grained features in medical images , while Transformers are hampered by their quadratic computational complexity. Recent research has shown that the state space model (SSM) represented by Mamba can efficiently model long-range interactions while maintaining linear computational complexity. Inspired by this, we propose Vision Mamba for medical image classification (MedMamba). More specifically, we introduce a novel Conv-SSM module, which combines the local feature extraction ability of convolutional layers with the ability of SSM to capture long-range dependency. To demonstrate the potential of MedMamba, we conduct
    
[^166]: 建模多模态社交互动：具有密集对齐表示的新挑战和基线

    Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations

    [https://arxiv.org/abs/2403.02090](https://arxiv.org/abs/2403.02090)

    提出了三个新的具有挑战性的任务来模拟多人之间的细粒度动态，并为社交推理游戏设置提供了广泛的数据注释；同时提出了一种新颖的多模态基线方法，利用密集对齐的语言-视觉表示。

    

    理解涉及言语和非言语线索的社交互动对有效解释社交情境至关重要。然而，大多数关于多模态社交线索的先前工作主要集中在单人行为上，或依赖于与多方环境中的话语密切对齐的整体视觉表示。它们在建模多方互动的复杂动态方面存在局限。在本文中，我们介绍了三个新的具有挑战性的任务，以建模多人之间的细粒度动态：话语目标识别、代词指代消解和提及玩家预测。我们为社交推理游戏设置中的这些新挑战提供了广泛的数据注释。此外，我们提出了一种新颖的多模态基线，通过将视觉特征与其对应的话语同步，利用密集对齐的语言-视觉表示，这有助于

    arXiv:2403.02090v1 Announce Type: cross  Abstract: Understanding social interactions involving both verbal and non-verbal cues is essential to effectively interpret social situations. However, most prior works on multimodal social cues focus predominantly on single-person behaviors or rely on holistic visual representations that are not densely aligned to utterances in multi-party environments. They are limited in modeling the intricate dynamics of multi-party interactions. In this paper, we introduce three new challenging tasks to model the fine-grained dynamics between multiple people: speaking target identification, pronoun coreference resolution, and mentioned player prediction. We contribute extensive data annotations to curate these new challenges in social deduction game settings. Furthermore, we propose a novel multimodal baseline that leverages densely aligned language-visual representations by synchronizing visual features with their corresponding utterances. This facilitates
    
[^167]: 学习在自然语言格式中压缩提示

    Learning to Compress Prompt in Natural Language Formats

    [https://arxiv.org/abs/2402.18700](https://arxiv.org/abs/2402.18700)

    该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。

    

    大型语言模型（LLMs）擅长处理多个自然语言处理任务，但它们的能力受到长上下文、推理速度慢以及计算结果成本高的限制。部署具有精确和信息丰富上下文的LLMs有助于用户更有效和更具成本效益地处理大规模数据集。现有作品依赖将长提示上下文压缩为软提示。然而，软提示压缩在不同LLM之间的可转移性受到限制，尤其是基于API的LLMs。因此，本研究旨在以LLM可转移性的形式压缩长提示的自然语言形式。这带来两个挑战：(i) 自然语言（NL）提示不兼容反向传播，(ii) NL提示在施加长度约束方面缺乏灵活性。在本研究中，我们提出了一种自然语言提示封装（Nano-Capsulator）框架

    arXiv:2402.18700v1 Announce Type: cross  Abstract: Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft prompt compression encounters limitations in transferability across different LLMs, especially API-based LLMs. To this end, this work aims to compress lengthy prompts in the form of natural language with LLM transferability. This poses two challenges: (i) Natural Language (NL) prompts are incompatible with back-propagation, and (ii) NL prompts lack flexibility in imposing length constraints. In this work, we propose a Natural Language Prompt Encapsulation (Nano-Capsulator) framewor
    
[^168]: 弹性时间步长的强化学习

    Reinforcement Learning with Elastic Time Steps

    [https://arxiv.org/abs/2402.14961](https://arxiv.org/abs/2402.14961)

    SEAC是一种弹性时间步长的离策略演员-评论家算法，通过可变持续时间的时间步长，使代理能够根据情况改变控制频率，在模拟环境中表现优异。

    

    传统的强化学习（RL）算法通常应用于机器人学习以以固定控制频率执行动作的控制器。鉴于RL算法的离散性质，它们对控制频率的选择的影响视而不见：找到正确的控制频率可能很困难，错误往往会导致过度使用计算资源甚至导致无法收敛。我们提出了软弹性演员-评论家（SEAC）, 一种新颖的离策略演员-评论家算法来解决这个问题。SEAC实现了弹性时间步长，即具有已知变化持续时间的时间步长，允许代理根据情况改变其控制频率。在实践中，SEAC仅在必要时应用控制，最小化计算资源和数据使用。我们在模拟环境中评估了SEAC在牛顿运动学迷宫导航任务和三维赛车视频游戏Trackmania中的能力。SEAC在表现上优于SAC基线。

    arXiv:2402.14961v1 Announce Type: cross  Abstract: Traditional Reinforcement Learning (RL) algorithms are usually applied in robotics to learn controllers that act with a fixed control rate. Given the discrete nature of RL algorithms, they are oblivious to the effects of the choice of control rate: finding the correct control rate can be difficult and mistakes often result in excessive use of computing resources or even lack of convergence.   We propose Soft Elastic Actor-Critic (SEAC), a novel off-policy actor-critic algorithm to address this issue. SEAC implements elastic time steps, time steps with a known, variable duration, which allow the agent to change its control frequency to adapt to the situation. In practice, SEAC applies control only when necessary, minimizing computational resources and data usage.   We evaluate SEAC's capabilities in simulation in a Newtonian kinematics maze navigation task and on a 3D racing video game, Trackmania. SEAC outperforms the SAC baseline in t
    
[^169]: 在广义朗之万方程中学习记忆核

    Learning Memory Kernels in Generalized Langevin Equations

    [https://arxiv.org/abs/2402.11705](https://arxiv.org/abs/2402.11705)

    提出一种学习广义朗之万方程中记忆核的新方法，通过正则化Prony方法估计相关函数并在Sobolev范数Loss函数和RKHS正则化下实现回归，在指数加权的$L^2$空间内获得改进性能，对比其他回归估计器展示了其优越性。

    

    我们引入了一种新颖的方法来学习广义朗之万方程中的记忆核。该方法最初利用正则化Prony方法从轨迹数据中估计相关函数，然后通过基于Sobolev范数的回归和RKHS正则化来进行回归。我们的方法保证在指数加权的$L^2$空间内获得了改进的性能，核估计误差受控于估计相关函数的误差。我们通过数值示例展示了我们的估计器相对于依赖于$L^2$损失函数的其他回归估计器以及从逆拉普拉斯变换推导出的估计器的优越性，这些示例突显了我们的估计器在各种权重参数选择上的持续优势。此外，我们提供了包括力和漂移项在方程中的应用示例。

    arXiv:2402.11705v1 Announce Type: cross  Abstract: We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our approach guarantees improved performance within an exponentially weighted $L^2$ space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on $L^2$ loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.
    
[^170]: 在线局部虚发现率控制：一种资源分配方法

    Online Local False Discovery Rate Control: A Resource Allocation Approach

    [https://arxiv.org/abs/2402.11425](https://arxiv.org/abs/2402.11425)

    该研究提出了一种在线局部虚发现率控制的资源分配方法，实现了$O(\sqrt{T})$的后悔率，并指出这种后悔率在一般情况下是不可改进的。

    

    我们考虑在线局部虚发现率（FDR）控制问题，其中多个测试被顺序进行，目标是最大化总期望的发现次数。我们将问题形式化为一种在线资源分配问题，涉及接受/拒绝决策，从高层次来看，这可以被视为一个带有额外不确定性的在线背包问题，即随机预算补充。我们从一般的到达分布开始，并提出了一个简单的策略，实现了$O(\sqrt{T})$的后悔。我们通过展示这种后悔率在一般情况下是不可改进的来补充这一结果。然后我们将焦点转向离散到达分布。我们发现许多现有的在线资源分配文献中的重新解决启发式虽然在典型设置中实现了有界的损失，但可能会造成$\Omega(\sqrt{T})$甚至$\Omega(T)$的后悔。通过观察到典型策略往往太过

    arXiv:2402.11425v1 Announce Type: cross  Abstract: We consider the problem of online local false discovery rate (FDR) control where multiple tests are conducted sequentially, with the goal of maximizing the total expected number of discoveries. We formulate the problem as an online resource allocation problem with accept/reject decisions, which from a high level can be viewed as an online knapsack problem, with the additional uncertainty of random budget replenishment. We start with general arrival distributions and propose a simple policy that achieves a $O(\sqrt{T})$ regret. We complement the result by showing that such regret rate is in general not improvable. We then shift our focus to discrete arrival distributions. We find that many existing re-solving heuristics in the online resource allocation literature, albeit achieve bounded loss in canonical settings, may incur a $\Omega(\sqrt{T})$ or even a $\Omega(T)$ regret. With the observation that canonical policies tend to be too op
    
[^171]: 在语言模型对话中测量和控制“人设”漂移

    Measuring and Controlling Persona Drift in Language Model Dialogs

    [https://arxiv.org/abs/2402.10962](https://arxiv.org/abs/2402.10962)

    提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移

    

    提示是定制语言模型聊天机器人的标准工具，使其能够承担特定的“人设”。在使用提示时的一个隐含假设是，它们将是稳定的，因此聊天机器人将在整个对话过程中继续根据规定的“人设”生成文本。我们提出了一个量化基准来测试这一假设，通过两个个性化聊天机器人之间的自我对话来评估“人设”的稳定性。我们对流行模型如LLaMA2-chat-70B进行测试，发现在八轮对话中存在显著的“人设”漂移。对这一现象的实证和理论分析表明，由于长对话中的注意力衰减，变压器注意力机制起到了一定作用。为了对抗注意力衰减和“人设”漂移，我们提出了一种称为split-softmax的轻量级方法，与两个强基线方法相比表现优异。

    arXiv:2402.10962v1 Announce Type: cross  Abstract: Prompting is a standard tool for customizing language-model chatbots, enabling them to take on a specific "persona". An implicit assumption in the use of prompts is that they will be stable, so the chatbot will continue to generate text according to the stipulated persona for the duration of a conversation. We propose a quantitative benchmark to test this assumption, evaluating persona stability via self-chats between two personalized chatbots. Testing popular models like LLaMA2-chat-70B, we reveal a significant persona drift within eight rounds of conversations. An empirical and theoretical analysis of this phenomenon suggests the transformer attention mechanism plays a role, due to attention decay over long exchanges. To combat attention decay and persona drift, we propose a lightweight method called split-softmax, which compares favorably against two strong baselines.
    
[^172]: AutoMathText：使用语言模型进行数学文本的自主数据选择

    AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts

    [https://arxiv.org/abs/2402.07625](https://arxiv.org/abs/2402.07625)

    本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。

    

    为了通过持续的预训练改善语言模型在数学推理方面的能力，我们引入了一种新颖的策略，利用基础语言模型进行自主数据选择。与传统的有人工标注数据的监督微调或训练过的分类器不同，我们的方法利用元提示语言模型作为零样本验证器，自主评估和选择高质量的数学内容，并发布了经过策划的开源AutoMathText数据集，其中包含超过200GB的数据。为了证明我们方法的有效性，我们对AutoMathText数据集进行了连续预训练，使得7B参数的Mistral语言模型在MATH数据集上的下游性能大幅提升，而令牌数量比之前的连续预训练工作减少了几个数量级。我们的方法展示了基准的预训练令牌效率提高了2倍，突显了我们方法在增强中的潜力。

    To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
    
[^173]: 带有动态过程不确定性的路径空间卡尔曼滤波器用于时间序列数据分析

    Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data

    [https://arxiv.org/abs/2402.04498](https://arxiv.org/abs/2402.04498)

    本论文提出了一种名为路径空间卡尔曼滤波器（PKF）的扩展算法，可以动态跟踪数据和先前知识的不确定性，并用贝叶斯方法量化不同的不确定性来源。通过在合成数据集上进行数值实验，我们证明了PKF优于传统KF方法，并将该方法应用于生物时间序列数据集。

    

    卡尔曼滤波器（KF）是一种最优线性状态预测算法，广泛应用于工程学、经济学、机器人学和太空探索等领域。在本文中，我们发展了KF的扩展，称为路径空间卡尔曼滤波器（PKF），它允许我们动态跟踪与底层数据和先前知识相关的不确定性，并使用贝叶斯方法量化不同的不确定性来源。该算法的一个应用是自动检测内部机制模型与数据在时间上发生变化的时间窗口。首先，我们提供了描述PKF算法收敛性的定理。然后，我们通过数值实验证明PKF在合成数据集上的性能优于传统KF方法，平均均方误差降低了数个数量级。最后，我们将该方法应用于生物时间序列数据集。

    Kalman Filter (KF) is an optimal linear state prediction algorithm, with applications in fields as diverse as engineering, economics, robotics, and space exploration. Here, we develop an extension of the KF, called a Pathspace Kalman Filter (PKF) which allows us to a) dynamically track the uncertainties associated with the underlying data and prior knowledge, and b) take as input an entire trajectory and an underlying mechanistic model, and using a Bayesian methodology quantify the different sources of uncertainty. An application of this algorithm is to automatically detect temporal windows where the internal mechanistic model deviates from the data in a time-dependent manner. First, we provide theorems characterizing the convergence of the PKF algorithm. Then, we numerically demonstrate that the PKF outperforms conventional KF methods on a synthetic dataset lowering the mean-squared-error by several orders of magnitude. Finally, we apply this method to biological time-course dataset i
    
[^174]: 在线均匀风险时间抽样：第一次近似算法，具有全置信区间集成的学习增强

    Online Uniform Risk Times Sampling: First Approximation Algorithms, Learning Augmentation with Full Confidence Interval Integration

    [https://arxiv.org/abs/2402.01995](https://arxiv.org/abs/2402.01995)

    本文首次引入在线均匀风险时间抽样问题，并提出了两种在线近似算法，一种带有学习增强，一种没有学习增强。通过竞争比分析，我们提供了严格的理论性能保证。我们通过合成实验和实际案例研究评估了算法的性能。

    

    在数字健康领域，将有限的治疗预算分配到可用的风险时间上是减少用户疲劳的关键策略。然而，由于未知的实际风险时间数量，这一策略遇到了显著的障碍，现有方法在理论保证方面还不足够。本文首次将在线均匀风险时间抽样问题引入近似算法框架。我们提出了两种在线近似算法，一种带有学习增强，一种没有学习增强，并使用竞争比分析为它们提供了严格的理论性能保证。我们使用合成实验和HeartSteps移动应用的实际案例研究评估了我们算法的性能。

    In digital health, the strategy of allocating a limited treatment budget across available risk times is crucial to reduce user fatigue. This strategy, however, encounters a significant obstacle due to the unknown actual number of risk times, a factor not adequately addressed by existing methods lacking theoretical guarantees. This paper introduces, for the first time, the online uniform risk times sampling problem within the approximation algorithm framework. We propose two online approximation algorithms for this problem, one with and one without learning augmentation, and provide rigorous theoretical performance guarantees for them using competitive ratio analysis. We assess the performance of our algorithms using both synthetic experiments and a real-world case study on HeartSteps mobile applications.
    
[^175]: 从粉末X射线衍射实现端到端的晶体结构预测

    End-to-End Crystal Structure Prediction from Powder X-Ray Diffraction

    [https://arxiv.org/abs/2401.03862](https://arxiv.org/abs/2401.03862)

    XtalNet是首个用于从粉末X射线衍射实现端到端晶体结构预测的等变深度生成模型，能够生成具有多达400个原子的有机结构。

    

    晶体结构预测（CSP）取得了显著进展，但大多数方法集中在无条件地生成具有有限原子的无机晶体。 本研究引入了XtalNet，这是首个用于从粉末X射线衍射（PXRD）实现端到端CSP的等变深度生成模型。 与先前仅依赖成分的方法不同，XtalNet利用PXRD作为额外条件，消除了模糊性，并使得能够生成具有多达400个原子的单元胞的复杂有机结构。 XtalNet包括两个模块：对比PXRD-晶体预训练（CPCP）模块，将PXRD空间与晶体结构空间对齐，以及条件晶体结构生成（CCSG）模块，根据PXRD模式生成候选晶体结构。 在两个MOF数据集（hMOF-100和hMOF-400）上的评估表明了XtalNet的有效性。 XtalNet实现了9的前十匹配率。

    arXiv:2401.03862v2 Announce Type: replace-cross  Abstract: Crystal structure prediction (CSP) has made significant progress, but most methods focus on unconditional generations of inorganic crystal with limited atoms in the unit cell. This study introduces XtalNet, the first equivariant deep generative model for end-to-end CSP from Powder X-ray Diffraction (PXRD). Unlike previous methods that rely solely on composition, XtalNet leverages PXRD as an additional condition, eliminating ambiguity and enabling the generation of complex organic structures with up to 400 atoms in the unit cell. XtalNet comprises two modules: a Contrastive PXRD-Crystal Pretraining (CPCP) module that aligns PXRD space with crystal structure space, and a Conditional Crystal Structure Generation (CCSG) module that generates candidate crystal structures conditioned on PXRD patterns. Evaluation on two MOF datasets (hMOF-100 and hMOF-400) demonstrates XtalNet's effectiveness. XtalNet achieves a top-10 Match Rate of 9
    
[^176]: pixelSplat：来自图像对的三维高斯斑块用于可扩展可泛化三维重建

    pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable Generalizable 3D Reconstruction

    [https://arxiv.org/abs/2312.12337](https://arxiv.org/abs/2312.12337)

    通过引入像素Splat，我们提出了一种学习从图像对中重建三维辐射场的模型，实现了内存高效渲染、高速3D重建，有效克服了稀疏表示的局部极小值问题，实现了优越的实时渲染性能。

    

    我们介绍了pixelSplat，这是一个前向模型，通过图像对学习重建由三维高斯基元参数化的三维辐射场。我们的模型具有实时和内存高效的渲染，可实现可扩展的训练，同时在推断时实现快速的三维重建。为了克服稀疏和局部支持表示固有的局部极小值问题，我们预测了三维上的密集概率分布，并从该概率分布中采样高斯均值。通过重新参数化技巧，我们使得这个采样操作可微分，从而能够通过高斯斑块表示反向传播梯度。我们在真实世界的RealEstate10k和ACID数据集上对我们的方法进行了广角基线新视图合成基准测试，我们的表现优于最先进的光场变换器，并在重建可解释和可编辑的三维辐射的同时加速渲染2.5个数量级。

    arXiv:2312.12337v3 Announce Type: replace-cross  Abstract: We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D radiance fields parameterized by 3D Gaussian primitives from pairs of images. Our model features real-time and memory-efficient rendering for scalable training as well as fast 3D reconstruction at inference time. To overcome local minima inherent to sparse and locally supported representations, we predict a dense probability distribution over 3D and sample Gaussian means from that probability distribution. We make this sampling operation differentiable via a reparameterization trick, allowing us to back-propagate gradients through the Gaussian splatting representation. We benchmark our method on wide-baseline novel view synthesis on the real-world RealEstate10k and ACID datasets, where we outperform state-of-the-art light field transformers and accelerate rendering by 2.5 orders of magnitude while reconstructing an interpretable and editable 3D radiance
    
[^177]: 大型人类语言模型：需求和挑战

    Large Human Language Models: A Need and the Challenges

    [https://arxiv.org/abs/2312.07751](https://arxiv.org/abs/2312.07751)

    大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。

    

    随着人类中心的自然语言处理研究的进展，人们越来越意识到将人类和社会因素纳入到自然语言处理模型的重要性。同时，我们的自然语言处理系统已经严重依赖于LLM，其中大多数并没有对作者进行建模。为了构建能够真正理解人类语言的自然语言处理系统，我们必须更好地将人类背景整合到LLM中。这提出了一系列设计考虑和挑战，涉及到要捕捉哪些人类因素、如何表示它们以及要采用何种建模策略等问题。为了应对这些挑战，我们提倡从心理学和行为科学的概念出发，支持三个立场来创建大型人类语言模型（LHLMs）：首先，语言模型训练应包括人类背景。其次，LHLMs应该意识到人不仅仅是他们所属的群体。第三，LHLMs应该能够考虑到人类背景的动态和时间依赖性特点。

    arXiv:2312.07751v2 Announce Type: replace-cross  Abstract: As research in human-centered NLP advances, there is a growing recognition of the importance of incorporating human and social factors into NLP models. At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors. To build NLP systems that can truly understand human language, we must better integrate human contexts into LLMs. This brings to the fore a range of design considerations and challenges in terms of what human aspects to capture, how to represent them, and what modeling strategies to pursue. To address these, we advocate for three positions toward creating large human language models (LHLMs) using concepts from psychological and behavioral sciences: First, LM training should include the human context. Second, LHLMs should recognize that people are more than their group(s). Third, LHLMs should be able to account for the dynamic and temporally-dependent nature of the human con
    
[^178]: 数学家的大型语言模型

    Large Language Models for Mathematicians

    [https://arxiv.org/abs/2312.04556](https://arxiv.org/abs/2312.04556)

    大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注，对数学家的潜在帮助和改变工作方式的影响进行了讨论。

    

    大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注。对许多职业来说，LLMs代表一种无价的工具，可以加快工作速度并提高工作质量。本文讨论它们在帮助专业数学家方面的作用程度。我们首先提供了所有现代语言模型中使用的Transformer模型的数学描述。基于最近的研究，我们概述了最佳实践和潜在问题，并报告了语言模型的数学能力。最后，我们探讨了LLMs改变数学家工作方式的潜力。

    arXiv:2312.04556v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) such as ChatGPT have received immense interest for their general-purpose language understanding and, in particular, their ability to generate high-quality text or computer code. For many professions, LLMs represent an invaluable tool that can speed up and improve the quality of work. In this note, we discuss to what extent they can aid professional mathematicians. We first provide a mathematical description of the transformer model used in all modern language models. Based on recent studies, we then outline best practices and potential issues and report on the mathematical abilities of language models. Finally, we shed light on the potential of LLMs to change how mathematicians work.
    
[^179]: 为所有人构建地理不可知模型的分类：消除地域偏见

    Classification for everyone : Building geography agnostic models for fairer recognition

    [https://arxiv.org/abs/2312.02957](https://arxiv.org/abs/2312.02957)

    本文分析了消除现有图像分类模型中地理偏见的方法，并探讨了如何使这些模型更加鲁棒到图像的地理位置。

    

    在本文中，我们分析了减轻现有最先进图像分类模型中固有地理偏见的不同方法。我们首先定量地展示了这种偏见在两个数据集上 - Dollar Street数据集和ImageNet上的存在，使用带有位置信息的图片。然后，我们提出了可以用来减少这种偏见的不同方法。最后，我们分析了不同技术对于使这些模型更加鲁棒到图像地理位置的有效性。

    arXiv:2312.02957v3 Announce Type: replace-cross  Abstract: In this paper, we analyze different methods to mitigate inherent geographical biases present in state of the art image classification models. We first quantitatively present this bias in two datasets - The Dollar Street Dataset and ImageNet, using images with location information. We then present different methods which can be employed to reduce this bias. Finally, we analyze the effectiveness of the different techniques on making these models more robust to geographical locations of the images.
    
[^180]: DiffiT: 用于图像生成的扩散视觉Transformer模型

    DiffiT: Diffusion Vision Transformers for Image Generation

    [https://arxiv.org/abs/2312.02139](https://arxiv.org/abs/2312.02139)

    DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。

    

    具有强大表现力和高样本质量的扩散模型在生成领域取得了最先进的性能。开创性的视觉Transformer（ViT）展现了强大的建模能力和可扩展性，特别适用于识别任务。本文研究了ViTs在基于扩散的生成学习中的有效性，并提出了一个新模型，称为Diffusion Vision Transformers（DiffiT）。具体地，我们提出了一种用于对去噪过程进行细粒度控制的方法，并引入了时间依赖的多头自注意力（TMSA）机制。DiffiT在生成高保真图像方面非常有效，参数效率也显著提高。我们还提出了基于潜空间和图像空间的DiffiT模型，并在不同分辨率的各种类别条件和非条件综合任务上展现了最先进的性能。潜空间DiffiT模型达到

    arXiv:2312.02139v2 Announce Type: replace-cross  Abstract: Diffusion models with their powerful expressivity and high sample quality have achieved State-Of-The-Art (SOTA) performance in the generative domain. The pioneering Vision Transformer (ViT) has also demonstrated strong modeling capabilities and scalability, especially for recognition tasks. In this paper, we study the effectiveness of ViTs in diffusion-based generative learning and propose a new model denoted as Diffusion Vision Transformers (DiffiT). Specifically, we propose a methodology for finegrained control of the denoising process and introduce the Time-dependant Multihead Self Attention (TMSA) mechanism. DiffiT is surprisingly effective in generating high-fidelity images with significantly better parameter efficiency. We also propose latent and image space DiffiT models and show SOTA performance on a variety of class-conditional and unconditional synthesis tasks at different resolutions. The Latent DiffiT model achieves
    
[^181]: 早期和晚期隐性偏见的二分法可以明显诱导领悟

    Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking

    [https://arxiv.org/abs/2311.18817](https://arxiv.org/abs/2311.18817)

    通过早期和晚期隐性偏见的二分法，本文证明在训练同质神经网络时会出现从核预测器到最小范数/最大间隔预测器的急剧转变，从而引发测试准确性的显著变化。

    

    Power等人（2022）最近的研究突出了学习算术任务中出现的令人惊讶的“领悟”现象：神经网络首先“记忆”训练集，导致训练准确性完美，但测试准确性接近随机，然后在训练足够长时间后，突然过渡至完美测试准确性。本文研究了领悟现象在理论设置中的情况，并展示了它可以通过早期和晚期隐性偏见的二分法来诱导。具体来说，当使用大的初始化和小的权重衰减训练同质神经网络进行分类和回归任务时，我们证明训练过程在长时间内被困在对应于核预测器的解上，然后突然出现对于最小范数/最大间隔预测器的非常明显的过渡，导致测试准确性出现显著变化。

    arXiv:2311.18817v2 Announce Type: replace-cross  Abstract: Recent work by Power et al. (2022) highlighted a surprising "grokking" phenomenon in learning arithmetic tasks: a neural net first "memorizes" the training set, resulting in perfect training accuracy but near-random test accuracy, and after training for sufficiently longer, it suddenly transitions to perfect test accuracy. This paper studies the grokking phenomenon in theoretical setups and shows that it can be induced by a dichotomy of early and late phase implicit biases. Specifically, when training homogeneous neural nets with large initialization and small weight decay on both classification and regression tasks, we prove that the training process gets trapped at a solution corresponding to a kernel predictor for a long time, and then a very sharp transition to min-norm/max-margin predictors occurs, leading to a dramatic change in test accuracy.
    
[^182]: XLB：一种基于Python的可微大规模并行晶格玻尔兹曼库

    XLB: A differentiable massively parallel lattice Boltzmann library in Python

    [https://arxiv.org/abs/2311.16080](https://arxiv.org/abs/2311.16080)

    XLB是一种基于Python的不同iable LBM库，优化了在不同硬件平台上的性能，并成功处理了数十亿个单元的模拟。

    

    LBM（晶格玻尔兹曼方法）由于其在计算可扩展性方面的算法潜力而成为解决流体动力学问题的杰出技术。我们介绍了XLB库，这是一个基于Python的可微LBM库，基于JAX平台。 XLB的架构建立在确保可访问性、可扩展性和计算性能的基础上，有效实现在CPU、TPU、多GPU和分布式多GPU或TPU系统上的缩放。该库可以轻松地扩展为具有新颖边界条件、碰撞模型或多物理模拟能力。 XLB的可微性和数据结构与广泛的基于JAX的机器学习生态系统兼容，使其能够解决基于物理的机器学习、优化和反问题。 XLB已成功扩展到处理数十亿个单元的模拟，实现每秒十亿级别的晶格更新。

    arXiv:2311.16080v3 Announce Type: replace-cross  Abstract: The lattice Boltzmann method (LBM) has emerged as a prominent technique for solving fluid dynamics problems due to its algorithmic potential for computational scalability. We introduce XLB library, a Python-based differentiable LBM library based on the JAX platform. The architecture of XLB is predicated upon ensuring accessibility, extensibility, and computational performance, enabling scaling effectively across CPU, TPU, multi-GPU, and distributed multi-GPU or TPU systems. The library can be readily augmented with novel boundary conditions, collision models, or multi-physics simulation capabilities. XLB's differentiability and data structure is compatible with the extensive JAX-based machine learning ecosystem, enabling it to address physics-based machine learning, optimization, and inverse problems. XLB has been successfully scaled to handle simulations with billions of cells, achieving giga-scale lattice updates per second. 
    
[^183]: 发现有效的土地利用规划政策

    Discovering Effective Policies for Land-Use Planning

    [https://arxiv.org/abs/2311.12304](https://arxiv.org/abs/2311.12304)

    通过学习代理模型并使用进化搜索过程，发现了可定制到不同位置的有效土地利用政策，为土地利用规划提供了一个潜在有用的工具。

    

    土地被分配给不同的用途，如森林、城市区域和农业，对陆地碳平衡和气候变化有重大影响。基于可用的土地利用变化的历史数据和相关的碳排放和吸收的模拟，可以学习到一个代理模型，从而能够高效评估决策者可选择的不同选项。然后可以使用进化搜索过程来发现特定位置的有效土地利用政策。该系统构建在Project Resilience平台上，并使用Land-Use Harmonization数据集LUH2和簿记模型BLUE进行评估。它生成可定制到不同位置的碳影响和土地利用变化量的帕累托前沿，从而为土地利用规划提供了一个潜在有用的工具。

    How areas of land are allocated for different uses, such as forests, urban areas, and agriculture, has a large effect on the terrestrial carbon balance, and therefore climate change. Based on available historical data on land-use changes and a simulation of the associated carbon emissions and removals, a surrogate model can be learned that makes it possible to evaluate the different options available to decision-makers efficiently. An evolutionary search process can then be used to discover effective land-use policies for specific locations. Such a system was built on the Project Resilience platform and evaluated with the Land-Use Harmonization dataset LUH2 and the bookkeeping model BLUE. It generates Pareto fronts that trade off carbon impact and amount of land-use change customized to different locations, thus providing a potentially useful tool for land-use planning.
    
[^184]: 具有连续动作空间的低秩马尔可夫决策过程

    Low-Rank MDPs with Continuous Action Spaces

    [https://arxiv.org/abs/2311.03564](https://arxiv.org/abs/2311.03564)

    该研究通过探索多种方法，将针对低秩MDPs的现有方法扩展到连续动作空间，同时保持近似正确的学习保证。

    

    低秩马尔可夫决策过程（MDPs）最近在强化学习（RL）领域中崭露头角，因为它们可以提供约等于正确（PAC）的学习保证，同时还可以融合ML算法进行表示学习。然而，当前对低秩MDPs的方法存在局限性，它们只考虑有限的动作空间，并且在动作数量$|\mathcal{A}| \to \infty$时给出了空洞的界限，这极大地限制了它们的适用性。在这项工作中，我们研究了将这些方法扩展到具有连续动作的设置的问题，并探讨了多种具体的方法来进行这种扩展。作为案例研究，我们考虑了FLAMBE算法（Agarwal等，2020），这是一种用于低秩MDPs的PAC RL的奖励无关方法。我们展示了，在不对算法进行任何修改的情况下，当允许动作为连续时，我们获得了类似的PAC界限。

    arXiv:2311.03564v2 Announce Type: replace-cross  Abstract: Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\mathcal{A}| \to \infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain a similar PAC bound when actions are allowed to be continuous. Specifical
    
[^185]: 分离和学习潜在混淆因素以增强用户偏好建模

    Separating and Learning Latent Confounders to Enhancing User Preferences Modeling

    [https://arxiv.org/abs/2311.03381](https://arxiv.org/abs/2311.03381)

    通过分离和学习潜在混淆因素，提高了用户偏好建模的准确性

    

    推荐模型旨在从历史反馈中捕获用户偏好，然后预测用户对候选项目的特定反馈。然而，各种未测量的混淆因素导致历史反馈中的用户偏好与真实偏好之间存在偏差，进而导致模型未达到预期的性能。现有的去偏模型要么特定于解决特定偏差，要么直接从用户历史反馈中获取辅助信息，这无法确定所学偏好是真实用户偏好还是混入未测量的混淆因素。此外，我们发现以前的推荐系统不仅是未测量的混淆因素的后继者，还会作为影响用户偏好建模的未测量混淆因素，这在先前的研究中一直被忽视。为此，我们将前述推荐系统的影响纳入考虑，并将其视为

    arXiv:2311.03381v2 Announce Type: replace-cross  Abstract: Recommender models aim to capture user preferences from historical feedback and then predict user-specific feedback on candidate items. However, the presence of various unmeasured confounders causes deviations between the user preferences in the historical feedback and the true preferences, resulting in models not meeting their expected performance. Existing debias models either (1) specific to solving one particular bias or (2) directly obtain auxiliary information from user historical feedback, which cannot identify whether the learned preferences are true user preferences or mixed with unmeasured confounders. Moreover, we find that the former recommender system is not only a successor to unmeasured confounders but also acts as an unmeasured confounder affecting user preference modeling, which has always been neglected in previous studies. To this end, we incorporate the effect of the former recommender system and treat it as
    
[^186]: 随机目标嵌入对连续输出神经机器翻译的非理性有效性

    The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation

    [https://arxiv.org/abs/2310.20620](https://arxiv.org/abs/2310.20620)

    随机目标嵌入在连续输出神经机器翻译中表现出非理性有效性，尤其在较大的数据集上并且对罕见词效果最为显著。

    

    连续输出神经机器翻译（CoNMT）将离散的下一个词预测问题替换为嵌入预测。目标嵌入空间的语义结构（即相关词之间的接近程度）在直觉上被认为至关重要。我们挑战了这一假设，并展示完全随机的输出嵌入可以胜过费力预训练的嵌入，特别是在较大的数据集上。进一步的研究显示，这一令人惊讶的效果对于罕见词最为显著，这是由于它们的嵌入的几何性质。我们通过设计一种混合策略，结合不同标记的随机和预训练嵌入，进一步阐明了这一发现。

    arXiv:2310.20620v2 Announce Type: replace  Abstract: Continuous-output neural machine translation (CoNMT) replaces the discrete next-word prediction problem with an embedding prediction. The semantic structure of the target embedding space (i.e., closeness of related words) is intuitively believed to be crucial. We challenge this assumption and show that completely random output embeddings can outperform laboriously pretrained ones, especially on larger datasets. Further investigation shows this surprising effect is strongest for rare words, due to the geometry of their embeddings. We shed further light on this finding by designing a mixed strategy that combines random and pre-trained embeddings for different tokens.
    
[^187]: 情感和动态束搜索用于故事生成

    Affective and Dynamic Beam Search for Story Generation

    [https://arxiv.org/abs/2310.15079](https://arxiv.org/abs/2310.15079)

    本文提出了一种情感故事生成器AffGen，通过引入动态束调整和情感重新排名两种新技术，在叙事中注入“有趣的转折”，并在生成充满情感和有趣的叙事方面表现出优异性能。

    

    故事具有迷人的潜力，使其成为一个引人入胜的研究领域，对娱乐、教育、治疗和认知研究具有重要意义。本文提出了一种情感故事生成器（AffGen），用于生成有趣的叙事。AffGen通过采用两种新技术——动态束调整和情感重新排名，在叙事中引入“有趣的转折”。动态束调整使用上下文多臂赌博模型鼓励不太可预测、更具吸引力的词语选择。情感重新排名基于情感强度对句子候选项进行优先排序。我们的实证评估，包括自动评估和人类评估，证明了AffGen在生成充满情感并且有趣的叙事方面优于现有的基线模型。我们的消融研究和分析提供了关于AffGen优势和劣势的见解。

    arXiv:2310.15079v1 Announce Type: cross  Abstract: Storytelling's captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies. In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives. AffGen introduces "intriguing twists" in narratives by employing two novel techniques-Dynamic Beam Sizing and Affective Reranking. Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model. Affective Reranking prioritizes sentence candidates based on affect intensity. Our empirical evaluations, both automatic and human, demonstrate AffGen's superior performance over existing baselines in generating affectively charged and interesting narratives. Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen.
    
[^188]: 重新表述、增强、推理：视觉问题的视觉基础与语言模型

    Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models

    [https://arxiv.org/abs/2310.05861](https://arxiv.org/abs/2310.05861)

    通过在输入中添加具有视觉基础的信息作为预防性澄清，可以提高模型性能，减少不充分性，并简化模型回答问题的方式。

    

    越来越多的视觉-语言任务可以在零至少训练的情况下处理，即通过将大型语言模型（LLMs）与视觉编码器相结合，形成大型视觉-语言模型（LVLMs）。尽管这具有巨大的优势，比如不需要训练数据或自定义架构，但如何将输入呈现给LVLM会对零参考模型的性能产生重大影响。特别是，以不充分方式表达的输入可能会导致错误答案，原因包括缺失视觉信息、复杂的隐含推理或语言歧义。因此，通过在输入中添加具有视觉基础的信息作为预防性澄清，应该能够通过减少不充分性提高模型性能，例如通过定位对象和消除引用歧义。类似地，在VQA设置中，改变问题的构思方式可以使模型更容易回答。

    arXiv:2310.05861v2 Announce Type: replace-cross  Abstract: An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to an LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually-grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To th
    
[^189]: 研究 PINNs 在接近有限时间爆炸的 Burgers' PDE 中的能力

    Investigating the Ability of PINNs To Solve Burgers' PDE Near Finite-Time BlowUp

    [https://arxiv.org/abs/2310.05169](https://arxiv.org/abs/2310.05169)

    通过理论分析和实验验证，研究者从严谨的视角探究了 PINNs 在接近有限时间爆炸的 Burgers' PDE 中的稳定性和泛化界限。

    

    arXiv:2310.05169v2 公告类型: 替换 摘要: 物理启发的神经网络（PINNs）在解决复杂的 PDE 时不断取得新的成就，同时在精度和推理速度之间提供了有吸引力的权衡。PDE 的一个特别具有挑战性的方面是，存在一些简单的 PDE，它们可以从光滑的初始条件开始，在有限时间内演变为奇异解。近来一些引人注目的实验表明，PINNs 可能甚至擅长检测这种有限时间的爆炸。在这项工作中，我们着手从严谨的理论视角研究 PINNs 的稳定性。首先，我们为 Burgers' PDE 推导了 PINNs 的泛化界限，在任意维度下，在允许有限时间爆炸的条件下。然后，我们通过实验表明，我们的界限与神经网络找到的替代解与真实爆炸解之间的 $\ell_2$ 距离显着相关。

    arXiv:2310.05169v2 Announce Type: replace  Abstract: Physics Informed Neural Networks (PINNs) have been achieving ever newer feats of solving complicated PDEs numerically while offering an attractive trade-off between accuracy and speed of inference. A particularly challenging aspect of PDEs is that there exist simple PDEs which can evolve into singular solutions in finite time starting from smooth initial conditions. In recent times some striking experiments have suggested that PINNs might be good at even detecting such finite-time blow-ups. In this work, we embark on a program to investigate this stability of PINNs from a rigorous theoretical viewpoint. Firstly, we derive generalization bounds for PINNs for Burgers' PDE, in arbitrary dimensions, under conditions that allow for a finite-time blow-up. Then we demonstrate via experiments that our bounds are significantly correlated to the $\ell_2$-distance of the neurally found surrogate from the true blow-up solution, when computed on 
    
[^190]: 通过预条件器解决注意力核回归问题

    Solving Attention Kernel Regression Problem via Pre-conditioner

    [https://arxiv.org/abs/2308.14304](https://arxiv.org/abs/2308.14304)

    本文通过定义两个问题，设计了用于注意力矩阵的代理快速算法及其回归问题求解算法。

    

    注意力机制是大型语言模型的关键，注意力矩阵作为这种方案的算法和计算瓶颈。本文通过定义两个问题，旨在设计用于代理注意力矩阵的快速算法以及解决回归问题。首先考虑矩阵$A\in \mathbb{R}^{n\times d}$的矩阵指数$A^\top A$作为一个代理，然后设计两种类型的回归问题的算法：对于任意正整数$j$，分别是$\min_{x\in \mathbb{R}^d}\|(A^\top A)^jx-b\|_2$和$\min_{x\in \mathbb{R}^d}\|A(A^\top A)^jx-b\|_2$。研究这些回归的算法是至关重要的，因为矩阵指数可以通过这些较小的问题逐项逼近。第二个代理是将指数逐项应用于Gram矩阵，记为$\exp(AA^\top)$，并解决回归问题$\min

    arXiv:2308.14304v2 Announce Type: replace  Abstract: The attention mechanism is the key to large language models, and the attention matrix serves as an algorithmic and computational bottleneck for such a scheme. In this paper, we define two problems, motivated by designing fast algorithms for proxy of attention matrix and solving regressions against them. Given an input matrix $A\in \mathbb{R}^{n\times d}$ with $n\gg d$ and a response vector $b$, we first consider the matrix exponential of the matrix $A^\top A$ as a proxy, and we in turn design algorithms for two types of regression problems: $\min_{x\in \mathbb{R}^d}\|(A^\top A)^jx-b\|_2$ and $\min_{x\in \mathbb{R}^d}\|A(A^\top A)^jx-b\|_2$ for any positive integer $j$. Studying algorithms for these regressions is essential, as matrix exponential can be approximated term-by-term via these smaller problems. The second proxy is applying exponential entrywise to the Gram matrix, denoted by $\exp(AA^\top)$ and solving the regression $\min
    
[^191]: 采用各向异性高斯过程从车辆轨迹中估计交通状态

    Traffic State Estimation from Vehicle Trajectories with Anisotropic Gaussian Processes

    [https://arxiv.org/abs/2303.02311](https://arxiv.org/abs/2303.02311)

    通过各向异性高斯过程的方法填补交通状态数据，提供更可靠的交通状态估计，具有统计不确定性量化。

    

    准确监测道路交通状态对各种应用至关重要，包括旅行时间预测、交通控制和交通安全。然而，传感器的缺乏经常导致交通状态数据不完整，使得获取可靠信息以进行决策变得具有挑战性。本文提出了一种新颖的方法，使用高斯过程（GP）来填补交通状态数据，以解决这一问题。我们提出了一种核旋转重新参数化方案，将标准各向同性GP核转换为各向异性核，从而更好地对交通流数据中的拥堵传播进行建模。模型参数可以通过使用来自稀疏探测车辆或环形检测器的数据进行统计推断来估计。此外，旋转的GP方法为填补后的交通状态提供了统计不确定性量化，使其更可靠。我们还将我们的方法扩展到多输出GP，这允许si

    arXiv:2303.02311v2 Announce Type: replace  Abstract: Accurately monitoring road traffic state is crucial for various applications, including travel time prediction, traffic control, and traffic safety. However, the lack of sensors often results in incomplete traffic state data, making it challenging to obtain reliable information for decision-making. This paper proposes a novel method for imputing traffic state data using Gaussian processes (GP) to address this issue. We propose a kernel rotation re-parametrization scheme that transforms a standard isotropic GP kernel into an anisotropic kernel, which can better model the congestion propagation in traffic flow data. The model parameters can be estimated by statistical inference using data from sparse probe vehicles or loop detectors. Moreover, the rotated GP method provides statistical uncertainty quantification for the imputed traffic state, making it more reliable. We also extend our approach to a multi-output GP, which allows for si
    
[^192]: 使用1-Lipschitz神经网络的带符号距离函数的鲁棒一类分类

    Robust One-Class Classification with Signed Distance Function using 1-Lipschitz Neural Networks

    [https://arxiv.org/abs/2303.01978](https://arxiv.org/abs/2303.01978)

    提出了一种新的方法OCSDF，通过学习带符号距离函数实现一类分类，提供鲁棒性边界对$l2$对抗攻击，竞争性能在表格和图像数据上，对抗攻击的鲁棒性强，连接OCC与图像生成和隐式神经表面参数。

    

    我们提出了一种新方法，称为一类带符号距离函数（OCSDF），通过可证明地学习边界支持的带符号距离函数（SDF）来执行一类分类（OCC）。支持到边界的距离可以解释为正常度分数，其使用1-Lipschitz神经网络的近似提供了对$l2$对抗攻击的鲁棒性边界，这是基于深度学习的OCC算法中一个未被充分探索的弱点。因此，OCSDF带有一种新的度量标准，称为认证AUROC，可以以与任何传统AUROC相同的成本计算。我们展示了在表格和图像数据上OCSDF与并发方法竞争，同时对抗攻击的鲁棒性要强得多，说明了其理论特性。最后，作为探索性研究展望，我们从理论和经验角度展示了OCSDF如何将OCC与图像生成和隐式神经表面参数联系起来。

    arXiv:2303.01978v2 Announce Type: replace  Abstract: We propose a new method, dubbed One Class Signed Distance Function (OCSDF), to perform One Class Classification (OCC) by provably learning the Signed Distance Function (SDF) to the boundary of the support of any distribution. The distance to the support can be interpreted as a normality score, and its approximation using 1-Lipschitz neural networks provides robustness bounds against $l2$ adversarial attacks, an under-explored weakness of deep learning-based OCC algorithms. As a result, OCSDF comes with a new metric, certified AUROC, that can be computed at the same cost as any classical AUROC. We show that OCSDF is competitive against concurrent methods on tabular and image data while being way more robust to adversarial attacks, illustrating its theoretical properties. Finally, as exploratory research perspectives, we theoretically and empirically show how OCSDF connects OCC with image generation and implicit neural surface parametr
    
[^193]: 在建筑优化测试框架（BOPTEST）中对模型预测控制算法进行基准测试

    Benchmarking Model Predictive Control Algorithms in Building Optimization Testing Framework (BOPTEST)

    [https://arxiv.org/abs/2301.13447](https://arxiv.org/abs/2301.13447)

    提出了一个基于数据驱动的建模和控制框架，加速模型评估、提供成本效益的梯度，并在模型预测控制中保持良好的预测精度，同时通过建筑优化测试框架（BOPTEST）对建模和控制性能进行广泛评估

    

    我们提出了一个基于数据驱动的建模和控制框架，用于基于物理的建筑仿真器。我们的方法包括：（a）训练加速模型评估、提供具有成本效益的梯度、并保持在模型预测控制（MPC）中回溯视野的良好预测精度的可微替代模型；以及（b）制定和解决非线性建筑空调暖通空调MPC问题。我们通过使用建筑优化测试框架（BOPTEST）中提供的各种测试案例，广泛评估建模和控制性能。我们的框架与其他建模技术兼容，并可以通过不同的控制公式进行定制，使其适应并为当前正在为BOPTEST开发的测试案例提供了前瞻设计保证。这种模块化性为在大型建筑物中设计预测控制器提供了一条道路，确保

    arXiv:2301.13447v2 Announce Type: replace-cross  Abstract: We present a data-driven modeling and control framework for physics-based building emulators. Our approach consists of: (a) Offline training of differentiable surrogate models that accelerate model evaluations, provide cost-effective gradients, and maintain good predictive accuracy for the receding horizon in Model Predictive Control (MPC), and (b) Formulating and solving nonlinear building HVAC MPC problems. We extensively evaluate the modeling and control performance using multiple surrogate models and optimization frameworks across various test cases available in the Building Optimization Testing Framework (BOPTEST). Our framework is compatible with other modeling techniques and can be customized with different control formulations, making it adaptable and future-proof for test cases currently under development for BOPTEST. This modularity provides a path towards prototyping predictive controllers in large buildings, ensurin
    
[^194]: BRAIxDet：学习使用不完整注释检测恶性乳腺病变

    BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations

    [https://arxiv.org/abs/2301.13418](https://arxiv.org/abs/2301.13418)

    本文提出了一种中间解决方案，即将训练构建为弱监督和半监督学习问题，以解决通过不完整注释数据检测恶性乳腺病变的困境

    

    从筛查乳房X线照片中检测恶性病变的方法通常是使用具有完全注释的数据集进行训练，其中图像被标记为癌症病变的定位和分类。然而，真实世界的筛查乳房X线照片数据集通常有一个部分是完全注释的，另一个部分只有全局分类的弱注释（即没有病变定位）。鉴于这类数据集的庞大规模，研究人员通常在弱注释子集面临两难选择：要么不使用它，要么完全注释它。第一种选择会降低检测准确性，因为它没有使用整个数据集，而第二种选择则过于昂贵，因为注释需要专业放射科医师完成。在本文中，我们提出了这一困境的一个中间解决方案，即将训练构建为一个我们称之为恶性

    arXiv:2301.13418v3 Announce Type: replace-cross  Abstract: Methods to detect malignant lesions from screening mammograms are usually trained with fully annotated datasets, where images are labelled with the localisation and classification of cancerous lesions. However, real-world screening mammogram datasets commonly have a subset that is fully annotated and another subset that is weakly annotated with just the global classification (i.e., without lesion localisation). Given the large size of such datasets, researchers usually face a dilemma with the weakly annotated subset: to not use it or to fully annotate it. The first option will reduce detection accuracy because it does not use the whole dataset, and the second option is too expensive given that the annotation needs to be done by expert radiologists. In this paper, we propose a middle-ground solution for the dilemma, which is to formulate the training as a weakly- and semi-supervised learning problem that we refer to as malignant
    
[^195]: 使用全并行模拟加法器网络和单ADC接口的65nm 8b激活8b加权SRAM基于充电域计算内存宏

    A 65nm 8b-Activation 8b-Weight SRAM-Based Charge-Domain Computing-in-Memory Macro Using A Fully-Parallel Analog Adder Network and A Single-ADC Interface

    [https://arxiv.org/abs/2212.04320](https://arxiv.org/abs/2212.04320)

    提出了一种具有高吞吐量的SRAM ReLU优化CD-CiM宏，可以在一个CiM周期内完成两个8b向量的MAC和ReLU，仅需进行一次A/D转换。

    

    在冯诺依曼架构中执行数据密集型任务具有挑战性，因为存在内存墙瓶颈，同时实现高性能和功耗效率。计算内存（CiM）是一种有希望的缓解方法，通过在内存中支持外设接口和数据通路，在其中进行并行原位乘累加（MAC）操作。基于充电域的SRAM CiM（CD-CiM）显示出增强功耗效率和计算精度的潜力。然而，现有的基于SRAM的CD-CiM面临着规模化挑战，以满足高性能多比特量化应用的吞吐量要求。本文提出了一种高吞吐量的SRAM ReLU优化CD-CiM宏。它能够在一个CiM周期内完成两个8b向量的MAC和ReLU，仅需进行一次A/D转换。除了用于模拟计算和A/D转换接口的非线性补偿，这项工作实现了...

    arXiv:2212.04320v2 Announce Type: replace-cross  Abstract: Performing data-intensive tasks in the von Neumann architecture is challenging to achieve both high performance and power efficiency due to the memory wall bottleneck. Computing-in-memory (CiM) is a promising mitigation approach by enabling parallel in-situ multiply-accumulate (MAC) operations within the memory with support from the peripheral interface and datapath. SRAM-based charge-domain CiM (CD-CiM) has shown its potential of enhanced power efficiency and computing accuracy. However, existing SRAM-based CD-CiM faces scaling challenges to meet the throughput requirement of high-performance multi-bit-quantization applications. This paper presents an SRAM-based high-throughput ReLU-optimized CD-CiM macro. It is capable of completing MAC and ReLU of two signed 8b vectors in one CiM cycle with only one A/D conversion. Along with non-linearity compensation for the analog computing and A/D conversion interfaces, this work achieve
    
[^196]: 可解释的特征保留流形逼近与投影的降维方法

    Interpretable Dimensionality Reduction by Feature Preserving Manifold Approximation and Projection

    [https://arxiv.org/abs/2211.09321](https://arxiv.org/abs/2211.09321)

    featMAP方法通过保留源特征，利用切线空间嵌入和各向异性投影实现了可解释的降维，能够有效解释数字分类、目标检测和对抗样本的误分类。

    

    非线性降维由于低维嵌入空间中缺少源特征而缺乏可解释性。我们提出了一种名为featMAP的可解释方法，通过切线空间嵌入来保留源特征。我们的提议的核心是利用局部奇异值分解（SVD）来逼近切线空间，并通过保持对齐将其嵌入到低维空间中。基于嵌入的切线空间，featMAP通过局部展示源特征和特征重要性实现了可解释性。此外，featMAP通过各向异性投影将数据点嵌入以保留局部相似性和原始密度。我们将featMAP应用于解释数字分类、目标检测和MNIST对抗样本。FeatMAP利用源特征明确区分数字和对象，并解释对抗样本的误分类。

    arXiv:2211.09321v2 Announce Type: replace-cross  Abstract: Nonlinear dimensionality reduction lacks interpretability due to the absence of source features in low-dimensional embedding space. We propose an interpretable method featMAP to preserve source features by tangent space embedding. The core of our proposal is to utilize local singular value decomposition (SVD) to approximate the tangent space which is embedded to low-dimensional space by maintaining the alignment. Based on the embedding tangent space, featMAP enables the interpretability by locally demonstrating the source features and feature importance. Furthermore, featMAP embeds the data points by anisotropic projection to preserve the local similarity and original density. We apply featMAP to interpreting digit classification, object detection and MNIST adversarial examples. FeatMAP uses source features to explicitly distinguish the digits and objects and to explain the misclassification of adversarial examples. We also com
    
[^197]: GIDN：用于高效链接预测的轻量级图创世扩散网络

    GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient Link Prediction

    [https://arxiv.org/abs/2210.01301](https://arxiv.org/abs/2210.01301)

    GIDN模型通过创世模块在不同特征空间中泛化了图扩散，以达到更高的性能表现。

    

    在本文中，我们提出了一种图创世扩散网络（GIDN）模型。该模型在不同特征空间中泛化了图扩散，并使用创世模块来避免复杂网络结构引起的大量计算。我们在Open Graph Benchmark（OGB）数据集上评估了GIDN模型，在ogbl-collab数据集上比AGDN表现提高了11%。

    arXiv:2210.01301v3 Announce Type: replace  Abstract: In this paper, we propose a Graph Inception Diffusion Networks(GIDN) model. This model generalizes graph diffusion in different feature spaces, and uses the inception module to avoid the large amount of computations caused by complex network structures. We evaluate GIDN model on Open Graph Benchmark(OGB) datasets, reached an 11% higher performance than AGDN on ogbl-collab dataset.
    
[^198]: 从算法到行动：改进患者护理需要因果关系

    From algorithms to action: improving patient care requires causality

    [https://arxiv.org/abs/2209.07397](https://arxiv.org/abs/2209.07397)

    改进患者护理需要考虑因果关系，建立和验证的预测模型必须对治疗决策的因果关系进行考虑，以避免在决策时造成伤害。

    

    在癌症研究中，建立和验证预测结果的兴趣很大，以支持治疗决策。然而，由于大多数结果预测模型是在不考虑治疗决策的因果关系的情况下开发和验证的，许多已发表的结果预测模型在用于决策时可能会造成伤害，尽管在验证研究中被发现准确。《美国联合癌症委员会风险模型认可核查单》对预测模型的验证指南和风险模型认可核查表无法防止在开发和验证过程中准确但在用于决策时有害的预测模型的出现。我们解释了为什么会出现这种情况以及如何构建和验证对决策有用的模型。

    arXiv:2209.07397v2 Announce Type: replace  Abstract: In cancer research there is much interest in building and validating outcome predicting outcomes to support treatment decisions. However, because most outcome prediction models are developed and validated without regard to the causal aspects of treatment decision making, many published outcome prediction models may cause harm when used for decision making, despite being found accurate in validation studies. Guidelines on prediction model validation and the checklist for risk model endorsement by the American Joint Committee on Cancer do not protect against prediction models that are accurate during development and validation but harmful when used for decision making. We explain why this is the case and how to build and validate models that are useful for decision making.
    
[^199]: 基于时间条件变分自动编码器的多变量时间序列预测中的分布漂移适应

    Distributional Drift Adaptation with Temporal Conditional Variational Autoencoder for Multivariate Time Series Forecasting

    [https://arxiv.org/abs/2209.00654](https://arxiv.org/abs/2209.00654)

    提出了一种针对多变量时间序列预测中的分布漂移问题的解决方案，使用时间条件变分自动编码器（TCVAE）来模拟动态分布依赖关系，并利用潜在变量进行预测

    

    由于现实世界中多变量时间序列（MTS）的非平稳性，随着时间推移其分布会发生变化，这被称为分布漂移。大多数现有的MTS预测模型在处理分布漂移时遭受重创，并随着时间的推移而降低预测性能。现有方法通过适应最新到达的数据或根据未来数据推导的元知识自我纠正来解决分布漂移。尽管这些方法在MTS预测中取得了巨大成功，但它们很少从分布角度捕捉内在的分布变化。因此，我们提出了一个新颖的框架：时间条件变分自动编码器（TCVAE），用于在MTS中模拟历史观察值和未来数据之间的动态分布依赖关系，并将这些依赖关系推断为一个时间条件分布以利用潜在变量。具体来说，一个新颖的时间Hawkes注意力模型

    arXiv:2209.00654v4 Announce Type: replace  Abstract: Due to the non-stationary nature, the distribution of real-world multivariate time series (MTS) changes over time, which is known as distribution drift. Most existing MTS forecasting models greatly suffer from distribution drift and degrade the forecasting performance over time. Existing methods address distribution drift via adapting to the latest arrived data or self-correcting per the meta knowledge derived from future data. Despite their great success in MTS forecasting, these methods hardly capture the intrinsic distribution changes, especially from a distributional perspective. Accordingly, we propose a novel framework temporal conditional variational autoencoder (TCVAE) to model the dynamic distributional dependencies over time between historical observations and future data in MTSs and infer the dependencies as a temporal conditional distribution to leverage latent variables. Specifically, a novel temporal Hawkes attention me
    
[^200]: 贝叶斯地板场：跨环境传输人流预测

    Bayesian Floor Field: Transferring people flow predictions across environments

    [https://arxiv.org/abs/2208.10851](https://arxiv.org/abs/2208.10851)

    提出了一种贝叶斯方法，能够结合环境几何知识和人类轨迹观察，学习人员动态，实现跨环境人流预测。

    

    映射人员动态对机器人非常重要，因为它使它们能够在人类居住的环境中共存。然而，学习人员动态模型是一个耗时的过程，需要观察大量人员在环境中移动。此外，用于映射动态的方法无法跨环境传输学习的模型。然而，建筑几何形状对人员移动的影响可以用来预测他们的动态模式，最近的研究已经开始从占用学习动态地图。到目前为止，基于轨迹和基于几何的方法尚未结合。在这项工作中，我们提出了一种新颖的贝叶斯方法来学习可以结合环境几何知识和来自人类轨迹的观察的人员动态。

    arXiv:2208.10851v2 Announce Type: replace-cross  Abstract: Mapping people dynamics is a crucial skill for robots, because it enables them to coexist in human-inhabited environments. However, learning a model of people dynamics is a time consuming process which requires observation of large amount of people moving in an environment. Moreover, approaches for mapping dynamics are unable to transfer the learned models across environments: each model is only able to describe the dynamics of the environment it has been built in. However, the impact of architectural geometry on people's movement can be used to anticipate their patterns of dynamics, and recent work has looked into learning maps of dynamics from occupancy. So far however, approaches based on trajectories and those based on geometry have not been combined. In this work we propose a novel Bayesian approach to learn people dynamics able to combine knowledge about the environment geometry with observations from human trajectories. 
    
[^201]: ReLU神经网络函数的局部和全局拓扑复杂度测量

    Local and global topological complexity measures OF ReLU neural network functions

    [https://arxiv.org/abs/2204.06062](https://arxiv.org/abs/2204.06062)

    应用广义分段线性莫尔斯理论定义和研究了ReLU神经网络函数的局部和全局拓扑复杂度，提出了一个便于计算的紧凑模型，并证明局部复杂度可以任意高。

    

    我们应用了Grunert-Kuhnel-Rote提出的广义分段线性(PL)莫尔斯理论来定义和研究全连接前馈ReLU神经网络函数 F: R^n -> R 的新局部和全局拓扑复杂度概念。在此过程中，我们展示了如何为每个这样的 F 构建一个规范多面体复合体 K(F)，并且定义了定义域到 K(F) 的形变缩并，从而得到一个方便的紧凑模型进行计算。我们还给出了一个构造，表明局部复杂度可以任意高。

    arXiv:2204.06062v2 Announce Type: replace-cross  Abstract: We apply a generalized piecewise-linear (PL) version of Morse theory due to Grunert-Kuhnel-Rote to define and study new local and global notions of topological complexity for fully-connected feedforward ReLU neural network functions, F: R^n -> R. Along the way, we show how to construct, for each such F, a canonical polytopal complex K(F) and a deformation retract of the domain onto K(F), yielding a convenient compact model for performing calculations. We also give a construction showing that local complexity can be arbitrarily high.
    
[^202]: 自监督探索中的变分动力学在深度强化学习中的应用

    Variational Dynamic for Self-Supervised Exploration in Deep Reinforcement Learning

    [https://arxiv.org/abs/2010.08755](https://arxiv.org/abs/2010.08755)

    该论文提出了一种基于条件变分推理的变分动态模型，用于在深度强化学习中解决自监督探索中的多模态性和随机性问题。

    

    强化学习中的有效探索仍然是一个具有挑战性的问题，特别是对于那些外部奖励稀疏甚至完全被忽视的任务。基于内在动机的显著进展在简单环境中表现出有希望的结果，但在具有多模态和随机动态的环境中经常陷入困境。在这项工作中，我们提出了一种基于条件变分推理的变分动态模型，以建模多模态性和随机性。我们将环境状态-动作转换视为一种条件生成过程，通过在当前状态、动作和潜变量条件下生成下一个状态的预测，从而更好地理解动态并在探索中取得更好的性能。我们推导了环境转换的负对数似然的上界，并将这样的上界用作内在奖励。

    arXiv:2010.08755v3 Announce Type: replace  Abstract: Efficient exploration remains a challenging problem in reinforcement learning, especially for tasks where extrinsic rewards from environments are sparse or even totally disregarded. Significant advances based on intrinsic motivation show promising results in simple environments but often get stuck in environments with multimodal and stochastic dynamics. In this work, we propose a variational dynamic model based on the conditional variational inference to model the multimodality and stochasticity. We consider the environmental state-action transition as a conditional generative process by generating the next-state prediction under the condition of the current state, action, and latent variable, which provides a better understanding of the dynamics and leads a better performance in exploration. We derive an upper bound of the negative log-likelihood of the environmental transition and use such an upper bound as the intrinsic reward for
    
[^203]: 图神经网络中带有Pfaffian激活函数的VC维度

    VC dimension of Graph Neural Networks with Pfaffian activation functions. (arXiv:2401.12362v1 [stat.ML])

    [http://arxiv.org/abs/2401.12362](http://arxiv.org/abs/2401.12362)

    本文分析了图神经网络（GNN）中使用不同常用激活函数（如sigmoid和双曲正切）时的VC维度，采用了Pfaffian函数理论框架，通过架构参数和合作数量提供了界限。

    

    图神经网络（GNN）近年来作为一种强大的工具出现，以数据驱动的方式学习各种图领域的任务；基于消息传递机制，GNN由于其与Weisfeiler-Lehman（WL）图同构测试密切相关的直观表达而越来越受欢迎，它们已被证明等价。从理论角度看，GNN被证明是通用逼近器，并且最近对具有分段多项式激活函数的GNN的泛化能力（即，对Vapnik Cherovenikis（VC）维度的界限）进行了研究。我们的工作目标是将对GNN的VC维度的分析扩展到其他常用激活函数，如sigmoid和双曲正切，使用Pfaffian函数理论框架。提供了与架构参数（深度，神经元数量，输入尺寸）以及与合作数量有关的界限。

    Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool to learn tasks across a wide range of graph domains in a data-driven fashion; based on a message passing mechanism, GNNs have gained increasing popularity due to their intuitive formulation, closely linked with the Weisfeiler-Lehman (WL) test for graph isomorphism, to which they have proven equivalent. From a theoretical point of view, GNNs have been shown to be universal approximators, and their generalization capability (namely, bounds on the Vapnik Chervonekis (VC) dimension) has recently been investigated for GNNs with piecewise polynomial activation functions. The aim of our work is to extend this analysis on the VC dimension of GNNs to other commonly used activation functions, such as sigmoid and hyperbolic tangent, using the framework of Pfaffian function theory. Bounds are provided with respect to architecture parameters (depth, number of neurons, input size) as well as with respect to the number of co
    
[^204]: 基于基础模型集成的联邦学习在敌对威胁下的漏洞

    Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats. (arXiv:2401.10375v1 [cs.CR])

    [http://arxiv.org/abs/2401.10375](http://arxiv.org/abs/2401.10375)

    本文研究基于基础模型集成的联邦学习在敌对威胁下的漏洞，提出了一种新的攻击策略，揭示了该模型在不同配置的联邦学习下对敌对威胁的高敏感性。

    

    联邦学习是解决与数据隐私和安全相关的机器学习的重要问题，但在某些情况下存在数据不足和不平衡问题。基础模型的出现为现有联邦学习框架的局限性提供了潜在的解决方案，例如通过生成合成数据进行模型初始化。然而，由于基础模型的内在安全性问题，将基础模型集成到联邦学习中可能引入新的风险，这方面的研究尚属未开发。为了填补这一空白，我们首次研究基于基础模型集成的联邦学习在敌对威胁下的漏洞。基于基础模型集成的联邦学习的统一框架，我们引入了一种新的攻击策略，利用基础模型的安全性问题来破坏联邦学习客户端模型。通过在图像和文本领域中使用知名模型和基准数据集进行广泛实验，我们揭示了基于基础模型集成的联邦学习在不同配置的联邦学习下对这种新威胁的高敏感性。

    Federated Learning (FL) addresses critical issues in machine learning related to data privacy and security, yet suffering from data insufficiency and imbalance under certain circumstances. The emergence of foundation models (FMs) offers potential solutions to the limitations of existing FL frameworks, e.g., by generating synthetic data for model initialization. However, due to the inherent safety concerns of FMs, integrating FMs into FL could introduce new risks, which remains largely unexplored. To address this gap, we conduct the first investigation on the vulnerability of FM integrated FL (FM-FL) under adversarial threats. Based on a unified framework of FM-FL, we introduce a novel attack strategy that exploits safety issues of FM to compromise FL client models. Through extensive experiments with well-known models and benchmark datasets in both image and text domains, we reveal the high susceptibility of the FM-FL to this new threat under various FL configurations. Furthermore, we f
    
[^205]: DEM: 航空航天中用于认证深度神经网络分类器输出的方法

    DEM: A Method for Certifying Deep Neural Network Classifier Outputs in Aerospace. (arXiv:2401.02283v1 [cs.SE])

    [http://arxiv.org/abs/2401.02283](http://arxiv.org/abs/2401.02283)

    这项工作提出了一种新的、以输出为中心的方法，通过统计验证技术来认证深度神经网络(DNN)分类器的输出。该方法能够标记可能不可靠的特定输入，以便后续由人工专家检查。与现有技术相比，该方法主要关注单个输出而不是整个DNN的认证。

    

    航空航天领域的软件开发要求遵循严格、高质量的标准。尽管在这个领域中存在着商用软件的监管指南（例如ARP-4754和DO-178），但这些指南并不适用于具有深度神经网络（DNN）组件的软件。因此，如何使航空航天系统受益于深度学习的革命尚不清楚。我们的研究旨在通过一种新颖的、以输出为中心的方法来解决这个挑战，用于DNN的认证。我们的方法采用统计验证技术，并具有能够标记DNN输出可能不可靠的特定输入的关键优势，以便后续由专家检查。为了实现这一点，我们的方法对DNN对其他附近输入的预测进行统计分析，以检测不一致性。这与现有技术相反，后者通常试图对整个DNN进行认证，而非单个输出。

    Software development in the aerospace domain requires adhering to strict, high-quality standards. While there exist regulatory guidelines for commercial software in this domain (e.g., ARP-4754 and DO-178), these do not apply to software with deep neural network (DNN) components. Consequently, it is unclear how to allow aerospace systems to benefit from the deep learning revolution. Our work here seeks to address this challenge with a novel, output-centric approach for DNN certification. Our method employs statistical verification techniques, and has the key advantage of being able to flag specific inputs for which the DNN's output may be unreliable - so that they may be later inspected by a human expert. To achieve this, our method conducts a statistical analysis of the DNN's predictions for other, nearby inputs, in order to detect inconsistencies. This is in contrast to existing techniques, which typically attempt to certify the entire DNN, as opposed to individual outputs. Our method
    
[^206]: 短期与长期无人机协调：分布式优化与深度强化学习的交汇

    Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning. (arXiv:2311.09852v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2311.09852](http://arxiv.org/abs/2311.09852)

    这项研究介绍了一种将短期计划生成和选择与分布式优化以及深度强化学习相结合的渐进方法，用于无人机的协调和规划。实验结果表明，与最先进的方法相比，该方法在动态环境中具有出色的性能。

    

    在智能城市中，支持充电技术的自主交互式无人机群可以提供引人注目的感知能力，例如交通监测和灾难响应。现有方法，包括分布式优化和深度强化学习(DRL)，旨在协调无人机以实现成本效益高、高质量的导航、感知和充电。然而，它们面临着重大挑战：短期优化在动态环境中的意外变化下并不有效，而长期学习缺乏可扩展性、韧性和灵活性。为了弥合这一差距，本文提出了一种新的渐进方法，将基于分布式优化的短期计划生成和选择与基于DRL的长期飞行方向的战略调度相结合。通过对从现实城市移动中生成的数据集进行广泛实验，表明所提出的解决方案与最先进的方法相比具有卓越的性能。

    Swarms of autonomous interactive drones, with the support of recharging technology, can provide compelling sensing capabilities in Smart Cities, such as traffic monitoring and disaster response. Existing approaches, including distributed optimization and deep reinforcement learning (DRL), aim to coordinate drones to achieve cost-effective, high-quality navigation, sensing, and charging. However, they face grand challenges: short-term optimization is not effective in dynamic environments with unanticipated changes, while long-term learning lacks scalability, resilience, and flexibility. To bridge this gap, this paper introduces a new progressive approach that combines short-term plan generation and selection based on distributed optimization with a DRL-based long-term strategic scheduling of flying direction. Extensive experimentation with datasets generated from realistic urban mobility underscores an outstanding performance of the proposed solution compared to state-of-the-art. We als
    
[^207]: FedSN：一个适用于LEO卫星网络的通用联邦学习框架

    FedSN: A General Federated Learning Framework over LEO Satellite Networks. (arXiv:2311.01483v1 [cs.LG])

    [http://arxiv.org/abs/2311.01483](http://arxiv.org/abs/2311.01483)

    FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。

    

    最近，许多低地球轨道（LEO）卫星已经由商业公司成功地发射和部署到太空中，如SpaceX。由于LEO卫星配备了多模传感器，它们不仅用于通信，还用于各种机器学习应用，如空间调制识别、遥感图像分类等。然而，由于与LEO卫星的有限接触时间（例如5分钟），地面站（GS）可能无法下载如此大量的原始感测数据进行集中模型训练。因此，联邦学习（FL）已经成为解决这个问题的有希望的解决方案，通过在设备上进行训练。不幸的是，要在LEO卫星上使用FL，我们仍然面临三个关键挑战，即i）异构计算和存储能力，ii）有限的上行速率，以及iii）模型陈旧问题。为此，我们提出了一种名为FedSN的通用FL框架来解决上述挑战，一

    Recently, a large number of Low Earth Orbit (LEO) satellites have been launched and deployed successfully in space by commercial companies, such as SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve not only for communication but also for various machine learning applications, such as space modulation recognition, remote sensing image classification, etc. However, the ground station (GS) may be incapable of downloading such a large volume of raw sensing data for centralized model training due to the limited contact time with LEO satellites (e.g. 5 minutes). Therefore, federated learning (FL) has emerged as the promising solution to address this problem via on-device training. Unfortunately, to enable FL on LEO satellites, we still face three critical challenges that are i) heterogeneous computing and memory capabilities, ii) limited uplink rate, and iii) model staleness. To this end, we propose FedSN as a general FL framework to tackle the above challenges, an
    
[^208]: Kiki还是Bouba？视觉与语言模型中的声音象征性

    Kiki or Bouba? Sound Symbolism in Vision-and-Language Models. (arXiv:2310.16781v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.16781](http://arxiv.org/abs/2310.16781)

    这项研究通过调查视觉与语言模型中的内在知识，发现它们显示了声音象征性的模式，进一步证实声音和意义之间的相关性在跨模态关联中得到了体现。

    

    尽管人类语言中的声音和意义之间的映射被认为在很大程度上是随机的，但认知科学的研究表明，在语言和人口群体之间的特定声音和意义之间存在非平凡的相关性，这种现象被称为声音象征性。在许多意义维度中，声音象征性在语言和视觉领域之间的跨模态关联方面尤为显著和充分证明。在这项工作中，我们探讨了声音象征性是否在CLIP和Stable Diffusion等视觉与语言模型中得到体现。通过使用零样本知识探测来调查这些模型的内在知识，我们发现强有力的证据表明它们确实显示了这种模式，与心理语言学中众所周知的kiki-bouba效应相一致。我们的工作提供了一种使用计算工具来展示声音象征性并理解其本质的新方法。我们的代码将公开提供。

    Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available.
    
[^209]: 探索模型架构与上下文学习能力之间的关系

    Exploring the Relationship Between Model Architecture and In-Context Learning Ability. (arXiv:2310.08049v1 [cs.LG])

    [http://arxiv.org/abs/2310.08049](http://arxiv.org/abs/2310.08049)

    现有的模型架构在上下文学习中表现最好，特别是在任务复杂性增加的情况下。不同架构对超参数设置的敏感度有所差异，且一些架构展现出平稳的学习轨迹。

    

    模型架构和执行上下文学习任务的能力之间有什么关联？在这项实证研究中，我们首次尝试回答这个问题。具体而言，我们评估了十五种模型架构在一套合成的上下文学习任务中的表现。所选的架构代表了各种范式，包括循环和卷积神经网络，变换器以及新兴的注意力替代方案。我们发现，在特定条件下，所有考虑的架构都能够执行上下文学习任务。然而，当任务复杂性增加时，当代架构表现最好。此外，我们的后续实验探索了一些影响上下文学习的因素。我们观察到，不同架构对超参数设置有不同的敏感性。我们对训练动态的研究揭示了某些架构呈现出平稳、渐进的学习轨迹，而...

    What is the relationship between model architecture and the ability to perform in-context learning? In this empirical study, we take the first steps towards answering this question. In particular, we evaluate fifteen model architectures across a suite of synthetic in-context learning tasks. The selected architectures represent a broad range of paradigms, including recurrent and convolution-based neural networks, transformers, and emerging attention alternatives. We discover that all considered architectures can perform in-context learning under certain conditions. However, contemporary architectures are found to be the best performing, especially as task complexity grows. Additionally, our follow-up experiments delve into various factors that influence in-context learning. We observe varied sensitivities among architectures with respect to hyperparameter settings. Our study of training dynamics reveals that certain architectures exhibit a smooth, progressive learning trajectory, while 
    
[^210]: Hexa: 知识驱动的对话系统的自我提升

    Hexa: Self-Improving for Knowledge-Grounded Dialogue System. (arXiv:2310.06404v1 [cs.CL])

    [http://arxiv.org/abs/2310.06404](http://arxiv.org/abs/2310.06404)

    本论文提出了一种自我提升的方法，用于改进知识驱动对话生成的中间步骤的生成性能。通过引入引导提示和修改损失函数的自举策略，提高了生成自动生成回答的多样性，并在各种基准数据集上实验证明了该方法的有效性。

    

    知识驱动的对话生成中一种常见的做法是使用模块化的方法明确地利用中间步骤（如网络搜索、记忆检索）。然而，与对话响应相比，这些步骤的数据往往难以获取，因为在普通对话中无法观察到它们。为了填补这些数据的缺失，我们开发了一种自我提升方法，以改进中间步骤的生成性能，而不需要地面真实数据。具体而言，我们提出了一种新颖的引导提示和修改的损失函数的引导自动生成回答多样性的自举方法。通过在各种基准数据集上进行实验，我们经验证明我们的方法成功地利用了自我提升机制，在生成中间和最终回答方面改善了知识驱动对话生成任务的性能。

    A common practice in knowledge-grounded dialogue generation is to explicitly utilize intermediate steps (e.g., web-search, memory retrieval) with modular approaches. However, data for such steps are often inaccessible compared to those of dialogue responses as they are unobservable in an ordinary dialogue. To fill in the absence of these data, we develop a self-improving method to improve the generative performances of intermediate steps without the ground truth data. In particular, we propose a novel bootstrapping scheme with a guided prompt and a modified loss function to enhance the diversity of appropriate self-generated responses. Through experiments on various benchmark datasets, we empirically demonstrate that our method successfully leverages a self-improving mechanism in generating intermediate and final responses and improves the performances on the task of knowledge-grounded dialogue generation.
    
[^211]: TEMPO: 基于提示的生成式预训练变换器模型用于时间序列预测

    TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting. (arXiv:2310.04948v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.04948](http://arxiv.org/abs/2310.04948)

    本文提出了一个新的框架 TEMPO，通过利用时间序列任务的两个重要归纳偏差，即将复杂交互分解和引入基于选择的提示来有效学习时间序列表示。

    

    在过去的十年中，深度学习在时间序列建模方面取得了显著进展。尽管在取得最先进的结果的同时，最好的架构在不同应用和领域之间差异很大。与此同时，在自然语言处理方面，生成式预训练变换器(GPT)通过训练一个通用模型在各种文本数据集上展现出了令人印象深刻的性能。有趣的是，探索是否GPT类型的架构可以对时间序列产生有效的影响，捕捉其内在动态属性并显著提高准确性。在本文中，我们提出了一个新颖的框架TEMPO，可以有效地学习时间序列表示。我们专注于利用时间序列任务的两种重要归纳偏差来预训练模型：(i) 对趋势、季节和残差成分复杂交互的分解；和(ii) 提出基于选择的提示以便于非分布自适应。

    The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer (GPT) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether GPT-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, TEMPO, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the selection-based prompts to facilitate distribution adaptation in non-
    
[^212]: 关于生成模型在其自己的数据上迭代训练的稳定性研究

    On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])

    [http://arxiv.org/abs/2310.00429](http://arxiv.org/abs/2310.00429)

    本文研究了生成模型在混合数据集上训练对稳定性的影响，通过证明初始生成模型足够接近数据分布并且数据比例适当，迭代训练是稳定的。

    

    深度生成模型在建模复杂数据方面取得了巨大的进展，往往展现出超过典型人类能力的样本真实性辨别能力。这一成功的关键驱动力无疑是这些模型消耗海量网络规模数据的结果。由于这些模型惊人的性能和易得性，网络上将不可避免地出现越来越多的合成内容。这个事实直接意味着生成模型的未来迭代必须面对一个现实：它们的训练数据由清洁数据和先前模型生成的人工数据组成。在本文中，我们开发了一个框架来对混合数据集（包括真实数据和合成数据）上训练生成模型对稳定性的影响进行严格研究。我们首先证明了在初始生成模型足够好地近似数据分布并且真实数据与合成数据的比例适当的情况下，迭代训练的稳定性。

    Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
    
[^213]: IBM最大量子处理器的张量网络模拟的高效方法

    Efficient tensor network simulation of IBM's largest quantum processors. (arXiv:2309.15642v1 [quant-ph])

    [http://arxiv.org/abs/2309.15642](http://arxiv.org/abs/2309.15642)

    本文展示了如何使用量子启发的二维张量网络高效模拟IBM最大的量子处理器，通过简单的张量更新实现前所未有的准确度和极低的计算资源消耗，并为最新的IBM量子机器设立了基准。

    

    我们展示了如何使用量子启发的二维张量网络来高效准确地模拟IBM最大的量子处理器，即Eagle（127个量子比特），Osprey（433个量子比特）和Condor（1121个量子比特）。我们使用基于图的投影纠缠对态（gPEPS）模拟了一个复杂的量子多体系统的动力学，具体来说，这是IBM最近在Nature 618年第500-505页（2023年）上考虑的踢击易辛实验-我们在PRB 99, 195105（2019年）中提出了这个模型。我们的结果表明，对于该模型，简单的张量更新已经足以以极低的计算资源实现非常大的前所未有的精度。除了模拟127个量子比特的原始实验外，我们还将结果扩展到433个和1121个量子比特，从而为最新的IBM量子机器设定了一个基准。我们还报道了无限多个量子比特的准确模拟。我们的结果表明，gPEPS是高效模拟量子计算机的自然工具。

    We show how quantum-inspired 2d tensor networks can be used to efficiently and accurately simulate the largest quantum processors from IBM, namely Eagle (127 qubits), Osprey (433 qubits) and Condor (1121 qubits). We simulate the dynamics of a complex quantum many-body system -- specifically, the kicked Ising experiment considered recently by IBM in Nature 618, p. 500-505 (2023) -using graph-based Projected Entangled Pair States (gPEPS), which was proposed by some of us in PRB 99, 195105 (2019). Our results show that simple tensor updates are already sufficient to achieve very large unprecedented accuracy with remarkably low computational resources for this model. Apart from simulating the original experiment for 127 qubits, we also extend our results to 433 and 1121 qubits, thus setting a benchmark for the newest IBM quantum machines. We also report accurate simulations for infinitely-many qubits. Our results show that gPEPS are a natural tool to efficiently simulate quantum computer
    
[^214]: 让PPO变得更好：基于值导向的Monte-Carlo Tree Search解码

    Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])

    [http://arxiv.org/abs/2309.15028](http://arxiv.org/abs/2309.15028)

    本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。

    

    在生成自然语言文本时，使用最新的强化学习算法，如Proximal Policy Optimization (PPO)，因此可以认为推理时间的搜索算法，如Monte-Carlo Tree Search (MCTS) 是不必要的。本文证明了通过在PPO之上集成MCTS，可以进一步提升PPO的性能。关键思想是在解码文本时，不要丢弃值网络，即PPO训练时用于评估部分输出序列的副产品，而是将其与策略网络紧密结合。具体而言，本文提出了一种称为PPO-MCTS的新颖的值导向解码算法，可以将来自PPO的值网络与推理时间产生的策略网络紧密结合。与基于MCTS的控制文本生成的先前方法相比，我们的方法的关键优势在于减少了训练和测试之间部分输出的评分机制的基本不匹配。在四个文本生成任务上的评估结果表明，PPO-MCTS可以显著提升性能。

    Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS grea
    
[^215]: 论文标题：The Rashomon Importance Distribution: 摆脱不稳定的基于单一模型的变量重要性

    The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])

    [http://arxiv.org/abs/2309.13775](http://arxiv.org/abs/2309.13775)

    提出了一种新的变量重要性框架，该框架在数据分布上是稳定的，并可以与现有的模型类和全局变量重要性指标结合使用。

    

    量化变量重要性对于回答遗传学、公共政策和医学等领域的重大问题至关重要。当前的方法通常计算给定数据集上训练的给定模型的变量重要性。然而，对于给定数据集，可能有许多模型同样能解释目标结果;如果不考虑所有可能的解释，不同的研究者可能会得出许多冲突但同样有效的结论。此外，即使考虑了给定数据集的所有可能解释，这些洞察力可能不具有普适性，因为并非所有好的解释在合理的数据扰动下都是稳定的。我们提出了一种新的变量重要性框架，该框架量化了在所有好的模型集合中的变量重要性，并且在数据分布上是稳定的。我们的框架非常灵活，可以与大多数现有的模型类和全局变量重要性指标结合使用。

    Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
    
[^216]: 梯度反击：如何滤除高频率提高解释性

    Gradient strikes back: How filtering out high frequencies improves explanations. (arXiv:2307.09591v1 [cs.AI])

    [http://arxiv.org/abs/2307.09591](http://arxiv.org/abs/2307.09591)

    本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。

    

    近年来，新型基于预测的属性方法的发展迅猛，逐渐取代了旧的基于梯度的方法来解释深度神经网络的决策。然而，预测型方法为何优于梯度型方法仍不清楚。本文从经验观察开始：这两种方法产生的属性图具有非常不同的功率谱，梯度型方法揭示了比预测型方法更多的高频内容。这一观察引发了多个问题：这种高频信息的来源是什么，它是否真正反映了系统所作出的决策？最后，为什么在多个评价指标下，预测型方法中缺乏高频信息将产生更好的可解释性分数？我们分析了三个代表性的视觉分类模型的梯度，并观察到它包含来自高频的噪声信息。

    Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthe
    
[^217]: 学习核技术用于可解释和高效的PPG信号质量评估和伪影分割

    Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])

    [http://arxiv.org/abs/2307.05385](http://arxiv.org/abs/2307.05385)

    本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。

    

    光电容抗(PPG)提供了一种低成本、非侵入性的方法来持续监测各种心血管参数。PPG信号由可穿戴设备产生，常常包含由外部因素(如人体运动)引起的大型伪影。为了确保对生理参数进行稳健和准确的提取，信号的损坏区域需要被正确地识别和处理。之前的方法依靠手工特征检测器或信号度量，结果性能不佳，或依靠深度神经网络(DNN)等机器学习技术，缺乏可解释性，计算和内存密集。在这项工作中，我们提出了一种新的方法，学习一小组可解释的卷积核，其性能与现有技术DNN方法相似，甚至更好，而参数数量比DNN方法少几个数量级。这项工作实现了高效、稳健和可解释的PPG信号质量评估和伪影分割。

    Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and int
    
[^218]: 基于Samplet基 Pursuit 的核学习方法

    Samplet basis pursuit. (arXiv:2306.10180v1 [stat.ML])

    [http://arxiv.org/abs/2306.10180](http://arxiv.org/abs/2306.10180)

    本文提出了基于Samplet坐标下核学习的方法，其中引入l1正则化项可以增加系数的稀疏性。相比于单尺度基，Samplet基可以更好地表示更多类型的信号。作者提出了使用软阈值和半光滑牛顿法解决该问题的方法，并通过实验证明了其优越性。

    

    本文考虑了基于l1正则化的Samplet坐标下的核学习问题。在Samplet基的系数上，应用l1正则化项可以强制增加稀疏性。因此，我们称这种方法为Samplet基 Pursuit。Samplet基是波形类型的有符号测度，专门用于散乱数据。它们具有与小波相似的本地化、多分辨率分析和数据压缩性质。可以在Samplet基上稀疏地表示的信号类比单尺度基上能够表示稀疏的信号类别要大得多。特别地，仅用基函数映射的几个特征叠加即可表示的所有信号也可以在Samplet坐标下实现稀疏表示。我们提出了一种高效解决该问题的方法，将软阈值和半光滑牛顿法相结合，并将该方法与快速迭代收缩阈值算法进行了比较。实验结果表明了该方法在稀疏性和预测精度方面的优势。

    We consider kernel-based learning in samplet coordinates with l1-regularization. The application of an l1-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Therefore, we call this approach samplet basis pursuit. Samplets are wavelet-type signed measures, which are tailored to scattered data. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. The class of signals that can sparsely be represented in a samplet basis is considerably larger than the class of signals which exhibit a sparse representation in the single-scale basis. In particular, every signal that can be represented by the superposition of only a few features of the canonical feature map is also sparse in samplet coordinates. We propose the efficient solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method and compare the approach to the fast iterative shrinkage thresh
    
[^219]: FasterViT：具有分层注意力的快速视觉变换器

    FasterViT: Fast Vision Transformers with Hierarchical Attention. (arXiv:2306.06189v1 [cs.CV])

    [http://arxiv.org/abs/2306.06189](http://arxiv.org/abs/2306.06189)

    本研究设计了一种新型混合CNN-ViT神经网络FasterViT，引入了具有分层注意力的方法HAT，将全局自我注意力分解为多级注意力，实现了高效的跨窗口通信。 FasterViT在精度和图像吞吐量方面达到了SOTA前沿水平，并已在分类，物体检测和分割等CV任务中得到广泛验证。

    

    本研究设计了一种新型混合CNN-ViT神经网络，命名为FasterViT，专注于计算机视觉应用中的高图像吞吐量。FasterViT将CNN中快速本地表示学习的优点与ViT中的全局建模特性相结合。我们引入了分层注意力（HAT）方法，将具有二次复杂度的全局自我注意力分解为具有较小计算成本的多级注意力。我们受益于高效的基于窗口的自我注意力，每个窗口都可以访问专门用于本地和全局表示学习的专用载体令牌。在高层次上，全局自我注意力实现了较低成本的跨窗口通信，FasterViT在精度与图像吞吐量方面实现了SOTA前沿水平，并已在各种CV任务中进行了广泛验证，包括分类，物体检测和分割。我们还展示了HAT可以用作现有CNN架构的即插即用模块，以改善性能。

    We design a new family of hybrid CNN-ViT neural networks, named FasterViT, with a focus on high image throughput for computer vision (CV) applications. FasterViT combines the benefits of fast local representation learning in CNNs and global modeling properties in ViT. Our newly introduced Hierarchical Attention (HAT) approach decomposes global self-attention with quadratic complexity into a multi-level attention with reduced computational costs. We benefit from efficient window-based self-attention. Each window has access to dedicated carrier tokens that participate in local and global representation learning. At a high level, global self-attentions enable the efficient cross-window communication at lower costs. FasterViT achieves a SOTA Pareto-front in terms of accuracy \vs image throughput. We have extensively validated its effectiveness on various CV tasks including classification, object detection and segmentation. We also show that HAT can be used as a plug-and-play module for exi
    
[^220]: N-元事实的少样本链接预测

    Few-shot Link Prediction on N-ary Facts. (arXiv:2305.06104v1 [cs.AI])

    [http://arxiv.org/abs/2305.06104](http://arxiv.org/abs/2305.06104)

    本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。

    

    N-元事实由主要三元组（头实体、关系、尾实体）和任意数量的辅助属性值对组成，这在现实世界的知识图谱中很常见。对于N-元事实的链接预测是预测其中一个元素的缺失，填补缺失元素有助于丰富知识图谱并促进许多下游应用程序。以往的研究通常需要大量高质量的数据来理解N-元事实中的元素，但这些研究忽视了少样本关系，在现实世界的场景中却很常见。因此，本文引入一个新任务——少样本N-元事实链接预测，旨在使用有限的标记实例来预测N-元事实中的缺失实体。我们也提出了一个针对N-元事实的少样本链接预测模型FLEN，它由三个模块组成：关系学习模块、支持特定调整模块和查询推理模块。

    N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-specific adjusting, and query inference modules. FLEN captures relation me
    
[^221]: 深度迁移学习在入侵检测系统中的应用：综述

    Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review. (arXiv:2304.10550v1 [cs.CR])

    [http://arxiv.org/abs/2304.10550](http://arxiv.org/abs/2304.10550)

    本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。

    

    全球范围内，外部互联网越来越多地与当代工业控制系统相连接。因此，有一个迫切的需求保护网络免受各种威胁。可以使用入侵检测系统（IDS）来保护工业活动的关键基础设施，这是一种预防性措施机制，用于识别新的危险威胁和敌对活动。本文研究了用于在许多种工业控制网络中创建IDS的最新人工智能（AI）技术，特别侧重于基于IDS的深度迁移学习（DTL）。DTL可以看作是将来自多个领域的知识融合和/或适应以增强目标任务的性能的一种信息融合。重点是当目标域中的标记数据很少时，DTL可以帮助提高IDS的性能。考虑了2015年之后的出版物。这些选定的出版物被分为三类：仅DTL和仅IDS，具有迁移学习（TL）的IDS，以及基于深度迁移学习的IDS。该研究全面回顾了入侵检测系统中深度迁移学习应用的最新技术和方法。

    Globally, the external Internet is increasingly being connected to the contemporary industrial control system. As a result, there is an immediate need to protect the network from several threats. The key infrastructure of industrial activity may be protected from harm by using an intrusion detection system (IDS), a preventive measure mechanism, to recognize new kinds of dangerous threats and hostile activities. The most recent artificial intelligence (AI) techniques used to create IDS in many kinds of industrial control networks are examined in this study, with a particular emphasis on IDS-based deep transfer learning (DTL). This latter can be seen as a type of information fusion that merge, and/or adapt knowledge from multiple domains to enhance the performance of the target task, particularly when the labeled data in the target domain is scarce. Publications issued after 2015 were taken into account. These selected publications were divided into three categories: DTL-only and IDS-onl
    
[^222]: 基于MCMC的贝叶斯神经网络：基于Python的教程

    Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])

    [http://arxiv.org/abs/2304.02595](http://arxiv.org/abs/2304.02595)

    本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。

    

    贝叶斯推断为机器学习和深度学习提供了参数估计和不确定性量化的方法。变分推断和马尔科夫链蒙特卡罗（MCMC）采样技术用于实现贝叶斯推断。在过去三十年中，MCMC方法在适应更大的模型（如深度学习）和大数据问题方面面临了许多挑战。包括梯度的高级提议（例如Langevin提议分布）提供了一种解决MCMC采样中的一些限制的方法，此外，MCMC方法通常被限制在统计学家的使用范围内，并且仍不是深度学习研究人员的主流方法。我们提供了一个MCMC方法的教程，涵盖了简单的贝叶斯线性和逻辑模型，以及贝叶斯神经网络。这个教程的目的是通过编码来弥合理论和实现之间的差距，鉴于当前MCMC方法的普及程度仍然较低。

    Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
    
[^223]: 终身学习在异常检测中的应用: 新的挑战、视角和见解

    Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights. (arXiv:2303.07557v1 [cs.LG])

    [http://arxiv.org/abs/2303.07557](http://arxiv.org/abs/2303.07557)

    本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。

    

    在许多实际领域中，异常检测具有极其重要的意义，特别是在行为不断变化的情况下。终身学习是一种新兴趋势，它能够满足需要机器学习模型在动态环境中不断适应新挑战并保留过去知识的需求。然而，目前很少有人致力于建立终身异常检测的基础，这与更广泛探索的分类设置存在本质不同的挑战。本文通过探讨、阐述和讨论终身异常检测，试图为其更广泛的采用建立基础。首先，我们解释了为什么终身异常检测很重要，定义了应对终身学习复杂性的异常检测方法设计的挑战和机会。其次，我们对学习设置和场景生成过程进行了表征，使研究人员能够使用这些工具进行终身异常检测的实验。

    Anomaly detection is of paramount importance in many real-world domains, characterized by evolving behavior. Lifelong learning represents an emerging trend, answering the need for machine learning models that continuously adapt to new challenges in dynamic environments while retaining past knowledge. However, limited efforts are dedicated to building foundations for lifelong anomaly detection, which provides intrinsically different challenges compared to the more widely explored classification setting. In this paper, we face this issue by exploring, motivating, and discussing lifelong anomaly detection, trying to build foundations for its wider adoption. First, we explain why lifelong anomaly detection is relevant, defining challenges and opportunities to design anomaly detection methods that deal with lifelong learning complexities. Second, we characterize learning settings and a scenario generation procedure that enables researchers to experiment with lifelong anomaly detection using
    
[^224]: 用鲁棒交替最小化方法在几乎线性时间内完成低秩矩阵补全

    Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time. (arXiv:2302.11068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11068](http://arxiv.org/abs/2302.11068)

    本论文提出了一种在几乎线性时间内用鲁棒交替最小化方法完成低秩矩阵补全的方法，并证明了观察几乎线性数量的条目即可恢复矩阵$M$，此方法克服了交替最小化方法需要精确计算的限制，更符合实际实现中对效率的要求。

    

    给定一个矩阵$M\in \mathbb{R}^{m\times n}$，低秩矩阵补全问题要求我们通过只观察一组指定的条目$\Omega\subseteq [m]\times [n]$来找到$M$的秩为$k$的近似$UV^\top$，其中$U\in \mathbb{R}^{m\times k}$，$V\in \mathbb{R}^{n\times k}$。本文主要研究了一种被广泛使用的方法--交替最小化框架。Jain、Netrapalli和Sanghavi~\cite{jns13}证明了如果$M$的行和列是不相干的，那么交替最小化方法可以通过观察几乎线性数量的条目可靠地恢复矩阵$M$。虽然样本复杂度之后被改进~\cite{glz17}，但交替最小化步骤要求精确计算。这阻碍了更高效算法的开发，并未描述交替最小化的实际实现，其中更新通常是近似执行，以提高效率。

    Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in \mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a few entries specified by a set of entries $\Omega\subseteq [m]\times [n]$. In particular, we examine an approach that is widely used in practice -- the alternating minimization framework. Jain, Netrapalli and Sanghavi~\cite{jns13} showed that if $M$ has incoherent rows and columns, then alternating minimization provably recovers the matrix $M$ by observing a nearly linear in $n$ number of entries. While the sample complexity has been subsequently improved~\cite{glz17}, alternating minimization steps are required to be computed exactly. This hinders the development of more efficient algorithms and fails to depict the practical implementation of alternating minimization, where the updates are usually performed approximately in favor of efficiency.  In this p
    
[^225]: 基于分层生成对抗模拟学习的自动驾驶在城市环境中的应用

    Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments. (arXiv:2302.04823v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04823](http://arxiv.org/abs/2302.04823)

    本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。

    

    对于现实中的城市导航场景，设计健壮的控制策略并不是一项简单的任务。在端到端的方法中，这些策略必须将车辆摄像头获得的高维图像映射到低级动作，如转向和油门。本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。

    Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on rewards,Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive. In this work, the hGAIL architecture was proposed to solve the autonomous navigation of a vehicle in an end-to-end approach, mapping sensory perceptions directly to low-level actions, while simultaneously learning mid-level input representations of the agent's environment. The proposed hGAIL consists of an hierarchical Adversarial Imitation Learning architecture composed of two main modules: the GAN (Generative Adversarial Nets) which generates the Bird's-
    
[^226]: 使用采样算法估计量子玻色系统的截断效应

    Estimating truncation effects of quantum bosonic systems using sampling algorithms. (arXiv:2212.08546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2212.08546](http://arxiv.org/abs/2212.08546)

    本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    

    要在基于量子比特或量子位的量子计算机上模拟玻色子，必须通过将无限维局部希尔伯特空间截断为有限维来规范理论。在寻求实际量子应用的过程中，了解截断误差有多大非常重要。通常情况下，除非我们拥有好的量子计算机，否则很难估计误差。本文表明，传统的经典设备采样方法，具体而言是马尔科夫链蒙特卡罗方法可以用现有合理的计算资源解决这个问题。我们以二维格点上的标量场理论为例演示了这个想法，其大小超过了使用确切对角化方法所能达到的范围。这种方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    To simulate bosons on a qubit- or qudit-based quantum computer, one has to regularize the theory by truncating infinite-dimensional local Hilbert spaces to finite dimensions. In the search for practical quantum applications, it is important to know how big the truncation errors can be. In general, it is not easy to estimate errors unless we have a good quantum computer. In this paper we show that traditional sampling methods on classical devices, specifically Markov Chain Monte Carlo, can address this issue with a reasonable amount of computational resources available today. As a demonstration, we apply this idea to the scalar field theory on a two-dimensional lattice, with a size that goes beyond what is achievable using exact diagonalization methods. This method can be used to estimate the resources needed for realistic quantum simulations of bosonic theories, and also, to check the validity of the results of the corresponding quantum simulations.
    
[^227]: 可靠的半监督学习中的对比可信度传播

    Contrastive Credibility Propagation for Reliable Semi-Supervised Learning. (arXiv:2211.09929v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09929](http://arxiv.org/abs/2211.09929)

    对比可信度传播采用迭代的传导式伪标签细化，将半监督学习和嘈杂标签学习统一，可在各种数据场景中可靠地超过有监督基准。

    

    生成无标签数据的标签容易出错，这使得半监督学习(Semi-Supervised Learning, SSL)变得困难。通常，我们很少了解算法何时以及为什么无法超过有监督基准。我们使用基准数据集构建了五种常见的真实世界半监督学习数据场景：少标签样本、开放域样本、嘈杂标签、有标签和无标签集合中的类别分布不均衡/错位。我们提出了一种名为对比可信度传播(Contrastive Credibility Propagation, CCP)的新算法，通过迭代的传导式伪标签细化实现深度半监督学习。CCP将半监督学习和嘈杂标签学习统一在一起，目的是在任何数据场景中可靠地超过有监督基准。与专注于子集场景的之前方法相比，CCP在所有场景中独特地超过了有监督基准，支持在标注数据或无标签数据质量未知的情况下的实践者。

    Producing labels for unlabeled data is error-prone, making semi-supervised learning (SSL) troublesome. Often, little is known about when and why an algorithm fails to outperform a supervised baseline. Using benchmark datasets, we craft five common real-world SSL data scenarios: few-label, open-set, noisy-label, and class distribution imbalance/misalignment in the labeled and unlabeled sets. We propose a novel algorithm called Contrastive Credibility Propagation (CCP) for deep SSL via iterative transductive pseudo-label refinement. CCP unifies semi-supervised learning and noisy label learning for the goal of reliably outperforming a supervised baseline in any data scenario. Compared to prior methods which focus on a subset of scenarios, CCP uniquely outperforms the supervised baseline in all scenarios, supporting practitioners when the qualities of labeled or unlabeled data are unknown.
    
[^228]: MAgNET: 面向基于网格模拟的图形U-Net架构

    MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations. (arXiv:2211.00713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00713](http://arxiv.org/abs/2211.00713)

    MAgNET是一个新颖的几何深度学习框架，基于MAg（多通道聚合）操作，采用图形U-Net架构处理任意结构（图形数据）的大维数据，能够高效地处理任意复杂的网格。

    

    在许多尖端应用中，高保真计算模型被证明速度太慢而不切实际，因此被更快的代理模型所替代。最近，深度学习技术在加速这种预测方面变得越来越重要。然而，当面对更大更复杂的问题时，它们往往表现不佳。因此，本文介绍了MAgNET：多通道聚合网络，这是一种新颖的几何深度学习框架，旨在处理任意结构（图形数据）的大维数据。MAgNET建立在MAg（多通道聚合）操作之上，它将卷积神经网络中多通道本地操作的概念推广到任意非网格输入。MAg层与所提出的新型图形池化/反池化操作交错，形成了一个图形U-Net架构，具有鲁棒性，可以高效地处理任意复杂的网格，并对大维图形结构数据进行监督学习。

    In many cutting-edge applications, high-fidelity computational models prove too slow to be practical and are thus replaced by much faster surrogate models. Recently, deep learning techniques have become increasingly important in accelerating such predictions. However, they tend to falter when faced with larger and more complex problems. Therefore, this work introduces MAgNET: Multi-channel Aggregation Network, a novel geometric deep learning framework designed to operate on large-dimensional data of arbitrary structure (graph data). MAgNET is built upon the MAg (Multichannel Aggregation) operation, which generalizes the concept of multi-channel local operations in convolutional neural networks to arbitrary non-grid inputs. The MAg layers are interleaved with the proposed novel graph pooling/unpooling operations to form a graph U-Net architecture that is robust and can handle arbitrary complex meshes, efficiently performing supervised learning on large-dimensional graph-structured data.
    
[^229]: 关于广义似然比检验和一类分类器

    On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12494](http://arxiv.org/abs/2210.12494)

    本文考虑了一类分类器和广义似然比检验的问题，证明了多层感知器神经网络和支持向量机模型在收敛时会表现为广义似然比检验。同时，作者还展示了一类最小二乘SVM在收敛时也能达到广义似然比检验的效果。

    

    一类分类（OCC）是决定观察样本是否属于目标类的问题。我们考虑在包含目标类样本的数据集上学习一个表现为广义似然比检验（GLRT）的OCC模型的问题。当目标类的统计信息可用时，GLRT解决了相同的问题。GLRT是一个众所周知且在特定条件下可证明最佳的分类器。为此，我们考虑了多层感知器神经网络（NN）和支持向量机（SVM）模型。它们使用人工数据集训练为两类分类器，其中替代类使用在目标类数据集的定义域上均匀生成的随机样本。我们证明，在适当的假设下，模型在大数据集上收敛到了GLRT。此外，我们还展示了具有适当核函数的一类最小二乘SVM（OCLSSVM）在收敛时表现为GLRT。

    One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
    
[^230]: CP-PINNs: 使用物理知识神经网络和总变差惩罚进行PDE中的变点检测

    CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty. (arXiv:2208.08626v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.08626](http://arxiv.org/abs/2208.08626)

    本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。

    

    本文展示了在参数中存在未知变点的情况下，物理知识神经网络（PINNs）可能无法正确估计偏微分方程（PDE）的动态过程。为了解决这个问题，我们提出了一个新的CP-PINNs模型，将PINNs与总变差惩罚相结合，用于准确的变点检测和PDE的发现。为了在模型拟合、PDE发现和变点检测任务之间进行最优组合，我们开发了一种新的元学习算法，利用批量学习在数据的连续批次上动态改进优化目标。在实证方面，在动态过程中存在变点的情况下，我们的方法能够准确估计参数和模型对齐，在数据中没有变点的情况下，数值上收敛到原始PINNs模型的解。

    The paper shows that Physics-Informed Neural Networks (PINNs) can fail to estimate the correct Partial Differential Equations (PDEs) dynamics in cases of unknown changepoints in the parameters. To address this, we propose a new CP-PINNs model which integrates PINNs with Total-Variation penalty for accurate changepoints detection and PDEs discovery. In order to optimally combine the tasks of model fitting, PDEs discovery, and changepoints detection, we develop a new meta-learning algorithm that exploits batch learning to dynamically refines the optimization objective when moving over the consecutive batches of the data. Empirically, in case of changepoints in the dynamics, our approach demonstrates accurate parameter estimation and model alignment, and in case of no changepoints in the data, it converges numerically to the solution from the original PINNs model.
    
[^231]: 可扩展的分布式算法在MapReduce和适应性复杂度模型中用于大小约束子模型最大化问题的研究

    Scalable Distributed Algorithms for Size-Constrained Submodular Maximization in the MapReduce and Adaptive Complexity Models. (arXiv:2206.09563v4 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.09563](http://arxiv.org/abs/2206.09563)

    本论文研究了在MapReduce和适应性复杂度模型中用于大小约束子模型最大化问题的可扩展分布式算法。通过使用几种次线性自适应算法，我们证明了这些算法满足在MR环境中所需的一致性特性，并且提出了世界首个具有恒定MR轮次的线性时间分布式算法。

    

    在MapReduce模型中对子模型函数进行分布式最大化的研究已经引起了广泛的关注，这导致了两种框架可以在MR环境中运行集中式算法而不损失逼近性能，只要集中式算法满足一定的一致性特性 - 这个特性仅由标准的贪婪算法和连续贪婪算法满足。另一方面，还有一系列的研究工作着眼于自适应复杂度模型中的子模型最大化的并行计算能力，其中每个线程可以访问整个底集。对于满足大小约束的单调子模型函数最大化问题，我们展示了几种次线性自适应算法满足在MR环境中所需的一致性特性，从而得到了高度实用的可并行计算和分布式算法。此外，我们还开发了第一个具有恒定MR轮次的线性时间分布式算法。最后，我们提供了一种增加m的方法。

    Distributed maximization of a submodular function in the MapReduce model has received much attention, culminating in two frameworks that allow a centralized algorithm to be run in the MR setting without loss of approximation, as long as the centralized algorithm satisfies a certain consistency property - which had only been shown to be satisfied by the standard greedy and continous greedy algorithms. A separate line of work has studied parallelizability of submodular maximization in the adaptive complexity model, where each thread may have access to the entire ground set. For the size-constrained maximization of a monotone and submodular function, we show that several sublinearly adaptive algorithms satisfy the consistency property required to work in the MR setting, which yields highly practical parallelizable and distributed algorithms. Also, we develop the first linear-time distributed algorithm for this problem with constant MR rounds. Finally, we provide a method to increase the m
    

