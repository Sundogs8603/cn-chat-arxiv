# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Exphormer: Sparse Transformers for Graphs.](http://arxiv.org/abs/2303.06147) | Exphormer是一种新的图形Transformer架构，采用虚拟全局节点和扩展图形的稀疏注意机制，具有与消息传递网络相竞争的准确性和线性的复杂度。在广泛的图形数据集上，Exphormer在最近提出的GraphGPS框架中展现出有竞争力的实证结果。 |
| [^2] | [StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces.](http://arxiv.org/abs/2303.06146) | 本文提出了一种简单有效的解决方案，通过使用扩张卷积来重新调整StyleGAN中浅层的接受域，从而将StyleGAN的面部操作扩展到除了裁剪对齐的人脸之外，以实现真实的面部反演和操作。 |
| [^3] | [Multiple Hands Make Light Work: Enhancing Quality and Diversity using MAP-Elites with Multiple Parallel Evolution Strategies.](http://arxiv.org/abs/2303.06137) | 本论文提出了一种新的QD算法——MAP-Elites-Multi-ES（MEMES），该算法基于进化策略（ES）和快速并行评估，通过维护具有大规模并行性的多个独立ES线程来扩展现有算法。实验表明，该算法在代数方面表现更好，是一种有效的算法创新。 |
| [^4] | [Rewarding Chatbots for Real-World Engagement with Millions of Users.](http://arxiv.org/abs/2303.06135) | 本研究提出了一种奖励系统来训练优秀的聊天机器人，利用用户反馈数据去筛选输出来提高保留率，A/B测试表明该方法能提高68%的保留率。 |
| [^5] | [Ignorance is Bliss: Robust Control via Information Gating.](http://arxiv.org/abs/2303.06121) | 本论文提出了信息门控的概念，即学习用于解决特定任务的最小信息掩码，以实现更简洁的表示。该方法适用于各种目标，并且可以改善算法性能。 |
| [^6] | [On the Fusion Strategies for Federated Decision Making.](http://arxiv.org/abs/2303.06109) | 本文考虑了联邦决策中信息聚合的问题，建立了汇集策略都导致系统的渐近正态性描述，用于计算错误概率，并通过模拟验证了理论结果。 |
| [^7] | [Long-tailed Classification from a Bayesian-decision-theory Perspective.](http://arxiv.org/abs/2303.06075) | 本论文提出了一种基于贝叶斯决策理论的通用和原则性的长尾分类框架，通过综合风险和贝叶斯深度集成方法，提出了一种改进所有类别精度的新目标，特别是“尾部”。此外，该框架允许任务自适应决策损失，从而在不同的任务中提供可证明的最优决策。 |
| [^8] | [EEG Synthetic Data Generation Using Probabilistic Diffusion Models.](http://arxiv.org/abs/2303.06068) | 本文提出一种使用概率扩散模型生成脑电合成数据的方法，从带有情感标签的EEG记录的电极-频率分布图中生成合成数据。 |
| [^9] | [Modeling Events and Interactions through Temporal Processes -- A Survey.](http://arxiv.org/abs/2303.06067) | 本文调查了通过时间过程进行事件序列建模的概率模型，分类为简单的、标记的和时空点过程，并回顾了现有的基于深度学习的方法。研究可用于解决预测和建模方面的场景。 |
| [^10] | [Non-invasive Waveform Analysis for Emergency Triage via Simulated Hemorrhage: An Experimental Study using Novel Dynamic Lower Body Negative Pressure Model.](http://arxiv.org/abs/2303.06064) | 本研究使用新颖的动态下半身负压模型模拟持续性失血水平，并通过深度学习（DL）框架分类鉴别不同程度的失血水平，为急诊分级提供新思路。 |
| [^11] | [A General Recipe for the Analysis of Randomized Multi-Armed Bandit Algorithms.](http://arxiv.org/abs/2303.06058) | 本文提出了一种通用的方法来推导随机多臂老虎机算法的遗憾界，并将其应用于多种分布模型，证明MED在所有模型下都是渐进最优的，同时为某些TS算法提供了简单的遗憾分析。同时，通过分析新的非参数TS算法（h-NPTS），本文进一步说明了方法的优越性。 |
| [^12] | [TSMixer: An all-MLP Architecture for Time Series Forecasting.](http://arxiv.org/abs/2303.06053) | 本文提出了一种全MLP架构的时间序列预测方法TSMixer，通过混合操作，利用时间和特征维度高效提取信息，在M5基准测试中表现优于最新的替代方案 |
| [^13] | [Analysis and Evaluation of Explainable Artificial Intelligence on Suicide Risk Assessment.](http://arxiv.org/abs/2303.06052) | 本研究使用了可解释人工智能技术和数据增强技术来预测自杀风险，实验结果表明决策树（DT）、随机森林（RF）和极限梯度提升（XGBoost）模型取得了最佳结果。愤怒问题、抑郁症和社交隔离是预测自杀风险的主要变量，而收入好、职业受人尊敬和接受大学教育的患者风险最小。这些结果证明了机器学习和XAI框架在自杀风险预测方面的有效性，以及它们在医疗保健和公共卫生领域的应用。 |
| [^14] | [VALERIAN: Invariant Feature Learning for IMU Sensor-based Human Activity Recognition in the Wild.](http://arxiv.org/abs/2303.06048) | 本文提出了VALERIAN，这是一种用于野外可穿戴式传感器人体活动识别的不变特征学习方法，通过为每个受试者训练具有单独任务特定层的多任务模型，VALERIAN允许单独处理噪声标签。 |
| [^15] | [One step closer to EEG based eye tracking.](http://arxiv.org/abs/2303.06039) | 该论文提出了一种新的深度神经网络(DNN)用于直接通过脑电图数据确定凝视位置，但精度仍低于基于图像的眼动追踪系统。 |
| [^16] | [Tactile-Filter: Interactive Tactile Perception for Part Mating.](http://arxiv.org/abs/2303.06034) | 本文提出了一种使用基于视觉的触觉传感器进行多对象组装的交互式感知方法，其中机器人使用触觉传感器和使用粒子滤波器的反馈机制逐步改进其对适合组装的对象的估计。 |
| [^17] | [Depression Diagnosis and Drug Response Prediction via Recurrent Neural Networks and Transformers Utilizing EEG Signals.](http://arxiv.org/abs/2303.06033) | 该论文提出了一种使用EEG信号进行抑郁症诊断和预测药物反应的方法，采用transformers能够有效地评估时间序列的时间依赖性，并获得了很高的分类准确率。 |
| [^18] | [Exploring Adversarial Attacks on Neural Networks: An Explainable Approach.](http://arxiv.org/abs/2303.06032) | 文章使用梯度热图分析了VGG-16模型对抗攻击下的响应特性，发现与高斯随机噪声相比，对抗噪声会分散网络中的集中区域，导致严重的行为偏差。此外，在许多情况下，对抗性示例只需破坏少数中间块即可误导最终决策，并且特定块更容易受到攻击。 |
| [^19] | [Sleep Quality Prediction from Wearables using Convolution Neural Networks and Ensemble Learning.](http://arxiv.org/abs/2303.06028) | 本研究使用可穿戴设备和调查数据，结合卷积神经网络、XGBoost和随机森林预测睡眠质量。 |
| [^20] | [wav2vec and its current potential to Automatic Speech Recognition in German for the usage in Digital History: A comparative assessment of available ASR-technologies for the use in cultural heritage contexts.](http://arxiv.org/abs/2303.06026) | 本文研究了使用wav2vec2的ASR模型在德语文化遗产索引中的表现，并与商业云和专有服务进行了比较。目前可以实现90％以上的识别率，但这些数字很快就会降低，一旦录音具有受限的音频质量或使用非日常或过时的语言。 |
| [^21] | [A hybrid deep-learning-metaheuristic framework to approximate discrete road network design problems.](http://arxiv.org/abs/2303.06024) | 本文提出了一种混合深度学习元启发式框架，可以在极短的时间内近似求解道路网络设计问题，适用于许多未来研究方向。 |
| [^22] | [Machine learning for sports betting: should forecasting models be optimised for accuracy or calibration?.](http://arxiv.org/abs/2303.06021) | 本文研究了机器学习应用于体育博彩问题，提出对于这个问题，模型校准比准确性更重要，并使用NBA数据展示，将预测模型优化到校准比将其优化到准确性产生更高的收益 |
| [^23] | [HARDC : A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN.](http://arxiv.org/abs/2303.06020) | 本文提出了一种新的心律失常分类方法，称为HARDC，通过利用扩张CNN和双向递归神经网络单元来生成融合特征，加上注意力机制，显著提高了模型的性能和可解释性。 |
| [^24] | [Scatter-based common spatial patterns -- a unified spatial filtering framework.](http://arxiv.org/abs/2303.06019) | 提出了一种新的空间滤波框架scaCSP，能够在二元和多类问题中普遍使用，并且可以轻松地将包含在其他散点矩阵中的更具有区分性的信息纳入其中 |
| [^25] | [Hierarchical Neural Program Synthesis.](http://arxiv.org/abs/2303.06018) | 本研究提出了一种分层组合程序来合成程序的可扩展程序合成框架，这能够避免从头合成长或更复杂的程序。 |
| [^26] | [Forecasting Solar Irradiance without Direct Observation: An Empirical Analysis.](http://arxiv.org/abs/2303.06010) | 本文对有效的太阳辐射预测方法进行了比较分析，通过利用分布在英国各地的数据和商业可用的天气数据，提出了一种不需要观测数据的系统。 |
| [^27] | [Neural Gromov-Wasserstein Optimal Transport.](http://arxiv.org/abs/2303.05978) | 该论文提出了一种使用神经网络和随机小批量优化解决Gromov-Wasserstein最优传输问题的方法，有效克服了现有方法的限制，具有较强的可扩展性和样本外估计能力，可应用于无监督对齐词嵌入等任务。 |
| [^28] | [Classifying the evolution of COVID-19 severity on patients with combined dynamic Bayesian networks and neural networks.](http://arxiv.org/abs/2303.05972) | 本研究采用动态贝叶斯网络和神经网络，对COVID-19患者的病情进行预测分类，该模型具有较高的分类准确性。 |
| [^29] | [Understanding and Constructing Latent Modality Structures in Multi-modal Representation Learning.](http://arxiv.org/abs/2303.05952) | 对比损失使模态匹配，但完美的模态对齐不利于下游预测任务。 本文提出有意义的潜在模态结构是更好的表现关键。 作者设计了三种通用方法，分别是用于模内正则化的深度特征分离损失，用于模间正则化的布朗运动桥损失以及用于模内和模间正则化的几何一致性损失。 经过广泛实验验证。 |
| [^30] | [Automotive Perception Software Development: An Empirical Investigation into Data, Annotation, and Ecosystem Challenges.](http://arxiv.org/abs/2303.05947) | 汽车感知软件中的机器学习算法的训练和验证需要大量的注释数据集。面向此类数据密集型汽车软件组件的数据和注释服务产业已经出现。面临挑战的是规定数据和注释需求，挑战OEM（原始设备制造商）与他们的软件组件、数据和注释供应商之间的合作。 |
| [^31] | [Estimating friction coefficient using generative modelling.](http://arxiv.org/abs/2303.05927) | 本文提出了一种将摩擦估计问题制定为视觉感知学习任务的方法，可以通过检测表面特征来预测摩擦力。该方法为从语义分割模型的潜在空间的回归问题。 |
| [^32] | [Variational formulations of ODE-Net as a mean-field optimal control problem and existence results.](http://arxiv.org/abs/2303.05924) | 本文分析了ODE-Net模型，并将其形式化为均场最优控制问题，证明了当描述ODE-Net向量场的神经网络对于可学习参数是线性时的存在性结果 |
| [^33] | [eBPF-based Working Set Size Estimation in Memory Management.](http://arxiv.org/abs/2303.05919) | 本文提出了一种基于eBPF的内存管理工作集大小估计框架，可有效估算WSS，避免了基于虚拟机的方法的较大开销。 |
| [^34] | [Lifelong Machine Learning Potentials.](http://arxiv.org/abs/2303.05911) | 本文提出了一种元素融合的基于原子中心的对称函数，将结构特性和元素信息相结合，发展出一种终身机器学习势能（lMLP），能够超越固定的、预训练的MLP，实现不断适应。 |
| [^35] | [Product Jacobi-Theta Boltzmann machines with score matching.](http://arxiv.org/abs/2303.05910) | 本文介绍了一种新型的受BM启发的模型：产品Jacobi-Theta玻尔兹曼机(pJTBM)，并表明可以使用Fisher差异的得分匹配方法更有效地使用pJTBM来适应概率密度，比使用原始RTBM更有效。 |
| [^36] | [Deep Anomaly Detection on Tennessee Eastman Process Data.](http://arxiv.org/abs/2303.05904) | 本论文首次全面评估并分析了用于化学过程数据的现代（深度学习）无监督异常检测方法。研究发现可在工业应用中选择适当的异常检测方法 |
| [^37] | [Distribution Preserving Source Separation With Time Frequency Predictive Models.](http://arxiv.org/abs/2303.05896) | 该论文提出了一种基于时频预测模型的分布保持源分离方法，可以有效解决现有方法的感知缺陷，提高分离结果的准确度。 |
| [^38] | [Simulation-based Bayesian inference for robotic grasping.](http://arxiv.org/abs/2303.05873) | 该论文提出了一种通过基于仿真的贝叶斯推断计算机器人抓取姿态的方法，成功率高。 |
| [^39] | [Accurate Real-time Polyp Detection in Videos from Concatenation of Latent Features Extracted from Consecutive Frames.](http://arxiv.org/abs/2303.05871) | 本文提出了一种有效的特征串联方法，通过将前一帧的特征映射并入当前帧来检测息肉，以此提高视频中自动息肉检测的性能。 |
| [^40] | [Variational Quantum Neural Networks (VQNNS) in Image Classification.](http://arxiv.org/abs/2303.05860) | 本研究探究了如何使用量子优化算法来提高量子神经网络的性能和时间复杂度，并且使用一个变分参数化电路作为输入层，可以用于图像分类。 |
| [^41] | [Decision-Making Under Uncertainty: Beyond Probabilities.](http://arxiv.org/abs/2303.05848) | 本文讨论超越传统概率理解的不确定性决策，介绍了解决部分可观测性和对抗行为的马尔科夫决策过程及其扩展。此外，本文还展示了多种解决离散和连续模型的方法。 |
| [^42] | [Contrastive Language-Image Pretrained (CLIP) Models are Powerful Out-of-Distribution Detectors.](http://arxiv.org/abs/2303.05828) | 研究表明，对比语言-图像预训练模型无需内部分布微调即可实现最先进的无监督越界检测表现，并提出是否需要新的视觉异常检测基准 |
| [^43] | [Semi-supervised Adversarial Learning for Complementary Item Recommendation.](http://arxiv.org/abs/2303.05812) | 文章提出了一种新的方法，结合商品辅助信息和标记的补充商品对来生成有效的补充推荐，用于无共同购买统计数据的商品。该方法维护每个商品类别的潜在空间，学习将分布式商品表示投影到这些类别空间中，以确定合适的推荐。 |
| [^44] | [Distributionally Robust Optimization with Probabilistic Group.](http://arxiv.org/abs/2303.05809) | 本文提出了一个新的PG-DRO框架，以概率群体成员身份为基础的分布式鲁棒优化。与以往的方法相比，该方法考虑到了软组成员身份而不是硬组注释，具有更强的灵活性和通用性。该方法适应具有组成员身份模糊性的样本，并在图像分类和自然语言处理基准测试中表现出最佳性能。 |
| [^45] | [Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals.](http://arxiv.org/abs/2303.05798) | 文章提出了一种处理协方差矩阵分布的新方法，并展示了其在M/EEG信号上的计算效率。这种方法利用了Sliced-Wasserstein距离和核方法，并证明它是一个有效的替代品，在领域适应的Wasserstein距离中被证明是非常高效的。 |
| [^46] | [Training, Architecture, and Prior for Deterministic Uncertainty Methods.](http://arxiv.org/abs/2303.05796) | 这项工作研究了确定性不确定性方法中的重要设计选择，包括解耦核心架构和不确定性头方案的训练方案、核心架构的表达能力对不确定性性能至关重要，以及与其他贝叶斯模型相反，DUMs定义的先验不会对最终性能产生强烈的影响。 |
| [^47] | [Deep Generative Fixed-filter Active Noise Control.](http://arxiv.org/abs/2303.05788) | 传统的自适应算法在处理动态噪声方面表现不佳，因此提出了一种深度学习的生成固定滤波器有源噪声控制（GFANC）方法，仅需少量先验数据即可自动生成适用于各种噪声的控制滤波器，并能够取得良好的效果。 |

# 详细

[^1]: Exphormer：用于图形的稀疏Transformer

    Exphormer: Sparse Transformers for Graphs. (arXiv:2303.06147v1 [cs.LG])

    [http://arxiv.org/abs/2303.06147](http://arxiv.org/abs/2303.06147)

    图形Transformer已成为各种图形学习和表示任务的一种有前途的体系结构。尽管它们取得了成功，但在保持与消息传递网络竞争力的精度的同时将图形Transformer扩展到大型图形仍然具有挑战性。在本文中，我们介绍了Exphormer，这是一个构建强大而可扩展的图形Transformer的框架。Exphormer由基于两个机制的稀疏注意机制组成：虚拟全局节点和扩展图形，其数学特征（例如，谱展开、伪随机性和稀疏性）产生的图形Transformer的复杂度仅与图形的大小成线性关系，同时允许我们证明所得Transformer模型的理论性质。我们展示了将Exphormer纳入最近提出的GraphGPS框架会产生具有竞争实证结果的模型，包括各种图形数据集上的最新结果。

    Graph transformers have emerged as a promising architecture for a variety of graph learning and representation tasks. Despite their successes, though, it remains challenging to scale graph transformers to large graphs while maintaining accuracy competitive with message-passing networks. In this paper, we introduce Exphormer, a framework for building powerful and scalable graph transformers. Exphormer consists of a sparse attention mechanism based on two mechanisms: virtual global nodes and expander graphs, whose mathematical characteristics, such as spectral expansion, pseduorandomness, and sparsity, yield graph transformers with complexity only linear in the size of the graph, while allowing us to prove desirable theoretical properties of the resulting transformer models. We show that incorporating \textsc{Exphormer} into the recently-proposed GraphGPS framework produces models with competitive empirical results on a wide variety of graph datasets, including state-of-the-art results o
    
[^2]: StyleGANEX：基于StyleGAN的面部操作扩展到除了裁剪对齐的人脸之外

    StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces. (arXiv:2303.06146v1 [cs.CV])

    [http://arxiv.org/abs/2303.06146](http://arxiv.org/abs/2303.06146)

    使用StyleGAN进行面部操作的最新进展取得了令人印象深刻的结果。然而，StyleGAN在固定图像分辨率下，本质上仅限于裁剪对齐的人脸。在本文中，我们通过使用扩张卷积来重新调整StyleGAN中浅层的接受域，而不改变任何模型参数，提出了一个简单有效的解决方案。这使得浅层固定大小的小特征可以扩展为可以适应变量分辨率的较大特征，使它们能够更好地表征不对齐的人脸。为了实现真实的面部反演和操作，我们引入了相应的编码器，除了潜在的样式代码外，还提供了扩展StyleGAN的第一层特征。我们在包括面部属性编辑、超分辨率、草图/面具到面部等各种分辨率的非对齐面部输入中验证了我们方法的有效性。

    Recent advances in face manipulation using StyleGAN have produced impressive results. However, StyleGAN is inherently limited to cropped aligned faces at a fixed image resolution it is pre-trained on. In this paper, we propose a simple and effective solution to this limitation by using dilated convolutions to rescale the receptive fields of shallow layers in StyleGAN, without altering any model parameters. This allows fixed-size small features at shallow layers to be extended into larger ones that can accommodate variable resolutions, making them more robust in characterizing unaligned faces. To enable real face inversion and manipulation, we introduce a corresponding encoder that provides the first-layer feature of the extended StyleGAN in addition to the latent style code. We validate the effectiveness of our method using unaligned face inputs of various resolutions in a diverse set of face manipulation tasks, including facial attribute editing, super-resolution, sketch/mask-to-face 
    
[^3]: 多手轻松完成：使用多个并行进化策略的MAP-Elites增强质量和多样性

    Multiple Hands Make Light Work: Enhancing Quality and Diversity using MAP-Elites with Multiple Parallel Evolution Strategies. (arXiv:2303.06137v1 [cs.NE])

    [http://arxiv.org/abs/2303.06137](http://arxiv.org/abs/2303.06137)

    随着硬件加速器及其相应工具的发展，在某些应用中通过快速和大规模的评估，评估已变得更加经济实惠。这种进展极大地加快了启发式算法（如质量-多样性优化）的运行时，并创造了通过规模进行算法创新的巨大潜力。在这项工作中，我们提出了MAP-Elites-Multi-ES（MEMES），这是一种基于进化策略（ES）的新型QD算法，专为快速并行评估而设计。 ME-Multi-ES在现有的MAP-Elites-ES算法基础上进行了改进，通过维护具有大规模并行性的多个独立ES线程来扩展它。我们还介绍了一种新的动态重置程序，用于自主最大化QD群体的改进。实验表明，与基于梯度和客观不可知的QD算法相比，MEMES在代数方面表现更好。

    With the development of hardware accelerators and their corresponding tools, evaluations have become more affordable through fast and massively parallel evaluations in some applications. This advancement has drastically sped up the runtime of evolution-inspired algorithms such as Quality-Diversity optimization, creating tremendous potential for algorithmic innovation through scale. In this work, we propose MAP-Elites-Multi-ES (MEMES), a novel QD algorithm based on Evolution Strategies (ES) designed for fast parallel evaluations. ME-Multi-ES builds on top of the existing MAP-Elites-ES algorithm, scaling it by maintaining multiple independent ES threads with massive parallelization. We also introduce a new dynamic reset procedure for the lifespan of the independent ES to autonomously maximize the improvement of the QD population. We show experimentally that MEMES outperforms existing gradient-based and objective-agnostic QD algorithms when compared in terms of generations. We perform thi
    
[^4]: 用于百万用户真实世界互动的聊天机器人的奖励系统

    Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v1 [cs.CL])

    [http://arxiv.org/abs/2303.06135](http://arxiv.org/abs/2303.06135)

    预训练的大型语言模型的出现导致了一系列的社交聊天机器人的部署，用于闲聊。虽然这些聊天机器人展示了语言能力和流利度，但它们并不一定引人入胜，有时候很难吸引用户。本研究调查了开发注重用户参与度的社交聊天机器人以增强保留率，特别是考察了使用人类反馈来高效开发极具吸引力的聊天机器人。所提出的方法利用从用户交互中收集的自动伪标签来训练一个奖励模型，在推理时可以用来拒绝聊天机器人模型产生的低分样本响应。引入了直观的评估指标，如平均对话长度 (MCL)，作为衡量部署聊天机器人的参与水平的代理。在Chai Research平台上，对每日新的10,000个聊天机器人用户组进行的A/B测试表明，这种方法将MCL提高了最多70％，这相当于将保留率从40％增加到68％。

    The emergence of pretrained large language models has led to the deployment of a range of social chatbots for chitchat. Although these chatbots demonstrate language ability and fluency, they are not guaranteed to be engaging and can struggle to retain users. This work investigates the development of social chatbots that prioritize user engagement to enhance retention, specifically examining the use of human feedback to efficiently develop highly engaging chatbots. The proposed approach uses automatic pseudo-labels collected from user interactions to train a reward model that can be used to reject low-scoring sample responses generated by the chatbot model at inference time. Intuitive evaluation metrics, such as mean conversation length (MCL), are introduced as proxies to measure the level of engagement of deployed chatbots. A/B testing on groups of 10,000 new daily chatbot users on the Chai Research platform shows that this approach increases the MCL by up to 70%, which translates to a
    
[^5]: 无知即福：通过信息门控实现鲁棒控制

    Ignorance is Bliss: Robust Control via Information Gating. (arXiv:2303.06121v1 [cs.LG])

    [http://arxiv.org/abs/2303.06121](http://arxiv.org/abs/2303.06121)

    信息简洁性——即使用任务所需的最小信息——为学习表示提供了有用的归纳偏置，从而通过对噪声和伪相关性具有鲁棒性而实现更好的泛化。我们提出了像素空间中的信息门控作为学习更简洁表示的一种方法。信息门控的作用是学习捕捉解决给定任务所需的最小信息的掩码。直观地说，我们的模型学习识别哪些视觉线索对于给定任务实际上很重要。我们使用信噪比的可微参数化对信号进行门控，该信噪比可应用于网络中的任意值，例如屏蔽输入层的像素。我们将我们的方法称为 InfoGating，并将其应用于各种目标，例如：多步前向和逆向动力学、Q学习、行为克隆和标准自监督任务。我们的实验表明，学习识别和使用最小信息有助于改善性能。

    Informational parsimony -- i.e., using the minimal information required for a task, -- provides a useful inductive bias for learning representations that achieve better generalization by being robust to noise and spurious correlations. We propose information gating in the pixel space as a way to learn more parsimonious representations. Information gating works by learning masks that capture only the minimal information required to solve a given task. Intuitively, our models learn to identify which visual cues actually matter for a given task. We gate information using a differentiable parameterization of the signal-to-noise ratio, which can be applied to arbitrary values in a network, e.g.~masking out pixels at the input layer. We apply our approach, which we call InfoGating, to various objectives such as: multi-step forward and inverse dynamics, Q-learning, behavior cloning, and standard self-supervised tasks. Our experiments show that learning to identify and use minimal information 
    
[^6]: 关于联邦决策中融合策略的研究

    On the Fusion Strategies for Federated Decision Making. (arXiv:2303.06109v1 [cs.LG])

    [http://arxiv.org/abs/2303.06109](http://arxiv.org/abs/2303.06109)

    本文考虑了联邦决策中信息聚合的问题，该问题涉及一组代理协作以推断自然状态，而不与中央处理器或彼此共享私人数据。我们分析了非贝叶斯社交学习策略，在该策略中，代理将其个人观察结果与贝叶斯规则相结合，形成观点（即软决策），并且中央处理器通过算术或几何平均聚合这些观点。基于我们之前的工作，我们确定两种汇集策略都导致系统的渐近正态性描述，例如，可以利用这种描述近似计算错误概率的表达式。我们通过模拟验证了理论结果并比较了两种策略。

    We consider the problem of information aggregation in federated decision making, where a group of agents collaborate to infer the underlying state of nature without sharing their private data with the central processor or each other. We analyze the non-Bayesian social learning strategy in which agents incorporate their individual observations into their opinions (i.e., soft-decisions) with Bayes rule, and the central processor aggregates these opinions by arithmetic or geometric averaging. Building on our previous work, we establish that both pooling strategies result in asymptotic normality characterization of the system, which, for instance, can be utilized in order to give approximate expressions for the error probability. We verify the theoretical findings with simulations and compare both strategies.
    
[^7]: 基于贝叶斯决策理论的长尾分类

    Long-tailed Classification from a Bayesian-decision-theory Perspective. (arXiv:2303.06075v1 [cs.LG])

    [http://arxiv.org/abs/2303.06075](http://arxiv.org/abs/2303.06075)

    由于其类概率的严重不平衡和尾部敏感性风险以及不对称的错误预测成本，长尾分类面临挑战。最近的尝试使用重新平衡损失和集合方法，但它们在很大程度上是启发式的，并且严重依赖于实证结果，缺乏理论解释。此外，现有方法忽略了决策损失，其表征了与尾部类别相关的不同成本。本文从贝叶斯决策理论的角度提出了一个通用和原则性的框架，统一了包括重新平衡和集合方法在内的现有技术，并为其有效性提供了理论证明。从这个角度出发，我们基于综合风险和贝叶斯深度集成方法，提出了一种改进所有类别精度的新目标，特别是“尾部”。此外，我们的框架允许任务自适应决策损失，从而在不同的任务中提供可证明的最优决策。

    Long-tailed classification poses a challenge due to its heavy imbalance in class probabilities and tail-sensitivity risks with asymmetric misprediction costs. Recent attempts have used re-balancing loss and ensemble methods, but they are largely heuristic and depend heavily on empirical results, lacking theoretical explanation. Furthermore, existing methods overlook the decision loss, which characterizes different costs associated with tailed classes. This paper presents a general and principled framework from a Bayesian-decision-theory perspective, which unifies existing techniques including re-balancing and ensemble methods, and provides theoretical justifications for their effectiveness. From this perspective, we derive a novel objective based on the integrated risk and a Bayesian deep-ensemble approach to improve the accuracy of all classes, especially the ``tail". Besides, our framework allows for task-adaptive decision loss which provides provably optimal decisions in varying tas
    
[^8]: 使用概率扩散模型生成脑电合成数据

    EEG Synthetic Data Generation Using Probabilistic Diffusion Models. (arXiv:2303.06068v1 [eess.SP])

    [http://arxiv.org/abs/2303.06068](http://arxiv.org/abs/2303.06068)

    脑电图（EEG）由于其无创、低成本和易于使用的特点在大脑计算机界颇具影响力，这使其成为公众广泛采用的高度理想的选项。本研究提出了一种先进的数据增强方法：使用去噪扩散概率模型生成合成EEG数据。合成数据是从带有情感标签的EEG记录的电极-频率分布图（EFDM）中生成的。为了评估所生成的合成数据的有效性，成功地进行了定性和定量与真实EEG数据的比较。 

    Electroencephalography (EEG) plays a significant role in the Brain Computer Interface (BCI) domain, due to its non-invasive nature, low cost, and ease of use, making it a highly desirable option for widespread adoption by the general public. This technology is commonly used in conjunction with deep learning techniques, the success of which is largely dependent on the quality and quantity of data used for training. To address the challenge of obtaining sufficient EEG data from individual participants while minimizing user effort and maintaining accuracy, this study proposes an advanced methodology for data augmentation: generating synthetic EEG data using denoising diffusion probabilistic models. The synthetic data are generated from electrode-frequency distribution maps (EFDMs) of emotionally labeled EEG recordings. To assess the validity of the synthetic data generated, both a qualitative and a quantitative comparison with real EEG data were successfully conducted. This study opens up
    
[^9]: 通过时间过程建模事件与交互-一项调查

    Modeling Events and Interactions through Temporal Processes -- A Survey. (arXiv:2303.06067v1 [cs.LG])

    [http://arxiv.org/abs/2303.06067](http://arxiv.org/abs/2303.06067)

    在现实世界的情况下，许多现象会产生一系列连续发生的事件。点过程提供了一种自然的数学框架，用于对这些事件序列进行建模。在本次调查中，我们调查了通过时间过程进行事件序列建模的概率模型。我们修订事件建模的概念，并提供了表征该主题文献的数学基础。我们定义了一个本体论，以基于深度学习的三个系列(简单的，标记的和时空点过程)来分类现有的方法。对于每个系列，我们系统地回顾了现有的基于深度学习的方法。最后，我们分析了提出的技术可以用于解决预测和建模方面的场景。

    In real-world scenario, many phenomena produce a collection of events that occur in continuous time. Point Processes provide a natural mathematical framework for modeling these sequences of events. In this survey, we investigate probabilistic models for modeling event sequences through temporal processes. We revise the notion of event modeling and provide the mathematical foundations that characterize the literature on the topic. We define an ontology to categorize the existing approaches in terms of three families: simple, marked, and spatio-temporal point processes. For each family, we systematically review the existing approaches based based on deep learning. Finally, we analyze the scenarios where the proposed techniques can be used for addressing prediction and modeling aspects.
    
[^10]: 非侵入式波形分析用于通过模拟失血进行急诊分级：一项使用新颖的动态下半身负压模型的实验研究。(arXiv:2303.06064v1 [eess.SP])

    Non-invasive Waveform Analysis for Emergency Triage via Simulated Hemorrhage: An Experimental Study using Novel Dynamic Lower Body Negative Pressure Model. (arXiv:2303.06064v1 [eess.SP])

    [http://arxiv.org/abs/2303.06064](http://arxiv.org/abs/2303.06064)

    探索非侵入性生理信号的先进波形分析能够诊断失血程度的程度仍不足。本研究探讨了深度学习（DL）框架分类进行下半身负压（LBNP）模拟的持续性失血水平的鉴别能力。我们使用动态LBNP协议，而不是传统的模型，在该协议中，LBNP以可预测的逐步下降的方式施加。该动态LBNP版本有助于解决时间依赖性问题，因为在现实生活中的院前设置中，由于体积复苏，血管内的血容量可能会波动。通过分割底层非侵入式信号并使用相应的LBNP目标级别对片段进行标记，实现了用于三元分类的监督式DL框架。具有两个输入的DL模型经过训练

    The extent to which advanced waveform analysis of non-invasive physiological signals can diagnose levels of hypovolemia remains insufficiently explored. The present study explores the discriminative ability of a deep learning (DL) framework to classify levels of ongoing hypovolemia, simulated via novel dynamic lower body negative pressure (LBNP) model among healthy volunteers. We used a dynamic LBNP protocol as opposed to the traditional model, where LBNP is applied in a predictable step-wise, progressively descending manner. This dynamic LBNP version assists in circumventing the problem posed in terms of time dependency, as in real-life pre-hospital settings, intravascular blood volume may fluctuate due to volume resuscitation. A supervised DL-based framework for ternary classification was realized by segmenting the underlying noninvasive signal and labeling segments with corresponding LBNP target levels. The proposed DL model with two inputs was trained with respective time-frequency
    
[^11]: 多臂老虎机算法分析的通用方法

    A General Recipe for the Analysis of Randomized Multi-Armed Bandit Algorithms. (arXiv:2303.06058v1 [cs.LG])

    [http://arxiv.org/abs/2303.06058](http://arxiv.org/abs/2303.06058)

    本文提出了一种通用的方法来推导随机多臂老虎机算法的遗憾界。 它包括检查每个臂的采样概率和分布族上的一组充分条件，以证明对数遗憾。 我们直接将其应用于两个著名的老虎机算法：最小经验差异（MED）和汤普森抽样（TS），包括单参数指数族，高斯分布，有界分布或满足其矩条件的分布的各种模型。 特别地，我们证明MED在所有这些模型下都是渐进最优的，但也为某些TS算法提供了简单的遗憾分析，其中优越性已知。 然后，我们通过分析新的非参数TS算法（h-NPTS）进一步说明了我们方法的优越性，该算法适用于具有有限h矩的某些未限制奖励分布族。

    In this paper we propose a general methodology to derive regret bounds for randomized multi-armed bandit algorithms. It consists in checking a set of sufficient conditions on the sampling probability of each arm and on the family of distributions to prove a logarithmic regret. As a direct application we revisit two famous bandit algorithms, Minimum Empirical Divergence (MED) and Thompson Sampling (TS), under various models for the distributions including single parameter exponential families, Gaussian distributions, bounded distributions, or distributions satisfying some conditions on their moments. In particular, we prove that MED is asymptotically optimal for all these models, but also provide a simple regret analysis of some TS algorithms for which the optimality is already known. We then further illustrate the interest of our approach, by analyzing a new Non-Parametric TS algorithm (h-NPTS), adapted to some families of unbounded reward distributions with a bounded h-moment. This mo
    
[^12]: TSMixer：一种全MLP架构的时间序列预测方法

    TSMixer: An all-MLP Architecture for Time Series Forecasting. (arXiv:2303.06053v1 [cs.LG])

    [http://arxiv.org/abs/2303.06053](http://arxiv.org/abs/2303.06053)

    实际的时间序列数据集通常是多变量且具有复杂的动态特性。传统的高容量体系结构，如基于递归或注意力的顺序模型已经变得流行。然而，最近的研究表明，简单的单变量线性模型可以胜过那些深度的替代方案。在本文中，我们调查了线性模型用于时间序列预测的能力，并提出了时间序列混合器（TSMixer），一种通过堆叠多层感知机（MLP）设计的体系结构。TSMixer基于沿时间和特征维度进行混合操作，以有效提取信息。在流行的学术基准测试中，易于实现的TSMixer与利用特定基准的归纳偏差的专业最新模型相当。在具有挑战性和大规模的M5基准测试中，即实际的零售数据集上，TSMixer表现优于最新的替代方案。我们的结果强调了高效提取信息的重要性

    Real-world time-series datasets are often multivariate with complex dynamics. Commonly-used high capacity architectures like recurrent- or attention-based sequential models have become popular. However, recent work demonstrates that simple univariate linear models can outperform those deep alternatives. In this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), an architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates superior performance compared to the state-of-the-art alternatives. Our results underline the importance of ef
    
[^13]: 可解释人工智能在自杀风险评估中的分析与评估

    Analysis and Evaluation of Explainable Artificial Intelligence on Suicide Risk Assessment. (arXiv:2303.06052v1 [cs.LG])

    [http://arxiv.org/abs/2303.06052](http://arxiv.org/abs/2303.06052)

    本研究探讨了可解释人工智能（XAI）技术在预测自杀风险和确定主要原因方面的有效性。利用数据增强技术和机器学习模型来预测相关风险。此外，使用SHapley Additive exPlanations（SHAP）和相关分析来排名预测中变量的重要性。实验结果表明，决策树（DT）、随机森林（RF）和极限梯度提升（XGBoost）模型取得了最佳结果，其中DT具有最佳表现，准确率为95.23%，曲线下面积（AUC）为0.95。根据SHAP的结果，愤怒问题、抑郁症和社交隔离是预测自杀风险的主要变量，而收入好、职业受人尊敬和接受大学教育的患者风险最小。结果证明了机器学习和XAI框架在自杀风险预测方面的有效性，以及它们在医疗保健和公共卫生领域的应用。

    This study investigates the effectiveness of Explainable Artificial Intelligence (XAI) techniques in predicting suicide risks and identifying the dominant causes for such behaviours. Data augmentation techniques and ML models are utilized to predict the associated risk. Furthermore, SHapley Additive exPlanations (SHAP) and correlation analysis are used to rank the importance of variables in predictions. Experimental results indicate that Decision Tree (DT), Random Forest (RF) and eXtreme Gradient Boosting (XGBoost) models achieve the best results while DT has the best performance with an accuracy of 95:23% and an Area Under Curve (AUC) of 0.95. As per SHAP results, anger problems, depression, and social isolation are the leading variables in predicting the risk of suicide, and patients with good incomes, respected occupations, and university education have the least risk. Results demonstrate the effectiveness of machine learning and XAI framework for suicide risk prediction, and they c
    
[^14]: VALERIAN：野外IMU传感器人体活动识别的不变特征学习

    VALERIAN: Invariant Feature Learning for IMU Sensor-based Human Activity Recognition in the Wild. (arXiv:2303.06048v1 [eess.SP])

    [http://arxiv.org/abs/2303.06048](http://arxiv.org/abs/2303.06048)

    从自然环境中收集到的数据通常包含显着的标签噪声，因此从受控的数据集训练的深度神经网络模型在实际部署中的适用性较差。在本研究中，我们检查了两个野外人类活动识别数据集和一种学习噪声标签的最新方法DivideMix，以了解训练数据中噪声标签的程度和影响。我们的实证分析表明，不同受试者之间的实质性领域差异导致学习噪声标签的方法违反一个关键的基本假设，即神经网络倾向于在早期训练时拟合更简单（因此更干净）的数据。受这些见解的启发，我们设计了VALERIAN，一种用于野外可穿戴式传感器人体活动识别的不变特征学习方法。通过为每个受试者训练具有单独任务特定层的多任务模型，VALERIAN允许单独处理噪声标签

    Deep neural network models for IMU sensor-based human activity recognition (HAR) that are trained from controlled, well-curated datasets suffer from poor generalizability in practical deployments. However, data collected from naturalistic settings often contains significant label noise. In this work, we examine two in-the-wild HAR datasets and DivideMix, a state-of-the-art learning with noise labels (LNL) method to understand the extent and impacts of noisy labels in training data. Our empirical analysis reveals that the substantial domain gaps among diverse subjects cause LNL methods to violate a key underlying assumption, namely, neural networks tend to fit simpler (and thus clean) data in early training epochs. Motivated by the insights, we design VALERIAN, an invariant feature learning method for in-the-wild wearable sensor-based HAR. By training a multi-task model with separate task-specific layers for each subject, VALERIAN allows noisy labels to be dealt with individually while 
    
[^15]: 一步接近基于脑电图的眼动追踪

    One step closer to EEG based eye tracking. (arXiv:2303.06039v1 [eess.SP])

    [http://arxiv.org/abs/2303.06039](http://arxiv.org/abs/2303.06039)

    本文介绍了两种方法和算法，它们可以使感兴趣的区域适应。我们介绍了一种新的深度神经网络(DNN)，可以直接使用脑电图数据来确定凝视位置。基于脑电图的眼动追踪是眼动追踪领域中一个新的且困难的研究课题，但它提供了一种替代基于图像的眼动追踪，且其输入数据集可与传统的图像处理相媲美。所呈现的DNN利用了脑电图信号的空间依赖性，并使用类似于空间滤波的卷积进行预处理脑电图信号。与现有技术相比，我们从脑电图信号中提高了直接凝视确定的精度，MAE(平均绝对误差)提高了3.5厘米，但不幸的是，与基于图像的眼动追踪相比，精度仍然明显较低，因此仍不能实现直接适用的系统。

    In this paper, we present two approaches and algorithms that adapt areas of interest We present a new deep neural network (DNN) that can be used to directly determine gaze position using EEG data. EEG-based eye tracking is a new and difficult research topic in the field of eye tracking, but it provides an alternative to image-based eye tracking with an input data set comparable to conventional image processing. The presented DNN exploits spatial dependencies of the EEG signal and uses convolutions similar to spatial filtering, which is used for preprocessing EEG signals. By this, we improve the direct gaze determination from the EEG signal compared to the state of the art by 3.5 cm MAE (Mean absolute error), but unfortunately still do not achieve a directly applicable system, since the inaccuracy is still significantly higher compared to image-based eye trackers.  Link: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FEEGGaze&mode=list
    
[^16]: Tactile-Filter: 用于配件组装的交互式触觉感知

    Tactile-Filter: Interactive Tactile Perception for Part Mating. (arXiv:2303.06034v1 [cs.RO])

    [http://arxiv.org/abs/2303.06034](http://arxiv.org/abs/2303.06034)

    人们依赖触觉和触觉传感器完成许多熟练的操作任务。 触觉传感器为我们提供了许多关于接触形态以及在任何交互期间关于对象的几何信息。 凭借这种动力，基于视觉的触觉传感器被广泛用于各种机器人感知和控制任务中。在本文中，我们提出了一种使用基于视觉的触觉传感器进行多对象组装的交互式感知方法。特别是，我们对零件组装过程中的触觉感知感兴趣，其中机器人可以使用触觉传感器和使用粒子滤波器的反馈机制逐步改进其对适合组装的对象的估计。为此，我们首先训练了一个深度神经网络，利用触觉图像来预测彼此契合的任意形状对象之间的概率对应关系。训练好的模型用于设计粒子滤波器，其具有两个用途。 首先，给定

    Humans rely on touch and tactile sensing for a lot of dexterous manipulation tasks. Our tactile sensing provides us with a lot of information regarding contact formations as well as geometric information about objects during any interaction. With this motivation, vision-based tactile sensors are being widely used for various robotic perception and control tasks. In this paper, we present a method for interactive perception using vision-based tactile sensors for multi-object assembly. In particular, we are interested in tactile perception during part mating, where a robot can use tactile sensors and a feedback mechanism using particle filter to incrementally improve its estimate of objects that fit together for assembly. To do this, we first train a deep neural network that makes use of tactile images to predict the probabilistic correspondence between arbitrarily shaped objects that fit together. The trained model is used to design a particle filter which is used twofold. First, given 
    
[^17]: 通过利用EEG信号的递归神经网络和transformers进行抑郁症诊断和药物反应预测

    Depression Diagnosis and Drug Response Prediction via Recurrent Neural Networks and Transformers Utilizing EEG Signals. (arXiv:2303.06033v1 [eess.SP])

    [http://arxiv.org/abs/2303.06033](http://arxiv.org/abs/2303.06033)

    早期诊断和治疗抑郁症对于有效治疗至关重要。然而，抑郁症作为最常见的心理疾病之一，在研究和临床实践方面仍然不太理解。在不同的治疗方法中，药物处方被广泛使用，然而这种药物治疗对许多患者并不有效。在这项工作中，我们提出了一种用于抑郁症诊断的方法以及一种用于预测患有抑郁症患者药物反应的方法，该方法使用EEG信号。方法：我们采用transformers，这是具有新颖架构的修改递归神经网络，以有效评估时间序列的时间依赖性。我们还将模型与众所周知的深度学习方案（如CNN、LSTM和CNN-LSTM）进行比较。结果：transformers平均召回率为99.41%，分类正常和MDD受试者的准确度为97.14%。此外，transformers在分类对响应者和非响应者方面也表现良好。

    The Early diagnosis and treatment of depression is essential for effective treatment. Depression, while being one of the most common mental illnesses, is still poorly understood in both research and clinical practice. Among different treatments, drug prescription is widely used, however the drug treatment is not effective for many patients. In this work, we propose a method for major depressive disorder (MDD) diagnosis as well as a method for predicting the drug response in patient with MDD using EEG signals. Method: We employ transformers, which are modified recursive neural networks with novel architecture to evaluate the time dependency of time series effectively. We also compare the model to the well-known deep learning schemes such as CNN, LSTM and CNN-LSTM. Results: The transformer achieves an average recall of 99.41% and accuracy of 97.14% for classifying normal and MDD subjects. Furthermore, the transformer also performed well in classifying responders and non-responders to the
    
[^18]: 探究神经网络的对抗攻击:一种可解释的方法

    Exploring Adversarial Attacks on Neural Networks: An Explainable Approach. (arXiv:2303.06032v1 [cs.LG])

    [http://arxiv.org/abs/2303.06032](http://arxiv.org/abs/2303.06032)

    深度学习(DL)被应用于各个领域，特别是在自动驾驶等安全关键应用中。因此，确保这些方法的鲁棒性并抵消由对抗攻击引起的不确定行为非常重要。本文使用梯度热图分析VGG-16模型的响应特性，当输入图像与对抗噪声和统计相似的高斯随机噪声混合时。特别是，我们逐层比较网络响应，以确定错误发生的位置。我们得出了几个有趣的发现。首先，与高斯随机噪声相比，有意生成的对抗噪声通过分散网络中的集中区域引起了严重的行为偏差。其次，在许多情况下，对抗性示例只需要破坏少数中间块即可误导最终决策。第三，我们的实验揭示了具体的块更容易受到攻击。 

    Deep Learning (DL) is being applied in various domains, especially in safety-critical applications such as autonomous driving. Consequently, it is of great significance to ensure the robustness of these methods and thus counteract uncertain behaviors caused by adversarial attacks. In this paper, we use gradient heatmaps to analyze the response characteristics of the VGG-16 model when the input images are mixed with adversarial noise and statistically similar Gaussian random noise. In particular, we compare the network response layer by layer to determine where errors occurred. Several interesting findings are derived. First, compared to Gaussian random noise, intentionally generated adversarial noise causes severe behavior deviation by distracting the area of concentration in the networks. Second, in many cases, adversarial examples only need to compromise a few intermediate blocks to mislead the final decision. Third, our experiments revealed that specific blocks are more vulnerable a
    
[^19]: 使用卷积神经网络和集成学习从可穿戴设备预测睡眠质量

    Sleep Quality Prediction from Wearables using Convolution Neural Networks and Ensemble Learning. (arXiv:2303.06028v1 [eess.SP])

    [http://arxiv.org/abs/2303.06028](http://arxiv.org/abs/2303.06028)

    睡眠是影响人们日常表现，幸福感和生活质量的最重要的因素之一。然而，现在可以通过佩戴设备在日常生活中无伤害地测量它。与通过摄像机记录和从图像中提取状态不同，手腕佩戴的设备可以通过加速度计，心率和心率变异性传感器直接测量。一些测量功能如下：上床时间，起床时间，入睡时间，入睡时间，唤醒后几分钟。文献中有几项关于睡眠质量和阶段预测的研究。然而，他们仅使用可穿戴设备数据来预测或关注睡眠阶段。在本研究中，我们使用NetHealth数据集，该数据集从698名大学生的可穿戴设备和调查中收集而来。近年来，深度学习算法取得了进展，它们通常比传统机器学习技术表现更好。其中，卷积神经网络用于特征提取，然后与XGBoost和随机森林一起使用进行睡眠质量预测。

    Sleep is among the most important factors affecting one's daily performance, well-being, and life quality. Nevertheless, it became possible to measure it in daily life in an unobtrusive manner with wearable devices. Rather than camera recordings and extraction of the state from the images, wrist-worn devices can measure directly via accelerometer, heart rate, and heart rate variability sensors. Some measured features can be as follows: time to bed, time out of bed, bedtime duration, minutes to fall asleep, and minutes after wake-up. There are several studies in the literature regarding sleep quality and stage prediction. However, they use only wearable data to predict or focus on the sleep stage. In this study, we use the NetHealth dataset, which is collected from 698 college students' via wearables, as well as surveys. Recently, there has been an advancement in deep learning algorithms, and they generally perform better than conventional machine learning techniques. Among them, Convol
    
[^20]: wav2vec及其在德语自动语音识别中的潜力：文化遗产场景下可用ASR技术的比较评估

    wav2vec and its current potential to Automatic Speech Recognition in German for the usage in Digital History: A comparative assessment of available ASR-technologies for the use in cultural heritage contexts. (arXiv:2303.06026v1 [eess.AS])

    [http://arxiv.org/abs/2303.06026](http://arxiv.org/abs/2303.06026)

    在本案例研究中，我们训练并发布了一个用于德语的最先进的开源自动语音识别（ASR）模型，以评估该技术在数字人文和文化遗产索引化的更大背景下的当前潜力。除了本文，我们还发布了基于wav2vec2的语音转文字模型，同时评估了我们的模型在与商用云和专有服务进行比较的历史录音语料库上的表现。虽然我们的模型取得了中等的结果，但我们发现专有云服务表现更好。正如我们的结果所显示的，目前可以实现90％以上的识别率，但这些数字很快就会降低，一旦录音具有受限的音频质量或使用非日常或过时的语言。德语中不同方言和口音的种类繁多是一个大问题。然而，本文强调了目前可用的识别质量是

    In this case study we trained and published a state-of-the-art open-source model for Automatic Speech Recognition (ASR) for German to evaluate the current potential of this technology for the use in the larger context of Digital Humanities and cultural heritage indexation. Along with this paper we publish our wav2vec2 based speech to text model while we evaluate its performance on a corpus of historical recordings we assembled compared against commercial cloud-based and proprietary services. While our model achieves moderate results, we see that proprietary cloud services fare significantly better. As our results show, recognition rates over 90 percent can currently be achieved, however, these numbers drop quickly once the recordings feature limited audio quality or use of non-every day or outworn language. A big issue is the high variety of different dialects and accents in the German language. Nevertheless, this paper highlights that the currently available quality of recognition is 
    
[^21]: 一种混合深度学习元启发式框架用于近似离散道路网络设计问题

    A hybrid deep-learning-metaheuristic framework to approximate discrete road network design problems. (arXiv:2303.06024v1 [cs.NE])

    [http://arxiv.org/abs/2303.06024](http://arxiv.org/abs/2303.06024)

    本研究提出了一种混合深度学习元启发式框架，具有双层架构，用于解决道路网络设计问题（NDPs）。我们训练一个图神经网络（GNN）来近似用户均衡（UE）交通分配问题的解，并使用训练模型得出的推论来计算遗传算法（GA）的适应函数值，以近似求解NDPs。使用两种NDP变体和一个精确求解器作为基准，我们展示了我们提出的框架可以在不到寻找最优结果所需时间的1％内提供在全局最优结果5％之内的解。此外，我们观察到许多有趣的未来方向，因此我们提出了这个主题的简要研究议程。关键观察是用GNN模型对遗传算法的推论进行适应函数值计算的时间为毫秒级，这提供了一个机会。

    This study proposes a hybrid deep-learning-metaheuristic framework with a bi-level architecture to solve road network design problems (NDPs). We train a graph neural network (GNN) to approximate the solution of the user equilibrium (UE) traffic assignment problem, and use inferences made by the trained model to calculate fitness function evaluations of a genetic algorithm (GA) to approximate solutions for NDPs. Using two NDP variants and an exact solver as benchmark, we show that our proposed framework can provide solutions within 5% gap of the global optimum results given less than 1% of the time required for finding the optimal results. Moreover, we observe many interesting future directions, thus we propose a brief research agenda for this topic. The key observation inspiring influential future research was that fitness function evaluation time using the inferences made by the GNN model for the genetic algorithm was in the order of milliseconds, which points to an opportunity and a 
    
[^22]: 体育博彩的机器学习：预测模型应该优化精度还是校准？

    Machine learning for sports betting: should forecasting models be optimised for accuracy or calibration?. (arXiv:2303.06021v1 [cs.LG])

    [http://arxiv.org/abs/2303.06021](http://arxiv.org/abs/2303.06021)

    美国体育博彩最近获得联邦合法化，这与机器学习的黄金时代相吻合。如果博彩者可以利用数据准确预测结果的概率，他们可以识别出书maker的赔率有利。由于仅在美国就是一个数十亿美元的产业，因此识别这种机会可能非常有利可图。许多研究人员已将机器学习应用于体育结果预测问题，通常使用准确性来评估预测模型的性能。我们假设，在体育博彩问题上，模型校准比准确性更重要。为了测试这个假设，我们在NBA数据上训练模型，并在一个赛季上运行博彩实验，使用已发布的赔率。通过评估各种博彩系统，我们表明，将预测模型优化到校准比将其优化到准确性产生更高的收益，平均回报率为110.42％

    Sports betting's recent federal legalisation in the USA coincides with the golden age of machine learning. If bettors can leverage data to accurately predict the probability of an outcome, they can recognise when the bookmaker's odds are in their favour. As sports betting is a multi-billion dollar industry in the USA alone, identifying such opportunities could be extremely lucrative. Many researchers have applied machine learning to the sports outcome prediction problem, generally using accuracy to evaluate the performance of forecasting models. We hypothesise that for the sports betting problem, model calibration is more important than accuracy. To test this hypothesis, we train models on NBA data over several seasons and run betting experiments on a single season, using published odds. Evaluating various betting systems, we show that optimising the forecasting model for calibration leads to greater returns than optimising for accuracy, on average (return on investment of $110.42\%$ v
    
[^23]: HARDC：一种基于心电图的心跳分类方法，使用分层注意力双结构RNN和扩张CNN(arXiv：2303.06020v1 [eess.SP])

    HARDC : A novel ECG-based heartbeat classification method to detect arrhythmia using hierarchical attention based dual structured RNN with dilated CNN. (arXiv:2303.06020v1 [eess.SP])

    [http://arxiv.org/abs/2303.06020](http://arxiv.org/abs/2303.06020)

    本文提出了一种新的混合分层注意力双向循环神经网络与扩张CNN（HARDC）方法用于心律失常分类。这解决了传统扩张卷积神经网络(CNN)模型忽略上下文之间的关联和梯度分散的问题。所提出的HARDC充分利用了扩张CNN和双向递归神经网络单元（BiGRU-BiLSTM）体系结构来生成融合特征。通过结合本地和全局特征信息和注意力机制，该模型的预测性能得到了提高。通过将融合特征与扩张CNN和分层注意力机制相结合，训练后的HARDC模型在PhysioNet 2017挑战数据集上表现出了明显的改进分类结果和特征提取的可解释性。使用连续Z-Score归一化、滤波、去噪和分段来准备原始数据。

    In this paper have developed a novel hybrid hierarchical attention-based bidirectional recurrent neural network with dilated CNN (HARDC) method for arrhythmia classification. This solves problems that arise when traditional dilated convolutional neural network (CNN) models disregard the correlation between contexts and gradient dispersion. The proposed HARDC fully exploits the dilated CNN and bidirectional recurrent neural network unit (BiGRU-BiLSTM) architecture to generate fusion features. As a result of incorporating both local and global feature information and an attention mechanism, the model's performance for prediction is improved.By combining the fusion features with a dilated CNN and a hierarchical attention mechanism, the trained HARDC model showed significantly improved classification results and interpretability of feature extraction on the PhysioNet 2017 challenge dataset. Sequential Z-Score normalization, filtering, denoising, and segmentation are used to prepare the raw
    
[^24]: 基于散点的公共空间模式-统一的空间滤波框架

    Scatter-based common spatial patterns -- a unified spatial filtering framework. (arXiv:2303.06019v1 [eess.SP])

    [http://arxiv.org/abs/2303.06019](http://arxiv.org/abs/2303.06019)

    公共空间模式（CSP）方法是一种最受欢迎的EEG分类空间滤波技术，用于基于运动想象（MI）的脑机接口（BCIs）中。然而，它仍然存在一些缺点，例如对噪声，非稳态和二元分类的限制性敏感。因此，我们提出了一种基于EEG信号的空间协方差散点矩阵的新型空间滤波框架，称为scaCSP，可以在二元和多类问题中普遍使用，而CSP只能在二元情况下将其作为一种特殊情况进行处理，只使用范围空间。我们进一步提出了子空间增强的scaCSP算法，它可以轻松地将包含在其他类间散点矩阵和类内散点矩阵的其他范围空间和零空间中的更具有区分性的信息纳入其中，在两种情况下，即零空间分量减少场景和附加空间滤波器学习场景下。

    The common spatial pattern (CSP) approach is known as one of the most popular spatial filtering techniques for EEG classification in motor imagery (MI) based brain-computer interfaces (BCIs). However, it still suffers some drawbacks such as sensitivity to noise, non-stationarity, and limitation to binary classification.Therefore, we propose a novel spatial filtering framework called scaCSP based on the scatter matrices of spatial covariances of EEG signals, which works generally in both binary and multi-class problems whereas CSP can be cast into our framework as a special case when only the range space of the between-class scatter matrix is used in binary cases.We further propose subspace enhanced scaCSP algorithms which easily permit incorporating more discriminative information contained in other range spaces and null spaces of the between-class and within-class scatter matrices in two scenarios: a nullspace components reduction scenario and an additional spatial filter learning sce
    
[^25]: 分层神经程序合成

    Hierarchical Neural Program Synthesis. (arXiv:2303.06018v1 [cs.SE])

    [http://arxiv.org/abs/2303.06018](http://arxiv.org/abs/2303.06018)

    程序合成旨在自动构建满足给定任务规范（例如输入/输出对或演示）的人类可读程序。最近的研究在各种领域取得了令人鼓舞的成果，如字符串转换、张量操作和描述具体化身代理的行为。大多数现有的程序合成方法都是从头开始合成程序，逐个令牌、逐行生成程序。这从根本上阻止了这些方法扩展到合成更长或更复杂的程序。在这项工作中，我们提出了一个可扩展的程序合成框架，该框架通过分层组合程序来合成程序。具体而言，我们首先学习任务嵌入空间和程序解码器，该解码器可以将任务嵌入解码为程序。然后，我们训练一个高层模块，以理解来自长程序的任务规范（例如输入/输出对或演示）并生成程序。

    Program synthesis aims to automatically construct human-readable programs that satisfy given task specifications, such as input/output pairs or demonstrations. Recent works have demonstrated encouraging results in a variety of domains, such as string transformation, tensor manipulation, and describing behaviors of embodied agents. Most existing program synthesis methods are designed to synthesize programs from scratch, generating a program token by token, line by line. This fundamentally prevents these methods from scaling up to synthesize programs that are longer or more complex. In this work, we present a scalable program synthesis framework that instead synthesizes a program by hierarchically composing programs. Specifically, we first learn a task embedding space and a program decoder that can decode a task embedding into a program. Then, we train a high-level module to comprehend the task specification (e.g., input/output pairs or demonstrations) from long programs and produce a se
    
[^26]: 无需直接观测预测太阳辐射：一个经验性分析

    Forecasting Solar Irradiance without Direct Observation: An Empirical Analysis. (arXiv:2303.06010v1 [cs.LG])

    [http://arxiv.org/abs/2303.06010](http://arxiv.org/abs/2303.06010)

    随着太阳能的使用增加，准确和及时的预测器对于顺畅的电网操作至关重要。有许多提出的方法来预测太阳辐射/太阳能产量。然而，许多这些方法将问题制定为时间序列，依赖于在感兴趣的位置近实时访问观测数据来生成预测。这需要访问实时数据流和足够的历史观测数据才能部署这些方法。在本文中，我们对比经典机器学习方法和最先进的深度学习的有效形式化预测问题的方法进行了深入分析。使用分布在英国各地的20个位置的数据和商业可用的天气数据，我们表明可以构建不需要访问这些数据的系统。利用其他位置的天气观测和测量，我们展示了可以创建具有预测能力的模型

    As the use of solar power increases, having accurate and timely forecasters will be essential for smooth grid operators. There are many proposed methods for forecasting solar irradiance / solar power production. However, many of these methods formulate the problem as a time-series, relying on near real-time access to observations at the location of interest to generate forecasts. This requires both access to a real-time stream of data and enough historical observations for these methods to be deployed. In this paper, we conduct a thorough analysis of effective ways to formulate the forecasting problem comparing classical machine learning approaches to state-of-the-art deep learning. Using data from 20 locations distributed throughout the UK and commercially available weather data, we show that it is possible to build systems that do not require access to this data. Leveraging weather observations and measurements from other locations we show it is possible to create models capable of a
    
[^27]: 神经格罗莫夫-华塞斯坦最优传输

    Neural Gromov-Wasserstein Optimal Transport. (arXiv:2303.05978v1 [cs.LG])

    [http://arxiv.org/abs/2303.05978](http://arxiv.org/abs/2303.05978)

    我们提出了一种可扩展的神经方法，用于解决具有内积成本的Gromov-Wasserstein（GW）最优传输（OT）问题。在这个问题中，给定支持在（可能不同的）空间上的两个分布，必须在它们之间找到最同构的映射。我们提出的方法使用神经网络和随机小批量优化，克服了现有GW方法的限制，例如随着样本数量的增加而出现的可扩展性差和缺乏样本外估计。为了展示我们所提出的方法的有效性，我们在合成数据上进行实验，并探讨了我们的方法在无监督对齐词嵌入的流行任务中的实际适用性。

    We present a scalable neural method to solve the Gromov-Wasserstein (GW) Optimal Transport (OT) problem with the inner product cost. In this problem, given two distributions supported on (possibly different) spaces, one has to find the most isometric map between them. Our proposed approach uses neural networks and stochastic mini-batch optimization which allows to overcome the limitations of existing GW methods such as their poor scalability with the number of samples and the lack of out-of-sample estimation. To demonstrate the effectiveness of our proposed method, we conduct experiments on the synthetic data and explore the practical applicability of our method to the popular task of the unsupervised alignment of word embeddings.
    
[^28]: 采用动态贝叶斯网络和神经网络对COVID-19患者病情演变进行分类

    Classifying the evolution of COVID-19 severity on patients with combined dynamic Bayesian networks and neural networks. (arXiv:2303.05972v1 [cs.LG])

    [http://arxiv.org/abs/2303.05972](http://arxiv.org/abs/2303.05972)

    当我们面对到达医院的患者患病的影响时，我们会面临一个主要问题，即评估这些患者是否在不久的将来需要重症监护。这种重症监护需要分配宝贵而稀缺的资源，预先知道患者疾病的严重程度可以改善其治疗和资源组织。我们在由西班牙COVID-19患者组成的数据集中说明了这个问题，其中我们将患者标记为重症患者，当他们不得不进入重症监护室或去世时。然后，我们结合使用动态贝叶斯网络，对未来40小时内患者的生命体征和血液分析结果进行预测，并使用神经网络评估患者在该时间间隔内的疾病严重程度。我们的实证结果表明，使用DBN将患者当前状态转移到未来值可以提高模型的准确性，我们的模型具有很高的分类准确性。

    When we face patients arriving to a hospital suffering from the effects of some illness, one of the main problems we can encounter is evaluating whether or not said patients are going to require intensive care in the near future. This intensive care requires allotting valuable and scarce resources, and knowing beforehand the severity of a patients illness can improve both its treatment and the organization of resources. We illustrate this issue in a dataset consistent of Spanish COVID-19 patients from the sixth epidemic wave where we label patients as critical when they either had to enter the intensive care unit or passed away. We then combine the use of dynamic Bayesian networks, to forecast the vital signs and the blood analysis results of patients over the next 40 hours, and neural networks, to evaluate the severity of a patients disease in that interval of time. Our empirical results show that the transposition of the current state of a patient to future values with the DBN for it
    
[^29]: 理解和构建多模态表示学习中的潜在模态结构

    Understanding and Constructing Latent Modality Structures in Multi-modal Representation Learning. (arXiv:2303.05952v1 [cs.LG])

    [http://arxiv.org/abs/2303.05952](http://arxiv.org/abs/2303.05952)

    对比损失在从多个模态学习表示中的应用越来越广泛。 在极限情况下，对比损失的本质促使模态在潜在空间中完全匹配。 然而，模态对齐如何影响下游任务性能仍然是一个开放的问题。 基于信息理论的论据，本文首先证明一般情况下精确的模态对齐是次优的下游预测任务。 因此，我们主张更好的表现关键在于有意义的潜在模态结构，而不是完美的模态对齐。 为此，我们提出了三种构建潜在模态结构的通用方法。 具体而言，我们设计了1）用于模内正则化的深度特征分离损失； 2）用于模间正则化的布朗运动桥损失； 3）用于模内和模间正则化的几何一致性损失。 在两个流行的数据集上进行了广泛的实验。

    Contrastive loss has been increasingly used in learning representations from multiple modalities. In the limit, the nature of the contrastive loss encourages modalities to exactly match each other in the latent space. Yet it remains an open question how the modality alignment affects the downstream task performance. In this paper, based on an information-theoretic argument, we first prove that exact modality alignment is sub-optimal in general for downstream prediction tasks. Hence we advocate that the key of better performance lies in meaningful latent modality structures instead of perfect modality alignment. To this end, we propose three general approaches to construct latent modality structures. Specifically, we design 1) a deep feature separation loss for intra-modality regularization; 2) a Brownian-bridge loss for inter-modality regularization; and 3) a geometric consistency loss for both intra- and inter-modality regularization. Extensive experiments are conducted on two popular
    
[^30]: 汽车感知软件开发：数据、注释和生态系统挑战的实证调查

    Automotive Perception Software Development: An Empirical Investigation into Data, Annotation, and Ecosystem Challenges. (arXiv:2303.05947v1 [cs.SE])

    [http://arxiv.org/abs/2303.05947](http://arxiv.org/abs/2303.05947)

    包含机器学习算法的软件是汽车感知的重要组成部分，例如在驾驶自动化系统中。这种软件的开发，特别是机器学习组件的训练和验证，需要大量的注释数据集。一个数据和注释服务产业已经出现，为这种数据密集型汽车软件组件的开发提供服务。广泛存在的困难在于规定数据和注释需求，挑战OEM（原始设备制造商）与他们的软件组件、数据和注释供应商之间的合作。本文研究了瑞典汽车工业从业者在为数据和注释制定清晰规范方面遇到的困难的原因。一项访谈研究的结果表明，数据质量方面缺乏有效的指标、工作方式的歧义、注释质量的不清晰定义以及商业方面的缺陷都是原因。

    Software that contains machine learning algorithms is an integral part of automotive perception, for example, in driving automation systems. The development of such software, specifically the training and validation of the machine learning components, require large annotated datasets. An industry of data and annotation services has emerged to serve the development of such data-intensive automotive software components. Wide-spread difficulties to specify data and annotation needs challenge collaborations between OEMs (Original Equipment Manufacturers) and their suppliers of software components, data, and annotations. This paper investigates the reasons for these difficulties for practitioners in the Swedish automotive industry to arrive at clear specifications for data and annotations. The results from an interview study show that a lack of effective metrics for data quality aspects, ambiguities in the way of working, unclear definitions of annotation quality, and deficits in the busine
    
[^31]: 使用生成建模估计摩擦系数

    Estimating friction coefficient using generative modelling. (arXiv:2303.05927v1 [cs.CV])

    [http://arxiv.org/abs/2303.05927](http://arxiv.org/abs/2303.05927)

    通常使用动态模型实时测量轮胎与路面之间的摩擦系数。相反，预测方法通过识别影响摩擦系数的环境因素来估计轮胎与路面之间的摩擦系数。本文旨在将摩擦估计问题制定为视觉知觉学习任务。该问题通过应用语义分割来检测表面特征，并使用提取的特征来预测摩擦力。本研究首次将摩擦估计问题制定为从语义分割模型的潜在空间的回归问题。初步结果表明，这种方法可以估计摩擦力。

    It is common to utilise dynamic models to measure the tyre-road friction in real-time. Alternatively, predictive approaches estimate the tyre-road friction by identifying the environmental factors affecting it. This work aims to formulate the problem of friction estimation as a visual perceptual learning task. The problem is broken down into detecting surface characteristics by applying semantic segmentation and using the extracted features to predict the frictional force. This work for the first time formulates the friction estimation problem as a regression from the latent space of a semantic segmentation model. The preliminary results indicate that this approach can estimate frictional force.
    
[^32]: ODE-Net的变分形式作为一个均场最优控制问题和存在性结果的数学分析

    Variational formulations of ODE-Net as a mean-field optimal control problem and existence results. (arXiv:2303.05924v1 [math.AP])

    [http://arxiv.org/abs/2303.05924](http://arxiv.org/abs/2303.05924)

    本文提出了对ODE-Net的数学分析，这是一种深度神经网络（DNN）的连续模型。在近年来，机器学习研究人员提出了用ODE作为连续极限来替代DNN的深度结构的想法。这些研究将ODE-Net的“学习”视为通过一个参数ODE限制的“损失”的最小化。尽管需要假设存在一个最小化问题的最小化器，但只有很少的研究在详细分析其存在性方面进行了调查。本文根据ODE-Net的测度理论均场最优控制问题的表述来讨论最小化器的存在性结果。当描述ODE-Net向量场的神经网络对于可学习参数是线性时，证明了存在性结果。证明采用了测度理论的形式，结合变分法的直接方法。其次，提出了一种理想化的最小化问题来消除......

    This paper presents a mathematical analysis of ODE-Net, a continuum model of deep neural networks (DNNs). In recent years, Machine Learning researchers have introduced ideas of replacing the deep structure of DNNs with ODEs as a continuum limit. These studies regard the "learning" of ODE-Net as the minimization of a "loss" constrained by a parametric ODE. Although the existence of a minimizer for this minimization problem needs to be assumed, only a few studies have investigated its existence analytically in detail. In the present paper, the existence of a minimizer is discussed based on a formulation of ODE-Net as a measure-theoretic mean-field optimal control problem. The existence result is proved when a neural network, which describes a vector field of ODE-Net, is linear with respect to learnable parameters. The proof employs the measure-theoretic formulation combined with the direct method of Calculus of Variations. Secondly, an idealized minimization problem is proposed to remove
    
[^33]: 基于eBPF的内存管理工作集大小估计

    eBPF-based Working Set Size Estimation in Memory Management. (arXiv:2303.05919v1 [cs.PF])

    [http://arxiv.org/abs/2303.05919](http://arxiv.org/abs/2303.05919)

    工作集大小估计(WSS)对于提高现代操作系统中程序执行和内存排布的效率具有重要意义。先前的工作提出了几种估算WSS的方法，包括自我充气、Z充气等。然而，这些基于虚拟机的方法通常会导致较大的开销。因此，使用这些方法来估算WSS是不实际的。本文提出了一个新的框架，使用eBPF(扩展伯克利数据包过滤器)，这是一种最先进的技术，通过与内核连接来监控和过滤数据。使用固定到内核的eBPF程序，我们可以得到页面错误等内存分配信息的时间。此外，我们通过使用vanilla工具收集WSS，用LightGBM训练预测模型来完成估算工作，LightGBM是一个在连续值上生成决策树的有用工具。实验结果表明，我们的框架可以有效地估算WSS。

    Working set size estimation (WSS) is of great significance to improve the efficiency of program executing and memory arrangement in modern operating systems. Previous work proposed several methods to estimate WSS, including self-balloning, Zballoning and so on. However, these methods which are based on virtual machine usually cause a large overhead. Thus, using those methods to estimate WSS is impractical. In this paper, we propose a novel framework to efficiently estimate WSS with eBPF (extended Berkeley Packet Filter), a cutting-edge technology which monitors and filters data by being attached to the kernel. With an eBPF program pinned into the kernel, we get the times of page fault and other information of memory allocation. Moreover, we collect WSS via vanilla tool to train a predictive model to complete estimation work with LightGBM, a useful tool which performs well on generating decision trees over continuous value. The experimental results illustrate that our framework can esti
    
[^34]: 终身机器学习潜力

    Lifelong Machine Learning Potentials. (arXiv:2303.05911v1 [cs.LG])

    [http://arxiv.org/abs/2303.05911](http://arxiv.org/abs/2303.05911)

    基于准确的量子化学数据训练的机器学习势能（MLP）可以保持高精度，而对计算要求很小。但是，它们需要针对每个单独的系统进行训练。近年来，已经从头开始训练了大量的MLP，因为学习额外数据通常需要重新对所有数据进行训练，以不忘记以前获得的知识。此外，MLP的大多数常见结构描述符不能有效地表示大量不同的化学元素。在本研究中，我们通过引入元素融合的基于原子中心的对称函数（eeACSFs）来解决这些问题，这些函数结合了周期表的结构特性和元素信息。这些eeACSFs是我们开发终身机器学习势能（lMLP）的关键。可以利用不确定性量化来超越固定的、预训练的MLP，以到达不断适应的lMLP，因为预定义的级别

    Machine learning potentials (MLPs) trained on accurate quantum chemical data can retain the high accuracy, while inflicting little computational demands. On the downside, they need to be trained for each individual system. In recent years, a vast number of MLPs has been trained from scratch because learning additional data typically requires to train again on all data to not forget previously acquired knowledge. Additionally, most common structural descriptors of MLPs cannot represent efficiently a large number of different chemical elements. In this work, we tackle these problems by introducing element-embracing atom-centered symmetry functions (eeACSFs) which combine structural properties and element information from the periodic table. These eeACSFs are a key for our development of a lifelong machine learning potential (lMLP). Uncertainty quantification can be exploited to transgress a fixed, pre-trained MLP to arrive at a continuously adapting lMLP, because a predefined level of ac
    
[^35]: 使用得分匹配的雅可比-Theta玻尔兹曼机

    Product Jacobi-Theta Boltzmann machines with score matching. (arXiv:2303.05910v1 [stat.ML])

    [http://arxiv.org/abs/2303.05910](http://arxiv.org/abs/2303.05910)

    估计概率密度函数是一项非常困难的任务，近年来已经采用机器学习技术来解决。通过受Boltzmann机(BM)架构启发的模型，可以获得成功的应用。本文介绍了产品Jacobi-Theta玻尔兹曼机(pJTBM)，作为具有对角线隐藏部分连接矩阵的Riemann-Theta玻尔兹曼机(RTBM)的限制版本。我们表明，基于Fisher差异的得分匹配可以更有效地使用pJTBM来适应概率密度，比使用原始RTBM更有效。

    The estimation of probability density functions is a non trivial task that over the last years has been tackled with machine learning techniques. Successful applications can be obtained using models inspired by the Boltzmann machine (BM) architecture. In this manuscript, the product Jacobi-Theta Boltzmann machine (pJTBM) is introduced as a restricted version of the Riemann-Theta Boltzmann machine (RTBM) with diagonal hidden sector connection matrix. We show that score matching, based on the Fisher divergence, can be used to fit probability densities with the pJTBM more efficiently than with the original RTBM.
    
[^36]: 田纳西·伊斯曼流程数据的深度异常检测

    Deep Anomaly Detection on Tennessee Eastman Process Data. (arXiv:2303.05904v1 [cs.LG])

    [http://arxiv.org/abs/2303.05904](http://arxiv.org/abs/2303.05904)

    本文首次全面评估和分析了用于化学过程数据的现代（深度学习）无监督异常检测方法。我们关注田纳西·伊斯曼流程数据集，这是一个标准的化验试验，用于评估异常检测方法已有近三十年。我们的广泛研究将有助于在工业应用中选择适当的异常检测方法。

    This paper provides the first comprehensive evaluation and analysis of modern (deep-learning) unsupervised anomaly detection methods for chemical process data. We focus on the Tennessee Eastman process dataset, which has been a standard litmus test to benchmark anomaly detection methods for nearly three decades. Our extensive study will facilitate choosing appropriate anomaly detection methods in industrial applications.
    
[^37]: 基于时频预测模型的分布保持源分离方法

    Distribution Preserving Source Separation With Time Frequency Predictive Models. (arXiv:2303.05896v1 [eess.AS])

    [http://arxiv.org/abs/2303.05896](http://arxiv.org/abs/2303.05896)

    我们提供了一个分布保持的源分离方法的例子，旨在解决最先进方法的感知缺陷。我们的方法使用信号源的无条件生成模型。通过对条件于混合实现的分布进行混合一致性采样，实现重构。分离的信号遵循各自的源分布，在听测试中评估分离结果时具有优势。

    We provide an example of a distribution preserving source separation method, which aims at addressing perceptual shortcomings of state-of-the-art methods. Our approach uses unconditioned generative models of signal sources. Reconstruction is achieved by means of mix-consistent sampling from a distribution conditioned on a realization of a mix. The separated signals follow their respective source distributions, which provides an advantage when separation results are evaluated in a listening test.
    
[^38]: 机器人抓取的基于仿真的贝叶斯推断

    Simulation-based Bayesian inference for robotic grasping. (arXiv:2303.05873v1 [cs.RO])

    [http://arxiv.org/abs/2303.05873](http://arxiv.org/abs/2303.05873)

    由于非平滑接触动力学和环境或传感器噪声的许多不确定性，一般的机器人夹爪很难控制。在这项工作中，我们演示了如何通过在机器人在其环境中进行完全随机前向仿真来鲁棒地考虑系统中的许多不确定性，从而计算出6自由度抓取姿态。使用保留旋转空间非线性性的黎曼流形优化程序计算最大后验抓取姿态。仿真和物理基准测试显示了该方法高成功率的前景。

    General robotic grippers are challenging to control because of their rich nonsmooth contact dynamics and the many sources of uncertainties due to the environment or sensor noise. In this work, we demonstrate how to compute 6-DoF grasp poses using simulation-based Bayesian inference through the full stochastic forward simulation of the robot in its environment while robustly accounting for many of the uncertainties in the system. A Riemannian manifold optimization procedure preserving the nonlinearity of the rotation space is used to compute the maximum a posteriori grasp pose. Simulation and physical benchmarks show the promising high success rate of the approach.
    
[^39]: 视频中准确的实时息肉检测：来自连续帧提取的潜在特征的串联

    Accurate Real-time Polyp Detection in Videos from Concatenation of Latent Features Extracted from Consecutive Frames. (arXiv:2303.05871v1 [cs.CV])

    [http://arxiv.org/abs/2303.05871](http://arxiv.org/abs/2303.05871)

    实时的息肉检测对于减少筛查过程中的漏诊率至关重要。本研究尝试通过在相邻帧之间整合时间信息来解决这个问题。我们提出了一种有效的特征串联方法，通过将前一帧的特征映射并入当前帧来检测息肉，以此不增加模型的复杂性。实验结果表明，这种特征串联方法可以提高视频中自动息肉检测的性能。

    An efficient deep learning model that can be implemented in real-time for polyp detection is crucial to reducing polyp miss-rate during screening procedures. Convolutional neural networks (CNNs) are vulnerable to small changes in the input image. A CNN-based model may miss the same polyp appearing in a series of consecutive frames and produce unsubtle detection output due to changes in camera pose, lighting condition, light reflection, etc. In this study, we attempt to tackle this problem by integrating temporal information among neighboring frames. We propose an efficient feature concatenation method for a CNN-based encoder-decoder model without adding complexity to the model. The proposed method incorporates extracted feature maps of previous frames to detect polyps in the current frame. The experimental results demonstrate that the proposed method of feature concatenation improves the overall performance of automatic polyp detection in videos. The following results are obtained on a
    
[^40]: 基于变分量子神经网络的图像分类

    Variational Quantum Neural Networks (VQNNS) in Image Classification. (arXiv:2303.05860v1 [quant-ph])

    [http://arxiv.org/abs/2303.05860](http://arxiv.org/abs/2303.05860)

    量子机器学习已成为一个跨学科领域，旨在克服经典机器学习和神经网络的限制。量子计算机能够解决输入之间存在复杂相关性的问题，这表明在量子计算机上建立的学习模型可能更强大，能够在较少的数据上进行更快的计算和更好的泛化。本文的目的是研究如何使用量子优化算法来训练量子神经网络（QNN），以提高QNN的性能和时间复杂度。可以部分量子化经典神经网络以创建混合量子-经典神经网络，主要用于分类和图像识别。本文提出了一种QNN结构，其中一个变分参数化电路被纳入作为称为变分Q的输入层

    Quantum machine learning has established as an interdisciplinary field to overcome limitations of classical machine learning and neural networks. This is a field of research which can prove that quantum computers are able to solve problems with complex correlations between inputs that can be hard for classical computers. This suggests that learning models made on quantum computers may be more powerful for applications, potentially faster computation and better generalization on less data. The objective of this paper is to investigate how training of quantum neural network (QNNs) can be done using quantum optimization algorithms for improving the performance and time complexity of QNNs. A classical neural network can be partially quantized to create a hybrid quantum-classical neural network which is used mainly in classification and image recognition. In this paper, a QNN structure is made where a variational parameterized circuit is incorporated as an input layer named as Variational Q
    
[^41]: 不确定性决策：超越概率

    Decision-Making Under Uncertainty: Beyond Probabilities. (arXiv:2303.05848v1 [cs.AI])

    [http://arxiv.org/abs/2303.05848](http://arxiv.org/abs/2303.05848)

    这篇论文对不确定性决策的最新发展进行了回顾。传统的假设是概率可以充分捕捉系统中的所有不确定性。本文关注超越这种传统解释的不确定性，特别是通过清晰区分模糊不确定性和认知不确定性。文章概述了马尔可夫决策过程（MDP）及其扩展，以解决部分可观测性和对抗行为的问题。这些模型可以很好地捕捉模糊不确定性，但未能充分考虑认知不确定性。因此，我们对所谓的“不确定性模型”进行了全面的概述，并展示了一些离散和连续模型的解决方法，从形式化验证、基于控制的抽象到强化学习。作为本文的一个重要组成部分，我们列出并讨论了若干个例子。

    This position paper reflects on the state-of-the-art in decision-making under uncertainty. A classical assumption is that probabilities can sufficiently capture all uncertainty in a system. In this paper, the focus is on the uncertainty that goes beyond this classical interpretation, particularly by employing a clear distinction between aleatoric and epistemic uncertainty. The paper features an overview of Markov decision processes (MDPs) and extensions to account for partial observability and adversarial behavior. These models sufficiently capture aleatoric uncertainty but fail to account for epistemic uncertainty robustly. Consequently, we present a thorough overview of so-called uncertainty models that exhibit uncertainty in a more robust interpretation. We show several solution techniques for both discrete and continuous models, ranging from formal verification, over control-based abstractions, to reinforcement learning. As an integral part of this paper, we list and discuss severa
    
[^42]: 对比语言图像预训练（CLIP）模型是强大的越界检测器。

    Contrastive Language-Image Pretrained (CLIP) Models are Powerful Out-of-Distribution Detectors. (arXiv:2303.05828v1 [cs.CV])

    [http://arxiv.org/abs/2303.05828](http://arxiv.org/abs/2303.05828)

    我们对用于视觉越界检测的预训练特征提取器进行了全面的实验研究。 我们检查了几个设置，基于标签或图像标题的可用性，使用不同的内部和外部分布的组合。 有趣的是，我们发现（i）对比语言-图像预训练模型使用最近邻特征相似性作为越界检测分数，实现了最先进的无监督越界检测表现，（ii）可以在不需要内部分布微调的情况下获得监督状态下的最先进越界检测性能，（iii）即使是针对自然语言监督进行训练的性能最佳的十亿级视觉变换器也无法检测到经过敌对操纵的越界图像。 最后，我们根据实验结果讨论了是否需要新的基于视觉异常检测的基准。 使用最大的公开可用视觉变换器，在所有18个报告的越界基准测试中都实现了最先进的性能

    We present a comprehensive experimental study on pretrained feature extractors for visual out-of-distribution (OOD) detection. We examine several setups, based on the availability of labels or image captions and using different combinations of in- and out-distributions. Intriguingly, we find that (i) contrastive language-image pretrained models achieve state-of-the-art unsupervised out-of-distribution performance using nearest neighbors feature similarity as the OOD detection score, (ii) supervised state-of-the-art OOD detection performance can be obtained without in-distribution fine-tuning, (iii) even top-performing billion-scale vision transformers trained with natural language supervision fail at detecting adversarially manipulated OOD images. Finally, we argue whether new benchmarks for visual anomaly detection are needed based on our experiments. Using the largest publicly available vision transformer, we achieve state-of-the-art performance across all $18$ reported OOD benchmark
    
[^43]: 半监督对抗学习用于补充商品推荐

    Semi-supervised Adversarial Learning for Complementary Item Recommendation. (arXiv:2303.05812v1 [cs.IR])

    [http://arxiv.org/abs/2303.05812](http://arxiv.org/abs/2303.05812)

    补充商品推荐是现代电子商务网站的普遍特征。当这些推荐基于协作信号，如共同购买统计数据时，它们非常有效。但是，在某些在线市场上，例如在线拍卖网站，不断有新商品加入目录。在这种情况下，由于缺乏交互数据，补充商品推荐通常基于商品辅助信息。本文提出了一种新方法，可以利用商品辅助信息和标记的补充商品对来生成有效的补充推荐，用于无冷启动商品，即尚不存在共同购买统计数据的商品。考虑到补充商品通常必须与种子商品不同类别，我们为每个商品类别技术维护一个潜在空间。同时，我们学习将分布式商品表示投影到这些类别空间中，以确定合适的推荐。

    Complementary item recommendations are a ubiquitous feature of modern e-commerce sites. Such recommendations are highly effective when they are based on collaborative signals like co-purchase statistics. In certain online marketplaces, however, e.g., on online auction sites, constantly new items are added to the catalog. In such cases, complementary item recommendations are often based on item side-information due to a lack of interaction data. In this work, we propose a novel approach that can leverage both item side-information and labeled complementary item pairs to generate effective complementary recommendations for cold items, i.e., for items for which no co-purchase statistics yet exist. Given that complementary items typically have to be of a different category than the seed item, we technically maintain a latent space for each item category. Simultaneously, we learn to project distributed item representations into these category spaces to determine suitable recommendations. Th
    
[^44]: 带有概率组的分布式鲁棒优化

    Distributionally Robust Optimization with Probabilistic Group. (arXiv:2303.05809v1 [cs.LG])

    [http://arxiv.org/abs/2303.05809](http://arxiv.org/abs/2303.05809)

    现代机器学习模型可能容易受到平均而非典型样本群体的表面相关性干扰。为了解决这个问题，以前的方法最小化经验最坏群体风险。尽管有前途，但它们经常假设每个样本属于一个且仅一个群体，这不允许表达群体标注的不确定性。在本文中，我们提出了一个新的PG-DRO框架，探索基于概率群体成员身份的分布式鲁棒优化的思想。我们的框架的关键是考虑到软组成员身份而非硬组注释。组概率可以使用监督学习或零样本方法灵活生成。我们的框架适应具有组成员身份模糊性的样本，比现有技术具有更强的灵活性和通用性。我们全面评估了PG-DRO在图像分类和自然语言处理基准测试中的表现，建立了超过其他方法的最佳性能。

    Modern machine learning models may be susceptible to learning spurious correlations that hold on average but not for the atypical group of samples. To address the problem, previous approaches minimize the empirical worst-group risk. Despite the promise, they often assume that each sample belongs to one and only one group, which does not allow expressing the uncertainty in group labeling. In this paper, we propose a novel framework PG-DRO, which explores the idea of probabilistic group membership for distributionally robust optimization. Key to our framework, we consider soft group membership instead of hard group annotations. The group probabilities can be flexibly generated using either supervised learning or zero-shot approaches. Our framework accommodates samples with group membership ambiguity, offering stronger flexibility and generality than the prior art. We comprehensively evaluate PG-DRO on both image classification and natural language processing benchmarks, establishing supe
    
[^45]: 对于M/EEG信号的对称正定矩阵上切片Wasserstein

    Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals. (arXiv:2303.05798v1 [cs.LG])

    [http://arxiv.org/abs/2303.05798](http://arxiv.org/abs/2303.05798)

    处理电或磁图记录时，许多监督的预测任务通过使用协方差矩阵来总结信号来解决。使用这些矩阵的学习需要使用Riemanian几何来考虑它们的结构。在本文中，我们提出了一种处理协方差矩阵分布的新方法，并在M / EEG多元时间序列上展示其计算效率。更具体地说，我们定义了对称正定矩阵测量之间的切片Wasserstein距离，并提供了强大的理论保证。然后，利用其属性和核方法将此距离应用于从MEG数据中脑年龄预测，并将其与基于Riemannian几何的最先进算法进行比较。最后，我们展示了它在领域适应的Wasserstein距离中是一个有效的替代品，用于脑机接口应用程序。

    When dealing with electro or magnetoencephalography records, many supervised prediction tasks are solved by working with covariance matrices to summarize the signals. Learning with these matrices requires using Riemanian geometry to account for their structure. In this paper, we propose a new method to deal with distributions of covariance matrices and demonstrate its computational efficiency on M/EEG multivariate time series. More specifically, we define a Sliced-Wasserstein distance between measures of symmetric positive definite matrices that comes with strong theoretical guarantees. Then, we take advantage of its properties and kernel methods to apply this distance to brain-age prediction from MEG data and compare it to state-of-the-art algorithms based on Riemannian geometry. Finally, we show that it is an efficient surrogate to the Wasserstein distance in domain adaptation for Brain Computer Interface applications.
    
[^46]: 确定性不确定性方法的训练、架构和先验

    Training, Architecture, and Prior for Deterministic Uncertainty Methods. (arXiv:2303.05796v1 [cs.LG])

    [http://arxiv.org/abs/2303.05796](http://arxiv.org/abs/2303.05796)

    准确高效的不确定性估计对于构建可靠的机器学习模型非常重要，这些模型能够提供校准的不确定性估计、推广并检测超出分布的数据集。为此，确定性不确定性方法（DUMs）是一种有前途的模型族，能够在单次前向传递中执行不确定性估计。本文研究了DUM中的重要设计选择：(1)我们表明，解耦核心架构和不确定性头方案的训练方案可以显著提高不确定性性能。(2)我们证明了核心架构的表达能力对不确定性性能至关重要，并且避免特征崩溃的其他架构约束可能会恶化OOD概括和检测之间的平衡。(3)与其他贝叶斯模型相反，我们表明DUMs定义的先验不会对最终性能产生强烈的影响。

    Accurate and efficient uncertainty estimation is crucial to build reliable Machine Learning (ML) models capable to provide calibrated uncertainty estimates, generalize and detect Out-Of-Distribution (OOD) datasets. To this end, Deterministic Uncertainty Methods (DUMs) is a promising model family capable to perform uncertainty estimation in a single forward pass. This work investigates important design choices in DUMs: (1) we show that training schemes decoupling the core architecture and the uncertainty head schemes can significantly improve uncertainty performances. (2) we demonstrate that the core architecture expressiveness is crucial for uncertainty performance and that additional architecture constraints to avoid feature collapse can deteriorate the trade-off between OOD generalization and detection. (3) Contrary to other Bayesian models, we show that the prior defined by DUMs do not have a strong effect on the final performances.
    
[^47]: 深度生成固定滤波器有源噪声控制

    Deep Generative Fixed-filter Active Noise Control. (arXiv:2303.05788v1 [eess.SY])

    [http://arxiv.org/abs/2303.05788](http://arxiv.org/abs/2303.05788)

    由于收敛速度慢，跟踪能力较差，传统的LMS自适应算法不太能够处理动态噪声。选择性固定滤波器有源噪声控制（SFANC）可以通过为不同的噪声选择合适的预训练控制滤波器，显著缩短响应时间。然而，预训练控制滤波器数量有限可能会影响噪声降低性能，特别是当入射噪声与预训练期间的初始噪声差异很大时。因此，本文提出了一种基于深度学习和完美重构滤波器组的生成固定滤波器有源噪声控制（GFANC）方法，只需要少量先验数据（一个预训练的宽带控制滤波器）即可自动生成适用于各种噪声的控制滤波器。通过对真实记录噪声的数值模拟，证明了GFANC方法的有效性。

    Due to the slow convergence and poor tracking ability, conventional LMS-based adaptive algorithms are less capable of handling dynamic noises. Selective fixed-filter active noise control (SFANC) can significantly reduce response time by selecting appropriate pre-trained control filters for different noises. Nonetheless, the limited number of pre-trained control filters may affect noise reduction performance, especially when the incoming noise differs much from the initial noises during pre-training. Therefore, a generative fixed-filter active noise control (GFANC) method is proposed in this paper to overcome the limitation. Based on deep learning and a perfect-reconstruction filter bank, the GFANC method only requires a few prior data (one pre-trained broadband control filter) to automatically generate suitable control filters for various noises. The efficacy of the GFANC method is demonstrated by numerical simulations on real-recorded noises.
    

