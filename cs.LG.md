# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Quantum-noise-limited optical neural networks operating at a few quanta per activation.](http://arxiv.org/abs/2307.15712) | 本文研究了在极低功率下操作的光学神经网络，其中一些层只使用一个光子来引发神经元激活。尽管存在极高的噪声，仍可以训练这些网络以高精度执行确定性图像分类任务。 |
| [^2] | [Semi-Supervised Object Detection in the Open World.](http://arxiv.org/abs/2307.15710) | 本文提出了一种半监督开放世界目标检测框架，能够有效地检测分布外的数据并从中学习，通过基于集成的OOD检测器和半监督学习方法，实现与最先进方法相当的性能。 |
| [^3] | [Uncertainty in Natural Language Generation: From Theory to Applications.](http://arxiv.org/abs/2307.15703) | 本文介绍了自然语言生成中不确定性的理论、应用和分类，提出了一种更详细和真实的分类法。 |
| [^4] | [Universal Recurrent Event Memories for Streaming Data.](http://arxiv.org/abs/2307.15694) | 本文提出了一种名为MemNet的通用递归事件记忆架构（MemNet），适用于不同类型的时间序列数据，并通过存储键值对来改善表示效果。MemNet具有线性自适应映射函数，适用于标量时间序列、逻辑运算和自然语言处理，并在各个应用领域中取得了最先进的结果。 |
| [^5] | [ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription.](http://arxiv.org/abs/2307.15691) | ODTlearn是一个开源的Python包，用于学习预测和处方的最优决策树。它提供了多种优化方法，并支持各种问题和算法的扩展。 |
| [^6] | [Benchmarking Offline Reinforcement Learning on Real-Robot Hardware.](http://arxiv.org/abs/2307.15690) | 从预先记录的数据中学习策略在解决真实世界机器人任务中具有潜力，该论文提出了一个基准测试，包括大量来自模拟环境的数据集以及在真实机器人系统和模拟环境中执行学习策略的选项，用于推动离线强化学习的研究。 |
| [^7] | [A supervised hybrid quantum machine learning solution to the emergency escape routing problem.](http://arxiv.org/abs/2307.15682) | 本文研究了使用监督式混合量子机器学习来优化自然灾害中汽车紧急疏散计划的潜力，并提出了一种新颖的混合监督学习方法来模拟最短路径算法。 |
| [^8] | [Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks.](http://arxiv.org/abs/2307.15679) | 本文研究了递归神经网络中的隐藏状态动态，并提出了一种新的角度来分析隐藏状态空间。基于特征值分析，我们提供了长期依赖性的解释，并在此基础上提出了递归神经网络的新初始化方法。 |
| [^9] | [Case Studies of Causal Discovery from IT Monitoring Time Series.](http://arxiv.org/abs/2307.15678) | 本研究通过案例研究，探索了将因果推断算法应用于不同IT监控数据的挑战和潜在益处。 |
| [^10] | [Adversarial training for tabular data with attack propagation.](http://arxiv.org/abs/2307.15677) | 该论文提出了一种针对表格数据的对抗训练方法，通过在训练循环中传播攻击来提高模型的鲁棒性。在信用卡欺诈检测领域的实证结果表明，该方法可以防止约30%的性能下降，并且对于非常激烈的攻击而言是必不可少的。 |
| [^11] | [Bayesian Time-Series Classifier for Decoding Simple Visual Stimuli from Intracranial Neural Activity.](http://arxiv.org/abs/2307.15672) | 本研究提出了一个基于贝叶斯的时间序列分类器模型，解决了处理有限数据和神经数据中随机性的问题，并在解码颅内神经活动中的简单视觉刺激方面取得了良好的分类结果。该模型在4名患者数据集上表现出75.55％的平均准确率，比先进的机器学习技术提高了约3.0个百分点。此外，该模型提供了可解释的结果，成为研究神经活动的有价值工具。 |
| [^12] | [CoRe Optimizer: An All-in-One Solution for Machine Learning.](http://arxiv.org/abs/2307.15663) | CoRe优化器是一种高性能的机器学习优化器，具有快速、平滑收敛、低计算需求和通用适用性的特点，在训练终身机器学习潜力方面表现出优势。 |
| [^13] | [Multi-layer Aggregation as a key to feature-based OOD detection.](http://arxiv.org/abs/2307.15647) | 该研究比较了多种基于特征的OOD检测方法，在大量OOD图像上进行了实验，并发现多层方法能够提供更好的OOD检测性能。 |
| [^14] | [Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation.](http://arxiv.org/abs/2307.15645) | 本文提出了一种尺度感知的测试时点击自适应方法，用于肺结节和肿块分割。该方法利用易获取的病变点击来增强分割性能，特别是对于大的病变，实验证明其有效性。 |
| [^15] | [Scaling Data Generation in Vision-and-Language Navigation.](http://arxiv.org/abs/2307.15644) | 这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。 |
| [^16] | [TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images.](http://arxiv.org/abs/2307.15638) | TriadNet是一种无采样预测区间的分割方法，能够快速准确地估计脑病变体积，并在临床实践中具有重要价值。 |
| [^17] | [A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data.](http://arxiv.org/abs/2307.15625) | 本文比较了不同机器学习方法在车道改变意图识别中的性能，结果表明集成方法能降低分类错误的影响，而LightGBM相比XGBoost算法在模型训练效率上有显著提升。 |
| [^18] | [Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search.](http://arxiv.org/abs/2307.15621) | 本文展示了一种名为PBT-NAS的方法，通过同时训练和混合神经网络，并使用收缩扰动技术改进架构，以实现有效的神经架构搜索。PBT-NAS在图像生成和强化学习等挑战性任务中表现出优越的性能。 |
| [^19] | [Robust Distortion-free Watermarks for Language Models.](http://arxiv.org/abs/2307.15593) | 该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。 |
| [^20] | [Dynamic algorithms for k-center on graphs.](http://arxiv.org/abs/2307.15557) | 本文提出了针对动态图中的k中心问题的高效算法，包括确定性递减的（2+ε）近似算法和随机增量的（4+ε）近似算法，同时给出了针对加权图的摊销更新时间为kn^{o(1)}的算法。此外，通过简化方法得到了对于k中心问题的全动态（2+ε）近似算法。 |
| [^21] | [On the Trade-off Between Efficiency and Precision of Neural Abstraction.](http://arxiv.org/abs/2307.15546) | 本研究探讨了神经抽象的效率和精确性之间的权衡问题，研究发现抽象的用途取决于具体场景，请求简单的粗略抽象同样会有其用途，而对于更复杂 |
| [^22] | [Backdoor Defense with Non-Adversarial Backdoor.](http://arxiv.org/abs/2307.15539) | 提出了一种非对抗性后门防御框架，通过在被污染样本中注入非对抗性后门，当触发时可以抑制攻击者对污染数据的后门攻击，同时保持对干净数据的影响有限。 |
| [^23] | [The Applicability of Federated Learning to Official Statistics.](http://arxiv.org/abs/2307.15503) | Federated Learning（FL）在官方统计中具有潜力，可以保护数据隐私并提升数据质量。 |
| [^24] | [From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs.](http://arxiv.org/abs/2307.15496) | 本论文通过使用张量列车方法结合回归类型方法来解决高维度偏微分方程的数值逼近问题。实验结果表明，该方法在精度和计算效率之间取得了有利的折中。 |
| [^25] | [FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines.](http://arxiv.org/abs/2307.15475) | FeedbackLogs是针对机器学习流程的利益相关者反馈记录和更新的补充工具，可以用于算法审计和记录反馈更新。 |
| [^26] | [LUCID-GAN: Conditional Generative Models to Locate Unfairness.](http://arxiv.org/abs/2307.15466) | LUCID-GAN是一个有条件生成模型，用于定位不公平性。它通过生成规范集来揭示模型的内部逻辑中潜在的不道德偏见，提供了对歧视来源的额外透明度。 |
| [^27] | [Worrisome Properties of Neural Network Controllers and Their Symbolic Representations.](http://arxiv.org/abs/2307.15456) | 本论文对神经网络控制器在简单强化学习问题中的稳健性产生了担忧，通过对低神经元和符号抽象的探究，发现即使控制器达到高回报，仍会产生大量持久低回报解决方案，对手可以轻易利用。论文提供了一个系统稳健性研究的算法，并证明了持久解决方案的存在性以及周期轨道的存在。 |
| [^28] | [Autonomous Payload Thermal Control.](http://arxiv.org/abs/2307.15438) | 该论文提出了一种基于深度强化学习的框架，利用软演员-评论家算法在卫星上学习热控制策略，以解决小型卫星中热控制的挑战。该框架在模拟环境和实际空间处理计算机上进行了评估，并证明能够辅助传统热控制系统，保持载荷温度在可操作范围内。 |
| [^29] | [Improvable Gap Balancing for Multi-Task Learning.](http://arxiv.org/abs/2307.15429) | 本文提出了两种新颖的可改进差距平衡算法（IGB）用于多任务学习，一种采用简单的启发式方法，另一种首次采用深度强化学习方法。这两种算法通过动态分配任务权重来实现可改进差距平衡，解决了损失平衡之后仍然存在的性能不平衡问题。 |
| [^30] | [Implicit neural representation for change detection.](http://arxiv.org/abs/2307.15428) | 这项研究提出了一种用于检测不同时间获取的LiDAR点云中变化的无监督方法，通过使用神经场进行连续形状重建，以及高斯混合模型进行变化分类。该方法能够处理不匹配的空间支持和噪声，并在检测能力上取得了显著的提升。 |
| [^31] | [Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis.](http://arxiv.org/abs/2307.15424) | 本文综述了近期合成数据生成的深度生成模型发展，重点关注表格数据集。通过使用深度生成模型，可以有效地生成隐私敏感数据的合成数据，并解决数据归一化、隐私和评估等方面的挑战。 |
| [^32] | [Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?.](http://arxiv.org/abs/2307.15422) | 传统的基准线在多层次超参数优化中取得了与其他方法类似的结果，并大幅减少计算成本。研究人员应该使用该基准线并扩大MF-HPO基准测试的多样性。 |
| [^33] | [The Initial Screening Order Problem.](http://arxiv.org/abs/2307.15398) | 本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。 |
| [^34] | [Noisy Interpolation Learning with Shallow Univariate ReLU Networks.](http://arxiv.org/abs/2307.15396) | 使用最小范数的两层ReLU网络进行噪声单变量回归的插值，对于$L_1$损失和$ p <2 $的$L_p$损失抑制过拟合，但对于$ p \geq 2 $的损失是灾难性的。 |
| [^35] | [Does Full Waveform Inversion Benefit from Big Data?.](http://arxiv.org/abs/2307.15388) | 本文研究了大数据对全波形反演深度学习模型的影响，并通过实证研究证明了更大的数据集能够提高模型性能和泛化能力，同时强调模型容量需要根据数据大小进行扩展以取得最佳改进效果。 |
| [^36] | [Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning.](http://arxiv.org/abs/2307.15377) | 本论文提出了一种称为共同注意力图汇聚（CAGPool）的新颖和高效的图级方法，用于提取图对之间的交互表示。该方法在分类和回归任务中展现出竞争性能。 |
| [^37] | [Conflict-free joint decision by lag and zero-lag synchronization in laser network.](http://arxiv.org/abs/2307.15373) | 本研究在竞争性多臂赌博机问题中探索了激光网络作为光子加速器的应用，通过滞后和非滞后同步实现了无冲突的合作决策，实验证实了低冲突率和高奖励。 |
| [^38] | [Toward Transparent Sequence Models with Model-Based Tree Markov Model.](http://arxiv.org/abs/2307.15367) | 本研究引入了基于模型的树马尔可夫模型（MOB-HSMM），用于解决复杂黑盒机器学习模型应用于序列数据时的可解释性问题。通过从深度神经网络中蒸馏的知识，实现了提高预测性能的同时提供清晰解释的目标。实验结果表明通过将LSTM学习到的顺序模式转移到MOB树中，可以进一步提高MOB树的性能，并利用MOB-HSMM将MOB树与隐马尔可夫模型（HSMM）整合，实现了潜在和可解释的序列的发现。 |
| [^39] | [Confident Feature Ranking.](http://arxiv.org/abs/2307.15361) | 提出了一种确定性特征排序的方法，该方法通过特征重要性值的两两比较，可以产生排序和同时的置信区间，并且可以选择前k个集合。 |
| [^40] | [Med-HALT: Medical Domain Hallucination Test for Large Language Models.](http://arxiv.org/abs/2307.15343) | Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。 |
| [^41] | [The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images.](http://arxiv.org/abs/2307.15339) | 该论文介绍了一种基于Radon变换和符号累积分布变换的图像表示方法，可以更准确地表示有符号图像的信息内容，并在图像分类中获得更高的准确性。 |
| [^42] | [Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation.](http://arxiv.org/abs/2307.15326) | 提出了使用检索辅助图像生成的方法来为未布置的电子商务产品图像生成吸引人和逼真的舞台背景，以提高在线广告的点击率。 |
| [^43] | [Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems.](http://arxiv.org/abs/2307.15325) | 本文解决了在大规模动态系统中部分观测或粗粒化的情况下，经典的EDMD算法不能准确提供Koopman算子近似的问题，并展示了将系统动态的对称性转移到Koopman算子可以显著提高模型效率。 |
| [^44] | [Robust Visual Sim-to-Real Transfer for Robotic Manipulation.](http://arxiv.org/abs/2307.15320) | 该论文研究了视觉模拟与实际机器人操作的跨界迁移问题，并提出了域随机化方法来弥合这一差距。通过离线代理任务和模拟训练，成功地优化了域随机化参数，从而实现了在真实机器人上的有效应用。 |
| [^45] | [DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation.](http://arxiv.org/abs/2307.15317) | 本文提出了一种利用可微分Kendall排名相关性进行少样本学习的新方法，证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠，并且实验证明在推理过程中用Kendall排名相关性替换几何相似度度量能够提高少样本学习性能。 |
| [^46] | [Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting.](http://arxiv.org/abs/2307.15299) | 本研究使用差分进化算法选择Transformer神经网络模型的优化超参数，以提高负荷预测的准确性。 |
| [^47] | [Learning Nonlinear Projections for Reduced-Order Modeling of Dynamical Systems using Constrained Autoencoders.](http://arxiv.org/abs/2307.15288) | 该论文提出了一种使用受约束的自编码器学习非线性投影的方法，用于动态系统的降阶建模。这种方法可以有效地对非线性动力学系统进行逼近，并解决了在流形附近对瞬态动力学建模时所面临的问题。 |
| [^48] | [Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks.](http://arxiv.org/abs/2307.15285) | 本论文解决了Zonoid的最优逼近和浅层神经网络的均匀逼近两个问题。对于Zonoid的逼近，我们填补了在$d=2,3$时的对数差距，实现了在所有维度上的解决方案。对于神经网络的逼近，我们的技术在$k \geq 1$时显著提高了目前的逼近率，并能够均匀逼近目标函数及其导数。 |
| [^49] | [Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture.](http://arxiv.org/abs/2307.15273) | 本文提出了一种基于模型的深度学习架构，用于从减少数量的扩散加权图像中恢复高质量的纤维定向分布（FOD），并通过引入fixel分类惩罚来提高下游分析的准确性。 |
| [^50] | [Is this model reliable for everyone? Testing for strong calibration.](http://arxiv.org/abs/2307.15247) | 通过重新排序观测值的预期残差，我们引入了一种新的测试程序来评估模型的强校准性能。 |
| [^51] | [A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design.](http://arxiv.org/abs/2307.15245) | 本文针对联邦学习在统计异质实验设计下的问题进行了全面研究，提供了设计有意义和具有良好激励机制的FL实验设置的见解和建议。 |
| [^52] | [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback.](http://arxiv.org/abs/2307.15217) | 本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。 |
| [^53] | [PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization.](http://arxiv.org/abs/2307.15199) | 提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。 |
| [^54] | [The Marginal Value of Momentum for Small Learning Rate SGD.](http://arxiv.org/abs/2307.15196) | 本文通过理论分析和实验证明，在小学习率和梯度噪声是主要不稳定源的随机环境中，动量在深度学习优化中的边际价值是有限的。 |
| [^55] | [Learning in Repeated Multi-Unit Pay-As-Bid Auctions.](http://arxiv.org/abs/2307.15193) | 本论文研究了在重复的多单位付费拍卖中学习如何出价的问题。通过在离线设置中优化出价向量，并利用多项式时间动态规划方案，设计了具有多项式时间和空间复杂度的在线学习算法。 |
| [^56] | [f-Divergence Minimization for Sequence-Level Knowledge Distillation.](http://arxiv.org/abs/2307.15190) | 本文提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。通过在词级上计算损失，能够更好地压缩语言模型并使学生模型从教师模型中学习。提出的方法在多个数据集上表现出色。 |
| [^57] | [RCT Rejection Sampling for Causal Estimation Evaluation.](http://arxiv.org/abs/2307.15176) | 该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。 |
| [^58] | [Causative Cyberattacks on Online Learning-based Automated Demand Response Systems.](http://arxiv.org/abs/2307.15175) | 该论文研究了在线学习型自动需求响应系统存在的因果性网络攻击漏洞，并设计了一种数据驱动的攻击策略来模拟对实时需求响应的恶意篡改。 |
| [^59] | [PredictChain: Empowering Collaboration and Data Accessibility for AI in a Decentralized Blockchain-based Marketplace.](http://arxiv.org/abs/2307.15168) | PredictChain是一个基于区块链的市场，旨在解决通过提供合作和数据可访问性的机制来训练和利用预测性机器学习模型时所面临的计算资源和训练数据有限访问的挑战。 |
| [^60] | [VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings.](http://arxiv.org/abs/2307.15164) | 本研究中，我们开发了一种利用深度学习模型和词嵌入表示的策略来捕捉复杂对话中情绪表达的微妙差异。我们的实验结果在情绪检测任务中取得了良好的效果，并在小样本和不平衡的混合目标情绪数据集中得到了验证。 |
| [^61] | [R-LPIPS: An Adversarially Robust Perceptual Similarity Metric.](http://arxiv.org/abs/2307.15157) | 该论文提出了一种针对对抗性示例具有鲁棒性的新型感知相似度度量方法R-LPIPS，用于解决在计算机视觉中广泛采用的LPIPS度量方法对对抗性示例的敏感性问题。 |
| [^62] | [A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity.](http://arxiv.org/abs/2307.15154) | 本文研究了在非稳态环境中的线性赌博机的最佳臂识别问题，提出了一种具有鲁棒性的算法来解决。该算法通过在每个时间步从一个G-最优设计中随机选择臂来实现最佳臂的鲁棒识别。 |
| [^63] | [R-Block: Regularized Block of Dropout for convolutional networks.](http://arxiv.org/abs/2307.15150) | 本文提出了一种名为R-Block的新型正则化Dropout块，通过互学习训练策略强制两个子模型的输出一致性，以解决卷积层中Dropout效果较差的问题。 |
| [^64] | [Detecting Morphing Attacks via Continual Incremental Training.](http://arxiv.org/abs/2307.15105) | 本文通过模拟更新学习模型以适应可变大小的新数据块的情景，研究了不同持续学习方法在检测变形攻击中的性能。实验结果表明，无遗忘学习（LwF）是表现最好的算法之一。 |
| [^65] | [Detection of Children Abuse by Voice and Audio Classification by Short-Time Fourier Transform Machine Learning implemented on Nvidia Edge GPU device.](http://arxiv.org/abs/2307.15101) | 通过机器学习技术，在Nvidia Edge GPU设备上利用声音和音频分类，成功实现了对儿童虐待的检测，确保了儿童的安全。 |
| [^66] | [Clustering of illustrations by atmosphere using a combination of supervised and unsupervised learning.](http://arxiv.org/abs/2307.15099) | 本文提出了一种使用监督和无监督学习的组合方法，通过伪标签对插图进行特征向量的提取，并基于这些特征向量进行聚类，从而解决了插图按照氛围进行分类的问题。 |
| [^67] | [Self-Supervised Learning for Improved Synthetic Aperture Sonar Target Recognition.](http://arxiv.org/abs/2307.15098) | 本研究探索了在合成孔径声纳（SAS）图像中应用自监督学习（SSL）进行目标识别的方法，并评估了两种自监督学习算法的性能。研究结果表明，SSL模型可以在没有标签的数据中学习特征，提高目标识别的效果。 |
| [^68] | [Cascaded Cross-Modal Transformer for Request and Complaint Detection.](http://arxiv.org/abs/2307.15097) | 本文提出了一种级联跨模态Transformer模型，结合语音和文本转录，用于检测电话对话中的客户请求和投诉。在ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，我们的系统在投诉和请求类别中达到了65.41%和85.87%的不平衡平均召回率。 |
| [^69] | [A Survey on Reservoir Computing and its Interdisciplinary Applications Beyond Traditional Machine Learning.](http://arxiv.org/abs/2307.15092) | 沉积计算是一个具有随机连接的循环神经网络，其简单的结构和丰富的动力学使其在各种应用中能够生成适当的响应。它的跨学科应用包括物理硬件实现和生物设备，同时也有助于理解大脑机制。 |
| [^70] | [Understanding Forward Process of Convolutional Neural Network.](http://arxiv.org/abs/2307.15090) | 本文揭示了CNN前向处理中的选择性旋转机制，并通过使用结构化数学工具对数据进行统计和分析，发现了人工神经网络和人脑在数据处理模式上的一致性。 |
| [^71] | [Information Gained Subgroup Discovery in Datasets.](http://arxiv.org/abs/2307.15089) | 该论文研究了在数据集中通过信息提升的方法进行子群发现。具体针对肺癌治疗，在保持或提高治疗效果的同时减少副作用对于改善患者的生活质量非常重要，临床指南虽然提供了治疗建议，但仍未将治疗结果纳入考量。 |
| [^72] | [Equitable Time-Varying Pricing Tariff Design: A Joint Learning and Optimization Approach.](http://arxiv.org/abs/2307.15088) | 本文提出了一种联合学习和优化方法，用于设计具有公平性的时变定价电费。通过基于循环神经网络的学习方法捕捉消费者价格响应行为，并将之嵌入到定价方案优化中，实现了保护低收入消费者免受价格波动的效果，同时有效激励了能源调整行为。 |
| [^73] | [Mathematical Modeling of BCG-based Bladder Cancer Treatment Using Socio-Demographics.](http://arxiv.org/abs/2307.15084) | 本研究利用患者的社会人口统计数据提供个性化的数学模型，以描述基于BCG的膀胱癌治疗的临床动态。 |
| [^74] | [Knowledge Graph Enhanced Intelligent Tutoring System Based on Exercise Representativeness and Informativeness.](http://arxiv.org/abs/2307.15076) | 本论文提出了一种基于知识图谱的智能辅导系统框架，通过考虑练习的代表性和信息丰富度，以及引入新颖的认知诊断模型，解决了传统算法中对练习特征建模的不足。 |
| [^75] | [ISAC-NET: Model-driven Deep Learning for Integrated Passive Sensing and Communication.](http://arxiv.org/abs/2307.15074) | 本文介绍了一种名为ISAC-NET的模型驱动的深度学习方法，将被动感知与通信信号检测相结合，通过同时获得被动感知结果和通信解调符号来解决被动感知在通信解调错误条件下的高感知性能问题。 |
| [^76] | [Drug Discovery under Covariate Shift with Domain-Informed Prior Distributions over Functions.](http://arxiv.org/abs/2307.15073) | 这篇论文提出了一种基于领域信息的先验分布模型Q-SAVI，能够解决药物发现中标签数据稀缺和特征转移的问题，并提供了一种透明且概率上合理的数据驱动模型建模方式。 |
| [^77] | [Detecting the Presence of COVID-19 Vaccination Hesitancy from South African Twitter Data Using Machine Learning.](http://arxiv.org/abs/2307.15072) | 本研究通过对南非疫苗犹豫相关推文进行情感分析和机器学习模型训练，检测出COVID-19疫苗犹豫情绪的存在并对用户生成内容进行分类。这对于应对疫苗犹豫对公共卫生工作的影响具有重要意义。 |
| [^78] | [Set-Membership Inference Attacks using Data Watermarking.](http://arxiv.org/abs/2307.15067) | 本文提出了一种使用深度图像水印技术进行生成模型的集合成员推理攻击，通过条件采样揭示训练数据中的水印，并证明该技术能够有效检测非法使用图像数据训练模型。 |
| [^79] | [A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs.](http://arxiv.org/abs/2307.14940) | 本论文提出了一种自适应惩罚算法，用于将约束的自然系统集成到神经常微分方程中，通过引入先验知识提高了模型的可解释性，并通过数值实验证明了其有效性。 |
| [^80] | [Solving Data Quality Problems with Desbordante: a Demo.](http://arxiv.org/abs/2307.14935) | Desbordante是一个旨在解决数据质量问题的工具，通过发现和验证复杂统计信息来帮助现代数据科学家进行数据概要分析。它提供了与现有工具的适当集成，同时考虑到工业级工作负载，并提供描述性的解释来解释模式缺失的原因。 |
| [^81] | [MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy.](http://arxiv.org/abs/2307.14643) | 本文提出了一种基于最大类间差异和最小冗余的非参数特征选择算法(MVMR-FS)，通过使用有监督和无监督核密度估计来度量特征之间的相关性和冗余，并提出了最大类间差异和最小冗余的准则(MVMR)，以辅助特征选择。 |
| [^82] | [Neural Schr\"odinger Bridge with Sinkhorn Losses: Application to Data-driven Minimum Effort Control of Colloidal Self-assembly.](http://arxiv.org/abs/2307.14442) | 本文介绍了一种基于神经网络的Schr\"odinger桥接算法，应用于胶体自组装的最小工作控制问题中。与现有方法相比，该方法考虑了胶体自组装中的非线性控制系数，并提出了一种数据驱动的学习和控制框架。 |
| [^83] | [ARB: Advanced Reasoning Benchmark for Large Language Models.](http://arxiv.org/abs/2307.13692) | ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。 |
| [^84] | [Duet: efficient and scalable hybriD neUral rElation undersTanding.](http://arxiv.org/abs/2307.13494) | Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。 |
| [^85] | [Conformal prediction for frequency-severity modeling.](http://arxiv.org/abs/2307.13124) | 这个论文提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，扩展了split conformal prediction技术到两阶段频率-严重性建模领域，并通过使用随机森林作为严重性模型，利用了袋外机制消除了校准集的需要，并实现了具有自适应宽度的预测区间的生成。 |
| [^86] | [A Deep Learning Approach for Overall Survival Analysis with Missing Values.](http://arxiv.org/abs/2307.11465) | 提出了一个深度学习模型，通过有效利用被审查和未被审查病人的信息，预测非小细胞肺癌（NSCLC）病人的整体生存。 |
| [^87] | [Creating a Dataset Supporting Translation Between OpenMP Fortran and C++ Code.](http://arxiv.org/abs/2307.07686) | 本研究创建了一个数据集，用于训练机器学习模型在OpenMP Fortran和C++代码之间进行翻译。这个数据集通过精细的代码相似性测试确保了可靠性和适用性，并且能够显著提升大规模语言模型的翻译能力。 |
| [^88] | [Dynamic Feature-based Deep Reinforcement Learning for Flow Control of Circular Cylinder with Sparse Surface Pressure Sensing.](http://arxiv.org/abs/2307.01995) | 本研究提出了一种基于动态特征的深度强化学习算法，针对稀疏表面压力传感器下的循环气缸流控制，实现了降低阻力和减小升力波动的目标。通过将传感器信号提取为动态特征，该算法能够自动学习并预测未来的流动状态，从而使得控制性能能够在不降低的情况下使用稀疏传感器感知流动。该方法在阻力系数和升力系数的改善上取得了显著的成果。 |
| [^89] | [A Conditional Flow Variational Autoencoder for Controllable Synthesis of Virtual Populations of Anatomy.](http://arxiv.org/abs/2306.14680) | 这篇论文提出了一种使用条件流变分自编码器来可控合成解剖学虚拟人群的方法，通过使用相关协变量，可以根据特定的目标人群/特征合成虚拟人群，具有较高的灵活性和复杂性。 |
| [^90] | [Automating Model Comparison in Factor Graphs.](http://arxiv.org/abs/2306.05965) | 本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。 |
| [^91] | [SACSoN: Scalable Autonomous Data Collection for Social Navigation.](http://arxiv.org/abs/2306.01874) | 本文介绍了一个名为SACSoN的自主导航机器人系统，可以在人类占用的现实场景中，通过视觉理解和学习，自主收集数据，实现更好的数据集拓展。 |
| [^92] | [FACT: Federated Adversarial Cross Training.](http://arxiv.org/abs/2306.00607) | FACT是一种联邦敌对交叉训练算法，利用源客户端之间的隐式领域差异来识别目标领域的领域转移。实验证明，FACT在多源单目标基准上优于其他模型，并且优于无监督领域适应模型。 |
| [^93] | [Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study.](http://arxiv.org/abs/2305.11164) | 本论文通过分析Hugging Face上1,417个ML模型及相关数据集的碳足迹测量情况，提出了有关如何报告和优化ML模型的碳效率的见解和建议。 |
| [^94] | [Graph Neural Networks and 3-Dimensional Topology.](http://arxiv.org/abs/2305.05966) | 本研究利用图神经网络解决了一类由管道图描述的三维流形分类问题，并训练了一个高准确性的GNN模型，同时介绍了GNN在增强学习中的应用。 |
| [^95] | [No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models using Differentiable Quantile Function Approximations.](http://arxiv.org/abs/2305.03824) | 本文提出了一种新颖的算法，CUQB，来解决复合函数（混合模型）的高效约束全局优化问题，并取得了良好的效果，在合成和真实的应用程序中均得到了验证，包括进行了最优控制的流体流量和拓扑结构优化，后者比当前最先进的设计强2倍。 |
| [^96] | [Multi-Domain Learning From Insufficient Annotations.](http://arxiv.org/abs/2305.02757) | 提出了一种名为多领域对比学习（MDCL）的新方法，在原有方法的基础上，利用来自标记和未标记数据的语义和结构信息，解决了不充分注释的问题，并在实验中取得了优异的成果。 |
| [^97] | [Earning Extra Performance from Restrictive Feedbacks.](http://arxiv.org/abs/2304.14831) | 本文提出了一个名为EXPECTED的挑战，解决模型调整问题，模型提供者可以通过来自本地用户的反馈多次访问候选模型的操作性能，从而优化模型，同时不需要依赖目标数据。 |
| [^98] | [VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.](http://arxiv.org/abs/2304.07810) | VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。 |
| [^99] | [Unsupervised ANN-Based Equalizer and Its Trainable FPGA Implementation.](http://arxiv.org/abs/2304.06987) | 本文提出了一种无监督基于ANN的均衡器及其可训练的FPGA实现，通过自定义的损失函数使其能够适应不同的信道条件，并实现了高效率的通信系统。 |
| [^100] | [Swarm Reinforcement Learning For Adaptive Mesh Refinement.](http://arxiv.org/abs/2304.00818) | 这项研究提出了一种适应网格细化的群体强化学习方法，通过将网格建模为一组简单协作的代理，并利用消息传递网络在相邻网格元素之间传播信息，以解决传统方法在复杂模拟中的应用限制。该方法被证实可以学习可靠、可扩展的网格细化策略。 |
| [^101] | [Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging.](http://arxiv.org/abs/2303.07189) | 本文旨在通过探索手动调整和自动化窗口设置优化，利用卷积神经网络在临床计算机断层扫描图像中检测慢性阻塞性肺疾病。研究结果表明，通过添加自定义层实现的自动化窗口设置优化可以改善检测性能。 |
| [^102] | [Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.01170) | 本文提出了Expert-Free Online Transfer Learning (EF-OnTL)算法，在多智能体系统中实现无专家的实时迁移学习。通过动态选择迁移源智能体和要转移的知识，解决了传统迁移学习需要对专家智能体任务有良好理解的问题。 |
| [^103] | [Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework.](http://arxiv.org/abs/2302.12247) | 通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。 |
| [^104] | [A Definition of Non-Stationary Bandits.](http://arxiv.org/abs/2302.12202) | 该论文提出了一个解决非稳态赌博机定义歧义的新定义，解决了之前定义中的问题并修复了代理设计中探索过度的情况。 |
| [^105] | [Multi-modal Machine Learning in Engineering Design: A Review and Future Directions.](http://arxiv.org/abs/2302.10909) | 本文综述了工程设计领域中多模态机器学习（MMML）的当前状态、进展和挑战，重点介绍了多模态信息表示、融合、对齐、转换和共学习的基本概念，以及与工程设计相关的前沿应用。我们提出了未来研究的潜在方向，包括构建广泛的数据集和基准测试环境，以促进算法性能的评估和比较。 |
| [^106] | [Deep Neural Networks based Meta-Learning for Network Intrusion Detection.](http://arxiv.org/abs/2302.09394) | 本研究提出了一种基于深度神经网络的元学习框架，INFUSE，用于网络入侵检测。该框架通过整合决策空间和特征空间创建混合特征空间，并使用五个不同的分类器进行分类和预测。 |
| [^107] | [Post-Episodic Reinforcement Learning Inference.](http://arxiv.org/abs/2302.08854) | 我们提出了一种后期情节式强化学习推断的方法，能够评估反事实的自适应策略并估计动态处理效应，通过重新加权的$Z$-估计方法稳定情节变化的估计方差。 |
| [^108] | [Automatic Intersection Management in Mixed Traffic Using Reinforcement Learning and Graph Neural Networks.](http://arxiv.org/abs/2301.12717) | 本研究提出了一种利用强化学习和图神经网络进行混合交通中的自动化交叉口管理的方法，该方法考虑到了人驾驶员的不确定性，并通过仿真评估进行了验证。 |
| [^109] | [DiME: Maximizing Mutual Information by a Difference of Matrix-Based Entropies.](http://arxiv.org/abs/2301.08164) | 本文提出了一种称为DiME的信息理论量，可以估计随机变量之间的互信息最大化，避免了平凡解，适用于多个实际应用。 |
| [^110] | [Towards Answering Climate Questionnaires from Unstructured Climate Reports.](http://arxiv.org/abs/2301.04253) | 本研究提出了一种从非结构化的气候报告中回答气候问卷的方法。研究引入两个新的大规模气候问卷数据集，并使用现有结构训练自监督模型，通过实验和人类试验验证了模型的有效性。同时，还引入了一个气候文本分类数据集的基准，以促进气候领域的自然语言处理研究。 |
| [^111] | [Consistent Range Approximation for Fair Predictive Modeling.](http://arxiv.org/abs/2212.10839) | 本文提出了一个新颖的框架，用于验证基于有偏数据训练的预测模型的公平性。通过一致范围逼近的方法，在目标人群上构建了可证明公平的预测模型，并在真实数据上展示了明显的改进。 |
| [^112] | [Shapley Curves: A Smoothing Perspective.](http://arxiv.org/abs/2211.13289) | 本文以平滑的角度引入了Shapley曲线作为局部变量重要性的度量，提出了两种估计策略，并在特征的独立和依赖情况下得到了一致性和渐近正态性，为估计的Shapley曲线构建了置信区间并进行了推断，通过实验证实了渐近结果。应用中分析了哪些属性驱动车辆价格。 |
| [^113] | [A Bi-level Nonlinear Eigenvector Algorithm for Wasserstein Discriminant Analysis.](http://arxiv.org/abs/2211.11891) | 本文提出了一种基于双层非线性特征向量算法（WDA-nepv）的Wasserstein判别分析方法，通过最大化不同类别的离散度，并最小化相同类别的离散度，充分利用WDA的双层优化结构，并在自洽场框架下高效求解。 |
| [^114] | [Resource frugal optimizer for quantum machine learning.](http://arxiv.org/abs/2211.04965) | 提出了一种名为Refoqus的资源节约的量子随机梯度下降优化器，通过同时随机采样数据集和测量操作，能够保存大量资源。 |
| [^115] | [Mitigating spectral bias for the multiscale operator learning with hierarchical attention.](http://arxiv.org/abs/2210.10890) | 本文提出了一种分层注意力神经算子（HANO），用于解决多尺度偏微分方程学习中存在的光谱偏差问题，并通过数值实验证明其优于现有方法。 |
| [^116] | [Learning Provably Stabilizing Neural Controllers for Discrete-Time Stochastic Systems.](http://arxiv.org/abs/2210.05304) | 本文提出了一种学习离散时间随机系统中的神经控制器的方法，该方法能够以概率1在指定的稳定区域内实现系统稳定，并引入了稳定排序超级鞅(sRSMs)的概念来克服先前方法的局限性。实验结果证明了该方法的有效性。 |
| [^117] | [Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results.](http://arxiv.org/abs/2209.14272) | 本研究提出了Passau-SFCH数据集，包含了11小时的录音，用于自发幽默的预测。通过多模态的分析和特征融合，实现了对幽默以及幽默情感的自动识别。 |
| [^118] | [SynthA1c: Towards Clinically Interpretable Patient Representations for Diabetes Risk Stratification.](http://arxiv.org/abs/2209.10043) | 该论文提出了一种名为SynthA1c的方法，利用图像数据来预测2型糖尿病风险，避免了额外的血液实验室测量，其敏感性高达87.6%。 |
| [^119] | [Cross-Domain Evaluation of a Deep Learning-Based Type Inference System.](http://arxiv.org/abs/2208.09189) | 本文研究了基于深度学习的类型推断系统Type4Py的跨领域泛化能力，并通过广泛的实验表明，Type4Py在应用于不同领域的类型推断时能够提供优异的性能。 |
| [^120] | [Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success.](http://arxiv.org/abs/2208.07734) | 这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。 |
| [^121] | [Multi-fidelity wavelet neural operator with application to uncertainty quantification.](http://arxiv.org/abs/2208.05606) | 提出了一个基于小波神经算子的多保真度学习框架，可以利用廉价的低保真度数据和昂贵的高保真度数据进行训练。该框架展示了出色的学习能力，并解决了需要有效相关性学习的问题。 |
| [^122] | [Trace Recovery from Stochastically Known Logs.](http://arxiv.org/abs/2206.12672) | 本文提出了一种从随机已知日志中恢复轨迹的算法，在两个公开数据集上平均恢复准确度达到90-97%。这一方法通过计算流程模型和随机已知轨迹的合规性，并恢复在该随机轨迹中的最佳对齐作为真实轨迹。对比其他轨迹恢复选项，使用了产品多图来分析成本模型对恢复准确性的影响。这一算法对于预测模型开发、错误排查和系统性能改进具有重要意义。 |
| [^123] | [Fail-Safe Adversarial Generative Imitation Learning.](http://arxiv.org/abs/2203.01696) | 提出了一种灵活而安全的模仿学习方法，包括一个安全层，使得生成连续策略的概率密度/梯度成为闭合形式，提供了端到端的生成对抗训练和最坏情况下的安全保证。采用对抗可达性分析和利普希茨连续性等方法，通过推断行动邻域的安全性来确定一组安全行动。在实际驾驶员交互数据的实验中，展示了该方法的可行性和鲁棒性优势。 |
| [^124] | [Learning a Discrete Set of Optimal Allocation Rules in a Queueing System with Unknown Service Rate.](http://arxiv.org/abs/2202.02419) | 该论文研究了在具有未知到达和服务率的排队系统中的入场控制问题。通过观察到到达时间和系统状态，我们旨在设计一种调度策略，以最大化调度员的长期平均回报。标准的强化学习方法不适用于此问题，因为调度员无法观察到服务时间和离开时间。 |
| [^125] | [Fairness-aware Online Price Discrimination with Nonparametric Demand Models.](http://arxiv.org/abs/2111.08221) | 本论文研究了在公平性约束下的动态歧视性定价问题，针对在线零售中存在的价格歧视问题，提出了一种公平感知的解决方法，旨在在最大化收入的同时确保公平性。 |
| [^126] | [Dynamic Silos: Increased Modularity in Intra-organizational Communication Networks during the Covid-19 Pandemic.](http://arxiv.org/abs/2104.00641) | COVID-19大流行期间，世界各地的组织在沟通上变得更加孤立，模块化增加，员工开始更加灵活地进行沟通。 |

# 详细

[^1]: 少量子激活下量子噪声受限的光学神经网络

    Quantum-noise-limited optical neural networks operating at a few quanta per activation. (arXiv:2307.15712v1 [physics.optics])

    [http://arxiv.org/abs/2307.15712](http://arxiv.org/abs/2307.15712)

    本文研究了在极低功率下操作的光学神经网络，其中一些层只使用一个光子来引发神经元激活。尽管存在极高的噪声，仍可以训练这些网络以高精度执行确定性图像分类任务。

    

    模拟物理神经网络被通常在相对高功率下操作，以保证信噪比大于10。本文研究了在极低功率下操作模拟系统时会发生什么，即系统行为变得高度随机且噪声不再是信号的小扰动。我们在光学神经网络中研究了这个问题，其中一些层只使用一个光子来引发神经元激活。在这种极低功率下，神经元激活受到量子噪声的主导，这是由于单光子检测弱光信号的基本概率性质。我们表明，尽管噪声极大（信噪比约为1），仍然可以训练随机光学神经网络以高精度执行确定性图像分类任务。

    Analog physical neural networks, which hold promise for improved energy efficiency and speed compared to digital electronic neural networks, are nevertheless typically operated in a relatively high-power regime so that the signal-to-noise ratio (SNR) is large (>10). What happens if an analog system is instead operated in an ultra-low-power regime, in which the behavior of the system becomes highly stochastic and the noise is no longer a small perturbation on the signal? In this paper, we study this question in the setting of optical neural networks operated in the limit where some layers use only a single photon to cause a neuron activation. Neuron activations in this limit are dominated by quantum noise from the fundamentally probabilistic nature of single-photon detection of weak optical signals. We show that it is possible to train stochastic optical neural networks to perform deterministic image-classification tasks with high accuracy in spite of the extremely high noise (SNR ~ 1) 
    
[^2]: 半监督开放世界目标检测

    Semi-Supervised Object Detection in the Open World. (arXiv:2307.15710v1 [cs.CV])

    [http://arxiv.org/abs/2307.15710](http://arxiv.org/abs/2307.15710)

    本文提出了一种半监督开放世界目标检测框架，能够有效地检测分布外的数据并从中学习，通过基于集成的OOD检测器和半监督学习方法，实现与最先进方法相当的性能。

    

    现有的半监督目标检测方法假设训练数据和未标记数据集中有一组固定的类别，即属于分布内（ID）的数据。然而，当这些方法在开放世界中应用时，性能显著下降，因为未标记和测试数据可能包含训练过程中未见过的对象，即属于分布外（OOD）的数据。本文探讨两个关键问题：我们是否能够检测这些OOD样本，如果可以，我们是否能够从中学习？考虑到这些问题，我们提出了一种有效的开放世界半监督检测框架（OWSSD），其能够有效地检测OOD数据，并通过半监督学习从ID和OOD数据中进行学习。我们引入了一个基于集成的OOD检测器，由仅在ID数据上训练的轻量级自编码器网络组成。通过广泛的评估，我们证明了我们的方法在OOD目标检测方面与最先进的方法竞争力相当。

    Existing approaches for semi-supervised object detection assume a fixed set of classes present in training and unlabeled datasets, i.e., in-distribution (ID) data. The performance of these techniques significantly degrades when these techniques are deployed in the open-world, due to the fact that the unlabeled and test data may contain objects that were not seen during training, i.e., out-of-distribution (OOD) data. The two key questions that we explore in this paper are: can we detect these OOD samples and if so, can we learn from them? With these considerations in mind, we propose the Open World Semi-supervised Detection framework (OWSSD) that effectively detects OOD data along with a semi-supervised learning pipeline that learns from both ID and OOD data. We introduce an ensemble based OOD detector consisting of lightweight auto-encoder networks trained only on ID data. Through extensive evalulation, we demonstrate that our method performs competitively against state-of-the-art OOD 
    
[^3]: 自然语言生成中的不确定性：从理论到应用

    Uncertainty in Natural Language Generation: From Theory to Applications. (arXiv:2307.15703v1 [cs.CL])

    [http://arxiv.org/abs/2307.15703](http://arxiv.org/abs/2307.15703)

    本文介绍了自然语言生成中不确定性的理论、应用和分类，提出了一种更详细和真实的分类法。

    

    最近强大的语言模型的进展使得自然语言生成（NLG）作为一种重要技术崭露头角，它不仅可以执行传统任务如摘要或翻译，也可以作为一种自然语言接口应用于各种应用程序。因此，NLG系统的可靠性和可信度至关重要，例如在可能出错时指示，并支持多种观点、背景和写作风格 - 反映多元化人类亚群体。本文认为，对不确定性的原则性处理能够帮助创建与这些目标更好地对齐的系统和评估协议。我们首先介绍表示不确定性所需的基本理论、框架和词汇。然后从语言学的角度描述NLG中的主要不确定性源，并提出一个比流行的随机性/认识性二分法更详细和真实的二维分类法。

    Recent advances of powerful Language Models have allowed Natural Language Generation (NLG) to emerge as an important technology that can not only perform traditional tasks like summarisation or translation, but also serve as a natural language interface to a variety of applications. As such, it is crucial that NLG systems are trustworthy and reliable, for example by indicating when they are likely to be wrong; and supporting multiple views, backgrounds and writing styles -- reflecting diverse human sub-populations. In this paper, we argue that a principled treatment of uncertainty can assist in creating systems and evaluation protocols better aligned with these goals. We first present the fundamental theory, frameworks and vocabulary required to represent uncertainty. We then characterise the main sources of uncertainty in NLG from a linguistic perspective, and propose a two-dimensional taxonomy that is more informative and faithful than the popular aleatoric/epistemic dichotomy. Final
    
[^4]: 用于流数据的通用递归事件记忆

    Universal Recurrent Event Memories for Streaming Data. (arXiv:2307.15694v1 [cs.LG])

    [http://arxiv.org/abs/2307.15694](http://arxiv.org/abs/2307.15694)

    本文提出了一种名为MemNet的通用递归事件记忆架构（MemNet），适用于不同类型的时间序列数据，并通过存储键值对来改善表示效果。MemNet具有线性自适应映射函数，适用于标量时间序列、逻辑运算和自然语言处理，并在各个应用领域中取得了最先进的结果。

    

    本文提出了一种新的递归神经网络事件记忆架构（MemNet），适用于标量、多变量或符号类型的时间序列数据。与其他外部神经记忆架构不同的是，它存储了键值对，将寻址和内容信息分离，从而提高表示效果，类似于数字典典型。此外，键值对还避免了内存深度和分辨率之间的折中，这适用于模型状态构建的记忆。MemNet的一个关键特点是，在对输入数据执行非线性操作时，只需要线性自适应映射函数。MemNet架构可以直接应用于标量时间序列、字符串的逻辑运算以及自然语言处理，为混沌时间序列、符号操作任务和问题回答等各个应用领域提供了最先进的结果。

    In this paper, we propose a new event memory architecture (MemNet) for recurrent neural networks, which is universal for different types of time series data such as scalar, multivariate or symbolic. Unlike other external neural memory architectures, it stores key-value pairs, which separate the information for addressing and for content to improve the representation, as in the digital archetype. Moreover, the key-value pairs also avoid the compromise between memory depth and resolution that applies to memories constructed by the model state. One of the MemNet key characteristics is that it requires only linear adaptive mapping functions while implementing a nonlinear operation on the input data. MemNet architecture can be applied without modifications to scalar time series, logic operators on strings, and also to natural language processing, providing state-of-the-art results in all application domains such as the chaotic time series, the symbolic operation tasks, and the question-answ
    
[^5]: ODTlearn: 一个用于学习预测和处方的最优决策树的包

    ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription. (arXiv:2307.15691v1 [stat.ML])

    [http://arxiv.org/abs/2307.15691](http://arxiv.org/abs/2307.15691)

    ODTlearn是一个开源的Python包，用于学习预测和处方的最优决策树。它提供了多种优化方法，并支持各种问题和算法的扩展。

    

    ODTLearn是一个开源的Python包，提供了基于混合整数优化(MIO)框架的高风险预测和处方任务的最优决策树学习方法。该包的当前版本提供了学习最优分类树、公平最优分类树、鲁棒最优分类树和从观测数据学习最优处方树的实现。我们设计了该包以便于维护和扩展，当引入新的最优决策树问题类、重构策略和解决算法时，可以轻松更新。为此，该包遵循面向对象的设计原则，并支持商业(Gurobi)和开源(COIN-OR branch and cut)求解器。包的文档和详细用户指南可以在https://d3m-research-group.github.io/odtlearn/找到。

    ODTLearn is an open-source Python package that provides methods for learning optimal decision trees for high-stakes predictive and prescriptive tasks based on the mixed-integer optimization (MIO) framework proposed in Aghaei et al. (2019) and several of its extensions. The current version of the package provides implementations for learning optimal classification trees, optimal fair classification trees, optimal classification trees robust to distribution shifts, and optimal prescriptive trees from observational data. We have designed the package to be easy to maintain and extend as new optimal decision tree problem classes, reformulation strategies, and solution algorithms are introduced. To this end, the package follows object-oriented design principles and supports both commercial (Gurobi) and open source (COIN-OR branch and cut) solvers. The package documentation and an extensive user guide can be found at https://d3m-research-group.github.io/odtlearn/. Additionally, users can view
    
[^6]: 在真实机器人硬件上进行离线强化学习的基准测试

    Benchmarking Offline Reinforcement Learning on Real-Robot Hardware. (arXiv:2307.15690v1 [cs.LG])

    [http://arxiv.org/abs/2307.15690](http://arxiv.org/abs/2307.15690)

    从预先记录的数据中学习策略在解决真实世界机器人任务中具有潜力，该论文提出了一个基准测试，包括大量来自模拟环境的数据集以及在真实机器人系统和模拟环境中执行学习策略的选项，用于推动离线强化学习的研究。

    

    从预先记录的数据中学习策略是解决真实世界机器人任务的有希望的方向，因为在线学习通常是不可行的。特别是在灵巧操作领域，目前仍然存在着通用形式的难题。然而，离线强化学习与大型多样数据集的结合有潜力在这个具有挑战性的领域取得突破，类似于近年来在监督学习方面取得的快速进展。为了协调研究社区的努力来解决这个问题，我们提出了一个基准测试，包括：i）从模拟环境中通过强化学习训练能力强大的代理智能体在两个任务上获得的用于离线学习的大量数据集；ii）在真实世界机器人系统和模拟环境上执行学习策略以便进行高效的调试。我们评估了主流的开源离线强化学习算法，并提供了可重复实验的设置。

    Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse datasets, however, has the potential to lead to a breakthrough in this challenging domain analogously to the rapid progress made in supervised learning in recent years. To coordinate the efforts of the research community toward tackling this problem, we propose a benchmark including: i) a large collection of data for offline learning from a dexterous manipulation platform on two tasks, obtained with capable RL agents trained in simulation; ii) the option to execute learned policies on a real-world robotic system and a simulation for efficient debugging. We evaluate prominent open-sourced offline reinforcement learning algorithms on the datasets and provide a reproducible experimental setup for of
    
[^7]: 一种用于应急逃生路径问题的监督式混合量子机器学习解决方案

    A supervised hybrid quantum machine learning solution to the emergency escape routing problem. (arXiv:2307.15682v1 [quant-ph])

    [http://arxiv.org/abs/2307.15682](http://arxiv.org/abs/2307.15682)

    本文研究了使用监督式混合量子机器学习来优化自然灾害中汽车紧急疏散计划的潜力，并提出了一种新颖的混合监督学习方法来模拟最短路径算法。

    

    有效管理对自然灾害的响应可以大大减轻其破坏性影响。本文探讨了使用监督式混合量子机器学习来优化自然灾害中汽车紧急疏散计划的潜力。该研究聚焦于地震紧急情况，将问题建模为一个动态计算图，地震破坏城市的一部分。居民试图通过到达交通拥堵发生的出口点来撤离城市。该情况被建模为在不确定和动态演化的地图上的最短路径问题。我们提出了一种新颖的混合监督学习方法，并在具体城市图上的假设情况下进行了测试。该方法使用了一种新颖的量子功能线性调制(FiLM)神经网络，与一个经典的FiLM网络并行，以模仿确定性动态图上的Dijkstra节点最短路径算法。并行添加量子神经网络

    Managing the response to natural disasters effectively can considerably mitigate their devastating impact. This work explores the potential of using supervised hybrid quantum machine learning to optimize emergency evacuation plans for cars during natural disasters. The study focuses on earthquake emergencies and models the problem as a dynamic computational graph where an earthquake damages an area of a city. The residents seek to evacuate the city by reaching the exit points where traffic congestion occurs. The situation is modeled as a shortest-path problem on an uncertain and dynamically evolving map. We propose a novel hybrid supervised learning approach and test it on hypothetical situations on a concrete city graph. This approach uses a novel quantum feature-wise linear modulation (FiLM) neural network parallel to a classical FiLM network to imitate Dijkstra's node-wise shortest path algorithm on a deterministic dynamic graph. Adding the quantum neural network in parallel increas
    
[^8]: 递归神经网络的动态分析和特征值初始化器

    Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks. (arXiv:2307.15679v1 [cs.LG])

    [http://arxiv.org/abs/2307.15679](http://arxiv.org/abs/2307.15679)

    本文研究了递归神经网络中的隐藏状态动态，并提出了一种新的角度来分析隐藏状态空间。基于特征值分析，我们提供了长期依赖性的解释，并在此基础上提出了递归神经网络的新初始化方法。

    

    在递归神经网络中，由于梯度消失和梯度爆炸问题，学习长期依赖性是主要难点。许多研究人员致力于解决这个问题，并提出了许多算法。尽管这些算法取得了很大的成功，但对信息衰减的理解仍然是一个开放的问题。本文研究了递归神经网络中的隐藏状态动态。我们提出了一种基于权重矩阵的特征值分解的隐藏状态空间分析新视角。我们从线性状态空间模型开始分析，并解释了激活函数中信息保留的功能。我们基于特征值分析提供了长期依赖性的解释。我们还指出了回归任务和分类任务特征值行为的差异。通过对训练良好的递归神经网络的观察，我们提出了一种递归神经网络的新初始化方法。

    In recurrent neural networks, learning long-term dependency is the main difficulty due to the vanishing and exploding gradient problem. Many researchers are dedicated to solving this issue and they proposed many algorithms. Although these algorithms have achieved great success, understanding how the information decays remains an open problem. In this paper, we study the dynamics of the hidden state in recurrent neural networks. We propose a new perspective to analyze the hidden state space based on an eigen decomposition of the weight matrix. We start the analysis by linear state space model and explain the function of preserving information in activation functions. We provide an explanation for long-term dependency based on the eigen analysis. We also point out the different behavior of eigenvalues for regression tasks and classification tasks. From the observations on well-trained recurrent neural networks, we proposed a new initialization method for recurrent neural networks, which 
    
[^9]: IT监控时间序列的因果推断案例研究

    Case Studies of Causal Discovery from IT Monitoring Time Series. (arXiv:2307.15678v1 [cs.LG])

    [http://arxiv.org/abs/2307.15678](http://arxiv.org/abs/2307.15678)

    本研究通过案例研究，探索了将因果推断算法应用于不同IT监控数据的挑战和潜在益处。

    

    信息技术（IT）系统对现代企业至关重要，处理数据存储、通信和流程自动化。监控这些系统对于其正常运行和效率至关重要，因为它允许收集详细的观测时间序列数据进行分析。随着IT监控系统中对因果推断的兴趣日益增长，了解IT系统不同组件之间的因果关系有助于减少停机时间，提高系统性能，并确定异常和事故的根本原因。它还通过历史数据分析可以预测未来的问题。尽管具有潜在的益处，应用因果推断算法到IT监控数据上面临着挑战，因为数据的复杂性。例如，IT监控数据通常包含不对齐的时间序列、休眠时间序列、时间戳错误和缺失值。本文提出了应用因果推断算法到不同IT监控数据的案例研究。

    Information technology (IT) systems are vital for modern businesses, handling data storage, communication, and process automation. Monitoring these systems is crucial for their proper functioning and efficiency, as it allows collecting extensive observational time series data for analysis. The interest in causal discovery is growing in IT monitoring systems as knowing causal relations between different components of the IT system helps in reducing downtime, enhancing system performance and identifying root causes of anomalies and incidents. It also allows proactive prediction of future issues through historical data analysis. Despite its potential benefits, applying causal discovery algorithms on IT monitoring data poses challenges, due to the complexity of the data. For instance, IT monitoring data often contains misaligned time series, sleeping time series, timestamp errors and missing values. This paper presents case studies on applying causal discovery algorithms to different IT mo
    
[^10]: 用于表格数据的对抗训练与攻击传播

    Adversarial training for tabular data with attack propagation. (arXiv:2307.15677v1 [cs.LG])

    [http://arxiv.org/abs/2307.15677](http://arxiv.org/abs/2307.15677)

    该论文提出了一种针对表格数据的对抗训练方法，通过在训练循环中传播攻击来提高模型的鲁棒性。在信用卡欺诈检测领域的实证结果表明，该方法可以防止约30%的性能下降，并且对于非常激烈的攻击而言是必不可少的。

    

    对抗攻击是安全中心应用中的重大关注点，恶意行为者不断试图将机器学习模型误导为将欺诈行为错误地分类为合法行为，而系统维护者则试图阻止他们。对抗性地训练机器学习模型以抵抗此类攻击可以防止业务损失并减轻系统维护者的工作负担。在这种应用中，数据通常是表格形式，攻击者可以利用进行复杂的特征工程转换，为模型训练提供有用信号，而攻击者无法访问。因此，我们提出了一种新的对抗训练形式，在训练循环中在两个空间之间传播攻击。然后，我们在信用卡欺诈检测领域的真实世界数据集上在实证上测试了这种方法。我们证明了我们的方法在面对中等攻击时可以防止约30%的性能下降，并且在非常激烈的攻击下是必不可少的。

    Adversarial attacks are a major concern in security-centered applications, where malicious actors continuously try to mislead Machine Learning (ML) models into wrongly classifying fraudulent activity as legitimate, whereas system maintainers try to stop them. Adversarially training ML models that are robust against such attacks can prevent business losses and reduce the work load of system maintainers. In such applications data is often tabular and the space available for attackers to manipulate undergoes complex feature engineering transformations, to provide useful signals for model training, to a space attackers cannot access. Thus, we propose a new form of adversarial training where attacks are propagated between the two spaces in the training loop. We then test this method empirically on a real world dataset in the domain of credit card fraud detection. We show that our method can prevent about 30% performance drops under moderate attacks and is essential under very aggressive att
    
[^11]: 基于贝叶斯的时间序列分类器用于从颅内神经活动中解码简单的视觉刺激

    Bayesian Time-Series Classifier for Decoding Simple Visual Stimuli from Intracranial Neural Activity. (arXiv:2307.15672v1 [cs.LG])

    [http://arxiv.org/abs/2307.15672](http://arxiv.org/abs/2307.15672)

    本研究提出了一个基于贝叶斯的时间序列分类器模型，解决了处理有限数据和神经数据中随机性的问题，并在解码颅内神经活动中的简单视觉刺激方面取得了良好的分类结果。该模型在4名患者数据集上表现出75.55％的平均准确率，比先进的机器学习技术提高了约3.0个百分点。此外，该模型提供了可解释的结果，成为研究神经活动的有价值工具。

    

    在临床和基础神经科学中，了解外部刺激如何编码在分布式神经活动中具有重要意义。为了解决这个问题，需要开发能够处理有限数据和神经数据中固有的随机性的分析工具。在本研究中，我们提出了一个简单的贝叶斯时间序列分类器（BTsC）模型，以解决这些挑战，同时保持较高的可解释性水平。我们通过利用神经数据解码视觉任务中的颜色来展示该方法的分类能力。该模型在4名患者数据集上表现出一致可靠的平均性能，平均准确率为75.55％，比先进的机器学习技术提高了约3.0个百分点。除了高分类准确率外，所提出的BTsC模型提供了可解释的结果，使这种技术成为研究各种任务和类别的神经活动的有价值的工具。

    Understanding how external stimuli are encoded in distributed neural activity is of significant interest in clinical and basic neuroscience. To address this need, it is essential to develop analytical tools capable of handling limited data and the intrinsic stochasticity present in neural data. In this study, we propose a straightforward Bayesian time series classifier (BTsC) model that tackles these challenges whilst maintaining a high level of interpretability. We demonstrate the classification capabilities of this approach by utilizing neural data to decode colors in a visual task. The model exhibits consistent and reliable average performance of 75.55% on 4 patients' dataset, improving upon state-of-the-art machine learning techniques by about 3.0 percent. In addition to its high classification accuracy, the proposed BTsC model provides interpretable results, making the technique a valuable tool to study neural activity in various tasks and categories. The proposed solution can be 
    
[^12]: CoRe优化器：机器学习的一体化解决方案

    CoRe Optimizer: An All-in-One Solution for Machine Learning. (arXiv:2307.15663v1 [cs.LG])

    [http://arxiv.org/abs/2307.15663](http://arxiv.org/abs/2307.15663)

    CoRe优化器是一种高性能的机器学习优化器，具有快速、平滑收敛、低计算需求和通用适用性的特点，在训练终身机器学习潜力方面表现出优势。

    

    优化算法及其超参数在机器学习应用中会显著影响训练速度和模型准确度。理想优化器的愿望清单包括快速、平滑地收敛到低误差、低计算需求和通用适用性。我们最近引入的持续弹性（CoRe）优化器在训练终身机器学习潜力方面比其他最先进的一阶梯度优化器表现出更好的性能。在这项工作中，我们对CoRe优化器进行了与其他九种优化算法的广泛性能对比，包括Adam优化器和弹性反向传播（RPROP）。我们分析了不同超参数的影响，并提供了通用适用的值。CoRe优化器在每个研究应用中都取得了最佳或竞争性的性能，只需要更改一个超参数，具体取决于小批量

    The optimization algorithm and its hyperparameters can significantly affect the training speed and resulting model accuracy in machine learning applications. The wish list for an ideal optimizer includes fast and smooth convergence to low error, low computational demand, and general applicability. Our recently introduced continual resilient (CoRe) optimizer has shown superior performance compared to other state-of-the-art first-order gradient-based optimizers for training lifelong machine learning potentials. In this work we provide an extensive performance comparison of the CoRe optimizer and nine other optimization algorithms including the Adam optimizer and resilient backpropagation (RPROP) for diverse machine learning tasks. We analyze the influence of different hyperparameters and provide generally applicable values. The CoRe optimizer yields best or competitive performance in every investigated application, while only one hyperparameter needs to be changed depending on mini-batch
    
[^13]: 多层聚合是基于特征的OOD检测的关键

    Multi-layer Aggregation as a key to feature-based OOD detection. (arXiv:2307.15647v1 [cs.CV])

    [http://arxiv.org/abs/2307.15647](http://arxiv.org/abs/2307.15647)

    该研究比较了多种基于特征的OOD检测方法，在大量OOD图像上进行了实验，并发现多层方法能够提供更好的OOD检测性能。

    

    深度学习模型容易受到输入图像的变化的干扰，这些变化在训练阶段没有观察到，导致无法预测的预测结果。在医学图像分析领域，检测这种非分布（OOD）图像尤其重要，因为可能的异常范围非常广泛。最近，出现了一种基于训练模型的中间特征的方法。这些方法可以分为两组：单层方法考虑在一个固定的、精心选择的层获得的特征图，和多层方法考虑由模型生成的特征映射的集合。虽然有希望，但这些算法的适当比较仍然缺失。在这项工作中，我们在大量的OOD（20种类型）上比较了各种基于特征的OOD检测方法，表示大约7800个3D MRIs。我们的实验揭示了两个现象。首先，多层方法可以提供更好的OOD检测性能。

    Deep Learning models are easily disturbed by variations in the input images that were not observed during the training stage, resulting in unpredictable predictions. Detecting such Out-of-Distribution (OOD) images is particularly crucial in the context of medical image analysis, where the range of possible abnormalities is extremely wide. Recently, a new category of methods has emerged, based on the analysis of the intermediate features of a trained model. These methods can be divided into 2 groups: single-layer methods that consider the feature map obtained at a fixed, carefully chosen layer, and multi-layer methods that consider the ensemble of the feature maps generated by the model. While promising, a proper comparison of these algorithms is still lacking. In this work, we compared various feature-based OOD detection methods on a large spectra of OOD (20 types), representing approximately 7800 3D MRIs. Our experiments shed the light on two phenomenons. First, multi-layer methods co
    
[^14]: 肺结节和肿块分割的尺度感知测试时点击自适应

    Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation. (arXiv:2307.15645v1 [eess.IV])

    [http://arxiv.org/abs/2307.15645](http://arxiv.org/abs/2307.15645)

    本文提出了一种尺度感知的测试时点击自适应方法，用于肺结节和肿块分割。该方法利用易获取的病变点击来增强分割性能，特别是对于大的病变，实验证明其有效性。

    

    肺结节和肿块是肺癌筛查中需要仔细处理的关键影像特征。尽管基于深度学习的医学图像分割取得了成功，但对于不同大小的结节和肿块的鲁棒性仍然具有挑战性。在本文中，我们提出了一种多尺度神经网络和尺度感知测试时适应的方法来解决这一挑战。具体而言，我们引入了一种自适应的尺度感知测试时点击自适应方法，基于易获取的病变点击作为测试时的线索，以增强分割性能，特别是对于大的病变。所提出的方法可以无缝集成到现有的网络中。在开源数据集和内部数据集上进行的大量实验证明了所提出方法在一些基于CNN和Transformer的分割方法上的有效性。我们的代码可在https://github.com/SplinterLi/SaTTCA获取。

    Pulmonary nodules and masses are crucial imaging features in lung cancer screening that require careful management in clinical diagnosis. Despite the success of deep learning-based medical image segmentation, the robust performance on various sizes of lesions of nodule and mass is still challenging. In this paper, we propose a multi-scale neural network with scale-aware test-time adaptation to address this challenge. Specifically, we introduce an adaptive Scale-aware Test-time Click Adaptation method based on effortlessly obtainable lesion clicks as test-time cues to enhance segmentation performance, particularly for large lesions. The proposed method can be seamlessly integrated into existing networks. Extensive experiments on both open-source and in-house datasets consistently demonstrate the effectiveness of the proposed method over some CNN and Transformer-based segmentation methods. Our code is available at https://github.com/SplinterLi/SaTTCA
    
[^15]: 视觉语言导航中的数据生成规模化

    Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])

    [http://arxiv.org/abs/2307.15644](http://arxiv.org/abs/2307.15644)

    这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。

    

    最近在语言引导的视觉导航研究中，对于遍历环境的多样性和训练可泛化代理的监督数量有了明显需求。为了解决现有视觉语言导航数据集中普遍存在的数据稀缺问题，我们提出了一种有效的范式，用于生成用于学习的大规模数据。我们应用了HM3D和Gibson数据集中的1200多个逼真的环境，并利用网络上的资源合成了490万个指令轨迹对。重要的是，我们调查了范式中每个组成部分对代理性能的影响，并研究了如何恰当地应用扩增数据来预训练和微调代理。得益于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以大幅提升（相对于之前的最佳结果绝对值增加了11%），在R2R测试集中单次运行成功率显著提升至80%。

    Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The
    
[^16]: TriadNet: 无采样预测区间用于三维脑MR图像中的病变体积

    TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images. (arXiv:2307.15638v1 [eess.IV])

    [http://arxiv.org/abs/2307.15638](http://arxiv.org/abs/2307.15638)

    TriadNet是一种无采样预测区间的分割方法，能够快速准确地估计脑病变体积，并在临床实践中具有重要价值。

    

    脑病变（如梗死或肿瘤）的体积是患者预后的有力指标，并可用于指导治疗策略。目前，通常通过深度卷积神经网络（CNN）进行分割来估计病变体积，这是最先进的方法。然而，迄今为止，很少有研究将体积分割工具配备适当的定量预测区间，这可能会影响其在临床实践中的有用性和接受度。在这项工作中，我们提出了TriadNet，一种基于多头CNN架构的分割方法，可以在不到一秒钟内同时提供病变体积和相关的预测区间。我们在BraTS 2021上证明了其优于其他解决方案的性能，这是一个大规模的MRI脑胶质母细胞瘤图像数据库。

    The volume of a brain lesion (e.g. infarct or tumor) is a powerful indicator of patient prognosis and can be used to guide the therapeutic strategy. Lesional volume estimation is usually performed by segmentation with deep convolutional neural networks (CNN), currently the state-of-the-art approach. However, to date, few work has been done to equip volume segmentation tools with adequate quantitative predictive intervals, which can hinder their usefulness and acceptation in clinical practice. In this work, we propose TriadNet, a segmentation approach relying on a multi-head CNN architecture, which provides both the lesion volumes and the associated predictive intervals simultaneously, in less than a second. We demonstrate its superiority over other solutions on BraTS 2021, a large-scale MRI glioblastoma image database.
    
[^17]: 通过车辆轨迹数据进行车道改变意图识别的机器学习方法的比较分析

    A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data. (arXiv:2307.15625v1 [stat.ML])

    [http://arxiv.org/abs/2307.15625](http://arxiv.org/abs/2307.15625)

    本文比较了不同机器学习方法在车道改变意图识别中的性能，结果表明集成方法能降低分类错误的影响，而LightGBM相比XGBoost算法在模型训练效率上有显著提升。

    

    准确地检测和预测车道改变过程可以帮助自动驾驶汽车更好地理解周围环境，识别潜在的安全隐患，并提高交通安全性。本文主要研究车道改变过程，并比较不同机器学习方法在从高维时间序列数据中识别车道改变意图方面的性能。为了验证所提模型的性能，从CitySim数据集中提取了总共1023个车辆轨迹。对于车道改变意图识别问题，结果表明，集成方法可以将II型和III型分类错误的影响降低到98%的分类准确率。在不损失识别准确率的情况下，LightGBM相比XGBoost算法在模型训练效率上提高了6倍。

    Accurately detecting and predicting lane change (LC)processes can help autonomous vehicles better understand their surrounding environment, recognize potential safety hazards, and improve traffic safety. This paper focuses on LC processes and compares different machine learning methods' performance to recognize LC intention from high-dimensionality time series data. To validate the performance of the proposed models, a total number of 1023 vehicle trajectories is extracted from the CitySim dataset. For LC intention recognition issues, the results indicate that with ninety-eight percent of classification accuracy, ensemble methods reduce the impact of Type II and Type III classification errors. Without sacrificing recognition accuracy, the LightGBM demonstrates a sixfold improvement in model training efficiency than the XGBoost algorithm.
    
[^18]: 使用收缩扰动技术改进种群训练过程中的架构混合，提高神经架构搜索效果的研究

    Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search. (arXiv:2307.15621v1 [cs.LG])

    [http://arxiv.org/abs/2307.15621](http://arxiv.org/abs/2307.15621)

    本文展示了一种名为PBT-NAS的方法，通过同时训练和混合神经网络，并使用收缩扰动技术改进架构，以实现有效的神经架构搜索。PBT-NAS在图像生成和强化学习等挑战性任务中表现出优越的性能。

    

    本文展示了同时训练和混合神经网络是进行神经架构搜索（NAS）的一种有前景的方法。对于超参数优化，通过重复使用部分训练好的权重，可以实现高效的搜索，这在种群训练（PBT）算法中已经有所展示。我们提出了PBT-NAS，这是一种将种群训练（PBT）算法适应到NAS的方法，通过将表现差的网络替换为混合表现好的网络，并使用收缩扰动技术继承权重来改进架构。在PBT-NAS结束后，创建的网络可以直接使用而无需重新训练。PBT-NAS具有高度可并行化和有效性，对于挑战性的任务（图像生成和强化学习）来说，PBT-NAS相比于基准（随机搜索和基于突变的PBT）实现了更优秀的性能。

    In this work, we show that simultaneously training and mixing neural networks is a promising way to conduct Neural Architecture Search (NAS). For hyperparameter optimization, reusing the partially trained weights allows for efficient search, as was previously demonstrated by the Population Based Training (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS where architectures are improved during training by replacing poorly-performing networks in a population with the result of mixing well-performing ones and inheriting the weights using the shrink-perturb technique. After PBT-NAS terminates, the created networks can be directly used without retraining. PBT-NAS is highly parallelizable and effective: on challenging tasks (image generation and reinforcement learning) PBT-NAS achieves superior performance compared to baselines (random search and mutation-based PBT).
    
[^19]: 语言模型的鲁棒无畸变水印方法

    Robust Distortion-free Watermarks for Language Models. (arXiv:2307.15593v1 [cs.LG])

    [http://arxiv.org/abs/2307.15593](http://arxiv.org/abs/2307.15593)

    该论文提出了一种在语言模型中添加鲁棒无畸变水印的方法，通过映射随机数序列到语言模型的样本，可以实现在不改变文本分布的前提下对水印文本进行检测，并且在多种改写攻击下依然保持较高的鲁棒性，实验证明在40-50%的随机扰动下仍可可靠地检测到水印文本。

    

    我们提出了一种在自回归语言模型中添加水印的方法，并且这些水印对扰动具有鲁棒性，而不会改变文本的分布，同时保证生成预算在一定范围内。我们用随机水印密钥计算的随机数序列映射到语言模型的样本来生成带水印的文本。要检测水印文本，只要知道密钥的任何一方都可以将文本与随机数序列对齐。我们使用两种采样方案来实例化水印方法：反变换采样和指数最小采样。我们将这些水印应用于三个语言模型——OPT-1.3B、LLaMA-7B和Alpaca-7B，以实验证明它们的统计功效和对各种改写攻击的鲁棒性。值得注意的是，对于OPT-1.3B和LLaMA-7B模型，即使在随机扰动了40-50%的词元后，我们仍然可以可靠地检测到带水印的文本（$p \leq 0.01$），只需要35个词元。

    We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokens via random
    
[^20]: 图上k中心问题的动态算法

    Dynamic algorithms for k-center on graphs. (arXiv:2307.15557v1 [cs.DS])

    [http://arxiv.org/abs/2307.15557](http://arxiv.org/abs/2307.15557)

    本文提出了针对动态图中的k中心问题的高效算法，包括确定性递减的（2+ε）近似算法和随机增量的（4+ε）近似算法，同时给出了针对加权图的摊销更新时间为kn^{o(1)}的算法。此外，通过简化方法得到了对于k中心问题的全动态（2+ε）近似算法。

    

    本文针对动态图中的k中心问题提出了第一种高效算法。在这个问题中，目标是通过选择k个中心将输入分为k个集合，使得任意数据点到最近中心的最大距离最小化。已知在该问题中，要获得优于2的近似解是NP难的。尽管在许多应用中，输入可以自然地建模为图，但在动态环境下的k中心问题的先前研究都是基于度量空间的。本文给出了一种确定性递减的（2+ε）近似算法和一种随机增量的（4+ε）近似算法，对于加权图，两种算法的摊销更新时间为kn^{o(1)}。此外，我们还展示了一种约简方法，从而得到了对于k中心问题的全动态（2+ε）近似算法，其最坏情况更新时间与维护（1+k近似解的最新上界相差不超过k。

    In this paper we give the first efficient algorithms for the $k$-center problem on dynamic graphs undergoing edge updates. In this problem, the goal is to partition the input into $k$ sets by choosing $k$ centers such that the maximum distance from any data point to the closest center is minimized. It is known that it is NP-hard to get a better than $2$ approximation for this problem.  While in many applications the input may naturally be modeled as a graph, all prior works on $k$-center problem in dynamic settings are on metrics. In this paper, we give a deterministic decremental $(2+\epsilon)$-approximation algorithm and a randomized incremental $(4+\epsilon)$-approximation algorithm, both with amortized update time $kn^{o(1)}$ for weighted graphs. Moreover, we show a reduction that leads to a fully dynamic $(2+\epsilon)$-approximation algorithm for the $k$-center problem, with worst-case update time that is within a factor $k$ of the state-of-the-art upper bound for maintaining $(1+
    
[^21]: 关于神经抽象的效率和精确性之间的权衡

    On the Trade-off Between Efficiency and Precision of Neural Abstraction. (arXiv:2307.15546v1 [cs.LO])

    [http://arxiv.org/abs/2307.15546](http://arxiv.org/abs/2307.15546)

    本研究探讨了神经抽象的效率和精确性之间的权衡问题，研究发现抽象的用途取决于具体场景，请求简单的粗略抽象同样会有其用途，而对于更复杂

    

    神经抽象最近被引入作为复杂非线性动力模型的形式近似。它们包括一个神经ODE和抽象神经网络与具体动力模型之间误差的证明上界。到目前为止，神经抽象仅以全$ReLU$激活函数组成的神经网络形式得到，导致具有分段仿射动力学的神经ODE模型，可以等效地解释为线性混合自动机。在这项工作中，我们观察到抽象的效用取决于它的使用：某些情况可能需要容易分析的粗略抽象，而其他情况可能需要更复杂的精细抽象。因此，我们考虑替代形状的神经抽象，即分段常数或非线性非多项式（具体来说，通过sigmoidal激活函数获得）。我们采用正式的归纳综合程序来生成神经抽象。

    Neural abstractions have been recently introduced as formal approximations of complex, nonlinear dynamical models. They comprise a neural ODE and a certified upper bound on the error between the abstract neural network and the concrete dynamical model. So far neural abstractions have exclusively been obtained as neural networks consisting entirely of $ReLU$ activation functions, resulting in neural ODE models that have piecewise affine dynamics, and which can be equivalently interpreted as linear hybrid automata. In this work, we observe that the utility of an abstraction depends on its use: some scenarios might require coarse abstractions that are easier to analyse, whereas others might require more complex, refined abstractions. We therefore consider neural abstractions of alternative shapes, namely either piecewise constant or nonlinear non-polynomial (specifically, obtained via sigmoidal activations). We employ formal inductive synthesis procedures to generate neural abstractions t
    
[^22]: 非对抗性后门防御

    Backdoor Defense with Non-Adversarial Backdoor. (arXiv:2307.15539v1 [cs.LG])

    [http://arxiv.org/abs/2307.15539](http://arxiv.org/abs/2307.15539)

    提出了一种非对抗性后门防御框架，通过在被污染样本中注入非对抗性后门，当触发时可以抑制攻击者对污染数据的后门攻击，同时保持对干净数据的影响有限。

    

    深度神经网络（DNNs）容易受到后门攻击的影响，这种攻击并不会影响网络对干净数据的性能，但一旦添加触发模式，就会操纵网络行为。现有的防御方法大大降低了攻击成功率，但它们在干净数据上的预测准确性仍然远远落后于干净模型。受后门攻击的隐蔽性和有效性的启发，我们提出了一个简单但非常有效的防御框架，该框架注入了针对被污染样本的非对抗性后门。按照后门攻击的一般步骤，我们检测一小组可疑样本，然后对它们应用毒化策略。一旦触发，非对抗性后门抑制了攻击者对污染数据的后门攻击，但对干净数据的影响有限。防御可以在数据预处理期间进行，而不需要对标准的端到端训练流程进行任何修改。

    Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on mul
    
[^23]: Federated Learning在官方统计中的适用性

    The Applicability of Federated Learning to Official Statistics. (arXiv:2307.15503v1 [cs.LG])

    [http://arxiv.org/abs/2307.15503](http://arxiv.org/abs/2307.15503)

    Federated Learning（FL）在官方统计中具有潜力，可以保护数据隐私并提升数据质量。

    

    本研究调查了Federated Learning（FL）在官方统计中的潜力，并展示了FL模型性能与集中式学习方法的匹配程度。同时，利用FL可以保护数据持有者的隐私，从而便于获取更广泛的数据并最终提升官方统计数据。通过模拟三种不同的使用案例，我们对这种技术的适用性获得了重要的见解。这些使用案例基于医疗保险数据集、细颗粒物污染数据集和移动无线信号覆盖数据集，这些数据集与官方统计密切相关。我们详细分析了结果，包括对每个模拟中集中式和FL算法性能的比较。在这三个使用案例中，我们能够通过FL训练模型，其性能与集中式模型基准非常接近。我们的关键观察和它们对模拟转移的影响。

    This work investigates the potential of Federated Learning (FL) for official statistics and shows how well the performance of FL models can keep up with centralized learning methods. At the same time, its utilization can safeguard the privacy of data holders, thus facilitating access to a broader range of data and ultimately enhancing official statistics. By simulating three different use cases, important insights on the applicability of the technology are gained. The use cases are based on a medical insurance data set, a fine dust pollution data set and a mobile radio coverage data set - all of which are from domains close to official statistics. We provide a detailed analysis of the results, including a comparison of centralized and FL algorithm performances for each simulation. In all three use cases, we were able to train models via FL which reach a performance very close to the centralized model benchmarks. Our key observations and their implications for transferring the simulatio
    
[^24]: 从连续时间表述到离散化方案：张量列车和鲁棒回归用于BSDEs和抛物线PDEs

    From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs. (arXiv:2307.15496v1 [cs.LG])

    [http://arxiv.org/abs/2307.15496](http://arxiv.org/abs/2307.15496)

    本论文通过使用张量列车方法结合回归类型方法来解决高维度偏微分方程的数值逼近问题。实验结果表明，该方法在精度和计算效率之间取得了有利的折中。

    

    在高维度中数值逼近偏微分方程（PDEs）面临着巨大的挑战，因为传统的基于网格的方法受到所谓维数诅咒的限制。最近的尝试依赖于蒙特卡罗方法和变分表述的组合，利用神经网络进行函数逼近。延续之前的工作（Richter等，2021），我们认为张量列车为抛物型PDE提供了一种吸引人的框架：通过以逆向随机微分方程和回归类型方法的形式重新表述，结合潜在的低秩结构，有望实现压缩和高效计算的目标。强调连续时间观点，我们开发了迭代方案，其在计算效率和鲁棒性方面有所不同。我们从理论和数值上都证明了我们的方法能够在精度和计算效率之间取得有利的折中。

    The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous 
    
[^25]: FeedbackLogs：将利益相关者反馈记录和纳入到机器学习流程中

    FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines. (arXiv:2307.15475v1 [cs.HC])

    [http://arxiv.org/abs/2307.15475](http://arxiv.org/abs/2307.15475)

    FeedbackLogs是针对机器学习流程的利益相关者反馈记录和更新的补充工具，可以用于算法审计和记录反馈更新。

    

    虽然机器学习流程影响着越来越多的利益相关者，但关于利益相关者输入的记录和利用方面的研究却很少。我们提出了FeedbackLogs，这是针对现有机器学习流程文档的补充，用于追踪多个利益相关者的输入。每个日志记录了关于反馈收集过程、反馈内容以及如何利用反馈更新机器学习流程的重要细节。本文介绍并正式化了收集FeedbackLog的过程，并提供了具体的使用案例，其中FeedbackLogs可以作为算法审计的证据，并用作记录基于利益相关者反馈的更新的工具。

    Even though machine learning (ML) pipelines affect an increasing array of stakeholders, there is little work on how input from stakeholders is recorded and incorporated. We propose FeedbackLogs, addenda to existing documentation of ML pipelines, to track the input of multiple stakeholders. Each log records important details about the feedback collection process, the feedback itself, and how the feedback is used to update the ML pipeline. In this paper, we introduce and formalise a process for collecting a FeedbackLog. We also provide concrete use cases where FeedbackLogs can be employed as evidence for algorithmic auditing and as a tool to record updates based on stakeholder feedback.
    
[^26]: LUCID-GAN: 有条件生成模型用于定位不公平性

    LUCID-GAN: Conditional Generative Models to Locate Unfairness. (arXiv:2307.15466v1 [cs.LG])

    [http://arxiv.org/abs/2307.15466](http://arxiv.org/abs/2307.15466)

    LUCID-GAN是一个有条件生成模型，用于定位不公平性。它通过生成规范集来揭示模型的内部逻辑中潜在的不道德偏见，提供了对歧视来源的额外透明度。

    

    大多数群体公平性概念通过计算模型输出的统计平衡度指标来检测不道德偏见。然而，这种方法存在几个缺点，如哲学分歧、相互不兼容和缺乏解释性。这些缺点促使了对补充性偏见检测方法的研究，这些方法可以提供对歧视来源的额外透明度，并且对于对公平定义和受保护特征的先验决策是不可知的。在这个方向上的一个最近的提议是LUCID（通过规范逆向设计定位不公平性），其中通过在输入空间上进行梯度下降来生成规范集，揭示了模型在给定首选输出的情况下所希望的输入。这些关于模型机制的信息，即为实现特定输出所必需的特征值，可以揭示其内部逻辑中潜在的不道德偏见。在这里，我们介绍了LUCID-GAN，它生成c

    Most group fairness notions detect unethical biases by computing statistical parity metrics on a model's output. However, this approach suffers from several shortcomings, such as philosophical disagreement, mutual incompatibility, and lack of interpretability. These shortcomings have spurred the research on complementary bias detection methods that offer additional transparency into the sources of discrimination and are agnostic towards an a priori decision on the definition of fairness and choice of protected features. A recent proposal in this direction is LUCID (Locating Unfairness through Canonical Inverse Design), where canonical sets are generated by performing gradient descent on the input space, revealing a model's desired input given a preferred output. This information about the model's mechanisms, i.e., which feature values are essential to obtain specific outputs, allows exposing potential unethical biases in its internal logic. Here, we present LUCID-GAN, which generates c
    
[^27]: 神经网络控制器及其符号表示的令人担忧的特性

    Worrisome Properties of Neural Network Controllers and Their Symbolic Representations. (arXiv:2307.15456v1 [cs.LG])

    [http://arxiv.org/abs/2307.15456](http://arxiv.org/abs/2307.15456)

    本论文对神经网络控制器在简单强化学习问题中的稳健性产生了担忧，通过对低神经元和符号抽象的探究，发现即使控制器达到高回报，仍会产生大量持久低回报解决方案，对手可以轻易利用。论文提供了一个系统稳健性研究的算法，并证明了持久解决方案的存在性以及周期轨道的存在。

    

    我们对简单的强化学习基准问题中控制器的稳健性提出了一些关切。我们关注神经网络控制器及其低神经元和符号抽象。一个典型的控制器可以达到很高的平均回报值，但仍会生成大量持久的低回报解决方案，这是一个非常不可取的特性，容易被对手利用。我们发现，简单的控制器会产生更多持久的不良解决方案。我们提供了一个系统稳健性研究的算法，并使用计算机辅助证明方法证明了持久解决方案的存在性，以及在某些情况下的周期轨道。

    We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology.
    
[^28]: 自主载荷热控制

    Autonomous Payload Thermal Control. (arXiv:2307.15438v1 [cs.LG])

    [http://arxiv.org/abs/2307.15438](http://arxiv.org/abs/2307.15438)

    该论文提出了一种基于深度强化学习的框架，利用软演员-评论家算法在卫星上学习热控制策略，以解决小型卫星中热控制的挑战。该框架在模拟环境和实际空间处理计算机上进行了评估，并证明能够辅助传统热控制系统，保持载荷温度在可操作范围内。

    

    在小型卫星中，热控制设备、科学仪器和电子部件的空间较小。此外，电子设备的近距离使得功耗散热困难，存在无法适当控制温度、降低部件寿命和任务性能的风险。为了应对这一挑战，利用卫星上逐渐增加的智能，提出了一种基于深度强化学习的框架，使用软演员-评论家算法来学习机载热控制策略。该框架在一个简单的模拟环境和未来将运往ISS并在IMAGIN-e任务中进行边缘计算的真实空间处理计算机中进行了评估。实验结果表明，所提出的框架能够学习控制载荷处理功率，以保持温度在操作范围内，补充传统热控制系统。

    In small satellites there is less room for heat control equipment, scientific instruments, and electronic components. Furthermore, the near proximity of the electronics makes power dissipation difficult, with the risk of not being able to control the temperature appropriately, reducing component lifetime and mission performance. To address this challenge, taking advantage of the advent of increasing intelligence on board satellites, a deep reinforcement learning based framework that uses Soft Actor-Critic algorithm is proposed for learning the thermal control policy onboard. The framework is evaluated both in a naive simulated environment and in a real space edge processing computer that will be shipped in the future IMAGIN-e mission and hosted in the ISS. The experiment results show that the proposed framework is able to learn to control the payload processing power to maintain the temperature under operational ranges, complementing traditional thermal control systems.
    
[^29]: 可改进的多任务学习中的差距平衡

    Improvable Gap Balancing for Multi-Task Learning. (arXiv:2307.15429v1 [cs.LG])

    [http://arxiv.org/abs/2307.15429](http://arxiv.org/abs/2307.15429)

    本文提出了两种新颖的可改进差距平衡算法（IGB）用于多任务学习，一种采用简单的启发式方法，另一种首次采用深度强化学习方法。这两种算法通过动态分配任务权重来实现可改进差距平衡，解决了损失平衡之后仍然存在的性能不平衡问题。

    

    在多任务学习中，梯度平衡近期比损失平衡更吸引研究兴趣，因为它通常能带来更好的性能。然而，损失平衡比梯度平衡更高效，因此在多任务学习中仍然值得进一步探索。注意先前的研究通常忽略了在多个任务之间存在可改进差距的事实，其中每个任务的可改进差距定义为当前训练进度与期望的最终训练进度之间的距离。因此，在损失平衡之后，性能不平衡在许多情况下仍然存在。在本文中，我们基于损失平衡框架提出了两种新的可改进差距平衡算法（IGB）用于多任务学习：一种采用简单的启发式方法，另一种（首次）采用深度强化学习用于多任务学习。特别地，两种算法都选择动态分配任务权重来进行可改进差距平衡。

    In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing
    
[^30]: 隐式神经表示用于变化检测

    Implicit neural representation for change detection. (arXiv:2307.15428v1 [cs.CV])

    [http://arxiv.org/abs/2307.15428](http://arxiv.org/abs/2307.15428)

    这项研究提出了一种用于检测不同时间获取的LiDAR点云中变化的无监督方法，通过使用神经场进行连续形状重建，以及高斯混合模型进行变化分类。该方法能够处理不匹配的空间支持和噪声，并在检测能力上取得了显著的提升。

    

    在相同地理区域的两个不同时间获取的一对3D航空LiDAR点云中检测变化是一项具有挑战性的任务，因为空间支持不匹配和获取系统噪声问题。最近的一些尝试基于监督方法来检测点云上的变化，这需要在实际应用中无法获得的大量标记数据。为了解决这些问题，我们提出了一种无监督方法，包括两个组件：连续形状重建的神经场（NF）和用于分类变化的高斯混合模型。NF提供了一种不依赖于网格的表示方法，可以对不匹配的空间支持进行编码，并可以通过正则化来增加高频细节和减少噪声。在任意空间尺度上比较每个时间戳的重建结果，从而显著提高了检测能力。我们将该方法应用于一组模拟LiDAR点云的基准数据集中。

    Detecting changes that occurred in a pair of 3D airborne LiDAR point clouds, acquired at two different times over the same geographical area, is a challenging task because of unmatching spatial supports and acquisition system noise. Most recent attempts to detect changes on point clouds are based on supervised methods, which require large labelled data unavailable in real-world applications. To address these issues, we propose an unsupervised approach that comprises two components: Neural Field (NF) for continuous shape reconstruction and a Gaussian Mixture Model for categorising changes. NF offer a grid-agnostic representation to encode bi-temporal point clouds with unmatched spatial support that can be regularised to increase high-frequency details and reduce noise. The reconstructions at each timestamp are compared at arbitrary spatial scales, leading to a significant increase in detection capabilities. We apply our method to a benchmark dataset of simulated LiDAR point clouds for u
    
[^31]: 深度生成模型、合成表格数据和差分隐私：综述与综合

    Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis. (arXiv:2307.15424v1 [cs.LG])

    [http://arxiv.org/abs/2307.15424](http://arxiv.org/abs/2307.15424)

    本文综述了近期合成数据生成的深度生成模型发展，重点关注表格数据集。通过使用深度生成模型，可以有效地生成隐私敏感数据的合成数据，并解决数据归一化、隐私和评估等方面的挑战。

    

    本文全面综述了通过深度生成模型生成合成数据的最新发展，重点关注表格数据集。我们特别概述了在隐私敏感数据背景下合成数据生成的重要性。此外，我们强调了使用深度生成模型相对于其他方法的优势，并详细解释了包括无监督学习、神经网络和生成模型在内的基本概念。论文涵盖了在使用深度生成模型处理表格数据集时涉及的挑战和考虑因素，如数据归一化、隐私问题和模型评估。本综述为对合成数据生成及其应用感兴趣的研究人员和实践者提供了宝贵的资源。

    This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.
    
[^32]: 一个Epoch就足够进行多层次超参数优化吗？

    Is One Epoch All You Need For Multi-Fidelity Hyperparameter Optimization?. (arXiv:2307.15422v1 [cs.LG])

    [http://arxiv.org/abs/2307.15422](http://arxiv.org/abs/2307.15422)

    传统的基准线在多层次超参数优化中取得了与其他方法类似的结果，并大幅减少计算成本。研究人员应该使用该基准线并扩大MF-HPO基准测试的多样性。

    

    超参数优化（HPO）对于微调机器学习模型至关重要，但计算成本很高。为了降低成本，多层次超参数优化（MF-HPO）利用学习过程中的中间准确性级别，并在学习早期丢弃低性能模型。我们在经典基准数据上将各种代表性的MF-HPO方法与简单的基准线进行了比较。基准线是在训练了仅一个Epoch后丢弃除Top-K之外的所有模型，然后进一步训练以选择最佳模型。令人惊讶的是，这个基准线与其对应的方法取得了类似的结果，而计算成本减少了一个数量级。在分析基准数据的学习曲线时，我们观察到了几个占主导地位的学习曲线，这解释了我们基准线的成功。这表明研究人员应该（1）在基准测试中始终使用建议的基准线，并且（2）扩大MF-HPO基准测试的多样性，包括更复杂的情况。

    Hyperparameter optimization (HPO) is crucial for fine-tuning machine learning models but can be computationally expensive. To reduce costs, Multi-fidelity HPO (MF-HPO) leverages intermediate accuracy levels in the learning process and discards low-performing models early on. We compared various representative MF-HPO methods against a simple baseline on classical benchmark data. The baseline involved discarding all models except the Top-K after training for only one epoch, followed by further training to select the best model. Surprisingly, this baseline achieved similar results to its counterparts, while requiring an order of magnitude less computation. Upon analyzing the learning curves of the benchmark data, we observed a few dominant learning curves, which explained the success of our baseline. This suggests that researchers should (1) always use the suggested baseline in benchmarks and (2) broaden the diversity of MF-HPO benchmarks to include more complex cases.
    
[^33]: 初始筛选顺序问题

    The Initial Screening Order Problem. (arXiv:2307.15398v1 [cs.LG])

    [http://arxiv.org/abs/2307.15398](http://arxiv.org/abs/2307.15398)

    本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。

    

    本文介绍了初始筛选顺序问题，这是候选人筛选中的关键步骤。它涉及一个类似人类的筛选者，其目标是在给定初始筛选顺序的候选人池中找到前k个适合的候选人，而不是最好的k个适合的候选人。初始筛选顺序表示类人筛选者在筛选之前如何安排候选人池。初始筛选顺序的选择对所选的k个候选人有重要影响。我们证明，在候选人池不平衡的情况下（例如，男性候选人多于女性候选人），类人筛选者可能在决策过程中对受保护的、代表性不足的群体产生不平等的努力。其他公平性结果也在类人筛选者下得到证明。这项研究是与一家大公司合作的，旨在更好地了解其潜在自动化的招聘流程。

    In this paper we present the initial screening order problem, a crucial step within candidate screening. It involves a human-like screener with an objective to find the first k suitable candidates rather than the best k suitable candidates in a candidate pool given an initial screening order. The initial screening order represents the way in which the human-like screener arranges the candidate pool prior to screening. The choice of initial screening order has considerable effects on the selected set of k candidates. We prove that under an unbalanced candidate pool (e.g., having more male than female candidates), the human-like screener can suffer from uneven efforts that hinder its decision-making over the protected, under-represented group relative to the non-protected, over-represented group. Other fairness results are proven under the human-like screener. This research is based on a collaboration with a large company to better understand its hiring process for potential automation. 
    
[^34]: 基于浅层单变量ReLU网络的噪声插值学习

    Noisy Interpolation Learning with Shallow Univariate ReLU Networks. (arXiv:2307.15396v1 [cs.LG])

    [http://arxiv.org/abs/2307.15396](http://arxiv.org/abs/2307.15396)

    使用最小范数的两层ReLU网络进行噪声单变量回归的插值，对于$L_1$损失和$ p <2 $的$L_p$损失抑制过拟合，但对于$ p \geq 2 $的损失是灾难性的。

    

    我们研究了噪声单变量回归中使用最小范数（权重的$\ell_2$范数）的两层ReLU网络进行插值的渐近过拟合行为。我们发现对于$L_1$损失和$ p <2 $的任何$L_p$损失，过拟合现象会被抑制，但对于$ p \geq 2 $的损失是灾难性的。

    We study the asymptotic overfitting behavior of interpolation with minimum norm ($\ell_2$ of the weights) two-layer ReLU networks for noisy univariate regression. We show that overfitting is tempered for the $L_1$ loss, and any $L_p$ loss for $p<2$, but catastrophic for $p\geq 2$.
    
[^35]: 全波形反演是否受益于大数据？

    Does Full Waveform Inversion Benefit from Big Data?. (arXiv:2307.15388v1 [cs.LG])

    [http://arxiv.org/abs/2307.15388](http://arxiv.org/abs/2307.15388)

    本文研究了大数据对全波形反演深度学习模型的影响，并通过实证研究证明了更大的数据集能够提高模型性能和泛化能力，同时强调模型容量需要根据数据大小进行扩展以取得最佳改进效果。

    

    本文研究了大数据对全波形反演（FWI）深度学习模型的影响。尽管众所周知，大数据可以提升深度学习模型在许多任务中的性能，但对于FWI的有效性尚未得到验证。为了填补这一空白，我们进行了一项实证研究，研究了在最近发布的大型、多结构数据集OpenFWI上训练的FWI深度学习模型的行为。特别地，我们在OpenFWI的10个2D子集的组合上训练和评估了FWI模型，这些子集总共包含了470K个数据对。我们的实验证明，更大的数据集能够提高FWI深度学习模型的性能和泛化能力。我们进一步证明，模型容量需要根据数据大小进行相应的扩展以获得最佳的改进效果。

    This paper investigates the impact of big data on deep learning models for full waveform inversion (FWI). While it is well known that big data can boost the performance of deep learning models in many tasks, its effectiveness has not been validated for FWI. To address this gap, we present an empirical study that investigates how deep learning models in FWI behave when trained on OpenFWI, a collection of large-scale, multi-structural datasets published recently. Particularly, we train and evaluate the FWI models on a combination of 10 2D subsets in OpenFWI that contain 470K data pairs in total. Our experiments demonstrate that larger datasets lead to better performance and generalization of deep learning models for FWI. We further demonstrate that model capacity needs to scale in accordance with data size for optimal improvement.
    
[^36]: 高效的成对图交互学习的共同注意力图汇聚

    Co-attention Graph Pooling for Efficient Pairwise Graph Interaction Learning. (arXiv:2307.15377v1 [cs.LG])

    [http://arxiv.org/abs/2307.15377](http://arxiv.org/abs/2307.15377)

    本论文提出了一种称为共同注意力图汇聚（CAGPool）的新颖和高效的图级方法，用于提取图对之间的交互表示。该方法在分类和回归任务中展现出竞争性能。

    

    图神经网络（GNN）在处理和学习图结构数据方面已经被证明是有效的。然而，先前的研究主要关注的是理解单一图输入，而许多现实应用需要对图结构数据进行成对分析（例如场景图匹配、代码搜索和药物相互作用预测）。为此，最近的研究开始将重点转向学习图对之间的交互。尽管这些方法的性能有所提升，但仍存在一些局限性，即交互是在节点级别进行考虑，导致计算成本高和性能亚优。为了解决这个问题，我们提出了一种新颖而高效的图级方法，利用共同注意力在图汇聚中提取交互表示。我们的方法，称为共同注意力图汇聚（CAGPool），在使用实际数据集进行分类和回归任务时，相对于现有方法展现出竞争性能。

    Graph Neural Networks (GNNs) have proven to be effective in processing and learning from graph-structured data. However, previous works mainly focused on understanding single graph inputs while many real-world applications require pair-wise analysis for graph-structured data (e.g., scene graph matching, code searching, and drug-drug interaction prediction). To this end, recent works have shifted their focus to learning the interaction between pairs of graphs. Despite their improved performance, these works were still limited in that the interactions were considered at the node-level, resulting in high computational costs and suboptimal performance. To address this issue, we propose a novel and efficient graph-level approach for extracting interaction representations using co-attention in graph pooling. Our method, Co-Attention Graph Pooling (CAGPool), exhibits competitive performance relative to existing methods in both classification and regression tasks using real-world datasets, whi
    
[^37]: 激光网络中基于滞后和非滞后同步的无冲突联合决策

    Conflict-free joint decision by lag and zero-lag synchronization in laser network. (arXiv:2307.15373v1 [physics.optics])

    [http://arxiv.org/abs/2307.15373](http://arxiv.org/abs/2307.15373)

    本研究在竞争性多臂赌博机问题中探索了激光网络作为光子加速器的应用，通过滞后和非滞后同步实现了无冲突的合作决策，实验证实了低冲突率和高奖励。

    

    随着摩尔定律的终结和对计算需求的增加，光子加速器引起了极大的关注。这是由于光的物理特性，如高带宽和复杂性，以及在激光物理领域中出现的各种同步现象。这些因素在计算机性能接近极限时发挥作用。在本研究中，我们探索了激光网络作为光子加速器应用于竞争性多臂赌博机问题。在这个背景下，冲突避免是最大化环境奖励的关键。我们在四个半导体激光器网络中实验验证了利用滞后和非滞后同步进行合作决策的效果。混沌的滞后同步实现了有效的决策，而零延迟的同步负责实现碰撞避免功能。我们在基本的冲突率低、奖励高的情况下进行了实验证实。

    With the end of Moore's Law and the increasing demand for computing, photonic accelerators are garnering considerable attention. This is due to the physical characteristics of light, such as high bandwidth and multiplicity, and the various synchronization phenomena that emerge in the realm of laser physics. These factors come into play as computer performance approaches its limits. In this study, we explore the application of a laser network, acting as a photonic accelerator, to the competitive multi-armed bandit problem. In this context, conflict avoidance is key to maximizing environmental rewards. We experimentally demonstrate cooperative decision-making using zero-lag and lag synchronization within a network of four semiconductor lasers. Lag synchronization of chaos realizes effective decision-making and zero-delay synchronization is responsible for the realization of the collision avoidance function. We experimentally verified a low collision rate and high reward in a fundamental 
    
[^38]: 通过基于模型的树马尔可夫模型，实现透明的序列模型

    Toward Transparent Sequence Models with Model-Based Tree Markov Model. (arXiv:2307.15367v1 [cs.LG])

    [http://arxiv.org/abs/2307.15367](http://arxiv.org/abs/2307.15367)

    本研究引入了基于模型的树马尔可夫模型（MOB-HSMM），用于解决复杂黑盒机器学习模型应用于序列数据时的可解释性问题。通过从深度神经网络中蒸馏的知识，实现了提高预测性能的同时提供清晰解释的目标。实验结果表明通过将LSTM学习到的顺序模式转移到MOB树中，可以进一步提高MOB树的性能，并利用MOB-HSMM将MOB树与隐马尔可夫模型（HSMM）整合，实现了潜在和可解释的序列的发现。

    

    本研究解决了应用于序列数据的复杂、黑盒机器学习模型的可解释性问题。我们引入了基于模型的树隐马尔可夫模型（MOB-HSMM），这是一个固有可解释性的模型，旨在检测高死亡风险事件，并发现与死亡风险相关的隐藏模式。该模型利用从深度神经网络（DNN）中蒸馏的知识，提高预测性能的同时提供清晰的解释。我们的实验结果表明，通过使用LSTM学习顺序模式，进而将其转移给MOB树，可以提高基于模型的树（MOB树）的性能。将MOB树与基于模型的隐马尔可夫模型（HSMM）集成在MOB-HSMM中，可以使用可用信息揭示潜在的和可解释的序列。

    In this study, we address the interpretability issue in complex, black-box Machine Learning models applied to sequence data. We introduce the Model-Based tree Hidden Semi-Markov Model (MOB-HSMM), an inherently interpretable model aimed at detecting high mortality risk events and discovering hidden patterns associated with the mortality risk in Intensive Care Units (ICU). This model leverages knowledge distilled from Deep Neural Networks (DNN) to enhance predictive performance while offering clear explanations. Our experimental results indicate the improved performance of Model-Based trees (MOB trees) via employing LSTM for learning sequential patterns, which are then transferred to MOB trees. Integrating MOB trees with the Hidden Semi-Markov Model (HSMM) in the MOB-HSMM enables uncovering potential and explainable sequences using available information.
    
[^39]: 确定性特征排序

    Confident Feature Ranking. (arXiv:2307.15361v1 [stat.ML])

    [http://arxiv.org/abs/2307.15361](http://arxiv.org/abs/2307.15361)

    提出了一种确定性特征排序的方法，该方法通过特征重要性值的两两比较，可以产生排序和同时的置信区间，并且可以选择前k个集合。

    

    特征重要性的解释通常依赖于特征的相对顺序而不是数值本身，也就是排序。然而，由于计算重要性值时使用的样本量较小，排序可能不稳定。我们提出了一种事后重要性方法，可以产生一种排序和同时的置信区间。基于特征重要性值的两两比较，我们的方法可以保证高概率包含“真实”（无限样本）排序，并允许选择前k个集合。

    Interpretation of feature importance values often relies on the relative order of the features rather than on the value itself, referred to as ranking. However, the order may be unstable due to the small sample sizes used in calculating the importance values. We propose that post-hoc importance methods produce a ranking and simultaneous confident intervals for the rankings. Based on pairwise comparisons of the feature importance values, our method is guaranteed to include the ``true'' (infinite sample) ranking with high probability and allows for selecting top-k sets.
    
[^40]: Med-HALT:大规模语言模型中医疗领域幻觉测试

    Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])

    [http://arxiv.org/abs/2307.15343](http://arxiv.org/abs/2307.15343)

    Med-HALT是一个新的基准和数据集，用于评估和减少大规模语言模型中医疗领域的幻觉问题。这个数据集包括多种创新的测试模式，并评估了领先的LLMs在性能上的差异。

    

    本研究论文关注大规模语言模型（LLMs）中幻觉问题的挑战，特别是在医疗领域的背景下。幻觉指这些模型生成了合理但未经验证或错误的信息，这可能对医疗应用产生严重影响。我们提出了一个新的基准和数据集，Med-HALT（医疗领域幻觉测试），专门设计用于评估和减少幻觉。Med-HALT提供了一个多元化的跨国数据集，这些数据集来自不同国家的医疗检查，包括多种创新的测试模式。Med-HALT包括两类测试：推理和基于记忆的幻觉测试，旨在评估LLMs的问题解决和信息检索能力。我们的研究评估了文本Davinci，GPT-3.5，LlaMa-2，MPT和Falcon等领先的LLMs，揭示了它们在性能上的显著差异。这篇论文提供了有关数据集的详细见解，促进了进一步的研究和发展。

    This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting
    
[^41]: Radon符号累积分布变换及其在有符号图像分类中的应用

    The Radon Signed Cumulative Distribution Transform and its applications in classification of Signed Images. (arXiv:2307.15339v1 [cs.IT])

    [http://arxiv.org/abs/2307.15339](http://arxiv.org/abs/2307.15339)

    该论文介绍了一种基于Radon变换和符号累积分布变换的图像表示方法，可以更准确地表示有符号图像的信息内容，并在图像分类中获得更高的准确性。

    

    在这里，我们介绍了一种基于运输和最优运输数学的新图像表示技术。该方法依赖于图像的著名Radon变换和最近的信号表示方法——符号累积分布变换的组合。新提出的方法将以前与运输相关的图像表示方法推广到任意函数（图像），因此可以在更多应用中使用。我们描述了这种新的变换，以及它的一些数学性质，并展示了它在实际和模拟数据上划分图像类别的能力。与现有的运输变换方法以及基于深度学习的分类方法相比，这种新的变换更准确地表示了有符号图像的信息内容，因此可以获得更高的分类准确性。所提出的方法在Python语言中的实现已作为PyTransKit软件包的一部分集成在内。

    Here we describe a new image representation technique based on the mathematics of transport and optimal transport. The method relies on the combination of the well-known Radon transform for images and a recent signal representation method called the Signed Cumulative Distribution Transform. The newly proposed method generalizes previous transport-related image representation methods to arbitrary functions (images), and thus can be used in more applications. We describe the new transform, and some of its mathematical properties and demonstrate its ability to partition image classes with real and simulated data. In comparison to existing transport transform methods, as well as deep learning-based classification methods, the new transform more accurately represents the information content of signed images, and thus can be used to obtain higher classification accuracies. The implementation of the proposed method in Python language is integrated as a part of the software package PyTransKit,
    
[^42]: 使用检索辅助图像生成为电子商务产品进行在线广告展示

    Staging E-Commerce Products for Online Advertising using Retrieval Assisted Image Generation. (arXiv:2307.15326v1 [cs.CV])

    [http://arxiv.org/abs/2307.15326](http://arxiv.org/abs/2307.15326)

    提出了使用检索辅助图像生成的方法来为未布置的电子商务产品图像生成吸引人和逼真的舞台背景，以提高在线广告的点击率。

    

    在线广告通常依赖电子商务平台通过目录将产品的图像发送给广告平台。在广告行业中，这样的广告通常被称为动态产品广告(DPA)。 DPA目录通常包含数百万个产品图像（与可以从电子商务平台购买的产品数量相对应）。然而，并非目录中的所有产品图像在直接重新定位为广告图像时都会吸引人，这可能会导致较低的点击率(CTR)。特别地，只放置在纯色背景上的产品可能不如在自然环境中布置的产品吸引人和逼真。为了解决DPA图像在大规模上的这些缺点，我们提出了一种基于生成对抗网络（GAN）的方法来为未布置产品图像生成舞台背景。生成整个布置的背景是一个具有挑战性的任务，容易产生幻觉。为了解决这个问题，我们引入了一个更简单的方法来生成隐含的框架。

    Online ads showing e-commerce products typically rely on the product images in a catalog sent to the advertising platform by an e-commerce platform. In the broader ads industry such ads are called dynamic product ads (DPA). It is common for DPA catalogs to be in the scale of millions (corresponding to the scale of products which can be bought from the e-commerce platform). However, not all product images in the catalog may be appealing when directly re-purposed as an ad image, and this may lead to lower click-through rates (CTRs). In particular, products just placed against a solid background may not be as enticing and realistic as a product staged in a natural environment. To address such shortcomings of DPA images at scale, we propose a generative adversarial network (GAN) based approach to generate staged backgrounds for un-staged product images. Generating the entire staged background is a challenging task susceptible to hallucinations. To get around this, we introduce a simpler ap
    
[^43]: 大规模动态系统中的观测部分、粗粒化和等变性在Koopman算子理论中的应用

    Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems. (arXiv:2307.15325v1 [math.DS])

    [http://arxiv.org/abs/2307.15325](http://arxiv.org/abs/2307.15325)

    本文解决了在大规模动态系统中部分观测或粗粒化的情况下，经典的EDMD算法不能准确提供Koopman算子近似的问题，并展示了将系统动态的对称性转移到Koopman算子可以显著提高模型效率。

    

    Koopman算子已经成为数据驱动分析、预测和控制复杂系统的重要工具，其主要原因是从测量中识别非线性动力学的线性函数空间表示的巨大潜力。然而，对于大规模系统，我们只能访问部分观测（如实验数据中非常常见的测量）或者出于效率原因刻意进行粗粒化的情况尚未得到充分研究。本文中，我们解决了这种情况中的困扰，即如果我们不仔细选择可观测数量，经典的EDMD算法不能自动提供潜在系统的Koopman算子近似。此外，我们还展示了系统动态中的对称性可以转移到Koopman算子中，从而大大提高模型的效率。我们还简要讨论了与域分解的联系。

    The Koopman operator has become an essential tool for data-driven analysis, prediction and control of complex systems, the main reason being the enormous potential of identifying linear function space representations of nonlinear dynamics from measurements. Until now, the situation where for large-scale systems, we (i) only have access to partial observations (i.e., measurements, as is very common for experimental data) or (ii) deliberately perform coarse graining (for efficiency reasons) has not been treated to its full extent. In this paper, we address the pitfall associated with this situation, that the classical EDMD algorithm does not automatically provide a Koopman operator approximation for the underlying system if we do not carefully select the number of observables. Moreover, we show that symmetries in the system dynamics can be carried over to the Koopman operator, which allows us to massively increase the model efficiency. We also briefly draw a connection to domain decompos
    
[^44]: 强大的视觉模拟与实际机器人操作的跨界迁移

    Robust Visual Sim-to-Real Transfer for Robotic Manipulation. (arXiv:2307.15320v1 [cs.RO])

    [http://arxiv.org/abs/2307.15320](http://arxiv.org/abs/2307.15320)

    该论文研究了视觉模拟与实际机器人操作的跨界迁移问题，并提出了域随机化方法来弥合这一差距。通过离线代理任务和模拟训练，成功地优化了域随机化参数，从而实现了在真实机器人上的有效应用。

    

    在模拟环境中学习视觉动作策略比在真实世界中更安全且更便宜。然而，由于模拟和真实数据之间的差异，经过模拟训练的策略在转移到真实机器人时经常失败。为了弥合视觉模拟与实际领域的差距，常用的方法是域随机化(domain randomization, DR)。然而，过去的研究主要评估了DR在姿态估计和物体检测等脱离力的任务上的表现，在这里，我们系统地探索了视觉域随机化方法，并在一系列具有挑战性的机器人操作任务上对其进行了基准测试。我们提出了一个离线代理任务，用于选择纹理随机化、光照随机化、物体颜色变化和相机参数等DR参数。特别值得注意的是，我们证明了DR参数对于离线代理任务和在线策略具有类似的影响。因此，我们使用经过离线优化的DR参数在模拟环境中训练视觉动作策略，并直接应用这些策略到实际机器人上。

    Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such 
    
[^45]: DiffKendall:一种利用可微分Kendall排名相关性进行少样本学习的新方法

    DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation. (arXiv:2307.15317v1 [cs.CV])

    [http://arxiv.org/abs/2307.15317](http://arxiv.org/abs/2307.15317)

    本文提出了一种利用可微分Kendall排名相关性进行少样本学习的新方法，证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠，并且实验证明在推理过程中用Kendall排名相关性替换几何相似度度量能够提高少样本学习性能。

    

    少样本学习旨在将在基本数据集上训练的模型适应到模型之前未见过的新领域的任务。这经常导致新类别上通道上特征值的分布相对均匀，难以确定新任务中通道的重要性。标准的少样本学习方法使用几何相似度度量，如余弦相似度和负欧几里德距离，来衡量两个特征之间的语义相关性。然而，在少样本学习的情况下，具有高几何相似度的特征可能具有不同的语义。本文证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠。我们观察到，仅在推理过程中用Kendall排名相关性替换几何相似度度量能够提高在各种数据集中的少样本学习性能。

    Few-shot learning aims to adapt models trained on the base dataset to novel tasks where the categories are not seen by the model before. This often leads to a relatively uniform distribution of feature values across channels on novel classes, posing challenges in determining channel importance for novel tasks. Standard few-shot learning methods employ geometric similarity metrics such as cosine similarity and negative Euclidean distance to gauge the semantic relatedness between two features. However, features with high geometric similarities may carry distinct semantics, especially in the context of few-shot learning. In this paper, we demonstrate that the importance ranking of feature channels is a more reliable indicator for few-shot learning than geometric similarity metrics. We observe that replacing the geometric similarity metric with Kendall's rank correlation only during inference is able to improve the performance of few-shot learning across a wide range of datasets with diffe
    
[^46]: 基于差分进化算法的Transformer神经网络模型用于负荷预测的超参数选择

    Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting. (arXiv:2307.15299v1 [cs.NE])

    [http://arxiv.org/abs/2307.15299](http://arxiv.org/abs/2307.15299)

    本研究使用差分进化算法选择Transformer神经网络模型的优化超参数，以提高负荷预测的准确性。

    

    精确的负荷预测在众多领域都起着重要作用，但准确捕捉动力系统的复杂动态仍然是传统统计模型面临的挑战。因此，时间序列模型（ARIMA）和深度学习模型（ANN，LSTM，GRU等）经常被使用，并且通常能够取得更好的成功率。本文分析了最近开发的Transformer-based神经网络模型在负荷预测中的效果。Transformer模型有望改进负荷预测，因为它们能够通过其Attention机制学习到长期依赖关系。我们运用了几种元启发式算法，如差分进化，以寻找Transformer-based神经网络的最优超参数，以产生精确的预测。差分进化为非可微分、多目标或约束优化问题提供了可扩展、强健和全局的解决方案。我们的工作比较了所提出的基于Transformer的神经网络与其他模型在负荷预测上的性能。

    Accurate load forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of dynamic power systems remains a challenge for traditional statistical models. For these reasons, time-series models (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly deployed and often experience higher success. In this paper, we analyze the efficacy of the recently developed Transformer-based Neural Network model in Load forecasting. Transformer models have the potential to improve Load forecasting because of their ability to learn long-range dependencies derived from their Attention Mechanism. We apply several metaheuristics namely Differential Evolution to find the optimal hyperparameters of the Transformer-based Neural Network to produce accurate forecasts. Differential Evolution provides scalable, robust, global solutions to non-differentiable, multi-objective, or constrained optimization problems. Our work compares the proposed Transformer based Ne
    
[^47]: 使用受约束的自编码器学习非线性投影，用于动态系统的降阶建模

    Learning Nonlinear Projections for Reduced-Order Modeling of Dynamical Systems using Constrained Autoencoders. (arXiv:2307.15288v1 [math.DS])

    [http://arxiv.org/abs/2307.15288](http://arxiv.org/abs/2307.15288)

    该论文提出了一种使用受约束的自编码器学习非线性投影的方法，用于动态系统的降阶建模。这种方法可以有效地对非线性动力学系统进行逼近，并解决了在流形附近对瞬态动力学建模时所面临的问题。

    

    最近开发的降阶建模技术旨在通过从数据中学习的低维流形对非线性动态系统进行逼近。这是一种在过渡后条件中对动力学建模的有效方法，其中初始条件和其他干扰的效应已经衰减。然而，对于需要实时控制和预测应用的基于流形的瞬态动力学建模来说，快速动态和非正常敏感机制的影响使得问题变得复杂。为了开始解决这些问题，我们引入了由从数据中学习的约束自编码器神经网络描述的一种参数化非线性投影类。我们的架构使用可逆激活函数和对偶权重矩阵，以确保编码器是解码器的左逆。我们还引入了新的具有动态感知性的成本函数，以促进学习考虑斜投影纤维的能力。

    Recently developed reduced-order modeling techniques aim to approximate nonlinear dynamical systems on low-dimensional manifolds learned from data. This is an effective approach for modeling dynamics in a post-transient regime where the effects of initial conditions and other disturbances have decayed. However, modeling transient dynamics near an underlying manifold, as needed for real-time control and forecasting applications, is complicated by the effects of fast dynamics and nonnormal sensitivity mechanisms. To begin to address these issues, we introduce a parametric class of nonlinear projections described by constrained autoencoder neural networks in which both the manifold and the projection fibers are learned from data. Our architecture uses invertible activation functions and biorthogonal weight matrices to ensure that the encoder is a left inverse of the decoder. We also introduce new dynamics-aware cost functions that promote learning of oblique projection fibers that account
    
[^48]: Zonoid的最优逼近和浅层神经网络的均匀逼近

    Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks. (arXiv:2307.15285v1 [stat.ML])

    [http://arxiv.org/abs/2307.15285](http://arxiv.org/abs/2307.15285)

    本论文解决了Zonoid的最优逼近和浅层神经网络的均匀逼近两个问题。对于Zonoid的逼近，我们填补了在$d=2,3$时的对数差距，实现了在所有维度上的解决方案。对于神经网络的逼近，我们的技术在$k \geq 1$时显著提高了目前的逼近率，并能够均匀逼近目标函数及其导数。

    

    我们研究了以下两个相关问题。第一个问题是确定一个任意的在$\mathbb{R}^{d+1}$空间中的Zonoid可以通过$n$个线段的Hausdorff距离来逼近的误差。第二个问题是确定浅层ReLU$^k$神经网络在其变分空间中的均匀范数的最优逼近率。第一个问题已经在$d \neq 2, 3$时得到解决，但当$d = 2, 3$时，最优上界和最优下界之间仍存在一个对数差距。我们填补了这个差距，完成了所有维度上的解决方案。对于第二个问题，我们的技术在$k \geq 1$时显著提高了现有的逼近率，并实现了目标函数及其导数的均匀逼近。

    We study the following two related problems. The first is to determine to what error an arbitrary zonoid in $\mathbb{R}^{d+1}$ can be approximated in the Hausdorff distance by a sum of $n$ line segments. The second is to determine optimal approximation rates in the uniform norm for shallow ReLU$^k$ neural networks on their variation spaces. The first of these problems has been solved for $d\neq 2,3$, but when $d=2,3$ a logarithmic gap between the best upper and lower bounds remains. We close this gap, which completes the solution in all dimensions. For the second problem, our techniques significantly improve upon existing approximation rates when $k\geq 1$, and enable uniform approximation of both the target function and its derivatives.
    
[^49]: 使用基于模型的深度学习架构从减少数量的扩散加权图像中恢复高质量的FOD

    Recovering high-quality FODs from a reduced number of diffusion-weighted images using a model-driven deep learning architecture. (arXiv:2307.15273v1 [cs.CV])

    [http://arxiv.org/abs/2307.15273](http://arxiv.org/abs/2307.15273)

    本文提出了一种基于模型的深度学习架构，用于从减少数量的扩散加权图像中恢复高质量的纤维定向分布（FOD），并通过引入fixel分类惩罚来提高下游分析的准确性。

    

    使用深度学习对纤维定向分布（FOD）进行重建有可能从减少数量的扩散加权图像（DWI）中产生准确的FOD，从而减少总成像时间。本文提出了一种球形去卷积网络，即基于模型的深度学习的FOD重建架构，确保网络产生的中间和输出的FOD与输入的DWI信号一致。此外，我们在损失函数中实施了一项fixel分类惩罚，鼓励网络产生能够进一步分割为正确数量的fixel并改善下游fixel-based分析的FOD。结果显示，该模型基于...

    Fibre orientation distribution (FOD) reconstruction using deep learning has the potential to produce accurate FODs from a reduced number of diffusion-weighted images (DWIs), decreasing total imaging time. Diffusion acquisition invariant representations of the DWI signals are typically used as input to these methods to ensure that they can be applied flexibly to data with different b-vectors and b-values; however, this means the network cannot condition its output directly on the DWI signal. In this work, we propose a spherical deconvolution network, a model-driven deep learning FOD reconstruction architecture, that ensures intermediate and output FODs produced by the network are consistent with the input DWI signals. Furthermore, we implement a fixel classification penalty within our loss function, encouraging the network to produce FODs that can subsequently be segmented into the correct number of fixels and improve downstream fixel-based analysis. Our results show that the model-base
    
[^50]: 这个模型对每个人都可靠吗？测试强校准

    Is this model reliable for everyone? Testing for strong calibration. (arXiv:2307.15247v1 [cs.LG])

    [http://arxiv.org/abs/2307.15247](http://arxiv.org/abs/2307.15247)

    通过重新排序观测值的预期残差，我们引入了一种新的测试程序来评估模型的强校准性能。

    

    在一个校准良好的风险预测模型中，对于任何给定的子群体，平均预测概率与真实事件率接近。这样的模型适用于异质人群，并满足强算法公平性的概念。然而，对于强校准，对模型进行审核是一个已知困难的任务，特别是对于机器学习算法来说，由于潜在的子群体数量庞大。因此，常见做法是只根据少数预定义的子群体评估校准。最近在拟合度检验方面的发展提供了潜在的解决方案，但对于信号较弱或校准不良的子群体较小的情况，这些方法要么过度细分数据，要么根本不进行细分。我们引入了一种新的测试过程，基于以下洞察：如果我们能够按预期的残差对观测进行重新排序，预测值和观察值之间的关联性应该会发生变化。

    In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult -- particularly for machine learning (ML) algorithms -- due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed resi
    
[^51]: 《在统计异质实验设计下的联邦学习实用配方》

    A Practical Recipe for Federated Learning Under Statistical Heterogeneity Experimental Design. (arXiv:2307.15245v1 [cs.LG])

    [http://arxiv.org/abs/2307.15245](http://arxiv.org/abs/2307.15245)

    本文针对联邦学习在统计异质实验设计下的问题进行了全面研究，提供了设计有意义和具有良好激励机制的FL实验设置的见解和建议。

    

    最近几年，联邦学习（FL）一直是研究的热点领域。已经有许多研究在处理数据异质性时对FL进行了改进。然而，尽管存在许多论文，但该领域的进展状况是未知的。许多研究采用了不一致的实验设置，并且没有对FL特定实验变量对结果的影响进行全面的研究，也没有提供一个更可比性和一致性的FL实验设置的实践见解。此外，存在多个基准和混杂变量进一步增加了不一致性和不确定性。在这项工作中，我们首次对FL特定实验变量与彼此之间和性能结果的影响进行了全面研究，提供了一些见解和建议，为设计有意义和具有良好激励机制的FL实验设置。我们还通过发布FedZoo-Bench来帮助社区，

    Federated Learning (FL) has been an area of active research in recent years. There have been numerous studies in FL to make it more successful in the presence of data heterogeneity. However, despite the existence of many publications, the state of progress in the field is unknown. Many of the works use inconsistent experimental settings and there are no comprehensive studies on the effect of FL-specific experimental variables on the results and practical insights for a more comparable and consistent FL experimental setup. Furthermore, the existence of several benchmarks and confounding variables has further complicated the issue of inconsistency and ambiguity. In this work, we present the first comprehensive study on the effect of FL-specific experimental variables in relation to each other and performance results, bringing several insights and recommendations for designing a meaningful and well-incentivized FL experimental setup. We further aid the community by releasing FedZoo-Bench,
    
[^52]: 从人类反馈中进行强化学习的开放问题和基本限制

    Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback. (arXiv:2307.15217v1 [cs.AI])

    [http://arxiv.org/abs/2307.15217](http://arxiv.org/abs/2307.15217)

    本文调查了从人类反馈中进行强化学习的开放问题和基本限制，并提出了加强社会监督的审计和披露标准。

    

    从人类反馈中进行强化学习（RLHF）是一种训练人工智能系统与人类目标保持一致的技术。RLHF已成为微调最新的大型语言模型（LLM）的核心方法。尽管如此受欢迎，但系统性地系统化其缺陷的公开工作相对较少。在本文中，我们（1）调查了RLHF及相关方法的开放问题和基本限制；（2）概述了了解、改进和补充RLHF的实践技术；以及（3）提出了审计和披露标准以改进RLHF系统的社会监督。我们的工作强调了RLHF的局限性，并强调了以多方面方法开发更安全的人工智能系统的重要性。

    Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.
    
[^53]: PromptStyler：基于提示的无源域泛化风格生成

    PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v1 [cs.CV])

    [http://arxiv.org/abs/2307.15199](http://arxiv.org/abs/2307.15199)

    提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。

    

    在联合视觉语言空间中，文本特征（如“一张狗的照片”）可以有效地表示其相关的图像特征（如狗的照片）。受此启发，我们提出了PromptStyler，通过使用提示来合成各种样式，而不使用任何图像来处理无源域泛化中的分布偏移。我们的方法通过可学习的样式词向量为伪词S*生成多样的样式特征（如“a S* style of a”）。为了确保学习到的样式不会扭曲内容信息，我们强制要求样式内容特征（如“a S* style of a [class]”）在联合视觉语言空间中靠近其对应的内容特征（如“[class]”）。在学习样式词向量之后，我们使用合成的样式内容特征训练一个线性分类器。尽管PromptStyler不需要使用任何图像，并且需要额外的训练，但在PACS、VLCS、OfficeHome和DomainNet上取得了最先进的结果。

    In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Inspired by this, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. Our method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not require any images and take
    
[^54]: 小学习率随机梯度下降中动量的边际价值

    The Marginal Value of Momentum for Small Learning Rate SGD. (arXiv:2307.15196v1 [cs.LG])

    [http://arxiv.org/abs/2307.15196](http://arxiv.org/abs/2307.15196)

    本文通过理论分析和实验证明，在小学习率和梯度噪声是主要不稳定源的随机环境中，动量在深度学习优化中的边际价值是有限的。

    

    在没有随机梯度噪声的强凸环境中，动量已被证明能加速梯度下降的收敛。在随机优化中，如训练神经网络，有传言认为动量可以通过减小随机梯度更新的方差来帮助深度学习优化，但之前的理论分析并没有发现动量可以提供任何可证实的加速。本文的理论结果阐明了在学习率较小且梯度噪声是主要不稳定源的随机环境中动量的作用，表明使用和不使用动量的随机梯度下降在短期和长期时间段内表现相似。实验证明，在实际训练中，动量在优化和泛化方面确实有局限的益处，特别是在学习率不是很大的情况下，包括在ImageNet上从头训练小至中等批次大小的模型和在下游任务上微调语言模型。

    Momentum is known to accelerate the convergence of gradient descent in strongly convex settings without stochastic gradient noise. In stochastic optimization, such as training neural networks, folklore suggests that momentum may help deep learning optimization by reducing the variance of the stochastic gradient update, but previous theoretical analyses do not find momentum to offer any provable acceleration. Theoretical results in this paper clarify the role of momentum in stochastic settings where the learning rate is small and gradient noise is the dominant source of instability, suggesting that SGD with and without momentum behave similarly in the short and long time horizons. Experiments show that momentum indeed has limited benefits for both optimization and generalization in practical training regimes where the optimal learning rate is not very large, including small- to medium-batch training from scratch on ImageNet and fine-tuning language models on downstream tasks.
    
[^55]: 在重复的多单位付费拍卖中学习

    Learning in Repeated Multi-Unit Pay-As-Bid Auctions. (arXiv:2307.15193v1 [cs.GT])

    [http://arxiv.org/abs/2307.15193](http://arxiv.org/abs/2307.15193)

    本论文研究了在重复的多单位付费拍卖中学习如何出价的问题。通过在离线设置中优化出价向量，并利用多项式时间动态规划方案，设计了具有多项式时间和空间复杂度的在线学习算法。

    

    受碳排放交易方案、国债拍卖和采购拍卖的启发，这些都涉及拍卖同质的多个单位，我们考虑了如何在重复的多单位付费拍卖中学习如何出价的问题。在每个拍卖中，大量（相同的）物品将被分配给最高的出价，每个中标价等于出价本身。由于行动空间的组合性质，学习如何在付费拍卖中出价是具有挑战性的。为了克服这个挑战，我们关注离线设置，其中投标人通过只能访问其他投标人过去提交的出价来优化他们的出价向量。我们证明了离线问题的最优解可以使用多项式时间动态规划（DP）方案来获得。我们利用DP方案的结构，设计了具有多项式时间和空间复杂度的在线学习算法。

    Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under fu
    
[^56]: f-Divergence最小化用于序列级知识蒸馏

    f-Divergence Minimization for Sequence-Level Knowledge Distillation. (arXiv:2307.15190v1 [cs.CL])

    [http://arxiv.org/abs/2307.15190](http://arxiv.org/abs/2307.15190)

    本文提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。通过在词级上计算损失，能够更好地压缩语言模型并使学生模型从教师模型中学习。提出的方法在多个数据集上表现出色。

    

    知识蒸馏（KD）是将知识从大模型转移到小模型的过程。在自然语言处理领域，由于对不断增长的语言模型进行压缩的需求，它受到越来越多的关注。在这项工作中，我们提出了一个f-DISTILL框架，将序列级知识蒸馏建模为最小化广义f-分歧函数。我们在我们的框架下提出了四种蒸馏变种，并表明现有的 SeqKD 和 ENGINE 方法是我们f-DISTILL方法的近似。我们进一步推导出了我们的f-DISTILL的逐步分解，将难以处理的序列级分歧简化为可以以一种可处理的方式计算的词级损失。在四个数据集上的实验证明我们的方法优于现有的KD方法，并且我们对称的蒸馏损失可以更好地强迫学生从教师分布中学习。

    Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one. It has gained increasing attention in the natural language processing community, driven by the demands of compressing ever-growing language models. In this work, we propose an f-DISTILL framework, which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our f-DISTILL methods. We further derive step-wise decomposition for our f-DISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner. Experiments across four datasets show that our methods outperform existing KD approaches, and that our symmetric distilling losses can better force the student to learn from the teacher distribution.
    
[^57]: RCT拒绝抽样用于因果估计评估

    RCT Rejection Sampling for Causal Estimation Evaluation. (arXiv:2307.15176v1 [cs.AI])

    [http://arxiv.org/abs/2307.15176](http://arxiv.org/abs/2307.15176)

    该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。

    

    混淆是从观测数据中无偏估计因果效应的一个重要障碍。对于高维协变量的情况，如文本数据、基因组学或行为社会科学，研究人员提出了适应机器学习方法进行因果估计的调整方法。然而，这些调整方法的经验评估一直存在困难和限制。在这项工作中，我们基于一种有前景的经验评估策略，简化了评估设计，并使用真实数据：对随机控制试验(RCT)进行子抽样，以创建混淆的观测数据集，同时使用RCT的平均因果效应作为基准真实值。我们提出了一种新的抽样算法，称为RCT拒绝抽样，并提供了理论保证，以确保观测数据的因果识别成立，从而可以与基准RCT进行有效比较。通过使用合成数据，我们展示了我们的算法在...

    Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm in
    
[^58]: 在线学习型自动需求响应系统上的因果性网络攻击

    Causative Cyberattacks on Online Learning-based Automated Demand Response Systems. (arXiv:2307.15175v1 [eess.SY])

    [http://arxiv.org/abs/2307.15175](http://arxiv.org/abs/2307.15175)

    该论文研究了在线学习型自动需求响应系统存在的因果性网络攻击漏洞，并设计了一种数据驱动的攻击策略来模拟对实时需求响应的恶意篡改。

    

    电力公用事业正在采用自动需求响应（ADR）来替代昂贵的燃煤发电机，并在电力需求高峰期预防拥塞。同样，第三方需求响应（DR）聚合器正在利用可控的小规模电力负荷为公用事业提供按需的电网支持服务。一些聚合器和公用事业开始应用人工智能（AI）来了解电力消费者的能源使用模式，并利用这一知识来设计最佳的DR激励措施。这样的AI框架使用了公用事业/聚合器和DR客户之间的开放通信渠道，这些通道容易受到\textit{因果性}数据完整性网络攻击的威胁。本文探讨了基于AI的DR学习的漏洞，并设计了一种数据驱动的攻击策略，该策略利用从纽约大学（NYU）校园建筑中收集的DR数据进行了信息收集。该案例研究证明了恶意篡改（i）实时DR的可行性和效果

    Power utilities are adopting Automated Demand Response (ADR) to replace the costly fuel-fired generators and to preempt congestion during peak electricity demand. Similarly, third-party Demand Response (DR) aggregators are leveraging controllable small-scale electrical loads to provide on-demand grid support services to the utilities. Some aggregators and utilities have started employing Artificial Intelligence (AI) to learn the energy usage patterns of electricity consumers and use this knowledge to design optimal DR incentives. Such AI frameworks use open communication channels between the utility/aggregator and the DR customers, which are vulnerable to \textit{causative} data integrity cyberattacks. This paper explores vulnerabilities of AI-based DR learning and designs a data-driven attack strategy informed by DR data collected from the New York University (NYU) campus buildings. The case study demonstrates the feasibility and effects of maliciously tampering with (i) real-time DR 
    
[^59]: PredictChain：为去中心化区块链市场赋能合作和数据可访问性的人工智能

    PredictChain: Empowering Collaboration and Data Accessibility for AI in a Decentralized Blockchain-based Marketplace. (arXiv:2307.15168v1 [cs.LG])

    [http://arxiv.org/abs/2307.15168](http://arxiv.org/abs/2307.15168)

    PredictChain是一个基于区块链的市场，旨在解决通过提供合作和数据可访问性的机制来训练和利用预测性机器学习模型时所面临的计算资源和训练数据有限访问的挑战。

    

    对计算资源和训练数据的有限访问给希望训练和利用预测性机器学习模型的个人和团体带来了重大挑战。尽管存在许多公开可用的机器学习模型，但它们通常没有托管，需要最终用户建立自己的计算基础设施。或者，这些模型可能仅通过付费的基于云的机制访问，这对于公众的一般使用可能是昂贵的。此外，模型和数据提供者需要一种更流畅的方法来跟踪资源使用情况，并从其他人的随后使用中获得资金和其他方面的利益。目前还缺乏一种有效的机制来为改进模型性能贡献高质量的数据。我们提出了一个名为“PredictChain”的基于区块链的市场，用于解决这些问题。这个市场允许用户上传数据集用于训练预测性机器学习模型，请求模型使用并追踪资源的使用情况。

    Limited access to computing resources and training data poses significant challenges for individuals and groups aiming to train and utilize predictive machine learning models. Although numerous publicly available machine learning models exist, they are often unhosted, necessitating end-users to establish their computational infrastructure. Alternatively, these models may only be accessible through paid cloud-based mechanisms, which can prove costly for general public utilization. Moreover, model and data providers require a more streamlined approach to track resource usage and capitalize on subsequent usage by others, both financially and otherwise. An effective mechanism is also lacking to contribute high-quality data for improving model performance. We propose a blockchain-based marketplace called "PredictChain" for predictive machine-learning models to address these issues. This marketplace enables users to upload datasets for training predictive machine learning models, request mod
    
[^60]: VISU参加WASSA 2023共享任务：利用BERT和堆叠嵌入检测对新闻故事的情绪反应

    VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News Stories Leveraging BERT and Stacked Embeddings. (arXiv:2307.15164v1 [cs.CL])

    [http://arxiv.org/abs/2307.15164](http://arxiv.org/abs/2307.15164)

    本研究中，我们开发了一种利用深度学习模型和词嵌入表示的策略来捕捉复杂对话中情绪表达的微妙差异。我们的实验结果在情绪检测任务中取得了良好的效果，并在小样本和不平衡的混合目标情绪数据集中得到了验证。

    

    我们的系统VISU参加了WASSA 2023共享任务（3），即从对新闻文章的反应中写的文章中进行情绪分类。从复杂对话中检测情绪是具有挑战性的，通常需要上下文/领域的理解。因此，在这项研究中，我们专注于开发深度学习（DL）模型，使用定制的预处理策略与词嵌入表示的组合来捕捉表达的情绪的微妙差异。我们的实验使用了静态和上下文嵌入（单独和堆叠）与双向长短期记忆（BiLSTM）和Transformer模型。在情绪检测任务中，我们占据了第十名，得分为0.2717的宏F1-分数，验证了我们实施的方法在小样本和不平衡的混合目标情绪数据集中的有效性。

    Our system, VISU, participated in the WASSA 2023 Shared Task (3) of Emotion Classification from essays written in reaction to news articles. Emotion detection from complex dialogues is challenging and often requires context/domain understanding. Therefore in this research, we have focused on developing deep learning (DL) models using the combination of word embedding representations with tailored prepossessing strategies to capture the nuances of emotions expressed. Our experiments used static and contextual embeddings (individual and stacked) with Bidirectional Long short-term memory (BiLSTM) and Transformer based models. We occupied rank tenth in the emotion detection task by scoring a Macro F1-Score of 0.2717, validating the efficacy of our implemented approaches for small and imbalanced datasets with mixed categories of target emotions.
    
[^61]: R-LPIPS: 一种具有对抗鲁棒性的感知相似度度量

    R-LPIPS: An Adversarially Robust Perceptual Similarity Metric. (arXiv:2307.15157v1 [cs.CV])

    [http://arxiv.org/abs/2307.15157](http://arxiv.org/abs/2307.15157)

    该论文提出了一种针对对抗性示例具有鲁棒性的新型感知相似度度量方法R-LPIPS，用于解决在计算机视觉中广泛采用的LPIPS度量方法对对抗性示例的敏感性问题。

    

    相似度度量在计算机视觉中扮演着重要角色，用于捕捉图像的基本语义。最近几年，出现了先进的相似度度量方法，例如学习的感知图像块相似度（LPIPS）。这些度量利用来自训练神经网络的深度特征，并在相对图像相似度评估中展现出与人类感知密切一致的能力。然而，现在已经众所周知，神经网络容易受到对抗性示例的影响，即对人类来说不可见的小扰动，被精心设计用来故意误导模型。因此，LPIPS度量方法也对这些对抗性示例敏感。这种敏感性引入了重大的安全问题，特别是考虑到LPIPS在大规模应用中的广泛采用。本文提出了鲁棒的学习感知图像块相似度（R-LPIPS）度量方法，一种利用对抗性训练的深度特征的新度量方法。

    Similarity metrics have played a significant role in computer vision to capture the underlying semantics of images. In recent years, advanced similarity metrics, such as the Learned Perceptual Image Patch Similarity (LPIPS), have emerged. These metrics leverage deep features extracted from trained neural networks and have demonstrated a remarkable ability to closely align with human perception when evaluating relative image similarity. However, it is now well-known that neural networks are susceptible to adversarial examples, i.e., small perturbations invisible to humans crafted to deliberately mislead the model. Consequently, the LPIPS metric is also sensitive to such adversarial examples. This susceptibility introduces significant security concerns, especially considering the widespread adoption of LPIPS in large-scale applications. In this paper, we propose the Robust Learned Perceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leverages adversarially trained deep f
    
[^62]: A/B测试和具有非稳态鲁棒性的线性赌博机最佳臂识别问题

    A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity. (arXiv:2307.15154v1 [cs.LG])

    [http://arxiv.org/abs/2307.15154](http://arxiv.org/abs/2307.15154)

    本文研究了在非稳态环境中的线性赌博机的最佳臂识别问题，提出了一种具有鲁棒性的算法来解决。该算法通过在每个时间步从一个G-最优设计中随机选择臂来实现最佳臂的鲁棒识别。

    

    本文研究了在可能存在非稳态环境下的线性赌博机中的固定预算最佳臂识别问题。给定有限臂集合X，固定预算T以及不可预测的参数序列θ，算法的目标是以尽可能高的概率正确识别最佳臂x*。之前的工作已经在稳态设置下进行了研究，并且证明了错误概率随着预算的增加而指数下降。但在许多现实世界的A/B/n多变量测试场景中，环境是非稳态的，而一个期望稳态的算法很容易失败。为了具有鲁棒的识别能力，众所周知，如果在每个时间步从X的一个G-最优设计中以随机和非自适应的方式选择臂，那么可以实现最佳臂的鲁棒识别。

    We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\mathcal{X}\subset\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\left\lbrace\theta_t\right\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \arg\max_{x\in\mathcal{X}}x^\top\sum_{t=1}^{T}\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\theta_t = \theta_1$ for all $t$ and demonstrated that the error probability decreases as $\exp(-T /\rho^*)$ for a problem-dependent constant $\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\mathcal{X}$ at each 
    
[^63]: R-Block: 用于卷积网络的正则化Dropout块

    R-Block: Regularized Block of Dropout for convolutional networks. (arXiv:2307.15150v1 [cs.CV])

    [http://arxiv.org/abs/2307.15150](http://arxiv.org/abs/2307.15150)

    本文提出了一种名为R-Block的新型正则化Dropout块，通过互学习训练策略强制两个子模型的输出一致性，以解决卷积层中Dropout效果较差的问题。

    

    Dropout作为一种正则化技术，在全连接层中被广泛使用，但在卷积层中效果较差。因此，提出了更有结构性的Dropout形式来正则化卷积网络。这些方法的缺点是引入的随机性导致训练和推断之间的不一致性。本文应用了一种互学习训练策略，即R-Block，来进行卷积层的正则化。它强制两个生成的最大化差异的子模型的输出彼此一致。具体而言，R-Block通过最小化训练数据集中每个样本的两个具有不同Drop区域的子模型的输出分布之间的损失来实现。我们设计了两种构建这样子模型的方法。我们的实验证明，R-Block比其他现有的结构化Dropout变体具有更好的性能。我们还证明了我们构建子模型的方法优于其他方法。

    Dropout as a regularization technique is widely used in fully connected layers while is less effective in convolutional layers. Therefore more structured forms of dropout have been proposed to regularize convolutional networks. The disadvantage of these methods is that the randomness introduced causes inconsistency between training and inference. In this paper, we apply a mutual learning training strategy for convolutional layer regularization, namely R-Block, which forces two outputs of the generated difference maximizing sub models to be consistent with each other. Concretely, R-Block minimizes the losses between the output distributions of two sub models with different drop regions for each sample in the training dataset. We design two approaches to construct such sub models. Our experiments demonstrate that R-Block achieves better performance than other existing structured dropout variants. We also demonstrate that our approaches to construct sub models outperforms others.
    
[^64]: 通过持续增量训练检测变形攻击

    Detecting Morphing Attacks via Continual Incremental Training. (arXiv:2307.15105v1 [cs.CV])

    [http://arxiv.org/abs/2307.15105](http://arxiv.org/abs/2307.15105)

    本文通过模拟更新学习模型以适应可变大小的新数据块的情景，研究了不同持续学习方法在检测变形攻击中的性能。实验结果表明，无遗忘学习（LwF）是表现最好的算法之一。

    

    在数据传输和存储限制的情况下，无法使用单个数据集组合多个数据来源进行批次训练，这对于开发鲁棒性模型来说是一种挑战。本文假设最近的持续学习（CL）范式可以有效解决通过多个站点进行增量训练的问题。实验结果表明，一种特殊的CL方法，即无遗忘学习（LwF），是性能最好的算法之一。

    Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and 
    
[^65]: 通过短时傅里叶变换机器学习在Nvidia Edge GPU设备上实现声音与音频分类的儿童虐待检测

    Detection of Children Abuse by Voice and Audio Classification by Short-Time Fourier Transform Machine Learning implemented on Nvidia Edge GPU device. (arXiv:2307.15101v1 [eess.AS])

    [http://arxiv.org/abs/2307.15101](http://arxiv.org/abs/2307.15101)

    通过机器学习技术，在Nvidia Edge GPU设备上利用声音和音频分类，成功实现了对儿童虐待的检测，确保了儿童的安全。

    

    儿童福利院中儿童的安全已成为一个日益关注的社会问题，本实验旨在利用机器学习应用于儿童虐待的场景检测，以提高儿童的安全性。该实验使用机器学习对儿童的声音进行分类和识别，预测儿童当前发出的声音是哭泣、尖叫还是笑声。如果发现儿童正在哭泣或尖叫，立即向相关人员发送警报，以便他们能够察觉到儿童在监控盲区中可能经历的情况，并及时作出反应。结合视频图像分类的混合使用，可以显著提高儿童虐待检测的准确性。这极大地降低了婴儿室中儿童遭受暴力虐待的可能性，并使工作人员能够及时阻止即将发生或初期的儿童虐待事件。本实验收集的数据集完全来自录音中的声音记录。

    The safety of children in children home has become an increasing social concern, and the purpose of this experiment is to use machine learning applied to detect the scenarios of child abuse to increase the safety of children. This experiment uses machine learning to classify and recognize a child's voice and predict whether the current sound made by the child is crying, screaming or laughing. If a child is found to be crying or screaming, an alert is immediately sent to the relevant personnel so that they can perceive what the child may be experiencing in a surveillance blind spot and respond in a timely manner. Together with a hybrid use of video image classification, the accuracy of child abuse detection can be significantly increased. This greatly reduces the likelihood that a child will receive violent abuse in the nursery and allows personnel to stop an imminent or incipient child abuse incident in time. The datasets collected from this experiment is entirely from sounds recorded 
    
[^66]: 使用监督和无监督学习的组合将插图按照氛围进行聚类

    Clustering of illustrations by atmosphere using a combination of supervised and unsupervised learning. (arXiv:2307.15099v1 [cs.CV])

    [http://arxiv.org/abs/2307.15099](http://arxiv.org/abs/2307.15099)

    本文提出了一种使用监督和无监督学习的组合方法，通过伪标签对插图进行特征向量的提取，并基于这些特征向量进行聚类，从而解决了插图按照氛围进行分类的问题。

    

    随着动画、游戏和动画电影的日益流行，社交媒体上插图的分布逐渐增加。插图的"氛围"在用户偏好中起着重要作用。按照氛围对插图进行分类可以为推荐和搜索提供帮助。然而，给难以定义的"氛围"分配明确的标签并且使用传统的监督分类并不总是可行的。此外，即使颜色、边缘和低层次特征相似的图像也可能没有相似的氛围，这使得基于低层次特征进行分类具有挑战性。本文提出了一种采用伪标签的监督和无监督学习相结合来解决这个问题的方法。使用伪标签通过监督方法获得的特征向量有助于处理模糊的氛围。然后，基于这些特征向量进行聚类。实验分析表明，我们的方法优于传统方法。

    The distribution of illustrations on social media, such as Twitter and Pixiv has increased with the growing popularity of animation, games, and animated movies. The "atmosphere" of illustrations plays an important role in user preferences. Classifying illustrations by atmosphere can be helpful for recommendations and searches. However, assigning clear labels to the elusive "atmosphere" and conventional supervised classification is not always practical. Furthermore, even images with similar colors, edges, and low-level features may not have similar atmospheres, making classification based on low-level features challenging. In this paper, this problem is solved using both supervised and unsupervised learning with pseudo-labels. The feature vectors are obtained using the supervised method with pseudo-labels that contribute to an ambiguous atmosphere. Further, clustering is performed based on these feature vectors. Experimental analyses show that our method outperforms conventional methods
    
[^67]: 提高合成孔径声纳目标识别的自监督学习

    Self-Supervised Learning for Improved Synthetic Aperture Sonar Target Recognition. (arXiv:2307.15098v1 [cs.CV])

    [http://arxiv.org/abs/2307.15098](http://arxiv.org/abs/2307.15098)

    本研究探索了在合成孔径声纳（SAS）图像中应用自监督学习（SSL）进行目标识别的方法，并评估了两种自监督学习算法的性能。研究结果表明，SSL模型可以在没有标签的数据中学习特征，提高目标识别的效果。

    

    本研究探讨了在合成孔径声纳（SAS）图像中应用自监督学习（SSL）以提高目标识别的应用。水下环境的独特挑战使得传统的依赖于光学相机图像的计算机视觉技术效果较差。SAS凭借其生成高分辨率图像的能力成为水下成像的首选。然而，庞大的高分辨率SAS数据对于标注来说是一个重要挑战，而标注是训练深度神经网络（DNNs）的关键步骤。自监督学习（SSL）被提出作为解决SAS数据标注挑战的潜在解决方案，它使得模型能够在没有标签的数据中学习特征。本研究评估了两种主要的自监督学习算法MoCov2和BYOL在二进制图像分类任务中与备受认可的有监督学习模型ResNet18的性能。研究结果表明，两种SSL模型都能胜过完全有监督的模型。

    This study explores the application of self-supervised learning (SSL) for improved target recognition in synthetic aperture sonar (SAS) imagery. The unique challenges of underwater environments make traditional computer vision techniques, which rely heavily on optical camera imagery, less effective. SAS, with its ability to generate high-resolution imagery, emerges as a preferred choice for underwater imaging. However, the voluminous high-resolution SAS data presents a significant challenge for labeling; a crucial step for training deep neural networks (DNNs).  SSL, which enables models to learn features in data without the need for labels, is proposed as a potential solution to the data labeling challenge in SAS. The study evaluates the performance of two prominent SSL algorithms, MoCov2 and BYOL, against the well-regarded supervised learning model, ResNet18, for binary image classification tasks. The findings suggest that while both SSL models can outperform a fully supervised model 
    
[^68]: 级联跨模态Transformer用于请求和投诉检测

    Cascaded Cross-Modal Transformer for Request and Complaint Detection. (arXiv:2307.15097v1 [cs.CL])

    [http://arxiv.org/abs/2307.15097](http://arxiv.org/abs/2307.15097)

    本文提出了一种级联跨模态Transformer模型，结合语音和文本转录，用于检测电话对话中的客户请求和投诉。在ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，我们的系统在投诉和请求类别中达到了65.41%和85.87%的不平衡平均召回率。

    

    我们提出了一种新颖的级联跨模态Transformer（CCMT），将语音和文本转录结合起来，以检测电话对话中的客户请求和投诉。我们的方法通过使用自动语音识别（ASR）模型转录语音，并将转录件翻译成不同语言来利用多模态范式。随后，我们将语言特定的基于BERT的模型与Wav2Vec2.0音频特征在一个新颖的级联交叉注意力Transformer模型中相结合。我们将我们的系统应用于ACM Multimedia 2023计算语言学挑战赛的请求子挑战中，在投诉和请求类别中分别达到了65.41%和85.87%的不平衡平均召回率（UAR）。

    We propose a novel cascaded cross-modal transformer (CCMT) that combines speech and text transcripts to detect customer requests and complaints in phone conversations. Our approach leverages a multimodal paradigm by transcribing the speech using automatic speech recognition (ASR) models and translating the transcripts into different languages. Subsequently, we combine language-specific BERT-based models with Wav2Vec2.0 audio features in a novel cascaded cross-attention transformer model. We apply our system to the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge, reaching unweighted average recalls (UAR) of 65.41% and 85.87% for the complaint and request classes, respectively.
    
[^69]: 关于沉积计算及其超越传统机器学习的跨学科应用的综述

    A Survey on Reservoir Computing and its Interdisciplinary Applications Beyond Traditional Machine Learning. (arXiv:2307.15092v1 [cs.NE])

    [http://arxiv.org/abs/2307.15092](http://arxiv.org/abs/2307.15092)

    沉积计算是一个具有随机连接的循环神经网络，其简单的结构和丰富的动力学使其在各种应用中能够生成适当的响应。它的跨学科应用包括物理硬件实现和生物设备，同时也有助于理解大脑机制。

    

    沉积计算（RC）首先用于时间信号处理，它是一个具有随机连接的循环神经网络。一旦初始化，连接强度将保持不变。这种简单的结构将RC转化为一个非线性动力系统，将低维输入映射到高维空间中。该模型的丰富动力学、线性可分性和记忆容量使得简单的线性读出能够为各种应用生成适当的响应。RC涵盖了远远超出机器学习范围的领域，因为已经证明复杂的动力学可以在各种物理硬件实现和生物设备中实现。这样可以提供更大的灵活性和更短的计算时间。此外，模型动力学触发的神经元响应也揭示了理解大脑机制的方法，这些机制也利用类似的动力学过程。虽然关于RC的文献非常庞大且碎片化，但我们在这里对RC的最新发展进行了统一的回顾。

    Reservoir computing (RC), first applied to temporal signal processing, is a recurrent neural network in which neurons are randomly connected. Once initialized, the connection strengths remain unchanged. Such a simple structure turns RC into a non-linear dynamical system that maps low-dimensional inputs into a high-dimensional space. The model's rich dynamics, linear separability, and memory capacity then enable a simple linear readout to generate adequate responses for various applications. RC spans areas far beyond machine learning, since it has been shown that the complex dynamics can be realized in various physical hardware implementations and biological devices. This yields greater flexibility and shorter computation time. Moreover, the neuronal responses triggered by the model's dynamics shed light on understanding brain mechanisms that also exploit similar dynamical processes. While the literature on RC is vast and fragmented, here we conduct a unified review of RC's recent devel
    
[^70]: 理解卷积神经网络的前向过程

    Understanding Forward Process of Convolutional Neural Network. (arXiv:2307.15090v1 [cs.LG])

    [http://arxiv.org/abs/2307.15090](http://arxiv.org/abs/2307.15090)

    本文揭示了CNN前向处理中的选择性旋转机制，并通过使用结构化数学工具对数据进行统计和分析，发现了人工神经网络和人脑在数据处理模式上的一致性。

    

    本文揭示了CNN前向处理中的选择性旋转。它阐明了激活函数作为一个分析机制，将输入数据的旋转方面统一量化。实验证明，这种定义的方法论反映了进程网络根据统计指标区分输入的能力，可以通过应用结构化的数学工具来理解或分析。我们的发现还揭示了人工神经网络和人脑在数据处理模式上的一致性。

    This paper reveal the selective rotation in the CNNs' forward processing. It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern.
    
[^71]: 数据集中的信息提升子群发现

    Information Gained Subgroup Discovery in Datasets. (arXiv:2307.15089v1 [cs.LG])

    [http://arxiv.org/abs/2307.15089](http://arxiv.org/abs/2307.15089)

    该论文研究了在数据集中通过信息提升的方法进行子群发现。具体针对肺癌治疗，在保持或提高治疗效果的同时减少副作用对于改善患者的生活质量非常重要，临床指南虽然提供了治疗建议，但仍未将治疗结果纳入考量。

    

    肺癌是癌症死亡的主要原因。预计2023年将有超过238,340例新的肺癌患者，其中有超过127,070例死亡。选择正确的治疗方案是提高存活率和改善患者生活质量的重要因素。癌症治疗可能引发副作用，这些毒副反应会引起不同的健康问题，影响患者的生活质量。因此，在保持或提高治疗效果的同时减少治疗副作用是临床角度要追求的重要目标。另一方面，临床指南包括癌症治疗建议的一般知识，以协助临床医生。尽管他们根据癌症疾病方面和个体患者特征提供治疗建议，但并未提供基于治疗结果的统计分析。因此，需要对临床指南与治疗结果进行比较。

    Lung cancer is the leading cause of cancer death. More than 238,340 new cases of lung cancer patients are expected in 2023, with an estimation of more than 127,070 deaths. Choosing the correct treatment is an important element to enhance the probability of survival and to improve patient's quality of life. Cancer treatments might provoke secondary effects. These toxicities cause different health problems that impact the patient's quality of life. Hence, reducing treatments toxicities while maintaining or improving their effectivenes is an important goal that aims to be pursued from the clinical perspective. On the other hand, clinical guidelines include general knowledge about cancer treatment recommendations to assist clinicians. Although they provide treatment recommendations based on cancer disease aspects and individual patient features, a statistical analysis taking into account treatment outcomes is not provided here. Therefore, the comparison between clinical guidelines with tre
    
[^72]: 具有公正性的时变定价电费设计：一种联合学习和优化方法

    Equitable Time-Varying Pricing Tariff Design: A Joint Learning and Optimization Approach. (arXiv:2307.15088v1 [cs.LG])

    [http://arxiv.org/abs/2307.15088](http://arxiv.org/abs/2307.15088)

    本文提出了一种联合学习和优化方法，用于设计具有公平性的时变定价电费。通过基于循环神经网络的学习方法捕捉消费者价格响应行为，并将之嵌入到定价方案优化中，实现了保护低收入消费者免受价格波动的效果，同时有效激励了能源调整行为。

    

    时变定价电费激励消费者调整电力需求以降低成本，但可能增加对反应能力有限的消费者的能源负担。因此，能源公司在设计这些定价方案时必须平衡可负担性和激励效果，并考虑消费者的反应期望。本文提出了一种基于联合学习和优化方法的公平时变定价电费设计方法。我们的方法将历史价格和需求响应数据编码为递归神经网络（RNN），以捕捉高维和非线性的消费者价格响应行为。然后，我们将RNN嵌入到定价方案优化中，构建一个目标为二次型的非线性优化问题。我们提出了一种基于梯度的解决方法，实现快速和可扩展的计算。使用真实消费者数据进行的模拟表明，我们的公平定价方案在保护低收入消费者免受价格波动的同时，有效地激励了能源调整行为。

    Time-varying pricing tariffs incentivize consumers to shift their electricity demand and reduce costs, but may increase the energy burden for consumers with limited response capability. The utility must thus balance affordability and response incentives when designing these tariffs by considering consumers' response expectations. This paper proposes a joint learning-based identification and optimization method to design equitable time-varying tariffs. Our proposed method encodes historical prices and demand response data into a recurrent neural network (RNN) to capture high-dimensional and non-linear consumer price response behaviors. We then embed the RNN into the tariff design optimization, formulating a non-linear optimization problem with a quadratic objective. We propose a gradient-based solution method that achieves fast and scalable computation. Simulation using real-world consumer data shows that our equitable tariffs protect low-income consumers from price surges while effecti
    
[^73]: 使用社会人口统计数据对基于BCG的膀胱癌治疗进行数学建模

    Mathematical Modeling of BCG-based Bladder Cancer Treatment Using Socio-Demographics. (arXiv:2307.15084v1 [cs.LG])

    [http://arxiv.org/abs/2307.15084](http://arxiv.org/abs/2307.15084)

    本研究利用患者的社会人口统计数据提供个性化的数学模型，以描述基于BCG的膀胱癌治疗的临床动态。

    

    癌症是世界上最常见的疾病之一，每年都有数百万新患者。膀胱癌是一种最普遍的癌症类型，影响所有人，并没有明显的典型患者。目前，BCG免疫治疗是膀胱癌的标准治疗方法，所有患者都会进行每周例行的BCG治疗。由于免疫系统、治疗和癌细胞之间的生物和临床复杂性，BCG治疗的临床结果在患者之间存在显著差异。在本研究中，我们利用患者的社会人口统计数据提供个性化的数学模型，以描述与基于BCG的治疗相关的临床动态。为此，我们采用了一种成熟的BCG治疗模型，并整合了机器学习组件，以在模型内部即时调整和重新配置关键参数，从而促进其个性化。

    Cancer is one of the most widespread diseases around the world with millions of new patients each year. Bladder cancer is one of the most prevalent types of cancer affecting all individuals alike with no obvious prototypical patient. The current standard treatment for BC follows a routine weekly Bacillus Calmette-Guerin (BCG) immunotherapy-based therapy protocol which is applied to all patients alike. The clinical outcomes associated with BCG treatment vary significantly among patients due to the biological and clinical complexity of the interaction between the immune system, treatments, and cancer cells. In this study, we take advantage of the patient's socio-demographics to offer a personalized mathematical model that describes the clinical dynamics associated with BCG-based treatment. To this end, we adopt a well-established BCG treatment model and integrate a machine learning component to temporally adjust and reconfigure key parameters within the model thus promoting its personali
    
[^74]: 基于练习代表性和信息丰富度的知识图增强智能辅导系统

    Knowledge Graph Enhanced Intelligent Tutoring System Based on Exercise Representativeness and Informativeness. (arXiv:2307.15076v1 [cs.CY])

    [http://arxiv.org/abs/2307.15076](http://arxiv.org/abs/2307.15076)

    本论文提出了一种基于知识图谱的智能辅导系统框架，通过考虑练习的代表性和信息丰富度，以及引入新颖的认知诊断模型，解决了传统算法中对练习特征建模的不足。

    

    目前，基于知识图谱的推荐算法已经引起了研究人员的广泛关注。然而，这些算法仅考虑了单一关系的知识图谱，并没有有效地对练习的特征进行建模，例如练习代表性和信息丰富度。因此，本文提出了一种框架，即知识图谱练习代表性和信息丰富度框架，以解决这两个问题。该框架由四个复杂的组件和一种新颖的认知诊断模型——神经注意力认知诊断模型组成。这些组件包括信息丰富性组件、练习表示组件、知识重要性组件和练习代表性组件。信息丰富性组件评估每个问题的信息价值，并确定具有最高练习信息丰富度的候选问题集。此外，技能嵌入也被引入用于评估学生的技能水平。

    Presently, knowledge graph-based recommendation algorithms have garnered considerable attention among researchers. However, these algorithms solely consider knowledge graphs with single relationships and do not effectively model exercise-rich features, such as exercise representativeness and informativeness. Consequently, this paper proposes a framework, namely the Knowledge-Graph-Exercise Representativeness and Informativeness Framework, to address these two issues. The framework consists of four intricate components and a novel cognitive diagnosis model called the Neural Attentive cognitive diagnosis model. These components encompass the informativeness component, exercise representation component, knowledge importance component, and exercise representativeness component. The informativeness component evaluates the informational value of each question and identifies the candidate question set that exhibits the highest exercise informativeness. Furthermore, the skill embeddings are em
    
[^75]: ISAC-NET: 基于模型驱动的深度学习用于集成被动感知和通信

    ISAC-NET: Model-driven Deep Learning for Integrated Passive Sensing and Communication. (arXiv:2307.15074v1 [cs.IT])

    [http://arxiv.org/abs/2307.15074](http://arxiv.org/abs/2307.15074)

    本文介绍了一种名为ISAC-NET的模型驱动的深度学习方法，将被动感知与通信信号检测相结合，通过同时获得被动感知结果和通信解调符号来解决被动感知在通信解调错误条件下的高感知性能问题。

    

    近年来，随着对感知能力巨大需求的无线通信的不断发展，集成感知和通信（ISAC）技术应运而生，其中被动感知起着重要的作用。被动感知的主要挑战是在通信解调错误的条件下如何实现高感知性能。在本文中，我们提出了一种称为ISAC-NET的ISAC网络，它通过使用基于模型的深度学习（DL）将被动感知与通信信号检测相结合。与现有的首先解调传输的符号，然后从解调的符号中获得被动感知结果的被动感知算法不同，ISAC-NET同时获得被动感知结果和通信解调符号。不同于数据驱动的DL方法，我们采用了块处理信号的方法，将ISAC-NET划分为被动感知模块、信号检测模块和信道重构模块。

    Recent advances in wireless communication with the enormous demands of sensing ability have given rise to the integrated sensing and communication (ISAC) technology, among which passive sensing plays an important role. The main challenge of passive sensing is how to achieve high sensing performance in the condition of communication demodulation errors. In this paper, we propose an ISAC network (ISAC-NET) that combines passive sensing with communication signal detection by using model-driven deep learning (DL). Dissimilar to existing passive sensing algorithms that first demodulate the transmitted symbols and then obtain passive sensing results from the demodulated symbols, ISAC-NET obtains passive sensing results and communication demodulated symbols simultaneously. Different from the data-driven DL method, we adopt the block-by-block signal processing method that divides the ISAC-NET into the passive sensing module, signal detection module and channel reconstruction module. From the s
    
[^76]: 在特征转移条件下利用基于领域信息的先验分布进行药物发现

    Drug Discovery under Covariate Shift with Domain-Informed Prior Distributions over Functions. (arXiv:2307.15073v1 [q-bio.BM])

    [http://arxiv.org/abs/2307.15073](http://arxiv.org/abs/2307.15073)

    这篇论文提出了一种基于领域信息的先验分布模型Q-SAVI，能够解决药物发现中标签数据稀缺和特征转移的问题，并提供了一种透明且概率上合理的数据驱动模型建模方式。

    

    加速发现新型和更有效的治疗药物是一个重要的制药问题，深度学习在其中扮演着愈发重要的角色。然而，真实世界的药物发现任务通常特点是标签数据稀缺和显著的特征转移，这对于标准的深度学习方法构成了挑战。在本论文中，我们提出了Q-SAVI，这是一个概率模型，能够通过将数据生成过程的显式先验知识编码为函数的先验分布，为研究人员提供了一种透明且概率上合理的方式来编码数据驱动的建模偏好。基于一个新颖的，高标准的生物活性数据集，使得在外推模式下能够进行有意义的模型比较，我们探索了不同的方法来诱导数据转移并构建一个具有挑战性的评估环境。然后我们证明了使用Q-SAVI可以在特征转移条件下更好地进行药物发现。

    Accelerating the discovery of novel and more effective therapeutics is an important pharmaceutical problem in which deep learning is playing an increasingly significant role. However, real-world drug discovery tasks are often characterized by a scarcity of labeled data and significant covariate shift$\unicode{x2013}\unicode{x2013}$a setting that poses a challenge to standard deep learning methods. In this paper, we present Q-SAVI, a probabilistic model able to address these challenges by encoding explicit prior knowledge of the data-generating process into a prior distribution over functions, presenting researchers with a transparent and probabilistically principled way to encode data-driven modeling preferences. Building on a novel, gold-standard bioactivity dataset that facilitates a meaningful comparison of models in an extrapolative regime, we explore different approaches to induce data shift and construct a challenging evaluation setup. We then demonstrate that using Q-SAVI to int
    
[^77]: 使用机器学习从南非Twitter数据中检测COVID-19疫苗犹豫情绪的存在

    Detecting the Presence of COVID-19 Vaccination Hesitancy from South African Twitter Data Using Machine Learning. (arXiv:2307.15072v1 [cs.CY])

    [http://arxiv.org/abs/2307.15072](http://arxiv.org/abs/2307.15072)

    本研究通过对南非疫苗犹豫相关推文进行情感分析和机器学习模型训练，检测出COVID-19疫苗犹豫情绪的存在并对用户生成内容进行分类。这对于应对疫苗犹豫对公共卫生工作的影响具有重要意义。

    

    在COVID-19大流行期间，关于南非用户生成内容的社交媒体研究非常少，使用手动标注方法更是凤毛麟角。疫苗接种是对抗疫情的主要手段，但疫苗犹豫危及公共卫生工作。本研究对与疫苗犹豫有关的南非推文进行情感分析，旨在训练AI媒介的分类模型，并评估其在分类用户生成内容时的可靠性。我们提取了来自南非的3万条推文，并将其手动标注为三个情感类别之一：积极、消极、中性。使用的机器学习模型包括LSTM、双向LSTM、SVM、BERT-base-cased和RoBERTa-base模型，通过WandB平台精心选择和调整了它们的超参数。我们使用了两种不同的预处理方法进行比较：一种基于语义，另一种基于语料库。

    Very few social media studies have been done on South African user-generated content during the COVID-19 pandemic and even fewer using hand-labelling over automated methods. Vaccination is a major tool in the fight against the pandemic, but vaccine hesitancy jeopardizes any public health effort. In this study, sentiment analysis on South African tweets related to vaccine hesitancy was performed, with the aim of training AI-mediated classification models and assessing their reliability in categorizing UGC. A dataset of 30000 tweets from South Africa were extracted and hand-labelled into one of three sentiment classes: positive, negative, neutral. The machine learning models used were LSTM, bi-LSTM, SVM, BERT-base-cased and the RoBERTa-base models, whereby their hyperparameters were carefully chosen and tuned using the WandB platform. We used two different approaches when we pre-processed our data for comparison: one was semantics-based, while the other was corpus-based. The pre-processi
    
[^78]: 使用数据水印技术进行集合成员推理攻击

    Set-Membership Inference Attacks using Data Watermarking. (arXiv:2307.15067v1 [cs.CV])

    [http://arxiv.org/abs/2307.15067](http://arxiv.org/abs/2307.15067)

    本文提出了一种使用深度图像水印技术进行生成模型的集合成员推理攻击，通过条件采样揭示训练数据中的水印，并证明该技术能够有效检测非法使用图像数据训练模型。

    

    在这项工作中，我们提出了一种使用深度图像水印技术进行生成模型的集合成员推理攻击。具体来说，我们展示了如何从生成模型中进行条件采样，以揭示注入到训练数据部分的水印。我们的实证结果表明，所提出的水印技术是一种检测非协商使用图像数据训练生成模型的原则性方法。

    In this work, we propose a set-membership inference attack for generative models using deep image watermarking techniques. In particular, we demonstrate how conditional sampling from a generative model can reveal the watermark that was injected into parts of the training data. Our empirical results demonstrate that the proposed watermarking technique is a principled approach for detecting the non-consensual use of image data in training generative models.
    
[^79]: 一种自适应惩罚方法用于将先验知识约束集成到神经常微分方程中

    A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs. (arXiv:2307.14940v1 [cs.LG])

    [http://arxiv.org/abs/2307.14940](http://arxiv.org/abs/2307.14940)

    本论文提出了一种自适应惩罚算法，用于将约束的自然系统集成到神经常微分方程中，通过引入先验知识提高了模型的可解释性，并通过数值实验证明了其有效性。

    

    使用神经常微分方程(Neural ODEs)，可以有效地对自然系统的连续动态进行建模。然而，为了实现准确而有意义的预测，模型必须遵循管理这些系统的基本规律或定律。在本论文中，我们提出了一种自适应惩罚算法，用于将约束的自然系统集成到神经常微分方程中。所提出的自适应惩罚函数可以动态调整惩罚参数。引入先验知识有助于增加基于神经常微分方程的模型的可解释性。我们通过模拟三个具有先验知识约束的自然系统(人口增长，化学反应演化和阻尼谐振运动)来验证所提出的方法。数值实验证明了所提出的自适应惩罚算法在神经常微分方程中的有效性，并与其他惩罚神经常微分方程方法和原始神经常微分方程进行了比较。

    The continuous dynamics of natural systems has been effectively modelled using Neural Ordinary Differential Equations (Neural ODEs). However, for accurate and meaningful predictions, it is crucial that the models follow the underlying rules or laws that govern these systems. In this work, we propose a self-adaptive penalty algorithm for Neural ODEs to enable modelling of constrained natural systems. The proposed self-adaptive penalty function can dynamically adjust the penalty parameters. The explicit introduction of prior knowledge helps to increase the interpretability of Neural ODE -based models. We validate the proposed approach by modelling three natural systems with prior knowledge constraints: population growth, chemical reaction evolution, and damped harmonic oscillator motion. The numerical experiments and a comparison with other penalty Neural ODE approaches and \emph{vanilla} Neural ODE, demonstrate the effectiveness of the proposed self-adaptive penalty algorithm for Neural
    
[^80]: 使用Desbordante解决数据质量问题：一项演示

    Solving Data Quality Problems with Desbordante: a Demo. (arXiv:2307.14935v1 [cs.DB])

    [http://arxiv.org/abs/2307.14935](http://arxiv.org/abs/2307.14935)

    Desbordante是一个旨在解决数据质量问题的工具，通过发现和验证复杂统计信息来帮助现代数据科学家进行数据概要分析。它提供了与现有工具的适当集成，同时考虑到工业级工作负载，并提供描述性的解释来解释模式缺失的原因。

    

    数据概要分析是现代数据驱动行业中的重要过程。其中一个关键组成部分是发现和验证复杂统计信息，包括函数依赖、数据约束、关联规则等。然而，大多数现有的专注于复杂统计的数据概要分析系统在与现代数据科学家使用的工具进行适当集成方面存在问题。这在行业中对这些工具采用造成了重大障碍。此外，现有系统并不考虑工业级工作负载。最后，它们不旨在提供描述性的解释，即为什么找不到给定的模式。这是一个重要问题，因为了解特定模式缺失的根本原因对基于数据的明智决策至关重要。因此，这些模式实际上是消失在空中中：它们的应用范围相对有限，很少被广大公众使用。

    Data profiling is an essential process in modern data-driven industries. One of its critical components is the discovery and validation of complex statistics, including functional dependencies, data constraints, association rules, and others.  However, most existing data profiling systems that focus on complex statistics do not provide proper integration with the tools used by contemporary data scientists. This creates a significant barrier to the adoption of these tools in the industry. Moreover, existing systems were not created with industrial-grade workloads in mind. Finally, they do not aim to provide descriptive explanations, i.e. why a given pattern is not found. It is a significant issue as it is essential to understand the underlying reasons for a specific pattern's absence to make informed decisions based on the data.  Because of that, these patterns are effectively rest in thin air: their application scope is rather limited, they are rarely used by the broader public. At the
    
[^81]: MVMR-FS：基于最大类间差异和最小冗余的非参数特征选择算法

    MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy. (arXiv:2307.14643v1 [cs.LG])

    [http://arxiv.org/abs/2307.14643](http://arxiv.org/abs/2307.14643)

    本文提出了一种基于最大类间差异和最小冗余的非参数特征选择算法(MVMR-FS)，通过使用有监督和无监督核密度估计来度量特征之间的相关性和冗余，并提出了最大类间差异和最小冗余的准则(MVMR)，以辅助特征选择。

    

    如何准确度量特征的相关性和冗余是特征选择领域的一个古老挑战。然而，现有的基于过滤的特征选择方法无法直接度量连续数据的冗余。此外，大多数方法依赖于手动指定特征数量，这在没有专家知识的情况下可能导致错误。本文提出了一种基于最大类间差异和最小冗余的非参数特征选择算法，简称为MVMR-FS。我们首先引入了对特征的有监督和无监督核密度估计，以捕捉它们在类间和整体分布中的相似性和差异。随后，我们提出了最大类间差异和最小冗余（MVMR）的准则，其中利用类间概率分布来反映特征的相关性，利用整体概率分布之间的距离来量化冗余。

    How to accurately measure the relevance and redundancy of features is an age-old challenge in the field of feature selection. However, existing filter-based feature selection methods cannot directly measure redundancy for continuous data. In addition, most methods rely on manually specifying the number of features, which may introduce errors in the absence of expert knowledge. In this paper, we propose a non-parametric feature selection algorithm based on maximum inter-class variation and minimum redundancy, abbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel density estimation on the features to capture their similarities and differences in inter-class and overall distributions. Subsequently, we present the criteria for maximum inter-class variation and minimum redundancy (MVMR), wherein the inter-class probability distributions are employed to reflect feature relevance and the distances between overall probability distributions are used to quantify redundanc
    
[^82]: 神经Schr\"odinger桥接配对Sinkhorn损失：应用于胶体自组装的数据驱动最小工作控制

    Neural Schr\"odinger Bridge with Sinkhorn Losses: Application to Data-driven Minimum Effort Control of Colloidal Self-assembly. (arXiv:2307.14442v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2307.14442](http://arxiv.org/abs/2307.14442)

    本文介绍了一种基于神经网络的Schr\"odinger桥接算法，应用于胶体自组装的最小工作控制问题中。与现有方法相比，该方法考虑了胶体自组装中的非线性控制系数，并提出了一种数据驱动的学习和控制框架。

    

    我们展示了胶体自组装的最小工作控制可以自然地在次序参数空间中以广义Schr\"odinger桥接问题的形式表达 - 这是一类在30年代末Erwin Schr\"odinger的作品中起源的固定时域随机最优控制问题。在近年来，这类问题在控制和机器学习社区中重新兴起了研究活动。与现有文献中关于这类问题的理论和计算有所不同，胶体自组装的控制漂移和扩散系数通常在控制方面是非线性的，且难以从基于物理建模中获得。我们推导了这类广义问题的最优性条件，并展示了导致的方程系统在结构上与现有结果完全不同，标准的计算方法不再适用。出于这个动机，我们提出了一个数据驱动的学习和控制框架。

    We show that the minimum effort control of colloidal self-assembly can be naturally formulated in the order-parameter space as a generalized Schr\"odinger bridge problem -- a class of fixed-horizon stochastic optimal control problems that originated in the works of Erwin Schr\"odinger in the early 1930s. In recent years, this class of problems has seen a resurgence of research activities in control and machine learning communities. Different from the existing literature on the theory and computation for such problems, the controlled drift and diffusion coefficients for colloidal self-assembly are typically non-affine in control, and are difficult to obtain from physics-based modeling. We deduce the conditions of optimality for such generalized problems, and show that the resulting system of equations is structurally very different from the existing results in a way that standard computational approaches no longer apply. Thus motivated, we propose a data-driven learning and control fram
    
[^83]: ARB：大型语言模型的高级推理基准

    ARB: Advanced Reasoning Benchmark for Large Language Models. (arXiv:2307.13692v1 [cs.CL])

    [http://arxiv.org/abs/2307.13692](http://arxiv.org/abs/2307.13692)

    ARB是一个新型基准，包含了数学、物理、生物、化学和法律领域的高级推理问题。目前的语言模型在这些任务上得分远低于50%，为了提高评估能力，我们引入了基于评分标准的评估方法。

    

    大型语言模型（LLMs）在各种定量推理和知识基准上展示了卓越的性能。然而，尽管在这些领域中还没有达到专家水平，但许多这些基准随着LLMs获得越来越高的分数而失去了效用。我们引入了ARB，一个由多个领域的高级推理问题组成的新型基准。ARB提供比以前的基准更具挑战性的测试，包括数学、物理、生物、化学和法律领域的问题。作为ARB的一部分，我们介绍了一组挑战性的数学和物理问题，需要高级符号推理和领域知识。我们评估了最近的模型，如GPT-4和Claude在ARB上的表现，并证明当前模型在更具挑战性的任务上得分远低于50%。为了改进自动和辅助评估能力，我们引入了基于评分标准的评估方法，允许GPT-4对其自身的中间推理步骤评分。

    Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct 
    
[^84]: Duet: 高效且可扩展的混合神经关系理解

    Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v1 [cs.DB])

    [http://arxiv.org/abs/2307.13494](http://arxiv.org/abs/2307.13494)

    Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。

    

    基于概率分布估计的基数估计方法相较于传统方法取得了高精度的估计结果。然而，最先进的方法由于在处理范围查询时使用的采样方法而导致估计成本较高。此外，这种采样方法也使得它们难以区分，因此来自查询工作负载的监督信号很难训练模型以提高基数估计的准确性。在本文中，我们提出了一种新的混合确定性建模方法（Duet）用于基数估计问题，与以前的方法相比，具有更好的效率和可扩展性。Duet可以以更低的时间和内存成本直接估计范围查询的基数，并且以可区分的形式呈现。由于此方法的预测过程是可微分的，我们可以将估计误差较大的查询纳入训练过程以进行改进。

    Cardinality estimation methods based on probability distribution estimation have achieved high-precision estimation results compared to traditional methods. However, the most advanced methods suffer from high estimation costs due to the sampling method they use when dealing with range queries. Also, such a sampling method makes them difficult to differentiate, so the supervision signal from the query workload is difficult to train the model to improve the accuracy of cardinality estimation. In this paper, we propose a new hybrid and deterministic modeling approach (Duet) for the cardinality estimation problem which has better efficiency and scalability compared to previous approaches. Duet allows for direct cardinality estimation of range queries with significantly lower time and memory costs, as well as in a differentiable form. As the prediction process of this approach is differentiable, we can incorporate queries with larger model estimation errors into the training process to addr
    
[^85]: 频率-严重性建模的符合性预测

    Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])

    [http://arxiv.org/abs/2307.13124](http://arxiv.org/abs/2307.13124)

    这个论文提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，扩展了split conformal prediction技术到两阶段频率-严重性建模领域，并通过使用随机森林作为严重性模型，利用了袋外机制消除了校准集的需要，并实现了具有自适应宽度的预测区间的生成。

    

    我们提出了一个非参数的模型无关框架，用于建立保险理赔的预测区间，并具有有限样本的统计保证，将分割符合性预测技术扩展到两阶段频率-严重性建模领域。通过模拟和真实数据集展示了该框架的有效性。当基础严重性模型是随机森林时，我们扩展了两阶段分割符合性预测过程，展示了如何利用袋外机制消除校准集的需要，并实现具有自适应宽度的预测区间的生成。

    We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
    
[^86]: 一种用于具有缺失值的整体生存分析的深度学习方法

    A Deep Learning Approach for Overall Survival Analysis with Missing Values. (arXiv:2307.11465v1 [cs.LG])

    [http://arxiv.org/abs/2307.11465](http://arxiv.org/abs/2307.11465)

    提出了一个深度学习模型，通过有效利用被审查和未被审查病人的信息，预测非小细胞肺癌（NSCLC）病人的整体生存。

    

    人工智能可以应用于肺癌研究，尤其是非小细胞肺癌（NSCLC），这是一个具有挑战性的领域。对于病人状态的整体生存（OS）是一个重要指标，可以帮助识别生存概率不同的亚组，从而实现个体化治疗和改善整体生存率。在这个分析中，需要考虑两个挑战。首先，很少有研究能够有效利用每个病人的可用信息，利用未被审查的（即死亡）和被审查的（即幸存者）病人的信息，也要考虑到死亡时间。其次，不完整数据处理是医学领域常见的问题。这个问题通常通过使用插补方法来解决。我们的目标是提出一个能够克服这些限制的人工智能模型，能够从被审查和未被审查的病人及其可用特征中有效学习，预测NSCLC病人的OS。

    One of the most challenging fields where Artificial Intelligence (AI) can be applied is lung cancer research, specifically non-small cell lung cancer (NSCLC). In particular, overall survival (OS) is a vital indicator of patient status, helping to identify subgroups with diverse survival probabilities, enabling tailored treatment and improved OS rates. In this analysis, there are two challenges to take into account. First, few studies effectively exploit the information available from each patient, leveraging both uncensored (i.e., dead) and censored (i.e., survivors) patients, considering also the death times. Second, the handling of incomplete data is a common issue in the medical field. This problem is typically tackled through the use of imputation methods. Our objective is to present an AI model able to overcome these limits, effectively learning from both censored and uncensored patients and their available features, for the prediction of OS for NSCLC patients. We present a novel 
    
[^87]: 创建一个支持OpenMP Fortran和C++代码相互翻译的数据集

    Creating a Dataset Supporting Translation Between OpenMP Fortran and C++ Code. (arXiv:2307.07686v1 [cs.SE])

    [http://arxiv.org/abs/2307.07686](http://arxiv.org/abs/2307.07686)

    本研究创建了一个数据集，用于训练机器学习模型在OpenMP Fortran和C++代码之间进行翻译。这个数据集通过精细的代码相似性测试确保了可靠性和适用性，并且能够显著提升大规模语言模型的翻译能力。

    

    在本研究中，我们提出了一个新颖的数据集，用于训练在OpenMP Fortran和C++代码之间进行翻译的机器学习模型。通过精细的代码相似性测试，我们确保了数据集的可靠性和适用性。我们使用定量（CodeBLEU）和定性（人工评估）方法评估了我们数据集的有效性。我们展示了这个数据集如何显著提高大规模语言模型的翻译能力，对于没有先前编码知识的模型，提高了5.1倍，对于具有一定编码熟悉度的模型，提高了9.9倍。我们的工作突显了这个数据集在高性能计算的代码翻译领域的潜力。

    In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is initially refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We demonstrate how this dataset can significantly improve the translation capabilities of large-scale language models, with improvements of \times 5.1 for models with no prior coding knowledge and \times 9.9 for models with some coding familiarity. Our work highlights the potential of this dataset to advance the field of code translation for high-performance computing.
    
[^88]: 基于动态特征的深度强化学习在稀疏表面压力传感器下的循环气缸流控制中的应用

    Dynamic Feature-based Deep Reinforcement Learning for Flow Control of Circular Cylinder with Sparse Surface Pressure Sensing. (arXiv:2307.01995v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.01995](http://arxiv.org/abs/2307.01995)

    本研究提出了一种基于动态特征的深度强化学习算法，针对稀疏表面压力传感器下的循环气缸流控制，实现了降低阻力和减小升力波动的目标。通过将传感器信号提取为动态特征，该算法能够自动学习并预测未来的流动状态，从而使得控制性能能够在不降低的情况下使用稀疏传感器感知流动。该方法在阻力系数和升力系数的改善上取得了显著的成果。

    

    本研究提出了一种自学习算法，针对稀疏传感器信息的封闭环气缸尾流控制，以降低阻力和减小升力的波动。该方法采用深度强化学习作为起始点，并通过将传感器信号提取为动态特征（DF）来显著提高DRL性能，从而预测未来的流动状态。由此得到的基于动态特征的深度强化学习（DF-DRL）在没有动态模型的情况下自动学习了一个在系统中的反馈控制。结果表明，相比直接传感器反馈的基准模型，DF-DRL模型的阻力系数减小了25%。更重要的是，仅使用一个表面压力传感器，DF-DRL可以将阻力系数降低到Re = 100时约8%的最先进性能，并且显著减轻了升力系数的波动。因此，DF-DRL允许在不降低控制性能的情况下部署稀疏传感器对流动进行感知。此方法还展示了良好的鲁棒性。

    This study proposes a self-learning algorithm for closed-loop cylinder wake control targeting lower drag and lower lift fluctuations with the additional challenge of sparse sensor information, taking deep reinforcement learning as the starting point. DRL performance is significantly improved by lifting the sensor signals to dynamic features (DF), which predict future flow states. The resulting dynamic feature-based DRL (DF-DRL) automatically learns a feedback control in the plant without a dynamic model. Results show that the drag coefficient of the DF-DRL model is 25% less than the vanilla model based on direct sensor feedback. More importantly, using only one surface pressure sensor, DF-DRL can reduce the drag coefficient to a state-of-the-art performance of about 8% at Re = 100 and significantly mitigate lift coefficient fluctuations. Hence, DF-DRL allows the deployment of sparse sensing of the flow without degrading the control performance. This method also shows good robustness in
    
[^89]: 一种用于可控合成解剖学虚拟人群的条件流变分自编码器

    A Conditional Flow Variational Autoencoder for Controllable Synthesis of Virtual Populations of Anatomy. (arXiv:2306.14680v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2306.14680](http://arxiv.org/abs/2306.14680)

    这篇论文提出了一种使用条件流变分自编码器来可控合成解剖学虚拟人群的方法，通过使用相关协变量，可以根据特定的目标人群/特征合成虚拟人群，具有较高的灵活性和复杂性。

    

    虚拟人群的生成对于进行医疗设备的计算机模拟试验至关重要。通常，生成的虚拟人群应该捕捉到足够的变异性，同时保持可信度，并反映真实人群中观察到的患者的特定特征和人口统计学特征。在一些应用中，希望以“可控”的方式合成虚拟人群，即使用相关协变量以条件合成虚拟人群，以适应特定的目标人群/特征。我们提出将条件变分自编码器(cVAE)与正则化流相结合，增强了学习到的近似后验的灵活性和复杂性，从而提高合成解剖结构虚拟人群的可控性。我们使用从2360名患者中获取的心脏左室数据集和相关的人口统计信息来展示我们的条件流变分自编码器的性能。

    The generation of virtual populations (VPs) of anatomy is essential for conducting in silico trials of medical devices. Typically, the generated VP should capture sufficient variability while remaining plausible and should reflect the specific characteristics and demographics of the patients observed in real populations. In several applications, it is desirable to synthesise virtual populations in a \textit{controlled} manner, where relevant covariates are used to conditionally synthesise virtual populations that fit a specific target population/characteristics. We propose to equip a conditional variational autoencoder (cVAE) with normalising flows to boost the flexibility and complexity of the approximate posterior learnt, leading to enhanced flexibility for controllable synthesis of VPs of anatomical structures. We demonstrate the performance of our conditional flow VAE using a data set of cardiac left ventricles acquired from 2360 patients, with associated demographic information an
    
[^90]: 在因子图中自动进行模型比较

    Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])

    [http://arxiv.org/abs/2306.05965](http://arxiv.org/abs/2306.05965)

    本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。

    

    在文献中，贝叶斯状态和参数估计已经被有效自动化，但对于模型比较尚未如此，因此仍需要容易出错和耗时的手动推导。因此，模型比较经常被忽视和忽略，尽管它很重要。本文通过在Forney样式的因子图上使用自定义混合节点上的消息传递来高效地自动化贝叶斯模型平均、选择和组合。进而可使用缩放因子同时执行参数和状态推断以及模型比较。这种方法缩短了模型设计周期，同时允许简单地扩展到分层和时间模型先验，以适应建模复杂的时变过程。

    Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
    
[^91]: SACSoN：面向社交导航的可扩展自主数据收集系统

    SACSoN: Scalable Autonomous Data Collection for Social Navigation. (arXiv:2306.01874v1 [cs.RO])

    [http://arxiv.org/abs/2306.01874](http://arxiv.org/abs/2306.01874)

    本文介绍了一个名为SACSoN的自主导航机器人系统，可以在人类占用的现实场景中，通过视觉理解和学习，自主收集数据，实现更好的数据集拓展。

    

    机器学习为构建符合社交规范的机器人系统提供了一个强大的工具，超越了对人类行为的简单预测模型。通过观察和理解过去经验中的人类交互，学习可以直接从数据中实现有效的社交导航行为。然而，在人类占用的环境中收集导航数据可能需要远程操作或持续监视，使得这个过程难以扩展。在本文中，我们提出了一个面向视觉导航的可扩展数据收集系统SACSoN，可以自主导航于挑战性的现实环境中的行人周围，并鼓励丰富的交互。SACSoN使用视觉观察来观察和回应其附近的人类。它将这种视觉理解与持续的学习和自主碰撞恢复系统相结合，从而限制了人操作员的参与，从而更好地扩展了数据集。我们使用这个系统来收集数据集

    Machine learning provides a powerful tool for building socially compliant robotic systems that go beyond simple predictive models of human behavior. By observing and understanding human interactions from past experiences, learning can enable effective social navigation behaviors directly from data. However, collecting navigation data in human-occupied environments may require teleoperation or continuous monitoring, making the process prohibitively expensive to scale. In this paper, we present a scalable data collection system for vision-based navigation, SACSoN, that can autonomously navigate around pedestrians in challenging real-world environments while encouraging rich interactions. SACSoN uses visual observations to observe and react to humans in its vicinity. It couples this visual understanding with continual learning and an autonomous collision recovery system that limits the involvement of a human operator, allowing for better dataset scaling. We use a this system to collect th
    
[^92]: FACT: 联邦敌对交叉训练

    FACT: Federated Adversarial Cross Training. (arXiv:2306.00607v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.00607](http://arxiv.org/abs/2306.00607)

    FACT是一种联邦敌对交叉训练算法，利用源客户端之间的隐式领域差异来识别目标领域的领域转移。实验证明，FACT在多源单目标基准上优于其他模型，并且优于无监督领域适应模型。

    

    联邦学习（FL）可以促进分布式模型开发，以聚合多个机密数据源。客户之间的信息传输可能受到分布差异的影响，即非独立同分布的数据。一个特别具有挑战性的情景是将联邦模型适应到目标客户端，而该客户端无法访问带注释的数据。我们提出了联邦敌对交叉训练（FACT），利用源客户端之间的隐式领域差异来识别目标领域的领域转移。在FL的每一轮中，FACT交叉初始化一对源客户端，生成专用于领域的表示，然后将其用作直接对手来学习领域不变的数据表示。我们通过实验证明，FACT在三个流行的多源单目标基准上优于最先进的联邦、非联邦和无源领域适应模型，并且优于最先进的无监督领域适应模型。

    Federated Learning (FL) facilitates distributed model development to aggregate multiple confidential data sources. The information transfer among clients can be compromised by distributional differences, i.e., by non-i.i.d. data. A particularly challenging scenario is the federated model adaptation to a target client without access to annotated data. We propose Federated Adversarial Cross Training (FACT), which uses the implicit domain differences between source clients to identify domain shifts in the target domain. In each round of FL, FACT cross initializes a pair of source clients to generate domain specialized representations which are then used as a direct adversary to learn a domain invariant data representation. We empirically show that FACT outperforms state-of-the-art federated, non-federated and source-free domain adaptation models on three popular multi-source-single-target benchmarks, and state-of-the-art Unsupervised Domain Adaptation (UDA) models on single-source-single-
    
[^93]: 探索抱抱脸ML模型的碳足迹：一项存储库挖掘研究

    Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study. (arXiv:2305.11164v1 [cs.LG])

    [http://arxiv.org/abs/2305.11164](http://arxiv.org/abs/2305.11164)

    本论文通过分析Hugging Face上1,417个ML模型及相关数据集的碳足迹测量情况，提出了有关如何报告和优化ML模型的碳效率的见解和建议。

    

    机器学习(ML)系统的崛起加剧了它们的碳足迹，这是由于其增加的能力和模型大小所致。然而，目前对ML模型的碳足迹如何实际测量、报告和评估的认识相对较少。因此，本论文旨在分析在Hugging Face上1,417个ML模型和相关数据集的碳足迹测量情况，Hugging Face是最受欢迎的预训练ML模型的存储库。目标是提供有关如何报告和优化ML模型的碳效率的见解和建议。该研究包括Hugging Face Hub API上有关碳排放的第一项存储库挖掘研究。本研究旨在回答两个研究问题：(1) ML模型的创建者如何在Hugging Face Hub上测量和报告碳排放？(2) 哪些方面影响了训练ML模型的碳排放？该研究得出了几个关键发现。其中包括碳排放报告模式比例的逐步下降等。

    The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting mode
    
[^94]: 图神经网络和三维拓扑

    Graph Neural Networks and 3-Dimensional Topology. (arXiv:2305.05966v1 [math.GT])

    [http://arxiv.org/abs/2305.05966](http://arxiv.org/abs/2305.05966)

    本研究利用图神经网络解决了一类由管道图描述的三维流形分类问题，并训练了一个高准确性的GNN模型，同时介绍了GNN在增强学习中的应用。

    

    本论文在某些简单情境中测试了将几何深度学习应用到低维拓扑问题的有效性。具体来说，我们考虑由管道图描述的三维流形类别，并使用图神经网络（GNN）解决判断一对图是否提供同胚三维流形问题。我们使用监督学习训练GNN，以高准确性提供这种问题的答案。此外，如果答案为肯定，我们考虑通过GNN进行增强学习，找到将一对图相关联的Neumann移动序列。这个情境可以作为解决一对Kirby图是否提供同构三维或四维流形问题的玩具模型理解。

    We test the efficiency of applying Geometric Deep Learning to the problems in low-dimensional topology in a certain simple setting. Specifically, we consider the class of 3-manifolds described by plumbing graphs and use Graph Neural Networks (GNN) for the problem of deciding whether a pair of graphs give homeomorphic 3-manifolds. We use supervised learning to train a GNN that provides the answer to such a question with high accuracy. Moreover, we consider reinforcement learning by a GNN to find a sequence of Neumann moves that relates the pair of graphs if the answer is positive. The setting can be understood as a toy model of the problem of deciding whether a pair of Kirby diagrams give diffeomorphic 3- or 4-manifolds.
    
[^95]: 无遗憾的约束贝叶斯优化方法用于带有噪声和昂贵混合模型的差分分位数函数逼近

    No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models using Differentiable Quantile Function Approximations. (arXiv:2305.03824v1 [stat.ML])

    [http://arxiv.org/abs/2305.03824](http://arxiv.org/abs/2305.03824)

    本文提出了一种新颖的算法，CUQB，来解决复合函数（混合模型）的高效约束全局优化问题，并取得了良好的效果，在合成和真实的应用程序中均得到了验证，包括进行了最优控制的流体流量和拓扑结构优化，后者比当前最先进的设计强2倍。

    

    本文研究了复合函数（混合模型）的高效约束全局优化问题，该模型的输入是具有矢量值输出和有噪声观测的昂贵黑盒函数，这在实际的科学、工程、制造和控制应用中经常出现。我们提出了一种新颖的算法Constrained Upper Quantile Bound（CUQB），用于解决这种问题，直接利用了我们展示的目标和约束函数的复合结构，从而大大提高了采样效率。CUQB的概念简单，避免了先前方法所使用的约束逼近。虽然CUQB的收购函数不在封闭形式中，但我们提出了一种新颖的可微随机逼近，使其能够有效地最大化。我们进一步得出了对于累积遗憾和约束违规的界限。由于在某些规则假设下这些界限对迭代次数具有次线性依赖性，因此我们的算法在渐近意义下无遗憾并满足约束条件。我们在几个合成和真实的应用程序中展示了CUQB的功效，包括桥架拓扑 - 在其中，我们发现的结构比当前最先进的设计强2倍 - 以及流体流量的最优控制，其中我们使用的方法比以前的方法少了3倍的模拟。

    This paper investigates the problem of efficient constrained global optimization of composite functions (hybrid models) whose input is an expensive black-box function with vector-valued outputs and noisy observations, which often arises in real-world science, engineering, manufacturing, and control applications. We propose a novel algorithm, Constrained Upper Quantile Bound (CUQB), to solve such problems that directly exploits the composite structure of the objective and constraint functions that we show leads substantially improved sampling efficiency. CUQB is conceptually simple and avoids the constraint approximations used by previous methods. Although the CUQB acquisition function is not available in closed form, we propose a novel differentiable stochastic approximation that enables it to be efficiently maximized. We further derive bounds on the cumulative regret and constraint violation. Since these bounds depend sublinearly on the number of iterations under some regularity assum
    
[^96]: 不充分标注下的多领域学习

    Multi-Domain Learning From Insufficient Annotations. (arXiv:2305.02757v1 [cs.LG])

    [http://arxiv.org/abs/2305.02757](http://arxiv.org/abs/2305.02757)

    提出了一种名为多领域对比学习（MDCL）的新方法，在原有方法的基础上，利用来自标记和未标记数据的语义和结构信息，解决了不充分注释的问题，并在实验中取得了优异的成果。

    

    多领域学习(MDL)指同时在来自不同领域的数据集上构建一个模型或一组模型。传统方法强调域共享信息的提取和域私有信息的保留，遵循共享-私有架构(SP模型)，这比单领域学习具有明显优势。然而，在每个领域中有限的已注释数据的可用性，严重阻碍了传统监督MDL方法在实际应用中的有效性。本文介绍了一种称为多领域对比学习(MDCL)的新方法，通过捕获来自标记和未标记数据的语义和结构信息，缓解了不充分注释的影响。具体而言，MDCL包括两个模块：域间语义对齐和域内对比。前者旨在将不同领域中相同语义类别的已标注实例在共享的隐空间中对齐，而后者旨在在每个领域内最大化分离来自不同类别的实例。我们在三个多领域学习任务上进行实验，包括图像分类、情感分析和假新闻检测，结果表明我们提出的MDCL方法在各种注释方案下优于现有的最先进MDL方法。

    Multi-domain learning (MDL) refers to simultaneously constructing a model or a set of models on datasets collected from different domains. Conventional approaches emphasize domain-shared information extraction and domain-private information preservation, following the shared-private framework (SP models), which offers significant advantages over single-domain learning. However, the limited availability of annotated data in each domain considerably hinders the effectiveness of conventional supervised MDL approaches in real-world applications. In this paper, we introduce a novel method called multi-domain contrastive learning (MDCL) to alleviate the impact of insufficient annotations by capturing both semantic and structural information from both labeled and unlabeled data.Specifically, MDCL comprises two modules: inter-domain semantic alignment and intra-domain contrast. The former aims to align annotated instances of the same semantic category from distinct domains within a shared hidd
    
[^97]: 从限制性反馈中提高模型性能

    Earning Extra Performance from Restrictive Feedbacks. (arXiv:2304.14831v1 [cs.LG])

    [http://arxiv.org/abs/2304.14831](http://arxiv.org/abs/2304.14831)

    本文提出了一个名为EXPECTED的挑战，解决模型调整问题，模型提供者可以通过来自本地用户的反馈多次访问候选模型的操作性能，从而优化模型，同时不需要依赖目标数据。

    

    许多机器学习应用程序面临这样一种情况：模型提供者需要进一步改进先前训练的模型以满足本地用户的特定需求。如果可以将目标数据传递给模型，那么这个问题就转化为标准的模型调整范例。然而，在许多实际应用中，目标数据并不共享给模型提供者，而只是一些关于模型的评估可供访问。本文提出了一个名为EXPECTED（Earning eXtra PerformancE from restriCTive feEDdbacks）的挑战，正式描述了这种形式的模型调整问题，允许模型提供者通过来自本地用户（或一组用户）的反馈多次访问候选模型的操作性能。模型提供者的目标是通过利用反馈最终向本地用户提供令人满意的模型。与现有的模型调整方法不同，EXPECTED在不依赖于目标数据的情况下实现了模型优化。

    Many machine learning applications encounter a situation where model providers are required to further refine the previously trained model so as to gratify the specific need of local users. This problem is reduced to the standard model tuning paradigm if the target data is permissibly fed to the model. However, it is rather difficult in a wide range of practical cases where target data is not shared with model providers but commonly some evaluations about the model are accessible. In this paper, we formally set up a challenge named \emph{Earning eXtra PerformancE from restriCTive feEDdbacks} (EXPECTED) to describe this form of model tuning problems. Concretely, EXPECTED admits a model provider to access the operational performance of the candidate model multiple times via feedback from a local user (or a group of users). The goal of the model provider is to eventually deliver a satisfactory model to the local user(s) by utilizing the feedbacks. Unlike existing model tuning methods wher
    
[^98]: VISAR：一种带有可视化编程和快速草案原型的人工智能论证写作助手

    VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])

    [http://arxiv.org/abs/2304.07810](http://arxiv.org/abs/2304.07810)

    VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。

    

    在辩论写作中，作者必须构思分层写作目标，确保其论点的说服力，并通过起草来修订和组织他们的计划。最近大型语言模型（LLM）的进展使得通过聊天界面进行交互式文本生成（例如ChatGPT）成为可能。然而，这种方法常常忽略了隐含的写作上下文和用户意图，缺乏用户控制和自主权，并且提供有限的帮助来进行意义构建和修订写作计划。为了应对这些挑战，我们引入了VISAR，一种AI支持的写作助手系统，旨在帮助作者在其写作上下文中构思和修订分层目标，通过同步文本编辑和可视化编程组织论证结构，并通过论证火花推荐增强说服力。VISAR允许用户使用自动草案原型探索、实验和验证他们的写作计划。一个受控实验室研究证实，VISAR可以通过客观和主观评估，有效地改善用户的写作体验和结果。

    In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confi
    
[^99]: 无监督的基于ANN的均衡器及其训练可编程门阵列实现

    Unsupervised ANN-Based Equalizer and Its Trainable FPGA Implementation. (arXiv:2304.06987v1 [eess.SP])

    [http://arxiv.org/abs/2304.06987](http://arxiv.org/abs/2304.06987)

    本文提出了一种无监督基于ANN的均衡器及其可训练的FPGA实现，通过自定义的损失函数使其能够适应不同的信道条件，并实现了高效率的通信系统。

    

    近年来，通信工程师强调基于人工神经网络（ANN）的算法，以提高系统及其组件的灵活性和自主性。在这个背景下，无监督训练具有特殊的意义，因为它可以在不传输导频符号的情况下进行自适应。本文介绍一种新颖的基于ANN的无监督均衡器及其可训练的现场可编程门阵列（FPGA）实现。我们证明了自定义的损失函数可以让ANN适应不同的信道条件，接近监督基线的性能。此外，为了实现实际的通信系统，我们设计了一个高效的FPGA实现，其吞吐量达到Gbit/s级别，远远超出高性能GPU的效率。

    In recent years, communication engineers put strong emphasis on artificial neural network (ANN)-based algorithms with the aim of increasing the flexibility and autonomy of the system and its components. In this context, unsupervised training is of special interest as it enables adaptation without the overhead of transmitting pilot symbols. In this work, we present a novel ANN-based, unsupervised equalizer and its trainable field programmable gate array (FPGA) implementation. We demonstrate that our custom loss function allows the ANN to adapt for varying channel conditions, approaching the performance of a supervised baseline. Furthermore, as a first step towards a practical communication system, we design an efficient FPGA implementation of our proposed algorithm, which achieves a throughput in the order of Gbit/s, outperforming a high-performance GPU by a large margin.
    
[^100]: 适应网格细化的群体强化学习

    Swarm Reinforcement Learning For Adaptive Mesh Refinement. (arXiv:2304.00818v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2304.00818](http://arxiv.org/abs/2304.00818)

    这项研究提出了一种适应网格细化的群体强化学习方法，通过将网格建模为一组简单协作的代理，并利用消息传递网络在相邻网格元素之间传播信息，以解决传统方法在复杂模拟中的应用限制。该方法被证实可以学习可靠、可扩展的网格细化策略。

    

    有限元方法是工程学中一种重要的技术，自适应网格细化（AMR）通过动态细化网格区域，在计算速度和模拟精度之间取得有利的平衡。传统的AMR方法依赖于特定任务的启发式规则或昂贵的误差估计器，限制了其在复杂模拟中的应用。最近的学习型AMR方法试图解决这些问题，但目前只能应用于简单的示例。我们将AMR表述为一种新颖的自适应群体马尔可夫决策过程，其中网格被建模为一组简单协作的代理，可以分裂为多个新代理。这个框架可以使用空间奖励公式化简分配问题，并结合消息传递网络在相邻网格元素之间传播信息。我们通过实验证明了我们的方法——自适应群体网格细化（ASMR）的有效性，显示它可以学习可靠、可扩展的网格细化策略。

    The Finite Element Method, an important technique in engineering, is aided by Adaptive Mesh Refinement (AMR), which dynamically refines mesh regions to allow for a favorable trade-off between computational speed and simulation accuracy. Classical methods for AMR depend on task-specific heuristics or expensive error estimators, hindering their use for complex simulations. Recent learned AMR methods tackle these problems, but so far scale only to simple toy examples. We formulate AMR as a novel Adaptive Swarm Markov Decision Process in which a mesh is modeled as a system of simple collaborating agents that may split into multiple new agents. This framework allows for a spatial reward formulation that simplifies the credit assignment problem, which we combine with Message Passing Networks to propagate information between neighboring mesh elements. We experimentally validate the effectiveness of our approach, Adaptive Swarm Mesh Refinement (ASMR), showing that it learns reliable, scalable,
    
[^101]: 在临床计算机断层扫描成像中优化卷积神经网络用于慢性阻塞性肺疾病检测

    Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging. (arXiv:2303.07189v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2303.07189](http://arxiv.org/abs/2303.07189)

    本文旨在通过探索手动调整和自动化窗口设置优化，利用卷积神经网络在临床计算机断层扫描图像中检测慢性阻塞性肺疾病。研究结果表明，通过添加自定义层实现的自动化窗口设置优化可以改善检测性能。

    

    目的：通过探索手动调整和自动化窗口设置优化，利用卷积神经网络（CNN）在肺部计算机断层扫描（CT）图像中检测慢性阻塞性肺疾病（COPD）的存在，来优化二进制COPD的检测。方法：回顾性选择了78名受试者（43名COPD患者；35名健康对照组）的7,194个CT图像（3,597个COPD；3,597个健康对照组）（2018年10月至2019年12月）。对每个图像，将强度值手动裁剪到肺气肿窗口设置和基准的“全范围”窗口设置。类平衡的训练、验证和测试集包含了3,392、1,114和2,688个图像。通过比较不同的CNN架构来优化网络主干。此外，还通过向模型添加自定义层来实现自动化的窗口设置优化。根据受试者工作特征曲线（ROC）下面积（AUC）的图像水平，计算出P值来评估性能。

    Purpose: To optimize the binary detection of Chronic Obstructive Pulmonary Disease (COPD) based on emphysema presence in the lung with convolutional neural networks (CNN) by exploring manually adjusted versus automated window-setting optimization (WSO) on computed tomography (CT) images.  Methods: 7,194 CT images (3,597 with COPD; 3,597 healthy controls) from 78 subjects (43 with COPD; 35 healthy controls) were selected retrospectively (10.2018-12.2019) and preprocessed. For each image, intensity values were manually clipped to the emphysema window setting and a baseline 'full-range' window setting. Class-balanced train, validation, and test sets contained 3,392, 1,114, and 2,688 images. The network backbone was optimized by comparing various CNN architectures. Furthermore, automated WSO was implemented by adding a customized layer to the model. The image-level area under the Receiver Operating Characteristics curve (AUC) [lower, upper limit 95% confidence] and P-values calculated from
    
[^102]: 无专家在线多智能体强化学习中的迁移学习

    Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning. (arXiv:2303.01170v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01170](http://arxiv.org/abs/2303.01170)

    本文提出了Expert-Free Online Transfer Learning (EF-OnTL)算法，在多智能体系统中实现无专家的实时迁移学习。通过动态选择迁移源智能体和要转移的知识，解决了传统迁移学习需要对专家智能体任务有良好理解的问题。

    

    传统上，强化学习中的迁移学习通过将知识从专家智能体转移到新手智能体来解决训练问题，如探索成本、数据可用性和收敛时间。然而，这种迁移需要新手智能体对专家智能体的任务有良好的理解才能有效。作为替代方案，本文提出了一种无专家在线动态迁移学习算法（EF-OnTL），该算法能够在多智能体系统中实现无专家的实时迁移学习。在每一次迁移步骤中，根据智能体的性能和不确定性来动态选择迁移源智能体和要转移的知识。为了提高不确定性估计，我们还提出了一种称为SARS-RND的方法，它是对RND的扩展，可以从智能体的状态、行动、奖励和下一状态中估计不确定性。

    Transfer learning in Reinforcement Learning (RL) has been widely studied to overcome training issues of Deep-RL, i.e., exploration cost, data availability and convergence time, by introducing a way to enhance training phase with external knowledge. Generally, knowledge is transferred from expert-agents to novices. While this fixes the issue for a novice agent, a good understanding of the task on expert agent is required for such transfer to be effective. As an alternative, in this paper we propose Expert-Free Online Transfer Learning (EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer learning in multi-agent system. No dedicated expert exists, and transfer source agent and knowledge to be transferred are dynamically selected at each transfer step based on agents' performance and uncertainty. To improve uncertainty estimation, we also propose State Action Reward Next-State Random Network Distillation (sars-RND), an extension of RND that estimates uncertainty from
    
[^103]: 量化和建模多模态交互：一种信息分解框架

    Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12247](http://arxiv.org/abs/2302.12247)

    通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。

    

    对于解决多模态任务所需的交互如何进行量化？最适合捕捉这些交互的多模态模型是什么？为了回答这些问题，我们提出了一种信息论方法来量化输入模态与输出任务之间的冗余度、独特性和协同性。我们将这三个衡量标准称为多模态分布（或简称PID）的PID统计量，并引入了两个新的PID统计估计器，适用于高维分布。为了验证PID估计，我们在已知PID的合成数据集和大规模多模态基准测试集上进行了大量实验。

    The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations
    
[^104]: 非稳态赌博机的定义

    A Definition of Non-Stationary Bandits. (arXiv:2302.12202v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12202](http://arxiv.org/abs/2302.12202)

    该论文提出了一个解决非稳态赌博机定义歧义的新定义，解决了之前定义中的问题并修复了代理设计中探索过度的情况。

    

    尽管非稳态赌博机学习的课题吸引了最近的很多关注，但我们还没有找到一个能够区分非稳态赌博机和稳态赌博机的形式定义。之前的研究将非稳态赌博机定义为奖励分布随时间变化的赌博机。我们证明这个定义在将同一个赌博机同时分类为稳态和非稳态时存在歧义；这种歧义源于该定义对潜在奖励分布序列的依赖。此外，这个定义也导致了两种广泛使用的遗憾概念：动态遗憾和弱遗憾。这些概念在一些赌博机中并不能准确地反映代理的性能。此外，这个非稳态赌博机的定义还导致了探索过度的代理设计。我们引入了一个解决这些问题的非稳态赌博机的形式定义。

    Despite the subject of non-stationary bandit learning having attracted much recent attention, we have yet to identify a formal definition of non-stationarity that can consistently distinguish non-stationary bandits from stationary ones. Prior work has characterized non-stationary bandits as bandits for which the reward distribution changes over time. We demonstrate that this definition can ambiguously classify the same bandit as both stationary and non-stationary; this ambiguity arises in the existing definition's dependence on the latent sequence of reward distributions. Moreover, the definition has given rise to two widely used notions of regret: the dynamic regret and the weak regret. These notions are not indicative of qualitative agent performance in some bandits. Additionally, this definition of non-stationary bandits has led to the design of agents that explore excessively. We introduce a formal definition of non-stationary bandits that resolves these issues. Our new definition 
    
[^105]: 工程设计中的多模态机器学习：综述与未来方向

    Multi-modal Machine Learning in Engineering Design: A Review and Future Directions. (arXiv:2302.10909v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10909](http://arxiv.org/abs/2302.10909)

    本文综述了工程设计领域中多模态机器学习（MMML）的当前状态、进展和挑战，重点介绍了多模态信息表示、融合、对齐、转换和共学习的基本概念，以及与工程设计相关的前沿应用。我们提出了未来研究的潜在方向，包括构建广泛的数据集和基准测试环境，以促进算法性能的评估和比较。

    

    在快速发展的多模态机器学习（MMML）领域中，多个数据模态的融合有潜力重塑各种应用。本文综述了工程设计领域中MMML的当前状态、进展和挑战。综述首先深入探讨了MMML的五个基本概念：多模态信息表示、融合、对齐、转换和共学习。随后，我们探讨了MMML的前沿应用，特别关注与工程设计相关的任务，如跨模态综合、多模态预测和跨模态信息检索。通过这个综述，我们突出了在工程设计中采用MMML所面临的固有挑战，并提出了未来研究的潜在方向。为了推动MMML在工程设计中的持续演进，我们提倡集中努力构建广泛的数据集和基准测试环境，以促进算法性能的评估和比较。

    In the rapidly advancing field of multi-modal machine learning (MMML), the convergence of multiple data modalities has the potential to reshape various applications. This paper presents a comprehensive overview of the current state, advancements, and challenges of MMML within the sphere of engineering design. The review begins with a deep dive into five fundamental concepts of MMML:multi-modal information representation, fusion, alignment, translation, and co-learning. Following this, we explore the cutting-edge applications of MMML, placing a particular emphasis on tasks pertinent to engineering design, such as cross-modal synthesis, multi-modal prediction, and cross-modal information retrieval. Through this comprehensive overview, we highlight the inherent challenges in adopting MMML in engineering design, and proffer potential directions for future research. To spur on the continued evolution of MMML in engineering design, we advocate for concentrated efforts to construct extensive 
    
[^106]: 基于深度神经网络的网络入侵检测元学习

    Deep Neural Networks based Meta-Learning for Network Intrusion Detection. (arXiv:2302.09394v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09394](http://arxiv.org/abs/2302.09394)

    本研究提出了一种基于深度神经网络的元学习框架，INFUSE，用于网络入侵检测。该框架通过整合决策空间和特征空间创建混合特征空间，并使用五个不同的分类器进行分类和预测。

    

    工业组件的数字化以及本地网络之间的互连性增加了网络攻击的风险。设计一个确保工业生态系统安全的入侵检测系统很困难，因为网络流量包含各种攻击类型，包括细微变化的新型和进化型攻击。用于构建计算机网络预测模型的数据具有偏斜的类分布和有限的攻击类型表示，这与真实的网络流量不同。这些限制导致了数据集漂移，负面影响机器学习模型的预测能力，并降低了对新型攻击的检测率。为了解决这些挑战，我们提出了一种新颖的基于深度神经网络的元学习框架；INformation FUsion and Stacking Ensemble (INFUSE)用于网络入侵检测。首先，通过整合决策空间和特征空间创建混合特征空间。然后，使用五个不同的分类器对数据进行分类和预测。

    The digitization of different components of industry and inter-connectivity among indigenous networks have increased the risk of network attacks. Designing an intrusion detection system to ensure security of the industrial ecosystem is difficult as network traffic encompasses various attack types, including new and evolving ones with minor changes. The data used to construct a predictive model for computer networks has a skewed class distribution and limited representation of attack types, which differ from real network traffic. These limitations result in dataset shift, negatively impacting the machine learning models' predictive abilities and reducing the detection rate against novel attacks. To address the challenges, we propose a novel deep neural network based Meta-Learning framework; INformation FUsion and Stacking Ensemble (INFUSE) for network intrusion detection. First, a hybrid feature space is created by integrating decision and feature spaces. Five different classifiers are 
    
[^107]: 后期情节式强化学习推断

    Post-Episodic Reinforcement Learning Inference. (arXiv:2302.08854v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08854](http://arxiv.org/abs/2302.08854)

    我们提出了一种后期情节式强化学习推断的方法，能够评估反事实的自适应策略并估计动态处理效应，通过重新加权的$Z$-估计方法稳定情节变化的估计方差。

    

    我们考虑从情节式强化学习算法收集的数据进行估计和推断；即在每个时期（也称为情节）以顺序方式与单个受试单元多次交互的自适应试验算法。我们的目标是在收集数据后能够评估反事实的自适应策略，并估计结构参数，如动态处理效应，这可以用于信用分配（例如，第一个时期的行动对最终结果的影响）。这些感兴趣的参数可以构成矩方程的解，但不是总体损失函数的最小化器，在静态数据情况下导致了$Z$-估计方法。然而，这样的估计量在自适应数据收集的情况下不能渐近正态。我们提出了一种重新加权的$Z$-估计方法，使用精心设计的自适应权重来稳定情节变化的估计方差，这是由非...

    We consider estimation and inference with data collected from episodic reinforcement learning (RL) algorithms; i.e. adaptive experimentation algorithms that at each period (aka episode) interact multiple times in a sequential manner with a single treated unit. Our goal is to be able to evaluate counterfactual adaptive policies after data collection and to estimate structural parameters such as dynamic treatment effects, which can be used for credit assignment (e.g. what was the effect of the first period action on the final outcome). Such parameters of interest can be framed as solutions to moment equations, but not minimizers of a population loss function, leading to $Z$-estimation approaches in the case of static data. However, such estimators fail to be asymptotically normal in the case of adaptive data collection. We propose a re-weighted $Z$-estimation approach with carefully designed adaptive weights to stabilize the episode-varying estimation variance, which results from the non
    
[^108]: 混合交通中使用强化学习和图神经网络进行自动化交叉口管理

    Automatic Intersection Management in Mixed Traffic Using Reinforcement Learning and Graph Neural Networks. (arXiv:2301.12717v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.12717](http://arxiv.org/abs/2301.12717)

    本研究提出了一种利用强化学习和图神经网络进行混合交通中的自动化交叉口管理的方法，该方法考虑到了人驾驶员的不确定性，并通过仿真评估进行了验证。

    

    连接的自动驾驶有潜力显著提高城市交通效率，例如通过减轻遮挡引起的问题。合作行为规划可以用于联合优化多辆车辆的运动。然而，大多数现有的自动交叉口管理方法只考虑完全自动化的交通。在实践中，混合交通，即自动驾驶和人驾驶车辆的同时道路使用，将普遍存在。本文提出利用强化学习和基于图的场景表示进行协同多智能体规划。我们建立在我们之前的研究基础上，这些研究表明这种机器学习方法适用于完全自动化的交通。场景表示扩展到混合交通，并考虑人驾驶员意图的不确定性。在基于仿真的评估中，我们通过使用实际数据调整的噪声过程模拟测量不确定性。

    Connected automated driving has the potential to significantly improve urban traffic efficiency, e.g., by alleviating issues due to occlusion. Cooperative behavior planning can be employed to jointly optimize the motion of multiple vehicles. Most existing approaches to automatic intersection management, however, only consider fully automated traffic. In practice, mixed traffic, i.e., the simultaneous road usage by automated and human-driven vehicles, will be prevalent. The present work proposes to leverage reinforcement learning and a graph-based scene representation for cooperative multi-agent planning. We build upon our previous works that showed the applicability of such machine learning methods to fully automated traffic. The scene representation is extended for mixed traffic and considers uncertainty in the human drivers' intentions. In the simulation-based evaluation, we model measurement uncertainties through noise processes that are tuned using real-world data. The paper evalua
    
[^109]: DiME：通过熵矩阵的差异最大化互信息

    DiME: Maximizing Mutual Information by a Difference of Matrix-Based Entropies. (arXiv:2301.08164v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08164](http://arxiv.org/abs/2301.08164)

    本文提出了一种称为DiME的信息理论量，可以估计随机变量之间的互信息最大化，避免了平凡解，适用于多个实际应用。

    

    我们引入了一种信息理论量，具有与相互信息类似的性质，并可从数据中估计，而不需要对潜在分布进行明确假设。该数量基于最近提出的基于矩阵的熵，该熵利用规范化 Gram 矩阵的特征值来计算再生核 Hilbert 空间中未集中协方差运算符的特征值的估计值。我们展示了一种差异矩阵熵（DiME）对于涉及随机变量之间相互信息最大化的问题非常适用。虽然许多此类任务的方法可能会导致平凡解，但 DiME 自然会对这样的结果进行惩罚。我们将 DiME 与多个相互信息基准估计器在一个玩具高斯数据集上进行比较。我们提供了 DiME 的用例示例，例如潜在因子分解和多视图表示学习问题，其中 DiME 被用于学习视图之间的共享表示，该表示具有高互信息量。

    We introduce an information-theoretic quantity with similar properties to mutual information that can be estimated from data without making explicit assumptions on the underlying distribution. This quantity is based on a recently proposed matrix-based entropy that uses the eigenvalues of a normalized Gram matrix to compute an estimate of the eigenvalues of an uncentered covariance operator in a reproducing kernel Hilbert space. We show that a difference of matrix-based entropies (DiME) is well suited for problems involving the maximization of mutual information between random variables. While many methods for such tasks can lead to trivial solutions, DiME naturally penalizes such outcomes. We compare DiME to several baseline estimators of mutual information on a toy Gaussian dataset. We provide examples of use cases for DiME, such as latent factor disentanglement and a multiview representation learning problem where DiME is used to learn a shared representation among views with high mu
    
[^110]: 从非结构化的气候报告中回答气候问卷的方法

    Towards Answering Climate Questionnaires from Unstructured Climate Reports. (arXiv:2301.04253v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.04253](http://arxiv.org/abs/2301.04253)

    本研究提出了一种从非结构化的气候报告中回答气候问卷的方法。研究引入两个新的大规模气候问卷数据集，并使用现有结构训练自监督模型，通过实验和人类试验验证了模型的有效性。同时，还引入了一个气候文本分类数据集的基准，以促进气候领域的自然语言处理研究。

    

    尽管气候变化问题紧迫，但在自然语言处理领域对其的关注有限。行动者和政策制定者需要自然语言处理工具，能够有效地将庞大且快速增长的非结构化文本气候报告转化为结构化形式。为了应对这一挑战，我们引入了两个新的大规模气候问卷数据集，并利用其现有结构来训练自监督模型。我们进行实验表明，这些模型能够学习到对训练过程中未见的不同组织类型的气候披露进行泛化。然后，我们使用这些模型在人类试验中帮助将非结构化气候文档中的文本与半结构化问卷对齐。最后，为了支持气候领域进一步的自然语言处理研究，我们引入了一个现有气候文本分类数据集的基准，以更好地评估和比较现有模型。

    The topic of Climate Change (CC) has received limited attention in NLP despite its urgency. Activists and policymakers need NLP tools to effectively process the vast and rapidly growing unstructured textual climate reports into structured form. To tackle this challenge we introduce two new large-scale climate questionnaire datasets and use their existing structure to train self-supervised models. We conduct experiments to show that these models can learn to generalize to climate disclosures of different organizations types than seen during training. We then use these models to help align texts from unstructured climate documents to the semi-structured questionnaires in a human pilot study. Finally, to support further NLP research in the climate domain we introduce a benchmark of existing climate text classification datasets to better evaluate and compare existing models.
    
[^111]: 公平预测建模的一种一致范围逼近方法

    Consistent Range Approximation for Fair Predictive Modeling. (arXiv:2212.10839v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10839](http://arxiv.org/abs/2212.10839)

    本文提出了一个新颖的框架，用于验证基于有偏数据训练的预测模型的公平性。通过一致范围逼近的方法，在目标人群上构建了可证明公平的预测模型，并在真实数据上展示了明显的改进。

    

    本文提出了一个新颖的框架，用于验证基于有偏数据训练的预测模型的公平性。它借鉴了对不完整和不一致数据库的查询回答，以形式化公平查询在目标人群上的一致范围逼近（CRA）问题。该框架利用数据收集过程和有偏数据的背景知识，可以在有限的目标人群统计数据的情况下，计算公平查询的答案范围。通过CRA，该框架构建的预测模型可以在目标人群上获得可证明的公平性，而不受训练过程中外部数据的可用性限制。通过对真实数据的评估，验证了该框架的有效性，显示出明显优于现有最先进方法的改进。

    This paper proposes a novel framework for certifying the fairness of predictive models trained on biased data. It draws from query answering for incomplete and inconsistent databases to formulate the problem of consistent range approximation (CRA) of fairness queries for a predictive model on a target population. The framework employs background knowledge of the data collection process and biased data, working with or without limited statistics about the target population, to compute a range of answers for fairness queries. Using CRA, the framework builds predictive models that are certifiably fair on the target population, regardless of the availability of external data during training. The framework's efficacy is demonstrated through evaluations on real data, showing substantial improvement over existing state-of-the-art methods.
    
[^112]: Shapley曲线：一种平滑视角

    Shapley Curves: A Smoothing Perspective. (arXiv:2211.13289v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.13289](http://arxiv.org/abs/2211.13289)

    本文以平滑的角度引入了Shapley曲线作为局部变量重要性的度量，提出了两种估计策略，并在特征的独立和依赖情况下得到了一致性和渐近正态性，为估计的Shapley曲线构建了置信区间并进行了推断，通过实验证实了渐近结果。应用中分析了哪些属性驱动车辆价格。

    

    源自合作博弈理论，Shapley值已成为应用机器学习中最广泛使用的变量重要性度量之一。然而，对Shapley值的统计理解仍然有限。本文以非参数(或平滑)的角度，引入Shapley曲线作为局部变量重要性的度量。我们提出了两种估计策略，并在特征独立和依赖的情况下都得出了一致性和渐近正态性。这样，我们可以构建置信区间并对估计的Shapley曲线进行推断。我们提出了一种新颖的野蛮引导程序版本，专门调整以获得Shapley曲线的良好有限样本覆盖。渐近结果在大量实验证实了。在实证应用中，我们分析了哪些属性驱动了车辆的价格。

    Originating from cooperative game theory, Shapley values have become one of the most widely used measures for variable importance in applied Machine Learning. However, the statistical understanding of Shapley values is still limited. In this paper, we take a nonparametric (or smoothing) perspective by introducing Shapley curves as a local measure of variable importance. We propose two estimation strategies and derive the consistency and asymptotic normality both under independence and dependence among the features. This allows us to construct confidence intervals and conduct inference on the estimated Shapley curves. We propose a novel version of the wild bootstrap procedure, specifically adjusted to give good finite sample coverage of the Shapley curves. The asymptotic results are validated in extensive experiments. In an empirical application, we analyze which attributes drive the prices of vehicles.
    
[^113]: 基于双层非线性特征向量算法的Wasserstein判别分析

    A Bi-level Nonlinear Eigenvector Algorithm for Wasserstein Discriminant Analysis. (arXiv:2211.11891v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.11891](http://arxiv.org/abs/2211.11891)

    本文提出了一种基于双层非线性特征向量算法（WDA-nepv）的Wasserstein判别分析方法，通过最大化不同类别的离散度，并最小化相同类别的离散度，充分利用WDA的双层优化结构，并在自洽场框架下高效求解。

    

    如同经典的Fisher线性判别分析（LDA），最近提出的Wasserstein判别分析（WDA）是一种线性降维方法，通过双层优化来寻求一个投影矩阵，最大化不同数据类别的离散度，并最小化相同数据类别的离散度。与LDA不同，WDA利用最优传输的基本原理，可以考虑数据类别之间的全局和局部相互关联关系。本文提出了一种基于双层非线性特征向量算法（WDA-nepv）来充分利用WDA的双层优化结构。WDA-nepv的内部层用于计算最优传输矩阵，并被构造为一个依赖于特征向量的非线性特征值问题（NEPv），同时，外部层用于追踪比率优化，并被构造为另一个NEPv问题。这两个NEPv问题可以在自洽场（SCF）框架下高效计算。WDA-nepv是可导的。

    Much like the classical Fisher linear discriminant analysis (LDA), the recently proposed Wasserstein discriminant analysis (WDA) is a linear dimensionality reduction method that seeks a projection matrix to maximize the dispersion of different data classes and minimize the dispersion of same data classes via a bi-level optimization. In contrast to LDA, WDA can account for both global and local interconnections between data classes by using the underlying principles of optimal transport. In this paper, a bi-level nonlinear eigenvector algorithm (WDA-nepv) is presented to fully exploit the structures of the bi-level optimization of WDA. The inner level of WDA-nepv for computing the optimal transport matrices is formulated as an eigenvector-dependent nonlinear eigenvalue problem (NEPv), and meanwhile, the outer level for trace ratio optimizations is formulated as another NEPv. Both NEPvs can be computed efficiently under the self-consistent field (SCF) framework. WDA-nepv is derivative-fr
    
[^114]: 资源节约的量子机器学习优化器

    Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.04965](http://arxiv.org/abs/2211.04965)

    提出了一种名为Refoqus的资源节约的量子随机梯度下降优化器，通过同时随机采样数据集和测量操作，能够保存大量资源。

    

    量子增强的数据科学，也称为量子机器学习（QML），作为近期量子计算机的应用越来越受关注。变分QML算法在涉及量子数据时有能力解决实际问题。然而，训练这些算法可能具有挑战性，并需要定制的优化程序。具体而言，QML应用可能需要大量的采样次数，因为涉及大型数据集。在这项工作中，我们提倡对数据集和定义损失函数的测量操作进行同时随机采样。我们考虑了一个高度通用的损失函数，包括了许多QML应用，并展示了如何构建其梯度的无偏估计器。这使我们能够提出一种称为Refoqus（资源节约的量子随机梯度下降优化器）的节约采样梯度下降优化器。我们的数值结果表明，Refoqus能够节省几个数量级的资源。

    Quantum-enhanced data science, also known as quantum machine learning (QML), is of growing interest as an application of near-term quantum computers. Variational QML algorithms have the potential to solve practical problems on real hardware, particularly when involving quantum data. However, training these algorithms can be challenging and calls for tailored optimization procedures. Specifically, QML applications can require a large shot-count overhead due to the large datasets involved. In this work, we advocate for simultaneous random sampling over both the dataset as well as the measurement operators that define the loss function. We consider a highly general loss function that encompasses many QML applications, and we show how to construct an unbiased estimator of its gradient. This allows us to propose a shot-frugal gradient descent optimizer called Refoqus (REsource Frugal Optimizer for QUantum Stochastic gradient descent). Our numerics indicate that Refoqus can save several orde
    
[^115]: 缓解分层注意力多尺度算子学习中的光谱偏差问题

    Mitigating spectral bias for the multiscale operator learning with hierarchical attention. (arXiv:2210.10890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10890](http://arxiv.org/abs/2210.10890)

    本文提出了一种分层注意力神经算子（HANO），用于解决多尺度偏微分方程学习中存在的光谱偏差问题，并通过数值实验证明其优于现有方法。

    

    神经算子已经成为学习偏微分方程（PDE）的无限维参数和解空间之间映射的强大工具。本文关注于具有重要应用的多尺度PDE，如油藏建模和湍流预测。我们证明对于这种PDE，对低频分量存在光谱偏差是现有神经算子的一大挑战。为了解决这个挑战，我们提出了一种受层次矩阵方法启发的分层注意力神经算子（HANO）。HANO具有自适应尺度交互范围和层次结构上的自注意力机制，能够实现可控线性成本的嵌套特征计算和多尺度解空间的编码/解码。我们还采用经验H^1损失函数来增强对高频分量的学习。我们的数值实验表明，HANO优于现有的最先进方法（SOTA）。

    Neural operators have emerged as a powerful tool for learning the mapping between infinite-dimensional parameter and solution spaces of partial differential equations (PDEs). In this work, we focus on multiscale PDEs that have important applications such as reservoir modeling and turbulence prediction. We demonstrate that for such PDEs, the spectral bias towards low-frequency components presents a significant challenge for existing neural operators. To address this challenge, we propose a hierarchical attention neural operator (HANO) inspired by the hierarchical matrix approach. HANO features a scale-adaptive interaction range and self-attentions over a hierarchy of levels, enabling nested feature computation with controllable linear cost and encoding/decoding of multiscale solution space. We also incorporate an empirical $H^1$ loss function to enhance the learning of high-frequency components. Our numerical experiments demonstrate that HANO outperforms state-of-the-art (SOTA) methods 
    
[^116]: 学习离散时间随机系统的可证明稳定神经控制器

    Learning Provably Stabilizing Neural Controllers for Discrete-Time Stochastic Systems. (arXiv:2210.05304v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05304](http://arxiv.org/abs/2210.05304)

    本文提出了一种学习离散时间随机系统中的神经控制器的方法，该方法能够以概率1在指定的稳定区域内实现系统稳定，并引入了稳定排序超级鞅(sRSMs)的概念来克服先前方法的局限性。实验结果证明了该方法的有效性。

    

    本文考虑在离散时间随机系统中学习控制策略的问题，该策略保证系统以概率1在某个指定的稳定区域内稳定。我们的方法基于我们在本文中引入的创新概念——稳定排序超级鞅(sRSMs)。我们的sRSMs克服了先前方法的局限性，这些方法仅适用于进入稳定区域后无法离开的系统。我们提出了一个学习过程，该过程学习一个控制策略和一个正式证明概率1稳定性的sRSM，两者都以神经网络的形式学习。我们还表明，该过程可以适应于在给定的Lipschitz连续控制策略下，验证随机系统以概率1在某个稳定区域内稳定。我们的实验评估表明，我们的学习过程能够成功地学习可证明稳定的神经控制器。

    We consider the problem of learning control policies in discrete-time stochastic systems which guarantee that the system stabilizes within some specified stabilization region with probability~$1$. Our approach is based on the novel notion of stabilizing ranking supermartingales (sRSMs) that we introduce in this work. Our sRSMs overcome the limitation of methods proposed in previous works whose applicability is restricted to systems in which the stabilizing region cannot be left once entered under any control policy. We present a learning procedure that learns a control policy together with an sRSM that formally certifies probability~$1$ stability, both learned as neural networks. We show that this procedure can also be adapted to formally verifying that, under a given Lipschitz continuous control policy, the stochastic system stabilizes within some stabilizing region with probability~$1$. Our experimental evaluation shows that our learning procedure can successfully learn provably stab
    
[^117]: 迈向多模态预测自发幽默：一份新颖的数据集和初步结果

    Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results. (arXiv:2209.14272v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14272](http://arxiv.org/abs/2209.14272)

    本研究提出了Passau-SFCH数据集，包含了11小时的录音，用于自发幽默的预测。通过多模态的分析和特征融合，实现了对幽默以及幽默情感的自动识别。

    

    幽默是人类情感和认知的重要元素。其自动理解可以促进更自然的人机交互和人工智能的人性化。目前的幽默检测方法仅基于策划数据，不能满足“现实世界”应用的需求。我们通过引入新颖的Passau-Spontaneous Football Coach Humour（Passau-SFCH）数据集，该数据集包含约11小时的录音，解决了这一缺陷。Passau-SFCH数据集的注释根据Martin的幽默风格问卷提出的幽默存在及其维度（情感和方向）。我们进行了一系列实验，采用预训练的Transformer、卷积神经网络和专家设计的特征。分析了自发幽默识别的每种模态（文本、音频、视频）的性能，并研究了它们之间的互补性。我们的研究结果表明，对于幽默及其情感的自动分析，多模态联合使用效果更好。

    Humour is a substantial element of human affect and cognition. Its automatic understanding can facilitate a more naturalistic human-device interaction and the humanisation of artificial intelligence. Current methods of humour detection are solely based on staged data making them inadequate for 'real-world' applications. We address this deficiency by introducing the novel Passau-Spontaneous Football Coach Humour (Passau-SFCH) dataset, comprising of about 11 hours of recordings. The Passau-SFCH dataset is annotated for the presence of humour and its dimensions (sentiment and direction) as proposed in Martin's Humor Style Questionnaire. We conduct a series of experiments, employing pretrained Transformers, convolutional neural networks, and expert-designed features. The performance of each modality (text, audio, video) for spontaneous humour recognition is analysed and their complementarity is investigated. Our findings suggest that for the automatic analysis of humour and its sentiment, 
    
[^118]: SynthA1c:针对糖尿病风险分层的临床解释型患者表示方法

    SynthA1c: Towards Clinically Interpretable Patient Representations for Diabetes Risk Stratification. (arXiv:2209.10043v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10043](http://arxiv.org/abs/2209.10043)

    该论文提出了一种名为SynthA1c的方法，利用图像数据来预测2型糖尿病风险，避免了额外的血液实验室测量，其敏感性高达87.6%。

    

    及时诊断2型糖尿病(T2DM)对于启动及时的治疗干预和生活方式改变至关重要。随着临床诊所访问时间的缩短和医学影像数据的广泛应用，可以利用患者图像数据机会性地通过医生对T2DM进行额外诊断工作。我们研究了是否可以利用图像衍生的表型数据在表格学习分类器模型中预测T2DM风险，以自动地确定高风险患者，而不需要额外的血液实验室测试。与传统的二分类器相比，我们利用神经网络和决策树模型将患者数据表示为“SynthA1c”潜在变量，这些变量模拟了血红蛋白A1c的经验实验室测量结果，其敏感性高达87.6%。为了评估SynthA1c模型在其他患者群体中的泛化能力，我们引入了一种新颖的可推广度量。

    Early diagnosis of Type 2 Diabetes Mellitus (T2DM) is crucial to enable timely therapeutic interventions and lifestyle modifications. As the time available for clinical office visits shortens and medical imaging data become more widely available, patient image data could be used to opportunistically identify patients for additional T2DM diagnostic workup by physicians. We investigated whether image-derived phenotypic data could be leveraged in tabular learning classifier models to predict T2DM risk in an automated fashion to flag high-risk patients without the need for additional blood laboratory measurements. In contrast to traditional binary classifiers, we leverage neural networks and decision tree models to represent patient data as 'SynthA1c' latent variables, which mimic blood hemoglobin A1c empirical lab measurements, that achieve sensitivities as high as 87.6%. To evaluate how SynthA1c models may generalize to other patient populations, we introduce a novel generalizable metric
    
[^119]: 基于深度学习的类型推断系统的跨域评估

    Cross-Domain Evaluation of a Deep Learning-Based Type Inference System. (arXiv:2208.09189v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2208.09189](http://arxiv.org/abs/2208.09189)

    本文研究了基于深度学习的类型推断系统Type4Py的跨领域泛化能力，并通过广泛的实验表明，Type4Py在应用于不同领域的类型推断时能够提供优异的性能。

    

    可选类型注释允许在动态编程语言中增加静态类型特性，例如更好的集成开发环境（IDE）支持、更精确的程序分析以及类型相关的运行时错误的早期检测和预防。基于机器学习的类型推断为自动化此任务提供了有趣的结果。然而，这些系统的实际使用取决于它们跨不同领域的泛化能力，因为它们经常被应用于训练领域之外。本文通过进行广泛的跨领域实验，将Type4Py作为最先进的基于深度学习的类型推断系统的代表进行了研究。我们解决以下问题：类不平衡、词汇表外单词、数据集转移和未知类。为了进行这样的实验，我们使用了ManyTypes4Py和CrossDomainTypes4Py数据集。我们在本文中介绍了后者。我们的数据集可以在更现实的情况下评估类型推断系统，在该情况下程序领域与训练集中的领域不同。我们表明，Type4Py优于基准方法，并为不同领域的类型推断提供了可伸缩的解决方案。

    Optional type annotations allow for enriching dynamic programming languages with static typing features like better Integrated Development Environment (IDE) support, more precise program analysis, and early detection and prevention of type-related runtime errors. Machine learning-based type inference promises interesting results for automating this task. However, the practical usage of such systems depends on their ability to generalize across different domains, as they are often applied outside their training domain. In this work, we investigate Type4Py as a representative of state-of-the-art deep learning-based type inference systems, by conducting extensive cross-domain experiments. Thereby, we address the following problems: class imbalances, out-of-vocabulary words, dataset shifts, and unknown classes. To perform such experiments, we use the datasets ManyTypes4Py and CrossDomainTypes4Py. The latter we introduce in this paper. Our dataset enables the evaluation of type inference sy
    
[^120]: 数据增强是一个超参数：精心筛选的自监督对于无监督异常检测的成功产生了幻象。

    Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success. (arXiv:2208.07734v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.07734](http://arxiv.org/abs/2208.07734)

    这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。

    

    自监督学习（SSL）已经成为一种有希望的替代方法，用于为现实世界的问题创建监督信号，避免了手动标注的巨大成本。对于标记异常稀缺或几乎不存在的无监督任务（如异常检测），SSL特别有吸引力。过去已经使用了大量的数据增强函数来进行基于SSL的异常检测（SSAD）的图像数据，并且最近的研究表明数据增强的类型对准确性有着重要影响。受此启发，本研究通过对三种不同检测模型和420个异常检测任务的广泛实验，提供了全面的数字和可视证据，证明数据增强与异常生成机制之间的对齐是SSAD成功的关键，而在缺乏对齐的情况下，SSL甚至可能降低准确性。据我们所知，这是关于图像型SSAD的首次深入研究。

    Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the fir
    
[^121]: 多保真度小波神经算子及其在不确定性量化中的应用

    Multi-fidelity wavelet neural operator with application to uncertainty quantification. (arXiv:2208.05606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.05606](http://arxiv.org/abs/2208.05606)

    提出了一个基于小波神经算子的多保真度学习框架，可以利用廉价的低保真度数据和昂贵的高保真度数据进行训练。该框架展示了出色的学习能力，并解决了需要有效相关性学习的问题。

    

    运算学习框架因其在两个无限维函数空间之间学习非线性映射的能力以及利用神经网络进行学习而在应用机器学习领域中最近成为一个更为重要的领域。尽管这些框架在建模复杂现象方面非常有能力，但为了成功训练，它们需要大量的数据，而这些数据通常不可用或过于昂贵。然而，使用多保真度学习可以缓解这个问题，其中模型使用大量廉价的低保真度数据和少量昂贵的高保真度数据进行训练。为此，我们开发了一个基于小波神经算子的新框架，该框架能够从多保真度数据集中进行学习。通过解决需要有效相关性学习的不同问题，我们展示了所开发模型的出色学习能力。

    Operator learning frameworks, because of their ability to learn nonlinear maps between two infinite dimensional functional spaces and utilization of neural networks in doing so, have recently emerged as one of the more pertinent areas in the field of applied machine learning. Although these frameworks are extremely capable when it comes to modeling complex phenomena, they require an extensive amount of data for successful training which is often not available or is too expensive. However, this issue can be alleviated with the use of multi-fidelity learning, where a model is trained by making use of a large amount of inexpensive low-fidelity data along with a small amount of expensive high-fidelity data. To this end, we develop a new framework based on the wavelet neural operator which is capable of learning from a multi-fidelity dataset. The developed model's excellent learning capabilities are demonstrated by solving different problems which require effective correlation learning betw
    
[^122]: 从随机已知日志中恢复轨迹

    Trace Recovery from Stochastically Known Logs. (arXiv:2206.12672v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.12672](http://arxiv.org/abs/2206.12672)

    本文提出了一种从随机已知日志中恢复轨迹的算法，在两个公开数据集上平均恢复准确度达到90-97%。这一方法通过计算流程模型和随机已知轨迹的合规性，并恢复在该随机轨迹中的最佳对齐作为真实轨迹。对比其他轨迹恢复选项，使用了产品多图来分析成本模型对恢复准确性的影响。这一算法对于预测模型开发、错误排查和系统性能改进具有重要意义。

    

    在这项工作中，我们提出了一种用于从随机已知日志中恢复轨迹的算法。随着传感器数量的增加和生成不确定数据的预测模型的增加，这种设置越来越常见。所提出的方法计算流程模型与随机已知轨迹之间的合规性，并在这个随机轨迹中恢复最佳对齐作为真实轨迹。论文对不同成本模型对轨迹恢复准确性的影响进行了分析，并利用产品多图来比较替代轨迹恢复选项。通过使用两个公开可用的数据集进行评估，我们的方法的平均准确性令人印象深刻，平均恢复准确度达到90-97%，显著改善了常见的启发式算法，该算法选择每个不确定活动的最可能值。我们相信，所提出的算法在从随机已知日志中恢复正确轨迹方面的有效性可能是开发预测模型、错误排查和改进系统性能的有力帮助。

    In this work we propose an algorithm for trace recovery from stochastically known logs, a setting that is becoming more common with the increasing number of sensors and predictive models that generate uncertain data. The suggested approach calculates the conformance between a process model and a stochastically known trace and recovers the best alignment within this stochastic trace as the true trace. The paper offers an analysis of the impact of various cost models on trace recovery accuracy and makes use of a product multi-graph to compare alternative trace recovery options. The average accuracy of our approach, evaluated using two publicly available datasets, is impressive, with an average recovery accuracy score of 90-97%, significantly improving a common heuristic that chooses the most likely value for each uncertain activity. We believe that the effectiveness of the proposed algorithm in recovering correct traces from stochastically known logs may be a powerful aid for developing 
    
[^123]: 安全可靠的对抗生成模仿学习

    Fail-Safe Adversarial Generative Imitation Learning. (arXiv:2203.01696v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01696](http://arxiv.org/abs/2203.01696)

    提出了一种灵活而安全的模仿学习方法，包括一个安全层，使得生成连续策略的概率密度/梯度成为闭合形式，提供了端到端的生成对抗训练和最坏情况下的安全保证。采用对抗可达性分析和利普希茨连续性等方法，通过推断行动邻域的安全性来确定一组安全行动。在实际驾驶员交互数据的实验中，展示了该方法的可行性和鲁棒性优势。

    

    为了实现灵活而安全的模仿学习（IL），我们提出了一种理论和模块化方法，其中包括一个安全层，该层能够使安全生成连续策略的概率密度/梯度成为闭合形式，并提供端到端的生成对抗训练和最坏情况下的安全保证。安全层将所有行动映射到一组安全行动，并使用变量转换公式和度量的可加性来计算密度。通过对回退操作的对抗可达性分析，我们首先检查有限样本的行动安全性，然后通过利普希茨连续性等方法来推断这些行动邻域的安全性。我们提供了理论分析，表明与仅在测试时使用安全层（最多二次误差）相比，在训练过程中使用安全层的鲁棒性优势（模仿误差与时间序列线性相关）。在实际驾驶员交互数据的实验中，我们经验性地证明了该方法的可行性。

    For flexible yet safe imitation learning (IL), we propose theory and a modular method, with a safety layer that enables a closed-form probability density/gradient of the safe generative continuous policy, end-to-end generative adversarial training, and worst-case safety guarantees. The safety layer maps all actions into a set of safe actions, and uses the change-of-variables formula plus additivity of measures for the density. The set of safe actions is inferred by first checking safety of a finite sample of actions via adversarial reachability analysis of fallback maneuvers, and then concluding on the safety of these actions' neighborhoods using, e.g., Lipschitz continuity. We provide theoretical analysis showing the robustness advantage of using the safety layer already during training (imitation error linear in the horizon) compared to only using it at test time (up to quadratic error). In an experiment on real-world driver interaction data, we empirically demonstrate tractability, 
    
[^124]: 学习具有未知服务率的排队系统中一组离散的最优分配规则

    Learning a Discrete Set of Optimal Allocation Rules in a Queueing System with Unknown Service Rate. (arXiv:2202.02419v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2202.02419](http://arxiv.org/abs/2202.02419)

    该论文研究了在具有未知到达和服务率的排队系统中的入场控制问题。通过观察到到达时间和系统状态，我们旨在设计一种调度策略，以最大化调度员的长期平均回报。标准的强化学习方法不适用于此问题，因为调度员无法观察到服务时间和离开时间。

    

    在广泛应用于通信网络、呼叫中心以及设计生产系统、消息系统和基于应用的停车系统等现代应用领域之外的Erlang-B阻塞模型中，考虑到到达和服务率未知的情况下对该系统的入场控制进行研究。在我们的模型中，在每个作业到达时，调度员决定将作业分配给一个可用的服务器或者阻塞它。每个已服务的作业为调度员带来了固定的回报，但也导致了每单位服务时间的成本。我们的目标是设计一种调度策略，基于仅观察到到达时间和每次到达时系统状态的情况，从而最大化调度员的长期平均回报，这反映了对这种系统的现实采样。关键是，调度员既不观察服务时间也不观察离开时间，因此不能应用使用奖励信号的标准强化学习方法。因此，我们发展了我们的学习基于...

    Motivated by the wide range of modern applications of the Erlang-B blocking model beyond communication networks and call centers to sizing and pricing in design production systems, messaging systems, and app-based parking systems, we study admission control for such a system but with unknown arrival and service rates. In our model, at every job arrival, a dispatcher decides to assign the job to an available server or block it. Every served job yields a fixed reward for the dispatcher, but it also results in a cost per unit time of service. Our goal is to design a dispatching policy that maximizes the long-term average reward for the dispatcher based on observing only the arrival times and the state of the system at each arrival that reflects a realistic sampling of such systems. Critically, the dispatcher observes neither the service times nor departure times so that standard reinforcement learning-based approaches that use reward signals do not apply. Hence, we develop our learning-ba
    
[^125]: 具有非参数需求模型的公平感知在线价格歧视

    Fairness-aware Online Price Discrimination with Nonparametric Demand Models. (arXiv:2111.08221v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.08221](http://arxiv.org/abs/2111.08221)

    本论文研究了在公平性约束下的动态歧视性定价问题，针对在线零售中存在的价格歧视问题，提出了一种公平感知的解决方法，旨在在最大化收入的同时确保公平性。

    

    价格歧视是在网上零售中广泛使用的一种策略，指的是为不同的客户群体设定不同的价格。尽管它有助于提高网上零售商的收入，但可能引发关于公平性的严重担忧，甚至违反规定和法律。本文研究了在公平性约束下的动态歧视性定价问题。具体而言，我们考虑了一个有限销售周期长度为T的单一产品，有两组客户。每组客户都有其未知的需求函数需要学习。对于每个销售周期，卖家确定每组的价格并观察其购买行为。虽然现有文献主要关注最大化收入，但在动态定价文献中尚未充分探讨确保不同客户之间的公平性。本研究采用了Cohen等人（2022）的公平概念。对于价格公平性，我们提出了一种最优动态方案。

    Price discrimination, which refers to the strategy of setting different prices for different customer groups, has been widely used in online retailing. Although it helps boost the collected revenue for online retailers, it might create serious concerns about fairness, which even violates the regulation and laws. This paper studies the problem of dynamic discriminatory pricing under fairness constraints. In particular, we consider a finite selling horizon of length $T$ for a single product with two groups of customers. Each group of customers has its unknown demand function that needs to be learned. For each selling period, the seller determines the price for each group and observes their purchase behavior. While existing literature mainly focuses on maximizing revenue, ensuring fairness among different customers has not been fully explored in the dynamic pricing literature. This work adopts the fairness notion from Cohen et al. (2022). For price fairness, we propose an optimal dynamic 
    
[^126]: 动态沟通网络：COVID-19大流行期间组织内部沟通网络中的模块化增加

    Dynamic Silos: Increased Modularity in Intra-organizational Communication Networks during the Covid-19 Pandemic. (arXiv:2104.00641v6 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2104.00641](http://arxiv.org/abs/2104.00641)

    COVID-19大流行期间，世界各地的组织在沟通上变得更加孤立，模块化增加，员工开始更加灵活地进行沟通。

    

    COVID-19，相关的居家办公政策和远程工作的兴起，极大地改变了世界各地的工作场所沟通方式。为了了解这些变化，我们分析了来自全球4361个组织的3600亿封电子邮件的聚合、匿名化元数据。通过比较每月和年度的指标，我们对COVID-19之前和之后24个月内网络社群结构的变化进行了研究。我们还研究了单个全球组织内多种沟通媒体（电子邮件、即时消息、视频通话和日历软件）的变化，并将其与由于组织结构改变而推动的沟通变化进行了比较。我们发现，在2020年，世界各地的组织比2019年更加孤立，表现为增加的模块化。这一转变与模块内稳定性的降低同时发生。我们的分析共同表明，COVID-19爆发后，员工开始更加灵活地进行沟通。

    Workplace communications around the world were drastically altered by Covid-19, related work-from-home orders, and the rise of remote work. To understand these shifts, we analyzed aggregated, anonymized metadata from over 360 billion emails within 4,361 organizations worldwide. By comparing month-to-month and year-over-year metrics, we examined changes in network community structures over 24 months before and after Covid-19. We also examined shifts across multiple communication media (email, instant messages, video calls, and calendaring software) within a single global organization, and compared them to communications shifts that were driven by changes in formal organizational structure. We found that, in 2020, organizations around the world became more siloed than in 2019, evidenced by increased modularity. This shift was concurrent with decreased stability within silos. Collectively, our analyses indicate that following the onset of Covid-19, employees began to shift more dynamicall
    

