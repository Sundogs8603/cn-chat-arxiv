# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Segment Anything.](http://arxiv.org/abs/2304.02643) | 这篇论文介绍了一个新的图像分割任务、模型和数据集，该模型具有高效的分割能力和任务迁移能力，可以在新的图像分布和任务中进行零-shot 任务迁移，使其零-shot表现令人印象深刻，并发布了Segment Anything Model（SAM）和相应的数据集（SA-1B），以促进计算机视觉基础模型研究的发展。 |
| [^2] | [Self-Distillation for Gaussian Process Regression and Classification.](http://arxiv.org/abs/2304.02641) | 本文针对高斯过程回归和分类提出了数据中心方法和分布中心方法，分析后发现其与内核岭回归自我蒸馏和普通GPR对应。其中GPC的分布中心方法近似对应于数据复制和协方差的特定缩放。 |
| [^3] | [GenPhys: From Physical Processes to Generative Models.](http://arxiv.org/abs/2304.02637) | 本文介绍了一个新的生成模型家族：GenPhys，它将从物理过程中描述的偏微分方程翻译为生成模型，并探索了更广泛的生成模型设计空间。 |
| [^4] | [Mapping historical forest biomass for stock-change assessments at parcel to landscape scales.](http://arxiv.org/abs/2304.02632) | 本文介绍了一项基本步骤，即利用Landsat影像、激光雷达和FIA数据，在整个纽约州（1990年至2019年）以较高时间和空间分辨率制作历史森林生物量地图，以便实现个体和景观尺度的库存变化评估。 |
| [^5] | [High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation.](http://arxiv.org/abs/2304.02621) | 本文提出了一种使用马尔可夫随机场增强弱监督分割中的高保真伪标签生成方法，能够生成更准确的伪标签，并使用新的训练策略来实现更好的收敛。实验结果表明该方法达到了弱监督分割方法的最佳性能。 |
| [^6] | [Efficient Quantum Algorithms for Quantum Optimal Control.](http://arxiv.org/abs/2304.02613) | 本文提出了一种高效的量子算法，解决量子最优控制问题，运用容错的量子计算机，具有复杂的机器学习关系。 |
| [^7] | [Query lower bounds for log-concave sampling.](http://arxiv.org/abs/2304.02599) | 该论文研究了对数凹采样的查询下界，在强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，在采样高斯分布中需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询。 |
| [^8] | [Bayesian neural networks via MCMC: a Python-based tutorial.](http://arxiv.org/abs/2304.02595) | 本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。 |
| [^9] | [A force-sensing surgical drill for real-time force feedback in robotic mastoidectomy.](http://arxiv.org/abs/2304.02583) | 本研究介绍了一种用于机器人辅助乳突切除术的力传感器手术钻，能够通过准确测量工具-组织相互作用力实现力控制和反馈，为手术医生提供实时力反馈，提高手术安全性和成功率。 |
| [^10] | [ECG Feature Importance Rankings: Cardiologists vs. Algorithms.](http://arxiv.org/abs/2304.02577) | 该研究检验了在心脏病学领域的真实数据上的特征重要性方法，尝试区分三种特定病理。一些方法表现良好，而其他方法表现不佳。 |
| [^11] | [Conformal Off-Policy Evaluation in Markov Decision Processes.](http://arxiv.org/abs/2304.02574) | 本论文提出了一种基于合规预测的异策评估方法，能够以一定的确定性水平输出包含目标策略的真实奖励的区间，并提出了不同的处理分布偏移方法，其中一些方法在保证合规性的前提下实现了最先进的性能。 |
| [^12] | [Self-Supervised Siamese Autoencoders.](http://arxiv.org/abs/2304.02549) | 本论文提出了一种新的自监督方法，名为SidAE，它结合了孪生架构和去噪自编码器的优点，可以更好地提取输入数据的特征，以在多个下游任务中获得更好的性能。 |
| [^13] | [Multi-annotator Deep Learning: A Probabilistic Framework for Classification.](http://arxiv.org/abs/2304.02539) | 该论文提出了一个名为多注释深度学习（MaDL）的概率训练框架，可以在由易错注释者提供的有噪音类别标签上进行端到端的联合训练，并有效地解决多注释监督学习中的次优表现问题。 |
| [^14] | [Learning to Compare Longitudinal Images.](http://arxiv.org/abs/2304.02531) | 本文提出了一种名为PaIRNet的深度学习模型，用于比较带有或不带有预处理的纵向图像对，以检测生物医学应用中与研究问题相关的变化。 |
| [^15] | [Hyper-parameter Tuning for Adversarially Robust Models.](http://arxiv.org/abs/2304.02497) | 本文探究对抗训练模型的超参数调节问题，明确对抗环境下需要额外调整的超参数，并提出利用廉价对抗训练方法的新方案降低调节成本。 |
| [^16] | [Quantifying the Roles of Visual, Linguistic, and Visual-Linguistic Complexity in Verb Acquisition.](http://arxiv.org/abs/2304.02492) | 本研究探讨了早期动词学习不对称性的原因，并量化地证明，与名词相比，动词更难习得，需要整合视觉和语言信息。另外，多语言和多模式输入可以改善语言和视觉信息之间的不匹配。 |
| [^17] | [Opening the random forest black box by the analysis of the mutual impact of features.](http://arxiv.org/abs/2304.02490) | 本文提出了两种新方法， MIR和MFI，这些方法基于特征之间的相互影响，超越了传统的变量重要性度量方法，并可生成p值选择相关和重要的特征。 |
| [^18] | [A dynamic Bayesian optimized active recommender system for curiosity-driven Human-in-the-loop automated experiments.](http://arxiv.org/abs/2304.02484) | 本文开发了一种基于贝叶斯优化的积极推荐人机交互实验系统，利用人类反馈实时塑造目标，并以铁电薄膜的压电响应力谱为例展示了该框架的应用。 |
| [^19] | [Quantum Imitation Learning.](http://arxiv.org/abs/2304.02480) | 本论文提出了量子模仿学习（QIL）以加速学习，其中通过采用变分量子电路（VQC）代替DNN来表示策略，分别开发了量子行为克隆（Q-BC）和量子生成对抗模仿学习（Q-GAIL）两种QIL算法，实验表明QIL可以实现至少与其经典对应物相当的结果，并且基于VQC的策略表示优于一些现有的量子RL算法。 |
| [^20] | [Fully Variational Noise-Contrastive Estimation.](http://arxiv.org/abs/2304.02473) | 本文提出了一种全变分噪声对比估计方法，可以用于潜变量模型，其中变分自编码器是其中一个特例，可以将真实数据与合成样本分离开来。 |
| [^21] | [Short-Term Volatility Prediction Using Deep CNNs Trained on Order Flow.](http://arxiv.org/abs/2304.02472) | 本文提出了一种将市场信息编码为图像并利用卷积神经网络进行短期实现波动率预测的方法，与其他基准模型相比具有更好的表现和潜力。 |
| [^22] | [Selecting Features by their Resilience to the Curse of Dimensionality.](http://arxiv.org/abs/2304.02455) | 该研究提出了一种新的特征选择方法，通过识别能够区分不同大小数据子集的特征来降低高维数据的复杂性。实验表明，该方法具有竞争力，并通常优于其他已有的特征选择方法。此外，该方法可扩展到由数百万数据点组成的数据集。 |
| [^23] | [Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems.](http://arxiv.org/abs/2304.02441) | 本文提出了一种用于解决分布式非凸强凹极小极大结构优化问题的方法，并在这种新颖的方法下，成功解决了可以在最小化和最大化变量上都包含凸非光滑项的复合非凸强凹极小极大问题；理论证明了本算法具有高概率的次线性收敛速度。 |
| [^24] | [Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping.](http://arxiv.org/abs/2304.02407) | 本研究提出了一个用于多模态数据融合的深度学习框架，采用可解释的机器学习方法来研究模态的影响，结果显示在野区地图制作任务中，利用土地覆盖和夜间光数据能够大大提高模型准确性。 |
| [^25] | [AutoRL Hyperparameter Landscapes.](http://arxiv.org/abs/2304.02396) | 本文提出了一种方法，在训练期间多次建立和分析AutoRL超参数的景观，证明代表算法（DQN和SAC）在不同环境下的超参数景观会随时间而变化。 |
| [^26] | [DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images.](http://arxiv.org/abs/2304.02389) | DRAC是一个用于超广角光学相干断层扫描血管造影图像的糖尿病视网膜病变分析挑战。该挑战包括三个任务：DR损伤分割、图像质量评估和DR分级，分别得到了来自地理上多样化的11个、12个和13个团队的积极响应。 |
| [^27] | [How good Neural Networks interpretation methods really are? A quantitative benchmark.](http://arxiv.org/abs/2304.02383) | 本论文提出了一种定量基准测试方法来评估深度学习模型的解释方法，旨在解决对基于视觉评估方法引入的假阳性偏见的关注。通过构建具有非线性可分离类别和逐渐增加的伪特征数据集的测试，为神经网络解释方法提供了量化标准。 |
| [^28] | [Physics-Inspired Interpretability Of Machine Learning Models.](http://arxiv.org/abs/2304.02381) | 本文提出了一种以能量景观方法为启发的机器学习模型可解释性研究方法，可以识别决策的驱动因素，有助于解决机器学习模型在高度敏感领域应用的难题。 |
| [^29] | [Effective control of two-dimensional Rayleigh--B\'enard convection: invariant multi-agent reinforcement learning is all you need.](http://arxiv.org/abs/2304.02370) | 本论文应用基于不变多智能体强化学习（MARL）的深度强化学习（DRL）方法，实现了对二维瑞利-贝纳德对流的有效控制。通过利用局部性和平移不变性，MARL所获得的控制法则不仅具有较好的性能，而且具有良好的应用前景。 |
| [^30] | [Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net.](http://arxiv.org/abs/2304.02353) | 本文介绍了使用U-Net架构进行全骨髓和淋巴结照射治疗计划靶体积分割的深度学习自动轮廓方法，使精确定位成为可能。 |
| [^31] | [Correcting Flaws in Common Disentanglement Metrics.](http://arxiv.org/abs/2304.02335) | 本文提出了两个新的解缠指标，用于修正现有指标的两个缺陷，并通过将组合泛化任务作为分类问题来衡量编码器的解缠能力。新指标与组合泛化任务的相关性最强。 |
| [^32] | [Efficient CNNs via Passive Filter Pruning.](http://arxiv.org/abs/2304.02319) | 本论文提出了一种被动滤波剪枝方法来达到高效CNN的目的，解决了高剪枝率下逐元素范数方法存在的性能下降问题。 |
| [^33] | [A step towards the applicability of algorithms based on invariant causal learning on observational data.](http://arxiv.org/abs/2304.02286) | 该论文提出了一种有效的方法以解决不变学习算法在观测数据和实际应用中的问题。其中，该算法基于多环境测试，使用多个训练环境来发现因果关系，并提供有良好结果的因果预测器。 |
| [^34] | [Rethinking the Trigger-injecting Position in Graph Backdoor Attack.](http://arxiv.org/abs/2304.02277) | 论文研究了在图神经网络中的背门攻击，发现在样本的最不重要区域中注入触发器的背门攻击效果更好，对该现象进行了解释。 |
| [^35] | [Optimal Sketching Bounds for Sparse Linear Regression.](http://arxiv.org/abs/2304.02261) | 本文研究稀疏线性回归的最优草图界限，表明稀疏恢复比稀疏回归更容易草图，对于稀疏l_p回归，其上界包括l_2的额外添加项。 |
| [^36] | [Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy.](http://arxiv.org/abs/2304.02247) | 本文提出了一种通过文档层次结构诱导来检测新闻中的政治偏见的方法，该方法克服了过拟合和有限的普适性，展现了更好的鲁棒性和准确性。 |
| [^37] | [List and Certificate Complexities in Replicable Learning.](http://arxiv.org/abs/2304.02240) | 研究复制学习算法的列表和证明复杂度，提出列表复制和证书复制的概念，设计了可行的方法，并在某些学习问题上建立了最优解。 |
| [^38] | [JPEG Compressed Images Can Bypass Protections Against AI Editing.](http://arxiv.org/abs/2304.02234) | 该论文指出微小但有效的图像扰动方法并不能抵御JPEG压缩，因此不能有效保护图像免受恶意编辑和深度伪造攻击，建议采用其他方法进行保护。 |
| [^39] | [Mixed Regression via Approximate Message Passing.](http://arxiv.org/abs/2304.02229) | 本文提出了一种新的近似消息传递算法来解决在广义线性模型中的回归问题，该算法适用于混合线性回归、最大仿射回归和专家混合模型等问题。 |
| [^40] | [Local Intrinsic Dimensional Entropy.](http://arxiv.org/abs/2304.02223) | 本文提出了一种新的在连续空间中测量熵的方法，称为ID-Entropy，它可以用于多轮数据变换和扭曲，同时可以捕捉数据的维度。 |
| [^41] | [Zero-shot domain adaptation of anomalous samples for semi-supervised anomaly detection.](http://arxiv.org/abs/2304.02221) | 本论文提出了一种适用于SSAD的零样本域自适应方法，以帮助其适应目标域中缺少的异常数据，这是通过引入一个域对抗网络和基于重要性采样的加权损失函数实现的。 |
| [^42] | [On the universal approximation property of radial basis function neural networks.](http://arxiv.org/abs/2304.02220) | 本论文研究了一种新的径向基函数神经网络类别，证明这些网络能够逼近任何连续多元函数，还讨论了有限个固定中心的RBF网络的逼近条件。 |
| [^43] | [PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data.](http://arxiv.org/abs/2304.02208) | PIKS是一种可以高效准确地识别医疗保健数据中异常值的技术，通过快速发现趋势和检测异常值，为政策制定者提供重要的决策支持。 |
| [^44] | [Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models.](http://arxiv.org/abs/2304.02202) | 本文提出了一个框架，结合模板图像字幕技术和大型语言模型，实现了深度神经网络的自解释性，填补了基于热力图的可解释AI自动化、交互式、可扩展、易于访问的空白。 |
| [^45] | [EigenFold: Generative Protein Structure Prediction with Diffusion Models.](http://arxiv.org/abs/2304.02198) | EigenFold是一种生成模型，利用扩散模型从蛋白质序列中采样结构分布集合，达到了较高的TMScore并提供了更全面的模型不确定性。它能有效地建模和预测折叠转换蛋白和配体诱导构象变化。 |
| [^46] | [Building predictive models of healthcare costs with open healthcare data.](http://arxiv.org/abs/2304.02191) | 利用纽约州 SPARCS 的匿名患者数据，使用机器学习技术预测病人的医疗成本，最好表现的模型使用了决策树，获得了 0.76 的 R-square 值。 |
| [^47] | [Globalizing Fairness Attributes in Machine Learning: A Case Study on Health in Africa.](http://arxiv.org/abs/2304.02190) | 该论文以非洲卫生领域为案例研究，提出了机器学习中全球化的公正属性的体系，并应用于医疗模式，为促进全球卫生中的公平研究提供了基础和行动的呼吁。 |
| [^48] | [A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data.](http://arxiv.org/abs/2304.02189) | 提出了一种探索大数据的系统，使用搜索光标技术系统地探索多种变量组合并识别异常值，可应用于开放医疗数据分析，识别出一些医院的绩效始终低于同行，并准确地指出具体的临床状况与高于预期的发病率和死亡率有关。 |
| [^49] | [Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model.](http://arxiv.org/abs/2304.02169) | 此论文提出了一种名为HALO的方法，它是一个层级自回归模型，可以生成高保真、细粒度电子健康记录数据，而这些数据可以用于训练准确的ML模型，且无需涉及隐私问题。 |
| [^50] | [I2I: Initializing Adapters with Improvised Knowledge.](http://arxiv.org/abs/2304.02168) | 本文提出了一种称为ImprovisetoInitialize(I2I)的连续学习算法，通过提取先前学习的任务适配器的知识来为即将到来的任务初始化适配器。这使得从一个任务到另一个任务的知识传递更加高效。 |
| [^51] | [Structure Learning with Continuous Optimization: A Sober Look and Beyond.](http://arxiv.org/abs/2304.02146) | 本文探讨了连续优化在有向无环图结构学习中的优点和缺点，分析了不相等噪声方差公式中的非凸性问题，并建议未来研究将更多地考虑先验知识和已知结构，以实现更健壮的优化方法。 |
| [^52] | [Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses.](http://arxiv.org/abs/2304.02141) | 本文提出了一种线性对数时间算法，用于解决单变量学习模型在线性损失函数下得分输出的最优单峰转换问题。 |
| [^53] | [Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach.](http://arxiv.org/abs/2304.02119) | 本论文介绍一个使用最佳线性逼近(BLA)初始化子空间编码器方法的初始方法，以提高非线性状态空间识别的收敛性。 |
| [^54] | [Deep learning for diffusion in porous media.](http://arxiv.org/abs/2304.02104) | 本文研究使用深度学习来预测多孔介质的基本特性，包括孔隙率和有效扩散系数，并通过构建U-Net架构成功重构了多孔介质的几何结构和浓度分布图。 |
| [^55] | [The CAMELS project: Expanding the galaxy formation model space with new ASTRID and 28-parameter TNG and SIMBA suites.](http://arxiv.org/abs/2304.02096) | CAMELS项目扩展了星系形成的模型空间，提供了更广泛的训练和测试环境，其中最新的CAMELS-ASTRID模拟套件通过多样的模拟涵盖了不同的星系群体和重要影响, 训练集覆盖不同宇宙学参数和星系反馈参数的变化， 加深了我们对星系形成的理解并为宇宙学研究提供了基础。 |
| [^56] | [Scalable Online Learning of Approximate Stackelberg Solutions in Energy Trading Games with Demand Response Aggregators.](http://arxiv.org/abs/2304.02086) | 本文提出了一个Stackelberg博弈理论框架，用于在需求响应（DR）聚合器和中间商之间双向交易能源，解决方案可扩展，且保证满足中间商每日能源的需求。 |
| [^57] | [EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT.](http://arxiv.org/abs/2304.02084) | 该论文介绍了使用X射线CT图像揭示赫库兰尼姆纸草卷隐藏文本的软件管道和数据集。他们运用了机器学习和几何框架的方法检测“不可见”的碳墨，达到了人类专家标记者难以达到的效果。 |
| [^58] | [Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation.](http://arxiv.org/abs/2304.02064) | 通过信息论工具的使用，该论文研究了多源域自适应表示学习中的联合分布对齐，提出了算法相关的泛化界限，并提出了一种新颖的深度学习算法，解决了目标偏移问题。 |
| [^59] | [Multi-Class Explainable Unlearning for Image Classification via Weight Filtering.](http://arxiv.org/abs/2304.02049) | 本论文提出一种基于权重滤波的多类可解释性卸载图像分类方法，可以在单个未训练轮中取消学习网络的所有类别，并且恢复可解释的类别表示。 |
| [^60] | [Deep Learning for Automated Experimentation in Scanning Transmission Electron Microscopy.](http://arxiv.org/abs/2304.02048) | 本文讨论了在扫描透射电子显微镜中实现主动机器学习的挑战以及需要开发的面向显微镜工作流程设计和优化的策略。同时，需要确定人类和机器学习代理在实验工作流程的构思、编排和执行中的相对贡献，并开发可跨多个平台应用的通用超语言。 |
| [^61] | [Effective Theory of Transformers at Initialization.](http://arxiv.org/abs/2304.02034) | 本研究分析了宽且深的Transformer中的前向和后向信号传播，提出了特定的初始化和训练超参数宽度缩放建议，并在实际设置中验证了这些建议。 |
| [^62] | [Online Joint Assortment-Inventory Optimization under MNL Choices.](http://arxiv.org/abs/2304.02022) | 本文提出了一个算法解决在线联合组合库存优化问题，能够在平衡探索与开发的措施下实现最大化预期总利润，并为该算法建立了遗憾上界。 |
| [^63] | [Detecting Fake Job Postings Using Bidirectional LSTM.](http://arxiv.org/abs/2304.02019) | 本研究使用双向LSTM模型，同时考虑数字和文本特征，以较高的ROC AUC得分和准确性识别虚假职位广告，有望应用于在线招聘市场，帮助解决虚假职位广告的问题和提高求职流程的完整性。 |
| [^64] | [The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery.](http://arxiv.org/abs/2304.02016) | 本文提出一种基于图像的轻量级和专业方法，使用多个API将对象列表作为输入传递给大型语言模型(LLM)，从而生成适合于特定约束条件的新颖的菜谱卡。 |
| [^65] | [DWA: Differential Wavelet Amplifier for Image Super-Resolution.](http://arxiv.org/abs/2304.01994) | 本文介绍了一种基于小波的图像超分辨率模块DWA，通过利用两个卷积滤波器的差异改进小波SR模型，在小波域中提高相关特征提取并抑制噪声。在现有的SR模型中集成DWA，如DWSR和MWCNN，可以显示出其有效性。 |
| [^66] | [Dual-Attention Neural Transducers for Efficient Wake Word Spotting in Speech Recognition.](http://arxiv.org/abs/2304.01905) | 本文介绍了一种新的“双关注神经变换器”，可以通过优化唤醒词检测来选择计算路径，从而提高唤醒词的准确性和推理时间效率，并且计算成本可以降低90％而仅增加1％的参数。这种架构可以在语音识别领域中大有裨益。 |
| [^67] | [Sociocultural knowledge is needed for selection of shots in hate speech detection tasks.](http://arxiv.org/abs/2304.01890) | HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。 |
| [^68] | [To ChatGPT, or not to ChatGPT: That is the question!.](http://arxiv.org/abs/2304.01487) | 研究评估了聊天GPT检测中的最新技术和其他AI生成文本检测工具的表现，并提出区分人工生成和AI生成文本的重要性。 |
| [^69] | [Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach.](http://arxiv.org/abs/2304.01240) | 该研究使用机器学习技术，成功地识别出心理健康电子健康记录中的疼痛提及，提高了对疼痛和心理健康之间关系的理解。 |
| [^70] | [POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems.](http://arxiv.org/abs/2304.01218) | POLAR-Express 是一种高效且准确的形式可达性分析工具，用于验证神经网络控制系统的安全性。它使用 Taylor 模型算术和逐层传播技术，可以分析具有连续激活功能的前馈神经网络，并在 ReLU 激活函数上提供了一种更有效的精确传播 TM 的新方法。 |
| [^71] | [Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning.](http://arxiv.org/abs/2304.01203) | 本文介绍了一种新的强化学习方法——准度量强化学习（QRL），利用准度量模型来学习最优价值函数；在离线和在线的目标达成基准测试中，QRL展示了更好的采样效率和性能，包括基于状态和基于图像的观测。 |
| [^72] | [Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation.](http://arxiv.org/abs/2304.00971) | 该论文提出了一种基于Cityscapes-3D的联合2D-3D多任务学习方法，旨在同时实现单眼3D车辆检测、语义分割和单眼深度估计，并通过优化多个目标单元，提高了模型性能。 |
| [^73] | [AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models.](http://arxiv.org/abs/2304.00830) | 研究提出了基于潜在扩散模型的指令引导音频编辑模型AUDIT，实现了在各种音频编辑任务上的最先进性能，并通过自适应方案和文本到片段匹配模块解决了先前扩散-based方法存在的问题。 |
| [^74] | [Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR.](http://arxiv.org/abs/2304.00668) | 本文通过量化不同区域对目标识别的贡献和解释数据偏差和模型偏差对非因果性的影响，提供了改善深度学习在SAR ATR中鲁棒性和泛化能力的重要见解。 |
| [^75] | [Time-series Anomaly Detection based on Difference Subspace between Signal Subspaces.](http://arxiv.org/abs/2303.17802) | 本文提出了一种新的基于信号子空间差异子空间的时间序列异常检测方法，通过捕获两个子空间的完整结构差异来提高性能，在公共时间序列数据集上证明了其有效性。 |
| [^76] | [Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization.](http://arxiv.org/abs/2303.17354) | 该论文提出一种基于Transformer骨干网络的渐进式自监督学习方法，可用于图像异常检测和定位，其中第一阶段使用MAE模型进行正常图像的训练，第二阶段使用像素级数据增强技术来生成损坏的正常图像，最终通过像素重建误差矩阵和像素异常概率矩阵综合得到一个异常得分矩阵。 |
| [^77] | [HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices.](http://arxiv.org/abs/2303.17218) | 本研究提出了一种面向FPGA设备的基于延迟的3D-CNN加速器工具链HARFLOW3D，它以机器学习模型和FPGA的特性描述为输入，生成最小化计算延迟的设计。实验证明HARFLOW3D相比其他方案能够实现更低的延迟。 |
| [^78] | [PopSparse: Accelerated block sparse matrix multiplication on IPU.](http://arxiv.org/abs/2303.16999) | 将大规模神经网络的计算成本降低到可接受的任务性能和加速改进是一个具有挑战的问题。本文介绍了一种利用IPU独特的硬件特性和数据中定义的任何块结构实现在Graphcore IPUs上快速稀疏操作的库——PopSparse。 |
| [^79] | [Function Approximation with Randomly Initialized Neural Networks for Approximate Model Reference Adaptive Control.](http://arxiv.org/abs/2303.16251) | 本论文提出一种新的构造方法——平滑的积分表示，使得可以使用随机初始化的神经网络保证逼近精度，并且可以适用于更广泛的激活函数。 |
| [^80] | [TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns.](http://arxiv.org/abs/2303.15747) | 提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。 |
| [^81] | [Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases.](http://arxiv.org/abs/2303.15739) | 本研究针对深度ReLU神经网络，证明了过参数化情况下的Bayesian自由能是有界的，说明Bayesian广义误差不会增加。 |
| [^82] | [Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation.](http://arxiv.org/abs/2303.15413) | 本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。 |
| [^83] | [Difficulty in learning chirality for Transformer fed with SMILES.](http://arxiv.org/abs/2303.11593) | 应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。 |
| [^84] | [Vibration Signal Denoising Using Deep Learning.](http://arxiv.org/abs/2303.11413) | 本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。 |
| [^85] | [Do we need entire training data for adversarial training?.](http://arxiv.org/abs/2303.06241) | 本文提出了一种新的对抗训练方法，通过对训练数据集进行筛选，仅使用易受对抗攻击的样本进行训练，从而减少训练时间。 |
| [^86] | [Label Attention Network for sequential multi-label classification: you were looking at a wrong self-attention.](http://arxiv.org/abs/2303.00280) | LANET是一种标签注意力网络，可用于解决序列多标签分类问题，能够更好地捕捉标签之间的相互关系，并且在实验中表现良好。 |
| [^87] | [Boosting Adversarial Transferability using Dynamic Cues.](http://arxiv.org/abs/2302.12252) | 本研究通过优化时间提示来引入动态特征，提高了图像模型到视频模型的对抗攻击的转移性能。 |
| [^88] | [KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction.](http://arxiv.org/abs/2302.12126) | 本文提出了一种新颖的知识感知政治立场预测方法，采用层次化注意力网络、外部知识库和知识感知损失函数，可以有效地捕捉新闻文章中的关键信息，优于现有方法。 |
| [^89] | [Topological Feature Selection: A Graph-Based Filter Feature Selection Approach.](http://arxiv.org/abs/2302.09543) | 本文提出了一种基于图论的特征选择方法，利用拓扑学和依赖关系，具有高度灵活性和解释性，在16个基准数据集上显示出优于或匹配于当前最先进技术的表现。 |
| [^90] | [InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis.](http://arxiv.org/abs/2302.08624) | InstructABSA是一种使用指令学习范式的方面情感分析方法，能够显著提高Aspect Term Extraction、Aspect Term Sentiment Classification、和Joint Task subtasks三个子任务的性能，并且在多个数据集上表现超过之前的最先进方法。 |
| [^91] | [Neural Architecture Search with Multimodal Fusion Methods for Diagnosing Dementia.](http://arxiv.org/abs/2302.05894) | 本文提出利用多模态融合方法进行神经结构搜索来诊断痴呆症，解决了以前工作中CNN结构寻找耗时的问题和多模态融合效果不佳的问题。 |
| [^92] | [A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser.](http://arxiv.org/abs/2301.13731) | 本文提出了一种新的收敛插入播放算法，使用一个松弛的近端去噪器和一个松弛的PGD算法，能够收敛于更广泛的正则化参数范围内。 |
| [^93] | [Learning Data Representations with Joint Diffusion Models.](http://arxiv.org/abs/2301.13622) | 本文提出了一种扩展香草扩散模型的方法，使用分类器进行联合端到端训练，以提高分类和生成数据的质量。 |
| [^94] | [Vision Learners Meet Web Image-Text Pairs.](http://arxiv.org/abs/2301.07088) | 本论文提出了一种基于网络数据的新型视觉学习方法MUlti-modal Generator (MUG)。在视觉数据集的转移学习任务上取得了最先进的表现，是之前最佳结果的3.4%和2.2%的提升。 |
| [^95] | [A Characterization of Multioutput Learnability.](http://arxiv.org/abs/2301.02729) | 该论文研究了多输出函数类的学习问题，提出了多输出函数类学习的特征化判别标准，即每个单输出子类可学习时多输出函数类才可学习，在多标记分类和多输出回归领域取得了重要进展。 |
| [^96] | [Self-Supervised Object Segmentation with a Cut-and-Pasting GAN.](http://arxiv.org/abs/2301.00366) | 提出了一种基于自监督的 Cut-and-Paste GAN，用于前景对象分割和组合图像生成，无需手动标注，通过学习全局数据表示和语义结构信息，实现了有意义的遮罩生成。 |
| [^97] | [Vision Transformers are Parameter-Efficient Audio-Visual Learners.](http://arxiv.org/abs/2212.07983) | 本文研究了冻结ViTs在没有微调任何原始参数的情况下将其推广到音像数据的能力。通过使用一个名为LAVISH的适配器和少数的可训练参数，有效融合视觉和音频提示，并在使用较少可调参数和不依赖昂贵的音频预训练的情况下，在各种音像任务上取得了竞争性性能。 |
| [^98] | [Jointly Learning Visual and Auditory Speech Representations from Raw Data.](http://arxiv.org/abs/2212.06246) | 本文提出了一种自监督算法RAVEn，能够同时学习视觉和听觉语音表示，无需准备大量标记数据，能在低资源和高资源数据设置下得到显著的结果，相比其他自监督算法在视觉语音识别上表现更好，在结合少量标记数据的情况下仍可超过使用大量非公共数据的半监督算法。 |
| [^99] | [Neural Bandits for Data Mining: Searching for Dangerous Polypharmacy.](http://arxiv.org/abs/2212.05190) | 本研究提出了一种名为OptimNeuralTS的策略，用于搜索有害多药疗法，基于神经汤普森采样和差分进化，能够高效地挖掘索赔数据库并建立药物组合与健康结果之间的预测模型。 |
| [^100] | [A soft nearest-neighbor framework for continual semi-supervised learning.](http://arxiv.org/abs/2212.05102) | 该论文介绍了一种用于持续半监督学习的软最近邻框架，该框架利用最近邻分类器来非线性地划分特征空间并非参数地建模潜在的数据分布，以避免模型忘记对未标记数据表示并过度拟合标记的样本。 |
| [^101] | [Three Variations on Variational Autoencoders.](http://arxiv.org/abs/2212.04451) | 本文针对变分自编码器提出三种变体，其中一种与原模型的ELBO逼近相比产生了证据上限（EUBO），可用来查询模型收敛情况。 |
| [^102] | [A Neural Network Approach for Selecting Track-like Events in Fluorescence Telescope Data.](http://arxiv.org/abs/2212.03787) | 该论文研究了如何使用神经网络在荧光望远镜数据中筛选出轨迹事件，结合实验测试了注册极高能宇宙射线的可能性。 |
| [^103] | [A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification.](http://arxiv.org/abs/2211.15259) | 本篇论文呼吁对图像分类中失败检测的评估实践进行反思。虽然现有的技术都在尝试通过置信度检测错误预测，但是它们目前构成了独立的研究领域，存在评估标准的不一致性。因此，我们需要进行综合和现实的评估，以解决当前存在的问题。 |
| [^104] | [Emerging trends in machine learning for computational fluid dynamics.](http://arxiv.org/abs/2211.15145) | 本文讨论了机器学习在计算流体力学领域中的新趋势，并重点讨论了ML和CFD之间的协同效应，还评估了仍在开发中的领域，提出了平衡谨慎乐观的视角。 |
| [^105] | [Collective Intelligence for 2D Push Manipulation with Mobile Robots.](http://arxiv.org/abs/2211.15136) | 本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。 |
| [^106] | [MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention.](http://arxiv.org/abs/2211.13955) | 本文提出了一种MPC友好的视觉Transformer模型MPCViT，该模型通过异构注意力搜索来实现准确且高效的ViT推理，并通过简单而有效的神经架构搜索算法来进一步提高推理效率。 |
| [^107] | [Bayesian Model Selection of Lithium-Ion Battery Models via Bayesian Quadrature.](http://arxiv.org/abs/2210.17299) | 本文介绍了一种使用贝叶斯四元数的贝叶斯模型选择方法来分析锂离子电池模型，以选择最简单的模型来描述数据集。使用样本有效的积分技术减少了电池模型评估的数量，并推断出模型参数的后验分布。 |
| [^108] | [FrozenQubits: Boosting Fidelity of QAOA by Skipping Hotspot Nodes.](http://arxiv.org/abs/2210.17037) | 提出FrozenQubits算法，通过冻结热点节点将状态空间分解为较小的子空间并独立地解决问题，提高了QAOA电路的保真度。 |
| [^109] | [MMRNet: Improving Reliability for Multimodal Object Detection and Segmentation for Bin Picking via Multimodal Redundancy.](http://arxiv.org/abs/2210.10842) | 本文提出了一个基于多模态冗余的可靠的抓取商品物体检测和分割系统MMRNet，能够在传感器失效等异常情况下具有更好的鲁棒性，并在YCB-Video数据集上取得了最先进的性能。 |
| [^110] | [A Policy-Guided Imitation Approach for Offline Reinforcement Learning.](http://arxiv.org/abs/2210.08323) | 该论文提出了一种策略指导模仿方法，它将传统的奖励最大化策略分解成引导策略和执行策略。在训练期间，引导策略和执行策略在仅使用数据集中的数据的情况下进行学习。在评估期间，引导策略通过指引执行策略以最大化奖励，起到“先知”的作用，允许合理的超出分布泛化。 |
| [^111] | [Boosting Graph Neural Networks via Adaptive Knowledge Distillation.](http://arxiv.org/abs/2210.05920) | 本文提出了一种自适应知识蒸馏框架（BGNN）来增强图神经网络。该框架可以有效地将多个模型的知识传输到具有相同容量的学生模型中，并充分利用学生模型的优势来学习知识。 |
| [^112] | [Learning-based Design of Luenberger Observers for Autonomous Nonlinear Systems.](http://arxiv.org/abs/2210.01476) | 该论文提出了一种新方法，使用神经网络来设计非线性系统的观测器，具有优秀的泛化能力和鲁棒性。 |
| [^113] | [Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection.](http://arxiv.org/abs/2210.00875) | 本文提出了一种针对数据集版权保护的无害和隐蔽的无目标后门水印方案，可以达到与最先进方案相当或更好的水印效果，并证明对模型性能无害且隐蔽。 |
| [^114] | [Robust Forecasting for Robotic Control: A Game-Theoretic Approach.](http://arxiv.org/abs/2209.10802) | 该论文提出了一种机器人控制鲁棒预测的新框架，该框架通过引入敌手概念，建立起机器人预测者与敌手之间的零和二人博弈模型，解决了仅依靠历史时间序列进行预测的问题。 |
| [^115] | [A Max-relevance-min-divergence Criterion for Data Discretization with Applications on Naive Bayes.](http://arxiv.org/abs/2209.10095) | 该论文提出了一种Max-Dependency-Min-Divergence (MDmD)准则，旨在同时最大化离散化数据的判别信息和泛化能力。此准则可应用于离散化数据的分类模型中，如朴素贝叶斯。 |
| [^116] | [A simple approach for quantizing neural networks.](http://arxiv.org/abs/2209.03487) | 本论文提出了一种简单的确定性预处理步骤来量化神经网络层的权重，并在不需要超参数调整的情况下保持网络性能，且相对误差随网络参数数量的增加而降低。 |
| [^117] | [Generalisation under gradient descent via deterministic PAC-Bayes.](http://arxiv.org/abs/2209.02525) | 本文介绍了一种新的PAC-Bayesian泛化界限，适用于使用梯度下降方法或连续梯度流训练模型的优化算法，且无需随机化。 |
| [^118] | [Adversarial robustness of VAEs through the lens of local geometry.](http://arxiv.org/abs/2208.03923) | 本文证明了对手攻击VAEs的最佳方法是利用由编码器和解码器网络引起的随机回溯度规张量的方向偏差。 |
| [^119] | [CFLIT: Coexisting Federated Learning and Information Transfer.](http://arxiv.org/abs/2207.12884) | 本文提出了一种共存的联邦学习和信息传输通信框架，其中利用多址信道的叠加特性，通过优化长期无线资源分配来最大化信息传输数据速率，并保证给定的联邦学习收敛性能。 |
| [^120] | [Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary Classification.](http://arxiv.org/abs/2206.09098) | 本文证明了对抗性代理风险的存在性、正则性和极小化定理，这一结果为对抗鲁棒性的理论提供了支持，并且可以指导算法的发展。 |
| [^121] | [Rethinking Initialization of the Sinkhorn Algorithm.](http://arxiv.org/abs/2206.07630) | 本文认为Sinkhorn算法的初始化备受忽视，但数据相关的初始化可以提高算法性能，并适用于端到端学习。 |
| [^122] | [Synopses of Movie Narratives: a Video-Language Dataset for Story Understanding.](http://arxiv.org/abs/2203.05711) | 这个研究收集并发布了一个视频-语言故事数据集SYMON，用于推进多模态故事理解的发展。 |
| [^123] | [GraphTune: A Learning-based Graph Generative Model with Tunable Structural Features.](http://arxiv.org/abs/2201.11494) | GraphTune是一种基于学习的图生成模型，允许我们调整生成图的全局结构特征的值作为条件，比传统模型更有效。 |
| [^124] | [CFU Playground: Full-Stack Open-Source Framework for Tiny Machine Learning (tinyML) Acceleration on FPGAs.](http://arxiv.org/abs/2201.01863) | CFU Playground是一个全栈开源框架，为嵌入式机器学习系统提供快速迭代设计和评估机器学习加速器的工具。通过CFU Playground，可以定制和协同优化实验性和定制体系结构，实现相对较小的定制投资即可让机器学习硬件和软件开发者获得显著回报。 |
| [^125] | [On Complexity of 1-Center in Various Metrics.](http://arxiv.org/abs/2112.03222) | 在本文中，研究了不同度量下1-中心问题的复杂性。小d时，在假设命中集合猜想（HSC）成立的情况下，无法通过任何lp度量或编辑或Ulam度量实现1-中心问题的次二次算法。大d时，在假设Quantified SETH的情况下，排除了基于编辑度量中的1-中心问题的次四次算法，同时给出了Ulam度量中1-中心问题的（1+ε）逼近算法。 |
| [^126] | [Newton methods based convolution neural networks using parallel processing.](http://arxiv.org/abs/2112.01401) | 本研究提出基于牛顿方法和并行处理的卷积神经网络训练方法，使用完整的数据集来处理Hessian矩阵，并比之前的方法更高效。 |
| [^127] | [A Semi-Supervised Adaptive Discriminative Discretization Method Improving Discrimination Power of Regularized Naive Bayes.](http://arxiv.org/abs/2111.10983) | 本文提出了一种半监督自适应判别离散化框架，通过伪标签技术利用标记数据和未标记数据，提高分离能力，避免信息损失，优化了正则化朴素贝叶斯分类器。 |
| [^128] | [CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation.](http://arxiv.org/abs/2110.06400) | CyTran 是一种基于循环一致的生成对抗卷积 Transformer 模型，通过多级循环一致性损失函数和一种新的对比损失函数实现了非对比度和对比度 CT 扫描的翻译，可为不能注射对比剂的患者自动生成对比 CT 扫描，同时增强对比和非对比 CT 扫描的对齐。 CyTran outperforms state-of-the-art models for both non-contrast to contrast and contrast to non-contrast CT translation tasks. |
| [^129] | [Federated Submodel Optimization for Hot and Cold Data Features.](http://arxiv.org/abs/2109.07704) | 本文提出了一种针对联邦学习稀疏数据特征的联邦子模型平均算法(FedSubAvg)，该算法可以有效避免数据稀疏问题导致的计算下降，并保证每个模型参数的全局更新期望等于涉及它的客户端的本地更新平均值。该算法的新度量元素梯度范数可以更好地表征在稀疏数据上的联邦优化收敛。 |
| [^130] | [Diffusion Schr\"odinger Bridge with Applications to Score-Based Generative Modeling.](http://arxiv.org/abs/2106.01357) | 本文提出了一种名为Diffusion SB (DSB) 的逼近迭代比例拟合程序，用于解决Schrödinger Bridge问题，该问题可以产生从数据分布中生成样本的扩散过程，而有限时间内完成。 |
| [^131] | [Improving Semiconductor Device Modeling for Electronic Design Automation by Machine Learning Techniques.](http://arxiv.org/abs/2105.11453) | 本文提出一种利用机器学习技术改进半导体器件建模的方法，通过自我增强策略和变分自编码器技术，只需少量实验数据点即可实现高精度预测，有效降低平均绝对误差，具有广泛应用价值。 |
| [^132] | [Approximated Multi-Agent Fitted Q Iteration.](http://arxiv.org/abs/2104.09343) | 本文提出了一种近似方法AMAFQI，可用于高效解决多智能体批量强化学习问题，相比于常用方法FQI，AMAFQI的计算量增长更为缓慢，以线性增长，且仿真实验显示两种方法的性能类似。 |
| [^133] | [Reinforcement Learning for Freight Booking Control Problems.](http://arxiv.org/abs/2102.00092) | 该论文介绍了如何使用强化学习解决货运预订控制方面的顺序决策问题。作者指出，惯例上在部署强化学习算法时解决运营问题可能太耗费时间，该研究提供了一种解决方案。 |
| [^134] | [Treatment Allocation with Strategic Agents.](http://arxiv.org/abs/2011.06528) | 论文研究了带有战略代理的治疗分配问题。研究表明，最优规则可以涉及随机化，对那些平均上对治疗有积极反应的个体也可以分配不到100%的治疗机会。 |
| [^135] | [Generative Adversarial Networks (GANs Survey): Challenges, Solutions, and Future Directions.](http://arxiv.org/abs/2005.00065) | 生成对抗网络（GANs）是一种学习复杂高维概率分布的新型深度生成模型，但其训练存在着诸多挑战，如模式崩溃、不收敛及不稳定性。最近，针对这些挑战，提出了多种GANs的设计和优化方案来解决这些问题。 |

# 详细

[^1]: 完成分割任务的万能模型

    Segment Anything. (arXiv:2304.02643v1 [cs.CV])

    [http://arxiv.org/abs/2304.02643](http://arxiv.org/abs/2304.02643)

    这篇论文介绍了一个新的图像分割任务、模型和数据集，该模型具有高效的分割能力和任务迁移能力，可以在新的图像分布和任务中进行零-shot 任务迁移，使其零-shot表现令人印象深刻，并发布了Segment Anything Model（SAM）和相应的数据集（SA-1B），以促进计算机视觉基础模型研究的发展。

    

    我们介绍了“Segment Anything（SA）”项目，这是一个新的图像分割任务、模型和数据集。我们使用高效的模型在数据收集循环中构建了到目前为止最大的分割数据集，涵盖1100万个许可和隐私尊重的图像，其中包含10亿个掩膜。该模型经过设计和训练，可以快速响应，因此可以在新的图像分布和任务中进行零-shot 任务迁移。我们对其在众多任务中的表现进行了评估，并发现其零-shot 性能令人印象深刻 -- 通常是竞争对手或甚至超过之前的完全监督结果。我们正在 https://segment-anything.com 上发布 Segment Anything Model（SAM）和相应的数据集（SA-1B），以促进计算机视觉基础模型研究的发展。

    We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.
    
[^2]: 高斯过程回归和分类的自我蒸馏

    Self-Distillation for Gaussian Process Regression and Classification. (arXiv:2304.02641v1 [stat.ML])

    [http://arxiv.org/abs/2304.02641](http://arxiv.org/abs/2304.02641)

    本文针对高斯过程回归和分类提出了数据中心方法和分布中心方法，分析后发现其与内核岭回归自我蒸馏和普通GPR对应。其中GPC的分布中心方法近似对应于数据复制和协方差的特定缩放。

    

    我们提出了两种方法来将知识蒸馏的概念扩展到高斯过程回归（GPR）和高斯过程分类（GPC）中；数据中心方法和分布中心方法。数据中心方法最像目前机器学习的大多数蒸馏技术，它在教师的确定性预测上重新适合一个模型，而分布中心方法则重新使用完整概率后验进行下一次迭代。通过分析这些方法的特性，我们表明GPR的数据中心方法与已知的内核岭回归自我蒸馏结果密切相关，而GPR的分布中心方法与具有特定超参数选择的普通GPR相对应。此外，我们演示了GPC的分布中心方法近似对应于数据复制和协方差的特定缩放，而GPC的数据中心方法需要重新定义模型。

    We propose two approaches to extend the notion of knowledge distillation to Gaussian Process Regression (GPR) and Gaussian Process Classification (GPC); data-centric and distribution-centric. The data-centric approach resembles most current distillation techniques for machine learning, and refits a model on deterministic predictions from the teacher, while the distribution-centric approach, re-uses the full probabilistic posterior for the next iteration. By analyzing the properties of these approaches, we show that the data-centric approach for GPR closely relates to known results for self-distillation of kernel ridge regression and that the distribution-centric approach for GPR corresponds to ordinary GPR with a very particular choice of hyperparameters. Furthermore, we demonstrate that the distribution-centric approach for GPC approximately corresponds to data duplication and a particular scaling of the covariance and that the data-centric approach for GPC requires redefining the mod
    
[^3]: GenPhys：从物理过程到生成模型

    GenPhys: From Physical Processes to Generative Models. (arXiv:2304.02637v1 [cs.LG])

    [http://arxiv.org/abs/2304.02637](http://arxiv.org/abs/2304.02637)

    本文介绍了一个新的生成模型家族：GenPhys，它将从物理过程中描述的偏微分方程翻译为生成模型，并探索了更广泛的生成模型设计空间。

    

    由于扩散模型(DM)和最近的泊松流生成模型(PFGM)都受到物理过程的启发，因此合理地问一下：物理过程能否提供更多新的生成模型？我们展示了答案是肯定的。我们介绍了一个通用的家族，即从物理过程到生成模型(GenPhys)，其中我们将描述物理过程的偏微分方程(PDEs)翻译为生成模型。我们展示了可以从s-生成的PDEs (s代表平滑)构建生成模型。GenPhys包含了两个现有生成模型(DM和PFGM)，并甚至引出了新的生成模型家族，例如，受弱相互作用启发的“Yukawa生成模型”。另一方面，某些物理过程默认不属于GenPhys家族，例如波动方程和薛定谔方程，但可以通过一些修改加入到GenPhys家族中。我们的目标是通过GenPhys来探索和扩展生成模型的设计空间。

    Since diffusion models (DM) and the more recent Poisson flow generative models (PFGM) are inspired by physical processes, it is reasonable to ask: Can physical processes offer additional new generative models? We show that the answer is yes. We introduce a general family, Generative Models from Physical Processes (GenPhys), where we translate partial differential equations (PDEs) describing physical processes to generative models. We show that generative models can be constructed from s-generative PDEs (s for smooth). GenPhys subsume the two existing generative models (DM and PFGM) and even give rise to new families of generative models, e.g., "Yukawa Generative Models" inspired from weak interactions. On the other hand, some physical processes by default do not belong to the GenPhys family, e.g., the wave equation and the Schr\"{o}dinger equation, but could be made into the GenPhys family with some modifications. Our goal with GenPhys is to explore and expand the design space of gener
    
[^4]: 历史森林生物量的地图制作，用于精确评估个体和景观尺度的库存变化

    Mapping historical forest biomass for stock-change assessments at parcel to landscape scales. (arXiv:2304.02632v1 [stat.AP])

    [http://arxiv.org/abs/2304.02632](http://arxiv.org/abs/2304.02632)

    本文介绍了一项基本步骤，即利用Landsat影像、激光雷达和FIA数据，在整个纽约州（1990年至2019年）以较高时间和空间分辨率制作历史森林生物量地图，以便实现个体和景观尺度的库存变化评估。

    

    理解历史森林动态，特别是森林生物量和碳储量的变化，已成为评估目前森林气候效益并在各种政策、监管和管理方案下预测未来效益的关键。本文利用Landsat影像、美国森林局森林库存与分析（FIA）数据和现成的激光雷达数据，以年度30米的时间和空间分辨率（1990年至2019年，包括纽约州的所有地区），使用免费的数据和开源工具，描述了建立基于地图的库存变化框架的基本步骤：制作历史森林生物量地图。

    Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios. Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time. Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.  Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches
    
[^5]: 增强弱监督分割的高保真伪标签生成方法

    High-fidelity Pseudo-labels for Boosting Weakly-Supervised Segmentation. (arXiv:2304.02621v1 [cs.CV])

    [http://arxiv.org/abs/2304.02621](http://arxiv.org/abs/2304.02621)

    本文提出了一种使用马尔可夫随机场增强弱监督分割中的高保真伪标签生成方法，能够生成更准确的伪标签，并使用新的训练策略来实现更好的收敛。实验结果表明该方法达到了弱监督分割方法的最佳性能。

    

    近年来，图像级别的弱监督语义分割（WSSS）任务因为其可减少大量数据标注成本而变得流行。WSSS的典型方法是使用全局平均池化（GAP）在卷积特征映射上训练图像分类网络。这使得可以基于类别激活图（CAMs）估计对象位置，CAMs识别图像区域的重要性。然后使用CAMs生成伪标签，以形式化的分割掩码的方式在缺乏像素级标签的情况下对分割模型进行监督。在SEAM基线的情况下，一个先前的工作提出了提高CAM学习的两种方法：（1）重要性抽样，它是GAP的替代方法；（2）特征相似性损失，它使用一种启发式方法，即对象轮廓几乎仅与图像中的颜色边缘对齐。在这项工作中，我们为这些任务提出了一种不同的概率解释CAM的方法，从而生成更精确的伪标签。具体而言，我们采用马尔可夫随机场将局部空间一致性约束融入CAM学习中。我们还提出了一种新的训练策略，交替更新CAM和分割模型以实现更好的收敛。在基准数据集上的实验结果表明，我们的方法在弱监督分割方法中实现了最先进的性能。

    The task of image-level weakly-supervised semantic segmentation (WSSS) has gained popularity in recent years, as it reduces the vast data annotation cost for training segmentation models. The typical approach for WSSS involves training an image classification network using global average pooling (GAP) on convolutional feature maps. This enables the estimation of object locations based on class activation maps (CAMs), which identify the importance of image regions. The CAMs are then used to generate pseudo-labels, in the form of segmentation masks, to supervise a segmentation model in the absence of pixel-level ground truth. In case of the SEAM baseline, a previous work proposed to improve CAM learning in two ways: (1) Importance sampling, which is a substitute for GAP, and (2) the feature similarity loss, which utilizes a heuristic that object contours almost exclusively align with color edges in images. In this work, we propose a different probabilistic interpretation of CAMs for thes
    
[^6]: 量子最优控制的高效量子算法

    Efficient Quantum Algorithms for Quantum Optimal Control. (arXiv:2304.02613v1 [quant-ph])

    [http://arxiv.org/abs/2304.02613](http://arxiv.org/abs/2304.02613)

    本文提出了一种高效的量子算法，解决量子最优控制问题，运用容错的量子计算机，具有复杂的机器学习关系。

    

    本文提出了一种高效的量子算法，比经典算法解决量子最优控制问题的速度快出指数倍。该问题需要寻找控制变量，以最大化在时间T时受时变薛定谔方程控制的系统的某个物理量。这种控制问题也与机器学习有着复杂的关系。我们的算法基于时变哈密顿模拟方法和快速梯度估计算法。我们还提供了全面的错误分析，以量化来自各个步骤的总误差，如控制函数的有限维表示、薛定谔方程的离散化、数值积分和优化。我们的量子算法需要容错的量子计算机。

    In this paper, we present efficient quantum algorithms that are exponentially faster than classical algorithms for solving the quantum optimal control problem. This problem involves finding the control variable that maximizes a physical quantity at time $T$, where the system is governed by a time-dependent Schr\"odinger equation. This type of control problem also has an intricate relation with machine learning. Our algorithms are based on a time-dependent Hamiltonian simulation method and a fast gradient-estimation algorithm. We also provide a comprehensive error analysis to quantify the total error from various steps, such as the finite-dimensional representation of the control function, the discretization of the Schr\"odinger equation, the numerical quadrature, and optimization. Our quantum algorithms require fault-tolerant quantum computers.
    
[^7]: 对数凹采样的查询下界

    Query lower bounds for log-concave sampling. (arXiv:2304.02599v1 [math.ST])

    [http://arxiv.org/abs/2304.02599](http://arxiv.org/abs/2304.02599)

    该论文研究了对数凹采样的查询下界，在强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，在采样高斯分布中需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询。

    

    最近几年，对数凹采样在算法方面取得了显著的进展，但相应的证明此任务的下界的问题仍然很难，以前只知道在一维中存在较小的下界。在这项工作中，我们建立了以下查询下界：（1）在维度 $d\ge 2$中从强对数凹和对数光滑分布中采样需要 $\Omega(\log \kappa)$ 查询，这在任何固定维度上都是最优的，（2）从高斯分布中采样需要 $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ 查询（因此也适用于在维数 $d$ 中采样一般的对数凹和光滑分布），这对于高斯类几乎是最优的。这里 $\kappa$ 是目标分布的条件数。我们的证明依赖于（1）一种多尺度构造，受到了关于谐振分析中的Kakeya猜想的工作的启发，以及（2）一种新颖的约简，证明了块Krylov算法在此问题中是最佳的。

    Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\ge 2$ requires $\Omega(\log \kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this probl
    
[^8]: 基于MCMC的贝叶斯神经网络：基于Python的教程

    Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])

    [http://arxiv.org/abs/2304.02595](http://arxiv.org/abs/2304.02595)

    本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。

    

    贝叶斯推断为机器学习和深度学习提供了参数估计和不确定性量化的方法。变分推断和马尔科夫链蒙特卡罗（MCMC）采样技术用于实现贝叶斯推断。在过去三十年中，MCMC方法在适应更大的模型（如深度学习）和大数据问题方面面临了许多挑战。包括梯度的高级提议（例如Langevin提议分布）提供了一种解决MCMC采样中的一些限制的方法，此外，MCMC方法通常被限制在统计学家的使用范围内，并且仍不是深度学习研究人员的主流方法。我们提供了一个MCMC方法的教程，涵盖了简单的贝叶斯线性和逻辑模型，以及贝叶斯神经网络。这个教程的目的是通过编码来弥合理论和实现之间的差距，鉴于当前MCMC方法的普及程度仍然较低。

    Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
    
[^9]: 一种用于机器人乳突切除术实时力反馈的力传感器手术钻

    A force-sensing surgical drill for real-time force feedback in robotic mastoidectomy. (arXiv:2304.02583v1 [cs.RO])

    [http://arxiv.org/abs/2304.02583](http://arxiv.org/abs/2304.02583)

    本研究介绍了一种用于机器人辅助乳突切除术的力传感器手术钻，能够通过准确测量工具-组织相互作用力实现力控制和反馈，为手术医生提供实时力反馈，提高手术安全性和成功率。

    

    目的：在耳科手术中使用机器人可以减轻手术医生在侧颅底关键结构周围骨组织清除过程中的任务负担。然而，安全地进入解剖通道需要开发先进的感知能力，以主动限制手术工具与重要解剖结构之间的交互力。方法：我们引入了一种手术钻具备的力传感器，能够测量准确的工具-组织相互作用力以实现向手术医生的力控制和反馈。本文描述了安装在协作控制手术机器人上的力传感器手术钻的设计、校准和验证。结果：手术钻尖端的力测量结果通过生鸡蛋钻孔实验进行了验证，在该实验中，安装在蛋下方的力传感器作为地面真值。点和路径钻孔实验的平均均方根误差（RMSE）为...

    Purpose: Robotic assistance in otologic surgery can reduce the task load of operating surgeons during the removal of bone around the critical structures in the lateral skull base. However, safe deployment into the anatomical passageways necessitates the development of advanced sensing capabilities to actively limit the interaction forces between the surgical tools and critical anatomy.  Methods: We introduce a surgical drill equipped with a force sensor that is capable of measuring accurate tool-tissue interaction forces to enable force control and feedback to surgeons. The design, calibration and validation of the force-sensing surgical drill mounted on a cooperatively controlled surgical robot are described in this work.  Results: The force measurements on the tip of the surgical drill are validated with raw-egg drilling experiments, where a force sensor mounted below the egg serves as ground truth. The average root mean square error (RMSE) for points and path drilling experiments ar
    
[^10]: ECG特征重要性排名：心脏病专家与算法的比较。

    ECG Feature Importance Rankings: Cardiologists vs. Algorithms. (arXiv:2304.02577v1 [physics.med-ph])

    [http://arxiv.org/abs/2304.02577](http://arxiv.org/abs/2304.02577)

    该研究检验了在心脏病学领域的真实数据上的特征重要性方法，尝试区分三种特定病理。一些方法表现良好，而其他方法表现不佳。

    

    特征重要性方法承诺提供根据给定分类任务对特征的重要性进行排序。存在各种各样的方法，但它们的排序经常不一致，由于缺乏除合成数据集以外的基准真相，它们本质上很难评估。在本研究中，我们在心脏病学领域的真实数据上对特征重要性方法进行了测试，我们试图根据与心脏病专家决策规则中使用的特征进行比较来区分健康受试者中的三种特定病理。一些方法表现良好，而另一些方法表现不佳，而有些方法在考虑的问题中表现良好，但并非所有问题。

    Feature importance methods promise to provide a ranking of features according to importance for a given classification task. A wide range of methods exist but their rankings often disagree and they are inherently difficult to evaluate due to a lack of ground truth beyond synthetic datasets. In this work, we put feature importance methods to the test on real-world data in the domain of cardiology, where we try to distinguish three specific pathologies from healthy subjects based on ECG features comparing to features used in cardiologists' decision rules as ground truth. Some methods generally performed well and others performed poorly, while some methods did well on some but not all of the problems considered.
    
[^11]: 马尔可夫决策过程中的合规异策评估

    Conformal Off-Policy Evaluation in Markov Decision Processes. (arXiv:2304.02574v1 [cs.LG])

    [http://arxiv.org/abs/2304.02574](http://arxiv.org/abs/2304.02574)

    本论文提出了一种基于合规预测的异策评估方法，能够以一定的确定性水平输出包含目标策略的真实奖励的区间，并提出了不同的处理分布偏移方法，其中一些方法在保证合规性的前提下实现了最先进的性能。

    

    强化学习旨在从数据中识别和评估有效的控制策略。在许多实际应用中，学习者不能进行实验，也不能以在线方式获取数据（在实验费用高昂、风险高或不道德的情况下，就会出现这种情况）。针对这种应用，必须使用在不同策略下收集的历史数据（行为策略）来估计给定策略（目标策略）的奖励。大多数针对这种学习任务的方法，即异策评估（OPE），都没有准确性和确定性保证。我们提出了一种基于合规预测的新型OPE方法，该方法输出一个包含目标策略的真实奖励的区间，同时具有一定的确定性水平。OPE中的主要挑战来自于目标策略和行为策略之间的差异引起的分布偏移。我们提出并经验性地评估了不同处理这种偏移的方法。其中一些方法在保证估计的奖励区间的合规性的同时，在基准环境中实现了最先进的性能。

    Reinforcement Learning aims at identifying and evaluating efficient control policies from data. In many real-world applications, the learner is not allowed to experiment and cannot gather data in an online manner (this is the case when experimenting is expensive, risky or unethical). For such applications, the reward of a given policy (the target policy) must be estimated using historical data gathered under a different policy (the behavior policy). Most methods for this learning task, referred to as Off-Policy Evaluation (OPE), do not come with accuracy and certainty guarantees. We present a novel OPE method based on Conformal Prediction that outputs an interval containing the true reward of the target policy with a prescribed level of certainty. The main challenge in OPE stems from the distribution shift due to the discrepancies between the target and the behavior policies. We propose and empirically evaluate different ways to deal with this shift. Some of these methods yield conform
    
[^12]: 自监督的孪生自编码器

    Self-Supervised Siamese Autoencoders. (arXiv:2304.02549v1 [cs.LG])

    [http://arxiv.org/abs/2304.02549](http://arxiv.org/abs/2304.02549)

    本论文提出了一种新的自监督方法，名为SidAE，它结合了孪生架构和去噪自编码器的优点，可以更好地提取输入数据的特征，以在多个下游任务中获得更好的性能。

    

    完全监督的模型通常需要大量的标记训练数据，这往往是昂贵且难以获得的。相反，自监督表示学习减少了实现相同或更高下游性能所需的标记数据量。目标是在自监督任务上预先训练深度神经网络，以便网络能够从原始输入数据中提取有意义的特征。然后，将这些特征用作下游任务（如图像分类）中的输入。在先前的研究中，自编码器和孪生网络（如SimSiam）已成功应用于这些任务中。然而，仍然存在一些挑战，例如将特征的特性（例如，细节级别）与给定的任务和数据集匹配。在本文中，我们提出了一种结合了孪生架构和去噪自编码器优势的新自监督方法。我们展示了我们的模型，名为SidAE（孪生去噪自编码器），在多个下游任务上胜过了两个自监督最新基准。

    Fully supervised models often require large amounts of labeled training data, which tends to be costly and hard to acquire. In contrast, self-supervised representation learning reduces the amount of labeled data needed for achieving the same or even higher downstream performance. The goal is to pre-train deep neural networks on a self-supervised task such that afterwards the networks are able to extract meaningful features from raw input data. These features are then used as inputs in downstream tasks, such as image classification. Previously, autoencoders and Siamese networks such as SimSiam have been successfully employed in those tasks. Yet, challenges remain, such as matching characteristics of the features (e.g., level of detail) to the given task and data set. In this paper, we present a new self-supervised method that combines the benefits of Siamese architectures and denoising autoencoders. We show that our model, called SidAE (Siamese denoising autoencoder), outperforms two se
    
[^13]: 多注释深度学习：分类问题的概率框架

    Multi-annotator Deep Learning: A Probabilistic Framework for Classification. (arXiv:2304.02539v1 [cs.LG])

    [http://arxiv.org/abs/2304.02539](http://arxiv.org/abs/2304.02539)

    该论文提出了一个名为多注释深度学习（MaDL）的概率训练框架，可以在由易错注释者提供的有噪音类别标签上进行端到端的联合训练，并有效地解决多注释监督学习中的次优表现问题。

    

    使用深度神经网络解决复杂分类任务通常需要大量注释数据，然而由易错注释者（如众包工人）提供的对应类别标签有噪音。在这样的多注释监督学习中，训练标准的深度神经网络会导致次优表现。我们通过提出名为多注释深度学习（MaDL）的概率训练框架来解决这个问题。在端到端的学习方法中，联合训练一个地面真相模型和一个注释者表现模型。地面真相模型学习预测实例的真实类别，而注释者表现模型推断注释者表现的概率估计。模块化的网络结构使我们能够对注释者的表现做出不同的假设，例如，可以考虑类别或实例依赖性。此外，我们学习注释者嵌入以估计潜在空间中注释者的密度作为迁移学习的代理。我们的方法不仅使我们能够估计真实的类别标签，而且能够估计所分配标签的可信度。在合成数据和真实数据上的实验表明，在注释者性能假设不同的情况下，我们的方法都具有有效性。

    Solving complex classification tasks using deep neural networks typically requires large amounts of annotated data. However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers. Training standard deep neural networks leads to subpar performances in such multi-annotator supervised learning settings. We address this issue by presenting a probabilistic training framework named multi-annotator deep learning (MaDL). A ground truth and an annotator performance model are jointly trained in an end-to-end learning approach. The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances. A modular network architecture enables us to make varying assumptions regarding annotators' performances, e.g., an optional class or instance dependency. Further, we learn annotator embeddings to estimate annotators' densities within a latent space as proxies of t
    
[^14]: 学习比较纵向图像

    Learning to Compare Longitudinal Images. (arXiv:2304.02531v1 [eess.IV])

    [http://arxiv.org/abs/2304.02531](http://arxiv.org/abs/2304.02531)

    本文提出了一种名为PaIRNet的深度学习模型，用于比较带有或不带有预处理的纵向图像对，以检测生物医学应用中与研究问题相关的变化。

    

    纵向研究是生物医学应用中研究和描述时间动态的常用技术，其中从相同的人群中在不同时间点获取一系列图像。传统的纵向比较方法是通过预处理来标准化噪声变化，例如图像方向或对比度差异，然后进行统计分析以检测感兴趣的变化。本文提出了一种基于简单机器学习的方法 PaIRNet，它可以减轻这些问题。在我们的方法中，我们训练一个深度学习模型来比较纵向图像对，无论是否进行预处理。PaIRNet学习识别两个图像之间的最具辨别性的区域，并提供相似度得分以反映它们的差异。

    Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications. The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing. Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level. This classical approach can suffer from pre-processing issues and limitations of the statistical modeling. For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes. In this paper, we present a simple machine learning-based approach that can alleviate these issues. In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or witho
    
[^15]: 面向对抗鲁棒模型的超参数调节

    Hyper-parameter Tuning for Adversarially Robust Models. (arXiv:2304.02497v1 [cs.LG])

    [http://arxiv.org/abs/2304.02497](http://arxiv.org/abs/2304.02497)

    本文探究对抗训练模型的超参数调节问题，明确对抗环境下需要额外调整的超参数，并提出利用廉价对抗训练方法的新方案降低调节成本。

    

    本文关注对抗训练模型的超参数调节问题，旨在确定在对抗环境下哪些额外的超参数是需要调节的，同时降低对抗训练模型的调节成本。通过对3个广泛应用于先前有关对抗鲁棒性文献中的模型进行广泛的实验研究，我们对这一问题进行了探究，并发现该问题在对抗环境下的复杂性主要有两个方面：需要调整额外的超参数来平衡标准训练和对抗训练；需要独立调整标准训练和对抗训练阶段的超参数。同时，本文还提出了利用廉价的对抗训练方法来降低对抗训练模型超参数调节成本的新机会。

    This work focuses on the problem of hyper-parameter tuning (HPT) for robust (i.e., adversarially trained) models, with the twofold goal of i) establishing which additional HPs are relevant to tune in adversarial settings, and ii) reducing the cost of HPT for robust models. We pursue the first goal via an extensive experimental study based on 3 recent models widely adopted in the prior literature on adversarial robustness. Our findings show that the complexity of the HPT problem, already notoriously expensive, is exacerbated in adversarial settings due to two main reasons: i) the need of tuning additional HPs which balance standard and adversarial training; ii) the need of tuning the HPs of the standard and adversarial training phases independently. Fortunately, we also identify new opportunities to reduce the cost of HPT for robust models. Specifically, we propose to leverage cheap adversarial training methods to obtain inexpensive, yet highly correlated, estimations of the quality ach
    
[^16]: 量化视觉、语言和视觉-语言复杂度在动词习得中的作用

    Quantifying the Roles of Visual, Linguistic, and Visual-Linguistic Complexity in Verb Acquisition. (arXiv:2304.02492v1 [cs.CL])

    [http://arxiv.org/abs/2304.02492](http://arxiv.org/abs/2304.02492)

    本研究探讨了早期动词学习不对称性的原因，并量化地证明，与名词相比，动词更难习得，需要整合视觉和语言信息。另外，多语言和多模式输入可以改善语言和视觉信息之间的不匹配。

    

    幼儿学习名词的意义通常比学习动词的意义早。但是，不清楚这种不对称性是由于语言所指的世界中类别的视觉结构的复杂性，语言本身的结构，还是两种信息来源之间的相互作用所致。我们通过使用大规模预训练的人工神经网络中来源于视觉和语言的单词表示，定量地测试了关于早期动词学习的这三个假说。通过检查视觉和语言嵌入空间的结构，我们发现，首先，与名词的表示相比，动词的表示在域内通常更加变化和不可辨识。其次，我们发现，如果每个类别只有一个学习实例，那么动词系统中的视觉和语言表示比名词系统中的不太吻合。然而，与人类语言发展的过程类似，如果在学习期间有多语言和多模式输入，那么名词和动词的语言和视觉信息都变得更加吻合。我们的研究结果表明，早期动词学习的不对称性至少部分归因于更复杂的动词含义，这需要集成视觉和语言信息，而不仅仅是视觉复杂度或语言结构。

    Children typically learn the meanings of nouns earlier than the meanings of verbs. However, it is unclear whether this asymmetry is a result of complexity in the visual structure of categories in the world to which language refers, the structure of language itself, or the interplay between the two sources of information. We quantitatively test these three hypotheses regarding early verb learning by employing visual and linguistic representations of words sourced from large-scale pre-trained artificial neural networks. Examining the structure of both visual and linguistic embedding spaces, we find, first, that the representation of verbs is generally more variable and less discriminable within domain than the representation of nouns. Second, we find that if only one learning instance per category is available, visual and linguistic representations are less well aligned in the verb system than in the noun system. However, in parallel with the course of human language development, if mult
    
[^17]: 分析特征相互作用揭开随机森林的黑匣子

    Opening the random forest black box by the analysis of the mutual impact of features. (arXiv:2304.02490v1 [cs.LG])

    [http://arxiv.org/abs/2304.02490](http://arxiv.org/abs/2304.02490)

    本文提出了两种新方法， MIR和MFI，这些方法基于特征之间的相互影响，超越了传统的变量重要性度量方法，并可生成p值选择相关和重要的特征。

    

    随机森林是一种流行的高维数据分析的机器学习方法，因为其灵活性并可提供变量重要性度量以选择相关特征。但是，特征之间的复杂关系通常不考虑选择，因此也被忽略了对分析样本的表征。本文提出了两种新方法，专注于随机森林中特征的相互影响。 Mutual forest impact（MFI）是一个关系参数，评估特征与结果之间的相互关联性，因此超越了相关系数分析。 Mutual impurity reduction（MIR）是一种重要性度量，它将这种关系参数与各个特征的重要性相结合。 MIR和MFI与测试程序一起实现，生成p值以选择相关和重要的特征。将其应用于各种模拟数据集，并进行比较。

    Random forest is a popular machine learning approach for the analysis of high-dimensional data because it is flexible and provides variable importance measures for the selection of relevant features. However, the complex relationships between the features are usually not considered for the selection and thus also neglected for the characterization of the analysed samples. Here we propose two novel approaches that focus on the mutual impact of features in random forests. Mutual forest impact (MFI) is a relation parameter that evaluates the mutual association of the featurs to the outcome and, hence, goes beyond the analysis of correlation coefficients. Mutual impurity reduction (MIR) is an importance measure that combines this relation parameter with the importance of the individual features. MIR and MFI are implemented together with testing procedures that generate p-values for the selection of related and important features. Applications to various simulated data sets and the comparis
    
[^18]: 一种基于动态贝叶斯优化的积极推荐人机交互实验系统

    A dynamic Bayesian optimized active recommender system for curiosity-driven Human-in-the-loop automated experiments. (arXiv:2304.02484v1 [cs.LG])

    [http://arxiv.org/abs/2304.02484](http://arxiv.org/abs/2304.02484)

    本文开发了一种基于贝叶斯优化的积极推荐人机交互实验系统，利用人类反馈实时塑造目标，并以铁电薄膜的压电响应力谱为例展示了该框架的应用。

    

    过去十年中，利用积极学习方法优化实验材料的合成和表征已经越来越流行，例如通过在同步辐射下对组合合金进行衍射测量，或者利用自动化合成机器人在化学空间中搜索钙钛矿。在几乎所有情况下，优化的目标物性是事先定义好的，操作期间的人类反馈有限。与此相反，我们提出了一种新型的人机交互实验流程，通过基于贝叶斯优化的积极推荐系统（BOARS）实时塑造目标，并且利用人类反馈。我们展示了这种框架在铁电薄膜的压电响应力谱预先获取数据和原子力显微镜实时优化对称压电响应幅度滞回特征寻找中的应用实例。发现这样的特征出现了。

    Optimization of experimental materials synthesis and characterization through active learning methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined apriori with limited human feedback during operation. In contrast, here we present the development of a new type of human in the loop experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly, employing human feedback. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and then implement this in real time on an atomic force microscope, where the optimization proceeds to find symmetric piezoresponse amplitude hysteresis loops. It is found that such features appear
    
[^19]: 量子模仿学习

    Quantum Imitation Learning. (arXiv:2304.02480v1 [quant-ph])

    [http://arxiv.org/abs/2304.02480](http://arxiv.org/abs/2304.02480)

    本论文提出了量子模仿学习（QIL）以加速学习，其中通过采用变分量子电路（VQC）代替DNN来表示策略，分别开发了量子行为克隆（Q-BC）和量子生成对抗模仿学习（Q-GAIL）两种QIL算法，实验表明QIL可以实现至少与其经典对应物相当的结果，并且基于VQC的策略表示优于一些现有的量子RL算法。

    

    尽管在解决各种复杂决策问题方面取得了卓越的成功，但使用深度神经网络（DNN）来训练模仿学习（IL）算法仍然面临着高计算负担。在本文中，我们提出了一种希望利用量子优势加速IL的量子模仿学习（QIL）。具体而言，我们开发了两种QIL算法，量子行为克隆（Q-BC）和量子生成对抗模仿学习（Q-GAIL）。Q-BC采用负对数似然损失以适应广泛的专家数据情况进行离线训练，而Q-GAIL采用逆强化学习方案进行在线和在线策略，适用于有限的专家数据情况。对于两种QIL算法，我们采用变分量子电路（VQC）代替DNN来表示策略，并通过数据重新上传和缩放参数进行修改以增强表现力。我们首先将经典数据编码为量子状态作为输入，然后使用带有噪声模拟器的VQC进行策略优化。我们的数值实验表明，QIL可以实现至少与其经典对应物相当的结果，并且基于VQC的策略表示优于一些现有的量子RL算法。

    Despite remarkable successes in solving various complex decision-making tasks, training an imitation learning (IL) algorithm with deep neural networks (DNNs) suffers from the high computation burden. In this work, we propose quantum imitation learning (QIL) with a hope to utilize quantum advantage to speed up IL. Concretely, we develop two QIL algorithms, quantum behavioural cloning (Q-BC) and quantum generative adversarial imitation learning (Q-GAIL). Q-BC is trained with a negative log-likelihood loss in an off-line manner that suits extensive expert data cases, whereas Q-GAIL works in an inverse reinforcement learning scheme, which is on-line and on-policy that is suitable for limited expert data cases. For both QIL algorithms, we adopt variational quantum circuits (VQCs) in place of DNNs for representing policies, which are modified with data re-uploading and scaling parameters to enhance the expressivity. We first encode classical data into quantum states as inputs, then perform V
    
[^20]: 全变分噪声对比估计

    Fully Variational Noise-Contrastive Estimation. (arXiv:2304.02473v1 [cs.LG])

    [http://arxiv.org/abs/2304.02473](http://arxiv.org/abs/2304.02473)

    本文提出了一种全变分噪声对比估计方法，可以用于潜变量模型，其中变分自编码器是其中一个特例，可以将真实数据与合成样本分离开来。

    

    本文利用适当评分规则的基本理论，设计了一族可用于潜变量模型的噪声对比估计（NCE）方法。这些方法可以将噪声和数据样本的对比损失函数分别下界为变分贝叶斯中的相应项，因此我们称这个损失函数族为全变分噪声对比估计。其中一个特例是变分自编码器，因此也可以理解为通过适当的分类损失将真实数据与合成样本分离开来。我们进一步讨论了全变分NCE目标函数族中的其他例子，并指出它们在实证行为上的差异。

    By using the underlying theory of proper scoring rules, we design a family of noise-contrastive estimation (NCE) methods that are tractable for latent variable models. Both terms in the underlying NCE loss, the one using data samples and the one using noise samples, can be lower-bounded as in variational Bayes, therefore we call this family of losses fully variational noise-contrastive estimation. Variational autoencoders are a particular example in this family and therefore can be also understood as separating real data from synthetic samples using an appropriate classification loss. We further discuss other instances in this family of fully variational NCE objectives and indicate differences in their empirical behavior.
    
[^21]: 使用基于订单流训练的深度卷积神经网络进行短期波动率预测

    Short-Term Volatility Prediction Using Deep CNNs Trained on Order Flow. (arXiv:2304.02472v1 [q-fin.RM])

    [http://arxiv.org/abs/2304.02472](http://arxiv.org/abs/2304.02472)

    本文提出了一种将市场信息编码为图像并利用卷积神经网络进行短期实现波动率预测的方法，与其他基准模型相比具有更好的表现和潜力。

    

    作为新兴的资产类别，加密货币相比传统的股票市场明显更具波动性。由于其大多数时候是无监管的，流动性通常较低，加密资产的价格在几分钟内就可出现显著变动，这可能会导致巨额损失。在本文中，我们采用将市场信息编码成图像并利用卷积神经网络进行短期实现波动率预测的方法。然后，我们将所提出的编码和相应的模型的表现与其他基准模型进行比较。实验结果表明，使用卷积神经网络作为预测模型的市场数据表示方法有潜力更好地捕捉市场动态并实现更好的波动率预测。

    As a newly emerged asset class, cryptocurrency is evidently more volatile compared to the traditional equity markets. Due to its mostly unregulated nature, and often low liquidity, the price of crypto assets can sustain a significant change within minutes that in turn might result in considerable losses. In this paper, we employ an approach for encoding market information into images and making predictions of short-term realized volatility by employing Convolutional Neural Networks. We then compare the performance of the proposed encoding and corresponding model with other benchmark models. The experimental results demonstrate that this representation of market data with a Convolutional Neural Network as a predictive model has the potential to better capture the market dynamics and a better volatility prediction.
    
[^22]: 根据数据的维度鲁棒性选择特征

    Selecting Features by their Resilience to the Curse of Dimensionality. (arXiv:2304.02455v1 [cs.LG])

    [http://arxiv.org/abs/2304.02455](http://arxiv.org/abs/2304.02455)

    该研究提出了一种新的特征选择方法，通过识别能够区分不同大小数据子集的特征来降低高维数据的复杂性。实验表明，该方法具有竞争力，并通常优于其他已有的特征选择方法。此外，该方法可扩展到由数百万数据点组成的数据集。

    

    真实世界中的数据集通常维度很高，并受到维度诅咒的影响，这阻碍了它们的可理解性和可解释性。为了降低复杂度，特征选择旨在识别对于学习数据至关重要的特征。虽然相关性和成对相似性的度量通常被使用，但维度诅咒很少被纳入到选择特征的过程中。本文提出了一种新的方法，通过识别能够区分不同大小数据子集的特征来降低维度诅咒。通过调整最近关于计算内在维度的工作，我们的方法能够选择能够区分数据的特征，并因此减弱维度诅咒。我们的实验表明，我们的方法具有竞争力，并通常优于成熟的特征选择方法。此外，我们提出了一个近似方法，使我们的方法可扩展到由数百万数据点组成的数据集。我们的研究结果表明，特征强度方法更加鲁棒，选择的特征更加适用于高维数据集。

    Real-world datasets are often of high dimension and effected by the curse of dimensionality. This hinders their comprehensibility and interpretability. To reduce the complexity feature selection aims to identify features that are crucial to learn from said data. While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features. Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes. By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality. Our experiments show that our method is competitive and commonly outperforms established feature selection methods. Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points. Our findings suggest that fea
    
[^23]: 分布式梯度下降最大化法解决复合非凸强凹极小极大问题

    Decentralized gradient descent maximization method for composite nonconvex strongly-concave minimax problems. (arXiv:2304.02441v1 [math.OC])

    [http://arxiv.org/abs/2304.02441](http://arxiv.org/abs/2304.02441)

    本文提出了一种用于解决分布式非凸强凹极小极大结构优化问题的方法，并在这种新颖的方法下，成功解决了可以在最小化和最大化变量上都包含凸非光滑项的复合非凸强凹极小极大问题；理论证明了本算法具有高概率的次线性收敛速度。

    

    极小极大问题近年来备受关注。为了解决分布式非凸强凹极小极大结构优化问题，研究者们尝试了一些努力，但是它们都局限于最多对极大变量施加一个约束的光滑问题。本文第一次尝试解决可以在最小化和最大化变量上都包含凸非光滑项的复合非凸强凹极小极大问题。我们的算法基于一种新颖的分布式极小极大问题重新表述的形式，该形式引入一个乘子来吸收双重共识约束。消除双重共识约束使得最具攻击性的（即本地最大化而不是梯度上升步骤）双重更新变得可能，有助于采用更大的原始步长和更好的复杂性结果。此外，将非光滑性和对双变量上的一致性进行分离，有助于分析分布式算法；因此我们的算法可以应用于更广泛的非凸强凹极小极大问题中。我们理论上证明了，在某些温和的假设下，我们的算法具有高概率的次线性收敛速度。数值仿真证明了我们的方法在收敛速度、解决方案质量和鲁棒性方面的优越性，与现有方法相比。

    Minimax problems have recently attracted a lot of research interests. A few efforts have been made to solve decentralized nonconvex strongly-concave (NCSC) minimax-structured optimization; however, all of them focus on smooth problems with at most a constraint on the maximization variable. In this paper, we make the first attempt on solving composite NCSC minimax problems that can have convex nonsmooth terms on both minimization and maximization variables. Our algorithm is designed based on a novel reformulation of the decentralized minimax problem that introduces a multiplier to absorb the dual consensus constraint. The removal of dual consensus constraint enables the most aggressive (i.e., local maximization instead of a gradient ascent step) dual update that leads to the benefit of taking a larger primal stepsize and better complexity results. In addition, the decoupling of the nonsmoothness and consensus on the dual variable eases the analysis of a decentralized algorithm; thus our
    
[^24]: 解释多模态数据融合：野区地图制作中的遮挡分析

    Explaining Multimodal Data Fusion: Occlusion Analysis for Wilderness Mapping. (arXiv:2304.02407v1 [cs.CV])

    [http://arxiv.org/abs/2304.02407](http://arxiv.org/abs/2304.02407)

    本研究提出了一个用于多模态数据融合的深度学习框架，采用可解释的机器学习方法来研究模态的影响，结果显示在野区地图制作任务中，利用土地覆盖和夜间光数据能够大大提高模型准确性。

    

    早在很久以前人们就发现，在一个共同的潜在空间中共同利用多模态输入数据的互补特征是有益的。然而，每种模态对模型决策的影响仍然令人困惑。本研究提出了一种用于多模态地球观测数据的模态级解释的深度学习框架，该框架利用了可解释的机器学习方法，即遮挡敏感性，并研究了在早期融合情况下模态的影响。我们表明，野区地图制作这一任务很大程度上受益于诸如土地覆盖和夜间光数据等辅助数据。

    Jointly harnessing complementary features of multi-modal input data in a common latent space has been found to be beneficial long ago. However, the influence of each modality on the models decision remains a puzzle. This study proposes a deep learning framework for the modality-level interpretation of multimodal earth observation data in an end-to-end fashion. While leveraging an explainable machine learning method, namely Occlusion Sensitivity, the proposed framework investigates the influence of modalities under an early-fusion scenario in which the modalities are fused before the learning process. We show that the task of wilderness mapping largely benefits from auxiliary data such as land cover and night time light data.
    
[^25]: AutoRL超参数景观

    AutoRL Hyperparameter Landscapes. (arXiv:2304.02396v1 [cs.LG])

    [http://arxiv.org/abs/2304.02396](http://arxiv.org/abs/2304.02396)

    本文提出了一种方法，在训练期间多次建立和分析AutoRL超参数的景观，证明代表算法（DQN和SAC）在不同环境下的超参数景观会随时间而变化。

    

    强化学习（RL）在取得令人瞩目成果的同时，其超参数对性能的影响限制了其应用范围。这经常使得在实践中难以获得良好的结果。自动化RL（AutoRL）解决了这个难题，但有关超参数优化（HPO）方法在搜索最佳配置时所遍历的超参数景观动态变化的信息很少。鉴于现有AutoRL方法动态调整超参数配置的情况，我们提出了一种方法，在训练期间不仅在一个时间点，而且在多个时间点上建立和分析这些超参数景观。针对关于这种动态AutoRL方法合法性的一个重要开放问题，我们提供了充分的证据，表明在不同种类的环境（Cartpole和Pendulum）中，来自RL文献的代表算法（DQN和SAC）的超参数景观会随时间而强烈变化。

    Although Reinforcement Learning (RL) has shown to be capable of producing impressive results, its use is limited by the impact of its hyperparameters on performance. This often makes it difficult to achieve good results in practice. Automated RL (AutoRL) addresses this difficulty, yet little is known about the dynamics of the hyperparameter landscapes that hyperparameter optimization (HPO) methods traverse in search of optimal configurations. In view of existing AutoRL approaches dynamically adjusting hyperparameter configurations, we propose an approach to build and analyze these hyperparameter landscapes not just for one point in time but at multiple points in time throughout training. Addressing an important open question on the legitimacy of such dynamic AutoRL approaches, we provide thorough empirical evidence that the hyperparameter landscapes strongly vary over time across representative algorithms from RL literature (DQN and SAC) in different kinds of environments (Cartpole and
    
[^26]: DRAC: 使用超广角光学相干断层扫描血管造影图像的糖尿病视网膜病变分析挑战

    DRAC: Diabetic Retinopathy Analysis Challenge with Ultra-Wide Optical Coherence Tomography Angiography Images. (arXiv:2304.02389v1 [eess.IV])

    [http://arxiv.org/abs/2304.02389](http://arxiv.org/abs/2304.02389)

    DRAC是一个用于超广角光学相干断层扫描血管造影图像的糖尿病视网膜病变分析挑战。该挑战包括三个任务：DR损伤分割、图像质量评估和DR分级，分别得到了来自地理上多样化的11个、12个和13个团队的积极响应。

    

    计算机辅助自动分析糖尿病视网膜病变（DR）对减少视力丧失和失明的风险具有重要意义，但缺乏公开可用的模型开发和评估基准。超广角光学相干断层扫描血管造影（UW-OCTA）是DR诊断系统中一种非侵入性和安全的成像模式。为了促进进一步的研究和使用UW-OCTA图像进行糖尿病视网膜病变分析的科学基准制定，我们与第25届医学图像计算和计算机辅助干预国际会议（MICCAI 2022）联合组织了一个名为“DRAC-Diabetic Retinopathy Analysis Challenge”的挑战比赛。该挑战包括三个任务：DR损伤分割、图像质量评估和DR分级。科学界积极响应该挑战，并从地理上不同的机构提交了11个、12个和13个团队提供的这三个任务的不同解决方案。

    Computer-assisted automatic analysis of diabetic retinopathy (DR) is of great importance in reducing the risks of vision loss and even blindness. Ultra-wide optical coherence tomography angiography (UW-OCTA) is a non-invasive and safe imaging modality in DR diagnosis system, but there is a lack of publicly available benchmarks for model development and evaluation. To promote further research and scientific benchmarking for diabetic retinopathy analysis using UW-OCTA images, we organized a challenge named "DRAC - Diabetic Retinopathy Analysis Challenge" in conjunction with the 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2022). The challenge consists of three tasks: segmentation of DR lesions, image quality assessment and DR grading. The scientific community responded positively to the challenge, with 11, 12, and 13 teams from geographically diverse institutes submitting different solutions in these three tasks, respectively. This p
    
[^27]: 神经网络解释方法有多好？一个定量基准测试。

    How good Neural Networks interpretation methods really are? A quantitative benchmark. (arXiv:2304.02383v1 [cs.LG])

    [http://arxiv.org/abs/2304.02383](http://arxiv.org/abs/2304.02383)

    本论文提出了一种定量基准测试方法来评估深度学习模型的解释方法，旨在解决对基于视觉评估方法引入的假阳性偏见的关注。通过构建具有非线性可分离类别和逐渐增加的伪特征数据集的测试，为神经网络解释方法提供了量化标准。

    

    唯有通过凸显模型认为相关的特征来解释深度学习模型决策的观点显著增加。这些 Saliency Maps（SMs）用于高度非线性问题，超越了线性特征选择 (FS) 方法的局限。然而，SM 等基于梯度的特征归因方法的可靠性主要是通过定性 (视觉上) 评估的，缺乏定量基准测试，部分原因是缺乏图像数据上的定义性标准。本文提出了神经网络 (NNs) 解释方法的合成定量基准测试，并就此目的构建了具有非线性可分离类别和逐渐增加的伪特征数据集。我们也将这些方法与传统的 FS 方法进行了比较。

    Saliency Maps (SMs) have been extensively used to interpret deep learning models decision by highlighting the features deemed relevant by the model. They are used on highly nonlinear problems, where linear feature selection (FS) methods fail at highlighting relevant explanatory variables. However, the reliability of gradient-based feature attribution methods such as SM has mostly been only qualitatively (visually) assessed, and quantitative benchmarks are currently missing, partially due to the lack of a definite ground truth on image data. Concerned about the apophenic biases introduced by visual assessment of these methods, in this paper we propose a synthetic quantitative benchmark for Neural Networks (NNs) interpretation methods. For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings. We also compare these methods to conventional approaches such 
    
[^28]: 机器学习模型的物理启发式可解释性研究

    Physics-Inspired Interpretability Of Machine Learning Models. (arXiv:2304.02381v1 [cs.LG])

    [http://arxiv.org/abs/2304.02381](http://arxiv.org/abs/2304.02381)

    本文提出了一种以能量景观方法为启发的机器学习模型可解释性研究方法，可以识别决策的驱动因素，有助于解决机器学习模型在高度敏感领域应用的难题。

    

    机器学习模型的决策解释能力一直是限制其在高度敏感领域如医学、网络安全或自动驾驶中广泛应用的主要障碍之一。本文提出了一种新颖的方法，受物理学领域的能量景观研究方法启发，以识别输入数据的相关特征以促进模型决策。通过识别损失景观局部极小值组中的守恒权重，我们可以确定模型决策的驱动因素。在分子科学中存在类似的思想，使用坐标不变量或有序参数来确定分子的关键特征。然而，在机器学习损失景观中没有这样的方法。本文将展示能量景观方法在机器学习模型中的适用性，并举例说明其应用。

    The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both 
    
[^29]: 二维瑞利-贝纳德对流的有效控制：仅需不变的多智能体强化学习方法。

    Effective control of two-dimensional Rayleigh--B\'enard convection: invariant multi-agent reinforcement learning is all you need. (arXiv:2304.02370v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.02370](http://arxiv.org/abs/2304.02370)

    本论文应用基于不变多智能体强化学习（MARL）的深度强化学习（DRL）方法，实现了对二维瑞利-贝纳德对流的有效控制。通过利用局部性和平移不变性，MARL所获得的控制法则不仅具有较好的性能，而且具有良好的应用前景。

    

    瑞利-贝纳德对流是几种工业和地球科学流动中的一个常见现象，从基本流体力学的角度也是一个研究充分的系统。然而，通过传统的控制理论方法控制瑞利-贝纳德对流，例如通过调节规范瑞利-贝纳德对流形态下底板加热的空间分布，仍然是一个具有挑战性的主题。在本研究中，我们应用深度强化学习（DRL）来控制瑞利-贝纳德对流。我们展示了通过利用内在于宽通道内的瑞利-贝纳德对流的局部性和平移不变性的多智能体不变性强化学习（MARL）来获取有效的瑞利-贝纳德对流控制。应用于瑞利-贝纳德对流的MARL框架允许增加控制段的数量，而不会遇到因naive DRL动作尺寸维数增加而导致的维度灾难。这得益于MARL能够重复使用在不同区域生成的知识，从而大大减少训练时间，并形成有效收敛的控制策略。我们的结果表明了所提出的MARL方法在瑞利-贝纳德对流控制中的有效性，为在工业和地球科学流动中的潜在应用铺平了道路。

    Rayleigh-B\'enard convection (RBC) is a recurrent phenomenon in several industrial and geoscience flows and a well-studied system from a fundamental fluid-mechanics viewpoint. However, controlling RBC, for example by modulating the spatial distribution of the bottom-plate heating in the canonical RBC configuration, remains a challenging topic for classical control-theory methods. In the present work, we apply deep reinforcement learning (DRL) for controlling RBC. We show that effective RBC control can be obtained by leveraging invariant multi-agent reinforcement learning (MARL), which takes advantage of the locality and translational invariance inherent to RBC flows inside wide channels. The MARL framework applied to RBC allows for an increase in the number of control segments without encountering the curse of dimensionality that would result from a naive increase in the DRL action-size dimension. This is made possible by the MARL ability for re-using the knowledge generated in differe
    
[^30]: 使用U-Net在CT序列中分割全骨髓照射的计划靶体积

    Segmentation of Planning Target Volume in CT Series for Total Marrow Irradiation Using U-Net. (arXiv:2304.02353v1 [cs.CV])

    [http://arxiv.org/abs/2304.02353](http://arxiv.org/abs/2304.02353)

    本文介绍了使用U-Net架构进行全骨髓和淋巴结照射治疗计划靶体积分割的深度学习自动轮廓方法，使精确定位成为可能。

    

    放射治疗（RT）是治疗各种癌症，包括急性淋巴细胞白血病（ALL）和急性髓性白血病（AML）的重要组成部分。精确定位危及器官（OARs）和治疗区域对于有效的治疗计划至关重要。调强放射治疗（IMRT）技术，如全骨髓照射（TMI）和全骨髓和淋巴结照射（TMLI），与全身照射（TBI）相比提供了更精确的放射治疗递送。然而，这些技术需要放射肿瘤学家在计算机断层扫描（CT）中耗时手动分割结构。本文提出了一种基于深度学习的自动轮廓方法，使用U-Net架构对TMLI治疗计划靶体积（PTV）进行分割。我们在2011年至2021年期间在Humanitas研究医院接受TMLI治疗的100名患者的数据集上训练并比较了两种具有不同损失函数的分割模型。

    Radiotherapy (RT) is a key component in the treatment of various cancers, including Acute Lymphocytic Leukemia (ALL) and Acute Myelogenous Leukemia (AML). Precise delineation of organs at risk (OARs) and target areas is essential for effective treatment planning. Intensity Modulated Radiotherapy (IMRT) techniques, such as Total Marrow Irradiation (TMI) and Total Marrow and Lymph node Irradiation (TMLI), provide more precise radiation delivery compared to Total Body Irradiation (TBI). However, these techniques require time-consuming manual segmentation of structures in Computerized Tomography (CT) scans by the Radiation Oncologist (RO). In this paper, we present a deep learning-based auto-contouring method for segmenting Planning Target Volume (PTV) for TMLI treatment using the U-Net architecture. We trained and compared two segmentation models with two different loss functions on a dataset of 100 patients treated with TMLI at the Humanitas Research Hospital between 2011 and 2021. Despi
    
[^31]: 修正普遍解缠度量中的错误

    Correcting Flaws in Common Disentanglement Metrics. (arXiv:2304.02335v1 [cs.LG])

    [http://arxiv.org/abs/2304.02335](http://arxiv.org/abs/2304.02335)

    本文提出了两个新的解缠指标，用于修正现有指标的两个缺陷，并通过将组合泛化任务作为分类问题来衡量编码器的解缠能力。新指标与组合泛化任务的相关性最强。

    

    近年来，越来越多的人对学习解缠表示产生了浓厚的兴趣，其中不同的特征，如大小或形状，由不同的神经元表示。量化特定表示解缠的程度并非易事，已经提出了多种指标。在本文中，我们确定了现有指标的两个缺陷，这意味着它们可以将一个仍然纠缠的模型评分高，并且我们提出了两个新指标，以纠正这些问题。然后我们考虑了组合泛化任务。与以往的工作不同，我们将其视为一个分类问题，这使得我们可以用它来衡量编码器的解缠能力，而不依赖于解码器。我们展示了这个任务的表现通常相当差，与大多数解缠度量相关，最强烈地与我们新提出的度量相关。

    Recent years have seen growing interest in learning disentangled representations, in which distinct features, such as size or shape, are represented by distinct neurons. Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed. In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems. We then consider the task of compositional generalization. Unlike prior works, we treat this as a classification problem, which allows us to use it to measure the disentanglement ability of the encoder, without depending on the decoder. We show that performance on this task is (a) generally quite poor, (b) correlated with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics.
    
[^32]: 通过被动滤波剪枝实现高效CNN

    Efficient CNNs via Passive Filter Pruning. (arXiv:2304.02319v1 [cs.LG])

    [http://arxiv.org/abs/2304.02319](http://arxiv.org/abs/2304.02319)

    本论文提出了一种被动滤波剪枝方法来达到高效CNN的目的，解决了高剪枝率下逐元素范数方法存在的性能下降问题。

    

    卷积神经网络在各种应用中已经展示出最先进的性能，但是由于对高计算复杂度和存储器的要求，CNN是资源密集型的。最近实现CNN计算效率的努力包括滤波剪枝方法，其根据滤波器的“重要性”消除CNN中的某些滤波器。大多数现有的滤波剪枝方法要么是“主动型”，即使用数据集和生成特征映射来量化滤波器的重要性；要么是“被动型”，即使用滤波器的逐元素范数计算滤波器的重要性而不涉及数据。在高剪枝率下，即需要从网络中剪枝大量的滤波器时，逐元素范数方法消除相对较小的范数滤波器而不考虑滤波器在产生节点输出方面的重要性，导致性能下降。为了解决这个问题，我们提出了一种被动滤波剪枝方法。

    Convolutional neural networks (CNNs) have shown state-of-the-art performance in various applications. However, CNNs are resource-hungry due to their requirement of high computational complexity and memory storage. Recent efforts toward achieving computational efficiency in CNNs involve filter pruning methods that eliminate some of the filters in CNNs based on the \enquote{importance} of the filters. The majority of existing filter pruning methods are either "active", which use a dataset and generate feature maps to quantify filter importance, or "passive", which compute filter importance using entry-wise norm of the filters without involving data. Under a high pruning ratio where large number of filters are to be pruned from the network, the entry-wise norm methods eliminate relatively smaller norm filters without considering the significance of the filters in producing the node output, resulting in degradation in the performance. To address this, we present a passive filter pruning me
    
[^33]: 基于不变因果学习算法的应用于观测数据的一步

    A step towards the applicability of algorithms based on invariant causal learning on observational data. (arXiv:2304.02286v1 [cs.LG])

    [http://arxiv.org/abs/2304.02286](http://arxiv.org/abs/2304.02286)

    该论文提出了一种有效的方法以解决不变学习算法在观测数据和实际应用中的问题。其中，该算法基于多环境测试，使用多个训练环境来发现因果关系，并提供有良好结果的因果预测器。

    

    机器学习可以从因果关系发现中获益，以便进行解释，并从因果推断中获益以进行推广。本文提出了一种方法，以有效的方式生成多个训练环境，为不变學習算法提供服务，该算法的一些是专注于因果发现，而另一些则直接提供有良好结果的因果预测器。

    Machine learning can benefit from causal discovery for interpretation and from causal inference for generalization. In this line of research, a few invariant learning algorithms for out-of-distribution (OOD) generalization have been proposed by using multiple training environments to find invariant relationships. Some of them are focused on causal discovery as Invariant Causal Prediction (ICP), which finds causal parents of a variable of interest, and some directly provide a causal optimal predictor that generalizes well in OOD environments as Invariant Risk Minimization (IRM). This group of algorithms works under the assumption of multiple environments that represent different interventions in the causal inference context. Those environments are not normally available when working with observational data and real-world applications. Here we propose a method to generate them in an efficient way. We assess the performance of this unsupervised learning problem by implementing ICP on simu
    
[^34]: 重新思考图形后门攻击中注入触发器的位置

    Rethinking the Trigger-injecting Position in Graph Backdoor Attack. (arXiv:2304.02277v1 [cs.LG])

    [http://arxiv.org/abs/2304.02277](http://arxiv.org/abs/2304.02277)

    论文研究了在图神经网络中的背门攻击，发现在样本的最不重要区域中注入触发器的背门攻击效果更好，对该现象进行了解释。

    

    后门攻击已经被证明是机器学习模型的安全威胁。传统的后门攻击意图将后门功能注入模型中，使得带有预定义后门触发器的输入能够出现异常的表现，但是该模型在干净的输入上仍然能够达到最先进的性能。虽然已经有一些关于图神经网络（GNN）背门攻击的研究，但是在图领域中的后门触发器大多被注入到样本的随机位置。尚未有研究分析和解释在样本的最重要或最不重要的区域注入触发器的背门攻击的性能，我们将其称为触发注入策略MIAS和LIAS。我们的研究结果表明，一般来说，LIAS的表现更好，并且LIAS和MIAS表现之间的差异可能是显著的。此外，我们通过解释说明了这两种策略的相似（更好）的攻击性能。

    Backdoor attacks have been demonstrated as a security threat for machine learning models. Traditional backdoor attacks intend to inject backdoor functionality into the model such that the backdoored model will perform abnormally on inputs with predefined backdoor triggers and still retain state-of-the-art performance on the clean inputs. While there are already some works on backdoor attacks on Graph Neural Networks (GNNs), the backdoor trigger in the graph domain is mostly injected into random positions of the sample. There is no work analyzing and explaining the backdoor attack performance when injecting triggers into the most important or least important area in the sample, which we refer to as trigger-injecting strategies MIAS and LIAS, respectively. Our results show that, generally, LIAS performs better, and the differences between the LIAS and MIAS performance can be significant. Furthermore, we explain these two strategies' similar (better) attack performance through explanation
    
[^35]: 稀疏线性回归的最优草图界限

    Optimal Sketching Bounds for Sparse Linear Regression. (arXiv:2304.02261v1 [cs.DS])

    [http://arxiv.org/abs/2304.02261](http://arxiv.org/abs/2304.02261)

    本文研究稀疏线性回归的最优草图界限，表明稀疏恢复比稀疏回归更容易草图，对于稀疏l_p回归，其上界包括l_2的额外添加项。

    

    本文研究了各种损失函数下k-稀疏线性回归的遗忘草图，如l_p范数或广泛的hinge-like损失函数类，其中包括logistic和ReLU损失。我们表明，对于稀疏l_2范数回归，存在一个遗忘草图分布，具有Θ(klog(d/k)/ε^2)排，这是紧的，直到一个常数因子。这扩展到l_p损失，上界还有一个附加的O(klog(k/ε)/ε^2)项。这建立了与相关的稀疏恢复问题的出人意料的分离，这是稀疏回归的一个重要特例。对于这个问题，在l_2范数下，我们观察到一个O(klog(d)/ε+klog(k/ε)/ε^2)行的上界，表明稀疏恢复比稀疏回归更容易草图。对于包括稀疏logistic和稀疏ReLU回归在内的hinge-like损失函数下的稀疏回归，我们给出了与之对应的最优草图界。

    We study oblivious sketching for $k$-sparse linear regression under various loss functions such as an $\ell_p$ norm, or from a broad class of hinge-like loss functions, which includes the logistic and ReLU losses. We show that for sparse $\ell_2$ norm regression, there is a distribution over oblivious sketches with $\Theta(k\log(d/k)/\varepsilon^2)$ rows, which is tight up to a constant factor. This extends to $\ell_p$ loss with an additional additive $O(k\log(k/\varepsilon)/\varepsilon^2)$ term in the upper bound. This establishes a surprising separation from the related sparse recovery problem, which is an important special case of sparse regression. For this problem, under the $\ell_2$ norm, we observe an upper bound of $O(k \log (d)/\varepsilon + k\log(k/\varepsilon)/\varepsilon^2)$ rows, showing that sparse recovery is strictly easier to sketch than sparse regression. For sparse regression under hinge-like loss functions including sparse logistic and sparse ReLU regression, we giv
    
[^36]: 《解开结构与风格的纽带：通过诱导文档层次结构来检测新闻中的政治偏见》

    Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy. (arXiv:2304.02247v1 [cs.CL])

    [http://arxiv.org/abs/2304.02247](http://arxiv.org/abs/2304.02247)

    本文提出了一种通过文档层次结构诱导来检测新闻中的政治偏见的方法，该方法克服了过拟合和有限的普适性，展现了更好的鲁棒性和准确性。

    

    本文针对新闻文章中政治偏见检测方面的重要差距进行研究。先前进行监督式文档分类的工作可能会偏向各网站的写作风格，导致过拟合和有限的普适性。我们的方法通过考虑句子级语义和文档级修辞结构来克服这一限制，从而产生一种更强大和不受风格影响的检测政治偏见的方法。我们引入了一种新颖的多头分层注意力模型，通过各种注意力头的不同集合有效地编码长文档的结构。我们展示了我们的方法克服了这种域依赖性，并表现出比先前方法更好的鲁棒性和准确性。进一步的分析表明，我们的模型能够捕捉到新闻中常用的话语结构。

    We address an important gap in detection of political bias in news articles. Previous works that perform supervised document classification can be biased towards the writing style of each news outlet, leading to overfitting and limited generalizability. Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles. We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads. While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet. We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy. Further analysis demonstrates the ability of our model to capture the discourse structures commonly used in the jou
    
[^37]: 复制学习中的列表和证明复杂度

    List and Certificate Complexities in Replicable Learning. (arXiv:2304.02240v1 [cs.LG])

    [http://arxiv.org/abs/2304.02240](http://arxiv.org/abs/2304.02240)

    研究复制学习算法的列表和证明复杂度，提出列表复制和证书复制的概念，设计了可行的方法，并在某些学习问题上建立了最优解。

    

    我们研究了可复制学习算法。我们希望设计算法，即使不同的运行观察到来自未知数据分布的不同样本集，也能在多次运行中输出相同的规范模型。一般情况下，这种强的复制性并不可行。因此，我们考虑了两个可行的复制概念，称为列表复制和证书复制。直观地，这些概念捕捉了（无）复制的程度。我们设计了某些学习问题的算法，这些算法在列表和证书复杂度上是最优的。我们建立了匹配的不可能结果。

    We investigate replicable learning algorithms. Ideally, we would like to design algorithms that output the same canonical model over multiple runs, even when different runs observe a different set of samples from the unknown data distribution. In general, such a strong notion of replicability is not achievable. Thus we consider two feasible notions of replicability called list replicability and certificate replicability. Intuitively, these notions capture the degree of (non) replicability. We design algorithms for certain learning problems that are optimal in list and certificate complexity. We establish matching impossibility results.
    
[^38]: JPEG压缩图像可以绕过对抗AI编辑的保护措施

    JPEG Compressed Images Can Bypass Protections Against AI Editing. (arXiv:2304.02234v1 [cs.LG])

    [http://arxiv.org/abs/2304.02234](http://arxiv.org/abs/2304.02234)

    该论文指出微小但有效的图像扰动方法并不能抵御JPEG压缩，因此不能有效保护图像免受恶意编辑和深度伪造攻击，建议采用其他方法进行保护。

    

    最近的文本生成图像模型使得高质量图像的编辑或生成变得更加容易。然而，其易用性引发了对恶意编辑或深度伪造的担忧。为防止传播模型生成真实图像，我们提出了微不可见的扰动作为保护图像免受恶意攻击的手段。然而，我们发现这些扰动不具有鲁棒性，不能经受JPEG压缩的考验，这是一个主要的弱点，因为JPEG具有普遍的使用和可获取性。我们讨论了加性微不可见扰动鲁棒性的重要性，鼓励采用其他方法来保护图像免受攻击。

    Recently developed text-to-image diffusion models make it easy to edit or create high-quality images. Their ease of use has raised concerns about the potential for malicious editing or deepfake creation. Imperceptible perturbations have been proposed as a means of protecting images from malicious editing by preventing diffusion models from generating realistic images. However, we find that the aforementioned perturbations are not robust to JPEG compression, which poses a major weakness because of the common usage and availability of JPEG. We discuss the importance of robustness for additive imperceptible perturbations and encourage alternative approaches to protect images against editing.
    
[^39]: 通过近似消息传递的混合回归（Mixed Regression via Approximate Message Passing）

    Mixed Regression via Approximate Message Passing. (arXiv:2304.02229v1 [stat.ML])

    [http://arxiv.org/abs/2304.02229](http://arxiv.org/abs/2304.02229)

    本文提出了一种新的近似消息传递算法来解决在广义线性模型中的回归问题，该算法适用于混合线性回归、最大仿射回归和专家混合模型等问题。

    

    本文研究了广义线性模型（GLM）中具有多个信号和潜变量的回归问题。该模型被称为矩阵GLM，涵盖了许多在统计学习中广泛研究的问题，包括混合线性回归、最大仿射回归和专家混合模型等。我们提出了一种新的近似消息传递（AMP）算法来估计矩阵GLM中的信号和潜变量，并在高维极限中对其性能进行了严格的表征。该表征是通过状态演化递归来计算的，从而可以精确计算渐近性能度量，例如信噪比下降阈值（threshold）。

    We study the problem of regression in a generalized linear model (GLM) with multiple signals and latent variables. This model, which we call a matrix GLM, covers many widely studied problems in statistical learning, including mixed linear regression, max-affine regression, and mixture-of-experts. In mixed linear regression, each observation comes from one of $L$ signal vectors (regressors), but we do not know which one; in max-affine regression, each observation comes from the maximum of $L$ affine functions, each defined via a different signal vector. The goal in all these problems is to estimate the signals, and possibly some of the latent variables, from the observations. We propose a novel approximate message passing (AMP) algorithm for estimation in a matrix GLM and rigorously characterize its performance in the high-dimensional limit. This characterization is in terms of a state evolution recursion, which allows us to precisely compute performance measures such as the asymptotic 
    
[^40]: 本地固有维度熵。

    Local Intrinsic Dimensional Entropy. (arXiv:2304.02223v1 [cs.LG])

    [http://arxiv.org/abs/2304.02223](http://arxiv.org/abs/2304.02223)

    本文提出了一种新的在连续空间中测量熵的方法，称为ID-Entropy，它可以用于多轮数据变换和扭曲，同时可以捕捉数据的维度。

    

    大多数熵测量依赖于概率分布在样本空间X上的展布情况，最大可实现熵与样本空间基数|X|成比例。对于有限|X|，这产生了满足许多重要属性（如对双射的不变性）的强大熵测量，而同样不能满足连续空间的要求（其中|X|=无穷大）。此外，由于R和R^d（d在Z+中）具有相同的基数（来自Cantor的对应论证），基数依赖性熵测量无法编码数据维度。在本文中，我们质疑了对连续空间定义熵测量中基数和分布展布的作用，这些连续空间可以进行多轮变换和扭曲，例如在神经网络中。我们发现如果用分布的局部固有维度的平均值来表示测量熵，被称为ID-Entropy，那么可以作为连续空间的强大熵测量，同时捕捉数据的维度。

    Most entropy measures depend on the spread of the probability distribution over the sample space X, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimen
    
[^41]: 零样本域自适应半监督异常检测

    Zero-shot domain adaptation of anomalous samples for semi-supervised anomaly detection. (arXiv:2304.02221v1 [cs.LG])

    [http://arxiv.org/abs/2304.02221](http://arxiv.org/abs/2304.02221)

    本论文提出了一种适用于SSAD的零样本域自适应方法，以帮助其适应目标域中缺少的异常数据，这是通过引入一个域对抗网络和基于重要性采样的加权损失函数实现的。

    

    半监督异常检测（SSAD）是一种任务，在此任务中，可以使用正常数据和有限数量的异常数据进行训练。在实际情况下，由于在训练阶段很难获得目标域的异常数据，因此SSAD方法不容易适应域偏移。为了解决这个问题，我们提出了一种适用于SSAD的域自适应方法，其中目标域没有可用的异常数据。首先，我们向基于变分自编码器的SSAD模型引入了一个域对抗网络，以获得域不变潜变量。由于解码器不能仅从域不变潜变量重构原始数据，因此我们将解码器建立在域标签之上。为了弥补目标域缺少的异常数据，我们引入了基于重要性采样的加权损失函数来近似理想的损失函数。实验结果表明，所提出的方法有助于使SSAD模型适应目标域。

    Semi-supervised anomaly detection~(SSAD) is a task where normal data and a limited number of anomalous data are available for training. In practical situations, SSAD methods suffer adapting to domain shifts, since anomalous data are unlikely to be available for the target domain in the training phase. To solve this problem, we propose a domain adaptation method for SSAD where no anomalous data are available for the target domain. First, we introduce a domain-adversarial network to a variational auto-encoder-based SSAD model to obtain domain-invariant latent variables. Since the decoder cannot reconstruct the original data solely from domain-invariant latent variables, we conditioned the decoder on the domain label. To compensate for the missing anomalous data of the target domain, we introduce an importance sampling-based weighted loss function that approximates the ideal loss function. Experimental results indicate that the proposed method helps adapt SSAD models to the target domain 
    
[^42]: 关于径向基函数神经网络普适逼近性质的研究

    On the universal approximation property of radial basis function neural networks. (arXiv:2304.02220v1 [cs.LG])

    [http://arxiv.org/abs/2304.02220](http://arxiv.org/abs/2304.02220)

    本论文研究了一种新的径向基函数神经网络类别，证明这些网络能够逼近任何连续多元函数，还讨论了有限个固定中心的RBF网络的逼近条件。

    

    本文研究了一种新的径向基函数神经网络类别，其中平滑因子被替换为位移。我们在激活函数的一定条件下证明了这些网络能够逼近欧几里得空间d维紧致子集上的任何连续多元函数。对于有限个固定中心的RBF网络，我们描述了保证任意精度逼近的条件。

    In this paper we consider a new class of RBF (Radial Basis Function) neural networks, in which smoothing factors are replaced with shifts. We prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional Euclidean space. For RBF networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.
    
[^43]: PIKS：一种通过开放医疗保健数据为政策制定者识别可操作趋势的技术

    PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data. (arXiv:2304.02208v1 [cs.LG])

    [http://arxiv.org/abs/2304.02208](http://arxiv.org/abs/2304.02208)

    PIKS是一种可以高效准确地识别医疗保健数据中异常值的技术，通过快速发现趋势和检测异常值，为政策制定者提供重要的决策支持。

    

    随着要求提高透明度，政府在多个领域包括财政、教育和医疗保健方面发布了更多的数据。有效地探索医疗保健数据构成了一个重大挑战。公共卫生的关键问题包括快速识别和分析趋势以及检测异常值。这可以快速调整政策以应对变化的情况。我们提出了一种有效的异常值检测技术，称为 PIKS（基于修剪的迭代 K 均值亮点搜索），它将迭代 k 均值算法与修剪搜索亮点扫描相结合。我们将此技术应用于识别两个公开可用的医疗保健数据集：纽约州全面规划和研究合作系统和加利福尼亚州全面卫生规划和发展厅。我们将我们的技术与三种现有的异常值检测技术（包括自编码器、孤立森林和深度自回归网络）进行比较，结果表明，在效率和准确性方面，PIKS优于其他技术。我们进一步通过纽约州数据集的案例研究展示了PIKS识别可操作趋势的实用性。

    With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education and healthcare. The efficient exploratory analysis of healthcare data constitutes a significant challenge. Key concerns in public health include the quick identification and analysis of trends, and the detection of outliers. This allows policies to be rapidly adapted to changing circumstances. We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan. We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California's Office of Statewide Health Planning and Development. We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests an
    
[^44]: 用热力图字幕和大语言模型实现深度神经网络自解释性的探索

    Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models. (arXiv:2304.02202v1 [cs.CV])

    [http://arxiv.org/abs/2304.02202](http://arxiv.org/abs/2304.02202)

    本文提出了一个框架，结合模板图像字幕技术和大型语言模型，实现了深度神经网络的自解释性，填补了基于热力图的可解释AI自动化、交互式、可扩展、易于访问的空白。

    

    热力图在解释深度神经网络中得到了广泛应用，特别是在计算机视觉任务中，基于热力图的可解释AI技术是一个经过深入研究的课题。然而，大多数研究都集中于提高生成热力图的质量或发现替代热力图生成技术，而很少有人付出努力使基于热力图的可解释AI自动化、交互式、可扩展、易于访问。为了填补这一空白，我们提出了一个包括两个模块的框架：(1) 上下文建模和(2) 推理。我们提出了一种基于模板的图像字幕方法来进行上下文建模，从热力图和输入数据生成基于文本的上下文信息。推理模块利用大型语言模型结合专业知识提供解释。我们的定性实验证明了我们框架和热力图字幕方法的有效性。所提出的基于模板的热力图字幕方法的代码已在网上公开。

    Heatmaps are widely used to interpret deep neural networks, particularly for computer vision tasks, and the heatmap-based explainable AI (XAI) techniques are a well-researched topic. However, most studies concentrate on enhancing the quality of the generated heatmap or discovering alternate heatmap generation techniques, and little effort has been devoted to making heatmap-based XAI automatic, interactive, scalable, and accessible. To address this gap, we propose a framework that includes two modules: (1) context modelling and (2) reasoning. We proposed a template-based image captioning approach for context modelling to create text-based contextual information from the heatmap and input data. The reasoning module leverages a large language model to provide explanations in combination with specialised knowledge. Our qualitative experiments demonstrate the effectiveness of our framework and heatmap captioning approach. The code for the proposed template-based heatmap captioning approach 
    
[^45]: EigenFold：扩散模型下的生成蛋白质结构预测

    EigenFold: Generative Protein Structure Prediction with Diffusion Models. (arXiv:2304.02198v1 [q-bio.BM])

    [http://arxiv.org/abs/2304.02198](http://arxiv.org/abs/2304.02198)

    EigenFold是一种生成模型，利用扩散模型从蛋白质序列中采样结构分布集合，达到了较高的TMScore并提供了更全面的模型不确定性。它能有效地建模和预测折叠转换蛋白和配体诱导构象变化。

    

    单个结构的蛋白质结构预测已经达到了革命性的准确度，但需要分布式建模范式以捕捉支配生物功能的构象集合和灵活性。为实现这一目标，我们开发了EigenFold，一种扩散生成建模框架，用于从给定的蛋白质序列中采样结构的分布。我们定义了一个扩散过程，将结构建模为谐振子系统，并自然地沿着系统的本征模式诱导出一种级联分辨率生成过程。在最近的CAMEO目标中，EigenFold达到了0.84的中位TMScore，相对于现有方法，提供了更全面的模型不确定性的结构集合。然后我们评估了EigenFold对于折叠转换蛋白和配体诱导构象变化的建模和预测能力。代码可在https://github.com/bjing2016/获得。

    Protein structure prediction has reached revolutionary levels of accuracy on single structures, yet distributional modeling paradigms are needed to capture the conformational ensembles and flexibility that underlie biological function. Towards this goal, we develop EigenFold, a diffusion generative modeling framework for sampling a distribution of structures from a given protein sequence. We define a diffusion process that models the structure as a system of harmonic oscillators and which naturally induces a cascading-resolution generative process along the eigenmodes of the system. On recent CAMEO targets, EigenFold achieves a median TMScore of 0.84, while providing a more comprehensive picture of model uncertainty via the ensemble of sampled structures relative to existing methods. We then assess EigenFold's ability to model and predict conformational heterogeneity for fold-switching proteins and ligand-induced conformational change. Code is available at https://github.com/bjing2016/
    
[^46]: 利用开放式医疗数据构建医疗成本预测模型

    Building predictive models of healthcare costs with open healthcare data. (arXiv:2304.02191v1 [cs.LG])

    [http://arxiv.org/abs/2304.02191](http://arxiv.org/abs/2304.02191)

    利用纽约州 SPARCS 的匿名患者数据，使用机器学习技术预测病人的医疗成本，最好表现的模型使用了决策树，获得了 0.76 的 R-square 值。

    

    由于全球医疗成本的快速上涨，控制医疗成本已成显著的关注点，其关键之一在于价格透明度，病人会选价格较低的医务服务，从而提高效率。这需要数据公开，以及能预测各种病人特征和状况下医疗成本的模型。我们利用机器学习技术开发了一种预测模型来解决这个问题。我们分析了纽约州SPARCS（州级规划和研究合作系统）的2.3百万记录的去身份化病人数据，从病人诊断和特征中构建成本预测模型。我们研究了由稀疏回归和决策树两类模型构成的模型，最终使用深度为10的决策树取得了最佳性能，获得了0.76的R-square值，优于文献报道的值。

    Due to rapidly rising healthcare costs worldwide, there is significant interest in controlling them. An important aspect concerns price transparency, as preliminary efforts have demonstrated that patients will shop for lower costs, driving efficiency. This requires the data to be made available, and models that can predict healthcare costs for a wide range of patient demographics and conditions. We present an approach to this problem by developing a predictive model using machine-learning techniques. We analyzed de-identified patient data from New York State SPARCS (statewide planning and research cooperative system), consisting of 2.3 million records in 2016. We built models to predict costs from patient diagnoses and demographics. We investigated two model classes consisting of sparse regression and decision trees. We obtained the best performance by using a decision tree with depth 10. We obtained an R-square value of 0.76 which is better than the values reported in the literature f
    
[^47]: 机器学习中全球化的公正属性：以非洲健康为例的案例研究

    Globalizing Fairness Attributes in Machine Learning: A Case Study on Health in Africa. (arXiv:2304.02190v1 [cs.LG])

    [http://arxiv.org/abs/2304.02190](http://arxiv.org/abs/2304.02190)

    该论文以非洲卫生领域为案例研究，提出了机器学习中全球化的公正属性的体系，并应用于医疗模式，为促进全球卫生中的公平研究提供了基础和行动的呼吁。

    

    随着机器学习在医疗保健中应用日益增加，有人呼吁在机器学习中实现公平，以了解和缓解这些系统可能带来的伦理问题。公平对非洲的全球卫生具有影响，因为全球南北之间已经存在不公平的权力失衡。本文旨在探讨非洲健康的公平性，并提出了非洲语境下考虑公平性的属性，并勾画了这些属性可能在不同的机器学习医学模式中发挥作用的范围。这项工作为促进全球卫生中的公平研究提供了基础和行动的呼吁。

    With growing machine learning (ML) applications in healthcare, there have been calls for fairness in ML to understand and mitigate ethical concerns these systems may pose. Fairness has implications for global health in Africa, which already has inequitable power imbalances between the Global North and South. This paper seeks to explore fairness for global health, with Africa as a case study. We propose fairness attributes for consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. This work serves as a basis and call for action for furthering research into fairness in global health.
    
[^48]: 一种探索大数据的系统：基于迭代k-means搜索光标的开放医疗数据异常检测

    A system for exploring big data: an iterative k-means searchlight for outlier detection on open health data. (arXiv:2304.02189v1 [cs.LG])

    [http://arxiv.org/abs/2304.02189](http://arxiv.org/abs/2304.02189)

    提出了一种探索大数据的系统，使用搜索光标技术系统地探索多种变量组合并识别异常值，可应用于开放医疗数据分析，识别出一些医院的绩效始终低于同行，并准确地指出具体的临床状况与高于预期的发病率和死亡率有关。

    

    大规模和不断变化的数据集的交互式探索是具有挑战性的，因为底层变量之间的关系可能尚未被完全理解。数据中可能存在值得进一步探索和分析的隐藏趋势和模式。我们提出了一种系统，使用搜索光标技术系统地探索多种变量组合并识别异常值。在数据库文献中使用的分割-应用-组合范式中，应用了迭代的k-means聚类算法来生成特征。异常值被识别为单个值或小簇。这个算法以搜索光标的方式扫过数据集。利用子集扫描技术，将包含异常值的维度与其他维度成对组合，以进一步了解异常值。我们通过分析纽约州发布的开放卫生保健数据来说明这个系统。我们使用迭代的k-means搜索光标后跟子集扫描。可以识别出几个异常趋势，例如识别出一些医院的绩效始终低于同行，并准确地指出具体的临床状况与高于预期的发病率和死亡率有关。

    The interactive exploration of large and evolving datasets is challenging as relationships between underlying variables may not be fully understood. There may be hidden trends and patterns in the data that are worthy of further exploration and analysis. We present a system that methodically explores multiple combinations of variables using a searchlight technique and identifies outliers. An iterative k-means clustering algorithm is applied to features derived through a split-apply-combine paradigm used in the database literature. Outliers are identified as singleton or small clusters. This algorithm is swept across the dataset in a searchlight manner. The dimensions that contain outliers are combined in pairs with other dimensions using a susbset scan technique to gain further insight into the outliers. We illustrate this system by anaylzing open health care data released by New York State. We apply our iterative k-means searchlight followed by subset scanning. Several anomalous trends
    
[^49]: 基于层级自回归语言模型合成极高维长期电子健康记录

    Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model. (arXiv:2304.02169v1 [cs.LG])

    [http://arxiv.org/abs/2304.02169](http://arxiv.org/abs/2304.02169)

    此论文提出了一种名为HALO的方法，它是一个层级自回归模型，可以生成高保真、细粒度电子健康记录数据，而这些数据可以用于训练准确的ML模型，且无需涉及隐私问题。

    

    合成的电子健康记录(EHRs)能够在机器学习(ML)和统计分析中作为真实EHRs的替代品，既真实又保护隐私。然而，由于高维数据的内在复杂性，以其原始高度维形式生成高保真、细粒度电子健康记录(EHR)数据对现有方法构成了挑战。本文提出了一种名为“Hierarchical Autoregressive Language mOdel (HALO)”的方法，用于生成纵向高维EHR数据，该方法保留了真实EHR的统计特性，可以用于训练准确的ML模型而不涉及隐私问题。我们的HALO方法被设计为一个层级自回归模型，生成一组针对医学代码、临床就诊和病人记录的概率密度函数，可以在其原始未聚合形式下生成真实的EHR数据，无需进行变量选择或聚合。此外，我们的模型还产生大量的随机样本，以提供复杂度较低但仍有意义的EHR数据。

    Synthetic electronic health records (EHRs) that are both realistic and preserve privacy can serve as an alternative to real EHRs for machine learning (ML) modeling and statistical analysis. However, generating high-fidelity and granular electronic health record (EHR) data in its original, highly-dimensional form poses challenges for existing methods due to the complexities inherent in high-dimensional data. In this paper, we propose Hierarchical Autoregressive Language mOdel (HALO) for generating longitudinal high-dimensional EHR, which preserve the statistical properties of real EHR and can be used to train accurate ML models without privacy concerns. Our HALO method, designed as a hierarchical autoregressive model, generates a probability density function of medical codes, clinical visits, and patient records, allowing for the generation of realistic EHR data in its original, unaggregated form without the need for variable selection or aggregation. Additionally, our model also produc
    
[^50]: I2I: 用改进的知识初始化转接器

    I2I: Initializing Adapters with Improvised Knowledge. (arXiv:2304.02168v1 [cs.CL])

    [http://arxiv.org/abs/2304.02168](http://arxiv.org/abs/2304.02168)

    本文提出了一种称为ImprovisetoInitialize(I2I)的连续学习算法，通过提取先前学习的任务适配器的知识来为即将到来的任务初始化适配器。这使得从一个任务到另一个任务的知识传递更加高效。

    

    转接器是延续学习中解决灾难性遗忘问题的一种有前途的解决方案。然而，为每个新任务训练独立的适配器模块错失了跨任务知识转移的机会。我们提出了一种称为 Improvise to Initialize (I2I) 的连续学习算法，通过提取先前学习的任务适配器的知识，为即将到来的任务初始化适配器。我们通过对视觉问答任务序列进行实验，评估了 I2I 在 CLiMB，一个多模态的连续学习基准上的表现。使用 I2I 训练的适配器始终比独立训练的适配器具有更好的任务精度，证明了我们的算法促进了任务适配器之间的知识转移，并且相对于先进的 AdapterFusion，I2I 也能实现更好的跨任务知识转移而不产生相关的参数成本。

    Adapters present a promising solution to the catastrophic forgetting problem in continual learning. However, training independent Adapter modules for every new task misses an opportunity for cross-task knowledge transfer. We propose Improvise to Initialize (I2I), a continual learning algorithm that initializes Adapters for incoming tasks by distilling knowledge from previously-learned tasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning benchmark, by conducting experiments on sequences of visual question answering tasks. Adapters trained with I2I consistently achieve better task accuracy than independently-trained Adapters, demonstrating that our algorithm facilitates knowledge transfer between task Adapters. I2I also results in better cross-task knowledge transfer than the state-of-the-art AdapterFusion without incurring the associated parametric cost.
    
[^51]: 带连续优化的结构学习：审慎观察及其发展

    Structure Learning with Continuous Optimization: A Sober Look and Beyond. (arXiv:2304.02146v1 [cs.LG])

    [http://arxiv.org/abs/2304.02146](http://arxiv.org/abs/2304.02146)

    本文探讨了连续优化在有向无环图结构学习中的优点和缺点，分析了不相等噪声方差公式中的非凸性问题，并建议未来研究将更多地考虑先验知识和已知结构，以实现更健壮的优化方法。

    

    本文研究连续优化在有向无环图（DAG）结构学习中的表现好坏及其原因，并提出了可能使搜索过程更可靠的方向。我们分析了连续方法在假设噪声方差相等和不相等的情况下的现象，并通过提供反例、理论证明和可能的替代解释来表明这种陈述在任一情况下都可能不成立。我们进一步证明了对于非相等噪声方差公式，非凸性可能是主要问题，而连续结构学习方面的最新进展则无法在学习速度和实现得分方面优于贪心搜索，并建议融合先验知识或已知结构的更健壮的优化方法是未来研究的一个有希望的方向。

    This paper investigates in which cases continuous optimization for directed acyclic graph (DAG) structure learning can and cannot perform well and why this happens, and suggests possible directions to make the search procedure more reliable. Reisach et al. (2021) suggested that the remarkable performance of several continuous structure learning approaches is primarily driven by a high agreement between the order of increasing marginal variances and the topological order, and demonstrated that these approaches do not perform well after data standardization. We analyze this phenomenon for continuous approaches assuming equal and non-equal noise variances, and show that the statement may not hold in either case by providing counterexamples, justifications, and possible alternative explanations. We further demonstrate that nonconvexity may be a main concern especially for the non-equal noise variances formulation, while recent advances in continuous structure learning fail to achieve impro
    
[^52]: 线性损失下的最优单峰拟合问题的线性对数时间算法

    Sequential Linearithmic Time Optimal Unimodal Fitting When Minimizing Univariate Linear Losses. (arXiv:2304.02141v1 [cs.LG])

    [http://arxiv.org/abs/2304.02141](http://arxiv.org/abs/2304.02141)

    本文提出了一种线性对数时间算法，用于解决单变量学习模型在线性损失函数下得分输出的最优单峰转换问题。

    

    本文关注于单变量学习模型在线性损失函数下得分输出的最优单峰转换问题。我们证明了分数面值和目标区域之间的最佳映射是一个矩形函数。为了获得观测样本的最优矩形拟合，我们提出了一种顺序方法，可以在每个新样本到来时进行估计。我们的方法每次迭代具有对数时间复杂度，并且具有最优的效率。

    This paper focuses on optimal unimodal transformation of the score outputs of a univariate learning model under linear loss functions. We demonstrate that the optimal mapping between score values and the target region is a rectangular function. To produce this optimal rectangular fit for the observed samples, we propose a sequential approach that can its estimation with each incoming new sample. Our approach has logarithmic time complexity per iteration and is optimally efficient.
    
[^53]: 非线性状态空间识别的子空间编码器方法的初始化方法

    Initialization Approach for Nonlinear State-Space Identification via the Subspace Encoder Approach. (arXiv:2304.02119v1 [eess.SY])

    [http://arxiv.org/abs/2304.02119](http://arxiv.org/abs/2304.02119)

    本论文介绍一个使用最佳线性逼近(BLA)初始化子空间编码器方法的初始方法，以提高非线性状态空间识别的收敛性。

    

    SUBNET神经网络结构被开发用于从输入输出数据中识别非线性状态空间模型，它将展开的非线性状态空间方程和状态编码器函数组合起来作为神经网络参数。引入编码器函数来从过去的输入输出数据中重构当前状态，从而使展开的状态空间模型得以前向模拟。该方法已经证明提供了高精度和一致的模型估计，但是通过有效的训练过程初始化可以显著提高其收敛性。本文重点介绍使用最佳线性逼近(BLA)初始化子空间编码器方法的初始方法。使用BLA提供的状态空间矩阵及其相关的可重构映射来初始化网络的状态转移部分和编码器。改进的初始化方案的表现在Wiener-Hamme上进行了评估。

    The SUBNET neural network architecture has been developed to identify nonlinear state-space models from input-output data. To achieve this, it combines the rolled-out nonlinear state-space equations and a state encoder function, both parameterised as a neural network. The encoder function is introduced to reconstruct the current state from past input-output data. Hence it enables the forward simulation of the rolled-out state-space model. While this approach has shown to provide high-accuracy and consistent model estimation, its convergence can be significantly improved by efficient initialization of the training process. This paper focuses on such an initialisation of the subspace encoder approach using the Best Linear Approximation (BLA). Using the BLA provided state-space matrices and its associated reconstructability map both the state-transition part of the network and the encoder are initialized. The performance of the improved initialisation scheme is evaluated on a Wiener-Hamme
    
[^54]: 深度学习用于多孔介质中的扩散

    Deep learning for diffusion in porous media. (arXiv:2304.02104v1 [physics.comp-ph])

    [http://arxiv.org/abs/2304.02104](http://arxiv.org/abs/2304.02104)

    本文研究使用深度学习来预测多孔介质的基本特性，包括孔隙率和有效扩散系数，并通过构建U-Net架构成功重构了多孔介质的几何结构和浓度分布图。

    

    本文利用卷积神经网络（CNN）预测多孔介质的基本特性，考虑了两种不同的介质类型：一种模拟砂岩，另一种模拟生物组织的细胞外空间衍生系统。采用Lattice Boltzmann方法获得必要的标记数据，并进行有监督的学习。我们区分了两个任务，在第一个任务中，基于系统几何分析的网络预测孔隙率和有效扩散系数，第二个任务中，网络重构了系统的几何结构和浓度分布。在第一个任务中，我们提出了两种CNN模型：C-Net和U-Net的编码器部分。两个网络均添加了自归一化模块。模型的预测结果仅在其训练的数据类型内有合理准确性。在第二个任务中，我们提出了使用ResNet编码器的U-Net架构重构多孔介质的几何结构和浓度分布图。结果表明该架构可以成功重构两种介质类型。

    We adopt convolutional neural networks (CNN) to predict the basic properties of the porous media. Two different media types are considered: one mimics the sandstone, and the other mimics the systems derived from the extracellular space of biological tissues. The Lattice Boltzmann Method is used to obtain the labeled data necessary for performing supervised learning. We distinguish two tasks. In the first, networks based on the analysis of the system's geometry predict porosity and effective diffusion coefficient. In the second, networks reconstruct the system's geometry and concentration map. In the first task, we propose two types of CNN models: the C-Net and the encoder part of the U-Net. Both networks are modified by adding a self-normalization module. The models predict with reasonable accuracy but only within the data type, they are trained on. For instance, the model trained on sandstone-like samples overshoots or undershoots for biological-like samples. In the second task, we pr
    
[^55]: CAMELS项目：使用新的ASTRID和28个参数的TNG和SIMBA套件扩展星系形成模型空间

    The CAMELS project: Expanding the galaxy formation model space with new ASTRID and 28-parameter TNG and SIMBA suites. (arXiv:2304.02096v1 [astro-ph.CO])

    [http://arxiv.org/abs/2304.02096](http://arxiv.org/abs/2304.02096)

    CAMELS项目扩展了星系形成的模型空间，提供了更广泛的训练和测试环境，其中最新的CAMELS-ASTRID模拟套件通过多样的模拟涵盖了不同的星系群体和重要影响, 训练集覆盖不同宇宙学参数和星系反馈参数的变化， 加深了我们对星系形成的理解并为宇宙学研究提供了基础。

    

    我们提出了CAMELS-ASTRID，这是Cosmology and Astrophysics with MachinE Learning（CAMELS）项目中的第三个流体力学模拟套件，以及基于之前的CAMELS-TNG和CAMELS-SIMBA框架扩展模型参数空间的新模拟套件，为设计用于宇宙学研究的机器学习算法提供更广泛的训练和测试环境。与CAMELS中现有的TNG和SIMBA模拟套件相比，ASTRID的基准模型具有最温和的AGN反馈，并且预测对物质功率谱的影响最小。ASTRID的训练集涵盖了更广泛的星系群体和对物质功率谱的重要影响。

    We present CAMELS-ASTRID, the third suite of hydrodynamical simulations in the Cosmology and Astrophysics with MachinE Learning (CAMELS) project, along with new simulation sets that extend the model parameter space based on the previous frameworks of CAMELS-TNG and CAMELS-SIMBA, to provide broader training sets and testing grounds for machine-learning algorithms designed for cosmological studies. CAMELS-ASTRID employs the galaxy formation model following the ASTRID simulation and contains 2,124 hydrodynamic simulation runs that vary 3 cosmological parameters ($\Omega_m$, $\sigma_8$, $\Omega_b$) and 4 parameters controlling stellar and AGN feedback. Compared to the existing TNG and SIMBA simulation suites in CAMELS, the fiducial model of ASTRID features the mildest AGN feedback and predicts the least baryonic effect on the matter power spectrum. The training set of ASTRID covers a broader variation in the galaxy populations and the baryonic impact on the matter power spectrum compared t
    
[^56]: 可扩展的在线学习近似Stackelberg解决方案在带有需求响应聚合器的能源交易中的应用

    Scalable Online Learning of Approximate Stackelberg Solutions in Energy Trading Games with Demand Response Aggregators. (arXiv:2304.02086v1 [cs.LG])

    [http://arxiv.org/abs/2304.02086](http://arxiv.org/abs/2304.02086)

    本文提出了一个Stackelberg博弈理论框架，用于在需求响应（DR）聚合器和中间商之间双向交易能源，解决方案可扩展，且保证满足中间商每日能源的需求。

    

    本文提出了一个Stackelberg博弈理论框架，用于在需求响应（DR）聚合器和中间商之间双向交易能源。该框架允许灵活的能源套利和额外的货币奖励，同时确保满足中间商所需的每日能源需求。然后，提出了一种可扩展（随着中间商数量增加）的方法，基于在线采样和学习中间商的累积最佳响应，寻找近似的均衡解。此外，还提供了有关近似均衡解质量的界限。最后，利用来自加利福尼亚日前能源市场和加州大学戴维斯分校建筑能源需求的真实数据，展示了所提出的框架和在线可扩展解决方案的功效。

    In this work, a Stackelberg game theoretic framework is proposed for trading energy bidirectionally between the demand-response (DR) aggregator and the prosumers. This formulation allows for flexible energy arbitrage and additional monetary rewards while ensuring that the prosumers' desired daily energy demand is met. Then, a scalable (with the number of prosumers) approach is proposed to find approximate equilibria based on online sampling and learning of the prosumers' cumulative best response. Moreover, bounds are provided on the quality of the approximate equilibrium solution. Last, real-world data from the California day-ahead energy market and the University of California at Davis building energy demands are utilized to demonstrate the efficacy of the proposed framework and the online scalable solution.
    
[^57]: 《EduceLab-Scrolls：利用X射线CT从赫库兰尼姆纸草卷中可验证地恢复文本》

    EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT. (arXiv:2304.02084v1 [cs.CV])

    [http://arxiv.org/abs/2304.02084](http://arxiv.org/abs/2304.02084)

    该论文介绍了使用X射线CT图像揭示赫库兰尼姆纸草卷隐藏文本的软件管道和数据集。他们运用了机器学习和几何框架的方法检测“不可见”的碳墨，达到了人类专家标记者难以达到的效果。

    

    我们提出了一个用于揭示赫库兰尼姆纸草卷隐藏文本的完整软件管道。这个增强的虚拟展开流水线将机器学习与一种新颖的几何框架相结合，将三维和二维图像联系起来。我们还提出了EduceLab-Scrolls，这是一个全面的开放数据集，代表了二十年来对这个问题的研究努力。EduceLab-Scrolls包含了一组小碎片和完整卷轴的体积X射线CT图像。该数据集还包含用于监督训练油墨检测模型的二维图像标签。通过将卷轴碎片的频谱照片与相同碎片的X射线CT图像对准，从而创建了一个可机器学习的图像空间和模态之间的映射。这种对准允许有监督地学习检测X射线CT中“隐形”碳墨的任务，即使对于人类专家标记者来说也是“不可能”的任务。据我们所知，这是第一个对齐数据集。

    We present a complete software pipeline for revealing the hidden texts of the Herculaneum papyri using X-ray CT images. This enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3D and 2D images. We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem. EduceLab-Scrolls contains a set of volumetric X-ray CT images of both small fragments and intact, rolled scrolls. The dataset also contains 2D image labels that are used in the supervised training of an ink detection model. Labeling is enabled by aligning spectral photography of scroll fragments with X-ray CT images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. This alignment permits supervised learning for the detection of "invisible" carbon ink in X-ray CT, a task that is "impossible" even for human expert labelers. To our knowledge, this is the first aligned datas
    
[^58]: 算法相关的界限对多源域自适应表示学习的影响

    Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation. (arXiv:2304.02064v1 [cs.LG])

    [http://arxiv.org/abs/2304.02064](http://arxiv.org/abs/2304.02064)

    通过信息论工具的使用，该论文研究了多源域自适应表示学习中的联合分布对齐，提出了算法相关的泛化界限，并提出了一种新颖的深度学习算法，解决了目标偏移问题。

    

    我们使用信息论工具从表示学习的角度对多源域自适应进行了新颖的分析，具体地，我们研究了有少量目标标签的监督 MDA 和带有伪标签的无监督 MDA 的联合分布对齐。我们进一步针对这两种情况提供了算法相关的泛化界限，其中泛化由参数与数据之间的互信息来描述。然后，我们提出了一种新颖的深度 MDA 算法，通过联合对齐隐含地解决了目标偏移问题。最后，这些互信息界限扩展到此算法，提供了一个非平庸的梯度范数估计。该算法在改进内存效率的同时，在目标偏移 MDA 基准测试中具有可比较的性能。

    We use information-theoretic tools to derive a novel analysis of Multi-source Domain Adaptation (MDA) from the representation learning perspective. Concretely, we study joint distribution alignment for supervised MDA with few target labels and unsupervised MDA with pseudo labels, where the latter is relatively hard and less commonly studied. We further provide algorithm-dependent generalization bounds for these two settings, where the generalization is characterized by the mutual information between the parameters and the data. Then we propose a novel deep MDA algorithm, implicitly addressing the target shift through joint alignment. Finally, the mutual information bounds are extended to this algorithm providing a non-vacuous gradient-norm estimation. The proposed algorithm has comparable performance to the state-of-the-art on target-shifted MDA benchmark with improved memory efficiency.
    
[^59]: 基于权重滤波的多类可解释性卸载图像分类

    Multi-Class Explainable Unlearning for Image Classification via Weight Filtering. (arXiv:2304.02049v1 [cs.CV])

    [http://arxiv.org/abs/2304.02049](http://arxiv.org/abs/2304.02049)

    本论文提出一种基于权重滤波的多类可解释性卸载图像分类方法，可以在单个未训练轮中取消学习网络的所有类别，并且恢复可解释的类别表示。

    

    机器卸载是最近浮现的一种选择性地将训练数据点的影响从网络中删除的范式。尽管现有方法已经集中在卸载训练数据的小子集或单个类别，但在本文中，我们采取了不同的方法，设计了一个框架，可以在单个未训练轮中取消学习图像分类网络的所有类别。我们提出的方法通过内部组件的记忆矩阵来调节图像分类网络，以便在训练后，同一网络可以有选择地展示任何类别的未学习行为。通过发现每个类别特定的权重，我们的方法还通过设计可解释性机制来恢复类别的表示。我们在小规模和中规模图像分类数据集上使用CNN和Transformer-based骨架测试了提出的框架。我们的工作提供了一种多类可解释性卸载的解决方案。

    Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work p
    
[^60]: 扫描透射电子显微镜中的自动实验深度学习

    Deep Learning for Automated Experimentation in Scanning Transmission Electron Microscopy. (arXiv:2304.02048v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2304.02048](http://arxiv.org/abs/2304.02048)

    本文讨论了在扫描透射电子显微镜中实现主动机器学习的挑战以及需要开发的面向显微镜工作流程设计和优化的策略。同时，需要确定人类和机器学习代理在实验工作流程的构思、编排和执行中的相对贡献，并开发可跨多个平台应用的通用超语言。

    

    机器学习在（扫描）透射电子显微镜成像和光谱学的后采集数据分析中变得至关重要。一种新兴的趋势是实时分析和闭环显微镜操作。有效利用机器学习在电子显微镜中现在需要开发面向显微镜工作流程设计和优化的策略。本文讨论了转向主动机器学习所涉及的挑战，包括序贯数据分析和超出分布漂移效应，边缘操作、本地和云数据存储的要求以及理论在环操作。具体来说，我们讨论了人类科学家和机器学习代理在实验工作流程的构思、编排和执行中的相对贡献，并需要开发可跨多个平台应用的通用超语言。这些考虑因素将共同影响机器学习在扫描透射电子显微镜中的操作化。

    Machine learning (ML) has become critical for post-acquisition data analysis in (scanning) transmission electron microscopy, (S)TEM, imaging and spectroscopy. An emerging trend is the transition to real-time analysis and closed-loop microscope operation. The effective use of ML in electron microscopy now requires the development of strategies for microscopy-centered experiment workflow design and optimization. Here, we discuss the associated challenges with the transition to active ML, including sequential data analysis and out-of-distribution drift effects, the requirements for the edge operation, local and cloud data storage, and theory in the loop operations. Specifically, we discuss the relative contributions of human scientists and ML agents in the ideation, orchestration, and execution of experimental workflows and the need to develop universal hyper languages that can apply across multiple platforms. These considerations will collectively inform the operationalization of ML in n
    
[^61]: 初始化时Transformer的有效理论分析

    Effective Theory of Transformers at Initialization. (arXiv:2304.02034v1 [cs.LG])

    [http://arxiv.org/abs/2304.02034](http://arxiv.org/abs/2304.02034)

    本研究分析了宽且深的Transformer中的前向和后向信号传播，提出了特定的初始化和训练超参数宽度缩放建议，并在实际设置中验证了这些建议。

    

    我们对宽且深的Transformer（即使用多头自注意块和多层感知机块的残差神经网络）中的前向和后向信号传播进行了有效理论分析。该分析建议这些模型的初始化和训练超参数采用特定的宽度缩放。我们随后采用这些建议，在实际设置中对视觉和语言Transformer进行训练。

    We perform an effective-theory analysis of forward-backward signal propagation in wide and deep Transformers, i.e., residual neural networks with multi-head self-attention blocks and multilayer perceptron blocks. This analysis suggests particular width scalings of initialization and training hyperparameters for these models. We then take up such suggestions, training Vision and Language Transformers in practical setups.
    
[^62]: 基于MNL选择模型的在线联合组合库存优化问题研究

    Online Joint Assortment-Inventory Optimization under MNL Choices. (arXiv:2304.02022v1 [cs.LG])

    [http://arxiv.org/abs/2304.02022](http://arxiv.org/abs/2304.02022)

    本文提出了一个算法解决在线联合组合库存优化问题，能够在平衡探索与开发的措施下实现最大化预期总利润，并为该算法建立了遗憾上界。

    

    本文研究了一种在线联合组合库存优化问题，在该问题中，我们假设每个顾客的选择行为都遵循Multinomial Logit（MNL）选择模型，吸引力参数是先验未知的。零售商进行周期性组合和库存决策，以动态地从实现的需求中学习吸引力参数，同时在时间上最大化预期的总利润。本文提出了一种新算法，可以有效地平衡组合和库存在线决策中的探索和开发。我们的算法建立在一个新的MNL吸引力参数估计器，一种通过自适应调整某些已知和未知参数来激励探索的新方法，以及一个用于静态单周期组合库存规划问题的优化oracle基础之上。我们为我们的算法建立了遗憾上界，以及关于在线联合组合库存优化问题的下界。

    We study an online joint assortment-inventory optimization problem, in which we assume that the choice behavior of each customer follows the Multinomial Logit (MNL) choice model, and the attraction parameters are unknown a priori. The retailer makes periodic assortment and inventory decisions to dynamically learn from the realized demands about the attraction parameters while maximizing the expected total profit over time. In this paper, we propose a novel algorithm that can effectively balance the exploration and exploitation in the online decision-making of assortment and inventory. Our algorithm builds on a new estimator for the MNL attraction parameters, a novel approach to incentivize exploration by adaptively tuning certain known and unknown parameters, and an optimization oracle to static single-cycle assortment-inventory planning problems with given parameters. We establish a regret upper bound for our algorithm and a lower bound for the online joint assortment-inventory optimi
    
[^63]: 使用双向LSTM检测虚假职位发布

    Detecting Fake Job Postings Using Bidirectional LSTM. (arXiv:2304.02019v1 [cs.LG])

    [http://arxiv.org/abs/2304.02019](http://arxiv.org/abs/2304.02019)

    本研究使用双向LSTM模型，同时考虑数字和文本特征，以较高的ROC AUC得分和准确性识别虚假职位广告，有望应用于在线招聘市场，帮助解决虚假职位广告的问题和提高求职流程的完整性。

    

    在线招聘平台上，虚假职位广告的出现越来越普遍，给求职者和招聘者带来了重大挑战。尽管有必要解决这个问题，但利用深度学习技术检测欺诈性招聘广告的研究还很有限。本研究通过应用双向长短期记忆（Bi-LSTM）模型来识别虚假职业广告以填补这一空白。我们的方法同时考虑数字和文本特征，有效地捕捉数据中的潜在模式和关系。所提出的模型表现优异，达到了0.91 ROC AUC得分和98.71％的准确率，表明其在在线招聘市场上具有实际应用的潜力。本研究的发现有助于开发强大的自动工具，帮助打击虚假职位广告的滋生，提高求职流程的整体完整性。此外，我们还探讨了挑战,

    Fake job postings have become prevalent in the online job market, posing significant challenges to job seekers and employers. Despite the growing need to address this problem, there is limited research that leverages deep learning techniques for the detection of fraudulent job advertisements. This study aims to fill the gap by employing a Bidirectional Long Short-Term Memory (Bi-LSTM) model to identify fake job advertisements. Our approach considers both numeric and text features, effectively capturing the underlying patterns and relationships within the data. The proposed model demonstrates a superior performance, achieving a 0.91 ROC AUC score and a 98.71% accuracy rate, indicating its potential for practical applications in the online job market. The findings of this research contribute to the development of robust, automated tools that can help combat the proliferation of fake job postings and improve the overall integrity of the job search process. Moreover, we discuss challenges,
    
[^64]: 多模式多模块的AI大厨：基于图像的复杂菜谱生成

    The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery. (arXiv:2304.02016v1 [cs.CL])

    [http://arxiv.org/abs/2304.02016](http://arxiv.org/abs/2304.02016)

    本文提出一种基于图像的轻量级和专业方法，使用多个API将对象列表作为输入传递给大型语言模型(LLM)，从而生成适合于特定约束条件的新颖的菜谱卡。

    

    AI社区采用多感官或多模态方法来推进这一代AI模型的智能水平。将语言和图像相结合代表了特定任务的熟悉方法，例如从描述中生成图像标题或图像。本文将这些单片式方法与基于采用图像模型标记对象的轻量级和专业方法进行了比较，然后串行提交此结果对象列表给大型语言模型(LLM)。多个API的使用使得正确对象列表的平均精度达到95%以上，这些列表作为输入传递给最新的Open AI文本生成器(GPT-4)。为了演示API作为模块化替代方案，我们解决了一个用户拍下冰箱中有哪些食材的照片，然后生成适合于成本、准备时间、饮食限制、分量大小和多个因素的新颖菜谱卡的问题。

    The AI community has embraced multi-sensory or multi-modal approaches to advance this generation of AI models to resemble expected intelligent understanding. Combining language and imagery represents a familiar method for specific tasks like image captioning or generation from descriptions. This paper compares these monolithic approaches to a lightweight and specialized method based on employing image models to label objects, then serially submitting this resulting object list to a large language model (LLM). This use of multiple Application Programming Interfaces (APIs) enables better than 95% mean average precision for correct object lists, which serve as input to the latest Open AI text generator (GPT-4). To demonstrate the API as a modular alternative, we solve the problem of a user taking a picture of ingredients available in a refrigerator, then generating novel recipe cards tailored to complex constraints on cost, preparation time, dietary restrictions, portion sizes, and multip
    
[^65]: DWA：差分小波放大器用于图像超分辨率

    DWA: Differential Wavelet Amplifier for Image Super-Resolution. (arXiv:2304.01994v1 [cs.CV])

    [http://arxiv.org/abs/2304.01994](http://arxiv.org/abs/2304.01994)

    本文介绍了一种基于小波的图像超分辨率模块DWA，通过利用两个卷积滤波器的差异改进小波SR模型，在小波域中提高相关特征提取并抑制噪声。在现有的SR模型中集成DWA，如DWSR和MWCNN，可以显示出其有效性。

    

    本文介绍了一种差分小波放大器(DWA)，这是一种基于小波的图像超分辨率(SR)模块。DWA为最近收到较少关注的混合离散小波变换(DWT)方法注入活力。DWT能够有效地为SR提供图像表示，并将其输入的空间面积减少4倍，从而减小了模型总大小和计算成本，并且成为可持续ML的一种有吸引力的方法。我们提出的DWA模型通过利用两个卷积滤波器之间的差异来改进小波SR模型，在小波域中提高相关特征提取，强调局部对比度并抑制输入信号中的常见噪声。将其集成到现有的SR模型中，如DWSR和MWCNN，可以显示出其有效性，并在SR任务中实现了明显的提高。此外，DWA使DWSR和MWCNN可以直接应用于输入图像空间，因为它省略了DWT表示的通道方式。

    This work introduces Differential Wavelet Amplifier (DWA), a drop-in module for wavelet-based image Super-Resolution (SR). DWA invigorates an approach recently receiving less attention, namely Discrete Wavelet Transformation (DWT). DWT enables an efficient image representation for SR and reduces the spatial area of its input by a factor of 4, the overall model size, and computation cost, framing it as an attractive approach for sustainable ML. Our proposed DWA model improves wavelet-based SR models by leveraging the difference between two convolutional filters to refine relevant feature extraction in the wavelet domain, emphasizing local contrasts and suppressing common noise in the input signals. We show its effectiveness by integrating it into existing SR models, e.g., DWSR and MWCNN, and demonstrate a clear improvement in classical SR tasks. Moreover, DWA enables a direct application of DWSR and MWCNN to input image space, reducing the DWT representation channel-wise since it omits 
    
[^66]: 双关注神经变换器用于语音识别时的高效唤醒词识别

    Dual-Attention Neural Transducers for Efficient Wake Word Spotting in Speech Recognition. (arXiv:2304.01905v1 [cs.SD])

    [http://arxiv.org/abs/2304.01905](http://arxiv.org/abs/2304.01905)

    本文介绍了一种新的“双关注神经变换器”，可以通过优化唤醒词检测来选择计算路径，从而提高唤醒词的准确性和推理时间效率，并且计算成本可以降低90％而仅增加1％的参数。这种架构可以在语音识别领域中大有裨益。

    

    本文提出了一种称为双关注神经网络的架构，旨在提高唤醒词识别的准确率并改善语音识别任务的推理时间。该架构通过利用唤醒词检测来选择哪个注意力网络执行输入音频帧的运行时计算路径。使用这种方法，作者有效提高了唤醒词识别的准确性，并定义了浮点运算（FLOPs）的运行时计算成本。在使用作者的内部数据集时，作者证明了所提出的双关注网络可以将唤醒词音频帧的计算成本降低$90\%$，而参数数量仅增加$1\%$。与基线相比，该架构提高了唤醒词F1得分$16\%$，并将一般的罕见词错误率提高了$3\%$。

    We present dual-attention neural biasing, an architecture designed to boost Wake Words (WW) recognition and improve inference time latency on speech recognition tasks. This architecture enables a dynamic switch for its runtime compute paths by exploiting WW spotting to select which branch of its attention networks to execute for an input audio frame. With this approach, we effectively improve WW spotting accuracy while saving runtime compute cost as defined by floating point operations (FLOPs). Using an in-house de-identified dataset, we demonstrate that the proposed dual-attention network can reduce the compute cost by $90\%$ for WW audio frames, with only $1\%$ increase in the number of parameters. This architecture improves WW F1 score by $16\%$ relative and improves generic rare word error rate by $3\%$ relative compared to the baselines.
    
[^67]: 社会文化知识在仇恨言论检测任务中对选项的选择是必要的

    Sociocultural knowledge is needed for selection of shots in hate speech detection tasks. (arXiv:2304.01890v1 [cs.CL])

    [http://arxiv.org/abs/2304.01890](http://arxiv.org/abs/2304.01890)

    HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。

    

    我们引入了HATELEXICON，这是一个包含巴西，德国，印度和肯尼亚的蔑称和仇恨言论目标的词汇表，以帮助模型的训练和可解释性。我们展示了我们的词汇表如何用于解释模型预测，表明发展用于分类极端言论的模型，在进行预测时严重依赖目标词。此外，我们提出了一种通过HATELEXICON来辅助低资源环境下训练选项的方法，选项选择在小样本学习中尤为重要。在我们的工作中，我们使用HASOC数据对德语和印地语进行了几个示范学习，并将Multilingual HateCheck（MHC）作为基准。我们展示了根据我们的词汇表选择样本，相对于随机采样的模型，能够更好地在MHC上表现。因此，当仅有少量的训练样本时，使用我们的词汇表来选择包含更多社会文化信息的样本能够更好地提高在仇恨言论检测任务中的性能。

    We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for the countries of Brazil, Germany, India and Kenya, to aid training and interpretability of models. We demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. Further, we propose a method to aid shot selection for training in low-resource settings via HATELEXICON. In few-shot learning, the selection of shots is of paramount importance to model performance. In our work, we simulate a few-shot setting for German and Hindi, using HASOC data for training and the Multilingual HateCheck (MHC) as a benchmark. We show that selecting shots based on our lexicon leads to models performing better on MHC than models trained on shots sampled randomly. Thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot perf
    
[^68]: 聊天GPT，还是不聊天GPT：这是一个问题！

    To ChatGPT, or not to ChatGPT: That is the question!. (arXiv:2304.01487v1 [cs.LG])

    [http://arxiv.org/abs/2304.01487](http://arxiv.org/abs/2304.01487)

    研究评估了聊天GPT检测中的最新技术和其他AI生成文本检测工具的表现，并提出区分人工生成和AI生成文本的重要性。

    

    聊天GPT已经成为一种全球感知。随着聊天GPT和其他大型语言模型（LLM）的出现，对于他们的误用的担忧也增加了，例如传播虚假消息，抄袭，操纵公众舆论，欺骗和欺诈。因此，区分人工生成和AI生成的文本变得越来越重要。研究人员提出了各种检测方法，从基本的二元分类器到更复杂的深度学习模型。一些检测技术依赖于统计特征或句法模式，而其他一些则包含语义或上下文信息以提高准确性。本研究的主要目标是对聊天GPT检测中最新技术进行全面和现代化的评估。此外，我们还评估了其他未专门声称检测聊天GPT生成内容的AI生成文本检测工具以评估它们在检测聊天GPT生成内容方面的表现。在我们的评估中，我们使用了一个包含人工编写和聊天GPT生成的文本的大型数据集。

    ChatGPT has become a global sensation. As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud. Hence, distinguishing AI-generated from human-generated becomes increasingly essential. Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models. Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy. The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection. Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content. For our evaluation,
    
[^69]: 用自然语言处理的方法识别心理健康记录中的疼痛提及

    Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach. (arXiv:2304.01240v1 [cs.CL])

    [http://arxiv.org/abs/2304.01240](http://arxiv.org/abs/2304.01240)

    该研究使用机器学习技术，成功地识别出心理健康电子健康记录中的疼痛提及，提高了对疼痛和心理健康之间关系的理解。

    

    疼痛是访问医疗资源的常见原因，并且是一个研究领域，特别是在与心理健康的重叠方面。心理健康电子健康记录是研究此重叠的良好数据来源。然而，疼痛的大量信息保存在这些记录的自由文本中，由于其歧义性，疼痛的提及呈现出独特的自然语言处理问题。本项目使用匿名的心理健康电子健康记录数据库中的数据。利用这些数据训练基于机器学习的分类算法，将句子分类为讨论患者疼痛或不讨论。这将有助于从大型数据库中提取相关疼痛信息，并将这些输出用于进一步研究疼痛和心理健康。共手动三重注释了1,985份文件，以创建黄金标准训练数据，并用于训练三种常用的分类算法。最佳模型的F1分数为0.787。结果证明了使用自然语言处理识别心理健康电子健康记录中的疼痛提及的可行性，这可以改善对疼痛和心理健康之间关系的理解。

    Pain is a common reason for accessing healthcare resources and is a growing area of research, especially in its overlap with mental health. Mental health electronic health records are a good data source to study this overlap. However, much information on pain is held in the free text of these records, where mentions of pain present a unique natural language processing problem due to its ambiguous nature. This project uses data from an anonymised mental health electronic health records database. The data are used to train a machine learning based classification algorithm to classify sentences as discussing patient pain or not. This will facilitate the extraction of relevant pain information from large databases, and the use of such outputs for further studies on pain and mental health. 1,985 documents were manually triple-annotated for creation of gold standard training data, which was used to train three commonly used classification algorithms. The best performing model achieved an F1-
    
[^70]: POLAR-Express: 神经网络控制系统的高效准确形式可达性分析

    POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems. (arXiv:2304.01218v1 [eess.SY])

    [http://arxiv.org/abs/2304.01218](http://arxiv.org/abs/2304.01218)

    POLAR-Express 是一种高效且准确的形式可达性分析工具，用于验证神经网络控制系统的安全性。它使用 Taylor 模型算术和逐层传播技术，可以分析具有连续激活功能的前馈神经网络，并在 ReLU 激活函数上提供了一种更有效的精确传播 TM 的新方法。

    

    在挑战性的控制问题上，扮演控制器角色的神经网络 (NN) 展示出了令人印象深刻的实验性能。但神经网络控制系统 (NNCS) 在实际应用中的潜在采用也引起了日益增长的对这些 NNCS 安全性的担忧，特别是在安全关键应用中的使用。本文提出了 POLAR-Express，一种高效且准确的形式可达性分析工具，用于验证 NNCS 的安全性。POLAR-Express 使用 Taylor 模型算术，逐层横跨神经网络来传播 Taylor 模型 (TM) 以计算神经网络函数的近似值。它可以用于分析任何具有连续激活功能的前馈神经网络。我们还提出了一种在 ReLU 激活函数上更有效地精确传播 TM 的新方法。此外，POLAR-Express 为逐层传播提供了并行计算支持。

    Neural networks (NNs) playing the role of controllers have demonstrated impressive empirical performances on challenging control problems. However, the potential adoption of NN controllers in real-life applications also gives rise to a growing concern over the safety of these neural-network controlled systems (NNCSs), especially when used in safety-critical applications. In this work, we present POLAR-Express, an efficient and precise formal reachability analysis tool for verifying the safety of NNCSs. POLAR-Express uses Taylor model arithmetic to propagate Taylor models (TMs) across a neural network layer-by-layer to compute an overapproximation of the neural-network function. It can be applied to analyze any feed-forward neural network with continuous activation functions. We also present a novel approach to propagate TMs more efficiently and precisely across ReLU activation functions. In addition, POLAR-Express provides parallel computation support for the layer-by-layer propagation
    
[^71]: 基于准度量学习的最优目标达成强化学习方法

    Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning. (arXiv:2304.01203v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.01203](http://arxiv.org/abs/2304.01203)

    本文介绍了一种新的强化学习方法——准度量强化学习（QRL），利用准度量模型来学习最优价值函数；在离线和在线的目标达成基准测试中，QRL展示了更好的采样效率和性能，包括基于状态和基于图像的观测。

    

    在目标达成强化学习中，最优价值函数具有特定的几何结构，称为准度量结构。本文介绍了一种新的强化学习方法——准度量强化学习（QRL），利用准度量模型来学习最优价值函数。与以往的方法不同，QRL的目标是专门为准度量设计的，并提供了强大的理论恢复保证。在离散化的MountainCar环境上进行了全面分析，确定了QRL的性质以及其优于其他方法的优势。在离线和在线的目标达成基准测试中，QRL还展示了更好的采样效率和性能，包括基于状态和基于图像的观测。

    In goal-reaching reinforcement learning (RL), the optimal value function has a particular geometry, called quasimetric structure. This paper introduces Quasimetric Reinforcement Learning (QRL), a new RL method that utilizes quasimetric models to learn optimal value functions. Distinct from prior approaches, the QRL objective is specifically designed for quasimetrics, and provides strong theoretical recovery guarantees. Empirically, we conduct thorough analyses on a discretized MountainCar environment, identifying properties of QRL and its advantages over alternatives. On offline and online goal-reaching benchmarks, QRL also demonstrates improved sample efficiency and performance, across both state-based and image-based observations.
    
[^72]: 基于Cityscapes-3D的联合2D-3D多任务学习：3D检测、分割和深度估计

    Joint 2D-3D Multi-Task Learning on Cityscapes-3D: 3D Detection, Segmentation, and Depth Estimation. (arXiv:2304.00971v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00971](http://arxiv.org/abs/2304.00971)

    该论文提出了一种基于Cityscapes-3D的联合2D-3D多任务学习方法，旨在同时实现单眼3D车辆检测、语义分割和单眼深度估计，并通过优化多个目标单元，提高了模型性能。

    

    这份报告是TaskPrompter在基于Cityscapes-3D的新联合2D-3D多任务学习标准上的实现的补充文档。TaskPrompter提出了一个创新的多任务提示框架，将（i）任务通用表示、（ii）任务特定表示和（iii）跨任务交互的学习统一起来，与以往的方法将这些学习目标分别存放在不同的网络模块中相反。这种统一的方法不仅减少了对结构设计的细致经验需求，还显著增强了多任务网络的表示学习能力，因为整个模型容量都致力于同时优化这三个目标。TaskPrompter在Cityscapes-3D数据集上引入了一个新的多任务基准，要求多任务模型同时为单眼3D车辆检测、语义分割和单眼深度估计生成预测。

    This report serves as a supplementary document for TaskPrompter, detailing its implementation on a new joint 2D-3D multi-task learning benchmark based on Cityscapes-3D. TaskPrompter presents an innovative multi-task prompting framework that unifies the learning of (i) task-generic representations, (ii) task-specific representations, and (iii) cross-task interactions, as opposed to previous approaches that separate these learning objectives into different network modules. This unified approach not only reduces the need for meticulous empirical structure design but also significantly enhances the multi-task network's representation learning capability, as the entire model capacity is devoted to optimizing the three objectives simultaneously. TaskPrompter introduces a new multi-task benchmark based on Cityscapes-3D dataset, which requires the multi-task model to concurrently generate predictions for monocular 3D vehicle detection, semantic segmentation, and monocular depth estimation. The
    
[^73]: AUDIT：基于潜在扩散模型的指令引导音频编辑

    AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models. (arXiv:2304.00830v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2304.00830](http://arxiv.org/abs/2304.00830)

    研究提出了基于潜在扩散模型的指令引导音频编辑模型AUDIT，实现了在各种音频编辑任务上的最先进性能，并通过自适应方案和文本到片段匹配模块解决了先前扩散-based方法存在的问题。

    

    音频编辑可用于各种目的，例如添加背景音效、替换乐器和修复损坏的音频。最近，一些基于扩散的方法通过使用以输出音频的文本说明为条件的扩散和去噪过程来实现零-shot音频编辑。然而，这些方法仍存在一些问题：1）它们并没有被训练用于编辑任务，不能保证良好的编辑效果；2）它们可能会错误地修改不需要编辑的音频片段；3）他们需要输出音频的完整描述，这在实际情况下并不总是可用或必要。在这项工作中，我们提出了AUDIT，一种基于潜在扩散模型的指令引导音频编辑模型。特别是，AUDIT具有三个主要设计特点：1）我们为不同的音频编辑任务构建三元训练数据（指令，输入音频，输出音频）并使用指令和输入（要编辑的音频）音频对训练扩散模型；2）我们引入了一种新的自适应方案，使用很少量的编辑任务音频数据对扩散模型进行微调；3）我们提出了一个文本到片段匹配模块，自动将输入指令与要编辑的相应音频片段对齐。实验结果表明，AUDIT在各种音频编辑任务上实现了最先进的性能，并且比以前的基于扩散的方法表现更优秀。

    Audio editing is applicable for various purposes, such as adding background sound effects, replacing a musical instrument, and repairing damaged audio. Recently, some diffusion-based methods achieved zero-shot audio editing by using a diffusion and denoising process conditioned on the text description of the output audio. However, these methods still have some problems: 1) they have not been trained on editing tasks and cannot ensure good editing effects; 2) they can erroneously modify audio segments that do not require editing; 3) they need a complete description of the output audio, which is not always available or necessary in practical scenarios. In this work, we propose AUDIT, an instruction-guided audio editing model based on latent diffusion models. Specifically, AUDIT has three main design features: 1) we construct triplet training data (instruction, input audio, output audio) for different audio editing tasks and train a diffusion model using instruction and input (to be edite
    
[^74]: 在SAR ATR中发现和解释深度学习的非因果性

    Discovering and Explaining the Non-Causality of Deep Learning in SAR ATR. (arXiv:2304.00668v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00668](http://arxiv.org/abs/2304.00668)

    本文通过量化不同区域对目标识别的贡献和解释数据偏差和模型偏差对非因果性的影响，提供了改善深度学习在SAR ATR中鲁棒性和泛化能力的重要见解。

    

    近年来，深度学习在SAR ATR中被广泛使用，并在MSTAR数据集上取得了优异的性能。然而，由于受限的成像条件，MSTAR存在背景相关等数据偏见，即背景杂波特性与目标类别存在虚假相关性。深度学习可以过度拟合杂波以减少训练误差。因此，杂波的过度拟合程度反映了SAR ATR中深度学习的非因果性。现有方法仅定性分析此现象。本文基于Shapley值量化不同区域对目标识别的贡献。杂波的Shapley值可以衡量其过度拟合程度。此外，我们解释了数据偏差和模型偏差对非因果性的影响。简言之，数据偏差导致训练集和测试集中的信杂比和杂波纹理可比，而各种模型结构对这些偏差的过拟合程度不同。非因果性的解释为提高深度学习在SAR ATR中的鲁棒性和泛化能力提供了重要的见解。

    In recent years, deep learning has been widely used in SAR ATR and achieved excellent performance on the MSTAR dataset. However, due to constrained imaging conditions, MSTAR has data biases such as background correlation, i.e., background clutter properties have a spurious correlation with target classes. Deep learning can overfit clutter to reduce training errors. Therefore, the degree of overfitting for clutter reflects the non-causality of deep learning in SAR ATR. Existing methods only qualitatively analyze this phenomenon. In this paper, we quantify the contributions of different regions to target recognition based on the Shapley value. The Shapley value of clutter measures the degree of overfitting. Moreover, we explain how data bias and model bias contribute to non-causality. Concisely, data bias leads to comparable signal-to-clutter ratios and clutter textures in training and test sets. And various model structures have different degrees of overfitting for these biases. The exp
    
[^75]: 基于信号子空间差异子空间的时间序列异常检测方法

    Time-series Anomaly Detection based on Difference Subspace between Signal Subspaces. (arXiv:2303.17802v1 [cs.LG])

    [http://arxiv.org/abs/2303.17802](http://arxiv.org/abs/2303.17802)

    本文提出了一种新的基于信号子空间差异子空间的时间序列异常检测方法，通过捕获两个子空间的完整结构差异来提高性能，在公共时间序列数据集上证明了其有效性。

    

    本文提出了一种基于奇异谱分析(SSA)和差异子空间概念的新型时间序列异常检测方法。其关键思想是通过监控过去和现在时间序列数据所对应的两个信号子空间之间轻微的时间变化来作为异常评分。这是传统SSA方法的自然推广，传统方法测量的是两个信号子空间之间的最小角度来表征变化的程度。通过用差异子空间替代最小角度，我们的方法在使用SSA框架的同时提高了性能，因为它可以捕捉到两个子空间之间的完整结构差异。我们通过对公共时间序列数据集的性能评估证明了方法的有效性。

    This paper proposes a new method for anomaly detection in time-series data by incorporating the concept of difference subspace into the singular spectrum analysis (SSA). The key idea is to monitor slight temporal variations of the difference subspace between two signal subspaces corresponding to the past and present time-series data, as anomaly score. It is a natural generalization of the conventional SSA-based method which measures the minimum angle between the two signal subspaces as the degree of changes. By replacing the minimum angle with the difference subspace, our method boosts the performance while using the SSA-based framework as it can capture the whole structural difference between the two subspaces in its magnitude and direction. We demonstrate our method's effectiveness through performance evaluations on public time-series datasets.
    
[^76]: 基于Transformer的渐进式自监督学习在异常检测和定位中的应用

    Incremental Self-Supervised Learning Based on Transformer for Anomaly Detection and Localization. (arXiv:2303.17354v1 [cs.CV])

    [http://arxiv.org/abs/2303.17354](http://arxiv.org/abs/2303.17354)

    该论文提出一种基于Transformer骨干网络的渐进式自监督学习方法，可用于图像异常检测和定位，其中第一阶段使用MAE模型进行正常图像的训练，第二阶段使用像素级数据增强技术来生成损坏的正常图像，最终通过像素重建误差矩阵和像素异常概率矩阵综合得到一个异常得分矩阵。

    

    在机器学习领域，对于图像数据中的异常检测和定位的研究，尤其是在工业缺陷检测等实际应用中引起了重视。虽然现有的方法主要依赖于卷积神经网络（CNN）作为骨干网络，但我们提出了一种基于Transformer骨干网络的创新方法。我们的方法采用了两阶段的渐进式学习策略。在第一阶段，我们仅使用正常图像对Masked Autoencoder （MAE）模型进行训练，在第二阶段，我们实现了像素级数据增强技术以生成已损坏的正常图像及其相应的像素标签。这个过程使得模型可以学习如何修复损坏的区域和分类每个像素的状态。最终，该模型产生一个像素重建误差矩阵和一个像素异常概率矩阵，这两个矩阵综合成一个异常得分矩阵，有效地用于图像异常检测。

    In the machine learning domain, research on anomaly detection and localization within image data has garnered significant attention, particularly in practical applications such as industrial defect detection. While existing approaches predominantly rely on Convolutional Neural Networks (CNN) as their backbone network, we propose an innovative method based on the Transformer backbone network. Our approach employs a two-stage incremental learning strategy. In the first stage, we train a Masked Autoencoder (MAE) model exclusively on normal images. Subsequently, in the second stage, we implement pixel-level data augmentation techniques to generate corrupted normal images and their corresponding pixel labels. This process enables the model to learn how to repair corrupted regions and classify the state of each pixel. Ultimately, the model produces a pixel reconstruction error matrix and a pixel anomaly probability matrix, which are combined to create an anomaly scoring matrix that effective
    
[^77]: HARFLOW3D：一种面向FPGA设备的基于延迟的3D-CNN加速器工具链

    HARFLOW3D: A Latency-Oriented 3D-CNN Accelerator Toolflow for HAR on FPGA Devices. (arXiv:2303.17218v1 [cs.AR])

    [http://arxiv.org/abs/2303.17218](http://arxiv.org/abs/2303.17218)

    本研究提出了一种面向FPGA设备的基于延迟的3D-CNN加速器工具链HARFLOW3D，它以机器学习模型和FPGA的特性描述为输入，生成最小化计算延迟的设计。实验证明HARFLOW3D相比其他方案能够实现更低的延迟。

    

    3D卷积神经网络已被证明在人体动作识别任务中具有高效性和最先进的结果。本研究引入一种新的基于流式架构的工具链，将此类模型映射到FPGA上，考虑模型固有特性和目标FPGA设备的特征。HARFLOW3D工具链以ONNX格式的3D卷积神经网络和FPGA特性描述为输入，生成最小化计算延迟的设计。该工具链由多个部分组成，包括i) 3D CNN解析器，ii) 性能和资源模型，iii) 用于在生成的硬件上执行3D模型的调度算法，iv) 针对3D模型量身定制的资源感知优化引擎，v) 自动映射到可合成的FPGA代码。通过对各种3D CNN和FPGA系统配对进行多个实验，展示了工具链支持广泛模型和设备的能力。此外，与其他最先进的3D CNN加速器设计方法相比，该工具链实现了更低的延迟。

    For Human Action Recognition tasks (HAR), 3D Convolutional Neural Networks have proven to be highly effective, achieving state-of-the-art results. This study introduces a novel streaming architecture based toolflow for mapping such models onto FPGAs considering the model's inherent characteristics and the features of the targeted FPGA device. The HARFLOW3D toolflow takes as input a 3D CNN in ONNX format and a description of the FPGA characteristics, generating a design that minimizes the latency of the computation. The toolflow is comprised of a number of parts, including i) a 3D CNN parser, ii) a performance and resource model, iii) a scheduling algorithm for executing 3D models on the generated hardware, iv) a resource-aware optimization engine tailored for 3D models, v) an automated mapping to synthesizable code for FPGAs. The ability of the toolflow to support a broad range of models and devices is shown through a number of experiments on various 3D CNN and FPGA system pairs. Furth
    
[^78]: PopSparse：在IPU上加速的块稀疏矩阵乘法

    PopSparse: Accelerated block sparse matrix multiplication on IPU. (arXiv:2303.16999v1 [cs.LG])

    [http://arxiv.org/abs/2303.16999](http://arxiv.org/abs/2303.16999)

    将大规模神经网络的计算成本降低到可接受的任务性能和加速改进是一个具有挑战的问题。本文介绍了一种利用IPU独特的硬件特性和数据中定义的任何块结构实现在Graphcore IPUs上快速稀疏操作的库——PopSparse。

    

    在深度学习社区中，使用稀疏性降低大规模神经网络的计算成本引起了广泛关注。虽然在维持可接受的任务性能的同时减少FLOP和参数数量取得了许多成功，但实际上获得加速改进通常更加困难，特别是在通用加速器（GPA）上，如使用低精度数字格式的NVIDIA GPU。在本文中，我们介绍了PopSparse，一种利用IPU的独特硬件特性以及数据中定义的任何块结构实现在Graphcore IPUs上快速稀疏操作的库。我们针对两种不同类型的稀疏性：静态稀疏性，其中稀疏模式在编译时固定；动态稀疏性，其中每次运行模型时都可以改变。我们针对各种块大小、矩阵大小和密度在IPU上进行矩阵乘法的基准测试。结果表明：

    Reducing the computational cost of running large scale neural networks using sparsity has attracted great attention in the deep learning community. While much success has been achieved in reducing FLOP and parameter counts while maintaining acceptable task performance, achieving actual speed improvements has typically been much more difficult, particularly on general purpose accelerators (GPAs) such as NVIDIA GPUs using low precision number formats. In this work we introduce PopSparse, a library that enables fast sparse operations on Graphcore IPUs by leveraging both the unique hardware characteristics of IPUs as well as any block structure defined in the data. We target two different types of sparsity: static, where the sparsity pattern is fixed at compile-time; and dynamic, where it can change each time the model is run. We present benchmark results for matrix multiplication for both of these modes on IPU with a range of block sizes, matrix sizes and densities. Results indicate that 
    
[^79]: 随机初始化神经网络进行模型参考自适应控制的函数逼近

    Function Approximation with Randomly Initialized Neural Networks for Approximate Model Reference Adaptive Control. (arXiv:2303.16251v1 [math.OC])

    [http://arxiv.org/abs/2303.16251](http://arxiv.org/abs/2303.16251)

    本论文提出一种新的构造方法——平滑的积分表示，使得可以使用随机初始化的神经网络保证逼近精度，并且可以适用于更广泛的激活函数。

    

    神经网络逼近理论中的经典结果表明，在激活函数满足某些温和的假设条件下，可以通过单层隐藏层的网络逼近任意连续函数。然而，经典理论并没有给出一种构造性方法来生成网络参数以实现所需的精度。最近的研究结果表明，对于专门的激活函数（如ReLU函数和某些类的解析函数），可以通过随机初始化激活的线性组合实现高精度逼近。这些最近的工作利用了特殊的积分表示，这些表示依赖于所使用的具体的激活函数。本文定义了平滑的积分表示，提供了一种使用激活形成目标函数积分表示的方法，而对于这些激活，目前还没有直接的积分表示。新的构造使得可以为随机初始化网络提供逼近保证。

    Classical results in neural network approximation theory show how arbitrary continuous functions can be approximated by networks with a single hidden layer, under mild assumptions on the activation function. However, the classical theory does not give a constructive means to generate the network parameters that achieve a desired accuracy. Recent results have demonstrated that for specialized activation functions, such as ReLUs and some classes of analytic functions, high accuracy can be achieved via linear combinations of randomly initialized activations. These recent works utilize specialized integral representations of target functions that depend on the specific activation functions used. This paper defines mollified integral representations, which provide a means to form integral representations of target functions using activations for which no direct integral representation is currently known. The new construction enables approximation guarantees for randomly initialized networks
    
[^80]: TabRet: 预训练Transformer-based表格模型，支持未知列

    TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. (arXiv:2303.15747v1 [cs.LG])

    [http://arxiv.org/abs/2303.15747](http://arxiv.org/abs/2303.15747)

    提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。

    

    我们提出了一种名为TabRet的可预训练Transformer-based表格模型。TabRet旨在为包含未在预训练中见过的列的下游任务提供支持。与其他方法不同，TabRet在微调之前有一个额外的学习步骤，称为重新标记化，它基于遮蔽自动编码损失来校准特征嵌入。在实验中，我们使用大量的公共健康调查数据对TabRet进行预训练，并在医疗保健分类任务上进行微调，在四个数据集上实现了最佳AUC性能。此外，消融研究表明，在预训练期间进行重新标记化和随机洗牌增强对性能提升有贡献。

    We present \emph{TabRet}, a pre-trainable Transformer-based model for tabular data. TabRet is designed to work on a downstream task that contains columns not seen in pre-training. Unlike other methods, TabRet has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. In experiments, we pre-trained TabRet with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and TabRet achieved the best AUC performance on four datasets. In addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains.
    
[^81]: 深度ReLU神经网络在过参数化情况下的贝叶斯自由能

    Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases. (arXiv:2303.15739v1 [cs.LG])

    [http://arxiv.org/abs/2303.15739](http://arxiv.org/abs/2303.15739)

    本研究针对深度ReLU神经网络，证明了过参数化情况下的Bayesian自由能是有界的，说明Bayesian广义误差不会增加。

    

    在人工智能的许多研究领域中，深度神经网络已被证明可用于估计高维输入空间中的未知函数。然而，它们的泛化性能尚未从理论角度完全澄清，因为它们是不可识别的和奇异的学习机器。此外，ReLU函数不可微，奇异学习理论中的代数或解析方法无法应用于它。本文研究了一种过参数化情况下的深度ReLU神经网络，并证明了Bayesian自由能是有界的，即使层数比估计未知数据生成函数所必需的层数更多。由于Bayesian广义误差等于样本大小的自由能增加，因此我们的结果也表明，Bayesian广义误差不会增加。

    In many research fields in artificial intelligence, it has been shown that deep neural networks are useful to estimate unknown functions on high dimensional input spaces. However, their generalization performance is not yet completely clarified from the theoretical point of view because they are nonidentifiable and singular learning machines. Moreover, a ReLU function is not differentiable, to which algebraic or analytic methods in singular learning theory cannot be applied. In this paper, we study a deep ReLU neural network in overparametrized cases and prove that the Bayesian free energy, which is equal to the minus log marginal likelihoodor the Bayesian stochastic complexity, is bounded even if the number of layers are larger than necessary to estimate an unknown data-generating function. Since the Bayesian generalization error is equal to the increase of the free energy as a function of a sample size, our result also shows that the Bayesian generalization error does not increase ev
    
[^82]: 2D扩散算法的去偏置方法用于文本到3D生成

    Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation. (arXiv:2303.15413v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15413](http://arxiv.org/abs/2303.15413)

    本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。

    

    本文探讨了在文本到3D生成中出现的视角一致性问题，也称为Janus问题。这个问题来自于2D扩散模型的固有偏置，导致生成的3D对象不真实。通过对其进行研究，我们提出了两种方法来去除偏置以实现文本到3D生成的鲁棒性。第一种方法叫做score debiasing，通过逐渐增加2D扩散模型得出的分数的截断值，来达到去除偏置的效果。第二种方法叫做prompt debiasing，利用语言模型确定用户提示和视角提示之间的矛盾词语，并调整视角提示和物体空间摄像机姿态之间的差异。我们的实验结果表明，我们的方法通过显著减少伪影，提高了真实感，并在质量与速度方面取得了良好的平衡。

    The view inconsistency problem in score-distilling text-to-3D generation, also known as the Janus problem, arises from the intrinsic bias of 2D diffusion models, which leads to the unrealistic generation of 3D objects. In this work, we explore score-distilling text-to-3D generation and identify the main causes of the Janus problem. Based on these findings, we propose two approaches to debias the score-distillation frameworks for robust text-to-3D generation. Our first approach, called score debiasing, involves gradually increasing the truncation value for the score estimated by 2D diffusion models throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts utilizing a language model and adjusts the discrepancy between view prompts and object-space camera poses. Our experimental results show that our methods improve realism by significantly reducing artifacts and achieve a good trade-off between fa
    
[^83]: 应用SMILES序列的Transformer模型在学习手性时存在困难

    Difficulty in learning chirality for Transformer fed with SMILES. (arXiv:2303.11593v1 [cs.LG])

    [http://arxiv.org/abs/2303.11593](http://arxiv.org/abs/2303.11593)

    应用SMILES序列的Transformer模型在学习分子结构的整体性和手性方面存在困难，需要进行长时间的训练。生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。

    

    近年来，基于对极其多样的分子进行表示学习的描述符生成已经得到了发展，特别是那些将自然语言处理（NLP）模型应用于SMILES，即分子结构的文字表示的模型。然而，关于这些模型如何理解化学结构的研究很少。为了解决这个问题，我们调查了一种代表性的NLP模型——Transformer，在学习SMILES和化学结构之间的关系。结果表明，虽然Transformer快速学习分子的部分结构，但需要进行长时间的训练才能理解整体结构。与之一致的是，在不同的学习步骤中生成的描述符用于分子性质预测时的准确率从开始到训练结束都是相似的。此外，我们发现Transformer需要特别长的训练时间才能学习手性，并且有时会出现低翻译准确率的停滞现象。

    Recent years have seen development of descriptor generation based on representation learning of extremely diverse molecules, especially those that apply natural language processing (NLP) models to SMILES, a literal representation of molecular structure. However, little research has been done on how these models understand chemical structure. To address this, we investigated the relationship between the learning progress of SMILES and chemical structure using a representative NLP model, the Transformer. The results suggest that while the Transformer learns partial structures of molecules quickly, it requires extended training to understand overall structures. Consistently, the accuracy of molecular property predictions using descriptors generated from models at different learning steps was similar from the beginning to the end of training. Furthermore, we found that the Transformer requires particularly long training to learn chirality and sometimes stagnates with low translation accura
    
[^84]: 基于深度学习的振动信号去噪方法

    Vibration Signal Denoising Using Deep Learning. (arXiv:2303.11413v1 [eess.SP])

    [http://arxiv.org/abs/2303.11413](http://arxiv.org/abs/2303.11413)

    本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。

    

    由脚步引起的结构振动信号被广泛用于人员识别、定位、人类活动推断、结构健康监测等任务。然而，由于环境噪声、电磁干扰等因素的影响，实际采集的信号通常会带有噪声。噪声的存在影响了信号处理过程，从而影响了最终任务的准确性和误差。本文主要探讨了基于深度学习的去除脚步引起的振动信号的噪声的方法。我们考虑了不同类型的噪声，包括高斯噪声和非平稳噪声等。

    Structure vibration signals induced by footsteps are widely used for tasks like occupant identification, localization, human activity inference, structure health monitoring and so on. The vibration signals are collected as time series with amplitude values. However, the collected signals are always noisy in practice due to the influence of environmental noise, electromagnetic interference and other factors. The presence of noise affects the process of signal analysis, thus affecting the accuracy and error of the final tasks. In this paper, we mainly explore the denoising methods for footstep-induced vibration signals. We have considered different kinds of noise including stationary noises such as gaussian noises and non-stationary noises such as item-dropping vibration noise and music noises.
    
[^85]: 对抗训练是否需要使用整个训练数据集？

    Do we need entire training data for adversarial training?. (arXiv:2303.06241v1 [cs.CV])

    [http://arxiv.org/abs/2303.06241](http://arxiv.org/abs/2303.06241)

    本文提出了一种新的对抗训练方法，通过对训练数据集进行筛选，仅使用易受对抗攻击的样本进行训练，从而减少训练时间。

    This paper proposes a new adversarial training method that reduces training time by selecting only the adversarially-prone samples from the training dataset.

    深度神经网络（DNN）被用于解决许多领域的问题，包括自动驾驶汽车和医学图像等安全关键领域。DNN对抗攻击的脆弱性已经被广泛关注。近年来，已经提出了许多方法来通过对抗训练来解决这个问题。几乎所有的方法都会为整个训练数据集生成对抗性示例，从而大大增加了训练时间。我们展示了通过仅使用训练数据的子集进行对抗训练，可以减少任何对抗训练算法的训练时间。为了选择子集，我们从训练数据中过滤出易受对抗攻击的样本。我们对所有训练样本执行简单的对抗攻击，以过滤出这个子集。在这个攻击中，我们向每个像素添加一个小扰动和几条网格线到输入图像中。我们对易受对抗攻击的子集进行对抗训练，并且...

    Deep Neural Networks (DNNs) are being used to solve a wide range of problems in many domains including safety-critical domains like self-driving cars and medical imagery. DNNs suffer from vulnerability against adversarial attacks. In the past few years, numerous approaches have been proposed to tackle this problem by training networks using adversarial training. Almost all the approaches generate adversarial examples for the entire training dataset, thus increasing the training time drastically. We show that we can decrease the training time for any adversarial training algorithm by using only a subset of training data for adversarial training. To select the subset, we filter the adversarially-prone samples from the training data. We perform a simple adversarial attack on all training examples to filter this subset. In this attack, we add a small perturbation to each pixel and a few grid lines to the input image.  We perform adversarial training on the adversarially-prone subset and mi
    
[^86]: 序列多标签分类的标签注意力网络：你以前看错了自注意力

    Label Attention Network for sequential multi-label classification: you were looking at a wrong self-attention. (arXiv:2303.00280v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00280](http://arxiv.org/abs/2303.00280)

    LANET是一种标签注意力网络，可用于解决序列多标签分类问题，能够更好地捕捉标签之间的相互关系，并且在实验中表现良好。

    

    大多数可用的用户信息可以表示为时间戳事件的序列。每个事件被分配了一组分类标签，其未来结构非常重要。例如，我们的目标是预测下一个客户购买的物品或明天的客户交易中的一组物品。这是一个序列数据的多标签分类问题。现代方法针对序列数据的转换器架构引入了元素的自关注。在这种情况下，我们考虑事件的时间交互作用，但是失去了标签之间的信息依赖关系。受到这个缺点的启发，我们建议利用先于预测步骤的标签的自注意机制。由于我们的方法是标签注意力网络，因此我们称之为LANET。实验证据表明，LANET优于已建立的模型的性能，并极大地捕捉了标签之间的相互关系。例如，我们的方法的微观AUC是0.9。

    Most of the available user information can be represented as a sequence of timestamped events. Each event is assigned a set of categorical labels whose future structure is of great interest. For instance, our goal is to predict a group of items in the next customer's purchase or tomorrow's client transactions. This is a multi-label classification problem for sequential data. Modern approaches focus on transformer architecture for sequential data introducing self-attention for the elements in a sequence. In that case, we take into account events' time interactions but lose information on label inter-dependencies. Motivated by this shortcoming, we propose leveraging a self-attention mechanism over labels preceding the predicted step. As our approach is a Label-Attention NETwork, we call it LANET. Experimental evidence suggests that LANET outperforms the established models' performance and greatly captures interconnections between labels. For example, the micro-AUC of our approach is $0.9
    
[^87]: 动态提示提高对抗性转移性能

    Boosting Adversarial Transferability using Dynamic Cues. (arXiv:2302.12252v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12252](http://arxiv.org/abs/2302.12252)

    本研究通过优化时间提示来引入动态特征，提高了图像模型到视频模型的对抗攻击的转移性能。

    

    对抗性攻击在图像模型之间的转移性能已经得到广泛的研究。然而，从图像模型生成的攻击不能捕捉到移动物体或变化场景的动态特征，因此对于表示丰富的图像模型（如Supervised Vision Transformers、Self-supervised ViTs和Vision-language模型）到黑盒视频模型的对抗攻击的转移性能降低。本研究为图像模型引入了动态提示，通过冻结图像模型来优化时间提示，从而捕捉动态特征，提高了对抗性攻击的转移性能。

    The transferability of adversarial perturbations between image models has been extensively studied. In this case, an attack is generated from a known surrogate \eg, the ImageNet trained model, and transferred to change the decision of an unknown (black-box) model trained on an image dataset. However, attacks generated from image models do not capture the dynamic nature of a moving object or a changing scene due to a lack of temporal cues within image models. This leads to reduced transferability of adversarial attacks from representation-enriched \emph{image} models such as Supervised Vision Transformers (ViTs), Self-supervised ViTs (\eg, DINO), and Vision-language models (\eg, CLIP) to black-box \emph{video} models. In this work, we induce dynamic cues within the image models without sacrificing their original performance on images. To this end, we optimize \emph{temporal prompts} through frozen image models to capture motion dynamics. Our temporal prompts are the result of a learnabl
    
[^88]: KHAN：基于知识的层次化注意力网络用于准确的政治立场预测

    KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate Political Stance Prediction. (arXiv:2302.12126v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12126](http://arxiv.org/abs/2302.12126)

    本文提出了一种新颖的知识感知政治立场预测方法，采用层次化注意力网络、外部知识库和知识感知损失函数，可以有效地捕捉新闻文章中的关键信息，优于现有方法。

    

    新闻文章的政治立场预测已被广泛研究，以减轻回声室效应，即人们落入其思想，强化其现有信念。以往关于政治立场问题的研究重点在于（1）识别可以反映新闻文章政治立场的政治因素和（2）有效地捕捉这些因素。尽管它们在经验上成功了，但在政治立场预测中其识别的因素的有效性没有得到充分证明。在此基础上，本文通过用户研究调查政治立场预测中的重要因素，并观察到新闻文章的环境和语调（隐含）以及文章中涉及的现实实体的外部知识（显式）在确定其政治立场方面是重要的。基于这一观察结果，我们提出了一种新颖的知识感知政治立场预测方法（KHAN），采用（1）层次化注意力网络有效地捕捉新闻文章中的关键信息，（2）外部知识库提供关于文章中提到的实体的额外信息，以及（3）知识感知损失函数学习优先考虑重要信息。多个数据集上的实验结果表明，我们的方法显著优于现有方法。

    The political stance prediction for news articles has been widely studied to mitigate the echo chamber effect -- people fall into their thoughts and reinforce their pre-existing beliefs. The previous works for the political stance problem focus on (1) identifying political factors that could reflect the political stance of a news article and (2) capturing those factors effectively. Despite their empirical successes, they are not sufficiently justified in terms of how effective their identified factors are in the political stance prediction. Motivated by this, in this work, we conduct a user study to investigate important factors in political stance prediction, and observe that the context and tone of a news article (implicit) and external knowledge for real-world entities appearing in the article (explicit) are important in determining its political stance. Based on this observation, we propose a novel knowledge-aware approach to political stance prediction (KHAN), employing (1) hierar
    
[^89]: 基于拓扑学的特征选择方法：一种基于图论的过滤特征选择方法

    Topological Feature Selection: A Graph-Based Filter Feature Selection Approach. (arXiv:2302.09543v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09543](http://arxiv.org/abs/2302.09543)

    本文提出了一种基于图论的特征选择方法，利用拓扑学和依赖关系，具有高度灵活性和解释性，在16个基准数据集上显示出优于或匹配于当前最先进技术的表现。

    

    本文介绍了一种新型的无监督的基于图论过滤方法进行特征选择的技术，利用了拓扑约束网络表示的威力。我们使用一系列弦图（三角最大过滤图）模拟特征之间的相互依赖关系，并通过研究特征在网络内的相对位置来最大化特征相关性的可能性。这种方法相对于其他方法有三个特点：（i）高度可调，易于适应输入数据的性质；（ii）完全可解释，同时保持了显著的简单性；（iii）计算成本比其替代方案更加便宜。我们在来自不同应用领域的16个基准数据集上测试了我们的算法，结果表明在异构评估条件下，它优于或与当前最先进技术相匹配。

    In this paper, we introduce a novel unsupervised, graph-based filter feature selection technique which exploits the power of topologically constrained network representations. We model dependency structures among features using a family of chordal graphs (the Triangulated Maximally Filtered Graph), and we maximise the likelihood of features' relevance by studying their relative position inside the network. Such an approach presents three aspects that are particularly satisfactory compared to its alternatives: (i) it is highly tunable and easily adaptable to the nature of input data; (ii) it is fully explainable, maintaining, at the same time, a remarkable level of simplicity; (iii) it is computationally cheaper compared to its alternatives. We test our algorithm on 16 benchmark datasets from different applicative domains showing that it outperforms or matches the current state-of-the-art under heterogeneous evaluation conditions.
    
[^90]: InstructABSA: 基于指令学习的方面情感分析

    InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis. (arXiv:2302.08624v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08624](http://arxiv.org/abs/2302.08624)

    InstructABSA是一种使用指令学习范式的方面情感分析方法，能够显著提高Aspect Term Extraction、Aspect Term Sentiment Classification、和Joint Task subtasks三个子任务的性能，并且在多个数据集上表现超过之前的最先进方法。

    

    本文介绍了InstructABSA，一种使用指令学习范式进行Aspect Based Sentiment Analysis (ABSA) 所有子任务（Aspect Term Extraction (ATE)，Aspect Term Sentiment Classification (ATSC)，以及Joint Task modeling）的方法。我们的方法对每个训练样本引入了正面、负面、和中性的例子，并使用指令来调整每个ABSA子任务的模型（Tk-Instruct），从而显著提高了性能。在Sem Eval 2014、2015和2016数据集上的实验结果表明，在所有三个ABSA子任务（ATE、ATSC和Joint Task）上，InstructABSA在性能上都比之前的最先进方法（SOTA）表现出了显著的优势，并且表现超过了7倍大的模型。特别是，在Rest14 ATE子任务上，InstructABSA超过了SOTA 7.31%的得分，Rest15 ATSC子任务上也有提升，并且在Lapt14 Joint Task上的表现提升了8.63%点。我们的结果还表明，对于所有三个子任务，InstructABSA具有强大的新领域泛化能力。

    In this paper, we present InstructABSA, Aspect Based Sentiment Analysis (ABSA) using the instruction learning paradigm for all ABSA subtasks: Aspect Term Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and Joint Task modeling. Our method introduces positive, negative, and neutral examples to each training sample, and instruction tunes the model (Tk-Instruct) for each ABSA subtask, yielding significant performance improvements. Experimental results on the Sem Eval 2014, 15, and 16 datasets demonstrate that InstructABSA outperforms the previous state-of-the-art (SOTA) approaches on all three ABSA subtasks (ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x larger models. In particular, InstructABSA surpasses the SOTA on the Rest14 ATE subtask by 7.31% points, Rest15 ATSC subtask by and on the Lapt14 Joint Task by 8.63% points. Our results also suggest a strong generalization ability to new domains across all three subtasks
    
[^91]: 用多模态融合方法进行神经结构搜索来诊断痴呆症

    Neural Architecture Search with Multimodal Fusion Methods for Diagnosing Dementia. (arXiv:2302.05894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05894](http://arxiv.org/abs/2302.05894)

    本文提出利用多模态融合方法进行神经结构搜索来诊断痴呆症，解决了以前工作中CNN结构寻找耗时的问题和多模态融合效果不佳的问题。

    

    阿尔茨海默病（AD）影响一个人的记忆、思维和语言能力，严重损害个体的生活。早期诊断非常重要，因为它可以使人们及时得到医疗帮助并确保生活质量。因此，利用自发言语和机器学习方法来识别AD患者已成为一个热门话题。大多数以前的工作使用卷积神经网络（CNN）处理输入信号。然而，寻找CNN结构是一个耗时的过程，需要领域专业知识。此外，研究人员介绍了早期和后期融合方法，用于融合不同的模态或者在训练期间连接不同模态的表示，因此不能捕捉模态间的交互作用。为了解决这些限制，首先我们利用神经结构搜索（NAS）方法自动发现高效的CNN结构。接下来，我们利用几种融合方法，包括多模态分解。

    Alzheimer's dementia (AD) affects memory, thinking, and language, deteriorating person's life. An early diagnosis is very important as it enables the person to receive medical help and ensure quality of life. Therefore, leveraging spontaneous speech in conjunction with machine learning methods for recognizing AD patients has emerged into a hot topic. Most of the previous works employ Convolutional Neural Networks (CNNs), to process the input signal. However, finding a CNN architecture is a time-consuming process and requires domain expertise. Moreover, the researchers introduce early and late fusion approaches for fusing different modalities or concatenate the representations of the different modalities during training, thus the inter-modal interactions are not captured. To tackle these limitations, first we exploit a Neural Architecture Search (NAS) method to automatically find a high performing CNN architecture. Next, we exploit several fusion methods, including Multimodal Factorized
    
[^92]: 一种松弛的近端梯度下降算法用于带有近端去噪器的收敛插入-播放算法

    A relaxed proximal gradient descent algorithm for convergent plug-and-play with proximal denoiser. (arXiv:2301.13731v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.13731](http://arxiv.org/abs/2301.13731)

    本文提出了一种新的收敛插入播放算法，使用一个松弛的近端去噪器和一个松弛的PGD算法，能够收敛于更广泛的正则化参数范围内。

    

    本文提出了一种新的收敛插入播放算法。插入播放方法是一种有效的迭代算法，用于解决被表述为数据适应项和正则化项之和的图像反问题的最小化问题。插入播放方法通过在近端算法（如近端梯度下降）中插入一个预先训练好的去噪器来执行正则化。为确保PnP方案的收敛，许多工作研究深度去噪器的特定参数化。然而，现有结果要么需要无法验证的假设或次优假设，要么在逆问题的参数上假设限制性条件。观察到这些限制可能是由于使用的近端算法，因此，我们研究了一种松弛版本的PGD算法（用于最小化凸函数和弱凸函数之和）。当与一个松弛的近端去噪器插入时，我们展示了所提出的PnP-$\alpha$PGD算法能够收敛于更广泛的正则化参数范围内。

    This paper presents a new convergent Plug-and-Play (PnP) algorithm. PnP methods are efficient iterative algorithms for solving image inverse problems formulated as the minimization of the sum of a data-fidelity term and a regularization term. PnP methods perform regularization by plugging a pre-trained denoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD). To ensure convergence of PnP schemes, many works study specific parametrizations of deep denoisers. However, existing results require either unverifiable or suboptimal hypotheses on the denoiser, or assume restrictive conditions on the parameters of the inverse problem. Observing that these limitations can be due to the proximal algorithm in use, we study a relaxed version of the PGD algorithm for minimizing the sum of a convex function and a weakly convex one. When plugged with a relaxed proximal denoiser, we show that the proposed PnP-$\alpha$PGD algorithm converges for a wider range of regularization parameters
    
[^93]: 使用联合扩散模型进行数据表示学习

    Learning Data Representations with Joint Diffusion Models. (arXiv:2301.13622v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13622](http://arxiv.org/abs/2301.13622)

    本文提出了一种扩展香草扩散模型的方法，使用分类器进行联合端到端训练，以提高分类和生成数据的质量。

    

    联合机器学习模型通常允许合成和分类数据，但常常在这些任务之间表现不平衡，或者不稳定。本文提出了扩展香草扩散模型以使用分类器进行稳定的联合端到端训练的方法。该模型在所有评估基准测试中在分类和生成质量方面均优于最新的混合方法。在我们的联合训练方法上，本文还介绍了如何通过引入一种方法进行直接益处共享生成和鉴别表示，以提供视觉反事实解释。

    Joint machine learning models that allow synthesizing and classifying data often offer uneven performance between those tasks or are unstable to train. In this work, we depart from a set of empirical observations that indicate the usefulness of internal representations built by contemporary deep diffusion-based generative models not only for generating but also predicting. We then propose to extend the vanilla diffusion model with a classifier that allows for stable joint end-to-end training with shared parameterization between those objectives. The resulting joint diffusion model outperforms recent state-of-the-art hybrid methods in terms of both classification and generation quality on all evaluated benchmarks. On top of our joint training approach, we present how we can directly benefit from shared generative and discriminative representations by introducing a method for visual counterfactual explanations.
    
[^94]: 视觉学习者遇见Web图像-文本对

    Vision Learners Meet Web Image-Text Pairs. (arXiv:2301.07088v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07088](http://arxiv.org/abs/2301.07088)

    本论文提出了一种基于网络数据的新型视觉学习方法MUlti-modal Generator (MUG)。在视觉数据集的转移学习任务上取得了最先进的表现，是之前最佳结果的3.4%和2.2%的提升。

    

    大多数最新的自监督学习方法都是在维护良好的ImageNet-1K数据集上进行预训练的。在本研究中，考虑到网络数据的出色可伸缩性，我们认为自我监督预训练应该基于嘈杂的网络源图文配对数据。首先，我们在如此设置下，对大规模网络数据上的代表性自监督预训练方法进行了基准研究。我们比较了一系列方法，包括使用被屏蔽的训练目标的单模式方法和使用图像-文本对比训练的多模式方法。我们发现，现有的多模态方法在视觉转移学习任务上并不比单模态方法表现更好。我们提出了一个信息论视角来解释这些基准结果，这提供了如何设计新型视觉学习者的见解。受到这些见解的启发，我们提出了一种新的视觉表示预训练方法——多模式生成器（MUG），它从可伸缩的网络源图文数据中学习。MUG在几个视觉数据集的转移学习任务上取得了最先进的性能，在CIFAR-10上优于之前最佳的结果3.4％，在STL-10上优于之前最佳的结果2.2％。

    Most recent self-supervised learning methods are pre-trained on the well-curated ImageNet-1K dataset. In this work, given the excellent scalability of web data, we consider self-supervised pre-training on noisy web sourced image-text paired data. First, we conduct a benchmark study of representative self-supervised pre-training methods on large-scale web data in a like-for-like setting. We compare a range of methods, including single-modal ones that use masked training objectives and multi-modal ones that use image-text constrastive training. We observe that existing multi-modal methods do not outperform their single-modal counterparts on vision transfer learning tasks. We derive an information-theoretical view to explain these benchmark results, which provides insight into how to design a novel vision learner. Inspired by this insight, we present a new visual representation pre-training method, MUlti-modal Generator~(MUG), that learns from scalable web sourced image-text data. MUG ach
    
[^95]: 多输出可学习性的特征化研究

    A Characterization of Multioutput Learnability. (arXiv:2301.02729v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.02729](http://arxiv.org/abs/2301.02729)

    该论文研究了多输出函数类的学习问题，提出了多输出函数类学习的特征化判别标准，即每个单输出子类可学习时多输出函数类才可学习，在多标记分类和多输出回归领域取得了重要进展。

    

    本文考虑了批处理和在线学习中的多输出函数类学习问题。我们证明了，当且仅当函数类的每个单输出子类都可学习时，多输出函数类才是可学习的。这提供了多标记分类和多输出回归在批处理和在线学习中可学习性的完整特征化。作为扩展，我们还考虑了在赌博反馈环境下的多标记学习，并展示了与完全反馈环境下类似的特征化。

    We consider the problem of learning multioutput function classes in batch and online settings. In both settings, we show that a multioutput function class is learnable if and only if each single-output restriction of the function class is learnable. This provides a complete characterization of the learnability of multilabel classification and multioutput regression in both batch and online settings. As an extension, we also consider multilabel learnability in the bandit feedback setting and show a similar characterization as in the full-feedback setting.
    
[^96]: 自监督 Cut-and-Paste GAN 进行对象分割

    Self-Supervised Object Segmentation with a Cut-and-Pasting GAN. (arXiv:2301.00366v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.00366](http://arxiv.org/abs/2301.00366)

    提出了一种基于自监督的 Cut-and-Paste GAN，用于前景对象分割和组合图像生成，无需手动标注，通过学习全局数据表示和语义结构信息，实现了有意义的遮罩生成。

    

    本文提出了一种基于自监督的 Cut-and-Paste GAN，用于进行前景对象分割并生成逼真的组合图像，无需手动标注。通过一个简单而有效的自监督方法，结合基于 U-Net 的鉴别器，完成了这一目标。该方法扩展了标准鉴别器的能力，不仅通过分类（真/假）学习全局数据表示，而且还通过使用自监督任务创建的伪标签学习语义和结构信息。该方法使生成器能够通过强制它从辨别器学习每像素的有意义的信息和全局图像反馈来创建有意义的遮罩。实验表明，我们提出的方法在标准基准数据集上显著优于现有最先进方法。

    This paper proposes a novel self-supervised based Cut-and-Paste GAN to perform foreground object segmentation and generate realistic composite images without manual annotations. We accomplish this goal by a simple yet effective self-supervised approach coupled with the U-Net based discriminator. The proposed method extends the ability of the standard discriminators to learn not only the global data representations via classification (real/fake) but also learn semantic and structural information through pseudo labels created using the self-supervised task. The proposed method empowers the generator to create meaningful masks by forcing it to learn informative per-pixel as well as global image feedback from the discriminator. Our experiments demonstrate that our proposed method significantly outperforms the state-of-the-art methods on the standard benchmark datasets.
    
[^97]: 视觉Transformer是参数高效的音像学习者

    Vision Transformers are Parameter-Efficient Audio-Visual Learners. (arXiv:2212.07983v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.07983](http://arxiv.org/abs/2212.07983)

    本文研究了冻结ViTs在没有微调任何原始参数的情况下将其推广到音像数据的能力。通过使用一个名为LAVISH的适配器和少数的可训练参数，有效融合视觉和音频提示，并在使用较少可调参数和不依赖昂贵的音频预训练的情况下，在各种音像任务上取得了竞争性性能。

    

    过去几年中，视觉Transformer（ViTs）在各种计算机视觉任务上取得了令人瞩目的成果。本文研究了仅在视觉数据上进行预训练的冻结ViTs在没有微调任何原始参数的情况下，将其推广到音像数据的能力。为此，我们提出了一种名为latent audio-visual hybrid（LAVISH）的适配器，通过向每个冻结ViT层注入少量可训练参数来将预训练的ViT调适用于音像任务。为了有效地融合视觉和音频提示，我们的LAVISH适配器使用一小组潜在令牌，形成一个注意瓶颈，从而消除了标准交叉关注的二次成本。与现有的模态特定音像方法相比，我们的方法在使用较少的可调参数并且不依赖昂贵的音频预训练或外部音频编码器的情况下，能够在各种音像任务上取得竞争性甚至更好的性能。我们的代码可在https://genj找到。

    Vision transformers (ViTs) have achieved impressive results on various computer vision tasks in the last several years. In this work, we study the capability of frozen ViTs, pretrained only on visual data, to generalize to audio-visual data without finetuning any of its original parameters. To do so, we propose a latent audio-visual hybrid (LAVISH) adapter that adapts pretrained ViTs to audio-visual tasks by injecting a small number of trainable parameters into every layer of a frozen ViT. To efficiently fuse visual and audio cues, our LAVISH adapter uses a small set of latent tokens, which form an attention bottleneck, thus, eliminating the quadratic cost of standard cross-attention. Compared to the existing modality-specific audio-visual methods, our approach achieves competitive or even better performance on various audio-visual tasks while using fewer tunable parameters and without relying on costly audio pretraining or external audio encoders. Our code is available at https://genj
    
[^98]: 从原始数据中共同学习视觉和听觉语音表示的RAVEn算法研究

    Jointly Learning Visual and Auditory Speech Representations from Raw Data. (arXiv:2212.06246v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06246](http://arxiv.org/abs/2212.06246)

    本文提出了一种自监督算法RAVEn，能够同时学习视觉和听觉语音表示，无需准备大量标记数据，能在低资源和高资源数据设置下得到显著的结果，相比其他自监督算法在视觉语音识别上表现更好，在结合少量标记数据的情况下仍可超过使用大量非公共数据的半监督算法。

    

    本文提出了一种自监督多模态方法RAVEn，用于共同学习视觉和听觉语音表示。我们的预训练目标包括编码掩蔽输入，然后预测由缓慢演化的动量编码器生成的上下文目标。由于视频和音频之间的固有差异，我们的设计对于两种模态的先前任务是不对称的：听觉流预测视觉和听觉目标，而视觉流只预测听觉目标。当微调来自单个预训练阶段的视觉和听觉编码器时，无论是低资源还是高资源标记数据设置，我们观察到强大的结果。值得注意的是，在LRS3上RAVEn超越了所有自监督方法的视觉语音识别（VSR），并且将RAVEn与仅使用30小时标记数据的自我训练相结合，甚至胜过一个仅在90,000小时非公共数据上训练的最近的半监督方法。

    We present RAVEn, a self-supervised multi-modal approach to jointly learn visual and auditory speech representations. Our pre-training objective involves encoding masked inputs, and then predicting contextualised targets generated by slowly-evolving momentum encoders. Driven by the inherent differences between video and audio, our design is asymmetric w.r.t. the two modalities' pretext tasks: Whereas the auditory stream predicts both the visual and auditory targets, the visual one predicts only the auditory targets. We observe strong results in low- and high-resource labelled data settings when fine-tuning the visual and auditory encoders resulting from a single pre-training stage, in which the encoders are jointly trained. Notably, RAVEn surpasses all self-supervised methods on visual speech recognition (VSR) on LRS3, and combining RAVEn with self-training using only 30 hours of labelled data even outperforms a recent semi-supervised method trained on 90,000 hours of non-public data. 
    
[^99]: 神经Bandits用于数据挖掘：搜索有害多药疗法

    Neural Bandits for Data Mining: Searching for Dangerous Polypharmacy. (arXiv:2212.05190v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.05190](http://arxiv.org/abs/2212.05190)

    本研究提出了一种名为OptimNeuralTS的策略，用于搜索有害多药疗法，基于神经汤普森采样和差分进化，能够高效地挖掘索赔数据库并建立药物组合与健康结果之间的预测模型。

    

    多药疗法通常被定义为同时服用五种或更多药物，是老年人中普遍存在的现象。其中一些不当的多药疗法可能与不良健康结果相关，如死亡或住院。考虑到问题的组合性质以及索赔数据库的大小和计算给定药物组合的确切关联度所需的成本，不可能调查每种可能的药物组合。因此，我们建议优化搜索潜在不当的多药疗法（PIPs）。为此，我们提出了基于神经汤普森采样和差分进化的OptimNeuralTS策略，以高效地挖掘索赔数据集并建立药物组合与健康结果之间的预测模型。我们使用一个由内部开发的多药疗法数据模拟器生成的两个数据集来基准测试我们的方法，该模拟器包含500种药物。

    Polypharmacy, most often defined as the simultaneous consumption of five or more drugs at once, is a prevalent phenomenon in the older population. Some of these polypharmacies, deemed inappropriate, may be associated with adverse health outcomes such as death or hospitalization. Considering the combinatorial nature of the problem as well as the size of claims database and the cost to compute an exact association measure for a given drug combination, it is impossible to investigate every possible combination of drugs. Therefore, we propose to optimize the search for potentially inappropriate polypharmacies (PIPs). To this end, we propose the OptimNeuralTS strategy, based on Neural Thompson Sampling and differential evolution, to efficiently mine claims datasets and build a predictive model of the association between drug combinations and health outcomes. We benchmark our method using two datasets generated by an internally developed simulator of polypharmacy data containing 500 drugs an
    
[^100]: 一种用于持续半监督学习的软最近邻框架

    A soft nearest-neighbor framework for continual semi-supervised learning. (arXiv:2212.05102v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.05102](http://arxiv.org/abs/2212.05102)

    该论文介绍了一种用于持续半监督学习的软最近邻框架，该框架利用最近邻分类器来非线性地划分特征空间并非参数地建模潜在的数据分布，以避免模型忘记对未标记数据表示并过度拟合标记的样本。

    

    尽管取得了显着进展，最先进的持续学习方法的表现仍然依赖于完全标记的数据的不现实情况。在本文中，我们解决了这一挑战，提出了一种适用于持续半监督学习的方法——一种未标记的数据样本不全部标记的情况。在这种情况下的一个主要问题是模型会忘记未标记数据的表示，并过度拟合标记的样本。我们利用最近邻分类器的威力来非线性地划分特征空间，并由于其非参数性质而灵活地对潜在的数据分布进行建模。这使得模型能够为当前任务学习强大的表示，并从以前的任务中提炼相关的信息。我们进行了彻底的实验评估，并展示了我们的方法以较大的优势优于所有现有的方法，在持续半监督学习范式上树立了坚实的现有技术。

    Despite significant advances, the performance of state-of-the-art continual learning approaches hinges on the unrealistic scenario of fully labeled data. In this paper, we tackle this challenge and propose an approach for continual semi-supervised learning--a setting where not all the data samples are labeled. A primary issue in this scenario is the model forgetting representations of unlabeled data and overfitting the labeled samples. We leverage the power of nearest-neighbor classifiers to nonlinearly partition the feature space and flexibly model the underlying data distribution thanks to its non-parametric nature. This enables the model to learn a strong representation for the current task, and distill relevant information from previous tasks. We perform a thorough experimental evaluation and show that our method outperforms all the existing approaches by large margins, setting a solid state of the art on the continual semi-supervised learning paradigm. For example, on CIFAR-100 we
    
[^101]: 变分自编码器的三种变体

    Three Variations on Variational Autoencoders. (arXiv:2212.04451v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04451](http://arxiv.org/abs/2212.04451)

    本文针对变分自编码器提出三种变体，其中一种与原模型的ELBO逼近相比产生了证据上限（EUBO），可用来查询模型收敛情况。

    

    变分自编码器（VAE）是一类基于已知数据推断的生成概率潜变量模型。我们通过引入第二个参数编码器/解码器对VAE进行了三种变体的开发，对于其中的一种变体，还引入了一个额外的固定编码器。编码器/解码器的参数将通过神经网络进行学习。固定编码器则由概率性PCA获得。这些变体与原始VAE的下限证据（ELBO）逼近进行了比较。其中一种变体产生了证据上限（EUBO），可与原始ELBO一起用来查询VAE的收敛情况。

    Variational autoencoders (VAEs) are one class of generative probabilistic latent-variable models designed for inference based on known data. We develop three variations on VAEs by introducing a second parameterized encoder/decoder pair and, for one variation, an additional fixed encoder. The parameters of the encoders/decoders are to be learned with a neural network. The fixed encoder is obtained by probabilistic-PCA. The variations are compared to the Evidence Lower Bound (ELBO) approximation to the original VAE. One variation leads to an Evidence Upper Bound (EUBO) that can be used in conjunction with the original ELBO to interrogate the convergence of the VAE.
    
[^102]: 一种用神经网络筛选荧光望远镜数据中轨迹事件的方法

    A Neural Network Approach for Selecting Track-like Events in Fluorescence Telescope Data. (arXiv:2212.03787v2 [astro-ph.IM] UPDATED)

    [http://arxiv.org/abs/2212.03787](http://arxiv.org/abs/2212.03787)

    该论文研究了如何使用神经网络在荧光望远镜数据中筛选出轨迹事件，结合实验测试了注册极高能宇宙射线的可能性。

    

    2016-2017年，TUS进行了首次测试通过观测地球夜间大气中的紫外线荧光辐射来注册极高能宇宙射线(UHECRs)的可能性。自2019年以来，俄罗斯-意大利荧光望远镜(Mini-EUSO)一直在国际空间站上运行。计划于2023年进行平流层实验EUSO-SPB2，该实验将使用荧光望远镜来注册UHECRs。我们展示了如何使用简单的卷积神经网络在这些仪器获得的多样数据中有效地找到轨迹事件。

    In 2016-2017, TUS, the world's first experiment for testing the possibility of registering ultra-high energy cosmic rays (UHECRs) by their fluorescent radiation in the night atmosphere of Earth was carried out. Since 2019, the Russian-Italian fluorescence telescope (FT) Mini-EUSO ("UV Atmosphere") has been operating on the ISS. The stratospheric experiment EUSO-SPB2, which will employ an FT for registering UHECRs, is planned for 2023. We show how a simple convolutional neural network can be effectively used to find track-like events in the variety of data obtained with such instruments.
    
[^103]: 在图像分类的失败检测评估实践上进行反思的呼吁

    A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification. (arXiv:2211.15259v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15259](http://arxiv.org/abs/2211.15259)

    本篇论文呼吁对图像分类中失败检测的评估实践进行反思。虽然现有的技术都在尝试通过置信度检测错误预测，但是它们目前构成了独立的研究领域，存在评估标准的不一致性。因此，我们需要进行综合和现实的评估，以解决当前存在的问题。

    

    在野外可靠地应用基于机器学习的决策系统是当前领域正在研究的主要挑战之一。许多现有的方法旨在通过分配置信度得到检测到错误预测的结果。这种置信度可以通过量化模型的预测不确定性、学习明确的评分函数或评估输入是否符合训练分布来获得。尽管这些方法都声明要解决在实际应用中检测分类器失败的相同最终目标，但它们目前在很大程度上构成了各自独立的研究领域，具有单独的评估协议，这些协议可能排除了大量相关方法或忽略了大量相关的失败来源。在这项工作中，我们系统地揭示了这些不一致性带来的当前缺陷，并提出了对于全面和现实的失败检测评估的要求。

    Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-life application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demon
    
[^104]: 计算流体力学中机器学习的新趋势

    Emerging trends in machine learning for computational fluid dynamics. (arXiv:2211.15145v2 [physics.flu-dyn] UPDATED)

    [http://arxiv.org/abs/2211.15145](http://arxiv.org/abs/2211.15145)

    本文讨论了机器学习在计算流体力学领域中的新趋势，并重点讨论了ML和CFD之间的协同效应，还评估了仍在开发中的领域，提出了平衡谨慎乐观的视角。

    

    科学界对机器学习的重新关注正在开辟许多新的研究领域。本文讨论了机器学习在计算流体力学领域中的新趋势，重点讨论了ML和CFD之间已经产生的协同效应，并评估了目前仍在开发中且可能在未来几年产生重要效益的领域。我们认为，强调谨慎乐观的平衡视角对于这些新兴方法非常重要。

    The renewed interest from the scientific community in machine learning (ML) is opening many new areas of research. Here we focus on how novel trends in ML are providing opportunities to improve the field of computational fluid dynamics (CFD). In particular, we discuss synergies between ML and CFD that have already shown benefits, and we also assess areas that are under development and may produce important benefits in the coming years. We believe that it is also important to emphasize a balanced perspective of cautious optimism for these emerging approaches
    
[^105]: 移动机器人的2D推动操作中的集体智能

    Collective Intelligence for 2D Push Manipulation with Mobile Robots. (arXiv:2211.15136v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.15136](http://arxiv.org/abs/2211.15136)

    本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。

    

    自然系统通常表现出能够自我组织和适应变化的集体智能，但大多数人工系统缺乏这种等效性。本文探讨使用移动机器人进行2D协作推动操作的集体智能系统的可能性。我们展示了将从软体物理模拟派生的规划器提炼为基于注意力的神经网络后，我们的多机器人推动操作系统相对于基线系统具有更好的性能，并可适应外部扰动和环境变化完成任务。

    While natural systems often present collective intelligence that allows them to self-organize and adapt to changes, the equivalent is missing in most artificial systems. We explore the possibility of such a system in the context of cooperative 2D push manipulations using mobile robots. Although conventional works demonstrate potential solutions for the problem in restricted settings, they have computational and learning difficulties. More importantly, these systems do not possess the ability to adapt when facing environmental changes. In this work, we show that by distilling a planner derived from a differentiable soft-body physics simulator into an attention-based neural network, our multi-robot push manipulation system achieves better performance than baselines. In addition, our system also generalizes to configurations not seen during training and is able to adapt toward task completions when external turbulence and environmental changes are applied. Supplementary videos can be foun
    
[^106]: MPCViT：使用异构注意力搜索精准高效的MPC友好视觉Transformer

    MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision Transformer with Heterogeneous Attention. (arXiv:2211.13955v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2211.13955](http://arxiv.org/abs/2211.13955)

    本文提出了一种MPC友好的视觉Transformer模型MPCViT，该模型通过异构注意力搜索来实现准确且高效的ViT推理，并通过简单而有效的神经架构搜索算法来进一步提高推理效率。

    

    安全多方计算(MPC)可以直接在加密数据上进行计算，并在深度学习推理中保护数据与模型的隐私。然而，现有的神经网络架构，包括Vision Transformers(ViTs)，并未专为MPC设计或优化，因此产生了显著的延迟开销。本文观察到Softmax是主要的延迟瓶颈，由于高通信复杂性，可有选择地替换或线性化而不影响模型准确性。因此，我们提出了MPC友好的ViT，称为MPCViT，在MPC中实现准确而高效的ViT推理。基于对Softmax注意力和其他注意力变体的系统延迟和精度评估，我们提出了一个异构注意力优化空间。我们还开发了一种简单而有效的MPC感知神经架构搜索算法，用于快速帕累托优化。为了进一步提高推理效率，我们提出了MPCViT+，以联合优化Softmax替换和模型压缩。

    Secure multi-party computation (MPC) enables computation directly on encrypted data and protects both data and model privacy in deep learning inference. However, existing neural network architectures, including Vision Transformers (ViTs), are not designed or optimized for MPC and incur significant latency overhead. We observe Softmax accounts for the major latency bottleneck due to a high communication complexity, but can be selectively replaced or linearized without compromising the model accuracy. Hence, in this paper, we propose an MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT inference in MPC. Based on a systematic latency and accuracy evaluation of the Softmax attention and other attention variants, we propose a heterogeneous attention optimization space. We also develop a simple yet effective MPC-aware neural architecture search algorithm for fast Pareto optimization. To further boost the inference efficiency, we propose MPCViT+, to jointly optimize the So
    
[^107]: 基于贝叶斯四元数的锂离子电池模型的贝叶斯模型选择

    Bayesian Model Selection of Lithium-Ion Battery Models via Bayesian Quadrature. (arXiv:2210.17299v4 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2210.17299](http://arxiv.org/abs/2210.17299)

    本文介绍了一种使用贝叶斯四元数的贝叶斯模型选择方法来分析锂离子电池模型，以选择最简单的模型来描述数据集。使用样本有效的积分技术减少了电池模型评估的数量，并推断出模型参数的后验分布。

    

    存在大量电池模型，不总是明显哪个模型最好地描述了数据集。本文提出了一种使用贝叶斯四元数的贝叶斯模型选择方法。采用模型证据作为选择标准，选择最简单的描述数据的模型，符合奥卡姆剃刀精神。但是，估计这个需要参数空间上的积分计算，这通常是无法承受的。贝叶斯四元数通过基于模型的推理提供了样本有效的积分，从而最大程度地减少了电池模型评估的数量。还可以作为副产品推断出模型参数的后验分布，无需进一步计算。本文使用最简单的锂离子电池模型，等效电路模型，分析了给定不同数据集和模型配置的选择标准的灵敏度。结果表明，流行的模型选择标准，例如均方根误差和贝叶斯信息

    A wide variety of battery models are available, and it is not always obvious which model `best' describes a dataset. This paper presents a Bayesian model selection approach using Bayesian quadrature. The model evidence is adopted as the selection metric, choosing the simplest model that describes the data, in the spirit of Occam's razor. However, estimating this requires integral computations over parameter space, which is usually prohibitively expensive. Bayesian quadrature offers sample-efficient integration via model-based inference that minimises the number of battery model evaluations. The posterior distribution of model parameters can also be inferred as a byproduct without further computation. Here, the simplest lithium-ion battery models, equivalent circuit models, were used to analyse the sensitivity of the selection criterion to given different datasets and model configurations. We show that popular model selection criteria, such as root-mean-square error and Bayesian informa
    
[^108]: FrozenQubits: 通过跳过热点节点提升QAOA的保真度

    FrozenQubits: Boosting Fidelity of QAOA by Skipping Hotspot Nodes. (arXiv:2210.17037v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2210.17037](http://arxiv.org/abs/2210.17037)

    提出FrozenQubits算法，通过冻结热点节点将状态空间分解为较小的子空间并独立地解决问题，提高了QAOA电路的保真度。

    

    量子近似优化算法（QAOA）是展示近期量子计算机具备量子优势的主要方法之一。然而，高设备误差率限制了我们对于超过几个量子比特的问题可靠地运行QAOA电路。在QAOA中，问题图被转换为一个量子电路，其中每条边对应于电路每层中的两个2量子比特CNOT操作。由于CNOT极易出错，因此QAOA电路的保真度由问题图中边的数量决定。我们观察到，大多数对应于实际应用的图遵循“幂律”分布，其中一些热点节点具有显着更高的连接数。我们利用这一洞见并提出“FrozenQubits”，冻结热点节点或量子比特，将给定问题的状态空间智能地分成几个较小的子空间，然后独立地解决它们。

    Quantum Approximate Optimization Algorithm (QAOA) is one of the leading candidates for demonstrating the quantum advantage using near-term quantum computers. Unfortunately, high device error rates limit us from reliably running QAOA circuits for problems with more than a few qubits. In QAOA, the problem graph is translated into a quantum circuit such that every edge corresponds to two 2-qubit CNOT operations in each layer of the circuit. As CNOTs are extremely error-prone, the fidelity of QAOA circuits is dictated by the number of edges in the problem graph.  We observe that majority of graphs corresponding to real-world applications follow the ``power-law`` distribution, where some hotspot nodes have significantly higher number of connections. We leverage this insight and propose ``FrozenQubits`` that freezes the hotspot nodes or qubits and intelligently partitions the state-space of the given problem into several smaller sub-spaces which are then solved independently. The correspondi
    
[^109]: MMRNet：通过多模态冗余提高多模态物体检测与分割的可靠性，应用于抓取商品

    MMRNet: Improving Reliability for Multimodal Object Detection and Segmentation for Bin Picking via Multimodal Redundancy. (arXiv:2210.10842v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10842](http://arxiv.org/abs/2210.10842)

    本文提出了一个基于多模态冗余的可靠的抓取商品物体检测和分割系统MMRNet，能够在传感器失效等异常情况下具有更好的鲁棒性，并在YCB-Video数据集上取得了最先进的性能。

    

    近年来，工业4.0基础设施的兴起解决了全球供应链的劳动力短缺问题。在实际应用中，通过部署基于人工智能的机器人货物捡拾系统来减轻工人的压力和体力需求，提高仓库的速度和效率已经变得尤为重要。但是，在传感器失灵等异常情况下可能会导致昂贵的损坏风险，因此可靠性成为将人工智能研究转化为实际应用和产品的关键因素。本文提出了一种可靠的物体检测和分割系统MMRNet，通过使用来自不同模态的数据进行抓取商品的物体检测和分割，而这是第一个将多模态冗余的概念引入到提高可靠性的抓取商品系统中。我们的系统在具有挑战性的YCB-Video数据集上实现了目标检测和分割的最先进性能，并且相较于基线方法具有更好的传感器失效表现。

    Recently, there has been tremendous interest in industry 4.0 infrastructure to address labor shortages in global supply chains. Deploying artificial intelligence-enabled robotic bin picking systems in real world has become particularly important for reducing stress and physical demands of workers while increasing speed and efficiency of warehouses. To this end, artificial intelligence-enabled robotic bin picking systems may be used to automate order picking, but with the risk of causing expensive damage during an abnormal event such as sensor failure. As such, reliability becomes a critical factor for translating artificial intelligence research to real world applications and products. In this paper, we propose a reliable object detection and segmentation system with MultiModal Redundancy (MMRNet) for tackling object detection and segmentation for robotic bin picking using data from different modalities. This is the first system that introduces the concept of multimodal redundancy to a
    
[^110]: 离线强化学习的策略指导模仿方法

    A Policy-Guided Imitation Approach for Offline Reinforcement Learning. (arXiv:2210.08323v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.08323](http://arxiv.org/abs/2210.08323)

    该论文提出了一种策略指导模仿方法，它将传统的奖励最大化策略分解成引导策略和执行策略。在训练期间，引导策略和执行策略在仅使用数据集中的数据的情况下进行学习。在评估期间，引导策略通过指引执行策略以最大化奖励，起到“先知”的作用，允许合理的超出分布泛化。

    

    在离线强化学习中，通常可以将方法分为两种：基于强化学习和基于模仿学习。基于强化学习的方法原则上可以享受超出分布的泛化，但会出现错误的离策略评估。基于模仿学习的方法避免了离策略评估，但过于保守，难以超越数据集。本研究提出了一种替代方法，继承了模仿式方法的训练稳定性，同时仍允许逻辑上的超出分布泛化。我们将离线强化学习中传统的奖励最大化策略分解成引导策略和执行策略。在训练期间，引导策略和执行策略仅使用数据集中的数据，以监督和解耦的方式进行学习。在评估期间，引导策略通过告诉执行策略应该去哪里以最大化奖励，来指引执行策略的走向，作为“先知”。如此，我们的算法允许“状态组合性”，从而实现了合理的超出分布泛化。

    Offline reinforcement learning (RL) methods can generally be categorized into two types: RL-based and Imitation-based. RL-based methods could in principle enjoy out-of-distribution generalization but suffer from erroneous off-policy evaluation. Imitation-based methods avoid off-policy evaluation but are too conservative to surpass the dataset. In this study, we propose an alternative approach, inheriting the training stability of imitation-style methods while still allowing logical out-of-distribution generalization. We decompose the conventional reward-maximizing policy in offline RL into a guide-policy and an execute-policy. During training, the guide-poicy and execute-policy are learned using only data from the dataset, in a supervised and decoupled manner. During evaluation, the guide-policy guides the execute-policy by telling where it should go so that the reward can be maximized, serving as the \textit{Prophet}. By doing so, our algorithm allows \textit{state-compositionality} f
    
[^111]: 自适应知识蒸馏增强图神经网络

    Boosting Graph Neural Networks via Adaptive Knowledge Distillation. (arXiv:2210.05920v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05920](http://arxiv.org/abs/2210.05920)

    本文提出了一种自适应知识蒸馏框架（BGNN）来增强图神经网络。该框架可以有效地将多个模型的知识传输到具有相同容量的学生模型中，并充分利用学生模型的优势来学习知识。

    

    图神经网络已在各种图挖掘任务上表现出了卓越的性能。尽管不同的图神经网络可以统一为相同的消息传递框架，但它们从同一图中学习互补的知识。为了提取多个模型的不同知识并将其结合，我们需要一种知识蒸馏方法。然而，为了避免过平滑，图神经网络通常是浅层的，这与知识蒸馏的设置相违背。在这种情况下，我们重新审视知识蒸馏，分离其从模型压缩中获益的好处，强调其将知识传递的能力。为此，我们需要解决两个挑战：如何将知识从紧凑的教师模型传输到具有相同容量的学生模型；以及如何利用学生模型的优势来学习知识。本文提出了一种新颖的自适应知识蒸馏框架，称为 BGNN，它将多个 GNN 顺序地传递知识到一个学生 GNN 中。

    Graph neural networks (GNNs) have shown remarkable performance on diverse graph mining tasks. Although different GNNs can be unified as the same message passing framework, they learn complementary knowledge from the same graph. Knowledge distillation (KD) is developed to combine the diverse knowledge from multiple models. It transfers knowledge from high-capacity teachers to a lightweight student. However, to avoid oversmoothing, GNNs are often shallow, which deviates from the setting of KD. In this context, we revisit KD by separating its benefits from model compression and emphasizing its power of transferring knowledge. To this end, we need to tackle two challenges: how to transfer knowledge from compact teachers to a student with the same capacity; and, how to exploit student GNN's own strength to learn knowledge. In this paper, we propose a novel adaptive KD framework, called BGNN, which sequentially transfers knowledge from multiple GNNs into a student GNN. We also introduce an a
    
[^112]: 基于学习的 Luenberger 观测器设计用于自主非线性系统

    Learning-based Design of Luenberger Observers for Autonomous Nonlinear Systems. (arXiv:2210.01476v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2210.01476](http://arxiv.org/abs/2210.01476)

    该论文提出了一种新方法，使用神经网络来设计非线性系统的观测器，具有优秀的泛化能力和鲁棒性。

    

    设计非线性系统的 Luenberger 观测器涉及将状态转换到一种可渐近稳定且在输出注入方面是线性的备选坐标系，可能是更高维度的。然后，观测器通过反转转换映射在原始坐标系中估计系统的状态。然而，对于一般的非线性系统，找到一个适合的可逆变换仍然是一个主要挑战。我们提出了一种新方法，使用受监督的物理学知识神经网络来近似转换及其反演。该方法展现了比现有方法更优秀的泛化能力，并且对于神经网络的近似误差与系统不确定性具有鲁棒性。

    Designing Luenberger observers for nonlinear systems involves the challenging task of transforming the state to an alternate coordinate system, possibly of higher dimensions, where the system is asymptotically stable and linear up to output injection. The observer then estimates the system's state in the original coordinates by inverting the transformation map. However, finding a suitable injective transformation whose inverse can be derived remains a primary challenge for general nonlinear systems. We propose a novel approach that uses supervised physics-informed neural networks to approximate both the transformation and its inverse. Our method exhibits superior generalization capabilities to contemporary methods and demonstrates robustness to both neural network's approximation errors and system uncertainties.
    
[^113]: 无目标后门水印：朝着无害和隐蔽的数据集版权保护迈进

    Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection. (arXiv:2210.00875v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.00875](http://arxiv.org/abs/2210.00875)

    本文提出了一种针对数据集版权保护的无害和隐蔽的无目标后门水印方案，可以达到与最先进方案相当或更好的水印效果，并证明对模型性能无害且隐蔽。

    

    深度神经网络已在实践中展现出了其优越性。可以说，深度神经网络的快速发展在很大程度上得益于高质量（开源）数据集，研究人员和开发人员可以在此基础上轻松地评估和改进他们的学习方法。由于数据收集通常是耗时甚至昂贵的，如何保护其版权具有重要意义并值得进一步探索。本文重新审视了数据集的所有权验证。我们发现，现有的验证方法由于有目标的后门水印的特性，会在受保护的数据集上训练的深度神经网络中引入新的安全风险。为了解决这个问题，在本文中，我们探讨了无目标后门水印方案，其中异常的模型行为不是确定性的。具体而言，我们介绍了两个分散度，并证明了它们的相关性，基于此我们在受污染标签和干净标签攻击设置下设计了无目标后门水印。实验结果表明，我们提出的方法在水印提取的准确性和模型性能上都能够达到甚至超过现有最先进的方案。此外，我们提出的方法还被证明对模型性能无害且隐蔽，不会引入任何可检测的扭曲或故障。

    Deep neural networks (DNNs) have demonstrated their superiority in practice. Arguably, the rapid development of DNNs is largely benefited from high-quality (open-sourced) datasets, based on which researchers and developers can easily evaluate and improve their learning methods. Since the data collection is usually time-consuming or even expensive, how to protect their copyrights is of great significance and worth further exploration. In this paper, we revisit dataset ownership verification. We find that existing verification methods introduced new security risks in DNNs trained on the protected dataset, due to the targeted nature of poison-only backdoor watermarks. To alleviate this problem, in this work, we explore the untargeted backdoor watermarking scheme, where the abnormal model behaviors are not deterministic. Specifically, we introduce two dispersibilities and prove their correlation, based on which we design the untargeted backdoor watermark under both poisoned-label and clean
    
[^114]: 机器人控制的鲁棒预测：一种博弈理论方法

    Robust Forecasting for Robotic Control: A Game-Theoretic Approach. (arXiv:2209.10802v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.10802](http://arxiv.org/abs/2209.10802)

    该论文提出了一种机器人控制鲁棒预测的新框架，该框架通过引入敌手概念，建立起机器人预测者与敌手之间的零和二人博弈模型，解决了仅依靠历史时间序列进行预测的问题。

    

    现代机器人需要准确的预测来在真实环境中做出最佳决策。我们提出了一个新颖的框架来为机器人控制生成鲁棒的预测。为了模拟影响未来预测的真实世界因素，我们引入了敌手的概念，通过扰乱观察到的历史时间序列来增加机器人最终的控制成本。具体而言，我们将这种交互建模为机器人预测者和理想中的敌手之间的零和二人博弈。我们展示了我们提出的博弈可以通过梯度优化求解到一个局部纳什均衡点。

    Modern robots require accurate forecasts to make optimal decisions in the real world. For example, self-driving cars need an accurate forecast of other agents' future actions to plan safe trajectories. Current methods rely heavily on historical time series to accurately predict the future. However, relying entirely on the observed history is problematic since it could be corrupted by noise, have outliers, or not completely represent all possible outcomes. To solve this problem, we propose a novel framework for generating robust forecasts for robotic control. In order to model real-world factors affecting future forecasts, we introduce the notion of an adversary, which perturbs observed historical time series to increase a robot's ultimate control cost. Specifically, we model this interaction as a zero-sum two-player game between a robot's forecaster and this hypothetical adversary. We show that our proposed game may be solved to a local Nash equilibrium using gradient-based optimizatio
    
[^115]: 基于最大相关最小差异标准的数据离散化及其在朴素贝叶斯上的应用

    A Max-relevance-min-divergence Criterion for Data Discretization with Applications on Naive Bayes. (arXiv:2209.10095v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10095](http://arxiv.org/abs/2209.10095)

    该论文提出了一种Max-Dependency-Min-Divergence (MDmD)准则，旨在同时最大化离散化数据的判别信息和泛化能力。此准则可应用于离散化数据的分类模型中，如朴素贝叶斯。

    

    在许多分类模型中，为更好地估计其分布，数据会被离散化。现有的离散化方法往往针对最大化离散化后数据的判别能力，而忽视了数据离散化在分类中的主要目标是提高泛化性能。因此，为同时最大化离散化后数据的判别信息和泛化能力，我们提出了Max-Dependency-Min-Divergence（MDmD）准则。具体而言，最大相关性准则最大化了离散化数据与分类变量之间的统计依赖性，而最小分歧准则在给定离散化方案时显式地最小化了训练数据与验证数据之间的JS距离。提出的MDmD准则在技术上非常有吸引力。

    In many classification models, data is discretized to better estimate its distribution. Existing discretization methods often target at maximizing the discriminant power of discretized data, while overlooking the fact that the primary target of data discretization in classification is to improve the generalization performance. As a result, the data tend to be over-split into many small bins since the data without discretization retain the maximal discriminant information. Thus, we propose a Max-Dependency-Min-Divergence (MDmD) criterion that maximizes both the discriminant information and generalization ability of the discretized data. More specifically, the Max-Dependency criterion maximizes the statistical dependency between the discretized data and the classification variable while the Min-Divergence criterion explicitly minimizes the JS-divergence between the training data and the validation data for a given discretization scheme. The proposed MDmD criterion is technically appealin
    
[^116]: 一种简单的神经网络量化方法

    A simple approach for quantizing neural networks. (arXiv:2209.03487v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.03487](http://arxiv.org/abs/2209.03487)

    本论文提出了一种简单的确定性预处理步骤来量化神经网络层的权重，并在不需要超参数调整的情况下保持网络性能，且相对误差随网络参数数量的增加而降低。

    

    在这篇短文中，我们提出了一种新的方法来量化完全训练过的神经网络的权重。简单的确定性预处理步骤使我们能够通过无记忆标量量化来量化网络层，同时保持在给定训练数据上的网络性能。我们的方法不需要任何超参数调整，并且与以前的方法相比，可以进行简单的分析。

    In this short note, we propose a new method for quantizing the weights of a fully trained neural network. A simple deterministic pre-processing step allows us to quantize network layers via memoryless scalar quantization while preserving the network performance on given training data. On one hand, the computational complexity of this pre-processing slightly exceeds that of state-of-the-art algorithms in the literature. On the other hand, our approach does not require any hyper-parameter tuning and, in contrast to previous methods, allows a plain analysis. We provide rigorous theoretical guarantees in the case of quantizing single network layers and show that the relative error decays with the number of parameters in the network if the training data behaves well, e.g., if it is sampled from suitable random distributions. The developed method also readily allows the quantization of deep networks by consecutive application to single layers.
    
[^117]: 基于确定性PAC-Bayes的梯度下降下的泛化

    Generalisation under gradient descent via deterministic PAC-Bayes. (arXiv:2209.02525v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.02525](http://arxiv.org/abs/2209.02525)

    本文介绍了一种新的PAC-Bayesian泛化界限，适用于使用梯度下降方法或连续梯度流训练模型的优化算法，且无需随机化。

    

    我们为使用梯度下降方法或连续梯度流训练模型建立了细分的PAC-Bayesian泛化界限。与PAC-Bayes设定中的标准做法相反，我们的结果适用于确定性的优化算法，而不需要任何去随机化的步骤。我们的界限是完全可计算的，取决于初始分布的密度和轨迹上训练目标的海森矩阵。我们展示了我们的框架可以应用于各种迭代优化算法，包括随机梯度下降（SGD）、动量算法和阻尼哈密顿动力学。

    We establish disintegrated PAC-Bayesian generalisation bounds for models trained with gradient descent methods or continuous gradient flows. Contrary to standard practice in the PAC-Bayesian setting, our result applies to optimisation algorithms that are deterministic, without requiring any de-randomisation step. Our bounds are fully computable, depending on the density of the initial distribution and the Hessian of the training objective over the trajectory. We show that our framework can be applied to a variety of iterative optimisation algorithms, including stochastic gradient descent (SGD), momentum-based schemes, and damped Hamiltonian dynamics.
    
[^118]: 通过本地几何角度理解VAEs的对抗鲁棒性

    Adversarial robustness of VAEs through the lens of local geometry. (arXiv:2208.03923v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03923](http://arxiv.org/abs/2208.03923)

    本文证明了对手攻击VAEs的最佳方法是利用由编码器和解码器网络引起的随机回溯度规张量的方向偏差。

    

    在对变分自编码器（VAEs）进行无监督攻击时，对手会找到一个输入样本中的小扰动，从而显着改变其潜在空间编码，从而损害了一个固定编码器的重构。这种脆弱性已知的原因是潜在后验分布的近似与先验分布之间的不匹配导致的潜在空间扭曲。因此，输入样本中的微小变化可能会将其编码移动到潜在空间中的低/零密度区域，从而产生无限制的生成。本文证明了对手攻击VAEs的最佳方法是利用由编码器和解码器网络引起的随机回溯度规张量的方向偏差。编码器的回溯度规张量测量它从输入到潜在空间的微小潜在体积的变化。因此，它可以被视为分析输入扰动导致潜在空间扭曲效果的镜头。

    In an unsupervised attack on variational autoencoders (VAEs), an adversary finds a small perturbation in an input sample that significantly changes its latent space encoding, thereby compromising the reconstruction for a fixed decoder. A known reason for such vulnerability is the distortions in the latent space resulting from a mismatch between approximated latent posterior and a prior distribution. Consequently, a slight change in an input sample can move its encoding to a low/zero density region in the latent space resulting in an unconstrained generation. This paper demonstrates that an optimal way for an adversary to attack VAEs is to exploit a directional bias of a stochastic pullback metric tensor induced by the encoder and decoder networks. The pullback metric tensor of an encoder measures the change in infinitesimal latent volume from an input to a latent space. Thus, it can be viewed as a lens to analyse the effect of input perturbations leading to latent space distortions. We
    
[^119]: CFLIT：共存的联邦学习与信息传输

    CFLIT: Coexisting Federated Learning and Information Transfer. (arXiv:2207.12884v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2207.12884](http://arxiv.org/abs/2207.12884)

    本文提出了一种共存的联邦学习和信息传输通信框架，其中利用多址信道的叠加特性，通过优化长期无线资源分配来最大化信息传输数据速率，并保证给定的联邦学习收敛性能。

    

    未来的无线网络将支持人工智能服务和普遍数据传输等多样化的移动服务。联邦学习是一种革命性的学习方法，可以实现分布式移动边缘设备之间的协作式人工智能模型训练。利用多址信道的叠加特性，空中计算允许大量设备在同一无线资源上并发上传模型，从而显著降低联邦学习的通信成本。本文研究了空中联邦学习和传统信息传输在移动边缘网络中的共存。我们提出了一个共存的联邦学习和信息传输通信框架（CFLIT），其中联邦学习和信息传输设备共享OFDM系统中的无线频谱。在这个框架下，我们旨在通过优化长期无线资源分配来最大化信息传输数据速率，并保证给定的联邦学习收敛性能。

    Future wireless networks are expected to support diverse mobile services, including artificial intelligence (AI) services and ubiquitous data transmissions. Federated learning (FL), as a revolutionary learning approach, enables collaborative AI model training across distributed mobile edge devices. By exploiting the superposition property of multiple-access channels, over-the-air computation allows concurrent model uploading from massive devices over the same radio resources, and thus significantly reduces the communication cost of FL. In this paper, we study the coexistence of over-the-air FL and traditional information transfer (IT) in a mobile edge network. We propose a coexisting federated learning and information transfer (CFLIT) communication framework, where the FL and IT devices share the wireless spectrum in an OFDM system. Under this framework, we aim to maximize the IT data rate and guarantee a given FL convergence performance by optimizing the long-term radio resource alloc
    
[^120]: 对抗性代理风险在二元分类中的存在性和极小化定理

    Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary Classification. (arXiv:2206.09098v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.09098](http://arxiv.org/abs/2206.09098)

    本文证明了对抗性代理风险的存在性、正则性和极小化定理，这一结果为对抗鲁棒性的理论提供了支持，并且可以指导算法的发展。

    

    对抗性训练是训练鲁棒性强的方法之一，然而，它从理论角度并不为人们所熟知。本文证明了对抗性代理风险的存在性、正则性和极小化定理。我们的结果解释了之前研究中有关对抗鲁棒性的一些经验观察，并提出了算法发展的新方向。此外，我们的结果将之前已知的对抗分类风险的存在和极小化定理扩展到了代理风险。

    Adversarial training is one of the most popular methods for training methods robust to adversarial attacks, however, it is not well-understood from a theoretical perspective. We prove and existence, regularity, and minimax theorems for adversarial surrogate risks. Our results explain some empirical observations on adversarial robustness from prior work and suggest new directions in algorithm development. Furthermore, our results extend previously known existence and minimax theorems for the adversarial classification risk to surrogate risks.
    
[^121]: 重新思考Sinkhorn算法的初始化

    Rethinking Initialization of the Sinkhorn Algorithm. (arXiv:2206.07630v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.07630](http://arxiv.org/abs/2206.07630)

    本文认为Sinkhorn算法的初始化备受忽视，但数据相关的初始化可以提高算法性能，并适用于端到端学习。

    

    尽管最优输运问题最初被制定为线性规划，但添加熵正则化已被证明在许多应用中具有优越的计算和统计效果。Sinkhorn算法是解决这个正则化问题的最常用方法，并且已经有多次尝试通过使用如正则化参数退火、动量或加速度来减少其运行时间。本文的前提是Sinkhorn算法的初始化相对较少受到关注，可能是由于两种先入为主的观念:由于正则化的OT问题是凸问题，因此可能不值得设计良好的初始化，因为任何初始化都是可行的；其次，因为Sinkhorn算法的输出通常在端到端管道中展开，所以数据相关的初始化会对雅各比计算造成偏差。我们挑战这种传统智慧，并展示了数据相关的初始化可以提高Sinkhorn算法的性能，并适用于端到端学习。

    While the optimal transport (OT) problem was originally formulated as a linear program, the addition of entropic regularization has proven beneficial both computationally and statistically, for many applications. The Sinkhorn fixed-point algorithm is the most popular approach to solve this regularized problem, and, as a result, multiple attempts have been made to reduce its runtime using, e.g., annealing in the regularization parameter, momentum or acceleration. The premise of this work is that initialization of the Sinkhorn algorithm has received comparatively little attention, possibly due to two preconceptions: since the regularized OT problem is convex, it may not be worth crafting a good initialization, since any is guaranteed to work; secondly, because the outputs of the Sinkhorn algorithm are often unrolled in end-to-end pipelines, a data-dependent initialization would bias Jacobian computations. We challenge this conventional wisdom, and show that data-dependent initializers re
    
[^122]: 电影叙述摘要：一个用于故事理解的视频语言数据集

    Synopses of Movie Narratives: a Video-Language Dataset for Story Understanding. (arXiv:2203.05711v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.05711](http://arxiv.org/abs/2203.05711)

    这个研究收集并发布了一个视频-语言故事数据集SYMON，用于推进多模态故事理解的发展。

    

    尽管AI有了最近的进展，但故事理解仍然是一个未被充分研究的问题。我们收集、预处理并公开发布了一个视频语言故事数据集SYMON，其中包含5,193个流行电影和电视剧的视频摘要。SYMON捕捉了由人类创作者制作的面向人类观众的自然故事叙述视频。作为一个原型和自然故事数据集，SYMON具有高覆盖的多模态故事事件、丰富的心理状态描述和视觉和文本模态之间的大语义差距。我们建立了视频文本检索和电影摘要视频的零样本对齐的基准，展示了在故事理解中领域内数据的重要性。通过SYMON，我们希望为多模态故事理解的进展打下基础。

    Despite recent advances of AI, story understanding remains an open and under-investigated problem. We collect, preprocess, and publicly release a video-language story dataset, Synopses of Movie Narratives (SYMON), containing 5,193 video summaries of popular movies and TV series. SYMON captures naturalistic story-telling videos for human audience made by human creators. As a prototypical and naturalistic story dataset, SYMON features high coverage of multimodal story events, abundant mental-state descriptions, and large semantic gaps between the visual and the textual modalities. We establish benchmarks on video-text retrieval and zero-shot alignment on movie summary videos, which showcase the importance of in-domain data in story understanding. With SYMON, we hope to lay the groundwork for progress in multimodal story understanding.
    
[^123]: GraphTune：一种具有可调结构特征的基于学习的图生成模型

    GraphTune: A Learning-based Graph Generative Model with Tunable Structural Features. (arXiv:2201.11494v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11494](http://arxiv.org/abs/2201.11494)

    GraphTune是一种基于学习的图生成模型，允许我们调整生成图的全局结构特征的值作为条件，比传统模型更有效。

    

    自从几十年前开始研究生成图的方法以来，这一领域已经得到了广泛的应用。最近，越来越多的研究者开始关注能够重现实际图的生成模型。虽然已经提出了几种利用现代机器学习技术的生成模型，但是在条件生成通用图形方面还有很多探索空间。本文提出了一种生成模型GraphTune，它允许我们将全局结构特征的值作为条件进行调整。GraphTune利用长短时记忆（LSTM）和条件变分自编码器（CVAE）使得可以调整生成图中的任何结构特征的值。使用真实图形数据集对GraphTune和传统模型进行比较评估，结果表明GraphTune可以更清晰地调整生成图的全局结构特征的值，效果优于传统模型。

    Generative models for graphs have been actively studied for decades, and they have a wide range of applications. Recently, learning-based graph generation that reproduces real-world graphs has been attracting the attention of many researchers. Although several generative models that utilize modern machine learning technologies have been proposed, conditional generation of general graphs has been less explored in the field. In this paper, we propose a generative model that allows us to tune the value of a global-level structural feature as a condition. Our model, called GraphTune, makes it possible to tune the value of any structural feature of generated graphs using Long Short Term Memory (LSTM) and a Conditional Variational AutoEncoder (CVAE). We performed comparative evaluations of GraphTune and conventional models on a real graph dataset. The evaluations show that GraphTune makes it possible to more clearly tune the value of a global-level structural feature better than conventional
    
[^124]: CFU Playground: 面向FPGA的TinyML加速的全栈开源框架

    CFU Playground: Full-Stack Open-Source Framework for Tiny Machine Learning (tinyML) Acceleration on FPGAs. (arXiv:2201.01863v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.01863](http://arxiv.org/abs/2201.01863)

    CFU Playground是一个全栈开源框架，为嵌入式机器学习系统提供快速迭代设计和评估机器学习加速器的工具。通过CFU Playground，可以定制和协同优化实验性和定制体系结构，实现相对较小的定制投资即可让机器学习硬件和软件开发者获得显著回报。

    

    需要高效处理神经网络的需求催生了硬件加速器的发展。专用硬件的广泛应用凸显出需要更灵活的硬件-软件协同设计和领域特定优化工具流程。本文介绍了CFU Playground：一种全栈开源框架，它可以快速迭代设计和评估嵌入式机器学习系统的机器学习加速器。我们的工具提供了一个完全开源的FPGA和未来系统硬件-软件协同设计流程。这个全栈框架使用户可以访问定制和协同优化的实验性和定制体系结构，特别针对嵌入式机器学习。使用CFU Playground的设计和评估回路，我们展示了显著的回报，而相对较小的定制投资即可让机器学习硬件和软件开发者受益。

    Need for the efficient processing of neural networks has given rise to the development of hardware accelerators. The increased adoption of specialized hardware has highlighted the need for more agile design flows for hardware-software co-design and domain-specific optimizations. In this paper, we present CFU Playground: a full-stack open-source framework that enables rapid and iterative design and evaluation of machine learning (ML) accelerators for embedded ML systems. Our tool provides a completely open-source end-to-end flow for hardware-software co-design on FPGAs and future systems research. This full-stack framework gives the users access to explore experimental and bespoke architectures that are customized and co-optimized for embedded ML. Our rapid, deploy-profile-optimization feedback loop lets ML hardware and software developers achieve significant returns out of a relatively small investment in customization. Using CFU Playground's design and evaluation loop, we show substan
    
[^125]: 不同度量下1-中心问题的复杂性研究

    On Complexity of 1-Center in Various Metrics. (arXiv:2112.03222v2 [cs.CC] UPDATED)

    [http://arxiv.org/abs/2112.03222](http://arxiv.org/abs/2112.03222)

    在本文中，研究了不同度量下1-中心问题的复杂性。小d时，在假设命中集合猜想（HSC）成立的情况下，无法通过任何lp度量或编辑或Ulam度量实现1-中心问题的次二次算法。大d时，在假设Quantified SETH的情况下，排除了基于编辑度量中的1-中心问题的次四次算法，同时给出了Ulam度量中1-中心问题的（1+ε）逼近算法。

    

    本文研究了经典的1-中心问题：给定度量空间中的一组n个点P，找到距离其他P中点距离最大的点。我们研究了在d维lp度量中以及基于字符串长度为d的编辑和Ulam度量中该问题的复杂性。对于1-中心问题，我们的研究结果可以按d进行分类。小d时，在假设命中集合猜想（HSC）成立的情况下，我们证明了当d=ω（logn）时，无法通过任何lp度量或编辑或Ulam度量实现1-中心问题的次二次算法。大d时，我们将有条件的下界推广到基于编辑度量中的1-中心问题，排除了次四次算法（假设Quantified SETH）。另一方面，我们给出了Ulam度量中1-中心问题的（1+ε）逼近算法，其运行时间为$\tilde{O_{\varepsilon}}(nd+n^2\sqrt{d})$。我们还通过允许近似来加强了一些之前的下界。

    We consider the classic 1-center problem: Given a set $P$ of $n$ points in a metric space find the point in $P$ that minimizes the maximum distance to the other points of $P$. We study the complexity of this problem in $d$-dimensional $\ell_p$-metrics and in edit and Ulam metrics over strings of length $d$. Our results for the 1-center problem may be classified based on $d$ as follows.  $\bullet$ Small $d$: Assuming the hitting set conjecture (HSC), we show that when $d=\omega(\log n)$, no subquadratic algorithm can solve 1-center problem in any of the $\ell_p$-metrics, or in edit or Ulam metrics.  $\bullet$ Large $d$: When $d=\Omega(n)$, we extend our conditional lower bound to rule out subquartic algorithms for 1-center problem in edit metric (assuming Quantified SETH). On the other hand, we give a $(1+\epsilon)$-approximation for 1-center in Ulam metric with running time $\tilde{O_{\varepsilon}}(nd+n^2\sqrt{d})$.  We also strengthen some of the above lower bounds by allowing approxi
    
[^126]: 基于牛顿方法和并行处理的卷积神经网络

    Newton methods based convolution neural networks using parallel processing. (arXiv:2112.01401v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.01401](http://arxiv.org/abs/2112.01401)

    本研究提出基于牛顿方法和并行处理的卷积神经网络训练方法，使用完整的数据集来处理Hessian矩阵，并比之前的方法更高效。

    

    卷积神经网络的训练是一个高维的非凸优化问题。目前，在无法自信地设置参数学习率的情况下，效率很低。过去的一些研究引入了牛顿方法来训练深度神经网络。对于卷积神经网络，牛顿方法涉及复杂的操作。通过使用子采样的Hessian牛顿方法，卷积神经网络的牛顿方法处理了这个问题。本研究中，我们使用完整的数据而不是一次只处理部分数据的子采样方法。此外，我们使用并行处理而不是串行处理来进行小批量计算。本研究中使用并行处理得到的结果优于之前所用方法所需的时间。

    Training of convolutional neural networks is a high dimensional and a non-convex optimization problem. At present, it is inefficient in situations where parametric learning rates can not be confidently set. Some past works have introduced Newton methods for training deep neural networks. Newton methods for convolutional neural networks involve complicated operations. Finding the Hessian matrix in second-order methods becomes very complex as we mainly use the finite differences method with the image data. Newton methods for convolutional neural networks deals with this by using the sub-sampled Hessian Newton methods. In this paper, we have used the complete data instead of the sub-sampled methods that only handle partial data at a time. Further, we have used parallel processing instead of serial processing in mini-batch computations. The results obtained using parallel processing in this study, outperform the time taken by the previous approach.
    
[^127]: 一种半监督适应性判别离散化方法，提高正则化朴素贝叶斯的区分能力。

    A Semi-Supervised Adaptive Discriminative Discretization Method Improving Discrimination Power of Regularized Naive Bayes. (arXiv:2111.10983v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.10983](http://arxiv.org/abs/2111.10983)

    本文提出了一种半监督自适应判别离散化框架，通过伪标签技术利用标记数据和未标记数据，提高分离能力，避免信息损失，优化了正则化朴素贝叶斯分类器。

    

    最近，许多提高了区分能力的改进朴素贝叶斯方法已经被开发出来。其中，通过平衡区分能力和泛化能力，正则化朴素贝叶斯(RNB)产生出色的性能。在朴素贝叶斯中，数据离散化非常重要。通过将类似的值分组为一个区间，可以更好地估计数据分布。然而，现有方法，包括RNB，经常将数据离散化为太少的间隔，这可能导致显着的信息丢失。为了解决这个问题，我们提出了一种半监督的自适应判别离散化框架，用通过伪标签技术利用标记数据和未标记数据，可以更好地估计数据分布。该提出的方法还通过使用自适应判别离散化方案，显着降低了离散化过程中的信息损失，从而极大地提高了分类器正则化朴素贝叶斯的区分能力。

    Recently, many improved naive Bayes methods have been developed with enhanced discrimination capabilities. Among them, regularized naive Bayes (RNB) produces excellent performance by balancing the discrimination power and generalization capability. Data discretization is important in naive Bayes. By grouping similar values into one interval, the data distribution could be better estimated. However, existing methods including RNB often discretize the data into too few intervals, which may result in a significant information loss. To address this problem, we propose a semi-supervised adaptive discriminative discretization framework for naive Bayes, which could better estimate the data distribution by utilizing both labeled data and unlabeled data through pseudo-labeling techniques. The proposed method also significantly reduces the information loss during discretization by utilizing an adaptive discriminative discretization scheme, and hence greatly improves the discrimination power of c
    
[^128]: CyTran: 一种多级连贯性的循环一致 Transformer 方法，用于非对比度到对比度 CT 扫描的翻译

    CyTran: A Cycle-Consistent Transformer with Multi-Level Consistency for Non-Contrast to Contrast CT Translation. (arXiv:2110.06400v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2110.06400](http://arxiv.org/abs/2110.06400)

    CyTran 是一种基于循环一致的生成对抗卷积 Transformer 模型，通过多级循环一致性损失函数和一种新的对比损失函数实现了非对比度和对比度 CT 扫描的翻译，可为不能注射对比剂的患者自动生成对比 CT 扫描，同时增强对比和非对比 CT 扫描的对齐。 CyTran outperforms state-of-the-art models for both non-contrast to contrast and contrast to non-contrast CT translation tasks.

    

    我们提出了一种新颖的方法，将非对比 CT 扫描和对比 CT 扫描相互翻译。解决这一问题有两个重要应用：(i) 为那些不能注射对比剂的患者自动生成对比 CT 扫描，(ii) 通过减少对比剂引起的差异来增强对比和非对比 CT 扫描的对齐。我们的方法基于循环一致的生成对抗卷积 Transformer 模型，简称 CyTran。由于整合了多级循环一致性损失函数，我们的神经模型可以在未成对图像上进行训练。除了在图像级别应用标准的循环一致性损失函数外，我们提出在中间特征表达之间应用额外的循环一致性损失函数，强制模型在多个表示层面上保持循环一致性，从而获得更好的结果。为应对非对比度和对比度 CT 扫描之间的高分辨率细节和大变异，我们引入了一种新的对比损失函数，不仅可以提高翻译图像的质量，还可以增强翻译和目标图像之间的相似性。实验表明，CyTran 在非对比度到对比度和对比度到非对比度 CT 扫描的翻译任务上优于现有的最先进模型。

    We propose a novel approach to translate unpaired contrast computed tomography (CT) scans to non-contrast CT scans and the other way around. Solving this task has two important applications: (i) to automatically generate contrast CT scans for patients for whom injecting contrast substance is not an option, and (ii) to enhance the alignment between contrast and non-contrast CT by reducing the differences induced by the contrast substance before registration. Our approach is based on cycle-consistent generative adversarial convolutional transformers, for short, CyTran. Our neural model can be trained on unpaired images, due to the integration of a multi-level cycle-consistency loss. Aside from the standard cycle-consistency loss applied at the image level, we propose to apply additional cycle-consistency losses between intermediate feature representations, which enforces the model to be cycle-consistent at multiple representations levels, leading to superior results. To deal with high-re
    
[^129]: Federated Submodel Optimization for Hot and Cold Data Features（热点和冷门数据特征的联邦子模型优化）

    Federated Submodel Optimization for Hot and Cold Data Features. (arXiv:2109.07704v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.07704](http://arxiv.org/abs/2109.07704)

    本文提出了一种针对联邦学习稀疏数据特征的联邦子模型平均算法(FedSubAvg)，该算法可以有效避免数据稀疏问题导致的计算下降，并保证每个模型参数的全局更新期望等于涉及它的客户端的本地更新平均值。该算法的新度量元素梯度范数可以更好地表征在稀疏数据上的联邦优化收敛。

    

    本文研究联邦学习中的实际数据特征，其中客户端的非独立同分布数据具有稀疏特征，并且某个客户端的本地数据通常仅涉及完整模型的一小部分，称为子模型。由于数据稀疏性，传统的联邦平均（FedAvg）算法或其变体将严重减慢，因为在更新全局模型时，每个客户端除其子模型外的零更新被不准确地聚合。因此，我们提出了联邦子模型平均（FedSubAvg），确保每个模型参数的全局更新的期望等于涉及它的客户端的本地更新的平均值。我们通过推导一个称为元素梯度范数的新度量上界来理论上证明了FedSubAvg的收敛速度。特别地，这个新度量可以表征在稀疏数据上的联邦优化收敛，而传统的平方梯度度量则无法完成这一任务。

    We study practical data characteristics underlying federated learning, where non-i.i.d. data from clients have sparse features, and a certain client's local data normally involves only a small part of the full model, called a submodel. Due to data sparsity, the classical federated averaging (FedAvg) algorithm or its variants will be severely slowed down, because when updating the global model, each client's zero update of the full model excluding its submodel is inaccurately aggregated. Therefore, we propose federated submodel averaging (FedSubAvg), ensuring that the expectation of the global update of each model parameter is equal to the average of the local updates of the clients who involve it. We theoretically proved the convergence rate of FedSubAvg by deriving an upper bound under a new metric called the element-wise gradient norm. In particular, this new metric can characterize the convergence of federated optimization over sparse data, while the conventional metric of squared g
    
[^130]: 应用于基于得分模型的扩散Schrödinger桥

    Diffusion Schr\"odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.01357](http://arxiv.org/abs/2106.01357)

    本文提出了一种名为Diffusion SB (DSB) 的逼近迭代比例拟合程序，用于解决Schrödinger Bridge问题，该问题可以产生从数据分布中生成样本的扩散过程，而有限时间内完成。

    

    逐步应用高斯噪声可以将复杂的数据分布转化为近似高斯分布。反向定义了一种生成模型。当正向噪声过程由随机微分方程（SDE）给出时，Song等人（2021）展示了如何使用得分匹配估计相应时间不均匀漂移的反向时间SDE。这种方法的局限性是需要运行足够长时间的正向时间SDE，才能使最终分布近似为高斯分布。相比之下，解决Schrödinger桥问题(SB)，即在路径空间上的熵正则化最优输运问题，可以产生从数据分布中生成样本的扩散过程，而有限时间内完成。我们提出了扩散SB（DSB），一个解决SB问题的原始近似迭代比例拟合（IPF）程序，并提供理论分析和生成建模实验。

    Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\"odinger Bridge problem (SB), i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the 
    
[^131]: 利用机器学习技术改进半导体器件建模的电子设计自动化

    Improving Semiconductor Device Modeling for Electronic Design Automation by Machine Learning Techniques. (arXiv:2105.11453v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.11453](http://arxiv.org/abs/2105.11453)

    本文提出一种利用机器学习技术改进半导体器件建模的方法，通过自我增强策略和变分自编码器技术，只需少量实验数据点即可实现高精度预测，有效降低平均绝对误差，具有广泛应用价值。

    

    机器学习（ML）技术在技术计算机辅助设计（TCAD）方法中的应用对半导体行业有很大的益处。然而，ML模型的性能在很大程度上依赖于训练数据集的质量和数量。由于器件制造的复杂性和成本，这些数据集在半导体行业中很难获得。本文提出一种自我增强策略，利用变分自编码器（VAE）技术改进基于ML的器件建模。这些技术只需要少量实验数据点，并且不依赖于TCAD工具。为了证明我们的方法的有效性，我们将其应用于镓氮器件中欧姆电阻值的深度神经网络预测任务。在预测实验结果时，平均绝对误差降低了70%。我们的方法具有固有的灵活性，可以轻松适应各种任务，因此具有广泛应用价值。

    The semiconductors industry benefits greatly from the integration of Machine Learning (ML)-based techniques in Technology Computer-Aided Design (TCAD) methods. The performance of ML models however relies heavily on the quality and quantity of training datasets. They can be particularly difficult to obtain in the semiconductor industry due to the complexity and expense of the device fabrication. In this paper, we propose a self-augmentation strategy for improving ML-based device modeling using variational autoencoder-based techniques. These techniques require a small number of experimental data points and does not rely on TCAD tools. To demonstrate the effectiveness of our approach, we apply it to a deep neural network-based prediction task for the Ohmic resistance value in Gallium Nitride devices. A 70% reduction in mean absolute error when predicting experimental results is achieved. The inherent flexibility of our approach allows easy adaptation to various tasks, thus making it highl
    
[^132]: 近似的多智能体拟合Q迭代

    Approximated Multi-Agent Fitted Q Iteration. (arXiv:2104.09343v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.09343](http://arxiv.org/abs/2104.09343)

    本文提出了一种近似方法AMAFQI，可用于高效解决多智能体批量强化学习问题，相比于常用方法FQI，AMAFQI的计算量增长更为缓慢，以线性增长，且仿真实验显示两种方法的性能类似。

    

    本文提出了一种高效的多智能体批量强化学习的近似方法，即近似的多智能体拟合Q迭代（AMAFQI）。我们提出了一个迭代策略搜索，并展示其得到的策略具有多个集中学习到的Q函数的近似的贪婪特性。在每次迭代和策略评估中，AMAFQI需要的计算量随着智能体数量呈线性增长，而拟合Q迭代（FQI）需要的计算量则呈指数增长，FQI是在批量强化学习中常用的方法。AMAFQI的这个特性对于设计可行的多智能体方法至关重要。我们在数值仿真中评估了AMAFQI的性能，并将其与FQI进行了比较。仿真结果表明，在多智能体问题中使用AMAFQI而不是FQI可以显著减少计算时间，并证实了两种方法的类似性能。

    We formulate an efficient approximation for multi-agent batch reinforcement learning, the approximated multi-agent fitted Q iteration (AMAFQI). We present a detailed derivation of our approach. We propose an iterative policy search and show that it yields a greedy policy with respect to multiple approximations of the centralized, learned Q-function. In each iteration and policy evaluation, AMAFQI requires a number of computations that scales linearly with the number of agents whereas the analogous number of computations increase exponentially for the fitted Q iteration (FQI), a commonly used approaches in batch reinforcement learning. This property of AMAFQI is fundamental for the design of a tractable multi-agent approach. We evaluate the performance of AMAFQI and compare it to FQI in numerical simulations. The simulations illustrate the significant computation time reduction when using AMAFQI instead of FQI in multi-agent problems and corroborate the similar performance of both appro
    
[^133]: 用于货运预订控制问题的强化学习

    Reinforcement Learning for Freight Booking Control Problems. (arXiv:2102.00092v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2102.00092](http://arxiv.org/abs/2102.00092)

    该论文介绍了如何使用强化学习解决货运预订控制方面的顺序决策问题。作者指出，惯例上在部署强化学习算法时解决运营问题可能太耗费时间，该研究提供了一种解决方案。

    

    预订控制问题是收益管理领域中出现的顺序决策问题。更确切地说，货运预订控制侧重于决定是否接受或拒绝预订请求：在有限的容量下，接受预订请求或拒绝它以保留容量供未来可能具有更高收益的预订使用。这个问题可以被形式化为一个有限时间段的随机动态规划，其中接受一组请求导致在预订期结束时获得的利润，该利润取决于履行接受的预订的成本。对于许多货运应用，满足请求的成本是通过解决运营决策问题获得的，这通常需要解决混合整数线性规划的解决方案。在部署强化学习算法时，常规解决此类运营问题可能太耗费时间。大多数预订控制策略是通过解决特定于问题的数学规划问题获得的。

    Booking control problems are sequential decision-making problems that occur in the domain of revenue management. More precisely, freight booking control focuses on the problem of deciding to accept or reject bookings: given a limited capacity, accept a booking request or reject it to reserve capacity for future bookings with potentially higher revenue. This problem can be formulated as a finite-horizon stochastic dynamic program, where accepting a set of requests results in a profit at the end of the booking period that depends on the cost of fulfilling the accepted bookings. For many freight applications, the cost of fulfilling requests is obtained by solving an operational decision-making problem, which often requires the solutions to mixed-integer linear programs. Routinely solving such operational problems when deploying reinforcement learning algorithms may be too time consuming. The majority of booking control policies are obtained by solving problem-specific mathematical program
    
[^134]: 具有战略代理的治疗分配

    Treatment Allocation with Strategic Agents. (arXiv:2011.06528v5 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2011.06528](http://arxiv.org/abs/2011.06528)

    论文研究了带有战略代理的治疗分配问题。研究表明，最优规则可以涉及随机化，对那些平均上对治疗有积极反应的个体也可以分配不到100%的治疗机会。

    

    越来越多的人对基于观察到的个体特征的治疗分配产生兴趣，例如定向营销、个性化信用报价和异质性定价等。治疗个性化引入了个体修改其行为以获得更好治疗的激励。战略行为会改变共变量和潜在结果的联合分布。在没有战略行为的情况下，最佳规则将分配治疗对于有积极条件平均治疗效应的个体。而在存在战略行为时，我们发现最佳规则可以涉及随机化，即使是对那些平均上对治疗有积极反应的个体，也可以分配不到100%的治疗机会。我们提出了一个基于贝叶斯优化的顺序实验，它可以在没有个体战略行为参数假设下，收敛到最优治疗分配规则。

    There is increasing interest in allocating treatments based on observed individual characteristics: examples include targeted marketing, individualized credit offers, and heterogeneous pricing. Treatment personalization introduces incentives for individuals to modify their behavior to obtain a better treatment. Strategic behavior shifts the joint distribution of covariates and potential outcomes. The optimal rule without strategic behavior allocates treatments only to those with a positive Conditional Average Treatment Effect. With strategic behavior, we show that the optimal rule can involve randomization, allocating treatments with less than 100% probability even to those who respond positively on average to the treatment. We propose a sequential experiment based on Bayesian Optimization that converges to the optimal treatment rule without parametric assumptions on individual strategic behavior.
    
[^135]: 生成对抗网络（GANs）综述：挑战，解决方案和未来方向。

    Generative Adversarial Networks (GANs Survey): Challenges, Solutions, and Future Directions. (arXiv:2005.00065v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.00065](http://arxiv.org/abs/2005.00065)

    生成对抗网络（GANs）是一种学习复杂高维概率分布的新型深度生成模型，但其训练存在着诸多挑战，如模式崩溃、不收敛及不稳定性。最近，针对这些挑战，提出了多种GANs的设计和优化方案来解决这些问题。

    

    生成对抗网络（GANs）是一种新型的深度生成模型，最近引起了相当多的关注。GANs可以隐式地学习图像，音频和数据中的复杂高维分布。然而，由于网络结构的不当设计，目标函数的使用和优化算法的选择，GANs的训练存在着主要的挑战，如模式崩溃，不收敛和不稳定性。最近，为了解决这些挑战，基于重新设计的网络架构，新的目标函数和替代优化算法的技术，提出了几种更好的GANs设计和优化的解决方案。据我们所知，目前还没有一篇专门关注这些解决方案的广泛和系统的综述研究。在本研究中，我们对GANs设计和优化解决方案的发展进行了全面的调查。

    Generative Adversarial Networks (GANs) is a novel class of deep generative models which has recently gained significant attention. GANs learns complex and high-dimensional distributions implicitly over images, audio, and data. However, there exists major challenges in training of GANs, i.e., mode collapse, non-convergence and instability, due to inappropriate design of network architecture, use of objective function and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges.
    

