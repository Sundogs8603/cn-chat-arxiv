# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Credal Learning Theory](https://rss.arxiv.org/abs/2402.00957) | 本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。 |
| [^2] | [Zero-shot Safety Prediction for Autonomous Robots with Foundation World Models](https://arxiv.org/abs/2404.00462) | 基于基础世界模型，提出了一种能够直接预测因果未来状态的方法，在安全预测任务中表现优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。 |
| [^3] | [Rotate to Scan: UNet-like Mamba with Triplet SSM Module for Medical Image Segmentation](https://arxiv.org/abs/2403.17701) | 本文提出了Triplet Mamba-UNet，利用残余VSS块提取密集上下文特征，并利用Triplet SSM融合空间和通道维度上的特征。 |
| [^4] | [Learning Action-based Representations Using Invariance](https://arxiv.org/abs/2403.16369) | 提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量 |
| [^5] | [From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?](https://arxiv.org/abs/2403.11894) | 该研究对医疗保健NLP中的深度学习进行了全面审查，提出了可解释和可解释的人工智能（XIAI）概念，并发现注意机制是主要新兴IAI，同时面临着缺乏全局建模、最佳实践以及系统评估和基准测试的挑战。 |
| [^6] | [Fisher Mask Nodes for Language Model Merging](https://arxiv.org/abs/2403.09891) | 介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。 |
| [^7] | [Reconstructions of Jupiter's magnetic field using physics informed neural networks](https://arxiv.org/abs/2403.07507) | 本研究提出了一种利用物理信息神经网络重建木星内部磁场的新方法，相比其他方法，能够更清晰地解析局部结构并避免深度噪声干扰。 |
| [^8] | [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/abs/2403.02545) | Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。 |
| [^9] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^10] | [Zero-shot generalization across architectures for visual classification](https://arxiv.org/abs/2402.14095) | 不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。 |
| [^11] | [3D-based RNA function prediction tools in rnaglib](https://arxiv.org/abs/2402.09330) | rnaglib是一个基于3D的RNA功能预测工具，可以用于在RNA 3D结构数据集上训练监督和非监督机器学习模型。 |
| [^12] | [Dr. Jekyll and Mr. Hyde: Two Faces of LLMs](https://arxiv.org/abs/2312.03853) | 本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。 |
| [^13] | [Modular Neural Networks for Time Series Forecasting: Interpretability and Feature Selection using Attention](https://arxiv.org/abs/2311.16834) | 该论文提出了一种新颖的模块化神经网络模型，用于多变量时间序列预测，通过循环神经网络学习时间依赖关系，并使用基于注意力的特征选择组件实现解释性，实验结果表明其优于当前最先进的解释性神经加性模型（NAM）及其变体。 |
| [^14] | [InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification](https://arxiv.org/abs/2109.07319) | 提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。 |
| [^15] | [LangProp: A code optimization framework using Language Models applied to driving.](http://arxiv.org/abs/2401.10314) | LangProp是一种用于自动驾驶的代码优化框架，利用语言模型迭代优化生成的代码。它通过评估代码性能和捕捉异常来改进生成的代码，展示了在CARLA中实现自动驾驶的概念验证。 |
| [^16] | [The Impact of Differential Feature Under-reporting on Algorithmic Fairness.](http://arxiv.org/abs/2401.08788) | 本文研究了差异特征未报告对算法公平性的影响，并提出了一个可分析的模型进行刻画。 |
| [^17] | [Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning.](http://arxiv.org/abs/2311.09441) | 本文研究了分割联邦学习（SFL）中隐私和能耗之间的权衡，强调了快速收敛的优势，并分析了切割层对客户端能耗和隐私的影响。 |
| [^18] | [Privately Aligning Language Models with Reinforcement Learning.](http://arxiv.org/abs/2310.16960) | 本文研究了通过强化学习实现隐私保护的语言模型对齐问题，提出了一种新的差分隐私框架，并通过实验证明了其有效性和实用性。 |
| [^19] | [From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks.](http://arxiv.org/abs/2310.11884) | 本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。 |
| [^20] | [BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity.](http://arxiv.org/abs/2310.04420) | "BrainSCUBA通过生成自然语言描述来预测最大激活个体感兴趣体素的图像，达到了细粒度的视觉皮层选择性描述。" |
| [^21] | [Deep Reinforcement Learning for Infinite Horizon Mean Field Problems in Continuous Spaces.](http://arxiv.org/abs/2309.10953) | 这项研究提出了一种基于深度强化学习的算法，通过将演员-评论家范式与均场分布表示配对，来解决连续空间中的均场博弈和均场控制问题，并使用朗之万动力学从分布中获取样本。该算法在渐近无限时域框架下使用线性二次基准进行评估。 |
| [^22] | [Compositional Learning of Visually-Grounded Concepts Using Reinforcement.](http://arxiv.org/abs/2309.04504) | 本研究探讨了深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。通过利用冻结的文本编码器，代理所需的训练回合数减少了20倍。 |
| [^23] | [A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond.](http://arxiv.org/abs/2307.08643) | 该研究提出了一个通用框架，在分布层面上对不同类型的数据污染模型进行了形式化分析，并通过分析贝叶斯风险的变化展示了这些污染对标准监督学习的影响。这些发现为进一步研究提供了新的方向和基础。 |
| [^24] | [Diffusion Models for Computational Design at the Example of Floor Plans.](http://arxiv.org/abs/2307.02511) | 该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。 |
| [^25] | [DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$.](http://arxiv.org/abs/2306.08068) | DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。 |
| [^26] | [A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2306.07465) | 本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。 |
| [^27] | [DiffECG: A Generalized Probabilistic Diffusion Model for ECG Signals Synthesis.](http://arxiv.org/abs/2306.01875) | 本文介绍了一种新颖的ECG信号合成方法——基于去噪扩散概率模型的DiffECG，能够涵盖三种情形，并且是ECG合成的第一个广义条件方法。实验证明该方法的有效性以及优于其他ECG生成模型并可提高分类器性能。 |
| [^28] | [Predictive change point detection for heterogeneous data.](http://arxiv.org/abs/2305.06630) | 该论文提出了一种基于“预测与比较”机器学习模型的变点监测框架，它能够比现有的在线监测方法更好地控制误报率和失控平均运行长度。该方法使用ARIMA模型和LSTM递归神经网络模型进行预测，具有很强的推广性能。 |
| [^29] | [Compressing neural network by tensor network with exponentially fewer variational parameters.](http://arxiv.org/abs/2305.06058) | 本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。 |
| [^30] | [Fed-GLOSS-DP: Federated, Global Learning using Synthetic Sets with Record Level Differential Privacy.](http://arxiv.org/abs/2302.01068) | 本文通过利用合成样本实现全局优化，加入记录级差分隐私以保护隐私，验证了该方法的数据集有效性。 |
| [^31] | [Neural Common Neighbor with Completion for Link Prediction.](http://arxiv.org/abs/2302.00890) | 提出了神经通用邻居模型（NCN）用于链接预测，使用可学习的成对表示来捕捉节点之间的成对关系，以提高性能，同时解决链路不完整问题。 |
| [^32] | [Random Subgraph Detection Using Queries.](http://arxiv.org/abs/2110.00744) | 本文研究了使用自适应查询来检测种植子图存在，确定了必要和充分的查询数量。 |

# 详细

[^1]: 信任学习理论

    Credal Learning Theory

    [https://rss.arxiv.org/abs/2402.00957](https://rss.arxiv.org/abs/2402.00957)

    本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。

    

    统计学习理论是机器学习的基础，为从未知概率分布中学习到的模型的风险提供理论边界。然而，在实际部署中，数据分布可能会变化，导致领域适应/泛化问题。在本文中，我们建立了一个“信任”学习理论的基础，使用概率的凸集（信任集）来建模数据生成分布的变异性。我们认为，这样的信任集可以从有限样本的训练集中推断出来。对于有限假设空间（无论是否可实现）和无限模型空间，推导出界限，这直接推广了经典结果。

    Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
    
[^2]: 具有基础世界模型的无人驾驶汽车零射击安全预测

    Zero-shot Safety Prediction for Autonomous Robots with Foundation World Models

    [https://arxiv.org/abs/2404.00462](https://arxiv.org/abs/2404.00462)

    基于基础世界模型，提出了一种能够直接预测因果未来状态的方法，在安全预测任务中表现优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。

    

    世界模型创造一个代理世界来训练控制器，并通过学习系统的内部动态模型来预测安全违规行为。然而，现有的世界模型仅依赖于统计学习如何观察随着行动而变化，缺乏对代理动态准确性的精确量化，这在安全关键系统中构成重大挑战。为了解决这一挑战，我们提出了将观察嵌入到有意义且因果潜在的表示中的基础世界模型。这使得代理动态能够通过利用无需训练的大型语言模型直接预测因果未来状态。在两个常见的基准测试中，这种新颖模型在安全预测任务中优于标准世界模型，并且性能与监督学习相当，尽管没有使用任何数据。我们通过比较更专业和系统相关的指标评估其性能。

    arXiv:2404.00462v1 Announce Type: new  Abstract: A world model creates a surrogate world to train a controller and predict safety violations by learning the internal dynamic model of systems. However, the existing world models rely solely on statistical learning of how observations change in response to actions, lacking precise quantification of how accurate the surrogate dynamics are, which poses a significant challenge in safety-critical systems. To address this challenge, we propose foundation world models that embed observations into meaningful and causally latent representations. This enables the surrogate dynamics to directly predict causal future states by leveraging a training-free large language model. In two common benchmarks, this novel model outperforms standard world models in the safety prediction task and has a performance comparable to supervised learning despite not using any data. We evaluate its performance with a more specialized and system-relevant metric by compar
    
[^3]: 旋转扫描：带有三元SSM模块的UNet-like Mamba用于医学图像分割

    Rotate to Scan: UNet-like Mamba with Triplet SSM Module for Medical Image Segmentation

    [https://arxiv.org/abs/2403.17701](https://arxiv.org/abs/2403.17701)

    本文提出了Triplet Mamba-UNet，利用残余VSS块提取密集上下文特征，并利用Triplet SSM融合空间和通道维度上的特征。

    

    图像分割在医疗领域的诊断和治疗中占据重要位置。传统的卷积神经网络（CNN）和Transformer模型在这一领域取得了重大进展，但仍然面临由于有限感受野或高计算复杂性而带来的挑战。最近，状态空间模型（SSM），特别是Mamba及其变体，在视觉领域表现出显著性能。然而，它们的特征提取方法可能不够有效，保留了一些冗余结构，留下了参数减少的空间。受先前的空间和通道注意方法的启发，我们提出了Triplet Mamba-UNet。该方法利用残余VSS块来提取密集的上下文特征，同时利用Triplet SSM来融合空间和通道维度上的特征。我们在ISIC17、ISIC18、CVC-300、CVC-ClinicDB上进行了实验。

    arXiv:2403.17701v1 Announce Type: cross  Abstract: Image segmentation holds a vital position in the realms of diagnosis and treatment within the medical domain. Traditional convolutional neural networks (CNNs) and Transformer models have made significant advancements in this realm, but they still encounter challenges because of limited receptive field or high computing complexity. Recently, State Space Models (SSMs), particularly Mamba and its variants, have demonstrated notable performance in the field of vision. However, their feature extraction methods may not be sufficiently effective and retain some redundant structures, leaving room for parameter reduction. Motivated by previous spatial and channel attention methods, we propose Triplet Mamba-UNet. The method leverages residual VSS Blocks to extract intensive contextual features, while Triplet SSM is employed to fuse features across spatial and channel dimensions. We conducted experiments on ISIC17, ISIC18, CVC-300, CVC-ClinicDB, 
    
[^4]: 使用不变性学习基于动作的表示

    Learning Action-based Representations Using Invariance

    [https://arxiv.org/abs/2403.16369](https://arxiv.org/abs/2403.16369)

    提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量

    

    强化学习代理使用高维度观测必须能够在许多外源性干扰中识别相关状态特征。一个能够捕捉可控性的表示通过确定影响代理控制的因素来识别这些状态元素。虽然诸如逆动力学和互信息等方法可以捕捉有限数量的时间步的可控性，但捕获长时间元素仍然是一个具有挑战性的问题。短视的可控性可以捕捉代理即将撞向墙壁的瞬间，但不能在代理还有一定距离之时捕捉墙壁的控制相关性。为解决这个问题，我们提出了动作双模拟编码，这是一种受到双模拟不变量假度量启发的方法，它通过递归不变性约束扩展了单步控制性。通过这种方式，动作双模拟学习了一个平滑折扣远期元素的多步控制度量。

    arXiv:2403.16369v1 Announce Type: cross  Abstract: Robust reinforcement learning agents using high-dimensional observations must be able to identify relevant state features amidst many exogeneous distractors. A representation that captures controllability identifies these state elements by determining what affects agent control. While methods such as inverse dynamics and mutual information capture controllability for a limited number of timesteps, capturing long-horizon elements remains a challenging problem. Myopic controllability can capture the moment right before an agent crashes into a wall, but not the control-relevance of the wall while the agent is still some distance away. To address this we introduce action-bisimulation encoding, a method inspired by the bisimulation invariance pseudometric, that extends single-step controllability with a recursive invariance constraint. By doing this, action-bisimulation learns a multi-step controllability metric that smoothly discounts dist
    
[^5]: 从可解释到可解释的深度学习在医疗自然语言处理中的应用：现实有多远？

    From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?

    [https://arxiv.org/abs/2403.11894](https://arxiv.org/abs/2403.11894)

    该研究对医疗保健NLP中的深度学习进行了全面审查，提出了可解释和可解释的人工智能（XIAI）概念，并发现注意机制是主要新兴IAI，同时面临着缺乏全局建模、最佳实践以及系统评估和基准测试的挑战。

    

    深度学习（DL）通过解决各种自然语言处理（NLP）任务，极大地增强了医疗保健研究。然而，基于DL的NLP方法日益复杂，需要透明的模型解释性，或至少是可解释性，以进行可靠的决策制定。本文对医疗健康NLP中的可解释和可解释的DL进行了彻底的范围审查。引入了术语“XIAI”（eXplainable和Interpretable Artificial Intelligence）以区分XAI和IAI。方法根据其功能（模型、输入、输出为基础）和范围（局部、全局）进一步分类。我们的分析表明，注意机制是最主要的新兴IAI。此外，IAI越来越多地用于对抗XAI。确定的主要挑战是大多数XIAI不探索“全局”建模过程，缺乏最佳实践，并且需要系统评估和基准测试。

    arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
    
[^6]: Fisher Mask节点用于语言模型合并

    Fisher Mask Nodes for Language Model Merging

    [https://arxiv.org/abs/2403.09891](https://arxiv.org/abs/2403.09891)

    介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。

    

    微调预训练模型在下游性能方面具有显著优势。预训练模型（如BERT及其衍生物）在自然语言处理中的普遍性也导致了任务特定微调模型的激增。在多任务场景中，由于这些模型通常只能很好地执行一项任务，因此需要额外的训练或集成。模型合并这一不断增长的领域提供了一个解决方案，解决了将多个任务特定模型合并为单个多任务模型的挑战。在本研究中，我们引入了一种新颖的用于Transformers的模型合并方法，结合了先前Fisher加权平均和Fisher信息在模型修剪中的应用的见解。通过利用Transformer架构内的mask节点的Fisher信息，我们设计了一个计算效率高的加权平均方案。我们的方法展现出了稳定且显著的性能。

    arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
    
[^7]: 利用物理信息神经网络重建木星的磁场

    Reconstructions of Jupiter's magnetic field using physics informed neural networks

    [https://arxiv.org/abs/2403.07507](https://arxiv.org/abs/2403.07507)

    本研究提出了一种利用物理信息神经网络重建木星内部磁场的新方法，相比其他方法，能够更清晰地解析局部结构并避免深度噪声干扰。

    

    利用由Juno任务收集的数据进行磁测可以用来约束木星的内部。然而，假设电导率为零并以球谐函数表示的重建向内继续是受到小尺度噪声增强的限制。本文描述了基于物理信息神经网络的木星内部磁场的新重建方法，使用Juno轨道的前33个（PINN33）或前50个（PINN50）。该方法可以解析出局部结构，并允许存在弱环境电流。与其他方法相比，我们对木星磁场的表面和上方的重建都相似，并且与Juno数据拟合相似。然而，我们的模型不受深度噪声干扰，因此能够提供更清晰的内部结构图像。

    arXiv:2403.07507v1 Announce Type: cross  Abstract: Magnetic sounding using data collected from the Juno mission can be used to provide constraints on Jupiter's interior. However, inwards continuation of reconstructions assuming zero electrical conductivity and a representation in spherical harmonics are limited by the enhancement of noise at small scales. In this paper we describe new reconstructions of Jupiter's internal magnetic field based on physics-informed neural networks and either the first 33 (PINN33) or the first 50 (PINN50) of Juno's orbits. The method can resolve local structures, and allows for weak ambient electrical currents. Compared with other methods, our reconstructions of Jupiter's magnetic field both on and above the surface are similar, and we achieve a similar fit to the Juno data. However, our models are not hampered by noise at depth, and so offer a much clearer picture of the interior structure. We estimate that the dynamo boundary is at a fractional radius of
    
[^8]: Wukong: 迈向大规模推荐的标度律

    Wukong: Towards a Scaling Law for Large-Scale Recommendation

    [https://arxiv.org/abs/2403.02545](https://arxiv.org/abs/2403.02545)

    Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。

    

    缩放定律在提高模型质量方面起着关键作用。然而，迄今为止的推荐模型并没有展现出类似于大型语言模型领域观察到的定律，这是由于它们的升级机制的低效性。本文提出了一种基于纯堆叠因子分解机和协同增长策略的有效网络架构，统称为Wukong，以在推荐领域建立一个标度律。Wukong的独特设计使其能够通过更高更宽的层次简单捕获各种任意阶的交互。我们在六个公共数据集上进行了广泛评估，结果表明，与最先进的模型相比，Wukong在质量方面始终表现优越。此外，我们评估了Wuko

    arXiv:2403.02545v1 Announce Type: cross  Abstract: Scaling laws play an instrumental role in the sustainable improvement in model quality. Unfortunately, recommendation models to date do not exhibit such laws similar to those observed in the domain of large language models, due to the inefficiencies of their upscaling mechanisms. This limitation poses significant challenges in adapting these models to increasingly more complex real-world datasets. In this paper, we propose an effective network architecture based purely on stacked factorization machines, and a synergistic upscaling strategy, collectively dubbed Wukong, to establish a scaling law in the domain of recommendation. Wukong's unique design makes it possible to capture diverse, any-order of interactions simply through taller and wider layers. We conducted extensive evaluations on six public datasets, and our results demonstrate that Wukong consistently outperforms state-of-the-art models quality-wise. Further, we assessed Wuko
    
[^9]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^10]: 跨架构零样本泛化的视觉分类

    Zero-shot generalization across architectures for visual classification

    [https://arxiv.org/abs/2402.14095](https://arxiv.org/abs/2402.14095)

    不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。

    

    深度网络的一个关键优势是对未见数据的泛化能力，但其与分类准确性的关系尚不清楚。我们利用一种极简的视觉数据集和一种泛化度量，展示了从深度卷积网络（CNNs）到transformers的流行网络在通过层和架构泛化到未见类别方面的能力存在差异。准确性并不是泛化能力的良好预测因子，并且泛化能力随着层深度呈非单调变化。代码可在https://github.com/dyballa/zero-shot-generalization 找到。

    arXiv:2402.14095v1 Announce Type: cross  Abstract: Generalization to unseen data is a key desideratum for deep networks, but its relation to classification accuracy is unclear. Using a minimalist vision dataset and a measure of generalizability, we show that popular networks, from deep convolutional networks (CNNs) to transformers, vary in their power to extrapolate to unseen classes both across layers and across architectures. Accuracy is not a good predictor of generalizability, and generalization varies non-monotonically with layer depth. Code is available at https://github.com/dyballa/zero-shot-generalization.
    
[^11]: rnaglib中基于3D的RNA功能预测工具

    3D-based RNA function prediction tools in rnaglib

    [https://arxiv.org/abs/2402.09330](https://arxiv.org/abs/2402.09330)

    rnaglib是一个基于3D的RNA功能预测工具，可以用于在RNA 3D结构数据集上训练监督和非监督机器学习模型。

    

    理解RNA的复杂结构特征与生物功能之间的联系是进化研究和RNA设计中的一个基本挑战。然而，构建RNA 3D结构的数据集并进行适当的建模选择仍然耗时且缺乏标准化。在本章中，我们描述了在RNA 3D结构数据集上训练监督和非监督机器学习功能预测模型的rnaglib的使用方法。

    arXiv:2402.09330v1 Announce Type: cross Abstract: Understanding the connection between complex structural features of RNA and biological function is a fundamental challenge in evolutionary studies and in RNA design. However, building datasets of RNA 3D structures and making appropriate modeling choices remains time-consuming and lacks standardization. In this chapter, we describe the use of rnaglib, to train supervised and unsupervised machine learning-based function prediction models on datasets of RNA 3D structures.
    
[^12]: LLMs的两面性：Jekyll博士与Hyde先生

    Dr. Jekyll and Mr. Hyde: Two Faces of LLMs

    [https://arxiv.org/abs/2312.03853](https://arxiv.org/abs/2312.03853)

    本研究通过让ChatGPT和Bard冒充复杂人物角色，绕过了安全机制和专门训练程序，展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。

    

    仅仅一年前，我们目睹了大型语言模型（LLMs）的使用增加，尤其是在结合像聊天机器人助手之类的应用时。为了防止这些助手产生不当回应，我们实施了安全机制和专门的训练程序。在这项工作中，我们通过让ChatGPT和Bard（以及在某种程度上是Bing chat）冒充复杂人物角色，绕过了这些措施，这些角色与它们本应成为的真实助手的特征相反。我们首先创造出这些人物角色的复杂传记，然后在同一聊天机器人中使用它们进行新的对话。我们的对话采用角色扮演风格，以获得助手不被允许提供的回应。通过使用人物角色，我们展示了被禁止的回应实际上被提供了，从而有可能获取未经授权、非法或有害的信息。这项工作表明，通过使用对抗性pe

    arXiv:2312.03853v2 Announce Type: replace-cross  Abstract: Only a year ago, we witnessed a rise in the use of Large Language Models (LLMs), especially when combined with applications like chatbot assistants. Safety mechanisms and specialized training procedures are implemented to prevent improper responses from these assistants. In this work, we bypass these measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them impersonate complex personas with opposite characteristics as those of the truthful assistants they are supposed to be. We start by creating elaborate biographies of these personas, which we then use in a new session with the same chatbots. Our conversation followed a role-play style to get the response the assistant was not allowed to provide. By making use of personas, we show that the response that is prohibited is actually provided, making it possible to obtain unauthorized, illegal, or harmful information. This work shows that by using adversarial pe
    
[^13]: 模块化神经网络用于时间序列预测：使用注意力进行解释性和特征选择

    Modular Neural Networks for Time Series Forecasting: Interpretability and Feature Selection using Attention

    [https://arxiv.org/abs/2311.16834](https://arxiv.org/abs/2311.16834)

    该论文提出了一种新颖的模块化神经网络模型，用于多变量时间序列预测，通过循环神经网络学习时间依赖关系，并使用基于注意力的特征选择组件实现解释性，实验结果表明其优于当前最先进的解释性神经加性模型（NAM）及其变体。

    

    多变量时间序列在医疗保健、气象学和生命科学等领域有许多应用。虽然深度学习模型在时间序列预测方面表现出色，但被批评为“黑盒”或无法解释。本文提出了一种新颖的用于多变量时间序列预测的模块化神经网络模型，其构造具有解释性。循环神经网络学习数据中的时间依赖关系，而基于注意力的特征选择组件选择最相关的特征并抑制在学习时间依赖性中使用的冗余特征。从选择的特征独立训练模块化深度网络，向用户展示特征如何影响结果，使模型具有解释性。实验结果表明，这种方法可以超过最先进的可解释性神经加性模型（NAM）及其变体。

    arXiv:2311.16834v3 Announce Type: replace-cross  Abstract: Multivariate time series have many applications, from healthcare and meteorology to life science. Although deep learning models have shown excellent predictive performance for time series, they have been criticised for being "black-boxes" or non-interpretable. This paper proposes a novel modular neural network model for multivariate time series prediction that is interpretable by construction. A recurrent neural network learns the temporal dependencies in the data while an attention-based feature selection component selects the most relevant features and suppresses redundant features used in the learning of the temporal dependencies. A modular deep network is trained from the selected features independently to show the users how features influence outcomes, making the model interpretable. Experimental results show that this approach can outperform state-of-the-art interpretable Neural Additive Models (NAM) and variations thereo
    
[^14]: InceptionXML：一种带有同步负采样的轻量级框架，用于短文本极端分类

    InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification

    [https://arxiv.org/abs/2109.07319](https://arxiv.org/abs/2109.07319)

    提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。

    

    短文本数据对大量目标标签进行自动注释，被称为短文本极端分类，已经在许多应用中得到应用，包括相关搜索预测和产品推荐任务。本文提出了一种卷积架构InceptionXML，其轻量但功能强大，并且能够应对搜索和推荐任务中短文本查询中固有的缺乏单词顺序的特点。我们通过将卷积的操作沿着嵌入维度重新构建，而不是像传统CNNs一样沿着单词维度进行文本分类，证明了应用卷积的有效性。为了将我们的模型扩展到具有数百万标签的数据集，我们还提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了最近提出的动态硬负采样技术在标签筛选中的缺陷。

    arXiv:2109.07319v3 Announce Type: replace-cross  Abstract: Automatic annotation of short-text data to a large number of target labels, referred to as Short Text Extreme Classification, has found numerous applications including prediction of related searches and product recommendation tasks. In this paper, we propose a convolutional architecture InceptionXML which is light-weight, yet powerful, and robust to the inherent lack of word-order in short-text queries encountered in search and recommendation tasks. We demonstrate the efficacy of applying convolutions by recasting the operation along the embedding dimension instead of the word dimension as applied in conventional CNNs for text classification. Towards scaling our model to datasets with millions of labels, we also propose InceptionXML+ framework which improves upon the shortcomings of the recently proposed dynamic hard-negative mining technique for label shortlisting by synchronizing the label-shortlister and extreme classifier. 
    
[^15]: LangProp: 一种应用于自动驾驶的使用语言模型的代码优化框架

    LangProp: A code optimization framework using Language Models applied to driving. (arXiv:2401.10314v1 [cs.SE])

    [http://arxiv.org/abs/2401.10314](http://arxiv.org/abs/2401.10314)

    LangProp是一种用于自动驾驶的代码优化框架，利用语言模型迭代优化生成的代码。它通过评估代码性能和捕捉异常来改进生成的代码，展示了在CARLA中实现自动驾驶的概念验证。

    

    LangProp是一个框架，用于在监督/强化学习环境中迭代优化大型语言模型(LLM)生成的代码。虽然LLM能够零-shot地生成合理的解决方案，但这些解决方案往往是次优的。特别是对于代码生成任务，初始代码可能在某些边缘情况下失败。LangProp自动评估数据集上的代码性能，并捕捉任何异常，并将结果反馈给LLM进行训练，以使LLM可以迭代改进其生成的代码。通过采用基于度量和数据驱动的训练范式来进行代码优化过程，可以轻松地借鉴传统机器学习技术，如模仿学习、DAgger和强化学习。我们展示了在CARLA中自动驾驶的代码优化的第一个概念验证，证明了LangProp可以生成可解释和透明的驾驶代码。

    LangProp is a framework for iteratively optimizing code generated by large language models (LLMs) in a supervised/reinforcement learning setting. While LLMs can generate sensible solutions zero-shot, the solutions are often sub-optimal. Especially for code generation tasks, it is likely that the initial code will fail on certain edge cases. LangProp automatically evaluates the code performance on a dataset of input-output pairs, as well as catches any exceptions, and feeds the results back to the LLM in the training loop, so that the LLM can iteratively improve the code it generates. By adopting a metricand data-driven training paradigm for this code optimization procedure, one could easily adapt findings from traditional machine learning techniques such as imitation learning, DAgger, and reinforcement learning. We demonstrate the first proof of concept of automated code optimization for autonomous driving in CARLA, showing that LangProp can generate interpretable and transparent dri
    
[^16]: 差异特征未报告对算法公平性的影响

    The Impact of Differential Feature Under-reporting on Algorithmic Fairness. (arXiv:2401.08788v1 [cs.LG])

    [http://arxiv.org/abs/2401.08788](http://arxiv.org/abs/2401.08788)

    本文研究了差异特征未报告对算法公平性的影响，并提出了一个可分析的模型进行刻画。

    

    公共部门的预测风险模型通常使用更完整的行政数据来开发，这些数据对于更大程度依赖公共服务的亚群体更为完整。例如，在美国，对于由医疗补助和医疗保险支持的个人，政府机构常常可以获得有关医疗保健利用的信息，但对于私人保险的人则没有。对公共部门算法的批评指出，差异特征未报告导致算法决策中的不公平。然而，这种数据偏见在技术视角下仍然研究不足。虽然以前的研究已经考察了添加特征噪声和明确标记为缺失的特征对公平性的影响，但缺失指标的数据缺失情况（即差异特征未报告）尚未得到研究的关注。在本研究中，我们提出了一个可分析的差异特征未报告模型，并将其应用于特征未报告对算法公平性的刻画。

    Predictive risk models in the public sector are commonly developed using administrative data that is more complete for subpopulations that more greatly rely on public services. In the United States, for instance, information on health care utilization is routinely available to government agencies for individuals supported by Medicaid and Medicare, but not for the privately insured. Critiques of public sector algorithms have identified such differential feature under-reporting as a driver of disparities in algorithmic decision-making. Yet this form of data bias remains understudied from a technical viewpoint. While prior work has examined the fairness impacts of additive feature noise and features that are clearly marked as missing, the setting of data missingness absent indicators (i.e. differential feature under-reporting) has been lacking in research attention. In this work, we present an analytically tractable model of differential feature under-reporting which we then use to charac
    
[^17]: 探索分割联邦学习的隐私-能耗权衡

    Exploring the Privacy-Energy Consumption Tradeoff for Split Federated Learning. (arXiv:2311.09441v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.09441](http://arxiv.org/abs/2311.09441)

    本文研究了分割联邦学习（SFL）中隐私和能耗之间的权衡，强调了快速收敛的优势，并分析了切割层对客户端能耗和隐私的影响。

    

    分割联邦学习（SFL）最近已经成为一种有前景的分布式学习技术，充分利用了联邦学习和分割学习的优势。它强调了快速收敛的优势，同时解决了隐私问题。因此，这一创新受到了工业界和学术界的广泛关注。然而，由于SFL中模型在特定层（称为切割层）上被分割为客户端和服务器端模型，选择切割层可能对客户端的能耗和隐私产生重大影响，因为它影响了训练负担和客户端模型的输出。此外，确定切割层的设计挑战非常复杂，主要由于客户端的计算和网络能力的固有异质性。在本文中，我们全面概述了SFL的过程，并对能耗和隐私进行了深入分析。

    Split Federated Learning (SFL) has recently emerged as a promising distributed learning technology, leveraging the strengths of both federated learning and split learning. It emphasizes the advantages of rapid convergence while addressing privacy concerns. As a result, this innovation has received significant attention from both industry and academia. However, since the model is split at a specific layer, known as a cut layer, into both client-side and server-side models for the SFL, the choice of the cut layer in SFL can have a substantial impact on the energy consumption of clients and their privacy, as it influences the training burden and the output of the client-side models. Moreover, the design challenge of determining the cut layer is highly intricate, primarily due to the inherent heterogeneity in the computing and networking capabilities of clients. In this article, we provide a comprehensive overview of the SFL process and conduct a thorough analysis of energy consumption and
    
[^18]: 通过强化学习实现隐私保护的语言模型对齐

    Privately Aligning Language Models with Reinforcement Learning. (arXiv:2310.16960v1 [cs.LG])

    [http://arxiv.org/abs/2310.16960](http://arxiv.org/abs/2310.16960)

    本文研究了通过强化学习实现隐私保护的语言模型对齐问题，提出了一种新的差分隐私框架，并通过实验证明了其有效性和实用性。

    

    在预训练和用户部署之间，通过强化学习对齐大型语言模型(LLMs)已经成为培训指令跟踪模型(如ChatGPT)的主流策略。本文在强化学习的基础上，引入差分隐私(DP)来研究隐私保护的LLMs对齐问题。我们研究了两种主要的范式：(i)不需要人工干预的强化学习对齐方法(如积极评价生成)，(ii)通过人类反馈的强化学习对齐方法(RLHF)(如以人类首选方式进行摘要生成)。我们提出了一种新的DP框架来实现强化学习的对齐，并证明了其正确性。实验结果验证了我们方法的有效性，能够在确保强隐私保护的同时，提供有竞争力的实用性。

    Positioned between pre-training and user deployment, aligning large language models (LLMs) through reinforcement learning (RL) has emerged as a prevailing strategy for training instruction following-models such as ChatGPT. In this work, we initiate the study of privacy-preserving alignment of LLMs through Differential Privacy (DP) in conjunction with RL. Following the influential work of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment via RL without human in the loop (e.g., positive review generation) and (ii) alignment via RL from human feedback (RLHF) (e.g., summarization in a human-preferred way). We give a new DP framework to achieve alignment via RL, and prove its correctness. Our experimental results validate the effectiveness of our approach, offering competitive utility while ensuring strong privacy protections.
    
[^19]: 从神经激活到概念: 解释神经网络中的概念的调查

    From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks. (arXiv:2310.11884v1 [cs.AI])

    [http://arxiv.org/abs/2310.11884](http://arxiv.org/abs/2310.11884)

    本文调查了解释神经网络中概念的最新方法，这对于实现基于可解释概念的神经符号化人工智能来说是重要的一步。

    

    在本文中，我们审查了解释神经网络中概念的最新方法。概念可以作为学习和推理之间的自然桥梁：一旦确定了神经学习系统使用的概念，就可以将这些概念与推理系统整合，用于推理或使用推理系统对其进行改进或增强以改善学习系统。另一方面，不仅可以从神经网络中提取知识，还可以将概念知识插入神经网络体系结构中。由于整合学习和推理是神经符号化人工智能的核心，所以通过这项调查获得的见解可以成为实现基于可解释概念的神经符号化人工智能的重要一步。

    In this paper, we review recent approaches for explaining concepts in neural networks. Concepts can act as a natural link between learning and reasoning: once the concepts are identified that a neural learning system uses, one can integrate those concepts with a reasoning system for inference or use a reasoning system to act upon them to improve or enhance the learning system. On the other hand, knowledge can not only be extracted from neural networks but concept knowledge can also be inserted into neural network architectures. Since integrating learning and reasoning is at the core of neuro-symbolic AI, the insights gained from this survey can serve as an important step towards realizing neuro-symbolic AI based on explainable concepts.
    
[^20]: "BrainSCUBA: 视觉皮层选择性的细粒度自然语言描述"

    BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity. (arXiv:2310.04420v1 [cs.LG])

    [http://arxiv.org/abs/2310.04420](http://arxiv.org/abs/2310.04420)

    "BrainSCUBA通过生成自然语言描述来预测最大激活个体感兴趣体素的图像，达到了细粒度的视觉皮层选择性描述。"

    

    "理解高级视觉皮层的功能组织是神经科学的核心关注点。过去的研究主要使用手动选择的刺激来映射神经群体的视觉和语义选择性，这可能会导致对视觉皮层功能的预设假设的结果偏差。我们引入了一种数据驱动的方法，通过生成自然语言描述来预测最大激活个体感兴趣体素的图像。我们的方法- 基于对比视觉-语言模型学到的丰富嵌入空间，并利用预训练的大型语言模型生成可解释的描述。我们通过高阶视觉区域进行了细粒度的体素级描述，并通过文本条件的图像合成验证了我们的方法，结果表明我们的图像在语义上是连贯的并且具有高的质量。"

    Understanding the functional organization of higher visual cortex is a central focus in neuroscience. Past studies have primarily mapped the visual and semantic selectivity of neural populations using hand-selected stimuli, which may potentially bias results towards pre-existing hypotheses of visual cortex functionality. Moving beyond conventional approaches, we introduce a data-driven method that generates natural language descriptions for images predicted to maximally activate individual voxels of interest. Our method -Semantic Captioning Using Brain Alignments ("BrainSCUBA") -- builds upon the rich embedding space learned by a contrastive vision-language model and utilizes a pre-trained large language model to generate interpretable captions. We validate our method through fine-grained voxel-level captioning across higher-order visual regions. We further perform text-conditioned image synthesis with the captions, and show that our images are semantically coherent and yield high pr
    
[^21]: 基于深度强化学习的连续空间无限时域均场问题解决方法

    Deep Reinforcement Learning for Infinite Horizon Mean Field Problems in Continuous Spaces. (arXiv:2309.10953v1 [math.OC])

    [http://arxiv.org/abs/2309.10953](http://arxiv.org/abs/2309.10953)

    这项研究提出了一种基于深度强化学习的算法，通过将演员-评论家范式与均场分布表示配对，来解决连续空间中的均场博弈和均场控制问题，并使用朗之万动力学从分布中获取样本。该算法在渐近无限时域框架下使用线性二次基准进行评估。

    

    我们提出了一种强化学习算法，用于统一解决连续空间均场博弈（MFG）和均场控制（MFC）问题，并对其进行了分析和发展。所提出的方法将演员-评论家（AC）范式与通过参数化评分函数表示的均场分布配对，可以以在线方式有效地更新，并使用朗之万动力学从得到的分布中获得样本。AC代理和评分函数按迭代方式进行更新，以收敛到给定均场问题的MFG平衡或MFC最优解，具体取决于学习率的选择。算法的简单修改使我们能够解决混合均场控制博弈（MFCG）。我们使用渐近无限时域框架中的线性二次基准评估我们的算法性能。

    We present the development and analysis of a reinforcement learning (RL) algorithm designed to solve continuous-space mean field game (MFG) and mean field control (MFC) problems in a unified manner. The proposed approach pairs the actor-critic (AC) paradigm with a representation of the mean field distribution via a parameterized score function, which can be efficiently updated in an online fashion, and uses Langevin dynamics to obtain samples from the resulting distribution. The AC agent and the score function are updated iteratively to converge, either to the MFG equilibrium or the MFC optimum for a given mean field problem, depending on the choice of learning rates. A straightforward modification of the algorithm allows us to solve mixed mean field control games (MFCGs). The performance of our algorithm is evaluated using linear-quadratic benchmarks in the asymptotic infinite horizon framework.
    
[^22]: 使用强化学习进行基于视觉的概念组合学习

    Compositional Learning of Visually-Grounded Concepts Using Reinforcement. (arXiv:2309.04504v1 [cs.LG])

    [http://arxiv.org/abs/2309.04504](http://arxiv.org/abs/2309.04504)

    本研究探讨了深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。通过利用冻结的文本编码器，代理所需的训练回合数减少了20倍。

    

    深度强化学习代理需要通过数百万个回合的训练才能较好地解决与指令相关的导航任务，并且它们是否能够推广到新颖的指令组合的能力尚不清楚。有趣的是，儿童可以分解基于语言的指令并导航到指定的物体，即使他们之前没有见过这些查询的组合。因此，我们创建了三个3D环境，研究深度强化学习代理如何学习和组合基于颜色和形状的组合指令，以解决空间导航任务中的新颖组合。首先，我们探讨代理是否能够进行组合学习，并且它们是否可以利用冻结的文本编码器（例如CLIP、BERT）在更少的回合中学习单词组合。接下来，我们证明当代理在形状或颜色概念上进行预训练时，它们所需的训练回合数减少了20倍，可以解决未见过的指令组合。最后，我们展示了...

    Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show tha
    
[^23]: 一个学习受到污染的通用框架：标签噪声、属性噪声等等

    A General Framework for Learning under Corruption: Label Noise, Attribute Noise, and Beyond. (arXiv:2307.08643v1 [cs.LG])

    [http://arxiv.org/abs/2307.08643](http://arxiv.org/abs/2307.08643)

    该研究提出了一个通用框架，在分布层面上对不同类型的数据污染模型进行了形式化分析，并通过分析贝叶斯风险的变化展示了这些污染对标准监督学习的影响。这些发现为进一步研究提供了新的方向和基础。

    

    数据中的污染现象很常见，并且已经在不同的污染模型下进行了广泛研究。尽管如此，对于这些模型之间的关系仍然了解有限，缺乏对污染及其对学习的影响的统一视角。在本研究中，我们通过基于马尔可夫核的一般性和详尽的框架，在分布层面上正式分析了污染模型。我们强调了标签和属性上存在的复杂联合和依赖性污染，这在现有研究中很少触及。此外，我们通过分析贝叶斯风险变化来展示这些污染如何影响标准的监督学习。我们的发现提供了对于“更复杂”污染对学习问题影响的定性洞察，并为未来的定量比较提供了基础。该框架的应用包括污染校正学习，其中包含一个子案例。

    Corruption is frequently observed in collected data and has been extensively studied in machine learning under different corruption models. Despite this, there remains a limited understanding of how these models relate such that a unified view of corruptions and their consequences on learning is still lacking. In this work, we formally analyze corruption models at the distribution level through a general, exhaustive framework based on Markov kernels. We highlight the existence of intricate joint and dependent corruptions on both labels and attributes, which are rarely touched by existing research. Further, we show how these corruptions affect standard supervised learning by analyzing the resulting changes in Bayes Risk. Our findings offer qualitative insights into the consequences of "more complex" corruptions on the learning problem, and provide a foundation for future quantitative comparisons. Applications of the framework include corruption-corrected learning, a subcase of which we 
    
[^24]: 用于计算设计的扩散模型在楼层平面示例中的应用

    Diffusion Models for Computational Design at the Example of Floor Plans. (arXiv:2307.02511v1 [cs.LG])

    [http://arxiv.org/abs/2307.02511](http://arxiv.org/abs/2307.02511)

    该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。

    

    最近，基于扩散模型的AI图像生成器因其能够根据简单的文本提示创建图像而受到广泛讨论。但是，在土木工程的实际应用中，它们需要能够根据给定的约束条件创建特定的建筑设计方案。在本文中，我们以楼层平面作为示例，探索基于扩散的AI生成器在计算设计中的能力，并确定它们目前的限制。我们解释了扩散模型的工作原理，并提出了具有改进的语义编码的新扩散模型。通过多次实验，我们展示了我们可以将生成的楼层平面的有效性从6%提高到90%，并改进了不同示例的查询性能。我们发现了一些问题，并针对这些模型提出了未来的研究挑战，并讨论了将扩散模型与建筑信息模型相结合的需要。通过这些，我们为土木工程中扩散模型的当前状态和未来方向提供了关键见解。

    AI Image generators based on diffusion models are widely discussed recently for their capability to create images from simple text prompts. But, for practical use in civil engineering they need to be able to create specific construction plans for given constraints. Within this paper we explore the capabilities of those diffusion-based AI generators for computational design at the example of floor plans and identify their current limitation. We explain how the diffusion-models work and propose new diffusion models with improved semantic encoding. In several experiments we show that we can improve validity of generated floor plans from 6% to 90% and query performance for different examples. We identify short comings and derive future research challenges of those models and discuss the need to combine diffusion models with building information modelling. With this we provide key insights into the current state and future directions for diffusion models in civil engineering.
    
[^25]: DORSal: 基于扩散的物体中心场景表示

    DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$. (arXiv:2306.08068v1 [cs.CV])

    [http://arxiv.org/abs/2306.08068](http://arxiv.org/abs/2306.08068)

    DORSal提出了一种基于扩散模型的物体中心场景表示方法，可以呈现高保真新视图，并在较大程度上保留了诸如基于物体的场景编辑之类的优点。

    

    最近在三维场景理解方面取得的进展使跨大量不同场景的数据集的可扩展表示学习成为可能。因此，对于未见过的场景和物体的泛化，仅通过单个或少数图像渲染新视图，以及支持编辑的可控场景生成现在成为可能。然而，联合训练大量场景通常会在渲染质量上妥协，而与单个场景优化模型（如NeRF）相比。在本文中，我们利用最近扩散模型的进展，使三维场景表示学习模型具备呈现高保真新视图的能力，同时在较大程度上保留了诸如基于物体的场景编辑之类的优点。特别地，我们提出了DORSal，它基于扩散视频架构，为基于物体中心的场景插槽表示的三维场景生成提供适应性。我们在复杂的合成多物体场景和现实世界大规模街景数据集上证明，我们的模型能够生成高质量的场景新视图，同时支持物体级别的编辑，并保留细粒度的纹理和反射等细节。

    Recent progress in 3D scene understanding enables scalable learning of representations across large datasets of diverse scenes. As a consequence, generalization to unseen scenes and objects, rendering novel views from just a single or a handful of input images, and controllable scene generation that supports editing, is now possible. However, training jointly on a large number of scenes typically compromises rendering quality when compared to single-scene optimized models such as NeRFs. In this paper, we leverage recent progress in diffusion models to equip 3D scene representation learning models with the ability to render high-fidelity novel views, while retaining benefits such as object-level scene editing to a large degree. In particular, we propose DORSal, which adapts a video diffusion architecture for 3D scene generation conditioned on object-centric slot-based representations of scenes. On both complex synthetic multi-object scenes and on the real-world large-scale Street View d
    
[^26]: 面向非平稳多智能体强化学习的黑盒方法

    A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning. (arXiv:2306.07465v1 [cs.LG])

    [http://arxiv.org/abs/2306.07465](http://arxiv.org/abs/2306.07465)

    本文提出了一种通用的黑盒方法，适用于多种多智能体强化学习问题，可以在非平稳环境下实现低遗憾率的学习。

    

    本文研究了在非平稳多智能体系统中学习均衡的方法，并解决了区别于单智能体学习的挑战。我们重点关注带有赌徒反馈的游戏，其中即使待测试的差距很小，测试一个均衡也可能导致大量的遗憾，并且在静态游戏中存在多个最优解（均衡）会带来额外的难题。为了克服这些障碍，我们提出了一种通用的黑盒方法，适用于广泛的问题，如一般和博弈、潜在博弈和马尔可夫博弈，只要在静态环境下配备适当的学习和测试神谕。当非平稳程度（通过总变化量 $\Delta$ 测量）已知时，我们的算法可以实现 $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ 的遗憾，当 $\Delta$ 未知时，可以实现 $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ 的遗憾。

    We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\widetilde{O}\left(\Delta^{1/4}T^{3/4}\right)$ regret when the degree of nonstationarity, as measured by total variation $\Delta$, is known, and $\widetilde{O}\left(\Delta^{1/5}T^{4/5}\right)$ regret when $\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, 
    
[^27]: DiffECG：ECG信号合成的一般化概率扩散模型

    DiffECG: A Generalized Probabilistic Diffusion Model for ECG Signals Synthesis. (arXiv:2306.01875v1 [cs.CV])

    [http://arxiv.org/abs/2306.01875](http://arxiv.org/abs/2306.01875)

    本文介绍了一种新颖的ECG信号合成方法——基于去噪扩散概率模型的DiffECG，能够涵盖三种情形，并且是ECG合成的第一个广义条件方法。实验证明该方法的有效性以及优于其他ECG生成模型并可提高分类器性能。

    

    近年来，深度生成模型在基于深度学习的ECG信号心脏疾病检测中作为一种有前途的数据增强解决方案备受关注。本文提出一种新颖的基于去噪扩散概率模型的ECG合成方法,覆盖了三种情形：心跳生成、部分信号完成和完整心跳预测。我们的方法是ECG合成的第一个广义条件方法，实验结果表明其对各种ECG相关任务的有效性。此外，我们还展示了我们的方法优于其他最先进的ECG生成模型并可以提高最先进的分类器的性能。

    In recent years, deep generative models have gained attention as a promising data augmentation solution for heart disease detection using deep learning approaches applied to ECG signals. In this paper, we introduce a novel approach based on denoising diffusion probabilistic models for ECG synthesis that covers three scenarios: heartbeat generation, partial signal completion, and full heartbeat forecasting. Our approach represents the first generalized conditional approach for ECG synthesis, and our experimental results demonstrate its effectiveness for various ECG-related tasks. Moreover, we show that our approach outperforms other state-of-the-art ECG generative models and can enhance the performance of state-of-the-art classifiers.
    
[^28]: 异质数据的预测性变点检测

    Predictive change point detection for heterogeneous data. (arXiv:2305.06630v1 [cs.LG])

    [http://arxiv.org/abs/2305.06630](http://arxiv.org/abs/2305.06630)

    该论文提出了一种基于“预测与比较”机器学习模型的变点监测框架，它能够比现有的在线监测方法更好地控制误报率和失控平均运行长度。该方法使用ARIMA模型和LSTM递归神经网络模型进行预测，具有很强的推广性能。

    

    引入一个名为“预测与比较”的机器学习模型辅助的变点检测（CPD）框架，并与其他在线CPD例程进行比较，结果表明该方法在误报率和失控平均运行长度方面表现更优。该方法的重点是通过使用更复杂的预测模型（预测步骤）代替通常使用的趋势估计函数（如滑动平均），并将其预测与实际数据进行比较（比较步骤），从而改善顺序分析中的标准方法，例如CUSUM规则，以提高这些质量指标。

    A change point detection (CPD) framework assisted by a predictive machine learning model called ''Predict and Compare'' is introduced and characterised in relation to other state-of-the-art online CPD routines which it outperforms in terms of false positive rate and out-of-control average run length. The method's focus is on improving standard methods from sequential analysis such as the CUSUM rule in terms of these quality measures.  This is achieved by replacing typically used trend estimation functionals such as the running mean with more sophisticated predictive models (Predict step), and comparing their prognosis with actual data (Compare step). The two models used in the Predict step are the ARIMA model and the LSTM recursive neural network. However, the framework is formulated in general terms, so as to allow the use of other prediction or comparison methods than those tested here. The power of the method is demonstrated in a tribological case study in which change points separa
    
[^29]: 使用指数级别的少量变分参数的张量网络压缩神经网络

    Compressing neural network by tensor network with exponentially fewer variational parameters. (arXiv:2305.06058v1 [cs.LG])

    [http://arxiv.org/abs/2305.06058](http://arxiv.org/abs/2305.06058)

    本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。

    

    为了解决神经网络（NN）所包含的巨大可变的参数问题，本文提出了一种将这些参数 encoding 为多层张量网络（TN）的压缩方案。这种方案演示了出色的压缩性能，超过了以浅层张量网络为基础的现有最先进方法。例如，VGG-16中的3个卷积层的大约1000万参数被压缩到具有仅632个参数的TN中，而在CIFAR-10上的测试准确性令人惊喜地提高了81.14％。

    Neural network (NN) designed for challenging machine learning tasks is in general a highly nonlinear mapping that contains massive variational parameters. High complexity of NN, if unbounded or unconstrained, might unpredictably cause severe issues including over-fitting, loss of generalization power, and unbearable cost of hardware. In this work, we propose a general compression scheme that significantly reduces the variational parameters of NN by encoding them to multi-layer tensor networks (TN's) that contain exponentially-fewer free parameters. Superior compression performance of our scheme is demonstrated on several widely-recognized NN's (FC-2, LeNet-5, and VGG-16) and datasets (MNIST and CIFAR-10), surpassing the state-of-the-art method based on shallow tensor networks. For instance, about 10 million parameters in the three convolutional layers of VGG-16 are compressed in TN's with just $632$ parameters, while the testing accuracy on CIFAR-10 is surprisingly improved from $81.14
    
[^30]: Fed-GLOSS-DP: 利用具有记录级差分隐私的合成集进行联邦全局学习

    Fed-GLOSS-DP: Federated, Global Learning using Synthetic Sets with Record Level Differential Privacy. (arXiv:2302.01068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01068](http://arxiv.org/abs/2302.01068)

    本文通过利用合成样本实现全局优化，加入记录级差分隐私以保护隐私，验证了该方法的数据集有效性。

    

    本文提出了Fed-GLOSS-DP，一种新颖的保护隐私的联邦学习方法。与以前的线性逐点梯度分享方案（如FedAvg）不同，我们的公式利用从客户端接收到的合成样本实现了一种全局优化。这些合成样本作为损失替代物，通过模拟本地区域内真实图像的实用性来近似本地损失地形。我们还引入了一种衡量有效逼近区域的方法，反映了近似的质量。因此，服务器可以恢复全局损失地形并全面优化模型。此外，受日益严重的隐私问题的启发，我们演示了我们的方法与记录级差分隐私（DP）无缝配合，为客户端上的每个数据记录提供理论上的隐私保证。广泛的结果验证了我们的公式在具有高度倾斜分布的各种数据集上的有效性。

    This work proposes Fed-GLOSS-DP, a novel privacy-preserving approach for federated learning. Unlike previous linear point-wise gradient-sharing schemes, such as FedAvg, our formulation enables a type of global optimization by leveraging synthetic samples received from clients. These synthetic samples, serving as loss surrogates, approximate local loss landscapes by simulating the utility of real images within a local region. We additionally introduce an approach to measure effective approximation regions reflecting the quality of the approximation. Therefore, the server can recover the global loss landscape and comprehensively optimize the model. Moreover, motivated by the emerging privacy concerns, we demonstrate that our approach seamlessly works with record-level differential privacy (DP), granting theoretical privacy guarantees for every data record on the clients. Extensive results validate the efficacy of our formulation on various datasets with highly skewed distributions. Our m
    
[^31]: 具有完成功能的神经通用邻居用于链接预测

    Neural Common Neighbor with Completion for Link Prediction. (arXiv:2302.00890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00890](http://arxiv.org/abs/2302.00890)

    提出了神经通用邻居模型（NCN）用于链接预测，使用可学习的成对表示来捕捉节点之间的成对关系，以提高性能，同时解决链路不完整问题。

    

    尽管vanilla信息传递神经网络（MPNN）在各种图任务中具有出色的性能，但在链接预测任务中通常失败，因为它只使用两个单独目标节点的表示，并忽略它们之间的成对关系。为了捕获成对关系，一些模型将手动功能添加到输入图中，并使用MPNN的输出来生成成对表示。相反，其他人直接将手动功能用作成对表示。尽管此简化避免了将GNN逐个链接地应用于每个链接，从而提高了可扩展性，但由于手工制作的和不可学习的成对特征，这些模型仍有很大的性能提升空间。为了在保持可扩展性的同时提高性能，我们提出了神经通用邻居（NCN），它使用可学习的成对表示。为了进一步提高NCN的性能，我们研究了未观察到的链接问题。图的不完整性是普遍存在的，并导致分布偏移

    Despite its outstanding performance in various graph tasks, vanilla Message Passing Neural Network (MPNN) usually fails in link prediction tasks, as it only uses representations of two individual target nodes and ignores the pairwise relation between them. To capture the pairwise relations, some models add manual features to the input graph and use the output of MPNN to produce pairwise representations. In contrast, others directly use manual features as pairwise representations. Though this simplification avoids applying a GNN to each link individually and thus improves scalability, these models still have much room for performance improvement due to the hand-crafted and unlearnable pairwise features. To upgrade performance while maintaining scalability, we propose Neural Common Neighbor (NCN), which uses learnable pairwise representations. To further boost NCN, we study the unobserved link problem. The incompleteness of the graph is ubiquitous and leads to distribution shifts between
    
[^32]: 使用查询来检测随机子图

    Random Subgraph Detection Using Queries. (arXiv:2110.00744v4 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2110.00744](http://arxiv.org/abs/2110.00744)

    本文研究了使用自适应查询来检测种植子图存在，确定了必要和充分的查询数量。

    

    种植的最密子图检测问题是指测试在给定的（随机）图中是否存在一个异常密集的子图。在本文中，我们考虑了一种自然的变体，即只能使用自适应边查询来观察图的一小部分。在这个模型下，我们确定了检测种植子图存在所需的查询数量。具体地，我们展示了任何（可能是随机化的）算法必须进行 $\mathsf{Q} = \Omega(\frac{n^2}{k^2\chi^4(p||q)}\log^2n)$ 个查询。

    The planted densest subgraph detection problem refers to the task of testing whether in a given (random) graph there is a subgraph that is unusually dense. Specifically, we observe an undirected and unweighted graph on $n$ nodes. Under the null hypothesis, the graph is a realization of an Erd\H{o}s-R\'{e}nyi graph with edge probability (or, density) $q$. Under the alternative, there is a subgraph on $k$ vertices with edge probability $p>q$. The statistical as well as the computational barriers of this problem are well-understood for a wide range of the edge parameters $p$ and $q$. In this paper, we consider a natural variant of the above problem, where one can only observe a small part of the graph using adaptive edge queries.  For this model, we determine the number of queries necessary and sufficient for detecting the presence of the planted subgraph. Specifically, we show that any (possibly randomized) algorithm must make $\mathsf{Q} = \Omega(\frac{n^2}{k^2\chi^4(p||q)}\log^2n)$ ada
    

