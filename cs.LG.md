# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prodigy: An Expeditiously Adaptive Parameter-Free Learner.](http://arxiv.org/abs/2306.06101) | 本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。 |
| [^2] | [NuCLR: Nuclear Co-Learned Representations.](http://arxiv.org/abs/2306.06099) | NuCLR是一种可以预测各种核可观测量，包括结合能、衰变能和核电荷半径的深度学习模型，使用共享表示法进行训练，具有最先进的性能，可以捕捉到核物理的基础物理原理，并有潜力为核理论提供有价值的见解。 |
| [^3] | [Error Feedback Can Accurately Compress Preconditioners.](http://arxiv.org/abs/2306.06098) | 本论文提出一种错误反馈技术，可以通过在馈入预处理器之前对梯度信息进行压缩（稀疏化或低秩压缩），将预处理器的存储成本压缩多达两个数量级，而不会丢失收敛性。 |
| [^4] | [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding.](http://arxiv.org/abs/2306.06094) | 本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。 |
| [^5] | [SENS: Sketch-based Implicit Neural Shape Modeling.](http://arxiv.org/abs/2306.06088) | SENS是一种基于草图的生成和编辑3D模型的新方法，该方法通过ViT补丁编码将草图映射到神经隐式形状架构的潜空间中，可以捕捉用户草图的意图进行生成，具有强大的性能和直观的基于草图的形状编辑功能。 |
| [^6] | [Learning Not to Spoof.](http://arxiv.org/abs/2306.06087) | 该论文提出了学习不进行欺骗的方法，并考虑了智能股票交易代理的欺诈行为识别和避免。 |
| [^7] | [Machine Vision Using Cellphone Camera: A Comparison of deep networks for classifying three challenging denominations of Indian Coins.](http://arxiv.org/abs/2306.06084) | 本研究利用手机相机拍摄印度硬币的数字图像，训练深度神经网络模型，成功实现了从硬币两侧准确判断硬币面额的功能，准确率达到97％。 |
| [^8] | [Improving Fairness and Robustness in End-to-End Speech Recognition through unsupervised clustering.](http://arxiv.org/abs/2306.06083) | 该论文提出了一种隐私保护的方法，通过无监督聚类提高端到端语音识别中的公平性和鲁棒性，并可以对所有人口统计学方面都有提高的效果。 |
| [^9] | [Augmentation-aware Self-supervised Learning with Guided Projector.](http://arxiv.org/abs/2306.06082) | 本文提出了一种名为CASSLE的方法，它通过修改自监督学习中的有向投影网络，利用增强信息来提高模型处理图像特征的鲁棒性。 |
| [^10] | [CARSO: Counter-Adversarial Recall of Synthetic Observations.](http://arxiv.org/abs/2306.06081) | 本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。 |
| [^11] | [Detection of Late Blight Disease in Tomato Leaf Using Image Processing Techniques.](http://arxiv.org/abs/2306.06080) | 本研究利用图像分割和多类支持向量机技术，对受晚疫病影响的番茄叶进行检测。利用图像分割技术，将受损区域分离出来，通过多类支持向量机算法来对疾病进行可靠的分类。 |
| [^12] | [Deep Learning for Day Forecasts from Sparse Observations.](http://arxiv.org/abs/2306.06079) | 本文提出了一种基于稀疏观测数据的MetNet-3深度学习模型，可对20小时内的天气进行准确的预测。MetNet-3的技术创新包括可学习卷积、特征学习和多任务训练优化。此外，使用持续性启发法来外推初始条件或进行短期预测来填补缺失的观测数据更进一步提高了预测性能。 |
| [^13] | [Cheating off your neighbors: Improving activity recognition through corroboration.](http://arxiv.org/abs/2306.06078) | 该论文提出了一种通过观察周围人来提高个人活动预测准确性的方法。 |
| [^14] | [Differentially Private Image Classification by Learning Priors from Random Processes.](http://arxiv.org/abs/2306.06076) | 本文提出了一种名为DP-RandP的方法，从随机过程中学习先验知识，并将其传递给私有数据，以改进差分隐私的图像分类，实现了新的最先进的结果，提高了CIFAR-10的精度。 |
| [^15] | [DeepSeaNet: Improving Underwater Object Detection using EfficientDet.](http://arxiv.org/abs/2306.06075) | 本文研究了在水下环境下，使用EfficientDet等模型提高水下物体检测的效率，并通过对比多个模型的精度和推理时间，发现效率更高的模型可以更好地应对水下物体检测的挑战。 |
| [^16] | [Feature Selection on Sentinel-2 Multi-spectral Imagery for Efficient Tree Cover Estimation.](http://arxiv.org/abs/2306.06073) | 本文提出了一种使用光谱指数过滤掉建筑区域并对特征进行精选的多光谱随机森林分类器，用于城市地区绿地覆盖率的估计，在LUMS的82 英亩指定区域测试中表现优于传统方法和最先进的方法。 |
| [^17] | [Adversarial Attack On Yolov5 For Traffic And Road Sign Detection.](http://arxiv.org/abs/2306.06071) | 本文研究了YOLOv5在交通和道路标志检测中的对抗攻击脆弱性，发现YOLOv5易受多种攻击的影响，有 important implications for the safety and reliability of object detection algorithms used in traffic. |
| [^18] | [DeepStay: Stay Region Extraction from Location Trajectories using Weak Supervision.](http://arxiv.org/abs/2306.06068) | DeepStay是一个基于弱监督和自监督的变压器模型，用于从位置轨迹中预测停留区域并提取个人兴趣点（POIs）而无需个人信息或其他数据。它是第一个在公共标记数据集上进行评估并优于最先进方法的深度学习方法。 |
| [^19] | [Multi-level Cross-modal Feature Alignment via Contrastive Learning towards Zero-shot Classification of Remote Sensing Image Scenes.](http://arxiv.org/abs/2306.06066) | 提出了一种基于对比学习的多级交叉模态特征对齐方法，用于零样本分类，能够有效应对大类内差异和小类间相似性的挑战。 |
| [^20] | [Neural Algorithmic Reasoning for Combinatorial Optimisation.](http://arxiv.org/abs/2306.06064) | 本文提出了一种用于组合优化问题的神经算法推理方法，旨在解决旅行商问题。该方法是通过在TSP实例训练之前，将神经模型用相关算法进行预训练来实现的。实验结果表明，该方法可以显著提高TSP问题的解决效率。 |
| [^21] | [Virtual Node Tuning for Few-shot Node Classification.](http://arxiv.org/abs/2306.06063) | 我们提出了一种虚拟节点调整方法VNT来解决图表示学习中少样本节点分类的挑战。VNT利用预训练的图变换器编码器和嵌入空间中注入虚拟节点，并通过元学习优化虚拟节点以调节每个FSNC任务的节点嵌入。该方法在处理基类别中有稀疏标签的情况下有优势。 |
| [^22] | [Neural FIM for learning Fisher Information Metrics from point cloud data.](http://arxiv.org/abs/2306.06062) | 本文提出了神经FIM，一种从点云数据中计算Fisher信息度量（FIM）的方法，可以连续地对数据进行流形建模，从而提高流形特征的描述能力。 |
| [^23] | [clustering an african hairstyle dataset using pca and k-means.](http://arxiv.org/abs/2306.06061) | 本文提出了一种使用K-means进行非洲女性图像分类的方法，以便识别不同的面部群集和发型。 |
| [^24] | [How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?.](http://arxiv.org/abs/2306.06048) | 本研究旨在探究微调对少样本下游任务的外分布检测的影响，发现适当选择外分布分数对于CLIP-based 微调至关重要。最大概念匹配（MCM）分数提供了一个有前途的解决方案。 |
| [^25] | [A Dynamical Graph Prior for Relational Inference.](http://arxiv.org/abs/2306.06041) | DYGR是一种用于关系推断的动态图先验方法，它利用高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度，并能够同时适用于具有共享图拓扑的“浅层”一步模型。 |
| [^26] | [Reconstructing Human Expressiveness in Piano Performances with a Transformer Network.](http://arxiv.org/abs/2306.06040) | 本文提出了一种利用Transformer网络来重建钢琴演奏中人类表现力的方法，使用转录乐谱来训练模型，整合钢琴家身份以控制采样过程，并成功生成了高度类人的钢琴表演。 |
| [^27] | [RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows.](http://arxiv.org/abs/2306.06034) | 本研究提出了RANS-PINN模型，通过引入2方程涡粘度模型，可预测高雷诺数湍流流动中的流场，从而提高流体动力学模拟计算效率。 |
| [^28] | [FinGPT: Open-Source Financial Large Language Models.](http://arxiv.org/abs/2306.06031) | FinGPT是一个开源的金融大型语言模型，提供了可访问和透明的资源来开发金融LLMs，其重要性在于自动数据筛选管道和轻量级低秩适应技术。 |
| [^29] | [Self-Interpretable Time Series Prediction with Counterfactual Explanations.](http://arxiv.org/abs/2306.06024) | 本文提出了一种自我解释的时间序列预测模型CounTS，该模型可以生成反事实和可操作的解释，适用于关键领域如医疗和自动驾驶等。与现有方法不同，该模型为可解释性建模做出了贡献。 |
| [^30] | [Distributed Consensus Algorithm for Decision-Making in Multi-agent Multi-armed Bandit.](http://arxiv.org/abs/2306.05998) | 本文提出了一种在动态环境中处理多智能体多臂老虎机问题的分布式共识算法，该算法能够最小化每个时间步不选择最优臂所产生的期望总损失。 |
| [^31] | [Approximate information state based convergence analysis of recurrent Q-learning.](http://arxiv.org/abs/2306.05991) | 本文研究了循环Q-learning在部分可观测环境下的收敛性，并提出了一种使用近似信息状态的变体算法，该算法在表现上优于强基线。 |
| [^32] | [Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection.](http://arxiv.org/abs/2306.05989) | 本文提出了一种名为QBSD的实时预测方法，以在时间序列异常检测中取得最佳平衡。 |
| [^33] | [Agent market orders representation through a contrastive learning approach.](http://arxiv.org/abs/2306.05987) | 通过对比学习方法，本研究构建了一个自监督学习模型，用于学习代理市场订单的表示。进一步地，我们使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。 |
| [^34] | [Automating Model Comparison in Factor Graphs.](http://arxiv.org/abs/2306.05965) | 本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。 |
| [^35] | [DDLP: Unsupervised Object-Centric Video Prediction with Deep Dynamic Latent Particles.](http://arxiv.org/abs/2306.05957) | DDLP算法使用深度潜在粒子(DLP)表示法实现无监督物体中心视频预测，并取得了最先进的预测结果。算法的可解释性使得可以进行“假设”生成，而DLP的紧凑结构使得效率高并可以进行基于扩散的无条件视频生成。 |
| [^36] | [Path Neural Networks: Expressive and Accurate Graph Neural Networks.](http://arxiv.org/abs/2306.05955) | 本文提出了路径神经网络模型，该模型通过聚合从节点出发的路径来更新节点表示，相比标准图神经网络具有更强的表达能力，能够区分一些1-WL无法区分的非同构图对。 |
| [^37] | [Overcoming Adversarial Attacks for Human-in-the-Loop Applications.](http://arxiv.org/abs/2306.05952) | 通过人类视觉注意力模型改善人机图像分析系统的可解释性和鲁棒性，克服针对人机交互应用的对抗攻击。 |
| [^38] | [Prediction of Transportation Index for Urban Patterns in Small and Medium-sized Indian Cities using Hybrid RidgeGAN Model.](http://arxiv.org/abs/2306.05951) | 本研究提出了一种基于混合RidgeGAN模型的交通指数预测方法，用于解决城市化带来的交通问题。实验结果显示，该方法在预测精度上显著优于传统回归模型。 |
| [^39] | [Robust Data-driven Prescriptiveness Optimization.](http://arxiv.org/abs/2306.05937) | 本文提出了一种鲁棒的数据驱动优化模型，其中处方性系数代替了经验风险最小化目标，可用于确定最大化上下文决策质量和参考决策以及侧面信息处方能力的最佳策略。 |
| [^40] | [Speaker Embeddings as Individuality Proxy for Voice Stress Detection.](http://arxiv.org/abs/2306.05915) | 该论文使用来自不同语言组、背景各异的一百多名说话者训练了一种语音应激检测的方法，并在混合特征中添加个体差异性识别技术，成功地提高了检测性能。 |
| [^41] | [2DeteCT -- A large 2D expandable, trainable, experimental Computed Tomography dataset for machine learning.](http://arxiv.org/abs/2306.05907) | 该论文提供了一个大型、可扩展的二维计算机断层扫描数据集，用于开发各种图像重建任务的机器学习技术，填补了当前X射线计算机断层扫描数据集匮乏的现状。 |
| [^42] | [TreeDQN: Learning to minimize Branch-and-Bound tree.](http://arxiv.org/abs/2306.05905) | TreeDQN提出了一种强化学习方法，可以学习到更加效率的分支启发式算法，减少了训练数据，并产生更小的子任务树。 |
| [^43] | [C(NN)FD -- a deep learning framework for turbomachinery CFD analysis.](http://arxiv.org/abs/2306.05889) | 本文介绍了一种新型深度学习框架C(NN)FD，用于实时预测燃气轮机中轴向压缩机制造和组装变化对整体性能的影响。该框架可过滤掉CFD解决方案中的相关部分，因此具有可扩展性，且实时精度可与CFD基准相媲美。 |
| [^44] | [Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations.](http://arxiv.org/abs/2306.05880) | 该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。 |
| [^45] | [Is Normalization Indispensable for Multi-domain Federated Learning?.](http://arxiv.org/abs/2306.05879) | 本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。 |
| [^46] | [Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions.](http://arxiv.org/abs/2306.05873) | 该论文提出了一种检测非鲁棒方向的新方法，通过局域二次逼近来检测对抗性攻击，并为安全观测和对抗性观测之间的基本截止提供了理论基础。并且该方法是非常有效的，能成功检测到对抗性方向并做出鲁棒决策。 |
| [^47] | [Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case.](http://arxiv.org/abs/2306.05865) | 本文提出了利用预测方法加速M-凸函数极小化的框架，特别适用于分层凸极小化等离散优化问题，并且能够较好地改善时间复杂度。 |
| [^48] | [Federated Learning You May Communicate Less Often!.](http://arxiv.org/abs/2306.05862) | 本研究针对联邦学习设定，探讨了通信次数对泛化误差的影响，并建立了PAC-Bayes和率失真理论限制，这些限制对广泛的损失函数和学习算法适用。 |
| [^49] | [Robust Reinforcement Learning via Adversarial Kernel Approximation.](http://arxiv.org/abs/2306.05859) | 该论文提出了一种新奇的在线鲁棒强化学习方法，它通过近似对抗核并使用标准非鲁棒强化学习算法学习鲁棒策略，可应用于任何基础的强化学习算法之上，可以轻松扩展到高维度域。 |
| [^50] | [How Sparse Can We Prune A Deep Network: A Geometric Viewpoint.](http://arxiv.org/abs/2306.05857) | 本文从高维几何的角度，通过在原始损失函数中强制施加稀疏性约束，描述了深度网络剪枝比率的相变点，该点等于某些凸体的平方高斯宽度除以参数的原始维度。 |
| [^51] | [How Object Information Improves Skeleton-based Human Action Recognition in Assembly Tasks.](http://arxiv.org/abs/2306.05844) | 本研究提出了一种将物体信息融入基于骨架的人类行为识别的新方法，以此来提高协作机器人在工业制造中的人机协作的效率。 |
| [^52] | [Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature.](http://arxiv.org/abs/2306.05843) | 本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。 |
| [^53] | [Expectation-Complete Graph Representations with Homomorphisms.](http://arxiv.org/abs/2306.05838) | 提出了一种基于同态映射的新型随机图嵌入方法，在期望的多项式时间内计算，能在期望中区分所有非同构图，具有高效的替代能力。 |
| [^54] | [Can Large Language Models Infer Causation from Correlation?.](http://arxiv.org/abs/2306.05836) | 本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。 |
| [^55] | [Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms.](http://arxiv.org/abs/2306.05815) | 本文提出了一种对偶化扩展的核主成分分析方法，使KPCA自然地扩展到多目标函数，并导致避免计算格拉姆矩阵的昂贵SVD的高效梯度算法。该方法还能在同一框架内促进稳健性和稀疏性。 |
| [^56] | [Incorporating Prior Knowledge in Deep Learning Models via Pathway Activity Autoencoders.](http://arxiv.org/abs/2306.05813) | 本研究提出了一种基于先验知识的深度自编码框架PAAE，将生物通路信息融入深度学习模型，可提高对疾病的预测建模和个性化治疗策略。 |
| [^57] | [HRTF upsampling with a generative adversarial network using a gnomonic equiangular projection.](http://arxiv.org/abs/2306.05812) | 本文利用生成对抗网络（GANs）将HRTF上采样，提出一种新方法，该方法在性能方面优于传统方法，使带HRTF的虚拟现实（VR）和增强现实（AR）环境更加逼真。 |
| [^58] | [Explaining Reinforcement Learning with Shapley Values.](http://arxiv.org/abs/2306.05810) | 该论文提出了一种使用Shapley值进行强化学习解释的方法，称之为Shapley Values for Explaining Reinforcement Learning (SVERL)，在实验中证明具有匹配并补充人类直觉的有意义解释效果。 |
| [^59] | [RankFormer: Listwise Learning-to-Rank Using Listwide Labels.](http://arxiv.org/abs/2306.05808) | RankFormer是一个可以利用列表标签进行列表学习排序的架构，并在多个最先进的LTR方法上展现了更好的表现。 |
| [^60] | [DynaBench: A benchmark dataset for learning dynamical systems from low-resolution data.](http://arxiv.org/abs/2306.05805) | DynaBench是一个新的模拟基准数据集，用于直接从低分辨率的稀疏数据中学习动力系统，评估了多个机器学习模型的预测性能。 |
| [^61] | [Causality between Sentiment and Cryptocurrency Prices.](http://arxiv.org/abs/2306.05803) | 本研究通过将主题建模和情感分析相结合，建立了关于加密货币的多个叙述，并发现这些叙述与加密货币价格之间存在强大的联系。 |
| [^62] | [Two-level histograms for dealing with outliers and heavy tail distributions.](http://arxiv.org/abs/2306.05786) | 本文介绍G-Enum直方图方法，它利用MDL原则构建直方图，在非常准确的情况下,无需任何用户参数，并在异常值或重尾分布情况下提出一种双层启发式方法 |
| [^63] | [End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$ Regularized Latency Surrogates.](http://arxiv.org/abs/2306.05785) | 提出了一种端到端的神经网络压缩技术，通过优化模型的浮点运算量或设备延迟来自动设置压缩超参数。算法速度快，并且可以与多种常用压缩方法一起使用，如剪枝、低秩分解和量化。在GLUE微调任务的BERT压缩中，FLOPs可降低50％，且性能仅下降1％；而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。 |
| [^64] | [Quantitative Ink Analysis: Estimating the Number of Inks in Documents through Hyperspectral Imaging.](http://arxiv.org/abs/2306.05784) | 本文提出了一种使用高光谱成像的墨水分析技术，可以有效地识别墨水聚类和区分不同的墨水，以此来确定文档中使用的不同墨水的数量。 |
| [^65] | [Adaptivity Complexity for Causal Graph Discovery.](http://arxiv.org/abs/2306.05781) | 研究了因果图发现的适应性复杂度，提供了一个r-adaptive算法在最小化总干预次数的同时正确学习出因果图。 |
| [^66] | [Transformer-based Time-to-Event Prediction for Chronic Kidney Disease Deterioration.](http://arxiv.org/abs/2306.05779) | 本论文提出了基于Transformer的STRAFE模型，用于慢性肾脏疾病恶化时间的生存分析预测，并在真实数据集上进行了验证，表明其在预测特定事件的确切时间方面具有较好性能。 |
| [^67] | [Weight Re-Mapping for Variational Quantum Algorithms.](http://arxiv.org/abs/2306.05776) | 我们使用权重重新映射的方法来改进变分量子电路(VQC)的训练，以解决当前的基于梯度的VQC训练方法无法充分考虑量子计算中可训练参数(或权重)的问题。在我们的研究中，我们使用了七种不同的权重重新映射函数来评估它们的实现效果。 |
| [^68] | [Weight Freezing: A Regularization Approach for Fully Connected Layers with an Application in EEG Classification.](http://arxiv.org/abs/2306.05775) | 本文提出了一种新颖的方法，权重冻结，它可以有效地减少全连接层中的特定神经元对特定EEG任务的决策过程的影响，从而提高人工神经网络（ANNs）的性能，是一种有效的正则化方法。 |
| [^69] | [Self-Paced Absolute Learning Progress as a Regularized Approach to Curriculum Learning.](http://arxiv.org/abs/2306.05769) | 自定进度绝对学习作为课程学习的规则方法，通过引入基于自定进度（深度）学习的新正则化方法，称为自定进度绝对学习进展（SPALP），解决了绝对学习进展（ALP）在重复已学习的行为上浪费计算资源的问题。 |
| [^70] | [Fair yet Asymptotically Equal Collaborative Learning.](http://arxiv.org/abs/2306.05764) | 本文探讨了一种公平的协作学习激励设计，避免了“富者越富”的现象，并为较少资源的节点提供了长期平等的机会。 |
| [^71] | [Advancing Counterfactual Inference through Quantile Regression.](http://arxiv.org/abs/2306.05751) | 本文提出一种基于分位数回归的反事实推断方法，旨在用于缺乏因果模型和直接条件分布估计的情况，并能提供估计结果的泛化能力和泛化误差上界。 |
| [^72] | [An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling Problems Based on Constraint Programming.](http://arxiv.org/abs/2306.05747) | 本文提出了一种新颖的基于约束编程和强化学习的端到端方法，通过通用CP编码、约束条件和反映JSSP最优标准的奖励函数，可为大型作业车间调度问题产生最优或近似最优解。 |
| [^73] | [Two Independent Teachers are Better Role Model.](http://arxiv.org/abs/2306.05745) | 提出了一种名为3D-DenseUNet的新深度学习模型，该模型采用自适应全局聚合块和自注意模块，以解决半监督技术中的效率和效果问题，同时通过训练两个独立的训练器处理不同的组织特性，在婴儿脑部分析中取得更好的结果。 |
| [^74] | [Leaping through tree space: continuous phylogenetic inference for rooted and unrooted trees.](http://arxiv.org/abs/2306.05739) | 本研究首次在连续空间中进行树形系统探索和推断，用于有根和无根树，优于当前最佳方法并在实验中证明了其效果，可用于加速生命科学的新进化发现。 |
| [^75] | [DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework.](http://arxiv.org/abs/2306.05734) | DP-HyPO 是一种自适应的、隐私保护的超参数优化框架，采用最先进的差分隐私高斯过程方法，提出了量身定制的优化启发式方法，保证隐私和效率，在保持强大隐私保证的同时实现了与非私有自适应优化方法相当的性能。 |
| [^76] | [The Role of Diverse Replay for Generalisation in Reinforcement Learning.](http://arxiv.org/abs/2306.05727) | 本文研究了在多任务强化学习中，增加重放缓存中数据过渡的多样性可以提高零-shot泛化性能，并且可能通过提高潜在表示的泛化性能来实现这种改善。 |
| [^77] | [In-Sample Policy Iteration for Offline Reinforcement Learning.](http://arxiv.org/abs/2306.05726) | 本文提出了一种采用样本内策略迭代的算法来增强离线强化学习中的行为规则方法，在实验中取得了显著的改进。 |
| [^78] | [Explaining Predictive Uncertainty with Information Theoretic Shapley Values.](http://arxiv.org/abs/2306.05724) | 本文提出了一种新的方法，通过Shapley值解释不确定性预测，可以量化每个特征对个别模型输出条件熵的贡献，适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。 |
| [^79] | [Estimation of Ridge Using Nonlinear Transformation on Density Function.](http://arxiv.org/abs/2306.05722) | 本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。 |
| [^80] | [Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model.](http://arxiv.org/abs/2306.05720) | 本文探究了潜在扩散模型内部是否创建和使用简单场景几何内部表示，使用线性探针发现LDM内部激活提供了关于3D深度数据和突出对象/背景分离的线性表示，在图像合成中具有因果作用, 可用于LDM输出的简单高级编辑。 |
| [^81] | [Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion.](http://arxiv.org/abs/2306.05708) | 本文提出了一种基于线性扩散模型的语音合成方法，能够同时实现快速推理和高样本质量 |
| [^82] | [Understanding How Consistency Works in Federated Learning via Stage-wise Relaxed Initialization.](http://arxiv.org/abs/2306.05706) | 本文提出了一种高效的联邦学习算法 FedInit，通过阶段性放松初始化来缓解“客户机漂移”问题，从而增强本地一致性，同时提出了一个理论框架解释本地不一致性的行为，并强调了初始化过程在优化联邦学习模型中的重要性。 |
| [^83] | [Finite-Time Analysis of Minimax Q-Learning for Two-Player Zero-Sum Markov Games: Switching System Approach.](http://arxiv.org/abs/2306.05700) | 本文研究了Q-learning算法应用于两人零和Markov博弈的有限时间分析，并通过切换系统方法提供了更简单和深入的收敛分析。 |
| [^84] | [JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its Application to Malicious Website Detection.](http://arxiv.org/abs/2306.05698) | 本文提出了一个名为JABBERWOCK的工具，用于通过JavaScript收集并生成WebAssembly数据集，以用于恶意网站检测，并证明其能够在4.5秒内生成一个数据集。 |
| [^85] | [Group Equivariant Fourier Neural Operators for Partial Differential Equations.](http://arxiv.org/abs/2306.05697) | 本文扩展了群卷积到频率域，并设计了具有旋转、平移和镜像等变性质的傅里叶层的G-FNO架构，该架构在不同对称性水平的设置中表现良好。 |
| [^86] | [Explainable Representation Learning of Small Quantum States.](http://arxiv.org/abs/2306.05694) | 该论文探讨了一种无监督机器学习模型在小量子态上的可解释表示学习方法，得到了一个与潜在结构相联系的可理解表示。 |
| [^87] | [Lightweight Monocular Depth Estimation via Token-Sharing Transformer.](http://arxiv.org/abs/2306.05682) | 本文提出了一种使用Transformer和全局令牌共享的轻量级单目深度估计方法，针对嵌入式设备进行了优化。 |
| [^88] | [Emotion Detection from EEG using Transfer Learning.](http://arxiv.org/abs/2306.05680) | 本研究采用迁移学习的方法，通过将MPC、MSC以及DE结合到图像矩阵中，提高了基于EEG的情绪检测的准确性。本研究为脑机接口和康复医学提供了有价值的信息。 |
| [^89] | [Efficient Uncertainty Quantification and Reduction for Over-Parameterized Neural Networks.](http://arxiv.org/abs/2306.05674) | 本论文基于神经切向核理论，提出了一种高效的方法以减少超参数化神经网络中的过程不确定性，并只需要使用一种辅助网络就可以消除这种不确定性。 |
| [^90] | [QuestEnvSim: Environment-Aware Simulated Motion Tracking from Sparse Sensors.](http://arxiv.org/abs/2306.05666) | 本研究利用物理模拟和环境感知相结合的方法，在高度约束的环境中，能够生成逼真的全身姿势，实现了高质量的交互动作。 |
| [^91] | [Communication-Efficient Zeroth-Order Distributed Online Optimization: Algorithm, Theory, and Applications.](http://arxiv.org/abs/2306.05655) | 本文提出了一种针对目标跟踪的分布式在线优化算法，并利用基于误差反馈的压缩方案来解决代理的通信限制问题。 |
| [^92] | [Differentially Private Sharpness-Aware Training.](http://arxiv.org/abs/2306.05651) | 本文提出了一种能够缓解隐私-优化制约关系的锐化感知训练方法。 |
| [^93] | [Specifying and Solving Robust Empirical Risk Minimization Problems Using CVXPY.](http://arxiv.org/abs/2306.05649) | 本文介绍了如何使用CVXPY以用户友好的方式自动化鲁棒经验风险最小化问题的对偶化过程，使得用户可以方便地解决各种回归和分类问题。 |
| [^94] | [Revisiting Permutation Symmetry for Merging Models between Different Datasets.](http://arxiv.org/abs/2306.05641) | 本研究通过理论和实证分析表明，不同数据集合并模型的准确性下降更为显著，因为每个数据集的不同损失函数使得合并更加困难。此外，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。 |
| [^95] | [On the Importance of Feature Decorrelation for Unsupervised Representation Learning in Reinforcement Learning.](http://arxiv.org/abs/2306.05637) | 本研究提出了一种新的URL框架，通过去相关潜空间中的特征来因果性地预测未来状态并增加潜空间的维度，从而有效地学习预测表示而不会崩溃，显着提高了基于Atari 100k基准的最新URL方法的样本效率。 |
| [^96] | [Quantifying the Knowledge in GNNs for Reliable Distillation into MLPs.](http://arxiv.org/abs/2306.05628) | 该论文提出了一种基于知识可靠性量化的方法，并通过采样一组额外的可靠知识点，实现了GNN向MLP的可靠蒸馏，从而提高了蒸馏效率和效果。 |
| [^97] | [Improving Quantum Circuit Synthesis with Machine Learning.](http://arxiv.org/abs/2306.05622) | 本论文提出了一种名为 QSeed 的种子合成算法，应用机器学习显著加速合成算法，针对核心量子算法组件，如 Shor 因式分解算法中的 64 比特模幂电路，QSeed 能在保持低门计数的同时将合成时间加速 $3.7\times$。 |
| [^98] | [Evaluating and Incentivizing Diverse Data Contributions in Collaborative Learning.](http://arxiv.org/abs/2306.05592) | 本研究针对合作学习中数据多样性与代表性的问题，设计了一种博弈机制以鼓励数据贡献者提供代表全局人口的数据。 |
| [^99] | [MC-NN: An End-to-End Multi-Channel Neural Network Approach for Predicting Influenza A Virus Hosts and Antigenic Types.](http://arxiv.org/abs/2306.05587) | 提出了一种利用多通道神经网络模型预测流感A病毒宿主和抗原亚型的方法，数据显示多通道神经网络模型具有较高的准确性和预测能力。 |
| [^100] | [Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation.](http://arxiv.org/abs/2306.05584) | 本文提出了一种基于SE（3）等变结构和非监督训练策略的方法，可以实现刚性分割和运动估计，不需要类别信息且具有极高的模型效率。 |
| [^101] | [SGLD-Based Information Criteria and the Over-Parameterized Regime.](http://arxiv.org/abs/2306.05583) | 本研究提出针对超参数化学习算法的SGLD信息准则，通过KL信息和KL散度罚项来追踪双下降现象。 |
| [^102] | [Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with Heterogeneous Rewards.](http://arxiv.org/abs/2306.05579) | 本文提出了一种处理多智能体多臂赌博机问题的算法框架，通过稳健模拟生成随机图并将加权技术结合UCB算法，以协作方式减小整个系统的总遗憾。 |
| [^103] | [Intelligent Energy Management with IoT Framework in Smart Cities Using Intelligent Analysis: An Application of Machine Learning Methods for Complex Networks and Systems.](http://arxiv.org/abs/2306.05567) | 本研究开发了一个智能城市能源管理的物联网框架，结合智能分析和多组件的架构，研究了基于智能机制的智能能源管理解决方案，以期节能和优化管理。 |
| [^104] | [Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations.](http://arxiv.org/abs/2306.05566) | 本文提出了一种数据自适应的贝叶斯滤波范式来解决现有概率ODE求解器无法解决的深层的局部最小值问题，结果表明该方法比现有概率ODE求解器更精确。 |
| [^105] | [On Performance Discrepancies Across Local Homophily Levels in Graph Neural Networks.](http://arxiv.org/abs/2306.05557) | 本文研究了GNN在测试时节点的本地同质性水平与其图的全局同质性水平偏离时的性能，并介绍一种新参数用于控制同质性，在生成的图中系统地研究本地同质性的影响。 |
| [^106] | [Emotion and Sentiment Guided Paraphrasing.](http://arxiv.org/abs/2306.05556) | 本研究提出了一种情感和情绪引导的改写框架，实现了细粒度的情感调节，可用于多种场景，通过添加细粒度情感标签可以提高结果质量。 |
| [^107] | [Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.05554) | 本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。 |
| [^108] | [Equivariant vs. Invariant Layers: A Comparison of Backbone and Pooling for Point Cloud Classification.](http://arxiv.org/abs/2306.05553) | 本文研究了置换等变骨干和置换不变全局池化在点云分类中的相互作用，揭示了使用复杂池化方法可以显著提高简单骨干的性能，但即使是复杂的骨干也可以受益于更复杂的、明确编码置换不变性的池化方法，使用置换不变池化是获得最先进结果的关键。 |
| [^109] | [Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks.](http://arxiv.org/abs/2306.05550) | 本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。 |
| [^110] | [AI Enhanced Control Engineering Methods.](http://arxiv.org/abs/2306.05545) | 本文讨论了利用AI工具进行控制工程的方法。其中，自动微分是核心工具之一，可用于局部稳定性分析和状态估计等方面。此外，还探讨了将微分代数方程转换为常微分方程进行控制设计以及利用机器学习模型进行全局参数化等应用。 |
| [^111] | [BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping.](http://arxiv.org/abs/2306.05544) | 本文提出了一种名为BOOT的技术，它使用有效的无数据蒸馏算法来训练一个时间条件模型，以预测预训练的差分扩散模型老师的输出。我们的方法可以适用于不同的扩散模型，同时实现了显著的推理时间加速。 |
| [^112] | [Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data.](http://arxiv.org/abs/2306.05535) | 政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。 |
| [^113] | [A brief review of contrastive learning applied to astrophysics.](http://arxiv.org/abs/2306.05528) | 对比学习是一种自监督机器学习算法，用于从多维数据集中提取信息度量。它可以消除已知的仪器效应，并使用有限的标签执行监督分类和回归，展示了面向“基础模型”的良好发展前景。 |
| [^114] | [PeFLL: A Lifelong Learning Approach to Personalized Federated Learning.](http://arxiv.org/abs/2306.05515) | PeFLL是个性化联邦学习的一种新方法，通过联合训练嵌入网络和超网络，PeFLL能够学习输出特定于每个客户端的模型，并且在其它新出现的客户端上表现良好。 |
| [^115] | [Robust Brain Age Estimation via Regression Models and MRI-derived Features.](http://arxiv.org/abs/2306.05514) | 本文提出了一个基于MRI特征和回归模型的健康大脑年龄鲁棒估计框架，可用于评估神经系统疾病和了解衰老期间形态学变化，平均绝对误差为3.02岁，相关系数为0.96，且具有高度的鲁棒性。 |
| [^116] | [AMEE: A Robust Framework for Explanation Evaluation in Time Series Classification.](http://arxiv.org/abs/2306.05501) | AMEE是一个模型无关的解释评价框架，用于量化和比较时间序列分类中多种基于显著性的解释方法的信息价值，帮助解决在这一领域中解释方法选择的难题。 |
| [^117] | [Word-Level Explanations for Analyzing Bias in Text-to-Image Models.](http://arxiv.org/abs/2306.05500) | 本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。 |
| [^118] | [Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models.](http://arxiv.org/abs/2306.05497) | 本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。 |
| [^119] | [Is Attentional Channel Processing Design Required? Comprehensive Analysis Of Robustness Between Vision Transformers And Fully Attentional Networks.](http://arxiv.org/abs/2306.05495) | 本研究比较了传统视觉变换器和全自注意力网络模型的鲁棒性，研究发现注意通道处理设计对于提高模型的鲁棒性很重要。 |
| [^120] | [Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning.](http://arxiv.org/abs/2306.05494) | 本文对于基于机器学习的网络入侵检测系统(NIDS)的对抗性攻击进行了分类，同时探究了持续再训练对NIDS对抗性攻击的影响。实验表明，即使没有对抗性训练，持续再训练也可以减少对抗性攻击的影响。 |
| [^121] | [Multi-Modal Classifiers for Open-Vocabulary Object Detection.](http://arxiv.org/abs/2306.05493) | 本文提出了一种开放词汇物体检测的多模态分类器，能够在推断过程中检测超出训练范畴的目标，并优于传统基线模型。 |
| [^122] | [Boosting with Tempered Exponential Measures.](http://arxiv.org/abs/2306.05487) | 本文提出了一种以温度指数测度为基础的机器学习算法——$t$-AdaBoost，并证明其在$t\in [0,1)$时可以保持AdaBoost的指数收敛速率，同时具有更好的性能表现。 |
| [^123] | [Task-specific experimental design for treatment effect estimation.](http://arxiv.org/abs/2306.05484) | 本文提出了一种任务特定的实验设计方法，可用于治疗效果评估，并在真实世界数据集和样本量上优于其他基准方法，例如在定向营销任务上需要更少的数据来达到与RCT相同的性能。 |
| [^124] | [On the Importance of Exploration for Generalization in Reinforcement Learning.](http://arxiv.org/abs/2306.05483) | 本论文研究了勘探在强化学习中的重要性，提出了一种名为EDE的基于值的算法，它是第一个在Procgen和Crafter等环境中取得最先进结果的方法，具有实用价值。 |
| [^125] | [Trajectory Prediction with Observations of Variable-Length for Motion Planning in Highway Merging scenarios.](http://arxiv.org/abs/2306.05478) | 本文提出一种基于Transformer的轨迹预测方法，可以处理任何长度的观察，并实现了在高速公路合并情境中的准确预测。 |
| [^126] | [Latent Phrase Matching for Dysarthric Speech.](http://arxiv.org/abs/2306.05446) | 患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。 |
| [^127] | [Towards Predicting Equilibrium Distributions for Molecular Systems with Deep Learning.](http://arxiv.org/abs/2306.05445) | 本文提出了一种新的深度学习框架DiG，通过对分子系统进行描述符的条件，能够预测分子系统的平衡分布，从而提供高效生成多样构型和状态密度估计的方法。 |
| [^128] | [CLC: Cluster Assignment via Contrastive Representation Learning.](http://arxiv.org/abs/2306.05439) | 本文提出了一种基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配，并在大规模数据集上取得了更好的聚类性能。 |
| [^129] | [DynamoRep: Trajectory-Based Population Dynamics for Classification of Black-box Optimization Problems.](http://arxiv.org/abs/2306.05438) | 本文提出了一种基于轨迹的人群学习动力学的特征提取方法，用于分类黑盒优化问题，能够在少量函数评估下实现与最先进方法相竞争的效果。 |
| [^130] | [One-step Multi-view Clustering with Diverse Representation.](http://arxiv.org/abs/2306.05437) | 本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中，实验结果表明其在各种标准的多视角数据集上都优于现有算法。 |
| [^131] | [Towards End-to-end Speech-to-text Summarization.](http://arxiv.org/abs/2306.05432) | 该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。 |
| [^132] | [A Crystal-Specific Pre-Training Framework for Crystal Material Property Prediction.](http://arxiv.org/abs/2306.05344) | 本论文提出了一种基于自监督学习的晶体特异性预训练框架，该框架设计了一种互斥掩码策略，缓解了晶体物性预测中存在的标记受限问题，并增强了表示学习。同时，该框架还考虑了晶体结构中的周期性不变性，开发了周期性不变的多图模块和周期特性学习。 |
| [^133] | [Federated Linear Contextual Bandits with User-level Differential Privacy.](http://arxiv.org/abs/2306.05275) | 本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。 |
| [^134] | [Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models.](http://arxiv.org/abs/2306.05272) | 本论文提出了一种新的图像聚类流程，利用大型预训练模型的强大特征表示，在规模上有效地对图像进行聚类，并通过优化速率降低目标和 CLIP 的图像-文本绑定，成功地提高了聚类的准确性和自标记算法的效果。 |
| [^135] | [Generalization Performance of Transfer Learning: Overparameterized and Underparameterized Regimes.](http://arxiv.org/abs/2306.04901) | 该研究探讨了转移学习在不同相似度条件下的表现，使用线性回归模型分析了两种参数传递选项的比较，并通过理论分析模型误差的特征来检验泛化性能如何随着参数数量的变化而变化。 |
| [^136] | [City-wide Origin-Destination Matrix Generation via Graph Denoising Diffusion.](http://arxiv.org/abs/2306.04873) | 本文提出了一种基于图去噪扩散的方法，从网络的角度生成城市全域的起点与终点矩阵，并通过学习区域层面的城市特征来设计出图去噪扩散方法的条件概率分布。 |
| [^137] | [Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection.](http://arxiv.org/abs/2306.04824) | SLCE是用线性变换将点重构为类别质心并使用$\ell_1$范数惩罚从输入数据中滤除不必要特征的特征选择新方法。该方法为多类数据使用单个模型，具有与最先进方法相当的性能，同时具有显着较少的特征数。 |
| [^138] | [Correlative Information Maximization: A Biologically Plausible Approach to Supervised Deep Neural Networks without Weight Symmetry.](http://arxiv.org/abs/2306.04810) | 本文提出了一种无需权重对称的有监督深度神经网络的生物合理方法，该方法利用相关信息最大化在层激活之间描述生物神经网络中的信号传播。通过坐标下降优化相应的目标和均方误差损失函数，可以产生一个更生物真实的神经网络结构。 |
| [^139] | [Feature Selection using Sparse Adaptive Bottleneck Centroid-Encoder.](http://arxiv.org/abs/2306.04795) | 该论文提出一种基于稀疏自适应瓶颈质心编码器的特征选择模型，该模型通过提取有区别的特征组以及在重构类别质心的同时减少同类分散度、增加不同类别质心的分离性，从而实现过滤输入数据中不必要特征的功能。 |
| [^140] | [Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning.](http://arxiv.org/abs/2306.04641) | 提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。 |
| [^141] | [On the Reliability of Watermarks for Large Language Models.](http://arxiv.org/abs/2306.04634) | 本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。 |
| [^142] | [Your Value Function is a Control Barrier Function: Verification of Learned Policies using Control Theory.](http://arxiv.org/abs/2306.04026) | 本研究将控制理论中的验证方法应用于强化学习中的价值函数，提出了新的度量方法以验证安全控制任务中的价值函数，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。 |
| [^143] | [Toward More Accurate and Generalizable Evaluation Metrics for Task-Oriented Dialogs.](http://arxiv.org/abs/2306.03984) | 本文提出了一种新的对话质量注释工作流程称为DQA，能够更准确和可推广地评估对话质量，尤其是通过一些客观对话属性的判断。 |
| [^144] | [SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with Missing Values for Environmental Monitoring.](http://arxiv.org/abs/2306.03042) | 该论文提出了两种模型用于处理具有缺失值的多变量不对齐稀疏时间序列数据，其中一种是基于Transformer的模型SERT，另一种是提供可解释结果的简单模型SST-ANN |
| [^145] | [A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast.](http://arxiv.org/abs/2306.01986) | 该论文提出了一种基于深度知识学习的新方法，通过混合预训练和自编码器结构，同时利用基于相关性优化模型构建多层网络和序列到序列模型来提高风速预测的准确性和建模效果。 |
| [^146] | [Bigger, Better, Faster: Human-level Atari with human-level efficiency.](http://arxiv.org/abs/2305.19452) | 引入BBF基于价值函数的RL代理，在Atari 100K基准测试上实现超人类表现，具有人类效率，提出了在样本高效RL研究的ALE中更新目标的可能。 |
| [^147] | [PFNs Are Flexible Models for Real-World Bayesian Optimization.](http://arxiv.org/abs/2305.17535) | 本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。 |
| [^148] | [Hierarchical forecasting for aggregated curves with an application to day-ahead electricity price auctions.](http://arxiv.org/abs/2305.16255) | 本文提出了一种协调方法来提高聚合曲线的预测准确性，并在德国日前电力竞拍市场进行了实证研究。 |
| [^149] | [Beyond Reward: Offline Preference-guided Policy Optimization.](http://arxiv.org/abs/2305.16217) | 本研究提出了离线偏好引导策略优化(OPPO)范例，它消除了传统强化学习中奖励函数的需求。 |
| [^150] | [Learning Robust Statistics for Simulation-based Inference under Model Misspecification.](http://arxiv.org/abs/2305.15871) | 本研究提出首个通用的方法来处理基于模拟的推论（如ABC和NPE）中由于模型错误引起的不可靠推论。通过约束统计量的选择，我们的方法通过惩罚与数据和模型之间不匹配的统计量来防止不可靠推论结果。我们在高维时间序列模型上进行了实验，证明了本方法的优越性能。 |
| [^151] | [Sharpness-Aware Minimization Revisited: Weighted Sharpness as a Regularization Term.](http://arxiv.org/abs/2305.15817) | 本文提出了一种新的加权锐度形式的正则化方法 WSAM，用于改进 Sharpness-Aware Minimization (SAM) 的泛化性能，并在多个公共数据集上实现了改进或竞争力。 |
| [^152] | [Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum.](http://arxiv.org/abs/2305.09943) | 本文提出了一种无需演示的自主强化学习算法（IBC），通过辅助代理和基于最优输运的双向目标课程，能够在无需先前数据依赖的情况下，实现从非周期性交互中学习，并在稀疏任务相关交互的环境中取得更好的表现。 |
| [^153] | [Double-Weighting for Covariate Shift Adaptation.](http://arxiv.org/abs/2305.08637) | 本文提出了一种双重加权的最小极大风险分类方法，可以有效避免协变量漂移对监督学习的影响。 |
| [^154] | [Voxel-wise classification for porosity investigation of additive manufactured parts with 3D unsupervised and (deeply) supervised neural networks.](http://arxiv.org/abs/2305.07894) | 本研究使用三维无监督和(深度)监督神经网络进行增材制造件孔隙率检测的体素级分类，得出使用体素级分类的三维DL模型在AM零件的孔隙率检测方面具有巨大潜力的结论。 |
| [^155] | [No-Reference Point Cloud Quality Assessment via Weighted Patch Quality Prediction.](http://arxiv.org/abs/2305.07829) | COPP-Net是一种利用加权补丁质量预测进行局部相关性分析的无参考点云质量评估方法，优于现有的基准NR-PCQA方法。 |
| [^156] | [Supervised learning with probabilistic morphisms and kernel mean embeddings.](http://arxiv.org/abs/2305.06348) | 本文提出了监督学习中正确损失函数的概念，其通过概率测度的条件正则概率测度解决线性算子方程的问题得到定义，适用于可测空间的输入空间和标签空间。 |
| [^157] | [SEGA: Structural Entropy Guided Anchor View for Graph Contrastive Learning.](http://arxiv.org/abs/2305.04501) | 本文提出了一种名为SEGA的锚点视图用于图形对比学习，该视图通过结构熵引导以保持输入图的基本信息，达到了较好的表现。 |
| [^158] | [Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data.](http://arxiv.org/abs/2305.03827) | 本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。 |
| [^159] | [Efficient Personalized Federated Learning via Sparse Model-Adaptation.](http://arxiv.org/abs/2305.02776) | 提出了一种名为pFedGate的新方法，通过自适应和高效的方式学习稀疏的本地模型，使得客户端可以发挥其模型容量的全部潜力，从而提高个性化联邦学习的效率。 |
| [^160] | [An Adaptive Algorithm for Learning with Unknown Distribution Drift.](http://arxiv.org/abs/2305.02252) | 一种适应未知分布漂移的学习算法，相对于当前分布在不需要先验知识的情况下，学习一个函数族，且误差几乎与预先知道漂移大小的学习算法相同。此外，由于该算法适应数据，因此可以保证比依赖于漂移宽松限制的算法具有更好的学习效果。 |
| [^161] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^162] | [Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models.](http://arxiv.org/abs/2304.13835) | 本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。 |
| [^163] | [Debiasing Conditional Stochastic Optimization.](http://arxiv.org/abs/2304.10613) | 本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。 |
| [^164] | [Reflected Diffusion Models.](http://arxiv.org/abs/2304.04740) | 该论文提出了反射扩散模型，通过学习反射随机微分方程的扰动评分函数，将数据约束原则性地整合到生成过程中，以取代之前采用的导致不自然样本的阈值处理方案。 |
| [^165] | [MGTBench: Benchmarking Machine-Generated Text Detection.](http://arxiv.org/abs/2303.14822) | 本文提出了MGTBench框架，旨在解决机器生成文本检测中现有评估方法的不足。该框架通过广泛评估和公开数据集，提供了全面的MGT检测评估，使研究人员能够比较不同检测方法的有效性。 |
| [^166] | [Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond.](http://arxiv.org/abs/2303.07160) | 本文研究了平滑（强）凸有限和最小化问题的无替换随机梯度下降（SGD）的收敛下界，提出了具有比现有下界更紧的$k$依赖性的下界，并通过在强凸和凸情况下完全消除加权平均迭代的上下界差距，证明了其可行性。 |
| [^167] | [Visual Abstraction and Reasoning through Language.](http://arxiv.org/abs/2303.04091) | 本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。 |
| [^168] | [Revisiting Weighted Aggregation in Federated Learning with Neural Networks.](http://arxiv.org/abs/2302.10911) | 本文重新审视了联邦学习中的加权聚合方法。作者发现权重总和可能小于1，从而改善了泛化性能。作者探索了最优缩小因子如何受到客户端数据异质性和本地周期的影响，并使用客户端相干性研究了客户端之间的相对聚合权重以描绘客户端的重要性。作者提出了一种有效的联邦学习方法（FLLAW），该方法具有可学习聚合权重和全局权重缩小效应。 |
| [^169] | [Causal Strategic Classification: A Tale of Two Shifts.](http://arxiv.org/abs/2302.06280) | 本文提出了因果策略分类的学习算法，可以在真实因果作用下平衡策略性行为和分布转变，实现对于特征修改的鲁棒预测。 |
| [^170] | [Provably Safe Reinforcement Learning with Step-wise Violation Constraints.](http://arxiv.org/abs/2302.06064) | 本文提出了一种具有逐步违规约束的新型安全强化学习问题和解决方案SUCBVI，并证明了其最优性能，同时研究了具有逐步违规约束的安全无奖探索问题并设计了算法SRF-UCRL。 |
| [^171] | [Differentially Private Optimization for Smooth Nonconvex ERM.](http://arxiv.org/abs/2302.04972) | 本论文提出了一种针对平滑非凸ERM的差分隐私优化算法，该算法采用线性搜索、小批量训练和两阶段策略等，能够有效提高算法速度。 |
| [^172] | [Performative Recommendation: Diversifying Content via Strategic Incentives.](http://arxiv.org/abs/2302.04336) | 本研究提出了一种执行推荐的方法，通过激励内容创作者创建多样性内容，以实现推荐系统的多样性。该方法利用推荐系统的表演性质和一种新型的正则化方法，可以预测内容的策略变化，并对内容的同质性进行惩罚。 |
| [^173] | [Improving the Model Consistency of Decentralized Federated Learning.](http://arxiv.org/abs/2302.04083) | 为了解决分散式联邦学习中的模型不一致性问题，我们提出了两种算法，DFedSAM 和 DFedSAM-MGS，分别通过采用梯度扰动和多次八卦步骤来生成本地平坦模型，从而提高了 DFL 的性能。 |
| [^174] | [SLaM: Student-Label Mixing for Distillation with Unlabeled Examples.](http://arxiv.org/abs/2302.03806) | 这篇论文介绍了一种名为SLaM的方法，用于解决知识蒸馏中教师伪标签噪声带来的问题。SLaM使用学生-标签混合的方式来生成更准确的标签，并在多个标准基准上取得了更好的性能。 |
| [^175] | [Unsupervised hierarchical clustering using the learning dynamics of RBMs.](http://arxiv.org/abs/2302.01851) | 本文提出了一种利用受限玻尔兹曼机（RBM）的学习动态构建关系数据树的无监督层次聚类方法，并在数字图像、人类基因组突变和同源蛋白质家族等不同真实数据集上进行了测试，能够自动识别数据的层次结构。 |
| [^176] | [MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows.](http://arxiv.org/abs/2302.01075) | 本文提出了一个新的GAN生成建模框架MonoFlow，通过Wasserstein梯度流获得理论洞见和算法启示。该框架使用密度比例的单调递增映射重新缩放粒子演化，并通过训练鉴别器获得MonoFlow的向量场，利用相应的向量场进行粒子流的生成。 |
| [^177] | [On the Connection Between MPNN and Graph Transformer.](http://arxiv.org/abs/2301.11956) | 本文研究了MPNN与图转换器之间的连接，并证明了带有虚拟节点的MPNN可以任意逼近GT的自注意力层。我们的工作阐明了两种图学习范式之间的关系和能力平衡。 |
| [^178] | [ExplainableFold: Understanding AlphaFold Prediction with Explainable AI.](http://arxiv.org/abs/2301.11765) | 本文提出了可解释AI框架ExplainableFold，用于对AlphaFold蛋白质结构预测进行解释。提供了接近实验的对氨基酸对3D蛋白质结构影响的理解，有潜力促进对蛋白质结构的更深入理解。 |
| [^179] | [Deep Laplacian-based Options for Temporally-Extended Exploration.](http://arxiv.org/abs/2301.11181) | 本文提出了一种基于深度学习的选项方法，以处理强化学习中的探索性动作选择问题，并利用最近的结果来拓展至可伸缩性更好的领域。 |
| [^180] | [Time-Warping Invariant Quantum Recurrent Neural Networks via Quantum-Classical Adaptive Gating.](http://arxiv.org/abs/2301.08173) | 这篇论文介绍了一种新的量子递归神经网络模型TWI-QRNN，它通过量子-经典自适应门控机制实现时间扭曲不变性，并在实验中证明了其有效性。 |
| [^181] | [Almost Surely $\sqrt{T}$ Regret Bound for Adaptive LQR.](http://arxiv.org/abs/2301.05537) | 本文提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限证明，且具有断电机制保证安全并对性能影响很小。 |
| [^182] | [A prediction and behavioural analysis of machine learning methods for modelling travel mode choice.](http://arxiv.org/abs/2301.04404) | 本研究分析了各种机器学习方法和传统随机效用模型在建模出行方式选择方面的性能和特点，并确定哪些模型最适合于建模，出行行为可解释性和解释性、计算复杂度和数据效率等因素需要进行整体考虑。 |
| [^183] | [Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games.](http://arxiv.org/abs/2212.14449) | 本文提出了在均场博弈中使用策略镜面上升实现高效独立学习的方法，不需要人口生成模型，且只需要约$\widetilde{\mathcal{O}}(\varepsilon^{-2})$个样本即可达到纳什均衡。 |
| [^184] | [Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization.](http://arxiv.org/abs/2212.12978) | 本文提出了一种双重平滑梯度下降上升法 (DSGDA)，该算法可以应用于非凸-非凹极小极大优化，并且能够全局收敛并消除极限环。在一定条件下，DSGDA 的迭代复杂度达到了文献中单循环算法的最佳结果。 |
| [^185] | [An Energy-aware and Fault-tolerant Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems.](http://arxiv.org/abs/2212.08230) | 本论文提出了一种基于无模型、深度多智能体强化学习的方法，以解决复杂巡逻环境中多个自主车辆协同执行任务的问题，该方法还考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。 |
| [^186] | [Huber-energy measure quantization.](http://arxiv.org/abs/2212.08162) | 该论文提出了一种Huber能量量化的算法，用于找到目标概率定律的最佳逼近，通过最小化原测度与量化版本之间的统计距离来实现。该算法已在多维高斯混合物、维纳空间魔方等几个数据库上进行了测试。 |
| [^187] | [How to Backdoor Diffusion Models?.](http://arxiv.org/abs/2212.05400) | 该论文介绍了针对扩散模型的后门攻击框架 BadDiffusion，其可以在模型训练期间实现植入后门，导致模型在正常数据输入时依然表现良好，但接收到触发信号时产生误导性输出。该攻击可能对建立在有问题的模型之上的下游任务和应用造成严重影响。 |
| [^188] | [On the effectiveness of partial variance reduction in federated learning with heterogeneous data.](http://arxiv.org/abs/2212.02191) | 本文研究了联邦学习中数据异构性如何影响深度神经网络层之间的梯度更新，发现虽然特征提取层能被有效学习，但客户端最终分类层的大量差异阻碍了该算法的性能，因此提出了仅对最终层的方差进行降低的方法，证明其可以在相似或更低的通信成本下显著优于现有的基准方法。 |
| [^189] | [Causal Deep Reinforcement Learning Using Observational Data.](http://arxiv.org/abs/2211.15355) | 本文提出了两种DRL去混淆方法，通过重新加权或重新采样离线数据集来调整不同采样对损失函数的影响，以确保其无偏。这些方法可以有效提高DRL算法的鲁棒性和泛化性。 |
| [^190] | [Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning.](http://arxiv.org/abs/2211.06530) | 本论文针对具有多次通过数据的基于梯度的机器学习提出了新的差分隐私机制，大大改善了隐私、效用和计算之间的折衷问题。作者提出了一种新的矩阵分解扩展方法，并设计了一种高效的傅里叶变换机制，同时取得了优于以往方法的显著改进。 |
| [^191] | [Automatic Change-Point Detection in Time Series via Deep Learning.](http://arxiv.org/abs/2211.03860) | 本文介绍了一种通过训练神经网络自动生成新的离线检测方法的方式，应用于时间序列中的自动变点检测，其性能可与标准CUSUM分类器性能竞争。 |
| [^192] | [L-GreCo: Layerwise-Adaptive Gradient Compression for Efficient and Accurate Deep Learning.](http://arxiv.org/abs/2210.17357) | L-GreCo是一个基于自适应算法的通用的框架，可在训练过程中动态调整模型层之间的压缩程度，提高了总体压缩率，大幅加速，不损失精度。 |
| [^193] | [Adaptive Estimation of Graphical Models under Total Positivity.](http://arxiv.org/abs/2210.15471) | 本文提出了一种自适应多阶段估计方法来估计高斯图模型中的（对角线占优的）M矩阵，同时基于梯度投影法开发了一个统一的框架来解决正则化问题。该方法在精度矩阵估计和图边缘识别方面表现优于现有最先进方法。 |
| [^194] | [Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming.](http://arxiv.org/abs/2210.14306) | 该论文研究了代码推荐系统GitHub Copilot，发现了程序员与该系统交互的一些常见活动，揭示了其低效性和时间成本，从而为改进界面设计和度量方法提供了动力。 |
| [^195] | [Action Matching: Learning Stochastic Dynamics from Samples.](http://arxiv.org/abs/2210.06662) | 本文提出了一种名为动作匹配的方法，可以从时间边缘的快照中学习动力学，无需完整样本轨迹。该方法使用了一种衡量动作序列的损失函数来模拟整个个体轨迹，并在随机微分方程和量子电路动力学系统上得到了实验验证。 |
| [^196] | [Self-Distillation for Further Pre-training of Transformers.](http://arxiv.org/abs/2210.02871) | 本文提出了自蒸馏作为进一步预训练阶段的正则化方法，用于解决Vision Transformer在目标未标注数据集上过拟合问题，实现了在多项基准数据集上的最先进结果。 |
| [^197] | [OCD: Learning to Overfit with Conditional Diffusion Models.](http://arxiv.org/abs/2210.00471) | 本文提出了一种基于去噪扩散模型的动态模型，它通过将权重与输入样本进行条件，学习匹配微调的基础模型在输入和标签上获得的权重，可以在图像分类、3D重建、表格数据、语音分离和自然语言处理等领域得到广泛应用。 |
| [^198] | [A One-shot Framework for Distributed Clustered Learning in Heterogeneous Environments.](http://arxiv.org/abs/2209.10866) | 本文提出了一种异构环境下分布式聚类学习的通信效率高的一次性方法族，通过局部计算和聚类聚合步骤，在每个用户处学习出真实模型，具有强大的学习保证。 |
| [^199] | [Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective.](http://arxiv.org/abs/2208.07365) | 本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。 |
| [^200] | [Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors.](http://arxiv.org/abs/2207.12497) | 本文提出了一种新的方法，可以在没有敏感属性的情况下估计和控制平等机会的违规，其通过一种后处理校正方法可以实现具有保证的EOD控制。 |
| [^201] | [Graph Generative Model for Benchmarking Graph Neural Networks.](http://arxiv.org/abs/2207.04396) | 本文提出了一个名为计算图转换器（CGT）的图生成模型，可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。 |
| [^202] | [Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning.](http://arxiv.org/abs/2206.13378) | 这篇论文研究了自监督学习领域中的一种通用技巧——通过移除网络层来改善泛化性能，并解释了为什么这种技巧能够奏效。 |
| [^203] | [MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning.](http://arxiv.org/abs/2206.09280) | 本论文提出了一种名为MetaGL的元学习方法，可以在免评估的情况下选择最佳的图学习模型和超参数，并且通过引入元图特征来预测各种图学习模型在新图上的性能，相比于凭经验的方法具有更好的准确性和效率。 |
| [^204] | [BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning.](http://arxiv.org/abs/2206.08657) | BridgeTower提出了多个桥接层建立了单模态编码器的顶层与跨模编码器的连接，实现了有效的自下而上跨模态对齐和融合，显著提升了模型性能。 |
| [^205] | [Deep Isolation Forest for Anomaly Detection.](http://arxiv.org/abs/2206.06602) | 本文提出了深度隔离森林，利用神经网络将原始数据映射到随机表示集合中，通过随机轴并行切割来执行数据分区，以解决孤立森林算法不能成功检测高维/非线性可分数据空间中的难以隔离的困难异常的问题。 |
| [^206] | [Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure.](http://arxiv.org/abs/2206.03569) | 本文提出一类具有潜在低秩结构的MDP问题，其中相关的最优$Q^*$函数是低秩的，利用算法可以在小于多项式增长的样本复杂度内，有效地学习了一个近似的最优策略。 |
| [^207] | [A memory-efficient neural ODE framework based on high-level adjoint differentiation.](http://arxiv.org/abs/2206.01298) | 本论文提出了一个基于高阶伴随微分的神经ODE框架PNODE，通过离散伴随时间积分器和先进的检查点策略实现内存高效和梯度计算的准确性，并提供了一个基于PyTorch和PE的开源实现。 |
| [^208] | [Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections.](http://arxiv.org/abs/2205.05359) | 本文介绍了一种使用动态线性投影方法来分析流行的非线性模型的局部解释的方法，探索预测变量之间的交互如何影响变量重要性估计，这对于理解模型的可解释性非常有用。 |
| [^209] | [Active Learning with Weak Supervision for Gaussian Processes.](http://arxiv.org/abs/2204.08335) | 本文提出了一种基于弱监督的主动学习算法，不仅选择要注释的观测结果，还选择要获得的注释精度，并在高斯过程中进行了实验验证。 |
| [^210] | [Distributed Task Management in Fog Computing: A Socially Concave Bandit Game.](http://arxiv.org/abs/2203.14572) | 本论文提出了两种无悔在线决策策略，适用于雾计算网络中任务分配的设计。该博弈具有唯一的纳什均衡点，可以使用无悔学习策略来实现。 |
| [^211] | [EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition.](http://arxiv.org/abs/2203.13617) | 提出了一种基于双流神经架构搜索的框架EmotionNAS用于语音情感识别，将两种流（即手工特征和深度特征）作为输入，通过高效的信息补充模块实现流之间的信息整合，并在实验中创下新的最优记录。 |
| [^212] | [L0Learn: A Scalable Package for Sparse Learning using L0 Regularization.](http://arxiv.org/abs/2202.04820) | L0Learn是一个可以用于解决数百万特征问题的稀疏学习软件包，具有可扩展的近似算法和用户友好的R和Python接口。 |
| [^213] | [Optimal Variable Clustering for High-Dimensional Matrix Valued Data.](http://arxiv.org/abs/2112.12909) | 提出了一种新的针对高维矩阵数据的特征潜变量模型，使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法，理论上实现了聚类一致性，在模拟和真实数据示例中证明了方法的优越性。 |
| [^214] | [Using Image Transformations to Learn Network Structure.](http://arxiv.org/abs/2112.03419) | 该论文展示了如何将节点网络及其之间的流作为图像进行处理，并利用图像压缩技术和地理签名学习网络结构以推荐未来的网络连通性。此外，该论文开发了一种利用统计摘要的网络信息和用户决策来强化代理概率决策的贝叶斯强化算法，并探究了利用压缩直接进行强化学习的方式。 |
| [^215] | [10 Security and Privacy Problems in Large Foundation Models.](http://arxiv.org/abs/2110.15444) | 大型基础模型存在多种攻击漏洞，包括模型反演、成员推断、数据污染、后门等，这些问题可能对现实世界的AI应用产生影响，需要寻求解决方案和未来研究方向。 |
| [^216] | [Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits.](http://arxiv.org/abs/2110.08627) | 本文研究了多臂老虎机中后悔最小化和最佳臂识别的帕累托前沿,设计了BoBW-lil'UCB $(\gamma)$算法，证明了没有算法能同时为RM和BAI目标表现最佳，BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。 |
| [^217] | [A Systematic Review of Automated Query Reformulations in Source Code Search.](http://arxiv.org/abs/2108.09646) | 许多研究尝试重新制定即席查询以支持开发人员进行代码搜索，本文针对70个主要查询再制定研究进行了细致筛选和深入的定性分析，提出了八种主要方法。 |
| [^218] | [Near-Optimal Algorithms for Private Online Learning in a Stochastic Environment.](http://arxiv.org/abs/2102.07929) | 本文提出了两种隐私在线随机学习的算法，包括差分隐私的随机赌博机算法和私有随机在线学习的完全信息版本。其中，我们提出的随时可用的基于UCB的算法达到了最优性能。 |
| [^219] | [A Unified Approach to Synchronization Problems over Subgroups of the Orthogonal Group.](http://arxiv.org/abs/2009.07514) | 本文提出了一个统一方法来解决正交群子群同步问题，该方法通过广义幂方法的迭代修正和恰当的初始步骤可以在某些假设条件下获得较强的理论保证，并且在计算机视觉和传感器网络等领域有实际应用。 |

# 详细

[^1]: Prodigy: 一种快速自适应零参数学习算法

    Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])

    [http://arxiv.org/abs/2306.06101](http://arxiv.org/abs/2306.06101)

    本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。

    

    本文研究自适应算法(如Adagrad和Adam)中的学习率估计问题，描述了两种技术Prodigy和Resetting，可以证明地估计到达解决方案所需的距离D，以便最优设置学习率。我们的技术是基于学习率自由的D-Adaptation方法的修改，并通过$O(\sqrt{\log(D/d_0)})$的因子提高了D-Adaptation的收敛速度，其中$d_0$是$D$的初始估计值。我们在12个常见的逻辑回归基准数据集、在CIFAR10上训练的VGG11和ResNet-50、在Imagenet上训练的ViT、在IWSLT14上训练的LSTM、在Criteo数据集上训练的DLRM、在Knee MRI数据集上的VarNet，以及在BookWiki上训练的RoBERTa和GPT transformer上测试了我们的方法。我们的实验结果表明，我们的方法始终优于D-Adaptation，并达到手动调整Adam的测试准确度值。

    We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
    
[^2]: NuCLR：核共学习表示

    NuCLR: Nuclear Co-Learned Representations. (arXiv:2306.06099v1 [nucl-th])

    [http://arxiv.org/abs/2306.06099](http://arxiv.org/abs/2306.06099)

    NuCLR是一种可以预测各种核可观测量，包括结合能、衰变能和核电荷半径的深度学习模型，使用共享表示法进行训练，具有最先进的性能，可以捕捉到核物理的基础物理原理，并有潜力为核理论提供有价值的见解。

    

    我们引入了核共学习表示（NuCLR），这是一种深度学习模型，可以预测各种核可观测量，包括结合能、衰变能和核电荷半径。该模型采用多任务学习方法进行训练，使用共享表示法，获得了最先进的性能，达到了理解核（天体）物理基本现象所必需的精度水平。我们还报告了一个有趣的发现，即NuCLR学习的表示展现出核壳模型的重要方面，包括壳层结构，包括众所周知的魔数和泡利排斥原理。这表明该模型能够捕捉到基础物理原理，我们的方法有潜力为核理论提供有价值的见解。

    We introduce Nuclear Co-Learned Representations (NuCLR), a deep learning model that predicts various nuclear observables, including binding and decay energies, and nuclear charge radii. The model is trained using a multi-task approach with shared representations and obtains state-of-the-art performance, achieving levels of precision that are crucial for understanding fundamental phenomena in nuclear (astro)physics. We also report an intriguing finding that the learned representation of NuCLR exhibits the prominent emergence of crucial aspects of the nuclear shell model, namely the shell structure, including the well-known magic numbers, and the Pauli Exclusion Principle. This suggests that the model is capable of capturing the underlying physical principles and that our approach has the potential to offer valuable insights into nuclear theory.
    
[^3]: 错误反馈可以准确地压缩预处理器。

    Error Feedback Can Accurately Compress Preconditioners. (arXiv:2306.06098v1 [cs.LG])

    [http://arxiv.org/abs/2306.06098](http://arxiv.org/abs/2306.06098)

    本论文提出一种错误反馈技术，可以通过在馈入预处理器之前对梯度信息进行压缩（稀疏化或低秩压缩），将预处理器的存储成本压缩多达两个数量级，而不会丢失收敛性。

    

    利用深度网络规模的二阶信息是改进当前用于深度学习优化器性能的主要途径之一。然而，现有的精确全矩阵预处理方法，如全矩阵Adagrad（GGT）或无矩阵近似曲率（M-FAC），即使应用于中等规模模型，也会遇到巨大的存储成本问题，因为它们必须存储梯度的滑动窗口，其存储需求在模型维度中是成倍增加的。本文通过一种高效且易于实现的错误反馈技术来解决这个问题，该技术可以在实践中将预处理器压缩多达两个数量级，而不会丢失收敛性。具体而言，我们的方法在将梯度信息馈入预处理器之前通过稀疏化或低秩压缩压缩梯度信息，将压缩误差反馈到未来的迭代中。对深度神经网络进行了大量实验。

    Leveraging second-order information at the scale of deep networks is one of the main lines of approach for improving the performance of current optimizers for deep learning. Yet, existing approaches for accurate full-matrix preconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate Curvature (M-FAC) suffer from massive storage costs when applied even to medium-scale models, as they must store a sliding window of gradients, whose memory requirements are multiplicative in the model dimension. In this paper, we address this issue via an efficient and simple-to-implement error-feedback technique that can be applied to compress preconditioners by up to two orders of magnitude in practice, without loss of convergence. Specifically, our approach compresses the gradient information via sparsification or low-rank compression \emph{before} it is fed into the preconditioner, feeding the compression error back into future iterations. Extensive experiments on deep neural networks
    
[^4]: 利用大型语言模型进行可伸缩矢量图驱动的图像理解

    Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding. (arXiv:2306.06094v1 [cs.CV])

    [http://arxiv.org/abs/2306.06094](http://arxiv.org/abs/2306.06094)

    本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。

    

    最近，大型语言模型(LLMs)在自然语言理解和生成方面取得了显著进展。然而，它们在计算机视觉领域的潜力仍然很大程度上没有被开发。本文介绍了一种新的探索性方法，使得LLMs能够使用可伸缩矢量图(SVG)格式处理图像。通过利用基于XML的SVG表述的文本描述而不是光栅图像，我们旨在弥合视觉和文本模态之间的差距，使LLMs能够直接理解和操作图像，而无需使用参数化的视觉组件。我们的方法仅利用LLMs的能力进行简单的图像分类、生成和上下文学习。我们展示了方法在判别和生成任务中的优异表现，重点介绍了它(i)对分布转移的鲁棒性，(ii)通过利用LLMs的上下文学习能力实现的显著改进，以及(iii)图像杂乱程度上的显著性能提高。

    Recently, large language models (LLMs) have made significant advancements in natural language understanding and generation. However, their potential in computer vision remains largely unexplored. In this paper, we introduce a new, exploratory approach that enables LLMs to process images using the Scalable Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions of SVG representations instead of raster images, we aim to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. Our method facilitates simple image classification, generation, and in-context learning using only LLM capabilities. We demonstrate the promise of our approach across discriminative and generative tasks, highlighting its (i) robustness against distribution shift, (ii) substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and (iii) image unders
    
[^5]: SENS：基于草图的隐式神经形状建模

    SENS: Sketch-based Implicit Neural Shape Modeling. (arXiv:2306.06088v1 [cs.GR])

    [http://arxiv.org/abs/2306.06088](http://arxiv.org/abs/2306.06088)

    SENS是一种基于草图的生成和编辑3D模型的新方法，该方法通过ViT补丁编码将草图映射到神经隐式形状架构的潜空间中，可以捕捉用户草图的意图进行生成，具有强大的性能和直观的基于草图的形状编辑功能。

    

    本文提出了SENS，一种从手绘草图中生成和编辑3D模型的新方法，包括那些抽象的草图。我们的方法允许用户快速轻松地草绘形状，然后将草图映射到一个面向部件的神经隐式形状架构的潜空间中。SENS分析草图并将其部件编码成ViT补丁编码，然后将其馈送到transformer解码器中，将其转换为适用于编辑3D隐式神经形状的形状嵌入。SENS不仅提供了直观的基于草图的生成和编辑，而且在捕捉用户草图意图方面表现出色，可以生成各种新颖和富有表现力的3D形状，甚至可以从抽象的草图中生成。我们使用客观指标评估标准和决定性用户研究来展示该模型的有效性，两者均表明它在具有中等抽象程度的草图中表现出强大的性能。此外，我们展示了它直观的基于草图的形状编辑功能。

    We present SENS, a novel method for generating and editing 3D models from hand-drawn sketches, including those of an abstract nature. Our method allows users to quickly and easily sketch a shape, and then maps the sketch into the latent space of a part-aware neural implicit shape architecture. SENS analyzes the sketch and encodes its parts into ViT patch encoding, then feeds them into a transformer decoder that converts them to shape embeddings, suitable for editing 3D neural implicit shapes. SENS not only provides intuitive sketch-based generation and editing, but also excels in capturing the intent of the user's sketch to generate a variety of novel and expressive 3D shapes, even from abstract sketches. We demonstrate the effectiveness of our model compared to the state-of-the-art using objective metric evaluation criteria and a decisive user study, both indicating strong performance on sketches with a medium level of abstraction. Furthermore, we showcase its intuitive sketch-based s
    
[^6]: 学会不进行欺骗

    Learning Not to Spoof. (arXiv:2306.06087v1 [cs.LG])

    [http://arxiv.org/abs/2306.06087](http://arxiv.org/abs/2306.06087)

    该论文提出了学习不进行欺骗的方法，并考虑了智能股票交易代理的欺诈行为识别和避免。

    

    随着基于强化学习（RL）的智能交易代理越来越普及，确保RL代理遵守法律、法规和人类行为期望变得更加重要。本文考虑了一系列实验，其中智能股票交易代理最大化利润，但可能无意中学会欺骗其参与的市场。本文首先引入手动编码的欺诈代理到一个多代理市场模拟中，并学习识别欺诈活动序列。然后，本文将手动编码的欺骗交易员替换为一个简单的最大化利润的RL代理，观察它是否会独立地学习欺诈行为，并尝试避免它。

    As intelligent trading agents based on reinforcement learning (RL) gain prevalence, it becomes more important to ensure that RL agents obey laws, regulations, and human behavioral expectations. There is substantial literature concerning the aversion of obvious catastrophes like crashing a helicopter or bankrupting a trading account, but little around the avoidance of subtle non-normative behavior for which there are examples, but no programmable definition. Such behavior may violate legal or regulatory, rather than physical or monetary, constraints.  In this article, I consider a series of experiments in which an intelligent stock trading agent maximizes profit but may also inadvertently learn to spoof the market in which it participates. I first inject a hand-coded spoofing agent to a multi-agent market simulation and learn to recognize spoofing activity sequences. Then I replace the hand-coded spoofing trader with a simple profit-maximizing RL agent and observe that it independently 
    
[^7]: 利用手机相机的机器视觉：比较三种难以区分的印度硬币类别的深度神经网络

    Machine Vision Using Cellphone Camera: A Comparison of deep networks for classifying three challenging denominations of Indian Coins. (arXiv:2306.06084v1 [cs.CV])

    [http://arxiv.org/abs/2306.06084](http://arxiv.org/abs/2306.06084)

    本研究利用手机相机拍摄印度硬币的数字图像，训练深度神经网络模型，成功实现了从硬币两侧准确判断硬币面额的功能，准确率达到97％。

    

    印度货币硬币有多种不同面额。其中1卢比、2卢比和5卢比的硬币直径相似。市面上流通的1卢比和2卢比硬币大多款式相同，只有反面上的数字不同。如果硬币正面朝下，则无法由人类判断其正确的面额。因此，我们提出通过训练深度神经网络模型，利用廉价的手机相机产生的硬币数字图像，来判断正反面的正确面额。通过初步分析，选择了四种最适合的深度神经网络架构进行比较，结果表明其中两种可实现从硬币两侧准确判断正确的面额，准确率为97％。

    Indian currency coins come in a variety of denominations. Off all the varieties Rs.1, RS.2, and Rs.5 have similar diameters. Majority of the coin styles in market circulation for denominations of Rs.1 and Rs.2 coins are nearly the same except for numerals on its reverse side. If a coin is resting on its obverse side, the correct denomination is not distinguishable by humans. Therefore, it was hypothesized that a digital image of a coin resting on its either size could be classified into its correct denomination by training a deep neural network model. The digital images were generated by using cheap cell phone cameras. To find the most suitable deep neural network architecture, four were selected based on the preliminary analysis carried out for comparison. The results confirm that two of the four deep neural network models can classify the correct denomination from either side of a coin with an accuracy of 97%.
    
[^8]: 通过无监督聚类提高端到端语音识别中的公平性和鲁棒性

    Improving Fairness and Robustness in End-to-End Speech Recognition through unsupervised clustering. (arXiv:2306.06083v1 [cs.SD])

    [http://arxiv.org/abs/2306.06083](http://arxiv.org/abs/2306.06083)

    该论文提出了一种隐私保护的方法，通过无监督聚类提高端到端语音识别中的公平性和鲁棒性，并可以对所有人口统计学方面都有提高的效果。

    

    当自动语音识别（ASR）系统不能为所有人群子组织提供同样出色的性能时，就会出现公平性挑战。近年来，虽然在整体语音识别质量方面已经有很多改进，但并没有特别关注为系统无法表现良好的所有用户组推进公平和平等方面的改进。因此，ASR的公平性也是一个鲁棒性问题。同时，数据隐私在生产系统中也是首要问题。本文提出了一种隐私保护方法，可以在不使用元数据、邮政编码甚至不直接使用说话人或话语嵌入的情况下，提高端到端ASR的公平性和鲁棒性。我们使用在公共数据集上训练的说话人ID模型来提取话语级别的嵌入，然后以无监督的方式使用它们来创建声学聚类。我们在模型训练期间使用聚类ID而不是说话人话语嵌入作为额外的特征，这表现出了对所有人口统计学方面都有提高的效果。

    The challenge of fairness arises when Automatic Speech Recognition (ASR) systems do not perform equally well for all sub-groups of the population. In the past few years there have been many improvements in overall speech recognition quality, but without any particular focus on advancing Equality and Equity for all user groups for whom systems do not perform well. ASR fairness is therefore also a robustness issue. Meanwhile, data privacy also takes priority in production systems. In this paper, we present a privacy preserving approach to improve fairness and robustness of end-to-end ASR without using metadata, zip codes, or even speaker or utterance embeddings directly in training. We extract utterance level embeddings using a speaker ID model trained on a public dataset, which we then use in an unsupervised fashion to create acoustic clusters. We use cluster IDs instead of speaker utterance embeddings as extra features during model training, which shows improvements for all demographic
    
[^9]: 增强感知的有向投影自监督学习

    Augmentation-aware Self-supervised Learning with Guided Projector. (arXiv:2306.06082v1 [cs.CV])

    [http://arxiv.org/abs/2306.06082](http://arxiv.org/abs/2306.06082)

    本文提出了一种名为CASSLE的方法，它通过修改自监督学习中的有向投影网络，利用增强信息来提高模型处理图像特征的鲁棒性。

    

    自监督学习是从无标签数据中学习健壮表示的强大技术。SimCLR和MoCo等方法通过学习对应用的数据增强保持不变，能够达到与监督方法相当的质量。然而，这种不变性可能对解决某些下游任务有害，这些任务依赖于受到预训练期间使用的增强影响的特征，例如颜色。在本文中，我们提出通过修改自监督架构的常见组件之一的有向投影网络，来促进表示空间对这些特征的敏感性。具体而言，我们为投影器补充有关应用于图像的增强的信息。为了让投影器在解决自监督学习任务时利用这种辅助指导，特征提取器学习在其表示中保留增强信息。我们的方法被称为有向投影自监督学习（CASSLE），通过这种方法提高了模型处理图像特征的鲁棒性。

    Self-supervised learning (SSL) is a powerful technique for learning robust representations from unlabeled data. By learning to remain invariant to applied data augmentations, methods such as SimCLR and MoCo are able to reach quality on par with supervised approaches. However, this invariance may be harmful to solving some downstream tasks which depend on traits affected by augmentations used during pretraining, such as color. In this paper, we propose to foster sensitivity to such characteristics in the representation space by modifying the projector network, a common component of self-supervised architectures. Specifically, we supplement the projector with information about augmentations applied to images. In order for the projector to take advantage of this auxiliary guidance when solving the SSL task, the feature extractor learns to preserve the augmentation information in its representations. Our approach, coined Conditional Augmentation-aware Selfsupervised Learning (CASSLE), is d
    
[^10]: CARSO: 对抗性合成观测的反对抗性召回

    CARSO: Counter-Adversarial Recall of Synthetic Observations. (arXiv:2306.06081v1 [cs.CV])

    [http://arxiv.org/abs/2306.06081](http://arxiv.org/abs/2306.06081)

    本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。

    

    本文提出了一种新的对抗性防御机制CARSO，用于图像分类，灵感来自认知神经科学的线索。该方法与对抗训练具有协同互补性，并依赖于被攻击分类器的内部表示的知识。通过利用生成模型进行对抗净化，该方法采样输入的重构来进行最终分类。在各种图像数据集和分类器体系结构上进行的实验评估表明，CARSO能够比最先进的对抗性训练更好地保护分类器——同时具有可接受的清洁准确度损失。此外，防御体系结构成功地保护自己免受未预见的威胁和最终攻击。代码和预训练模型可在https://github.com/获得。

    In this paper, we propose a novel adversarial defence mechanism for image classification -- CARSO -- inspired by cues from cognitive neuroscience. The method is synergistically complementary to adversarial training and relies on knowledge of the internal representation of the attacked classifier. Exploiting a generative model for adversarial purification, conditioned on such representation, it samples reconstructions of inputs to be finally classified. Experimental evaluation by a well-established benchmark of varied, strong adaptive attacks, across diverse image datasets and classifier architectures, shows that CARSO is able to defend the classifier significantly better than state-of-the-art adversarial training alone -- with a tolerable clean accuracy toll. Furthermore, the defensive architecture succeeds in effectively shielding itself from unforeseen threats, and end-to-end attacks adapted to fool stochastic defences. Code and pre-trained models are available at https://github.com/
    
[^11]: 基于图像处理技术的番茄晚疫病病叶检测

    Detection of Late Blight Disease in Tomato Leaf Using Image Processing Techniques. (arXiv:2306.06080v1 [cs.CV])

    [http://arxiv.org/abs/2306.06080](http://arxiv.org/abs/2306.06080)

    本研究利用图像分割和多类支持向量机技术，对受晚疫病影响的番茄叶进行检测。利用图像分割技术，将受损区域分离出来，通过多类支持向量机算法来对疾病进行可靠的分类。

    

    番茄作为最常见的农作物之一，晚疫病是世界上最常见的番茄病害，经常导致番茄作物的产量显著降低。为了保证番茄作为农产品的重要角色，早期检测晚疫病十分必要。本研究利用图像分割和多类支持向量机技术来检测晚疫病。利用图像分割技术，将受损区域分离出来，通过多类支持向量机算法来对疾病进行可靠的分类。本研究从30项权威研究中选定了一项。

    =One of the most frequently farmed crops is the tomato crop. Late blight is the most prevalent tomato disease in the world, and often causes a significant reduction in the production of tomato crops. The importance of tomatoes as an agricultural product necessitates early detection of late blight. It is produced by the fungus Phytophthora. The earliest signs of late blight on tomatoes are unevenly formed, water-soaked lesions on the leaves located on the plant canopy's younger leave White cottony growth may appear in humid environments evident on the undersides of the leaves that have been impacted. Lesions increase as the disease proceeds, turning the leaves brown to shrivel up and die. Using picture segmentation and the Multi-class SVM technique, late blight disorder is discovered in this work. Image segmentation is employed for separating damaged areas on leaves, and the Multi-class SVM method is used for reliable disease categorization. 30 reputable studies were chosen from a total
    
[^12]: 从稀疏观测数据中进行日预测的深度学习

    Deep Learning for Day Forecasts from Sparse Observations. (arXiv:2306.06079v1 [physics.ao-ph])

    [http://arxiv.org/abs/2306.06079](http://arxiv.org/abs/2306.06079)

    本文提出了一种基于稀疏观测数据的MetNet-3深度学习模型，可对20小时内的天气进行准确的预测。MetNet-3的技术创新包括可学习卷积、特征学习和多任务训练优化。此外，使用持续性启发法来外推初始条件或进行短期预测来填补缺失的观测数据更进一步提高了预测性能。

    

    深度神经网络提供了一种建模天气条件的替代范例。神经模型在数据可用时以少于1秒的速度进行预测，并以非常高的时间和空间分辨率进行预测。它们可以直接从大气观测数据中进行学习，这是这些模型独特的优势之一。然而，迄今为止，仅仅预测降水这一唯一变量时，仅能使用大气观测数据来训练神经模型，才能达到与现有概率性数值天气预报模型相当的良好表现到12个小时的提前量。本文提出了MetNet-3，它显著扩展了基于观测数据的神经模型能够良好预测的引导时间范围和变量。MetNet-3从密集和稀疏的数据传感器中学习，并为降水、风、温度和露点进行24小时的预测。MetNet-3在体系结构层面引入了许多技术创新，这被证明对提高模型性能有所贡献，包括可学习的时空卷积、基于注意力的特征学习和多任务训练优化。此外，我们展示了将神经模型泛化为仅接受稀疏的气压计观测数据作为输入，并通过使用简单的持续性启发法来外推初始条件，或通过使用低分辨率数值模型进行短期预测来填补缺失的观测数据的方法是有益的。MetNet-3在降水、温度和露点预测方面比现有的大气模型在提前至24小时方面表现更好。

    Deep neural networks offer an alternative paradigm for modeling weather conditions. The ability of neural models to make a prediction in less than a second once the data is available and to do so with very high temporal and spatial resolution, and the ability to learn directly from atmospheric observations, are just some of these models' unique advantages. Neural models trained using atmospheric observations, the highest fidelity and lowest latency data, have to date achieved good performance only up to twelve hours of lead time when compared with state-of-the-art probabilistic Numerical Weather Prediction models and only for the sole variable of precipitation. In this paper, we present MetNet-3 that extends significantly both the lead time range and the variables that an observation based neural model can predict well. MetNet-3 learns from both dense and sparse data sensors and makes predictions up to 24 hours ahead for precipitation, wind, temperature and dew point. MetNet-3 introduc
    
[^13]: 通过协同作业来提升活动识别

    Cheating off your neighbors: Improving activity recognition through corroboration. (arXiv:2306.06078v1 [cs.CV])

    [http://arxiv.org/abs/2306.06078](http://arxiv.org/abs/2306.06078)

    该论文提出了一种通过观察周围人来提高个人活动预测准确性的方法。

    

    仅通过一个人的数据来理解人类活动的复杂性可能是具有挑战性的。然而，在许多情况下，周围的人可能正在执行类似的活动，而现有的人类活动识别方法几乎完全集中在个体测量上，并且很大程度上忽略了活动的背景。本文提出了一种通过融入周围个体的见解来提高个人活动预测准确性的方法。我们收集了来自20名参与者的真实世界数据集，在超过58小时的数据中包括参加讲座等活动。

    Understanding the complexity of human activities solely through an individual's data can be challenging. However, in many situations, surrounding individuals are likely performing similar activities, while existing human activity recognition approaches focus almost exclusively on individual measurements and largely ignore the context of the activity. Consider two activities: attending a small group meeting and working at an office desk. From solely an individual's perspective, it can be difficult to differentiate between these activities as they may appear very similar, even though they are markedly different. Yet, by observing others nearby, it can be possible to distinguish between these activities. In this paper, we propose an approach to enhance the prediction accuracy of an individual's activities by incorporating insights from surrounding individuals. We have collected a real-world dataset from 20 participants with over 58 hours of data including activities such as attending lect
    
[^14]: 从随机过程中学习先验知识的差分隐私图像分类

    Differentially Private Image Classification by Learning Priors from Random Processes. (arXiv:2306.06076v1 [cs.CV])

    [http://arxiv.org/abs/2306.06076](http://arxiv.org/abs/2306.06076)

    本文提出了一种名为DP-RandP的方法，从随机过程中学习先验知识，并将其传递给私有数据，以改进差分隐私的图像分类，实现了新的最先进的结果，提高了CIFAR-10的精度。

    

    在隐私保护的机器学习中，不同ially私有的随机梯度下降（DP-SGD）由于每个样本梯度剪辑和噪声添加而表现不佳。隐私学习研究的一个最近重点是通过将在真实世界公共数据上学习的先验知识纳入这些数据，从而提高DP-SGD在私有数据上的性能。在这项工作中，我们探讨了如何通过从由随机过程生成的图像中学习先验知识并将这些先验知识转移到私有数据来改进DP-SGD的隐私-效用折衷。我们提出了DP-RandP，这是一个三阶段的方法。在CIFAR10、CIFAR100和MedMNIST上从头开始训练时，我们获得了新的最先进的结果，并适用于一系列隐私预算ε∈[1，8]。特别地，我们将在ε=1时在CIFAR10上报告的最佳准确性从60.6%提高到72.3%。我们的代码可在https://github.com/inspire-group/DP-RandP上找到。

    In privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient clipping and noise addition. A recent focus in private learning research is improving the performance of DP-SGD on private data by incorporating priors that are learned on real-world public data. In this work, we explore how we can improve the privacy-utility tradeoff of DP-SGD by learning priors from images generated by random processes and transferring these priors to private data. We propose DP-RandP, a three-phase approach. We attain new state-of-the-art accuracy when training from scratch on CIFAR10, CIFAR100, and MedMNIST for a range of privacy budgets $\varepsilon \in [1, 8]$. In particular, we improve the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3 \%$ for $\varepsilon=1$. Our code is available at https://github.com/inspire-group/DP-RandP.
    
[^15]: DeepSeaNet: 使用EfficientDet提高水下目标检测的效率

    DeepSeaNet: Improving Underwater Object Detection using EfficientDet. (arXiv:2306.06075v1 [cs.CV])

    [http://arxiv.org/abs/2306.06075](http://arxiv.org/abs/2306.06075)

    本文研究了在水下环境下，使用EfficientDet等模型提高水下物体检测的效率，并通过对比多个模型的精度和推理时间，发现效率更高的模型可以更好地应对水下物体检测的挑战。

    

    海洋动物和深海物体在保护水生生物的安全时很难识别和监测。当水中含有盐和颗粒状杂质时，挑战变得更加严峻。在这种天然对抗性环境中，传统的CNN方法开始失败并且计算成本很高。本项目包括在现有的带注释的水下数据集（称为“Brackish-Dataset”）上实施和评估各种目标检测模型，包括EfficientDet、YOLOv5、YOLOv8和Detectron2。该数据集包括在视野有限的下利姆弗约尔登水中捕捉到的鱼类、蟹、海星和其他水生动物的标注图像序列。本研究项目的目的是研究较新模型在同样数据集上的效率，并通过精度和推理时间将它们与先前结果进行对比。首先，我比较了YOLOv3（31.10%平均精度均值（mAP））、YOLOv4（83.72% mAP）、YOLOv5（97.6%）、YOLOv8（98.20%）的结果。

    Marine animals and deep underwater objects are difficult to recognize and monitor for safety of aquatic life. There is an increasing challenge when the water is saline with granular particles and impurities. In such natural adversarial environment, traditional approaches like CNN start to fail and are expensive to compute. This project involves implementing and evaluating various object detection models, including EfficientDet, YOLOv5, YOLOv8, and Detectron2, on an existing annotated underwater dataset, called the Brackish-Dataset. The dataset comprises annotated image sequences of fish, crabs, starfish, and other aquatic animals captured in Limfjorden water with limited visibility. The aim of this research project is to study the efficiency of newer models on the same dataset and contrast them with the previous results based on accuracy and inference time. Firstly, I compare the results of YOLOv3 (31.10% mean Average Precision (mAP)), YOLOv4 (83.72% mAP), YOLOv5 (97.6%), YOLOv8 (98.20
    
[^16]: 基于卫星多光谱影像的特征选择，用于城市绿地覆盖率有效估计

    Feature Selection on Sentinel-2 Multi-spectral Imagery for Efficient Tree Cover Estimation. (arXiv:2306.06073v1 [cs.CV])

    [http://arxiv.org/abs/2306.06073](http://arxiv.org/abs/2306.06073)

    本文提出了一种使用光谱指数过滤掉建筑区域并对特征进行精选的多光谱随机森林分类器，用于城市地区绿地覆盖率的估计，在LUMS的82 英亩指定区域测试中表现优于传统方法和最先进的方法。

    

    本文提出了一种适合城市地区绿地覆盖率估计的多光谱随机森林分类器，它具有适当的特征选择和掩蔽。所提出分类器的关键特点是利用光谱指数过滤掉建筑区域，然后使用精选特征对剩余掩蔽上实现随机森林分类。使用Sentinel-2卫星影像数据对Lahore University of Management Sciences（LUMS）的指定区域（约82英亩）进行评估，并表明我们的方法优于传统的随机森林分类器，以及European Space Agency（ESA）WorldCover 10m 2020产品和DeepLabv3深度学习架构等最先进的方法。

    This paper proposes a multi-spectral random forest classifier with suitable feature selection and masking for tree cover estimation in urban areas. The key feature of the proposed classifier is filtering out the built-up region using spectral indices followed by random forest classification on the remaining mask with carefully selected features. Using Sentinel-2 satellite imagery, we evaluate the performance of the proposed technique on a specified area (approximately 82 acres) of Lahore University of Management Sciences (LUMS) and demonstrate that our method outperforms a conventional random forest classifier as well as state-of-the-art methods such as European Space Agency (ESA) WorldCover 10m 2020 product as well as a DeepLabv3 deep learning architecture.
    
[^17]: YOLOv5在交通和道路标志检测中的对抗攻击

    Adversarial Attack On Yolov5 For Traffic And Road Sign Detection. (arXiv:2306.06071v1 [cs.CV])

    [http://arxiv.org/abs/2306.06071](http://arxiv.org/abs/2306.06071)

    本文研究了YOLOv5在交通和道路标志检测中的对抗攻击脆弱性，发现YOLOv5易受多种攻击的影响，有 important implications for the safety and reliability of object detection algorithms used in traffic.

    

    本文针对YOLOv5目标检测算法实现并研究了流行的对抗攻击。研究探讨了YOLOv5在交通和道路标志检测中的对抗攻击脆弱性。并研究了不同类型的攻击（包括L-BFGS、FGSM、C&W、BIM、PGD、One Pixel Attack和UAP）对YOLOv5在道路标志检测中的影响。结果显示，YOLOv5易受这些攻击的影响，随着扰动大小的增加，分类错误率也会增加。我们还使用显著性图解释了这些结果。本文的发现对于交通目标检测算法的安全性和可靠性具有重要的意义。

    This paper implements and investigates popular adversarial attacks on the YOLOv5 Object Detection algorithm. The paper explores the vulnerability of the YOLOv5 to adversarial attacks in the context of traffic and road sign detection. The paper investigates the impact of different types of attacks, including the Limited memory Broyden Fletcher Goldfarb Shanno (L-BFGS), the Fast Gradient Sign Method (FGSM) attack, the Carlini and Wagner (C&W) attack, the Basic Iterative Method (BIM) attack, the Projected Gradient Descent (PGD) attack, One Pixel Attack, and the Universal Adversarial Perturbations attack on the accuracy of YOLOv5 in detecting traffic and road signs. The results show that YOLOv5 is susceptible to these attacks, with misclassification rates increasing as the magnitude of the perturbations increases. We also explain the results using saliency maps. The findings of this paper have important implications for the safety and reliability of object detection algorithms used in traf
    
[^18]: DeepStay：使用弱监督从位置轨迹中提取停留区域。

    DeepStay: Stay Region Extraction from Location Trajectories using Weak Supervision. (arXiv:2306.06068v1 [cs.CV])

    [http://arxiv.org/abs/2306.06068](http://arxiv.org/abs/2306.06068)

    DeepStay是一个基于弱监督和自监督的变压器模型，用于从位置轨迹中预测停留区域并提取个人兴趣点（POIs）而无需个人信息或其他数据。它是第一个在公共标记数据集上进行评估并优于最先进方法的深度学习方法。

    

    如今，移动设备可以不断跟踪用户的位置，位置轨迹可用于推断个人兴趣点(POI)，如家庭、工作场所或商店。提取POI的常见方法是首先识别用户花费大量时间的时空区域，即停留区域(SR)。常见的SR提取方法要么仅评估无监督方法，要么在小规模私有数据集上进行评估，因为流行的公共数据集是未标记的。大多数这些方法依赖于手工特征或阈值，并且无法超出超参数优化范围。因此，我们提出了一个弱监督的自监督变压器模型DeepStay，它是在位置轨迹上训练的，用于预测停留区域。据我们所知，这是第一个基于深度学习的方法，也是第一个在公共标记数据集上进行评估的方法。我们的SR提取方法优于最先进的方法。此外，我们提出了一种从停留区域中提取个人POI的方法。我们的方法不依赖于任何个人信息，例如家庭或工作地址，也不需要除位置轨迹以外的其他数据。

    Nowadays, mobile devices enable constant tracking of the user's position and location trajectories can be used to infer personal points of interest (POIs) like homes, workplaces, or stores. A common way to extract POIs is to first identify spatio-temporal regions where a user spends a significant amount of time, known as stay regions (SRs).  Common approaches to SR extraction are evaluated either solely unsupervised or on a small-scale private dataset, as popular public datasets are unlabeled. Most of these methods rely on hand-crafted features or thresholds and do not learn beyond hyperparameter optimization. Therefore, we propose a weakly and self-supervised transformer-based model called DeepStay, which is trained on location trajectories to predict stay regions. To the best of our knowledge, this is the first approach based on deep learning and the first approach that is evaluated on a public, labeled dataset. Our SR extraction method outperforms state-of-the-art methods. In additi
    
[^19]: 基于对比学习的交叉模态特征对齐方法用于遥感图像场景的零样本分类

    Multi-level Cross-modal Feature Alignment via Contrastive Learning towards Zero-shot Classification of Remote Sensing Image Scenes. (arXiv:2306.06066v1 [cs.CV])

    [http://arxiv.org/abs/2306.06066](http://arxiv.org/abs/2306.06066)

    提出了一种基于对比学习的多级交叉模态特征对齐方法，用于零样本分类，能够有效应对大类内差异和小类间相似性的挑战。

    

    零样本图像场景分类可以识别在训练阶段未见过的图像场景，以此降低对大量标记样本的依赖性。近年来，交叉模态特征对齐方法已被提出来解决这个问题。这些方法主要关注将每个图像场景的视觉特征与其对应的语义描述符在潜在空间中匹配。较少关注不同图像场景和不同语义描述符之间的对比关系。

    Zero-shot classification of image scenes which can recognize the image scenes that are not seen in the training stage holds great promise of lowering the dependence on large numbers of labeled samples. To address the zero-shot image scene classification, the cross-modal feature alignment methods have been proposed in recent years. These methods mainly focus on matching the visual features of each image scene with their corresponding semantic descriptors in the latent space. Less attention has been paid to the contrastive relationships between different image scenes and different semantic descriptors. In light of the challenge of large intra-class difference and inter-class similarity among image scenes and the potential noisy samples, these methods are susceptible to the influence of the instances which are far from these of the same classes and close to these of other classes. In this work, we propose a multi-level cross-modal feature alignment method via contrastive learning for zero
    
[^20]: 用于组合优化的神经算法推理

    Neural Algorithmic Reasoning for Combinatorial Optimisation. (arXiv:2306.06064v1 [cs.NE])

    [http://arxiv.org/abs/2306.06064](http://arxiv.org/abs/2306.06064)

    本文提出了一种用于组合优化问题的神经算法推理方法，旨在解决旅行商问题。该方法是通过在TSP实例训练之前，将神经模型用相关算法进行预训练来实现的。实验结果表明，该方法可以显著提高TSP问题的解决效率。

    

    使用神经网络解决NP难/完全组合问题是一个挑战性的研究领域，旨在超越传统的近似算法。其长期目标是通过学习仅从训练数据生成更优解来超越手工设计的启发式算法，而旅行商问题(TSP)是经常被这些方法瞄准的一个重要的组合优化问题。然而，目前用于解决TSP的基于神经网络的方法常常忽略了问题固有的“算法”本质。与此相反，设计用于TSP的启发式方法常常利用诸如查找最小生成树之类的成熟算法。在本文中，我们提出利用神经算法推理的最新进展来改进TSP问题的学习。具体来说，我们建议在对TSP实例进行训练之前，在相关算法上对我们的神经模型进行预训练。我们的结果表明，使用这种学习方法可以显著提高TSP问题的解决效率。

    Solving NP-hard/complete combinatorial problems with neural networks is a challenging research area that aims to surpass classical approximate algorithms. The long-term objective is to outperform hand-designed heuristics for NP-hard/complete problems by learning to generate superior solutions solely from training data. The Travelling Salesman Problem (TSP) is a prominent combinatorial optimisation problem often targeted by such approaches. However, current neural-based methods for solving TSP often overlook the inherent "algorithmic" nature of the problem. In contrast, heuristics designed for TSP frequently leverage well-established algorithms, such as those for finding the minimum spanning tree. In this paper, we propose leveraging recent advancements in neural algorithmic reasoning to improve the learning of TSP problems. Specifically, we suggest pre-training our neural model on relevant algorithms before training it on TSP instances. Our results demonstrate that, using this learning
    
[^21]: 少样本节点分类的虚拟节点调整

    Virtual Node Tuning for Few-shot Node Classification. (arXiv:2306.06063v1 [cs.LG])

    [http://arxiv.org/abs/2306.06063](http://arxiv.org/abs/2306.06063)

    我们提出了一种虚拟节点调整方法VNT来解决图表示学习中少样本节点分类的挑战。VNT利用预训练的图变换器编码器和嵌入空间中注入虚拟节点，并通过元学习优化虚拟节点以调节每个FSNC任务的节点嵌入。该方法在处理基类别中有稀疏标签的情况下有优势。

    

    少样本节点分类（FSNC）是图表示学习中的一个挑战，仅有每个类别少量已标记节点可用于训练。为了解决这个问题，元学习被提出来将结构知识从有丰富标签的基类中转移至目标新类别。然而，当基类没有或标记节点非常少时，现有的解决方案变得无效或不可行。为了应对这一挑战，我们提出了一种创新方法，称为虚拟节点调整（VNT）。我们的方法利用预训练的图变换器作为编码器，并在嵌入空间中注入虚拟节点作为软提示，可通过少量样本标签在新类别中进行优化，以调制每个特定的FSNC任务的节点嵌入。 VNT的一项独特特点是，通过结合基于图的伪提示演化（GPPE）模块，VNT-GPPE可以处理基类别中有稀疏标签的情况。四个数据集上的实验结果表明，我们的方法在少样本分类准确性方面优于多个基线方法。

    Few-shot Node Classification (FSNC) is a challenge in graph representation learning where only a few labeled nodes per class are available for training. To tackle this issue, meta-learning has been proposed to transfer structural knowledge from base classes with abundant labels to target novel classes. However, existing solutions become ineffective or inapplicable when base classes have no or limited labeled nodes. To address this challenge, we propose an innovative method dubbed Virtual Node Tuning (VNT). Our approach utilizes a pretrained graph transformer as the encoder and injects virtual nodes as soft prompts in the embedding space, which can be optimized with few-shot labels in novel classes to modulate node embeddings for each specific FSNC task. A unique feature of VNT is that, by incorporating a Graph-based Pseudo Prompt Evolution (GPPE) module, VNT-GPPE can handle scenarios with sparse labels in base classes. Experimental results on four datasets demonstrate the superiority o
    
[^22]: 从点云数据中学习Fisher信息矩阵的神经FIM

    Neural FIM for learning Fisher Information Metrics from point cloud data. (arXiv:2306.06062v1 [cs.CV])

    [http://arxiv.org/abs/2306.06062](http://arxiv.org/abs/2306.06062)

    本文提出了神经FIM，一种从点云数据中计算Fisher信息度量（FIM）的方法，可以连续地对数据进行流形建模，从而提高流形特征的描述能力。

    

    虽然数据扩散嵌入在无监督学习中随处可见，并且已经被证明是揭示数据潜在内在几何的可行技术，但由于其离散性，扩散嵌入固有的局限性。因此，我们提出了神经FIM，一种从点云数据中计算Fisher信息度量（FIM）的方法，允许对数据进行连续流形建模。神经FIM从离散的点云数据中创建可扩展的度量空间，因此从度量中获取的信息可以告诉我们流形的特征，如体积和测地线。我们证明了神经FIM在选择PHATE可视化方法的参数以及在玩具数据集和两个IPSC重编程和PBMCs单细胞数据集的分支点和聚类中心嵌入中获取信息方面的效用。

    Although data diffusion embeddings are ubiquitous in unsupervised learning and have proven to be a viable technique for uncovering the underlying intrinsic geometry of data, diffusion embeddings are inherently limited due to their discrete nature. To this end, we propose neural FIM, a method for computing the Fisher information metric (FIM) from point cloud data - allowing for a continuous manifold model for the data. Neural FIM creates an extensible metric space from discrete point cloud data such that information from the metric can inform us of manifold characteristics such as volume and geodesics. We demonstrate Neural FIM's utility in selecting parameters for the PHATE visualization method as well as its ability to obtain information pertaining to local volume illuminating branching points and cluster centers embeddings of a toy dataset and two single-cell datasets of IPSC reprogramming and PBMCs (immune cells).
    
[^23]: 利用PCA和K-means对非洲发型数据集进行聚类分析

    clustering an african hairstyle dataset using pca and k-means. (arXiv:2306.06061v1 [cs.CV])

    [http://arxiv.org/abs/2306.06061](http://arxiv.org/abs/2306.06061)

    本文提出了一种使用K-means进行非洲女性图像分类的方法，以便识别不同的面部群集和发型。

    

    数字化转型并没有在构建非洲面部形状分类器上得到表现。本文介绍了一种方法，使用K-means对非洲女性图像进行分类。非洲女性在选择合适的发型时，会依赖于美丽的标准建议，个人偏好或最新的发型趋势。文章使用Haarcascade进行基于特征训练，应用K-means聚类进行图像分类，以识别潜在的面部群集。

    The adoption of digital transformation was not expressed in building an African face shape classifier. In this paper, an approach is presented that uses k-means to classify African women images. African women rely on beauty standards recommendations, personal preference, or the newest trends in hairstyles to decide on the appropriate hairstyle for them. In this paper, an approach is presented that uses K-means clustering to classify African women's images. In order to identify potential facial clusters, Haarcascade is used for feature-based training, and K-means clustering is applied for image classification.
    
[^24]: 微调对于视觉语言模型外分布检测的影响是怎样的？

    How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?. (arXiv:2306.06048v1 [cs.CV])

    [http://arxiv.org/abs/2306.06048](http://arxiv.org/abs/2306.06048)

    本研究旨在探究微调对少样本下游任务的外分布检测的影响，发现适当选择外分布分数对于CLIP-based 微调至关重要。最大概念匹配（MCM）分数提供了一个有前途的解决方案。

    

    最近的大型视觉语言模型，如CLIP，在外分布检测和泛化性能方面表现出色。然而，它们的零样本内分布准确性往往在下游数据集中受到限制。最近的基于CLIP的微调方法，如提示学习，已经在存在外分布标签的情况下显著改进了内分布分类和外分布泛化。然而，模型对于没有外分布标签的语义转移是否可靠仍然不清楚。为了填补这一空白，本文旨在对微调对于少样本下游任务的外分布检测的影响进行全面研究。通过将外分布检测框架化为多模式概念匹配，我们建立了微调方法和各种外分布分数之间的联系。我们的结果表明，选择适当的外分布分数对于基于CLIP的微调至关重要。特别是，最大概念匹配（MCM）分数提供了一个有前途的解决方案。

    Recent large vision-language models such as CLIP have shown remarkable out-of-distribution (OOD) detection and generalization performance. However, their zero-shot in-distribution (ID) accuracy is often limited for downstream datasets. Recent CLIP-based fine-tuning methods such as prompt learning have demonstrated significant improvements in ID classification and OOD generalization where OOD labels are available. Nonetheless, it remains unclear whether the model is reliable to semantic shifts without OOD labels. In this paper, we aim to bridge the gap and present a comprehensive study to understand how fine-tuning impact OOD detection for few-shot downstream tasks. By framing OOD detection as multi-modal concept matching, we establish a connection between fine-tuning methods and various OOD scores. Our results suggest that a proper choice of OOD scores is essential for CLIP-based fine-tuning. In particular, the maximum concept matching (MCM) score provides a promising solution consiste
    
[^25]: 动态图邻先验用于关系推断

    A Dynamical Graph Prior for Relational Inference. (arXiv:2306.06041v1 [cs.LG])

    [http://arxiv.org/abs/2306.06041](http://arxiv.org/abs/2306.06041)

    DYGR是一种用于关系推断的动态图先验方法，它利用高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度，并能够同时适用于具有共享图拓扑的“浅层”一步模型。

    

    关系推断旨在从观察到的动态系统中识别部件之间的相互作用。目前的最先进方法是在可学习的图上拟合图神经网络 (GNN) 来进行关系推断。它们使用一步消息传递 GNN--直观上来说是正确的选择，因为多步或谱 GNN 的非局部性可能会混淆直接和间接相互作用。但是“有效”的交互图取决于采样速率，很少局限于直接邻居，导致一个步骤模型的局部最小值。在本文中，我们提出了一种“动态图先验”(DYGR)来进行关系推断。我们称之为先验的原因是，与已有的方法不同，它在高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度。为了处理非唯一性，DYGR 同时适用于具有共享图拓扑的“浅层”一步模型。实验证明 DYGR 能够重新构建交互结构，同时获得更好的性能。

    Relational inference aims to identify interactions between parts of a dynamical system from the observed dynamics. Current state-of-the-art methods fit a graph neural network (GNN) on a learnable graph to the dynamics. They use one-step message-passing GNNs -- intuitively the right choice since non-locality of multi-step or spectral GNNs may confuse direct and indirect interactions. But the \textit{effective} interaction graph depends on the sampling rate and it is rarely localized to direct neighbors, leading to local minima for the one-step model. In this work, we propose a \textit{dynamical graph prior} (DYGR) for relational inference. The reason we call it a prior is that, contrary to established practice, it constructively uses error amplification in high-degree non-local polynomial filters to generate good gradients for graph learning. To deal with non-uniqueness, DYGR simultaneously fits a ``shallow'' one-step model with shared graph topology. Experiments show that DYGR reconstr
    
[^26]: 利用Transformer网络重建钢琴演奏中人类表现力

    Reconstructing Human Expressiveness in Piano Performances with a Transformer Network. (arXiv:2306.06040v1 [cs.SD])

    [http://arxiv.org/abs/2306.06040](http://arxiv.org/abs/2306.06040)

    本文提出了一种利用Transformer网络来重建钢琴演奏中人类表现力的方法，使用转录乐谱来训练模型，整合钢琴家身份以控制采样过程，并成功生成了高度类人的钢琴表演。

    

    利用计算方法捕捉人类音乐演奏中复杂微妙的表现力变化是一项具有挑战性的任务。本文提出了一种新颖的方法，利用多层双向Transformer编码器重建钢琴演奏中的人类表现力。为了解决训练神经网络需要大量准确捕捉和得分对齐的演奏数据的需求，我们使用从现有转录模型获取的转录乐谱来训练我们的模型。我们整合了钢琴家身份以控制采样过程，并探讨了我们的系统模拟不同钢琴家表现力变化的能力。通过生成的表现力演奏的统计分析和听力测试对系统进行评估。总体而言，结果表明我们的方法在从转录的乐谱中生成类人钢琴演奏方面达到了最先进的水平，同时充分和一致地重建了人类表现力。

    Capturing intricate and subtle variations in human expressiveness in music performance using computational approaches is challenging. In this paper, we propose a novel approach for reconstructing human expressiveness in piano performance with a multi-layer bi-directional Transformer encoder. To address the needs for large amounts of accurately captured and score-aligned performance data in training neural networks, we use transcribed scores obtained from an existing transcription model to train our model. We integrate pianist identities to control the sampling process and explore the ability of our system to model variations in expressiveness for different pianists. The system is evaluated through statistical analysis of generated expressive performances and a listening test. Overall, the results suggest that our method achieves state-of-the-art in generating human-like piano performances from transcribed scores, while fully and consistently reconstructing human expressiveness poses fu
    
[^27]: 基于RANS-PINN的模拟代理预测湍流流动

    RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows. (arXiv:2306.06034v1 [cs.LG])

    [http://arxiv.org/abs/2306.06034](http://arxiv.org/abs/2306.06034)

    本研究提出了RANS-PINN模型，通过引入2方程涡粘度模型，可预测高雷诺数湍流流动中的流场，从而提高流体动力学模拟计算效率。

    

    物理知识引导的神经网络（PINN）为建立由微分方程控制的动态系统的代理模型提供了框架。 PINN在学习过程中会通过损失函数中的物理基础正则化项来增强泛化性能。由于模拟由偏微分方程（PDEs）控制的动态可能计算成本过高，PINN已经在学习由Navier-Stokes方程控制的液体流动问题的参数代理方面广受欢迎。在这项工作中，我们介绍了RANS-PINN，一种修改后的PINN框架，用于预测高雷诺数湍流流动中的流场（即速度和压力）。为了考虑湍流引入的额外复杂性，RANS-PINN采用基于雷诺平均Navier-Stokes（RANS）的2方程涡粘度模型。此外，我们采用了一种新的训练方法，确保各个组成部分的有效初始化和平衡。

    Physics-informed neural networks (PINNs) provide a framework to build surrogate models for dynamical systems governed by differential equations. During the learning process, PINNs incorporate a physics-based regularization term within the loss function to enhance generalization performance. Since simulating dynamics controlled by partial differential equations (PDEs) can be computationally expensive, PINNs have gained popularity in learning parametric surrogates for fluid flow problems governed by Navier-Stokes equations. In this work, we introduce RANS-PINN, a modified PINN framework, to predict flow fields (i.e., velocity and pressure) in high Reynolds number turbulent flow regime. To account for the additional complexity introduced by turbulence, RANS-PINN employs a 2-equation eddy viscosity model based on a Reynolds-averaged Navier-Stokes (RANS) formulation. Furthermore, we adopt a novel training approach that ensures effective initialization and balance among the various component
    
[^28]: FinGPT：开源金融大型语言模型

    FinGPT: Open-Source Financial Large Language Models. (arXiv:2306.06031v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.06031](http://arxiv.org/abs/2306.06031)

    FinGPT是一个开源的金融大型语言模型，提供了可访问和透明的资源来开发金融LLMs，其重要性在于自动数据筛选管道和轻量级低秩适应技术。

    

    大型语言模型（LLMs）展示了在各个领域革新自然语言处理任务的潜力，引起了金融领域的浓厚兴趣。获得高质量的金融数据是金融LLMs（FinLLMs）的第一个挑战。在这篇论文中，我们提出了一个针对金融领域的开源大型语言模型FinGPT。与专有模型不同，FinGPT采用数据为中心的方法，为研究人员和从业者提供可访问和透明的资源来开发他们的金融LLMs。我们强调自动数据筛选管道和轻量级低秩适应技术在建立FinGPT中的重要性。此外，我们展示了几个潜在的应用作为用户的基础，如机器顾问、算法交易和论 。

    Large language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparking great interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.  In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes a data-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and l
    
[^29]: 可自我解释的时间序列预测与反事实解释

    Self-Interpretable Time Series Prediction with Counterfactual Explanations. (arXiv:2306.06024v1 [cs.LG])

    [http://arxiv.org/abs/2306.06024](http://arxiv.org/abs/2306.06024)

    本文提出了一种自我解释的时间序列预测模型CounTS，该模型可以生成反事实和可操作的解释，适用于关键领域如医疗和自动驾驶等。与现有方法不同，该模型为可解释性建模做出了贡献。

    

    可解释的时间序列预测对于像医疗和自动驾驶等安全关键领域至关重要。本文提出了一种不同于现有方法的思路，旨在开发出一种自我解释的模型，被称为Counterfactual Time Series（CounTS），该模型针对时间序列预测生成反事实和可操作的解释。具体而言，我们形式化了时间序列反事实解释的问题，建立了相应的评估协议，并提出了一种带有时间序列绑架、行动和预测反事实推理能力的变分贝叶斯深度学习模型。与最先进的基线相比，我们的自我解释模型可以生成更好的反事实解释，同时保持相当的预测准确性。

    Interpretable time series prediction is crucial for safety-critical areas such as healthcare and autonomous driving. Most existing methods focus on interpreting predictions by assigning important scores to segments of time series. In this paper, we take a different and more challenging route and aim at developing a self-interpretable model, dubbed Counterfactual Time Series (CounTS), which generates counterfactual and actionable explanations for time series predictions. Specifically, we formalize the problem of time series counterfactual explanations, establish associated evaluation protocols, and propose a variational Bayesian deep learning model equipped with counterfactual inference capability of time series abduction, action, and prediction. Compared with state-of-the-art baselines, our self-interpretable model can generate better counterfactual explanations while maintaining comparable prediction accuracy.
    
[^30]: 多智能体多臂老虎机的分布式共识算法

    Distributed Consensus Algorithm for Decision-Making in Multi-agent Multi-armed Bandit. (arXiv:2306.05998v1 [cs.LG])

    [http://arxiv.org/abs/2306.05998](http://arxiv.org/abs/2306.05998)

    本文提出了一种在动态环境中处理多智能体多臂老虎机问题的分布式共识算法，该算法能够最小化每个时间步不选择最优臂所产生的期望总损失。

    

    本文研究了动态环境中结构化的多智能体多臂老虎机问题。图形反映了代理之间的信息共享结构，臂的奖励分布是具有几个未知变化点的分段定常分布。代理面临相同的分段定常MAB问题。目标是为代理开发一个决策策略，使得后悔最小，即每个时间步不选择最优臂所产生的期望总损失。我们提出的解决方案是具有贝叶斯在线变点检测的重新启动协作UCB算法(RBO-Coop-UCB)，其中包括一个高效的多智能体UCB算法作为核心，并提升了合作决策。理论上，我们证明了RBO-Coop-UCB的预期团体后悔上界为$\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$。

    We study a structured multi-agent multi-armed bandit (MAMAB) problem in a dynamic environment. A graph reflects the information-sharing structure among agents, and the arms' reward distributions are piecewise-stationary with several unknown change points. The agents face the identical piecewise-stationary MAB problem. The goal is to develop a decision-making policy for the agents that minimizes the regret, which is the expected total loss of not playing the optimal arm at each time step. Our proposed solution, Restarted Bayesian Online Change Point Detection in Cooperative Upper Confidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agent UCB algorithm as its core enhanced with a Bayesian change point detector. We also develop a simple restart decision cooperation that improves decision-making. Theoretically, we establish that the expected group regret of RBO-Coop-UCB is upper bounded by $\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$, where K is the number of agents, M is 
    
[^31]: 基于近似信息状态的循环Q-learning收敛性分析

    Approximate information state based convergence analysis of recurrent Q-learning. (arXiv:2306.05991v1 [cs.LG])

    [http://arxiv.org/abs/2306.05991](http://arxiv.org/abs/2306.05991)

    本文研究了循环Q-learning在部分可观测环境下的收敛性，并提出了一种使用近似信息状态的变体算法，该算法在表现上优于强基线。

    

    尽管有很多针对部分可观测的马尔可夫决策过程的强化学习算法的文献，但仍缺乏完整的理论理解。在部分可观测的情况下，代理可用的数据历史会随着时间的推移而增加，因此大多数实用算法要么将历史截断到有限的窗口，要么使用递归神经网络进行压缩，导致代理状态不是马尔可夫的。本文证明了尽管缺乏马尔可夫性质，循环Q-learning（RQL）在表格设置中也会收敛。此外，本文还证明了收敛极限的质量取决于表示形式的质量，这是使用近似信息状态（AIS）来量化的。基于这种近似误差的表征，提出了一种带有AIS损失的RQL变体。与不使用AIS损失的RQL强基线相比，这种变体表现更好。

    In spite of the large literature on reinforcement learning (RL) algorithms for partially observable Markov decision processes (POMDPs), a complete theoretical understanding is still lacking. In a partially observable setting, the history of data available to the agent increases over time so most practical algorithms either truncate the history to a finite window or compress it using a recurrent neural network leading to an agent state that is non-Markovian. In this paper, it is shown that in spite of the lack of the Markov property, recurrent Q-learning (RQL) converges in the tabular setting. Moreover, it is shown that the quality of the converged limit depends on the quality of the representation which is quantified in terms of what is known as an approximate information state (AIS). Based on this characterization of the approximation error, a variant of RQL with AIS losses is presented. This variant performs better than a strong baseline for RQL that does not use AIS losses. It is de
    
[^32]: 基于四分位数的季节性分解用于时间序列预测和异常检测

    Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection. (arXiv:2306.05989v1 [cs.LG])

    [http://arxiv.org/abs/2306.05989](http://arxiv.org/abs/2306.05989)

    本文提出了一种名为QBSD的实时预测方法，以在时间序列异常检测中取得最佳平衡。

    

    在电信领域，及时检测异常非常重要，因为这有助于识别和表征不规则模式、异常行为和网络异常，从而提高服务质量和操作效率。精确地预测和消除可预测的时间序列模式是时间序列异常检测的重要组成部分。本文提出了一种名为基于四分位数的季节性分解（QBSD）的实时预测方法，以在计算复杂度和预测准确率之间取得最佳平衡。本文比较了QBSD与现有预测方法的性能及其适用性。

    The timely detection of anomalies is essential in the telecom domain as it facilitates the identification and characterization of irregular patterns, abnormal behaviors, and network anomalies, contributing to enhanced service quality and operational efficiency. Precisely forecasting and eliminating predictable time series patterns constitutes a vital component of time series anomaly detection. While the state-of-the-art methods aim to maximize forecasting accuracy, the computational performance takes a hit. In a system composed of a large number of time series variables, e.g., cell Key Performance Indicators (KPIs), the time and space complexity of the forecasting employed is of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a live forecasting method proposed in this paper to make an optimal trade-off between computational complexity and forecasting accuracy. This paper compares the performance of QBSD to the state-of-the-art forecasting methods and their applic
    
[^33]: 一种基于对比学习方法的代理市场订单表示

    Agent market orders representation through a contrastive learning approach. (arXiv:2306.05987v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.05987](http://arxiv.org/abs/2306.05987)

    通过对比学习方法，本研究构建了一个自监督学习模型，用于学习代理市场订单的表示。进一步地，我们使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。

    

    本研究通过访问Euronext的CAC40数据中的标记订单，分析代理在市场中根据其下达的订单的行为。本研究构建了一个自监督学习模型，使用三元组损失来有效地学习代理市场订单的表示。通过获取这个学习表示，各种下游任务变得可行。本研究使用K均值聚类算法对代理订单的学习表示向量进行聚类，以确定每个簇中的不同行为类型。

    Due to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyse agents' behaviours in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilise the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behaviour types within each cluster.
    
[^34]: 在因子图中自动进行模型比较

    Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])

    [http://arxiv.org/abs/2306.05965](http://arxiv.org/abs/2306.05965)

    本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。

    

    在文献中，贝叶斯状态和参数估计已经被有效自动化，但对于模型比较尚未如此，因此仍需要容易出错和耗时的手动推导。因此，模型比较经常被忽视和忽略，尽管它很重要。本文通过在Forney样式的因子图上使用自定义混合节点上的消息传递来高效地自动化贝叶斯模型平均、选择和组合。进而可使用缩放因子同时执行参数和状态推断以及模型比较。这种方法缩短了模型设计周期，同时允许简单地扩展到分层和时间模型先验，以适应建模复杂的时变过程。

    Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
    
[^35]: DDLP：基于深度动态潜在粒子的无监督物体中心视频预测

    DDLP: Unsupervised Object-Centric Video Prediction with Deep Dynamic Latent Particles. (arXiv:2306.05957v1 [cs.CV])

    [http://arxiv.org/abs/2306.05957](http://arxiv.org/abs/2306.05957)

    DDLP算法使用深度潜在粒子(DLP)表示法实现无监督物体中心视频预测，并取得了最先进的预测结果。算法的可解释性使得可以进行“假设”生成，而DLP的紧凑结构使得效率高并可以进行基于扩散的无条件视频生成。

    

    本文提出了一种基于深度潜在粒子（DLP）表示的新型物体中心视频预测算法。与现有的基于槽或补丁的表示相比，DLP使用一组关键点模拟场景，学习参数用于属性例如位置和大小，并且既高效又可解释。我们的方法——深度动态潜在粒子(DDLP)，在多个具有挑战性的数据集上实现了最先进的物体中心视频预测结果。DDLP的可解释性使我们能够执行“假设”生成——预测更改初始帧中对象属性的结果，而DLP的紧凑结构使得效率高并可以进行基于扩散的无条件视频生成。视频、代码和预训练模型可在此链接找到：https://taldatech.github.io/ddlp-web

    We propose a new object-centric video prediction algorithm based on the deep latent particle (DLP) representation. In comparison to existing slot- or patch-based representations, DLPs model the scene using a set of keypoints with learned parameters for properties such as position and size, and are both efficient and interpretable. Our method, deep dynamic latent particles (DDLP), yields state-of-the-art object-centric video prediction results on several challenging datasets. The interpretable nature of DDLP allows us to perform ``what-if'' generation -- predict the consequence of changing properties of objects in the initial frames, and DLP's compact structure enables efficient diffusion-based unconditional video generation. Videos, code and pre-trained models are available: https://taldatech.github.io/ddlp-web
    
[^36]: 路径神经网络：表达能力强且精确的图神经网络

    Path Neural Networks: Expressive and Accurate Graph Neural Networks. (arXiv:2306.05955v1 [cs.LG])

    [http://arxiv.org/abs/2306.05955](http://arxiv.org/abs/2306.05955)

    本文提出了路径神经网络模型，该模型通过聚合从节点出发的路径来更新节点表示，相比标准图神经网络具有更强的表达能力，能够区分一些1-WL无法区分的非同构图对。

    

    图神经网络（GNN）近期成为了学习图结构数据的标准方法。早先的研究揭示了它们的潜力，也揭示了它们的限制。不幸的是，标准的GNN在表达能力上存在局限性。在区分非同构图方面，这些模型的能力不超过一维Weisfeiler-Leman（1-WL）算法。本文提出了路径神经网络（PathNNs），该模型通过聚合从节点出发的路径来更新节点表示。我们推导出了三种不同的PathNN模型变体，以聚合单个最短路径、所有最短路径和所有长度不超过K的简单路径。我们证明了其中两个变体在表达能力上比1-WL算法严谨，同时我们通过实验证实了我们的理论结果。我们发现，PathNNs可以区分一些1-WL无法区分的非同构图对，而我们最表达丰富的PathNN变体具有更好的性能。

    Graph neural networks (GNNs) have recently become the standard approach for learning with graph-structured data. Prior work has shed light into their potential, but also their limitations. Unfortunately, it was shown that standard GNNs are limited in their expressive power. These models are no more powerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms of distinguishing non-isomorphic graphs. In this paper, we propose Path Neural Networks (PathNNs), a model that updates node representations by aggregating paths emanating from nodes. We derive three different variants of the PathNN model that aggregate single shortest paths, all shortest paths and all simple paths of length up to K. We prove that two of these variants are strictly more powerful than the 1-WL algorithm, and we experimentally validate our theoretical results. We find that PathNNs can distinguish pairs of non-isomorphic graphs that are indistinguishable by 1-WL, while our most expressive PathNN variant 
    
[^37]: 克服针对人机交互应用的对抗攻击

    Overcoming Adversarial Attacks for Human-in-the-Loop Applications. (arXiv:2306.05952v1 [cs.LG])

    [http://arxiv.org/abs/2306.05952](http://arxiv.org/abs/2306.05952)

    通过人类视觉注意力模型改善人机图像分析系统的可解释性和鲁棒性，克服针对人机交互应用的对抗攻击。

    

    包含人类分析可能对深度神经网络的强韧性产生积极影响，在对抗机器学习领域相对较少被探索。神经网络视觉解释图经常容易遭受对抗性攻击。为了让图像分析者评估给定模型，需要进一步研究选择稳健的解释可视化。这些因素极大地影响了人机交互（HITL）评估工具，因为它们依赖于对抗性图像，包括解释图和鲁棒性测量。我们相信，人类视觉注意力模型可以改善人机图像分析系统的可解释性和鲁棒性。我们面临的挑战是，在这种对抗性环境下，如何使HITL评估更加鲁棒。

    Including human analysis has the potential to positively affect the robustness of Deep Neural Networks and is relatively unexplored in the Adversarial Machine Learning literature. Neural network visual explanation maps have been shown to be prone to adversarial attacks. Further research is needed in order to select robust visualizations of explanations for the image analyst to evaluate a given model. These factors greatly impact Human-In-The-Loop (HITL) evaluation tools due to their reliance on adversarial images, including explanation maps and measurements of robustness. We believe models of human visual attention may improve interpretability and robustness of human-machine imagery analysis systems. Our challenge remains, how can HITL evaluation be robust in this adversarial landscape?
    
[^38]: 基于混合RidgeGAN模型的印度小中城市交通指数预测研究

    Prediction of Transportation Index for Urban Patterns in Small and Medium-sized Indian Cities using Hybrid RidgeGAN Model. (arXiv:2306.05951v1 [cs.LG])

    [http://arxiv.org/abs/2306.05951](http://arxiv.org/abs/2306.05951)

    本研究提出了一种基于混合RidgeGAN模型的交通指数预测方法，用于解决城市化带来的交通问题。实验结果显示，该方法在预测精度上显著优于传统回归模型。

    

    印度等大多数发展中国家的快速城市化趋势带来了大量社会问题，如绿地丧失、环境健康退化、清洁水资源短缺、空气污染、交通拥堵等。通过交通指数进行交通网络建模已被广泛应用于了解城市交通问题。因此，预测交通指数势在必行，以促进城市规划和交通管理的可持续性发展。本文提出了一个基于混合RidgeGAN模型的方法，用于预测印度小中城市的交通指数。其中，Ridge回归用于处理自变量之间的多重共线性，GAN架构用于生成合成训练数据集，以提高模型的准确性。通过对来自印度城市的真实世界数据集的实验证明了我们所提出的模型的性能。结论表明，与传统回归模型相比，混合RidgeGAN模型显著提高了预测精度。

    The rapid urbanization trend in most developing countries including India is creating a plethora of civic concerns such as loss of green space, degradation of environmental health, clean water availability, air pollution, traffic congestion leading to delays in vehicular transportation, etc. Transportation and network modeling through transportation indices have been widely used to understand transportation problems in the recent past. This necessitates predicting transportation indices to facilitate sustainable urban planning and traffic management. Recent advancements in deep learning research, in particular, Generative Adversarial Networks (GANs), and their modifications in spatial data analysis such as CityGAN, Conditional GAN, and MetroGAN have enabled urban planners to simulate hyper-realistic urban patterns. These synthetic urban universes mimic global urban patterns and evaluating their landscape structures through spatial pattern analysis can aid in comprehending landscape dyn
    
[^39]: 鲁棒的数据驱动处方优化

    Robust Data-driven Prescriptiveness Optimization. (arXiv:2306.05937v1 [math.OC])

    [http://arxiv.org/abs/2306.05937](http://arxiv.org/abs/2306.05937)

    本文提出了一种鲁棒的数据驱动优化模型，其中处方性系数代替了经验风险最小化目标，可用于确定最大化上下文决策质量和参考决策以及侧面信息处方能力的最佳策略。

    

    巨量的数据促进了各种优化技术的出现，旨在利用现有的侧面信息提供更具预判性的决策。广泛的方法和应用背景促进了设计一种称为处方性系数的通用无单位性能指标的产生。该系数旨在量化上下文决策的质量与参考决策以及侧面信息的处方能力。为了在数据驱动的情况下确定最大化前者的策略，本文引入了一种分布式鲁棒的上下文优化模型，其中处方性系数代替了经典的经验风险最小化目标。我们提出了一个双分法算法来解决这个模型，当分布不确定性集合具有适当的嵌套形式和多面体结构时，该算法依赖于解决一系列线性规划问题。本文研究了上下文短语的应用。

    The abundance of data has led to the emergence of a variety of optimization techniques that attempt to leverage available side information to provide more anticipative decisions. The wide range of methods and contexts of application have motivated the design of a universal unitless measure of performance known as the coefficient of prescriptiveness. This coefficient was designed to quantify both the quality of contextual decisions compared to a reference one and the prescriptive power of side information. To identify policies that maximize the former in a data-driven context, this paper introduces a distributionally robust contextual optimization model where the coefficient of prescriptiveness substitutes for the classical empirical risk minimization objective. We present a bisection algorithm to solve this model, which relies on solving a series of linear programs when the distributional ambiguity set has an appropriate nested form and polyhedral structure. Studying a contextual short
    
[^40]: 以说话人嵌入作为语音应激检测的个性代理

    Speaker Embeddings as Individuality Proxy for Voice Stress Detection. (arXiv:2306.05915v1 [eess.AS])

    [http://arxiv.org/abs/2306.05915](http://arxiv.org/abs/2306.05915)

    该论文使用来自不同语言组、背景各异的一百多名说话者训练了一种语音应激检测的方法，并在混合特征中添加个体差异性识别技术，成功地提高了检测性能。

    

    由于说话人的心理状态调节语音，因此认知或身体负荷引起的应激可以在语音中检测到。该论文提出了一种使用超过100名来自9个语言组和5种不同类型应激的说话人进行训练的语音应激检测的设计和开发。我们通过添加说话人嵌入到混合BYOL-S特征中来解决语音应激分析中的个体差异。该方法显著提高了声音应激检测性能，只需3-5秒的输入音频长度。

    Since the mental states of the speaker modulate speech, stress introduced by cognitive or physical loads could be detected in the voice. The existing voice stress detection benchmark has shown that the audio embeddings extracted from the Hybrid BYOL-S self-supervised model perform well. However, the benchmark only evaluates performance separately on each dataset, but does not evaluate performance across the different types of stress and different languages. Moreover, previous studies found strong individual differences in stress susceptibility. This paper presents the design and development of voice stress detection, trained on more than 100 speakers from 9 language groups and five different types of stress. We address individual variabilities in voice stress analysis by adding speaker embeddings to the hybrid BYOL-S features. The proposed method significantly improves voice stress detection performance with an input audio length of only 3-5 seconds.
    
[^41]: 2DeteCT -- 一个大型的可扩展、可训练的二维计算机断层扫描数据集，用于机器学习。

    2DeteCT -- A large 2D expandable, trainable, experimental Computed Tomography dataset for machine learning. (arXiv:2306.05907v1 [eess.IV])

    [http://arxiv.org/abs/2306.05907](http://arxiv.org/abs/2306.05907)

    该论文提供了一个大型、可扩展的二维计算机断层扫描数据集，用于开发各种图像重建任务的机器学习技术，填补了当前X射线计算机断层扫描数据集匮乏的现状。

    

    最近的计算成像研究主要集中在开发用于图像重建的机器学习技术上，这需要包含测量数据和地面真实图像的大规模训练数据集。然而，用于X射线计算机断层扫描（CT）的适当实验数据集很少，方法通常在模拟数据上开发和评估。我们通过提供一个多功能的、开放的二维扇形束CT数据集来填补这一空白，适用于开发各种图像重建任务的机器学习技术。为了获取此数据集，我们设计了一个复杂的、半自动的扫描程序，利用高度灵活的实验室X射线CT装置。扫描了一个具有高自然变异性的样本混合物，其形状和密度在每个切片上都有所不同（总共5000个切片），具有高角分辨率和空间分辨率，并具有三种不同的光束特征：高逼真度、低剂量和光束硬化。此外，还提供了750个分布外的样本，这些样本可用于测试新的数据增强技术。

    Recent research in computational imaging largely focuses on developing machine learning (ML) techniques for image reconstruction, which requires large-scale training datasets consisting of measurement data and ground-truth images. However, suitable experimental datasets for X-ray Computed Tomography (CT) are scarce, and methods are often developed and evaluated only on simulated data. We fill this gap by providing the community with a versatile, open 2D fan-beam CT dataset suitable for developing ML techniques for a range of image reconstruction tasks. To acquire it, we designed a sophisticated, semi-automatic scan procedure that utilizes a highly-flexible laboratory X-ray CT setup. A diverse mix of samples with high natural variability in shape and density was scanned slice-by-slice (5000 slices in total) with high angular and spatial resolution and three different beam characteristics: A high-fidelity, a low-dose and a beam-hardening-inflicted mode. In addition, 750 out-of-distributi
    
[^42]: TreeDQN: 学习如何最小化分支定界树

    TreeDQN: Learning to minimize Branch-and-Bound tree. (arXiv:2306.05905v1 [cs.LG])

    [http://arxiv.org/abs/2306.05905](http://arxiv.org/abs/2306.05905)

    TreeDQN提出了一种强化学习方法，可以学习到更加效率的分支启发式算法，减少了训练数据，并产生更小的子任务树。

    

    组合优化问题需要通过全面搜索才能找到最优解。分支定界是解决混合整数线性规划问题的方便方法。分支定界求解器将任务分成两个部分，将整数变量的域分成两个部分，然后递归地解决它们，产生一个嵌套子任务树。求解器的效率取决于用于选择分裂变量的分支启发式算法。在本研究中，我们提出了一种强化学习方法，可以有效地学习分支启发式算法。我们将变量选择任务视为树形马尔科夫决策过程，并证明了适用于树形马尔科夫决策过程的贝尔曼算子平均收缩，并提出了修改后的强化学习代理的学习目标。与之前的强化学习方法相比，我们的代理需要更少的训练数据，并产生更小的子任务树。

    Combinatorial optimization problems require an exhaustive search to find the optimal solution. A convenient approach to solving combinatorial optimization tasks in the form of Mixed Integer Linear Programs is Branch-and-Bound. Branch-and-Bound solver splits a task into two parts dividing the domain of an integer variable, then it solves them recursively, producing a tree of nested sub-tasks. The efficiency of the solver depends on the branchning heuristic used to select a variable for splitting. In the present work, we propose a reinforcement learning method that can efficiently learn the branching heuristic. We view the variable selection task as a tree Markov Decision Process, prove that the Bellman operator adapted for the tree Markov Decision Process is contracting in mean, and propose a modified learning objective for the reinforcement learning agent. Our agent requires less training data and produces smaller trees compared to previous reinforcement learning methods.
    
[^43]: C(NN)FD - 一种用于涡轮机械CFD分析的深度学习框架

    C(NN)FD -- a deep learning framework for turbomachinery CFD analysis. (arXiv:2306.05889v1 [cs.LG])

    [http://arxiv.org/abs/2306.05889](http://arxiv.org/abs/2306.05889)

    本文介绍了一种新型深度学习框架C(NN)FD，用于实时预测燃气轮机中轴向压缩机制造和组装变化对整体性能的影响。该框架可过滤掉CFD解决方案中的相关部分，因此具有可扩展性，且实时精度可与CFD基准相媲美。

    

    深度学习方法已经在不同工业领域得到广泛应用。迄今为止，对于诸如CFD（计算流体力学）的物理模拟的应用仅限于工业相关性较小的简单测试案例。本文展示了一种新型深度学习框架的开发，用于实时预测燃气轮机中轴向压缩机制造和组装变化对整体性能的影响，重点关注于叶片间隙的变化。效率的散布可以显著增加$CO_2$排放量，因此具有重要的工业和环境意义。所提出的C(NN)FD架构实时精度可与CFD基准相媲美。预测流场并使用其计算相应的整体性能使该方法具有普适性，而仅过滤CFD解决方案的相关部分使该方法可扩展到实际应用中。

    Deep Learning methods have seen a wide range of successful applications across different industries. Up until now, applications to physical simulations such as CFD (Computational Fluid Dynamics), have been limited to simple test-cases of minor industrial relevance. This paper demonstrates the development of a novel deep learning framework for real-time predictions of the impact of manufacturing and build variations on the overall performance of axial compressors in gas turbines, with a focus on tip clearance variations. The associated scatter in efficiency can significantly increase the $CO_2$ emissions, thus being of great industrial and environmental relevance. The proposed \textit{C(NN)FD} architecture achieves in real-time accuracy comparable to the CFD benchmark. Predicting the flow field and using it to calculate the corresponding overall performance renders the methodology generalisable, while filtering only relevant parts of the CFD solution makes the methodology scalable to in
    
[^44]: 基于Implicit Neural Representations的时间序列连续建模用于插值和预测

    Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations. (arXiv:2306.05880v1 [cs.LG])

    [http://arxiv.org/abs/2306.05880](http://arxiv.org/abs/2306.05880)

    该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。

    

    尽管时间序列建模已被广泛探索，但在面对真实世界的数据时仍面临重大挑战。我们提出了一种新颖的建模方法，利用Implicit Neural Representations (INR)。该方法使我们能够有效地捕捉时间序列的连续性，并提供了自然的解决方案，以处理缺失数据、处理不规则采样或来自多个传感器的不对准观测等重复建模问题。通过引入条件调制INR参数并利用元学习技术，我们解决了模型泛化到未见样本和时间窗口移位的问题。通过大量实验，我们的模型展示了在预测和插值任务中领先的性能，同时在处理许多竞争模型无法处理的各种具有挑战性的场景方面展现了灵活性。

    Although widely explored, time series modeling continues to encounter significant challenges when confronted with real-world data. We propose a novel modeling approach leveraging Implicit Neural Representations (INR). This approach enables us to effectively capture the continuous aspect of time series and provides a natural solution to recurring modeling issues such as handling missing data, dealing with irregular sampling, or unaligned observations from multiple sensors. By introducing conditional modulation of INR parameters and leveraging meta-learning techniques, we address the issue of generalization to both unseen samples and time window shifts. Through extensive experimentation, our model demonstrates state-of-the-art performance in forecasting and imputation tasks, while exhibiting flexibility in handling a wide range of challenging scenarios that competing models cannot.
    
[^45]: 多领域联邦学习是否离不开标准化?

    Is Normalization Indispensable for Multi-domain Federated Learning?. (arXiv:2306.05879v1 [cs.LG])

    [http://arxiv.org/abs/2306.05879](http://arxiv.org/abs/2306.05879)

    本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。

    

    联邦学习通过分散在客户端上的协作式内部训练增强了数据隐私。然而，联邦学习面临诸多挑战，其中包括非独立同分布数据（non-i.i.d）导致的潜在性能下降和收敛受阻问题。我们的研究解决了一个关键但常常被忽视的问题——多领域联邦学习。在这种情况下，客户端数据来源于具有不同特征分布的各种领域，而不是标签分布。为了解决联邦学习中的多领域问题，我们提出了一种新方法称为不使用规范化的联邦学习（FedWon）。FedWon从一个观察出发，即批量归一化（BN）在有效地建模多个领域的统计信息方面面临挑战，而替代规范化技术具有自身的局限性。FedWon通过消除规范化步骤来解决这些问题。

    Federated learning (FL) enhances data privacy with collaborative in-situ training on decentralized clients. Nevertheless, FL encounters challenges due to non-independent and identically distributed (non-i.i.d) data, leading to potential performance degradation and hindered convergence. While prior studies predominantly addressed the issue of skewed label distribution, our research addresses a crucial yet frequently overlooked problem known as multi-domain FL. In this scenario, clients' data originate from diverse domains with distinct feature distributions, as opposed to label distributions. To address the multi-domain problem in FL, we propose a novel method called Federated learning Without normalizations (FedWon). FedWon draws inspiration from the observation that batch normalization (BN) faces challenges in effectively modeling the statistics of multiple domains, while alternative normalization techniques possess their own limitations. In order to address these issues, FedWon elimi
    
[^46]: 检测深度强化学习中的对抗性方向以做出鲁棒决策

    Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions. (arXiv:2306.05873v1 [cs.LG])

    [http://arxiv.org/abs/2306.05873](http://arxiv.org/abs/2306.05873)

    该论文提出了一种检测非鲁棒方向的新方法，通过局域二次逼近来检测对抗性攻击，并为安全观测和对抗性观测之间的基本截止提供了理论基础。并且该方法是非常有效的，能成功检测到对抗性方向并做出鲁棒决策。

    

    随着强化学习算法的不断发展，现在可以在具有高度复杂状态表示的MDPs中进行学习。然而，这种复杂度的增加以及观测空间维度的增加都带来了易受对抗性攻击的波动。为了解决这个策略不稳定性问题，我们提出了一种新方法，通过对深度神经策略损失的局域二次逼近来检测这些非鲁棒方向的存在。我们的方法为安全观测和对抗性观测之间的基本截止提供了理论基础。此外，我们的技术具有计算上的效率，并且不依赖于生成最坏情况方向的方法。我们在Arcade Learning Environment中进行了大量的实验，使用了多种不同的对抗性攻击技术。最显着的是，我们的方法是非常有效的，能够成功检测到对抗性方向并做出相应的鲁棒决策。

    Learning in MDPs with highly complex state representations is currently possible due to multiple advancements in reinforcement learning algorithm design. However, this incline in complexity, and furthermore the increase in the dimensions of the observation came at the cost of volatility that can be taken advantage of via adversarial attacks (i.e. moving along worst-case directions in the observation space). To solve this policy instability problem we propose a novel method to detect the presence of these non-robust directions via local quadratic approximation of the deep neural policy loss. Our method provides a theoretical basis for the fundamental cut-off between safe observations and adversarial observations. Furthermore, our technique is computationally efficient, and does not depend on the methods used to produce the worst-case directions. We conduct extensive experiments in the Arcade Learning Environment with several different adversarial attack techniques. Most significantly, w
    
[^47]: 利用预测加速分离凸函数极小化：M-凸情况

    Faster Discrete Convex Function Minimization with Predictions: The M-Convex Case. (arXiv:2306.05865v1 [cs.LG])

    [http://arxiv.org/abs/2306.05865](http://arxiv.org/abs/2306.05865)

    本文提出了利用预测方法加速M-凸函数极小化的框架，特别适用于分层凸极小化等离散优化问题，并且能够较好地改善时间复杂度。

    

    近年来，越来越多的研究者将机器学习的预测方法应用于优化算法的加速。Sakaue和Oki（NeurIPS 2022）提出了一个通用框架，利用预测方法启动L-凸函数极小化方法，展示了这种方法在各种离散优化问题中的有效性。本文提出了一个利用预测方法加速M-凸函数极小化的框架，旨在补充以前的研究，扩展能从预测中受益的离散优化算法范围。我们的方法在重要子类——分层凸极小化中特别有效，该子类出现在许多运筹学应用中。我们的方法可以使用预测改善时间复杂度的最差情况下的结果，甚至有可能超过最低下界结果。

    Recent years have seen a growing interest in accelerating optimization algorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have developed a general framework that warm-starts the L-convex function minimization method with predictions, revealing the idea's usefulness for various discrete optimization problems. In this paper, we present a framework for using predictions to accelerate M-convex function minimization, thus complementing previous research and extending the range of discrete optimization algorithms that can benefit from predictions. Our framework is particularly effective for an important subclass called laminar convex minimization, which appears in many operations research applications. Our methods can improve time complexity bounds upon the best worst-case results by using predictions and even have potential to go beyond a lower-bound result.
    
[^48]: 联邦学习：减少通信次数！

    Federated Learning You May Communicate Less Often!. (arXiv:2306.05862v1 [stat.ML])

    [http://arxiv.org/abs/2306.05862](http://arxiv.org/abs/2306.05862)

    本研究针对联邦学习设定，探讨了通信次数对泛化误差的影响，并建立了PAC-Bayes和率失真理论限制，这些限制对广泛的损失函数和学习算法适用。

    

    本研究探讨了联邦学习(Federated Learning, FL)模型在一般性的设置下的泛化误差。具体来说，我们研究了客户端和参数服务器之间通信次数的泛化误差演变，即客户端计算的本地模型在参数服务器上合并的频率对泛化误差的影响。我们建立了PAC-Bayes和率失真理论对泛化误差的限制，明确考虑通信次数对误差的影响，另外还考虑了参与设备数量K和个人数据集大小n对误差的影响。这些限制适用于广泛的损失函数和学习算法，似乎是FL设置中首次出现的。此外，我们将我们的限制应用于FL类型的支持向量机(FSVM)；我们在这种情况下推导了更明确的泛化误差限制。

    We investigate the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, we study the evolution of the generalization error with the number of communication rounds between the clients and the parameter server, i.e., the effect on the generalization error of how often the local models as computed by the clients are aggregated at the parameter server. We establish PAC-Bayes and rate-distortion theoretic bounds on the generalization error that account explicitly for the effect of the number of rounds, say $ R \in \mathbb{N}$, in addition to the number of participating devices $K$ and individual datasets size $n$. The bounds, which apply in their generality for a large class of loss functions and learning algorithms, appear to be the first of their kind for the FL setting. Furthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and we derive (more) explicit bounds on the generalization error in this case. In particular, 
    
[^49]: 通过对抗核近似实现鲁棒强化学习

    Robust Reinforcement Learning via Adversarial Kernel Approximation. (arXiv:2306.05859v1 [cs.LG])

    [http://arxiv.org/abs/2306.05859](http://arxiv.org/abs/2306.05859)

    该论文提出了一种新奇的在线鲁棒强化学习方法，它通过近似对抗核并使用标准非鲁棒强化学习算法学习鲁棒策略，可应用于任何基础的强化学习算法之上，可以轻松扩展到高维度域。

    

    鲁棒性马尔可夫决策过程提供了一个框架，可以在转移核发生扰动的情况下进行序列决策。然而，在具有高维度域的现实在线环境中，鲁棒强化学习方法并不容易扩展。通过表征鲁棒性马尔可夫决策过程中的对抗核，我们提出一种新的在线鲁棒强化学习方法，它近似对抗核并使用标准（非鲁棒）的强化学习算法来学习一个鲁棒性方针。值得注意的是，我们的方法可以应用于任何基础的强化学习算法之上，可以实现对高维度域的轻松扩展。在经典控制任务、MinAtar和DeepMind控制套件中的实验中，我们的方法表现出了有效性和适用性。

    Robust Markov Decision Processes (RMDPs) provide a framework for sequential decision-making that is robust to perturbations on the transition kernel. However, robust reinforcement learning (RL) approaches in RMDPs do not scale well to realistic online settings with high-dimensional domains. By characterizing the adversarial kernel in RMDPs, we propose a novel approach for online robust RL that approximates the adversarial kernel and uses a standard (non-robust) RL algorithm to learn a robust policy. Notably, our approach can be applied on top of any underlying RL algorithm, enabling easy scaling to high-dimensional domains. Experiments in classic control tasks, MinAtar and DeepMind Control Suite demonstrate the effectiveness and the applicability of our method.
    
[^50]: 深度网络可以被剪枝到多么稀疏：几何视角下的研究

    How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])

    [http://arxiv.org/abs/2306.05857](http://arxiv.org/abs/2306.05857)

    本文从高维几何的角度，通过在原始损失函数中强制施加稀疏性约束，描述了深度网络剪枝比率的相变点，该点等于某些凸体的平方高斯宽度除以参数的原始维度。

    

    过度参数化是深度神经网络最重要的特征之一。虽然它可以提供出色的泛化性能，但同时也强加了重大的存储负担，因此有必要研究网络剪枝。一个自然而基本的问题是：我们能剪枝一个深度网络到多么稀疏（几乎不影响性能）？为了解决这个问题，本文采用了第一原理方法，具体地，只通过在原始损失函数中强制施加稀疏性约束，我们能够从高维几何的角度描述剪枝比率的尖锐相变点，该点对应于可行和不可行之间的边界。结果表明，剪枝比率的相变点等于某些凸体的平方高斯宽度，这些凸体是由$l_1$-规则化损失函数得出的，除以参数的原始维度。作为副产品，我们证明了剪枝过程中参数的分布性质。

    Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
    
[^51]: 在装配任务中，物体信息如何提高基于骨架的人类行为识别效果

    How Object Information Improves Skeleton-based Human Action Recognition in Assembly Tasks. (arXiv:2306.05844v1 [cs.CV])

    [http://arxiv.org/abs/2306.05844](http://arxiv.org/abs/2306.05844)

    本研究提出了一种将物体信息融入基于骨架的人类行为识别的新方法，以此来提高协作机器人在工业制造中的人机协作的效率。

    

    随着协作机器人 (cobots) 在工业制造中的应用不断增长，有效的人机协作需要人类行为识别能力的支持。骨架分析方法因其更好地适应不同人和环境而经常被使用。然而，仅处理骨架时，人与物体的交互信息将丢失。因此，本研究提出了一种将物体信息融入基于骨架的人类行为识别的新方法。本文通过将物体中心视为进一步的骨架关节，增强了两种先进方法。我们的实验使用了一个先进的实例分割模型对骨架关节与物体的预测进行了组合，结果表明，我们的方法大大改善了这些先进方法在装配数据集IKEA ASM上的性能。本研究为在工业制造中实现有效的人机协作以及骨架检测添加物体信息的好处提供了新思路。

    As the use of collaborative robots (cobots) in industrial manufacturing continues to grow, human action recognition for effective human-robot collaboration becomes increasingly important. This ability is crucial for cobots to act autonomously and assist in assembly tasks. Recently, skeleton-based approaches are often used as they tend to generalize better to different people and environments. However, when processing skeletons alone, information about the objects a human interacts with is lost. Therefore, we present a novel approach of integrating object information into skeleton-based action recognition. We enhance two state-of-the-art methods by treating object centers as further skeleton joints. Our experiments on the assembly dataset IKEA ASM show that our approach improves the performance of these state-of-the-art methods to a large extent when combining skeleton joints with objects predicted by a state-of-the-art instance segmentation model. Our research sheds light on the benefi
    
[^52]: 无领域偏见批量贝叶斯优化，通过贝叶斯积分处理多种约束条件

    Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature. (arXiv:2306.05843v1 [cs.LG])

    [http://arxiv.org/abs/2306.05843](http://arxiv.org/abs/2306.05843)

    本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。

    

    现实世界的优化问题通常具有多样的约束条件、离散和混合空间、高度可并行化等特点。同时，当存在未知约束时，例如在药物发现和动物实验安全性等领域，必须确立未知约束之后才能查询目标函数。现有工作通常仅针对上述某些特征而并非综合考虑。本文提出了cSOBER，一种基于SOBER算法的领域无关型谨慎并行主动采样器，考虑到了未知约束情况下的集成误差的影响并提出了处理方法，处理多种约束条件和未知约束查询拒绝的问题。

    Real-world optimisation problems often feature complex combinations of (1) diverse constraints, (2) discrete and mixed spaces, and are (3) highly parallelisable. (4) There are also cases where the objective function cannot be queried if unknown constraints are not satisfied, e.g. in drug discovery, safety on animal experiments (unknown constraints) must be established before human clinical trials (querying objective function) may proceed. However, most existing works target each of the above three problems in isolation and do not consider (4) unknown constraints with query rejection. For problems with diverse constraints and/or unconventional input spaces, it is difficult to apply these techniques as they are often mutually incompatible. We propose cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility under unknown constraints as a type of integration error that we can estimate. We propose 
    
[^53]: 基于同态映射的期望完全图表示

    Expectation-Complete Graph Representations with Homomorphisms. (arXiv:2306.05838v1 [cs.LG])

    [http://arxiv.org/abs/2306.05838](http://arxiv.org/abs/2306.05838)

    提出了一种基于同态映射的新型随机图嵌入方法，在期望的多项式时间内计算，能在期望中区分所有非同构图，具有高效的替代能力。

    

    我们研究了一种新颖的随机图嵌入，可以在期望的多项式时间内计算，并且能够在期望中区分所有非同构图。以前的图嵌入具有有限的表达能力，并且要么不能区分所有图，要么不能有效地计算每个图。为了能够在图上近似任意函数，我们对具有递增资源的高效替代方案感兴趣。我们的方法基于 Lov\'asz 对通过同态计数的无限维向量的图同构的表征。我们的实证评估显示了在几个基准图学习任务上具有竞争力的结果。

    We investigate novel random graph embeddings that can be computed in expected polynomial time and that are able to distinguish all non-isomorphic graphs in expectation. Previous graph embeddings have limited expressiveness and either cannot distinguish all graphs or cannot be computed efficiently for every graph. To be able to approximate arbitrary functions on graphs, we are interested in efficient alternatives that become arbitrarily expressive with increasing resources. Our approach is based on Lov\'asz' characterisation of graph isomorphism through an infinite dimensional vector of homomorphism counts. Our empirical evaluation shows competitive results on several benchmark graph learning tasks.
    
[^54]: 大型语言模型能否从相关性中推断出因果关系?

    Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v1 [cs.CL])

    [http://arxiv.org/abs/2306.05836](http://arxiv.org/abs/2306.05836)

    本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。

    

    因果推断是人类智慧的标志之一。虽然CausalNLP领域近年来引起了广泛关注，但NLP中现有的因果推断数据集主要依赖于从经验知识（例如常识知识）中发现因果关系。在本文中，我们提出了第一个基准数据集，用于测试大型语言模型（LLM）的纯因果推断能力。具体而言，我们制定了一个新的任务Corr2Cause，它采用一组相关语句并确定变量之间的因果关系。我们策划了一个大规模的数据集，其中包含超过400K个样本，我们在其中评估了17个现有的LLMs。通过我们的实验，我们确定了LLMs在因果推断技能方面的一个关键缺陷，并表明这些模型在该任务上的表现几乎接近随机。当我们尝试通过微调将LLMs重新用于这种技能时，这种缺陷在某种程度上得到了缓解，但我们发现这些模型仍然失败了。

    Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 400K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fa
    
[^55]: 通过对偶化扩展核主成分分析：稀疏性、鲁棒性和快速算法

    Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms. (arXiv:2306.05815v1 [cs.LG])

    [http://arxiv.org/abs/2306.05815](http://arxiv.org/abs/2306.05815)

    本文提出了一种对偶化扩展的核主成分分析方法，使KPCA自然地扩展到多目标函数，并导致避免计算格拉姆矩阵的昂贵SVD的高效梯度算法。该方法还能在同一框架内促进稳健性和稀疏性。

    

    本文旨在通过对偶化凸差函数，重新审视核主成分分析（KPCA）。这种方法使KPCA自然地扩展到多目标函数，并导致避免计算格拉姆矩阵的昂贵SVD的高效梯度算法。特别地，我们考虑可以写成Moreau包络的目标函数，演示如何在同一框架内促进稳健性和稀疏性。所提出的方法在合成和实际基准测试中进行了评估，显示出KPCA训练时间显著加速，而且在稳健性和稀疏性方面具有优势。

    The goal of this paper is to revisit Kernel Principal Component Analysis (KPCA) through dualization of a difference of convex functions. This allows to naturally extend KPCA to multiple objective functions and leads to efficient gradient-based algorithms avoiding the expensive SVD of the Gram matrix. Particularly, we consider objective functions that can be written as Moreau envelopes, demonstrating how to promote robustness and sparsity within the same framework. The proposed method is evaluated on synthetic and real-world benchmarks, showing significant speedup in KPCA training time as well as highlighting the benefits in terms of robustness and sparsity.
    
[^56]: 基于通路活性自编码器的深度学习模型中融入先验知识

    Incorporating Prior Knowledge in Deep Learning Models via Pathway Activity Autoencoders. (arXiv:2306.05813v1 [cs.LG])

    [http://arxiv.org/abs/2306.05813](http://arxiv.org/abs/2306.05813)

    本研究提出了一种基于先验知识的深度自编码框架PAAE，将生物通路信息融入深度学习模型，可提高对疾病的预测建模和个性化治疗策略。

    

    鉴于高通量分子分析技术（例如转录组学）的计算分析取得的进展，方法的简单性和可解释性与方法的复杂性和可解释性较低之间存在一种二分法。此外，很少有方法试图将解释性转化为生物学相关术语，例如已知的通路级联。生物学通路反映信号事件或代谢转化。通过确定哪些通路涉及疾病并将此类通路数据作为先验知识纳入可能增强预测建模和个性化诊断治疗和预防疾病策略的能力。

    Motivation: Despite advances in the computational analysis of high-throughput molecular profiling assays (e.g. transcriptomics), a dichotomy exists between methods that are simple and interpretable, and ones that are complex but with lower degree of interpretability. Furthermore, very few methods deal with trying to translate interpretability in biologically relevant terms, such as known pathway cascades. Biological pathways reflecting signalling events or metabolic conversions are Small improvements or modifications of existing algorithms will generally not be suitable, unless novel biological results have been predicted and verified. Determining which pathways are implicated in disease and incorporating such pathway data as prior knowledge may enhance predictive modelling and personalised strategies for diagnosis, treatment and prevention of disease.  Results: We propose a novel prior-knowledge-based deep auto-encoding framework, PAAE, together with its accompanying generative varian
    
[^57]: 使用gnomonic equiangular投影的生成对抗网络进行HRTF上采样

    HRTF upsampling with a generative adversarial network using a gnomonic equiangular projection. (arXiv:2306.05812v1 [eess.AS])

    [http://arxiv.org/abs/2306.05812](http://arxiv.org/abs/2306.05812)

    本文利用生成对抗网络（GANs）将HRTF上采样，提出一种新方法，该方法在性能方面优于传统方法，使带HRTF的虚拟现实（VR）和增强现实（AR）环境更加逼真。

    

    个性化的头部相关转移函数（HRTF）对于创建逼真的虚拟现实（VR）和增强现实（AR）环境至关重要。然而，声学测量高质量的HRTF需要昂贵的设备和声学实验室设置。为了克服这些限制并使测量更加高效，过去已经利用了HRTF上采样，其中从低分辨率的HRTF创建高分辨率的HRTF。本文展示了如何将生成对抗网络（GANs）应用于HRTF上采样。我们提出了一种新方法，将HRTF数据转换为与卷积超分辨率生成对抗网络（SRGAN）方便使用。这种新方法与两个基线进行了基准测试：重心上采样和HRTF选择方法。实验结果表明，所提出的方法在使用感知模型时，从log-spectral失真（LSD）和定位性能方面均优于两个基线。

    An individualised head-related transfer function (HRTF) is essential for creating realistic virtual reality (VR) and augmented reality (AR) environments. However, acoustically measuring high-quality HRTFs requires expensive equipment and an acoustic lab setting. To overcome these limitations and to make this measurement more efficient HRTF upsampling has been exploited in the past where a high-resolution HRTF is created from a low-resolution one. This paper demonstrates how generative adversarial networks (GANs) can be applied to HRTF upsampling. We propose a novel approach that transforms the HRTF data for convenient use with a convolutional super-resolution generative adversarial network (SRGAN). This new approach is benchmarked against two baselines: barycentric upsampling and a HRTF selection approach. Experimental results show that the proposed method outperforms both baselines in terms of log-spectral distortion (LSD) and localisation performance using perceptual models when the 
    
[^58]: 使用Shapley Values解释强化学习

    Explaining Reinforcement Learning with Shapley Values. (arXiv:2306.05810v1 [cs.LG])

    [http://arxiv.org/abs/2306.05810](http://arxiv.org/abs/2306.05810)

    该论文提出了一种使用Shapley值进行强化学习解释的方法，称之为Shapley Values for Explaining Reinforcement Learning (SVERL)，在实验中证明具有匹配并补充人类直觉的有意义解释效果。

    

    要想广泛采用强化学习系统，用户必须理解并信任它们。我们提出了使用Shapley值解释强化学习的理论分析，该分析遵循博弈论的原则，用于确定个体玩家对合作博弈结果的贡献。我们称之为Shapley Values for Explaining Reinforcement Learning (SVERL)的一般框架。我们的分析揭示了以前在强化学习中使用Shapley值的局限性，然后我们开发了一种使用Shapley值解释代理性能的方法。在各种领域中，SVERL提供了有意义的解释，匹配并补充了人类的直观认识。

    For reinforcement learning systems to be widely adopted, their users must understand and trust them. We present a theoretical analysis of explaining reinforcement learning using Shapley values, following a principled approach from game theory for identifying the contribution of individual players to the outcome of a cooperative game. We call this general framework Shapley Values for Explaining Reinforcement Learning (SVERL). Our analysis exposes the limitations of earlier uses of Shapley values in reinforcement learning. We then develop an approach that uses Shapley values to explain agent performance. In a variety of domains, SVERL produces meaningful explanations that match and supplement human intuition.
    
[^59]: RankFormer：使用列表标签的列表学习排序

    RankFormer: Listwise Learning-to-Rank Using Listwide Labels. (arXiv:2306.05808v1 [cs.IR])

    [http://arxiv.org/abs/2306.05808](http://arxiv.org/abs/2306.05808)

    RankFormer是一个可以利用列表标签进行列表学习排序的架构，并在多个最先进的LTR方法上展现了更好的表现。

    

    网络应用程序常常使用排序模型将最相关的结果排在前面，以呈现给用户有限的选择。通常假定从用户获得的反馈只反映了项目效用的相对评价，例如用户单击项目只暗示它比在同一排序列表中未单击的项目更好。因此，学习排序（LTR）中优化的目标往往是成对或按列表排序。然而，只看到相对反馈，我们忽视了用户对列表整体质量的绝对反馈，例如当选择中没有项目被单击时。因此，我们重新考虑了标准的LTR范式，并论述了从这种列表级信号中学习的好处。为此，我们提出了RankFormer作为一个带有Transformer核心的架构，可以共同优化新的列表评估目标和传统的按列表LTR目标。我们在公共数据集上模拟隐式反馈，并观察到RankFormer比几种最先进的LTR方法表现更好，从而证明了利用列表标签的有效性。

    Web applications where users are presented with a limited selection of items have long employed ranking models to put the most relevant results first. Any feedback received from users is typically assumed to reflect a relative judgement on the utility of items, e.g. a user clicking on an item only implies it is better than items not clicked in the same ranked list. Hence, the objectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.  Yet, by only viewing feedback as relative, we neglect the user's absolute feedback on the list's overall quality, e.g. when no items in the selection are clicked. We thus reconsider the standard LTR paradigm and argue the benefits of learning from this listwide signal. To this end, we propose the RankFormer as an architecture that, with a Transformer at its core, can jointly optimize a novel listwide assessment objective and a traditional listwise LTR objective.  We simulate implicit feedback on public datasets and observe that the Ra
    
[^60]: DynaBench: 从低分辨率数据中学习动力系统的基准数据集。

    DynaBench: A benchmark dataset for learning dynamical systems from low-resolution data. (arXiv:2306.05805v1 [cs.LG])

    [http://arxiv.org/abs/2306.05805](http://arxiv.org/abs/2306.05805)

    DynaBench是一个新的模拟基准数据集，用于直接从低分辨率的稀疏数据中学习动力系统，评估了多个机器学习模型的预测性能。

    

    先前从数据中学习物理系统的工作侧重于高分辨率网格结构测量。但是，现实世界中这种系统的知识（例如天气数据）依赖于稀疏分布的测量站。在本文中，我们介绍了一个新颖的模拟基准数据集DynaBench，用于直接从稀疏散布的数据中学习动力系统，不需要先前了解该方程式。该数据集专注于预测动力系统的演变，使用低分辨率、非结构化的测量方式。我们模拟了六个不同的偏微分方程，涵盖了文献中常用的各种物理系统，并评估了多个机器学习模型，包括传统的图神经网络和点云处理模型，以预测系统的演变。该基准数据集可以期望成为一种开箱即用的工具，用于评估模型性能。

    Previous work on learning physical systems from data has focused on high-resolution grid-structured measurements. However, real-world knowledge of such systems (e.g. weather data) relies on sparsely scattered measuring stations. In this paper, we introduce a novel simulated benchmark dataset, DynaBench, for learning dynamical systems directly from sparsely scattered data without prior knowledge of the equations. The dataset focuses on predicting the evolution of a dynamical system from low-resolution, unstructured measurements. We simulate six different partial differential equations covering a variety of physical systems commonly used in the literature and evaluate several machine learning models, including traditional graph neural networks and point cloud processing models, with the task of predicting the evolution of the system. The proposed benchmark dataset is expected to advance the state of art as an out-of-the-box easy-to-use tool for evaluating models in a setting where only u
    
[^61]: 情感和加密货币价格之间的因果关系

    Causality between Sentiment and Cryptocurrency Prices. (arXiv:2306.05803v1 [q-fin.CP])

    [http://arxiv.org/abs/2306.05803](http://arxiv.org/abs/2306.05803)

    本研究通过将主题建模和情感分析相结合，建立了关于加密货币的多个叙述，并发现这些叙述与加密货币价格之间存在强大的联系。

    

    本研究调查了微博平台（Twitter）传递的叙述与加密资产价值之间的关系。我们的研究采用了一种独特的技术，将短文本的主题建模与情感分析相结合，建立了关于加密货币的叙述。首先，我们使用了一种无监督的机器学习算法，从Twitter的大规模和嘈杂文本数据中发现潜在主题，然后我们揭示了4-5个与加密货币相关的叙述，包括与加密货币相关的金融投资、技术进步、金融和政治监管、加密资产和媒体报道。在许多情况下，我们注意到我们的叙述与加密货币价格之间存在强大的联系。我们的工作将最新的经济学创新——叙事经济学与主题建模和情感分析相结合的新领域联系起来，以关联消费者行为和叙述。

    This study investigates the relationship between narratives conveyed through microblogging platforms, namely Twitter, and the value of crypto assets. Our study provides a unique technique to build narratives about cryptocurrency by combining topic modelling of short texts with sentiment analysis. First, we used an unsupervised machine learning algorithm to discover the latent topics within the massive and noisy textual data from Twitter, and then we revealed 4-5 cryptocurrency-related narratives, including financial investment, technological advancement related to crypto, financial and political regulations, crypto assets, and media coverage. In a number of situations, we noticed a strong link between our narratives and crypto prices. Our work connects the most recent innovation in economics, Narrative Economics, to a new area of study that combines topic modelling and sentiment analysis to relate consumer behaviour to narratives.
    
[^62]: 处理异常值和重尾分布的双层直方图

    Two-level histograms for dealing with outliers and heavy tail distributions. (arXiv:2306.05786v1 [cs.LG])

    [http://arxiv.org/abs/2306.05786](http://arxiv.org/abs/2306.05786)

    本文介绍G-Enum直方图方法，它利用MDL原则构建直方图，在非常准确的情况下,无需任何用户参数，并在异常值或重尾分布情况下提出一种双层启发式方法

    

    直方图是在探索性分析中用于总结一元分布的最流行方法之一。尤其是不规则的直方图是良好的非参数密度估计量，其仅需要极少的参数：频率和带有长度的箱数。至今已经有许多方法被提出用于推断这些参数，有些采用对基础数据分布的模型假设，有些则用特定的模型选择方法。本文关注的是G-Enum直方图方法，其采用最小描述长度（MDL）法建立直方图，不需要任何用户参数，并且在准确性、简洁性和计算时间方面达到了最先进的性能表现。该方法在异常值或重尾分布情况下存在局限性，因此我们提出了一种双层启发式方法来处理这些情况。 第一层利用数据的对数变换将数据集分为数据子集列表

    Histograms are among the most popular methods used in exploratory analysis to summarize univariate distributions. In particular, irregular histograms are good non-parametric density estimators that require very few parameters: the number of bins with their lengths and frequencies. Many approaches have been proposed in the literature to infer these parameters, either assuming hypotheses about the underlying data distributions or exploiting a model selection approach. In this paper, we focus on the G-Enum histogram method, which exploits the Minimum Description Length (MDL) principle to build histograms without any user parameter and achieves state-of-the art performance w.r.t accuracy; parsimony and computation time. We investigate on the limits of this method in the case of outliers or heavy-tailed distributions. We suggest a two-level heuristic to deal with such cases. The first level exploits a logarithmic transformation of the data to split the data set into a list of data subsets w
    
[^63]: 通过$\frac{\ell_1}{\ell_2}$正则化延迟代理进行端到端神经网络压缩

    End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$ Regularized Latency Surrogates. (arXiv:2306.05785v1 [cs.LG])

    [http://arxiv.org/abs/2306.05785](http://arxiv.org/abs/2306.05785)

    提出了一种端到端的神经网络压缩技术，通过优化模型的浮点运算量或设备延迟来自动设置压缩超参数。算法速度快，并且可以与多种常用压缩方法一起使用，如剪枝、低秩分解和量化。在GLUE微调任务的BERT压缩中，FLOPs可降低50％，且性能仅下降1％；而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。

    

    神经网络（NN）的压缩通常需要手动或通过神经网络结构搜索（NAS）设置每个层的压缩超参数（例如，要剪枝的通道数，量化的位宽），这可能会耗费大量计算资源。我们提供了一种端到端技术，通过新颖的$\frac{\ell_1}{\ell_2}$延迟代理优化模型的浮点运算量（FLOPs）或设备延迟来解决此问题。我们的算法非常灵活，可以与许多常用的压缩方法（包括剪枝、低秩分解和量化）一起使用。关键是，它非常快速，几乎与单模型训练相同的时间，这比标准NAS方法可节省大量的训练时间。在GLUE微调任务的BERT压缩中，我们的算法可以使FLOPs降低50％，仅损失1％的性能。而在ImageNet-1K上对MobileNetV3进行压缩，则可以使FLOPs降低15％，同时性能基本不损失。

    Neural network (NN) compression via techniques such as pruning, quantization requires setting compression hyperparameters (e.g., number of channels to be pruned, bitwidths for quantization) for each layer either manually or via neural architecture search (NAS) which can be computationally expensive. We address this problem by providing an end-to-end technique that optimizes for model's Floating Point Operations (FLOPs) or for on-device latency via a novel $\frac{\ell_1}{\ell_2}$ latency surrogate. Our algorithm is versatile and can be used with many popular compression methods including pruning, low-rank factorization, and quantization. Crucially, it is fast and runs in almost the same amount of time as single model training; which is a significant training speed-up over standard NAS methods. For BERT compression on GLUE fine-tuning tasks, we achieve $50\%$ reduction in FLOPs with only $1\%$ drop in performance. For compressing MobileNetV3 on ImageNet-1K, we achieve $15\%$ reduction in
    
[^64]: 数量化墨水分析：基于高光谱成像估计文件中的墨水数量

    Quantitative Ink Analysis: Estimating the Number of Inks in Documents through Hyperspectral Imaging. (arXiv:2306.05784v1 [cs.LG])

    [http://arxiv.org/abs/2306.05784](http://arxiv.org/abs/2306.05784)

    本文提出了一种使用高光谱成像的墨水分析技术，可以有效地识别墨水聚类和区分不同的墨水，以此来确定文档中使用的不同墨水的数量。

    

    在文件取证领域，墨水分析在确定法律和历史文件的真实性以及检测伪造方面发挥着至关重要的作用。仅凭目视检查无法区分外观相似的墨水，必须采用先进的科学技术。本文提出了一种基于高光谱成像的墨水分析技术，可以在数百个狭窄的光谱带中检查文件，揭示隐藏的细节。本研究的主要目标是确定文档中使用的不同墨水的数量。采用了三种聚类算法，即k-means，Agglomerative和c-means，以估计存在的墨水数量。该方法涉及数据提取，墨水像素分割和墨水数确定。结果表明，所提出的技术在识别墨水聚类和区分不同墨水方面具有很好的效果。高光谱立方数据集的分析揭示了......（未完待续）

    In the field of document forensics, ink analysis plays a crucial role in determining the authenticity of legal and historic documents and detecting forgery. Visual examination alone is insufficient for distinguishing visually similar inks, necessitating the use of advanced scientific techniques. This paper proposes an ink analysis technique based on hyperspectral imaging, which enables the examination of documents in hundreds of narrowly spaced spectral bands, revealing hidden details. The main objective of this study is to identify the number of distinct inks used in a document. Three clustering algorithms, namely k-means, Agglomerative, and c-means, are employed to estimate the number of inks present. The methodology involves data extraction, ink pixel segmentation, and ink number determination. The results demonstrate the effectiveness of the proposed technique in identifying ink clusters and distinguishing between different inks. The analysis of a hyperspectral cube dataset reveals
    
[^65]: 因果图发现的适应性复杂度

    Adaptivity Complexity for Causal Graph Discovery. (arXiv:2306.05781v1 [cs.LG])

    [http://arxiv.org/abs/2306.05781](http://arxiv.org/abs/2306.05781)

    研究了因果图发现的适应性复杂度，提供了一个r-adaptive算法在最小化总干预次数的同时正确学习出因果图。

    

    因果发现是一个重要的问题，其中任务是设计一个干预策略，在最小化执行干预的数量的同时学习包含n个节点的因果图。本文研究了对于总共$r$个顺序回合，算法设计师如何在最小化总干预次数的同时恢复因果图的$r$适应性问题。对于这个问题，我们提供了一个$r$-adaptive算法，该算法在$O(n^2 2^r)$的总干预次数下，以高概率正确地学习$n$个节点的因果图，并证明了这个界限是最佳的。

    Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive
    
[^66]: 基于Transformer的慢性肾脏疾病恶化时间预测

    Transformer-based Time-to-Event Prediction for Chronic Kidney Disease Deterioration. (arXiv:2306.05779v1 [cs.LG])

    [http://arxiv.org/abs/2306.05779](http://arxiv.org/abs/2306.05779)

    本论文提出了基于Transformer的STRAFE模型，用于慢性肾脏疾病恶化时间的生存分析预测，并在真实数据集上进行了验证，表明其在预测特定事件的确切时间方面具有较好性能。

    

    深度学习技术，尤其是Transformer模型，已在增强纵向健康记录的预测性能方面显示出巨大潜力。虽然先前的方法主要集中在固定时间风险预测上，但时间到达事件预测（也称为生存分析）往往更适合于临床场景。在这里，我们提出了一个新的深度学习架构，名为STRAFE，这是一种基于Transformer的通用生存分析体系结构，用于电子健康记录。使用超过130,000人的真实世界索赔数据集评估了STRAFE的性能，这些人患有3期慢性肾脏疾病（CKD），发现其在预测到达5期的恶化的确切时间方面优于其他时间到达事件预测算法。此外，STRAFE在预测固定时间风险方面也优于二元结果算法，可能是由于其能够对被审查数据进行训练的能力。我们展示STRAFE的预测可以提高阳性预测。

    Deep-learning techniques, particularly the transformer model, have shown great potential in enhancing the prediction performance of longitudinal health records. While previous methods have mainly focused on fixed-time risk prediction, time-to-event prediction (also known as survival analysis) is often more appropriate for clinical scenarios. Here, we present a novel deep-learning architecture we named STRAFE, a generalizable survival analysis transformer-based architecture for electronic health records. The performance of STRAFE was evaluated using a real-world claim dataset of over 130,000 individuals with stage 3 chronic kidney disease (CKD) and was found to outperform other time-to-event prediction algorithms in predicting the exact time of deterioration to stage 5. Additionally, STRAFE was found to outperform binary outcome algorithms in predicting fixed-time risk, possibly due to its ability to train on censored data. We show that STRAFE predictions can improve the positive predic
    
[^67]: 变分量子算法的权重重新映射

    Weight Re-Mapping for Variational Quantum Algorithms. (arXiv:2306.05776v1 [quant-ph])

    [http://arxiv.org/abs/2306.05776](http://arxiv.org/abs/2306.05776)

    我们使用权重重新映射的方法来改进变分量子电路(VQC)的训练，以解决当前的基于梯度的VQC训练方法无法充分考虑量子计算中可训练参数(或权重)的问题。在我们的研究中，我们使用了七种不同的权重重新映射函数来评估它们的实现效果。

    

    受人工神经网络在广泛AI任务中的卓越成功启发，变分量子电路(VQCs)最近在量子机器学习应用方面出现了一波高潮。VQC所展示出的有希望的结果，如改进的泛化和减少的参数训练要求，归功于量子计算的强大算法能力。然而，目前的基于梯度的VQC训练方法没有充分考虑到可训练参数(或权重)通常被用作旋转门中的角度这一事实。为了解决这个问题，我们扩展了Kolle等人引入的VQC权重重新映射概念。这种方法明确地将权重映射到长度为$2\pi$的区间，镜像常规机器学习中已被证明在众多场景中非常有益的数据重新缩放技术。在我们的研究中，我们使用了七种不同的权重重新映射函数来评估它们的实现效果。

    Inspired by the remarkable success of artificial neural networks across a broad spectrum of AI tasks, variational quantum circuits (VQCs) have recently seen an upsurge in quantum machine learning applications. The promising outcomes shown by VQCs, such as improved generalization and reduced parameter training requirements, are attributed to the robust algorithmic capabilities of quantum computing. However, the current gradient-based training approaches for VQCs do not adequately accommodate the fact that trainable parameters (or weights) are typically used as angles in rotational gates. To address this, we extend the concept of weight re-mapping for VQCs, as introduced by K\"olle et al. (2023). This approach unambiguously maps the weights to an interval of length $2\pi$, mirroring data rescaling techniques in conventional machine learning that have proven to be highly beneficial in numerous scenarios. In our study, we employ seven distinct weight re-mapping functions to assess their im
    
[^68]: 权重冻结：一种正则化方法在脑电分类中的应用

    Weight Freezing: A Regularization Approach for Fully Connected Layers with an Application in EEG Classification. (arXiv:2306.05775v1 [cs.LG])

    [http://arxiv.org/abs/2306.05775](http://arxiv.org/abs/2306.05775)

    本文提出了一种新颖的方法，权重冻结，它可以有效地减少全连接层中的特定神经元对特定EEG任务的决策过程的影响，从而提高人工神经网络（ANNs）的性能，是一种有效的正则化方法。

    

    在脑电解码领域，提高人工神经网络（ANNs）的性能具有重要的潜力。本研究介绍了一种新颖的方法，称为“权重冻结”，该方法基于ANN正则化和神经科学先验知识的原则。权重冻结的概念围绕着通过冻结全连接层中的特定权重来减少某些神经元对特定EEG任务的决策过程的影响。这是通过使用掩码矩阵和阈值来确定在反向传播过程中需要冻结的权重比例来实现的。此外，通过将被掩蔽的权重设置为零，权重冻结不仅可以在具有全连接层分类器的网络中实现稀疏连接，还可以作为全连接层的有效正则化方法。

    In the realm of EEG decoding, enhancing the performance of artificial neural networks (ANNs) carries significant potential. This study introduces a novel approach, termed "weight freezing", that is anchored on the principles of ANN regularization and neuroscience prior knowledge. The concept of weight freezing revolves around the idea of reducing certain neurons' influence on the decision-making process for a specific EEG task by freezing specific weights in the fully connected layer during the backpropagation process. This is actualized through the use of a mask matrix and a threshold to determine the proportion of weights to be frozen during backpropagation. Moreover, by setting the masked weights to zero, weight freezing can not only realize sparse connections in networks with a fully connected layer as the classifier but also function as an efficacious regularization method for fully connected layers. Through experiments involving three distinct ANN architectures and three widely r
    
[^69]: 自定进度绝对学习作为课程学习的规则方法

    Self-Paced Absolute Learning Progress as a Regularized Approach to Curriculum Learning. (arXiv:2306.05769v1 [cs.LG])

    [http://arxiv.org/abs/2306.05769](http://arxiv.org/abs/2306.05769)

    自定进度绝对学习作为课程学习的规则方法，通过引入基于自定进度（深度）学习的新正则化方法，称为自定进度绝对学习进展（SPALP），解决了绝对学习进展（ALP）在重复已学习的行为上浪费计算资源的问题。

    

    强化学习的可用性受到其所需的大量计算时间的限制。课程强化学习通过定义帮助智能体遇到任务的有用顺序（即从简单到难），加速学习。基于绝对学习进展（ALP）的课程在不同环境中已被证明成功，但浪费计算资源在新任务中重复已学习的行为。我们通过引入基于自定进度（深度）学习的新正则化方法，称为自定进度绝对学习进展（SPALP），解决了这个问题。我们在三个不同的环境中评估了我们的方法。在所有情况下，我们的方法的效果与原始ALP相当，并且在其中两种情况下更快地达到了ALP的效果。我们还阐述了进一步提高SPALP效率和性能的可能性。

    The usability of Reinforcement Learning is restricted by the large computation times it requires. Curriculum Reinforcement Learning speeds up learning by defining a helpful order in which an agent encounters tasks, i.e. from simple to hard. Curricula based on Absolute Learning Progress (ALP) have proven successful in different environments, but waste computation on repeating already learned behaviour in new tasks. We solve this problem by introducing a new regularization method based on Self-Paced (Deep) Learning, called Self-Paced Absolute Learning Progress (SPALP). We evaluate our method in three different environments. Our method achieves performance comparable to original ALP in all cases, and reaches it quicker than ALP in two of them. We illustrate possibilities to further improve the efficiency and performance of SPALP.
    
[^70]: 公平但渐近相等的协作学习

    Fair yet Asymptotically Equal Collaborative Learning. (arXiv:2306.05764v1 [cs.LG])

    [http://arxiv.org/abs/2306.05764](http://arxiv.org/abs/2306.05764)

    本文探讨了一种公平的协作学习激励设计，避免了“富者越富”的现象，并为较少资源的节点提供了长期平等的机会。

    

    在流数据的协作学习中，节点（例如组织）通过共享从其最新流数据计算出的最新模型更新来共同持续学习机器学习（ML）模型。为了更有资源的节点愿意共享其模型更新，他们需要得到公平的激励。本文探讨了一种激励设计，保证公平，使节点获得与其贡献相称的奖励。我们的方法利用探索-利用的形式估计节点的贡献（即探索），实现了理论上保证的公正激励（即利用）。然而，我们观察到现有的保证公平的方法中出现了“富者越富”的现象，这阻碍了资源较少的节点的参与。为了解决这个问题，我们另外保持渐近平等，即较少资源的节点最终实现与较有资源的“富”节点相等的性能。

    In collaborative learning with streaming data, nodes (e.g., organizations) jointly and continuously learn a machine learning (ML) model by sharing the latest model updates computed from their latest streaming data. For the more resourceful nodes to be willing to share their model updates, they need to be fairly incentivized. This paper explores an incentive design that guarantees fairness so that nodes receive rewards commensurate to their contributions. Our approach leverages an explore-then-exploit formulation to estimate the nodes' contributions (i.e., exploration) for realizing our theoretically guaranteed fair incentives (i.e., exploitation). However, we observe a "rich get richer" phenomenon arising from the existing approaches to guarantee fairness and it discourages the participation of the less resourceful nodes. To remedy this, we additionally preserve asymptotic equality, i.e., less resourceful nodes achieve equal performance eventually to the more resourceful/"rich" nodes. 
    
[^71]: 通过分位数回归推进反事实推断

    Advancing Counterfactual Inference through Quantile Regression. (arXiv:2306.05751v1 [cs.LG])

    [http://arxiv.org/abs/2306.05751](http://arxiv.org/abs/2306.05751)

    本文提出一种基于分位数回归的反事实推断方法，旨在用于缺乏因果模型和直接条件分布估计的情况，并能提供估计结果的泛化能力和泛化误差上界。

    

    应对反事实“假设”问题的能力对于理解和利用因果影响至关重要。传统的反事实推断通常假定存在结构性因果模型。然而，在实践中，这样的因果模型通常是未知的，甚至不可辨识的。本文旨在基于（学习到的）定性因果结构和观测数据，不需要给定因果模型甚至不需要直接估计条件分布，就能进行可靠的反事实推断。我们使用神经网络将反事实推理重新转化为一个扩展分位数回归问题。这种方法在统计上比现有方法更有效，并且进一步使得估计的反事实结果对未见数据具有一定的泛化能力，并提供了泛化误差的上界。多个数据集上的实验结果强烈支持我们的理论贡献。

    The capacity to address counterfactual "what if" inquiries is crucial for understanding and making use of causal influences. Traditional counterfactual inference usually assumes a structural causal model is available. However, in practice, such a causal model is often unknown and may not be identifiable. This paper aims to perform reliable counterfactual inference based on the (learned) qualitative causal structure and observational data, without a given causal model or even directly estimating conditional distributions. We re-cast counterfactual reasoning as an extended quantile regression problem using neural networks. The approach is statistically more efficient than existing ones, and further makes it possible to develop the generalization ability of the estimated counterfactual outcome to unseen data and provide an upper bound on the generalization error. Experiment results on multiple datasets strongly support our theoretical claims.
    
[^72]: 基于约束编程的作业车间调度问题的端到端强化学习方法

    An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling Problems Based on Constraint Programming. (arXiv:2306.05747v1 [cs.AI])

    [http://arxiv.org/abs/2306.05747](http://arxiv.org/abs/2306.05747)

    本文提出了一种新颖的基于约束编程和强化学习的端到端方法，通过通用CP编码、约束条件和反映JSSP最优标准的奖励函数，可为大型作业车间调度问题产生最优或近似最优解。

    

    约束编程(CP)是一种声明式编程范例，可用于建模和解决组合优化问题，如作业车间调度问题(JSSP)。虽然CP求解器能够找到小实例的最优或近似最优解，但它们不适用于大实例，即需要长时间计算或产生低质量解。因此，实际调度应用经常采用快速手工制作的基于优先级的调度启发式方法以找到良好的初始解，并使用优化方法对其进行优化。本文提出了一种新颖的端到端方法，通过CP和强化学习(RL)来解决调度问题。与先前针对特定问题定制的RL方法不同，包括过程模拟算法、复杂的特征工程或手工制作的奖励函数，我们的神经网络架构和训练算法仅需要某些调度问题的通用CP编码、一小组问题特定约束条件和反映JSSP最优标准的奖励函数。对几个JSSP基准测试结果表明，我们的方法与最先进的RL和CP方法竞争，并且通常可以在很短时间内为大型实例产生最优或近似最优解。

    Constraint Programming (CP) is a declarative programming paradigm that allows for modeling and solving combinatorial optimization problems, such as the Job-Shop Scheduling Problem (JSSP). While CP solvers manage to find optimal or near-optimal solutions for small instances, they do not scale well to large ones, i.e., they require long computation times or yield low-quality solutions. Therefore, real-world scheduling applications often resort to fast, handcrafted, priority-based dispatching heuristics to find a good initial solution and then refine it using optimization methods.  This paper proposes a novel end-to-end approach to solving scheduling problems by means of CP and Reinforcement Learning (RL). In contrast to previous RL methods, tailored for a given problem by including procedural simulation algorithms, complex feature engineering, or handcrafted reward functions, our neural-network architecture and training algorithm merely require a generic CP encoding of some scheduling pr
    
[^73]: 两个独立训练器是更好的模范

    Two Independent Teachers are Better Role Model. (arXiv:2306.05745v1 [eess.IV])

    [http://arxiv.org/abs/2306.05745](http://arxiv.org/abs/2306.05745)

    提出了一种名为3D-DenseUNet的新深度学习模型，该模型采用自适应全局聚合块和自注意模块，以解决半监督技术中的效率和效果问题，同时通过训练两个独立的训练器处理不同的组织特性，在婴儿脑部分析中取得更好的结果。

    

    最近深度学习模型在婴儿脑部分析中引起了巨大的关注。这些模型表现出最先进的性能，例如半监督技术（例如，时间集成，平均教师）。然而，这些模型依赖于编码器-解码器结构，用堆叠的局部运算符来收集远程信息，而局部运算符限制了效率和效果。此外，MRI数据包含不同的组织特性（TPs），例如T1和T2。这些模型的一个主要限制是，它们将两种数据都作为输入用于分割过程，即模型一次训练于数据集，推断过程中需要大量的计算和存储空间。在本文中，我们通过设计一个名为3D-DenseUNet的新深度学习模型来解决上述限制，其作为自适应全局聚合块在下采样中工作以解决空间信息丢失的问题。自注意模块将下采样层与上采样层连接在一起，以收集远程信息。此外，我们提出的模型通过训练两个独立的训练器处理不同的组织特性，并取得比当前最先进模型更好的结果。

    Recent deep learning models have attracted substantial attention in infant brain analysis. These models have performed state-of-the-art performance, such as semi-supervised techniques (e.g., Temporal Ensembling, mean teacher). However, these models depend on an encoder-decoder structure with stacked local operators to gather long-range information, and the local operators limit the efficiency and effectiveness. Besides, the $MRI$ data contain different tissue properties ($TPs$) such as $T1$ and $T2$. One major limitation of these models is that they use both data as inputs to the segment process, i.e., the models are trained on the dataset once, and it requires much computational and memory requirements during inference. In this work, we address the above limitations by designing a new deep-learning model, called 3D-DenseUNet, which works as adaptable global aggregation blocks in down-sampling to solve the issue of spatial information loss. The self-attention module connects the down-s
    
[^74]: 跃迁于树空间：连续的树形系统推断方法用于有根和无根树

    Leaping through tree space: continuous phylogenetic inference for rooted and unrooted trees. (arXiv:2306.05739v1 [q-bio.PE])

    [http://arxiv.org/abs/2306.05739](http://arxiv.org/abs/2306.05739)

    本研究首次在连续空间中进行树形系统探索和推断，用于有根和无根树，优于当前最佳方法并在实验中证明了其效果，可用于加速生命科学的新进化发现。

    

    生物进化系统学现在是生命科学中的一个基础，可以阐明生命早期支系和传染病的起源和传播。然而，从可能的树的广阔空间中找到合适的系统树仍然具有挑战性。为了解决这个问题，我们首次在连续空间中进行了树形系统探索和推断，使梯度计算成为可能。这种连续的放松方式允许在有根和无根树中跨越树空间，且不易收敛到局部最小值。我们的方法优于当前最佳的无根树推断方法，并且在模拟中准确地推断出树和树根。该方法在实际数据中也很有效，我们在颌口动物的系统发育中证明了这一点。事实上，仅具有超指数信号的少数基因通常足以分辨脊椎动物的主要谱系。通过我们的方法，我们希望加速发现生命科学中的新进化发现。

    Phylogenetics is now fundamental in life sciences, providing insights into the earliest branches of life and the origins and spread of epidemics. However, finding suitable phylogenies from the vast space of possible trees remains challenging. To address this problem, for the first time, we perform both tree exploration and inference in a continuous space where the computation of gradients is possible. This continuous relaxation allows for major leaps across tree space in both rooted and unrooted trees, and is less susceptible to convergence to local minima. Our approach outperforms the current best methods for inference on unrooted trees and, in simulation, accurately infers the tree and root in ultrametric cases. The approach is effective in cases of empirical data with negligible amounts of data, which we demonstrate on the phylogeny of jawed vertebrates. Indeed, only a few genes with an ultrametric signal were generally sufficient for resolving the major lineages of vertebrate. With
    
[^75]: DP-HyPO: 一种自适应的私有超参数优化框架

    DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework. (arXiv:2306.05734v1 [cs.LG])

    [http://arxiv.org/abs/2306.05734](http://arxiv.org/abs/2306.05734)

    DP-HyPO 是一种自适应的、隐私保护的超参数优化框架，采用最先进的差分隐私高斯过程方法，提出了量身定制的优化启发式方法，保证隐私和效率，在保持强大隐私保证的同时实现了与非私有自适应优化方法相当的性能。

    

    超参数优化是提高模型性能的广泛认可的技术。然而，在训练私有的机器学习模型时，许多从业者经常忽视与超参数优化相关的隐私风险，这可能会暴露有关底层数据集的敏感信息。目前，唯一现有的允许隐私保护超参数优化的方法是随机选择一些超参数进行多次运行，并最终报告最佳超参数。相比之下，在非私有设置中，从业者通常使用“自适应”超参数优化方法，如基于高斯过程的优化，该优化方法基于先前输出收集的信息选择下一个候选项。这种私有和非私有超参数优化之间的巨大差异凸显出一个关键问题。在本文中，我们介绍了DP-HyPO，一种提供自适应和隐私保护超参数优化的开创性框架。DP-HyPO采用最先进的差分隐私高斯过程方法，并提出了量身定制的优化启发式方法，保证隐私和效率，并且在保持强大隐私保证的同时实现了与非私有自适应优化方法相当的性能。

    Hyperparameter optimization, also known as hyperparameter tuning, is a widely recognized technique for improving model performance. Regrettably, when training private ML models, many practitioners often overlook the privacy risks associated with hyperparameter optimization, which could potentially expose sensitive information about the underlying dataset. Currently, the sole existing approach to allow privacy-preserving hyperparameter optimization is to uniformly and randomly select hyperparameters for a number of runs, subsequently reporting the best-performing hyperparameter. In contrast, in non-private settings, practitioners commonly utilize "adaptive" hyperparameter optimization methods such as Gaussian process-based optimization, which select the next candidate based on information gathered from previous outputs. This substantial contrast between private and non-private hyperparameter optimization underscores a critical concern. In our paper, we introduce DP-HyPO, a pioneering fr
    
[^76]: 强化学习中多样性重放在泛化中的作用

    The Role of Diverse Replay for Generalisation in Reinforcement Learning. (arXiv:2306.05727v1 [cs.LG])

    [http://arxiv.org/abs/2306.05727](http://arxiv.org/abs/2306.05727)

    本文研究了在多任务强化学习中，增加重放缓存中数据过渡的多样性可以提高零-shot泛化性能，并且可能通过提高潜在表示的泛化性能来实现这种改善。

    

    在强化学习中，探索策略和重放缓存是其许多算法的关键组成部分。这些策略规定了要收集和训练哪些环境数据，并在强化学习文献中得到了广泛研究。本文旨在研究这些组件在多任务强化学习中泛化时的影响。我们研究了一个假设：从训练环境中收集和训练更多样化的数据将提高到新环境/任务的零-shot泛化性能。我们通过数学推导和实证研究证明，增加重放缓存中过渡的多样性可以提高到训练过程中“可达到”的状态的泛化性能。此外，我们还证明了这种策略对于类似但“不可达”状态的泛化性能也有所提高，并且可能是由于潜在表示的泛化性能得到了改善。

    In reinforcement learning (RL), key components of many algorithms are the exploration strategy and replay buffer. These strategies regulate what environment data is collected and trained on and have been extensively studied in the RL literature. In this paper, we investigate the impact of these components in the context of generalisation in multi-task RL. We investigate the hypothesis that collecting and training on more diverse data from the training environment will improve zero-shot generalisation to new environments/tasks. We motivate mathematically and show empirically that generalisation to states that are "reachable" during training is improved by increasing the diversity of transitions in the replay buffer. Furthermore, we show empirically that this same strategy also shows improvement for generalisation to similar but "unreachable" states and could be due to improved generalisation of latent representations.
    
[^77]: 离线强化学习的样本内政策迭代方法

    In-Sample Policy Iteration for Offline Reinforcement Learning. (arXiv:2306.05726v1 [cs.LG])

    [http://arxiv.org/abs/2306.05726](http://arxiv.org/abs/2306.05726)

    本文提出了一种采用样本内策略迭代的算法来增强离线强化学习中的行为规则方法，在实验中取得了显著的改进。

    

    离线强化学习通过利用以前收集到的数据来推导出有效的控制策略。为了解决由于数据覆盖不足而导致的错误，行为规则方法优化控制策略的同时，同时最小化偏离数据收集策略的误差。然而，当离线数据集由次优策略收集时，这些方法经常表现出不佳的实际性能。在本文中，我们提出了一种采用样本内策略迭代的新算法，它在离线强化学习中显著增强了行为规则方法。核心见解是通过不断改进用于行为规则的策略，样本内政策迭代逐渐改进自身，同时隐式避免查询样本外的行动，以避免灾难性的学习失败。我们的理论分析验证了其学习仅利用数据集中良好覆盖的行动学习样本内最优策略的能力。此外，我们在四个任务上进行了广泛的实验，证明我们的算法在现实世界的离线强化学习应用中能够显著改进现有方法。

    Offline reinforcement learning (RL) seeks to derive an effective control policy from previously collected data. To circumvent errors due to inadequate data coverage, behavior-regularized methods optimize the control policy while concurrently minimizing deviation from the data collection policy. Nevertheless, these methods often exhibit subpar practical performance, particularly when the offline dataset is collected by sub-optimal policies. In this paper, we propose a novel algorithm employing in-sample policy iteration that substantially enhances behavior-regularized methods in offline RL. The core insight is that by continuously refining the policy used for behavior regularization, in-sample policy iteration gradually improves itself while implicitly avoids querying out-of-sample actions to avert catastrophic learning failures. Our theoretical analysis verifies its ability to learn the in-sample optimal policy, exclusively utilizing actions well-covered by the dataset. Moreover, we pr
    
[^78]: 用信息理论的Shapley值解释预测的不确定性

    Explaining Predictive Uncertainty with Information Theoretic Shapley Values. (arXiv:2306.05724v1 [stat.ML])

    [http://arxiv.org/abs/2306.05724](http://arxiv.org/abs/2306.05724)

    本文提出了一种新的方法，通过Shapley值解释不确定性预测，可以量化每个特征对个别模型输出条件熵的贡献，适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。

    

    可解释人工智能研究人员开发了大量方法来帮助用户理解复杂监督学习模型的预测结果。相比之下，解释模型输出的$\textit{不确定性}$却受到了相对较少的关注。我们将广泛使用的Shapley值框架用于解释各种类型的预测不确定性，量化每个特征对个别模型输出条件熵的贡献。我们考虑了修改特征函数的博弈，并发现了由此产生的Shapley值与信息论和条件独立性测试中的基本量之间的深刻联系。我们概述了有证明保证的有限样本误差率控制的推理过程，并实现了一种高效的算法，在真实和模拟数据的一系列实验中表现良好。我们的方法适用于协变量转移检测、主动学习、特征选择和活动特征价值评估等方面。

    Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement an efficient algorithm that performs well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-val
    
[^79]: 利用密度函数的非线性变换估计岭

    Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])

    [http://arxiv.org/abs/2306.05722](http://arxiv.org/abs/2306.05722)

    本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。

    

    岭在准确近似流形的基础结构方面发挥着重要作用。本文通过将凹非线性变换应用于密度函数以探索岭的变化。通过对Hessian矩阵的推导和分析，我们发现非线性变换产生了Hessian矩阵的秩一修改。利用特征值问题的变分性质，我们建立了相应岭之间的偏序包含关系。我们直观地发现，通过Hessian矩阵的秩一修改，变换可以导致对切空间的估计改进。为验证我们的理论，我们在合成和真实世界数据集上进行了大量数值实验，证明了与其他流形拟合算法相比，我们的变换方法得到的岭在近似底层真实流形方面更加优越。

    Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
    
[^80]: 超越表面统计学：潜在扩散模型中的场景表示

    Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model. (arXiv:2306.05720v1 [cs.CV])

    [http://arxiv.org/abs/2306.05720](http://arxiv.org/abs/2306.05720)

    本文探究了潜在扩散模型内部是否创建和使用简单场景几何内部表示，使用线性探针发现LDM内部激活提供了关于3D深度数据和突出对象/背景分离的线性表示，在图像合成中具有因果作用, 可用于LDM输出的简单高级编辑。

    

    潜在扩散模型（LDM）展现了产生逼真图像的惊人能力，但这些模型的内在机制仍然神秘。即使在没有显式深度信息的图像上进行训练，它们通常也会输出一致的3D场景图片。在这项工作中，我们探讨了一个基本的可解释性问题：LDM是否创建并使用一个简单的场景几何内部表示？使用线性探针，我们发现LDM的内部激活编码了线性表示，既包括3D深度数据，又包括突出对象/背景区别。这些表示似乎在去噪过程的早期就出现了——在人类能轻易理解嘈杂的图像之前。干预性实验进一步表明，这些表示在图像合成中扮演因果作用，并且可能用于LDM输出的简单高级编辑。

    Latent diffusion models (LDMs) exhibit an impressive ability to produce realistic images, yet the inner workings of these models remain mysterious. Even when trained purely on images without explicit depth information, they typically output coherent pictures of 3D scenes. In this work, we investigate a basic interpretability question: does an LDM create and use an internal representation of simple scene geometry? Using linear probes, we find evidence that the internal activations of the LDM encode linear representations of both 3D depth data and a salient-object / background distinction. These representations appear surprisingly early in the denoising process$-$well before a human can easily make sense of the noisy images. Intervention experiments further indicate these representations play a causal role in image synthesis, and may be used for simple high-level editing of an LDM's output.
    
[^81]: 线性扩散提升了快速高质量语音合成

    Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion. (arXiv:2306.05708v1 [cs.SD])

    [http://arxiv.org/abs/2306.05708](http://arxiv.org/abs/2306.05708)

    本文提出了一种基于线性扩散模型的语音合成方法，能够同时实现快速推理和高样本质量

    

    面向各种生成任务，去噪扩散概率模型已经展现出了非凡的能力。然而，它们的慢推理速度使得它们在语音合成中不实用。本文提出了一种基于普通微分方程的线性扩散模型（LinDiff），以同时实现快速推理和高样本质量。同时，为了降低计算复杂度并实现对噪声语音的有效全局建模，LinDiff采用了基于分区的处理方法，将输入信号划分为小补丁。

    Denoising Diffusion Probabilistic Models have shown extraordinary ability on various generative tasks. However, their slow inference speed renders them impractical in speech synthesis. This paper proposes a linear diffusion model (LinDiff) based on an ordinary differential equation to simultaneously reach fast inference and high sample quality. Firstly, we employ linear interpolation between the target and noise to design a diffusion sequence for training, while previously the diffusion path that links the noise and target is a curved segment. When decreasing the number of sampling steps (i.e., the number of line segments used to fit the path), the ease of fitting straight lines compared to curves allows us to generate higher quality samples from a random noise with fewer iterations. Secondly, to reduce computational complexity and achieve effective global modeling of noisy speech, LinDiff employs a patch-based processing approach that partitions the input signal into small patches. Th
    
[^82]: 通过阶段性放松初始化理解联邦学习的一致性问题

    Understanding How Consistency Works in Federated Learning via Stage-wise Relaxed Initialization. (arXiv:2306.05706v1 [cs.LG])

    [http://arxiv.org/abs/2306.05706](http://arxiv.org/abs/2306.05706)

    本文提出了一种高效的联邦学习算法 FedInit，通过阶段性放松初始化来缓解“客户机漂移”问题，从而增强本地一致性，同时提出了一个理论框架解释本地不一致性的行为，并强调了初始化过程在优化联邦学习模型中的重要性。

    

    联邦学习是一种分布式范式，通过阶段性的本地训练过程协调大量本地客户端，对异构数据集进行全局模型协同训练。先前的研究已经暗示了联邦学习面临“客户机漂移”问题的困扰，这是由于本地客户端的不一致性最优解所导致的。然而，到目前为止，仍缺乏实质性的理论分析来解释这种本地不一致性的影响。为了缓解“客户机漂移”的负面影响并探索其在联邦学习中的实质，本文首先设计了一种高效的联邦学习算法 FedInit，该算法允许在每个本地训练阶段开始时使用个性化的放松初始化状态。具体而言，FedInit通过朝着最新本地状态的反向移动，将本地状态从当前全局状态中移开以进行放松的初始化。这种放松初始化有助于修正本地分歧并增强本地一致性。此外，我们提出了一个理论框架，以理解联邦学习中本地不一致性的行为。我们展示了阶段性放松初始化可以缓解本地不一致性的负面影响，并强调初始化过程在优化联邦学习模型中的重要性。

    Federated learning (FL) is a distributed paradigm that coordinates massive local clients to collaboratively train a global model via stage-wise local training processes on the heterogeneous dataset. Previous works have implicitly studied that FL suffers from the ``client-drift'' problem, which is caused by the inconsistent optimum across local clients. However, till now it still lacks solid theoretical analysis to explain the impact of this local inconsistency. To alleviate the negative impact of the ``client drift'' and explore its substance in FL, in this paper, we first design an efficient FL algorithm \textit{FedInit}, which allows employing the personalized relaxed initialization state at the beginning of each local training stage. Specifically, \textit{FedInit} initializes the local state by moving away from the current global state towards the reverse direction of the latest local state. This relaxed initialization helps to revise the local divergence and enhance the local consi
    
[^83]: 两人零和Markov博弈的极小极大Q-learning的有限时间分析：切换系统方法

    Finite-Time Analysis of Minimax Q-Learning for Two-Player Zero-Sum Markov Games: Switching System Approach. (arXiv:2306.05700v1 [eess.SY])

    [http://arxiv.org/abs/2306.05700](http://arxiv.org/abs/2306.05700)

    本文研究了Q-learning算法应用于两人零和Markov博弈的有限时间分析，并通过切换系统方法提供了更简单和深入的收敛分析。

    

    本文旨在研究Q-learning算法应用于两人零和Markov博弈的有限时间分析。我们针对极小极大Q-learning算法以及相应的价值迭代方法进行了有限时间分析。为了增强对价值迭代和Q-learning的分析，我们采用了极小极大Q-learning的切换系统模型和相应的价值迭代法。这种方法提供了对极小极大Q-learning的进一步洞察，并有助于更简单和深入的收敛分析。我们预计这些额外的洞察力有潜力揭示控制理论和强化学习社区概念之间的新联系，并促进它们之间的合作。

    The objective of this paper is to investigate the finite-time analysis of a Q-learning algorithm applied to two-player zero-sum Markov games. Specifically, we establish a finite-time analysis of both the minimax Q-learning algorithm and the corresponding value iteration method. To enhance the analysis of both value iteration and Q-learning, we employ the switching system model of minimax Q-learning and the associated value iteration. This approach provides further insights into minimax Q-learning and facilitates a more straightforward and insightful convergence analysis. We anticipate that the introduction of these additional insights has the potential to uncover novel connections and foster collaboration between concepts in the fields of control theory and reinforcement learning communities.
    
[^84]: JABBERWOCK：WebAssembly数据集生成工具及其在恶意网站检测中的应用

    JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its Application to Malicious Website Detection. (arXiv:2306.05698v1 [cs.CR])

    [http://arxiv.org/abs/2306.05698](http://arxiv.org/abs/2306.05698)

    本文提出了一个名为JABBERWOCK的工具，用于通过JavaScript收集并生成WebAssembly数据集，以用于恶意网站检测，并证明其能够在4.5秒内生成一个数据集。

    

    机器学习常被用于恶意网站的检测，但据我们所知，还没有探索利用WebAssembly作为特征的方法，原因是样本数量有限。在本文中，我们提出了JABBERWOCK（基于JavaScript和WebAssembly优化打包的二进制编码工具），用于通过JavaScript伪造生成WebAssembly数据集。JABBERWOCK主要自动收集真实世界中的JavaScript代码，将其转换成WebAssembly，然后将输出WebAssembly的向量作为恶意网站检测的样本。我们还对JABBERWOCK进行了实验评估，包括数据集生成的处理时间，生成样本与从互联网收集的实际WebAssembly样本的比较，以及在恶意网站检测中的应用。关于处理时间，我们显示JABBERWOCK可以在任意样本数量下每4.5秒构建一个数据集。

    Machine learning is often used for malicious website detection, but an approach incorporating WebAssembly as a feature has not been explored due to a limited number of samples, to the best of our knowledge. In this paper, we propose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization paCKer), a tool to generate WebAssembly datasets in a pseudo fashion via JavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code in the real world, convert them into WebAssembly, and then outputs vectors of the WebAssembly as samples for malicious website detection. We also conduct experimental evaluations of JABBERWOCK in terms of the processing time for dataset generation, comparison of the generated samples with actual WebAssembly samples gathered from the Internet, and an application for malicious website detection. Regarding the processing time, we show that JABBERWOCK can construct a dataset in 4.5 seconds per sample for any number of samples. Next, comparin
    
[^85]: 基于群等变性的傅里叶神经算子求解偏微分方程

    Group Equivariant Fourier Neural Operators for Partial Differential Equations. (arXiv:2306.05697v1 [cs.LG])

    [http://arxiv.org/abs/2306.05697](http://arxiv.org/abs/2306.05697)

    本文扩展了群卷积到频率域，并设计了具有旋转、平移和镜像等变性质的傅里叶层的G-FNO架构，该架构在不同对称性水平的设置中表现良好。

    

    本研究考虑使用在频率域下操作的傅里叶神经算子（FNOs）求解偏微分方程（PDEs）。由于物理定律不依赖于用于描述它们的坐标系, 因此将这些对称性编码进神经算子架构以提高性能和更容易的学习是有益的。尽管使用群论编码物理域内的对称性已经被广泛研究，但如何在频率域内捕捉对称性仍未得到充分探讨。本文将群卷积扩展到频率域，并设计具有旋转、平移和镜像等变性质的傅里叶层，利用傅里叶变换的等变性质。产生的G-FNO架构跨输入分辨率具有良好的推广效果，并在具有不同对称性水平的设置中表现良好。我们的代码可作为AIRS库的一部分公开在Github（https://github.com/divelab/AIRS）上获得。

    We consider solving partial differential equations (PDEs) with Fourier neural operators (FNOs), which operate in the frequency domain. Since the laws of physics do not depend on the coordinate system used to describe them, it is desirable to encode such symmetries in the neural operator architecture for better performance and easier learning. While encoding symmetries in the physical domain using group theory has been studied extensively, how to capture symmetries in the frequency domain is under-explored. In this work, we extend group convolutions to the frequency domain and design Fourier layers that are equivariant to rotations, translations, and reflections by leveraging the equivariance property of the Fourier transform. The resulting $G$-FNO architecture generalizes well across input resolutions and performs well in settings with varying levels of symmetry. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).
    
[^86]: 小量子态的可解释表示学习

    Explainable Representation Learning of Small Quantum States. (arXiv:2306.05694v1 [quant-ph])

    [http://arxiv.org/abs/2306.05694](http://arxiv.org/abs/2306.05694)

    该论文探讨了一种无监督机器学习模型在小量子态上的可解释表示学习方法，得到了一个与潜在结构相联系的可理解表示。

    

    无监督的机器学习模型能够在没有明确人类指导或特征工程的情况下建立起对训练数据的内部表示。通过这种学习到的表示，我们可以进一步了解到关于处理任务所需的数据特征信息。在量子物理学的背景下，训练模型以描述量子态又未经人类干预地学习信息是获得深入了解机器如何呈现复杂量子态的重要途径。解释学习到的表示将为非平凡的量子系统及其有效表示带来新的视角。我们针对由参数化量子电路生成的两量子比特密度矩阵训练了一个生成模型。通过一系列计算实验，我们调查了该模型所学习到的表示以及其内部对数据信息的理解。我们观察到模型学习了一种可解释的表示方式，并将量子态与其潜在结构相联系。

    Unsupervised machine learning models build an internal representation of their training data without the need for explicit human guidance or feature engineering. This learned representation provides insights into which features of the data are relevant for the task at hand. In the context of quantum physics, training models to describe quantum states without human intervention offers a promising approach to gaining insight into how machines represent complex quantum states. The ability to interpret the learned representation may offer a new perspective on non-trivial features of quantum systems and their efficient representation. We train a generative model on two-qubit density matrices generated by a parameterized quantum circuit. In a series of computational experiments, we investigate the learned representation of the model and its internal understanding of the data. We observe that the model learns an interpretable representation which relates the quantum states to their underlying
    
[^87]: 通过令牌共享Transformer实现轻量级单目深度估计

    Lightweight Monocular Depth Estimation via Token-Sharing Transformer. (arXiv:2306.05682v1 [cs.CV])

    [http://arxiv.org/abs/2306.05682](http://arxiv.org/abs/2306.05682)

    本文提出了一种使用Transformer和全局令牌共享的轻量级单目深度估计方法，针对嵌入式设备进行了优化。

    

    深度估计是各种机器人系统和应用中的重要任务，单目深度估计是一种理想的选择，然而大多数方法使用卷积神经网络，而本文提出了一种Token-Sharing Transformer体系结构来优化在嵌入式设备中的单目深度估计。

    Depth estimation is an important task in various robotics systems and applications. In mobile robotics systems, monocular depth estimation is desirable since a single RGB camera can be deployable at a low cost and compact size. Due to its significant and growing needs, many lightweight monocular depth estimation networks have been proposed for mobile robotics systems. While most lightweight monocular depth estimation methods have been developed using convolution neural networks, the Transformer has been gradually utilized in monocular depth estimation recently. However, massive parameters and large computational costs in the Transformer disturb the deployment to embedded devices. In this paper, we present a Token-Sharing Transformer (TST), an architecture using the Transformer for monocular depth estimation, optimized especially in embedded devices. The proposed TST utilizes global token sharing, which enables the model to obtain an accurate depth prediction with high throughput in emb
    
[^88]: 通过迁移学习的方法基于脑电图检测情绪

    Emotion Detection from EEG using Transfer Learning. (arXiv:2306.05680v1 [eess.SP])

    [http://arxiv.org/abs/2306.05680](http://arxiv.org/abs/2306.05680)

    本研究采用迁移学习的方法，通过将MPC、MSC以及DE结合到图像矩阵中，提高了基于EEG的情绪检测的准确性。本研究为脑机接口和康复医学提供了有价值的信息。

    

    使用脑电图（EEG）进行情绪检测是脑机接口领域中非常关键的领域，并在康复和医学领域有很有价值的应用。本研究采用了迁移学习来克服基于EEG情绪检测的数据有限性挑战。本研究中使用的基本模型是Resnet50。此外，我们在基于EEG的情绪检测中采用了一种新颖的特征组合。模型的输入形式是一个图像矩阵，其中上三角矩阵和下三角矩阵分别包括平均相位相干（MPC）和幅度平方相干（MSC）。我们通过将差分熵（DE）获得的特征结合到对角线中进一步改进了该技术，以前对情绪分类几乎没有有用的信息。本研究使用的数据集是SEED EEG（62通道EEG），包括三个类别（积极，中性和消极）。我们计算了使用我们的方法进行情绪检测的准确性，并比较了其它方法的准确性。

    The detection of emotions using an Electroencephalogram (EEG) is a crucial area in brain-computer interfaces and has valuable applications in fields such as rehabilitation and medicine. In this study, we employed transfer learning to overcome the challenge of limited data availability in EEG-based emotion detection. The base model used in this study was Resnet50. Additionally, we employed a novel feature combination in EEG-based emotion detection. The input to the model was in the form of an image matrix, which comprised Mean Phase Coherence (MPC) and Magnitude Squared Coherence (MSC) in the upper-triangular and lower-triangular matrices, respectively. We further improved the technique by incorporating features obtained from the Differential Entropy (DE) into the diagonal, which previously held little to no useful information for classifying emotions. The dataset used in this study, SEED EEG (62 channel EEG), comprises three classes (Positive, Neutral, and Negative). We calculated both
    
[^89]: 面向超参数化神经网络的高效不确定性量化和减少方法

    Efficient Uncertainty Quantification and Reduction for Over-Parameterized Neural Networks. (arXiv:2306.05674v1 [stat.ML])

    [http://arxiv.org/abs/2306.05674](http://arxiv.org/abs/2306.05674)

    本论文基于神经切向核理论，提出了一种高效的方法以减少超参数化神经网络中的过程不确定性，并只需要使用一种辅助网络就可以消除这种不确定性。

    

    不确定性量化（UQ）对于机器学习模型的可靠性评估和改进至关重要。在深度学习中，不确定性不仅来自数据，还来自训练过程中注入的大量噪声和偏差。这些噪声和偏差妨碍了统计保证的实现，并且由于需要重复的网络重新训练，对UQ提出了计算挑战。基于最近的神经切向核理论，我们创建了具有统计保证的方案，以通过非常低的计算量量化和减少超参数化神经网络的过程不确定性。特别地，我们的方法基于我们称为过程噪声校正（PNC）预测器，通过只使用一种适当标记数据集上训练的辅助网络来消除过程不确定性，而不是使用深层集成中的许多重新训练的网络。此外，通过将我们的PNC预测器与所提出的先验模型结合起来，我们可以显著减少所需的网络正则化。

    Uncertainty quantification (UQ) is important for reliability assessment and enhancement of machine learning models. In deep learning, uncertainties arise not only from data, but also from the training procedure that often injects substantial noises and biases. These hinder the attainment of statistical guarantees and, moreover, impose computational challenges on UQ due to the need for repeated network retraining. Building upon the recent neural tangent kernel theory, we create statistically guaranteed schemes to principally \emph{quantify}, and \emph{remove}, the procedural uncertainty of over-parameterized neural networks with very low computation effort. In particular, our approach, based on what we call a procedural-noise-correcting (PNC) predictor, removes the procedural uncertainty by using only \emph{one} auxiliary network that is trained on a suitably labeled data set, instead of many retrained networks employed in deep ensembles. Moreover, by combining our PNC predictor with su
    
[^90]: QuestEnvSim：基于环境感知的稀疏传感器模拟运动追踪

    QuestEnvSim: Environment-Aware Simulated Motion Tracking from Sparse Sensors. (arXiv:2306.05666v1 [cs.GR])

    [http://arxiv.org/abs/2306.05666](http://arxiv.org/abs/2306.05666)

    本研究利用物理模拟和环境感知相结合的方法，在高度约束的环境中，能够生成逼真的全身姿势，实现了高质量的交互动作。

    

    仅使用可穿戴传感器复制用户的姿势对于许多AR/VR应用程序非常重要。大多数现有的运动跟踪方法在环境交互方面都避免了除脚-地面接触外的其他因素，因为它们具有复杂的动态和硬约束。但是，在日常生活中，人们经常与环境进行交互，例如坐在沙发上或倚靠在桌子上。使用强化学习，我们展示了即使在高度约束的环境中，只要将头戴式显示器和控制器姿势与物理模拟和环境观察相结合，即可生成逼真的全身姿势。物理模拟自动实施逼真姿势所需的各种约束条件，而不像许多运动学方法中那样手动指定它们。这些硬约束条件使我们能够实现高质量的交互动作，而不会出现典型的穿透或接触滑动等问题。我们讨论了三个特性，环境表征，接触奖励和场景随机化，这些特性有助于我们的方法的成功，并展示了各种定性和定量结果。

    Replicating a user's pose from only wearable sensors is important for many AR/VR applications. Most existing methods for motion tracking avoid environment interaction apart from foot-floor contact due to their complex dynamics and hard constraints. However, in daily life people regularly interact with their environment, e.g. by sitting on a couch or leaning on a desk. Using Reinforcement Learning, we show that headset and controller pose, if combined with physics simulation and environment observations can generate realistic full-body poses even in highly constrained environments. The physics simulation automatically enforces the various constraints necessary for realistic poses, instead of manually specifying them as in many kinematic approaches. These hard constraints allow us to achieve high-quality interaction motions without typical artifacts such as penetration or contact sliding. We discuss three features, the environment representation, the contact reward and scene randomizatio
    
[^91]: 通信效率优化问题的分布式零阶在线优化：算法、理论和应用

    Communication-Efficient Zeroth-Order Distributed Online Optimization: Algorithm, Theory, and Applications. (arXiv:2306.05655v1 [cs.LG])

    [http://arxiv.org/abs/2306.05655](http://arxiv.org/abs/2306.05655)

    本文提出了一种针对目标跟踪的分布式在线优化算法，并利用基于误差反馈的压缩方案来解决代理的通信限制问题。

    

    本文关注于在联邦学习环境中，针对目标跟踪的多智能体零阶在线优化问题。代理只能感知自己与目标的当前距离，并力求保持彼此之间的最小安全距离，以避免碰撞。代理之间的协调和碰撞预防信息的传播由中央服务器使用联邦学习范式进行管理。所提出的公式导致了一个分布式在线非凸优化问题的实例，该问题通过一组受通信限制的代理解决。为了处理代理的通信限制，利用基于误差反馈的压缩方案进行代理到服务器的通信。所提出的算法在理论上分析了分布式在线非凸优化问题的一般类。我们提供了非渐近收敛速率，表明主导项独立于压缩性质。

    This paper focuses on a multi-agent zeroth-order online optimization problem in a federated learning setting for target tracking. The agents only sense their current distances to their targets and aim to maintain a minimum safe distance from each other to prevent collisions. The coordination among the agents and dissemination of collision-prevention information is managed by a central server using the federated learning paradigm. The proposed formulation leads to an instance of distributed online nonconvex optimization problem that is solved via a group of communication-constrained agents. To deal with the communication limitations of the agents, an error feedback-based compression scheme is utilized for agent-to-server communication. The proposed algorithm is analyzed theoretically for the general class of distributed online nonconvex optimization problems. We provide non-asymptotic convergence rates that show the dominant term is independent of the characteristics of the compression 
    
[^92]: 差分隐私锐化感知训练

    Differentially Private Sharpness-Aware Training. (arXiv:2306.05651v1 [cs.LG])

    [http://arxiv.org/abs/2306.05651](http://arxiv.org/abs/2306.05651)

    本文提出了一种能够缓解隐私-优化制约关系的锐化感知训练方法。

    

    使用差分隐私进行训练会导致深度学习模型性能下降。本文研究了私有学习的几何属性，提出了一种新的锐化感知的训练方法，以缓解隐私-优化的制约关系。

    Training deep learning models with differential privacy (DP) results in a degradation of performance. The training dynamics of models with DP show a significant difference from standard training, whereas understanding the geometric properties of private learning remains largely unexplored. In this paper, we investigate sharpness, a key factor in achieving better generalization, in private learning. We show that flat minima can help reduce the negative effects of per-example gradient clipping and the addition of Gaussian noise. We then verify the effectiveness of Sharpness-Aware Minimization (SAM) for seeking flat minima in private learning. However, we also discover that SAM is detrimental to the privacy budget and computational time due to its two-step optimization. Thus, we propose a new sharpness-aware training method that mitigates the privacy-optimization trade-off. Our experimental results demonstrate that the proposed method improves the performance of deep learning models with 
    
[^93]: 使用CVXPY规定和解决鲁棒经验风险最小化问题

    Specifying and Solving Robust Empirical Risk Minimization Problems Using CVXPY. (arXiv:2306.05649v1 [math.OC])

    [http://arxiv.org/abs/2306.05649](http://arxiv.org/abs/2306.05649)

    本文介绍了如何使用CVXPY以用户友好的方式自动化鲁棒经验风险最小化问题的对偶化过程，使得用户可以方便地解决各种回归和分类问题。

    

    我们考虑鲁棒性经验风险最小化（ERM），其中模型参数被选为使得每个数据点在给定的凸不确定性集内变化时最小化最坏情况下的经验损失。在一些简单的情况下，这些问题可以表达为解析形式。一般情况下，可以通过对偶化使问题变得可行，这将一个min-max问题转换为一个min-min问题。对偶化需要专业知识，很烦琐也容易出现错误。我们展示了如何使用CVXPY以用户友好的方式自动化这个对偶化过程。我们的框架允许从一个一般的凸损失类中捕捉许多标准的回归和分类问题，并且用户可以轻松地指定任何可以用纪律化凸规划（DCP）约束表示的复杂不确定性集合。

    We consider robust empirical risk minimization (ERM), where model parameters are chosen to minimize the worst-case empirical loss when each data point varies over a given convex uncertainty set. In some simple cases, such problems can be expressed in an analytical form. In general the problem can be made tractable via dualization, which turns a min-max problem into a min-min problem. Dualization requires expertise and is tedious and error-prone. We demonstrate how CVXPY can be used to automate this dualization procedure in a user-friendly manner. Our framework allows practitioners to specify and solve robust ERM problems with a general class of convex losses, capturing many standard regression and classification problems. Users can easily specify any complex uncertainty set that is representable via disciplined convex programming (DCP) constraints.
    
[^94]: 重新思考置换对不同数据集间模型合并的作用

    Revisiting Permutation Symmetry for Merging Models between Different Datasets. (arXiv:2306.05641v1 [cs.LG])

    [http://arxiv.org/abs/2306.05641](http://arxiv.org/abs/2306.05641)

    本研究通过理论和实证分析表明，不同数据集合并模型的准确性下降更为显著，因为每个数据集的不同损失函数使得合并更加困难。此外，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。

    

    模型合并是一种通过组合不同训练模型的权重来创建新模型的新方法。以往的研究表明，模型合并对于不同随机数训练模型的单一数据集非常有效，但是在不同数据集之间进行模型合并却很困难。将不同数据集的知识合并具有实际意义，但尚未得到很好的研究。本文通过理论和实证分析探讨了不同数据集间合并模型的特性。我们发现随着数据集的差异越大，合并模型的准确性下降得更为显著，而每个数据集的不同损失函数使得不同数据集之间的模型合并更加困难。我们还表明合并的模型需要数据集才能实现高精度合并。此外，我们还表明当合并模型时，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。

    Model merging is a new approach to creating a new model by combining the weights of different trained models. Previous studies report that model merging works well for models trained on a single dataset with different random seeds, while model merging between different datasets is difficult. Merging knowledge from different datasets has practical significance, but it has not been well investigated. In this paper, we investigate the properties of merging models between different datasets. Through theoretical and empirical analyses, we find that the accuracy of the merged model decreases more significantly as the datasets diverge more and that the different loss landscapes for each dataset make model merging between different datasets difficult. We also show that merged models require datasets for merging in order to achieve a high accuracy. Furthermore, we show that condensed datasets created by dataset condensation can be used as substitutes for the original datasets when merging model
    
[^95]: 关于无监督表示学习在强化学习中特征去相关性的重要性

    On the Importance of Feature Decorrelation for Unsupervised Representation Learning in Reinforcement Learning. (arXiv:2306.05637v1 [cs.LG])

    [http://arxiv.org/abs/2306.05637](http://arxiv.org/abs/2306.05637)

    本研究提出了一种新的URL框架，通过去相关潜空间中的特征来因果性地预测未来状态并增加潜空间的维度，从而有效地学习预测表示而不会崩溃，显着提高了基于Atari 100k基准的最新URL方法的样本效率。

    

    最近，无监督表示学习（URL）通过从大型无标签数据集中预训练模型来提高强化学习（RL）的样本效率。这些方法的基本原则是通过在潜空间中预测未来状态来学习时间上的预测表示。然而，这种方法的一个重要挑战是表示崩溃，其中潜表征的子空间崩溃为低维流形。为了解决这个问题，我们提出了一种新的URL框架，通过去相关潜空间中的特征来因果性地预测未来状态并增加潜空间的维度。通过广泛的经验研究，我们证明了我们的框架有效地学习预测表示而不会崩溃，从而显着提高了基于Atari 100k基准的最新URL方法的样本效率。代码可在 https://github.com/dojeon-ai/SimTPR 上获得。

    Recently, unsupervised representation learning (URL) has improved the sample efficiency of Reinforcement Learning (RL) by pretraining a model from a large unlabeled dataset. The underlying principle of these methods is to learn temporally predictive representations by predicting future states in the latent space. However, an important challenge of this approach is the representational collapse, where the subspace of the latent representations collapses into a low-dimensional manifold. To address this issue, we propose a novel URL framework that causally predicts future states while increasing the dimension of the latent manifold by decorrelating the features in the latent space. Through extensive empirical studies, we demonstrate that our framework effectively learns predictive representations without collapse, which significantly improves the sample efficiency of state-of-the-art URL methods on the Atari 100k benchmark. The code is available at https://github.com/dojeon-ai/SimTPR.
    
[^96]: 量化GNN中的知识以实现可靠的蒸馏到MLP

    Quantifying the Knowledge in GNNs for Reliable Distillation into MLPs. (arXiv:2306.05628v1 [cs.LG])

    [http://arxiv.org/abs/2306.05628](http://arxiv.org/abs/2306.05628)

    该论文提出了一种基于知识可靠性量化的方法，并通过采样一组额外的可靠知识点，实现了GNN向MLP的可靠蒸馏，从而提高了蒸馏效率和效果。

    

    为了弥合有拓扑感知的图神经网络（GNN）和推理高效的多层感知器（MLP）之间的差距，GLNN提议从经过充分训练的Teacher GNN中蒸馏出知识到Student MLP中。本文不同于其他工作探索了GNN中不同知识点（节点）的可靠性，特别是在蒸馏过程中扮演的角色方面。我们首先通过计算信息熵对噪声扰动的不变性来量化GNN中的知识可靠性，从中我们观察到不同的知识点：（1）显示出不同的蒸馏速度（时间性）；（2）在图中分布不均匀（空间方面）。为了实现可靠蒸馏，我们提出了一种有效的方法，即基于知识启发的可靠蒸馏（KRD），它基于对节点成为信息丰富、可靠的知识点的概率建模，从中采样一组额外的可靠知识点以实现更好的蒸馏。各种基准数据集上的实验结果显示了KRD相对于现有技术水平的优越性。

    To bridge the gaps between topology-aware Graph Neural Networks (GNNs) and inference-efficient Multi-Layer Perceptron (MLPs), GLNN proposes to distill knowledge from a well-trained teacher GNN into a student MLP. Despite their great progress, comparatively little work has been done to explore the reliability of different knowledge points (nodes) in GNNs, especially their roles played during distillation. In this paper, we first quantify the knowledge reliability in GNN by measuring the invariance of their information entropy to noise perturbations, from which we observe that different knowledge points (1) show different distillation speeds (temporally); (2) are differentially distributed in the graph (spatially). To achieve reliable distillation, we propose an effective approach, namely Knowledge-inspired Reliable Distillation (KRD), that models the probability of each node being an informative and reliable knowledge point, based on which we sample a set of additional reliable knowledg
    
[^97]: 用机器学习提高量子电路合成的效率

    Improving Quantum Circuit Synthesis with Machine Learning. (arXiv:2306.05622v1 [quant-ph])

    [http://arxiv.org/abs/2306.05622](http://arxiv.org/abs/2306.05622)

    本论文提出了一种名为 QSeed 的种子合成算法，应用机器学习显著加速合成算法，针对核心量子算法组件，如 Shor 因式分解算法中的 64 比特模幂电路，QSeed 能在保持低门计数的同时将合成时间加速 $3.7\times$。

    

    在嘈杂中等规模量子 (NISQ) 时代，找到最小化昂贵和容易出错的多比特门数量的量子算法实现对于确保计算产生有意义的输出是至关重要的。赋范合成是找到实现目标酉矩阵的量子电路的过程，在很多情况下能够最优地解决这个问题。然而，目前自底向上的赋范合成算法的运行时间受指数增长的限制。我们展示了如何将机器学习应用于赋范数据集，使合成算法得到显著的加速。本文介绍了 QSeed，一种种子合成算法，它使用学习的模型快速提出资源有效的电路实现。QSeed 保持低门计数，并针对 Shor 因式分解算法中的 64 比特模幂电路核心组件，比现有技术在合成时间方面提供了 $3.7\times$ 的加速。QSeed 的性能优于当前公认的合成算法，并提供了可扩展性和泛化性能。

    In the Noisy Intermediate Scale Quantum (NISQ) era, finding implementations of quantum algorithms that minimize the number of expensive and error prone multi-qubit gates is vital to ensure computations produce meaningful outputs. Unitary synthesis, the process of finding a quantum circuit that implements some target unitary matrix, is able to solve this problem optimally in many cases. However, current bottom-up unitary synthesis algorithms are limited by their exponentially growing run times. We show how applying machine learning to unitary datasets permits drastic speedups for synthesis algorithms. This paper presents QSeed, a seeded synthesis algorithm that employs a learned model to quickly propose resource efficient circuit implementations of unitaries. QSeed maintains low gate counts and offers a speedup of $3.7\times$ in synthesis time over the state of the art for a 64 qubit modular exponentiation circuit, a core component in Shor's factoring algorithm. QSeed's performance impr
    
[^98]: 合作学习中多样化数据贡献的评估与激励机制

    Evaluating and Incentivizing Diverse Data Contributions in Collaborative Learning. (arXiv:2306.05592v1 [cs.GT])

    [http://arxiv.org/abs/2306.05592](http://arxiv.org/abs/2306.05592)

    本研究针对合作学习中数据多样性与代表性的问题，设计了一种博弈机制以鼓励数据贡献者提供代表全局人口的数据。

    

    为了使联邦学习模型表现良好，拥有多样化和有代表性的数据集是至关重要的。然而，数据贡献者可能只关心特定人群子集的表现，这可能无法反映更广泛人口的多样性。这导致了PRINCIPAL（FL平台设计者）关心全局表现与AGENTS（数据收集者）关心局部表现之间的紧张关系。本研究将这种紧张关系形式化为PRINCIPAL与多个AGENTS之间的博弈，并针对线性试验设计问题来研究它们的交互。我们展示了用于量化数据多样性的统计标准以及所选择的联邦学习算法对结果平衡的影响。我们利用这一点来设计简单的最优联邦学习机制，以鼓励数据收集者贡献代表全局人口的数据。

    For a federated learning model to perform well, it is crucial to have a diverse and representative dataset. However, the data contributors may only be concerned with the performance on a specific subset of the population, which may not reflect the diversity of the wider population. This creates a tension between the principal (the FL platform designer) who cares about global performance and the agents (the data collectors) who care about local performance. In this work, we formulate this tension as a game between the principal and multiple agents, and focus on the linear experiment design problem to formally study their interaction. We show that the statistical criterion used to quantify the diversity of the data, as well as the choice of the federated learning algorithm used, has a significant effect on the resulting equilibrium. We leverage this to design simple optimal federated learning mechanisms that encourage data collectors to contribute data representative of the global popula
    
[^99]: MC-NN：一种端到端的多通道神经网络方法，用于预测流感病毒宿主和抗原类型。

    MC-NN: An End-to-End Multi-Channel Neural Network Approach for Predicting Influenza A Virus Hosts and Antigenic Types. (arXiv:2306.05587v1 [cs.LG])

    [http://arxiv.org/abs/2306.05587](http://arxiv.org/abs/2306.05587)

    提出了一种利用多通道神经网络模型预测流感A病毒宿主和抗原亚型的方法，数据显示多通道神经网络模型具有较高的准确性和预测能力。

    

    流感对公共卫生构成重大威胁，特别是对老年人、儿童和患有潜在疾病的人来说更为严重。严重病况的发生，如肺炎，凸显了预防流感传播的重要性。准确而具有成本效益的预测流感A病毒的宿主和抗原亚型对于应对这一问题至关重要，特别是在资源有限的地区。在本研究中，我们提出了一种多通道神经网络模型，用于从血凝素和神经氨酸酶蛋白序列预测流感A病毒的宿主和抗原亚型。我们的模型是在一个完整蛋白质序列的全面数据集上进行训练的，并在各种完整和不完整序列的测试数据集上进行评估。结果表明，使用多通道神经网络来预测来自完整和部分蛋白质序列的流感A病毒的宿主和抗原亚型具有潜力和实用性。

    Influenza poses a significant threat to public health, particularly among the elderly, young children, and people with underlying dis-eases. The manifestation of severe conditions, such as pneumonia, highlights the importance of preventing the spread of influenza. An accurate and cost-effective prediction of the host and antigenic sub-types of influenza A viruses is essential to addressing this issue, particularly in resource-constrained regions. In this study, we propose a multi-channel neural network model to predict the host and antigenic subtypes of influenza A viruses from hemagglutinin and neuraminidase protein sequences. Our model was trained on a comprehensive data set of complete protein sequences and evaluated on various test data sets of complete and incomplete sequences. The results demonstrate the potential and practicality of using multi-channel neural networks in predicting the host and antigenic subtypes of influenza A viruses from both full and partial protein sequence
    
[^100]: 多体SE（3）等变性用于无监督的刚体分割和运动估计

    Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation. (arXiv:2306.05584v1 [cs.CV])

    [http://arxiv.org/abs/2306.05584](http://arxiv.org/abs/2306.05584)

    本文提出了一种基于SE（3）等变结构和非监督训练策略的方法，可以实现刚性分割和运动估计，不需要类别信息且具有极高的模型效率。

    

    实现刚体分割和运动估计的真正通用方法对于理解关节物体和移动场景的三维影像至关重要。鉴于分割和运动估计之间密切的关系，我们提出了一种SE（3）等变体系结构和培训策略，以无监督的方式解决这个任务。我们的体系结构包括两个轻量级和相互连接的头部，使用点级不变特征和来自SE（3）等变特征的运动估计来预测分割掩模，而不需要类别信息。我们的统一培训策略可以在线执行，通过利用场景流，分割掩模和刚性变换之间的相互关系来同时优化两个预测。我们在四个数据集上的实验表明，我们的方法在模型性能和计算效率方面均表现出优越性，只有0.25M参数和0.92G FLOPs。

    A truly generalizable approach to rigid segmentation and motion estimation is fundamental to 3D understanding of articulated objects and moving scenes. In view of the tightly coupled relationship between segmentation and motion estimates, we present an SE(3) equivariant architecture and a training strategy to tackle this task in an unsupervised manner. Our architecture comprises two lightweight and inter-connected heads that predict segmentation masks using point-level invariant features and motion estimates from SE(3) equivariant features without the prerequisites of category information. Our unified training strategy can be performed online while jointly optimizing the two predictions by exploiting the interrelations among scene flow, segmentation mask, and rigid transformations. We show experiments on four datasets as evidence of the superiority of our method both in terms of model performance and computational efficiency with only 0.25M parameters and 0.92G FLOPs. To the best of ou
    
[^101]: 基于SGLD的信息准则与超参数化模型研究

    SGLD-Based Information Criteria and the Over-Parameterized Regime. (arXiv:2306.05583v1 [cs.LG])

    [http://arxiv.org/abs/2306.05583](http://arxiv.org/abs/2306.05583)

    本研究提出针对超参数化学习算法的SGLD信息准则，通过KL信息和KL散度罚项来追踪双下降现象。

    

    “双丘陵”是指过度参数化学习算法在插值阈值之外的意外测试损失下降，这不是由于标准渐进方法的局限性，导致经典形式的信息准则无法预测。我们使用信息风险最小化框架更新这些分析，并为通过随机梯度Langevin动力学（SGLD）学习的模型提供了Akaike信息准则（AIC）和贝叶斯信息准则（BIC）。值得注意的是，SGLD的AIC和BIC罚项对应特定的信息度量，即对称的KL信息和KL散度。我们通过表征大量参数模型的SGLD-BIC扩展了此信息理论分析，其中参数数$p$和样本数$n$趋于无穷大，$p/n$固定。我们的实验表明，改进的SGLD-BIC可以跟踪双下降曲线。

    Double-descent refers to the unexpected drop in test loss of a learning algorithm beyond an interpolating threshold with over-parameterization, which is not predicted by information criteria in their classical forms due to the limitations in the standard asymptotic approach. We update these analyses using the information risk minimization framework and provide Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for models learned by stochastic gradient Langevin dynamics (SGLD). Notably, the AIC and BIC penalty terms for SGLD correspond to specific information measures, i.e., symmetrized KL information and KL divergence. We extend this information-theoretic analysis to over-parameterized models by characterizing the SGLD-based BIC for the random feature model in the regime where the number of parameters $p$ and the number of samples $n$ tend to infinity, with $p/n$ fixed. Our experiments demonstrate that the refined SGLD-based BIC can track the double-descent cur
    
[^102]: 分布式随机分布的异构奖励多智能体多臂赌博机

    Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with Heterogeneous Rewards. (arXiv:2306.05579v1 [cs.LG])

    [http://arxiv.org/abs/2306.05579](http://arxiv.org/abs/2306.05579)

    本文提出了一种处理多智能体多臂赌博机问题的算法框架，通过稳健模拟生成随机图并将加权技术结合UCB算法，以协作方式减小整个系统的总遗憾。

    

    本文研究了分布式多智能体多臂赌博机问题，多个客户端通过由环境提供的时间依赖性随机图进行连接。每个臂的奖励分布因客户而异，并且奖励是根据包括亚指数和亚高斯分布在内的分布，由环境独立地随时间生成的。每个客户端都会拉动一个臂，并根据由环境提供的图与邻居进行通信。我们的目标是通过协作来减小整个系统的总遗憾。为此，我们引入了一种新的算法框架，该框架首先提供了使用快速混合马尔可夫链或随机图模型生成随机图的稳健仿真方法，然后将基于平均一致性方法和新提出的加权技术以及上置信限结合起来，提供了一种UCB类型的解决方案。我们的算法考虑到了图形中的随机性，消除了限制条件。

    We study a decentralized multi-agent multi-armed bandit problem in which multiple clients are connected by time dependent random graphs provided by an environment. The reward distributions of each arm vary across clients and rewards are generated independently over time by an environment based on distributions that include both sub-exponential and sub-gaussian distributions. Each client pulls an arm and communicates with neighbors based on the graph provided by the environment. The goal is to minimize the overall regret of the entire system through collaborations. To this end, we introduce a novel algorithmic framework, which first provides robust simulation methods for generating random graphs using rapidly mixing Markov chains or the random graph model, and then combines an averaging-based consensus approach with a newly proposed weighting technique and the upper confidence bound to deliver a UCB-type solution. Our algorithms account for the randomness in the graphs, removing the con
    
[^103]: 智能分析，在物联网框架下的智能城市能源管理：复杂网络和系统机器学习方法应用的案例研究

    Intelligent Energy Management with IoT Framework in Smart Cities Using Intelligent Analysis: An Application of Machine Learning Methods for Complex Networks and Systems. (arXiv:2306.05567v1 [cs.LG])

    [http://arxiv.org/abs/2306.05567](http://arxiv.org/abs/2306.05567)

    本研究开发了一个智能城市能源管理的物联网框架，结合智能分析和多组件的架构，研究了基于智能机制的智能能源管理解决方案，以期节能和优化管理。

    

    智能建筑越来越多地使用基于物联网的无线传感系统来降低能源消耗和环境影响。本研究的主要贡献是开发了一个全面的基于物联网的智能城市能源管理框架，融合了多个物联网架构和框架的组件。该框架通过智能分析，不仅收集和存储信息，而且还是其他企业开发应用的平台。此外，我们还研究了基于智能机制的智能能源管理解决方案。能源资源的消耗和需求增加导致了节能与优化管理的需求和挑战。

    Smart buildings are increasingly using Internet of Things (IoT)-based wireless sensing systems to reduce their energy consumption and environmental impact. As a result of their compact size and ability to sense, measure, and compute all electrical properties, Internet of Things devices have become increasingly important in our society. A major contribution of this study is the development of a comprehensive IoT-based framework for smart city energy management, incorporating multiple components of IoT architecture and framework. An IoT framework for intelligent energy management applications that employ intelligent analysis is an essential system component that collects and stores information. Additionally, it serves as a platform for the development of applications by other companies. Furthermore, we have studied intelligent energy management solutions based on intelligent mechanisms. The depletion of energy resources and the increase in energy demand have led to an increase in energy 
    
[^104]: 数据自适应概率似然逼近常微分方程

    Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations. (arXiv:2306.05566v1 [stat.ML])

    [http://arxiv.org/abs/2306.05566](http://arxiv.org/abs/2306.05566)

    本文提出了一种数据自适应的贝叶斯滤波范式来解决现有概率ODE求解器无法解决的深层的局部最小值问题，结果表明该方法比现有概率ODE求解器更精确。

    

    常微分方程（ODEs）的参数推断在许多科学应用中具有基本重要性。虽然ODE解通常由确定性算法近似，但有关概率求解器的新研究表明，它们通过更好地考虑数字误差产生更可靠的参数估计。然而，许多ODE系统对其参数值非常敏感。这在似然函数中产生了深层的局部最小值——现有的概率求解器尚未解决这个问题。在这里，我们展示了一种用于概率ODE解的贝叶斯滤波范式，通过数据自适应地学习嘈杂的ODE观察结果，可以显着降低参数的敏感性。我们的方法适用于具有部分未观测分量和任意非高斯噪声的ODEs。几个例子表明，它比现有的概率ODE求解器更精确，甚至在某些情况下比精确ODE似然函数更精确。

    Parameter inference for ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODE solutions are typically approximated by deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local minima in the likelihood function -- a problem which existing probabilistic solvers have yet to resolve. Here, we show that a Bayesian filtering paradigm for probabilistic ODE solution can dramatically reduce sensitivity to parameters by learning from the noisy ODE observations in a data-adaptive manner. Our method is applicable to ODEs with partially unobserved components and with arbitrary non-Gaussian noise. Several examples demonstrate that it is more accurate than existing probabilistic ODE solvers, and even in some cases than the exact ODE likel
    
[^105]: 关于图神经网络中本地同质性水平的性能差异

    On Performance Discrepancies Across Local Homophily Levels in Graph Neural Networks. (arXiv:2306.05557v1 [cs.SI])

    [http://arxiv.org/abs/2306.05557](http://arxiv.org/abs/2306.05557)

    本文研究了GNN在测试时节点的本地同质性水平与其图的全局同质性水平偏离时的性能，并介绍一种新参数用于控制同质性，在生成的图中系统地研究本地同质性的影响。

    

    GNN的研究强调高同质性（即相似类节点相互连接的倾向）与节点分类的强预测性能之间的关系。然而，最近的研究发现这种关系更加微妙，证明即使简单的GNN也可以在某些异质性环境中学习。为了弥合这些发现之间的差距，我们重新思考了先前作品中的假设，并确定数据集经常被视为在节点间具有恒定的同质性水平。为了更接近真实世界的数据集，我们理论上和实证地研究了GNN在测试时节点的本地同质性水平与其图的全局同质性水平偏离时的性能。为了帮助我们的理论分析，我们在同质性分析中常用的优先附加模型中引入了一个新参数，以控制生成的图中的本地同质性水平，从而实现系统的实证研究，探究本地同质性的影响。

    Research on GNNs has highlighted a relationship between high homophily (i.e., the tendency for nodes of a similar class to connect) and strong predictive performance in node classification. However, recent research has found the relationship to be more nuanced, demonstrating that even simple GNNs can learn in certain heterophilous settings. To bridge the gap between these findings, we revisit the assumptions made in previous works and identify that datasets are often treated as having a constant homophily level across nodes. To align closer to real-world datasets, we theoretically and empirically study the performance of GNNs when the local homophily level of a node deviates at test-time from the global homophily level of its graph. To aid our theoretical analysis, we introduce a new parameter to the preferential attachment model commonly used in homophily analysis to enable the control of local homophily levels in generated graphs, enabling a systematic empirical study on how local ho
    
[^106]: 情感和情绪引导的改写

    Emotion and Sentiment Guided Paraphrasing. (arXiv:2306.05556v1 [cs.CL])

    [http://arxiv.org/abs/2306.05556](http://arxiv.org/abs/2306.05556)

    本研究提出了一种情感和情绪引导的改写框架，实现了细粒度的情感调节，可用于多种场景，通过添加细粒度情感标签可以提高结果质量。

    

    改写生成是自然语言处理中常见且重要的任务，它可以对文本进行修改同时保留原本的意思。情绪改写可用于多种场景，包括调节在线对话和防止网络欺凌。本文提出了一种新的任务——细粒度情绪改写，可以在保留原文意义的同时，平滑地改变其情感强度，从而实现细粒度的情感调节。我们通过添加细粒度情感标签对几个常用的改写数据集进行了重建。然后，利用预训练语言模型进行有条件的文本生成，提出了一种情感和情绪引导的改写框架。对调整后的模型进行广泛的评估表明，将细粒度情感标签包含在改写训练中可以提高结果质量。

    Paraphrase generation, a.k.a. paraphrasing, is a common and important task in natural language processing. Emotional paraphrasing, which changes the emotion embodied in a piece of text while preserving its meaning, has many potential applications, including moderating online dialogues and preventing cyberbullying. We introduce a new task of fine-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in fine-grained settings following smooth variations in affective dimensions while preserving the meaning of the original text. We reconstruct several widely used paraphrasing datasets by augmenting the input and target texts with their fine-grained emotion labels. Then, we propose a framework for emotion and sentiment guided paraphrasing by leveraging pre-trained language models for conditioned text generation. Extensive evaluation of the fine-tuned models suggests that including fine-grained emotion labels in the paraphrase t
    
[^107]: 物理信息神经网络在逆流自发渗透中的应用和预测：早期和晚期的模拟

    Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks. (arXiv:2306.05554v1 [physics.comp-ph])

    [http://arxiv.org/abs/2306.05554](http://arxiv.org/abs/2306.05554)

    本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。

    

    逆流自发渗透（COUCSI）是一种多孔材料中的过程，其中润湿相取代了非润湿相的位置。本文首次探讨了物理信息神经网络（PINNs）在解决早期（ET）和晚期（LT）COUCSI问题中的应用。同时，我们还研究了改变变量技术以改进PINNs的性能。我们通过改变自变量将COUCSI问题分别用XT-，XY-和Z-三种等效形式进行描述：第一个描述了饱和度作为规范化位置X和时间T的函数;第二个描述了X和Y=T^0.5作为函数的饱和度;第三个作为Z=X/T^0.5的唯一函数（仅在ET下有效）。该PINN模型使用前馈神经网络生成，并基于最小化加权损失函数进行训练，包括物理信息丢失项和与初始边界条件相对应的项。没有合成或实验数据被调用。

    Countercurrent spontaneous imbibition (COUCSI) is a process in porous materials in which a wetting phase displaces non-wetting phase. In this work, we investigate for the first time the application of Physics-Informed Neural Networks (PINNs) in solving the 1D COUCSI problem in both early (ET) and late (LT) times. Also novel, we examine the Change-of-Variables technique for improving the performance of PINNs. We formulated the COUCSI problem in three equivalent forms by changing the independent variables: XT-, XY-, and Z-formulations. The first describes saturation as function of normalized position X and time T; the second as function of X and Y=T^0.5; and the third as a sole function of Z=X/T^0.5 (valid only at ET). The PINN model was generated using a feed-forward neural network and trained based on minimizing a weighted loss function, including the physics-informed loss term and terms corresponding to the initial and boundary conditions. No synthetical or experimental data were invo
    
[^108]: 等变层与不变层的对比：点云分类中骨干网络和池化的比较

    Equivariant vs. Invariant Layers: A Comparison of Backbone and Pooling for Point Cloud Classification. (arXiv:2306.05553v1 [cs.CV])

    [http://arxiv.org/abs/2306.05553](http://arxiv.org/abs/2306.05553)

    本文研究了置换等变骨干和置换不变全局池化在点云分类中的相互作用，揭示了使用复杂池化方法可以显著提高简单骨干的性能，但即使是复杂的骨干也可以受益于更复杂的、明确编码置换不变性的池化方法，使用置换不变池化是获得最先进结果的关键。

    

    学习点云等集合结构数据已受到学术界的广泛关注。几何深度学习通过整合置换对称性，为设计有效的点云神经网络提供了蓝本。我们感兴趣的是置换不变网络，该网络由置换等变骨干、置换不变全局池化和回归/分类头组成。尽管现有文献侧重于改善置换等变骨干，但全局池化的影响往往被忽视。在本文中，我们研究了置换等变骨干和置换不变全局池化在三个基准点云分类数据集上的相互作用。我们的研究结果表明：1）诸如基于传输或注意力的复杂池化方法可以显著提高简单骨干的性能，但对于更复杂的骨干，这些方法的收益会减弱。2）甚至复杂的骨干也可以受益于更复杂的池化方法，这些方法明确地编码置换不变性。3）使用置换不变池化对于在点云分类数据集上获得最先进的结果至关重要。

    Learning from set-structured data, such as point clouds, has gained significant attention from the community. Geometric deep learning provides a blueprint for designing effective set neural networks by incorporating permutation symmetry. Of our interest are permutation invariant networks, which are composed of a permutation equivariant backbone, permutation invariant global pooling, and regression/classification head. While existing literature has focused on improving permutation equivariant backbones, the impact of global pooling is often overlooked. In this paper, we examine the interplay between permutation equivariant backbones and permutation invariant global pooling on three benchmark point cloud classification datasets. Our findings reveal that: 1) complex pooling methods, such as transport-based or attention-based poolings, can significantly boost the performance of simple backbones, but the benefits diminish for more complex backbones, 2) even complex backbones can benefit fro
    
[^109]: 对带“标记语言模型”中93个受歧视群体的偏见及其对下游情感分类任务的影响

    Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks. (arXiv:2306.05550v1 [cs.CY])

    [http://arxiv.org/abs/2306.05550](http://arxiv.org/abs/2306.05550)

    本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。

    

    人工智能模型的快速部署需要对这些模型固有的偏见和风险进行彻底的调查，以了解它们对个人和社会的影响。本研究通过对大规模社会污名化的偏见进行研究，扩展了已有工作对偏见评估的焦点。它关注美国93个社会污名化群体，包括与疾病、残疾、药物使用、心理疾病、宗教、性取向、社会经济地位和其他相关因素有关的一系列情况。我们研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对这些群体的偏见。为了评估93个污名化条件的偏见存在，我们确定了29个非污名化条件进行比较分析。基于社会排斥的心理学尺度-社会距离量表，我们对六个MLMs进行了提示：RoBERTa-base、RoBERTa-large、XLNet-large、BERTweet-base、BERTweet-la。

    The rapid deployment of artificial intelligence (AI) models demands a thorough investigation of biases and risks inherent in these models to understand their impact on individuals and society. This study extends the focus of bias evaluation in extant work by examining bias against social stigmas on a large scale. It focuses on 93 stigmatized groups in the United States, including a wide range of conditions related to disease, disability, drug use, mental illness, religion, sexuality, socioeconomic status, and other relevant factors. We investigate bias against these groups in English pre-trained Masked Language Models (MLMs) and their downstream sentiment classification tasks. To evaluate the presence of bias against 93 stigmatized conditions, we identify 29 non-stigmatized conditions to conduct a comparative analysis. Building upon a psychology scale of social rejection, the Social Distance Scale, we prompt six MLMs: RoBERTa-base, RoBERTa-large, XLNet-large, BERTweet-base, BERTweet-la
    
[^110]: AI增强的控制工程方法

    AI Enhanced Control Engineering Methods. (arXiv:2306.05545v1 [math.OC])

    [http://arxiv.org/abs/2306.05545](http://arxiv.org/abs/2306.05545)

    本文讨论了利用AI工具进行控制工程的方法。其中，自动微分是核心工具之一，可用于局部稳定性分析和状态估计等方面。此外，还探讨了将微分代数方程转换为常微分方程进行控制设计以及利用机器学习模型进行全局参数化等应用。

    

    基于人工智能和机器学习的方法正在几乎所有工程领域中变得普遍。控制工程也不能逃避这一趋势。本文探讨了如何在控制应用中使用AI工具。我们所关注的核心工具是自动微分。其两个直接应用包括利用Kalman滤波器将系统动力学线性化以进行局部稳定性分析或状态估计。此外，我们还探讨了其他用途，例如将微分代数方程转换为常微分方程进行控制设计。此外，我们还探讨了在模型预测控制应用中，利用机器学习模型为状态向量和控制输入进行全局参数化的用途。对于每个考虑的用例，我们都给出了例子和结果。

    AI and machine learning based approaches are becoming ubiquitous in almost all engineering fields. Control engineering cannot escape this trend. In this paper, we explore how AI tools can be useful in control applications. The core tool we focus on is automatic differentiation. Two immediate applications are linearization of system dynamics for local stability analysis or for state estimation using Kalman filters. We also explore other usages such as conversion of differential algebraic equations to ordinary differential equations for control design. In addition, we explore the use of machine learning models for global parameterizations of state vectors and control inputs in model predictive control applications. For each considered use case, we give examples and results.
    
[^111]: BOOT: 无需数据的差分扩散模型蒸馏方法

    BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping. (arXiv:2306.05544v1 [cs.CV])

    [http://arxiv.org/abs/2306.05544](http://arxiv.org/abs/2306.05544)

    本文提出了一种名为BOOT的技术，它使用有效的无数据蒸馏算法来训练一个时间条件模型，以预测预训练的差分扩散模型老师的输出。我们的方法可以适用于不同的扩散模型，同时实现了显著的推理时间加速。

    

    差分扩散模型在生成多样的图像方面具有潜在的优势。然而，由于迭代去噪的缘故，它们的性能常常受到缓慢的生成速度的影响。知识蒸馏最近被提出作为一种可行的方法，它可以在不显著降低质量的情况下将推理步骤减少到一个或几个步骤。然而，现有的蒸馏方法要么需要在老师模型中生成大量的合成训练数据，要么需要使用真实数据进行昂贵的在线学习。本文提出了一种新的技术BOOT，通过有效的无数据蒸馏算法克服了这些限制。核心思想是学习一个时间条件模型，它可以根据任何时间步长预测一个预训练的差分扩散模型老师的输出。这种模型可以通过两个连续采样步骤的自助法进行有效的训练。此外，我们的方法可以轻松适用于不同的扩散模型，并且不需要任何额外的训练数据或计算资源。在样本质量和多样性方面，我们在几个扩散模型上展示了我们方法的有效性，同时实现了显著的推理时间加速。

    Diffusion models have demonstrated excellent potential for generating diverse images. However, their performance often suffers from slow generation due to iterative denoising. Knowledge distillation has been recently proposed as a remedy that can reduce the number of inference steps to one or a few without significant quality degradation. However, existing distillation methods either require significant amounts of offline computation for generating synthetic training data from the teacher model or need to perform expensive online learning with the help of real data. In this work, we present a novel technique called BOOT, that overcomes these limitations with an efficient data-free distillation algorithm. The core idea is to learn a time-conditioned model that predicts the output of a pre-trained diffusion model teacher given any time step. Such a model can be efficiently trained based on bootstrapping from two consecutive sampled steps. Furthermore, our method can be easily adapted to 
    
[^112]: 使用音频数据检测政治辩论、演讲和访谈中值得核实的论断

    Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data. (arXiv:2306.05535v1 [cs.CL])

    [http://arxiv.org/abs/2306.05535](http://arxiv.org/abs/2306.05535)

    政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。

    

    社会的一大部分团结在相同的愿景和思想周围，具有巨大的能量。这正是政治人物希望为他们的事业所累积的。为了达到这个目标，他们有时会使用扭曲或隐藏真相的手段，无论是无意的还是有意的，这为错误信息和误导开了大门。自动检测值得核实的论断的工具将对辩论主持人、记者和事实核查组织有很大帮助。虽然以前关于检测值得核实的论断的工作重点是文本，但在这里，我们探讨了音频信号作为额外信息源的实用性。我们创建了一个新的多模态数据集（英语文本和音频），包含48小时的演讲。我们的评估结果表明，在多个演讲者的情况下，音频模态与文本结合使用比仅使用文本具有改进效果。此外，单声道音频模型可以胜过单声道文本模型。

    A large portion of society united around the same vision and ideas carries enormous energy. That is precisely what political figures would like to accumulate for their cause. With this goal in mind, they can sometimes resort to distorting or hiding the truth, unintentionally or on purpose, which opens the door for misinformation and disinformation. Tools for automatic detection of check-worthy claims would be of great help to moderators of debates, journalists, and fact-checking organizations. While previous work on detecting check-worthy claims has focused on text, here we explore the utility of the audio signal as an additional information source. We create a new multimodal dataset (text and audio in English) containing 48 hours of speech. Our evaluation results show that the audio modality together with text yields improvements over text alone in the case of multiple speakers. Moreover, an audio-only model could outperform a text-only one for a single speaker.
    
[^113]: 应用于天体物理学的对比学习的简要评论

    A brief review of contrastive learning applied to astrophysics. (arXiv:2306.05528v1 [astro-ph.IM])

    [http://arxiv.org/abs/2306.05528](http://arxiv.org/abs/2306.05528)

    对比学习是一种自监督机器学习算法，用于从多维数据集中提取信息度量。它可以消除已知的仪器效应，并使用有限的标签执行监督分类和回归，展示了面向“基础模型”的良好发展前景。

    

    随着天文数据集的增加，从高维度空间中提取模式的可靠工具变得更加必要。对比学习是一种自监督机器学习算法，从多维数据集中提取信息度量，近年来在计算机视觉和机器学习社区越来越受欢迎。它最大化了同一输入数据的增强版本中提取的信息之间的一致性，使最终表示对应用的变换不变。对比学习在天文学中特别有用，可以消除已知的仪器效应，并使用有限的标签执行监督分类和回归，展示了面向“基础模型”的良好发展前景。这篇简短的评论论文简要总结了对比学习背后的主要概念，并评估了第一个有前途的应用。

    Reliable tools to extract patterns from high-dimensionality spaces are becoming more necessary as astronomical datasets increase both in volume and complexity. Contrastive Learning is a self-supervised machine learning algorithm that extracts informative measurements from multi-dimensional datasets, which has become increasingly popular in the computer vision and Machine Learning communities in recent years. To do so, it maximizes the agreement between the information extracted from augmented versions of the same input data, making the final representation invariant to the applied transformations. Contrastive Learning is particularly useful in astronomy for removing known instrumental effects and for performing supervised classifications and regressions with a limited amount of available labels, showing a promising avenue towards \emph{Foundation Models}. This short review paper briefly summarizes the main concepts behind contrastive learning and reviews the first promising application
    
[^114]: 一种个性化联邦学习的终身学习方法

    PeFLL: A Lifelong Learning Approach to Personalized Federated Learning. (arXiv:2306.05515v1 [cs.LG])

    [http://arxiv.org/abs/2306.05515](http://arxiv.org/abs/2306.05515)

    PeFLL是个性化联邦学习的一种新方法，通过联合训练嵌入网络和超网络，PeFLL能够学习输出特定于每个客户端的模型，并且在其它新出现的客户端上表现良好。

    

    个性化联邦学习（pFL）已成为应对参与客户端数据分布的统计异质性挑战的常用方法。pFL不是学习单个全局模型，而是旨在学习每个客户端的个体模型，同时仍然利用其他客户端可用的数据。在这项工作中，我们提出了PeFLL，这是一种根植于终身学习的新型pFL方法，不仅在训练阶段存在的客户端上表现良好，而且在未来可能出现的客户端上也表现良好。PeFLL通过联合训练嵌入网络和超网络来学习输出特定于客户端的模型。嵌入网络学习以一种反映它们之间相似性的潜在描述符空间中表示客户端。超网络学习从这个潜在空间到可能的客户模型空间的映射。我们的实验证明，与先前的方法相比，PeFLL产生了更高准确率的模型。

    Personalized federated learning (pFL) has emerged as a popular approach to dealing with the challenge of statistical heterogeneity between the data distributions of the participating clients. Instead of learning a single global model, pFL aims to learn an individual model for each client while still making use of the data available at other clients. In this work, we present PeFLL, a new pFL approach rooted in lifelong learning that performs well not only on clients present during its training phase, but also on any that may emerge in the future. PeFLL learns to output client specific models by jointly training an embedding network and a hypernetwork. The embedding network learns to represent clients in a latent descriptor space in a way that reflects their similarity to each other. The hypernetwork learns a mapping from this latent space to the space of possible client models. We demonstrate experimentally that PeFLL produces models of superior accuracy compared to previous methods, es
    
[^115]: 基于回归模型和MRI特征的健康大脑年龄鲁棒估计。

    Robust Brain Age Estimation via Regression Models and MRI-derived Features. (arXiv:2306.05514v1 [eess.IV])

    [http://arxiv.org/abs/2306.05514](http://arxiv.org/abs/2306.05514)

    本文提出了一个基于MRI特征和回归模型的健康大脑年龄鲁棒估计框架，可用于评估神经系统疾病和了解衰老期间形态学变化，平均绝对误差为3.02岁，相关系数为0.96，且具有高度的鲁棒性。

    

    生物学大脑年龄的确定是评估神经系统疾病和了解衰老期间形态学变化的重要生物标志物。提出了各种机器学习模型来通过健康控制者的磁共振成像(MRI)来估计脑龄。然而，由于选择适当的MRI特征和MRI获取成本高昂，开发强大的脑龄估测(BAE)框架一直是具有挑战性的。本文使用OpenBHB数据集提出了一种新的BAE框架，该数据集是一个新的多站点和公开可用的基准数据集，包括来自6至86岁之间3965名健康受试者的T1加权(T1-w)脑MRI扫描的区域特征。我们的方法集成了三种不同的MRI区域特征和不同的回归模型，从而实现高精度的脑龄估计，平均绝对误差(MAE)为3.02岁，预测和实际年龄之间的相关系数(r)为0.96。我们的框架在外部验证以及对不同MRI采集协议的概括方面高度鲁棒，预计在临床和研究领域具有广泛的应用。

    The determination of biological brain age is a crucial biomarker in the assessment of neurological disorders and understanding of the morphological changes that occur during aging. Various machine learning models have been proposed for estimating brain age through Magnetic Resonance Imaging (MRI) of healthy controls. However, developing a robust brain age estimation (BAE) framework has been challenging due to the selection of appropriate MRI-derived features and the high cost of MRI acquisition. In this study, we present a novel BAE framework using the Open Big Healthy Brain (OpenBHB) dataset, which is a new multi-site and publicly available benchmark dataset that includes region-wise feature metrics derived from T1-weighted (T1-w) brain MRI scans of 3965 healthy controls aged between 6 to 86 years. Our approach integrates three different MRI-derived region-wise features and different regression models, resulting in a highly accurate brain age estimation with a Mean Absolute Error (MAE
    
[^116]: AMEE：时间序列分类的解释评价框架

    AMEE: A Robust Framework for Explanation Evaluation in Time Series Classification. (arXiv:2306.05501v1 [cs.LG])

    [http://arxiv.org/abs/2306.05501](http://arxiv.org/abs/2306.05501)

    AMEE是一个模型无关的解释评价框架，用于量化和比较时间序列分类中多种基于显著性的解释方法的信息价值，帮助解决在这一领域中解释方法选择的难题。

    

    本文旨在提供一个框架，用于定量评估和排名时间序列分类任务中的解释方法，该任务涉及到卫生保健和金融等关键领域的普遍数据类型。最近对时间序列分类解释方法的研究兴趣激增，提供了各种各样的解释技术。然而，当这些解释技术在特定问题上产生分歧时，仍然不清楚使用哪种技术。比较解释以找到正确答案并不容易。两个关键挑战仍然存在：如何定量和稳健地评估给定解释方法的信息价值（即与分类任务相关性），以及如何并排比较解释方法。我们提出了AMEE，一种模型无关的解释评价框架，用于量化和比较多种应用于时间序列分类的基于显著性的解释方法。在输入时间序列中增加扰动

    This paper aims to provide a framework to quantitatively evaluate and rank explanation methods for the time series classification task, which deals with a prevalent data type in critical domains such as healthcare and finance. The recent surge of research interest in explanation methods for time series classification has provided a great variety of explanation techniques. Nevertheless, when these explanation techniques disagree on a specific problem, it remains unclear which of them to use. Comparing the explanations to find the right answer is non-trivial. Two key challenges remain: how to quantitatively and robustly evaluate the informativeness (i.e., relevance for the classification task) of a given explanation method, and how to compare explanation methods side-by-side. We propose AMEE, a Model-Agnostic Explanation Evaluation framework for quantifying and comparing multiple saliency-based explanations for time series classification. Perturbation is added to the input time series gu
    
[^117]: 文本到图像模型中分析偏见的单词级解释

    Word-Level Explanations for Analyzing Bias in Text-to-Image Models. (arXiv:2306.05500v1 [cs.CL])

    [http://arxiv.org/abs/2306.05500](http://arxiv.org/abs/2306.05500)

    本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。

    

    文本到图像模型接收一句话（即提示）并生成与该输入提示相关联的图像。但是，这些模型可以生成基于种族和性别而偏袒少数族裔的图像。本文研究了输入提示中哪个单词导致生成图像出现偏见。我们引入了一种计算提示中每个单词得分的方法；这些得分代表其在模型输出偏差中的影响。我们的方法遵循“删除解释”的原则，利用屏蔽语言模型计算影响得分。我们在稳定扩散上进行实验，证明我们的方法可以识别生成的图像中复制社会刻板印象。

    Text-to-image models take a sentence (i.e., prompt) and generate images associated with this input prompt. These models have created award wining-art, videos, and even synthetic datasets. However, text-to-image (T2I) models can generate images that underrepresent minorities based on race and sex. This paper investigates which word in the input prompt is responsible for bias in generated images. We introduce a method for computing scores for each word in the prompt; these scores represent its influence on biases in the model's output. Our method follows the principle of \emph{explaining by removing}, leveraging masked language models to calculate the influence scores. We perform experiments on Stable Diffusion to demonstrate that our method identifies the replication of societal stereotypes in generated images.
    
[^118]: 重新评估损失函数：增强深度学习模型对标签噪声的鲁棒性

    Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models. (arXiv:2306.05497v1 [cs.LG])

    [http://arxiv.org/abs/2306.05497](http://arxiv.org/abs/2306.05497)

    本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。

    

    大规模标注的数据集中难免会出现错误的标签，这给深度神经网络的训练带来了极大的挑战，因为它们很容易适应这些错误的标签。只有使用不受噪声干扰的鲁棒模型进行训练，才能获得良好的泛化性能。创建噪声鲁棒模型的一种简单而有效的方式是使用噪声鲁棒损失函数。然而，提出的损失函数数量众多，它们通常伴随着超参数，而且可能学习速度比广泛使用但对噪声敏感的交叉熵损失要慢。通过启发式考虑和广泛的数值实验，我们研究了在哪些情况下提出的损失函数适用，并提出了如何选择合适的损失的建议。此外，我们提出了一种新的技术来增强带有有界损失函数的学习：包括输出偏置，即略微增加与正确标签相对应的神经元预激活。令人惊讶的是，我们发现这种技术在无需超参数调整的情况下表现与最先进的方法类似。

    Large annotated datasets inevitably contain incorrect labels, which poses a major challenge for the training of deep neural networks as they easily fit the labels. Only when training with a robust model that is not easily distracted by the noise, a good generalization performance can be achieved. A simple yet effective way to create a noise robust model is to use a noise robust loss function. However, the number of proposed loss functions is large, they often come with hyperparameters, and may learn slower than the widely used but noise sensitive Cross Entropy loss. By heuristic considerations and extensive numerical experiments, we study in which situations the proposed loss functions are applicable and give suggestions on how to choose an appropriate loss. Additionally, we propose a novel technique to enhance learning with bounded loss functions: the inclusion of an output bias, i.e. a slight increase in the neuron pre-activation corresponding to the correct label. Surprisingly, we f
    
[^119]: 视觉变换器与全自注意力网络的鲁棒性综合分析：需要注意通道处理设计吗？

    Is Attentional Channel Processing Design Required? Comprehensive Analysis Of Robustness Between Vision Transformers And Fully Attentional Networks. (arXiv:2306.05495v1 [cs.CV])

    [http://arxiv.org/abs/2306.05495](http://arxiv.org/abs/2306.05495)

    本研究比较了传统视觉变换器和全自注意力网络模型的鲁棒性，研究发现注意通道处理设计对于提高模型的鲁棒性很重要。

    

    对于标准CNN模型和视觉变换器，已经进行了鲁棒性测试，但是缺乏传统视觉变换器不带额外注意通道设计与最新的全自注意力网络模型鲁棒性的综合研究。因此，本文使用ImageNet数据集比较全自注意网络(FAN)模型与传统视觉变换器的鲁棒性，以了解注意通道处理设计的作用，并使用白盒攻击和黑盒攻击研究它们之间的可迁移性。

    The robustness testing has been performed for standard CNN models and Vision Transformers, however there is a lack of comprehensive study between the robustness of traditional Vision Transformers without an extra attentional channel design and the latest fully attentional network(FAN) models. So in this paper, we use the ImageNet dataset to compare the robustness of fully attentional network(FAN) models with traditional Vision Transformers to understand the role of an attentional channel processing design using white box attacks and also study the transferability between the same using black box attacks.
    
[^120]: 神经网络中对抗性漏洞攻击的实用性测试：动态学习的影响

    Adversarial Evasion Attacks Practicality in Networks: Testing the Impact of Dynamic Learning. (arXiv:2306.05494v1 [cs.CR])

    [http://arxiv.org/abs/2306.05494](http://arxiv.org/abs/2306.05494)

    本文对于基于机器学习的网络入侵检测系统(NIDS)的对抗性攻击进行了分类，同时探究了持续再训练对NIDS对抗性攻击的影响。实验表明，即使没有对抗性训练，持续再训练也可以减少对抗性攻击的影响。

    

    机器学习被广泛应用于网络入侵检测系统(NIDS)中，由于其自动化的特性和在处理和分类大量数据上的高精度。但机器学习存在缺陷，其中最大的问题之一是对抗性攻击，其目的是使机器学习模型产生错误的预测。本文提出了两个独特的贡献：对抗性攻击对基于机器学习的NIDS实用性问题的分类和对持续训练对NIDS对抗性攻击的影响进行了研究。我们的实验表明，即使没有对抗性训练，持续再训练也可以减少对抗性攻击的影响。虽然对抗性攻击可能会危及基于机器学习的NIDS，但持续再训练可带来一定的缓解效果。

    Machine Learning (ML) has become ubiquitous, and its deployment in Network Intrusion Detection Systems (NIDS) is inevitable due to its automated nature and high accuracy in processing and classifying large volumes of data. However, ML has been found to have several flaws, on top of them are adversarial attacks, which aim to trick ML models into producing faulty predictions. While most adversarial attack research focuses on computer vision datasets, recent studies have explored the practicality of such attacks against ML-based network security entities, especially NIDS.  This paper presents two distinct contributions: a taxonomy of practicality issues associated with adversarial attacks against ML-based NIDS and an investigation of the impact of continuous training on adversarial attacks against NIDS. Our experiments indicate that continuous re-training, even without adversarial training, can reduce the effect of adversarial attacks. While adversarial attacks can harm ML-based NIDSs, ou
    
[^121]: 开放词汇物体检测的多模态分类器

    Multi-Modal Classifiers for Open-Vocabulary Object Detection. (arXiv:2306.05493v1 [cs.CV])

    [http://arxiv.org/abs/2306.05493](http://arxiv.org/abs/2306.05493)

    本文提出了一种开放词汇物体检测的多模态分类器，能够在推断过程中检测超出训练范畴的目标，并优于传统基线模型。

    

    本文的目标在于实现开放词汇物体检测（OVOD），提出了通过语言描述、图像实例或两者的组合，指定新类别的三种方式，并构建了基于文本和基于视觉的强大分类器，最终提出一种融合了多模态信息的分类器。在评估中，我们的方法优于基线。

    The goal of this paper is open-vocabulary object detection (OVOD) $\unicode{x2013}$ building a model that can detect objects beyond the set of categories seen at training, thus enabling the user to specify categories of interest at inference without the need for model retraining. We adopt a standard two-stage object detector architecture, and explore three ways for specifying novel categories: via language descriptions, via image exemplars, or via a combination of the two. We make three contributions: first, we prompt a large language model (LLM) to generate informative language descriptions for object classes, and construct powerful text-based classifiers; second, we employ a visual aggregator on image exemplars that can ingest any number of images as input, forming vision-based classifiers; and third, we provide a simple method to fuse information from language descriptions and image exemplars, yielding a multi-modal classifier. When evaluating on the challenging LVIS open-vocabulary
    
[^122]: 带温度指数测度的增强学习算法

    Boosting with Tempered Exponential Measures. (arXiv:2306.05487v1 [cs.LG])

    [http://arxiv.org/abs/2306.05487](http://arxiv.org/abs/2306.05487)

    本文提出了一种以温度指数测度为基础的机器学习算法——$t$-AdaBoost，并证明其在$t\in [0,1)$时可以保持AdaBoost的指数收敛速率，同时具有更好的性能表现。

    

    本文提出了一种新的机器学习算法——$t$-AdaBoost，它是AdaBoost算法的推广。我们使用以温度参数$t$为索引的温度指数测度（TEM）对损失函数进行建模并证明当$t\in [0,1)$时，该算法保持了AdaBoost的指数收敛速率。此外，我们还进行了一些实验，将本算法与AdaBoost算法进行比较，并展示了$t$-AdaBoost算法在某些情况下的性能优势。

    One of the most popular ML algorithms, AdaBoost, can be derived from the dual of a relative entropy minimization problem subject to the fact that the positive weights on the examples sum to one. Essentially, harder examples receive higher probabilities. We generalize this setup to the recently introduced {\it tempered exponential measure}s (TEMs) where normalization is enforced on a specific power of the measure and not the measure itself. TEMs are indexed by a parameter $t$ and generalize exponential families ($t=1$). Our algorithm, $t$-AdaBoost, recovers AdaBoost~as a special case ($t=1$). We show that $t$-AdaBoost retains AdaBoost's celebrated exponential convergence rate when $t\in [0,1)$ while allowing a slight improvement of the rate's hidden constant compared to $t=1$. $t$-AdaBoost partially computes on a generalization of classical arithmetic over the reals and brings notable properties like guaranteed bounded leveraging coefficients for $t\in [0,1)$. From the loss that $t$-Ada
    
[^123]: 任务特定的实验设计用于治疗效果评估

    Task-specific experimental design for treatment effect estimation. (arXiv:2306.05484v1 [stat.ME])

    [http://arxiv.org/abs/2306.05484](http://arxiv.org/abs/2306.05484)

    本文提出了一种任务特定的实验设计方法，可用于治疗效果评估，并在真实世界数据集和样本量上优于其他基准方法，例如在定向营销任务上需要更少的数据来达到与RCT相同的性能。

    

    理解因果关系应该是通过人工智能实现真正影响的核心要求。由于反事实的内在不可观测性，大型随机试验（RCT）是因果推断的标准。但大型实验通常代价高昂，而随机化本身也具有成本，例如在试验的时候进行次优决策。最近的研究提出了更加样本高效的替代品，但这些替代品不能适应寻求因果效应的下游应用。在这项工作中，我们开发了一种任务特定的实验设计方法，并推导出适用于特定下游应用的采样策略。在一系列重要任务、真实世界数据集和样本量上，我们的方法优于其他基准，例如在定向营销任务上需要一个数量级的更少数据来与RCT的性能匹配。

    Understanding causality should be a core requirement of any attempt to build real impact through AI. Due to the inherent unobservability of counterfactuals, large randomised trials (RCTs) are the standard for causal inference. But large experiments are generically expensive, and randomisation carries its own costs, e.g. when suboptimal decisions are trialed. Recent work has proposed more sample-efficient alternatives to RCTs, but these are not adaptable to the downstream application for which the causal effect is sought. In this work, we develop a task-specific approach to experimental design and derive sampling strategies customised to particular downstream applications. Across a range of important tasks, real-world datasets, and sample sizes, our method outperforms other benchmarks, e.g. requiring an order-of-magnitude less data to match RCT performance on targeted marketing tasks.
    
[^124]: 关于勘探在强化学习泛化中的重要性

    On the Importance of Exploration for Generalization in Reinforcement Learning. (arXiv:2306.05483v1 [cs.LG])

    [http://arxiv.org/abs/2306.05483](http://arxiv.org/abs/2306.05483)

    本论文研究了勘探在强化学习中的重要性，提出了一种名为EDE的基于值的算法，它是第一个在Procgen和Crafter等环境中取得最先进结果的方法，具有实用价值。

    

    目前提高强化学习泛化能力的方法主要集中于表示学习，而忽略了勘探等强化学习特有的方面。我们假设代理的勘探策略在其泛化到新环境的能力中发挥了关键作用。通过一系列实验，在一个基于表格的情境MDP中展示了勘探不仅有助于在训练环境中有效地找到最优策略，而且有助于获取知识以便在未知环境中进行决策。基于这些观察结果，我们提出了EDE：通过分布式集合实现勘探，这是一种方法，通过Q值分布的集合鼓励开发具有高先验不确定性的状态的勘探。我们的算法是第一个在高维观察中获得Procgen和Crafter中泛化性最好的值方法。提供了开源实现。

    Existing approaches for improving generalization in deep reinforcement learning (RL) have mostly focused on representation learning, neglecting RL-specific aspects such as exploration. We hypothesize that the agent's exploration strategy plays a key role in its ability to generalize to new environments. Through a series of experiments in a tabular contextual MDP, we show that exploration is helpful not only for efficiently finding the optimal policy for the training environments but also for acquiring knowledge that helps decision making in unseen environments. Based on these observations, we propose EDE: Exploration via Distributional Ensemble, a method that encourages exploration of states with high epistemic uncertainty through an ensemble of Q-value distributions. Our algorithm is the first value-based approach to achieve state-of-the-art on both Procgen and Crafter, two benchmarks for generalization in RL with high-dimensional observations. The open-sourced implementation can be f
    
[^125]: 针对高速公路合流场景的运动规划，基于可变长度观察的轨迹预测

    Trajectory Prediction with Observations of Variable-Length for Motion Planning in Highway Merging scenarios. (arXiv:2306.05478v1 [cs.RO])

    [http://arxiv.org/abs/2306.05478](http://arxiv.org/abs/2306.05478)

    本文提出一种基于Transformer的轨迹预测方法，可以处理任何长度的观察，并实现了在高速公路合并情境中的准确预测。

    

    在动态驾驶场景（如高速公路合流）中，准确预测附近车辆的轨迹对于自动驾驶车辆的安全运动规划至关重要。现有的方法无法对车辆进行预测，除非观察了固定时长的两秒或以上。这导致车辆对于进入其感知范围的车辆无法快速反应，从而产生安全隐患。因此，本文提出了一种新颖的基于Transformer的轨迹预测方法，特别训练以处理观察长度大于一帧的任何情况。我们使用两个大型高速公路轨迹数据集（highD和exiD）对所提出的方法进行了全面评估。此外，我们使用exiD数据集中的广泛合并场景研究了所提出的预测方法对运动规划和控制任务的影响。据我们所知，这是首次采用这样一个大型高速公路合流数据集进行研究。

    Accurate trajectory prediction of nearby vehicles is crucial for the safe motion planning of automated vehicles in dynamic driving scenarios such as highway merging. Existing methods cannot initiate prediction for a vehicle unless observed for a fixed duration of two or more seconds. This prevents a fast reaction by the ego vehicle to vehicles that enter its perception range, thus creating safety concerns. Therefore, this paper proposes a novel transformer-based trajectory prediction approach, specifically trained to handle any observation length larger than one frame. We perform a comprehensive evaluation of the proposed method using two large-scale highway trajectory datasets, namely the highD and exiD. In addition, we study the impact of the proposed prediction approach on motion planning and control tasks using extensive merging scenarios from the exiD dataset. To the best of our knowledge, this marks the first instance where such a large-scale highway merging dataset has been empl
    
[^126]: 患语言障碍者的潜在短语匹配系统

    Latent Phrase Matching for Dysarthric Speech. (arXiv:2306.05446v1 [eess.AS])

    [http://arxiv.org/abs/2306.05446](http://arxiv.org/abs/2306.05446)

    患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。

    

    很多消费类语音识别系统不能为语言障碍患者提供良好的体验和识别效果，尤其是对于语言障碍情况更为严重的人。最近的研究集中于个性化语音模型的探索，以便更好地适应非典型的语音模式。我们提出了一种基于示例的个性化短语识别系统，该系统使用少量的语音进行训练，不依赖于传统发音词典，不受不同语言影响，且在各种语音障碍情况下具有很好的泛化性能。在32名患有言语困难的人员的内部数据集上，该方法不受严重程度影响，与商业语音识别系统相比，召回率提高了60%。在公共EasyCall数据集上，我们的方法将精度提高了30.5%。当训练50个独特短语时，性能随短语数量增加而下降，但始终优于ASR系统。

    Many consumer speech recognition systems are not tuned for people with speech disabilities, resulting in poor recognition and user experience, especially for severe speech differences. Recent studies have emphasized interest in personalized speech models from people with atypical speech patterns. We propose a query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities. On an internal dataset collected from 32 people with dysarthria, this approach works regardless of severity and shows a 60% improvement in recall relative to a commercial speech recognition system. On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.
    
[^127]: 用深度学习预测分子系统的平衡分布

    Towards Predicting Equilibrium Distributions for Molecular Systems with Deep Learning. (arXiv:2306.05445v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.05445](http://arxiv.org/abs/2306.05445)

    本文提出了一种新的深度学习框架DiG，通过对分子系统进行描述符的条件，能够预测分子系统的平衡分布，从而提供高效生成多样构型和状态密度估计的方法。

    

    深度学习的进步大大提高了分子结构预测的精度。然而，许多对于实际应用来说重要的宏观观察结果不仅仅是一个分子结构的函数，而是由结构的平衡分布决定的。获得这些分布的传统方法，如分子动力学模拟，计算代价昂贵且常常难以处理。本文中，我们引入了一种新的深度学习框架，称为Distributional Graphormer（DiG），以预测分子系统的平衡分布。受热力学中的退火过程启发，DiG使用深度神经网络将一个简单的分布转化为平衡分布，条件是对分子系统的描述符，如化学图或蛋白质序列。这个框架使得各种构型的高效生成成为可能，并提供状态密度的估计。我们展示了我们的方法在预测各种分子系统的热力学和动力学性质方面的有效性和通用性。

    Advances in deep learning have greatly improved structure prediction of molecules. However, many macroscopic observations that are important for real-world applications are not functions of a single molecular structure, but rather determined from the equilibrium distribution of structures. Traditional methods for obtaining these distributions, such as molecular dynamics simulation, are computationally expensive and often intractable. In this paper, we introduce a novel deep learning framework, called Distributional Graphormer (DiG), in an attempt to predict the equilibrium distribution of molecular systems. Inspired by the annealing process in thermodynamics, DiG employs deep neural networks to transform a simple distribution towards the equilibrium distribution, conditioned on a descriptor of a molecular system, such as a chemical graph or a protein sequence. This framework enables efficient generation of diverse conformations and provides estimations of state densities. We demonstrat
    
[^128]: CLC: 基于对比表示学习的聚类分配方法

    CLC: Cluster Assignment via Contrastive Representation Learning. (arXiv:2306.05439v1 [cs.LG])

    [http://arxiv.org/abs/2306.05439](http://arxiv.org/abs/2306.05439)

    本文提出了一种基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配，并在大规模数据集上取得了更好的聚类性能。

    

    聚类是一项重要而具有挑战性的任务，旨在将样本分组，而不需要手动注释。最近的研究通过对自监督学习得到的特征表示进行聚类，在小型数据集上取得了出色的结果。然而，对于包含大量聚类的数据集，如ImageNet，当前的方法仍然无法实现高聚类性能。在本文中，我们提出了基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配。我们将表示分解为两部分：一部分对类别信息进行编码，并采用等分约束，另一部分捕捉实例因素。我们提出了一种对比损失，使用表示的两个部分。我们在理论上分析了所提出的对比损失，并揭示了CLC在学习聚类分配时为负样本设置不同的权重。进一步的梯度分析表明，当使用CLC时，在大规模数据集上取得了更好的聚类性能。

    Clustering remains an important and challenging task of grouping samples into clusters without manual annotations. Recent works have achieved excellent results on small datasets by performing clustering on feature representations learned from self-supervised learning. However, for datasets with a large number of clusters, such as ImageNet, current methods still can not achieve high clustering performance. In this paper, we propose Contrastive Learning-based Clustering (CLC), which uses contrastive learning to directly learn cluster assignment. We decompose the representation into two parts: one encodes the categorical information under an equipartition constraint, and the other captures the instance-wise factors. We propose a contrastive loss using both parts of the representation. We theoretically analyze the proposed contrastive loss and reveal that CLC sets different weights for the negative samples while learning cluster assignments. Further gradient analysis shows that the larger 
    
[^129]: DynamoRep: 基于轨迹的人群学习动力学用于黑盒优化问题的分类

    DynamoRep: Trajectory-Based Population Dynamics for Classification of Black-box Optimization Problems. (arXiv:2306.05438v1 [cs.LG])

    [http://arxiv.org/abs/2306.05438](http://arxiv.org/abs/2306.05438)

    本文提出了一种基于轨迹的人群学习动力学的特征提取方法，用于分类黑盒优化问题，能够在少量函数评估下实现与最先进方法相竞争的效果。

    

    将机器学习模型应用于优化算法的分析需要使用数值特征来表示优化问题，这些特征可用作机器学习模型的输入，该模型被训练用于选择或配置适合的算法来解决特定问题。在纯黑盒优化中，有关问题实例的信息只能通过函数评估获取，一种常见的方法是专门用于特征提取的功能评估，例如使用随机抽样。这种方法有两个关键缺点：（1）它减少了实际优化阶段的预算，（2）它忽略了可以从问题求解器交互中获得的有价值的信息。本文提出了一种使用简单描述统计描述优化算法轨迹的特征提取方法。我们评估了生成的特征用于从Black Box Optimization Benchmarking（BBOB）套件中分类问题类的任务。我们的结果表明，所提出的方法在需要明显较少的功能评估进行特征提取的同时，具有与最先进方法相竞争的水平。

    The application of machine learning (ML) models to the analysis of optimization algorithms requires the representation of optimization problems using numerical features. These features can be used as input for ML models that are trained to select or to configure a suitable algorithm for the problem at hand. Since in pure black-box optimization information about the problem instance can only be obtained through function evaluation, a common approach is to dedicate some function evaluations for feature extraction, e.g., using random sampling. This approach has two key downsides: (1) It reduces the budget left for the actual optimization phase, and (2) it neglects valuable information that could be obtained from a problem-solver interaction.  In this paper, we propose a feature extraction method that describes the trajectories of optimization algorithms using simple descriptive statistics. We evaluate the generated features for the task of classifying problem classes from the Black Box Op
    
[^130]: 多视角聚类方法：一步多视角聚类与多样性表征

    One-step Multi-view Clustering with Diverse Representation. (arXiv:2306.05437v1 [cs.LG])

    [http://arxiv.org/abs/2306.05437](http://arxiv.org/abs/2306.05437)

    本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中，实验结果表明其在各种标准的多视角数据集上都优于现有算法。

    

    多视角聚类因其能够利用不同视角的信息来提高效果而备受关注。本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中。实验结果表明，在各种标准的多视角数据集上，我们的方法在效果和效率方面都优于现有的同类算法。

    Multi-view clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-view clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, which limits the expressiveness of the model. Moreover, a range of methods suffer from a two-step process, i.e., multimodal learning and the subsequent $k$-means, inevitably causing a sub-optimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation method, which incorporates multi-view learning and $k$-means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervis
    
[^131]: 迈向端到端语音到文本摘要技术

    Towards End-to-end Speech-to-text Summarization. (arXiv:2306.05432v1 [cs.CL])

    [http://arxiv.org/abs/2306.05432](http://arxiv.org/abs/2306.05432)

    该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。

    

    语音到文本（S2T）摘要是一种节省时间的技术，可用于过滤和跟踪每天上传在线的广播新闻。最近深度学习中出现了具有出色文本生成能力的大型语言模型，引起了对产生简洁文档版本的摘要系统的研究重点，也称为抽象摘要。端到端（E2E）建模的S2T抽象摘要是一种有前途的方法，它提供了产生丰富潜在表示的可能性，这些表示利用了非语言和声学信息，而不是仅使用级联系统中自动生成的转录文本的语言信息。然而，文献中关于这项任务的E2E建模很少探索不同的领域，特别是广播新闻是一个具有挑战性的领域，每天向用户呈现大量和多样化的数据。我们采用级联翻译方法和端到端方法建模S2T摘要，并在广播新闻的新数据集上进行了评估。我们的结果显示，E2E方法具有更好的表现潜力，但需要进一步的研究来提高其在不同领域中的有效性和鲁棒性。

    Speech-to-text (S2T) summarization is a time-saving technique for filtering and keeping up with the broadcast news uploaded online on a daily basis. The rise of large language models from deep learning with impressive text generation capabilities has placed the research focus on summarization systems that produce paraphrased compact versions of the document content, also known as abstractive summaries. End-to-end (E2E) modelling of S2T abstractive summarization is a promising approach that offers the possibility of generating rich latent representations that leverage non-verbal and acoustic information, as opposed to the use of only linguistic information from automatically generated transcripts in cascade systems. However, the few literature on E2E modelling of this task fails on exploring different domains, namely broadcast news, which is challenging domain where large and diversified volumes of data are presented to the user every day. We model S2T summarization both with a cascade 
    
[^132]: 水晶材料性能预测的晶体特异性预训练框架

    A Crystal-Specific Pre-Training Framework for Crystal Material Property Prediction. (arXiv:2306.05344v1 [cs.LG])

    [http://arxiv.org/abs/2306.05344](http://arxiv.org/abs/2306.05344)

    本论文提出了一种基于自监督学习的晶体特异性预训练框架，该框架设计了一种互斥掩码策略，缓解了晶体物性预测中存在的标记受限问题，并增强了表示学习。同时，该框架还考虑了晶体结构中的周期性不变性，开发了周期性不变的多图模块和周期特性学习。

    

    水晶物性预测是开发新材料的重要方面。然而，为了加速晶体的研究，需要解决两个技术难题：其一，标记晶体物性本质上是困难的，因为需要进行昂贵耗时的物理模拟或实验；其二，晶体遵循特定的量子化学原理，即周期性不变性，往往无法被现有的机器学习方法捕捉到。为了克服这些挑战，我们提出了一种基于自监督学习的晶体特异性预训练框架，用于学习晶体表示。框架设计了一种互斥掩码策略，增强了表示学习，缓解了晶体物性预测中存在的标记受限问题。此外，我们还考虑了晶体结构中的周期性不变性，开发了周期性不变的多图模块和周期特性学习。

    Crystal property prediction is a crucial aspect of developing novel materials. However, there are two technical challenges to be addressed for speeding up the investigation of crystals. First, labeling crystal properties is intrinsically difficult due to the high cost and time involved in physical simulations or lab experiments. Second, crystals adhere to a specific quantum chemical principle known as periodic invariance, which is often not captured by existing machine learning methods. To overcome these challenges, we propose the crystal-specific pre-training framework for learning crystal representations with self-supervision. The framework designs a mutex mask strategy for enhancing representation learning so as to alleviate the limited labels available for crystal property prediction. Moreover, we take into account the specific periodic invariance in crystal structures by developing a periodic invariance multi-graph module and periodic attribute learning within our framework. This 
    
[^133]: 带有用户级差分隐私的联邦线性上下文强化学习

    Federated Linear Contextual Bandits with User-level Differential Privacy. (arXiv:2306.05275v1 [cs.LG])

    [http://arxiv.org/abs/2306.05275](http://arxiv.org/abs/2306.05275)

    本文研究了带有用户级差分隐私的联邦线性上下文强化学习模型，为CDP提出了近乎最优的联邦算法\robin，在LDP下证明了学习必须承受至少一个遗憾膨胀因子。

    

    本文研究了在用户级差分隐私（DP）概念下的联邦线性上下文强化学习。我们首先介绍了一个统一的联邦强化学习框架，可以适应顺序决策设置中DP的各种定义。然后在联邦强化学习框架中正式引入了用户级中心DP和本地DP，并研究了联邦线性上下文强化学习模型中学习遗憾和相应DP保证之间的基本权衡。对于CDP，我们提出了一种称为\robin的联邦算法，并通过推导在满足用户级DP时的几乎匹配的上界和下界遗憾界，证明其在客户端数量$M$和隐私预算$\varepsilon$方面是近乎最优的。对于LDP，我们获得了几个下界，表明在用户级$(\varepsilon,\delta)$-LDP下学习必须至少承受一个遗憾膨胀因子至少为{$\min\{1/\varepsilon,M\}$或$\min\{1/\sqrt{\varepsilon},\sq

    This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as \robin and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least {$\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sq
    
[^134]: 利用预训练模型的速率降低原则进行图像聚类

    Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models. (arXiv:2306.05272v1 [cs.CV])

    [http://arxiv.org/abs/2306.05272](http://arxiv.org/abs/2306.05272)

    本论文提出了一种新的图像聚类流程，利用大型预训练模型的强大特征表示，在规模上有效地对图像进行聚类，并通过优化速率降低目标和 CLIP 的图像-文本绑定，成功地提高了聚类的准确性和自标记算法的效果。

    

    大型预训练模型的出现已经在视觉表示学习和自然语言处理方面带来了范式转变，但是聚类未标记的图像作为一种基本和经典的机器学习问题，仍然缺乏有效的解决方案，特别是对于大规模数据集。在本文中，我们提出了一种新的图像聚类流程，利用 CLIP 等大型预训练模型的强大特征表示，在规模上有效地对图像进行聚类。我们展示了预训练特征通过进一步优化速率降低目标，更具有结构性。由此产生的特征可以显著提高聚类的准确性，例如从 ImageNet-1k 的 57％提高到 66％。此外，通过利用 CLIP 的图像-文本绑定，我们展示了新的聚类方法如何导致简单而有效的自标记算法，成功地应用于未标记的大型数据集，例如 MS-COCO 和 LAION-Aesthetics。

    The advent of large pre-trained models has brought about a paradigm shift in both visual representation learning and natural language processing. However, clustering unlabeled images, as a fundamental and classic machine learning problem, still lacks effective solution, particularly for large-scale datasets. In this paper, we propose a novel image clustering pipeline that leverages the powerful feature representation of large pre-trained models such as CLIP and cluster images effectively and efficiently at scale. We show that the pre-trained features are significantly more structured by further optimizing the rate reduction objective. The resulting features may significantly improve the clustering accuracy, e.g., from 57\% to 66\% on ImageNet-1k. Furthermore, by leveraging CLIP's image-text binding, we show how the new clustering method leads to a simple yet effective self-labeling algorithm that successfully works on unlabeled large datasets such as MS-COCO and LAION-Aesthetics. We wi
    
[^135]: 转移学习的泛化性能：过参数化和欠参数化的情况

    Generalization Performance of Transfer Learning: Overparameterized and Underparameterized Regimes. (arXiv:2306.04901v1 [cs.LG])

    [http://arxiv.org/abs/2306.04901](http://arxiv.org/abs/2306.04901)

    该研究探讨了转移学习在不同相似度条件下的表现，使用线性回归模型分析了两种参数传递选项的比较，并通过理论分析模型误差的特征来检验泛化性能如何随着参数数量的变化而变化。

    

    转移学习是一种使用源任务中获得的知识并将其应用于目标任务，以实现改善性能和降低训练成本的有用技术。评估转移学习的有效性依赖于理解源任务和目标任务之间的相似性。在实际应用中，任务通常表现出部分相似性，其中某些方面相似而另一些方面则不同或无关。为了研究部分相似性对转移学习性能的影响，我们专注于具有两组不同特征的线性回归模型：在任务间共享的公共部分和任务特定的部分。我们的研究探索了各种类型的转移学习，涵盖了两个参数传递选项。通过建立学习模型误差的理论特征，我们比较这些转移学习选项，特别关注泛化性能如何随学习模型参数数量的变化而变化。

    Transfer learning is a useful technique for achieving improved performance and reducing training costs by leveraging the knowledge gained from source tasks and applying it to target tasks. Assessing the effectiveness of transfer learning relies on understanding the similarity between the ground truth of the source and target tasks. In real-world applications, tasks often exhibit partial similarity, where certain aspects are similar while others are different or irrelevant. To investigate the impact of partial similarity on transfer learning performance, we focus on a linear regression model with two distinct sets of features: a common part shared across tasks and a task-specific part. Our study explores various types of transfer learning, encompassing two options for parameter transfer. By establishing a theoretical characterization on the error of the learned model, we compare these transfer learning options, particularly examining how generalization performance changes with the numbe
    
[^136]: 基于图去噪扩散的城市全域起点与终点矩阵生成

    City-wide Origin-Destination Matrix Generation via Graph Denoising Diffusion. (arXiv:2306.04873v1 [cs.LG])

    [http://arxiv.org/abs/2306.04873](http://arxiv.org/abs/2306.04873)

    本文提出了一种基于图去噪扩散的方法，从网络的角度生成城市全域的起点与终点矩阵，并通过学习区域层面的城市特征来设计出图去噪扩散方法的条件概率分布。

    

    起点终点矩阵估计了区域之间的出行人数，即城市中的人流量，广泛应用于城市规划、交通等领域。本文提出了一种基于图去噪扩散的方法，从网络的角度生成城市全域的起点与终点矩阵，并通过学习区域层面的城市特征来设计出图去噪扩散方法的条件概率分布。为了克服涵盖数千个区域的城市全域起点和终点矩阵的学习难度，我们将其分解成了若干小块、独立的部分。

    The Origin-Destination~(OD) matrix provides an estimation of number of individuals traveling between regions, i.e., mobility flow in the city, which is widely-used in urban planning, transportation, etc. Given various city characteristics of urban regions, generating the city-wide OD matrix without using historical flow information has become increasingly appealing to both researchers and practitioners. However, existing works are limited in independent generation of each element, i.e., flow, in OD matrix, overlooking the element relations within the matrix that can be well formulated as a network. In this paper, we instead propose to generate the city-wide OD matrix from the network perspective, and design a graph denoising diffusion method to learn the conditional joint probability distribution of all elements in the OD matrix given city characteristics at region level. To overcome the learning difficulty of the city-wide OD matrix covering over thousands of regions, we decompose the
    
[^137]: 稀疏线性质心编码器：一种特征选择的凸方法

    Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection. (arXiv:2306.04824v1 [cs.LG])

    [http://arxiv.org/abs/2306.04824](http://arxiv.org/abs/2306.04824)

    SLCE是用线性变换将点重构为类别质心并使用$\ell_1$范数惩罚从输入数据中滤除不必要特征的特征选择新方法。该方法为多类数据使用单个模型，具有与最先进方法相当的性能，同时具有显着较少的特征数。

    

    我们提出了一种新的特征选择技术，称为稀疏线性质心编码器（SLCE）。该算法使用一个线性变换将一个点重构为其类别的质心，并同时使用$\ell_1$范数惩罚从输入数据中滤除不必要的特征。优化问题的原始公式是非凸的，但我们提出了一个两步法，其中每一步都是凸的。在第一步中，我们解决线性质心编码器，它是一个矩阵$A$上的凸优化问题。在第二步中，我们只在对角线矩阵$B$上搜索稀疏解，同时保持$A$不变。与其他线性方法（例如稀疏支持向量机和Lasso）不同，稀疏线性质心编码器对于多类数据使用单个模型。我们对所提出的模型进行了深入的实证分析，并表明它促进了各种数据集（包括高维生物数据）上的稀疏性。我们的实验结果表明，SLCE在分类准确率方面具有与最先进方法相当的性能，同时具有显着较少的特征数。

    We present a novel feature selection technique, Sparse Linear Centroid-Encoder (SLCE). The algorithm uses a linear transformation to reconstruct a point as its class centroid and, at the same time, uses the $\ell_1$-norm penalty to filter out unnecessary features from the input data. The original formulation of the optimization problem is nonconvex, but we propose a two-step approach, where each step is convex. In the first step, we solve the linear Centroid-Encoder, a convex optimization problem over a matrix $A$. In the second step, we only search for a sparse solution over a diagonal matrix $B$ while keeping $A$ fixed. Unlike other linear methods, e.g., Sparse Support Vector Machines and Lasso, Sparse Linear Centroid-Encoder uses a single model for multi-class data. We present an in-depth empirical analysis of the proposed model and show that it promotes sparsity on various data sets, including high-dimensional biological data. Our experimental results show that SLCE has a performan
    
[^138]: 相关信息最大化：一种无需权重对称的有监督深度神经网络的生物合理方法

    Correlative Information Maximization: A Biologically Plausible Approach to Supervised Deep Neural Networks without Weight Symmetry. (arXiv:2306.04810v1 [cs.NE])

    [http://arxiv.org/abs/2306.04810](http://arxiv.org/abs/2306.04810)

    本文提出了一种无需权重对称的有监督深度神经网络的生物合理方法，该方法利用相关信息最大化在层激活之间描述生物神经网络中的信号传播。通过坐标下降优化相应的目标和均方误差损失函数，可以产生一个更生物真实的神经网络结构。

    

    反向传播算法在训练大规模人工神经网络方面取得了显著的成功，但其生物合理性受到争议，现在仍然存在一个开放的问题，即大脑是否采用类似于它的监督学习机制。在本文中，我们提出了在层激活之间进行相关信息最大化的替代规范方法，以描述生物神经网络中信号在前向和后向方向上传播的机制。这种新框架解决了有关传统人工神经网络和反向传播算法生物合理性的许多问题。相应目标的坐标下降优化，与均方误差损失函数相结合，可以产生一个神经网络结构，模拟一种具有树突处理和侧抑制神经元的更生物真实的多室金字塔形神经元网络。

    The backpropagation algorithm has experienced remarkable success in training large-scale artificial neural networks, however, its biological-plausibility is disputed, and it remains an open question whether the brain employs supervised learning mechanisms akin to it. Here, we propose correlative information maximization between layer activations as an alternative normative approach to describe the signal propagation in biological neural networks in both forward and backward directions. This new framework addresses many concerns about the biological-plausibility of conventional artificial neural networks and the backpropagation algorithm. The coordinate descent-based optimization of the corresponding objective, combined with the mean square error loss function for fitting labeled supervision data, gives rise to a neural network structure that emulates a more biologically realistic network of multi-compartment pyramidal neurons with dendritic processing and lateral inhibitory neurons. Fu
    
[^139]: 使用稀疏自适应瓶颈质心编码器进行特征选择

    Feature Selection using Sparse Adaptive Bottleneck Centroid-Encoder. (arXiv:2306.04795v1 [cs.LG])

    [http://arxiv.org/abs/2306.04795](http://arxiv.org/abs/2306.04795)

    该论文提出一种基于稀疏自适应瓶颈质心编码器的特征选择模型，该模型通过提取有区别的特征组以及在重构类别质心的同时减少同类分散度、增加不同类别质心的分离性，从而实现过滤输入数据中不必要特征的功能。

    

    我们引入了一种新的非线性模型，即稀疏自适应瓶颈质心编码器（SABCE），用于确定能够区分两个或多个类别的特征。该算法旨在提取有区别的特征组，并在环境空间中重构类别质心，同时在瓶颈层使用附加惩罚项来减少同类分散度并增加不同类别质心的分离性。模型具有促进稀疏性的层（SPL），与输入层具有一对一的连接。除了主要目标，我们还最小化稀疏层的$l_{2,1}$-范数，从而过滤掉输入数据中的不必要的特征。在训练期间，我们通过将质心和稀疏层的权重的Hadamard积来更新类别质心，从而忽略目标中的无关特征。因此，该方法学习重建类别质心的关键组件，而不是整个质心。

    We introduce a novel nonlinear model, Sparse Adaptive Bottleneck Centroid-Encoder (SABCE), for determining the features that discriminate between two or more classes. The algorithm aims to extract discriminatory features in groups while reconstructing the class centroids in the ambient space and simultaneously use additional penalty terms in the bottleneck layer to decrease within-class scatter and increase the separation of different class centroids. The model has a sparsity-promoting layer (SPL) with a one-to-one connection to the input layer. Along with the primary objective, we minimize the $l_{2,1}$-norm of the sparse layer, which filters out unnecessary features from input data. During training, we update class centroids by taking the Hadamard product of the centroids and weights of the sparse layer, thus ignoring the irrelevant features from the target. Therefore the proposed method learns to reconstruct the critical components of class centroids rather than the whole centroids.
    
[^140]: 多样化和区分化表示学习的通用低资源活动识别

    Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning. (arXiv:2306.04641v1 [cs.CV])

    [http://arxiv.org/abs/2306.04641](http://arxiv.org/abs/2306.04641)

    提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。

    

    人类活动识别是一项时间序列分类任务，重点是从人类传感器读数中识别动作模式。然而，获取充足的数据是训练通用人类活动识别模型的关键难点，这有助于在线网络应用程序的定制和优化。本文提出了一种新的方法DDLearn，通过构建自监督学习任务，同时考虑差异性和歧视性学习，从而实现了通用低资源人类活动识别。

    Human activity recognition (HAR) is a time series classification task that focuses on identifying the motion patterns from human sensor readings. Adequate data is essential but a major bottleneck for training a generalizable HAR model, which assists customization and optimization of online web applications. However, it is costly in time and economy to collect large-scale labeled data in reality, i.e., the low-resource challenge. Meanwhile, data collected from different persons have distribution shifts due to different living habits, body shapes, age groups, etc. The low-resource and distribution shift challenges are detrimental to HAR when applying the trained model to new unseen subjects. In this paper, we propose a novel approach called Diverse and Discriminative representation Learning (DDLearn) for generalizable low-resource HAR. DDLearn simultaneously considers diversity and discrimination learning. With the constructed self-supervised learning task, DDLearn enlarges the data dive
    
[^141]: 论大型语言模型水印的可靠性

    On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])

    [http://arxiv.org/abs/2306.04634](http://arxiv.org/abs/2306.04634)

    本文研究了大型语言模型水印在混合其他文本来源时的可靠性，并提供了在实际应用中的建议。

    

    大型语言模型(LLMs)已经开始应用于日常使用，并有能力在未来的十年内产生大量的文本。机器生成的文本可能会取代互联网上的人类写作文本，并有可能被用于恶意目的，如钓鱼攻击和社交媒体机器人。水印是一种简单有效的策略，通过使LLM生成的文本可检测和可记录，来降低这些伤害。然而，一个关键问题仍然存在：在现实中混合了其他的文本来源，被人类写作者或其他语言模型改写，被用于社交和技术领域的各种应用时，水印在实际设置中的可靠性如何？在本文中，我们探讨了不同的检测方案，量化了它们检测水印的能力，并确定在每个情况下需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调了当水印与其他文本来源混合时水印的可靠性，并提供了未来使用LLM生成的文本水印的建议。

    Large language models (LLMs) are now deployed to everyday use and positioned to produce large quantities of text in the coming decade. Machine-generated text may displace human-written text on the internet and has the potential to be used for malicious purposes, such as spearphishing attacks and social media bots. Watermarking is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet, a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text might be mixed with other text sources, paraphrased by human writers or other language models, and used for applications in a broad number of domains, both social and technical. In this paper, we explore different detection schemes, quantify their power at detecting watermarks, and determine how much machine-generated text needs to be observed in each scenario to reliably detect the watermark. We especially highlight o
    
[^142]: 价值函数即控制障碍函数：使用控制理论验证学习策略

    Your Value Function is a Control Barrier Function: Verification of Learned Policies using Control Theory. (arXiv:2306.04026v1 [cs.LG])

    [http://arxiv.org/abs/2306.04026](http://arxiv.org/abs/2306.04026)

    本研究将控制理论中的验证方法应用于强化学习中的价值函数，提出了新的度量方法以验证安全控制任务中的价值函数，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。

    

    尽管强化学习具有高度的通用性和可伸缩性，但验证策略行为的难度对于安全关键应用程序构成了挑战。为了解决这个问题，我们建议将控制理论中使用的验证方法应用于学习的价值函数。通过分析安全维护的简单任务结构，我们推导出将值函数与控制障碍函数相联系的原始定理。受此启发，我们提出了新的度量方法，以验证安全控制任务中的价值函数，并提出了改善学习的实际实施细节。除了提出证书学习的新方法外，我们的工作为RL策略解锁了丰富的控制理论验证方法，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。

    Although RL is highly general and scalable, the difficulty of verifying policy behaviours poses challenges for safety-critical applications. To remedy this, we propose to apply verification methods used in control theory to learned value functions. By analyzing a simple task structure for safety preservation, we derive original theorems linking value functions to control barrier functions. Inspired by this, we propose novel metrics for verification of value functions in safe control tasks, and practical implementation details that improve learning. Besides proposing a novel method for certificate learning, our work unlocks a wealth of verification methods in control theory for RL policies, and represents a first step towards a framework for general, scalable, and verifiable design of control systems.
    
[^143]: 面向任务型对话的更准确和可推广的评估指标探索

    Toward More Accurate and Generalizable Evaluation Metrics for Task-Oriented Dialogs. (arXiv:2306.03984v1 [cs.CL])

    [http://arxiv.org/abs/2306.03984](http://arxiv.org/abs/2306.03984)

    本文提出了一种新的对话质量注释工作流程称为DQA，能够更准确和可推广地评估对话质量，尤其是通过一些客观对话属性的判断。

    

    评估交互质量对于改进口语对话系统至关重要。现有的对话质量估计方法要么侧重于评估单个对话轮次的质量，要么从终端用户立即在交互之后收集对话级别的质量测量数据。与这些方法相比，我们引入了一种新的对话级别注释工作流程称为对话质量注释（DQA）。DQA专家注释员评估整个对话的质量，并标记对话的目标完成和用户情感等属性。本文的贡献是，我们展示了：（i）尽管对话质量不能完全分解成对话级别属性，但某些客观对话属性与对话质量的判断之间存在着强关系；（ii）对于对话级别质量估计任务，一个在对话级别注释上训练的监督模型优于仅基于聚合轮次级别特征的方法；以及（iii）使用DQA相比现有方法能够得到更准确和可推广的对话质量评估。

    Measurement of interaction quality is a critical task for the improvement of spoken dialog systems. Existing approaches to dialog quality estimation either focus on evaluating the quality of individual turns, or collect dialog-level quality measurements from end users immediately following an interaction. In contrast to these approaches, we introduce a new dialog-level annotation workflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate the quality of dialogs as a whole, and also label dialogs for attributes such as goal completion and user sentiment. In this contribution, we show that: (i) while dialog quality cannot be completely decomposed into dialog-level attributes, there is a strong relationship between some objective dialog attributes and judgments of dialog quality; (ii) for the task of dialog-level quality estimation, a supervised model trained on dialog-level annotations outperforms methods based purely on aggregating turn-level features; and (iii) the 
    
[^144]: SERT: 基于Transformer的缺失空间-时间传感器数据模型用于环境监测

    SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with Missing Values for Environmental Monitoring. (arXiv:2306.03042v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.03042](http://arxiv.org/abs/2306.03042)

    该论文提出了两种模型用于处理具有缺失值的多变量不对齐稀疏时间序列数据，其中一种是基于Transformer的模型SERT，另一种是提供可解释结果的简单模型SST-ANN

    

    环境监测对于我们理解气候变化、生物多样性丧失和污染等方面具有关键作用。来自传感器和卫星等数据源的大规模空间-时间数据的可用性使我们能够开发复杂的预测模型，并了解主要的驱动因素。但由于设备问题或维护问题，从传感器收集到的数据往往包含缺失值。缺失值很少同时发生，导致数据是多变量不对齐的稀疏时间序列数据。我们提出了两种模型，能够在处理缺失数据时自然地执行多变量空间-时间预测，而不需要插补。第一个模型是基于Transformer的模型，我们将其命名为SERT（来自Transformer的空间-时间编码表示）。第二个模型是一个更简单的模型，被命名为SST-ANN（稀疏空间-时间人工神经网络），能够提供可解释的结果。我们进行了大量实验...

    Environmental monitoring is crucial to our understanding of climate change, biodiversity loss and pollution. The availability of large-scale spatio-temporal data from sources such as sensors and satellites allows us to develop sophisticated models for forecasting and understanding key drivers. However, the data collected from sensors often contain missing values due to faulty equipment or maintenance issues. The missing values rarely occur simultaneously leading to data that are multivariate misaligned sparse time series. We propose two models that are capable of performing multivariate spatio-temporal forecasting while handling missing data naturally without the need for imputation. The first model is a transformer-based model, which we name SERT (Spatio-temporal Encoder Representations from Transformers). The second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial Neural Network) which is capable of providing interpretable results. We conduct extensive experiments 
    
[^145]: 一种基于相关性优化的风速预测深度学习新方法

    A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast. (arXiv:2306.01986v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.01986](http://arxiv.org/abs/2306.01986)

    该论文提出了一种基于深度知识学习的新方法，通过混合预训练和自编码器结构，同时利用基于相关性优化模型构建多层网络和序列到序列模型来提高风速预测的准确性和建模效果。

    

    随着风力发电装机率的增加，给全球能源系统带来了巨大的挑战。为了确保电力系统的可靠运行，需要准确预测风力涡轮机的风速和功率。目前，深度学习被逐渐应用于风速预测，但由于模型可解释性和硬件限制等问题，这些方法在实际应用中仍存在尴尬之处。因此，本文提出了一种新颖的基于深度知识学习的方法。该方法混合了预训练方法和自编码器结构，以提高深度知识学习框架的数据表现和建模。为了形成知识和对应吸收器，原始数据经由基于相关性的优化模型预处理，构建多层网络（知识），被序列到序列（Seq2Seq）模型吸收。

    The increasing installation rate of wind power poses great challenges to the global power system. In order to ensure the reliable operation of the power system, it is necessary to accurately forecast the wind speed and power of the wind turbines. At present, deep learning is progressively applied to the wind speed prediction. Nevertheless, the recent deep learning methods still reflect the embarrassment for practical applications due to model interpretability and hardware limitation. To this end, a novel deep knowledge-based learning method is proposed in this paper. The proposed method hybridizes pre-training method and auto-encoder structure to improve data representation and modeling of the deep knowledge-based learning framework. In order to form knowledge and corresponding absorbers, the original data is preprocessed by an optimization model based on correlation to construct multi-layer networks (knowledge) which are absorbed by sequence to sequence (Seq2Seq) models. Specifically,
    
[^146]: 更大、更好、更快：具有人类效率的人类级Atari游戏

    Bigger, Better, Faster: Human-level Atari with human-level efficiency. (arXiv:2305.19452v1 [cs.LG])

    [http://arxiv.org/abs/2305.19452](http://arxiv.org/abs/2305.19452)

    引入BBF基于价值函数的RL代理，在Atari 100K基准测试上实现超人类表现，具有人类效率，提出了在样本高效RL研究的ALE中更新目标的可能。

    

    我们引入了一个名为BBF的基于价值函数的强化学习代理来实现Atari 100K基准测试的超人类表现。BBF依靠神经网络的价值估计扩展以及其他设计选择，在遵循样本高效的情况下，能够实现这种扩展。我们对这些设计选择进行了广泛的分析并为未来的工作提供了洞见。最后，我们讨论了更新ALE上样本高效的RL研究目标的问题。我们将我们的代码和数据公开在https://github.com/google-research/google-research/tree/master/bigger_better_faster。

    We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark. BBF relies on scaling the neural networks used for value estimation, as well as a number of other design choices that enable this scaling in a sample-efficient manner. We conduct extensive analyses of these design choices and provide insights for future work. We end with a discussion about updating the goalposts for sample-efficient RL research on the ALE. We make our code and data publicly available at https://github.com/google-research/google-research/tree/master/bigger_better_faster.
    
[^147]: PFN是适用于实际贝叶斯优化的灵活模型。

    PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])

    [http://arxiv.org/abs/2305.17535](http://arxiv.org/abs/2305.17535)

    本文使用灵活的PFN作为BO代理建模，该模型能够允许进一步信息纳入以进行非远视BO。在三种不同的问题上得到了很好的结果。

    

    本文使用先验数据拟合网络(PFNs)作为贝叶斯优化(BO)的灵活代理。PFN是一种神经过程，被训练用于近似后验预测分布(PPD)，适用于任何可有效采样的先验分布。我们描述了如何利用这种灵活性来进行BO的代理建模。我们使用PFN来模拟一个朴素高斯过程(GP)，一个先进的GP和一个贝叶斯神经网络(BNN)。此外，我们展示了如何将进一步的信息纳入先验，例如允许有关最优位置的提示(用户先验)，忽略不相关的维度，并通过学习获取函数来执行非远视BO。这些扩展的灵活性为使用PFN进行BO开辟了广阔的可能性。我们在人工高斯过程样本和三个不同的超参数优化测试平台上展示了PFN对BO的有用性：HPO-B、Bayesmark和PD1。

    In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
    
[^148]: 层次预测聚合曲线并应用于日前电力竞拍

    Hierarchical forecasting for aggregated curves with an application to day-ahead electricity price auctions. (arXiv:2305.16255v1 [stat.AP])

    [http://arxiv.org/abs/2305.16255](http://arxiv.org/abs/2305.16255)

    本文提出了一种协调方法来提高聚合曲线的预测准确性，并在德国日前电力竞拍市场进行了实证研究。

    

    聚合曲线在经济和金融中很常见，最突出的例子是供给和需求曲线。我们发现所有聚合曲线都具有内在的层次结构，因此可以使用层次协调方法来提高预测准确性。我们提供了聚合曲线如何构建或解构的深入理论，并得出这些方法在弱假设下是等效的结论。我们考虑了多种聚合曲线的协调方法，包括已经建立的自下而上、自上而下和线性最优协调方法。我们还提出了一种新的基准协调方法，称为“聚合-下”，其复杂度类似于自下而上和自上而下方法，但在这种设置中往往提供更好的准确性。我们对德国日前电力竞拍市场进行了实证预测研究，预测了需求和供给曲线，并对其均衡性进行了分析。

    Aggregated curves are common structures in economics and finance, and the most prominent examples are supply and demand curves. In this study, we exploit the fact that all aggregated curves have an intrinsic hierarchical structure, and thus hierarchical reconciliation methods can be used to improve the forecast accuracy. We provide an in-depth theory on how aggregated curves can be constructed or deconstructed, and conclude that these methods are equivalent under weak assumptions. We consider multiple reconciliation methods for aggregated curves, including previously established bottom-up, top-down, and linear optimal reconciliation approaches. We also present a new benchmark reconciliation method called 'aggregated-down' with similar complexity to bottom-up and top-down approaches, but it tends to provide better accuracy in this setup. We conducted an empirical forecasting study on the German day-ahead power auction market by predicting the demand and supply curves, where their equili
    
[^149]: 超越奖励：离线偏好引导策略优化

    Beyond Reward: Offline Preference-guided Policy Optimization. (arXiv:2305.16217v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.16217](http://arxiv.org/abs/2305.16217)

    本研究提出了离线偏好引导策略优化(OPPO)范例，它消除了传统强化学习中奖励函数的需求。

    

    本研究关注离线基于偏好的强化学习(PbRL)，它是传统强化学习的一种变体，不需要在线交互或指定奖励函数。相反，代理被提供了固定的离线轨迹和人类偏好之间的信息来分别提取动态和任务信息。为了解决学习过程中的信息瓶颈，我们提出了离线偏好引导策略优化(OPPO)范例，它在一个步骤中对离线轨迹和偏好进行建模，消除了分别学习奖励函数的需求。

    This study focuses on the topic of offline preference-based reinforcement learning (PbRL), a variant of conventional reinforcement learning that dispenses with the need for online interaction or specification of reward functions. Instead, the agent is provided with fixed offline trajectories and human preferences between pairs of trajectories to extract the dynamics and task information, respectively. Since the dynamics and task information are orthogonal, a naive approach would involve using preference-based reward learning followed by an off-the-shelf offline RL algorithm. However, this requires the separate learning of a scalar reward function, which is assumed to be an information bottleneck of the learning process. To address this issue, we propose the offline preference-guided policy optimization (OPPO) paradigm, which models offline trajectories and preferences in a one-step process, eliminating the need for separately learning a reward function. OPPO achieves this by introducin
    
[^150]: 学习鲁棒统计用于模型错误情况下的基于模拟推论

    Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v1 [stat.ML])

    [http://arxiv.org/abs/2305.15871](http://arxiv.org/abs/2305.15871)

    本研究提出首个通用的方法来处理基于模拟的推论（如ABC和NPE）中由于模型错误引起的不可靠推论。通过约束统计量的选择，我们的方法通过惩罚与数据和模型之间不匹配的统计量来防止不可靠推论结果。我们在高维时间序列模型上进行了实验，证明了本方法的优越性能。

    

    基于模拟的推论方法（如近似贝叶斯计算（ABC），合成似然性和神经后验估计（NPE））依赖于模拟统计量以推断难以计算的似然模型的参数。然而，已知这种方法在模型错误情况下会产生不可信和误导性的推论结果，从而阻碍了它们的广泛应用。在本文中，我们提出了第一个通用方法来处理跨不同类别的SBI方法的模型错误情况。利用统计量的选择确定SBI中的误差程度，我们引入了一个正则化损失函数，惩罚那些增加数据和模型之间不匹配的统计量。以NPE和ABC为应用案例，我们展示了我们的方法在人工错误规范化的高维时间序列模型上表现出优越的性能。我们还将我们的方法应用于来自无线电传播领域的实际数据。

    Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC), synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalises those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagat
    
[^151]: 锐度感知最小化：将锐度作为正则化项的加权形式

    Sharpness-Aware Minimization Revisited: Weighted Sharpness as a Regularization Term. (arXiv:2305.15817v1 [cs.LG])

    [http://arxiv.org/abs/2305.15817](http://arxiv.org/abs/2305.15817)

    本文提出了一种新的加权锐度形式的正则化方法 WSAM，用于改进 Sharpness-Aware Minimization (SAM) 的泛化性能，并在多个公共数据集上实现了改进或竞争力。

    

    深度神经网络（DNNs）的泛化能力与最小值的平坦度密切相关，导致发展了Sharpness-Aware Minimization (SAM)来寻找更平坦的最小值和更好的泛化。本文重新审视了 SAM 的损失函数并提出了一种更为通用的方法，称为 WSAM，通过将锐度作为正则化项进行改进。我们通过PAC和Bayes-PAC技术的结合证明了它的泛化边界，并在各种公共数据集上评估了它的性能。结果表明，与 vanilla optimizer、SAM 及其变体相比，WSAM 取得了改善的泛化性能，或者至少是非常有竞争力的。代码可从 https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers 获取。

    Deep Neural Networks (DNNs) generalization is known to be closely related to the flatness of minima, leading to the development of Sharpness-Aware Minimization (SAM) for seeking flatter minima and better generalization. In this paper, we revisit the loss of SAM and propose a more general method, called WSAM, by incorporating sharpness as a regularization term. We prove its generalization bound through the combination of PAC and Bayes-PAC techniques, and evaluate its performance on various public datasets. The results demonstrate that WSAM achieves improved generalization, or is at least highly competitive, compared to the vanilla optimizer, SAM and its variants. The code is available at https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.
    
[^152]: 无需演示的自主增强学习：隐式双向课程法

    Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum. (arXiv:2305.09943v1 [cs.LG])

    [http://arxiv.org/abs/2305.09943](http://arxiv.org/abs/2305.09943)

    本文提出了一种无需演示的自主强化学习算法（IBC），通过辅助代理和基于最优输运的双向目标课程，能够在无需先前数据依赖的情况下，实现从非周期性交互中学习，并在稀疏任务相关交互的环境中取得更好的表现。

    

    虽然强化学习在仅通过与环境交互来获得复杂技能方面取得了巨大成功，但它假设在每个周期结束时都可以轻易地回到初始状态。这种假设妨碍了具身代理的自主学习，因为在物理世界中进行重置需要耗费时间和繁琐的解决方案。因此，对于能够从非周期性交互中学习的自主强化学习（ARL）方法越来越受到关注。然而，现有的ARL方法受到其对先前数据的依赖的限制，无法在任务相关交互稀疏的环境中学习。相反，我们提出了一种通过隐式和双向课程的无演示ARL算法（IBC）。通过辅助代理以及基于最优输运的双向目标课程，我们的方法表现优于以前的方法，甚至比利用演示的方法还要好。

    While reinforcement learning (RL) has achieved great success in acquiring complex skills solely from environmental interactions, it assumes that resets to the initial state are readily available at the end of each episode. Such an assumption hinders the autonomous learning of embodied agents due to the time-consuming and cumbersome workarounds for resetting in the physical world. Hence, there has been a growing interest in autonomous RL (ARL) methods that are capable of learning from non-episodic interactions. However, existing works on ARL are limited by their reliance on prior data and are unable to learn in environments where task-relevant interactions are sparse. In contrast, we propose a demonstration-free ARL algorithm via Implicit and Bi-directional Curriculum (IBC). With an auxiliary agent that is conditionally activated upon learning progress and a bidirectional goal curriculum based on optimal transport, our method outperforms previous methods, even the ones that leverage dem
    
[^153]: 为协变量漂移自适应引入双重加权方法

    Double-Weighting for Covariate Shift Adaptation. (arXiv:2305.08637v1 [stat.ML])

    [http://arxiv.org/abs/2305.08637](http://arxiv.org/abs/2305.08637)

    本文提出了一种双重加权的最小极大风险分类方法，可以有效避免协变量漂移对监督学习的影响。

    

    监督学习中常常受到协变量漂移影响，即训练样本和测试样本的实例边缘分布不同但标签条件相同。现有方法通过使用比率p_te（x）/p_tr（x）对训练样本进行加权（重新加权方法），或者使用比率p_tr（x）/p_te（x）对测试样本进行加权（鲁棒方法）来解决这种协变量漂移。然而，在支持不匹配或上述比率取大值时，这些方法的性能可能很差。我们提出了一种最小极大风险分类(MRC)方法，通过对训练样本和测试样本进行加权来避免这种限制。此外，我们开发了有效的技术来获得两组加权，并推广了传统的核均值匹配方法。我们提供了新的生成模型和实际数据集上的实验结果来证明我们方法的优越性。

    Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $\mathrm{p}_\text{tr}(x)$ and $\mathrm{p}_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $\mathrm{p}_\text{te}(x)/\mathrm{p}_\text{tr}(x)$ to weight training samples (reweighting methods) or using the ratio $\mathrm{p}_\text{tr}(x)/\mathrm{p}_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel genera
    
[^154]: 利用三维无监督和(深度)监督神经网络进行增材制造件孔隙率检测的体素级分类

    Voxel-wise classification for porosity investigation of additive manufactured parts with 3D unsupervised and (deeply) supervised neural networks. (arXiv:2305.07894v1 [cs.CE])

    [http://arxiv.org/abs/2305.07894](http://arxiv.org/abs/2305.07894)

    本研究使用三维无监督和(深度)监督神经网络进行增材制造件孔隙率检测的体素级分类，得出使用体素级分类的三维DL模型在AM零件的孔隙率检测方面具有巨大潜力的结论。

    

    增材制造已成为一种生产进程，可以直接从数字模型中生产样本。为了确保在整个制造批次中的所有产品样本都符合质量标准，通常使用X射线计算机断层扫描（X-CT）与自动化异常检测相结合。本研究重新审视了最近的监督和无监督深度学习（DL）模型，对来自X-CT图像的AM样品中的孔隙分析进行了扩展，以接受3D输入数据进行体素级分类，从而降低计算要求，提高效率和通用性。结果表明，使用体素级分类的三维DL模型在AM零件的孔隙率检测方面具有巨大的潜力。

    Additive Manufacturing (AM) has emerged as a manufacturing process that allows the direct production of samples from digital models. To ensure that quality standards are met in all manufactured samples of a batch, X-ray computed tomography (X-CT) is often used combined with automated anomaly detection. For the latter, deep learning (DL) anomaly detection techniques are increasingly, as they can be trained to be robust to the material being analysed and resilient towards poor image quality. Unfortunately, most recent and popular DL models have been developed for 2D image processing, thereby disregarding valuable volumetric information.  This study revisits recent supervised (UNet, UNet++, UNet 3+, MSS-UNet) and unsupervised (VAE, ceVAE, gmVAE, vqVAE) DL models for porosity analysis of AM samples from X-CT images and extends them to accept 3D input data with a 3D-patch pipeline for lower computational requirements, improved efficiency and generalisability. The supervised models were trai
    
[^155]: 基于加权补丁质量预测的无参考点云质量评估

    No-Reference Point Cloud Quality Assessment via Weighted Patch Quality Prediction. (arXiv:2305.07829v1 [cs.CV])

    [http://arxiv.org/abs/2305.07829](http://arxiv.org/abs/2305.07829)

    COPP-Net是一种利用加权补丁质量预测进行局部相关性分析的无参考点云质量评估方法，优于现有的基准NR-PCQA方法。

    

    随着基于点云的三维视觉应用的快速发展，点云质量评估成为一个重要的研究课题。本文提出了一种具有局部区域相关性分析能力的无参考点云质量评估（NR-PCQA）方法，称为COPP-Net。具体而言，我们将点云分为补丁，为每个补丁生成纹理和结构特征，并将它们融合成补丁特征来预测补丁质量。然后，我们收集一个点云中所有补丁的特征进行相关性分析，以获得相关性权重。最后，预测的质量和所有补丁的相关权重用于推导最终质量得分。实验结果表明，我们的方法优于现有的基准NR-PCQA方法。

    With the rapid development of 3D vision applications based on point clouds, point cloud quality assessment(PCQA) is becoming an important research topic. However, the prior PCQA methods ignore the effect of local quality variance across different areas of the point cloud. To take an advantage of the quality distribution imbalance, we propose a no-reference point cloud quality assessment (NR-PCQA) method with local area correlation analysis capability, denoted as COPP-Net. More specifically, we split a point cloud into patches, generate texture and structure features for each patch, and fuse them into patch features to predict patch quality. Then, we gather the features of all the patches of a point cloud for correlation analysis, to obtain the correlation weights. Finally, the predicted qualities and correlation weights for all the patches are used to derive the final quality score. Experimental results show that our method outperforms the state-of-the-art benchmark NR-PCQA methods. Th
    
[^156]: 带概率态射和核平均嵌入的监督学习

    Supervised learning with probabilistic morphisms and kernel mean embeddings. (arXiv:2305.06348v1 [math.ST])

    [http://arxiv.org/abs/2305.06348](http://arxiv.org/abs/2305.06348)

    本文提出了监督学习中正确损失函数的概念，其通过概率测度的条件正则概率测度解决线性算子方程的问题得到定义，适用于可测空间的输入空间和标签空间。

    

    本文提出了一个监督学习的生成模型中正确损失函数的概念，适用于可测空间的输入空间X和标签空间Y。 生成模型中的正确损失函数必须正确地度量可能预测器的假设空间H中的元素与监管运算符之间的差异，而监管运算符可能不属于H。 为了定义正确的损失函数，本文提出了一个关于概率测度μ在投影ΠX：X×Y→X相对于概率测度μ𝑋×𝑌的条件正则概率测度μY| X的特殊性质的表征方法，作为线性算子方程的解决方案。 如果Y是一个具有Borel σ-代数 BY的可分的可度量化拓扑空间，则提出了关于概率测度μ相对于投影ΠX的条件正则概率测度μY| X的另一种特殊性质的表征方法。

    In this paper I propose a concept of a correct loss function in a generative model of supervised learning for an input space $\mathcal{X}$ and a label space $\mathcal{Y}$, which are measurable spaces. A correct loss function in a generative model of supervised learning must correctly measure the discrepancy between elements of a hypothesis space $\mathcal{H}$ of possible predictors and the supervisor operator, which may not belong to $\mathcal{H}$. To define correct loss functions, I propose a characterization of a regular conditional probability measure $\mu_{\mathcal{Y}|\mathcal{X}}$ for a probability measure $\mu$ on $\mathcal{X} \times \mathcal{Y}$ relative to the projection $\Pi_{\mathcal{X}}: \mathcal{X}\times\mathcal{Y}\to \mathcal{X}$ as a solution of a linear operator equation. If $\mathcal{Y}$ is a separable metrizable topological space with the Borel $\sigma$-algebra $ \mathcal{B} (\mathcal{Y})$, I propose another characterization of a regular conditional probability measure
    
[^157]: SEGA：用于图形对比学习的结构熵引导的锚点视图

    SEGA: Structural Entropy Guided Anchor View for Graph Contrastive Learning. (arXiv:2305.04501v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.04501](http://arxiv.org/abs/2305.04501)

    本文提出了一种名为SEGA的锚点视图用于图形对比学习，该视图通过结构熵引导以保持输入图的基本信息，达到了较好的表现。

    

    在对比学习中，“视图”的选择控制着表示捕获的信息并影响模型的性能。然而，主要的图像对比学习方法通常通过随机损坏或学习来产生视图，这可能导致关键信息的丢失和语义信息的变化。对于对比学习来说，保持输入图形的基本信息的锚点视图很少受到研究。在本文中，基于图信息瓶颈理论，我们推导了这个锚点视图的定义；换句话说，“具有输入图的基本信息的锚点视图应该具有最小的结构不确定性”。此外，我们通过结构熵实现了该锚点视图，称为SEGA，用于图对比学习。我们对各种基准测试进行了广泛的验证，包括在无监督、半监督和监督下的图分类。

    In contrastive learning, the choice of ``view'' controls the information that the representation captures and influences the performance of the model. However, leading graph contrastive learning methods generally produce views via random corruption or learning, which could lead to the loss of essential information and alteration of semantic information. An anchor view that maintains the essential information of input graphs for contrastive learning has been hardly investigated. In this paper, based on the theory of graph information bottleneck, we deduce the definition of this anchor view; put differently, \textit{the anchor view with essential information of input graph is supposed to have the minimal structural uncertainty}. Furthermore, guided by structural entropy, we implement the anchor view, termed \textbf{SEGA}, for graph contrastive learning. We extensively validate the proposed anchor view on various benchmarks regarding graph classification under unsupervised, semi-supervise
    
[^158]: 基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取

    Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data. (arXiv:2305.03827v1 [cs.CL])

    [http://arxiv.org/abs/2305.03827](http://arxiv.org/abs/2305.03827)

    本文提出了基于不确定性感知的Bootstrap学习用于远程监督数据联合抽取。通过探索数据不确定性和自我集成正则化器，使得模型在早期快速收敛并且缓解了噪声标签产生的模型不确定性，并在两个大型数据集上实验表明该方法在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    

    在处理带有模糊或噪声标签的远程监督数据时，联合抽取实体对及其关系是具有挑战性的。为了缓解这种影响，我们提出了基于不确定性感知的Bootstrap学习，其动机是根据直觉，一个实例的不确定性越高，模型置信度与真实标签不一致的可能性就越大。具体而言，我们首先探索实例级别的数据不确定性，创建一个高置信的初始样例集。这样的子集用于过滤噪声实例，并有助于模型在早期快速收敛。在Bootstrap学习期间，我们提出自我集成作为正则化器，以减轻噪声标签产生的模型间不确定性。我们进一步定义联合标记概率的概率方差，以估计内部模型参数的不确定性，用于选择和建立新的可靠训练实例进行下一次迭代。两个大型数据集的实验结果表明，我们的方法明显优于最先进的基准方法，在实体对抽取和关系抽取方面的F1得分分别提高了4.43%和4.92%。

    Jointly extracting entity pairs and their relations is challenging when working on distantly-supervised data with ambiguous or noisy labels. To mitigate such impact, we propose uncertainty-aware bootstrap learning, which is motivated by the intuition that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. Specifically, we first explore instance-level data uncertainty to create an initial high-confident examples. Such subset serves as filtering noisy instances and facilitating the model to converge fast at the early stage. During bootstrap learning, we propose self-ensembling as a regularizer to alleviate inter-model uncertainty produced by noisy labels. We further define probability variance of joint tagging probabilities to estimate inner-model parametric uncertainty, which is used to select and build up new reliable training instances for the next iteration. Experimental results on two large datasets reveal that our app
    
[^159]: 通过稀疏模型自适应实现高效个性化联邦学习

    Efficient Personalized Federated Learning via Sparse Model-Adaptation. (arXiv:2305.02776v1 [cs.LG])

    [http://arxiv.org/abs/2305.02776](http://arxiv.org/abs/2305.02776)

    提出了一种名为pFedGate的新方法，通过自适应和高效的方式学习稀疏的本地模型，使得客户端可以发挥其模型容量的全部潜力，从而提高个性化联邦学习的效率。

    

    联邦学习（FL）旨在为多个客户端培训机器学习模型，而不共享其私有数据。由于客户端本地数据分布的异构性，最近的研究探索了个性化FL，通过辅助全局模型学习并部署不同的局部模型。但是，客户端可能在计算和通信资源方面存在异质性。个性化模型的容量和效率受到最低资源客户端的限制，导致个性化FL的性能不佳和实用性有限。为克服这些挑战，我们提出了一种名为pFedGate的新方法，通过自适应和高效地学习稀疏的本地模型来实现高效个性化FL。通过轻量级可训练的门控层，pFedGate能够产生不同的稀疏模型，从而发挥客户端在模型容量方面的全部潜力，考虑到异构数据和计算能力的影响。

    Federated Learning (FL) aims to train machine learning models for multiple clients without sharing their own private data. Due to the heterogeneity of clients' local data distribution, recent studies explore the personalized FL that learns and deploys distinct local models with the help of auxiliary global models. However, the clients can be heterogeneous in terms of not only local data distribution, but also their computation and communication resources. The capacity and efficiency of personalized models are restricted by the lowest-resource clients, leading to sub-optimal performance and limited practicality of personalized FL. To overcome these challenges, we propose a novel approach named pFedGate for efficient personalized FL by adaptively and efficiently learning sparse local models. With a lightweight trainable gating layer, pFedGate enables clients to reach their full potential in model capacity by generating different sparse models accounting for both the heterogeneous data di
    
[^160]: 一种适应未知分布漂移的学习算法

    An Adaptive Algorithm for Learning with Unknown Distribution Drift. (arXiv:2305.02252v1 [cs.LG])

    [http://arxiv.org/abs/2305.02252](http://arxiv.org/abs/2305.02252)

    一种适应未知分布漂移的学习算法，相对于当前分布在不需要先验知识的情况下，学习一个函数族，且误差几乎与预先知道漂移大小的学习算法相同。此外，由于该算法适应数据，因此可以保证比依赖于漂移宽松限制的算法具有更好的学习效果。

    

    我们开发和分析了一种学习未知分布漂移的通用技术。给定一个从漂移分布的最后$T$步中独立观测到的序列，我们的算法在$T$时刻不加区分地学习一个函数族，相对于当前分布。与以前的工作不同，我们的技术不需要关于漂移大小的先验知识。相反，该算法适应样本数据。在不明确估计漂移的情况下，该算法学习的函数族的误差几乎与预先知道漂移大小的学习算法相同。此外，由于我们的算法适应数据，它可以保证比依赖于漂移宽松限制的算法具有更好的学习效果。

    We develop and analyze a general technique for learning with an unknown distribution drift. Given a sequence of independent observations from the last $T$ steps of a drifting distribution, our algorithm agnostically learns a family of functions with respect to the current distribution at time $T$. Unlike previous work, our technique does not require prior knowledge about the magnitude of the drift. Instead, the algorithm adapts to the sample data. Without explicitly estimating the drift, the algorithm learns a family of functions with almost the same error as a learning algorithm that knows the magnitude of the drift in advance. Furthermore, since our algorithm adapts to the data, it can guarantee a better learning error than an algorithm that relies on loose bounds on the drift.
    
[^161]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^162]: 多方聊天：人类和模型中的群聊对话代理

    Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models. (arXiv:2304.13835v1 [cs.CL])

    [http://arxiv.org/abs/2304.13835](http://arxiv.org/abs/2304.13835)

    本文通过收集和评估多方对话情况，探讨了模型在群体对话中需要具备的技能，发现新数据集MultiLIGHT可以在这个领域带来显着的进展。

    

    当前的对话研究主要研究成对（双方）对话，并没有涉及到多于两个人在一起对话的日常情景。本文使用LIGHT环境构建接地对话来收集和评估多方对话情况。我们对比在新数据集MultiLIGHT上训练的模型和现有的成对训练的对话模型以及带有少量提示的大型语言模型。我们发现，我们将公开发布MultiLIGHT数据集，这将有助于在群体设置中带来显着的改进。

    Current dialogue research primarily studies pairwise (two-party) conversations, and does not address the everyday setting where more than two speakers converse together. In this work, we both collect and evaluate multi-party conversations to study this more general case. We use the LIGHT environment to construct grounded conversations, where each participant has an assigned character to role-play. We thus evaluate the ability of language models to act as one or more characters in such conversations. Models require two skills that pairwise-trained models appear to lack: (1) being able to decide when to talk; (2) producing coherent utterances grounded on multiple characters. We compare models trained on our new dataset to existing pairwise-trained dialogue models, as well as large language models with few-shot prompting. We find that our new dataset, MultiLIGHT, which we will publicly release, can help bring significant improvements in the group setting.
    
[^163]: 消除条件随机优化偏差

    Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])

    [http://arxiv.org/abs/2304.10613](http://arxiv.org/abs/2304.10613)

    本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。

    

    本文研究了覆盖了多个应用领域，包括投资组合选择、强化学习、鲁棒学习、因果推断等的条件随机优化（CSO）问题。由于其嵌套结构，CSO目标的样本平均梯度存在偏差，因此需要较高的样本复杂度才能达到收敛。我们引入了一种有效降低偏差的通用随机外推技术。我们证明，在非凸光滑目标函数中，将这种外推与方差缩减技术相结合，可以达到比现有界限更好的样本复杂度。我们还开发了用于有限和变量的CSO的新算法，也显著改进了现有结果。最后，我们认为我们的去偏技术也可能是适用于其他随机优化问题的有趣工具。

    In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
    
[^164]: 反射扩散模型

    Reflected Diffusion Models. (arXiv:2304.04740v1 [stat.ML])

    [http://arxiv.org/abs/2304.04740](http://arxiv.org/abs/2304.04740)

    该论文提出了反射扩散模型，通过学习反射随机微分方程的扰动评分函数，将数据约束原则性地整合到生成过程中，以取代之前采用的导致不自然样本的阈值处理方案。

    

    基于分数的扩散模型学习将数据映射到噪声的随机微分方程的反向。然而，对于复杂任务，数值误差可以累积并导致高度不自然的样本。以前的工作通过阈值处理来缓解漂移，每次扩散步骤后投影到自然数据域（例如图像的像素空间），但这导致训练和生成过程之间存在不匹配。为了以一种原则性的方式合并数据约束，我们提出了反射扩散模型，该模型反向演化在数据支持的反射随机微分方程上。我们的方法通过一般化的分数匹配损失函数学习扰动评分函数，并扩展了标准扩散模型的关键组件，包括扩散引导、基于似然的训练和ODE采样。我们还弥合了阈值处理的理论差距:这样的方案只是反射SDE的离散化。在标准图像基准测试中，我们的

    Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalize score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our 
    
[^165]: MGTBench：机器生成文本检测基准测试

    MGTBench: Benchmarking Machine-Generated Text Detection. (arXiv:2303.14822v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2303.14822](http://arxiv.org/abs/2303.14822)

    本文提出了MGTBench框架，旨在解决机器生成文本检测中现有评估方法的不足。该框架通过广泛评估和公开数据集，提供了全面的MGT检测评估，使研究人员能够比较不同检测方法的有效性。

    

    现在，大型语言模型（LLM）在多种自然语言处理（NLP）任务中显示出了革命性的力量，例如文本分类，情感分析，语言翻译和问答。因此，检测机器生成文本（MGT）随着LLM变得越来越先进和普遍变得越来越重要。这些模型可以生成类似于人类写作的语言，很难与人类写的文本区分开来，这引发了关于真实性，问责和潜在偏见的担忧。然而，现有的MGT检测方法是在不同的模型体系结构，数据集和实验设置下进行评估的，导致缺乏跨不同方法学的全面评估框架。本文通过提出名为MGTBench的MGT检测基准框架来填补这个空白。对由ChatGPT生成的答案进行了广泛的评估，该模型是中国最具代表性和最强大的LLM模型。结果表明，MGTBench提供了公平和全面的MGT检测评估，并使研究人员比较了不同检测方法的有效性。

    Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies  In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and power
    
[^166]: 改进 Shuffling SGD 的收敛下界：随机置换及其他

    Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond. (arXiv:2303.07160v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07160](http://arxiv.org/abs/2303.07160)

    本文研究了平滑（强）凸有限和最小化问题的无替换随机梯度下降（SGD）的收敛下界，提出了具有比现有下界更紧的$k$依赖性的下界，并通过在强凸和凸情况下完全消除加权平均迭代的上下界差距，证明了其可行性。

    

    本文研究了平滑（强）凸有限和最小化问题的无替换随机梯度下降（SGD）的收敛下界。与大多数现有的结果侧重于最终迭代下界，这些下界是关于组件数$n$和迭代次数$K$的，我们寻求各种带权重平均迭代的下界，这些下界在包括条件数$k$在内的所有因素中都是紧的。对于带随机洗牌的SGD，我们提出了具有比现有下界更紧的$k$依赖性的下界。我们的结果是首个在强凸和凸情况下完全消除加权平均迭代的上下界差距的。我们还为任意基于置换的SGD证明了加权平均迭代的下界，这适用于所有小心选择最佳置换的变体。我们的下界在$n$和$k$因素方面都优于现有下界，从而与最近提出的算法的上界相一致。

    We study convergence lower bounds of without-replacement stochastic gradient descent (SGD) for solving smooth (strongly-)convex finite-sum minimization problems. Unlike most existing results focusing on final iterate lower bounds in terms of the number of components $n$ and the number of epochs $K$, we seek bounds for arbitrary weighted average iterates that are tight in all factors including the condition number $\kappa$. For SGD with Random Reshuffling, we present lower bounds that have tighter $\kappa$ dependencies than existing bounds. Our results are the first to perfectly close the gap between lower and upper bounds for weighted average iterates in both strongly-convex and convex cases. We also prove weighted average iterate lower bounds for arbitrary permutation-based SGD, which apply to all variants that carefully choose the best permutation. Our bounds improve the existing bounds in factors of $n$ and $\kappa$ and thereby match the upper bounds shown for a recently proposed al
    
[^167]: 通过语言实现视觉抽象和推理技术

    Visual Abstraction and Reasoning through Language. (arXiv:2303.04091v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04091](http://arxiv.org/abs/2303.04091)

    本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    

    尽管人工智能（AI）模型在局限应用中已经达到了人类甚至超越人类的性能，但它们仍然难以展现更广泛和更灵活的智能。Abstraction and Reasoning Corpus（ARC）旨在评估AI系统与人类类似的认知能力。目前大多数方法依赖于精心设计的特定领域语言（DSL），用于暴力解决ARC中的任务。在这项工作中，我们提出了一个基于任务自然语言描述的通用框架来解决ARC问题。虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    While Artificial Intelligence (AI) models have achieved human or even superhuman performance in narrowly defined applications, they still struggle to show signs of broader and more flexible intelligence. The Abstraction and Reasoning Corpus (ARC), introduced by Fran\c{c}ois Chollet, aims to assess how close AI systems are to human-like cognitive abilities. Most current approaches rely on carefully handcrafted domain-specific languages (DSLs), which are used to brute-force solutions to the tasks present in ARC. In this work, we propose a general framework for solving ARC based on natural language descriptions of the tasks. While not yet beating state-of-the-art DSL models on ARC, we demonstrate the immense potential of our approach hinted at by the ability to solve previously unsolved tasks.
    
[^168]: 重新审视联邦学习中的加权聚合方法

    Revisiting Weighted Aggregation in Federated Learning with Neural Networks. (arXiv:2302.10911v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10911](http://arxiv.org/abs/2302.10911)

    本文重新审视了联邦学习中的加权聚合方法。作者发现权重总和可能小于1，从而改善了泛化性能。作者探索了最优缩小因子如何受到客户端数据异质性和本地周期的影响，并使用客户端相干性研究了客户端之间的相对聚合权重以描绘客户端的重要性。作者提出了一种有效的联邦学习方法（FLLAW），该方法具有可学习聚合权重和全局权重缩小效应。

    

    在联邦学习（FL）中，对本地模型进行加权聚合以生成全局模型，聚合权重被标准化（权重和为1）并与本地数据大小成比例。本文重新审视了加权聚合过程，并深入探讨了FL的训练动力学。首先，我们发现权重总和可能小于1，导致全局权重缩小效应（类似于权重衰减）并改善了泛化性能。我们探讨了最优缩小因子如何受到客户端数据异质性和本地周期的影响。其次，我们深入研究了客户端之间的相对聚合权重以描绘客户端的重要性。我们开发了客户端相干性来研究学习动态，并发现存在一个关键点。在进入临界点之前，相干性更高的客户端在泛化中发挥了更重要的作用。基于上述洞见，我们提出了一种有效的联邦学习方法——具有可学习聚合权重的联邦学习（FLLAW），它允许全局权重缩小效应和可学习聚合权重。在各种基准测试中的实验结果表明，FLLAW在更快的收敛速度、更高的准确性和更好的抗数据异质性方面具有很好的效果。

    In federated learning (FL), weighted aggregation of local models is conducted to generate a global model, and the aggregation weights are normalized (the sum of weights is 1) and proportional to the local data sizes. In this paper, we revisit the weighted aggregation process and gain new insights into the training dynamics of FL. First, we find that the sum of weights can be smaller than 1, causing global weight shrinking effect (analogous to weight decay) and improving generalization. We explore how the optimal shrinking factor is affected by clients' data heterogeneity and local epochs. Second, we dive into the relative aggregation weights among clients to depict the clients' importance. We develop client coherence to study the learning dynamics and find a critical point that exists. Before entering the critical point, more coherent clients play more essential roles in generalization. Based on the above insights, we propose an effective method for Federated Learning with Learnable Ag
    
[^169]: 因果策略分类：两种转变之旅

    Causal Strategic Classification: A Tale of Two Shifts. (arXiv:2302.06280v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06280](http://arxiv.org/abs/2302.06280)

    本文提出了因果策略分类的学习算法，可以在真实因果作用下平衡策略性行为和分布转变，实现对于特征修改的鲁棒预测。

    

    当用户可以从某些预测结果中获益时，他们可能会倾向于通过策略性修改其特征来实现这些结果。因此，策略分类的目标是训练具有对这种行为稳健性的预测模型。然而，传统框架假设更改特征不会更改实际结果，这描绘了用户“操纵”系统的情形。在这里，我们消除了这种假设，并研究了真实结果会发生变化的因果策略设置中的学习。以准确性为我们的主要目标，我们展示了策略性行为和因果作用在两种互补的分布转变形式下的作用。我们表征了这些变化，并提出了一种学习算法，可以在这两个力量之间平衡并允许端到端训练。在合成和半合成数据上的实验证明了我们的方法的实用性。

    When users can benefit from certain predictive outcomes, they may be prone to act to achieve those outcome, e.g., by strategically modifying their features. The goal in strategic classification is therefore to train predictive models that are robust to such behavior. However, the conventional framework assumes that changing features does not change actual outcomes, which depicts users as "gaming" the system. Here we remove this assumption, and study learning in a causal strategic setting where true outcomes do change. Focusing on accuracy as our primary objective, we show how strategic behavior and causal effects underlie two complementing forms of distribution shift. We characterize these shifts, and propose a learning algorithm that balances between these two forces and over time, and permits end-to-end training. Experiments on synthetic and semi-synthetic data demonstrate the utility of our approach.
    
[^170]: 具有逐步违规约束的可证明安全的强化学习

    Provably Safe Reinforcement Learning with Step-wise Violation Constraints. (arXiv:2302.06064v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06064](http://arxiv.org/abs/2302.06064)

    本文提出了一种具有逐步违规约束的新型安全强化学习问题和解决方案SUCBVI，并证明了其最优性能，同时研究了具有逐步违规约束的安全无奖探索问题并设计了算法SRF-UCRL。

    

    本文研究了一种具有逐步违规约束的新型安全强化学习问题。我们的问题不同于现有的研究，我们考虑更严格的逐步违规约束，并且不假定存在安全动作，使得我们的表述更适合需要在所有决策步骤中确保安全且可能不总是具有安全动作的安全关键应用，例如机器人控制和自动驾驶。我们提出了一种新的算法SUCBVI，该算法保证$\tilde{O}(\sqrt{ST})$的逐步违规和$\tilde{O}(\sqrt{H^3SAT})$的后悔。我们提供了下界，以验证对于$S$和$T$的违规和后悔性能的最优性。此外，我们进一步研究了一种具有逐步违规约束的新型安全无奖探索问题。对于这个问题，我们设计了一个$(\varepsilon,\delta)$-PAC算法SRF-UCRL，其实现了几乎最先进的样本复杂度$\tilde{O}((\frac{nHS^2A}{\epsilon})^{\frac{1}{3}}(SAT)^{\frac{2}{3}})$。

    In this paper, we investigate a novel safe reinforcement learning problem with step-wise violation constraints. Our problem differs from existing works in that we consider stricter step-wise violation constraints and do not assume the existence of safe actions, making our formulation more suitable for safety-critical applications which need to ensure safety in all decision steps and may not always possess safe actions, e.g., robot control and autonomous driving. We propose a novel algorithm SUCBVI, which guarantees $\widetilde{O}(\sqrt{ST})$ step-wise violation and $\widetilde{O}(\sqrt{H^3SAT})$ regret. Lower bounds are provided to validate the optimality in both violation and regret performance with respect to $S$ and $T$. Moreover, we further study a novel safe reward-free exploration problem with step-wise violation constraints. For this problem, we design an $(\varepsilon,\delta)$-PAC algorithm SRF-UCRL, which achieves nearly state-of-the-art sample complexity $\widetilde{O}((\frac
    
[^171]: 平滑非凸ERM的差分隐私优化算法

    Differentially Private Optimization for Smooth Nonconvex ERM. (arXiv:2302.04972v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04972](http://arxiv.org/abs/2302.04972)

    本论文提出了一种针对平滑非凸ERM的差分隐私优化算法，该算法采用线性搜索、小批量训练和两阶段策略等，能够有效提高算法速度。

    

    我们研究了一种简单的差分隐私优化算法，沿着期望下降方向寻找非凸ERM的二阶近似解。我们使用线性搜索，小批量训练和两阶段策略来提高算法的速度和实用性。数值实验证明了这些方法的有效性。

    We develop simple differentially private optimization algorithms that move along directions of (expected) descent to find an approximate second-order solution for nonconvex ERM. We use line search, mini-batching, and a two-phase strategy to improve the speed and practicality of the algorithm. Numerical experiments demonstrate the effectiveness of these approaches.
    
[^172]: 执行推荐：通过策略激励实现多样性内容推荐

    Performative Recommendation: Diversifying Content via Strategic Incentives. (arXiv:2302.04336v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04336](http://arxiv.org/abs/2302.04336)

    本研究提出了一种执行推荐的方法，通过激励内容创作者创建多样性内容，以实现推荐系统的多样性。该方法利用推荐系统的表演性质和一种新型的正则化方法，可以预测内容的策略变化，并对内容的同质性进行惩罚。

    

    推荐系统的主要目标是向用户推荐相关联的内容，但是优化推荐系统的准确性往往导致推荐的内容缺乏多样性。为了解决这个问题，传统的方法，如重新排序推荐，可以通过呈现更多样的项目来提高多样性。本文认为，为了促进多样性的产生和延续，系统必须鼓励内容创造者创造多样性内容。为此，我们利用推荐系统的表演性质，展示了如何利用学习来激励内容创作者创建多样性内容。我们的方法依赖于一种新型的正则化方法，可以预测内容的策略变化，并对内容的同质性进行惩罚。我们提供了分析和实证结果，证明了何时以及如何可以激励多样性，并在合成和半合成数据上实验性地证明了我们的方法的效用。

    The primary goal in recommendation is to suggest relevant content to users, but optimizing for accuracy often results in recommendations that lack diversity. To remedy this, conventional approaches such as re-ranking improve diversity by presenting more diverse items. Here we argue that to promote inherent and prolonged diversity, the system must encourage its creation. Towards this, we harness the performative nature of recommendation, and show how learning can incentivize strategic content creators to create diverse content. Our approach relies on a novel form of regularization that anticipates strategic changes to content, and penalizes for content homogeneity. We provide analytic and empirical results that demonstrate when and how diversity can be incentivized, and experimentally demonstrate the utility of our approach on synthetic and semi-synthetic data.
    
[^173]: 提高分散式联邦学习的模型一致性

    Improving the Model Consistency of Decentralized Federated Learning. (arXiv:2302.04083v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04083](http://arxiv.org/abs/2302.04083)

    为了解决分散式联邦学习中的模型不一致性问题，我们提出了两种算法，DFedSAM 和 DFedSAM-MGS，分别通过采用梯度扰动和多次八卦步骤来生成本地平坦模型，从而提高了 DFL 的性能。

    

    为了减轻联邦学习（FL）的隐私泄漏和通信负担，分散式联邦学习（DFL）放弃了中央服务器，每个客户端只与其在分散式通信网络中的邻居通信。然而，现有的DFL在本地客户端之间存在高度不一致性，这导致了严重的分布转移和较低的性能，尤其是在异构数据或稀疏通信拓扑上。为了缓解这个问题，我们提出了两种名为DFedSAM和DFedSAM-MGS的DFL算法来改善DFL的性能。具体而言，DFedSAM利用梯度扰动通过Sharpness Aware Minimization（SAM）来生成本地平坦模型，SAM搜索具有统一低损失值的模型。DFedSAM-MGS通过采用多次八卦步骤（MGS）来进一步提高DFedSAM，以实现更好的模型一致性，加速本地平坦模型的聚合，并更好地平衡通信复杂度和泛化性能。

    To mitigate the privacy leakages and communication burdens of Federated Learning (FL), decentralized FL (DFL) discards the central server and each client only communicates with its neighbors in a decentralized communication network. However, existing DFL suffers from high inconsistency among local clients, which results in severe distribution shift and inferior performance compared with centralized FL (CFL), especially on heterogeneous data or sparse communication topology. To alleviate this issue, we propose two DFL algorithms named DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically, DFedSAM leverages gradient perturbation to generate local flat models via Sharpness Aware Minimization (SAM), which searches for models with uniformly low loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip Steps (MGS) for better model consistency, which accelerates the aggregation of local flat models and better balances communication complexity and generaliza
    
[^174]: SLaM: 用未标注样本的学生-标签混合进行蒸馏

    SLaM: Student-Label Mixing for Distillation with Unlabeled Examples. (arXiv:2302.03806v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03806](http://arxiv.org/abs/2302.03806)

    这篇论文介绍了一种名为SLaM的方法，用于解决知识蒸馏中教师伪标签噪声带来的问题。SLaM使用学生-标签混合的方式来生成更准确的标签，并在多个标准基准上取得了更好的性能。

    

    未标注样本的知识蒸馏是一种强大的训练范式，用于在标记数据有限但可以访问大量未标注数据的应用中生成紧凑、轻量级的学生模型。在这种设置中，一个大的教师模型为未标记的数据集生成“软”伪标签，然后用于训练学生模型。尽管在各种应用中都取得了成功，但这种方法的一个缺点是教师的伪标签经常是带有噪声的，从而导致学生性能受到影响。在本文中，我们提出了一种名为学生-标签混合（SLaM）的未标注示例知识蒸馏的原则方法，并展示了它在评估几个标准基准时始终优于先前的方法。最后，我们展示SLaM具有理论保证；在此过程中，我们给出了一种算法，改进了半空间学习的最佳已知样本复杂度。

    Knowledge distillation with unlabeled examples is a powerful training paradigm for generating compact and lightweight student models in applications where the amount of labeled data is limited but one has access to a large pool of unlabeled data. In this setting, a large teacher model generates ``soft'' pseudo-labels for the unlabeled dataset which are then used for training the student model. Despite its success in a wide variety of applications, a shortcoming of this approach is that the teacher's pseudo-labels are often noisy, leading to impaired student performance. In this paper, we present a principled method for knowledge distillation with unlabeled examples that we call Student-Label Mixing (SLaM) and we show that it consistently improves over prior approaches by evaluating it on several standard benchmarks. Finally, we show that SLaM comes with theoretical guarantees; along the way we give an algorithm improving the best-known sample complexity for learning halfspaces with mar
    
[^175]: 利用RBM的学习动态进行无监督层次聚类

    Unsupervised hierarchical clustering using the learning dynamics of RBMs. (arXiv:2302.01851v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01851](http://arxiv.org/abs/2302.01851)

    本文提出了一种利用受限玻尔兹曼机（RBM）的学习动态构建关系数据树的无监督层次聚类方法，并在数字图像、人类基因组突变和同源蛋白质家族等不同真实数据集上进行了测试，能够自动识别数据的层次结构。

    

    现实世界中的数据集往往是复杂的，具有一定的层次结构，不同抽象级别上的数据组和子组共享共同特征。理解和揭示这些数据集的隐藏结构是一项重要任务，具有许多实际应用。为了应对这一挑战，我们提出了一种利用受限玻尔兹曼机（RBM）的学习动态构建关系数据树的新方法。我们的方法基于平均场方法，由Plefka扩展导出，并在无序系统的背景下进行开发。该方法旨在易于理解。我们在人工创建的层次数据集和三个不同的真实数据集（数字图像，人类基因组突变和同源蛋白质家族）上测试了我们的方法。该方法能够自动识别数据的层次结构。这在同源蛋白质的研究中可能会有用。

    Datasets in the real world are often complex and to some degree hierarchical, with groups and sub-groups of data sharing common characteristics at different levels of abstraction. Understanding and uncovering the hidden structure of these datasets is an important task that has many practical applications. To address this challenge, we present a new and general method for building relational data trees by exploiting the learning dynamics of the Restricted Boltzmann Machine (RBM). Our method is based on the mean-field approach, derived from the Plefka expansion, and developed in the context of disordered systems. It is designed to be easily interpretable. We tested our method in an artificially created hierarchical dataset and on three different real-world datasets (images of digits, mutations in the human genome, and a homologous family of proteins). The method is able to automatically identify the hierarchical structure of the data. This could be useful in the study of homologous prote
    
[^176]: MonoFlow: 从Wasserstein梯度流的角度重新思考Divergence GANs

    MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.01075](http://arxiv.org/abs/2302.01075)

    本文提出了一个新的GAN生成建模框架MonoFlow，通过Wasserstein梯度流获得理论洞见和算法启示。该框架使用密度比例的单调递增映射重新缩放粒子演化，并通过训练鉴别器获得MonoFlow的向量场，利用相应的向量场进行粒子流的生成。

    

    传统上，生成对抗网络（GANs）的对抗训练是通过判别器来估计离散度，生成器学习最小化这个离散度。我们认为，尽管许多GANs变体都是按照这个范例开发的，但当前GANs的理论理解和实际算法是不一致的。在本文中，通过利用展示了样本空间内粒子演化的Wasserstein梯度流来获得GANs的理论洞见和算法启示，我们介绍了一个统一的生成建模框架MonoFlow：粒子演化通过密度比例的单调递增映射进行重新缩放。在我们的框架下，对抗性训练可以被视为一个过程，首先通过训练鉴别器获得MonoFlow的向量场，然后生成器学习由相应向量场所定义的粒子流。

    The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework - MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We al
    
[^177]: MPNN与图转换器之间的连接

    On the Connection Between MPNN and Graph Transformer. (arXiv:2301.11956v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11956](http://arxiv.org/abs/2301.11956)

    本文研究了MPNN与图转换器之间的连接，并证明了带有虚拟节点的MPNN可以任意逼近GT的自注意力层。我们的工作阐明了两种图学习范式之间的关系和能力平衡。

    

    最近出现了一种新的图学习算法范例——图转换器（GT），在多个基准测试中表现优于之前流行的消息传递神经网络（MPNN）。以前的工作表明，通过适当的位置嵌入，GT可以任意逼近MPNN，这意味着GT至少与MPNN一样强大。本文研究了反向连接，并展示了带有虚拟节点（VN）的MPNN足够强大，可以任意逼近GT的自注意力层。特别地，我们首先展示了如果考虑一种线性变换器——所谓的表现者/线性变换器，则具有O（1）深度和O（1）宽度的MPNN + VN可以逼近表现者/线性变换器的自我注意层。接下来，通过MPNN + VN与DeepSets之间的联系，我们证明了具有O(n^d)宽度和O(1)深度的MPNN + VN可以逼近GT的任何层，其中n是图中的节点数，d是图的直径。我们的工作阐明了两种图学习范式之间的关系和能力平衡。

    Graph Transformer (GT) recently has emerged as a new paradigm of graph learning algorithms, outperforming the previously popular Message Passing Neural Network (MPNN) on multiple benchmarks. Previous work (Kim et al., 2022) shows that with proper position embedding, GT can approximate MPNN arbitrarily well, implying that GT is at least as powerful as MPNN. In this paper, we study the inverse connection and show that MPNN with virtual node (VN), a commonly used heuristic with little theoretical understanding, is powerful enough to arbitrarily approximate the self-attention layer of GT.  In particular, we first show that if we consider one type of linear transformer, the so-called Performer/Linear Transformer (Choromanski et al., 2020; Katharopoulos et al., 2020), then MPNN + VN with only O(1) depth and O(1) width can approximate a self-attention layer in Performer/Linear Transformer. Next, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN with O(n^d) width and O(1)
    
[^178]: ExplainableFold：利用可解释AI理解AlphaFold蛋白质结构预测

    ExplainableFold: Understanding AlphaFold Prediction with Explainable AI. (arXiv:2301.11765v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11765](http://arxiv.org/abs/2301.11765)

    本文提出了可解释AI框架ExplainableFold，用于对AlphaFold蛋白质结构预测进行解释。提供了接近实验的对氨基酸对3D蛋白质结构影响的理解，有潜力促进对蛋白质结构的更深入理解。

    

    本文提出了ExplainableFold，一种用于蛋白质结构预测的可解释AI框架。尽管像AlphaFold这样的基于AI的方法在该领域取得了成功，但由于深度学习模型的黑盒特性，其预测的基本原因仍不清楚。为解决这个问题，我们提出了一个受生物学原理启发的反事实学习框架，用于生成反事实解释，从而实现一个干实验的方法。我们的实验结果表明，ExplainableFold能够生成高质量的AlphaFold预测解释，提供接近实验的对氨基酸对3D蛋白质结构影响的理解。这一框架有潜力促进对蛋白质结构的更深入理解。

    This paper presents ExplainableFold, an explainable AI framework for protein structure prediction. Despite the success of AI-based methods such as AlphaFold in this field, the underlying reasons for their predictions remain unclear due to the black-box nature of deep learning models. To address this, we propose a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction, enabling a dry-lab experimentation approach. Our experimental results demonstrate the ability of ExplainableFold to generate high-quality explanations for AlphaFold's predictions, providing near-experimental understanding of the effects of amino acids on 3D protein structure. This framework has the potential to facilitate a deeper understanding of protein structures.
    
[^179]: 基于拉普拉斯算子的深度选项方法用于时间扩展探索

    Deep Laplacian-based Options for Temporally-Extended Exploration. (arXiv:2301.11181v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11181](http://arxiv.org/abs/2301.11181)

    本文提出了一种基于深度学习的选项方法，以处理强化学习中的探索性动作选择问题，并利用最近的结果来拓展至可伸缩性更好的领域。

    

    在强化学习中，选择具有丰富经验流的探索性动作以进行更好学习是一项基本挑战。解决此问题的一种方法是根据特定的策略在一段时间内选择动作，也称为选项。最近一种用于获取此类探索选项的工作基于图拉普拉斯算子的本征函数。重要的是，直到现在，这些方法在图表领域中大多被限制在以下方面：(1)图拉普拉斯矩阵已给出或可以完全估计，(2)在该矩阵上进行特征分解是可计算的，(3)值函数可以被完全学习。此外，这些方法需要一个单独的选项发现阶段。这些假设在根本上是不可扩展的。在本文中，我们解决了这些限制，并展示了如何利用最近直接逼近拉普拉斯算子本征函数的结果，真正实现选项方法的可伸缩性。

    Selecting exploratory actions that generate a rich stream of experience for better learning is a fundamental challenge in reinforcement learning (RL). An approach to tackle this problem consists in selecting actions according to specific policies for an extended period of time, also known as options. A recent line of work to derive such exploratory options builds upon the eigenfunctions of the graph Laplacian. Importantly, until now these methods have been mostly limited to tabular domains where (1) the graph Laplacian matrix was either given or could be fully estimated, (2) performing eigendecomposition on this matrix was computationally tractable, and (3) value functions could be learned exactly. Additionally, these methods required a separate option discovery phase. These assumptions are fundamentally not scalable. In this paper we address these limitations and show how recent results for directly approximating the eigenfunctions of the Laplacian can be leveraged to truly scale up o
    
[^180]: 通过量子-经典自适应门控实现时间扭曲不变量的量子递归神经网络。

    Time-Warping Invariant Quantum Recurrent Neural Networks via Quantum-Classical Adaptive Gating. (arXiv:2301.08173v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2301.08173](http://arxiv.org/abs/2301.08173)

    这篇论文介绍了一种新的量子递归神经网络模型TWI-QRNN，它通过量子-经典自适应门控机制实现时间扭曲不变性，并在实验中证明了其有效性。

    

    经典递归神经网络（RNN）通过自适应门控在时间数据处理中发挥关键作用，因为它促进了保留过去信息以预测未来的机制，提供了一个保持对时间扭曲转换不变的机制。本文基于量子递归神经网络（QRNNs），一种具有量子内存的动态模型，引入了一种新的时间数据处理量子模型，可以保持对输入-输出序列的时间扭曲转换不变性。这个模型被称为时间扭曲不变QRNN（TWI-QRNN），通过一个量子-经典自适应门控机制增强了QRNN，该机制可以根据输入序列的过去样本通过经典递归模型决定是否在每个时间步骤应用参数化的酉变换。 TWI-QRNN模型类从基本原理中推导出来，并且通过实验成功地实现了时间扭曲转换不变量。

    Adaptive gating plays a key role in temporal data processing via classical recurrent neural networks (RNN), as it facilitates retention of past information necessary to predict the future, providing a mechanism that preserves invariance to time warping transformations. This paper builds on quantum recurrent neural networks (QRNNs), a dynamic model with quantum memory, to introduce a novel class of temporal data processing quantum models that preserve invariance to time-warping transformations of the (classical) input-output sequences. The model, referred to as time warping-invariant QRNN (TWI-QRNN), augments a QRNN with a quantum-classical adaptive gating mechanism that chooses whether to apply a parameterized unitary transformation at each time step as a function of the past samples of the input sequence via a classical recurrent model. The TWI-QRNN model class is derived from first principles, and its capacity to successfully implement time-warping transformations is experimentally d
    
[^181]: 自适应 LQR 算法的近乎必然 $\sqrt{T}$ 后悔上限分析

    Almost Surely $\sqrt{T}$ Regret Bound for Adaptive LQR. (arXiv:2301.05537v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2301.05537](http://arxiv.org/abs/2301.05537)

    本文提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限证明，且具有断电机制保证安全并对性能影响很小。

    

    对于未知系统参数的线性二次调节问题(LQR)已经得到广泛研究，但是至今仍不清楚是否能几乎必然地达到 $\tilde{ \mathcal{O}}(\sqrt{T})$ 的后悔上限，而本文则提出了一种自适应LQR控制器，在几乎必然的情况下具有 $\tilde{ \mathcal{O}}(\sqrt{T})$ 后悔上限的证明。该控制器具有断电机制，可以绕过潜在的安全隐患并确保系统参数估计的收敛性，但被证明只会有有限次触发，并对控制器的渐近性能几乎没有影响。通过在田纳西伊士曼(Tennessee Eastman)工艺中进行仿真验证了该控制器的有效性。

    The Linear-Quadratic Regulation (LQR) problem with unknown system parameters has been widely studied, but it has remained unclear whether $\tilde{ \mathcal{O}}(\sqrt{T})$ regret, which is the best known dependence on time, can be achieved almost surely. In this paper, we propose an adaptive LQR controller with almost surely $\tilde{ \mathcal{O}}(\sqrt{T})$ regret upper bound. The controller features a circuit-breaking mechanism, which circumvents potential safety breach and guarantees the convergence of the system parameter estimate, but is shown to be triggered only finitely often and hence has negligible effect on the asymptotic performance of the controller. The proposed controller is also validated via simulation on Tennessee Eastman Process~(TEP), a commonly used industrial process example.
    
[^182]: 对出行方式选择建模的机器学习方法进行预测和行为分析

    A prediction and behavioural analysis of machine learning methods for modelling travel mode choice. (arXiv:2301.04404v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.04404](http://arxiv.org/abs/2301.04404)

    本研究分析了各种机器学习方法和传统随机效用模型在建模出行方式选择方面的性能和特点，并确定哪些模型最适合于建模，出行行为可解释性和解释性、计算复杂度和数据效率等因素需要进行整体考虑。

    

    为了出行方式选择问题，各种机器学习方法的出现提出了一个有趣的问题：哪些模型适用于哪些应用？这个问题的答案不仅仅在于简单的预测性能，还涉及行为可解释性和解释性、计算复杂度和数据效率等多方面的平衡。许多研究试图比较不同机器学习分类器与传统随机效用模型的预测性能。然而，现有研究通常只分析离散预测性能，忽略其他影响模型选择的方面。此外，许多研究受技术限制的影响，例如使用不恰当的验证方案、分层数据的错误抽样、缺乏外部验证以及仅使用离散度量等。为了解决这些限制，我们进行了系统性的行为分析，旨在比较不同机器学习方法的表现和特点，以便确定最适合建模出行选择的模型类型。

    The emergence of a variety of Machine Learning (ML) approaches for travel mode choice prediction poses an interesting question to transport modellers: which models should be used for which applications? The answer to this question goes beyond simple predictive performance, and is instead a balance of many factors, including behavioural interpretability and explainability, computational complexity, and data efficiency. There is a growing body of research which attempts to compare the predictive performance of different ML classifiers with classical random utility models. However, existing studies typically analyse only the disaggregate predictive performance, ignoring other aspects affecting model choice. Furthermore, many studies are affected by technical limitations, such as the use of inappropriate validation schemes, incorrect sampling for hierarchical data, lack of external validation, and the exclusive use of discrete metrics. We address these limitations by conducting a systemati
    
[^183]: 《在均场博弈中使用策略镜面上升实现高效独立学习》

    Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games. (arXiv:2212.14449v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2212.14449](http://arxiv.org/abs/2212.14449)

    本文提出了在均场博弈中使用策略镜面上升实现高效独立学习的方法，不需要人口生成模型，且只需要约$\widetilde{\mathcal{O}}(\varepsilon^{-2})$个样本即可达到纳什均衡。

    

    均场博弈被用作获得对称和匿名的N人博弈的近似纳什均衡的理论工具。然而，现有的理论结果只适用于"人口生成模型"的变化，该模型允许学习算法通过人口分布进行任意修改。此外，学习算法通常使用具有人口属性的抽象模拟器，而不是N人博弈。我们展示了N个代理运行策略镜面上升是如何在不使用人口生成模型的情况下，从单个样本轨迹中收敛于规则博弈的纳什均衡，只需要大约$\widetilde{\mathcal{O}}(\varepsilon^{-2})$的样本，由于均场的缘故，误差为$\mathcal{O}(\frac{1}{\sqrt{N}})$。相较于文献的不同方法，我们首先展示了可以使用策略镜面上升映射来构建一个契约算子，而不是与最佳响应映射一起工作。

    Mean-field games have been used as a theoretical tool to obtain an approximate Nash equilibrium for symmetric and anonymous $N$-player games. However, limiting applicability, existing theoretical results assume variations of a "population generative model", which allows arbitrary modifications of the population distribution by the learning algorithm. Moreover, learning algorithms typically work on abstract simulators with population instead of the $N$-player game. Instead, we show that $N$ agents running policy mirror ascent converge to the Nash equilibrium of the regularized game within $\widetilde{\mathcal{O}}(\varepsilon^{-2})$ samples from a single sample trajectory without a population generative model, up to a standard $\mathcal{O}(\frac{1}{\sqrt{N}})$ error due to the mean field. Taking a divergent approach from the literature, instead of working with the best-response map we first show that a policy mirror ascent map can be used to construct a contractive operator having the Na
    
[^184]: 双重平滑GDA：用于非凸-非凹极小极大优化的全局收敛算法

    Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization. (arXiv:2212.12978v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2212.12978](http://arxiv.org/abs/2212.12978)

    本文提出了一种双重平滑梯度下降上升法 (DSGDA)，该算法可以应用于非凸-非凹极小极大优化，并且能够全局收敛并消除极限环。在一定条件下，DSGDA 的迭代复杂度达到了文献中单循环算法的最佳结果。

    

    非凸-非凹极小极大优化近年来受到了广泛的关注，其在机器学习中具有广泛的应用。然而，大多数现有算法不能保证全局收敛，甚至会遭受极限环的困扰。为了解决这个问题，我们提出了一种新颖的单循环算法，称为双重平滑梯度下降上升法 (DSGDA)，它能够自然地平衡原始与对偶更新，并且将极其具有挑战性的非凸-非凹例子中的极限环消除，包括 Forsaken，Bilinearly-coupled minimax，Sixth-order polynomial 和 PolarGame。我们进一步证明，在一个单侧的 $\theta\in(0,1)$ Kurdyka-\L{}ojasiewicz条件（或凸原始/凹对偶函数）下，DSGDA 可以找到一个游戏平衡点，并且具有迭代复杂度 $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$（或 $\mathcal{O}(\epsilon^{-4})$），这些与文献中单循环算法的最佳结果相匹配。

    Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Unfortunately, most existing algorithms cannot be guaranteed to converge globally and even suffer from limit cycles. To address this issue, we propose a novel single-loop algorithm called doubly smoothed gradient descent ascent method (DSGDA), which naturally balances the primal and dual updates. The proposed DSGDA can get rid of limit cycles in various challenging nonconvex-nonconcave examples in the literature, including Forsaken, Bilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further show that under an one-sided Kurdyka-\L{}ojasiewicz condition with exponent $\theta\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a game-stationary point with an iteration complexity of $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ (resp. $\mathcal{O}(\epsilon^{-4})$). These match the best results for single-loop al
    
[^185]: 基于深度强化学习的多智能体巡逻问题的能量感知和容错方法

    An Energy-aware and Fault-tolerant Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems. (arXiv:2212.08230v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.08230](http://arxiv.org/abs/2212.08230)

    本论文提出了一种基于无模型、深度多智能体强化学习的方法，以解决复杂巡逻环境中多个自主车辆协同执行任务的问题，该方法还考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。

    

    自主车辆适用于连续区域巡逻问题。然而，由于众多原因，寻找最优巡逻策略可能具有挑战性。首先，巡逻环境通常较为复杂，可能会包含诸如风或景观等未知环境因素。其次，自主车辆可能会出现故障或硬件限制，例如电池寿命有限。重要的是，巡逻大区域通常需要多个智能体协同执行任务。在本文中，我们考虑了这些限制，并提出了一种基于无模型、深度多智能体强化学习的方法。在该方法中，智能体被训练在具有各种未知动态和因素的环境中进行巡逻。它们可以自动充电以支持连续集体巡逻。我们提出了一种分布式的同构多智能体架构，其中所有巡逻智能体基于其本地观察和共享通信在本地执行相同的策略。此外，所提出的方法考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。

    Autonomous vehicles are suited for continuous area patrolling problems. However, finding an optimal patrolling strategy can be challenging for many reasons. Firstly, patrolling environments are often complex and can include unknown environmental factors, such as wind or landscape. Secondly, autonomous vehicles can have failures or hardware constraints, such as limited battery life. Importantly, patrolling large areas often requires multiple agents that need to collectively coordinate their actions. In this work, we consider these limitations and propose an approach based on model-free, deep multi-agent reinforcement learning. In this approach, the agents are trained to patrol an environment with various unknown dynamics and factors. They can automatically recharge themselves to support continuous collective patrolling. A distributed homogeneous multi-agent architecture is proposed, where all patrolling agents execute identical policies locally based on their local observations and shar
    
[^186]: Huber能量量化

    Huber-energy measure quantization. (arXiv:2212.08162v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.08162](http://arxiv.org/abs/2212.08162)

    该论文提出了一种Huber能量量化的算法，用于找到目标概率定律的最佳逼近，通过最小化原测度与量化版本之间的统计距离来实现。该算法已在多维高斯混合物、维纳空间魔方等几个数据库上进行了测试。

    

    我们描述了一种测量量化过程，即一种算法，它通过$Q$个狄拉克函数的总和（$Q$为量化参数），找到目标概率定律（更一般地，为有限变差测度）的最佳逼近。该过程通过将原测度与其量化版本之间的统计距离最小化来实现；该距离基于负定核构建，并且如果必要，可以实时计算并输入随机优化算法（如SGD，Adam等）。我们在理论上研究了最优测量量化器的存在的基本问题，并确定了需要保证合适行为的核属性。我们提出了两个最佳线性无偏（BLUE）估计器，用于平方统计距离，并将它们用于无偏程序HEMQ中，以找到最佳量化。我们在多维高斯混合物、维纳空间魔方等几个数据库上测试了HEMQ

    We describe a measure quantization procedure i.e., an algorithm which finds the best approximation of a target probability law (and more generally signed finite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the quantization parameter). The procedure is implemented by minimizing the statistical distance between the original measure and its quantized version; the distance is built from a negative definite kernel and, if necessary, can be computed on the fly and feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We investigate theoretically the fundamental questions of existence of the optimal measure quantizer and identify what are the required kernel properties that guarantee suitable behavior. We propose two best linear unbiased (BLUE) estimators for the squared statistical distance and use them in an unbiased procedure, called HEMQ, to find the optimal quantization. We test HEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space cub
    
[^187]: 如何后门扩散模型？

    How to Backdoor Diffusion Models?. (arXiv:2212.05400v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.05400](http://arxiv.org/abs/2212.05400)

    该论文介绍了针对扩散模型的后门攻击框架 BadDiffusion，其可以在模型训练期间实现植入后门，导致模型在正常数据输入时依然表现良好，但接收到触发信号时产生误导性输出。该攻击可能对建立在有问题的模型之上的下游任务和应用造成严重影响。

    

    扩散模型是最先进的基于深度学习的生成模型，其训练原理是通过逐步添加噪声和去噪学习正向和反向的扩散过程。为了更好地了解其限制和潜在风险，本文首次研究了扩散模型对后门攻击的鲁棒性。具体而言，我们提出了BadDiffusion，这是一个新的攻击框架，它在模型训练期间工程化了受损的扩散过程，进行后门植入。在推理阶段，后门扩散模型将像普通数据输入的未篡改生成器一样运行，同时在接收到植入的触发信号后，伪造出一些被坏演员设计的目标结果。这种重大风险可能对建立在有问题的模型之上的下游任务和应用造成严重影响。我们在各种后门攻击设置上进行了广泛的实验，结果表明 BadDiffusion 可以稳定地伪造特定的目标结果。

    Diffusion models are state-of-the-art deep learning empowered generative models that are trained based on the principle of learning forward and reverse diffusion processes via progressive noise-addition and denoising. To gain a better understanding of the limitations and potential risks, this paper presents the first study on the robustness of diffusion models against backdoor attacks. Specifically, we propose BadDiffusion, a novel attack framework that engineers compromised diffusion processes during model training for backdoor implantation. At the inference stage, the backdoored diffusion model will behave just like an untampered generator for regular data inputs, while falsely generating some targeted outcome designed by the bad actor upon receiving the implanted trigger signal. Such a critical risk can be dreadful for downstream tasks and applications built upon the problematic model. Our extensive experiments on various backdoor attack settings show that BadDiffusion can consisten
    
[^188]: 论异构数据中部分方差降低在联邦学习中的有效性

    On the effectiveness of partial variance reduction in federated learning with heterogeneous data. (arXiv:2212.02191v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.02191](http://arxiv.org/abs/2212.02191)

    本文研究了联邦学习中数据异构性如何影响深度神经网络层之间的梯度更新，发现虽然特征提取层能被有效学习，但客户端最终分类层的大量差异阻碍了该算法的性能，因此提出了仅对最终层的方差进行降低的方法，证明其可以在相似或更低的通信成本下显著优于现有的基准方法。

    

    客户端数据的异构性是联邦学习中的一个关键挑战，之前的方法通过调整客户端和服务器模型或使用控制变量来纠正客户端模型漂移来解决这个问题。虽然这些方法能在凸或简单的非凸问题中实现快速收敛，但在深度神经网络等过度参数化的模型中性能较差。在本文中，我们首先重新审查了一个深度神经网络中广泛使用的FedAvg算法，以了解数据异构性如何影响神经网络层之间的梯度更新。我们观察到，虽然FedAvg有效地学习了特征提取层，但客户端最终分类层的大量差异会阻碍性能。在此基础上，我们提出仅对最终层的方差进行降低以纠正模型漂移。我们证明了这样做可以在相似或更低的通信成本下显著优于现有的基准方法。此外，我们还提供了证明…

    Data heterogeneity across clients is a key challenge in federated learning. Prior works address this by either aligning client and server models or using control variates to correct client model drift. Although these methods achieve fast convergence in convex or simple non-convex problems, the performance in over-parameterized models such as deep neural networks is lacking. In this paper, we first revisit the widely used FedAvg algorithm in a deep neural network to understand how data heterogeneity influences the gradient updates across the neural network layers. We observe that while the feature extraction layers are learned efficiently by FedAvg, the substantial diversity of the final classification layers across clients impedes the performance. Motivated by this, we propose to correct model drift by variance reduction only on the final layers. We demonstrate that this significantly outperforms existing benchmarks at a similar or lower communication cost. We furthermore provide proof
    
[^189]: 利用观测数据进行因果深度强化学习

    Causal Deep Reinforcement Learning Using Observational Data. (arXiv:2211.15355v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15355](http://arxiv.org/abs/2211.15355)

    本文提出了两种DRL去混淆方法，通过重新加权或重新采样离线数据集来调整不同采样对损失函数的影响，以确保其无偏。这些方法可以有效提高DRL算法的鲁棒性和泛化性。

    

    深度强化学习（DRL）需要收集干预数据，在现实世界中有时昂贵甚至不道德，比如在自动驾驶和医疗领域。离线强化学习通过利用现实世界中广泛可用的观测数据来缓解这个问题。但是，如果产生数据的行为策略取决于未观察到的随机变量（即混淆因素），那么观测数据可能会误导学习智能体产生不想要的结果。本文提出了两种DRL去混淆方法来解决这个问题。这些方法首先使用因果推断技术计算不同采样的重要程度，然后通过重新加权或重新采样离线数据集来调整不同采样对损失函数的影响，以确保其无偏。这些去混淆的方法可以灵活地与现有的基于模型的DRL算法（如软演员-评论家和近端策略优化）相结合，以学习因果最优策略。我们在人工合成数据集和具有混淆因素的基准测试环境中评估了我们的方法，表明它们可以有效地估计因果效应，并提高DRL算法的鲁棒性和泛化性。

    Deep reinforcement learning (DRL) requires the collection of interventional data, which is sometimes expensive and even unethical in the real world, such as in the autonomous driving and the medical field. Offline reinforcement learning promises to alleviate this issue by exploiting the vast amount of observational data available in the real world. However, observational data may mislead the learning agent to undesirable outcomes if the behavior policy that generates the data depends on unobserved random variables (i.e., confounders). In this paper, we propose two deconfounding methods in DRL to address this problem. The methods first calculate the importance degree of different samples based on the causal inference technique, and then adjust the impact of different samples on the loss function by reweighting or resampling the offline dataset to ensure its unbiasedness. These deconfounding methods can be flexibly combined with existing model-free DRL algorithms such as soft actor-criti
    
[^190]: 针对私有机器学习的多时期矩阵分解机制

    Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning. (arXiv:2211.06530v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.06530](http://arxiv.org/abs/2211.06530)

    本论文针对具有多次通过数据的基于梯度的机器学习提出了新的差分隐私机制，大大改善了隐私、效用和计算之间的折衷问题。作者提出了一种新的矩阵分解扩展方法，并设计了一种高效的傅里叶变换机制，同时取得了优于以往方法的显著改进。

    

    我们引入了新的差分隐私（DP）机制，用于具有多次通过（时期）数据集的基于梯度的机器学习（ML），大大改善了可实现的隐私-效用-计算折衷。我们形式化了针对具有多次参与的自适应流的DP机制的问题，并将在线矩阵分解DP机制的非平凡扩展引入到我们的设置中。这包括建立灵敏度计算的必要理论和优化矩阵的高效计算。对于一些应用程序，例如$>\!\! 10,000$ SGD步骤，应用这些最佳技术会变得计算昂贵。因此，我们设计了一种基于傅里叶变换的高效机制，只有轻微的效用损失。对于图像分类的示例级DP和语言模型的用户级DP进行了广泛的经验评估，证明了在所有先前方法中均获得了显着的改进，包括广泛使用的DP-SGD。虽然我们的主要应用

    We introduce new differentially private (DP) mechanisms for gradient-based machine learning (ML) with multiple passes (epochs) over a dataset, substantially improving the achievable privacy-utility-computation tradeoffs. We formalize the problem of DP mechanisms for adaptive streams with multiple participations and introduce a non-trivial extension of online matrix factorization DP mechanisms to our setting. This includes establishing the necessary theory for sensitivity calculations and efficient computation of optimal matrices. For some applications like $>\!\! 10,000$ SGD steps, applying these optimal techniques becomes computationally expensive. We thus design an efficient Fourier-transform-based mechanism with only a minor utility loss. Extensive empirical evaluation on both example-level DP for image classification and user-level DP for language modeling demonstrate substantial improvements over all previous methods, including the widely-used DP-SGD . Though our primary applicati
    
[^191]: 通过深度学习实现时间序列中的自动变点检测

    Automatic Change-Point Detection in Time Series via Deep Learning. (arXiv:2211.03860v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.03860](http://arxiv.org/abs/2211.03860)

    本文介绍了一种通过训练神经网络自动生成新的离线检测方法的方式，应用于时间序列中的自动变点检测，其性能可与标准CUSUM分类器性能竞争。

    

    数据中的变点检测具有挑战性，我们通过训练神经网络自动生成新的离线检测方法，并提出了一种理论量化此方法的误差率及其与训练数据量的关系。实证结果表明，即使有限的训练数据，其性能也可与用于检测中变化的标准CUSUM分类器的性能竞争。

    Detecting change-points in data is challenging because of the range of possible types of change and types of behaviour of data when there is no change. Statistically efficient methods for detecting a change will depend on both of these features, and it can be difficult for a practitioner to develop an appropriate detection method for their application of interest. We show how to automatically generate new offline detection methods based on training a neural network. Our approach is motivated by many existing tests for the presence of a change-point being representable by a simple neural network, and thus a neural network trained with sufficient data should have performance at least as good as these methods. We present theory that quantifies the error rate for such an approach, and how it depends on the amount of training data. Empirical results show that, even with limited training data, its performance is competitive with the standard CUSUM-based classifier for detecting a change in m
    
[^192]: L-GreCo：层间自适应梯度压缩可用于高效和精确深度学习

    L-GreCo: Layerwise-Adaptive Gradient Compression for Efficient and Accurate Deep Learning. (arXiv:2210.17357v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17357](http://arxiv.org/abs/2210.17357)

    L-GreCo是一个基于自适应算法的通用的框架，可在训练过程中动态调整模型层之间的压缩程度，提高了总体压缩率，大幅加速，不损失精度。

    

    深度神经网络（DNN）的数据并行分布式训练得到广泛采用，但仍可能存在通信瓶颈。为了解决这个问题，开发了包括量化、稀疏化和低秩逼近在内的整个压缩机制系列，其中一些正在得到显着的实际采用。尽管取得了进展，但几乎所有已知压缩方案均在DNN层上均匀应用压缩，尽管在参数计数和对模型准确性的影响方面，层是异构的。在这项工作中，我们提供了一个通用框架，在训练过程中动态调整模型层之间的压缩程度，提高了总体压缩率，同时导致了大幅加速，而不会损失精度。我们的框架叫做L-GreCo，基于自适应算法，可以自动选择为模型层选择最佳压缩参数，以保证最佳压缩比。

    Data-parallel distributed training of deep neural networks (DNN) has gained very widespread adoption, but can still experience communication bottlenecks. To address this issue, entire families of compression mechanisms have been developed, including quantization, sparsification, and low-rank approximation, some of which are seeing significant practical adoption. Despite this progress, almost all known compression schemes apply compression uniformly across DNN layers, although layers are heterogeneous in terms of parameter count and their impact on model accuracy. In this work, we provide a general framework for adapting the degree of compression across the model's layers dynamically during training, improving the overall compression, while leading to substantial speedups, without sacrificing accuracy. Our framework, called L-GreCo, is based on an adaptive algorithm, which automatically picks the optimal compression parameters for model layers guaranteeing the best compression ratio whi
    
[^193]: 全正半定下图模型的自适应估计

    Adaptive Estimation of Graphical Models under Total Positivity. (arXiv:2210.15471v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.15471](http://arxiv.org/abs/2210.15471)

    本文提出了一种自适应多阶段估计方法来估计高斯图模型中的（对角线占优的）M矩阵，同时基于梯度投影法开发了一个统一的框架来解决正则化问题。该方法在精度矩阵估计和图边缘识别方面表现优于现有最先进方法。

    

    本文考虑了在高斯图模型中将（对角线占优的）M矩阵作为精度矩阵进行估计的问题。这些模型展现了有趣的性质，例如仅使用两个观测值就能获得M矩阵的最大似然估计 \citep{lauritzen2019maximum,slawski2015estimation}，以及对角线占优的M矩阵仅用一个观测值就能获得最大似然估计 \citep{truell2021maximum}。我们提出了一种自适应多阶段估计方法，该方法通过在每个阶段解决加权的$\ell_1$-正则问题来优化估计。此外，我们基于梯度投影法开发了一个统一的框架来解决正则化问题，结合不同的投影来处理M矩阵和对角线占优的M矩阵的约束。提供了对估计误差的理论分析。我们的方法在精度矩阵估计和图边缘识别方面优于现有最先进方法，这一点在合成和金融时间序列数据上得到了证实。

    We consider the problem of estimating (diagonally dominant) M-matrices as precision matrices in Gaussian graphical models. These models exhibit intriguing properties, such as the existence of the maximum likelihood estimator with merely two observations for M-matrices \citep{lauritzen2019maximum,slawski2015estimation} and even one observation for diagonally dominant M-matrices \citep{truell2021maximum}. We propose an adaptive multiple-stage estimation method that refines the estimate by solving a weighted $\ell_1$-regularized problem at each stage. Furthermore, we develop a unified framework based on the gradient projection method to solve the regularized problem, incorporating distinct projections to handle the constraints of M-matrices and diagonally dominant M-matrices. A theoretical analysis of the estimation error is provided. Our method outperforms state-of-the-art methods in precision matrix estimation and graph edge identification, as evidenced by synthetic and financial time-s
    
[^194]: 读懂代码背后：模拟AI辅助编程中的用户行为和成本

    Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming. (arXiv:2210.14306v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2210.14306](http://arxiv.org/abs/2210.14306)

    该论文研究了代码推荐系统GitHub Copilot，发现了程序员与该系统交互的一些常见活动，揭示了其低效性和时间成本，从而为改进界面设计和度量方法提供了动力。

    

    代码推荐系统，如Copilot和CodeWhisperer，通过自动建议和自动完成代码，有潜力提高程序员的生产率。然而，要充分发挥它们的潜力，我们必须了解程序员如何与这些系统交互，并确定改进交互的方法。为了取得进展，我们研究了每天由数百万程序员使用的代码推荐系统GitHub Copilot。我们开发了一个常见程序员活动的分类系统CUPS，以便模拟用户与Copilot的交互。我们对21名完成编码任务并回顾性地使用CUPS标记其会话的程序员的研究表明，CUPS可以帮助我们了解程序员如何与代码推荐系统交互，揭示了效率低下和时间成本。我们的洞见揭示了程序员如何与Copilot交互，并激发了新的界面设计和度量方法。

    Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To make progress, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics.
    
[^195]: 动作匹配：从样本中学习随机动力学

    Action Matching: Learning Stochastic Dynamics from Samples. (arXiv:2210.06662v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06662](http://arxiv.org/abs/2210.06662)

    本文提出了一种名为动作匹配的方法，可以从时间边缘的快照中学习动力学，无需完整样本轨迹。该方法使用了一种衡量动作序列的损失函数来模拟整个个体轨迹，并在随机微分方程和量子电路动力学系统上得到了实验验证。

    

    从时间边缘的快照中学习系统的连续动力学是自然科学和机器学习中出现的问题，包括量子系统、单细胞生物数据和生成建模。在这些设置中，我们假设只能访问在时间上不相关的横截面样本，而不是完整的样本轨迹。为了更好地理解观察的系统，我们希望学习一个模型，使我们能够在时间上传播样本，从而模拟整个个体轨迹。在本文中，我们提出了动作匹配方法，使用仅来自其时间演化的独立样本来学习丰富的动力学家族。我们推导出一个容易处理的训练目标，它不依赖于关于底层动力学的显式假设，也不需要通过微分方程或最优传输解算器进行反向传播。受到最优传输和生成对抗网络的启发，我们的方法学习一种损失函数，它衡量一系列动作将系统从一个时间点驱动到下一个时间点的可能性。我们在一系列动力学系统上展示了我们的方法的优越性，包括随机微分方程和量子电路。

    Learning the continuous dynamics of a system from snapshots of its temporal marginals is a problem which appears throughout natural sciences and machine learning, including in quantum systems, single-cell biological data, and generative modeling. In these settings, we assume access to cross-sectional samples that are uncorrelated over time, rather than full trajectories of samples. In order to better understand the systems under observation, we would like to learn a model of the underlying process that allows us to propagate samples in time and thereby simulate entire individual trajectories. In this work, we propose Action Matching, a method for learning a rich family of dynamics using only independent samples from its time evolution. We derive a tractable training objective, which does not rely on explicit assumptions about the underlying dynamics and does not require back-propagation through differential equations or optimal transport solvers. Inspired by connections with optimal tr
    
[^196]: 自蒸馏在Transformer进一步预训练中的应用

    Self-Distillation for Further Pre-training of Transformers. (arXiv:2210.02871v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.02871](http://arxiv.org/abs/2210.02871)

    本文提出了自蒸馏作为进一步预训练阶段的正则化方法，用于解决Vision Transformer在目标未标注数据集上过拟合问题，实现了在多项基准数据集上的最先进结果。

    

    在大量无标注数据上对Transformer模型进行预训练并在标记数据集上进行微调已被证明是一种成功的策略，适用于不同的视觉和自然语言处理任务。然而，如果在预训练和微调之间存在大的数据领域上的差异，则直接微调预训练模型可能是次优的。为了解决这个问题，前人提出了进一步预训练策略，即在目标未标注数据集上继续预训练模型，但所有这些方法都仅关注于语言模型。我们发现在对目标未标注数据集进行预训练时，Vision Transformer容易出现过拟合问题。为解决这一问题，我们提出了自蒸馏作为进一步预训练阶段的正则化。具体地，我们首先在目标未标注数据集上进一步预训练初始预训练模型，然后将从进一步训练模型中提取的知识蒸馏到初始预训练模型中。在三个不同的视觉任务上的实验表明，我们提出的自蒸馏方法始终提高了初始预训练Vision Transformer的性能，优于先前的进一步预训练方法，并在几个基准数据集上实现了最先进的结果。

    Pre-training a large transformer model on a massive amount of unlabeled data and fine-tuning it on labeled datasets for diverse downstream tasks has proven to be a successful strategy, for a variety of vision and natural language processing tasks. However, direct fine-tuning of the pre-trained model may be suboptimal if there exist large discrepancies across data domains for pre-training and fine-tuning. To tackle this issue, several previous studies have proposed further pre-training strategies, where we continue to pre-train the model on the target unlabeled dataset before fine-tuning. However, all of them solely focus on language models and we empirically find that a Vision Transformer is vulnerable to overfitting as we continue to pretrain the model on target unlabeled data. In order to tackle this limitation, we propose self-distillation as a regularization for a further pre-training stage. Specifically, we first further pre-train the initial pre-trained model on the target unlabe
    
[^197]: OCD：使用条件扩散模型学习过度拟合

    OCD: Learning to Overfit with Conditional Diffusion Models. (arXiv:2210.00471v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00471](http://arxiv.org/abs/2210.00471)

    本文提出了一种基于去噪扩散模型的动态模型，它通过将权重与输入样本进行条件，学习匹配微调的基础模型在输入和标签上获得的权重，可以在图像分类、3D重建、表格数据、语音分离和自然语言处理等领域得到广泛应用。

    

    我们提出了一个动态模型，其中权重基于输入样本x进行条件，学习匹配通过对x及其标签y进行微调所获得的权重。该输入样本与网络权重之间的映射通过去噪扩散模型进行近似。我们使用的扩散模型专注于修改基础模型的一个单层，并基于该层的输入、激活以及输出进行条件。由于扩散模型具有随机性质，多次初始化会生成不同的网络，形成一个集合，进一步提高了性能。我们的实验证明了该方法在图像分类、三维重建、表格数据、语音分离和自然语言处理方面的广泛适用性。我们的代码位于 https://github.com/ShaharLutatiPersonal/OCD。

    We present a dynamic model in which the weights are conditioned on an input sample x and are learned to match those that would be obtained by finetuning a base model on x and its label y. This mapping between an input sample and network weights is approximated by a denoising diffusion model. The diffusion model we employ focuses on modifying a single layer of the base model and is conditioned on the input, activations, and output of this layer. Since the diffusion model is stochastic in nature, multiple initializations generate different networks, forming an ensemble, which leads to further improvements. Our experiments demonstrate the wide applicability of the method for image classification, 3D reconstruction, tabular data, speech separation, and natural language processing. Our code is available at https://github.com/ShaharLutatiPersonal/OCD
    
[^198]: 异构环境下分布式聚类学习的一次性框架

    A One-shot Framework for Distributed Clustered Learning in Heterogeneous Environments. (arXiv:2209.10866v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10866](http://arxiv.org/abs/2209.10866)

    本文提出了一种异构环境下分布式聚类学习的通信效率高的一次性方法族，通过局部计算和聚类聚合步骤，在每个用户处学习出真实模型，具有强大的学习保证。

    

    本文提出了一种通信效率高的方法族，用于解决在用户从$K$个不同分布中获取数据的异构环境中进行分布式学习的问题。在所提出的设置中，用户的分组（基于他们采样的数据分布）以及分布的统计属性是先验未知的。提出了一系列基于集合可接受的聚类算法$\mathcal{C}$参数化的一次性分布式聚类学习方法（ODCL-$\mathcal{C}$），其目标是在每个用户处学习真实模型。可接受的聚类方法包括$K$均值（KM）和凸聚类（CC），从而产生了所提出的各种一次性方法，如ODCL-KM和ODCL-CC。所提出的一次性方法，基于用户的本地计算和服务器上基于聚类的聚合步骤，被证明能够提供强大的学习保证。特别是，对于强凸问题，

    The paper proposes a family of communication efficient methods for distributed learning in heterogeneous environments in which users obtain data from one of $K$ different distributions. In the proposed setup, the grouping of users (based on the data distributions they sample), as well as the underlying statistical properties of the distributions, are apriori unknown. A family of One-shot Distributed Clustered Learning methods (ODCL-$\mathcal{C}$) is proposed, parametrized by the set of admissible clustering algorithms $\mathcal{C}$, with the objective of learning the true model at each user. The admissible clustering methods include $K$-means (KM) and convex clustering (CC), giving rise to various one-shot methods within the proposed family, such as ODCL-KM and ODCL-CC. The proposed one-shot approach, based on local computations at the users and a clustering based aggregation step at the server is shown to provide strong learning guarantees. In particular, for strongly convex problems 
    
[^199]: 无监督视频领域自适应动作识别：一个解缠视角

    Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective. (arXiv:2208.07365v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.07365](http://arxiv.org/abs/2208.07365)

    本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。

    

    无监督视频领域自适应是一项实践性而又具有挑战性的任务。本文首次从解缠视角入手处理该问题。我们的主要思路是通过解缠来分别处理空间和时间领域的差异。具体而言，我们考虑从包含静态信息的一组潜在因素和包含动态信息的另一组潜在因素中生成跨领域视频。我们开发了一个转移时序VAE（TranSVAE）框架来建模这种生成过程。为了更好地进行自适应，我们提出了几个约束潜在因素的目标。通过这些约束，静态领域特定信息的解缠可以轻松移除，通过对抗性学习从帧和视频层面进一步减少了时间差异。在UCF-HMDB、Jester和Epic-Kitchens数据集上进行的广泛实验验证了TranSVAE相比其他方法的有效性和优越性。

    Unsupervised video domain adaptation is a practical yet challenging task. In this work, for the first time, we tackle it from a disentanglement view. Our key idea is to handle the spatial and temporal domain divergence separately through disentanglement. Specifically, we consider the generation of cross-domain videos from two sets of latent factors, one encoding the static information and another encoding the dynamic information. A Transfer Sequential VAE (TranSVAE) framework is then developed to model such generation. To better serve for adaptation, we propose several objectives to constrain the latent factors. With these constraints, the spatial divergence can be readily removed by disentangling the static domain-specific information out, and the temporal divergence is further reduced from both frame- and video-levels through adversarial learning. Extensive experiments on the UCF-HMDB, Jester, and Epic-Kitchens datasets verify the effectiveness and superiority of TranSVAE compared wi
    
[^200]: 通过敏感属性预测器估计和控制平等机会

    Estimating and Controlling for Equalized Odds via Sensitive Attribute Predictors. (arXiv:2207.12497v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.12497](http://arxiv.org/abs/2207.12497)

    本文提出了一种新的方法，可以在没有敏感属性的情况下估计和控制平等机会的违规，其通过一种后处理校正方法可以实现具有保证的EOD控制。

    

    随着机器学习模型在现实中高风险决策场景中的使用不断增长，我们能够审计和控制这些模型向某些群体表现出的任何潜在公平性违规非常重要。为此，自然需要访问敏感属性，例如人口统计数据、性别或其他可能决定组成员身份的敏感特征。不幸的是，在许多情况下，这些信息通常不可用。在本文中，我们研究了公平性的众所周知的“平等机会”（EOD）定义。在没有敏感属性的情况下，我们首先为预测器的EOD违规提供了紧密且可计算的上界。这些边界正好反映了最坏的EOD违规。其次，我们展示了如何用一种新的后处理校正方法有保证地控制最坏情况下的EOD。我们的结果表明了直接针对预测的敏感属性控制EOD的情况。

    As the use of machine learning models in real world high-stakes decision settings continues to grow, it is highly important that we are able to audit and control for any potential fairness violations these models may exhibit towards certain groups. To do so, one naturally requires access to sensitive attributes, such as demographics, gender, or other potentially sensitive features that determine group membership. Unfortunately, in many settings, this information is often unavailable. In this work we study the well known \emph{equalized odds} (EOD) definition of fairness. In a setting without sensitive attributes, we first provide tight and computable upper bounds for the EOD violation of a predictor. These bounds precisely reflect the worst possible EOD violation. Second, we demonstrate how one can provably control the worst-case EOD by a new post-processing correction method. Our results characterize when directly controlling for EOD with respect to the predicted sensitive attributes 
    
[^201]: 用于基准测试图神经网络的图生成模型

    Graph Generative Model for Benchmarking Graph Neural Networks. (arXiv:2207.04396v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04396](http://arxiv.org/abs/2207.04396)

    本文提出了一个名为计算图转换器（CGT）的图生成模型，可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。

    

    随着图神经网络（GNN）领域的不断发展，对于训练和测试新的GNN模型以解决实际问题，需要使用大量的真实世界图数据集。然而，这样的数据集通常来自于在线、高度限制隐私的生态系统，这使得在这些数据集上进行研究和开发变得困难。为了解决这个问题，我们引入一种新颖的图生成模型，计算图转换器（CGT），该模型可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。

    As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this problem, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that learns and reproduces the distribution of real-world graphs in a privacy-controlled way. More specifically, CGT (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale graphs, (3) incorporates off-the-shelf privacy modules to guarantee end-user p
    
[^202]: 断头台正则化：为什么在自监督学习中需要移除网络层以提高泛化性能

    Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning. (arXiv:2206.13378v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.13378](http://arxiv.org/abs/2206.13378)

    这篇论文研究了自监督学习领域中的一种通用技巧——通过移除网络层来改善泛化性能，并解释了为什么这种技巧能够奏效。

    

    近年来出现了一种出人意料的技术，即使用自监督学习方法训练深度神经网络（DN），并在下游任务中使用这个网络，但将其最后几个投影层完全去除。对于在ImageNet上展现竞争性能的自监督学习方法，这个去除投影器的技巧实际上是至关重要的，这样可以获得超过30个百分点的性能提升。然而，这个技巧似乎与在自监督训练中显式强制执行不变性的最后一个投影层不符，我们称之为Guillotine Regularization（GR），这是一种通用的方法，已用于改善转移学习情况下的泛化性能，并在这项工作中，我们确定了其成功背后的原因。

    One unexpected technique that emerged in recent years consists in training a Deep Network (DN) with a Self-Supervised Learning (SSL) method, and using this network on downstream tasks but with its last few projector layers entirely removed. This trick of throwing away the projector is actually critical for SSL methods to display competitive performances on ImageNet for which more than 30 percentage points can be gained that way. This is a little vexing, as one would hope that the network layer at which invariance is explicitly enforced by the SSL criterion during training (the last projector layer) should be the one to use for best generalization performance downstream. But it seems not to be, and this study sheds some light on why. This trick, which we name Guillotine Regularization (GR), is in fact a generically applicable method that has been used to improve generalization performance in transfer learning scenarios. In this work, we identify the underlying reasons behind its success
    
[^203]: MetaGL: 利用元学习对图学习模型进行免评估选择。

    MetaGL: Evaluation-Free Selection of Graph Learning Models via Meta-Learning. (arXiv:2206.09280v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.09280](http://arxiv.org/abs/2206.09280)

    本论文提出了一种名为MetaGL的元学习方法，可以在免评估的情况下选择最佳的图学习模型和超参数，并且通过引入元图特征来预测各种图学习模型在新图上的性能，相比于凭经验的方法具有更好的准确性和效率。

    

    给定一个图学习任务，例如在新图中的链接预测，如何在不训练或评估新图上的模型的情况下选择最佳方法以及其超参数（统称为模型）?图学习模型的选择大多是凭经验的。一种常见的方法是将流行的方法应用于新数据集，但这通常不是最优的。另一方面，在新图上系统地比较模型很快就变得过于昂贵，甚至是不切实际的。在这项工作中，我们开发了一种元学习方法，称为MetaGL，用于免评估的图学习模型选择，利用现有方法在各种基准图数据集上的先前表现，自动选择适用于新图的有效模型，无需对新图上的任何模型进行训练或评估。为了量化各种类型图之间的相似度，我们引入了专门的元图特征，捕捉图的结构特征。然后我们描述了一个元学习框架，利用这些元图特征预测各种图学习模型在新图上的性能，而无需在新图上训练或评估任何模型。我们的实证结果表明，MetaGL在几个基准数据集上实现了最先进的性能，并在准确性和效率方面大大优于凭经验的方法。

    Given a graph learning task, such as link prediction, on a new graph, how can we select the best method as well as its hyperparameters (collectively called a model) without having to train or evaluate any model on the new graph? Model selection for graph learning has been largely ad hoc. A typical approach has been to apply popular methods to new datasets, but this is often suboptimal. On the other hand, systematically comparing models on the new graph quickly becomes too costly, or even impractical. In this work, we develop the first meta-learning approach for evaluation-free graph learning model selection, called MetaGL, which utilizes the prior performances of existing methods on various benchmark graph datasets to automatically select an effective model for the new graph, without any model training or evaluations. To quantify similarities across a wide variety of graphs, we introduce specialized meta-graph features that capture the structural characteristics of a graph. Then we des
    
[^204]: BridgeTower：在视觉语言表示学习中建立编码器之间的桥梁

    BridgeTower: Building Bridges Between Encoders in Vision-Language Representation Learning. (arXiv:2206.08657v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.08657](http://arxiv.org/abs/2206.08657)

    BridgeTower提出了多个桥接层建立了单模态编码器的顶层与跨模编码器的连接，实现了有效的自下而上跨模态对齐和融合，显著提升了模型性能。

    

    最近几年，拥有双塔架构的视觉语言模型巩固了视觉语言表示学习的地位。当前的视觉语言模型要么使用轻量级的单模态编码器，学习从深度跨模编码器中提取、对齐和融合两种模态的表示，要么将深度预训练的单模态编码器的最后一层单模态表示馈送到顶部跨模编码器中。这两种方法都可能限制视觉语言表示学习并限制模型性能。本文提出了BridgeTower，它引入了多个桥接层，建立了单模态编码器的顶层与跨模编码器的每一层之间的连接。这使得来自预训练单模态编码器的不同语义级别的视觉和文本表示在跨模编码器中实现了有效的自下而上跨模态对齐和融合。通过仅使用400万张图像进行预训练，BridgeTower实现了最先进的性能。

    Vision-Language (VL) models with the Two-Tower architecture have dominated visual-language representation learning in recent years. Current VL models either use lightweight uni-modal encoders and learn to extract, align and fuse both modalities simultaneously in a deep cross-modal encoder, or feed the last-layer uni-modal representations from the deep pre-trained uni-modal encoders into the top cross-modal encoder. Both approaches potentially restrict vision-language representation learning and limit model performance. In this paper, we propose BridgeTower, which introduces multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This enables effective bottom-up cross-modal alignment and fusion between visual and textual representations of different semantic levels of pre-trained uni-modal encoders in the cross-modal encoder. Pre-trained with only 4M images, BridgeTower achieves state-of-the-art performance o
    
[^205]: 深度隔离森林用于异常检测

    Deep Isolation Forest for Anomaly Detection. (arXiv:2206.06602v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.06602](http://arxiv.org/abs/2206.06602)

    本文提出了深度隔离森林，利用神经网络将原始数据映射到随机表示集合中，通过随机轴并行切割来执行数据分区，以解决孤立森林算法不能成功检测高维/非线性可分数据空间中的难以隔离的困难异常的问题。

    

    孤立森林（iForest）由于在不同基准测试中的普适有效性和强大的可扩展性而逐渐成为可能是最受欢迎的异常检测器。然而，它的线性轴并行隔离方法经常导致（i）检测难以在高维/非线性可分数据空间中隔离的困难异常的失败，以及（ii）臭名昭着的算法偏差，将预期较低的异常得分分配给工件区域。这些问题导致高误报率。引入了几个iForest扩展，但它们本质上仍然使用浅层的线性数据分区，限制了它们隔离真正异常的能力。因此，本文提出了深度隔离森林。我们引入了一种新的表示方案，利用随意初始化的神经网络将原始数据映射到随机表示集合中，随后应用随机轴并行切割来执行数据分区。

    Isolation forest (iForest) has been emerging as arguably the most popular anomaly detector in recent years due to its general effectiveness across different benchmarks and strong scalability. Nevertheless, its linear axis-parallel isolation method often leads to (i) failure in detecting hard anomalies that are difficult to isolate in high-dimensional/non-linear-separable data space, and (ii) notorious algorithmic bias that assigns unexpectedly lower anomaly scores to artefact regions. These issues contribute to high false negative errors. Several iForest extensions are introduced, but they essentially still employ shallow, linear data partition, restricting their power in isolating true anomalies. Therefore, this paper proposes deep isolation forest. We introduce a new representation scheme that utilises casually initialised neural networks to map original data into random representation ensembles, where random axis-parallel cuts are subsequently applied to perform the data partition. 
    
[^206]: 具有潜在低秩结构的样本有效强化学习克服长时差障碍。

    Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure. (arXiv:2206.03569v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03569](http://arxiv.org/abs/2206.03569)

    本文提出一类具有潜在低秩结构的MDP问题，其中相关的最优$Q^*$函数是低秩的，利用算法可以在小于多项式增长的样本复杂度内，有效地学习了一个近似的最优策略。

    

    由于与问题规模相关的缩放性能差，强化学习算法的实用性受到限制，学习ε-最优策略的样本复杂度为 $\tilde{\Omega}\left(|S||A|H^3 / \epsilon^2\right)$，其中$S$是状态空间，$A$是动作空间，$H$是时间横跨的多个状态。 我们考虑一类具有潜在低秩结构的MDP，其中相关的最优 $Q^*$ 函数是低秩的，潜在的特征是未知的。虽然由于低秩结构，我们希望能够在 $|S|$ 和 $|A|$ 上实现线性样本复杂度，但如果除了 $Q^*$ 的低秩性之外没有施加进一步的假设，则在仅使用来自条目子集的观察来估计 $Q$ 函数的情况下，存在最坏的实例，在这种情况下，要学习接近最优策略，必须承担随着时间视野 $H$ 指数增长的样本复杂度。我们随后展示，在更强的低秩结构假设下，假设有一个生成模型，利用我们提出的算法，我们在小于多项式增长的样本复杂度内，即 $\tilde O\left(|S|^{3/2}/\epsilon\right)$，有效地学习了一个近似的最优策略。

    The practicality of reinforcement learning algorithms has been limited due to poor scaling with respect to the problem size, as the sample complexity of learning an $\epsilon$-optimal policy is $\tilde{\Omega}\left(|S||A|H^3 / \epsilon^2\right)$ over worst case instances of an MDP with state space $S$, action space $A$, and horizon $H$. We consider a class of MDPs for which the associated optimal $Q^*$ function is low rank, where the latent features are unknown. While one would hope to achieve linear sample complexity in $|S|$ and $|A|$ due to the low rank structure, we show that without imposing further assumptions beyond low rank of $Q^*$, if one is constrained to estimate the $Q$ function using only observations from a subset of entries, there is a worst case instance in which one must incur a sample complexity exponential in the horizon $H$ to learn a near optimal policy. We subsequently show that under stronger low rank structural assumptions, given access to a generative model, L
    
[^207]: 基于高阶伴随微分的内存高效神经ODE框架

    A memory-efficient neural ODE framework based on high-level adjoint differentiation. (arXiv:2206.01298v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01298](http://arxiv.org/abs/2206.01298)

    本论文提出了一个基于高阶伴随微分的神经ODE框架PNODE，通过离散伴随时间积分器和先进的检查点策略实现内存高效和梯度计算的准确性，并提供了一个基于PyTorch和PE的开源实现。

    

    神经常微分方程(神经ODE)作为一种将动态系统和深度学习相结合的新型网络架构已经出现。然而，用于原始神经ODE中的连续伴随方法求解的梯度并不具有反向精度。其他方法由于深度计算图的需求过高或时间积分方案的选择受限，限制了其应用于大规模复杂动态系统。为了在不影响内存效率和灵活性的情况下实现精确梯度计算，我们提出了一种新的神经ODE框架PNODE，基于高级离散伴随算法微分。通过利用离散伴随时间积分器和为这些积分器量身定制的高级检查点策略，PNODE可在计算和内存成本之间提供平衡，同时计算梯度时保持一致和准确。我们提供了一个基于PyTorch和PE的开源实现。

    Neural ordinary differential equations (neural ODEs) have emerged as a novel network architecture that bridges dynamical systems and deep learning. However, the gradient obtained with the continuous adjoint method in the vanilla neural ODE is not reverse-accurate. Other approaches suffer either from an excessive memory requirement due to deep computational graphs or from limited choices for the time integration scheme, hampering their application to large-scale complex dynamical systems. To achieve accurate gradients without compromising memory efficiency and flexibility, we present a new neural ODE framework, PNODE, based on high-level discrete adjoint algorithmic differentiation. By leveraging discrete adjoint time integrators and advanced checkpointing strategies tailored for these integrators, PNODE can provide a balance between memory and computational costs, while computing the gradients consistently and accurately. We provide an open-source implementation based on PyTorch and PE
    
[^208]: 使用动态线性投影方法探索非线性模型的局部解释

    Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections. (arXiv:2205.05359v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.05359](http://arxiv.org/abs/2205.05359)

    本文介绍了一种使用动态线性投影方法来分析流行的非线性模型的局部解释的方法，探索预测变量之间的交互如何影响变量重要性估计，这对于理解模型的可解释性非常有用。

    

    机器学习模型的预测能力日益增强，但与参数统计模型相比，其复杂性和可解释性下降。这种折衷导致了可解释的人工智能（XAI）的出现，提供了诸如局部解释（LE）和局部变量归因（LVA）之类的方法，以揭示模型如何使用预测变量进行预测。然而，LVA通常不能有效处理预测变量之间的关联。为了理解预测变量之间的交互如何影响变量重要性估计，可以将LVA转换为线性投影，并使用径向游览。这对于学习模型如何犯错，或异常值的影响，或观测值的聚类也非常有用。本文使用各种流行的非线性模型（包括随机森林和神经网络）的示例来说明这种方法。

    The increased predictive power of machine learning models comes at the cost of increased complexity and loss of interpretability, particularly in comparison to parametric statistical models. This trade-off has led to the emergence of eXplainable AI (XAI) which provides methods, such as local explanations (LEs) and local variable attributions (LVAs), to shed light on how a model use predictors to arrive at a prediction. These provide a point estimate of the linear variable importance in the vicinity of a single observation. However, LVAs tend not to effectively handle association between predictors. To understand how the interaction between predictors affects the variable importance estimate, we can convert LVAs into linear projections and use the radial tour. This is also useful for learning how a model has made a mistake, or the effect of outliers, or the clustering of observations. The approach is illustrated with examples from categorical (penguin species, chocolate types) and quant
    
[^209]: 基于弱监督的高斯过程主动学习

    Active Learning with Weak Supervision for Gaussian Processes. (arXiv:2204.08335v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2204.08335](http://arxiv.org/abs/2204.08335)

    本文提出了一种基于弱监督的主动学习算法，不仅选择要注释的观测结果，还选择要获得的注释精度，并在高斯过程中进行了实验验证。

    

    对于监督学习，进行数据注释需要耗费大量成本。当注释预算有限时，可以使用主动学习来选择和注释那些可能在模型性能上获得最大收益的观测结果。我们提出了一种主动学习算法，除了选择要注释的观测结果外，还选择要获得的注释精度。假定具有低精度的注释比具有高精度的注释更便宜，这使得模型能够在相同的注释预算下探索输入空间的更大部分。我们在先前针对高斯过程提出的BALD目标基础上构建了我们的获取函数，并在实验中展示了能够调整主动学习循环中的注释精度的优势。

    Annotating data for supervised learning can be costly. When the annotation budget is limited, active learning can be used to select and annotate those observations that are likely to give the most gain in model performance. We propose an active learning algorithm that, in addition to selecting which observation to annotate, selects the precision of the annotation that is acquired. Assuming that annotations with low precision are cheaper to obtain, this allows the model to explore a larger part of the input space, with the same annotation budget. We build our acquisition function on the previously proposed BALD objective for Gaussian Processes, and empirically demonstrate the gains of being able to adjust the annotation precision in the active learning loop.
    
[^210]: 雾计算中的分布式任务管理：一个社交凹凸赌博博弈

    Distributed Task Management in Fog Computing: A Socially Concave Bandit Game. (arXiv:2203.14572v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2203.14572](http://arxiv.org/abs/2203.14572)

    本论文提出了两种无悔在线决策策略，适用于雾计算网络中任务分配的设计。该博弈具有唯一的纳什均衡点，可以使用无悔学习策略来实现。

    

    雾计算利用网络边缘的任务卸载功能提高效率并快速响应应用需求。然而，由于雾节点的异构性和系统动态的不确定性，雾计算网络中任务分配策略的设计仍具有挑战性。我们将分布式任务分配问题形式化为具有赌博反馈的社交凹凸博弈，并证明该博弈具有唯一的纳什均衡点，可以使用无悔学习策略（对数减小的遗憾）来实现。我们开发了两种无悔的在线决策策略。一种策略是具有动量的赌博梯度上升，是具有赌博反馈的在线凸优化算法。另一种策略是利普希茨赌徒有初始化算法，是EXP3多臂赌博算法。我们建立了两种策略的遗憾界，并分析了它们的收敛特性。此外，我们比较了所提出的策略。

    Fog computing leverages the task offloading capabilities at the network's edge to improve efficiency and enable swift responses to application demands. However, the design of task allocation strategies in a fog computing network is still challenging because of the heterogeneity of fog nodes and uncertainties in system dynamics. We formulate the distributed task allocation problem as a social-concave game with bandit feedback and show that the game has a unique Nash equilibrium, which is implementable using no-regret learning strategies (regret with sublinear growth). We then develop two no-regret online decision-making strategies. One strategy, namely bandit gradient ascent with momentum, is an online convex optimization algorithm with bandit feedback. The other strategy, Lipschitz bandit with initialization, is an EXP3 multi-armed bandit algorithm. We establish regret bounds for both strategies and analyze their convergence characteristics. Moreover, we compare the proposed strategies
    
[^211]: EmotionNAS: 面向语音情感识别的双流神经架构搜索

    EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition. (arXiv:2203.13617v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2203.13617](http://arxiv.org/abs/2203.13617)

    提出了一种基于双流神经架构搜索的框架EmotionNAS用于语音情感识别，将两种流（即手工特征和深度特征）作为输入，通过高效的信息补充模块实现流之间的信息整合，并在实验中创下新的最优记录。

    

    语音情感识别（SER）是人机交互中的重要研究课题，现有工作主要依赖于人类专业知识来设计模型。尽管这些模型成功率高，但不同的数据集往往需要不同的结构和超参数，为每个数据集搜索最优模型的过程耗费时间和精力。为了解决这个问题，我们提出了一种基于双流神经架构搜索（NAS）的框架，称为“EmotionNAS”。具体而言，我们将两种流（即手工特征和深度特征）作为输入，然后进行NAS以搜索每个流的最佳结构。此外，我们通过高效的信息补充模块整合不同流中的互补信息。实验结果表明，我们的方法超过了现有的手动设计和基于NAS的模型，并创下了新的最优记录。

    Speech emotion recognition (SER) is an important research topic in human-computer interaction. Existing works mainly rely on human expertise to design models. Despite their success, different datasets often require distinct structures and hyperparameters. Searching for an optimal model for each dataset is time-consuming and labor-intensive. To address this problem, we propose a two-stream neural architecture search (NAS) based framework, called \enquote{EmotionNAS}. Specifically, we take two-stream features (i.e., handcrafted and deep features) as the inputs, followed by NAS to search for the optimal structure for each stream. Furthermore, we incorporate complementary information in different streams through an efficient information supplement module. Experimental results demonstrate that our method outperforms existing manually-designed and NAS-based models, setting the new state-of-the-art record.
    
[^212]: L0Learn: 使用L0正则化的稀疏学习的可扩展软件包

    L0Learn: A Scalable Package for Sparse Learning using L0 Regularization. (arXiv:2202.04820v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04820](http://arxiv.org/abs/2202.04820)

    L0Learn是一个可以用于解决数百万特征问题的稀疏学习软件包，具有可扩展的近似算法和用户友好的R和Python接口。

    

    我们提出了L0Learn：一个使用 $\ell_0$ 正则化进行稀疏线性回归和分类的开源软件包。L0Learn实现了基于坐标下降和本地组合优化的可扩展的近似算法。该软件包使用C ++构建，并具有用户友好的R和Python接口。L0Learn能够解决具有数百万特征的问题，在与最先进的稀疏学习软件包相比获得有竞争力的运行时和统计性能。L0Learn在CRAN和GitHub上都可用（https://cran.r-project.org/package=L0Learn和https://github.com/hazimehh/L0Learn）。

    We present L0Learn: an open-source package for sparse linear regression and classification using $\ell_0$ regularization. L0Learn implements scalable, approximate algorithms, based on coordinate descent and local combinatorial optimization. The package is built using C++ and has user-friendly R and Python interfaces. L0Learn can address problems with millions of features, achieving competitive run times and statistical performance with state-of-the-art sparse learning packages. L0Learn is available on both CRAN and GitHub (https://cran.r-project.org/package=L0Learn and https://github.com/hazimehh/L0Learn).
    
[^213]: 针对高维矩阵数据的最优变量聚类

    Optimal Variable Clustering for High-Dimensional Matrix Valued Data. (arXiv:2112.12909v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.12909](http://arxiv.org/abs/2112.12909)

    提出了一种新的针对高维矩阵数据的特征潜变量模型，使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法，理论上实现了聚类一致性，在模拟和真实数据示例中证明了方法的优越性。

    

    矩阵值数据在许多应用中日益普及。大多数现有的这种类型数据的聚类方法是针对平均模型设计的，不考虑特征的依赖结构，而该结构在高维情况下尤为重要。为了从依赖结构中提取信息进行聚类，我们提出了一种新的特征潜变量模型，该模型将特征排列成矩阵形式，并使用一些未知的成员矩阵表示行和列的聚类。在此模型下，我们进一步提出了一类使用加权协方差矩阵的差异作为不相似度测量的层次聚类算法。在理论上，我们证明了在温和的条件下，我们的算法可以在高维情况下实现聚类一致性。虽然这种一致性结果适用于我们的算法和广泛的加权协方差矩阵类别，但这个结果的条件依赖于协方差函数和加权机制的选择。通过模拟和真实数据示例，我们证明了我们的方法相对于现有方法提供了更好的聚类性能和特征选择准确性。

    Matrix valued data has become increasingly prevalent in many applications. Most of the existing clustering methods for this type of data are tailored to the mean model and do not account for the dependence structure of the features, which can be very informative, especially in high-dimensional settings. To extract the information from the dependence structure for clustering, we propose a new latent variable model for the features arranged in matrix form, with some unknown membership matrices representing the clusters for the rows and columns. Under this model, we further propose a class of hierarchical clustering algorithms using the difference of a weighted covariance matrix as the dissimilarity measure. Theoretically, we show that under mild conditions, our algorithm attains clustering consistency in the high-dimensional setting. While this consistency result holds for our algorithm with a broad class of weighted covariance matrices, the conditions for this result depend on the choic
    
[^214]: 利用图像变换学习网络结构

    Using Image Transformations to Learn Network Structure. (arXiv:2112.03419v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2112.03419](http://arxiv.org/abs/2112.03419)

    该论文展示了如何将节点网络及其之间的流作为图像进行处理，并利用图像压缩技术和地理签名学习网络结构以推荐未来的网络连通性。此外，该论文开发了一种利用统计摘要的网络信息和用户决策来强化代理概率决策的贝叶斯强化算法，并探究了利用压缩直接进行强化学习的方式。

    

    许多学习任务需要观察一系列图像并做出决策。在设计和规划节点之间的货运箱的运输问题中，我们展示了如何将节点网络及其之间的流作为图像处理。这些图像具有有用的结构信息，可以进行统计摘要。利用图像压缩技术，将图像压缩成包含可解释地理信息的数字集合，我们将其称作地理签名。利用地理签名，我们学习网络结构，以推荐未来的网络连通性。我们开发了一种贝叶斯强化算法，利用统计摘要的网络信息作为先验知识和用户决策来强化代理的概率决策。此外，我们还展示了在简单任务中如何直接使用压缩进行强化学习，不需要解释。

    Many learning tasks require observing a sequence of images and making a decision. In a transportation problem of designing and planning for shipping boxes between nodes, we show how to treat the network of nodes and the flows between them as images. These images have useful structural information that can be statistically summarized. Using image compression techniques, we reduce an image down to a set of numbers that contain interpretable geographic information that we call geographic signatures. Using geographic signatures, we learn network structure that can be utilized to recommend future network connectivity. We develop a Bayesian reinforcement algorithm that takes advantage of statistically summarized network information as priors and user-decisions to reinforce an agent's probabilistic decision. Additionally, we show how reinforcement learning can be used with compression directly without interpretation in simple tasks.
    
[^215]: 大型基础模型存在的10个安全和隐私问题

    10 Security and Privacy Problems in Large Foundation Models. (arXiv:2110.15444v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2110.15444](http://arxiv.org/abs/2110.15444)

    大型基础模型存在多种攻击漏洞，包括模型反演、成员推断、数据污染、后门等，这些问题可能对现实世界的AI应用产生影响，需要寻求解决方案和未来研究方向。

    

    基础模型（如GPT、CLIP和DINO）在过去几年中取得了革命性进展，被普遍认为是通用AI的一种有前途的方法。特别是，采用无监督学习来预训练基础模型，使用大量未标记的数据。预训练的基础模型就像AI生态系统的“操作系统”。现有研究主要集中在预训练一个更好的基础模型，以改善其在非对抗设置下在下游任务中的表现，而在对抗设置下，其安全和隐私则很少被探索。预训练基础模型的安全或隐私问题会导致AI生态系统的单一故障点。

    Foundation models--such as GPT, CLIP, and DINO--have achieved revolutionary progress in the past several years and are commonly believed to be a promising approach for general-purpose AI. In particular, self-supervised learning is adopted to pre-train a foundation model using a large amount of unlabeled data. A pre-trained foundation model is like an ``operating system'' of the AI ecosystem. Specifically, a foundation model can be used as a feature extractor for many downstream tasks with little or no labeled training data. Existing studies on foundation models mainly focused on pre-training a better foundation model to improve its performance on downstream tasks in non-adversarial settings, leaving its security and privacy in adversarial settings largely unexplored. A security or privacy issue of a pre-trained foundation model leads to a single point of failure for the AI ecosystem. In this book chapter, we discuss 10 basic security and privacy problems for the pre-trained foundation 
    
[^216]: 在多臂老虎机中实现后悔最小化和最佳臂识别的帕累托前沿

    Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits. (arXiv:2110.08627v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.08627](http://arxiv.org/abs/2110.08627)

    本文研究了多臂老虎机中后悔最小化和最佳臂识别的帕累托前沿,设计了BoBW-lil'UCB $(\gamma)$算法，证明了没有算法能同时为RM和BAI目标表现最佳，BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。

    

    本文研究了多臂老虎机中两个典型目标的帕累托前沿，即固定时间内的后悔最小化和最佳臂识别。平衡探索和利用对于后悔最小化和最佳臂识别都至关重要，但对于后者来说，探索更关键。本文设计和分析了BoBW-lil'UCB $(\gamma)$算法，通过建立基于BAI失败概率的可达到遗憾下限，我们展示了(i)没有算法能同时为RM和BAI目标表现最佳，(ii)BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。我们的工作通过展示先前作品中的常数如何依赖某些难度参数，更精确地阐明了此类算法中的权衡。最后，我们展示BoBW-lil'UCB优于其最接近的竞争者UCB$_\alpha$。

    We study the Pareto frontier of two archetypal objectives in multi-armed bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To this end, we design and analyze the BoBW-lil'UCB$(\gamma)$ algorithm. Complementarily, by establishing lower bounds on the regret achievable by any algorithm with a given BAI failure probability, we show that (i) no algorithm can simultaneously perform optimally for both the RM and BAI objectives, and (ii) BoBW-lil'UCB$(\gamma)$ achieves order-wise optimal performance for RM or BAI under different values of $\gamma$. Our work elucidates the trade-off more precisely by showing how the constants in previous works depend on certain hardness parameters. Finally, we show that BoBW-lil'UCB outperforms a close competitor UCB$_\a
    
[^217]: 自动查询再制定在源代码搜索中的系统性研究

    A Systematic Review of Automated Query Reformulations in Source Code Search. (arXiv:2108.09646v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2108.09646](http://arxiv.org/abs/2108.09646)

    许多研究尝试重新制定即席查询以支持开发人员进行代码搜索，本文针对70个主要查询再制定研究进行了细致筛选和深入的定性分析，提出了八种主要方法。

    

    修复软件漏洞和添加新功能是主要的维护任务之二。这些漏洞和功能以更改请求的形式报告。开发人员会从这些请求中选择一些关键词作为即席查询，然后使用搜索引擎执行查询，查找需要更改的软件代码的确切位置。然而，即使是经验丰富的开发人员通常也无法选择适当的查询，这导致在代码搜索期间进行昂贵的试错。多年来，许多研究尝试重新制定开发人员的即席查询以支持他们。本文系统地对70个主要查询再制定研究进行细致筛选（从2,970个候选研究中选择），进行深入的定性分析（如基础理论），并回答七个研究问题并提出主要发现。首先，迄今为止，已采用了八种主要方法（如词项加权，词项共现分析，词库查找）。

    Fixing software bugs and adding new features are two of the major maintenance tasks. Software bugs and features are reported as change requests. Developers consult these requests and often choose a few keywords from them as an ad hoc query. Then they execute the query with a search engine to find the exact locations within software code that need to be changed. Unfortunately, even experienced developers often fail to choose appropriate queries, which leads to costly trials and errors during a code search. Over the years, many studies attempt to reformulate the ad hoc queries from developers to support them. In this systematic literature review, we carefully select 70 primary studies on query reformulations from 2,970 candidate studies, perform an in-depth qualitative analysis (e.g., Grounded Theory), and then answer seven research questions with major findings. First, to date, eight major methodologies (e.g., term weighting, term co-occurrence analysis, thesaurus lookup) have been adop
    
[^218]: 隐私在线随机学习的近似最优算法。

    Near-Optimal Algorithms for Private Online Learning in a Stochastic Environment. (arXiv:2102.07929v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.07929](http://arxiv.org/abs/2102.07929)

    本文提出了两种隐私在线随机学习的算法，包括差分隐私的随机赌博机算法和私有随机在线学习的完全信息版本。其中，我们提出的随时可用的基于UCB的算法达到了最优性能。

    

    本文研究了两种私有随机在线学习的变体。第一种变体是差分隐私的随机赌博机算法。本文提出了一种随时可用的基于UCB的算法，可以达到最优性能。第二种变体是私有随机在线学习的完全信息版本。我们提出了一种新的算法，可同时获得隐私和性能的良好表现。

    We consider two variants of private stochastic online learning. The first variant is differentially private stochastic bandits. Previously, Sajed and Sheffet (2019) devised the DP Successive Elimination (DP-SE) algorithm that achieves the optimal $ O \biggl(\sum\limits_{1\le j \le K: \Delta_j >0} \frac{ \log T}{ \Delta_j} + \frac{ K\log T}{\epsilon} \biggr)$ problem-dependent regret bound, where $K$ is the number of arms, $\Delta_j$ is the mean reward gap of arm $j$, $T$ is the time horizon, and $\epsilon$ is the required privacy parameter. However, like other elimination style algorithms, it is not an anytime algorithm. Until now, it was not known whether UCB-based algorithms could achieve this optimal regret bound. We present an anytime, UCB-based algorithm that achieves optimality. Our experiments show that the UCB-based algorithm is competitive with DP-SE. The second variant is the full information version of private stochastic online learning. Specifically, for the problem of deci
    
[^219]: 正交群子群同步问题的统一方法

    A Unified Approach to Synchronization Problems over Subgroups of the Orthogonal Group. (arXiv:2009.07514v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2009.07514](http://arxiv.org/abs/2009.07514)

    本文提出了一个统一方法来解决正交群子群同步问题，该方法通过广义幂方法的迭代修正和恰当的初始步骤可以在某些假设条件下获得较强的理论保证，并且在计算机视觉和传感器网络等领域有实际应用。

    

    同步问题旨在估计一组群元素$G^*_1,\dots,G^*_n\in\mathcal{G}$,基于形如$G^*_i{G^*_j}^{-1}$的所有成对比率子集的嘈杂观测。本文考虑群为正交群的同步问题。我们提出了一种统一的解决方案，它由适当的初始化步骤和基于广义幂法的迭代细化步骤组成，并表明它在对群、测量图、噪声和初始化的某些假设下具有强大的理论保证。

    The problem of synchronization over a group $\mathcal{G}$ aims to estimate a collection of group elements $G^*_1, \dots, G^*_n \in \mathcal{G}$ based on noisy observations of a subset of all pairwise ratios of the form $G^*_i {G^*_j}^{-1}$. Such a problem has gained much attention recently and finds many applications across a wide range of scientific and engineering areas. In this paper, we consider the class of synchronization problems in which the group is a closed subgroup of the orthogonal group. This class covers many group synchronization problems that arise in practice. Our contribution is fivefold. First, we propose a unified approach for solving this class of group synchronization problems, which consists of a suitable initialization step and an iterative refinement step based on the generalized power method, and show that it enjoys a strong theoretical guarantee on the estimation error under certain assumptions on the group, measurement graph, noise, and initialization. Secon
    

