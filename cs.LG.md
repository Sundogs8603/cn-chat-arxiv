# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Isotonic Mechanism for Exponential Family Estimation.](http://arxiv.org/abs/2304.11160) | 本文利用扩展的保序机制，将其应用于指数族分布以提高同行评审的质量，并发现作者的同行评分可以较准确地在不需要知道具体分布情况下进行调整。 |
| [^2] | [Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single.](http://arxiv.org/abs/2304.11153) | ES-Single是一种用于估计展开的计算图中梯度的进化策略算法，其简单实现、方差较低，在各种任务中表现优异。 |
| [^3] | [Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs.](http://arxiv.org/abs/2304.11140) | 本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。 |
| [^4] | [Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference.](http://arxiv.org/abs/2304.11134) | 本文介绍一种插拔式分割 Gibbs 采样算法，将后验采样任务分为两个较简单的子问题，其中第二个子问题可以用深度生成模型轻松地解决，从而实现了在贝叶斯推断中嵌入深度生成先验以及自动适应后验分布的复杂性。 |
| [^5] | [Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses.](http://arxiv.org/abs/2304.11130) | 该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。 |
| [^6] | [Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance.](http://arxiv.org/abs/2304.11127) | 该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。 |
| [^7] | [A vector quantized masked autoencoder for speech emotion recognition.](http://arxiv.org/abs/2304.11117) | 本文提出了一种自监督模型 VQ-MAE-S 以识别情感，预训练在 VoxCeleb2 数据集上微调，性能优于其他最先进的方法。 |
| [^8] | [Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT.](http://arxiv.org/abs/2304.11116) | 本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。 |
| [^9] | [Inducing anxiety in large language models increases exploration and bias.](http://arxiv.org/abs/2304.11111) | 对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。 |
| [^10] | [A Convolutional Spiking Network for Gesture Recognition in Brain-Computer Interfaces.](http://arxiv.org/abs/2304.11106) | 本文提出了一种用于脑机接口手势分类的卷积脉冲网络，采用事件驱动可塑性规则进行无监督特征学习，具有较好的推广性和效果。 |
| [^11] | [Federated Learning for Predictive Maintenance and Quality Inspection in Industrial Applications.](http://arxiv.org/abs/2304.11101) | 本文评估了联邦学习在四个具有不同数据分布的数据集上的表现，并将其与中心和本地训练方法进行比较。结果表明，FL的性能高度取决于数据以及其在客户端之间的分布，FL可以成为传统中心或本地训练方法的有效替代。此外，该论文引入了一个真实的质量检查情境中的联邦学习数据集。 |
| [^12] | [Is Cross-modal Information Retrieval Possible without Training?.](http://arxiv.org/abs/2304.11095) | 本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。 |
| [^13] | [Hi Sheldon! Creating Deep Personalized Characters from TV Shows.](http://arxiv.org/abs/2304.11093) | 从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。 |
| [^14] | [Feature-Based Generalized Gaussian Distribution Method for NLoS Detection in Ultra-Wideband (UWB) Indoor Positioning System.](http://arxiv.org/abs/2304.11091) | 本文提出了一种基于特征的广义高斯分布方法，可有效解决超宽带室内定位系统中非直视传播条件下分类精度不高的问题。 |
| [^15] | [Profiling the news spreading barriers using news headlines.](http://arxiv.org/abs/2304.11088) | 本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。 |
| [^16] | [Training Automated Defense Strategies Using Graph-based Cyber Attack Simulations.](http://arxiv.org/abs/2304.11084) | 该论文提出了一种自动化的网络防御代理，并使用基于 Meta Attack Language 语言的攻击图对其进行培训。该代理利用强化学习执行预定义的防御措施，以捕获网络攻击，并考虑防御措施对系统性能的影响，通过引入噪声来评估其效果。 |
| [^17] | [Multimodal contrastive learning for diagnosing cardiovascular diseases from electrocardiography (ECG) signals and patient metadata.](http://arxiv.org/abs/2304.11080) | 本文讨论了使用对比学习和深度学习从心电图(ECG)信号中诊断心血管疾病的方法。研究在损失函数中使用对比学习的方法可以使得用于诊断的少量ECG导联信号具有更好的性能表现。 |
| [^18] | [Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects.](http://arxiv.org/abs/2304.11075) | 本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。 |
| [^19] | [An Unbiased Transformer Source Code Learning with Semantic Vulnerability Graph.](http://arxiv.org/abs/2304.11072) | 该论文提出了一种基于语义漏洞图的无偏Transformer源代码学习方法，通过利用从源代码中得到的语义漏洞图（SVG）表示来解决当前漏洞筛选技术对于识别新漏洞或为开发人员提供漏洞和分类方面的效果不佳的问题，并在公开数据集上实现了最先进的性能。 |
| [^20] | [Autoregressive models for biomedical signal processing.](http://arxiv.org/abs/2304.11070) | 本文提出了一种新的自回归建模框架，通过超参数化损失函数来明确纳入数据不确定性，展示了该程序可以成功地去噪时间序列并成功重构系统参数。该范式可在神经科学的多种应用中使用。 |
| [^21] | [Color-based classification of EEG Signals for people with the severe locomotive disorder.](http://arxiv.org/abs/2304.11068) | 本文研究了基于颜色的EEG信号分类，可作为严重运动障碍患者的替代输入。 使用基于注意力的LSTM网络分类两种或四种不同颜色，取得了较高分类准确度。 |
| [^22] | [Novel Fine-Tuned Attribute Weighted Na\"ive Bayes NLoS Classifier for UWB Positioning.](http://arxiv.org/abs/2304.11067) | 本文提出了一种Fine-Tuned属性加权朴素贝叶斯分类器，用于室内UWB信号的直达和非直达传播识别。通过对比实验结果，发现该分类器在NLoS分类准确率上表现优异，为99.7%（不平衡数据）和99.8%（平衡数据），明显优于其他算法。 |
| [^23] | [Scaling Transformer to 1M tokens and beyond with RMT.](http://arxiv.org/abs/2304.11062) | 本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。 |
| [^24] | [Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions.](http://arxiv.org/abs/2304.11059) | 本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。 |
| [^25] | [PowerGAN: A Machine Learning Approach for Power Side-Channel Attack on Compute-in-Memory Accelerators.](http://arxiv.org/abs/2304.11056) | 本文提出了一种基于机器学习的计算内存加速器功耗副信道攻击技术，可以在大噪声和对抗措施存在的情况下重构用户的私有输入数据。 |
| [^26] | [A Multiagent CyberBattleSim for RL Cyber Operation Agents.](http://arxiv.org/abs/2304.11052) | 本文介绍了一种新的对抗训练环境——CyberBattleSim，设计用于RL网络操作代理的训练。本文着重报道了对防御型蓝色代理训练的改进，结果表明红色代理与蓝色代理联合训练可以有效提高蓝色代理的防御能力。 |
| [^27] | [Using Mobile Data and Deep Models to Assess Auditory Verbal Hallucinations.](http://arxiv.org/abs/2304.11049) | 该论文利用移动数据和深度模型评估听觉性幻觉，通过参与者使用移动应用程序对听到的幻听声音的情感色彩进行生态时刻评估，从而测量精神疾病的严重程度。 |
| [^28] | [Affective social anthropomorphic intelligent system.](http://arxiv.org/abs/2304.11046) | 本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。 |
| [^29] | [Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training.](http://arxiv.org/abs/2304.11043) | 本文提出了一种基于分离变分对抗训练的风险感知型股票推荐方法，通过对抗性扰动提高模型对于风险的感知能力，通过变分扰动生成器模拟不同的风险因素并生成代表性的风险指标对抗样本。在真实股票数据上进行的实验表明该方法有效降低了投资风险同时保持高预期收益。 |
| [^30] | [Backpropagation-free Training of Deep Physical Neural Networks.](http://arxiv.org/abs/2304.11042) | 该论文提出了一种新方法来训练深度学习模型，不需要使用反向传播算法。该方法可以有效地应用于基于物理系统的深度学习。 |
| [^31] | [Emotional Expression Detection in Spoken Language Employing Machine Learning Algorithms.](http://arxiv.org/abs/2304.11040) | 通过使用MATLAB函数和机器学习算法，研究人员利用声音的特征来识别人类不同的情感，提高了机器学习模型的效率。 |
| [^32] | [Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation.](http://arxiv.org/abs/2304.11028) | 该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。 |
| [^33] | [Self-Correcting Bayesian Optimization through Bayesian Active Learning.](http://arxiv.org/abs/2304.11005) | 该论文提出了SAL和SCoreBO两种方法，用于提高高斯过程模型的超参数选择和贝叶斯优化的表现。 |
| [^34] | [Knowledge Distillation Under Ideal Joint Classifier Assumption.](http://arxiv.org/abs/2304.11004) | 本文提出了基于理想联合分类器假设的知识蒸馏框架，可以提供清晰全面的理解和为未来研究提供理论基础，使得教师和学生网络之间的知识传递更加高效。 |
| [^35] | [Balancing Simulation-based Inference for Conservative Posteriors.](http://arxiv.org/abs/2304.10978) | 本研究将平衡技术扩展到后验密度算法，提出了神经后验估计和对比神经比率估计的平衡版本，可有效缓解保守推断问题。 |
| [^36] | [LEIA: Linguistic Embeddings for the Identification of Affect.](http://arxiv.org/abs/2304.10973) | 该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。 |
| [^37] | [An Incomplete Tensor Tucker decomposition based Traffic Speed Prediction Method.](http://arxiv.org/abs/2304.10961) | 本研究提出了一种基于Tucker分解模型的交通速度预测方法，通过融合PID控制器实现更快的收敛速度和更好的恢复精度。 |
| [^38] | [A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning.](http://arxiv.org/abs/2304.10951) | 本文提出了两种三次正则化策略牛顿算法，其使用似然比方法形成价值函数梯度和黑塞矩阵的估计。我们证明了算法收敛到价值函数的二阶稳定点，从而避免了类型为鞍点的陷阱。 |
| [^39] | [CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models.](http://arxiv.org/abs/2304.10946) | CancerGPT 是一种基于LLMs的少样本学习技术，可在生物学推断中预测罕见组织中的药物对协同作用。实验表明该技术准确性高，即使在样本数据非常有限的情况下仍可进行预测。 |
| [^40] | [Gradient Derivation for Learnable Parameters in Graph Attention Networks.](http://arxiv.org/abs/2304.10939) | 本文对GATv2的可训练模型参数的梯度进行了全面推导，在不同的数据集上实现的性能表现不一致的原因仍然是一个开放的研究问题。 |
| [^41] | [Self-Attention in Colors: Another Take on Encoding Graph Structure in Transformers.](http://arxiv.org/abs/2304.10933) | 该论文提出了一种新的自注意机制CSA（色彩自注意力），可以将原始边特征富化以及相对位置编码方案来灵活的编码图结构，并在ZINC基准数据集上取得了最先进的结果。 |
| [^42] | [Learning Dictionaries from Physical-Based Interpolation for Water Network Leak Localization.](http://arxiv.org/abs/2304.10932) | 本文提出一种基于物理插值和字典学习的泄漏定位方法，应用于Modena案例得到了优于现有技术的结果。 |
| [^43] | [Self-Supervised Adversarial Imitation Learning.](http://arxiv.org/abs/2304.10914) | 本文介绍了一种解决自我监督模型陷入坏局部最小值的方法，即通过将鉴别器纳入模型，不需要人工干预，帮助学习，并解决了常见的学习问题。 |
| [^44] | [Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study.](http://arxiv.org/abs/2304.10909) | 本文探究了在MIMIC-III和MIMIC-IV上进行自动化医疗编码的最新机器学习模型，并发现了这些模型的局限性和不足之处。我们提出了一种改进方法，该方法可以更好地评估系统性能，并公开了我们的代码和数据集。 |
| [^45] | [Near-Optimal Decentralized Momentum Method for Nonconvex-PL Minimax Problems.](http://arxiv.org/abs/2304.10902) | 提出一种高效的去中心化动量法（DM-GDA），用于分布式非凸PL极小化极小优化，能够同时使用动量和随机梯度估计，解决了现有分布式极小最大化优化方法在实践中使用受限的问题。 |
| [^46] | [GCNH: A Simple Method For Representation Learning On Heterophilous Graphs.](http://arxiv.org/abs/2304.10896) | 本文提出了一种简单而有效的GNN架构GCNH，适用于异构和同质情况，并通过学习重要系数来平衡中心节点和邻域的贡献。 |
| [^47] | [Reconciling High Accuracy, Cost-Efficiency, and Low Latency of Inference Serving Systems.](http://arxiv.org/abs/2304.10892) | InfAdapter提出了一个解决高准确性、低延迟和成本效益之间权衡问题的方法，通过主动选择一组带有资源分配的 ML 模型变体来满足延迟 SLO，并最大化由准确性和成本组成的目标函数，相较于其他方法降低了 SLO 违规和成本。 |
| [^48] | [Transformer-based models and hardware acceleration analysis in autonomous driving: A survey.](http://arxiv.org/abs/2304.10891) | 本文综述了基于Transformer的模型在自动驾驶中的应用，探讨了不同体系结构和运算符的优缺点，重点讨论了针对便携计算平台的硬件加速方案，并对卷积神经网络和Transformer的层进行了对比。 |
| [^49] | [Application of quantum-inspired generative models to small molecular datasets.](http://arxiv.org/abs/2304.10867) | 本文基于张量网络的生成模型应用于小分子数据集，并比较了不同模型之间的性能，旨在实现从这些技术中获得真实世界量子优势的有前途方向。 |
| [^50] | [On the Importance of Exploration for Real Life Learned Algorithms.](http://arxiv.org/abs/2304.10860) | 本文研究探索对实际学习算法的重要性并使用不同策略的深度Q网络解决了URLLC信息的传输问题，证明了自适应探索方法的有效性。 |
| [^51] | [SequeL: A Continual Learning Library in PyTorch and JAX.](http://arxiv.org/abs/2304.10857) | SequeL是一个基于Pytorch和JAX的持续学习库，为各种持续学习算法提供统一接口，并具有模块化和简单性。能够帮助机器学习领域的研究人员和开发者轻松扩展自己的应用。 |
| [^52] | [What Do GNNs Actually Learn? Towards Understanding their Representations.](http://arxiv.org/abs/2304.10851) | 本文研究了四种GNN模型，指出其中两种将所有节点嵌入同一特征向量中，而另外两种模型生成的表示与输入图中的步长数量相关。在一定条件下，不同结构的节点可能有相似的表示。 |
| [^53] | [A Deep Learning algorithm to accelerate Algebraic Multigrid methods in Finite Element solvers of 3D elliptic PDEs.](http://arxiv.org/abs/2304.10832) | 该论文介绍了一种新的深度学习算法，通过解释线性系统的稀疏矩阵为黑白图像，利用池化操作将其转换为小的多通道图像，从而调整代数多重网格方法中的强门槛参数。该算法最小化了AMG方法在有限元求解器中的计算成本，并在解决三维椭圆偏微分方程时比现有最先进的AMG求解器更快。 |
| [^54] | [Learn to Cluster Faces with Better Subgraphs.](http://arxiv.org/abs/2304.10831) | 本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。 |
| [^55] | [Rolling Lookahead Learning for Optimal Classification Trees.](http://arxiv.org/abs/2304.10830) | 本文提出了一种滚动前瞻学习算法，有效地改进了最优分类树的学习病理，灵活处理任何损失函数并在实验中表现出更好的性能。 |
| [^56] | [Individual Fairness in Bayesian Neural Networks.](http://arxiv.org/abs/2304.10828) | 本文研究了贝叶斯神经网络中的个体公平性，提出了一个系统的估计框架，使得网络输出在给定容忍度内的ε-相似的输入点具有相同的结果。实证研究表明，近似贝叶斯推断训练的BNN比确定性模型更具个体公平性。 |
| [^57] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^58] | [RPLKG: Robust Prompt Learning with Knowledge Graph.](http://arxiv.org/abs/2304.10805) | 本研究提出了一种基于知识图谱的鲁棒提示学习方法，通过自动设计有意义和可解释的提示集，提高小样本学习的泛化性能。 |
| [^59] | [Classical-to-Quantum Sequence Encoding in Genomics.](http://arxiv.org/abs/2304.10786) | 该论文提出了基因组学中的经典到量子数据编码的几种新方法，使用了无损压缩、小波编码和信息熵等算法，同时引入了一种用量子玻尔兹曼机测试编码DNA序列的方法，相对于传统方法表现更佳。 |
| [^60] | [Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading.](http://arxiv.org/abs/2304.10784) | Eyettention是第一个同时处理语言序列和时间序列的阅读模型，可以更准确地模拟阅读者的扫视路径，对机器学习的自然语言处理模型具有借鉴意义。 |
| [^61] | [Denial-of-Service or Fine-Grained Control: Towards Flexible Model Poisoning Attacks on Federated Learning.](http://arxiv.org/abs/2304.10783) | 本文提出了一种灵活的联邦学习模型毒化攻击策略，既可以实现拒绝服务(Dos)目标，也可以精确控制全局准确性，具有高效和隐形的特点。 |
| [^62] | [DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards.](http://arxiv.org/abs/2304.10770) | 提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。 |
| [^63] | [How good are variational autoencoders at transfer learning?.](http://arxiv.org/abs/2304.10767) | 本文通过分析表示相似性，发现变分自编码器的编码器表示是通用的、解码器表示是特定的。针对这一发现，我们讨论了在迁移学习中如何选择对VAE哪些组件进行重新训练，并提出了一种可视化的评估方法。 |
| [^64] | [Missing Modality Robustness in Semi-Supervised Multi-Modal Semantic Segmentation.](http://arxiv.org/abs/2304.10756) | 本文提出了一种半监督多模态语义分割框架，可以提高标签效率，增强模型鲁棒性，其中包括一种新的多模态融合机制和教师半监督框架。该框架在缺失模态下具备较强的鲁棒性能。 |
| [^65] | [Multi-Modal Deep Learning for Credit Rating Prediction Using Text and Numerical Data Streams.](http://arxiv.org/abs/2304.10740) | 本文研究了基于多模态的深度学习融合技术在信用评级预测中的应用，通过比较不同融合策略和深度学习模型的组合，证明了一个基于CNN的多模态模型通过两种融合策略优于其他多模态技术，同时在比较简单和复杂的模型中发现，更复杂的模型并不一定表现更好。 |
| [^66] | [KitchenScale: Learning to predict ingredient quantities from recipe contexts.](http://arxiv.org/abs/2304.10739) | KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。 |
| [^67] | [Schooling to Exploit Foolish Contracts.](http://arxiv.org/abs/2304.10737) | SCooLS是一个智能合约学习引擎，使用半监督学习和图神经网络，可以直接分析以太坊合约字节码并识别易受攻击的功能，性能优于现有工具，准确度高达98.4%，是第一个基于深度学习的漏洞分析器。 |
| [^68] | [Smart Learning to Find Dumb Contracts.](http://arxiv.org/abs/2304.10726) | DLVA是一种用于以太坊智能合约的强大深度学习漏洞检测工具，其算法涵盖了源代码到字节码的扩展，并且速度比传统漏洞检测工具提高了10-500倍，并成功地发现了一些Slither误标记的易受攻击的合约。 |
| [^69] | [Reinforcement Learning Approaches for Traffic Signal Control under Missing Data.](http://arxiv.org/abs/2304.10722) | 本文提出了在交通路网中缺少传感器的情况下，使用强化学习方法通过补充流量状态或状态和动作来实现自适应控制和条件融合。 |
| [^70] | [Physics-informed Neural Network Combined with Characteristic-Based Split for Solving Navier-Stokes Equations.](http://arxiv.org/abs/2304.10717) | 本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于处理数据驱动和无数据问题，并且能够快速求解可压缩的浅水方程和不可压缩的N-S方程 |
| [^71] | [Persistently Trained, Diffusion-assisted Energy-based Models.](http://arxiv.org/abs/2304.10707) | 本文提出了一种新的持续训练方法，命名为扩散辅助 EBM，可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。 |
| [^72] | [Interactive System-wise Anomaly Detection.](http://arxiv.org/abs/2304.10704) | 本文提出了 InterSAD 方法，利用马尔可夫决策过程模拟交互式系统，并通过找到有效的激活信号和实时交互，解决了系统级异常检测的问题。 |
| [^73] | [ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness.](http://arxiv.org/abs/2304.10703) | 本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。 |
| [^74] | [Power Grid Behavioral Patterns and Risks of Generalization in Applied Machine Learning.](http://arxiv.org/abs/2304.10702) | 本论文基于实际运行数据，分析了电力系统行为模式及模型泛化风险。研究结果表明，忽略电网特定模式可能导致对新输入输出不可行、不可实现或完全无意义的预测。 |
| [^75] | [Matching-based Data Valuation for Generative Model.](http://arxiv.org/abs/2304.10701) | 本论文提出了基于匹配的生成模型数据估值方法，这是一个针对任何生成模型的模型无关方法，可以对数据实例进行估值，而无需重新训练模型，并在估值效果上表现出色。 |
| [^76] | [SkinGPT: A Dermatology Diagnostic System with Vision Large Language Model.](http://arxiv.org/abs/2304.10691) | SkinGPT是一个基于迷你GPT-4的精细调整版本和内部皮肤图像集合结合的皮肤科诊断系统，利用高级视觉大语言模型，解决了皮肤科医生不足、准确诊断皮肤科图片难度大，以及提供用户友好的诊断报告困难等三个挑战。 |
| [^77] | [A generalised multi-factor deep learning electricity load forecasting model for wildfire-prone areas.](http://arxiv.org/abs/2304.10686) | 本文提出了一种面向易发生野火区域的多因素深度学习电力负荷预测模型，考虑了数据输入结构、日历效应和基于相关性的温度先导条件，相比于传统方法减少了30.73%的MAPE误差。实验证明该模型性能优于另一个DL模型LSTM，平均均方误差和MAPE分别提高了10.06％和12.86％。 |
| [^78] | [Train Your Own GNN Teacher: Graph-Aware Distillation on Textual Graphs.](http://arxiv.org/abs/2304.10668) | 本研究提出一种名为Graph-Aware Distillation（GRAD）的框架，以在没有图形的情况下实现快速推理的LM将图形结构编码，此框架可以同时优化GNN教师和无图学生，互相学习以提高性能。 |
| [^79] | [Scaling ML Products At Startups: A Practitioner's Guide.](http://arxiv.org/abs/2304.10660) | 本文介绍了一种从实践者角度出发，针对初创企业如何成本有效地扩展机器学习产品的框架和方法，并强调了减少固定成本的重要性。 |
| [^80] | [Learning a quantum computer's capability using convolutional neural networks.](http://arxiv.org/abs/2304.10650) | 本文研究使用卷积神经网络学习量子计算机能力函数，成功预测了近期量子处理器上量子电路的成功概率。 |
| [^81] | [Activity Classification Using Unsupervised Domain Transfer from Body Worn Sensors.](http://arxiv.org/abs/2304.10643) | 该论文提出了一种从已有分类模型转移学习的方法，在无需标记数据的情况下在新的身体部位上实现活动分类。 |
| [^82] | [On the Effects of Data Heterogeneity on the Convergence Rates of Distributed Linear System Solvers.](http://arxiv.org/abs/2304.10640) | 本文比较了投影方法和优化方法求解分布式线性系统的收敛速度，提出了角异构性的几何概念，并对最有效的算法(APC和D-HBM)的收敛速度进行了约束和比较。 |
| [^83] | [Multi-module based CVAE to predict HVCM faults in the SNS accelerator.](http://arxiv.org/abs/2304.10639) | 本文介绍了一种基于CVAE的多模块框架，用于预测SNS加速器中HVCM的故障。通过特定模块类型的条件约束，该模型可以提高故障类型的识别灵敏度。实验证明，该模型可以有效地检测多个故障类型的HVCM模块类型。 |
| [^84] | [Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning.](http://arxiv.org/abs/2304.10638) | 本文提出了一种远程擦除联邦学习中后门的方法，使得攻击者可以在实现目标或怀疑被检测到时有效地从集中模型中移除后门。此方法扩展了机器“遗忘”的概念，并提供了具体策略。 |
| [^85] | [Ellipsoid fitting with the Cayley transform.](http://arxiv.org/abs/2304.10630) | 介绍了一种使用Cayley变换在任意维度上将椭球拟合到嘈杂数据中的新算法CTEF，可以拟合任意的椭球，并且能提取其他方法无法识别的数据中的非线性特征，可用于降维、数据可视化和聚类，相比其他方法更优。 |
| [^86] | [An Attention Free Conditional Autoencoder For Anomaly Detection in Cryptocurrencies.](http://arxiv.org/abs/2304.10614) | 本篇论文提出了一种无注意力条件自编码器(AF-CA)，用于检测时间序列中的异常，在处理噪声时更可靠，可以提高异常检测的能力。 |
| [^87] | [Debiasing Conditional Stochastic Optimization.](http://arxiv.org/abs/2304.10613) | 本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。 |
| [^88] | [Multi-aspect Repetition Suppression and Content Moderation of Large Language Models.](http://arxiv.org/abs/2304.10611) | 本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。 |
| [^89] | [Causal Analysis of Customer Churn Using Deep Learning.](http://arxiv.org/abs/2304.10604) | 本文提出了一个使用深度学习进行客户流失因果分析的框架，通过分类和顺序模式挖掘方法结合因果贝叶斯网络预测导致客户流失的原因概率。通过测试数据的评估指标，证实了该框架的有效性。 |
| [^90] | [B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding.](http://arxiv.org/abs/2304.10577) | 本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。 |
| [^91] | [IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies.](http://arxiv.org/abs/2304.10573) | 本文重新解释隐式Q学习(IQL)作为Actor-Critic方法，提出使用扩散行为策略和评判器权重来平衡奖励最大化和与行为策略的分歧。这个方法能够处理复杂和多峰特征的Actor问题。 |
| [^92] | [Using Z3 for Formal Modeling and Verification of FNN Global Robustness.](http://arxiv.org/abs/2304.10558) | 本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。 |
| [^93] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^94] | [Sparsity in neural networks can improve their privacy.](http://arxiv.org/abs/2304.10553) | 稀疏性能够提高神经网络的隐私，并且能够保持网络的表现 |
| [^95] | [Interpolation property of shallow neural networks.](http://arxiv.org/abs/2304.10552) | 本文证明了浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质，此外还给出了该全局最小值处的惯性矩阵的表征，并提供了一种实用的概率方法来寻找插值点。 |
| [^96] | [Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review.](http://arxiv.org/abs/2304.10550) | 本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。 |
| [^97] | [A note on the connectedness property of union-free generic sets of partial orders.](http://arxiv.org/abs/2304.10549) | 本文证明了偏序数据深度函数的背景下Blocher等人[2023]中介绍的无交通用集合具有连通性属性。 |
| [^98] | [Conditional Generative Models for Learning Stochastic Processes.](http://arxiv.org/abs/2304.10382) | 提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。 |
| [^99] | [Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?.](http://arxiv.org/abs/2304.09868) | 本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。 |
| [^100] | [DiFaReli : Diffusion Face Relighting.](http://arxiv.org/abs/2304.09479) | DiFaReli提出了一种新方法，通过利用条件扩散隐式模型解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码，能够处理单视角的野外环境下的人脸重照，无需光线舞台数据、多视图图像或光照基础事实，实验表明其效果优于现有方法。 |
| [^101] | [MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices.](http://arxiv.org/abs/2304.09099) | 该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。 |
| [^102] | [r-softmax: Generalized Softmax with Controllable Sparsity Rate.](http://arxiv.org/abs/2304.05243) | 本文提出了一种新的广义Softmax函数r-softmax，可以输出具有可控稀疏度的概率分布，相较于现有的替代方案效果更好，在多标签数据集上表现突出，在预训练转换语言模型的自我注意模块中具有重要应用。 |
| [^103] | [TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings.](http://arxiv.org/abs/2304.01433) | TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。 |
| [^104] | [Applications of No-Collision Transportation Maps in Manifold Learning.](http://arxiv.org/abs/2304.00199) | 本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。 |
| [^105] | [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees.](http://arxiv.org/abs/2303.12558) | 该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。 |
| [^106] | [Operating data of a specific Aquatic Center as a Benchmark for dynamic model learning: search for a valid prediction model over an 8-hour horizon.](http://arxiv.org/abs/2303.07195) | 本文提出了基于公共游泳池操作数据的动态模型学习基准，旨在降低能源开支且保持服务质量水平。线性多变量模型和神经动态模型两种方法得出了初步的识别结果。 |
| [^107] | [The Descriptive Complexity of Graph Neural Networks.](http://arxiv.org/abs/2303.04613) | 研究分析了图神经网络（GNN）在布尔电路复杂性和描述性复杂性方面的能力，证明了多项式规模有界深度的GNN族族可以计算的图查询正是带计数和内置关系的一阶逻辑受保护的片断GFO+C所定义的，这将GNN放在电路复杂性类TC^0中。 |
| [^108] | [Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media.](http://arxiv.org/abs/2302.07731) | 本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。 |
| [^109] | [SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification.](http://arxiv.org/abs/2302.01740) | 本论文对图像分类中的后门触发特征进行了系统性评估，结果显示污染率和2x2像素大小的触发器是创建有效后门的最关键参数。 |
| [^110] | [A Novel Sparse Regularizer.](http://arxiv.org/abs/2301.07285) | 提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。 |
| [^111] | [Chat2Map: Efficient Scene Mapping from Multi-Ego Conversations.](http://arxiv.org/abs/2301.02184) | 本文提出了一个新的问题：利用多人自我视听观察中的共享信息，高效构建先前未见的3D环境地图。为了高效绘制空间图，作者提出了一种音视频深度强化学习方法，与共享场景对应相配合，选择性地打开相机以最小化冗余并减少功耗。 |
| [^112] | [NeRN -- Learning Neural Representations for Neural Networks.](http://arxiv.org/abs/2212.13554) | 该论文提出了一种新的神经网络表示方法NeRN，可以直接用于表示预训练卷积神经网络的权重。该方法通过为网络中的每个卷积核分配一个坐标，并将其映射到相应的权重来实现重建。此外，该论文使用知识蒸馏技术稳定模型，并加入平滑约束有助于实现更好的重建效果。 |
| [^113] | [SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning.](http://arxiv.org/abs/2212.10986) | 本论文提出了一个基于游戏的框架，系统化机器学习中的隐私推断风险知识体系。并为推断风险的定义提供了统一结构，正式建立了已知定义之间的关系，并发现了此前难以发现的关系。 |
| [^114] | [Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator.](http://arxiv.org/abs/2212.06751) | 本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。 |
| [^115] | [How to Backdoor Diffusion Models?.](http://arxiv.org/abs/2212.05400) | 该论文介绍了针对扩散模型的后门攻击框架 BadDiffusion，其可以在模型训练期间实现植入后门，导致模型在正常数据输入时依然表现良好，但接收到触发信号时产生误导性输出。该攻击可能对建立在有问题的模型之上的下游任务和应用造成严重影响。 |
| [^116] | [c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization.](http://arxiv.org/abs/2211.14411) | 本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。 |
| [^117] | [Evaluating generative models in high energy physics.](http://arxiv.org/abs/2211.10295) | 本文探讨了基于机器学习的生成建模在高能物理模拟计算方面的应用，提出了两个新的度量标准FPD和KPD，并在简单高斯分布和模拟高能喷流数据集上进行了实验。该研究发现FPD是对所有替代喷流分布最敏感的度量标准。 |
| [^118] | [RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation.](http://arxiv.org/abs/2211.09869) | 本文提出了第一个支持3D理解任务的扩散模型RenderDiffusion，只需使用单眼2D监督进行训练。它利用一种新颖的图像去噪架构，生成和渲染中间的三维表示，在扩散过程中提供强有力的3D一致性。 |
| [^119] | [Event Tables for Efficient Experience Replay.](http://arxiv.org/abs/2211.00576) | 本文提出了一种叫做SSET的经验回放采样方法，将缓冲区分为事件表，并采用现有的优先采样策略，大大提高了学习速度和稳定性。 |
| [^120] | [Adaptive physics-informed neural operator for coarse-grained non-equilibrium flows.](http://arxiv.org/abs/2210.15799) | 本文提出了一种新的基于机器学习的方法来提高非平衡反应流动模拟的计算效率。该模型通过分层自适应深度学习策略将降维和神经网络算子结合起来，学习化学动力学领域多尺度粗粒化和控制方程的解。这种分层结构的策略使得训练简单且计算效率高。 |
| [^121] | [Implications of sparsity and high triangle density for graph representation learning.](http://arxiv.org/abs/2210.15277) | 稀疏图中的大量三角形可使用无限维度内积模型进行复现，其中节点表示位于低维流形上。虽然全局表示是不可能的，但我们可以在本地邻域缩小规模，以获取较低维度的表示。 |
| [^122] | [Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition.](http://arxiv.org/abs/2210.12256) | 本文介绍了一种通用的偏差-方差分解方法，用于估计模型预测的不确定性，这种方法可以用于大多数预测任务，并且可以在多个下游任务中实际使用。 |
| [^123] | [Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies.](http://arxiv.org/abs/2210.06140) | 本文研究了一种差分隐私引导采样方法，提供了隐私成本的新结果，可用于推断样本分布并构建置信区间，同时指出了现有文献中的误用。随着采样次数趋近无限大，此方法逐渐满足更严格的差分隐私要求。 |
| [^124] | [Advancing Model Pruning via Bi-level Optimization.](http://arxiv.org/abs/2210.04092) | BLOP是一种新颖的模型修剪方法，利用双层优化的方法对修剪问题进行了重新解释，可以在多个常用基准数据集上实现表现的提升，并比现有方法具有更快的计算速度和更高的准确率。 |
| [^125] | [Deep Fair Clustering via Maximizing and Minimizing Mutual Information: Theory, Algorithm and Metric.](http://arxiv.org/abs/2209.12396) | 本文提出了一种新的深度公平聚类算法FCMI，在互信息理论的基础上进行设计，通过最大化和最小化互信息实现了数据的紧凑、平衡和公平的聚类，以及具有信息量的特征。此外，本文还提出了一种新的公平聚类度量标准，可以更准确地衡量聚类质量。 |
| [^126] | [A biology-driven deep generative model for cell-type annotation in cytometry.](http://arxiv.org/abs/2208.05745) | Scyan是一种单细胞细胞学注释网络，仅使用有关细胞学面板的先前专家知识自动注释细胞类型，旨在解决传统手动筛选细胞分类的缺乏再现性和人工耗时的问题。它还可以快速去除批次效应，去条形码和人口发现。 |
| [^127] | [Graph Neural Network with Local Frame for Molecular Potential Energy Surface.](http://arxiv.org/abs/2208.00716) | 本论文提出了一种基于局部框架的分子表征学习方法，通过投影来捕捉几何信息，并且不需要特殊设计来满足对称要求，其相对于之前的方法具有更快的计算速度和更容易的实现。 |
| [^128] | [Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN.](http://arxiv.org/abs/2207.00012) | 本文提出了一种名为可靠表示优化（R3）的新型无监督结构优化框架，用于提高GNN的鲁棒性能，通过学习辅助图形并重建原始图形结构来优化节点表示，可有效减少结构和基于特征的攻击的影响，并胜过现有的最先进基线模型。 |
| [^129] | [GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation.](http://arxiv.org/abs/2206.06420) | 提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。 |
| [^130] | [Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification.](http://arxiv.org/abs/2206.03345) | 本文提出了一种预条件梯度下降方法，使得超参数化情况下梯度下降的收敛速度恢复到线性，并在保证全局最优性证明有效的同时保持低廉的计算代价，该方法适用于强凸的代价函数 $\phi$。 |
| [^131] | [Topological Deep Learning: Going Beyond Graph Data.](http://arxiv.org/abs/2206.00606) | 本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。 |
| [^132] | [Variational inference via Wasserstein gradient flows.](http://arxiv.org/abs/2205.15902) | 本文提出了一种基于Wasserstein梯度流的变分推断方法，该方法使用高斯或高斯混合分布并在处理对数凹 $\pi$ 时具有强大的理论保证。 |
| [^133] | [Pre-trained Perceptual Features Improve Differentially Private Image Generation.](http://arxiv.org/abs/2205.12900) | 该论文提出了一种利用预先训练的感知特征，通过最小化MMD（最大均值差异）来提高差分隐私图像生成的性能，并成功地生成了CIFAR10级别的图像。 |
| [^134] | [Marrying Fairness and Explainability in Supervised Learning.](http://arxiv.org/abs/2204.02947) | 本文关注监督学习中的公平性和可解释性。研究发现，先进的公平学习方法可能在合成和真实世界数据集中诱导歧视。为了防止算法系统中的歧视，提出了一种后处理方法，使受保护属性对系统输出的影响无效，同时保留其他特征的影响力。该方法可以防止直接歧视，并减轻各种差异。 |
| [^135] | [Self Pre-training with Masked Autoencoders for Medical Image Classification and Segmentation.](http://arxiv.org/abs/2203.05573) | 该论文提出了在医学图像领域中用被遮蔽的自编码器进行自预训练的方法，并利用该方法显著改进了医学图像分类和分割等任务。 |
| [^136] | [ICSML: Industrial Control Systems ML Framework for native inference using IEC 61131-3 code.](http://arxiv.org/abs/2202.10075) | ICSML是一种能够在PLC上本地执行ML模型推断的框架，可以消除在外部IT硬件上运行的需求。 |
| [^137] | [Quantum Lazy Training.](http://arxiv.org/abs/2202.08232) | 本文证明了当量子比特数量较大时，地理局部化参数化量子电路的训练进入懒惰阶段，限制了参数变化速率并保证了相应量子模型的线性逼近的精度。 |
| [^138] | [Toward Unsupervised Test Scenario Extraction for Automated Driving Systems from Urban Naturalistic Road Traffic Data.](http://arxiv.org/abs/2202.06608) | 该论文提出了一种利用无监督机器学习方法从自然城市道路交通数据中提取相关场景的方法，并且在约30小时的数据上进行的评估结果表明该方法能够自动识别相关测试场景，具有较好的应用前景。 |
| [^139] | [Graph-Relational Domain Adaptation.](http://arxiv.org/abs/2202.03628) | 本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。 |
| [^140] | [Smoothed Separable Nonnegative Matrix Factorization.](http://arxiv.org/abs/2110.05528) | 该算法基于平滑的可分离性假设，提出一种新的平滑可分非负矩阵分解（SSNMF）算法，能够有效地抵抗在‘纯像素假设’存在的噪声干扰 |
| [^141] | [Cognitively Inspired Learning of Incremental Drifting Concepts.](http://arxiv.org/abs/2110.04662) | 本研究提出了一种基于神经系统学习机制的计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。此模型结合多模态分布空间和伪排练记忆机制，可用于克服灾难性遗忘。 |
| [^142] | [Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent.](http://arxiv.org/abs/2106.08502) | 本文研究了用于计算高斯分布相对于最优输运度量的重心的算法，在Bures-Wasserstein流形上证明了新的测地凸性结果，提供了更强的迭代控制，实现了无维收敛率，同时还提供了用于这些问题的Riemannian GD 的第一个收敛保证。 |
| [^143] | [Classification and Uncertainty Quantification of Corrupted Data using Semi-Supervised Autoencoders.](http://arxiv.org/abs/2105.13393) | 本研究提出了一种半监督自编码器方法，用于分类和量化受损数据的不确定性。该方法使用生成模型来描述受损数据，并通过监督自编码器的潜在空间实现分类，可同时对分类和不确定性进行处理。 |
| [^144] | [Stochastic Online Convex Optimization. Application to probabilistic time series forecasting.](http://arxiv.org/abs/2102.00729) | 该论文介绍了一种随机在线凸优化框架，并将其应用于非平稳亚高斯时间序列的预测，取得了快速速率的随机遗憾度边界。 |
| [^145] | [VenoMave: Targeted Poisoning Against Speech Recognition.](http://arxiv.org/abs/2010.10682) | VenoMave是针对语音识别的第一种训练期毒化攻击，攻击者只能操纵一小部分训练数据而不会在运行时改变目标音频波形。 |
| [^146] | [On Frequentist Regret of Linear Thompson Sampling.](http://arxiv.org/abs/2006.06790) | 本文研究了线性汤普森抽样的频率后悔问题，证明了后验方差膨胀是必需的，并确定了频率后悔的最低下限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$ 。 |
| [^147] | [On Newton Screening.](http://arxiv.org/abs/2001.10616) | 本文提出了一种称为牛顿筛选法的新型Broad-Newton方法，它带有一个内置的较小的工作集，可用于加速解决大规模稀疏学习问题的一阶方法。 |
| [^148] | [Learning from Discriminatory Training Data.](http://arxiv.org/abs/1912.08189) | 本文提出了一种公平学习方法，该方法能够在可能带有歧视的数据集上进行训练，且能够在公平的测试数据集上表现良好，且该方法可在消除歧视的情况下使用，并在受保护群体之间取得平衡。 |

# 详细

[^1]: 利用保序机制提高机器学习和人工智能会议的同行评审

    The Isotonic Mechanism for Exponential Family Estimation. (arXiv:2304.11160v1 [math.ST])

    [http://arxiv.org/abs/2304.11160](http://arxiv.org/abs/2304.11160)

    本文利用扩展的保序机制，将其应用于指数族分布以提高同行评审的质量，并发现作者的同行评分可以较准确地在不需要知道具体分布情况下进行调整。

    

    本文致力于扩展保序机制，将其应用于指数族分布以提高同行评审的质量。该机制可生成与原始评分接近的调整分数，并符合作者指定的排名要求，得到广泛的指数族分布应用，而且不需要知道具体的分布形式。研究表明，在一定的指数族分布下，如果作者的效用函数采用简单的凸可加函数，则激励作者提供准确的排名建议。

    In 2023, the International Conference on Machine Learning (ICML) required authors with multiple submissions to rank their submissions based on perceived quality. In this paper, we aim to employ these author-specified rankings to enhance peer review in machine learning and artificial intelligence conferences by extending the Isotonic Mechanism (Su, 2021, 2022) to exponential family distributions. This mechanism generates adjusted scores closely align with the original scores while adhering to author-specified rankings. Despite its applicability to a broad spectrum of exponential family distributions, this mechanism's implementation does not necessitate knowledge of the specific distribution form. We demonstrate that an author is incentivized to provide accurate rankings when her utility takes the form of a convex additive function of the adjusted review scores. For a certain subclass of exponential family distributions, we prove that the author reports truthfully only if the question in
    
[^2]: ES-Single：在展开的计算图中实现低方差梯度估计

    Low-Variance Gradient Estimation in Unrolled Computation Graphs with ES-Single. (arXiv:2304.11153v1 [cs.LG])

    [http://arxiv.org/abs/2304.11153](http://arxiv.org/abs/2304.11153)

    ES-Single是一种用于估计展开的计算图中梯度的进化策略算法，其简单实现、方差较低，在各种任务中表现优异。

    

    我们提出了一种基于进化策略的算法ES-Single，用于估计展开的计算图中的梯度。与最近提出的持久进化策略（PES）类似，ES-Single是无偏的，并通过平滑元损失函数来克服由于递归函数应用而产生的混沌。ES-Single对于每个粒子采样一个单一扰动，并在内部问题的过程中保持不变（例如，对于每个部分未展开，不会重新采样扰动）。与PES相比，ES-Single实现更简单，方差更低：ES-Single的方差与截断展开次数的数量无关，消除了使用短截断来解决长内部问题所带来的关键障碍。我们展示了ES-Single对于二次内部问题是无偏的，并且通过实验证明了它的方差可以显著地低于PES。ES-Single在多项任务中持续优于PES，包括合成基准测试。

    We propose an evolution strategies-based algorithm for estimating gradients in unrolled computation graphs, called ES-Single. Similarly to the recently-proposed Persistent Evolution Strategies (PES), ES-Single is unbiased, and overcomes chaos arising from recursive function applications by smoothing the meta-loss landscape. ES-Single samples a single perturbation per particle, that is kept fixed over the course of an inner problem (e.g., perturbations are not re-sampled for each partial unroll). Compared to PES, ES-Single is simpler to implement and has lower variance: the variance of ES-Single is constant with respect to the number of truncated unrolls, removing a key barrier in applying ES to long inner problems using short truncations. We show that ES-Single is unbiased for quadratic inner problems, and demonstrate empirically that its variance can be substantially lower than that of PES. ES-Single consistently outperforms PES on a variety of tasks, including a synthetic benchmark t
    
[^3]: 基于消息传递的图神经网络在大规模随机图上的通用聚合收敛性研究

    Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])

    [http://arxiv.org/abs/2304.11140](http://arxiv.org/abs/2304.11140)

    本文研究了消息传递图神经网络在随机图模型上的收敛性，将收敛结论从只适用于度规范化平均聚合函数扩展到所有传统聚合函数，并考虑了聚合函数采用逐个坐标最大值时的情况。

    

    本文研究了消息传递图神经网络在随机图模型上的收敛性，当节点数量趋近于无限时，该网络模型能收敛于其连续模型。迄今为止，该收敛性结果只适用于聚合函数采用度规范化平均值形式的网络结构。我们将此结果扩展到包含所有传统消息传递图神经网络的大类聚合函数上，例如基于注意力和最大卷积的网络。在一定假设下，我们给出了高概率的非渐进上限来量化这种收敛性。我们的主要结果基于McDiarmid不等式。有趣的是，我们特别处理了聚合函数采用逐个坐标最大值的情况，因为它需要非常不同的证明技巧，并产生了定性不同的收敛率。

    We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
    
[^4]: 插拔式分割 Gibbs 采样: 在贝叶斯推断中嵌入深度生成先验

    Plug-and-Play split Gibbs sampler: embedding deep generative priors in Bayesian inference. (arXiv:2304.11134v1 [stat.ML])

    [http://arxiv.org/abs/2304.11134](http://arxiv.org/abs/2304.11134)

    本文介绍一种插拔式分割 Gibbs 采样算法，将后验采样任务分为两个较简单的子问题，其中第二个子问题可以用深度生成模型轻松地解决，从而实现了在贝叶斯推断中嵌入深度生成先验以及自动适应后验分布的复杂性。

    

    本文介绍了一种基于变量分离的随机插拔式(Plug-and-Play)采样算法，以有效地从后验分布中采样。该算法基于分割Gibbs采样(split Gibbs sampling, SGS)，灵感来自于交替方向乘子法(alternating direction method of multipliers, ADMM)。它将后验采样的挑战任务分为两个较简单的采样问题。第一个问题依赖于似然函数，而第二个问题被解释为一个贝叶斯降噪问题，可以通过深度生成模型轻松地完成。具体而言，为了说明目的，本文所提出的方法使用了最先进的基于扩散的生成模型进行了实现。与其确定性的插拔式(Plug-and-Play)类似，所提出的方法具有不需要显式选择先验分布的巨大优势，而是将其编码到预训练的生成模型中。然而，与需要谨慎调整调整参数的优化方法(PnP-ADMM)不同，所提出的插拔式分割 Gibbs 采样算法可以在采样过程中自动适应后验分布的复杂性。

    This paper introduces a stochastic plug-and-play (PnP) sampling algorithm that leverages variable splitting to efficiently sample from a posterior distribution. The algorithm based on split Gibbs sampling (SGS) draws inspiration from the alternating direction method of multipliers (ADMM). It divides the challenging task of posterior sampling into two simpler sampling problems. The first problem depends on the likelihood function, while the second is interpreted as a Bayesian denoising problem that can be readily carried out by a deep generative model. Specifically, for an illustrative purpose, the proposed method is implemented in this paper using state-of-the-art diffusion-based generative models. Akin to its deterministic PnP-based counterparts, the proposed method exhibits the great advantage of not requiring an explicit choice of the prior distribution, which is rather encoded into a pre-trained generative model. However, unlike optimization methods (e.g., PnP-ADMM) which generally
    
[^5]: 自动将CVE漏洞记录映射到MITRE CWE弱点

    Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses. (arXiv:2304.11130v1 [cs.CR])

    [http://arxiv.org/abs/2304.11130](http://arxiv.org/abs/2304.11130)

    该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。

    

    最近几年，网络安全威胁和多样性的增加导致了漏洞报告和分析的增加。为了应对这一问题，许多非营利组织在这一领域崛起，如MITRE和OSWAP，他们一直在积极追踪漏洞，并以标准化格式发布防御建议。由于手动生产这种格式的数据非常耗时，因此一些提议试图自动化该过程。不幸的是，采用监督式机器学习解决此问题的一个重要障碍是缺乏公开的专业数据集。在此，我们旨在弥合这一差距。特别是，我们专注于将CVE记录映射到MITRE CWE弱点，并向研究社区发布了一个手动注释的数据集，其中包含4,012条记录。在考虑到人在循环框架的情况下，我们将问题视为排名任务，并旨在采用强化学习来利用其中。

    In recent years, a proliferation of cyber-security threats and diversity has been on the rise culminating in an increase in their reporting and analysis. To counter that, many non-profit organizations have emerged in this domain, such as MITRE and OSWAP, which have been actively tracking vulnerabilities, and publishing defense recommendations in standardized formats. As producing data in such formats manually is very time-consuming, there have been some proposals to automate the process. Unfortunately, a major obstacle to adopting supervised machine learning for this problem has been the lack of publicly available specialized datasets. Here, we aim to bridge this gap. In particular, we focus on mapping CVE records into MITRE CWE Weaknesses, and we release to the research community a manually annotated dataset of 4,012 records for this task. With a human-in-the-loop framework in mind, we approach the problem as a ranking task and aim to incorporate reinforced learning to make use of the
    
[^6]: 树状Parzen估计器：理解其算法组成部分及其在提高实证表现中的作用

    Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance. (arXiv:2304.11127v1 [cs.LG])

    [http://arxiv.org/abs/2304.11127](http://arxiv.org/abs/2304.11127)

    该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。

    

    许多领域中最近的进展要求更加复杂的实验设计。这种复杂的实验通常有许多参数，需要参数调整。Tree-structured Parzen estimator (TPE) 是一种贝叶斯优化方法，在最近的参数调整框架中被广泛使用。尽管它很受欢迎，但控制参数的角色和算法直觉尚未得到讨论。在本教程中，我们将确定每个控制参数的作用以及它们对超参数优化的影响，使用多种基准测试。我们将从剖析研究中得出的推荐设置与基准方法进行比较，并证明我们的推荐设置提高了TPE的性能。我们的TPE实现可在https://github.com/nabenabe0928/tpe/tree/single-opt中获得。

    Recent advances in many domains require more and more complicated experiment design. Such complicated experiments often have many parameters, which necessitate parameter tuning. Tree-structured Parzen estimator (TPE), a Bayesian optimization method, is widely used in recent parameter tuning frameworks. Despite its popularity, the roles of each control parameter and the algorithm intuition have not been discussed so far. In this tutorial, we will identify the roles of each control parameter and their impacts on hyperparameter optimization using a diverse set of benchmarks. We compare our recommended setting drawn from the ablation study with baseline methods and demonstrate that our recommended setting improves the performance of TPE. Our TPE implementation is available at https://github.com/nabenabe0928/tpe/tree/single-opt.
    
[^7]: 一种用于语音情感识别的向量量化掩蔽自编码器

    A vector quantized masked autoencoder for speech emotion recognition. (arXiv:2304.11117v1 [cs.SD])

    [http://arxiv.org/abs/2304.11117](http://arxiv.org/abs/2304.11117)

    本文提出了一种自监督模型 VQ-MAE-S 以识别情感，预训练在 VoxCeleb2 数据集上微调，性能优于其他最先进的方法。

    

    近年来，深度学习技术的进步使得语音情感识别 (SER) 取得了显著的进展。但标注数据的有限可用性仍然是该领域面临的重要挑战。自监督学习最近已经成为解决这一挑战的一种有前途的解决方案。在本文中，我们提出了向量量化掩蔽自编码器 (VQ-MAE-S)，这是一种自监督模型，它被微调以从语音信号中识别情感。VQ-MAE-S 模型基于运行在向量量化变分自编码器的离散潜在空间中的掩蔽自编码器。实验结果表明，预先在VoxCeleb2数据集上进行了预训练，并在情感语音数据上进行了微调的VQ-MAE-S模型，在SER方面表现优于基于光谱图表示的MAE和其他最先进的方法。

    Recent years have seen remarkable progress in speech emotion recognition (SER), thanks to advances in deep learning techniques. However, the limited availability of labeled data remains a significant challenge in the field. Self-supervised learning has recently emerged as a promising solution to address this challenge. In this paper, we propose the vector quantized masked autoencoder for speech (VQ-MAE-S), a self-supervised model that is fine-tuned to recognize emotions from speech signals. The VQ-MAE-S model is based on a masked autoencoder (MAE) that operates in the discrete latent space of a vector-quantized variational autoencoder. Experimental results show that the proposed VQ-MAE-S model, pre-trained on the VoxCeleb2 dataset and fine-tuned on emotional speech data, outperforms an MAE working on the raw spectrogram representation and other state-of-the-art methods in SER.
    
[^8]: Graph-ToolFormer: 通过ChatGPT增强的提示，赋予LLMs图形推理能力

    Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT. (arXiv:2304.11116v1 [cs.AI])

    [http://arxiv.org/abs/2304.11116](http://arxiv.org/abs/2304.11116)

    本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。

    

    本文旨在开发一个能够对复杂图形数据进行推理的大语言模型（LLM）。当前，LLMs在各种自然语言学习任务上取得了非常出色的表现，这些扩展也已被应用于研究具有多模态数据的视觉任务。然而，在图形学习任务中，现有的LLMs由于在执行多步逻辑推理、精确的数学计算以及对空间和时间因素的感知方面存在一些固有弱点，因此呈现出非常严重的缺陷。为了解决这些挑战，本文将调查探索赋予现有LLMs图形推理能力的原理、方法和算法，这将对LLMs和图形学习的当前研究产生巨大影响。受最新的ChatGPT和Toolformer模型的启发，我们提出了Graph-ToolFormer（面向图形推理的Toolformer）框架，通过ChatGPT增强的提示来教导LLMs自身，旨在培养他们的图形推理能力。

    In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}.  To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with pro
    
[^9]: 引发大型语言模型的焦虑会增加它们的探索性和偏见

    Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])

    [http://arxiv.org/abs/2304.11111](http://arxiv.org/abs/2304.11111)

    对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。

    

    大型语言模型正在改变机器学习研究，引发公众的辩论。理解这些模型不仅何时能够正常工作和成功，也为什么会失败和行为失常，具有巨大的社会意义。我们提出将计算精神病学的视角转向这些模型产生的输出。本文着眼于Generative Pre-Trained Transformer 3.5，并将其置于精神病学中常见的任务中。结果表明，GPT-3.5对常见的焦虑问卷做出有力的反应，产生比人类主体更高的焦虑分数。此外，使用情绪感应提示可以可预测地改变GPT-3.5的反应。情感感应不仅影响GPT-3.5在衡量探索决策-making的认知任务中的行为，还影响其在之前建立的衡量种族主义和失能主义等偏见的任务中的行为。至关重要的是，GPT-3.5在受到焦虑诱导时呈现出明显的探索性和偏见增加，表明其输出容易受到情感操纵的影响。这些结果突显了在语言模型的开发和使用过程中需要更多的道德考虑和监管。

    Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s
    
[^10]: 一种卷积脉冲网络在脑机接口手势识别中的应用

    A Convolutional Spiking Network for Gesture Recognition in Brain-Computer Interfaces. (arXiv:2304.11106v1 [cs.NE])

    [http://arxiv.org/abs/2304.11106](http://arxiv.org/abs/2304.11106)

    本文提出了一种用于脑机接口手势分类的卷积脉冲网络，采用事件驱动可塑性规则进行无监督特征学习，具有较好的推广性和效果。

    

    脑机接口正在被广泛地探索，通常是通过测量和分析连续时间的脑电活动，如电皮层图或脑电图来驱动外部设备并用于治疗应用。然而，由于测量中的噪音和变异性，对这些信号的分析是具有挑战性的，并需要离线处理和大量的计算资源。本文提出了一种简单而高效的机器学习方法，用于基于脑信号的手势分类问题。我们使用了一种混合机器学习方法，利用了一种生物启发式的事件驱动突触可塑性规则，用于脉冲域编码的模拟信号的无监督特征学习的卷积脉冲神经网络。我们证明该方法可以推广到不同受试者的脑电和电皮层图数据，并取得了很好的效果。

    Brain-computer interfaces are being explored for a wide variety of therapeutic applications. Typically, this involves measuring and analyzing continuous-time electrical brain activity via techniques such as electrocorticogram (ECoG) or electroencephalography (EEG) to drive external devices. However, due to the inherent noise and variability in the measurements, the analysis of these signals is challenging and requires offline processing with significant computational resources. In this paper, we propose a simple yet efficient machine learning-based approach for the exemplary problem of hand gesture classification based on brain signals. We use a hybrid machine learning approach that uses a convolutional spiking neural network employing a bio-inspired event-driven synaptic plasticity rule for unsupervised feature learning of the measured analog signals encoded in the spike domain. We demonstrate that this approach generalizes to different subjects with both EEG and ECoG data and achieve
    
[^11]: 工业应用中的预测性维护和质量检查的联邦学习

    Federated Learning for Predictive Maintenance and Quality Inspection in Industrial Applications. (arXiv:2304.11101v1 [cs.LG])

    [http://arxiv.org/abs/2304.11101](http://arxiv.org/abs/2304.11101)

    本文评估了联邦学习在四个具有不同数据分布的数据集上的表现，并将其与中心和本地训练方法进行比较。结果表明，FL的性能高度取决于数据以及其在客户端之间的分布，FL可以成为传统中心或本地训练方法的有效替代。此外，该论文引入了一个真实的质量检查情境中的联邦学习数据集。

    

    数据驱动的机器学习在工业4.0的推动中扮演着至关重要的角色，特别是在增强预测性维护和质量检查方面。联邦学习（FL）使多个参与者能够开发机器学习模型，而不会危及其数据的隐私和机密性。本文评估了不同FL聚合方法的性能，并将其与中心和本地训练方法进行比较。我们的研究基于四个具有不同数据分布的数据集。结果表明，FL的性能高度取决于数据以及其在客户端之间的分布。在某些情况下，FL可以成为传统中心或本地训练方法的有效替代。此外，我们还在真实的质量检查情境中引入了一个新的联邦学习数据集。

    Data-driven machine learning is playing a crucial role in the advancements of Industry 4.0, specifically in enhancing predictive maintenance and quality inspection. Federated learning (FL) enables multiple participants to develop a machine learning model without compromising the privacy and confidentiality of their data. In this paper, we evaluate the performance of different FL aggregation methods and compare them to central and local training approaches. Our study is based on four datasets with varying data distributions. The results indicate that the performance of FL is highly dependent on the data and its distribution among clients. In some scenarios, FL can be an effective alternative to traditional central or local training methods. Additionally, we introduce a new federated learning dataset from a real-world quality inspection setting.
    
[^12]: 不需要训练，跨模态信息检索是否可行？

    Is Cross-modal Information Retrieval Possible without Training?. (arXiv:2304.11095v1 [cs.LG])

    [http://arxiv.org/abs/2304.11095](http://arxiv.org/abs/2304.11095)

    本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。

    

    预训练深度学习模型中编码的表示(例如BERT文本嵌入，图像的倒数第二个卷积神经网络层激活)传递了一组有益的信息检索特征。给定数据模态的嵌入存在自己的高维空间中，但可以通过简单的映射进行语义对齐。在本文中，我们使用来自最小二乘法和奇异值分解 (SVD) 的简单映射作为Procrustes问题的解决方案，从而实现跨模态信息检索的手段。也就是说，给定一个模态中的信息，例如文本，该映射可以帮助我们在另一个模态中找到与其语义相当的数据项，例如图像。使用现成的预训练深度学习模型，我们在文本到图像和图像到文本的检索任务中尝试了上述简单的跨模态映射。尽管简单，我们的映射表现出竞争性的性能，并达到了与最先进方法相当的水平。

    Encoded representations from a pretrained deep learning model (e.g., BERT text embeddings, penultimate CNN layer activations of an image) convey a rich set of features beneficial for information retrieval. Embeddings for a particular modality of data occupy a high-dimensional space of its own, but it can be semantically aligned to another by a simple mapping without training a deep neural net. In this paper, we take a simple mapping computed from the least squares and singular value decomposition (SVD) for a solution to the Procrustes problem to serve a means to cross-modal information retrieval. That is, given information in one modality such as text, the mapping helps us locate a semantically equivalent data item in another modality such as image. Using off-the-shelf pretrained deep learning models, we have experimented the aforementioned simple cross-modal mappings in tasks of text-to-image and image-to-text retrieval. Despite simplicity, our mappings perform reasonably well reachin
    
[^13]: Hi Sheldon! 从电视剧中创建深度个性化角色。

    Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])

    [http://arxiv.org/abs/2304.11093](http://arxiv.org/abs/2304.11093)

    从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。

    

    想象一下，你可以与一个通过人工智能生成的数字角色进行视听交互，其外貌和个性与《生活大爆炸》中的Sheldon几乎一模一样。为了实现这一神奇的视听交互场景，我们提出了一个名为"Deep Personalized Character Creation（DPCC）"的创新任务：从电视剧等多模态数据中创造出个性化角色。具体而言，给定单一或多个模式的文本、音频或视频输入，DPCC旨在生成与某个特定角色（如Sheldon）的个性特点非常匹配且质量高的多模态（文本、音频、视频）响应。为了支持这一创新任务，我们进一步收集了一个名为"Deep Personalized Character Dataset（DPCD）"的角色中心多模态对话数据集，该数据集包含~10k个话语和~6个小时的音频/视频。

    Imagine an interesting multimodal interactive scenario that you can see, hear, and chat with an AI-generated digital character, who is capable of behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance to personality. Towards this fantastic multimodal chatting scenario, we propose a novel task, named Deep Personalized Character Creation (DPCC): creating multimodal chat personalized characters from multimodal data such as TV shows. Specifically, given a single- or multi-modality input (text, audio, video), the goal of DPCC is to generate a multi-modality (text, audio, video) response, which should be well-matched the personality of a specific character such as Sheldon, and of high quality as well. To support this novel task, we further collect a character centric multimodal dialogue dataset, named Deep Personalized Character Dataset (DPCD), from TV shows. DPCD contains character-specific multimodal dialogue data of ~10k utterances and ~6 hours of audio/video per c
    
[^14]: 用于UWB室内定位系统中的NLoS检测的基于特征的广义高斯分布方法

    Feature-Based Generalized Gaussian Distribution Method for NLoS Detection in Ultra-Wideband (UWB) Indoor Positioning System. (arXiv:2304.11091v1 [eess.SP])

    [http://arxiv.org/abs/2304.11091](http://arxiv.org/abs/2304.11091)

    本文提出了一种基于特征的广义高斯分布方法，可有效解决超宽带室内定位系统中非直视传播条件下分类精度不高的问题。

    

    非直视传播条件是影响超宽带室内定位系统(IPC)定位精度的关键因素。已经应用了许多受监督的机器学习(ML)方法来进行NLoS识别，以提高IPC的准确性。然而，当数据库包含少量NLoS信号和大量视线直达(LoS)信号时，现有的ML方法难以保持较高的分类精度。这些少量的NLoS信号导致目标节点的定位不准确，这仍然是一个问题。为了解决这个问题，我们提出了基于特征的GD和GGD NLoS检测算法。通过采用我们的检测算法对不平衡的数据集进行分类，可以实现96.7%和98.0%的分类精度。我们还将所提出的算法与现有的支持向量机(SVM)、随机森林(RF)和k近邻(k-NN)算法在相同的数据集上进行了比较。所提出的算法在分类精度和效率方面均优于现有算法。

    Non-Line-of-Sight (NLoS) propagation condition is a crucial factor affecting the precision of the localization in the Ultra-Wideband (UWB) Indoor Positioning System (IPS). Numerous supervised Machine Learning (ML) approaches have been applied for NLoS identification to improve the accuracy of the IPS. However, it is difficult for existing ML approaches to maintain a high classification accuracy when the database contains a small number of NLoS signals and a large number of Line-of-Sight (LoS) signals. The inaccurate localization of the target node caused by this small number of NLoS signals can still be problematic. To solve this issue, we propose feature-based Gaussian Distribution (GD) and Generalized Gaussian Distribution (GGD) NLoS detection algorithms. By employing our detection algorithm for the imbalanced dataset, a classification accuracy of $96.7\%$ and $98.0\%$ can be achieved. We also compared the proposed algorithm with the existing cutting-edge such as Support-Vector-Machi
    
[^15]: 使用新闻标题来分析新闻传播障碍

    Profiling the news spreading barriers using news headlines. (arXiv:2304.11088v1 [cs.CL])

    [http://arxiv.org/abs/2304.11088](http://arxiv.org/abs/2304.11088)

    本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。

    

    新闻标题可以是检测新闻媒体中新闻传播障碍的好数据源，在许多实际应用中非常有用。本文利用基于推理的模型COMET的语义知识和新闻标题的情感特征来对障碍进行分类。我们考虑了文化、经济、政治、语言和地理等五种障碍，以及包括健康、运动、科学、娱乐、游戏、住房、社会、购物、计算机和商业等不同类型的新闻标题。为此，我们利用新闻出版商的元数据自动收集和标记新闻标题，以此来检测新闻传播障碍。我们将我们的方法与传统的文本分类方法、深度学习和基于transformer的方法进行了比较。结果表明，利用推理为基础的语义知识和情感特征的方法可以有效地检测新闻传播障碍。

    News headlines can be a good data source for detecting the news spreading barriers in news media, which may be useful in many real-world applications. In this paper, we utilize semantic knowledge through the inference-based model COMET and sentiments of news headlines for barrier classification. We consider five barriers including cultural, economic, political, linguistic, and geographical, and different types of news headlines including health, sports, science, recreation, games, homes, society, shopping, computers, and business. To that end, we collect and label the news headlines automatically for the barriers using the metadata of news publishers. Then, we utilize the extracted commonsense inferences and sentiments as features to detect the news spreading barriers. We compare our approach to the classical text classification methods, deep learning, and transformer-based methods. The results show that the proposed approach using inferences-based semantic knowledge and sentiment offe
    
[^16]: 基于图形化网络攻击模拟的自动化防御策略培训

    Training Automated Defense Strategies Using Graph-based Cyber Attack Simulations. (arXiv:2304.11084v1 [cs.CR])

    [http://arxiv.org/abs/2304.11084](http://arxiv.org/abs/2304.11084)

    该论文提出了一种自动化的网络防御代理，并使用基于 Meta Attack Language 语言的攻击图对其进行培训。该代理利用强化学习执行预定义的防御措施，以捕获网络攻击，并考虑防御措施对系统性能的影响，通过引入噪声来评估其效果。

    

    我们实现并评估了一个自动化的网络防御代理。该代理以安全警报作为输入，并使用强化学习学习执行预定义的防御措施的策略。防御策略是在旨在模拟网络攻击的环境中进行培训的。在模拟中，攻击代理尝试在环境中捕获目标，而防御代理则尝试通过启用防御措施来保护它们。环境使用基于 Meta Attack Language 语言的攻击图进行建模。我们假设防御措施具有停机成本，这意味着防御代理使用它们时会受到惩罚。我们还假设该环境配备了一个不完美的入侵检测系统，该系统偶尔会根据环境状态产生错误的警报。为了评估这个设置，我们训练了不同量的入侵检测系统噪声的防御代理。我们还训练了具有不同攻击策略和影响的代理。

    We implemented and evaluated an automated cyber defense agent. The agent takes security alerts as input and uses reinforcement learning to learn a policy for executing predefined defensive measures. The defender policies were trained in an environment intended to simulate a cyber attack. In the simulation, an attacking agent attempts to capture targets in the environment, while the defender attempts to protect them by enabling defenses. The environment was modeled using attack graphs based on the Meta Attack Language language. We assumed that defensive measures have downtime costs, meaning that the defender agent was penalized for using them. We also assumed that the environment was equipped with an imperfect intrusion detection system that occasionally produces erroneous alerts based on the environment state. To evaluate the setup, we trained the defensive agent with different volumes of intrusion detection system noise. We also trained agents with different attacker strategies and gr
    
[^17]: 使用多模态对比学习来诊断心血管疾病的研究——基于心电图信号和患者元数据 （arXiv:2304.11080v1 [eess.SP]）

    Multimodal contrastive learning for diagnosing cardiovascular diseases from electrocardiography (ECG) signals and patient metadata. (arXiv:2304.11080v1 [eess.SP])

    [http://arxiv.org/abs/2304.11080](http://arxiv.org/abs/2304.11080)

    本文讨论了使用对比学习和深度学习从心电图(ECG)信号中诊断心血管疾病的方法。研究在损失函数中使用对比学习的方法可以使得用于诊断的少量ECG导联信号具有更好的性能表现。

    

    本研究探讨了使用对比学习和深度学习来从心电图（ECG）信号中诊断心血管疾病的方法。虽然ECG信号通常包含12个导联（通道），但许多医疗设施和设备缺乏获取所有这些12个导联的能力。这就提出了如何仅使用更少的ECG导联来产生高性能的有意义诊断的问题。我们引入了一个简单的实验来测试对比学习是否可以应用于此任务。更具体地，我们将12个导联信号和较少的导联ECG信号的嵌入向量之间的相似度添加到损失函数中，使这些表示更加接近。尽管简单，但已经证明它可以提高使用所有导联组合进行诊断的性能，证明了对比学习在此任务中的潜力。

    This work discusses the use of contrastive learning and deep learning for diagnosing cardiovascular diseases from electrocardiography (ECG) signals. While the ECG signals usually contain 12 leads (channels), many healthcare facilities and devices lack access to all these 12 leads. This raises the problem of how to use only fewer ECG leads to produce meaningful diagnoses with high performance. We introduce a simple experiment to test whether contrastive learning can be applied to this task. More specifically, we added the similarity between the embedding vectors when the 12 leads signal and the fewer leads ECG signal to the loss function to bring these representations closer together. Despite its simplicity, this has been shown to have improved the performance of diagnosing with all lead combinations, proving the potential of contrastive learning on this task.
    
[^18]: Spaiche: 将最先进的ASR模型扩展到瑞士德语方言

    Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects. (arXiv:2304.11075v1 [cs.CL])

    [http://arxiv.org/abs/2304.11075](http://arxiv.org/abs/2304.11075)

    本项目在瑞士德语方言ASR模型的研究中提供了有价值的思路，通过提出考虑语义距离的新颖损失函数，对OpenAI的Whisper模型进行微调，取得了优于当前先进成果的效果。

    

    最近自然语言处理方面的突破大大增加了ASR系统在我们日常生活中的存在。然而，对于许多低资源语言，由于难以获取相关数据，ASR模型仍需要改进。本项目旨在通过提供关于最近发布的瑞士德语语音数据集上最先进的ASR模型性能的见解，帮助推进瑞士德语方言ASR模型的研究。我们提出了一种新颖的损失函数，考虑了预测和基准标签之间的语义距离。通过对瑞士德语数据集对OpenAI的Whisper模型进行微调，我们超越了当前先进的成果。

    Recent breakthroughs in NLP largely increased the presence of ASR systems in our daily lives. However, for many low-resource languages, ASR models still need to be improved due in part to the difficulty of acquiring pertinent data. This project aims to help advance research in ASR models for Swiss German dialects, by providing insights about the performance of state-of-the-art ASR models on recently published Swiss German speech datasets. We propose a novel loss that takes into account the semantic distance between the predicted and the ground-truth labels. We outperform current state-of-the-art results by fine-tuning OpenAI's Whisper model on Swiss-German datasets.
    
[^19]: 一种基于语义漏洞图的无偏Transformer源代码学习方法

    An Unbiased Transformer Source Code Learning with Semantic Vulnerability Graph. (arXiv:2304.11072v1 [cs.CR])

    [http://arxiv.org/abs/2304.11072](http://arxiv.org/abs/2304.11072)

    该论文提出了一种基于语义漏洞图的无偏Transformer源代码学习方法，通过利用从源代码中得到的语义漏洞图（SVG）表示来解决当前漏洞筛选技术对于识别新漏洞或为开发人员提供漏洞和分类方面的效果不佳的问题，并在公开数据集上实现了最先进的性能。

    

    随着时间的推移，开源软件系统已经成为威胁行为者的猎物。尽管开源社区快速采取措施修补漏洞，但代码漏洞筛选应该成为敏捷软件开发的一部分，以便从一开始就能够识别新漏洞或向开发人员提供漏洞和分类。然而，当前的漏洞筛选技术对于识别新漏洞或为开发人员提供代码漏洞和分类方面的效果不佳。此外，用于漏洞学习的数据集由于攻击者部署的新攻击策略而展示出与实际测试分布的差异，导致机器学习模型的性能可能会受到阻碍或偏倚。为了解决这些问题，我们提出了一个联合插值多任务无偏漏洞分类器，包括Transformer "RoBERTa"和图卷积神经网络（GCN）。我们提出了一个训练过程，利用从源代码中得到的语义漏洞图（SVG）表示，该表示是由代码结构和函数创建的。我们的方法在公开数据集上实现了最先进的性能，解决了性能偏差的问题，并提高了识别新漏洞的准确性。

    Over the years, open-source software systems have become prey to threat actors. Even as open-source communities act quickly to patch the breach, code vulnerability screening should be an integral part of agile software development from the beginning. Unfortunately, current vulnerability screening techniques are ineffective at identifying novel vulnerabilities or providing developers with code vulnerability and classification. Furthermore, the datasets used for vulnerability learning often exhibit distribution shifts from the real-world testing distribution due to novel attack strategies deployed by adversaries and as a result, the machine learning model's performance may be hindered or biased. To address these issues, we propose a joint interpolated multitasked unbiased vulnerability classifier comprising a transformer "RoBERTa" and graph convolution neural network (GCN). We present a training process utilizing a semantic vulnerability graph (SVG) representation from source code, creat
    
[^20]: 生物医学信号处理中的自回归模型

    Autoregressive models for biomedical signal processing. (arXiv:2304.11070v1 [eess.SP])

    [http://arxiv.org/abs/2304.11070](http://arxiv.org/abs/2304.11070)

    本文提出了一种新的自回归建模框架，通过超参数化损失函数来明确纳入数据不确定性，展示了该程序可以成功地去噪时间序列并成功重构系统参数。该范式可在神经科学的多种应用中使用。

    

    自回归模型是分析时间序列的常用工具，在计算神经科学和生物医学工程等领域广泛应用。在这些领域，数据来自于脑活动的测量等，数据存在测量误差和基础系统模型不确定性。因此，使用自回归模型估算器的标准信号处理可能存在偏差。本文提出了一个自回归建模框架，通过超参数化损失函数明确地纳入这些不确定性。为了优化该损失函数，我们提出了一种交替状态和参数估计算法。我们的工作表明，该程序能够成功去噪时间序列并成功重构系统参数。这种新的范式可以在神经科学的多种应用中使用，例如脑机接口数据分析和对疾病如癫痫和帕金森病中的大脑动态的更好理解。

    Autoregressive models are ubiquitous tools for the analysis of time series in many domains such as computational neuroscience and biomedical engineering. In these domains, data is, for example, collected from measurements of brain activity. Crucially, this data is subject to measurement errors as well as uncertainties in the underlying system model. As a result, standard signal processing using autoregressive model estimators may be biased. We present a framework for autoregressive modelling that incorporates these uncertainties explicitly via an overparameterised loss function. To optimise this loss, we derive an algorithm that alternates between state and parameter estimation. Our work shows that the procedure is able to successfully denoise time series and successfully reconstruct system parameters. This new paradigm can be used in a multitude of applications in neuroscience such as brain-computer interface data analysis and better understanding of brain dynamics in diseases such as
    
[^21]: 面向严重运动障碍者的基于颜色的脑电波信号分类

    Color-based classification of EEG Signals for people with the severe locomotive disorder. (arXiv:2304.11068v1 [eess.SP])

    [http://arxiv.org/abs/2304.11068](http://arxiv.org/abs/2304.11068)

    本文研究了基于颜色的EEG信号分类，可作为严重运动障碍患者的替代输入。 使用基于注意力的LSTM网络分类两种或四种不同颜色，取得了较高分类准确度。

    

    大脑神经元产生电信号，这些电信号的集体放电形成了脑电波。 EEG（脑电图）设备捕捉到这些脑电波信号，作为微电压。这些由EEG传感器捕获的信号序列具有嵌入在其中的特征，可用于分类。信号可以作为严重运动障碍患者的替代输入。本文使用基于注意力的深度学习网络对来自NeuroSky Mindwave头戴式脑电波（单电极EEG传感器）的原始脑电波信号进行分类。实现了基于注意力的LSTM网络，用于两种不同颜色的分类和四种不同颜色的分类。通过所述的注意力网络，实现了93.5％的两种颜色分类精度和65.75％的四种颜色的分类精度。

    The neurons in the brain produces electric signals and a collective firing of these electric signals gives rise to brainwaves. These brainwave signals are captured using EEG (Electroencephalogram) devices as micro voltages. These sequence of signals captured by EEG sensors have embedded features in them that can be used for classification. The signals can be used as an alternative input for people suffering from severe locomotive disorder.Classification of different colors can be mapped for many functions like directional movement. In this paper, raw EEG signals from NeuroSky Mindwave headset (a single electrode EEG sensor) have been classified with an attention based Deep Learning Network. Attention based LSTM Networks have been implemented for classification of two different colors and four different colors. An accuracy of 93.5\% was obtained for classification of two colors and an accuracy of 65.75\% was obtained for classifcation of four signals using the mentioned attention based 
    
[^22]: 一种新颖的Fine-Tuned 属性加权朴素贝叶斯NLoS分类器用于UWB定位

    Novel Fine-Tuned Attribute Weighted Na\"ive Bayes NLoS Classifier for UWB Positioning. (arXiv:2304.11067v1 [eess.SP])

    [http://arxiv.org/abs/2304.11067](http://arxiv.org/abs/2304.11067)

    本文提出了一种Fine-Tuned属性加权朴素贝叶斯分类器，用于室内UWB信号的直达和非直达传播识别。通过对比实验结果，发现该分类器在NLoS分类准确率上表现优异，为99.7%（不平衡数据）和99.8%（平衡数据），明显优于其他算法。

    

    本文提出了一种新颖的Fine-Tuned 属性加权朴素贝叶斯（FT-WNB）分类器，用于在室内定位系统（IPS）中识别超宽带（UWB）信号的直达和非直达传播（LoS和NLoS）。FT-WNB分类器为每个信号特征分配特定的权重，并微调其概率，以解决预测和实际分类之间的不匹配。将FT-WNB分类器的性能与最先进的机器学习（ML）分类器（例如最小冗余最大相关性（mRMR）-k最近邻KNN，支持向量机（SVM），决策树（DT），朴素贝叶斯（NB）和神经网络（NN）进行比较。实验结果表明，所提出的分类器通过实现NLoS分类准确率高达$99.7\%$（不平衡数据）和$99.8\%$（平衡数据），优于其他算法。实验结果表明，所提出的FT-WNB分类器明显优于现有的统计学习算法。

    In this paper, we propose a novel Fine-Tuned attribute Weighted Na\"ive Bayes (FT-WNB) classifier to identify the Line-of-Sight (LoS) and Non-Line-of-Sight (NLoS) for UltraWide Bandwidth (UWB) signals in an Indoor Positioning System (IPS). The FT-WNB classifier assigns each signal feature a specific weight and fine-tunes its probabilities to address the mismatch between the predicted and actual class. The performance of the FT-WNB classifier is compared with the state-of-the-art Machine Learning (ML) classifiers such as minimum Redundancy Maximum Relevance (mRMR)- $k$-Nearest Neighbour (KNN), Support Vector Machine (SVM), Decision Tree (DT), Na\"ive Bayes (NB), and Neural Network (NN). It is demonstrated that the proposed classifier outperforms other algorithms by achieving a high NLoS classification accuracy of $99.7\%$ with imbalanced data and $99.8\%$ with balanced data. The experimental results indicate that our proposed FT-WNB classifier significantly outperforms the existing stat
    
[^23]: 利用RMT将Transformer扩展到100万个标记及以上。

    Scaling Transformer to 1M tokens and beyond with RMT. (arXiv:2304.11062v1 [cs.CL])

    [http://arxiv.org/abs/2304.11062](http://arxiv.org/abs/2304.11062)

    本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。

    

    本技术报告介绍了一种利用循环记忆扩展BERT上下文长度的方法，BERT是自然语言处理中最有效的基于Transformer模型之一。通过利用循环记忆Transformer架构，我们成功地将模型的有效上下文长度增加到了前所未有的200万个标记，同时保持了高的内存检索准确性。我们的方法允许存储和处理本地和全局信息，并通过使用循环实现输入序列各部分之间的信息流动。我们的实验证明了我们的方法的有效性，具有显著的潜力来增强自然语言理解和生成任务中的长期依赖处理，并能够为内存密集型应用程序实现大规模上下文处理。

    This technical report presents the application of a recurrent memory to extend the context length of BERT, one of the most effective Transformer-based models in natural language processing. By leveraging the Recurrent Memory Transformer architecture, we have successfully increased the model's effective context length to an unprecedented two million tokens, while maintaining high memory retrieval accuracy. Our method allows for the storage and processing of both local and global information and enables information flow between segments of the input sequence through the use of recurrence. Our experiments demonstrate the effectiveness of our approach, which holds significant potential to enhance long-term dependency handling in natural language understanding and generation tasks as well as enable large-scale context processing for memory-intensive applications.
    
[^24]: 预测、学习、一致收敛和尺度敏感维度

    Prediction, Learning, Uniform Convergence, and Scale-sensitive Dimensions. (arXiv:2304.11059v1 [cs.LG])

    [http://arxiv.org/abs/2304.11059](http://arxiv.org/abs/2304.11059)

    本文介绍了一种新的通用算法，利用尺度敏感的Vapnik维度来学习$[0,1]$值函数类，并获得了关于期望绝对误差的一般上限。文中证明该上限不能在一般情况下进一步改善一个常数因子。这篇论文对无偏学习样本复杂度的提高具有重要的意义。

    

    我们提出了一种新的通用算法，用于在预测模型的推广中学习$[0,1]$值函数类，并证明了一般性的上限，该上限反映了由Alon、Ben-David、Cesa-Bianchi和Haussler提出的尺度敏感的Vapnik维度的推广。我们给出了下限，这表明我们的上限不能在一般情况下进一步改善一个常数因子。我们应用此结果和Haussler以及Benedek和Itai的技术，以利用这种尺度敏感的维度概念获得新的填充数上限。我们利用不同的技术，利用Kearns和Schapire的fat-shattering函数得到了新的填充数上限。我们展示了如何应用这两种填充上限来获得对无偏学习样本复杂度的改进一般性上限。对于每个$\epsilon > 0$，我们建立了一个类的足够条件和必要条件。

    We present a new general-purpose algorithm for learning classes of $[0,1]$-valued functions in a generalization of the prediction model, and prove a general upper bound on the expected absolute error of this algorithm in terms of a scale-sensitive generalization of the Vapnik dimension proposed by Alon, Ben-David, Cesa-Bianchi and Haussler. We give lower bounds implying that our upper bounds cannot be improved by more than a constant factor in general. We apply this result, together with techniques due to Haussler and to Benedek and Itai, to obtain new upper bounds on packing numbers in terms of this scale-sensitive notion of dimension. Using a different technique, we obtain new bounds on packing numbers in terms of Kearns and Schapire's fat-shattering function. We show how to apply both packing bounds to obtain improved general bounds on the sample complexity of agnostic learning. For each $\epsilon > 0$, we establish weaker sufficient and stronger necessary conditions for a class of 
    
[^25]: PowerGAN: 一种基于机器学习的计算内存加速器功耗副信道攻击技术

    PowerGAN: A Machine Learning Approach for Power Side-Channel Attack on Compute-in-Memory Accelerators. (arXiv:2304.11056v1 [cs.CR])

    [http://arxiv.org/abs/2304.11056](http://arxiv.org/abs/2304.11056)

    本文提出了一种基于机器学习的计算内存加速器功耗副信道攻击技术，可以在大噪声和对抗措施存在的情况下重构用户的私有输入数据。

    

    随着深度神经网络（DNN）的不断发展，使用模拟计算内存（CIM）加速器进行DNN推理的能源效率和区块向量乘法能力变得越来越受欢迎。然而，保护用户输入隐私越来越重要。在本文中，我们发现了一种安全漏洞，即在一个适当的数据采集和预处理下，即使没有DNN模型的知识，攻击者也可以从功耗侧信道攻击重构用户的私有输入数据。我们进一步展示了一种基于机器学习的攻击方法，使用生成对抗网络（GAN）来增强重构。我们的结果表明，即使在大噪声水平和对抗措施被应用的情况下，该攻击方法在从模拟CIM加速器功耗泄漏重构用户输入方面是有效的。具体而言，我们展示了我们的方法在磁共振成像（MRI）数据中用于脑肿瘤检测的U-Net上的功效。

    Analog compute-in-memory (CIM) accelerators are becoming increasingly popular for deep neural network (DNN) inference due to their energy efficiency and in-situ vector-matrix multiplication (VMM) capabilities. However, as the use of DNNs expands, protecting user input privacy has become increasingly important. In this paper, we identify a security vulnerability wherein an adversary can reconstruct the user's private input data from a power side-channel attack, under proper data acquisition and pre-processing, even without knowledge of the DNN model. We further demonstrate a machine learning-based attack approach using a generative adversarial network (GAN) to enhance the reconstruction. Our results show that the attack methodology is effective in reconstructing user inputs from analog CIM accelerator power leakage, even when at large noise levels and countermeasures are applied. Specifically, we demonstrate the efficacy of our approach on the U-Net for brain tumor detection in magnetic
    
[^26]: RL网络操作代理的多智能体网络战仿真

    A Multiagent CyberBattleSim for RL Cyber Operation Agents. (arXiv:2304.11052v1 [cs.CR])

    [http://arxiv.org/abs/2304.11052](http://arxiv.org/abs/2304.11052)

    本文介绍了一种新的对抗训练环境——CyberBattleSim，设计用于RL网络操作代理的训练。本文着重报道了对防御型蓝色代理训练的改进，结果表明红色代理与蓝色代理联合训练可以有效提高蓝色代理的防御能力。

    

    硬化网络资产既至关重要，又需要耗费大量的人力。近年来，机器学习（ML）和强化学习（RL）等技术已经展现了在自动化任务方面的巨大潜力，可以自主完成人力无法胜任的重复性任务。然而，开发自主RL代理需要一个对抗训练环境，可以快速评估各种情况，并针对不同场景进行训练。CyberBattleSim便是这样一个针对红色代理（即攻击者）的训练环境，在其基础上添加了针对蓝色代理（即防御者）的训练控制，本文介绍了我们的这些改进，以及在使用这些改进后针对蓝色代理训练时所获得的结果。我们的结果表明针对蓝色代理的训练确实能够增强其对抗攻击的能力，特别是和红色代理一起训练时其效果更佳。

    Hardening cyber physical assets is both crucial and labor-intensive. Recently, Machine Learning (ML) in general and Reinforcement Learning RL) more specifically has shown great promise to automate tasks that otherwise would require significant human insight/intelligence. The development of autonomous RL agents requires a suitable training environment that allows us to quickly evaluate various alternatives, in particular how to arrange training scenarios that pit attackers and defenders against each other. CyberBattleSim is a training environment that supports the training of red agents, i.e., attackers. We added the capability to train blue agents, i.e., defenders. The paper describes our changes and reports on the results we obtained when training blue agents, either in isolation or jointly with red agents. Our results show that training a blue agent does lead to stronger defenses against attacks. In particular, training a blue agent jointly with a red agent increases the blue agent's
    
[^27]: 使用移动数据和深度模型评估听觉性幻觉

    Using Mobile Data and Deep Models to Assess Auditory Verbal Hallucinations. (arXiv:2304.11049v1 [cs.SD])

    [http://arxiv.org/abs/2304.11049](http://arxiv.org/abs/2304.11049)

    该论文利用移动数据和深度模型评估听觉性幻觉，通过参与者使用移动应用程序对听到的幻听声音的情感色彩进行生态时刻评估，从而测量精神疾病的严重程度。

    

    幻觉是一种在实际外部感官刺激缺失时出现的想象感知。听觉幻觉是一种听到虚假声音的感知。听觉性幻觉是一种常见形式的听觉幻觉，指在没有任何说话者的情况下听到声音，通常出现在被诊断患有双相情感障碍和精神分裂症等精神疾病的人们中。评估幻听声音的情感色彩（即声音是负面的还是正面的）可以帮助测量精神疾病的严重程度。我们研究了435名体验幻听的个体，以评估听觉性幻觉。参与者通过一个移动应用程序，每天四次通过生态时刻评估回答四个答案等级的问题，向我们报告他们听到的声音的情感色彩，从“完全没有”到“极其”。我们将这些自我报告作为AVH事件的情感监督来收集。

    Hallucination is an apparent perception in the absence of real external sensory stimuli. An auditory hallucination is a perception of hearing sounds that are not real. A common form of auditory hallucination is hearing voices in the absence of any speakers which is known as Auditory Verbal Hallucination (AVH). AVH is fragments of the mind's creation that mostly occur in people diagnosed with mental illnesses such as bipolar disorder and schizophrenia. Assessing the valence of hallucinated voices (i.e., how negative or positive voices are) can help measure the severity of a mental illness. We study N=435 individuals, who experience hearing voices, to assess auditory verbal hallucination. Participants report the valence of voices they hear four times a day for a month through ecological momentary assessments with questions that have four answering scales from ``not at all'' to ``extremely''. We collect these self-reports as the valence supervision of AVH events via a mobile application. 
    
[^28]: 情感社交化人形智能系统

    Affective social anthropomorphic intelligent system. (arXiv:2304.11046v1 [cs.SD])

    [http://arxiv.org/abs/2304.11046](http://arxiv.org/abs/2304.11046)

    本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。

    

    人类的对话风格可以通过幽默感、个性和语调来衡量。这些特征已经成为对话智能虚拟助手的关键。然而，大多数最先进的智能虚拟助手（IVAs）无法解释人类声音的情感语义。本研究提出了一个人形智能系统，可以通过表达情感和个性来进行类人对话。同时，提出了一种语音风格转换方法，可以将特定情感的属性映射出来。首先，通过将时间音频波形数据转换为频域数据（Mel-Spectrogram），创建了离散的音频特征模式，如音符、音调、节奏、旋律等等。并使用一个外部CNN-Transformer-Encoder模型来预测声音中的七种不同的情感状态。同时，该模型将语音输入到一个RNN模型（Deep-speech）中，生成对音频的文本转录。然后，转录文本将通过一个transformer解码器与相应情感的响应一起产生。

    Human conversational styles are measured by the sense of humor, personality, and tone of voice. These characteristics have become essential for conversational intelligent virtual assistants. However, most of the state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret the affective semantics of human voices. This research proposes an anthropomorphic intelligent system that can hold a proper human-like conversation with emotion and personality. A voice style transfer method is also proposed to map the attributes of a specific emotion. Initially, the frequency domain data (Mel-Spectrogram) is created by converting the temporal audio wave data, which comprises discrete patterns for audio features such as notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used to predict seven different affective states from voice. The voice is also fed parallelly to the deep-speech, an RNN model that generates the text transcription from the spectrogram. Then t
    
[^29]: 扰动有助于降低投资风险吗？ 基于分离变分对抗训练的风险感知型股票推荐方法

    Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training. (arXiv:2304.11043v1 [q-fin.RM])

    [http://arxiv.org/abs/2304.11043](http://arxiv.org/abs/2304.11043)

    本文提出了一种基于分离变分对抗训练的风险感知型股票推荐方法，通过对抗性扰动提高模型对于风险的感知能力，通过变分扰动生成器模拟不同的风险因素并生成代表性的风险指标对抗样本。在真实股票数据上进行的实验表明该方法有效降低了投资风险同时保持高预期收益。

    

    在股票市场，成功的投资需要在利润和风险之间取得良好的平衡。最近，在量化投资中广泛研究了股票推荐，以为投资者选择具有更高收益率的股票。尽管在获利方面取得了成功，但大多数现有的推荐方法仍然在风险控制方面较弱，这可能导致实际股票投资中难以承受的亏损。为了有效降低风险，我们从对抗性扰动中获得启示，并提出了一种新的基于分离变分对抗训练（SVAT）框架的风险感知型股票推荐方法。本质上，SVAT鼓励模型对风险股票样本的对抗性扰动敏感，并通过学习扰动来增强模型的风险意识。为了生成代表性的风险指标对抗样本，我们设计了一个变分扰动生成器来模拟不同的风险因素。特别地，变分结构使我们的方法能够捕捉难以明确量化和建模的各种风险因素。在真实股票数据上的综合实验表明，SVAT在降低投资风险的同时保持高预期收益上非常有效。

    In the stock market, a successful investment requires a good balance between profits and risks. Recently, stock recommendation has been widely studied in quantitative investment to select stocks with higher return ratios for investors. Despite the success in making profits, most existing recommendation approaches are still weak in risk control, which may lead to intolerable paper losses in practical stock investing. To effectively reduce risks, we draw inspiration from adversarial perturbations and propose a novel Split Variational Adversarial Training (SVAT) framework for risk-aware stock recommendation. Essentially, SVAT encourages the model to be sensitive to adversarial perturbations of risky stock examples and enhances the model's risk awareness by learning from perturbations. To generate representative adversarial examples as risk indicators, we devise a variational perturbation generator to model diverse risk factors. Particularly, the variational architecture enables our method
    
[^30]: 无需反向传播的深度物理神经网络训练

    Backpropagation-free Training of Deep Physical Neural Networks. (arXiv:2304.11042v1 [cs.LG])

    [http://arxiv.org/abs/2304.11042](http://arxiv.org/abs/2304.11042)

    该论文提出了一种新方法来训练深度学习模型，不需要使用反向传播算法。该方法可以有效地应用于基于物理系统的深度学习。

    

    近年来，深度学习在诸如视觉和自然语言处理等各个领域取得了杰出的成功。这一成功很大程度上归功于深度学习模型的大规模，预计会不断增加。这种深度学习模型的增长伴随着与其可扩展性和训练、推理阶段中的能耗等问题相关的问题。虽然已经提出了一些基于非传统物理系统的工作来解决推理阶段的能效问题，但深度学习模型的有效训练仍未得到解决。迄今为止，数字深度学习模型的训练主要依赖于反向传播，但这种方法不适用于物理实现，因为它需要完全了解所谓前向传递的计算。在这里，我们通过提出一种简单的深度神经网络结构来解决这个问题。

    Recent years have witnessed the outstanding success of deep learning in various fields such as vision and natural language processing. This success is largely indebted to the massive size of deep learning models that is expected to increase unceasingly. This growth of the deep learning models is accompanied by issues related to their considerable energy consumption, both during the training and inference phases, as well as their scalability. Although a number of work based on unconventional physical systems have been proposed which addresses the issue of energy efficiency in the inference phase, efficient training of deep learning models has remained unaddressed. So far, training of digital deep learning models mainly relies on backpropagation, which is not suitable for physical implementation as it requires perfect knowledge of the computation performed in the so-called forward pass of the neural network. Here, we tackle this issue by proposing a simple deep neural network architectur
    
[^31]: 基于机器学习算法的口语情感识别

    Emotional Expression Detection in Spoken Language Employing Machine Learning Algorithms. (arXiv:2304.11040v1 [cs.SD])

    [http://arxiv.org/abs/2304.11040](http://arxiv.org/abs/2304.11040)

    通过使用MATLAB函数和机器学习算法，研究人员利用声音的特征来识别人类不同的情感，提高了机器学习模型的效率。

    

    人类的声音具有多种特征，如音高、音色、音量和嗓音。通过这些特征可以观察到人们在说话时使用不同的嗓音质量来表达情感。本研究的主要目标是使用多个MATLAB函数，如谱描述符、周期性和谐波，识别人类的不同情感，如愤怒、悲伤、恐惧、中立、厌恶、惊喜和快乐。为了完成这项工作，我们分析了人类语音的CREMA-D（众包情感多模态演员数据）和TESS（多伦多情感语音集）数据集。音频文件包含具有各种特征（如嘈杂、快速、缓慢）的数据，因此机器学习模型的效率显著提高。利用经验模态分解（EMD）进行信号分解的过程。然后，通过使用几个

    There are a variety of features of the human voice that can be classified as pitch, timbre, loudness, and vocal tone. It is observed in numerous incidents that human expresses their feelings using different vocal qualities when they are speaking. The primary objective of this research is to recognize different emotions of human beings such as anger, sadness, fear, neutrality, disgust, pleasant surprise, and happiness by using several MATLAB functions namely, spectral descriptors, periodicity, and harmonicity. To accomplish the work, we analyze the CREMA-D (Crowd-sourced Emotional Multimodal Actors Data) & TESS (Toronto Emotional Speech Set) datasets of human speech. The audio file contains data that have various characteristics (e.g., noisy, speedy, slow) thereby the efficiency of the ML (Machine Learning) models increases significantly. The EMD (Empirical Mode Decomposition) is utilized for the process of signal decomposition. Then, the features are extracted through the use of severa
    
[^32]: 预测中的外在数据：一种用于关联评估的FARM方法

    Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation. (arXiv:2304.11028v1 [eess.SP])

    [http://arxiv.org/abs/2304.11028](http://arxiv.org/abs/2304.11028)

    该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。

    

    外在数据被认为在提高预测准确性方面起着关键作用。针对恰当的选择，全面的相关性分析是一个基本的第一步，从外在数据与参考时间序列的相似性开始。受现有时间序列相似性指标的启发，我们介绍了一种名为FARM（前向角相关度量）的新方法，能够有效地处理实时数据流。我们的前向方法依赖于一种角度特征，该特征利用后续数据点的变化比较来对齐经过时间变形的序列。所提出的算法结合了本地和全局指标，提供了一个平衡的相关性度量。这导致将部分、中间匹配也视为外在数据序列重要指标的考虑因素。作为第一步验证，我们介绍了我们的FARM方法对合成但具有代表性的信号和真实世界时间序列记录的应用。同时展示了FARM方法提高了预测准确度的结果。

    Exogenous data is believed to play a key role for increasing forecasting accuracy. For an appropriate selection, a throughout relevance analysis is a fundamental first step, starting from the exogenous data similarity with the reference time series. Inspired by existing metrics for time series similarity, we introduce a new approach named FARM - Forward Angular Relevance Measure, able to effectively deal with real-time data streams. Our forward method relies on an angular feature that compares changes in subsequent data points to align time-warped series in an efficient way. The proposed algorithm combines local and global measures to provide a balanced relevance measure. This results in considering also partial, intermediate matches as relevant indicators for exogenous data series significance. As a first validation step, we present the application of our FARM approach to both synthetic but representative signals and real-world time series recordings. While demonstrating the improved 
    
[^33]: 通过贝叶斯主动学习实现自校正贝叶斯优化

    Self-Correcting Bayesian Optimization through Bayesian Active Learning. (arXiv:2304.11005v1 [cs.LG])

    [http://arxiv.org/abs/2304.11005](http://arxiv.org/abs/2304.11005)

    该论文提出了SAL和SCoreBO两种方法，用于提高高斯过程模型的超参数选择和贝叶斯优化的表现。

    

    高斯过程已成为贝叶斯优化和主动学习中的首选模型。然而，高斯过程的完全发挥需要巧妙选择超参数，而在文献中很少有关于找到正确超参数的努力。我们演示了选择好的超参数对于高斯过程的影响，并提出了两个明确优先考虑此目标的收购函数。统计距离主动学习（SAL）考虑后验样本的平均不一致性，由统计距离测量。结果显示，在许多测试函数上，它胜过了贝叶斯主动学习的最新结果。然后，我们引入了自校正贝叶斯优化（SCoreBO），它将SAL扩展到同时执行贝叶斯优化和主动超参数学习。相比传统BO，SCoreBO以改进的速度学习模型超参数，同时在最新的贝叶斯优化搜索中取得更好的表现。

    Gaussian processes are cemented as the model of choice in Bayesian optimization and active learning. Yet, they are severely dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding the right hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize this goal. Statistical distance-based Active Learning (SAL) considers the average disagreement among samples from the posterior, as measured by a statistical distance. It is shown to outperform the state-of-the-art in Bayesian active learning on a number of test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active hyperparameter learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization met
    
[^34]: 基于理想联合分类器假设的知识蒸馏

    Knowledge Distillation Under Ideal Joint Classifier Assumption. (arXiv:2304.11004v1 [cs.LG])

    [http://arxiv.org/abs/2304.11004](http://arxiv.org/abs/2304.11004)

    本文提出了基于理想联合分类器假设的知识蒸馏框架，可以提供清晰全面的理解和为未来研究提供理论基础，使得教师和学生网络之间的知识传递更加高效。

    

    知识蒸馏是一种将大型神经网络压缩为更高效小型网络的强大技术。Softmax回归表征学习是一种常用的方法，它使用预先训练的教师网络来指导更小的学生网络的学习。尽管有几项研究探讨了Softmax回归表征学习的有效性，但提供知识转移的基础机制尚不够清楚。本文提出了理想联合分类器知识蒸馏（IJCKD），这是一个统一的框架，旨在为现有的知识蒸馏方法提供清晰全面的理解和为未来研究提供理论基础。我们使用从领域适应理论推导出的数学技术，提供了学生网络误差界的详细分析，其作为教师的函数关系。我们的框架可以在深度学习中应用于各种应用，包括图像识别和自然语言处理。

    Knowledge distillation is a powerful technique to compress large neural networks into smaller, more efficient networks. Softmax regression representation learning is a popular approach that uses a pre-trained teacher network to guide the learning of a smaller student network. While several studies explored the effectiveness of softmax regression representation learning, the underlying mechanism that provides knowledge transfer is not well understood. This paper presents Ideal Joint Classifier Knowledge Distillation (IJCKD), a unified framework that provides a clear and comprehensive understanding of the existing knowledge distillation methods and a theoretical foundation for future research. Using mathematical techniques derived from a theory of domain adaptation, we provide a detailed analysis of the student network's error bound as a function of the teacher. Our framework enables efficient knowledge transfer between teacher and student networks and can be applied to various applicati
    
[^35]: 平衡模拟推断，得到保守的后验分布

    Balancing Simulation-based Inference for Conservative Posteriors. (arXiv:2304.10978v1 [stat.ML])

    [http://arxiv.org/abs/2304.10978](http://arxiv.org/abs/2304.10978)

    本研究将平衡技术扩展到后验密度算法，提出了神经后验估计和对比神经比率估计的平衡版本，可有效缓解保守推断问题。

    

    保守推断是模拟推断中的一个重要问题。已经证明常用算法可能会产生过于自信的后验分布。实验证明，平衡可以有效缓解这个问题，但其应用仍限于神经比率估计。在这项工作中，我们将平衡扩展到提供后验密度的任何算法。特别地，我们引入了神经后验估计和对比神经比率估计的平衡版本。实验表明，平衡版本倾向于在广泛的基准测试上产生保守的后验分布逼近。此外，我们提供了平衡条件的另一种解释，即$ \chi^2$ 隔离度。

    Conservative inference is a major concern in simulation-based inference. It has been shown that commonly used algorithms can produce overconfident posterior approximations. Balancing has empirically proven to be an effective way to mitigate this issue. However, its application remains limited to neural ratio estimation. In this work, we extend balancing to any algorithm that provides a posterior density. In particular, we introduce a balanced version of both neural posterior estimation and contrastive neural ratio estimation. We show empirically that the balanced versions tend to produce conservative posterior approximations on a wide variety of benchmarks. In addition, we provide an alternative interpretation of the balancing condition in terms of the $\chi^2$ divergence.
    
[^36]: LEIA：语言嵌入用于情感识别

    LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])

    [http://arxiv.org/abs/2304.10973](http://arxiv.org/abs/2304.10973)

    该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。

    

    社交媒体产生了大量文本数据，使得使用语言模型分析情感变得更加容易。这些模型通常在由读者生成的小型而昂贵的文本注释数据集上进行训练，这些读者猜测社交媒体帖子中表达的情感。这影响了情感识别方法的质量，因为存在训练数据大小限制和用于模型开发的标签生产中的噪声。我们提出了LEIA，这是一种文本情感识别模型，它基于由超过6百万个帖子组成的数据集进行训练，其中这些帖子具有自注释的情感标签，包括快乐、亲情、悲伤、愤怒和恐惧。LEIA基于一种掩蔽单词的方法，增强了模型预训练过程中对情感单词的学习。LEIA在三个测试数据集上实现了约73的宏F1值，优于其他监督和无监督方法，并在强基准测试中表现出LEIA可以概括不同的帖子、用户和时间段。

    The wealth of text data generated by social media has enabled new kinds of analysis of emotions with language models. These models are often trained on small and costly datasets of text annotations produced by readers who guess the emotions expressed by others in social media posts. This affects the quality of emotion identification methods due to training data size limitations and noise in the production of labels used in model development. We present LEIA, a model for emotion identification in text that has been trained on a dataset of more than 6 million posts with self-annotated emotion labels for happiness, affection, sadness, anger, and fear. LEIA is based on a word masking method that enhances the learning of emotion words during model pre-training. LEIA achieves macro-F1 values of approximately 73 on three in-domain test datasets, outperforming other supervised and unsupervised methods in a strong benchmark that shows that LEIA generalizes across posts, users, and time periods.
    
[^37]: 基于不完整张量Tucker分解的交通速度预测方法

    An Incomplete Tensor Tucker decomposition based Traffic Speed Prediction Method. (arXiv:2304.10961v1 [cs.LG])

    [http://arxiv.org/abs/2304.10961](http://arxiv.org/abs/2304.10961)

    本研究提出了一种基于Tucker分解模型的交通速度预测方法，通过融合PID控制器实现更快的收敛速度和更好的恢复精度。

    

    在智能交通系统中，缺失数据是比较常见和不可避免的情况。而完整和有效的交通速度数据对于智能交通系统非常重要。潜变量分解张量模型是解决缺失交通数据恢复问题最有吸引力的方法之一，因为它的可扩展性。该模型通常通过随机梯度下降(SGD)求解器实现优化，但基于SGD求解的潜变量分解张量模型收敛速度较慢。为了解决这个问题，本文将比例积分微分(PID)控制器的独特优势融入Tucker分解的潜变量分解张量模型中。它采用了两个思想：a)采用Tucker分解构建一个用于实现更好的恢复精度的潜变量分解张量模型。b)基于PID控制理论的调整实例误差融入SGD求解器中，从而有效提高收敛速度。我们在两个主要城市交通道路速度数据集上进行的实验研究表明，本文提出的PID控制器Tucker分解模型具有更好的性能表现。

    In intelligent transport systems, it is common and inevitable with missing data. While complete and valid traffic speed data is of great importance to intelligent transportation systems. A latent factorization-of-tensors (LFT) model is one of the most attractive approaches to solve missing traffic data recovery due to its well-scalability. A LFT model achieves optimization usually via a stochastic gradient descent (SGD) solver, however, the SGD-based LFT suffers from slow convergence. To deal with this issue, this work integrates the unique advantages of the proportional-integral-derivative (PID) controller into a Tucker decomposition based LFT model. It adopts two-fold ideas: a) adopting tucker decomposition to build a LFT model for achieving a better recovery accuracy. b) taking the adjusted instance error based on the PID control theory into the SGD solver to effectively improve convergence rate. Our experimental studies on two major city traffic road speed datasets show that the pr
    
[^38]: 强化学习中的三次正则化策略牛顿算法

    A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning. (arXiv:2304.10951v1 [cs.LG])

    [http://arxiv.org/abs/2304.10951](http://arxiv.org/abs/2304.10951)

    本文提出了两种三次正则化策略牛顿算法，其使用似然比方法形成价值函数梯度和黑塞矩阵的估计。我们证明了算法收敛到价值函数的二阶稳定点，从而避免了类型为鞍点的陷阱。

    

    本文研究了在没有模型信息的强化学习（RL）环境下的控制问题。针对这个问题，我们提出了两种策略牛顿算法，其中包含了三次正则化。这两种算法采用似然比方法使用样本轨迹形成价值函数梯度和黑塞矩阵的估计。第一种算法在每次迭代中需要三次正则化问题的精确解，而第二种算法则使用了一种高效的梯度下降近似方法。我们证明了所提出的算法收敛到价值函数的二阶稳定点（SOSP），从而避免了类型为鞍点的陷阱。特别地，我们的算法的样本复杂度为$\epsilon$

    We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an $\epsilon$
    
[^39]: CancerGPT: 基于LLMs的极少样本药物对协同作用预测技术

    CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models. (arXiv:2304.10946v1 [cs.CL])

    [http://arxiv.org/abs/2304.10946](http://arxiv.org/abs/2304.10946)

    CancerGPT 是一种基于LLMs的少样本学习技术，可在生物学推断中预测罕见组织中的药物对协同作用。实验表明该技术准确性高，即使在样本数据非常有限的情况下仍可进行预测。

    

    大型预训练语言模型（LLMs）在许多领域中具有显着的远程监控潜力，即使只有极少量的训练数据。但是，它们在更复杂的领域，如生物学领域中对未见过的任务的泛化能力尚未得到充分评估。 LLM可以提供一种有前途的替代方法，特别是在结构化数据和样本大小有限的情况下，通过从文本语料库中提取先验知识。 我们提出了一种基于LLMs的少样本学习方法，用于预测缺乏结构化数据和特征的罕见组织中药物对的协同作用。 实验涉及来自不同癌症类型的七种罕见组织，表明基于LLMs的预测模型在非常少或零样本的情况下也能取得显着的准确性。我们提出的模型CancerGPT（具有$\sim 124M$参数）甚至可以与更大的微调GPT-3模型（具有$\sim 175B$参数）相媲美。我们的研究是第一个利用LLMs进行少样本学习的案例，为生物学推断提供了一种有前途的替代方法。

    Large pre-trained language models (LLMs) have been shown to have significant potential in few-shot learning across various fields, even with minimal training data. However, their ability to generalize to unseen tasks in more complex fields, such as biology, has yet to be fully evaluated. LLMs can offer a promising alternative approach for biological inference, particularly in cases where structured data and sample size are limited, by extracting prior knowledge from text corpora. Our proposed few-shot learning approach uses LLMs to predict the synergy of drug pairs in rare tissues that lack structured data and features. Our experiments, which involved seven rare tissues from different cancer types, demonstrated that the LLM-based prediction model achieved significant accuracy with very few or zero samples. Our proposed model, the CancerGPT (with $\sim$ 124M parameters), was even comparable to the larger fine-tuned GPT-3 model (with $\sim$ 175B parameters). Our research is the first to 
    
[^40]: 图注意力网络中可学习参数的梯度推导

    Gradient Derivation for Learnable Parameters in Graph Attention Networks. (arXiv:2304.10939v1 [cs.LG])

    [http://arxiv.org/abs/2304.10939](http://arxiv.org/abs/2304.10939)

    本文对GATv2的可训练模型参数的梯度进行了全面推导，在不同的数据集上实现的性能表现不一致的原因仍然是一个开放的研究问题。

    

    本文对图注意力网络（GAT）的广泛实现之一——GATv2的可训练模型参数的梯度进行了全面的推导。虽然GAT已被证明是处理图结构数据的强大框架，但是在不同数据集上实现的性能表现不一致，其原因仍然是一个开放的研究问题。由于梯度流为统计学习模型的训练动态提供了有价值的洞见，因此本文推导了GATv2的可训练模型参数的梯度。这些梯度推导补充了[2]的工作，后者调查了GATv2的潜在陷阱。

    This work provides a comprehensive derivation of the parameter gradients for GATv2 [4], a widely used implementation of Graph Attention Networks (GATs). GATs have proven to be powerful frameworks for processing graph-structured data and, hence, have been used in a range of applications. However, the achieved performance by these attempts has been found to be inconsistent across different datasets and the reasons for this remains an open research question. As the gradient flow provides valuable insights into the training dynamics of statistically learning models, this work obtains the gradients for the trainable model parameters of GATv2. The gradient derivations supplement the efforts of [2], where potential pitfalls of GATv2 are investigated.
    
[^41]: 色彩中的自注意力：transformer中图结构编码的另一种方法

    Self-Attention in Colors: Another Take on Encoding Graph Structure in Transformers. (arXiv:2304.10933v1 [cs.LG])

    [http://arxiv.org/abs/2304.10933](http://arxiv.org/abs/2304.10933)

    该论文提出了一种新的自注意机制CSA（色彩自注意力），可以将原始边特征富化以及相对位置编码方案来灵活的编码图结构，并在ZINC基准数据集上取得了最先进的结果。

    

    我们引入了一种称为CSA（色彩自注意力）的新型自注意机制，将注意力分数的概念扩展到注意力过滤器上，独立调制特征通道。我们在完全注意力的图形Transformer CGT（色彩图形Transformer）中展示了CSA，通过富化原始边特征以及相对位置编码方案，完全绕过了本地消息传递组件的需求，通过节点之间的相互作用灵活地编码图结构。我们提出了一种基于随机游走的新方案，可以编码结构和位置信息，并展示如何纳入更高阶的拓扑信息，例如分子图中的环。我们的方法在ZINC基准数据集上取得了最先进的结果，同时为编码图结构和纳入更高阶的拓扑结构提供了一个灵活的框架。

    We introduce a novel self-attention mechanism, which we call CSA (Chromatic Self-Attention), which extends the notion of attention scores to attention _filters_, independently modulating the feature channels. We showcase CSA in a fully-attentional graph Transformer CGT (Chromatic Graph Transformer) which integrates both graph structural information and edge features, completely bypassing the need for local message-passing components. Our method flexibly encodes graph structure through node-node interactions, by enriching the original edge features with a relative positional encoding scheme. We propose a new scheme based on random walks that encodes both structural and positional information, and show how to incorporate higher-order topological information, such as rings in molecular graphs. Our approach achieves state-of-the-art results on the ZINC benchmark dataset, while providing a flexible framework for encoding graph structure and incorporating higher-order topology.
    
[^42]: 基于物理插值的水网泄漏定位中的字典学习

    Learning Dictionaries from Physical-Based Interpolation for Water Network Leak Localization. (arXiv:2304.10932v1 [eess.SY])

    [http://arxiv.org/abs/2304.10932](http://arxiv.org/abs/2304.10932)

    本文提出一种基于物理插值和字典学习的泄漏定位方法，应用于Modena案例得到了优于现有技术的结果。

    

    本文介绍了一种基于状态估计和学习的泄漏定位方法。第一个阶段由插值方案处理，第二个阶段考虑字典学习。新提出的插值技术利用了水力连接的物理学原理，连接相邻节点的液压头。另外，残差直接被插值而不是液压头值。将所提出的方法应用于一个著名案例(Modena)，结果表明，新的插值方法在插值误差(考虑状态和残差估计)和后验定位方面都优于现有技术。

    This article presents a leak localization methodology based on state estimation and learning. The first is handled by an interpolation scheme, whereas dictionary learning is considered for the second stage. The novel proposed interpolation technique exploits the physics of the interconnections between hydraulic heads of neighboring nodes in water distribution networks. Additionally, residuals are directly interpolated instead of hydraulic head values. The results of applying the proposed method to a well-known case study (Modena) demonstrated the improvements of the new interpolation method with respect to a state-of-the-art approach, both in terms of interpolation error (considering state and residual estimation) and posterior localization.
    
[^43]: 自监督对抗仿真学习

    Self-Supervised Adversarial Imitation Learning. (arXiv:2304.10914v1 [cs.LG])

    [http://arxiv.org/abs/2304.10914](http://arxiv.org/abs/2304.10914)

    本文介绍了一种解决自我监督模型陷入坏局部最小值的方法，即通过将鉴别器纳入模型，不需要人工干预，帮助学习，并解决了常见的学习问题。

    

    行为克隆是一种通过专家演示来教授智能体如何行为的仿真学习技术。最近的方法使用自我监督的完全可观察未标记状态的快照来将状态对解码为动作。然而，这些技术采用的迭代学习方案容易陷入坏的局部最小值。先前的工作使用目标感知策略来解决这个问题。然而，这需要人工介入来验证智能体是否达到了目标。我们通过将鉴别器纳入原始框架来解决这个限制，提供了两个关键优势，并直接解决了以前的一个学习问题。首先，它不需要人工干预。其次，它通过指导基于专家轨迹的状态转换的函数逼近来帮助学习。第三，鉴别器解决了策略模型常见的学习问题，即有时会执行“无动作”。

    Behavioural cloning is an imitation learning technique that teaches an agent how to behave via expert demonstrations. Recent approaches use self-supervision of fully-observable unlabelled snapshots of the states to decode state pairs into actions. However, the iterative learning scheme employed by these techniques is prone to get trapped into bad local minima. Previous work uses goal-aware strategies to solve this issue. However, this requires manual intervention to verify whether an agent has reached its goal. We address this limitation by incorporating a discriminator into the original framework, offering two key advantages and directly solving a learning problem previous work had. First, it disposes of the manual intervention requirement. Second, it helps in learning by guiding function approximation based on the state transition of the expert's trajectories. Third, the discriminator solves a learning issue commonly present in the policy model, which is to sometimes perform a `no ac
    
[^44]: MIMIC-III和MIMIC-IV上的自动化医疗编码：一项关键回顾和可复制性研究

    Automated Medical Coding on MIMIC-III and MIMIC-IV: A Critical Review and Replicability Study. (arXiv:2304.10909v1 [cs.LG])

    [http://arxiv.org/abs/2304.10909](http://arxiv.org/abs/2304.10909)

    本文探究了在MIMIC-III和MIMIC-IV上进行自动化医疗编码的最新机器学习模型，并发现了这些模型的局限性和不足之处。我们提出了一种改进方法，该方法可以更好地评估系统性能，并公开了我们的代码和数据集。

    

    医疗编码是将医学代码分配给临床自由文档的任务。医疗专业人士手动分配这些代码以跟踪患者的诊断和治疗。自动化医疗编码可以极大地减轻这种行政负担。本文重现、比较和分析了最先进的自动化医疗编码机器学习模型。我们显示出多个模型表现不佳，原因是配置弱、训练-测试拆分样本不足以及评估不充分。在以往的工作中，宏平均F1分数被计算出亚优的结果，并且我们的修正使其翻倍。我们采用分层抽样和相同的实验设置进行了修订的模型比较，包括超参数和决策边界调整。我们分析预测误差来验证和证伪以前的工作假设。分析证实，所有模型都难以处理稀有的代码，而长文档仅对结果有微不足道的影响。最后，我们提出了一种基于流行病学采样的改进，该方法可以更好地评估系统的性能，并公开了我们的代码和数据集。

    Medical coding is the task of assigning medical codes to clinical free-text documentation. Healthcare professionals manually assign such codes to track patient diagnoses and treatments. Automated medical coding can considerably alleviate this administrative burden. In this paper, we reproduce, compare, and analyze state-of-the-art automated medical coding machine learning models. We show that several models underperform due to weak configurations, poorly sampled train-test splits, and insufficient evaluation. In previous work, the macro F1 score has been calculated sub-optimally, and our correction doubles it. We contribute a revised model comparison using stratified sampling and identical experimental setups, including hyperparameters and decision boundary tuning. We analyze prediction errors to validate and falsify assumptions of previous works. The analysis confirms that all models struggle with rare codes, while long documents only have a negligible impact. Finally, we present the 
    
[^45]: 分布式PL非凸最小化极小问题的近似最优去中心化动量法

    Near-Optimal Decentralized Momentum Method for Nonconvex-PL Minimax Problems. (arXiv:2304.10902v1 [math.OC])

    [http://arxiv.org/abs/2304.10902](http://arxiv.org/abs/2304.10902)

    提出一种高效的去中心化动量法（DM-GDA），用于分布式非凸PL极小化极小优化，能够同时使用动量和随机梯度估计，解决了现有分布式极小最大化优化方法在实践中使用受限的问题。

    

    最小最大化优化在许多机器学习任务中扮演着重要角色，如生成式对抗网络（GANs）和对抗性训练。本文提出了一种高效的去中心化动量梯度下降上升法（DM-GDA）方法，用于分布式非凸PL极小化极小优化。

    Minimax optimization plays an important role in many machine learning tasks such as generative adversarial networks (GANs) and adversarial training. Although recently a wide variety of optimization methods have been proposed to solve the minimax problems, most of them ignore the distributed setting where the data is distributed on multiple workers. Meanwhile, the existing decentralized minimax optimization methods rely on the strictly assumptions such as (strongly) concavity and variational inequality conditions. In the paper, thus, we propose an efficient decentralized momentum-based gradient descent ascent (DM-GDA) method for the distributed nonconvex-PL minimax optimization, which is nonconvex in primal variable and is nonconcave in dual variable and satisfies the Polyak-Lojasiewicz (PL) condition. In particular, our DM-GDA method simultaneously uses the momentum-based techniques to update variables and estimate the stochastic gradients. Moreover, we provide a solid convergence anal
    
[^46]: GCNH：一种用于异构图上表示学习的简单方法

    GCNH: A Simple Method For Representation Learning On Heterophilous Graphs. (arXiv:2304.10896v1 [cs.LG])

    [http://arxiv.org/abs/2304.10896](http://arxiv.org/abs/2304.10896)

    本文提出了一种简单而有效的GNN架构GCNH，适用于异构和同质情况，并通过学习重要系数来平衡中心节点和邻域的贡献。

    

    图神经网络（GNN）很适合在同质图上学习，即在这种图中，边往往连接同一类型的节点。然而，在异构图上实现一致的GNN性能仍然是一个开放的研究问题。最近的研究提出了扩展标准GNN架构的方法，以改善在异构图上的性能，但是这些模型无法捕捉到基本的图形属性，例如邻居标签分布，这是学习的基础。在这项工作中，我们提出了GCN for Heterophily（GCNH），这是一种简单但有效的GNN架构，适用于异构和同质情况。GCNH学习并组合了节点和其邻居的分离表示，使用每层学习的一个重要系数来平衡中心节点和邻域的贡献。我们在八个真实世界的图和一组人造图上进行了广泛的实验。

    Graph Neural Networks (GNNs) are well-suited for learning on homophilous graphs, i.e., graphs in which edges tend to connect nodes of the same type. Yet, achievement of consistent GNN performance on heterophilous graphs remains an open research problem. Recent works have proposed extensions to standard GNN architectures to improve performance on heterophilous graphs, trading off model simplicity for prediction accuracy. However, these models fail to capture basic graph properties, such as neighborhood label distribution, which are fundamental for learning. In this work, we propose GCN for Heterophily (GCNH), a simple yet effective GNN architecture applicable to both heterophilous and homophilous scenarios. GCNH learns and combines separate representations for a node and its neighbors, using one learned importance coefficient per layer to balance the contributions of center nodes and neighborhoods. We conduct extensive experiments on eight real-world graphs and a set of synthetic graphs
    
[^47]: 协调推理服务系统的高准确性、成本效益和低延迟

    Reconciling High Accuracy, Cost-Efficiency, and Low Latency of Inference Serving Systems. (arXiv:2304.10892v1 [cs.LG])

    [http://arxiv.org/abs/2304.10892](http://arxiv.org/abs/2304.10892)

    InfAdapter提出了一个解决高准确性、低延迟和成本效益之间权衡问题的方法，通过主动选择一组带有资源分配的 ML 模型变体来满足延迟 SLO，并最大化由准确性和成本组成的目标函数，相较于其他方法降低了 SLO 违规和成本。

    

    机器学习（ML）推理服务的使用正在急剧增加。ML推理服务与用户直接交互，需要快速准确的响应。此外，这些服务面临不断变化的请求工作负载，需要调整其计算资源。计算资源不合理会导致延迟服务级别目标 (SLOs) 违规或浪费计算资源。考虑准确性、延迟和资源成本等方面的所有因素来适应动态工作负载具有挑战性。为了应对这些挑战，我们提出了 InfAdapter，它会主动选择一组带有资源分配的 ML 模型变体，以满足延迟 SLO，并最大化由准确性和成本组成的目标函数。相较于流行的行业自动缩放器 (Kubernetes Vertical Pod Autoscaler)，InfAdapter 分别降低了 SLO 违规和成本达 65% 和 33%。

    The use of machine learning (ML) inference for various applications is growing drastically. ML inference services engage with users directly, requiring fast and accurate responses. Moreover, these services face dynamic workloads of requests, imposing changes in their computing resources. Failing to right-size computing resources results in either latency service level objectives (SLOs) violations or wasted computing resources. Adapting to dynamic workloads considering all the pillars of accuracy, latency, and resource cost is challenging. In response to these challenges, we propose InfAdapter, which proactively selects a set of ML model variants with their resource allocations to meet latency SLO while maximizing an objective function composed of accuracy and cost. InfAdapter decreases SLO violation and costs up to 65% and 33%, respectively, compared to a popular industry autoscaler (Kubernetes Vertical Pod Autoscaler).
    
[^48]: 自动驾驶中基于Transformer的模型及其硬件加速分析：综述 (arXiv:2304.10891v1 [cs.LG])

    Transformer-based models and hardware acceleration analysis in autonomous driving: A survey. (arXiv:2304.10891v1 [cs.LG])

    [http://arxiv.org/abs/2304.10891](http://arxiv.org/abs/2304.10891)

    本文综述了基于Transformer的模型在自动驾驶中的应用，探讨了不同体系结构和运算符的优缺点，重点讨论了针对便携计算平台的硬件加速方案，并对卷积神经网络和Transformer的层进行了对比。

    

    近年来，Transformer架构在各种自动驾驶应用中表现出了很好的性能。另一方面，将其专门用于便携式计算平台的硬件加速已成为实际部署在真实自动汽车中的下一步关键步骤。本综述论文提供了针对自动驾驶任务的基于Transformer的模型的全面概述、基准和分析，例如车道检测、分割、跟踪、规划和决策制定。我们审查了不同的体系结构，用于组织Transformer的输入和输出，例如编码器-解码器和仅编码器结构，并探讨了它们各自的优缺点。此外，我们深入讨论了Transformer相关的运算符及其硬件加速方案，考虑到关键因素，如量化和运行时。我们特别在移动和桌面平台上对卷积神经网络的层与基于Transformer的模型的运算符进行了对比。总的来说，本综述论文为研究人员和从业者提供了系统的指南，以了解基于Transformer的模型及其在自动驾驶中的硬件加速的当前进展和挑战。

    Transformer architectures have exhibited promising performance in various autonomous driving applications in recent years. On the other hand, its dedicated hardware acceleration on portable computational platforms has become the next critical step for practical deployment in real autonomous vehicles. This survey paper provides a comprehensive overview, benchmark, and analysis of Transformer-based models specifically tailored for autonomous driving tasks such as lane detection, segmentation, tracking, planning, and decision-making. We review different architectures for organizing Transformer inputs and outputs, such as encoder-decoder and encoder-only structures, and explore their respective advantages and disadvantages. Furthermore, we discuss Transformer-related operators and their hardware acceleration schemes in depth, taking into account key factors such as quantization and runtime. We specifically illustrate the operator level comparison between layers from convolutional neural ne
    
[^49]: 量子启发的生成模型在小分子数据集上的应用

    Application of quantum-inspired generative models to small molecular datasets. (arXiv:2304.10867v1 [quant-ph])

    [http://arxiv.org/abs/2304.10867](http://arxiv.org/abs/2304.10867)

    本文基于张量网络的生成模型应用于小分子数据集，并比较了不同模型之间的性能，旨在实现从这些技术中获得真实世界量子优势的有前途方向。

    

    随着量子计算的普及，量子和量子启发式机器学习已成为一个有前途且具具有挑战性的研究领域。理论上的贡献指向生成建模作为实现从这些技术中获得真实世界量子优势的有前途方向。一些实证研究也证明了这种潜力，尤其是当考虑基于张量网络的量子启发式模型时。在本文中，我们将基于张量网络的生成模型应用于分子发现问题。在我们的方法中，我们利用了两个小型分子数据集：QM9数据集中的4989个分子的子集和TotalEnergies中的516个验证抗氧化剂的小型数据集。我们采用不同的基于采样的度量标准比较了几种张量网络模型和一个生成对抗网络，这些标准反映了它们在每个任务上的学习性能和多目标性能。

    Quantum and quantum-inspired machine learning has emerged as a promising and challenging research field due to the increased popularity of quantum computing, especially with near-term devices. Theoretical contributions point toward generative modeling as a promising direction to realize the first examples of real-world quantum advantages from these technologies. A few empirical studies also demonstrate such potential, especially when considering quantum-inspired models based on tensor networks. In this work, we apply tensor-network-based generative models to the problem of molecular discovery. In our approach, we utilize two small molecular datasets: a subset of $4989$ molecules from the QM9 dataset and a small in-house dataset of $516$ validated antioxidants from TotalEnergies. We compare several tensor network models against a generative adversarial network using different sample-based metrics, which reflect their learning performances on each task, and multiobjective performances us
    
[^50]: 论探索对实际学习算法的重要性

    On the Importance of Exploration for Real Life Learned Algorithms. (arXiv:2304.10860v1 [cs.LG])

    [http://arxiv.org/abs/2304.10860](http://arxiv.org/abs/2304.10860)

    本文研究探索对实际学习算法的重要性并使用不同策略的深度Q网络解决了URLLC信息的传输问题，证明了自适应探索方法的有效性。

    

    数据驱动的学习算法的质量与可用数据的质量显著相关。生成好的数据的最简单方式之一是智能地对数据源进行采样或探索。智能采样可以降低获取样本的成本，减少学习过程中的计算成本，并使学习算法能够适应未预料到的事件。在本文中，我们使用不同探索策略教授了三个深度Q网络（DQN）来解决URLLC信息的打孔传输问题。我们证明了两种自适应探索候选方法（基于方差和基于最大熵的探索）相对于标准的简单epsilon-greedy探索方法的效率。

    The quality of data driven learning algorithms scales significantly with the quality of data available. One of the most straight-forward ways to generate good data is to sample or explore the data source intelligently. Smart sampling can reduce the cost of gaining samples, reduce computation cost in learning, and enable the learning algorithm to adapt to unforeseen events. In this paper, we teach three Deep Q-Networks (DQN) with different exploration strategies to solve a problem of puncturing ongoing transmissions for URLLC messages. We demonstrate the efficiency of two adaptive exploration candidates, variance-based and Maximum Entropy-based exploration, compared to the standard, simple epsilon-greedy exploration approach.
    
[^51]: SequeL: 一个基于PyTorch和JAX的持续学习库

    SequeL: A Continual Learning Library in PyTorch and JAX. (arXiv:2304.10857v1 [cs.LG])

    [http://arxiv.org/abs/2304.10857](http://arxiv.org/abs/2304.10857)

    SequeL是一个基于Pytorch和JAX的持续学习库，为各种持续学习算法提供统一接口，并具有模块化和简单性。能够帮助机器学习领域的研究人员和开发者轻松扩展自己的应用。

    

    持续学习是机器学习中一个重要且具有挑战性的问题，模型必须适应连续的新数据流而不会忘记先前获得的知识。现有框架基于PyTorch构建，但JAX的日益流行可能导致不同的代码库，最终阻碍了可重复性和进展。为了解决这个问题，我们介绍了SequeL，它是一个灵活且可扩展的持续学习库，支持PyTorch和JAX框架。SequeL为各种持续学习算法提供统一的接口，包括基于正则化的方法、基于回放的方法和混合方法。该库设计具有模块化和简单性，使API适合研究人员和实践者使用。我们将SequeL作为开源库发布，使研究人员和开发人员能够轻松地实验和扩展该库以适应自己的目的。

    Continual Learning is an important and challenging problem in machine learning, where models must adapt to a continuous stream of new data without forgetting previously acquired knowledge. While existing frameworks are built on PyTorch, the rising popularity of JAX might lead to divergent codebases, ultimately hindering reproducibility and progress. To address this problem, we introduce SequeL, a flexible and extensible library for Continual Learning that supports both PyTorch and JAX frameworks. SequeL provides a unified interface for a wide range of Continual Learning algorithms, including regularization-based approaches, replay-based approaches, and hybrid approaches. The library is designed towards modularity and simplicity, making the API suitable for both researchers and practitioners. We release SequeL\footnote{\url{https://github.com/nik-dim/sequel}} as an open-source library, enabling researchers and developers to easily experiment and extend the library for their own purposes
    
[^52]: GNNs到底在学什么？——理解它们的表示方法

    What Do GNNs Actually Learn? Towards Understanding their Representations. (arXiv:2304.10851v1 [cs.LG])

    [http://arxiv.org/abs/2304.10851](http://arxiv.org/abs/2304.10851)

    本文研究了四种GNN模型，指出其中两种将所有节点嵌入同一特征向量中，而另外两种模型生成的表示与输入图中的步长数量相关。在一定条件下，不同结构的节点可能有相似的表示。

    

    最近几年，图神经网络（GNNs）在图嵌入学习领域取得了巨大成功。尽管以往的研究揭示了这些模型的表达能力（即它们是否能区分非同构图对），但仍不清楚这些模型所学习的节点表示中编码了哪些结构信息。本文研究了四种流行的GNN模型，并展示了其中两种将所有节点嵌入同一特征向量中，而另外两种模型生成的表示与输入图中的步长数量相关。令人惊讶的是，如果两个不同结构的节点在某一层$k>1$ 中的步长相同，则它们的表示可能相似。我们在真实数据集上进行了实证验证，从而验证了我们的理论发现。

    In recent years, graph neural networks (GNNs) have achieved great success in the field of graph representation learning. Although prior work has shed light into the expressiveness of those models (\ie whether they can distinguish pairs of non-isomorphic graphs), it is still not clear what structural information is encoded into the node representations that are learned by those models. In this paper, we investigate which properties of graphs are captured purely by these models, when no node attributes are available. Specifically, we study four popular GNN models, and we show that two of them embed all nodes into the same feature vector, while the other two models generate representations that are related to the number of walks over the input graph. Strikingly, structurally dissimilar nodes can have similar representations at some layer $k>1$, if they have the same number of walks of length $k$. We empirically verify our theoretical findings on real datasets.
    
[^53]: 一种加速有限元求解器中代数多重网格方法的深度学习算法

    A Deep Learning algorithm to accelerate Algebraic Multigrid methods in Finite Element solvers of 3D elliptic PDEs. (arXiv:2304.10832v1 [math.NA])

    [http://arxiv.org/abs/2304.10832](http://arxiv.org/abs/2304.10832)

    该论文介绍了一种新的深度学习算法，通过解释线性系统的稀疏矩阵为黑白图像，利用池化操作将其转换为小的多通道图像，从而调整代数多重网格方法中的强门槛参数。该算法最小化了AMG方法在有限元求解器中的计算成本，并在解决三维椭圆偏微分方程时比现有最先进的AMG求解器更快。

    

    代数多重网格方法是解线性方程组的最有效的求解器之一，广泛用于离散化的偏微分方程问题。然而，该方法存在高度依赖于需要调优的参数，尤其是强门槛参数，这是构建多重网格所需的。我们引入了一种新的深度学习算法，通过把线性系统的稀疏矩阵解释为黑白图像，利用池化操作将它转换为小的多通道图像，从而调整强门槛参数，最小化了AMG方法在有限元求解器中的计算成本。我们展示了该算法对于解决三维椭圆偏微分方程的速度显著快于现有最先进的AMG求解器。

    Algebraic multigrid (AMG) methods are among the most efficient solvers for linear systems of equations and they are widely used for the solution of problems stemming from the discretization of Partial Differential Equations (PDEs). The most severe limitation of AMG methods is the dependence on parameters that require to be fine-tuned. In particular, the strong threshold parameter is the most relevant since it stands at the basis of the construction of successively coarser grids needed by the AMG methods. We introduce a novel Deep Learning algorithm that minimizes the computational cost of the AMG method when used as a finite element solver. We show that our algorithm requires minimal changes to any existing code. The proposed Artificial Neural Network (ANN) tunes the value of the strong threshold parameter by interpreting the sparse matrix of the linear system as a black-and-white image and exploiting a pooling operator to transform it into a small multi-channel image. We experimentall
    
[^54]: 学习如何使用更好的子图进行人脸聚类

    Learn to Cluster Faces with Better Subgraphs. (arXiv:2304.10831v1 [cs.CV])

    [http://arxiv.org/abs/2304.10831](http://arxiv.org/abs/2304.10831)

    本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。

    

    人脸聚类可以为海量无标签人脸数据提供伪标签，并提高不同人脸识别模型的性能。现有的聚类方法通常是在子图内聚合特征，这些子图通常基于统一的阈值或学习得到的截止位置实现。这可能会降低子图的召回率，从而降低聚类性能。本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。具体来说，所提出的方法包括两个组件，即使用邻居的嵌入来增强人脸嵌入，并对节点对进行封闭子图构建以提取结构信息。将嵌入组合起来，预测所有节点对的链接概率以替换余弦相似度来生成新的子图。

    Face clustering can provide pseudo-labels to the massive unlabeled face data and improve the performance of different face recognition models. The existing clustering methods generally aggregate the features within subgraphs that are often implemented based on a uniform threshold or a learned cutoff position. This may reduce the recall of subgraphs and hence degrade the clustering performance. This work proposed an efficient neighborhood-aware subgraph adjustment method that can significantly reduce the noise and improve the recall of the subgraphs, and hence can drive the distant nodes to converge towards the same centers. More specifically, the proposed method consists of two components, i.e. face embeddings enhancement using the embeddings from neighbors, and enclosed subgraph construction of node pairs for structural information extraction. The embeddings are combined to predict the linkage probabilities for all node pairs to replace the cosine similarities to produce new subgraphs
    
[^55]: 滚动前瞻学习在分类树中的应用

    Rolling Lookahead Learning for Optimal Classification Trees. (arXiv:2304.10830v1 [cs.LG])

    [http://arxiv.org/abs/2304.10830](http://arxiv.org/abs/2304.10830)

    本文提出了一种滚动前瞻学习算法，有效地改进了最优分类树的学习病理，灵活处理任何损失函数并在实验中表现出更好的性能。

    

    由于其本质可解释性和可扩展性，分类树在机器学习领域中仍被广泛应用。本文提出一种滚动子树前瞻算法，将近视方法的相对可扩展性与构建树的最优方法的预见性结合起来。我们算法中的有限预见降低了最优方法中观察到的学习病理。我们算法的核心是一种新颖的二级最优二叉分类树公式，灵活处理任何损失函数。我们证明了这种公式的可行域是一个整数多面体，从而产生最优的LP松弛解。通过广泛的计算分析，我们证明了我们的方法在1330个问题实例中有808个的性能优于最优和近视方法，分别将外样本精度提高了23.6%和14.4%。

    Classification trees continue to be widely adopted in machine learning applications due to their inherently interpretable nature and scalability. We propose a rolling subtree lookahead algorithm that combines the relative scalability of the myopic approaches with the foresight of the optimal approaches in constructing trees. The limited foresight embedded in our algorithm mitigates the learning pathology observed in optimal approaches. At the heart of our algorithm lies a novel two-depth optimal binary classification tree formulation flexible to handle any loss function. We show that the feasible region of this formulation is an integral polyhedron, yielding the LP relaxation solution optimal. Through extensive computational analyses, we demonstrate that our approach outperforms optimal and myopic approaches in 808 out of 1330 problem instances, improving the out-of-sample accuracy by up to 23.6% and 14.4%, respectively.
    
[^56]: 贝叶斯神经网络中的个体公平性研究

    Individual Fairness in Bayesian Neural Networks. (arXiv:2304.10828v1 [cs.LG])

    [http://arxiv.org/abs/2304.10828](http://arxiv.org/abs/2304.10828)

    本文研究了贝叶斯神经网络中的个体公平性，提出了一个系统的估计框架，使得网络输出在给定容忍度内的ε-相似的输入点具有相同的结果。实证研究表明，近似贝叶斯推断训练的BNN比确定性模型更具个体公平性。

    

    本文研究了贝叶斯神经网络（BNNs）中的个体公平性（IF）。具体而言，我们考虑了ε-δ-个体公平性概念，该概念要求对于任何一对根据给定相似度度量ε-相似的输入点，BNN的输出在给定容忍度δ>0内。我们利用输入空间上的统计抽样界限以及对抗鲁棒性和个体公平性之间的关系，推导出了$\epsilon$-$\delta$-IF的系统估计框架，设计了Fair-FGSM和Fair-PGD作为针对BNN的全局公平度攻击的扩展。我们通过对公平性基准测试的各种不同架构的BNN进行实证研究，与使用频率主义技术学习的确定性模型进行比较。有趣的是，我们发现通过近似的贝叶斯推断训练的BNNs通常比确定性模型更加具有个体公平性。

    We study Individual Fairness (IF) for Bayesian neural networks (BNNs). Specifically, we consider the $\epsilon$-$\delta$-individual fairness notion, which requires that, for any pair of input points that are $\epsilon$-similar according to a given similarity metrics, the output of the BNN is within a given tolerance $\delta>0.$ We leverage bounds on statistical sampling over the input space and the relationship between adversarial robustness and individual fairness to derive a framework for the systematic estimation of $\epsilon$-$\delta$-IF, designing Fair-FGSM and Fair-PGD as global,fairness-aware extensions to gradient-based attacks for BNNs. We empirically study IF of a variety of approximately inferred BNNs with different architectures on fairness benchmarks, and compare against deterministic models learnt using frequentist techniques. Interestingly, we find that BNNs trained by means of approximate Bayesian inference consistently tend to be markedly more individually fair than th
    
[^57]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^58]: RPLKG: 基于知识图谱的鲁棒提示学习

    RPLKG: Robust Prompt Learning with Knowledge Graph. (arXiv:2304.10805v1 [cs.AI])

    [http://arxiv.org/abs/2304.10805](http://arxiv.org/abs/2304.10805)

    本研究提出了一种基于知识图谱的鲁棒提示学习方法，通过自动设计有意义和可解释的提示集，提高小样本学习的泛化性能。

    

    大规模预训练模型已经被证明是可迁移的，并且对未知数据集具有很好的泛化性能。最近，诸如CLIP之类的多模态预训练模型在各种实验中表现出显着的性能提升。然而，当标记数据集有限时，新数据集或领域的泛化仍然具有挑战性。为了提高小样本学习的泛化性能，已经进行了各种努力，如提示学习和适配器。然而，当前的少样本自适应方法不具备可解释性，并且需要高计算成本来进行自适应。在本研究中，我们提出了一种新的方法，即基于知识图谱的鲁棒提示学习（RPLKG）。基于知识图谱，我们自动设计出各种可解释和有意义的提示集。我们的模型在大型预训练模型的一次正向传递后获得提示集的缓存嵌入。之后，模型使用GumbelSoftmax优化提示选择过程。

    Large-scale pre-trained models have been known that they are transferable, and they generalize well on the unseen dataset. Recently, multimodal pre-trained models such as CLIP show significant performance improvement in diverse experiments. However, when the labeled dataset is limited, the generalization of a new dataset or domain is still challenging. To improve the generalization performance on few-shot learning, there have been diverse efforts, such as prompt learning and adapter. However, the current few-shot adaptation methods are not interpretable, and they require a high computation cost for adaptation. In this study, we propose a new method, robust prompt learning with knowledge graph (RPLKG). Based on the knowledge graph, we automatically design diverse interpretable and meaningful prompt sets. Our model obtains cached embeddings of prompt sets after one forwarding from a large pre-trained model. After that, model optimizes the prompt selection processes with GumbelSoftmax. In
    
[^59]: 基因组学中的经典到量子序列编码

    Classical-to-Quantum Sequence Encoding in Genomics. (arXiv:2304.10786v1 [quant-ph])

    [http://arxiv.org/abs/2304.10786](http://arxiv.org/abs/2304.10786)

    该论文提出了基因组学中的经典到量子数据编码的几种新方法，使用了无损压缩、小波编码和信息熵等算法，同时引入了一种用量子玻尔兹曼机测试编码DNA序列的方法，相对于传统方法表现更佳。

    

    DNA测序可确定生物个体的遗传编码，因此是医学、生命科学、进化生物学、食品科学和技术以及农业等领域中不可或缺的工具。本文提出了几种受不同数学领域启发的经典到量子数据编码的新方法，并将这些思想应用于生物信息学中。特别地，引入了一些启发于电气与电子工程、信息论、微分几何和神经网络架构的算法。我们完整介绍已有的数据编码方案，并展示如何在基因组学中使用它们。这些算法使用了无损压缩、小波编码和信息熵。此外，我们提出了一种用量子玻尔兹曼机测试编码DNA序列的方法。为了评估我们算法的有效性，我们进行了基因测序过程的模拟，并表明我们提出的方法优于传统的经典方法。

    DNA sequencing allows for the determination of the genetic code of an organism, and therefore is an indispensable tool that has applications in Medicine, Life Sciences, Evolutionary Biology, Food Sciences and Technology, and Agriculture. In this paper, we present several novel methods of performing classical-to-quantum data encoding inspired by various mathematical fields, and we demonstrate these ideas within Bioinformatics. In particular, we introduce algorithms that draw inspiration from diverse fields such as Electrical and Electronic Engineering, Information Theory, Differential Geometry, and Neural Network architectures. We provide a complete overview of the existing data encoding schemes and show how to use them in Genomics. The algorithms provided utilise lossless compression, wavelet-based encoding, and information entropy. Moreover, we propose a contemporary method for testing encoded DNA sequences using Quantum Boltzmann Machines. To evaluate the effectiveness of our algorit
    
[^60]: Eyettention：基于注意力机制的双序列模型以预测人类阅读时的扫视路径

    Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading. (arXiv:2304.10784v1 [cs.CL])

    [http://arxiv.org/abs/2304.10784](http://arxiv.org/abs/2304.10784)

    Eyettention是第一个同时处理语言序列和时间序列的阅读模型，可以更准确地模拟阅读者的扫视路径，对机器学习的自然语言处理模型具有借鉴意义。

    

    阅读时的眼动揭示了阅读者的认知过程和所阅读文本的特征。因此，阅读中扫视路径的分析已引起各个领域的关注，涵盖了从认知科学到语言学和计算机科学。然而，模拟阅读时人类的扫视路径的主要挑战在于它们是由双序列组成的：单词按照语言的语法规则排序，而注视则按照时间顺序排序。人类并不严格按左到右的顺序阅读，而是跳过或重复注视单词，并倒退到以前的单词，语言序列和时间序列的对齐并不容易。本文开发了Eyettention，这是第一个同时处理语言序列和时间序列的双序列模型。

    Eye movements during reading offer insights into both the reader's cognitive processes and the characteristics of the text that is being read. Hence, the analysis of scanpaths in reading have attracted increasing attention across fields, ranging from cognitive science over linguistics to computer science. In particular, eye-tracking-while-reading data has been argued to bear the potential to make machine-learning-based language models exhibit a more human-like linguistic behavior. However, one of the main challenges in modeling human scanpaths in reading is their dual-sequence nature: the words are ordered following the grammatical rules of the language, whereas the fixations are chronologically ordered. As humans do not strictly read from left-to-right, but rather skip or refixate words and regress to previous words, the alignment of the linguistic and the temporal sequence is non-trivial. In this paper, we develop Eyettention, the first dual-sequence model that simultaneously process
    
[^61]: 拒绝服务或细粒度控制：面向联邦学习的灵活模型毒化攻击

    Denial-of-Service or Fine-Grained Control: Towards Flexible Model Poisoning Attacks on Federated Learning. (arXiv:2304.10783v1 [cs.LG])

    [http://arxiv.org/abs/2304.10783](http://arxiv.org/abs/2304.10783)

    本文提出了一种灵活的联邦学习模型毒化攻击策略，既可以实现拒绝服务(Dos)目标，也可以精确控制全局准确性，具有高效和隐形的特点。

    

    联邦学习容易受到毒化攻击，敌对方会破坏全局聚合结果并造成拒绝服务。本文提出了一种灵活模型毒化攻击(FMPA)，旨在实现多功能攻击目标。本文考虑如下实际情景：敌对方没有关于FL系统的额外信息（例如，聚合规则或良性设备上的更新）。FMPA利用全局历史信息构建估计器，将下一轮全局模型预测为良性参考模型，并微调参考模型以获得所需的精度低和扰动小的毒化模型。FMPA不仅可以达到DoS的目标，还可以自然地扩展到启动细粒度可控攻击，从而精确降低全局准确性。本文进一步探索了FMPA在几种FL场景下的攻击性能，包括二元分类和图像分类，在不同的攻击目标和攻击知识水平下。实验结果表明，FMPA可以有效而高效地实现所需的攻击目标，同时保持隐形和不可感知。

    Federated learning (FL) is vulnerable to poisoning attacks, where adversaries corrupt the global aggregation results and cause denial-of-service (DoS). Unlike recent model poisoning attacks that optimize the amplitude of malicious perturbations along certain prescribed directions to cause DoS, we propose a Flexible Model Poisoning Attack (FMPA) that can achieve versatile attack goals. We consider a practical threat scenario where no extra knowledge about the FL system (e.g., aggregation rules or updates on benign devices) is available to adversaries. FMPA exploits the global historical information to construct an estimator that predicts the next round of the global model as a benign reference. It then fine-tunes the reference model to obtain the desired poisoned model with low accuracy and small perturbations. Besides the goal of causing DoS, FMPA can be naturally extended to launch a fine-grained controllable attack, making it possible to precisely reduce the global accuracy. Armed wi
    
[^62]: DEIR: 基于区分性模型的情节内在奖励，高效且鲁棒的探索方法

    DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards. (arXiv:2304.10770v1 [cs.LG])

    [http://arxiv.org/abs/2304.10770](http://arxiv.org/abs/2304.10770)

    提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。

    

    探索是强化学习中的一个基本方面，其有效性关键地影响着强化学习算法的性能，尤其是面对稀疏的外部奖励时更为重要。最近的研究表明，从观测中估计新颖性的内在奖励可以有效鼓励探索。然而，由于环境的随机性以及代理的行为可能会影响观察结果，因此一个观测的新颖性与探索之间存在差距。为了准确估计探索行为，我们提出了DEIR，一种新颖的方法，其中我们从条件互信息项中理论上导出内在奖励，该奖励主要与代理的探索行为所贡献的新颖性成比例，并借助区分性的前向模型实现奖励。我们在MiniGrid中进行了广泛的实验，包括标准和硬核探索游戏，在结果上DEIR比基线学习更快并且具有更高的成功率和鲁棒性，适应环境动态变化。

    Exploration is a fundamental aspect of reinforcement learning (RL), and its effectiveness crucially decides the performance of RL algorithms, especially when facing sparse extrinsic rewards. Recent studies showed the effectiveness of encouraging exploration with intrinsic rewards estimated from novelty in observations. However, there is a gap between the novelty of an observation and an exploration in general, because the stochasticity in the environment as well as the behavior of an agent may affect the observation. To estimate exploratory behaviors accurately, we propose DEIR, a novel method where we theoretically derive an intrinsic reward from a conditional mutual information term that principally scales with the novelty contributed by agent explorations, and materialize the reward with a discriminative forward model. We conduct extensive experiments in both standard and hardened exploration games in MiniGrid to show that DEIR quickly learns a better policy than baselines. Our eval
    
[^63]: 变分自编码器在迁移学习中表现如何？

    How good are variational autoencoders at transfer learning?. (arXiv:2304.10767v1 [cs.LG])

    [http://arxiv.org/abs/2304.10767](http://arxiv.org/abs/2304.10767)

    本文通过分析表示相似性，发现变分自编码器的编码器表示是通用的、解码器表示是特定的。针对这一发现，我们讨论了在迁移学习中如何选择对VAE哪些组件进行重新训练，并提出了一种可视化的评估方法。

    

    变分自编码器（VAE）被用于诸多领域的迁移学习，例如音乐生成和医学图像分析。但是，在迁移前，没有一种原则性的方法来评估哪些组件需要重新训练，或者迁移学习是否有可能在目标任务上起到帮助作用。本文通过表示相似性的视角来探讨这个问题，具体来说，我们使用中心核对齐方法（CKA）来评估在不同数据集上训练的VAE的相似性，并表明编码器的表示是通用的，而解码器的表示是特定的。基于这些认识，我们讨论了选择VAE哪些组件重新训练的影响，并提出了一种可视化评估迁移学习是否有可能在分类任务上有帮助的方法。

    Variational autoencoders (VAEs) are used for transfer learning across various research domains such as music generation or medical image analysis. However, there is no principled way to assess before transfer which components to retrain or whether transfer learning is likely to help on a target task. We propose to explore this question through the lens of representational similarity. Specifically, using Centred Kernel Alignment (CKA) to evaluate the similarity of VAEs trained on different datasets, we show that encoders' representations are generic but decoders' specific. Based on these insights, we discuss the implications for selecting which components of a VAE to retrain and propose a method to visually assess whether transfer learning is likely to help on classification tasks.
    
[^64]: 半监督多模态语义分割中的缺失模态鲁棒性问题

    Missing Modality Robustness in Semi-Supervised Multi-Modal Semantic Segmentation. (arXiv:2304.10756v1 [cs.CV])

    [http://arxiv.org/abs/2304.10756](http://arxiv.org/abs/2304.10756)

    本文提出了一种半监督多模态语义分割框架，可以提高标签效率，增强模型鲁棒性，其中包括一种新的多模态融合机制和教师半监督框架。该框架在缺失模态下具备较强的鲁棒性能。

    

    在语义分割中使用多个空间模态已被证明有助于提高性能。然而，现实中还存在一些挑战，需要解决：(a) 提高标签效率；(b) 在测试时模态缺失的情况下增强模型鲁棒性。为了解决这些挑战，我们首先提出了一种简单而高效的多模态融合机制线性融合，即使在有限监督下，表现也比最先进的多模态模型更好。其次，我们提出了M3L：Masked Modality Learning的多模态教师半监督框架，它不仅提高了多模态性能，还使用未标记的数据使模型在现实情况下对缺失模态更加鲁棒。我们创建了第一个半监督多模态语义分割基准，并报告了对缺失模态的鲁棒性。我们的提议在合成和现实世界数据集上在鲁棒mIoU上比最重要的基线有最多10％的绝对改进。

    Using multiple spatial modalities has been proven helpful in improving semantic segmentation performance. However, there are several real-world challenges that have yet to be addressed: (a) improving label efficiency and (b) enhancing robustness in realistic scenarios where modalities are missing at the test time. To address these challenges, we first propose a simple yet efficient multi-modal fusion mechanism Linear Fusion, that performs better than the state-of-the-art multi-modal models even with limited supervision. Second, we propose M3L: Multi-modal Teacher for Masked Modality Learning, a semi-supervised framework that not only improves the multi-modal performance but also makes the model robust to the realistic missing modality scenario using unlabeled data. We create the first benchmark for semi-supervised multi-modal semantic segmentation and also report the robustness to missing modalities. Our proposal shows an absolute improvement of up to 10% on robust mIoU above the most 
    
[^65]: 基于多模态深度学习的信用评级预测方法研究——以文本和数字数据流为例

    Multi-Modal Deep Learning for Credit Rating Prediction Using Text and Numerical Data Streams. (arXiv:2304.10740v1 [q-fin.GN])

    [http://arxiv.org/abs/2304.10740](http://arxiv.org/abs/2304.10740)

    本文研究了基于多模态的深度学习融合技术在信用评级预测中的应用，通过比较不同融合策略和深度学习模型的组合，证明了一个基于CNN的多模态模型通过两种融合策略优于其他多模态技术，同时在比较简单和复杂的模型中发现，更复杂的模型并不一定表现更好。

    

    了解信用评级分配中哪些因素是重要的可以帮助做出更好的决策。然而，目前文献的重点大多集中在结构化数据上，较少研究非结构化或多模态数据集。本文提出了一种分析结构化和非结构化不同类型数据集的深度学习模型融合的有效架构，以预测公司信用评级标准。在模型中，我们测试了不同的深度学习模型及融合策略的组合，包括CNN，LSTM，GRU和BERT。我们研究了数据融合策略（包括早期和中间融合）以及技术（包括串联和交叉注意）等方面。结果表明，一个基于CNN的多模态模型通过两种融合策略优于其他多模态技术。此外，通过比较简单的架构与更复杂的架构，我们发现，更复杂的模型并不一定能在信用评级预测中发挥更好的性能。

    Knowing which factors are significant in credit rating assignment leads to better decision-making. However, the focus of the literature thus far has been mostly on structured data, and fewer studies have addressed unstructured or multi-modal datasets. In this paper, we present an analysis of the most effective architectures for the fusion of deep learning models for the prediction of company credit rating classes, by using structured and unstructured datasets of different types. In these models, we tested different combinations of fusion strategies with different deep learning models, including CNN, LSTM, GRU, and BERT. We studied data fusion strategies in terms of level (including early and intermediate fusion) and techniques (including concatenation and cross-attention). Our results show that a CNN-based multi-modal model with two fusion strategies outperformed other multi-modal techniques. In addition, by comparing simple architectures with more complex ones, we found that more soph
    
[^66]: KitchenScale: 从食谱上下文中学习预测成分量。

    KitchenScale: Learning to predict ingredient quantities from recipe contexts. (arXiv:2304.10739v1 [cs.CL])

    [http://arxiv.org/abs/2304.10739](http://arxiv.org/abs/2304.10739)

    KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。

    

    在烹饪实践中，确定成分的适当量对于丰富口感和促进健康至关重要。我们介绍了KitchenScale，这是一个经过Fine-tuned的预训练语言模型（PLM），根据食谱上下文预测目标成分的数量和测量单位。为了有效地训练我们的KitchenScale模型，我们制定了一个包括三个子任务的成分量预测任务，这些子任务是成分测量类型分类、单位分类和数量回归任务。此外，我们利用了从食谱文本到PLMs的烹饪知识的转移学习。我们采用了离散潜在指数（DExp）方法来应对食谱语料库中数字尺度的高方差。我们使用我们新构建的数据集和推荐示例进行实验，证明了KitchenScale理解各种食谱语境以及在预测成分量方面具有泛化性。我们实现了一个Web应用程序，为用户提供所需的用于所需人数食品量的配方特定的测量单位。

    Determining proper quantities for ingredients is an essential part of cooking practice from the perspective of enriching tastiness and promoting healthiness. We introduce KitchenScale, a fine-tuned Pre-trained Language Model (PLM) that predicts a target ingredient's quantity and measurement unit given its recipe context. To effectively train our KitchenScale model, we formulate an ingredient quantity prediction task that consists of three sub-tasks which are ingredient measurement type classification, unit classification, and quantity regression task. Furthermore, we utilized transfer learning of cooking knowledge from recipe texts to PLMs. We adopted the Discrete Latent Exponent (DExp) method to cope with high variance of numerical scales in recipe corpora. Experiments with our newly constructed dataset and recommendation examples demonstrate KitchenScale's understanding of various recipe contexts and generalizability in predicting ingredient quantities. We implemented a web applicati
    
[^67]: 利用愚蠢合同进行学习

    Schooling to Exploit Foolish Contracts. (arXiv:2304.10737v1 [cs.CR])

    [http://arxiv.org/abs/2304.10737](http://arxiv.org/abs/2304.10737)

    SCooLS是一个智能合约学习引擎，使用半监督学习和图神经网络，可以直接分析以太坊合约字节码并识别易受攻击的功能，性能优于现有工具，准确度高达98.4%，是第一个基于深度学习的漏洞分析器。

    

    我们介绍了SCooLS，即我们的智能合约学习（半监督）引擎。SCooLS使用神经网络来分析以太坊合约字节码并识别特定的易受攻击的功能。SCooLS包括两个关键元素：半监督学习和图神经网络（GNN）。半监督学习比无监督学习产生更准确的模型，同时不需要大型的标记训练集，而有监督学习则需要。GNN使得可以直接分析智能合约字节码，而不需要任何手动特征工程、预定义的模式或专家规则。SCooLS是半监督学习应用于智能合约漏洞分析的首个应用，也是第一个基于深度学习的漏洞分析器，可以识别特定易受攻击的功能。SCooLS的性能优于现有工具，准确度达到了98.4%，F1得分达到了90.5%，假阳性率仅为0.8%。此外，SCooLS速度很快，

    We introduce SCooLS, our Smart Contract Learning (Semi-supervised) engine. SCooLS uses neural networks to analyze Ethereum contract bytecode and identifies specific vulnerable functions. SCooLS incorporates two key elements: semi-supervised learning and graph neural networks (GNNs). Semi-supervised learning produces more accurate models than unsupervised learning, while not requiring the large oracle-labeled training set that supervised learning requires. GNNs enable direct analysis of smart contract bytecode without any manual feature engineering, predefined patterns, or expert rules.  SCooLS is the first application of semi-supervised learning to smart contract vulnerability analysis, as well as the first deep learning-based vulnerability analyzer to identify specific vulnerable functions. SCooLS's performance is better than existing tools, with an accuracy level of 98.4%, an F1 score of 90.5%, and an exceptionally low false positive rate of only 0.8%. Furthermore, SCooLS is fast, an
    
[^68]: 智能学习发现 愚笨合约

    Smart Learning to Find Dumb Contracts. (arXiv:2304.10726v1 [cs.CR])

    [http://arxiv.org/abs/2304.10726](http://arxiv.org/abs/2304.10726)

    DLVA是一种用于以太坊智能合约的强大深度学习漏洞检测工具，其算法涵盖了源代码到字节码的扩展，并且速度比传统漏洞检测工具提高了10-500倍，并成功地发现了一些Slither误标记的易受攻击的合约。

    

    我们引入了基于强大深度学习技术的 Deep Learning Vulnerability Analyzer （DLVA），它是一种针对以字节码为基础的以太坊智能合约的漏洞检测工具。我们在没有手动特征工程、预定义模式或专家规则的情况下，将源代码分析扩展到字节码，训练DLVA判断字节码。DLVA训练算法的鲁棒性也很强：它克服了1.25%误标记合约的错误率，学生超越了老师，并发现了Slither误标记的易受攻击的合约。DLVA比基于形式方法的传统智能合约漏洞检测工具快得多：DLVA检查了29个漏洞所需的时间为0.2秒，速度提高了10-500倍。DLVA有三个关键组成部分：Smart Contract to Vector（SC2Vec）将智能合约转换为深度学习模型的向量表示。Bytecode Tokenizer（BCT）将底层字节码转换为神经网络的有意义的标记，DLVA是神经网络模型，可预测智能合约是否包含漏洞。我们对Etherscan的28,505个经过验证的智能合约数据集进行了DLVA评估，发现它取得了0.964的AUC（真阳率/假阳率曲线下的面积）得分。与基线方法相比，DLVA在F1分数上显示了30.7%的改进，它是精度和召回的调和平均值。

    We introduce Deep Learning Vulnerability Analyzer (DLVA), a vulnerability detection tool for Ethereum smart contracts based on powerful deep learning techniques for sequential data adapted for bytecode. We train DLVA to judge bytecode even though the supervising oracle, Slither, can only judge source code. DLVA's training algorithm is general: we "extend" a source code analysis to bytecode without any manual feature engineering, predefined patterns, or expert rules. DLVA's training algorithm is also robust: it overcame a 1.25% error rate mislabeled contracts, and the student surpassing the teacher; found vulnerable contracts that Slither mislabeled. In addition to extending a source code analyzer to bytecode, DLVA is much faster than conventional tools for smart contract vulnerability detection based on formal methods: DLVA checks contracts for 29 vulnerabilities in 0.2 seconds, a speedup of 10-500x+ compared to traditional tools.  DLVA has three key components. Smart Contract to Vecto
    
[^69]: 缺失数据下的交通信号控制的强化学习方法

    Reinforcement Learning Approaches for Traffic Signal Control under Missing Data. (arXiv:2304.10722v1 [cs.LG])

    [http://arxiv.org/abs/2304.10722](http://arxiv.org/abs/2304.10722)

    本文提出了在交通路网中缺少传感器的情况下，使用强化学习方法通过补充流量状态或状态和动作来实现自适应控制和条件融合。

    

    强化学习方法在交通信号控制任务中的应用已经取得了比传统的基于规则的方法更好的性能。然而，现实中交通状态的缺失可能经常发生，使得现有的强化学习方法在缺少传感器的路网上无法应用。本文旨在控制交通信号在现实环境下的设置中，其中一些路口没有安装传感器，因此周围没有直接观察数据。在我们所知道的范围内，我们是第一个使用强化学习方法来解决这个现实世界中的交通信号控制问题。具体地，我们提出了两种解决方案：第一种方案补充流量状态以实现自适应控制，第二种方案补充状态和动作以进行条件融合。

    The emergence of reinforcement learning (RL) methods in traffic signal control tasks has achieved better performance than conventional rule-based approaches. Most RL approaches require the observation of the environment for the agent to decide which action is optimal for a long-term reward. However, in real-world urban scenarios, missing observation of traffic states may frequently occur due to the lack of sensors, which makes existing RL methods inapplicable on road networks with missing observation. In this work, we aim to control the traffic signals in a real-world setting, where some of the intersections in the road network are not installed with sensors and thus with no direct observations around them. To the best of our knowledge, we are the first to use RL methods to tackle the traffic signal control problem in this real-world setting. Specifically, we propose two solutions: the first one imputes the traffic states to enable adaptive control, and the second one imputes both stat
    
[^70]: 应用基于特征分裂的物理信息神经网络求解Navier-Stokes方程

    Physics-informed Neural Network Combined with Characteristic-Based Split for Solving Navier-Stokes Equations. (arXiv:2304.10717v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2304.10717](http://arxiv.org/abs/2304.10717)

    本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于处理数据驱动和无数据问题，并且能够快速求解可压缩的浅水方程和不可压缩的N-S方程

    

    本文提出了一种基于特征分裂的物理信息神经网络（PINN）方法，可用于求解时间依赖的Navier-Stokes方程。该方法将输出参数和相应的损失值分离，使输出参数间的权重不被考虑。不是所有的偏导数都参与梯度反向传播，其余项会被重复使用。因此，与传统的PINN相比，该方法更快速。本方法将标签数据、物理约束和网络输出视为先验信息，将N-S方程的残差视为后验信息。因此，它可以处理数据驱动和无数据问题。结果，它能够求解可压缩的浅水方程和不可压缩的N-S方程。由于边界条件已知，该方法只需要在特定时间点获得流场信息即可。

    In this paper, physics-informed neural network (PINN) based on characteristic-based split (CBS) is proposed, which can be used to solve the time-dependent Navier-Stokes equations (N-S equations). In this method, The output parameters and corresponding losses are separated, so the weights between output parameters are not considered. Not all partial derivatives participate in gradient backpropagation, and the remaining terms will be reused.Therefore, compared with traditional PINN, this method is a rapid version. Here, labeled data, physical constraints and network outputs are regarded as priori information, and the residuals of the N-S equations are regarded as posteriori information. So this method can deal with both data-driven and data-free problems. As a result, it can solve the special form of compressible N-S equations -- -Shallow-Water equations, and incompressible N-S equations. As boundary conditions are known, this method only needs the flow field information at a certain tim
    
[^71]: 基于扩散的能量模型的持续训练

    Persistently Trained, Diffusion-assisted Energy-based Models. (arXiv:2304.10707v1 [stat.ML])

    [http://arxiv.org/abs/2304.10707](http://arxiv.org/abs/2304.10707)

    本文提出了一种新的持续训练方法，命名为扩散辅助 EBM，可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。

    

    能量模型 (EBMs) 的最大似然 (ML) 学习很具有挑战性，部分原因在于马尔可夫链蒙特卡罗的不收敛。虽然已经提出了几种 ML 学习的变体，但现有方法都未能同时实现训练后的图像生成和合适的密度估计。我们提出了引入扩散数据，并通过使用增强的采样算法进行持续训练 (即使用持续的对比散度)，来学习一个称为扩散辅助 EBM 的联合 EBM，以便从复杂的、多峰的分布中进行适当的采样。我们在二维的示例实验和图像实验中展示了结果，并证明了针对图像数据，持续训练的 EBM 可以同时实现长期稳定性、训练后的图像生成和优越的越界检测。

    Maximum likelihood (ML) learning for energy-based models (EBMs) is challenging, partly due to non-convergence of Markov chain Monte Carlo.Several variations of ML learning have been proposed, but existing methods all fail to achieve both post-training image generation and proper density estimation. We propose to introduce diffusion data and learn a joint EBM, called diffusion assisted-EBMs, through persistent training (i.e., using persistent contrastive divergence) with an enhanced sampling algorithm to properly sample from complex, multimodal distributions. We present results from a 2D illustrative experiment and image experiments and demonstrate that, for the first time for image data, persistently trained EBMs can {\it simultaneously} achieve long-run stability, post-training image generation, and superior out-of-distribution detection.
    
[^72]: 交互式系统级异常检测

    Interactive System-wise Anomaly Detection. (arXiv:2304.10704v1 [cs.LG])

    [http://arxiv.org/abs/2304.10704](http://arxiv.org/abs/2304.10704)

    本文提出了 InterSAD 方法，利用马尔可夫决策过程模拟交互式系统，并通过找到有效的激活信号和实时交互，解决了系统级异常检测的问题。

    

    异常检测在各种应用中发挥着基础性的作用，其目的是找到包含不同于大多数的特征模式的数据实例。然而，现有方法很难处理其中实例是系统的情况，因为系统的特征不易观察作为数据。需要适当的交互来与系统进行交互并识别那些具有异常响应的系统，这是一个具有挑战性的任务。本文提出了交互式系统级异常检测方法来解决这些挑战。具体而言，我们采用马尔可夫决策过程来模拟交互式系统，并定义了系统级异常检测问题。同时，我们通过找到有效的激活信号来与系统进行交互，并通过实时交互确保稳定的训练过程。

    Anomaly detection, where data instances are discovered containing feature patterns different from the majority, plays a fundamental role in various applications. However, it is challenging for existing methods to handle the scenarios where the instances are systems whose characteristics are not readily observed as data. Appropriate interactions are needed to interact with the systems and identify those with abnormal responses. Detecting system-wise anomalies is a challenging task due to several reasons including: how to formally define the system-wise anomaly detection problem; how to find the effective activation signal for interacting with systems to progressively collect the data and learn the detector; how to guarantee stable training in such a non-stationary scenario with real-time interactions? To address the challenges, we propose InterSAD (Interactive System-wise Anomaly Detection). Specifically, first, we adopt Markov decision process to model the interactive systems, and defi
    
[^73]: 通过正确性和信息量评估推理链的ReCEval

    ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness. (arXiv:2304.10703v1 [cs.CL])

    [http://arxiv.org/abs/2304.10703](http://arxiv.org/abs/2304.10703)

    本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。

    

    多步推理能力在许多自然语言任务中都是基础，但什么构成好的推理链以及如何评估它们尚不清楚。大多数现有方法仅关注推理链是否导致正确的结论，但这种以答案为导向的观点可能会将好的推理质量与其他用于预测答案的假捷径混淆。为了弥补这一差距，我们将推理链视为推导最终答案的非正式证明，通过评估推理链的两个关键特性——（1）正确性，即每个步骤基于步骤，前置步骤和输入上下文中包含的信息进行有效推理，以及（2）信息量，即每个步骤提供新信息有助于推导生成的答案——我们提出了ReCEval（推理链评估）框架。我们使用自然语言推理模型和信息理论测量实现了ReCEval。在多个数据集上的实验表明，我们的框架在评估推理链方面比现有方法更加客观、系统和准确。

    Multi-step reasoning ability is fundamental to many natural language tasks, yet it is unclear what constitutes a good reasoning chain and how to evaluate them. Most existing methods focus solely on whether the reasoning chain leads to the correct conclusion, but this answer-oriented view may confound the quality of reasoning with other spurious shortcuts to predict the answer. To bridge this gap, we evaluate reasoning chains by viewing them as informal proofs that derive the final answer. Specifically, we propose ReCEval (Reasoning Chain Evaluation), a framework that evaluates reasoning chains through two key properties: (1) correctness, i.e., each step makes a valid inference based on the information contained within the step, preceding steps, and input context, and (2) informativeness, i.e., each step provides new information that is helpful towards deriving the generated answer. We implement ReCEval using natural language inference models and information-theoretic measures. On multi
    
[^74]: 电力系统行为模式及应用机器学习中的泛化风险

    Power Grid Behavioral Patterns and Risks of Generalization in Applied Machine Learning. (arXiv:2304.10702v1 [eess.SY])

    [http://arxiv.org/abs/2304.10702](http://arxiv.org/abs/2304.10702)

    本论文基于实际运行数据，分析了电力系统行为模式及模型泛化风险。研究结果表明，忽略电网特定模式可能导致对新输入输出不可行、不可实现或完全无意义的预测。

    

    近年来，出现了大量针对电力系统应用的数据驱动方法的文献。然而，忽略领域知识会对这些方法的实用性造成高风险。具体来说，忽略电网特定的时空模式（负荷、发电和拓扑等）可能导致对新输入输出不可行、不可实现或完全无意义的预测。为了解决这个问题，本文调查实际运行数据，提供电力系统行为模式的见解，包括时变的拓扑、负荷和发电以及单个负荷和发电之间的空间差异（在峰值时间、多种风格下）。然后根据这些观察结果，评估了一些现有机器学习方法在模型设计和训练中忽略这些电网特定模式所造成的泛化风险。

    Recent years have seen a rich literature of data-driven approaches designed for power grid applications. However, insufficient consideration of domain knowledge can impose a high risk to the practicality of the methods. Specifically, ignoring the grid-specific spatiotemporal patterns (in load, generation, and topology, etc.) can lead to outputting infeasible, unrealizable, or completely meaningless predictions on new inputs. To address this concern, this paper investigates real-world operational data to provide insights into power grid behavioral patterns, including the time-varying topology, load, and generation, as well as the spatial differences (in peak hours, diverse styles) between individual loads and generations. Then based on these observations, we evaluate the generalization risks in some existing ML works causedby ignoring these grid-specific patterns in model design and training.
    
[^75]: 基于匹配的生成模型数据估值方法

    Matching-based Data Valuation for Generative Model. (arXiv:2304.10701v1 [cs.CV])

    [http://arxiv.org/abs/2304.10701](http://arxiv.org/abs/2304.10701)

    本论文提出了基于匹配的生成模型数据估值方法，这是一个针对任何生成模型的模型无关方法，可以对数据实例进行估值，而无需重新训练模型，并在估值效果上表现出色。

    

    数据估值对于机器学习非常重要，因为它有助于增强模型的透明度并保护数据特性。现有的数据估值方法主要集中在判别模型上，忽略了最近吸引了大量关注的深度生成模型。与判别模型类似，需要评估深度生成模型中数据贡献的紧迫需求也存在。然而，以往的数据估值方法主要依赖于判别模型性能指标，并需要对模型进行重新训练。因此，它们不能在实际中直接高效地应用于近期的深度生成模型，例如生成对抗网络和扩散模型。为了弥补这一差距，我们从相似性匹配的角度对生成模型中的数据估值问题进行了构建。具体地，我们引入了“Generative Model Valuator”（GMValuator）——第一个针对任何生成模型的模型无关方法，旨在为生成模型提供数据估值而无需重新训练模型。我们的方法利用数据实例及由生成模型生成的相应合成实例之间的相似度来估计原始数据的价值。大量实验证明了我们的方法在为不同的生成模型（包括GAN和扩散模型）评估数据实例方面的优越性。

    Data valuation is critical in machine learning, as it helps enhance model transparency and protect data properties. Existing data valuation methods have primarily focused on discriminative models, neglecting deep generative models that have recently gained considerable attention. Similar to discriminative models, there is an urgent need to assess data contributions in deep generative models as well. However, previous data valuation approaches mainly relied on discriminative model performance metrics and required model retraining. Consequently, they cannot be applied directly and efficiently to recent deep generative models, such as generative adversarial networks and diffusion models, in practice. To bridge this gap, we formulate the data valuation problem in generative models from a similarity-matching perspective. Specifically, we introduce Generative Model Valuator (GMValuator), the first model-agnostic approach for any generative models, designed to provide data valuation for gener
    
[^76]: SkinGPT: 一种基于视觉大语言模型的皮肤科诊断系统

    SkinGPT: A Dermatology Diagnostic System with Vision Large Language Model. (arXiv:2304.10691v1 [eess.IV])

    [http://arxiv.org/abs/2304.10691](http://arxiv.org/abs/2304.10691)

    SkinGPT是一个基于迷你GPT-4的精细调整版本和内部皮肤图像集合结合的皮肤科诊断系统，利用高级视觉大语言模型，解决了皮肤科医生不足、准确诊断皮肤科图片难度大，以及提供用户友好的诊断报告困难等三个挑战。

    

    皮肤和皮下疾病是全球非致命疾病负担的主要原因之一，影响了大部分人口。然而，皮肤科诊断领域存在三个主要挑战：皮肤科医生不足、准确诊断皮肤科图片难度大以及提供用户友好的诊断报告困难。最近大型语言模型的进展显示出了在临床应用中的潜力。然而，当前的大型语言模型在处理图像上存在困难，并且使用ChatGPT的API上传数据会存在潜在的隐私问题。在本文中，我们提出了SkinGPT，这是第一个利用高级视觉大语言模型的皮肤科诊断系统。SkinGPT是首个采用内部皮肤图像集合和迷你GPT-4的精细调整版本结合而成的系统。

    Skin and subcutaneous diseases are among the major causes of the nonfatal disease burden worldwide, affecting a significant proportion of the population. However, there are three major challenges in the field of dermatology diagnosis. Firstly, there is a shortage of dermatologists available to diagnose patients. Secondly, accurately diagnosing dermatological pictures can be challenging. Lastly, providing user-friendly diagnostic reports can be difficult. Recent advancements in the field of large language models (LLMs) have shown potential for clinical applications. However, current LLMs have difficulty processing images, and there are potential privacy concerns associated with using ChatGPT's API for uploading data. In this paper, we propose SkinGPT, which is the first dermatology diagnostic system that utilizes an advanced vision-based large language model. SkinGPT is the first system of its kind, incorporating a fine-tuned version of MiniGPT-4 with a vast collection of in-house skin 
    
[^77]: 面向易发生野火区域的多因素深度学习电力负荷预测模型

    A generalised multi-factor deep learning electricity load forecasting model for wildfire-prone areas. (arXiv:2304.10686v1 [eess.SY])

    [http://arxiv.org/abs/2304.10686](http://arxiv.org/abs/2304.10686)

    本文提出了一种面向易发生野火区域的多因素深度学习电力负荷预测模型，考虑了数据输入结构、日历效应和基于相关性的温度先导条件，相比于传统方法减少了30.73%的MAPE误差。实验证明该模型性能优于另一个DL模型LSTM，平均均方误差和MAPE分别提高了10.06％和12.86％。

    

    本文提出了一种通用和鲁棒的多因素门控循环神经网络（GRU）基于深度学习（DL）模型，用于预测野火季节地区分布网络的电力负荷。该灵活的建模方法考虑数据输入结构、日历效应以及基于相关性的温度先导条件。与常规瞬时温度的使用相比，采用所提出的输入特征选择和温度先导关系使平均绝对百分比误差（MAPE）降低了30.73%%。我们的模型通用且应用于澳大利亚维多利亚州在2015-2020年野火季节期间的八个真实分布式网络中。我们展示了基于GRU的模型在每个步骤中始终优于另一个DL模型，即长短期记忆（LSTM），相对于平均均方误差和MAPE分别提高了10.06％和12.86％。还研究了对训练数据集中的大规模气候变异的敏感性，例如El Niño或La Niña。结果表明我们提出的模型对这种变异是鲁棒的。

    This paper proposes a generalised and robust multi-factor Gated Recurrent Unit (GRU) based Deep Learning (DL) model to forecast electricity load in distribution networks during wildfire seasons. The flexible modelling methods consider data input structure, calendar effects and correlation-based leading temperature conditions. Compared to the regular use of instantaneous temperature, the Mean Absolute Percentage Error (MAPE) is decreased by 30.73% by using the proposed input feature selection and leading temperature relationships. Our model is generalised and applied to eight real distribution networks in Victoria, Australia, during the wildfire seasons of 2015-2020. We demonstrate that the GRU-based model consistently outperforms another DL model, Long Short-Term Memory (LSTM), at every step, giving average improvements in Mean Squared Error (MSE) and MAPE of 10.06% and 12.86%, respectively. The sensitivity to large-scale climate variability in training data sets, e.g. El Ni\~no or La 
    
[^78]: 训练你自己的GNN教师：面向文本图的图感知蒸馏

    Train Your Own GNN Teacher: Graph-Aware Distillation on Textual Graphs. (arXiv:2304.10668v1 [cs.LG])

    [http://arxiv.org/abs/2304.10668](http://arxiv.org/abs/2304.10668)

    本研究提出一种名为Graph-Aware Distillation（GRAD）的框架，以在没有图形的情况下实现快速推理的LM将图形结构编码，此框架可以同时优化GNN教师和无图学生，互相学习以提高性能。

    

    如何在文本图上实现有效的节点表示学习？将语言模型（LM）与图神经网络（GNN）相结合，以对图形的文本信息进行编码的GNN在许多节点分类任务中取得了最先进的性能。然而，由于可扩展性问题，将GNN与LM相结合进行实际部署并没有得到广泛探索。本文通过开发一种名为Graph-Aware Distillation（GRAD）的框架来解决这一难题，以在没有图形的情况下实现快速推理的LM将图形结构编码。与传统的知识蒸馏不同，GRAD通过共享LM在图的节点上同时优化GNN教师和无图学生。这鼓励无图学生利用由GNN教师编码的图形信息，同时使GNN教师更好地利用未标记节点的文本信息。因此，教师和学生模型相互学习以提高其整体性能。

    How can we learn effective node representations on textual graphs? Graph Neural Networks (GNNs) that use Language Models (LMs) to encode textual information of graphs achieve state-of-the-art performance in many node classification tasks. Yet, combining GNNs with LMs has not been widely explored for practical deployments due to its scalability issues. In this work, we tackle this challenge by developing a Graph-Aware Distillation framework (GRAD) to encode graph structures into an LM for graph-free, fast inference. Different from conventional knowledge distillation, GRAD jointly optimizes a GNN teacher and a graph-free student over the graph's nodes via a shared LM. This encourages the graph-free student to exploit graph information encoded by the GNN teacher while at the same time, enables the GNN teacher to better leverage textual information from unlabeled nodes. As a result, the teacher and the student models learn from each other to improve their overall performance. Experiments i
    
[^79]: 初创企业如何扩展机器学习产品：从实践者角度的指南

    Scaling ML Products At Startups: A Practitioner's Guide. (arXiv:2304.10660v1 [cs.LG])

    [http://arxiv.org/abs/2304.10660](http://arxiv.org/abs/2304.10660)

    本文介绍了一种从实践者角度出发，针对初创企业如何成本有效地扩展机器学习产品的框架和方法，并强调了减少固定成本的重要性。

    

    在初创企业如何扩展机器学习产品？特别是如何成本有效地处理更大量，更多样化和更快速的查询？我们将成本分为可变成本-提供模型和性能的成本-和固定成本-开发和训练新模型的成本。我们提出了一个框架来概念化这些成本，将它们细分为更细的类别，并阐述减少成本的方法。最后，由于从我们的经验来看，机器学习系统中最昂贵的固定成本是确定失败根本原因并推动持续改进的成本，我们介绍了一种概念化问题并分享我们的方法。

    How do you scale a machine learning product at a startup? In particular, how do you serve a greater volume, velocity, and variety of queries cost-effectively? We break down costs into variable costs-the cost of serving the model and performant-and fixed costs-the cost of developing and training new models. We propose a framework for conceptualizing these costs, breaking them into finer categories, and limn ways to reduce costs. Lastly, since in our experience, the most expensive fixed cost of a machine learning system is the cost of identifying the root causes of failures and driving continuous improvement, we present a way to conceptualize the issues and share our methodology for the same.
    
[^80]: 使用卷积神经网络学习量子计算机的能力

    Learning a quantum computer's capability using convolutional neural networks. (arXiv:2304.10650v1 [quant-ph])

    [http://arxiv.org/abs/2304.10650](http://arxiv.org/abs/2304.10650)

    本文研究使用卷积神经网络学习量子计算机能力函数，成功预测了近期量子处理器上量子电路的成功概率。

    

    当前量子处理器的计算能力受硬件错误影响导致计算失败。我们探讨使用人工神经网络来学习处理器能力函数的近似值。结果表明使用卷积神经网络能够有效地学习量子处理器的能力函数，使得近期量子处理器上的量子电路可以快速可靠地预测成功概率。

    The computational power of contemporary quantum processors is limited by hardware errors that cause computations to fail. In principle, each quantum processor's computational capabilities can be described with a capability function that quantifies how well a processor can run each possible quantum circuit (i.e., program), as a map from circuits to the processor's success rates on those circuits. However, capability functions are typically unknown and challenging to model, as the particular errors afflicting a specific quantum processor are a priori unknown and difficult to completely characterize. In this work, we investigate using artificial neural networks to learn an approximation to a processor's capability function. We explore how to define the capability function, and we explain how data for training neural networks can be efficiently obtained for a capability function defined using process fidelity. We then investigate using convolutional neural networks to model a quantum compu
    
[^81]: 通过无监督域转移从体戴式传感器中进行活动分类

    Activity Classification Using Unsupervised Domain Transfer from Body Worn Sensors. (arXiv:2304.10643v1 [cs.LG])

    [http://arxiv.org/abs/2304.10643](http://arxiv.org/abs/2304.10643)

    该论文提出了一种从已有分类模型转移学习的方法，在无需标记数据的情况下在新的身体部位上实现活动分类。

    

    活动分类已经成为可穿戴健康追踪设备的重要特征。随着这个领域的创新不断增长，佩戴在身体不同部位的可穿戴设备正在出现。要对新的身体部位进行活动分类，通常需要相应新位置的标记数据，但这样做的成本很高。在这项工作中，我们提出了一种创新的方法，利用已经在参考身体位置（源域）上从惯性测量单元（IMU）数据训练好的活动分类器，以无监督的方式在新的身体位置（目标域）上进行活动分类，即无需在新位置使用分类标签。具体而言，通过复制源域的嵌入，我们训练一个嵌入模型，以在目标域执行活动分类。

    Activity classification has become a vital feature of wearable health tracking devices. As innovation in this field grows, wearable devices worn on different parts of the body are emerging. To perform activity classification on a new body location, labeled data corresponding to the new locations are generally required, but this is expensive to acquire. In this work, we present an innovative method to leverage an existing activity classifier, trained on Inertial Measurement Unit (IMU) data from a reference body location (the source domain), in order to perform activity classification on a new body location (the target domain) in an unsupervised way, i.e. without the need for classification labels at the new location. Specifically, given an IMU embedding model trained to perform activity classification at the source domain, we train an embedding model to perform activity classification at the target domain by replicating the embeddings at the source domain. This is achieved using simulta
    
[^82]: 论数据异构性对分布式线性系统求解器收敛速度的影响

    On the Effects of Data Heterogeneity on the Convergence Rates of Distributed Linear System Solvers. (arXiv:2304.10640v1 [cs.DC])

    [http://arxiv.org/abs/2304.10640](http://arxiv.org/abs/2304.10640)

    本文比较了投影方法和优化方法求解分布式线性系统的收敛速度，提出了角异构性的几何概念，并对最有效的算法(APC和D-HBM)的收敛速度进行了约束和比较。

    

    本文考虑了解决大规模线性方程组的基本问题。特别地，我们考虑任务负责人打算在一组具有一些方程组子集的机器的分布式/联合帮助下解决该系统的设置。虽然有几种方法用于解决这个问题，但缺少对投影方法和优化方法收敛速度的严格比较。在本文中，我们分析并比较这两类算法，特别关注每个类别中最有效的方法，即最近提出的加速投影一致性(APC)和分布式重球方法(D-HBM)。为此，我们首先提出了称为角异构性的几何概念，并讨论其普遍性。使用该概念，我们约束并比较所研究算法的收敛速度，并捕捉两种方法的异构数据的效应。

    We consider the fundamental problem of solving a large-scale system of linear equations. In particular, we consider the setting where a taskmaster intends to solve the system in a distributed/federated fashion with the help of a set of machines, who each have a subset of the equations. Although there exist several approaches for solving this problem, missing is a rigorous comparison between the convergence rates of the projection-based methods and those of the optimization-based ones. In this paper, we analyze and compare these two classes of algorithms with a particular focus on the most efficient method from each class, namely, the recently proposed Accelerated Projection-Based Consensus (APC) and the Distributed Heavy-Ball Method (D-HBM). To this end, we first propose a geometric notion of data heterogeneity called angular heterogeneity and discuss its generality. Using this notion, we bound and compare the convergence rates of the studied algorithms and capture the effects of both 
    
[^83]: 基于多模块CVAE的SNS加速器HVCM故障预测

    Multi-module based CVAE to predict HVCM faults in the SNS accelerator. (arXiv:2304.10639v1 [cs.LG])

    [http://arxiv.org/abs/2304.10639](http://arxiv.org/abs/2304.10639)

    本文介绍了一种基于CVAE的多模块框架，用于预测SNS加速器中HVCM的故障。通过特定模块类型的条件约束，该模型可以提高故障类型的识别灵敏度。实验证明，该模型可以有效地检测多个故障类型的HVCM模块类型。

    

    我们提出了一个基于条件变分自编码器（CVAE）的多模块框架，用于检测来自多个高压变换器模块（HVCM）的电源信号中的异常。我们通过特定模块类型对模型进行条件约束，以捕获正常波形的不同表示，并提高模型对在给定模块类型的有限样本情况下识别特定故障类型的灵敏度。我们针对CVAE模型研究了几种神经网络（NN）架构，并通过观察其稳定性和泛化性的损失景观来评估模型性能。我们的研究结果显示，训练出的模型对于检测多个故障类型的多个HVCM模块类型具有良好的泛化效果。该研究的结果可以用于提高HVCM的可靠性和整体SNS正常运行时间。

    We present a multi-module framework based on Conditional Variational Autoencoder (CVAE) to detect anomalies in the power signals coming from multiple High Voltage Converter Modulators (HVCMs). We condition the model with the specific modulator type to capture different representations of the normal waveforms and to improve the sensitivity of the model to identify a specific type of fault when we have limited samples for a given module type. We studied several neural network (NN) architectures for our CVAE model and evaluated the model performance by looking at their loss landscape for stability and generalization. Our results for the Spallation Neutron Source (SNS) experimental data show that the trained model generalizes well to detecting multiple fault types for several HVCM module types. The results of this study can be used to improve the HVCM reliability and overall SNS uptime
    
[^84]: 摆脱隐患：远程擦除联邦学习中的后门

    Get Rid Of Your Trail: Remotely Erasing Backdoors in Federated Learning. (arXiv:2304.10638v1 [cs.LG])

    [http://arxiv.org/abs/2304.10638](http://arxiv.org/abs/2304.10638)

    本文提出了一种远程擦除联邦学习中后门的方法，使得攻击者可以在实现目标或怀疑被检测到时有效地从集中模型中移除后门。此方法扩展了机器“遗忘”的概念，并提供了具体策略。

    

    联邦学习（FL）使多个参与者能够在不暴露敏感个人数据的情况下进行协作深度学习训练。然而，FL的分布式性质和未经审核的参与者数据使其容易受到后门攻击。在这些攻击中，对手在训练期间向集中式模型注入恶意功能，导致特定对手选择的输入故意错分。虽然以前的研究已经证明了在FL中成功注入持久后门的可能性，但其持久性也带来了挑战，因为它们在集中式模型中的存在可能会促使中央聚合服务器采取预防措施来惩罚对手。因此，本文提出了一种方法，可以使敌人在实现其目标或怀疑可能被检测到时有效地从集中模型中移除后门。所提出的方法扩展了机器“遗忘”的概念，并提出了策略。

    Federated Learning (FL) enables collaborative deep learning training across multiple participants without exposing sensitive personal data. However, the distributed nature of FL and the unvetted participants' data makes it vulnerable to backdoor attacks. In these attacks, adversaries inject malicious functionality into the centralized model during training, leading to intentional misclassifications for specific adversary-chosen inputs. While previous research has demonstrated successful injections of persistent backdoors in FL, the persistence also poses a challenge, as their existence in the centralized model can prompt the central aggregation server to take preventive measures to penalize the adversaries. Therefore, this paper proposes a methodology that enables adversaries to effectively remove backdoors from the centralized model upon achieving their objectives or upon suspicion of possible detection. The proposed approach extends the concept of machine unlearning and presents stra
    
[^85]: 用Cayley变换拟合椭球

    Ellipsoid fitting with the Cayley transform. (arXiv:2304.10630v1 [stat.ML])

    [http://arxiv.org/abs/2304.10630](http://arxiv.org/abs/2304.10630)

    介绍了一种使用Cayley变换在任意维度上将椭球拟合到嘈杂数据中的新算法CTEF，可以拟合任意的椭球，并且能提取其他方法无法识别的数据中的非线性特征，可用于降维、数据可视化和聚类，相比其他方法更优。

    

    我们引入了一种算法，Cayley变换椭球拟合(CTEF)，它使用Cayley变换在任意维度上将椭球拟合到嘈杂的数据中。与许多椭球拟合方法不同，CTEF是椭球特定的——意味着它总是返回椭圆解——并且可以拟合任意的椭球。当数据不均匀地分布在椭球表面上时，它也优于其他拟合方法。受机器学习中可解释和可重复方法的呼吁启发，我们将CTEF应用于降维、数据可视化和聚类。由于CTEF捕捉全局曲率，因此它能够提取其他方法无法识别的数据中的非线性特征。这在人类细胞周期数据的降维和在经典玩具例子的聚类的背景下得到了说明。在后一种情况下，CTEF优于10种流行的聚类算法。

    We introduce an algorithm, Cayley transform ellipsoid fitting (CTEF), that uses the Cayley transform to fit ellipsoids to noisy data in any dimension. Unlike many ellipsoid fitting methods, CTEF is ellipsoid specific -- meaning it always returns elliptic solutions -- and can fit arbitrary ellipsoids. It also outperforms other fitting methods when data are not uniformly distributed over the surface of an ellipsoid. Inspired by calls for interpretable and reproducible methods in machine learning, we apply CTEF to dimension reduction, data visualization, and clustering. Since CTEF captures global curvature, it is able to extract nonlinear features in data that other methods fail to identify. This is illustrated in the context of dimension reduction on human cell cycle data, and in the context of clustering on classical toy examples. In the latter case, CTEF outperforms 10 popular clustering algorithms.
    
[^86]: 无注意力条件自编码器用于加密货币异常检测

    An Attention Free Conditional Autoencoder For Anomaly Detection in Cryptocurrencies. (arXiv:2304.10614v1 [cs.LG])

    [http://arxiv.org/abs/2304.10614](http://arxiv.org/abs/2304.10614)

    本篇论文提出了一种无注意力条件自编码器(AF-CA)，用于检测时间序列中的异常，在处理噪声时更可靠，可以提高异常检测的能力。

    

    在时间序列中识别异常很困难，尤其是在存在大量噪声的情况下。降噪技术可以去除噪声，但这可能会导致信息的显著损失。为了检测时间序列中的异常，我们提出了一种无注意力条件自编码器(AF-CA)。我们从自编码器条件模型开始，添加了一个无注意力LSTM层\cite{inzirillo2022attention}，以使异常检测能力更可靠，并增加异常检测的功率。我们将我们的Attention Free Conditional Autoencoder与LSTM Autoencoder的结果进行了比较，明显提高了模型的解释能力，因此可以更好地检测噪声时间序列中的异常。

    It is difficult to identify anomalies in time series, especially when there is a lot of noise. Denoising techniques can remove the noise but this technique can cause a significant loss of information. To detect anomalies in the time series we have proposed an attention free conditional autoencoder (AF-CA). We started from the autoencoder conditional model on which we added an Attention-Free LSTM layer \cite{inzirillo2022attention} in order to make the anomaly detection capacity more reliable and to increase the power of anomaly detection. We compared the results of our Attention Free Conditional Autoencoder with those of an LSTM Autoencoder and clearly improved the explanatory power of the model and therefore the detection of anomaly in noisy time series.
    
[^87]: 消除条件随机优化偏差

    Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])

    [http://arxiv.org/abs/2304.10613](http://arxiv.org/abs/2304.10613)

    本文提出了一种通用的随机外推技术，用于降低条件随机优化问题中的偏差，并证明在非凸光滑目标函数中，将外推与方差缩减技术相结合可以显著改善样本复杂度。

    

    本文研究了覆盖了多个应用领域，包括投资组合选择、强化学习、鲁棒学习、因果推断等的条件随机优化（CSO）问题。由于其嵌套结构，CSO目标的样本平均梯度存在偏差，因此需要较高的样本复杂度才能达到收敛。我们引入了一种有效降低偏差的通用随机外推技术。我们证明，在非凸光滑目标函数中，将这种外推与方差缩减技术相结合，可以达到比现有界限更好的样本复杂度。我们还开发了用于有限和变量的CSO的新算法，也显著改进了现有结果。最后，我们认为我们的去偏技术也可能是适用于其他随机优化问题的有趣工具。

    In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
    
[^88]: 大型语言模型的多方面重复抑制和内容调控

    Multi-aspect Repetition Suppression and Content Moderation of Large Language Models. (arXiv:2304.10611v1 [cs.CL])

    [http://arxiv.org/abs/2304.10611](http://arxiv.org/abs/2304.10611)

    本文介绍了一种使用标记和序列级别的不可能性损失，以及在培训期间的重复惩罚、推理和后处理等多层面方法来抑制大型语言模型中的重复，并避免生成攻击性内容的能力。

    

    自然语言生成在NLP领域是最具影响力的领域之一，近年来由大型语言模型(LLMs)带来的进步得到了人们的关注。作为编写助手应用程序的关键工具，它们通常容易复制或扩展输入中提供的具有攻击性的内容。在低资源数据环境中，它们也可能导致输出重复的问题。本文介绍了一种精确和非精确重复抑制的结合方法，使用标记和序列级别的不可能性损失，培训期间的重复惩罚、推理和后处理。我们进一步探讨了多级不可能性损失的范围，以赋予模型避免从一开始产生攻击性词汇和短语的能力。最后，通过全面的实验，在多个度量标准上证明了我们提出的方法的有效性。

    Natural language generation is one of the most impactful fields in NLP, and recent years have witnessed its evolution brought about by large language models (LLMs). As the key instrument for writing assistance applications, they are generally prone to replicating or extending offensive content provided in the input. In low-resource data regime, they can also lead to repetitive outputs (Holtzman et al., 2019) [1]. Usually, offensive content and repetitions are mitigated with post-hoc methods, including n-gram level blocklists, top-k and nucleus sampling. In this paper, we introduce a combination of exact and non-exact repetition suppression using token and sequence level unlikelihood loss, repetition penalty during training, inference, and post-processing respectively. We further explore multi-level unlikelihood loss to the extent that it endows the model with abilities to avoid generating offensive words and phrases from the beginning. Finally, with comprehensive experiments, we demons
    
[^89]: 使用深度学习进行客户流失的因果分析

    Causal Analysis of Customer Churn Using Deep Learning. (arXiv:2304.10604v1 [cs.LG])

    [http://arxiv.org/abs/2304.10604](http://arxiv.org/abs/2304.10604)

    本文提出了一个使用深度学习进行客户流失因果分析的框架，通过分类和顺序模式挖掘方法结合因果贝叶斯网络预测导致客户流失的原因概率。通过测试数据的评估指标，证实了该框架的有效性。

    

    客户流失指终止与商业关系或在指定期间内减少客户参与度。增加市场份额和价值有两个主要的商业营销策略：吸引新客户和保留现有客户。与客户获取成本相比，客户保留成本可能高出五到六倍，因此对具有流失风险的客户进行投资是明智的。本文提出了一个框架，使用深度前馈神经网络来进行分类，并结合高维稀疏数据中的顺序模式挖掘方法。我们还提出了一个因果贝叶斯网络来预测导致客户流失的原因概率。测试数据的评估指标证实了XGBoost和我们的深度学习模型的效果。

    Customer churn describes terminating a relationship with a business or reducing customer engagement over a specific period. Two main business marketing strategies play vital roles to increase market share dollar-value: gaining new and preserving existing customers. Customer acquisition cost can be five to six times that for customer retention, hence investing in customers with churn risk is smart. Causal analysis of the churn model can predict whether a customer will churn in the foreseeable future and assist enterprises to identify effects and possible causes for churn and subsequently use that knowledge to apply tailored incentives. This paper proposes a framework using a deep feedforward neural network for classification accompanied by a sequential pattern mining method on high-dimensional sparse data. We also propose a causal Bayesian network to predict cause probabilities that lead to customer churn. Evaluation metrics on test data confirm the XGBoost and our deep learning model o
    
[^90]: B-Learner：隐藏混淆下异质因果效应的准神谕界限

    B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding. (arXiv:2304.10577v1 [cs.LG])

    [http://arxiv.org/abs/2304.10577](http://arxiv.org/abs/2304.10577)

    本文提出了一种元学习器 B-Learner，它可以在限制隐藏混淆水平的情况下高效地学习 CATE 函数的尖锐界限。

    

    从观察数据中估计异质治疗效应是许多领域中的重要任务，有助于政策和决策者做出更好的行动。近年来，在估计条件平均治疗效应（CATE）函数方面取得了鲁棒且高效的方法，但这些方法通常未考虑隐藏混淆的风险，这可能会对基于观察数据的任何因果估计造成任意和不知情的偏差。我们提出了一种名为B-Learner的元学习器，它可以在限制隐藏混淆水平的情况下高效地学习CATE函数的尖锐界限。我们通过将最近针对平均治疗效应的尖锐且有效边界结果（Dorn等人，2021）调整为Kallus＆Oprescu（2022）所提供的稳健和模型无关的分布式治疗效应学习框架，派生出B-Learner。B-Learner可以使用任何函数估计器，例如随机森林和深度神经网络，我们证明了它的。

    Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus & Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its 
    
[^91]: IDQL: 作为一种扩散策略的Actor-Critic方法的隐式Q学习。 (arXiv:2304.10573v1 [cs.LG])

    IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies. (arXiv:2304.10573v1 [cs.LG])

    [http://arxiv.org/abs/2304.10573](http://arxiv.org/abs/2304.10573)

    本文重新解释隐式Q学习(IQL)作为Actor-Critic方法，提出使用扩散行为策略和评判器权重来平衡奖励最大化和与行为策略的分歧。这个方法能够处理复杂和多峰特征的Actor问题。

    

    有效的离线RL方法需要正确处理超出分布的行为。隐式Q学习（IQL）通过仅使用数据集行动通过修改后的Bellman Backup来训练Q函数来解决此问题。但是，不清楚哪个策略实际上实现了此隐含训练的Q函数所代表的值。在本文中，我们将IQL重新解释为Actor-Critic方法，通过广义化评判目标并将其连接到行为规范化的隐式Actor来实现。这种泛化显示了引入的Actor如何平衡奖励最大化和与行为策略的分歧，具体的损失选择决定了这种权衡的性质。值得注意的是，这个Actor可以表现出复杂和多峰的特征，这表明了利用优势加权回归（AWR）中使用的条件高斯Actor的拟合问题。相反，我们建议使用来自参数化扩散行为策略的样本和由评判器计算的权重，然后将其导入。

    Effective offline RL methods require properly handling out-of-distribution actions. Implicit Q-learning (IQL) addresses this by training a Q-function using only dataset actions through a modified Bellman backup. However, it is unclear which policy actually attains the values represented by this implicitly trained Q-function. In this paper, we reinterpret IQL as an actor-critic method by generalizing the critic objective and connecting it to a behavior-regularized implicit actor. This generalization shows how the induced actor balances reward maximization and divergence from the behavior policy, with the specific loss choice determining the nature of this tradeoff. Notably, this actor can exhibit complex and multimodal characteristics, suggesting issues with the conditional Gaussian actor fit with advantage weighted regression (AWR) used in prior methods. Instead, we propose using samples from a diffusion parameterized behavior policy and weights computed from the critic to then importa
    
[^92]: 使用Z3进行FNN全局鲁棒性的形式化建模和验证

    Using Z3 for Formal Modeling and Verification of FNN Global Robustness. (arXiv:2304.10558v1 [cs.LG])

    [http://arxiv.org/abs/2304.10558](http://arxiv.org/abs/2304.10558)

    本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。

    

    虽然前馈神经网络（FNN）在各种任务中取得了显著的成功，但它们对对抗样本很容易受到攻击。已经开发了几种技术来验证FNN的对抗鲁棒性，但大多数技术都集中在针对单个数据点的局部扰动邻域的鲁棒性验证上。全局鲁棒性分析仍存在较大的研究空白。DeepGlobal是一种全局鲁棒性可验证框架，旨在确定FNN的所有可能的对抗危险区域（ADR），不限于测试集中的数据样本。本文提出了DeepGlobal的完整规范和实现，利用SMT求解器Z3进行更明确的定义，并提出了几项改进以进行更高效的验证。为了评估我们的实现和改进的有效性，我们对一组基准数据集进行了广泛的实验。我们的实验结果进行了可视化。

    While Feedforward Neural Networks (FNNs) have achieved remarkable success in various tasks, they are vulnerable to adversarial examples. Several techniques have been developed to verify the adversarial robustness of FNNs, but most of them focus on robustness verification against the local perturbation neighborhood of a single data point. There is still a large research gap in global robustness analysis. The global-robustness verifiable framework DeepGlobal has been proposed to identify \textit{all} possible Adversarial Dangerous Regions (ADRs) of FNNs, not limited to data samples in a test set. In this paper, we propose a complete specification and implementation of DeepGlobal utilizing the SMT solver Z3 for more explicit definition, and propose several improvements to DeepGlobal for more efficient verification. To evaluate the effectiveness of our implementation and improvements, we conduct extensive experiments on a set of benchmark datasets. Visualization of our experiment results s
    
[^93]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^94]: 稀疏性能够提高神经网络的隐私

    Sparsity in neural networks can improve their privacy. (arXiv:2304.10553v1 [cs.LG])

    [http://arxiv.org/abs/2304.10553](http://arxiv.org/abs/2304.10553)

    稀疏性能够提高神经网络的隐私，并且能够保持网络的表现

    

    本文研究稀疏性如何提高神经网络对成员推理攻击的鲁棒性。实验结果表明，稀疏性能够提高网络的隐私，同时保持其在任务上的相似表现。这个实证研究完善和扩展了现有文献。

    This article measures how sparsity can make neural networks more robust to membership inference attacks. The obtained empirical results show that sparsity improves the privacy of the network, while preserving comparable performances on the task at hand. This empirical study completes and extends existing literature.
    
[^95]: 浅层神经网络的插值性质

    Interpolation property of shallow neural networks. (arXiv:2304.10552v1 [cs.LG])

    [http://arxiv.org/abs/2304.10552](http://arxiv.org/abs/2304.10552)

    本文证明了浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质，此外还给出了该全局最小值处的惯性矩阵的表征，并提供了一种实用的概率方法来寻找插值点。

    

    我们研究了超参数化神经网络的损失函数全局最小值的几何性质。在大多数优化问题中，损失函数是凸函数，这种情况下我们只有一个全局最小值，或者是非凸函数，在这种情况下我们有一个有限的全局最小值。在本文中，我们证明了在超参数化范围内，对于非小次数多项式的激活函数，浅层神经网络可以插值任何数据集，即损失函数具有全局最小值为零的性质。此外，如果存在这样的全局最小值，则全局最小值的轮廓有无穷多个点。此外，我们给出了在全局最小值处求解损失函数的海塞矩阵的表征，并在最后一节中，我们提供了一种实用的概率方法来寻找插值点。

    We study the geometry of global minima of the loss landscape of overparametrized neural networks. In most optimization problems, the loss function is convex, in which case we only have a global minima, or nonconvex, with a discrete number of global minima. In this paper, we prove that in the overparametrized regime, a shallow neural network can interpolate any data set, i.e. the loss function has a global minimum value equal to zero as long as the activation function is not a polynomial of small degree. Additionally, if such a global minimum exists, then the locus of global minima has infinitely many points. Furthermore, we give a characterization of the Hessian of the loss function evaluated at the global minima, and in the last section, we provide a practical probabilistic method of finding the interpolation point.
    
[^96]: 深度迁移学习在入侵检测系统中的应用：综述

    Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review. (arXiv:2304.10550v1 [cs.CR])

    [http://arxiv.org/abs/2304.10550](http://arxiv.org/abs/2304.10550)

    本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。

    

    全球范围内，外部互联网越来越多地与当代工业控制系统相连接。因此，有一个迫切的需求保护网络免受各种威胁。可以使用入侵检测系统（IDS）来保护工业活动的关键基础设施，这是一种预防性措施机制，用于识别新的危险威胁和敌对活动。本文研究了用于在许多种工业控制网络中创建IDS的最新人工智能（AI）技术，特别侧重于基于IDS的深度迁移学习（DTL）。DTL可以看作是将来自多个领域的知识融合和/或适应以增强目标任务的性能的一种信息融合。重点是当目标域中的标记数据很少时，DTL可以帮助提高IDS的性能。考虑了2015年之后的出版物。这些选定的出版物被分为三类：仅DTL和仅IDS，具有迁移学习（TL）的IDS，以及基于深度迁移学习的IDS。该研究全面回顾了入侵检测系统中深度迁移学习应用的最新技术和方法。

    Globally, the external Internet is increasingly being connected to the contemporary industrial control system. As a result, there is an immediate need to protect the network from several threats. The key infrastructure of industrial activity may be protected from harm by using an intrusion detection system (IDS), a preventive measure mechanism, to recognize new kinds of dangerous threats and hostile activities. The most recent artificial intelligence (AI) techniques used to create IDS in many kinds of industrial control networks are examined in this study, with a particular emphasis on IDS-based deep transfer learning (DTL). This latter can be seen as a type of information fusion that merge, and/or adapt knowledge from multiple domains to enhance the performance of the target task, particularly when the labeled data in the target domain is scarce. Publications issued after 2015 were taken into account. These selected publications were divided into three categories: DTL-only and IDS-onl
    
[^97]: 关于无交集偏序通用集合的连通性属性的注记

    A note on the connectedness property of union-free generic sets of partial orders. (arXiv:2304.10549v1 [cs.LG])

    [http://arxiv.org/abs/2304.10549](http://arxiv.org/abs/2304.10549)

    本文证明了偏序数据深度函数的背景下Blocher等人[2023]中介绍的无交通用集合具有连通性属性。

    

    本短文描述并证明了在偏序数据深度函数的背景下Blocher等人[2023]引入的连通性属性。 连通性属性为无交通用集合提供了结构性的深入认识。这些集合是在Blocher等人[2023]中介绍的，它们使用在形式概念分析理论中自然出现的所有偏序集合上的闭包运算进行定义。在形式概念分析的语言中，连通性的属性可以生动地被证明。但是，由于在Blocher等人[2023]中我们没有讨论形式概念分析,因此我们把证明放到了这里。

    This short note describes and proves a connectedness property which was introduced in Blocher et al. [2023] in the context of data depth functions for partial orders. The connectedness property gives a structural insight into union-free generic sets. These sets, presented in Blocher et al. [2023], are defined by using a closure operator on the set of all partial orders which naturally appears within the theory of formal concept analysis. In the language of formal concept analysis, the property of connectedness can be vividly proven. However, since within Blocher et al. [2023] we did not discuss formal concept analysis, we outsourced the proof to this note.
    
[^98]: 学习随机过程的有条件生成模型

    Conditional Generative Models for Learning Stochastic Processes. (arXiv:2304.10382v1 [quant-ph])

    [http://arxiv.org/abs/2304.10382](http://arxiv.org/abs/2304.10382)

    提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。

    

    提出了一种学习多模态分布的框架，称为条件量子生成对抗网络（C-qGAN）。神经网络结构严格采用量子电路，因此被证明能够比当前的方法更有效地表示状态准备过程。这种方法有潜力加速蒙特卡罗分析等算法。特别地，在展示了网络在学习任务中的有效性后，将该技术应用于定价亚式期权衍生品，为未来研究其他路径相关期权打下基础。

    A framework to learn a multi-modal distribution is proposed, denoted as the Conditional Quantum Generative Adversarial Network (C-qGAN). The neural network structure is strictly within a quantum circuit and, as a consequence, is shown to represents a more efficient state preparation procedure than current methods. This methodology has the potential to speed-up algorithms, such as Monte Carlo analysis. In particular, after demonstrating the effectiveness of the network in the learning task, the technique is applied to price Asian option derivatives, providing the foundation for further research on other path-dependent options.
    
[^99]: 通过保留谱的数据压缩加速支持向量聚类

    Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])

    [http://arxiv.org/abs/2304.09868](http://arxiv.org/abs/2304.09868)

    本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。

    

    支持向量聚类是一种重要的聚类方法，但是由于其计算昂贵的簇分配步骤，它面临着可伸缩性问题。在本文中，我们通过保留谱的数据压缩来加速支持向量聚类。具体而言，我们将原始数据集压缩成少量谱表示的聚合数据点，然后在压缩后的数据集上执行标准的支持向量聚类，最后将压缩数据集的聚类结果映射回原始数据集以发现簇。我们在真实数据集上的大量实验结果表明，相较于标准支持向量聚类，我们的方法大大提高了速度，而不会损失聚类质量。

    Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
    
[^100]: DiFaReli: 扩散人脸重照技术

    DiFaReli : Diffusion Face Relighting. (arXiv:2304.09479v1 [cs.CV])

    [http://arxiv.org/abs/2304.09479](http://arxiv.org/abs/2304.09479)

    DiFaReli提出了一种新方法，通过利用条件扩散隐式模型解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码，能够处理单视角的野外环境下的人脸重照，无需光线舞台数据、多视图图像或光照基础事实，实验表明其效果优于现有方法。

    

    我们提出了一种新方法，用于处理野外环境下的单视角人脸重照。处理全局照明或投影阴影等非漫反射效应一直是人脸重照领域的难点。以往的研究通常假定兰伯特反射表面，简化光照模型，或者需要估计三维形状、反射率或阴影图。然而，这种估计是容易出错的，需要许多具有光照基础事实的训练样本才能很好地推广。我们的研究绕过了准确估计固有组件的需要，可以仅通过2D图像训练而不需要任何光线舞台数据、多视图图像或光照基础事实。我们的关键思想是利用条件扩散隐式模型（DDIM）解码解耦的光编码以及从现成的估算器推断出的与3D形状和面部身份相关的其他编码。我们还提出了一种新的调节技术，通过使用归一化方案，简化光与几何之间复杂互动的建模。在多个基准数据集上的实验表明，我们的方法优于现有方法。

    We present a novel approach to single-view face relighting in the wild. Handling non-diffuse effects, such as global illumination or cast shadows, has long been a challenge in face relighting. Prior work often assumes Lambertian surfaces, simplified lighting models or involves estimating 3D shape, albedo, or a shadow map. This estimation, however, is error-prone and requires many training examples with lighting ground truth to generalize well. Our work bypasses the need for accurate estimation of intrinsic components and can be trained solely on 2D images without any light stage data, multi-view images, or lighting ground truth. Our key idea is to leverage a conditional diffusion implicit model (DDIM) for decoding a disentangled light encoding along with other encodings related to 3D shape and facial identity inferred from off-the-shelf estimators. We also propose a novel conditioning technique that eases the modeling of the complex interaction between light and geometry by using a ren
    
[^101]: MATURE-HEALTH: MAndatory FeaTURE选择的健康推荐系统

    MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices. (arXiv:2304.09099v1 [cs.IR])

    [http://arxiv.org/abs/2304.09099](http://arxiv.org/abs/2304.09099)

    该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。

    

    平衡电解质对于人体器官的适当功能至关重要和必不可少，因为电解质失衡可能是潜在病理生理学发展的指示。高效监测电解质失衡不仅可以增加疾病早期检测的机会，而且可以通过严格遵循营养控制饮食以平衡电解质从而防止健康进一步恶化。本研究提出并实施了一个推荐系统MATURE Health，该系统预测血液中必需电解质和其他物质的不平衡，然后推荐含有平衡营养的食物，以避免电解质不平衡的发生。该模型考虑到用户最近的实验室结果和每日食物摄入量来预测电解质不平衡。MATURE Health依赖于MATURE Food算法推荐食物，后者仅推荐那些

    Balancing electrolytes is utmost important and essential for appropriate functioning of organs in human body as electrolytes imbalance can be an indication of the development of underlying pathophysiology. Efficient monitoring of electrolytes imbalance not only can increase the chances of early detection of disease, but also prevents the further deterioration of the health by strictly following nutrient controlled diet for balancing the electrolytes post disease detection. In this research, a recommender system MATURE Health is proposed and implemented, which predicts the imbalance of mandatory electrolytes and other substances presented in blood and recommends the food items with the balanced nutrients to avoid occurrence of the electrolytes imbalance. The proposed model takes user most recent laboratory results and daily food intake into account to predict the electrolytes imbalance. MATURE Health relies on MATURE Food algorithm to recommend food items as latter recommends only those
    
[^102]: r-softmax: 具有可控稀疏率的广义Softmax

    r-softmax: Generalized Softmax with Controllable Sparsity Rate. (arXiv:2304.05243v1 [cs.LG])

    [http://arxiv.org/abs/2304.05243](http://arxiv.org/abs/2304.05243)

    本文提出了一种新的广义Softmax函数r-softmax，可以输出具有可控稀疏度的概率分布，相较于现有的替代方案效果更好，在多标签数据集上表现突出，在预训练转换语言模型的自我注意模块中具有重要应用。

    

    如今，人工神经网络模型在许多领域取得了显著的成果。将模型提供的表示映射到概率分布的函数是深度学习解决方案的不可分割的方面。虽然softmax是机器学习社区中通常接受的概率映射函数，但它不能返回稀疏的输出，并且总是将正概率分散到所有位置。在本文中，我们提出了r-softmax，这是softmax的一种修改，它输出具有可控稀疏度的稀疏概率分布。与现有的稀疏概率映射函数相比，我们提供了一种直观的机制来控制输出稀疏度。我们在几个多标签数据集上展示了r-softmax优于其他稀疏的softmax替代方案，并且与原始的softmax相比具有高竞争力。我们还将r-softmax应用于预训练转换语言模型的自我注意模块中，并展示了它在自然语言处理方面的应用。

    Nowadays artificial neural network models achieve remarkable results in many disciplines. Functions mapping the representation provided by the model to the probability distribution are the inseparable aspect of deep learning solutions. Although softmax is a commonly accepted probability mapping function in the machine learning community, it cannot return sparse outputs and always spreads the positive probability to all positions. In this paper, we propose r-softmax, a modification of the softmax, outputting sparse probability distribution with controllable sparsity rate. In contrast to the existing sparse probability mapping functions, we provide an intuitive mechanism for controlling the output sparsity level. We show on several multi-label datasets that r-softmax outperforms other sparse alternatives to softmax and is highly competitive with the original softmax. We also apply r-softmax to the self-attention module of a pre-trained transformer language model and demonstrate that it l
    
[^103]: TPU v4：一款支持嵌入式硬件的可重构光学超级计算机用于机器学习

    TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings. (arXiv:2304.01433v1 [cs.AR])

    [http://arxiv.org/abs/2304.01433](http://arxiv.org/abs/2304.01433)

    TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。

    

    针对机器学习模型的创新，生产工作负载发生了根本性和迅速的变化。TPU v4是谷歌的第五代面向特定领域架构（DSA），是其第三个用于处理此类机器学习模型的超级计算机。光学电路交换机（OCS）动态重新配置其互连拓扑，以提高规模、可用性、利用率、模块化、部署、安全、功率和性能。部署自2020年以来，TPU v4超级计算机的表现优于TPU v3，同时性能/Watt提高了2.7倍。

    In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x-7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus ~10x faster overall, which along with OCS flexibility helps large language models. For sim
    
[^104]: 无碰撞运输图在流行学习中的应用

    Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])

    [http://arxiv.org/abs/2304.00199](http://arxiv.org/abs/2304.00199)

    本文研究了在流形学习中应用无碰撞运输图的方法，其可以比OT图更便宜地计算距离，并提供单个概率测度的平移和伸缩的等距性。

    

    本文研究了引入于[Nurbekyan et al.，2020]的无碰撞运输图在图像数据的流形学习中的应用。近年来，在表示类似运动或变形现象的数据中，应用基于运输的距离和特征的研究大幅增加。事实上，固定位置比较强度通常无法显示数据结构。在[Nurbekyan et al.，2020]中开发的无碰撞图和距离类似于最优传输(OT)图的几何特征但由于无需优化，计算成本要便宜得多。本文证明无碰撞距离提供单个概率测度的平移(分别是伸缩)和装备欧几里得距离的平移(分别是伸缩)向量之间的等距性。此外，我们证明，无碰撞运输图以及OT和线性OT图，一般来说不能为旋转提供等距性。

    In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
    
[^105]: Wasserstein自编码MDPs：具有多方保证的高效RL策略正式验证

    Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees. (arXiv:2303.12558v1 [cs.LG])

    [http://arxiv.org/abs/2303.12558](http://arxiv.org/abs/2303.12558)

    该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。

    

    尽管深度强化学习（DRL）有许多成功案例，但通过这些先进技术学习的决策者在安全关键场景中的大规模部署受到正式保证不足的阻碍。变分马尔可夫决策过程（VAE-MDPs）是离散潜在空间模型，提供了从任何RL策略中提取形式可验证控制器的可靠框架。虽然相关保证涵盖了实际问题的满足性和安全性等方面，但VAE方法因缺乏抽象和表示保证以支持潜在最优化而遭受多种学习缺陷（后验崩塌，学习速度慢，动力学估计不良）。我们引入了Wasserstein自编码MDP（WAE-MDP），这是一种潜在空间模型，通过最小化执行原始策略的智能体行为和提取出的策略之间的最优转运的惩罚形式来解决这些问题。我们证明了所提出的方法可以有利于控制性能和安全之间的平衡，同时减轻了上述的学习问题。我们推导了关于性能和安全的理论保证，并在不同的RL基准上验证了该方法。

    Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent space models that provide a reliable framework for distilling formally verifiable controllers from any RL policy. While the related guarantees address relevant practical aspects such as the satisfaction of performance and safety properties, the VAE approach suffers from several learning flaws (posterior collapse, slow learning speed, poor dynamics estimates), primarily due to the absence of abstraction and representation guarantees to support latent optimization. We introduce the Wasserstein auto-encoded MDP (WAE-MDP), a latent space model that fixes those issues by minimizing a penalized form of the optimal transport between the behaviors of the agent executing the original policy and the disti
    
[^106]: 以某水上运动中心的运行数据为基准的动态模型学习：在8小时范围内搜索有效预测模型

    Operating data of a specific Aquatic Center as a Benchmark for dynamic model learning: search for a valid prediction model over an 8-hour horizon. (arXiv:2303.07195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07195](http://arxiv.org/abs/2303.07195)

    本文提出了基于公共游泳池操作数据的动态模型学习基准，旨在降低能源开支且保持服务质量水平。线性多变量模型和神经动态模型两种方法得出了初步的识别结果。

    

    本文提出了一种基于公共游泳池操作数据的识别基准。 这样的系统既是复杂的过程，又易于所有人理解。最终目标是在保持服务质量水平的同时降低能源开支。这一目标具有普遍性，不仅限于公共游泳池。经济预测控制可以有效地实现这一目标。这种先进的控制基于一个过程模型。本文旨在通过实际操作数据获得这样的动态模型。为此，整理和共享操作数据，并提出模型质量指标。基于此，第一次识别结果分别通过线性多变量模型和神经动态模型进行分析。该基准需要其他控制方案和结果的提出。

    This article presents an identification benchmark based on data from a public swimming pool in operation. Such a system is both a complex process and easily understandable by all with regard to the stakes. Ultimately, the objective is to reduce the energy bill while maintaining the level of quality of service. This objective is general in scope and is not limited to public swimming pools. This can be done effectively through what is known as economic predictive control. This type of advanced control is based on a process model. It is the aim of this article and the considered benchmark to show that such a dynamic model can be obtained from operating data. For this, operational data is formatted and shared, and model quality indicators are proposed. On this basis, the first identification results illustrate the results obtained by a linear multivariable model on the one hand, and by a neural dynamic model on the other hand. The benchmark calls for other proposals and results from contro
    
[^107]: 图神经网络的描述性复杂性

    The Descriptive Complexity of Graph Neural Networks. (arXiv:2303.04613v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2303.04613](http://arxiv.org/abs/2303.04613)

    研究分析了图神经网络（GNN）在布尔电路复杂性和描述性复杂性方面的能力，证明了多项式规模有界深度的GNN族族可以计算的图查询正是带计数和内置关系的一阶逻辑受保护的片断GFO+C所定义的，这将GNN放在电路复杂性类TC^0中。

    

    我们分析了图神经网络（GNN）的布尔电路复杂性和描述性复杂性的能力。我们证明了多项式规模有界深度的GNN族族可以计算的图查询正是那些用带计数和内置关系的一阶逻辑受保护的片断GFO+C定义的。这将GNN放在电路复杂性类TC^0中。值得注意的是，GNN家族可以使用任意实数权值和包括标准ReLU、Logistic“sigmod”和双曲正切函数在内的广泛激活函数类。如果GNN被允许使用随机初始化和全局读取（这些都是GNN在实践中广泛使用的标准功能），它们可以计算与阈门的有界深度布尔电路完全相同的查询，即在TC^0中的查询。此外，我们展示了一个带分段线性激活和有理权重的单个GNN可以在不建造内部关系的情况下由GFO+C定义。

    We analyse the power of graph neural networks (GNNs) in terms of Boolean circuit complexity and descriptive complexity.  We prove that the graph queries that can be computed by a polynomial-size bounded-depth family of GNNs are exactly those definable in the guarded fragment GFO+C of first-order logic with counting and with built-in relations. This puts GNNs in the circuit complexity class TC^0. Remarkably, the GNN families may use arbitrary real weights and a wide class of activation functions that includes the standard ReLU, logistic "sigmod", and hyperbolic tangent functions. If the GNNs are allowed to use random initialisation and global readout (both standard features of GNNs widely used in practice), they can compute exactly the same queries as bounded depth Boolean circuits with threshold gates, that is, exactly the queries in TC^0.  Moreover, we show that queries computable by a single GNN with piecewise linear activations and rational weights are definable in GFO+C without bui
    
[^108]: AI对抗AI：在社交媒体上打击机器生成的虚假餐厅评论

    Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07731](http://arxiv.org/abs/2302.07731)

    本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。

    

    最近生成模型（如GPT）的发展使得以更低的成本制造出难以区分的虚假顾客评论，从而对社交媒体平台检测这些机器生成的虚假评论造成挑战。本文提出利用Yelp验证的高质量的精英餐厅评论来生成OpenAI GPT评论生成器的虚假评论，并最终微调GPT输出检测器来预测明显优于现有解决方案的虚假评论。我们进一步将模型应用于预测非精英评论，并在几个维度（如评论、用户和餐厅特征以及写作风格）上识别模式。我们展示了社交媒体平台正在不断面临机器生成的虚假评论的挑战，尽管他们可能实施检测系统以过滤出可疑的评论。

    Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
    
[^109]: SoK：图像分类中后门触发特征的系统性评估

    SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in Image Classification. (arXiv:2302.01740v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01740](http://arxiv.org/abs/2302.01740)

    本论文对图像分类中的后门触发特征进行了系统性评估，结果显示污染率和2x2像素大小的触发器是创建有效后门的最关键参数。

    

    深度学习在许多机器学习任务中都取得了出色的成果。然而，它容易受到后门攻击的影响，这种攻击通过修改训练集来嵌入受控功能于训练好的模型中。所修改训练样本具有秘密属性，即一个触发器。在推理时，当输入包含触发器时，秘密功能被激活，而在其他情况下模型则能正常运作。虽然已知有许多后门攻击和防御方法，但成功创建隐蔽的后门攻击仍然很困难。成功地创建后门触发器取决于众多参数，不幸的是，尚未确定哪些参数对攻击性能贡献最大。因此本文通过系统分析最相关的后门攻击参数，即触发器尺寸，位置，颜色和污染率。使用迁移学习来评估现有最先进的模型（ResNet，VGG，AlexNet）和数据集（MNIST，CIFAR-10，ImageNet）中的攻击。我们的结果表明，污染率是创建有效后门的最关键参数；2x2像素大小的触发器已足够大多数情况。

    Deep learning achieves outstanding results in many machine learning tasks. Nevertheless, it is vulnerable to backdoor attacks that modify the training set to embed a secret functionality in the trained model. The modified training samples have a secret property, i. e., a trigger. At inference time, the secret functionality is activated when the input contains the trigger, while the model functions correctly in other cases. While there are many known backdoor attacks (and defenses), deploying a stealthy attack is still far from trivial. Successfully creating backdoor triggers depends on numerous parameters. Unfortunately, research has not yet determined which parameters contribute most to the attack performance.  This paper systematically analyzes the most relevant parameters for the backdoor attacks, i.e., trigger size, position, color, and poisoning rate. Using transfer learning, which is very common in computer vision, we evaluate the attack on state-of-the-art models (ResNet, VGG, A
    
[^110]: 一种新颖的稀疏正则化方法

    A Novel Sparse Regularizer. (arXiv:2301.07285v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07285](http://arxiv.org/abs/2301.07285)

    提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。

    

    本文介绍了一种不基于 $L_{p}$-norm 的新颖正则化方法。与传统方法只考虑模型中各权重值的度量不同，这种正则化方法关注权重矩阵内权重的空间排列。该方法的加入项可以用于损失函数中，可微分，简单快速计算，与尺度无关，仅需要微小的额外内存，容易并行化。经实验证明，在相同精度水平下，该方法可以使模型参数的非零数量提高一个数量级。

    $L_{p}$-norm regularization schemes such as $L_{0}$, $L_{1}$, and $L_{2}$-norm regularization and $L_{p}$-norm-based regularization techniques such as weight decay and group LASSO compute a quantity which de pends on model weights considered in isolation from one another. This paper describes a novel regularizer which is not based on an $L_{p}$-norm. In contrast with $L_{p}$-norm-based regularization, this regularizer is concerned with the spatial arrangement of weights within a weight matrix. This regularizer is an additive term for the loss function and is differentiable, simple and fast to compute, scale-invariant, requires a trivial amount of additional memory, and can easily be parallelized. Empirically this method yields approximately a one order-of-magnitude improvement in the number of nonzero model parameters at a given level of accuracy.
    
[^111]: Chat2Map：从多重自我对话中高效构建场景地图

    Chat2Map: Efficient Scene Mapping from Multi-Ego Conversations. (arXiv:2301.02184v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.02184](http://arxiv.org/abs/2301.02184)

    本文提出了一个新的问题：利用多人自我视听观察中的共享信息，高效构建先前未见的3D环境地图。为了高效绘制空间图，作者提出了一种音视频深度强化学习方法，与共享场景对应相配合，选择性地打开相机以最小化冗余并减少功耗。

    

    本文旨在回答一个问题：从多个自我视角捕捉的对话视频中能否以成本有效的方式揭示场景地图？我们提出了一个新问题：通过利用自然对话参与者的自我视听观察中的共享信息，高效构建先前未见的3D环境地图。我们的假设是，多个人（“自我”）在场景中移动并相互交谈时，接收到的丰富视听线索可以帮助揭示场景中未知的地区。鉴于持续处理自我中心视觉流的高成本，我们进一步探索如何主动协调视觉信息的采样，以最小化冗余并减少功耗。为此，我们提出了一种音视频深度强化学习方法，与我们的共享场景对应相配合，选择性地打开相机以高效地绘制空间图。我们使用最先进的音视频自我场景共享数据集评估了该方法。

    Can conversational videos captured from multiple egocentric viewpoints reveal the map of a scene in a cost-efficient way? We seek to answer this question by proposing a new problem: efficiently building the map of a previously unseen 3D environment by exploiting shared information in the egocentric audio-visual observations of participants in a natural conversation. Our hypothesis is that as multiple people ("egos") move in a scene and talk among themselves, they receive rich audio-visual cues that can help uncover the unseen areas of the scene. Given the high cost of continuously processing egocentric visual streams, we further explore how to actively coordinate the sampling of visual information, so as to minimize redundancy and reduce power use. To that end, we present an audio-visual deep reinforcement learning approach that works with our shared scene mapper to selectively turn on the camera to efficiently chart out the space. We evaluate the approach using a state-of-the-art audi
    
[^112]: NeRN——学习神经网络的神经表示法

    NeRN -- Learning Neural Representations for Neural Networks. (arXiv:2212.13554v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13554](http://arxiv.org/abs/2212.13554)

    该论文提出了一种新的神经网络表示方法NeRN，可以直接用于表示预训练卷积神经网络的权重。该方法通过为网络中的每个卷积核分配一个坐标，并将其映射到相应的权重来实现重建。此外，该论文使用知识蒸馏技术稳定模型，并加入平滑约束有助于实现更好的重建效果。

    

    最近，神经表示法已被证明可以有效地重建广泛的信号，从3D网格和形状到图像和视频。我们展示了当神经表示法适当地被调整时，可以用于直接表示预训练卷积神经网络的权重，从而得到一个神经网络的神经表示法（NeRN）。受以前神经表示法方法的坐标输入的启发，我们为网络中的每个卷积核分配一个坐标，基于其在体系结构中的位置，并优化一个预测器网络来将坐标映射到相应的权重。与视觉场景的空间平滑性类似，我们显示在原始网络的权重上加入平滑约束有助于NeRN实现更好的重建。此外，由于预训练模型权重的轻微扰动可能导致相当大的精度损失，我们采用知识蒸馏领域的技术来稳定模型。

    Neural Representations have recently been shown to effectively reconstruct a wide range of signals from 3D meshes and shapes to images and videos. We show that, when adapted correctly, neural representations can be used to directly represent the weights of a pre-trained convolutional neural network, resulting in a Neural Representation for Neural Networks (NeRN). Inspired by coordinate inputs of previous neural representation methods, we assign a coordinate to each convolutional kernel in our network based on its position in the architecture, and optimize a predictor network to map coordinates to their corresponding weights. Similarly to the spatial smoothness of visual scenes, we show that incorporating a smoothness constraint over the original network's weights aids NeRN towards a better reconstruction. In addition, since slight perturbations in pre-trained model weights can result in a considerable accuracy loss, we employ techniques from the field of knowledge distillation to stabi
    
[^113]: SoK：让隐私保护游戏开始！机器学习中数据推断隐私的统一处理

    SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning. (arXiv:2212.10986v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10986](http://arxiv.org/abs/2212.10986)

    本论文提出了一个基于游戏的框架，系统化机器学习中的隐私推断风险知识体系。并为推断风险的定义提供了统一结构，正式建立了已知定义之间的关系，并发现了此前难以发现的关系。

    

    在生产环境中部署机器学习模型可能会使对手推断出有关训练数据的敏感信息。已有大量文献分析了不同类型的推断风险，从成员推断到重构攻击不等。一些作者受到密码学中使用游戏（即概率实验）研究安全性质的成功启发，用类似的基于游戏的风格描述机器学习中的隐私推断风险。然而，对手的能力和目标在不同的呈现方式中经常有微妙的不同，这使得难以关联和组合结果。本文提出了一个基于游戏的框架，系统化机器学习中的隐私推断风险知识体系。我们使用此框架来（1）为推断风险的定义提供统一结构，（2）正式建立已知定义之间的关系，以及（3）发现此前难以发现的关系。

    Deploying machine learning models in production may allow adversaries to infer sensitive information about training data. There is a vast literature analyzing different types of inference risks, ranging from membership inference to reconstruction attacks. Inspired by the success of games (i.e., probabilistic experiments) to study security properties in cryptography, some authors describe privacy inference risks in machine learning using a similar game-based style. However, adversary capabilities and goals are often stated in subtly different ways from one presentation to the other, which makes it hard to relate and compose results. In this paper, we present a game-based framework to systematize the body of knowledge on privacy inference risks in machine learning. We use this framework to (1) provide a unifying structure for definitions of inference risks, (2) formally establish known relations among definitions, and (3) to uncover hitherto unknown relations that would have been difficu
    
[^114]: 基于任务相似度元学习加速多目标非分层超参数最优化的树形结构Parzen估计

    Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator. (arXiv:2212.06751v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06751](http://arxiv.org/abs/2212.06751)

    本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。

    

    超参数优化是提高深度学习性能的关键步骤。实践者通常面临多个方面的权衡，如准确性和延迟时间。在深度学习的高计算需求和对高效超参数优化的不断增长需求下，加速多目标优化变得越来越重要。本文将TPE的收购函数扩展到元学习设置中，使用由任务之间顶级域之间的重叠度定义的任务相似性。我们也从理论上分析并解决了任务相似性的局限性。在实验中，我们展示了我们的方法在表格HPO基准上加速了MO-TPE，并获得了最先进的性能。我们的方法还通过赢得AutoML 2022来得到外部验证。

    Hyperparameter optimization (HPO) is a vital step in improving performance in deep learning (DL). Practitioners are often faced with the trade-off between multiple criteria, such as accuracy and latency. Given the high computational needs of DL and the growing demand for efficient HPO, the acceleration of multi-objective (MO) optimization becomes ever more important. Despite the significant body of work on meta-learning for HPO, existing methods are inapplicable to MO tree-structured Parzen estimator (MO-TPE), a simple yet powerful MO-HPO algorithm. In this paper, we extend TPE's acquisition function to the meta-learning setting using a task similarity defined by the overlap of top domains between tasks. We also theoretically analyze and address the limitations of our task similarity. In the experiments, we demonstrate that our method speeds up MO-TPE on tabular HPO benchmarks and attains state-of-the-art performance. Our method was also validated externally by winning the AutoML 2022 
    
[^115]: 如何后门扩散模型？

    How to Backdoor Diffusion Models?. (arXiv:2212.05400v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.05400](http://arxiv.org/abs/2212.05400)

    该论文介绍了针对扩散模型的后门攻击框架 BadDiffusion，其可以在模型训练期间实现植入后门，导致模型在正常数据输入时依然表现良好，但接收到触发信号时产生误导性输出。该攻击可能对建立在有问题的模型之上的下游任务和应用造成严重影响。

    

    扩散模型是最先进的基于深度学习的生成模型，其训练原理是通过逐步添加噪声和去噪学习正向和反向的扩散过程。为了更好地了解其限制和潜在风险，本文首次研究了扩散模型对后门攻击的鲁棒性。具体而言，我们提出了BadDiffusion，这是一个新的攻击框架，它在模型训练期间工程化了受损的扩散过程，进行后门植入。在推理阶段，后门扩散模型将像普通数据输入的未篡改生成器一样运行，同时在接收到植入的触发信号后，伪造出一些被坏演员设计的目标结果。这种重大风险可能对建立在有问题的模型之上的下游任务和应用造成严重影响。我们在各种后门攻击设置上进行了广泛的实验，结果表明 BadDiffusion 可以稳定地伪造特定的目标结果。

    Diffusion models are state-of-the-art deep learning empowered generative models that are trained based on the principle of learning forward and reverse diffusion processes via progressive noise-addition and denoising. To gain a better understanding of the limitations and potential risks, this paper presents the first study on the robustness of diffusion models against backdoor attacks. Specifically, we propose BadDiffusion, a novel attack framework that engineers compromised diffusion processes during model training for backdoor implantation. At the inference stage, the backdoored diffusion model will behave just like an untampered generator for regular data inputs, while falsely generating some targeted outcome designed by the bad actor upon receiving the implanted trigger signal. Such a critical risk can be dreadful for downstream tasks and applications built upon the problematic model. Our extensive experiments on various backdoor attack settings show that BadDiffusion can consisten
    
[^116]: c-TPE:基于树形结构的带不等式约束的帕捷斯特估计器用于昂贵超参数优化

    c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization. (arXiv:2211.14411v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14411](http://arxiv.org/abs/2211.14411)

    本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。

    

    超参数优化（HPO）对于深度学习算法的强大性能至关重要，实际应用通常会在性能要求之上施加一些限制，例如内存使用或延迟等。在本文中，我们提出了约束TPE（c-TPE），这是广泛使用的多功能贝叶斯优化方法——树形Parzen估计器（TPE）的扩展，以处理这些约束。我们提出的扩展不仅是简单地将现有收益函数和原始TPE组合起来，而是包括修改来解决导致性能不佳的问题。我们从经验和理论上深入分析这些修改，提供了有关它们如何有效地克服这些挑战的见解。在实验中，我们证明了c-TPE在81个昂贵的HPO设置中表现出最佳的平均排名性能，具有统计显着性。

    Hyperparameter optimization (HPO) is crucial for strong performance of deep learning algorithms and real-world applications often impose some constraints, such as memory usage, or latency on top of the performance requirement. In this work, we propose constrained TPE (c-TPE), an extension of the widely-used versatile Bayesian optimization method, tree-structured Parzen estimator (TPE), to handle these constraints. Our proposed extension goes beyond a simple combination of an existing acquisition function and the original TPE, and instead includes modifications that address issues that cause poor performance. We thoroughly analyze these modifications both empirically and theoretically, providing insights into how they effectively overcome these challenges. In the experiments, we demonstrate that c-TPE exhibits the best average rank performance among existing methods with statistical significance on 81 expensive HPO settings.
    
[^117]: 在高能物理中评估生成模型

    Evaluating generative models in high energy physics. (arXiv:2211.10295v2 [hep-ex] UPDATED)

    [http://arxiv.org/abs/2211.10295](http://arxiv.org/abs/2211.10295)

    本文探讨了基于机器学习的生成建模在高能物理模拟计算方面的应用，提出了两个新的度量标准FPD和KPD，并在简单高斯分布和模拟高能喷流数据集上进行了实验。该研究发现FPD是对所有替代喷流分布最敏感的度量标准。

    

    最近，基于机器学习的生成建模在高能物理（HEP）模拟计算方面的应用有了突破性进展。为了在实践中使用这样的替代模拟器，我们需要明确定义的度量标准来比较不同的生成模型，并评估它们与真实分布的差异。本文提出了第一个系统的评估度量标准研究并探讨了它们对失效模式的敏感性以及它们对HEP的相关性和可行性。受物理学和计算机视觉领域以前的工作的启发，我们提出了两个新的度量标准，即Fr\'echet和核物理距离（FPD和KPD），并进行了各种实验，测量它们在简单高斯分布和模拟高能喷流数据集上的性能。我们发现，特别是FPD是对所有替代喷流分布最敏感的度量标准。

    There has been a recent explosion in research into machine-learning-based generative modeling to tackle computational challenges for simulations in high energy physics (HEP). In order to use such alternative simulators in practice, we need well-defined metrics to compare different generative models and evaluate their discrepancy from the true distributions. We present the first systematic review and investigation into evaluation metrics and their sensitivity to failure modes of generative models, using the framework of two-sample goodness-of-fit testing, and their relevance and viability for HEP. Inspired by previous work in both physics and computer vision, we propose two new metrics, the Fr\'echet and kernel physics distances (FPD and KPD, respectively), and perform a variety of experiments measuring their performance on simple Gaussian-distributed, and simulated high energy jet datasets. We find FPD, in particular, to be the most sensitive metric to all alternative jet distributions
    
[^118]: RenderDiffusion: 用于3D重建、修复和生成的图像扩散方法

    RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation. (arXiv:2211.09869v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.09869](http://arxiv.org/abs/2211.09869)

    本文提出了第一个支持3D理解任务的扩散模型RenderDiffusion，只需使用单眼2D监督进行训练。它利用一种新颖的图像去噪架构，生成和渲染中间的三维表示，在扩散过程中提供强有力的3D一致性。

    

    目前，扩散模型在有条件和无条件的图像生成方面均达到了最先进的水平。但是，目前的图像扩散模型不支持用于3D理解所需的任务，例如视角一致的3D生成或单视角物体重建。本文提出了RenderDiffusion，这是第一个用于3D生成和推断的扩散模型，只需使用单眼2D监督进行训练。方法的核心是一种新颖的图像去噪架构，在每个去噪步骤中生成和渲染场景的中间三维表示。这在扩散过程中强制实现了一个强的归纳结构，提供了3D一致的表示，同时只需要2D监督。生成的3D表示可以从任何视角渲染。我们评估了RenderDiffusion在FFHQ、AFHQ、ShapeNet和CLEVR数据集上的性能，显示出了在生成3D场景和从2D图像推断3D场景方面具有竞争力的表现。

    Diffusion models currently achieve state-of-the-art performance for both conditional and unconditional image generation. However, so far, image diffusion models do not support tasks required for 3D understanding, such as view-consistent 3D generation or single-view object reconstruction. In this paper, we present RenderDiffusion, the first diffusion model for 3D generation and inference, trained using only monocular 2D supervision. Central to our method is a novel image denoising architecture that generates and renders an intermediate three-dimensional representation of a scene in each denoising step. This enforces a strong inductive structure within the diffusion process, providing a 3D consistent representation while only requiring 2D supervision. The resulting 3D representation can be rendered from any view. We evaluate RenderDiffusion on FFHQ, AFHQ, ShapeNet and CLEVR datasets, showing competitive performance for generation of 3D scenes and inference of 3D scenes from 2D images. Ad
    
[^119]: 有效经验回放的事件表

    Event Tables for Efficient Experience Replay. (arXiv:2211.00576v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00576](http://arxiv.org/abs/2211.00576)

    本文提出了一种叫做SSET的经验回放采样方法，将缓冲区分为事件表，并采用现有的优先采样策略，大大提高了学习速度和稳定性。

    

    经验回放(ER)是许多深度强化学习(RL)系统的关键组成部分。然而，从ER缓冲区进行统一采样可能导致缓慢的收敛和不稳定的渐近行为。本文介绍了事件表的分层采样（SSET），将ER缓冲区分为事件表，每个事件表捕获了最优行为的重要子序列。我们证明相对于传统的统一缓冲区方法，这种方法具有理论优势，并将SSET与现有的优先采样策略结合起来，进一步提高了学习速度和稳定性。在具有挑战性的MiniGrid领域，基准RL环境以及高保真度的汽车赛车模拟器中的实证结果表明了SSET相对于现有ER缓冲区采样方法的优势和多功能性。

    Experience replay (ER) is a crucial component of many deep reinforcement learning (RL) systems. However, uniform sampling from an ER buffer can lead to slow convergence and unstable asymptotic behaviors. This paper introduces Stratified Sampling from Event Tables (SSET), which partitions an ER buffer into Event Tables, each capturing important subsequences of optimal behavior. We prove a theoretical advantage over the traditional monolithic buffer approach and combine SSET with an existing prioritized sampling strategy to further improve learning speed and stability. Empirical results in challenging MiniGrid domains, benchmark RL environments, and a high-fidelity car racing simulator demonstrate the advantages and versatility of SSET over existing ER buffer sampling approaches.
    
[^120]: 自适应物理信息神经网络求解非平衡流体的粗粒化问题

    Adaptive physics-informed neural operator for coarse-grained non-equilibrium flows. (arXiv:2210.15799v2 [physics.comp-ph] UPDATED)

    [http://arxiv.org/abs/2210.15799](http://arxiv.org/abs/2210.15799)

    本文提出了一种新的基于机器学习的方法来提高非平衡反应流动模拟的计算效率。该模型通过分层自适应深度学习策略将降维和神经网络算子结合起来，学习化学动力学领域多尺度粗粒化和控制方程的解。这种分层结构的策略使得训练简单且计算效率高。

    

    本文提出了一种新的基于机器学习的方法，旨在提高非平衡反应流动模拟的计算效率，同时确保符合底层物理规律。该框架通过分层自适应深度学习策略将降维和神经网络算子结合起来，学习化学动力学领域多尺度粗粒化和控制方程的解。所提出的代理的结构被组织成一个树，其中叶节点表示单独的神经网络算子块，物理约束以多种软硬约束的形式嵌入其中。分层属性有两个优点：i）通过从最慢的时间尺度开始的迁移学习，使训练阶段变得简单；ii）通过基于气体的局部非平衡程度仅对必要的叶节点进行代理评估，从而加速预测步骤。

    This work proposes a new machine learning (ML)-based paradigm aiming to enhance the computational efficiency of non-equilibrium reacting flow simulations while ensuring compliance with the underlying physics. The framework combines dimensionality reduction and neural operators through a hierarchical and adaptive deep learning strategy to learn the solution of multi-scale coarse-grained governing equations for chemical kinetics. The proposed surrogate's architecture is structured as a tree, with leaf nodes representing separate neural operator blocks where physics is embedded in the form of multiple soft and hard constraints. The hierarchical attribute has two advantages: i) It allows the simplification of the training phase via transfer learning, starting from the slowest temporal scales; ii) It accelerates the prediction step by enabling adaptivity as the surrogate's evaluation is limited to the necessary leaf nodes based on the local degree of non-equilibrium of the gas. The model is
    
[^121]: 稀疏与高三角密度对于图表示学习的影响

    Implications of sparsity and high triangle density for graph representation learning. (arXiv:2210.15277v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.15277](http://arxiv.org/abs/2210.15277)

    稀疏图中的大量三角形可使用无限维度内积模型进行复现，其中节点表示位于低维流形上。虽然全局表示是不可能的，但我们可以在本地邻域缩小规模，以获取较低维度的表示。

    

    最近的研究表明，在包含许多三角形的稀疏图中，无法使用节点的有限维度表示来重现，其中连结概率是内积。在这里，我们展示了这样的图可以使用无限维度的内积模型来复现，其中节点表示位于低维流形上。在稀疏的情况下，恢复流形的全局表示是不可能的。然而，我们可以缩小到本地邻域，在那里较低维度的表示是可能的。由于我们的构造允许点均匀分布在流形上，因此我们发现了反对通常的看法——三角形意味着社区结构。

    Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure.
    
[^122]: 一种通用偏差-方差分解方法用于预测的不确定性估计

    Uncertainty Estimates of Predictions via a General Bias-Variance Decomposition. (arXiv:2210.12256v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12256](http://arxiv.org/abs/2210.12256)

    本文介绍了一种通用的偏差-方差分解方法，用于估计模型预测的不确定性，这种方法可以用于大多数预测任务，并且可以在多个下游任务中实际使用。

    

    在许多安全关键的应用中，可靠地估计模型生命周期内的预测不确定性至关重要。最常用的衡量方法是通过预测置信度来衡量。虽然这种方法在领域内样本中表现良好，但在领域漂移时这些估计是不可靠的，并且仅限于分类。相反，对于大多数预测任务，可以使用适当的得分，但是当前文献中不存在用于模型不确定性的偏差-方差分解方法。在这项工作中，我们引入了适用于适当得分的通用偏差-方差分解方法，由此引出Bregman信息作为方差项。我们发现指数族和分类对数似然是特殊情况，并提供了新的公式。令人惊讶的是，我们可以纯粹地在logit空间中表示分类情况。我们展示了这种分解方法在多个下游任务中的实际相关性，包括模型集成和置信区间。

    Reliably estimating the uncertainty of a prediction throughout the model lifecycle is crucial in many safety-critical applications. The most common way to measure this uncertainty is via the predicted confidence. While this tends to work well for in-domain samples, these estimates are unreliable under domain drift and restricted to classification. Alternatively, proper scores can be used for most predictive tasks but a bias-variance decomposition for model uncertainty does not exist in the current literature. In this work we introduce a general bias-variance decomposition for proper scores, giving rise to the Bregman Information as the variance term. We discover how exponential families and the classification log-likelihood are special cases and provide novel formulations. Surprisingly, we can express the classification case purely in the logit space. We showcase the practical relevance of this decomposition on several downstream tasks, including model ensembles and confidence regions.
    
[^123]: 差分隐私引导采样：新的隐私分析与推断策略

    Differentially Private Bootstrap: New Privacy Analysis and Inference Strategies. (arXiv:2210.06140v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.06140](http://arxiv.org/abs/2210.06140)

    本文研究了一种差分隐私引导采样方法，提供了隐私成本的新结果，可用于推断样本分布并构建置信区间，同时指出了现有文献中的误用。随着采样次数趋近无限大，此方法逐渐满足更严格的差分隐私要求。

    

    差分隐私机制通过引入随机性来保护个人信息，但在应用中，统计推断仍然缺乏通用技术。本文研究了一个差分隐私引导采样方法，通过发布多个私有引导采样估计来推断样本分布并构建置信区间。我们的隐私分析提供了单个差分隐私引导采样估计的隐私成本新结果，适用于任何差分隐私机制，并指出了现有文献中引导采样的一些误用。使用Gaussian-DP（GDP）框架，我们证明从满足 $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP 的机制中释放 $B$ 个差分隐私引导采样估计，在 $B$ 趋近无限大时渐近地满足 $\mu$-GDP。此外，我们使用差分隐私引导采样估计的反卷积对样本分布进行准确推断。

    Differentially private (DP) mechanisms protect individual-level information by introducing randomness into the statistical analysis procedure. Despite the availability of numerous DP tools, there remains a lack of general techniques for conducting statistical inference under DP. We examine a DP bootstrap procedure that releases multiple private bootstrap estimates to infer the sampling distribution and construct confidence intervals (CIs). Our privacy analysis presents new results on the privacy cost of a single DP bootstrap estimate, applicable to any DP mechanisms, and identifies some misapplications of the bootstrap in the existing literature. Using the Gaussian-DP (GDP) framework (Dong et al.,2022), we show that the release of $B$ DP bootstrap estimates from mechanisms satisfying $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP asymptotically satisfies $\mu$-GDP as $B$ goes to infinity. Moreover, we use deconvolution with the DP bootstrap estimates to accurately infer the sampling distribution
    
[^124]: 通过双层优化推进模型修剪

    Advancing Model Pruning via Bi-level Optimization. (arXiv:2210.04092v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04092](http://arxiv.org/abs/2210.04092)

    BLOP是一种新颖的模型修剪方法，利用双层优化的方法对修剪问题进行了重新解释，可以在多个常用基准数据集上实现表现的提升，并比现有方法具有更快的计算速度和更高的准确率。

    

    实际应用中的部署限制需要修剪大规模深度学习模型，即促进它们的权重稀疏性。修剪还有可能提高它们的泛化能力。本文提出了一种新颖的修剪方法：双层优化（BLOP），利用双层优化的方法对修剪问题进行了重新解释，并在多个常用基准数据集上实现了表现的提升。该方法比现有方法具有更快的计算速度和更高的准确率。

    The deployment constraints in practical applications necessitate the pruning of large-scale deep learning models, i.e., promoting their weight sparsity. As illustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the potential of improving their generalization ability. At the core of LTH, iterative magnitude pruning (IMP) is the predominant pruning method to successfully find 'winning tickets'. Yet, the computation cost of IMP grows prohibitively as the targeted pruning ratio increases. To reduce the computation overhead, various efficient 'one-shot' pruning methods have been developed, but these schemes are usually unable to find winning tickets as good as IMP. This raises the question of how to close the gap between pruning accuracy and pruning efficiency? To tackle it, we pursue the algorithmic advancement of model pruning. Specifically, we formulate the pruning problem from a fresh and novel viewpoint, bi-level optimization (BLO). We show that the BLO interpretation pro
    
[^125]: 通过最大化和最小化互信息进行深度公平聚类：理论、算法和度量(arXiv:2209.12396v2 [cs.LG]已更新)

    Deep Fair Clustering via Maximizing and Minimizing Mutual Information: Theory, Algorithm and Metric. (arXiv:2209.12396v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.12396](http://arxiv.org/abs/2209.12396)

    本文提出了一种新的深度公平聚类算法FCMI，在互信息理论的基础上进行设计，通过最大化和最小化互信息实现了数据的紧凑、平衡和公平的聚类，以及具有信息量的特征。此外，本文还提出了一种新的公平聚类度量标准，可以更准确地衡量聚类质量。

    

    公平聚类旨在将数据划分为不同的簇，同时防止敏感属性（例如性别、种族、RNA测序技术）在聚类中占主导地位。尽管最近进行了许多工作并取得了巨大成功，但大多数都是启发式的，缺乏统一的算法设计理论。本文通过发展深度公平聚类的互信息理论，并设计了一个新的算法FCMI，填补了这一空白。简而言之，通过最大化和最小化互信息，FCMI旨在实现深度公平聚类高度期望的四个特征，即紧凑、平衡和公平的聚类，以及具有信息量的特征。除了对理论和算法的贡献外，本文的另一个贡献是提出了一种建立在信息理论基础上的新的公平聚类度量标准。与现有的评估指标不同，我们的度量标准衡量聚类质量...

    Fair clustering aims to divide data into distinct clusters while preventing sensitive attributes (\textit{e.g.}, gender, race, RNA sequencing technique) from dominating the clustering. Although a number of works have been conducted and achieved huge success recently, most of them are heuristical, and there lacks a unified theory for algorithm design. In this work, we fill this blank by developing a mutual information theory for deep fair clustering and accordingly designing a novel algorithm, dubbed FCMI. In brief, through maximizing and minimizing mutual information, FCMI is designed to achieve four characteristics highly expected by deep fair clustering, \textit{i.e.}, compact, balanced, and fair clusters, as well as informative features. Besides the contributions to theory and algorithm, another contribution of this work is proposing a novel fair clustering metric built upon information theory as well. Unlike existing evaluation metrics, our metric measures the clustering quality an
    
[^126]: 一种基于生物学的深度生成模型用于细胞分类学中的单细胞注释

    A biology-driven deep generative model for cell-type annotation in cytometry. (arXiv:2208.05745v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2208.05745](http://arxiv.org/abs/2208.05745)

    Scyan是一种单细胞细胞学注释网络，仅使用有关细胞学面板的先前专家知识自动注释细胞类型，旨在解决传统手动筛选细胞分类的缺乏再现性和人工耗时的问题。它还可以快速去除批次效应，去条形码和人口发现。

    

    细胞分类学可实现对杂多种群体内单个细胞的准确表型分析。传统上这些细胞按人工筛选方式进行分类，但这种方法缺乏再现性，且对批次效应敏感。最新的光谱流式细胞术或质谱细胞术创造了丰富和高维数据，而通过人工筛选的分析变得具有挑战性和耗时。为了解决这些限制，我们引入了Scyan（https://github.com/MICS-Lab/scyan），一种单细胞细胞学注释网络，仅使用有关细胞学面板的先前专家知识自动注释细胞类型。我们证明Scyan在多个公共数据集上的性能显着优于相关的最新模型，同时速度更快且具有可解释性。此外，Scyan还可解决几个辅助任务，例如批次效应去除、去条形码和人口发现。总体而言，这一模型加速和简化了细胞种群表征。

    Cytometry enables precise single-cell phenotyping within heterogeneous populations. These cell types are traditionally annotated via manual gating, but this method suffers from a lack of reproducibility and sensitivity to batch-effect. Also, the most recent cytometers - spectral flow or mass cytometers - create rich and high-dimensional data whose analysis via manual gating becomes challenging and time-consuming. To tackle these limitations, we introduce Scyan (https://github.com/MICS-Lab/scyan), a Single-cell Cytometry Annotation Network that automatically annotates cell types using only prior expert knowledge about the cytometry panel. We demonstrate that Scyan significantly outperforms the related state-of-the-art models on multiple public datasets while being faster and interpretable. In addition, Scyan overcomes several complementary tasks such as batch-effect removal, debarcoding, and population discovery. Overall, this model accelerates and eases cell population characterisation
    
[^127]: 基于局部框架的图神经网络在分子势能面建模中的应用

    Graph Neural Network with Local Frame for Molecular Potential Energy Surface. (arXiv:2208.00716v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.00716](http://arxiv.org/abs/2208.00716)

    本论文提出了一种基于局部框架的分子表征学习方法，通过投影来捕捉几何信息，并且不需要特殊设计来满足对称要求，其相对于之前的方法具有更快的计算速度和更容易的实现。

    

    分子势能面建模是科学研究中非常关键的一部分。图神经网络在这个领域内已经展示出了很大的成功。然而，他们的信息传递方案需要特殊设计来捕捉几何信息和满足旋转等变性这样的对称要求，导致了复杂的结构。为了避免这些设计，我们引入了一种新型的局部框架方法来进行分子表征学习，并分析了其表达性。通过投影到框架上，等变特征如3D坐标被转化为不变特征，这样我们就可以通过这些投影来捕捉几何信息，同时从GNN设计中分离对称要求。我们在理论上证明，给定非退化的框架，即使是普通的GNN也可以将分子编码为可注入的，并且使用坐标投影和框架之间的投影可以达到最大表达性。在实验中，我们的模型使用了简单的普通GNN架构，但是达到了最先进的精度。这种简单的架构也使得计算更快，实现更容易。

    Modeling molecular potential energy surface is of pivotal importance in science. Graph Neural Networks have shown great success in this field. However, their message passing schemes need special designs to capture geometric information and fulfill symmetry requirement like rotation equivariance, leading to complicated architectures. To avoid these designs, we introduce a novel local frame method to molecule representation learning and analyze its expressivity. Projected onto a frame, equivariant features like 3D coordinates are converted to invariant features, so that we can capture geometric information with these projections and decouple the symmetry requirement from GNN design. Theoretically, we prove that given non-degenerate frames, even ordinary GNNs can encode molecules injectively and reach maximum expressivity with coordinate projection and frame-frame projection. In experiments, our model uses a simple ordinary GNN architecture yet achieves state-of-the-art accuracy. The simp
    
[^128]: 可靠表示使防御者更强大：鲁棒GNN的无监督结构优化

    Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN. (arXiv:2207.00012v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.00012](http://arxiv.org/abs/2207.00012)

    本文提出了一种名为可靠表示优化（R3）的新型无监督结构优化框架，用于提高GNN的鲁棒性能，通过学习辅助图形并重建原始图形结构来优化节点表示，可有效减少结构和基于特征的攻击的影响，并胜过现有的最先进基线模型。

    

    由于消息传递机制，图神经网络（GNN）在处理图形数据方面在许多任务上取得了成功。然而，最近的研究表明，攻击者可以通过恶意修改图形结构来灾难性地降低GNN的性能。解决这个问题的直接方法是通过学习两个端节点之间的成对表示的度量函数来建模边缘权重，试图为对抗性边缘分配低权重。现有的方法使用原始特征或由有监督GNN学习的表示来模拟边缘权重。然而，这两种策略都面临一些直接问题：原始特征不能表示节点的各种属性（例如结构信息），而由有监督GNN学习的表示可能会受到在污染图上分类器性能差的影响。我们需要表示既携带特征信息，又尽可能多地携带正确结构信息。在本文中，我们提出了一种名为可靠表示优化的新型无监督结构优化框架，用于鲁棒GNN。R3首先通过删除对抗性边缘从输入图形中学习辅助图形，然后通过重建原始图形结构来优化该辅助图形上的节点表示。此外，我们研究了不同预训练策略对学习节点表示质量的影响。针对图形抗性评估的几个基准数据集的实验结果表明，R3可以有效减少结构和基于特征的攻击的影响，并胜过现有的最先进基线模型。

    Benefiting from the message passing mechanism, Graph Neural Networks (GNNs) have been successful on flourish tasks over graph data. However, recent studies have shown that attackers can catastrophically degrade the performance of GNNs by maliciously modifying the graph structure. A straightforward solution to remedy this issue is to model the edge weights by learning a metric function between pairwise representations of two end nodes, which attempts to assign low weights to adversarial edges. The existing methods use either raw features or representations learned by supervised GNNs to model the edge weights. However, both strategies are faced with some immediate problems: raw features cannot represent various properties of nodes (e.g., structure information), and representations learned by supervised GNN may suffer from the poor performance of the classifier on the poisoned graph. We need representations that carry both feature information and as mush correct structure information as p
    
[^129]: GraphMLP：一种用于3D人体姿态估计的图形MLP式架构

    GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation. (arXiv:2206.06420v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.06420](http://arxiv.org/abs/2206.06420)

    提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。

    

    现代多层感知器（MLP）模型已经展现出在没有自我注意力的情况下学习视觉表示方面的竞争性结果，然而，现有的MLP模型并不擅长捕捉局部细节，也缺乏有关人体构型的先验知识，这限制了它们用于骨骼表示学习的建模能力。为了解决这些问题，我们提出了一种简单而有效的图形增强的MLP式架构，称为GraphMLP，它结合了MLP和图形卷积网络（GCN）在全局-局部-图形统一架构中用于3D人体姿态估计。GraphMLP将人体的图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。此外，我们提出了将GraphMLP灵活高效地扩展到视频领域，并展示了可以以可忽略的计算代价来有效地建模复杂的时间动力学。

    Modern multi-layer perceptron (MLP) models have shown competitive results in learning visual representations without self-attention. However, existing MLP models are not good at capturing local details and lack prior knowledge of human body configurations, which limits their modeling power for skeletal representation learning. To address these issues, we propose a simple yet effective graph-reinforced MLP-Like architecture, named GraphMLP, that combines MLPs and graph convolutional networks (GCNs) in a global-local-graphical unified architecture for 3D human pose estimation. GraphMLP incorporates the graph structure of human bodies into an MLP model to meet the domain-specific demand of the 3D human pose, while allowing for both local and global spatial interactions. Furthermore, we propose to flexibly and efficiently extend the GraphMLP to the video domain and show that complex temporal dynamics can be effectively modeled in a simple way with negligible computational cost gains in the
    
[^130]: 针对超参数化的非凸Burer-Monteiro分解的预条件梯度下降与全局最优性证明

    Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification. (arXiv:2206.03345v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.03345](http://arxiv.org/abs/2206.03345)

    本文提出了一种预条件梯度下降方法，使得超参数化情况下梯度下降的收敛速度恢复到线性，并在保证全局最优性证明有效的同时保持低廉的计算代价，该方法适用于强凸的代价函数 $\phi$。

    

    本文探讨了使用梯度下降优化非凸函数$f(X)=\phi(XX^{T})$的方法，其中 $\phi$是一个平滑凸的$n\times n$矩阵上下文的代价函数。虽然仅有二阶停留点可以在合理时间内被证明找到，但如果 $X$ 的秩缺失，那么它的秩缺失将证明它是全局最优的。这种认证全局最优性的方法必然需要当前迭代$X$的搜索秩 $r$ 超过全局最小化器$X^{\star}$ 的秩$r^{\star}$。不幸的是，超参数化显著减慢了梯度下降的收敛速度，从 $r=r^{\star}$ 时的线性速度降为 $r>r^{\star}$ 时的亚线性速度，即使 $\phi$ 是强凸的情况下也是如此。在本文中，我们提出了一种廉价的预条件梯度下降方法，将超参数化情况下梯度下降的收敛速度恢复到线性，同时保证全局最优性证明依旧有效。这种方法只需要进行简单的矩阵乘法和求逆，并且适用于强凸的$φ$。我们通过仿真实验在合成数据和现实应用中验证了我们提出的方法。

    We consider using gradient descent to minimize the nonconvex function $f(X)=\phi(XX^{T})$ over an $n\times r$ factor matrix $X$, in which $\phi$ is an underlying smooth convex cost function defined over $n\times n$ matrices. While only a second-order stationary point $X$ can be provably found in reasonable time, if $X$ is additionally rank deficient, then its rank deficiency certifies it as being globally optimal. This way of certifying global optimality necessarily requires the search rank $r$ of the current iterate $X$ to be overparameterized with respect to the rank $r^{\star}$ of the global minimizer $X^{\star}$. Unfortunately, overparameterization significantly slows down the convergence of gradient descent, from a linear rate with $r=r^{\star}$ to a sublinear rate when $r>r^{\star}$, even when $\phi$ is strongly convex. In this paper, we propose an inexpensive preconditioner that restores the convergence rate of gradient descent back to linear in the overparameterized case, while
    
[^131]: 拓扑深度学习：超越图数据

    Topological Deep Learning: Going Beyond Graph Data. (arXiv:2206.00606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00606](http://arxiv.org/abs/2206.00606)

    本文提出了一个拓扑深度学习的框架，其中包含组合复合体这一新型拓扑域。组合复合体结合了超图和胞腔复合体的优点，允许构建分层高阶关系。

    

    拓扑深度学习是一个快速发展的领域，与开发支持于拓扑域上的深度学习模型有关，例如单纯复合体、胞腔复合体和超图。这些拓扑域在科学计算中广泛应用。在本文中，我们提出了一个建立在更丰富数据结构之上的统一深度学习框架，包括拓扑域。我们首先介绍组合复合体，这是一种新型的拓扑域。组合复合体可以看作是保持某些理想性质的图的推广。类似于超图，组合复合体对关系集合不施加任何约束。此外，组合复合体允许构建分层高阶关系，类似于单纯和胞腔复合体中的关系。因此，组合复合体推广并结合了超图和胞腔复合体的有用特性。

    Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains.  Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, whi
    
[^132]: 基于Wasserstein梯度流的变分推断

    Variational inference via Wasserstein gradient flows. (arXiv:2205.15902v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.15902](http://arxiv.org/abs/2205.15902)

    本文提出了一种基于Wasserstein梯度流的变分推断方法，该方法使用高斯或高斯混合分布并在处理对数凹 $\pi$ 时具有强大的理论保证。

    

    随着马尔可夫链蒙特卡洛 (MCMC) 方法一起，变分推断（VI）已经成为大规模贝叶斯推断的中心计算方法。VI 不是从真实后验 $\pi$ 中进行采样，而是旨在生成一个简单而有效的近似 $\hat \pi$，使得摘要统计量易于计算。然而，与广为研究的 MCMC 方法不同，VI 的算法保证仍然相对较少被理解。在本工作中，我们提出了基于高斯或高斯混合分布的变分推断方法，这些方法基于高斯测度的Bures-Wasserstein 空间上的梯度流理论。当 $\pi$ 是对数凹的时候，与MCMC类似，该方法具有强大的理论保证。

    Along with Markov chain Monte Carlo (MCMC) methods, variational inference (VI) has emerged as a central computational approach to large-scale Bayesian inference. Rather than sampling from the true posterior $\pi$, VI aims at producing a simple but effective approximation $\hat \pi$ to $\pi$ for which summary statistics are easy to compute. However, unlike the well-studied MCMC methodology, algorithmic guarantees for VI are still relatively less well-understood. In this work, we propose principled methods for VI, in which $\hat \pi$ is taken to be a Gaussian or a mixture of Gaussians, which rest upon the theory of gradient flows on the Bures--Wasserstein space of Gaussian measures. Akin to MCMC, it comes with strong theoretical guarantees when $\pi$ is log-concave.
    
[^133]: 预先训练的感知特征提高差分隐私图像生成的性能

    Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.12900](http://arxiv.org/abs/2205.12900)

    该论文提出了一种利用预先训练的感知特征，通过最小化MMD（最大均值差异）来提高差分隐私图像生成的性能，并成功地生成了CIFAR10级别的图像。

    

    使用差分隐私随机梯度下降（DP-SGD）进行中等规模生成模型的训练非常困难：为了保持合理的隐私水平所需的噪声水平过大。相反，我们建议利用信息丰富的公共数据集上的良好相关表征，然后学习使用该表征模型化私有数据。特别的，我们使用从公共数据集中学习的感知特征的核函数，最小化私有目标数据与生成器分布之间的最大均值差异（MMD）。使用MMD，我们可以一次性对数据相关项进行隐私处理，而无需像DP-SGD一样在优化每一步中引入噪声。我们的算法使我们能够生成CIFAR10级别的图像，其 $\epsilon \approx 2$，捕捉了分布中的独特特征，远远超过当前的技术水平，主要集中于数据集，如MNIST和FashionMNIST 以较大的 $\epsilon$。

    Training even moderately-sized generative models with differentially-private stochastic gradient descent (DP-SGD) is difficult: the required level of noise for reasonable levels of privacy is simply too large. We advocate instead building off a good, relevant representation on an informative public dataset, then learning to model the private data with that representation. In particular, we minimize the maximum mean discrepancy (MMD) between private target data and a generator's distribution, using a kernel based on perceptual features learned from a public dataset. With the MMD, we can simply privatize the data-dependent term once and for all, rather than introducing noise at each step of optimization as in DP-SGD. Our algorithm allows us to generate CIFAR10-level images with $\epsilon \approx 2$ which capture distinctive features in the distribution, far surpassing the current state of the art, which mostly focuses on datasets such as MNIST and FashionMNIST at a large $\epsilon \appro
    
[^134]: 在监督学习中嫁接公平性与可解释性

    Marrying Fairness and Explainability in Supervised Learning. (arXiv:2204.02947v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.02947](http://arxiv.org/abs/2204.02947)

    本文关注监督学习中的公平性和可解释性。研究发现，先进的公平学习方法可能在合成和真实世界数据集中诱导歧视。为了防止算法系统中的歧视，提出了一种后处理方法，使受保护属性对系统输出的影响无效，同时保留其他特征的影响力。该方法可以防止直接歧视，并减轻各种差异。

    

    辅助人类决策的机器学习算法可能会无意中歧视某些受保护的群体。我们将直接歧视形式化为受保护属性对决策的直接因果影响，而将间接歧视形式化为与受保护属性相关的非保护特征因果影响的改变。边际直接作用（MDE）和SHapley Additive exPlanations（SHAP）的量度显示，最先进的公平学习方法可以通过合成和真实世界数据集中的关联或反向歧视诱导歧视。为了抑制算法系统中的歧视，我们提出了使受保护属性对系统输出的影响无效，同时保留其他特征影响力的后处理方法。我们引入并研究了实现这些目标的后处理方法，发现它们具有相对较高的模型准确性，可以防止直接歧视，并减轻各种差异。

    Machine learning algorithms that aid human decision-making may inadvertently discriminate against certain protected groups. We formalize direct discrimination as a direct causal effect of the protected attributes on the decisions, while induced discrimination as a change in the causal influence of non-protected features associated with the protected attributes. The measurements of marginal direct effect (MDE) and SHapley Additive exPlanations (SHAP) reveal that state-of-the-art fair learning methods can induce discrimination via association or reverse discrimination in synthetic and real-world datasets. To inhibit discrimination in algorithmic systems, we propose to nullify the influence of the protected attribute on the output of the system, while preserving the influence of remaining features. We introduce and study post-processing methods achieving such objectives, finding that they yield relatively high model accuracy, prevent direct discrimination, and diminishes various disparity
    
[^135]: 用被遮蔽的自编码器进行自预训练用于医学图像分类和分割

    Self Pre-training with Masked Autoencoders for Medical Image Classification and Segmentation. (arXiv:2203.05573v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.05573](http://arxiv.org/abs/2203.05573)

    该论文提出了在医学图像领域中用被遮蔽的自编码器进行自预训练的方法，并利用该方法显著改进了医学图像分类和分割等任务。

    

    最近研究表明，被遮蔽的自编码器 (MAE) 在自然图像分析中为视觉变换器 (ViT) 的预训练是有效的。通过从部分遮蔽的输入中重建完整的图像，ViT 编码器聚合上下文信息以推断被遮蔽的图像区域。我们认为，这种上下文聚合能力在医学图像领域尤其重要，因为每个解剖结构在功能和机械上都与其他结构和区域相连。由于缺乏 ImageNet 规模的医学图像数据集进行预训练，因此我们研究了用 MAE 进行自预训练的方法以用于医学图像分析任务。我们的方法在目标数据的训练集上对 ViT 进行预训练，而不是使用另一个数据集。因此，自预训练可以使更多难以获取预训练数据的情况受益。我们的实验结果表明，MAE 自预训练显著改进了包括胸部 X 光疾病分类、腹部 CT 在内的各种医学图像任务。

    Masked Autoencoder (MAE) has recently been shown to be effective in pre-training Vision Transformers (ViT) for natural image analysis. By reconstructing full images from partially masked inputs, a ViT encoder aggregates contextual information to infer masked image regions. We believe that this context aggregation ability is particularly essential to the medical image domain where each anatomical structure is functionally and mechanically connected to other structures and regions. Because there is no ImageNet-scale medical image dataset for pre-training, we investigate a self pre-training paradigm with MAE for medical image analysis tasks. Our method pre-trains a ViT on the training set of the target data instead of another dataset. Thus, self pre-training can benefit more scenarios where pre-training data is hard to acquire. Our experimental results show that MAE self pre-training markedly improves diverse medical image tasks including chest X-ray disease classification, abdominal CT m
    
[^136]: ICSML: 用于使用IEC 61131-3代码进行本地推断的工业控制系统ML框架

    ICSML: Industrial Control Systems ML Framework for native inference using IEC 61131-3 code. (arXiv:2202.10075v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.10075](http://arxiv.org/abs/2202.10075)

    ICSML是一种能够在PLC上本地执行ML模型推断的框架，可以消除在外部IT硬件上运行的需求。

    

    工业控制系统（ICS）在促进第四次工业革命方面发挥了催化作用。像可编程逻辑控制器（PLC）这样的ICS设备自动化、监控和控制着工业、能源和商业环境中的关键过程。传统运营技术（OT）与信息技术（IT）的融合打开了一个新的独特威胁环境。这启发了基于机器学习（ML）的异常检测方法的防御性研究，这些方法在外部IT硬件上运行，这意味着成本的增加和威胁环境的进一步扩展。为了消除这种需求，我们介绍了ICS机器学习推断框架（ICSML），它使得能够在PLC上本地执行ML模型推断。 ICSML是用IEC 61131-3代码实现的，并提供了几种优化方法，以绕过领域特定语言的限制。因此，它适用于所有PLC，无需供应商支持。

    Industrial Control Systems (ICS) have played a catalytic role in enabling the 4th Industrial Revolution. ICS devices like Programmable Logic Controllers (PLCs), automate, monitor, and control critical processes in industrial, energy, and commercial environments. The convergence of traditional Operational Technology (OT) with Information Technology (IT) has opened a new and unique threat landscape. This has inspired defense research that focuses heavily on Machine Learning (ML) based anomaly detection methods that run on external IT hardware, which means an increase in costs and the further expansion of the threat landscape. To remove this requirement, we introduce the ICS machine learning inference framework (ICSML) which enables executing ML model inference natively on the PLC. ICSML is implemented in IEC 61131-3 code and provides several optimizations to bypass the limitations imposed by the domain-specific languages. Therefore, it works on every PLC without the need for vendor suppo
    
[^137]: 量子懒惰训练

    Quantum Lazy Training. (arXiv:2202.08232v6 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2202.08232](http://arxiv.org/abs/2202.08232)

    本文证明了当量子比特数量较大时，地理局部化参数化量子电路的训练进入懒惰阶段，限制了参数变化速率并保证了相应量子模型的线性逼近的精度。

    

    在梯度下降训练超参数模型函数时，有时参数不会发生显着变化，保持接近其初始值。这种现象称为懒惰训练，并激发了对模型函数在初始参数周围的线性逼近的考虑。在懒惰阶段，线性逼近模拟了参数化函数的行为，其相关内核称为切向内核，指定了模型的训练性能。已知大宽度（经典）神经网络的情况下会出现懒惰训练。我们在本文中展示了在量子比特数量较大时，地理局部化参数化量子电路的训练进入懒惰阶段。更准确地说，我们证明了这种地理局部化参数化量子电路参数变化速率的限制，以及其相关量子模型的线性逼近的精度。

    In the training of over-parameterized model functions via gradient descent, sometimes the parameters do not change significantly and remain close to their initial values. This phenomenon is called lazy training, and motivates consideration of the linear approximation of the model function around the initial parameters. In the lazy regime, this linear approximation imitates the behavior of the parameterized function whose associated kernel, called the tangent kernel, specifies the training performance of the model. Lazy training is known to occur in the case of (classical) neural networks with large widths. In this paper, we show that the training of geometrically local parameterized quantum circuits enters the lazy regime for large numbers of qubits. More precisely, we prove bounds on the rate of changes of the parameters of such a geometrically local parameterized quantum circuit in the training process, and on the precision of the linear approximation of the associated quantum model 
    
[^138]: 面向自动驾驶系统的无监督测试场景提取方法——基于自然城市道路交通数据

    Toward Unsupervised Test Scenario Extraction for Automated Driving Systems from Urban Naturalistic Road Traffic Data. (arXiv:2202.06608v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2202.06608](http://arxiv.org/abs/2202.06608)

    该论文提出了一种利用无监督机器学习方法从自然城市道路交通数据中提取相关场景的方法，并且在约30小时的数据上进行的评估结果表明该方法能够自动识别相关测试场景，具有较好的应用前景。

    

    基于场景的测试是解决配备自动驾驶系统的车辆安全行为验证挑战的一种有前途的方法。由于在真实道路交通中可以在理论上发生无限数量的具体场景，因此从安全相关行为的角度提取相关场景是成功验证和验证这些系统的关键。因此，提出了一种从自然城市道路交通数据中无监督地提取多模式城市交通场景的方法，最小化（可能有偏见的）先前专家知识的量。所提出的方法采用无监督机器学习流程，而不是通过提取具体场景到预定义功能场景的（精细的）基于规则的分配。该方法允许探索数据的未知性质及其解释为专家未能预期的测试场景。该方法在约30个小时的自然道路交通数据上进行了评估，并显示出自动识别相关测试场景的有希望的结果。

    Scenario-based testing is a promising approach to solve the challenge of proving the safe behavior of vehicles equipped with automated driving systems. Since an infinite number of concrete scenarios can theoretically occur in real-world road traffic, the extraction of scenarios relevant in terms of the safety-related behavior of these systems is a key aspect for their successful verification and validation. Therefore, a method for extracting multimodal urban traffic scenarios from naturalistic road traffic data in an unsupervised manner, minimizing the amount of (potentially biased) prior expert knowledge, is proposed. Rather than an (elaborate) rule-based assignment by extracting concrete scenarios into predefined functional scenarios, the presented method deploys an unsupervised machine learning pipeline. The approach allows exploring the unknown nature of the data and their interpretation as test scenarios that experts could not have anticipated. The method is evaluated for naturali
    
[^139]: 图关系领域适应

    Graph-Relational Domain Adaptation. (arXiv:2202.03628v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03628](http://arxiv.org/abs/2202.03628)

    本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。

    

    现有的领域适应方法往往将每个领域等同对待并完美对齐，忽略了不同领域之间的拓扑结构，因此对于相邻领域可能有利，但对于远离领域则可能无益。本文通过使用领域图对领域相邻性进行编码，例如以美国不同州为领域创建的状态图，使得领域可以根据图结构灵活对齐，从而放宽了这种统一的对齐方法。我们使用一种新的图判别器将现有的对抗学习框架进行了推广，并使用编码条件图嵌入。理论分析表明，在均衡状态下，当图是一个团时，我们的方法会恢复经典的领域适应方法，并为其他类型的图实现了非平凡的对齐。实证结果表明，我们的方法可以成功地推广统一的对齐方法，并自然地融合了领域信息。

    Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented b
    
[^140]: 平滑可分非负矩阵分解

    Smoothed Separable Nonnegative Matrix Factorization. (arXiv:2110.05528v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2110.05528](http://arxiv.org/abs/2110.05528)

    该算法基于平滑的可分离性假设，提出一种新的平滑可分非负矩阵分解（SSNMF）算法，能够有效地抵抗在‘纯像素假设’存在的噪声干扰

    

    该论文提出了一种新算法--平滑可分非负矩阵分解（SSNMF），该算法基于一个经过平滑的可分离性假设，被制定为一个凸优化问题来抵抗在‘纯像素假设’存在的情况下噪声的干扰。该算法的有效实施和广泛实验表明，它可以保证在特定噪声水平内收敛到非负矩阵分解，且得出真实顶点。

    Given a set of data points belonging to the convex hull of a set of vertices, a key problem in linear algebra, signal processing, data analysis and machine learning is to estimate these vertices in the presence of noise. Many algorithms have been developed under the assumption that there is at least one nearby data point to each vertex; two of the most widely used ones are vertex component analysis (VCA) and the successive projection algorithm (SPA). This assumption is known as the pure-pixel assumption in blind hyperspectral unmixing, and as the separability assumption in nonnegative matrix factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex (ALLS) that relies on the assumption that there is more than one nearby data point to each vertex. In that scenario, ALLS is probalistically more robust to noise than algorithms based on the separability assumption. In this paper, inspired by A
    
[^141]: 基于认知的增量漂移概念学习

    Cognitively Inspired Learning of Incremental Drifting Concepts. (arXiv:2110.04662v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.04662](http://arxiv.org/abs/2110.04662)

    本研究提出了一种基于神经系统学习机制的计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。此模型结合多模态分布空间和伪排练记忆机制，可用于克服灾难性遗忘。

    

    人类不断将自己学到的知识拓展到新的领域，并且在学习新的概念时不会对以前学习的经验有任何干扰。相反，机器学习模型在连续的学习环境中表现不佳，因为输入数据的分布会随着时间的推移而变化。受神经系统学习机制的启发，我们开发了一种计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。我们依靠并行分布处理理论，在一个多模态分布空间中，用内部数据表示在隐藏网络层中建模抽象概念。同时，我们还利用补充学习系统理论，通过实现伪排练来为模型配备记忆机制，以克服灾难性遗忘。我们的模型可以生成伪数据点进行经验回放和知识积累，这些点将被用作新数据的训练输入。

    Humans continually expand their learned knowledge to new domains and learn new concepts without any interference with past learned experiences. In contrast, machine learning models perform poorly in a continual learning setting, where input data distribution changes over time. Inspired by the nervous system learning mechanisms, we develop a computational model that enables a deep neural network to learn new concepts and expand its learned knowledge to new domains incrementally in a continual learning setting. We rely on the Parallel Distributed Processing theory to encode abstract concepts in an embedding space in terms of a multimodal distribution. This embedding space is modeled by internal data representations in a hidden network layer. We also leverage the Complementary Learning Systems theory to equip the model with a memory mechanism to overcome catastrophic forgetting through implementing pseudo-rehearsal. Our model can generate pseudo-data points for experience replay and accum
    
[^142]: Bures-Wasserstein流形上的平均：梯度下降的无维收敛。

    Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent. (arXiv:2106.08502v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2106.08502](http://arxiv.org/abs/2106.08502)

    本文研究了用于计算高斯分布相对于最优输运度量的重心的算法，在Bures-Wasserstein流形上证明了新的测地凸性结果，提供了更强的迭代控制，实现了无维收敛率，同时还提供了用于这些问题的Riemannian GD 的第一个收敛保证。

    

    我们研究了用于计算高斯分布相对于最优输运度量的重心的一阶优化算法。尽管目标是测地不凸的，但测地梯度下降在经验上快速收敛，实际上比诸如欧几里德梯度下降和SDP求解器等现成方法更快。这与Riemannian GD的已知的最佳理论结果形成了鲜明对比，后者是以指数方式依赖于维度的。在这项工作中，我们证明了新的测地凸性结果，提供了更强的迭代控制，从而得到了无维收敛率。我们的技术还使得对两种相关的平均概念 - 熵正则化的重心和几何中位数进行分析，为这些问题的Riemannian GD提供了第一个收敛保证。

    We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian GD empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP solvers. This stands in stark contrast to the best-known theoretical results for Riemannian GD, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for Riemannian GD for these problems.
    
[^143]: 利用半监督自编码器对受损数据进行分类和不确定性量化

    Classification and Uncertainty Quantification of Corrupted Data using Semi-Supervised Autoencoders. (arXiv:2105.13393v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.13393](http://arxiv.org/abs/2105.13393)

    本研究提出了一种半监督自编码器方法，用于分类和量化受损数据的不确定性。该方法使用生成模型来描述受损数据，并通过监督自编码器的潜在空间实现分类，可同时对分类和不确定性进行处理。

    

    参数化和非参数化分类器经常不得不处理真实世界中的数据，其中噪声、遮挡和模糊等污染是不可避免的，带来了重大挑战。本文提出了一种概率方法，用于分类强烈受损的数据并量化不确定性，尽管模型仅在未受损的数据上进行了训练。底层架构是一个只在未经污染的数据上进行训练的半监督自编码器。我们使用解码部分作为真实数据的生成模型，并通过卷积、掩蔽和加性高斯噪声来描述其不完美之处。这构成了一个统计推断问题，涉及到底层未受污染数据的最佳潜在空间激活。我们使用度量高斯变分推断（MGVI）来近似解决此问题。自编码器潜在空间的监督使我们能够在不确定性下直接对受损数据进行分类，同时使用统计推断的潜在空间激活。

    Parametric and non-parametric classifiers often have to deal with real-world data, where corruptions like noise, occlusions, and blur are unavoidable posing significant challenges. We present a probabilistic approach to classify strongly corrupted data and quantify uncertainty, despite the model only having been trained with uncorrupted data. A semi-supervised autoencoder trained on uncorrupted data is the underlying architecture. We use the decoding part as a generative model for realistic data and extend it by convolutions, masking, and additive Gaussian noise to describe imperfections. This constitutes a statistical inference task in terms of the optimal latent space activations of the underlying uncorrupted datum. We solve this problem approximately with Metric Gaussian Variational Inference (MGVI). The supervision of the autoencoder's latent space allows us to classify corrupted data directly under uncertainty with the statistically inferred latent space activations. Furthermore
    
[^144]: 随机在线凸优化。应用于概率时间序列预测。

    Stochastic Online Convex Optimization. Application to probabilistic time series forecasting. (arXiv:2102.00729v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.00729](http://arxiv.org/abs/2102.00729)

    该论文介绍了一种随机在线凸优化框架，并将其应用于非平稳亚高斯时间序列的预测，取得了快速速率的随机遗憾度边界。

    

    我们介绍了一种通用的随机在线凸优化框架，以获得快速速率的随机遗憾度边界。我们证明在线牛顿步和一个缩放自由的伯恩斯坦在线聚合等算法在无界随机环境下实现了最佳已知速率。我们将我们的方法应用于校准非平稳亚高斯时间序列的参数概率预测器。我们的快速率随机遗憾度边界是任意时间有效的。我们的证明结合了自限定和泊松不等式，用于零增长和次高斯随机变量，分别在随机exp-凸性假设下。

    We introduce a general framework of stochastic online convex optimization to obtain fast-rate stochastic regret bounds. We prove that algorithms such as online newton steps and a scale-free 10 version of Bernstein online aggregation achieve best-known rates in unbounded stochastic settings. We apply our approach to calibrate parametric probabilistic forecasters of non-stationary sub-gaussian time series. Our fast-rate stochastic regret bounds are any-time valid. Our proofs combine self-bounded and Poissonnian inequalities for martingales and sub-gaussian random variables, respectively, under a stochastic exp-concavity assumption.
    
[^145]: VenoMave：面向语音识别的有针对性毒化攻击

    VenoMave: Targeted Poisoning Against Speech Recognition. (arXiv:2010.10682v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2010.10682](http://arxiv.org/abs/2010.10682)

    VenoMave是针对语音识别的第一种训练期毒化攻击，攻击者只能操纵一小部分训练数据而不会在运行时改变目标音频波形。

    

    尽管自动语音识别取得了显著的改进，但仍容易受到对抗性干扰。与标准的机器学习架构相比，这些攻击更加具有挑战性，尤其是因为语音识别系统的输入是包含语音的声学和语言属性的时间序列。提取所有识别相关信息需要更复杂的流程和一组专门的组件。因此，攻击者需要考虑整个流程。本文介绍了VenoMave，这是针对语音识别的第一种训练期毒化攻击。与主要研究规避攻击相似，我们追求相同的目标：将系统引导到目标音频波形的不正确和攻击者选择的转录。然而，与规避攻击不同的是，我们假定攻击者只能操纵一小部分训练数据，而不会在运行时改变目标音频波形。

    Despite remarkable improvements, automatic speech recognition is susceptible to adversarial perturbations. Compared to standard machine learning architectures, these attacks are significantly more challenging, especially since the inputs to a speech recognition system are time series that contain both acoustic and linguistic properties of speech. Extracting all recognition-relevant information requires more complex pipelines and an ensemble of specialized components. Consequently, an attacker needs to consider the entire pipeline. In this paper, we present VENOMAVE, the first training-time poisoning attack against speech recognition. Similar to the predominantly studied evasion attacks, we pursue the same goal: leading the system to an incorrect and attacker-chosen transcription of a target audio waveform. In contrast to evasion attacks, however, we assume that the attacker can only manipulate a small part of the training data without altering the target audio waveform at runtime. We e
    
[^146]: 关于线性汤普森抽样的频率后悔问题

    On Frequentist Regret of Linear Thompson Sampling. (arXiv:2006.06790v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.06790](http://arxiv.org/abs/2006.06790)

    本文研究了线性汤普森抽样的频率后悔问题，证明了后验方差膨胀是必需的，并确定了频率后悔的最低下限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$ 。

    

    本文研究随机线性赌博机问题，其中决策者从可能时变的$\mathbb{R}^d$向量集中选择行动并获得噪声奖励。目标是在一系列$T$个决策中最小化后悔，即决策者的累积预期奖励与能够访问每个行动预期奖励的神谕之间的差异。线性汤普森抽样(LinTS)是一种流行的贝叶斯启发式算法，通过理论分析表明其贝叶斯后悔受到$\widetilde{\mathcal{O}}(d\sqrt{T})$的界限约束，达到极小值下限。然而，先前的研究表明，LinTS的频率后悔界限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$，需要后验方差膨胀，并且比最佳基于乐观主义的算法差一个$\sqrt{d}$的因子。我们证明了这种膨胀是基本的，并且频率界限为$\widetilde{\mathcal{O}}(d\sqrt{dT})$是最佳的。

    This paper studies the stochastic linear bandit problem, where a decision-maker chooses actions from possibly time-dependent sets of vectors in $\mathbb{R}^d$ and receives noisy rewards. The objective is to minimize regret, the difference between the cumulative expected reward of the decision-maker and that of an oracle with access to the expected reward of each action, over a sequence of $T$ decisions. Linear Thompson Sampling (LinTS) is a popular Bayesian heuristic, supported by theoretical analysis that shows its Bayesian regret is bounded by $\widetilde{\mathcal{O}}(d\sqrt{T})$, matching minimax lower bounds. However, previous studies demonstrate that the frequentist regret bound for LinTS is $\widetilde{\mathcal{O}}(d\sqrt{dT})$, which requires posterior variance inflation and is by a factor of $\sqrt{d}$ worse than the best optimism-based algorithms. We prove that this inflation is fundamental and that the frequentist bound of $\widetilde{\mathcal{O}}(d\sqrt{dT})$ is the best pos
    
[^147]: 论牛顿筛选法

    On Newton Screening. (arXiv:2001.10616v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2001.10616](http://arxiv.org/abs/2001.10616)

    本文提出了一种称为牛顿筛选法的新型Broad-Newton方法，它带有一个内置的较小的工作集，可用于加速解决大规模稀疏学习问题的一阶方法。

    

    筛选和工作集技术是减小优化问题规模的重要方法，已广泛应用于加速解决大规模稀疏学习问题的一阶方法中。本文提出了一种新的筛选方法，称为牛顿筛选法（NS），它是一种带有内置筛选机制的广义牛顿方法。我们推导了基于等效KKT系统的Lasso模型，利用广义牛顿方法来求解KKT方程组。基于这个KKT系统，首先利用上一次迭代生成的原始和对偶变量之和确定一个具有相对较小大小的内置工作集，然后通过在工作集上求解最小二乘问题来更新原始变量，并基于闭式表达式更新对偶变量。此外，我们提出了一个带有热启动策略的牛顿筛选法的连续版本。我们证明了NS在最优收敛性方面具有优异的性质。

    Screening and working set techniques are important approaches to reducing the size of an optimization problem. They have been widely used in accelerating first-order methods for solving large-scale sparse learning problems. In this paper, we develop a new screening method called Newton screening (NS) which is a generalized Newton method with a built-in screening mechanism. We derive an equivalent KKT system for the Lasso and utilize a generalized Newton method to solve the KKT equations. Based on this KKT system, a built-in working set with a relatively small size is first determined using the sum of primal and dual variables generated from the previous iteration, then the primal variable is updated by solving a least-squares problem on the working set and the dual variable updated based on a closed-form expression. Moreover, we consider a sequential version of Newton screening (SNS) with a warm-start strategy. We show that NS possesses an optimal convergence property in the sense that
    
[^148]: 从带有歧视性质的训练数据中学习

    Learning from Discriminatory Training Data. (arXiv:1912.08189v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1912.08189](http://arxiv.org/abs/1912.08189)

    本文提出了一种公平学习方法，该方法能够在可能带有歧视的数据集上进行训练，且能够在公平的测试数据集上表现良好，且该方法可在消除歧视的情况下使用，并在受保护群体之间取得平衡。

    

    监督学习系统是通过历史数据训练的，如果这些数据受到歧视性质的影响，那么该系统可能会在保护组中产生歧视。本文提出了公平学习的方法，即使在潜在的歧视性的数据集上训练，也将在公平的测试数据集上表现良好。这样的数据集转变为特定公平学习方法的应用方案。例如，消除直接歧视可以被表示为特定的数据集转变问题。对于这种情况，我们提出了一种学习方法，该方法在盲目训练包含直接加性歧视的数据集的同时，在公平数据集上可以证明最小化模型误差。该方法与现有的法律体系兼容，并通过在受保护群体之间取得平衡来解决广泛讨论的受保护群体交叉的问题。从技术上讲，该方法应用了概率干预，并具有因果和反事实公式。

    Supervised learning systems are trained using historical data and, if the data was tainted by discrimination, they may unintentionally learn to discriminate against protected groups. We propose that fair learning methods, despite training on potentially discriminatory datasets, shall perform well on fair test datasets. Such dataset shifts crystallize application scenarios for specific fair learning methods. For instance, the removal of direct discrimination can be represented as a particular dataset shift problem. For this scenario, we propose a learning method that provably minimizes model error on fair datasets, while blindly training on datasets poisoned with direct additive discrimination. The method is compatible with existing legal systems and provides a solution to the widely discussed issue of protected groups' intersectionality by striking a balance between the protected groups. Technically, the method applies probabilistic interventions, has causal and counterfactual formulat
    

