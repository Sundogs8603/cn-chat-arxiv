# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Expressive Text-to-Image Generation with Rich Text.](http://arxiv.org/abs/2304.06720) | 本文提出了一种使用富文本编辑器生成表达性文本图像的方法，可以通过局部样式控制、明确的标记重新加权、精确的颜色渲染和详细的区域合成，生成高质量且多样化的图像。 |
| [^2] | [Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance.](http://arxiv.org/abs/2304.06715) | 本文提出了解释不变性和等变性的概念，通过对对称群下具有不变性的神经网络，建立两种度量方法来提高解释方法对于不变性的健壮性并证明为一些流行的解释方法提供了理论健壮性保证。 |
| [^3] | [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields.](http://arxiv.org/abs/2304.06706) | 本文提出了一种 Zip-NeRF 技术，将 mip-NeRF 360 和基于网格的模型相结合，以实现抗锯齿、提高训练速度并降低误差率。 |
| [^4] | [Learning Personalized Decision Support Policies.](http://arxiv.org/abs/2304.06701) | 本文提出了一种学习个性化决策支持策略的算法 $\texttt{THREAD}$，可以为决策者提供不同形式的支持。同时，引入了 $\texttt{Modiste}$ 工具来提供个性化的医学诊断决策支持，使用 $\texttt{THREAD}$ 学习个性化决策支持策略，有效提高了预期的诊断正确性，并减少了严重并发症的风险，同时推荐了更少和更便宜的研究。 |
| [^5] | [Learning Controllable 3D Diffusion Models from Single-view Images.](http://arxiv.org/abs/2304.06700) | 该论文介绍了一种名为Control3Diff的三维扩散模型，结合了扩散模型和3D GANs的优点，可以用于单视图数据集的多功能、可控的三维感知图像合成。 |
| [^6] | [Improving novelty detection with generative adversarial networks on hand gesture data.](http://arxiv.org/abs/2304.06696) | 本研究提出了一种使用生成对抗网络框架下的人工神经网络来解决识别未知手势问题的新方法，该方法在样本生成质量和分类测试中均表现出优异性能。 |
| [^7] | [OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems.](http://arxiv.org/abs/2304.06686) | 本文提出了一种名为 OKRidge 的方法，用于确定非线性动态系统的稀疏控制方程，并通过求解稀疏岭回归问题，实现了可扩展性和快速性，和现有方法相比，有着更高的效率。 |
| [^8] | [Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation.](http://arxiv.org/abs/2304.06671) | 本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。 |
| [^9] | [Do deep neural networks have an inbuilt Occam's razor?.](http://arxiv.org/abs/2304.06670) | 该研究利用基于函数先验的贝叶斯视角来研究深度神经网络（DNNs）的表现来源，结果表明DNNs之所以成功，是因为它对于具有结构的数据，具备一种内在的奥卡姆剃刀式的归纳偏差，足以抵消函数数量及复杂度的指数级增长。 |
| [^10] | [D-SVM over Networked Systems with Non-Ideal Linking Conditions.](http://arxiv.org/abs/2304.06667) | 本论文讨论了具有非线性链接条件的多智能体网络的分布式支持向量机，提出了解决目标优化约束的一种动态平衡有向网络的奇数扇区限制非线性映射方法。 |
| [^11] | [G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection.](http://arxiv.org/abs/2304.06653) | G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。 |
| [^12] | [How Useful are Educational Questions Generated by Large Language Models?.](http://arxiv.org/abs/2304.06638) | 本文研究通过结合CTG和问题分类生成的输出，通过教师评估证明这些生成的问题质量高且足够有用，有极大的应用潜力。 |
| [^13] | [PGTask: Introducing the Task of Profile Generation from Dialogues.](http://arxiv.org/abs/2304.06634) | 对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。 |
| [^14] | [CoSDA: Continual Source-Free Domain Adaptation.](http://arxiv.org/abs/2304.06627) | 提出了一种名为CoSDA的持续无源域适应的方法，采用双速度优化的师生模型对并配备有一致性学习能力，旨在减轻灾难性遗忘的问题，并在实验中取得了较优的表现。 |
| [^15] | [Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation.](http://arxiv.org/abs/2304.06600) | 本文提出了一种“无损适应”的方法，成功地将预训练视觉模型应用于机器人操纵中，并在不改变原始模型的情况下显著提高了性能。 |
| [^16] | [Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints.](http://arxiv.org/abs/2304.06596) | 该论文介绍了一种带有组公平性约束的随机子集选择的框架，并提出了一个全新的优化方法，可以优化一系列超出次模性范围的问题。在测试中，该框架可以实现组公平性而不牺牲太多效用。 |
| [^17] | [Solving Tensor Low Cycle Rank Approximation.](http://arxiv.org/abs/2304.06594) | 该论文介绍了如何解决张量低周期秩近似问题，这是自然语言处理、语言翻译和语音识别中重要的计算任务。 |
| [^18] | [Adversarial Examples from Dimensional Invariance.](http://arxiv.org/abs/2304.06575) | 对抗样本产生的原因是对于输入数据近似双射映射所规定的维度不变性导致的近似不连续性。 |
| [^19] | [Bayes classifier cannot be learned from noisy responses with unknown noise rates.](http://arxiv.org/abs/2304.06574) | 本文研究了在有噪声标签的情况下训练分类器的问题，发现贝叶斯决策规则通常无法识别，并提出了一种简单算法来学习贝叶斯决策规则，不需要知道噪声分布。 |
| [^20] | [counterfactuals: An R Package for Counterfactual Explanation Methods.](http://arxiv.org/abs/2304.06569) | 该论文介绍了一个统一且模块化的 R6 接口，用于具体实现反事实解释方法。通过实现三种方法并推广到不同的情境中，结合真实用例，此方法能够快速准确地得出有关如何更改单个观测值的特征值以获得所需预测的信息。 |
| [^21] | [Deep reinforcement learning applied to an assembly sequence planning problem with user preferences.](http://arxiv.org/abs/2304.06567) | 本文研究了将深度强化学习应用于装配序列规划问题，引入参数行动以提高训练时间和样本效率，并使用了两种不同的奖励信号。研究结果表明，三种最强大的深度RL方法，A2C、DQN和Rainbow都能够解决这个问题。 |
| [^22] | [Decentralized federated learning methods for reducing communication cost and energy consumption in UAV networks.](http://arxiv.org/abs/2304.06551) | 本文提出了两种去中心化联邦学习方法：交换律联邦学习和轮流联邦学习。这些方法可以降低通信成本和能耗，同时确保数据隐私。 |
| [^23] | [Multi-kernel Correntropy-based Orientation Estimation of IMUs: Gradient Descent Methods.](http://arxiv.org/abs/2304.06548) | 本文提出了两种基于重对比损失的算法，用于IMU定向估计，相比传统方法具有更好的准确性、鲁棒性和计算效率。 |
| [^24] | [Temporal Knowledge Sharing enable Spiking Neural Network Learning from Past and Future.](http://arxiv.org/abs/2304.06540) | 本文提出了一种时间知识共享方法（TKS），在不同时刻之间交互信息，并辅助真实标签引导脉冲神经网络（SNN）的训练，以实现SNN对过去和未来的学习。实验证明，在多个数据集上使用TKS可以获得当前最优的性能。 |
| [^25] | [An Efficient Transfer Learning-based Approach for Apple Leaf Disease Classification.](http://arxiv.org/abs/2304.06520) | 本研究提出了一种基于转移学习的苹果叶病识别技术，通过预训练的EfficientNetV2S架构提取特征并结合分类器块进行预测。该研究解决了类不平衡的问题，对各种超参数进行了仔细调查，为苹果树农提供了更加快速高效的叶病分类解决方案。 |
| [^26] | [Secure Federated Learning for Cognitive Radio Sensing.](http://arxiv.org/abs/2304.06519) | 本文探讨了在认知无线电环境下基于联邦学习实现可靠和安全的频谱感知（SS），深入分析了FL在SS中的动机、架构和算法，同时提供了安全和隐私威胁的对抗措施。 |
| [^27] | [ML-Enabled Outdoor User Positioning in 5G NR Systems via Uplink SRS Channel Estimates.](http://arxiv.org/abs/2304.06514) | 本文研究了通过机器学习技术在5G NR系统中使用上行SRS信道估计进行用户定位，证明了在商用5G环境中即使使用很少的数据，也可以用小型神经网络实现具有米级精度的室外用户定位。 |
| [^28] | [Philosophical Foundations of GeoAI: Exploring Sustainability, Diversity, and Bias in GeoAI and Spatial Data Science.](http://arxiv.org/abs/2304.06508) | 本文介绍了GeoAI和空间数据科学的哲学基础，分别从可持续性、训练数据中的偏差、模式知识的多样性和系统中的中立性缺失等角度出发，为我们设计、培训和部署基于GeoAI的系统提供了帮助，也为我们理解人工智能和机器学习研究的利益和潜在危险提供了共同理解。 |
| [^29] | [Variations of Squeeze and Excitation networks.](http://arxiv.org/abs/2304.06502) | 本文提出了Squeeze and Excitation网络的变体来改进重要特征的学习过程，从而提高神经网络的性能。实验表明这些变体在残差网络上效果良好。 |
| [^30] | [EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition.](http://arxiv.org/abs/2304.06496) | EEGMatch是一种半监督学习框架，可用于脑电情绪识别。通过基于EEG-Mixup的数据增强方法和半监督多域自适应方法，可以有效提高情绪识别准确性和稳定性。 |
| [^31] | [An embedding for EEG signals learned using a triplet loss.](http://arxiv.org/abs/2304.06495) | 本文提出了一种使用三元组损失学习的EEG信号嵌入方法，通过无监督学习直接学习EEG信号的低维度和可转移表示，并在公开的EEG数据集上表现出优异的迁移能力。 |
| [^32] | [Fault diagnosis for PV arrays considering dust impact based on transformed graphical feature of characteristic curves and convolutional neural network with CBAM modules.](http://arxiv.org/abs/2304.06493) | 本文提出了一种新的PV阵列故障诊断方法，可以考虑灰尘影响并通过将Is-Voc normalized Gramian angular difference field方法与卷积神经网络和CBAM模块相结合，准确地识别多种复杂故障，实验结果证明其准确性与有效性。 |
| [^33] | [A New Paradigm for Device-free Indoor Localization: Deep Learning with Error Vector Spectrum in Wi-Fi Systems.](http://arxiv.org/abs/2304.06490) | 本论文提出了一种基于误差向量谱的深度学习方案，用于解决无需设备的室内定位中的RFO问题。该方案通过物理层信号中提取的信道特征进行人员位置分类，性能更优于现有技术。 |
| [^34] | [Domain Adaptation for Inertial Measurement Unit-based Human Activity Recognition: A Survey.](http://arxiv.org/abs/2304.06489) | 本文综述了惯性测量单元人体活动识别中利用领域自适应技术解决数据分布异质性问题的最新进展。 |
| [^35] | [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era.](http://arxiv.org/abs/2304.06488) | ChatGPT是生成式AI的一小步，也是AGI的一大步，我们进行了综述，并对其如何演变为AIGC展望不同于以往的通用AI生成内容的发展道路。 |
| [^36] | [CoRe-Sleep: A Multimodal Fusion Framework for Time Series Robust to Imperfect Modalities.](http://arxiv.org/abs/2304.06485) | CoRe-Sleep是一种多模态融合框架，特别关注于提高对不完善数据的信号分析的鲁棒性，它通过适当处理多模态信息，容忍噪声或丢失的模态片段，展现最先进的性能。 |
| [^37] | [Exploring Gender and Race Biases in the NFT Market.](http://arxiv.org/abs/2304.06484) | 本研究测试了 CryptoPunks 和 NFT市场中的种族和性别偏见。结果发现存在种族偏见而非性别偏见。同时，我们引入了一个带有性别标签的NFT艺术品数据集，以促进这个新兴市场的社会平等研究。 |
| [^38] | [Joint optimization of a $\beta$-VAE for ECG task-specific feature extraction.](http://arxiv.org/abs/2304.06476) | 本文研究了使用$\beta$-VAE作为可解释特征提取器，并联合优化信号重建和心脏功能预测。在7255名患者的数据上进行测试，显示出相比先前方法，该方法显著改善了预测能力和可解释性。 |
| [^39] | [Two Heads are Better than One: A Bio-inspired Method for Improving Classification on EEG-ET Data.](http://arxiv.org/abs/2304.06471) | 该论文提出了一种生物启发的EEG数据分类方法，将特征选择和时间分割相结合，显着提高了机器学习分类器的性能，同时降低了计算复杂度。 |
| [^40] | [Analysing Fairness of Privacy-Utility Mobility Models.](http://arxiv.org/abs/2304.06469) | 本研究为人类移动性定义了一组公平度量指标，基于轨迹的结构相似性和熵，研究了两种依靠生成对抗网络和表示学习降低用户的重新识别率的隐私保护模型，并探讨了它们的公平性优势和差异。 |
| [^41] | [SpectFormer: Frequency and Attention is what you need in a Vision Transformer.](http://arxiv.org/abs/2304.06446) | 本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。 |
| [^42] | [In-Distribution and Out-of-Distribution Self-supervised ECG Representation Learning for Arrhythmia Detection.](http://arxiv.org/abs/2304.06427) | 本文系统研究了自监督学习方法在ECG表征学习上的应用，首次对三个常用ECG心律失常数据集进行了分布分析，实验发现SwAV方法表现最佳，能够超越传统的有监督学习方法，还具有较强的鲁棒性，有望在大规模和多样化人群中检测心律失常。 |
| [^43] | [Quantifying and Explaining Machine Learning Uncertainty in Predictive Process Monitoring: An Operations Research Perspective.](http://arxiv.org/abs/2304.06412) | 本论文提出了一种综合的、多阶段的机器学习方法，利用分位数回归森林生成区间预测来解决预测流程监控中的问题，同时使用SHapley可加解释来解释模型不确定性的来源。 |
| [^44] | [Learning Accurate Performance Predictors for Ultrafast Automated Model Compression.](http://arxiv.org/abs/2304.06393) | 本文提出了一种超快速自动模型压缩框架SeerNet，通过直接优化具有准确性能预测器的压缩策略来实现对各种计算成本约束的超快速自动模型压缩。 |
| [^45] | [VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking.](http://arxiv.org/abs/2304.06391) | VISION DIFFMASK提出了一种可解释性的方法，通过使用门控机制识别最小输入子集来预测对其最终预测有贡献的输入部分。 |
| [^46] | [Multi-Subset Approach to Early Sepsis Prediction.](http://arxiv.org/abs/2304.06384) | 本文提出了一种多子集方法，将不同特征子集的多个机器学习模型集成起来，可在ICU患者中早期预测感染性休克的发生。 |
| [^47] | [Neural State-Space Models: Empirical Evaluation of Uncertainty Quantification.](http://arxiv.org/abs/2304.06349) | 本文以贝叶斯概率设置为框架，提出了神经态空间模型系统识别的不确定性量化方法，给出了后验分布、可信区间及惊异指数，以有效甄别模型在分布外情况下的使用可能带来的危险性。 |
| [^48] | [Streamlined Framework for Agile Forecasting Model Development towards Efficient Inventory Management.](http://arxiv.org/abs/2304.06344) | 本文提出了一个敏捷预测模型开发的框架，通过简化核心组件之间的连接使得新数据集能够快速和稳健地集成，并选择最佳模型。通过不同的评估指标，找到最适合不同应用的模型。该框架能够应用在库存管理环境中，提高效率。 |
| [^49] | [Attributed Multi-order Graph Convolutional Network for Heterogeneous Graphs.](http://arxiv.org/abs/2304.06336) | 本文提出了一个AMOGCN模型，它自动从多阶邻接矩阵的自适应聚合中研究包含多跳邻居的元路径，并使用节点属性评价监督。其能够有效地从异构图中发现有区别的节点嵌入和关系。 |
| [^50] | [Deep Learning-based Fall Detection Algorithm Using Ensemble Model of Coarse-fine CNN and GRU Networks.](http://arxiv.org/abs/2304.06335) | 该研究提出一种基于粗细CNN和GRU网络的深度学习集成模型，用于更可靠的跌倒检测，能够还原不同的空间特征粒度，并捕获时间依赖关系以进行特征表示。 |
| [^51] | [Priors for symbolic regression.](http://arxiv.org/abs/2304.06333) | 本文提出了一种在符号回归（SR）框架内将有关函数和参数的详细先验信息纳入的方法，并且演示了该先验在基准数据集和材料科学应用中的性能。 |
| [^52] | [Understanding Overfitting in Adversarial Training in Kernel Regression.](http://arxiv.org/abs/2304.06326) | 本文研究了核回归的对抗训练和带噪声的数据增强，发现如果没有适当的正则化，这两种方法可能会导致过拟合现象，但适当的正则化可以缓解这种现象，提高性能。 |
| [^53] | [Sequential Monte Carlo applied to virtual flow meter calibration.](http://arxiv.org/abs/2304.06310) | 提出了一种利用顺序蒙特卡罗方法进行虚拟流量计校准的新方法，该方法可以连续地联合校准VFMs，即使单独井流量高度不平衡也能提供准确的校准。 |
| [^54] | [Improved Naive Bayes with Mislabeled Data.](http://arxiv.org/abs/2304.06292) | 该论文提出了一种改进的朴素贝叶斯算法来处理误标签数据，通过指定误标签的生成机制，使用EM算法迭代优化对数似然函数来提高分类性能。 |
| [^55] | [Model-based Dynamic Shielding for Safe and Efficient Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2304.06281) | 本论文介绍了模型驱动的动态屏蔽设计用于多智能体强化学习中的安全保障，屏蔽器能够动态分割、合并和重新计算智能体状态，同时支持更加高效的合成屏蔽器以监控复杂环境中的智能体。 |
| [^56] | [Optimizing Multi-Domain Performance with Active Learning-based Improvement Strategies.](http://arxiv.org/abs/2304.06277) | 本文提出了一个基于主动学习的框架，用于改善多领域性能。该方法分为两个阶段，在保证高效性的前提下实现了最先进的性能。 |
| [^57] | [Canonical and Noncanonical Hamiltonian Operator Inference.](http://arxiv.org/abs/2304.06262) | 介绍了一种结构保留的模型简化方法，可以用于规范和非规范哈密顿系统，具有收敛性和良好的保守性质。 |
| [^58] | [MProtoNet: A Case-Based Interpretable Model for Brain Tumor Classification with 3D Multi-parametric Magnetic Resonance Imaging.](http://arxiv.org/abs/2304.06258) | 本论文提出了一种基于案例的可解释性模型MProtoNet，用于带有3D多参数磁共振成像的脑肿瘤分类，通过引入新型的注意模块，比四个状态-of-the-art深度学习模型在解释性和分类性能上有所提高。 |
| [^59] | [Enhancing Model Learning and Interpretation Using Multiple Molecular Graph Representations for Compound Property and Activity Prediction.](http://arxiv.org/abs/2304.06253) | 本文研究了使用多种分子图表示增强化合物属性和活性预测中的模型学习和解释能力的方法，并提出了利用可解释性方法增强图神经网络模型的解释性能力，对于药物发现有重要帮助。 |
| [^60] | [Asymmetrically-powered Neural Image Compression with Shallow Decoders.](http://arxiv.org/abs/2304.06244) | 采用浅层或线性解码转换来缩小解码复杂度，同时利用通常不对称的计算预算、更强的编码网络和迭代编码来保持压缩性能，实现了速率失真性能与传统方法相竞争，解码复杂度降低80%以上。 |
| [^61] | [An Arrhythmia Classification-Guided Segmentation Model for Electrocardiogram Delineation.](http://arxiv.org/abs/2304.06237) | 本文提出了一种利用深度学习模型结合心律失常分类指导的心电图分割方法，能够准确划分广泛异常节律类型的信号，减少虚报检测。 |
| [^62] | [Physics-informed radial basis network (PIRBN): A local approximation neural network for solving nonlinear PDEs.](http://arxiv.org/abs/2304.06234) | PIRBN是一种局部逼近神经网络，适用于求解具有高频特征和不适定计算域的PDE方程，相比PINN更加高效有效。通过使用梯度下降法训练PIRBN可以收敛到高斯过程。 |
| [^63] | [Situational-Aware Multi-Graph Convolutional Recurrent Network (SA-MGCRN) for Travel Demand Forecasting During Wildfires.](http://arxiv.org/abs/2304.06233) | 本研究提出一种新的方法框架，利用大规模GPS数据和最先进的人工智能技术，建立了采用多种数据源的出行生成模型，并提出了基于SA-MGCRN的情境感知多图卷积递归网络以实现野火疏散时交通需求的实时预测。 |
| [^64] | [Difficult Lessons on Social Prediction from Wisconsin Public Schools.](http://arxiv.org/abs/2304.06205) | 美国公立学校引入的预测算法（EWS）未能提高毕业率，EWS准确性高，但环境因素影响更大。 |
| [^65] | [SURFSUP: Learning Fluid Simulation for Novel Surfaces.](http://arxiv.org/abs/2304.06197) | SURFSUP采用有符号距离函数连续表示对象，提供更准确和高效的流体对象相互作用的学习方法；且能够适用于分布之外的复杂真实场景和对象，可以反演适用于物体操纵流体流动。 |
| [^66] | [Learning Over All Contracting and Lipschitz Closed-Loops for Partially-Observed Nonlinear Systems.](http://arxiv.org/abs/2304.06193) | 本文提出了一种针对非线性部分观测动态系统的学习控制策略参数化，能够自动满足闭环系统的稳定性和用户可调整的鲁棒性条件，在两个强化学习任务的模拟中表现良好且有强鲁棒性。 |
| [^67] | [Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model.](http://arxiv.org/abs/2304.06174) | 本文开发了一种物体感知 SE(3) 等变扩散模型，可以在几秒钟内精确地生成过渡态结构，与基于量子化学的优化相比，计算时间大大缩短，其生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差，可以实现反应速率估计所需的精度。 |
| [^68] | [NP-Free: A Real-Time Normalization-free and Parameter-tuning-free Representation Approach for Open-ended Time Series.](http://arxiv.org/abs/2304.06168) | 提出开放式时间序列表示方法NP-Free, 实时处理速度且无需归一化和参数调节。 |
| [^69] | [Learning Robust and Correct Controllers from Signal Temporal Logic Specifications Using BarrierNet.](http://arxiv.org/abs/2304.06160) | 本文提出了一个通用的过程，构造出可训练的控制障碍函数，强制实现STL中某一片段的规范满足，同时使用BarrierNet作为神经网络控制器最后一层，保证规范的满足，提高控制器的鲁棒性。 |
| [^70] | [The growclusters Package for R.](http://arxiv.org/abs/2304.06145) | R语言的growclusters软件包实现了增强版的k-means聚类算法，可以发现多组数据集中的局部聚类或分区，函数包含估计多元数据分区结构的功能，使用惩罚优化方法进行。并可创建可视化应用程序展示其操作和功能。 |
| [^71] | [An Edit Friendly DDPM Noise Space: Inversion and Manipulations.](http://arxiv.org/abs/2304.06140) | 本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。 |
| [^72] | [Towards Evaluating Explanations of Vision Transformers for Medical Imaging.](http://arxiv.org/abs/2304.06133) | 本文研究了多种方法在应用于医学图像分类的Vision Transformer上的性能，并说明逐层相关性传播比局部可解释的模型无关解释和关注可视化提供更准确和可靠的ViT所学习的表示。 |
| [^73] | [UniverSeg: Universal Medical Image Segmentation.](http://arxiv.org/abs/2304.06131) | UniverSeg是一种用于解决未见医学图像分割任务的通用方法，无需额外的训练。该方法采用交叉块机制来生成准确的分割地图，并使用收集的53个开放医学数据集进行推广。 |
| [^74] | [Label-Free Concept Bottleneck Models.](http://arxiv.org/abs/2304.06129) | 无标签CBM是一个可解释的框架，能够将任何神经网络转化为CBM，并且不需要标记数据，同时保持高准确性。 |
| [^75] | [AutoShot: A Short Video Dataset and State-of-the-Art Shot Boundary Detection.](http://arxiv.org/abs/2304.06116) | AutoShot 发布了一份新的短视频镜头边界检测数据集，采用名为 AutoShot 的方法进行模型设计优化，比之前的最新技术水平在 F1 分数上获得更高的准确性。 |
| [^76] | [PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting.](http://arxiv.org/abs/2304.06107) | PATMAT使用参考图像和微调技术有效地保留了面部修补中的细节和人物身份。 |
| [^77] | [Primal-Dual Contextual Bayesian Optimization for Control System Online Optimization with Time-Average Constraints.](http://arxiv.org/abs/2304.06104) | 提出了一种基于原始-对偶语境贝叶斯优化算法，可以实现对约束闭环控制系统的在线性能优化，同时满足所需的约束条件。 |
| [^78] | [Fast emulation of cosmological density fields based on dimensionality reduction and supervised machine-learning.](http://arxiv.org/abs/2304.06099) | 本研究使用简单的机器学习方法，通过降维和监督式回归，对暗物质密度场进行快速而准确的仿真，从而有效地应对复杂参数空间的挑战。 |
| [^79] | [Energy-guided Entropic Neural Optimal Transport.](http://arxiv.org/abs/2304.06094) | 本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。 |
| [^80] | [Efficient Deep Learning Models for Privacy-preserving People Counting on Low-resolution Infrared Arrays.](http://arxiv.org/abs/2304.06059) | 本文比较了六种不同的高效深度学习模型对低分辨率红外阵列的人流量计算的性能，通过全面的探索获得了富有成效的 Pareto 最优解，实现了高准确性和低成本同时满足的目标。 |
| [^81] | [Maximal Fairness.](http://arxiv.org/abs/2304.06057) | 本文通过识别可以同时满足的常用公平性措施的最大集，填补了“不可能定理”的空白，从而得出了12个最大集是可能的这一结论。 |
| [^82] | [Landslide Susceptibility Prediction Modeling Based on Self-Screening Deep Learning Model.](http://arxiv.org/abs/2304.06054) | 本文提出了一种基于自筛选深度学习模型的滑坡易发性预测建模方法，通过自筛选网络和图卷积网络提取环境因素之间的非线性关系，具有更好的性能。 |
| [^83] | [Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling.](http://arxiv.org/abs/2304.06052) | 本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。 |
| [^84] | [Open-TransMind: A New Baseline and Benchmark for 1st Foundation Model Challenge of Intelligent Transportation.](http://arxiv.org/abs/2304.06051) | Open-TransMind是智能交通领域第一个基础模型挑战赛的新基准，旨在解决数据量少、泛化能力差以及缺乏多模态技术等典型挑战。 |
| [^85] | [Exact and Cost-Effective Automated Transformation of Neural Network Controllers to Decision Tree Controllers.](http://arxiv.org/abs/2304.06049) | 本文研究了将基于神经网络的控制器转换为等效软决策树控制器并提出了一种自动且节约成本的转换算法。该方法适用于包括ReLU激活函数在内的离散输出NN控制器，并能够提高形式验证的运行效率。 |
| [^86] | [RELS-DQN: A Robust and Efficient Local Search Framework for Combinatorial Optimization.](http://arxiv.org/abs/2304.06048) | 该论文提出了一个名为RELS-DQN的轻量级DQN框架，可以展现局部搜索行为并提供实用的可扩展性，其在多个应用程序上具有类似局部搜索算法的效果，并且解决方案值要高于或等于局部搜索算法和专家设计的启发式方法。 |
| [^87] | [Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN.](http://arxiv.org/abs/2304.06044) | 通过物理训练的神经网络可解决非线性材料行为的本构关系，无需初始数据，避免重复的牛顿迭代。训练好的模型可作为有限元程序的用户定义材料模型，但需要解决诸多挑战。 |
| [^88] | [Deep Learning Systems for Advanced Driving Assistance.](http://arxiv.org/abs/2304.06041) | 本论文提出了一种智能驾驶辅助的深度学习系统，利用生物传感系统来重构汽车驾驶员的生理注意力状态，该探针通过深度学习系统分析和处理获得的PPG信号，以识别与驾驶员注意力水平相一致的特定模式。 |
| [^89] | [Knowledge-Distilled Graph Neural Networks for Personalized Epileptic Seizure Detection.](http://arxiv.org/abs/2304.06038) | 采用知识蒸馏方法，从通过全套电极数据训练的检测器中传输知识，构建了新的检测器，能够为个体患者定制少量通道，并提供了轻量级、高准确率的实现，相对于现有的基于全套电极的方案大为改善。 |
| [^90] | [Quantitative Trading using Deep Q Learning.](http://arxiv.org/abs/2304.06037) | 本文探讨了强化学习在量化交易中的运用，揭示了基于 RL 的交易算法的案例研究结果表明，它有潜力优于传统的交易算法。这一研究代表了一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。 |
| [^91] | [Quantifying the Impact of Data Characteristics on the Transferability of Sleep Stage Scoring Models.](http://arxiv.org/abs/2304.06033) | 本文通过评估不同数据特征对模型传递性的影响，提出了一种新的方法来帮助选择转移学习源数据集并优化深度学习模型的性能。 |
| [^92] | [Fairness: from the ethical principle to the practice of Machine Learning development as an ongoing agreement with stakeholders.](http://arxiv.org/abs/2304.06031) | 本文提出了一种支持伦理的迭代过程，旨在通过机器学习设计中的持续协议挑战不对称的权力动态，并支持团队在各个步骤中识别、减轻和监测偏差。 |
| [^93] | [ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation.](http://arxiv.org/abs/2304.05977) | ImageReward是一种通用的文本到图像生成的人类喜好奖励模型，它可以通过收集专家的比较数据集来解决生成模型的问题，并且在人类评估中表现出色，有望成为一种用于评估和改进文本到图像合成的自动度量标准。 |
| [^94] | [LMR: Lane Distance-Based Metric for Trajectory Prediction.](http://arxiv.org/abs/2304.05869) | LMR是一种基于车道距离的度量，适用于轨迹预测中的结构化环境，相比传统的欧氏距离度量更准确。 |
| [^95] | [Proximity Forest 2.0: A new effective and scalable similarity-based classifier for time series.](http://arxiv.org/abs/2304.05800) | Proximity Forest 2.0是一种新的有效且可扩展的基于相似性的时间序列分类器，优于先前最先进的基于相似性的分类器以及最先进的基于内核、神经网络和混合方法在特定数据集上的表现。 |
| [^96] | [Astroformer: More Data Might Not be All You Need for Classification.](http://arxiv.org/abs/2304.05350) | 该文提出了使用混合变换器 - 卷积架构的方法，结合新的堆栈设计、不同的相对自我注意层创建方式和精心选择的数据增强和正则化技术，从少量数据中学习，将此方法应用于Galaxy Zoo数据集，结果表明在少量数据的情况下取得了与以前方法相同的分类结果，并且不会损失性能。 |
| [^97] | [Model sparsification can simplify machine unlearning.](http://arxiv.org/abs/2304.04934) | 本文提出了一种基于模型稀疏化的机器反学习方案，称为prune first, then unlearn和sparsity-aware unlearning。此方案可以提高近似反学习器的多标准反学习性能，并在不同的场景中表现出一致的效果。 |
| [^98] | [Deep-learning based measurement of planetary radial velocities in the presence of stellar variability.](http://arxiv.org/abs/2304.04807) | 本文提出了一种基于深度学习的方法，使用神经网络来减少三年HARPS-N太阳-星形光谱中的恒星径向速度抖动。该方法能够以前无法想象的小行星径向速度检测精度，为缓解恒星径向速度变异提供了希望。 |
| [^99] | [Reflected Diffusion Models.](http://arxiv.org/abs/2304.04740) | 该论文提出了反射扩散模型，通过学习反射随机微分方程的扰动评分函数，将数据约束原则性地整合到生成过程中，以取代之前采用的导致不自然样本的阈值处理方案。 |
| [^100] | [Probably Approximately Correct Federated Learning.](http://arxiv.org/abs/2304.04641) | 本文提出了FedPAC框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。 |
| [^101] | [OpenAGI: When LLM Meets Domain Experts.](http://arxiv.org/abs/2304.04370) | 基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。 |
| [^102] | [PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling.](http://arxiv.org/abs/2304.04307) | PriorCVAE 提出了一种处理高斯过程先验 MCMC 参数推断的贝叶斯深度生成建模新方法，可通过将 VAE 建模条件化于随机过程超参数处理超参数推断与学习先验之间的信息流断裂问题。 |
| [^103] | [Counterfactual Explanations of Neural Network-Generated Response Curves.](http://arxiv.org/abs/2304.04063) | 本文提出一种使用反事实解释（CFEs）确定神经网络黑盒生成的响应曲线上最具相关性的特征的方法，并将其应用于工业资产预测维护的案例研究中，可以解释模型的行为并检测异常行为的潜在原因。 |
| [^104] | [EGC: Image Generation and Classification via a Single Energy-Based Model.](http://arxiv.org/abs/2304.02012) | EGC是一种使用单个神经网络在图像分类和图像生成任务中实现卓越性能的方法，可以较好地生成出高质量图像，并在多项数据集上实现了领先的分类结果。 |
| [^105] | [Reducing Discretization Error in the Frank-Wolfe Method.](http://arxiv.org/abs/2304.01432) | 本论文提出了两个改进方法：一个多步的Frank-Wolfe方法，直接应用优化的高阶离散化方案；以及一种具有较少离散化误差的LMO-平均方案，其收敛速率加速到$O(1/k^{3/2})$，从而更好地解决了Frank-Wolfe方法中的离散化误差问题。 |
| [^106] | [Using AI to Measure Parkinson's Disease Severity at Home.](http://arxiv.org/abs/2303.17573) | 该论文提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法，该方法可重复用于类似的运动任务，拥有较高的可靠性和准确性。 |
| [^107] | [Energy-efficient Task Adaptation for NLP Edge Inference Leveraging Heterogeneous Memory Architectures.](http://arxiv.org/abs/2303.16100) | adapter-ALBERT是一种高效的NLP模型优化方法，可以在实现多任务推理同时最大程度地实现数据重用，并提高对数据压缩方法的鲁棒性。 |
| [^108] | [Vibration Signal Denoising Using Deep Learning.](http://arxiv.org/abs/2303.11413) | 本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。 |
| [^109] | [Hardware-Aware Graph Neural Network Automated Design for Edge Computing Platforms.](http://arxiv.org/abs/2303.10875) | 本文提出了HGNAS框架，它是第一个面向资源受限的边缘设备的硬件感知图神经结构搜索框架。通过解耦GNN范式，它构建了一个精细的设计空间，并通过利用硬件性能预测器，在GNN架构设计中实现了硬件感知。实验结果表明，HGNAS实现了高效的GNN设计，显著提高了推理速度和减少了内存占用，同时保持竞争性的准确度，相较于手动设计模型而言。 |
| [^110] | [n-Step Temporal Difference Learning with Optimal n.](http://arxiv.org/abs/2303.07068) | 本文提出了使用SPSA算法求解n步时序差分学习中的最优n值的算法SDPSA，并证明了其收敛性和有效性。 |
| [^111] | [Hardware Acceleration of Neural Graphics.](http://arxiv.org/abs/2303.05735) | 本文研究了神经图形是否需要硬件支持，发现当前GPU性能无法满足对4K分辨率60FPS渲染的需求，且在增强现实/虚拟现实应用中性能缺口更大。作者确定输入编码和MLP内核是性能瓶颈。 |
| [^112] | [ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design.](http://arxiv.org/abs/2303.02155) | 本论文提出了一种新的结合交互式进化和大型语言模型的协作游戏设计框架，用于模拟典型的人类设计过程，并用大型语言模型进行非常复杂的创造性任务－思想的重组和变异。 |
| [^113] | [Evidence-empowered Transfer Learning for Alzheimer's Disease.](http://arxiv.org/abs/2303.01105) | 该研究提出了一种在阿尔茨海默病诊断中使用证据支持的转移学习方法，通过利用AD相关的辅助任务来学习MRI扫描中形态学特征的证据和可转移知识，提高了检测性能，同时更具有数据效率和可信度。 |
| [^114] | [K-SHAP: Policy Clustering Algorithm for Anonymous State-Action Pairs.](http://arxiv.org/abs/2302.11996) | 本文提出了一种名为K-SHAP的算法，来解决多个智能体保持匿名且仅有状态-动作对的情况下学习智能体决策的问题。 |
| [^115] | [With Shared Microexponents, A Little Shifting Goes a Long Way.](http://arxiv.org/abs/2302.08007) | 本论文提出了一种名为BDR的框架，用于评估窄精度格式。通过BDR，本文发现了一种基于共享微指数的新格式，其在大规模生成预训练和推理以及推荐系统方面的效果优于其他先进的量化方法。 |
| [^116] | [Data efficiency and extrapolation trends in neural network interatomic potentials.](http://arxiv.org/abs/2302.05823) | 本文研究了神经网络原子势模型在体系架构和优化选择方面的影响，揭示了分子动力学稳定性、数据效率和损失空间等趋势。研究结果表明，使用损失空间可视化和损失熵的度量可以预测NNIP的泛化能力。 |
| [^117] | [Towards Inferential Reproducibility of Machine Learning Research.](http://arxiv.org/abs/2302.04054) | 本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。 |
| [^118] | [Efficient Graph Field Integrators Meet Point Clouds.](http://arxiv.org/abs/2302.00942) | 本文提出了两种算法用于非欧几里得空间中的高效图场积分，适用于点云网格图或ε-最近邻图的表征方法，具有很强的实用性。 |
| [^119] | [ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients.](http://arxiv.org/abs/2301.11300) | 本文提出了一种基于梯度的零样本代理ZiCo，通过研究特定的梯度属性如何影响神经网络的收敛速度和泛化能力，ZiCo成为了第一个在多个NAS基准测试上一致优于朴素代理(#Params)的代理，可以显著降低寻找最佳神经结构的搜索成本。 |
| [^120] | [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture.](http://arxiv.org/abs/2301.08243) | 本论文提出了一种非生成方法的自监督学习架构，即Image-based Joint-Embedding Predictive Architecture（I-JEPA），可以生成高度语义图像表示，通过联合嵌入预测架构和掩模策略达到这一目的。 |
| [^121] | [A Novel Sparse Regularizer.](http://arxiv.org/abs/2301.07285) | 提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。 |
| [^122] | [Reconstructing Individual Data Points in Federated Learning Hardened with Differential Privacy and Secure Aggregation.](http://arxiv.org/abs/2301.04017) | 本文研究了在联邦学习被差分隐私和安全聚合保护的情况下，恶意服务器可以通过引入 Sybil 设备来重构用户数据的问题，揭示了其中的权力不平衡。 |
| [^123] | [Learning Subgrid-scale Models with Neural Ordinary Differential Equations.](http://arxiv.org/abs/2212.09967) | 本文提出了利用神经常微分方程学习亚网格尺度模型的新方法，可以提高计算流体动力学求解器的准确性和效率。该方法具有NODE优点，可以参数化亚网格尺度、近似耦合算子，并提高低阶求解器的效率。 |
| [^124] | [Collaborative Training of Medical Artificial Intelligence Models with non-uniform Labels.](http://arxiv.org/abs/2211.13606) | 本研究提出了一种灵活的联合学习方法(FFL)，可以协同训练异质化标注数据集来构建强大而稳健的深度学习模型，为不同机构间的广泛合作提供了一种有前途的替代方案。 |
| [^125] | [From Node Interaction to Hop Interaction: New Effective and Scalable Graph Learning Paradigm.](http://arxiv.org/abs/2211.11761) | 本文提出了一种新的跳跃交互范式，用于解决现有图神经网络（GNN）中存在的可扩展性限制和过度平滑问题。其核心思想是将节点之间的交互目标转换为节点内部经过预处理的多跳特征，并通过HopGNN框架实现跳跃交互。 |
| [^126] | [Token Turing Machines.](http://arxiv.org/abs/2211.09119) | 令牌图灵机是一种序列自回归Transformer模型，具有的外部存储器可以总结先前的历史并以有限的计算成本处理长序列，相比其他替代方法在序列视觉理解任务中表现更优。 |
| [^127] | [Quantum Similarity Testing with Convolutional Neural Networks.](http://arxiv.org/abs/2211.01668) | 本文提出了一种基于卷积神经网络的机器学习算法，通过测量数据构建量子态的低维表示进行相似性评估，可以对非高斯量子态进行相似性检测，并在准确性和效率方面优于以往方法。 |
| [^128] | [An Exponentially Converging Particle Method for the Mixed Nash Equilibrium of Continuous Games.](http://arxiv.org/abs/2211.01280) | 本文提出并分析了一种基于粒子的方法，用于计算具有连续纯策略集和对收益函数的一阶访问的两人零和博弈的混合纳什均衡问题，并在满足假设的情况下从任何初始化指数收敛于准确的解。 |
| [^129] | [Iterative Teaching by Data Hallucination.](http://arxiv.org/abs/2210.17467) | 本文提出了基于数据幻象教学（DHT）的迭代式教学方法，解决了在连续输入空间下教师提供示例的能力问题，并在多个挑战性的教学设置中验证了DHT的有效性。 |
| [^130] | [Self-Supervised Predictive Coding with Multimodal Fusion for Patient Deterioration Prediction in Fine-grained Time Resolution.](http://arxiv.org/abs/2210.16598) | 本研究提出了一种基于自监督预测编码和多模态融合的每小时病人恶化预测方法，以提高精细的时间分辨率下的预测准确性。在多项实验中，我们证明了该方法可以显著提高性能，尤其是针对远期预测任务。 |
| [^131] | [Addressing contingency in algorithmic (mis)information classification: Toward a responsible machine learning agenda.](http://arxiv.org/abs/2210.09014) | 本文重点讨论了机器学习（ML）启用的分类模型处理在线虚假信息和其他可能被识别为有害的内容时，对“真相”来源的合法性、权威性和客观性所采取的立场以及ML驱动的审查系统可能在不利影响方面产生的问题，分析了算法的偶然性和可能引起的评估误差。 |
| [^132] | [SQA3D: Situated Question Answering in 3D Scenes.](http://arxiv.org/abs/2210.07474) | 本文提出了一个新的任务，即评估具有场景理解能力的代理人在三维场景中的情境问答。基于650个场景的数据集为智能代理人的推理能力考察提供了广泛且大量的问题，这对当前的多模式，特别是3D推理模型提出了很大挑战。 |
| [^133] | [On Distillation of Guided Diffusion Models.](http://arxiv.org/abs/2210.03142) | 本论文提出了一种将免分类器的引导式扩散模型蒸馏为易于采样的模型的方法，以降低在推断时的计算成本，并且能够在像素空间生成高质量的图像。 |
| [^134] | [On The Relative Error of Random Fourier Features for Preserving Kernel Distance.](http://arxiv.org/abs/2210.00244) | 研究发现，对于大多数核，包括著名的拉普拉斯核，RFF不能使用低维近似核距离并保持小的相对误差。当核是解析的时候，RFF可以使用多项式维度实现$\epsilon$-相对误差，并且在特定应用中，维度边界得到了改进。 |
| [^135] | [PiFold: Toward effective and efficient protein inverse folding.](http://arxiv.org/abs/2209.12643) | PiFold 提出了一种新的残基特征提取器和 PiGNN 层，能够一次性生成蛋白质序列并提高恢复效果，在 CATH 4.2 上达到了 51.66% 的恢复率，推理速度比自回归竞争对手快 70 倍，在 TS50 和 TS500 上分别达到了 58.72% 和 60.42% 的恢复分数。 |
| [^136] | [KL-divergence Based Deep Learning for Discrete Time Model.](http://arxiv.org/abs/2208.05100) | 该论文提出了一种基于KL散度的深度学习程序，用于解决生存分析中短数据问题，通过将外部生存预测模型与新收集的时间至事件数据相结合来获得更好的性能和鲁棒性。 |
| [^137] | [Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach.](http://arxiv.org/abs/2208.04405) | 这篇论文介绍了一种基于深度学习的方法，通过对观察到的时间序列数据进行特征向量计算，实现了部分可观察下的网络动态系统的图形恢复，因果推断机制优于最先进的同类机制，并且有很好的泛化性能。 |
| [^138] | [Model Reduction for Nonlinear Systems by Balanced Truncation of State and Gradient Covariance.](http://arxiv.org/abs/2207.14387) | 该论文提出了协变量平衡约简方法，使用共轭选取的快照来平衡系统的状态和基于共轭的梯度协方差矩阵，以解决降阶模型中对低方差坐标敏感的问题。 |
| [^139] | [Understanding Influence Maximization via Higher-Order Decomposition.](http://arxiv.org/abs/2207.07833) | 本文提出了一种利用Sobol指数对种子在IM中的影响和高阶相互作用进行分析的方法，通过此方法提出了一种名为SIM的IM算法，该算法通过过度选择节点来改善当前IM算法的性能。 |
| [^140] | [LaserMix for Semi-Supervised LiDAR Semantic Segmentation.](http://arxiv.org/abs/2207.00026) | 本文提出了一种名为LaserMix的半监督学习方法，利用LiDAR点云的强空间线索更好地利用未标记数据，具有通用性、统计基础和有效性，并在SemanticKITTI上取得了最优性能。 |
| [^141] | [Generative Modelling With Inverse Heat Dissipation.](http://arxiv.org/abs/2206.13397) | 该论文提出了一种新的类似扩散的模型来生成图像，它通过随机反转热方程在2D平面上运行来生成图像，并展示了与标准扩散模型不同的新颖定性性质，包括图像中整体颜色和形状的解缠绕现象。 |
| [^142] | [Variable importance without impossible data.](http://arxiv.org/abs/2205.15750) | 评估黑箱预测模型中变量重要性的流行方法不可信，因为使用了不可能的数据。本文提出一种名为Cohort Shapley的方法，它基于经济博弈理论，仅使用实际观测到的数据来量化变量重要性，可以解决算法公平性问题。 |
| [^143] | [Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions.](http://arxiv.org/abs/2205.13803) | 本文提出了一个新的视觉推理基准测试Bongard-HOI，它专注于从自然图像中学习人-物交互的组合性学习，挑战了现有最先进模型，鼓励开发更好的算法进行组合推理和泛化到新的HOI概念。 |
| [^144] | [On the Inconsistency of Kernel Ridgeless Regression in Fixed Dimensions.](http://arxiv.org/abs/2205.13525) | 在固定维度下，平移不变核的重要预测类别，如高斯核、拉普拉斯核和柯西核，在任何非零回归函数和任何带宽选择下都不具备“良性过拟合”特性。 |
| [^145] | [Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems.](http://arxiv.org/abs/2204.01815) | 本文介绍了一种新的一致性方法来解决矩阵和张量补全问题，在推荐系统应用中，我们证明了通过保留单位比例和一致性两个约束条件可以实现解的存在性与唯一性。 |
| [^146] | [Continual Learning from Demonstration of Robotics Skills.](http://arxiv.org/abs/2202.06843) | 该论文提出了一种持续学习示教方法，使用超网络和神经常微分方程求解器，可以记住长序列轨迹学习任务，而无需存储来自过去示教的任何数据。 |
| [^147] | [GoSafeOpt: Scalable Safe Exploration for Global Optimization of Dynamical Systems.](http://arxiv.org/abs/2201.09562) | GoSafeOpt是第一个能够安全探索高维系统并提供全局最优保证的算法。 |
| [^148] | [ADI: Adversarial Dominating Inputs in Vertical Federated Learning Systems.](http://arxiv.org/abs/2201.02775) | 本文研究了垂直联邦学习系统中的对抗性主导输入（ADIs），并证明了其在典型VFL系统中的存在。该研究为防止ADIs的使用提供了方法。 |
| [^149] | [When the Curious Abandon Honesty: Federated Learning Is Not Private.](http://arxiv.org/abs/2112.02918) | 联邦学习被认为是隐私保护的一种手段，然而本文研究表明，即使是一个被动的、诚实但好奇的攻击者观察到梯度，也可以重构参与协议的个人用户的数据。本文提出了一种新的数据重构攻击方法，让一个主动的、不诚实的中央方从接收到的梯度中高效地提取用户数据，并在流行的FL框架上展示了其有效性。 |
| [^150] | [Regret-Optimal LQR Control.](http://arxiv.org/abs/2105.01244) | 本文提出了一种动态后悔，通过在所有有界干扰下找到最小化最坏情况下后悔的因果控制器，实现了后悔最小LQR控制。 |
| [^151] | [Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence.](http://arxiv.org/abs/2104.08736) | 本文提出了一种用于深度学习的基于平均精度的方法来优化AUPRC，提出了一种可证收敛的SOAP算法。 |
| [^152] | [A method to integrate and classify normal distributions.](http://arxiv.org/abs/2012.14331) | 本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。 |
| [^153] | [The Role of Mutual Information in Variational Classifiers.](http://arxiv.org/abs/2010.11642) | 本文研究了基于随机编码的分类器的泛化误差，并得出了泛化误差受输入特征和潜空间表示之间互信息限制的结论。 |
| [^154] | [Semi-supervised Hypergraph Node Classification on Hypergraph Line Expansion.](http://arxiv.org/abs/2005.04843) | 本文提出了一种新的超图学习方法，即“线扩展(LE)”，该方法通过将顶点-超边对作为“线节点”，在超图中引出同构结构，适用于各种超图扩展并达到了显著优于SOTA的效果。 |

# 详细

[^1]: 富文本生成表达性文本图像

    Expressive Text-to-Image Generation with Rich Text. (arXiv:2304.06720v1 [cs.CV])

    [http://arxiv.org/abs/2304.06720](http://arxiv.org/abs/2304.06720)

    本文提出了一种使用富文本编辑器生成表达性文本图像的方法，可以通过局部样式控制、明确的标记重新加权、精确的颜色渲染和详细的区域合成，生成高质量且多样化的图像。

    

    纯文本已经成为文字到图像合成的流行界面。但是，它的定制选项有限，阻碍了用户精确描述所需的输出。为了解决这些挑战，我们提出使用支持字体样式、大小、颜色和脚注等格式的富文本编辑器。我们从富文本中提取每个字的属性，以启用局部样式控制、明确的标记重新加权、精确的颜色渲染和详细的区域合成。我们通过基于区域的扩散过程实现了这些功能。我们的实验表明，我们的方法可以比现有的文本到图像方法更好地生成高质量和多样化的图像。

    Plain text has become a prevalent interface for text-to-image synthesis. However, its limited customization options hinder users from accurately describing desired outputs. For example, plain text makes it hard to specify continuous quantities, such as the precise RGB color value or importance of each word. Furthermore, creating detailed text prompts for complex scenes is tedious for humans to write and challenging for text encoders to interpret. To address these challenges, we propose using a rich-text editor supporting formats such as font style, size, color, and footnote. We extract each word's attributes from rich text to enable local style control, explicit token reweighting, precise color rendering, and detailed region synthesis. We achieve these capabilities through a region-based diffusion process. We first obtain each word's region based on cross-attention maps of a vanilla diffusion process using plain text. For each region, we enforce its text attributes by creating region-s
    
[^2]: 通过解释不变性和等变性评估解释方法的健壮性

    Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance. (arXiv:2304.06715v1 [cs.LG])

    [http://arxiv.org/abs/2304.06715](http://arxiv.org/abs/2304.06715)

    本文提出了解释不变性和等变性的概念，通过对对称群下具有不变性的神经网络，建立两种度量方法来提高解释方法对于不变性的健壮性并证明为一些流行的解释方法提供了理论健壮性保证。

    

    只有当解释方法忠实地描述所解释的模型时，解释方法才有价值。本文考虑了神经网络，其预测在特定对称群下具有不变性，这包括从卷积神经网络到图神经网络的流行架构。任何忠实描述这种类型模型的解释都需要与该不变性属性一致。我们通过运用几何深度学习的形式化方法，通过解释不变性和等变性的概念来形式化这种直觉。通过这种严格的形式化方法，我们得出了（1）两个度量来衡量任何解释方法相对于模型对称群的健壮性;（2）一些流行的解释方法的理论健壮性保证；（3）提高任何解释方法相对于对称群的不变性的系统方法。通过在与不同对称群相关的模型的解释中经验地测量我们的度量标准，我们展示了解释不变性和等变性对于强大的解释方法是重要的属性。

    Interpretability methods are valuable only if their explanations faithfully describe the explained model. In this work, we consider neural networks whose predictions are invariant under a specific symmetry group. This includes popular architectures, ranging from convolutional to graph neural networks. Any explanation that faithfully explains this type of model needs to be in agreement with this invariance property. We formalize this intuition through the notion of explanation invariance and equivariance by leveraging the formalism from geometric deep learning. Through this rigorous formalism, we derive (1) two metrics to measure the robustness of any interpretability method with respect to the model symmetry group; (2) theoretical robustness guarantees for some popular interpretability methods and (3) a systematic approach to increase the invariance of any interpretability method with respect to a symmetry group. By empirically measuring our metrics for explanations of models associate
    
[^3]: Zip-NeRF：抗锯齿网格化神经辐射场

    Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields. (arXiv:2304.06706v1 [cs.CV])

    [http://arxiv.org/abs/2304.06706](http://arxiv.org/abs/2304.06706)

    本文提出了一种 Zip-NeRF 技术，将 mip-NeRF 360 和基于网格的模型相结合，以实现抗锯齿、提高训练速度并降低误差率。

    

    神经辐射场（NeRF）的网格化表示可以加速训练，但缺乏对比例的明确理解，容易引入锯齿或丢失场景内容。本文提出了一种将渲染和信号处理思想用于将 mip-NeRF 360 和基于网格的模型相结合，误差率比先前的技术低8%到76%，并比 mip-NeRF 360 快22倍的方法。

    Neural Radiance Field training can be accelerated through the use of grid-based representations in NeRF's learned mapping from spatial coordinates to colors and volumetric density. However, these grid-based approaches lack an explicit understanding of scale and therefore often introduce aliasing, usually in the form of jaggies or missing scene content. Anti-aliasing has previously been addressed by mip-NeRF 360, which reasons about sub-volumes along a cone rather than points along a ray, but this approach is not natively compatible with current grid-based techniques. We show how ideas from rendering and signal processing can be used to construct a technique that combines mip-NeRF 360 and grid-based models such as Instant NGP to yield error rates that are 8% - 76% lower than either prior technique, and that trains 22x faster than mip-NeRF 360.
    
[^4]: 学习个性化决策支持策略

    Learning Personalized Decision Support Policies. (arXiv:2304.06701v1 [cs.LG])

    [http://arxiv.org/abs/2304.06701](http://arxiv.org/abs/2304.06701)

    本文提出了一种学习个性化决策支持策略的算法 $\texttt{THREAD}$，可以为决策者提供不同形式的支持。同时，引入了 $\texttt{Modiste}$ 工具来提供个性化的医学诊断决策支持，使用 $\texttt{THREAD}$ 学习个性化决策支持策略，有效提高了预期的诊断正确性，并减少了严重并发症的风险，同时推荐了更少和更便宜的研究。

    

    个体决策者可能需要不同形式的支持来提高决策结果，但重要的问题是，哪种形式的支持会在低成本下导致准确的决策。本文提出了学习决策支持策略的方法，它在给定输入时选择是否以及如何提供支持。我们考虑没有先验信息的决策者，并将学习各自的策略形式化为一个多目标优化问题，这个问题权衡了准确性和成本。使用随机环境的技术，我们提出了 $\texttt{THREAD}$，这是一种个性化决策支持策略的在线算法，并设计了一种超参数调整策略，以利用模拟人类行为来确定成本-性能权衡。我们提供计算实验来证明 $\texttt{THREAD}$ 相对于线下基线的优势。然后，我们推出了一个交互式工具 $\texttt{Modiste}$，它为现实中的医学诊断提供个性化决策支持。$\texttt{Modiste}$ 使用 $\texttt{THREAD}$ 为每位医生学习个性化的决策支持策略，并推荐个性化研究以优化患者的预期结果并将严重并发症的风险降至最低。使用电子健康记录数据，我们展示了 $\texttt{Modiste}$ 显著提高了预期的诊断正确性，并减少了严重并发症的风险，同时推荐了更少和更便宜的研究。

    Individual human decision-makers may benefit from different forms of support to improve decision outcomes. However, a key question is which form of support will lead to accurate decisions at a low cost. In this work, we propose learning a decision support policy that, for a given input, chooses which form of support, if any, to provide. We consider decision-makers for whom we have no prior information and formalize learning their respective policies as a multi-objective optimization problem that trades off accuracy and cost. Using techniques from stochastic contextual bandits, we propose $\texttt{THREAD}$, an online algorithm to personalize a decision support policy for each decision-maker, and devise a hyper-parameter tuning strategy to identify a cost-performance trade-off using simulated human behavior. We provide computational experiments to demonstrate the benefits of $\texttt{THREAD}$ compared to offline baselines. We then introduce $\texttt{Modiste}$, an interactive tool that pr
    
[^5]: 从单视图图像学习可控三维扩散模型

    Learning Controllable 3D Diffusion Models from Single-view Images. (arXiv:2304.06700v1 [cs.CV])

    [http://arxiv.org/abs/2304.06700](http://arxiv.org/abs/2304.06700)

    该论文介绍了一种名为Control3Diff的三维扩散模型，结合了扩散模型和3D GANs的优点，可以用于单视图数据集的多功能、可控的三维感知图像合成。

    

    最近，扩散模型已经成为2D领域生成建模的事实标准。然而，由于获取三维基准数据进行训练的困难，将扩散模型扩展到三维领域是具有挑战性的。另一方面，将隐式三维表示集成到GANs中的3D GANs在仅训练单视图图像数据集时展示了显着的3D感知生成。然而，3D GANs没有提供精确控制图像合成的简单方法。为了解决这些挑战，我们提出了Control3Diff，这是一种结合了扩散模型和3D GANs优点的三维扩散模型，用于单视图数据集的多功能，可控的三维感知图像合成。Control3Diff明确地建模了潜在的潜在分布（可以是外部输入条件下的潜在分布），从而允许在扩散过程中直接控制。此外，我们的方法通用，可适用于任何类型的控制输入，使我们能够使用相同的基础体系结构对其进行训练。

    Diffusion models have recently become the de-facto approach for generative modeling in the 2D domain. However, extending diffusion models to 3D is challenging due to the difficulties in acquiring 3D ground truth data for training. On the other hand, 3D GANs that integrate implicit 3D representations into GANs have shown remarkable 3D-aware generation when trained only on single-view image datasets. However, 3D GANs do not provide straightforward ways to precisely control image synthesis. To address these challenges, We present Control3Diff, a 3D diffusion model that combines the strengths of diffusion models and 3D GANs for versatile, controllable 3D-aware image synthesis for single-view datasets. Control3Diff explicitly models the underlying latent distribution (optionally conditioned on external inputs), thus enabling direct control during the diffusion process. Moreover, our approach is general and applicable to any type of controlling input, allowing us to train it with the same di
    
[^6]: 利用生成对抗网络改进手势数据的新颖性检测

    Improving novelty detection with generative adversarial networks on hand gesture data. (arXiv:2304.06696v1 [cs.LG])

    [http://arxiv.org/abs/2304.06696](http://arxiv.org/abs/2304.06696)

    本研究提出了一种使用生成对抗网络框架下的人工神经网络来解决识别未知手势问题的新方法，该方法在样本生成质量和分类测试中均表现出优异性能。

    

    我们提出了一种新方法，使用生成对抗网络（GAN）框架下训练的人工神经网络（ANN）来解决识别未知手势的问题。生成模型会动态地增加在线数据，并用随机目标向量进行训练，鉴别模型决定数据的分类。该方法在UC2017 SG和UC2018 DualMyo数据集上得到了评估。使用距离度量瞄准生成和真实样本的差距来评估生成模型的性能；使用训练样本和未知样本上的准确率评估鉴别模型的性能。在样本的生成质量方面，所有类别的平均距离上，GAN生成的样本均明显优于随机分布（噪声）。在分类测试中，基准神经网络无法识别未训练的手势。当采用所提出的方法时，我们发现识别已训练手势和未训练手势之间存在权衡。

    We propose a novel way of solving the issue of classification of out-of-vocabulary gestures using Artificial Neural Networks (ANNs) trained in the Generative Adversarial Network (GAN) framework. A generative model augments the data set in an online fashion with new samples and stochastic target vectors, while a discriminative model determines the class of the samples. The approach was evaluated on the UC2017 SG and UC2018 DualMyo data sets. The generative models performance was measured with a distance metric between generated and real samples. The discriminative models were evaluated by their accuracy on trained and novel classes. In terms of sample generation quality, the GAN is significantly better than a random distribution (noise) in mean distance, for all classes. In the classification tests, the baseline neural network was not capable of identifying untrained gestures. When the proposed methodology was implemented, we found that there is a trade-off between the detection of trai
    
[^7]: OKRidge: 用于学习动态系统的可扩展 k 稀疏岭回归

    OKRidge: Scalable Optimal k-Sparse Ridge Regression for Learning Dynamical Systems. (arXiv:2304.06686v1 [cs.LG])

    [http://arxiv.org/abs/2304.06686](http://arxiv.org/abs/2304.06686)

    本文提出了一种名为 OKRidge 的方法，用于确定非线性动态系统的稀疏控制方程，并通过求解稀疏岭回归问题，实现了可扩展性和快速性，和现有方法相比，有着更高的效率。

    

    本文解决了科学发现中的一个重要问题，即，确定非线性动态系统的稀疏控制方程，通过求解稀疏岭回归问题可以证明最优性，以确定驱动基础动态的项。我们提出了一种称为 OKRidge 的快速算法，用一种新颖的下界计算方法，涉及鞍点公式，然后使用线性系统或基于 ADMM 的方法来解决，其中可以通过解决另一个线性系统和单调回归问题来有效地计算近端算子。我们还提出了一种启动我们求解器的方法，利用了波束搜索。在实验中，我们的方法达到可证明的最优性，并且运行时间比商业求解器 Gurobi 解决的现有 MIP公式运行时间快几个数量级。

    We consider an important problem in scientific discovery, identifying sparse governing equations for nonlinear dynamical systems. This involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. We propose a fast algorithm, OKRidge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an ADMM-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. We also propose a method to warm-start our solver, which leverages a beam search. Experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing MIP formulations solved by the commercial solver Gurobi.
    
[^8]: 布局引导下的图像生成的诊断基准和迭代修复

    Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation. (arXiv:2304.06671v1 [cs.CV])

    [http://arxiv.org/abs/2304.06671](http://arxiv.org/abs/2304.06671)

    本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。

    

    空间控制是可控图像生成的核心能力。在布局引导下的图像生成方面的进展已经显示出在具有类似空间配置的内分布（ID）数据集上有良好的结果。然而，当面对任意不确定的布局的离线分布样本时，这些模型的表现还不清楚。在本文中，我们提出了LayoutBench，这是一种对布局引导下的图像生成进行诊断的基准，它检查了四种空间控制技能：数量，位置，大小和形状。我们对两种最近代表性的布局引导下的图像生成方法进行了基准测试，并观察到良好的ID布局控制可能无法很好地推广到任意布局的野外环境（例如，边界上的对象）。接下来，我们提出了一个新的基准方法IterInpaint，它通过修复逐步生成前景和背景区域，展示出在LayoutBench的OOD布局上更强的通用性。我们进行了数量和定性评估，表明IterInpaint相对于现有方法具有更好的生成多样和视觉上令人愉悦的图像和可控的空间布局。

    Spatial control is a core capability in controllable image generation. Advancements in layout-guided image generation have shown promising results on in-distribution (ID) datasets with similar spatial configurations. However, it is unclear how these models perform when facing out-of-distribution (OOD) samples with arbitrary, unseen layouts. In this paper, we propose LayoutBench, a diagnostic benchmark for layout-guided image generation that examines four categories of spatial control skills: number, position, size, and shape. We benchmark two recent representative layout-guided image generation methods and observe that the good ID layout control may not generalize well to arbitrary layouts in the wild (e.g., objects at the boundary). Next, we propose IterInpaint, a new baseline that generates foreground and background regions in a step-by-step manner via inpainting, demonstrating stronger generalizability than existing models on OOD layouts in LayoutBench. We perform quantitative and q
    
[^9]: 深度神经网络是否具备内置的奥卡姆剃刀？

    Do deep neural networks have an inbuilt Occam's razor?. (arXiv:2304.06670v1 [cs.LG])

    [http://arxiv.org/abs/2304.06670](http://arxiv.org/abs/2304.06670)

    该研究利用基于函数先验的贝叶斯视角来研究深度神经网络（DNNs）的表现来源，结果表明DNNs之所以成功，是因为它对于具有结构的数据，具备一种内在的奥卡姆剃刀式的归纳偏差，足以抵消函数数量及复杂度的指数级增长。

    

    超参数化深度神经网络（DNNs）的卓越性能必须源自于网络架构、训练算法和数据结构之间的相互作用。为了区分这三个部分，我们应用了基于DNN所表达的函数的贝叶斯视角来进行监督学习。经过网络确定的函数先验通过利用有序和混沌状态之间的转变而变化。对于布尔函数分类，我们利用函数的误差谱在数据上进行可能性的近似。当与先验相结合时，它可以精确地预测使用随机梯度下降训练的DNN的后验概率。该分析揭示了结构化数据，以及内在的奥卡姆剃刀式归纳偏差，即足以抵消复杂度随函数数量呈指数增长而产生的影响，是DNNs成功的关键。

    The remarkable performance of overparameterized deep neural networks (DNNs) must arise from an interplay between network architecture, training algorithms, and structure in the data. To disentangle these three components, we apply a Bayesian picture, based on the functions expressed by a DNN, to supervised learning. The prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes. For Boolean function classification, we approximate the likelihood using the error spectrum of functions on data. When combined with the prior, this accurately predicts the posterior, measured for DNNs trained with stochastic gradient descent. This analysis reveals that structured data, combined with an intrinsic Occam's razor-like inductive bias towards (Kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity, is a key to the success of DNNs.
    
[^10]: 具有非理想链接的网络系统中的D-SVM

    D-SVM over Networked Systems with Non-Ideal Linking Conditions. (arXiv:2304.06667v1 [eess.SY])

    [http://arxiv.org/abs/2304.06667](http://arxiv.org/abs/2304.06667)

    本论文讨论了具有非线性链接条件的多智能体网络的分布式支持向量机，提出了解决目标优化约束的一种动态平衡有向网络的奇数扇区限制非线性映射方法。

    

    本论文考虑了一种分布式优化算法，应用于通过分布式支持向量机（D-SVM）进行二元分类的多智能体网络，其具有一些链接的非线性特征。代理通过连续时间动力学协同解决共识约束分布式优化，而链接则受到强烈的符号保持奇异非线性条件的影响。对数量化和截取（饱和）是这样的非线性例子。与现有文献主要考虑理想链接和通过线性通道进行完美信息交换相比，我们展示了一般的扇区限制模型如何影响到在动态平衡的有向网络上收敛到优化器（即SVM分类器）。一般而言，任何奇数扇区限制非线性映射都可以应用于我们的动力学。主要挑战在于证明所提出的系统动力学始终具有一个零特征值（与共识相关）和其他特征值都是负实数的性质。

    This paper considers distributed optimization algorithms, with application in binary classification via distributed support-vector-machines (D-SVM) over multi-agent networks subject to some link nonlinearities. The agents solve a consensus-constraint distributed optimization cooperatively via continuous-time dynamics, while the links are subject to strongly sign-preserving odd nonlinear conditions. Logarithmic quantization and clipping (saturation) are two examples of such nonlinearities. In contrast to existing literature that mostly considers ideal links and perfect information exchange over linear channels, we show how general sector-bounded models affect the convergence to the optimizer (i.e., the SVM classifier) over dynamic balanced directed networks. In general, any odd sector-bounded nonlinear mapping can be applied to our dynamics. The main challenge is to show that the proposed system dynamics always have one zero eigenvalue (associated with the consensus) and the other eigen
    
[^11]: G2T: 基于预训练语言模型和社区检测的主题建模框架

    G2T: A simple but versatile framework for topic modeling based on pretrained language model and community detection. (arXiv:2304.06653v1 [cs.CL])

    [http://arxiv.org/abs/2304.06653](http://arxiv.org/abs/2304.06653)

    G2T是一种基于预训练语言模型和社区检测的主题建模框架，自动评估表明，G2T在多个数据集上均与当前最先进的方法相比表现更好。

    

    先前的研究表明，基于聚类的主题模型能够通过适当的词语筛选方法聚类高质量的句子嵌入，生成比生成式概率主题模型更好的主题。然而，这些方法存在选择合适参数的困难以及不完整的模型忽略单词与主题及主题与文本之间的定量关系的问题。为了解决这些问题，我们提出了一种简洁但有效的主题建模框架，即图主题（G2T）。

    It has been reported that clustering-based topic models, which cluster high-quality sentence embeddings with an appropriate word selection method, can generate better topics than generative probabilistic topic models. However, these approaches suffer from the inability to select appropriate parameters and incomplete models that overlook the quantitative relation between words with topics and topics with text. To solve these issues, we propose graph to topic (G2T), a simple but effective framework for topic modelling. The framework is composed of four modules. First, document representation is acquired using pretrained language models. Second, a semantic graph is constructed according to the similarity between document representations. Third, communities in document semantic graphs are identified, and the relationship between topics and documents is quantified accordingly. Fourth, the word--topic distribution is computed based on a variant of TFIDF. Automatic evaluation suggests that G2
    
[^12]: 大型语言模型生成的教育问题有多有用？

    How Useful are Educational Questions Generated by Large Language Models?. (arXiv:2304.06638v1 [cs.CL])

    [http://arxiv.org/abs/2304.06638](http://arxiv.org/abs/2304.06638)

    本文研究通过结合CTG和问题分类生成的输出，通过教师评估证明这些生成的问题质量高且足够有用，有极大的应用潜力。

    

    由大型语言模型进行可控文本生成（CTG）对于教师和学生来说有着巨大的潜力，特别是高质量和多样性的问题生成可以大幅减轻教师的负担，提高他们教学内容的质量。最近在该领域的研究已经取得了进展，但未能表明真正的教师评判生成的问题在课堂环境中是否足够有用，或者问题是否存在错误和/或教学内容的帮助不大。本文通过人类评估教师的方式，评估通过结合CTG和问题分类（Bloom's和难度分类）生成的输出的质量和有用性。结果表明生成的问题质量高且足够有用，展示了在课堂环境中广泛使用的潜力。

    Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting.
    
[^13]: PGTask：介绍从对话中生成档案的任务

    PGTask: Introducing the Task of Profile Generation from Dialogues. (arXiv:2304.06634v1 [cs.CL])

    [http://arxiv.org/abs/2304.06634](http://arxiv.org/abs/2304.06634)

    对话系统的个性化需要个人资料信息，而从对话中提取/生成个人资料信息是一项基本需求。为此，我们提出了档案生成任务（PGTask）并提供了相关的数据集和基准，该任务使得研究者可以更好地了解档案生成任务的挑战和可能的解决方案。

    

    最近的研究尝试通过将个人资料信息融入模型来个性化对话系统。然而，这种知识信息稀少且难以获取，这使得从对话中提取/生成个人资料信息成为一项基本需求。为了克服这一限制，我们引入了档案生成任务（PGTask）。我们为此问题提供了一个新的数据集，其中包括与相关话语对齐的档案句子，从对话语料库中提取。此外，利用最先进的方法，我们为这个新数据集提供了一个档案生成的基准。我们的实验揭示了档案生成的挑战，并希望这引入了一个新的研究方向。

    Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.
    
[^14]: CoSDA: 持续的无源域适应

    CoSDA: Continual Source-Free Domain Adaptation. (arXiv:2304.06627v1 [cs.LG])

    [http://arxiv.org/abs/2304.06627](http://arxiv.org/abs/2304.06627)

    提出了一种名为CoSDA的持续无源域适应的方法，采用双速度优化的师生模型对并配备有一致性学习能力，旨在减轻灾难性遗忘的问题，并在实验中取得了较优的表现。

    

    无源域适应（SFDA）是指在没有访问源数据的情况下，将源域训练模型的知识应用于目标域。由于需要保护源域数据的隐私，SFDA最近变得流行起来，但由于缺乏数据，它会在源域上出现灾难性的遗忘现象。为了系统地研究灾难性遗忘的机制，我们首先在统一框架内重新实现了以往的SFDA方法，并在四项基准测试中对它们进行评估。我们观察到，对于适应性增益和遗忘损失之间存在一种权衡，这促使我们设计一种一致性正则化来减轻遗忘。特别地，我们提出了一种名为CoSDA的持续无源域适应方法，采用双速度优化的师生模型对，并配备有一致性学习能力。我们的实验表明，CoSDA在持续适应方面优于现有的方法。

    Without access to the source data, source-free domain adaptation (SFDA) transfers knowledge from a source-domain trained model to target domains. Recently, SFDA has gained popularity due to the need to protect the data privacy of the source domain, but it suffers from catastrophic forgetting on the source domain due to the lack of data. To systematically investigate the mechanism of catastrophic forgetting, we first reimplement previous SFDA approaches within a unified framework and evaluate them on four benchmarks. We observe that there is a trade-off between adaptation gain and forgetting loss, which motivates us to design a consistency regularization to mitigate forgetting. In particular, we propose a continual source-free domain adaptation approach named CoSDA, which employs a dual-speed optimized teacher-student model pair and is equipped with consistency learning capability. Our experiments demonstrate that CoSDA outperforms state-of-the-art approaches in continuous adaptation. N
    
[^15]: 无损调整预训练视觉模型以用于机器人操纵

    Lossless Adaptation of Pretrained Vision Models For Robotic Manipulation. (arXiv:2304.06600v1 [cs.LG])

    [http://arxiv.org/abs/2304.06600](http://arxiv.org/abs/2304.06600)

    本文提出了一种“无损适应”的方法，成功地将预训练视觉模型应用于机器人操纵中，并在不改变原始模型的情况下显著提高了性能。

    

    最近的研究表明，通常用于视觉学习的大型预训练模型可为各种专门的感知问题以及各种机器人操纵任务提供有用的表示。虽然机器人操纵的先前工作主要使用了冻结的预训练特征，但我们证明，在机器人领域，这种方法可能无法达到最佳性能，全模型微调可以带来显着更好的结果。不幸的是，微调会破坏预先训练的视觉表示，并导致代表性向微调任务的漂移，从而导致原始模型的多用性丢失。我们介绍了“无损适应”来解决经典微调的这个缺点。我们演示了适当放置我们的参数高效适配器可以显着减少性能差距，从而使冻结预训练表示与全端到端微调之间的差距缩小，而不改变原始模型。

    Recent works have shown that large models pretrained on common visual learning tasks can provide useful representations for a wide range of specialized perception problems, as well as a variety of robotic manipulation tasks. While prior work on robotic manipulation has predominantly used frozen pretrained features, we demonstrate that in robotics this approach can fail to reach optimal performance, and that fine-tuning of the full model can lead to significantly better results. Unfortunately, fine-tuning disrupts the pretrained visual representation, and causes representational drift towards the fine-tuned task thus leading to a loss of the versatility of the original model. We introduce "lossless adaptation" to address this shortcoming of classical fine-tuning. We demonstrate that appropriate placement of our parameter efficient adapters can significantly reduce the performance gap between frozen pretrained representations and full end-to-end fine-tuning without changes to the origina
    
[^16]: 超越次模性：带组公平性约束的随机集合选择的统一框架

    Beyond Submodularity: A Unified Framework of Randomized Set Selection with Group Fairness Constraints. (arXiv:2304.06596v1 [cs.LG])

    [http://arxiv.org/abs/2304.06596](http://arxiv.org/abs/2304.06596)

    该论文介绍了一种带有组公平性约束的随机子集选择的框架，并提出了一个全新的优化方法，可以优化一系列超出次模性范围的问题。在测试中，该框架可以实现组公平性而不牺牲太多效用。

    

    机器学习算法在多个重要决策过程中发挥着重要作用，包括定向广告展示、家庭贷款批准和犯罪行为预测等。鉴于这些算法的深远影响，关键在于它们运作应该公平，没有偏见或对某些群体的偏见。确保这些算法的公正性对于促进平等和避免歧视至关重要。为此，我们引入了一个带有组公平性约束的随机子集选择的统一框架。我们的问题涉及全局效用函数以及每个组的一组效用函数，其中一个组指共享相同属性（例如性别）的个体组。我们的目标是生成跨可行子集的分布，指定每个可行集的选择概率，以最大化全局效用函数并满足预定配额的要求。

    Machine learning algorithms play an important role in a variety of important decision-making processes, including targeted advertisement displays, home loan approvals, and criminal behavior predictions. Given the far-reaching impact of these algorithms, it is crucial that they operate fairly, free from bias or prejudice towards certain groups in the population. Ensuring impartiality in these algorithms is essential for promoting equality and avoiding discrimination. To this end we introduce a unified framework for randomized subset selection that incorporates group fairness constraints. Our problem involves a global utility function and a set of group utility functions for each group, here a group refers to a group of individuals (e.g., people) sharing the same attributes (e.g., gender). Our aim is to generate a distribution across feasible subsets, specifying the selection probability of each feasible set, to maximize the global utility function while meeting a predetermined quota for
    
[^17]: 解决张量低周期秩近似问题

    Solving Tensor Low Cycle Rank Approximation. (arXiv:2304.06594v1 [cs.DS])

    [http://arxiv.org/abs/2304.06594](http://arxiv.org/abs/2304.06594)

    该论文介绍了如何解决张量低周期秩近似问题，这是自然语言处理、语言翻译和语音识别中重要的计算任务。

    

    大型语言模型已经成为现代生活中普遍存在的事物，在自然语言处理、语言翻译和语音识别等各个领域都有着广泛的应用。最近的一项突破性工作[Zhao, Panigrahi, Ge, and Arora Arxiv 2023]从概率上下文无关语法(PCFG)的角度解释了注意力模型。在计算PCFG概率的核心计算任务中，需要解决一个特定的张量低周期秩近似问题，我们称之为张量周期秩。给定一个$n\times n\times n$的三阶张量$A$，如果存在三个$n\times k^2$大小的矩阵$U,V,W$，满足对于每个条目中的每个$A_{a,b,c}$，都有\begin{align*} A_{a,b,c} = \sum_{i=1}^k \sum_{j=1}^k \sum_{l=1}^k U_{a,i+k(j-1)} \otimes V_{b, j + k(l-1)} \otimes W_{c, l + k(i-1) } \end{align*},对于所有的$a \in [n], b \in [n], c \in [n]$，则称$A$具有周期秩-$k$。对于张量经典秩、Tucker秩和Train秩等问题已经被广泛研究[SOD

    Large language models have become ubiquitous in modern life, finding applications in various domains such as natural language processing, language translation, and speech recognition. Recently, a breakthrough work [Zhao, Panigrahi, Ge, and Arora Arxiv 2023] explains the attention model from probabilistic context-free grammar (PCFG). One of the central computation task for computing probability in PCFG is formulating a particular tensor low rank approximation problem, we can call it tensor cycle rank. Given an $n \times n \times n$ third order tensor $A$, we say that $A$ has cycle rank-$k$ if there exists three $n \times k^2$ size matrices $U , V$, and $W$ such that for each entry in each \begin{align*} A_{a,b,c} = \sum_{i=1}^k \sum_{j=1}^k \sum_{l=1}^k U_{a,i+k(j-1)} \otimes V_{b, j + k(l-1)} \otimes W_{c, l + k(i-1) } \end{align*} for all $a \in [n], b \in [n], c \in [n]$. For the tensor classical rank, tucker rank and train rank, it has been well studied in [Song, Woodruff, Zhong SOD
    
[^18]: 具有维度不变性的对抗样本

    Adversarial Examples from Dimensional Invariance. (arXiv:2304.06575v1 [cs.LG])

    [http://arxiv.org/abs/2304.06575](http://arxiv.org/abs/2304.06575)

    对抗样本产生的原因是对于输入数据近似双射映射所规定的维度不变性导致的近似不连续性。

    

    对抗样本已经被发现针对各种深度和浅层学习模型，有时被建议是可修复的模型特定错误，或者是固有的数据集特征，或者两者兼备。我们提出理论和实证结果，以展示对抗样本是由于模型规定了近似双射映射$f:\Bbb R^n \to \Bbb R^m; n \neq m$，其输入的近似不连续性产生的，而这种不连续性是由于维度的拓扑不变性导致的。

    Adversarial examples have been found for various deep as well as shallow learning models, and have at various times been suggested to be either fixable model-specific bugs, or else inherent dataset feature, or both. We present theoretical and empirical results to show that adversarial examples are approximate discontinuities resulting from models that specify approximately bijective maps $f: \Bbb R^n \to \Bbb R^m; n \neq m$ over their inputs, and this discontinuity follows from the topological invariance of dimension.
    
[^19]: 贝叶斯分类器无法从具有未知噪声率的嘈杂响应中学习。(arXiv:2304.06574v1 [stat.ML])

    Bayes classifier cannot be learned from noisy responses with unknown noise rates. (arXiv:2304.06574v1 [stat.ML])

    [http://arxiv.org/abs/2304.06574](http://arxiv.org/abs/2304.06574)

    本文研究了在有噪声标签的情况下训练分类器的问题，发现贝叶斯决策规则通常无法识别，并提出了一种简单算法来学习贝叶斯决策规则，不需要知道噪声分布。

    

    用嘈杂的标签训练分类器通常需要学习者指定标签噪音的分布，但在实际中往往是未知的。尽管最近有一些尝试放宽该要求，但我们表明，在大多数嘈杂标签分类问题中，贝叶斯决策规则是无法识别的。这表明一般情况下无法绕过或放宽该要求。在贝叶斯决策规则被识别的特殊情况下，我们开发了一种简单的算法来学习贝叶斯决策规则，不需要知道噪声分布。

    Training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. Although there have been some recent attempts to relax that requirement, we show that the Bayes decision rule is unidentified in most classification problems with noisy labels. This suggests it is generally not possible to bypass/relax the requirement. In the special cases in which the Bayes decision rule is identified, we develop a simple algorithm to learn the Bayes decision rule, that does not require knowledge of the noise distribution.
    
[^20]: counterfactuals: 用于反事实解释方法的 R 包

    counterfactuals: An R Package for Counterfactual Explanation Methods. (arXiv:2304.06569v1 [stat.ML])

    [http://arxiv.org/abs/2304.06569](http://arxiv.org/abs/2304.06569)

    该论文介绍了一个统一且模块化的 R6 接口，用于具体实现反事实解释方法。通过实现三种方法并推广到不同的情境中，结合真实用例，此方法能够快速准确地得出有关如何更改单个观测值的特征值以获得所需预测的信息。

    

    反事实解释方法提供有关如何更改单个观测值的特征值以获得所需预测的信息。尽管研究中提出了越来越多的方法，但只有少数具有广泛变化的接口和要求的实现存在。在本文中，我们介绍 counterfactuals R 包，它提供了一个基于 R6 的模块化和统一的接口，用于反事实解释方法。我们已经实现了三种现有的反事实解释方法，并提出了一些可选的方法学扩展，以将这些方法推广到不同的场景并使其更具可比性。我们使用真实用例解释了包的结构和工作流程，并展示了如何将其他反事实解释方法集成到包中。此外，我们针对各种模型和数据集比较了实施的方法，以评估其反事实解释的质量和运行时行为。

    Counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. Despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. In this work, we introduce the counterfactuals R package, which provides a modular and unified R6-based interface for counterfactual explanation methods. We implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. We explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. In addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.
    
[^21]: 利用深度强化学习解决装配序列规划问题

    Deep reinforcement learning applied to an assembly sequence planning problem with user preferences. (arXiv:2304.06567v1 [cs.LG])

    [http://arxiv.org/abs/2304.06567](http://arxiv.org/abs/2304.06567)

    本文研究了将深度强化学习应用于装配序列规划问题，引入参数行动以提高训练时间和样本效率，并使用了两种不同的奖励信号。研究结果表明，三种最强大的深度RL方法，A2C、DQN和Rainbow都能够解决这个问题。

    

    深度强化学习（DRL）在解决复杂制造决策问题方面展示了其潜力，特别是在没有训练数据的情况下随着实际操作而进行系统学习的环境下。本文提出了一种将DRL方法应用于装配序列规划（ASP）的方法。所提出的方法在RL环境中引入了参数行动，以提高训练时间和样本效率，并使用了两种不同的奖励信号：（1）用户的偏好和（2）总装配时间。用户的偏好信号解决了装配过程中人类面临的困难和非人体工效特性，而总装配时间信号则强制执行装配的优化。本文研究了三种最强大的深度RL方法 A2C、DQN 和 Rainbow，并在两个不同场景下进行了研究：

    Deep reinforcement learning (DRL) has demonstrated its potential in solving complex manufacturing decision-making problems, especially in a context where the system learns over time with actual operation in the absence of training data. One interesting and challenging application for such methods is the assembly sequence planning (ASP) problem. In this paper, we propose an approach to the implementation of DRL methods in ASP. The proposed approach introduces in the RL environment parametric actions to improve training time and sample efficiency and uses two different reward signals: (1) user's preferences and (2) total assembly time duration. The user's preferences signal addresses the difficulties and non-ergonomic properties of the assembly faced by the human and the total assembly time signal enforces the optimization of the assembly. Three of the most powerful deep RL methods were studied, Advantage Actor-Critic (A2C), Deep Q-Learning (DQN), and Rainbow, in two different scenarios:
    
[^22]: 无人机网络中的去中心化联邦学习方法以减少通信成本和能耗

    Decentralized federated learning methods for reducing communication cost and energy consumption in UAV networks. (arXiv:2304.06551v1 [cs.LG])

    [http://arxiv.org/abs/2304.06551](http://arxiv.org/abs/2304.06551)

    本文提出了两种去中心化联邦学习方法：交换律联邦学习和轮流联邦学习。这些方法可以降低通信成本和能耗，同时确保数据隐私。

    

    无人机在现代智慧城市中扮演着很多角色，如物品配送、实时道路交通地图制作和污染监测。然而，传统的无人机机器学习模型面临着数据隐私问题、通信成本和能量限制等挑战。联邦学习是一种分布式机器学习方法，能很好地解决这些问题。它可以让无人机在不传输原始数据的情况下进行本地模型训练。然而，现有的联邦学习需要一个中央服务器来聚合无人机的训练模型参数。如果中央服务器发生故障，将会对训练造成重大影响。本文提出了两种聚合方法：交换律联邦学习和轮流联邦学习。这两种方法基于已有的去中心化无人机联邦学习架构，在每个无人机的模型参数中添加一个唯一标识符。所提出的方法旨在减少通信成本和能耗，同时确保数据隐私。

    Unmanned aerial vehicles (UAV) or drones play many roles in a modern smart city such as the delivery of goods, mapping real-time road traffic and monitoring pollution. The ability of drones to perform these functions often requires the support of machine learning technology. However, traditional machine learning models for drones encounter data privacy problems, communication costs and energy limitations. Federated Learning, an emerging distributed machine learning approach, is an excellent solution to address these issues. Federated learning (FL) allows drones to train local models without transmitting raw data. However, existing FL requires a central server to aggregate the trained model parameters of the UAV. A failure of the central server can significantly impact the overall training. In this paper, we propose two aggregation methods: Commutative FL and Alternate FL, based on the existing architecture of decentralised Federated Learning for UAV Networks (DFL-UN) by adding a unique
    
[^23]: 基于多核重对比损失的IMU定向估计：梯度下降法

    Multi-kernel Correntropy-based Orientation Estimation of IMUs: Gradient Descent Methods. (arXiv:2304.06548v1 [eess.SY])

    [http://arxiv.org/abs/2304.06548](http://arxiv.org/abs/2304.06548)

    本文提出了两种基于重对比损失的算法，用于IMU定向估计，相比传统方法具有更好的准确性、鲁棒性和计算效率。

    

    本文介绍了两个计算效率高的算法，用于惯性测量单元（IMUs）的定向估计：重对比梯度下降（CGD）和重对比解耦定向估计（CDOE）。传统方法，如梯度下降（GD）和解耦定向估计（DOE），依赖于均方误差（MSE）准则，使其容易受到外部加速度和磁干扰的影响。为解决这个问题，我们证明了当噪声遵循一种重尾分布时，多核重对比损失（MKCL）是最优的极大似然估计（MLE）目标函数。在某些情况下，即使存在任意大的离群值，MKCL的估计误差也是有界的。通过用MKCL替换标准MSE成本函数，我们开发了CGD和CDOE算法。我们通过比较这些方法在各种传感器设置和运动场景中的表现来评估它们的有效性。实验结果表明，CGD和CDOE在精度、健壮性和计算效率方面均达到了卓越的表现。

    This paper presents two computationally efficient algorithms for the orientation estimation of inertial measurement units (IMUs): the correntropy-based gradient descent (CGD) and the correntropy-based decoupled orientation estimation (CDOE). Traditional methods, such as gradient descent (GD) and decoupled orientation estimation (DOE), rely on the mean squared error (MSE) criterion, making them vulnerable to external acceleration and magnetic interference. To address this issue, we demonstrate that the multi-kernel correntropy loss (MKCL) is an optimal objective function for maximum likelihood estimation (MLE) when the noise follows a type of heavy-tailed distribution. In certain situations, the estimation error of the MKCL is bounded even in the presence of arbitrarily large outliers. By replacing the standard MSE cost function with MKCL, we develop the CGD and CDOE algorithms. We evaluate the effectiveness of our proposed methods by comparing them with existing algorithms in various s
    
[^24]: 使用时间知识共享实现脉冲神经网络对过去和未来的学习

    Temporal Knowledge Sharing enable Spiking Neural Network Learning from Past and Future. (arXiv:2304.06540v1 [cs.NE])

    [http://arxiv.org/abs/2304.06540](http://arxiv.org/abs/2304.06540)

    本文提出了一种时间知识共享方法（TKS），在不同时刻之间交互信息，并辅助真实标签引导脉冲神经网络（SNN）的训练，以实现SNN对过去和未来的学习。实验证明，在多个数据集上使用TKS可以获得当前最优的性能。

    

    脉冲神经网络因其类似于大脑信息处理机制而吸引了许多领域的研究人员的广泛关注。替代梯度的提出使得脉冲神经网络能够迁移到更复杂的任务，并逐步缩小与传统人工神经网络之间的差距。目前的脉冲神经网络利用所有时刻的输出来产生最终的预测，这牺牲了它们的时间特性，导致性能和效率降低。我们提出了一种时间知识共享方法（TKS），它通过选择特定时刻的输出来构成教师信号，使得信息可以在不同时刻之间交互，辅助真实标签引导网络训练。我们在静态数据集CIFAR10、CIFAR100、ImageNet-1k以及神经形态学数据集DVS-CIFAR10、NCALTECH101上验证了TKS。我们的实验结果表明，使用TKS，我们已经在CIFAR10和CIFAR100上取得了当前最优的性能，并且使用TKS的NCALTECH101超过了现有最先进的结果。

    Spiking neural networks have attracted extensive attention from researchers in many fields due to their brain-like information processing mechanism. The proposal of surrogate gradient enables the spiking neural networks to migrate to more complex tasks, and gradually close the gap with the conventional artificial neural networks. Current spiking neural networks utilize the output of all moments to produce the final prediction, which compromises their temporal characteristics and causes a reduction in performance and efficiency. We propose a temporal knowledge sharing approach (TKS) that enables the interaction of information between different moments, by selecting the output of specific moments to compose teacher signals to guide the training of the network along with the real labels. We have validated TKS on both static datasets CIFAR10, CIFAR100, ImageNet-1k and neuromorphic datasets DVS-CIFAR10, NCALTECH101. Our experimental results indicate that we have achieved the current optimal
    
[^25]: 基于转移学习的高效苹果叶病分类方法

    An Efficient Transfer Learning-based Approach for Apple Leaf Disease Classification. (arXiv:2304.06520v1 [cs.CV])

    [http://arxiv.org/abs/2304.06520](http://arxiv.org/abs/2304.06520)

    本研究提出了一种基于转移学习的苹果叶病识别技术，通过预训练的EfficientNetV2S架构提取特征并结合分类器块进行预测。该研究解决了类不平衡的问题，对各种超参数进行了仔细调查，为苹果树农提供了更加快速高效的叶病分类解决方案。

    

    正确识别和分类植物疾病对于保障全球粮食供应的安全和各利益相关者的经济成功至关重要。针对不同的主要作物，通过引入深度学习分类系统，提供了广泛的解决方案。尽管在许多地区是最重要的商业作物之一，但对于自动分类苹果叶病的智能解决方案的研究相对较少。本研究提出了一种基于转移学习的苹果叶病识别技术。该系统使用预训练的EfficientNetV2S架构提取特征，并传递到分类器块进行有效的预测。通过利用运行时数据增强来解决类不平衡问题。已经仔细调查了各种超参数的影响，如输入分辨率、学习率、纪元数等。该方案的能力得到了证明。

    Correct identification and categorization of plant diseases are crucial for ensuring the safety of the global food supply and the overall financial success of stakeholders. In this regard, a wide range of solutions has been made available by introducing deep learning-based classification systems for different staple crops. Despite being one of the most important commercial crops in many parts of the globe, research proposing a smart solution for automatically classifying apple leaf diseases remains relatively unexplored. This study presents a technique for identifying apple leaf diseases based on transfer learning. The system extracts features using a pretrained EfficientNetV2S architecture and passes to a classifier block for effective prediction. The class imbalance issues are tackled by utilizing runtime data augmentation. The effect of various hyperparameters, such as input resolution, learning rate, number of epochs, etc., has been investigated carefully. The competence of the pro
    
[^26]: 在认知无线电环境下安全的联邦学习频谱感知

    Secure Federated Learning for Cognitive Radio Sensing. (arXiv:2304.06519v1 [eess.SP])

    [http://arxiv.org/abs/2304.06519](http://arxiv.org/abs/2304.06519)

    本文探讨了在认知无线电环境下基于联邦学习实现可靠和安全的频谱感知（SS），深入分析了FL在SS中的动机、架构和算法，同时提供了安全和隐私威胁的对抗措施。

    

    本文考虑在认知无线电环境中基于联邦学习实现可靠和安全的频谱感知（SS）。讨论了FL在SS中的动机、架构和算法。概述了这些算法面临的安全和隐私威胁，并提出可能的对抗措施。同时提供了一些图示例，以及针对未来CR中基于FL的SS的设计建议。

    This paper considers reliable and secure Spectrum Sensing (SS) based on Federated Learning (FL) in the Cognitive Radio (CR) environment. Motivation, architectures, and algorithms of FL in SS are discussed. Security and privacy threats on these algorithms are overviewed, along with possible countermeasures to such attacks. Some illustrative examples are also provided, with design recommendations for FL-based SS in future CRs.
    
[^27]: 通过上行SRS通道估计在5G NR系统中实现的ML辅助室外用户定位

    ML-Enabled Outdoor User Positioning in 5G NR Systems via Uplink SRS Channel Estimates. (arXiv:2304.06514v1 [eess.SP])

    [http://arxiv.org/abs/2304.06514](http://arxiv.org/abs/2304.06514)

    本文研究了通过机器学习技术在5G NR系统中使用上行SRS信道估计进行用户定位，证明了在商用5G环境中即使使用很少的数据，也可以用小型神经网络实现具有米级精度的室外用户定位。

    

    手机用户的定位是5G NR网络提供的一项重要服务，同时，机器学习技术被预见将成为5G NR系统的集成部分，可提高无线电性能并减少复杂度。本文探讨了使用来自物理层通道的上行信道估计构成的5G NR指纹进行定位的ML技术。我们展示了使用探测参考信号（SRS）信道指纹提供足够的数据推断用户位置是可能的。此外，我们还证明即使在非常稀疏的SRS数据情况下，小型全连接较深的神经网络也可以在商用5G环境中实现具有米级精度的成功室外用户定位。

    Cellular user positioning is a promising service provided by Fifth Generation New Radio (5G NR) networks. Besides, Machine Learning (ML) techniques are foreseen to become an integrated part of 5G NR systems improving radio performance and reducing complexity. In this paper, we investigate ML techniques for positioning using 5G NR fingerprints consisting of uplink channel estimates from the physical layer channel. We show that it is possible to use Sounding Reference Signals (SRS) channel fingerprints to provide sufficient data to infer user position. Furthermore, we show that small fully-connected moderately Deep Neural Networks, even when applied to very sparse SRS data, can achieve successful outdoor user positioning with meter-level accuracy in a commercial 5G environment.
    
[^28]: GeoAI的哲学基础：探索GeoAI和空间数据科学中的可持续性、多样性和偏见

    Philosophical Foundations of GeoAI: Exploring Sustainability, Diversity, and Bias in GeoAI and Spatial Data Science. (arXiv:2304.06508v1 [cs.CY])

    [http://arxiv.org/abs/2304.06508](http://arxiv.org/abs/2304.06508)

    本文介绍了GeoAI和空间数据科学的哲学基础，分别从可持续性、训练数据中的偏差、模式知识的多样性和系统中的中立性缺失等角度出发，为我们设计、培训和部署基于GeoAI的系统提供了帮助，也为我们理解人工智能和机器学习研究的利益和潜在危险提供了共同理解。

    

    本章介绍了可能构成GeoAI和空间数据科学哲学基础的一些基本假设和原则。文章强调了可持续性、训练数据中的偏差、模式知识的多样性以及来自统一伦理视角的GeoAI系统中（潜在的）中立性缺失等主题，而非审查空间数据（分析）的成熟特征，如交互、邻域和自相关性。反思我们职业道德的影响将有助于我们更负责地进行潜在的研究，识别设计、培训和部署基于GeoAI的系统中的陷阱，并在跨学科领域中共同开发人工智能和机器学习研究的利益和潜在危险的共同理解，同时与他人分享我们独特的（地理）空间视角。

    This chapter presents some of the fundamental assumptions and principles that could form the philosophical foundation of GeoAI and spatial data science. Instead of reviewing the well-established characteristics of spatial data (analysis), including interaction, neighborhoods, and autocorrelation, the chapter highlights themes such as sustainability, bias in training data, diversity in schema knowledge, and the (potential lack of) neutrality of GeoAI systems from a unifying ethical perspective. Reflecting on our profession's ethical implications will assist us in conducting potentially disruptive research more responsibly, identifying pitfalls in designing, training, and deploying GeoAI-based systems, and developing a shared understanding of the benefits but also potential dangers of artificial intelligence and machine learning research across academic fields, all while sharing our unique (geo)spatial perspective with others.
    
[^29]: Squeeze and Excitation网络的变体

    Variations of Squeeze and Excitation networks. (arXiv:2304.06502v1 [cs.CV])

    [http://arxiv.org/abs/2304.06502](http://arxiv.org/abs/2304.06502)

    本文提出了Squeeze and Excitation网络的变体来改进重要特征的学习过程，从而提高神经网络的性能。实验表明这些变体在残差网络上效果良好。

    

    卷积神经网络学习空间特征，并在内核中紧密相连。SE模块打破了神经网络传递整体结果至下一层的传统路线。相反，SE仅传递包含其挤压和激励模块的重要特征进行学习。本文提出了SE模块的变体，改进了挤压和激励的过程，并提高了性能。所提出的挤压或激励层使得层权重的转换变得更加平滑。这些变化还保留了SE模块的特点。实验结果在残差网络上进行，并进行了表格化的展示。

    Convolutional neural networks learns spatial features and are heavily interlinked within kernels. The SE module have broken the traditional route of neural networks passing the entire result to next layer. Instead SE only passes important features to be learned with its squeeze and excitation (SE) module. We propose variations of the SE module which improvises the process of squeeze and excitation and enhances the performance. The proposed squeezing or exciting the layer makes it possible for having a smooth transition of layer weights. These proposed variations also retain the characteristics of SE module. The experimented results are carried out on residual networks and the results are tabulated.
    
[^30]: EEGMatch: 学习不完整标记的半监督脑电情绪识别

    EEGMatch: Learning with Incomplete Labels for Semi-Supervised EEG-based Cross-Subject Emotion Recognition. (arXiv:2304.06496v1 [eess.SP])

    [http://arxiv.org/abs/2304.06496](http://arxiv.org/abs/2304.06496)

    EEGMatch是一种半监督学习框架，可用于脑电情绪识别。通过基于EEG-Mixup的数据增强方法和半监督多域自适应方法，可以有效提高情绪识别准确性和稳定性。

    

    脑电图（EEG）是情绪识别的客观工具，并显示出良好的性能。然而，标签稀缺问题是该领域的主要挑战，限制了基于EEG的情绪识别的广泛应用。本文提出了一种新的半监督学习框架（EEGMatch），以利用标记和未标记的EEG数据。首先，开发了一种基于EEG-Mixup数据增强方法，以生成更多用于模型学习的有效样本。其次，提出了一种半监督的两步成对学习方法，将原型式和实例化式成对学习连接起来，其中原型式成对学习衡量EEG数据与每个情感类别的原型表示之间的全局关系，而实例化式成对学习捕捉EEG数据之间的局部内在关系。第三，引入了一种半监督的多域自适应，以对齐多个域（标记的和未标记的数据集）之间的数据表示。实验结果表明，EEGMatch在情绪识别任务中表现出比现有的半监督方法更高的准确性和稳定性。

    Electroencephalography (EEG) is an objective tool for emotion recognition and shows promising performance. However, the label scarcity problem is a main challenge in this field, which limits the wide application of EEG-based emotion recognition. In this paper, we propose a novel semi-supervised learning framework (EEGMatch) to leverage both labeled and unlabeled EEG data. First, an EEG-Mixup based data augmentation method is developed to generate more valid samples for model learning. Second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between EEG data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among EEG data. Third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled
    
[^31]: 一种使用三元组损失学习的EEG信号嵌入

    An embedding for EEG signals learned using a triplet loss. (arXiv:2304.06495v1 [eess.SP])

    [http://arxiv.org/abs/2304.06495](http://arxiv.org/abs/2304.06495)

    本文提出了一种使用三元组损失学习的EEG信号嵌入方法，通过无监督学习直接学习EEG信号的低维度和可转移表示，并在公开的EEG数据集上表现出优异的迁移能力。

    

    类似于脑电图（EEG）或局部场电位的神经生理时间序列记录来自多个传感器。它们可以被机器学习模型解码，以估计患者或健康用户的正在进行的脑状态。在脑机接口（BCI）中，这种解码的脑状态信息可以用于控制应用程序，例如通信或中风后康复，或者被动监测受试者的正在进行的脑状态，例如在苛刻的工作环境中。这种解码任务所面临的一个特殊挑战是BCI中相对于计算机视觉或自然语言处理等其他机器学习领域的小数据集大小。在BCI中解决分类或回归问题的一种可能性是通过迁移学习，该方法利用来自其他会话、主题甚至数据集的数据来训练模型。在这项探索性研究中，为了使脑机接口中的神经生理时间序列数据具备迁移学习的能力，我们提出了一种基于三元组损失的神经嵌入学习方法用于EEG信号。我们的方法利用无监督学习直接学习EEG信号的低维度和可转移表示。我们在公开可用的EEG数据集上评估了我们的方法，并表明我们学习的嵌入可以在不同的患者、同一患者的不同会话甚至不同EEG数据集之间转移，在基准方法上表现优异。

    Neurophysiological time series recordings like the electroencephalogram (EEG) or local field potentials are obtained from multiple sensors. They can be decoded by machine learning models in order to estimate the ongoing brain state of a patient or healthy user. In a brain-computer interface (BCI), this decoded brain state information can be used with minimal time delay to either control an application, e.g., for communication or for rehabilitation after stroke, or to passively monitor the ongoing brain state of the subject, e.g., in a demanding work environment. A specific challenge in such decoding tasks is posed by the small dataset sizes in BCI compared to other domains of machine learning like computer vision or natural language processing. A possibility to tackle classification or regression problems in BCI despite small training data sets is through transfer learning, which utilizes data from other sessions, subjects or even datasets to train a model. In this exploratory study, w
    
[^32]: 考虑灰尘影响的光伏阵列故障诊断：基于特征曲线的变换图形特征和带CBAM模块的卷积神经网络

    Fault diagnosis for PV arrays considering dust impact based on transformed graphical feature of characteristic curves and convolutional neural network with CBAM modules. (arXiv:2304.06493v1 [eess.SP])

    [http://arxiv.org/abs/2304.06493](http://arxiv.org/abs/2304.06493)

    本文提出了一种新的PV阵列故障诊断方法，可以考虑灰尘影响并通过将Is-Voc normalized Gramian angular difference field方法与卷积神经网络和CBAM模块相结合，准确地识别多种复杂故障，实验结果证明其准确性与有效性。

    

    光伏阵列在运行过程中可能出现多种故障，而灰尘和不同的二极管配置使故障更加复杂。但是，目前基于I-V特性曲线的故障诊断方法仅利用部分特征信息，并且通常依赖于将场特性曲线校准到标准测试条件（STC）。这很难在实践中应用，并准确地识别多个复杂故障，特别是在灰尘影响下PV阵列中具有相似性的不同阻塞二极管配置。因此，提出了一种考虑灰尘影响的PV阵列故障诊断新方法。在预处理阶段中，提出了Isc-Voc归一化压缩图正弦角差（GADF）方法，该方法将场特性曲线包括I-V和P-V的重采样PV阵列特性曲线归一化和转换，以获取特征矩阵。然后，在故障诊断阶段中，将转换后的图形特征矩阵输入带有通道注意力和空间注意力模块的卷积神经网络（CNN），即卷积块注意力模块（CBAM），以准确识别故障。实验结果表明，所提出的方法可以准确识别包括部分遮蔽、开路故障和灰尘导致的异常工作条件在内的故障。总体诊断准确率达到100％，证明了所提出方法的有效性。

    Various faults can occur during the operation of PV arrays, and both the dust-affected operating conditions and various diode configurations make the faults more complicated. However, current methods for fault diagnosis based on I-V characteristic curves only utilize partial feature information and often rely on calibrating the field characteristic curves to standard test conditions (STC). It is difficult to apply it in practice and to accurately identify multiple complex faults with similarities in different blocking diodes configurations of PV arrays under the influence of dust. Therefore, a novel fault diagnosis method for PV arrays considering dust impact is proposed. In the preprocessing stage, the Isc-Voc normalized Gramian angular difference field (GADF) method is presented, which normalizes and transforms the resampled PV array characteristic curves from the field including I-V and P-V to obtain the transformed graphical feature matrices. Then, in the fault diagnosis stage, the
    
[^33]: 基于误差向量谱的Wi-Fi无需设备室内定位的新范式：深度学习

    A New Paradigm for Device-free Indoor Localization: Deep Learning with Error Vector Spectrum in Wi-Fi Systems. (arXiv:2304.06490v1 [eess.SP])

    [http://arxiv.org/abs/2304.06490](http://arxiv.org/abs/2304.06490)

    本论文提出了一种基于误差向量谱的深度学习方案，用于解决无需设备的室内定位中的RFO问题。该方案通过物理层信号中提取的信道特征进行人员位置分类，性能更优于现有技术。

    

    随着其便利性和多样化的应用，使用商用Wi-Fi设备进行无需设备的室内定位的需求在各个领域中迅速增加。然而，无线信道中的随机频率偏移（RFO）会影响室内定位的准确性，当使用波动的信道状态信息（CSI）时更是如此。为了减轻RFO问题，通过误差向量谱（EVS）来提高信号的分辨率并增强其对RFO的稳健性。为了解决这些挑战，本文提出了一种新颖的依赖于误差向量的深度学习（EVAL）方案，用于无需设备的室内定位。该方案采用深度神经网络来从物理层信号中提取丰富的信道特征，并通过分类的方式来确定人在室内环境中的位置。我们基于OpenWiFi项目进行了实际实验，以提取EVS和CSI并检验不同无需设备的定位技术的性能。实验结果表明，我们的EVAL方案在各项性能指标上均优于现有的定位技术。

    The demand for device-free indoor localization using commercial Wi-Fi devices has rapidly increased in various fields due to its convenience and versatile applications. However, random frequency offset (RFO) in wireless channels poses challenges to the accuracy of indoor localization when using fluctuating channel state information (CSI). To mitigate the RFO problem, an error vector spectrum (EVS) is conceived thanks to its higher resolution of signal and robustness to RFO. To address these challenges, this paper proposed a novel error vector assisted learning (EVAL) for device-free indoor localization. The proposed EVAL scheme employs deep neural networks to classify the location of a person in the indoor environment by extracting ample channel features from the physical layer signals. We conducted realistic experiments based on OpenWiFi project to extract both EVS and CSI to examine the performance of different device-free localization techniques. Experimental results show that our p
    
[^34]: 惯性测量单元人体活动识别的领域自适应: 一项综述

    Domain Adaptation for Inertial Measurement Unit-based Human Activity Recognition: A Survey. (arXiv:2304.06489v1 [eess.SP])

    [http://arxiv.org/abs/2304.06489](http://arxiv.org/abs/2304.06489)

    本文综述了惯性测量单元人体活动识别中利用领域自适应技术解决数据分布异质性问题的最新进展。

    

    基于机器学习的可穿戴式人体活动识别模型，可以开发各种智能社区应用，如睡眠模式监测、药物提醒、认知健康评估、运动分析等。但是，由于传感器放置在不同的身体位置、设备固有偏差和异质性，以及个人和环境的差异等造成的数据分布异质性，这些WHAR模型的性能受到了影响。文献中提出了各种传统的机器学习算法和迁移学习技术来解决处理这种数据异质性的挑战。领域自适应是近年来广受欢迎的一种迁移学习技术之一。本文对惯性测量单元(IMU)人体活动识别中的领域自适应技术的最新进展进行了调查。

    Machine learning-based wearable human activity recognition (WHAR) models enable the development of various smart and connected community applications such as sleep pattern monitoring, medication reminders, cognitive health assessment, sports analytics, etc. However, the widespread adoption of these WHAR models is impeded by their degraded performance in the presence of data distribution heterogeneities caused by the sensor placement at different body positions, inherent biases and heterogeneities across devices, and personal and environmental diversities. Various traditional machine learning algorithms and transfer learning techniques have been proposed in the literature to address the underpinning challenges of handling such data heterogeneities. Domain adaptation is one such transfer learning techniques that has gained significant popularity in recent literature. In this paper, we survey the recent progress of domain adaptation techniques in the Inertial Measurement Unit (IMU)-based 
    
[^35]: 生成式AI的一小步，AGI的一大步：AIGC时代中ChatGPT的全面调查

    One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era. (arXiv:2304.06488v1 [cs.CY])

    [http://arxiv.org/abs/2304.06488](http://arxiv.org/abs/2304.06488)

    ChatGPT是生成式AI的一小步，也是AGI的一大步，我们进行了综述，并对其如何演变为AIGC展望不同于以往的通用AI生成内容的发展道路。

    

    OpenAI 最近发布了GPT-4（又称为ChatGPT plus），该模型被证明是生成式AI（GAI）迈出的一小步，但对于人工通用智能（AGI）来说则是一个重大的飞跃。自2022年11月正式发布以来，ChatGPT便迅速吸引了众多用户，引起了广泛的媒体关注，相关的学术文章也超过了500篇。因此，有必要进行一次综述，我们的工作就是填补这一空白。总的来说，我们是第一个从技术、应用和挑战三个方面全面调查ChatGPT的团队，并展望了ChatGPT如何演变以实现通用的AI生成内容（AIGC），这将是AGI发展的重要里程碑。

    OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.
    
[^36]: CoRe-Sleep: 一种多模态融合框架，用于对不完善模态具有鲁棒性的时间序列分析

    CoRe-Sleep: A Multimodal Fusion Framework for Time Series Robust to Imperfect Modalities. (arXiv:2304.06485v1 [eess.SP])

    [http://arxiv.org/abs/2304.06485](http://arxiv.org/abs/2304.06485)

    CoRe-Sleep是一种多模态融合框架，特别关注于提高对不完善数据的信号分析的鲁棒性，它通过适当处理多模态信息，容忍噪声或丢失的模态片段，展现最先进的性能。

    

    睡眠异常可能会对健康产生严重的后果。自动化睡眠分期可以简化诊断过程。以往的自动化睡眠分期工作取得了很好的结果，主要依赖于 EEG 信号。但是，通常在 EEG 之外还有多个信息源可用。当 EEG 记录存在噪声甚至完全缺失时，这可能尤为有益。本文提出了 CoRe-Sleep，一种协调表示多模态融合网络，它特别关注于提高对不完善数据的信号分析的鲁棒性。我们展示了适当处理多模态信息可以是实现这种鲁棒性的关键。CoRe-Sleep 容忍噪声或缺失的模态片段，允许在不完整数据上进行训练。此外，它在使用单个模式进行多模态数据测试和单模态数据测试时都展现了最先进的性能。

    Sleep abnormalities can have severe health consequences. Automated sleep staging, i.e. labelling the sequence of sleep stages from the patient's physiological recordings, could simplify the diagnostic process. Previous work on automated sleep staging has achieved great results, mainly relying on the EEG signal. However, often multiple sources of information are available beyond EEG. This can be particularly beneficial when the EEG recordings are noisy or even missing completely. In this paper, we propose CoRe-Sleep, a Coordinated Representation multimodal fusion network that is particularly focused on improving the robustness of signal analysis on imperfect data. We demonstrate how appropriately handling multimodal information can be the key to achieving such robustness. CoRe-Sleep tolerates noisy or missing modalities segments, allowing training on incomplete data. Additionally, it shows state-of-the-art performance when testing on both multimodal and unimodal data using a single mode
    
[^37]: 探索NFT市场中的性别和种族偏见

    Exploring Gender and Race Biases in the NFT Market. (arXiv:2304.06484v1 [cs.CY])

    [http://arxiv.org/abs/2304.06484](http://arxiv.org/abs/2304.06484)

    本研究测试了 CryptoPunks 和 NFT市场中的种族和性别偏见。结果发现存在种族偏见而非性别偏见。同时，我们引入了一个带有性别标签的NFT艺术品数据集，以促进这个新兴市场的社会平等研究。

    

    非同质化代币(NFTs)是指那些通常存储在区块链上的非可替代性资产，通常是数字艺术。初步研究发现，女性和较深肤色的NFTs的价值低于男性和较浅肤色的作品。然而，这些研究仅分析了CryptoPunks艺术品收藏。我们测试了CryptoPunks价格中的种族和性别偏见的统计显著性，并首次研究了NFT市场的性别偏见。我们发现证据支持存在种族偏见而非性别偏见。我们的研究还引入了一个带有性别标签的NFT艺术品数据集，以推进对于这个新兴市场的社会平等性的更广泛研究。

    Non-Fungible Tokens (NFTs) are non-interchangeable assets, usually digital art, which are stored on the blockchain. Preliminary studies find that female and darker-skinned NFTs are valued less than their male and lighter-skinned counterparts. However, these studies analyze only the CryptoPunks collection. We test the statistical significance of race and gender biases in the prices of CryptoPunks and present the first study of gender bias in the broader NFT market. We find evidence of racial bias but not gender bias. Our work also introduces a dataset of gender-labeled NFT collections to advance the broader study of social equity in this emerging market.
    
[^38]: 基于$\beta$-VAE的心电图任务特定特征提取联合优化

    Joint optimization of a $\beta$-VAE for ECG task-specific feature extraction. (arXiv:2304.06476v1 [eess.SP])

    [http://arxiv.org/abs/2304.06476](http://arxiv.org/abs/2304.06476)

    本文研究了使用$\beta$-VAE作为可解释特征提取器，并联合优化信号重建和心脏功能预测。在7255名患者的数据上进行测试，显示出相比先前方法，该方法显著改善了预测能力和可解释性。

    

    心电图是研究心脏情况的最常用方法，通过观察心脏节律和电活动进行诊断和监测。本文研究了使用$\beta$-变分自动编码器作为可解释的特征提取器，并通过联合优化信号重建和心脏功能预测来改进其预测能力。然后，使用逻辑回归对提取的特征进行心脏功能预测。该方法在7255名患者的数据上进行训练和测试，并显示出与先前方法相比，我们的方法显著改善了预测能力和可解释性。

    Electrocardiography is the most common method to investigate the condition of the heart through the observation of cardiac rhythm and electrical activity, for both diagnosis and monitoring purposes. Analysis of electrocardiograms (ECGs) is commonly performed through the investigation of specific patterns, which are visually recognizable by trained physicians and are known to reflect cardiac (dis)function. In this work we study the use of $\beta$-variational autoencoders (VAEs) as an explainable feature extractor, and improve on its predictive capacities by jointly optimizing signal reconstruction and cardiac function prediction. The extracted features are then used for cardiac function prediction using logistic regression. The method is trained and tested on data from 7255 patients, who were treated for acute coronary syndrome at the Leiden University Medical Center between 2010 and 2021. The results show that our method significantly improved prediction and explainability compared to 
    
[^39]: 两个头胜过一个：一种生物启发的方法来改善对EEG-ET数据的分类

    Two Heads are Better than One: A Bio-inspired Method for Improving Classification on EEG-ET Data. (arXiv:2304.06471v1 [eess.SP])

    [http://arxiv.org/abs/2304.06471](http://arxiv.org/abs/2304.06471)

    该论文提出了一种生物启发的EEG数据分类方法，将特征选择和时间分割相结合，显着提高了机器学习分类器的性能，同时降低了计算复杂度。

    

    对EEG数据进行分类对于脑机接口（BCI）和其应用至关重要。然而，由于其生物性质和复杂的数据收集过程，外部噪声常常干扰EEG数据。特别是在处理分类任务时，标准EEG预处理方法从整个数据集中提取相关事件和特征，但这些方法平等地处理所有相关的认知事件，并忽视了大脑随时间动态的特性。相反，我们受到神经科学研究的启发，提出了一种新方法，将特征选择和EEG数据的时间分割相结合。在EEGEyeNet数据集上进行测试，我们提出的方法显着提高了机器学习分类器的性能，同时降低了它们各自的计算复杂度。

    Classifying EEG data is integral to the performance of Brain Computer Interfaces (BCI) and their applications. However, external noise often obstructs EEG data due to its biological nature and complex data collection process. Especially when dealing with classification tasks, standard EEG preprocessing approaches extract relevant events and features from the entire dataset. However, these approaches treat all relevant cognitive events equally and overlook the dynamic nature of the brain over time. In contrast, we are inspired by neuroscience studies to use a novel approach that integrates feature selection and time segmentation of EEG data. When tested on the EEGEyeNet dataset, our proposed method significantly increases the performance of Machine Learning classifiers while reducing their respective computational complexity.
    
[^40]: 分析隐私-效用移动模型的公平性

    Analysing Fairness of Privacy-Utility Mobility Models. (arXiv:2304.06469v1 [cs.LG])

    [http://arxiv.org/abs/2304.06469](http://arxiv.org/abs/2304.06469)

    本研究为人类移动性定义了一组公平度量指标，基于轨迹的结构相似性和熵，研究了两种依靠生成对抗网络和表示学习降低用户的重新识别率的隐私保护模型，并探讨了它们的公平性优势和差异。

    

    在共享时空数据集中，保护个人的隐私对于防止基于唯一轨迹的重新识别攻击至关重要。现有的隐私技术往往提出理想的隐私-效用权衡，但基本忽略了移动模型的公平性影响，以及这些技术对不同用户群体是否同等适用。在时空背景下，公平性与隐私意识模型之间的度量仍然不清晰，并且几乎不存在任何定义的公平度量集。在本文中，我们定义了一组专为人类移动性而设计的公平度量指标，基于轨迹的结构相似性和熵。在这些定义下，我们研究了两种最先进的隐私保护模型，在数据共享中依靠生成对抗网络和表示学习降低用户的重新识别率，检查了其公平性。我们的结果表明，虽然这两种模型都保证在组上公平性方面具有优势，但它们在个别公平性方面存在显著区别。

    Preserving the individuals' privacy in sharing spatial-temporal datasets is critical to prevent re-identification attacks based on unique trajectories. Existing privacy techniques tend to propose ideal privacy-utility tradeoffs, however, largely ignore the fairness implications of mobility models and whether such techniques perform equally for different groups of users. The quantification between fairness and privacy-aware models is still unclear and there barely exists any defined sets of metrics for measuring fairness in the spatial-temporal context. In this work, we define a set of fairness metrics designed explicitly for human mobility, based on structural similarity and entropy of the trajectories. Under these definitions, we examine the fairness of two state-of-the-art privacy-preserving models that rely on GAN and representation learning to reduce the re-identification rate of users for data sharing. Our results show that while both models guarantee group fairness in terms of de
    
[^41]: SpectFormer: 频率和注意力是视觉Transformer所需要的。

    SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v1 [cs.CV])

    [http://arxiv.org/abs/2304.06446](http://arxiv.org/abs/2304.06446)

    本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。

    

    视觉Transformer已成功地应用于图像识别任务中。其种类包括基于多头自我注意力机制（如ViT、DeIT）和基于谱层（如Fnet、GFNet、AFNO）的模型。本文发现，多头注意力和谱层都对Transformer起到重要作用，将两者结合可以得到更好的性能表现。因此提出了新的Spectformer架构，将多头注意力和谱层融合起来。实验表明，Spectformer可恰当地捕捉特征表示，与其他Transformer表征相比，可以提高top-1准确率2%。

    Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2
    
[^42]: 自监督ECG表征学习在心律失常检测中的应用研究：分布分析及实验探究

    In-Distribution and Out-of-Distribution Self-supervised ECG Representation Learning for Arrhythmia Detection. (arXiv:2304.06427v1 [cs.LG])

    [http://arxiv.org/abs/2304.06427](http://arxiv.org/abs/2304.06427)

    本文系统研究了自监督学习方法在ECG表征学习上的应用，首次对三个常用ECG心律失常数据集进行了分布分析，实验发现SwAV方法表现最佳，能够超越传统的有监督学习方法，还具有较强的鲁棒性，有望在大规模和多样化人群中检测心律失常。

    

    本文针对心电图(ECG)心律失常检测问题，系统地研究了自监督学习(Self-Supervised Learning, SSL)方法的有效性。我们首先对三个常用的ECG心律失常数据集进行了分布分析，并进行了综合性实验，使用不同增强和参数评估了各种SSL方法（如SimCRL、BYOL和SwAV）在ECG表征学习方面的有效性。实验结果表明，SwAV方法表现最佳。我们进一步进行了针对In-Distribution (ID)和Out-of-Distribution (OOD) ECG数据的交叉数据集训练和测试实验，结果表明SSL方法，特别是SwAV，在ECG表征学习方面具有很高的竞争力，并且对不同种类的ECG数据具有较强的鲁棒性，从而有望在大规模和多样化人群中检测心律失常。

    This paper presents a systematic investigation into the effectiveness of Self-Supervised Learning (SSL) methods for Electrocardiogram (ECG) arrhythmia detection. We begin by conducting a novel distribution analysis on three popular ECG-based arrhythmia datasets: PTB-XL, Chapman, and Ribeiro. To the best of our knowledge, our study is the first to quantify these distributions in this area. We then perform a comprehensive set of experiments using different augmentations and parameters to evaluate the effectiveness of various SSL methods, namely SimCRL, BYOL, and SwAV, for ECG representation learning, where we observe the best performance achieved by SwAV. Furthermore, our analysis shows that SSL methods achieve highly competitive results to those achieved by supervised state-of-the-art methods. To further assess the performance of these methods on both In-Distribution (ID) and Out-of-Distribution (OOD) ECG data, we conduct cross-dataset training and testing experiments. Our comprehensive
    
[^43]: 量化和解释预测流程监控中的机器学习不确定性：运筹学视角

    Quantifying and Explaining Machine Learning Uncertainty in Predictive Process Monitoring: An Operations Research Perspective. (arXiv:2304.06412v1 [cs.LG])

    [http://arxiv.org/abs/2304.06412](http://arxiv.org/abs/2304.06412)

    本论文提出了一种综合的、多阶段的机器学习方法，利用分位数回归森林生成区间预测来解决预测流程监控中的问题，同时使用SHapley可加解释来解释模型不确定性的来源。

    

    本文介绍了一种综合的、多阶段的机器学习方法，有效地将信息系统和人工智能融合，以增强运筹学领域内的决策过程。所提出的框架巧妙地解决了现有解决方案普遍存在的问题，比如忽略关键生产参数的数据驱动估计、仅生成点预测而不考虑模型不确定性以及缺乏关于这种不确定性来源的解释。我们的方法利用分位数回归森林生成区间预测，同时使用本地和全局变体的SHapley可加解释来解决研究的预测性过程监控问题。所提出的方法在一个真实的生产计划案例中得到了实际应用，并强调了规定性分析在精细化决策过程中的潜力。本文强调

    This paper introduces a comprehensive, multi-stage machine learning methodology that effectively integrates information systems and artificial intelligence to enhance decision-making processes within the domain of operations research. The proposed framework adeptly addresses common limitations of existing solutions, such as the neglect of data-driven estimation for vital production parameters, exclusive generation of point forecasts without considering model uncertainty, and lacking explanations regarding the sources of such uncertainty. Our approach employs Quantile Regression Forests for generating interval predictions, alongside both local and global variants of SHapley Additive Explanations for the examined predictive process monitoring problem. The practical applicability of the proposed methodology is substantiated through a real-world production planning case study, emphasizing the potential of prescriptive analytics in refining decision-making procedures. This paper accentuates
    
[^44]: 学习准确的性能预测器用于超快速自动模型压缩

    Learning Accurate Performance Predictors for Ultrafast Automated Model Compression. (arXiv:2304.06393v1 [cs.CV])

    [http://arxiv.org/abs/2304.06393](http://arxiv.org/abs/2304.06393)

    本文提出了一种超快速自动模型压缩框架SeerNet，通过直接优化具有准确性能预测器的压缩策略来实现对各种计算成本约束的超快速自动模型压缩。

    

    本文提出了一种名为SeerNet的超快速自动模型压缩框架，用于灵活的网络部署。与传统的非可微分方法和现有的可微分方法相比，我们通过直接优化具有准确性能预测器的压缩策略来获得最优的高效网络，在不需要复杂的压缩策略搜索和评估过程的情况下，实现了对各种计算成本约束的超快速自动模型压缩。

    In this paper, we propose an ultrafast automated model compression framework called SeerNet for flexible network deployment. Conventional non-differen-tiable methods discretely search the desirable compression policy based on the accuracy from exhaustively trained lightweight models, and existing differentiable methods optimize an extremely large supernet to obtain the required compressed model for deployment. They both cause heavy computational cost due to the complex compression policy search and evaluation process. On the contrary, we obtain the optimal efficient networks by directly optimizing the compression policy with an accurate performance predictor, where the ultrafast automated model compression for various computational cost constraint is achieved without complex compression policy search and evaluation. Specifically, we first train the performance predictor based on the accuracy from uncertain compression policies actively selected by efficient evolutionary search, so that
    
[^45]: VISION DIFFMASK：具有可微分补丁掩码的视觉Transformer的忠实解释

    VISION DIFFMASK: Faithful Interpretation of Vision Transformers with Differentiable Patch Masking. (arXiv:2304.06391v1 [cs.CV])

    [http://arxiv.org/abs/2304.06391](http://arxiv.org/abs/2304.06391)

    VISION DIFFMASK提出了一种可解释性的方法，通过使用门控机制识别最小输入子集来预测对其最终预测有贡献的输入部分。

    

    尽管具有高效性，但Vision Transformer缺乏可解释性可能会阻碍其在关键实际应用中的使用。为了克服这个问题，我们提出了一种名为VISION DIFFMASK的事后可解释性方法，该方法使用模型隐藏层的激活来预测对其最终预测有贡献的输入部分。我们的方法使用门控机制来识别保留预测类别分布的最小原始输入子集。我们通过引入忠实度任务并在CIFAR-10和ImageNet-1K上与其他最先进的归因方法进行比较，证明了我们方法的忠实度，取得了令人信服的结果。为了促进我们工作的再现性和进一步扩展，我们公开了我们的实现：https://github.com/AngelosNal/Vision-DiffMask

    The lack of interpretability of the Vision Transformer may hinder its use in critical real-world applications despite its effectiveness. To overcome this issue, we propose a post-hoc interpretability method called VISION DIFFMASK, which uses the activations of the model's hidden layers to predict the relevant parts of the input that contribute to its final predictions. Our approach uses a gating mechanism to identify the minimal subset of the original input that preserves the predicted distribution over classes. We demonstrate the faithfulness of our method, by introducing a faithfulness task, and comparing it to other state-of-the-art attribution methods on CIFAR-10 and ImageNet-1K, achieving compelling results. To aid reproducibility and further extension of our work, we open source our implementation: https://github.com/AngelosNal/Vision-DiffMask
    
[^46]: 早期感染性休克预测的多子集方法

    Multi-Subset Approach to Early Sepsis Prediction. (arXiv:2304.06384v1 [cs.LG])

    [http://arxiv.org/abs/2304.06384](http://arxiv.org/abs/2304.06384)

    本文提出了一种多子集方法，将不同特征子集的多个机器学习模型集成起来，可在ICU患者中早期预测感染性休克的发生。

    

    Sepsis是由于宿主无法抵御感染而引起的危及生命的器官功能障碍，如果不进行适当和及时的治疗，会导致死亡。因此，在高危人群中及时诊断和治疗感染性休克对提供患者快速治疗至关重要。研究表明，将感染性休克检测提前6小时可以提高抗生素的早期使用率，从而改善病死率。然而，诸如序贯器官衰竭评分（SOFA）之类的临床评分不适用于早期预测，而机器学习算法可以帮助捕捉早期预测的发展模式。因此，我们旨在开发一种机器学习算法，可以在临床怀疑感染性休克之前6小时预测其发生。尽管已经将一些机器学习算法应用于感染性休克预测，但其中许多算法并没有考虑到6小时并不是一个小的时间窗口。在本文中，我们提出了一种多子集方法，将具有不同特征子集的多个机器学习模型集成起来，从而可以早期预测ICU患者感染性休克的发生。

    Sepsis is a life-threatening organ malfunction caused by the host's inability to fight infection, which can lead to death without proper and immediate treatment. Therefore, early diagnosis and medical treatment of sepsis in critically ill populations at high risk for sepsis and sepsis-associated mortality are vital to providing the patient with rapid therapy. Studies show that advancing sepsis detection by 6 hours leads to earlier administration of antibiotics, which is associated with improved mortality. However, clinical scores like Sequential Organ Failure Assessment (SOFA) are not applicable for early prediction, while machine learning algorithms can help capture the progressing pattern for early prediction. Therefore, we aim to develop a machine learning algorithm that predicts sepsis onset 6 hours before it is suspected clinically. Although some machine learning algorithms have been applied to sepsis prediction, many of them did not consider the fact that six hours is not a small
    
[^47]: 基于神经态空间模型的不确定性量化的实证评估

    Neural State-Space Models: Empirical Evaluation of Uncertainty Quantification. (arXiv:2304.06349v1 [cs.LG])

    [http://arxiv.org/abs/2304.06349](http://arxiv.org/abs/2304.06349)

    本文以贝叶斯概率设置为框架，提出了神经态空间模型系统识别的不确定性量化方法，给出了后验分布、可信区间及惊异指数，以有效甄别模型在分布外情况下的使用可能带来的危险性。

    

    有效量化不确定性是实现深度学习在各种应用中，包括关键任务中更广泛采用的一个关键且仍然缺失的步骤。尤其是描述非线性动态系统的深度学习模型的预测不确定性的研究目前非常有限。本文旨在填补这一空白，并提出了神经态空间模型系统识别中的不确定性量化的初步结果。我们将学习问题框架放在贝叶斯概率设置中，并通过近似推理技术获得神经网络的权重和输出的后验分布。根据后验分布，我们构建输出的可信区间，并定义一种惊异指数，该指数可以有效地诊断模型在潜在危险的分布外情况下的使用情况，这时的预测是不能被信任的。

    Effective quantification of uncertainty is an essential and still missing step towards a greater adoption of deep-learning approaches in different applications, including mission-critical ones. In particular, investigations on the predictive uncertainty of deep-learning models describing non-linear dynamical systems are very limited to date. This paper is aimed at filling this gap and presents preliminary results on uncertainty quantification for system identification with neural state-space models. We frame the learning problem in a Bayesian probabilistic setting and obtain posterior distributions for the neural network's weights and outputs through approximate inference techniques. Based on the posterior, we construct credible intervals on the outputs and define a surprise index which can effectively diagnose usage of the model in a potentially dangerous out-of-distribution regime, where predictions cannot be trusted.
    
[^48]: 敏捷预测模型开发的简化框架提高库存管理效率

    Streamlined Framework for Agile Forecasting Model Development towards Efficient Inventory Management. (arXiv:2304.06344v1 [cs.LG])

    [http://arxiv.org/abs/2304.06344](http://arxiv.org/abs/2304.06344)

    本文提出了一个敏捷预测模型开发的框架，通过简化核心组件之间的连接使得新数据集能够快速和稳健地集成，并选择最佳模型。通过不同的评估指标，找到最适合不同应用的模型。该框架能够应用在库存管理环境中，提高效率。

    

    本文提出了一个框架，通过简化开发过程的核心组件之间的连接来开发预测模型。该框架使得新数据集能够快速和稳健地集成，实验不同算法，并选择最佳模型。我们从不同问题的数据集入手，并应用预处理步骤来清理和提取时间序列数据的有意义表示。为了确定稳健的训练配置，我们引入了一种新的多重交叉验证策略机制。我们应用不同的评估指标来找到最适合不同应用的模型。其中之一是我们参加了美国国际开发署（USAID）组织的智能预测竞赛。最后，我们利用框架的灵活性，应用不同的评估指标来评估模型在库存管理环境中的性能。

    This paper proposes a framework for developing forecasting models by streamlining the connections between core components of the developmental process. The proposed framework enables swift and robust integration of new datasets, experimentation on different algorithms, and selection of the best models. We start with the datasets of different issues and apply pre-processing steps to clean and engineer meaningful representations of time-series data. To identify robust training configurations, we introduce a novel mechanism of multiple cross-validation strategies. We apply different evaluation metrics to find the best-suited models for varying applications. One of the referent applications is our participation in the intelligent forecasting competition held by the United States Agency of International Development (USAID). Finally, we leverage the flexibility of the framework by applying different evaluation metrics to assess the performance of the models in inventory management settings.
    
[^49]: 多属性多阶图卷积神经网络用于异构图

    Attributed Multi-order Graph Convolutional Network for Heterogeneous Graphs. (arXiv:2304.06336v1 [cs.LG])

    [http://arxiv.org/abs/2304.06336](http://arxiv.org/abs/2304.06336)

    本文提出了一个AMOGCN模型，它自动从多阶邻接矩阵的自适应聚合中研究包含多跳邻居的元路径，并使用节点属性评价监督。其能够有效地从异构图中发现有区别的节点嵌入和关系。

    

    异构图神经网络旨在从多关系网络中发现有区别的节点嵌入和关系。异构图学习的一个挑战是设计可学习的元路径，它显着地影响了学习到的嵌入的质量。因此，在本文中，我们提出了一个带属性的多阶图卷积网络（AMOGCN），它自动从多阶邻接矩阵的自适应聚合中研究包含多跳邻居的元路径。该模型首先从手动设计的节点连接中构建不同阶数的邻接矩阵。之后，从各种阶数的邻接矩阵的自动融合中附加一个完整的多阶邻接矩阵。这个过程由从节点同质性通过属性评价提取的节点语义信息监督。最终，我们使用一个学习到的多阶邻接矩阵的一层简化图卷积网络。

    Heterogeneous graph neural networks aim to discover discriminative node embeddings and relations from multi-relational networks.One challenge of heterogeneous graph learning is the design of learnable meta-paths, which significantly influences the quality of learned embeddings.Thus, in this paper, we propose an Attributed Multi-Order Graph Convolutional Network (AMOGCN), which automatically studies meta-paths containing multi-hop neighbors from an adaptive aggregation of multi-order adjacency matrices. The proposed model first builds different orders of adjacency matrices from manually designed node connections. After that, an intact multi-order adjacency matrix is attached from the automatic fusion of various orders of adjacency matrices. This process is supervised by the node semantic information, which is extracted from the node homophily evaluated by attributes. Eventually, we utilize a one-layer simplifying graph convolutional network with the learned multi-order adjacency matrix,
    
[^50]: 基于深度学习的集成模型粗细CNN和GRU网络的跌倒检测算法

    Deep Learning-based Fall Detection Algorithm Using Ensemble Model of Coarse-fine CNN and GRU Networks. (arXiv:2304.06335v1 [cs.LG])

    [http://arxiv.org/abs/2304.06335](http://arxiv.org/abs/2304.06335)

    该研究提出一种基于粗细CNN和GRU网络的深度学习集成模型，用于更可靠的跌倒检测，能够还原不同的空间特征粒度，并捕获时间依赖关系以进行特征表示。

    

    跌倒是全球老年人的公共健康问题，跌倒所导致的伤害与大量医疗成本有关。跌倒可以造成严重的伤害，甚至导致死亡，如果老年人长时间躺着。因此，需要可靠的跌倒检测 (FD) 系统，以提供紧急求助警报。由于可穿戴设备技术和人工智能的进步，一些跌倒检测系统已经使用机器学习和深度学习方法，分析从加速度计和陀螺仪收集的信号。为了实现更好的跌倒检测性能，本研究提出了一种结合了粗细卷积神经网络和门控循环单元的集成模型。该模型中所采用的并行结构设计还原了不同空间特征的粒度，并捕获了时间依赖关系以进行特征表示。本研究将FallAllD公共数据集应用于验证。

    Falls are the public health issue for the elderly all over the world since the fall-induced injuries are associated with a large amount of healthcare cost. Falls can cause serious injuries, even leading to death if the elderly suffers a "long-lie". Hence, a reliable fall detection (FD) system is required to provide an emergency alarm for first aid. Due to the advances in wearable device technology and artificial intelligence, some fall detection systems have been developed using machine learning and deep learning methods to analyze the signal collected from accelerometer and gyroscopes. In order to achieve better fall detection performance, an ensemble model that combines a coarse-fine convolutional neural network and gated recurrent unit is proposed in this study. The parallel structure design used in this model restores the different grains of spatial characteristics and capture temporal dependencies for feature representation. This study applies the FallAllD public dataset to valida
    
[^51]: 符号回归的先验知识

    Priors for symbolic regression. (arXiv:2304.06333v1 [cs.LG])

    [http://arxiv.org/abs/2304.06333](http://arxiv.org/abs/2304.06333)

    本文提出了一种在符号回归（SR）框架内将有关函数和参数的详细先验信息纳入的方法，并且演示了该先验在基准数据集和材料科学应用中的性能。

    

    在为数据集选择符号模型时，人们自然倾向于选择“简单”的表达式或更接近之前在类似情况下看到的方程式。这表明函数应该具有非均匀先验知识，然而，在符号回归（SR）框架内很少考虑。在本文中，我们开发了一种方法，将有关函数和参数的详细先验信息纳入SR中。我们对函数结构的先验是基于n-gram语言模型的，该模型对各个运算符的排列方式以及每个运算符的出现频率都非常敏感。我们还开发了一种基于分式贝叶斯因子的形式体系，以处理数值参数的先验知识，使得可以通过贝叶斯证据公平比较模型，同时明确比较了贝叶斯、最小描述长度和启发式方法用于模型选择。我们通过对基准数据集进行实验以及在材料科学中的应用演示了我们的先验的性能。

    When choosing between competing symbolic models for a data set, a human will naturally prefer the "simpler" expression or the one which more closely resembles equations previously seen in a similar context. This suggests a non-uniform prior on functions, which is, however, rarely considered within a symbolic regression (SR) framework. In this paper we develop methods to incorporate detailed prior information on both functions and their parameters into SR. Our prior on the structure of a function is based on a $n$-gram language model, which is sensitive to the arrangement of operators relative to one another in addition to the frequency of occurrence of each operator. We also develop a formalism based on the Fractional Bayes Factor to treat numerical parameter priors in such a way that models may be fairly compared though the Bayesian evidence, and explicitly compare Bayesian, Minimum Description Length and heuristic methods for model selection. We demonstrate the performance of our pri
    
[^52]: 理解核回归对抗训练中的过拟合现象

    Understanding Overfitting in Adversarial Training in Kernel Regression. (arXiv:2304.06326v1 [stat.ML])

    [http://arxiv.org/abs/2304.06326](http://arxiv.org/abs/2304.06326)

    本文研究了核回归的对抗训练和带噪声的数据增强，发现如果没有适当的正则化，这两种方法可能会导致过拟合现象，但适当的正则化可以缓解这种现象，提高性能。

    

    对抗训练和带噪声的数据增强是提高神经网络性能的常见方法。本文研究了在再生希尔伯特空间（RKHS）中正则化回归的对抗训练和带噪声的数据增强。当攻击和噪声大小以及正则化参数趋向于零时，建立了这些技术的极限公式。根据该极限公式，分析了特定情况并证明了，如果没有适当的正则化，这两种方法可能具有大于标准核回归的广义误差和Lipschitz常数。然而，通过选择适当的正则化参数，这两种方法可以优于标准核回归，达到更小的广义误差和Lipschitz常数。这些发现支持对抗训练可能导致过拟合的经验观察，以及适当的正则化方法能够缓解这种过拟合现象。

    Adversarial training and data augmentation with noise are widely adopted techniques to enhance the performance of neural networks. This paper investigates adversarial training and data augmentation with noise in the context of regularized regression in a reproducing kernel Hilbert space (RKHS). We establish the limiting formula for these techniques as the attack and noise size, as well as the regularization parameter, tend to zero. Based on this limiting formula, we analyze specific scenarios and demonstrate that, without appropriate regularization, these two methods may have larger generalization error and Lipschitz constant than standard kernel regression. However, by selecting the appropriate regularization parameter, these two methods can outperform standard kernel regression and achieve smaller generalization error and Lipschitz constant. These findings support the empirical observations that adversarial training can lead to overfitting, and appropriate regularization methods, suc
    
[^53]: 应用顺序蒙特卡罗方法进行虚拟流量计校准

    Sequential Monte Carlo applied to virtual flow meter calibration. (arXiv:2304.06310v1 [cs.LG])

    [http://arxiv.org/abs/2304.06310](http://arxiv.org/abs/2304.06310)

    提出了一种利用顺序蒙特卡罗方法进行虚拟流量计校准的新方法，该方法可以连续地联合校准VFMs，即使单独井流量高度不平衡也能提供准确的校准。

    

    软测量由于其在设备上的干预较少且成本低廉而变得越来越受欢迎。在石油和天然气生产中，虚拟流量计（VFM）是一种流行的软测量方法，试图实时估计复相流量。VFM基于模型，这些模型需要校准。校准高度依赖应用程序，既因为模型的多样性，也因为可用测量的多样性。通过仔细调整VFM参数以满足井测试可实现最精确的校准，但这可能是繁重的，而且并不是所有的井都有频繁的井测试数据可用。本文提出了一种基于生产分离器提供的测量，以及观察到的流量应该等于每个单独井的流量之和的假设，可以连续地联合校准VFMs的方法。该方法应用顺序蒙特卡罗（SMC）方法来估计VFM模型的参数。在合成数据上的结果表明，所提出的方法可以在单独井流量高度不平衡的情况下提供准确且连续的VFM校准。

    Soft-sensors are gaining popularity due to their ability to provide estimates of key process variables with little intervention required on the asset and at a low cost. In oil and gas production, virtual flow metering (VFM) is a popular soft-sensor that attempts to estimate multiphase flow rates in real time. VFMs are based on models, and these models require calibration. The calibration is highly dependent on the application, both due to the great diversity of the models, and in the available measurements. The most accurate calibration is achieved by careful tuning of the VFM parameters to well tests, but this can be work intensive, and not all wells have frequent well test data available. This paper presents a calibration method based on the measurement provided by the production separator, and the assumption that the observed flow should be equal to the sum of flow rates from each individual well. This allows us to jointly calibrate the VFMs continuously. The method applies Sequenti
    
[^54]: 改进的朴素贝叶斯算法处理误标签数据

    Improved Naive Bayes with Mislabeled Data. (arXiv:2304.06292v1 [cs.LG])

    [http://arxiv.org/abs/2304.06292](http://arxiv.org/abs/2304.06292)

    该论文提出了一种改进的朴素贝叶斯算法来处理误标签数据，通过指定误标签的生成机制，使用EM算法迭代优化对数似然函数来提高分类性能。

    

    在实际应用中，标签错误是经常遇到的问题。如果未得到妥善处理，标签错误会严重影响模型的分类性能。为了解决这个问题，我们提出了一种改进的朴素贝叶斯文本分类方法。它在分析上很简单，没有任何关于正确和错误标签的主观判断。通过指定错误标签的生成机制，我们使用EM算法迭代优化相应的对数似然函数。我们的模拟和实验结果表明，改进的朴素贝叶斯方法极大地提高了处理误标签数据的朴素贝叶斯方法的性能。

    Labeling mistakes are frequently encountered in real-world applications. If not treated well, the labeling mistakes can deteriorate the classification performances of a model seriously. To address this issue, we propose an improved Naive Bayes method for text classification. It is analytically simple and free of subjective judgements on the correct and incorrect labels. By specifying the generating mechanism of incorrect labels, we optimize the corresponding log-likelihood function iteratively by using an EM algorithm. Our simulation and experiment results show that the improved Naive Bayes method greatly improves the performances of the Naive Bayes method with mislabeled data.
    
[^55]: 模型驱动的动态盾型保障用于安全和高效的多智能体强化学习

    Model-based Dynamic Shielding for Safe and Efficient Multi-Agent Reinforcement Learning. (arXiv:2304.06281v1 [cs.LG])

    [http://arxiv.org/abs/2304.06281](http://arxiv.org/abs/2304.06281)

    本论文介绍了模型驱动的动态屏蔽设计用于多智能体强化学习中的安全保障，屏蔽器能够动态分割、合并和重新计算智能体状态，同时支持更加高效的合成屏蔽器以监控复杂环境中的智能体。

    

    多智能体强化学习(MARL)发现最大化回报的策略，但在学习和部署阶段没有安全保障。虽然线性时间逻辑(LTL)的屏蔽是确保单智能体强化学习(RL)安全的有前途的正式方法，但它在扩展到多智能体场景时会导致保守行为。此外，在复杂多智能体环境中合成屏蔽存在计算挑战。本文介绍了MBDS以支持MARL算法设计。我们的算法合成分布式屏蔽器，这些屏蔽器是与每个MARL智能体并行运行的反应系统，用于监控和纠正不安全的行为。这种设计使得在没有协调开销的情况下，能够有效合成屏蔽器以监视复杂环境中的智能体。我们还提出一种算法，在不知道环境的完整转换函数的情况下合成屏障，并展示我们的方法在交通信号控制任务和无人机巡逻任务中优于LTL屏蔽。

    Multi-Agent Reinforcement Learning (MARL) discovers policies that maximize reward but do not have safety guarantees during the learning and deployment phases. Although shielding with Linear Temporal Logic (LTL) is a promising formal method to ensure safety in single-agent Reinforcement Learning (RL), it results in conservative behaviors when scaling to multi-agent scenarios. Additionally, it poses computational challenges for synthesizing shields in complex multi-agent environments. This work introduces Model-based Dynamic Shielding (MBDS) to support MARL algorithm design. Our algorithm synthesizes distributive shields, which are reactive systems running in parallel with each MARL agent, to monitor and rectify unsafe behaviors. The shields can dynamically split, merge, and recompute based on agents' states. This design enables efficient synthesis of shields to monitor agents in complex environments without coordination overheads. We also propose an algorithm to synthesize shields witho
    
[^56]: 基于主动学习的改进策略优化多领域性能

    Optimizing Multi-Domain Performance with Active Learning-based Improvement Strategies. (arXiv:2304.06277v1 [cs.LG])

    [http://arxiv.org/abs/2304.06277](http://arxiv.org/abs/2304.06277)

    本文提出了一个基于主动学习的框架，用于改善多领域性能。该方法分为两个阶段，在保证高效性的前提下实现了最先进的性能。

    

    提高多领域性能是一个具有挑战性的任务，通常需要大量的数据来训练和测试模型。主动学习技术通过使模型选择最具信息量的样本进行标记，从而减少了实现高性能所需的标记数据量，提供了一个有希望的解决方案。本文提出了一个基于主动学习的框架，用于改进多个领域的性能。我们的方法分为两个阶段：首先，我们使用一组初始标记数据来训练基础模型，然后我们迭代地选择最具信息量的样本进行标记，以改进模型。我们在多个数据集上评估了我们的方法，包括图像分类、情感分析和物体识别。我们的实验表明，我们的方法始终优于基准方法，并在多个数据集上实现了最先进的性能。我们还表明，我们的方法高效，只需要很小的标记数据量就能取得更好的性能。

    Improving performance in multiple domains is a challenging task, and often requires significant amounts of data to train and test models. Active learning techniques provide a promising solution by enabling models to select the most informative samples for labeling, thus reducing the amount of labeled data required to achieve high performance. In this paper, we present an active learning-based framework for improving performance across multiple domains. Our approach consists of two stages: first, we use an initial set of labeled data to train a base model, and then we iteratively select the most informative samples for labeling to refine the model. We evaluate our approach on several multi-domain datasets, including image classification, sentiment analysis, and object recognition. Our experiments demonstrate that our approach consistently outperforms baseline methods and achieves state-of-the-art performance on several datasets. We also show that our method is highly efficient, requirin
    
[^57]: 规范和非规范哈密顿算子推理

    Canonical and Noncanonical Hamiltonian Operator Inference. (arXiv:2304.06262v1 [cs.LG])

    [http://arxiv.org/abs/2304.06262](http://arxiv.org/abs/2304.06262)

    介绍了一种结构保留的模型简化方法，可以用于规范和非规范哈密顿系统，具有收敛性和良好的保守性质。

    

    本文介绍了一种用于规范和非规范哈密顿系统的非侵入式和结构保留的模型简化方法。基于算子推理的思想，这种技术是可证明收敛的，并且在给定快照数据和系统哈密顿的灰盒知识的情况下，可以简化为一个直接的线性求解问题。通过几个涉及多个双曲型偏微分方程的例子，结果表明所提出的方法产生的简化模型除了准确且稳定地处理基础模式的添加外，还可以很好地保留其训练数据范围之外的守恒量。

    A method for the nonintrusive and structure-preserving model reduction of canonical and noncanonical Hamiltonian systems is presented. Based on the idea of operator inference, this technique is provably convergent and reduces to a straightforward linear solve given snapshot data and gray-box knowledge of the system Hamiltonian. Examples involving several hyperbolic partial differential equations show that the proposed method yields reduced models which, in addition to being accurate and stable with respect to the addition of basis modes, preserve conserved quantities well outside the range of their training data.
    
[^58]: MProtoNet：一种基于案例的可解释性模型，用于带有3D多参数磁共振成像的脑肿瘤分类

    MProtoNet: A Case-Based Interpretable Model for Brain Tumor Classification with 3D Multi-parametric Magnetic Resonance Imaging. (arXiv:2304.06258v1 [cs.CV])

    [http://arxiv.org/abs/2304.06258](http://arxiv.org/abs/2304.06258)

    本论文提出了一种基于案例的可解释性模型MProtoNet，用于带有3D多参数磁共振成像的脑肿瘤分类，通过引入新型的注意模块，比四个状态-of-the-art深度学习模型在解释性和分类性能上有所提高。

    

    近年来，深度卷积神经网络在医学影像中的应用引发了人们对其可解释性的担忧。我们提出了第一个医疗原型网络（MProtoNet），用于将ProtoPNet扩展到使用3D多参数磁共振成像数据进行脑肿瘤分类。为了解决2D自然图像和3D mpMRI之间在本地化注意区域方面的不同要求，引入了一种使用软掩膜和在线CAM损失的新型注意模块。MProtoNet通过注意力映射和原型可视化维持解释性，并在一个包含脑胶质瘤和脑膜瘤的mpMRI数据集上取得了显著的分类性能提高。

    Recent applications of deep convolutional neural networks in medical imaging raise concerns about their interpretability. While most explainable deep learning applications use post hoc methods (such as GradCAM) to generate feature attribution maps, there is a new type of case-based reasoning models, namely ProtoPNet and its variants, which identify prototypes during training and compare input image patches with those prototypes. We propose the first medical prototype network (MProtoNet) to extend ProtoPNet to brain tumor classification with 3D multi-parametric magnetic resonance imaging (mpMRI) data. To address different requirements between 2D natural images and 3D mpMRIs especially in terms of localizing attention regions, a new attention module with soft masking and online-CAM loss is introduced. Soft masking helps sharpen attention maps, while online-CAM loss directly utilizes image-level labels when training the attention module. MProtoNet achieves statistically significant improv
    
[^59]: 使用多种分子图表示增强化合物性质和活性预测中的模型学习和解释能力

    Enhancing Model Learning and Interpretation Using Multiple Molecular Graph Representations for Compound Property and Activity Prediction. (arXiv:2304.06253v1 [q-bio.BM])

    [http://arxiv.org/abs/2304.06253](http://arxiv.org/abs/2304.06253)

    本文研究了使用多种分子图表示增强化合物属性和活性预测中的模型学习和解释能力的方法，并提出了利用可解释性方法增强图神经网络模型的解释性能力，对于药物发现有重要帮助。

    

    图神经网络（GNN）由于能够高效地学习复杂的分子结构而在化合物性质和活性预测中表现出色。然而，化合物的表示和模型的解释性仍存在两个主要限制。虽然基于原子级别的分子图表示通常被使用，因为它们能够捕捉自然拓扑，但它们可能不能完全表达重要的亚结构或功能基团，这些基团对分子性质有着重要的影响。因此，近期的研究提出了采用降维技术融合高级信息的替代表示，同时利用两种表示进行模型学习。然而，关于不同分子图表示对模型学习和解释的研究仍不够充分。解释性对于药物发现也至关重要，它可以提供化学洞察力和优化灵感。许多研究尝试通过可解释性的方法来增强GNN模型的解释性能力。

    Graph neural networks (GNNs) demonstrate great performance in compound property and activity prediction due to their capability to efficiently learn complex molecular graph structures. However, two main limitations persist including compound representation and model interpretability. While atom-level molecular graph representations are commonly used because of their ability to capture natural topology, they may not fully express important substructures or functional groups which significantly influence molecular properties. Consequently, recent research proposes alternative representations employing reduction techniques to integrate higher-level information and leverages both representations for model learning. However, there is still a lack of study about different molecular graph representations on model learning and interpretation. Interpretability is also crucial for drug discovery as it can offer chemical insights and inspiration for optimization. Numerous studies attempt to inclu
    
[^60]: 具有浅层解码器的不对称神经图像压缩

    Asymmetrically-powered Neural Image Compression with Shallow Decoders. (arXiv:2304.06244v1 [eess.IV])

    [http://arxiv.org/abs/2304.06244](http://arxiv.org/abs/2304.06244)

    采用浅层或线性解码转换来缩小解码复杂度，同时利用通常不对称的计算预算、更强的编码网络和迭代编码来保持压缩性能，实现了速率失真性能与传统方法相竞争，解码复杂度降低80%以上。

    

    近年来，神经图像压缩方法表现越来越强。但与传统编解码器相比，它们的计算复杂度高出数个数量级，这成为实际部署的障碍。本文通过采用浅层甚至线性解码转换来缩小解码复杂度的差距迈出了一步。为了弥补由此导致的压缩性能下降，作者利用编码和解码之间通常不对称的计算预算，采用更强大的编码网络和迭代编码。理论上证明了这个想法，实验结果在神经图像压缩的速率失真和解码复杂度的权衡方面开启了新的前沿。具体而言，我们实现了与Minnen等人（2018）的平均比例超先验体系结构相竞争的速率失真性能，同时减小了总体解码复杂度80％，或者超过。

    Neural image compression methods have seen increasingly strong performance in recent years. However, they suffer orders of magnitude higher computational complexity compared to traditional codecs, which stands in the way of real-world deployment. This paper takes a step forward in closing this gap in decoding complexity by adopting shallow or even linear decoding transforms. To compensate for the resulting drop in compression performance, we exploit the often asymmetrical computation budget between encoding and decoding, by adopting more powerful encoder networks and iterative encoding. We theoretically formalize the intuition behind, and our experimental results establish a new frontier in the trade-off between rate-distortion and decoding complexity for neural image compression. Specifically, we achieve rate-distortion performance competitive with the established mean-scale hyperprior architecture of Minnen et al. (2018), while reducing the overall decoding complexity by 80 %, or ove
    
[^61]: 一种基于心律失常分类指导的心电图分割模型

    An Arrhythmia Classification-Guided Segmentation Model for Electrocardiogram Delineation. (arXiv:2304.06237v1 [cs.LG])

    [http://arxiv.org/abs/2304.06237](http://arxiv.org/abs/2304.06237)

    本文提出了一种利用深度学习模型结合心律失常分类指导的心电图分割方法，能够准确划分广泛异常节律类型的信号，减少虚报检测。

    

    准确划分ECG中的关键波形是提取相关特征以支持诊断和治疗心脏疾病的关键步骤。虽然利用分割模型的深度学习方法定位P、QRS和T波已经取得了有希望的结果，但它们处理呈现心律失常的信号的能力尚不明确。在本研究中，我们提出了一种新方法，利用深度学习模型准确划分具有广泛心律失常的信号。我们的方法是使用混合损失函数训练分割模型，将分割与心律失常分类任务相结合。此外，我们还使用包含各种心律失常类型的多样化训练集，使我们的模型能够处理广泛的具有挑战性的情况。实验结果表明，我们的模型准确划分了广泛异常节律类型的信号，同时结合分类指导的训练可以有效地减少虚报检测。

    Accurate delineation of key waveforms in an ECG is a critical initial step in extracting relevant features to support the diagnosis and treatment of heart conditions. Although deep learning based methods using a segmentation model to locate P, QRS and T waves have shown promising results, their ability to handle signals exhibiting arrhythmia remains unclear. In this study, we propose a novel approach that leverages a deep learning model to accurately delineate signals with a wide range of arrhythmia. Our approach involves training a segmentation model using a hybrid loss function that combines segmentation with the task of arrhythmia classification. In addition, we use a diverse training set containing various arrhythmia types, enabling our model to handle a wide range of challenging cases. Experimental results show that our model accurately delineates signals with a broad range of abnormal rhythm types, and the combined training with classification guidance can effectively reduce fals
    
[^62]: 物理信息径向基网络（PIRBN）：用于求解非线性偏微分方程的局部逼近神经网络

    Physics-informed radial basis network (PIRBN): A local approximation neural network for solving nonlinear PDEs. (arXiv:2304.06234v1 [cs.LG])

    [http://arxiv.org/abs/2304.06234](http://arxiv.org/abs/2304.06234)

    PIRBN是一种局部逼近神经网络，适用于求解具有高频特征和不适定计算域的PDE方程，相比PINN更加高效有效。通过使用梯度下降法训练PIRBN可以收敛到高斯过程。

    

    我们最近的深入研究发现，经过训练后的物理信息神经网络（PINN）往往是局部逼近器。这一观察结果引发了这种新型的物理信息径向基网络（PIRBN），它可以在整个训练过程中保持局部特性。与深度神经网络相比，PIRBN只包含一个隐藏层和一个径向基“激活”函数。在适当的条件下，我们证明了使用梯度下降法训练PIRBN可以收敛到高斯过程。此外，我们通过神经切线核（NTK）理论研究了PIRBN的训练动力学。此外，我们还对PIRBN的初始化策略进行了全面调查。基于数值例子，PIRBN已被证明比PINN在解决具有高频特征和不适定计算域的PDE方程方面更有效和高效。此外，现有的PINN数字技术，例如ad...

    Our recent intensive study has found that physics-informed neural networks (PINN) tend to be local approximators after training. This observation leads to this novel physics-informed radial basis network (PIRBN), which can maintain the local property throughout the entire training process. Compared to deep neural networks, a PIRBN comprises of only one hidden layer and a radial basis "activation" function. Under appropriate conditions, we demonstrated that the training of PIRBNs using gradient descendent methods can converge to Gaussian processes. Besides, we studied the training dynamics of PIRBN via the neural tangent kernel (NTK) theory. In addition, comprehensive investigations regarding the initialisation strategies of PIRBN were conducted. Based on numerical examples, PIRBN has been demonstrated to be more effective and efficient than PINN in solving PDEs with high-frequency features and ill-posed computational domains. Moreover, the existing PINN numerical techniques, such as ad
    
[^63]: 基于SA-MGCRN的野火疏散情况下交通需求预测方法研究

    Situational-Aware Multi-Graph Convolutional Recurrent Network (SA-MGCRN) for Travel Demand Forecasting During Wildfires. (arXiv:2304.06233v1 [cs.LG])

    [http://arxiv.org/abs/2304.06233](http://arxiv.org/abs/2304.06233)

    本研究提出一种新的方法框架，利用大规模GPS数据和最先进的人工智能技术，建立了采用多种数据源的出行生成模型，并提出了基于SA-MGCRN的情境感知多图卷积递归网络以实现野火疏散时交通需求的实时预测。

    

    在野火疏散期间实时准确地预测交通需求对于应急管理人员和交通规划者做出及时和明智的决策至关重要。然而，目前很少有研究关注大规模紧急疏散情况下的准确交通需求预测。因此，本研究提出并测试了一种新的方法框架，利用大规模移动设备生成的GPS数据和最先进的人工智能技术，建立了采用多种数据源的出行生成模型，并开展了交通需求预测。基于GPS数据推断出的交通需求，本研究提出了一种新的深度学习模型——基于SA-MGCRN的情境感知多图卷积递归网络，并提出了一种模型更新方案以实现野火疏散期间交通需求的实时预测。本研究在真实案例——加利福尼亚州索诺玛县2019年Kincade火灾中对提出的方法框架进行了测试。

    Real-time forecasting of travel demand during wildfire evacuations is crucial for emergency managers and transportation planners to make timely and better-informed decisions. However, few studies focus on accurate travel demand forecasting in large-scale emergency evacuations. Therefore, this study develops and tests a new methodological framework for modeling trip generation in wildfire evacuations by using (a) large-scale GPS data generated by mobile devices and (b) state-of-the-art AI technologies. The proposed methodology aims at forecasting evacuation trips and other types of trips. Based on the travel demand inferred from the GPS data, we develop a new deep learning model, i.e., Situational-Aware Multi-Graph Convolutional Recurrent Network (SA-MGCRN), along with a model updating scheme to achieve real-time forecasting of travel demand during wildfire evacuations. The proposed methodological framework is tested in this study for a real-world case study: the 2019 Kincade Fire in So
    
[^64]: 威斯康星公立学校社交预测的困难教训

    Difficult Lessons on Social Prediction from Wisconsin Public Schools. (arXiv:2304.06205v1 [cs.CY])

    [http://arxiv.org/abs/2304.06205](http://arxiv.org/abs/2304.06205)

    美国公立学校引入的预测算法（EWS）未能提高毕业率，EWS准确性高，但环境因素影响更大。

    

    美国公立学校近期引入了预测算法（EWS）来提高毕业率。这些系统通过预测哪些学生可能退学，帮助对个体学生进行干预。虽然投资巨大，得到广泛应用，但对EWS有效性的理解仍然存在重大差距。本研究利用威斯康星全区的近十年数据，首次对EWS对毕业率的长期影响进行大规模评估。我们提供证据表明预测系统所做的风险评估非常准确，特别是对于来自边缘化背景的学生。尽管该系统准确性高并且得到广泛应用，但我们发现没有证据表明它会导致毕业率的提高。我们提供了一个强大的统计模式，可以解释为什么这些看似矛盾的见解存在，即环境因素，例如学生所在学校或社区的质量，淹没了EWS对毕业率可能产生的任何影响。

    Early warning systems (EWS) are prediction algorithms that have recently taken a central role in efforts to improve graduation rates in public schools across the US. These systems assist in targeting interventions at individual students by predicting which students are at risk of dropping out. Despite significant investments and adoption, there remain significant gaps in our understanding of the efficacy of EWS. In this work, we draw on nearly a decade's worth of data from a system used throughout Wisconsin to provide the first large-scale evaluation of the long-term impact of EWS on graduation outcomes.  We present evidence that risk assessments made by the prediction system are highly accurate, including for students from marginalized backgrounds. Despite the system's accuracy and widespread use, we find no evidence that it has led to improved graduation rates. We surface a robust statistical pattern that can explain why these seemingly contradictory insights hold. Namely, environmen
    
[^65]: SURFSUP：学习新颖表面流体模拟

    SURFSUP: Learning Fluid Simulation for Novel Surfaces. (arXiv:2304.06197v1 [cs.LG])

    [http://arxiv.org/abs/2304.06197](http://arxiv.org/abs/2304.06197)

    SURFSUP采用有符号距离函数连续表示对象，提供更准确和高效的流体对象相互作用的学习方法；且能够适用于分布之外的复杂真实场景和对象，可以反演适用于物体操纵流体流动。

    

    在设计、图形和机器人领域，模拟复杂场景中流体的力学是至关重要的。基于学习的方法提供了快速和可微的流体模拟器，但是先前的大部分工作不能精确地模拟流体如何与在训练中未见过的新颖表面相互作用。我们引入了SURFSUP，这是一个使用有符号距离函数（SDF）隐式表示对象的框架，而不是显式表示网格或粒子。几何体的这种连续表示使得在长时间段内更准确地模拟流体对象相互作用成为可能，同时使计算更加高效。此外，SURFSUP在简单的形状基元上训练，能够广泛地适用于分布之外，甚至适用于复杂的真实场景和对象。最后，我们展示了我们可以反演我们的模型来设计简单的物体来操纵流体流动。

    Modeling the mechanics of fluid in complex scenes is vital to applications in design, graphics, and robotics. Learning-based methods provide fast and differentiable fluid simulators, however most prior work is unable to accurately model how fluids interact with genuinely novel surfaces not seen during training. We introduce SURFSUP, a framework that represents objects implicitly using signed distance functions (SDFs), rather than an explicit representation of meshes or particles. This continuous representation of geometry enables more accurate simulation of fluid-object interactions over long time periods while simultaneously making computation more efficient. Moreover, SURFSUP trained on simple shape primitives generalizes considerably out-of-distribution, even to complex real-world scenes and objects. Finally, we show we can invert our model to design simple objects to manipulate fluid flow.
    
[^66]: 针对部分观测非线性系统的全收敛和Lipschitz闭环学习策略参数化

    Learning Over All Contracting and Lipschitz Closed-Loops for Partially-Observed Nonlinear Systems. (arXiv:2304.06193v1 [eess.SY])

    [http://arxiv.org/abs/2304.06193](http://arxiv.org/abs/2304.06193)

    本文提出了一种针对非线性部分观测动态系统的学习控制策略参数化，能够自动满足闭环系统的稳定性和用户可调整的鲁棒性条件，在两个强化学习任务的模拟中表现良好且有强鲁棒性。

    

    本文针对非线性部分观测动态系统提出了一种基于 Youla 参数化和最近提出的 REN 模型的学习控制策略参数化。我们证明，该策略参数化自动满足了闭环系统的稳定性（收敛）和用户可调整的鲁棒性（Lipschitz）条件。这意味着它可以用于安全的基于学习的控制，不需要额外的约束或投影来强制稳定性或鲁棒性。我们在两个强化学习任务的模拟中测试了新的策略类：1）磁悬浮，2）倒置旋转臂摆。我们发现 Youla-REN 在确保稳定性和展示对敌对扰动提高的鲁棒性的同时，表现类似于现有的学习控制和最优控制方法。

    This paper presents a policy parameterization for learning-based control on nonlinear, partially-observed dynamical systems. The parameterization is based on a nonlinear version of the Youla parameterization and the recently proposed Recurrent Equilibrium Network (REN) class of models. We prove that the resulting Youla-REN parameterization automatically satisfies stability (contraction) and user-tunable robustness (Lipschitz) conditions on the closed-loop system. This means it can be used for safe learning-based control with no additional constraints or projections required to enforce stability or robustness. We test the new policy class in simulation on two reinforcement learning tasks: 1) magnetic suspension, and 2) inverting a rotary-arm pendulum. We find that the Youla-REN performs similarly to existing learning-based and optimal control methods while also ensuring stability and exhibiting improved robustness to adversarial disturbances.
    
[^67]: 一种具有物体感知等变基元反应扩散模型的精确过渡态生成方法

    Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model. (arXiv:2304.06174v1 [physics.chem-ph])

    [http://arxiv.org/abs/2304.06174](http://arxiv.org/abs/2304.06174)

    本文开发了一种物体感知 SE(3) 等变扩散模型，可以在几秒钟内精确地生成过渡态结构，与基于量子化学的优化相比，计算时间大大缩短，其生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差，可以实现反应速率估计所需的精度。

    

    过渡态搜索在化学中具有重要作用，可用于阐明反应机理和探索反应网络。但搜索精确的三维过渡态结构需要大量的量子化学计算，因为势能面的复杂性。本文开发了一种物体感知 SE(3) 等变扩散模型，满足生成反应物、过渡态和生成物三种结构的所有物理对称性和约束条件。在已知反应物和生成物的情况下，该模型可以在几秒钟内生成过渡态结构，而不需要进行基于量子化学的优化，从而大大缩短了计算时间。生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差。通过对不确定性进行评估，并进行置信度评分，可以实现反应速率估计所需的精度 (2.6 kcal/mol)，并且只需对 14% 的结果进行基于量子化学的优化。

    Transition state (TS) search is key in chemistry for elucidating reaction mechanisms and exploring reaction networks. The search for accurate 3D TS structures, however, requires numerous computationally intensive quantum chemistry calculations due to the complexity of potential energy surfaces. Here, we developed an object-aware SE(3) equivariant diffusion model that satisfies all physical symmetries and constraints for generating pairs of structures, i.e., reactant, TS, and product, in an elementary reaction. Provided reactant and product, this model generates a TS structure in seconds instead of the hours required when performing quantum chemistry-based optimizations. The generated TS structures achieve an average error of 0.13 A root mean square deviation compared to true TS. With a confidence scoring model for uncertainty quantification, we approach an accuracy required for reaction rate estimation (2.6 kcal/mol) by only performing quantum chemistry-based optimizations on 14% of th
    
[^68]: NP-Free：一种实时、非归一化、免参数调节的开放式时间序列表示方法

    NP-Free: A Real-Time Normalization-free and Parameter-tuning-free Representation Approach for Open-ended Time Series. (arXiv:2304.06168v1 [cs.LG])

    [http://arxiv.org/abs/2304.06168](http://arxiv.org/abs/2304.06168)

    提出开放式时间序列表示方法NP-Free, 实时处理速度且无需归一化和参数调节。

    

    随着越来越多的联网设备在物联网中实现，并期望在实时收集和处理数据，处理时间序列数据的能力变得日益重要。许多时间序列表示方法已被提出以帮助在数据挖掘应用程序中分析时间序列，但现有方法不适用于开放式时间序列，因为这些方法需要提前知道目标时间序列的总长度，并使用归一化方法对整个序列进行预处理。此外，许多表示方法需要用户预先配置和调整某些参数以获得满意的表示结果。在本文中，我们提出了一种实时的非归一化、免参数调节的开放式时间序列表示方法NP-Free。我们采用了新颖的技术，适应性地处理未知的数据长度并动态调整每个数据点的权重，而不使用任何归一化或参数调节。 我们的方法在多个时间序列分类任务中实现了最先进的性能，同时保持了实时处理速度。

    As more connected devices are implemented in a cyber-physical world and data is expected to be collected and processed in real time, the ability to handle time series data has become increasingly significant. To help analyze time series in data mining applications, many time series representation approaches have been proposed to convert a raw time series into another series for representing the original time series. However, existing approaches are not designed for open-ended time series (which is a sequence of data points being continuously collected at a fixed interval without any length limit) because these approaches need to know the total length of the target time series in advance and pre-process the entire time series using normalization methods. Furthermore, many representation approaches require users to configure and tune some parameters beforehand in order to achieve satisfactory representation results. In this paper, we propose NP-Free, a real-time Normalization-free and Pa
    
[^69]: 从信号时序逻辑规范中使用BarrierNet学习健壮且正确的控制器

    Learning Robust and Correct Controllers from Signal Temporal Logic Specifications Using BarrierNet. (arXiv:2304.06160v1 [eess.SY])

    [http://arxiv.org/abs/2304.06160](http://arxiv.org/abs/2304.06160)

    本文提出了一个通用的过程，构造出可训练的控制障碍函数，强制实现STL中某一片段的规范满足，同时使用BarrierNet作为神经网络控制器最后一层，保证规范的满足，提高控制器的鲁棒性。

    

    本文考虑了一个系统需要满足信号时序逻辑(STL)规范的神经网络控制器学习问题。我们利用STL的定量语义来定义鲁棒满足的概念。确保神经网络控制器的正确性，即保证被控制的系统满足规范，是一个近期受到广泛关注的难题。我们提供了一个通用的过程来构造一组可训练的高阶控制障碍函数(HOCBFs)，强制执行STL中某一片段的公式的满足。我们使用BarrierNet作为神经网络控制器的最后一层，实现了具有控制障碍函数限制的可微分二次规划(dQP)，以保证STL公式的满足。我们一起训练HOCBF和其他神经网络参数以进一步提高控制器的鲁棒性。仿真结果表明，与现有方法相比，我们的方法保证了STL规范的满足，并对扰动更具鲁棒性。

    In this paper, we consider the problem of learning a neural network controller for a system required to satisfy a Signal Temporal Logic (STL) specification. We exploit STL quantitative semantics to define a notion of robust satisfaction. Guaranteeing the correctness of a neural network controller, i.e., ensuring the satisfaction of the specification by the controlled system, is a difficult problem that received a lot of attention recently. We provide a general procedure to construct a set of trainable High Order Control Barrier Functions (HOCBFs) enforcing the satisfaction of formulas in a fragment of STL. We use the BarrierNet, implemented by a differentiable Quadratic Program (dQP) with HOCBF constraints, as the last layer of the neural network controller, to guarantee the satisfaction of the STL formulas. We train the HOCBFs together with other neural network parameters to further improve the robustness of the controller. Simulation results demonstrate that our approach ensures sati
    
[^70]: R语言的growclusters软件包

    The growclusters Package for R. (arXiv:2304.06145v1 [cs.MS])

    [http://arxiv.org/abs/2304.06145](http://arxiv.org/abs/2304.06145)

    R语言的growclusters软件包实现了增强版的k-means聚类算法，可以发现多组数据集中的局部聚类或分区，函数包含估计多元数据分区结构的功能，使用惩罚优化方法进行。并可创建可视化应用程序展示其操作和功能。

    

    growclusters软件包实现了一个增强版k-means聚类算法，可以发现多组数据集中的局部聚类或分区，每组数据的聚类中心都来源于一个全局分区。该软件包包含一些估计多元数据分区结构的函数。估计是基于贝叶斯非参数表述推导出的一种惩罚优化方法进行的。本文介绍了growclusters软件包的一些功能和能力，包括创建R Shiny应用程序以可视化展示growclusters软件包的操作和功能。

    The growclusters package for R implements an enhanced version of k-means clustering that allows discovery of local clusterings or partitions for a collection of data sets that each draw their cluster means from a single, global partition. The package contains functions to estimate a partition structure for multivariate data. Estimation is performed under a penalized optimization derived from Bayesian non-parametric formulations. This paper describes some of the functions and capabilities of the growclusters package, including the creation of R Shiny applications designed to visually illustrate the operation and functionality of the growclusters package.
    
[^71]: 一种易于编辑的DDPM噪声空间：反演与操作

    An Edit Friendly DDPM Noise Space: Inversion and Manipulations. (arXiv:2304.06140v1 [cs.CV])

    [http://arxiv.org/abs/2304.06140](http://arxiv.org/abs/2304.06140)

    本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。

    

    降噪扩散概率模型（DDPM）利用一系列白噪声样本生成图像。类似于GAN，这些噪声图可以看作是生成图像相关的潜在代码。然而，这种原始噪声空间没有方便的结构，因此在编辑任务中很难使用。本文提出了一种替代DDPM的潜在噪声空间，可通过简单手段进行广泛的编辑操作，并提出一种用于提取任何给定图像（真实或合成生成）的易于编辑噪声图的反演方法。

    Denoising diffusion probabilistic models (DDPMs) employ a sequence of white Gaussian noise samples to generate an image. In analogy with GANs, those noise maps could be considered as the latent code associated with the generated image. However, this native noise space does not possess a convenient structure, and is thus challenging to work with in editing tasks. Here, we propose an alternative latent noise space for DDPM that enables a wide range of editing operations via simple means, and present an inversion method for extracting these edit-friendly noise maps for any given image (real or synthetically generated). As opposed to the native DDPM noise space, the edit-friendly noise maps do not have a standard normal distribution and are not statistically independent across timesteps. However, they allow perfect reconstruction of any desired image, and simple transformations on them translate into meaningful manipulations of the output image (e.g., shifting, color edits). Moreover, in t
    
[^72]: 面向医学图像视觉转换器解释的评估

    Towards Evaluating Explanations of Vision Transformers for Medical Imaging. (arXiv:2304.06133v1 [cs.CV])

    [http://arxiv.org/abs/2304.06133](http://arxiv.org/abs/2304.06133)

    本文研究了多种方法在应用于医学图像分类的Vision Transformer上的性能，并说明逐层相关性传播比局部可解释的模型无关解释和关注可视化提供更准确和可靠的ViT所学习的表示。

    

    随着深度学习模型在医学图像等关键领域的应用越来越普遍，透明和可信的决策变得至关重要。许多解释方法通过将重要性归因于输入特征来为这些模型的预测提供深入的洞察。随着视觉转换器（ViT）成为卷积神经网络的一种有希望的替代方案，其可解释性仍然是一个未解决的研究问题。本文研究了多种解释方法在应用于对胸部X射线图像进行分类的ViT上的性能。我们引入了评估ViT解释的忠实度、敏感度和复杂度的概念。所得结果表明，基于转换器的逐层相关性传播优于局部可解释的模型无关解释和关注可视化，提供了更准确和可靠的ViT所学习的表示。我们的发现提供了洞见。

    As deep learning models increasingly find applications in critical domains such as medical imaging, the need for transparent and trustworthy decision-making becomes paramount. Many explainability methods provide insights into how these models make predictions by attributing importance to input features. As Vision Transformer (ViT) becomes a promising alternative to convolutional neural networks for image classification, its interpretability remains an open research question. This paper investigates the performance of various interpretation methods on a ViT applied to classify chest X-ray images. We introduce the notion of evaluating faithfulness, sensitivity, and complexity of ViT explanations. The obtained results indicate that Layerwise relevance propagation for transformers outperforms Local interpretable model-agnostic explanations and Attention visualization, providing a more accurate and reliable representation of what a ViT has actually learned. Our findings provide insights int
    
[^73]: UniverSeg: 通用医学图像分割

    UniverSeg: Universal Medical Image Segmentation. (arXiv:2304.06131v1 [cs.CV])

    [http://arxiv.org/abs/2304.06131](http://arxiv.org/abs/2304.06131)

    UniverSeg是一种用于解决未见医学图像分割任务的通用方法，无需额外的训练。该方法采用交叉块机制来生成准确的分割地图，并使用收集的53个开放医学数据集进行推广。

    

    虽然深度学习模型已成为医学图像分割的主要方法，但它们通常无法推广到涉及新解剖学、图像模式或标签的未见分割任务。针对新的分割任务，研究人员通常必须训练或微调模型，这是耗时的，并且对于临床研究人员来说构成了实质性的障碍，他们往往缺乏训练神经网络所需的资源和经验。我们提出了一种称为UniverSeg的方法，用于解决未见的医学分割任务，无需额外的训练。给定一个查询图像和一组定义新分割任务的图像-标签对示例集，UniverSeg使用新的交叉块机制生成准确的分割地图，无需额外的训练。为了实现对新任务的推广，我们收集并标准化了53个开放医学分割数据集，包含超过22,000个扫描图像，我们称之为MegaMedical。

    While deep learning models have become the predominant method for medical image segmentation, they are typically not capable of generalizing to unseen segmentation tasks involving new anatomies, image modalities, or labels. Given a new segmentation task, researchers generally have to train or fine-tune models, which is time-consuming and poses a substantial barrier for clinical researchers, who often lack the resources and expertise to train neural networks. We present UniverSeg, a method for solving unseen medical segmentation tasks without additional training. Given a query image and example set of image-label pairs that define a new segmentation task, UniverSeg employs a new Cross-Block mechanism to produce accurate segmentation maps without the need for additional training. To achieve generalization to new tasks, we have gathered and standardized a collection of 53 open-access medical segmentation datasets with over 22,000 scans, which we refer to as MegaMedical. We used this colle
    
[^74]: 无标签概念瓶颈模型

    Label-Free Concept Bottleneck Models. (arXiv:2304.06129v1 [cs.LG])

    [http://arxiv.org/abs/2304.06129](http://arxiv.org/abs/2304.06129)

    无标签CBM是一个可解释的框架，能够将任何神经网络转化为CBM，并且不需要标记数据，同时保持高准确性。

    

    概念瓶颈模型(CBM)是一种创建更易解释的神经网络的流行方法，其采用隐藏层神经元对应于人类可理解的概念。然而，现有的CBM及其变体存在两个关键限制：首先，它们需要为每个预定义的概念收集标记数据，这是耗时且劳动密集的；其次，在更复杂的数据集上，CBM的准确性通常明显低于标准神经网络的准确性，这样的表现为其在实际世界应用中造成一定的障碍。鉴于这些挑战，我们提出了无标签CBM，它是一种将任何神经网络转换为可解释CBM的新框架，无需标记概念数据，同时保持高准确性。我们的无标签CBM有许多优点，它是可扩展的——我们提出了第一个可扩展到ImageNet的CBM，高效的——即使对于非常大的数据集，创建CBM仅需要几个小时，而且可以自动化进行，不需要人类干预。

    Concept bottleneck models (CBM) are a popular way of creating more interpretable neural networks by having hidden layer neurons correspond to human-understandable concepts. However, existing CBMs and their variants have two crucial limitations: first, they need to collect labeled data for each of the predefined concepts, which is time consuming and labor intensive; second, the accuracy of a CBM is often significantly lower than that of a standard neural network, especially on more complex datasets. This poor performance creates a barrier for adopting CBMs in practical real world applications. Motivated by these challenges, we propose Label-free CBM which is a novel framework to transform any neural network into an interpretable CBM without labeled concept data, while retaining a high accuracy. Our Label-free CBM has many advantages, it is: scalable - we present the first CBM scaled to ImageNet, efficient - creating a CBM takes only a few hours even for very large datasets, and automate
    
[^75]: AutoShot：一份短视频数据集和最新的镜头边界检测技术

    AutoShot: A Short Video Dataset and State-of-the-Art Shot Boundary Detection. (arXiv:2304.06116v1 [cs.CV])

    [http://arxiv.org/abs/2304.06116](http://arxiv.org/abs/2304.06116)

    AutoShot 发布了一份新的短视频镜头边界检测数据集，采用名为 AutoShot 的方法进行模型设计优化，比之前的最新技术水平在 F1 分数上获得更高的准确性。

    

    短视频在新的社交媒体趋势中爆发性地流行起来。镜头边界检测（SBD）是各种场景中最基本的组成部分之一，对于视频内容的创建和理解至关重要。 在本研究中，我们发布了一个名为SHOT的新的公共短视频镜头边界检测数据集，包括853个完整的短视频和11,606个镜头注释，其中包括200个测试视频中的2,716个高质量的镜头边界注释。利用这个新的数据财富，我们提出了一种名为AutoShot的方法，通过在包含各种先进的3D ConvNets和Transformers的搜索空间中进行神经架构搜索，来优化镜头边界检测模型的设计。我们的方法在F1分数上比先前的最先进方法实现了更高的准确性，例如在超过TransNetV2 4.2％的情况下获得更好的性能。

    The short-form videos have explosive popularity and have dominated the new social media trends. Prevailing short-video platforms,~\textit{e.g.}, Kuaishou (Kwai), TikTok, Instagram Reels, and YouTube Shorts, have changed the way we consume and create content. For video content creation and understanding, the shot boundary detection (SBD) is one of the most essential components in various scenarios. In this work, we release a new public Short video sHot bOundary deTection dataset, named SHOT, consisting of 853 complete short videos and 11,606 shot annotations, with 2,716 high quality shot boundary annotations in 200 test videos. Leveraging this new data wealth, we propose to optimize the model design for video SBD, by conducting neural architecture search in a search space encapsulating various advanced 3D ConvNets and Transformers. Our proposed approach, named AutoShot, achieves higher F1 scores than previous state-of-the-art approaches, e.g., outperforming TransNetV2 by 4.2%, when bein
    
[^76]: PATMAT: 面向个体化的面部修复的遮罩感知Transformer

    PATMAT: Person Aware Tuning of Mask-Aware Transformer for Face Inpainting. (arXiv:2304.06107v1 [cs.CV])

    [http://arxiv.org/abs/2304.06107](http://arxiv.org/abs/2304.06107)

    PATMAT使用参考图像和微调技术有效地保留了面部修补中的细节和人物身份。

    

    风格生成模型如StyleGAN2和Stable Diffusion已经在计算机视觉任务中取得了最先进的性能，例如图像合成、修复和去噪。但是，当前用于面部修补的生成模型通常无法保留细节和个人的身份，尽管它们能创建出审美上可信的图像结构和纹理。在这项工作中，我们提出了一种Person Aware Tuning (PAT)的Mask-Aware Transformer (MAT)方法，用于解决这个问题。我们的方法PATMAT通过使用一个人的参考图像和微调在面孔上训练过的MAT模型，有效地保留了其身份。PATMAT使用约40个参考图像在MAT的样式模块中创建锚点，并使用锚点来适应新的面部身份。此外，PATMAT利用训练期间每个锚点的多个图像使模型使用比竞争方法更少的参考图像。我们展示了PATMAT在基准数据集上胜过现有的面部修补模型，同时保留了细节和身份。

    Generative models such as StyleGAN2 and Stable Diffusion have achieved state-of-the-art performance in computer vision tasks such as image synthesis, inpainting, and de-noising. However, current generative models for face inpainting often fail to preserve fine facial details and the identity of the person, despite creating aesthetically convincing image structures and textures. In this work, we propose Person Aware Tuning (PAT) of Mask-Aware Transformer (MAT) for face inpainting, which addresses this issue. Our proposed method, PATMAT, effectively preserves identity by incorporating reference images of a subject and fine-tuning a MAT architecture trained on faces. By using ~40 reference images, PATMAT creates anchor points in MAT's style module, and tunes the model using the fixed anchors to adapt the model to a new face identity. Moreover, PATMAT's use of multiple images per anchor during training allows the model to use fewer reference images than competing methods. We demonstrate th
    
[^77]: 基于原始-对偶语境贝叶斯优化的带时间平均约束的控制系统在线优化

    Primal-Dual Contextual Bayesian Optimization for Control System Online Optimization with Time-Average Constraints. (arXiv:2304.06104v1 [cs.LG])

    [http://arxiv.org/abs/2304.06104](http://arxiv.org/abs/2304.06104)

    提出了一种基于原始-对偶语境贝叶斯优化算法，可以实现对约束闭环控制系统的在线性能优化，同时满足所需的约束条件。

    

    本文研究带有外生时间变化上下文干扰的未知黑盒函数的约束闭环控制系统在线性能优化问题。提出了一种原始-对偶语境贝叶斯优化算法，在满足一定正则条件下，实现了对动态最优解的亚线性累积遗憾。此外，该算法可以实现零时间平均约束违规，确保了约束函数的平均值满足所需的约束条件。该方法应用于高斯过程的采样实例和连续搅拌槽反应器参数调节问题。仿真结果表明，该方法同时提供接近最优的性能和平均保持约束可行性，这与当前的最先进方法形成对比，后者要么遭受大量累积遗憾，要么存在严重约束违规问题。

    This paper studies the problem of online performance optimization of constrained closed-loop control systems, where both the objective and the constraints are unknown black-box functions affected by exogenous time-varying contextual disturbances. A primal-dual contextual Bayesian optimization algorithm is proposed that achieves sublinear cumulative regret with respect to the dynamic optimal solution under certain regularity conditions. Furthermore, the algorithm achieves zero time-average constraint violation, ensuring that the average value of the constraint function satisfies the desired constraint. The method is applied to both sampled instances from Gaussian processes and a continuous stirred tank reactor parameter tuning problem; simulation results show that the method simultaneously provides close-to-optimal performance and maintains constraint feasibility on average. This contrasts current state-of-the-art methods, which either suffer from large cumulative regret or severe const
    
[^78]: 基于降维和监督式机器学习的宇宙密度场快速仿真

    Fast emulation of cosmological density fields based on dimensionality reduction and supervised machine-learning. (arXiv:2304.06099v1 [astro-ph.CO])

    [http://arxiv.org/abs/2304.06099](http://arxiv.org/abs/2304.06099)

    本研究使用简单的机器学习方法，通过降维和监督式回归，对暗物质密度场进行快速而准确的仿真，从而有效地应对复杂参数空间的挑战。

    

    N-body模拟是研究大尺度结构非线性演化的最有力方法。然而，它们需要大量计算资源，在需要广泛探索参数空间的情况下直接采用是不可行的。本研究表明，可以使用简单的机器学习方法进行快速的暗物质密度场仿真，并具有竞争性的精度。我们基于降维和机器学习回归构建了一个模拟器，结合简单的主成分分析和监督式学习方法。针对单个自由参数的估计，我们训练了暗物质密度参数$\Omega_m$，而对于具有两个自由参数的仿真，我们训练了一系列$\Omega_m$和红移。该方法首先采用给定基底的模拟网格的投影；然后，在该投影网格上进行机器学习回归的训练。最后，针对不同参数的新密度立方体进行预测。

    N-body simulations are the most powerful method to study the non-linear evolution of large-scale structure. However, they require large amounts of computational resources, making unfeasible their direct adoption in scenarios that require broad explorations of parameter spaces. In this work, we show that it is possible to perform fast dark matter density field emulations with competitive accuracy using simple machine-learning approaches. We build an emulator based on dimensionality reduction and machine learning regression combining simple Principal Component Analysis and supervised learning methods. For the estimations with a single free parameter, we train on the dark matter density parameter, $\Omega_m$, while for emulations with two free parameters, we train on a range of $\Omega_m$ and redshift. The method first adopts a projection of a grid of simulations on a given basis; then, a machine learning regression is trained on this projected grid. Finally, new density cubes for differe
    
[^79]: 能量引导的熵神经最优输运

    Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])

    [http://arxiv.org/abs/2304.06094](http://arxiv.org/abs/2304.06094)

    本论文提出了一种新的方法，将能量基础模型和熵正则化最优输运结合起来，以解决生成建模问题。我们在2D情景和图像到图像翻译问题中验证了该方法的适用性。

    

    能量基础模型（EBMs）在机器学习社区已经有数十年的历史。自两千年代起，一直有很多高效的方法通过能量势（非归一化的似然函数）来解决生成建模问题。相比之下，最优输运（OT）领域，尤其是神经OT求解器，受到的探索要少得多，仅有一些近期的研究（不包括利用OT作为损失函数来解决问题的WGAN方法）。在本研究中，我们弥合了EBMs和熵正则化OT之间的差距，提出了一种新的方法，允许利用前者的最新发展和技术改进来丰富后者。我们在2D情景和标准的图像到图像翻译问题中验证了我们方法的适用性。为简单起见，我们选择了简短和长跑的EBMs。

    Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
    
[^80]: 低分辨率红外阵列上保护隐私的人流量计算的高效深度学习模型

    Efficient Deep Learning Models for Privacy-preserving People Counting on Low-resolution Infrared Arrays. (arXiv:2304.06059v1 [cs.CV])

    [http://arxiv.org/abs/2304.06059](http://arxiv.org/abs/2304.06059)

    本文比较了六种不同的高效深度学习模型对低分辨率红外阵列的人流量计算的性能，通过全面的探索获得了富有成效的 Pareto 最优解，实现了高准确性和低成本同时满足的目标。

    

    超低分辨率红外(IR)阵列传感器为人流量计算提供了一种低成本、能效高且保护隐私的解决方案，可用于占用监测等应用。以前的工作表明，深度学习(DL)在这个任务上可以获得卓越的性能。然而，文献缺乏一个对基于IR阵列的人流量计算的各种高效DL架构进行广泛比较分析的研究，这些架构不仅考虑了其准确性，还考虑了将其部署在记忆和能量受限的物联网(IoT)边缘节点上的成本。本研究通过比较6种不同的DL架构，在一个新颖的由商业8x8阵列收集的IR图像数据集上，进行了全面的探索。我们公开了这个数据集。在每种模型类型的广泛架构探索下，我们获得了一组富有成效的Pareto最优解，其交叉验证平衡准确性得分范围为55.70%-82.70%。当在S商业微控制器(MCU)上部署时，所有DL模型在测试集上均可实现实时性，并在省电模式下消耗极少的能量。

    Ultra-low-resolution Infrared (IR) array sensors offer a low-cost, energy-efficient, and privacy-preserving solution for people counting, with applications such as occupancy monitoring. Previous work has shown that Deep Learning (DL) can yield superior performance on this task. However, the literature was missing an extensive comparative analysis of various efficient DL architectures for IR array-based people counting, that considers not only their accuracy, but also the cost of deploying them on memory- and energy-constrained Internet of Things (IoT) edge nodes. In this work, we address this need by comparing 6 different DL architectures on a novel dataset composed of IR images collected from a commercial 8x8 array, which we made openly available. With a wide architectural exploration of each model type, we obtain a rich set of Pareto-optimal solutions, spanning cross-validated balanced accuracy scores in the 55.70-82.70% range. When deployed on a commercial Microcontroller (MCU) by S
    
[^81]: 最大公平性(Maximal Fairness)

    Maximal Fairness. (arXiv:2304.06057v1 [cs.CY])

    [http://arxiv.org/abs/2304.06057](http://arxiv.org/abs/2304.06057)

    本文通过识别可以同时满足的常用公平性措施的最大集，填补了“不可能定理”的空白，从而得出了12个最大集是可能的这一结论。

    

    人工智能中的公平性已经引起了研究和社会的广泛关注。所谓的“不可能定理”是一个更为显著的研究结果，它具有理论和实践后果，因为它认为满足一定组合的公平性措施是不可能的。迄今为止，这个负面结果还没有得到积极的补充:即对哪些公平性观念的组合是可能的进行描述。本文旨在填补这一空白，通过识别可以同时满足的常用公平性措施的最大集来实现这一目标。使用的公平性措施是人口比例平等、平等机会、误判率平等、预测准确性平等、总体准确性平等和治疗平等。我们得出结论，总共有12个这些公平性措施的最大集是可能的，其中有七种两个措施的组合和五种三个措施的组合。我们的工作引起了一些有趣的问题。

    Fairness in AI has garnered quite some attention in research, and increasingly also in society. The so-called "Impossibility Theorem" has been one of the more striking research results with both theoretical and practical consequences, as it states that satisfying a certain combination of fairness measures is impossible. To date, this negative result has not yet been complemented with a positive one: a characterization of which combinations of fairness notions are possible. This work aims to fill this gap by identifying maximal sets of commonly used fairness measures that can be simultaneously satisfied. The fairness measures used are demographic parity, equal opportunity, false positive parity, predictive parity, predictive equality, overall accuracy equality and treatment equality. We conclude that in total 12 maximal sets of these fairness measures are possible, among which seven combinations of two measures, and five combinations of three measures. Our work raises interest questions
    
[^82]: 基于自筛选深度学习模型的滑坡易发性预测建模

    Landslide Susceptibility Prediction Modeling Based on Self-Screening Deep Learning Model. (arXiv:2304.06054v1 [cs.LG])

    [http://arxiv.org/abs/2304.06054](http://arxiv.org/abs/2304.06054)

    本文提出了一种基于自筛选深度学习模型的滑坡易发性预测建模方法，通过自筛选网络和图卷积网络提取环境因素之间的非线性关系，具有更好的性能。

    

    滑坡易发性预测一直是一个重要而具有挑战性的内容。然而，易发性建模存在一些不确定性问题，如滑坡样本误差和环境因素之间的复杂非线性关系。本文提出了一种自筛选图卷积网络和长短期记忆网络（SGCN-LSTM）模型，以克服滑坡易发性预测中的上述问题。SGCN-LSTM模型具有广泛性和良好的学习能力。自筛选网络可以消除一定阈值区间外具有大误差的滑坡样本，并且可以从空间节点和时间序列中提取环境因素之间的非线性关系，从而更好地模拟环境因素之间的非线性关系。SGCN-LSTM模型应用于江西省安远县的滑坡易发性预测，并与多元逻辑回归、随机森林、极端学习机和支持向量机等四种常用模型进行比较。结果表明，SGCN-LSTM模型在滑坡易发性预测方面具有最高的准确度和曲线下面积（AUC）值，表明其在滑坡易发性预测方面具有更好的性能。

    Landslide susceptibility prediction has always been an important and challenging content. However, there are some uncertain problems to be solved in susceptibility modeling, such as the error of landslide samples and the complex nonlinear relationship between environmental factors. A self-screening graph convolutional network and long short-term memory network (SGCN-LSTM) is proposed int this paper to overcome the above problems in landslide susceptibility prediction. The SGCN-LSTM model has the advantages of wide width and good learning ability. The landslide samples with large errors outside the set threshold interval are eliminated by self-screening network, and the nonlinear relationship between environmental factors can be extracted from both spatial nodes and time series, so as to better simulate the nonlinear relationship between environmental factors. The SGCN-LSTM model was applied to landslide susceptibility prediction in Anyuan County, Jiangxi Province, China, and compared w
    
[^83]: 基于符合性预测和符合性风险控制的有信心物体检测：铁路信号应用研究

    Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling. (arXiv:2304.06052v1 [cs.LG])

    [http://arxiv.org/abs/2304.06052](http://arxiv.org/abs/2304.06052)

    本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。

    

    在实际认证系统中使用深度学习模型需要提供能够准确反映不确定性的置信度估计。本文演示了利用符合性预测框架构建可靠的、值得信赖的检测铁路信号的预测器的方法。我们使用包含火车操作员视角下的图像和最先进的物体检测器的新数据集。我们测试了几种符合性方法，并引入了一种基于符合性风险控制的新方法。研究结果表明符合性预测框架评估模型性能和提供正式保证的不确定性边界具有潜力，为实现这一目标提供了实用指导。

    Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.
    
[^84]: 开放式智能交通基础模型挑战赛的新基准与基准数据集 - Open-TransMind

    Open-TransMind: A New Baseline and Benchmark for 1st Foundation Model Challenge of Intelligent Transportation. (arXiv:2304.06051v1 [cs.CV])

    [http://arxiv.org/abs/2304.06051](http://arxiv.org/abs/2304.06051)

    Open-TransMind是智能交通领域第一个基础模型挑战赛的新基准，旨在解决数据量少、泛化能力差以及缺乏多模态技术等典型挑战。

    

    随着近年来计算能力和深度学习算法的不断提升，基础模型越来越受欢迎。由于其强大的能力和出色的性能，这种技术被越来越多的行业采用和应用。在智能交通行业中，人工智能面临着以下典型挑战：数据量少、泛化能力差以及缺乏多模态技术。基础模型技术可以显著缓解上述问题。为解决这些问题，我们设计了第一个基础模型挑战，旨在增加基础模型技术在交通场景中的普及度，并促进智能交通行业的快速发展。该挑战分为两个赛道：全能型和跨模态图像检索。此外，我们为这两个赛道提供了一个新的基线和基准数据，称为Open-TransMind。据我们所知，这是智能交通领域的第一个基础模型基准。

    With the continuous improvement of computing power and deep learning algorithms in recent years, the foundation model has grown in popularity. Because of its powerful capabilities and excellent performance, this technology is being adopted and applied by an increasing number of industries. In the intelligent transportation industry, artificial intelligence faces the following typical challenges: few shots, poor generalization, and a lack of multi-modal techniques. Foundation model technology can significantly alleviate the aforementioned issues. To address these, we designed the 1st Foundation Model Challenge, with the goal of increasing the popularity of foundation model technology in traffic scenarios and promoting the rapid development of the intelligent transportation industry. The challenge is divided into two tracks: all-in-one and cross-modal image retrieval. Furthermore, we provide a new baseline and benchmark for the two tracks, called Open-TransMind. According to our knowledg
    
[^85]: 神经网络控制器到决策树控制器的精确且节约成本的自动转换

    Exact and Cost-Effective Automated Transformation of Neural Network Controllers to Decision Tree Controllers. (arXiv:2304.06049v1 [cs.LG])

    [http://arxiv.org/abs/2304.06049](http://arxiv.org/abs/2304.06049)

    本文研究了将基于神经网络的控制器转换为等效软决策树控制器并提出了一种自动且节约成本的转换算法。该方法适用于包括ReLU激活函数在内的离散输出NN控制器，并能够提高形式验证的运行效率。

    

    在过去的十年中，基于神经网络（NN）的控制器在各种决策任务中表现出了显着的功效。然而，它们的黑盒特性和意外行为和令人惊讶的结果的风险对于在具有正确性和安全性强保证的真实世界系统中的部署构成了挑战。我们通过调查将基于NN的控制器转换为等效的软决策树（SDT）控制器及其对可验证性的影响来解决这些限制。与以前的方法不同，我们专注于离散输出NN控制器，包括整流线性单元（ReLU）激活函数以及argmax操作。然后，我们设计了一种精确但节省成本的转换算法，因为它可以自动删除多余的分支。我们使用OpenAI Gym环境的两个基准测试来评估我们的方法。我们的结果表明，SDT转换可以使形式验证受益，显示运行时改进。

    Over the past decade, neural network (NN)-based controllers have demonstrated remarkable efficacy in a variety of decision-making tasks. However, their black-box nature and the risk of unexpected behaviors and surprising results pose a challenge to their deployment in real-world systems with strong guarantees of correctness and safety. We address these limitations by investigating the transformation of NN-based controllers into equivalent soft decision tree (SDT)-based controllers and its impact on verifiability. Differently from previous approaches, we focus on discrete-output NN controllers including rectified linear unit (ReLU) activation functions as well as argmax operations. We then devise an exact but cost-effective transformation algorithm, in that it can automatically prune redundant branches. We evaluate our approach using two benchmarks from the OpenAI Gym environment. Our results indicate that the SDT transformation can benefit formal verification, showing runtime improveme
    
[^86]: RELS-DQN：组合优化的强大和高效的局部搜索框架

    RELS-DQN: A Robust and Efficient Local Search Framework for Combinatorial Optimization. (arXiv:2304.06048v1 [cs.LG])

    [http://arxiv.org/abs/2304.06048](http://arxiv.org/abs/2304.06048)

    该论文提出了一个名为RELS-DQN的轻量级DQN框架，可以展现局部搜索行为并提供实用的可扩展性，其在多个应用程序上具有类似局部搜索算法的效果，并且解决方案值要高于或等于局部搜索算法和专家设计的启发式方法。

    

    组合优化旨在高效地找到最佳解决方案，涉及从统计物理到社交媒体营销的NP难问题。许多组合优化应用可以从局部搜索方法中受益，因为它们允许在贪婪策略上进行可逆操作。使用消息传递神经网络（MPNN）的深度Q学习（DQN）已经显示出在复制局部搜索行为和获得与局部搜索算法相当的结果方面很有前途。然而，在消息传递迭代过程中，过于平滑和信息丢失限制了其在应用程序中的鲁棒性，并且大的消息向量导致内存效率低下。我们的论文介绍了RELS-DQN，这是一个轻量级的DQN框架，展示了局部搜索行为同时提供实用的可扩展性。使用在一个应用程序上训练的RELS-DQN模型，它可以通过提供高于或等于局部搜索算法和专家设计的启发式方法的解决方案值来推广到各种应用程序。

    Combinatorial optimization (CO) aims to efficiently find the best solution to NP-hard problems ranging from statistical physics to social media marketing. A wide range of CO applications can benefit from local search methods because they allow reversible action over greedy policies. Deep Q-learning (DQN) using message-passing neural networks (MPNN) has shown promise in replicating the local search behavior and obtaining comparable results to the local search algorithms. However, the over-smoothing and the information loss during the iterations of message passing limit its robustness across applications, and the large message vectors result in memory inefficiency. Our paper introduces RELS-DQN, a lightweight DQN framework that exhibits the local search behavior while providing practical scalability. Using the RELS-DQN model trained on one application, it can generalize to various applications by providing solution values higher than or equal to both the local search algorithms and the e
    
[^87]: 使用物理训练的神经网络学习非线性本构材料模型：COMM-PINN。

    Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN. (arXiv:2304.06044v1 [cs.CE])

    [http://arxiv.org/abs/2304.06044](http://arxiv.org/abs/2304.06044)

    通过物理训练的神经网络可解决非线性材料行为的本构关系，无需初始数据，避免重复的牛顿迭代。训练好的模型可作为有限元程序的用户定义材料模型，但需要解决诸多挑战。

    

    我们使用物理训练的神经网络来解决非线性、路径相关材料行为的本构关系。训练好的网络不仅满足所有热力学约束，而且在任何给定的加载情况下，立即提供关于当前材料状态（即自由能，应力和内部变量的演变）的信息，而不需要初始数据。这项工作的一个优点是它规避了求解复材料模型中非线性方程所需的重复牛顿迭代。此外，我们提供了减少获取切向算子所需的导数次序的策略。训练好的模型可以直接用作任何有限元程序（或其他数值方法）中的用户定义材料模型。然而，在定义配点和整合同时激活或非激活的多个非相等约束方面仍存在挑战。

    We applied physics-informed neural networks to solve the constitutive relations for nonlinear, path-dependent material behavior. As a result, the trained network not only satisfies all thermodynamic constraints but also instantly provides information about the current material state (i.e., free energy, stress, and the evolution of internal variables) under any given loading scenario without requiring initial data. One advantage of this work is that it bypasses the repetitive Newton iterations needed to solve nonlinear equations in complex material models. Additionally, strategies are provided to reduce the required order of derivation for obtaining the tangent operator. The trained model can be directly used in any finite element package (or other numerical methods) as a user-defined material model. However, challenges remain in the proper definition of collocation points and in integrating several non-equality constraints that become active or non-active simultaneously. We tested this
    
[^88]: 智能驾驶辅助的深度学习系统

    Deep Learning Systems for Advanced Driving Assistance. (arXiv:2304.06041v1 [eess.SP])

    [http://arxiv.org/abs/2304.06041](http://arxiv.org/abs/2304.06041)

    本论文提出了一种智能驾驶辅助的深度学习系统，利用生物传感系统来重构汽车驾驶员的生理注意力状态，该探针通过深度学习系统分析和处理获得的PPG信号，以识别与驾驶员注意力水平相一致的特定模式。

    

    下一代汽车通过创新解决方案智能评估车辆驾驶安全。这项安全驾驶监测可以使用许多在科学文献中广泛讨论的方法来实现。在这种情况下，作者提出了一种创新方法，使用特定的生物传感系统来重构汽车驾驶员的生理注意力状态。为了重构汽车驾驶员的生理状态，作者提出了使用生物传感探针的方法，该探针由近红外(NiR)光谱下的耦合LED和光电检测器组成。该探针放置在被监测的对象上，可以检测到一种称为光电容积描记(PPG)的生理信号。PPG信号的形成由被监测对象血液中氧合和非氧合血红蛋白浓度的变化调节，这将直接与由自主神经系统(ANS)调节的心脏活动相连接。通过深度学习系统处理和分析获得的PPG信号，可以识别出与驾驶员注意力水平一致的特定模式。

    Next generation cars embed intelligent assessment of car driving safety through innovative solutions often based on usage of artificial intelligence. The safety driving monitoring can be carried out using several methodologies widely treated in scientific literature. In this context, the author proposes an innovative approach that uses ad-hoc bio-sensing system suitable to reconstruct the physio-based attentional status of the car driver. To reconstruct the car driver physiological status, the author proposed the use of a bio-sensing probe consisting of a coupled LEDs at Near infrared (NiR) spectrum with a photodetector. This probe placed over the monitored subject allows to detect a physiological signal called PhotoPlethysmoGraphy (PPG). The PPG signal formation is regulated by the change in oxygenated and non-oxygenated hemoglobin concentration in the monitored subject bloodstream which will be directly connected to cardiac activity in turn regulated by the Autonomic Nervous System (
    
[^89]: 面向个性化癫痫发作检测的知识蒸馏图神经网络

    Knowledge-Distilled Graph Neural Networks for Personalized Epileptic Seizure Detection. (arXiv:2304.06038v1 [eess.SP])

    [http://arxiv.org/abs/2304.06038](http://arxiv.org/abs/2304.06038)

    采用知识蒸馏方法，从通过全套电极数据训练的检测器中传输知识，构建了新的检测器，能够为个体患者定制少量通道，并提供了轻量级、高准确率的实现，相对于现有的基于全套电极的方案大为改善。

    

    可穿戴设备对于癫痫患者的监测检测可以极大地改善生活质量。然而，现有的解决方案大多依赖于全脑电图（EEG）测量的完整电极组，可能对于日常使用不太方便。在本文中，我们提出了一种新颖的知识蒸馏方法，从经过全套电极数据训练的先进癫痫检测器（称为教师）中传输知识，以学习新的检测器（称为学生）。它们都提供轻量级的实现，显著减少了记录脑电图所需的电极数量。我们考虑了教师和学生癫痫检测器都是图神经网络（GNN）的情况，因为这些架构积极使用连接信息。我们考虑了两种情况：（a）使用预选通道为所有患者学习单个学生；（b）为每个个体患者使用少量通道学习个性化学生。该方法在公共数据集上进行了评估，相对于现有的个性化癫痫检测方法使用极少量电极取得了更好的效果。

    Wearable devices for seizure monitoring detection could significantly improve the quality of life of epileptic patients. However, existing solutions that mostly rely on full electrode set of electroencephalogram (EEG) measurements could be inconvenient for every day use. In this paper, we propose a novel knowledge distillation approach to transfer the knowledge from a sophisticated seizure detector (called the teacher) trained on data from the full set of electrodes to learn new detectors (called the student). They are both providing lightweight implementations and significantly reducing the number of electrodes needed for recording the EEG. We consider the case where the teacher and the student seizure detectors are graph neural networks (GNN), since these architectures actively use the connectivity information. We consider two cases (a) when a single student is learnt for all the patients using preselected channels; and (b) when personalized students are learnt for every individual p
    
[^90]: 使用深度 Q 学习进行量化交易。

    Quantitative Trading using Deep Q Learning. (arXiv:2304.06037v1 [q-fin.TR])

    [http://arxiv.org/abs/2304.06037](http://arxiv.org/abs/2304.06037)

    本文探讨了强化学习在量化交易中的运用，揭示了基于 RL 的交易算法的案例研究结果表明，它有潜力优于传统的交易算法。这一研究代表了一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。

    

    强化学习是机器学习的一个分支，已被用于机器人技术、游戏玩法和自主系统等多种应用。近年来，人们越来越关注强化学习在量化交易领域的应用，旨在在金融市场上进行盈利交易。本论文探讨了 RL 在量化交易中的使用，并提供了一个基于 RL 的交易算法的案例研究。结果显示，RL 可以成为量化交易的强有力工具，并且它有潜力优于传统的交易算法。在量化交易中使用强化学习代表着一个有希望的研究领域，可以潜在地引导更为复杂和有效的交易系统的开发。未来的工作可以探索使用替代的强化学习算法，整合其他数据来源，并在不同的资产类别上测试该系统。总体而言，我们的研究证明了它的潜力。

    Reinforcement learning (RL) is a branch of machine learning that has been used in a variety of applications such as robotics, game playing, and autonomous systems. In recent years, there has been growing interest in applying RL to quantitative trading, where the goal is to make profitable trades in financial markets. This paper explores the use of RL in quantitative trading and presents a case study of a RL-based trading algorithm. The results show that RL can be a powerful tool for quantitative trading, and that it has the potential to outperform traditional trading algorithms. The use of reinforcement learning in quantitative trading represents a promising area of research that can potentially lead to the development of more sophisticated and effective trading systems. Future work could explore the use of alternative reinforcement learning algorithms, incorporate additional data sources, and test the system on different asset classes. Overall, our research demonstrates the potential 
    
[^91]: 评估数据特征对睡眠分期模型传递性的影响

    Quantifying the Impact of Data Characteristics on the Transferability of Sleep Stage Scoring Models. (arXiv:2304.06033v1 [eess.SP])

    [http://arxiv.org/abs/2304.06033](http://arxiv.org/abs/2304.06033)

    本文通过评估不同数据特征对模型传递性的影响，提出了一种新的方法来帮助选择转移学习源数据集并优化深度学习模型的性能。

    

    基于单通道脑电图的深度学习模型已被提出作为远程睡眠监测的一种有前途的方法。然而，将这些模型应用于新数据集，特别是来自可穿戴设备的数据集，会引发两个问题。首先，在目标数据集上无法获得注释时，哪些不同的数据特征最影响睡眠分期的得分表现，影响有多大？其次，在有注释的情况下，应该使用哪个数据集作为转移学习的来源，以优化性能？本文提出了一种新的方法，通过在源和目标数据集之间训练和评估两个有显着架构差异的模型TinySleepNet和U-Time，来计算不同数据特征对深度学习模型传递性的影响。

    Deep learning models for scoring sleep stages based on single-channel EEG have been proposed as a promising method for remote sleep monitoring. However, applying these models to new datasets, particularly from wearable devices, raises two questions. First, when annotations on a target dataset are unavailable, which different data characteristics affect the sleep stage scoring performance the most and by how much? Second, when annotations are available, which dataset should be used as the source of transfer learning to optimize performance? In this paper, we propose a novel method for computationally quantifying the impact of different data characteristics on the transferability of deep learning models. Quantification is accomplished by training and evaluating two models with significant architectural differences, TinySleepNet and U-Time, under various transfer configurations in which the source and target datasets have different recording channels, recording environments, and subject c
    
[^92]: 公正：从伦理原则到机器学习开发中与利益相关者的持续协议

    Fairness: from the ethical principle to the practice of Machine Learning development as an ongoing agreement with stakeholders. (arXiv:2304.06031v1 [cs.CY])

    [http://arxiv.org/abs/2304.06031](http://arxiv.org/abs/2304.06031)

    本文提出了一种支持伦理的迭代过程，旨在通过机器学习设计中的持续协议挑战不对称的权力动态，并支持团队在各个步骤中识别、减轻和监测偏差。

    

    本文阐明了为什么无法完全消除机器学习（ML）中的偏见，并提出了一种端到端的方法来将正义与公正的伦理原则转化为与利益相关者的持续协议，纳入ML开发实践中。本文提出的支持伦理的迭代过程旨在挑战ML设计中的不对称权力动态，帮助ML开发团队在ML系统开发的每个步骤中识别、减轻和监测偏见。该过程还提供了如何向用户解释偏见在权衡方面始终不完美的指导。

    This paper clarifies why bias cannot be completely mitigated in Machine Learning (ML) and proposes an end-to-end methodology to translate the ethical principle of justice and fairness into the practice of ML development as an ongoing agreement with stakeholders. The pro-ethical iterative process presented in the paper aims to challenge asymmetric power dynamics in the fairness decision making within ML design and support ML development teams to identify, mitigate and monitor bias at each step of ML systems development. The process also provides guidance on how to explain the always imperfect trade-offs in terms of bias to users.
    
[^93]: ImageReward：学习和评估文本到图像生成的人类喜好

    ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation. (arXiv:2304.05977v1 [cs.CV])

    [http://arxiv.org/abs/2304.05977](http://arxiv.org/abs/2304.05977)

    ImageReward是一种通用的文本到图像生成的人类喜好奖励模型，它可以通过收集专家的比较数据集来解决生成模型的问题，并且在人类评估中表现出色，有望成为一种用于评估和改进文本到图像合成的自动度量标准。

    

    本文提出一种通用的文本到图像生成人类喜好奖励模型ImageReward，旨在解决生成模型中存在的各种问题，并使其与人类价值和偏好保持一致。该奖励模型的训练基于我们的系统注释流程，其中包括评分和排名组件，迄今已收集了137k的专家比较数据集。在人类评估中，ImageReward的表现优于现有的评分方法（例如比CLIP高38.6\%），因此它是一种有前途的用于评估和改进文本到图像合成的自动度量标准。该奖励模型通过\texttt {image-reward}程序包公开提供，网址为\url{https://github.com/THUDM/ImageReward}。

    We present ImageReward -- the first general-purpose text-to-image human preference reward model -- to address various prevalent issues in generative models and align them with human values and preferences. Its training is based on our systematic annotation pipeline that covers both the rating and ranking components, collecting a dataset of 137k expert comparisons to date. In human evaluation, ImageReward outperforms existing scoring methods (e.g., CLIP by 38.6\%), making it a promising automatic metric for evaluating and improving text-to-image synthesis. The reward model is publicly available via the \texttt{image-reward} package at \url{https://github.com/THUDM/ImageReward}.
    
[^94]: LMR: 基于车道距离的轨迹预测度量

    LMR: Lane Distance-Based Metric for Trajectory Prediction. (arXiv:2304.05869v1 [cs.CV])

    [http://arxiv.org/abs/2304.05869](http://arxiv.org/abs/2304.05869)

    LMR是一种基于车道距离的度量，适用于轨迹预测中的结构化环境，相比传统的欧氏距离度量更准确。

    

    轨迹预测方法的开发需要度量来验证和比较它们的性能。目前已经确定的度量基于欧氏距离，这意味着在所有方向上都给出了相同的误差权重。欧几里得度量对于像道路这样的结构化环境是不足够的，因为它们没有妥善捕捉到与底层车道相关的操作员意图。为了针对下游规划任务合理评估轨迹预测方法，我们提出了一种新的度量，即基于车道距离的车道错过率（LMR）。对于LMR的计算，将地面实测和预测端点分配给车道线段，更确切地说是它们的中心线。通过沿车道线段的距离测量，预测与实测之间的距离在一定阈值范围内的预测被称为命中，否则称为错过。LMR则定义为产生错过的序列的比率。我们在三个不同的数据集上的结果表明，相对于传统的基于欧氏距离的度量，LMR是适用于类似车道这样的结构化环境的轨迹预测更为合适的度量。

    The development of approaches for trajectory prediction requires metrics to validate and compare their performance. Currently established metrics are based on Euclidean distance, which means that errors are weighted equally in all directions. Euclidean metrics are insufficient for structured environments like roads, since they do not properly capture the agent's intent relative to the underlying lane. In order to provide a reasonable assessment of trajectory prediction approaches with regard to the downstream planning task, we propose a new metric that is lane distance-based: Lane Miss Rate (LMR). For the calculation of LMR, the ground-truth and predicted endpoints are assigned to lane segments, more precisely their centerlines. Measured by the distance along the lane segments, predictions that are within a certain threshold distance to the ground-truth count as hits, otherwise they count as misses. LMR is then defined as the ratio of sequences that yield a miss. Our results on three s
    
[^95]: Proximity Forest 2.0：一种新的有效且可扩展的基于相似性的时间序列分类器

    Proximity Forest 2.0: A new effective and scalable similarity-based classifier for time series. (arXiv:2304.05800v1 [cs.LG])

    [http://arxiv.org/abs/2304.05800](http://arxiv.org/abs/2304.05800)

    Proximity Forest 2.0是一种新的有效且可扩展的基于相似性的时间序列分类器，优于先前最先进的基于相似性的分类器以及最先进的基于内核、神经网络和混合方法在特定数据集上的表现。

    

    时间序列分类（TSC）由于可能与不同分类任务相关的特征类型的多样性而具有挑战性，包括趋势、方差、频率、幅度和各种模式。为了应对这一挑战，已经开发了几种替代方法类别，包括基于相似性、特征和间隔、形状、字典、内核、神经网络和混合方法。本文提出了一种新的基于相似性的分类器Proximity Forest版本2.0（PF 2.0），它在UCR基准测试中优于先前最先进的基于相似性的分类器，并在基准测试中优于最先进的基于内核、神经网络和混合方法的特定数据集，这些数据集最适合使用基于相似性的方法。PF 2.0 合并了时间序列相似性最近的三个进展……

    Time series classification (TSC) is a challenging task due to the diversity of types of feature that may be relevant for different classification tasks, including trends, variance, frequency, magnitude, and various patterns. To address this challenge, several alternative classes of approach have been developed, including similarity-based, features and intervals, shapelets, dictionary, kernel, neural network, and hybrid approaches. While kernel, neural network, and hybrid approaches perform well overall, some specialized approaches are better suited for specific tasks. In this paper, we propose a new similarity-based classifier, Proximity Forest version 2.0 (PF 2.0), which outperforms previous state-of-the-art similarity-based classifiers across the UCR benchmark and outperforms state-of-the-art kernel, neural network, and hybrid methods on specific datasets in the benchmark that are best addressed by similarity-base methods. PF 2.0 incorporates three recent advances in time series simi
    
[^96]: Astroformer：分类并不总是需要更多数据

    Astroformer: More Data Might Not be All You Need for Classification. (arXiv:2304.05350v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2304.05350](http://arxiv.org/abs/2304.05350)

    该文提出了使用混合变换器 - 卷积架构的方法，结合新的堆栈设计、不同的相对自我注意层创建方式和精心选择的数据增强和正则化技术，从少量数据中学习，将此方法应用于Galaxy Zoo数据集，结果表明在少量数据的情况下取得了与以前方法相同的分类结果，并且不会损失性能。

    

    自然语言处理和计算机视觉领域的最新进展依赖于复杂的大型模型，这些模型使用大量未标记或部分标记的数据进行训练。在资源受限制的环境中训练或部署这些最先进的方法一直是一个挑战。星系形态对于理解星系的形成和演化过程至关重要。需要高效的方法来分类星系形态，并从现代天文学调查中提取物理信息。在本文中，我们介绍了从少量数据中学习的方法。我们提出使用混合变换器 - 卷积架构，从CoAtNet和MaxViT的成功中汲取灵感。具体来说，我们使用具有新堆栈设计和不同的相对自我注意层创建方式的Transformer - 卷积混合。并将其与精心选择的数据增强和正则化技术相配对。我们将这种方法应用于Galaxy Zoo数据集，结果表明，通过仔细的网络设计和正则化技术，可以在比以前的方法少的数据条件下取得有竞争力的分类结果，而不会牺牲性能。

    Recent advancements in areas such as natural language processing and computer vision rely on intricate and massive models that have been trained using vast amounts of unlabelled or partly labeled data and training or deploying these state-of-the-art methods to resource constraint environments has been a challenge. Galaxy morphologies are crucial to understanding the processes by which galaxies form and evolve. Efficient methods to classify galaxy morphologies are required to extract physical information from modern-day astronomy surveys. In this paper, we introduce methods to learn from less amounts of data. We propose using a hybrid transformer-convolutional architecture drawing much inspiration from the success of CoAtNet and MaxViT. Concretely, we use the transformer-convolutional hybrid with a new stack design for the network, a different way of creating a relative self-attention layer, and pair it with a careful selection of data augmentation and regularization techniques. Our app
    
[^97]: 模型稀疏化可以简化机器反学习

    Model sparsification can simplify machine unlearning. (arXiv:2304.04934v1 [cs.LG])

    [http://arxiv.org/abs/2304.04934](http://arxiv.org/abs/2304.04934)

    本文提出了一种基于模型稀疏化的机器反学习方案，称为prune first, then unlearn和sparsity-aware unlearning。此方案可以提高近似反学习器的多标准反学习性能，并在不同的场景中表现出一致的效果。

    

    最近的数据管制要求机器反学习（MU）：从模型中移除指定样例的影响。虽然可以通过使用剩余数据从头开始进行模型重新训练来进行精确反学习，但是其计算成本导致了近似但高效的反学习方案的开发。除了数据中心的MU解决方案，我们通过一种新颖的基于模型的视角推进MU：通过权值修剪进行稀疏化。我们的理论和实践结果表明，模型稀疏性可以提高近似反学习器的多标准反学习性能，缩小近似间隙，同时保持高效。有了这个认识，我们制定了两个新的稀疏感知反学习元方案，称为“先修剪，然后反学习”和“稀疏感知反学习”。广泛的实验表明，我们的发现和提议在各种场景下始终有益于MU，包括按类数据擦除、随机数据擦除和后门数据伪造等。

    Recent data regulations necessitate machine unlearning (MU): The removal of the effect of specific examples from the model. While exact unlearning is possible by conducting a model retraining with the remaining data from scratch, its computational cost has led to the development of approximate but efficient unlearning schemes. Beyond data-centric MU solutions, we advance MU through a novel model-based viewpoint: sparsification via weight pruning. Our results in both theory and practice indicate that model sparsity can boost the multi-criteria unlearning performance of an approximate unlearner, closing the approximation gap, while continuing to be efficient. With this insight, we develop two new sparsity-aware unlearning meta-schemes, termed `prune first, then unlearn' and `sparsity-aware unlearning'. Extensive experiments show that our findings and proposals consistently benefit MU in various scenarios, including class-wise data scrubbing, random data scrubbing, and backdoor data forge
    
[^98]: 在恒星变异存在下，基于深度学习的行星径向速度测量方法

    Deep-learning based measurement of planetary radial velocities in the presence of stellar variability. (arXiv:2304.04807v1 [astro-ph.EP])

    [http://arxiv.org/abs/2304.04807](http://arxiv.org/abs/2304.04807)

    本文提出了一种基于深度学习的方法，使用神经网络来减少三年HARPS-N太阳-星形光谱中的恒星径向速度抖动。该方法能够以前无法想象的小行星径向速度检测精度，为缓解恒星径向速度变异提供了希望。

    

    本文提出了一种基于深度学习的方法，用于在恒星变异存在下测量小行星的径向速度。我们使用神经网络来减少三年HARPS-N太阳-星形光谱中的恒星径向速度抖动。我们开发并比较了不同的降维和数据分割方法，以及各种神经网络体系结构，包括单线CNN、单线CNN集合和多线CNN。我们将类似于行星的径向速度注入光谱中并使用网络恢复它们。我们发现，多线CNN能够恢复0.2m/s半振幅、50天周期的行星，其振幅误差为8.8％，周期误差为0.7％。这种方法展示了在缓解恒星径向速度变异的同时，实现了以前无法想象的小行星径向速度检测精度的承诺。

    We present a deep-learning based approach for measuring small planetary radial velocities in the presence of stellar variability. We use neural networks to reduce stellar RV jitter in three years of HARPS-N sun-as-a-star spectra. We develop and compare dimensionality-reduction and data splitting methods, as well as various neural network architectures including single line CNNs, an ensemble of single line CNNs, and a multi-line CNN. We inject planet-like RVs into the spectra and use the network to recover them. We find that the multi-line CNN is able to recover planets with 0.2 m/s semi-amplitude, 50 day period, with 8.8% error in the amplitude and 0.7% in the period. This approach shows promise for mitigating stellar RV variability and enabling the detection of small planetary RVs with unprecedented precision.
    
[^99]: 反射扩散模型

    Reflected Diffusion Models. (arXiv:2304.04740v1 [stat.ML])

    [http://arxiv.org/abs/2304.04740](http://arxiv.org/abs/2304.04740)

    该论文提出了反射扩散模型，通过学习反射随机微分方程的扰动评分函数，将数据约束原则性地整合到生成过程中，以取代之前采用的导致不自然样本的阈值处理方案。

    

    基于分数的扩散模型学习将数据映射到噪声的随机微分方程的反向。然而，对于复杂任务，数值误差可以累积并导致高度不自然的样本。以前的工作通过阈值处理来缓解漂移，每次扩散步骤后投影到自然数据域（例如图像的像素空间），但这导致训练和生成过程之间存在不匹配。为了以一种原则性的方式合并数据约束，我们提出了反射扩散模型，该模型反向演化在数据支持的反射随机微分方程上。我们的方法通过一般化的分数匹配损失函数学习扰动评分函数，并扩展了标准扩散模型的关键组件，包括扩散引导、基于似然的训练和ODE采样。我们还弥合了阈值处理的理论差距:这样的方案只是反射SDE的离散化。在标准图像基准测试中，我们的

    Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalize score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our 
    
[^100]: 可能大致正确联邦学习

    Probably Approximately Correct Federated Learning. (arXiv:2304.04641v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.04641](http://arxiv.org/abs/2304.04641)

    本文提出了FedPAC框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。

    

    联邦学习是一种新的分布式学习范例，其主要支柱为隐私、效用和效率。现有研究表明，同时实现无穷小隐私泄露、效用损失和效率是不可能的。因此，在设计联邦学习算法时，如何找到最佳权衡解决方案是关键考虑因素。一种常见的方法是将权衡问题视为多目标优化问题，即目标是在约束隐私泄露不超过预定值的情况下最小化效用损失和效率降低。然而，现有的多目标优化框架非常耗时，并且不能保证帕累托前沿的存在性，这激励我们寻求一种方法，将多目标问题转化为单目标问题，因为它更高效、更容易被解决。为此，本文提出了FedPAC，这是一个统一的框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。具体而言，我们首先将FL问题公式化为一个二分类任务，然后设计一个自适应FL算法，动态调整每个客户端的采样比率，以平衡全局和本地的隐私-效用权衡，最后证明FedPAC可以在温和的假设下高概率地实现最优的隐私-效用权衡。基准数据集上的大量实验证明了我们提出的FedPAC框架的功效和效率。

    Federated learning (FL) is a new distributed learning paradigm, with privacy, utility, and efficiency as its primary pillars. Existing research indicates that it is unlikely to simultaneously attain infinitesimal privacy leakage, utility loss, and efficiency. Therefore, how to find an optimal trade-off solution is the key consideration when designing the FL algorithm. One common way is to cast the trade-off problem as a multi-objective optimization problem, i.e., the goal is to minimize the utility loss and efficiency reduction while constraining the privacy leakage not exceeding a predefined value. However, existing multi-objective optimization frameworks are very time-consuming, and do not guarantee the existence of the Pareto frontier, this motivates us to seek a solution to transform the multi-objective problem into a single-objective problem because it is more efficient and easier to be solved. To this end, in this paper, we propose FedPAC, a unified framework that leverages PAC l
    
[^101]: OpenAGI：当LLM遇到领域专家

    OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v1 [cs.AI])

    [http://arxiv.org/abs/2304.04370](http://arxiv.org/abs/2304.04370)

    基于大型语言模型的OpenAGI平台通过整合领域专家模型和自然语言问答形式，实现复杂任务解决。

    

    人类具有将基本技能组合成复杂技能以解决复杂任务的显著能力。这种能力对于人工智能同样重要，因此，我们断言，除了开发大型综合智能模型外，将不同领域专家模型应用于复杂任务解决能力同样关键，以在人工智能通用智能的追求中使其具备这种能力。最近的大型语言模型（LLM）的发展证明其具有出色的学习和推理能力，使它们成为选择、综合和执行外部模型以解决复杂任务的控制器的有前途的选择。在这个项目中，我们开发了一个名为OpenAGI的开源AGI研究平台，专门设计为提供复杂的多步骤任务，并配有任务特定的数据集、评估指标和各种可扩展模型。OpenAGI将复杂任务阐释为自然语言问答，旨在促进领域专家和语言模型之间的协同作用。

    Human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. This ability is equally important for Artificial Intelligence (AI), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of Artificial General Intelligence (AGI). Recent developments in Large Language Models (LLMs) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. In this project, we develop OpenAGI, an open-source AGI research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. OpenAGI formulates complex tasks as natural language q
    
[^102]: PriorCVAE: 基于贝叶斯深度生成建模的可扩展 MCMC 参数推断

    PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling. (arXiv:2304.04307v1 [stat.ML])

    [http://arxiv.org/abs/2304.04307](http://arxiv.org/abs/2304.04307)

    PriorCVAE 提出了一种处理高斯过程先验 MCMC 参数推断的贝叶斯深度生成建模新方法，可通过将 VAE 建模条件化于随机过程超参数处理超参数推断与学习先验之间的信息流断裂问题。

    

    在应用场景中，推理速度和模型灵活性至关重要，贝叶斯推断在具有随机过程先验的模型中（如高斯过程）被广泛应用。最近的研究表明，使用变分自动编码器（VAE）等深度生成模型可以编码由 GP 先验或其有限实现引起的计算瓶颈，并且所学生成器可以代替 MCMC 推断中的原始先验。虽然此方法实现了快速而高效的推理，但它丢失了关于随机过程超参数的信息，导致超参数推断不可能和学到的先验模糊不清。我们建议解决上述问题，通过将 VAE 建模条件化于随机过程超参数，以便超参数与 GP 实现一起进行编码。

    In applied fields where the speed of inference and model flexibility are crucial, the use of Bayesian inference for models with a stochastic process as their prior, e.g. Gaussian processes (GPs) is ubiquitous. Recent literature has demonstrated that the computational bottleneck caused by GP priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (VAEs), and the learned generators can then be used instead of the original priors during Markov chain Monte Carlo (MCMC) inference in a drop-in manner. While this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. We propose to resolve the aforementioned issue and disentangle the learned priors by conditioning the VAE on stochastic process hyperparameters. This way, the hyperparameters are encoded alongside GP real
    
[^103]: 神经网络生成响应曲线的反事实解释

    Counterfactual Explanations of Neural Network-Generated Response Curves. (arXiv:2304.04063v1 [cs.LG])

    [http://arxiv.org/abs/2304.04063](http://arxiv.org/abs/2304.04063)

    本文提出一种使用反事实解释（CFEs）确定神经网络黑盒生成的响应曲线上最具相关性的特征的方法，并将其应用于工业资产预测维护的案例研究中，可以解释模型的行为并检测异常行为的潜在原因。

    

    响应曲线展示了一个敏感系统对不同刺激的响应程度。然而，这类系统的反应可能对多个不一定独立的刺激（即输入特征）敏感。因此，为了一个选定的输入特征（称为“活动特征”）所生成的响应曲线的形状可能依赖于其他输入特征（称为“被动特征”）的值。在这项工作中，我们考虑了使用回归神经网络逼近响应的系统。我们提出使用反事实解释（CFEs）来确定通过神经网络黑盒生成的响应曲线上最具相关性的特征。 CFE是通过基于遗传算法的方法生成的，该方法解决了多目标优化问题。特别地，对于为主动特征生成的响应曲线，CFE找到需要修改的被动特征的最小组合，以改变曲线的形状。我们将我们的方法应用于两个工业资产预测维护的案例研究中，其中黑盒回归模型生成的响应曲线用于检测异常。我们演示了如何使用CFEs来解释这些模型的行为，并检测异常行为的潜在原因。

    Response curves exhibit the magnitude of the response of a sensitive system to a varying stimulus. However, response of such systems may be sensitive to multiple stimuli (i.e., input features) that are not necessarily independent. As a consequence, the shape of response curves generated for a selected input feature (referred to as "active feature") might depend on the values of the other input features (referred to as "passive features"). In this work we consider the case of systems whose response is approximated using regression neural networks. We propose to use counterfactual explanations (CFEs) for the identification of the features with the highest relevance on the shape of response curves generated by neural network black boxes. CFEs are generated by a genetic algorithm-based approach that solves a multi-objective optimization problem. In particular, given a response curve generated for an active feature, a CFE finds the minimum combination of passive features that need to be mod
    
[^104]: EGC: 一种通过单一能量模型生成与分类图像的方法

    EGC: Image Generation and Classification via a Single Energy-Based Model. (arXiv:2304.02012v1 [cs.CV])

    [http://arxiv.org/abs/2304.02012](http://arxiv.org/abs/2304.02012)

    EGC是一种使用单个神经网络在图像分类和图像生成任务中实现卓越性能的方法，可以较好地生成出高质量图像，并在多项数据集上实现了领先的分类结果。

    

    使用相同的网络参数学习图像分类和生成图像是一个具有挑战性的问题。最近的先进方法在一项任务上表现良好，但在另一项任务上却表现不佳。本文引入了一种名为EGC的基于能量的分类器和生成器，它可以使用单个神经网络在两个任务中实现卓越性能。与传统的分类器输出给定图像的标签（即条件分布$p(y|\mathbf{x})$）不同，EGC的前向传递器是一个分类器，它输出一个联合分布$p(\mathbf{x},y)$，在后向传递器中通过边缘化标签$y$实现生成器。在前向传递中，估计给定噪声图像的能量和分类概率，而在后向传递中，通过估计得分函数对其进行去噪。EGC在ImageNet-1k、CelebA-HQ和LSUN Church上实现了与最先进方法相当的生成结果，同时在CIFAR-10、CIFAR-100和ImageNet-1k上实现了最先进的分类结果。

    Learning image classification and image generation using the same set of network parameters is a challenging problem. Recent advanced approaches perform well in one task often exhibit poor performance in the other. This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network. Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achi
    
[^105]: 降低Frank-Wolfe方法中的离散化误差

    Reducing Discretization Error in the Frank-Wolfe Method. (arXiv:2304.01432v1 [math.OC])

    [http://arxiv.org/abs/2304.01432](http://arxiv.org/abs/2304.01432)

    本论文提出了两个改进方法：一个多步的Frank-Wolfe方法，直接应用优化的高阶离散化方案；以及一种具有较少离散化误差的LMO-平均方案，其收敛速率加速到$O(1/k^{3/2})$，从而更好地解决了Frank-Wolfe方法中的离散化误差问题。

    

    Frank-Wolfe算法是结构受限机器学习应用中常用的方法，因其快速迭代复杂度而受欢迎。然而，该方法的一个主要限制是收敛速度缓慢，由于步长方向的不规则震荡而难以加速，即使在接近解的渐近情况下也是如此。我们认为这是离散化的产物；也就是说，Frank-Wolfe的流（即渐近小步长情况下的轨迹）不会出现不规则震荡，因此减少离散化误差将与产生更稳定的方法和更好的收敛特性相辅相成。我们提出了两个改进：一个多步Frank-Wolfe方法，直接应用优化的高阶离散化方案；和一个具有降低离散化误差的LMO-平均方案，其在一般凸集上的局部收敛速率从$O(1/k)$加速到$O(1/k^{3/2})$ 。

    The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe \emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.
    
[^106]: 使用人工智能在家中测量帕金森病的严重程度

    Using AI to Measure Parkinson's Disease Severity at Home. (arXiv:2303.17573v1 [cs.LG])

    [http://arxiv.org/abs/2303.17573](http://arxiv.org/abs/2303.17573)

    该论文提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法，该方法可重复用于类似的运动任务，拥有较高的可靠性和准确性。

    

    我们提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法。参与者在网络摄像头前完成了运动任务（即点击手指），250名全球参与者的数据按照运动障碍协会统一帕金森病评分量表 (MDS-UPDRS) 的标准由三名专家神经学家进行了评估。神经学家的评估具有高度的可靠性，内部一致性系数（ICC）为0.88。我们开发了计算机算法来获得与MDS-UPDRS指南一致且与神经学家的评估高度相关的客观测量结果。我们的机器学习模型在这些指标的训练下表现优于一个MDS-UPDRS认证的评分者，平均绝对误差（MAE）为0.59，而评分者的MAE为0.79。然而，该模型的表现略逊于专家神经学家（0.53 MAE）。该方法可重复用于类似的运动任务，提供了可能性。

    We present an artificial intelligence system to remotely assess the motor performance of individuals with Parkinson's disease (PD). Participants performed a motor task (i.e., tapping fingers) in front of a webcam, and data from 250 global participants were rated by three expert neurologists following the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS). The neurologists' ratings were highly reliable, with an intra-class correlation coefficient (ICC) of 0.88. We developed computer algorithms to obtain objective measurements that align with the MDS-UPDRS guideline and are strongly correlated with the neurologists' ratings. Our machine learning model trained on these measures outperformed an MDS-UPDRS certified rater, with a mean absolute error (MAE) of 0.59 compared to the rater's MAE of 0.79. However, the model performed slightly worse than the expert neurologists (0.53 MAE). The methodology can be replicated for similar motor tasks, providing the possibili
    
[^107]: 基于异构内存结构的边缘NLP推理的节能任务适应性

    Energy-efficient Task Adaptation for NLP Edge Inference Leveraging Heterogeneous Memory Architectures. (arXiv:2303.16100v1 [cs.LG])

    [http://arxiv.org/abs/2303.16100](http://arxiv.org/abs/2303.16100)

    adapter-ALBERT是一种高效的NLP模型优化方法，可以在实现多任务推理同时最大程度地实现数据重用，并提高对数据压缩方法的鲁棒性。

    

    在资源受限的边缘设备上执行机器学习推理任务需要仔细的硬件-软件协同设计优化。最近的研究表明，基于变压器的深度神经网络模型，如ALBERT可以用于在移动系统级芯片上执行自然语言处理（NLP）推理，并配备自定义硬件加速器。然而，这些现有的解决方案虽然可以有效地缓解运行单个NLP任务的延迟、能量和面积成本，但对于实现多任务推理，需要在针对每个目标任务的多个模型参数的基础上执行计算。这种方法会导致过高的芯片内存需求或支付芯片外部存储器访问的成本。本文提出了一种高效的模型优化方法，即adapter-ALBERT，用于在不同任务之间实现最大化数据重用性。该模型的性能和对数据压缩方法的鲁棒性进行了评估。

    Executing machine learning inference tasks on resource-constrained edge devices requires careful hardware-software co-design optimizations. Recent examples have shown how transformer-based deep neural network models such as ALBERT can be used to enable the execution of natural language processing (NLP) inference on mobile systems-on-chip housing custom hardware accelerators. However, while these existing solutions are effective in alleviating the latency, energy, and area costs of running single NLP tasks, achieving multi-task inference requires running computations over multiple variants of the model parameters, which are tailored to each of the targeted tasks. This approach leads to either prohibitive on-chip memory requirements or paying the cost of off-chip memory access. This paper proposes adapter-ALBERT, an efficient model optimization for maximal data reuse across different tasks. The proposed model's performance and robustness to data compression methods are evaluated across s
    
[^108]: 基于深度学习的振动信号去噪方法

    Vibration Signal Denoising Using Deep Learning. (arXiv:2303.11413v1 [eess.SP])

    [http://arxiv.org/abs/2303.11413](http://arxiv.org/abs/2303.11413)

    本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。

    

    由脚步引起的结构振动信号被广泛用于人员识别、定位、人类活动推断、结构健康监测等任务。然而，由于环境噪声、电磁干扰等因素的影响，实际采集的信号通常会带有噪声。噪声的存在影响了信号处理过程，从而影响了最终任务的准确性和误差。本文主要探讨了基于深度学习的去除脚步引起的振动信号的噪声的方法。我们考虑了不同类型的噪声，包括高斯噪声和非平稳噪声等。

    Structure vibration signals induced by footsteps are widely used for tasks like occupant identification, localization, human activity inference, structure health monitoring and so on. The vibration signals are collected as time series with amplitude values. However, the collected signals are always noisy in practice due to the influence of environmental noise, electromagnetic interference and other factors. The presence of noise affects the process of signal analysis, thus affecting the accuracy and error of the final tasks. In this paper, we mainly explore the denoising methods for footstep-induced vibration signals. We have considered different kinds of noise including stationary noises such as gaussian noises and non-stationary noises such as item-dropping vibration noise and music noises.
    
[^109]: 边缘计算平台上的硬件感知图神经网络自动化设计

    Hardware-Aware Graph Neural Network Automated Design for Edge Computing Platforms. (arXiv:2303.10875v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.10875](http://arxiv.org/abs/2303.10875)

    本文提出了HGNAS框架，它是第一个面向资源受限的边缘设备的硬件感知图神经结构搜索框架。通过解耦GNN范式，它构建了一个精细的设计空间，并通过利用硬件性能预测器，在GNN架构设计中实现了硬件感知。实验结果表明，HGNAS实现了高效的GNN设计，显著提高了推理速度和减少了内存占用，同时保持竞争性的准确度，相较于手动设计模型而言。

    

    面对非欧几里德数据的流行策略，图神经网络(GNNs)因其最先进的性能而应运而生。然而，大多数当前的GNN模型设计主要关注任务准确性，缺乏考虑硬件资源限制和边缘应用场景的实时要求。对典型GNN模型的全面分析表明，在不同的计算平台上，它们的执行特性受到了显著的影响，这需要高效的GNN设计与硬件意识。本文提出了HGNAS作为第一个面向资源受限的边缘设备的硬件感知图神经结构搜索框架。通过解耦GNN范式，HGNAS构建了一个精细的设计空间，并利用高效的多阶段搜索策略在数个GPU小时内探索最佳结构。此外，HGNAS通过利用硬件性能预测器，在GNN架构设计中实现了硬件感知。在几个基准数据集上的实验结果表明，HGNAS实现了高效的GNN设计，显著提高了推理速度和减少了内存占用，同时保持竞争性的准确度，相较于手动设计模型而言。

    Graph neural networks (GNNs) have emerged as a popular strategy for handling non-Euclidean data due to their state-of-the-art performance. However, most of the current GNN model designs mainly focus on task accuracy, lacking in considering hardware resources limitation and real-time requirements of edge application scenarios. Comprehensive profiling of typical GNN models indicates that their execution characteristics are significantly affected across different computing platforms, which demands hardware awareness for efficient GNN designs. In this work, HGNAS is proposed as the first Hardware-aware Graph Neural Architecture Search framework targeting resource constraint edge devices. By decoupling the GNN paradigm, HGNAS constructs a fine-grained design space and leverages an efficient multi-stage search strategy to explore optimal architectures within a few GPU hours. Moreover, HGNAS achieves hardware awareness during the GNN architecture design by leveraging a hardware performance pr
    
[^110]: 《具有最优n的n步时序差分学习》

    n-Step Temporal Difference Learning with Optimal n. (arXiv:2303.07068v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07068](http://arxiv.org/abs/2303.07068)

    本文提出了使用SPSA算法求解n步时序差分学习中的最优n值的算法SDPSA，并证明了其收敛性和有效性。

    

    本文考虑了在n步时序差分算法中找到最优n值的问题。我们采用了模型自由优化技术，即同时扰动随机逼近（SPSA）方法来寻找最优n。我们采用了一个模拟SPSA程序，将其原始连续优化框架引入离散优化框架，但并结合了循环扰动序列。我们证明了我们提出的算法SDPSA的收敛性，并表明它可以在任意初始值的情况下找到n步TD中的最优n值。通过实验，我们展示了SDPSA能够实现最优n值的求解。

    We consider the problem of finding the optimal value of n in the n-step temporal difference (TD) algorithm. We find the optimal n by resorting to the model-free optimization technique of simultaneous perturbation stochastic approximation (SPSA). We adopt a one-simulation SPSA procedure that is originally for continuous optimization to the discrete optimization framework but incorporates a cyclic perturbation sequence. We prove the convergence of our proposed algorithm, SDPSA, and show that it finds the optimal value of n in n-step TD. Through experiments, we show that the optimal value of n is achieved with SDPSA for any arbitrary initial value of the same.
    
[^111]: 神经图形的硬件加速

    Hardware Acceleration of Neural Graphics. (arXiv:2303.05735v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2303.05735](http://arxiv.org/abs/2303.05735)

    本文研究了神经图形是否需要硬件支持，发现当前GPU性能无法满足对4K分辨率60FPS渲染的需求，且在增强现实/虚拟现实应用中性能缺口更大。作者确定输入编码和MLP内核是性能瓶颈。

    

    传统的计算机图形学渲染和反渲染算法已被神经表示（NR）所取代。NR最近被用于学习场景的几何和材质属性，并使用这些信息合成真实的图像，因此承诺用可伸缩的质量和可预测的性能替换传统的渲染算法。本文提出问题：神经图形（NG）是否需要硬件支持？我们研究了代表性的NG应用程序，发现如果我们要在当前的GPU上以60FPS渲染4K分辨率，则所需性能与当前GPU的实际性能存在1.5倍至55倍的差距。对于增强现实/虚拟现实应用程序，所需性能与所需系统功率之间存在更大的差距。我们确定输入编码和MLP内核是性能瓶颈，对于多分辨率哈希网格、多分辨率密集网格和低分辨率密集网格，它们占应用程序时间的72％、60％和59％。

    Rendering and inverse-rendering algorithms that drive conventional computer graphics have recently been superseded by neural representations (NR). NRs have recently been used to learn the geometric and the material properties of the scenes and use the information to synthesize photorealistic imagery, thereby promising a replacement for traditional rendering algorithms with scalable quality and predictable performance. In this work we ask the question: Does neural graphics (NG) need hardware support? We studied representative NG applications showing that, if we want to render 4k res. at 60FPS there is a gap of 1.5X-55X in the desired performance on current GPUs. For AR/VR applications, there is an even larger gap of 2-4 OOM between the desired performance and the required system power. We identify that the input encoding and the MLP kernels are the performance bottlenecks, consuming 72%,60% and 59% of application time for multi res. hashgrid, multi res. densegrid and low res. densegrid 
    
[^112]: ChatGPT和其他大型语言模型作为在线互动协作游戏设计的进化引擎（arXiv:2303.02155v2 [cs.AI] UPDATED）

    ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design. (arXiv:2303.02155v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02155](http://arxiv.org/abs/2303.02155)

    本论文提出了一种新的结合交互式进化和大型语言模型的协作游戏设计框架，用于模拟典型的人类设计过程，并用大型语言模型进行非常复杂的创造性任务－思想的重组和变异。

    

    大型语言模型（LLMs）已经在科学界掀起风暴，改变了自然语言处理和人机交互的现状。这些强大的工具可以回答复杂的问题，出奇地完成有挑战性的创造性任务（例如，生成代码和应用程序来解决问题，写故事、音乐片段等）。在本文中，我们提出了一种结合交互式进化和大型语言模型的协作游戏设计框架，以模拟典型的人类设计过程。我们使用前者利用用户的反馈选择最有前途的想法，使用大型语言模型进行非常复杂的创造性任务——思想的重组和变异。在我们的框架中，过程始于一个简要说明和一组候选设计，这些设计是使用语言模型生成的，或由用户提出的。接下来，用户通过向交互式遗传算法提供反馈来协作设计过程，该算法选择、重组和突变设计。

    Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative game design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task - the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mu
    
[^113]: 证据支持的转移学习在阿尔茨海默病中的应用

    Evidence-empowered Transfer Learning for Alzheimer's Disease. (arXiv:2303.01105v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2303.01105](http://arxiv.org/abs/2303.01105)

    该研究提出了一种在阿尔茨海默病诊断中使用证据支持的转移学习方法，通过利用AD相关的辅助任务来学习MRI扫描中形态学特征的证据和可转移知识，提高了检测性能，同时更具有数据效率和可信度。

    

    转移学习已经被广泛应用于减轻阿尔茨海默病（AD）领域中的数据匮乏问题。传统的转移学习依赖于重复使用在AD非相关任务（例如自然图像分类）上训练的模型。然而，由于非医学来源和目标医学领域之间的差异，它经常导致负转移。为了解决这个问题，我们提出了一种证据支持的AD诊断转移学习方法。与传统方法不同的是，我们利用AD相关的辅助任务，即形态变化预测，而无需额外的MRI数据。在这个辅助任务中，诊断模型学习来自MRI扫描中形态学特征的证据和可转移知识。实验结果表明，我们的框架不仅可以提高检测性能，而且无论模型容量如何，也更具有数据效率和可信度。

    Transfer learning has been widely utilized to mitigate the data scarcity problem in the field of Alzheimer's disease (AD). Conventional transfer learning relies on re-using models trained on AD-irrelevant tasks such as natural image classification. However, it often leads to negative transfer due to the discrepancy between the non-medical source and target medical domains. To address this, we present evidence-empowered transfer learning for AD diagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary task, namely morphological change prediction, without requiring additional MRI data. In this auxiliary task, the diagnosis model learns the evidential and transferable knowledge from morphological features in MRI scans. Experimental results demonstrate that our framework is not only effective in improving detection performance regardless of model capacity, but also more data-efficient and faithful.
    
[^114]: K-SHAP: 一种用于匿名状态-动作对的策略聚类算法

    K-SHAP: Policy Clustering Algorithm for Anonymous State-Action Pairs. (arXiv:2302.11996v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11996](http://arxiv.org/abs/2302.11996)

    本文提出了一种名为K-SHAP的算法，来解决多个智能体保持匿名且仅有状态-动作对的情况下学习智能体决策的问题。

    

    从观测数据中学习智能体行为已经被证明可以提高我们对它们决策过程的理解，从而增强我们解释它们与环境和其他智能体之间交互的能力。尽管文献中已经提出了多种学习技术，但还有一种特定的情况尚未被探索，那就是智能体身份保持匿名的多智能体系统。例如，在金融市场中，标记数据通常是专有的，仅公开多个市场参与者交互而产生的匿名状态-动作对。因此，智能体行动序列不可观测，限制了现有工作的适用性。本文提出了一种策略聚类算法K-SHAP，它学习根据智能体策略对匿名状态-动作对进行分组。我们将该问题作为模仿学习(IL)任务，学习一个w...

    Learning agent behaviors from observational data has shown to improve our understanding of their decision-making processes, advancing our ability to explain their interactions with the environment and other agents. While multiple learning techniques have been proposed in the literature, there is one particular setting that has not been explored yet: multi agent systems where agent identities remain anonymous. For instance, in financial markets labeled data that identifies market participant strategies is typically proprietary, and only the anonymous state-action pairs that result from the interaction of multiple market participants are publicly available. As a result, sequences of agent actions are not observable, restricting the applicability of existing work. In this paper, we propose a Policy Clustering algorithm, called K-SHAP, that learns to group anonymous state-action pairs according to the agent policies. We frame the problem as an Imitation Learning (IL) task, and we learn a w
    
[^115]: 利用共享微指数，微小的位移带来了巨大的变化

    With Shared Microexponents, A Little Shifting Goes a Long Way. (arXiv:2302.08007v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08007](http://arxiv.org/abs/2302.08007)

    本论文提出了一种名为BDR的框架，用于评估窄精度格式。通过BDR，本文发现了一种基于共享微指数的新格式，其在大规模生成预训练和推理以及推荐系统方面的效果优于其他先进的量化方法。

    

    本文介绍了一种名为模块数据表示（BDR）的框架，用于探索和评估一系列用于深度学习的窄精度格式。它能够比较流行的量化标准，并通过BDR，发现了一种基于共享微指数（MX）的新格式，其优于其他最先进的量化方法，包括窄精度浮点和块浮点。MX 在硬件中利用多个量化级别，使用基于共享微指数的超细缩放因子。MX 的有效性在包括大规模生成预训练和推理以及生产规模推荐系统在内的实际模型上得到了证明。

    This paper introduces Block Data Representations (BDR), a framework for exploring and evaluating a wide spectrum of narrow-precision formats for deep learning. It enables comparison of popular quantization standards, and through BDR, new formats based on shared microexponents (MX) are identified, which outperform other state-of-the-art quantization approaches, including narrow-precision floating-point and block floating-point. MX utilizes multiple levels of quantization scaling with ultra-fine scaling factors based on shared microexponents in the hardware. The effectiveness of MX is demonstrated on real-world models including large-scale generative pretraining and inferencing, and production-scale recommendation systems.
    
[^116]: 神经网络原子势的数据效率和外推趋势

    Data efficiency and extrapolation trends in neural network interatomic potentials. (arXiv:2302.05823v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05823](http://arxiv.org/abs/2302.05823)

    本文研究了神经网络原子势模型在体系架构和优化选择方面的影响，揭示了分子动力学稳定性、数据效率和损失空间等趋势。研究结果表明，使用损失空间可视化和损失熵的度量可以预测NNIP的泛化能力。

    

    近年来，神经网络原子势（NNIP）的关键架构进步包括了消息传递网络、等变性或多体展开项。尽管现代NNIP模型在能量/力误差方面存在微小差异，但在开发新的NNIP体系结构时，提高准确性仍然被视为主要目标。在本研究中，我们展示了体系结构和优化选择如何影响NNIP的普遍化，揭示了分子动力学（MD）稳定性、数据效率和损失空间的趋势。利用3BPA数据集，我们表明NNIP的测试误差遵循比例关系，并且可以耐受噪声，但不能预测高精度区域的MD稳定性。为了解决这个问题，我们提出了使用损失空间可视化和损失熵的度量来预测NNIP的泛化能力。通过对NequIP和MACE进行大规模研究，我们展示了损失熵的优势。

    Over the last few years, key architectural advances have been proposed for neural network interatomic potentials (NNIPs), such as incorporating message-passing networks, equivariance, or many-body expansion terms. Although modern NNIP models exhibit small differences in energy/forces errors, improvements in accuracy are still considered the main target when developing new NNIP architectures. In this work, we show how architectural and optimization choices influence the generalization of NNIPs, revealing trends in molecular dynamics (MD) stability, data efficiency, and loss landscapes. Using the 3BPA dataset, we show that test errors in NNIP follow a scaling relation and can be robust to noise, but cannot predict MD stability in the high-accuracy regime. To circumvent this problem, we propose the use of loss landscape visualizations and a metric of loss entropy for predicting the generalization power of NNIPs. With a large-scale study on NequIP and MACE, we show that the loss entropy pr
    
[^117]: 追求机器学习研究的推理复现性

    Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04054](http://arxiv.org/abs/2302.04054)

    本研究提出利用线性混合效应模型（LMEM）来分析机器学习性能评估分数，并考虑多个方差来源及其与数据特性相互作用，从而评估可靠性和可复制性，促进对机器学习算法行为的更全面理解。

    

    机器学习评估的可靠性——即在复制的模型训练运行中观察到的评估分数的一致性——受到几种非确定性来源的影响，可以被视为测量噪声。目前的趋势是去除噪声，以强制研究结果的可复制性，忽略了实现层面固有的非确定性以及算法噪声因素和数据特性之间的关键相互作用效应。这限制了从这些实验中可以得出的结论范围。我们提出的方法是将几个方差来源，包括它们与数据特性的相互作用，纳入机器学习评估的显著性和可靠性分析中，以期从训练模型的特定实例得出推理结论, 而非去除噪声。我们展示如何使用线性混合效应模型（LMEM）来分析性能评估分数，并用广义似然比检验进行统计推断。我们的方法提供了一种系统的方式来考虑算法和数据相关的噪声来源，并使我们能够量化各个方差来源对机器学习实验的可靠性和可复制性的影响。我们在一系列合成和真实数据集上演示了我们方法的实用性，并说明了我们的方法如何促进对机器学习算法行为的更全面理解。

    Reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized lik
    
[^118]: 高效图场积分器在点云中的应用

    Efficient Graph Field Integrators Meet Point Clouds. (arXiv:2302.00942v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00942](http://arxiv.org/abs/2302.00942)

    本文提出了两种算法用于非欧几里得空间中的高效图场积分，适用于点云网格图或ε-最近邻图的表征方法，具有很强的实用性。

    

    文章提出了两种新的算法类别，用于对编码点云的图形进行高效场积分。第一类算法使用点云网格图的有界亏格，第二类算法则使用点云的流行的ε-最近邻图表示方法。两种算法都可以被看作 Fast Multipole Methods(FMMs) 的可行替代，但适用于非欧几里得空间。文章重点研究基于点之间步长分布（如最短路径距离）所引发的几何学。通过提供详细的理论分析，文章获得了结构图论的新结果。文章还进行了全面的实证评估，包括对刚性和可变形物体的表面插值（特别是用于网格动态建模），点云的Wasserstein距离计算以及Gromov-Wasserstein变体等。

    We present two new classes of algorithms for efficient field integration on graphs encoding point clouds. The first class, SeparatorFactorization(SF), leverages the bounded genus of point cloud mesh graphs, while the second class, RFDiffusion(RFD), uses popular epsilon-nearest-neighbor graph representations for point clouds. Both can be viewed as providing the functionality of Fast Multipole Methods (FMMs), which have had a tremendous impact on efficient integration, but for non-Euclidean spaces. We focus on geometries induced by distributions of walk lengths between points (e.g., shortest-path distance). We provide an extensive theoretical analysis of our algorithms, obtaining new results in structural graph theory as a byproduct. We also perform exhaustive empirical evaluation, including on-surface interpolation for rigid and deformable objects (particularly for mesh-dynamics modeling), Wasserstein distance computations for point clouds, and the Gromov-Wasserstein variant.
    
[^119]: 基于梯度系数变异的零样本NAS：ZiCo

    ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients. (arXiv:2301.11300v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11300](http://arxiv.org/abs/2301.11300)

    本文提出了一种基于梯度的零样本代理ZiCo，通过研究特定的梯度属性如何影响神经网络的收敛速度和泛化能力，ZiCo成为了第一个在多个NAS基准测试上一致优于朴素代理(#Params)的代理，可以显著降低寻找最佳神经结构的搜索成本。

    

    神经结构搜索(NAS)被广泛用于自动获得在大量候选结构中性能最佳的神经网络。为了缩短搜索时间，零样本NAS旨在设计可以预测给定结构的测试性能的无需训练的代理。然而，最近的研究表明，迄今为止提出的所有零样本代理都不能比朴素代理 (#Params) 一致地获得更好的效果。为了改善这种现状，本文首先阐述了一些特定的梯度属性如何影响神经网络的收敛速度和泛化能力。在此基础上，我们提出了一种新的零样本代理ZiCo，它是第一个比#Params一致更好的代理。我们证明了ZiCo在几个流行的NAS基准测试(NASBench101、NATSBench-SSS/TSS和NASBench201)上比最先进的代理效果更好，并且可以显著降低寻找最佳神经结构的搜索成本。

    Neural Architecture Search (NAS) is widely used to automatically obtain the neural network with the best performance among a large number of candidate architectures. To reduce the search time, zero-shot NAS aims at designing training-free proxies that can predict the test performance of a given architecture. However, as shown recently, none of the zero-shot proxies proposed to date can actually work consistently better than a naive proxy, namely, the number of network parameters (#Params). To improve this state of affairs, as the main theoretical contribution, we first reveal how some specific gradient properties across different samples impact the convergence rate and generalization capacity of neural networks. Based on this theoretical analysis, we propose a new zero-shot proxy, ZiCo, the first proxy that works consistently better than #Params. We demonstrate that ZiCo works better than State-Of-The-Art (SOTA) proxies on several popular NAS-Benchmarks (NASBench101, NATSBench-SSS/TSS,
    
[^120]: 具有联合嵌入预测架构的图像自监督学习

    Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture. (arXiv:2301.08243v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.08243](http://arxiv.org/abs/2301.08243)

    本论文提出了一种非生成方法的自监督学习架构，即Image-based Joint-Embedding Predictive Architecture（I-JEPA），可以生成高度语义图像表示，通过联合嵌入预测架构和掩模策略达到这一目的。

    

    本论文提出了一种在不依赖手工制作数据增强的情况下学习高度语义图像表示的方法。我们介绍了基于图像的联合嵌入预测架构（I-JEPA），这是一种从图像中进行自我监督学习的非生成方法。I-JEPA的核心设计选择是掩模策略，以引导I-JEPA产生语义表示。当与Vision Transformers结合使用时，证明I-JEPA具有高度可扩展性。

    This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting a
    
[^121]: 一种新颖的稀疏正则化方法

    A Novel Sparse Regularizer. (arXiv:2301.07285v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07285](http://arxiv.org/abs/2301.07285)

    提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。

    

    本文介绍了一种不基于 $L_{p}$-norm 的新颖正则化方法。与传统方法只考虑模型中各权重值的度量不同，这种正则化方法关注权重矩阵内权重的空间排列。该方法的加入项可以用于损失函数中，可微分，简单快速计算，与尺度无关，仅需要微小的额外内存，容易并行化。经实验证明，在相同精度水平下，该方法可以使模型参数的非零数量提高一个数量级。

    $L_{p}$-norm regularization schemes such as $L_{0}$, $L_{1}$, and $L_{2}$-norm regularization and $L_{p}$-norm-based regularization techniques such as weight decay and group LASSO compute a quantity which de pends on model weights considered in isolation from one another. This paper describes a novel regularizer which is not based on an $L_{p}$-norm. In contrast with $L_{p}$-norm-based regularization, this regularizer is concerned with the spatial arrangement of weights within a weight matrix. This regularizer is an additive term for the loss function and is differentiable, simple and fast to compute, scale-invariant, requires a trivial amount of additional memory, and can easily be parallelized. Empirically this method yields approximately a one order-of-magnitude improvement in the number of nonzero model parameters at a given level of accuracy.
    
[^122]: 使用差分隐私和安全聚合的联邦学习的个体数据点重构

    Reconstructing Individual Data Points in Federated Learning Hardened with Differential Privacy and Secure Aggregation. (arXiv:2301.04017v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2301.04017](http://arxiv.org/abs/2301.04017)

    本文研究了在联邦学习被差分隐私和安全聚合保护的情况下，恶意服务器可以通过引入 Sybil 设备来重构用户数据的问题，揭示了其中的权力不平衡。

    

    联邦学习是一种让用户联合训练机器学习模型的框架，并被宣传为一种提供数据最小化的隐私增强技术（PET）。 先前的工作表明，在普通的联邦学习中，恶意服务器可以从模型更新中提取用户的私有数据。 本文进一步证明，在有防护措施的协议中，恶意服务器甚至可以重构用户数据。作者们提出了一种针对使用分布式差分隐私（DDP）和安全聚合（SA）保护的联邦学习的攻击方法。攻击方法基于引入违反协议的Sybil设备，以揭示个人用户的数据，以供服务器重构。导致此漏洞的根本原因是权力不平衡：服务器协调整个协议。

    Federated learning (FL) is a framework for users to jointly train a machine learning model. FL is promoted as a privacy-enhancing technology (PET) that provides data minimization: data never "leaves" personal devices and users share only model updates with a server (e.g., a company) coordinating the distributed training. While prior work showed that in vanilla FL a malicious server can extract users' private data from the model updates, in this work we take it further and demonstrate that a malicious server can reconstruct user data even in hardened versions of the protocol. More precisely, we propose an attack against FL protected with distributed differential privacy (DDP) and secure aggregation (SA). Our attack method is based on the introduction of sybil devices that deviate from the protocol to expose individual users' data for reconstruction by the server. The underlying root cause for the vulnerability to our attack is a power imbalance: the server orchestrates the whole protoco
    
[^123]: 利用神经常微分方程学习亚网格尺度模型

    Learning Subgrid-scale Models with Neural Ordinary Differential Equations. (arXiv:2212.09967v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2212.09967](http://arxiv.org/abs/2212.09967)

    本文提出了利用神经常微分方程学习亚网格尺度模型的新方法，可以提高计算流体动力学求解器的准确性和效率。该方法具有NODE优点，可以参数化亚网格尺度、近似耦合算子，并提高低阶求解器的效率。

    

    我们提出了一种新方法来学习偏微分方程(PDEs)的亚网格尺度模型。该方法基于神经常微分方程(NODE)来解决计算上的挑战，可以使用神经网络来学习从粗网格到细网格的映射，从而实现亚网格尺度参数化。我们提出了一种策略，利用NODE和部分知识来在连续级别上学习源动力学。该方法继承了NODE的优点，可以用于参数化亚网格尺度、近似耦合算子，并提高低阶求解器的效率。数值结果表明了我们方法的有效性。

    We propose a new approach to learning the subgrid-scale model when simulating partial differential equations (PDEs) solved by the method of lines and their representation in chaotic ordinary differential equations, based on neural ordinary differential equations (NODEs). Solving systems with fine temporal and spatial grid scales is an ongoing computational challenge, and closure models are generally difficult to tune. Machine learning approaches have increased the accuracy and efficiency of computational fluid dynamics solvers. In this approach neural networks are used to learn the coarse- to fine-grid map, which can be viewed as subgrid-scale parameterization. We propose a strategy that uses the NODE and partial knowledge to learn the source dynamics at a continuous level. Our method inherits the advantages of NODEs and can be used to parameterize subgrid scales, approximate coupling operators, and improve the efficiency of low-order solvers. Numerical results with the two-scale Loren
    
[^124]: 医疗人工智能模型非均一标签的协同训练

    Collaborative Training of Medical Artificial Intelligence Models with non-uniform Labels. (arXiv:2211.13606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.13606](http://arxiv.org/abs/2211.13606)

    本研究提出了一种灵活的联合学习方法(FFL)，可以协同训练异质化标注数据集来构建强大而稳健的深度学习模型，为不同机构间的广泛合作提供了一种有前途的替代方案。

    

    近年来，深度学习已经成为医学图像分析领域的主流手段。然而，构建强大而稳健的深度学习模型需要使用大规模多方数据集进行训练。虽然多个利益相关者已经提供了公开的数据集，但是这些数据的标签方式差异很大。为了解决这一问题，本文提出了一种灵活的联合学习方法：灵活联合学习(FFL)。通过对来自全球五个机构的695,000个具有不同标签的胸部透视图进行协同训练，我们证明了在异质化标注数据集情况下使用FFL可以比传统的联邦学习获得更好的性能，并提供了在机构之间进行广泛协作的一种有前途的替代方法。

    Due to the rapid advancements in recent years, medical image analysis is largely dominated by deep learning (DL). However, building powerful and robust DL models requires training with large multi-party datasets. While multiple stakeholders have provided publicly available datasets, the ways in which these data are labeled vary widely. For Instance, an institution might provide a dataset of chest radiographs containing labels denoting the presence of pneumonia, while another institution might have a focus on determining the presence of metastases in the lung. Training a single AI model utilizing all these data is not feasible with conventional federated learning (FL). This prompts us to propose an extension to the widespread FL process, namely flexible federated learning (FFL) for collaborative training on such data. Using 695,000 chest radiographs from five institutions from across the globe each with differing labels - we demonstrate that having heterogeneously labeled datasets, FF
    
[^125]: 从节点交互到跳跃交互：新的高效可扩展的图学习范式

    From Node Interaction to Hop Interaction: New Effective and Scalable Graph Learning Paradigm. (arXiv:2211.11761v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11761](http://arxiv.org/abs/2211.11761)

    本文提出了一种新的跳跃交互范式，用于解决现有图神经网络（GNN）中存在的可扩展性限制和过度平滑问题。其核心思想是将节点之间的交互目标转换为节点内部经过预处理的多跳特征，并通过HopGNN框架实现跳跃交互。

    

    存在的图神经网络（GNN）遵循迭代地在节点之间进行信息交互的信息传递机制。然而，这种节点交互范式仍存在可扩展性限制，即在快速扩展的邻居之间进行节点交互会产生高计算和内存开销；以及过度平滑问题，即节点的判别能力受限，重复节点交互后不同类别节点的表示将会收敛到无法区分的状态。本文提出了一种新的跳跃交互范式，以同时解决这些限制。其核心思想是将节点之间的交互目标转换为节点内部经过预处理的多跳特征。我们设计了一个简单而有效的 HopGNN 框架，可以轻松地利用现有的GNN实现跳跃交往。

    Existing Graph Neural Networks (GNNs) follow the message-passing mechanism that conducts information interaction among nodes iteratively. While considerable progress has been made, such node interaction paradigms still have the following limitation. First, the scalability limitation precludes the broad application of GNNs in large-scale industrial settings since the node interaction among rapidly expanding neighbors incurs high computation and memory costs. Second, the over-smoothing problem restricts the discrimination ability of nodes, i.e., node representations of different classes will converge to indistinguishable after repeated node interactions. In this work, we propose a novel hop interaction paradigm to address these limitations simultaneously. The core idea is to convert the interaction target among nodes to pre-processed multi-hop features inside each node. We design a simple yet effective HopGNN framework that can easily utilize existing GNNs to achieve hop interaction. Fur
    
[^126]: 令牌图灵机

    Token Turing Machines. (arXiv:2211.09119v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09119](http://arxiv.org/abs/2211.09119)

    令牌图灵机是一种序列自回归Transformer模型，具有的外部存储器可以总结先前的历史并以有限的计算成本处理长序列，相比其他替代方法在序列视觉理解任务中表现更优。

    

    我们提出了令牌图灵机（TTM），它是一种带有存储器的序列自回归Transformer模型，用于实际世界的序列视觉理解。我们的模型受到 Neural Turing Machine 的启发，并具有由一组令牌组成的外部存储器，用于总结先前的历史（即帧）。该存储器使用Transformer作为每个步骤的处理单元/控制器进行高效地址寻找、读取和写入。模型的存储器模块确保新的观察结果仅使用存储器的内容（而不是整个历史记录）进行处理，这意味着它可以以有限的计算成本每步高效处理长序列。我们展示了TTM在两个真实世界的序列视觉理解任务上（在线时间活动检测和基于视觉的机器人行动策略学习）表现优于其他替代方法，例如为长序列设计的其他Transformer模型和递归神经网络。

    We propose Token Turing Machines (TTM), a sequential, autoregressive Transformer model with memory for real-world sequential visual understanding. Our model is inspired by the seminal Neural Turing Machine, and has an external memory consisting of a set of tokens which summarise the previous history (i.e., frames). This memory is efficiently addressed, read and written using a Transformer as the processing unit/controller at each step. The model's memory module ensures that a new observation will only be processed with the contents of the memory (and not the entire history), meaning that it can efficiently process long sequences with a bounded computational cost at each step. We show that TTM outperforms other alternatives, such as other Transformer models designed for long sequences and recurrent neural networks, on two real-world sequential visual understanding tasks: online temporal activity detection from videos and vision-based robot action policy learning.  Code is publicly avail
    
[^127]: 基于卷积神经网络的量子相似性检测

    Quantum Similarity Testing with Convolutional Neural Networks. (arXiv:2211.01668v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.01668](http://arxiv.org/abs/2211.01668)

    本文提出了一种基于卷积神经网络的机器学习算法，通过测量数据构建量子态的低维表示进行相似性评估，可以对非高斯量子态进行相似性检测，并在准确性和效率方面优于以往方法。

    

    检测两个未经特征化的量子设备是否以相同方式运作对于基准测试近期量子计算机和量子模拟器至关重要，但至今为止，在连续变量量子系统中，存在一些未解决问题。在本文中，我们开发了一种机器学习算法，使用有限且嘈杂的数据比较未知的连续变量态。算法适用于非高斯量子态，而此前的技术无法实现相似性检测。我们的方法基于一个卷积神经网络，根据测量数据构建一个低维态表示来评估量子态的相似性。网络可以进行离线训练，使用具有与待测试态相似结构的一组基准态的经典模拟数据，或使用对基准态的测量所生成的实验数据，或使用模拟和实验数据的组合。我们通过比较非高斯压缩相干态来测试算法的性能，并证明它在准确性和效率方面均优于先前的方法。

    The task of testing whether two uncharacterized quantum devices behave in the same way is crucial for benchmarking near-term quantum computers and quantum simulators, but has so far remained open for continuous-variable quantum systems. In this Letter, we develop a machine learning algorithm for comparing unknown continuous variable states using limited and noisy data. The algorithm works on non-Gaussian quantum states for which similarity testing could not be achieved with previous techniques. Our approach is based on a convolutional neural network that assesses the similarity of quantum states based on a lower-dimensional state representation built from measurement data. The network can be trained offline with classically simulated data from a fiducial set of states sharing structural similarities with the states to be tested, or with experimental data generated by measurements on the fiducial states, or with a combination of simulated and experimental data. We test the performance o
    
[^128]: 一种连续博弈混合纳什均衡的指数收敛粒子方法

    An Exponentially Converging Particle Method for the Mixed Nash Equilibrium of Continuous Games. (arXiv:2211.01280v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.01280](http://arxiv.org/abs/2211.01280)

    本文提出并分析了一种基于粒子的方法，用于计算具有连续纯策略集和对收益函数的一阶访问的两人零和博弈的混合纳什均衡问题，并在满足假设的情况下从任何初始化指数收敛于准确的解。

    

    本文考虑解决具有连续纯策略集和对收益函数的一阶访问的两人零和博弈的混合纳什均衡计算问题。该问题在以博弈理论为灵感的机器学习应用中出现，如分布式稳健学习。在这些应用中，策略集是高维的，因此基于离散化的方法不能返回高精度的解。本文引入并分析了一种基于粒子的方法，该方法针对此问题具有保证的局部收敛性。该方法将混合策略参数化为原子测度，并对原子的权重和位置应用近端点更新。它可以被解释为“相互作用”Wasserstein-Fisher-Rao梯度流的时间隐式离散化。我们证明，在非退化的假设下，该方法从任何初始化以指数速度收敛于准确的混合纳什均衡，并提供数值实验来说明该方法的实际性能。

    We consider the problem of computing mixed Nash equilibria of two-player zero-sum games with continuous sets of pure strategies and with first-order access to the payoff function. This problem arises for example in game-theory-inspired machine learning applications, such as distributionally-robust learning. In those applications, the strategy sets are high-dimensional and thus methods based on discretisation cannot tractably return high-accuracy solutions.  In this paper, we introduce and analyze a particle-based method that enjoys guaranteed local convergence for this problem. This method consists in parametrizing the mixed strategies as atomic measures and applying proximal point updates to both the atoms' weights and positions. It can be interpreted as a time-implicit discretization of the "interacting" Wasserstein-Fisher-Rao gradient flow.  We prove that, under non-degeneracy assumptions, this method converges at an exponential rate to the exact mixed Nash equilibrium from any init
    
[^129]: 基于数据幻象的迭代式教学

    Iterative Teaching by Data Hallucination. (arXiv:2210.17467v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17467](http://arxiv.org/abs/2210.17467)

    本文提出了基于数据幻象教学（DHT）的迭代式教学方法，解决了在连续输入空间下教师提供示例的能力问题，并在多个挑战性的教学设置中验证了DHT的有效性。

    

    本文研究了在连续输入空间下迭代教学的问题，即教师根据学习者的状态和目标概念提供示例。我们提出了数据幻象教学（DHT）方法，在有限的样本空间内，通过智能地生成输入数据，解决了教师提供示例的能力问题。我们考虑了许多挑战性的教学设置，并进行了广泛的实证研究，验证了DHT的有效性。

    We consider the problem of iterative machine teaching, where a teacher sequentially provides examples based on the status of a learner under a discrete input space (i.e., a pool of finite samples), which greatly limits the teacher's capability. To address this issue, we study iterative teaching under a continuous input space where the input example (i.e., image) can be either generated by solving an optimization problem or drawn directly from a continuous distribution. Specifically, we propose data hallucination teaching (DHT) where the teacher can generate input data intelligently based on labels, the learner's status and the target concept. We study a number of challenging teaching setups (e.g., linear/neural learners in omniscient and black-box settings). Extensive empirical results verify the effectiveness of DHT.
    
[^130]: 基于多模态融合的自监督预测编码用于精细时间分辨率下的病人恶化预测

    Self-Supervised Predictive Coding with Multimodal Fusion for Patient Deterioration Prediction in Fine-grained Time Resolution. (arXiv:2210.16598v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16598](http://arxiv.org/abs/2210.16598)

    本研究提出了一种基于自监督预测编码和多模态融合的每小时病人恶化预测方法，以提高精细的时间分辨率下的预测准确性。在多项实验中，我们证明了该方法可以显著提高性能，尤其是针对远期预测任务。

    

    在紧急情况下，精确地预测病人的关键事件发生时间至关重要，而许多使用电子病历(EHR)的自动预测方法由于时间分辨率过粗，限制了它们在急诊科和重症监护室等紧急环境中的实际应用。因此，在本研究中，我们提出了一种基于自监督预测编码和多模态融合的每小时预测方法，用于两个关键任务：死亡率和血管升压药需求预测。通过大量实验，我们证明了多模态融合和自监督预测正则化对性能的显著提升，尤其是在远期预测方面，在实践中变得尤为重要。我们的单模态/双模态/双模态自监督在死亡率(远期死亡率)方面得分分别为0.846/0.877/0.897 (0.824/0.855/0.886)，在血管升压药需求预测方面得分分别为0.817/0.820/0.858 (0.807/0.81/0.855)。

    Accurate time prediction of patients' critical events is crucial in urgent scenarios where timely decision-making is important. Though many studies have proposed automatic prediction methods using Electronic Health Records (EHR), their coarse-grained time resolutions limit their practical usage in urgent environments such as the emergency department (ED) and intensive care unit (ICU). Therefore, in this study, we propose an hourly prediction method based on self-supervised predictive coding and multi-modal fusion for two critical tasks: mortality and vasopressor need prediction. Through extensive experiments, we prove significant performance gains from both multi-modal fusion and self-supervised predictive regularization, most notably in far-future prediction, which becomes especially important in practice. Our uni-modal/bi-modal/bi-modal self-supervision scored 0.846/0.877/0.897 (0.824/0.855/0.886) and 0.817/0.820/0.858 (0.807/0.81/0.855) with mortality (far-future mortality) and with
    
[^131]: 处理算法（误）信息分类中的偶然性：走向负责任的机器学习议程

    Addressing contingency in algorithmic (mis)information classification: Toward a responsible machine learning agenda. (arXiv:2210.09014v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2210.09014](http://arxiv.org/abs/2210.09014)

    本文重点讨论了机器学习（ML）启用的分类模型处理在线虚假信息和其他可能被识别为有害的内容时，对“真相”来源的合法性、权威性和客观性所采取的立场以及ML驱动的审查系统可能在不利影响方面产生的问题，分析了算法的偶然性和可能引起的评估误差。

    

    机器学习（ML）启用的分类模型越来越受欢迎，用于解决庞大且速度快的在线虚假信息和其他可能被识别为有害的内容。在构建这些模型时，数据科学家需要对用于模型训练和测试的“真相”来源的合法性、权威性和客观性采取立场。这涉及政治、伦理和认识论方面的问题，其在技术论文中很少得到解决。尽管（也就是由于）其报告的高准确性和性能，由ML驱动的审查系统可能会塑造在线公共辩论，并产生负面影响，如不当审查和强化错误信念。我们采用合作的民族志学和社会科学和专业知识的理论洞见，对建立（误）信息分类的ML模型的过程进行了批判性分析，以识别一系列算法的偶然性——关键的模型决策点，这些决策点可能会在技术实现中引入自己的诠释和评估。

    Machine learning (ML) enabled classification models are becoming increasingly popular for tackling the sheer volume and speed of online misinformation and other content that could be identified as harmful. In building these models, data scientists need to take a stance on the legitimacy, authoritativeness and objectivity of the sources of ``truth" used for model training and testing. This has political, ethical and epistemic implications which are rarely addressed in technical papers. Despite (and due to) their reported high accuracy and performance, ML-driven moderation systems have the potential to shape online public debate and create downstream negative impacts such as undue censorship and the reinforcing of false beliefs. Using collaborative ethnography and theoretical insights from social studies of science and expertise, we offer a critical analysis of the process of building ML models for (mis)information classification: we identify a series of algorithmic contingencies--key mo
    
[^132]: SQA3D：三维场景中的情境问答

    SQA3D: Situated Question Answering in 3D Scenes. (arXiv:2210.07474v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07474](http://arxiv.org/abs/2210.07474)

    本文提出了一个新的任务，即评估具有场景理解能力的代理人在三维场景中的情境问答。基于650个场景的数据集为智能代理人的推理能力考察提供了广泛且大量的问题，这对当前的多模式，特别是3D推理模型提出了很大挑战。

    

    我们提出了一个新的任务来评估具有场景理解能力的代理人：三维场景中的情境问答（SQA3D）。给定一个场景上下文（例如三维扫描），SQA3D要求经过测试的代理人首先理解其在文本描述下的3D场景中的情境（位置、方向等），然后在该情境下进行推理，回答一个问题。基于来自ScanNet的650个场景，我们提供了一个数据集，其中心围绕6.8k个唯一情境，20.4k的描述和33.4k多样的推理问题。这些问题涵盖了对智能代理人范围广泛的推理能力的考察，从空间关系理解到常识理解、导航和多跳推理。SQA3D对当前的多模式尤其是3D推理模型提出了重大挑战。我们评估了各种最先进的方法，并发现最佳结果仅达到了47.20%的总体得分，而业余水平的表现更为糟糕。

    We propose a new task to benchmark scene understanding of embodied agents: Situated Question Answering in 3D Scenes (SQA3D). Given a scene context (e.g., 3D scan), SQA3D requires the tested agent to first understand its situation (position, orientation, etc.) in the 3D scene as described by text, then reason about its surrounding environment and answer a question under that situation. Based upon 650 scenes from ScanNet, we provide a dataset centered around 6.8k unique situations, along with 20.4k descriptions and 33.4k diverse reasoning questions for these situations. These questions examine a wide spectrum of reasoning capabilities for an intelligent agent, ranging from spatial relation comprehension to commonsense understanding, navigation, and multi-hop reasoning. SQA3D imposes a significant challenge to current multi-modal especially 3D reasoning models. We evaluate various state-of-the-art approaches and find that the best one only achieves an overall score of 47.20%, while amateu
    
[^133]: 关于引导式扩散模型的蒸馏

    On Distillation of Guided Diffusion Models. (arXiv:2210.03142v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.03142](http://arxiv.org/abs/2210.03142)

    本论文提出了一种将免分类器的引导式扩散模型蒸馏为易于采样的模型的方法，以降低在推断时的计算成本，并且能够在像素空间生成高质量的图像。

    

    最近，免分类器的引导式扩散模型已被证明在高分辨率图像生成方面非常有效，它们已广泛用于包括 DALLE-2、Stable Diffusion 和 Imagen 在内的大规模扩散框架中。然而，免分类器的引导式扩散模型的缺点是，在推断时计算成本很高，因为需要评估两个扩散模型（一个类有条件的模型和一个无条件的模型）数十到数百次。为了解决这个限制，我们提出了一种将免分类器的引导式扩散模型蒸馏为易于采样的模型的方法: 给定一个经过预训练的免分类器引导模型，我们首先学习一个单一的模型以匹配联合有条件和无条件模型的输出，然后逐步将该模型蒸馏到只需要更少的采样步骤的扩散模型。对于在像素空间训练的标准扩散模型，我们的方法能够生成高质量的图像。

    Classifier-free guided diffusion models have recently been shown to be highly effective at high-resolution image generation, and they have been widely used in large-scale diffusion frameworks including DALLE-2, Stable Diffusion and Imagen. However, a downside of classifier-free guided diffusion models is that they are computationally expensive at inference time since they require evaluating two diffusion models, a class-conditional model and an unconditional model, tens to hundreds of times. To deal with this limitation, we propose an approach to distilling classifier-free guided diffusion models into models that are fast to sample from: Given a pre-trained classifier-free guided model, we first learn a single model to match the output of the combined conditional and unconditional models, and then we progressively distill that model to a diffusion model that requires much fewer sampling steps. For standard diffusion models trained on the pixel-space, our approach is able to generate im
    
[^134]: 关于随机傅里叶特征相对误差保持核距离的研究

    On The Relative Error of Random Fourier Features for Preserving Kernel Distance. (arXiv:2210.00244v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00244](http://arxiv.org/abs/2210.00244)

    研究发现，对于大多数核，包括著名的拉普拉斯核，RFF不能使用低维近似核距离并保持小的相对误差。当核是解析的时候，RFF可以使用多项式维度实现$\epsilon$-相对误差，并且在特定应用中，维度边界得到了改进。

    

    随机傅里叶特征（RFF）是一种强大的技术，针对平移不变核，在（高维）核空间中找到点的近似低维表示。尽管在各种误差保证概念下分析了RFF，但以“相对误差”保持核距离的能力较少被理解。我们发现，在包括著名的拉普拉斯核在内的大多数核范围内，RFF不能使用低维近似核距离并保持小的相对误差。当平移不变核是“解析”的时候，RFF可以使用$\mathrm{poly}(\epsilon^{-1}\log n)$维度来实现对于$n$点的配对核距离的$\epsilon$-相对误差，并且在对于特定的“核$k$-means”的应用中，维度边界得到了改进，变为$\mathrm{poly}(\epsilon^{-1}\log k)$。最后，我们超越了RFF，迈出了第一步。

    The method of random Fourier features (RFF), proposed in a seminal paper by Rahimi and Recht (NIPS'07), is a powerful technique to find approximate low-dimensional representations of points in (high-dimensional) kernel space, for shift-invariant kernels. While RFF has been analyzed under various notions of error guarantee, the ability to preserve the kernel distance with \emph{relative} error is less understood. We show that for a significant range of kernels, including the well-known Laplacian kernels, RFF cannot approximate the kernel distance with small relative error using low dimensions. We complement this by showing as long as the shift-invariant kernel is analytic, RFF with $\mathrm{poly}(\epsilon^{-1} \log n)$ dimensions achieves $\epsilon$-relative error for pairwise kernel distance of $n$ points, and the dimension bound is improved to $\mathrm{poly}(\epsilon^{-1}\log k)$ for the specific application of kernel $k$-means. Finally, going beyond RFF, we make the first step toward
    
[^135]: PiFold: 实现高效和有效的蛋白质逆向折叠

    PiFold: Toward effective and efficient protein inverse folding. (arXiv:2209.12643v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.12643](http://arxiv.org/abs/2209.12643)

    PiFold 提出了一种新的残基特征提取器和 PiGNN 层，能够一次性生成蛋白质序列并提高恢复效果，在 CATH 4.2 上达到了 51.66% 的恢复率，推理速度比自回归竞争对手快 70 倍，在 TS50 和 TS500 上分别达到了 58.72% 和 60.42% 的恢复分数。

    

    如何高效而有效地设计能够折叠成所需结构的蛋白序列？近年来，基于结构的蛋白质设计的AI方法已经引起了越来越多的关注；然而，由于特征表达不够充分和自回归序列解码器的缺乏，很少有方法能够同时提高准确性和效率。为了解决这些问题，我们提出了PiFold，它包含了一种新的残基特征提取器和PiGNN层，以一次性生成蛋白质序列并提高恢复效果。实验表明，PiFold 在 CATH 4.2 上能够达到 51.66\% 的恢复率，而推理速度比自回归竞争对手快 70 倍。此外，PiFold 在 TS50 和 TS500 上分别达到了 58.72\% 和 60.42\% 的恢复分数。我们进行了全面的消融研究，揭示了不同类型蛋白质特征和模型设计的作用，为进一步简化和改进提供了灵感。PyTorch 代码可在 \href{https://github.com/idea-iitp/PiFold}{https://github.com/idea-iitp/PiFold} 上获取。

    How can we design protein sequences folding into the desired structures effectively and efficiently? AI methods for structure-based protein design have attracted increasing attention in recent years; however, few methods can simultaneously improve the accuracy and efficiency due to the lack of expressive features and autoregressive sequence decoder. To address these issues, we propose PiFold, which contains a novel residue featurizer and PiGNN layers to generate protein sequences in a one-shot way with improved recovery. Experiments show that PiFold could achieve 51.66\% recovery on CATH 4.2, while the inference speed is 70 times faster than the autoregressive competitors. In addition, PiFold achieves 58.72\% and 60.42\% recovery scores on TS50 and TS500, respectively. We conduct comprehensive ablation studies to reveal the role of different types of protein features and model designs, inspiring further simplification and improvement. The PyTorch code is available at \href{https://gith
    
[^136]: 基于KL散度的离散时间模型深度学习

    KL-divergence Based Deep Learning for Discrete Time Model. (arXiv:2208.05100v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.05100](http://arxiv.org/abs/2208.05100)

    该论文提出了一种基于KL散度的深度学习程序，用于解决生存分析中短数据问题，通过将外部生存预测模型与新收集的时间至事件数据相结合来获得更好的性能和鲁棒性。

    

    神经网络（深度学习）是人工智能中的现代模型，并已被利用于生存分析中。尽管之前的研究已经展示了一些改进，但训练出一个优秀的深度学习模型需要大量的数据，在实践中可能并不存在。为了解决这个挑战，我们开发了一种基于Kullback-Leibler（KL）的深度学习程序，将外部生存预测模型与新收集的时间至事件数据相结合。利用时间相关的KL区分信息来衡量外部数据和内部数据之间的差异。这是第一个考虑使用先前信息来处理深度学习中的短数据问题的工作。模拟和实际数据结果表明，与之前的工作相比，所提出的模型具有更好的性能和更高的鲁棒性。

    Neural Network (Deep Learning) is a modern model in Artificial Intelligence and it has been exploited in Survival Analysis. Although several improvements have been shown by previous works, training an excellent deep learning model requires a huge amount of data, which may not hold in practice. To address this challenge, we develop a Kullback-Leibler-based (KL) deep learning procedure to integrate external survival prediction models with newly collected time-to-event data. Time-dependent KL discrimination information is utilized to measure the discrepancy between the external and internal data. This is the first work considering using prior information to deal with short data problem in Survival Analysis for deep learning. Simulation and real data results show that the proposed model achieves better performance and higher robustness compared with previous works.
    
[^137]: 基于深度学习的部分可观察下网络动态系统的图形恢复方法

    Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach. (arXiv:2208.04405v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04405](http://arxiv.org/abs/2208.04405)

    这篇论文介绍了一种基于深度学习的方法，通过对观察到的时间序列数据进行特征向量计算，实现了部分可观察下的网络动态系统的图形恢复，因果推断机制优于最先进的同类机制，并且有很好的泛化性能。

    

    本研究研究了图形结构识别问题，即恢复时间序列的依存关系图。我们将这些时间序列数据建模为线性随机网络动态系统状态的组成部分。我们假设部分可观察性，仅观测到包含网络的子集的状态演化。我们设计了一种新的特征向量，从观察到的时间序列计算出，并证明这些特征是线性可分的，即存在一个超平面，可以将与连接节点配对的特征群与与未连接配对的特征群分开。这使得这些特征适合训练各种分类器来执行因果推断。特别地，我们使用这些特征来训练卷积神经网络(CNNs)。由此得到的因果推断机制在样本复杂度方面优于最先进的同类推断机制。训练的CNNs在结构上不同的网络中具有很好的泛化性。

    We study the problem of graph structure identification, i.e., of recovering the graph of dependencies among time series. We model these time series data as components of the state of linear stochastic networked dynamical systems. We assume partial observability, where the state evolution of only a subset of nodes comprising the network is observed. We devise a new feature vector computed from the observed time series and prove that these features are linearly separable, i.e., there exists a hyperplane that separates the cluster of features associated with connected pairs of nodes from those associated with disconnected pairs. This renders the features amenable to train a variety of classifiers to perform causal inference. In particular, we use these features to train Convolutional Neural Networks (CNNs). The resulting causal inference mechanism outperforms state-of-the-art counterparts w.r.t. sample-complexity. The trained CNNs generalize well over structurally distinct networks (dense
    
[^138]: 非线性系统的模型缩减：通过平衡状态和梯度协方差的截断平衡方法

    Model Reduction for Nonlinear Systems by Balanced Truncation of State and Gradient Covariance. (arXiv:2207.14387v4 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2207.14387](http://arxiv.org/abs/2207.14387)

    该论文提出了协变量平衡约简方法，使用共轭选取的快照来平衡系统的状态和基于共轭的梯度协方差矩阵，以解决降阶模型中对低方差坐标敏感的问题。

    

    基于数据的降阶模型常常无法准确预测对低方差坐标敏感的高维非线性动态系统，因为这些坐标往往被截断，例如通过正交分解、核主成分分析和自编码器。这样的系统在受剪切的流体流中经常发现，非正态性在干扰增长中起着重要作用。为了解决这些问题，我们借鉴了主子空间的思想，寻找平衡的降维坐标系统，以平衡基于共轭的关于系统敏感性和状态沿轨迹方差的信息。由此产生的方法，我们称之为协变量平衡约简方法，使用共轭选取的快照来平衡系统的状态和基于共轭的梯度协方差矩阵，代替系统格拉米安矩阵，遵循同样的关键转换定律。

    Data-driven reduced-order models often fail to make accurate forecasts of high-dimensional nonlinear dynamical systems that are sensitive along coordinates with low-variance because such coordinates are often truncated, e.g., by proper orthogonal decomposition, kernel principal component analysis, and autoencoders. Such systems are encountered frequently in shear-dominated fluid flows where non-normality plays a significant role in the growth of disturbances. In order to address these issues, we employ ideas from active subspaces to find low-dimensional systems of coordinates for model reduction that balance adjoint-based information about the system's sensitivity with the variance of states along trajectories. The resulting method, which we refer to as covariance balancing reduction using adjoint snapshots (CoBRAS), is analogous to balanced truncation with state and adjoint-based gradient covariance matrices replacing the system Gramians and obeying the same key transformation laws. H
    
[^139]: 通过高阶分解理解影响最大化

    Understanding Influence Maximization via Higher-Order Decomposition. (arXiv:2207.07833v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2207.07833](http://arxiv.org/abs/2207.07833)

    本文提出了一种利用Sobol指数对种子在IM中的影响和高阶相互作用进行分析的方法，通过此方法提出了一种名为SIM的IM算法，该算法通过过度选择节点来改善当前IM算法的性能。

    

    在在线社交网络上广泛应用的影响最大化(IM)已经引起了相当大的关注。由于IM的复杂性，大多数当前的研究集中于估计节点对种子集的一阶贡献，而忽略不同种子之间的高阶相互作用。因此，实际影响传播经常偏离预期，并且种子集对这种偏差的定量贡献仍然不清楚。为了解决这个缺陷，本文利用Sobol指数(一种基于方差敏感性分析的方法)对各个种子的影响及其高阶相互作用进行了分析。为了适应IM环境，种子选择被表述为二进制变量，并分为不同阶数的分布。基于我们的各种Sobol指数分析，提出了一种IM算法SIM，通过过度选择节点改善了当前IM算法的性能。

    Given its vast application on online social networks, Influence Maximization (IM) has garnered considerable attention over the last couple of decades. Due to the intricacy of IM, most current research concentrates on estimating the first-order contribution of the nodes to select a seed set, disregarding the higher-order interplay between different seeds. Consequently, the actual influence spread frequently deviates from expectations, and it remains unclear how the seed set quantitatively contributes to this deviation. To address this deficiency, this work dissects the influence exerted on individual seeds and their higher-order interactions utilizing the Sobol index, a variance-based sensitivity analysis. To adapt to IM contexts, seed selection is phrased as binary variables and split into distributions of varying orders. Based on our analysis with various Sobol indices, an IM algorithm dubbed SIM is proposed to improve the performance of current IM algorithms by over-selecting nodes f
    
[^140]: 半监督LiDAR语义分割的LaserMix方法

    LaserMix for Semi-Supervised LiDAR Semantic Segmentation. (arXiv:2207.00026v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.00026](http://arxiv.org/abs/2207.00026)

    本文提出了一种名为LaserMix的半监督学习方法，利用LiDAR点云的强空间线索更好地利用未标记数据，具有通用性、统计基础和有效性，并在SemanticKITTI上取得了最优性能。

    

    密集标注LiDAR点云耗费巨大，限制了完全监督学习方法的可扩展性。本文研究了LiDAR分割中未被充分探索的半监督学习。我们的核心想法是利用LiDAR点云的强空间线索更好地利用未标记数据。我们提出了LaserMix方法，将来自不同LiDAR扫描的激光束混合，然后促使模型在混合前后做出一致且自信的预测。我们的框架具有三个吸引人的特点：1）通用性：LaserMix与LiDAR表示（例如，视角和体素）无关，因此我们的半监督框架可以普遍应用。2）统计基础：我们提供了详细的分析，从理论上解释了所提出框架的适用性。3）有效性：对流行的LiDAR分割数据集（nuScenes，SemanticKITTI和ScribbleKITTI）的全面实验分析证明了我们的有效性和优越性。值得注意的是，我们在SemanticKITTI上取得了显著优势的最优性能。

    Densely annotating LiDAR point clouds is costly, which restrains the scalability of fully-supervised learning methods. In this work, we study the underexplored semi-supervised learning (SSL) in LiDAR segmentation. Our core idea is to leverage the strong spatial cues of LiDAR point clouds to better exploit unlabeled data. We propose LaserMix to mix laser beams from different LiDAR scans, and then encourage the model to make consistent and confident predictions before and after mixing. Our framework has three appealing properties: 1) Generic: LaserMix is agnostic to LiDAR representations (e.g., range view and voxel), and hence our SSL framework can be universally applied. 2) Statistically grounded: We provide a detailed analysis to theoretically explain the applicability of the proposed framework. 3) Effective: Comprehensive experimental analysis on popular LiDAR segmentation datasets (nuScenes, SemanticKITTI, and ScribbleKITTI) demonstrates our effectiveness and superiority. Notably, we
    
[^141]: 带有逆热传导的生成建模

    Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v7 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.13397](http://arxiv.org/abs/2206.13397)

    该论文提出了一种新的类似扩散的模型来生成图像，它通过随机反转热方程在2D平面上运行来生成图像，并展示了与标准扩散模型不同的新颖定性性质，包括图像中整体颜色和形状的解缠绕现象。

    

    虽然扩散模型在图像生成方面取得了巨大成功，但它们的噪声反演生成过程并没有明确考虑图像的结构，例如其固有的多尺度性质。受到扩散模型和粗到细建模的实证成功的启发，我们提出了一种新的类似扩散的模型，通过随机地反转热方程在2D平面上运行来生成图像，当其运行时地局部抹去了图像的细尺度信息。我们将具有恒定加性噪声的正向热方程的解释为扩散潜在变量模型中的变分近似。我们的新模型显示出并不在标准扩散模型中看到的新颖的定性性质，例如图像中整体颜色和形状的解缠绕现象。自然图像的谱分析突出了与扩散模型的联系并揭示了其中一个隐含的粗到细归纳偏差。

    While diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. Inspired by diffusion models and the empirical success of coarse-to-fine modelling, we propose a new diffusion-like model that generates images through stochastically reversing the heat equation, a PDE that locally erases fine-scale information when run over the 2D plane of the image. We interpret the solution of the forward heat equation with constant additive noise as a variational approximation in the diffusion latent variable model. Our new model shows emergent qualitative properties not seen in standard diffusion models, such as disentanglement of overall colour and shape in images. Spectral analysis on natural images highlights connections to diffusion models and reveals an implicit coarse-to-fine inductive bias in them.
    
[^142]: 无需不可能数据的变量重要性分析方法

    Variable importance without impossible data. (arXiv:2205.15750v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15750](http://arxiv.org/abs/2205.15750)

    评估黑箱预测模型中变量重要性的流行方法不可信，因为使用了不可能的数据。本文提出一种名为Cohort Shapley的方法，它基于经济博弈理论，仅使用实际观测到的数据来量化变量重要性，可以解决算法公平性问题。

    

    目前，评估黑箱预测模型中变量重要性的最流行方法是使用人工合成的输入数据，这些数据结合了多个参与者的预测变量，这些输入数据可能是不可能的、物理上不可能的，甚至是逻辑上不可能的，由此得出的预测结果可能与黑箱训练数据有很大不同。因此，当解释决策时使用这些值时，用户不能信任预测算法的解释。我们提倡一种名为Cohort Shapley的方法，它基于经济博弈理论，与大多数其他博弈论方法不同，仅使用实际观测到的数据来量化变量重要性。Cohort Shapley通过缩小与目标对象在一个或多个特征上相似的对象组来实现。我们将其应用于一个算法公平性问题，其中必须将重要性归因于模型未经训练的受保护变量。

    The most popular methods for measuring importance of the variables in a black box prediction algorithm make use of synthetic inputs that combine predictor variables from multiple subjects. These inputs can be unlikely, physically impossible, or even logically impossible. As a result, the predictions for such cases can be based on data very unlike any the black box was trained on. We think that users cannot trust an explanation of the decision of a prediction algorithm when the explanation uses such values. Instead we advocate a method called Cohort Shapley that is grounded in economic game theory and unlike most other game theoretic methods, it uses only actually observed data to quantify variable importance. Cohort Shapley works by narrowing the cohort of subjects judged to be similar to a target subject on one or more features. We illustrate it on an algorithmic fairness problem where it is essential to attribute importance to protected variables that the model was not trained on.
    
[^143]: Bongard-HOI：基于人-物交互的几种情况视觉推理基准测试

    Bongard-HOI: Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions. (arXiv:2205.13803v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.13803](http://arxiv.org/abs/2205.13803)

    本文提出了一个新的视觉推理基准测试Bongard-HOI，它专注于从自然图像中学习人-物交互的组合性学习，挑战了现有最先进模型，鼓励开发更好的算法进行组合推理和泛化到新的HOI概念。

    

    目前，当涉及到新概念的几种情况学习和组合推理时，今天的视觉图案识别模型和人类级别的视觉认知之间仍存在巨大差距。本文引入了Bongard-HOI，这是一个新的视觉推理基准测试，侧重于从自然图像中学习人-物交互的组合性学习。它受到古典的Bongard问题（BPs）中的两个可取特征的启发：1）几种情况的概念学习和2）上下文相关的推理。我们精心策划了少样本实例包含困难的负例，其中正负图像仅在动作标签上存在差异，仅仅对对象类别的识别不足以完成我们的基准测试。我们还设计了多个测试集，以系统研究视觉学习模型的泛化能力，其中我们改变了几种情况实例的训练和测试集之间的HOI概念重叠程度，从部分到没有重叠。Bongard-HOI对现有的最先进模型提出了实质性挑战，并为开发可以进行组合推理并能够推广到新的HOI概念的新算法提供了强有力的动力。

    A significant gap remains between today's visual pattern recognition models and human-level visual cognition especially when it comes to few-shot learning and compositional reasoning of novel concepts. We introduce Bongard-HOI, a new visual reasoning benchmark that focuses on compositional learning of human-object interactions (HOIs) from natural images. It is inspired by two desirable characteristics from the classical Bongard problems (BPs): 1) few-shot concept learning, and 2) context-dependent reasoning. We carefully curate the few-shot instances with hard negatives, where positive and negative images only disagree on action labels, making mere recognition of object categories insufficient to complete our benchmarks. We also design multiple test sets to systematically study the generalization of visual learning models, where we vary the overlap of the HOI concepts between the training and test sets of few-shot instances, from partial to no overlaps. Bongard-HOI presents a substanti
    
[^144]: 关于固定维度下核岭回归的不一致性

    On the Inconsistency of Kernel Ridgeless Regression in Fixed Dimensions. (arXiv:2205.13525v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13525](http://arxiv.org/abs/2205.13525)

    在固定维度下，平移不变核的重要预测类别，如高斯核、拉普拉斯核和柯西核，在任何非零回归函数和任何带宽选择下都不具备“良性过拟合”特性。

    

    “良性过拟合”是指某些算法能够插值噪声训练数据并在样本外表现良好，已经引起了最近的相当大的关注。我们使用固定设计设置表明，具有平移不变核的重要预测类别，例如高斯核，拉普拉斯核和柯西核在固定维度下并不表现出良性过拟合。特别地，任何非零回归函数和任何（甚至是自适应的）带宽选择都不会使得估计的预测器随着样本量的增加收敛于基本真相。为了证明这些结果，我们给出了泛化误差及其在对kernel带宽的选择上产生权衡之下的近似误差和估计误差的确切表达式。

    ``Benign overfitting'', the ability of certain algorithms to interpolate noisy training data and yet perform well out-of-sample, has been a topic of considerable recent interest. We show, using a fixed design setup, that an important class of predictors, kernel machines with translation-invariant kernels, does not exhibit benign overfitting in fixed dimensions. In particular, the estimated predictor does not converge to the ground truth with increasing sample size, for any non-zero regression function and any (even adaptive) bandwidth selection. To prove these results, we give exact expressions for the generalization error, and its decomposition in terms of an approximation error and an estimation error that elicits a trade-off based on the selection of the kernel bandwidth. Our results apply to commonly used translation-invariant kernels such as Gaussian, Laplace, and Cauchy.
    
[^145]: 具有可证明的一致性和公平保证的推荐系统张量补全

    Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems. (arXiv:2204.01815v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2204.01815](http://arxiv.org/abs/2204.01815)

    本文介绍了一种新的一致性方法来解决矩阵和张量补全问题，在推荐系统应用中，我们证明了通过保留单位比例和一致性两个约束条件可以实现解的存在性与唯一性。

    

    我们引入了一种新的基于一致性的方法来定义和解决非负/正矩阵和张量补全问题。该框架的新颖之处在于，我们不是人为地将问题形式化为任意优化问题，例如，最小化一个结构量，如秩或范数，而是展示了一个单一的属性/约束：保留单位比例一致性，保证了解的存在，并在相对较弱的支持假设下保证了解的唯一性。该框架和解算法也直接推广到任意维度的张量中，同时保持了固定维度 d 的问题规模的线性计算复杂性。在推荐系统应用中，我们证明了两个合理的性质，这些性质应该适用于任何 RS 问题的解，足以允许在我们的框架内建立唯一性保证。关键理论贡献是展示了这些约束下解的存在性与唯一性。

    We introduce a new consistency-based approach for defining and solving nonnegative/positive matrix and tensor completion problems. The novelty of the framework is that instead of artificially making the problem well-posed in the form of an application-arbitrary optimization problem, e.g., minimizing a bulk structural measure such as rank or norm, we show that a single property/constraint: preserving unit-scale consistency, guarantees the existence of both a solution and, under relatively weak support assumptions, uniqueness. The framework and solution algorithms also generalize directly to tensors of arbitrary dimensions while maintaining computational complexity that is linear in problem size for fixed dimension d. In the context of recommender system (RS) applications, we prove that two reasonable properties that should be expected to hold for any solution to the RS problem are sufficient to permit uniqueness guarantees to be established within our framework. Key theoretical contribu
    
[^146]: 持续学习机器人技能的示教方法

    Continual Learning from Demonstration of Robotics Skills. (arXiv:2202.06843v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2202.06843](http://arxiv.org/abs/2202.06843)

    该论文提出了一种持续学习示教方法，使用超网络和神经常微分方程求解器，可以记住长序列轨迹学习任务，而无需存储来自过去示教的任何数据。

    

    目前机器人学习运动技能的方法侧重于一次训练一个技能。然而，从示教中学习的机器人可以通过新增连续学习能力来学习新的运动技能，同时不会忘记过去学到的内容。为此，我们提出了一种使用超网络和神经常微分方程求解器进行持续的示教学习方法。我们通过实验验证了该方法在记住长序列轨迹学习任务方面的有效性，而无需存储来自过去示教的任何数据。实验结果表明，超网络在学习示教的最新技术方面优于其他现有的持续学习方法。我们在流行的LASA基准测试、我们在本文中引入的两个新的真实机器人基座演示数据集HelloWorld和RoboTasks上评估我们的方法，并在实际机器人上进行了演示。

    Methods for teaching motion skills to robots focus on training for a single skill at a time. Robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. To this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. We empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. Our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. In our experiments, we use the popular LASA benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the HelloWorld and RoboTasks datasets. We evaluate our approach on a physical robot and demonstrat
    
[^147]: GoSafeOpt: 可扩展的安全全局优化动态系统的探索

    GoSafeOpt: Scalable Safe Exploration for Global Optimization of Dynamical Systems. (arXiv:2201.09562v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.09562](http://arxiv.org/abs/2201.09562)

    GoSafeOpt是第一个能够安全探索高维系统并提供全局最优保证的算法。

    

    直接在物理系统上学习最优控制策略具有挑战性，因为即使一次失败也可能导致昂贵的硬件损坏。大多数现有的保证安全（即在探索过程中没有失败）的无模型学习方法仅局限于局部最优解。GoSafe算法是一个值得注意的例外，但不幸的是，它无法处理高维系统，因此无法应用于大多数实际的动态系统。这项工作提出了GoSafeOpt作为第一个能够安全地发现高维系统的全局最优策略并具有安全和最优性保证的算法。我们在机械臂上展示了GoSafeOpt比其他模型无关的安全学习方法更优秀，而GoSafe在该机械臂上将是禁止使用的。

    Learning optimal control policies directly on physical systems is challenging since even a single failure can lead to costly hardware damage. Most existing model-free learning methods that guarantee safety, i.e., no failures, during exploration are limited to local optima. A notable exception is the GoSafe algorithm, which, unfortunately, cannot handle high-dimensional systems and hence cannot be applied to most real-world dynamical systems. This work proposes GoSafeOpt as the first algorithm that can safely discover globally optimal policies for high-dimensional systems while giving safety and optimality guarantees. We demonstrate the superiority of GoSafeOpt over competing model-free safe learning methods on a robot arm that would be prohibitive for GoSafe.
    
[^148]: ADI: 在垂直联邦学习系统中的对抗性主导输入

    ADI: Adversarial Dominating Inputs in Vertical Federated Learning Systems. (arXiv:2201.02775v3 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2201.02775](http://arxiv.org/abs/2201.02775)

    本文研究了垂直联邦学习系统中的对抗性主导输入（ADIs），并证明了其在典型VFL系统中的存在。该研究为防止ADIs的使用提供了方法。

    

    最近，垂直联邦学习（VFL）系统作为处理分散在许多个体来源中的数据的概念而变得突出，无需将其集中化。多个参与者以隐私意识的方式协作训练基于其本地数据的模型。到目前为止，VFL已成为在组织之间安全学习模型的事实解决方案，允许共享知识而不影响任何个人的隐私。尽管VFL系统的发展昌盛，但我们发现某些参与者的输入，称为对抗性主导输入（ADIs），可以支配共同推断朝着对手的意愿方向并迫使其他（受害者）参与者做出微不足道的贡献，失去通常在联邦学习场景中提供的对其贡献重要性的奖励。我们对ADIs进行了系统研究，首先证明了它们在典型的VFL系统中的存在。然后，我们提出了基于梯度的方法

    Vertical federated learning (VFL) system has recently become prominent as a concept to process data distributed across many individual sources without the need to centralize it. Multiple participants collaboratively train models based on their local data in a privacy-aware manner. To date, VFL has become a de facto solution to securely learn a model among organizations, allowing knowledge to be shared without compromising privacy of any individuals. Despite the prosperous development of VFL systems, we find that certain inputs of a participant, named adversarial dominating inputs (ADIs), can dominate the joint inference towards the direction of the adversary's will and force other (victim) participants to make negligible contributions, losing rewards that are usually offered regarding the importance of their contributions in federated learning scenarios. We conduct a systematic study on ADIs by first proving their existence in typical VFL systems. We then propose gradient-based methods
    
[^149]: 当好奇的人放弃诚实：联邦学习不是隐私的保护者

    When the Curious Abandon Honesty: Federated Learning Is Not Private. (arXiv:2112.02918v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.02918](http://arxiv.org/abs/2112.02918)

    联邦学习被认为是隐私保护的一种手段，然而本文研究表明，即使是一个被动的、诚实但好奇的攻击者观察到梯度，也可以重构参与协议的个人用户的数据。本文提出了一种新的数据重构攻击方法，让一个主动的、不诚实的中央方从接收到的梯度中高效地提取用户数据，并在流行的FL框架上展示了其有效性。

    

    在联邦学习中，数据不会在联合训练机器学习模型时离开个人设备。相反，这些设备会共享梯度、参数或其他模型更新，并由一个中央方（例如公司）协调培训。因为数据从未“离开”个人设备，所以FL通常被认为是保护隐私的。然而，最近的研究表明，这种保护只是一个薄薄的外衣，因为即使是一个被动的，诚实但好奇的攻击者观察到梯度，也可以重构参与协议的个人用户的数据。在这项工作中，我们展示了一种新颖的数据重构攻击，可以让一个主动的，不诚实的中央方从接收到的梯度中高效地提取用户数据。虽然FL的数据重构先前的工作依赖于解决计算昂贵的优化问题或对共享模型的体系结构或参数进行容易检测的修改，但在我们的攻击中，中央方对FL协议本身进行了不引人注目的修改以实现攻击。我们在流行的FL框架上展示了我们攻击的有效性，并讨论了可能的防御措施。

    In federated learning (FL), data does not leave personal devices when they are jointly training a machine learning model. Instead, these devices share gradients, parameters, or other model updates, with a central party (e.g., a company) coordinating the training. Because data never "leaves" personal devices, FL is often presented as privacy-preserving. Yet, recently it was shown that this protection is but a thin facade, as even a passive, honest-but-curious attacker observing gradients can reconstruct data of individual users contributing to the protocol. In this work, we show a novel data reconstruction attack which allows an active and dishonest central party to efficiently extract user data from the received gradients. While prior work on data reconstruction in FL relies on solving computationally expensive optimization problems or on making easily detectable modifications to the shared model's architecture or parameters, in our attack the central party makes inconspicuous changes 
    
[^150]: 后悔最小LQR控制

    Regret-Optimal LQR Control. (arXiv:2105.01244v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2105.01244](http://arxiv.org/abs/2105.01244)

    本文提出了一种动态后悔，通过在所有有界干扰下找到最小化最坏情况下后悔的因果控制器，实现了后悔最小LQR控制。

    

    本文考虑了无限时间LQR控制问题。受在线学习竞争分析的启发，我们引入动态后悔作为控制器设计的标准。动态后悔是指因果控制器（仅具有过去干扰的访问权限）的LQR成本与已知优于其他所有控制器的唯一预知控制器（也具有未来干扰的访问权限）的LQR成本之间的差异。后悔本身是干扰的函数，我们建议找到一个能够最小化所有有界能量干扰下的最坏情况下后悔的因果控制器。得到的控制器的解释是，与能够看到未来的最佳非因果控制器相比，保证了最小的后悔。我们推导出状态空间设置的最优后悔和后悔最优控制器的显式公式。通过证明后悔最优控制问题可以归约为Nehari指数问题，得到了这些显式解。

    We consider the infinite-horizon LQR control problem. Motivated by competitive analysis in online learning, as a criterion for controller design we introduce the dynamic regret, defined as the difference between the LQR cost of a causal controller (that has only access to past disturbances) and the LQR cost of the \emph{unique} clairvoyant one (that has also access to future disturbances) that is known to dominate all other controllers. The regret itself is a function of the disturbances, and we propose to find a causal controller that minimizes the worst-case regret over all bounded energy disturbances. The resulting controller has the interpretation of guaranteeing the smallest regret compared to the best non-causal controller that can see the future. We derive explicit formulas for the optimal regret and for the regret-optimal controller for the state-space setting. These explicit solutions are obtained by showing that the regret-optimal control problem can be reduced to a Nehari ex
    
[^151]: 可证收敛的精确率-召回曲线下面积随机优化

    Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence. (arXiv:2104.08736v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.08736](http://arxiv.org/abs/2104.08736)

    本文提出了一种用于深度学习的基于平均精度的方法来优化AUPRC，提出了一种可证收敛的SOAP算法。

    

    ROC下面积（AUROC）和精确率-召回曲线下面积（AUPRC）是用于评估不平衡问题分类性能的常见指标。与AUROC相比，AUPRC是高度不平衡数据集的更合适的指标。虽然关于AUROC的随机优化已得到广泛研究，但基于原则的AUPRC的随机优化却很少探索。本文提出了一种基于最大化平均精度（AP）的技术方法来优化深度学习的AUPRC的方法。我们将目标表示为依赖组合函数之和，其中内部函数依赖于外层的随机变量。我们通过利用随机组合优化的最新进展，提出了高效的自适应和非自适应随机算法SOAP，这些算法在温和条件下具有可证收敛性保证。在图像和图形数据集上进行了广泛的实验结果。

    Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common metrics for evaluating classification performance for imbalanced problems. Compared with AUROC, AUPRC is a more appropriate metric for highly imbalanced datasets. While stochastic optimization of AUROC has been studied extensively, principled stochastic optimization of AUPRC has been rarely explored. In this work, we propose a principled technical method to optimize AUPRC for deep learning. Our approach is based on maximizing the averaged precision (AP), which is an unbiased point estimator of AUPRC. We cast the objective into a sum of {\it dependent compositional functions} with inner functions dependent on random variables of the outer level. We propose efficient adaptive and non-adaptive stochastic algorithms named SOAP with {\it provable convergence guarantee under mild conditions} by leveraging recent advances in stochastic compositional optimization. Extensive experimental results on image and graph datasets d
    
[^152]: 一种整合和分类正态分布的方法

    A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2012.14331](http://arxiv.org/abs/2012.14331)

    本文介绍了一种可以对任意参数维度下的任意域内正态分布进行积分的方法，提供了法向向量函数的相关概率密度和统计指标，同时还提供了可以对任意数量正态分布进行分类的方法和维度降低和可视化的技术。

    

    单变量和多变量正态概率分布在模拟不确定性决策中被广泛使用。计算这些模型的性能需要在特定区域内对这些分布进行积分，这在不同的模型中可以有很大的差异。除了一些特殊情况，目前不存在通用的分析表达式、标准数值方法或软件来计算这些积分。本文提供了数学结果和开源软件，可以提供以下内容：（i）任意参数维度下任意域内法向的概率，（ii）法向向量函数的概率密度、累积分布和逆累积分布，（iii）任意数量正态分布之间的分类误差、贝叶斯最优辨别指数以及其与工作特征曲线的关系，（iv）此类问题的维度降低和可视化，以及（v）对于给定数据这些方法的可靠性测试。我们通过几个具体的例子，包括金融、生物和心理学来演示这些功能。

    Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
    
[^153]: 互信息在变分分类器中的作用

    The Role of Mutual Information in Variational Classifiers. (arXiv:2010.11642v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.11642](http://arxiv.org/abs/2010.11642)

    本文研究了基于随机编码的分类器的泛化误差，并得出了泛化误差受输入特征和潜空间表示之间互信息限制的结论。

    

    过拟合是一种众所周知的现象，与生成过度拟合特定数据实例的模型有关，因此可能无法可靠地预测未来观察结果。在实践中，通过各种，有时是启发式的正则化技术控制此行为，这些技术的动机是以开发上限来泛化误差。在这项工作中，我们研究了基于在交叉熵损失上训练的随机编码的分类器的泛化误差，这在深度学习中经常用于分类问题。我们推导了泛化误差的边界，表明存在一种区域，其中泛化误差由输入特征和与编码分布随机生成的潜空间中的相应表示之间的互信息所限制。我们的边界提供了对所谓的变异级别的泛化的信息论理解。

    Overfitting data is a well-known phenomenon related with the generation of a model that mimics too closely (or exactly) a particular instance of data, and may therefore fail to predict future observations reliably. In practice, this behaviour is controlled by various--sometimes heuristics--regularization techniques, which are motivated by developing upper bounds to the generalization error. In this work, we study the generalization error of classifiers relying on stochastic encodings trained on the cross-entropy loss, which is often used in deep learning for classification problems. We derive bounds to the generalization error showing that there exists a regime where the generalization error is bounded by the mutual information between input features and the corresponding representations in the latent space, which are randomly generated according to the encoding distribution. Our bounds provide an information-theoretic understanding of generalization in the so-called class of variation
    
[^154]: 基于超图线扩展的半监督超图节点分类

    Semi-supervised Hypergraph Node Classification on Hypergraph Line Expansion. (arXiv:2005.04843v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.04843](http://arxiv.org/abs/2005.04843)

    本文提出了一种新的超图学习方法，即“线扩展(LE)”，该方法通过将顶点-超边对作为“线节点”，在超图中引出同构结构，适用于各种超图扩展并达到了显著优于SOTA的效果。

    

    先前的超图扩展仅在顶点级别或超边级别上进行，因此缺乏数据共现的对称性，导致信息损失。为了解决这个问题，本文平等对待顶点和超边，提出了一种名为\emph{线扩展(LE)}的新型超图学习方法。该方法通过将顶点-超边对作为“线节点”，在超图中双射引出一种同构结构。通过将超图减少为简单图，提出的\emph{线扩展}使得已有的图学习算法适用于高阶结构，并已被证明是各种超图扩展的统一框架。我们在五个超图数据集上评估了所提出的线扩展，结果表明我们的方法显著优于SOTA基线。

    Previous hypergraph expansions are solely carried out on either vertex level or hyperedge level, thereby missing the symmetric nature of data co-occurrence, and resulting in information loss. To address the problem, this paper treats vertices and hyperedges equally and proposes a new hypergraph formulation named the \emph{line expansion (LE)} for hypergraphs learning. The new expansion bijectively induces a homogeneous structure from the hypergraph by treating vertex-hyperedge pairs as "line nodes". By reducing the hypergraph to a simple graph, the proposed \emph{line expansion} makes existing graph learning algorithms compatible with the higher-order structure and has been proven as a unifying framework for various hypergraph expansions. We evaluate the proposed line expansion on five hypergraph datasets, the results show that our method beats SOTA baselines by a significant margin.
    

