# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions](https://rss.arxiv.org/abs/2402.01116) | 我们提出了一个层级架构，通过使用对偶交互预测和精简的MPC问题，实现了可扩展的实时模型预测控制，在复杂的多模态交通场景中展示了12倍的速度提升。 |
| [^2] | [Tuning for the Unknown: Revisiting Evaluation Strategies for Lifelong RL](https://arxiv.org/abs/2404.02113) | 提出了一种新方法来调整和评估终身强化学习代理，在此方法中，只有实验数据的一小部分可用于超参数调整，针对终身强化学习的研究进展可能被不当的经验方法所阻碍 |
| [^3] | [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/abs/2404.01413) | 本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。 |
| [^4] | [Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation](https://arxiv.org/abs/2403.16771) | 本文提出了用于鲁棒性混合代码翻译的合成数据生成和联合学习方法，包括开发了Hinglish到英语的平行语料库以及提出的能够处理噪声的联合训练模型RCMT。 |
| [^5] | [Estimating Causal Effects with Double Machine Learning -- A Method Evaluation](https://arxiv.org/abs/2403.14385) | 双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。 |
| [^6] | [Integrating Large Language Models for Severity Classification in Traffic Incident Management: A Machine Learning Approach](https://arxiv.org/abs/2403.13547) | 本研究评估了大型语言模型在交通事件管理中的应用，发现将语言模型特征与传统特征结合可以提高或匹配机器学习技术在事件严重性分类中的表现。 |
| [^7] | [Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines](https://arxiv.org/abs/2403.11585) | Linguacodus是一种创新框架，通过部署动态流水线和精细调整的大型语言模型，实现了将自然语言任务描述转换为代码的自动化过程，极大地推进了机器学习应用的发展。 |
| [^8] | [Just Say the Name: Online Continual Learning with Category Names Only via Data Generation](https://arxiv.org/abs/2403.10853) | 提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。 |
| [^9] | [Giving a Hand to Diffusion Models: a Two-Stage Approach to Improving Conditional Human Image Generation](https://arxiv.org/abs/2403.10731) | 提出了一种改进条件人类图像生成的两阶段方法，首先训练手部生成器产生手部图像和分割掩模，在第二阶段使用改进的 ControlNet 模型绘制生成手部周围的身体。 |
| [^10] | [LAB: Large-Scale Alignment for ChatBots](https://arxiv.org/abs/2403.01081) | 介绍了一种名为LAB的方法，旨在克服大型语言模型训练中的可扩展性挑战，通过分类法指导的合成数据生成和多阶段调整框架，实现了对昂贵人工标注和GPT-4等专有模型依赖较少的大规模对齐，提供了一种可扩展、具有成本效益的解决方案，不会出现灾难性遗忘情况，进一步增强了LLM的训练效率。 |
| [^11] | [Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints](https://arxiv.org/abs/2402.18012) | 使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。 |
| [^12] | [Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist](https://arxiv.org/abs/2402.18002) | 本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。 |
| [^13] | [QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations](https://arxiv.org/abs/2402.17516) | QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。 |
| [^14] | [Stick to your Role! Stability of Personal Values Expressed in Large Language Models](https://arxiv.org/abs/2402.14846) | 本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。 |
| [^15] | [Balancing Spectral, Temporal and Spatial Information for EEG-based Alzheimer's Disease Classification](https://arxiv.org/abs/2402.13523) | 通过变化每个维度的比例来调查空间信息对于脑电图阿尔茨海默病分类的重要性，结果表明空间信息比时间信息更相关，与频谱信息的相关性相同 |
| [^16] | [Universal Physics Transformers](https://arxiv.org/abs/2402.12365) | 提出了通用物理变压器（UPTs）这一新颖学习范式，能够模拟广泛的时空问题，同时适用于拉格朗日和欧拉离散化方案，有效地传播动态并允许查询潜在空间 |
| [^17] | [Tracking Changing Probabilities via Dynamic Learners](https://arxiv.org/abs/2402.10142) | 该论文介绍了通过动态学习器追踪概率变化的方法，通过输出候选项目及其概率来预测离散项目序列中下一个可能出现的项目。 |
| [^18] | [The Essential Role of Causality in Foundation World Models for Embodied AI](https://arxiv.org/abs/2402.06665) | 基于因果关系的基础世界模型对于具身人工智能的发展至关重要，当前的基础模型无法准确建模与现实世界的物理相互作用。因果关系的研究有助于构建真实世界模型，提高对可能相互作用结果的准确预测能力。 |
| [^19] | [Multiscale Modelling with Physics-informed Neural Network: from Large-scale Dynamics to Small-scale Predictions in Complex Systems](https://arxiv.org/abs/2402.05067) | 本文提出了利用物理信息神经网络进行多尺度建模的方法，通过解耦大尺度和小尺度动力学，并在正交基函数空间中近似小尺度系统。实验结果表明该方法在处理液体动力学问题以及更复杂的情况下具有较高的有效性和适用性。 |
| [^20] | [Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?](https://arxiv.org/abs/2402.03305) | 本研究通过实验探究了条件DDPMs学习生成2D球形高斯凸起的过程，在学习的过程中发现了潜在表示的关键，产生了与不同阶段对应的 qualitatively 不同的生成行为。 |
| [^21] | [An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification](https://arxiv.org/abs/2312.16043) | 本文提出了一个新的多项式参数化sigmoid函数(SIGTRON)，并且介绍了其伴随的SIC模型。相比传统的成本敏感学习模型，在给定的训练数据集接近良好平衡的条件下，所提出的SIC模型对于数据集的变化更加适应，并通过创建倾斜的超平面方程来实现。 |
| [^22] | [Underwater Acoustic Target Recognition based on Smoothness-inducing Regularization and Spectrogram-based Data Augmentation](https://arxiv.org/abs/2306.06945) | 通过平滑度诱导正则化和基于频谱图的数据增强，提高水下声学目标识别模型的泛化能力和避免性能降级的风险 |
| [^23] | [Towards a Systems Theory of Algorithms.](http://arxiv.org/abs/2401.14029) | 向算法的系统理论迈进，将算法视为开放的动态系统与其他算法、物理系统、人类或数据库交互，提供宝贵的洞见。 |
| [^24] | [Benchmarking the Fairness of Image Upsampling Methods.](http://arxiv.org/abs/2401.13555) | 这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。 |
| [^25] | [Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph.](http://arxiv.org/abs/2310.16452) | 本文提出了一个名为PEARLM的方法，通过语言建模开展基于路径的知识图谱推荐，解决了现有方法中对预训练知识图谱嵌入的依赖以及未充分利用实体和关系之间相互依赖性的问题，还避免了生成不准确的解释。实验结果表明，与现有方法相比，我们的方法效果显著。 |
| [^26] | [Contrastive Preference Learning: Learning from Human Feedback without RL.](http://arxiv.org/abs/2310.13639) | 对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。 |
| [^27] | [Effective and Efficient Federated Tree Learning on Hybrid Data.](http://arxiv.org/abs/2310.11865) | 这项研究提出了一种名为HybridTree的新方法，可以在混合数据上进行联邦树学习。通过利用树中的一致分割规则，参与方的知识可以被纳入树的较低层，从而实现高效的联邦学习。 |
| [^28] | [IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training.](http://arxiv.org/abs/2310.07355) | IMITATE是一种临床先验指导的分层视觉语言预训练模型。它利用医学报告的层级结构，从胸部X射线图像中提取多级视觉特征，并与分层医学报告中的描述性和结论性文本进行对齐。 |
| [^29] | [CacheGen: Fast Context Loading for Language Model Applications.](http://arxiv.org/abs/2310.07240) | CacheGen是一种用于语言模型应用的技术，通过对上下文进行压缩来减少LLM的网络获取和处理延迟。 |
| [^30] | [Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images.](http://arxiv.org/abs/2310.07027) | 本研究探讨了使用合成图像在医学VLP中的可行性和有效性，通过用真实医学报告生成的合成图像替换真实图像进行训练，并在图像分类、语义分割和目标检测任务中进行了实证评估。 |
| [^31] | [Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning.](http://arxiv.org/abs/2310.03718) | 这个论文提出了一种约束条件下的策略优化框架，用于训练多功能安全强化学习智能体。通过引入多功能值估计和有条件的变分推理模块，该框架在训练效率和零-shot适应能力方面表现优于基准方法。 |
| [^32] | [Heteroskedastic conformal regression.](http://arxiv.org/abs/2309.08313) | 本文研究了使用标准化和Mondrian符合规范的方法如何构建自适应的预测区间，以解决回归问题中的异方差噪声。 |
| [^33] | [Causal Inference with Differentially Private (Clustered) Outcomes.](http://arxiv.org/abs/2308.00957) | 本文提出了一种新的差分隐私机制"Cluster-DP"，它在保证隐私的同时利用数据的聚类结构，从而实现了更强的隐私保证和较低的方差，可以用于进行因果分析。 |
| [^34] | [Multi-task Learning for Radar Signal Characterisation.](http://arxiv.org/abs/2306.13105) | 本文提出一种多任务学习的方法来解决雷达信号分类和特征化的问题，引入IQST等参考架构，通过回归和分类的多重任务优化提高性能，在合成雷达数据集上展示了良好的表现，并提供了首个雷达信号特征化基准测试样例。 |
| [^35] | [Any-dimensional equivariant neural networks.](http://arxiv.org/abs/2306.06327) | 该论文提出了一个新的方法，利用代数拓扑中的表示稳定性，可以定义出一个可以以任意维度为输入的等变神经网络。这种方法使用方便，只需指定网络架构和等变性的组，且在任何训练过程中都可以使用。 |
| [^36] | [Quantum Kernel Mixtures for Probabilistic Deep Learning.](http://arxiv.org/abs/2305.18204) | 本文提出了一种量子核混合方法，可以用于表示连续和离散随机变量的联合概率分布。该框架允许构建可微分的模型，适用于密度估计、推理和采样，以及各种机器学习任务，包括生成建模和判别学习。 |
| [^37] | [FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework.](http://arxiv.org/abs/2305.01658) | FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。 |
| [^38] | [Regularized Complete Cycle Consistent GAN for Anomaly Detection.](http://arxiv.org/abs/2304.07769) | 本研究提出了RCALAD方法，通过循环一致性和新的鉴别器增强了GAN在异常检测中的效果。同时，利用补充分布引导重建和引入新的异常评分进一步提高了模型性能。 |
| [^39] | [The growclusters Package for R.](http://arxiv.org/abs/2304.06145) | R语言的growclusters软件包实现了增强版的k-means聚类算法，可以发现多组数据集中的局部聚类或分区，函数包含估计多元数据分区结构的功能，使用惩罚优化方法进行。并可创建可视化应用程序展示其操作和功能。 |
| [^40] | [Neural Operator Learning for Long-Time Integration in Dynamical Systems with Recurrent Neural Networks.](http://arxiv.org/abs/2303.02243) | 本文提出了一种将神经算子和递归神经网络相结合的新型框架，解决了深度神经网络无法准确外推和误差积累的问题，在 Korteweg-de Vries 方程中表现出更好的精度和稳定性。 |
| [^41] | [Orthonormal Expansions for Translation-Invariant Kernels.](http://arxiv.org/abs/2206.08648) | 该论文提出了一种傅里叶分析技术，用于从$\mathscr{L}_2(\mathbb{R})$的正交基中构建平移不变核函数的正交基展开，实现了马特尔核函数、柯西核函数和高斯核函数的明确展开表达式。 |
| [^42] | [An extension of McDiarmid's inequality.](http://arxiv.org/abs/1511.05240) | 本文推广了McDiarmid不等式，使其适用于具有有界差异的函数，并进一步将结果推广到一般度量空间的集中性。 |

# 详细

[^1]: 可扩展多模型MPC的基于对偶交互预测的层级架构

    Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions

    [https://rss.arxiv.org/abs/2402.01116](https://rss.arxiv.org/abs/2402.01116)

    我们提出了一个层级架构，通过使用对偶交互预测和精简的MPC问题，实现了可扩展的实时模型预测控制，在复杂的多模态交通场景中展示了12倍的速度提升。

    

    我们提出了一个层级架构，用于在复杂的多模态交通场景中实现可扩展的实时模型预测控制(MPC)。该架构由两个关键组件组成：1) RAID-Net，一种基于注意力机制的新颖循环神经网络，使用拉格朗日对偶性预测自动驾驶车辆与周围车辆之间在MPC预测范围内的相关交互；2) 一个简化的随机MPC问题，消除不相关的避碰约束，提高计算效率。我们的方法在一个模拟交通路口中演示，展示了解决运动规划问题的12倍速提升。您可以在这里找到展示该架构在多个复杂交通场景中的视频：https://youtu.be/-TcMeolCLWc

    We propose a hierarchical architecture designed for scalable real-time Model Predictive Control (MPC) in complex, multi-modal traffic scenarios. This architecture comprises two key components: 1) RAID-Net, a novel attention-based Recurrent Neural Network that predicts relevant interactions along the MPC prediction horizon between the autonomous vehicle and the surrounding vehicles using Lagrangian duality, and 2) a reduced Stochastic MPC problem that eliminates irrelevant collision avoidance constraints, enhancing computational efficiency. Our approach is demonstrated in a simulated traffic intersection with interactive surrounding vehicles, showcasing a 12x speed-up in solving the motion planning problem. A video demonstrating the proposed architecture in multiple complex traffic scenarios can be found here: https://youtu.be/-TcMeolCLWc
    
[^2]: 针对未知进行调整：重新审视终身强化学习的评估策略

    Tuning for the Unknown: Revisiting Evaluation Strategies for Lifelong RL

    [https://arxiv.org/abs/2404.02113](https://arxiv.org/abs/2404.02113)

    提出了一种新方法来调整和评估终身强化学习代理，在此方法中，只有实验数据的一小部分可用于超参数调整，针对终身强化学习的研究进展可能被不当的经验方法所阻碍

    

    在继续或终身强化学习中，对环境的访问应该是有限的。如果我们希望设计的算法能够长时间运行，并不断适应新的、意想不到的情况，那么我们必须愿意在整个代理的整个生命周期内部署我们的代理而不调整它们的超参数。本文探讨了深度强化学习中 -- 甚至继续强化学习中 -- 具备对代理的部署环境具有无限制访问权的标准做法可能已经阻碍了对终身强化学习研究的进展。在本文中，我们提出了一种新的方法，用于调整和评估终身强化学习代理，其中只有实验数据的百分之一可以用于超参数调整。然后，我们对DQN和Soft Actor Critic在各种持续和非稳定领域进行了实证研究。我们发现这两种方法通常表现较好。

    arXiv:2404.02113v1 Announce Type: new  Abstract: In continual or lifelong reinforcement learning access to the environment should be limited. If we aspire to design algorithms that can run for long-periods of time, continually adapting to new, unexpected situations then we must be willing to deploy our agents without tuning their hyperparameters over the agent's entire lifetime. The standard practice in deep RL -- and even continual RL -- is to assume unfettered access to deployment environment for the full lifetime of the agent. This paper explores the notion that progress in lifelong RL research has been held back by inappropriate empirical methodologies. In this paper we propose a new approach for tuning and evaluating lifelong RL agents where only one percent of the experiment data can be used for hyperparameter tuning. We then conduct an empirical study of DQN and Soft Actor Critic across a variety of continuing and non-stationary domains. We find both methods generally perform po
    
[^3]: 模型崩溃是否不可避免？通过累积真实和合成数据打破递归的诅咒

    Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data

    [https://arxiv.org/abs/2404.01413](https://arxiv.org/abs/2404.01413)

    本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。

    

    随着生成模型的激增，以及在网络规模数据上的预训练，一个及时的问题浮出水面：当这些模型被训练在它们自己生成的输出上时会发生什么？最近对模型数据反馈循环的研究发现，这样的循环可能导致模型崩溃，即性能随着每次模型拟合迭代逐渐下降，直到最新的模型变得无用。然而，最近几篇研究模型崩溃的论文都假设随着时间推移，新数据会取代旧数据，而不是假设数据会随时间累积。在本文中，我们比较了这两种情况，并表明积累数据可以防止模型崩溃。我们首先研究了一个解析可处理的设置，其中一系列线性模型拟合到先前模型的预测。先前的工作表明，如果数据被替换，测试误差会随着模型拟合迭代次数线性增加；我们扩展了这个研究探讨了数据逐渐累积的情况下会发生什么。

    arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
    
[^4]: 用于鲁棒性混合代码翻译的合成数据生成和联合学习

    Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation

    [https://arxiv.org/abs/2403.16771](https://arxiv.org/abs/2403.16771)

    本文提出了用于鲁棒性混合代码翻译的合成数据生成和联合学习方法，包括开发了Hinglish到英语的平行语料库以及提出的能够处理噪声的联合训练模型RCMT。

    

    现代多语言世界中的广泛网络交流为在单个话语中混合多种语言（又称混合代码语言）提供了机会。由于标注数据的稀缺和噪音的存在，这给计算模型带来了严峻挑战。在资源匮乏的环境中缓解数据稀缺问题的潜在解决方案是通过翻译利用资源丰富语言中的现有数据。本文针对混合代码（印地语和孟加拉语）到英语的机器翻译问题。首先，我们合成开发了HINMIX一个印地语到英语的平行语料库，包含约420万个句对。随后，我们提出了RCMT，一种基于强健扰动的联合训练模型，通过在干净和带噪声单词之间共享参数，学习处理现实世界混合代码文本中的噪声。此外，我们展示了RCMT在零-shot设置中对孟加拉语的适应能力。

    arXiv:2403.16771v1 Announce Type: new  Abstract: The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English, with ~4.2M sentence pairs. Subsequently, we propose RCMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of RCMT in a zero-shot setup for Bengalish t
    
[^5]: 用双机器学习估计因果效应--一种方法评估

    Estimating Causal Effects with Double Machine Learning -- A Method Evaluation

    [https://arxiv.org/abs/2403.14385](https://arxiv.org/abs/2403.14385)

    双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。

    

    使用观测数据估计因果效应仍然是一个非常活跃的研究领域。近年来，研究人员开发了利用机器学习放宽传统假设以估计因果效应的新框架。在本文中，我们回顾了其中一个最重要的方法-"双/无偏机器学习"（DML），并通过比较它在模拟数据上相对于更传统的统计方法的表现，然后将其应用于真实世界数据进行了实证评估。我们的研究发现表明，在DML中应用一个适当灵活的机器学习算法可以改进对各种非线性混淆关系的调整。这种优势使得可以摆脱通常在因果效应估计中必需的传统函数形式假设。然而，我们表明该方法在关于因果关系的标准假设方面仍然至关重要。

    arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal 
    
[^6]: 在交通事件管理中集成大型语言模型进行严重性分类：一种机器学习方法

    Integrating Large Language Models for Severity Classification in Traffic Incident Management: A Machine Learning Approach

    [https://arxiv.org/abs/2403.13547](https://arxiv.org/abs/2403.13547)

    本研究评估了大型语言模型在交通事件管理中的应用，发现将语言模型特征与传统特征结合可以提高或匹配机器学习技术在事件严重性分类中的表现。

    

    本研究评估了大型语言模型对提升交通事件管理的机器学习过程的影响。它考察了现代语言模型生成的特征在使用事故报告对事件严重性进行分类时如何改善或与预测准确性相匹配。在语言模型和机器学习算法（包括梯度提升决策树、随机森林和极限梯度提升）组合之间进行了多次比较。我们的研究使用了文本和事件报告中传统特征和语言模型生成特征，以及它们的组合进行严重性分类。将语言模型的特征与直接从事件报告中获取的特征结合起来，已经显示出在将事件的严重级别指派给事件时，尤其是在使用随机森林和Ex时，能够提高或至少匹配机器学习技术的性能。

    arXiv:2403.13547v1 Announce Type: new  Abstract: This study evaluates the impact of large language models on enhancing machine learning processes for managing traffic incidents. It examines the extent to which features generated by modern language models improve or match the accuracy of predictions when classifying the severity of incidents using accident reports. Multiple comparisons performed between combinations of language models and machine learning algorithms, including Gradient Boosted Decision Trees, Random Forests, and Extreme Gradient Boosting. Our research uses both conventional and language model-derived features from texts and incident reports, and their combinations to perform severity classification. Incorporating features from language models with those directly obtained from incident reports has shown to improve, or at least match, the performance of machine learning techniques in assigning severity levels to incidents, particularly when employing Random Forests and Ex
    
[^7]: Linguacodus：一种在机器学习流水线中进行变革性代码生成的协同框架

    Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines

    [https://arxiv.org/abs/2403.11585](https://arxiv.org/abs/2403.11585)

    Linguacodus是一种创新框架，通过部署动态流水线和精细调整的大型语言模型，实现了将自然语言任务描述转换为代码的自动化过程，极大地推进了机器学习应用的发展。

    

    在不断发展的机器学习领域中，将自然语言描述无缝转化为可执行代码仍然是一个巨大的挑战。本文介绍了Linguacodus，这是一个创新性框架，旨在通过部署一个动态流水线，通过高级数据塑形指令，将自然语言任务描述迭代地转换为代码来应对这一挑战。Linguacodus的核心是一个经过精细调整的大型语言模型（LLM），能够评估各种问题的多样解决方案，并为特定任务选择最合适的解决方案。本文详细介绍了精细调整过程，并阐明了如何将自然语言描述转化为功能性代码。Linguacodus代表了自动化代码生成的重大飞跃，有效地弥合了任务描述和可执行代码之间的差距。它对推进跨不同领域的机器学习应用具有巨大潜力。

    arXiv:2403.11585v1 Announce Type: cross  Abstract: In the ever-evolving landscape of machine learning, seamless translation of natural language descriptions into executable code remains a formidable challenge. This paper introduces Linguacodus, an innovative framework designed to tackle this challenge by deploying a dynamic pipeline that iteratively transforms natural language task descriptions into code through high-level data-shaping instructions. The core of Linguacodus is a fine-tuned large language model (LLM), empowered to evaluate diverse solutions for various problems and select the most fitting one for a given task. This paper details the fine-tuning process, and sheds light on how natural language descriptions can be translated into functional code. Linguacodus represents a substantial leap towards automated code generation, effectively bridging the gap between task descriptions and executable code. It holds great promise for advancing machine learning applications across div
    
[^8]: 只说名称：通过数据生成实现仅利用类别名称进行在线连续学习

    Just Say the Name: Online Continual Learning with Category Names Only via Data Generation

    [https://arxiv.org/abs/2403.10853](https://arxiv.org/abs/2403.10853)

    提出了在线连续学习框架G-NoCL，采用生成数据并利用DIverSity和COmplexity enhancing ensemBlER（DISCOBER）进行数据融合，展示了其在在线连续学习基准测试中的优越性能。

    

    在现实世界的场景中，由于成本过高，对于连续学习进行大量手动注释是不切实际的。虽然之前的研究受到大规模网络监督训练的影响，建议在连续学习中利用网络抓取的数据，但这带来了诸如数据不平衡、使用限制和隐私问题等挑战。为了解决连续网络监督训练的风险，我们提出了一种在线连续学习框架 - 仅使用名称的生成式连续学习（G-NoCL）。所提出的G-NoCL使用一组生成器G以及学习者。当遇到新概念（例如，类别）时，G-NoCL采用新颖的样本复杂性引导数据合成技术DIverSity and COmplexity enhancing ensemBlER（DISCOBER）从生成的数据中最优抽样训练数据。通过大量实验，我们展示了DISCOBER在G-NoCL在线连续学习基准测试中表现出的优越性能，涵盖了In-Distributi。

    arXiv:2403.10853v1 Announce Type: cross  Abstract: In real-world scenarios, extensive manual annotation for continual learning is impractical due to prohibitive costs. Although prior arts, influenced by large-scale webly supervised training, suggest leveraging web-scraped data in continual learning, this poses challenges such as data imbalance, usage restrictions, and privacy concerns. Addressing the risks of continual webly supervised training, we present an online continual learning framework - Generative Name only Continual Learning (G-NoCL). The proposed G-NoCL uses a set of generators G along with the learner. When encountering new concepts (i.e., classes), G-NoCL employs the novel sample complexity-guided data ensembling technique DIverSity and COmplexity enhancing ensemBlER (DISCOBER) to optimally sample training data from generated data. Through extensive experimentation, we demonstrate superior performance of DISCOBER in G-NoCL online CL benchmarks, covering both In-Distributi
    
[^9]: 一种为扩散模型提供帮助的方法：改进条件人类图像生成的两阶段方法

    Giving a Hand to Diffusion Models: a Two-Stage Approach to Improving Conditional Human Image Generation

    [https://arxiv.org/abs/2403.10731](https://arxiv.org/abs/2403.10731)

    提出了一种改进条件人类图像生成的两阶段方法，首先训练手部生成器产生手部图像和分割掩模，在第二阶段使用改进的 ControlNet 模型绘制生成手部周围的身体。

    

    近年来，人类图像生成取得了显著进展，特别是在扩散模型的进步方面。然而，现有的扩散方法在生成一致的手部解剖结构时遇到挑战，并且生成的图像通常缺乏对手部姿势的精确控制。为了解决这一局限性，我们引入了一种新颖的方法来进行姿势条件的人类图像生成，将过程分为两个阶段：手的生成和随后围绕手部进行身体外部绘制。我们提出通过多任务设置训练手部生成器来生成手部图像及其对应的分割掩模，并在第一阶段中使用训练好的模型。然后在第二阶段使用适应的 ControlNet 模型来绘制周围的身体，生成最终结果。我们引入了一种新颖的混合技术，在第二阶段保留手部细节。

    arXiv:2403.10731v1 Announce Type: cross  Abstract: Recent years have seen significant progress in human image generation, particularly with the advancements in diffusion models. However, existing diffusion methods encounter challenges when producing consistent hand anatomy and the generated images often lack precise control over the hand pose. To address this limitation, we introduce a novel approach to pose-conditioned human image generation, dividing the process into two stages: hand generation and subsequent body out-painting around the hands. We propose training the hand generator in a multi-task setting to produce both hand images and their corresponding segmentation masks, and employ the trained model in the first stage of generation. An adapted ControlNet model is then used in the second stage to outpaint the body around the generated hands, producing the final result. A novel blending technique is introduced to preserve the hand details during the second stage that combines the
    
[^10]: LAB：针对ChatBots的大规模对齐

    LAB: Large-Scale Alignment for ChatBots

    [https://arxiv.org/abs/2403.01081](https://arxiv.org/abs/2403.01081)

    介绍了一种名为LAB的方法，旨在克服大型语言模型训练中的可扩展性挑战，通过分类法指导的合成数据生成和多阶段调整框架，实现了对昂贵人工标注和GPT-4等专有模型依赖较少的大规模对齐，提供了一种可扩展、具有成本效益的解决方案，不会出现灾难性遗忘情况，进一步增强了LLM的训练效率。

    

    这项工作介绍了LAB（ChatBots的大规模对齐），这是一种旨在克服大型语言模型（LLM）训练中指令调整阶段的可扩展性挑战的创新方法。通过利用基于分类法的合成数据生成过程和多阶段调整框架，LAB显著减少对昂贵的人类注释和诸如GPT-4之类的专有模型的依赖。我们证明，使用LAB训练的模型在几个基准测试中的性能可以与使用传统人类注释或GPT-4生成的合成数据训练的模型相比具有竞争力。因此，在不会出现灾难性遗忘的情况下，提供了一种可扩展、具有成本效益的解决方案，以增强LLM的能力和指令遵循行为，标志着在高效训练各种应用的LLM方面迈出了一步。

    arXiv:2403.01081v1 Announce Type: new  Abstract: This work introduces LAB (Large-scale Alignment for chatBots), a novel methodology designed to overcome the scalability challenges in the instruction-tuning phase of large language model (LLM) training. Leveraging a taxonomy-guided synthetic data generation process and a multi-phase tuning framework, LAB significantly reduces reliance on expensive human annotations and proprietary models like GPT-4. We demonstrate that LAB-trained models can achieve competitive performance across several benchmarks compared to models trained with traditional human-annotated or GPT-4 generated synthetic data. Thus offering a scalable, cost-effective solution for enhancing LLM capabilities and instruction-following behaviors without the drawbacks of catastrophic forgetting, marking a step forward in the efficient training of LLMs for a wide range of applications.
    
[^11]: 扩散模型作为具有未知约束的优化约束抽样器

    Diffusion Models as Constrained Samplers for Optimization with Unknown Constraints

    [https://arxiv.org/abs/2402.18012](https://arxiv.org/abs/2402.18012)

    使用扩散模型在数据流形内进行优化，通过在目标函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积上进行抽样来解决具有未知约束的优化问题。

    

    处理现实世界的优化问题在分析客观函数或约束不可用时变得尤为具有挑战性。虽然许多研究已经解决了未知目标的问题，但有限研究关注了约束条件未明确给出的情况。忽略这些约束可能导致在实践中不现实的虚假解决方案。为了处理这种未知约束，我们建议使用扩散模型在数据流形内进行优化。为了将优化过程限制在数据流形内，我们将原始优化问题重新构造为通过客观函数定义的Boltzmann分布和扩散模型学习的数据分布的乘积的抽样问题。为了增强抽样效率，我们提出了一个两阶段框架，以引导扩散过程进行预热，然后是Langevin动态。

    arXiv:2402.18012v1 Announce Type: cross  Abstract: Addressing real-world optimization problems becomes particularly challenging when analytic objective functions or constraints are unavailable. While numerous studies have addressed the issue of unknown objectives, limited research has focused on scenarios where feasibility constraints are not given explicitly. Overlooking these constraints can lead to spurious solutions that are unrealistic in practice. To deal with such unknown constraints, we propose to perform optimization within the data manifold using diffusion models. To constrain the optimization process to the data manifold, we reformulate the original optimization problem as a sampling problem from the product of the Boltzmann distribution defined by the objective function and the data distribution learned by the diffusion model. To enhance sampling efficiency, we propose a two-stage framework that begins with a guided diffusion process for warm-up, followed by a Langevin dyna
    
[^12]: 考虑对称性的软腕部分可观测性下机器人装配的强化学习

    Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist

    [https://arxiv.org/abs/2402.18002](https://arxiv.org/abs/2402.18002)

    本研究利用部分可观测性和深度强化学习处理机器人装配中的零件装配任务，通过利用领域对称性提高样本效率，成功构建了一种基于记忆的代理模型。

    

    本研究运用软腕来解决机器人装配中的代表性但具有挑战性的富接触PEG-IN-HOLE任务，该软腕可以比刚性腕部更安全地操作并容忍较低频率的控制信号。与以往研究通常使用完全可观测公式不同，该公式需要外部设置或估计器来获取PEG-TO-HOLE姿态。相反，我们使用部分可观测公式和基于深度强化学习的示范来学习一种基于记忆的代理，该代理完全基于触觉和本体感知信号行动。此外，以前的研究未融合潜在领域对称性，因此必须在更大的空间中搜索解决方案。相反，我们建议利用对称性来提高样本效率，通过增加训练数据并构建辅助损失来强迫代理遵守对称性。在模拟实验中，使用五种不同对称PEG形状显示，我们提出的代理可以与

    arXiv:2402.18002v1 Announce Type: cross  Abstract: This study tackles the representative yet challenging contact-rich peg-in-hole task of robotic assembly, using a soft wrist that can operate more safely and tolerate lower-frequency control signals than a rigid one. Previous studies often use a fully observable formulation, requiring external setups or estimators for the peg-to-hole pose. In contrast, we use a partially observable formulation and deep reinforcement learning from demonstrations to learn a memory-based agent that acts purely on haptic and proprioceptive signals. Moreover, previous works do not incorporate potential domain symmetry and thus must search for solutions in a bigger space. Instead, we propose to leverage the symmetry for sample efficiency by augmenting the training data and constructing auxiliary losses to force the agent to adhere to the symmetry. Results in simulation with five different symmetric peg shapes show that our proposed agent can be comparable to 
    
[^13]: QUCE: 减少和量化基于路径的不确定性以生成对抗性反事实解释

    QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations

    [https://arxiv.org/abs/2402.17516](https://arxiv.org/abs/2402.17516)

    QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。

    

    arXiv:2402.17516v1 公告类型：跨学科 深度神经网络（DNNs）作为机器学习领域最突出的方法之一。DNNs的有效性随着最近计算能力的增加而激增，使得这些方法能够扩展到处理大数据中的重要复杂性以应对预测挑战。然而，随着DNN模型复杂性的提高，可解释性降低。针对这一挑战，诸如对抗梯度整合（AGI）这样的可解释模型利用DNN提供的基于路径的梯度来阐明它们的决策。然而，当梯度在越界路径遍历期间表现出不规则性时，基于路径的解释器的性能可能会受到损害。在这种情况下，我们介绍了Quantified Uncertainty Counterfactual Explanations（QUCE），这是一种旨在减少路径不确定性的方法，以缓解越界遍历。 QUCE不仅在提出解释时量化不确定性

    arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
    
[^14]: 坚持你的角色！个人价值在大型语言模型中的稳定性

    Stick to your Role! Stability of Personal Values Expressed in Large Language Models

    [https://arxiv.org/abs/2402.14846](https://arxiv.org/abs/2402.14846)

    本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。

    

    通过基准测试或心理问卷的标准方式研究大型语言模型(LLMs)是提供许多来源于类似最小背景的不同查询（例如多项选择问题）。然而，由于LLM高度依赖于背景，因此从这种最小背景评估中得出的结论可能对模型在部署中的行为（在那里它将暴露于许多新背景）的说明很少。我们认为，依赖于背景的特性应该作为LLM比较的另一个维度来研究，而不是其他维度，如认知能力、知识或模型大小。在本文中，我们提出了一个关于在不同背景下（模拟对不同话题的对话）价值表达稳定性的案例研究，并使用标准心理学问卷（PVQ）和行为下游任务进行测量。我们考虑了来自五个家族的19个开源LLM。借鉴心理学方法，我们研究了等级稳定性。

    arXiv:2402.14846v1 Announce Type: cross  Abstract: The standard way to study Large Language Models (LLMs) through benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLM's highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model's behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size. In this paper, we present a case-study about the stability of value expression over different contexts (simulated conversations on different topics), and as measured using a standard psychology questionnaire (PVQ) and a behavioral downstream task. We consider 19 open-sourced LLMs from five families. Reusing methods from psychology, we study Rank-order stabilit
    
[^15]: 平衡脑电图中的频谱、时间和空间信息用于基于脑电图的阿尔茨海默病分类

    Balancing Spectral, Temporal and Spatial Information for EEG-based Alzheimer's Disease Classification

    [https://arxiv.org/abs/2402.13523](https://arxiv.org/abs/2402.13523)

    通过变化每个维度的比例来调查空间信息对于脑电图阿尔茨海默病分类的重要性，结果表明空间信息比时间信息更相关，与频谱信息的相关性相同

    

    未来治疗前景需要开发经济有效的阿尔茨海默病筛查方法。在这方面，脑电图（EEG）是一个有前途的候选方法，因为它是最经济的成像模式之一。最近的脑电图分析工作已经转向利用空间信息，采用新颖的框架，如图信号处理或图神经网络。在本研究中，我们系统地调查了相对于频谱或时间信息的空间信息的重要性，通过改变每个维度所占比例来进行阿尔茨海默病分类。为此，我们在两个常规脑电图数据集上测试了各种维度分辨率配置。我们发现，空间信息始终比时间信息更相关，与频谱信息的相关性相同。这些结果强调了考虑空间信息进行基于脑电图的阿尔茨海默病分类的必要性。在我们的第二个数据集上，

    arXiv:2402.13523v1 Announce Type: cross  Abstract: The prospect of future treatment warrants the development of cost-effective screening for Alzheimer's disease (AD). A promising candidate in this regard is electroencephalography (EEG), as it is one of the most economic imaging modalities. Recent efforts in EEG analysis have shifted towards leveraging spatial information, employing novel frameworks such as graph signal processing or graph neural networks. Here, we systematically investigate the importance of spatial information relative to spectral or temporal information by varying the proportion of each dimension for AD classification. To do so, we test various dimension resolution configurations on two routine EEG datasets. We find that spatial information is consistently more relevant than temporal information and equally relevant as spectral information. These results emphasise the necessity to consider spatial information for EEG-based AD classification. On our second dataset, we
    
[^16]: 通用物理变压器

    Universal Physics Transformers

    [https://arxiv.org/abs/2402.12365](https://arxiv.org/abs/2402.12365)

    提出了通用物理变压器（UPTs）这一新颖学习范式，能够模拟广泛的时空问题，同时适用于拉格朗日和欧拉离散化方案，有效地传播动态并允许查询潜在空间

    

    基于深度神经网络的偏微分方程替代者近来引起了越来越多的关注。然而，类似于它们的数值对应物，在不同应用中使用不同的技术，即使系统的基础动态相似。一个著名的例子是在计算流体动力学中的拉格朗日和欧拉表述，这为神经网络有效地建模基于粒子而不是网格的动态构成了挑战。我们引入了通用物理变压器（UPTs），这是一种新颖的学习范式，它模拟了一系列时空问题 - 对拉格朗日和欧拉离散化方案。UPTs在没有基于网格或基于粒子的潜在结构的情况下运行，从而在网格和粒子之间实现了灵活性。UPTs在潜在空间中高效传播动态，强调了逆编码和解码技术。最后，UPTs允许查询潜在空间表现

    arXiv:2402.12365v1 Announce Type: cross  Abstract: Deep neural network based surrogates for partial differential equations have recently gained increased interest. However, akin to their numerical counterparts, different techniques are used across applications, even if the underlying dynamics of the systems are similar. A prominent example is the Lagrangian and Eulerian specification in computational fluid dynamics, posing a challenge for neural networks to effectively model particle- as opposed to grid-based dynamics. We introduce Universal Physics Transformers (UPTs), a novel learning paradigm which models a wide range of spatio-temporal problems - both for Lagrangian and Eulerian discretization schemes. UPTs operate without grid- or particle-based latent structures, enabling flexibility across meshes and particles. UPTs efficiently propagate dynamics in the latent space, emphasized by inverse encoding and decoding techniques. Finally, UPTs allow for queries of the latent space repre
    
[^17]: 通过动态学习器追踪概率变化

    Tracking Changing Probabilities via Dynamic Learners

    [https://arxiv.org/abs/2402.10142](https://arxiv.org/abs/2402.10142)

    该论文介绍了通过动态学习器追踪概率变化的方法，通过输出候选项目及其概率来预测离散项目序列中下一个可能出现的项目。

    

    考虑一个预测器，即一个学习器，其输入是一系列离散项目。预测器的任务是在每个时间点进行概率多类别预测，即通过输出有零个或多个候选项目及其概率来预测接下来可能发生的项目，然后揭示实际项目并从中学习。为了输出概率，预测器会跟踪其所见项目的比例。预测器具有恒定（有限）的空间，我们寻求高效的预测和更新技术：流是无界的，项目的集合对预测器是未知的，它们的总数也可能无限增长。此外，存在非平稳性：项目的潜在频率可能会不时发生显著变化。例如，新项目可能开始出现，一些当前频繁出现的项目可能再次停止出现。由于有空间限制，预测器只需要提供概率。

    arXiv:2402.10142v1 Announce Type: cross  Abstract: Consider a predictor, a learner, whose input is a stream of discrete items. The predictor's task, at every time point, is probabilistic multiclass prediction, i.e., to predict which item may occur next by outputting zero or more candidate items, each with a probability, after which the actual item is revealed and the predictor learns from this observation. To output probabilities, the predictor keeps track of the proportions of the items it has seen. The predictor has constant (limited) space and we seek efficient prediction and update techniques: The stream is unbounded, the set of items is unknown to the predictor and their totality can also grow unbounded. Moreover, there is non-stationarity: the underlying frequencies of items may change, substantially, from time to time. For instance, new items may start appearing and a few currently frequent items may cease to occur again. The predictor, being space-bounded, need only provide pro
    
[^18]: 基于因果关系的基础世界模型在具身人工智能中的重要作用

    The Essential Role of Causality in Foundation World Models for Embodied AI

    [https://arxiv.org/abs/2402.06665](https://arxiv.org/abs/2402.06665)

    基于因果关系的基础世界模型对于具身人工智能的发展至关重要，当前的基础模型无法准确建模与现实世界的物理相互作用。因果关系的研究有助于构建真实世界模型，提高对可能相互作用结果的准确预测能力。

    

    最近在基础模型中取得的进展，尤其是在大型多模态模型和对话代理方面，引发了对具备普遍能力的具身代理人潜力的兴趣。这样的代理人需要能够在许多不同的真实世界环境中执行新任务。然而，当前的基础模型未能准确建模与现实世界的物理相互作用，因此对于具身人工智能而言是不够的。因果关系的研究有助于构建真实世界模型，这对于准确预测可能相互作用的结果至关重要。本文着重探讨了为即将到来的具身代理生成基础世界模型的前景，并对其中的因果关系的重要性提出了新的观点。我们认为整合因果关系是促进与世界的有意义的物理相互作用至关重要的。最后，我们揭示了这一背景下对因果关系的误解，并展示了我们对未来的展望。

    Recent advances in foundation models, especially in large multi-modal models and conversational agents, have ignited interest in the potential of generally capable embodied agents. Such agents would require the ability to perform new tasks in many different real-world environments. However, current foundation models fail to accurately model physical interactions with the real world thus not sufficient for Embodied AI. The study of causality lends itself to the construction of veridical world models, which are crucial for accurately predicting the outcomes of possible interactions. This paper focuses on the prospects of building foundation world models for the upcoming generation of embodied agents and presents a novel viewpoint on the significance of causality within these. We posit that integrating causal considerations is vital to facilitate meaningful physical interactions with the world. Finally, we demystify misconceptions about causality in this context and present our outlook fo
    
[^19]: 物理信息神经网络的多尺度建模：从复杂系统的大尺度动力学到小尺度预测

    Multiscale Modelling with Physics-informed Neural Network: from Large-scale Dynamics to Small-scale Predictions in Complex Systems

    [https://arxiv.org/abs/2402.05067](https://arxiv.org/abs/2402.05067)

    本文提出了利用物理信息神经网络进行多尺度建模的方法，通过解耦大尺度和小尺度动力学，并在正交基函数空间中近似小尺度系统。实验结果表明该方法在处理液体动力学问题以及更复杂的情况下具有较高的有效性和适用性。

    

    多尺度现象在各个科学领域中普遍存在，对于准确有效地预测复杂系统中的多尺度动力学提出了普遍的挑战。本文提出了一种通过解耦方法对多尺度动力学进行表征的新的求解模式。通过独立地建模大尺度动力学，并将小尺度动力学视为从属系统，我们开发了一种谱PINN方法，在正交基函数空间中接近小尺度系统。通过大量的数值实验，包括一维Kuramot-Sivashinsky (KS)方程、二维和三维Navier-Stokes (NS)方程，我们展示了该方法的有效性，展示了它在液体动力学问题中的多样性。此外，我们还深入研究了该方法在更复杂问题中的应用，包括非均匀网格、复杂几何形状、带噪声的大尺度数据和高维小尺度动力学。

    Multiscale phenomena manifest across various scientific domains, presenting a ubiquitous challenge in accurately and effectively predicting multiscale dynamics in complex systems. In this paper, a novel solving mode is proposed for characterizing multiscale dynamics through a decoupling method. By modelling large-scale dynamics independently and treating small-scale dynamics as a slaved system, a Spectral PINN is developed to approach the small-scale system in an orthogonal basis functional space. The effectiveness of the method is demonstrated through extensive numerical experiments, including one-dimensional Kuramot-Sivashinsky (KS) equation, two- and three-dimensional Navier-Stokes (NS) equations, showcasing its versatility in addressing problems of fluid dynamics. Furthermore, we also delve into the application of the proposed approach to more complex problems, including non-uniform meshes, complex geometries, large-scale data with noise, and high-dimensional small-scale dynamics. 
    
[^20]: 扩散模型是否学习语义有意义和高效的表示？

    Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?

    [https://arxiv.org/abs/2402.03305](https://arxiv.org/abs/2402.03305)

    本研究通过实验探究了条件DDPMs学习生成2D球形高斯凸起的过程，在学习的过程中发现了潜在表示的关键，产生了与不同阶段对应的 qualitatively 不同的生成行为。

    

    扩散模型能够以不寻常的方式生成图像，例如宇航员骑在月球上的马，并且有正确的阴影。这些输出表明了模型具有组合泛化的能力，但是模型是如何做到这一点的呢？我们在条件DDPMs上进行了控制实验，学习生成以指定的$x$和$y$位置为中心的2D球形高斯凸起。我们的结果表明，产生语义有意义的潜在表示对于实现高性能至关重要。在学习过程中，模型经历了三个不同的潜在表示阶段：(A阶段)没有潜在结构，(B阶段)一个混乱状态的2D流形，以及(C阶段)一个有序的2D流形。对应于这些阶段，我们发现了 qualitatively 不同的生成行为：1）生成多个凸起，2）生成一个凸起，但$x$和$y$位置不准确，3）生成一个凸起且位置准确。

    Diffusion models are capable of impressive feats of image generation with uncommon juxtapositions such as astronauts riding horses on the moon with properly placed shadows. These outputs indicate the ability to perform compositional generalization, but how do the models do so? We perform controlled experiments on conditional DDPMs learning to generate 2D spherical Gaussian bumps centered at specified $x$- and $y$-positions. Our results show that the emergence of semantically meaningful latent representations is key to achieving high performance. En route to successful performance over learning, the model traverses three distinct phases of latent representations: (phase A) no latent structure, (phase B) a 2D manifold of disordered states, and (phase C) a 2D ordered manifold. Corresponding to each of these phases, we identify qualitatively different generation behaviors: 1) multiple bumps are generated, 2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is genera
    
[^21]: 一种针对不平衡线性分类的扩展非对称sigmoid和感知机(SIGTRON)

    An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification

    [https://arxiv.org/abs/2312.16043](https://arxiv.org/abs/2312.16043)

    本文提出了一个新的多项式参数化sigmoid函数(SIGTRON)，并且介绍了其伴随的SIC模型。相比传统的成本敏感学习模型，在给定的训练数据集接近良好平衡的条件下，所提出的SIC模型对于数据集的变化更加适应，并通过创建倾斜的超平面方程来实现。

    

    本文提出了一种新的多项式参数化sigmoid函数，称为SIGTRON，它是一种扩展的非对称sigmoid函数和感知机的结合，以及它的伴随凸模型SIGTRON-不平衡分类(SIC)模型，该模型使用了虚拟SIGTRON产生的凸损失函数。与传统的$\pi$-加权成本敏感学习模型相比，SIC模型在损失函数上没有外部的$\pi$-权重，而是在虚拟的SIGTRON产生的损失函数中有内部参数。因此，当给定的训练数据集接近良好平衡的条件时，我们展示了所提出的SIC模型对数据集的变化更加适应，比如训练集和测试集之间比例不平衡的不一致性。这种适应是通过创建一个倾斜的超平面方程来实现的。另外，我们提出了一个基于拟牛顿优化(L-BFGS)框架的虚拟凸损失，通过开发一个基于区间的二分线性搜索算法来实现。

    This article presents a new polynomial parameterized sigmoid called SIGTRON, which is an extended asymmetric sigmoid with Perceptron, and its companion convex model called SIGTRON-imbalanced classification (SIC) model that employs a virtual SIGTRON-induced convex loss function. In contrast to the conventional $\pi$-weighted cost-sensitive learning model, the SIC model does not have an external $\pi$-weight on the loss function but has internal parameters in the virtual SIGTRON-induced loss function. As a consequence, when the given training dataset is close to the well-balanced condition, we show that the proposed SIC model is more adaptive to variations of the dataset, such as the inconsistency of the scale-class-imbalance ratio between the training and test datasets. This adaptation is achieved by creating a skewed hyperplane equation. Additionally, we present a quasi-Newton optimization(L-BFGS) framework for the virtual convex loss by developing an interval-based bisection line sear
    
[^22]: 基于平滑度诱导正则化和基于频谱图的数据增强的水下声学目标识别

    Underwater Acoustic Target Recognition based on Smoothness-inducing Regularization and Spectrogram-based Data Augmentation

    [https://arxiv.org/abs/2306.06945](https://arxiv.org/abs/2306.06945)

    通过平滑度诱导正则化和基于频谱图的数据增强，提高水下声学目标识别模型的泛化能力和避免性能降级的风险

    

    水下声学目标识别是一项具有挑战性的任务，这归因于复杂的水下环境和有限的数据可用性。数据不足可能会阻碍识别系统支持复杂建模的能力，从而阻碍其发展。为了提高识别模型的泛化能力，已经采用了诸如数据增强之类的技术来模拟水下信号并丰富数据分布。然而，水下环境的复杂性可能导致模拟信号偏离真实场景，导致受到非真实数据误导的偏见模型。在本研究中，我们提出了两种策略，可以在数据有限的情况下增强模型的泛化能力，同时避免性能降级的风险。首先，作为替代传统数据增强的方法，我们利用平滑度诱导正则化，该方法仅纳入模拟信号

    arXiv:2306.06945v2 Announce Type: replace-cross  Abstract: Underwater acoustic target recognition is a challenging task owing to the intricate underwater environments and limited data availability. Insufficient data can hinder the ability of recognition systems to support complex modeling, thus impeding their advancement. To improve the generalization capacity of recognition models, techniques such as data augmentation have been employed to simulate underwater signals and diversify data distribution. However, the complexity of underwater environments can cause the simulated signals to deviate from real scenarios, resulting in biased models that are misguided by non-true data. In this study, we propose two strategies to enhance the generalization ability of models in the case of limited data while avoiding the risk of performance degradation. First, as an alternative to traditional data augmentation, we utilize smoothness-inducing regularization, which only incorporates simulated signal
    
[^23]: 向算法的系统理论迈进

    Towards a Systems Theory of Algorithms. (arXiv:2401.14029v1 [math.OC])

    [http://arxiv.org/abs/2401.14029](http://arxiv.org/abs/2401.14029)

    向算法的系统理论迈进，将算法视为开放的动态系统与其他算法、物理系统、人类或数据库交互，提供宝贵的洞见。

    

    传统上，数值算法被视为独立的代码片段，局限于``in silico''存在。然而，这种观点不适用于许多现代计算方法，如控制、学习或优化中，其中``in vivo''算法与其环境进行交互。这些``开放''的例子包括各种实时基于优化的控制策略、强化学习、决策架构、在线优化等等。此外，即使在学习或优化中，``闭合''的算法也越来越多地被抽象为具有相互作用的动态模块和管道的块图。在这篇观点文章中，我们阐述了我们对即将发展的``算法的系统理论''的愿景，并主张将算法视为与其他算法、物理系统、人类或数据库交互的开放动态系统。值得注意的是，在系统理论的伞下开发的多种工具也提供了宝贵的洞见。

    Traditionally, numerical algorithms are seen as isolated pieces of code confined to an {\em in silico} existence. However, this perspective is not appropriate for many modern computational approaches in control, learning, or optimization, wherein {\em in vivo} algorithms interact with their environment. Examples of such {\em open} include various real-time optimization-based control strategies, reinforcement learning, decision-making architectures, online optimization, and many more. Further, even {\em closed} algorithms in learning or optimization are increasingly abstracted in block diagrams with interacting dynamic modules and pipelines. In this opinion paper, we state our vision on a to-be-cultivated {\em systems theory of algorithms} and argue in favour of viewing algorithms as open dynamical systems interacting with other algorithms, physical systems, humans, or databases. Remarkably, the manifold tools developed under the umbrella of systems theory also provide valuable insights
    
[^24]: 图像上采样方法的公平性基准测试

    Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])

    [http://arxiv.org/abs/2401.13555](http://arxiv.org/abs/2401.13555)

    这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。

    

    近年来，深度生成模型在创建合成媒体（如图像和视频）方面取得了快速发展。虽然这些模型在日常任务中的实际应用非常诱人，但评估其公平性相关的潜在风险至关重要。在这项工作中，我们引入了一个全面的框架，用于评估有条件生成模型的性能和公平性。我们开发了一套度量标准——受监督公平性的灵感来源——来评估模型的公平性和多样性。我们针对图像上采样这个特定应用，创建了一个涵盖各种现代上采样方法的基准测试。作为基准测试的一部分，我们引入了UnfairFace，这是FairFace的一个子集，复制了常见大规模人脸数据集的种族分布。我们的实证研究凸显了使用无偏训练集的重要性，并揭示了算法对该问题的响应变化。

    Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\unicode{x2013}$inspired by their supervised fairness counterparts$\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to 
    
[^25]: 可解释的基于路径的知识图推荐中的忠实路径语言建模

    Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph. (arXiv:2310.16452v1 [cs.IR])

    [http://arxiv.org/abs/2310.16452](http://arxiv.org/abs/2310.16452)

    本文提出了一个名为PEARLM的方法，通过语言建模开展基于路径的知识图谱推荐，解决了现有方法中对预训练知识图谱嵌入的依赖以及未充分利用实体和关系之间相互依赖性的问题，还避免了生成不准确的解释。实验结果表明，与现有方法相比，我们的方法效果显著。

    

    针对知识图谱中的路径推理方法在提高推荐系统透明度方面的潜力，本文提出了一种名为PEARLM的新方法，该方法通过语言建模有效捕获用户行为和产品端知识。我们的方法通过语言模型直接从知识图谱上的路径中学习知识图谱嵌入，并将实体和关系统一在同一优化空间中。序列解码的约束保证了路径对知识图谱的忠实性。在两个数据集上的实验证明了我们方法与现有最先进方法的有效性。

    Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED.
    
[^26]: 对比偏好学习：学习用户反馈而无需RL的方法

    Contrastive Preference Learning: Learning from Human Feedback without RL. (arXiv:2310.13639v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.13639](http://arxiv.org/abs/2310.13639)

    对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。

    

    "从人类反馈中进行强化学习（RLHF）已经成为一种与人类意图对齐的流行范式。通常的RLHF算法分为两个阶段：首先，利用人类偏好学习奖励函数，然后通过强化学习（RL）优化学习到的奖励函数以对齐模型。这种范式假设人类偏好是根据奖励分布的，但最近的研究表明，实际上它们遵循用户最佳策略下的遗憾。因此，从反馈中学习奖励函数不仅基于人类偏好的错误假设，还导致了由于策略梯度或RL阶段的自助法引起的棘手的优化挑战。由于这些优化挑战，当代的RLHF方法限制自己只能应用于上下文强化学习（如大型语言模型）或限制了观测维度（如基于状态的机器人）。我们通过引入一种新的方法来克服这些限制。"

    Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new famil
    
[^27]: 混合数据上有效高效的联邦树学习

    Effective and Efficient Federated Tree Learning on Hybrid Data. (arXiv:2310.11865v1 [cs.LG])

    [http://arxiv.org/abs/2310.11865](http://arxiv.org/abs/2310.11865)

    这项研究提出了一种名为HybridTree的新方法，可以在混合数据上进行联邦树学习。通过利用树中的一致分割规则，参与方的知识可以被纳入树的较低层，从而实现高效的联邦学习。

    

    联邦学习作为一种有前景的分布式学习范式，可以促进多个参与方在不传输原始数据的情况下进行协作学习。然而，大多数现有的联邦学习研究集中在水平数据或垂直数据设置上，其中不同参与方的数据被认为来自相同的特征或样本空间。在实践中，常见的情况是混合数据设置，其中来自不同参与方的数据在特征和样本方面可能存在差异。为了解决这个问题，我们提出了HybridTree，一种在混合数据上进行联邦树学习的新方法。我们观察到树中存在一致的分割规则。借助这些分割规则，我们在理论上证明了参与方的知识可以被纳入树的较低层。基于我们的理论分析，我们提出了一种层级解决方案，不需要频繁的通信流量来训练一棵树。我们的实验证明了我们的方法在处理混合数据时的有效性和高效性。

    Federated learning has emerged as a promising distributed learning paradigm that facilitates collaborative learning among multiple parties without transferring raw data. However, most existing federated learning studies focus on either horizontal or vertical data settings, where the data of different parties are assumed to be from the same feature or sample space. In practice, a common scenario is the hybrid data setting, where data from different parties may differ both in the features and samples. To address this, we propose HybridTree, a novel federated learning approach that enables federated tree learning on hybrid data. We observe the existence of consistent split rules in trees. With the help of these split rules, we theoretically show that the knowledge of parties can be incorporated into the lower layers of a tree. Based on our theoretical analysis, we propose a layer-level solution that does not need frequent communication traffic to train a tree. Our experiments demonstrate 
    
[^28]: IMITATE: 临床先验指导的分层视觉语言预训练模型

    IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training. (arXiv:2310.07355v1 [cs.CV])

    [http://arxiv.org/abs/2310.07355](http://arxiv.org/abs/2310.07355)

    IMITATE是一种临床先验指导的分层视觉语言预训练模型。它利用医学报告的层级结构，从胸部X射线图像中提取多级视觉特征，并与分层医学报告中的描述性和结论性文本进行对齐。

    

    在医学视觉语言预训练（VLP）领域，人们致力于从临床报告和相关医学图像中提取文本和图像特征。然而，大多数现有的方法可能忽视了利用临床报告固有的层级结构的机会，这些报告通常被分为描述性内容的“发现”和结论性观察的“印象”。当前的医学VLP方法往往将报告简化为一个统一的实体或分散的标记，而没有利用这种丰富的、结构化的格式。在这项工作中，我们提出了一种新的临床先验指导的VLP框架，名为IMITATE，用于从医学报告中学习结构信息，并使用分层视觉语言对齐。该框架从胸部X射线（CXR）图像中提取多级视觉特征，并将这些特征与分层医学报告中的描述性和结论性文本分别对齐。

    In the field of medical Vision-Language Pre-training (VLP), significant efforts have been devoted to deriving text and image features from both clinical reports and associated medical images. However, most existing methods may have overlooked the opportunity in leveraging the inherent hierarchical structure of clinical reports, which are generally split into `findings' for descriptive content and `impressions' for conclusive observation. Instead of utilizing this rich, structured format, current medical VLP approaches often simplify the report into either a unified entity or fragmented tokens. In this work, we propose a novel clinical prior guided VLP framework named IMITATE to learn the structure information from medical reports with hierarchical vision-language alignment. The framework derives multi-level visual features from the chest X-ray (CXR) images and separately aligns these features with the descriptive and the conclusive text encoded in the hierarchical medical report. Furth
    
[^29]: CacheGen：用于语言模型应用的快速上下文加载

    CacheGen: Fast Context Loading for Language Model Applications. (arXiv:2310.07240v1 [cs.NI])

    [http://arxiv.org/abs/2310.07240](http://arxiv.org/abs/2310.07240)

    CacheGen是一种用于语言模型应用的技术，通过对上下文进行压缩来减少LLM的网络获取和处理延迟。

    

    随着大型语言模型（LLM）承担越来越复杂的任务，其输入将整合更长的上下文，以应对需要领域知识或用户特定的对话历史的问题。然而，使用长上下文对于响应式的LLM系统来说是一个挑战，因为在所有上下文被获取和LLM处理之前，无法生成任何内容。现有系统仅通过优化上下文处理的计算延迟（例如，通过缓存文本上下文的中间键值特征）来解决问题，但往往会导致上下文获取的网络延迟更长（例如，键值特征消耗的带宽比文本上下文大几个数量级）。本文介绍了CacheGen，以最小化LLM上下文获取和处理的延迟。CacheGen通过将长上下文的键值（KV）特征压缩为更紧凑的比特流表示，减少了传输所需的带宽。编码器结合了自适应量化和......

    As large language models (LLMs) take on more complex tasks, their inputs incorporate longer contexts to respond to questions that require domain knowledge or user-specific conversational histories. Yet, using long contexts poses a challenge for responsive LLM systems, as nothing can be generated until all the contexts are fetched to and processed by the LLM. Existing systems optimize only the computation delay in context processing (e.g., by caching intermediate key-value features of the text context) but often cause longer network delays in context fetching (e.g., key-value features consume orders of magnitude larger bandwidth than the text context).  This paper presents CacheGen to minimize the delays in fetching and processing contexts for LLMs. CacheGen reduces the bandwidth needed for transmitting long contexts' key-value (KV) features through a novel encoder that compresses KV features into more compact bitstream representations. The encoder combines adaptive quantization with a 
    
[^30]: 利用合成数据进行医学视觉-语言预训练：绕过对真实图像的需求

    Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images. (arXiv:2310.07027v1 [cs.CV])

    [http://arxiv.org/abs/2310.07027](http://arxiv.org/abs/2310.07027)

    本研究探讨了使用合成图像在医学VLP中的可行性和有效性，通过用真实医学报告生成的合成图像替换真实图像进行训练，并在图像分类、语义分割和目标检测任务中进行了实证评估。

    

    医学视觉-语言预训练(VLP)从医学图像和配对的放射学报告中联合学习表示。它通常需要大规模的图像-文本配对数据集，以实现图像编码器和文本编码器的有效预训练。文本引导生成模型的出现引发了一个引人注目的问题：是否可以仅使用从真实放射学报告中生成的合成图像来实现VLP，从而减轻了对大量配对和筛选图像-文本数据集的需要？在这项工作中，我们通过检查使用合成图像进行医学VLP的可行性和有效性来审查这个问题。我们用真实医学报告生成的合成图像替换真实医学图像。我们使用三种最先进的VLP算法专门在这些合成样本上进行训练。我们的经验评估涵盖了三个连续任务，即图像分类、语义分割和目标检测。

    Medical Vision-Language Pre-training (VLP) learns representations jointly from medical images and paired radiology reports. It typically requires large-scale paired image-text datasets to achieve effective pre-training for both the image encoder and text encoder. The advent of text-guided generative models raises a compelling question: Can VLP be implemented solely with synthetic images generated from genuine radiology reports, thereby mitigating the need for extensively pairing and curating image-text datasets? In this work, we scrutinize this very question by examining the feasibility and effectiveness of employing synthetic images for medical VLP. We replace real medical images with their synthetic equivalents, generated from authentic medical reports. Utilizing three state-of-the-art VLP algorithms, we exclusively train on these synthetic samples. Our empirical evaluation across three subsequent tasks, namely image classification, semantic segmentation and object detection, reveals
    
[^31]: 约束条件下的策略优化用于多功能安全强化学习

    Constraint-Conditioned Policy Optimization for Versatile Safe Reinforcement Learning. (arXiv:2310.03718v1 [cs.LG])

    [http://arxiv.org/abs/2310.03718](http://arxiv.org/abs/2310.03718)

    这个论文提出了一种约束条件下的策略优化框架，用于训练多功能安全强化学习智能体。通过引入多功能值估计和有条件的变分推理模块，该框架在训练效率和零-shot适应能力方面表现优于基准方法。

    

    安全强化学习（RL）专注于训练在预定义安全约束条件下能够最大化奖励的智能体。然而，在部署过程中，学习能够适应不同安全约束要求且无需重新训练的多功能安全策略仍然是一个较为未开发和具有挑战性的领域。在这项工作中，我们提出了多功能安全强化学习问题，并考虑了两个主要需求：训练效率和零-shot适应能力。为了解决这些问题，我们引入了Conditioned Constrained Policy Optimization（CCPO）框架，包括两个关键模块：（1）多功能值估计（VVE），用于在未见过的阈值条件下近似值函数，并且（2）有条件的变分推理（CVI），用于在策略优化中编码任意约束阈值。我们的大量实验表明，CCPO在安全和任务性能方面优于基准，并保持了对不同约束的零-shot适应能力。

    Safe reinforcement learning (RL) focuses on training reward-maximizing agents subject to pre-defined safety constraints. Yet, learning versatile safe policies that can adapt to varying safety constraint requirements during deployment without retraining remains a largely unexplored and challenging area. In this work, we formulate the versatile safe RL problem and consider two primary requirements: training efficiency and zero-shot adaptation capability. To address them, we introduce the Conditioned Constrained Policy Optimization (CCPO) framework, consisting of two key modules: (1) Versatile Value Estimation (VVE) for approximating value functions under unseen threshold conditions, and (2) Conditioned Variational Inference (CVI) for encoding arbitrary constraint thresholds during policy optimization. Our extensive experiments demonstrate that CCPO outperforms the baselines in terms of safety and task performance while preserving zero-shot adaptation capabilities to different constraint 
    
[^32]: 异方差拟合置信回归

    Heteroskedastic conformal regression. (arXiv:2309.08313v1 [stat.ML])

    [http://arxiv.org/abs/2309.08313](http://arxiv.org/abs/2309.08313)

    本文研究了使用标准化和Mondrian符合规范的方法如何构建自适应的预测区间，以解决回归问题中的异方差噪声。

    

    符合规范的预测以及特定的拆分符合规范的预测提供了一种无分布的方法来估计具有统计保证的预测区间。最近的研究表明，当专注于边际覆盖时，即在校准数据集上，该方法产生的预测区间平均包含预定义覆盖水平的真实值，拆分符合规范的预测可以产生最先进的预测区间。然而，这样的区间通常不是自适应的，这对于具有异方差噪声的回归问题可能是有问题的。本文试图阐明如何使用标准化和Mondrian符合规范的方法来构建自适应的预测区间。我们以系统的方式提出理论和实验结果来研究这些方法。

    Conformal prediction, and split conformal prediction as a specific implementation, offer a distribution-free approach to estimating prediction intervals with statistical guarantees. Recent work has shown that split conformal prediction can produce state-of-the-art prediction intervals when focusing on marginal coverage, i.e., on a calibration dataset the method produces on average prediction intervals that contain the ground truth with a predefined coverage level. However, such intervals are often not adaptive, which can be problematic for regression problems with heteroskedastic noise. This paper tries to shed new light on how adaptive prediction intervals can be constructed using methods such as normalized and Mondrian conformal prediction. We present theoretical and experimental results in which these methods are investigated in a systematic way.
    
[^33]: 具有差分隐私(分组)结果的因果推断

    Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])

    [http://arxiv.org/abs/2308.00957](http://arxiv.org/abs/2308.00957)

    本文提出了一种新的差分隐私机制"Cluster-DP"，它在保证隐私的同时利用数据的聚类结构，从而实现了更强的隐私保证和较低的方差，可以用于进行因果分析。

    

    从随机实验中估计因果效应只有在参与者同意透露他们可能敏感的响应时才可行。在确保隐私的许多方法中，标签差分隐私是一种广泛使用的算法隐私保证度量，可以鼓励参与者分享响应而不会面临去匿名化的风险。许多差分隐私机制会向原始数据集中注入噪音来实现这种隐私保证，这会增加大多数统计估计量的方差，使得精确测量因果效应变得困难：从差分隐私数据进行因果分析存在着固有的隐私-方差权衡。为了实现更强隐私保证的较低方差，我们提出了一种新的差分隐私机制"Cluster-DP"，它利用数据的任何给定的聚类结构，同时仍然允许对因果效应进行估计。

    Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
    
[^34]: 多任务学习用于雷达信号特征化

    Multi-task Learning for Radar Signal Characterisation. (arXiv:2306.13105v1 [eess.SP])

    [http://arxiv.org/abs/2306.13105](http://arxiv.org/abs/2306.13105)

    本文提出一种多任务学习的方法来解决雷达信号分类和特征化的问题，引入IQST等参考架构，通过回归和分类的多重任务优化提高性能，在合成雷达数据集上展示了良好的表现，并提供了首个雷达信号特征化基准测试样例。

    

    无论是民用还是军事应用，无线电信号识别都是至关重要的任务，对于未知信号的准确和及时的识别是频谱管理和电子战的重要组成部分。然而，在这个领域里，大部分的研究都专注于使用深度学习来进行调制分类，而没能充分研究信号特征化的任务。本文提出了一种多任务学习（MTL）的方法来应对雷达信号分类和特征化的问题，提出了 IQ Signal Transformer (IQST) 和其他参考架构，使得能够同时优化多重回归和分类任务。我们在一个合成雷达数据集上展示了我们提出的 MTL 模型的性能，同时提供了一个首次的雷达信号特征化基准测试样例。

    Radio signal recognition is a crucial task in both civilian and military applications, as accurate and timely identification of unknown signals is an essential part of spectrum management and electronic warfare. The majority of research in this field has focused on applying deep learning for modulation classification, leaving the task of signal characterisation as an understudied area. This paper addresses this gap by presenting an approach for tackling radar signal classification and characterisation as a multi-task learning (MTL) problem. We propose the IQ Signal Transformer (IQST) among several reference architectures that allow for simultaneous optimisation of multiple regression and classification tasks. We demonstrate the performance of our proposed MTL model on a synthetic radar dataset, while also providing a first-of-its-kind benchmark for radar signal characterisation.
    
[^35]: 任意维度等变神经网络

    Any-dimensional equivariant neural networks. (arXiv:2306.06327v1 [cs.LG])

    [http://arxiv.org/abs/2306.06327](http://arxiv.org/abs/2306.06327)

    该论文提出了一个新的方法，利用代数拓扑中的表示稳定性，可以定义出一个可以以任意维度为输入的等变神经网络。这种方法使用方便，只需指定网络架构和等变性的组，且在任何训练过程中都可以使用。

    

    传统的监督学习旨在通过将函数拟合到一组具有固定维度的输入/输出对来学习未知映射。然后，在相同维度的输入上定义拟合函数。然而，在许多情况下，未知映射以任意维度的输入作为输入；例如，定义在任意大小的图形上的图形参数和定义在任意数量粒子上的物理量。我们利用代数拓扑中的新现象——表示稳定性，来定义等变神经网络，可以使用固定维度的数据进行训练，然后在任意维度上扩展接受输入。我们的方法易于使用，只需要网络架构和等变性的组，并且可以与任何训练过程结合使用。我们提供了我们方法的简单开源实现，并提供了初步的数值实验。

    Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.
    
[^36]: 概率深度学习的量子核混合方法

    Quantum Kernel Mixtures for Probabilistic Deep Learning. (arXiv:2305.18204v1 [cs.LG])

    [http://arxiv.org/abs/2305.18204](http://arxiv.org/abs/2305.18204)

    本文提出了一种量子核混合方法，可以用于表示连续和离散随机变量的联合概率分布。该框架允许构建可微分的模型，适用于密度估计、推理和采样，以及各种机器学习任务，包括生成建模和判别学习。

    

    本文提出了一种新的概率深度学习方法——量子核混合，它是从量子密度矩阵的数学形式中推导出来的。该方法提供了一种简单而有效的机制，用于表示连续和离散随机变量的联合概率分布。该框架允许构建可微分的模型，用于密度估计、推理和采样，从而能够整合到端到端的深度神经模型中。通过这样做，我们提供了一种多功能的边际和联合概率分布表示，可以开发一种可微分的、组合的和可逆的推理过程，涵盖了广泛的机器学习任务，包括密度估计、判别学习和生成建模。我们通过两个示例来说明该框架的广泛适用性：一个图像分类模型，它可以自然地转化为条件生成模型，得益于量子核混合的表示能力。

    This paper presents a novel approach to probabilistic deep learning (PDL), quantum kernel mixtures, derived from the mathematical formalism of quantum density matrices, which provides a simpler yet effective mechanism for representing joint probability distributions of both continuous and discrete random variables. The framework allows for the construction of differentiable models for density estimation, inference, and sampling, enabling integration into end-to-end deep neural models. In doing so, we provide a versatile representation of marginal and joint probability distributions that allows us to develop a differentiable, compositional, and reversible inference procedure that covers a wide range of machine learning tasks, including density estimation, discriminative learning, and generative modeling. We illustrate the broad applicability of the framework with two examples: an image classification model, which can be naturally transformed into a conditional generative model thanks to
    
[^37]: FlightBERT++：一种非自回归多时域飞行轨迹预测框架

    FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory Prediction Framework. (arXiv:2305.01658v1 [cs.LG])

    [http://arxiv.org/abs/2305.01658](http://arxiv.org/abs/2305.01658)

    FlightBERT++提出了一种非自回归的多时域飞行轨迹预测框架，通过引入时域感知上下文生成器解决了误差累积和低效率的问题。

    

    飞行轨迹预测是空中交通管制中的重要任务，可以帮助空管员更安全高效地管理空域。现有方法通常采用自回归方式执行多时域飞行轨迹预测任务，容易出现误差累积和低效率问题。本文提出了一种新的框架，称为FlightBERT++，以i）直接以非自回归方式预测多时域飞行轨迹，和ii）改善FlightBERT框架中二进制编码（BE）表示的限制。具体而言，所提出的框架通过通用的编码器-解码器架构实现，其中编码器从历史观测中学习时空模式，而解码器预测未来时间步的飞行状态。与传统架构相比，额外的时域感知上下文生成器（HACG）专门设计考虑先前的时域。

    Flight Trajectory Prediction (FTP) is an essential task in Air Traffic Control (ATC), which can assist air traffic controllers to manage airspace more safely and efficiently. Existing approaches generally perform multi-horizon FTP tasks in an autoregressive manner, which is prone to suffer from error accumulation and low-efficiency problems. In this paper, a novel framework, called FlightBERT++, is proposed to i) forecast multi-horizon flight trajectories directly in a non-autoregressive way, and ii) improved the limitation of the binary encoding (BE) representation in the FlightBERT framework. Specifically, the proposed framework is implemented by a generalized Encoder-Decoder architecture, in which the encoder learns the temporal-spatial patterns from historical observations and the decoder predicts the flight status for the future time steps. Compared to conventional architecture, an extra horizon-aware contexts generator (HACG) is dedicatedly designed to consider the prior horizon 
    
[^38]: 正则化完整循环一致性GAN用于异常检测

    Regularized Complete Cycle Consistent GAN for Anomaly Detection. (arXiv:2304.07769v1 [cs.LG])

    [http://arxiv.org/abs/2304.07769](http://arxiv.org/abs/2304.07769)

    本研究提出了RCALAD方法，通过循环一致性和新的鉴别器增强了GAN在异常检测中的效果。同时，利用补充分布引导重建和引入新的异常评分进一步提高了模型性能。

    

    本研究提出了一种用于实际应用中异常检测的对抗性方法，通过重建误差中循环一致性利用生成对抗神经网络（GAN）的威力。以往的方法由于类别间精度高度差异而未被应用于所有类型的异常情况。RCALAD是一种旨在通过将新的鉴别器引入到结构中来解决这个问题的方法，从而实现更高效的训练过程。此外，RCALAD在输入空间中使用补充分布，将重建引导到正常数据分布，有效地将异常样本与其重建分离，进而实现更准确的异常检测。为了进一步提高模型的性能，引入了两个新的异常评分。在六个不同数据集的大量实验中对所提出的模型进行了全面评估，得出了展示出其优越性能的结果。

    This study presents an adversarial method for anomaly detection in real-world applications, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Previous methods suffer from the high variance between class-wise accuracy which leads to not being applicable for all types of anomalies. The proposed method named RCALAD tries to solve this problem by introducing a novel discriminator to the structure, which results in a more efficient training process. Additionally, RCALAD employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution, effectively separating anomalous samples from their reconstructions and facilitating more accurate anomaly detection. To further enhance the performance of the model, two novel anomaly scores are introduced. The proposed model has been thoroughly evaluated through extensive experiments on six various datasets, yielding results that demonst
    
[^39]: R语言的growclusters软件包

    The growclusters Package for R. (arXiv:2304.06145v1 [cs.MS])

    [http://arxiv.org/abs/2304.06145](http://arxiv.org/abs/2304.06145)

    R语言的growclusters软件包实现了增强版的k-means聚类算法，可以发现多组数据集中的局部聚类或分区，函数包含估计多元数据分区结构的功能，使用惩罚优化方法进行。并可创建可视化应用程序展示其操作和功能。

    

    growclusters软件包实现了一个增强版k-means聚类算法，可以发现多组数据集中的局部聚类或分区，每组数据的聚类中心都来源于一个全局分区。该软件包包含一些估计多元数据分区结构的函数。估计是基于贝叶斯非参数表述推导出的一种惩罚优化方法进行的。本文介绍了growclusters软件包的一些功能和能力，包括创建R Shiny应用程序以可视化展示growclusters软件包的操作和功能。

    The growclusters package for R implements an enhanced version of k-means clustering that allows discovery of local clusterings or partitions for a collection of data sets that each draw their cluster means from a single, global partition. The package contains functions to estimate a partition structure for multivariate data. Estimation is performed under a penalized optimization derived from Bayesian non-parametric formulations. This paper describes some of the functions and capabilities of the growclusters package, including the creation of R Shiny applications designed to visually illustrate the operation and functionality of the growclusters package.
    
[^40]: 基于递归神经网络的神经算子学习在动力系统中的应用及长时间积分问题解决

    Neural Operator Learning for Long-Time Integration in Dynamical Systems with Recurrent Neural Networks. (arXiv:2303.02243v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02243](http://arxiv.org/abs/2303.02243)

    本文提出了一种将神经算子和递归神经网络相结合的新型框架，解决了深度神经网络无法准确外推和误差积累的问题，在 Korteweg-de Vries 方程中表现出更好的精度和稳定性。

    

    相比传统科学计算方法，深度神经网络在模拟复杂动力系统方面具有计算成本降低、可以直接从观测数据进行训练等优势。然而，现有的方法在长时间积分中存在无法准确外推和误差积累的问题。本文通过将神经算子与递归神经网络相结合，构建出一种新颖有效的框架，提升了比现有技术更准确的积分。这个新型的混合模型基于算子学习，同时提供递归结构来捕捉时间依赖关系。实验结果表明，这个综合框架对于 Korteweg-de Vries 方程插值和外推均稳定解决了误差积累问题。

    Deep neural networks are an attractive alternative for simulating complex dynamical systems, as in comparison to traditional scientific computing methods, they offer reduced computational costs during inference and can be trained directly from observational data. Existing methods, however, cannot extrapolate accurately and are prone to error accumulation in long-time integration. Herein, we address this issue by combining neural operators with recurrent neural networks to construct a novel and effective architecture, resulting in superior accuracy compared to the state-of-the-art. The new hybrid model is based on operator learning while offering a recurrent structure to capture temporal dependencies. The integrated framework is shown to stabilize the solution and reduce error accumulation for both interpolation and extrapolation of the Korteweg-de Vries equation.
    
[^41]: 平移不变核函数的正交展开

    Orthonormal Expansions for Translation-Invariant Kernels. (arXiv:2206.08648v3 [math.CA] UPDATED)

    [http://arxiv.org/abs/2206.08648](http://arxiv.org/abs/2206.08648)

    该论文提出了一种傅里叶分析技术，用于从$\mathscr{L}_2(\mathbb{R})$的正交基中构建平移不变核函数的正交基展开，实现了马特尔核函数、柯西核函数和高斯核函数的明确展开表达式。

    

    我们提出了一种用于构建平移不变核函数的正交基展开的傅里叶分析技术，该技术利用$\mathscr{L}_2(\mathbb{R})$上的正交基，得到了实轴上所有半整数阶马特尔核函数、柯西核函数以及高斯核函数的明确展开表达式，分别由相关的拉盖尔函数、有理函数和厄米函数表示。

    We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\mathscr{L}_2(\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions.
    
[^42]: McDiarmid不等式的推广

    An extension of McDiarmid's inequality. (arXiv:1511.05240v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1511.05240](http://arxiv.org/abs/1511.05240)

    本文推广了McDiarmid不等式，使其适用于具有有界差异的函数，并进一步将结果推广到一般度量空间的集中性。

    

    我们使用推广论证推广McDiarmid不等式，使它适用于具有有界差异的函数，并且适用于高概率集合。这些函数集中于它们的条件期望周围。我们进一步将结果推广到一般度量空间的集中性。

    We generalize McDiarmid's inequality for functions with bounded differences on a high probability set, using an extension argument. Those functions concentrate around their conditional expectations. We further extend the results to concentration in general metric spaces.
    

