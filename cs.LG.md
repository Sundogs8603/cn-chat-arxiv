# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Critic-Actor for Average Reward MDPs with Function Approximation: A Finite-Time Analysis](https://rss.arxiv.org/abs/2402.01371) | 本论文提出了一个评论家-演员算法，解决了长期平均奖励设置中的函数逼近问题，并进行了有限时间分析。实验结果表明，我们的算法能够在评论家的均方误差上界为$\epsilon$的情况下，获得样本复杂度为$\mathcal{\tilde{O}}(\epsilon^{-2.08})$，优于演员-评论家算法的结果。 |
| [^2] | [Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations](https://rss.arxiv.org/abs/2402.01195) | 本文提出了使用条件化正则化流和主动学习的方法来解决粗粒化分子表示中的玻尔兹曼分布采样问题，相比传统的分子动力学模拟，该方法能够获得更高效的加速效果。 |
| [^3] | [Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models](https://arxiv.org/abs/2403.19521) | 通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。 |
| [^4] | [Enhancing Efficiency in Sparse Models with Sparser Selection](https://arxiv.org/abs/2403.18926) | 提出了一种新颖的MoE模型\tool，通过利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数，从而在减少MoE层计算负载50%以上的同时提高模型性能。 |
| [^5] | [Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images](https://arxiv.org/abs/2403.14547) | 本文提出了一种用于估计通道数据增强技术对遥感图像物理信息一致性影响的方法，以解决这一领域中存在的争议。 |
| [^6] | [Hierarchical NeuroSymbolic Approach for Action Quality Assessment](https://arxiv.org/abs/2403.13798) | 引入分层神经符号范式的动作质量评估方法，在跳水中取得了领先的表现，通过从视频数据中提取可解释符号并应用规则进行质量评估，优于端到端神经模型，同时实现了动作识别和时间分割，并生成详细报告。 |
| [^7] | [UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation](https://arxiv.org/abs/2403.07187) | UPS通过跨模态适应训练神经网络，将不同PDE统一到一致的表示空间，并在少样本下达到了强有力的实验结果，优于现有基线，实现了1D和2D数据集上的最先进结果。 |
| [^8] | [Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation](https://arxiv.org/abs/2402.18839) | 本文基于Flow Matching发展了条件生成理论，通过使用广义连续性方程的数学框架而非流匹配中的连续性方程，实现了一种新颖的流基条件分布生成方法。 |
| [^9] | [Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling](https://arxiv.org/abs/2402.18508) | 兰花引入了一种新的数据相关卷积机制，通过动态调整卷积核，实现了高表达能力和计算效率的平衡。 |
| [^10] | [DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning](https://arxiv.org/abs/2402.18137) | 本文提出了 DecisionNCE 框架，通过隐式偏好学习实体多模态表示，实现了提取任务进展信息和与语言指令对齐的有效方法 |
| [^11] | [Conformer: Embedding Continuous Attention in Vision Transformer for Weather Forecasting](https://arxiv.org/abs/2402.17966) | Conformer是一种用于天气预测的时空连续视觉Transformer，通过在多头注意力机制中实现连续性来学习时间上的连续天气演变。 |
| [^12] | [DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning](https://arxiv.org/abs/2402.17453) | DS-Agent是一个自动框架，结合了大型语言模型代理和案例推理，能够在数据科学任务中灵活利用专家知识并通过反馈机制持续改善性能 |
| [^13] | [Informed Meta-Learning](https://arxiv.org/abs/2402.16105) | 该研究提出了通知元学习这一新范式，旨在通过人类和机器之间的跨任务知识共享，提高数据效率和抵御观测噪声。 |
| [^14] | [EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems](https://arxiv.org/abs/2402.15164) | EasyRL4Rec是一个面向基于强化学习的推荐系统的用户友好和高效库，提供了多样化的RL环境、全面的核心模块、一致的评估标准和定制解决方案，旨在帮助简化模型开发并改善长期用户参与度。 |
| [^15] | [Average gradient outer product as a mechanism for deep neural collapse](https://arxiv.org/abs/2402.13728) | 本文通过提供证据表明，深度神经网络中的神经坍塌主要是通过平均梯度外积进行深度特征学习的，权重的奇异结构与AGOP高度相关，导致类内变异坍塌。 |
| [^16] | [Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers](https://arxiv.org/abs/2402.13380) | 这项研究利用变压器模型解决混合整数规划问题，首次采用变压器预测二进制变量，提出的算法在解决时间上超越了传统CPLEX和LSTM。 |
| [^17] | [PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling](https://arxiv.org/abs/2402.12503) | PARCv2通过引入微分算子扩展了PARC模型，用于模拟不稳定、瞬态和传输主导系统的时空动力学。 |
| [^18] | [Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment](https://arxiv.org/abs/2402.10207) | 本文介绍了Rewards-in-Context（RiC）方法，该方法通过多个奖励条件控制基础模型的响应，并应用有监督的微调进行对齐。它具有简单性和适应性，并支持在推理时动态调整用户偏好。 |
| [^19] | [GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering](https://arxiv.org/abs/2402.10128) | 本研究引入了GES（广义指数喷洒），一种利用广义指数函数来建模3D场景的新表示方法，可以显著提高3D重建和生成的效率。相比于传统的高斯喷洒方法，GES所需的粒子数量更少，能更准确地表示具有锐利边缘的信号。 |
| [^20] | [Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic](https://arxiv.org/abs/2402.09469) | 本研究探索了神经网络和Transformer在数学推理和模运算中的潜力。我们分析了单隐藏层神经网络和单层Transformer在解决复杂代数学习任务中的特征。阐明了边缘最大化原则对单隐藏层神经网络的影响。 |
| [^21] | [A Distributional Analogue to the Successor Representation](https://arxiv.org/abs/2402.08530) | 本文提出了一种新的分布式强化学习方法，它通过分离转换结构和奖励，引入了分布式后继度量来描述行为的分布式后果。在实验中展示了该方法的实用性，特别是在零样本风险敏感策略评估方面。 |
| [^22] | [Verified Multi-Step Synthesis using Large Language Models and Monte Carlo Tree Search](https://arxiv.org/abs/2402.08147) | 本文提出了一种使用蒙特卡洛树搜索引导大型语言模型生成验证程序的方法，通过结合验证器的反馈和LLM先验知识提高了合成能力，实验证明这种方法在一组验证编程问题上的性能优于基本模型和具有插件的ChatGPT4。 |
| [^23] | [Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF](https://arxiv.org/abs/2402.06886) | 本文提出了一种基于惩罚的方法来解决Bilevel强化学习和RLHF问题，这是首个有原则的算法框架。通过理论分析和实验证明了算法的有效性。 |
| [^24] | [A self-supervised framework for learning whole slide representations](https://arxiv.org/abs/2402.06188) | 这个论文提出了一个自监督学习框架（S3L），用于学习整个切片的表示。它结合了变压器模型的视觉和语言建模策略，通过生成配对视图进行自监督学习，以实现高质量的WSI视觉特征学习。 |
| [^25] | [Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss](https://arxiv.org/abs/2402.06187) | Premier-TACO是一种多任务特征表示学习方法，通过预训练通用特征表示，并引入负例抽样策略来提高时序行动对比学习的计算效率，从而显著增强了对新颖动作的少样本模仿学习的效果。 |
| [^26] | [The last Dance : Robust backdoor attack via diffusion models and bayesian approach](https://arxiv.org/abs/2402.05967) | 本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。 |
| [^27] | [Nonparametric Instrumental Variable Regression through Stochastic Approximate Gradients](https://arxiv.org/abs/2402.05639) | 本文提出了一种通过随机近似梯度最小化投影群体风险的新型非参数仪器变量回归框架，并通过理论和实证实验证明了其竞争性能。此外，本文还处理了二元结果的情况，取得了有希望的结果。 |
| [^28] | [QGFN: Controllable Greediness with Action Values](https://arxiv.org/abs/2402.05234) | 本文提出了一种新的算法QGFN，通过将GFN策略与动作值估计相结合，可以生成更多高奖励的样本而不牺牲多样性。 |
| [^29] | [Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data](https://arxiv.org/abs/2402.03614) | 本研究提出了一种新的贝叶斯VAR模型，利用分层图先验推断二元格兰杰因果图的后验概率。相比竞争方法，我们的方法在不确定性量化、超参数数量和稀疏多变量时间序列数据上都表现更好。 |
| [^30] | [Consistent Validation for Predictive Methods in Spatial Settings](https://arxiv.org/abs/2402.03527) | 本论文研究了在空间环境中验证预测方法的一致性问题，提出了一种能够处理不匹配情况的方法。 |
| [^31] | [Isotropy, Clusters, and Classifiers](https://arxiv.org/abs/2402.03191) | 同性质的嵌入空间对聚类和线性分类目标具有负面影响，这一事实得到了本文的实证支持，并对文献中的先前结果有所启示。 |
| [^32] | [Dual Lagrangian Learning for Conic Optimization](https://arxiv.org/abs/2402.03086) | 本文介绍了对偶拉格朗日学习（DLL）方法，通过结合锥对偶理论和机器学习模型表示能力，在参数化线性和非线性锥优化问题上提供了有效的拉格朗日对偶界限，证明了其性能在优化问题上接近最优解的0.5%。 |
| [^33] | [Decoding-time Realignment of Language Models](https://arxiv.org/abs/2402.02992) | 本研究提出了解码时间对齐（DeRa）方法，可以在不重新训练模型的情况下探索和评估不同的规则化强度，从而对齐语言模型和人类偏好。 |
| [^34] | [MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters](https://arxiv.org/abs/2402.02342) | MetaOptimize是一个框架，通过动态调整学习率来优化机器学习算法中的元参数，以提高训练效率和模型性能。 |
| [^35] | [Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling](https://arxiv.org/abs/2402.00522) | 本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。 |
| [^36] | [Robustly overfitting latents for flexible neural image compression](https://arxiv.org/abs/2401.17789) | 这项研究提出了一种鲁棒的过拟合潜变量方法来改进神经图像压缩模型，通过使用SGA+，可以显著提高性能并减少对超参数选择的敏感性。 |
| [^37] | [The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting](https://arxiv.org/abs/2401.11929) | 本研究通过调查条件相关性和自相关性，揭示了输入数据中的冗余性，并提出了HDformer，这是一种轻量级的Transformer变种，利用蒸馏技术和快速网络连接层来降低模型复杂性。 |
| [^38] | [Efficient Out-of-Distribution Detection with Prototypical Semi-Supervised Learning and Foundation Models](https://arxiv.org/abs/2311.17093) | 本文介绍了一种新的改进的半监督学习方法，利用冻结的基础模型作为神经网络骨干，在半监督学习和超出分布检测方面取得了优越的表现，并引入了新的预训练技术、损失函数和原型选择方法。 |
| [^39] | [On the Theory of Risk-Aware Agents: Bridging Actor-Critic and Economics](https://arxiv.org/abs/2310.19527) | 通过应用期望效用假设，本文揭示了风险中性和风险感知RL目标实际上可以通过使用指数效用函数的期望效用最大化来解释，提出了双演员-评论家（DAC）算法，为风险感知的RL算法贡献了框架。 |
| [^40] | [Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space.](http://arxiv.org/abs/2401.13530) | 本文研究了在Wasserstein概率空间上的Riemannian SGD和SVRG流的优化方法，通过构建随机微分方程来丰富Wasserstein空间中的连续优化方法。 |
| [^41] | [Towards Principled Graph Transformers.](http://arxiv.org/abs/2401.10119) | 边缘变换器是一个全局注意力模型，它具有至少3-WL的表达能力，能够在预测性能上超过其他架构，而不依赖于位置或结构编码。 |
| [^42] | [DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning.](http://arxiv.org/abs/2401.09243) | 本文介绍了DiffClone，一种通过扩散驱动的策略学习增强行为克隆代理的离线算法。在真实的在线物理机器人上的实验表明，采用MOCO微调的ResNet50的效果最好。 |
| [^43] | [Detecting Out-of-Distribution Through the Lens of Neural Collapse.](http://arxiv.org/abs/2311.01479) | 通过观察到的群内特征聚集和群外特征离散的性质，本论文提出了一种基于特征和权重向量接近程度的神经坍塌（NC-OOD）检测器来提高OAD检测的泛化能力，并取得了最先进的效果。 |
| [^44] | [Proportional Fairness in Clustering: A Social Choice Perspective.](http://arxiv.org/abs/2310.18162) | 在这篇论文中，我们研究了比例聚类问题，将其与计算社会选择中的多赢家投票领域相关联。我们发现满足Brill和Peters的比例概念的任何聚类都能同时获得Chen等人的比例公平性、个体公平性和核心的最佳近似。我们还研究了更强的比例代表性概念，并展示了这些更强概念对应的近似。 |
| [^45] | [Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs.](http://arxiv.org/abs/2310.10107) | 本文分析了后验采样学习算法在序列化POMDPs中的遗憾性能，并在一定条件下提供了改进的多项式贝叶斯遗憾界。 |
| [^46] | [A Carbon Tracking Model for Federated Learning: Impact of Quantization and Sparsification.](http://arxiv.org/abs/2310.08087) | 本文提出了一个碳追踪模型，用于实时监测联邦学习系统的能源消耗和碳足迹影响。通过对不同的计算和通信高效联邦学习方法进行定量评估，为减少能源消耗和碳排放提供了参考。 |
| [^47] | [On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism.](http://arxiv.org/abs/2310.07852) | 本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。 |
| [^48] | [Universal Graph Random Features.](http://arxiv.org/abs/2310.04859) | 本文提出了一种新的准蒙特卡罗机制，称为排斥随机游走，通过改进图的采样，提高了统计估计器的集中度。该机制在估计图内核、PageRank向量和图形浓度等方面展示了有效性。 |
| [^49] | [Repelling Random Walks.](http://arxiv.org/abs/2310.04854) | 抵制随机游走是一种新的准蒙特卡罗机制，通过在图上的行走者之间引入相关性，能够更高效地探索图并提高统计估计的集中度，同时保持其无偏性。此机制在估计图核、PageRank向量和图元浓度等多个领域都展示了其有效性，并提供了详细的实验评估和理论保证。 |
| [^50] | [Perfect Alignment May be Poisonous to Graph Contrastive Learning.](http://arxiv.org/abs/2310.03977) | 本研究探讨了图形对比学习中增强方法和下游性能的关系，并发现图形对比学习主要通过分离不同类别的节点来为下游任务做出贡献。 |
| [^51] | [Tackling Hybrid Heterogeneity on Federated Optimization via Gradient Diversity Maximization.](http://arxiv.org/abs/2310.02702) | 本文探讨了混合异构性如何影响联邦优化，并提出了一种通过最大化梯度多样性来减轻混合异构性负面影响的方法。 |
| [^52] | [HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning.](http://arxiv.org/abs/2310.00113) | HyperMask是一种用于持续学习的方法，它使用基于超网络的掩码来训练一个单一网络，以克服人工神经网络在多任务上的灾难性遗忘问题。 |
| [^53] | [Adversarial Imitation Learning from Visual Observations using Latent Information.](http://arxiv.org/abs/2309.17371) | 本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。 |
| [^54] | [Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank.](http://arxiv.org/abs/2309.15560) | 研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。 |
| [^55] | [Provable Training for Graph Contrastive Learning.](http://arxiv.org/abs/2309.13944) | 图对比学习中，我们发现训练存在不平衡的问题，为此我们提出了“节点紧凑性”度量来指导训练。 |
| [^56] | [Des-q: a quantum algorithm to construct and efficiently retrain decision trees for regression and binary classification.](http://arxiv.org/abs/2309.09976) | Des-q是一种量子算法，用于在回归和二分类任务中构建和重新训练决策树。它显著减少了树重新训练所需的时间复杂度，并且能够处理新样本的加载时间。该算法通过 k 分段线性树分裂来构建决策树，将数据划分为不同的子空间。 |
| [^57] | [Critical Learning Periods Emerge Even in Deep Linear Networks.](http://arxiv.org/abs/2308.12221) | 即使在深度线性网络中也存在关键学习期，这些关键学习期取决于模型的深度和数据分布的结构。 |
| [^58] | [A Quantum Approximation Scheme for k-Means.](http://arxiv.org/abs/2308.08167) | 这个论文提出了一个量子逼近方案，用于解决经典的k-Means聚类问题，该方案的运行时间与数据点的数量具有多对数依赖关系，并且能够在高概率下输出一个近似最优解，这是第一个具有多对数运行时间的量子算法，并且能够提供一个可证明的逼近保证。 |
| [^59] | [Submodular Reinforcement Learning.](http://arxiv.org/abs/2307.13372) | 子模块强化学习(SubRL)是一种用于优化非可加奖励的范式，通过子模块集合函数来建模递减回报。这篇论文提出了SubRL的简单策略梯度算法SubPO，可以用于处理这种类型的奖励。 |
| [^60] | [Amortized Variational Inference: When and Why?.](http://arxiv.org/abs/2307.11018) | 本文研究了分期变分推断作为近似后验推断的一种通用替代方法，探讨了何时能够达到与传统的因子化变分推断相同的最优解。 |
| [^61] | [Nonlinear Meta-Learning Can Guarantee Faster Rates.](http://arxiv.org/abs/2307.10870) | 非线性元学习可以保证更快的收敛速度。 |
| [^62] | [TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning.](http://arxiv.org/abs/2306.13229) | 本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。 |
| [^63] | [Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity.](http://arxiv.org/abs/2306.11626) | 本论文研究了正则化鲁棒MDP问题和风险敏感MDP问题的相关性，并提出了有效的学习算法和样本复杂度分析。 |
| [^64] | [Optimal transport for automatic alignment of untargeted metabolomic data.](http://arxiv.org/abs/2306.03218) | 本文提出了一种名为GromovMatcher的算法，通过使用最优输运自动合并LC-MS数据集，可提高数据对齐的准确性和鲁棒性，有效解决代谢组学数据合并的挑战。 |
| [^65] | [Improving selective classification performance of deep neural networks through post-hoc logit normalization and temperature scaling.](http://arxiv.org/abs/2305.15508) | 本文提出了一种$p$-NormSoftmax的事后置信度估计器来提高深度神经网络的选择分类性能。 |
| [^66] | [Cost-aware learning of relevant contextual variables within Bayesian optimization.](http://arxiv.org/abs/2305.14120) | 本文提出一种基于代价感知的模型选择BO方法SADCBO，通过对后验代理模型的敏感性分析来学习关于环境的相关情境信息，并通过平均模型预测来最小化优化代价，在实验中表现出卓越的性能。 |
| [^67] | [Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling.](http://arxiv.org/abs/2305.09993) | Reprompting是一种无需人类干预的算法，通过迭代采样新配方解决多步推理任务，比人类编写的思维链提示表现更好，还可以提高较弱模型的性能。 |
| [^68] | [Sparsity in neural networks can increase their privacy.](http://arxiv.org/abs/2304.07234) | 神经网络的稀疏性能提高隐私性并保持性能表现 |
| [^69] | [First-order methods for Stochastic Variational Inequality problems with Function Constraints.](http://arxiv.org/abs/2304.04778) | 本文提出了一种新的一阶方法，适用于具有随机算子和/或随机约束的带函数约束的变分不等式问题，当FCVI问题是确定性非光滑的或随机的时，这些方法可以实现最优算子或样本复杂性。 |
| [^70] | [Leveraging joint sparsity in hierarchical Bayesian learning.](http://arxiv.org/abs/2303.16954) | 本文提出了一种分层贝叶斯学习方法，用于从多个测量向量中推断联合稀疏的参数向量，该方法使用共同的伽马分布超参数来强制联合稀疏性，并在实验中进行了验证。 |
| [^71] | [Heart Murmur and Abnormal PCG Detection via Wavelet Scattering Transform & a 1D-CNN.](http://arxiv.org/abs/2303.11423) | 该研究提出了一种小波散射变换和1D-CNN深度学习技术结合的心杂音自动检测方法，可实现97.98%的高准确率。 |
| [^72] | [Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation.](http://arxiv.org/abs/2303.08777) | 本文提出通过模型选择和交叉验证风险估计来学习的一般方法，并建立了无分布偏差界，比经验风险最小化方法更紧密，在一些情况下表现更优。 |
| [^73] | [Partial Neural Optimal Transport.](http://arxiv.org/abs/2303.07988) | 我们提出了一种新的神经方法来计算部分最优输运映射，并在合成例子上进行了测试。 |
| [^74] | [An Asymptotically Optimal Algorithm for the Convex Hull Membership Problem.](http://arxiv.org/abs/2302.02033) | 本研究提出了一个名为Thompson-CHM的渐近最优算法，用于解决凸包成员问题，且将算法扩展到了一维和多维环境中。该算法基于模块化设计，包括停止规则和采样规则，并通过数值实验验证了理论结果的准确性。 |
| [^75] | [Average-Constrained Policy Optimization.](http://arxiv.org/abs/2302.00808) | 本研究提出了一种新的基于函数逼近算法的带平均标准约束 MDP 的策略优化算法，具有较好的性能表现。 |
| [^76] | [RFold: RNA Secondary Structure Prediction with Decoupled Optimization.](http://arxiv.org/abs/2212.14041) | 所提出的RFold方法采用解耦优化过程和注意力机制进行简单又有效的RNA二级结构预测，具有较高的准确性和速度。 |
| [^77] | [Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework.](http://arxiv.org/abs/2207.01955) | 本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。 |

# 详细

[^1]: Critic-Actor算法在平均奖励MDPs中的函数逼近问题：有限时间分析

    Critic-Actor for Average Reward MDPs with Function Approximation: A Finite-Time Analysis

    [https://rss.arxiv.org/abs/2402.01371](https://rss.arxiv.org/abs/2402.01371)

    本论文提出了一个评论家-演员算法，解决了长期平均奖励设置中的函数逼近问题，并进行了有限时间分析。实验结果表明，我们的算法能够在评论家的均方误差上界为$\epsilon$的情况下，获得样本复杂度为$\mathcal{\tilde{O}}(\epsilon^{-2.08})$，优于演员-评论家算法的结果。

    

    最近，关于两个时间尺度演员-评论家算法的渐近和非渐近收敛分析的研究工作非常活跃，其中演员的更新速度比评论家慢。在最近的一项工作中，提出了一个评论家-演员算法，用于无限时域折扣成本设置中的查找表情况，其中演员和评论家的时间尺度相反，并给出了渐近收敛分析。在我们的工作中，我们首次提出了一个具有函数逼近的评论家-演员算法，并在长期平均奖励设置中进行了首次有限时间（非渐近）分析。我们得到了最优的学习速率，并证明了我们的算法从评论家的均方误差上界为$\epsilon$，其样本复杂度为$\mathcal{\tilde{O}}(\epsilon^{-2.08})$，此结果比演员-评论家算法获得的结果要好。

    In recent years, there has been a lot of research work activity focused on carrying out asymptotic and non-asymptotic convergence analyses for two-timescale actor critic algorithms where the actor updates are performed on a timescale that is slower than that of the critic. In a recent work, the critic-actor algorithm has been presented for the infinite horizon discounted cost setting in the look-up table case where the timescales of the actor and the critic are reversed and asymptotic convergence analysis has been presented. In our work, we present the first critic-actor algorithm with function approximation and in the long-run average reward setting and present the first finite-time (non-asymptotic) analysis of such a scheme. We obtain optimal learning rates and prove that our algorithm achieves a sample complexity of $\mathcal{\tilde{O}}(\epsilon^{-2.08})$ for the mean squared error of the critic to be upper bounded by $\epsilon$ which is better than the one obtained for actor-critic
    
[^2]: 条件化正则化流用于粗粒化分子表示的主动学习

    Conditional Normalizing Flows for Active Learning of Coarse-Grained Molecular Representations

    [https://rss.arxiv.org/abs/2402.01195](https://rss.arxiv.org/abs/2402.01195)

    本文提出了使用条件化正则化流和主动学习的方法来解决粗粒化分子表示中的玻尔兹曼分布采样问题，相比传统的分子动力学模拟，该方法能够获得更高效的加速效果。

    

    高效采样分子系统的玻尔兹曼分布是一个长期存在的挑战。最近，与生成长时间分子动力学模拟不同，生成机器学习方法如正则化流被用于直接学习玻尔兹曼分布，而不需要样本。然而，这种方法容易出现模式崩溃，因此常常无法探索全部的构型空间。在这项工作中，我们将问题分为两个层次，细粒度和粗粒度自由度。在粗粒化空间上条件化正则化流可以产生两个层次之间的概率连接。为了探索构型空间，我们采用了粗粒化模拟与主动学习的方法，可以在必要时更新流并进行全原子势能评估。以丙氨酸二肽为例，我们展示了我们的方法相对于分子动力学模拟的加速效果。

    Efficient sampling of the Boltzmann distribution of molecular systems is a long-standing challenge. Recently, instead of generating long molecular dynamics simulations, generative machine learning methods such as normalizing flows have been used to learn the Boltzmann distribution directly, without samples. However, this approach is susceptible to mode collapse and thus often does not explore the full configurational space. In this work, we address this challenge by separating the problem into two levels, the fine-grained and coarse-grained degrees of freedom. A normalizing flow conditioned on the coarse-grained space yields a probabilistic connection between the two levels. To explore the configurational space, we employ coarse-grained simulations with active learning which allows us to update the flow and make all-atom potential energy evaluations only when necessary. Using alanine dipeptide as an example, we show that our methods obtain a speedup to molecular dynamics simulations of
    
[^3]: 解释基于Transformer模型的语言模型在事实回忆中的关键机制

    Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models

    [https://arxiv.org/abs/2403.19521](https://arxiv.org/abs/2403.19521)

    通过深入研究Transformer-based语言模型在事实回忆任务中的机制，我们发现了零/少次样本情况下的特定任务头、MLP层和残差流的功能，以及抗过度自信机制。

    

    本文深入探讨了Transformer-based语言模型在事实回忆任务中所采用的机制。在零次样本情况下，给定类似“法国的首都是”的提示，特定任务的注意力头会从上下文中提取主题实体，如“法国”，并将其传递给后续的MLP以回忆所需的答案，如“巴黎”。我们引入了一种新颖的分析方法，旨在将MLP的输出分解为人类可理解的组件。通过这种方法，我们量化了跟随这些特定任务头的MLP层的功能。在残差流中，它会擦除或放大来自各个头的信息。此外，它会生成一个组件，将残差流重新定向到预期答案的方向。这些零次机制也适用于少次样本情况。此外，我们观察到一种广泛存在的抗过度自信机制。

    arXiv:2403.19521v1 Announce Type: cross  Abstract: In this paper, we deeply explore the mechanisms employed by Transformer-based language models in factual recall tasks. In zero-shot scenarios, given a prompt like "The capital of France is," task-specific attention heads extract the topic entity, such as "France," from the context and pass it to subsequent MLPs to recall the required answer such as "Paris." We introduce a novel analysis method aimed at decomposing the outputs of the MLP into components understandable by humans. Through this method, we quantify the function of the MLP layer following these task-specific heads. In the residual stream, it either erases or amplifies the information originating from individual heads. Moreover, it generates a component that redirects the residual stream towards the direction of its expected answer. These zero-shot mechanisms are also employed in few-shot scenarios. Additionally, we observed a widely existent anti-overconfidence mechanism in 
    
[^4]: 用更稀疏的选择提高稀疏模型的效率

    Enhancing Efficiency in Sparse Models with Sparser Selection

    [https://arxiv.org/abs/2403.18926](https://arxiv.org/abs/2403.18926)

    提出了一种新颖的MoE模型\tool，通过利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数，从而在减少MoE层计算负载50%以上的同时提高模型性能。

    

    稀疏模型，包括稀疏的专家混合（MoE）模型，已经成为缩放Transformer模型的有效方法。然而，它们通常存在计算效率低的问题，因为大量参数通过将值乘以零或低激活值无谓参与计算。为了解决这一问题，我们提出了一种名为\tool 的新颖MoE模型，旨在提升稀疏MoE模型的功效和效率。 \tool 利用小型专家和基于阈值的路由器，使标记能够选择性地仅涉及到必要的参数。我们在语言建模和机器翻译任务上进行了大量实验，结果表明\tool 可以在不牺牲性能的情况下，将MoE层的计算负载减少50\%以上，同时提高模型性能。此外，我们展示了\tool 的通用性，通过将其应用于密集模型，在推断期间实现稀疏计算。

    arXiv:2403.18926v1 Announce Type: cross  Abstract: Sparse models, including sparse Mixture-of-Experts (MoE) models, have emerged as an effective approach for scaling Transformer models. However, they often suffer from computational inefficiency since a significant number of parameters are unnecessarily involved in computations via multiplying values by zero or low activation values. To address this issue, we present \tool, a novel MoE designed to enhance both the efficacy and efficiency of sparse MoE models. \tool leverages small experts and a threshold-based router to enable tokens to selectively engage only essential parameters. Our extensive experiments on language modeling and machine translation tasks demonstrate that \tool can enhance model performance while decreasing the computation load at MoE layers by over 50\% without sacrificing performance. Furthermore, we present the versatility of \tool by applying it to dense models, enabling sparse computation during inference. We pro
    
[^5]: 估计通道数据增强对遥感图像物理信息一致性的影响

    Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images

    [https://arxiv.org/abs/2403.14547](https://arxiv.org/abs/2403.14547)

    本文提出了一种用于估计通道数据增强技术对遥感图像物理信息一致性影响的方法，以解决这一领域中存在的争议。

    

    数据增强在深度学习方法中发挥着重要作用，特别是通道变换被整合到遥感图像分类任务的数据增强流程中。本文提出一种方法，用于估计通道增强技术是否会影响遥感图像的物理信息，以解决人们对其在遥感图像上的适用性存在争议的问题。

    arXiv:2403.14547v1 Announce Type: cross  Abstract: The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification. In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks. However, contradicting beliefs exist about their proper applications to RS images. A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures). To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images. To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject
    
[^6]: 分层神经符号方法用于动作质量评估

    Hierarchical NeuroSymbolic Approach for Action Quality Assessment

    [https://arxiv.org/abs/2403.13798](https://arxiv.org/abs/2403.13798)

    引入分层神经符号范式的动作质量评估方法，在跳水中取得了领先的表现，通过从视频数据中提取可解释符号并应用规则进行质量评估，优于端到端神经模型，同时实现了动作识别和时间分割，并生成详细报告。

    

    动作质量评估（AQA）应用计算机视觉定量评估人类动作的表现或执行。当前的AQA方法是端到端的神经模型，缺乏透明度并且易受偏见，因为它们是基于主观人类判断作为地面真相进行训练的。为了解决这些问题，我们介绍了一种用于AQA的神经符号范式，该方法使用神经网络从视频数据中抽象出可解释的符号，并通过将规则应用于这些符号进行质量评估。我们以跳水为案例研究。我们发现领域专家更喜欢我们的系统，并发现其比纯神经方法更具信息量。我们的系统还实现了最先进的动作识别和时间分割，并自动生成了一份详细报告，将跳水分解为其元素，并提供带有视觉证据的客观评分。经一组领域专家验证，

    arXiv:2403.13798v1 Announce Type: cross  Abstract: Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, t
    
[^7]: UPS: 通过跨模态适应实现偏微分方程求解的基础模型

    UPS: Towards Foundation Models for PDE Solving via Cross-Modal Adaptation

    [https://arxiv.org/abs/2403.07187](https://arxiv.org/abs/2403.07187)

    UPS通过跨模态适应训练神经网络，将不同PDE统一到一致的表示空间，并在少样本下达到了强有力的实验结果，优于现有基线，实现了1D和2D数据集上的最先进结果。

    

    我们介绍了UPS（统一PDE求解器），这是一种有效的数据高效方法，用于解决不同域、维度和分辨率上定义的各种时空PDE。UPS将不同的PDE统一到一致的表示空间中，并使用将LLMs与特定域神经算子相结合的统一网络架构处理各种PDE数据集合。我们通过两阶段的跨模态适应过程训练网络，利用模态对齐和多任务学习的思想。通过从预训练的LLMs进行调整并利用文本形式的元信息，我们能够使用比以前的方法少得多的训练样本，并获得强有力的实证结果。UPS在PDEBench的广泛1D和2D数据集上明显优于现有基线，对考虑的10个任务中的8个任务达到了最先进的结果。与此同时，它能够少样本快速转移至不同的PDE。

    arXiv:2403.07187v1 Announce Type: new  Abstract: We introduce UPS (Unified PDE Solver), an effective and data-efficient approach to solve diverse spatiotemporal PDEs defined over various domains, dimensions, and resolutions. UPS unifies different PDEs into a consistent representation space and processes diverse collections of PDE data using a unified network architecture that combines LLMs with domain-specific neural operators. We train the network via a two-stage cross-modal adaptation process, leveraging ideas of modality alignment and multi-task learning. By adapting from pretrained LLMs and exploiting text-form meta information, we are able to use considerably fewer training samples than previous methods while obtaining strong empirical results. UPS outperforms existing baselines, often by a large margin, on a wide range of 1D and 2D datasets in PDEBench, achieving state-of-the-art results on 8 of 10 tasks considered. Meanwhile, it is capable of few-shot transfer to different PDE f
    
[^8]: 扩展流匹配：具有广义连续性方程的条件生成方法

    Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation

    [https://arxiv.org/abs/2402.18839](https://arxiv.org/abs/2402.18839)

    本文基于Flow Matching发展了条件生成理论，通过使用广义连续性方程的数学框架而非流匹配中的连续性方程，实现了一种新颖的流基条件分布生成方法。

    

    条件生成任务是生成模型中最重要的应用之一，迄今为止已经开发了许多基于著名扩散模型的方法，其中以基于引导的无分类器方法为首。然而，基于引导的方法的理论不仅要求用户微调“引导强度”，而且其目标向量场不一定对应于训练中使用的条件分布。本文基于流匹配发展了条件生成理论，流匹配是扩散方法的当前强大竞争者之一。受将概率路径解释为路径空间上的分布的启发，我们建立了一个新颖的流基条件分布生成理论，通过使用广义连续性方程的数学框架而不是流匹配中的连续性方程。这一理论自然地推导出一种方法

    arXiv:2402.18839v1 Announce Type: new  Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method th
    
[^9]: 兰花：灵活且数据相关的卷积用于序列建模

    Orchid: Flexible and Data-Dependent Convolution for Sequence Modeling

    [https://arxiv.org/abs/2402.18508](https://arxiv.org/abs/2402.18508)

    兰花引入了一种新的数据相关卷积机制，通过动态调整卷积核，实现了高表达能力和计算效率的平衡。

    

    在深度学习不断发展的格局中，平衡表达能力与计算效率的模型已经变得至关重要。本文介绍了一种名为兰花（Orchid）的新型架构，通过包含一种新的数据相关卷积机制来重新构想序列建模。兰花旨在解决传统注意力机制固有的限制，特别是它们的二次复杂性，同时不影响捕捉远程依赖性和上下文学习的能力。兰花的核心是数据相关卷积层，它利用专门的条件化神经网络根据输入数据动态调整其卷积核。我们设计了两个简单的条件化网络，以在自适应卷积操作中维持平移等变性。数据相关卷积核的动态特性，加上门控操作，赋予了兰花高表达能力，同时维持了计算效率。

    arXiv:2402.18508v1 Announce Type: new  Abstract: In the rapidly evolving landscape of deep learning, the quest for models that balance expressivity with computational efficiency has never been more critical. This paper introduces Orchid, a novel architecture that reimagines sequence modeling by incorporating a new data-dependent convolution mechanism. Orchid is designed to address the inherent limitations of traditional attention mechanisms, particularly their quadratic complexity, without compromising the ability to capture long-range dependencies and in-context learning. At the core of Orchid lies the data-dependent convolution layer, which dynamically adjusts its kernel conditioned on input data using a dedicated conditioning neural network. We design two simple conditioning networks that maintain shift equivariance in the adaptive convolution operation. The dynamic nature of data-dependent convolution kernel, coupled with gating operations, grants Orchid high expressivity while mai
    
[^10]: DecisionNCE: 通过隐式偏好学习实体多模态表示

    DecisionNCE: Embodied Multimodal Representations via Implicit Preference Learning

    [https://arxiv.org/abs/2402.18137](https://arxiv.org/abs/2402.18137)

    本文提出了 DecisionNCE 框架，通过隐式偏好学习实体多模态表示，实现了提取任务进展信息和与语言指令对齐的有效方法

    

    多模态预训练已被证明是自主机器人中表示学习的三大目标：1）提取局部和全局任务进展信息；2）强化视觉表示的时间一致性；3）捕获轨迹级语言基础的有效策略。大部分已有方法通过不同的目标来处理这些问题，往往导致次优解。本文提出了一个通用统一目标，可以同时从图像序列中提取有意义的任务进展信息，并将它们与语言指令无缝对齐。我们发现，通过隐式偏好，在视觉轨迹与其对应的语言指令相比不匹配对更好地对齐时，流行的 Bradley-Terry 模型可以通过适当的奖励重新参数化而变为表示学习。结果产生的 DecisionNCE 框架，类似于 InfoNC

    arXiv:2402.18137v1 Announce Type: cross  Abstract: Multimodal pretraining has emerged as an effective strategy for the trinity of goals of representation learning in autonomous robots: 1) extracting both local and global task progression information; 2) enforcing temporal consistency of visual representation; 3) capturing trajectory-level language grounding. Most existing methods approach these via separate objectives, which often reach sub-optimal solutions. In this paper, we propose a universal unified objective that can simultaneously extract meaningful task progression information from image sequences and seamlessly align them with language instructions. We discover that via implicit preferences, where a visual trajectory inherently aligns better with its corresponding language instruction than mismatched pairs, the popular Bradley-Terry model can transform into representation learning through proper reward reparameterizations. The resulted framework, DecisionNCE, mirrors an InfoNC
    
[^11]: Conformer：将连续注意力嵌入视觉Transformer用于天气预测

    Conformer: Embedding Continuous Attention in Vision Transformer for Weather Forecasting

    [https://arxiv.org/abs/2402.17966](https://arxiv.org/abs/2402.17966)

    Conformer是一种用于天气预测的时空连续视觉Transformer，通过在多头注意力机制中实现连续性来学习时间上的连续天气演变。

    

    操作性天气预报系统依赖于计算昂贵的基于物理的模型。尽管基于Transformer的模型在天气预测中显示出了显著潜力，但Transformers是离散模型，限制了其学习动态天气系统连续时空特征的能力。我们通过Conformer解决了这个问题，这是一种用于天气预测的时空连续视觉Transformer。Conformer旨在通过在多头注意力机制中实现连续性来学习时间上的连续天气演变。注意力机制被编码为Transformer架构中的可微分函数，以建模复杂的天气动态。我们将Conformer与最先进的数值天气预报（NWP）模型和几种基于深度学习的天气预测模型进行了评估。Conformer在所有前导时间上优于一些现有的数据驱动模型

    arXiv:2402.17966v1 Announce Type: new  Abstract: Operational weather forecasting system relies on computationally expensive physics-based models. Although Transformers-based models have shown remarkable potential in weather forecasting, Transformers are discrete models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system. We address this issue with Conformer, a spatio-temporal Continuous Vision Transformer for weather forecasting. Conformer is designed to learn the continuous weather evolution over time by implementing continuity in the multi-head attention mechanism. The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics. We evaluate Conformer against a state-of-the-art Numerical Weather Prediction (NWP) model and several deep learning based weather forecasting models. Conformer outperforms some of the existing data-driven models at all lead times while 
    
[^12]: DS-Agent：通过赋予大型语言模型案例推理能力实现自动化数据科学

    DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning

    [https://arxiv.org/abs/2402.17453](https://arxiv.org/abs/2402.17453)

    DS-Agent是一个自动框架，结合了大型语言模型代理和案例推理，能够在数据科学任务中灵活利用专家知识并通过反馈机制持续改善性能

    

    在这项工作中，我们研究了基于大型语言模型（LLMs）代理的潜力，以自动化数据科学任务，目标是理解任务要求，然后构建和训练最合适的机器学习模型。尽管现有的LLM代理取得了广泛成功，但在这种情景下生成不合理的实验计划受到阻碍。为此，我们提出了DS-Agent，这是一个利用LLM代理和案例推理（CBR）的新颖自动化框架。在开发阶段，DS-Agent遵循CBR框架来构建自动迭代流水线，可以灵活利用来自Kaggle的专业知识，并通过反馈机制促进一致的性能改进。此外，DS-Agent实现了一个低资源部署阶段，采用简化的CBR范例来适应开发阶段成功解决方案，以进行直接代码生成，显著减少了...

    arXiv:2402.17453v1 Announce Type: new  Abstract: In this work, we investigate the potential of large language models (LLMs) based agents to automate data science tasks, with the goal of comprehending task requirements, then building and training the best-fit machine learning models. Despite their widespread success, existing LLM agents are hindered by generating unreasonable experiment plans within this scenario. To this end, we present DS-Agent, a novel automatic framework that harnesses LLM agent and case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR framework to structure an automatic iteration pipeline, which can flexibly capitalize on the expert knowledge from Kaggle, and facilitate consistent performance improvement through the feedback mechanism. Moreover, DS-Agent implements a low-resource deployment stage with a simplified CBR paradigm to adapt past successful solutions from the development stage for direct code generation, significantly reducing th
    
[^13]: 通知元学习

    Informed Meta-Learning

    [https://arxiv.org/abs/2402.16105](https://arxiv.org/abs/2402.16105)

    该研究提出了通知元学习这一新范式，旨在通过人类和机器之间的跨任务知识共享，提高数据效率和抵御观测噪声。

    

    在真实应用中盛行的嘈杂和低数据情况下，机器学习中一个突出的挑战在于有效地融合促进数据效率和稳健性的归纳偏差。元学习和通知机器学习是两种将先验知识纳入机器学习流程的方法。前者依赖于一种纯数据驱动的先验来源，而后者受专家知识的形式化表示引导。本文介绍了一种新颖的混合范式，通知元学习，旨在实现人类和机器之间跨任务知识共享的互补性。我们建立了通知元学习的基本组成部分，并提出了这一框架的具体实例--通知神经过程。通过一系列说明性和更大规模的实验，我们展示了通知元学习在提高数据效率和抵御观测噪声方面的潜在优势。

    arXiv:2402.16105v1 Announce Type: new  Abstract: In noisy and low-data regimes prevalent in real-world applications, an outstanding challenge of machine learning lies in effectively incorporating inductive biases that promote data efficiency and robustness. Meta-learning and informed ML stand out as two approaches for incorporating prior knowledge into the ML pipeline. While the former relies on a purely data-driven source of priors, the latter is guided by a formal representation of expert knowledge. This paper introduces a novel hybrid paradigm, informed meta-learning, seeking complementarity in cross-task knowledge sharing of humans and machines. We establish the foundational components of informed meta-learning and present a concrete instantiation of this framework--the Informed Neural Process. Through a series of illustrative and larger-scale experiments, we demonstrate the potential benefits of informed meta-learning in improving data efficiency and robustness to observational no
    
[^14]: EasyRL4Rec：面向基于强化学习的推荐系统的用户友好代码库

    EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems

    [https://arxiv.org/abs/2402.15164](https://arxiv.org/abs/2402.15164)

    EasyRL4Rec是一个面向基于强化学习的推荐系统的用户友好和高效库，提供了多样化的RL环境、全面的核心模块、一致的评估标准和定制解决方案，旨在帮助简化模型开发并改善长期用户参与度。

    

    强化学习（RL）-基础的推荐系统（RSs）越来越被认可其提高长期用户参与度的能力。然而，这个领域面临挑战，如缺乏易用的框架、评估标准不一致以及复制以前的工作的复杂性。为解决这些障碍，我们提出了EasyRL4Rec，一个专为基于RL的RSs量身定制的用户友好和高效的库。EasyRL4Rec具有基于五个广泛使用的公共数据集构建的轻量级、多样化的RL环境，并配备了全面的核心模块，提供丰富的选项来简化模型的开发。它建立了一致的评估标准，重点关注长期影响，并引入了针对推荐系统定制的状态建模和行为表示的定制解决方案。此外，我们分享了通过与当前方法进行的大量实验获得的宝贵见解。EasyRL4Rec旨在促进

    arXiv:2402.15164v1 Announce Type: cross  Abstract: Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement. Yet, the field grapples with challenges such as the absence of accessible frameworks, inconsistent evaluation standards, and the complexity of replicating prior work. Addressing these obstacles, we present EasyRL4Rec, a user-friendly and efficient library tailored for RL-based RSs. EasyRL4Rec features lightweight, diverse RL environments built on five widely-used public datasets, and is equipped with comprehensive core modules that offer rich options to ease the development of models. It establishes consistent evaluation criteria with a focus on long-term impacts and introduces customized solutions for state modeling and action representation tailored to recommender systems. Additionally, we share valuable insights gained from extensive experiments with current methods. EasyRL4Rec aims to facil
    
[^15]: 平均梯度外积作为深度神经坍塌机制的研究

    Average gradient outer product as a mechanism for deep neural collapse

    [https://arxiv.org/abs/2402.13728](https://arxiv.org/abs/2402.13728)

    本文通过提供证据表明，深度神经网络中的神经坍塌主要是通过平均梯度外积进行深度特征学习的，权重的奇异结构与AGOP高度相关，导致类内变异坍塌。

    

    Deep Neural Collapse (DNC)指的是深度神经网络(DNNs)最后几层数据表示的惊人刚性结构。尽管这种现象在各种情境中都得到了测量，但其出现只有部分被理解。本文提供了充分证据，表明DNC主要是通过平均梯度外积(AGOP)进行深度特征学习而发生的。相比于解释神经坍塌的特征不可知方法，如无约束特征模型，这一进展更进一步。我们继续提供证据表明，权重的右奇异向量和奇异值是DNN中类内变异坍塌的主要因素。正如最近的研究所示，这种奇异结构与AGOP的高度相关。然后我们在实验和理论上证明了AGOP在随机初始化的神经网络中引发神经坍塌。

    arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
    
[^16]: 迈向变压器：用变压器彻底改变混合整数规划的解决方案

    Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers

    [https://arxiv.org/abs/2402.13380](https://arxiv.org/abs/2402.13380)

    这项研究利用变压器模型解决混合整数规划问题，首次采用变压器预测二进制变量，提出的算法在解决时间上超越了传统CPLEX和LSTM。

    

    在这项研究中，我们引入了一种创新的深度学习框架，利用变压器模型来解决混合整数规划的挑战，特别是专注于容量限制批量生产问题（CLSP）。据我们所知，我们的方法是首个利用变压器来预测混合整数规划问题中的二进制变量。具体而言，我们的方法利用编码器-解码器变压器处理顺序数据的能力，非常适合预测每个CLSP周期中表示生产设置决策的二进制变量。这个问题本质上是动态的，我们需要在约束条件下处理顺序决策。我们提出了一种有效的算法，通过变压器神经网络学习CLSP解决方案。所提出的后处理变压器算法在解决时间上超越了最先进的求解器CPLEX和长短期记忆（LSTM）。

    arXiv:2402.13380v1 Announce Type: new  Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time
    
[^17]: PARCv2：物理感知循环卷积神经网络用于时空动力学建模

    PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling

    [https://arxiv.org/abs/2402.12503](https://arxiv.org/abs/2402.12503)

    PARCv2通过引入微分算子扩展了PARC模型，用于模拟不稳定、瞬态和传输主导系统的时空动力学。

    

    arXiv:2402.12503v1 公告类型：新摘要：对不稳定的、快速瞬态和优势传输主导的物理问题进行建模是物理感知深度学习（PADL）面临的迫切挑战。复杂系统的物理由大型偏微分方程（PDEs）系统和带有非线性结构的辅助本构模型所控制，同时还包括表现出急剧梯度和快速变形材料界面的演化状态场。在这里，我们研究了一种多功能且通用的归纳偏见方法，用于模拟通用的非线性场演变问题。我们的研究聚焦于最近的物理感知循环卷积（PARC），它结合了一种区分-积分器结构，归纳地模拟了通用物理系统的时空动力学。我们扩展了PARC的功能，以模拟不稳定、瞬态和传输主导系统。这个扩展模型被称为PARCv2，配备了微分算子来建模

    arXiv:2402.12503v1 Announce Type: new  Abstract: Modeling unsteady, fast transient, and advection-dominated physics problems is a pressing challenge for physics-aware deep learning (PADL). The physics of complex systems is governed by large systems of partial differential equations (PDEs) and ancillary constitutive models with nonlinear structures, as well as evolving state fields exhibiting sharp gradients and rapidly deforming material interfaces. Here, we investigate an inductive bias approach that is versatile and generalizable to model generic nonlinear field evolution problems. Our study focuses on the recent physics-aware recurrent convolutions (PARC), which incorporates a differentiator-integrator architecture that inductively models the spatiotemporal dynamics of generic physical systems. We extend the capabilities of PARC to simulate unsteady, transient, and advection-dominant systems. The extended model, referred to as PARCv2, is equipped with differential operators to model
    
[^18]: 基于上下文的奖励：基于动态偏好调整的多目标基础模型对齐

    Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment

    [https://arxiv.org/abs/2402.10207](https://arxiv.org/abs/2402.10207)

    本文介绍了Rewards-in-Context（RiC）方法，该方法通过多个奖励条件控制基础模型的响应，并应用有监督的微调进行对齐。它具有简单性和适应性，并支持在推理时动态调整用户偏好。

    

    我们考虑了基于人类偏好的基础模型多目标对齐问题，这是实现有益和无害的人工智能系统的关键步骤。然而，使用强化学习（RL）对大型基础模型进行微调通常是昂贵且不稳定的，并且人类偏好的多维度、异质性和冲突性进一步复杂化了对齐过程。在本文中，我们引入了Rewards-in-Context（RiC）方法，它使得基础模型的响应取决于其提示上下文中的多个奖励，并应用有监督的微调来进行对齐。RiC的显著特点是简单性和适应性，因为它只需要对单个基础模型进行有监督的微调，并支持在推理时动态调整用户偏好。受到抽象的凸优化问题的解析解的启发，我们提出了一种动态推理时调整方法。

    arXiv:2402.10207v1 Announce Type: cross  Abstract: We consider the problem of multi-objective alignment of foundation models with human preferences, which is a critical step towards helpful and harmless AI systems. However, it is generally costly and unstable to fine-tune large foundation models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity, and conflicting nature of human preferences further complicate the alignment process. In this paper, we introduce Rewards-in-Context (RiC), which conditions the response of a foundation model on multiple rewards in its prompt context and applies supervised fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity, as it only requires supervised fine-tuning of a single foundation model and supports dynamic adjustment for user preferences during inference time. Inspired by the analytical solution of an abstracted convex optimization problem, our dynamic inference-time adjustment method appro
    
[^19]: GES：用于高效辐射场渲染的广义指数喷洒

    GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering

    [https://arxiv.org/abs/2402.10128](https://arxiv.org/abs/2402.10128)

    本研究引入了GES（广义指数喷洒），一种利用广义指数函数来建模3D场景的新表示方法，可以显著提高3D重建和生成的效率。相比于传统的高斯喷洒方法，GES所需的粒子数量更少，能更准确地表示具有锐利边缘的信号。

    

    arXiv:2402.10128v1 公告类型：跨领域 摘要：3D高斯喷洒技术的进展显著加快了3D重建和生成的速度。然而，这可能需要大量高斯函数，导致占用大量内存。本文介绍了GES（广义指数喷洒），这是一种新的表示方法，它利用广义指数函数（GEF）来建模3D场景，只需要很少的粒子来表示一个场景，因此在效率上明显优于基于高斯的喷洒方法，并且具有高斯-based utilities的即插即用替换能力。GES在理论上和实证上都得到了验证，在原则上的1D设置和逼真的3D场景中。实验证明，GEF比高斯函数更准确地表示具有锐利边缘的信号，这在高斯函数中是具有挑战性的，因为它们具有低通特性。我们的实证分析表明，GEF在拟合自然发生的信号（例如正方形、三角形）方面优于高斯函数。

    arXiv:2402.10128v1 Announce Type: cross  Abstract: Advancements in 3D Gaussian Splatting have significantly accelerated 3D reconstruction and generation. However, it may require a large number of Gaussians, which creates a substantial memory footprint. This paper introduces GES (Generalized Exponential Splatting), a novel representation that employs Generalized Exponential Function (GEF) to model 3D scenes, requiring far fewer particles to represent a scene and thus significantly outperforming Gaussian Splatting methods in efficiency with a plug-and-play replacement ability for Gaussian-based utilities. GES is validated theoretically and empirically in both principled 1D setup and realistic 3D scenes.   It is shown to represent signals with sharp edges more accurately, which are typically challenging for Gaussians due to their inherent low-pass characteristics. Our empirical analysis demonstrates that GEF outperforms Gaussians in fitting natural-occurring signals (e.g. squares, triangl
    
[^20]: 神经网络中的傅立叶电路：解锁大规模语言模型在数学推理和模运算中的潜力

    Fourier Circuits in Neural Networks: Unlocking the Potential of Large Language Models in Mathematical Reasoning and Modular Arithmetic

    [https://arxiv.org/abs/2402.09469](https://arxiv.org/abs/2402.09469)

    本研究探索了神经网络和Transformer在数学推理和模运算中的潜力。我们分析了单隐藏层神经网络和单层Transformer在解决复杂代数学习任务中的特征。阐明了边缘最大化原则对单隐藏层神经网络的影响。

    

    在机器学习不断发展的背景下，理解神经网络和Transformer所利用的内部表示是一个关键挑战。本研究在近期的研究基础上，对网络采用特定计算策略背后的原因进行了探索。我们的研究聚焦于涉及k个输入的复杂代数学习任务，即模运算的加法。我们对单隐藏层神经网络和单层Transformer在解决这一任务中学到的特征进行了深入的分析。我们理论框架的一个关键是阐明边缘最大化原则对单隐藏层神经网络采用的特征的影响。其中，p表示模数，Dp表示k个输入的模运算数据集，m表示网络输出。

    arXiv:2402.09469v1 Announce Type: new  Abstract: In the evolving landscape of machine learning, a pivotal challenge lies in deciphering the internal representations harnessed by neural networks and Transformers. Building on recent progress toward comprehending how networks execute distinct target functions, our study embarks on an exploration of the underlying reasons behind networks adopting specific computational strategies. We direct our focus to the complex algebraic learning task of modular addition involving $k$ inputs. Our research presents a thorough analytical characterization of the features learned by stylized one-hidden layer neural networks and one-layer Transformers in addressing this task.   A cornerstone of our theoretical framework is the elucidation of how the principle of margin maximization shapes the features adopted by one-hidden layer neural networks. Let $p$ denote the modulus, $D_p$ denote the dataset of modular arithmetic with $k$ inputs and $m$ denote the net
    
[^21]: 分布式后续表示的分布式类比

    A Distributional Analogue to the Successor Representation

    [https://arxiv.org/abs/2402.08530](https://arxiv.org/abs/2402.08530)

    本文提出了一种新的分布式强化学习方法，它通过分离转换结构和奖励，引入了分布式后继度量来描述行为的分布式后果。在实验中展示了该方法的实用性，特别是在零样本风险敏感策略评估方面。

    

    本文提出了一种新的分布式强化学习方法，它将转换结构和奖励在学习过程中进行了明确的分离。与后续表示（SR）描述按照给定策略行为的期望后果类似，我们的分布式后继度量（SM）描述了这种行为的分布式结果。我们将分布式SM构建为一个分布的分布，并提供了与分布式和基于模型的强化学习相关的理论。此外，我们提出了一种从数据中学习分布式SM的算法，通过最小化两个层次的最大均值差异来实现。我们方法的关键是一些独立有价值的学习状态生成模型的算法技术。作为分布式SM有用性的例证，我们展示了它使得零样本风险敏感策略评估成为可能，这在以前是不可能的。

    This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possi
    
[^22]: 使用大型语言模型和蒙特卡洛树搜索进行验证的多步合成

    Verified Multi-Step Synthesis using Large Language Models and Monte Carlo Tree Search

    [https://arxiv.org/abs/2402.08147](https://arxiv.org/abs/2402.08147)

    本文提出了一种使用蒙特卡洛树搜索引导大型语言模型生成验证程序的方法，通过结合验证器的反馈和LLM先验知识提高了合成能力，实验证明这种方法在一组验证编程问题上的性能优于基本模型和具有插件的ChatGPT4。

    

    我们提出了一种使用蒙特卡洛树搜索（MCTS）引导大型语言模型（LLMs）生成在Dafny、Lean和Coq中验证的程序的方法。我们的方法被称为VMCTS，通过在每个步骤检查部分程序来利用搜索算法中的验证器。结合LLM先验知识，验证器的反馈提高了开源模型的合成能力。在一组五个经过验证的编程问题中，我们发现在四个问题中，即使重新对解决方案进行一小时的重新采样，基本模型无法解决问题，而VMCTS可以在6分钟内解决这些问题。在这些问题上，基本模型加上VMCTS甚至与具有插件和多次重试的ChatGPT4竞争力相当。我们的代码和基准测试结果可在https://github.com/namin/llm-verified-with-monte-carlo-tree-search找到。

    We present an approach using Monte Carlo Tree Search (MCTS) to guide Large Language Models (LLMs) to generate verified programs in Dafny, Lean and Coq. Our method, which we call VMCTS, leverages the verifier inside the search algorithm by checking partial programs at each step. In combination with the LLM prior, the verifier feedback raises the synthesis capabilities of open source models. On a set of five verified programming problems, we find that in four problems where the base model cannot solve the question even when re-sampling solutions for one hour, VMCTS can solve the problems within 6 minutes. The base model with VMCTS is even competitive with ChatGPT4 augmented with plugins and multiple re-tries on these problems. Our code and benchmarks are available at https://github.com/namin/llm-verified-with-monte-carlo-tree-search .
    
[^23]: Bilevel强化学习和RLHF的有原则的基于惩罚的方法

    Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF

    [https://arxiv.org/abs/2402.06886](https://arxiv.org/abs/2402.06886)

    本文提出了一种基于惩罚的方法来解决Bilevel强化学习和RLHF问题，这是首个有原则的算法框架。通过理论分析和实验证明了算法的有效性。

    

    最近，Bilevel优化已被应用于许多机器学习任务中。然而，它们的应用仅限于监督学习设置，其中考虑了具有良性结构的静态目标函数。但是，激励设计、反向强化学习(RL)和来自人类反馈的RLHF等Bilevel问题通常被建模为超越简单静态目标结构的动态目标函数，这给使用现有Bilevel解决方案带来了重大挑战。为了解决这一新的Bilevel问题类别，我们通过惩罚形式引入了解决Bilevel RL问题的第一个原则性算法框架。我们通过理论研究问题的景观及其基于惩罚的（策略）梯度算法进行了验证。我们通过在Stackelberg马尔可夫博弈、来自人类反馈的RL和激励设计中进行模拟来证明我们算法的有效性。

    Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.
    
[^24]: 一个自监督学习框架用于学习整个切片的表示

    A self-supervised framework for learning whole slide representations

    [https://arxiv.org/abs/2402.06188](https://arxiv.org/abs/2402.06188)

    这个论文提出了一个自监督学习框架（S3L），用于学习整个切片的表示。它结合了变压器模型的视觉和语言建模策略，通过生成配对视图进行自监督学习，以实现高质量的WSI视觉特征学习。

    

    整个切片成像对于生物医学显微镜和计算病理学至关重要。然而，由于其千兆像素的大小、多样的组织病理学特征、空间异质性以及有限的/不存在的数据注释，整个切片图像 (WSIs) 构成了一个复杂的计算机视觉挑战。这些挑战突显了仅依靠监督训练可能导致次优的整个切片表示。自监督表示学习可以为下游诊断任务（如癌症诊断或分子遗传预测）实现高质量的WSI视觉特征学习。在这里，我们提出了一个通用的自监督整个切片学习（S3L）框架，用于千兆像素规模的WSI自监督。S3L将来自基于变压器的视觉和语言建模的数据转换策略结合到一个统一的框架中，以生成用于自监督的配对视图。S3L利用内在的区域异质性、组织学特征的可变性和信息冗余性

    Whole slide imaging is fundamental to biomedical microscopy and computational pathology. However, whole slide images (WSIs) present a complex computer vision challenge due to their gigapixel size, diverse histopathologic features, spatial heterogeneity, and limited/absent data annotations. These challenges highlight that supervised training alone can result in suboptimal whole slide representations. Self-supervised representation learning can achieve high-quality WSI visual feature learning for downstream diagnostic tasks, such as cancer diagnosis or molecular genetic prediction. Here, we present a general self-supervised whole slide learning (S3L) framework for gigapixel-scale self-supervision of WSIs. S3L combines data transformation strategies from transformer-based vision and language modeling into a single unified framework to generate paired views for self-supervision. S3L leverages the inherent regional heterogeneity, histologic feature variability, and information redundancy wi
    
[^25]: Premier-TACO: 通过时间驱动的对比损失进行多任务表示预训练

    Premier-TACO: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss

    [https://arxiv.org/abs/2402.06187](https://arxiv.org/abs/2402.06187)

    Premier-TACO是一种多任务特征表示学习方法，通过预训练通用特征表示，并引入负例抽样策略来提高时序行动对比学习的计算效率，从而显著增强了对新颖动作的少样本模仿学习的效果。

    

    我们提出了Premier-TACO，这是一种多任务特征表示学习方法，旨在提高顺序决策任务中少样本策略学习的效率。Premier-TACO利用一部分多任务离线数据集进行预训练通用特征表示，该特征表示捕捉了关键的环境动力学，并使用最少的专家演示进行微调。它通过引入一种新的负例抽样策略推动了时序行动对比学习（TACO）目标的发展，TACO在视觉控制任务中具有最先进的结果。这种策略在显著提高TACO的计算效率方面非常重要，使大规模多任务离线预训练成为可能。我们在包括Deepmind Control Suite、MetaWorld和LIBERO在内的各种连续控制基准测试中进行了广泛的实证评估，证明了Premier-TACO在预训练视觉表示方面的有效性，显著增强了对新颖动作的少样本模仿学习。

    We present Premier-TACO, a multitask feature representation learning approach designed to improve few-shot policy learning efficiency in sequential decision-making tasks. Premier-TACO leverages a subset of multitask offline datasets for pretraining a general feature representation, which captures critical environmental dynamics and is fine-tuned using minimal expert demonstrations. It advances the temporal action contrastive learning (TACO) objective, known for state-of-the-art results in visual control tasks, by incorporating a novel negative example sampling strategy. This strategy is crucial in significantly boosting TACO's computational efficiency, making large-scale multitask offline pretraining feasible. Our extensive empirical evaluation in a diverse set of continuous control benchmarks including Deepmind Control Suite, MetaWorld, and LIBERO demonstrate Premier-TACO's effectiveness in pretraining visual representations, significantly enhancing few-shot imitation learning of nove
    
[^26]: 最后之舞：通过扩散模型和贝叶斯方法进行鲁棒后门攻击

    The last Dance : Robust backdoor attack via diffusion models and bayesian approach

    [https://arxiv.org/abs/2402.05967](https://arxiv.org/abs/2402.05967)

    本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。

    

    扩散模型是最先进的深度学习生成模型，其通过逐步添加噪音和去噪的方式学习正向和反向扩散过程的原理进行训练。本文旨在欺骗基于音频的DNN模型，例如Hugging Face框架中的音频模型，特别是基于Transformer的人工智能模型，这些模型是强大的机器学习模型，节省时间，提供更高效的结果。我们证明了在Hugging Face推导出的音频Transformer上实现后门攻击（称为`BacKBayDiffMod`）的可行性。本文中开发的后门攻击基于毒化模型的训练数据，涉及后门扩散采样和贝叶斯方法分布的引入。

    Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we seek to trick audio-based DNN models, such as those in the Hugging Face framework, for example, those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and deliver faster, more efficient results. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence (AI) research. The backdoor attack developed in this paper is based on poisoning the model's training data by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.
    
[^27]: 非参数仪器变量回归通过随机近似梯度

    Nonparametric Instrumental Variable Regression through Stochastic Approximate Gradients

    [https://arxiv.org/abs/2402.05639](https://arxiv.org/abs/2402.05639)

    本文提出了一种通过随机近似梯度最小化投影群体风险的新型非参数仪器变量回归框架，并通过理论和实证实验证明了其竞争性能。此外，本文还处理了二元结果的情况，取得了有希望的结果。

    

    本文提出了SAGD-IV，这是一种通过使用随机近似梯度来最小化投影群体风险的新型非参数仪器变量（NPIV）回归框架。仪器变量（IV）被广泛应用于计量经济学中，以解决在存在不可观测混淆因素的情况下的估计问题，并且机器学习社区致力于改进现有方法并在NPIV设置下设计新方法，该设置被认为是一个不适定的线性逆问题。我们提供了对我们算法的理论支持，并通过实证实验进一步证明了其竞争性能。此外，我们还处理了二元结果的情况，并取得了有希望的结果，而该情况在社区中没有得到与其连续对应物的同样关注。

    This paper proposes SAGD-IV, a novel framework for conducting nonparametric instrumental variable (NPIV) regression by employing stochastic approximate gradients to minimize the projected populational risk. Instrumental Variables (IVs) are widely used in econometrics to address estimation problems in the presence of unobservable confounders, and the Machine Learning community has devoted significant effort to improving existing methods and devising new ones in the NPIV setting, which is known to be an ill-posed linear inverse problem. We provide theoretical support for our algorithm and further exemplify its competitive performance through empirical experiments. Furthermore, we address, with promising results, the case of binary outcomes, which has not received as much attention from the community as its continuous counterpart.
    
[^28]: QGFN:具有动作值的可控贪婪算法

    QGFN: Controllable Greediness with Action Values

    [https://arxiv.org/abs/2402.05234](https://arxiv.org/abs/2402.05234)

    本文提出了一种新的算法QGFN，通过将GFN策略与动作值估计相结合，可以生成更多高奖励的样本而不牺牲多样性。

    

    生成流网络（GFlowNets;GFNs）是一种用于组合对象的基于奖励/能量的生成方法，能够生成多样化和高效的样本。然而，偏向于生成高效样本的GFNs并不容易。在这项工作中，我们利用GFNs和强化学习（RL）之间的联系，提出将GFN策略与动作值估计$Q$相结合，从而创建可以通过混合参数控制的贪婪采样策略。我们展示了几个QGFN的变体能够在各种任务中改善生成高奖励样本的数量，同时不牺牲多样性。

    Generative Flow Networks (GFlowNets; GFNs) are a family of reward/energy-based generative methods for combinatorial objects, capable of generating diverse and high-utility samples. However, biasing GFNs towards producing high-utility samples is non-trivial. In this work, we leverage connections between GFNs and reinforcement learning (RL) and propose to combine the GFN policy with an action-value estimate, $Q$, to create greedier sampling policies which can be controlled by a mixing parameter. We show that several variants of the proposed method, QGFN, are able to improve on the number of high-reward samples generated in a variety of tasks without sacrificing diversity.
    
[^29]: 贝叶斯分解格兰杰因果图用于多变量时间序列数据的研究

    Bayesian Factorised Granger-Causal Graphs For Multivariate Time-series Data

    [https://arxiv.org/abs/2402.03614](https://arxiv.org/abs/2402.03614)

    本研究提出了一种新的贝叶斯VAR模型，利用分层图先验推断二元格兰杰因果图的后验概率。相比竞争方法，我们的方法在不确定性量化、超参数数量和稀疏多变量时间序列数据上都表现更好。

    

    我们研究了自动发现多变量时间序列数据中格兰杰因果关系的问题。矢量自回归(VAR)模型已经在解决这个问题上经过了时间的考验，包括贝叶斯变种和使用深度神经网络的最新发展。大多数现有的VAR格兰杰因果方法使用稀疏性诱导惩罚/先验或事后阈值来解释它们的系数作为格兰杰因果图。相反，我们提出了一个新的贝叶斯VAR模型，其中包含了一个分层图先验来表示二元格兰杰因果图，与VAR系数分开考虑。我们开发了一种高效的算法来推断二元格兰杰因果图的后验概率。我们的方法提供了更好的不确定性量化，较少的超参数，并在稀疏多变量时间序列数据上实现了更好的性能。

    We study the problem of automatically discovering Granger causal relations from observational multivariate time-series data. Vector autoregressive (VAR) models have been time-tested for this problem, including Bayesian variants and more recent developments using deep neural networks. Most existing VAR methods for Granger causality use sparsity-inducing penalties/priors or post-hoc thresholds to interpret their coefficients as Granger causal graphs. Instead, we propose a new Bayesian VAR model with a hierarchical graph prior over binary Granger causal graphs, separately from the VAR coefficients. We develop an efficient algorithm to infer the posterior over binary Granger causal graphs. Our method provides better uncertainty quantification, has less hyperparameters, and achieves better performance than competing approaches, especially on sparse multivariate time-series data.
    
[^30]: 在空间环境中一致验证预测方法

    Consistent Validation for Predictive Methods in Spatial Settings

    [https://arxiv.org/abs/2402.03527](https://arxiv.org/abs/2402.03527)

    本论文研究了在空间环境中验证预测方法的一致性问题，提出了一种能够处理不匹配情况的方法。

    

    空间预测任务对于天气预报、空气污染研究和其他科学工作至关重要。确定我们对统计或物理方法所作预测的可信度是科学结论的重要问题。不幸的是，传统的验证方法无法处理验证位置和我们希望进行预测的（测试）位置之间的不匹配。这种不匹配通常不是协变量偏移的一个实例（常常被形式化），因为验证和测试位置是固定的（例如，在网格上或选定的点上），而不是从两个分布中独立同分布地采样。在本文中，我们形式化了对验证方法的检查：随着验证数据的密度越来越大，它们能够变得任意精确。我们证明了传统方法和协变量偏移方法可能不满足这个检查。相反，我们提出了一种方法，它借鉴了协变量偏移文献中的现有思想，但对验证数据进行了调整。

    Spatial prediction tasks are key to weather forecasting, studying air pollution, and other scientific endeavors. Determining how much to trust predictions made by statistical or physical methods is essential for the credibility of scientific conclusions. Unfortunately, classical approaches for validation fail to handle mismatch between locations available for validation and (test) locations where we want to make predictions. This mismatch is often not an instance of covariate shift (as commonly formalized) because the validation and test locations are fixed (e.g., on a grid or at select points) rather than i.i.d. from two distributions. In the present work, we formalize a check on validation methods: that they become arbitrarily accurate as validation data becomes arbitrarily dense. We show that classical and covariate-shift methods can fail this check. We instead propose a method that builds from existing ideas in the covariate-shift literature, but adapts them to the validation data 
    
[^31]: 同性质，聚类和分类器

    Isotropy, Clusters, and Classifiers

    [https://arxiv.org/abs/2402.03191](https://arxiv.org/abs/2402.03191)

    同性质的嵌入空间对聚类和线性分类目标具有负面影响，这一事实得到了本文的实证支持，并对文献中的先前结果有所启示。

    

    最近，关于嵌入空间是否均匀利用所有维度（即是否具有同性质）的问题引起了讨论。有证据支持和反对在嵌入空间中实施同性质。在本文中，我们强调同性质对嵌入空间的要求与聚类的存在不兼容，这也对线性分类目标产生了负面影响。我们通过实验证明了这个事实，并用它来阐明文献中的先前结果。

    Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters -- which also negatively impacts linear classification objectives. We demonstrate this fact empirically and use it to shed light on previous results from the literature.
    
[^32]: 对偶拉格朗日学习用于锥优化问题

    Dual Lagrangian Learning for Conic Optimization

    [https://arxiv.org/abs/2402.03086](https://arxiv.org/abs/2402.03086)

    本文介绍了对偶拉格朗日学习（DLL）方法，通过结合锥对偶理论和机器学习模型表示能力，在参数化线性和非线性锥优化问题上提供了有效的拉格朗日对偶界限，证明了其性能在优化问题上接近最优解的0.5%。

    

    本文介绍了对偶拉格朗日学习（DLL），一种结合锥对偶理论和机器学习模型表示能力的原理性学习方法。DLL利用锥对偶提供对偶可行解，并因此对参数化线性和非线性锥优化问题提供有效的拉格朗日对偶界限。本文引入了可微分锥投影层，一个系统的对偶完成过程以及一个自监督学习框架。DLL的有效性在线性和非线性参数化优化问题上得到了证明，DLL可以在优化性能的0.5%之内提供有效的对偶界限。

    This paper presents Dual Lagrangian Learning (DLL), a principled learning methodology that combines conic duality theory with the represen- tation power of ML models. DLL leverages conic duality to provide dual-feasible solutions, and therefore valid Lagrangian dual bounds, for para- metric linear and nonlinear conic optimization problems. The paper introduces differentiable conic projection layers, a systematic dual com- pletion procedure, and a self-supervised learning framework. The effectiveness of DLL is demon- strated on linear and nonlinear parametric opti- mization problems for which DLL provides valid dual bounds within 0.5% of optimality.
    
[^33]: 论文标题：解码时间对齐的语言模型

    Decoding-time Realignment of Language Models

    [https://arxiv.org/abs/2402.02992](https://arxiv.org/abs/2402.02992)

    本研究提出了解码时间对齐（DeRa）方法，可以在不重新训练模型的情况下探索和评估不同的规则化强度，从而对齐语言模型和人类偏好。

    

    将语言模型与人类偏好对齐对于减少模型中的错误和偏差非常重要。对齐技术，如从人类反馈中进行的强化学习（RLHF），通常被视为在人类偏好奖励和鼓励保持与未对齐模型接近的接近性规则项之间进行优化的权衡。选择适当的规则化水平至关重要：规则化不足可能导致由于奖励欺骗而降低模型能力，而过度规则化则阻碍对齐。传统方法找到最佳规则化水平需要使用不同规则化强度重新训练多个模型。然而，这个过程耗费资源，特别是对于大型模型来说。为了解决这个挑战，我们提出了解码时间对齐（DeRa），一种简单的方法，在无需重新训练的情况下探索和评估不同的规则化强度。DeRa可以对对齐模型的程度进行控制。

    Aligning language models with human preferences is crucial for reducing errors and biases in these models. Alignment techniques, such as reinforcement learning from human feedback (RLHF), are typically cast as optimizing a tradeoff between human preference rewards and a proximity regularization term that encourages staying close to the unaligned model. Selecting an appropriate level of regularization is critical: insufficient regularization can lead to reduced model capabilities due to reward hacking, whereas excessive regularization hinders alignment. Traditional methods for finding the optimal regularization level require retraining multiple models with varying regularization strengths. This process, however, is resource-intensive, especially for large models. To address this challenge, we propose decoding-time realignment (DeRa), a simple method to explore and evaluate different regularization strengths in aligned models without retraining. DeRa enables control over the degree of al
    
[^34]: MetaOptimize：一个优化步长和其他元参数的框架

    MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters

    [https://arxiv.org/abs/2402.02342](https://arxiv.org/abs/2402.02342)

    MetaOptimize是一个框架，通过动态调整学习率来优化机器学习算法中的元参数，以提高训练效率和模型性能。

    

    本文解决了机器学习算法中优化元参数（即超参数）的挑战，这是影响训练效率和模型性能的关键因素。我们引入了MetaOptimize框架，摆脱了计算昂贵的传统元参数搜索方法，通过动态调整元参数，特别是步长（也称为学习率），来训练模型。具体而言，MetaOptimize可以适用于任何一阶优化算法，在训练过程中实时调整步长，通过未来损失的折现总和来最小化一种特定形式的遗憾。我们还介绍了MetaOptimize的低复杂度变体，结合其适应多个优化算法的能力，展示了在各种机器学习应用中与手工设计的学习率计划相媲美的性能。

    This paper addresses the challenge of optimizing meta-parameters (i.e., hyperparameters) in machine learning algorithms, a critical factor influencing training efficiency and model performance. Moving away from the computationally expensive traditional meta-parameter search methods, we introduce MetaOptimize framework that dynamically adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that accounts for long-term effect of step sizes on training, through a discounted sum of future losses. We also introduce low complexity variants of MetaOptimize that, in conjunction with its adaptability to multiple optimization algorithms, demonstrate performance competitive to those of best hand-crafted learning rate schedules across various machine learning applications.
    
[^35]: 理解Transformer在序列建模中的表达能力和机制

    Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling

    [https://arxiv.org/abs/2402.00522](https://arxiv.org/abs/2402.00522)

    本研究系统地探讨了Transformer在长序列建模中的近似性质，并研究了其关键组件对表达能力的影响机制。这些发现揭示了关键参数对Transformer的作用，并为替代架构提供了自然建议。

    

    我们对Transformer在长、稀疏和复杂记忆的序列建模中的近似性质进行了系统研究。我们调查了Transformer的不同组件（如点积自注意力、位置编码和前馈层）是如何影响其表达能力的机制，并通过建立明确的近似率来研究它们的综合影响。我们的研究揭示了Transformer中关键参数（如层数和注意力头数）的作用，并且这些洞察还为替代架构提供了自然建议。

    We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
    
[^36]: 弹性神经图像压缩中的鲁棒过拟合潜变量

    Robustly overfitting latents for flexible neural image compression

    [https://arxiv.org/abs/2401.17789](https://arxiv.org/abs/2401.17789)

    这项研究提出了一种鲁棒的过拟合潜变量方法来改进神经图像压缩模型，通过使用SGA+，可以显著提高性能并减少对超参数选择的敏感性。

    

    神经图像压缩取得了很大的进展。最先进的模型基于变分自编码器，胜过了传统模型。神经压缩模型学会将图像编码为量化的潜变量表示，然后将其高效地发送给解码器，解码器再将量化的潜变量解码为重建图像。虽然这些模型在实践中取得了成功，但由于优化不完美以及编码器和解码器容量的限制，它们导致了次优结果。最近的研究表明，如何利用随机Gumbel退火（SGA）来改进预训练的神经图像压缩模型的潜变量。我们通过引入SGA+扩展了这个想法，SGA+包含了三种不同的方法，这些方法都建立在SGA的基础上。此外，我们对我们提出的方法进行了详细分析，展示了它们如何改进性能，并且证明它们对超参数选择不敏感。此外，我们还展示了如何将每个方法扩展到三个而不是两个。

    Neural image compression has made a great deal of progress. State-of-the-art models are based on variational autoencoders and are outperforming classical models. Neural compression models learn to encode an image into a quantized latent representation that can be efficiently sent to the decoder, which decodes the quantized latent into a reconstructed image. While these models have proven successful in practice, they lead to sub-optimal results due to imperfect optimization and limitations in the encoder and decoder capacity. Recent work shows how to use stochastic Gumbel annealing (SGA) to refine the latents of pre-trained neural image compression models. We extend this idea by introducing SGA+, which contains three different methods that build upon SGA. Further, we give a detailed analysis of our proposed methods, show how they improve performance, and show that they are less sensitive to hyperparameter choices. Besides, we show how each method can be extended to three- instead of two
    
[^37]: “越大越好？”重新思考长期时间序列预测中的有效模型规模

    The Bigger the Better? Rethinking the Effective Model Scale in Long-term Time Series Forecasting

    [https://arxiv.org/abs/2401.11929](https://arxiv.org/abs/2401.11929)

    本研究通过调查条件相关性和自相关性，揭示了输入数据中的冗余性，并提出了HDformer，这是一种轻量级的Transformer变种，利用蒸馏技术和快速网络连接层来降低模型复杂性。

    

    长期时间序列预测（LTSF）是时间序列分析中的一个重要前沿，其特点是关注于大量输入序列，与传统方法中的有限长度相比有所不同。尽管更长的序列本质上传达了更丰富的信息，可能提高了预测的精度，但目前的技术往往通过提高模型复杂性来应对。这些复杂的模型可以膨胀为数百万个参数，包括位置编码、前馈网络和自注意机制等参数密集型元素。然而，这种复杂性导致了禁止性的模型规模，特别是考虑到时间序列数据的语义简单性。出于追求简洁性的动机，我们的研究利用条件相关性和自相关性作为调查工具，揭示了输入数据中的显著冗余。借助这些见解，我们引入了HDformer，这是一种轻量级的Transformer变体，经过增强，使用蒸馏技术和快速网络连接层来降低模型复杂性。

    Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, distinguished by its focus on extensive input sequences, in contrast to the constrained lengths typical of traditional approaches. While longer sequences inherently convey richer information, potentially enhancing predictive precision, prevailing techniques often respond by escalating model complexity. These intricate models can inflate into millions of parameters, incorporating parameter-intensive elements like positional encodings, feed-forward networks and self-attention mechanisms. This complexity, however, leads to prohibitive model scale, particularly given the time series data's semantic simplicity. Motivated by the pursuit of parsimony, our research employs conditional correlation and auto-correlation as investigative tools, revealing significant redundancies within the input data. Leveraging these insights, we introduce the HDformer, a lightweight Transformer variant enhanced with 
    
[^38]: 用原型半监督学习和基础模型实现高效的超出分布检测

    Efficient Out-of-Distribution Detection with Prototypical Semi-Supervised Learning and Foundation Models

    [https://arxiv.org/abs/2311.17093](https://arxiv.org/abs/2311.17093)

    本文介绍了一种新的改进的半监督学习方法，利用冻结的基础模型作为神经网络骨干，在半监督学习和超出分布检测方面取得了优越的表现，并引入了新的预训练技术、损失函数和原型选择方法。

    

    本文介绍了PAWS-VMK，一种改进的原型半监督学习方法，专门设计用于利用冻结的基础模型作为神经网络骨干，该方法在计算机视觉领域中优于以往的半监督学习和超出分布（OOD）检测结果，改进了Predicting View-Assignments With Support Samples（PAWS）半监督学习方法。我们引入了(1) 参数化von-Mises Fisher随机邻域嵌入（vMF-SNE）来预训练投影头，使用基础模型的高质量嵌入;(2) 受MixMatch启发的损失，通过对多视图的预测进行平均，提供比PAWS中使用的一致性损失更可靠的监督信号;和(3) 简单k-Means原型选择（SKMPS），一种比其他无监督标签选择方法提供更优越性能的技术。

    arXiv:2311.17093v2 Announce Type: replace-cross  Abstract: This paper describes PAWS-VMK, an improved approach to prototypical semi-supervised learning in the field of computer vision, specifically designed to utilize a frozen foundation model as the neural network backbone. This method outperforms previous results in semi-supervised learning and out-of-distribution (OOD) detection, improving upon the Predicting View-Assignments With Support Samples (PAWS) semi-supervised learning method. We introduce (1) parametric von-Mises Fisher Stochastic Neighbour Embedding (vMF-SNE) to pretrain the projection head using the high-quality embeddings of the foundation model; (2) a MixMatch inspired loss, where predictions across multiple views are averaged to provide a more reliable supervision signal compared to the consistency loss used in PAWS and (3) simple $k$-Means prototype selection (SKMPS), a technique that provides superior performance to other unsupervised label selection approaches in t
    
[^39]: 关于风险感知代理理论：桥接演员-评论家和经济学

    On the Theory of Risk-Aware Agents: Bridging Actor-Critic and Economics

    [https://arxiv.org/abs/2310.19527](https://arxiv.org/abs/2310.19527)

    通过应用期望效用假设，本文揭示了风险中性和风险感知RL目标实际上可以通过使用指数效用函数的期望效用最大化来解释，提出了双演员-评论家（DAC）算法，为风险感知的RL算法贡献了框架。

    

    arXiv:2310.19527v2 公告类型：替换 摘要：风险感知强化学习（RL）算法如SAC和TD3在各种连续动作任务中的实证表现优于其风险中性对应物。然而，这些算法采用的悲观目标的理论基础尚未建立，这引发了关于它们实施的具体政策类别的问题。 在本研究中，我们应用了期望效用假设，这是经济学中的一个基本概念，以阐明风险中性和风险感知RL目标可以通过使用指数效用函数的期望效用最大化来解释。 这种方法揭示了风险感知政策有效地最大化了价值确定性等价物，使其与传统决策理论原则保持一致。此外，我们提出了双演员-评论家（Dual Actor-Critic，DAC）。 DAC是一种风险感知的无模型算法，具有两个不同的演员网络：一个用于时序差分的悲观演员。

    arXiv:2310.19527v2 Announce Type: replace  Abstract: Risk-aware Reinforcement Learning (RL) algorithms like SAC and TD3 were shown empirically to outperform their risk-neutral counterparts in a variety of continuous-action tasks. However, the theoretical basis for the pessimistic objectives these algorithms employ remains unestablished, raising questions about the specific class of policies they are implementing. In this work, we apply the expected utility hypothesis, a fundamental concept in economics, to illustrate that both risk-neutral and risk-aware RL goals can be interpreted through expected utility maximization using an exponential utility function. This approach reveals that risk-aware policies effectively maximize value certainty equivalent, aligning them with conventional decision theory principles. Furthermore, we propose Dual Actor-Critic (DAC). DAC is a risk-aware, model-free algorithm that features two distinct actor networks: a pessimistic actor for temporal-difference 
    
[^40]: 在Wasserstein概率空间上理解Riemannian SGD和SVRG流的研究

    Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])

    [http://arxiv.org/abs/2401.13530](http://arxiv.org/abs/2401.13530)

    本文研究了在Wasserstein概率空间上的Riemannian SGD和SVRG流的优化方法，通过构建随机微分方程来丰富Wasserstein空间中的连续优化方法。

    

    最近，对于Riemannian流形上的优化研究为优化领域提供了新的见解。在这方面，概率测度度量空间作为流形，配备第二阶Wasserstein距离，尤其引人关注，因为在其上的优化可以与实际的采样过程相关联。一般来说，Wasserstein空间上的最优化方法是Riemannian梯度流（即，在最小化KL散度时的Langevin动力学）。在本文中，我们旨在通过将梯度流延展到随机梯度下降（SGD）流和随机方差减少梯度（SVRG）流，丰富Wasserstein空间中的连续优化方法。Euclidean空间上的这两种流是标准的随机优化方法，而它们在Riemannian空间中的对应方法尚未被探索。通过利用Wasserstein空间中的结构，我们构建了一个随机微分方程（SDE）来近似离散动态。

    Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamic
    
[^41]: 走向基于原则的图形变换器

    Towards Principled Graph Transformers. (arXiv:2401.10119v1 [cs.LG])

    [http://arxiv.org/abs/2401.10119](http://arxiv.org/abs/2401.10119)

    边缘变换器是一个全局注意力模型，它具有至少3-WL的表达能力，能够在预测性能上超过其他架构，而不依赖于位置或结构编码。

    

    基于k维Weisfeiler-Leman（k-WL）层次结构的图形学习架构提供了理论上很好理解的表达能力。然而，这样的架构在真实任务中往往无法提供可靠的预测性能，从而限制了它们的实际影响力。相比之下，基于全局注意力的模型如图形变换器在实践中表现出了强大的性能，但是将它们的表达能力与k-WL层次结构进行比较仍然具有挑战性，尤其是因为这些架构依赖于位置或结构编码来实现其表达能力和预测性能。为了解决这个问题，我们展示了最近提出的边缘变换器，这是一个在节点对而不是节点上进行操作的全局注意力模型，具有至少3-WL的表达能力。经验上，我们证明了边缘变换器在预测性能上超过了其他理论对齐的架构，同时不依赖于位置或结构编码。

    Graph learning architectures based on the k-dimensional Weisfeiler-Leman (k-WL) hierarchy offer a theoretically well-understood expressive power. However, such architectures often fail to deliver solid predictive performance on real-world tasks, limiting their practical impact. In contrast, global attention-based models such as graph transformers demonstrate strong performance in practice, but comparing their expressive power with the k-WL hierarchy remains challenging, particularly since these architectures rely on positional or structural encodings for their expressivity and predictive performance. To address this, we show that the recently proposed Edge Transformer, a global attention model operating on node pairs instead of nodes, has at least 3-WL expressive power. Empirically, we demonstrate that the Edge Transformer surpasses other theoretically aligned architectures regarding predictive performance while not relying on positional or structural encodings.
    
[^42]: DiffClone: 使用扩散驱动的策略学习增强机器人行为克隆

    DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning. (arXiv:2401.09243v1 [cs.RO])

    [http://arxiv.org/abs/2401.09243](http://arxiv.org/abs/2401.09243)

    本文介绍了DiffClone，一种通过扩散驱动的策略学习增强行为克隆代理的离线算法。在真实的在线物理机器人上的实验表明，采用MOCO微调的ResNet50的效果最好。

    

    机器人学习任务在计算上非常密集且硬件特定。因此，通过使用多样化的离线演示数据集来训练机器人操作代理，来应对这些挑战的方式非常吸引人。Train-Offline-Test-Online（TOTO）基准提供了一个经过精心策划的开源离线训练数据集，主要由专家数据组成，并提供了常见离线强化学习和行为克隆代理的基准分数。在本文中，我们介绍了DiffClone，一种增强行为克隆代理的离线算法，采用基于扩散的策略学习，并在测试时在真实的在线物理机器人上评估了我们的方法的有效性。同时，这也是我们在NeurIPS 2023举办的Train-Offline-Test-Online（TOTO）基准挑战赛中的官方提交。我们尝试了预训练的视觉表示和代理策略。在实验中，我们发现MOCO微调的ResNet50相比其他微调方法表现最好。

    Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned
    
[^43]: 通过神经坍塌的视角检测到群外分布

    Detecting Out-of-Distribution Through the Lens of Neural Collapse. (arXiv:2311.01479v1 [cs.LG])

    [http://arxiv.org/abs/2311.01479](http://arxiv.org/abs/2311.01479)

    通过观察到的群内特征聚集和群外特征离散的性质，本论文提出了一种基于特征和权重向量接近程度的神经坍塌（NC-OOD）检测器来提高OAD检测的泛化能力，并取得了最先进的效果。

    

    群外（OOD）检测对于安全部署人工智能至关重要。特别是，OOD检测器应该在各种场景中有效地泛化。为了改进现有OOD检测器的泛化能力，我们引入了一种高度灵活的OOD检测器，称为神经坍塌（NC-OOD）检测器。我们扩展了普遍观察到的群内（ID）特征倾向于形成簇，而群外特征则远离的观察。特别是基于最近的观察结果，神经坍塌，我们进一步证明ID特征倾向于在接近权重向量的位置聚集。根据我们的扩展观察，我们提出了一种基于特征与权重向量的接近程度来检测OOD的方法。为了进一步排除OOD样本，我们利用了OOD特征倾向于比ID特征更接近原点的观察结果。大量实验证明我们的方法增强了现有工作的泛化能力，并且在OOD检测方面始终能够达到最先进的水平。

    Out-of-distribution (OOD) detection is essential for the safe deployment of AI. Particularly, OOD detectors should generalize effectively across diverse scenarios. To improve upon the generalizability of existing OOD detectors, we introduce a highly versatile OOD detector, called Neural Collapse inspired OOD detector (NC-OOD). We extend the prevalent observation that in-distribution (ID) features tend to form clusters, whereas OOD features are far away. Particularly, based on the recent observation, Neural Collapse, we further demonstrate that ID features tend to cluster in proximity to weight vectors. From our extended observation, we propose to detect OOD based on feature proximity to weight vectors. To further rule out OOD samples, we leverage the observation that OOD features tend to reside closer to the origin than ID features. Extensive experiments show that our approach enhances the generalizability of existing work and can consistently achieve state-of-the-art OOD detection per
    
[^44]: 集群中的比例公平性: 社会选择视角的研究

    Proportional Fairness in Clustering: A Social Choice Perspective. (arXiv:2310.18162v1 [cs.LG])

    [http://arxiv.org/abs/2310.18162](http://arxiv.org/abs/2310.18162)

    在这篇论文中，我们研究了比例聚类问题，将其与计算社会选择中的多赢家投票领域相关联。我们发现满足Brill和Peters的比例概念的任何聚类都能同时获得Chen等人的比例公平性、个体公平性和核心的最佳近似。我们还研究了更强的比例代表性概念，并展示了这些更强概念对应的近似。

    

    我们研究了Chen等人的比例聚类问题，并将其与计算社会选择中的多赢家投票领域相关联。我们展示了满足Brill和Peters的弱比例概念的任何聚类同时获得了Chen等人的比例公平性的最佳近似，也获得了个体公平性和“核心”的最佳近似。事实上，我们表明任何对比例公平性的近似也是对个体公平性的近似，反之亦然。最后，我们还研究了更强的比例代表性概念，其中偏差不仅发生在单个候选中心，而是多个候选中心，并展示了Brill和Peters的更强比例概念暗示了这些更强保证的近似。

    We study the proportional clustering problem of Chen et al. [ICML'19] and relate it to the area of multiwinner voting in computational social choice. We show that any clustering satisfying a weak proportionality notion of Brill and Peters [EC'23] simultaneously obtains the best known approximations to the proportional fairness notion of Chen et al. [ICML'19], but also to individual fairness [Jung et al., FORC'20] and the "core" [Li et al. ICML'21]. In fact, we show that any approximation to proportional fairness is also an approximation to individual fairness and vice versa. Finally, we also study stronger notions of proportional representation, in which deviations do not only happen to single, but multiple candidate centers, and show that stronger proportionality notions of Brill and Peters [EC'23] imply approximations to these stronger guarantees.
    
[^45]: 后验采样学习算法在序列化POMDPs中的遗憾分析

    Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])

    [http://arxiv.org/abs/2310.10107](http://arxiv.org/abs/2310.10107)

    本文分析了后验采样学习算法在序列化POMDPs中的遗憾性能，并在一定条件下提供了改进的多项式贝叶斯遗憾界。

    

    相比于马尔科夫决策过程（MDPs），部分可观察马尔科夫决策过程（POMDPs）的学习由于观察数据难以解读而变得更加困难。在本文中，我们考虑了具有未知转移和观测模型的POMDPs中的序列化学习问题。我们考虑了基于后验采样的强化学习算法（PSRL）在POMDPs中的应用，并证明其贝叶斯遗憾随着序列的数量的平方根而缩小。一般来说，遗憾随着时间长度$H$呈指数级增长，并通过提供一个下界证明了这一点。然而，在POMDP是欠完备且弱可识别的条件下，我们建立了一个多项式贝叶斯遗憾界，相比于arXiv:2204.08967的最新结果，改进了遗憾界约$\Omega(H^2\sqrt{SA})$倍。

    Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
    
[^46]: 一种用于联邦学习的碳追踪模型：量化和稀疏化的影响

    A Carbon Tracking Model for Federated Learning: Impact of Quantization and Sparsification. (arXiv:2310.08087v1 [eess.SP])

    [http://arxiv.org/abs/2310.08087](http://arxiv.org/abs/2310.08087)

    本文提出了一个碳追踪模型，用于实时监测联邦学习系统的能源消耗和碳足迹影响。通过对不同的计算和通信高效联邦学习方法进行定量评估，为减少能源消耗和碳排放提供了参考。

    

    联邦学习方法采用高效的通信技术将机器学习任务分布在边缘设备上，与集中式解决方案相比，在数据存储和计算复杂性方面减少了开销。联邦学习为解决从生产者（传感器、机器）到能耗高的数据中心大量传输数据引起的资源需求而引发的环境问题提供了替代解决方案，同时使得新的物联网人工智能（AIoT）应用成为可能。本文提出了一个用于实时监测联邦学习系统能源消耗和碳足迹影响的框架。该碳追踪工具对共识（完全分散）和传统联邦学习策略进行了评估。我们首次从能耗和等效碳排放的角度定量评估了不同的计算和通信高效联邦学习方法。

    Federated Learning (FL) methods adopt efficient communication technologies to distribute machine learning tasks across edge devices, reducing the overhead in terms of data storage and computational complexity compared to centralized solutions. Rather than moving large data volumes from producers (sensors, machines) to energy-hungry data centers, raising environmental concerns due to resource demands, FL provides an alternative solution to mitigate the energy demands of several learning tasks while enabling new Artificial Intelligence of Things (AIoT) applications. This paper proposes a framework for real-time monitoring of the energy and carbon footprint impacts of FL systems. The carbon tracking tool is evaluated for consensus (fully decentralized) and classical FL policies. For the first time, we present a quantitative evaluation of different computationally and communication efficient FL methods from the perspectives of energy consumption and carbon equivalent emissions, suggesting 
    
[^47]: 关于通过指数机制进行高维私有模型选择的计算复杂性

    On the Computational Complexity of Private High-dimensional Model Selection via the Exponential Mechanism. (arXiv:2310.07852v1 [stat.ML])

    [http://arxiv.org/abs/2310.07852](http://arxiv.org/abs/2310.07852)

    本文研究了在高维稀疏线性回归模型中的差分隐私模型选择问题。我们使用指数机制进行模型选择，并提出了Metropolis-Hastings算法来克服指数搜索空间的计算复杂性。我们的算法在一定边界条件下能够实现强模型恢复性质，并具有多项式混合时间和近似差分隐私性质。

    

    在差分隐私框架下，我们考虑了高维稀疏线性回归模型中的模型选择问题。具体而言，我们考虑了差分隐私最佳子集选择的问题，并研究了其效用保证。我们采用了广为人知的指数机制来选择最佳模型，并在一定边界条件下，建立了其强模型恢复性质。然而，指数机制的指数搜索空间导致了严重的计算瓶颈。为了克服这个挑战，我们提出了Metropolis-Hastings算法来进行采样步骤，并在问题参数$n$、$p$和$s$中建立了其到稳态分布的多项式混合时间。此外，我们还利用其混合性质建立了Metropolis-Hastings随机行走的最终估计的近似差分隐私性质。最后，我们还进行了一些说明性模拟，印证了我们主要结果的理论发现。

    We consider the problem of model selection in a high-dimensional sparse linear regression model under the differential privacy framework. In particular, we consider the problem of differentially private best subset selection and study its utility guarantee. We adopt the well-known exponential mechanism for selecting the best model, and under a certain margin condition, we establish its strong model recovery property. However, the exponential search space of the exponential mechanism poses a serious computational bottleneck. To overcome this challenge, we propose a Metropolis-Hastings algorithm for the sampling step and establish its polynomial mixing time to its stationary distribution in the problem parameters $n,p$, and $s$. Furthermore, we also establish approximate differential privacy for the final estimates of the Metropolis-Hastings random walk using its mixing property. Finally, we also perform some illustrative simulations that echo the theoretical findings of our main results
    
[^48]: 通用图随机特征

    Universal Graph Random Features. (arXiv:2310.04859v1 [stat.ML])

    [http://arxiv.org/abs/2310.04859](http://arxiv.org/abs/2310.04859)

    本文提出了一种新的准蒙特卡罗机制，称为排斥随机游走，通过改进图的采样，提高了统计估计器的集中度。该机制在估计图内核、PageRank向量和图形浓度等方面展示了有效性。

    

    我们提出了一种新颖的准蒙特卡罗机制，称为排斥随机游走，以改进基于图的采样。通过在相互作用集合的轨迹之间引入相关性，使它们的边际转移概率保持不变，我们能够更高效地探索图形，提高统计估计器的集中度，同时保持它们的无偏性。该机制可以轻松地实现。我们展示了在估计图内核、PageRank向量和图形浓度等各种情况下，排斥随机游走的有效性。我们提供了详细的实验评估和鲁棒的理论保证。据我们所知，排斥随机游走是第一个在图上相关步行者方向进行严格研究的准蒙特卡罗方案，为这个令人兴奋的新兴领域带来了新的研究。

    We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
    
[^49]: 抵制随机游走

    Repelling Random Walks. (arXiv:2310.04854v1 [stat.ML])

    [http://arxiv.org/abs/2310.04854](http://arxiv.org/abs/2310.04854)

    抵制随机游走是一种新的准蒙特卡罗机制，通过在图上的行走者之间引入相关性，能够更高效地探索图并提高统计估计的集中度，同时保持其无偏性。此机制在估计图核、PageRank向量和图元浓度等多个领域都展示了其有效性，并提供了详细的实验评估和理论保证。

    

    我们提出了一种新的准蒙特卡罗机制来改进基于图的抽样，称为抵制随机游走。通过在一个相互作用的集合中的轨迹之间引入相关性，使它们的边际转移概率保持不变，我们能够更有效地探索图，提高统计估计器的集中度，同时保持其无偏性。这个机制有一个简单的插入实现方式。我们展示了抵制随机游走在一系列设置中的有效性，包括图核的估计、PageRank向量和图元浓度。我们提供了详细的实验评估和稳健的理论保证。据我们所知，抵制随机游走是首个在图上相关行走方向的准蒙特卡罗方案进行了严谨研究，为这个令人兴奋的新兴领域开展新的研究提供了契机。

    We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain.
    
[^50]: 完美对齐可能对图形对比学习产生负面影响

    Perfect Alignment May be Poisonous to Graph Contrastive Learning. (arXiv:2310.03977v1 [cs.LG])

    [http://arxiv.org/abs/2310.03977](http://arxiv.org/abs/2310.03977)

    本研究探讨了图形对比学习中增强方法和下游性能的关系，并发现图形对比学习主要通过分离不同类别的节点来为下游任务做出贡献。

    

    图形对比学习旨在通过对齐正样本和分离负样本来学习节点表示。然而，在基于图形的学习中，对于特定增强方法背后的内在规律的研究有限。什么样的增强方法可以提高下游性能？对比学习如何实际影响下游任务？为什么增强的幅度很重要？本文试图通过建立增强方法和下游性能之间的联系，以及对对比学习的泛化性进行研究来回答这些问题。我们的发现表明，图形对比学习主要通过分离不同类别而不是聚集同一类别的节点来为下游任务做出贡献。因此，无法解释对比学习的成功，即全部样本完美对齐和增强重叠。为了理解增强如何辅助对比学习过程，我们进行了进一步的研究。

    Graph Contrastive Learning (GCL) aims to learn node representations by aligning positive pairs and separating negative ones. However, limited research has been conducted on the inner law behind specific augmentations used in graph-based learning. What kind of augmentation will help downstream performance, how does contrastive learning actually influence downstream tasks, and why the magnitude of augmentation matters? This paper seeks to address these questions by establishing a connection between augmentation and downstream performance, as well as by investigating the generalization of contrastive learning. Our findings reveal that GCL contributes to downstream tasks mainly by separating different classes rather than gathering nodes of the same class. So perfect alignment and augmentation overlap which draw all intra-class samples the same can not explain the success of contrastive learning. Then in order to comprehend how augmentation aids the contrastive learning process, we conduct 
    
[^51]: 通过最大化梯度多样性来解决联邦优化中的混合异构性

    Tackling Hybrid Heterogeneity on Federated Optimization via Gradient Diversity Maximization. (arXiv:2310.02702v1 [cs.LG])

    [http://arxiv.org/abs/2310.02702](http://arxiv.org/abs/2310.02702)

    本文探讨了混合异构性如何影响联邦优化，并提出了一种通过最大化梯度多样性来减轻混合异构性负面影响的方法。

    

    联邦学习是一种分布式机器学习范式，其中数据样本被分散和分布在多个客户端之间。这些样本可能表现出统计异质性，即数据分布在客户端之间不是独立和相同的。此外，系统异质性，即客户端计算能力的变化，会给联邦学习带来偏差。统计和系统异质性的综合效应可以显著降低联邦优化的效率。然而，混合异构性的影响并没有得到严谨的讨论。本文通过研究服务器端优化，探讨了混合异构性如何影响联邦优化。理论结果表明，在服务器更新方向上自适应地最大化梯度多样性可以帮助减轻混合异构性的潜在负面影响。为此，我们引入了一种新颖的基于服务器端梯度的优化器。

    Federated learning refers to a distributed machine learning paradigm in which data samples are decentralized and distributed among multiple clients. These samples may exhibit statistical heterogeneity, which refers to data distributions are not independent and identical across clients. Additionally, system heterogeneity, or variations in the computational power of the clients, introduces biases into federated learning. The combined effects of statistical and system heterogeneity can significantly reduce the efficiency of federated optimization. However, the impact of hybrid heterogeneity is not rigorously discussed. This paper explores how hybrid heterogeneity affects federated optimization by investigating server-side optimization. The theoretical results indicate that adaptively maximizing gradient diversity in server update direction can help mitigate the potential negative consequences of hybrid heterogeneity. To this end, we introduce a novel server-side gradient-based optimizer \
    
[^52]: HyperMask: 自适应的基于超网络的掩码用于持续学习

    HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning. (arXiv:2310.00113v1 [cs.LG])

    [http://arxiv.org/abs/2310.00113](http://arxiv.org/abs/2310.00113)

    HyperMask是一种用于持续学习的方法，它使用基于超网络的掩码来训练一个单一网络，以克服人工神经网络在多任务上的灾难性遗忘问题。

    

    当人工神经网络在多个任务上顺序训练时，往往会出现灾难性遗忘的问题。为了克服这个问题，已经存在许多持续学习策略，其中最有效的之一是基于超网络的方法。超网络根据任务的特征生成目标模型的权重。然而，该模型的主要限制是超网络对于每个任务可以产生完全不同的网络结构，因此每个任务都是单独解决的。模型在学习后续任务时不使用之前任务所关联的网络信息，并实际上产生了新的网络架构。为了解决这个问题，我们使用了彩票票证假设，该假设认为存在稀疏的子网络（即中奖票），可以保持完整网络的性能。在本文中，我们提出了一种名为HyperMask的方法，该方法为所有任务训练一个单一网络。超网络产生半二进制掩码，以获取目标子网络。

    Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, there exist many continual learning strategies. One of the most effective is the hypernetwork-based approach. The hypernetwork generates the weights of a target model based on the task's identity. The model's main limitation is that hypernetwork can produce completely different nests for each task. Consequently, each task is solved separately. The model does not use information from the network dedicated to previous tasks and practically produces new architectures when it learns the subsequent tasks. To solve such a problem, we use the lottery ticket hypothesis, which postulates the existence of sparse subnetworks, named winning tickets, that preserve the performance of a full network.  In the paper, we propose a method called HyperMask, which trains a single network for all tasks. Hypernetwork produces semi-binary masks to obtain target subnetw
    
[^53]: 利用潜在信息从视觉观察中进行对抗性模仿学习

    Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v1 [cs.LG])

    [http://arxiv.org/abs/2309.17371](http://arxiv.org/abs/2309.17371)

    本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。

    

    我们专注于从视觉观察中进行模仿学习的问题，学习代理只能访问专家的视频作为其唯一的学习源。这个框架的挑战包括缺乏专家的动作和环境的局部可观测性，因为地面真实状态只能从像素中推断出来。为了解决这个问题，我们首先对部分可观测环境中的模仿学习进行了理论分析。我们在专家和代理潜在状态转换分布之间的差异度上建立了学习代理子优度的上界。受到这个分析的启发，我们引入了一种称为潜在对抗观察模仿的算法，它将离策略对抗学习技术与从观察序列中学习的代理状态的潜在表示相结合。在高维连续机器人任务的实验证明，我们的算法与最先进的方法相匹配。

    We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-t
    
[^54]: 识别性很重要：揭示无偏学习排名中隐藏的可恢复条件

    Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank. (arXiv:2309.15560v1 [cs.IR])

    [http://arxiv.org/abs/2309.15560](http://arxiv.org/abs/2309.15560)

    研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。

    

    无偏学习排名(Unbiased Learning to Rank, ULTR)在从有偏点击日志训练无偏排名模型的现代系统中被广泛应用。关键在于明确地建模用户行为的生成过程，并基于检验假设对点击数据进行拟合。先前的研究经验性地发现只要点击完全拟合，大多数情况下可以恢复出真实潜在相关性。然而，我们证明并非总是能够实现这一点，从而导致排名性能显著降低。在本工作中，我们旨在回答真实相关性是否能够从点击数据恢复出来的问题，这是ULTR领域的一个基本问题。我们首先将一个排名模型定义为可识别的，如果它可以恢复出真实相关性，最多只有一个缩放变换，这对于成对排名目标来说已足够。然后，我们探讨了一个等价的可识别条件，可以新颖地表达为一个图连通性测试问题：当且仅当一个图（即可识别性图）连通时，该排名模型是可识别的。

    The application of Unbiased Learning to Rank (ULTR) is widespread in modern systems for training unbiased ranking models from biased click logs. The key is to explicitly model a generation process for user behavior and fit click data based on examination hypothesis. Previous research found empirically that the true latent relevance can be recovered in most cases as long as the clicks are perfectly fitted. However, we demonstrate that this is not always achievable, resulting in a significant reduction in ranking performance. In this work, we aim to answer if or when the true relevance can be recovered from click data, which is a foundation issue for ULTR field. We first define a ranking model as identifiable if it can recover the true relevance up to a scaling transformation, which is enough for pairwise ranking objective. Then we explore an equivalent condition for identifiability that can be novely expressed as a graph connectivity test problem: if and only if a graph (namely identifi
    
[^55]: 图对比学习的可证明训练方法

    Provable Training for Graph Contrastive Learning. (arXiv:2309.13944v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13944](http://arxiv.org/abs/2309.13944)

    图对比学习中，我们发现训练存在不平衡的问题，为此我们提出了“节点紧凑性”度量来指导训练。

    

    图对比学习（GCL）已经成为一种从增强图中学习节点嵌入而无需标签的流行训练方法。尽管最大化正节点对之间的相似性并最小化负节点对之间的相似性的关键原则已经得到确认，但仍存在一些基本问题。考虑到复杂的图结构，是否有一些节点始终按照这一原则进行良好训练，即使在不同的图增强方法下也是如此？还是有一些节点更有可能在图增强中未经训练，并违反这一原则？如何区分这些节点并进一步指导GCL的训练？为了回答这些问题，我们首先提出了实验证据，表明GCL的训练在所有节点上确实存在不平衡。为了解决这个问题，我们提出了度量“节点紧凑性”，它是节点遵循GCL原则与增强范围相关的下界。我们进一步导出了

    Graph Contrastive Learning (GCL) has emerged as a popular training approach for learning node embeddings from augmented graphs without labels. Despite the key principle that maximizing the similarity between positive node pairs while minimizing it between negative node pairs is well established, some fundamental problems are still unclear. Considering the complex graph structure, are some nodes consistently well-trained and following this principle even with different graph augmentations? Or are there some nodes more likely to be untrained across graph augmentations and violate the principle? How to distinguish these nodes and further guide the training of GCL? To answer these questions, we first present experimental evidence showing that the training of GCL is indeed imbalanced across all nodes. To address this problem, we propose the metric "node compactness", which is the lower bound of how a node follows the GCL principle related to the range of augmentations. We further derive the
    
[^56]: Des-q: 一种用于回归和二分类的构建和高效重新训练决策树的量子算法

    Des-q: a quantum algorithm to construct and efficiently retrain decision trees for regression and binary classification. (arXiv:2309.09976v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2309.09976](http://arxiv.org/abs/2309.09976)

    Des-q是一种量子算法，用于在回归和二分类任务中构建和重新训练决策树。它显著减少了树重新训练所需的时间复杂度，并且能够处理新样本的加载时间。该算法通过 k 分段线性树分裂来构建决策树，将数据划分为不同的子空间。

    

    决策树由于其简单构造和可解释性而广泛应用于机器学习。然而，随着数据规模的增长，传统的决策树构建和重新训练方法变得越来越慢，与训练样本数量呈多项式规模。在本研究中，我们介绍了一种新颖的量子算法Des-q，用于在回归和二分类任务中构建和重新训练决策树。假设数据流产生较小的新训练样本增量，我们证明了我们的Des-q算法显著减少了树重新训练所需的时间，即使考虑将新样本加载到量子可访问内存所需的时间，其时间复杂度也达到了多对数级别。我们的方法涉及构建一个决策树算法，在每个内部节点执行k分段线性树分裂。这些分裂同时生成多个超平面，将数据划分为不同的子空间。

    Decision trees are widely used in machine learning due to their simplicity in construction and interpretability. However, as data sizes grow, traditional methods for constructing and retraining decision trees become increasingly slow, scaling polynomially with the number of training examples. In this work, we introduce a novel quantum algorithm, named Des-q, for constructing and retraining decision trees in regression and binary classification tasks. Assuming the data stream produces small increments of new training examples, we demonstrate that our Des-q algorithm significantly reduces the time required for tree retraining, achieving a poly-logarithmic time complexity in the number of training examples, even accounting for the time needed to load the new examples into quantum-accessible memory. Our approach involves building a decision tree algorithm to perform k-piecewise linear tree splits at each internal node. These splits simultaneously generate multiple hyperplanes, dividing the
    
[^57]: 即使在深度线性网络中也存在关键学习期

    Critical Learning Periods Emerge Even in Deep Linear Networks. (arXiv:2308.12221v1 [cs.LG])

    [http://arxiv.org/abs/2308.12221](http://arxiv.org/abs/2308.12221)

    即使在深度线性网络中也存在关键学习期，这些关键学习期取决于模型的深度和数据分布的结构。

    

    关键学习期是指在发育早期，暂时的感知缺陷会对行为和学习表示产生永久影响的时间段。尽管生物网络和人工网络之间存在根本性的差异，但关键学习期在两个系统中都有经验观察到。这表明关键学习期可能是学习的基本要素，而不是生物学上的偶然现象。然而，为什么关键学习期会在深度网络中出现仍然是一个未解之谜，尤其是不清楚在两个系统中观察到的关键学习期是否依赖于特定的架构或优化细节。为了确定关键的基本因素，我们专注于深度线性网络模型，并展示了令人惊讶的是，这样的网络也显示出生物学和人工网络中观察到的许多行为，同时还可以进行分析处理。我们展示了关键学习期取决于模型的深度和数据分布的结构。

    Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show 
    
[^58]: 一个用于k-Means的量子逼近方案

    A Quantum Approximation Scheme for k-Means. (arXiv:2308.08167v1 [quant-ph])

    [http://arxiv.org/abs/2308.08167](http://arxiv.org/abs/2308.08167)

    这个论文提出了一个量子逼近方案，用于解决经典的k-Means聚类问题，该方案的运行时间与数据点的数量具有多对数依赖关系，并且能够在高概率下输出一个近似最优解，这是第一个具有多对数运行时间的量子算法，并且能够提供一个可证明的逼近保证。

    

    我们在QRAM模型中提供了一个量子逼近方案（即对于任意ε > 0, 都是 (1 + ε)-逼近），用于经典的k-Means聚类问题，其运行时间仅与数据点的数量具有多对数依赖关系。具体而言，给定一个在QRAM数据结构中存储的具有N个点的数据集V，这个量子算法的运行时间为Õ(2^(Õ(k/ε))η^2d)，并且以高概率输出一个包含k个中心的集合C，满足cost(V, C) ≤ (1+ε) · cost(V, C_OPT)。这里C_OPT表示最优的k个中心，cost(.)表示标准的k-Means代价函数（即点到最近中心的平方距离之和），而η是纵横比（即最远距离与最近距离的比值）。这是第一个具有多对数运行时间的量子算法，并且能够提供一个可证明的(1+ε)逼近保证。

    We give a quantum approximation scheme (i.e., $(1 + \varepsilon)$-approximation for every $\varepsilon > 0$) for the classical $k$-means clustering problem in the QRAM model with a running time that has only polylogarithmic dependence on the number of data points. More specifically, given a dataset $V$ with $N$ points in $\mathbb{R}^d$ stored in QRAM data structure, our quantum algorithm runs in time $\tilde{O} \left( 2^{\tilde{O}(\frac{k}{\varepsilon})} \eta^2 d\right)$ and with high probability outputs a set $C$ of $k$ centers such that $cost(V, C) \leq (1+\varepsilon) \cdot cost(V, C_{OPT})$. Here $C_{OPT}$ denotes the optimal $k$-centers, $cost(.)$ denotes the standard $k$-means cost function (i.e., the sum of the squared distance of points to the closest center), and $\eta$ is the aspect ratio (i.e., the ratio of maximum distance to minimum distance). This is the first quantum algorithm with a polylogarithmic running time that gives a provable approximation guarantee of $(1+\varep
    
[^59]: 子模块强化学习

    Submodular Reinforcement Learning. (arXiv:2307.13372v1 [cs.LG])

    [http://arxiv.org/abs/2307.13372](http://arxiv.org/abs/2307.13372)

    子模块强化学习(SubRL)是一种用于优化非可加奖励的范式，通过子模块集合函数来建模递减回报。这篇论文提出了SubRL的简单策略梯度算法SubPO，可以用于处理这种类型的奖励。

    

    在强化学习中，状态的奖励通常被认为是可加的，并且根据马尔可夫假设，它们与之前访问的状态$\textit{独立}$。在许多重要应用中，如覆盖控制、实验设计和信息路径规划，奖励自然具有递减回报，即其价值随之前访问过的相似状态的增加而减小。为了解决这个问题，我们提出了$\textit{子模块强化学习}$ (SubRL) ，这一范式旨在通过子模块集合函数来建模递减回报，从而优化更一般的非可加奖励（历史相关）。然而，不幸的是，即使在表格设置中，我们证明了得到的优化问题很难近似解决。另一方面，受经典子模块优化中贪婪算法的成功启发，我们提出了SubPO，一种用于SubRL的简单基于策略梯度的算法，通过贪婪地最大化边际来处理非可加奖励。

    In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are $\textit{independent}$ of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose $\textit{submodular RL}$ (SubRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose SubPO, a simple policy gradient-based algorithm for SubRL that handles non-additive rewards by greedily maximizing marginal
    
[^60]: 分期变分推断：何时以及为什么使用？

    Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])

    [http://arxiv.org/abs/2307.11018](http://arxiv.org/abs/2307.11018)

    本文研究了分期变分推断作为近似后验推断的一种通用替代方法，探讨了何时能够达到与传统的因子化变分推断相同的最优解。

    

    分期变分推断（A-VI）是一种近似处理概率模型中的难以计算的后验分布的方法。A-VI的定义特点是学习一个全局推断函数，将每个观察映射到其局部潜变量的近似后验分布。这与更传统的分解（或均场）变分推断（F-VI）形成对比，后者直接学习每个潜变量的近似分布的参数。在深度生成模型中，A-VI用作加速局部潜变量推断的计算技巧。本文研究A-VI作为近似后验推断的一种通用替代方法。由于分期家族是分解家族的子集，A-VI无法产生比F-VI最优解更低的Kullback-Leibler散度的近似值。因此，一个核心的理论问题是刻画A-VI何时仍然达到F-VI的最优解。

    Amortized variational inference (A-VI) is a method for approximating the intractable posterior distributions that arise in probabilistic models. The defining feature of A-VI is that it learns a global inference function that maps each observation to its local latent variable's approximate posterior. This stands in contrast to the more classical factorized (or mean-field) variational inference (F-VI), which directly learns the parameters of the approximating distribution for each latent variable. In deep generative models, A-VI is used as a computational trick to speed up inference for local latent variables. In this paper, we study A-VI as a general alternative to F-VI for approximate posterior inference. A-VI cannot produce an approximation with a lower Kullback-Leibler divergence than F-VI's optimal solution, because the amortized family is a subset of the factorized family. Thus a central theoretical problem is to characterize when A-VI still attains F-VI's optimal solution. We deri
    
[^61]: 非线性元学习可以保证更快的收敛速度

    Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])

    [http://arxiv.org/abs/2307.10870](http://arxiv.org/abs/2307.10870)

    非线性元学习可以保证更快的收敛速度。

    

    最近许多关于元学习的理论研究旨在利用相关任务中的相似表示结构来简化目标任务，并实现收敛速率的保证。然而，在实践中，表示往往是高度非线性的，引入了每个任务中不可简单平均的非平凡偏差。本研究通过非线性表示推导出元学习的理论保证。

    Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
    
[^62]: TACO：基于时间潜在动作驱动对比损失的视觉强化学习

    TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning. (arXiv:2306.13229v1 [cs.LG])

    [http://arxiv.org/abs/2306.13229](http://arxiv.org/abs/2306.13229)

    本文提出了TACO方法，一种基于时间潜在动作驱动对比损失的视觉强化学习方法，能够同时学习状态表示和动作表示，提高代理学习的效率。

    

    尽管在强化学习（RL）从原始像素数据中取得了最近的进展，但样本效率仍然是一个重要的障碍。先前的工作试图通过创建自监督辅助任务来解决这个挑战，旨在为未来状态预测丰富代理学习的表示与控制相关信息。然而，这些目标通常不足以学习能够表示最优策略或值函数的表示，并且它们通常考虑具有小的抽象离散动作空间的任务，因此忽视了在连续控制中动作表示学习的重要性。在本文中，我们引入了TACO：一种简单而强大的时间对比学习方法，利用它，代理可以同时获得潜在状态和动作表示。TACO通过优化重新获得观察与最近的多个先前观察的相似性，同时学习状态与动作表示。

    Despite recent progress in reinforcement learning (RL) from raw pixel data, sample inefficiency continues to present a substantial obstacle. Prior works have attempted to address this challenge by creating self-supervised auxiliary tasks, aiming to enrich the agent's learned representations with control-relevant information for future state prediction. However, these objectives are often insufficient to learn representations that can represent the optimal policy or value function, and they often consider tasks with small, abstract discrete action spaces and thus overlook the importance of action representation learning in continuous control. In this paper, we introduce TACO: Temporal Action-driven Contrastive Learning, a simple yet powerful temporal contrastive learning approach that facilitates the concurrent acquisition of latent state and action representations for agents. TACO simultaneously learns a state and an action representation by optimizing the mutual information between re
    
[^63]: 正则化鲁棒的MDPs和风险敏感的MDPs：等价性、策略梯度和样本复杂度

    Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity. (arXiv:2306.11626v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2306.11626](http://arxiv.org/abs/2306.11626)

    本论文研究了正则化鲁棒MDP问题和风险敏感MDP问题的相关性，并提出了有效的学习算法和样本复杂度分析。

    

    本论文关注于正则化鲁棒马尔可夫决策过程（MDP）问题的强化学习，它是鲁棒MDP框架的一个扩展。我们首先介绍了风险敏感MDP，并建立了风险敏感MDP和正则化鲁棒MDP之间的等价性。这种等价性为解决正则化RMDP提供了另一种视角，并且使得设计高效的学习算法成为可能。在这种等价性的基础上，我们进一步推导了正则化鲁棒MDP问题的策略梯度定理，并在具有直接参数化的表格设置下证明了精确策略梯度方法的全局收敛性。我们还提出了一种基于样本的离线学习算法，即鲁棒的FZI迭代，用于具有KL散度正则化项的特定正则化鲁棒MDP问题，并分析了算法的样本复杂度。我们的结果也得到了数值模拟的支持。

    This paper focuses on reinforcement learning for the regularized robust Markov decision process (MDP) problem, an extension of the robust MDP framework. We first introduce the risk-sensitive MDP and establish the equivalence between risk-sensitive MDP and regularized robust MDP. This equivalence offers an alternative perspective for addressing the regularized RMDP and enables the design of efficient learning algorithms. Given this equivalence, we further derive the policy gradient theorem for the regularized robust MDP problem and prove the global convergence of the exact policy gradient method under the tabular setting with direct parameterization. We also propose a sample-based offline learning algorithm, namely the robust fitted-Z iteration (RFZI), for a specific regularized robust MDP problem with a KL-divergence regularization term and analyze the sample complexity of the algorithm. Our results are also supported by numerical simulations.
    
[^64]: 用于无目标代谢组学数据自动对齐的最优输运

    Optimal transport for automatic alignment of untargeted metabolomic data. (arXiv:2306.03218v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.03218](http://arxiv.org/abs/2306.03218)

    本文提出了一种名为GromovMatcher的算法，通过使用最优输运自动合并LC-MS数据集，可提高数据对齐的准确性和鲁棒性，有效解决代谢组学数据合并的挑战。

    

    液相色谱-质谱（LC-MS）通过测量生物标本中的大量代谢物推动药物研发，疾病诊断和风险预测的进展。然而，LC-MS的低通量对于生物标记物发现，注释和实验比较构成了主要挑战，需要合并多个数据集。当前的数据池化方法由于对数据变化和超参数依赖性的脆弱性而遇到实际限制。本文介绍了GromovMatcher，一种灵活且用户友好的算法，使用最优输运自动结合LC-MS数据集。通过利用特征强度相关结构，GromovMatcher提供了比现有方法更高的对齐准确性和鲁棒性。该算法可扩展到需要最小超参数调整的数千个特征。将我们的方法应用于肝癌和胰腺癌的实验患者研究

    Untargeted metabolomic profiling through liquid chromatography-mass spectrometry (LC-MS) measures a vast array of metabolites within biospecimens, advancing drug development, disease diagnosis, and risk prediction. However, the low throughput of LC-MS poses a major challenge for biomarker discovery, annotation, and experimental comparison, necessitating the merging of multiple datasets. Current data pooling methods encounter practical limitations due to their vulnerability to data variations and hyperparameter dependence. Here we introduce GromovMatcher, a flexible and user-friendly algorithm that automatically combines LC-MS datasets using optimal transport. By capitalizing on feature intensity correlation structures, GromovMatcher delivers superior alignment accuracy and robustness compared to existing approaches. This algorithm scales to thousands of features requiring minimal hyperparameter tuning. Applying our method to experimental patient studies of liver and pancreatic cancer, 
    
[^65]: 通过事后对数归一化和温度缩放改善深度神经网络的选择分类性能

    Improving selective classification performance of deep neural networks through post-hoc logit normalization and temperature scaling. (arXiv:2305.15508v1 [cs.LG])

    [http://arxiv.org/abs/2305.15508](http://arxiv.org/abs/2305.15508)

    本文提出了一种$p$-NormSoftmax的事后置信度估计器来提高深度神经网络的选择分类性能。

    

    本文解决深度神经网络的选择分类问题，其中模型可以避免潜在错误通过放弃低置信度的预测。我们针对的是优化固定分类器的置信度估计器，旨在增强其误分类检测性能，即通过将更高的置信度值分配给正确的预测来区分正确和不正确的预测。我们提出了一个简单有效的事后置信度估计器$p$-NormSoftmax，通过对数进行$p$-范数归一化和温度缩放得到。

    This paper addresses the problem of selective classification for deep neural networks, where a model is allowed to abstain from low-confidence predictions to avoid potential errors. Specifically, we tackle the problem of optimizing the confidence estimator of a fixed classifier, aiming to enhance its misclassification detection performance, i.e., its ability to discriminate between correct and incorrect predictions by assigning higher confidence values to the correct ones. Previous work has found that different classifiers exhibit varying levels of misclassification detection performance, particularly when using the maximum softmax probability (MSP) as a measure of confidence. However, we argue that these findings are mainly due to a sub-optimal confidence estimator being used for each model. To overcome this issue, we propose a simple and efficient post-hoc confidence estimator, named $p$-NormSoftmax, which consists of transforming the logits through $p$-norm normalization and tempera
    
[^66]: 基于代价感知的情境变量在贝叶斯优化中的学习

    Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])

    [http://arxiv.org/abs/2305.14120](http://arxiv.org/abs/2305.14120)

    本文提出一种基于代价感知的模型选择BO方法SADCBO，通过对后验代理模型的敏感性分析来学习关于环境的相关情境信息，并通过平均模型预测来最小化优化代价，在实验中表现出卓越的性能。

    

    情境贝叶斯优化(CBO)是一种强大的框架，可针对设计变量优化黑盒昂贵的评估函数，并同时有效地整合关于环境的相关情境信息，如实验条件。然而，在许多实际场景中，情境变量的相关性不一定是预先已知的。此外，有时还可以最优化情境变量本身，这是当前CBO算法未考虑的设置。优化情境变量可能是昂贵的，这引出了确定一个最小相关子集的问题。在本文中，我们将这个问题作为一个代价感知的模型选择BO任务来构架，采用一种新方法，即基于敏感性分析的情境BO (SADCBO) 来解决这个问题。我们通过对特定输入点后验代理模型的敏感性分析来学习情境变量的相关性，同时通过平均模型预测来最小化优化的代价。SADCBO在多个合成和真实基准问题上进行了实证评估，显示出优于现有算法的性能。

    Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
    
[^67]: Reprompting: 通过吉布斯采样自动推断思维链的提示

    Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling. (arXiv:2305.09993v1 [cs.LG])

    [http://arxiv.org/abs/2305.09993](http://arxiv.org/abs/2305.09993)

    Reprompting是一种无需人类干预的算法，通过迭代采样新配方解决多步推理任务，比人类编写的思维链提示表现更好，还可以提高较弱模型的性能。

    

    我们引入了Reprompting，这是一种迭代采样算法，可以在没有人类干预的情况下搜索给定任务的思维链配方。通过吉布斯采样，我们推断适用于一组训练样例的思维链配方。我们的方法使用先前采样的解作为父提示，迭代地采样新的配方来解决其他训练问题。在需要多步推理的五个Big-Bench Hard任务中，Reprompting的表现始终优于零样本、少样本和人类编写的思维链基线。Reprompting还可以促进知识从一个更强的模型到一个较弱的模型的转移，从而大大提高了较弱模型的性能。总体而言，Reprompting相对于使用人类编写的思维链提示的先前最先进方法，带来了高达+17个性能改进。

    We introduce Reprompting, an iterative sampling algorithm that searches for the Chain-of-Thought (CoT) recipes for a given task without human intervention. Through Gibbs sampling, we infer CoT recipes that work consistently well for a set of training samples. Our method iteratively samples new recipes using previously sampled solutions as parent prompts to solve other training problems. On five Big-Bench Hard tasks that require multi-step reasoning, Reprompting achieves consistently better performance than the zero-shot, few-shot, and human-written CoT baselines. Reprompting can also facilitate transfer of knowledge from a stronger model to a weaker model leading to substantially improved performance of the weaker model. Overall, Reprompting brings up to +17 point improvements over the previous state-of-the-art method that uses human-written CoT prompts.
    
[^68]: 稀疏性可提高神经网络的隐私性

    Sparsity in neural networks can increase their privacy. (arXiv:2304.07234v1 [cs.CR])

    [http://arxiv.org/abs/2304.07234](http://arxiv.org/abs/2304.07234)

    神经网络的稀疏性能提高隐私性并保持性能表现

    

    本文研究了稀疏性如何使神经网络对成员推断攻击更加鲁棒。实证结果表明，稀疏性能够提高网络的隐私性，同时保持相应任务的性能表现。这项实证研究完善了并扩展了现有文献的内容。

    This article measures how sparsity can make neural networks more robust to membership inference attacks. The obtained empirical results show that sparsity improves the privacy of the network, while preserving comparable performances on the task at hand. This empirical study completes and extends existing literature.
    
[^69]: 带函数约束的随机变分不等式问题的一阶方法

    First-order methods for Stochastic Variational Inequality problems with Function Constraints. (arXiv:2304.04778v1 [math.OC])

    [http://arxiv.org/abs/2304.04778](http://arxiv.org/abs/2304.04778)

    本文提出了一种新的一阶方法，适用于具有随机算子和/或随机约束的带函数约束的变分不等式问题，当FCVI问题是确定性非光滑的或随机的时，这些方法可以实现最优算子或样本复杂性。

    

    在机器学习中，单调变分不等式是一个重要的问题。许多情况下，变分不等式问题伴随着可能是数据驱动的函数约束，这使得投影算子的计算变得具有挑战性。本文针对各种情况下的带函数约束的变分不等式问题，包括具有随机算子和/或随机约束的光滑或非光滑问题，提出了新的一阶方法。首先，我们介绍了{\texttt{OpConEx}}方法及其随机变体，它们采用算子和限制评估的外推来更新变量和Lagrangian乘数。当FCVI问题是确定性非光滑的或随机的（包括光滑或非光滑的随机约束）时，这些方法可以实现最优算子或样本复杂性。值得注意的是，我们的算法是简单的单循环程序，不需要知道拉格朗日乘数就可以达到最优性。

    The monotone Variational Inequality (VI) is an important problem in machine learning. In numerous instances, the VI problems are accompanied by function constraints which can possibly be data-driven, making the projection operator challenging to compute. In this paper, we present novel first-order methods for function constrained VI (FCVI) problem under various settings, including smooth or nonsmooth problems with a stochastic operator and/or stochastic constraints. First, we introduce the~{\texttt{OpConEx}} method and its stochastic variants, which employ extrapolation of the operator and constraint evaluations to update the variables and the Lagrangian multipliers. These methods achieve optimal operator or sample complexities when the FCVI problem is either (i) deterministic nonsmooth, or (ii) stochastic, including smooth or nonsmooth stochastic constraints. Notably, our algorithms are simple single-loop procedures and do not require the knowledge of Lagrange multipliers to attain th
    
[^70]: 利用联合稀疏性的分层贝叶斯学习方法

    Leveraging joint sparsity in hierarchical Bayesian learning. (arXiv:2303.16954v1 [stat.ML])

    [http://arxiv.org/abs/2303.16954](http://arxiv.org/abs/2303.16954)

    本文提出了一种分层贝叶斯学习方法，用于从多个测量向量中推断联合稀疏的参数向量，该方法使用共同的伽马分布超参数来强制联合稀疏性，并在实验中进行了验证。

    

    我们提出了一种分层贝叶斯学习方法，从多个测量向量中推断联合稀疏的参数向量。我们的模型为每个参数向量使用单独的条件高斯先验，并使用共同的伽马分布超参数来强制联合稀疏性。得到的联合稀疏性先验与现有的贝叶斯推断方法相结合，形成了一系列新算法。我们的数值实验，包括多线圈磁共振成像应用，证明了我们的新方法始终优于常用的分层贝叶斯方法。

    We present a hierarchical Bayesian learning approach to infer jointly sparse parameter vectors from multiple measurement vectors. Our model uses separate conditionally Gaussian priors for each parameter vector and common gamma-distributed hyper-parameters to enforce joint sparsity. The resulting joint-sparsity-promoting priors are combined with existing Bayesian inference methods to generate a new family of algorithms. Our numerical experiments, which include a multi-coil magnetic resonance imaging application, demonstrate that our new approach consistently outperforms commonly used hierarchical Bayesian methods.
    
[^71]: 利用小波散射变换和1D-CNN进行听诊器心杂音和异常PCG检测

    Heart Murmur and Abnormal PCG Detection via Wavelet Scattering Transform & a 1D-CNN. (arXiv:2303.11423v1 [eess.SP])

    [http://arxiv.org/abs/2303.11423](http://arxiv.org/abs/2303.11423)

    该研究提出了一种小波散射变换和1D-CNN深度学习技术结合的心杂音自动检测方法，可实现97.98%的高准确率。

    

    本项研究利用深度学习技术对听诊器心杂音的自动和准确检测，并使用两个公共PCG数据集（CirCor Digiscope 2022和PCG 2016数据集）进行训练和测试三个自定义神经网络：一维卷积神经网络（CNN），长短期记忆（LSTM）递归神经网络（RNN）和卷积RNN（C-RNN）。

    This work leverages deep learning (DL) techniques in order to do automatic and accurate heart murmur detection from phonocardiogram (PCG) recordings. Two public PCG datasets (CirCor Digiscope 2022 dataset and PCG 2016 dataset) from Physionet online database are utilized to train and test three custom neural networks (NN): a 1D convolutional neural network (CNN), a long short-term memory (LSTM) recurrent neural network (RNN), and a convolutional RNN (C-RNN). Under our proposed method, we first do pre-processing on both datasets in order to prepare the data for the NNs. Key pre-processing steps include the following: denoising, segmentation, re-labeling of noise-only segments, data normalization, and time-frequency analysis of the PCG segments using wavelet scattering transform. To evaluate the performance of the three NNs we have implemented, we conduct four experiments, first three using PCG 2022 dataset, and fourth using PCG 2016 dataset. It turns out that our custom 1D-CNN outperform
    
[^72]: 模型选择配合交叉验证风险估计的无分布偏差界学习方法

    Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation. (arXiv:2303.08777v1 [stat.ML])

    [http://arxiv.org/abs/2303.08777](http://arxiv.org/abs/2303.08777)

    本文提出通过模型选择和交叉验证风险估计来学习的一般方法，并建立了无分布偏差界，比经验风险最小化方法更紧密，在一些情况下表现更优。

    

    交叉验证方法的风险估计和模型选择在统计学和机器学习中得到了广泛应用。然而，学习通过模型选择与交叉验证风险估计的理论性质的理解在其广泛使用面前相当缺乏。在这个背景下，本文将学习通过模型选择与交叉验证风险估计作为一种经典统计学习理论中的一般系统学习框架，并建立了基于VC维的无分布偏差边界，给出了结果的详细证明，并考虑了有界和无界的损失函数。我们还推导出在整个假设空间中，学习通过模型选择的偏差界比通过经验风险最小化学习的偏差界更紧密的条件，支持在一些情况下经验上观察到的模型选择框架的更好性能。

    Cross-validation techniques for risk estimation and model selection are widely used in statistics and machine learning. However, the understanding of the theoretical properties of learning via model selection with cross-validation risk estimation is quite low in face of its widespread use. In this context, this paper presents learning via model selection with cross-validation risk estimation as a general systematic learning framework within classical statistical learning theory and establishes distribution-free deviation bounds in terms of VC dimension, giving detailed proofs of the results and considering both bounded and unbounded loss functions. We also deduce conditions under which the deviation bounds of learning via model selection are tighter than that of learning via empirical risk minimization in the whole hypotheses space, supporting the better performance of model selection frameworks observed empirically in some instances.
    
[^73]: 部分神经最优输运

    Partial Neural Optimal Transport. (arXiv:2303.07988v1 [cs.LG])

    [http://arxiv.org/abs/2303.07988](http://arxiv.org/abs/2303.07988)

    我们提出了一种新的神经方法来计算部分最优输运映射，并在合成例子上进行了测试。

    

    我们提出了一种新颖的神经方法来计算部分最优输运（OT）映射，即指定质量的度量部分之间的OT映射。我们在合成例子上测试了我们的部分神经最优输运算法。

    We propose a novel neural method to compute partial optimal transport (OT) maps, i.e., OT maps between parts of measures of the specified masses. We test our partial neural optimal transport algorithm on synthetic examples.
    
[^74]: 一个渐近最优的凸包成员问题算法

    An Asymptotically Optimal Algorithm for the Convex Hull Membership Problem. (arXiv:2302.02033v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.02033](http://arxiv.org/abs/2302.02033)

    本研究提出了一个名为Thompson-CHM的渐近最优算法，用于解决凸包成员问题，且将算法扩展到了一维和多维环境中。该算法基于模块化设计，包括停止规则和采样规则，并通过数值实验验证了理论结果的准确性。

    

    本研究将凸包成员问题的纯探索设置与凸包均值的有限分布集合中有效准确地确定给定点是否在凸包中相关。我们在一维环境中完全刻画了凸包成员问题的样本复杂性。我们提出了第一个渐近最优算法，名为Thompson-CHM，其模块化设计包括停止规则和采样规则。此外，我们将算法扩展到了一些在多臂赌博机文献中广义的重要问题。此外，我们还讨论了Thompson-CHM在高维情况下的扩展。最后，我们进行了数值实验，以展示算法的经验行为与我们在实际时间范围内的理论结果相匹配。

    This work studies the pure-exploration setting for the convex hull membership (CHM) problem where one aims to efficiently and accurately determine if a given point lies in the convex hull of means of a finite set of distributions. We give a complete characterization of the sample complexity of the CHM problem in the one-dimensional setting. We present the first asymptotically optimal algorithm called Thompson-CHM, whose modular design consists of a stopping rule and a sampling rule. In addition, we extend the algorithm to settings that generalize several important problems in the multi-armed bandit literature. Furthermore, we discuss the extension of Thompson-CHM to higher dimensions. Finally, we provide numerical experiments to demonstrate the empirical behavior of the algorithm matches our theoretical results for realistic time horizons.
    
[^75]: 平均限制策略优化

    Average-Constrained Policy Optimization. (arXiv:2302.00808v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00808](http://arxiv.org/abs/2302.00808)

    本研究提出了一种新的基于函数逼近算法的带平均标准约束 MDP 的策略优化算法，具有较好的性能表现。

    

    有限制条件的强化学习对于各种应用变得越来越重要。通常，平均标准比折扣标准更合适。然而，针对平均限制 CMDP 的强化学习仍然是一个具有挑战性的问题。针对折扣限制 RL 问题设计的算法通常在平均 CMDP 环境下表现不佳。在本文中，我们引入了一种新的基于函数逼近算法的带平均标准约束 MDP 的策略优化算法。平均限制策略优化（ACPO）算法的灵感来自基于信任区域方法的著名 PPO 类算法。我们发展了基本的平均 MDP 敏感性理论，然后在算法设计中使用相应的界限。我们提供了其性能的理论保证，并通过在各种具有挑战性的 MuJoCo 环境中进行大量实验工作，展示了该算法与其他常规算法相比的卓越表现。

    Reinforcement Learning (RL) with constraints is becoming an increasingly important problem for various applications. Often, the average criterion is more suitable than the discounted criterion. Yet, RL for average criterion-constrained MDPs remains a challenging problem. Algorithms designed for discounted constrained RL problems often do not perform well for the average CMDP setting. In this paper, we introduce a new policy optimization with function approximation algorithm for constrained MDPs with the average criterion. The Average-Constrained Policy Optimization (ACPO) algorithm is inspired by the famed PPO-type algorithms based on trust region methods. We develop basic sensitivity theory for average MDPs, and then use the corresponding bounds in the design of the algorithm. We provide theoretical guarantees on its performance, and through extensive experimental work in various challenging MuJoCo environments, show the superior performance of the algorithm when compared to other sta
    
[^76]: RFold：基于解耦优化方法的RNA二级结构预测

    RFold: RNA Secondary Structure Prediction with Decoupled Optimization. (arXiv:2212.14041v2 [q-bio.BM] UPDATED)

    [http://arxiv.org/abs/2212.14041](http://arxiv.org/abs/2212.14041)

    所提出的RFold方法采用解耦优化过程和注意力机制进行简单又有效的RNA二级结构预测，具有较高的准确性和速度。

    

    核糖核酸（RNA）的二级结构比三级结构更稳定和更易于在细胞中访问，因此对于功能预测至关重要。尽管深度学习在这个领域中显示出了很好的结果，但当前的方法存在泛化性差和复杂性高的问题。在这项工作中，我们提出了一种简单而有效的RNA二级结构预测方法RFold。RFold引入了一种解耦优化的过程，将传统的约束满足问题分解为逐行和逐列优化，简化了求解过程，同时保证了输出的有效性。此外，RFold采用注意力地图作为信息表示，而不是设计手工特征。广泛的实验表明，RFold具有竞争性能，并且比现有最先进的方法具有约8倍的推理效率。代码和Colab演示可在\href{this http URL}{this http UR}上找到。

    The secondary structure of ribonucleic acid (RNA) is more stable and accessible in the cell than its tertiary structure, making it essential for functional prediction. Although deep learning has shown promising results in this field, current methods suffer from poor generalization and high complexity. In this work, we present RFold, a simple yet effective RNA secondary structure prediction in an end-to-end manner. RFold introduces a decoupled optimization process that decomposes the vanilla constraint satisfaction problem into row-wise and column-wise optimization, simplifying the solving process while guaranteeing the validity of the output. Moreover, RFold adopts attention maps as informative representations instead of designing hand-crafted features. Extensive experiments demonstrate that RFold achieves competitive performance and about eight times faster inference efficiency than the state-of-the-art method. The code and Colab demo are available in \href{this http URL}{this http UR
    
[^77]: Ask-AC: 一种循环中的主动顾问演员-评论家框架

    Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework. (arXiv:2207.01955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01955](http://arxiv.org/abs/2207.01955)

    本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。

    

    尽管交互式强化学习方案取得了很多有希望的结果，但目前的方案仍然依赖于来自顾问专家的被动监督信号，形式包括持续监控或预定义规则，这不可避免地导致了一种麻烦而昂贵的学习过程。在本文中，我们介绍了一种新的主动顾问演员-评论家框架，称为Ask-AC，它用一个双向的学习者主动机制替换了单向的顾问指导机制，从而实现了学习者和顾问之间的定制化和有效的信息交换。Ask-AC 的核心是两个互补的组件，分别是动作请求者和自适应状态选择器，可以方便地纳入各种离散的演员-评论家架构中。前者允许代理主动寻求不确定状态下的顾问干预，后者则可以识别漏掉的不稳定状态。

    Despite the promising results achieved, state-of-the-art interactive reinforcement learning schemes rely on passively receiving supervision signals from advisor experts, in the form of either continuous monitoring or pre-defined rules, which inevitably result in a cumbersome and expensive learning process. In this paper, we introduce a novel initiative advisor-in-the-loop actor-critic framework, termed as Ask-AC, that replaces the unilateral advisor-guidance mechanism with a bidirectional learner-initiative one, and thereby enables a customized and efficacious message exchange between learner and advisor. At the heart of Ask-AC are two complementary components, namely action requester and adaptive state selector, that can be readily incorporated into various discrete actor-critic architectures. The former component allows the agent to initiatively seek advisor intervention in the presence of uncertain states, while the latter identifies the unstable states potentially missed by the for
    

