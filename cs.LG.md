# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Amide Proton Transfer (APT) imaging in tumor with a machine learning approach using partially synthetic data.](http://arxiv.org/abs/2311.01683) | 本研究介绍了一种使用部分合成数据和机器学习方法的新平台，旨在训练模型预测酰胺质子转移（APT）效应。通过将模拟数据和实测数据结合起来生成部分合成的数据，实现了模拟的灵活性和准确性之间的平衡。 |
| [^2] | [Beyond U: Making Diffusion Models Faster & Lighter.](http://arxiv.org/abs/2310.20092) | 本文介绍了一种利用连续动力系统设计扩散模型的新型去噪网络，该网络具有更高的参数效率、快速收敛和更好的噪声稳健性。实验证明，与标准U-Net相比，我们的模型在参数和计算成本方面显著减少，并且在推理速度和质量解方面都取得了优于基准模型的结果。 |
| [^3] | [Personas as a Way to Model Truthfulness in Language Models.](http://arxiv.org/abs/2310.18168) | 本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。 |
| [^4] | [19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics.](http://arxiv.org/abs/2310.16121) | 只需19个参数的微型神经网络在顶夸克喷注的二分类任务上表现出优于数以万计参数的通用架构的性能。 |
| [^5] | [Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data.](http://arxiv.org/abs/2310.06372) | 该文提出了一种利用扩散模型的新方法，通过合成变化并结合知识蒸馏，使模型能够在可能被污染的数据集上进行鲁棒训练，解决后门攻击带来的安全威胁。 |
| [^6] | [Subspace Identification for Multi-Source Domain Adaptation.](http://arxiv.org/abs/2310.04723) | 该论文提出了一个基于子空间识别理论的多源域自适应方法，通过最小化域之间的偏移对不变变量的影响，实现了源域的知识转移到目标域。该方法相对于现有方法更加灵活，不需要满足严格的假设条件。 |
| [^7] | [Relaxed Octahedral Group Convolution for Learning Symmetry Breaking in 3D Physical Systems.](http://arxiv.org/abs/2310.02299) | 本文介绍了一种用于建模3D物理系统的松弛八面体群卷积技术，它可以在保持数据一致的最高等变性水平的同时，发现物理系统中微妙的对称性破缺因素。 |
| [^8] | [GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking.](http://arxiv.org/abs/2310.01794) | 本研究通过基准测试系统评估了基于扰动的GNN解释性方法，发现帕累托最优方法在噪声存在的情况下表现出卓越效力和稳定性。 |
| [^9] | [Transferring climate change knowledge.](http://arxiv.org/abs/2309.14780) | 通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。 |
| [^10] | [Recovering from Privacy-Preserving Masking with Large Language Models.](http://arxiv.org/abs/2309.08628) | 本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。 |
| [^11] | [Structure-Preserving Transformers for Sequences of SPD Matrices.](http://arxiv.org/abs/2309.07579) | 本文介绍了一种保持序列的对称正定矩阵的黎曼几何特性的结构保持变压器机制，并将其应用于自动睡眠分期，取得了高水平的阶段性能。 |
| [^12] | [Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning.](http://arxiv.org/abs/2309.06869) | 本研究提出使用强化学习来控制具有多边形单元颗粒的动态自组装过程，形成十二边准晶体。我们通过估计最佳的温度控制策略，成功地生成了几乎没有缺陷的结构。强化学习获得的温度调度比传统的预设温度调度更有效地重现了期望的结构。 |
| [^13] | [Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines.](http://arxiv.org/abs/2309.06157) | 本文提出了一种稳健的多支路深度学习模型，用于旋转机器的剩余寿命预测和运行状态识别。该模型包括LSTM-Autoencoder对振动数据进行去噪、特征提取和多支路深度学习网络结构等组件，并在实验中证明了它在轴承机器应用中的优越性和潜力。 |
| [^14] | [Practical Homomorphic Aggregation for Byzantine ML.](http://arxiv.org/abs/2309.05395) | 本文介绍了一种适用于拜占庭式机器学习的实用同态聚合方法，以应对拜占庭节点和服务器隐私侵犯的问题。 |
| [^15] | [Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms.](http://arxiv.org/abs/2308.06221) | 该论文提出了一种多步训练方法，用于设计深度自编码器，并通过修剪和增长方法以及优化隐藏层大小和训练时长来改善其性能。 |
| [^16] | [ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation.](http://arxiv.org/abs/2308.03793) | ReCLIP是一种用于改善视觉语言模型的无源领域自适应方法，通过学习投影空间和使用伪标签进行自训练，减少领域差异和嵌入不准确性。 |
| [^17] | [Diffusion Model in Causal Inference with Unmeasured Confounders.](http://arxiv.org/abs/2308.03669) | 本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。 |
| [^18] | [Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces.](http://arxiv.org/abs/2308.03443) | 本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。 |
| [^19] | [Guided Distillation for Semi-Supervised Instance Segmentation.](http://arxiv.org/abs/2308.02668) | 这项研究提出了一种半监督实例分割的引导蒸馏方法，通过引入新的“引导预烧”阶段和利用未标记数据的导师模型指导，取得了显著的改进。 |
| [^20] | [DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations.](http://arxiv.org/abs/2308.01890) | DualCoOp++是一种快速有效的方法，用于在有限注释情况下进行多标签识别。它通过利用强大的文本和视觉特征对齐，采用Evidence-guided Dual Context Optimization框架来解决部分标签和零样本多标签识别的问题。 |
| [^21] | [Explainable Equivariant Neural Networks for Particle Physics: PELICAN.](http://arxiv.org/abs/2307.16506) | PELICAN是一种可解释的等变神经网络，应用于粒子物理问题中。相比于其他方法，PELICAN的优势在于它采用了基于对称群的架构，具有降低复杂性、增加可解释性和提高性能的特点。它在标记和重构动量增强的顶夸克，并在密集环境中特别识别和测量W玻色子，以及识别不同类型的喷注等任务方面展示了出色的表现。 |
| [^22] | [Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques.](http://arxiv.org/abs/2307.12971) | 本文介绍了一种新的大数据-供应链管理框架，通过数据预处理和机器学习技术实现供应链预测，优化操作管理、透明度，并讨论了幻影库存对预测的不利影响。 |
| [^23] | [Neural Network Field Theories: Non-Gaussianity, Actions, and Locality.](http://arxiv.org/abs/2307.03223) | 本文研究了神经网络场理论，包括非高斯性、作用量和局域性。通过对网络参数的统计独立性进行微小破坏，可以得到相互作用理论，这种展开方法相比于常用的$1/N$展开在普适逼近定理方面表现更好，同时通过关联函数可以系统地重建作用量。 |
| [^24] | [AVSegFormer: Audio-Visual Segmentation with Transformer.](http://arxiv.org/abs/2307.01146) | AVSegFormer是一种基于Transformer的音视频分割框架，通过引入音频查询和可学习查询来选择性地关注视觉特征，还使用音频-视觉混合器动态调整视觉特征，并通过中间掩模损失增强解码器的监督。实验证明该方法的有效性。 |
| [^25] | [AutoST: Training-free Neural Architecture Search for Spiking Transformers.](http://arxiv.org/abs/2307.00293) | AutoST是一种无需训练的神经架构搜索方法，用于识别高性能和能效的脉冲变压器架构。 |
| [^26] | [Robot Learning with Sensorimotor Pre-training.](http://arxiv.org/abs/2306.10007) | 本论文介绍了一种针对机器人学习的自监督感觉运动预训练方法，使用 Transformer 模型在视觉表示上进行操作，通过 20,000 条真实世界轨迹数据集的预训练可以使机器人在堆积方块任务中性能提高 2 倍，并使其能够更快地学习新任务。 |
| [^27] | [GSHOT: Few-shot Generative Modeling of Labeled Graphs.](http://arxiv.org/abs/2306.03480) | GSHOT是一个用于少样本标记图生成建模的元学习框架，通过学习从类似的辅助图数据集中转移元知识，从而快速适应未见过的图数据集。 |
| [^28] | [Lagrangian Flow Networks for Conservation Laws.](http://arxiv.org/abs/2305.16846) | 该论文提出了LFlows模型，它使用可微和可逆的变换，在时间上规定参数化的微分同胚变换来对基础密度进行转换，以连续地建模流体密度和速度。与传统方法相比，其优势在于速度的解析表达式总是与密度保持一致，无需昂贵的数值求解器，也无需使用惩罚方法。 |
| [^29] | [String Diagrams with Factorized Densities.](http://arxiv.org/abs/2305.02506) | 本文描述了一个定义在随机变量集上的联合密度的范畴及其意义，以帮助概率编程和因果推断中的组合推理。 |
| [^30] | [Predicting the Initial Conditions of the Universe using Deep Learning.](http://arxiv.org/abs/2303.13056) | 本文首次证明了使用深度学习模型可以反向预测宇宙初始线性位移，该方法能够在减少计算量的同时准确恢复初始线性位移。 |
| [^31] | [Inference on Optimal Dynamic Policies via Softmax Approximation.](http://arxiv.org/abs/2303.04416) | 本文提出了一种简单的softmax逼近方法，可用于从离线数据中估计最优的动态治疗方案并对其进行有效推断。 |
| [^32] | [Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering.](http://arxiv.org/abs/2303.01903) | 本研究提出了一个名为Prophet的框架，使用答案启发式方式促使GPT-3解决基于知识的视觉问答问题。在特定的知识型VQA数据集上训练一个纯VQA模型，并从中提取出答案启发式，可提高模型的性能。 |
| [^33] | [DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction.](http://arxiv.org/abs/2303.01141) | 本文提出了一种学习神经网络的方法，该神经网络可以强制执行多样化的约束并且保证所有可能的预测都满足约束限制。 |
| [^34] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^35] | [QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based Generative Models.](http://arxiv.org/abs/2302.00919) | 该论文提出了一种名为QCS-SGM+的算法，利用基于得分的生成模型(SGM)作为隐式先验进行量化压缩感知(QCS)，并可以有效地处理一般矩阵。这个算法解决了在粗糙量化的情况下恢复挑战的问题。 |
| [^36] | [Distributed Stochastic Optimization under a General Variance Condition.](http://arxiv.org/abs/2301.12677) | 这项研究通过重新审视联邦平均算法，在最小假设下对分布式非凸目标进行了随机优化，建立了仅满足随机梯度温和条件的收敛结果。 |
| [^37] | [Simplifying Subgraph Representation Learning for Scalable Link Prediction.](http://arxiv.org/abs/2301.12562) | 提出了一种新的可扩展简化子图表示学习（S3GRL）框架，通过简化每个链接子图中的消息传递和聚合操作实现更快的训练和推理，并可适应各种子图采样策略和扩散操作符以模拟计算代价高的子图表示学习。大量实验证明了S3GRL模型可以扩展SGRL而不会显著降低性能。 |
| [^38] | [An Isolation-Aware Online Virtual Network Embedding via Deep Reinforcement Learning.](http://arxiv.org/abs/2211.14158) | 本文提出了一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法，以解决虚拟网络环境中多个VN共存可能导致隔离问题的挑战。 |

# 详细

[^1]: 使用部分合成数据及机器学习方法的肿瘤酰胺质子转移（APT）成像研究

    Amide Proton Transfer (APT) imaging in tumor with a machine learning approach using partially synthetic data. (arXiv:2311.01683v1 [physics.med-ph])

    [http://arxiv.org/abs/2311.01683](http://arxiv.org/abs/2311.01683)

    本研究介绍了一种使用部分合成数据和机器学习方法的新平台，旨在训练模型预测酰胺质子转移（APT）效应。通过将模拟数据和实测数据结合起来生成部分合成的数据，实现了模拟的灵活性和准确性之间的平衡。

    

    机器学习（ML）被越来越多地用于量化化学交换饱和转移（CEST）效应。ML模型通常使用实测数据或完全模拟数据进行训练。然而，使用实测数据进行训练往往缺乏足够的训练数据，而使用完全模拟数据进行训练可能由于有限的模拟资源而引入偏差。本研究引入了一个新平台，将模拟数据和实测数据结合起来生成部分合成的CEST数据，并评估其用于训练ML模型预测酰胺质子转移（APT）效应的可行性。部分合成的CEST信号使用从模拟中的APT效应的逆求和和来自实测数据的其他成分创建。通过改变APT模拟参数并应用缩放因子来调整实测数据的成分，生成了训练数据，实现了模拟的灵活性和准确性之间的平衡。

    Machine learning (ML) has been increasingly used to quantify chemical exchange saturation transfer (CEST) effect. ML models are typically trained using either measured data or fully simulated data. However, training with measured data often lacks sufficient training data, while training with fully simulated data may introduce bias due to limited simulations pools. This study introduces a new platform that combines simulated and measured components to generate partially synthetic CEST data, and to evaluate its feasibility for training ML models to predict amide proton transfer (APT) effect. Partially synthetic CEST signals were created using an inverse summation of APT effects from simulations and the other components from measurements. Training data were generated by varying APT simulation parameters and applying scaling factors to adjust the measured components, achieving a balance between simulation flexibility and fidelity. First, tissue-mimicking CEST signals along with ground trut
    
[^2]: 超越U：使扩散模型更快更轻

    Beyond U: Making Diffusion Models Faster & Lighter. (arXiv:2310.20092v1 [cs.LG])

    [http://arxiv.org/abs/2310.20092](http://arxiv.org/abs/2310.20092)

    本文介绍了一种利用连续动力系统设计扩散模型的新型去噪网络，该网络具有更高的参数效率、快速收敛和更好的噪声稳健性。实验证明，与标准U-Net相比，我们的模型在参数和计算成本方面显著减少，并且在推理速度和质量解方面都取得了优于基准模型的结果。

    

    扩散模型是一类生成模型，在图像合成、视频生成和分子设计等任务中取得了创纪录的性能。尽管具备这些能力，但其效率，特别是在逆向去噪过程中，仍然面临着慢收敛速度和高计算成本的挑战。在这项工作中，我们引入了一种利用连续动力系统来设计扩散模型的新型去噪网络的方法，该方法更具参数效率，收敛速度更快，并且具有更高的噪声稳健性。通过对去噪概率扩散模型进行实验，我们的框架使用的参数约为标准去噪概率扩散模型（DDPM）中标准U-Net的四分之一，浮点运算（FLOPs）约为标准U-Net的30%。此外，在相等条件下测量时，我们的模型的推理速度比基准模型快70％，同时收敛到更好的质量解。

    Diffusion models are a family of generative models that yield record-breaking performance in tasks such as image synthesis, video generation, and molecule design. Despite their capabilities, their efficiency, especially in the reverse denoising process, remains a challenge due to slow convergence rates and high computational costs. In this work, we introduce an approach that leverages continuous dynamical systems to design a novel denoising network for diffusion models that is more parameter-efficient, exhibits faster convergence, and demonstrates increased noise robustness. Experimenting with denoising probabilistic diffusion models, our framework operates with approximately a quarter of the parameters and 30% of the Floating Point Operations (FLOPs) compared to standard U-Nets in Denoising Diffusion Probabilistic Models (DDPMs). Furthermore, our model is up to 70% faster in inference than the baseline models when measured in equal conditions while converging to better quality solutio
    
[^3]: 使用人设来建模语言模型中的真实性

    Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v1 [cs.CL])

    [http://arxiv.org/abs/2310.18168](http://arxiv.org/abs/2310.18168)

    本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。

    

    大型语言模型使用互联网上的大量文本进行训练，这些文本中既包含了事实，也包含了误导性的信息。语言模型能够从这些相互矛盾的数据中辨别真实与虚假吗？基于语言模型能够建模不同产生文本的个体这一观点，我们假设它们可以通过建模真实人设来聚类真实文本：一群很可能产生真实文本并具有相似特征的个体。例如，可信源如维基百科和科学期刊通常使用正式的写作风格并提出一致的主张。通过建模这一人设，语言模型可以将真实性推广到每个个体生成训练文本的特定上下文之外。例如，模型可以推断出“维基百科”这个个体在“科学”生成的主题上会表现出真实性，因为它们共享一个人设。我们首先通过两个观察结果为人设假设提供了证据：（1）我们可以探测模型在不同领域中判断真实性的能力；（2）模型可以从相关特征中推测个体产生文本的真实性。

    Large Language Models are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. Can language models discern truth from falsehood in this contradicting data? Expanding on the view that LLMs can model different agents producing the corpora, we hypothesize that they can cluster truthful text by modeling a truthful persona: a group of agents that are likely to produce truthful text and share similar features. For example, trustworthy sources like Wikipedia and Science usually use formal writing styles and make consistent claims. By modeling this persona, LLMs can generalize truthfulness beyond the specific contexts in which each agent generated the training text. For example, the model can infer that the agent "Wikipedia" will behave truthfully on topics that were only generated by "Science" because they share a persona. We first show evidence for the persona hypothesis via two observations: (1) we can probe whether a mod
    
[^4]: 只需19个参数：用于粒子物理学的微型神经网络

    19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics. (arXiv:2310.16121v1 [hep-ph])

    [http://arxiv.org/abs/2310.16121](http://arxiv.org/abs/2310.16121)

    只需19个参数的微型神经网络在顶夸克喷注的二分类任务上表现出优于数以万计参数的通用架构的性能。

    

    随着粒子加速器增加碰撞速率和深度学习解决方案的可行性得到证实，对于低延迟任务（如触发器），需要轻量且快速的神经网络架构。我们研究了最近的洛伦兹和置换对称架构PELICAN的潜力，并展示了该架构的几个实例，其中可训练参数仅为19个，在顶夸克喷注的二分类任务上，性能超过了数以万计参数的通用架构。

    As particle accelerators increase their collision rates, and deep learning solutions prove their viability, there is a growing need for lightweight and fast neural network architectures for low-latency tasks such as triggering. We examine the potential of one recent Lorentz- and permutation-symmetric architecture, PELICAN, and present its instances with as few as 19 trainable parameters that outperform generic architectures with tens of thousands of parameters when compared on the binary classification task of top quark jet tagging.
    
[^5]: 利用基于扩散的图像变化为鲁棒训练提供支持

    Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data. (arXiv:2310.06372v1 [cs.CR])

    [http://arxiv.org/abs/2310.06372](http://arxiv.org/abs/2310.06372)

    该文提出了一种利用扩散模型的新方法，通过合成变化并结合知识蒸馏，使模型能够在可能被污染的数据集上进行鲁棒训练，解决后门攻击带来的安全威胁。

    

    后门攻击对训练神经网络构成严重安全威胁，它们在模型中秘密引入隐藏功能。这些后门在对干净输入进行推理时保持沉默，由于隐蔽的行为而避免被检测。然而，一旦输入数据中出现特定的触发模式，后门就会激活，导致模型执行其隐藏的功能。通过手动检查，在庞大的数据集中检测到这种被污染的样本几乎是不可能的。为了解决这个挑战，我们提出了一种新颖的方法，通过利用最近的扩散模型的强大功能，实现对可能被污染的数据集进行模型训练。具体而言，我们通过在所有训练样本上创建合成变化，利用扩散模型对数据中的潜在触发模式具有固有的弹性。通过将这种生成方法与知识蒸馏相结合，我们生成了保持任务上的总体性能的学生模型。

    Backdoor attacks pose a serious security threat for training neural networks as they surreptitiously introduce hidden functionalities into a model. Such backdoors remain silent during inference on clean inputs, evading detection due to inconspicuous behavior. However, once a specific trigger pattern appears in the input data, the backdoor activates, causing the model to execute its concealed function. Detecting such poisoned samples within vast datasets is virtually impossible through manual inspection. To address this challenge, we propose a novel approach that enables model training on potentially poisoned datasets by utilizing the power of recent diffusion models. Specifically, we create synthetic variations of all training samples, leveraging the inherent resilience of diffusion models to potential trigger patterns in the data. By combining this generative approach with knowledge distillation, we produce student models that maintain their general performance on the task while exhib
    
[^6]: 多源域自适应的子空间识别

    Subspace Identification for Multi-Source Domain Adaptation. (arXiv:2310.04723v1 [cs.LG])

    [http://arxiv.org/abs/2310.04723](http://arxiv.org/abs/2310.04723)

    该论文提出了一个基于子空间识别理论的多源域自适应方法，通过最小化域之间的偏移对不变变量的影响，实现了源域的知识转移到目标域。该方法相对于现有方法更加灵活，不需要满足严格的假设条件。

    

    多源域自适应（MSDA）方法旨在将多个有标签的源域的知识转移到一个无标签的目标域中。尽管当前的方法通过在域之间施加最小的变化来实现目标联合分布的可辨识性，但它们通常需要严格的条件，如足够数量的域、潜在变量的单调变换和不变的标签分布。这些要求在实际应用中很难满足。为了减轻对这些严格假设的需求，我们提出了一个子空间识别理论，它在关于域数量和变换特性方面具有较宽松的约束条件，从而通过最小化域之间的偏移对不变变量的影响来促进域自适应。基于这个理论，我们开发了一个利用变分推断的子空间识别保证（SIG）模型。

    Multi-source domain adaptation (MSDA) methods aim to transfer knowledge from multiple labeled source domains to an unlabeled target domain. Although current methods achieve target joint distribution identifiability by enforcing minimal changes across domains, they often necessitate stringent conditions, such as an adequate number of domains, monotonic transformation of latent variables, and invariant label distributions. These requirements are challenging to satisfy in real-world applications. To mitigate the need for these strict assumptions, we propose a subspace identification theory that guarantees the disentanglement of domain-invariant and domain-specific variables under less restrictive constraints regarding domain numbers and transformation properties, thereby facilitating domain adaptation by minimizing the impact of domain shifts on invariant variables. Based on this theory, we develop a Subspace Identification Guarantee (SIG) model that leverages variational inference. Furth
    
[^7]: 3D物理系统中学习对称性破缺的松弛八面体群卷积

    Relaxed Octahedral Group Convolution for Learning Symmetry Breaking in 3D Physical Systems. (arXiv:2310.02299v1 [cs.LG])

    [http://arxiv.org/abs/2310.02299](http://arxiv.org/abs/2310.02299)

    本文介绍了一种用于建模3D物理系统的松弛八面体群卷积技术，它可以在保持数据一致的最高等变性水平的同时，发现物理系统中微妙的对称性破缺因素。

    

    深度等价模型利用对称性提高样本效率和泛化性能。然而，在许多这些模型中，完美对称性的假设有时可能会限制性能，特别是当数据与这些对称性不完全一致时。因此，我们在本文中引入了用于建模3D物理系统的松弛八面体群卷积。这种灵活的卷积技术能够在保持与数据一致的最高等变性水平的同时，发现物理系统中微妙的对称性破缺因素。实证结果验证了我们的方法不仅可以揭示相变中的对称性破缺因素，还可以在流体超分辨率任务中实现卓越性能。

    Deep equivariant models use symmetries to improve sample efficiency and generalization. However, the assumption of perfect symmetry in many of these models can sometimes be restrictive, especially when the data does not perfectly align with such symmetries. Thus, we introduce relaxed octahedral group convolution for modeling 3D physical systems in this paper. This flexible convolution technique provably allows the model to both maintain the highest level of equivariance that is consistent with data and discover the subtle symmetry-breaking factors in the physical systems. Empirical results validate that our approach can not only provide insights into the symmetry-breaking factors in phase transitions but also achieves superior performance in fluid super-resolution tasks.
    
[^8]: GNNX-BENCH: 通过深度基准测试揭示基于扰动的GNN解释器的实用性

    GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking. (arXiv:2310.01794v1 [cs.LG])

    [http://arxiv.org/abs/2310.01794](http://arxiv.org/abs/2310.01794)

    本研究通过基准测试系统评估了基于扰动的GNN解释性方法，发现帕累托最优方法在噪声存在的情况下表现出卓越效力和稳定性。

    

    已经提出了许多解释性方法来揭示GNN的内部工作方式。尽管所有提出的算法都包含了实证评估，但这些评估的询问方面缺乏多样性。因此，关于GNN解释性的各个方面，如对事实求证推理器的比较分析、它们对不同GNN架构、噪声、非凸损失表面中的随机性、在领域约束条件下的可行性等等，尚未得到正式的研究。受此需求的激发，我们在基于扰动的GNN解释性方法上进行了基准测试研究，旨在系统评估和比较各种解释性技术。在我们的研究的关键发现中，我们确定了在噪声存在的情况下表现出卓越效力和稳定性的帕累托最优方法。然而，我们的研究揭示了所有算法都受到稳定性的影响。

    Numerous explainability methods have been proposed to shed light on the inner workings of GNNs. Despite the inclusion of empirical evaluations in all the proposed algorithms, the interrogative aspects of these evaluations lack diversity. As a result, various facets of explainability pertaining to GNNs, such as a comparative analysis of counterfactual reasoners, their stability to variational factors such as different GNN architectures, noise, stochasticity in non-convex loss surfaces, feasibility amidst domain constraints, and so forth, have yet to be formally investigated. Motivated by this need, we present a benchmarking study on perturbation-based explainability methods for GNNs, aiming to systematically evaluate and compare a wide range of explainability techniques. Among the key findings of our study, we identify the Pareto-optimal methods that exhibit superior efficacy and stability in the presence of noise. Nonetheless, our study reveals that all algorithms are affected by stabi
    
[^9]: 转移气候变化知识

    Transferring climate change knowledge. (arXiv:2309.14780v1 [physics.ao-ph])

    [http://arxiv.org/abs/2309.14780](http://arxiv.org/abs/2309.14780)

    通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。

    

    准确的气候预测对于气候适应和减缓至关重要。用于预测气候变化的地球系统模型模拟在对小尺度物理过程（例如云）的表示中本质上进行了近似，这是全球平均温度对增加的温室气体浓度的响应中不确定性的根源。已经开发了多种方法，用于使用历史观测约束未来预测，并减少气候预测和气候反馈的不确定性。然而，这些方法无法捕捉气候系统固有的非线性复杂性。通过使用转移学习方法，我们展示了机器学习，特别是深度神经网络，可以用于最大程度地利用和整合从地球系统模型模拟和历史观测中获得的知识，以更准确地预测21世纪全球表面温度场。

    Accurate climate projections are required for climate adaptation and mitigation. Earth system model simulations, used to project climate change, inherently make approximations in their representation of small-scale physical processes, such as clouds, that are at the root of the uncertainties in global mean temperature's response to increased greenhouse gas concentrations. Several approaches have been developed to use historical observations to constrain future projections and reduce uncertainties in climate projections and climate feedbacks. Yet those methods cannot capture the non-linear complexity inherent in the climate system. Using a Transfer Learning approach, we show that Machine Learning, in particular Deep Neural Networks, can be used to optimally leverage and merge the knowledge gained from Earth system model simulations and historical observations to more accurately project global surface temperature fields in the 21st century. For the Shared Socioeconomic Pathways (SSPs) 2-
    
[^10]: 通过大型语言模型进行隐私保护掩码的恢复

    Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v1 [cs.CL])

    [http://arxiv.org/abs/2309.08628](http://arxiv.org/abs/2309.08628)

    本文利用大型语言模型（LLM）探索了替换标识信息的方法，并在下游语言建模任务上进行了评估。实验结果表明，使用混淆语料库训练的模型能够达到可比较的性能。

    

    模型适应对于处理代理训练数据和实际用户数据之间的差异非常重要。为了有效地进行适应，用户的文本数据通常存储在服务器或本地设备上，下游的自然语言处理模型可以使用这些领域内的数据进行直接训练。然而，这可能会引起隐私和安全问题，因为存在向对手泄露用户信息的额外风险。最近，人们开始探索使用通用标记替换文本中的标识信息。在这项工作中，我们利用大型语言模型（LLM）来建议替换掩码标记的方法，并在下游语言建模任务上评估其效果。具体而言，我们提出了多种基于预训练和微调的LLM方法，并在不同数据集上进行实证研究以比较这些方法。实验结果表明，在混淆语料库上训练的模型能够达到可比较的性能。

    Model adaptation is crucial to handle the discrepancy between proxy training data and actual users data received. To effectively perform adaptation, textual data of users is typically stored on servers or their local devices, where downstream natural language processing (NLP) models can be directly trained using such in-domain data. However, this might raise privacy and security concerns due to the extra risks of exposing user information to adversaries. Replacing identifying information in textual data with a generic marker has been recently explored. In this work, we leverage large language models (LLMs) to suggest substitutes of masked tokens and have their effectiveness evaluated on downstream language modeling tasks. Specifically, we propose multiple pre-trained and fine-tuned LLM-based approaches and perform empirical studies on various datasets for the comparison of these methods. Experimental results show that models trained on the obfuscation corpora are able to achieve compar
    
[^11]: 保持结构的变压器用于序列的SPD矩阵

    Structure-Preserving Transformers for Sequences of SPD Matrices. (arXiv:2309.07579v1 [cs.LG])

    [http://arxiv.org/abs/2309.07579](http://arxiv.org/abs/2309.07579)

    本文介绍了一种保持序列的对称正定矩阵的黎曼几何特性的结构保持变压器机制，并将其应用于自动睡眠分期，取得了高水平的阶段性能。

    

    近年来，基于变压器的自注意力机制已成功应用于各种上下文相关的数据类型的分析，从文本到图像等，包括非欧几里得几何的数据。本文提出了一种这样的机制，用于分类序列的对称正定矩阵，并在整个分析过程中保持它们的黎曼几何特性。我们将我们的方法应用于来自标准数据集中的脑电图协方差矩阵序列的自动睡眠分期，取得了高水平的阶段性能。

    In recent years, Transformer-based auto-attention mechanisms have been successfully applied to the analysis of a variety of context-reliant data types, from texts to images and beyond, including data from non-Euclidean geometries. In this paper, we present such a mechanism, designed to classify sequences of Symmetric Positive Definite matrices while preserving their Riemannian geometry throughout the analysis. We apply our method to automatic sleep staging on timeseries of EEG-derived covariance matrices from a standard dataset, obtaining high levels of stage-wise performance.
    
[^12]: 通过强化学习动态控制拟晶结构的自组装

    Dynamic control of self-assembly of quasicrystalline structures through reinforcement learning. (arXiv:2309.06869v1 [cond-mat.soft])

    [http://arxiv.org/abs/2309.06869](http://arxiv.org/abs/2309.06869)

    本研究提出使用强化学习来控制具有多边形单元颗粒的动态自组装过程，形成十二边准晶体。我们通过估计最佳的温度控制策略，成功地生成了几乎没有缺陷的结构。强化学习获得的温度调度比传统的预设温度调度更有效地重现了期望的结构。

    

    我们提出使用强化学习来控制具有多边形单元的颗粒的动态自组装过程，形成十二边准晶体（DDQC）。这些具有多边形单元的颗粒与其他颗粒具有各向异性相互作用，从而形成DDQC。然而，它们在稳态下的结构受其结构形成的动力学路径的显著影响。我们通过Q学习方法估计了最佳的温度控制策略，并证明我们可以使用估计的策略生成几乎没有缺陷的DDQC。通过强化学习获得的温度调度比传统的预设温度调度（如退火）更有效地重现了期望的结构。为了阐明学习的成功，我们还分析了一个描述结构变化动力学的简单模型，其中的运动是在三井势能中进行的。我们发现强化学习能够自主地发现增强结构波动的临界温度。

    We propose reinforcement learning to control the dynamical self-assembly of the dodecagonal quasicrystal (DDQC) from patchy particles. The patchy particles have anisotropic interactions with other particles and form DDQC. However, their structures at steady states are significantly influenced by the kinetic pathways of their structural formation. We estimate the best policy of temperature control trained by the Q-learning method and demonstrate that we can generate DDQC with few defects using the estimated policy. The temperature schedule obtained by reinforcement learning can reproduce the desired structure more efficiently than the conventional pre-fixed temperature schedule, such as annealing. To clarify the success of the learning, we also analyse a simple model describing the kinetics of structural changes through the motion in a triple-well potential. We have found that reinforcement learning autonomously discovers the critical temperature at which structural fluctuations enhance
    
[^13]: Robust-MBDL:一种用于旋转机器剩余寿命预测和运行状态鉴别的稳健的多支路深度学习模型

    Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines. (arXiv:2309.06157v1 [cs.LG])

    [http://arxiv.org/abs/2309.06157](http://arxiv.org/abs/2309.06157)

    本文提出了一种稳健的多支路深度学习模型，用于旋转机器的剩余寿命预测和运行状态识别。该模型包括LSTM-Autoencoder对振动数据进行去噪、特征提取和多支路深度学习网络结构等组件，并在实验中证明了它在轴承机器应用中的优越性和潜力。

    

    本文提出了一种用于旋转机器剩余寿命(RUL)预测和运行状态(CO)鉴别的稳健的多支路深度学习系统。具体而言，该系统包括主要组件：(1)采用LSTM-Autoencoder对振动数据进行去噪；(2)使用特征提取从去噪数据中生成时域、频域和时频域特征；(3)采用新颖而稳健的多支路深度学习网络结构来利用多个特征。我们的系统在XJTU-SY和PRONOSTIA两个基准数据集上与现有技术水平进行了评估和比较。实验结果证明我们的系统表现优于现有技术水平，并具有在轴承机器实际应用中的潜力。

    In this paper, a Robust Multi-branch Deep learning-based system for remaining useful life (RUL) prediction and condition operations (CO) identification of rotating machines is proposed. In particular, the proposed system comprises main components: (1) an LSTM-Autoencoder to denoise the vibration data; (2) a feature extraction to generate time-domain, frequency-domain, and time-frequency based features from the denoised data; (3) a novel and robust multi-branch deep learning network architecture to exploit the multiple features. The performance of our proposed system was evaluated and compared to the state-of-the-art systems on two benchmark datasets of XJTU-SY and PRONOSTIA. The experimental results prove that our proposed system outperforms the state-of-the-art systems and presents potential for real-life applications on bearing machines.
    
[^14]: 适用于拜占庭式机器学习的实用同态聚合

    Practical Homomorphic Aggregation for Byzantine ML. (arXiv:2309.05395v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.05395](http://arxiv.org/abs/2309.05395)

    本文介绍了一种适用于拜占庭式机器学习的实用同态聚合方法，以应对拜占庭节点和服务器隐私侵犯的问题。

    

    由于数据的大规模可用性，机器学习算法正在分布式拓扑中部署，不同的节点通过与中央服务器交换与模型相关的信息（例如梯度）来共同训练其个体数据上的机器学习模型。然而，分布式学习方案容易受到两种威胁。首先，拜占庭式节点可以通过向服务器发送不正确的信息（例如错误的梯度）单独破坏学习过程。缓解此类行为的标准方法是在服务器上使用非线性鲁棒聚合方法。其次，服务器可以侵犯节点的隐私。最近的攻击已经表明，交换（未加密的）梯度使得一个好奇的服务器能够恢复出所有节点的数据。同态加密（HE），一种金标准安全原语，已经广泛研究作为非拜占庭场景中分布式学习的隐私保护解决方案。

    Due to the large-scale availability of data, machine learning (ML) algorithms are being deployed in distributed topologies, where different nodes collaborate to train ML models over their individual data by exchanging model-related information (e.g., gradients) with a central server. However, distributed learning schemes are notably vulnerable to two threats. First, Byzantine nodes can single-handedly corrupt the learning by sending incorrect information to the server, e.g., erroneous gradients. The standard approach to mitigate such behavior is to use a non-linear robust aggregation method at the server. Second, the server can violate the privacy of the nodes. Recent attacks have shown that exchanging (unencrypted) gradients enables a curious server to recover the totality of the nodes' data. The use of homomorphic encryption (HE), a gold standard security primitive, has extensively been studied as a privacy-preserving solution to distributed learning in non-Byzantine scenarios. Howev
    
[^15]: 使用二阶算法自动调整和训练高效的深度自编码器

    Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms. (arXiv:2308.06221v1 [cs.LG])

    [http://arxiv.org/abs/2308.06221](http://arxiv.org/abs/2308.06221)

    该论文提出了一种多步训练方法，用于设计深度自编码器，并通过修剪和增长方法以及优化隐藏层大小和训练时长来改善其性能。

    

    我们提出了一种多步训练方法，用于设计广义线性分类器。首先，通过回归找到一个初始的多类线性分类器。然后通过修剪不必要的输入来最小化验证误差。同时，通过类似于Ho-Kashyap规则的方法改善期望输出。接下来，将输出判别式缩放为广义线性分类器中S型输出单元的网络函数。然后，我们开发了一族批量训练算法，用于优化多层感知机的隐藏层大小和训练时长。接着，我们将修剪与增长方法相结合。然后，将输入单元缩放为S型输出单元的网络函数，然后将其作为输入馈送到MLP中。最后，我们提出了深度学习模块中的改进，从而提高了深度架构的整体性能。我们讨论了关于d的学习算法的原则和公式。

    We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for d
    
[^16]: ReCLIP: 使用无源领域自适应优化对比性语言图像预训练

    ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation. (arXiv:2308.03793v1 [cs.CV])

    [http://arxiv.org/abs/2308.03793](http://arxiv.org/abs/2308.03793)

    ReCLIP是一种用于改善视觉语言模型的无源领域自适应方法，通过学习投影空间和使用伪标签进行自训练，减少领域差异和嵌入不准确性。

    

    大规模预训练的视觉语言模型（例如CLIP）在零样本分类方面表现出色，例如在没有看到任何示例的情况下，在ImageNet上实现了76.3％的top-1准确率，这为许多没有标注数据的任务带来了潜在的好处。然而，将CLIP应用于下游目标领域时，视觉和文本领域差异以及交叉模态对齐不准确可能会对模型性能产生很大影响。为了解决这些挑战，我们提出了ReCLIP，这是一种针对视觉语言模型的无源领域自适应方法，不需要任何源数据或目标标注数据。ReCLIP首先学习一个投影空间来减轻不对齐的视觉-文本嵌入，并学习伪标签，然后使用伪标签部署交叉模态自训练，以迭代地更新视觉和文本编码器，优化标签，并减少领域差距和嵌入不准确性。通过大量实验证明，ReCLIP能够减少平均...

    Large-scale Pre-Training Vision-Language Model such as CLIP has demonstrated outstanding performance in zero-shot classification, e.g. achieving 76.3% top-1 accuracy on ImageNet without seeing any example, which leads to potential benefits to many tasks that have no labeled data. However, while applying CLIP to a downstream target domain, the presence of visual and text domain gaps and cross-modality misalignment can greatly impact the model performance. To address such challenges, we propose ReCLIP, the first source-free domain adaptation method for vision-language models, which does not require any source data or target labeled data. ReCLIP first learns a projection space to mitigate the misaligned visual-text embeddings and learns pseudo labels, and then deploys cross-modality self-training with the pseudo labels, to update visual and text encoders, refine labels and reduce domain gaps and misalignments iteratively. With extensive experiments, we demonstrate ReCLIP reduces the avera
    
[^17]: 无法测量混淆因素下因果推断中的扩散模型

    Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])

    [http://arxiv.org/abs/2308.03669](http://arxiv.org/abs/2308.03669)

    本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。

    

    我们研究了如何在无法测量的混淆因素存在的情况下，扩展扩散模型的使用，以从观测数据中回答因果问题。在Pearl的使用有向无环图（DAG）捕捉因果干预的框架中，提出了一种基于扩散模型的因果模型（DCM），可以更准确地回答因果问题，假设所有混淆因素都是可以观察到的。然而，实际中存在无法测量的混淆因素，这使得DCM无法应用。为了缓解DCM的这一局限性，我们提出了一个扩展模型，称为基于反门准则的DCM（BDCM），其思想根植于在DAG中找到要包括在扩散模型解码过程中的变量的反门准则，这样我们可以将DCM扩展到存在无法测量的混淆因素的情况。合成数据实验表明，我们提出的模型在无法测量混淆因素的情况下更精确地捕捉到了反事实分布。

    We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
    
[^18]: 用于具有大动作空间的离策略评估的双重稳健估计器

    Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])

    [http://arxiv.org/abs/2308.03443](http://arxiv.org/abs/2308.03443)

    本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。

    

    本文研究了在具有大动作空间的背景下的离策略评估（OPE）。现有的基准估计器存在严重的偏差和方差折衷问题。参数化方法由于很难确定正确的模型而导致偏差，而重要性加权方法由于方差而产生问题。为了克服这些限制，本文提出了基于判别式的不良行为抑制器（MIPS）来通过对动作的嵌入来减小估计器的方差。为了使估计器更准确，我们提出了MIPS的双重稳健估计器——边际化双重稳健（MDR）估计器。理论分析表明，所提出的估计器在比MIPS更弱的假设下是无偏的，同时保持了对IPS的方差减小，这是MIPS的主要优势。经验实验证实了MDR相对于现有估计器的优越性。

    We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
    
[^19]: 半监督实例分割的引导蒸馏

    Guided Distillation for Semi-Supervised Instance Segmentation. (arXiv:2308.02668v1 [cs.CV])

    [http://arxiv.org/abs/2308.02668](http://arxiv.org/abs/2308.02668)

    这项研究提出了一种半监督实例分割的引导蒸馏方法，通过引入新的“引导预烧”阶段和利用未标记数据的导师模型指导，取得了显著的改进。

    

    虽然实例分割方法有了显著的改进，但主导范式是依赖于完全带注释的训练图像，这需要费时费力。为了减轻这种依赖并提高结果，半监督方法利用未标记数据作为额外的训练信号，以限制对标记样本的过拟合。在这个背景下，我们提出了一些新颖的设计选择来显著改进师生蒸馏模型。特别是，我们(i)通过引入新的“引导预烧”阶段改进了蒸馏方法，(ii)评估了不同的实例分割架构、主干网络和预训练策略。与之前只使用监督数据来对学生模型进行预烧的工作相反，我们还利用导师模型的指导在预烧阶段中利用未标记数据。我们改进的蒸馏方法在之前最先进的结果上取得了显著的改进。

    Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on 
    
[^20]: DualCoOp++: 针对有限注释的多标签识别进行快速有效的适应

    DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations. (arXiv:2308.01890v1 [cs.CV])

    [http://arxiv.org/abs/2308.01890](http://arxiv.org/abs/2308.01890)

    DualCoOp++是一种快速有效的方法，用于在有限注释情况下进行多标签识别。它通过利用强大的文本和视觉特征对齐，采用Evidence-guided Dual Context Optimization框架来解决部分标签和零样本多标签识别的问题。

    

    在低标签情况下进行多标签图像识别是一个极具挑战和实际意义的任务。之前的研究主要关注学习文本和视觉空间之间的对齐，以弥补图像标签有限所带来的准确性降低的问题。然而，由于高质量的多标签注释稀缺，这种方法可能会导致准确性下降。在这项研究中，我们利用了用数百万个辅助图像-文本对预训练的文本和视觉特征之间的强大对齐。我们提出了一种高效且有效的框架，称为Evidence-guided Dual Context Optimization (DualCoOp++)，它作为一种统一的方法来解决部分标签和零样本多标签识别的问题。在DualCoOp++中，我们单独对目标类别的证据、正面和负面上下文进行编码，作为语言输入（即提示）的参数组件。证据上下文旨在发现与目标类别相关的所有视觉内容，并作为聚合正面和负面上下文的指导。

    Multi-label image recognition in the low-label regime is a task of great challenge and practical significance. Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations. In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs. We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition. In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts). The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive 
    
[^21]: 可解释的等变神经网络在粒子物理中的应用：PELICAN

    Explainable Equivariant Neural Networks for Particle Physics: PELICAN. (arXiv:2307.16506v2 [hep-ph] UPDATED)

    [http://arxiv.org/abs/2307.16506](http://arxiv.org/abs/2307.16506)

    PELICAN是一种可解释的等变神经网络，应用于粒子物理问题中。相比于其他方法，PELICAN的优势在于它采用了基于对称群的架构，具有降低复杂性、增加可解释性和提高性能的特点。它在标记和重构动量增强的顶夸克，并在密集环境中特别识别和测量W玻色子，以及识别不同类型的喷注等任务方面展示了出色的表现。

    

    PELICAN是一种新颖的置换等变且洛伦兹不变或协变的聚合网络，旨在克服应用于粒子物理问题的常见限制。与许多使用非专用架构的方法相比，PELICAN采用基于对称群的架构，体现了复杂度降低、可解释性增强和性能提升等优势，而非以庞大的参数为代价。我们在标记（分类）和重构（回归）动量增强的顶夸克的背景下对PELICAN算法架构进行全面研究，包括在洛伦兹增强的顶夸克强子末态的密集环境中特别识别和测量W玻色子的困难任务。我们还将PELICAN应用于识别夸克-引发与胶子-引发喷注以及多类别分类任务。

    PELICAN is a novel permutation equivariant and Lorentz invariant or covariant aggregator network designed to overcome common limitations found in architectures applied to particle physics problems. Compared to many approaches that use non-specialized architectures that neglect underlying physics principles and require very large numbers of parameters, PELICAN employs a fundamentally symmetry group-based architecture that demonstrates benefits in terms of reduced complexity, increased interpretability, and raw performance. We present a comprehensive study of the PELICAN algorithm architecture in the context of both tagging (classification) and reconstructing (regression) Lorentz-boosted top quarks, including the difficult task of specifically identifying and measuring the $W$-boson inside the dense environment of the Lorentz-boosted top-quark hadronic final state. We also extend the application of PELICAN to the tasks of identifying quark-initiated vs.~gluon-initiated jets, and a multi-
    
[^22]: 大数据-供应链管理框架的预测：数据预处理和机器学习技术

    Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])

    [http://arxiv.org/abs/2307.12971](http://arxiv.org/abs/2307.12971)

    本文介绍了一种新的大数据-供应链管理框架，通过数据预处理和机器学习技术实现供应链预测，优化操作管理、透明度，并讨论了幻影库存对预测的不利影响。

    

    本文旨在系统地识别和比较分析最先进的供应链预测策略和技术。提出了一个新的框架，将大数据分析应用于供应链管理中，包括问题识别、数据来源、探索性数据分析、机器学习模型训练、超参数调优、性能评估和优化，以及预测对人力、库存和整个供应链的影响。首先讨论了根据供应链策略收集数据的需求以及如何收集数据。文章讨论了根据周期或供应链目标需要不同类型的预测。推荐使用供应链绩效指标和误差测量系统来优化表现最佳的模型。还讨论了幻影库存对预测的不利影响以及管理决策依赖供应链绩效指标来确定模型性能参数和改进运营管理、透明度的问题。

    This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
    
[^23]: 神经网络场理论：非高斯性，作用量和局域性

    Neural Network Field Theories: Non-Gaussianity, Actions, and Locality. (arXiv:2307.03223v1 [hep-th])

    [http://arxiv.org/abs/2307.03223](http://arxiv.org/abs/2307.03223)

    本文研究了神经网络场理论，包括非高斯性、作用量和局域性。通过对网络参数的统计独立性进行微小破坏，可以得到相互作用理论，这种展开方法相比于常用的$1/N$展开在普适逼近定理方面表现更好，同时通过关联函数可以系统地重建作用量。

    

    场论中的路径积分测度和神经网络的集合描述的是函数分布。当中心极限定理适用于无限宽度（无限$N$）极限时，网络的集合对应于自由场理论。虽然在$1/N$的展开中对应于场论中的相互作用，但其他展开，如网络参数统计独立性的微小破坏，也可以导致相互作用理论。这些其他的展开可以比$1/N$展开更具优势，例如在普适逼近定理方面表现更好。通过给定场论的关联函数，可以使用一种新的费曼图规则，顶点为关联函数，系统地按照展开参数逐阶重建作用量。这种方法受到了Edgeworth展开的启发，可以为神经网络场理论导出作用量。

    Both the path integral measure in field theory and ensembles of neural networks describe distributions over functions. When the central limit theorem can be applied in the infinite-width (infinite-$N$) limit, the ensemble of networks corresponds to a free field theory. Although an expansion in $1/N$ corresponds to interactions in the field theory, others, such as in a small breaking of the statistical independence of network parameters, can also lead to interacting theories. These other expansions can be advantageous over the $1/N$-expansion, for example by improved behavior with respect to the universal approximation theorem. Given the connected correlators of a field theory, one can systematically reconstruct the action order-by-order in the expansion parameter, using a new Feynman diagram prescription whose vertices are the connected correlators. This method is motivated by the Edgeworth expansion and allows one to derive actions for neural network field theories. Conversely, the co
    
[^24]: AVSegFormer: 基于Transformer的音视频分割

    AVSegFormer: Audio-Visual Segmentation with Transformer. (arXiv:2307.01146v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.01146](http://arxiv.org/abs/2307.01146)

    AVSegFormer是一种基于Transformer的音视频分割框架，通过引入音频查询和可学习查询来选择性地关注视觉特征，还使用音频-视觉混合器动态调整视觉特征，并通过中间掩模损失增强解码器的监督。实验证明该方法的有效性。

    

    音频与视觉的结合长期以来一直是多模态领域的一个研究课题。最近，引入了一项新的音频-视觉分割（AVS）任务，旨在定位和分割给定视频中的有声对象。这个任务首次要求在像素级别对音频驱动的场景进行理解，存在着重大挑战。在本文中，我们提出了AVSegFormer，这是一种利用Transformer架构进行AVS任务的新框架。具体来说，我们在变压器解码器中引入了音频查询和可学习查询，使网络能够有选择地关注感兴趣的视觉特征。此外，我们还设计了一个音频-视觉混合器，通过增强相关的空间通道和抑制无关的空间通道来动态调整视觉特征。此外，我们设计了一个中间掩模损失，以增强解码器的监督，鼓励网络产生更准确的中间预测。大量实验证明了我们方法的有效性。

    The combination of audio and vision has long been a topic of interest in the multi-modal community. Recently, a new audio-visual segmentation (AVS) task has been introduced, aiming to locate and segment the sounding objects in a given video. This task demands audio-driven pixel-level scene understanding for the first time, posing significant challenges. In this paper, we propose AVSegFormer, a novel framework for AVS tasks that leverages the transformer architecture. Specifically, we introduce audio queries and learnable queries into the transformer decoder, enabling the network to selectively attend to interested visual features. Besides, we present an audio-visual mixer, which can dynamically adjust visual features by amplifying relevant and suppressing irrelevant spatial channels. Additionally, we devise an intermediate mask loss to enhance the supervision of the decoder, encouraging the network to produce more accurate intermediate predictions. Extensive experiments demonstrate tha
    
[^25]: AutoST：无需训练的脉冲变压器神经架构搜索

    AutoST: Training-free Neural Architecture Search for Spiking Transformers. (arXiv:2307.00293v1 [cs.NE])

    [http://arxiv.org/abs/2307.00293](http://arxiv.org/abs/2307.00293)

    AutoST是一种无需训练的神经架构搜索方法，用于识别高性能和能效的脉冲变压器架构。

    

    脉冲变压器因同时具备脉冲神经网络（SNN）的能效和变压器的高容量而备受关注。然而，现有的脉冲变压器架构基于人工神经网络（ANN）的推导，存在明显的架构差距，导致性能不及其ANN对应物。传统方法通常依赖手动过程或神经架构搜索（NAS）方法来寻找最优架构，但这些方法要么耗时，要么在内存占用和计算时间方面代价高昂。为解决这些限制，我们提出了AutoST，一种用于脉冲变压器的无需训练的NAS方法，可以快速识别高性能和能效的脉冲变压器架构。与现有的无需训练NAS方法不同，我们提出利用浮点运算（FLOPs）作为一种指导可行性的度量，

    Spiking Transformers have gained considerable attention because they achieve both the energy efficiency of Spiking Neural Networks (SNNs) and the high capacity of Transformers. However, the existing Spiking Transformer architectures, derived from ANNs, exhibit a notable architectural gap, resulting in suboptimal performance compared to their ANN counterparts. Traditional approaches to discovering optimal architectures primarily rely on either manual procedures, which are time-consuming, or Neural Architecture Search (NAS) methods, which are usually expensive in terms of memory footprints and computation time. To address these limitations, we introduce AutoST, a training-free NAS method for Spiking Transformers, to rapidly identify high-performance and energy-efficient Spiking Transformer architectures. Unlike existing training-free NAS methods, which struggle with the non-differentiability and high sparsity inherent in SNNs, we propose to utilize Floating-Point Operations (FLOPs) as a 
    
[^26]: 具有感觉运动预训练的机器人学习

    Robot Learning with Sensorimotor Pre-training. (arXiv:2306.10007v1 [cs.RO])

    [http://arxiv.org/abs/2306.10007](http://arxiv.org/abs/2306.10007)

    本论文介绍了一种针对机器人学习的自监督感觉运动预训练方法，使用 Transformer 模型在视觉表示上进行操作，通过 20,000 条真实世界轨迹数据集的预训练可以使机器人在堆积方块任务中性能提高 2 倍，并使其能够更快地学习新任务。

    

    我们提出了一种自监督的感觉运动预训练方法，用于机器人学习。我们的模型称为 RPT，是一种 Transformer，它对感觉运动令牌序列进行操作。给定一系列相机图像、本体感觉机器人状态和过去的动作，我们将交错的序列编码为令牌，掩模出随机子集，并训练模型来预测掩模的内容。我们假设如果机器人能够预测缺失的内容，它已经获得了一个可以使其行动的物理世界的良好模型。RPT 的设计是在潜在的视觉表示上进行操作，从而使预测变得可行，能够实现 10 倍的模型扩展，并能在实际机器人上进行每秒 10 次的推理。为了评估我们的方法，我们使用运动规划和基于模型的抓取算法，收集了 9 个月内的 20,000 条真实世界轨迹数据集。我们发现，对这些数据进行预训练始终优于从头开始训练，在堆积方块任务中导致 2 倍的性能提高，并使机器人能够更快地学习新任务。

    We present a self-supervised sensorimotor pre-training approach for robotics. Our model, called RPT, is a Transformer that operates on sequences of sensorimotor tokens. Given a sequence of camera images, proprioceptive robot states, and past actions, we encode the interleaved sequence into tokens, mask out a random subset, and train a model to predict the masked-out content. We hypothesize that if the robot can predict the missing content it has acquired a good model of the physical world that can enable it to act. RPT is designed to operate on latent visual representations which makes prediction tractable, enables scaling to 10x larger models, and 10 Hz inference on a real robot. To evaluate our approach, we collect a dataset of 20,000 real-world trajectories over 9 months using a combination of motion planning and model-based grasping algorithms. We find that pre-training on this data consistently outperforms training from scratch, leads to 2x improvements in the block stacking task,
    
[^27]: GSHOT: 少样本标记图生成建模

    GSHOT: Few-shot Generative Modeling of Labeled Graphs. (arXiv:2306.03480v1 [cs.LG])

    [http://arxiv.org/abs/2306.03480](http://arxiv.org/abs/2306.03480)

    GSHOT是一个用于少样本标记图生成建模的元学习框架，通过学习从类似的辅助图数据集中转移元知识，从而快速适应未见过的图数据集。

    

    近年来，深度图生成建模因其直接学习潜在隐藏图分布的惊人能力而受到极大关注。尽管这些技术最初取得了成功，但像许多现有的深度生成方法一样，需要大量的训练样本才能学习一个好的模型。不幸的是，在罕见疾病的药物发现等场景中，可能不总是有足够的训练样本可用。同时，最近少样本学习的进展为训练数据有限的应用打开了大门。本文介绍了少样本图生成建模这一迄今未曾探索的范式。为此，我们开发了GSHOT，一个基于元学习的框架，用于少样本标记图生成建模。GSHOT学习从类似的辅助图数据集中转移元知识。利用这些先前的经验，GSHOT通过自适应的自我调整快速适应未见过的图数据集。

    Deep graph generative modeling has gained enormous attraction in recent years due to its impressive ability to directly learn the underlying hidden graph distribution. Despite their initial success, these techniques, like much of the existing deep generative methods, require a large number of training samples to learn a good model. Unfortunately, large number of training samples may not always be available in scenarios such as drug discovery for rare diseases. At the same time, recent advances in few-shot learning have opened door to applications where available training data is limited. In this work, we introduce the hitherto unexplored paradigm of few-shot graph generative modeling. Towards this, we develop GSHOT, a meta-learning based framework for few-shot labeled graph generative modeling. GSHOT learns to transfer meta-knowledge from similar auxiliary graph datasets. Utilizing these prior experiences, GSHOT quickly adapts to an unseen graph dataset through self-paced fine-tuning. 
    
[^28]: 拉格朗日流网络用于守恒定律

    Lagrangian Flow Networks for Conservation Laws. (arXiv:2305.16846v1 [cs.LG])

    [http://arxiv.org/abs/2305.16846](http://arxiv.org/abs/2305.16846)

    该论文提出了LFlows模型，它使用可微和可逆的变换，在时间上规定参数化的微分同胚变换来对基础密度进行转换，以连续地建模流体密度和速度。与传统方法相比，其优势在于速度的解析表达式总是与密度保持一致，无需昂贵的数值求解器，也无需使用惩罚方法。

    

    我们提出了拉格朗日流网络（LFlows），用于连续地建模流体密度和速度。所提出的LFlows基于连续方程的解，其中连续方程是描述不同形式的质量守恒性质的偏微分方程。我们的模型基于这样的思路：连续方程的解可以通过可微和可逆的变换表示为时间依赖的密度变换。因此，我们通过在时间上规定参数化的微分同胚变换来对基础密度进行转换以建模流体密度。与依赖于Neural-ODE或PINNs的方法相比，关键的优势在于速度的解析表达式始终与密度保持一致。此外，无需昂贵的数值求解器，也无需使用惩罚方法来实施偏微分方程。拉格朗日流网络在合成密度数据上显示出了更高的预测精度。

    We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time. The proposed LFlows satisfy by construction the continuity equation, a PDE describing mass conservation in its differentiable form. Our model is based on the insight that solutions to the continuity equation can be expressed as time-dependent density transformations via differentiable and invertible maps. This follows from classical theory of existence and uniqueness of Lagrangian flows for smooth vector fields. Hence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time. The key benefit compared to methods relying on Neural-ODE or PINNs is that the analytic expression of the velocity is always consistent with the density. Furthermore, there is no need for expensive numerical solvers, nor for enforcing the PDE with penalty methods. Lagrangian Flow Networks show improved predictive accuracy on synthetic densi
    
[^29]: 带有分解密度的字符串图表

    String Diagrams with Factorized Densities. (arXiv:2305.02506v1 [cs.PL])

    [http://arxiv.org/abs/2305.02506](http://arxiv.org/abs/2305.02506)

    本文描述了一个定义在随机变量集上的联合密度的范畴及其意义，以帮助概率编程和因果推断中的组合推理。

    

    有关概率编程和因果模型的研究越来越多地强调了需要在扩展定向图模型的模型类之间进行组合推理的必要性。概率编程和因果模型都定义了一组随机变量上的联合概率密度，并且展示了可以用于推理因果关系和条件独立性的稀疏结构。本文基于最近有关概率映射的马尔可夫范畴的工作，定义了一个范畴，其态射将分别由每个样本空间分解的联合密度与从样本到返回值的确定性映射组合。这是迈向最近的范畴论概率测度描述和通常在概率编程和因果推断中使用的分解密度的操作定义之间的缩小差距的一步。

    A growing body of research on probabilistic programs and causal models has highlighted the need to reason compositionally about model classes that extend directed graphical models. Both probabilistic programs and causal models define a joint probability density over a set of random variables, and exhibit sparse structure that can be used to reason about causation and conditional independence. This work builds on recent work on Markov categories of probabilistic mappings to define a category whose morphisms combine a joint density, factorized over each sample space, with a deterministic mapping from samples to return values. This is a step towards closing the gap between recent category-theoretic descriptions of probability measures, and the operational definitions of factorized densities that are commonly employed in probabilistic programming and causal inference.
    
[^30]: 使用深度学习预测宇宙的初始条件

    Predicting the Initial Conditions of the Universe using Deep Learning. (arXiv:2303.13056v1 [astro-ph.CO])

    [http://arxiv.org/abs/2303.13056](http://arxiv.org/abs/2303.13056)

    本文首次证明了使用深度学习模型可以反向预测宇宙初始线性位移，该方法能够在减少计算量的同时准确恢复初始线性位移。

    

    找到导致当前宇宙状态的初始条件是具有挑战性的，因为它涉及到搜索一个巨大的初始条件输入空间，并通过诸如N-体模拟等工具建模它们的演化，这是计算上昂贵的。深度学习已经成为一种替代建模工具，它可以学习N-体模拟的线性输入与红移为零时的最终非线性位移之间的映射，这可以显著加速向前的模拟。但是，这并不能减少初始条件的搜索空间。在本文中，我们首次证明了深度学习模型可以被用于反向映射。我们训练了一个基于V-Net的卷积神经网络，它可以在给定系统当前时间的非线性位移和宇宙学参数的情况下输出N-体系统的线性位移。我们证明了这个神经网络可以准确地恢复初始线性位移。

    Finding the initial conditions that led to the current state of the universe is challenging because it involves searching over a vast input space of initial conditions, along with modeling their evolution via tools such as N-body simulations which are computationally expensive. Deep learning has emerged as an alternate modeling tool that can learn the mapping between the linear input of an N-body simulation and the final nonlinear displacements at redshift zero, which can significantly accelerate the forward modeling. However, this does not help reduce the search space for initial conditions. In this paper, we demonstrate for the first time that a deep learning model can be trained for the reverse mapping. We train a V-Net based convolutional neural network, which outputs the linear displacement of an N-body system, given the current time nonlinear displacement and the cosmological parameters of the system. We demonstrate that this neural network accurately recovers the initial linear 
    
[^31]: 通过Softmax逼近实现动态最优策略的推断

    Inference on Optimal Dynamic Policies via Softmax Approximation. (arXiv:2303.04416v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2303.04416](http://arxiv.org/abs/2303.04416)

    本文提出了一种简单的softmax逼近方法，可用于从离线数据中估计最优的动态治疗方案并对其进行有效推断。

    

    从离线数据中估计最优的动态策略是动态决策制定中的一个基本问题。在因果推断的背景下，该问题被称为估计最优的动态治疗方案。即使存在大量的估计方法，构建置信区间来估计最优策略的价值及其相关的结构参数本质上更加困难，因为它涉及到未知量的非线性和非可微函数。以前的研究采用了亚样本方法，但可能会降低估计的质量。我们证明，对于一个适当增长的温度参数，最优治疗方案的简单softmax逼近可以实现对真正最优方案的有效推断。我们将我们的结果用于两期的最优动态方案，并将该方法直接推广到有限的时间段情况。我们的工作结合了半参数方法和机器学习技术。

    Estimating optimal dynamic policies from offline data is a fundamental problem in dynamic decision making. In the context of causal inference, the problem is known as estimating the optimal dynamic treatment regime. Even though there exists a plethora of methods for estimation, constructing confidence intervals for the value of the optimal regime and structural parameters associated with it is inherently harder, as it involves non-linear and non-differentiable functionals of un-known quantities that need to be estimated. Prior work resorted to sub-sample approaches that can deteriorate the quality of the estimate. We show that a simple soft-max approximation to the optimal treatment regime, for an appropriately fast growing temperature parameter, can achieve valid inference on the truly optimal regime. We illustrate our result for a two-period optimal dynamic regime, though our approach should directly extend to the finite horizon case. Our work combines techniques from semi-parametric
    
[^32]: 用答案启发式方式促使大型语言模型解决基于知识的视觉问答问题

    Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering. (arXiv:2303.01903v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.01903](http://arxiv.org/abs/2303.01903)

    本研究提出了一个名为Prophet的框架，使用答案启发式方式促使GPT-3解决基于知识的视觉问答问题。在特定的知识型VQA数据集上训练一个纯VQA模型，并从中提取出答案启发式，可提高模型的性能。

    

    基于知识的视觉问答需要超出图像范围的外部知识来回答问题。早期的研究从显式知识库（KBs）检索所需的知识，这经常会引入与问题无关的信息，从而限制了模型的性能。最近的研究试图将大型语言模型（即GPT-3）作为隐含式知识引擎来获取回答所需的必要知识。尽管这些方法取得了令人鼓舞的结果，但我们认为它们还没有充分发挥GPT-3的能力，因为提供的输入信息仍然不足。在本文中，我们提出了Prophet——一个概念上简单的框架，旨在通过回答启发式方式，促使GPT-3解决基于知识的VQA问题。具体来说，我们首先在特定的基于知识的VQA数据集上训练一个纯VQA模型，而不使用外部知识。之后，我们从模型中提取了两种互补的答案启发式：答案候选项。

    Knowledge-based visual question answering (VQA) requires external knowledge beyond the image to answer the question. Early studies retrieve required knowledge from explicit knowledge bases (KBs), which often introduces irrelevant information to the question, hence restricting the performance of their models. Recent works have sought to use a large language model (i.e., GPT-3) as an implicit knowledge engine to acquire the necessary knowledge for answering. Despite the encouraging results achieved by these methods, we argue that they have not fully activated the capacity of GPT-3 as the provided input information is insufficient. In this paper, we present Prophet -- a conceptually simple framework designed to prompt GPT-3 with answer heuristics for knowledge-based VQA. Specifically, we first train a vanilla VQA model on a specific knowledge-based VQA dataset without external knowledge. After that, we extract two types of complementary answer heuristics from the model: answer candidates 
    
[^33]: DeepSaDe: 学习确保满足领域约束的神经网络

    DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint Satisfaction. (arXiv:2303.01141v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01141](http://arxiv.org/abs/2303.01141)

    本文提出了一种学习神经网络的方法，该神经网络可以强制执行多样化的约束并且保证所有可能的预测都满足约束限制。

    

    随着机器学习模型的普及，尤其是神经网络，人们越来越关注它们的可信度，特别是在安全关键应用中，如自动驾驶汽车的行为必须是安全的。当前一些方法可以对神经网络进行约束，但它们不能保证所有可能的预测都满足约束限制（即使在未看过的数据上），或者它们对可强制执行的约束类型有限制。为了解决这些问题，本文提出了一种方法，用于训练可以强制执行广泛约束并保证所有可能预测都满足约束的神经网络。该方法基于以往将学习线性模型视为约束满足问题（CSP）的工作。为了将这个想法应用于神经网络，本文增加了两个关键的新元素：网络层上的约束传播和权重更新。

    As machine learning models, specifically neural networks, are becoming increasingly popular, there are concerns regarding their trustworthiness, specially in safety-critical applications, e.g. actions of an autonomous vehicle must be safe. There are approaches that can train neural networks where such domain requirements are enforced as constraints, but they either cannot guarantee that the constraint will be satisfied by all possible predictions (even on unseen data) or they are limited in the type of constraints that can be enforced. In this paper, we present an approach to train neural networks which can enforce a wide variety of constraints and guarantee that the constraint is satisfied by all possible predictions. The approach builds on earlier work where learning linear models is formulated as a constraint satisfaction problem (CSP). To make this idea applicable to neural networks, two crucial new elements are added: constraint propagation over the network layers, and weight upda
    
[^34]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^35]: QCM-SGM+: 基于得分生成模型的量化压缩感知改进

    QCM-SGM+: Improved Quantized Compressed Sensing With Score-Based Generative Models. (arXiv:2302.00919v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2302.00919](http://arxiv.org/abs/2302.00919)

    该论文提出了一种名为QCS-SGM+的算法，利用基于得分的生成模型(SGM)作为隐式先验进行量化压缩感知(QCS)，并可以有效地处理一般矩阵。这个算法解决了在粗糙量化的情况下恢复挑战的问题。

    

    在实际的压缩感知过程中，获得的测量数据通常需要在传输或存储前限制为有限比特的量化。这个非线性量化过程带来了重大的恢复挑战，特别是在极度粗糙的量化如1比特下。最近，提出了一种称为QCS-SGM的有效算法，该算法利用基于得分的生成模型(SGM)作为隐式先验进行量化压缩感知(QCS)。由于SGM在捕捉自然信号的复杂结构方面的熟练程度，QCS-SGM明显优于以前的QCS方法。然而，QCS-SGM局限于(近似)行正交传感矩阵，否则可能会无法计算似然分数。为了解决这个限制，我们引入了QCS-SGM+的高级变体，可以有效地处理一般矩阵。关键思想是似然分数计算的贝叶斯推理观点，其中计算期望得分以解决每个测量的结构非正交情况。

    In practical compressed sensing (CS), the obtained measurements typically necessitate quantization to a limited number of bits prior to transmission or storage. This nonlinear quantization process poses significant recovery challenges, particularly with extreme coarse quantization such as 1-bit. Recently, an efficient algorithm called QCS-SGM was proposed for quantized CS (QCS) which utilizes score-based generative models (SGM) as an implicit prior. Due to the adeptness of SGM in capturing the intricate structures of natural signals, QCS-SGM substantially outperforms previous QCS methods. However, QCS-SGM is constrained to (approximately) row-orthogonal sensing matrices as the computation of the likelihood score becomes intractable otherwise. To address this limitation, we introduce an advanced variant of QCS-SGM, termed QCS-SGM+, capable of handling general matrices effectively. The key idea is a Bayesian inference perspective on the likelihood score computation, wherein an expectatio
    
[^36]: 通用方差条件下的分布式随机优化

    Distributed Stochastic Optimization under a General Variance Condition. (arXiv:2301.12677v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2301.12677](http://arxiv.org/abs/2301.12677)

    这项研究通过重新审视联邦平均算法，在最小假设下对分布式非凸目标进行了随机优化，建立了仅满足随机梯度温和条件的收敛结果。

    

    分布式随机优化在解决大规模机器学习问题时表现出了很高的效率。尽管已经提出并成功应用于一般实际问题的算法很多，但它们的理论保证主要依赖于随机梯度的某些有界条件，从均匀有界性到放松增长条件。此外，在代理之间表征数据异质性及其对算法性能的影响依然具有挑战性。出于这样的动机，我们重新考虑了经典的联邦平均（FedAvg）算法，以解决分布式随机优化问题，并在平滑非凸目标函数的随机梯度仅满足温和方差条件的情况下建立了收敛结果。在此条件下，还建立了接近确定的收敛到一个稳态点。此外，我们讨论了一个更具信息性的度量标准。

    Distributed stochastic optimization has drawn great attention recently due to its effectiveness in solving large-scale machine learning problems. Though numerous algorithms have been proposed and successfully applied to general practical problems, their theoretical guarantees mainly rely on certain boundedness conditions on the stochastic gradients, varying from uniform boundedness to the relaxed growth condition. In addition, how to characterize the data heterogeneity among the agents and its impacts on the algorithmic performance remains challenging. In light of such motivations, we revisit the classical Federated Averaging (FedAvg) algorithm for solving the distributed stochastic optimization problem and establish the convergence results under only a mild variance condition on the stochastic gradients for smooth nonconvex objective functions. Almost sure convergence to a stationary point is also established under the condition. Moreover, we discuss a more informative measurement for
    
[^37]: 针对可扩展性的子图表示学习简化以进行可扩展的链接预测

    Simplifying Subgraph Representation Learning for Scalable Link Prediction. (arXiv:2301.12562v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12562](http://arxiv.org/abs/2301.12562)

    提出了一种新的可扩展简化子图表示学习（S3GRL）框架，通过简化每个链接子图中的消息传递和聚合操作实现更快的训练和推理，并可适应各种子图采样策略和扩散操作符以模拟计算代价高的子图表示学习。大量实验证明了S3GRL模型可以扩展SGRL而不会显著降低性能。

    

    图上的链接预测是一个基本问题。子图表示学习方法通过将链接预测转化为在链接周围子图上的图分类来实现了最先进的链接预测。然而，子图表示学习方法计算代价高，并且由于子图水平操作的代价而不适用于大规模图形。我们提出了一种新的子图表示学习类，称为可扩展简化子图表示学习（S3GRL），旨在实现更快的训练和推理。S3GRL简化了每个链接子图中的消息传递和聚合操作。作为可扩展性框架，S3GRL适应各种子图采样策略和扩散运算符来模拟计算代价高的子图表示学习方法。我们提出了多个S3GRL实例，并在小到大规模的图形上进行了实证研究。我们广泛的实验表明，所提出的S3GRL模型可以扩展SGRL而不会显著降低性能。

    Link prediction on graphs is a fundamental problem. Subgraph representation learning approaches (SGRLs), by transforming link prediction to graph classification on the subgraphs around the links, have achieved state-of-the-art performance in link prediction. However, SGRLs are computationally expensive, and not scalable to large-scale graphs due to expensive subgraph-level operations. To unlock the scalability of SGRLs, we propose a new class of SGRLs, that we call Scalable Simplified SGRL (S3GRL). Aimed at faster training and inference, S3GRL simplifies the message passing and aggregation operations in each link's subgraph. S3GRL, as a scalability framework, accommodates various subgraph sampling strategies and diffusion operators to emulate computationally-expensive SGRLs. We propose multiple instances of S3GRL and empirically study them on small to large-scale graphs. Our extensive experiments demonstrate that the proposed S3GRL models scale up SGRLs without significant performance 
    
[^38]: 一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法

    An Isolation-Aware Online Virtual Network Embedding via Deep Reinforcement Learning. (arXiv:2211.14158v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2211.14158](http://arxiv.org/abs/2211.14158)

    本文提出了一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法，以解决虚拟网络环境中多个VN共存可能导致隔离问题的挑战。

    

    虚拟化技术是现代ICT基础设施的基础，它使服务提供商能够创建支持各种智能城市应用的专用虚拟网络（VN）。这些VN不断产生大量数据，需要严格的可靠性和安全性要求。然而，在虚拟化网络环境中，多个VN可能共存于同一物理基础设施上，如果隔离不当，则可能相互干扰或提供未经授权的访问。前者会导致性能降低，后者会破坏VN的安全性。当特定VN违反隔离要求时，基础设施提供商的服务保障变得更加复杂。为解决隔离问题，本文提出在虚拟网络嵌入（VNE）期间进行隔离，即将VN分配到物理基础设施上的过程。

    Virtualization technologies are the foundation of modern ICT infrastructure, enabling service providers to create dedicated virtual networks (VNs) that can support a wide range of smart city applications. These VNs continuously generate massive amounts of data, necessitating stringent reliability and security requirements. In virtualized network environments, however, multiple VNs may coexist on the same physical infrastructure and, if not properly isolated, may interfere with or provide unauthorized access to one another. The former causes performance degradation, while the latter compromises the security of VNs. Service assurance for infrastructure providers becomes significantly more complicated when a specific VN violates the isolation requirement.  In an effort to address the isolation issue, this paper proposes isolation during virtual network embedding (VNE), the procedure of allocating VNs onto physical infrastructure. We define a simple abstracted concept of isolation levels t
    

