# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Skip $\textbackslash n$: A simple method to reduce hallucination in Large Vision-Language Models](https://rss.arxiv.org/abs/2402.01345) | 本文提出了一种新的视角，指出LVLMs中固有的偏见可能是多模态幻觉的关键因素。通过系统识别与段落分割符相关的语义漂移偏差，我们发现模型在训练数据中经常遇到明显的内容语义变化，导致幻觉的产生。 |
| [^2] | [BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic Architectures against Model Inversion Attacks](https://rss.arxiv.org/abs/2402.00906) | 本研究探索了神经形态架构对模型反转攻击的隐私保护能力，发现脉冲神经网络具有固有的隐私保护性质，并能有效抵抗基于梯度的攻击。 |
| [^3] | [Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models](https://arxiv.org/abs/2404.00506) | 该论文提出了一种无需标签的无监督去学习方法，通过引入变分方法并利用表示分布的近似，实现了在深度模型中消除已遗忘数据信息的目标。 |
| [^4] | [Synapse: Learning Preferential Concepts from Visual Demonstrations](https://arxiv.org/abs/2403.16689) | Synapse是一种神经符号化方法，旨在从有限演示中高效学习偏好概念，通过将偏好表示为神经符号程序并利用视觉解析、大型语言模型和程序合成相结合的方式来学习个人偏好。 |
| [^5] | [FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions](https://arxiv.org/abs/2403.15246) | 该论文引入了FollowIR数据集，包含严格的说明书评估基准和训练集，帮助信息检索模型更好地遵循真实世界的说明书。议论基于TREC会议的历史，旨在使信息检索模型能够根据详细说明书理解和判断相关性。 |
| [^6] | [L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification](https://arxiv.org/abs/2403.06064) | 本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。 |
| [^7] | [DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training](https://arxiv.org/abs/2403.03542) | 本文提出了一种新的自回归去噪预训练策略，可以更稳定、更高效地在PDE数据上进行预训练，并且通过基于傅里叶注意力的模型架构设计，实现了在大规模预训练中轻松扩展模型，该模型在多个PDE数据集上取得了SOTA表现。 |
| [^8] | [World Models for Autonomous Driving: An Initial Survey](https://arxiv.org/abs/2403.02622) | 世界模型在自主驾驶领域的重要性和作用，是通过准确预测未来事件和评估其影响来帮助决策过程，从而推动自主驾驶技术发展的革命性方法。 |
| [^9] | [Joint Parameter and Parameterization Inference with Uncertainty Quantification through Differentiable Programming](https://arxiv.org/abs/2403.02215) | 通过可微分编程，本研究提出了一种新框架，能够联合估计和量化物理参数以及机器学习参数化，实现了高维参数空间内的在线训练和有效贝叶斯推断。 |
| [^10] | [Explainable Classification Techniques for Quantum Dot Device Measurements](https://arxiv.org/abs/2402.13699) | 提出了一种基于合成数据的的可解释特征技术，利用可解释性提升机（EBMs）实现了在量子点调谐中较高的可解释性和准确性。 |
| [^11] | [Chain of Thought Empowers Transformers to Solve Inherently Serial Problems](https://arxiv.org/abs/2402.12875) | 思维链赋予变压器模型执行固有串行计算的能力，提高了变压器在算术和符号推理任务中的准确性。 |
| [^12] | [What Changed? Converting Representational Interventions to Natural Language](https://arxiv.org/abs/2402.11355) | 将表征空间的反事实转化为自然语言，以分析和解释模型干预所引起的语言变化，并减轻分类中的偏见。 |
| [^13] | [CHEMREASONER: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback](https://arxiv.org/abs/2402.10980) | 通过将大型语言模型推理与量子化学反馈相结合，我们引入了一个AI引导的计算筛选框架，将催化剂发现形式化为一个不确定环境，从而实现高效催化剂的积极搜索 |
| [^14] | [Generative AI and Process Systems Engineering: The Next Frontier](https://arxiv.org/abs/2402.10977) | 新兴生成人工智能模型（如基础模型）在过程系统工程中的应用，提供了多功能的适应性，对合成与设计、优化与集成以及过程监控与控制等关键领域具有重要影响。 |
| [^15] | [Selective Prediction for Semantic Segmentation using Post-Hoc Confidence Estimation and Its Performance under Distribution Shift](https://arxiv.org/abs/2402.10665) | 本文研究了在低资源环境中语义分割的选择性预测，提出了一种针对语义分割量身定制的新型图像级置信度测量，并通过实验证明了其有效性 |
| [^16] | [Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs](https://arxiv.org/abs/2402.10517) | 任意精度LLM引入了一种轻量级方法，通过将不同大小LLMs量化为不同位宽（如3、4、...，n位）并叠加到内存中，显着降低了部署多个不同大小LLMs的高成本 |
| [^17] | [GraphCBAL: Class-Balanced Active Learning for Graph Neural Networks via Reinforcement Learning](https://arxiv.org/abs/2402.10074) | 本文提出了一种通过强化学习对图神经网络进行类平衡主动学习的框架GraphCBAL，该框架能够学习一种最佳策略，选择类平衡和信息丰富的节点进行注释，以最大化GNNs性能。 |
| [^18] | [Misspecification uncertainties in near-deterministic regression](https://arxiv.org/abs/2402.01810) | 该论文研究了近确定性回归中错误规范化的不确定性问题，并提出了一种组合模型，以准确预测和控制参数不确定性。 |
| [^19] | [Large Language Models for Time Series: A Survey](https://arxiv.org/abs/2402.01801) | 本调研论文深入探讨了大规模语言模型（LLM）在时间序列分析中的应用方法。通过解决LLM与数值型时间序列数据之间的差异挑战，揭示了LLM在时间序列领域的潜力，并提出了直接提示、量化、对齐、利用视觉方式和结合工具等方法。此外，还提供了对应用领域、评估方法和未来研究方向的讨论。 |
| [^20] | [Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation](https://arxiv.org/abs/2402.01705) | 本研究超越行为主义的定义范围，提出了一种度量和减轻表征性伤害的框架，强调了大型语言模型在实施这些伤害时的脆弱性，并提出了减轻措施的建议。 |
| [^21] | [Creativity and Machine Learning: A Survey](https://arxiv.org/abs/2104.02726) | 本调查论文总结了机器学习和创造力领域的历史、现状，以及关键的贡献和研究挑战。 |
| [^22] | [CascadedGaze: Efficiency in Global Context Extraction for Image Restoration.](http://arxiv.org/abs/2401.15235) | 本文提出了一种名为CascadedGaze的网络架构，使用了一种新颖而高效的全局上下文提取方法，以解决图像恢复中全局信息的问题。通过在卷积层之间引入小的卷积核，该方法可以学习到全局的依赖关系，而无需使用自注意力机制。实验结果表明，该方法在多种图像去噪任务上优于其他先进方法。 |
| [^23] | [Accelerating Material Property Prediction using Generically Complete Isometry Invariants.](http://arxiv.org/abs/2401.15089) | 本研究提出了一种使用通用完全等变量加速材料属性预测的方法，通过采用点距离分布(PDD)作为学习算法的表示，并开发了一个修改的自注意机制的变压器模型来利用PDD。 |
| [^24] | [Inverse Molecular Design with Multi-Conditional Diffusion Guidance.](http://arxiv.org/abs/2401.13858) | 借助多条件扩散引导的逆分子设计模型在材料和药物发现方面具有巨大潜力。通过引入Transformer-based去噪模型和图依赖的扩散过程，该模型能够在多个条件约束下准确地生成聚合物和小分子。 |
| [^25] | [Link Me Baby One More Time: Social Music Discovery on Spotify.](http://arxiv.org/abs/2401.08818) | 本研究探讨了在社交音乐推荐中影响音乐互动的社交和环境因素。研究发现，接收者与发送者音乐品味相似、分享的音轨适合接收者的品味、接收者与发送者具有更强和更亲密的联系以及分享的艺术家在接收者的关系中受欢迎，这些因素都会增加接收者与新艺术家的互动。 |
| [^26] | [Risk-anticipatory autonomous driving strategies considering vehicles' weights, based on hierarchical deep reinforcement learning.](http://arxiv.org/abs/2401.08661) | 本研究基于分层深度强化学习开发了一种风险预测自动驾驶策略，考虑车辆的重量，并将其纳入自动驾驶决策中，以降低潜在风险和事故后果。 |
| [^27] | [An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models.](http://arxiv.org/abs/2401.06692) | 该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。 |
| [^28] | [Scalable network reconstruction in subquadratic time.](http://arxiv.org/abs/2401.01404) | 这篇论文提出了一个可扩展的网络重建算法，能够在次二次时间内实现结果，通过随机的二阶邻居搜索产生最佳的边候选。 |
| [^29] | [Transformers as Recognizers of Formal Languages: A Survey on Expressivity.](http://arxiv.org/abs/2311.00208) | 本文对transformers在形式语言识别领域的相关研究进行了全面调查，为理解其表达能力提供了一个统一的框架。 |
| [^30] | [ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality.](http://arxiv.org/abs/2310.16242) | 本文介绍了一种名为ZzzGPT的交互式GPT方法，旨在提高睡眠质量。通过利用大型语言模型进行预测和反馈，该方法融合了先进的机器学习和用户导向设计，以提供准确和有价值的结果。 |
| [^31] | [The Role of Federated Learning in a Wireless World with Foundation Models.](http://arxiv.org/abs/2310.04003) | 基于联邦学习的无线世界中，基础模型（FMs）为生成式AI应用提供支持，并且可以通过分散的数据和计算资源来提高联邦学习（FL）的性能，但是FMs对资源需求较高可能给FL-enabled的无线网络带来挑战。 |
| [^32] | [Language Models as Black-Box Optimizers for Vision-Language Models.](http://arxiv.org/abs/2309.05950) | 本论文介绍了一种新的视觉-语言模型 (VLMs) 微调方法，通过自然语言提示来避免访问模型参数，采用聊天式的语言模型作为黑盒优化器，在少样本图像分类任务中达到效果。 |
| [^33] | [Utilizing Admissible Bounds for Heuristic Learning.](http://arxiv.org/abs/2308.11905) | 本文通过将可接受启发式作为截断高斯分布的参数，明确了在监督启发式学习中可接受启发式的作用，紧缩了假设空间。 |
| [^34] | [The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation.](http://arxiv.org/abs/2308.09764) | 本研究通过去除时尚图像的背景，提高了数据质量和模型性能，在多个方面进行了广泛的比较实验，结果表明背景去除对于模型训练有积极的影响。 |
| [^35] | [Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics.](http://arxiv.org/abs/2308.05739) | 本论文提出了ZeroGrads框架，通过学习非可微图形的局部替代损失函数来解决无梯度问题，并通过主动平滑和局部性约束优化替代损失的拟合，同时设计了高效的采样方案，实现了可行的运行时间和竞争力。 |
| [^36] | [PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks.](http://arxiv.org/abs/2307.11833) | PINNsFormer是一种基于Transformer的框架，通过捕捉时间依赖性准确逼近求解偏微分方程，相比传统方法具有更好的性能。 |
| [^37] | [On the power of graph neural networks and the role of the activation function.](http://arxiv.org/abs/2307.04661) | 本文通过对称多项式代数的工具证明了对于具有分段多项式激活函数且体系结构大小不变的GNNs，存在一对非同构根树在任意迭代次数内无法被区分，与此同时，具有不同大小的GNNs只需两次迭代即可区分。此外，我们还证明了如果允许非分段多项式激活函数，则在两次迭代内，单个神经元感知器可以区分任意一对非同构树的根节点。 |
| [^38] | [Hierarchical Autoencoder-based Lossy Compression for Large-scale High-resolution Scientific Data.](http://arxiv.org/abs/2307.04216) | 本论文提出了一种基于分层自编码器的神经网络模型，能够显著压缩大规模高分辨率科学数据，并保持高重建质量。 |
| [^39] | [MLP-Mixer as a Wide and Sparse MLP.](http://arxiv.org/abs/2306.01470) | 深度学习中常用的MLP有潜力提高性能。本研究揭示MLP-Mixer 可以作为具有稀疏权重的宽MLP有效地工作。 |
| [^40] | [Benchmarks and leaderboards for sound demixing tasks.](http://arxiv.org/abs/2305.07489) | 本文介绍了两个新的声源分离任务基准，并将流行的模型及其集成在这些基准上的表现进行了比较。他们还开发了一种新的音频分离方法，基于适合特定音轨的不同模型的集成，该方法在2023年音乐分离挑战赛中取得了高水平成绩，并开源了代码和方法。 |
| [^41] | [Materials Discovery with Extreme Properties via AI-Driven Combinatorial Chemistry.](http://arxiv.org/abs/2303.11833) | 本文提出了一种基于人工智能驱动的组合化学方法，不依赖于数据，可以发现未知材料并具有更优越的性质。实验证明这种方法比概率分布学习的模型更适合于发现更好的材料。 |
| [^42] | [Global Performance Guarantees for Neural Network Models of AC Power Flow.](http://arxiv.org/abs/2211.07125) | 本文首次开发了一种可行的神经网络验证程序，它结合了非线性AC电力流方程的ground truth，以确定最坏的神经网络性能。使用顺序添加有针对性的切割，我们迭代地收紧我们的公式，直到解决方案足够紧密或达到一个安全性阈值。 |
| [^43] | [Fant\^omas: Understanding Face Anonymization Reversibility.](http://arxiv.org/abs/2210.10651) | 本文对脸部匿名逆转现象进行了全面的研究，发现11种脸部匿名化方法至少部分可逆，并强调了重构和反演实现可逆性的机制。 |

# 详细

[^1]: 跳过$\textbackslash n$: 一种简单的方法减少大规模视觉-语言模型中的幻觉

    Skip $\textbackslash n$: A simple method to reduce hallucination in Large Vision-Language Models

    [https://rss.arxiv.org/abs/2402.01345](https://rss.arxiv.org/abs/2402.01345)

    本文提出了一种新的视角，指出LVLMs中固有的偏见可能是多模态幻觉的关键因素。通过系统识别与段落分割符相关的语义漂移偏差，我们发现模型在训练数据中经常遇到明显的内容语义变化，导致幻觉的产生。

    

    最近大规模视觉-语言模型（LVLMs）的进展展示了其在视觉信息理解与人类语言方面的令人印象深刻的能力。尽管取得了这些进展，LVLMs仍然面临多模态幻觉的挑战，例如生成与视觉信息中不存在的对象相关的文本描述。然而，多模态幻觉的根本原因仍然未被充分探索。在本文中，我们提出了一个新的视角，认为LVLMs中固有的偏见可能是幻觉的关键因素。具体而言，我们系统地确定了与段落分割符（'$\textbackslash n\textbackslash n$'）相关的语义漂移偏差，即在训练数据中，在“$\textbackslash n\textbackslash n$”之前和之后的内容经常表现出显著的语义改变。这种模式使得模型推断在“$\textbackslash n\textbackslash n$”之后的内容应明显不同于前面的内容。

    Recent advancements in large vision-language models (LVLMs) have demonstrated impressive capability in visual information understanding with human language. Despite these advances, LVLMs still face challenges with multimodal hallucination, such as generating text descriptions of objects that are not present in the visual information. However, the underlying fundamental reasons of multimodal hallucinations remain poorly explored. In this paper, we propose a new perspective, suggesting that the inherent biases in LVLMs might be a key factor in hallucinations. Specifically, we systematically identify a semantic shift bias related to paragraph breaks ('$\textbackslash n\textbackslash n$'), where the content before and after '$\textbackslash n\textbackslash n$' in the training data frequently exhibit significant semantic changes. This pattern leads the model to infer that the contents following '$\textbackslash n\textbackslash n$' should be obviously different from the preceding contents wi
    
[^2]: BrainLeaks: 关于神经形态架构对模型反转攻击的隐私保护性质

    BrainLeaks: On the Privacy-Preserving Properties of Neuromorphic Architectures against Model Inversion Attacks

    [https://rss.arxiv.org/abs/2402.00906](https://rss.arxiv.org/abs/2402.00906)

    本研究探索了神经形态架构对模型反转攻击的隐私保护能力，发现脉冲神经网络具有固有的隐私保护性质，并能有效抵抗基于梯度的攻击。

    

    随着机器学习在医疗保健和金融等安全敏感领域的主流整合，对数据隐私的担忧已经加剧。传统的人工神经网络（ANNs）已被发现容易受到多种泄露敏感数据的攻击。特别是，模型反转（MI）攻击可以重构用于训练模型的数据样本。神经形态架构已经成为神经计算的一种范式转变，实现了异步和节能的计算。然而，几乎没有现有的工作研究了神经形态架构对模型反转的隐私性。我们的研究受到的启示是，脉冲神经网络（SNNs）的不可微特性可能导致固有的隐私保护性质，尤其抵抗基于梯度的攻击。为了研究这一假设，我们提出了对SNNs的隐私保护能力进行全面探索。

    With the mainstream integration of machine learning into security-sensitive domains such as healthcare and finance, concerns about data privacy have intensified. Conventional artificial neural networks (ANNs) have been found vulnerable to several attacks that can leak sensitive data. Particularly, model inversion (MI) attacks enable the reconstruction of data samples that have been used to train the model. Neuromorphic architectures have emerged as a paradigm shift in neural computing, enabling asynchronous and energy-efficient computation. However, little to no existing work has investigated the privacy of neuromorphic architectures against model inversion. Our study is motivated by the intuition that the non-differentiable aspect of spiking neural networks (SNNs) might result in inherent privacy-preserving properties, especially against gradient-based attacks. To investigate this hypothesis, we propose a thorough exploration of SNNs' privacy-preserving capabilities. Specifically, we 
    
[^3]: 与标签无关的遗忘:深度模型中无监督的去学习

    Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models

    [https://arxiv.org/abs/2404.00506](https://arxiv.org/abs/2404.00506)

    该论文提出了一种无需标签的无监督去学习方法，通过引入变分方法并利用表示分布的近似，实现了在深度模型中消除已遗忘数据信息的目标。

    

    机器去学习旨在从已遗忘数据中删除信息，同时保留训练良好的模型中剩余数据的信息。然而，现有的机器去学习方法通常依赖于整个去学习过程中的完全监督。不幸的是，由于标注真实世界数据集所需的巨大成本，获得这种监督可能实际上是不切实际的。这个挑战促使我们提出一种在去学习过程中无需标签的无监督去学习方法。具体地，我们引入一种变分方法来近似剩余数据的表示分布。利用这种近似，我们调整原始模型以在表示级别消除已遗忘数据中的信息。

    arXiv:2404.00506v1 Announce Type: new  Abstract: Machine unlearning aims to remove information derived from forgotten data while preserving that of the remaining dataset in a well-trained model. With the increasing emphasis on data privacy, several approaches to machine unlearning have emerged. However, these methods typically rely on complete supervision throughout the unlearning process. Unfortunately, obtaining such supervision, whether for the forgetting or remaining data, can be impractical due to the substantial cost associated with annotating real-world datasets. This challenge prompts us to propose a supervision-free unlearning approach that operates without the need for labels during the unlearning process. Specifically, we introduce a variational approach to approximate the distribution of representations for the remaining data. Leveraging this approximation, we adapt the original model to eliminate information from the forgotten data at the representation level. To further a
    
[^4]: Synapse: 从视觉演示中学习优先概念

    Synapse: Learning Preferential Concepts from Visual Demonstrations

    [https://arxiv.org/abs/2403.16689](https://arxiv.org/abs/2403.16689)

    Synapse是一种神经符号化方法，旨在从有限演示中高效学习偏好概念，通过将偏好表示为神经符号程序并利用视觉解析、大型语言模型和程序合成相结合的方式来学习个人偏好。

    

    本文解决了偏好学习问题，旨在从视觉输入中学习用户特定偏好（例如，“好停车位”，“方便的下车位置”）。尽管与学习事实概念（例如，“红色立方体”）相似，但偏好学习是一个基本更加困难的问题，因为它涉及主观性质和个人特定训练数据的缺乏。我们使用一种名为Synapse的新框架来解决这个问题，这是一种神经符号化方法，旨在有效地从有限演示中学习偏好概念。Synapse将偏好表示为在图像上运作的领域特定语言（DSL）中的神经符号程序，并利用视觉解析、大型语言模型和程序合成的新组合来学习代表个人偏好的程序。我们通过广泛的实验评估了Synapse，包括一个关注与移动相关的用户案例研究。

    arXiv:2403.16689v1 Announce Type: cross  Abstract: This paper addresses the problem of preference learning, which aims to learn user-specific preferences (e.g., "good parking spot", "convenient drop-off location") from visual input. Despite its similarity to learning factual concepts (e.g., "red cube"), preference learning is a fundamentally harder problem due to its subjective nature and the paucity of person-specific training data. We address this problem using a new framework called Synapse, which is a neuro-symbolic approach designed to efficiently learn preferential concepts from limited demonstrations. Synapse represents preferences as neuro-symbolic programs in a domain-specific language (DSL) that operates over images, and leverages a novel combination of visual parsing, large language models, and program synthesis to learn programs representing individual preferences. We evaluate Synapse through extensive experimentation including a user case study focusing on mobility-related
    
[^5]: FollowIR: 评估和教授信息检索模型以遵循说明书

    FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions

    [https://arxiv.org/abs/2403.15246](https://arxiv.org/abs/2403.15246)

    该论文引入了FollowIR数据集，包含严格的说明书评估基准和训练集，帮助信息检索模型更好地遵循真实世界的说明书。议论基于TREC会议的历史，旨在使信息检索模型能够根据详细说明书理解和判断相关性。

    

    现代大型语言模型（LLMs）能够遵循长且复杂的说明书，从而实现多样化的用户任务。然而，尽管信息检索（IR）模型使用LLMs作为其架构的支柱，几乎所有这些模型仍然只接受查询作为输入，没有说明书。对于最近一些接受说明书的模型来说，它们如何使用这些说明书还不清楚。我们引入了FollowIR数据集，其中包含严格的说明书评估基准，以及一个训练集，帮助IR模型学习更好地遵循现实世界的说明书。FollowIR基于TREC会议的悠久历史：正如TREC为人类标注员提供说明书（也称为叙述）来判断文档的相关性一样，因此IR模型应该能够根据这些详细说明书理解和确定相关性。我们的评估基准从三个经过深度判断的TREC收藏开始

    arXiv:2403.15246v1 Announce Type: cross  Abstract: Modern Large Language Models (LLMs) are capable of following long and complex instructions that enable a diverse amount of user tasks. However, despite Information Retrieval (IR) models using LLMs as the backbone of their architectures, nearly all of them still only take queries as input, with no instructions. For the handful of recent models that do take instructions, it's unclear how they use them. We introduce our dataset FollowIR, which contains a rigorous instruction evaluation benchmark as well as a training set for helping IR models learn to better follow real-world instructions. FollowIR builds off the long history of the TREC conferences: as TREC provides human annotators with instructions (also known as narratives) to determine document relevance, so should IR models be able to understand and decide relevance based on these detailed instructions. Our evaluation benchmark starts with three deeply judged TREC collections and al
    
[^6]: L$^2$GC: 洛伦兹线性图卷积网络用于节点分类

    L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification

    [https://arxiv.org/abs/2403.06064](https://arxiv.org/abs/2403.06064)

    本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。

    

    线性图卷积网络（GCNs）用于对图数据中的节点进行分类。然而，我们注意到大多数现有的线性GCN模型在欧几里得空间中执行神经网络操作，这并没有明确捕捉到作为图模型的现实世界数据集中呈现出的类似树状的层次结构。本文尝试将双曲空间引入线性GCN，并提出了一种新颖的洛伦兹线性GCN框架。具体来说，我们将图节点的学习特征映射到双曲空间中，然后进行洛伦兹线性特征变换，以捕获数据的潜在树状结构。在标准引文网络数据集上进行的半监督学习实验结果显示，我们的方法在Citeseer数据集上达到了74.7%的准确度，而在PubMed数据集上达到了81.3%的准确度，创造了新的最先进结果。此外，我们观察到我们的方法可以训练至少达到2个数量级。

    arXiv:2403.06064v1 Announce Type: cross  Abstract: Linear Graph Convolutional Networks (GCNs) are used to classify the node in the graph data. However, we note that most existing linear GCN models perform neural network operations in Euclidean space, which do not explicitly capture the tree-like hierarchical structure exhibited in real-world datasets that modeled as graphs. In this paper, we attempt to introduce hyperbolic space into linear GCN and propose a novel framework for Lorentzian linear GCN. Specifically, we map the learned features of graph nodes into hyperbolic space, and then perform a Lorentzian linear feature transformation to capture the underlying tree-like structure of data. Experimental results on standard citation networks datasets with semi-supervised learning show that our approach yields new state-of-the-art results of accuracy 74.7$\%$ on Citeseer and 81.3$\%$ on PubMed datasets. Furthermore, we observe that our approach can be trained up to two orders of magnitu
    
[^7]: DPOT: 自回归去噪运算器变换器用于大规模PDE预训练

    DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE Pre-Training

    [https://arxiv.org/abs/2403.03542](https://arxiv.org/abs/2403.03542)

    本文提出了一种新的自回归去噪预训练策略，可以更稳定、更高效地在PDE数据上进行预训练，并且通过基于傅里叶注意力的模型架构设计，实现了在大规模预训练中轻松扩展模型，该模型在多个PDE数据集上取得了SOTA表现。

    

    预训练已经被研究用来提高在数据稀缺环境中训练神经算子的效率和性能。然而，由于偏微分方程（PDE）数据的固有复杂性和多样性，如长轨迹、多个尺度和不同维度，它在很大程度上还处于起步阶段。在本文中，我们提出了一种新的自回归去噪预训练策略，这种策略能够更稳定、更高效地在PDE数据上进行预训练，并且可以泛化到各种下游任务。此外，通过基于傅里叶注意力的灵活可扩展模型架构的设计，我们可以轻松地将模型扩展到大规模预训练。我们在10+个PDE数据集上训练了具有超过0.5B参数的PDE基础模型，包括超过100k轨迹。大量实验证明我们在这些基准上取得了SOTA，并验证了我们的模型对显著提升性能的强大泛化能力。

    arXiv:2403.03542v1 Announce Type: new  Abstract: Pre-training has been investigated to improve the efficiency and performance of training neural operators in data-scarce settings. However, it is largely in its infancy due to the inherent complexity and diversity, such as long trajectories, multiple scales and varying dimensions of partial differential equations (PDEs) data. In this paper, we present a new auto-regressive denoising pre-training strategy, which allows for more stable and efficient pre-training on PDE data and generalizes to various downstream tasks. Moreover, by designing a flexible and scalable model architecture based on Fourier attention, we can easily scale up the model for large-scale pre-training. We train our PDE foundation model with up to 0.5B parameters on 10+ PDE datasets with more than 100k trajectories. Extensive experiments show that we achieve SOTA on these benchmarks and validate the strong generalizability of our model to significantly enhance performanc
    
[^8]: 自主驾驶的世界模型：一项初步调查

    World Models for Autonomous Driving: An Initial Survey

    [https://arxiv.org/abs/2403.02622](https://arxiv.org/abs/2403.02622)

    世界模型在自主驾驶领域的重要性和作用，是通过准确预测未来事件和评估其影响来帮助决策过程，从而推动自主驾驶技术发展的革命性方法。

    

    在自主驾驶领域不断发展的背景下，准确预测未来事件并评估其影响对于安全和效率至关重要，关键地帮助决策过程。世界模型已经成为一种革命性方法，使自主驾驶系统能够综合和解释大量传感器数据，从而预测潜在的未来情景并弥补信息缺口。本文对自主驾驶中世界模型的当前状态和未来发展进行了初步审查，涵盖了其理论基础、实际应用以及旨在克服现有限制的正在进行的研究工作。强调了世界模型在推动自主驾驶技术发展中的重要作用，本调查旨在成为研究社区的基础参考，便于快速获得和应用。

    arXiv:2403.02622v1 Announce Type: cross  Abstract: In the rapidly evolving landscape of autonomous driving, the capability to accurately predict future events and assess their implications is paramount for both safety and efficiency, critically aiding the decision-making process. World models have emerged as a transformative approach, enabling autonomous driving systems to synthesize and interpret vast amounts of sensor data, thereby predicting potential future scenarios and compensating for information gaps. This paper provides an initial review of the current state and prospective advancements of world models in autonomous driving, spanning their theoretical underpinnings, practical applications, and the ongoing research efforts aimed at overcoming existing limitations. Highlighting the significant role of world models in advancing autonomous driving technologies, this survey aspires to serve as a foundational reference for the research community, facilitating swift access to and com
    
[^9]: 通过可微分编程实现带不确定性量化的联合参数和参数化推断

    Joint Parameter and Parameterization Inference with Uncertainty Quantification through Differentiable Programming

    [https://arxiv.org/abs/2403.02215](https://arxiv.org/abs/2403.02215)

    通过可微分编程，本研究提出了一种新框架，能够联合估计和量化物理参数以及机器学习参数化，实现了高维参数空间内的在线训练和有效贝叶斯推断。

    

    精确地表示数值模拟中未知和亚网格物理过程的参数化(或闭合)并对其不确定性进行量化对于解析许多问题的粗粒化偏微分方程非常关键，这些问题包括天气和气候预测以及湍流模拟。最近的进展看到机器学习（ML）越来越多地应用于对这些亚网格过程建模，导致了通过与数值求解器集成开发混合物理-ML模型。在这项工作中，我们介绍了一种通过联合估计和不确定性量化物理参数和机器学习参数化的新框架，利用了可微分编程。通过在线训练和高维参数空间内的有效贝叶斯推断实现，这种方法借助可微分编程的能力实现。

    arXiv:2403.02215v1 Announce Type: new  Abstract: Accurate representations of unknown and sub-grid physical processes through parameterizations (or closure) in numerical simulations with quantified uncertainty are critical for resolving the coarse-grained partial differential equations that govern many problems ranging from weather and climate prediction to turbulence simulations. Recent advances have seen machine learning (ML) increasingly applied to model these subgrid processes, resulting in the development of hybrid physics-ML models through the integration with numerical solvers. In this work, we introduce a novel framework for the joint estimation and uncertainty quantification of physical parameters and machine learning parameterizations in tandem, leveraging differentiable programming. Achieved through online training and efficient Bayesian inference within a high-dimensional parameter space, this approach is enabled by the capabilities of differentiable programming. This proof 
    
[^10]: 可解释的量子点器件测量分类技术

    Explainable Classification Techniques for Quantum Dot Device Measurements

    [https://arxiv.org/abs/2402.13699](https://arxiv.org/abs/2402.13699)

    提出了一种基于合成数据的的可解释特征技术，利用可解释性提升机（EBMs）实现了在量子点调谐中较高的可解释性和准确性。

    

    在物理科学中，对图像数据的稳健特征表示需求增加：图像采集，在广义上指二维数据，现在在许多领域广泛应用，包括我们在此考虑的量子信息科学。虽然在这些情况下广泛使用传统图像特征，但它们的使用正在迅速被神经网络技术所取代，后者往往以牺牲可解释性为代价换取高准确性。为了弥合这种权衡，我们提出了一种基于合成数据的技术，可以产生可解释的特征。我们利用可解释性提升机（EBMs）展示，这种方法提供了卓越的可解释性，并且不会降低准确性。具体而言，我们展示了在量子点调谐的背景下，这种技术带来了实质性的益处，当前发展阶段需要人类干预。

    arXiv:2402.13699v1 Announce Type: cross  Abstract: In the physical sciences, there is an increased need for robust feature representations of image data: image acquisition, in the generalized sense of two-dimensional data, is now widespread across a large number of fields, including quantum information science, which we consider here. While traditional image features are widely utilized in such cases, their use is rapidly being supplanted by Neural Network-based techniques that often sacrifice explainability in exchange for high accuracy. To ameliorate this trade-off, we propose a synthetic data-based technique that results in explainable features. We show, using Explainable Boosting Machines (EBMs), that this method offers superior explainability without sacrificing accuracy. Specifically, we show that there is a meaningful benefit to this technique in the context of quantum dot tuning, where human intervention is necessary at the current stage of development.
    
[^11]: 思维链激发变压器解决固有串行问题的能力

    Chain of Thought Empowers Transformers to Solve Inherently Serial Problems

    [https://arxiv.org/abs/2402.12875](https://arxiv.org/abs/2402.12875)

    思维链赋予变压器模型执行固有串行计算的能力，提高了变压器在算术和符号推理任务中的准确性。

    

    指导模型生成一系列中间步骤，即思维链（CoT），是提高大型语言模型（LLMs）在算术和符号推理任务上准确性的高效方法。然而，CoT背后的机制仍不清楚。这项工作通过表达性的视角提供了对解码器专用变压器的CoT能力的理论理解。在概念上，CoT赋予模型执行固有串行计算的能力，而这种能力在变压器中缺乏，特别是当深度较低时。先前的作品已经表明，在没有CoT的情况下，具有有限精度$\mathsf{poly}(n)$嵌入尺寸的恒定深度变压器只能在$\mathsf{TC}^0$中解决问题。我们首先展示了具有常数位精度的恒定深度变压器的更紧密的表达性上界，它只能解决$\mathsf{AC}^0$中的问题。

    arXiv:2402.12875v1 Announce Type: new  Abstract: Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have shown that constant-depth transformers with finite precision $\mathsf{poly}(n)$ embedding size can only solve problems in $\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\mathsf{AC}^0$, a 
    
[^12]: 改变了什么？将表征干预转化为自然语言

    What Changed? Converting Representational Interventions to Natural Language

    [https://arxiv.org/abs/2402.11355](https://arxiv.org/abs/2402.11355)

    将表征空间的反事实转化为自然语言，以分析和解释模型干预所引起的语言变化，并减轻分类中的偏见。

    

    针对语言模型（LMs）表征空间的干预方法已经被证明是影响模型行为的有效手段。这些方法被用来消除或改变模型表示中的人口统计信息（如性别）的编码，创建一个反事实的表示。然而，由于干预操作在表示空间内，准确理解它修改了哪些特征是一个挑战。我们展示了表征空间的反事实可以转化为自然语言的反事实。我们证明了这种方法使我们能够分析对应于给定表示空间干预的语言变化，并解释用于编码特定概念的特征。此外，由此产生的反事实可以用于减轻分类中的偏见。

    arXiv:2402.11355v1 Announce Type: new  Abstract: Interventions targeting the representation space of language models (LMs) have emerged as effective means to influence model behavior. These methods are employed, for example, to eliminate or alter the encoding of demographic information such as gender within the model's representations, creating a counterfactual representation. However, since the intervention operates within the representation space, understanding precisely which features it modifies poses a challenge. We show that representation-space counterfactuals can be converted into natural language counterfactuals. We demonstrate that this approach enables us to analyze the linguistic alterations corresponding to a given representation-space intervention and to interpret the features utilized for encoding a specific concept. Moreover, the resulting counterfactuals can be used to mitigate bias in classification.
    
[^13]: CHEMREASONER：使用量子化学反馈在大型语言模型的知识空间中进行启发式搜索

    CHEMREASONER: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback

    [https://arxiv.org/abs/2402.10980](https://arxiv.org/abs/2402.10980)

    通过将大型语言模型推理与量子化学反馈相结合，我们引入了一个AI引导的计算筛选框架，将催化剂发现形式化为一个不确定环境，从而实现高效催化剂的积极搜索

    

    arXiv:2402.10980v1 类型公告：跨领域 摘要：发现新的催化剂对于设计新的更高效的化学过程至关重要，以实现向可持续未来的过渡。我们引入了一种人工智能引导的计算筛选框架，将语言推理与基于量子化学的三维原子表示的反馈统一起来。我们的方法将催化剂发现构建为一个不确定环境，其中一个代理通过大型语言模型（LLM）推导的假设与基于原子图神经网络（GNN）的反馈的迭代组合，积极搜索高效催化剂。在中间搜索步骤确定的催化剂经过基于空间定向、反应途径和稳定性的结构评估。基于吸附能和势垒的评分函数引导在LLM的知识空间中向能量有利、高效的催化剂探索。我们引入了可以自动规划的方法

    arXiv:2402.10980v1 Announce Type: cross  Abstract: The discovery of new catalysts is essential for the design of new and more efficient chemical processes in order to transition to a sustainable future. We introduce an AI-guided computational screening framework unifying linguistic reasoning with quantum-chemistry based feedback from 3D atomistic representations. Our approach formulates catalyst discovery as an uncertain environment where an agent actively searches for highly effective catalysts via the iterative combination of large language model (LLM)-derived hypotheses and atomistic graph neural network (GNN)-derived feedback. Identified catalysts in intermediate search steps undergo structural evaluation based on spatial orientation, reaction pathways, and stability. Scoring functions based on adsorption energies and barriers steer the exploration in the LLM's knowledge space toward energetically favorable, high-efficiency catalysts. We introduce planning methods that automaticall
    
[^14]: 生成人工智能与过程系统工程：下一个前沿

    Generative AI and Process Systems Engineering: The Next Frontier

    [https://arxiv.org/abs/2402.10977](https://arxiv.org/abs/2402.10977)

    新兴生成人工智能模型（如基础模型）在过程系统工程中的应用，提供了多功能的适应性，对合成与设计、优化与集成以及过程监控与控制等关键领域具有重要影响。

    

    本文探讨了新兴生成人工智能（GenAI）模型，如大型语言模型（LLMs），如何增强过程系统工程（PSE）中的解决方法。这些最前沿的GenAI模型，特别是基础模型（FMs），它们在广泛的通用数据集上预训练，为涉及查询响应、图像生成和复杂决策等广泛任务提供了多功能的适应性。鉴于PSE的进展与计算和系统技术的发展之间密切关系，探索GenAI和PSE之间的协同作用是至关重要的。我们从经典和新兴的GenAI模型，包括FMs的简要概述开始讨论，然后深入探讨它们在关键PSE领域内的应用：合成与设计、优化与集成，以及过程监控与控制。在每个领域中，我们探讨了GenAI模型如何可以促进

    arXiv:2402.10977v1 Announce Type: new  Abstract: This article explores how emerging generative artificial intelligence (GenAI) models, such as large language models (LLMs), can enhance solution methodologies within process systems engineering (PSE). These cutting-edge GenAI models, particularly foundation models (FMs), which are pre-trained on extensive, general-purpose datasets, offer versatile adaptability for a broad range of tasks, including responding to queries, image generation, and complex decision-making. Given the close relationship between advancements in PSE and developments in computing and systems technologies, exploring the synergy between GenAI and PSE is essential. We begin our discussion with a compact overview of both classic and emerging GenAI models, including FMs, and then dive into their applications within key PSE domains: synthesis and design, optimization and integration, and process monitoring and control. In each domain, we explore how GenAI models could pot
    
[^15]: 使用事后置信度估计的选择性预测在语义分割中的性能及其在分布偏移下的表现

    Selective Prediction for Semantic Segmentation using Post-Hoc Confidence Estimation and Its Performance under Distribution Shift

    [https://arxiv.org/abs/2402.10665](https://arxiv.org/abs/2402.10665)

    本文研究了在低资源环境中语义分割的选择性预测，提出了一种针对语义分割量身定制的新型图像级置信度测量，并通过实验证明了其有效性

    

    语义分割在各种计算机视觉应用中扮演着重要角色，然而其有效性常常受到高质量标记数据的缺乏所限。为了解决这一挑战，一个常见策略是利用在不同种群上训练的模型，如公开可用的数据集。然而，这种方法导致了分布偏移问题，在兴趣种群上表现出降低的性能。在模型错误可能带来重大后果的情况下，选择性预测方法提供了一种减轻风险、减少对专家监督依赖的手段。本文研究了在资源匮乏环境下语义分割的选择性预测，着重于应用于在分布偏移下运行的预训练模型的事后置信度估计器。我们提出了一种针对语义分割量身定制的新型图像级置信度测量，并通过实验证明了其有效性。

    arXiv:2402.10665v1 Announce Type: new  Abstract: Semantic segmentation plays a crucial role in various computer vision applications, yet its efficacy is often hindered by the lack of high-quality labeled data. To address this challenge, a common strategy is to leverage models trained on data from different populations, such as publicly available datasets. This approach, however, leads to the distribution shift problem, presenting a reduced performance on the population of interest. In scenarios where model errors can have significant consequences, selective prediction methods offer a means to mitigate risks and reduce reliance on expert supervision. This paper investigates selective prediction for semantic segmentation in low-resource settings, thus focusing on post-hoc confidence estimators applied to pre-trained models operating under distribution shift. We propose a novel image-level confidence measure tailored for semantic segmentation and demonstrate its effectiveness through expe
    
[^16]: 任意精度LLM：多个不同大小LLM的低成本部署

    Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs

    [https://arxiv.org/abs/2402.10517](https://arxiv.org/abs/2402.10517)

    任意精度LLM引入了一种轻量级方法，通过将不同大小LLMs量化为不同位宽（如3、4、...，n位）并叠加到内存中，显着降低了部署多个不同大小LLMs的高成本

    

    最近，人们对压缩大型语言模型（LLMs）进行了相当多的努力，这些LLMs在各种应用中展示了突破性的能力，但由于其庞大的体积而导致部署成本高昂。与此同时，尽管多个不同大小的LLMs部署的成本在实际意义上很重要，但却受到的关注较少。因此，本文引入了“任意精度LLM”，将任意精度DNN的概念扩展到LLMs。解决了任意精度LLM中的挑战，我们提出了一种轻量级的LLMs任意精度量化方法，利用后训练量化框架，并开发了一个专门的软件引擎来实现其有效的服务。结果，我们的解决方案通过将以不同位宽（如3、4、…，n位）量化的LLMs叠加到内存足印中，显着降低了部署多个不同大小的LLMs的高成本。

    arXiv:2402.10517v1 Announce Type: new  Abstract: Recently, considerable efforts have been directed towards compressing Large Language Models (LLMs), which showcase groundbreaking capabilities across diverse applications but entail significant deployment costs due to their large sizes. Meanwhile, much less attention has been given to mitigating the costs associated with deploying multiple LLMs of varying sizes despite its practical significance. Thus, this paper introduces \emph{any-precision LLM}, extending the concept of any-precision DNN to LLMs. Addressing challenges in any-precision LLM, we propose a lightweight method for any-precision quantization of LLMs, leveraging a post-training quantization framework, and develop a specialized software engine for its efficient serving. As a result, our solution significantly reduces the high costs of deploying multiple, different-sized LLMs by overlaying LLMs quantized to varying bit-widths, such as 3, 4, ..., $n$ bits, into a memory footpri
    
[^17]: GraphCBAL: 通过强化学习对图神经网络进行类平衡主动学习

    GraphCBAL: Class-Balanced Active Learning for Graph Neural Networks via Reinforcement Learning

    [https://arxiv.org/abs/2402.10074](https://arxiv.org/abs/2402.10074)

    本文提出了一种通过强化学习对图神经网络进行类平衡主动学习的框架GraphCBAL，该框架能够学习一种最佳策略，选择类平衡和信息丰富的节点进行注释，以最大化GNNs性能。

    

    最近，图神经网络（GNNs）已经取得了显著的成功。GNNs的主动学习旨在从未标记的数据中查询有价值的样本进行注释，以最大限度地降低成本并提高GNNs的性能。然而，对于GNNs中的强化主动学习，现有的大多数方法可能导致高度不平衡的类分布，尤其是在高度倾斜的类别场景下。这进一步对分类性能产生负面影响。为了解决这个问题，本文提出了一种新颖的增强类平衡主动学习框架GraphCBAL，用于GNNs。它学习一种最佳策略，以获取类平衡和信息丰富的节点进行注释，从而最大化选择的标记节点训练的GNNs的性能。GraphCBAL设计了类平衡感知状态和奖励函数，实现模型性能和类平衡之间的折衷。我们进一步改进了GraphCBAL，得到GraphCBAL++。

    arXiv:2402.10074v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have recently demonstrated significant success. Active learning for GNNs aims to query the valuable samples from the unlabeled data for annotation to maximize the GNNs' performance at a low cost. However, most existing methods for reinforced active learning in GNNs may lead to a highly imbalanced class distribution, especially in highly skewed class scenarios. This further adversely affects the classification performance. To tackle this issue, in this paper, we propose a novel reinforced class-balanced active learning framework for GNNs, namely, GraphCBAL. It learns an optimal policy to acquire class-balanced and informative nodes for annotation, maximizing the performance of GNNs trained with selected labeled nodes. GraphCBAL designs class-balance-aware states, as well as a reward function that achieves trade-off between model performance and class balance. We further upgrade GraphCBAL to GraphCBAL++ by intr
    
[^18]: 近确定性回归中的错误规范化不确定性

    Misspecification uncertainties in near-deterministic regression

    [https://arxiv.org/abs/2402.01810](https://arxiv.org/abs/2402.01810)

    该论文研究了近确定性回归中错误规范化的不确定性问题，并提出了一种组合模型，以准确预测和控制参数不确定性。

    

    期望损失是模型泛化误差的上界，可用于学习的鲁棒PAC-Bayes边界。然而，损失最小化被认为忽略了错误规范化，即模型不能完全复制观测结果。这导致大数据或欠参数化极限下对参数不确定性的显著低估。我们分析近确定性、错误规范化和欠参数化替代模型的泛化误差，这是科学和工程中广泛相关的一个领域。我们证明后验分布必须覆盖每个训练点，以避免发散的泛化误差，并导出一个符合这个约束的组合模型。对于线性模型，这种高效的方法产生的额外开销最小。这种高效方法在模型问题上进行了演示，然后应用于原子尺度机器学习中的高维数据集。

    The expected loss is an upper bound to the model generalization error which admits robust PAC-Bayes bounds for learning. However, loss minimization is known to ignore misspecification, where models cannot exactly reproduce observations. This leads to significant underestimates of parameter uncertainties in the large data, or underparameterized, limit. We analyze the generalization error of near-deterministic, misspecified and underparametrized surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and derive an ensemble {ansatz} that respects this constraint, which for linear models incurs minimal overhead. The efficient approach is demonstrated on model problems before application to high dimensional datasets in atomistic machine learning. Parameter uncertainties from misspecification survive in the underparametrized limit, giving accurate prediction and boundin
    
[^19]: 大规模语言模型用于时间序列：一项调研

    Large Language Models for Time Series: A Survey

    [https://arxiv.org/abs/2402.01801](https://arxiv.org/abs/2402.01801)

    本调研论文深入探讨了大规模语言模型（LLM）在时间序列分析中的应用方法。通过解决LLM与数值型时间序列数据之间的差异挑战，揭示了LLM在时间序列领域的潜力，并提出了直接提示、量化、对齐、利用视觉方式和结合工具等方法。此外，还提供了对应用领域、评估方法和未来研究方向的讨论。

    

    大规模语言模型（LLM）在自然语言处理和计算机视觉等领域得到了广泛应用。LLM不仅仅局限于文本、图像和图形，还具有对时间序列数据进行分析的重要潜力，可以在气候、物联网、医疗、交通、音频和金融等领域受益。本调研论文对利用LLM进行时间序列分析的各种方法进行了深入探讨和详细分类。我们解决了LLM原始文本数据训练与数值型时间序列数据之间的差异挑战，并探索了将LLM的知识转移和提取到数值时间序列分析的策略。我们详细介绍了各种方法，包括（1）直接提示LLM，（2）时间序列量化，（3）对齐技术，（4）利用视觉方式作为桥接机制，和（5）结合LLM与工具。此外，本调研还提供了一系列涉及应用领域、评估方法和未来研究方向的讨论。

    Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) alignment techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey off
    
[^20]: 超越行为主义的表征伤害：度量和减轻计划

    Beyond Behaviorist Representational Harms: A Plan for Measurement and Mitigation

    [https://arxiv.org/abs/2402.01705](https://arxiv.org/abs/2402.01705)

    本研究超越行为主义的定义范围，提出了一种度量和减轻表征性伤害的框架，强调了大型语言模型在实施这些伤害时的脆弱性，并提出了减轻措施的建议。

    

    算法伤害通常被分为配置性或表征性。本研究专门针对后者，重点在于对当前表征性伤害定义的审查，以确定其中包含什么和不包含什么。这个分析促使我们扩展超越行为主义的定义范围，包括对认知和情感状态的伤害。本文概述了度量的高级要求：确定实施这种方法所需的专业知识，并通过案例研究进行说明。我们的工作凸显了大型语言模型在实施表征性伤害时的独特脆弱性，特别是当这些伤害未被度量和减轻时。该研究通过提出减轻措施并界定何时使用它们来结束。这项研究的总体目标是建立一个框架，扩大表征性伤害的定义，并将公平研究的见解转化为实际的度量方法。

    Algorithmic harms are commonly categorized as either allocative or representational. This study specifically addresses the latter, focusing on an examination of current definitions of representational harms to discern what is included and what is not. This analysis motivates our expansion beyond behavioral definitions to encompass harms to cognitive and affective states. The paper outlines high-level requirements for measurement: identifying the necessary expertise to implement this approach and illustrating it through a case study. Our work highlights the unique vulnerabilities of large language models to perpetrating representational harms, particularly when these harms go unmeasured and unmitigated. The work concludes by presenting proposed mitigations and delineating when to employ them. The overarching aim of this research is to establish a framework for broadening the definition of representational harms and to translate insights from fairness research into practical measurement 
    
[^21]: 创意与机器学习：一项调查

    Creativity and Machine Learning: A Survey

    [https://arxiv.org/abs/2104.02726](https://arxiv.org/abs/2104.02726)

    本调查论文总结了机器学习和创造力领域的历史、现状，以及关键的贡献和研究挑战。

    

    在机器学习和创意领域，越来越多的人开始感兴趣。本调查综述了计算创造力理论的历史和现状、关键的机器学习技术（包括生成式深度学习）以及相应的自动评估方法。在对该领域的关键贡献进行批判性讨论之后，我们概述了当前研究面临的挑战和这一领域的新兴机遇。

    arXiv:2104.02726v4 Announce Type: replace  Abstract: There is a growing interest in the area of machine learning and creativity. This survey presents an overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods. After presenting a critical discussion of the key contributions in this area, we outline the current research challenges and emerging opportunities in this field.
    
[^22]: CascadedGaze: 图像恢复中的全局上下文提取的高效方法

    CascadedGaze: Efficiency in Global Context Extraction for Image Restoration. (arXiv:2401.15235v1 [eess.IV])

    [http://arxiv.org/abs/2401.15235](http://arxiv.org/abs/2401.15235)

    本文提出了一种名为CascadedGaze的网络架构，使用了一种新颖而高效的全局上下文提取方法，以解决图像恢复中全局信息的问题。通过在卷积层之间引入小的卷积核，该方法可以学习到全局的依赖关系，而无需使用自注意力机制。实验结果表明，该方法在多种图像去噪任务上优于其他先进方法。

    

    传统的图像恢复任务依赖于卷积神经网络。然而，由于卷积运算符的局部性质，它们很难捕捉到全局信息。Transformer中的注意力机制的优势在于解决了这个问题，但却需要大量的计算资源。最近的一些图像恢复研究集中在通过变种Transformer解决性能和计算成本之间的平衡挑战。在本文中，我们提出了CascadedGaze网络（CGNet），它是一种编码器-解码器架构，采用了全局上下文提取器（GCE），一种新颖且高效的图像恢复全局信息的方法。GCE模块通过在卷积层之间使用小的卷积核来学习全局依赖关系，而无需自注意力机制。广泛的实验结果表明，我们的方法在去噪基准数据集上（包括真实图像去噪和）的性能优于许多最先进的方法。

    Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our approach outperforms a range of state-of-the-art methods on denoising benchmark datasets including both real image denoising and 
    
[^23]: 使用通用完全等变量加速材料属性预测

    Accelerating Material Property Prediction using Generically Complete Isometry Invariants. (arXiv:2401.15089v1 [cs.LG])

    [http://arxiv.org/abs/2401.15089](http://arxiv.org/abs/2401.15089)

    本研究提出了一种使用通用完全等变量加速材料属性预测的方法，通过采用点距离分布(PDD)作为学习算法的表示，并开发了一个修改的自注意机制的变压器模型来利用PDD。

    

    最近几年，使用机器学习进行材料或晶体属性预测变得流行起来，因为它提供了对传统模拟方法的计算上高效的替代。对于这些算法的关键第一步是周期性晶体的表示。虽然类似的分子和蛋白质等物体有有限数量的原子，并且它们的表示可以基于有限点云进行解释，但是周期性晶体的尺寸是无限的，所以它们的表示更具挑战性。在本研究中，我们采用了点距离分布(PDD)，这是一种连续且通用的完全等变量，用作我们学习算法的表示。尽管PDD在区分周期性点集的等变性上非常有效，但其没有考虑基础材料的组成。我们开发了一个具有修改的自注意机制的变压器模型，可以利用PDD和...

    Material or crystal property prediction using machine learning has grown popular in recent years as it provides a computationally efficient replacement to classical simulation methods. A crucial first step for any of these algorithms is the representation used for a periodic crystal. While similar objects like molecules and proteins have a finite number of atoms and their representation can be built based upon a finite point cloud interpretation, periodic crystals are unbounded in size, making their representation more challenging. In the present work, we adapt the Pointwise Distance Distribution (PDD), a continuous and generically complete isometry invariant for periodic point sets, as a representation for our learning algorithm. While the PDD is effective in distinguishing periodic point sets up to isometry, there is no consideration for the composition of the underlying material. We develop a transformer model with a modified self-attention mechanism that can utilize the PDD and inc
    
[^24]: 借助多条件扩散引导的逆分子设计

    Inverse Molecular Design with Multi-Conditional Diffusion Guidance. (arXiv:2401.13858v1 [cs.LG])

    [http://arxiv.org/abs/2401.13858](http://arxiv.org/abs/2401.13858)

    借助多条件扩散引导的逆分子设计模型在材料和药物发现方面具有巨大潜力。通过引入Transformer-based去噪模型和图依赖的扩散过程，该模型能够在多个条件约束下准确地生成聚合物和小分子。

    

    借助扩散模型进行逆分子设计在材料和药物发现方面具有巨大潜力。虽然在无条件分子生成方面取得了成功，但将合成评分和气体渗透性等多个属性作为条件约束集成到扩散模型中仍未被探索。我们引入了多条件扩散引导。所提出的基于Transformer的去噪模型具有一个条件编码器，该编码器学习了数值和分类条件的表示。组成结构编码器-解码器的去噪模型在条件表示下进行去噪训练。扩散过程变得依赖于图来准确估计分子中与图相关的噪声，而不像以前的模型仅关注原子或键的边缘分布。我们广泛验证了我们的模型在多条件聚合物和小分子生成方面的优越性。结果显示我们在分布度量方面的优势。

    Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We introduce multi-conditional diffusion guidance. The proposed Transformer-based denoising model has a condition encoder that learns the representations of numerical and categorical conditions. The denoising model, consisting of a structure encoder-decoder, is trained for denoising under the representation of conditions. The diffusion process becomes graph-dependent to accurately estimate graph-related noise in molecules, unlike the previous models that focus solely on the marginal distributions of atoms or bonds. We extensively validate our model for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution
    
[^25]: Link Me Baby One More Time: 在 Spotify 上的社交音乐发现

    Link Me Baby One More Time: Social Music Discovery on Spotify. (arXiv:2401.08818v1 [cs.SI])

    [http://arxiv.org/abs/2401.08818](http://arxiv.org/abs/2401.08818)

    本研究探讨了在社交音乐推荐中影响音乐互动的社交和环境因素。研究发现，接收者与发送者音乐品味相似、分享的音轨适合接收者的品味、接收者与发送者具有更强和更亲密的联系以及分享的艺术家在接收者的关系中受欢迎，这些因素都会增加接收者与新艺术家的互动。

    

    我们探讨影响个人之间音乐推荐和发现结果的社交和环境因素。具体来说，我们使用 Spotify 的数据来研究用户之间发送链接导致接收者与分享的艺术家的音乐互动。我们考虑了几个可能影响这一过程的因素，如发送者与接收者的关系强度，用户在 Spotify 社交网络中的角色，他们的音乐社交凝聚力，以及新艺术家与接收者的品味相似程度。我们发现，当接收者与发送者的音乐品味相似且分享的音轨适合他们的品味时，他们更有可能与新艺术家互动；当他们与发送者有更强和更亲密的联系时，也更有可能互动；以及当分享的艺术家在接收者的关系中受欢迎时，也更有可能互动。最后，我们利用这些发现构建了一个随机森林分类器，用于预测分享的音乐轨道是否会导致接收者的互动。

    We explore the social and contextual factors that influence the outcome of person-to-person music recommendations and discovery. Specifically, we use data from Spotify to investigate how a link sent from one user to another results in the receiver engaging with the music of the shared artist. We consider several factors that may influence this process, such as the strength of the sender-receiver relationship, the user's role in the Spotify social network, their music social cohesion, and how similar the new artist is to the receiver's taste. We find that the receiver of a link is more likely to engage with a new artist when (1) they have similar music taste to the sender and the shared track is a good fit for their taste, (2) they have a stronger and more intimate tie with the sender, and (3) the shared artist is popular with the receiver's connections. Finally, we use these findings to build a Random Forest classifier to predict whether a shared music track will result in the receiver
    
[^26]: 考虑车辆重量的风险预测自动驾驶策略，基于分层深度强化学习

    Risk-anticipatory autonomous driving strategies considering vehicles' weights, based on hierarchical deep reinforcement learning. (arXiv:2401.08661v1 [cs.RO])

    [http://arxiv.org/abs/2401.08661](http://arxiv.org/abs/2401.08661)

    本研究基于分层深度强化学习开发了一种风险预测自动驾驶策略，考虑车辆的重量，并将其纳入自动驾驶决策中，以降低潜在风险和事故后果。

    

    自动驾驶车辆具有减少人为错误导致的事故和降低道路交通风险的潜力。然而，由于重型车辆的性质，其碰撞会导致更严重的事故，因此在自动驾驶的背景下，需要考虑车辆的重量来制定降低潜在风险和后果的驾驶策略。本研究基于风险预测开发了一种自动驾驶策略，考虑周围车辆的重量，并使用分层深度强化学习。通过风险场理论提出了一个综合周围车辆重量的风险指标，并将其纳入自动驾驶决策中。设计了一个混合行动空间，允许左车道变道、右车道变道和跟车行为，使自动驾驶车辆能够在可能的情况下更自由、更真实地行动。为了解决上述混合决策问题，采用了分层近端策略优化（HPPO）算法。

    Autonomous vehicles (AVs) have the potential to prevent accidents caused by drivers' error and reduce road traffic risks. Due to the nature of heavy vehicles, whose collisions cause more serious crashes, the weights of vehicles need to be considered when making driving strategies aimed at reducing the potential risks and their consequences in the context of autonomous driving. This study develops an autonomous driving strategy based on risk anticipation, considering the weights of surrounding vehicles and using hierarchical deep reinforcement learning. A risk indicator integrating surrounding vehicles' weights, based on the risk field theory, is proposed and incorporated into autonomous driving decisions. A hybrid action space is designed to allow for left lane changes, right lane changes and car-following, which enables AVs to act more freely and realistically whenever possible. To solve the above hybrid decision-making problem, a hierarchical proximal policy optimization (HPPO) algor
    
[^27]: 大型语言模型有限标签监督微调的实验设计框架

    An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models. (arXiv:2401.06692v1 [cs.CL])

    [http://arxiv.org/abs/2401.06692](http://arxiv.org/abs/2401.06692)

    该论文提出了一个实验设计框架来减少大型语言模型有限标签监督微调的注释成本，并解决了主动学习的计算瓶颈问题。

    

    在现代大型语言模型中，指导数据集上的有限标签监督微调（SFT）在实现了令人惊叹的零射击泛化能力方面发挥了至关重要的作用。然而，为了为指令产生高质量的回答所需的注释工作正在变得难以承受，特别是随着指令数据集所涵盖的任务数量的增加。主动学习可以有效地从未标记的样本池中确定有用的子集进行注释，但其高计算成本仍然是其在LLMs环境中广泛应用的障碍。为了减少SFT的注释成本并规避主动学习的计算瓶颈，我们提出使用实验设计。实验设计技术选择最具信息量的样本进行标注，通常最大化某种不确定性和/或多样性的概念。在我们的工作中，我们实施了一个评估多种现有和新颖的实验设计方法的框架。

    Supervised finetuning (SFT) on instruction datasets has played a crucial role in achieving the remarkable zero-shot generalization capabilities observed in modern large language models (LLMs). However, the annotation efforts required to produce high quality responses for instructions are becoming prohibitively expensive, especially as the number of tasks spanned by instruction datasets continues to increase. Active learning is effective in identifying useful subsets of samples to annotate from an unlabeled pool, but its high computational cost remains a barrier to its widespread applicability in the context of LLMs. To mitigate the annotation cost of SFT and circumvent the computational bottlenecks of active learning, we propose using experimental design. Experimental design techniques select the most informative samples to label, and typically maximize some notion of uncertainty and/or diversity. In our work, we implement a framework that evaluates several existing and novel experimen
    
[^28]: 可扩展的子二次时间网络重建

    Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])

    [http://arxiv.org/abs/2401.01404](http://arxiv.org/abs/2401.01404)

    这篇论文提出了一个可扩展的网络重建算法，能够在次二次时间内实现结果，通过随机的二阶邻居搜索产生最佳的边候选。

    

    网络重建是指在只有关于条件偶联的观测数据，例如时间序列或图模型的独立样本的情况下，确定N个节点之间未观测到的成对耦合。针对这个问题提出的算法的可扩展性的主要障碍是似乎无法避免的二次复杂度O(N^2)，即要考虑每种可能的成对耦合至少一次，尽管大多数感兴趣的网络都是稀疏的，非零耦合的数量只有O(N)。在这里，我们提出了一个适用于广泛重建问题的通用算法，其在子二次时间内实现结果，其数据相关复杂度宽松上界为O(N^(3/2)logN)，但具有更典型的对数线性复杂度O(Nlog^2 N)。我们的算法依赖于一个随机的二阶邻居搜索，产生了最佳的边候选。

    Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
    
[^29]: Transformers作为形式语言识别器：关于表达能力的调查

    Transformers as Recognizers of Formal Languages: A Survey on Expressivity. (arXiv:2311.00208v1 [cs.LG])

    [http://arxiv.org/abs/2311.00208](http://arxiv.org/abs/2311.00208)

    本文对transformers在形式语言识别领域的相关研究进行了全面调查，为理解其表达能力提供了一个统一的框架。

    

    随着transformers在自然语言处理中的重要性日益突出，一些研究人员开始从理论上探讨它们能否解决问题，将问题视为形式语言。探索这类问题将有助于比较transformers与其他模型以及不同变种之间的差异，适用于各种任务。近年来，在这个子领域的工作取得了相当大的进展。本文对这方面的工作进行了全面调查，记录了不同结果背后的各种假设，并提供了一个统一的框架，以协调看似相互矛盾的研究结果。

    As transformers have gained prominence in natural language processing, some researchers have investigated theoretically what problems they can and cannot solve, by treating problems as formal languages. Exploring questions such as this will help to compare transformers with other models, and transformer variants with one another, for various tasks. Work in this subarea has made considerable progress in recent years. Here, we undertake a comprehensive survey of this work, documenting the diverse assumptions that underlie different results and providing a unified framework for harmonizing seemingly contradictory findings.
    
[^30]: ZzzGPT: 提高睡眠质量的交互式GPT方法

    ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality. (arXiv:2310.16242v1 [cs.LG])

    [http://arxiv.org/abs/2310.16242](http://arxiv.org/abs/2310.16242)

    本文介绍了一种名为ZzzGPT的交互式GPT方法，旨在提高睡眠质量。通过利用大型语言模型进行预测和反馈，该方法融合了先进的机器学习和用户导向设计，以提供准确和有价值的结果。

    

    在当今世界中，睡眠质量对总体健康至关重要。虽然可穿戴传感器提供实时监测，但它们常常缺乏有针对性的见解，导致用户放弃使用。本文研究了技术在理解睡眠模式方面的作用。我们引入了一个两阶段的框架，利用大型语言模型 (LLMs)，旨在提供准确的睡眠预测和有价值的反馈。利用GLOBEM数据集和LLMs的合成数据，我们展示了与XGBoost等模型相比的增强结果。我们的方法将先进的机器学习与以用户为中心的设计相结合，将科学准确性与实用性融合在一起。

    In today's world, sleep quality is pivotal for overall well-being. While wearable sensors offer real-time monitoring, they often lack actionable insights, leading to user abandonment. This paper delves into the role of technology in understanding sleep patterns. We introduce a two-stage framework, utilizing Large Language Models (LLMs), aiming to provide accurate sleep predictions with actionable feedback. Leveraging the GLOBEM dataset and synthetic data from LLMs, we highlight enhanced results with models like XGBoost. Our approach merges advanced machine learning with user-centric design, blending scientific accuracy with practicality.
    
[^31]: 基于联邦学习的无线世界中的基础模型的作用

    The Role of Federated Learning in a Wireless World with Foundation Models. (arXiv:2310.04003v1 [cs.NI])

    [http://arxiv.org/abs/2310.04003](http://arxiv.org/abs/2310.04003)

    基于联邦学习的无线世界中，基础模型（FMs）为生成式AI应用提供支持，并且可以通过分散的数据和计算资源来提高联邦学习（FL）的性能，但是FMs对资源需求较高可能给FL-enabled的无线网络带来挑战。

    

    基础模型（FMs）是通用人工智能（AI）模型，最近为多个全新的生成式AI应用提供了支持。FMs的快速发展为下一代无线网络的愿景提供了重要的背景，其中联邦学习（FL）是分布式网络智能的关键驱动因素。目前，FMs和FL之间的相互作用仍处于初级阶段。FMs可以提高FL的性能，而FL也可以利用分散的数据和计算资源来辅助训练FMs。然而，FMs对计算资源、存储和通信开销的要求异常高，这给FL-enabled无线网络带来重要挑战。在本文中，我们探讨FMs在无线网络上是否适用于FL，包括对研究挑战和机遇的广泛概述。特别是，我们讨论了多份FL和FL资源的需求的联合训练等关键问题。

    Foundation models (FMs) are general-purpose artificial intelligence (AI) models that have recently enabled multiple brand-new generative AI applications. The rapid advances in FMs serve as an important contextual backdrop for the vision of next-generation wireless networks, where federated learning (FL) is a key enabler of distributed network intelligence. Currently, the exploration of the interplay between FMs and FL is still in its nascent stage. Naturally, FMs are capable of boosting the performance of FL, and FL could also leverage decentralized data and computing resources to assist in the training of FMs. However, the exceptionally high requirements that FMs have for computing resources, storage, and communication overhead would pose critical challenges to FL-enabled wireless networks. In this article, we explore the extent to which FMs are suitable for FL over wireless networks, including a broad overview of research challenges and opportunities. In particular, we discuss multip
    
[^32]: 语言模型作为视觉-语言模型的黑盒优化器

    Language Models as Black-Box Optimizers for Vision-Language Models. (arXiv:2309.05950v1 [cs.CL])

    [http://arxiv.org/abs/2309.05950](http://arxiv.org/abs/2309.05950)

    本论文介绍了一种新的视觉-语言模型 (VLMs) 微调方法，通过自然语言提示来避免访问模型参数，采用聊天式的语言模型作为黑盒优化器，在少样本图像分类任务中达到效果。

    

    预训练在大规模网络数据集上的视觉-语言模型 (VLMs) 展示了在各种视觉和多模态任务中的显著能力。目前，VLMs 的微调方法主要在白盒环境中操作，需要访问模型参数进行反向传播。然而，许多 VLMs 依赖于专有数据且不开源，限制了使用白盒方法进行微调。鉴于像 ChatGPT 这样的受欢迎私有大型语言模型 (LLMs) 仍然提供基于语言的用户界面，我们旨在通过自然语言提示开发一种新的 VLMs 微调方法，从而避免访问模型参数、特征嵌入或输出 logits 的需要。在这种设置下，我们提出使用基于聊天的 LLMs 作为黑盒优化器，以在使用 CLIP 进行少样本图像分类的示例任务中寻找最佳文本提示。具体而言，我们采用自动"爬山"程序，它能收敛到有效的提示上。

    Vision-language models (VLMs) pre-trained on web-scale datasets have demonstrated remarkable capabilities across a variety of vision and multimodal tasks. Currently, fine-tuning methods for VLMs mainly operate in a white-box setting, requiring access to model parameters for backpropagation. However, many VLMs rely on proprietary data and are not open-source, which restricts the use of white-box approaches for fine-tuning. Given that popular private large language models (LLMs) like ChatGPT still offer a language-based user interface, we aim to develop a novel fine-tuning approach for VLMs through natural language prompts, thereby avoiding the need to access model parameters, feature embeddings, or output logits. In this setup, we propose employing chat-based LLMs as black-box optimizers to search for the best text prompt on the illustrative task of few-shot image classification using CLIP. Specifically, we adopt an automatic "hill-climbing" procedure that converges on an effective prom
    
[^33]: 利用可接受边界进行启发式学习

    Utilizing Admissible Bounds for Heuristic Learning. (arXiv:2308.11905v1 [cs.AI])

    [http://arxiv.org/abs/2308.11905](http://arxiv.org/abs/2308.11905)

    本文通过将可接受启发式作为截断高斯分布的参数，明确了在监督启发式学习中可接受启发式的作用，紧缩了假设空间。

    

    虽然利用现代机器学习技术学习前向搜索算法的启发式函数近年来受到了关注，但对于它们应该学习的内容、如何训练以及为什么这样做的理论认识还很少。这种理解的不足导致文献中进行数据集选择（次优成本对最优成本或可接受对不可接受启发式）和优化指标（例如平方误差和绝对误差）时进行了临时选择。此外，由于所得到的训练启发式函数缺乏可接受性，对于学习过程中可接受性的重要性也缺乏关注。本文通过将可接受启发式作为截断高斯分布的参数，明确了在监督启发式学习中可接受启发式的作用，相比普通高斯分布，紧缩了假设空间。我们认为这个数学模型忠实地遵循了最大熵原则。

    While learning a heuristic function for forward search algorithms with modern machine learning techniques has been gaining interest in recent years, there has been little theoretical understanding of \emph{what} they should learn, \emph{how} to train them, and \emph{why} we do so. This lack of understanding leads to various literature performing an ad-hoc selection of datasets (suboptimal vs optimal costs or admissible vs inadmissible heuristics) and optimization metrics (e.g., squared vs absolute errors). Moreover, due to the lack of admissibility of the resulting trained heuristics, little focus has been put on the role of admissibility \emph{during} learning. This paper articulates the role of admissible heuristics in supervised heuristic learning using them as parameters of Truncated Gaussian distributions, which tightens the hypothesis space compared to ordinary Gaussian distributions. We argue that this mathematical model faithfully follows the principle of maximum entropy and em
    
[^34]: 去除背景对于神经网络在时尚图像分类和分割中的性能影响

    The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation. (arXiv:2308.09764v1 [cs.CV])

    [http://arxiv.org/abs/2308.09764](http://arxiv.org/abs/2308.09764)

    本研究通过去除时尚图像的背景，提高了数据质量和模型性能，在多个方面进行了广泛的比较实验，结果表明背景去除对于模型训练有积极的影响。

    

    时尚理解是计算机视觉中的热门话题，在市场上具有很大的商业价值。由于服装的巨大多样性以及各种场景和背景的存在，时尚理解对于计算机视觉仍然是一个很大的挑战。在这项工作中，我们尝试去除时尚图像中的背景，以提高数据质量并提高模型性能。通过利用显著性物体检测，我们可以对时尚数据进行背景去除。被去除背景的时尚图像与时尚数据集中的原始图像形成对比。我们对这两种类型的图像进行了广泛的比较实验，包括模型架构、模型初始化、与其他训练技巧和数据增强的兼容性以及目标任务类型。实验证明，背景去除对于模型训练在多个方面都有影响。

    Fashion understanding is a hot topic in computer vision, with many applications having great business value in the market. Fashion understanding remains a difficult challenge for computer vision due to the immense diversity of garments and various scenes and backgrounds. In this work, we try removing the background from fashion images to boost data quality and increase model performance. Having fashion images of evident persons in fully visible garments, we can utilize Salient Object Detection to achieve the background removal of fashion data to our expectations. A fashion image with the background removed is claimed as the "rembg" image, contrasting with the original one in the fashion dataset. We conducted extensive comparative experiments with these two types of images on multiple aspects of model training, including model architectures, model initialization, compatibility with other training tricks and data augmentations, and target task types. Our experiments show that background 
    
[^35]: 永远不给任何零梯度：学习非可微图形的局部替代损失

    Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics. (arXiv:2308.05739v1 [cs.CV])

    [http://arxiv.org/abs/2308.05739](http://arxiv.org/abs/2308.05739)

    本论文提出了ZeroGrads框架，通过学习非可微图形的局部替代损失函数来解决无梯度问题，并通过主动平滑和局部性约束优化替代损失的拟合，同时设计了高效的采样方案，实现了可行的运行时间和竞争力。

    

    基于梯度的优化在图形领域变得普遍，但不幸的是无法应用于具有未定义或零梯度的问题。为了解决这个问题，可以通过手动替换损失函数来使用类似极小值但可微的“替代损失”。我们提出的ZeroGrads框架通过学习目标函数的神经逼近，即替代损失，来自动化这个过程，从而可以通过任意黑盒图形流程进行微分。我们训练替代损失在目标函数的主动平滑版本上，并鼓励局部性，使替代损失的容量集中在当前训练阶段的关键内容上。拟合是在线执行的，与参数优化同时进行，自监督进行，无需预先计算数据或预训练模型。由于目标的采样是昂贵的（需要完整的渲染或模拟运行），我们设计了一个高效的采样方案，以实现可行的运行时间和竞争力。

    Gradient-based optimization is now ubiquitous across graphics, but unfortunately can not be applied to problems with undefined or zero gradients. To circumvent this issue, the loss function can be manually replaced by a "surrogate" that has similar minima but is differentiable. Our proposed framework, ZeroGrads, automates this process by learning a neural approximation of the objective function, the surrogate, which in turn can be used to differentiate through arbitrary black-box graphics pipelines. We train the surrogate on an actively smoothed version of the objective and encourage locality, focusing the surrogate's capacity on what matters at the current training episode. The fitting is performed online, alongside the parameter optimization, and self-supervised, without pre-computed data or pre-trained models. As sampling the objective is expensive (it requires a full rendering or simulator run), we devise an efficient sampling scheme that allows for tractable run-times and competit
    
[^36]: PINNsFormer: 基于Transformer的物理信息神经网络框架

    PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks. (arXiv:2307.11833v1 [cs.CE])

    [http://arxiv.org/abs/2307.11833](http://arxiv.org/abs/2307.11833)

    PINNsFormer是一种基于Transformer的框架，通过捕捉时间依赖性准确逼近求解偏微分方程，相比传统方法具有更好的性能。

    

    物理信息神经网络（PINNs）已经成为一种有效的深度学习框架，用于近似求解偏微分方程（PDEs）的数值解。然而，传统的PINNs和大多数相关研究采用全连接的多层感知机（MLP）作为核心结构，忽略了PDEs中的时间关系，无法准确逼近真解。在本文中，我们提出了一种新的基于Transformer的框架，即PINNsFormer，通过Transformer-based模型中的多头注意力机制捕捉时间依赖性，准确逼近PDEs的解。PINNsFormer不仅适应输入向量以伪序列的形式进行近似预测，还将逐点的PINNs损失改为了顺序的PINNs损失。此外，PINNsFormer还配备了一种新的激活函数，即小波函数，通过深度神经网络实现对傅里叶分解的预测。我们通过实验证明了PINNsFormer捕捉时间依赖关系的能力。

    Physics-Informed Neural Networks (PINNs) have emerged as a promising deep learning framework for approximating numerical solutions for partial differential equations (PDEs). While conventional PINNs and most related studies adopt fully-connected multilayer perceptrons (MLP) as the backbone structure, they have neglected the temporal relations in PDEs and failed to approximate the true solution. In this paper, we propose a novel Transformer-based framework, namely PINNsFormer, that accurately approximates PDEs' solutions by capturing the temporal dependencies with multi-head attention mechanisms in Transformer-based models. Instead of approximating point predictions, PINNsFormer adapts input vectors to pseudo sequences and point-wise PINNs loss to a sequential PINNs loss. In addition, PINNsFormer is equipped with a novel activation function, namely Wavelet, which anticipates the Fourier decomposition through deep neural networks. We empirically demonstrate PINNsFormer's ability to captu
    
[^37]: 关于图神经网络的能力和激活函数的作用

    On the power of graph neural networks and the role of the activation function. (arXiv:2307.04661v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.04661](http://arxiv.org/abs/2307.04661)

    本文通过对称多项式代数的工具证明了对于具有分段多项式激活函数且体系结构大小不变的GNNs，存在一对非同构根树在任意迭代次数内无法被区分，与此同时，具有不同大小的GNNs只需两次迭代即可区分。此外，我们还证明了如果允许非分段多项式激活函数，则在两次迭代内，单个神经元感知器可以区分任意一对非同构树的根节点。

    

    在这篇文章中，我们提出了关于图神经网络（GNNs）表达能力的新结果。我们证明了对于任何具有分段多项式激活函数、其体系结构大小不随图输入大小增长的GNNs，存在一对深度为二的非同构根树，使得GNNs在任意迭代次数内无法区分它们的根节点。证明依赖于对称多项式代数的工具。相比之下，已经知道具有分段多项式激活函数的无界GNNs（其大小允许随图大小改变）只需两次迭代即可区分这些顶点。我们的结果对于有界大小和无界大小的GNNs之间存在严格的分离，回答了 [Grohe, 2021] 提出的一个开放性问题。接下来，我们证明如果允许非分段多项式激活函数，则在两次迭代中，单个神经元感知器可以区分任意一对非同构树的根节点。

    In this article we present new results about the expressivity of Graph Neural Networks (GNNs). We prove that for any GNN with piecewise polynomial activations, whose architecture size does not grow with the graph input sizes, there exists a pair of non-isomorphic rooted trees of depth two such that the GNN cannot distinguish their root vertex up to an arbitrary number of iterations. The proof relies on tools from the algebra of symmetric polynomials. In contrast, it was already known that unbounded GNNs (those whose size is allowed to change with the graph sizes) with piecewise polynomial activations can distinguish these vertices in only two iterations. Our results imply a strict separation between bounded and unbounded size GNNs, answering an open question formulated by [Grohe, 2021]. We next prove that if one allows activations that are not piecewise polynomial, then in two iterations a single neuron perceptron can distinguish the root vertices of any pair of nonisomorphic trees of 
    
[^38]: 基于分层自编码器的大规模高分辨率科学数据有损压缩

    Hierarchical Autoencoder-based Lossy Compression for Large-scale High-resolution Scientific Data. (arXiv:2307.04216v1 [cs.LG])

    [http://arxiv.org/abs/2307.04216](http://arxiv.org/abs/2307.04216)

    本论文提出了一种基于分层自编码器的神经网络模型，能够显著压缩大规模高分辨率科学数据，并保持高重建质量。

    

    有损压缩已成为许多领域中减小数据大小的重要技术。这种压缩方法对于大小在几个PB范围内的大规模科学数据尤为重要。虽然基于自编码器的模型已成功地用于压缩图像和视频，但这种神经网络在科学数据领域尚未广为关注。我们的工作提出了一个神经网络，不仅可以显著压缩大规模科学数据，还可以保持高重建质量。所提出的模型在公开的科学基准数据上进行了测试，并应用于一种大规模高分辨率的气候模拟数据集。我们的模型在几个基准数据集上实现了140的压缩比，同时保持重建质量。高分辨率社区地球系统模型(CESM) Version 1.3的模拟数据在压缩比达到200的同时进行了压缩。

    Lossy compression has become an important technique to reduce data size in many domains. This type of compression is especially valuable for large-scale scientific data, whose size ranges up to several petabytes. Although Autoencoder-based models have been successfully leveraged to compress images and videos, such neural networks have not widely gained attention in the scientific data domain. Our work presents a neural network that not only significantly compresses large-scale scientific data but also maintains high reconstruction quality. The proposed model is tested with scientific benchmark data available publicly and applied to a large-scale high-resolution climate modeling data set. Our model achieves a compression ratio of 140 on several benchmark data sets without compromising the reconstruction quality. Simulation data from the High-Resolution Community Earth System Model (CESM) Version 1.3 over 500 years are also being compressed with a compression ratio of 200 while the recon
    
[^39]: MLP-Mixer作为宽且稀疏的MLP

    MLP-Mixer as a Wide and Sparse MLP. (arXiv:2306.01470v1 [cs.LG])

    [http://arxiv.org/abs/2306.01470](http://arxiv.org/abs/2306.01470)

    深度学习中常用的MLP有潜力提高性能。本研究揭示MLP-Mixer 可以作为具有稀疏权重的宽MLP有效地工作。

    

    多层感知器(MLP)是深度学习中被广泛应用于多种问题的基础组件。然而，最近基于MLP的架构(特别是MLP-Mixer)的实证成功表明，提高MLP的性能仍具有潜在的潜力。在本研究中，我们发现MLP-Mixer有效地作为具有某些稀疏权重的宽MLP。最初，我们澄清Mixer的混合层可以作为具有稀疏权重且由Kronecker乘积表示的更宽MLP的有效表达。该表达式自然地定义了一组置换-Kronecker(PK)家族，可以被视为混合层的一般类，也可以被视为Monarch矩阵的一种近似。随后，由于PK家族有效构成具有稀疏权重的宽MLP，因此，可以应用Golubeva、Neyshabur和Gur-Ari(2021)提出的假设，即预测性能：

    Multi-layer perceptron (MLP) is a fundamental component of deep learning that has been extensively employed for various problems. However, recent empirical successes in MLP-based architectures, particularly the progress of the MLP-Mixer, have revealed that there is still hidden potential in improving MLPs to achieve better performance. In this study, we reveal that the MLP-Mixer works effectively as a wide MLP with certain sparse weights. Initially, we clarify that the mixing layer of the Mixer has an effective expression as a wider MLP whose weights are sparse and represented by the Kronecker product. This expression naturally defines a permuted-Kronecker (PK) family, which can be regarded as a general class of mixing layers and is also regarded as an approximation of Monarch matrices. Subsequently, because the PK family effectively constitutes a wide MLP with sparse weights, one can apply the hypothesis proposed by Golubeva, Neyshabur and Gur-Ari (2021) that the prediction performanc
    
[^40]: 声音拆分任务的基准和排行榜

    Benchmarks and leaderboards for sound demixing tasks. (arXiv:2305.07489v1 [cs.SD])

    [http://arxiv.org/abs/2305.07489](http://arxiv.org/abs/2305.07489)

    本文介绍了两个新的声源分离任务基准，并将流行的模型及其集成在这些基准上的表现进行了比较。他们还开发了一种新的音频分离方法，基于适合特定音轨的不同模型的集成，该方法在2023年音乐分离挑战赛中取得了高水平成绩，并开源了代码和方法。

    

    音乐拆分是将给定的单音频信号分离成组成部分（例如鼓、低音和人声等）与其他伴奏音乐分离的任务。源分离在许多领域中都十分有用，包括娱乐和助听器。本文提出了两个新的声源分离任务基准，并比较了流行的声音拆分模型及其集成在这些基准上的表现。我们提供了模型排行榜 https://mvsep.com/quality_checker/，以对各种模型进行比较。新的基准数据集可供下载。我们还开发了一种新的音频分离方法，基于适合特定音轨的不同模型的集成。所提出的解决方案在2023音乐分离挑战赛中取得了高水平成绩。我们的代码和方法在GitHub上公开发布。

    Music demixing is the task of separating different tracks from the given single audio signal into components, such as drums, bass, and vocals from the rest of the accompaniment. Separation of sources is useful for a range of areas, including entertainment and hearing aids. In this paper, we introduce two new benchmarks for the sound source separation tasks and compare popular models for sound demixing, as well as their ensembles, on these benchmarks. For the models' assessments, we provide the leaderboard at https://mvsep.com/quality_checker/, giving a comparison for a range of models. The new benchmark datasets are available for download. We also develop a novel approach for audio separation, based on the ensembling of different models that are suited best for the particular stem. The proposed solution was evaluated in the context of the Music Demixing Challenge 2023 and achieved top results in different tracks of the challenge. The code and the approach are open-sourced on GitHub.
    
[^41]: 基于人工智能驱动的组合化学在极端特性材料发现中的应用

    Materials Discovery with Extreme Properties via AI-Driven Combinatorial Chemistry. (arXiv:2303.11833v1 [q-bio.BM])

    [http://arxiv.org/abs/2303.11833](http://arxiv.org/abs/2303.11833)

    本文提出了一种基于人工智能驱动的组合化学方法，不依赖于数据，可以发现未知材料并具有更优越的性质。实验证明这种方法比概率分布学习的模型更适合于发现更好的材料。

    

    大多数材料的发现都旨在发现比目前已知材料更优越的材料。然而，这很接近于外推，对于大多数学习数据概率分布的机器学习模型来说这是一个弱点。本文提出了一种基于人工智能驱动的组合化学方法，它是一种基于规则的反向分子设计器，不依赖于数据。由于我们的模型有可能生成从分子片段组合中获得的所有可能的分子结构，因此可以发现具有更优越性质的未知材料。我们理论和实验证明了我们的模型比概率分布学习的模型更适合于发现更好的材料。在一个旨在发现七个目标特性分子的实验中，我们的模型在10万次试验中发现了1315个达到全部目标的分子和7629个达到五个目标的分子，而概率分布学习模型只有发现几个。

    The goal of most materials discovery is to discover materials that are superior to those currently known. Fundamentally, this is close to extrapolation, which is a weak point for most machine learning models that learn the probability distribution of data. Herein, we develop AI-driven combinatorial chemistry, which is a rule-based inverse molecular designer that does not rely on data. Since our model has the potential to generate all possible molecular structures that can be obtained from combinations of molecular fragments, unknown materials with superior properties can be discovered. We theoretically and empirically demonstrate that our model is more suitable for discovering better materials than probability distribution-learning models. In an experiment aimed at discovering molecules that hit seven target properties, our model discovered 1,315 of all target-hitting molecules and 7,629 of five target-hitting molecules out of 100,000 trials, whereas the probability distribution-learni
    
[^42]: AC电力流的神经网络建模的全局性能保证

    Global Performance Guarantees for Neural Network Models of AC Power Flow. (arXiv:2211.07125v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2211.07125](http://arxiv.org/abs/2211.07125)

    本文首次开发了一种可行的神经网络验证程序，它结合了非线性AC电力流方程的ground truth，以确定最坏的神经网络性能。使用顺序添加有针对性的切割，我们迭代地收紧我们的公式，直到解决方案足够紧密或达到一个安全性阈值。

    

    机器学习可以生成既快又准的黑盒子模型。但严格验证黑盒模型的准确性是计算上具有挑战性的。对于电力系统来说，学习AC电力流是任何希望显著加速计算的机器学习黑盒模型的基石，无论是为了优化、控制还是动力学。本文首次开发一种可行的神经网络验证程序，它结合了非线性AC电力流方程的ground truth，以确定最坏的神经网络性能。我们的方法称为Sequential Targeted Tightening (STT)，它利用松弛的凸规划重构了原始的验证问题，该问题是一个混合整数二次规划（MIQP）。通过顺序添加有针对性的切割，我们迭代地收紧我们的公式，直到解决方案足够紧密或达到一个安全性阈值。

    Machine learning can generate black-box surrogate models which are both extremely fast and highly accurate. Rigorously verifying the accuracy of these black-box models, however, is computationally challenging. When it comes to power systems, learning AC power flow is the cornerstone of any machine learning surrogate model wishing to drastically accelerate computations, whether it is for optimization, control, or dynamics. This paper develops for the first time, to our knowledge, a tractable neural network verification procedure which incorporates the ground truth of the non-linear AC power flow equations to determine worst-case neural network performance. Our approach, termed Sequential Targeted Tightening (STT), leverages a loosely convexified reformulation of the original verification problem, which is a mixed integer quadratic program (MIQP). Using the sequential addition of targeted cuts, we iteratively tighten our formulation until either the solution is sufficiently tight or a sa
    
[^43]: 理解脸部匿名逆转：Fant\^omas研究

    Fant\^omas: Understanding Face Anonymization Reversibility. (arXiv:2210.10651v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.10651](http://arxiv.org/abs/2210.10651)

    本文对脸部匿名逆转现象进行了全面的研究，发现11种脸部匿名化方法至少部分可逆，并强调了重构和反演实现可逆性的机制。

    

    脸部图像是一个丰富的信息源，可以用来识别个人并推断他们的私人信息。为了减轻这种隐私风险，匿名化方法使用对清晰图像进行转换以混淆敏感信息，同时保留一定的实用性。然而，虽然它们以令人印象深刻的声明发表，但有时并未经过令人信服的方法评估。将匿名化图像逆转回仿真其真实输入的程度，甚至能被人脸识别方法识别，这对于匿名化的缺陷是最强有力的指标。最近的一些研究结果的确表明，对于某些方法而言这是可能的。然而，目前对于哪些方法是可逆的，以及为什么可逆还不太清楚。在本文中，我们对脸部匿名逆转现象进行了全面的研究。我们发现，在经过测试的15种方法中，有11种至少部分可逆，并重点介绍了重构和反演是如何实现可逆性的。

    Face images are a rich source of information that can be used to identify individuals and infer private information about them. To mitigate this privacy risk, anonymizations employ transformations on clear images to obfuscate sensitive information, all while retaining some utility. Albeit published with impressive claims, they sometimes are not evaluated with convincing methodology.  Reversing anonymized images to resemble their real input -- and even be identified by face recognition approaches -- represents the strongest indicator for flawed anonymization. Some recent results indeed indicate that this is possible for some approaches. It is, however, not well understood, which approaches are reversible, and why. In this paper, we provide an exhaustive investigation in the phenomenon of face anonymization reversibility. Among other things, we find that 11 out of 15 tested face anonymizations are at least partially reversible and highlight how both reconstruction and inversion are the u
    

