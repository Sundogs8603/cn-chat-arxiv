# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multi-task learning of convex combinations of forecasting models.](http://arxiv.org/abs/2310.20545) | 本文提出了一种多任务学习方法，通过深度神经网络同时解决了预测模型选择和凸组合权重学习的问题。通过回归分支学习权重和分类分支选择具有多样性的预测方法，提高了基于特征的预测的精确度。 |
| [^2] | [Backdoor Attack through Machine Unlearning.](http://arxiv.org/abs/2310.10659) | 本文提出了一种基于机器遗忘的新型黑盒后门攻击方法，通过激活隐藏后门来输出恶意预测，从而针对深度学习模型的脆弱性进行攻击。 |
| [^3] | [Defending Our Privacy With Backdoors.](http://arxiv.org/abs/2310.08320) | 本研究提出了一种基于后门攻击的防御方法，通过对模型进行策略性插入后门，对齐敏感短语与中性术语的嵌入，以删除训练数据中的私人信息。实证结果显示该方法的有效性。 |
| [^4] | [A Language-Agent Approach to Formal Theorem-Proving.](http://arxiv.org/abs/2310.04353) | COPRA是一种面向形式定理证明的语言代理方法，利用大型语言模型进行上下文学习，通过选择策略和检索定义和引理进行证明，在MiniF2F基准和Coq任务上表现出优异的性能。 |
| [^5] | [Attributing Learned Concepts in Neural Networks to Training Data.](http://arxiv.org/abs/2310.03149) | 通过将数据归因方法与概念探测方法相结合，研究了神经网络中学习到的概念与训练数据的关系，并发现概念的位置和稀疏性并不完全依赖于少量特定示例。 |
| [^6] | [HappyFeat -- An interactive and efficient BCI framework for clinical applications.](http://arxiv.org/abs/2310.02948) | HappyFeat是一种面向临床应用的交互和高效的BCI框架，通过一个方便的GUI和参数自动化的帮助，使得基于运动想象的BCI实验更加容易，并能在时间受限的环境中实现良好的性能。 |
| [^7] | [On the Stability of Iterative Retraining of Generative Models on their own Data.](http://arxiv.org/abs/2310.00429) | 本文研究了生成模型在混合数据集上训练对稳定性的影响，通过证明初始生成模型足够接近数据分布并且数据比例适当，迭代训练是稳定的。 |
| [^8] | [DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space.](http://arxiv.org/abs/2309.14585) | DifAttack是一种基于解耦特征空间的高效黑盒攻击方法，通过迭代优化对抗特征并利用受害者模型的查询反馈生成成功的对抗样本。 |
| [^9] | [Coreset selection can accelerate quantum machine learning models with provable generalization.](http://arxiv.org/abs/2309.10441) | 本论文提出了一种统一的方法，通过从原始训练数据集中选取一个合理的子集，加速量子神经网络和量子核的训练，并分析了它们在这些核心集上训练时的泛化误差界限，揭示了与在完整原始数据集上训练相比具有可比性的性能。 |
| [^10] | [Domain Generalization with Fourier Transform and Soft Thresholding.](http://arxiv.org/abs/2309.09866) | 本研究提出了一种基于傅里叶变换和软阈值的领域泛化方法，用于提高神经网络在不同源上的视网膜底图图像分割任务中的性能。 |
| [^11] | [Toward Discretization-Consistent Closure Schemes for Large Eddy Simulation Using Reinforcement Learning.](http://arxiv.org/abs/2309.06260) | 本研究提出了一种使用强化学习方法开发离散一致性闭塞方案的新方法，其中将大涡模拟中的闭塞模型系数调整任务定义为马尔可夫决策过程，通过后期的强化学习解决。这一方法能够将模型调整到实际的离散化中并考虑离散化和模型本身之间的相互作用。通过优化显式和隐式闭塞模型中的局部涡粘度模型和混合策略，实现了闭塞模型的优化。 |
| [^12] | [AmbientFlow: Invertible generative models from incomplete, noisy measurements.](http://arxiv.org/abs/2309.04856) | AmbientFlow是一个从噪声和不完整数据中直接学习基于流的生成模型的新框架，通过使用变分贝叶斯方法来建立这种模型，展示了其在图像科学中的应用潜力。 |
| [^13] | [Adapting Self-Supervised Representations to Multi-Domain Setups.](http://arxiv.org/abs/2309.03999) | 该论文提出了一种通用的、轻量级的领域解缠模块（DDM），可以在多个不同领域上进行有效的自监督表示学习，并显示出较高的线性探测准确率提升。 |
| [^14] | [Norm Tweaking: High-performance Low-bit Quantization of Large Language Models.](http://arxiv.org/abs/2309.02784) | 本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。 |
| [^15] | [On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design.](http://arxiv.org/abs/2308.09888) | 该论文提出了一种估计贝叶斯实验设计中期望信息增益梯度的方法，通过结合随机梯度下降算法，实现了高效优化。具体而言，通过后验期望表示来估计与设计变量相关的梯度，并提出了UEEG-MCMC和BEEG-AP两种估计方法。这些方法在不同的实验设计问题上都表现出良好的性能。 |
| [^16] | [Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression.](http://arxiv.org/abs/2308.09065) | 本文提出了一种用于回归任务的广义AuxUE方案，目的是实现更鲁棒的不确定性量化。具体而言，该方案通过考虑不同的分布假设，选择Laplace分布来近似p，以实现更鲁棒的本质不确定性估计。 |
| [^17] | [PMET: Precise Model Editing in a Transformer.](http://arxiv.org/abs/2308.08742) | 该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。 |
| [^18] | [Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening.](http://arxiv.org/abs/2308.07707) | 选择性突触减弱（SSD）是快速、性能优越且无需重新训练的机器遗忘方法，能够同时保护模型的性能并遗忘特定信息。 |
| [^19] | [PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning.](http://arxiv.org/abs/2308.03977) | 我们提出了一种使用逼真且语义可控的合成数据的方法，用于表示学习研究，该方法具有渲染所需数量的数据样本、精确控制场景和分布转变以及精细的真实标签的优点。 |
| [^20] | [Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges.](http://arxiv.org/abs/2308.00031) | 这篇论文调查了在生成人工智能中应用强化学习的现状、机会和开放研究问题。作者主要讨论了三种应用类型：无特定目标的生成方式、同时最大化目标函数的输出生成方式以及将无法通过目标函数捕捉的期望特征嵌入生成过程的方式。这个新兴领域中存在着丰富的机会和挑战。 |
| [^21] | [Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques.](http://arxiv.org/abs/2307.12971) | 本文介绍了一种新的大数据-供应链管理框架，通过数据预处理和机器学习技术实现供应链预测，优化操作管理、透明度，并讨论了幻影库存对预测的不利影响。 |
| [^22] | [TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars.](http://arxiv.org/abs/2307.10705) | 本文提出了一种轻量级模型TwinLiteNet，用于自动驾驶车辆中的可驱动区域和车道分割。该模型成本低廉且高效准确，并在实验中表现出明显的计算资源节约。 |
| [^23] | [LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning.](http://arxiv.org/abs/2307.02345) | 本研究通过研究在线和离线增强学习中 Bellman 近似误差的分布发现，Bellman 误差符合逻辑分布。基于这一发现，本研究提出了一种使用 Logistic 最大似然函数作为替代方法的方案，并通过实验证明了其有效性。 |
| [^24] | [Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings.](http://arxiv.org/abs/2306.04064) | 本文提出一种方法，通过自编码器生成通用鲁棒嵌入，将分类数据转换为向量，从而实现对抗训练，提高分类器的鲁棒性，并在多个数据集上取得了最先进的对抗鲁棒性性能表现。 |
| [^25] | [Efficient Training of Energy-Based Models Using Jarzynski Equality.](http://arxiv.org/abs/2305.19414) | 本文介绍了一种通过使用Jarzynski平等式和顺序蒙特卡罗采样绕过标准对比散度算法中的不可控逼近误差，有效训练能量基模型的方法。 |
| [^26] | [The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond.](http://arxiv.org/abs/2305.10697) | 本文提出了异构群体强化学习中联邦Q学习的样本复杂度保证，讨论了同步和异步版本的线性加速，同时探究了等权重平均本地Q估计的缺陷。 |
| [^27] | [Accelerating Batch Active Learning Using Continual Learning Techniques.](http://arxiv.org/abs/2305.06408) | 本文介绍了一种新的技术，即永续性主动学习（CAL），通过偏向先前标记集来加速训练，通过使用一系列回放方案，包括模型蒸馏和从历史中选择多样化的和不确定的点。实验结果表明，CAL可以大幅提升训练速度。 |
| [^28] | [Semi-Supervised Segmentation of Functional Tissue Units at the Cellular Level.](http://arxiv.org/abs/2305.02148) | 通过利用最新的深度学习语义分割、领域适配和半监督学习技术，该研究提出了一种半监督分割方法，可在细胞水平上对功能性组织单元进行分割，并取得了先进水平的结果。 |
| [^29] | [Do SSL Models Have D\'ej\`a Vu? A Case of Unintended Memorization in Self-supervised Learning.](http://arxiv.org/abs/2304.13850) | 自监督学习（SSL）算法会意外地记忆单个训练样本中的特定部分，称为“似曾相识”记忆，该现象是普遍存在的，不能被传统的评估方法检测。 |
| [^30] | [Learning to Transmit with Provable Guarantees in Wireless Federated Learning.](http://arxiv.org/abs/2304.09329) | 该研究提出了一种数据驱动方法，用于分配联邦学习中的发射功率，以优化通信约束下FL过程中服务器端接收到的信息，并提高全局FL模型的准确性和效率。 |
| [^31] | [Leveraging sparse and shared feature activations for disentangled representation learning.](http://arxiv.org/abs/2304.07939) | 本文提出了利用从多样化监督任务中提取的知识来学习通用的解缠表示的方法，使监督多任务模型的特征空间得以解缠，适当共享信息，达到可识别性。 |
| [^32] | [Conformal Prediction Regions for Time Series using Linear Complementarity Programming.](http://arxiv.org/abs/2304.01075) | 本文提出了一种基于优化的方法，通过将预测误差参数化为多个时间步长，以找到不保守的预测区间，实现在使用学习启用的时间序列预测器进行长期规划和验证。 |
| [^33] | [Ensemble Reinforcement Learning: A Survey.](http://arxiv.org/abs/2303.02618) | 集成强化学习（ERL）是一种将强化学习（RL）与集成学习（EL）相结合的有前途的方法，旨在利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。 |
| [^34] | [Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation.](http://arxiv.org/abs/2301.13428) | 本文提出了一个无源域适应的实用且具有挑战性的方案，通过在原始特征空间聚类，构建真正困难的负对，结合噪声对比估计理论，学习一个域不变的特征来解决域上的差异问题，能够在三个常见的基准数据集上实现有效结果。 |
| [^35] | [Mixed moving average field guided learning for spatio-temporal data.](http://arxiv.org/abs/2301.00736) | 本论文提出了一种理论引导机器学习方法，采用广义贝叶斯算法进行混合移动平均场引导的时空数据建模，可以进行因果未来预测。 |
| [^36] | [On the fast convergence of minibatch heavy ball momentum.](http://arxiv.org/abs/2206.07553) | 本文研究了一种随机Kaczmarz算法，使用小批量和重球动量进行加速，在二次优化问题中保持快速收敛率。 |
| [^37] | [Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features.](http://arxiv.org/abs/2203.01881) | 从自监督学习模型中提取区分特征，并使用它们压缩表示空间，提出了一种Q-Score自监督表示质量分数，可以可靠地预测线性评估期间的错误分类。 |
| [^38] | [Generating Novel Scene Compositions from Single Images and Videos.](http://arxiv.org/abs/2103.13389) | 本研究提出了SIV-GAN，一种无条件生成模型，可以从单个图像或视频中生成新的场景组合。通过引入内容和布局分支的鉴别器架构，该模型能够生成多样化、高质量的图像，并在保留上下文的同时保持视觉逼真。 |
| [^39] | [Acting in Delayed Environments with Non-Stationary Markov Policies.](http://arxiv.org/abs/2101.11992) | 该论文介绍了在延迟环境中，学习和规划的马尔可夫决策过程(MDP)框架，证明了在延迟执行的情况下，原始状态空间中的非固定马尔可夫策略可以实现最大奖励，提出了一种解决延迟执行任务的非固定Q-learning风格算法。 |

# 详细

[^1]: 多任务学习凸组合预测模型

    Multi-task learning of convex combinations of forecasting models. (arXiv:2310.20545v1 [cs.LG])

    [http://arxiv.org/abs/2310.20545](http://arxiv.org/abs/2310.20545)

    本文提出了一种多任务学习方法，通过深度神经网络同时解决了预测模型选择和凸组合权重学习的问题。通过回归分支学习权重和分类分支选择具有多样性的预测方法，提高了基于特征的预测的精确度。

    

    预测组合涉及使用多个预测来创建单一、更精确的预测。最近，基于特征的预测已被用于选择最合适的预测模型或学习它们的凸组合权重。在本文中，我们提出了一种同时解决这两个问题的多任务学习方法。该方法通过深度神经网络实现，其中包括两个分支：回归分支通过最小化组合预测误差来学习各种预测方法的权重，分类分支则重点选择多样性的预测方法。为了为分类任务生成训练标签，我们引入了一种优化驱动的方法，用于确定给定时间序列的最合适的方法。所提出的方法揭示了基于特征的预测中多样性的重要作用，并凸显了模型组合和选择之间的相互作用。

    Forecast combination involves using multiple forecasts to create a single, more accurate prediction. Recently, feature-based forecasting has been employed to either select the most appropriate forecasting models or to learn the weights of their convex combination. In this paper, we present a multi-task learning methodology that simultaneously addresses both problems. This approach is implemented through a deep neural network with two branches: the regression branch, which learns the weights of various forecasting methods by minimizing the error of combined forecasts, and the classification branch, which selects forecasting methods with an emphasis on their diversity. To generate training labels for the classification task, we introduce an optimization-driven approach that identifies the most appropriate methods for a given time series. The proposed approach elicits the essential role of diversity in feature-based forecasting and highlights the interplay between model combination and mo
    
[^2]: 通过机器遗忘实施后门攻击

    Backdoor Attack through Machine Unlearning. (arXiv:2310.10659v1 [cs.CR])

    [http://arxiv.org/abs/2310.10659](http://arxiv.org/abs/2310.10659)

    本文提出了一种基于机器遗忘的新型黑盒后门攻击方法，通过激活隐藏后门来输出恶意预测，从而针对深度学习模型的脆弱性进行攻击。

    

    最近几年，由于深度学习研究和应用的快速发展，人工智能的安全问题变得越来越突出。后门攻击是一种针对深度学习模型的攻击，攻击者通过嵌入的触发器激活隐藏的后门，从而输出可能与给定输入的预期输出不符的恶意预测。在本文中，我们提出了一种基于机器遗忘的新型黑盒后门攻击。攻击者首先通过精心设计的样本（包括毒数据和缓解数据）扩充训练集，训练一个“善意”模型。然后，攻击者提交遗忘请求，以移除缓解样本对模型的影响，逐步激活隐藏的后门。由于后门是在迭代的遗忘过程中植入的，这显著增加了现有的后门检测方法的计算开销。

    In recent years, the security issues of artificial intelligence have become increasingly prominent due to the rapid development of deep learning research and applications. Backdoor attack is an attack targeting the vulnerability of deep learning models, where hidden backdoors are activated by triggers embedded by the attacker, thereby outputting malicious predictions that may not align with the intended output for a given input. In this work, we propose a novel black-box backdoor attack based on machine unlearning. The attacker first augments the training set with carefully designed samples, including poison and mitigation data, to train a 'benign' model. Then, the attacker posts unlearning requests for the mitigation samples to remove the impact of relevant data on the model, gradually activating the hidden backdoor. Since backdoors are implanted during the iterative unlearning process, it significantly increases the computational overhead of existing defense methods for backdoor dete
    
[^3]: 使用后门技术保护我们的隐私

    Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])

    [http://arxiv.org/abs/2310.08320](http://arxiv.org/abs/2310.08320)

    本研究提出了一种基于后门攻击的防御方法，通过对模型进行策略性插入后门，对齐敏感短语与中性术语的嵌入，以删除训练数据中的私人信息。实证结果显示该方法的有效性。

    

    在使用未经筛选、常常包含敏感信息的网页数据训练大型人工智能模型的情况下，隐私问题成为了一个重要的关注点。其中一个问题是，攻击者可以利用隐私攻击的方法提取出训练数据的信息。然而，如何在不降低模型性能的情况下去除特定信息是一个不容易解决且具有挑战性的问题。我们提出了一个基于后门攻击的简单而有效的防御方法，用于从模型中删除私人信息，如个人姓名，特别是针对文本编码器的。具体而言，通过策略性地插入后门，我们将敏感短语的嵌入与中性术语的嵌入对齐，例如用"a person"代替人名。我们的实证结果通过对零样本分类器使用专门的隐私攻击测试表明了我们基于后门的防御方法的效果。我们的方法提供了一个新的"双重用途"的视角。

    The proliferation of large AI models trained on uncurated, often sensitive web-scraped data has raised significant privacy concerns. One of the concerns is that adversaries can extract information about the training data using privacy attacks. Unfortunately, the task of removing specific information from the models without sacrificing performance is not straightforward and has proven to be challenging. We propose a rather easy yet effective defense based on backdoor attacks to remove private information such as names of individuals from models, and focus in this work on text encoders. Specifically, through strategic insertion of backdoors, we align the embeddings of sensitive phrases with those of neutral terms-"a person" instead of the person's name. Our empirical results demonstrate the effectiveness of our backdoor-based defense on CLIP by assessing its performance using a specialized privacy attack for zero-shot classifiers. Our approach provides not only a new "dual-use" perspecti
    
[^4]: 一种面向形式定理证明的语言代理方法

    A Language-Agent Approach to Formal Theorem-Proving. (arXiv:2310.04353v1 [cs.LG])

    [http://arxiv.org/abs/2310.04353](http://arxiv.org/abs/2310.04353)

    COPRA是一种面向形式定理证明的语言代理方法，利用大型语言模型进行上下文学习，通过选择策略和检索定义和引理进行证明，在MiniF2F基准和Coq任务上表现出优异的性能。

    

    语言代理是利用大型语言模型（LLM）进行上下文学习来与外部环境进行交互的方法，最近被认为是一种有前景的控制任务方法。

    Language agents, which use a large language model (LLM) capable of in-context learning to interact with an external environment, have recently emerged as a promising approach to control tasks. We present the first language-agent approach to formal theorem-proving. Our method, COPRA, uses a high-capacity, black-box LLM (GPT-4) as part of a policy for a stateful backtracking search. During the search, the policy can select proof tactics and retrieve lemmas and definitions from an external database. Each selected tactic is executed in the underlying proof framework, and the execution feedback is used to build the prompt for the next policy invocation. The search also tracks selected information from its history and uses it to reduce hallucinations and unnecessary LLM queries.  We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the Compcert project. On these benchmarks, COPRA is significantly better than one-shot invocations of GPT-4, as well as state-of-the-ar
    
[^5]: 将神经网络中学习到的概念归因于训练数据

    Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v1 [cs.LG])

    [http://arxiv.org/abs/2310.03149](http://arxiv.org/abs/2310.03149)

    通过将数据归因方法与概念探测方法相结合，研究了神经网络中学习到的概念与训练数据的关系，并发现概念的位置和稀疏性并不完全依赖于少量特定示例。

    

    现在有大量的证据表明，深度学习模型学习到了某些可解释的人类特征，作为其对数据的内部表示的一部分。由于拥有正确（或错误）的概念对于可信赖的机器学习系统至关重要，自然而然地我们想要知道在给定层次上，模型原始训练集中的哪些输入对于学习一个概念最为重要。为了回答这个问题，我们将数据归因方法与探测模型学习到的概念的方法相结合。通过在一系列网络层次上训练网络和探测模型，并使用最近开发的用于大规模数据归因的TRAK方法，我们对两个概念数据集进行训练网络和探测模型的集合。我们发现一些证据表明，通过移除对一个概念具有最高归因的前10000张图像并重新训练模型，概念在网络中的位置以及概念的探测稀疏性并没有发生改变。这表明，与依赖于少量特定示例不同，用于确定概念的特征具有较高的独立性。

    By now there is substantial evidence that deep learning models learn certain human-interpretable features as part of their internal representations of data. As having the right (or wrong) concepts is critical to trustworthy machine learning systems, it is natural to ask which inputs from the model's original training set were most important for learning a concept at a given layer. To answer this, we combine data attribution methods with methods for probing the concepts learned by a model. Training network and probe ensembles for two concept datasets on a range of network layers, we use the recently developed TRAK method for large-scale data attribution. We find some evidence for convergence, where removing the 10,000 top attributing images for a concept and retraining the model does not change the location of the concept in the network nor the probing sparsity of the concept. This suggests that rather than being highly dependent on a few specific examples, the features that inform the 
    
[^6]: HappyFeat -- 一种面向临床应用的交互和高效的BCI框架

    HappyFeat -- An interactive and efficient BCI framework for clinical applications. (arXiv:2310.02948v1 [q-bio.NC])

    [http://arxiv.org/abs/2310.02948](http://arxiv.org/abs/2310.02948)

    HappyFeat是一种面向临床应用的交互和高效的BCI框架，通过一个方便的GUI和参数自动化的帮助，使得基于运动想象的BCI实验更加容易，并能在时间受限的环境中实现良好的性能。

    

    脑机接口（BCI）系统允许用户通过将大脑活动转化为命令来执行动作。这类系统通常需要进行训练阶段，包括通过使用记录的信号的特定特征来训练分类算法，以区分不同的心理状态。在临床背景下，如中风康复，对于BCI的性能和特征选择的培训阶段有特定的要求。本文介绍了HappyFeat，一种软件，在单一便利的图形用户界面和实验或分析参数的自动化的帮助下，使基于运动想象（MI）的BCI实验更加容易。结果工作流程可以轻松选择最佳特征，有助于在时间受限的环境中实现良好的BCI性能。基于功能连通性的替代特征可以与功率谱密度相比或结合使用。

    Brain-Computer Interface (BCI) systems allow users to perform actions by translating their brain activity into commands. Such systems usually need a training phase, consisting in training a classification algorithm to discriminate between mental states using specific features from the recorded signals. This phase of feature selection and training is crucial for BCI performance and presents specific constraints to be met in a clinical context, such as post-stroke rehabilitation.  In this paper, we present HappyFeat, a software making Motor Imagery (MI) based BCI experiments easier, by gathering all necessary manipulations and analysis in a single convenient GUI and via automation of experiment or analysis parameters. The resulting workflow allows for effortlessly selecting the best features, helping to achieve good BCI performance in time-constrained environments. Alternative features based on Functional Connectivity can be used and compared or combined with Power Spectral Density, allo
    
[^7]: 关于生成模型在其自己的数据上迭代训练的稳定性研究

    On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])

    [http://arxiv.org/abs/2310.00429](http://arxiv.org/abs/2310.00429)

    本文研究了生成模型在混合数据集上训练对稳定性的影响，通过证明初始生成模型足够接近数据分布并且数据比例适当，迭代训练是稳定的。

    

    深度生成模型在建模复杂数据方面取得了巨大的进展，往往展现出超过典型人类能力的样本真实性辨别能力。这一成功的关键驱动力无疑是这些模型消耗海量网络规模数据的结果。由于这些模型惊人的性能和易得性，网络上将不可避免地出现越来越多的合成内容。这个事实直接意味着生成模型的未来迭代必须面对一个现实：它们的训练数据由清洁数据和先前模型生成的人工数据组成。在本文中，我们开发了一个框架来对混合数据集（包括真实数据和合成数据）上训练生成模型对稳定性的影响进行严格研究。我们首先证明了在初始生成模型足够好地近似数据分布并且真实数据与合成数据的比例适当的情况下，迭代训练的稳定性。

    Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
    
[^8]: DifAttack: 基于解耦特征空间的高效黑盒攻击方法

    DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature Space. (arXiv:2309.14585v1 [cs.CV])

    [http://arxiv.org/abs/2309.14585](http://arxiv.org/abs/2309.14585)

    DifAttack是一种基于解耦特征空间的高效黑盒攻击方法，通过迭代优化对抗特征并利用受害者模型的查询反馈生成成功的对抗样本。

    

    本研究研究了具有高攻击成功率和良好泛化能力的高效基于分数的黑盒对抗攻击。我们设计了一种基于解耦特征空间的新型攻击方法，称为DifAttack，与现有方法在整个特征空间上操作有显著差异。具体而言，DifAttack首先将图像的潜在特征解耦为对抗特征和视觉特征，其中前者主导图像的对抗能力，而后者主要决定其视觉外观。我们使用由可用替代模型通过白盒攻击方法生成的干净图像和其对抗性样本来训练自动编码器进行解耦。最终，DifAttack根据受害者模型的查询反馈，迭代优化对抗特征，直到成功生成对抗样本，同时保持视觉特征不变。此外，由于避免使用...

    This work investigates efficient score-based black-box adversarial attacks with a high Attack Success Rate (ASR) and good generalizability. We design a novel attack method based on a Disentangled Feature space, called DifAttack, which differs significantly from the existing ones operating over the entire feature space. Specifically, DifAttack firstly disentangles an image's latent feature into an adversarial feature and a visual feature, where the former dominates the adversarial capability of an image, while the latter largely determines its visual appearance. We train an autoencoder for the disentanglement by using pairs of clean images and their Adversarial Examples (AEs) generated from available surrogate models via white-box attack methods. Eventually, DifAttack iteratively optimizes the adversarial feature according to the query feedback from the victim model until a successful AE is generated, while keeping the visual feature unaltered. In addition, due to the avoidance of using
    
[^9]: 通过可证明的泛化加速量子机器学习模型的核心集选取

    Coreset selection can accelerate quantum machine learning models with provable generalization. (arXiv:2309.10441v1 [quant-ph])

    [http://arxiv.org/abs/2309.10441](http://arxiv.org/abs/2309.10441)

    本论文提出了一种统一的方法，通过从原始训练数据集中选取一个合理的子集，加速量子神经网络和量子核的训练，并分析了它们在这些核心集上训练时的泛化误差界限，揭示了与在完整原始数据集上训练相比具有可比性的性能。

    

    量子神经网络和量子核在量子机器学习领域中具有突出地位，利用即将到来的近期量子计算机的能力来克服经典机器学习的挑战。然而，训练效率的挑战限制了量子神经网络和量子核在应用于大规模数据集时的效果。为了解决这个问题，我们提出了一种统一的方法：核心集选择，旨在通过从原始训练数据集中提取出一个合理的子集来加速量子神经网络和量子核的训练。此外，当在这些核心集上训练时，我们分析了量子神经网络和量子核的泛化误差界限，并揭示了与在完整原始数据集上训练相比具有可比性的性能。通过系统的数值模拟，我们展示了核心集选择在加速涵盖合成数据分类、量子协议鉴定等任务中的潜力。

    Quantum neural networks (QNNs) and quantum kernels stand as prominent figures in the realm of quantum machine learning, poised to leverage the nascent capabilities of near-term quantum computers to surmount classical machine learning challenges. Nonetheless, the training efficiency challenge poses a limitation on both QNNs and quantum kernels, curbing their efficacy when applied to extensive datasets. To confront this concern, we present a unified approach: coreset selection, aimed at expediting the training of QNNs and quantum kernels by distilling a judicious subset from the original training dataset. Furthermore, we analyze the generalization error bounds of QNNs and quantum kernels when trained on such coresets, unveiling the comparable performance with those training on the complete original dataset. Through systematic numerical simulations, we illuminate the potential of coreset selection in expediting tasks encompassing synthetic data classification, identification of quantum co
    
[^10]: 傅里叶变换和软阈值的领域泛化方法

    Domain Generalization with Fourier Transform and Soft Thresholding. (arXiv:2309.09866v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2309.09866](http://arxiv.org/abs/2309.09866)

    本研究提出了一种基于傅里叶变换和软阈值的领域泛化方法，用于提高神经网络在不同源上的视网膜底图图像分割任务中的性能。

    

    领域泛化旨在训练模型以适应多个源领域，并实现对未见过的目标领域的良好泛化能力。在许多领域泛化方法中，基于傅里叶变换的方法因为利用傅里叶变换来捕捉数据中的重要模式和规律，从而使模型对领域转移更加鲁棒而备受青睐。主流的基于傅里叶变换的领域泛化方法在源图像和目标图像之间交换傅里叶幅度谱，同时保留相位谱。然而，它忽略了幅度谱中的背景干扰。为了克服这个局限性，我们在傅里叶域引入了一个软阈值函数。我们将这个新设计的算法应用于视网膜底图图像分割，这对于诊断眼科疾病很重要，但由于领域转移，神经网络在不同源上的性能可能会下降。

    Domain generalization aims to train models on multiple source domains so that they can generalize well to unseen target domains. Among many domain generalization methods, Fourier-transform-based domain generalization methods have gained popularity primarily because they exploit the power of Fourier transformation to capture essential patterns and regularities in the data, making the model more robust to domain shifts. The mainstream Fourier-transform-based domain generalization swaps the Fourier amplitude spectrum while preserving the phase spectrum between the source and the target images. However, it neglects background interference in the amplitude spectrum. To overcome this limitation, we introduce a soft-thresholding function in the Fourier domain. We apply this newly designed algorithm to retinal fundus image segmentation, which is important for diagnosing ocular diseases but the neural network's performance can degrade across different sources due to domain shifts. The proposed 
    
[^11]: 通过强化学习实现离散一致性闭塞方案用于大涡模拟

    Toward Discretization-Consistent Closure Schemes for Large Eddy Simulation Using Reinforcement Learning. (arXiv:2309.06260v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2309.06260](http://arxiv.org/abs/2309.06260)

    本研究提出了一种使用强化学习方法开发离散一致性闭塞方案的新方法，其中将大涡模拟中的闭塞模型系数调整任务定义为马尔可夫决策过程，通过后期的强化学习解决。这一方法能够将模型调整到实际的离散化中并考虑离散化和模型本身之间的相互作用。通过优化显式和隐式闭塞模型中的局部涡粘度模型和混合策略，实现了闭塞模型的优化。

    

    我们提出了一种新的方法来开发用于隐式滤波的大涡模拟（LES）中的离散一致性闭塞方案。在隐式滤波的LES中，感应滤波核和闭塞项是由网格和离散化操作符的性质决定的，从而产生额外的未知计算细网项。因此，将LES闭塞模型的系数调整任务定义为马尔可夫决策过程，并通过强化学习在后期解决。这允许将模型调整到实际的离散化中，同时还包括离散化和模型本身之间的相互作用。这个优化框架应用于显式和隐式闭塞模型。通过优化局部涡粘度模型作为显式模型，通过强化学习来识别混合不连续G的最优混合策略。

    We propose a novel method for developing discretization-consistent closure schemes for implicitly filtered Large Eddy Simulation (LES). In implicitly filtered LES, the induced filter kernel, and thus the closure terms, are determined by the properties of the grid and the discretization operator, leading to additional computational subgrid terms that are generally unknown in a priori analysis. Therefore, the task of adapting the coefficients of LES closure models is formulated as a Markov decision process and solved in an a posteriori manner with Reinforcement Learning (RL). This allows to adjust the model to the actual discretization as it also incorporates the interaction between the discretization and the model itself. This optimization framework is applied to both explicit and implicit closure models. An element-local eddy viscosity model is optimized as the explicit model. For the implicit modeling, RL is applied to identify an optimal blending strategy for a hybrid discontinuous G
    
[^12]: AmbientFlow: 来自不完整、噪声测量的可逆生成模型

    AmbientFlow: Invertible generative models from incomplete, noisy measurements. (arXiv:2309.04856v1 [cs.LG])

    [http://arxiv.org/abs/2309.04856](http://arxiv.org/abs/2309.04856)

    AmbientFlow是一个从噪声和不完整数据中直接学习基于流的生成模型的新框架，通过使用变分贝叶斯方法来建立这种模型，展示了其在图像科学中的应用潜力。

    

    生成模型在图像科学中具有潜在的应用，如图像重建、后验采样和数据共享。基于流的生成模型特别有吸引力，因为它们能以可行的方式提供精确的密度估计以及快速、廉价和多样的样本。然而，训练这样的模型需要一个大型、高质量的对象数据集。在计算成像等应用中，由于需要长时间获取或高辐射剂量，往往难以获取这样的数据，而获取这些对象的噪声或部分观测测量更可行。在这项工作中，我们提出了AmbientFlow，一个从噪声和不完整数据直接学习基于流的生成模型的框架。使用变分贝叶斯方法，提出了一个从噪声、不完整数据建立基于流的生成模型的新框架。广泛的数值研究证明了该方法的有效性。

    Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness o
    
[^13]: 自适应自监督表示到多领域设置中

    Adapting Self-Supervised Representations to Multi-Domain Setups. (arXiv:2309.03999v1 [cs.CV])

    [http://arxiv.org/abs/2309.03999](http://arxiv.org/abs/2309.03999)

    该论文提出了一种通用的、轻量级的领域解缠模块（DDM），可以在多个不同领域上进行有效的自监督表示学习，并显示出较高的线性探测准确率提升。

    

    当在单个领域上训练时，当前最先进的自监督方法非常有效，但在未知领域上的泛化能力有限。我们观察到，即使在混合领域上进行训练，这些模型的泛化能力也很差，因此不适合在多样化的真实世界环境中部署。因此，我们提出了一个通用、轻量级的领域解缠模块（DDM），可以插入到任何自监督编码器中，在具有或不具有共享类的多个不同领域上有效地进行表示学习。在自监督损失的预训练过程中，DDM通过分割表示空间为领域变体和领域不变部分来强制实现表示空间中的解缠。当没有领域标签可用时，DDM使用强健的聚类方法来发现伪领域。我们展示了使用DDM进行预训练可以在最先进的自监督模型上显示出高达3.5%的线性探测准确率的提升。

    Current state-of-the-art self-supervised approaches, are effective when trained on individual domains but show limited generalization on unseen domains. We observe that these models poorly generalize even when trained on a mixture of domains, making them unsuitable to be deployed under diverse real-world setups. We therefore propose a general-purpose, lightweight Domain Disentanglement Module (DDM) that can be plugged into any self-supervised encoder to effectively perform representation learning on multiple, diverse domains with or without shared classes. During pre-training according to a self-supervised loss, DDM enforces a disentanglement in the representation space by splitting it into a domain-variant and a domain-invariant portion. When domain labels are not available, DDM uses a robust clustering approach to discover pseudo-domains. We show that pre-training with DDM can show up to 3.5% improvement in linear probing accuracy on state-of-the-art self-supervised models including 
    
[^14]: Norm调整：大型语言模型的高性能低比特量化

    Norm Tweaking: High-performance Low-bit Quantization of Large Language Models. (arXiv:2309.02784v1 [cs.LG])

    [http://arxiv.org/abs/2309.02784](http://arxiv.org/abs/2309.02784)

    本文介绍了一种称为“norm tweaking”的技术，通过调整量化的激活分布来实现高精度的低比特量化，以提高大型语言模型的压缩性能。

    

    随着大型语言模型（LLMs）的尺寸不断增大，在保持精度的前提下进行模型压缩已成为部署的关键挑战。虽然一些量化方法，如GPTQ，在实现可接受的4比特权重量化方面取得了进展，但尝试更低位的量化往往导致严重的性能降低。在本文中，我们引入了一种称为“norm tweaking”的技术，它可以作为当前PTQ方法的插件，实现高精度和成本高效。我们的方法受到一项观察的启示，即使调整量化的激活分布以与其浮点对应物匹配，也可以恢复LLMs的准确性。为了实现这一点，我们精心设计了一个调整策略，包括生成校准数据和通道距离约束，以更新归一化层的权重以获得更好的泛化性能。我们在各种数据集上进行了大量实验，使用了几个开源的LLMs。

    As the size of large language models (LLMs) continues to grow, model compression without sacrificing accuracy has become a crucial challenge for deployment. While some quantization methods, such as GPTQ, have made progress in achieving acceptable 4-bit weight-only quantization, attempts at lower bit quantization often result in severe performance degradation. In this paper, we introduce a technique called norm tweaking, which can be used as a plugin in current PTQ methods to achieve high precision while being cost-efficient. Our approach is inspired by the observation that rectifying the quantized activation distribution to match its float counterpart can readily restore accuracy for LLMs. To achieve this, we carefully design a tweaking strategy that includes calibration data generation and channel-wise distance constraint to update the weights of normalization layers for better generalization. We conduct extensive experiments on various datasets using several open-sourced LLMs. Our me
    
[^15]: 关于贝叶斯实验设计中期望信息增益梯度的估计

    On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design. (arXiv:2308.09888v1 [stat.ML])

    [http://arxiv.org/abs/2308.09888](http://arxiv.org/abs/2308.09888)

    该论文提出了一种估计贝叶斯实验设计中期望信息增益梯度的方法，通过结合随机梯度下降算法，实现了高效优化。具体而言，通过后验期望表示来估计与设计变量相关的梯度，并提出了UEEG-MCMC和BEEG-AP两种估计方法。这些方法在不同的实验设计问题上都表现出良好的性能。

    

    贝叶斯实验设计旨在找到贝叶斯推断的最佳实验条件，通常被描述为优化期望信息增益（EIG）。为了高效地优化EIG，往往需要梯度信息，因此估计EIG的梯度能力对于贝叶斯实验设计问题至关重要。该工作的主要目标是开发估计EIG梯度的方法，结合随机梯度下降算法，实现EIG的高效优化。具体而言，我们首先介绍了与设计变量相关的EIG梯度的后验期望表示。基于此，我们提出了两种估计EIG梯度的方法，UEEG-MCMC利用通过马尔科夫链蒙特卡洛（MCMC）生成的后验样本来估计EIG梯度，而BEEG-AP则专注于通过反复使用参数样本来实现高模拟效率。理论分析和数值实验表明，我们的方法在不同的实验设计问题上都能获得较好的性能。

    Bayesian Experimental Design (BED), which aims to find the optimal experimental conditions for Bayesian inference, is usually posed as to optimize the expected information gain (EIG). The gradient information is often needed for efficient EIG optimization, and as a result the ability to estimate the gradient of EIG is essential for BED problems. The primary goal of this work is to develop methods for estimating the gradient of EIG, which, combined with the stochastic gradient descent algorithms, result in efficient optimization of EIG. Specifically, we first introduce a posterior expected representation of the EIG gradient with respect to the design variables. Based on this, we propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate the EIG gradient, and BEEG-AP that focuses on achieving high simulation efficiency by repeatedly using parameter samples. Theoretical analysis and numerica
    
[^16]: 通过离散化引发的Dirichlet后验用于回归问题的鲁棒性不确定性量化

    Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression. (arXiv:2308.09065v1 [cs.CV])

    [http://arxiv.org/abs/2308.09065](http://arxiv.org/abs/2308.09065)

    本文提出了一种用于回归任务的广义AuxUE方案，目的是实现更鲁棒的不确定性量化。具体而言，该方案通过考虑不同的分布假设，选择Laplace分布来近似p，以实现更鲁棒的本质不确定性估计。

    

    在实际应用中，不确定性量化对于部署深度神经网络（DNNs）至关重要。辅助不确定性估计器（AuxUE）是一种在不修改主任务模型的情况下估计主任务预测不确定性的最有效手段之一。为了被认为是鲁棒的，AuxUE必须能够在遇到超出分布范围的输入时保持性能并引发更高的不确定性，即提供鲁棒的本质不确定性和认识不确定性。然而，对于视觉回归任务，当前的AuxUE设计主要用于本质不确定性估计，并且尚未探索AuxUE的鲁棒性。在这项工作中，我们提出了一种用于回归任务的更鲁棒不确定性量化的广义AuxUE方案。具体而言，为了实现更鲁棒的本质不确定性估计，在异方差噪声方面考虑了不同的分布假设，并最终选择Laplace分布来近似p

    Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the p
    
[^17]: PMET: 在Transformer中的精确模型编辑

    PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])

    [http://arxiv.org/abs/2308.08742](http://arxiv.org/abs/2308.08742)

    该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。

    

    模型编辑技术可以以较低的成本修改大型语言模型中的少量知识，并且已经取得了显著的成功。现有方法假设Transformer层隐藏状态是前馈网络的键值内存的值。它们通常优化Transformer层隐藏状态来记忆目标知识，并将其用于更新大型语言模型中前馈网络的权重。然而，Transformer层隐藏状态的信息流来自三个部分：多头自注意力、前馈网络和残差连接。现有方法忽视了Transformer层隐藏状态包含了前馈网络特别需要的信息这一事实。因此，模型编辑的性能下降。为了实现更精确的模型编辑，我们分析了多头自注意力和前馈网络的隐藏状态，发现多头自注意力编码了某些通用知识提取模式。这意味着当引入新知识时，多头自注意力的权重不需要更新。

    Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
    
[^18]: 通过选择性突触减弱实现快速的机器遗忘无需重新训练

    Fast Machine Unlearning Without Retraining Through Selective Synaptic Dampening. (arXiv:2308.07707v1 [cs.LG])

    [http://arxiv.org/abs/2308.07707](http://arxiv.org/abs/2308.07707)

    选择性突触减弱（SSD）是快速、性能优越且无需重新训练的机器遗忘方法，能够同时保护模型的性能并遗忘特定信息。

    

    机器遗忘，即机器学习模型的遗忘能力，正在越来越重要，以便符合数据隐私法规，并删除有害、篡改或过时的信息。关键挑战在于在保护模型在其余数据上的性能的同时遗忘特定信息。虽然目前的最先进方法表现良好，但通常需要在保留数据上进行某种程度的重新训练，以保护或恢复模型性能。这增加了计算开销，并要求训练数据保持可用和可访问，这可能并不可行。相反，其他方法采用无需重新训练的范式，但这些方法在计算上代价过高，并且性能不及重新训练的对应方法。我们提出选择性突触减弱（SSD），一种新颖的两步后验、无需重新训练的机器遗忘方法，快速、性能优越，并且不需要长时间的模型训练。

    Machine unlearning, the ability for a machine learning model to forget, is becoming increasingly important to comply with data privacy regulations, as well as to remove harmful, manipulated, or outdated information. The key challenge lies in forgetting specific information while protecting model performance on the remaining data. While current state-of-the-art methods perform well, they typically require some level of retraining over the retained data, in order to protect or restore model performance. This adds computational overhead and mandates that the training data remain available and accessible, which may not be feasible. In contrast, other methods employ a retrain-free paradigm, however, these approaches are prohibitively computationally expensive and do not perform on par with their retrain-based counterparts. We present Selective Synaptic Dampening (SSD), a novel two-step, post hoc, retrain-free approach to machine unlearning which is fast, performant, and does not require lon
    
[^19]: PUG:用于表示学习的逼真且语义可控的合成数据

    PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning. (arXiv:2308.03977v1 [cs.CV])

    [http://arxiv.org/abs/2308.03977](http://arxiv.org/abs/2308.03977)

    我们提出了一种使用逼真且语义可控的合成数据的方法，用于表示学习研究，该方法具有渲染所需数量的数据样本、精确控制场景和分布转变以及精细的真实标签的优点。

    

    合成图像数据集在设计和评估深度神经网络方面具有独特的优势：它们可以渲染所需数量的数据样本，精确控制每个场景并提供精细的真实标签（和标题），并可以精确控制训练和测试之间的分布转变，以隔离感兴趣的变量进行可靠实验。尽管具有如此优势，但合成图像数据的使用仍受限制，并且通常由于其缺乏真实性而被忽视。因此，大多数工作仍依赖于来自互联网上公开图像的真实图像数据集，并且可能存在隐私、偏见和版权问题，且对于对象的精确呈现方式控制能力较小。在这项工作中，我们提出了利用逼真的合成数据解决该问题的途径：我们开发了一种用于表示学习研究的新一代交互环境，提供了可控性和逼真度。

    Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and r
    
[^20]: 生成人工智能的强化学习：现状、机会和开放研究挑战

    Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges. (arXiv:2308.00031v1 [cs.LG])

    [http://arxiv.org/abs/2308.00031](http://arxiv.org/abs/2308.00031)

    这篇论文调查了在生成人工智能中应用强化学习的现状、机会和开放研究问题。作者主要讨论了三种应用类型：无特定目标的生成方式、同时最大化目标函数的输出生成方式以及将无法通过目标函数捕捉的期望特征嵌入生成过程的方式。这个新兴领域中存在着丰富的机会和挑战。

    

    生成人工智能（AI）是近十年来计算机科学领域最令人兴奋的发展之一。与此同时，强化学习（RL）在各种机器学习任务中已经成为非常成功的范式。在本调查中，我们讨论了将RL应用于生成AI中的现状、机会和开放的研究问题。具体而言，我们将讨论三种应用类型，即作为一种无特定目标的生成方式，作为一种同时最大化目标函数的输出生成方式，以及作为一种将无法通过目标函数轻松捕捉的期望特征嵌入生成过程的方式。我们在调查结果中对这个迷人的新兴领域中的机会和挑战进行了深入的讨论。

    Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.
    
[^21]: 大数据-供应链管理框架的预测：数据预处理和机器学习技术

    Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])

    [http://arxiv.org/abs/2307.12971](http://arxiv.org/abs/2307.12971)

    本文介绍了一种新的大数据-供应链管理框架，通过数据预处理和机器学习技术实现供应链预测，优化操作管理、透明度，并讨论了幻影库存对预测的不利影响。

    

    本文旨在系统地识别和比较分析最先进的供应链预测策略和技术。提出了一个新的框架，将大数据分析应用于供应链管理中，包括问题识别、数据来源、探索性数据分析、机器学习模型训练、超参数调优、性能评估和优化，以及预测对人力、库存和整个供应链的影响。首先讨论了根据供应链策略收集数据的需求以及如何收集数据。文章讨论了根据周期或供应链目标需要不同类型的预测。推荐使用供应链绩效指标和误差测量系统来优化表现最佳的模型。还讨论了幻影库存对预测的不利影响以及管理决策依赖供应链绩效指标来确定模型性能参数和改进运营管理、透明度的问题。

    This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
    
[^22]: TwinLiteNet：自动驾驶汽车中可驱动区域和车道分割的高效轻量模型

    TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars. (arXiv:2307.10705v1 [cs.CV])

    [http://arxiv.org/abs/2307.10705](http://arxiv.org/abs/2307.10705)

    本文提出了一种轻量级模型TwinLiteNet，用于自动驾驶车辆中的可驱动区域和车道分割。该模型成本低廉且高效准确，并在实验中表现出明显的计算资源节约。

    

    语义分割是自动驾驶中一个常见的任务，用于理解周围环境。对于道路上的安全和高效导航来说，可驱动区域分割和车道检测尤为重要。然而，原始的语义分割模型计算开销大，需要高端硬件，这对于嵌入式系统的自动驾驶车辆来说是不可行的。本文提出了一种轻量级的可驱动区域和车道线分割模型。TwinLiteNet设计成成本低廉，但能够实现准确和高效的分割结果。我们在BDD100K数据集上评估了TwinLiteNet，并与现代模型进行了比较。实验结果表明，我们的TwinLiteNet与现有方法表现相似，但所需的计算资源显著减少。具体而言，TwinLiteNet在可驱动区域任务上实现了91.3%的mIoU评分，在车道检测任务上实现了31.08%的IoU评分，仅使用了40万个参数，在GPU RTX上实现了415 FPS。

    Semantic segmentation is a common task in autonomous driving to understand the surrounding environment. Driveable Area Segmentation and Lane Detection are particularly important for safe and efficient navigation on the road. However, original semantic segmentation models are computationally expensive and require high-end hardware, which is not feasible for embedded systems in autonomous vehicles. This paper proposes a lightweight model for the driveable area and lane line segmentation. TwinLiteNet is designed cheaply but achieves accurate and efficient segmentation results. We evaluate TwinLiteNet on the BDD100K dataset and compare it with modern models. Experimental results show that our TwinLiteNet performs similarly to existing approaches, requiring significantly fewer computational resources. Specifically, TwinLiteNet achieves a mIoU score of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task with only 0.4 million parameters and achieves 415 FPS on GPU RTX 
    
[^23]: LLQL: 逻辑似然 Q-Learning 用于增强学习

    LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02345](http://arxiv.org/abs/2307.02345)

    本研究通过研究在线和离线增强学习中 Bellman 近似误差的分布发现，Bellman 误差符合逻辑分布。基于这一发现，本研究提出了一种使用 Logistic 最大似然函数作为替代方法的方案，并通过实验证明了其有效性。

    

    现代增强学习（RL）可以分为在线和离线两种变体。作为在线和离线 RL 的关键方面，当前对 Bellman 方程的研究主要集中在优化技术和性能增强上，而不是探索 Bellman 误差的固有结构特性，如其分布特征。本研究通过对 Bellman 方程进行迭代探索，研究了在线 RL 和离线 RL 中 Bellman 近似误差的分布情况。我们观察到无论是在线 RL 还是离线 RL，Bellman 误差都符合逻辑分布。基于这一发现，本研究采用 Logistic 最大似然函数（LLoss）作为常用的 MSE Loss 的替代方法，假设 Bellman 误差服从正态分布。通过广泛的数值实验验证了我们的假设，在不同的在线和离线环境中得到了验证。

    Modern reinforcement learning (RL) can be categorized into online and offline variants. As a pivotal aspect of both online and offline RL, current research on the Bellman equation revolves primarily around optimization techniques and performance enhancement rather than exploring the inherent structural properties of the Bellman error, such as its distribution characteristics. This study investigates the distribution of the Bellman approximation error in both online and offline settings through iterative exploration of the Bellman equation. We observed that both in online RL and offline RL, the Bellman error conforms to a Logistic distribution. Building upon this discovery, this study employed the Logistics maximum likelihood function (LLoss) as an alternative to the commonly used MSE Loss, assuming that Bellman errors adhere to a normal distribution. We validated our hypotheses through extensive numerical experiments across diverse online and offline environments. In particular, we app
    
[^24]: 通过通用鲁棒嵌入实现分类数据的可转移对抗鲁棒性

    Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings. (arXiv:2306.04064v1 [cs.LG])

    [http://arxiv.org/abs/2306.04064](http://arxiv.org/abs/2306.04064)

    本文提出一种方法，通过自编码器生成通用鲁棒嵌入，将分类数据转换为向量，从而实现对抗训练，提高分类器的鲁棒性，并在多个数据集上取得了最先进的对抗鲁棒性性能表现。

    

    很多场景下，对分类数据的鲁棒性需要更高的关注度。然而，分类数据具有类别特征，现有的优化程序无法直接解决这个问题。本文提出一种方法，利用自编码器生成通用鲁棒嵌入，将分类数据转化到一个空间中，并实现对抗训练，从而提高分类器的鲁棒性，并保持对于干净数据高分类准确度。结果表明，本文方法应用在不同的分类数据集上时，具有最先进的对抗鲁棒性能力。

    Research on adversarial robustness is primarily focused on image and text data. Yet, many scenarios in which lack of robustness can result in serious risks, such as fraud detection, medical diagnosis, or recommender systems often do not rely on images or text but instead on tabular data. Adversarial robustness in tabular data poses two serious challenges. First, tabular datasets often contain categorical features, and therefore cannot be tackled directly with existing optimization procedures. Second, in the tabular domain, algorithms that are not based on deep networks are widely used and offer great performance, but algorithms to enhance robustness are tailored to neural networks (e.g. adversarial training).  In this paper, we tackle both challenges. We present a method that allows us to train adversarially robust deep networks for tabular data and to transfer this robustness to other classifiers via universal robust embeddings tailored to categorical data. These embeddings, created u
    
[^25]: 利用Jarzynski平等式高效训练能量基模型

    Efficient Training of Energy-Based Models Using Jarzynski Equality. (arXiv:2305.19414v1 [cs.LG])

    [http://arxiv.org/abs/2305.19414](http://arxiv.org/abs/2305.19414)

    本文介绍了一种通过使用Jarzynski平等式和顺序蒙特卡罗采样绕过标准对比散度算法中的不可控逼近误差，有效训练能量基模型的方法。

    

    能量基模型是受统计物理启发的生成模型，在无监督学习中有广泛应用。模型分布相对于数据分布的交叉熵是衡量它们性能的最佳指标。然而，使用交叉熵作为训练目标挑战重重，因为它对于模型参数的梯度计算需要对模型分布进行采样。在这里，我们展示了基于Jarzynski等式的非平衡热力学结果，结合顺序蒙特卡罗采样工具，可以有效地进行计算，避免使用标准对比散度算法所产生的不可控逼近误差。具体而言，我们介绍了未调整Langevin算法的修改版本，在其中每个Walker都会获得一个权重，使得能够在任何步骤时估计交叉熵的梯度，从而规避由采样偏差导致的问题。

    Energy-based models (EBMs) are generative models inspired by statistical physics with a wide range of applications in unsupervised learning. Their performance is best measured by the cross-entropy (CE) of the model distribution relative to the data distribution. Using the CE as the objective for training is however challenging because the computation of its gradient with respect to the model parameters requires sampling the model distribution. Here we show how results for nonequilibrium thermodynamics based on Jarzynski equality together with tools from sequential Monte-Carlo sampling can be used to perform this computation efficiently and avoid the uncontrolled approximations made using the standard contrastive divergence algorithm. Specifically, we introduce a modification of the unadjusted Langevin algorithm (ULA) in which each walker acquires a weight that enables the estimation of the gradient of the cross-entropy at any step during GD, thereby bypassing sampling biases induced by
    
[^26]: 异构群体强化学习中的福音：线性加速和更多可能

    The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond. (arXiv:2305.10697v1 [cs.LG])

    [http://arxiv.org/abs/2305.10697](http://arxiv.org/abs/2305.10697)

    本文提出了异构群体强化学习中联邦Q学习的样本复杂度保证，讨论了同步和异步版本的线性加速，同时探究了等权重平均本地Q估计的缺陷。

    

    当强化学习（RL）的数据由多个代理以分布式方式收集时，联邦RL算法允许协作学习，无需共享本地数据。本文考虑联邦Q学习，其目的是通过定期聚合仅在本地数据上训练的本地Q估计来学习最优Q函数。针对无限时间蒸馏标记决策过程，我们为同步和异步版本的联邦Q学习提供了样本复杂度保证。在两种情况下，我们的界限展示了与代理数量成线性加速以及其他显著问题参数的更尖锐的依赖关系。此外，现有的联邦Q学习方法采用等权重平均本地Q估计，这在异步设置中可能会高度次优，因为由于不同的本地行为策略，本地轨迹可能高度异构。现有的样本最优化策略在异步设置中存在巨大缺陷。

    When the data used for reinforcement learning (RL) are collected by multiple agents in a distributed manner, federated versions of RL algorithms allow collaborative learning without the need of sharing local data. In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning. In both cases, our bounds exhibit a linear speedup with respect to the number of agents and sharper dependencies on other salient problem parameters. Moreover, existing approaches to federated Q-learning adopt an equally-weighted averaging of local Q-estimates, which can be highly sub-optimal in the asynchronous setting since the local trajectories can be highly heterogeneous due to different local behavior policies. Existing sample com
    
[^27]: 使用永续学习技术加速批次主动学习

    Accelerating Batch Active Learning Using Continual Learning Techniques. (arXiv:2305.06408v1 [cs.LG])

    [http://arxiv.org/abs/2305.06408](http://arxiv.org/abs/2305.06408)

    本文介绍了一种新的技术，即永续性主动学习（CAL），通过偏向先前标记集来加速训练，通过使用一系列回放方案，包括模型蒸馏和从历史中选择多样化的和不确定的点。实验结果表明，CAL可以大幅提升训练速度。

    

    主动学习（AL）的一个主要问题是训练成本很高，因为模型通常在每个查询轮之后都要从头开始重新训练。本文首先演示了使用预热启动的标准神经网络进行AL的失败，既不能加速训练，又不能避免在AL查询轮上使用微调时发生灾难性遗忘。然后，我们开发了一类新的技术，通过偏向先前标记集来加速训练。我们通过使用现有的和发展新的基于回放的永续学习（CL）算法实现这一点，这些算法在快速学习新知识而不遗忘老知识的情况下，在数据来自不断变化的分布时特别有效。我们将这一范例称为“永续性主动学习”（CAL）。我们展示了CAL通过使用大量的回放方案来实现显著的加速效果，这些方案使用模型蒸馏并从历史中选择多样化的和不确定的点。我们在许多数据领域进行了实验，包括自然

    A major problem with Active Learning (AL) is high training costs since models are typically retrained from scratch after every query round. We start by demonstrating that standard AL on neural networks with warm starting fails, both to accelerate training and to avoid catastrophic forgetting when using fine-tuning over AL query rounds. We then develop a new class of techniques, circumventing this problem, by biasing further training towards previously labeled sets. We accomplish this by employing existing, and developing novel, replay-based Continual Learning (CL) algorithms that are effective at quickly learning the new without forgetting the old, especially when data comes from an evolving distribution. We call this paradigm Continual Active Learning (CAL). We show CAL achieves significant speedups using a plethora of replay schemes that use model distillation and that select diverse, uncertain points from the history. We conduct experiments across many data domains, including natura
    
[^28]: 细胞水平的功能性组织单元半监督分割方法

    Semi-Supervised Segmentation of Functional Tissue Units at the Cellular Level. (arXiv:2305.02148v1 [eess.IV])

    [http://arxiv.org/abs/2305.02148](http://arxiv.org/abs/2305.02148)

    通过利用最新的深度学习语义分割、领域适配和半监督学习技术，该研究提出了一种半监督分割方法，可在细胞水平上对功能性组织单元进行分割，并取得了先进水平的结果。

    

    我们提出了一种新的半监督学习技术与领域自适应的深度学习语义分割方法，用于细胞水平的功能性组织单元分割。该方法利用深度学习语义分割方法、领域自适应和半监督学习技术，可最小化HPA和HubMAP数据集之间的领域差异、类别不平衡和捕获设置影响。所提出的方法在功能性组织单元在细胞水平的分割方面，达到了与现有先进方法可比拟的结果。源代码可在 https://github.com/VSydorskyy/hubmap_2022_htt_solution 上获取。

    We present a new method for functional tissue unit segmentation at the cellular level, which utilizes the latest deep learning semantic segmentation approaches together with domain adaptation and semi-supervised learning techniques. This approach allows for minimizing the domain gap, class imbalance, and captures settings influence between HPA and HubMAP datasets. The presented approach achieves comparable with state-of-the-art-result in functional tissue unit segmentation at the cellular level. The source code is available at https://github.com/VSydorskyy/hubmap_2022_htt_solution
    
[^29]: SSL模型是否感到“似曾相识”？自监督学习中的意外记忆

    Do SSL Models Have D\'ej\`a Vu? A Case of Unintended Memorization in Self-supervised Learning. (arXiv:2304.13850v1 [cs.CV])

    [http://arxiv.org/abs/2304.13850](http://arxiv.org/abs/2304.13850)

    自监督学习（SSL）算法会意外地记忆单个训练样本中的特定部分，称为“似曾相识”记忆，该现象是普遍存在的，不能被传统的评估方法检测。

    

    自监督学习（SSL）算法可以通过学习将自然图像的不同部分相互关联来产生有用的图像表示。然而，当被推向极端时，SSL模型会意外地记忆单个训练样本中的特定部分，而不是学习有意义的语义关联。在本研究中，我们对SSL模型中的意外记忆现象进行了系统研究，我们称之为“似曾相识”记忆。具体而言，我们展示了在给定训练模型和一个仅包含背景（如水、天空、草地）的训练图像裁剪后，可以高精度或甚至视觉重构地推断出前景对象。此外，我们展示了“似曾相识”记忆是不同SSL算法的普遍现象，并且会因某些设计选择而恶化，而且不能通过传统的评估表示质量的技术来检测。“似曾相识”记忆的研究

    Self-supervised learning (SSL) algorithms can produce useful image representations by learning to associate different parts of natural images with one another. However, when taken to the extreme, SSL models can unintendedly memorize specific parts in individual training samples rather than learning semantically meaningful associations. In this work, we perform a systematic study of the unintended memorization of image-specific information in SSL models -- which we refer to as d\'ej\`a vu memorization. Concretely, we show that given the trained model and a crop of a training image containing only the background (e.g., water, sky, grass), it is possible to infer the foreground object with high accuracy or even visually reconstruct it. Furthermore, we show that d\'ej\`a vu memorization is common to different SSL algorithms, is exacerbated by certain design choices, and cannot be detected by conventional techniques for evaluating representation quality. Our study of d\'ej\`a vu memorizatio
    
[^30]: 学习在无线联邦学习中具有可证明保障的发射

    Learning to Transmit with Provable Guarantees in Wireless Federated Learning. (arXiv:2304.09329v1 [cs.LG])

    [http://arxiv.org/abs/2304.09329](http://arxiv.org/abs/2304.09329)

    该研究提出了一种数据驱动方法，用于分配联邦学习中的发射功率，以优化通信约束下FL过程中服务器端接收到的信息，并提高全局FL模型的准确性和效率。

    

    我们提出了一种新的数据驱动方法，用于分配联邦学习中的发射功率，适用于干扰受限无线网络中的挑战性情景，如FL训练过程中无线信道正在变化以及本地设备上的训练数据不是独立且同分布的情况下。直观来说，功率策略旨在优化通信约束下FL过程中服务器端接收到的信息。我们的目标是提高全局FL模型的准确性和效率。该策略使用图卷积网络进行参数化，并通过原始-对偶算法求解相关的约束优化问题。从理论上讲，我们表明了制定问题具有零对偶间隙，并且一旦参数化功率策略，则最优性取决于此参数化的表达能力。数值上，我们使用实际的无线数据集评估了方法的性能，并证明了其优于传统的功率分配方法。

    We propose a novel data-driven approach to allocate transmit power for federated learning (FL) over interference-limited wireless networks. The proposed method is useful in challenging scenarios where the wireless channel is changing during the FL training process and when the training data are not independent and identically distributed (non-i.i.d.) on the local devices. Intuitively, the power policy is designed to optimize the information received at the server end during the FL process under communication constraints. Ultimately, our goal is to improve the accuracy and efficiency of the global FL model being trained. The proposed power allocation policy is parameterized using a graph convolutional network and the associated constrained optimization problem is solved through a primal-dual (PD) algorithm. Theoretically, we show that the formulated problem has zero duality gap and, once the power policy is parameterized, optimality depends on how expressive this parameterization is. Nu
    
[^31]: 利用稀疏和共享特征激活进行解缠表示学习

    Leveraging sparse and shared feature activations for disentangled representation learning. (arXiv:2304.07939v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.07939](http://arxiv.org/abs/2304.07939)

    本文提出了利用从多样化监督任务中提取的知识来学习通用的解缠表示的方法，使监督多任务模型的特征空间得以解缠，适当共享信息，达到可识别性。

    

    迄今为止，恢复高维数据的潜在变化因素一直集中在简单的合成环境中。在大多数基于无监督和弱监督目标的先前研究中，人们忽略了这对真实世界数据的表示学习的积极影响。在本研究中，我们建议利用从多样化监督任务中提取的知识来学习通用的解缠表示。我们假设每个监督任务仅依赖于未知因素的子集，我们将监督多任务模型的特征空间解缠，并在不同任务之间稀疏地激活特征并适当地共享信息。重要的是，我们从未直接观察到变异因素，但在充分性和最小性假设下，访问多个任务足以实现可识别性。我们在六个真实世界分布转移基准以及不同的数据模态（图像，文本）上验证了我们的方法。

    Recovering the latent factors of variation of high dimensional data has so far focused on simple synthetic settings. Mostly building on unsupervised and weakly-supervised objectives, prior work missed out on the positive implications for representation learning on real world data. In this work, we propose to leverage knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation. Assuming each supervised task only depends on an unknown subset of the factors of variation, we disentangle the feature space of a supervised multi-task model, with features activating sparsely across different tasks and information being shared as appropriate. Importantly, we never directly observe the factors of variations but establish that access to multiple tasks is sufficient for identifiability under sufficiency and minimality assumptions. We validate our approach on six real world distribution shift benchmarks, and different data modalities (images, text), 
    
[^32]: 使用线性互补编程的时序符合预测区间

    Conformal Prediction Regions for Time Series using Linear Complementarity Programming. (arXiv:2304.01075v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2304.01075](http://arxiv.org/abs/2304.01075)

    本文提出了一种基于优化的方法，通过将预测误差参数化为多个时间步长，以找到不保守的预测区间，实现在使用学习启用的时间序列预测器进行长期规划和验证。

    

    符合预测是一种用于生成机器学习模型预测区间的统计工具，其具有高概率有效性。然而，将符合预测应用于时间序列数据会导致保守的预测区间。本文提出了一种基于优化的方法来减少这种保守性，以便在使用学习启用的时间序列预测器进行长期规划和验证。我们将预测误差参数化为多个时间步长，通过对额外数据集上的参数进行优化，找到了不保守的预测区间。我们表明，该问题可以被看作是一个混合整数线性互补规划（MILCP），我们将其放宽为一个线性互补规划（LCP）。

    Conformal prediction is a statistical tool for producing prediction regions of machine learning models that are valid with high probability. However, applying conformal prediction to time series data leads to conservative prediction regions. In fact, to obtain prediction regions over $T$ time steps with confidence $1-\delta$, {previous works require that each individual prediction region is valid} with confidence $1-\delta/T$. We propose an optimization-based method for reducing this conservatism to enable long horizon planning and verification when using learning-enabled time series predictors. Instead of considering prediction errors individually at each time step, we consider a parameterized prediction error over multiple time steps. By optimizing the parameters over an additional dataset, we find prediction regions that are not conservative. We show that this problem can be cast as a mixed integer linear complementarity program (MILCP), which we then relax into a linear complementa
    
[^33]: 集成强化学习综述

    Ensemble Reinforcement Learning: A Survey. (arXiv:2303.02618v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02618](http://arxiv.org/abs/2303.02618)

    集成强化学习（ERL）是一种将强化学习（RL）与集成学习（EL）相结合的有前途的方法，旨在利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。

    

    强化学习（RL）已成为解决各种科学和应用问题的高效技术。尽管其取得了成功，但某些复杂任务仍难以仅使用单个模型和算法解决。作为响应，集成强化学习（ERL）作为一种有前途的方法，结合了RL和集成学习（EL）的优点，已经广泛受到欢迎。ERL利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。本研究旨在提供ERL的综合调查，以便为读者提供该领域的最新进展和挑战概述。首先，我们介绍ERL的背景和动机。其次，我们详细分析了成功应用于ERL中的策略，包括模型平均、模型选择和模型组合。随后，我们总结了相关数据集并分析了所使用的算法。

    Reinforcement Learning (RL) has emerged as a highly effective technique for addressing various scientific and applied problems. Despite its success, certain complex tasks remain challenging to be addressed solely with a single model and algorithm. In response, ensemble reinforcement learning (ERL), a promising approach that combines the benefits of both RL and ensemble learning (EL), has gained widespread popularity. ERL leverages multiple models or training algorithms to comprehensively explore the problem space and possesses strong generalization capabilities. In this study, we present a comprehensive survey on ERL to provide readers with an overview of recent advances and challenges in the field. First, we introduce the background and motivation for ERL. Second, we analyze in detail the strategies that have been successfully applied in ERL, including model averaging, model selection, and model combination. Subsequently, we summarize the datasets and analyze algorithms used in releva
    
[^34]: 对比与聚类：学习邻域对表示用于无源域自适应

    Contrast and Clustering: Learning Neighborhood Pair Representation for Source-free Domain Adaptation. (arXiv:2301.13428v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13428](http://arxiv.org/abs/2301.13428)

    本文提出了一个无源域适应的实用且具有挑战性的方案，通过在原始特征空间聚类，构建真正困难的负对，结合噪声对比估计理论，学习一个域不变的特征来解决域上的差异问题，能够在三个常见的基准数据集上实现有效结果。

    

    无监督域适应利用来自不同分布的源数据解决从未标记目标域分类数据的问题。然而，传统方法需要访问源数据，这经常引起数据隐私方面的担忧。本文中，我们考虑了一个更加实际但充满挑战的设置，在这个设置中，源域数据不可用，目标域数据未标记。具体而言，我们从对比学习的角度解决了域间差异问题。我们的工作的关键思想是通过以下方式学习一个域不变的特征:1)在原始特征空间中直接执行具有最近邻居的聚类；2)通过扩展邻居构造真正困难的负对，而不引入额外的计算复杂度；3)结合噪声对比估计理论以获得计算优势。我们在三个常见的基准数据集VisDA、Office-Home和Office-31上进行了仔细的消融研究和广泛的实验。

    Unsupervised domain adaptation uses source data from different distributions to solve the problem of classifying data from unlabeled target domains. However, conventional methods require access to source data, which often raise concerns about data privacy. In this paper, we consider a more practical but challenging setting where the source domain data is unavailable and the target domain data is unlabeled. Specifically, we address the domain discrepancy problem from the perspective of contrastive learning. The key idea of our work is to learn a domain-invariant feature by 1) performing clustering directly in the original feature space with nearest neighbors; 2) constructing truly hard negative pairs by extended neighbors without introducing additional computational complexity; and 3) combining noise-contrastive estimation theory to gain computational advantage. We conduct careful ablation studies and extensive experiments on three common benchmarks: VisDA, Office-Home, and Office-31. T
    
[^35]: 混合移动平均场引导的时空数据学习

    Mixed moving average field guided learning for spatio-temporal data. (arXiv:2301.00736v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.00736](http://arxiv.org/abs/2301.00736)

    本论文提出了一种理论引导机器学习方法，采用广义贝叶斯算法进行混合移动平均场引导的时空数据建模，可以进行因果未来预测。

    

    受到混合移动平均场的影响，时空数据的建模是一个多功能的技巧。但是，它们的预测分布通常不可访问。在这个建模假设下，我们定义了一种新的理论引导机器学习方法，采用广义贝叶斯算法进行预测。我们采用Lipschitz预测器（例如线性模型或前馈神经网络），并通过最小化沿空间和时间维度串行相关的数据的新型PAC贝叶斯界限来确定一个随机估计值。进行因果未来预测是我们方法的一个亮点，因为它适用于具有短期和长期相关性的数据。最后，我们通过展示线性预测器和模拟STOU过程的时空数据的示例来展示学习方法的性能。

    Influenced mixed moving average fields are a versatile modeling class for spatio-temporal data. However, their predictive distribution is not generally accessible. Under this modeling assumption, we define a novel theory-guided machine learning approach that employs a generalized Bayesian algorithm to make predictions. We employ a Lipschitz predictor, for example, a linear model or a feed-forward neural network, and determine a randomized estimator by minimizing a novel PAC Bayesian bound for data serially correlated along a spatial and temporal dimension. Performing causal future predictions is a highlight of our methodology as its potential application to data with short and long-range dependence. We conclude by showing the performance of the learning methodology in an example with linear predictors and simulated spatio-temporal data from an STOU process.
    
[^36]: 论小批量重球动量法的快速收敛性

    On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07553](http://arxiv.org/abs/2206.07553)

    本文研究了一种随机Kaczmarz算法，使用小批量和重球动量进行加速，在二次优化问题中保持快速收敛率。

    

    简单的随机动量方法被广泛用于机器学习优化中，但由于还没有加速的理论保证，这与它们在实践中的良好性能并不相符。本文旨在通过展示，随机重球动量在二次最优化问题中保持（确定性）重球动量的快速线性率，至少在使用足够大的批量大小进行小批量处理时。我们所研究的算法可以被解释为带小批量处理和重球动量的加速随机Kaczmarz算法。该分析依赖于仔细分解动量转移矩阵，并使用新的独立随机矩阵乘积的谱范围集中界限。我们提供了数值演示，证明了我们的界限相当尖锐。

    Simple stochastic momentum methods are widely used in machine learning optimization, but their good practical performance is at odds with an absence of theoretical guarantees of acceleration in the literature. In this work, we aim to close the gap between theory and practice by showing that stochastic heavy ball momentum retains the fast linear rate of (deterministic) heavy ball momentum on quadratic optimization problems, at least when minibatching with a sufficiently large batch size. The algorithm we study can be interpreted as an accelerated randomized Kaczmarz algorithm with minibatching and heavy ball momentum. The analysis relies on carefully decomposing the momentum transition matrix, and using new spectral norm concentration bounds for products of independent random matrices. We provide numerical illustrations demonstrating that our bounds are reasonably sharp.
    
[^37]: 使用区分特征度量下游分类的自监督表示质量

    Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features. (arXiv:2203.01881v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01881](http://arxiv.org/abs/2203.01881)

    从自监督学习模型中提取区分特征，并使用它们压缩表示空间，提出了一种Q-Score自监督表示质量分数，可以可靠地预测线性评估期间的错误分类。

    

    自监督学习在下游分类任务中展现出了惊人的结果。然而，对于它们的失败模式和学习表示的解释，存在着有限的研究。本文研究了 SimCLR、SwaV、MoCo、BYOL、DINO、SimSiam、VICReg 和 Barlow Twins 等最先进的自监督模型的表示空间。在不使用类标签信息的情况下，我们发现了对应于图像中独特物理属性的区分特征，这些区分特征主要存在于正确分类的表示中。使用这些特征，我们可以将表示空间压缩多达 40%，而不会显著影响线性分类性能。然后，我们提出了自监督表示质量分数（或 Q-Score），这是一种模型无关、无监督的分数，可以可靠地预测一个给定样本在线性评估期间是否可能被错误分类，并在 ImageNet-100 和 ImageNet-1K 上实现了 AUPRC 分别为 91.45 和 78.78。

    Self-supervised learning has shown impressive results in downstream classification tasks. However, there is limited work in understanding their failure modes and interpreting their learned representations. In this paper, we study the representation space of state-of-the-art self-supervised models including SimCLR, SwaV, MoCo, BYOL, DINO, SimSiam, VICReg and Barlow Twins. Without the use of class label information, we discover discriminative features that correspond to unique physical attributes in images, present mostly in correctly-classified representations. Using these features, we can compress the representation space by up to $40\%$ without significantly affecting linear classification performance. We then propose Self-Supervised Representation Quality Score (or Q-Score), a model-agnostic, unsupervised score that can reliably predict if a given sample is likely to be mis-classified during linear evaluation, achieving AUPRC of 91.45 on ImageNet-100 and 78.78 on ImageNet-1K. Q-Score
    
[^38]: 从单个图像和视频中生成新颖的场景组合

    Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2103.13389](http://arxiv.org/abs/2103.13389)

    本研究提出了SIV-GAN，一种无条件生成模型，可以从单个图像或视频中生成新的场景组合。通过引入内容和布局分支的鉴别器架构，该模型能够生成多样化、高质量的图像，并在保留上下文的同时保持视觉逼真。

    

    在训练数据集较大的情况下，生成对抗网络（GAN）可以在图像合成任务中取得显著的性能。然而，在极低数据环境中训练GAN仍然是一个挑战，因为往往会发生过拟合，导致记忆或训练发散。在本研究中，我们引入了SIV-GAN，这是一个无条件的生成模型，可以从单个训练图像或单个视频剪辑中生成新的场景组合。我们提出了一个具有内容和布局分支的两支鉴别器架构，分别设计用于判断内部内容和场景布局的真实性。这种鉴别器设计可以合成视觉上逼真、新颖的场景组合，具有不同的内容和布局，同时保留原始样本的上下文。与以前的单图像GAN相比，我们的模型生成了更多样化、质量更高的图像，同时不限于单个图像设置。我们进一步引入了一种新的具有挑战性的情况

    Given a large dataset for training, generative adversarial networks (GANs) can achieve remarkable performance for the image synthesis task. However, training GANs in extremely low data regimes remains a challenge, as overfitting often occurs, leading to memorization or training divergence. In this work, we introduce SIV-GAN, an unconditional generative model that can generate new scene compositions from a single training image or a single video clip. We propose a two-branch discriminator architecture, with content and layout branches designed to judge internal content and scene layout realism separately from each other. This discriminator design enables synthesis of visually plausible, novel compositions of a scene, with varying content and layout, while preserving the context of the original sample. Compared to previous single image GANs, our model generates more diverse, higher quality images, while not being restricted to a single image setting. We further introduce a new challengin
    
[^39]: 在延迟环境中以非固定马尔可夫策略行动

    Acting in Delayed Environments with Non-Stationary Markov Policies. (arXiv:2101.11992v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2101.11992](http://arxiv.org/abs/2101.11992)

    该论文介绍了在延迟环境中，学习和规划的马尔可夫决策过程(MDP)框架，证明了在延迟执行的情况下，原始状态空间中的非固定马尔可夫策略可以实现最大奖励，提出了一种解决延迟执行任务的非固定Q-learning风格算法。

    

    标准的马尔可夫决策过程(MDP)假设在选择动作后立即执行，但这种假设常常不切实际，会在机器人操纵、云计算和金融等应用中导致灾难性故障。我们引入了一个学习和计划的MDP框架，其中决策者选择的动作需要延迟$m$步才能执行。我们证明了在延迟执行的情况下，原始状态空间中的确定性马尔可夫策略足以实现最大奖励，但需要是非固定的。然而，我们还证明了固定的马尔可夫策略在一般情况下是次优的。因此，我们设计了一种非固定的基于模型的Q-learning风格算法，可以解决延迟执行任务。

    The standard Markov Decision Process (MDP) formulation hinges on the assumption that an action is executed immediately after it was chosen. However, assuming it is often unrealistic and can lead to catastrophic failures in applications such as robotic manipulation, cloud computing, and finance. We introduce a framework for learning and planning in MDPs where the decision-maker commits actions that are executed with a delay of $m$ steps. The brute-force state augmentation baseline where the state is concatenated to the last $m$ committed actions suffers from an exponential complexity in $m$, as we show for policy iteration. We then prove that with execution delay, deterministic Markov policies in the original state-space are sufficient for attaining maximal reward, but need to be non-stationary. As for stationary Markov policies, we show they are sub-optimal in general. Consequently, we devise a non-stationary Q-learning style model-based algorithm that solves delayed execution tasks wi
    

