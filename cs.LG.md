# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FP8-LM: Training FP8 Large Language Models.](http://arxiv.org/abs/2310.18313) | 本文提出了一种用于训练大语言模型的新型FP8自动混合精度框架，能够在不影响模型准确性的情况下显著减少内存使用并提高训练速度。 |
| [^2] | [Is Channel Independent strategy optimal for Time Series Forecasting?.](http://arxiv.org/abs/2310.17658) | 本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。 |
| [^3] | [Graph Attention-based Deep Reinforcement Learning for solving the Chinese Postman Problem with Load-dependent costs.](http://arxiv.org/abs/2310.15516) | 本论文提出了一个基于图注意力的深度强化学习方法来解决带有负载相关成本的中国邮递员问题。该方法将问题形式化为马尔可夫决策过程，引入了一个编码器和解码器的自回归模型来有效处理问题。 |
| [^4] | [Divide-and-Conquer Dynamics in AI-Driven Disempowerment.](http://arxiv.org/abs/2310.06009) | 这项研究通过构建游戏理论模型，研究了AI驱动的剥夺中的不团结问题。研究发现，当前受害者需要让未来受害者认识到他们的利益同样面临严重和紧迫的威胁，以激励未来受害者以团结支持当前受害者。 |
| [^5] | [Recurrent Neural Language Models as Probabilistic Finite-state Automata.](http://arxiv.org/abs/2310.05161) | 本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。 |
| [^6] | [Hire When You Need to: Gradual Participant Recruitment for Auction-based Federated Learning.](http://arxiv.org/abs/2310.02651) | GPS-AFL是一种基于拍卖的联邦学习渐进式参与者选择方案，通过在多轮训练中逐渐选择数据所有者，解决了冷启动问题和选择偏差对联邦学习的影响。 |
| [^7] | [One for All: Towards Training One Graph Model for All Classification Tasks.](http://arxiv.org/abs/2310.00149) | 这项研究提出了一种名为“一刀切”的通用框架，该框架能够使用单一图模型解决不同领域的多个任务。该框架克服了图学习领域的挑战，包括不同属性和分布的图数据、不同类型的任务以及上下文学习的问题。 |
| [^8] | [SEPT: Towards Efficient Scene Representation Learning for Motion Prediction.](http://arxiv.org/abs/2309.15289) | SEPT是一个利用自监督学习进行场景表示学习的建模框架，通过预训练的编码器捕捉轨迹的运动学特征、道路网络的空间结构以及道路和代理之间的交互作用，实现了在运动预测任务上的最先进性能。 |
| [^9] | [ICML 2023 Topological Deep Learning Challenge : Design and Results.](http://arxiv.org/abs/2309.15188) | 本文介绍了ICML 2023拓扑深度学习挑战，该挑战要求参与者在两个月内提供开源实现的拓扑神经网络，吸引了28个合格的提交。 |
| [^10] | [Physics-informed State-space Neural Networks for Transport Phenomena.](http://arxiv.org/abs/2309.12211) | 这项研究引入了物理信息触发状态空间神经网络模型（PSMs），用于解决在化学、生物医学和电厂等传输现象中实现实时优化和容错性的问题。通过使用传感器数据训练深度神经网络，并使用物理模型进行传输系统建模，PSMs提供了比传统数据驱动模型更准确的方法，并具有多种应用场景。 |
| [^11] | [Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks.](http://arxiv.org/abs/2309.11651) | 该论文提出了一种基于神经网络的计算方法，用于漂移控制高维RBMs。通过深度神经网络技术，该方法在测试问题上达到了较高的准确性。 |
| [^12] | [Ad-load Balancing via Off-policy Learning in a Content Marketplace.](http://arxiv.org/abs/2309.11518) | 本文介绍了一个使用离线学习和强化学习反馈的方法来解决在线广告系统中的广告负载平衡问题，该方法能够适应用户偏好和上下文因素的变化，并最大化用户参与度和收入。 |
| [^13] | [Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures.](http://arxiv.org/abs/2309.08765) | 通过使用大型语言模型挖掘化学专利，我们得到了一个包含10万个分子及其功能标签的化学功能（CheF）数据集，这些功能标签经过验证是高质量的。 |
| [^14] | [Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model.](http://arxiv.org/abs/2309.06453) | 本文通过实验比较了监督和无监督句子表示学习在训练过程中的行为，并探讨了如何缩小性能差距。 |
| [^15] | [Label Denoising through Cross-Model Agreement.](http://arxiv.org/abs/2308.13976) | 本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。 |
| [^16] | [Bang and the Artefacts are Gone! Rapid Artefact Removal and Tissue Segmentation in Haematoxylin and Eosin Stained Biopsies.](http://arxiv.org/abs/2308.13304) | 该论文提出了一种基于H&E Otsu thresholding的方案，可以快速去除标本残留物和分割组织，在血染乙酸洋红染色的活检中取得了良好的效果。 |
| [^17] | [LR-XFL: Logical Reasoning-based Explainable Federated Learning.](http://arxiv.org/abs/2308.12681) | LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。 |
| [^18] | [Finite Element Operator Network for Solving Parametric PDEs.](http://arxiv.org/abs/2308.04690) | 本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。 |
| [^19] | [Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale.](http://arxiv.org/abs/2308.02068) | 本研究利用日常抓取的1,404个不可靠新闻网站以及大型语言模型和聚类算法，提出了一个自动分析网络生态系统中传播的叙述的系统。通过识别55,301个叙述，描述了2022年传播最广泛的叙述，并确定了最具影响力的起源和放大叙述的网站。该系统可用于检测来自不可靠新闻网站的新叙述，并帮助事实核查组织更快地应对错误信息。 |
| [^20] | [Fast Neural Network Inference on FPGAs for Triggering on Long-Lived Particles at Colliders.](http://arxiv.org/abs/2307.05152) | 这项研究提出了两种机器学习算法，用于在CERN大型强子对撞机中选择中性长寿命粒子衰变的事件，并通过加速卡进行加速。实验结果表明，这些算法在加速的情况下仍然保持准确性，并符合第二级触发的延迟要求。 |
| [^21] | [H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models.](http://arxiv.org/abs/2306.14048) | 本文提出了一种通过预测文本中的热门元素来减少GPU内存消耗的方法，在实验中表现良好。 |
| [^22] | [HypLL: The Hyperbolic Learning Library.](http://arxiv.org/abs/2306.06154) | HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。 |
| [^23] | [Maximum Likelihood Training of Autoencoders.](http://arxiv.org/abs/2306.01843) | 本文介绍了一种成功的最大似然训练方法，用于非约束自编码器，将生成建模的优异性质与高效自编码器相结合。作者克服了两个挑战：设计了消除迭代的估计器并提出了稳定的最大似然训练目标。实验证明这种方法可以成功训练一系列非约束性自编码器，并取得了有竞争力的性能。 |
| [^24] | [Ghost Noise for Regularizing Deep Neural Networks.](http://arxiv.org/abs/2305.17205) | 本文研究了幽灵批量归一化（GBN）中的“幽灵噪声”，提出了一种新的正则化技术Ghost Noise Injection (GNI)，该方法能够避免小批量训练带来的训练-测试差异效应，并在深度神经网络中提供更好的泛化效果。 |
| [^25] | [Probabilistic Exponential Integrators.](http://arxiv.org/abs/2305.14978) | 本文提出了一种新的概率指数积分器，它在处理刚性系统时具有更好的性能，能够提供数值误差的概率解释，并且能够被应用于广泛的非线性系统中。 |
| [^26] | [Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations.](http://arxiv.org/abs/2305.13030) | 本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。 |
| [^27] | [Machine-Made Media: Monitoring the Mobilization of Machine-Generated Articles on Misinformation and Mainstream News Websites.](http://arxiv.org/abs/2305.09820) | 这篇论文研究了机器生成文章在虚假新闻和主流新闻网站的普及程度，发现虚假新闻网站上合成文章的使用速度比主流网站上更快。 |
| [^28] | [JaxPruner: A concise library for sparsity research.](http://arxiv.org/abs/2304.14082) | 本文介绍了JaxPruner，一款用于研究稀疏神经网络的开源库。JaxPruner提供了流行的剪枝和稀疏训练算法的简明实现，最小化内存和延迟开销，并可轻松集成到现有的JAX库中。 |
| [^29] | [GDP nowcasting with artificial neural networks: How much does long-term memory matter?.](http://arxiv.org/abs/2304.05805) | 通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。 |
| [^30] | [Futures Quantitative Investment with Heterogeneous Continual Graph Neural Network.](http://arxiv.org/abs/2303.16532) | 为了预测期货价格趋势，本文提出了一种基于异构任务设计和连续训练的时空图神经网络模型，可以捕捉长期和短期特征。 |
| [^31] | [Conductivity Imaging from Internal Measurements with Mixed Least-Squares Deep Neural Networks.](http://arxiv.org/abs/2303.16454) | 本论文提出了一种新的通过深度神经网络从内部测量中重构椭圆问题中的导电率分布的方法，并在连续和经验损失的神经网络逼近上进行了深入的分析，展示了该方法对于数据噪声的优异稳定性以及解决高维问题的能力。 |
| [^32] | [LossMix: Simplify and Generalize Mixup for Object Detection and Beyond.](http://arxiv.org/abs/2303.10343) | 本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。 |
| [^33] | [Identifying Label Errors in Object Detection Datasets by Loss Inspection.](http://arxiv.org/abs/2303.06999) | 本研究首次引入了一个用于目标检测数据集上标签错误检测的基准以及一种标签错误检测方法和几种基线方法。研究模拟了四种不同类型的随机引入的标签错误，并提出了一种通过损失检查来检测这些错误的方法。 |
| [^34] | [Pseudo Contrastive Learning for Graph-based Semi-supervised Learning.](http://arxiv.org/abs/2302.09532) | 本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。 |
| [^35] | [Mithridates: Boosting Natural Resistance to Backdoor Learning.](http://arxiv.org/abs/2302.04977) | Mithridates 是一种新方法，通过在不改变训练管道的情况下增强机器学习模型对后门攻击的自然抵抗力，让从业人员能够回答如何评估模型对后门中毒攻击的抵抗力以及如何提高抵抗力的可行问题。 |
| [^36] | [On the Efficacy of Differentially Private Few-shot Image Classification.](http://arxiv.org/abs/2302.01190) | 本文通过一系列实验研究了差分隐私少样本图像分类模型的准确性和易受攻击性，揭示了样本数、隐私级别、模型架构、下游数据集以及可学习参数子集等因素对分类效果的影响。 |
| [^37] | [Risk-Sensitive Reinforcement Learning with Exponential Criteria.](http://arxiv.org/abs/2212.09010) | 本文介绍了一种风险敏感的强化学习算法，使用指数判据来提高其系统抗干扰性和实用性。作者进行了在模拟和实际机器人上的实验验证，表明该算法能够有效地提高样本效率和执行效果。 |
| [^38] | [Fake detection in imbalance dataset by Semi-supervised learning with GAN.](http://arxiv.org/abs/2212.01071) | 本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。 |
| [^39] | [Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning.](http://arxiv.org/abs/2211.09273) | 本研究通过对抗机器学习的方法，提出了一种名为DARE-GP的解决方案，可以在不影响智能音箱效用的情况下，逃避与智能音箱相连的语音情感识别分类器，从而保护隐私。 |
| [^40] | [Polar Encoding: A Simple Baseline Approach for Classification with Missing Values.](http://arxiv.org/abs/2210.01905) | 极化编码是一种用于处理具有缺失值的分类问题的简单基线方法，它能保留缺失信息、无需插补，让决策树自由选择如何处理缺失值。 |
| [^41] | [Meta-Referential Games to Learn Compositional Learning Behaviours.](http://arxiv.org/abs/2207.08012) | 本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。 |
| [^42] | [Augmentation-Aware Self-Supervision for Data-Efficient GAN Training.](http://arxiv.org/abs/2205.15677) | 本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。 |

# 详细

[^1]: FP8-LM：训练FP8大语言模型

    FP8-LM: Training FP8 Large Language Models. (arXiv:2310.18313v1 [cs.LG])

    [http://arxiv.org/abs/2310.18313](http://arxiv.org/abs/2310.18313)

    本文提出了一种用于训练大语言模型的新型FP8自动混合精度框架，能够在不影响模型准确性的情况下显著减少内存使用并提高训练速度。

    

    本文探讨了用于高效训练大语言模型（LLMs）的FP8低比特数据格式。我们的关键洞察是，在LLM训练中，大多数变量（如梯度和优化器状态）可以使用低精度数据格式，而不会影响模型准确性，并且不需要改变超参数。具体地，我们提出了一种新的FP8自动混合精度框架用于训练LLMs。该框架为LLM的混合精度和分布式并行训练提供了三个级别的FP8利用。它逐步引入8位梯度，优化器状态和分布式学习。实验结果表明，在H100 GPU平台上训练GPT-175B模型期间，我们的FP8混合精度训练框架不仅实现了显著的42%的真实内存使用减少，而且比广泛采用的BF16框架（即Megatron-LM）运行速度快64%，比Nvidia Transformer Engine快17%。

    In this paper, we explore FP8 low-bit data formats for efficient training of large language models (LLMs). Our key insight is that most variables, such as gradients and optimizer states, in LLM training can employ low-precision data formats without compromising model accuracy and requiring no changes to hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision framework for training LLMs. This framework offers three levels of FP8 utilization to streamline mixed-precision and distributed parallel training for LLMs. It gradually incorporates 8-bit gradients, optimizer states, and distributed learning in an incremental manner. Experiment results show that, during the training of GPT-175B model on H100 GPU platform, our FP8 mixed-precision training framework not only achieved a remarkable 42% reduction in real memory usage but also ran 64% faster than the widely adopted BF16 framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer Engine by 17%. This l
    
[^2]: 通道独立策略是否是时间序列预测的最佳解？

    Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v1 [cs.LG])

    [http://arxiv.org/abs/2310.17658](http://arxiv.org/abs/2310.17658)

    本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。

    

    近年来出现了许多用于长期时间序列预测的模型。最近的研究表明，使用单一线性层的通道相关(CD)或通道独立(CI)建模，甚至可以超过许多复杂模型的性能。然而，当前的研究主要将CD和CI视为两种互补但互斥的方法，无法同时利用这两个极端。而且，CD和CI都是静态策略，无法在没有大量实验的情况下确定是特定数据集的最佳策略。在本文中，我们重新考虑了当前CI策略是否是时间序列预测的最佳解决方案。首先，我们提出了一种简单而有效的策略，称为CSC（通道自聚类策略），用于线性模型。我们的通道自聚类策略增强了CI策略的性能改进，并减小了参数大小。

    There has been an emergence of various models for long-term time series forecasting. Recent studies have demonstrated that a single linear layer, using Channel Dependent (CD) or Channel Independent (CI) modeling, can even outperform a large number of sophisticated models. However, current research primarily considers CD and CI as two complementary yet mutually exclusive approaches, unable to harness these two extremes simultaneously. And it is also a challenging issue that both CD and CI are static strategies that cannot be determined to be optimal for a specific dataset without extensive experiments. In this paper, we reconsider whether the current CI strategy is the best solution for time series forecasting. First, we propose a simple yet effective strategy called CSC, which stands for $\mathbf{C}$hannel $\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel Self-Clustering (CSC) enhances CI strategy's performance improvements while reducing parameter size, fo
    
[^3]: 基于图注意力的深度强化学习用于解决带有负载相关成本的中国邮递员问题

    Graph Attention-based Deep Reinforcement Learning for solving the Chinese Postman Problem with Load-dependent costs. (arXiv:2310.15516v1 [cs.LG])

    [http://arxiv.org/abs/2310.15516](http://arxiv.org/abs/2310.15516)

    本论文提出了一个基于图注意力的深度强化学习方法来解决带有负载相关成本的中国邮递员问题。该方法将问题形式化为马尔可夫决策过程，引入了一个编码器和解码器的自回归模型来有效处理问题。

    

    最近，深度强化学习（DRL）模型在解决路径规划问题方面展现了良好的结果。然而，大多数DRL求解器通常是用来解决节点路径规划问题，例如旅行推销员问题（TSP）。与此同时，关于应用神经方法来解决弧路径规划问题，例如中国邮递员问题（CPP），的研究却十分有限，因为与TSP相比，它们的解空间通常更加不规则和复杂。为了填补这些空白，本文提出了一个新的DRL框架，来解决带有负载相关成本（CPP-LC）的CPP问题，这是一个具有负载约束的复杂弧路径规划问题。我们方法的创新点有两个。首先，我们将CPP-LC问题形式化为马尔可夫决策过程（MDP）顺序模型。随后，我们引入了一种基于DRL的自回归模型，即Arc-DRL模型，它由一个编码器和一个解码器组成，可以有效处理CPP-LC问题。这样的框架使得DRL模型能够高效地工作。

    Recently, Deep reinforcement learning (DRL) models have shown promising results in solving routing problems. However, most DRL solvers are commonly proposed to solve node routing problems, such as the Traveling Salesman Problem (TSP). Meanwhile, there has been limited research on applying neural methods to arc routing problems, such as the Chinese Postman Problem (CPP), since they often feature irregular and complex solution spaces compared to TSP. To fill these gaps, this paper proposes a novel DRL framework to address the CPP with load-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc routing problem with load constraints. The novelty of our method is two-fold. First, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential model. Subsequently, we introduce an autoregressive model based on DRL, namely Arc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge effectively. Such a framework allows the DRL model to work efficiently 
    
[^4]: AI驱动的剥夺中的分而治之动态

    Divide-and-Conquer Dynamics in AI-Driven Disempowerment. (arXiv:2310.06009v1 [cs.CY])

    [http://arxiv.org/abs/2310.06009](http://arxiv.org/abs/2310.06009)

    这项研究通过构建游戏理论模型，研究了AI驱动的剥夺中的不团结问题。研究发现，当前受害者需要让未来受害者认识到他们的利益同样面临严重和紧迫的威胁，以激励未来受害者以团结支持当前受害者。

    

    AI公司试图创造出在大部分经济价值工作上超越人类的AI系统。当前的AI模型已经自动化削弱了一些艺术家、演员和作家的生计。但是在那些优先考虑当前危害和未来危害之间存在着内讧。我们构建了一个博弈论模型来研究这种不团结的原因和后果。我们的模型还有助于解释为什么在历史上，面临共同威胁的利益相关方发现联合起来对抗该威胁是有利的，而该共同威胁又发现分而治之是有利的。在现实参数假设下，我们的模型提出了几个预测，在历史经验记录中得到了初步的证实。

    AI companies are attempting to create AI systems that outperform humans at most economically valuable work. Current AI models are already automating away the livelihoods of some artists, actors, and writers. But there is infighting between those who prioritize current harms and future harms. We construct a game-theoretic model of conflict to study the causes and consequences of this disunity. Our model also helps explain why throughout history, stakeholders sharing a common threat have found it advantageous to unite against it, and why the common threat has in turn found it advantageous to divide and conquer.  Under realistic parameter assumptions, our model makes several predictions that find preliminary corroboration in the historical-empirical record. First, current victims of AI-driven disempowerment need the future victims to realize that their interests are also under serious and imminent threat, so that future victims are incentivized to support current victims in solidarity. Se
    
[^5]: 循环神经语言模型作为概率有限状态自动机

    Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05161](http://arxiv.org/abs/2310.05161)

    本文研究了循环神经网络语言模型（RNN LMs）作为概率有限状态自动机的能力，并发现它们只能表示有限状态模型所能表达的概率分布的一个严格子集。

    

    通过以容易理解的形式来研究语言模型（LMs）可以使我们精确地描述它们的能力和局限性。先前的研究已经考察了循环神经网络（RNN）语言模型在识别无权重形式语言的能力。然而，LMs并不描述无权重形式语言，而是定义了对字符串的概率分布。在本研究中，我们研究了RNN LMs可以表示哪些类的概率分布，这使得我们可以更直接地陈述它们的能力。我们证明了简单的RNN等价于概率有限状态自动机的一个子类，因此只能模拟有限状态模型所能表达的概率分布的一个严格子集。此外，我们研究了用RNNs表示有限状态LMs的空间复杂度。我们证明了，为了表示一个任意确定的有限状态LMs，其中有$N$个状态且字符集为$\Sigma$的RNN requir

    Studying language models (LMs) in terms of well-understood formalisms allows us to precisely characterize their abilities and limitations. Previous work has investigated the representational capacity of recurrent neural network (RNN) LMs in terms of their capacity to recognize unweighted formal languages. However, LMs do not describe unweighted formal languages -- rather, they define probability distributions over strings. In this work, we study what classes of such probability distributions RNN LMs can represent, which allows us to make more direct statements about their capabilities. We show that simple RNNs are equivalent to a subclass of probabilistic finite-state automata, and can thus model a strict subset of probability distributions expressible by finite-state models. Furthermore, we study the space complexity of representing finite-state LMs with RNNs. We show that, to represent an arbitrary deterministic finite-state LM with $N$ states over an alphabet $\Sigma$, an RNN requir
    
[^6]: 在需要时聘用：渐进式参与者招募用于基于拍卖的联邦学习

    Hire When You Need to: Gradual Participant Recruitment for Auction-based Federated Learning. (arXiv:2310.02651v1 [cs.LG])

    [http://arxiv.org/abs/2310.02651](http://arxiv.org/abs/2310.02651)

    GPS-AFL是一种基于拍卖的联邦学习渐进式参与者选择方案，通过在多轮训练中逐渐选择数据所有者，解决了冷启动问题和选择偏差对联邦学习的影响。

    

    联邦学习的成功依赖于数据所有者（DOs）的数量和质量，以及他们参与联邦学习模型训练的动机。已经提出了以声誉为基础的联邦学习参与者选择方法。然而，它们仍然面临冷启动问题和对高声誉DOs的潜在选择偏差的挑战。这种偏差可能导致较低声誉的DOs被过早地排除在未来的联邦学习训练轮次中，从而降低了训练数据的多样性和结果模型的泛化能力。为了解决这些挑战，我们提出了基于拍卖的联邦学习渐进式参与者选择方案（GPS-AFL）。与现有的联邦学习激励机制不同，后者通常认为用于联邦学习任务的所有DOs必须一次性选择，GPS-AFL在多轮训练中逐渐选择所需的DOs，随着通过重复交互逐渐揭示更多信息。它的设计旨在在成本和效用之间取得平衡。

    The success of federated Learning (FL) depends on the quantity and quality of the data owners (DOs) as well as their motivation to join FL model training. Reputation-based FL participant selection methods have been proposed. However, they still face the challenges of the cold start problem and potential selection bias towards highly reputable DOs. Such a bias can result in lower reputation DOs being prematurely excluded from future FL training rounds, thereby reducing the diversity of training data and the generalizability of the resulting models. To address these challenges, we propose the Gradual Participant Selection scheme for Auction-based Federated Learning (GPS-AFL). Unlike existing AFL incentive mechanisms which generally assume that all DOs required for an FL task must be selected in one go, GPS-AFL gradually selects the required DOs over multiple rounds of training as more information is revealed through repeated interactions. It is designed to strike a balance between cost s
    
[^7]: 一刀切：向能够训练多个分类任务的单一图模型迈进

    One for All: Towards Training One Graph Model for All Classification Tasks. (arXiv:2310.00149v1 [cs.LG])

    [http://arxiv.org/abs/2310.00149](http://arxiv.org/abs/2310.00149)

    这项研究提出了一种名为“一刀切”的通用框架，该框架能够使用单一图模型解决不同领域的多个任务。该框架克服了图学习领域的挑战，包括不同属性和分布的图数据、不同类型的任务以及上下文学习的问题。

    

    设计一个能够解决多个任务的单一模型一直是人工智能领域的长期目标。最近，大型语言模型展示了在语言领域内整合和解决不同任务的异常能力。然而，在图学习领域，针对各种任务的统一模型仍然未被充分探索，主要是由于图学习领域独特的挑战。首先，来自不同领域的图数据具有不同的属性和遵循不同的分布。这种差异使得很难将图表示在一个统一的表示空间中。其次，图上的任务分化为节点、链接和图任务，需要不同的嵌入策略。最后，关于上下文学习的适当图提示范式尚不清楚。为了应对上述挑战，我们提出了"一刀切"（OFA），这是第一个能够使用单一图模型来解决上述挑战的通用框架。

    Designing a single model that addresses multiple tasks has been a long-standing objective in artificial intelligence. Recently, large language models have demonstrated exceptional capability in integrating and solving different tasks within the language domain. However, a unified model for various tasks on graphs remains underexplored, primarily due to the challenges unique to the graph learning domain. First, graph data from different areas carry distinct attributes and follow different distributions. Such discrepancy makes it hard to represent graphs in a single representation space. Second, tasks on graphs diversify into node, link, and graph tasks, requiring distinct embedding strategies. Finally, an appropriate graph prompting paradigm for in-context learning is unclear. Striving to handle all the aforementioned challenges, we propose One for All (OFA), the first general framework that can use a single graph model to address the above challenges. Specifically, OFA proposes text-at
    
[^8]: SEPT: 为运动预测的高效场景表示学习

    SEPT: Towards Efficient Scene Representation Learning for Motion Prediction. (arXiv:2309.15289v1 [cs.CV])

    [http://arxiv.org/abs/2309.15289](http://arxiv.org/abs/2309.15289)

    SEPT是一个利用自监督学习进行场景表示学习的建模框架，通过预训练的编码器捕捉轨迹的运动学特征、道路网络的空间结构以及道路和代理之间的交互作用，实现了在运动预测任务上的最先进性能。

    

    运动预测对于自动驾驶汽车在复杂交通环境中安全运行至关重要。提取交通元素之间的有效时空关系是准确预测的关键。本文受到预训练大型语言模型成功应用的启发，提出了SEPT，这是一个利用自监督学习来开发复杂交通场景中强大的时空理解能力的建模框架。具体而言，我们的方法涉及到在场景输入上进行三个掩码重构建模任务，包括代理路径和道路网络，预训练场景编码器以捕捉轨迹的运动学特征，道路网络的空间结构以及道路和代理之间的交互作用。预训练的编码器然后在下游预测任务上进行微调。大量实验证明，SEPT在Argoverse 1和Argoverse上无需精心设计的架构或手动特征工程，达到了最先进的性能水平。

    Motion prediction is crucial for autonomous vehicles to operate safely in complex traffic environments. Extracting effective spatiotemporal relationships among traffic elements is key to accurate forecasting. Inspired by the successful practice of pretrained large language models, this paper presents SEPT, a modeling framework that leverages self-supervised learning to develop powerful spatiotemporal understanding for complex traffic scenes. Specifically, our approach involves three masking-reconstruction modeling tasks on scene inputs including agents' trajectories and road network, pretraining the scene encoder to capture kinematics within trajectory, spatial structure of road network, and interactions among roads and agents. The pretrained encoder is then finetuned on the downstream forecasting task. Extensive experiments demonstrate that SEPT, without elaborate architectural design or manual feature engineering, achieves state-of-the-art performance on the Argoverse 1 and Argoverse
    
[^9]: ICML 2023拓扑深度学习挑战：设计与结果

    ICML 2023 Topological Deep Learning Challenge : Design and Results. (arXiv:2309.15188v1 [cs.LG])

    [http://arxiv.org/abs/2309.15188](http://arxiv.org/abs/2309.15188)

    本文介绍了ICML 2023拓扑深度学习挑战，该挑战要求参与者在两个月内提供开源实现的拓扑神经网络，吸引了28个合格的提交。

    

    本文介绍了ICML 2023拓扑与几何机器学习研讨会中举办的拓扑深度学习计算挑战。该比赛要求参与者通过贡献于python包TopoNetX（数据处理）和TopoModelX（深度学习）的开源实现来提供文献中的拓扑神经网络。该挑战在两个月的时间内吸引了28个合格的提交。本文描述了挑战的设计并总结了其主要发现。

    This paper presents the computational challenge on topological deep learning that was hosted within the ICML 2023 Workshop on Topology and Geometry in Machine Learning. The competition asked participants to provide open-source implementations of topological neural networks from the literature by contributing to the python packages TopoNetX (data processing) and TopoModelX (deep learning). The challenge attracted twenty-eight qualifying submissions in its two-month duration. This paper describes the design of the challenge and summarizes its main findings.
    
[^10]: 物理信息触发状态空间神经网络用于传输现象

    Physics-informed State-space Neural Networks for Transport Phenomena. (arXiv:2309.12211v1 [cs.LG])

    [http://arxiv.org/abs/2309.12211](http://arxiv.org/abs/2309.12211)

    这项研究引入了物理信息触发状态空间神经网络模型（PSMs），用于解决在化学、生物医学和电厂等传输现象中实现实时优化和容错性的问题。通过使用传感器数据训练深度神经网络，并使用物理模型进行传输系统建模，PSMs提供了比传统数据驱动模型更准确的方法，并具有多种应用场景。

    

    本研究介绍了物理信息触发状态空间神经网络模型（PSMs），这是一种在自主系统中实现实时优化、灵活性和容错性的新颖解决方案，特别适用于化学、生物医学和电厂等以传输为主导的系统。传统的数据驱动方法由于缺乏像质量守恒这样的物理约束而有所不足。PSMs通过使用传感器数据训练深度神经网络，并使用部分微分方程对物理信息进行建模，从而得到具有物理约束的可迭代前向动力学模型。通过两个仿真实验 - 加热通道和冷却系统回路，我们证明PSMs比纯数据驱动模型提供更准确的方法。除了准确性之外，PSMs还具有多种令人信服的用例。本文展示了其中的两个：通过顺序更新的状态空间表示创建非线性监控控制器

    This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models.  Beyond accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representatio
    
[^11]: 高维RBM的漂移控制：基于神经网络的计算方法

    Drift Control of High-Dimensional RBM: A Computational Method Based on Neural Networks. (arXiv:2309.11651v1 [eess.SY])

    [http://arxiv.org/abs/2309.11651](http://arxiv.org/abs/2309.11651)

    该论文提出了一种基于神经网络的计算方法，用于漂移控制高维RBMs。通过深度神经网络技术，该方法在测试问题上达到了较高的准确性。

    

    受排队理论应用的启发，我们考虑了一个状态空间为d维正半轴的随机控制问题。控制过程Z按照一个反射布朗运动演化，其协方差矩阵是外生指定的，反射方向是从正半轴边界表面反射。系统管理员根据Z的历史选择每个时间点t上的漂移向量θ(t)，而时间点t上的成本率取决于Z(t)和θ(t)。在我们的初始问题表述中，目标是在无限规划时间范围内最小化期望贴现成本，之后我们处理相应的人均控制问题。借鉴韩海亮等人（国家科学院学报，2018, 8505-8510）的早期工作，我们开发并展示了一种基于深度神经网络技术的基于模拟的计算方法。到目前为止，我们研究的测试问题中，我们的方法的精度在一个小数范围内准确。

    Motivated by applications in queueing theory, we consider a stochastic control problem whose state space is the $d$-dimensional positive orthant. The controlled process $Z$ evolves as a reflected Brownian motion whose covariance matrix is exogenously specified, as are its directions of reflection from the orthant's boundary surfaces. A system manager chooses a drift vector $\theta(t)$ at each time $t$ based on the history of $Z$, and the cost rate at time $t$ depends on both $Z(t)$ and $\theta(t)$. In our initial problem formulation, the objective is to minimize expected discounted cost over an infinite planning horizon, after which we treat the corresponding ergodic control problem. Extending earlier work by Han et al. (Proceedings of the National Academy of Sciences, 2018, 8505-8510), we develop and illustrate a simulation-based computational method that relies heavily on deep neural network technology. For test problems studied thus far, our method is accurate to within a fraction o
    
[^12]: 在内容市场中的离线学习下的广告负载平衡

    Ad-load Balancing via Off-policy Learning in a Content Marketplace. (arXiv:2309.11518v1 [cs.IR])

    [http://arxiv.org/abs/2309.11518](http://arxiv.org/abs/2309.11518)

    本文介绍了一个使用离线学习和强化学习反馈的方法来解决在线广告系统中的广告负载平衡问题，该方法能够适应用户偏好和上下文因素的变化，并最大化用户参与度和收入。

    

    广告负载平衡是在线广告系统中的一个关键挑战，尤其在社交媒体平台的背景下，目标是在保持用户体验的同时最大化用户参与度和收入。传统的广告负载平衡方法依赖于静态分配策略，无法适应用户偏好和上下文因素的变化。本文提出了一种利用离线学习和依据记录的强化学习反馈的方法。我们首先进行了广告负载平衡问题的分析，强调了用户满意度和广告收入之间的冲突目标。我们强调了由于用户异质性和用户在会话中的位置的依赖性而引起的细微差别。基于这个分析，我们定义了在特定的内容获取中确定最优广告负载的问题。

    Ad-load balancing is a critical challenge in online advertising systems, particularly in the context of social media platforms, where the goal is to maximize user engagement and revenue while maintaining a satisfactory user experience. This requires the optimization of conflicting objectives, such as user satisfaction and ads revenue. Traditional approaches to ad-load balancing rely on static allocation policies, which fail to adapt to changing user preferences and contextual factors. In this paper, we present an approach that leverages off-policy learning and evaluation from logged bandit feedback. We start by presenting a motivating analysis of the ad-load balancing problem, highlighting the conflicting objectives between user satisfaction and ads revenue. We emphasize the nuances that arise due to user heterogeneity and the dependence on the user's position within a session. Based on this analysis, we define the problem as determining the optimal ad-load for a particular feed fetch.
    
[^13]: 使用大型语言模型挖掘专利展示了功能标签与化学结构的一致性

    Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures. (arXiv:2309.08765v1 [q-bio.QM])

    [http://arxiv.org/abs/2309.08765](http://arxiv.org/abs/2309.08765)

    通过使用大型语言模型挖掘化学专利，我们得到了一个包含10万个分子及其功能标签的化学功能（CheF）数据集，这些功能标签经过验证是高质量的。

    

    从结构预测化学功能是化学科学的一个主要目标，从发现和重用新型药物到创造新材料。最近，新的机器学习算法开辟了涵盖许多不同化学功能的通用预测模型的可能性。在这里，我们考虑将大型语言模型应用于化学专利的挑战，以整合和利用这些资源所捕捉的关于化学功能的信息。化学专利包含大量关于化学功能的知识，但由于提取高质量功能标签的不可行性，它们作为数据集的有用性历来被忽视。使用可扩展的ChatGPT辅助专利摘要和词嵌入标签清理流程，我们得到了一个化学功能（CheF）数据集，包含10万个分子及其专利衍生的功能标签。这些功能标签经过验证是高质量的，使我们能够

    Predicting chemical function from structure is a major goal of the chemical sciences, from the discovery and repurposing of novel drugs to the creation of new materials. Recently, new machine learning algorithms are opening up the possibility of general predictive models spanning many different chemical functions. Here, we consider the challenge of applying large language models to chemical patents in order to consolidate and leverage the information about chemical functionality captured by these resources. Chemical patents contain vast knowledge on chemical function, but their usefulness as a dataset has historically been neglected due to the impracticality of extracting high-quality functional labels. Using a scalable ChatGPT-assisted patent summarization and word-embedding label cleaning pipeline, we derive a Chemical Function (CheF) dataset, containing 100K molecules and their patent-derived functional labels. The functional labels were validated to be of high quality, allowing us 
    
[^14]: 缩小监督和无监督句子表示学习的差距：大规模语言模型

    Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model. (arXiv:2309.06453v1 [cs.CL])

    [http://arxiv.org/abs/2309.06453](http://arxiv.org/abs/2309.06453)

    本文通过实验比较了监督和无监督句子表示学习在训练过程中的行为，并探讨了如何缩小性能差距。

    

    句子表示学习是自然语言处理中的一项基本任务，对比学习的句子嵌入（CSE）作为主流技术具有出色的性能。然而，在CSE中有一个有趣的现象，即监督和无监督方法之间存在显著的性能差距，即使它们的句子编码器和损失函数相同。本文通过实证实验回答“发生了什么导致了性能差距”和“如何缩小性能差距”的问题。我们首先通过彻底比较监督和无监督CSE在各自的训练过程中的行为来回答“发生了什么”这个问题。

    Sentence Representation Learning (SRL) is a fundamental task in Natural Language Processing (NLP), with Contrastive learning of Sentence Embeddings (CSE) as the mainstream technique due to its superior performance. An intriguing phenomenon in CSE is the significant performance gap between supervised and unsupervised methods, even when their sentence encoder and loss function are the same. Previous works attribute this performance gap to differences in two representation properties (alignment and uniformity). However, alignment and uniformity only measure the results, which means they cannot answer "What happens during the training process that leads to the performance gap?" and "How can the performance gap be narrowed?". In this paper, we conduct empirical experiments to answer these "What" and "How" questions. We first answer the "What" question by thoroughly comparing the behavior of supervised and unsupervised CSE during their respective training processes. From the comparison, We o
    
[^15]: 通过跨模型一致性进行标签去噪

    Label Denoising through Cross-Model Agreement. (arXiv:2308.13976v1 [cs.LG])

    [http://arxiv.org/abs/2308.13976](http://arxiv.org/abs/2308.13976)

    本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。

    

    在现实世界的机器学习应用中，从有噪声的标签学习是非常常见的。记忆这些有噪声的标签可能会影响模型的学习，从而导致次优的性能。在这项工作中，我们提出了一种新颖的框架，用于从有噪声标签中学习鲁棒的机器学习模型。通过实证研究，我们发现不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。受到这一观察的启发，我们提出了使用跨模型一致性进行去噪（DeCA）的方法，该方法旨在最小化由两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。我们将提出的DeCA方法应用于二进制标签情景和多标签情景。对于二进制标签情景，我们选择隐式反馈推荐作为下游任务，并进行了四种最先进方法的实验。

    Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \em denoising with cross-model agreement \em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the
    
[^16]: 激光和标本消失了！快速去除标本残留物和组织分割在血染乙酸洋红染色活检中

    Bang and the Artefacts are Gone! Rapid Artefact Removal and Tissue Segmentation in Haematoxylin and Eosin Stained Biopsies. (arXiv:2308.13304v1 [eess.IV])

    [http://arxiv.org/abs/2308.13304](http://arxiv.org/abs/2308.13304)

    该论文提出了一种基于H&E Otsu thresholding的方案，可以快速去除标本残留物和分割组织，在血染乙酸洋红染色的活检中取得了良好的效果。

    

    我们提出了一种H&E Otsu thresholding方案，用于快速检测全幻灯片图像中的组织，可以消除笔迹和扫描残留等各种不良标本残留物。我们的方法涉及到获取低放大倍率RGB全景图像的双峰表示，从而可以简单地使用Otsu thresholding方法将组织与背景和残留物分离。我们在来自各种机构和WSI数字扫描仪的WSI制备的图像上演示了我们的方法，每张图像都包含大量的残留物，其他方法都无法处理。我们方法的美妙之处在于其简洁性：通过操作RGB颜色空间并使用Otsu thresholding可以快速去除残留物并分割组织。

    We present H&E Otsu thresholding, a scheme for rapidly detecting tissue in whole-slide images (WSIs) that eliminates a wide range of undesirable artefacts such as pen marks and scanning artefacts. Our method involves obtaining a bid-modal representation of a low-magnification RGB overview image which enables simple Otsu thresholding to separate tissue from background and artefacts. We demonstrate our method on WSIs prepared from a wide range of institutions and WSI digital scanners, each containing substantial artefacts that cause other methods to fail. The beauty of our approach lies in its simplicity: manipulating RGB colour space and using Otsu thresholding allows for the rapid removal of artefacts and segmentation of tissue.
    
[^17]: LR-XFL: 基于逻辑推理的可解释联邦学习

    LR-XFL: Logical Reasoning-based Explainable Federated Learning. (arXiv:2308.12681v1 [cs.AI])

    [http://arxiv.org/abs/2308.12681](http://arxiv.org/abs/2308.12681)

    LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。

    

    联邦学习 (FL) 是一种新兴的机器学习模型协作训练方法，能够保护数据隐私。隐私保护的需求使得FL模型很难实现全局透明度和可解释性。为了解决这个限制，我们提出了基于逻辑推理的可解释联邦学习 (LR-XFL) 方法，将逻辑推理融入FL中。在LR-XFL中，FL客户端根据其本地数据创建本地逻辑规则，并将其与模型更新一起发送到FL服务器。FL服务器通过适当的逻辑连接符将本地逻辑规则连接起来，该连接符基于客户端数据的属性进行推导，而无需访问原始数据。此外，服务器还根据客户端上传的逻辑规则反映的本地数据的质量，使用权重值对本地模型更新进行聚合。结果显示，LR-XFL在最相关的基准测试中超过1.19％，5.81％和5.41％。

    Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients' local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in
    
[^18]: 用于解决参数PDE的有限元算子网络

    Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])

    [http://arxiv.org/abs/2308.04690](http://arxiv.org/abs/2308.04690)

    本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。

    

    偏微分方程（PDE）是我们理解和预测物理、工程和金融等众多领域自然现象的基础。然而，解决参数PDE是一项复杂的任务，需要高效的数值方法。在本文中，我们提出了一种通过有限元算子网络（FEONet）解决参数PDE的新方法。我们的方法结合了深度学习和传统数值方法，特别是有限元法，以在没有任何配对的输入-输出训练数据的情况下解决参数PDE。我们在几个基准问题上展示了我们方法的效果，并且表明它在准确度、泛化性和计算灵活性方面优于现有的最先进方法。我们的FEONet框架在模拟具有不同边界条件和复杂域的各种领域中显示出潜力。

    Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and sin
    
[^19]: 虚假网站：在规模上追踪和影响虚假新闻故事的传播

    Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale. (arXiv:2308.02068v1 [cs.SI])

    [http://arxiv.org/abs/2308.02068](http://arxiv.org/abs/2308.02068)

    本研究利用日常抓取的1,404个不可靠新闻网站以及大型语言模型和聚类算法，提出了一个自动分析网络生态系统中传播的叙述的系统。通过识别55,301个叙述，描述了2022年传播最广泛的叙述，并确定了最具影响力的起源和放大叙述的网站。该系统可用于检测来自不可靠新闻网站的新叙述，并帮助事实核查组织更快地应对错误信息。

    

    虚假信息、宣传和彻头彻尾的谎言在网络上大量传播，其中一些叙述对公共健康、选举和个人安全产生危险的现实影响。然而，尽管虚假信息的影响，研究界在追踪在线平台上的新闻叙述方面主要缺乏自动化和程序化的方法。在这项研究中，利用对1,404个不可靠新闻网站的日常抓取、大型语言模型MPNet和DP-Means聚类，我们介绍了一个系统来自动分离和分析在线生态系统中传播的叙述。我们在这些1,404个网站上识别了55,301个叙述，描述了2022年传播最广泛的叙述，并确定了起源和放大叙述的最具影响力的网站。最后，我们展示了如何利用我们的系统来检测源自不可靠新闻网站的新叙述，并帮助Politifact、路透社和美联社等事实核查组织更快地应对错误信息。

    Misinformation, propaganda, and outright lies proliferate on the web, with some narratives having dangerous real-world consequences on public health, elections, and individual safety. However, despite the impact of misinformation, the research community largely lacks automated and programmatic approaches for tracking news narratives across online platforms. In this work, utilizing daily scrapes of 1,404 unreliable news websites, the large-language model MPNet, and DP-Means clustering, we introduce a system to automatically isolate and analyze the narratives spread within online ecosystems. Identifying 55,301 narratives on these 1,404 websites, we describe the most prevalent narratives spread in 2022 and identify the most influential websites that originate and magnify narratives. Finally, we show how our system can be utilized to detect new narratives originating from unreliable news websites and aid fact-checkers like Politifact, Reuters, and AP News in more quickly addressing misinfo
    
[^20]: 在强子对撞机上用于长寿命粒子触发的FPGA快速神经网络推理

    Fast Neural Network Inference on FPGAs for Triggering on Long-Lived Particles at Colliders. (arXiv:2307.05152v1 [hep-ex])

    [http://arxiv.org/abs/2307.05152](http://arxiv.org/abs/2307.05152)

    这项研究提出了两种机器学习算法，用于在CERN大型强子对撞机中选择中性长寿命粒子衰变的事件，并通过加速卡进行加速。实验结果表明，这些算法在加速的情况下仍然保持准确性，并符合第二级触发的延迟要求。

    

    实验粒子物理学需要一个复杂的触发和采集系统，能够高效地保留感兴趣的碰撞事件以供进一步研究。利用FPGA加速卡进行异构计算可能成为CERN大型强子对撞机即将到来的高亮度计划中触发策略的一种新趋势技术。在这个背景下，我们提出了两种机器学习算法，用于选择在探测器体积内发生中性长寿命粒子衰变的事件，并研究了在商业可获得的Xilinx FPGA加速卡上进行加速的准确性和推理时间。推理时间还与基于CPU和GPU的硬件设置进行了对比。结果表明，所提出的新算法在考虑的基准物理场景中是高效的，并且在FPGA卡上加速时准确性没有降低。所有测试的架构都符合第二级触发的延迟要求。

    Experimental particle physics demands a sophisticated trigger and acquisition system capable to efficiently retain the collisions of interest for further investigation. Heterogeneous computing with the employment of FPGA cards may emerge as a trending technology for the triggering strategy of the upcoming high-luminosity program of the Large Hadron Collider at CERN. In this context, we present two machine-learning algorithms for selecting events where neutral long-lived particles decay within the detector volume studying their accuracy and inference time when accelerated on commercially available Xilinx FPGA accelerator cards. The inference time is also confronted with a CPU- and GPU-based hardware setup. The proposed new algorithms are proven efficient for the considered benchmark physics scenario and their accuracy is found to not degrade when accelerated on the FPGA cards. The results indicate that all tested architectures fit within the latency requirements of a second-level trigge
    
[^21]: H$_2$O: 高效生成大型语言模型的热门元素预测器

    H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models. (arXiv:2306.14048v1 [cs.LG])

    [http://arxiv.org/abs/2306.14048](http://arxiv.org/abs/2306.14048)

    本文提出了一种通过预测文本中的热门元素来减少GPU内存消耗的方法，在实验中表现良好。

    

    大型语言模型(LLM)在最近取得了令人瞩目的成就, 但是由于成本过高，它们特别难以用于对话系统和故事创作等需要生成长内容的应用。除了模型参数外，通常还需要在GPU内存中存储大量临时状态信息，称为KV cache，它与序列长度和批量大小呈线性关系。在本文中, 我们提出了一种新颖的实现KV cache的方法，它显著地减少了其内存占用量。我们的方法基于一个引人注目的发现，即在计算注意力分数时，小部分标记贡献最大价值。我们称这些标记为热门元素(H$_2$)。通过全面的研究，我们发现(i) H$_2$的出现是自然而然的，并且与文本中标记的频繁共现强相关；(ii)去除它们会导致明显的性能下降。基于这些见解，我们提出了H$_2$O，一种用于高效生成LLM的热门元素预测器。H$_2$O可以准确地预测给定序列中的热门元素，并因此保持一个更小的KV cache,将GPU内存消耗减少了50%。我们在几个基准数据集上的实验表明,H$_2$O可以在显著减少内存消耗的同时，实现与完整KV cache相当的性能。

    Large Language Models (LLMs), despite their recent impressive accomplishments, are notably cost-prohibitive to deploy, particularly for applications involving long-content generation, such as dialogue systems and story writing. Often, a large amount of transient state information, referred to as the KV cache, is stored in GPU memory in addition to model parameters, scaling linearly with the sequence length and batch size. In this paper, we introduce a novel approach for implementing the KV cache which significantly reduces its memory footprint. Our approach is based on the noteworthy observation that a small portion of tokens contributes most of the value when computing attention scores. We call these tokens Heavy Hitters (H$_2$). Through a comprehensive investigation, we find that (i) the emergence of H$_2$ is natural and strongly correlates with the frequent co-occurrence of tokens in the text, and (ii) removing them results in significant performance degradation. Based on these insi
    
[^22]: HypLL: 希亚空间深度学习库

    HypLL: The Hyperbolic Learning Library. (arXiv:2306.06154v1 [cs.LG])

    [http://arxiv.org/abs/2306.06154](http://arxiv.org/abs/2306.06154)

    HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。

    

    在机器学习、多媒体和计算机视觉等领域，希亚空间深度学习正迅速引起关注。深度网络通常在欧几里得空间中运行，隐含地假设数据在规则网格上。最近的研究表明，当处理层次化数据和使用少量嵌入维度时，希亚几何提供了一个可行的深度学习基础。然而，目前没有可访问的开源库用于构建类似于众所周知的深度学习库的希亚网络模块。我们提出了HypLL, 即希亚空间深度学习库，以将希亚深度学习的进展聚集在一起。HypLL建立在PyTorch之上，特别强调其易用性设计，以吸引广泛的受众关注这个新的和开放的研究方向。代码可在以下网址找到：https://github.com/maxvanspengler/hyperbolic_learning_library。压缩文件可在以下网址找到：https://d

    Deep learning in hyperbolic space is quickly gaining traction in the fields of machine learning, multimedia, and computer vision. Deep networks commonly operate in Euclidean space, implicitly assuming that data lies on regular grids. Recent advances have shown that hyperbolic geometry provides a viable alternative foundation for deep learning, especially when data is hierarchical in nature and when working with few embedding dimensions. Currently however, no accessible open-source library exists to build hyperbolic network modules akin to well-known deep learning libraries. We present HypLL, the Hyperbolic Learning Library to bring the progress on hyperbolic deep learning together. HypLL is built on top of PyTorch, with an emphasis in its design for easy-of-use, in order to attract a broad audience towards this new and open-ended research direction. The code is available at: https://github.com/maxvanspengler/hyperbolic_learning_library. The compressed archive is available at: https://d
    
[^23]: 自编码器的最大似然训练

    Maximum Likelihood Training of Autoencoders. (arXiv:2306.01843v1 [cs.LG])

    [http://arxiv.org/abs/2306.01843](http://arxiv.org/abs/2306.01843)

    本文介绍了一种成功的最大似然训练方法，用于非约束自编码器，将生成建模的优异性质与高效自编码器相结合。作者克服了两个挑战：设计了消除迭代的估计器并提出了稳定的最大似然训练目标。实验证明这种方法可以成功训练一系列非约束性自编码器，并取得了有竞争力的性能。

    

    最大似然训练在生成建模中具有优异的统计性质，尤其是在归一化流模型中非常流行。另一方面，由于流形假设，生成自编码器有望比归一化流更高效。本文首次引入了非约束自编码器的成功最大似然训练，将这两种范式融合在一起。为此，我们识别并克服了两个挑战：首先，现有的自由格式网络的最大似然估计器过于缓慢，依赖于迭代方案，其成本随潜在维度呈线性增长。我们引入了一个改进的估计器，消除了迭代，从而使成本保持不变（每个批次的运行时间大约是普通自编码器的两倍）。其次，我们证明朴素地将最大似然应用于自编码器可能导致发散解决方案，并利用这个想法来推动稳定的最大似然训练目标。我们进行了实验，表明所提出的训练方法可以成功训练一系列非约束性自编码器，并在生成图像、插值和变换等任务中取得了有竞争力的性能。

    Maximum likelihood training has favorable statistical properties and is popular for generative modeling, especially with normalizing flows. On the other hand, generative autoencoders promise to be more efficient than normalizing flows due to the manifold hypothesis. In this work, we introduce successful maximum likelihood training of unconstrained autoencoders for the first time, bringing the two paradigms together. To do so, we identify and overcome two challenges: Firstly, existing maximum likelihood estimators for free-form networks are unacceptably slow, relying on iteration schemes whose cost scales linearly with latent dimension. We introduce an improved estimator which eliminates iteration, resulting in constant cost (roughly double the runtime per batch of a vanilla autoencoder). Secondly, we demonstrate that naively applying maximum likelihood to autoencoders can lead to divergent solutions and use this insight to motivate a stable maximum likelihood training objective. We per
    
[^24]: 正则化深度神经网络的幽灵噪声

    Ghost Noise for Regularizing Deep Neural Networks. (arXiv:2305.17205v1 [cs.LG])

    [http://arxiv.org/abs/2305.17205](http://arxiv.org/abs/2305.17205)

    本文研究了幽灵批量归一化（GBN）中的“幽灵噪声”，提出了一种新的正则化技术Ghost Noise Injection (GNI)，该方法能够避免小批量训练带来的训练-测试差异效应，并在深度神经网络中提供更好的泛化效果。

    

    批量归一化（BN）被广泛用于稳定深度神经网络的优化过程并提高测试性能。BN的正则化效果取决于批量大小，显式使用较小的批量大小会通过批量归一化提高泛化性，在许多设置中都具有很好的应用。本文通过将引入的“幽灵噪声”与归一化进行分离，并定量分析噪声的分布及其对模型性能的影响来研究GBN的有效性。受我们分析的启发，我们提出了一种新的正则化技术称为Ghost Noise Injection (GNI)，模仿了GBN中的噪声，而避免了小批量训练带来的有害的训练-测试差异效应。实验证明GNI可以比GBN提供更好的泛化效益。Ghost Noise Injection在其他非噪声设置中，例如层归一化网络也能够产生积极作用。

    Batch Normalization (BN) is widely used to stabilize the optimization process and improve the test performance of deep neural networks. The regularization effect of BN depends on the batch size and explicitly using smaller batch sizes with Batch Normalization, a method known as Ghost Batch Normalization (GBN), has been found to improve generalization in many settings. We investigate the effectiveness of GBN by disentangling the induced "Ghost Noise" from normalization and quantitatively analyzing the distribution of noise as well as its impact on model performance. Inspired by our analysis, we propose a new regularization technique called Ghost Noise Injection (GNI) that imitates the noise in GBN without incurring the detrimental train-test discrepancy effects of small batch training. We experimentally show that GNI can provide a greater generalization benefit than GBN. Ghost Noise Injection can also be beneficial in otherwise non-noisy settings such as layer-normalized networks, provi
    
[^25]: 概率指数积分器

    Probabilistic Exponential Integrators. (arXiv:2305.14978v1 [math.NA])

    [http://arxiv.org/abs/2305.14978](http://arxiv.org/abs/2305.14978)

    本文提出了一种新的概率指数积分器，它在处理刚性系统时具有更好的性能，能够提供数值误差的概率解释，并且能够被应用于广泛的非线性系统中。

    

    概率求解器为动态系统的模拟、不确定性量化和推断提供了灵活和高效的框架。然而，在某些刚性系统中，它们像标准求解器一样会遇到性能惩罚，因为需要采取小步长不是为了数值精度，而是为了稳定性。本文提出的概率指数积分器极大地缓解了这个问题。通过将快速、线性动态加入先验中，我们得到了一类具有有利性质的概率积分器。即它们被证明是L-稳定的，在某些情况下，它们会降低到经典的指数积分器，同时提供了数值误差的概率解释。通过在先前估计值的向量场雅可比上强加分段半线性，该方法还推广到任意非线性系统，从而产生了能够在广泛的刚性问题中保持稳定性和准确性的概率指数积分器。

    Probabilistic solvers provide a flexible and efficient framework for simulation, uncertainty quantification, and inference in dynamical systems. However, like standard solvers, they suffer performance penalties for certain stiff systems, where small steps are required not for reasons of numerical accuracy but for the sake of stability. This issue is greatly alleviated in semi-linear problems by the probabilistic exponential integrators developed in this paper. By including the fast, linear dynamics in the prior, we arrive at a class of probabilistic integrators with favorable properties. Namely, they are proven to be L-stable, and in a certain case reduce to a classic exponential integrator -- with the added benefit of providing a probabilistic account of the numerical error. The method is also generalized to arbitrary non-linear systems by imposing piece-wise semi-linearity on the prior via Jacobians of the vector field at the previous estimates, resulting in probabilistic exponential
    
[^26]: 多智能体真实世界展示中强化学习的自适应行动监督

    Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations. (arXiv:2305.13030v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.13030](http://arxiv.org/abs/2305.13030)

    本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。

    

    在各种科学和工程领域中，对真实世界生物多智能体进行建模是一个基本问题。强化学习（RL）是在网络空间中生成灵活和多样化行为的强大框架；然而，在建模真实世界生物多智能体时，在源（即真实世界数据）和目标（即 RL 的网络空间）之间存在域差异，并且源环境参数通常是未知的。在本文中，我们提出了一种从多智能体场景的真实世界展示中进行 RL 的自适应行动监督的方法。我们采用结合 RL 和监督学习的方法，通过选择基于动态时间扭曲的演示动作来在 RL 中利用未知源动态的信息。这种方法可以轻松应用于许多现有的神经网络架构，并为我们提供一个在复制和推广之间平衡的 RL 模型。

    Modeling of real-world biological multi-agents is a fundamental problem in various scientific and engineering fields. Reinforcement learning (RL) is a powerful framework to generate flexible and diverse behaviors in cyberspace; however, when modeling real-world biological multi-agents, there is a domain gap between behaviors in the source (i.e., real-world data) and the target (i.e., cyberspace for RL), and the source environment parameters are usually unknown. In this paper, we propose a method for adaptive action supervision in RL from real-world demonstrations in multi-agent scenarios. We adopt an approach that combines RL and supervised learning by selecting actions of demonstrations in RL based on the minimum distance of dynamic time warping for utilizing the information of the unknown source dynamics. This approach can be easily applied to many existing neural network architectures and provide us with an RL model balanced between reproducibility as imitation and generalization ab
    
[^27]: 机器制造的媒体：监测虚假新闻和主流新闻网站上机器生成文章的动向。

    Machine-Made Media: Monitoring the Mobilization of Machine-Generated Articles on Misinformation and Mainstream News Websites. (arXiv:2305.09820v1 [cs.CY])

    [http://arxiv.org/abs/2305.09820](http://arxiv.org/abs/2305.09820)

    这篇论文研究了机器生成文章在虚假新闻和主流新闻网站的普及程度，发现虚假新闻网站上合成文章的使用速度比主流网站上更快。

    

    随着像ChatGPT这样的生成式大型语言模型（LLM）日益流行，越来越多的新闻网站开始利用它们生成文章。然而，这些语言模型不仅可能在声誉良好的网站上产生事实不准确的文章，而且不良新闻网站也可以利用这些LLM批量生产虚假信息。为了开始理解这一现象，我们提出了首个大规模研究合成文章在线新闻媒体中普及率的研究。为此，我们训练了一个基于DeBERTa的合成新闻检测器，并对3074个虚假新闻和主流新闻网站的超过1291万篇文章进行分类。我们发现，在2022年1月1日至2023年4月1日期间，合成新闻文章的相对数量在主流网站上增加了79.4％，而在虚假信息网站上增加了342％。分析ChatGPT发布的影响，使用中断时间序列，我们发现，虽然它的发布导致合成文章的使用显著增加，但虚假信息网站上的合成文章使用速度比主流网站上的快。

    With the increasing popularity of generative large language models (LLMs) like ChatGPT, an increasing number of news websites have begun utilizing them to generate articles. However, not only can these language models produce factually inaccurate articles on reputable websites but disreputable news sites can utilize these LLMs to mass produce misinformation. To begin to understand this phenomenon, we present one of the first large-scale studies of the prevalence of synthetic articles within online news media. To do this, we train a DeBERTa-based synthetic news detector and classify over 12.91 million articles from 3,074 misinformation and mainstream news websites. We find that between January 1, 2022 and April 1, 2023, the relative number of synthetic news articles increased by 79.4% on mainstream websites while increasing by 342% on misinformation sites. Analyzing the impact of the release of ChatGPT using an interrupted-time-series, we show that while its release resulted in a marked
    
[^28]: JaxPruner：一个用于稀疏性研究的简明库

    JaxPruner: A concise library for sparsity research. (arXiv:2304.14082v1 [cs.LG])

    [http://arxiv.org/abs/2304.14082](http://arxiv.org/abs/2304.14082)

    本文介绍了JaxPruner，一款用于研究稀疏神经网络的开源库。JaxPruner提供了流行的剪枝和稀疏训练算法的简明实现，最小化内存和延迟开销，并可轻松集成到现有的JAX库中。

    

    本文介绍了JaxPruner，这是一个基于JAX的开源剪枝和稀疏训练库，旨在通过提供流行的剪枝和稀疏训练算法的简明实现，最小化内存和延迟开销，加速稀疏神经网络的研究。JaxPruner实现的算法使用通用API，并与流行的优化库Optax无缝协作，从而使其能轻松集成到现有的JAX库中。我们通过在四个不同的代码库中提供示例并在流行的基准测试中提供基准实验来展示这种集成的便捷性。

    This paper introduces JaxPruner, an open-source JAX-based pruning and sparse training library for machine learning research. JaxPruner aims to accelerate research on sparse neural networks by providing concise implementations of popular pruning and sparse training algorithms with minimal memory and latency overhead. Algorithms implemented in JaxPruner use a common API and work seamlessly with the popular optimization library Optax, which, in turn, enables easy integration with existing JAX based libraries. We demonstrate this ease of integration by providing examples in four different codebases: Scenic, t5x, Dopamine and FedJAX and provide baseline experiments on popular benchmarks.
    
[^29]: 用人工神经网络预测国内生产总值：长期记忆有多大的作用？

    GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])

    [http://arxiv.org/abs/2304.05805](http://arxiv.org/abs/2304.05805)

    通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。

    

    在本研究中，我们将不同的统计模型应用于美国经济季度国内生产总值（GDP）增长预测。使用每月的FRED-MD数据库，我们比较了动态因子模型（DFM）和四个人工神经网络（ANNs）的预测表现：多层感知机（MLP）、一维卷积神经网络（1D CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。实证分析呈现了两个不同评估周期的结果。第一个周期（2010年第1季度至2019年第4季度）具有平衡的经济增长，而第二个周期（2010年第1季度至2022年第3季度）还包括COVID-19衰退期间的时间。根据我们的结果，更长的输入序列在平衡经济增长期间能够实现更准确的预测。然而，在一个相对较低的阈值值（约六个季度或十八个月）以后，这种效应会消失。在经济动荡期（如COVID-19衰退期间），长期记忆的效果会变得较为明显。

    In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
    
[^30]: 异构时空图神经网络在期货量化投资中的应用研究

    Futures Quantitative Investment with Heterogeneous Continual Graph Neural Network. (arXiv:2303.16532v1 [cs.LG])

    [http://arxiv.org/abs/2303.16532](http://arxiv.org/abs/2303.16532)

    为了预测期货价格趋势，本文提出了一种基于异构任务设计和连续训练的时空图神经网络模型，可以捕捉长期和短期特征。

    

    传统计量模型预测期货价格趋势是一个具有挑战性的问题，因为需要考虑到期货历史数据以及不同期货之间的关联。时空图神经网络在处理此类空间时间数据方面具有很大的优势。本研究通过设计四个异构任务来捕捉长期和短期特征：价格回归、移动平均价格回归、短时间内的价格差回归和变化点检测。为了充分利用这些标签，我们采用连续训练的方式对模型进行训练。

    It is a challenging problem to predict trends of futures prices with traditional econometric models as one needs to consider not only futures' historical data but also correlations among different futures. Spatial-temporal graph neural networks (STGNNs) have great advantages in dealing with such kind of spatial-temporal data. However, we cannot directly apply STGNNs to high-frequency future data because future investors have to consider both the long-term and short-term characteristics when doing decision-making. To capture both the long-term and short-term features, we exploit more label information by designing four heterogeneous tasks: price regression, price moving average regression, price gap regression (within a short interval), and change-point detection, which involve both long-term and short-term scenes. To make full use of these labels, we train our model in a continual manner. Traditional continual GNNs define the gradient of prices as the parameter important to overcome ca
    
[^31]: 混合最小二乘深度神经网络在内部测量下的导电率成像

    Conductivity Imaging from Internal Measurements with Mixed Least-Squares Deep Neural Networks. (arXiv:2303.16454v1 [math.NA])

    [http://arxiv.org/abs/2303.16454](http://arxiv.org/abs/2303.16454)

    本论文提出了一种新的通过深度神经网络从内部测量中重构椭圆问题中的导电率分布的方法，并在连续和经验损失的神经网络逼近上进行了深入的分析，展示了该方法对于数据噪声的优异稳定性以及解决高维问题的能力。

    

    在这项工作中，我们使用深度神经网络开发了一种新的方法，从一个内部测量中重构椭圆问题中的导电率分布。该方法基于控制方程的混合改造，并利用标准的最小二乘目标函数同时近似导电率和通量，以深度神经网络作为试探函数。我们对连续和经验损失的神经网络逼近进行了深入的分析，包括通过噪声水平、各种惩罚参数和神经网络结构参数（深度、宽度和参数边界）显式地估计误差的严格估计。我们还进行了广泛的数值实验，以展示该方法的不同特点，例如对于数据噪声的优异稳定性以及解决高维问题的能力。

    In this work we develop a novel approach using deep neural networks to reconstruct the conductivity distribution in elliptic problems from one internal measurement. The approach is based on a mixed reformulation of the governing equation and utilizes the standard least-squares objective to approximate the conductivity and flux simultaneously, with deep neural networks as ansatz functions. We provide a thorough analysis of the neural network approximations for both continuous and empirical losses, including rigorous error estimates that are explicit in terms of the noise level, various penalty parameters and neural network architectural parameters (depth, width and parameter bound). We also provide extensive numerical experiments in two- and multi-dimensions to illustrate distinct features of the approach, e.g., excellent stability with respect to data noise and capability of solving high-dimensional problems.
    
[^32]: LossMix：简化和广泛应用 Mixup 于目标检测和更多领域

    LossMix: Simplify and Generalize Mixup for Object Detection and Beyond. (arXiv:2303.10343v1 [cs.CV])

    [http://arxiv.org/abs/2303.10343](http://arxiv.org/abs/2303.10343)

    本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。

    

    数据混合增强广泛应用于图像分类任务中，但由于空间错位、前景/背景区分以及多个实例的挑战，这些技术不易应用于目标检测。本文提出一种称为监督插值的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，然后在这个框架的基础上，提出了 LossMix，这是一种简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性。我们的关键insight是，通过插值损失误差来调整训练可以有效规范混合数据的训练，而不是使用ground truth标签。在PASCAL VOC和MS COCO数据集上的实证结果表明，LossMix始终优于当前流行的混合策略，并且我们设计了一种两阶段领域m...

    The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain m
    
[^33]: 通过损失检查在目标检测数据集中识别标签错误

    Identifying Label Errors in Object Detection Datasets by Loss Inspection. (arXiv:2303.06999v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.06999](http://arxiv.org/abs/2303.06999)

    本研究首次引入了一个用于目标检测数据集上标签错误检测的基准以及一种标签错误检测方法和几种基线方法。研究模拟了四种不同类型的随机引入的标签错误，并提出了一种通过损失检查来检测这些错误的方法。

    

    为监督目标检测的标签数据集进行标注是一个枯燥且耗时的任务。在注释过程中很容易引入错误，并且在审核过程中可能会被忽视，导致准确度低下的基准和基于噪声标签训练的深度神经网络性能降低。在本研究中，我们首次引入了一个用于目标检测数据集上的标签错误检测方法的基准以及一个标签错误检测方法和一些基线方法。我们在已经标记良好的目标检测数据集的训练集和测试集中模拟了四种不同类型的随机引入的标签错误。对于我们的标签错误检测方法，我们假设已经提供了一个两阶段目标检测器，并考虑两个阶段的分类损失和回归损失的总和。这些损失基于预测和包括模拟标签错误的噪声标签进行计算，旨在检测后者。我们将我们的方法与三个基线进行了比较：一个无深度学习的朴素方法，目标检测器的...

    Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector'
    
[^34]: 基于伪对比学习的基于图的半监督学习

    Pseudo Contrastive Learning for Graph-based Semi-supervised Learning. (arXiv:2302.09532v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09532](http://arxiv.org/abs/2302.09532)

    本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。

    

    伪标签是一种用于改进半监督图神经网络(GNNs)性能的技术，通过根据自信的预测生成附加的伪标签。然而，由于分类目标对给定标签的敏感性，生成的伪标签质量一直是一个长期存在的问题。为了避免不可靠的分类监督“一个节点属于特定类”，我们更喜欢容错性对比监督“两个节点不属于同一类”。因此，生成高质量伪标签问题转化为一个放松的版本，即识别可靠的负样本对。为了实现这一点，我们提出了一种通用的GNNs框架，称之为伪对比学习(PCL)。它将目标为相同类的正伪标签和负伪标签的两个节点分开。为了将拓扑知识纳入学习中，我们设计了一种拓扑加权对比学习方法

    Pseudo Labeling is a technique used to improve the performance of semi-supervised Graph Neural Networks (GNNs) by generating additional pseudo-labels based on confident predictions. However, the quality of generated pseudo-labels has been a longstanding concern due to the sensitivity of the classification objective with respect to the given labels. To avoid the untrustworthy classification supervision indicating ``a node belongs to a specific class,'' we favor the fault-tolerant contrasting supervision demonstrating ``two nodes do not belong to the same class.'' Thus, the problem of generating high-quality pseudo-labels is then transformed into a relaxed version, i.e., identifying reliable negative pairs. To achieve this, we propose a general framework for GNNs, termed Pseudo Contrastive Learning (PCL). It separates two nodes whose positive and negative pseudo-labels target the same class. To incorporate topological knowledge into learning, we devise a topologically weighted contrastiv
    
[^35]: Mithridates：增强对后门学习的自然抵抗

    Mithridates: Boosting Natural Resistance to Backdoor Learning. (arXiv:2302.04977v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.04977](http://arxiv.org/abs/2302.04977)

    Mithridates 是一种新方法，通过在不改变训练管道的情况下增强机器学习模型对后门攻击的自然抵抗力，让从业人员能够回答如何评估模型对后门中毒攻击的抵抗力以及如何提高抵抗力的可行问题。

    

    在潜在不可信来源的数据上训练的机器学习模型容易受到中毒攻击。训练输入的一个小的恶意制作的子集可以导致模型学习一个“后门”任务（例如，错误分类具有特定特征的输入），除了其主任务。虽然后门攻击仍然主要是一种假设的威胁，但最先进的防御需要对现有的机器学习管道进行巨大的改变，而且对于实际部署来说太复杂了。在本文中，我们采取了一种实用的视角，研究了机器学习管道对后门攻击的自然抵抗力，即在不改变模型训练方式的情况下实现的抵抗力。我们设计、实现和评估了 Mithridates，一种新的方法，帮助从业人员回答两个可行的问题：（1）我的模型在抵御后门中毒攻击方面表现如何？（2）如何提高它的抵抗力而不改变训练管道？Mithridates 利用超参数搜索

    Machine learning (ML) models trained on data from potentially untrusted sources are vulnerable to poisoning. A small, maliciously crafted subset of the training inputs can cause the model to learn a "backdoor" task (e.g., misclassify inputs with a certain feature) in addition to its main task. While backdoor attacks remain largely a hypothetical threat, state-of-the-art defenses require massive changes to the existing ML pipelines and are too complex for practical deployment.  In this paper, we take a pragmatic view and investigate natural resistance of ML pipelines to backdoor attacks, i.e., resistance that can be achieved without changes to how models are trained. We design, implement, and evaluate Mithridates, a new method that helps practitioners answer two actionable questions: (1) how well does my model resist backdoor poisoning attacks?, and (2) how can I increase its resistance without changing the training pipeline? Mithridates leverages hyperparameter search $\unicode{x2013}$
    
[^36]: 关于差分隐私少样本图像分类方法有效性的研究

    On the Efficacy of Differentially Private Few-shot Image Classification. (arXiv:2302.01190v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.01190](http://arxiv.org/abs/2302.01190)

    本文通过一系列实验研究了差分隐私少样本图像分类模型的准确性和易受攻击性，揭示了样本数、隐私级别、模型架构、下游数据集以及可学习参数子集等因素对分类效果的影响。

    

    近年来，在训练差分隐私（DP）模型方面取得了显著进展，这些DP模型的准确性接近最佳的非私有模型。这些DP模型通常在大规模公共数据集上预训练，然后在相对大且与预训练数据分布相似的私有下游数据集上进行微调。然而，在许多应用中，包括个性化和联合学习，重要的是在少样本情况下良好地表现（i.e. 获取大量标记数据可能有问题），且能够在各种领域的数据集上（即用于各种专业设置）进行良好的分类。为了了解少样本DP何时有效，我们进行了一系列详尽的实验，揭示了每类样本数、隐私级别、模型架构、下游数据集以及可学习参数子集等对少样本DP图像分类模型准确性和易受攻击性的影响。

    There has been significant recent progress in training differentially private (DP) models which achieve accuracy that approaches the best non-private models. These DP models are typically pretrained on large public datasets and then fine-tuned on private downstream datasets that are relatively large and similar in distribution to the pretraining data. However, in many applications including personalization and federated learning, it is crucial to perform well (i) in the few-shot setting, as obtaining large amounts of labeled data may be problematic; and (ii) on datasets from a wide variety of domains for use in various specialist settings. To understand under which conditions few-shot DP can be effective, we perform an exhaustive set of experiments that reveals how the accuracy and vulnerability to attack of few-shot DP image classification models are affected as the number of shots per class, privacy level, model architecture, downstream dataset, and subset of learnable parameters in 
    
[^37]: 风险敏感的强化学习算法：指数标准的应用

    Risk-Sensitive Reinforcement Learning with Exponential Criteria. (arXiv:2212.09010v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.09010](http://arxiv.org/abs/2212.09010)

    本文介绍了一种风险敏感的强化学习算法，使用指数判据来提高其系统抗干扰性和实用性。作者进行了在模拟和实际机器人上的实验验证，表明该算法能够有效地提高样本效率和执行效果。

    

    尽管风险中性的强化学习已经在很多应用中得到了实验成功，但是这种方法容易受到噪声和系统参数扰动的影响而不够稳健。因此,对风险敏感的强化学习算法进行了研究，以提高其系统抗干扰性，样本效率和实用性。本文介绍了一种新型的无模型风险敏感学习算法，将广泛使用的策略梯度算法进行变体，其实现过程类似。具体来说，本文研究了指数标准对强化学习代理的策略风险敏感性的影响，并开发了蒙特卡罗策略梯度算法和在线(时间差分)演员-评论家算法的变体。分析结果表明，指数标准的使用能够推广常用的特定正则化方法。作者在摆动杆和摆摆杆任务上进行了测试，验证了所提出的算法的实现性能和稳健性。

    While risk-neutral reinforcement learning has shown experimental success in a number of applications, it is well-known to be non-robust with respect to noise and perturbations in the parameters of the system. For this reason, risk-sensitive reinforcement learning algorithms have been studied to introduce robustness and sample efficiency, and lead to better real-life performance. In this work, we introduce new model-free risk-sensitive reinforcement learning algorithms as variations of widely-used Policy Gradient algorithms with similar implementation properties. In particular, we study the effect of exponential criteria on the risk-sensitivity of the policy of a reinforcement learning agent, and develop variants of the Monte Carlo Policy Gradient algorithm and the online (temporal-difference) Actor-Critic algorithm. Analytical results showcase that the use of exponential criteria generalize commonly used ad-hoc regularization approaches. The implementation, performance, and robustness 
    
[^38]: 通过半监督学习和生成对抗网络在不平衡数据集中进行虚假检测

    Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01071](http://arxiv.org/abs/2212.01071)

    本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。

    

    随着社交媒体的快速发展，骚扰行为变得更加普遍，这导致了虚假检测成为研究人员中引人注目的领域。数据的图形特性以及大量节点导致了许多障碍，包括矩阵中大量无关特征的高离散度和不平衡类别。为了解决这些问题，本文采用了自编码器和半监督学习与生成对抗网络算法的组合，即SGAN。本文将少量标签应用于SGAN作为分类器。实验结果表明，仅使用100个标记样本，该方法在检测虚假账户方面的准确率达到了91\%。

    As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\% in detecting fake accounts using only 100 labeled samples.
    
[^39]: 针对声学对抗性机器学习逃避的实时语音情感检测的隐私保护

    Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning. (arXiv:2211.09273v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09273](http://arxiv.org/abs/2211.09273)

    本研究通过对抗机器学习的方法，提出了一种名为DARE-GP的解决方案，可以在不影响智能音箱效用的情况下，逃避与智能音箱相连的语音情感识别分类器，从而保护隐私。

    

    情感监视是一个新兴领域，涉及到广泛的隐私问题。这些问题在普遍存在的物联网设备和多传感器的支持下，变得更加严重，而这些设备可以支持这些监视用例。本文考虑了一个这样的应用案例：使用与智能音箱相连的语音情感识别（SER）分类器。本文展示了如何在不影响智能音箱的效用的情况下，逃避与智能音箱相连的黑盒SER分类器。通过对机器学习的对抗逃避的视角来考虑这个隐私问题。我们的解决方案名为“通过遗传规划击败声学情感识别的DARE-GP”，它使用遗传规划生成非侵入性的添加音频扰动（AAPs）。通过约束这些AAP的进化，可以保护转录准确性，同时降低SER分类器的性能。这些AAP的加性特性，以及为特定目标生成这些AAPs的方法，使DARE-GP成为一个有效的隐私保护方法。

    Emotional Surveillance is an emerging area with wide-reaching privacy concerns. These concerns are exacerbated by ubiquitous IoT devices with multiple sensors that can support these surveillance use cases. The work presented here considers one such use case: the use of a speech emotion recognition (SER) classifier tied to a smart speaker. This work demonstrates the ability to evade black-box SER classifiers tied to a smart speaker without compromising the utility of the smart speaker. This privacy concern is considered through the lens of adversarial evasion of machine learning. Our solution, Defeating Acoustic Recognition of Emotion via Genetic Programming (DARE-GP), uses genetic programming to generate non-invasive additive audio perturbations (AAPs). By constraining the evolution of these AAPs, transcription accuracy can be protected while simultaneously degrading SER classifier performance. The additive nature of these AAPs, along with an approach that generates these AAPs for a fi
    
[^40]: 极化编码：一种用于处理缺失值分类的简单基线方法

    Polar Encoding: A Simple Baseline Approach for Classification with Missing Values. (arXiv:2210.01905v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01905](http://arxiv.org/abs/2210.01905)

    极化编码是一种用于处理具有缺失值的分类问题的简单基线方法，它能保留缺失信息、无需插补，让决策树自由选择如何处理缺失值。

    

    我们提出了一种称为极化编码的表示方法，用于处理具有缺失值的分类问题中的分类和数值型$[0,1]$值属性。我们认为这是一种很好的基准方法，因为它可以与任何分类算法配合使用，能够保留缺失信息，非常简单易用并且性能良好。与现有的缺失指示方法不同，极化编码不需要插补，确保缺失值与非缺失值等距离，让决策树算法自由选择如何分割缺失值，从而实现了“属性中包含缺失性”（MIA）的实际处理。此外，我们还展示了分类和$[0,1]$值属性可以被看作是一个单一属性类型的特殊情况，对应于经典的重心坐标概念，这提供了极化编码的模糊化形式的自然解释。

    We propose polar encoding, a representation of categorical and numerical $[0,1]$-valued attributes with missing values to be used in a classification context. We argue that this is a good baseline approach, because it can be used with any classification algorithm, preserves missingness information, is very simple to apply and offers good performance. In particular, unlike the existing missing-indicator approach, it does not require imputation, ensures that missing values are equidistant from non-missing values, and lets decision tree algorithms choose how to split missing values, thereby providing a practical realisation of the "missingness incorporated in attributes" (MIA) proposal. Furthermore, we show that categorical and $[0,1]$-valued attributes can be viewed as special cases of a single attribute type, corresponding to the classical concept of barycentric coordinates, and that this offers a natural interpretation of polar encoding as a fuzzified form of one-hot encoding. With an 
    
[^41]: 元元反游戏学习组合学习行为

    Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.08012](http://arxiv.org/abs/2207.08012)

    本论文提出了一种元元反游戏学习的方法来解决组合学习行为的问题，通过解决绑定问题来支持人工智能代理展示组合学习行为的能力。

    

    人类利用组合性从过去的经验中推广到新颖的经验。我们假设我们的经验可以分解为基本的原子组件，这些组件可以以新颖的方式重新组合，以支持我们参与新颖经验的能力。我们将这视为学习以组合方式泛化的能力，并将利用这种能力的行为称为组合学习行为（CLBs）。学习CLBs的一个核心问题是解决绑定问题（BP）。尽管这是人类轻松完成的智能壮举，但对于现有技术的人工智能代理来说并非如此。因此，为了构建能够与人类合作的人工智能代理，我们建议开发一个新的基准来研究代理商通过解决BP的领域无关版本来展示CLBs的能力。我们受到指代游戏的语言涌现和基础架构框架的启发，提出了一个元学习扩展方案

    Human beings use compositionality to generalise from past experiences to novel experiences. We assume a separation of our experiences into fundamental atomic components that can be recombined in novel ways to support our ability to engage with novel experiences. We frame this as the ability to learn to generalise compositionally, and we will refer to behaviours making use of this ability as compositional learning behaviours (CLBs). A central problem to learning CLBs is the resolution of a binding problem (BP). While it is another feat of intelligence that human beings perform with ease, it is not the case for state-of-the-art artificial agents. Thus, in order to build artificial agents able to collaborate with human beings, we propose to develop a novel benchmark to investigate agents' abilities to exhibit CLBs by solving a domain-agnostic version of the BP. We take inspiration from the language emergence and grounding framework of referential games and propose a meta-learning extensio
    
[^42]: 数据有效的 GAN 训练中的自我监督增强技术

    Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15677](http://arxiv.org/abs/2205.15677)

    本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。

    

    有限数据情况下训练生成式对抗网络（GAN）是具有挑战性的，因为判别器容易过拟合。先前提出的可微增强技术改善了GAN训练的数据效率。但是，增强技术隐式地引入了不良不变性因素，因为它忽略了由数据转换引起的标签空间语义变化，这可能限制了判别器的表示学习能力，并最终影响生成模型的表现。为了减轻不变性的负面影响，同时继承数据增强的好处，我们提出了一种新的增强感知的自监督判别器，该判别器可以预测增强数据的参数。特别地，真实数据和生成数据的预测目标在训练过程中需要区别开来。我们还鼓励生成器对抗地生成其增强参数可以被判别器准确预测的数据，从而获得更多信息量和更高效的判别器，提高生成模型的性能。多个数据集上的实验表明，我们的方法在数据有效的 GAN 训练中实现了最先进的性能。

    Training generative adversarial networks (GANs) with limited data is challenging because discriminator is prone to overfitting. Previously proposed differentiable augmentation demonstrates improved data efficiency of training GANs. However, the augmentation implicitly introduces undesired invariance to augmentation for the discriminator since it ignores the change of semantics in the label space caused by data transformation, which may limit the representation learning ability of the discriminator and ultimately affect the generative modeling performance of the generator. To mitigate the negative impact of invariance while inheriting the benefits of data augmentation, we propose a novel augmentation-aware self-supervised discriminator that predicts the augmentation parameter of the augmented data. Particularly, the prediction targets of real data and generated data are required to be distinguished since they are different during training. We further encourage the generator to adversari
    

