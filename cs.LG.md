# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deep Conditional Generative Learning: Model and Error Analysis](https://rss.arxiv.org/abs/2402.01460) | 提出了一种基于ODE的深度生成方法，通过条件Follmer流来学习条件分布，通过离散化和深度神经网络实现高效转化。同时，通过Wasserstein距离的非渐近收敛速率，提供了第一个端到端误差分析，数值实验证明其在不同场景下的优越性。 |
| [^2] | [Functional Bilevel Optimization for Machine Learning](https://arxiv.org/abs/2403.20233) | 介绍了机器学习中的函数双层优化问题，提出了不依赖于强凸假设的方法，并展示了在仪表回归和强化学习任务中使用神经网络的优势。 |
| [^3] | [Multi-Scale Protein Language Model for Unified Molecular Modeling](https://arxiv.org/abs/2403.12995) | 提出了一种多尺度蛋白质语言模型，能够在蛋白质和小分子相关任务中超越先前的方法，并且通过统一分子建模实现了充分利用蛋白质语言模型的潜力。 |
| [^4] | [Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making](https://arxiv.org/abs/2403.11432) | 本研究致力于研究基于注意力的DRL框架的可解释性，在自主车辆决策中，通过在开源AV仿真环境中添加多头注意力框架，提高了模型的解释性。 |
| [^5] | [ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image](https://arxiv.org/abs/2403.09871) | ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。 |
| [^6] | [Towards Model-Agnostic Posterior Approximation for Fast and Accurate Variational Autoencoders](https://arxiv.org/abs/2403.08941) | 最近的研究表明，为了确保高质量的推断模型，可以通过迭代训练最大化与推断模型相关的目标函数，以解决变分自编码器中推断模型近似不准确导致的局部最优解问题。 |
| [^7] | [Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations](https://arxiv.org/abs/2403.06009) | 创建了一系列检测器库，其中包含紧凑且易于构建的分类模型，为各种危害提供标签，可作为大型语言模型（LLMs）的有效替代方案。 |
| [^8] | [Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event Argument Data](https://arxiv.org/abs/2403.03304) | Mad Libs 提供的数据增强方法 MLA 在跨领域文档级事件参数数据提取上取得了显著的性能提升，平均提高了 2.6 个 F1 分数。同时，在零和少样本事件角色方面相比无增强基线，提高了 3.9 和 5.2 个百分点。 |
| [^9] | [On a Neural Implementation of Brenier's Polar Factorization](https://arxiv.org/abs/2403.03071) | 提出了Brenier的极分解定理的神经实现，探讨了在机器学习中的应用，并通过神经网络参数化潜在函数$u$，从最新神经最优输运领域的进展中汲取灵感。 |
| [^10] | [Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning](https://arxiv.org/abs/2402.15734) | 该论文提出了一种通过无监督预训练和上下文学习方法实现PDE运算符学习的高效方式，以提高数据效率并改善模型的外域性能。 |
| [^11] | [Bridging Associative Memory and Probabilistic Modeling](https://arxiv.org/abs/2402.10202) | 基于联想记忆的能量函数可以被视为概率建模的对数似然函数，这篇论文构建了两者之间的桥梁，提出了新的基于能量的模型，并展示了两种新的联想记忆模型，可灵活适应上下文数据集。 |
| [^12] | [Predictive Linear Online Tracking for Unknown Targets](https://arxiv.org/abs/2402.10036) | 本文提出了一种名为预测性线性在线追踪（PLOT）的算法，用于在线追踪未知目标。该算法使用具有指数遗忘的递归最小二乘法来学习目标的时变动态模型，并在递推视线控制的框架下使用所学模型进行最优策略。与先前的工作不同，我们的理论结果适用于非平稳目标。 |
| [^13] | [Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning](https://arxiv.org/abs/2402.07586) | 该研究在联邦学习中的分布式环境下，首次探索了在存在特定群体概念漂移的情况下实现公平性的挑战和解决方案。 |
| [^14] | [Transfer learning with generative models for object detection on limited datasets](https://arxiv.org/abs/2402.06784) | 本论文提出了一个适用于通用情景的基于生成模型的迁移学习框架，用于解决有限数据集上的目标检测任务。 |
| [^15] | [Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions](https://arxiv.org/abs/2402.06160) | 本文通过混合狄利克雷分布来改进证据深度学习（EDL）方法，解决了现有方法中认知不确定性在无限样本限制下可能不会消失的问题。 |
| [^16] | [Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss](https://arxiv.org/abs/2402.05928) | 本文研究了依赖学习理论中的尖锐率，主要是为了避免样本大小缩减对方差产生影响。当假设类别的拓扑结构符合某些条件时，经验风险最小化者的性能与类别的复杂性和二阶统计量有关。 |
| [^17] | [Unichain and Aperiodicity are Sufficient for Asymptotic Optimality of Average-Reward Restless Bandits](https://arxiv.org/abs/2402.05689) | 该论文提出了一种新的策略类别，用于解决无限期平均回报好转胆冒险问题。研究表明，在单臂松弛问题是Unichain和非周期性的情况下，该策略类别具有渐进最优性。 |
| [^18] | [A Non-Intrusive Neural Quality Assessment Model for Surface Electromyography Signals](https://arxiv.org/abs/2402.05482) | 本研究提出了一种新的非侵入性神经质量评估模型QASE-net，可以有效预测表面肌电信号的信噪比，实验证明其相比之前的模型具有更低的预测误差和更高的线性相关性。 |
| [^19] | [Open-Vocabulary Calibration for Vision-Language Models](https://arxiv.org/abs/2402.04655) | 本文研究了视觉语言模型中的开放词汇校准问题，在提示学习的背景下发现现有的校准方法不足以解决该问题。为此，提出了一种称为 Distance-Aware Ca 的简单而有效的方法来解决问题。 |
| [^20] | [LESS: Selecting Influential Data for Targeted Instruction Tuning](https://arxiv.org/abs/2402.04333) | LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。 |
| [^21] | [Gaussian Plane-Wave Neural Operator for Electron Density Estimation](https://arxiv.org/abs/2402.04278) | 本研究提出了一种名为高斯平面波神经算子(GPWNO)的方法，用于机器学习中的电子密度预测。该方法利用平面波和高斯型轨道基底在无限维功能空间中进行操作，可以有效地表示密度的高频和低频成分，并在多个数据集上展示出卓越的性能。 |
| [^22] | [Learning Metrics that Maximise Power for Accelerated A/B-Tests](https://arxiv.org/abs/2402.03915) | 本论文提出了一种新方法，通过从短期信号中学习指标，直接最大化指标与北极度量标准之间的统计能力，从而减少在线控制实验的成本。 |
| [^23] | [Flora: Low-Rank Adapters Are Secretly Gradient Compressors](https://arxiv.org/abs/2402.03293) | 本文研究了低秩适配器的动力学，并提出了一种基于随机投影的方法Flora，通过重新采样投影矩阵实现高秩更新，同时减少优化状态的空间复杂度。 |
| [^24] | [An Analysis of the Variance of Diffusion-based Speech Enhancement](https://arxiv.org/abs/2402.00811) | 本研究发现，方差的规模是影响语音增强性能的主要参数，较大的方差可增加噪声抑制并减少计算量。 |
| [^25] | [Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey](https://arxiv.org/abs/2401.11963) | 通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。 |
| [^26] | [Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch](https://arxiv.org/abs/2311.03099) | 本文揭示了语言模型可以通过吸收同源模型的参数来获得新的能力，而无需重新训练或使用GPU。作者提出了DARE技术来稀疏化参数并将多个同源模型合并为一个模型。实验证明，DARE可以轻松删除大部分参数并实现多任务融合。 |
| [^27] | [Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior.](http://arxiv.org/abs/2401.09050) | 本论文提出了一种名为“Consistent3D”的方法，通过探索普通微分方程的确定性采样先验，解决了分数蒸馏采样（SDS）在文本到3D生成中容易出现几何崩溃和质量差纹理的问题。 |
| [^28] | [Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving.](http://arxiv.org/abs/2401.03160) | 本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。 |
| [^29] | [Redco: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs.](http://arxiv.org/abs/2310.16355) | Redco是一个轻量级工具，旨在自动化分布式训练LLMs，并简化ML流程的开发。 |
| [^30] | [Language Models As Semantic Indexers.](http://arxiv.org/abs/2310.07815) | 本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。 |
| [^31] | [Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective.](http://arxiv.org/abs/2310.02897) | 本研究从逆问题的角度研究了从过参数自编码器模型恢复训练数据的问题，并提出了一种实际方法，该方法利用训练好的自编码器来定义正则化器并通过迭代计算处理未知的退化操作符。实验结果表明，该方法在自编码器恢复训练数据方面具有显著的优势。 |
| [^32] | [Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models.](http://arxiv.org/abs/2310.02409) | Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。 |
| [^33] | [Beyond Labeling Oracles: What does it mean to steal ML models?.](http://arxiv.org/abs/2310.01959) | 本文研究了模型提取攻击，发现攻击者往往不能节约数据和标注成本，因为攻击隐含地依赖于从受害模型的数据分布中采样的能力。攻击者的先前知识对攻击成功至关重要。 |
| [^34] | [Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming.](http://arxiv.org/abs/2309.12701) | 本文提出了一种使用动态规划找到最优决策树的方法，可以得到多个可解释性-性能权衡的最优决策树，使用户可以根据自己的需求选择最适合的树。 |
| [^35] | [Graph topological property recovery with heat and wave dynamics-based features on graphsD.](http://arxiv.org/abs/2309.09924) | 本文提出了一种名为图微分方程网络（GDeNet）的方法，利用热和波动方程动力学特征来恢复图的拓扑属性，能够在各种下游任务中获得优秀的表现，同时在实际应用中也展现了较好的性能。 |
| [^36] | [PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph Construction Methods and Chebyshev Graph Convolutions.](http://arxiv.org/abs/2309.08630) | 本研究提出了一种基于图形的喷注表示方法，并设计了一种名为PCN的图神经网络（GNN），利用切比雪夫图卷积（ChebConv）进行深度学习喷注标记，取得了显著的改进。 |
| [^37] | [Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker Verification.](http://arxiv.org/abs/2309.07115) | 本文介绍了一种弱监督多任务学习的方法，用于音视频说话人验证。我们通过引入辅助任务和非同步采样策略来提高距离度量学习方法的性能。实验结果表明，我们的网络在说话人验证中取得了最先进的性能。 |
| [^38] | [Neural-network quantum state study of the long-range antiferromagnetic Ising chain.](http://arxiv.org/abs/2308.09709) | 在这项研究中，我们使用变分蒙特卡洛方法和约束玻尔兹曼机作为试验波函数参数化，研究了具有代数衰减长程反铁磁相互作用的横向场伊辛链中的量子相变。通过有限大小缩放分析，我们发现中心荷的值与衰变指数$\alpha_\mathrm{LR}$不同，而临界指数则保持接近短程伊辛模型的值，这支持了先前提出的共形不变性破缺场景。 |
| [^39] | [Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications.](http://arxiv.org/abs/2306.04539) | 本文研究在只有带标签的单模态数据和自然出现的多模态数据的情况下，如何量化多模态交互的挑战，并提出了两个下界和一个上界来量化多模态交互量。 |
| [^40] | [Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic Knowledge Graph and Text Mining Approach.](http://arxiv.org/abs/2306.03833) | 本研究提出了一种多模态动态知识驱动退出预测（MDKDP）框架，能够解决虚拟健康中不同利益相关者之间和医疗保健交付系统之间的信息不对称问题，提高了退出预测的性能。 |
| [^41] | [Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm.](http://arxiv.org/abs/2306.02939) | 本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。 |
| [^42] | [The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors.](http://arxiv.org/abs/2305.12883) | 该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。 |
| [^43] | [Hyper-parameter Tuning for Adversarially Robust Models.](http://arxiv.org/abs/2304.02497) | 本文探究对抗训练模型的超参数调节问题，明确对抗环境下需要额外调整的超参数，并提出利用廉价对抗训练方法的新方案降低调节成本。 |
| [^44] | [Efficiently Counting Substructures by Subgraph GNNs without Running GNN on Subgraphs.](http://arxiv.org/abs/2303.10576) | 本文提出了一种使用结构嵌入和预计算的方法，以减少计算和内存成本，并实现了在子图 GNN 上高效计数子结构的目的。 |
| [^45] | [VFP: Converting Tabular Data for IIoT into Images Considering Correlations of Attributes for Convolutional Neural Networks.](http://arxiv.org/abs/2303.09068) | 这篇论文提出了一种新的将工业物联网表格数据转换为图像的方法，考虑了属性之间的相关性，可以更好地利用卷积神经网络进行数据处理。 |
| [^46] | [Robust Knowledge Transfer in Tiered Reinforcement Learning.](http://arxiv.org/abs/2302.05534) | 本文研究了层级增强学习中的知识传输，提出了一种新颖的在线学习算法，在没有先验知识的任务相似性的情况下实现强大的知识传输。 |

# 详细

[^1]: 深度条件生成学习：模型与误差分析

    Deep Conditional Generative Learning: Model and Error Analysis

    [https://rss.arxiv.org/abs/2402.01460](https://rss.arxiv.org/abs/2402.01460)

    提出了一种基于ODE的深度生成方法，通过条件Follmer流来学习条件分布，通过离散化和深度神经网络实现高效转化。同时，通过Wasserstein距离的非渐近收敛速率，提供了第一个端到端误差分析，数值实验证明其在不同场景下的优越性。

    

    我们介绍了一种基于普通微分方程（ODE）的深度生成方法，用于学习条件分布，称为条件Follmer流。从标准高斯分布开始，所提出的流能够以高效的方式将其转化为目标条件分布，在时间1处达到稳定。为了有效实现，我们使用欧拉方法对流进行离散化，使用深度神经网络非参数化估计速度场。此外，我们导出了学习样本的分布与目标分布之间的Wasserstein距离的非渐近收敛速率，在条件分布学习中提供了第一个全面的端到端误差分析。我们的数值实验展示了它在一系列情况下的有效性，从标准的非参数化条件密度估计问题到涉及图像数据的更复杂的挑战，说明它优于各种现有方法。

    We introduce an Ordinary Differential Equation (ODE) based deep generative method for learning a conditional distribution, named the Conditional Follmer Flow. Starting from a standard Gaussian distribution, the proposed flow could efficiently transform it into the target conditional distribution at time 1. For effective implementation, we discretize the flow with Euler's method where we estimate the velocity field nonparametrically using a deep neural network. Furthermore, we derive a non-asymptotic convergence rate in the Wasserstein distance between the distribution of the learned samples and the target distribution, providing the first comprehensive end-to-end error analysis for conditional distribution learning via ODE flow. Our numerical experiments showcase its effectiveness across a range of scenarios, from standard nonparametric conditional density estimation problems to more intricate challenges involving image data, illustrating its superiority over various existing condition
    
[^2]: 机器学习中的函数双层优化

    Functional Bilevel Optimization for Machine Learning

    [https://arxiv.org/abs/2403.20233](https://arxiv.org/abs/2403.20233)

    介绍了机器学习中的函数双层优化问题，提出了不依赖于强凸假设的方法，并展示了在仪表回归和强化学习任务中使用神经网络的优势。

    

    在本文中，我们介绍了针对机器学习中的双层优化问题的一种新的函数视角，其中内部目标在函数空间上被最小化。这些类型的问题通常通过在参数设置下开发的方法来解决，其中内部目标对于预测函数的参数强凸。函数视角不依赖于此假设，特别允许使用超参数化的神经网络作为内部预测函数。我们提出了可扩展和高效的算法来解决函数双层优化问题，并展示了我们方法在适合自然函数双层结构的仪表回归和强化学习任务上的优势。

    arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
    
[^3]: 多尺度蛋白质语言模型用于统一分子建模

    Multi-Scale Protein Language Model for Unified Molecular Modeling

    [https://arxiv.org/abs/2403.12995](https://arxiv.org/abs/2403.12995)

    提出了一种多尺度蛋白质语言模型，能够在蛋白质和小分子相关任务中超越先前的方法，并且通过统一分子建模实现了充分利用蛋白质语言模型的潜力。

    

    蛋白质语言模型在蛋白质工程领域展现出了显著潜力。然而，当前的蛋白质语言模型主要在残基级别上运行，这限制了它们在原子水平提供信息的能力。这一限制阻碍了我们充分利用蛋白质语言模型在涉及蛋白质和小分子的应用中的能力。本文提出了ms-ESM（多尺度ESM），一种新颖的方法，实现了多尺度统一分子建模。ms-ESM通过预训练多尺度代码切换蛋白质序列并利用多尺度位置编码来捕获残基和原子之间的关系来实现这一目标。实验结果表明，ms-ESM在蛋白质-分子任务中超越了先前的方法，展示了对蛋白质语言模型的充分利用。进一步的研究揭示通过统一分子建模，ms-ESM不

    arXiv:2403.12995v1 Announce Type: cross  Abstract: Protein language models have demonstrated significant potential in the field of protein engineering. However, current protein language models primarily operate at the residue scale, which limits their ability to provide information at the atom level. This limitation prevents us from fully exploiting the capabilities of protein language models for applications involving both proteins and small molecules. In this paper, we propose ms-ESM (multi-scale ESM), a novel approach that enables multi-scale unified molecular modeling. ms-ESM achieves this by pre-training on multi-scale code-switch protein sequences and utilizing a multi-scale position encoding to capture relationships among residues and atoms. Experimental results indicate that ms-ESM surpasses previous methods in protein-molecule tasks, demonstrating the full utilization of protein language models. Further investigations reveal that through unified molecular modeling, ms-ESM not 
    
[^4]: 深度强化学习驱动的自主车辆决策的揭秘

    Demystifying Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making

    [https://arxiv.org/abs/2403.11432](https://arxiv.org/abs/2403.11432)

    本研究致力于研究基于注意力的DRL框架的可解释性，在自主车辆决策中，通过在开源AV仿真环境中添加多头注意力框架，提高了模型的解释性。

    

    随着强化学习领域中通用函数逼近器的出现，利用深度强化学习（DRL）的实际应用数量激增。自动驾驶任务中的决策制定已成为其中一项主要应用，将传感器数据或高阶运动学变量作为输入，并提供离散选择或连续控制输出。然而，模型的黑盒特性限制了DRL在自主车辆中的实际部署。因此，在这项研究工作中，我们关注基于注意力的DRL框架的可解释性。我们在开源AV仿真环境中使用了基于连续近端策略优化的DRL算法作为基线模型，并添加了一个多头注意力框架。我们提供了一些分析技术来讨论训练模型的可解释性。

    arXiv:2403.11432v1 Announce Type: cross  Abstract: With the advent of universal function approximators in the domain of reinforcement learning, the number of practical applications leveraging deep reinforcement learning (DRL) has exploded. Decision-making in automated driving tasks has emerged as a chief application among them, taking the sensor data or the higher-order kinematic variables as the input and providing a discrete choice or continuous control output. However, the black-box nature of the models presents an overwhelming limitation that restricts the real-world deployment of DRL in autonomous vehicles (AVs). Therefore, in this research work, we focus on the interpretability of an attention-based DRL framework. We use a continuous proximal policy optimization-based DRL algorithm as the baseline model and add a multi-head attention framework in an open-source AV simulation environment. We provide some analytical techniques for discussing the interpretability of the trained mode
    
[^5]: ThermoHands：一种用于从主观视角热图中估计3D手部姿势的基准

    ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image

    [https://arxiv.org/abs/2403.09871](https://arxiv.org/abs/2403.09871)

    ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。

    

    在这项工作中，我们提出了ThermoHands，这是一个针对基于热图的主观视角3D手部姿势估计的新基准，旨在克服诸如光照变化和遮挡（例如手部穿戴物）等挑战。该基准包括来自28名主体进行手-物体和手-虚拟交互的多样数据集，经过自动化过程准确标注了3D手部姿势。我们引入了一个定制的基线方法TheFormer，利用双transformer模块在热图中实现有效的主观视角3D手部姿势估计。我们的实验结果突显了TheFormer的领先性能，并确认了热成像在实现恶劣条件下稳健的3D手部姿势估计方面的有效性。

    arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
    
[^6]: 面向模型无关后验逼近的快速准确变分自编码器

    Towards Model-Agnostic Posterior Approximation for Fast and Accurate Variational Autoencoders

    [https://arxiv.org/abs/2403.08941](https://arxiv.org/abs/2403.08941)

    最近的研究表明，为了确保高质量的推断模型，可以通过迭代训练最大化与推断模型相关的目标函数，以解决变分自编码器中推断模型近似不准确导致的局部最优解问题。

    

    变分自编码器（VAEs）的推断包括学习两个模型：（1）生成模型，将潜在空间上的简单分布转换为观测数据分布，以及（2）推断模型，近似给定数据的潜在编码后验。这两个组件通过对生成模型对数边际似然的下界进行联合学习。在联合训练的早期阶段，推断模型很差地近似了潜在编码后验。最近的研究表明，这导致优化陷入局部最优解，对学习到的生成模型造成负面影响。因此，最近的研究建议通过迭代训练确保高质量的推断模型：相对于生成模型的每次更新之前最大化与推断模型相关的目标函数。不幸的是，迭代训练效率低，需要启发式标准来从迭代中恢复。

    arXiv:2403.08941v1 Announce Type: cross  Abstract: Inference for Variational Autoencoders (VAEs) consists of learning two models: (1) a generative model, which transforms a simple distribution over a latent space into the distribution over observed data, and (2) an inference model, which approximates the posterior of the latent codes given data. The two components are learned jointly via a lower bound to the generative model's log marginal likelihood. In early phases of joint training, the inference model poorly approximates the latent code posteriors. Recent work showed that this leads optimization to get stuck in local optima, negatively impacting the learned generative model. As such, recent work suggests ensuring a high-quality inference model via iterative training: maximizing the objective function relative to the inference model before every update to the generative model. Unfortunately, iterative training is inefficient, requiring heuristic criteria for reverting from iterative
    
[^7]: 用于安全可靠LLM的检测器：实现、用途和局限性

    Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations

    [https://arxiv.org/abs/2403.06009](https://arxiv.org/abs/2403.06009)

    创建了一系列检测器库，其中包含紧凑且易于构建的分类模型，为各种危害提供标签，可作为大型语言模型（LLMs）的有效替代方案。

    

    大型语言模型（LLMs）容易受到各种风险的影响，从输出不忠实到有偏见和有毒的生成。由于围绕LLMs存在的几个限制性因素（训练成本、API访问、数据可用性等），在部署模型时可能并非总是可行施加直接安全约束。因此，需要一个高效可靠的替代方案。为此，我们正在努力创建和部署一系列检测器库：紧凑且易于构建的分类模型，为各种危害提供标签。除了检测器本身，我们还讨论了这些检测器模型的广泛用途——从充当防护栏到促进有效的AI治理。我们还深入探讨了它们的开发中固有的挑战，并讨论了未来工作，旨在使检测器更可靠并拓展其范围。

    arXiv:2403.06009v1 Announce Type: new  Abstract: Large language models (LLMs) are susceptible to a variety of risks, from non-faithful output to biased and toxic generations. Due to several limiting factors surrounding LLMs (training cost, API access, data availability, etc.), it may not always be feasible to impose direct safety constraints on a deployed model. Therefore, an efficient and reliable alternative is required. To this end, we present our ongoing efforts to create and deploy a library of detectors: compact and easy-to-build classification models that provide labels for various harms. In addition to the detectors themselves, we discuss a wide range of uses for these detector models - from acting as guardrails to enabling effective AI governance. We also deep dive into inherent challenges in their development and discuss future work aimed at making the detectors more reliable and broadening their scope.
    
[^8]: 所需只是 Mad Libs: 增强跨领域文档级事件参数数据

    Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event Argument Data

    [https://arxiv.org/abs/2403.03304](https://arxiv.org/abs/2403.03304)

    Mad Libs 提供的数据增强方法 MLA 在跨领域文档级事件参数数据提取上取得了显著的性能提升，平均提高了 2.6 个 F1 分数。同时，在零和少样本事件角色方面相比无增强基线，提高了 3.9 和 5.2 个百分点。

    

    文档级事件参数提取（DocEAE）是一个极其困难的信息提取问题，尤其在低资源跨领域设置中存在着显著的局限性。为了解决这个问题，我们引入了 Mad Lib Aug（MLA），这是一个新颖的生成式 DocEAE 数据增强框架。我们的方法利用了 Mad Libs 的直觉，即作为一种热门游戏中使用的分类掩码文档可以被 LLMs 生成并解答，从而为 DocEAE 生成数据。使用 MLA，我们的整体 F1 分数平均改进了 2.6 个百分点。此外，与无增强基线相比，该方法在零和少样本事件角色方面在所有实验中平均提高了 3.9 和 5.2 个百分点。

    arXiv:2403.03304v1 Announce Type: new  Abstract: Document-Level Event Argument Extraction (DocEAE) is an extremely difficult information extraction problem -- with significant limitations in low-resource cross-domain settings. To address this problem, we introduce Mad Lib Aug (MLA), a novel generative DocEAE data augmentation framework. Our approach leverages the intuition that Mad Libs, which are categorically masked documents used as a part of a popular game, can be generated and solved by LLMs to produce data for DocEAE. Using MLA, we achieve a 2.6-point average improvement in overall F1 score. Moreover, this approach achieves a 3.9 and 5.2 point average increase in zero and few-shot event roles compared to augmentation-free baselines across all experiments.   To better facilitate analysis of cross-domain DocEAE, we additionally introduce a new metric, Role-Depth F1 (RDF1), which uses statistical depth to identify roles in the target domain which are semantic outliers with respect t
    
[^9]: 论Brenier的极分解的神经实现

    On a Neural Implementation of Brenier's Polar Factorization

    [https://arxiv.org/abs/2403.03071](https://arxiv.org/abs/2403.03071)

    提出了Brenier的极分解定理的神经实现，探讨了在机器学习中的应用，并通过神经网络参数化潜在函数$u$，从最新神经最优输运领域的进展中汲取灵感。

    

    在1991年，Brenier证明了一个定理，将$QR$分解（分为半正定矩阵$\times$酉矩阵）推广到任意矢量场$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$。这个被称为极分解定理的定理表明，任意场$F$都可以表示为凸函数$u$的梯度与保测度映射$M$的复合，即$F=\nabla u \circ M$。我们提出了这一具有深远理论意义的结果的实际实现，并探讨了在机器学习中可能的应用。该定理与最优输运（OT）理论密切相关，我们借鉴了神经最优输运领域的最新进展，将潜在函数$u$参数化为输入凸神经网络。映射$M$可以通过使用$u^*$，即$u$的凸共轭，逐点计算得到，即$M=\nabla u^* \circ F$，或者作为辅助网络学习得到。因为$M$在基因

    arXiv:2403.03071v1 Announce Type: cross  Abstract: In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\times$ unitary -- to any vector field $F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary network. Because $M$ is, in gene
    
[^10]: 通过无监督预训练和上下文学习实现高效的运算符学习

    Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning

    [https://arxiv.org/abs/2402.15734](https://arxiv.org/abs/2402.15734)

    该论文提出了一种通过无监督预训练和上下文学习方法实现PDE运算符学习的高效方式，以提高数据效率并改善模型的外域性能。

    

    近年来，人们见证了将机器学习方法与物理领域特定洞察力相结合，以解决基于偏微分方程（PDEs）的科学问题的潜力。然而，由于数据密集，这些方法仍然需要大量PDE数据。 这重新引入了对昂贵的数值PDE解决方案的需求，部分削弱了避免这些昂贵模拟的原始目标。 在这项工作中，为了寻求数据效率，我们设计了用于PDE运算符学习的无监督预训练和上下文学习方法。 为了减少对带有模拟解的训练数据的需求，我们使用基于重构的代理任务在未标记的PDE数据上预训练神经运算符。 为了提高超出分布性能，我们进一步帮助神经运算符灵活地利用上下文学习方法，而无需额外的训练成本或设计。 在各种PD上进行了大量实证评估

    arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
    
[^11]: 构建联想记忆与概率建模之间的桥梁

    Bridging Associative Memory and Probabilistic Modeling

    [https://arxiv.org/abs/2402.10202](https://arxiv.org/abs/2402.10202)

    基于联想记忆的能量函数可以被视为概率建模的对数似然函数，这篇论文构建了两者之间的桥梁，提出了新的基于能量的模型，并展示了两种新的联想记忆模型，可灵活适应上下文数据集。

    

    arXiv:2402.10202v1 公告类型：新的 摘要：联想记忆和概率建模是人工智能中两个基本的主题。第一个研究设计用于去噪、完成和检索数据的递归神经网络，而第二个研究学习和从概率分布中采样。基于联想记忆的能量函数可以被视为概率建模的负对数似然函数的观察，我们在两个之间建立了一座桥梁，使得想法能在两个方向上有益的流动。我们展示了四个例子：首先，我们提出了新的以能量为基础的模型，这些模型可以灵活地适应新的上下文数据集，这种方法称为“上下文学习能量函数”。其次，我们提出了两种新的联想记忆模型：一种是根据训练数据的需要动态创建新的记忆，使用贝叶斯非参数方法，另一种是明确计算比例记忆分配，使用e作为概率函数分配记忆。

    arXiv:2402.10202v1 Announce Type: new  Abstract: Associative memory and probabilistic modeling are two fundamental topics in artificial intelligence. The first studies recurrent neural networks designed to denoise, complete and retrieve data, whereas the second studies learning and sampling from probability distributions. Based on the observation that associative memory's energy functions can be seen as probabilistic modeling's negative log likelihoods, we build a bridge between the two that enables useful flow of ideas in both directions. We showcase four examples: First, we propose new energy-based models that flexibly adapt their energy functions to new in-context datasets, an approach we term \textit{in-context learning of energy functions}. Second, we propose two new associative memory models: one that dynamically creates new memories as necessitated by the training data using Bayesian nonparametrics, and another that explicitly computes proportional memory assignments using the e
    
[^12]: 预测性线性在线追踪未知目标

    Predictive Linear Online Tracking for Unknown Targets

    [https://arxiv.org/abs/2402.10036](https://arxiv.org/abs/2402.10036)

    本文提出了一种名为预测性线性在线追踪（PLOT）的算法，用于在线追踪未知目标。该算法使用具有指数遗忘的递归最小二乘法来学习目标的时变动态模型，并在递推视线控制的框架下使用所学模型进行最优策略。与先前的工作不同，我们的理论结果适用于非平稳目标。

    

    本文研究了在线线性控制系统中的追踪问题，目标是跟随一个移动的目标。与经典的追踪控制不同，目标是未知的、非平稳的，并且它的状态逐步揭示，因此适合在线非随机控制的框架。我们考虑了二次成本的情况，并提出了一种新算法，称为预测性线性在线追踪（PLOT）。该算法使用具有指数遗忘的递归最小二乘法来学习目标的时变动态模型。所学模型在递推视线控制的框架下用于优化策略。我们证明了PLOT的动态遗憾与$\mathcal{O}(\sqrt{TV_T})$成比例，其中$V_T$是目标动力学的总变化量，$T$是时间长度。与先前的工作不同，我们的理论结果适用于非平稳目标。我们在一个真实的四旋翼机上实现了PLOT，并提供了开源代码。

    arXiv:2402.10036v1 Announce Type: cross  Abstract: In this paper, we study the problem of online tracking in linear control systems, where the objective is to follow a moving target. Unlike classical tracking control, the target is unknown, non-stationary, and its state is revealed sequentially, thus, fitting the framework of online non-stochastic control. We consider the case of quadratic costs and propose a new algorithm, called predictive linear online tracking (PLOT). The algorithm uses recursive least squares with exponential forgetting to learn a time-varying dynamic model of the target. The learned model is used in the optimal policy under the framework of receding horizon control. We show the dynamic regret of PLOT scales with $\mathcal{O}(\sqrt{TV_T})$, where $V_T$ is the total variation of the target dynamics and $T$ is the time horizon. Unlike prior work, our theoretical results hold for non-stationary targets. We implement PLOT on a real quadrotor and provide open-source so
    
[^13]: 揭示特定群体的分布式概念漂移: 联邦学习中的公平要求

    Unveiling Group-Specific Distributed Concept Drift: A Fairness Imperative in Federated Learning

    [https://arxiv.org/abs/2402.07586](https://arxiv.org/abs/2402.07586)

    该研究在联邦学习中的分布式环境下，首次探索了在存在特定群体概念漂移的情况下实现公平性的挑战和解决方案。

    

    在机器学习领域的不断发展中，确保公平性已成为一个重要关注点，推动了开发旨在减少决策过程中歧视结果的算法。然而，在存在特定群体的概念漂移的情况下实现公平性仍然是一个未被探索的领域，我们的研究代表了在这方面的开拓性努力。特定群体的概念漂移是指一个群体随时间经历概念漂移，而另一个群体却没有，导致公平性下降，即使准确性保持相对稳定。在联邦学习的框架下，客户端共同训练模型，其分布式性质进一步放大了这些挑战，因为每个客户端可以独立经历特定群体的概念漂移，同时仍共享相同的基本概念，从而创造了一个复杂而动态的环境来维持公平性。我们研究的一个重要贡献之一是对群体特定的概念漂移进行形式化和内部化的过程。

    In the evolving field of machine learning, ensuring fairness has become a critical concern, prompting the development of algorithms designed to mitigate discriminatory outcomes in decision-making processes. However, achieving fairness in the presence of group-specific concept drift remains an unexplored frontier, and our research represents pioneering efforts in this regard. Group-specific concept drift refers to situations where one group experiences concept drift over time while another does not, leading to a decrease in fairness even if accuracy remains fairly stable. Within the framework of federated learning, where clients collaboratively train models, its distributed nature further amplifies these challenges since each client can experience group-specific concept drift independently while still sharing the same underlying concept, creating a complex and dynamic environment for maintaining fairness. One of the significant contributions of our research is the formalization and intr
    
[^14]: 有限数据集上基于生成模型的迁移学习用于目标检测

    Transfer learning with generative models for object detection on limited datasets

    [https://arxiv.org/abs/2402.06784](https://arxiv.org/abs/2402.06784)

    本论文提出了一个适用于通用情景的基于生成模型的迁移学习框架，用于解决有限数据集上的目标检测任务。

    

    在某些领域中，数据的可用性是有限的，尤其是对于目标检测任务，需要正确标记每个目标周围的边界框。一个显著的例子是在海洋生物学领域，需要开发自动检测海洋物种用于环境监测的方法。为了解决数据限制问题，目前最先进的机器学习策略采用了两种主要方法。第一种方法是在现有数据集上预训练模型，然后推广到具体的领域。第二种策略是使用copy-paste技术或ad-hoc模拟器等方法创建特定于目标领域的合成数据集。第一种方法往往面临重大的领域转移问题，而第二种方法需要针对特定任务设计定制解决方案。为了应对这些挑战，我们提出了一个在通用情景下有效的迁移学习框架。

    The availability of data is limited in some fields, especially for object detection tasks, where it is necessary to have correctly labeled bounding boxes around each object. A notable example of such data scarcity is found in the domain of marine biology, where it is useful to develop methods to automatically detect submarine species for environmental monitoring. To address this data limitation, the state-of-the-art machine learning strategies employ two main approaches. The first involves pretraining models on existing datasets before generalizing to the specific domain of interest. The second strategy is to create synthetic datasets specifically tailored to the target domain using methods like copy-paste techniques or ad-hoc simulators. The first strategy often faces a significant domain shift, while the second demands custom solutions crafted for the specific task. In response to these challenges, here we propose a transfer learning framework that is valid for a generic scenario. In
    
[^15]: 通过混合狄利克雷分布改进证据深度学习

    Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions

    [https://arxiv.org/abs/2402.06160](https://arxiv.org/abs/2402.06160)

    本文通过混合狄利克雷分布来改进证据深度学习（EDL）方法，解决了现有方法中认知不确定性在无限样本限制下可能不会消失的问题。

    

    本文探讨了一种现代的预测不确定性估计方法，称为证据深度学习（EDL），其中通过最小化特定的目标函数，训练单个神经网络模型以学习预测分布上的元分布。尽管现有方法在经验性能方面表现强大，但Bengs等人的最近研究发现了现有方法的一个根本缺陷：即使在无限样本限制下，学习到的认知不确定性可能不会消失。通过提供文献中一类广泛使用的目标函数的统一视角，我们得到了这个观察的证实。我们的分析揭示了EDL方法本质上通过最小化分布与与样本大小无关的目标分布之间的特定差异度量来训练元分布，从而产生错误的认知不确定性。基于理论原则，我们提出通过将其建模为狄利克雷分布混合物来学习一致目标分布，从而改进了EDL方法。

    This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a sample-size-independent target distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and lear
    
[^16]: 依赖学习理论中的尖锐率：避免样本大小缩减的平方损失

    Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss

    [https://arxiv.org/abs/2402.05928](https://arxiv.org/abs/2402.05928)

    本文研究了依赖学习理论中的尖锐率，主要是为了避免样本大小缩减对方差产生影响。当假设类别的拓扑结构符合某些条件时，经验风险最小化者的性能与类别的复杂性和二阶统计量有关。

    

    本文研究了具有依赖性（β-混合）数据和平方损失的统计学习，在一个假设类别Φ_p的子集F中，其中Φ_p是范数∥f∥_Φ_p≡sup_m≥1 m^{-1/p}∥f∥_L^m，其中p∈[2，∞]。我们的研究动机是在具有依赖性数据的学习中寻找尖锐的噪声交互项或方差代理。在没有任何可实现性假设的情况下，典型的非渐近结果显示出方差代理通过底层协变量过程的混合时间进行了乘积缩减。我们证明，只要在我们的假设类别F上，L^2和Φ_p的拓扑是可比较的，即Φ_p是一个弱亚高斯类别：∥f∥_Φ_p≲∥f∥_L^2^η，其中η∈(0，1]，经验风险最小化者在其主导项中只实现了一种只依赖于类别复杂性和二阶统计量的速率。我们的结果适用于许多依赖性数据模型。

    In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
    
[^17]: Unichain和非周期性足以保证平均回报好转胆冒险目标的渐进最优性

    Unichain and Aperiodicity are Sufficient for Asymptotic Optimality of Average-Reward Restless Bandits

    [https://arxiv.org/abs/2402.05689](https://arxiv.org/abs/2402.05689)

    该论文提出了一种新的策略类别，用于解决无限期平均回报好转胆冒险问题。研究表明，在单臂松弛问题是Unichain和非周期性的情况下，该策略类别具有渐进最优性。

    

    我们考虑了离散时间下的无限期平均回报的好转胆冒险问题。我们提出了一种新的策略类别，旨在将逐渐扩大的臂子集向最佳分布方向推进。我们证明了我们的策略在N臂问题中是渐进最优的，如果单臂松弛问题是Unichain和非周期性的，那么就会有一个$O(1/\sqrt{N})$的最优间隙。我们的方法不同于大多数现有的研究，这些研究侧重于指数或优先级策略，这些策略依赖于统一全局吸引子属性（UGAP）来保证收敛到最优，或者依赖于最近开发的基于模拟的策略，该策略要求遵循同步假设（SA）。

    We consider the infinite-horizon, average-reward restless bandit problem in discrete time. We propose a new class of policies that are designed to drive a progressively larger subset of arms toward the optimal distribution. We show that our policies are asymptotically optimal with an $O(1/\sqrt{N})$ optimality gap for an $N$-armed problem, provided that the single-armed relaxed problem is unichain and aperiodic. Our approach departs from most existing work that focuses on index or priority policies, which rely on the Uniform Global Attractor Property (UGAP) to guarantee convergence to the optimum, or a recently developed simulation-based policy, which requires a Synchronization Assumption (SA).
    
[^18]: 一种非侵入性神经质量评估模型应用于表面肌电信号

    A Non-Intrusive Neural Quality Assessment Model for Surface Electromyography Signals

    [https://arxiv.org/abs/2402.05482](https://arxiv.org/abs/2402.05482)

    本研究提出了一种新的非侵入性神经质量评估模型QASE-net，可以有效预测表面肌电信号的信噪比，实验证明其相比之前的模型具有更低的预测误差和更高的线性相关性。

    

    在涉及测量肌肉表面肌电（sEMG）的实际场景中，尤其是靠近心脏的区域，主要的污染源之一是心电图（ECG）信号的存在。为了更有效地评估实际世界中的sEMG数据质量，本研究提出了QASE-net，一种新的非侵入性模型，可以预测sEMG信号的信噪比。QASE-net将CNN-BLSTM与注意力机制相结合，并采用端到端的训练策略。我们的实验框架利用了两个开放访问数据库的实际世界sEMG和ECG数据，分别是非侵入性适应性假肢数据库和MIT-BIH正常窦性心律数据库。实验结果表明，QASE-net优于先前的评估模型，具有显著降低的预测误差和明显更高的线性相关性。这些发现显示了QASE-net在提高可靠性和的潜力

    In practical scenarios involving the measurement of surface electromyography (sEMG) in muscles, particularly those areas near the heart, one of the primary sources of contamination is the presence of electrocardiogram (ECG) signals. To assess the quality of real-world sEMG data more effectively, this study proposes QASE-net, a new non-intrusive model that predicts the SNR of sEMG signals. QASE-net combines CNN-BLSTM with attention mechanisms and follows an end-to-end training strategy. Our experimental framework utilizes real-world sEMG and ECG data from two open-access databases, the Non-Invasive Adaptive Prosthetics Database and the MIT-BIH Normal Sinus Rhythm Database, respectively. The experimental results demonstrate the superiority of QASE-net over the previous assessment model, exhibiting significantly reduced prediction errors and notably higher linear correlations with the ground truth. These findings show the potential of QASE-net to substantially enhance the reliability and 
    
[^19]: 视觉语言模型的开放词汇校准

    Open-Vocabulary Calibration for Vision-Language Models

    [https://arxiv.org/abs/2402.04655](https://arxiv.org/abs/2402.04655)

    本文研究了视觉语言模型中的开放词汇校准问题，在提示学习的背景下发现现有的校准方法不足以解决该问题。为此，提出了一种称为 Distance-Aware Ca 的简单而有效的方法来解决问题。

    

    视觉语言模型 (VLM) 已经成为强大的工具，在处理图像识别、文本驱动的视觉内容生成、视觉聊天机器人等各种开放词汇任务上展现出了强大的能力。近年来，人们在提高 VLM 下游性能的适应方法上投入了大量的努力和资源，尤其是在参数高效的微调方法（如提示学习）上。然而，一个被大大忽视的关键问题是在微调的 VLM 中的置信度校准问题，在实际部署这样的模型时会大大降低可靠性。本文通过系统地研究提示学习背景下的置信度校准问题，发现现有的校准方法不能解决这个问题，尤其是在开放词汇的设置中。为了解决这个问题，我们提出了一种简单而有效的方法，称为 "Distance-Aware Ca"

    Vision-language models (VLMs) have emerged as formidable tools, showing their strong capability in handling various open-vocabulary tasks in image recognition, text-driven visual content generation, and visual chatbots, to name a few. In recent years, considerable efforts and resources have been devoted to adaptation methods for improving downstream performance of VLMs, particularly on parameter-efficient fine-tuning methods like prompt learning. However, a crucial aspect that has been largely overlooked is the confidence calibration problem in fine-tuned VLMs, which could greatly reduce reliability when deploying such models in the real world. This paper bridges the gap by systematically investigating the confidence calibration problem in the context of prompt learning and reveals that existing calibration methods are insufficient to address the problem, especially in the open-vocabulary setting. To solve the problem, we present a simple and effective approach called Distance-Aware Ca
    
[^20]: LESS：用于目标指导调整的选择有影响力的数据

    LESS: Selecting Influential Data for Targeted Instruction Tuning

    [https://arxiv.org/abs/2402.04333](https://arxiv.org/abs/2402.04333)

    LESS是一种优化感知且实际高效的算法，用于在大型语言模型中选择具有影响力的数据以开发特定能力，它采用低秩梯度相似性搜索方法进行指令数据选择。

    

    指令调整已经在大型语言模型中释放出强大的能力，有效地使用组合数据集来开发通用聊天机器人。然而，实际应用往往需要一套专门的技能（例如推理）。挑战在于从这些广泛的数据集中识别出最相关的数据，以有效开发特定的能力，我们将这种情况称为目标指导调整。我们提出了LESS，一种优化感知且实际高效的算法，以有效估计数据影响并执行适用于指令数据选择的低秩梯度相似性搜索。关键在于LESS将现有的影响公式调整为与Adam优化器和可变长度指令数据一起工作。LESS首先构建了一个具有低维梯度特征的高度可重用和可传递的梯度数据存储库，然后根据它们与具有特定能力的少样本示例的相似度选择示例。实验证明，t

    Instruction tuning has unlocked powerful capabilities in large language models (LLMs), effectively using combined datasets to develop generalpurpose chatbots. However, real-world applications often require a specialized suite of skills (e.g., reasoning). The challenge lies in identifying the most relevant data from these extensive datasets to effectively develop specific capabilities, a setting we frame as targeted instruction tuning. We propose LESS, an optimizer-aware and practically efficient algorithm to effectively estimate data influences and perform Low-rank gradiEnt Similarity Search for instruction data selection. Crucially, LESS adapts existing influence formulations to work with the Adam optimizer and variable-length instruction data. LESS first constructs a highly reusable and transferable gradient datastore with low-dimensional gradient features and then selects examples based on their similarity to few-shot examples embodying a specific capability. Experiments show that t
    
[^21]: 用于电子密度估计的高斯平面波神经算子

    Gaussian Plane-Wave Neural Operator for Electron Density Estimation

    [https://arxiv.org/abs/2402.04278](https://arxiv.org/abs/2402.04278)

    本研究提出了一种名为高斯平面波神经算子(GPWNO)的方法，用于机器学习中的电子密度预测。该方法利用平面波和高斯型轨道基底在无限维功能空间中进行操作，可以有效地表示密度的高频和低频成分，并在多个数据集上展示出卓越的性能。

    

    本研究探讨了用于电子密度预测的机器学习方法，这对于理解化学系统和密度泛函理论(DFT)模拟是基础性的。为此，我们引入了高斯平面波神经算子(GPWNO)，它在无限维功能空间中使用平面波和高斯型轨道基底进行操作，在DFT的背景中得到广泛认可。特别地，由于两种基底的互补性质，密度的高频和低频成分都可以被有效地表示。对QM9、MD和材料项目数据集进行的大量实验表明，GPWNO相比其他十种基线方法具有优越的性能。

    This work studies machine learning for electron density prediction, which is fundamental for understanding chemical systems and density functional theory (DFT) simulations. To this end, we introduce the Gaussian plane-wave neural operator (GPWNO), which operates in the infinite-dimensional functional space using the plane-wave and Gaussian-type orbital bases, widely recognized in the context of DFT. In particular, both high- and low-frequency components of the density can be effectively represented due to the complementary nature of the two bases. Extensive experiments on QM9, MD, and material project datasets demonstrate GPWNO's superior performance over ten baselines.
    
[^22]: 学习最大化加速A/B测试的指标

    Learning Metrics that Maximise Power for Accelerated A/B-Tests

    [https://arxiv.org/abs/2402.03915](https://arxiv.org/abs/2402.03915)

    本论文提出了一种新方法，通过从短期信号中学习指标，直接最大化指标与北极度量标准之间的统计能力，从而减少在线控制实验的成本。

    

    在技术公司中，在线控制实验是一种重要的工具，可以实现自信的决策。定义了一个北极度量标准（如长期收入或用户保留），在A/B测试中，能够在这个指标上有统计显著提升的系统变体可以被认为是优越的。然而，北极度量标准通常具有时延和不敏感性。因此，实验的成本很高：实验需要长时间运行，即使如此，二类错误（即假阴性）仍然普遍存在。为了解决这个问题，我们提出了一种从短期信号中学习指标的方法，这些指标直接最大化它们相对于北极度量标准所具有的统计能力。我们展示了现有方法容易过拟合的问题，即更高的平均度量敏感性并不意味着改进了二类错误，我们建议通过最小化指标在过去实验的$log$上产生的$p$-value来解决。我们从两个社交媒体应用程序中收集了这样的数据集。

    Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent.   We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with
    
[^23]: Flora: 低秩适配器是悄悄的梯度压缩器

    Flora: Low-Rank Adapters Are Secretly Gradient Compressors

    [https://arxiv.org/abs/2402.03293](https://arxiv.org/abs/2402.03293)

    本文研究了低秩适配器的动力学，并提出了一种基于随机投影的方法Flora，通过重新采样投影矩阵实现高秩更新，同时减少优化状态的空间复杂度。

    

    尽管大型神经网络展示了完成不同任务的显着能力，但它们需要过多的内存使用来存储训练的优化状态。为了缓解这个问题，提出低秩适配（LoRA）来通过训练更少的参数来减少优化状态。然而，LoRA将整体权重更新矩阵限制为低秩，限制了模型的性能。在这项工作中，我们研究了LoRA的动力学，并确定它可以近似为随机投影。基于这一观察，我们提出了Flora，它能够通过重新采样投影矩阵实现高秩更新，同时享受优化状态的次线性空间复杂度。我们在不同任务和模型架构上进行实验证实了我们方法的有效性。

    Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.
    
[^24]: 扩散基于语音增强的方差分析

    An Analysis of the Variance of Diffusion-based Speech Enhancement

    [https://arxiv.org/abs/2402.00811](https://arxiv.org/abs/2402.00811)

    本研究发现，方差的规模是影响语音增强性能的主要参数，较大的方差可增加噪声抑制并减少计算量。

    

    扩散模型被证明是用于生成语音增强的强大模型。在最近的SGMSE+方法中，训练涉及到控制演化过程中均值和方差的随机微分方程，在逐渐添加高斯噪声和环境噪声到干净语音信号中。语音增强性能取决于选择用来控制添加环境和高斯噪声下演化过程的随机微分方程。在这项工作中，我们强调方差的规模是影响语音增强性能的主要参数，并且展示了它控制着噪声抑制和语音失真之间的权衡。更具体地说，我们展示了较大的方差增加了噪声抑制并且减少了计算量，因为产生估计的函数评估次数减少了。

    Diffusion models proved to be powerful models for generative speech enhancement. In recent SGMSE+ approaches, training involves a stochastic differential equation for the diffusion process, adding both Gaussian and environmental noise to the clean speech signal gradually. The speech enhancement performance varies depending on the choice of the stochastic differential equation that controls the evolution of the mean and the variance along the diffusion processes when adding environmental and Gaussian noise. In this work, we highlight that the scale of the variance is a dominant parameter for speech enhancement performance and show that it controls the tradeoff between noise attenuation and speech distortions. More concretely, we show that a larger variance increases the noise attenuation and allows for reducing the computational footprint, as fewer function evaluations for generating the estimate are required.
    
[^25]: 跨越进化算法和强化学习：一项全面调查

    Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2401.11963](https://arxiv.org/abs/2401.11963)

    通过整合进化算法与强化学习，进化强化学习（ERL）展现出卓越的性能提升，本综述呈现了ERL领域的各个研究分支，突出了EA辅助RL的优化、RL辅助EA的优化以及EA和RL的协同优化这三个主要研究方向。

    

    进化强化学习（ERL）将进化算法（EAs）和强化学习（RL）相结合进行优化，表现出卓越的性能提升。通过融合两种方法的优势，ERL已经成为一个有前景的研究方向。本调查综述了ERL中不同研究分支的全面概述。具体而言，我们系统总结了相关算法的最新进展，并确定了三个主要研究方向：EA辅助RL的优化，RL辅助EA的优化，以及EA和RL的协同优化。随后，我们深入分析了每个研究方向，组织了多个研究分支。我们阐明了每个分支致力于解决的问题，以及EA和RL的整合如何应对这些挑战。最后，我们讨论了潜在的挑战和未来的研究方向。

    arXiv:2401.11963v2 Announce Type: replace-cross  Abstract: Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary Algorithms (EAs) and Reinforcement Learning (RL) for optimization, has demonstrated remarkable performance advancements. By fusing the strengths of both approaches, ERL has emerged as a promising research direction. This survey offers a comprehensive overview of the diverse research branches in ERL. Specifically, we systematically summarize recent advancements in relevant algorithms and identify three primary research directions: EA-assisted optimization of RL, RL-assisted optimization of EA, and synergistic optimization of EA and RL. Following that, we conduct an in-depth analysis of each research direction, organizing multiple research branches. We elucidate the problems that each branch aims to tackle and how the integration of EA and RL addresses these challenges. In conclusion, we discuss potential challenges and prospective future research directions
    
[^26]: 语言模型就像超级马里奥：通过吸收同源模型的能力来实现免费午餐

    Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch

    [https://arxiv.org/abs/2311.03099](https://arxiv.org/abs/2311.03099)

    本文揭示了语言模型可以通过吸收同源模型的参数来获得新的能力，而无需重新训练或使用GPU。作者提出了DARE技术来稀疏化参数并将多个同源模型合并为一个模型。实验证明，DARE可以轻松删除大部分参数并实现多任务融合。

    

    在本文中，我们揭示了语言模型(LMs)可以通过吸收同源模型的参数来获得新的能力，而无需重新训练或使用GPU。我们首先引入了DARE来将大多数delta参数（即微调和预训练参数之间的差异）设置为零，而不会影响监督微调(SFT) LMs的能力，DARE通过随机删除比率为p的delta参数，并通过1/(1 - p)重新缩放剩余参数来近似原始嵌入。然后，我们将DARE作为一种通用的即插即用技术来稀疏化多个SFT同源模型的delta参数，以减轻参数干扰，并通过参数融合将它们合并为一个模型。我们通过编码器和解码器为基础的LM进行实验，结果表明：（1）SFT delta参数值范围通常很小（在0.005以内），具有极高的冗余，DARE可以轻松删除90%甚至99%的参数。（2）DARE可以将多个任务特定的LM合并为一个LM，并有驾驶技能

    In this paper, we unveil that Language Models (LMs) can acquire new capabilities by assimilating parameters from homologous models without retraining or GPUs. We first introduce DARE to set most delta parameters (i.e., the disparity between fine-tuned and pre-trained parameters) to zeros without affecting the abilities of Supervised Fine-Tuning (SFT) LMs, which randomly Drops delta parameters with a ratio p And REscales the remaining ones by 1/(1 - p) to approximate the original embeddings. Then, we use DARE as a versatile plug-and-play technique to sparsify delta parameters of multiple SFT homologous models for mitigating parameter interference and merge them into a single model by parameter fusing. We experiment with encoder- and decoder-based LMs, showing that: (1) SFT delta parameter value ranges are typically small (within 0.005) with extreme redundancy, and DARE can effortlessly eliminate 90% or even 99% of them. (2) DARE can merge multiple task-specific LMs into one LM with dive
    
[^27]: Consistent3D: 实现一致高保真度的文本到3D生成方法，采用确定性采样先验

    Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation with Deterministic Sampling Prior. (arXiv:2401.09050v1 [cs.CV])

    [http://arxiv.org/abs/2401.09050](http://arxiv.org/abs/2401.09050)

    本论文提出了一种名为“Consistent3D”的方法，通过探索普通微分方程的确定性采样先验，解决了分数蒸馏采样（SDS）在文本到3D生成中容易出现几何崩溃和质量差纹理的问题。

    

    分数蒸馏采样（SDS）及其变种极大地推动了文本到3D生成领域的发展，但容易出现几何崩溃和质量差的纹理。为了解决这个问题，我们首先深入分析了SDS，并发现它的蒸馏采样过程实际上对应于随机微分方程（SDE）的轨迹采样：SDS沿着SDE轨迹进行采样，以产生一个更少带噪声的样本，这个样本则作为优化3D模型的指导。然而，SDE采样中的随机性经常导致样本多样且不可预测，不总是更少带噪声，因此不是一个一致正确的指导，这解释了SDS的易受攻击性。由于对于任何SDE，总是存在一个普通微分方程（ODE），其轨迹采样可以确定性和一致地收敛到所需目标点作为SDE，我们提出了一种新颖有效的“Consistent3D”方法，探索ODE的确定性采样先验以解决这个问题。

    Score distillation sampling (SDS) and its variants have greatly boosted the development of text-to-3D generation, but are vulnerable to geometry collapse and poor textures yet. To solve this issue, we first deeply analyze the SDS and find that its distillation sampling process indeed corresponds to the trajectory sampling of a stochastic differential equation (SDE): SDS samples along an SDE trajectory to yield a less noisy sample which then serves as a guidance to optimize a 3D model. However, the randomness in SDE sampling often leads to a diverse and unpredictable sample which is not always less noisy, and thus is not a consistently correct guidance, explaining the vulnerability of SDS. Since for any SDE, there always exists an ordinary differential equation (ODE) whose trajectory sampling can deterministically and consistently converge to the desired target point as the SDE, we propose a novel and effective "Consistent3D" method that explores the ODE deterministic sampling prior for
    
[^28]: 人作为AI导师：增强人机协作强化学习以实现安全高效的自动驾驶

    Human as AI Mentor: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving. (arXiv:2401.03160v1 [cs.LG])

    [http://arxiv.org/abs/2401.03160](http://arxiv.org/abs/2401.03160)

    本文提出了一种增强的人机协作强化学习方法，通过将人类智能注入到AI中实现混合交通编队中的安全高效自动驾驶。该方法将人类专家作为导师，允许代理在不确定环境中进行探索，同时在危险情况下接管控制以避免事故，并指导代理减小交通流干扰，优化交通流效果。

    

    尽管自动驾驶车辆（AVs）取得了重大进展，但确保AVs的安全性和交通流效率的驾驶策略的发展尚未得到充分探索。在本文中，我们提出了一种增强的人机协作强化学习方法，称为基于人作为AI导师的深度强化学习（HAIM-DRL）框架，以在混合交通编队中实现安全高效的自动驾驶。从人类学习过程中汲取灵感，我们首先引入了一种创新的学习范式，有效地将人类智能注入到AI中，称为人作为AI导师（HAIM）。在这个范式中，人类专家作为导师为AI代理提供帮助。在允许代理在不确定环境中进行充分探索的同时，人类专家可以在危险情况下接管控制，并展示正确的行动以避免潜在事故。另一方面，可以指导代理减小交通流干扰，从而优化交通流效果。

    Despite significant progress in autonomous vehicles (AVs), the development of driving policies that ensure both the safety of AVs and traffic flow efficiency has not yet been fully explored. In this paper, we propose an enhanced human-in-the-loop reinforcement learning method, termed the Human as AI mentor-based deep reinforcement learning (HAIM-DRL) framework, which facilitates safe and efficient autonomous driving in mixed traffic platoon. Drawing inspiration from the human learning process, we first introduce an innovative learning paradigm that effectively injects human intelligence into AI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves as a mentor to the AI agent. While allowing the agent to sufficiently explore uncertain environments, the human expert can take control in dangerous situations and demonstrate correct actions to avoid potential accidents. On the other hand, the agent could be guided to minimize traffic flow disturbance, thereby optimizi
    
[^29]: Redco:一个轻量级工具，可在任何GPU/TPUs上自动化分布式训练LLMs

    Redco: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs. (arXiv:2310.16355v1 [cs.LG])

    [http://arxiv.org/abs/2310.16355](http://arxiv.org/abs/2310.16355)

    Redco是一个轻量级工具，旨在自动化分布式训练LLMs，并简化ML流程的开发。

    

    人工智能的最新进展主要归功于大型语言模型（LLMs）。然而，它们不断增长的内存需求给机器学习（ML）研究人员和工程师带来了挑战。解决这个问题需要开发人员将大型模型分区以分布在多个GPU或TPU上。这需要使用现有模型并行工具（如Megatron-LM、DeepSpeed和Alpa）进行相当的编码和复杂的配置工作。这些工具需要用户具备机器学习系统（MLSys）的专业知识，给LLM开发带来了瓶颈，特别是对于没有MLSys背景的开发人员。在这项工作中，我们提出了Redco，这是一个轻量级且用户友好的工具，旨在自动化LLMs的分布式训练和推理，以及简化ML流程的开发。Redco的设计强调了两个关键方面。首先，为了自动化模型并行，我们的研究确定了两个简单的规则，用于为任何GPU / TPU生成张量并行策略。

    The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa. These tools require users' expertise in machine learning systems (MLSys), creating a bottleneck in LLM development, particularly for developers without MLSys background. In this work, we present Redco, a lightweight and user-friendly tool crafted to automate distributed training and inference for LLMs, as well as to simplify ML pipeline development. The design of Redco emphasizes two key aspects. Firstly, to automate model parallism, our study identifies two straightforward rules to generate tensor parallel strategies for any g
    
[^30]: 语言模型作为语义索引器

    Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])

    [http://arxiv.org/abs/2310.07815](http://arxiv.org/abs/2310.07815)

    本文介绍了一种使用生成性语言模型学习语义ID的自监督框架LMINDEXER。

    

    语义标识符（ID）是信息检索中的一个重要概念，旨在保留对象（如文档和项）内部的语义。先前的研究通常采用两阶段流程来学习语义ID，首先使用现成的文本编码器获取嵌入，并根据嵌入来推导ID。然而，每个步骤都会引入潜在的信息损失，并且文本编码器生成的潜在空间内的嵌入分布通常与语义索引所需的预期分布存在固有的不匹配。然而，设计一个既能学习文档的语义表示又能同时学习其分层结构的方法并不容易，因为语义ID是离散和顺序结构的，并且语义监督是不充分的。在本文中，我们引入了LMINDEXER，它是一个自监督框架，用于使用生成性语言模型学习语义ID。

    Semantic identifier (ID) is an important concept in information retrieval that aims to preserve the semantics of objects such as documents and items inside their IDs. Previous studies typically adopt a two-stage pipeline to learn semantic IDs by first procuring embeddings using off-the-shelf text encoders and then deriving IDs based on the embeddings. However, each step introduces potential information loss and there is usually an inherent mismatch between the distribution of embeddings within the latent space produced by text encoders and the anticipated distribution required for semantic indexing. Nevertheless, it is non-trivial to design a method that can learn the document's semantic representations and its hierarchical structure simultaneously, given that semantic IDs are discrete and sequentially structured, and the semantic supervision is deficient. In this paper, we introduce LMINDEXER, a self-supervised framework to learn semantic IDs with a generative language model. We tackl
    
[^31]: 从过参数自编码器中恢复训练数据：逆问题的观点

    Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective. (arXiv:2310.02897v1 [cs.LG])

    [http://arxiv.org/abs/2310.02897](http://arxiv.org/abs/2310.02897)

    本研究从逆问题的角度研究了从过参数自编码器模型恢复训练数据的问题，并提出了一种实际方法，该方法利用训练好的自编码器来定义正则化器并通过迭代计算处理未知的退化操作符。实验结果表明，该方法在自编码器恢复训练数据方面具有显著的优势。

    

    我们研究了从过参数自编码器模型中恢复训练数据的问题。给定一个退化的训练样本，我们将原始样本的恢复定义为一个逆问题，并将其构建为一个优化任务。在我们的逆问题中，我们使用训练好的自编码器来隐式地定义一个正则化器，用于从特定的训练数据集中检索。我们将复杂的优化任务开发成一个实际方法，该方法迭代地应用训练好的自编码器和相对简单的计算来估计和处理未知的退化操作符。我们将该方法应用于盲目修补，目标是从许多缺失的像素中恢复训练图像，而这些缺失的像素是按照未知的模式进行的。我们检验了各种深度自编码器架构，如全连接和U-Net（具有不同的非线性和多样的训练损失值），并且证明了我们的方法明显优于以前的自编码器恢复训练数据的方法。

    We study the recovery of training data from overparameterized autoencoder models. Given a degraded training sample, we define the recovery of the original sample as an inverse problem and formulate it as an optimization task. In our inverse problem, we use the trained autoencoder to implicitly define a regularizer for the particular training dataset that we aim to retrieve from. We develop the intricate optimization task into a practical method that iteratively applies the trained autoencoder and relatively simple computations that estimate and address the unknown degradation operator. We evaluate our method for blind inpainting where the goal is to recover training images from degradation of many missing pixels in an unknown pattern. We examine various deep autoencoder architectures, such as fully connected and U-Net (with various nonlinearities and at diverse train loss values), and show that our method significantly outperforms previous methods for training data recovery from autoen
    
[^32]: Nugget 2D：用于仅解码器语言模型的动态上下文压缩的扩展

    Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models. (arXiv:2310.02409v1 [cs.CL])

    [http://arxiv.org/abs/2310.02409](http://arxiv.org/abs/2310.02409)

    Nugget 2D是一种用于仅解码器语言模型的动态上下文压缩方法，可以在保留任务能力的同时大幅减少解码过程所需的时间和空间开销。

    

    标准的基于Transformer的语言模型在长上下文中缩放效果不佳。我们提出了一种基于动态上下文压缩的解决方案，该方案将Qin＆Van Durme（2023年）的Nugget方法从BERT类框架扩展到仅解码器的语言模型。我们的方法将历史建模为压缩的“nuggets”，这些“nuggets”经过训练可以进行重建，它可以使用诸如LLaMA之类的现成模型进行初始化。我们通过语言建模、问答和摘要的实验证明，Nugget2D在这些任务中保留了能力，同时在解码过程中大幅减少了时间和空间开销。例如，在自动编码实验中，Nugget2D可以以20倍的压缩比收缩上下文，重建时的BLEU得分为98％，实现了近乎无损编码。

    Standard Transformer-based language models (LMs) scale poorly to long contexts. We propose a solution based on dynamic contextual compression, which extends the Nugget approach of Qin & Van Durme (2023) from BERT-like frameworks to decoder-only LMs. Our method models history as compressed "nuggets" which are trained to allow for reconstruction, and it can be initialized with off-the-shelf models such as LLaMA. We demonstrate through experiments in language modeling, question answering, and summarization that Nugget2D retains capabilities in these tasks, while drastically reducing the overhead during decoding in terms of time and space. For example, in the experiments of autoencoding, Nugget2D can shrink context at a 20x compression ratio with a BLEU score of 98% for reconstruction, achieving nearly lossless encoding.
    
[^33]: 超越标签神谕：什么是模型窃取的含义？

    Beyond Labeling Oracles: What does it mean to steal ML models?. (arXiv:2310.01959v1 [cs.LG])

    [http://arxiv.org/abs/2310.01959](http://arxiv.org/abs/2310.01959)

    本文研究了模型提取攻击，发现攻击者往往不能节约数据和标注成本，因为攻击隐含地依赖于从受害模型的数据分布中采样的能力。攻击者的先前知识对攻击成功至关重要。

    

    模型提取攻击旨在通过只有查询访问权限来窃取训练好的模型，通常通过ML-as-a-Service提供的API来实现。由于数据难以获取，训练ML模型的成本很高，因此模型提取的主要动机是在比从头开始训练更少成本的情况下获取模型。关于模型提取的文献普遍声称或假设攻击者能够节约数据获取和标注成本。然而我们发现攻击者往往不能实现这一点，因为当前的攻击隐含地依赖于攻击者能够从受害模型的数据分布中采样。我们对影响模型提取成功的因素进行了全面评估，发现攻击者对受害者的先前知识，即对分布数据的访问，比攻击策略（决定向受害者模型API发出哪些查询）等其他因素更为重要。因此，一个希望开发同等水平的攻击者更重要的是获取对分布数据的先前知识。

    Model extraction attacks are designed to steal trained models with only query access, as is often provided through APIs that ML-as-a-Service providers offer. ML models are expensive to train, in part because data is hard to obtain, and a primary incentive for model extraction is to acquire a model while incurring less cost than training from scratch. Literature on model extraction commonly claims or presumes that the attacker is able to save on both data acquisition and labeling costs. We show that the attacker often does not. This is because current attacks implicitly rely on the adversary being able to sample from the victim model's data distribution. We thoroughly evaluate factors influencing the success of model extraction. We discover that prior knowledge of the attacker, i.e. access to in-distribution data, dominates other factors like the attack policy the adversary follows to choose which queries to make to the victim model API. Thus, an adversary looking to develop an equally 
    
[^34]: 使用动态规划发现决策树的可解释性-性能帕累托前沿

    Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming. (arXiv:2309.12701v1 [cs.LG])

    [http://arxiv.org/abs/2309.12701](http://arxiv.org/abs/2309.12701)

    本文提出了一种使用动态规划找到最优决策树的方法，可以得到多个可解释性-性能权衡的最优决策树，使用户可以根据自己的需求选择最适合的树。

    

    众所周知，决策树由于可以被人类检查和解释而具有固有的可解释性。此外，最近硬件的进步重新引起了对最优决策树算法的关注，这些算法比通常的贪婪方法产生更准确的树。然而，这些最优算法返回的是一个优化手动定义的可解释性-性能权衡的单个树，通过指定最大决策节点数量来获得，对于这个权衡的质量没有进一步的洞察。在本文中，我们提出了一种新的马尔可夫决策问题（MDP）形式来找到最优决策树。这种形式的主要优点是，我们可以通过解决一个单一的动态规划问题计算出多个可解释性-性能权衡的最优决策树，让用户事后选择最适合他们需求的树。在实证方面，我们证明我们的方法在准确性和运行时间方面与最先进的算法竞争力相当。

    Decision trees are known to be intrinsically interpretable as they can be inspected and interpreted by humans. Furthermore, recent hardware advances have rekindled an interest for optimal decision tree algorithms, that produce more accurate trees than the usual greedy approaches. However, these optimal algorithms return a single tree optimizing a hand defined interpretability-performance trade-off, obtained by specifying a maximum number of decision nodes, giving no further insights about the quality of this trade-off. In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. The main interest of this formulation is that we can compute the optimal decision trees for several interpretability-performance trade-offs by solving a single dynamic program, letting the user choose a posteriori the tree that best suits their needs. Empirically, we show that our method is competitive with state-of-the-art algorithms in terms of accuracy and run
    
[^35]: 基于热和波动动力学特征的图拓扑属性恢复

    Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])

    [http://arxiv.org/abs/2309.09924](http://arxiv.org/abs/2309.09924)

    本文提出了一种名为图微分方程网络（GDeNet）的方法，利用热和波动方程动力学特征来恢复图的拓扑属性，能够在各种下游任务中获得优秀的表现，同时在实际应用中也展现了较好的性能。

    

    本文提出了一种名为图微分方程网络（GDeNet）的方法，利用图上的PDE解的表达能力，为各种下游任务获得连续的节点和图级表示。我们推导出了热和波动方程动力学与图的谱特性以及连续时间随机游走在图上行为之间的理论结果。我们通过恢复随机图生成参数、Ricci曲率和持久同调等方式实验证明了这些动力学能够捕捉到图形几何和拓扑的显著方面。此外，我们还展示了GDeNet在包括引用图、药物分子和蛋白质在内的真实世界数据集上的优越性能。

    In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
    
[^36]: PCN：一种利用新颖的图构建方法和切比雪夫图卷积的深度学习方法进行喷注标记

    PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph Construction Methods and Chebyshev Graph Convolutions. (arXiv:2309.08630v1 [hep-ph])

    [http://arxiv.org/abs/2309.08630](http://arxiv.org/abs/2309.08630)

    本研究提出了一种基于图形的喷注表示方法，并设计了一种名为PCN的图神经网络（GNN），利用切比雪夫图卷积（ChebConv）进行深度学习喷注标记，取得了显著的改进。

    

    喷注标记是高能物理实验中的一个分类问题，旨在识别粒子碰撞产生的锥状喷注，并将其标记为发射粒子。喷注标记的进展为超出标准模型的新物理搜索提供了机会。目前的方法使用深度学习在复杂碰撞数据中寻找隐藏的模式。然而，将喷注表示为深度学习模型的输入的方法多种多样，并且通常会向模型隐藏有信息的特征。在这项研究中，我们提出了一种基于图形的喷注表示方法，以尽可能地编码最多的信息。为了从这种表示中最好地学习，我们设计了一种名为Particle Chebyshev Network（PCN）的图神经网络（GNN），并使用切比雪夫图卷积（ChebConv）。ChebConv已经被证明是GNN中的一种有效替代传统图卷积的方法，而在喷注标记中还没有被探索过。PCN取得了显著的改进。

    Jet tagging is a classification problem in high-energy physics experiments that aims to identify the collimated sprays of subatomic particles, jets, from particle collisions and tag them to their emitter particle. Advances in jet tagging present opportunities for searches of new physics beyond the Standard Model. Current approaches use deep learning to uncover hidden patterns in complex collision data. However, the representation of jets as inputs to a deep learning model have been varied, and often, informative features are withheld from models. In this study, we propose a graph-based representation of a jet that encodes the most information possible. To learn best from this representation, we design Particle Chebyshev Network (PCN), a graph neural network (GNN) using Chebyshev graph convolutions (ChebConv). ChebConv has been demonstrated as an effective alternative to classical graph convolutions in GNNs and has yet to be explored in jet tagging. PCN achieves a substantial improvemen
    
[^37]: 面向音视频说话人验证的弱监督多任务学习

    Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker Verification. (arXiv:2309.07115v1 [cs.SD])

    [http://arxiv.org/abs/2309.07115](http://arxiv.org/abs/2309.07115)

    本文介绍了一种弱监督多任务学习的方法，用于音视频说话人验证。我们通过引入辅助任务和非同步采样策略来提高距离度量学习方法的性能。实验结果表明，我们的网络在说话人验证中取得了最先进的性能。

    

    本文提出了一种方法，用于实现针对开放集音视频说话人验证的鲁棒多模态个人表示。距离度量学习（DML）方法通常在该问题领域占据主导地位，因为在新的和未见过的类上表现出很强的性能。在我们的工作中，我们探索了多任务学习技术，进一步提高了DML方法的性能，并展示了一个带有弱标签的辅助任务可以增加学习到的说话人表示的紧凑性。我们还将广义端到端损失（GE2E）扩展到多模态输入，并证明它可以在音视频空间中实现竞争性能。最后，我们在训练期间引入了一种非同步音视频采样随机策略，已经显示可以提高泛化能力。我们的网络在说话人验证方面达到了最先进的性能，报告了VoxCeleb1-O/E的三个官方试验列表上的0.244％，0.252％，0.441％的等误差率（EER）。

    In this paper, we present a methodology for achieving robust multimodal person representations optimized for open-set audio-visual speaker verification. Distance Metric Learning (DML) approaches have typically dominated this problem space, owing to strong performance on new and unseen classes. In our work, we explored multitask learning techniques to further boost performance of the DML approach and show that an auxiliary task with weak labels can increase the compactness of the learned speaker representation. We also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and demonstrate that it can achieve competitive performance in an audio-visual space. Finally, we introduce a non-synchronous audio-visual sampling random strategy during training time that has shown to improve generalization. Our network achieves state of the art performance for speaker verification, reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official trial lists of VoxCeleb1-O/E
    
[^38]: 神经网络量子态研究长程反铁磁伊辛链

    Neural-network quantum state study of the long-range antiferromagnetic Ising chain. (arXiv:2308.09709v2 [cond-mat.stat-mech] UPDATED)

    [http://arxiv.org/abs/2308.09709](http://arxiv.org/abs/2308.09709)

    在这项研究中，我们使用变分蒙特卡洛方法和约束玻尔兹曼机作为试验波函数参数化，研究了具有代数衰减长程反铁磁相互作用的横向场伊辛链中的量子相变。通过有限大小缩放分析，我们发现中心荷的值与衰变指数$\alpha_\mathrm{LR}$不同，而临界指数则保持接近短程伊辛模型的值，这支持了先前提出的共形不变性破缺场景。

    

    我们利用变分蒙特卡洛方法研究具有代数衰减长程反铁磁相互作用的横向场伊辛链中的量子相变，采用约束玻尔兹曼机作为试验波函数参数化。在有限大小缩放分析中，通过序参数和第二个Renyi熵，我们发现中心荷与小的衰变指数$\alpha_\mathrm{LR}$不同，偏离了1/2，而临界指数则无论受到$\alpha_\mathrm{LR}$的影响如何，都保持非常接近短程（SR）伊辛模型的值，支持先前提出的共形不变性破缺场景。为了确定伊辛宇宙性和共形对称性的临界点，我们对普适Binder比和相关函数的共形场论（CFT）描述进行了两项附加测试。结果发现，在$\alpha_\mat

    We investigate quantum phase transitions in the transverse field Ising chain with algebraically decaying long-range antiferromagnetic interactions by using the variational Monte Carlo method with the restricted Boltzmann machine being employed as a trial wave function ansatz. In the finite-size scaling analysis with the order parameter and the second R\'enyi entropy, we find that the central charge deviates from 1/2 at a small decay exponent $\alpha_\mathrm{LR}$ in contrast to the critical exponents staying very close to the short-range (SR) Ising values regardless of $\alpha_\mathrm{LR}$ examined, supporting the previously proposed scenario of conformal invariance breakdown. To identify the threshold of the Ising universality and the conformal symmetry, we perform two additional tests for the universal Binder ratio and the conformal field theory (CFT) description of the correlation function. It turns out that both indicate a noticeable deviation from the SR Ising class at $\alpha_\mat
    
[^39]: 无标记多模态数据的多模态学习：保证和应用

    Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications. (arXiv:2306.04539v1 [cs.LG])

    [http://arxiv.org/abs/2306.04539](http://arxiv.org/abs/2306.04539)

    本文研究在只有带标签的单模态数据和自然出现的多模态数据的情况下，如何量化多模态交互的挑战，并提出了两个下界和一个上界来量化多模态交互量。

    

    在许多共同学习多个模态的机器学习系统中，一个核心的研究问题是理解多模态交互的本质：在从两个都没有的模态学习时出现了新的任务相关信息。我们在半监督的情况下研究这一交互量化的挑战，只使用带标签的单模态数据和自然出现的多模态数据（例如，无标签的图像和标题，视频和相应的音频）。利用精确的信息论交互定义，我们的主要贡献是推导下界和上界，量化这种半监督设置下的多模态交互量。我们提出了基于模态共享信息量和单独训练的单模态分类器之间的不一致性的两个下界，并通过连接到近似算法来推导上界。

    In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms fo
    
[^40]: 虚拟健康中的患者预测：一种多模态动态知识图谱和文本挖掘方法

    Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic Knowledge Graph and Text Mining Approach. (arXiv:2306.03833v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.03833](http://arxiv.org/abs/2306.03833)

    本研究提出了一种多模态动态知识驱动退出预测（MDKDP）框架，能够解决虚拟健康中不同利益相关者之间和医疗保健交付系统之间的信息不对称问题，提高了退出预测的性能。

    

    虚拟健康被誉为医疗保健交付中的改变性力量。然而，它的退出问题是至关重要的，会导致较差的健康结果，增加健康、社会和经济成本。及时预测患者的退出使股东能够采取积极的步骤，解决患者的问题，可能提高保留率。为了解决这些信息不对称问题，我们提出了一种多模态动态知识驱动退出预测（MDKDP）框架，该框架从在线和离线医疗保健交付系统的医生患者对话、各个股东的动态和复杂网络中学习隐式和显式知识。我们通过与中国最大的虚拟健康平台之一合作来评估MDKDP。MDKDP提高了退出预测的性能。

    Virtual health has been acclaimed as a transformative force in healthcare delivery. Yet, its dropout issue is critical that leads to poor health outcomes, increased health, societal, and economic costs. Timely prediction of patient dropout enables stakeholders to take proactive steps to address patients' concerns, potentially improving retention rates. In virtual health, the information asymmetries inherent in its delivery format, between different stakeholders, and across different healthcare delivery systems hinder the performance of existing predictive methods. To resolve those information asymmetries, we propose a Multimodal Dynamic Knowledge-driven Dropout Prediction (MDKDP) framework that learns implicit and explicit knowledge from doctor-patient dialogues and the dynamic and complex networks of various stakeholders in both online and offline healthcare delivery systems. We evaluate MDKDP by partnering with one of the largest virtual health platforms in China. MDKDP improves the 
    
[^41]: 分布式SGD算法的稳定性与泛化分析改进

    Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])

    [http://arxiv.org/abs/2306.02939](http://arxiv.org/abs/2306.02939)

    本文提出了新的算法稳定性理论来改进分布式SGD算法的泛化性能分析，推翻了现有技术对通信图负面影响的观点，并展示了D-SGD在凸设置中与经典SGD算法泛化界相同。

    

    本文基于算法稳定性，提出了分布式随机梯度下降(D-SGD)算法的新的泛化误差分析方法。得到的结果大大改进了现有技术，并推翻了它们关于通信图对泛化的负面影响的观点。例如，在凸设置中，无论图的选择如何，D-SGD具有与经典SGD算法相同的泛化界。我们发现这种反直觉的结果来自于考虑本地参数的平均值，这会隐藏一个与分布式场景不兼容的最终全局平均化步骤。考虑到这一观察结果，我们倡导分析本地参数的上确界，并展示了在这种情况下，图确实对泛化产生影响。与之前的结果不同，我们的分析即使对于非连接图也能产生非平凡边界。

    This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
    
[^42]: 基于一般回归误差假设来研究无噪声回归最小二乘估计值的均方误差

    The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])

    [http://arxiv.org/abs/2305.12883](http://arxiv.org/abs/2305.12883)

    该论文研究了基于一般回归误差假设的无噪声回归最小二乘估计值的均方误差，并发现包含大量不重要的参数可以有效地降低估计器的均方误差。

    

    近年来，最小$\ell_2$范数（无岭）插值最小二乘估计器的研究方兴未艾。然而，大多数分析都局限于简单的回归误差结构，假设误差是独立同分布的，具有零均值和相同的方差，与特征向量无关。此外，这些理论分析的主要重点是样本外预测风险。本文通过检查无岭插值最小二乘估计器的均方误差，允许更一般的回归误差假设，打破了现有文献的局限性。具体而言，我们研究过度参数化的潜在好处，通过描绘有限样本中的均方误差来表征均方误差。我们的研究结果表明，相对于样本量，包含大量不重要的参数可以有效地降低估计器的均方误差。

    In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
    
[^43]: 面向对抗鲁棒模型的超参数调节

    Hyper-parameter Tuning for Adversarially Robust Models. (arXiv:2304.02497v1 [cs.LG])

    [http://arxiv.org/abs/2304.02497](http://arxiv.org/abs/2304.02497)

    本文探究对抗训练模型的超参数调节问题，明确对抗环境下需要额外调整的超参数，并提出利用廉价对抗训练方法的新方案降低调节成本。

    

    本文关注对抗训练模型的超参数调节问题，旨在确定在对抗环境下哪些额外的超参数是需要调节的，同时降低对抗训练模型的调节成本。通过对3个广泛应用于先前有关对抗鲁棒性文献中的模型进行广泛的实验研究，我们对这一问题进行了探究，并发现该问题在对抗环境下的复杂性主要有两个方面：需要调整额外的超参数来平衡标准训练和对抗训练；需要独立调整标准训练和对抗训练阶段的超参数。同时，本文还提出了利用廉价的对抗训练方法来降低对抗训练模型超参数调节成本的新机会。

    This work focuses on the problem of hyper-parameter tuning (HPT) for robust (i.e., adversarially trained) models, with the twofold goal of i) establishing which additional HPs are relevant to tune in adversarial settings, and ii) reducing the cost of HPT for robust models. We pursue the first goal via an extensive experimental study based on 3 recent models widely adopted in the prior literature on adversarial robustness. Our findings show that the complexity of the HPT problem, already notoriously expensive, is exacerbated in adversarial settings due to two main reasons: i) the need of tuning additional HPs which balance standard and adversarial training; ii) the need of tuning the HPs of the standard and adversarial training phases independently. Fortunately, we also identify new opportunities to reduce the cost of HPT for robust models. Specifically, we propose to leverage cheap adversarial training methods to obtain inexpensive, yet highly correlated, estimations of the quality ach
    
[^44]: 不需要在子图上运行 GNN，使用子图 GNN 高效计数子结构

    Efficiently Counting Substructures by Subgraph GNNs without Running GNN on Subgraphs. (arXiv:2303.10576v1 [cs.LG])

    [http://arxiv.org/abs/2303.10576](http://arxiv.org/abs/2303.10576)

    本文提出了一种使用结构嵌入和预计算的方法，以减少计算和内存成本，并实现了在子图 GNN 上高效计数子结构的目的。

    

    近来，在图学习中使用图神经网络 (GNN) 来近似计算特定函数，如计数图的子结构，是一个热门趋势。在这些工作中，一种常用的方法是使用子图 GNN，将输入图分解为一系列子图，并通过对每个子图应用 GNN 来增强图的表示。尽管子图 GNN 能够计数复杂的子结构，但它们会遭受高计算和内存成本的困扰。本文提出了一个非常规的问题：我们是否能够使用 GNN 高效地计数子结构？为了回答这个问题，我们首先理论上证明，在子图中到根节点的距离是提高子图 GNN 计数能力的关键。然后，我们将这种信息编码为结构嵌入，并预先计算这些嵌入，以避免通过 GNN 反复提取所有子图中的信息。在各种基准测试上的实验表明，所提出的模型可以保持子图 GNN 的计数能力，同时显著降低计算和内存成本。

    Using graph neural networks (GNNs) to approximate specific functions such as counting graph substructures is a recent trend in graph learning. Among these works, a popular way is to use subgraph GNNs, which decompose the input graph into a collection of subgraphs and enhance the representation of the graph by applying GNN to individual subgraphs. Although subgraph GNNs are able to count complicated substructures, they suffer from high computational and memory costs. In this paper, we address a non-trivial question: can we count substructures efficiently with GNNs? To answer the question, we first theoretically show that the distance to the rooted nodes within subgraphs is key to boosting the counting power of subgraph GNNs. We then encode such information into structural embeddings, and precompute the embeddings to avoid extracting information over all subgraphs via GNNs repeatedly. Experiments on various benchmarks show that the proposed model can preserve the counting power of subgra
    
[^45]: VFP：考虑属性相关性将工业物联网表格数据转换为图像以供卷积神经网络使用。

    VFP: Converting Tabular Data for IIoT into Images Considering Correlations of Attributes for Convolutional Neural Networks. (arXiv:2303.09068v1 [cs.CV])

    [http://arxiv.org/abs/2303.09068](http://arxiv.org/abs/2303.09068)

    这篇论文提出了一种新的将工业物联网表格数据转换为图像的方法，考虑了属性之间的相关性，可以更好地利用卷积神经网络进行数据处理。

    

    对于从工业物联网设备生成的表格数据，传统基于决策树算法的机器学习（ML）技术已被采用。 但是，这些方法在处理真实数字属性占主导地位的表格数据时存在限制。 为了解决这个问题，提出了DeepInsight，REFINED和IGTD将表格数据转换为图像以利用卷积神经网络（CNN）。 他们在图像的某些特定位置收集相似的特征，使转换后的图像看起来像是实际图像。 收集类似的特征与传统的针对表格数据的ML技术形成对比，后者删除一些高度相关的属性以避免过度拟合。 此外，先前的转换方法固定了图像大小，根据表格数据的属性数量，会造成浪费或不足的像素。 因此，本文提出了一种新的转换方法Vortex特征定位（VFP）。 VFP考虑特征的相关性并放置类似的特征。

    For tabular data generated from IIoT devices, traditional machine learning (ML) techniques based on the decision tree algorithm have been employed. However, these methods have limitations in processing tabular data where real number attributes dominate. To address this issue, DeepInsight, REFINED, and IGTD were proposed to convert tabular data into images for utilizing convolutional neural networks (CNNs). They gather similar features in some specific spots of an image to make the converted image look like an actual image. Gathering similar features contrasts with traditional ML techniques for tabular data, which drops some highly correlated attributes to avoid overfitting. Also, previous converting methods fixed the image size, and there are wasted or insufficient pixels according to the number of attributes of tabular data. Therefore, this paper proposes a new converting method, Vortex Feature Positioning (VFP). VFP considers the correlation of features and places similar features fa
    
[^46]: 强大的层级增强学习中的知识传输

    Robust Knowledge Transfer in Tiered Reinforcement Learning. (arXiv:2302.05534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05534](http://arxiv.org/abs/2302.05534)

    本文研究了层级增强学习中的知识传输，提出了一种新颖的在线学习算法，在没有先验知识的任务相似性的情况下实现强大的知识传输。

    

    本文研究了层级增强学习设置，这是一个并行传输学习框架，在这个框架中，目标是将知识从低层（源）任务传输到高层（目标）任务，以减少后者的探索风险，同时并行解决这两个任务。与先前的工作不同，我们不假设低层和高层任务共享相同的动态或奖励函数，并且专注于在没有先验知识的任务相似性的情况下实现强大的知识传输。我们确定了一个称为“最优值支配”的自然而必要的条件，适用于我们的目标。在这个条件下，我们提出了一种新颖的在线学习算法，使得对于高层任务，在部分状态上可以实现恒定的遗憾，这取决于任务相似性，并在两个任务不相似时保持接近最优遗憾；而对于低层任务，它可以在不做出牺牲的情况下保持接近最优。此外，我们进一步研究了具有多个低层任务的情况。

    In this paper, we study the Tiered Reinforcement Learning setting, a parallel transfer learning framework, where the goal is to transfer knowledge from the low-tier (source) task to the high-tier (target) task to reduce the exploration risk of the latter while solving the two tasks in parallel. Unlike previous work, we do not assume the low-tier and high-tier tasks share the same dynamics or reward functions, and focus on robust knowledge transfer without prior knowledge on the task similarity. We identify a natural and necessary condition called the ``Optimal Value Dominance'' for our objective. Under this condition, we propose novel online learning algorithms such that, for the high-tier task, it can achieve constant regret on partial states depending on the task similarity and retain near-optimal regret when the two tasks are dissimilar, while for the low-tier task, it can keep near-optimal without making sacrifice. Moreover, we further study the setting with multiple low-tier tasks
    

