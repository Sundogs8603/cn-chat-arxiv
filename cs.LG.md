# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Approximate Control for Continuous-Time POMDPs](https://rss.arxiv.org/abs/2402.01431) | 本文提出了一个适用于连续时间部分可观察系统的决策框架，通过近似方法实现了针对大规模状态空间的过滤和控制问题的可扩展解决方案。 |
| [^2] | [Vaccine: Perturbation-aware Alignment for Large Language Model](https://rss.arxiv.org/abs/2402.01109) | 疫苗是一种针对大规模语言模型的干扰感知对齐技术，通过逐渐添加扰动产生不变的隐藏嵌入，提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。 |
| [^3] | [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://arxiv.org/abs/2402.19475) | 大多数代码语言模型对生成的冒牌样本的理解较为肤浅，存在三种明显的失败模式：误将冒牌样本分类为正确、在推理冒牌样本的执行行为时表现更差、修复冒牌样本的成功率往往低于生成它们的成功率。 |
| [^4] | [Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress](https://arxiv.org/abs/2402.19472) | 提出了终身基准的概念，通过创建不断扩展的大规模基准来减少过拟合风险，并引入了高效的评估框架Sort \& Search（S&S）来解决评估成本问题。 |
| [^5] | [Humanoid Locomotion as Next Token Prediction](https://arxiv.org/abs/2402.19469) | 该研究将人形控制问题转化为下一个标记预测问题，通过因果变压器训练实现传感器轨迹的自回归预测，可在缺失模态数据下训练，并成功使人形机器人完成步行任务。 |
| [^6] | [Curiosity-driven Red-teaming for Large Language Models](https://arxiv.org/abs/2402.19464) | 研究提出了一种新方法，能够通过训练红队LLM，自动化生成测试案例，以最大化引出目标LLM不良响应，以解决当前RL方法生成测试案例覆盖范围较低的问题。 |
| [^7] | [Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks](https://arxiv.org/abs/2402.19460) | 该论文评估了在ImageNet上的多种不确定性估计器，发现虽然有理论努力，但实践中尚未实现不确定性的解开，同时揭示了哪些估计器在特定任务上表现出色，为从业者提供见解并指导未来研究。 |
| [^8] | [Listening to the Noise: Blind Denoising with Gibbs Diffusion](https://arxiv.org/abs/2402.19455) | 引入了Gibbs扩散（GDiff）方法，通过交替采样信号先验和噪声分布族，以及蒙特卡洛采样来推断噪声参数，解决了盲去噪中需要知道噪声水平和协方差的问题。 |
| [^9] | [Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models](https://arxiv.org/abs/2402.19449) | 研究发现语言模型中的重尾类别不平衡问题导致了优化动态上的困难，Adam和基于符号的方法在这种情况下优于梯度下降。 |
| [^10] | [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](https://arxiv.org/abs/2402.19446) | 本文提出了一个用于构建LLMs的多轮强化学习算法的框架 |
| [^11] | [Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality](https://arxiv.org/abs/2402.19442) | 研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。 |
| [^12] | [Differentially Private Worst-group Risk Minimization](https://arxiv.org/abs/2402.19437) | 该论文介绍了在差分隐私下进行最坏组风险最小化的系统研究，提出了一种新算法，通过稳定性分析实现了接近最优的风险控制效果。 |
| [^13] | [Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](https://arxiv.org/abs/2402.19427) | 提出了 Griffin 模型，将门控线性循环与局部注意力相结合，实现高效的语言模型，该模型在推理过程中具有低延迟和高吞吐量。 |
| [^14] | [PaECTER: Patent-level Representation Learning using Citation-informed Transformers](https://arxiv.org/abs/2402.19411) | PaECTER是一个专为专利设计的开放源码文档级编码器，利用引文信息对BERT进行微调，生成专利文档的数值表示，并在专利领域的相似性任务中表现优异。 |
| [^15] | [A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting](https://arxiv.org/abs/2402.19402) | 提出了一种名为Forchestra的时间序列预测框架，能够准确预测各种物品的未来需求，并且在模型规模和泛化能力上均表现优异。 |
| [^16] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^17] | [Structure Preserving Diffusion Models](https://arxiv.org/abs/2402.19369) | 提出了一种结构保持的扩散过程，可以学习具有群对称性等额外结构的分布，并开发了一系列对称等变扩散模型来实现这一点。 |
| [^18] | [Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361) | LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。 |
| [^19] | [Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification](https://arxiv.org/abs/2402.19355) | 该论文提出了一种检测对抗性样本和识别受害模型的方法，通过扩展先前的攻击类型分类工作和引入新的架构，在攻击检测方面取得了很高的AUC，攻击分类准确率达到86.48%，受害模型分类准确率达到72.28%。 |
| [^20] | [Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook](https://arxiv.org/abs/2402.19348) | 这项调查系统地回顾了针对城市计算量身定制的深度学习数据融合方法的最新进展，将方法分为四大类别，并对不同数据来源和模态在跨领域数据融合中的作用进行了深入研究。 |
| [^21] | [Verification of Neural Networks' Global Robustness](https://arxiv.org/abs/2402.19322) | 提出了一种新的全局鲁棒性属性，旨在找到分类器的最小全局鲁棒边界，并引入了VHAGaR，一个用于计算此边界的验证器。 |
| [^22] | [Attacks Against Mobility Prediction in 5G Networks](https://arxiv.org/abs/2402.19319) | 本文揭示了针对5G网络中移动性预测的潜在攻击，展示了在具有1万名用户的场景中，对手能够显著降低预测准确性的实验结果。 |
| [^23] | [Loss-Free Machine Unlearning](https://arxiv.org/abs/2402.19308) | 我们提出了一种无需重新训练和标记的机器遗忘方法，通过改进算法以在不需要标记数据的情况下近似灵敏度，实验结果表明我们的方法与现有最先进方法竞争力强。 |
| [^24] | [Learnability Gaps of Strategic Classification](https://arxiv.org/abs/2402.19303) | 任何可学习的类也可以战略学习，我们展示了在完全信息设置下的情况，学习者在训练期间可以访问到预处理的信息结构。 |
| [^25] | [RL-GPT: Integrating Reinforcement Learning and Code-as-policy](https://arxiv.org/abs/2402.19299) | RL-GPT 是一个两级分层框架，结合了慢速代理和快速代理，能够高效地整合强化学习和编码任务，在Minecraft游戏中表现出卓越效率。 |
| [^26] | [An AI based Digital Score of Tumour-Immune Microenvironment Predicts Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric Adenocarcinoma](https://arxiv.org/abs/2402.19296) | 人工智能基于肿瘤免疫微环境数字评分成功预测食管胃腺癌患者对维持性免疫治疗的益处，具有临床前景。 |
| [^27] | [Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling](https://arxiv.org/abs/2402.19295) | 本研究探索了在海上风力涡轮结构使用层级贝叶斯模型进行异常检测的方法，以推断土壤刚度分布并实现冲刷的检测。 |
| [^28] | [Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes](https://arxiv.org/abs/2402.19294) | 提出了一种利用UMAP技术的新型故障模式诊断方法，能够有效应对复杂系统中多种故障模式导致的不同降解路径，提高故障模式的准确识别能力。 |
| [^29] | [Estimation and Deconvolution of Second Order Cyclostationary Signals](https://arxiv.org/abs/2402.19290) | 该方法解决了盲去卷积和估计带噪声二阶循环平稳信号时间波形的双重问题，通过证明去卷积滤波器存在，消除信号的TF效应，实现高精度算法，有潜力改善机器学习模型的训练。 |
| [^30] | [StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds](https://arxiv.org/abs/2402.19287) | StiefelGen 提出了一种简单的、与模型无关的方法，可以在黎曼流形上进行时间序列数据增强，填补了现有方法尚未解决的问题。 |
| [^31] | [Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning](https://arxiv.org/abs/2402.19275) | 通过密集强化学习，开发了一个自适应测试环境，包含多个代理模型并优化其组合系数，增强了评估的鲁棒性，提高了评估效率。 |
| [^32] | [Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach](https://arxiv.org/abs/2402.19265) | 通过归纳逻辑编程方法，从POMDP执行痕迹中学习高质量启发式，以指导政策选择过程。 |
| [^33] | [Masks, Signs, And Learning Rate Rewinding](https://arxiv.org/abs/2402.19262) | 学习率回溯（LRR）通过早期翻转参数符号且对符号扰动保持稳健性的能力，不仅在掩模识别方面更有效，而且可以优化各种掩模，包括随机掩模。 |
| [^34] | [Machine learning for modular multiplication](https://arxiv.org/abs/2402.19254) | 证明了模乘任务的困难性，为基于加密系统的任务提供了机器学习方法的研究证据 |
| [^35] | [Derivative-enhanced Deep Operator Network](https://arxiv.org/abs/2402.19242) | DE-DeepONet通过整合导数信息提高了预测准确性，尤其在训练数据有限的情况下，相比传统DeepONet取得了更好的效果。 |
| [^36] | [Trained Random Forests Completely Reveal your Dataset](https://arxiv.org/abs/2402.19232) | 随机森林训练中没有采用自举聚合但具有特征随机化的模型容易被完全重建，即使采用自举聚合，大部分数据也可以被重建。 |
| [^37] | [Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain](https://arxiv.org/abs/2402.19226) | 该研究通过机器学习算法调查了个性化疼痛护理推荐中的性别公平性，发现在某些患者信息缺失时，女性的疼痛护理推荐质量明显低于男性。 |
| [^38] | [Deep Reinforcement Learning: A Convex Optimization Approach](https://arxiv.org/abs/2402.19212) | 本文提出了一种深度强化学习的凸优化方法，通过每集使用凸优化来训练神经网络近似最优$Q$-函数，确保收敛参数可以无限接近最优参数。 |
| [^39] | [Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction](https://arxiv.org/abs/2402.19197) | FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。 |
| [^40] | [Disentangling representations of retinal images with generative models](https://arxiv.org/abs/2402.19186) | 引入一种新颖的视网膜底图像群体模型，有效解开患者属性与相机效果，实现可控且高度逼真的图像生成。 |
| [^41] | [FedStruct: Federated Decoupled Learning over Interconnected Graphs](https://arxiv.org/abs/2402.19163) | FedStruct提出了一种新的框架，利用深层结构依赖关系在互联图上进行联合解耦学习，有效地维护隐私并捕捉节点间的依赖关系。 |
| [^42] | [Beyond Language Models: Byte Models are Digital World Simulators](https://arxiv.org/abs/2402.19155) | bGPT模型利用next byte prediction成功模拟并预测数字世界的各种操作，表现出色，包括在音乐数据转换和CPU行为模拟方面取得了显著进展。 |
| [^43] | [ProtoP-OD: Explainable Object Detection with Prototypical Parts](https://arxiv.org/abs/2402.19142) | 提出了ProtoP-OD，介绍了一种用于目标检测的可解释性扩展，通过构建典型的局部特征，提高模型对图像内容的可解释性和可靠性。 |
| [^44] | [Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets](https://arxiv.org/abs/2402.19110) | 提出了一种利用深度强化学习在现货市场和容灾频率控制辅助服务市场进行出价的新颖BESS联合竞标策略，通过时序特征提取器有效响应多个市场的价格波动，发展出更具解释性的DRL模型。 |
| [^45] | [CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI](https://arxiv.org/abs/2402.19105) | CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。 |
| [^46] | [FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness](https://arxiv.org/abs/2402.19102) | FlatNAS是文献中首个系统探索神经网络丢失函数平坦区域的NAS方法，同时优化其在分布数据和分布之外鲁棒性的性能，以及约束其架构参数数量。 |
| [^47] | [Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation](https://arxiv.org/abs/2402.19101) | 该研究提出了一种有效的两阶段跨实体跨域推荐知识传输方法，解决了多实体推荐中源实体数据分布不同和特征模式不对齐等重要问题。 |
| [^48] | [A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration](https://arxiv.org/abs/2402.19095) | 本研究提出了一种利用Transformer和CNN集成的蛋白质结构预测方法，通过二维融合深度神经网络模型DstruCCN，有助于提升蛋白质二级结构预测的准确性和效率。 |
| [^49] | [Best Arm Identification with Resource Constraints](https://arxiv.org/abs/2402.19090) | 该论文研究了具有资源约束的最佳臂识别问题，提出了连续减半算法（SH-RR），在非渐近情况下以接近最优速度成功识别最佳臂，并发现了确定性和随机资源消耗情况下的收敛速度差异。 |
| [^50] | [Smooth Tchebycheff Scalarization for Multi-Objective Optimization](https://arxiv.org/abs/2402.19078) | 通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。 |
| [^51] | [TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2402.19072) | 本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。 |
| [^52] | [Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach](https://arxiv.org/abs/2402.19062) | 该研究提出了一种全面的方法，通过图卷积神经网络实现了自动超声心动图视图识别，结合了3D心脏网格重建和后续任务如分割和姿势估计。 |
| [^53] | [Theoretical Foundations of Deep Selective State-Space Models](https://arxiv.org/abs/2402.19047) | 随着GateLoop、Mamba和GLA等具有乘法交互的线性递归驱动下的深度SSM架构的出现，它们在准确性和效率上超越了基于注意力的文本训练的基础模型。 |
| [^54] | [A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces](https://arxiv.org/abs/2402.19037) | 通过深度学习技术，成功实现了在侧信道跟踪中定位目标加密操作的时间瞬间，即使存在跟踪变形。 |
| [^55] | [Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness](https://arxiv.org/abs/2402.19025) | 引入了将弱学习者解释组合的方法来改进随机森林的解释性和稳健性，通过对集成方法中解释进行判别平均，取得了成功的实验结果和定量改进。 |
| [^56] | [SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery](https://arxiv.org/abs/2402.19016) | 本研究提出了一种新的用于联邦学习的差分隐私稀疏基础恢复算法SPriFed-OMP，通过将OMP转化为FL设置，并结合SMPC和DP，有效降低了噪声添加量来实现差分隐私。 |
| [^57] | [Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding](https://arxiv.org/abs/2402.19009) | 引入了具有可学习编码器-解码器的广义扩散（DiLED），用于在不同数据类型上无缝整合生成新实例、重建输入和学习紧凑表示，扩展了现有模型家族的性能。 |
| [^58] | [Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series](https://arxiv.org/abs/2402.18995) | 提出了一种负二项随机Gamma马尔可夫过程，用于改进异质过度离散计数时间序列的预测性能，并加快推断算法的收敛速度。 |
| [^59] | [Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks](https://arxiv.org/abs/2402.18994) | Spyx旨在提供一个用于即时编译优化脉冲神经网络的库，以在训练时增强能效并减少硬件占用。 |
| [^60] | [Graph Generation via Spectral Diffusion](https://arxiv.org/abs/2402.18974) | 提出了一种基于图拉普拉斯矩阵谱分解和扩散过程的新颖图生成模型GRASP，能够通过截断拉普拉斯频谱快速准确地捕捉图的结构特征，同时处理节点特征，避免了二次复杂性瓶颈。 |
| [^61] | [Improving Group Connectivity for Generalization of Federated Deep Learning](https://arxiv.org/abs/2402.18949) | 通过研究和改进联邦学习的泛化能力，本文从“连接性”视角探讨了如何改善本地模型间的连接性以生成更具泛化能力的全局模型。 |
| [^62] | [Real-Time Adaptive Safety-Critical Control with Gaussian Processes in High-Order Uncertain Models](https://arxiv.org/abs/2402.18946) | 本文提出了一种用于高阶不确定模型的实时自适应安全关键控制的方法，包括利用稀疏高斯过程进行在线学习和基于高阶控制屏障函数的安全过滤器。 |
| [^63] | [Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation](https://arxiv.org/abs/2402.18919) | 通过组合方法改善模型对相关性转移的稳健性，解决了图像分类中伪相关性的问题。 |
| [^64] | [Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization](https://arxiv.org/abs/2402.18917) | 针对带偏好反馈的积极在线分类优化问题，提出了一种既高效又具有最优后悔保证的算法。 |
| [^65] | [DIGIC: Domain Generalizable Imitation Learning by Causal Discovery](https://arxiv.org/abs/2402.18910) | 通过在只有单一领域数据的情况下发现因果特征，提出了一种新颖的领域泛化模仿学习框架DIGIC，可以作为非结构化假设下基于跨领域变化方法的补充 |
| [^66] | [On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?](https://arxiv.org/abs/2402.18905) | 本文分析了差分隐私线性探测（LP）和完全微调（FT）的训练动态，探索了从线性探测过渡到完全微调（LP-FT）的顺序微调现象及其对测试损失的影响，提供了关于在超参数化神经网络中差分隐私微调收敛性的理论洞见和隐私预算分配的效用曲线。 |
| [^67] | [Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos](https://arxiv.org/abs/2402.18888) | 提出了一种基于不确定性的可拓展编码本的联邦学习框架，用于应对异构数据孤岛中模型适应新分布的挑战 |
| [^68] | [BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet](https://arxiv.org/abs/2402.18886) | 本研究提出了基于物理的DeepONet方法，用于预测动脉血压（ABP）波形，首次实现了连续预测ABP波形，满足Navier-Stokes方程和Windkessel边界条件。 |
| [^69] | [Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features](https://arxiv.org/abs/2402.18884) | 通过监督对比表示学习，在超参数化的深度神经网络中研究解决方案，揭示了最小化SC损失的全局最小值和唯一最小化器。 |
| [^70] | [Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2402.18875) | 本文研究了课程学习技术在改善异构图神经网络性能和鲁棒性方面的应用，提出了一种损失感知的训练计划LTS，有效减少偏差和方差，减轻嘈杂数据影响，增强整体准确性。 |
| [^71] | [Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming](https://arxiv.org/abs/2402.18866) | 本文提出了一个新的基于模型的通用型Agent Dr. Strategy，配备了Dreaming Strategy，实现了在梦境中学习一组潜在地标，并利用这些地标学习地标条件的高速公路策略。 |
| [^72] | [Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning](https://arxiv.org/abs/2402.18865) | 通过模式连接调查了连续微调中不同极小值之间的几何连接，揭示了大型语言模型中的灾难性遗忘问题。 |
| [^73] | [Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models](https://arxiv.org/abs/2402.18863) | 概率Lipschitz性与稳定秩的研究为比较解释模型提供了新的角度和度量标准。 |
| [^74] | [Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation](https://arxiv.org/abs/2402.18859) | 本研究集中于为电网储能中的退役电池设计健康监测算法，开发了四种基于机器学习的健康评估模型，并提出了一种自适应在线健康评估算法。 |
| [^75] | [Rethinking Multi-domain Generalization with A General Learning Objective](https://arxiv.org/abs/2402.18853) | 提出了一个通用学习目标范式，通过Y-mapping来放松约束并设计新的学习目标，包括学习域无关的条件特征和最大化后验概率，通过正则化项解决放松约束引起的问题 |
| [^76] | [Applications of 0-1 Neural Networks in Prescription and Prediction](https://arxiv.org/abs/2402.18851) | 引入了处方网络（PNNs）这种新型神经网络，通过混合整数规划训练，结合反事实估计，在医疗决策中展现出优于现有方法的表现，可优化治疗策略，并具有更大的可解释性和更复杂的策略编码能力。 |
| [^77] | [Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling](https://arxiv.org/abs/2402.18846) | 提出了一种多保真度残差神经过程（MFRNP）框架，旨在优化低保真度解码器，通过聚合准确的信息共享来解决不同保真度之间的共享信息不准确的问题。 |
| [^78] | [Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation](https://arxiv.org/abs/2402.18839) | 本文基于Flow Matching发展了条件生成理论，通过使用广义连续性方程的数学框架而非流匹配中的连续性方程，实现了一种新颖的流基条件分布生成方法。 |
| [^79] | [A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations](https://arxiv.org/abs/2402.18836) | 这个方法结合了最大熵强化学习和行为克隆损失的扩展策略损失，通过调整权重提高了强化学习的效率，并在连续控制任务中表现优异。 |
| [^80] | [Training-set-free two-stage deep learning for Spectroscopic data de-noising](https://arxiv.org/abs/2402.18830) | 提出了一种无需训练集的两阶段深度学习方法，结合自适应先验和先进优化技术，实现了比先前工作快五倍的加速。 |
| [^81] | [Batch size invariant Adam](https://arxiv.org/abs/2402.18824) | 提出了Adam的批量大小不变版本，通过改变计算顺序实现批量大小不变性，比之前的方法具有更广泛的适用范围。 |
| [^82] | [Dual Operating Modes of In-Context Learning](https://arxiv.org/abs/2402.18819) | 该论文介绍了In-Context Learning的双重运行模式，通过引入概率模型同时解释了任务学习和任务检索，对线性函数的上下文学习进行了扩展，分析了优化预训练模型在平方损失下的行为，并推导出了任务后验分布的闭式表达式。 |
| [^83] | [To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models](https://arxiv.org/abs/2402.18803) | 该研究分析了群体公平训练对共享模型的正则化效果，通过推导群体特定的泛化误差界限以解决不同群体之间的性能差异问题，尤其对于较小的群体规模有显着改进。 |
| [^84] | [BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data](https://arxiv.org/abs/2402.18800) | 该论文提出了一种名为BlockEcho的新矩阵填充方法，通过将矩阵分解和生成对抗网络相结合，创造性地保留了原始矩阵中的长距离依赖关系，以解决块状缺失数据对数据插值和预测能力的挑战。 |
| [^85] | [MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks](https://arxiv.org/abs/2402.18792) | 提出了一种基于恶意扰动的对抗训练方法（MPAT）来构建鲁棒的深度神经网络，用于抵御文本对抗攻击。 |
| [^86] | [FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning](https://arxiv.org/abs/2402.18789) | FlexLLM是第一个可以在同一迭代中共同提供推理和参数高效微调请求的系统，通过引入标记级微调机制实现共享GPU资源的高效利用 |
| [^87] | [Enhancing the "Immunity" of Mixture-of-Experts Networks for Adversarial Defense](https://arxiv.org/abs/2402.18787) | 提出了一种名为“免疫力”(Immunity)的新对抗性防御方法，通过修改的专家混合(MoE)架构，结合随机切换门(RSGs)和基于互信息(MI)和位置稳定性的损失函数，增加了专家网络的多样性和因果关系。 |
| [^88] | [Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games](https://arxiv.org/abs/2402.18781) | 提出了一种具有假设在线学习（COL）的学习方案，针对通用AISG，结构化为一个先验预测者-演员-评论家（FAC）架构，利用一级信念和对手策略的主观预测，通过在线展开更新策略，并通过贝叶斯学习校准假设。 |
| [^89] | [Disentangling the Causes of Plasticity Loss in Neural Networks](https://arxiv.org/abs/2402.18762) | 这篇论文研究了神经网络中可塑性丧失的原因，探讨了不稳定性的根源以及如何结合减轻策略以保持网络的可训练性。 |
| [^90] | [Learning with Language-Guided State Abstractions](https://arxiv.org/abs/2402.18759) | 利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。 |
| [^91] | [Pre-training Differentially Private Models with Limited Public Data](https://arxiv.org/abs/2402.18752) | 通过使用有限的公共数据，研究者提出了一种新颖的差分隐私持续预训练策略，以显著缓解优化器性能下降。 |
| [^92] | [Multi-Sensor and Multi-temporal High-Throughput Phenotyping for Monitoring and Early Detection of Water-Limiting Stress in Soybean](https://arxiv.org/abs/2402.18751) | 该研究结合多模式信息，开发了快速分类大豆干旱胁迫症状的自动化方法，并研究了干旱胁迫的早期检测方法。 |
| [^93] | [Accelerating Computer Architecture Simulation through Machine Learning](https://arxiv.org/abs/2402.18746) | 通过机器学习技术加速计算机体系结构模拟，利用应用程序特征和微体系结构特征的组合来预测性能，有效地提高了体系结构探索的速度，并展示了在测试数据中预测IPC值的能力。 |
| [^94] | [Priority Sampling of Large Language Models for Compilers](https://arxiv.org/abs/2402.18734) | 提出了一种优先采样技术，能够按照模型信心度产生唯一样本，在生成和优化代码时表现优于核采样方法。 |
| [^95] | [GAIA: Categorical Foundations of Generative AI](https://arxiv.org/abs/2402.18732) | 提出了一种基于范畴论的生成AI架构GAIA，采用层次模型和单纯复合体组织模块，将参数更新建模为单纯集上的提升图表，并采用余代数的形式进行深度学习。 |
| [^96] | [A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks](https://arxiv.org/abs/2402.18729) | 使用贝叶斯神经网络对反应流动模型中的不确定性进行量化，特别是在湍涡预混火焰动态中关键变量的建模方面取得重要进展 |
| [^97] | [Unveiling Privacy, Memorization, and Input Curvature Links](https://arxiv.org/abs/2402.18726) | 本研究揭示了记忆与输入损失曲率之间的联系，并建立了差分隐私、记忆和输入损失曲率之间的理论联系。 |
| [^98] | [Learning Associative Memories with Gradient Descent](https://arxiv.org/abs/2402.18724) | 该论文研究了一个关联记忆模块的训练动态，通过理论和实验揭示了在过参数化和欠参数化情况下的学习动态和误差特性。 |
| [^99] | [Learning to Compress Prompt in Natural Language Formats](https://arxiv.org/abs/2402.18700) | 该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。 |
| [^100] | [Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting](https://arxiv.org/abs/2402.18697) | 通过识别一个生成网络模型，我们建立了一个设置，IPF可以恢复最大似然估计，揭示了关于在这种设置中使用IPF的隐含假设，并可以为IPF的参数估计提供结构相关的误差界。 |
| [^101] | [The VOROS: Lifting ROC curves to 3D](https://arxiv.org/abs/2402.18689) | 引入第三维度，将ROC曲线提升为ROC曲面，提出VOROS作为2D ROC曲线下面积的3D泛化，可以更好地捕捉不同分类器的成本。 |
| [^102] | [Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679) | 本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。 |
| [^103] | [Simple linear attention language models balance the recall-throughput tradeoff](https://arxiv.org/abs/2402.18668) | 提出了一种简单的线性注意力语言模型架构，可以平衡召回和内存消耗之间的权衡。 |
| [^104] | [Quantifying Human Priors over Social and Navigation Networks](https://arxiv.org/abs/2402.18651) | 本研究利用图的组合结构来量化人类对社交和导航网络的先验知识，揭示了一些一致的特征和特定领域的倾向，为高效建模数据中的潜在偏见提供了方法。 |
| [^105] | [GNSS Positioning using Cost Function Regulated Multilateration and Graph Neural Networks](https://arxiv.org/abs/2402.18630) | 使用图神经网络替代传统误差估计方法，并通过分析多站定位过程的成本函数，提出一种优化方法，显著改善了GNSS定位精度。 |
| [^106] | [ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games](https://arxiv.org/abs/2402.18617) | 该研究提出了一种新颖的方法，利用无监督学习技术估计不同示范者制作的零和博弈离线数据集中每条轨迹的被利用水平，并将其融入离线学习以最大化支配策略的影响力。 |
| [^107] | [Deep Neural Network Models Trained With A Fixed Random Classifier Transfer Better Across Domains](https://arxiv.org/abs/2402.18614) | DNN模型利用ETF进行训练，在最后一层权重固定的情况下，显著提高了跨域数据集上的转移性能。 |
| [^108] | [Understanding random forests and overfitting: a visualization and simulation study](https://arxiv.org/abs/2402.18612) | 这项研究通过可视化和模拟研究探讨了随机森林的行为，发现在训练集存在过拟合的情况下，模型在测试数据上表现出了竞争力。 |
| [^109] | [HemaGraph: Breaking Barriers in Hematologic Single Cell Classification with Graph Attention](https://arxiv.org/abs/2402.18611) | HemaGraph利用图注意力网络实现了从流式细胞术数据中对血液学单细胞进行准确分类，尤其在处理巨大图以检测低频细胞群体方面表现出色。 |
| [^110] | [Why Attention Graphs Are All We Need: Pioneering Hierarchical Classification of Hematologic Cell Populations with LeukoGraph](https://arxiv.org/abs/2402.18610) | LeukoGraph是一个使用图注意力网络实现细胞群体的层次分类的先驱方法，可以处理大规模的数据集，并解决复杂数据集中细胞群体的层次结构挑战。 |
| [^111] | [ICE-SEARCH: A Language Model-Driven Feature Selection Approach](https://arxiv.org/abs/2402.18609) | ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。 |
| [^112] | [Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective](https://arxiv.org/abs/2402.18607) | 本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。 |
| [^113] | [Impact of network topology on the performance of Decentralized Federated Learning](https://arxiv.org/abs/2402.18606) | 研究探讨了不同类型的网络结构如何影响去中心化联邦学习中的知识传播，并通过三种网络拓扑和六种数据分布方法研究了网络结构与学习性能之间的复杂相互作用。 |
| [^114] | [FORML: A Riemannian Hessian-free Method for Meta-learning with Orthogonality Constraint](https://arxiv.org/abs/2402.18605) | 该论文介绍了一种 FORML 方法，使用斯蒂夫尔流形上的一阶导数近似，通过引入海森自由方法来降低计算负担和内存占用，并在元学习中实现参数正交约束。 |
| [^115] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^116] | [Meta-Tasks: An alternative view on Meta-Learning Regularization](https://arxiv.org/abs/2402.18599) | 该论文提出了一种新颖的解决方案，通过使用meta-tasks作为元学习正则化的视角，实现了对训练和新颖任务的泛化，避免标记数据稀缺的困扰，并在实验中表现优越，相较于原型网络提高了3.9%的性能。 |
| [^117] | [EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural Network Acceleration](https://arxiv.org/abs/2402.18595) | 提出了一种基于编码的新型数字MAC设计，通过用简单的逻辑门代替乘法器，训练特定神经网络的位置权重，实现逐位加权累积，从而提高神经网络加速的能效和计算效果。 |
| [^118] | [Stochastic contextual bandits with graph feedback: from independence number to MAS number](https://arxiv.org/abs/2402.18591) | 本文研究了具有图反馈的上下文赌博问题，提出了一个刻画学习极限的图论量 $\beta_M(G)$，并建立了对应的遗憾下限。 |
| [^119] | [Verif.ai: Towards an Open-Source Scientific Generative Question-Answering System with Referenced and Verifiable Answers](https://arxiv.org/abs/2402.18589) | Verif.ai是一个具有引用和可验证答案的开源科学生成式问答系统，通过信息检索、生成模型和验证引擎的结合实现对主张的生成和验证。 |
| [^120] | [At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence](https://arxiv.org/abs/2402.18587) | GenAI在无线领域是关键资产，能够处理稀缺、不完整、难以获取和理解的真实世界数据，可以取代或补充判别式人工智能方法，本文汇总了6G和无线智能领域的新前沿。 |
| [^121] | [Binding-Adaptive Diffusion Models for Structure-Based Drug Design](https://arxiv.org/abs/2402.18583) | 提出了一种新的框架——结合自适应扩散模型（BindDM），通过自适应地提取蛋白质-配体相互作用的重要部分，并利用SE(3)-等变神经网络处理，将结合信息传回每个原子，从而增强了基于目标的3D分子扩散生成的方法 |
| [^122] | [Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network](https://arxiv.org/abs/2402.18576) | 本研究提出利用PSO-RDV框架改进预测方法，通过采用随机下降速度惯性权重（RDV IW）技术提高了粒子群优化（PSO）的收敛性和人工神经网络（ANN）的准确性。 |
| [^123] | [DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images](https://arxiv.org/abs/2402.18575) | 本研究提出了DiffuseRAW，一个端到端生成RAW图像处理方法，重点解决了低光照图像处理中整个图像处理管道学习的问题。 |
| [^124] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^125] | [Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces](https://arxiv.org/abs/2402.18546) | TOTEM模型在应对传感器故障的神经科学研究中实现了更好的泛化性能。 |
| [^126] | [RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval](https://arxiv.org/abs/2402.18510) | 本文研究了RNNs和Transformer在处理算法问题时的表现能力差距，发现RNNs存在关键瓶颈，即无法完美地从上下文中检索信息，导致无法像Transformer那样轻松解决需要这种能力的任务。 |
| [^127] | [ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning](https://arxiv.org/abs/2402.18495) | 提出了一个名为ROG$_PL$的统一框架，通过基于区域的原型学习实现了稳健的开放集图学习。 |
| [^128] | [Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion](https://arxiv.org/abs/2402.17886) | 本文提出了一种基于去噪扩散过程的零阶扩散蒙特卡洛算法，克服了非对数凹分布采样中的亚稳定性问题，并证明其采样精度具有倒多项式依赖。 |
| [^129] | [A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)](https://arxiv.org/abs/2402.17398) | 使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。 |
| [^130] | [Discovering Symmetry Group Structures via Implicit Orthogonality Bias](https://arxiv.org/abs/2402.17002) | HyperCube网络通过独特的因式分解架构和正则化器，成功学习了对称群的操作，能够高效地恢复完整操作表，并形成广义傅里叶基进行群卷积。 |
| [^131] | [A Provably Accurate Randomized Sampling Algorithm for Logistic Regression](https://arxiv.org/abs/2402.16326) | 提出了一种逻辑回归问题的简单随机抽样算法，通过随机矩阵乘法实现高质量逼近估计概率和模型整体差异性。 |
| [^132] | [Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy](https://arxiv.org/abs/2402.16041) | 通过多种群意识优化检测机器生成文本的最大均值离差，解决了机器生成文本与人工编写文本之间微妙的分布差异挑战。 |
| [^133] | [Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning](https://arxiv.org/abs/2402.15893) | 提出了一种同时学习安全RL控制策略和识别未知安全约束参数的新方法。 |
| [^134] | [GraphEdit: Large Language Models for Graph Structure Learning](https://arxiv.org/abs/2402.15183) | 本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。 |
| [^135] | [Neural Networks and Friction: Slide, Hold, Learn](https://arxiv.org/abs/2402.14148) | 循环神经网络利用GRU架构学习合成数据中复杂摩擦定律动力学，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。 |
| [^136] | [E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://arxiv.org/abs/2402.14041) | E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。 |
| [^137] | [Everything You Always Wanted to Know About Storage Compressibility of Pre-Trained ML Models but Were Afraid to Ask](https://arxiv.org/abs/2402.13429) | 这项研究是关于对预训练机器学习模型数据集的存储可压缩性进行首次全面分析，发现现代数据缩减工具在处理PTM数据集时并不有效。 |
| [^138] | [Random Projection Layers for Multidimensional Time Sires Forecasting](https://arxiv.org/abs/2402.10487) | 提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能 |
| [^139] | [ManiFPT: Defining and Analyzing Fingerprints of Generative Models](https://arxiv.org/abs/2402.10401) | 本文明确定了生成模型中的工件和指纹的定义，并提出了计算它们的算法，发现使用该定义可以显著提高识别潜在生成过程的性能。 |
| [^140] | [Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias](https://arxiv.org/abs/2402.10192) | 该论文引入了多激发投影模拟（mePS），通过在超图上多个粒子的随机游走，解决了投影模拟（PS）无法模拟同时结合多个概念的思维的问题。 |
| [^141] | [Less is More: Fewer Interpretable Region via Submodular Subset Selection](https://arxiv.org/abs/2402.09164) | 本论文将图像归属问题重新建模为次模子集选择问题，通过使用更少的区域来增强模型的解释性，解决了现有归属解决方案面临的不准确区域和预测错误样本的问题。 |
| [^142] | [Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes](https://arxiv.org/abs/2402.03726) | 本论文提出了一种名为ISAHP的深度学习框架，可以从异步、相互依赖的多类型事件序列中无监督地学习实例级的格兰杰因果关系。它是第一个满足格兰杰因果关系要求的神经点过程模型，并利用变压器的自我注意机制来实现格兰杰因果关系的推断。 |
| [^143] | [Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models](https://arxiv.org/abs/2402.03659) | 这个论文介绍了使用大型语言模型生成可解释的股票预测的方法，并提出了Summarize-Explain-Predict（SEP）模型来解决股票预测中的解释问题和数据标注成本的挑战。 |
| [^144] | [Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic Scene Classification under Domain Shift](https://arxiv.org/abs/2402.02694) | 这项研究介绍了ICME 2024 Grand Challenge中的半监督领域转移下的声场分类任务，该任务探索了不同区域之间领域转移的挑战，同时研究了如何利用未标记数据来提升声场分类模型的性能。 |
| [^145] | [Unveiling Molecular Moieties through Hierarchical Graph Explainability](https://arxiv.org/abs/2402.01744) | 本论文提出了一种使用图神经网络和分层可解释人工智能技术的方法，能够准确预测生物活性并找到与之相关的最重要的成分。 |
| [^146] | [A Study of Acquisition Functions for Medical Imaging Deep Active Learning](https://arxiv.org/abs/2401.15721) | 本研究探讨了在医学图像领域中如何应用主动学习以解决数据稀缺的问题，并通过对比不同的选择标准和获取池大小对模型性能的影响，结果表明不确定性对于黑色素瘤检测任务是有帮助的。 |
| [^147] | [OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics](https://arxiv.org/abs/2401.12202) | 该研究提出了一种新型基于开放知识的机器人框架OK-Robot，通过整合视觉-语言模型、导航原语和抓取原语，为Pick-and-Drop操作提供了一个集成解决方案，无需任何训练。 |
| [^148] | [Tight Verification of Probabilistic Robustness in Bayesian Neural Networks](https://arxiv.org/abs/2401.11627) | 通过引入两种算法，实现了对Bayesian神经网络概率鲁棒性的严格验证，相比标准神经网络，这些算法更加高效且能够搜索参数空间以找到安全权重。 |
| [^149] | [Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization](https://arxiv.org/abs/2312.16731) | 引入了Infinite dSprites工具，用于创建任意长度的连续分类和分解基准，可以全面控制生成因素，有望缩小机器学习系统与人类学习在动态开放环境中的差距 |
| [^150] | [Dual-stage optimizer for systematic overestimation adjustment applied to multi-objective genetic algorithms for biomarker selection](https://arxiv.org/abs/2312.16624) | 该论文介绍了一种双阶段优化器，用于对多目标遗传算法中的生物标志物选择进行系统性过估调整。 |
| [^151] | [Poincar\'e Differential Privacy for Hierarchy-Aware Graph Embedding](https://arxiv.org/abs/2312.12183) | 提出了Poincaré差分隐私框架PoinDP，用于保护基于层次感知的图嵌入，解决了在图神经网络中层次性带来的隐私泄露问题。 |
| [^152] | [Safe Reinforcement Learning in a Simulated Robotic Arm](https://arxiv.org/abs/2312.09468) | 本文通过在Panda机器人臂上创建定制环境，扩展了安全强化学习算法的适用性，实现了安全RL算法在物理环境中的测试。 |
| [^153] | [Topology-Based Reconstruction Prevention for Decentralised Learning](https://arxiv.org/abs/2312.05248) | 通过研究发现，在去中心化学习中，被动的好奇敌手可以在几次保护隐私的求和操作后推断出其他用户的私人数据。 |
| [^154] | [Multitask Learning Can Improve Worst-Group Outcomes](https://arxiv.org/abs/2312.03151) | 本文研究了多任务学习对最糟糕群体准确性的影响，并探讨了其作为解决组内公平挑战工具的潜力。 |
| [^155] | [Detecting algorithmic bias in medical AI-models](https://arxiv.org/abs/2312.02959) | 本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚，通过采用CART算法有效地识别医疗AI模型中的潜在偏倚，并在合成数据实验和真实临床环境中验证了其有效性。 |
| [^156] | [Convergence Analysis for Learning Orthonormal Deep Linear Neural Networks](https://arxiv.org/abs/2311.14658) | 提供了学习正交深度线性神经网络的收敛分析，通过Riemannian梯度下降以线性速率收敛于具有一类损失函数的训练正交深度线性神经网络。 |
| [^157] | [Molecular Identification and Peak Assignment: Leveraging Multi-Level Multimodal Alignment on NMR](https://arxiv.org/abs/2311.13817) | 本文提出了一种新颖的解决方案，即多级多模态对齐（K-M3AID），通过在分子图和NMR光谱之间建立对应关系，采用知识引导的实例级对比学习，以解决分子检索、异构体识别和峰归属等任务中的挑战。 |
| [^158] | [FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning](https://arxiv.org/abs/2311.13250) | 本文介绍了FedHCA$^2$框架，旨在解决异构客户联邦多任务学习中的模型不一致问题，实现个性化模型联邦训练。 |
| [^159] | [Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints](https://arxiv.org/abs/2311.08675) | 探索了在模型性能约束下的最小核心集大小精化选择问题，并提出了一种创新方法来有效地优化核心集大小和模型性能，同时提供了理论上的收敛保证。 |
| [^160] | [Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?](https://arxiv.org/abs/2310.08540) | 本研究重新审视了预训练的Transformer是否通过梯度下降在上下文中学习的假设，并发现现有研究中的假设存在限制性假设，使其与实际语言模型训练时的语境存在显著差异。同时，通过对真实模型的观察和比较，揭示了ICL和GD在观察演示顺序上的不同敏感性。 |
| [^161] | [Analyzing Trendy Twitter Hashtags in the 2022 French Election](https://arxiv.org/abs/2310.07576) | 提出了一种使用语义网络作为用户级特征进行机器学习任务的方法，通过分析2022年法国总统选举相关的Twitter标签构建了一个双分图，并将其转换为具有最受欢迎的哈希标签的最大生成树 |
| [^162] | [Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic](https://arxiv.org/abs/2309.13339) | 提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。 |
| [^163] | [Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation](https://arxiv.org/abs/2306.00964) | 提出了鸡尾酒方法，将不同模态混合到一个嵌入中，结合通用控制网络、可控归一化和空间引导采样方法，实现了对文本条件扩散模型的多模态和空间精细控制。 |
| [^164] | [Differential Diffusion: Giving Each Pixel Its Strength](https://arxiv.org/abs/2306.00950) | 该论文介绍了一种新颖的框架，允许对每个像素或图像区域的改变量进行定制化，为扩散模型增加了粒度控制的能力，进一步扩展了图像编辑的功能。 |
| [^165] | [Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting](https://arxiv.org/abs/2304.00933) | 揭示了持续学习表示中的知识积累和特征遗忘问题，表明即使特征遗忘的绝对程度可能较小，新学习的信息在表示层面也面临着严重遗忘。 |
| [^166] | [Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection](https://arxiv.org/abs/2302.02237) | 提出了一种名为CSForest的方法，利用Conformalized Semi-Supervised Random Forest技术来解决训练集和测试集之间的差异，提高准确性并标识未见的离群值。 |
| [^167] | [IMG2IMU: Translating Knowledge from Large-Scale Images to IMU Sensing Applications](https://arxiv.org/abs/2209.00945) | 通过将大规模图像中预训练获得的表示适应于IMU感知任务，提出了IMG2IMU方法，实现了对IMU感知应用的知识转化。 |
| [^168] | [Transferability-Guided Cross-Domain Cross-Task Transfer Learning](https://arxiv.org/abs/2207.05510) | 提出了两种新的传递性度量标准 F-OTCE 和 JC-OTCE，用于评估源模型对目标任务的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。 |
| [^169] | [Neural Galerkin Schemes with Active Learning for High-Dimensional Evolution Equations](https://arxiv.org/abs/2203.01360) | 通过神经Galerkin方案结合深度学习和主动学习，能够自主生成训练数据用于高维偏微分方程的数值求解 |
| [^170] | [CAREER: A Foundation Model for Labor Sequence Data](https://arxiv.org/abs/2202.08370) | CAREER模型结合大规模在线简历数据和小型纵向调查数据，有效预测工作序列。 |
| [^171] | [Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation](https://arxiv.org/abs/2112.01799) | 结合VQ-VAE的内容丰富的离散视觉码书，离散扩散模型能够生成具有全局背景的高保真度图像，弥补了传统自回归模型在像素空间中的不足。 |
| [^172] | [Self-Initiated Open World Learning for Autonomous AI Agents](https://arxiv.org/abs/2110.11385) | 论文提出了一种自主开放世界学习的方法，使人工智能代理能够在自主、自我激励和自我监督的方式下学习，以应对未知或新颖性环境中的挑战，实现逐步学习和提升知识与能力。 |
| [^173] | [Practical Transferability Estimation for Image Classification Tasks](https://arxiv.org/abs/2106.10479) | 提出了一个实用的转移性度量JC-NCE分数，通过显著改善OTCE中任务差异估计的鲁棒性，消除了对辅助任务的需求。 |
| [^174] | [Offline detection of change-points in the mean for stationary graph signals](https://arxiv.org/abs/2006.10628) | 提出了一种离线方法用于检测图信号中均值变化点，通过在频谱域解决问题，充分利用了稀疏性，采用模型选择方法自动确定变点的数量，并给出了非渐近oracle不等式的证明。 |
| [^175] | [The committee machine: Computational to statistical gaps in learning a two-layers neural network](https://arxiv.org/abs/1806.05451) | 介绍了对于两层神经网络模型委员会机器的严格理论基础和近似消息传递算法，揭示了计算到统计学差距。 |
| [^176] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^177] | [Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer.](http://arxiv.org/abs/2401.09181) | 本研究提出了一种名为Fwd-Prompt的方法，通过对输入嵌入进行奇异值分解，并在残差空间和预训练子空间中进行梯度投影，以解决多模态连续指导调优中的灾难性遗忘和负面的正向传递问题。 |
| [^178] | [Score Models for Offline Goal-Conditioned Reinforcement Learning.](http://arxiv.org/abs/2311.02013) | 本文提出了一种新颖的离线目标条件强化学习方法，称为SMORe，它将占有匹配的视角与混合分布匹配相结合，无需学习鉴别器，从而提高了GCRL在离线环境中的表现。 |
| [^179] | [The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing.](http://arxiv.org/abs/2311.01410) | 本论文提出了一种概率形式的扩散图像编辑方法，说明了SDE在图像编辑中的优势，并提供了SDE和ODE在各种任务中的对应关系。此外，还提出了一种基于SDE的点在图像上拖动的方法，并建立了一个具有开放集的挑战性基准。 |
| [^180] | [Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models.](http://arxiv.org/abs/2310.18127) | 本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。 |
| [^181] | [Looping in the Human: Collaborative and Explainable Bayesian Optimization.](http://arxiv.org/abs/2310.17273) | 协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。 |
| [^182] | [Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks.](http://arxiv.org/abs/2310.14720) | 本研究提出了一种名为EDAIn的扩展深度自适应输入规范化层，通过以端到端的方式学习如何适当地规范化时序数据，而不是使用固定的规范化方案，来提高深度神经网络在时序预测和分类任务中的性能。实验证明该方法在不同数据集上都取得了良好效果。 |
| [^183] | [A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model.](http://arxiv.org/abs/2310.11143) | 本研究提出了一种基于机器学习的概率暴露模型，可以更准确地估计德国室内氡气分布，并具有更高的空间分辨率。 |
| [^184] | [Score dynamics: scaling molecular dynamics with picosecond timesteps via conditional diffusion model.](http://arxiv.org/abs/2310.01678) | 该论文提出了Score dynamics (SD) 方法，通过条件扩散模型，可以使用1 ps的时间步长进行分子动力学模拟。基于图神经网络的Score dynamics模型展示了在丙氨酸二肽和短链烷烃案例中的效果。 |
| [^185] | [Mirror Diffusion Models for Constrained and Watermarked Generation.](http://arxiv.org/abs/2310.01236) | 提出了一种新的镜像扩散模型（MDM），可以在受限制集合上生成数据而不丧失可追溯性。这通过在一个标准的欧几里得空间中学习扩散过程，并利用镜像映射来实现。 |
| [^186] | [PlaceNav: Topological Navigation through Place Recognition.](http://arxiv.org/abs/2309.17260) | PlaceNav是一种通过地点识别进行拓扑导航的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件，通过使用非机器人来源的大规模数据集增加训练数据的可用性，同时通过地点识别来提高导航性能。新模型的性能提高了76%。 |
| [^187] | [Cross-Prediction-Powered Inference.](http://arxiv.org/abs/2309.16598) | 本文介绍了一种基于机器学习的交叉预测方法，可以有效地进行推理。该方法通过使用一个小型标记数据集和一个大型未标记数据集，通过机器学习填补缺失的标签，并采用去偏差方法纠正预测的不准确性。 |
| [^188] | [Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation.](http://arxiv.org/abs/2309.13192) | 本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。 |
| [^189] | [Sparser Random Networks Exist: Enforcing Communication-Efficient Federated Learning via Regularization.](http://arxiv.org/abs/2309.10834) | 本论文提出了一种通过正则化方法增强通信效率的联合学习方法，该方法训练过参数化的随机网络，通过优化二进制掩码来减少通信开销，同时在本地目标中添加正则化项来促进稀疏网络的解决方案。实验证明，在通信和内存效率方面取得了显著的改进。 |
| [^190] | [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models.](http://arxiv.org/abs/2309.05605) | 本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。 |
| [^191] | [Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces.](http://arxiv.org/abs/2308.16089) | 本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。 |
| [^192] | [Improving Reinforcement Learning Training Regimes for Social Robot Navigation.](http://arxiv.org/abs/2308.14947) | 本研究提出了一种改进社交机器人导航的强化学习训练方法，通过使用课程学习，多样化环境和建模行人等技术，实现了更好的泛化性能。 |
| [^193] | [Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing.](http://arxiv.org/abs/2308.08705) | 本文研究了部分可观测随机博弈的可证明多Agent强化学习。通过信息共享和观测可能性假设，提出了构建近似模型以实现准效率的方法。 |
| [^194] | [CMISR: Circular Medical Image Super-Resolution.](http://arxiv.org/abs/2308.08567) | 这里是中文总结出的一句话要点：本文提出了一种循环医学图像超分辨率方法（CMISR），采用全局反馈的闭环框架，具有明确的欠分辨率和超分辨率元素。CMISR在稳态下具有零恢复误差，且可以应用于现有的MISR算法。 |
| [^195] | [Symphony: Optimized Model Serving using Centralized Orchestration.](http://arxiv.org/abs/2308.07470) | Symphony是一个集中式调度系统，可以优化深度神经网络模型服务，在满足高加速器效率和延迟SLO的同时适应工作负载变化。通过非工作保持调度算法和模型分配算法，Symphony能够实现高批处理效率和强大的自动缩放功能，比之前的系统提供高达4.7倍的吞吐量。 |
| [^196] | [Learning to Sample Tasks for Meta Learning.](http://arxiv.org/abs/2307.08924) | 通过实验得出了三个结论：没有通用的任务采样策略能保证元学习模型的性能；任务的多样性会导致模型在训练过程中出现欠拟合或过拟合的问题；模型的泛化性能受到任务的差异、任务熵和任务难度的影响。针对这些发现，提出了一种新颖的任务采样器ASr，它利用任务的差异、任务熵和任务难度来采样任务，并通过重新思考和提出一个简单而通用的元学习算法来优化ASr。大量实证实验表明了ASr的有效性。 |
| [^197] | [Inverse Optimization for Routing Problems.](http://arxiv.org/abs/2307.07357) | 本研究提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法，并在亚马逊末端路由研究挑战中测试了该方法，在复制人类驾驶员的路由偏好方面取得了第2名的成绩。 |
| [^198] | [Efficient Model-Free Exploration in Low-Rank MDPs.](http://arxiv.org/abs/2307.03997) | 提出了第一个计算高效、无模型的低秩MDPs探索算法，允许通用函数逼近，不需要额外的结构假设。 |
| [^199] | [Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives.](http://arxiv.org/abs/2307.02140) | 本文探讨了开放联邦学习平台的技术和法律观察，提出了基于查询和基于合同的两种适用于开放联邦学习的合作框架，并对构建开放的FL平台的可行性进行了全面评估。 |
| [^200] | [Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures.](http://arxiv.org/abs/2306.15012) | 本论文提出了一种用于从噪声混合物中恢复目标信号的统计分量分离方法，并且在图像降噪任务中展示了其优于标准降噪方法的表现。 |
| [^201] | [Differentially Private Synthetic Data via Foundation Model APIs 1: Images.](http://arxiv.org/abs/2305.15560) | 该论文提出了基于API的方法生成密切类似于原始私有数据的差分隐私（DP）合成数据，可以更轻松地部署。使用Private Evolution（PE）框架生成DP合成图像，结合了差分隐私、进化算法和元学习的技术，可以在保护隐私的同时生成既为DP又与原始图像外观相似的合成图像，并在流行的图像数据集上表现优异。 |
| [^202] | [Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation.](http://arxiv.org/abs/2305.10361) | 本文研究了语言游戏中的离线策略评估，并提出了一种结合真实和模拟数据的新方法。 |
| [^203] | [Multi-label Node Classification On Graph-Structured Data.](http://arxiv.org/abs/2304.10398) | 该论文提出了一种新的图神经网络架构 MLGCN，用于处理多标签节点分类任务，并研究了多标签场景中同类偏好的语义。在各种基准测试中，MLGCN优于现有的最先进的多标签分类方法。 |
| [^204] | [GDP nowcasting with artificial neural networks: How much does long-term memory matter?.](http://arxiv.org/abs/2304.05805) | 通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。 |
| [^205] | [Exact Characterization of the Convex Hulls of Reachable Sets.](http://arxiv.org/abs/2303.17674) | 本文精确地刻画了具有有界扰动的非线性系统的可达集的凸包为一阶常微分方程的解的凸包，提出了一种低成本、高精度的估计算法，可用于过逼近可达集。 |
| [^206] | [Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays.](http://arxiv.org/abs/2302.13991) | 通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。 |
| [^207] | [Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning.](http://arxiv.org/abs/2302.07457) | 通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。 |
| [^208] | [Federated contrastive learning models for prostate cancer diagnosis and Gleason grading.](http://arxiv.org/abs/2302.06089) | 该研究提出了一个面向大规模病理图像和异质性挑战的联邦对比学习模型（FCL），通过最大化本地客户端和服务器模型间的注意力一致性来增强模型的泛化能力。 在前列腺癌诊断和格里森分级任务中，FCL表现出优异的性能。 |
| [^209] | [Cooperative Open-ended Learning Framework for Zero-shot Coordination.](http://arxiv.org/abs/2302.04831) | 该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。 |
| [^210] | [Adaptive Federated Minimax Optimization with Lower complexities.](http://arxiv.org/abs/2211.07303) | 本文提出了一种自适应联邦式最小最大优化算法（AdaFGDA），用于解决分布式最小最大问题，在梯度和通信复杂性较低的情况下取得了良好的效果。 |
| [^211] | [Imputation of missing values in multi-view data.](http://arxiv.org/abs/2210.14484) | 本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。 |
| [^212] | [Invariant Aggregator for Defending against Federated Backdoor Attacks.](http://arxiv.org/abs/2210.01834) | 该论文针对联邦学习中的背后攻击提出了一种不变聚合器，防御背后攻击并保持模型的整体效用。研究发现在扁平损失空间中，恶意客户端可以通过提供背后样本来误导联邦学习模型，而不需要与良性客户端有明显的差异。 |

# 详细

[^1]: 连续时间POMDP的近似控制

    Approximate Control for Continuous-Time POMDPs

    [https://rss.arxiv.org/abs/2402.01431](https://rss.arxiv.org/abs/2402.01431)

    本文提出了一个适用于连续时间部分可观察系统的决策框架，通过近似方法实现了针对大规模状态空间的过滤和控制问题的可扩展解决方案。

    

    本文提出了一个针对具有离散状态和动作空间的连续时间部分可观察系统的决策框架。由于大规模状态空间的最优决策变得难以处理，我们采用了适用于具有不断增加的状态数量的过滤和控制问题的近似方法。具体而言，我们通过将高维过滤分布投影到参数分布族上来近似它，并将其整合到基于完全可观察系统的控制启发式中，以获得可扩展的策略。我们在几个部分观察系统上证明了我们方法的有效性，包括排队系统和化学反应网络。

    This work proposes a decision-making framework for partially observable systems in continuous time with discrete state and action spaces. As optimal decision-making becomes intractable for large state spaces we employ approximation methods for the filtering and the control problem that scale well with an increasing number of states. Specifically, we approximate the high-dimensional filtering distribution by projecting it onto a parametric family of distributions, and integrate it into a control heuristic based on the fully observable system to obtain a scalable policy. We demonstrate the effectiveness of our approach on several partially observed systems, including queueing systems and chemical reaction networks.
    
[^2]: 疫苗：针对大规模语言模型的干扰感知对齐技术

    Vaccine: Perturbation-aware Alignment for Large Language Model

    [https://rss.arxiv.org/abs/2402.01109](https://rss.arxiv.org/abs/2402.01109)

    疫苗是一种针对大规模语言模型的干扰感知对齐技术，通过逐渐添加扰动产生不变的隐藏嵌入，提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。

    

    作为一种新的微调即服务范 paradigm，大型语言模型 (LLM) 为用户上传的一小部分有害数据提供了新的攻击面，这些数据很容易欺骗微调过程从而产生对齐失效的模型。我们进行了实证分析，揭示了一种可能导致对齐失效的有害嵌入漂移现象。受到我们的发现启发，我们提出了疫苗 (Vaccine) ，一种针对干扰感知的对齐技术，以减轻用户微调的安全风险。疫苗的核心思想是通过在对齐阶段逐渐添加精心设计的扰动，产生不变的隐藏嵌入，从而使嵌入能够抵御来自未经消毒的用户数据的有害扰动。我们在开源主流LLM（如Llama2，Opt，Vicuna）上的实验结果表明，疫苗能够提高对抗有害提示引起的嵌入漂移的对齐鲁棒性，同时保留对良性提示的推理能力。

    The new paradigm of finetuning-as-a-service introduces a new attack surface for Large Language Models (LLMs): a few harmful data uploaded by users can easily trick the finetuning to produce an alignment-broken model. We conduct an empirical analysis and uncover a \textit{harmful embedding drift} phenomenon, showing a probable cause of the alignment-broken effect. Inspired by our findings, we propose Vaccine, a perturbation-aware alignment technique to mitigate the security risk of users finetuning. The core idea of Vaccine is to produce invariant hidden embeddings by progressively adding crafted perturbation to them in the alignment phase. This enables the embeddings to withstand harmful perturbation from un-sanitized user data in the finetuning phase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna) demonstrate that Vaccine can boost the robustness of alignment against harmful prompts induced embedding drift while reserving reasoning ability towards benign prompt
    
[^3]: 冒牌难题：代码语言模型能理解其不正确生成的微妙之处吗？

    The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?

    [https://arxiv.org/abs/2402.19475](https://arxiv.org/abs/2402.19475)

    大多数代码语言模型对生成的冒牌样本的理解较为肤浅，存在三种明显的失败模式：误将冒牌样本分类为正确、在推理冒牌样本的执行行为时表现更差、修复冒牌样本的成功率往往低于生成它们的成功率。

    

    尽管语言模型在代码生成方面变得越来越熟练，它们仍然经常生成不正确的程序。许多这些程序显然是错误的，但其他一些则更为微妙，可以通过更弱的正确性检查，例如能够编译。在这项工作中，我们关注这些伪造的样本：从语言模型中抽样得到的程序，这些程序1）在适度温度下生成的对数概率足够高，2）通过弱正确性检查。总体而言，我们发现大多数模型对伪造品的理解非常肤浅，存在三种明显的失败模式。首先，模型错误地将它们分类为正确。其次，模型在推理伪造品的执行行为方面更差，通常将它们的执行结果预测为如果它们是正确的一样。第三，在要求模型修复伪造品时，模型成功修复伪造品的可能性往往甚至低于抽样生成伪造品的可能性。

    arXiv:2402.19475v1 Announce Type: cross  Abstract: While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of samp
    
[^4]: 终身基准：在快速进展时代中高效的模型评估

    Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress

    [https://arxiv.org/abs/2402.19472](https://arxiv.org/abs/2402.19472)

    提出了终身基准的概念，通过创建不断扩展的大规模基准来减少过拟合风险，并引入了高效的评估框架Sort \& Search（S&S）来解决评估成本问题。

    

    标准化基准推动机器学习的进步。然而，通过重复测试，算法对基准的特殊性过度利用，会增加过拟合的风险。在我们的工作中，我们试图通过编制不断扩展的大规模基准（称为终身基准）来缓解这一挑战。作为我们方法的示例，我们创建了终身-CIFAR10和终身-ImageNet，分别包含（目前）1.69百万和1.98百万个测试样本。尽管减少了过拟合，终身基准引入了一个关键挑战：评估日益增多的模型在不断扩大的样本集上的高成本。为了解决这一挑战，我们还引入了一种高效的评估框架：Sort \& Search (S&S)，通过利用动态规划算法有选择地对测试样本进行排序和子选择，使得终身基准评估具有成本效益。通过对31,000个模型进行广泛的实证评估

    arXiv:2402.19472v1 Announce Type: new  Abstract: Standardized benchmarks drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking. Extensive empirical evaluations across 31,000 models 
    
[^5]: 人形机器人运动作为下一个标记预测

    Humanoid Locomotion as Next Token Prediction

    [https://arxiv.org/abs/2402.19469](https://arxiv.org/abs/2402.19469)

    该研究将人形控制问题转化为下一个标记预测问题，通过因果变压器训练实现传感器轨迹的自回归预测，可在缺失模态数据下训练，并成功使人形机器人完成步行任务。

    

    我们将现实世界的人形控制解释为一个下一个标记预测问题，类似于预测语言中的下一个单词。我们的模型是一个经过自回归预测传感器轨迹训练的因果变压器。为了考虑数据的多模态性质，我们以模态对齐的方式进行预测，对于每个输入标记，从相同的模态预测下一个标记。这种一般性显示使我们能够利用缺失模态的数据，例如没有动作的视频轨迹。我们在模拟轨迹集合上训练我们的模型，这些轨迹来自先前的神经网络策略、基于模型的控制器、动作捕捉数据和人类的YouTube视频。我们展示了我们的模型使一个全尺寸的人形机器人能够在旧金山行走，甚至没有受到器官。我们的模型可以在只有27小时行走数据的情况下转移到现实世界，并且可以推广到训练时没有看到的命令，比如向后走。

    arXiv:2402.19469v1 Announce Type: cross  Abstract: We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction of sensorimotor trajectories. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backwar
    
[^6]: 大语言模型的好奇驱动的红队对抗

    Curiosity-driven Red-teaming for Large Language Models

    [https://arxiv.org/abs/2402.19464](https://arxiv.org/abs/2402.19464)

    研究提出了一种新方法，能够通过训练红队LLM，自动化生成测试案例，以最大化引出目标LLM不良响应，以解决当前RL方法生成测试案例覆盖范围较低的问题。

    

    大型语言模型（LLMs）在许多自然语言应用中具有巨大潜力，但存在生成不正确或有毒内容的风险。为了探究LLM何时生成不需要的内容，当前的范例是招募一个人类测试者\textit{红队}来设计输入提示（即测试案例），这些提示可以引出LLMs的不良反应。然而，仅依赖人类测试者是昂贵且耗时的。近期的研究通过训练一个单独的采用强化学习（RL）的红队LLM自动化红队对抗，生成最大化引出目标LLMs不良响应的测试案例。然而，当前的RL方法只能生成少量有效的测试案例，导致对引出目标LLMs不良响应提示范围的覆盖率较低。为了克服这一限制，我们将增加生成测试案例覆盖范围的问题与.

    arXiv:2402.19464v1 Announce Type: cross  Abstract: Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases an
    
[^7]: 为标准化的任务专门指定不确定性量化：专门的不确定性用于专门的任务

    Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks

    [https://arxiv.org/abs/2402.19460](https://arxiv.org/abs/2402.19460)

    该论文评估了在ImageNet上的多种不确定性估计器，发现虽然有理论努力，但实践中尚未实现不确定性的解开，同时揭示了哪些估计器在特定任务上表现出色，为从业者提供见解并指导未来研究。

    

    不确定性量化，曾经是一个独立的任务，已经发展成为一个包含预测抑制、越界检测以及随机不确定性量化在内的任务谱系。最新的目标是解开不确定性：构建多个估计器，每个都专门定制于一个特定任务。因此，最近有大量不同意图的最新进展——这些往往完全偏离实际行为。本文在ImageNet上对多种不确定性估计器进行全面评估。我们发现，尽管有着颇有希望的理论努力，实践中仍未实现解开。此外，我们揭示了哪些不确定性估计器在哪些特定任务上表现出色，为从业者提供见解并引导未来研究朝着基于任务和解开的不确定性估计方法发展。我们的代码可在 https://github.com/bmucsanyi/bud 找到。

    arXiv:2402.19460v1 Announce Type: new  Abstract: Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at https://github.com/bmucsanyi/bud.
    
[^8]: 听噪声：使用Gibbs扩散进行盲去噪

    Listening to the Noise: Blind Denoising with Gibbs Diffusion

    [https://arxiv.org/abs/2402.19455](https://arxiv.org/abs/2402.19455)

    引入了Gibbs扩散（GDiff）方法，通过交替采样信号先验和噪声分布族，以及蒙特卡洛采样来推断噪声参数，解决了盲去噪中需要知道噪声水平和协方差的问题。

    

    近年来，去噪问题与深度生成模型的发展密不可分。特别是，扩散模型被训练成去噪器，它们所建模的分布与贝叶斯图像中的去噪先验相符。然而，通过基于扩散的后验采样进行去噪需要知道噪声水平和协方差，这阻碍了盲去噪。我们通过引入 Gibbs扩散（GDiff）克服了这一限制，这是一种通用方法论，可以处理信号和噪声参数的后验采样。假设任意参数化的高斯噪声，我们开发了一种Gibbs算法，交替地从条件扩散模型中进行采样，该模型经过训练将信号先验映射到噪声分布族，以及一个蒙特卡洛采样器来推断噪声参数。我们的理论分析突出了潜在的缺陷，指导了诊断的使用，并量化了Gibbs s中的错误。

    arXiv:2402.19455v1 Announce Type: cross  Abstract: In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, diffusion models are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through diffusion-based posterior sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs Diffusion (GDiff), a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs s
    
[^9]: Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models

    Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models

    [https://arxiv.org/abs/2402.19449](https://arxiv.org/abs/2402.19449)

    研究发现语言模型中的重尾类别不平衡问题导致了优化动态上的困难，Adam和基于符号的方法在这种情况下优于梯度下降。

    

    本文研究了在语言建模任务中存在的重尾类别不平衡问题，以及为什么Adam在优化大型语言模型时的表现优于梯度下降方法。我们发现，由于语言建模任务中存在的重尾类别不平衡，使用梯度下降时，与不常见单词相关的损失下降速度比与常见单词相关的损失下降速度慢。由于大多数样本来自相对不常见的单词，平均损失值在梯度下降时下降速度较慢。相比之下，Adam和基于符号的方法却不受此问题影响，并改善了所有类别的预测性能。我们在不同架构和数据类型上进行了实证研究，证明了这种行为确实是由类别不平衡引起的。

    arXiv:2402.19449v1 Announce Type: cross  Abstract: Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear clas
    
[^10]: ArCHer: 通过分层多轮强化学习训练语言模型代理

    ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL

    [https://arxiv.org/abs/2402.19446](https://arxiv.org/abs/2402.19446)

    本文提出了一个用于构建LLMs的多轮强化学习算法的框架

    

    大型语言模型（LLMs）的一个广泛应用案例是目标导向的决策任务（或“代理”任务），在这些任务中，LLM不仅需要为给定提示生成完成，而且需要在多轮交互中做出智能决策以完成任务（例如，与网络交互，使用工具或提供客户支持）。本文提出了一个用于构建LLMs的多轮强化学习算法的框架。

    arXiv:2402.19446v1 Announce Type: cross  Abstract: A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or "agent" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fin
    
[^11]: 多头softmax注意力机制在上下文学习中的训练动态：涌现、收敛和最优性

    Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality

    [https://arxiv.org/abs/2402.19442](https://arxiv.org/abs/2402.19442)

    研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。

    

    我们研究了用于上下文学习的多任务线性回归的多头softmax注意力模型的梯度流动力学。我们证明了在适当的初始化选择下，梯度流动的全局收敛性。此外，我们证明了在梯度流动动力学中出现了有趣的“任务分配”现象，每个注意力头都专注于解决多任务模型中的单个任务。具体而言，我们证明了梯度流动动力学可以分为三个阶段——热身阶段，在这个阶段损失减少速度较慢，注意力头逐渐倾向于各自的任务；涌现阶段，在这个阶段，每个头选择一个单独的任务，损失迅速减少；和收敛阶段，在这个阶段，注意力参数收敛到一个极限。此外，我们证明了梯度流在学习极限模型方面的最优性。

    arXiv:2402.19442v1 Announce Type: cross  Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flo
    
[^12]: 差分隐私下的最坏组风险最小化

    Differentially Private Worst-group Risk Minimization

    [https://arxiv.org/abs/2402.19437](https://arxiv.org/abs/2402.19437)

    该论文介绍了在差分隐私下进行最坏组风险最小化的系统研究，提出了一种新算法，通过稳定性分析实现了接近最优的风险控制效果。

    

    我们在$(\epsilon, \delta)$-差分隐私（DP）下对最坏组风险最小化进行了系统研究。目标是找到一个可以在$p$个具有不同分布的子人群（组）中近似最小化最大风险的私有模型，其中每个组的分布通过样本访问。我们首先提出了一种新算法，其实现的最坏组群体风险超出度为$\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} + \sqrt{\frac{p}{K}})$，其中$K$是从所有组中抽取的样本的总数，$d$是问题维度。当每个分布通过大小为$K/p$的固定大小数据集观察时，我们的速率几乎是最优的。我们的结果基于对泛化误差的新稳定性分析。特别是，我们表明$\Delta$-一致性参数稳定性意味着相对于最坏组风险的$\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$泛化误差，其中$n$是个数。

    arXiv:2402.19437v1 Announce Type: cross  Abstract: We initiate a systematic study of worst-group risk minimization under $(\epsilon, \delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} + \sqrt{\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\Delta$-uniform argument stability implies $\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number 
    
[^13]: Griffin: 将门控线性循环与局部注意力相结合，实现高效语言模型

    Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models

    [https://arxiv.org/abs/2402.19427](https://arxiv.org/abs/2402.19427)

    提出了 Griffin 模型，将门控线性循环与局部注意力相结合，实现高效的语言模型，该模型在推理过程中具有低延迟和高吞吐量。

    

    循环神经网络（RNNs）在长序列上具有快速推理和高效扩展的优势，但训练困难且难以扩展。本文提出了Hawk，一种具有门控线性循环的RNN，以及Griffin，一种混合模型，将门控线性循环与局部注意力相结合。Hawk在下游任务的表现超过了Mamba，而Griffin在训练时仅使用了6倍少的令牌数量却与Llama-2的表现相匹配。我们还展示了Griffin在训练期间可以对比训练时长得多的序列进行推断。我们的模型在训练时具有与Transformer相匹配的硬件效率，而在推理过程中具有更低的延迟和更高的吞吐量。我们将Griffin扩展到了14B参数，并解释了如何对我们的模型进行分片以实现高效的分布式训练。

    arXiv:2402.19427v1 Announce Type: cross  Abstract: Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.
    
[^14]: PaECTER：使用引文信息的专利级表示学习

    PaECTER: Patent-level Representation Learning using Citation-informed Transformers

    [https://arxiv.org/abs/2402.19411](https://arxiv.org/abs/2402.19411)

    PaECTER是一个专为专利设计的开放源码文档级编码器，利用引文信息对BERT进行微调，生成专利文档的数值表示，并在专利领域的相似性任务中表现优异。

    

    PaECTER是一个公开可用的、面向专利的文档级编码器，我们利用审核员添加的引文信息对BERT进行微调，为专利文档生成数值表示。与专利领域中当前最先进的模型相比，PaECTER在相似性任务中表现更好。具体来说，我们的模型在专利引文预测测试数据集上两种不同的排名评估指标上均优于下一个最佳专利特定的预训练语言模型（专利BERT）。与25个不相关的专利相比，PaECTER在平均排名1.32处预测到至少一个最相似的专利。PaECTER从专利文本生成的数值表示可用于分类、追踪知识流动或语义相似性搜索等下游任务。语义相似性搜索在发明人和专利的先前技术搜索背景中尤为重要。

    arXiv:2402.19411v1 Announce Type: cross  Abstract: PaECTER is a publicly available, open-source document-level encoder specific for patents. We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the next-best patent specific pre-trained language model (BERT for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and paten
    
[^15]: 一种可扩展且可迁移的时间序列预测框架用于需求预测

    A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting

    [https://arxiv.org/abs/2402.19402](https://arxiv.org/abs/2402.19402)

    提出了一种名为Forchestra的时间序列预测框架，能够准确预测各种物品的未来需求，并且在模型规模和泛化能力上均表现优异。

    

    时间序列预测是许多业务问题中最基本且最普遍的任务之一，包括需求预测和物流优化。然而，传统的时间序列预测方法由于在保持高准确性的同时难以扩展其模型大小，导致其模型规模较小且表现力有限。在本文中，我们提出了Forecasting orchestra (Forchestra)，这是一个简单但功能强大的框架，能够准确预测各种物品的未来需求。我们从经验上证明，模型规模可扩展至高达0.8亿个参数。所提出的方法不仅明显优于现有的预测模型，而且在零样本方式评估下游数据集时也能很好地泛化到未见数据点。最后，我们进行了广泛的定性和定量研究，以分析所提出的模型

    arXiv:2402.19402v1 Announce Type: cross  Abstract: Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model 
    
[^16]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^17]: 结构保持的扩散模型

    Structure Preserving Diffusion Models

    [https://arxiv.org/abs/2402.19369](https://arxiv.org/abs/2402.19369)

    提出了一种结构保持的扩散过程，可以学习具有群对称性等额外结构的分布，并开发了一系列对称等变扩散模型来实现这一点。

    

    近年来，扩散模型已成为主要的分布学习方法。在本文中，我们介绍了结构保持的扩散过程，这是一类用于学习具有额外结构（如群对称性）的分布的扩散过程，通过制定扩散转换步骤保持对称性的理论条件。除了实现等变数据采样轨迹外，我们通过开发一系列不同的对称等变扩散模型来说明这些结果，这些模型能够学习固有对称的分布。我们使用实证研究验证所开发的模型符合提出的理论，并在样本均等性方面能够胜过现有方法。我们还展示了如何利用提出的模型实现理论上保证的等变图像噪声。

    arXiv:2402.19369v1 Announce Type: new  Abstract: Diffusion models have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise r
    
[^18]: 大型语言模型中的水印窃取

    Watermark Stealing in Large Language Models

    [https://arxiv.org/abs/2402.19361](https://arxiv.org/abs/2402.19361)

    LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。

    

    LLM水印技术作为一种检测AI生成内容的有效方式，受到了关注。然而，我们在这项研究中争辩称当前方案可能已经可以部署，我们认为水印窃取（WS）是这些方案的一个根本性漏洞。我们展示了通过查询带有水印的LLM的API来近似逆向水印，从而实现实用的欺骗攻击，同时大幅增加了之前未被注意到的擦除攻击。我们是第一个提出自动WS算法并将其用于在现实环境中进行欺骗和擦除的全面研究。我们展示了仅需不到50美元的成本，攻击者就能够欺骗并擦除之前被认为是安全的最先进方案，平均成功率超过80%。我们的研究挑战了关于LLM水印技术的常见信念，强调了更加健壮方案的必要性。

    arXiv:2402.19361v1 Announce Type: cross  Abstract: LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We mak
    
[^19]: 揭示针对说话人识别的对抗样本--攻击检测和受害模型分类技术

    Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification

    [https://arxiv.org/abs/2402.19355](https://arxiv.org/abs/2402.19355)

    该论文提出了一种检测对抗性样本和识别受害模型的方法，通过扩展先前的攻击类型分类工作和引入新的架构，在攻击检测方面取得了很高的AUC，攻击分类准确率达到86.48%，受害模型分类准确率达到72.28%。

    

    对抗样本已经被证明对说话人识别系统构成威胁，并已经提出了一些针对它们的对策。本文提出了一种检测对抗样本存在的方法，即通过区分良性样本和对抗样本的二元分类器。我们在攻击类型分类的基础上进行扩展，探索新的架构。此外，我们介绍了一种用于识别进行对抗攻击的受害模型的方法。为了实现这一目标，我们生成了一个包含针对各种受害模型进行多次攻击的新数据集。我们在攻击检测方面实现了0.982的AUC，在未知攻击情况下性能下降不超过0.03。使用我们的LightResNet34架构，我们可以实现在八种攻击类型上达到86.48%的攻击分类准确率（除去良性样本），而我们的受害模型分类准确率达到72.28%。

    arXiv:2402.19355v1 Announce Type: cross  Abstract: Adversarial examples have proven to threaten speaker identification systems, and several countermeasures against them have been proposed. In this paper, we propose a method to detect the presence of adversarial examples, i.e., a binary classifier distinguishing between benign and adversarial examples. We build upon and extend previous work on attack type classification by exploring new architectures. Additionally, we introduce a method for identifying the victim model on which the adversarial attack is carried out. To achieve this, we generate a new dataset containing multiple attacks performed against various victim models. We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks. Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across
    
[^20]: 深度学习在城市计算中的跨域数据融合：分类、进展和展望

    Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook

    [https://arxiv.org/abs/2402.19348](https://arxiv.org/abs/2402.19348)

    这项调查系统地回顾了针对城市计算量身定制的深度学习数据融合方法的最新进展，将方法分为四大类别，并对不同数据来源和模态在跨领域数据融合中的作用进行了深入研究。

    

    随着城市的不断蓬勃发展，城市计算作为一门关键学科，通过利用来自各种来源（如地理、交通、社交媒体和环境数据）和模态（如时空、视觉和文本模态）的跨领域数据融合的力量，成为可持续发展的关键。最近，我们正在见证一种利用各种深度学习方法促进智慧城市中的跨领域数据融合的趋势。为此，我们提出了第一份系统地回顾了专门为城市计算量身定制的基于深度学习的数据融合方法的最新进展的调查。具体而言，我们首先深入研究数据视角，以理解每种模态和数据来源的作用。其次，我们将方法论分类为四大主要类别：基于特征、基于对齐、基于对比和基于生成的融合方法。第三，我们进一步对多模态城市应用进行分类。

    arXiv:2402.19348v1 Announce Type: cross  Abstract: As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applicatio
    
[^21]: 神经网络全局鲁棒性的验证

    Verification of Neural Networks' Global Robustness

    [https://arxiv.org/abs/2402.19322](https://arxiv.org/abs/2402.19322)

    提出了一种新的全局鲁棒性属性，旨在找到分类器的最小全局鲁棒边界，并引入了VHAGaR，一个用于计算此边界的验证器。

    

    神经网络在各种应用中取得了成功，但也容易受到对抗性攻击的影响。为了展示网络分类器的安全性，引入了许多验证器来推理给定输入对给定扰动的局部鲁棒性。尽管成功，局部鲁棒性不能推广到未见过的输入。一些工作分析全局鲁棒性属性，然而，它们都无法提供网络分类器在不改变分类的情况下的精确保证。在这项工作中，我们提出了一种针对分类器的新全局鲁棒性属性，旨在找到最小的全局稳健边界，其自然地扩展了用于分类器的流行的局部鲁棒性属性。我们引入了VHAGaR，一个用于计算此边界的可随时使用的验证器。VHAGaR依赖于三个主要思想：将问题编码为混合整数规划，并通过识别由于每个局部更改而产生的依赖关系来修剪搜索空间。

    arXiv:2402.19322v1 Announce Type: new  Abstract: Neural networks are successful in various applications but are also susceptible to adversarial attacks. To show the safety of network classifiers, many verifiers have been introduced to reason about the local robustness of a given input to a given perturbation. While successful, local robustness cannot generalize to unseen inputs. Several works analyze global robustness properties, however, neither can provide a precise guarantee about the cases where a network classifier does not change its classification. In this work, we propose a new global robustness property for classifiers aiming at finding the minimal globally robust bound, which naturally extends the popular local robustness property for classifiers. We introduce VHAGaR, an anytime verifier for computing this bound. VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the per
    
[^22]: 对5G网络中的移动性预测攻击

    Attacks Against Mobility Prediction in 5G Networks

    [https://arxiv.org/abs/2402.19319](https://arxiv.org/abs/2402.19319)

    本文揭示了针对5G网络中移动性预测的潜在攻击，展示了在具有1万名用户的场景中，对手能够显著降低预测准确性的实验结果。

    

    第5代移动网络引入了新的网络功能（NF），即网络数据分析功能（NWDAF），其主要目标是为网络内的各种实体和5G生态系统中的外部应用服务提供先进的分析服务。 NWDAF的一个关键用例是移动轨迹预测，旨在通过及时分配必要的网络资源来准确支持网络中用户设备（UE）的高效移动管理。本文展示了可能损害这些预测准确性的潜在移动性攻击。在一个半现实场景中，我们展示了在拥有1万名用户的情况下，一个具备劫持蜂窝移动设备并克隆它们能力的对手仅使用100个恶意

    arXiv:2402.19319v1 Announce Type: cross  Abstract: The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\% to 40\% using just 100 adve
    
[^23]: 无损机器遗忘

    Loss-Free Machine Unlearning

    [https://arxiv.org/abs/2402.19308](https://arxiv.org/abs/2402.19308)

    我们提出了一种无需重新训练和标记的机器遗忘方法，通过改进算法以在不需要标记数据的情况下近似灵敏度，实验结果表明我们的方法与现有最先进方法竞争力强。

    

    我们提出了一种无需重新训练和标记的机器遗忘方法。大多数现有的机器遗忘方法要求对模型进行微调以删除信息同时保持性能。这在计算上消耗巨大，并且需要存储整个数据集以供模型的整个生命周期使用。无需重新训练的方法通常利用来自损失函数的Fisher信息，但这需要标记数据，而这可能不容易获取。因此，我们提出了对选择性突触抑制算法的扩展，将Fisher信息矩阵的对角线替换为模型输出l2范数的梯度以近似灵敏度。我们在一系列使用ResNet18和Vision Transformer的实验证明了我们的方法与现有最先进方法的竞争性。

    arXiv:2402.19308v1 Announce Type: new  Abstract: We present a machine unlearning approach that is both retraining- and label-free. Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and Vision Transformer. Results show our label-free method is competitive with existing state-of-the-art approaches.
    
[^24]: 战略分类学习能力差距

    Learnability Gaps of Strategic Classification

    [https://arxiv.org/abs/2402.19303](https://arxiv.org/abs/2402.19303)

    任何可学习的类也可以战略学习，我们展示了在完全信息设置下的情况，学习者在训练期间可以访问到预处理的信息结构。

    

    与标准分类任务相反，战略分类涉及代理主动调整其特征以获得有利的预测。在一个决定贷款批准的分类器中，申请者可能会开启或关闭他们的信用卡以愚弄分类器。学习目标是找到一个对战略调整具有鲁棒性的分类器。战略分类中已经探讨了不同的设置，基于什么信息在何时可得知。在这项工作中，我们聚焦于解决一个基本问题：战略分类和标准学习之间的学习差距。

    arXiv:2402.19303v1 Announce Type: new  Abstract: In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning.   We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\star$) is known and during training time the learner has access to both the pre-man
    
[^25]: RL-GPT: 将强化学习和代码作为策略进行整合

    RL-GPT: Integrating Reinforcement Learning and Code-as-policy

    [https://arxiv.org/abs/2402.19299](https://arxiv.org/abs/2402.19299)

    RL-GPT 是一个两级分层框架，结合了慢速代理和快速代理，能够高效地整合强化学习和编码任务，在Minecraft游戏中表现出卓越效率。

    

    大型语言模型(LLMs)表现出在利用编码时各种工具方面的熟练程度，但在处理复杂逻辑和精确控制方面存在局限性。在具体任务中，高层规划适宜于直接编码，而低层动作通常需要任务特定的细化，比如强化学习（RL）。为了无缝整合这两种模式，我们引入了一个两级分层框架RL-GPT，包括一个慢速代理和一个快速代理。慢速代理分析适合编码的动作，而快速代理执行编码任务。这种分解有效地使每个代理专注于特定任务，在我们的流水线中证明是非常高效的。我们的方法胜过传统的RL方法和现有的GPT代理，表现出卓越的效率。在Minecraft游戏中，它在RTX3090上在一天内迅速获得了钻石。此外，它在所有设计方面实现了SOTA性能。

    arXiv:2402.19299v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all desig
    
[^26]: 基于人工智能的肿瘤免疫微环境数字评分可预测食管胃腺癌晚期免疫治疗维持益处

    An AI based Digital Score of Tumour-Immune Microenvironment Predicts Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric Adenocarcinoma

    [https://arxiv.org/abs/2402.19296](https://arxiv.org/abs/2402.19296)

    人工智能基于肿瘤免疫微环境数字评分成功预测食管胃腺癌患者对维持性免疫治疗的益处，具有临床前景。

    

    胃癌和食管癌是导致全球癌症死亡的主要原因。在食管癌中，最近的研究表明PDL1免疫检查点抑制剂（ICI）与化疗结合可以提高患者的存活率。然而，我们对食管癌的肿瘤免疫微环境的理解仍然有限。本研究从接受第一线氟蘇氨酸嘌呤和铂类化疗的平台试验（NCT02678182）中的食管胃腺癌（OGA）晚期患者的多重免疫荧光（mIF）图像入手，旨在预测该治疗的疗效并探索对维持性达伐单抗（PDL1抑制剂）有效的患者的生物学基础。我们提出的基于人工智能的标记成功地识别出了反应者和非反应者（p <0.05），以及那些可能从ICI中获益的患者（p <0.05)。

    arXiv:2402.19296v1 Announce Type: cross  Abstract: Gastric and oesophageal (OG) cancers are the leading causes of cancer mortality worldwide. In OG cancers, recent studies have showed that PDL1 immune checkpoint inhibitors (ICI) in combination with chemotherapy improves patient survival. However, our understanding of the tumour immune microenvironment in OG cancers remains limited. In this study, we interrogate multiplex immunofluorescence (mIF) images taken from patients with advanced Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict the efficacy of the treatment and to explore the biological basis of patients responding to maintenance durvalumab (PDL1 inhibitor). Our proposed Artificial Intelligence (AI) based marker successfully identified responder from non-responder (p < 0.05) as well as those who could potentially benefit from ICI with statistical significance (p < 0.05) fo
    
[^27]: 使用层级贝叶斯建模在海上风力涡轮结构中进行异常检测

    Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling

    [https://arxiv.org/abs/2402.19295](https://arxiv.org/abs/2402.19295)

    本研究探索了在海上风力涡轮结构使用层级贝叶斯模型进行异常检测的方法，以推断土壤刚度分布并实现冲刷的检测。

    

    人口结构健康监测（PBSHM）旨在在群体成员之间共享信息。一个海上风电场可以被视为一个名义上相同的风力涡轮结构的群体。然而，成员之间存在着良性变化，比如几何形状，海床条件和温差。这些因素可能影响结构特性，从而影响动态响应，使得通过传统SHM技术更难以检测结构问题。本文探讨了使用层级贝叶斯模型推断人口和本地水平预期土壤刚度分布的可能性，作为进行新旧涡轮结构异常检测（如冲刷）的基础。为了实现这一点，将生成类似于小型风力涡轮群体的自然频率的观测。个体观测之间的差异将通过假设引入。

    arXiv:2402.19295v1 Announce Type: new  Abstract: Population-based structural health monitoring (PBSHM), aims to share information between members of a population. An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures. However, benign variations exist among members, such as geometry, sea-bed conditions and temperature differences. These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques. This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform anomaly detection, in the form of scour, for new and existing turbines. To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines. Differences between individual observations will be introduced by postula
    
[^28]: 未知故障模式下的降解建模与预测分析

    Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes

    [https://arxiv.org/abs/2402.19294](https://arxiv.org/abs/2402.19294)

    提出了一种利用UMAP技术的新型故障模式诊断方法，能够有效应对复杂系统中多种故障模式导致的不同降解路径，提高故障模式的准确识别能力。

    

    操作单元经常在复杂系统中经历各种故障模式，导致不同的降解路径。依赖于在单一故障模式上训练的预测模型可能会导致跨多个故障模式的泛化性能较差。因此，准确识别故障模式至关重要。当前的预测方法要么在降解过程中忽略故障模式，要么假定已知的故障模式标签，而在实践中获得这些标签可能具有挑战性。此外，传感器信号的高维度和复杂关系使得准确识别故障模式具有挑战性。为解决这些问题，我们提出了一种新颖的故障模式诊断方法，利用一种名为UMAP（Uniform Manifold Approximation and Projection）的降维技术将每个单元的降解轨迹投影和可视化到较低维度。然后，利用这些降解轨迹，我们发展了

    arXiv:2402.19294v1 Announce Type: cross  Abstract: Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop 
    
[^29]: 二阶循环平稳信号估计和去卷积

    Estimation and Deconvolution of Second Order Cyclostationary Signals

    [https://arxiv.org/abs/2402.19290](https://arxiv.org/abs/2402.19290)

    该方法解决了盲去卷积和估计带噪声二阶循环平稳信号时间波形的双重问题，通过证明去卷积滤波器存在，消除信号的TF效应，实现高精度算法，有潜力改善机器学习模型的训练。

    

    这种方法解决了盲去卷积和估计通过传输函数(TF)传输到传感器的带噪声二阶循环平稳(CS2)信号的时间波形的双重问题。我们已经证明，去卷积滤波器存在并消除了统计特性随时间变化的信号上的TF效应。这种方法是盲目的，即不需要关于信号或TF的先前知识。模拟表明，算法在各种信号类型、TF和信噪比(SNR)下具有高精度。在本研究中，CS2信号族被限制为确定性周期函数和白噪声的乘积。此外，这种方法有潜力改善机器学习模型的训练，其中需要聚合来自相同系统但具有不同TF的信号。

    arXiv:2402.19290v1 Announce Type: new  Abstract: This method solves the dual problem of blind deconvolution and estimation of the time waveform of noisy second-order cyclo-stationary (CS2) signals that traverse a Transfer Function (TF) en route to a sensor. We have proven that the deconvolution filter exists and eliminates the TF effect from signals whose statistics vary over time. This method is blind, meaning it does not require prior knowledge about the signals or TF. Simulations demonstrate the algorithm high precision across various signal types, TFs, and Signal-to-Noise Ratios (SNRs). In this study, the CS2 signals family is restricted to the product of a deterministic periodic function and white noise. Furthermore, this method has the potential to improve the training of Machine Learning models where the aggregation of signals from identical systems but with different TFs is required.
    
[^30]: StiefelGen: 一种简单的，与模型无关的通过黎曼流形进行时间序列数据增强的方法

    StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds

    [https://arxiv.org/abs/2402.19287](https://arxiv.org/abs/2402.19287)

    StiefelGen 提出了一种简单的、与模型无关的方法，可以在黎曼流形上进行时间序列数据增强，填补了现有方法尚未解决的问题。

    

    数据增强是一个研究领域，在许多机器学习领域中都得到了积极的发展，比如基于图像的学习模型、用于自动驾驶车辆的强化学习以及对点云数据进行通用的噪声注入。然而，对于一般的时间序列数据增强，仍然有很多问题有待解决，尤其是因为为这些模型开发的方法并不容易跨越。关于时间序列数据增强的三种常见方法包括：(i) 构建基于物理的模型，然后在系数空间中赋予不确定性（例如），(ii) 向观察到的数据集添加噪声，以及(iii) 从中可以训练出稳健生成神经网络模型的大量时间序列数据集。然而，对于在工业中处理时间序列数据的许多实际问题：(i) 通常并没有一个稳健的物理模型可供使用，(ii)...

    arXiv:2402.19287v1 Announce Type: new  Abstract: Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data. However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained. However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) Th
    
[^31]: 基于密集强化学习的互联与自动驾驶车辆自适应测试环境生成

    Adaptive Testing Environment Generation for Connected and Automated Vehicles with Dense Reinforcement Learning

    [https://arxiv.org/abs/2402.19275](https://arxiv.org/abs/2402.19275)

    通过密集强化学习，开发了一个自适应测试环境，包含多个代理模型并优化其组合系数，增强了评估的鲁棒性，提高了评估效率。

    

    安全性能评估在互联和自动驾驶车辆（CAVs）的发展和部署中起着至关重要的作用。一种常见的方法涉及基于对CAVs的先前知识（如代理模型）设计测试场景， 在这些场景中进行测试，然后评估CAVs的安全性能。然而，CAVs和先前知识之间存在实质性差异可能会显著降低评估效率。为了应对这一问题，现有研究主要集中在CAV测试过程中测试场景的自适应设计上。然而，这些方法在高维场景中的适用性存在限制。为了克服这一挑战，我们开发了一个自适应测试环境，通过结合多个代理模型并优化这些代理模型的组合系数来增强评估的鲁棒性，从而提高评估效率。

    arXiv:2402.19275v1 Announce Type: cross  Abstract: The assessment of safety performance plays a pivotal role in the development and deployment of connected and automated vehicles (CAVs). A common approach involves designing testing scenarios based on prior knowledge of CAVs (e.g., surrogate models), conducting tests in these scenarios, and subsequently evaluating CAVs' safety performances. However, substantial differences between CAVs and the prior knowledge can significantly diminish the evaluation efficiency. In response to this issue, existing studies predominantly concentrate on the adaptive design of testing scenarios during the CAV testing process. Yet, these methods have limitations in their applicability to high-dimensional scenarios. To overcome this challenge, we develop an adaptive testing environment that bolsters evaluation robustness by incorporating multiple surrogate models and optimizing the combination coefficients of these surrogate models to enhance evaluation effic
    
[^32]: 在POMDPs中学习逻辑规范以指导政策：归纳逻辑编程方法

    Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach

    [https://arxiv.org/abs/2402.19265](https://arxiv.org/abs/2402.19265)

    通过归纳逻辑编程方法，从POMDP执行痕迹中学习高质量启发式，以指导政策选择过程。

    

    部分可观察马尔可夫决策过程（POMDPs）是一个强大的不确定性规划框架，允许将状态不确定性建模为信念概率分布。基于蒙特卡洛采样的近似求解器显示出很大成功，以放宽计算需求并执行在线规划。然而，扩展到具有许多动作和长期规划视野的复杂现实域仍然是一个重大挑战，实现良好性能的关键点是通过定制特定应用域的领域相关策略启发来引导行动选择过程。我们提出从由任何求解器生成的POMDP执行痕迹中学习高质量启发式。我们将信念-动作对转换为逻辑语义，并利用数据和时间高效的归纳逻辑编程（ILP）生成可解释的基于信念的策略规范，然后将其用作在线启发式。

    arXiv:2402.19265v1 Announce Type: new  Abstract: Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristi
    
[^33]: 口罩、标志和学习率回溯

    Masks, Signs, And Learning Rate Rewinding

    [https://arxiv.org/abs/2402.19262](https://arxiv.org/abs/2402.19262)

    学习率回溯（LRR）通过早期翻转参数符号且对符号扰动保持稳健性的能力，不仅在掩模识别方面更有效，而且可以优化各种掩模，包括随机掩模。

    

    学习率回溯（LRR）已被确定为深度超参数化神经网络中寻找“中奖券”的迭代幅度剪枝（IMP）的强变体。虽然两种迭代剪枝方案都将结构和参数学习耦合在一起，但理解LRR在两个方面的优势如何可以使我们更接近设计更灵活的深度学习算法，从而可以优化各种稀疏架构。为此，我们进行了实验，解开了掩模学习和参数优化的效果以及两者如何从超参数化中受益的方式。LRR早期翻转参数符号并保持对符号扰动的稳健性的能力似乎使其在不仅在掩模识别方面更加有效，而且在优化各种掩模，包括随机掩模方面也更加有效。支持这一假设，我们在简化的单个隐藏神经元设置中证明LRR成功的情况比IMP更多，因为它可以摆脱

    arXiv:2402.19262v1 Announce Type: new  Abstract: Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape i
    
[^34]: 用于模乘的机器学习

    Machine learning for modular multiplication

    [https://arxiv.org/abs/2402.19254](https://arxiv.org/abs/2402.19254)

    证明了模乘任务的困难性，为基于加密系统的任务提供了机器学习方法的研究证据

    

    受到密码应用的启发，我们研究了两种机器学习方法来进行模乘：循环回归和序列到序列变换器模型。我们结果中展示的这两种方法的有限成功证明了与基于加密系统的模乘相关的任务的困难性。

    arXiv:2402.19254v1 Announce Type: new  Abstract: Motivated by cryptographic applications, we investigate two machine learning approaches to modular multiplication: namely circular regression and a sequence-to-sequence transformer model. The limited success of both methods demonstrated in our results gives evidence for the hardness of tasks involving modular multiplication upon which cryptosystems are based.
    
[^35]: 深度导数增强的操作网络

    Derivative-enhanced Deep Operator Network

    [https://arxiv.org/abs/2402.19242](https://arxiv.org/abs/2402.19242)

    DE-DeepONet通过整合导数信息提高了预测准确性，尤其在训练数据有限的情况下，相比传统DeepONet取得了更好的效果。

    

    深度操作网络（DeepONets）是一类学习函数空间之间映射的神经算子，最近被开发为参数化偏微分方程（PDEs）的代理模型。本文提出了一种导数增强的深度操作网络（DE-DeepONet），它利用导数信息增强预测准确性，提供更准确的导数近似，特别是在训练数据有限的情况下。DE-DeepONet将输入的维度缩减到DeepONet中，并在训练的损失函数中包含两种类型的导数标签，即关于输入函数的输出函数的方向导数和关于物理域变量的输出函数的梯度。我们通过在三个不断增加复杂度的方程上测试DE-DeepONet，以展示其相对于普通DeepONet的有效性。

    arXiv:2402.19242v1 Announce Type: new  Abstract: Deep operator networks (DeepONets), a class of neural operators that learn mappings between function spaces, have recently been developed as surrogate models for parametric partial differential equations (PDEs). In this work we propose a derivative-enhanced deep operator network (DE-DeepONet), which leverages the derivative information to enhance the prediction accuracy, and provide a more accurate approximation of the derivatives, especially when the training data are limited. DE-DeepONet incorporates dimension reduction of input into DeepONet and includes two types of derivative labels in the loss function for training, that is, the directional derivatives of the output function with respect to the input function and the gradient of the output function with respect to the physical domain variables. We test DE-DeepONet on three different equations with increasing complexity to demonstrate its effectiveness compared to the vanilla DeepON
    
[^36]: 训练的随机森林完全揭示您的数据集

    Trained Random Forests Completely Reveal your Dataset

    [https://arxiv.org/abs/2402.19232](https://arxiv.org/abs/2402.19232)

    随机森林训练中没有采用自举聚合但具有特征随机化的模型容易被完全重建，即使采用自举聚合，大部分数据也可以被重建。

    

    我们介绍了一种基于优化的重建攻击，能够完全或几乎完全重建用于训练随机森林的数据集。值得注意的是，我们的方法仅依赖于常用库（如scikit-learn）中随处可得的信息。为了实现这一点，我们将重建问题构建为一个组合问题，目标是最大似然。我们证明这个问题是NP难问题，但可以利用约束编程在规模上解决 —— 这是一种基于约束传播和解域缩减的方法。通过广泛的计算研究，我们证明没有采用自举聚合但具有特征随机化的随机森林容易被完全重建。即使使用少量树，这仍然成立。即使通过自举聚合，大部分数据也可以被重建。这些发现强调了一种关键。

    arXiv:2402.19232v1 Announce Type: new  Abstract: We introduce an optimization-based reconstruction attack capable of completely or near-completely reconstructing a dataset utilized for training a random forest. Notably, our approach relies solely on information readily available in commonly used libraries such as scikit-learn. To achieve this, we formulate the reconstruction problem as a combinatorial problem under a maximum likelihood objective. We demonstrate that this problem is NP-hard, though solvable at scale using constraint programming -- an approach rooted in constraint propagation and solution-domain reduction. Through an extensive computational investigation, we demonstrate that random forests trained without bootstrap aggregation but with feature randomization are susceptible to a complete reconstruction. This holds true even with a small number of trees. Even with bootstrap aggregation, the majority of the data can also be reconstructed. These findings underscore a critica
    
[^37]: 探究机器学习驱动的慢性疼痛个性化护理中的性别公平性

    Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain

    [https://arxiv.org/abs/2402.19226](https://arxiv.org/abs/2402.19226)

    该研究通过机器学习算法调查了个性化疼痛护理推荐中的性别公平性，发现在某些患者信息缺失时，女性的疼痛护理推荐质量明显低于男性。

    

    本研究利用机器学习算法调查了个性化疼痛护理推荐中的性别公平性。利用上下文臂框架，使用LinUCB算法对包含164位患者在每个10次会话中的互动数据集进行了个性化推荐的制定和评估。结果表明，尽管对算法参数进行调整会影响疼痛护理推荐的质量，但这种影响在不同性别间保持一致。然而，当某些患者信息，如自我报告的疼痛测量值，缺失时，女性的疼痛护理推荐质量明显低于男性。

    arXiv:2402.19226v1 Announce Type: new  Abstract: This study investigates gender fairness in personalized pain care recommendations using machine learning algorithms. Leveraging a contextual bandits framework, personalized recommendations are formulated and evaluated using LinUCB algorithm on a dataset comprising interactions with $164$ patients across $10$ sessions each. Results indicate that while adjustments to algorithm parameters influence the quality of pain care recommendations, this impact remains consistent across genders. However, when certain patient information, such as self-reported pain measurements, is absent, the quality of pain care recommendations for women is notably inferior to that for men.
    
[^38]: 深度强化学习：一个凸优化方法

    Deep Reinforcement Learning: A Convex Optimization Approach

    [https://arxiv.org/abs/2402.19212](https://arxiv.org/abs/2402.19212)

    本文提出了一种深度强化学习的凸优化方法，通过每集使用凸优化来训练神经网络近似最优$Q$-函数，确保收敛参数可以无限接近最优参数。

    

    在本文中，我们考虑了具有连续状态和动作空间的非线性系统的强化学习。我们提出了一种分集学习算法，其中我们在每个集中使用凸优化来找到最优$Q$-函数的两层神经网络近似。凸优化方法确保每个集合中计算的权重是最优的，关于当前集合的采样状态和动作。对于稳定的非线性系统，我们证明了算法收敛，并且经过训练的神经网络的收敛参数可以与最优神经网络参数无限接近。特别是，如果正则化参数为$\rho$，时间长度为$T$，那么经过训练的神经网络的参数收敛到$w$，其中$w$与最优参数$w^\star$之间的距离受到$\mathcal{O}(\rho T^{-1})$的限制。

    arXiv:2402.19212v1 Announce Type: cross  Abstract: In this paper, we consider reinforcement learning of nonlinear systems with continuous state and action spaces. We present an episodic learning algorithm, where we for each episode use convex optimization to find a two-layer neural network approximation of the optimal $Q$-function. The convex optimization approach guarantees that the weights calculated at each episode are optimal, with respect to the given sampled states and actions of the current episode. For stable nonlinear systems, we show that the algorithm converges and that the converging parameters of the trained neural network can be made arbitrarily close to the optimal neural network parameters. In particular, if the regularization parameter is $\rho$ and the time horizon is $T$, then the parameters of the trained neural network converge to $w$, where the distance between $w$ from the optimal parameters $w^\star$ is bounded by $\mathcal{O}(\rho T^{-1})$. That is, when the nu
    
[^39]: 细结构感知采样: 一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案

    Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction

    [https://arxiv.org/abs/2402.19197](https://arxiv.org/abs/2402.19197)

    FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。

    

    像素对齐的隐式模型，如PIFu、PIFuHD和ICON，用于单视图着装人体重建。这些模型需要使用采样训练方案进行训练。现有的采样训练方案要么无法捕捉薄表面（如耳朵、手指），要么会导致重建网格中的噪声伪影。为解决这些问题，我们引入了细结构感知采样（FSS），这是一种新的用于单视图人体重建中训练像素对齐隐式模型的采样训练方案。FSS通过主动适应表面的厚度和复杂性来解决前述问题。此外，与现有的采样训练方案不同，FSS显示了如何利用样本点的法线在训练过程中提高结果。最后，为进一步改进训练过程，FSS提出了一个用于像素对齐隐式模型的网格厚度损失信号。这使得在训练过程中利用法线变得计算上可行。

    arXiv:2402.19197v1 Announce Type: cross  Abstract: Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to int
    
[^40]: 用生成模型解开视网膜图像的表征

    Disentangling representations of retinal images with generative models

    [https://arxiv.org/abs/2402.19186](https://arxiv.org/abs/2402.19186)

    引入一种新颖的视网膜底图像群体模型，有效解开患者属性与相机效果，实现可控且高度逼真的图像生成。

    

    视网膜底图像在早期检测眼部疾病中起着至关重要的作用，最近的研究甚至表明，利用深度学习方法，这些图像还可以用于检测心血管风险因素和神经系统疾病。然而，这些图像受技术因素的影响可能对眼科领域可靠的人工智能应用构成挑战。例如，大型底图队列往往受到相机类型、图像质量或照明水平等因素的影响，存在学习快捷方式而不是图像生成过程背后因果关系的风险。在这里，我们提出了一个新颖的视网膜底图像群体模型，有效地解开了患者属性与相机效果，从而实现了可控且高度逼真的图像生成。为了实现这一目标，我们提出了一个基于距离相关性的新颖解开损失。通过定性和定量分析，我们展示了...

    arXiv:2402.19186v1 Announce Type: cross  Abstract: Retinal fundus images play a crucial role in the early detection of eye diseases and, using deep learning approaches, recent studies have even demonstrated their potential for detecting cardiovascular risk factors and neurological disorders. However, the impact of technical factors on these images can pose challenges for reliable AI applications in ophthalmology. For example, large fundus cohorts are often confounded by factors like camera type, image quality or illumination level, bearing the risk of learning shortcuts rather than the causal relationships behind the image generation process. Here, we introduce a novel population model for retinal fundus images that effectively disentangles patient attributes from camera effects, thus enabling controllable and highly realistic image generation. To achieve this, we propose a novel disentanglement loss based on distance correlation. Through qualitative and quantitative analyses, we demon
    
[^41]: FedStruct：联合解耦学习在互联图上

    FedStruct: Federated Decoupled Learning over Interconnected Graphs

    [https://arxiv.org/abs/2402.19163](https://arxiv.org/abs/2402.19163)

    FedStruct提出了一种新的框架，利用深层结构依赖关系在互联图上进行联合解耦学习，有效地维护隐私并捕捉节点间的依赖关系。

    

    我们解决了分布在多个客户端上的图结构数据上的联合学习挑战。具体来说，我们关注互联子图的普遍情况，其中不同客户端之间的相互连接起着关键作用。我们提出了针对这种情况的一种新颖框架，名为FedStruct，它利用深层结构依赖关系。为了维护隐私，与现有方法不同，FedStruct消除了在客户端之间共享或生成敏感节点特征或嵌入的必要性。相反，它利用显式全局图结构信息来捕捉节点间的依赖关系。我们通过在六个数据集上进行的实验结果验证了FedStruct的有效性，展示了在各种情况下（包括不同数据分区方法、不同标签可用性以及客户个数的）接近于集中式方法的性能。

    arXiv:2402.19163v1 Announce Type: new  Abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where inter-connections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of cl
    
[^42]: 超越语言模型：字节模型是数字世界的模拟器

    Beyond Language Models: Byte Models are Digital World Simulators

    [https://arxiv.org/abs/2402.19155](https://arxiv.org/abs/2402.19155)

    bGPT模型利用next byte prediction成功模拟并预测数字世界的各种操作，表现出色，包括在音乐数据转换和CPU行为模拟方面取得了显著进展。

    

    传统的深度学习常常忽略字节，即数字世界的基本单位，所有形式的信息和操作都是以二进制格式编码和操作的。受自然语言处理中下一个标记预测成功的启发，我们引入了bGPT，一个具有下一个字节预测的模型，用于模拟数字世界。bGPT在各种模态（包括文本、音频和图像）上的性能与专业模型相匹配，并为预测、模拟和诊断算法或硬件行为提供了新的可能性。它几乎完美地复制了将符号音乐数据转换的过程，在将ABC记号转换为MIDI格式时，错误率仅为0.0011比特每字节。此外，bGPT在模拟CPU行为方面表现出色，执行各种操作的准确性超过99.99%。利用下一个字节预测，像bGPT这样的模型可以直接l

    arXiv:2402.19155v1 Announce Type: new  Abstract: Traditional deep learning often overlooks bytes, the basic units of the digital world, where all forms of information and operations are encoded and manipulated in binary format. Inspired by the success of next token prediction in natural language processing, we introduce bGPT, a model with next byte prediction to simulate the digital world. bGPT matches specialized models in performance across various modalities, including text, audio, and images, and offers new possibilities for predicting, simulating, and diagnosing algorithm or hardware behaviour. It has almost flawlessly replicated the process of converting symbolic music data, achieving a low error rate of 0.0011 bits per byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates exceptional capabilities in simulating CPU behaviour, with an accuracy exceeding 99.99% in executing various operations. Leveraging next byte prediction, models like bGPT can directly l
    
[^43]: ProtoP-OD: 具有典型部分的可解释目标检测

    ProtoP-OD: Explainable Object Detection with Prototypical Parts

    [https://arxiv.org/abs/2402.19142](https://arxiv.org/abs/2402.19142)

    提出了ProtoP-OD，介绍了一种用于目标检测的可解释性扩展，通过构建典型的局部特征，提高模型对图像内容的可解释性和可靠性。

    

    理解和可视化检测变型器的行为往往会突出模型关注的图像位置，但对模型关注的\emph{语义}提供有限的见解。本文介绍了一种扩展检测变压器，它构建典型的局部特征并在目标检测中使用这些特征。我们称之为典型部分的这些自定义特征旨在彼此互斥并与模型的分类一致。所提出的扩展包括一个瓶颈模块，原型颈，它计算原型激活的离散表示，并一个新的损失项，它将原型与对象类匹配。这一设置导致了原型颈中的可解释表示，允许对模型感知的图像内容进行视觉检查，并更好地理解模型的可靠性。我们通过实验证明

    arXiv:2402.19142v1 Announce Type: cross  Abstract: Interpretation and visualization of the behavior of detection transformers tends to highlight the locations in the image that the model attends to, but it provides limited insight into the \emph{semantics} that the model is focusing on. This paper introduces an extension to detection transformers that constructs prototypical local features and uses them in object detection. These custom features, which we call prototypical parts, are designed to be mutually exclusive and align with the classifications of the model. The proposed extension consists of a bottleneck module, the prototype neck, that computes a discretized representation of prototype activations and a new loss term that matches prototypes to object classes. This setup leads to interpretable representations in the prototype neck, allowing visual inspection of the image content perceived by the model and a better understanding of the model's reliability. We show experimentally
    
[^44]: 能源存储出价中的时序感知深度强化学习在能源和备用服务市场中的应用

    Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in Energy and Contingency Reserve Markets

    [https://arxiv.org/abs/2402.19110](https://arxiv.org/abs/2402.19110)

    提出了一种利用深度强化学习在现货市场和容灾频率控制辅助服务市场进行出价的新颖BESS联合竞标策略，通过时序特征提取器有效响应多个市场的价格波动，发展出更具解释性的DRL模型。

    

    电池能量存储系统（BESS）通过参与电力市场极大地提高了电网的可靠性和安全性。BESS常常通过参与多个市场来寻求各种收入来源，以发挥其全部潜力，但关于在价格不确定性下联合参与市场的有效算法在现有研究中尚未得到充分探讨。为了弥补这一不足，我们开发了一种利用深度强化学习（DRL）在现货市场和容灾频率控制辅助服务（FCAS）市场出价的新颖BESS联合竞标策略。我们的方法利用基于transformer的时序特征提取器来有效应对七个市场同时的价格波动，并帮助DRL学习最佳的BESS出价策略。此外，与传统的“黑匣子”DRL模型不同，我们的方法更具可解释性，并提供有价值的i

    arXiv:2402.19110v1 Announce Type: cross  Abstract: The battery energy storage system (BESS) has immense potential for enhancing grid reliability and security through its participation in the electricity market. BESS often seeks various revenue streams by taking part in multiple markets to unlock its full potential, but effective algorithms for joint-market participation under price uncertainties are insufficiently explored in the existing research. To bridge this gap, we develop a novel BESS joint bidding strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and contingency frequency control ancillary services (FCAS) markets. Our approach leverages a transformer-based temporal feature extractor to effectively respond to price fluctuations in seven markets simultaneously and helps DRL learn the best BESS bidding strategy in joint-market participation. Additionally, unlike conventional "black-box" DRL model, our approach is more interpretable and provides valuable i
    
[^45]: CollaFuse：在协作生成人工智能中导航有限资源和隐私

    CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI

    [https://arxiv.org/abs/2402.19105](https://arxiv.org/abs/2402.19105)

    CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。

    

    在生成人工智能领域，扩散式模型在数据需求和隐私方面给社会技术系统带来挑战。传统方法如联邦学习分发学习过程，但会给个别客户带来压力，尤其是在资源受限情况下（例如边缘设备）。为了解决这些挑战，我们引入了CollaFuse，这是一个受拆分学习启发的新框架。为了有效协作使用去噪扩散概率模型，CollaFuse实现了共享服务器训练和推理，减轻了客户端的计算负担。这通过在每个客户端本地保留数据和计算成本低廉的GPU进程，同时将计算成本高昂的进程外包给共享服务器来实现。在医疗环境中展示，CollaFuse通过大大减少对敏感信息共享的需求来增强隐私保护能力。

    arXiv:2402.19105v1 Announce Type: cross  Abstract: In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabiliti
    
[^46]: FlatNAS：优化神经结构搜索中的平坦性以实现对分布之外的鲁棒性

    FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness

    [https://arxiv.org/abs/2402.19102](https://arxiv.org/abs/2402.19102)

    FlatNAS是文献中首个系统探索神经网络丢失函数平坦区域的NAS方法，同时优化其在分布数据和分布之外鲁棒性的性能，以及约束其架构参数数量。

    

    神经结构搜索（NAS）为神经网络（NN）架构的自动定义铺平了道路，在各种场景中引起越来越多的研究关注并提供解决方案。本研究介绍了一种名为Flat Neural Architecture Search（FlatNAS）的新颖NAS解决方案，它探讨了基于对权重扰动的鲁棒性和具有锐度感知最小化（SAM）的单一NN优化的相互关系。与当前主要集中于OOD算法的研究不同，FlatNAS成功地评估了NN架构对OOD鲁棒性的影响，这是一个关键方面。

    arXiv:2402.19102v1 Announce Type: cross  Abstract: Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their out-of-distribution (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect
    
[^47]: 有效的两阶段跨实体跨域推荐知识传输

    Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain Recommendation

    [https://arxiv.org/abs/2402.19101](https://arxiv.org/abs/2402.19101)

    该研究提出了一种有效的两阶段跨实体跨域推荐知识传输方法，解决了多实体推荐中源实体数据分布不同和特征模式不对齐等重要问题。

    

    近年来，电子商务平台上的推荐内容变得越来越丰富 -- 单个用户反馈可能包含多个实体，如销售产品、短视频和内容帖子。为了解决多实体推荐问题，一个直观的解决方案是采用基于共享网络的架构进行联合训练。这一想法是将一个类型实体（源实体）中提取的知识传输到另一个类型实体（目标实体）中。

    arXiv:2402.19101v1 Announce Type: cross  Abstract: In recent years, the recommendation content on e-commerce platforms has become increasingly rich -- a single user feed may contain multiple entities, such as selling products, short videos, and content posts. To deal with the multi-entity recommendation problem, an intuitive solution is to adopt the shared-network-based architecture for joint training. The idea is to transfer the extracted knowledge from one type of entity (source entity) to another (target entity). However, different from the conventional same-entity cross-domain recommendation, multi-entity knowledge transfer encounters several important issues: (1) data distributions of the source entity and target entity are naturally different, making the shared-network-based joint training susceptible to the negative transfer issue, (2) more importantly, the corresponding feature schema of each entity is not exactly aligned (e.g., price is an essential feature for selling product
    
[^48]: 一种利用Transformer和CNN集成的蛋白质结构预测方法

    A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration

    [https://arxiv.org/abs/2402.19095](https://arxiv.org/abs/2402.19095)

    本研究提出了一种利用Transformer和CNN集成的蛋白质结构预测方法，通过二维融合深度神经网络模型DstruCCN，有助于提升蛋白质二级结构预测的准确性和效率。

    

    蛋白质对于生命至关重要，其结构决定其功能。蛋白的二级结构是由蛋白质的一级结构折叠形成的，而蛋白的三级结构是由二级结构的弯曲和折叠形成的。因此，研究蛋白的二级结构对于整体理解蛋白质结构非常有帮助。虽然随着机器学习和深度学习的发展，蛋白质二级结构预测的准确性不断提高，但不幸的是，蛋白结构预测领域的进展仍然不足以满足对蛋白质信息的大量需求。因此，基于深度学习方法在特征提取和学习能力方面的优势，本文采用了一个二维融合深度神经网络模型DstruCCN，该模型使用了卷积神经网络(CNN)和一个监督Transformer。

    arXiv:2402.19095v1 Announce Type: cross  Abstract: Proteins are essential for life, and their structure determines their function. The protein secondary structure is formed by the folding of the protein primary structure, and the protein tertiary structure is formed by the bending and folding of the secondary structure. Therefore, the study of protein secondary structure is very helpful to the overall understanding of protein structure. Although the accuracy of protein secondary structure prediction has continuously improved with the development of machine learning and deep learning, progress in the field of protein structure prediction, unfortunately, remains insufficient to meet the large demand for protein information. Therefore, based on the advantages of deep learning-based methods in feature extraction and learning ability, this paper adopts a two-dimensional fusion deep neural network model, DstruCCN, which uses Convolutional Neural Networks (CCN) and a supervised Transformer pr
    
[^49]: 具有资源约束的最佳臂识别

    Best Arm Identification with Resource Constraints

    [https://arxiv.org/abs/2402.19090](https://arxiv.org/abs/2402.19090)

    该论文研究了具有资源约束的最佳臂识别问题，提出了连续减半算法（SH-RR），在非渐近情况下以接近最优速度成功识别最佳臂，并发现了确定性和随机资源消耗情况下的收敛速度差异。

    

    受到不同替代方案实验成本异质性的启发，我们研究了具有资源约束的最佳臂识别（BAIwRC）问题。代理商旨在在资源约束下识别最佳臂，其中资源被每次拉动手臂消耗。我们做出了两个新的贡献。我们设计并分析了具有资源比例的连续减半算法（SH-RR）。SH-RR以近乎最优的非渐近收敛速度实现了成功识别最佳臂的概率。有趣的是，我们确定了确定性和随机资源消耗情况下收敛速度之间的差异。

    arXiv:2402.19090v1 Announce Type: new  Abstract: Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption.
    
[^50]: 光滑 Tchebycheff 标量化用于多目标优化

    Smooth Tchebycheff Scalarization for Multi-Objective Optimization

    [https://arxiv.org/abs/2402.19078](https://arxiv.org/abs/2402.19078)

    通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。

    

    多目标优化问题在许多现实世界应用中都能找到，在这些问题中，目标经常相互冲突，不能通过单个解进行优化。在过去的几十年中，已经提出了许多方法来找到帕累托解，这些解代表了对于给定问题的不同最佳权衡。然而，这些现有方法可能具有较高的计算复杂性，或者可能不能具备解决一般可微分多目标优化问题的良好理论属性。在本项工作中，通过利用光滑优化技术，我们提出了一种新颖且轻量的光滑 Tchebycheff 标量化方法，用于基于梯度的多目标优化。它对于找到所有帕累托解具有良好的理论属性，同时相对于其他方法具有显着较低的计算复杂性。在各种实验结果上

    arXiv:2402.19078v1 Announce Type: cross  Abstract: Multi-objective optimization problems can be found in many real-world applications, where the objectives often conflict each other and cannot be optimized by a single solution. In the past few decades, numerous methods have been proposed to find Pareto solutions that represent different optimal trade-offs among the objectives for a given problem. However, these existing methods could have high computational complexity or may not have good theoretical properties for solving a general differentiable multi-objective optimization problem. In this work, by leveraging the smooth optimization technique, we propose a novel and lightweight smooth Tchebycheff scalarization approach for gradient-based multi-objective optimization. It has good theoretical properties for finding all Pareto solutions with valid trade-off preferences, while enjoying significantly lower computational complexity compared to other methods. Experimental results on variou
    
[^51]: TimeXer：利用外生变量增强变压器进行时间序列预测

    TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables

    [https://arxiv.org/abs/2402.19072](https://arxiv.org/abs/2402.19072)

    本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。

    

    最近的研究表明，在时间序列预测方面取得了显著的性能。然而，由于现实应用的部分观测性质，仅专注于感兴趣的目标，也就是所谓的内生变量，通常是不足以保证准确预测的。值得注意的是，系统通常记录为多个变量，其中外生序列可以为内生变量提供有价值的外部信息。因此，与先前确立的多变量或单变量预测不同，它们要么将所有变量等同对待，要么忽视外生信息，本文关注的是一种实际设置，即具有外生变量的时间序列预测。我们提出了一个新颖的框架TimeXer，利用外部信息增强内生变量的预测。通过巧妙设计的嵌入层，TimeXer使传统的Transformer架构具有重新

    arXiv:2402.19072v1 Announce Type: cross  Abstract: Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reco
    
[^52]: 自动超声心动图视图识别的图卷积神经网络：一种全面方法

    Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach

    [https://arxiv.org/abs/2402.19062](https://arxiv.org/abs/2402.19062)

    该研究提出了一种全面的方法，通过图卷积神经网络实现了自动超声心动图视图识别，结合了3D心脏网格重建和后续任务如分割和姿势估计。

    

    为了促进对心脏超声波（US）的诊断，临床实践已经建立了心脏的几种标准视图，这些视图作为诊断测量的参考点，并定义了图像获取的视口。自动视图识别涉及将这些图像分组为标准视图的类别。尽管深度学习技术在实现这一点方面取得了成功，但仍然存在在验证图像是否适合特定测量方面的困难，原因包括心脏结构的正确位置、姿势和可能的遮挡。我们的方法超越了视图分类，并融合了对心脏的三维网格重建，从而实现了更多后续任务，如分割和姿势估计。在这项工作中，我们探讨了通过图卷积学习3D心脏网格，使用类似的技术来学习自然图像中的3D网格，例如人体姿势估计。

    arXiv:2402.19062v1 Announce Type: cross  Abstract: To facilitate diagnosis on cardiac ultrasound (US), clinical practice has established several standard views of the heart, which serve as reference points for diagnostic measurements and define viewports from which images are acquired. Automatic view recognition involves grouping those images into classes of standard views. Although deep learning techniques have been successful in achieving this, they still struggle with fully verifying the suitability of an image for specific measurements due to factors like the correct location, pose, and potential occlusions of cardiac structures. Our approach goes beyond view classification and incorporates a 3D mesh reconstruction of the heart that enables several more downstream tasks, like segmentation and pose estimation. In this work, we explore learning 3D heart meshes via graph convolutions, using similar techniques to learn 3D meshes in natural images, such as human pose estimation. As the 
    
[^53]: 深度选择性状态空间模型的理论基础

    Theoretical Foundations of Deep Selective State-Space Models

    [https://arxiv.org/abs/2402.19047](https://arxiv.org/abs/2402.19047)

    随着GateLoop、Mamba和GLA等具有乘法交互的线性递归驱动下的深度SSM架构的出现，它们在准确性和效率上超越了基于注意力的文本训练的基础模型。

    

    结构化状态空间模型（SSM）如S4，源自Gu等人的开创性工作，作为建模序列数据的有效方法而日益受到青睐。深度SSM在各种领域展现出卓越的性能，相较于基于注意力的transformers，训练和推理成本降低。最近的研究表明，如果驱动SSM的线性递归允许输入和隐藏状态之间的乘法交互（如GateLoop，Mamba，GLA），那么所得到的架构可以在准确性和效率上超越基于注意力的文本训练的基础模型，参数规模达到十亿级。在本文中，我们使用Rough Path Theory的工具，为这一最近的发现提供了理论基础：我们表明，当随机线性递归配备简单的输入控制转换（选择性机制）时，隐藏状态可被证明是低维的投影。

    arXiv:2402.19047v1 Announce Type: new  Abstract: Structured state-space models (SSMs) such as S4, stemming from the seminal work of Gu et al., are gaining popularity as effective approaches for modeling sequential data. Deep SSMs demonstrate outstanding performance across a diverse set of domains, at a reduced training and inference cost compared to attention-based transformers. Recent developments show that if the linear recurrence powering SSMs allows for multiplicative interactions between inputs and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture can surpass in both in accuracy and efficiency attention-powered foundation models trained on text, at scales of billion parameters. In this paper, we give theoretical grounding to this recent finding using tools from Rough Path Theory: we show that when random linear recurrences are equipped with simple input-controlled transitions (selectivity mechanism), then the hidden state is provably a low-dimensional proj
    
[^54]: 一种用于定位侧信道跟踪中密码操作的深度学习技术

    A Deep-Learning Technique to Locate Cryptographic Operations in Side-Channel Traces

    [https://arxiv.org/abs/2402.19037](https://arxiv.org/abs/2402.19037)

    通过深度学习技术，成功实现了在侧信道跟踪中定位目标加密操作的时间瞬间，即使存在跟踪变形。

    

    侧信道攻击通过相关部分已知计算数据和已测量的侧信道信号，允许从加密原语的执行中提取秘密信息。本文提出了一种新颖的深度学习技术，用于定位侧信道追踪中执行的目标计算密码操作的时间瞬间。与现有解决方案相比，所提出的方法甚至在通过随机延迟插入技术获得的跟踪变形的情况下也能工作。

    arXiv:2402.19037v1 Announce Type: cross  Abstract: Side-channel attacks allow extracting secret information from the execution of cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. However, to set up a successful side-channel attack, the attacker has to perform i) the challenging task of locating the time instant in which the target cryptographic primitive is executed inside a side-channel trace and then ii)the time-alignment of the measured data on that time instant. This paper presents a novel deep-learning technique to locate the time instant in which the target computed cryptographic operations are executed in the side-channel trace. In contrast to state-of-the-art solutions, the proposed methodology works even in the presence of trace deformations obtained through random delay insertion techniques. We validated our proposal through a successful attack against a variety of unprotected and protected cryptographic primitive
    
[^55]: 将弱学习者解释的组合用于改进随机森林的解释性和稳健性

    Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness

    [https://arxiv.org/abs/2402.19025](https://arxiv.org/abs/2402.19025)

    引入了将弱学习者解释组合的方法来改进随机森林的解释性和稳健性，通过对集成方法中解释进行判别平均，取得了成功的实验结果和定量改进。

    

    XAI中的稳健性概念指的是观察到的关于学习模型预测解释在对导致该预测的输入变化时的变化。直觉上，如果要解释的输入略微变化，以至于不会太大程度改变模型的预测，那么我们期望对于该新输入的解释也不会有太大变化。我们认为，通过对弱学习者解释进行判别平均的组合可以提高集成方法中解释的稳健性。该方法已经在后续SHAP方法和随机森林集成中得到实施和测试，并取得了成功的结果。所获得的改进已经通过定量方式进行了测量，并提供了一些关于集成方法中解释性稳健性的见解。

    arXiv:2402.19025v1 Announce Type: cross  Abstract: The notion of robustness in XAI refers to the observed variations in the explanation of the prediction of a learned model with respect to changes in the input leading to that prediction. Intuitively, if the input being explained is modified slightly subtly enough so as to not change the prediction of the model too much, then we would expect that the explanation provided for that new input does not change much either. We argue that a combination through discriminative averaging of ensembles weak learners explanations can improve the robustness of explanations in ensemble methods.This approach has been implemented and tested with post-hoc SHAP method and Random Forest ensemble with successful results. The improvements obtained have been measured quantitatively and some insights into the explicability robustness in ensemble methods are presented.
    
[^56]: SPriFed-OMP：用于稀疏基础恢复的差分隐私联邦学习算法

    SPriFed-OMP: A Differentially Private Federated Learning Algorithm for Sparse Basis Recovery

    [https://arxiv.org/abs/2402.19016](https://arxiv.org/abs/2402.19016)

    本研究提出了一种新的用于联邦学习的差分隐私稀疏基础恢复算法SPriFed-OMP，通过将OMP转化为FL设置，并结合SMPC和DP，有效降低了噪声添加量来实现差分隐私。

    

    稀疏基础恢复是一个经典且重要的统计学习问题，当模型维度$p$远大于样本数$n$时，尤其重要。然而，在联邦学习（FL）框架中研究稀疏基础恢复的工作很少，其中必须同时保护客户数据的差分隐私（DP）。特别是，现有的DP-FL算法（如DP-SGD）的性能保证在$p \gg n$时会显著下降，因此它们将无法准确学习真实的底层稀疏模型。在本工作中，我们开发了一种新的差分私密稀疏基础恢复算法用于FL设置，称为SPriFed-OMP。SPriFed-OMP将OMP（Orthogonal Matching Pursuit）转化为FL设置。此外，它将SMPC（Secure Multi-Party Computation）和DP结合起来，以确保只需添加少量的噪声即可实现差分隐私。

    arXiv:2402.19016v1 Announce Type: new  Abstract: Sparse basis recovery is a classical and important statistical learning problem when the number of model dimensions $p$ is much larger than the number of samples $n$. However, there has been little work that studies sparse basis recovery in the Federated Learning (FL) setting, where the client data's differential privacy (DP) must also be simultaneously protected. In particular, the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will degrade significantly when $p \gg n$, and thus, they will fail to learn the true underlying sparse model accurately. In this work, we develop a new differentially private sparse basis recovery algorithm for the FL setting, called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to the FL setting. Further, it combines SMPC (secure multi-party computation) and DP to ensure that only a small amount of noise needs to be added in order to achieve differential privacy. As a
    
[^57]: 生成、重建和表示离散和连续数据：具有可学习编码-解码器的广义扩散

    Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding

    [https://arxiv.org/abs/2402.19009](https://arxiv.org/abs/2402.19009)

    引入了具有可学习编码器-解码器的广义扩散（DiLED），用于在不同数据类型上无缝整合生成新实例、重建输入和学习紧凑表示，扩展了现有模型家族的性能。

    

    深度生成模型的广泛应用基于三项核心能力--生成新实例、重建输入和学习紧凑表示--跨不同数据类型，如离散文本/蛋白序列和连续图像。现有的模型家族，如变分自动编码器（VAEs）、生成对抗网络（GANs）、自回归模型和扩散模型，通常在特定能力和数据类型上表现优异，但在其他方面表现不佳。我们引入了具有可学习编码器-解码器的广义扩散（DiLED），它无缝地集成了广泛适用性和增强性能的核心能力。DiLED通过引入参数化编码-解码来将标准扩散中的高斯加噪-去噪进行了泛化。关键是，DiLED与成熟的扩散模型目标和训练方法兼容，可有效学习编码-解码器。

    arXiv:2402.19009v1 Announce Type: cross  Abstract: The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder 
    
[^58]: 用于异质过度离散计数时间序列的负二项随机Gamma马尔可夫过程

    Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series

    [https://arxiv.org/abs/2402.18995](https://arxiv.org/abs/2402.18995)

    提出了一种负二项随机Gamma马尔可夫过程，用于改进异质过度离散计数时间序列的预测性能，并加快推断算法的收敛速度。

    

    对于计数值时间序列的建模自然地在物理和社会领域中引起越来越多的关注。Poisson gamma动态系统（PGDSs）是新开发的方法，可以很好地捕捉计数序列背后表现出的明显的潜在转换结构和突发动态。特别是，与基于经典线性动态系统（LDS）的方法相比，PGDSs在数据填充和预测方面表现出优越性能。尽管具有这些优势，PGDS不能捕捉基础动态过程的异质过度离散行为。为了减轻这一缺陷，我们提出了一种负二项随机Gamma马尔可夫过程，它不仅显著改善了所提出的动态系统的预测性能，还促进了推断算法的快速收敛。此外，我们开发了估计因子结构和图结构的方法。

    arXiv:2402.18995v1 Announce Type: cross  Abstract: Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph
    
[^59]: Spyx：用于脉冲神经网络即时编译优化的库

    Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural Networks

    [https://arxiv.org/abs/2402.18994](https://arxiv.org/abs/2402.18994)

    Spyx旨在提供一个用于即时编译优化脉冲神经网络的库，以在训练时增强能效并减少硬件占用。

    

    随着人工智能在现代社会中的作用日益关键，深度神经网络的高效训练和部署已成为关注的重点领域。最近关注度较高的大规模神经架构的进展推动了AI加速器的发展，促进了庞大、多十亿参数模型的训练。尽管这些强大的网络很有效，但在生产环境中往往会产生高昂的执行成本。受生物神经过程启发，神经形态计算提供了一个有前途的替代方案。通过利用时间稀疏计算，脉冲神经网络（SNNs）通过减少和降低功耗硬件占用来增强能效。然而，由于其循环性质，SNNs的训练可能具有挑战性，难以像现代AI加速器那样轻松利用巨大的并行性。为了促进对S的研究

    arXiv:2402.18994v1 Announce Type: cross  Abstract: As the role of artificial intelligence becomes increasingly pivotal in modern society, the efficient training and deployment of deep neural networks have emerged as critical areas of focus. Recent advancements in attention-based large neural architectures have spurred the development of AI accelerators, facilitating the training of extensive, multi-billion parameter models. Despite their effectiveness, these powerful networks often incur high execution costs in production environments. Neuromorphic computing, inspired by biological neural processes, offers a promising alternative. By utilizing temporally-sparse computations, Spiking Neural Networks (SNNs) offer to enhance energy efficiency through a reduced and low-power hardware footprint. However, the training of SNNs can be challenging due to their recurrent nature which cannot as easily leverage the massive parallelism of modern AI accelerators. To facilitate the investigation of S
    
[^60]: 通过谱扩散生成图形

    Graph Generation via Spectral Diffusion

    [https://arxiv.org/abs/2402.18974](https://arxiv.org/abs/2402.18974)

    提出了一种基于图拉普拉斯矩阵谱分解和扩散过程的新颖图生成模型GRASP，能够通过截断拉普拉斯频谱快速准确地捕捉图的结构特征，同时处理节点特征，避免了二次复杂性瓶颈。

    

    在本文中，我们提出了GRASP，一种基于图拉普拉斯矩阵的谱分解和扩散过程的新颖图生成模型。具体而言，我们提出使用去噪模型从中采样特征向量和特征值，从而可以重建图拉普拉斯矩阵和邻接矩阵。我们的置换不变模型还可以通过将节点特征连接到每个节点的特征向量来处理节点特征。使用拉普拉斯频谱使我们能够自然捕获图的结构特征，并直接在节点空间中工作，同时避免了限制其他方法适用性的二次复杂性瓶颈。通过截断谱，我们实现了更快但准确的生成过程，这在我们的实验中得到了证实。对合成和现实世界图形的大量实验显示了我们模型相对于最先进的模型的优势。

    arXiv:2402.18974v1 Announce Type: new  Abstract: In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other methods. This is achieved by truncating the spectrum, which as we show in our experiments results in a faster yet accurate generative process. An extensive set of experiments on both synthetic and real world graphs demonstrates the strengths of our model against state-of-the-art a
    
[^61]: 提高联邦深度学习的群组连接性以实现泛化能力

    Improving Group Connectivity for Generalization of Federated Deep Learning

    [https://arxiv.org/abs/2402.18949](https://arxiv.org/abs/2402.18949)

    通过研究和改进联邦学习的泛化能力，本文从“连接性”视角探讨了如何改善本地模型间的连接性以生成更具泛化能力的全局模型。

    

    联邦学习（FL）涉及多个异构客户端通过迭代本地更新和模型融合共同训练全局模型。与集中式训练相比，FL的全局模型的泛化存在很大差距，这是其在更广泛应用中的瓶颈。本文通过基本的“连接性”视角研究和改进FL的泛化，即本地模型在参数区域中如何连接并融合为泛化的全局模型。术语“连接性”源自线性模式连接（LMC），研究神经网络的两种不同解决方案（例如模式）的内插损失景观。在本文中，我们通过利用固定的锚定模型来研究连接性的传递性质，从两个模型（LMC）到一组模型（FL中的模型融合）。根据所发现的结果，我们提出

    arXiv:2402.18949v1 Announce Type: new  Abstract: Federated learning (FL) involves multiple heterogeneous clients collaboratively training a global model via iterative local updates and model fusion. The generalization of FL's global model has a large gap compared with centralized training, which is its bottleneck for broader applications. In this paper, we study and improve FL's generalization through a fundamental ``connectivity'' perspective, which means how the local models are connected in the parameter region and fused into a generalized global model. The term ``connectivity'' is derived from linear mode connectivity (LMC), studying the interpolated loss landscape of two different solutions (e.g., modes) of neural networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed anchor models to empirically and theoretically study the transitivity property of connectivity from two models (LMC) to a group of models (model fusion in FL). Based on the findings, we propo
    
[^62]: 在高阶不确定模型中使用高斯过程进行实时自适应安全关键控制

    Real-Time Adaptive Safety-Critical Control with Gaussian Processes in High-Order Uncertain Models

    [https://arxiv.org/abs/2402.18946](https://arxiv.org/abs/2402.18946)

    本文提出了一种用于高阶不确定模型的实时自适应安全关键控制的方法，包括利用稀疏高斯过程进行在线学习和基于高阶控制屏障函数的安全过滤器。

    

    本文提出了一种自适应在线学习框架，用于具有不确定参数的系统，以确保在非平稳环境中进行安全关键控制。我们的方法包括两个阶段。初始阶段集中在一个新颖的稀疏高斯过程（GP）框架上。我们首先集成了一个遗忘因子来优化变分稀疏GP算法，从而增强其适应性。随后，使用特殊复合核对高斯模型的超参数进行训练，并通过更新一个源自新样本的孤独感应点来加强高斯模型的在线推理能力和计算效率，同时与学习到的超参数相结合。在第二阶段，我们提出了基于高阶控制屏障函数（HOCBFs）的安全过滤器，与先前训练的学习模型协同工作。通过利用第一阶段的复合核，我们有效地解决了

    arXiv:2402.18946v1 Announce Type: new  Abstract: This paper presents an adaptive online learning framework for systems with uncertain parameters to ensure safety-critical control in non-stationary environments. Our approach consists of two phases. The initial phase is centered on a novel sparse Gaussian process (GP) framework. We first integrate a forgetting factor to refine a variational sparse GP algorithm, thus enhancing its adaptability. Subsequently, the hyperparameters of the Gaussian model are trained with a specially compound kernel, and the Gaussian model's online inferential capability and computational efficiency are strengthened by updating a solitary inducing point derived from new samples, in conjunction with the learned hyperparameters. In the second phase, we propose a safety filter based on high-order control barrier functions (HOCBFs), synergized with the previously trained learning model. By leveraging the compound kernel from the first phase, we effectively address 
    
[^63]: Decompose-and-Compose: 一种组合方法来减轻伪相关性

    Decompose-and-Compose: A Compositional Approach to Mitigating Spurious Correlation

    [https://arxiv.org/abs/2402.18919](https://arxiv.org/abs/2402.18919)

    通过组合方法改善模型对相关性转移的稳健性，解决了图像分类中伪相关性的问题。

    

    尽管标准的经验风险最小化（ERM）训练已被证明在图像分类中的内分布数据上是有效的，但在外分布样本上表现不佳。图像分类中的一个主要分布转移来源是图像的组成性质。具体来说，除了确定标签的主要对象或组件外，通常还存在一些其他图像组件，这可能导致训练和测试环境之间的输入分布转移。更重要的是，这些组件可能与标签具有伪相关性。为了解决这个问题，我们提出了Decompose-and-Compose（DaC），通过基于组合图像元素的组合方法改善了对相关性转移的稳健性。根据我们的观察，使用ERM训练的模型通常高度关注要么是因果组件，要么是与标签具有高伪相关性的组件（尤其

    arXiv:2402.18919v1 Announce Type: cross  Abstract: While standard Empirical Risk Minimization (ERM) training is proven effective for image classification on in-distribution data, it fails to perform well on out-of-distribution samples. One of the main sources of distribution shift for image classification is the compositional nature of images. Specifically, in addition to the main object or component(s) determining the label, some other image components usually exist, which may lead to the shift of input distribution between train and test environments. More importantly, these components may have spurious correlations with the label. To address this issue, we propose Decompose-and-Compose (DaC), which improves robustness to correlation shift by a compositional approach based on combining elements of images. Based on our observations, models trained with ERM usually highly attend to either the causal components or the components having a high spurious correlation with the label (especia
    
[^64]: 不要依赖无选择，不要重复移动：一种用于分类优化的最佳、高效和实用算法

    Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization

    [https://arxiv.org/abs/2402.18917](https://arxiv.org/abs/2402.18917)

    针对带偏好反馈的积极在线分类优化问题，提出了一种既高效又具有最优后悔保证的算法。

    

    我们解决了带偏好反馈的积极在线分类优化问题，这是一种用于建模用户选择和子集效用最大化的框架。该框架在各种真实应用中非常有用，包括广告放置、在线零售、推荐系统、微调语言模型等。虽然这个问题过去已经被研究过，但缺乏直观和实用的解决方案，同时需要高效的算法和最优的后悔保证。例如，通常使用的分类选择算法通常需要存在一个始终包含在选择集中的“强参考项”，此外，它们还被设计为重复提供相同的分类，直到参考项被选择 — 所有这些要求对于实际应用而言都非常不现实。在本文中，我们为分类中的后悔最小化问题设计了高效的算法。

    arXiv:2402.18917v1 Announce Type: new  Abstract: We address the problem of active online assortment optimization problem with preference feedback, which is a framework for modeling user choices and subsetwise utility maximization. The framework is useful in various real-world applications including ad placement, online retail, recommender systems, fine-tuning language models, amongst many. The problem, although has been studied in the past, lacks an intuitive and practical solution approach with simultaneously efficient algorithm and optimal regret guarantee. E.g., popularly used assortment selection algorithms often require the presence of a `strong reference' which is always included in the choice sets, further they are also designed to offer the same assortments repeatedly until the reference item gets selected -- all such requirements are quite unrealistic for practical applications. In this paper, we designed efficient algorithms for the problem of regret minimization in assortmen
    
[^65]: DIGIC: 通过因果发现实现领域泛化的模仿学习

    DIGIC: Domain Generalizable Imitation Learning by Causal Discovery

    [https://arxiv.org/abs/2402.18910](https://arxiv.org/abs/2402.18910)

    通过在只有单一领域数据的情况下发现因果特征，提出了一种新颖的领域泛化模仿学习框架DIGIC，可以作为非结构化假设下基于跨领域变化方法的补充

    

    因果性已经与机器学习相结合，产生了针对领域泛化的强大表示。大多数现有的这类方法需要来自多个领域的大量数据，通过跨领域变化来识别引起特征，这可能昂贵甚至不可行，在某些情况下可能会导致误识别。在这项工作中，我们通过利用演示数据分布来发现领域泛化策略的因果特征，提出了一种不同的尝试。我们设计了一个名为DIGIC的新领域泛化模仿学习框架，通过因果发现从演示数据分布中找出专家动作的直接原因来识别因果特征。我们的框架可以在只有单一领域数据的情况下实现领域泛化的模仿学习，并在基础因果模型的非结构化假设下作为基于跨领域变化方法的补充。

    arXiv:2402.18910v1 Announce Type: cross  Abstract: Causality has been combined with machine learning to produce robust representations for domain generalization. Most existing methods of this type require massive data from multiple domains to identify causal features by cross-domain variations, which can be expensive or even infeasible and may lead to misidentification in some cases. In this work, we make a different attempt by leveraging the demonstration data distribution to discover the causal features for a domain generalizable policy. We design a novel framework, called DIGIC, to identify the causal features by finding the direct cause of the expert action from the demonstration data distribution via causal discovery. Our framework can achieve domain generalizable imitation learning with only single-domain data and serve as a complement for cross-domain variation-based methods under non-structural assumptions on the underlying causal models. Our empirical study in various control 
    
[^66]: 论差分隐私微调的收敛性：应线性探测还是完全微调？

    On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?

    [https://arxiv.org/abs/2402.18905](https://arxiv.org/abs/2402.18905)

    本文分析了差分隐私线性探测（LP）和完全微调（FT）的训练动态，探索了从线性探测过渡到完全微调（LP-FT）的顺序微调现象及其对测试损失的影响，提供了关于在超参数化神经网络中差分隐私微调收敛性的理论洞见和隐私预算分配的效用曲线。

    

    差分隐私（DP）机器学习流水线通常包括两个阶段的过程：在公共数据集上进行非私有预训练，然后使用DP优化技术在私有数据上进行微调。在DP设置中，已经观察到完全微调有时候并不总是产生最佳的测试准确度，即使对于分布内数据也是如此。本文（1）分析了DP线性探测（LP）和完全微调（FT）的训练动态，以及（2）探索了顺序微调的现象，从线性探测开始，过渡到完全微调（LP-FT），以及它对测试损失的影响。我们提供了有关DP微调在超参数化神经网络中的收敛性的理论洞见，并建立了一个确定隐私预算在线性探测和完全微调之间分配的效用曲线。理论结果得到了对各种基准和模型的经验评估支持。

    arXiv:2402.18905v1 Announce Type: cross  Abstract: Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models.
    
[^67]: 基于不确定性的离散异构数据孤岛中可拓展编码本的联邦学习

    Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos

    [https://arxiv.org/abs/2402.18888](https://arxiv.org/abs/2402.18888)

    提出了一种基于不确定性的可拓展编码本的联邦学习框架，用于应对异构数据孤岛中模型适应新分布的挑战

    

    旨在利用广泛分布的数据集进行联邦学习(FL)面临着一个关键挑战：不同孤岛间数据的异构性。我们发现从FL导出的模型在应用于具有陌生分布的数据孤岛时会表现出明显增加的不确定性。因此，我们提出了一种创新而简单的迭代框架，称为基于不确定性的可拓展编码本联邦学习(UEFL)。该框架动态地将潜在特征映射到可训练的离散向量，评估不确定性，并针对表现出高不确定性的孤岛特别地扩展离散化词典或编码本。

    arXiv:2402.18888v1 Announce Type: new  Abstract: Federated learning (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos. While previous studies have explored discrete representations to enhance model generalization across minor distributional shifts, these approaches often struggle to adapt to new data silos with significantly divergent distributions. In response, we have identified that models derived from FL exhibit markedly increased uncertainty when applied to data silos with unfamiliar distributions. Consequently, we propose an innovative yet straightforward iterative framework, termed Uncertainty-Based Extensible-Codebook Federated Learning (UEFL). This framework dynamically maps latent features to trainable discrete vectors, assesses the uncertainty, and specifically extends the discretization dictionary or codebook for silos exhibiting high uncertainty. Our approach aims to simultaneously enhance a
    
[^68]: BP-DeepONet: 一种使用基于物理的DeepONet的无袖血压估计新方法

    BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet

    [https://arxiv.org/abs/2402.18886](https://arxiv.org/abs/2402.18886)

    本研究提出了基于物理的DeepONet方法，用于预测动脉血压（ABP）波形，首次实现了连续预测ABP波形，满足Navier-Stokes方程和Windkessel边界条件。

    

    心血管疾病是全球死亡的主要原因，血压是一个关键指标。 动脉血压（ABP）波形提供了整个心脏周期中的连续压力测量，并提供了有价值的诊断见解。 因此，人们迫切需要无创的无袖方法来持续测量ABP波形。 准确预测ABP波形还可以改善对平均血压的估计，这是一项重要的心血管健康特征。 本研究提出了一种基于物理信息DeepONet方法的新框架来预测ABP波形。 与先前的方法不同，我们的方法要求预测的ABP波形满足带有时间周期条件和Windkessel边界条件的Navier-Stokes方程。 值得注意的是，我们的框架是第一个连续预测ABP波形的框架，同时具有地点和时间。

    arXiv:2402.18886v1 Announce Type: new  Abstract: Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic.   This study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the 
    
[^69]: 监督对比表示学习：具有不受限制特征的景观分析

    Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features

    [https://arxiv.org/abs/2402.18884](https://arxiv.org/abs/2402.18884)

    通过监督对比表示学习，在超参数化的深度神经网络中研究解决方案，揭示了最小化SC损失的全局最小值和唯一最小化器。

    

    最近的研究发现，在超参数化的深度神经网络中，经过零训练误差训练后的网络，在最后一层呈现出严格的结构模式，被称为神经坍塌（NC）。这些结果表明，在这种网络中，最终隐藏层输出在训练集上显示出最小的类内变化。虽然现有研究在交叉熵损失下广泛探讨了这一现象，但关于其对应的对比损失——监督对比（SC）损失的研究较少。本文通过NC的视角，采用分析方法研究了优化SC损失所得解决方案。我们采用不受限制特征模型（UFM）作为代表性代理，揭示了在充分超参数化的深度网络中衍生的与NC相关现象。我们展示了，尽管SC损失最小化是非凸的，但所有局部最小值都是全局最小值。此外，最小化器是唯一的

    arXiv:2402.18884v1 Announce Type: new  Abstract: Recent findings reveal that over-parameterized deep neural networks, trained beyond zero training-error, exhibit a distinctive structural pattern at the final layer, termed as Neural-collapse (NC). These results indicate that the final hidden-layer outputs in such networks display minimal within-class variations over the training set. While existing research extensively investigates this phenomenon under cross-entropy loss, there are fewer studies focusing on its contrastive counterpart, supervised contrastive (SC) loss. Through the lens of NC, this paper employs an analytical approach to study the solutions derived from optimizing the SC loss. We adopt the unconstrained features model (UFM) as a representative proxy for unveiling NC-related phenomena in sufficiently over-parameterized deep networks. We show that, despite the non-convexity of SC loss minimization, all local minima are global minima. Furthermore, the minimizer is unique (
    
[^70]: Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks

    Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks

    [https://arxiv.org/abs/2402.18875](https://arxiv.org/abs/2402.18875)

    本文研究了课程学习技术在改善异构图神经网络性能和鲁棒性方面的应用，提出了一种损失感知的训练计划LTS，有效减少偏差和方差，减轻嘈杂数据影响，增强整体准确性。

    

    异构图神经网络（HGNN）是一类专为异构图设计的深度学习模型，其图中包含不同类型的节点和边。本文研究了课程学习技术在改善异构图神经网络（GNN）性能和鲁棒性方面的应用。为了更好地对数据的质量进行分类，我们设计了一种损失感知的训练计划，命名为LTS，该计划衡量了数据每个节点的质量，并逐步将训练数据集融入模型中，以逐步增加难度。 LTS可以无缝集成到各种框架中，有效减少偏差和方差，减轻嘈杂数据的影响，提高整体准确性。我们的研究结果表明，课程学习在增强HGNN分析复杂图结构数据能力方面具有显著功效。

    arXiv:2402.18875v1 Announce Type: new  Abstract: Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning models designed specifically for heterogeneous graphs, which are graphs that contain different types of nodes and edges. This paper investigates the application of curriculum learning techniques to improve the performance and robustness of Heterogeneous Graph Neural Networks (GNNs). To better classify the quality of the data, we design a loss-aware training schedule, named LTS that measures the quality of every nodes of the data and incorporate the training dataset into the model in a progressive manner that increases difficulty step by step. LTS can be seamlessly integrated into various frameworks, effectively reducing bias and variance, mitigating the impact of noisy data, and enhancing overall accuracy. Our findings demonstrate the efficacy of curriculum learning in enhancing HGNNs capabilities for analyzing complex graph-structured data. The code is public at ht
    
[^71]: Dr. Strategy: 具有战略梦想的基于模型的通用型Agent

    Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming

    [https://arxiv.org/abs/2402.18866](https://arxiv.org/abs/2402.18866)

    本文提出了一个新的基于模型的通用型Agent Dr. Strategy，配备了Dreaming Strategy，实现了在梦境中学习一组潜在地标，并利用这些地标学习地标条件的高速公路策略。

    

    Model-based reinforcement learning（MBRL）一直是改善样本效率问题并创建通用型Agent的主要方法。然而，对于增强梦想策略本身的努力并不多。在本文中，受认知科学观察到人类在规划时使用空间分隔与征服策略的启发，我们提出了一个新的MBRL agent，称为Dr. Strategy，它配备了一种新颖的Dreaming Strategy。所提出的Agent在梦境中实现了一种类似于分隔与征服的策略。

    arXiv:2402.18866v1 Announce Type: new  Abstract: Model-based reinforcement learning (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question whether and how an agent can "dream better" in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in planning, we propose a new MBRL agent, called Dr. Strategy, which is equipped with a novel Dreaming Strategy. The proposed agent realizes a version of divide-and-conquer-like strategy in dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the dream to move to a landmark, and from there it tackles the exploration and achi
    
[^72]: 分析和减少参数高效调整中的灾难性遗忘

    Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning

    [https://arxiv.org/abs/2402.18865](https://arxiv.org/abs/2402.18865)

    通过模式连接调查了连续微调中不同极小值之间的几何连接，揭示了大型语言模型中的灾难性遗忘问题。

    

    已有研究显示，大型语言模型（LLMs）在语言理解和生成方面表现出色。然而，当LLMs不断在复杂和多样化的特定领域下游任务上进行微调时，对历史任务的推理性能会急剧下降，这被称为灾难性遗忘问题。需要在学习可塑性和记忆稳定性之间保持权衡。已有很多研究探讨了诸如记忆重放、正则化和参数隔离等策略，但在连续的LLMs微调场景中，对各个相邻极小值之间的几何连接知之甚少。在这项工作中，我们通过模式连接的视角调查了不同极小值之间的几何连接，这意味着不同极小值可以通过一个低损失的山谷相连接。通过大量实验，我们揭示了LLMs微调中的模式连接现象。

    arXiv:2402.18865v1 Announce Type: cross  Abstract: Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs contin
    
[^73]: 概率Lipschitz性和稳定秩用于比较解释模型

    Probabilistic Lipschitzness and the Stable Rank for Comparing Explanation Models

    [https://arxiv.org/abs/2402.18863](https://arxiv.org/abs/2402.18863)

    概率Lipschitz性与稳定秩的研究为比较解释模型提供了新的角度和度量标准。

    

    解释性模型如今在机器学习中广泛应用，以解决神经网络的黑盒特性。现在的问题是哪种解释性模型最有效。概率Lipschitz性表明神经网络的平滑性与事后解释的质量基本相关。本文在对Integrated Gradients、LIME和SmoothGrad的概率Lipschitzness进行理论下限证明的基础上，提出了一种新的度量标准，使用概率Lipschitz性和归一化的聪明度来比较解释性模型的稳健性。此外，我们证明了神经网络的局部Lipschitz常数与其稳定秩之间的联系。然后我们证明神经网络的稳定秩提供了解释性模型稳健性的一种启发式方法。

    arXiv:2402.18863v1 Announce Type: new  Abstract: Explainability models are now prevalent within machine learning to address the black-box nature of neural networks. The question now is which explainability model is most effective. Probabilistic Lipschitzness has demonstrated that the smoothness of a neural network is fundamentally linked to the quality of post hoc explanations. In this work, we prove theoretical lower bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and SmoothGrad. We propose a novel metric using probabilistic Lipschitzness, normalised astuteness, to compare the robustness of explainability models. Further, we prove a link between the local Lipschitz constant of a neural network and its stable rank. We then demonstrate that the stable rank of a neural network provides a heuristic for the robustness of explainability models.
    
[^74]: 利用实验，数据分析和健康评估使二次利用电池由耗尽到强大

    Taking Second-life Batteries from Exhausted to Empowered using Experiments, Data Analysis, and Health Estimation

    [https://arxiv.org/abs/2402.18859](https://arxiv.org/abs/2402.18859)

    本研究集中于为电网储能中的退役电池设计健康监测算法，开发了四种基于机器学习的健康评估模型，并提出了一种自适应在线健康评估算法。

    

    本研究侧重于为部署在电网储能应用中的退役电池（BMS$_2$）设计健康监测算法。在15个月的测试中，我们编制、分析并公开分享了一个二次利用（SL）电池的数据集，实施了一个循环协议，模拟了在3 V-4 V电压范围内的电网储能负荷曲线。开发并比较了四个基于机器学习的健康评估模型，依赖于BMS$_2$特征和初始容量，所选模型在测试数据上实现了低于2.3%的平均绝对百分比误差（MAPE）。此外，通过整合基于聚类的方法，提出了一种自适应在线健康评估算法，在线部署过程中限制了估计误差。

    arXiv:2402.18859v1 Announce Type: new  Abstract: The reuse of retired electric vehicle (EV) batteries in electric grid energy storage emerges as a promising strategy to address environmental concerns and boost economic value. This study concentrates on devising health monitoring algorithms for retired batteries (BMS$_2$) deployed in grid storage applications. Over 15 months of testing, we compile, analyze, and publicly share a dataset of second-life (SL) batteries, implementing a cycling protocol simulating grid energy storage load profiles within a 3 V-4 V voltage window. Four machine learning-based health estimation models, relying on BMS$_2$ features and initial capacity, are developed and compared, with the selected model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test data. Additionally, an adaptive online health estimation algorithm is proposed by integrating a clustering-based method, limiting estimation errors during online deployment. These results constit
    
[^75]: 重新思考带有通用学习目标的多领域泛化

    Rethinking Multi-domain Generalization with A General Learning Objective

    [https://arxiv.org/abs/2402.18853](https://arxiv.org/abs/2402.18853)

    提出了一个通用学习目标范式，通过Y-mapping来放松约束并设计新的学习目标，包括学习域无关的条件特征和最大化后验概率，通过正则化项解决放松约束引起的问题

    

    多领域泛化（mDG）的普遍目标是最小化训练和测试分布之间的差异，以增强边际到标签分布映射。然而，现有的mDG文献缺乏一个通用的学习目标范式，通常对静态目标边际分布施加约束。在本文中，我们提议利用一个$Y$-mapping来放松约束。我们重新思考了mDG的学习目标，并设计了一个新的通用学习目标来解释和分析大多数现有的mDG智慧。这个通用目标分为两个协同的目标：学习与域无关的条件特征和最大化一个后验。我们探索了两个有效的正则化项，这些项结合了先验信息并抑制了无效的因果关系，减轻了放松约束所带来的问题。我们在理论上为域对齐提供了一个上限。

    arXiv:2402.18853v1 Announce Type: cross  Abstract: Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of 
    
[^76]: 在处方和预测中应用0-1神经网络

    Applications of 0-1 Neural Networks in Prescription and Prediction

    [https://arxiv.org/abs/2402.18851](https://arxiv.org/abs/2402.18851)

    引入了处方网络（PNNs）这种新型神经网络，通过混合整数规划训练，结合反事实估计，在医疗决策中展现出优于现有方法的表现，可优化治疗策略，并具有更大的可解释性和更复杂的策略编码能力。

    

    医疗决策中的一个关键挑战是在有限的观察数据下学习针对患者的治疗策略。为了解决这个问题，我们引入了处方网络（PNNs），这是用混合整数规划训练的浅层0-1神经网络，可以与反事实估计一起在中等数据情况下优化策略。这些模型比深度神经网络具有更大的可解释性，并且可以编码比常见模型（如决策树）更复杂的策略。我们展示了PNNs在合成数据实验和产后高血压治疗分配案例研究中表现优于现有方法。特别是，PNNs被证明能够产生可降低高血压峰值的治疗策略。

    arXiv:2402.18851v1 Announce Type: cross  Abstract: A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak bloo
    
[^77]: 多保真度残差神经过程用于可扩展的替代建模

    Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling

    [https://arxiv.org/abs/2402.18846](https://arxiv.org/abs/2402.18846)

    提出了一种多保真度残差神经过程（MFRNP）框架，旨在优化低保真度解码器，通过聚合准确的信息共享来解决不同保真度之间的共享信息不准确的问题。

    

    多保真度替代建模旨在通过结合来自多个来源的数据，在最高保真度水平学习准确的替代模型。传统方法依赖于高斯过程，很难扩展到高维数据。深度学习方法利用基于神经网络的编码器和解码器来提高可扩展性。这些方法在不包括对应解码器参数的情况下在不同保真度之间共享编码表示。在最高保真度时，用不同参数解码表示，使共享信息固有不准确。这限制了推断性能，特别是在最高保真度数据的域覆盖有限的情况下。为了解决这些限制，我们提出了一种新颖的多保真度替代建模框架——多保真度残差神经过程（MFRNP）。

    arXiv:2402.18846v1 Announce Type: new  Abstract: Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the highest fidelity level by combining data from multiple sources. Traditional methods relying on Gaussian processes can hardly scale to high-dimensional data. Deep learning approaches utilize neural network based encoders and decoders to improve scalability. These approaches share encoded representations across fidelities without including corresponding decoder parameters. At the highest fidelity, the representations are decoded with different parameters, making the shared information inherently inaccurate. This hinders inference performance, especially in out-of-distribution scenarios when the highest fidelity data has limited domain coverage. To address these limitations, we propose Multi-fidelity Residual Neural Processes (MFRNP), a novel multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity decoders for accurate information sharing by agg
    
[^78]: 扩展流匹配：具有广义连续性方程的条件生成方法

    Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation

    [https://arxiv.org/abs/2402.18839](https://arxiv.org/abs/2402.18839)

    本文基于Flow Matching发展了条件生成理论，通过使用广义连续性方程的数学框架而非流匹配中的连续性方程，实现了一种新颖的流基条件分布生成方法。

    

    条件生成任务是生成模型中最重要的应用之一，迄今为止已经开发了许多基于著名扩散模型的方法，其中以基于引导的无分类器方法为首。然而，基于引导的方法的理论不仅要求用户微调“引导强度”，而且其目标向量场不一定对应于训练中使用的条件分布。本文基于流匹配发展了条件生成理论，流匹配是扩散方法的当前强大竞争者之一。受将概率路径解释为路径空间上的分布的启发，我们建立了一个新颖的流基条件分布生成理论，通过使用广义连续性方程的数学框架而不是流匹配中的连续性方程。这一理论自然地推导出一种方法

    arXiv:2402.18839v1 Announce Type: new  Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated diffusion models, with the guidance-based classifier-free method taking the lead. However, the theory of the guidance-based method not only requires the user to fine-tune the "guidance strength," but its target vector field does not necessarily correspond to the conditional distribution used in training. In this paper, we develop the theory of conditional generation based on Flow Matching, a current strong contender of diffusion methods. Motivated by the interpretation of a probability path as a distribution on path space, we establish a novel theory of flow-based generation of conditional distribution by employing the mathematical framework of generalized continuity equation instead of the continuity equation in flow matching. This theory naturally derives a method th
    
[^79]: 基于模型的方法改进强化学习效率，利用专家观察

    A Model-Based Approach for Improving Reinforcement Learning Efficiency Leveraging Expert Observations

    [https://arxiv.org/abs/2402.18836](https://arxiv.org/abs/2402.18836)

    这个方法结合了最大熵强化学习和行为克隆损失的扩展策略损失，通过调整权重提高了强化学习的效率，并在连续控制任务中表现优异。

    

    这篇论文研究了如何将专家观察（没有明确的专家行动信息）纳入深度强化学习环境，以提高样本效率。首先，我们形成了一个扩展的策略损失，结合了最大熵强化学习目标与利用前向动力学模型的行为克隆损失。然后，我们提出了一个算法，自动调整扩展损失函数中每个组件的权重。在各种连续控制任务的实验证明，所提出的算法通过有效利用可用的专家观察击败了各种基准。

    arXiv:2402.18836v1 Announce Type: new  Abstract: This paper investigates how to incorporate expert observations (without explicit information on expert actions) into a deep reinforcement learning setting to improve sample efficiency. First, we formulate an augmented policy loss combining a maximum entropy reinforcement learning objective with a behavioral cloning loss that leverages a forward dynamics model. Then, we propose an algorithm that automatically adjusts the weights of each component in the augmented loss function. Experiments on a variety of continuous control tasks demonstrate that the proposed algorithm outperforms various benchmarks by effectively utilizing available expert observations.
    
[^80]: 无需训练集的两阶段深度学习用于光谱数据去噪

    Training-set-free two-stage deep learning for Spectroscopic data de-noising

    [https://arxiv.org/abs/2402.18830](https://arxiv.org/abs/2402.18830)

    提出了一种无需训练集的两阶段深度学习方法，结合自适应先验和先进优化技术，实现了比先前工作快五倍的加速。

    

    去噪是光谱后处理过程中的重要步骤。先前的基于机器学习的方法快速但大多基于监督学习，需要一个训练集，在实际实验测量中可能成本较高。基于无监督学习的算法速度慢，并且需要多次迭代才能收敛。本文通过提出一种无需训练集的两阶段深度学习方法，弥合了这一差距。我们展示了之前方法中模糊固定输入的改进，引入自适应先验。结合更先进的优化技术，我们的方法比前人工作快五倍。理论上，我们研究了相应非凸线性问题的潜在状态，并且结果表明，这个问题对于一阶算法收敛具有良好的几何性质。

    arXiv:2402.18830v1 Announce Type: cross  Abstract: De-noising is a prominent step in the spectra post-processing procedure. Previous machine learning-based methods are fast but mostly based on supervised learning and require a training set that may be typically expensive in real experimental measurements. Unsupervised learning-based algorithms are slow and require many iterations to achieve convergence. Here, we bridge this gap by proposing a training-set-free two-stage deep learning method. We show that the fuzzy fixed input in previous methods can be improved by introducing an adaptive prior. Combined with more advanced optimization techniques, our approach can achieve five times acceleration compared to previous work. Theoretically, we study the landscape of a corresponding non-convex linear problem, and our results indicates that this problem has benign geometry for first-order algorithms to converge.
    
[^81]: Adam的批量大小不变版本

    Batch size invariant Adam

    [https://arxiv.org/abs/2402.18824](https://arxiv.org/abs/2402.18824)

    提出了Adam的批量大小不变版本，通过改变计算顺序实现批量大小不变性，比之前的方法具有更广泛的适用范围。

    

    我们提出了Adam的批量大小不变版本，适用于大规模分布式设置，其中小批量被分成微批量，然后分配给工作节点。在标准Adam中，对v项首先计算微批量梯度的平均值，然后求平方，而在这里提出的批量大小不变的Adam中，我们首先对微批量梯度求平方，然后平均。先前的工作（例如Malladi等人2022年）使用一种涉及学习率的平方根缩放的替代方法，但这种方法需要强大的假设才能起作用；特别是梯度方差主导期望梯度的平方。相比之下，这里提出的方法在不需要这种假设的情况下实现了批量大小不变性。我们证实在实践中，我们的方案在比以前的方法更多的情况下给出了批量大小不变性。

    arXiv:2402.18824v1 Announce Type: new  Abstract: We propose a batch size invariant version of Adam, for use in large-scale, distributed settings, in which the mini-batch is divided into micro-batches which are distributed among worker nodes. For the v term, standard Adam first computes the average over micro-batch gradients, then squares, while in the batch size invariant Adam proposed here, we first square the micro-batch gradients, then average. Previous work (e.g. Malladi et al. 2022) used an alternative approach that involved a square-root scaling of the learning rate, but this approach requires strong assumptions to work; in particular that the gradient variance dominates the square of the expected gradient. In contrast, the approach proposed here gives batch size invariance without this assumption. We confirm that in practice our scheme gives batch size invariance in a much larger range of scenarios than the previous approach.
    
[^82]: In-Context Learning的双重运行模式

    Dual Operating Modes of In-Context Learning

    [https://arxiv.org/abs/2402.18819](https://arxiv.org/abs/2402.18819)

    该论文介绍了In-Context Learning的双重运行模式，通过引入概率模型同时解释了任务学习和任务检索，对线性函数的上下文学习进行了扩展，分析了优化预训练模型在平方损失下的行为，并推导出了任务后验分布的闭式表达式。

    

    In-Context Learning (ICL)展示了双重运行模式：任务学习，即从上下文样本中获取新技能，和任务检索，即查找并激活相关的预训练技能。最近的理论研究探讨了各种数学模型来分析ICL，但现有模型一次只能解释一种操作模式。我们引入了一个概率模型，可以同时解释ICL的双重运行模式。专注于线性函数的上下文学习，通过引入多个任务组和任务相关的输入分布扩展现有模型用于预训练数据。然后分析在平方损失下表现最优的预训练模型的行为，即给定上下文样本标签的最小均方误差估计器。将预训练任务分布视为先验，将上下文示例视为观测值，我们推导出任务后验分布的闭式表达式。

    arXiv:2402.18819v1 Announce Type: new  Abstract: In-context learning (ICL) exhibits dual operating modes: task learning, i.e., acquiring a new skill from in-context samples, and task retrieval, i.e., locating and activating a relevant pretrained skill. Recent theoretical work investigates various mathematical models to analyze ICL, but existing models explain only one operating mode at a time. We introduce a probabilistic model, with which one can explain the dual operating modes of ICL simultaneously. Focusing on in-context learning of linear functions, we extend existing models for pretraining data by introducing multiple task groups and task-dependent input distributions. We then analyze the behavior of the optimally pretrained model under the squared loss, i.e., the MMSE estimator of the label given in-context examples. Regarding pretraining task distribution as prior and in-context examples as the observation, we derive the closed-form expression of the task posterior distribution
    
[^83]: 是否进行数据汇集：分析群体公平训练对共享模型的正则化效果

    To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models

    [https://arxiv.org/abs/2402.18803](https://arxiv.org/abs/2402.18803)

    该研究分析了群体公平训练对共享模型的正则化效果，通过推导群体特定的泛化误差界限以解决不同群体之间的性能差异问题，尤其对于较小的群体规模有显着改进。

    

    在公平机器学习中，导致群体之间性能差异的一个原因是对相对少量训练样本的过度拟合。我们推导了围绕多数群体更大样本量的福利中心公平机器学习的泛化误差的群体特定界限。我们通过考虑受限假设类别上的群体特定Rademacher平均值来实现这一点，该假设类别包含在公平学习目标（例如，幂均值）方面表现良好的模型族。我们的模拟表明，这些界限相对于朴素方法有所改进，这符合理论预期，尤其对于较小的群体规模有显着改进。

    arXiv:2402.18803v1 Announce Type: new  Abstract: In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.
    
[^84]: BlockEcho：保留长距离依赖关系用于填补块状缺失数据

    BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data

    [https://arxiv.org/abs/2402.18800](https://arxiv.org/abs/2402.18800)

    该论文提出了一种名为BlockEcho的新矩阵填充方法，通过将矩阵分解和生成对抗网络相结合，创造性地保留了原始矩阵中的长距离依赖关系，以解决块状缺失数据对数据插值和预测能力的挑战。

    

    arXiv:2402.18800v1 类型：新  摘要：块状缺失数据在实际数据填补任务中带来了显著挑战。与分散的缺失数据相比，块状缺失数据加剧了对后续分析和机器学习任务的不利影响，因为缺乏局部相邻元素显著降低了插值能力和预测能力。然而，这个问题尚未得到充分关注。由于过度依赖邻近元素进行预测，大多数SOTA矩阵填充方法显示出较低的有效性。我们系统地分析了这个问题，并提出了一种新颖的矩阵填充方法“BlockEcho”以提供更全面的解决方案。该方法创造性地将矩阵分解（MF）与生成对抗网络（GAN）相结合，以明确保留原始矩阵中的长距离元素间关系。此外，我们还为GAN引入了一个额外的鉴别器，比较生成器的中间进程。

    arXiv:2402.18800v1 Announce Type: new  Abstract: Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progre
    
[^85]: MPAT: 抗击文本对抗攻击的鲁棒深度神经网络构建

    MPAT: Building Robust Deep Neural Networks against Textual Adversarial Attacks

    [https://arxiv.org/abs/2402.18792](https://arxiv.org/abs/2402.18792)

    提出了一种基于恶意扰动的对抗训练方法（MPAT）来构建鲁棒的深度神经网络，用于抵御文本对抗攻击。

    

    深度神经网络已被证明对于对抗性示例是脆弱的，并且已经提出了各种方法来防御自然语言处理任务的对抗攻击。然而，先前的防御方法在保持有效的防御同时确保原始任务性能方面存在局限性。本文提出了一种基于恶意扰动的对抗训练方法（MPAT），用于构建抵御文本对抗攻击的鲁棒深度神经网络。具体而言，我们构建了一个多级恶意示例生成策略，以生成带有恶意扰动的对抗性示例，这些示例被用来代替模型训练中的原始输入。此外，我们采用了一个新颖的训练目标函数，以确保达到防御目标而不损害原始任务上的性能。我们进行了全面的实验来评估我们的防御方法，通过攻击五个v

    arXiv:2402.18792v1 Announce Type: cross  Abstract: Deep neural networks have been proven to be vulnerable to adversarial examples and various methods have been proposed to defend against adversarial attacks for natural language processing tasks. However, previous defense methods have limitations in maintaining effective defense while ensuring the performance of the original task. In this paper, we propose a malicious perturbation based adversarial training method (MPAT) for building robust deep neural networks against textual adversarial attacks. Specifically, we construct a multi-level malicious example generation strategy to generate adversarial examples with malicious perturbations, which are used instead of original inputs for model training. Additionally, we employ a novel training objective function to ensure achieving the defense goal without compromising the performance on the original task. We conduct comprehensive experiments to evaluate our defense method by attacking five v
    
[^86]: FlexLLM：一种用于共同提供大型语言模型推理和参数高效微调的系统

    FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning

    [https://arxiv.org/abs/2402.18789](https://arxiv.org/abs/2402.18789)

    FlexLLM是第一个可以在同一迭代中共同提供推理和参数高效微调请求的系统，通过引入标记级微调机制实现共享GPU资源的高效利用

    

    Parameter-efficient finetuning（PEFT）是一种广泛使用的技术，用于为不同任务调整大型语言模型。通常，服务提供商会为用户创建单独的系统，以执行PEFT模型微调和推理任务。这是因为现有系统无法处理包含推理和PEFT微调请求混合的工作负载。因此，共享的GPU资源利用不足，导致效率低下。为解决这一问题，我们提出了FlexLLM，这是第一个可以在同一迭代中为推理和参数高效微调请求提供服务的系统。我们的系统利用这两个任务的互补性质，并利用共享的GPU资源来共同运行它们，使用一种称为共同提供的方法。为实现这一目标，FlexLLM引入了一种新颖的标记级微调机制，将序列的微调计算分解为更小的标记级计算，并使用依赖并行化。

    arXiv:2402.18789v1 Announce Type: cross  Abstract: Parameter-efficient finetuning (PEFT) is a widely used technique to adapt large language models for different tasks. Service providers typically create separate systems for users to perform PEFT model finetuning and inference tasks. This is because existing systems cannot handle workloads that include a mix of inference and PEFT finetuning requests. As a result, shared GPU resources are underutilized, leading to inefficiencies. To address this problem, we present FlexLLM, the first system that can serve inference and parameter-efficient finetuning requests in the same iteration. Our system leverages the complementary nature of these two tasks and utilizes shared GPU resources to run them jointly, using a method called co-serving. To achieve this, FlexLLM introduces a novel token-level finetuning mechanism, which breaks down the finetuning computation of a sequence into smaller token-level computations and uses dependent parallelization
    
[^87]: 提升混合专家网络的“免疫力”以抵御对抗性攻击

    Enhancing the "Immunity" of Mixture-of-Experts Networks for Adversarial Defense

    [https://arxiv.org/abs/2402.18787](https://arxiv.org/abs/2402.18787)

    提出了一种名为“免疫力”(Immunity)的新对抗性防御方法，通过修改的专家混合(MoE)架构，结合随机切换门(RSGs)和基于互信息(MI)和位置稳定性的损失函数，增加了专家网络的多样性和因果关系。

    

    近期研究揭示了深度神经网络(DNNs)对抗性示例的易受攻击性，这些示例可以轻松地愚弄DNNs，使其做出错误的预测。为了减少这种缺陷，本文提出了一种基于修改的专家混合(MoE)架构的新型对抗性防御方法称为“免疫力”(Innovative MoE with MUtual information \& positioN stabilITY)。该方法的关键改进有两方面：1)集成随机切换门(RSGs)，在评估时通过随机排列RSG参数获得多样的网络结构，尽管RSGs在经过一次训练后确定；2)利用Grad-CAM的解释能力，通过设计基于互信息(MI)和位置稳定性的损失函数，增加专家网络的多样性和因果关系。值得注意的是，我们的基于MI的损失直接在热图上运行，从而诱导出更微妙的负向特征。

    arXiv:2402.18787v1 Announce Type: new  Abstract: Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs) to adversarial examples, which can easily fool DNNs into making incorrect predictions. To mitigate this deficiency, we propose a novel adversarial defense method called "Immunity" (Innovative MoE with MUtual information \& positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture in this work. The key enhancements to the standard MoE are two-fold: 1) integrating of Random Switch Gates (RSGs) to obtain diverse network structures via random permutation of RSG parameters at evaluation time, despite of RSGs being determined after one-time training; 2) devising innovative Mutual Information (MI)-based and Position Stability-based loss functions by capitalizing on Grad-CAM's explanatory power to increase the diversity and the causality of expert networks. Notably, our MI-based loss operates directly on the heatmaps, thereby inducing subtler negati
    
[^88]: 具有一级信念的假设在线学习在不对称信息随机博弈中的应用

    Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games

    [https://arxiv.org/abs/2402.18781](https://arxiv.org/abs/2402.18781)

    提出了一种具有假设在线学习（COL）的学习方案，针对通用AISG，结构化为一个先验预测者-演员-评论家（FAC）架构，利用一级信念和对手策略的主观预测，通过在线展开更新策略，并通过贝叶斯学习校准假设。

    

    随机博弈出现在许多复杂的社会技术系统中，如网络物理系统和IT基础设施，信息不对称为决策实体（玩家）的决策带来挑战。现有的不对称信息随机博弈（AISG）的计算方法主要是离线的，针对特殊类别的AISG，以避免信念层次，并且缺乏适应均衡偏差的在线能力。为了解决这一限制，我们提出了一种具有假设在线学习（COL）的学习方案，专门针对通用AISG。COL结构化为一个先验预测者-演员-评论家（FAC）架构，利用对隐藏状态的一级信念和对对手策略的主观预测。针对假设的对手，COL通过在线展开更新策略，并通过贝叶斯学习校准假设。我们证明了COL中的假设与t一致。

    arXiv:2402.18781v1 Announce Type: cross  Abstract: Stochastic games arise in many complex socio-technical systems, such as cyber-physical systems and IT infrastructures, where information asymmetry presents challenges for decision-making entities (players). Existing computational methods for asymmetric information stochastic games (AISG) are primarily offline, targeting special classes of AISGs to avoid belief hierarchies, and lack online adaptability to deviations from equilibrium. To address this limitation, we propose a conjectural online learning (COL), a learning scheme for generic AISGs. COL, structured as a forecaster-actor-critic (FAC) architecture, utilizes first-order beliefs over the hidden states and subjective forecasts of the opponent's strategies. Against the conjectured opponent, COL updates strategies in an actor-critic approach using online rollout and calibrates conjectures through Bayesian learning. We prove that conjecture in COL is asymptotically consistent with t
    
[^89]: 解开神经网络中可塑性丧失的原因

    Disentangling the Causes of Plasticity Loss in Neural Networks

    [https://arxiv.org/abs/2402.18762](https://arxiv.org/abs/2402.18762)

    这篇论文研究了神经网络中可塑性丧失的原因，探讨了不稳定性的根源以及如何结合减轻策略以保持网络的可训练性。

    

    设计、初始化和优化神经网络的过去几十年的工作的基础是一个看似无关紧要的假设：网络是在一个\textit{固定的}数据分布上进行训练的。在违反这一假设的情况下，例如在深度强化学习中，学习算法对超参数甚至随机种子变得不稳定和脆弱。导致这种不稳定性的一个因素是可塑性的丢失，这意味着随着训练的进行，更新网络的预测以应对新信息变得更加困难。尽管许多最近的研究对这种现象进行了分析并提出了部分解决方案，但一个基本问题仍然没有得到回答：已知的可塑性丧失机制在多大程度上重叠，以及如何结合减轻策略才能最好地维持网络的可训练性？本文解决了这些问题，展示了可塑性丧失可以被解除。

    arXiv:2402.18762v1 Announce Type: new  Abstract: Underpinning the past decades of work on the design, initialization, and optimization of neural networks is a seemingly innocuous assumption: that the network is trained on a \textit{stationary} data distribution. In settings where this assumption is violated, e.g.\ deep reinforcement learning, learning algorithms become unstable and brittle with respect to hyperparameters and even random seeds. One factor driving this instability is the loss of plasticity, meaning that updating the network's predictions in response to new information becomes more difficult as training progresses. While many recent works provide analyses and partial solutions to this phenomenon, a fundamental question remains unanswered: to what extent do known mechanisms of plasticity loss overlap, and how can mitigation strategies be combined to best maintain the trainability of a network? This paper addresses these questions, showing that loss of plasticity can be dec
    
[^90]: 基于语言引导的状态抽象学习

    Learning with Language-Guided State Abstractions

    [https://arxiv.org/abs/2402.18759](https://arxiv.org/abs/2402.18759)

    利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。

    

    我们描述了一个利用自然语言设计状态抽象用于模仿学习的框架。在高维观测空间中实现泛化策略学习的关键在于精心设计的状态表示，这可以将环境中的重要特征展现出来并隐藏不相关的特征。这些状态表示通常是手动指定的，或者是从其他繁重的标记过程中导出的。我们的方法LGA（语言引导的抽象）利用自然语言监督和语言模型的背景知识的结合自动构建适用于未见任务的状态表示。在LGA中，用户首先使用自然语言提供目标任务的（可能是不完整的）描述；接下来，一个预训练的语言模型将这个任务描述转化为掩盖不相关特征的状态抽象函数；最后，使用少量演示数据训练一个模仿策略。

    arXiv:2402.18759v1 Announce Type: cross  Abstract: We describe a framework for using natural language to design state abstractions for imitation learning. Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. Our method, LGA (language-guided abstraction), uses a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demo
    
[^91]: 使用有限公共数据对有差异隐私的模型进行预训练

    Pre-training Differentially Private Models with Limited Public Data

    [https://arxiv.org/abs/2402.18752](https://arxiv.org/abs/2402.18752)

    通过使用有限的公共数据，研究者提出了一种新颖的差分隐私持续预训练策略，以显著缓解优化器性能下降。

    

    大型基础模型卓越的性能依赖于大量高质量数据的使用，然而这些数据通常包含需要正式保护的敏感、私人和受版权保护的信息。差分隐私是一种用于衡量模型提供的安全程度的重要方法，然而由于在预训练阶段应用差分隐私会导致性能下降，因此其应用通常仅限于模型微调阶段。因此，差分隐私目前尚不能保护初始预训练过程中使用的大部分数据。在这项工作中，我们首先通过分析每次迭代的损失改进，对差分隐私训练的有效性提供了理论理解。我们观察到，通过使用有限的公共数据，可以显著缓解差分隐私优化器的性能下降，从而引出一种新颖的差分隐私持续预训练策略。在实证方面，通过

    arXiv:2402.18752v1 Announce Type: new  Abstract: The superior performance of large foundation models relies on the use of massive amounts of high-quality data, which often contain sensitive, private and copyrighted material that requires formal protection. While differential privacy (DP) is a prominent method to gauge the degree of security provided to the models, its application is commonly limited to the model fine-tuning stage, due to the performance degradation when applying DP during the pre-training stage. Consequently, DP is yet not capable of protecting a substantial portion of the data used during the initial pre-training process.   In this work, we first provide a theoretical understanding of the efficacy of DP training by analyzing the per-iteration loss improvement. We make a key observation that DP optimizers' performance degradation can be significantly mitigated by the use of limited public data, which leads to a novel DP continual pre-training strategy. Empirically, usi
    
[^92]: 多传感器和多时间高通量表型鉴定技术用于盐胁迫监测和早期检测大豆水分限制性胁迫

    Multi-Sensor and Multi-temporal High-Throughput Phenotyping for Monitoring and Early Detection of Water-Limiting Stress in Soybean

    [https://arxiv.org/abs/2402.18751](https://arxiv.org/abs/2402.18751)

    该研究结合多模式信息，开发了快速分类大豆干旱胁迫症状的自动化方法，并研究了干旱胁迫的早期检测方法。

    

    大豆生产容易受到生物性和非生物性胁迫的影响，在极端天气事件的加剧下更是如此。水分限制性胁迫，即干旱，成为大豆生产一个重要风险，强调了对作物育种和生产中胁迫监测的需求。本项目结合多模式信息，确定了最有效和高效的自动化方法，用于研究干旱响应。我们以多传感器和时间序列高通量表型方式调查了一组不同的大豆种质，旨在：（1）开发用于快速分类大豆干旱胁迫症状的流程，以及（2）研究干旱胁迫早期检测的方法。我们利用了高通量时间序列表型技术，结合无人机和传感器以及机器学习（ML）分析，提供了快速有效的表型方法。红缘和绿波段对于

    arXiv:2402.18751v1 Announce Type: new  Abstract: Soybean production is susceptible to biotic and abiotic stresses, exacerbated by extreme weather events. Water limiting stress, i.e. drought, emerges as a significant risk for soybean production, underscoring the need for advancements in stress monitoring for crop breeding and production. This project combines multi-modal information to identify the most effective and efficient automated methods to investigate drought response. We investigated a set of diverse soybean accessions using multiple sensors in a time series high-throughput phenotyping manner to: (1) develop a pipeline for rapid classification of soybean drought stress symptoms, and (2) investigate methods for early detection of drought stress. We utilized high-throughput time-series phenotyping using UAVs and sensors in conjunction with machine learning (ML) analytics, which offered a swift and efficient means of phenotyping. The red-edge and green bands were most effective to
    
[^93]: 通过机器学习加速计算机体系结构模拟

    Accelerating Computer Architecture Simulation through Machine Learning

    [https://arxiv.org/abs/2402.18746](https://arxiv.org/abs/2402.18746)

    通过机器学习技术加速计算机体系结构模拟，利用应用程序特征和微体系结构特征的组合来预测性能，有效地提高了体系结构探索的速度，并展示了在测试数据中预测IPC值的能力。

    

    本文介绍了我们利用机器学习技术加速计算机体系结构模拟的方法。传统的计算机体系结构模拟耗时较长，使得高效地探索不同设计选择变得具有挑战性。我们提出的模型利用应用程序特征和微体系结构特征的组合来预测应用程序的性能。这些特征来源于应用程序的一小部分的模拟。我们通过构建和评估一个机器学习模型来展示我们方法的有效性，该模型在体系结构探索中提供了显著的加速。该模型展示了在测试数据中预测IPC值的能力，均方根误差小于0.1。

    arXiv:2402.18746v1 Announce Type: cross  Abstract: This paper presents our approach to accelerate computer architecture simulation by leveraging machine learning techniques. Traditional computer architecture simulations are time-consuming, making it challenging to explore different design choices efficiently. Our proposed model utilizes a combination of application features and micro-architectural features to predict the performance of an application. These features are derived from simulations of a small portion of the application. We demonstrate the effectiveness of our approach by building and evaluating a machine learning model that offers significant speedup in architectural exploration. This model demonstrates the ability to predict IPC values for the testing data with a root mean square error of less than 0.1.
    
[^94]: 编译器大型语言模型的优先采样

    Priority Sampling of Large Language Models for Compilers

    [https://arxiv.org/abs/2402.18734](https://arxiv.org/abs/2402.18734)

    提出了一种优先采样技术，能够按照模型信心度产生唯一样本，在生成和优化代码时表现优于核采样方法。

    

    大型语言模型在生成和优化代码方面表现出巨大潜力。广泛使用的采样方法，比如核采样（Nucleus Sampling），增加了生成的多样性，但在低温度下经常产生重复的样本，在高温度下产生不连贯的样本。此外，温度系数必须针对每个任务进行调整，限制了其可用性。我们提出了优先采样（Priority Sampling），一种简单且确定性的采样技术，它产生按模型置信度排序的唯一样本。每个新样本都会扩展扩展搜索树中概率最高的未扩展令牌。此外，优先采样支持基于正则表达式的生成，提供可控和结构化的探索过程。优先采样在任意数量的样本情况下均优于核采样，将原始模型的性能从2.87%提升至5%超过-Oz。此外，它超过了自

    arXiv:2402.18734v1 Announce Type: cross  Abstract: Large language models show great potential in generating and optimizing code. Widely used sampling methods such as Nucleus Sampling increase the diversity of generation but often produce repeated samples for low temperatures and incoherent samples for high temperatures. Furthermore, the temperature coefficient has to be tuned for each task, limiting its usability. We present Priority Sampling, a simple and deterministic sampling technique that produces unique samples ordered by the model's confidence. Each new sample expands the unexpanded token with the highest probability in the augmented search tree. Additionally, Priority Sampling supports generation based on regular expression that provides a controllable and structured exploration process. Priority Sampling outperforms Nucleus Sampling for any number of samples, boosting the performance of the original model from 2.87% to 5% improvement over -Oz. Moreover, it outperforms the auto
    
[^95]: GAIA: 生成AI的范畴基础

    GAIA: Categorical Foundations of Generative AI

    [https://arxiv.org/abs/2402.18732](https://arxiv.org/abs/2402.18732)

    提出了一种基于范畴论的生成AI架构GAIA，采用层次模型和单纯复合体组织模块，将参数更新建模为单纯集上的提升图表，并采用余代数的形式进行深度学习。

    

    在本文中，我们提出了GAIA，一种基于范畴论的生成AI架构。GAIA基于一个层次模型，其中模块被组织为一个单纯复合体。每个单纯复合体根据从其上级单纯体接收到的信息更新其内部参数，并将更新传递给其下级子单纯体。参数更新以单纯集上的提升图表的形式进行，其中内部和外部角扩展对应不同类型的学习问题。反向传播被建模为参数范畴上的一个自函子，导致深度学习的一个余代数形式。

    arXiv:2402.18732v1 Announce Type: new  Abstract: In this paper, we propose GAIA, a generative AI architecture based on category theory. GAIA is based on a hierarchical model where modules are organized as a simplicial complex. Each simplicial complex updates its internal parameters biased on information it receives from its superior simplices and in turn relays updates to its subordinate sub-simplices. Parameter updates are formulated in terms of lifting diagrams over simplicial sets, where inner and outer horn extensions correspond to different types of learning problems. Backpropagation is modeled as an endofunctor over the category of parameters, leading to a coalgebraic formulation of deep learning.
    
[^96]: 利用贝叶斯神经网络对反应湍流封闭模型进行先验不确定性量化

    A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks

    [https://arxiv.org/abs/2402.18729](https://arxiv.org/abs/2402.18729)

    使用贝叶斯神经网络对反应流动模型中的不确定性进行量化，特别是在湍涡预混火焰动态中关键变量的建模方面取得重要进展

    

    虽然为大涡模拟（LES）中的子滤波尺度（SFS）提出了许多基于物理的封闭模型形式，但直接数值模拟（DNS）提供的大量数据为利用数据驱动建模技术创造了机会。尽管灵活，数据驱动模型仍取决于选择的数据集和模型的函数形式。采用这种模型的增加需要可靠地估计数据驱动模型中数据知识和超出分布范围的不确定性。在本工作中，我们利用贝叶斯神经网络（BNNs）来捕捉反应流动模型中的逻辑不确定性和偶然不确定性。特别是，我们模拟了在湍涡预混火焰动态中起关键作用的滤波进展变量标量耗散率。我们展示了BNN模型可以提供关于数据驱动封闭模型的不确定性结构的独特见解。我们还提出了一种方法来进行...

    arXiv:2402.18729v1 Announce Type: cross  Abstract: While many physics-based closure model forms have been posited for the sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data available from direct numerical simulation (DNS) create opportunities to leverage data-driven modeling techniques. Albeit flexible, data-driven models still depend on the dataset and the functional form of the model chosen. Increased adoption of such models requires reliable uncertainty estimates both in the data-informed and out-of-distribution regimes. In this work, we employ Bayesian neural networks (BNNs) to capture both epistemic and aleatoric uncertainties in a reacting flow model. In particular, we model the filtered progress variable scalar dissipation rate which plays a key role in the dynamics of turbulent premixed flames. We demonstrate that BNN models can provide unique insights about the structure of uncertainty of the data-driven closure models. We also propose a method for the
    
[^97]: 揭示隐私、记忆和输入曲率之间的联系

    Unveiling Privacy, Memorization, and Input Curvature Links

    [https://arxiv.org/abs/2402.18726](https://arxiv.org/abs/2402.18726)

    本研究揭示了记忆与输入损失曲率之间的联系，并建立了差分隐私、记忆和输入损失曲率之间的理论联系。

    

    深度神经网络(DNNs)已成为解决许多新兴问题的普遍工具。然而，它们往往会过度拟合和记忆训练集。记忆是一个备受关注的问题，因为它与诸多概念如泛化、有噪学习和隐私密切相关。最近的研究显示了输入损失曲率（通过损失Hessian矩阵对输入的迹进行测量）与记忆之间的经验性联系。它被证明比计算记忆分数要高效约3个数量级。然而，目前缺乏将记忆与输入损失曲率联系起来的理论理解。本文不仅研究了这种联系，还扩展了我们的分析，建立了差分隐私、记忆和输入损失曲率之间的理论联系。

    arXiv:2402.18726v1 Announce Type: cross  Abstract: Deep Neural Nets (DNNs) have become a pervasive tool for solving many emerging problems. However, they tend to overfit to and memorize the training set. Memorization is of keen interest since it is closely related to several concepts such as generalization, noisy learning, and privacy. To study memorization, Feldman (2019) proposed a formal score, however its computational requirements limit its practical use. Recent research has shown empirical evidence linking input loss curvature (measured by the trace of the loss Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of magnitude more efficient than calculating the memorization score. However, there is a lack of theoretical understanding linking memorization with input loss curvature. In this paper, we not only investigate this connection but also extend our analysis to establish theoretical links between differential privacy, memorization, and input loss curvature. F
    
[^98]: 使用梯度下降学习关联记忆

    Learning Associative Memories with Gradient Descent

    [https://arxiv.org/abs/2402.18724](https://arxiv.org/abs/2402.18724)

    该论文研究了一个关联记忆模块的训练动态，通过理论和实验揭示了在过参数化和欠参数化情况下的学习动态和误差特性。

    

    这项工作主要关注存储标记嵌入的外积的一个关联记忆模块的训练动态。我们将这个问题简化为研究一个粒子系统，这些粒子根据数据分布的特性以及嵌入之间的相关性进行交互。通过理论和实验，我们提供了一些见解。在过参数化的情况下，我们获得了“分类边界”的对数增长。然而，我们表明标记频率的不平衡和由相关嵌入导致的内存干扰会导致振荡的瞬态区域。振荡在步长较大时更为明显，这可能导致良性损失峰，尽管这些学习率加速了动态并加速了渐近收敛。在欠参数化的情况下，我们阐明了交叉熵损失如何导致次优的记忆方案。最后，我们评估了我们发现的在小规模Tr上的有效性。

    arXiv:2402.18724v1 Announce Type: cross  Abstract: This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Tr
    
[^99]: 学习在自然语言格式中压缩提示

    Learning to Compress Prompt in Natural Language Formats

    [https://arxiv.org/abs/2402.18700](https://arxiv.org/abs/2402.18700)

    该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。

    

    大型语言模型（LLMs）擅长处理多个自然语言处理任务，但它们的能力受到长上下文、推理速度慢以及计算结果成本高的限制。部署具有精确和信息丰富上下文的LLMs有助于用户更有效和更具成本效益地处理大规模数据集。现有作品依赖将长提示上下文压缩为软提示。然而，软提示压缩在不同LLM之间的可转移性受到限制，尤其是基于API的LLMs。因此，本研究旨在以LLM可转移性的形式压缩长提示的自然语言形式。这带来两个挑战：(i) 自然语言（NL）提示不兼容反向传播，(ii) NL提示在施加长度约束方面缺乏灵活性。在本研究中，我们提出了一种自然语言提示封装（Nano-Capsulator）框架

    arXiv:2402.18700v1 Announce Type: cross  Abstract: Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft prompt compression encounters limitations in transferability across different LLMs, especially API-based LLMs. To this end, this work aims to compress lengthy prompts in the form of natural language with LLM transferability. This poses two challenges: (i) Natural Language (NL) prompts are incompatible with back-propagation, and (ii) NL prompts lack flexibility in imposing length constraints. In this work, we propose a Natural Language Prompt Encapsulation (Nano-Capsulator) framewor
    
[^100]: 从边际推断动态网络的方法：迭代比例拟合

    Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting

    [https://arxiv.org/abs/2402.18697](https://arxiv.org/abs/2402.18697)

    通过识别一个生成网络模型，我们建立了一个设置，IPF可以恢复最大似然估计，揭示了关于在这种设置中使用IPF的隐含假设，并可以为IPF的参数估计提供结构相关的误差界。

    

    来自现实数据约束的常见网络推断问题是如何从时间聚合的邻接矩阵和时间变化边际（即行向量和列向量之和）推断动态网络。先前的方法为了解决这个问题重新利用了经典的迭代比例拟合（IPF）过程，也称为Sinkhorn算法，并取得了令人满意的经验结果。然而，使用IPF的统计基础尚未得到很好的理解：在什么情况下，IPF提供了从边际准确估计动态网络的原则性，以及它在多大程度上估计了网络？在这项工作中，我们确定了这样一个设置，通过识别一个生成网络模型，IPF可以恢复其最大似然估计。我们的模型揭示了关于在这种设置中使用IPF的隐含假设，并使得可以进行新的分析，如有关IPF参数估计的结构相关误差界。当IPF失败时

    arXiv:2402.18697v1 Announce Type: cross  Abstract: A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to c
    
[^101]: VOROS：将ROC曲线提升到3D

    The VOROS: Lifting ROC curves to 3D

    [https://arxiv.org/abs/2402.18689](https://arxiv.org/abs/2402.18689)

    引入第三维度，将ROC曲线提升为ROC曲面，提出VOROS作为2D ROC曲线下面积的3D泛化，可以更好地捕捉不同分类器的成本。

    

    ROC曲线下面积是一个常用的度量，通常用于排列不同二元分类器的相对性能。然而，正如以前所指出的，当真实类值或误分类成本在两个类别之间高度不平衡时，它可能无法准确捕捉不同分类器的效益。我们引入第三维来捕获这些成本，并以一种自然的方式将ROC曲线提升为ROC曲面。我们研究了这个曲面，并引入了VOROS，即ROC曲面上方的体积，作为2D ROC曲线下面积的3D泛化。对于存在预期成本或类别不平衡边界的问题，我们限制考虑适当子区域的ROC曲面的体积。我们展示了VOROS如何在经典和现代示例数据集上更好地捕捉不同分类器的成本。

    arXiv:2402.18689v1 Announce Type: new  Abstract: The area under the ROC curve is a common measure that is often used to rank the relative performance of different binary classifiers. However, as has been also previously noted, it can be a measure that ill-captures the benefits of different classifiers when either the true class values or misclassification costs are highly unbalanced between the two classes. We introduce a third dimension to capture these costs, and lift the ROC curve to a ROC surface in a natural way. We study both this surface and introduce the VOROS, the volume over this ROC surface, as a 3D generalization of the 2D area under the ROC curve. For problems where there are only bounds on the expected costs or class imbalances, we restrict consideration to the volume of the appropriate subregion of the ROC surface. We show how the VOROS can better capture the costs of different classifiers on both a classical and a modern example dataset.
    
[^102]: 数据解释器：用于数据科学的LLM代理

    Data Interpreter: An LLM Agent For Data Science

    [https://arxiv.org/abs/2402.18679](https://arxiv.org/abs/2402.18679)

    本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。

    

    大型语言模型（LLM）代理已表现出显著的有效性。然而，在需要实时数据调整、优化专业知识以应对各种任务间复杂依赖性以及精确推理的逻辑错误识别的数据科学场景中，它们的性能可能会受到影响。本研究介绍了数据解释器，这是一个设计用于解决强调三种关键技术以增强数据科学中问题解决的方案的代码：1）具有分层图结构的动态规划，用于实时数据适应性；2）工具集成动态化，以增强代码执行过程中的熟练度，丰富必要的专业知识；3）在反馈中识别逻辑不一致性，并通过经验记录来提高效率。我们评估了数据解释器在各种数据科学和现实任务上的表现。与开源基线相比，它展现了s

    arXiv:2402.18679v1 Announce Type: new  Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated s
    
[^103]: 简单的线性注意力语言模型平衡了召回-吞吐量的折衷

    Simple linear attention language models balance the recall-throughput tradeoff

    [https://arxiv.org/abs/2402.18668](https://arxiv.org/abs/2402.18668)

    提出了一种简单的线性注意力语言模型架构，可以平衡召回和内存消耗之间的权衡。

    

    最近的研究表明，基于注意力的语言模型擅长召回，即在上下文中已经看到的标记。然而，在推断过程中，基于注意力的模型的效率受到KV-cache的内存消耗的瓶颈限制。在这项工作中，我们探讨了是否可以提高语言模型的效率（例如通过减少内存消耗）而不影响召回。通过将实验和理论应用于广泛的架构，我们确定了模型状态大小和召回能力之间的一个关键权衡。我们发现，与注意力的高效替代方法（例如H3、Mamba、RWKV）保持固定大小的循环状态，但在召回方面表现不佳。我们提出了BASED，这是一种结合了线性和滑动窗口注意力的简单架构。通过改变BASED窗口大小和线性注意力特征维度，我们可以调整状态大小，并遍历召回-内存折衷的帕累托前沿。

    arXiv:2402.18668v1 Announce Type: new  Abstract: Recent work has shown that attention-based language models excel at recall, the ability to ground generations in tokens previously seen in context. However, the efficiency of attention-based models is bottle-necked during inference by the KV-cache's aggressive memory consumption. In this work, we explore whether we can improve language model efficiency (e.g. by reducing memory consumption) without compromising on recall. By applying experiments and theory to a broad set of architectures, we identify a key tradeoff between a model's state size and recall ability. We show that efficient alternatives to attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but struggle at recall. We propose BASED a simple architecture combining linear and sliding window attention. By varying BASED window size and linear attention feature dimension, we can dial the state size and traverse the pareto frontier of the recall-memory tradeoff cu
    
[^104]: 量化人类对社交和导航网络的先验知识

    Quantifying Human Priors over Social and Navigation Networks

    [https://arxiv.org/abs/2402.18651](https://arxiv.org/abs/2402.18651)

    本研究利用图的组合结构来量化人类对社交和导航网络的先验知识，揭示了一些一致的特征和特定领域的倾向，为高效建模数据中的潜在偏见提供了方法。

    

    人类知识主要是隐含的和关系型的 —— 我们是否有共同的朋友？我能从这里走到那里吗？本研究利用图的组合结构来量化人类对这种关系数据的先验知识。我们的实验着重于两个在进化时间尺度上持续相关的领域：社交互动和空间导航。我们发现一些推断得到的先验知识特征非常一致，例如稀疏性倾向随着图的大小变化。其他特征是特定于领域的，例如社交互动中的三元闭合倾向。更广泛地，我们的工作展示了如何利用间接行为实验的非经典统计分析来高效建模数据中的潜在偏见。

    arXiv:2402.18651v1 Announce Type: cross  Abstract: Human knowledge is largely implicit and relational -- do we have a friend in common? can I walk from here to there? In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. Other features are domain-specific, such as the propensity for triadic closure in social interactions. More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.
    
[^105]: 使用成本函数调节多站定位和图神经网络的GNSS定位

    GNSS Positioning using Cost Function Regulated Multilateration and Graph Neural Networks

    [https://arxiv.org/abs/2402.18630](https://arxiv.org/abs/2402.18630)

    使用图神经网络替代传统误差估计方法，并通过分析多站定位过程的成本函数，提出一种优化方法，显著改善了GNSS定位精度。

    

    在城市环境中，GNSS卫星的视距信号经常被高层建筑物阻挡，导致GNSS接收机在测量卫星距离时产生较大误差。我们的研究用基于图神经网络的深度学习模型取代了传统的误差估计启发式方法。此外，通过分析多站定位过程的成本函数，我们提出了一种利用估计误差的最优方法。我们的方法确保在误差估计准确度提高时，多站定位将收敛到接收机位置。我们在一个真实数据集上评估了我们的解决方案，该数据集包含来自多个城市、不同特性的10万多个GNSS历元。实证结果显示水平定位误差的改进范围为40%到80%。

    arXiv:2402.18630v1 Announce Type: new  Abstract: In urban environments, where line-of-sight signals from GNSS satellites are frequently blocked by high-rise objects, GNSS receivers are subject to large errors in measuring satellite ranges. Heuristic methods are commonly used to estimate these errors and reduce the impact of noisy measurements on localization accuracy. In our work, we replace these error estimation heuristics with a deep learning model based on Graph Neural Networks. Additionally, by analyzing the cost function of the multilateration process, we derive an optimal method to utilize the estimated errors. Our approach guarantees that the multilateration converges to the receiver's location as the error estimation accuracy increases. We evaluate our solution on a real-world dataset containing more than 100k GNSS epochs, collected from multiple cities with diverse characteristics. The empirical results show improvements from 40% to 80% in the horizontal localization error ag
    
[^106]: ELA：零和博弈中融入利用水平的离线学习

    ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games

    [https://arxiv.org/abs/2402.18617](https://arxiv.org/abs/2402.18617)

    该研究提出了一种新颖的方法，利用无监督学习技术估计不同示范者制作的零和博弈离线数据集中每条轨迹的被利用水平，并将其融入离线学习以最大化支配策略的影响力。

    

    离线学习由于能够从专家示范者收集的离线数据集中推导出有效策略而不需要直接与环境进行交互，已经被广泛使用。最近的研究探索了通过考虑数据集的特征（例如，专业水平或多个示范者）来增强离线学习效率的各种方式。然而，在零和博弈的背景下，需要一种不同的方法，因为结果根据对手的策略而显著变化。在本研究中，我们介绍了一种新颖的方法，利用无监督学习技术估计由不同示范者制作的零和博弈的离线数据集中每条轨迹的被利用水平。随后，我们将估计的被利用水平结合到离线学习中，以最大化支配策略的影响力。我们的方法实现了在多个示范者的零和博弈离线数据集中可解释的被利用水平估计。

    arXiv:2402.18617v1 Announce Type: cross  Abstract: Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple z
    
[^107]: 用固定的随机分类器训练的深度神经网络模型在不同领域之间转移更好

    Deep Neural Network Models Trained With A Fixed Random Classifier Transfer Better Across Domains

    [https://arxiv.org/abs/2402.18614](https://arxiv.org/abs/2402.18614)

    DNN模型利用ETF进行训练，在最后一层权重固定的情况下，显著提高了跨域数据集上的转移性能。

    

    最近发现的神经坍缩（NC）现象表明，深度神经网络（DNN）的最后一层权重在训练的最后阶段会收敛到所谓的等角紧框架（ETF）单纯形。这种ETF几何形状相当于最后一层激活的类内变化消失。受NC属性启发，本文探讨了使用最后一层权重固定为ETF的DNN模型的可转移性。这通过消除类协方差信息强化了类别分离，有效提供了隐式正则化。我们展示了使用这种固定分类器训练的DNN模型显著改善了转移性能，特别是在跨领域数据集上。在广泛的细粒度图像分类数据集上，我们的方法优于没有执行任何协方差正则化的基线方法（高达22%），以及明确方法

    arXiv:2402.18614v1 Announce Type: new  Abstract: The recently discovered Neural collapse (NC) phenomenon states that the last-layer weights of Deep Neural Networks (DNN), converge to the so-called Equiangular Tight Frame (ETF) simplex, at the terminal phase of their training. This ETF geometry is equivalent to vanishing within-class variability of the last layer activations. Inspired by NC properties, we explore in this paper the transferability of DNN models trained with their last layer weight fixed according to ETF. This enforces class separation by eliminating class covariance information, effectively providing implicit regularization. We show that DNN models trained with such a fixed classifier significantly improve transfer performance, particularly on out-of-domain datasets. On a broad range of fine-grained image classification datasets, our approach outperforms i) baseline methods that do not perform any covariance regularization (up to 22%), as well as ii) methods that explici
    
[^108]: 理解随机森林和过拟合：一项可视化和模拟研究

    Understanding random forests and overfitting: a visualization and simulation study

    [https://arxiv.org/abs/2402.18612](https://arxiv.org/abs/2402.18612)

    这项研究通过可视化和模拟研究探讨了随机森林的行为，发现在训练集存在过拟合的情况下，模型在测试数据上表现出了竞争力。

    

    随机森林在临床风险预测建模中变得流行。在一项关于预测卵巢恶性的案例研究中，我们观察到训练集上的c-统计值接近1。尽管这表明存在过拟合，但在测试数据上表现竞争力。我们旨在通过（1）在三个真实案例研究中可视化数据空间和（2）进行模拟研究来理解随机森林的行为。在案例研究中，使用热力图在二维子空间中可视化风险估计。模拟研究包括48个逻辑数据生成机制（DGM），变化预测变量分布、预测变量数量、预测变量之间的相关性、真实c-统计值和真实预测变量的强度。对于每个DGM，模拟生成大小为200或4000的1000个训练数据集，并使用ranger包训练最小节点大小为2或20的随机森林模型，总共得到了192个场景。可视化结果表明，模型…

    arXiv:2402.18612v1 Announce Type: cross  Abstract: Random forests have become popular for clinical risk prediction modelling. In a case study on predicting ovarian malignancy, we observed training c-statistics close to 1. Although this suggests overfitting, performance was competitive on test data. We aimed to understand the behaviour of random forests by (1) visualizing data space in three real world case studies and (2) a simulation study. For the case studies, risk estimates were visualised using heatmaps in a 2-dimensional subspace. The simulation study included 48 logistic data generating mechanisms (DGM), varying the predictor distribution, the number of predictors, the correlation between predictors, the true c-statistic and the strength of true predictors. For each DGM, 1000 training datasets of size 200 or 4000 were simulated and RF models trained with minimum node size 2 or 20 using ranger package, resulting in 192 scenarios in total. The visualizations suggested that the mod
    
[^109]: HemaGraph：利用图注意力突破血液学单细胞分类的障碍

    HemaGraph: Breaking Barriers in Hematologic Single Cell Classification with Graph Attention

    [https://arxiv.org/abs/2402.18611](https://arxiv.org/abs/2402.18611)

    HemaGraph利用图注意力网络实现了从流式细胞术数据中对血液学单细胞进行准确分类，尤其在处理巨大图以检测低频细胞群体方面表现出色。

    

    在血液学细胞群分类领域，流式细胞术数据中的复杂模式要求使用先进的分析工具。本文提出了基于图注意力网络（GATs）的新框架“HemaGraph”，用于从流式细胞术数据中对血液学细胞进行单细胞多类别分类。利用GATs的强大能力，我们的方法捕捉微小的细胞关系，提供高度准确的患者画像。通过对30名患者数据的评估，HemaGraph展示了跨五个不同细胞类别的分类性能，胜过传统方法和最先进的方法。此外，该框架的独特之处在于HemaGraph的训练和测试阶段，它已被应用于包含高达数十万个节点和两百万条边的极大图形，以检测低频细胞群体（例如一个群体的0.01%）

    arXiv:2402.18611v1 Announce Type: cross  Abstract: In the realm of hematologic cell populations classification, the intricate patterns within flow cytometry data necessitate advanced analytical tools. This paper presents 'HemaGraph', a novel framework based on Graph Attention Networks (GATs) for single-cell multi-class classification of hematological cells from flow cytometry data. Harnessing the power of GATs, our method captures subtle cell relationships, offering highly accurate patient profiling. Based on evaluation of data from 30 patients, HemaGraph demonstrates classification performance across five different cell classes, outperforming traditional methodologies and state-of-the-art methods. Moreover, the uniqueness of this framework lies in the training and testing phase of HemaGraph, where it has been applied for extremely large graphs, containing up to hundreds of thousands of nodes and two million edges, to detect low frequency cell populations (e.g. 0.01% for one population
    
[^110]: 为什么关注图形就足够了：LeukoGraph的造血细胞群体的层次分类先驱

    Why Attention Graphs Are All We Need: Pioneering Hierarchical Classification of Hematologic Cell Populations with LeukoGraph

    [https://arxiv.org/abs/2402.18610](https://arxiv.org/abs/2402.18610)

    LeukoGraph是一个使用图注意力网络实现细胞群体的层次分类的先驱方法，可以处理大规模的数据集，并解决复杂数据集中细胞群体的层次结构挑战。

    

    在血液学样本的复杂景观中，如外周血或骨髓，细胞分类将不同种群划分为分层结构，对此提出了 LeukoGraph，这是一个专门设计用于这一目的的新框架，利用图注意力网络 (GATs) 来应对层次分类的复杂性。LeukoGraph标志着图神经网络 (GNNs) 应用于图的层次推理的先驱努力，可以处理高达一百万个节点和成百万条边，全部来自流式细胞术数据。LeukoGraph 以精密的方式解决了一个分类范式，例如四种不同细胞群体经过扁平分类，而第五种则分成两个不同的子分支，展示了复杂数据集中固有的微妙层次结构。

    arXiv:2402.18610v1 Announce Type: new  Abstract: In the complex landscape of hematologic samples such as peripheral blood or bone marrow, cell classification, delineating diverse populations into a hierarchical structure, presents profound challenges. This study presents LeukoGraph, a recently developed framework designed explicitly for this purpose employing graph attention networks (GATs) to navigate hierarchical classification (HC) complexities. Notably, LeukoGraph stands as a pioneering effort, marking the application of graph neural networks (GNNs) for hierarchical inference on graphs, accommodating up to one million nodes and millions of edges, all derived from flow cytometry data. LeukoGraph intricately addresses a classification paradigm where for example four different cell populations undergo flat categorization, while a fifth diverges into two distinct child branches, exemplifying the nuanced hierarchical structure inherent in complex datasets. The technique is more general 
    
[^111]: ICE-SEARCH: 一种基于语言模型驱动的特征选择方法

    ICE-SEARCH: A Language Model-Driven Feature Selection Approach

    [https://arxiv.org/abs/2402.18609](https://arxiv.org/abs/2402.18609)

    ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。

    

    本研究揭示了In-Context Evolutionary Search (ICE-SEARCH)方法，这是首个将语言模型(LMs)与进化算法相结合用于特征选择(FS)任务的工作，并展示了其在医学预测分析(MPA)应用中的有效性。ICE-SEARCH利用语言模型中固有的交叉和突变能力，在一个进化框架内显着改进特征选择，通过模型的全面世界知识和其适应各种角色的能力。我们对该方法的评估涵盖了三个关键的MPA任务：中风、心血管疾病和糖尿病，在这些任务中ICE-SEARCH在确定医学应用的关键特征方面优于传统的FS方法。ICE-SEARCH在中风预测和糖尿病预测中实现了领先水平；决策随机化ICE-SEARCH在心血管疾病预测中排名为领先水平。我们的结果不仅证明了

    arXiv:2402.18609v1 Announce Type: cross  Abstract: This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate
    
[^112]: 在分享扩散模型中探讨隐私和公平风险：一种对抗性视角

    Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective

    [https://arxiv.org/abs/2402.18607](https://arxiv.org/abs/2402.18607)

    本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。

    

    扩散模型近年来在学术界和工业界引起了广泛关注，因为其在采样质量和分布覆盖方面表现出色。因此，提出了跨不同组织分享预训练扩散模型的建议，以提高数据利用率同时通过避免直接分享私人数据来增强隐私保护。然而，与这种方法相关的潜在风险尚未得到全面调查。本文从对抗性的角度探讨了与分享扩散模型相关的潜在隐私和公平风险。具体而言，我们调查了一方（分享者）使用私人数据训练扩散模型并向另一方（接收者）提供预训练模型的黑盒访问权限用于下游任务的情况。我们展示了分享者可以实行的行动

    arXiv:2402.18607v1 Announce Type: cross  Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.   In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execut
    
[^113]: 网络拓扑对分布式联邦学习性能的影响

    Impact of network topology on the performance of Decentralized Federated Learning

    [https://arxiv.org/abs/2402.18606](https://arxiv.org/abs/2402.18606)

    研究探讨了不同类型的网络结构如何影响去中心化联邦学习中的知识传播，并通过三种网络拓扑和六种数据分布方法研究了网络结构与学习性能之间的复杂相互作用。

    

    完全去中心化的学习正在蓬勃发展，用于在互联网边缘训练人工智能模型，解决基础设施挑战和隐私问题。在去中心化机器学习系统中，数据分布在多个节点上，每个节点根据其各自的数据集训练本地模型。然后这些本地模型被共享和合并，形成能够对新数据进行准确预测的全局模型。我们的研究重点是不同类型的网络结构如何影响知识传播，即节点如何吸收来自网络上其他节点可用数据学习模式的洞见。具体而言，这项研究通过三种网络拓扑和六种数据分布方法探讨网络结构与学习性能之间的复杂相互作用。这些方法考虑了不同的顶点属性，包括度中心性，介数中心性等。

    arXiv:2402.18606v1 Announce Type: cross  Abstract: Fully decentralized learning is gaining momentum for training AI models at the Internet's edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge - the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness cent
    
[^114]: FORML：一种具有正交约束的流形海森自由元学习方法

    FORML: A Riemannian Hessian-free Method for Meta-learning with Orthogonality Constraint

    [https://arxiv.org/abs/2402.18605](https://arxiv.org/abs/2402.18605)

    该论文介绍了一种 FORML 方法，使用斯蒂夫尔流形上的一阶导数近似，通过引入海森自由方法来降低计算负担和内存占用，并在元学习中实现参数正交约束。

    

    元学习问题通常被表述为一个双层优化问题，其中任务特定参数和元参数分别在优化的内部和外部循环中进行更新。然而，在黎曼空间中进行优化，参数和元参数位于黎曼流形上，这在计算上是非常密集的。与欧几里德方法不同，黎曼反向传播需要计算包括通过黎曼算子（如收缩和正交投影）的二阶导数。本文介绍了一种使用斯蒂夫尔流形上的导数的一阶近似的海森自由方法。我们的方法显著减少了计算负载和内存占用。我们展示了如何使用一个斯蒂夫尔全连接层作为骨干网络的最后分类层参数上的正交约束。

    arXiv:2402.18605v1 Announce Type: new  Abstract: Meta-learning problem is usually formulated as a bi-level optimization in which the task-specific and the meta-parameters are updated in the inner and outer loops of optimization, respectively. However, performing the optimization in the Riemannian space, where the parameters and meta-parameters are located on Riemannian manifolds is computationally intensive. Unlike the Euclidean methods, the Riemannian backpropagation needs computing the second-order derivatives that include backward computations through the Riemannian operators such as retraction and orthogonal projection. This paper introduces a Hessian-free approach that uses a first-order approximation of derivatives on the Stiefel manifold. Our method significantly reduces the computational load and memory footprint. We show how using a Stiefel fully-connected layer that enforces orthogonality constraint on the parameters of the last classification layer as the head of the backbon
    
[^115]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^116]: Meta-Tasks: 元学习正则化的另一种视角

    Meta-Tasks: An alternative view on Meta-Learning Regularization

    [https://arxiv.org/abs/2402.18599](https://arxiv.org/abs/2402.18599)

    该论文提出了一种新颖的解决方案，通过使用meta-tasks作为元学习正则化的视角，实现了对训练和新颖任务的泛化，避免标记数据稀缺的困扰，并在实验中表现优越，相较于原型网络提高了3.9%的性能。

    

    Few-shot learning (FSL)是一个具有挑战性的机器学习问题，因为标记数据稀缺。这篇论文提出了一种新颖的解决方案，可以泛化到训练和新颖的任务，同时利用未标记样本。该方法在更新外层循环之前，使用无监督技术对嵌入模型进行了细化，将其作为“元任务”。实验结果表明，我们提出的方法在新颖和训练任务上表现良好，收敛更快、更好，泛化误差和标准差更低，表明其在FSL中的实际应用潜力。实验结果表明，所提出的方法的表现比原型网络高出3.9%。

    arXiv:2402.18599v1 Announce Type: cross  Abstract: Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.
    
[^117]: EncodingNet: 一种用于高效神经网络加速的基于编码的新型MAC设计

    EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural Network Acceleration

    [https://arxiv.org/abs/2402.18595](https://arxiv.org/abs/2402.18595)

    提出了一种基于编码的新型数字MAC设计，通过用简单的逻辑门代替乘法器，训练特定神经网络的位置权重，实现逐位加权累积，从而提高神经网络加速的能效和计算效果。

    

    arXiv:2402.18595v1 发表类型：跨  摘要：深度神经网络（DNNs）在诸如图像分类和自然语言处理等许多领域取得了巨大突破。然而，DNN的执行需要在硬件上进行大量的乘-累积（MAC）运算，从而导致大量功耗消耗。为了解决这一挑战，我们提出了一种基于编码的新型数字MAC设计。在这种新设计中，乘法器被简单的逻辑门所取代，用于将结果投影到宽比特表示中。这些比特携带各自的位置权重，可以针对特定神经网络进行训练，以增强推断精度。新乘法器的输出通过逐位加权累积进行相加，并且累积结果与现有计算平台兼容，可加速神经网络的统一或非统一量化。由于乘法函数被简单的逻辑投影所取代，导致能量效率和计算效果的增加。

    arXiv:2402.18595v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) have achieved great breakthroughs in many fields such as image classification and natural language processing. However, the execution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC) operations on hardware and thus incurs a large power consumption. To address this challenge, we propose a novel digital MAC design based on encoding. In this new design, the multipliers are replaced by simple logic gates to project the results onto a wide bit representation. These bits carry individual position weights, which can be trained for specific neural networks to enhance inference accuracy. The outputs of the new multipliers are added by bit-wise weighted accumulation and the accumulation results are compatible with existing computing platforms accelerating neural networks with either uniform or non-uniform quantization. Since the multiplication function is replaced by simple logic projection, the c
    
[^118]: 具有图反馈的随机上下文赌博：从独立数到MAS数

    Stochastic contextual bandits with graph feedback: from independence number to MAS number

    [https://arxiv.org/abs/2402.18591](https://arxiv.org/abs/2402.18591)

    本文研究了具有图反馈的上下文赌博问题，提出了一个刻画学习极限的图论量 $\beta_M(G)$，并建立了对应的遗憾下限。

    

    我们考虑具有图反馈的上下文赌博，在这类互动学习问题中，具有比普通上下文赌博更丰富结构，其中采取一个行动将在所有情境下揭示所有相邻行动的奖励。与多臂赌博设置不同，多文献已经对图反馈的理解进行了全面探讨，但在上下文赌博对应部分仍有许多未被探讨的地方。在本文中，我们通过建立一个遗憾下限 $\Omega(\sqrt{\beta_M(G) T})$ 探究了这个问题，其中 $M$ 是情境数，$G$ 是反馈图，$\beta_M(G)$ 是我们提出的表征该问题类的基础学习限制的图论量。有趣的是，$\beta_M(G)$ 在 $\alpha(G)$ (图的独立数) 和 $\mathsf{m}(G)$ (图的最大无环子图（MAS）数) 之间插值。

    arXiv:2402.18591v1 Announce Type: new  Abstract: We consider contextual bandits with graph feedback, a class of interactive learning problems with richer structures than vanilla contextual bandits, where taking an action reveals the rewards for all neighboring actions in the feedback graph under all contexts. Unlike the multi-armed bandits setting where a growing literature has painted a near-complete understanding of graph feedback, much remains unexplored in the contextual bandits counterpart. In this paper, we make inroads into this inquiry by establishing a regret lower bound $\Omega(\sqrt{\beta_M(G) T})$, where $M$ is the number of contexts, $G$ is the feedback graph, and $\beta_M(G)$ is our proposed graph-theoretical quantity that characterizes the fundamental learning limit for this class of problems. Interestingly, $\beta_M(G)$ interpolates between $\alpha(G)$ (the independence number of the graph) and $\mathsf{m}(G)$ (the maximum acyclic subgraph (MAS) number of the graph) as 
    
[^119]: Verif.ai: 一种具有引用和可验证答案的开源科学生成式问答系统

    Verif.ai: Towards an Open-Source Scientific Generative Question-Answering System with Referenced and Verifiable Answers

    [https://arxiv.org/abs/2402.18589](https://arxiv.org/abs/2402.18589)

    Verif.ai是一个具有引用和可验证答案的开源科学生成式问答系统，通过信息检索、生成模型和验证引擎的结合实现对主张的生成和验证。

    

    在本文中，我们介绍了项目Verif.ai的当前进展，这是一个具有引用和可验证答案的开源科学生成式问答系统。该系统的组成部分包括（1）一个信息检索系统，结合语义和词汇搜索技术对科学论文（PubMed）进行检索，（2）一个经过微调的生成模型（Mistral 7B），获取前几个答案并生成附有从中得出主张的论文引用的答案，以及（3）一个验证引擎，用于交叉检查生成的主张和从中得出主张的摘要或论文，验证生成主张时是否存在任何错觉。我们通过提供上下文中的摘要加强了生成模型，但此外，一个独立的方法和模型集正在验证答案并检查是否存在错觉。因此，我们相信通过使用我们的方法，我们可以使科学家们

    arXiv:2402.18589v1 Announce Type: cross  Abstract: In this paper, we present the current progress of the project Verif.ai, an open-source scientific generative question-answering system with referenced and verified answers. The components of the system are (1) an information retrieval system combining semantic and lexical search techniques over scientific papers (PubMed), (2) a fine-tuned generative model (Mistral 7B) taking top answers and generating answers with references to the papers from which the claim was derived, and (3) a verification engine that cross-checks the generated claim and the abstract or paper from which the claim was derived, verifying whether there may have been any hallucinations in generating the claim. We are reinforcing the generative model by providing the abstract in context, but in addition, an independent set of methods and models are verifying the answer and checking for hallucinations. Therefore, we believe that by using our method, we can make scientis
    
[^120]: 处于生成式人工智能时代之初：关于6G无线智能新领域的教程和调研

    At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence

    [https://arxiv.org/abs/2402.18587](https://arxiv.org/abs/2402.18587)

    GenAI在无线领域是关键资产，能够处理稀缺、不完整、难以获取和理解的真实世界数据，可以取代或补充判别式人工智能方法，本文汇总了6G和无线智能领域的新前沿。

    

    大多数基于数据驱动的无线研究严重依赖于需要大量真实世界数据集的判别式人工智能（DAI）。与DAI不同，生成式人工智能（GenAI）涉及能够识别输入数据的潜在数据分布、模式和特征的生成模型（GMs）。这使得GenAI在无线领域成为一个关键资产，其中真实世界数据通常稀缺、不完整、获取成本高，难以建模或理解。有了这些吸引人的特征，GenAI可以取代或补充DAI方法的各种能力。因此，这篇结合了教程和调研的论文从6G和无线智能的基础开始，通过概述候选6G应用和服务、提出现代DAI模型的分类法、举例说明著名的DAI用例，并阐明GenAI如何增强DAI的多方面方式。接着，我们通过重点介绍开创性的GMs来呈现一个GMs的教程。

    arXiv:2402.18587v1 Announce Type: cross  Abstract: The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal
    
[^121]: 结合自适应扩散模型用于基于结构的药物设计

    Binding-Adaptive Diffusion Models for Structure-Based Drug Design

    [https://arxiv.org/abs/2402.18583](https://arxiv.org/abs/2402.18583)

    提出了一种新的框架——结合自适应扩散模型（BindDM），通过自适应地提取蛋白质-配体相互作用的重要部分，并利用SE(3)-等变神经网络处理，将结合信息传回每个原子，从而增强了基于目标的3D分子扩散生成的方法

    

    结构基药物设计旨在生成能够与特定蛋白靶向结合的三维配体分子。现有的3D深度生成模型，包括扩散模型，已经展现出在结构基药物设计中具有很大潜力。然而，在三维空间精确捕获蛋白质-配体相互作用是复杂的。为了解决这一问题，我们提出了一种新的框架，即结合自适应扩散模型（BindDM）。在BindDM中，我们自适应地提取亚复杂体，即负责蛋白质-配体相互作用的结合位点的重要部分。然后，所选的蛋白质-配体亚复杂体通过SE(3)-等变神经网络进行处理，并传回到复杂体的每个原子，以增强基于目标的3D分子扩散生成，并带有结合相互作用信息。我们通过跨层次交互节点迭代进行这种分层复杂体-亚复杂体过程，以充分融合全局结合上下文

    arXiv:2402.18583v1 Announce Type: cross  Abstract: Structure-based drug design (SBDD) aims to generate 3D ligand molecules that bind to specific protein targets. Existing 3D deep generative models including diffusion models have shown great promise for SBDD. However, it is complex to capture the essential protein-ligand interactions exactly in 3D space for molecular generation. To address this problem, we propose a novel framework, namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively extract subcomplex, the essential part of binding sites responsible for protein-ligand interactions. Then the selected protein-ligand subcomplex is processed with SE(3)-equivariant neural networks, and transmitted back to each atom of the complex for augmenting the target-aware 3D molecule diffusion generation with binding interaction information. We iterate this hierarchical complex-subcomplex process with cross-hierarchy interaction node for adequately fusing global binding context
    
[^122]: 利用PSO-RDV框架改善人工神经网络的预测能力

    Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network

    [https://arxiv.org/abs/2402.18576](https://arxiv.org/abs/2402.18576)

    本研究提出利用PSO-RDV框架改进预测方法，通过采用随机下降速度惯性权重（RDV IW）技术提高了粒子群优化（PSO）的收敛性和人工神经网络（ANN）的准确性。

    

    决策和规划长期以来一直严重依赖于基于人工智能的预测。政府和公众在潜在未来公共卫生不确定性面临风险最小化和利益最大化。本研究利用改进的预测方法，利用随机下降速度惯性权重（RDV IW）技术来提高粒子群优化（PSO）的收敛和人工神经网络（ANN）的准确性。 受高尔夫球运动启发，IW技术修改了粒子接近解决方案点时的速度，使其呈现抛物线下降结构。 仿真结果显示，建议的预测模型使用[0.4, 0.9]的alpha和alpha_dump组合，相对于旧模型在位置误差上有6.36％的改进，计算时间上有11.75％的改进，从而提高了其收敛性。 它达到了最优水平。

    arXiv:2402.18576v1 Announce Type: cross  Abstract: Decision making and planning have long relied heavily on AI-driven forecasts. The government and the general public are working to minimize the risks while maximizing benefits in the face of potential future public health uncertainties. This study used an improved method of forecasting utilizing the Random Descending Velocity Inertia Weight (RDV IW) technique to improve the convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial Neural Network (ANN). The IW technique, inspired by the motions of a golf ball, modified the particles' velocities as they approached the solution point to a parabolically descending structure. Simulation results revealed that the proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump exhibits a 6.36% improvement in position error and 11.75% improvement in computational time compared to the old model, thus, improving its convergence. It reached the optimum level a
    
[^123]: DiffuseRAW：端到端生成RAW图像处理用于低光照图像

    DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images

    [https://arxiv.org/abs/2402.18575](https://arxiv.org/abs/2402.18575)

    本研究提出了DiffuseRAW，一个端到端生成RAW图像处理方法，重点解决了低光照图像处理中整个图像处理管道学习的问题。

    

    在极低光条件下成像面临着巨大挑战，由于最小光子捕获引起的低信噪比（SNR），这是一个逆问题。以前，扩散模型已经用于多种生成任务和图像到图像任务，但这些模型作为后处理步骤。这些扩散模型是在处理后的图像上训练的，并在处理后的图像上进行学习。然而，这种方法通常不适用于极低光任务。与低光图像增强或图像到图像增强任务不同，我们解决了从RAW图像到处理后图像的整个图像处理管道学习任务。对于这个任务，传统的图像处理管道通常由多个专门化部分组成，过度依赖下游任务。与这些不同，我们开发了一种新的生成ISP，依赖于微调潜在的扩散模型o

    arXiv:2402.18575v1 Announce Type: cross  Abstract: Imaging under extremely low-light conditions presents a significant challenge and is an ill-posed problem due to the low signal-to-noise ratio (SNR) caused by minimal photon capture. Previously, diffusion models have been used for multiple kinds of generative tasks and image-to-image tasks, however, these models work as a post-processing step. These diffusion models are trained on processed images and learn on processed images. However, such approaches are often not well-suited for extremely low-light tasks. Unlike the task of low-light image enhancement or image-to-image enhancement, we tackle the task of learning the entire image-processing pipeline, from the RAW image to a processed image. For this task, a traditional image processing pipeline often consists of multiple specialized parts that are overly reliant on the downstream tasks. Unlike these, we develop a new generative ISP that relies on fine-tuning latent diffusion models o
    
[^124]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^125]: 传感器故障下的泛化性能：Tokenization + Transformers 实现更健壮的潜在空间

    Generalizability Under Sensor Failure: Tokenization + Transformers Enable More Robust Latent Spaces

    [https://arxiv.org/abs/2402.18546](https://arxiv.org/abs/2402.18546)

    TOTEM模型在应对传感器故障的神经科学研究中实现了更好的泛化性能。

    

    神经科学的一个主要目标是发现能够泛化的神经数据表示。这一目标受到记录会话（例如环境）、受试者（例如变化的神经结构）和传感器（例如传感器噪声）等因素的挑战。最近的工作已经开始解决跨会话和受试者的泛化问题，但很少有研究针对在神经科学实验中普遍存在的传感器故障的稳健性。为了解决这些泛化性维度，我们首先收集了我们自己的脑电图数据集，其中包含多个会话、受试者和传感器，然后研究了两个时间序列模型：EEGNet（Lawhern等人，2018）和TOTEM（Talukder等人，2024）。EEGNet 是一个广泛使用的卷积神经网络，而 TOTEM 是一个离散时间序列标记器和 Transformer 模型。我们发现，在所有泛化案例中，TOTEM 的表现优于或与 EEGNet 相匹配。最后，通过分析 TOTEM 的潜在编码

    arXiv:2402.18546v1 Announce Type: new  Abstract: A major goal in neuroscience is to discover neural data representations that generalize. This goal is challenged by variability along recording sessions (e.g. environment), subjects (e.g. varying neural structures), and sensors (e.g. sensor noise), among others. Recent work has begun to address generalization across sessions and subjects, but few study robustness to sensor failure which is highly prevalent in neuroscience experiments. In order to address these generalizability dimensions we first collect our own electroencephalography dataset with numerous sessions, subjects, and sensors, then study two time series models: EEGNet (Lawhern et al., 2018) and TOTEM (Talukder et al., 2024). EEGNet is a widely used convolutional neural network, while TOTEM is a discrete time series tokenizer and transformer model. We find that TOTEM outperforms or matches EEGNet across all generalizability cases. Finally through analysis of TOTEM's latent cod
    
[^126]: RNNs还不是Transformer：在上下文检索中的关键瓶颈

    RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval

    [https://arxiv.org/abs/2402.18510](https://arxiv.org/abs/2402.18510)

    本文研究了RNNs和Transformer在处理算法问题时的表现能力差距，发现RNNs存在关键瓶颈，即无法完美地从上下文中检索信息，导致无法像Transformer那样轻松解决需要这种能力的任务。

    

    本文探讨循环神经网络（RNNs）和Transformer在解决算法问题时的表示能力差距。我们重点关注RNNs是否能在处理长序列时，通过Chain-of-Thought (CoT)提示，与Transformer的性能相匹配。我们的理论分析显示CoT可以改进RNNs，但无法弥补与Transformer之间的差距。关键瓶颈在于RNNs无法完全从上下文中检索信息，即使经过CoT的增强：对于几个明确或隐式需要这种能力的任务，如联想召回和确定图是否为树，我们证明RNNs表达能力不足以解决这些任务，而Transformer可以轻松解决。相反，我们证明采用增强RNNs上下文检索能力的技术，包括

    arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
    
[^127]: ROG$_{PL}$: 通过基于区域的原型学习实现稳健的开放集图学习

    ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype Learning

    [https://arxiv.org/abs/2402.18495](https://arxiv.org/abs/2402.18495)

    提出了一个名为ROG$_PL$的统一框架，通过基于区域的原型学习实现了稳健的开放集图学习。

    

    开放集图学习是一个实际的任务，旨在对已知分类节点进行分类，并将未知类别样本识别为未知。传统的节点分类方法通常在开放集场景下表现不佳，这是由于它们所遇到的复杂数据，如分布外（OOD）数据和分布内（IND）噪声。OOD数据是不属于任何已知类别的样本。如果它们在训练中出现（OOD噪声），在测试中出现则为开放集样本。IND噪声是被错误标记的训练样本。IND噪声和OOD噪声的存在是普遍的，通常会引起模糊问题，包括类内变化问题和类间混淆问题。因此，探索稳健的开放集学习方法是必要且困难的，对于非独立同分布的图数据来说更加困难。为此，我们提出了一个名为ROG$_PL$的统一框架。

    arXiv:2402.18495v1 Announce Type: new  Abstract: Open-set graph learning is a practical task that aims to classify the known class nodes and to identify unknown class samples as unknowns. Conventional node classification methods usually perform unsatisfactorily in open-set scenarios due to the complex data they encounter, such as out-of-distribution (OOD) data and in-distribution (IND) noise. OOD data are samples that do not belong to any known classes. They are outliers if they occur in training (OOD noise), and open-set samples if they occur in testing. IND noise are training samples which are assigned incorrect labels. The existence of IND noise and OOD noise is prevalent, which usually cause the ambiguity problem, including the intra-class variety problem and the inter-class confusion problem. Thus, to explore robust open-set learning methods is necessary and difficult, and it becomes even more difficult for non-IID graph data.To this end, we propose a unified framework named ROG$_
    
[^128]: 用于非对数凹分布的零阶采样方法：通过去噪扩散缓解亚稳定性

    Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion

    [https://arxiv.org/abs/2402.17886](https://arxiv.org/abs/2402.17886)

    本文提出了一种基于去噪扩散过程的零阶扩散蒙特卡洛算法，克服了非对数凹分布采样中的亚稳定性问题，并证明其采样精度具有倒多项式依赖。

    

    这篇论文考虑了基于其非对数凹分布未归一化密度查询的采样问题。首先描述了一个基于模拟去噪扩散过程的框架，即扩散蒙特卡洛（DMC），其得分函数通过通用蒙特卡洛估计器逼近。DMC是一个基于神谕的元算法，其中神谕是假设可以访问生成蒙特卡洛分数估计器的样本的访问。然后，我们提供了一个基于拒绝采样的这个神谕的实现，这将DMC转化为一个真正的算法，称为零阶扩散蒙特卡洛（ZOD-MC）。我们通过首先构建一个通用框架，即DMC的性能保证，而不假设目标分布为对数凹或满足任何等周不等式，提供了收敛分析。然后我们证明ZOD-MC对所需采样精度具有倒多项式依赖，尽管仍然受到...

    arXiv:2402.17886v1 Announce Type: cross  Abstract: This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit sti
    
[^129]: 量子方法研究合成少数类过采样技术（SMOTE）

    A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)

    [https://arxiv.org/abs/2402.17398](https://arxiv.org/abs/2402.17398)

    使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。

    

    这篇论文提出了Quantum-SMOTE方法，这是一种使用量子计算技术来解决机器学习数据集中普遍存在的类别不平衡问题的新颖解决方案。Quantum-SMOTE受到合成少数类过采样技术（SMOTE）的启发，利用量子过程如交换测试和量子旋转生成合成数据点。该方法与传统的SMOTE算法使用K-最近邻（KNN）和欧氏距离的方式有所不同，能够从少数类数据点生成合成实例而无需依赖于邻近性。算法通过引入旋转角度、少数类百分比和分裂因子等超参数，可以更好地控制合成数据生成过程，从而实现对特定数据集需求的定制。该方法在TelecomChurn公共数据集上进行了测试，并与两种主要的分类算法进行了评估。

    arXiv:2402.17398v1 Announce Type: cross  Abstract: The paper proposes the Quantum-SMOTE method, a novel solution that uses quantum computing techniques to solve the prevalent problem of class imbalance in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority Oversampling Technique (SMOTE), generates synthetic data points using quantum processes such as swap tests and quantum rotation. The process varies from the conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean distances, enabling synthetic instances to be generated from minority class data points without relying on neighbor proximity. The algorithm asserts greater control over the synthetic data generation process by introducing hyperparameters such as rotation angle, minority percentage, and splitting factor, which allow for customization to specific dataset requirements. The approach is tested on a public dataset of TelecomChurn and evaluated alongside two prominent classification
    
[^130]: 通过隐含正交偏置发现对称群结构

    Discovering Symmetry Group Structures via Implicit Orthogonality Bias

    [https://arxiv.org/abs/2402.17002](https://arxiv.org/abs/2402.17002)

    HyperCube网络通过独特的因式分解架构和正则化器，成功学习了对称群的操作，能够高效地恢复完整操作表，并形成广义傅里叶基进行群卷积。

    

    我们介绍了HyperCube网络，一个用于自动发现数据中对称群结构的新方法。关键创新在于独特的因式分解架构，结合一种新颖的正则化器，向学习正交表示灌输了强大的归纳偏差。这利用了表示理论的一个基本定理，即所有紧致/有限群都可以由正交矩阵表示。HyperCube能够高效地从部分观测数据中学习通用群操作，成功恢复完整的操作表。值得注意的是，所学习出的因素直接对应于底层群的精确矩阵表示。此外，这些因素捕捉到了群的完整不可约表示集合，形成了执行群卷积的广义傅里叶基。在对群和非群符号操作进行的大量实验证明，HyperCube展示了10

    arXiv:2402.17002v1 Announce Type: new  Abstract: We introduce the HyperCube network, a novel approach for autonomously discovering symmetry group structures within data. The key innovation is a unique factorization architecture coupled with a novel regularizer that instills a powerful inductive bias towards learning orthogonal representations. This leverages a fundamental theorem of representation theory that all compact/finite groups can be represented by orthogonal matrices. HyperCube efficiently learns general group operations from partially observed data, successfully recovering complete operation tables. Remarkably, the learned factors correspond directly to exact matrix representations of the underlying group. Moreover, these factors capture the group's complete set of irreducible representations, forming the generalized Fourier basis for performing group convolutions. In extensive experiments with both group and non-group symbolic operations, HyperCube demonstrates a dramatic 10
    
[^131]: 逻辑回归的可证实准确性随机抽样算法

    A Provably Accurate Randomized Sampling Algorithm for Logistic Regression

    [https://arxiv.org/abs/2402.16326](https://arxiv.org/abs/2402.16326)

    提出了一种逻辑回归问题的简单随机抽样算法，通过随机矩阵乘法实现高质量逼近估计概率和模型整体差异性。

    

    在统计学和机器学习中，逻辑回归是一种广泛应用于二分类任务的监督学习技术。当观测数量远远超过预测变量数量时，我们提出了一种简单的基于随机抽样的逻辑回归问题算法，保证高质量逼近估计概率和模型整体差异性。我们的分析建立在两个简单的结构条件基础上，这两个条件可归结为随机矩阵乘法，是随机化数值线性代数的基本且深入理解的基元。当利用杠杆分数对观测进行抽样时，我们分析了逻辑回归的估计概率属性，并证明准确逼近可以通过远小于总观测数的样本实现。为了进一步验证我们的理论发现，

    arXiv:2402.16326v1 Announce Type: cross  Abstract: In statistics and machine learning, logistic regression is a widely-used supervised learning technique primarily employed for binary classification tasks. When the number of observations greatly exceeds the number of predictor variables, we present a simple, randomized sampling-based algorithm for logistic regression problem that guarantees high-quality approximations to both the estimated probabilities and the overall discrepancy of the model. Our analysis builds upon two simple structural conditions that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized numerical linear algebra. We analyze the properties of estimated probabilities of logistic regression when leverage scores are used to sample observations, and prove that accurate approximations can be achieved with a sample whose size is much smaller than the total number of observations. To further validate our theoretical findi
    
[^132]: 通过多种群意识优化检测机器生成文本的最大均值离差

    Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy

    [https://arxiv.org/abs/2402.16041](https://arxiv.org/abs/2402.16041)

    通过多种群意识优化检测机器生成文本的最大均值离差，解决了机器生成文本与人工编写文本之间微妙的分布差异挑战。

    

    大型语言模型（LLMs）如ChatGPT在生成类人文本方面表现出色。然而，机器生成文本可能存在严重风险，如抄袭问题、误导性信息或幻觉问题。因此，在许多情况下，检测机器生成文本是非常紧迫和重要的。不幸的是，由于LLMs的出色表现，区分机器生成文本和人工编写文本之间的分布差异常常非常微妙，这是具有挑战性的。在这篇论文中，我们试图利用\textit{最大均值离差}（MMD）来解决这个问题，因为MMD可以很好地识别分布差异。然而，直接使用各种机器生成文本对MMD进行训练将导致MMD的方差显著增加，因为不同LLMs的机器生成文本可能包含\textit{多个文本群体}。这将严重损害MMD测量分布差异的能力。

    arXiv:2402.16041v1 Announce Type: new  Abstract: Large language models (LLMs) such as ChatGPT have exhibited remarkable performance in generating human-like texts. However, machine-generated texts (MGTs) may carry critical risks, such as plagiarism issues, misleading information, or hallucination issues. Therefore, it is very urgent and important to detect MGTs in many situations. Unfortunately, it is challenging to distinguish MGTs and human-written texts because the distributional discrepancy between them is often very subtle due to the remarkable performance of LLMs. In this paper, we seek to exploit \textit{maximum mean discrepancy} (MMD) to address this issue in the sense that MMD can well identify distributional discrepancies. However, directly training a detector with MMD using diverse MGTs will incur a significantly increased variance of MMD since MGTs may contain \textit{multiple text populations} due to various LLMs. This will severely impair MMD's ability to measure the diff
    
[^133]: 强化学习中并行学习策略和未知安全约束

    Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning

    [https://arxiv.org/abs/2402.15893](https://arxiv.org/abs/2402.15893)

    提出了一种同时学习安全RL控制策略和识别未知安全约束参数的新方法。

    

    强化学习（RL）在过去几十年中已经彻底改变了跨多个领域的决策制定。然而，在实际场景中部署RL策略面临着确保安全的关键挑战。传统的安全RL方法主要集中于将预定义的安全约束纳入到策略学习过程中。然而，在动态和不可预测的实际环境中，这种对预定义安全约束的依赖在安全控制RL任务中具有限制，因为这些约束可能无法得到或不够适应。为弥补这一差距，我们提出了一种新颖的方法，同时学习安全的RL控制策略并确定给定环境的未知安全约束参数。通过使用一个参数化的信号时间逻辑（pSTL）安全规范和一个小的初始标记数据集进行初始化，我们将问题构建为一个双层优化任务，巧妙地将受限策略op

    arXiv:2402.15893v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has revolutionized decision-making across a wide range of domains over the past few decades. Yet, deploying RL policies in real-world scenarios presents the crucial challenge of ensuring safety. Traditional safe RL approaches have predominantly focused on incorporating predefined safety constraints into the policy learning process. However, this reliance on predefined safety constraints poses limitations in dynamic and unpredictable real-world settings where such constraints may not be available or sufficiently adaptable. Bridging this gap, we propose a novel approach that concurrently learns a safe RL control policy and identifies the unknown safety constraint parameters of a given environment. Initializing with a parametric signal temporal logic (pSTL) safety specification and a small initial labeled dataset, we frame the problem as a bilevel optimization task, intricately integrating constrained policy op
    
[^134]: GraphEdit：用于图结构学习的大型语言模型

    GraphEdit: Large Language Models for Graph Structure Learning

    [https://arxiv.org/abs/2402.15183](https://arxiv.org/abs/2402.15183)

    本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。

    

    图结构学习（GSL）致力于通过生成新颖的图结构来捕捉图结构数据中节点之间的固有依赖性和相互作用。本文提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习图结构化数据中复杂的节点关系。通过在图结构上进行指导调整，增强LLMs的推理能力，我们旨在克服显式图结构信息带来的挑战，并提高图结构学习的可靠性。

    arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
    
[^135]: 神经网络与摩擦：滑动、保持、学习

    Neural Networks and Friction: Slide, Hold, Learn

    [https://arxiv.org/abs/2402.14148](https://arxiv.org/abs/2402.14148)

    循环神经网络利用GRU架构学习合成数据中复杂摩擦定律动力学，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。

    

    本研究表明，利用门控循环单元（GRU）架构的循环神经网络（RNNs）具有学习合成数据中速率与状态摩擦定律复杂动力学的能力。用于训练网络的数据通过应用传统速率与状态摩擦方程结合状态演化老化定律生成。我们方法的一个新颖之处在于制定一个损失函数，该函数明确考虑训练过程中的初始条件、直接效应以及状态变量的演变。研究发现，具有GRU架构的RNN能够有效学习预测摩擦系数由于速度跳跃而产生的变化，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。

    arXiv:2402.14148v1 Announce Type: cross  Abstract: In this study, it is demonstrated that Recurrent Neural Networks (RNNs), specifically those utilizing Gated Recurrent Unit (GRU) architecture, possess the capability to learn the complex dynamics of rate-and-state friction laws from synthetic data. The data employed for training the network is generated through the application of traditional rate-and-state friction equations coupled with the aging law for state evolution. A novel aspect of our approach is the formulation of a loss function that explicitly accounts for initial conditions, the direct effect, and the evolution of state variables during training. It is found that the RNN, with its GRU architecture, effectively learns to predict changes in the friction coefficient resulting from velocity jumps, thereby showcasing the potential of machine learning models in understanding and simulating the physics of frictional processes.
    
[^136]: E2USD：用于多元时间序列的高效而有效的无监督状态检测

    E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series

    [https://arxiv.org/abs/2402.14041](https://arxiv.org/abs/2402.14041)

    E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。

    

    我们提出了E2USD方法，能够实现高效而准确的无监督多元时间序列状态检测。E2USD利用基于快速傅立叶变换的时间序列压缩器(FFTCompress)和分解的双视图嵌入模块(DDEM)，一起以低计算开销对输入的多元时间序列进行编码。此外，我们提出了一种假阴性取消对比学习方法(FNCCLearning)，以抵消假阴性的影响，并实现更友好的簇嵌入空间。为了在流式设置中进一步减少计算开销，我们引入了自适应阈值检测(ADATD)。通过使用六个基线模型和六个数据集进行全面实验，我们证明E2USD能够在显著降低计算开销的情况下达到SOTA的准确性。我们的代码可在https://github.com/AI4CTS/E2Usd 找到。

    arXiv:2402.14041v1 Announce Type: cross  Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd.
    
[^137]: 有关预训练机器学习模型存储可压缩性的一切你想知道但却不敢询问的问题

    Everything You Always Wanted to Know About Storage Compressibility of Pre-Trained ML Models but Were Afraid to Ask

    [https://arxiv.org/abs/2402.13429](https://arxiv.org/abs/2402.13429)

    这项研究是关于对预训练机器学习模型数据集的存储可压缩性进行首次全面分析，发现现代数据缩减工具在处理PTM数据集时并不有效。

    

    随着预训练机器学习（ML）模型数量呈指数增长，数据缩减工具却未能跟上。现有的数据缩减技术并非专门针对预训练模型（PTM）数据集文件而设计。这在很大程度上是由于对这些数据集的模式和特征的理解不足，尤其是与数据缩减和可压缩性相关的特征。

    arXiv:2402.13429v1 Announce Type: cross  Abstract: As the number of pre-trained machine learning (ML) models is growing exponentially, data reduction tools are not catching up. Existing data reduction techniques are not specifically designed for pre-trained model (PTM) dataset files. This is largely due to a lack of understanding of the patterns and characteristics of these datasets, especially those relevant to data reduction and compressibility.   This paper presents the first, exhaustive analysis to date of PTM datasets on storage compressibility. Our analysis spans different types of data reduction and compression techniques, from hash-based data deduplication, data similarity detection, to dictionary-coding compression. Our analysis explores these techniques at three data granularity levels, from model layers, model chunks, to model parameters. We draw new observations that indicate that modern data reduction tools are not effective when handling PTM datasets. There is a pressing 
    
[^138]: 针对多维时间序列预测的随机投影层

    Random Projection Layers for Multidimensional Time Sires Forecasting

    [https://arxiv.org/abs/2402.10487](https://arxiv.org/abs/2402.10487)

    提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能

    

    多层感知器（MLP）混合模型已被证明对时间序列预测问题有效。然而，当将此类模型应用于高维时间序列（例如空间-时间数据集中的时间序列）时，由于过拟合问题，其性能可能会下降。本文提出了一种全MLP时间序列预测架构，称为RPMixer。我们的方法利用了深度神经网络的集成式行为，其中网络中的每个单独块的作用类似于集成模型中的基本学习器，特别是在引入身份映射残差连接时。通过将随机投影层集成到我们的模型中，我们增加了块输出之间的多样性，从而提高了RPMixer的整体性能。对大规模空间-时间预测基准数据集进行的大量实验表明，我们提出的方法胜过了

    arXiv:2402.10487v1 Announce Type: cross  Abstract: All-Multi-Layer Perceptron (all-MLP) mixer models have been shown to be effective for time series forecasting problems. However, when such a model is applied to high-dimensional time series (e.g., the time series in a spatial-temporal dataset), its performance is likely to degrade due to overfitting issues. In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer. Our method leverages the ensemble-like behavior of deep neural networks, where each individual block within the network acts like a base learner in an ensemble model, especially when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby enhancing the overall performance of RPMixer. Extensive experiments conducted on large-scale spatial-temporal forecasting benchmark datasets demonstrate that our proposed method outperf
    
[^139]: ManiFPT: 定义和分析生成模型的指纹

    ManiFPT: Defining and Analyzing Fingerprints of Generative Models

    [https://arxiv.org/abs/2402.10401](https://arxiv.org/abs/2402.10401)

    本文明确定了生成模型中的工件和指纹的定义，并提出了计算它们的算法，发现使用该定义可以显著提高识别潜在生成过程的性能。

    

    最近的研究表明，生成模型在生成的样本上留下了它们潜在生成过程的痕迹，广泛称为生成模型的指纹，并研究了它们在检测真实图像和合成图像方面的实用性。然而，这些指纹能够区分各种类型的合成图像以及帮助识别潜在生成过程的程度仍未得到充分探讨。尤其是，据我们所知，指纹的定义仍不清楚。为此，在这项工作中，我们明确定义了生成模型中的工件和指纹，提出了一种实际计算它们的算法，并最终研究了它在区分大量不同生成模型方面的有效性。我们发现使用我们提出的定义可以显著提高从样本中识别潜在生成过程的性能。

    arXiv:2402.10401v1 Announce Type: new  Abstract: Recent works have shown that generative models leave traces of their underlying generative process on the generated samples, broadly referred to as fingerprints of a generative model, and have studied their utility in detecting synthetic images from real ones. However, the extend to which these fingerprints can distinguish between various types of synthetic image and help identify the underlying generative process remain under-explored. In particular, the very definition of a fingerprint remains unclear, to our knowledge. To that end, in this work, we formalize the definition of artifact and fingerprint in generative models, propose an algorithm for computing them in practice, and finally study its effectiveness in distinguishing a large array of different generative models. We find that using our proposed definition can significantly improve the performance on the task of identifying the underlying generative process from samples (model
    
[^140]: 借鉴多体物理的归纳偏置的多激发投影模拟

    Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias

    [https://arxiv.org/abs/2402.10192](https://arxiv.org/abs/2402.10192)

    该论文引入了多激发投影模拟（mePS），通过在超图上多个粒子的随机游走，解决了投影模拟（PS）无法模拟同时结合多个概念的思维的问题。

    

    随着深度学习的进步，依赖于机器学习的应用正在越来越多地融入日常生活。然而，大多数深度学习模型具有不透明的、类似于神谕般的特性，使得解释和理解它们的决策变得困难。这个问题导致了被称为可解释人工智能（XAI）的领域的发展。该领域中的一种方法称为投影模拟（PS），将思维过程建模为一个在具有概念附加的顶点的图上的粒子的随机游走。虽然这种描述具有各种好处，包括量化的可能性，但不能自然地用来模拟同时结合多个概念的思维。为了克服这个限制，我们引入了一种称为多激发投影模拟（mePS）的推广，它将思维过程视为超图上多个粒子的随机游走。

    arXiv:2402.10192v1 Announce Type: cross  Abstract: With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led to the development of the field known as eXplainable Artificial Intelligence (XAI). One method in this field known as Projective Simulation (PS) models a chain-of-thought as a random walk of a particle on a graph with vertices that have concepts attached to them. While this description has various benefits, including the possibility of quantization, it cannot be naturally used to model thoughts that combine several concepts simultaneously. To overcome this limitation, we introduce Multi-Excitation Projective Simulation (mePS), a generalization that considers a chain-of-thought to be a random walk of several particles on a hypergraph. A definition for
    
[^141]: 简约即是美：通过次模子集选择减少可解释区域

    Less is More: Fewer Interpretable Region via Submodular Subset Selection

    [https://arxiv.org/abs/2402.09164](https://arxiv.org/abs/2402.09164)

    本论文将图像归属问题重新建模为次模子集选择问题，通过使用更少的区域来增强模型的解释性，解决了现有归属解决方案面临的不准确区域和预测错误样本的问题。

    

    图像归属算法旨在确定与模型决策高度相关的重要区域。尽管现有的归属解决方案可以有效地给目标元素分配重要性，但仍面临以下挑战：1）现有的归属方法生成不准确的小区域，从而误导正确归属的方向；2）模型无法为预测错误的样本产生良好的归属结果。为了解决上述挑战，本文将上述图像归属问题重新建模为次模子集选择问题，旨在使用更少的区域增强模型的可解释性。为了解决对局部区域的关注不足，我们构造了一个新的次模函数来发现更准确的精细解释区域。为了增强所有样本的归属效果，我们还对子区域选择施加了四个不同的约束，即置信度，

    arXiv:2402.09164v1 Announce Type: cross Abstract: Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate fine-grained interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, 
    
[^142]: 从实例级的自我注意力Hawkes过程中学习格兰杰因果关系

    Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes

    [https://arxiv.org/abs/2402.03726](https://arxiv.org/abs/2402.03726)

    本论文提出了一种名为ISAHP的深度学习框架，可以从异步、相互依赖的多类型事件序列中无监督地学习实例级的格兰杰因果关系。它是第一个满足格兰杰因果关系要求的神经点过程模型，并利用变压器的自我注意机制来实现格兰杰因果关系的推断。

    

    我们解决了从异步、相互依赖的多类型事件序列中学习格兰杰因果关系的问题。特别是，我们对以无监督的方式发现实例级的因果结构感兴趣。实例级因果关系识别单个事件之间的因果关系，为决策提供了更精细化的信息。现有文献中的工作要么需要强加一些假设，比如强加到强度函数中的线性假设，要么启发式地定义模型参数，这些不一定满足格兰杰因果关系的要求。我们提出了一种新颖的深度学习框架，即实例级自我注意力Hawkes过程（ISAHP），可以直接推断事件实例级的格兰杰因果关系。ISAHP是第一个满足格兰杰因果关系要求的神经点过程模型。它利用了变压器的自我注意机制，与格兰杰因果关系的原理相一致。我们通过实验证明了ISAHP的有效性和优越性。

    We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate th
    
[^143]: 使用自反大型语言模型学习生成可解释的股票预测

    Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models

    [https://arxiv.org/abs/2402.03659](https://arxiv.org/abs/2402.03659)

    这个论文介绍了使用大型语言模型生成可解释的股票预测的方法，并提出了Summarize-Explain-Predict（SEP）模型来解决股票预测中的解释问题和数据标注成本的挑战。

    

    对于传统的非生成式深度学习模型来说，解释股票预测通常是一项困难的任务，其中解释仅限于可视化重要文本上的注意力权重。目前，大型语言模型（LLM）为解决这个问题提供了一个解决方案，因为它们具有生成人类可读解释其决策过程的能力。然而，股票预测对LLM来说仍然具有挑战性，因为它需要能够权衡混乱社会文本对股票价格的不同影响。随着引入解释组件，问题变得越来越困难，需要LLM能够用口头方式解释为什么某些因素比其他因素更重要。另一方面，要为这样的任务对LLM进行微调，需要专家标注的样本来解释训练集中的每次股票波动，这在成本和实际可扩展性上是昂贵且不可行的。为了解决这些问题，我们提出了我们的Summarize-Explain-Predict（SEP）模型。

    Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) 
    
[^144]: IEEE ICME 2024大挑战赛: 半监督领域转移下的声场分类描述

    Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic Scene Classification under Domain Shift

    [https://arxiv.org/abs/2402.02694](https://arxiv.org/abs/2402.02694)

    这项研究介绍了ICME 2024 Grand Challenge中的半监督领域转移下的声场分类任务，该任务探索了不同区域之间领域转移的挑战，同时研究了如何利用未标记数据来提升声场分类模型的性能。

    

    声场分类是计算声场分析中一个关键的研究问题，旨在识别环境的独特声学特征。声场分类任务面临的一个挑战是训练和测试数据之间的分布差异所引起的领域转移。虽然近年来的声场分类挑战已经在设备通用性方面取得了实质性进展，但涉及时间、空间、文化和语言等特征的不同区域之间领域转移的挑战目前尚未得到充分探讨。此外，考虑到现实世界中未标记的声场数据的丰富性，研究利用这些未标记数据的可能方法是很重要的。因此，我们在ICME 2024大挑战赛中引入了半监督领域转移下的声场分类任务。

    Acoustic scene classification (ASC) is a crucial research problem in computational auditory scene analysis, and it aims to recognize the unique acoustic characteristics of an environment. One of the challenges of the ASC task is domain shift caused by a distribution gap between training and testing data. Since 2018, ASC challenges have focused on the generalization of ASC models across different recording devices. Although this task in recent years has achieved substantial progress in device generalization, the challenge of domain shift between different regions, involving characteristics such as time, space, culture, and language, remains insufficiently explored at present. In addition, considering the abundance of unlabeled acoustic scene data in the real world, it is important to study the possible ways to utilize these unlabelled data. Therefore, we introduce the task Semi-supervised Acoustic Scene Classification under Domain Shift in the ICME 2024 Grand Challenge. We encourage par
    
[^145]: 通过分层图解释揭示分子成分

    Unveiling Molecular Moieties through Hierarchical Graph Explainability

    [https://arxiv.org/abs/2402.01744](https://arxiv.org/abs/2402.01744)

    本论文提出了一种使用图神经网络和分层可解释人工智能技术的方法，能够准确预测生物活性并找到与之相关的最重要的成分。

    

    背景：图神经网络（GNN）作为一种强大的工具，在支持体外虚拟筛选方面已经出现多年。在这项工作中，我们提出了一种使用图卷积架构实现高精度多靶标筛选的GNN。我们还设计了一种分层可解释人工智能（XAI）技术，通过利用信息传递机制，在原子、环和整个分子层面上直接捕获信息，从而找到与生物活性预测相关的最重要的成分。结果：我们在支持虚拟筛选方面的二十个细胞周期依赖性激酶靶标上报道了一种最先进的GNN分类器。我们的分类器超越了作者提出的先前最先进方法。此外，我们还设计了一个仅针对CDK1的高灵敏度版本的GNN，以使用我们的解释器来避免多类别模型固有的偏差。分层解释器已经由一位专家化学家在19个CDK1批准药物上进行了验证。

    Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer 
    
[^146]: 用于医学图像深度主动学习的获取函数研究

    A Study of Acquisition Functions for Medical Imaging Deep Active Learning

    [https://arxiv.org/abs/2401.15721](https://arxiv.org/abs/2401.15721)

    本研究探讨了在医学图像领域中如何应用主动学习以解决数据稀缺的问题，并通过对比不同的选择标准和获取池大小对模型性能的影响，结果表明不确定性对于黑色素瘤检测任务是有帮助的。

    

    深度学习革命已经在近年取得了突破性成就。 从乳腺癌检测到蛋白质折叠，深度学习算法一直是非常重要的进步的核心。 但是，这些现代进步越来越需要数据，特别是标记数据，其可用性稀缺：在医学背景下更为常见。在这项工作中，我们展示了在数据稀缺情况下主动学习可能非常有效，其中获取标记数据（或注释预算非常有限）。 我们在ISIC 2016数据集上比较了几种选择标准（BALD，MeanSTD和MaxEntropy）。 我们还探讨了获取的池大小对模型性能的影响。 我们的结果表明，不确定性对于黑色素瘤检测任务是有帮助的，并且证实了作者的猜测，即\textit {bald} 平均比其他方式更好执行。

    arXiv:2401.15721v2 Announce Type: replace-cross  Abstract: The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \textit{bald} performs on average better than other a
    
[^147]: OK-Robot: 整合开放知识模型在机器人领域的重要性

    OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics

    [https://arxiv.org/abs/2401.12202](https://arxiv.org/abs/2401.12202)

    该研究提出了一种新型基于开放知识的机器人框架OK-Robot，通过整合视觉-语言模型、导航原语和抓取原语，为Pick-and-Drop操作提供了一个集成解决方案，无需任何训练。

    

    近年来在视觉、语言和机器人领域取得了显著进展。我们现在拥有能够根据语言查询识别物体的视觉模型，能有效控制移动系统的导航系统，以及能够处理各种物体的抓取模型。尽管取得了这些进步，但机器人的通用应用仍然落后，尽管它们依赖于识别、导航和抓取等基本能力。在本文中，我们采用了系统优先的方法，开发了一个名为OK-Robot的新型基于开放知识的机器人框架。通过将用于对象检测的视觉-语言模型（VLMs）、用于移动的导航原语和用于物体操作的抓取原语结合在一起，OK-Robot为Pick-and-Drop操作提供了一个集成解决方案，而无需任何训练。为了评估其性能，我们在10个真实家庭环境中运行了OK-Robot。

    arXiv:2401.12202v2 Announce Type: replace-cross  Abstract: Remarkable progress has been made in recent years in the fields of vision, language, and robotics. We now have vision models capable of recognizing objects based on language queries, navigation systems that can effectively control mobile systems, and grasping models that can handle a wide range of objects. Despite these advancements, general-purpose applications of robotics still lag behind, even though they rely on these fundamental capabilities of recognition, navigation, and grasping. In this paper, we adopt a systems-first approach to develop a new Open Knowledge-based robotics framework called OK-Robot. By combining Vision-Language Models (VLMs) for object detection, navigation primitives for movement, and grasping primitives for object manipulation, OK-Robot offers a integrated solution for pick-and-drop operations without requiring any training. To evaluate its performance, we run OK-Robot in 10 real-world home environme
    
[^148]: Bayesian神经网络中概率鲁棒性的严格验证

    Tight Verification of Probabilistic Robustness in Bayesian Neural Networks

    [https://arxiv.org/abs/2401.11627](https://arxiv.org/abs/2401.11627)

    通过引入两种算法，实现了对Bayesian神经网络概率鲁棒性的严格验证，相比标准神经网络，这些算法更加高效且能够搜索参数空间以找到安全权重。

    

    我们介绍了两种用于计算Bayesian神经网络（BNNs）的概率鲁棒性上严格保证的算法。计算BNNs的鲁棒性保证要比验证标准神经网络（NNs）的鲁棒性困难得多，因为它需要在参数空间中搜索安全权重。此外，标准NNs验证的紧密和完整方法，例如基于混合整数线性规划（MILP）的方法，不能直接用于BNNs的验证，因为由于编码权重的变量连续相乘而产生的多项式项。我们的算法通过使用迭代扩展和网络的梯度有效地搜索参数空间以寻找安全权重，并且可以与BNNs的任何验证算法一起使用。

    arXiv:2401.11627v2 Announce Type: replace-cross  Abstract: We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the So
    
[^149]: 用于分解连续学习的无限dSprites：将记忆编辑与泛化分离

    Infinite dSprites for Disentangled Continual Learning: Separating Memory Edits from Generalization

    [https://arxiv.org/abs/2312.16731](https://arxiv.org/abs/2312.16731)

    引入了Infinite dSprites工具，用于创建任意长度的连续分类和分解基准，可以全面控制生成因素，有望缩小机器学习系统与人类学习在动态开放环境中的差距

    

    机器学习系统持续学习的能力受到灾难性遗忘的阻碍，即神经网络在学习新任务时会覆盖现有知识。持续学习方法通过正则化、参数隔离或排练来缓解这一问题，但它们通常在仅包含少数任务的基准测试上进行评估。为了取得进展以缩小这一差距，我们介绍了Infinite dSprites，这是一个简洁的工具，可创建任意长度的连续分类和分解基准，并对生成因素拥有完全控制。我们展示，在足够长的时间范围内，所有主要类型的持续学习方法的性能都表现出...

    arXiv:2312.16731v2 Announce Type: replace  Abstract: The ability of machine learning systems to learn continually is hindered by catastrophic forgetting, the tendency of neural networks to overwrite existing knowledge when learning a new task. Continual learning methods alleviate this problem through regularization, parameter isolation, or rehearsal, but they are typically evaluated on benchmarks comprising only a handful of tasks. In contrast, humans are able to learn continually in dynamic, open-world environments, effortlessly achieving one-shot memorization of unfamiliar objects and reliably recognizing them under various transformations. To make progress towards closing this gap, we introduce Infinite dSprites, a parsimonious tool for creating continual classification and disentanglement benchmarks of arbitrary length and with full control over generative factors. We show that over a sufficiently long time horizon, the performance of all major types of continual learning methods d
    
[^150]: 双阶段优化器用于系统性过估调整应用于多目标遗传算法的生物标志物选择

    Dual-stage optimizer for systematic overestimation adjustment applied to multi-objective genetic algorithms for biomarker selection

    [https://arxiv.org/abs/2312.16624](https://arxiv.org/abs/2312.16624)

    该论文介绍了一种双阶段优化器，用于对多目标遗传算法中的生物标志物选择进行系统性过估调整。

    

    在使用机器学习从组学数据中发现生物标志物的挑战在于分子特征的丰富性但样本的稀缺性。大多数机器学习中的特征选择方法需要评估各种特征集（模型）以确定最有效的组合。这个过程通常使用验证数据集进行，涉及测试不同的特征集以优化模型的性能。评估存在性能估计误差，当选择涉及多个模型时，最好的模型几乎肯定被过估。使用特征选择方法进行生物标志物识别可以视为具有预测能力和特征数量中的简约性之间的权衡的多目标问题。遗传算法是多目标优化中的一种流行工具，但它们进化出许多解决方案，因此容易出现过估。已经提出了一些方法来在选择了模型后减少过估。

    The challenge in biomarker discovery using machine learning from omics data lies in the abundance of molecular features but scarcity of samples. Most feature selection methods in machine learning require evaluating various sets of features (models) to determine the most effective combination. This process, typically conducted using a validation dataset, involves testing different feature sets to optimize the model's performance. Evaluations have performance estimation error and when the selection involves many models the best ones are almost certainly overestimated. Biomarker identification with feature selection methods can be addressed as a multi-objective problem with trade-offs between predictive ability and parsimony in the number of features. Genetic algorithms are a popular tool for multi-objective optimization but they evolve numerous solutions thus are prone to overestimation. Methods have been proposed to reduce the overestimation after a model has already been selected in si
    
[^151]: 基于Poincaré差分隐私的层次感知图嵌入

    Poincar\'e Differential Privacy for Hierarchy-Aware Graph Embedding

    [https://arxiv.org/abs/2312.12183](https://arxiv.org/abs/2312.12183)

    提出了Poincaré差分隐私框架PoinDP，用于保护基于层次感知的图嵌入，解决了在图神经网络中层次性带来的隐私泄露问题。

    

    层次是现实世界图中的一个重要且常见的拓扑性质，它表明了主管和下属之间的关系，或者人类群体的组织行为。伴随着层次性作为一种新的归纳偏差被引入到不同任务中的图神经网络（GNNs）中，这暗示了攻击者改进其推断攻击性能的潜在拓扑关系，导致严重的隐私泄露问题。此外，由于现有的保护框架在层次传播中无法正确估计层次性扰动边界的自适应上界，导致其在层次传播中保护能力降低，急需有效利用数据的层次特性以确保隐私保证。为了解决这一问题，我们提出了基于Poincaré差分隐私框架的PoinDP，用于保护基于层次感知的图嵌入。

    arXiv:2312.12183v3 Announce Type: replace  Abstract: Hierarchy is an important and commonly observed topological property in real-world graphs that indicate the relationships between supervisors and subordinates or the organizational behavior of human groups. As hierarchy is introduced as a new inductive bias into the Graph Neural Networks (GNNs) in various tasks, it implies latent topological relations for attackers to improve their inference attack performance, leading to serious privacy leakage issues. In addition, existing privacy-preserving frameworks suffer from reduced protection ability in hierarchical propagation due to the deficiency of adaptive upper-bound estimation of the hierarchical perturbation boundary. It is of great urgency to effectively leverage the hierarchical property of data while satisfying privacy guarantees. To solve the problem, we propose the Poincar\'e Differential Privacy framework, named PoinDP, to protect the hierarchy-aware graph embedding based on hy
    
[^152]: 在模拟机器人臂中的安全强化学习

    Safe Reinforcement Learning in a Simulated Robotic Arm

    [https://arxiv.org/abs/2312.09468](https://arxiv.org/abs/2312.09468)

    本文通过在Panda机器人臂上创建定制环境，扩展了安全强化学习算法的适用性，实现了安全RL算法在物理环境中的测试。

    

    强化学习（RL）代理需要探索环境以学习最优策略。在许多环境和任务中，安全性至关重要。模拟器的广泛使用提供了许多优势，其中包括安全探索，当RL系统需要直接在物理环境（例如在人机交互中）中进行训练时，安全探索将是不可避免的。流行的Safety Gym库提供了三种移动代理类型，可以学习目标导向任务同时考虑各种安全约束。本文通过创建一个带有Panda机器人臂的定制环境，扩展了安全RL算法的适用性，以便测试Safety Gym算法。我们使用流行的PPO算法进行了试点实验，比较了基线与受限版本，并表明受限版本能够学习出同样优秀的策略，同时更好地符合安全性。

    arXiv:2312.09468v2 Announce Type: replace-cross  Abstract: Reinforcement learning (RL) agents need to explore their environments in order to learn optimal policies. In many environments and tasks, safety is of critical importance. The widespread use of simulators offers a number of advantages, including safe exploration which will be inevitable in cases when RL systems need to be trained directly in the physical environment (e.g. in human-robot interaction). The popular Safety Gym library offers three mobile agent types that can learn goal-directed tasks while considering various safety constraints. In this paper, we extend the applicability of safe RL algorithms by creating a customized environment with Panda robotic arm where Safety Gym algorithms can be tested. We performed pilot experiments with the popular PPO algorithm comparing the baseline with the constrained version and show that the constrained version is able to learn the equally good policy while better complying with safe
    
[^153]: 基于拓扑的去重建防护在去中心化学习中的应用

    Topology-Based Reconstruction Prevention for Decentralised Learning

    [https://arxiv.org/abs/2312.05248](https://arxiv.org/abs/2312.05248)

    通过研究发现，在去中心化学习中，被动的好奇敌手可以在几次保护隐私的求和操作后推断出其他用户的私人数据。

    

    最近，去中心化学习作为一种替代联邦学习的方式，获得了人们的关注，其中数据和协调都分布在用户之间。为了保护数据的机密性，去中心化学习依赖于差分隐私、多方计算，或者二者的结合。然而，连续运行多个保护隐私的求和操作可能会使对手进行重建攻击。不幸的是，当前的重建对策要么无法简单地适应分布式环境，要么会添加过多的噪音。在这项工作中，我们首先表明，被动的好奇敌手可以在几次保护隐私的求和之后推断出其他用户的私人数据。例如，在拓扑中有18个用户的子图中，我们发现只有三个被动的好奇敌手成功重建私人数据的概率为11.0%，平均每个对手需要8.8次求和。

    arXiv:2312.05248v2 Announce Type: replace-cross  Abstract: Decentralised learning has recently gained traction as an alternative to federated learning in which both data and coordination are distributed over its users. To preserve data confidentiality, decentralised learning relies on differential privacy, multi-party computation, or a combination thereof. However, running multiple privacy-preserving summations in sequence may allow adversaries to perform reconstruction attacks. Unfortunately, current reconstruction countermeasures either cannot trivially be adapted to the distributed setting, or add excessive amounts of noise.   In this work, we first show that passive honest-but-curious adversaries can infer other users' private data after several privacy-preserving summations. For example, in subgraphs with 18 users, we show that only three passive honest-but-curious adversaries succeed at reconstructing private data 11.0% of the time, requiring an average of 8.8 summations per adve
    
[^154]: 多任务学习可以改善最差群体结果

    Multitask Learning Can Improve Worst-Group Outcomes

    [https://arxiv.org/abs/2312.03151](https://arxiv.org/abs/2312.03151)

    本文研究了多任务学习对最糟糕群体准确性的影响，并探讨了其作为解决组内公平挑战工具的潜力。

    

    为了创建能够为各种用户提供良好服务的机器学习系统，不仅需要实现高平均性能，还需要确保在不同群体之间实现公平结果至关重要。然而，大多数机器学习方法旨在改善模型在选择的最终任务上的平均性能，而不考虑其对最差群体误差的影响。多任务学习（MTL）是一种广泛使用的技术。本文旨在不仅理解MTL对最差群体准确性的影响，而且探讨其作为解决组内公平挑战的工具的潜力。我们主要考虑了微调预训练模型的标准设置，在这个设置中，我们将最终任务与来自最终任务数据本身的预训练目标进行多任务处理。在少量或没有群体注释的环境中，我们发现多任务处理通常，但不总是

    arXiv:2312.03151v2 Announce Type: replace  Abstract: In order to create machine learning systems that serve a variety of users well, it is vital to not only achieve high average performance but also ensure equitable outcomes across diverse groups. However, most machine learning methods are designed to improve a model's average performance on a chosen end task without consideration for their impact on worst group error. Multitask learning (MTL) is one such widely used technique. In this paper, we seek not only to understand the impact of MTL on worst-group accuracy but also to explore its potential as a tool to address the challenge of group-wise fairness. We primarily consider the standard setting of fine-tuning a pre-trained model, where, following recent work \citep{gururangan2020don, dery2023aang}, we multitask the end task with the pre-training objective constructed from the end task data itself. In settings with few or no group annotations, we find that multitasking often, but not
    
[^155]: 在医疗AI模型中检测算法偏倚

    Detecting algorithmic bias in medical AI-models

    [https://arxiv.org/abs/2312.02959](https://arxiv.org/abs/2312.02959)

    本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚，通过采用CART算法有效地识别医疗AI模型中的潜在偏倚，并在合成数据实验和真实临床环境中验证了其有效性。

    

    随着机器学习和人工智能医疗决策支持系统日益普及，确保这些系统以公平、公正的方式提供患者结果变得同样重要。本文提出了一种创新的框架，用于检测医疗AI决策支持系统中的算法偏倚区域。我们的方法通过采用分类与回归树（CART）算法，在脓毒症预测背景下有效地识别医疗AI模型中的潜在偏倚。我们通过进行一系列合成数据实验验证了我们的方法，展示了其在受控环境中准确估计偏倚区域的能力。这一概念的有效性通过使用亚特兰大乔治亚州格雷迪纪念医院的电子病历进行实验进一步得到验证。这些测试展示了我们策略在临床中的实际应用。

    arXiv:2312.02959v3 Announce Type: replace-cross  Abstract: With the growing prevalence of machine learning and artificial intelligence-based medical decision support systems, it is equally important to ensure that these systems provide patient outcomes in a fair and equitable fashion. This paper presents an innovative framework for detecting areas of algorithmic bias in medical-AI decision support systems. Our approach efficiently identifies potential biases in medical-AI models, specifically in the context of sepsis prediction, by employing the Classification and Regression Trees (CART) algorithm. We verify our methodology by conducting a series of synthetic data experiments, showcasing its ability to estimate areas of bias in controlled settings precisely. The effectiveness of the concept is further validated by experiments using electronic medical records from Grady Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical implementation of our strategy in a clini
    
[^156]: 学习正交深度线性神经网络的收敛分析

    Convergence Analysis for Learning Orthonormal Deep Linear Neural Networks

    [https://arxiv.org/abs/2311.14658](https://arxiv.org/abs/2311.14658)

    提供了学习正交深度线性神经网络的收敛分析，通过Riemannian梯度下降以线性速率收敛于具有一类损失函数的训练正交深度线性神经网络。

    

    强制权重矩阵具有正交或等距性质已被证明可以通过减轻梯度爆炸/消失来增强深度神经网络的训练，并增加学到的网络的鲁棒性。然而，尽管具有实际性能，但神经网络中正交性的理论分析仍然缺乏；例如，正交性如何影响训练过程的收敛。在这封信中，我们旨在填补这一空白，为训练正交深度线性神经网络提供收敛分析。具体地，我们展示了通过适当初始化的Riemannian梯度下降在一类损失函数下以线性速率收敛于训练正交深度线性神经网络。与现有的通过正交化所有层的工作不同，我们的方法排除了对一个层的正交权重矩阵的要求，这对建立收敛性至关重要。

    arXiv:2311.14658v2 Announce Type: replace  Abstract: Enforcing orthonormal or isometric property for the weight matrices has been shown to enhance the training of deep neural networks by mitigating gradient exploding/vanishing and increasing the robustness of the learned networks. However, despite its practical performance, the theoretical analysis of orthonormality in neural networks is still lacking; for example, how orthonormality affects the convergence of the training process. In this letter, we aim to bridge this gap by providing convergence analysis for training orthonormal deep linear neural networks. Specifically, we show that Riemannian gradient descent with an appropriate initialization converges at a linear rate for training orthonormal deep linear neural networks with a class of loss functions. Unlike existing works that enforce orthonormal weight matrices for all the layers, our approach excludes this requirement for one layer, which is crucial to establish the convergenc
    
[^157]: 分子鉴定与峰归属：在NMR上利用多级多模态对齐

    Molecular Identification and Peak Assignment: Leveraging Multi-Level Multimodal Alignment on NMR

    [https://arxiv.org/abs/2311.13817](https://arxiv.org/abs/2311.13817)

    本文提出了一种新颖的解决方案，即多级多模态对齐（K-M3AID），通过在分子图和NMR光谱之间建立对应关系，采用知识引导的实例级对比学习，以解决分子检索、异构体识别和峰归属等任务中的挑战。

    

    arXiv:2311.13817v2 公告类型：替换 摘要：核磁共振（NMR）光谱在解读分子结构和动态行为方面起着至关重要的作用。虽然基于AI的NMR预测模型具有潜力，但在分子检索、异构体识别和峰归属等任务中仍然存在挑战。为此，本文引入了一种新颖的解决方案，即具有知识引导的实例级对齐的多级多模态对齐（K-M3AID），该解决方案在两种异质模态之间建立对应关系：分子图和NMR光谱。K-M3AID采用了一个双协调对比学习架构，包含三个关键模块：图级对齐模块、节点级对齐模块和通信通道。值得注意的是，在节点级对齐模块中，K-M3AID引入了知识引导的实例级对比学习。此外，K-M3AID表明在节点级对齐过程中获得的技能

    arXiv:2311.13817v2 Announce Type: replace  Abstract: Nuclear magnetic resonance (NMR) spectroscopy plays an essential role in deciphering molecular structure and dynamic behaviors. While AI-enhanced NMR prediction models hold promise, challenges still persist in tasks such as molecular retrieval, isomer recognition, and peak assignment. In response, this paper introduces a novel solution, Multi-Level Multimodal Alignment with Knowledge-Guided Instance-Wise Discrimination (K-M3AID), which establishes correspondences between two heterogeneous modalities: molecular graphs and NMR spectra. K-M3AID employs a dual-coordinated contrastive learning architecture with three key modules: a graph-level alignment module, a node-level alignment module, and a communication channel. Notably, K-M3AID introduces knowledge-guided instance-wise discrimination into contrastive learning within the node-level alignment module. In addition, K-M3AID demonstrates that skills acquired during node-level alignment
    
[^158]: FedHCA$^2$: 面向异构客户联邦多任务学习

    FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning

    [https://arxiv.org/abs/2311.13250](https://arxiv.org/abs/2311.13250)

    本文介绍了FedHCA$^2$框架，旨在解决异构客户联邦多任务学习中的模型不一致问题，实现个性化模型联邦训练。

    

    联邦学习（FL）通过使用客户端的本地数据进行联合训练，从而实现了分布式客户端之间的联合训练。联邦多任务学习（FMTL）建立在FL基础上，用于处理多个任务，假设模型的一致性，即在每个客户端部署相同的模型架构。为了放宽这一假设，从而扩展现实世界的适用性，我们引入了一个新颖的问题设置，即面向异构客户的联邦多任务学习（HC-FMTL），以适应多样的任务设置。HC-FMTL的主要挑战是模型不一致问题，这使传统聚合方法失效。这也使得准确模型聚合以处理FMTL中固有的数据和任务异质性的困难加剧。为了解决这些挑战，我们提出了FedHCA$^2$框架，它允许通过对异构客户之间的关系进行建模来进行个性化模型的联邦训练。根据我们对客户端不同之处的理论见解，我们发现

    arXiv:2311.13250v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) enables joint training across distributed clients using their local data privately. Federated Multi-Task Learning (FMTL) builds on FL to handle multiple tasks, assuming model congruity that identical model architecture is deployed in each client. To relax this assumption and thus extend real-world applicability, we introduce a novel problem setting, Hetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse task setups. The main challenge of HC-FMTL is the model incongruity issue that invalidates conventional aggregation methods. It also escalates the difficulties in accurate model aggregation to deal with data and task heterogeneity inherent in FMTL. To address these challenges, we propose the FedHCA$^2$ framework, which allows for federated training of personalized models by modeling relationships among heterogeneous clients. Drawing on our theoretical insights into the difference be
    
[^159]: 经过模型性能约束的最小核心集大小精化选择

    Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints

    [https://arxiv.org/abs/2311.08675](https://arxiv.org/abs/2311.08675)

    探索了在模型性能约束下的最小核心集大小精化选择问题，并提出了一种创新方法来有效地优化核心集大小和模型性能，同时提供了理论上的收敛保证。

    

    核心集选择在减少计算成本、加速深度学习算法数据处理方面具有强大的作用。它致力于从大规模数据中识别一个小的子集，从而仅在子集上训练就能实际上与完整数据表现相当。实践者经常希望在现实场景中识别可能的最小核心集，同时保持可比较的模型性能，以最小化成本和最大化加速。受此愿景的启发，我们首次提出了经过精化的核心集选择问题，探讨了在模型性能约束下的最小核心集大小。此外，为了解决这个问题，我们提出了一种创新方法，该方法在核心集选择过程中保持优化优先顺序，优先考虑模型性能和核心集大小，并有效地优化它们。在理论上，我们提供了所提出方法的收敛保证。

    arXiv:2311.08675v2 Announce Type: replace  Abstract: Coreset selection is powerful in reducing computational costs and accelerating data processing for deep learning algorithms. It strives to identify a small subset from large-scale data, so that training only on the subset practically performs on par with full data. Practitioners regularly desire to identify the smallest possible coreset in realistic scenes while maintaining comparable model performance, to minimize costs and maximize acceleration. Motivated by this desideratum, for the first time, we pose the problem of refined coreset selection, in which the minimal coreset size under model performance constraints is explored. Moreover, to address this problem, we propose an innovative method, which maintains optimization priority order over the model performance and coreset size, and efficiently optimizes them in the coreset selection procedure. Theoretically, we provide the convergence guarantee of the proposed method. Empirically
    
[^160]: 重新审视假设：预训练的Transformer是否通过梯度下降在上下文中学习？

    Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?

    [https://arxiv.org/abs/2310.08540](https://arxiv.org/abs/2310.08540)

    本研究重新审视了预训练的Transformer是否通过梯度下降在上下文中学习的假设，并发现现有研究中的假设存在限制性假设，使其与实际语言模型训练时的语境存在显著差异。同时，通过对真实模型的观察和比较，揭示了ICL和GD在观察演示顺序上的不同敏感性。

    

    LLM中的In-Context Learning（ICL）的出现仍然是一个重要现象，但我们对其了解甚少。为了解释ICL，最近的研究尝试在理论上将其与梯度下降（GD）联系起来。我们问，这种联系在实际预训练模型中是否成立？我们强调先前作品中的限制性假设使得它们的语境与语言模型实际训练时的实际语境差别很大。例如，这些研究中使用的理论手工构造的权重具有与真实LLM不匹配的属性。此外，他们的实验验证使用ICL目标（明确为ICL训练模型），这与野外出现的ICL有所不同。我们还寻找了真实模型中的证据。我们观察到ICL和GD对于观察演示的顺序有不同的敏感性。最后，我们在自然环境中探讨并比较ICL与GD假设。

    arXiv:2310.08540v4 Announce Type: replace-cross  Abstract: The emergence of In-Context Learning (ICL) in LLMs remains a significant phenomenon with little understanding. To explain ICL, recent studies try to theoretically connect it to Gradient Descent (GD). We ask, does this connection hold up in actual pre-trained models?   We highlight the limiting assumptions in prior works that make their context considerably different from the practical context in which language models are trained. For example, the theoretical hand-constructed weights used in these studies have properties that don't match those of real LLMs. Furthermore, their experimental verification uses ICL objective (training models explicitly for ICL), which differs from the emergent ICL in the wild.   We also look for evidence in real models. We observe that ICL and GD have different sensitivity to the order in which they observe demonstrations. Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting. 
    
[^161]: 分析2022年法国选举中流行的Twitter话题

    Analyzing Trendy Twitter Hashtags in the 2022 French Election

    [https://arxiv.org/abs/2310.07576](https://arxiv.org/abs/2310.07576)

    提出了一种使用语义网络作为用户级特征进行机器学习任务的方法，通过分析2022年法国总统选举相关的Twitter标签构建了一个双分图，并将其转换为具有最受欢迎的哈希标签的最大生成树

    

    训练用于预测社交媒体用户未来活动的回归模型需要丰富的特征才能得到准确的预测。许多先进模型用于生成这些特征；然而，当它们在海量数据集上运行时，它们的计算时间复杂度通常是禁锢的。一些研究表明，简单的语义网络特征可能足够丰富，可用于回归而无需复杂的计算。我们提出了一种使用语义网络作为用户级特征进行机器学习任务的方法。我们进行了一项实验，使用了一个包含370万条与2022年法国总统选举有关的推文的1037个Twitter标签的语义网络。构建了一个双分图，其中标签是节点，带权边连接标签，反映了与这些标签互动的Twitter用户数量。然后将图转换为具有最受欢迎的哈希标签的最大生成树。

    arXiv:2310.07576v2 Announce Type: replace-cross  Abstract: Regressions trained to predict the future activity of social media users need rich features for accurate predictions. Many advanced models exist to generate such features; however, the time complexities of their computations are often prohibitive when they run on enormous data-sets. Some studies have shown that simple semantic network features can be rich enough to use for regressions without requiring complex computations. We propose a method for using semantic networks as user-level features for machine learning tasks. We conducted an experiment using a semantic network of 1037 Twitter hashtags from a corpus of 3.7 million tweets related to the 2022 French presidential election. A bipartite graph is formed where hashtags are nodes and weighted edges connect the hashtags reflecting the number of Twitter users that interacted with both hashtags. The graph is then transformed into a maximum-spanning tree with the most popular ha
    
[^162]: 通过逻辑增强大型语言模型中的零射链推理能力

    Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    [https://arxiv.org/abs/2309.13339](https://arxiv.org/abs/2309.13339)

    提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。

    

    大型语言模型的最新进展展示了它们在各个领域的 remarkable generalizability。然而，它们的推理能力仍有很大的提升空间，特别是在需要多步推理的情况下。尽管大型语言模型具有广泛的知识，但它们的推理经常未能有效利用这些知识来建立连贯的思维范式。这些模型有时会出现幻觉，因为它们的推理过程未受逻辑原则的限制。为了改进大型语言模型的零射链推理能力，我们提出了 LoT（Logical Thoughts）提示，这是一个自我改进的框架，利用根植于符号逻辑的原则，特别是归谬法，逐步系统地验证和纠正推理过程。在语言任务上进行的实验评估

    arXiv:2309.13339v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts) prompting, a self-improvement framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in
    
[^163]: 鸡尾酒：混合多模态控制以进行文本条件图像生成

    Cocktail: Mixing Multi-Modality Controls for Text-Conditional Image Generation

    [https://arxiv.org/abs/2306.00964](https://arxiv.org/abs/2306.00964)

    提出了鸡尾酒方法，将不同模态混合到一个嵌入中，结合通用控制网络、可控归一化和空间引导采样方法，实现了对文本条件扩散模型的多模态和空间精细控制。

    

    arXiv:2306.00964v1 公告类型：交叉 摘要：文本条件扩散模型能够生成具有不同内容的高保真图像。然而，语言表示经常展示对所设想目标图像的模棱两可描述，需要引入额外的控制信号来增强文本引导扩散模型的功效。在这项工作中，我们提出了鸡尾酒，这是一个将各种模态混合为一个嵌入的流水线，与通用控制网络（gControlNet）、可控归一化（ControlNorm）和空间引导采样方法相结合，以实现文本条件扩散模型的多模态和空间精细控制。具体而言，我们引入了一个超网络gControlNet，专门用于将来自不同模态的控制信号与预训练扩散模型进行对齐和融合。gControlNet能够接受灵活的模态信号，包括同时接收任何

    arXiv:2306.00964v1 Announce Type: cross  Abstract: Text-conditional diffusion models are able to generate high-fidelity images with diverse contents. However, linguistic representations frequently exhibit ambiguous descriptions of the envisioned objective imagery, requiring the incorporation of additional control signals to bolster the efficacy of text-guided diffusion models. In this work, we propose Cocktail, a pipeline to mix various modalities into one embedding, amalgamated with a generalized ControlNet (gControlNet), a controllable normalisation (ControlNorm), and a spatial guidance sampling method, to actualize multi-modal and spatially-refined control for text-conditional diffusion models. Specifically, we introduce a hyper-network gControlNet, dedicated to the alignment and infusion of the control signals from disparate modalities into the pre-trained diffusion model. gControlNet is capable of accepting flexible modality signals, encompassing the simultaneous reception of any 
    
[^164]: 差分扩散：赋予每个像素以其强度

    Differential Diffusion: Giving Each Pixel Its Strength

    [https://arxiv.org/abs/2306.00950](https://arxiv.org/abs/2306.00950)

    该论文介绍了一种新颖的框架，允许对每个像素或图像区域的改变量进行定制化，为扩散模型增加了粒度控制的能力，进一步扩展了图像编辑的功能。

    

    扩散模型在图像生成和编辑方面产生了革命性的变化，取得了在有条件和无条件图像合成方面的最新结果。该论文引入了一种新颖的框架，使得每个像素或图像区域的改变量可以进行定制化。我们的框架可以集成到任何现有的扩散模型中，为其增加这种功能。对变化量的粒度控制打开了各种新的编辑能力，如控制单个对象被修改的程度，或者引入逐渐的空间变化等。此外，我们展示了该框架在软修复方面的有效性，即在完成图像部分的同时，微调周围区域以确保一致。

    arXiv:2306.00950v2 Announce Type: replace-cross  Abstract: Diffusion models have revolutionized image generation and editing, producing state-of-the-art results in conditioned and unconditioned image synthesis. While current techniques enable user control over the degree of change in an image edit, the controllability is limited to global changes over an entire edited region. This paper introduces a novel framework that enables customization of the amount of change per pixel or per image region. Our framework can be integrated into any existing diffusion model, enhancing it with this capability. Such granular control on the quantity of change opens up a diverse array of new editing capabilities, such as control of the extent to which individual objects are modified, or the ability to introduce gradual spatial changes. Furthermore, we showcase the framework's effectiveness in soft-inpainting -- the completion of portions of an image while subtly adjusting the surrounding areas to ensure
    
[^165]: 在不断学习的表示中的知识积累与特征遗忘问题

    Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting

    [https://arxiv.org/abs/2304.00933](https://arxiv.org/abs/2304.00933)

    揭示了持续学习表示中的知识积累和特征遗忘问题，表明即使特征遗忘的绝对程度可能较小，新学习的信息在表示层面也面临着严重遗忘。

    

    连续学习研究表明，神经网络在“输出级别”遭受灾难性遗忘，但有争议的是是否在学习的表示级别也存在这种情况。多个最近的研究将表示归因为具有一定程度的固有抗遗忘性 - 仅会最小程度忘记且不会遗失关键信息。我们重新审视并扩展了揭示这种遗忘差异的实验，说明了影响持续学习表示质量的两种现象共存：知识积累和特征遗忘。我们谨慎考虑了这两个方面，表明尽管绝对值上特征遗忘可能较小，新学习的信息在表示层面与输出层面一样面临灾难性遗忘。接下来，我们展示了这种特征遗忘问题

    arXiv:2304.00933v3 Announce Type: replace  Abstract: Continual learning research has shown that neural networks suffer from catastrophic forgetting "at the output level", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally and no critical information. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Carefully taking both aspects into account, we show that, even though it is true that feature forgetting can be small in absolute terms, newly learned information tends to be forgotten just as catastrophically at the level of the representation as it is at the output level. Next we show that this feature forgetting is problem
    
[^166]: 基于半监督随机森林的分类和异常检测的一致化方法

    Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection

    [https://arxiv.org/abs/2302.02237](https://arxiv.org/abs/2302.02237)

    提出了一种名为CSForest的方法，利用Conformalized Semi-Supervised Random Forest技术来解决训练集和测试集之间的差异，提高准确性并标识未见的离群值。

    

    随机森林分类器作为一种广泛使用的即插即用分类工具，假设训练和测试样本与其他标准分类器来自相同分布。然而，在诸如医学诊断和网络攻击检测等关键安全场景中，训练集和测试集之间的差异，包括潜在出现在训练期间未见的新离群样本，可能带来重大挑战。为解决这一问题，我们引入了一种称为Conformalized Semi-Supervised Random Forest (CSForest)的方法，该方法将一致化技术Jackknife+aB与半监督树集成相结合，构建一个集值预测 C(x)。CSForest不再优化训练分布，而是利用未标记的测试样本来提高准确性，并通过生成空集来标识未见的离群值。从理论上讲，我们建立了CSForest覆盖以前观察到的内群类的真实标签。

    arXiv:2302.02237v2 Announce Type: replace  Abstract: The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes un
    
[^167]: IMG2IMU：从大规模图像向IMU感知应用的知识转化

    IMG2IMU: Translating Knowledge from Large-Scale Images to IMU Sensing Applications

    [https://arxiv.org/abs/2209.00945](https://arxiv.org/abs/2209.00945)

    通过将大规模图像中预训练获得的表示适应于IMU感知任务，提出了IMG2IMU方法，实现了对IMU感知应用的知识转化。

    

    通过自监督学习获取的预训练表示在即使是训练数据较少的任务上也能达到很高的准确性。与视觉和自然语言处理领域不同，IMU感知应用的预训练具有挑战性，因为公开数据集中没有足够规模和多样性用以学习具有泛化能力的表示。为了解决这一问题，我们提出了IMG2IMU，将从大规模图像中获得的预训练表示适应于各种IMU感知任务。我们将传感器数据转换为可视化的谱图，供模型利用从视觉中获取的知识。我们进一步提出了一种面向图像的传感器感知预训练方法，使模型能够获取对IMU感知应用具有特别影响的知识。这涉及在我们为传感器数据属性定制的增强集上使用对比学习。我们在四种不同的IMU感知任务上进行了评估

    arXiv:2209.00945v2 Announce Type: replace  Abstract: Pre-training representations acquired via self-supervised learning could achieve high accuracy on even tasks with small training data. Unlike in vision and natural language processing domains, pre-training for IMU-based applications is challenging, as there are few public datasets with sufficient size and diversity to learn generalizable representations. To overcome this problem, we propose IMG2IMU that adapts pre-trained representation from large-scale images to diverse IMU sensing tasks. We convert the sensor data into visually interpretable spectrograms for the model to utilize the knowledge gained from vision. We further present a sensor-aware pre-training method for images that enables models to acquire particularly impactful knowledge for IMU sensing applications. This involves using contrastive learning on our augmentation set customized for the properties of sensor data. Our evaluation with four different IMU sensing tasks sh
    
[^168]: 跨领域跨任务迁移学习中的传递性指导

    Transferability-Guided Cross-Domain Cross-Task Transfer Learning

    [https://arxiv.org/abs/2207.05510](https://arxiv.org/abs/2207.05510)

    提出了两种新的传递性度量标准 F-OTCE 和 JC-OTCE，用于评估源模型对目标任务的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。

    

    我们提出了两种新的传递性度量标准 F-OTCE（基于快速最优传输的条件熵）和 JC-OTCE（联合对应 OTCE），用于评估源模型（任务）对目标任务学习的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。与现有的度量标准不同，它们需要在辅助任务上评估经验传递性，我们的度量标准是无需辅助的，因此可以更高效地计算。具体而言，F-OTCE首先通过在源和目标分布之间解决最优传输（OT）问题来估计传递性，然后使用最优耦合来计算源和目标标签之间的负条件熵。它还可以作为损失函数，在微调目标任务之前最大化源模型的传递性。同时，JC-OTCE改善了传递性...

    arXiv:2207.05510v2 Announce Type: replace-cross  Abstract: We propose two novel transferability metrics F-OTCE (Fast Optimal Transport based Conditional Entropy) and JC-OTCE (Joint Correspondence OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more transferable representations for cross-domain cross-task transfer learning. Unlike the existing metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an Optimal Transport (OT) problem between source and target distributions, and then uses the optimal coupling to compute the Negative Conditional Entropy between source and target labels. It can also serve as a loss function to maximize the transferability of the source model before finetuning on the target task. Meanwhile, JC-OTCE improves the transferability r
    
[^169]: 具有主动学习的神经Galerkin方案用于高维演化方程

    Neural Galerkin Schemes with Active Learning for High-Dimensional Evolution Equations

    [https://arxiv.org/abs/2203.01360](https://arxiv.org/abs/2203.01360)

    通过神经Galerkin方案结合深度学习和主动学习，能够自主生成训练数据用于高维偏微分方程的数值求解

    

    深度神经网络已被证明能够在高维度中提供准确的函数逼近。然而，拟合网络参数需要信息丰富的训练数据，在科学和工程应用中往往难以收集。本文提出了基于深度学习的神经Galerkin方案，通过主动学习生成训练数据，用于数值求解高维偏微分方程。神经Galerkin方案基于Dirac-Frenkel变分原理，通过随时间顺序最小化残差来训练网络，这使得能够以自主、动态描述的方式收集新的训练数据，以指导偏微分方程描述的动态。这与其他机器学习方法形成对比，其他方法旨在全局时间内拟合网络参数，而不考虑训练数据获取。我们的发现是主动形式的

    arXiv:2203.01360v4 Announce Type: replace-cross  Abstract: Deep neural networks have been shown to provide accurate function approximations in high dimensions. However, fitting network parameters requires informative training data that are often challenging to collect in science and engineering applications. This work proposes Neural Galerkin schemes based on deep learning that generate training data with active learning for numerically solving high-dimensional partial differential equations. Neural Galerkin schemes build on the Dirac-Frenkel variational principle to train networks by minimizing the residual sequentially over time, which enables adaptively collecting new training data in a self-informed manner that is guided by the dynamics described by the partial differential equations. This is in contrast to other machine learning methods that aim to fit network parameters globally in time without taking into account training data acquisition. Our finding is that the active form of 
    
[^170]: CAREER：劳动序列数据的基础模型

    CAREER: A Foundation Model for Labor Sequence Data

    [https://arxiv.org/abs/2202.08370](https://arxiv.org/abs/2202.08370)

    CAREER模型结合大规模在线简历数据和小型纵向调查数据，有效预测工作序列。

    

    劳动经济学家经常通过将预测模型拟合到小型、精心构建的纵向调查数据集中来分析就业数据。近年来，大量在线简历数据集也变得可用，提供了数百万人的职业轨迹数据。为此，我们开发了一种名为CAREER的基础模型，用于工作序列。首先，将CAREER拟合到大规模被动收集的简历数据上，然后微调到规模较小、更好筛选过的数据集以进行经济推断。我们将CAREER拟合到了包含来自简历的2400万个工作序列的数据集中，并在小型纵向调查数据集上进行了调整。我们发现，CAREER能够准确预测工作序列。

    arXiv:2202.08370v4 Announce Type: replace  Abstract: Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences
    
[^171]: 在矢量量化建模中应用离散扩散的全局背景在图像生成中的应用

    Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation

    [https://arxiv.org/abs/2112.01799](https://arxiv.org/abs/2112.01799)

    结合VQ-VAE的内容丰富的离散视觉码书，离散扩散模型能够生成具有全局背景的高保真度图像，弥补了传统自回归模型在像素空间中的不足。

    

    将矢量量化变分自动编码器（VQ-VAE）与自回归模型整合作为生成部分在图像生成上取得了高质量结果。然而，在采样阶段，自回归模型会严格遵循逐渐扫描顺序，这导致现有的VQ系列模型很难摆脱缺乏全局信息的困境。在连续域中，去噪扩散概率模型（DDPM）已经显示出捕捉全局背景的能力，同时生成高质量图像。在离散状态空间中，一些研究已经展示了执行文本生成和低分辨率图像生成的潜力。我们表明，通过从VQ-VAE获得内容丰富的离散视觉码书的帮助，离散扩散模型也能生成具有全局背景的高保真度图像，从而弥补了经典自回归模型在像素空间上的不足。

    arXiv:2112.01799v1 Announce Type: cross  Abstract: The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. 
    
[^172]: 自主人工智能代理的自主开放世界学习

    Self-Initiated Open World Learning for Autonomous AI Agents

    [https://arxiv.org/abs/2110.11385](https://arxiv.org/abs/2110.11385)

    论文提出了一种自主开放世界学习的方法，使人工智能代理能够在自主、自我激励和自我监督的方式下学习，以应对未知或新颖性环境中的挑战，实现逐步学习和提升知识与能力。

    

    随着越来越多的人工智能代理被实际应用，是时候考虑如何使这些代理完全自主，以便它们可以自主学习，而不是定期由人类工程师启动并使用扩展的训练数据进行重新训练。由于现实世界是一个具有未知或新颖性的开放环境，检测新颖性或未知性，描述它们，适应或适应它们，收集地面真实训练数据，并逐步学习未知和新颖性对于使代理越来越有知识和能力变得至关重要。关键挑战在于如何自动化这个过程，使其由代理主动进行并通过其与人类和环境的互动进行。由于人工智能代理通常有一个性能任务，因此对每种新颖性进行特征化变得至关重要和必要，以便代理可以制定

    arXiv:2110.11385v3 Announce Type: replace  Abstract: As more and more AI agents are used in practice, it is time to think about how to make these agents fully autonomous so that they can learn by themselves in a self-motivated and self-supervised manner rather than being retrained periodically on the initiation of human engineers using expanded training data. As the real-world is an open environment with unknowns or novelties, detecting novelties or unknowns, characterizing them, accommodating or adapting to them, gathering ground-truth training data, and incrementally learning the unknowns/novelties are critical to making the agent more and more knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried out on the agent's own initiative and through its own interactions with humans and the environment. Since an AI agent usually has a performance task, characterizing each novelty becomes critical and necessary so that the agent can formu
    
[^173]: 图像分类任务的实用可转移性估计

    Practical Transferability Estimation for Image Classification Tasks

    [https://arxiv.org/abs/2106.10479](https://arxiv.org/abs/2106.10479)

    提出了一个实用的转移性度量JC-NCE分数，通过显著改善OTCE中任务差异估计的鲁棒性，消除了对辅助任务的需求。

    

    可转移性估计是迁移学习中的一个关键问题，用于预测将源模型（或源任务）转移到目标任务时性能有多好。最近，分析性的转移性度量已被广泛用于源模型选择和多任务学习。主要挑战是如何在跨领域跨任务的设置下使转移性估计具有鲁棒性。最近提出的OTCE分数通过考虑域和任务差异来解决这个问题，借助辅助任务的转移经验，但这会导致效率开销。在这项工作中，我们提出了一个称为JC-NCE分数的实用转移性度量，显著改善了OTCE中任务差异估计的鲁棒性，从而消除了对辅助任务的需求。具体而言，通过解决最优输运问题建立源数据和目标数据之间的联合对应。

    arXiv:2106.10479v3 Announce Type: replace-cross  Abstract: Transferability estimation is an essential problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. Recent analytical transferability metrics have been widely used for source model selection and multi-task learning. A major challenge is how to make transfereability estimation robust under the cross-domain cross-task settings. The recently proposed OTCE score solves this problem by considering both domain and task differences, with the help of transfer experiences on auxiliary tasks, which causes an efficiency overhead. In this work, we propose a practical transferability metric called JC-NCE score that dramatically improves the robustness of the task difference estimation in OTCE, thus removing the need for auxiliary tasks. Specifically, we build the joint correspondences between source and target data via solving an optimal transport problem with a 
    
[^174]: 离线检测平稳图信号均值变化点

    Offline detection of change-points in the mean for stationary graph signals

    [https://arxiv.org/abs/2006.10628](https://arxiv.org/abs/2006.10628)

    提出了一种离线方法用于检测图信号中均值变化点，通过在频谱域解决问题，充分利用了稀疏性，采用模型选择方法自动确定变点的数量，并给出了非渐近oracle不等式的证明。

    

    这篇论文解决了图信号流分割的问题：我们旨在检测已知图上的多变量信号均值变化。我们提出了一种离线方法，依赖于图信号平稳性的概念，并允许将问题从原始顶点域转换到频谱域（图傅里叶变换），在那里更容易解决。虽然在实际应用中获得的频谱表示是稀疏的，但据我们所知，这种特性在现有相关文献中尚未得到充分利用。我们的变点检测方法采用模型选择方法，考虑了频谱表示的稀疏性，并自动确定变点的数量。我们的检测器伴随着非渐近优等性的证明。数值实验展示了该方法的性能。

    arXiv:2006.10628v2 Announce Type: replace  Abstract: This paper addresses the problem of segmenting a stream of graph signals: we aim to detect changes in the mean of a multivariate signal defined over the nodes of a known graph. We propose an offline method that relies on the concept of graph signal stationarity and allows the convenient translation of the problem from the original vertex domain to the spectral domain (Graph Fourier Transform), where it is much easier to solve. Although the obtained spectral representation is sparse in real applications, to the best of our knowledge this property has not been sufficiently exploited in the existing related literature. Our change-point detection method adopts a model selection approach that takes into account the sparsity of the spectral representation and determines automatically the number of change-points. Our detector comes with a proof of a non-asymptotic oracle inequality. Numerical experiments demonstrate the performance of the p
    
[^175]: 委员会机器：学习两层神经网络中计算到统计学差距的研究

    The committee machine: Computational to statistical gaps in learning a two-layers neural network

    [https://arxiv.org/abs/1806.05451](https://arxiv.org/abs/1806.05451)

    介绍了对于两层神经网络模型委员会机器的严格理论基础和近似消息传递算法，揭示了计算到统计学差距。

    

    过去，统计物理学中的启发式工具被用来定位相变并计算多层神经网络中教师-学生场景中的最优学习和泛化错误。在这篇论文中，我们为一个名为委员会机器的两层神经网络模型提供了这些方法的严格理论基础。我们还引入了一个委员会机器的近似消息传递（AMP）算法版本，允许在多种参数下以多项式时间执行最佳学习。我们发现在某些情况下，虽然AMP算法无法实现，但在信息理论上可以实现低泛化错误率，这强烈暗示对于这些情况不存在有效算法，揭示了一个巨大的计算差距。

    arXiv:1806.05451v3 Announce Type: replace  Abstract: Heuristic tools from statistical physics have been used in the past to locate the phase transitions and compute the optimal learning and generalization errors in the teacher-student scenario in multi-layer neural networks. In this contribution, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows to perform optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it, strongly suggesting that no efficient algorithm exists for those cases, and unveiling a large computational gap.
    
[^176]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^177]: 超越反遗忘: 带有正向传递的多模态连续指导调优

    Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer. (arXiv:2401.09181v1 [cs.LG])

    [http://arxiv.org/abs/2401.09181](http://arxiv.org/abs/2401.09181)

    本研究提出了一种名为Fwd-Prompt的方法，通过对输入嵌入进行奇异值分解，并在残差空间和预训练子空间中进行梯度投影，以解决多模态连续指导调优中的灾难性遗忘和负面的正向传递问题。

    

    多模态连续指导调优（MCIT）使得多模态大型语言模型（MLLMs）可以满足不断出现的需求，而无需昂贵的重新训练。MCIT面临两个主要障碍：灾难性遗忘（旧知识被遗忘）和负面的正向传递（未来任务的性能下降）。虽然现有方法大大缓解了灾难性遗忘，但仍然遭受负面的正向传递。通过对输入嵌入进行奇异值分解（SVD），我们发现不同输入嵌入之间存在很大差异。这种差异导致模型学习与旧的和预训练的任务无关的信息，从而导致灾难性遗忘和负面的正向传递。为了解决这些问题，我们提出了Fwd-Prompt，这是一种基于提示的方法，将提示梯度投影到残差空间中，以减小任务之间的干扰，并投影到预训练子空间中以重用预训练的知识。

    Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large Language Models (MLLMs) to meet continuously emerging requirements without expensive retraining. MCIT faces two major obstacles: catastrophic forgetting (where old knowledge is forgotten) and negative forward transfer (where the performance of future tasks is degraded). Although existing methods have greatly alleviated catastrophic forgetting, they still suffer from negative forward transfer. By performing singular value decomposition (SVD) on input embeddings, we discover a large discrepancy in different input embeddings. The discrepancy results in the model learning irrelevant information for old and pre-trained tasks, which leads to catastrophic forgetting and negative forward transfer. To address these issues, we propose Fwd-Prompt, a prompt-based method projecting prompt gradient to the residual space to minimize the interference between tasks and to the pre-trained subspace for reusing pre-trained knowledge. 
    
[^178]: 离线目标条件强化学习的评分模型

    Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])

    [http://arxiv.org/abs/2311.02013](http://arxiv.org/abs/2311.02013)

    本文提出了一种新颖的离线目标条件强化学习方法，称为SMORe，它将占有匹配的视角与混合分布匹配相结合，无需学习鉴别器，从而提高了GCRL在离线环境中的表现。

    

    离线目标条件强化学习（GCRL）的任务是使用稀疏奖励函数从离线数据集中学习在环境中实现多个目标。离线GCRL对于开发能够利用预先存在的数据集学习多样化和可复用技能的通用型代理至关重要，而无需手工设计奖励函数。然而，基于监督学习和对比学习的现代GCRL方法在离线环境中往往不太理想。GCRL的另一种观点是优化占有匹配，但需要学习鉴别器，随后该鉴别器作为下游强化学习的伪奖励。学习到的鉴别器的不准确性可能会导致负面影响，进而影响生成的策略。我们提出了一种新颖的GCRL方法，基于混合分布匹配的新视角，采用无鉴别器的方法：SMORe。关键洞见是将GCRL的占有匹配视角与一个有效的聚类算法相结合，从而得到了我们的无鉴别器方法：SMORe。

    Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a conve
    
[^179]: 随机性的福音：SDE在一般扩散图像编辑中超过ODE

    The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing. (arXiv:2311.01410v1 [cs.CV])

    [http://arxiv.org/abs/2311.01410](http://arxiv.org/abs/2311.01410)

    本论文提出了一种概率形式的扩散图像编辑方法，说明了SDE在图像编辑中的优势，并提供了SDE和ODE在各种任务中的对应关系。此外，还提出了一种基于SDE的点在图像上拖动的方法，并建立了一个具有开放集的挑战性基准。

    

    我们提出了一种统一的概率形式的扩散图像编辑方法，在这种方法中，一个隐变量以特定任务的方式进行编辑，并且通常与原始随机微分方程（SDE）或常微分方程（ODE）引发的边缘分布有所不同。相反，它为编辑定义了相应的SDE或ODE。在这种方法中，我们证明了两个SDE的边缘分布之间的Kullback-Leibler散度逐渐减小，而对于ODE来说，随着时间趋近于零，散度保持不变，这显示了SDE在图像编辑中的优势。受此启发，我们提供了各种任务中常用的ODE基线的SDE对应物，包括修复和图像到图像的转换，在这些任务中，SDE显示了一致且显著的改进。此外，我们还提出了SDE-Drag - 一种简单而有效的基于SDE公式的点在图像上拖动的方法。我们还建立了一个具有开放集的挑战性基准（称为DragBench） 。

    We present a unified probabilistic formulation for diffusion-based image editing, where a latent variable is edited in a task-specific manner and generally deviates from the corresponding marginal distribution induced by the original stochastic or ordinary differential equation (SDE or ODE). Instead, it defines a corresponding SDE or ODE for editing. In the formulation, we prove that the Kullback-Leibler divergence between the marginal distributions of the two SDEs gradually decreases while that for the ODEs remains as the time approaches zero, which shows the promise of SDE in image editing. Inspired by it, we provide the SDE counterparts for widely used ODE baselines in various tasks including inpainting and image-to-image translation, where SDE shows a consistent and substantial improvement. Moreover, we propose SDE-Drag -- a simple yet effective method built upon the SDE formulation for point-based content dragging. We build a challenging benchmark (termed DragBench) with open-set 
    
[^180]: 提问更多，了解更多：利用大型语言模型强化学习的决策问题与思维链

    Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models. (arXiv:2310.18127v1 [cs.LG])

    [http://arxiv.org/abs/2310.18127](http://arxiv.org/abs/2310.18127)

    本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。

    

    大型语言模型通过将基于行动的策略与思维链（CoT）推理相结合，展示了解决复杂实际挑战的潜力。然而，对于该框架的有效性来说，具有高质量的提示非常重要。目前，这些提示是通过广泛使用人力手工制作的，导致CoT策略经常无法推广。为了确保低层控制器适当地处理CoT推理，还需要人为介入来开发接地函数。在本文中，我们迈出了迈向在复杂推理中应用实际环境中的任务解决的完全集成的端到端框架的第一步。为此，我们提供了一个新的领导者-追随者双层框架，能够学习提问相关问题（提示），并随后进行推理，指导在环境中执行的行为的学习。一个好的提示应该基于历史的自省性修订来进行修改。

    Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilizing extensive human labor, resulting in CoT policies that frequently fail to generalize. Human intervention is also required in order to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we take the first step towards a fully integrated end-to-end framework for task-solving in real settings employing complicated reasoning. To that purpose, we offer a new leader-follower bilevel framework capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions to be performed in an environment. A good prompt should make introspective revisions based on historical fi
    
[^181]: 将循环引入人类：协作和可解释的贝叶斯优化

    Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])

    [http://arxiv.org/abs/2310.17273](http://arxiv.org/abs/2310.17273)

    协作和可解释的贝叶斯优化框架(CoExBO)在贝叶斯优化中引入了循环，平衡了人工智能和人类的合作关系。它利用偏好学习将用户见解融合到优化中，解释每次迭代的候选选择，从而增强用户对优化过程的信任，并提供无害保证。

    

    像许多优化器一样，贝叶斯优化在获得用户信任方面常常存在不足，因为其不透明性。虽然已经尝试开发面向人类的优化器，但它们通常假设用户知识是明确且无误的，并主要将用户作为优化过程的监督者。我们放宽了这些假设，提出了一种更平衡的人工智能和人类合作伙伴关系，即我们的协作和可解释的贝叶斯优化（CoExBO）框架。CoExBO使用偏好学习来无缝地将人类见解整合到优化中，从而产生与用户使用偏好一致的算法建议。CoExBO解释其每次迭代的候选选择，以培养信任，使用户更清楚地掌握优化的过程。此外，CoExBO提供无害保证，允许用户犯错误；即使在极端对抗性干扰下，算法也会渐进地收敛。

    Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
    
[^182]: 扩展深度自适应输入规范化用于神经网络对时序数据的预处理

    Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks. (arXiv:2310.14720v1 [cs.LG])

    [http://arxiv.org/abs/2310.14720](http://arxiv.org/abs/2310.14720)

    本研究提出了一种名为EDAIn的扩展深度自适应输入规范化层，通过以端到端的方式学习如何适当地规范化时序数据，而不是使用固定的规范化方案，来提高深度神经网络在时序预测和分类任务中的性能。实验证明该方法在不同数据集上都取得了良好效果。

    

    数据预处理是任何机器学习流程中至关重要的一部分，它对性能和训练效率都有重要影响。当使用深度神经网络进行时序预测和分类时，这一点尤为明显：真实世界的时序数据通常表现出多样性、偏斜和异常值等不规则特征，如果不充分处理这些特征，模型性能很快会下降。在本研究中，我们提出了EDAIN（扩展深度自适应输入规范化）层，一种新颖的自适应神经层，它能够以端到端的方式学习如何适当地规范化不规则的时序数据，而不是使用固定的规范化方案。这通过使用反向传播算法，同时优化其未知参数和深度神经网络来实现。我们的实验证明，这一方法在使用合成数据、信用违约预测数据集和大规模限价单簿基准数据集时都取得了良好效果。

    Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark datase
    
[^183]: 一种基于机器学习的概率暴露模型的德国高分辨率室内氡气地图

    A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])

    [http://arxiv.org/abs/2310.11143](http://arxiv.org/abs/2310.11143)

    本研究提出了一种基于机器学习的概率暴露模型，可以更准确地估计德国室内氡气分布，并具有更高的空间分辨率。

    

    室内氡气是一种致癌的放射性气体，可以在室内积累。通常情况下，全国范围内的室内氡暴露是基于广泛的测量活动估计得来的。然而，样本的特征往往与人口特征不同，这是由于许多相关因素，如地质源氡气的可用性或楼层水平。此外，样本大小通常不允许以高空间分辨率进行暴露估计。我们提出了一种基于模型的方法，可以比纯数据方法更加现实地估计室内氡分布，并具有更高的空间分辨率。我们采用了两阶段建模方法：1）应用分位数回归森林，使用环境和建筑数据作为预测因子，估计了德国每个住宅楼的每个楼层的室内氡概率分布函数；2）使用概率蒙特卡罗抽样技术使它们组合和。

    Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
    
[^184]: Score dynamics: 使用条件扩散模型通过皮秒时间步提高分子动力学的规模化

    Score dynamics: scaling molecular dynamics with picosecond timesteps via conditional diffusion model. (arXiv:2310.01678v1 [physics.comp-ph])

    [http://arxiv.org/abs/2310.01678](http://arxiv.org/abs/2310.01678)

    该论文提出了Score dynamics (SD) 方法，通过条件扩散模型，可以使用1 ps的时间步长进行分子动力学模拟。基于图神经网络的Score dynamics模型展示了在丙氨酸二肽和短链烷烃案例中的效果。

    

    我们提出了一种称为Score dynamics (SD) 的通用框架，用于从分子动力学模拟中学习有效的演化算子，用于原子级和粗粒化动力学。SD以分数为中心，即与动态自由度的转换对数概率导数相关的量。后者在分数时间步中起到与MD中力场相同的作用，但在去噪扩散概率模型中用于生成动态变量的离散转变。这种时间步长可以比典型的MD时间步长大几个数量级。在这项工作中，我们构建了基于图神经网络的Score dynamics模型，用于演化以1~ps时间步长的现实分子体系。我们通过丙氨酸二肽和水溶液中的短链烷烃的案例研究证明了Score dynamics的效能。通过从条件概率的平稳分布中推导出的平衡预测和对转换速率和转换的动力学预测进行演示。

    We propose score dynamics (SD), a general framework for learning effective evolution operators for atomistic as well as coarse-grained dynamics from molecular-dynamics (MD) simulations. SD is centered around scores, or derivatives of the transition log-probability with respect to the dynamical degrees of freedom. The latter play the same role as force fields in MD but are used in denoising diffusion probability models to generate discrete transitions of the dynamical variables in an SD timestep, which can be orders of magnitude larger than a typical MD timestep. In this work, we construct graph neural network based score dynamics models of realistic molecular systems that are evolved with 1~ps timesteps. We demonstrate the efficacy of score dynamics with case studies of alanine dipeptide and short alkanes in aqueous solution. Both equilibrium predictions derived from the stationary distributions of the conditional probability and kinetic predictions for the transition rates and transit
    
[^185]: 受限制和带水印生成的镜像扩散模型

    Mirror Diffusion Models for Constrained and Watermarked Generation. (arXiv:2310.01236v1 [stat.ML])

    [http://arxiv.org/abs/2310.01236](http://arxiv.org/abs/2310.01236)

    提出了一种新的镜像扩散模型（MDM），可以在受限制集合上生成数据而不丧失可追溯性。这通过在一个标准的欧几里得空间中学习扩散过程，并利用镜像映射来实现。

    

    现代扩散模型在学习复杂的高维数据分布方面取得了成功，这部分归功于其能够构建具有解析转移核函数和评分函数的扩散过程。这种可追溯性结果在不需要模拟的框架中具有稳定的回归损失，从而可以学习到可以扩展的逆向生成过程。然而，当数据被限制在受限制集合而不是标准的欧几里得空间中时，根据之前的尝试，这些理想的特性似乎丧失了。在这项工作中，我们提出了镜像扩散模型（MDM），一种新的扩散模型类，可以在凸约束集合上生成数据而不丧失任何可追溯性。这是通过在从镜像映射构建的对偶空间中学习扩散过程来实现的，关键的是，这是一个标准的欧几里得空间。我们推导了流行的约束集合（如单纯形和$\ell_2$-球）的镜像映射的有效计算，显示明显的提升。

    Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\ell_2$-balls, showing significantly im
    
[^186]: PlaceNav: 通过地点识别进行拓扑导航

    PlaceNav: Topological Navigation through Place Recognition. (arXiv:2309.17260v1 [cs.RO])

    [http://arxiv.org/abs/2309.17260](http://arxiv.org/abs/2309.17260)

    PlaceNav是一种通过地点识别进行拓扑导航的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件，通过使用非机器人来源的大规模数据集增加训练数据的可用性，同时通过地点识别来提高导航性能。新模型的性能提高了76%。

    

    最近的研究结果表明，将拓扑导航分为机器人无关和机器人特定的组件可以提高导航性能，通过使用不同类型机器人收集的数据来训练机器人无关部分。然而，导航方法仍受到适合训练数据的稀缺性和计算缩放性差的限制。在本文中，我们提出了一个名为PlaceNav的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件。我们利用视觉地点识别来选择拓扑导航流程中的子目标。这使得子目标选择更高效，并能够利用非机器人来源的大规模数据集增加训练数据的可用性。地点识别使得贝叶斯滤波成为可能，进一步通过增加子目标的时间一致性来提高导航性能。我们的实验结果验证了这一设计，并且新模型的性能提高了76%。

    Recent results suggest that splitting topological navigation into robot-independent and robot-specific components improves navigation performance by enabling the robot-independent part to be trained with data collected by different robot types. However, the navigation methods are still limited by the scarcity of suitable training data and suffer from poor computational scaling. In this work, we present~\methodname, subdividing the robot-independent part into navigation-specific and generic computer vision components. We utilize visual place recognition for the subgoal selection of the topological navigation pipeline. This makes subgoal selection more efficient and enables leveraging large-scale datasets from non-robotics sources, increasing training data availability. Bayes filtering, enabled by place recognition, further improves navigation performance by increasing the temporal consistency of subgoals. Our experimental results verify the design and the new model obtains a 76% higher 
    
[^187]: 基于交叉预测的推理

    Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])

    [http://arxiv.org/abs/2309.16598](http://arxiv.org/abs/2309.16598)

    本文介绍了一种基于机器学习的交叉预测方法，可以有效地进行推理。该方法通过使用一个小型标记数据集和一个大型未标记数据集，通过机器学习填补缺失的标签，并采用去偏差方法纠正预测的不准确性。

    

    可靠的数据驱动决策依赖于高质量的标注数据，然而获取高质量的标注数据经常需要繁琐的人工标注或者缓慢昂贵的科学测量。机器学习作为一种替代方案正变得越来越有吸引力，因为精密的预测技术可以快速、廉价地产生大量预测标签；例如，预测的蛋白质结构被用来补充实验得到的结构，卫星图像预测的社会经济指标被用来补充准确的调查数据等。由于预测具有不完美和潜在偏差的特点，这种做法对下游推理的有效性产生了质疑。我们引入了基于机器学习的交叉预测方法，用于有效的推理。通过一个小的标记数据集和一个大的未标记数据集，交叉预测通过机器学习填补缺失的标签，并应用一种去偏差的方法来纠正预测不准确性。

    While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccurac
    
[^188]: 通过自适应反向传播实现大型语言模型的绿色AI细调

    Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation. (arXiv:2309.13192v1 [cs.LG])

    [http://arxiv.org/abs/2309.13192](http://arxiv.org/abs/2309.13192)

    本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。

    

    细调是将预训练的大型语言模型（LLMs）适应到下游应用中最有效的方法。随着LLM驱动的AI应用的快速增长以及开源LLM的民主化，非专业人员也可以进行细调，但是全球范围内对LLM的大规模细调可能导致能源消耗和碳足迹显著增加，从而对环境产生重大影响。实现绿色AI以减少细调的FLOPs直接相关，但是现有的高效LLM细调技术只能实现有限的FLOPs降低，因为它们忽视了细调中的反向传播成本。为了解决这个限制，本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，通过选择最有效的张量来最小化细调成本。

    Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most a
    
[^189]: 存在稀疏的随机网络：通过正则化增强通信效率的联合学习方法

    Sparser Random Networks Exist: Enforcing Communication-Efficient Federated Learning via Regularization. (arXiv:2309.10834v1 [cs.LG])

    [http://arxiv.org/abs/2309.10834](http://arxiv.org/abs/2309.10834)

    本论文提出了一种通过正则化方法增强通信效率的联合学习方法，该方法训练过参数化的随机网络，通过优化二进制掩码来减少通信开销，同时在本地目标中添加正则化项来促进稀疏网络的解决方案。实验证明，在通信和内存效率方面取得了显著的改进。

    

    本研究提出了一种新的方法，用于增强随机联合学习中的通信效率，该方法训练过参数化的随机网络。在这种设置下，优化的是二进制掩码，而不是固定的模型权重。该掩码表征了一个能够和较小的目标网络一样好地泛化的稀疏子网络。重要的是，在传统联合学习中，交换的是稀疏的二进制掩码，而不是浮点权重，这样可以将通信成本降低到每个参数最多1个比特。我们发现，之前的最先进的随机方法无法找到能够通过一致的损失目标减少通信和存储开销的稀疏网络。为了解决这个问题，我们建议在本地目标中添加正则化项，通过消除子网络之间的冗余特征来促进更稀疏的解决方案。大量实验表明，在通信和内存效率方面取得了显著的改进，高达五个数量级。

    This work presents a new method for enhancing communication efficiency in stochastic Federated Learning that trains over-parameterized random networks. In this setting, a binary mask is optimized instead of the model weights, which are kept fixed. The mask characterizes a sparse sub-network that is able to generalize as good as a smaller target network. Importantly, sparse binary masks are exchanged rather than the floating point weights in traditional federated learning, reducing communication cost to at most 1 bit per parameter. We show that previous state of the art stochastic methods fail to find the sparse networks that can reduce the communication and storage overhead using consistent loss objectives. To address this, we propose adding a regularization term to local objectives that encourages sparser solutions by eliminating redundant features across sub-networks. Extensive experiments demonstrate significant improvements in communication and memory efficiency of up to five magni
    
[^190]: 内存注入：在Transformer-Based语言模型中纠正多跳推理错误

    Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models. (arXiv:2309.05605v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05605](http://arxiv.org/abs/2309.05605)

    本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。

    

    回答多跳推理问题需要从多个信息源中检索和综合信息。大语言模型(LLMs)往往难以保持一致的推理能力。本文提出了一种通过在LLM注意力头部进行定向内存注入来确定和纠正多跳推理错误的方法。首先，我们分析了GPT-2模型在单跳和多跳提示下各层的激活情况。然后，我们提出了一种机制，允许用户在推理过程中向关键LLM位置注入相关的提示特定信息，我们将其称为“记忆”。通过在推理过程中使LLM能够整合额外的相关信息，我们提高了多跳提示生成的质量。我们实证表明，将简单、高效且定向的记忆注入到关键注意力层中往往能够提高多跳任务中所需下一个标记的概率，提高了达到424%。

    Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as "memories," at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.
    
[^191]: 基于区域方法的机器学习和物理约束神经网络在加热炉中的应用

    Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces. (arXiv:2308.16089v1 [cs.LG])

    [http://arxiv.org/abs/2308.16089](http://arxiv.org/abs/2308.16089)

    本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。

    

    尽管基础产业的经济重要性很高，但其生产链中的一些组件，如加热炉，能耗较高。通过减少加热炉中的整体加热时间，可以显著降低能耗。在基础产业可持续制造中，计算机集成的机器学习（ML）和人工智能（AI）控制系统可能是实现“零净排放”目标的关键。本文中，由于在加热炉等场景中无法获得高质量的数据的可行性，采用经典的Hottel区域方法基于计算模型生成数据，用于ML和深度学习（DL）模型的回归训练。值得注意的是，区域方法提供了一种优雅的方式来建模辐射传热（RHT）的物理现象，这是加热炉内高温过程中占主导地位的传热机制。利用这些数据，进行了详细的实验研究。

    Despite the high economic relevance of Foundation Industries, certain components like Reheating furnaces within their manufacturing chain are energy-intensive. Notable energy consumption reduction could be obtained by reducing the overall heating time in furnaces. Computer-integrated Machine Learning (ML) and Artificial Intelligence (AI) powered control systems in furnaces could be enablers in achieving the Net-Zero goals in Foundation Industries for sustainable manufacturing.  In this work, due to the infeasibility of achieving good quality data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for ML and Deep Learning (DL) based model training via regression. It should be noted that the zone method provides an elegant way to model the physical phenomenon of Radiative Heat Transfer (RHT), the dominating heat transfer mechanism in high-temperature processes inside heating furnaces. Using this data, an extensive
    
[^192]: 改进社交机器人导航的强化学习训练方法

    Improving Reinforcement Learning Training Regimes for Social Robot Navigation. (arXiv:2308.14947v1 [cs.RO])

    [http://arxiv.org/abs/2308.14947](http://arxiv.org/abs/2308.14947)

    本研究提出了一种改进社交机器人导航的强化学习训练方法，通过使用课程学习，多样化环境和建模行人等技术，实现了更好的泛化性能。

    

    为了让自主移动机器人在人类空间中导航，它们必须遵守我们的社交规范。强化学习（RL）已经成为一种有效的训练机器人导航策略的方法，以便使其能够遵守这些规范。然而，该领域中现有工作的很大一部分在简化环境中进行RL训练和测试。这限制了这些模型在未知环境中的泛化能力和其结果的实质性。我们提出了一种使用课程学习方法来提高RL社交导航方法泛化性能的方法。通过使用多种环境类型和多个动力学模型来建模行人，我们能够逐步增加训练的多样性和难度。我们的结果表明，在训练过程中使用课程学习可以实现比以前的训练方法更好的泛化性能。我们还展示了许多现有统计结果的结果之一，并对模型进行了详细分析。

    In order for autonomous mobile robots to navigate in human spaces, they must abide by our social norms. Reinforcement learning (RL) has emerged as an effective method to train robot navigation policies that are able to respect these norms. However, a large portion of existing work in the field conducts both RL training and testing in simplistic environments. This limits the generalization potential of these models to unseen environments, and the meaningfulness of their reported results. We propose a method to improve the generalization performance of RL social navigation methods using curriculum learning. By employing multiple environment types and by modeling pedestrians using multiple dynamics models, we are able to progressively diversify and escalate difficulty in training. Our results show that the use of curriculum learning in training can be used to achieve better generalization performance than previous training methods. We also show that results presented in many existing stat
    
[^193]: 部分可观测的多Agent强化学习与（准）效率：信息共享的好处。

    Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing. (arXiv:2308.08705v1 [cs.LG])

    [http://arxiv.org/abs/2308.08705](http://arxiv.org/abs/2308.08705)

    本文研究了部分可观测随机博弈的可证明多Agent强化学习。通过信息共享和观测可能性假设，提出了构建近似模型以实现准效率的方法。

    

    本文研究了部分可观测随机博弈（POSGs）的可证明多Agent强化学习（MARL）。为了规避已知的难度问题和使用计算不可行的预言机，我们倡导利用Agent之间的潜在“信息共享”，这是实证MARL中的常见做法，也是具备通信功能的多Agent控制系统的标准模型。我们首先建立了若干计算复杂性结果，来证明信息共享的必要性，以及观测可能性假设为了求解POSGs中的计算效率已经使得部分可观测的单Agent强化学习具有准效率。然后我们提出进一步“近似”共享的公共信息构建POSG的“近似模型”，在该模型中计划一个近似均衡（从解决原始POSG的角度）可以实现准效率，即准多项式时间，前提是上述假设满足。

    We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermo
    
[^194]: CMISR：循环医学图像超分辨率

    CMISR: Circular Medical Image Super-Resolution. (arXiv:2308.08567v1 [eess.IV])

    [http://arxiv.org/abs/2308.08567](http://arxiv.org/abs/2308.08567)

    这里是中文总结出的一句话要点：本文提出了一种循环医学图像超分辨率方法（CMISR），采用全局反馈的闭环框架，具有明确的欠分辨率和超分辨率元素。CMISR在稳态下具有零恢复误差，且可以应用于现有的MISR算法。

    

    传统的医学图像超分辨率（MISR）方法采用隐式的欠分辨率（UR）单元和明确的超分辨率（SR）单元的开环架构。UR单元可以始终给出、假设或估计，而SR单元根据各种SR算法进行精心设计。闭环反馈机制广泛应用于当前的MISR方法，并能有效提高其性能。反馈机制可以分为两类：局部反馈和全局反馈。因此，本文提出了一种基于全局反馈的闭环框架，即循环MISR（CMISR），具有明确的UR和SR元素。建立CMISR的数学模型和闭环方程。通过泰勒级数逼近的数学证明表明，CMISR在稳态下具有零恢复误差。此外，CMISR具有即插即用的特性，可以建立在任何现有的MISR算法上。分别提出了五种CMISR算法。

    Classical methods of medical image super-resolution (MISR) utilize open-loop architecture with implicit under-resolution (UR) unit and explicit super-resolution (SR) unit. The UR unit can always be given, assumed, or estimated, while the SR unit is elaborately designed according to various SR algorithms. The closed-loop feedback mechanism is widely employed in current MISR approaches and can efficiently improve their performance. The feedback mechanism may be divided into two categories: local and global feedback. Therefore, this paper proposes a global feedback-based closed-cycle framework, circular MISR (CMISR), with unambiguous UR and SR elements. Mathematical model and closed-loop equation of CMISR are built. Mathematical proof with Taylor-series approximation indicates that CMISR has zero recovery error in steady-state. In addition, CMISR holds plug-and-play characteristic which can be established on any existing MISR algorithms. Five CMISR algorithms are respectively proposed bas
    
[^195]: Symphony: 使用集中式协调来优化模型服务

    Symphony: Optimized Model Serving using Centralized Orchestration. (arXiv:2308.07470v1 [cs.DC])

    [http://arxiv.org/abs/2308.07470](http://arxiv.org/abs/2308.07470)

    Symphony是一个集中式调度系统，可以优化深度神经网络模型服务，在满足高加速器效率和延迟SLO的同时适应工作负载变化。通过非工作保持调度算法和模型分配算法，Symphony能够实现高批处理效率和强大的自动缩放功能，比之前的系统提供高达4.7倍的吞吐量。

    

    在GPU集群上进行深度神经网络(DNN)模型推理的协调存在两个重要挑战：在满足批处理属性的模型推理同时实现高加速器效率，并满足延迟服务级别目标(SLO)，以及适应工作负载的变化，无论是短期波动还是长期资源分配。为了解决这些挑战，我们提出了Symphony，这是一个可以扩展到每秒数百万个请求并协调数万个GPU的集中式调度系统。我们的系统使用非工作保持调度算法，能够实现高批处理效率，同时也能实现强大的自动缩放。此外，我们还开发了一个基于模型的计算和内存需求分配子集群的算法。通过广泛的实验，我们证明Symphony的性能优于之前的系统，最多可以提高4.7倍的吞吐量。

    The orchestration of deep neural network (DNN) model inference on GPU clusters presents two significant challenges: achieving high accelerator efficiency given the batching properties of model inference while meeting latency service level objectives (SLOs), and adapting to workload changes both in terms of short-term fluctuations and long-term resource allocation. To address these challenges, we propose Symphony, a centralized scheduling system that can scale to millions of requests per second and coordinate tens of thousands of GPUs. Our system utilizes a non-work-conserving scheduling algorithm capable of achieving high batch efficiency while also enabling robust autoscaling. Additionally, we developed an epoch-scale algorithm that allocates models to sub-clusters based on the compute and memory needs of the models. Through extensive experiments, we demonstrate that Symphony outperforms prior systems by up to 4.7x higher goodput.
    
[^196]: 学习采样任务用于元学习

    Learning to Sample Tasks for Meta Learning. (arXiv:2307.08924v1 [cs.LG])

    [http://arxiv.org/abs/2307.08924](http://arxiv.org/abs/2307.08924)

    通过实验得出了三个结论：没有通用的任务采样策略能保证元学习模型的性能；任务的多样性会导致模型在训练过程中出现欠拟合或过拟合的问题；模型的泛化性能受到任务的差异、任务熵和任务难度的影响。针对这些发现，提出了一种新颖的任务采样器ASr，它利用任务的差异、任务熵和任务难度来采样任务，并通过重新思考和提出一个简单而通用的元学习算法来优化ASr。大量实证实验表明了ASr的有效性。

    

    通过对各种元学习方法、任务采样器和少样本学习任务的实验，本文得出了三个结论。首先，没有通用的任务采样策略能保证元学习模型的性能。其次，任务的多样性会导致模型在训练过程中出现欠拟合或过拟合的问题。最后，模型的泛化性能受到任务的差异、任务熵和任务难度的影响。针对这些发现，我们提出了一种新颖的任务采样器，称为自适应采样器（ASr）。ASr是一个即插即用的任务采样器，它利用任务的差异、任务熵和任务难度来采样任务。为了优化ASr，我们重新思考并提出了一个简单而通用的元学习算法。最后，大量的实证实验证明了所提出的ASr的有效性。

    Through experiments on various meta-learning methods, task samplers, and few-shot learning tasks, this paper arrives at three conclusions. Firstly, there are no universal task sampling strategies to guarantee the performance of meta-learning models. Secondly, task diversity can cause the models to either underfit or overfit during training. Lastly, the generalization performance of the models are influenced by task divergence, task entropy, and task difficulty. In response to these findings, we propose a novel task sampler called Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes task divergence, task entropy, and task difficulty to sample tasks. To optimize ASr, we rethink and propose a simple and general meta-learning algorithm. Finally, a large number of empirical experiments demonstrate the effectiveness of the proposed ASr.
    
[^197]: 反向最优化用于路由问题

    Inverse Optimization for Routing Problems. (arXiv:2307.07357v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2307.07357](http://arxiv.org/abs/2307.07357)

    本研究提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法，并在亚马逊末端路由研究挑战中测试了该方法，在复制人类驾驶员的路由偏好方面取得了第2名的成绩。

    

    我们提出了一种使用反向最优化（IO）学习路由问题决策者行为的方法。IO框架属于监督学习类别，并建立在目标行为是未知成本函数的优化器的前提下。这个成本函数通过历史数据进行学习，在路由问题的背景下，可以理解为决策者的路由偏好。在这个视角下，本研究的主要贡献是提出了一种适用于路由问题的IO方法，包括假设函数、损失函数和基于随机一阶算法。我们进一步在亚马逊末端路由研究挑战中测试了我们的IO方法，该挑战的目标是使用成千上万个真实世界的路由案例学习模型以复制人类驾驶员的路由偏好。我们最终学习到的IO路由模型在48个晋级到决赛的模型中排名第2。

    We propose a method for learning decision-makers' behavior in routing problems using Inverse Optimization (IO). The IO framework falls into the supervised learning category and builds on the premise that the target behavior is an optimizer of an unknown cost function. This cost function is to be learned through historical data, and in the context of routing problems, can be interpreted as the routing preferences of the decision-makers. In this view, the main contributions of this study are to propose an IO methodology with a hypothesis function, loss function, and stochastic first-order algorithm tailored to routing problems. We further test our IO approach in the Amazon Last Mile Routing Research Challenge, where the goal is to learn models that replicate the routing preferences of human drivers, using thousands of real-world routing examples. Our final IO-learned routing model achieves a score that ranks 2nd compared with the 48 models that qualified for the final round of the challe
    
[^198]: 低秩MDP中高效的无模型探索

    Efficient Model-Free Exploration in Low-Rank MDPs. (arXiv:2307.03997v1 [cs.LG])

    [http://arxiv.org/abs/2307.03997](http://arxiv.org/abs/2307.03997)

    提出了第一个计算高效、无模型的低秩MDPs探索算法，允许通用函数逼近，不需要额外的结构假设。

    

    强化学习中一个主要的挑战是在需要泛化和函数逼近的高维领域中开发出实用、样本高效的探索算法。低秩马尔可夫决策过程（MDPs）——其中转移概率可以基于未知特征嵌入进行低秩分解——为带有函数逼近的强化学习提供了简单而富有表现力的框架，但现有算法要么计算复杂度很高，要么依赖于限制性的统计假设，如潜变量结构、对模型为基础的函数逼近的访问性或可达性。在这项工作中，我们提出了第一个经过验证的低秩MDPs探索的样本高效算法，该算法既计算高效又无模型，允许进行通用的函数逼近，并且不需要额外的结构假设。我们的算法VoX使用了一个广义优化设计的特征嵌入概念作为探索的效能。

    A major challenge in reinforcement learning is to develop practical, sample-efficient algorithms for exploration in high-dimensional domains where generalization and function approximation is required. Low-Rank Markov Decision Processes -- where transition probabilities admit a low-rank factorization based on an unknown feature embedding -- offer a simple, yet expressive framework for RL with function approximation, but existing algorithms are either (1) computationally intractable, or (2) reliant upon restrictive statistical assumptions such as latent variable structure, access to model-based function approximation, or reachability. In this work, we propose the first provably sample-efficient algorithm for exploration in Low-Rank MDPs that is both computationally efficient and model-free, allowing for general function approximation and requiring no additional structural assumptions. Our algorithm, VoX, uses the notion of a generalized optimal design for the feature embedding as an eff
    
[^199]: 开放联邦学习平台：技术和法律观察的综述和愿景

    Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives. (arXiv:2307.02140v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.02140](http://arxiv.org/abs/2307.02140)

    本文探讨了开放联邦学习平台的技术和法律观察，提出了基于查询和基于合同的两种适用于开放联邦学习的合作框架，并对构建开放的FL平台的可行性进行了全面评估。

    

    传统的联邦学习（FL）遵循服务器主导的合作模式，限制了FL的应用场景，并降低了数据持有者参与的热情。为了充分释放FL的潜力，我们主张重新思考当前FL框架的设计，并将其扩展为更通用的概念：开放联邦学习平台。我们提出了两个相互合作的FL框架：基于查询的FL和基于合同的FL。在这个综述中，我们从技术和法律的角度对构建开放的FL平台的可行性进行了全面的评估。我们首先回顾了FL的定义，并总结了其固有的局限性，包括服务器-客户端耦合、模型可重用性低和非公开性。在基于查询的FL平台中，这是一个由社区赋能的开放模型共享和重用平台，我们探讨了一系列有价值的主题，包括全球最新可用模型和模型的查询、服务质量保证和奖励机制。

    Traditional Federated Learning (FL) follows a server-domincated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate. To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms. We propose two reciprocal cooperation frameworks for FL to achieve this: query-based FL and contract-based FL. In this survey, we conduct a comprehensive review of the feasibility of constructing an open FL platform from both technical and legal perspectives. We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public. In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-d
    
[^200]: 用于噪声混合物中目标信号恢复的统计分量分离

    Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v1 [stat.ML])

    [http://arxiv.org/abs/2306.15012](http://arxiv.org/abs/2306.15012)

    本论文提出了一种用于从噪声混合物中恢复目标信号的统计分量分离方法，并且在图像降噪任务中展示了其优于标准降噪方法的表现。

    

    当只对给定信号的特定属性感兴趣时，从一个加性混合物中分离信号可能是一个不必要地困难的问题。在本工作中，我们解决了更简单的“统计分量分离”问题，该问题专注于从噪声混合物中恢复目标信号的预定义统计描述量。假设可以获得噪声过程的样本，我们研究了一种方法，该方法旨在使受噪声样本污染的解决方案候选的统计特性与观测的混合物的统计特性匹配。首先，我们使用具有解析可追踪计算的简单示例分析了该方法的行为。然后，我们将其应用于图像降噪环境中，使用了1）基于小波的描述符，2）针对天体物理和ImageNet数据的ConvNet-based描述符。在第一种情况下，我们展示了我们的方法在大多数情况下比标准降噪方法更好地恢复了目标数据的描述符。此外，尽管不是为此目的构建的，它也表现出对目标信号描述符恢复的潜力。

    Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler "statistical component separation" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it pe
    
[^201]: 基于 Foundation Model APIs 的差分隐私合成数据：图片

    Differentially Private Synthetic Data via Foundation Model APIs 1: Images. (arXiv:2305.15560v1 [cs.CV])

    [http://arxiv.org/abs/2305.15560](http://arxiv.org/abs/2305.15560)

    该论文提出了基于API的方法生成密切类似于原始私有数据的差分隐私（DP）合成数据，可以更轻松地部署。使用Private Evolution（PE）框架生成DP合成图像，结合了差分隐私、进化算法和元学习的技术，可以在保护隐私的同时生成既为DP又与原始图像外观相似的合成图像，并在流行的图像数据集上表现优异。

    

    在当前数据驱动的世界中，生成密切类似于原始私有数据的差分隐私（DP）合成数据是一种可扩展的方法，可减轻隐私问题。与当前为此任务训练定制模型的做法相反，我们旨在通过API生成DP合成数据（DPSDA），其中我们将基础模型视为黑盒并只利用其推理API。这些基于API的、无需训练的方法更容易部署，如最近 API 应用程序的激增所证明的那样。这些方法还可以利用可通过其推理API访问其权重未发布的大型基础模型的能力。但是，由于模型访问更加严格，还需保护API提供商的隐私，这将带来更大的挑战。在本文中，我们提出了一个称为 Private Evolution（PE）的新框架，以解决这个问题，并展示了其在使用基础模型API生成DP合成图像方面的初始实现。PE结合了差分隐私、进化算法和元学习的技术，有效地生成既为DP又与原始图像外观相似的合成图像。我们还在流行的图像数据集如CIFAR-10上评估了我们的框架，并显示我们的方法在效用和隐私方面优于现有的DP图像生成方法。

    Generating differentially private (DP) synthetic data that closely resembles the original private data without leaking sensitive user information is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are accessible via their inference APIs while the model weights are unreleased. However, this comes with greater challenges due to strictly more restrictive model access and the additional need to protect privacy from the API provider.  In this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its ini
    
[^202]: 非合作博弈中的人类选择预测：基于模拟的离线策略评估

    Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation. (arXiv:2305.10361v1 [cs.LG])

    [http://arxiv.org/abs/2305.10361](http://arxiv.org/abs/2305.10361)

    本文研究了语言游戏中的离线策略评估，并提出了一种结合真实和模拟数据的新方法。

    

    说服游戏在经济和人工智能研究中具有重要意义并具有重要的实际应用。本文探讨了在基于语言的说服游戏中离线策略评估（OPE）的挑战性问题，提出了一种结合真实和模拟人类 - 机器人交互数据的新方法，并给出了一种深度学习训练算法，该算法有效地整合了真实交互和模拟数据。

    Persuasion games have been fundamental in economics and AI research, and have significant practical applications. Recent works in this area have started to incorporate natural language, moving beyond the traditional stylized message setting. However, previous research has focused on on-policy prediction, where the train and test data have the same distribution, which is not representative of real-life scenarios. In this paper, we tackle the challenging problem of off-policy evaluation (OPE) in language-based persuasion games. To address the inherent difficulty of human data collection in this setup, we propose a novel approach which combines real and simulated human-bot interaction data. Our simulated data is created by an exogenous model assuming decision makers (DMs) start with a mixture of random and decision-theoretic based behaviors and improve over time. We present a deep learning training algorithm that effectively integrates real interaction and simulated data, substantially im
    
[^203]: 基于图结构的多标签节点分类

    Multi-label Node Classification On Graph-Structured Data. (arXiv:2304.10398v1 [cs.LG])

    [http://arxiv.org/abs/2304.10398](http://arxiv.org/abs/2304.10398)

    该论文提出了一种新的图神经网络架构 MLGCN，用于处理多标签节点分类任务，并研究了多标签场景中同类偏好的语义。在各种基准测试中，MLGCN优于现有的最先进的多标签分类方法。

    

    图神经网络（GNN）在图中节点分类任务方面展示了最先进的改进。虽然这些进展在多类分类场景中得到了广泛的展示，但一个更普遍和现实的情况，在这种情况下，每个节点可能有多个标签，一直以来受到了很少关注。在进行关于多标签节点分类的重点研究的首要挑战是公开可用的多标签图数据集数量有限。因此，作为我们的第一个贡献，我们收集并发布了三个真实的生物数据集，并开发了一个多标签图生成器，以生成具有可调属性的数据集。虽然高标签相似性（高同类偏好）通常被归因于GNN的成功，但我们认为多标签场景并不遵循目前为多类场景定义的同类偏好和异类偏好的常规语义。作为我们的第二个贡献，我们除了为多标签场景定义同类偏好外，还开发了一种新颖的GNN体系结构，即MLGCN（多标签图卷积网络），来处理多标签节点分类任务。我们的实验表明，在各种基准测试中，MLGCN优于现有的最先进的多标签分类方法。

    Graph Neural Networks (GNNs) have shown state-of-the-art improvements in node classification tasks on graphs. While these improvements have been largely demonstrated in a multi-class classification scenario, a more general and realistic scenario in which each node could have multiple labels has so far received little attention. The first challenge in conducting focused studies on multi-label node classification is the limited number of publicly available multi-label graph datasets. Therefore, as our first contribution, we collect and release three real-world biological datasets and develop a multi-label graph generator to generate datasets with tunable properties. While high label similarity (high homophily) is usually attributed to the success of GNNs, we argue that a multi-label scenario does not follow the usual semantics of homophily and heterophily so far defined for a multi-class scenario. As our second contribution, besides defining homophily for the multi-label scenario, we dev
    
[^204]: 用人工神经网络预测国内生产总值：长期记忆有多大的作用？

    GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])

    [http://arxiv.org/abs/2304.05805](http://arxiv.org/abs/2304.05805)

    通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。

    

    在本研究中，我们将不同的统计模型应用于美国经济季度国内生产总值（GDP）增长预测。使用每月的FRED-MD数据库，我们比较了动态因子模型（DFM）和四个人工神经网络（ANNs）的预测表现：多层感知机（MLP）、一维卷积神经网络（1D CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。实证分析呈现了两个不同评估周期的结果。第一个周期（2010年第1季度至2019年第4季度）具有平衡的经济增长，而第二个周期（2010年第1季度至2022年第3季度）还包括COVID-19衰退期间的时间。根据我们的结果，更长的输入序列在平衡经济增长期间能够实现更准确的预测。然而，在一个相对较低的阈值值（约六个季度或十八个月）以后，这种效应会消失。在经济动荡期（如COVID-19衰退期间），长期记忆的效果会变得较为明显。

    In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
    
[^205]: 可达集的凸包的精确刻画

    Exact Characterization of the Convex Hulls of Reachable Sets. (arXiv:2303.17674v1 [math.OC])

    [http://arxiv.org/abs/2303.17674](http://arxiv.org/abs/2303.17674)

    本文精确地刻画了具有有界扰动的非线性系统的可达集的凸包为一阶常微分方程的解的凸包，提出了一种低成本、高精度的估计算法，可用于过逼近可达集。

    

    本文研究了具有有界扰动的非线性系统的可达集的凸包。可达集在控制中起着至关重要的作用，但计算起来仍然非常具有挑战性，现有的过逼近工具往往过于保守或计算代价高昂。本文精确地刻画了可达集的凸包，将其表示成一阶常微分方程的解的凸包，这个有限维的刻画开启了一种紧密的估计算法，可用于过逼近可达集，且成本比现有方法更低、更精准。本文还提出了神经反馈环分析和鲁棒模型预测控制的应用。

    We study the convex hulls of reachable sets of nonlinear systems with bounded disturbances. Reachable sets play a critical role in control, but remain notoriously challenging to compute, and existing over-approximation tools tend to be conservative or computationally expensive. In this work, we exactly characterize the convex hulls of reachable sets as the convex hulls of solutions of an ordinary differential equation from all possible initial values of the disturbances. This finite-dimensional characterization unlocks a tight estimation algorithm to over-approximate reachable sets that is significantly faster and more accurate than existing methods. We present applications to neural feedback loop analysis and robust model predictive control.
    
[^206]: 通过内容感知的风格不变模型学习对未知领域进行泛化：用于胸部X射线疾病检测的翻译摘要

    Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays. (arXiv:2302.13991v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.13991](http://arxiv.org/abs/2302.13991)

    通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。

    

    在基于深度学习的医学图像分析中，由于源领域不匹配而导致性能降低一直是一个长期存在的挑战，特别是在胸部X射线（CXR）领域。为了解决这种领域转移问题，已经提出了一些方法（如对抗训练，多领域混合），用于提取领域不变的高级特征。然而，这些方法并没有明确规范提取的领域不变特征的内容和风格特征。最近的研究表明，CNN模型对风格（例如，无信息的纹理）有很强的偏好，而不是对内容（例如，形状）的偏好，这与人类视觉系统形成鲜明对比。放射科医师倾向于从CXR图像中学习视觉线索，并因此在多个领域中表现良好。因此，在从CXR图像进行病理诊断的医学成像中，模型应该提取既是风格不变又是内容偏好的领域不变特征。受此启发，我们在实验中使用了新颖的风格随机化模块（SRMs）。

    Performance degradation due to source domain mismatch is a longstanding challenge in deep learning-based medical image analysis, particularly for chest X-rays (CXRs). Several methods (e.g., adversarial training, multi-domain mixups) have been proposed to extract domain-invariant high-level features to address this domain shift. However, these methods do not explicitly regularize the content and style characteristics of the extracted domain-invariant features. Recent studies have demonstrated that CNN models exhibit a strong bias toward styles (e.g., uninformative textures) rather than content (e.g., shape), in stark contrast to the human-vision system. Radiologists tend to learn visual cues from CXRs and thus perform well across multiple domains. Therefore, in medical imaging for pathology diagnosis from CXR images, models should extract domain-invariant features that are style-invariant and content-biased. Motivated by this, we employ the novel style randomization modules (SRMs) at bo
    
[^207]: 通过演示来理解专业技能：离线逆向强化学习的最大似然框架

    Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning. (arXiv:2302.07457v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07457](http://arxiv.org/abs/2302.07457)

    通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。

    

    离线逆向强化学习（Offline IRL）旨在从专家代理的固定有限演示中恢复支撑观察到的操作的奖励和环境动态的结构。准确的专业执行任务的模型在安全敏感的应用中具有重要应用，例如临床决策和自动驾驶。然而，专家喜好隐含在观察到的操作中的结构与专家对环境动态的模型（即“世界”）密切相关。因此，从具有有限覆盖范围的有限数据中获得的不准确世界模型可能会导致估计的奖励的不准确性变得更加严重。为了解决这个问题，我们提出了一个双层优化公式的估计任务，其中上层是基于专家策略的保守模型的最大似然估计（下层）。策略模型是保守的，因为它在惩罚（惩罚会随着专家对世界模型的不确定性而增加）下最大化奖励。我们的实验表明，我们的方法在各种基准测试任务中提高了离线IRL方法的准确性。

    Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncerta
    
[^208]: 面向前列腺癌诊断和格里森分级的联邦对比学习模型

    Federated contrastive learning models for prostate cancer diagnosis and Gleason grading. (arXiv:2302.06089v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.06089](http://arxiv.org/abs/2302.06089)

    该研究提出了一个面向大规模病理图像和异质性挑战的联邦对比学习模型（FCL），通过最大化本地客户端和服务器模型间的注意力一致性来增强模型的泛化能力。 在前列腺癌诊断和格里森分级任务中，FCL表现出优异的性能。

    

    人工智能在医学影像领域的应用效果显著。然而，稳健的人工智能模型训练需要大规模的数据集，但数据收集面临沟通、伦理和隐私保护等限制。联邦学习可以通过协调多个客户端训练模型而不共享原始数据来解决上述问题。本研究设计了一个面向大规模病理图像和异质性挑战的联邦对比学习框架（FCL），通过最大化本地客户端和服务器模型间的注意力一致性来增强模型的泛化能力。为了缓解参数传输中的隐私泄露问题并验证FCL的稳健性，我们使用差分隐私通过添加噪音进一步保护模型。我们在19,635个来自多个客户端的前列腺癌WSI上评估了FCL在癌症诊断任务和格里森分级任务中的有效性。在诊断任务中，我们实现了区分癌性和非癌性WSI的0.99的曲线下面积（AUC）。在格里森分级任务中，我们的FCL模型实现了一个均方误差（MSE）为0.143，相比最先进的方法降低了21.7％。

    The application effect of artificial intelligence (AI) in the field of medical imaging is remarkable. Robust AI model training requires large datasets, but data collection faces communication, ethics, and privacy protection constraints. Fortunately, federated learning can solve the above problems by coordinating multiple clients to train the model without sharing the original data. In this study, we design a federated contrastive learning framework (FCL) for large-scale pathology images and the heterogeneity challenges. It enhances the model's generalization ability by maximizing the attention consistency between the local client and server models. To alleviate the privacy leakage problem when transferring parameters and verify the robustness of FCL, we use differential privacy to further protect the model by adding noise. We evaluate the effectiveness of FCL on the cancer diagnosis task and Gleason grading task on 19,635 prostate cancer WSIs from multiple clients. In the diagnosis tas
    
[^209]: 零样本协同合作学习框架的合作开放式学习

    Cooperative Open-ended Learning Framework for Zero-shot Coordination. (arXiv:2302.04831v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.04831](http://arxiv.org/abs/2302.04831)

    该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。

    

    协作人工智能中的零样本协调仍然是一个重大挑战，有效地协调一系列看不见的合作伙伴。先前的算法试图通过优化种群中的固定目标来改善策略或行为的多样性来解决这一挑战。然而，这些方法可能导致学习损失和与种群中某些策略无法合作，即合作不兼容性。为了解决这个问题，我们提出了合作开放式学习（COLE）框架，该框架从图论的角度构建了协作游戏的开放式目标，以评估和确定每个策略的协作能力。我们进一步明确了框架并提出了一种实用的算法，该算法利用了博弈论和图论的知识。此外，对算法的学习过程进行的分析显示，它可以有效地克服学习困难。

    Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overc
    
[^210]: 自适应联邦式最小最大优化及其较低复杂度

    Adaptive Federated Minimax Optimization with Lower complexities. (arXiv:2211.07303v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.07303](http://arxiv.org/abs/2211.07303)

    本文提出了一种自适应联邦式最小最大优化算法（AdaFGDA），用于解决分布式最小最大问题，在梯度和通信复杂性较低的情况下取得了良好的效果。

    

    联邦学习是一种流行的分布式和隐私保护的机器学习范例。同时，作为一种有效的层次优化方法，最小最大优化广泛应用于机器学习中。最近，已经提出了一些联邦式最小最大优化方法来解决分布式最小最大问题。然而，这些联邦式最小最大方法仍然受到梯度和通信复杂性高的问题的困扰。同时，很少有算法专注于使用自适应学习率来加速算法。为了填补这一空白，在本文中，我们研究了一类非凸最小最大优化问题，并提出了一种高效的自适应联邦式最小最大优化算法（即AdaFGDA）来解决这些分布式最小最大问题。具体而言，我们的AdaFGDA建立在基于动量的方差减少和局部SGD技术的基础上，通过使用统一的自适应矩阵可以灵活地结合各种自适应学习率。从理论上讲，我们提供了一个坚实的收敛性分析框架……

    Federated learning is a popular distributed and privacy-preserving machine learning paradigm. Meanwhile, minimax optimization, as an effective hierarchical optimization, is widely applied in machine learning. Recently, some federated optimization methods have been proposed to solve the distributed minimax problems. However, these federated minimax methods still suffer from high gradient and communication complexities. Meanwhile, few algorithm focuses on using adaptive learning rate to accelerate algorithms. To fill this gap, in the paper, we study a class of nonconvex minimax optimization, and propose an efficient adaptive federated minimax optimization algorithm (i.e., AdaFGDA) to solve these distributed minimax problems. Specifically, our AdaFGDA builds on the momentum-based variance reduced and local-SGD techniques, and it can flexibly incorporate various adaptive learning rates by using the unified adaptive matrix. Theoretically, we provide a solid convergence analysis framework fo
    
[^211]: 多视角数据中缺失值的插补问题解决方法

    Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.14484](http://arxiv.org/abs/2210.14484)

    本文提出了一种基于StaPLR算法的新的多视角数据插补算法，通过在降维空间中执行插补以解决计算挑战，并在模拟数据集中得到了竞争性结果。

    

    多视角数据是指由多个不同特征集描述的数据。在处理多视角数据时，若出现缺失值，则一个视角中的所有特征极有可能同时缺失，因而导致非常大量的缺失数据问题。本文提出了一种新的多视角学习算法中的插补方法，它基于堆叠惩罚逻辑回归(StaPLR)算法，在降维空间中执行插补，以解决固有的多视角计算挑战。实验结果表明，该方法在模拟数据集上具有竞争性结果，而且具有更低的计算成本，从而可以使用先进的插补算法，例如missForest。

    Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
    
[^212]: 防御联邦背后攻击的不变聚合器

    Invariant Aggregator for Defending against Federated Backdoor Attacks. (arXiv:2210.01834v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01834](http://arxiv.org/abs/2210.01834)

    该论文针对联邦学习中的背后攻击提出了一种不变聚合器，防御背后攻击并保持模型的整体效用。研究发现在扁平损失空间中，恶意客户端可以通过提供背后样本来误导联邦学习模型，而不需要与良性客户端有明显的差异。

    

    联邦学习因其能够在不直接共享私密数据的情况下训练高效模型而日益受到关注。然而，这种联邦设置使得模型在存在恶意客户端的情况下容易受到各种敌对攻击。尽管对于旨在降低模型效用的攻击的防御已经取得了理论和实证上的成功，但防御仅提高背后样本上模型准确性而不损害其他样本效用的背后攻击仍然具有挑战性。为此，我们首先分析了联邦学习在扁平损失空间上对背后攻击的脆弱性，这种扁平损失空间常见于设计良好的神经网络，如Resnet [He et al., 2015]，但往往被先前的工作所忽视。在扁平损失空间上，误导联邦学习模型以仅对恶意客户端的背后样本有利，并不需要恶意和良性客户端之间存在显著差异。

    Federated learning is gaining popularity as it enables training high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Despite the theoretical and empirical success in defending against attacks that aim to degrade models' utility, defense against backdoor attacks that increase model accuracy on backdoor samples exclusively without hurting the utility on other samples remains challenging. To this end, we first analyze the vulnerability of federated learning to backdoor attacks over a flat loss landscape which is common for well-designed neural networks such as Resnet [He et al., 2015] but is often overlooked by previous works. Over a flat loss landscape, misleading federated learning models to exclusively benefit malicious clients with backdoor samples do not require a significant difference between malicious and benign cli
    

