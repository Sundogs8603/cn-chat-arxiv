# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations.](http://arxiv.org/abs/2308.04431) | 引入额外数据集可能会通过引入虚假相关性来降低性能，即使添加的数据使训练分布更接近测试分布。这种现象是由于医院特定的图像伪像引起的。这一结果挑战了常见的认为更多数据能提高模型性能的观念。 |
| [^2] | [SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore.](http://arxiv.org/abs/2308.04430) | SILO是一种新的语言模型，通过在推理过程中对非参数化的数据存储进行查询，实现在面临法律风险和模型性能之间的权衡，并支持数据归属和数据生产者退出模型的功能。 |
| [^3] | [Meta-Learning Operators to Optimality from Multi-Task Non-IID Data.](http://arxiv.org/abs/2308.04428) | 本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。 |
| [^4] | [A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces.](http://arxiv.org/abs/2308.04426) | 本文介绍了一种使用自动编码器和生成对抗网络的深度学习方法，用于实时自动检测古代石碑表面的自然破坏和人为损坏。这种方法克服了现有方法的局限性，可以全面检测各种不可预测的异常情况。 |
| [^5] | [Stock Market Price Prediction: A Hybrid LSTM and Sequential Self-Attention based Approach.](http://arxiv.org/abs/2308.04419) | 本论文介绍了一种基于混合LSTM和顺序自注意力的方法，旨在预测股票未来价格，并通过实验证明了该方法的有效性。 |
| [^6] | [DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images.](http://arxiv.org/abs/2308.04417) | 本文提出了一种名为DiffCR的快速条件扩散框架，用于高性能的光学卫星图像云去除。它利用深度卷积网络和条件引导扩散来提供强大的颜色表征，确保合成输出与条件输入之间的外观信息具有紧密的相似性。 |
| [^7] | [Probabilistic Invariant Learning with Randomized Linear Classifiers.](http://arxiv.org/abs/2308.04412) | 本文介绍了一种使用随机线性分类器进行概率不变学习的方法，通过接受概率化的普遍逼近和不变性，设计了能同时具有表达能力和不变性的模型，并且使用更少的资源。通过实验证明了这种方法在分类任务中的有效性。 |
| [^8] | [XGBD: Explanation-Guided Graph Backdoor Detection.](http://arxiv.org/abs/2308.04406) | 本文提出了一种说明引导的图反向门探测方法，通过利用拓扑信息来增强反向门检测的有效性 |
| [^9] | [Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review.](http://arxiv.org/abs/2308.04404) | 联邦学习是一种新兴的机器学习模型，它可以在无线边缘网络中实现数据获取和计算的分离，对于未来的移动网络尤其是6G及以后具有重要作用。 |
| [^10] | [Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining.](http://arxiv.org/abs/2308.04396) | 本论文提出了一种定制的企业协作系统的事件抽象方法，通过比较实际用户活动和系统生成的低级别跟踪来训练模型，并将低级别跟踪转换为抽象的高级别日志，以支持社会流程挖掘。 |
| [^11] | [Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging.](http://arxiv.org/abs/2308.04395) | 本论文提出了一种基于数据增强的医学图像无监督领域适应方法，在大脑MRI分割任务中显示出高准确性、广泛适用性和对抗领域偏移的鲁棒性，超过现有技术的性能。 |
| [^12] | [Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making.](http://arxiv.org/abs/2308.04375) | 本研究利用因果解释方法帮助人类分析审查人工智能建议，减少对人工智能的过度依赖，提高了临床决策的质量和表现。 |
| [^13] | [Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning.](http://arxiv.org/abs/2308.04373) | Pelta是一种新颖的联邦学习机制，利用可信硬件的能力来保护模型免受恶意探测攻击。它遮蔽了反向传播的部分链规则，提供更高的安全性。 |
| [^14] | [SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling.](http://arxiv.org/abs/2308.04365) | SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。 |
| [^15] | [Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage.](http://arxiv.org/abs/2308.04341) | 本研究提出了两种新颖的方法来生成差分隐私追索权：差分隐私模型（DPM）和拉普拉斯追索权（LR）。在逻辑回归分类器和真实世界合成数据集的实验中发现，DPM和LR在减少攻击者可以推断的信息方面表现良好，特别是在低误报率下。当训练数据集足够大时，我们的新颖LR方法成功地防止了隐私泄漏。 |
| [^16] | [RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback.](http://arxiv.org/abs/2308.04332) | RLHF-Blender是一个可配置的、互动的界面，用于从多种人类反馈中学习，研究人员可以系统地探索不同类型的反馈以及人类因素对奖励学习的影响。 |
| [^17] | [Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs.](http://arxiv.org/abs/2308.04314) | 本文提出了一种新的合作赌博机算法，实现了最佳的个体遗憾和恒定的通信成本。 |
| [^18] | [The Model Inversion Eavesdropping Attack in Semantic Communication Systems.](http://arxiv.org/abs/2308.04304) | 本文介绍了在语义通信系统中的模型反演窃听攻击（MIEA），通过窃听和模型反演来重构原始消息，研究发现MIEA在不同信道条件下能够成功地重构出具有良好质量的原始消息。为了实现安全的语义通信，提出了一种基于随机置换和替换的防御方法。 |
| [^19] | [Comparative Analysis of the wav2vec 2.0 Feature Extractor.](http://arxiv.org/abs/2308.04286) | 本研究比较了wav2vec 2.0模型的特征提取器与传统特征提取方法在连接主义时间分类ASR模型上的表现，发现两者在LibriSpeech基准测试上具有竞争力。通过分析学习到的滤波器，发现ASR系统最重要的信息是通过一组带通滤波器获得的。 |
| [^20] | [In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning.](http://arxiv.org/abs/2308.04275) | 本文提出了一种在微调之前与纯净语言模型进行对话的方法，通过上下文学习实现了推理时的对齐。实验证明，这种方法将纯净语言模型的胜率提高了7倍，使其可以与通过对齐微调的强基准模型媲美。 |
| [^21] | [Teacher-Student Architecture for Knowledge Distillation: A Survey.](http://arxiv.org/abs/2308.04268) | 本文综述了知识蒸馏的师生架构，在多个蒸馏目标领域中取得了有效并广泛的应用，包括知识压缩、知识扩展、知识适应和知识增强，通过轻量化和通用化的学生网络实现多个蒸馏目标。 |
| [^22] | [BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning.](http://arxiv.org/abs/2308.04263) | BarlowRL通过将Barlow Twins和DER相结合，实现了数据效率强化学习，并在Atari 100k基准测试上优于其他算法。它通过信息扩散避免了维度折叠，使得RL算法能够利用均匀分布的状态表示，从而实现卓越的性能。 |
| [^23] | [SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction.](http://arxiv.org/abs/2308.04262) | 提出了一种窗口式的transformer网络，该网络通过整合扩张注意机制和卷积，用于加速MRI图像重建，并通过增强远处邻域像素关系和学习低级平移不变特征来提高重建质量。 |
| [^24] | [Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets.](http://arxiv.org/abs/2308.04258) | 本研究提出了一个基于预训练转换器的文本到音频检索系统，通过在共享空间中映射音频和文字描述来提高检索性能，其中自注意力的音频编码器和额外的人工生成和合成数据集是关键组件，取得了在DCASE挑战中的第一名，并在ClothoV2基准测试中超过当前最先进方法5.6个百分点。 |
| [^25] | [Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction.](http://arxiv.org/abs/2308.04237) | 本论文提出了一种基于联合符合预测的无线通道联合推理方法，通过设备到服务器的通信提高了服务器的推理决策的可靠性和准确性。 |
| [^26] | [OpinionConv: Conversational Product Search with Grounded Opinions.](http://arxiv.org/abs/2308.04226) | OpinionConv是第一个用于模拟销售对话的对话式AI，通过利用产品评论作为观点的丰富来源，实现了对话和决策中的真实性和信息基础。 |
| [^27] | [Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models.](http://arxiv.org/abs/2308.04220) | 本论文提出了一种方法来在GNN模型中增强可解释性，通过引入语义关注和建立特征重要性权重与模型准确性之间的相关性。这对于图深度学习任务具有重要意义。 |
| [^28] | [Iterative Sketching for Secure Coded Regression.](http://arxiv.org/abs/2308.04185) | 这篇论文提出了一种迭代草图方法，用于加速分布式线性回归计算并确保安全性。通过利用随机草图技术和改进异步系统中的块效应韧性，将信息保护与回归问题维度的减小相结合。特别是，通过应用随机正交矩阵和子采样"块"，实现了在每次迭代中考虑新草图的分布式迭代草图方法。同时，对子采样随机哈达玛变换进行了推广并修改以保证数据的安全性。 |
| [^29] | [Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: "Are we on the same page ?".](http://arxiv.org/abs/2308.04180) | 本研究通过不同的视角研究在线文本中的社交不可接受言论（SUD）分类和检测，并建立了一个新颖的语料库。通过分析不同背景下的SUD分类器的泛化能力以及注释模态对SUD学习的影响，我们提出了一些开放的挑战和研究方向，并提供了有助于领域专家在注释任务中的数据洞察。 |
| [^30] | [Dual input neural networks for positional sound source localization.](http://arxiv.org/abs/2308.04169) | 双输入神经网络（DI-NN）是一种简单有效的方法，用于声源定位算法中的音频信号和场景声学属性的建模。实验结果显示，DI-NN相比于经典方法和其他神经网络架构具有更低的定位误差。 |
| [^31] | [Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness.](http://arxiv.org/abs/2308.04137) | 通过综合评估深度学习分类器的性能，发现它们缺乏稳定性和可靠性，并建议采用广泛的数据类型和统一的评估指标进行性能基准测试。 |
| [^32] | [OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation.](http://arxiv.org/abs/2308.04126) | OmniDataComposer是一种创新的多模态数据融合和无限数据生成方法，通过引入一个有效的协调数据结构，可以处理和合并视频、音频和文本等多模态数据输入，并实现跨模态数据校正。 |
| [^33] | [Constructing Custom Thermodynamics Using Deep Learning.](http://arxiv.org/abs/2308.04119) | 本文使用深度学习构建了一个基于广义Onsager原理的平台，可以从微观轨迹的观察中学习任意随机耗散系统的宏观动力学描述。 |
| [^34] | [Asynchronous Evolution of Deep Neural Network Architectures.](http://arxiv.org/abs/2308.04102) | 本文提出了一种通用的异步评估策略，用于增加进化神经网络架构搜索的吞吐量。该策略维护一个个体队列，并在适当数量的个体被评估后立即进入下一代，平衡多样性和效率。 |
| [^35] | [Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK.](http://arxiv.org/abs/2308.04082) | 提出扩展QUARK框架以评估量子生成模型的训练和部署能力，并通过多个示例应用展示了其灵活性和泛化能力评估。 |
| [^36] | [Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients.](http://arxiv.org/abs/2308.04077) | 本论文提出了一种使用轨迹信息的代理梯度方法，用于解决联邦零阶优化中的查询和通信效率问题。 |
| [^37] | [Learning Specialized Activation Functions for Physics-informed Neural Networks.](http://arxiv.org/abs/2308.04073) | 本文发现物理信息神经网络（PINNs）在解决偏微分方程时对激活函数非常敏感，为了避免低效的手动选择并减轻优化困难，我们引入了自适应激活函数，并提出了将学习候选激活函数组合的思想应用于PINNs优化的方法。 |
| [^38] | [Path Signatures for Diversity in Probabilistic Trajectory Optimisation.](http://arxiv.org/abs/2308.04071) | 本文提出了一种基于路径签名的算法，用于解决并行轨迹优化中的模式塌陷问题，并实现更好的全局性能。 |
| [^39] | [ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data.](http://arxiv.org/abs/2308.04070) | ConDistFL框架将联邦学习与知识蒸馏相结合，通过充分设计条件概率表示从部分标注数据中提取无标注信息，解决了有限全标注训练数据的挑战，并在多个腹部CT数据集上展现了显著的性能优势。 |
| [^40] | [Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation.](http://arxiv.org/abs/2308.04061) | 本文提出了一种适用于标记数据稀缺环境的半监督对抗训练算法，通过引入适用于无标签数据的正则化项和知识蒸馏，实现了对抗鲁棒性的增强，并在实验证明了其显著优势。 |
| [^41] | [Toward Improving Predictive Risk Modelling for New Zealand's Child Welfare System Using Clustering Methods.](http://arxiv.org/abs/2308.04060) | 本文利用主成分分析和K-Means聚类方法，初步研究了新西兰儿童福利系统的预测风险建模，发现了一些特征并了解了其对当前风险建模框架的潜在影响。 |
| [^42] | [The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings.](http://arxiv.org/abs/2308.04052) | 五美元模型是一种轻量级的文本到图像生成架构，可以从编码的文本提示中生成低维度的图片，并在有限数据集上保持语义含义。 |
| [^43] | [Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization.](http://arxiv.org/abs/2308.04051) | 该论文提出了一种新的形状优化方法，通过降低设计空间维度和建模数据的生成过程，实现了提高全局优化算法效率和生成无几何异常的高质量设计。 |
| [^44] | [A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset.](http://arxiv.org/abs/2308.04037) | 该论文比较研究了TF-IDF特征加权方法并使用非结构化数据集进行了分析，结果发现相比于N-Gram，使用TF-IDF特征可以显著提高特征提取效果。 |
| [^45] | [Top K Relevant Passage Retrieval for Biomedical Question Answering.](http://arxiv.org/abs/2308.04028) | 这篇论文提出了一种用于生物医学问题回答的Top K相关段落检索方法，传统的稀疏向量空间模型不适用于这个任务。然而，对于临床领域来说，这个问题还没有得到很好的解决。 |
| [^46] | [Scope Loss for Imbalanced Classification and RL Exploration.](http://arxiv.org/abs/2308.04024) | 本文介绍了范围损失，这是一种新的适用于强化学习和监督分类的损失函数，它能够解决探索利用权衡和数据集不平衡问题，并在实验中表现出优于其他损失函数的性能。 |
| [^47] | [Improving Performance of Semi-Supervised Learning by Adversarial Attacks.](http://arxiv.org/abs/2308.04018) | 本文提出了一个名为SCAR的通用框架，通过对预训练模型进行对抗攻击来改进半监督学习算法的性能，显著提高了图像分类的准确性。 |
| [^48] | [Continual Pre-Training of Large Language Models: How to (re)warm your model?.](http://arxiv.org/abs/2308.04014) | 该论文研究了大型语言模型的持续预训练问题，探讨了热启动策略对于解决分布变化和提高计算效率的影响。 |
| [^49] | [Generalization bound for estimating causal effects from observational network data.](http://arxiv.org/abs/2308.04011) | 该论文提出了一种从观测网络数据中估计因果效应的泛化界限，通过利用联合倾向得分的重新加权模式和积分概率度量的表示学习模式进行推导，从而支持缓解混淆偏差和指导学习目标的设计。 |
| [^50] | [Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning.](http://arxiv.org/abs/2308.03999) | 本文提供了一种使用结构化背景知识和演绎推理的方法，用于解释CNN隐藏神经元的激活。该方法能够提供有意义的解释，解决了深度学习系统黑盒特性的问题。 |
| [^51] | [Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks.](http://arxiv.org/abs/2308.03995) | 本文提出了一种合作式多类型多智能体深度强化学习方法，应用于空天地一体化网络的资源管理，实验结果表明其有效性和潜在价值。 |
| [^52] | [Fourier neural operator for real-time simulation of 3D dynamic urban microclimate.](http://arxiv.org/abs/2308.03985) | 该论文介绍了傅里叶神经运算器（FNO）用于实时模拟3D动态城市微气候。通过深度学习技术，FNO在加速解决复杂非线性相互作用和系统动力学建模方面表现出很大的潜力。 |
| [^53] | [PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning.](http://arxiv.org/abs/2308.03977) | 我们提出了一种使用逼真且语义可控的合成数据的方法，用于表示学习研究，该方法具有渲染所需数量的数据样本、精确控制场景和分布转变以及精细的真实标签的优点。 |
| [^54] | [Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models.](http://arxiv.org/abs/2308.03960) | 本文提出了一种摊还全局搜索框架（AmorGS），利用深度生成模型加速对初步轨迹设计问题的全局搜索。该方法通过预测具有相似结构的轨迹解，能够在高维度和非凸性问题中更高效地寻找多个不同特征的解。通过在两个实际问题上的评估，证明了该方法的有效性。 |
| [^55] | [Fixed Inter-Neuron Covariability Induces Adversarial Robustness.](http://arxiv.org/abs/2308.03956) | 该论文研究了固定的神经元协变性对深度神经网络（DNN）的对抗性鲁棒性的影响，提出了自洽激活（SCA）层，其激活具有固定但可学习的协变性模式，以提高DNN的鲁棒性。 |
| [^56] | [PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning.](http://arxiv.org/abs/2308.03953) | 本研究提出了一种基于PMU测量的电力系统短期电压稳定性评估方法，利用深度迁移学习解决了拓扑变化、样本标注和小规模数据集处理等挑战，并且在实验中取得了较好的模型评估准确性。 |
| [^57] | [The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers.](http://arxiv.org/abs/2308.03945) | 本文研究了在大规模异构联邦学习中，通过Transformer模型实现泛化和个性化的前景，并通过广泛的比较实验证明了Transformer在大规模异构FL任务中相对于深度神经网络的优势，并通过分析中心核对齐（CKA）表示相似性来深入了解Transformer有前景的能力背后的原因。 |
| [^58] | [GraPhSyM: Graph Physical Synthesis Model.](http://arxiv.org/abs/2308.03944) | GraPhSyM是一种用于从物理合成电路网表中快速准确地估计后物理合成电路延迟和面积指标的模型，提供了准确的指标可见性给早期的EDA阶段，可用于全局协同优化，并对基于机器学习的EDA优化框架具有重要的作用。 |
| [^59] | [Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning.](http://arxiv.org/abs/2308.03928) | 本论文提出了在单克隆抗体生产中优化切换操作的方法，通过经济模型预测控制和强化学习来提高连续生产过程的效率和质量。 |
| [^60] | [Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables.](http://arxiv.org/abs/2308.03915) | 通过使用具有内部变量的深度物理引导神经网络，在只使用测量的力-位移数据进行训练的情况下，本文发现了非线性材料的本构定律。这一方法能够预测未见的加载情况下的内部和外部变量，无论材料的性质如何。 |
| [^61] | [ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition.](http://arxiv.org/abs/2308.03908) | 本论文提出了一种基于姿势增强的视觉语言模型(VLM)，用于视频动作识别。实验结果表明，该模型能够取得令人期待的准确率，并在两个流行的动作识别数据集上取得了优异的性能。 |
| [^62] | [Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art.](http://arxiv.org/abs/2308.03907) | 众包监控系统是解决公共安全问题的关键，本研究对基于视觉和非基于视觉的技术进行了深入分析。 |
| [^63] | [Intelligent Assistant Language Understanding On Device.](http://arxiv.org/abs/2308.03905) | 本论文描述了一种在设备上运行的自然语言理解系统的设计，相比于基于服务器的助手，该系统更加私密、可靠、快速、表达更强、准确性更高。通过分享实践经验，为研究界的未来工作提供参考。 |
| [^64] | [On genuine invariance learning without weight-tying.](http://arxiv.org/abs/2308.03904) | 本文研究了神经网络从数据中学习到的不变性与通过权重绑定实现的真正不变性之间的区别，并提出了正则化方法来指导学习真正的不变性，实现了在输入数据分布发生变化时仍然可靠的不变性模型。 |
| [^65] | [FLIPS: Federated Learning using Intelligent Participant Selection.](http://arxiv.org/abs/2308.03901) | 本文介绍了FLIPS，这是一个用于管理联邦学习中数据和参与者异质性的中间件系统。FLIPS通过标签分布聚类和智能参与者选择，并使用可信执行环境来确保隐私保护。实证评估表明，FLIPS相比随机方法有更好的性能。 |
| [^66] | [A new approach for evaluating internal cluster validation indices.](http://arxiv.org/abs/2308.03894) | 本文回顾了现有的聚类验证方法并提出了一种新方法，用于评估无监督分类算法在不同类型的数据中的表现。 |
| [^67] | [Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data.](http://arxiv.org/abs/2308.03892) | 本研究通过机器学习和人工智能方法实现了可扩展且公平的大规模教育数据中数学问题解决策略预测。 |
| [^68] | [Deep neural networks from the perspective of ergodic theory.](http://arxiv.org/abs/2308.03888) | 本论文从遍历理论的角度出发，将深度神经网络视为动力系统的时间演化，通过引入一些经验法则，解释了神经网络设计中的一些启发式方法。 |
| [^69] | [Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach.](http://arxiv.org/abs/2308.03887) | 本论文提出了一种使用时间对称的深度学习方法来提升细胞跟踪的准确性。该方法不依赖于连续帧跟踪，而是基于细胞的时空邻域进行跟踪，具有学习细胞运动模式的能力，并能处理具有严重伪影的大量视频帧。 |
| [^70] | [Generative Benchmark Creation for Table Union Search.](http://arxiv.org/abs/2308.03883) | 采用生成型AI模型为表联合搜索创建结构化数据基准 |
| [^71] | [Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations.](http://arxiv.org/abs/2308.03882) | 本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。 |
| [^72] | [Evaluating and Explaining Large Language Models for Code Using Syntactic Structures.](http://arxiv.org/abs/2308.03873) | 本文介绍了一种针对代码的大型语言模型（LLM）的解释方法ASTxplainer，该方法能够可靠地将模型的预测映射到可理解的概念上，从而实现模型的可解释性。 |
| [^73] | [Semantic Equivalence of e-Commerce Queries.](http://arxiv.org/abs/2308.03869) | 本文介绍了一种识别和利用电子商务查询等价性的框架，以提升搜索者和商业结果。该框架解决了将查询映射为搜索意图向量表示、识别等价或相似意图的最近邻查询以及优化用户或商业目标等三个关键问题。通过表面相似性和行为相似性来确定查询的等价性。 |
| [^74] | [Revisiting Prompt Engineering via Declarative Crowdsourcing.](http://arxiv.org/abs/2308.03854) | 本研究通过借鉴声明式众包的思想，提出了一种声明式提示工程的方法，旨在解决大型语言模型在数据处理中的质量优化和成本控制问题。 |
| [^75] | [Search Engine and Recommendation System for the Music Industry built with JinaAI.](http://arxiv.org/abs/2308.03842) | 该论文介绍了使用JinaAI构建音乐行业的搜索引擎和推荐系统的研究，通过匹配歌曲歌词和提供准确的搜索结果来解决现有搜索引擎的问题。 |
| [^76] | ["Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models.](http://arxiv.org/abs/2308.03825) | 本文对大规模语言模型中的越狱提示进行了特征化和评估研究。通过测量野外越狱提示的唯一特征和主要攻击策略，我们发现越狱提示越来越多地从公共平台转移到私人平台，给LLM供应商在主动检测方面带来了新的挑战。 |
| [^77] | [Distributionally Robust Classification on a Data Budget.](http://arxiv.org/abs/2308.03821) | 本研究介绍了一种基于数据预算的分布鲁棒分类方法，在有限的数据情况下，通过精心设计的训练集和控制实验，证明了在240万个图像样本上的训练可以获得与在4亿个图像样本上训练相媲美的鲁棒性。 |
| [^78] | [XFlow: Benchmarking Flow Behaviors over Graphs.](http://arxiv.org/abs/2308.03819) | XFlow是一种在图上评估流行为的基准测试方法，解决了流动行为的理解和算法评估的问题。 |
| [^79] | [A sparse coding approach to inverse problems with application to microwave tomography imaging.](http://arxiv.org/abs/2308.03818) | 本文介绍了基于稀疏编码的逆问题方法，并将其应用于微波断层成像，为现有算法的改进提供了可能。 |
| [^80] | [High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers.](http://arxiv.org/abs/2308.03813) | 该论文提出了一种新的方法来增加个性化颅骨重建的可用性，通过点云完成任务实现高分辨率颅缺损重建，并在训练和推理过程中快速且资源高效。 |
| [^81] | [Noncompact uniform universal approximation.](http://arxiv.org/abs/2308.03812) | 这篇论文将通用逼近定理推广到非紧致输入空间，并确定了在有界激活函数条件下可以通过神经网络一致逼近的函数类别，并提出了代数结构的意外结果。 |
| [^82] | [Non-Convex Bilevel Optimization with Time-Varying Objective Functions.](http://arxiv.org/abs/2308.03811) | 本论文研究了在线双层优化问题，提出了一种基于窗口平均的单循环在线双层优化器（SOBOW），它能在处理函数变化和真实超梯度不可用的情况下高效更新决策。 |
| [^83] | [AdaER: An Adaptive Experience Replay Approach for Continual Lifelong Learning.](http://arxiv.org/abs/2308.03810) | AdaER是一种自适应经验重播方法，用于解决连续终身学习中的灾难性遗忘问题。它采用上下文提示的记忆回忆策略，选择性地重播最冲突的记忆。 |
| [^84] | [Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction.](http://arxiv.org/abs/2308.03807) | 提出了一种基于第二Nesterov近端梯度优化的深度几何增量学习框架，能够在图像重建时减轻伪影，同时实现快速收敛。 |
| [^85] | [Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables.](http://arxiv.org/abs/2308.03805) | 提出了一种使用弱监督多任务表示学习的方法，通过将数据映射到多个表示空间并根据多个方面对数据进行聚类，实现了同时解决多个任务的能力。 |
| [^86] | [Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach.](http://arxiv.org/abs/2308.03800) | 该论文提出了一种深度学习方法，用于分析金融欺诈文本并进行分类。通过比较多种神经网络模型的准确性，该研究对金融欺诈检测具有重要意义 |
| [^87] | [Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels.](http://arxiv.org/abs/2308.03792) | 本文展示了通过设计一个单一的对抗扰动P，在多个图像上实现将其原始类别改变为不同目标类别的多重攻击。研究发现在像素空间中存在大量高类别置信度的区域，对全面的防御策略构成重要挑战。 |
| [^88] | [Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction.](http://arxiv.org/abs/2308.03782) | 该研究比较了Bio+Clinical BERT、BERT Base和CNN在预测药物评价满意度方面的性能，结果显示医学领域特定的Bio+Clinical BERT模型在整体性能上优于通用领域的BERT Base模型，提高了11%的Macro F1和召回率得分。 |
| [^89] | [Goodness-of-Fit of Attributed Probabilistic Graph Generative Models.](http://arxiv.org/abs/2308.03773) | 本文研究了属性概率图生成模型的拟合优度，并以均方互信息系数为指标进行了评估和验证。 |
| [^90] | [Improved Neural Radiance Fields Using Pseudo-depth and Fusion.](http://arxiv.org/abs/2308.03772) | 本文提出了一种改进神经光辐射场的方法，通过构建多尺度编码体和提供多尺度几何信息，同时进行深度预测和辐射场重建，以实现对真实场景中物体的准确建模和视角合成。 |
| [^91] | [Applications of Machine Learning to Modelling and Analysing Dynamical Systems.](http://arxiv.org/abs/2308.03763) | 本论文介绍了将机器学习应用于模拟和分析动力系统的方法，并提出了一种结合了哈密顿神经网络结构的可调节辛形状神经网络的架构，该架构在预测动力学时保留了哈密顿方程和相空间的辛结构。这种方法在预测哈密顿动力学中表现出很高的精确性和鲁棒性。 |
| [^92] | [Randomized algorithms for precise measurement of differentially-private, personalized recommendations.](http://arxiv.org/abs/2308.03735) | 这项研究提出了一种随机算法，用于精确测量差分隐私的个性化推荐。通过离线实验，该算法在关键指标上与私密的非个性化和非私密的个性化实现进行了比较。 |
| [^93] | [Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission.](http://arxiv.org/abs/2308.03713) | 本文提出了一个基于联邦学习的语义通信框架，用于多任务分布式图像传输，通过全局聚合改进了语义提取和任务性能。 |
| [^94] | [MedMine: Examining Pre-trained Language Models on Medication Mining.](http://arxiv.org/abs/2308.03629) | MedMine通过检验预训练语言模型在药物挖掘中的应用，发现了它们在不同实体类型和临床事件上的不平衡表现，并提供了解决这些问题的研究方向。 |
| [^95] | [Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks.](http://arxiv.org/abs/2308.02632) | 本研究提出了一种使用生成对抗网络生成合成毫米波雷达数据的快速方法，可以增加数据增强的潜力，并进一步开发雷达数据处理算法。 |
| [^96] | [Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting.](http://arxiv.org/abs/2308.02582) | 该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。 |
| [^97] | [Federated Representation Learning for Automatic Speech Recognition.](http://arxiv.org/abs/2308.02013) | 使用联邦学习和自监督学习的结合方法，研究了面向自动语音识别的联邦表示学习，将边缘设备上的隐私数据用于学习健壮的音频表示，并取得了显著的性能改善。 |
| [^98] | [An Exact Kernel Equivalence for Finite Classification Models.](http://arxiv.org/abs/2308.00824) | 本研究推导出梯度下降训练的有限分类模型的精确核表示，揭示了神经网络和核方法之间的等价性，并通过实验证明了精确核对神经网络预测的指导作用。 |
| [^99] | [ProtoFL: Unsupervised Federated Learning via Prototypical Distillation.](http://arxiv.org/abs/2307.12450) | 本文提出了ProtoFL，一种基于原型蒸馏的无监督联邦学习方法，用于提高全局模型的表示能力并减少通信成本。此外，引入了基于正规流的本地单类分类器以提高有限数据下的性能。在五个基准数据集上的实验证明了该方法相较于先前方法具有超越性能。 |
| [^100] | [Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations?.](http://arxiv.org/abs/2307.12344) | 本研究在胸透诊断任务中评估了五种事后解释技术和一种本质上可解释的方法对于检测虚假相关性的能力，发现SHAP和Attri-Net可以有效地检测出这种类型的依赖关系。 |
| [^101] | [Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts.](http://arxiv.org/abs/2307.11661) | 本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。 |
| [^102] | [SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning.](http://arxiv.org/abs/2307.10579) | 提出了一种通过多目标联邦学习来调优SecureBoost超参数的方法，以找到在效用、效率和隐私之间最佳平衡的一组超参数解决方案。 |
| [^103] | [Can We Trust Race Prediction?.](http://arxiv.org/abs/2307.08496) | 本文研究了在没有敏感的种族和族裔数据的情况下，使用代理模型进行种族预测的问题。研究者训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，还构建了美国最全面的姓氏和名字分布数据库，并提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。 |
| [^104] | [Towards Understanding Adversarial Transferability From Surrogate Training.](http://arxiv.org/abs/2307.07873) | 本论文探索了对抗性可转移性的理解，特别关注替代训练。通过研究模型的平滑性和梯度相似性之间的权衡，发现对抗训练可以提高模型的替代能力。研究结果对数据分布的转变提出了新的推测。 |
| [^105] | [Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models.](http://arxiv.org/abs/2307.06713) | 本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。 |
| [^106] | [Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization.](http://arxiv.org/abs/2307.03571) | 本文介绍了一种通用框架，可以在稀疏正则化中进行平滑优化，与主流的一阶优化方法兼容，并且能够得到匹配的全局最小值和等价的局部最小值。 |
| [^107] | [Evaluating Data Attribution for Text-to-Image Models.](http://arxiv.org/abs/2306.09345) | 本论文评估了文本到图像模型的数据归因问题，通过定制方法，我们可以有效地创建受典型对象影响的合成图像，并通过调整标准模型，解决归因问题。 |
| [^108] | [GCformer: An Efficient Framework for Accurate and Scalable Long-Term Multivariate Time Series Forecasting.](http://arxiv.org/abs/2306.08325) | GCformer是一个结合了全局卷积和局部Transformer分支的框架，旨在解决长期多元时间序列预测的精确性和可扩展性问题。通过引入具有亚线性复杂度的结构化卷积核，GCformer在各种基准数据集上实现了优于其他方法的性能。 |
| [^109] | [Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders.](http://arxiv.org/abs/2305.19259) | 本论文研究了一种允许任意数据排序的普通SGD算法,并表明在非凸函数情况下，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。 |
| [^110] | [UMD: Unsupervised Model Detection for X2X Backdoor Attacks.](http://arxiv.org/abs/2305.18651) | UMD是一种无监督的模型检测方法，能够有效地检测X2X后门攻击，对抗（源，目标）类别对进行联合推断，该方法定义了新的可转移性统计量，并使用聚类方法来测量和选择潜在的后门类别对的子集。 |
| [^111] | [Measuring and Modeling Physical Intrinsic Motivation.](http://arxiv.org/abs/2305.13452) | 本文对身体内在动机进行了量化建模，发现对抗性奖励模型可以最好地预测人类对物理情境的趣味反应，还发现简单场景特征模型无法在所有情境中预测人类反应，将对抗模型和场景中碰撞数量进行线性组合，能够显著提高对人类反应的预测能力，表明人类追求高信息增益和身体活动的情况。 |
| [^112] | [P-NOC: Adversarial CAM Generation for Weakly Supervised Semantic Segmentation.](http://arxiv.org/abs/2305.12522) | 本文提出了一种新的弱监督语义分割策略，通过对抗性CAM生成网络生成稳健的语义分割提议，结果表明该方法显著提高了分割效果。 |
| [^113] | [Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders.](http://arxiv.org/abs/2305.02640) | 本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。 |
| [^114] | [Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels.](http://arxiv.org/abs/2305.01160) | 本论文提出了一种名为LC的新长尾识别方法，它能够更好地模拟真实标签分布，同时解决类别标签不平衡问题，从而在CIFAR-10，CIFAR-100和ImageNet基准数据集上显着优于现有方法。 |
| [^115] | [Tackling Face Verification Edge Cases: In-Depth Analysis and Human-Machine Fusion Approach.](http://arxiv.org/abs/2304.08134) | 本文研究了临近边缘案例的面部验证问题，发现结合人机决策可以进一步提高最先进的面部验证系统在各种基准数据集上的性能。 |
| [^116] | [PMAA: A Progressive Multi-scale Attention Autoencoder Model for High-Performance Cloud Removal from Multi-temporal Satellite Imagery.](http://arxiv.org/abs/2303.16565) | PMAA是一种利用全局和局部信息的高性能卫星遥感云去除架构。其中，独特的多尺度注意力模块和局部交互模块能够同时表示细粒度和粗粒度特征，相比现有方法表现更优。 |
| [^117] | [GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization.](http://arxiv.org/abs/2303.16459) | GNNBuilder是一个自动化的、通用的、端到端的GNN加速器生成框架，它可以为用户任意定义的广泛的GNN模型自动生成加速器，且运行速度比软件基准快多达12.95倍。 |
| [^118] | [Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals.](http://arxiv.org/abs/2303.00500) | 提出了一种名为Attri-Net的内在可解释模型，用于多标签分类，它能提供透明、可信赖和人可理解的解释。该模型通过生成类别特定的归因图，基于对抗事实来确定图像中对应于特定医疗发现的区域，并使用逻辑回归模型对归因图进行分类预测。 |
| [^119] | [Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction.](http://arxiv.org/abs/2303.00286) | 通过引入领域和范围约束，我们提出了基于语义的损失函数来区分不同质量的负样本，实验证明在链接预测任务上有效。 |
| [^120] | [A semantic backdoor attack against Graph Convolutional Networks.](http://arxiv.org/abs/2302.14353) | 该论文研究了图卷积网络（GCNs）是否容易受到语义后门攻击，提出了一种针对GCNs的语义后门攻击方法（SBAG），通过在样本中的特定节点作为触发器，并注入隐藏的后门来攻击GCNs模型。 |
| [^121] | [Causal Razors.](http://arxiv.org/abs/2302.10331) | 本文比较了许多出现在文献中的因果剃刀，并特别研究了在多项式因果模型中不太受欢迎的因果剃刀——参数最小性。逻辑结果揭示了选择合理得分标准时的困境。 |
| [^122] | [MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows.](http://arxiv.org/abs/2302.01075) | 本文提出了一个新的GAN生成建模框架MonoFlow，通过Wasserstein梯度流获得理论洞见和算法启示。该框架使用密度比例的单调递增映射重新缩放粒子演化，并通过训练鉴别器获得MonoFlow的向量场，利用相应的向量场进行粒子流的生成。 |
| [^123] | [Weight Prediction Boosts the Convergence of AdamW.](http://arxiv.org/abs/2302.00195) | 本文通过将权重预测技术引入AdamW优化器，加速了深度神经网络的收敛过程，实验结果表明，该方法提升了AdamW的收敛性并在训练DNN模型时获得更高的准确性。 |
| [^124] | [Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets.](http://arxiv.org/abs/2301.10227) | 本研究证明，去噪扩散概率模型可以通过无监督和直观的方法生成完全标注的显微镜图像数据集，有助于减少对人工标注的依赖，并且能够对多样的数据集进行分割。 |
| [^125] | [Dynamic Feature Engineering and model selection methods for temporal tabular datasets with regime changes.](http://arxiv.org/abs/2301.00790) | 本文提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。使用梯度提升决策树（GBDT）并结合dropout技术的模型具有良好的性能和泛化能力，而动态特征中和则是一种高效而不需要重新训练模型就可以应用于任何机器学习模型中的后处理技术。 |
| [^126] | [Genie: Show Me the Data for Quantization.](http://arxiv.org/abs/2212.04780) | Genie提出了一个后训练量化方案，用于开发轻量级深度神经网络，并提出了一个用于生成适合零样本量化的数据的框架。 |
| [^127] | [Selective Memory Recursive Least Squares: Recast Forgetting into Memory in RBF Neural Network Based Real-Time Learning.](http://arxiv.org/abs/2211.07909) | 本文提出了一种名为选择性记忆递归最小二乘法（SMRLS）的实时训练方法，将经典遗忘机制转化为记忆机制，通过综合评估样本的采集时间和时空分布来评估样本的重要性。 |
| [^128] | [Learning To Rank Diversely At Airbnb.](http://arxiv.org/abs/2210.07774) | 这篇论文研究了在Airbnb上学习多样化的排序方法。通过纠正传统排序框架中的假设，提出了一种基于高效神经网络架构的排序策略，以实现更准确的房源匹配，并加入了考虑房源相似性的方法以实现多样化的排序。 |
| [^129] | [Spiking Neural Networks for event-based action recognition: A new task to understand their advantage.](http://arxiv.org/abs/2209.14915) | 本文通过提出新任务DVS-GC并进行实证研究，展示了脉冲神经网络在事件驱动动作识别中的优势，包括实现时间特征提取和对事件顺序的理解。 |
| [^130] | [Adversarial Coreset Selection for Efficient Robust Training.](http://arxiv.org/abs/2209.05785) | 本文提出了一种对抗性核心集选择的方法，通过选择训练数据的小子集来降低稳健训练的时间复杂度，并提供了收敛保证。 |
| [^131] | [Machine Learning and Computer Vision Techniques in Bee Monitoring Applications.](http://arxiv.org/abs/2208.00085) | 本文介绍了机器学习和计算机视觉在蜜蜂监测中的最新应用，展示了自动化蜜蜂计数算法的潜力，并希望能够激发其他科学家的灵感和兴趣。 |
| [^132] | [Set-based value operators for non-stationary Markovian environments.](http://arxiv.org/abs/2207.07271) | 本文将Bellman算子和策略评估算子推广为值函数空间上的压缩算子，并将其提升为作用于值函数集合的基于集合的值运算符。利用集合论的见解，我们将经典鲁棒MDP文献中的矩形条件推广为适用于更多参数不确定MDP和动态规划中的压缩算子的包含条件。研究结果表明，基于集合的值运算符具有压缩性。 |
| [^133] | [Auto-Encoding Adversarial Imitation Learning.](http://arxiv.org/abs/2206.11004) | 自动编码对抗性模仿学习（AEAIL）是一种稳健且可扩展的方法，利用自动编码器的重构误差作为奖励信号来优化策略。在基于状态和基于图像的环境中，AEAIL比现有方法表现更好，并且对于噪声示范专家具有更好的稳健性。 |
| [^134] | [ORC: Network Group-based Knowledge Distillation using Online Role Change.](http://arxiv.org/abs/2206.01186) | 本文提出了一种利用在线角色变换的网络群组知识蒸馏方法，通过将多个网络分成教师组和学生组，学生组学习教师的知识，使用在线角色变换策略将学生组中排名靠前的网络晋升为教师组，通过训练教师组以改进其知识，实现了更好的知识蒸馏效果。 |
| [^135] | [Differentiable Rendering for Synthetic Aperture Radar Imagery.](http://arxiv.org/abs/2204.01248) | 本研究提出了一种可微分合成孔径雷达成像方法，用于三维物体重建，通过结合三维计算机图形学方法和神经渲染技术，使用高保真度的模拟SAR数据进行验证。 |
| [^136] | [Transferability Properties of Graph Neural Networks.](http://arxiv.org/abs/2112.04629) | 本文研究了将图神经网络（GNNs）从中等规模图迁移到大规模图的问题，并通过引入图核密度滤波器和图核密度神经网络（WNNs）的概念，提出了逼近方法以限定迁移误差。 |
| [^137] | [Composite Goodness-of-fit Tests with Kernels.](http://arxiv.org/abs/2111.10275) | 本文提出了一种基于核的假设检验方法，可以解决具有挑战性的复合检验问题，其核心思想是在正确的模型规范的零假设下，非参数地估计参数（或模拟器）分布。 |
| [^138] | [Analysis of Regularized Learning for Linear-functional Data in Banach Spaces.](http://arxiv.org/abs/2109.03159) | 本文研究了巴拿赫空间中线性函数数据的正则化学习的整个理论，包括表示定理、伪逼近定理和收敛定理。正则化学习通过最小化正则化经验风险来逼近未知或未明确的原问题的精确解，并且可以应用于解决多种问题。 |
| [^139] | [Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression.](http://arxiv.org/abs/2105.02796) | 高斯过程回归提供了不确定性估计，但其贝叶斯性质限制了其在某些重要应用中的使用。为解决这一问题，我们提出了实用且严格的不确定性界限，相比现有结果更准确，并且对模型偏差有优雅的退化。 |
| [^140] | [Machine learning for rapid discovery of laminar flow channel wall modifications that enhance heat transfer.](http://arxiv.org/abs/2101.08130) | 本文提出了一种组合精确数值模拟和机器学习模型的方法，用于快速发现增强传热的层流流道壁修饰。通过卷积神经网络的预测，可以在较短时间内准确评估壁面性能，并且可以应用于大规模的壁面结构筛选。 |
| [^141] | [Learning Bayesian Networks with Annealing Machine.](http://arxiv.org/abs/2006.06926) | 本文提出了一种用于贝叶斯网络结构学习的模拟退火机器方法，通过先进的候选父节点集合的确定和分解，以及整数规划问题的解决，能够在比特容量有限的情况下高效地解决基于评分的学习问题。 |
| [^142] | [Discriminator optimal transport.](http://arxiv.org/abs/1910.06832) | 这篇论文研究了判别器优化过程如何增加生成对抗网络中Wasserstein距离的对偶代价函数的下限，从而使训练好的判别器能够近似最优输运。作者提出了一种判别器最优输运（DOT）方案，通过实验证明了在不同数据集上的生成图像质量有所提升。 |

# 详细

[^1]: 当越多越少：引入额外数据集可能通过引入虚假相关性来降低性能

    When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations. (arXiv:2308.04431v1 [cs.LG])

    [http://arxiv.org/abs/2308.04431](http://arxiv.org/abs/2308.04431)

    引入额外数据集可能会通过引入虚假相关性来降低性能，即使添加的数据使训练分布更接近测试分布。这种现象是由于医院特定的图像伪像引起的。这一结果挑战了常见的认为更多数据能提高模型性能的观念。

    

    在机器学习中，引入更多数据通常被视为提高模型性能的可靠策略；本研究挑战了这一观念，通过证明在许多情况下，引入外部数据集可能会损害所得模型的性能。通过对四个不同开源胸部X光数据集和9个不同标签的组合进行大规模经验研究，我们证明在43%的设置中，仅使用单个医院的数据进行训练的模型在两个医院上的最差组准确率都比使用两个医院的数据进行训练的模型要低。即使添加的医院使训练分布更接近测试分布，这一令人惊讶的结果仍会出现。我们解释了这种现象是由于与疾病和医院之间的虚假相关性产生，这是由于医院特定的图像伪像引起的。我们强调了在训练多个数据集时所遇到的折衷取舍，即额外数据的明显好处和虚假相关性引入的性能损失之间的平衡。

    In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and i
    
[^2]: SILO语言模型：在非参数化数据存储中隔离法律风险

    SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore. (arXiv:2308.04430v1 [cs.CL])

    [http://arxiv.org/abs/2308.04430](http://arxiv.org/abs/2308.04430)

    SILO是一种新的语言模型，通过在推理过程中对非参数化的数据存储进行查询，实现在面临法律风险和模型性能之间的权衡，并支持数据归属和数据生产者退出模型的功能。

    

    在对将语言模型（LMs）训练在受版权或受其他限制的数据上的合法性进行激烈辩论的同时，我们展示了仅在低风险文本（例如过期版权图书或政府文件）上训练时，模型性能显著下降的问题，原因是该文本的规模和领域覆盖有限。我们提出了SILO，一种新的语言模型，在推理过程中管理这种风险-性能权衡。SILO通过以下方式构建：（1）在我们策划的新语料库“开放许可证语料库”（OLC）上训练参数化的LM，该语料库包含228B个公共领域和许可文本。（2）通过非参数化的数据存储（例如包含受版权保护的图书或新闻的数据）对其进行扩充，该数据存储仅在推理过程中被查询。该数据存储允许使用高风险数据而无需对其进行训练，支持句级数据归属，并使数据生产者可以通过从存储中删除内容来选择退出模型。这些功能可以促进对数据使用规范的遵循。

    The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use
    
[^3]: 从多任务非独立同分布数据中元学习操作符到最优性

    Meta-Learning Operators to Optimality from Multi-Task Non-IID Data. (arXiv:2308.04428v1 [stat.ML])

    [http://arxiv.org/abs/2308.04428](http://arxiv.org/abs/2308.04428)

    本文提出了从多任务非独立同分布数据中恢复线性操作符的方法，并发现现有的各向同性无关的元学习方法会对表示更新造成偏差，限制了表示学习的样本复杂性。为此，引入了去偏差和特征白化的适应方法。

    

    机器学习中最近取得进展的一个强大概念是从异构来源或任务的数据中提取共同特征。直观地说，将所有数据用于学习共同的表示函数，既有助于计算效率，又有助于统计泛化，因为它可以减少要在给定任务上进行微调的参数数量。为了在理论上做出这些优点的根源，我们提出了从噪声向量测量$y = Mx + w$中回复线性操作符$M$的一般模型。其中，协变量$x$既可以是非独立同分布的，也可以是非各向同性的。我们证明了现有的各向同性无关的元学习方法会对表示更新造成偏差，这导致噪声项的缩放不再有利于源任务数量。这反过来会导致表示学习的样本复杂性受到单任务数据规模的限制。我们引入了一种方法，称为去偏差和特征白化。

    A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}
    
[^4]: 使用自动编码器和生成对抗网络的深度学习方法实现古代石碑表面异常检测

    A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces. (arXiv:2308.04426v1 [cs.CV])

    [http://arxiv.org/abs/2308.04426](http://arxiv.org/abs/2308.04426)

    本文介绍了一种使用自动编码器和生成对抗网络的深度学习方法，用于实时自动检测古代石碑表面的自然破坏和人为损坏。这种方法克服了现有方法的局限性，可以全面检测各种不可预测的异常情况。

    

    准确检测古代石碑表面的自然破坏和人为损坏是其预防性保护的关键。现有的文化遗产保护方法无法完美地实现这一目标，因为很难在准确性、效率、及时性和成本之间取得平衡。本文提出了一种深度学习方法，通过使用自动编码器（AE）和生成对抗网络（GAN），实时自动检测古代石碑上述紧急情况。所提出的方法通过不需要大量异常样本的方式克服了现有方法的局限性，同时实现了对不可预测异常的全面检测。该方法包括监测、数据采集、预处理、模型构建和后处理等阶段。以龙门石窟的石碑为案例研究，提出了一个基于AE和GAN架构的无监督学习模型，并进行了重构验证。

    Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstru
    
[^5]: 股市价格预测：基于混合LSTM和顺序自注意力的方法

    Stock Market Price Prediction: A Hybrid LSTM and Sequential Self-Attention based Approach. (arXiv:2308.04419v1 [cs.AI])

    [http://arxiv.org/abs/2308.04419](http://arxiv.org/abs/2308.04419)

    本论文介绍了一种基于混合LSTM和顺序自注意力的方法，旨在预测股票未来价格，并通过实验证明了该方法的有效性。

    

    股市是最令人着迷的研究领域之一，预测股票价格可以帮助投资者在正确的时间做出最佳决策从而获利。深度学习策略已经成为金融市场领域的关键技术。股市受两个方面的影响，一方面是地缘政治、社会和全球事件，这些事件可能影响价格趋势。与此同时，第二个方面纯粹关注历史价格趋势和季节性，使我们能够预测股票价格。本文旨在专注于第二个方面，建立一个能够以最小误差预测未来价格的模型。为了提供更好的股票价格预测结果，我们提出了一个名为长短期记忆 (LSTM) 和顺序自注意力机制 (LSTM-SSAM) 的新模型。最后，我们对三个股票数据集进行了广泛的实验：SBIN、HDFCBANK 和 BANKBARODA。实验结果证明了模型的有效性。

    One of the most enticing research areas is the stock market, and projecting stock prices may help investors profit by making the best decisions at the correct time. Deep learning strategies have emerged as a critical technique in the field of the financial market. The stock market is impacted due to two aspects, one is the geo-political, social and global events on the bases of which the price trends could be affected. Meanwhile, the second aspect purely focuses on historical price trends and seasonality, allowing us to forecast stock prices. In this paper, our aim is to focus on the second aspect and build a model that predicts future prices with minimal errors. In order to provide better prediction results of stock price, we propose a new model named Long Short-Term Memory (LSTM) with Sequential Self-Attention Mechanism (LSTM-SSAM). Finally, we conduct extensive experiments on the three stock datasets: SBIN, HDFCBANK, and BANKBARODA. The experimental results prove the effectiveness a
    
[^6]: DiffCR: 一种快速的光学卫星图像云去除的条件扩散框架

    DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images. (arXiv:2308.04417v1 [cs.CV])

    [http://arxiv.org/abs/2308.04417](http://arxiv.org/abs/2308.04417)

    本文提出了一种名为DiffCR的快速条件扩散框架，用于高性能的光学卫星图像云去除。它利用深度卷积网络和条件引导扩散来提供强大的颜色表征，确保合成输出与条件输入之间的外观信息具有紧密的相似性。

    

    光学卫星图像是重要的数据来源，然而云覆盖经常会影响它们的质量，阻碍图像应用和分析。因此，有效地从光学卫星图像中去除云层成为一个突出的研究方向。虽然最近云去除的进展主要依赖生成对抗网络，但这可能导致图像质量次优。扩散模型在多样的图像生成任务中展现了显著的成功，显示了其在解决这一挑战中的潜力。本文提出了一种名为DiffCR的新型框架，它利用带有深度卷积网络的条件引导扩散，实现高性能的光学卫星图像云去除。具体而言，我们引入了一种用于条件图像特征提取的解耦编码器，提供了强大的颜色表征，以确保条件输入和合成输出之间的外观信息的紧密相似性。

    Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover
    
[^7]: 使用随机线性分类器进行概率不变学习

    Probabilistic Invariant Learning with Randomized Linear Classifiers. (arXiv:2308.04412v1 [cs.LG])

    [http://arxiv.org/abs/2308.04412](http://arxiv.org/abs/2308.04412)

    本文介绍了一种使用随机线性分类器进行概率不变学习的方法，通过接受概率化的普遍逼近和不变性，设计了能同时具有表达能力和不变性的模型，并且使用更少的资源。通过实验证明了这种方法在分类任务中的有效性。

    

    设计既具有表达能力又能保持任务已知不变性的模型是一个越来越困难的问题。现有解决方案在不变性和计算或内存资源之间进行权衡。在这项工作中，我们展示了如何利用随机性设计既具表达能力又具不变性但使用更少资源的模型。受随机算法的启发，我们的关键洞察是接受概率化的普遍逼近和不变性可以减少资源需求。具体而言，我们提出了一类称为随机线性分类器 (RLCs) 的二分类模型。我们给出了参数和样本大小的条件，在这些条件下，RLCs 可以以高概率逼近任何（平滑）函数，并保持对紧致群变换的不变性。利用这一结果，我们设计了三种可验证地概率不变的 RLCs，用于集合、图和球形数据的分类任务。我们展示了这些模型如何实现概率不变性。

    Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invari
    
[^8]: XGBD: 说明引导的图反向门探测

    XGBD: Explanation-Guided Graph Backdoor Detection. (arXiv:2308.04406v1 [cs.CR])

    [http://arxiv.org/abs/2308.04406](http://arxiv.org/abs/2308.04406)

    本文提出了一种说明引导的图反向门探测方法，通过利用拓扑信息来增强反向门检测的有效性

    

    反向门攻击对图学习模型构成了重大的安全风险。通过将反向门触发器插入训练数据集，可以将反向门嵌入到目标模型中，导致模型在存在触发器时做出错误的预测。为了对抗反向门攻击，已经提出了反向门检测方法。在视觉和自然语言处理领域中，一种新兴的检测策略基于一个有趣的现象：在将模型训练于包含反向门和干净样本的混合数据集时，反向门样本的损失下降速度明显快于干净样本，从而可以通过选择损失值最低的样本来轻松检测反向门样本。然而，对图数据忽略了拓扑特征信息，限制了检测的有效性。因此，我们提出了一种说明引导的反向门检测方法来利用拓扑信息。具体来说，我们在图数据集上训练助手模型f

    Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, f
    
[^9]: 用联邦学习革新无线网络：一项综合评述

    Revolutionizing Wireless Networks with Federated Learning: A Comprehensive Review. (arXiv:2308.04404v1 [cs.LG])

    [http://arxiv.org/abs/2308.04404](http://arxiv.org/abs/2308.04404)

    联邦学习是一种新兴的机器学习模型，它可以在无线边缘网络中实现数据获取和计算的分离，对于未来的移动网络尤其是6G及以后具有重要作用。

    

    随着智能手机、平板电脑和车辆等无线用户设备的计算能力不断提高，以及对共享私人数据的日益关注，一种名为联邦学习（FL）的新型机器学习模型已经出现。FL使得数据获取和计算在中央单元中分离，这与在数据中心中进行的集中式学习不同。FL通常用于无线边缘网络中，其中通信资源有限且不可靠。带宽限制要求在每次迭代中仅安排部分用户设备进行更新，并且由于无线介质是共享的，传输易受干扰且不保证。本文讨论了机器学习在无线通信中的重要性，并强调了联邦学习（FL）作为一种新颖方法，在未来的移动网络中特别是6G及以后扮演重要角色。

    These days with the rising computational capabilities of wireless user equipment such as smart phones, tablets, and vehicles, along with growing concerns about sharing private data, a novel machine learning model called federated learning (FL) has emerged. FL enables the separation of data acquisition and computation at the central unit, which is different from centralized learning that occurs in a data center. FL is typically used in a wireless edge network where communication resources are limited and unreliable. Bandwidth constraints necessitate scheduling only a subset of UEs for updates in each iteration, and because the wireless medium is shared, transmissions are susceptible to interference and are not assured. The article discusses the significance of Machine Learning in wireless communication and highlights Federated Learning (FL) as a novel approach that could play a vital role in future mobile networks, particularly 6G and beyond.
    
[^10]: 企业协作系统的事件抽象以支持社会流程挖掘

    Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining. (arXiv:2308.04396v1 [cs.LG])

    [http://arxiv.org/abs/2308.04396](http://arxiv.org/abs/2308.04396)

    本论文提出了一种定制的企业协作系统的事件抽象方法，通过比较实际用户活动和系统生成的低级别跟踪来训练模型，并将低级别跟踪转换为抽象的高级别日志，以支持社会流程挖掘。

    

    流程挖掘的一个目标是从信息系统的事件日志中发现流程模型。流程挖掘已成功应用于面向流程的企业系统，但对于面向通信和文档的企业协作系统（ECS）来说不太适用。ECS事件日志非常细粒度，对其日志应用流程挖掘会导致混乱的模型。一个常见的解决方案是事件抽象，即在运行发现算法之前将低级别日志转换为更抽象的高级别日志。迄今为止，既有的事件抽象方法尚未完全解决ECS日志的特殊特征。我们旨在通过定制的ECS事件抽象（ECSEA）方法来弥补这一差距，该方法通过比较记录的实际用户活动（高级别跟踪）与系统生成的低级别跟踪（从ECS中提取）来训练模型。该模型使我们能够自动将未来的低级别跟踪转换为抽象的高级别日志。

    One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can 
    
[^11]: 基于数据增强的医学图像无监督领域适应

    Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging. (arXiv:2308.04395v1 [eess.IV])

    [http://arxiv.org/abs/2308.04395](http://arxiv.org/abs/2308.04395)

    本论文提出了一种基于数据增强的医学图像无监督领域适应方法，在大脑MRI分割任务中显示出高准确性、广泛适用性和对抗领域偏移的鲁棒性，超过现有技术的性能。

    

    基于深度学习的医学图像模型经常在新的扫描中难以有效推广，这是由于硬件、采集参数、人群和伪影引起的数据异质性。这个限制在临床实践中应用机器学习模型时带来了重大挑战。我们提出了一种基于MRI特定增强技术的大脑MRI分割的无监督领域适应方法。为了评估我们方法的有效性，我们在不同的数据集、模态和分割任务上进行了广泛的实验，并与最先进的方法进行了比较。结果表明，我们提出的方法在大多数情况下都能取得高精度，具有广泛的适用性，并且在各种任务中都展现出了显著的对抗领域偏移的鲁棒性，超过了现有技术的性能。

    Deep learning-based models in medical imaging often struggle to generalize effectively to new scans due to data heterogeneity arising from differences in hardware, acquisition parameters, population, and artifacts. This limitation presents a significant challenge in adopting machine learning models for clinical practice. We propose an unsupervised method for robust domain adaptation in brain MRI segmentation by leveraging MRI-specific augmentation techniques. To evaluate the effectiveness of our method, we conduct extensive experiments across diverse datasets, modalities, and segmentation tasks, comparing against the state-of-the-art methods. The results show that our proposed approach achieves high accuracy, exhibits broad applicability, and showcases remarkable robustness against domain shift in various tasks, surpassing the state-of-the-art performance in the majority of cases.
    
[^12]: 理解因果解释对于人工智能与人类协作临床决策中信任和依赖的影响

    Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making. (arXiv:2308.04375v1 [cs.HC])

    [http://arxiv.org/abs/2308.04375](http://arxiv.org/abs/2308.04375)

    本研究利用因果解释方法帮助人类分析审查人工智能建议，减少对人工智能的过度依赖，提高了临床决策的质量和表现。

    

    人工智能（AI）越来越被考虑用于辅助高风险领域（如健康）中的人类决策。然而，研究人员讨论了一个问题，即人类可能会过度依赖错误的AI模型建议，而非实现人工智能与人类的互补性能。在这项工作中，我们利用显著特征解释和假设性因果解释，使人类能更分析地审查AI建议，以减少对AI的过度依赖，并探讨这些解释对临床决策中的信任和依赖的影响。我们在七位治疗师和十位非专业人士中进行了一项实验，任务是评估中风后幸存者的运动质量，并分析了他们的表现、任务上的一致性水平以及在无解释和有两种AI解释的情况下对AI的依赖。结果显示，具有显著特征和因果解释的AI模型帮助治疗师和非专业人士改善了他们的表现。

    Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their 
    
[^13]: Pelta：用于缓解联邦学习中逃避攻击的变压器保护机制

    Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning. (arXiv:2308.04373v1 [cs.LG])

    [http://arxiv.org/abs/2308.04373](http://arxiv.org/abs/2308.04373)

    Pelta是一种新颖的联邦学习机制，利用可信硬件的能力来保护模型免受恶意探测攻击。它遮蔽了反向传播的部分链规则，提供更高的安全性。

    

    联邦学习的主要前提是机器学习模型的更新是在本地计算的，以保护用户数据的隐私，因为这些数据不会离开设备的范围。然而，如果没有适当的防御措施，受 compromise 的客户端可以轻易地在其本地内存中探测模型，寻找对抗样本。为了缓解这种恶意探测，我们引入了一种新颖的 Pelta 护盾机制，利用可信硬件的能力。通过利用可信执行环境 (TEE) 的能力，Pelta 遮蔽了反向传播的部分链规则，这通常是攻击者利用的要点。

    The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers fo
    
[^14]: SLEM：机器学习用于路径建模和因果推断的超级学习者方程模型

    SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])

    [http://arxiv.org/abs/2308.04365](http://arxiv.org/abs/2308.04365)

    SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。

    

    因果推断是科学的关键目标，使研究人员能够通过观察数据得出关于对假定干预的预测的有意义的结论。路径模型、结构方程模型(SEMs)以及更一般的有向无环图(DAGs)能够明确地指定关于现象背后的因果结构的假设。与DAGs不同，SEMs假设线性关系，这可能导致函数错误规范，从而阻碍研究人员进行可靠的效果大小估计。相反，我们提出了超级学习者方程模型（SLEM），一种集成了机器学习超级学习者集成的路径建模技术。我们通过实证研究，证明了SLEM能够提供一致且无偏的因果效应估计，在与SEMs进行线性模型比较时表现出竞争力，并且在处理非线性关系时优于SEMs。

    Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
    
[^15]: 准确、可解释和私密的模型：在最小化训练数据泄漏的同时提供追索权

    Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage. (arXiv:2308.04341v1 [cs.LG])

    [http://arxiv.org/abs/2308.04341](http://arxiv.org/abs/2308.04341)

    本研究提出了两种新颖的方法来生成差分隐私追索权：差分隐私模型（DPM）和拉普拉斯追索权（LR）。在逻辑回归分类器和真实世界合成数据集的实验中发现，DPM和LR在减少攻击者可以推断的信息方面表现良好，特别是在低误报率下。当训练数据集足够大时，我们的新颖LR方法成功地防止了隐私泄漏。

    

    机器学习模型在影响深远的领域越来越多地被用于预测个体结果。因此，许多模型为收到负面结果的个体提供了算法追索权。然而，追索权可以被攻击者利用来披露私人信息。本文首次尝试缓解此类攻击。我们提出了两种新颖的方法来生成差分隐私追索权：差分隐私模型（DPM）和拉普拉斯追索权（LR）。使用逻辑回归分类器和真实世界和合成数据集，我们发现DPM和LR在减少攻击者可以推断的信息方面表现良好，特别是在低FPR下。当训练数据集的大小足够大时，我们发现我们的新颖LR方法在保持模型和追索准确性的同时成功地防止了隐私泄漏。

    Machine learning models are increasingly utilized across impactful domains to predict individual outcomes. As such, many models provide algorithmic recourse to individuals who receive negative outcomes. However, recourse can be leveraged by adversaries to disclose private information. This work presents the first attempt at mitigating such attacks. We present two novel methods to generate differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR). Using logistic regression classifiers and real world and synthetic datasets, we find that DPM and LR perform well in reducing what an adversary can infer, especially at low FPR. When training dataset size is large enough, we find particular success in preventing privacy leakage while maintaining model and recourse accuracy with our novel LR method.
    
[^16]: RLHF-Blender: 可配置的与人类反馈交互学习的界面

    RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback. (arXiv:2308.04332v1 [cs.LG])

    [http://arxiv.org/abs/2308.04332](http://arxiv.org/abs/2308.04332)

    RLHF-Blender是一个可配置的、互动的界面，用于从多种人类反馈中学习，研究人员可以系统地探索不同类型的反馈以及人类因素对奖励学习的影响。

    

    在实际应用中使用强化学习从人类反馈中学习（RLHF）是至关重要的，关键是通过多种人类反馈源学习奖励模型，并考虑涉及不同类型反馈的人类因素。然而，由于研究人员缺乏标准化的工具，对从不同类型反馈中学习的系统性研究受到阻碍。为此，我们提出了RLHF-Blender，一个可配置的、互动的用于从人类反馈中学习的界面。RLHF-Blender提供了一个模块化的实验框架和实现，使研究人员能够系统地研究人类反馈对奖励学习的特性和质量。该系统促进了各种反馈类型的探索，包括演示、排序、比较和自然语言指令，并考虑了人类因素对其有效性的影响。我们讨论了RLHF-Blender所实现的一系列具体研究机会。

    To use reinforcement learning from human feedback (RLHF) in practical applications, it is crucial to learn reward models from diverse sources of human feedback and to consider human factors involved in providing feedback of different types. However, the systematic study of learning from diverse types of feedback is held back by limited standardized tooling available to researchers. To bridge this gap, we propose RLHF-Blender, a configurable, interactive interface for learning from human feedback. RLHF-Blender provides a modular experimentation framework and implementation that enables researchers to systematically investigate the properties and qualities of human feedback for reward learning. The system facilitates the exploration of various feedback types, including demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness. We discuss a set of concrete research opportunities enabled by RL
    
[^17]: 合作式多智能体赌博机：具有最佳个体遗憾和恒定通信成本的分布式算法

    Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs. (arXiv:2308.04314v1 [cs.LG])

    [http://arxiv.org/abs/2308.04314](http://arxiv.org/abs/2308.04314)

    本文提出了一种新的合作赌博机算法，实现了最佳的个体遗憾和恒定的通信成本。

    

    最近，对合作式多智能体多臂赌博机进行了广泛研究，其中一组分布式智能体合作玩相同的多臂赌博游戏。目标是开发具有最佳群体和个体遗憾以及智能体之间通信成本低的赌博机算法。在前期工作中，使用了两种范式来解决这个问题：领导者-跟随者和完全分布式算法。在这两种范式中，以前的算法都能达到最佳群体遗憾。领导者-跟随者算法实现了恒定的通信成本，但未能达到最佳个体遗憾。目前最先进的完全分布式算法实现了最佳个体遗憾，但未能实现恒定的通信成本。本文提出了一种简单而有效的通信策略，并将其整合到合作赌博机的学习算法中。我们的算法同时实现了两种范式的最优个体遗憾和恒定通信成本。

    Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.
    
[^18]: 在语义通信系统中的模型反演窃听攻击

    The Model Inversion Eavesdropping Attack in Semantic Communication Systems. (arXiv:2308.04304v1 [cs.IT])

    [http://arxiv.org/abs/2308.04304](http://arxiv.org/abs/2308.04304)

    本文介绍了在语义通信系统中的模型反演窃听攻击（MIEA），通过窃听和模型反演来重构原始消息，研究发现MIEA在不同信道条件下能够成功地重构出具有良好质量的原始消息。为了实现安全的语义通信，提出了一种基于随机置换和替换的防御方法。

    

    近年来，由于其通信效率的优势，语义通信一直是一个热门研究课题。由于语义通信依赖于深度学习从原始消息中提取含义，因此它容易受到针对深度学习模型的攻击。本文介绍了一种模型反演窃听攻击（MIEA），以揭示语义通信系统中隐私泄露的风险。在MIEA中，攻击者首先窃听语义通信系统传输的信号，然后进行模型反演攻击以重构原始消息，同时考虑了白盒和黑盒设置。评估结果表明，在不同的信道条件下，MIEA可以成功地重构出具有良好质量的原始消息。然后，我们提出了一种基于随机置换和替换的防御方法，以抵御MIEA，实现安全的语义通信。我们的实验结果证明了该方法的有效性。

    In recent years, semantic communication has been a popular research topic for its superiority in communication efficiency. As semantic communication relies on deep learning to extract meaning from raw messages, it is vulnerable to attacks targeting deep learning models. In this paper, we introduce the model inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in the semantic communication system. In MIEA, the attacker first eavesdrops the signal being transmitted by the semantic communication system and then performs model inversion attack to reconstruct the raw message, where both the white-box and black-box settings are considered. Evaluation results show that MIEA can successfully reconstruct the raw message with good quality under different channel conditions. We then propose a defense method based on random permutation and substitution to defend against MIEA in order to achieve secure semantic communication. Our experimental results demonstrate the effectivene
    
[^19]: wav2vec 2.0特征提取器的比较分析

    Comparative Analysis of the wav2vec 2.0 Feature Extractor. (arXiv:2308.04286v1 [eess.AS])

    [http://arxiv.org/abs/2308.04286](http://arxiv.org/abs/2308.04286)

    本研究比较了wav2vec 2.0模型的特征提取器与传统特征提取方法在连接主义时间分类ASR模型上的表现，发现两者在LibriSpeech基准测试上具有竞争力。通过分析学习到的滤波器，发现ASR系统最重要的信息是通过一组带通滤波器获得的。

    

    自动语音识别（ASR）系统通常使用手工设计的特征提取流程。为了避免它们固有的信息损失，并实现从语音到转录文本的更一致的建模，神经原始波形特征提取器（FEs）是一种有吸引力的方法。最近广受欢迎的wav2vec 2.0模型也使用了卷积FE，直接对语音波形进行操作。然而，它在文献中研究得还不够充分。本研究中，我们研究了它在连接主义时间分类（CTC）ASR模型中替代标准特征提取方法的能力，并将其与另一种替代性神经FE进行了比较。我们表明，在LibriSpeech基准测试中，两者都与传统的FEs竞争力不相上下，并分析了各个组件的影响。此外，我们还分析了学习到的滤波器，并显示ASR系统的最重要信息是通过一组带通滤波器获得的。

    Automatic speech recognition (ASR) systems typically use handcrafted feature extraction pipelines. To avoid their inherent information loss and to achieve more consistent modeling from speech to transcribed text, neural raw waveform feature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model, which has recently gained large popularity, uses a convolutional FE which operates directly on the speech waveform. However, it is not yet studied extensively in the literature. In this work, we study its capability to replace the standard feature extraction methods in a connectionist temporal classification (CTC) ASR model and compare it to an alternative neural FE. We show that both are competitive with traditional FEs on the LibriSpeech benchmark and analyze the effect of the individual components. Furthermore, we analyze the learned filters and show that the most important information for the ASR system is obtained by a set of bandpass filters.
    
[^20]: 在微调之前与纯净语言模型对话进行上下文对齐

    In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning. (arXiv:2308.04275v1 [cs.CL])

    [http://arxiv.org/abs/2308.04275](http://arxiv.org/abs/2308.04275)

    本文提出了一种在微调之前与纯净语言模型进行对话的方法，通过上下文学习实现了推理时的对齐。实验证明，这种方法将纯净语言模型的胜率提高了7倍，使其可以与通过对齐微调的强基准模型媲美。

    

    在这个说明中，我们通过上下文学习来探索推理时的对齐。我们考虑了一个纯净的预训练语言模型 Llama-2，在进行任何微调之前，当模型被要求按照聊天式的指令进行操作时，我们检索到了平均9个对齐演示示例。与直接提示相比，不改变模型权重的上下文对齐导致了与OpenAI的text-davinci-003模型相比，胜率提高了7倍，使得纯净语言模型可以媲美通过对齐微调的强基准模型。

    In this note, we explore inference-time alignment through in-context learning. We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions. Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning.
    
[^21]: 知识蒸馏的师生架构：综述

    Teacher-Student Architecture for Knowledge Distillation: A Survey. (arXiv:2308.04268v1 [cs.LG])

    [http://arxiv.org/abs/2308.04268](http://arxiv.org/abs/2308.04268)

    本文综述了知识蒸馏的师生架构，在多个蒸馏目标领域中取得了有效并广泛的应用，包括知识压缩、知识扩展、知识适应和知识增强，通过轻量化和通用化的学生网络实现多个蒸馏目标。

    

    尽管深度神经网络（DNN）在许多领域的大规模问题中展现出强大的解决能力，但由于参数庞大，这种DNN很难应用于现实世界的系统中。为解决这个问题，提出了师生架构，其中简单的学生网络只有少量参数，却能达到与拥有许多参数的深度师傅网络相当的性能。最近，师生架构已被广泛应用于知识蒸馏的多个目标领域，包括知识压缩、知识扩展、知识适应和知识增强。借助师生架构，目前的研究能够通过轻量化和通用化的学生网络实现多个蒸馏目标。与现有的主要关注知识压缩的蒸馏调查不同，本调查首次探讨了跨多个蒸馏目标的师生架构。

    Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. This surv
    
[^22]: BarlowRL: Barlow Twins用于数据效率强化学习

    BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning. (arXiv:2308.04263v1 [cs.LG])

    [http://arxiv.org/abs/2308.04263](http://arxiv.org/abs/2308.04263)

    BarlowRL通过将Barlow Twins和DER相结合，实现了数据效率强化学习，并在Atari 100k基准测试上优于其他算法。它通过信息扩散避免了维度折叠，使得RL算法能够利用均匀分布的状态表示，从而实现卓越的性能。

    

    本文介绍了BarlowRL，一种将Barlow Twins自监督学习框架与DER（Data-Efficient Rainbow）算法相结合的数据效率强化学习代理。BarlowRL在Atari 100k基准测试中优于DER和对比算法CURL。BarlowRL通过确保信息扩散到整个空间来避免维度折叠。这有助于RL算法利用均匀分布的状态表示，最终实现卓越的性能。Barlow Twins与DER的整合增强了数据效率，并在RL任务中实现了卓越的性能。BarlowRL展示了将自监督学习技术纳入强化学习算法以提高性能的潜力。

    This paper introduces BarlowRL, a data-efficient reinforcement learning agent that combines the Barlow Twins self-supervised learning framework with DER (Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its contrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids dimensional collapse by enforcing information spread to the whole space. This helps RL algorithms to utilize uniformly spread state representation that eventually results in a remarkable performance. The integration of Barlow Twins with DER enhances data efficiency and achieves superior performance in the RL tasks. BarlowRL demonstrates the potential of incorporating self-supervised learning techniques to improve RL algorithms.
    
[^23]: SDLFormer: 一种稀疏和密集增强的Transformer用于加速MR图像重构

    SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction. (arXiv:2308.04262v1 [eess.IV])

    [http://arxiv.org/abs/2308.04262](http://arxiv.org/abs/2308.04262)

    提出了一种窗口式的transformer网络，该网络通过整合扩张注意机制和卷积，用于加速MRI图像重建，并通过增强远处邻域像素关系和学习低级平移不变特征来提高重建质量。

    

    随着transformer的出现，它们已成为卷积神经网络的可行替代方案，因为它们能够学习空间域中的非局部区域关系。transformer的自注意机制使其能捕捉图像中的长距离依赖关系，这对于加速MRI图像重建是有益的，因为欠采样的影响在图像域中是非局部的。尽管窗口式transformer具有计算效率，但由于依赖关系限于图像窗口的范围，因此其感受野受限。我们提出了一种基于窗口的transformer网络，该网络整合了扩张注意机制和卷积，用于加速MRI图像重建。所提出的网络由扩张和密集邻域注意transformer组成，以增强远处邻域像素关系，并在transformer模块内引入深度卷积，以学习低级平移不变特征。

    Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant f
    
[^24]: 使用PaSST和大规模音频字幕数据集推进基于自然语言的音频检索

    Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets. (arXiv:2308.04258v1 [eess.AS])

    [http://arxiv.org/abs/2308.04258](http://arxiv.org/abs/2308.04258)

    本研究提出了一个基于预训练转换器的文本到音频检索系统，通过在共享空间中映射音频和文字描述来提高检索性能，其中自注意力的音频编码器和额外的人工生成和合成数据集是关键组件，取得了在DCASE挑战中的第一名，并在ClothoV2基准测试中超过当前最先进方法5.6个百分点。

    

    本研究提出了一种基于预训练文本和频谱图转换器的文本到音频检索系统。我们的方法将录音和文字描述映射到共享的音频字幕空间中，使得不同模态的相关示例靠近。通过系统分析，我们研究了系统的每个组件对检索性能的影响。结果表明，我们确认了两个关键组件在提高性能方面起到了至关重要的作用：基于自注意力的音频编码器用于音频嵌入和利用额外的人工生成和合成数据集进行预训练。我们进一步尝试通过添加可用关键字来增加ClothoV2字幕的多样性，但这只带来了较小的改进。我们的系统在2023年DCASE挑战中名列第一，并且在ClothoV2基准测试中的平均准确率（mAP@10）较当前最先进方法提升了5.6个百分点。

    This work presents a text-to-audio-retrieval system based on pre-trained text and spectrogram transformers. Our method projects recordings and textual descriptions into a shared audio-caption space in which related examples from different modalities are close. Through a systematic analysis, we examine how each component of the system influences retrieval performance. As a result, we identify two key components that play a crucial role in driving performance: the self-attention-based audio encoder for audio embedding and the utilization of additional human-generated and synthetic data sets during pre-training. We further experimented with augmenting ClothoV2 captions with available keywords to increase their variety; however, this only led to marginal improvements. Our system ranked first in the 2023's DCASE Challenge, and it outperforms the current state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.
    
[^25]: 基于符合预测的可靠不确定性量化的无线通道联合推理

    Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction. (arXiv:2308.04237v1 [cs.IT])

    [http://arxiv.org/abs/2308.04237](http://arxiv.org/abs/2308.04237)

    本论文提出了一种基于联合符合预测的无线通道联合推理方法，通过设备到服务器的通信提高了服务器的推理决策的可靠性和准确性。

    

    在设备和服务器共享预训练模型的设置中，服务器希望根据模型对新输入进行推理。设备可以通过共同的无线信道与服务器通信，并且可以访问以前未用于训练的数据。如果设备无法访问新输入，设备到服务器的通信是否可以提高服务器的推理决策质量？最近的研究引入了联合符合预测（CP），利用设备到服务器的通信来提高服务器决策的可靠性。在联合CP中，设备向服务器传递关于本地数据上共享的预训练模型损失的信息，服务器利用这些信息来校准一个决策区间，以便其在预定义的目标可靠性水平下保证包含正确答案。

    Consider a setting in which devices and a server share a pre-trained model. The server wishes to make an inference on a new input given the model. Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel. If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server? Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a 
    
[^26]: OpinionConv: 通过基于真实主观体验的观点实现对话式产品搜索

    OpinionConv: Conversational Product Search with Grounded Opinions. (arXiv:2308.04226v1 [cs.HC])

    [http://arxiv.org/abs/2308.04226](http://arxiv.org/abs/2308.04226)

    OpinionConv是第一个用于模拟销售对话的对话式AI，通过利用产品评论作为观点的丰富来源，实现了对话和决策中的真实性和信息基础。

    

    在搜索产品时，他人的观点在做出明智决策方面起着重要作用。对产品的主观体验可以是有价值的信息来源。这在销售对话中也是如此，在这种对话中，客户和销售助手交换有关产品的事实和观点。然而，训练一个用于此类对话的AI是复杂的，因为语言模型由于缺乏真实世界的经验没有真实的观点。我们通过利用产品评论作为产品观点的丰富来源来解决这个问题，以真实主观叙述支持对话式AI。通过OpinionConv，我们开发了第一个模拟销售对话的对话式AI。为了验证生成的对话，我们进行了多个用户研究，结果显示生成的观点被认为是真实的。我们的评估员也确认了观点对于决策的信息基础的重要性。

    When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.
    
[^27]: 对GNN模型基于图Attention的解释的语义解释和验证

    Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models. (arXiv:2308.04220v1 [cs.LG])

    [http://arxiv.org/abs/2308.04220](http://arxiv.org/abs/2308.04220)

    本论文提出了一种方法来在GNN模型中增强可解释性，通过引入语义关注和建立特征重要性权重与模型准确性之间的相关性。这对于图深度学习任务具有重要意义。

    

    在这项工作中，我们提出了一种方法来研究在图神经网络（GNN）模型中应用语义关注以增强可解释性，引入语义信息的扰动，并建立预测特征重要性权重与模型准确性之间的相关性。图深度学习（GDL）已经成为一种应用于场景解释等任务的有前途的领域，利用灵活的图结构来简洁地描述复杂的特征和关系。由于传统的解释性AI（XAI）中使用的解释方法不能直接应用于这种结构，因此引入了图特定的方法。注意力机制在估计深度学习模型中输入特征的重要性方面表现出了很好的效果，因此先前已经使用它们为GNN预测提供基于特征的解释。基于这些见解，我们扩展了现有的基于注意力的图解释方法，研究了使用语义信息的图Attention方法。

    In this work, we propose a methodology for investigating the application of semantic attention to enhance the explainability of Graph Neural Network (GNN)-based models, introducing semantically-informed perturbations and establishing a correlation between predicted feature-importance weights and model accuracy. Graph Deep Learning (GDL) has emerged as a promising field for tasks like scene interpretation, leveraging flexible graph structures to concisely describe complex features and relationships. As traditional explainability methods used in eXplainable AI (XAI) cannot be directly applied to such structures, graph-specific approaches are introduced. Attention mechanisms have demonstrated their efficacy in estimating the importance of input features in deep learning models and thus have been previously employed to provide feature-based explanations for GNN predictions. Building upon these insights, we extend existing attention-based graph-explainability methods investigating the use o
    
[^28]: 迭代式草图用于安全编码回归

    Iterative Sketching for Secure Coded Regression. (arXiv:2308.04185v1 [cs.IT])

    [http://arxiv.org/abs/2308.04185](http://arxiv.org/abs/2308.04185)

    这篇论文提出了一种迭代草图方法，用于加速分布式线性回归计算并确保安全性。通过利用随机草图技术和改进异步系统中的块效应韧性，将信息保护与回归问题维度的减小相结合。特别是，通过应用随机正交矩阵和子采样"块"，实现了在每次迭代中考虑新草图的分布式迭代草图方法。同时，对子采样随机哈达玛变换进行了推广并修改以保证数据的安全性。

    

    在这项工作中，我们提出了一种加速线性回归分布式计算并确保安全性的方法。我们利用随机草图技术，并改善了异步系统中的块效应韧性。具体而言，我们应用了一个随机正交矩阵，然后对"块"进行子采样，以同时保护信息并减小回归问题的维数。在我们的设置中，这个转换对应于"近似梯度编码方案"中的编码加密，而子采样对应于非散乱工作节点的响应；在一个集中式编码计算网络中。这导致了一种分布式的"迭代草图"方法，用于$\ell_2$-子空间嵌入，即在每次迭代中考虑一个新的草图。我们还专注于"子采样随机哈达玛变换"的特殊情况，将其推广为块采样，并讨论了如何修改该方法以确保数据的安全。

    In this work, we propose methods for speeding up linear regression distributively, while ensuring security. We leverage randomized sketching techniques, and improve straggler resilience in asynchronous systems. Specifically, we apply a random orthonormal matrix and then subsample \textit{blocks}, to simultaneously secure the information and reduce the dimension of the regression problem. In our setup, the transformation corresponds to an encoded encryption in an \textit{approximate gradient coding scheme}, and the subsampling corresponds to the responses of the non-straggling workers; in a centralized coded computing network. This results in a distributive \textit{iterative sketching} approach for an $\ell_2$-subspace embedding, \textit{i.e.} a new sketch is considered at each iteration. We also focus on the special case of the \textit{Subsampled Randomized Hadamard Transform}, which we generalize to block sampling; and discuss how it can be modified in order to secure the data.
    
[^29]: 通过不同视角研究社交不可接受言论分类（SUD）：“我们是否在同一页上？”

    Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: "Are we on the same page ?". (arXiv:2308.04180v1 [cs.CL])

    [http://arxiv.org/abs/2308.04180](http://arxiv.org/abs/2308.04180)

    本研究通过不同的视角研究在线文本中的社交不可接受言论（SUD）分类和检测，并建立了一个新颖的语料库。通过分析不同背景下的SUD分类器的泛化能力以及注释模态对SUD学习的影响，我们提出了一些开放的挑战和研究方向，并提供了有助于领域专家在注释任务中的数据洞察。

    

    我们研究在线文本中社交不可接受言论（SUD）的特征和检测。我们首先构建并展示了一个新颖的语料库，其中包含了来自不同在线来源的大量手工注释文本，这些文本在现有的最先进的机器学习（ML）SUD检测解决方案中使用。这种全局背景使我们可以测试获取关于相同SUD类别的知识的SUD分类器的泛化能力，但来自不同背景的知识。从这个角度出发，我们可以通过讨论开放的挑战和开放的研究方向来分析注释模态可能对SUD学习的影响。我们还提供了一些数据洞察，可以支持领域专家在注释任务中。

    We study Socially Unacceptable Discourse (SUD) characterization and detection in online text. We first build and present a novel corpus that contains a large variety of manually annotated texts from different online sources used so far in state-of-the-art Machine learning (ML) SUD detection solutions. This global context allows us to test the generalization ability of SUD classifiers that acquire knowledge around the same SUD categories, but from different contexts. From this perspective, we can analyze how (possibly) different annotation modalities influence SUD learning by discussing open challenges and open research directions. We also provide several data insights which can support domain experts in the annotation task.
    
[^30]: 双输入神经网络用于声源定位

    Dual input neural networks for positional sound source localization. (arXiv:2308.04169v1 [cs.SD])

    [http://arxiv.org/abs/2308.04169](http://arxiv.org/abs/2308.04169)

    双输入神经网络（DI-NN）是一种简单有效的方法，用于声源定位算法中的音频信号和场景声学属性的建模。实验结果显示，DI-NN相比于经典方法和其他神经网络架构具有更低的定位误差。

    

    在许多信号处理应用中，元数据可以有利地与高维信号结合使用，以产生所需的输出。在经典的声源定位算法中，将多个分布式麦克风接收到的高维多通道音频信号的信息与描述场景声学特性（如麦克风在空间中的坐标）的信息相结合，以估计声源的位置。我们介绍了双输入神经网络（DI-NNs）作为在神经网络中建模这两种数据类型的简单有效的方法。我们在不同难度和真实性的场景上训练和评估了我们提出的DI-NN，并将其与另一种架构、经典最小二乘（LS）方法以及经典卷积循环神经网络（CRNN）进行了比较。我们的结果表明，DI-NN明显优于基准算法，定位误差比LS方法低五倍。

    In many signal processing applications, metadata may be advantageously used in conjunction with a high dimensional signal to produce a desired output. In the case of classical Sound Source Localization (SSL) algorithms, information from a high dimensional, multichannel audio signals received by many distributed microphones is combined with information describing acoustic properties of the scene, such as the microphones' coordinates in space, to estimate the position of a sound source. We introduce Dual Input Neural Networks (DI-NNs) as a simple and effective way to model these two data types in a neural network. We train and evaluate our proposed DI-NN on scenarios of varying difficulty and realism and compare it against an alternative architecture, a classical Least-Squares (LS) method as well as a classical Convolutional Recurrent Neural Network (CRNN). Our results show that the DI-NN significantly outperforms the baselines, achieving a five times lower localization error than the LS
    
[^31]: 深度学习分类器性能的综合评估揭示出惊人的缺乏稳定性

    Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness. (arXiv:2308.04137v1 [cs.LG])

    [http://arxiv.org/abs/2308.04137](http://arxiv.org/abs/2308.04137)

    通过综合评估深度学习分类器的性能，发现它们缺乏稳定性和可靠性，并建议采用广泛的数据类型和统一的评估指标进行性能基准测试。

    

    可靠而稳健的评估方法是开发本身稳健可靠的机器学习模型的必要第一步。然而，目前用于评估分类器的常规评估协议在综合评估性能方面存在不足，因为它们往往依赖于有限类型的测试数据，忽视其他类型的数据。例如，使用标准测试数据无法评估分类器对于未经训练的类别样本的预测。另一方面，使用包含未知类别样本的数据进行测试无法评估分类器对于已知类别标签的预测能力。本文提倡使用各种不同类型的数据进行性能基准测试，并使用一种可应用于所有这些数据类型的单一指标，以产生一致的性能评估结果。通过这样的基准测试发现，目前的深度神经网络，包括使用认为是全面的方法进行训练的网络，也存在缺乏稳定性的问题。

    Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to pro
    
[^32]: OmniDataComposer: 用于多模态数据融合和无限数据生成的统一数据结构

    OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation. (arXiv:2308.04126v1 [cs.CV])

    [http://arxiv.org/abs/2308.04126](http://arxiv.org/abs/2308.04126)

    OmniDataComposer是一种创新的多模态数据融合和无限数据生成方法，通过引入一个有效的协调数据结构，可以处理和合并视频、音频和文本等多模态数据输入，并实现跨模态数据校正。

    

    本论文提出了OmniDataComposer，一种创新的多模态数据融合和无限数据生成方法，旨在改善和简化不同数据模态之间的相互作用。最核心的突破是引入了一种有效处理和合并多模态数据输入的协调数据结构，包括视频、音频和文本。我们设计的算法利用了视频/图像字幕提取、密集字幕提取、自动语音识别（ASR）、光学字符识别（OCR）、Recognize Anything Model（RAM）和物体跟踪等多种操作的进展。OmniDataComposer能够识别超过6400种对象类别，显著扩大了视觉信息的范围。它将这些多样的模态融合在一起，促进模态之间的相互增强，并促进跨模态数据校正。最终输出将每个视频输入转化为详细的顺序文档。

    This paper presents OmniDataComposer, an innovative approach for multimodal data fusion and unlimited data generation with an intent to refine and uncomplicate interplay among diverse data modalities. Coming to the core breakthrough, it introduces a cohesive data structure proficient in processing and merging multimodal data inputs, which include video, audio, and text. Our crafted algorithm leverages advancements across multiple operations such as video/image caption extraction, dense caption extraction, Automatic Speech Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything Model(RAM), and object tracking. OmniDataComposer is capable of identifying over 6400 categories of objects, substantially broadening the spectrum of visual information. It amalgamates these diverse modalities, promoting reciprocal enhancement among modalities and facilitating cross-modal data correction. \textbf{The final output metamorphoses each video input into an elaborate sequential docum
    
[^33]: 使用深度学习构建定制热力学

    Constructing Custom Thermodynamics Using Deep Learning. (arXiv:2308.04119v1 [cond-mat.soft])

    [http://arxiv.org/abs/2308.04119](http://arxiv.org/abs/2308.04119)

    本文使用深度学习构建了一个基于广义Onsager原理的平台，可以从微观轨迹的观察中学习任意随机耗散系统的宏观动力学描述。

    

    人工智能的一个令人兴奋的应用是基于先前积累的数据以及已知的物理原理（包括对称性和守恒定律）提供的限制，进行自动科学发现。这样的自动假设创建和验证可以帮助科学家研究复杂的现象，传统的物理直觉可能无法应对。尤其重要的是复杂的动态系统，其时间演变受到变化的外部参数的强烈影响。在本文中，我们开发了一个基于广义Onsager原理的平台，从微观轨迹的观察中直接学习任意随机耗散系统的宏观动力学描述。我们专注于那些微观描述完整不切实际、构建理论宏观模型需要广泛领域知识或试错的系统。我们的机器学习方法通过模拟来解决这个问题。

    One of the most exciting applications of AI is automated scientific discovery based on previously amassed data, coupled with restrictions provided by the known physical principles, including symmetries and conservation laws. Such automated hypothesis creation and verification can assist scientists in studying complex phenomena, where traditional physical intuition may fail. Of particular importance are complex dynamic systems where their time evolution is strongly influenced by varying external parameters. In this paper we develop a platform based on a generalised Onsager principle to learn macroscopic dynamical descriptions of arbitrary stochastic dissipative systems directly from observations of their microscopic trajectories. We focus on systems whose complexity and sheer sizes render complete microscopic description impractical, and constructing theoretical macroscopic models requires extensive domain knowledge or trial-and-error. Our machine learning approach addresses this by sim
    
[^34]: 深度神经网络架构的异步进化

    Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v1 [cs.NE])

    [http://arxiv.org/abs/2308.04102](http://arxiv.org/abs/2308.04102)

    本文提出了一种通用的异步评估策略，用于增加进化神经网络架构搜索的吞吐量。该策略维护一个个体队列，并在适当数量的个体被评估后立即进入下一代，平衡多样性和效率。

    

    许多进化算法(EAs)利用候选解的并行评估。然而，如果评估时间差异很大，许多工作节点(即计算客户端)大部分时间都处于闲置状态，等待下一代的创建。进化神经网络架构搜索(ENAS)是一类优化深度神经网络架构和超参数的EA，特别容易受到这个问题的影响。本文提出了一种通用的异步评估策略(AES)，然后将其适配到ENAS上。AES通过维护一个多达$K$个个体的队列，这些个体已准备好被发送到工作器进行评估，并在由工作器评估了$M<<K$个个体之后立即进入下一代。合适的$M$值是通过实验确定的，平衡多样性和效率。为了展示AES的普适性和能力，首先在11位多路复用器设计(一个单个种群可验证的发现任务)上进行了评估。

    Many evolutionary algorithms (EAs) take advantage of parallel evaluation of candidates. However, if evaluation times vary significantly, many worker nodes (i.e.,\ compute clients) are idle much of the time, waiting for the next generation to be created. Evolutionary neural architecture search (ENAS), a class of EAs that optimizes the architecture and hyperparameters of deep neural networks, is particularly vulnerable to this issue. This paper proposes a generic asynchronous evaluation strategy (AES) that is then adapted to work with ENAS. AES increases throughput by maintaining a queue of upto $K$ individuals ready to be sent to the workers for evaluation and proceeding to the next generation as soon as $M<<K$ individuals have been evaluated by the workers. A suitable value for $M$ is determined experimentally, balancing diversity and efficiency. To showcase the generality and power of AES, it was first evaluated in 11-bit multiplexer design (a single-population verifiable discovery ta
    
[^35]: 使用QUARK的面向应用的量子生成学习基准测试

    Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK. (arXiv:2308.04082v1 [quant-ph])

    [http://arxiv.org/abs/2308.04082](http://arxiv.org/abs/2308.04082)

    提出扩展QUARK框架以评估量子生成模型的训练和部署能力，并通过多个示例应用展示了其灵活性和泛化能力评估。

    

    量子机器学习（QML）算法的基准测试面临着复杂性和可变性的挑战，例如模型假设、数据集、训练技术和超参数选择。QUARK框架简化和标准化了量子计算应用的基准测试研究。在这里，我们提出了几个扩展QUARK的方法，以包括评估量子生成模型的训练和部署能力。我们描述了更新后的软件架构，并通过几个示例应用说明了其灵活性：（1）我们使用多种电路假设、数据集和数据转换训练了不同的量子生成模型。（2）我们在GPU和真实的量子硬件上评估了我们的模型。（3）我们利用一系列评估指标评估了我们生成模型的泛化能力，例如生成数据的新颖性和有效性。

    Benchmarking of quantum machine learning (QML) algorithms is challenging due to the complexity and variability of QML systems, e.g., regarding model ansatzes, data sets, training techniques, and hyper-parameters selection. The QUantum computing Application benchmaRK (QUARK) framework simplifies and standardizes benchmarking studies for quantum computing applications. Here, we propose several extensions of QUARK to include the ability to evaluate the training and deployment of quantum generative models. We describe the updated software architecture and illustrate its flexibility through several example applications: (1) We trained different quantum generative models using several circuit ansatzes, data sets, and data transformations. (2) We evaluated our models on GPU and real quantum hardware. (3) We assessed the generalization capabilities of our generative models using a broad set of metrics that capture, e.g., the novelty and validity of the generated data.
    
[^36]: 使用轨迹信息的代理梯度进行联邦零阶优化

    Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients. (arXiv:2308.04077v1 [cs.LG])

    [http://arxiv.org/abs/2308.04077](http://arxiv.org/abs/2308.04077)

    本论文提出了一种使用轨迹信息的代理梯度方法，用于解决联邦零阶优化中的查询和通信效率问题。

    

    联邦优化是一种新兴的范式，广泛应用于联邦学习等实际场景中，它使多个客户端（如边缘设备）能够共同优化一个全局函数。这些客户端不共享本地数据集，通常只共享本地梯度。然而，在许多联邦优化应用中，梯度信息是不可用的，因此引出了联邦零阶优化（ZOO）的范式。现有的联邦ZOO算法存在查询和通信效率的限制，这可以归因于：（a）它们对梯度估计需要大量的函数查询；（b）它们的实际本地更新与预期全局更新存在显著差异。为此，我们引入了基于轨迹信息的梯度代理，它能够利用优化过程中的函数查询历史进行准确且高效的梯度估计。

    Federated optimization, an emerging paradigm which finds wide real-world applications such as federated learning, enables multiple clients (e.g., edge devices) to collaboratively optimize a global function. The clients do not share their local datasets and typically only share their local gradients. However, the gradient information is not available in many applications of federated optimization, which hence gives rise to the paradigm of federated zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from the limitations of query and communication inefficiency, which can be attributed to (a) their reliance on a substantial number of function queries for gradient estimation and (b) the significant disparity between their realized local updates and the intended global updates. To this end, we (a) introduce trajectory-informed gradient surrogates which is able to use the history of function queries during optimization for accurate and query-efficient gradient estimatio
    
[^37]: 为物理信息神经网络学习专门的激活函数

    Learning Specialized Activation Functions for Physics-informed Neural Networks. (arXiv:2308.04073v1 [cs.LG])

    [http://arxiv.org/abs/2308.04073](http://arxiv.org/abs/2308.04073)

    本文发现物理信息神经网络（PINNs）在解决偏微分方程时对激活函数非常敏感，为了避免低效的手动选择并减轻优化困难，我们引入了自适应激活函数，并提出了将学习候选激活函数组合的思想应用于PINNs优化的方法。

    

    众所周知，物理信息神经网络（PINNs）在优化过程中存在困难。本文揭示了PINNs的优化困难与激活函数之间的联系。具体而言，我们发现，在解决具有不同属性的偏微分方程时，PINNs对激活函数非常敏感。现有的方法通常通过低效的试错方式选择激活函数。为了避免低效的手动选择，并减轻PINNs的优化困难，我们引入了自适应激活函数，用于在解决不同问题时搜索最佳函数。我们比较了不同的自适应激活函数，并讨论了它们在PINNs中的局限性。此外，我们提出了将学习候选激活函数组合的思想应用于PINNs优化的方法，这对所学函数的平滑性和多样性有更高要求。通过移除不能满足要求的激活函数，我们实现了这一目标。

    Physics-informed neural networks (PINNs) are known to suffer from optimization difficulty. In this work, we reveal the connection between the optimization difficulty of PINNs and activation functions. Specifically, we show that PINNs exhibit high sensitivity to activation functions when solving PDEs with distinct properties. Existing works usually choose activation functions by inefficient trial-and-error. To avoid the inefficient manual selection and to alleviate the optimization difficulty of PINNs, we introduce adaptive activation functions to search for the optimal function when solving different problems. We compare different adaptive activation functions and discuss their limitations in the context of PINNs. Furthermore, we propose to tailor the idea of learning combinations of candidate activation functions to the PINNs optimization, which has a higher requirement for the smoothness and diversity on learned functions. This is achieved by removing activation functions which canno
    
[^38]: 路径签名在概率轨迹优化中的多样性

    Path Signatures for Diversity in Probabilistic Trajectory Optimisation. (arXiv:2308.04071v1 [cs.RO])

    [http://arxiv.org/abs/2308.04071](http://arxiv.org/abs/2308.04071)

    本文提出了一种基于路径签名的算法，用于解决并行轨迹优化中的模式塌陷问题，并实现更好的全局性能。

    

    运动规划可以被看作是一个轨迹优化问题，其中成本被最小化，以生成轨迹为函数。在具有多个障碍物和复杂几何的复杂环境中，这个优化问题通常很难解决，并容易陷入局部最小值。然而，最近计算硬件的进步使得可以进行并行轨迹优化，其中同时得到多个解，每个解从不同的起始点初始化。不幸的是，如果没有一个策略防止两个解塌陷在一起，简单的并行优化会遭受模式塌陷的问题，降低方法的效率和找到全局解的可能性。在本文中，我们利用最近在粗路径理论方面的进展，设计了一种用于促进多样性的并行轨迹优化算法，从而避免模式塌陷并实现更好的全局特性。我们的方法...

    Motion planning can be cast as a trajectory optimisation problem where a cost is minimised as a function of the trajectory being generated. In complex environments with several obstacles and complicated geometry, this optimisation problem is usually difficult to solve and prone to local minima. However, recent advancements in computing hardware allow for parallel trajectory optimisation where multiple solutions are obtained simultaneously, each initialised from a different starting point. Unfortunately, without a strategy preventing two solutions to collapse on each other, naive parallel optimisation can suffer from mode collapse diminishing the efficiency of the approach and the likelihood of finding a global solution. In this paper we leverage on recent advances in the theory of rough paths to devise an algorithm for parallel trajectory optimisation that promotes diversity over the range of solutions, therefore avoiding mode collapses and achieving better global properties. Our appro
    
[^39]: ConDistFL：针对部分标注数据的联邦学习条件蒸馏

    ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data. (arXiv:2308.04070v1 [cs.CV])

    [http://arxiv.org/abs/2308.04070](http://arxiv.org/abs/2308.04070)

    ConDistFL框架将联邦学习与知识蒸馏相结合，通过充分设计条件概率表示从部分标注数据中提取无标注信息，解决了有限全标注训练数据的挑战，并在多个腹部CT数据集上展现了显著的性能优势。

    

    开发一个能够同时描绘多个器官和疾病的广义分割模型具有很高的价值。联邦学习（FL）是一种无需交换训练数据的协作开发模型的关键技术。然而，有限的全标注训练数据的获取权限给训练可泛化模型带来了重大挑战。我们提出了“ConDistFL”框架，通过将FL与知识蒸馏相结合来解决这个问题。本地模型可以通过充分设计的条件概率表示从全局模型的部分标注数据中提取无标注器官和肿瘤的知识。我们在来自MSD和KiTS19挑战赛的四个不同部分标注腹部CT数据集上验证了我们的框架。实验结果表明，所提出的框架明显优于FedAvg和FedOpt基线。此外，对外部测试数据集的性能表现显示了更好的泛化能力。

    Developing a generalized segmentation model capable of simultaneously delineating multiple organs and diseases is highly desirable. Federated learning (FL) is a key technology enabling the collaborative development of a model without exchanging training data. However, the limited access to fully annotated training data poses a major challenge to training generalizable models. We propose "ConDistFL", a framework to solve this problem by combining FL with knowledge distillation. Local models can extract the knowledge of unlabeled organs and tumors from partially annotated data from the global model with an adequately designed conditional probability representation. We validate our framework on four distinct partially annotated abdominal CT datasets from the MSD and KiTS19 challenges. The experimental results show that the proposed framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the performance on an external test dataset demonstrates superior generalizability c
    
[^40]: 通过自适应加权正则化和知识蒸馏提高低标签环境下的对抗鲁棒性

    Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation. (arXiv:2308.04061v1 [cs.LG])

    [http://arxiv.org/abs/2308.04061](http://arxiv.org/abs/2308.04061)

    本文提出了一种适用于标记数据稀缺环境的半监督对抗训练算法，通过引入适用于无标签数据的正则化项和知识蒸馏，实现了对抗鲁棒性的增强，并在实验证明了其显著优势。

    

    对抗鲁棒性是近年来受到广泛关注的研究领域，它与构建可信人工智能密切相关。然而，现有的对抗鲁棒性研究主要集中在有大量标记数据的监督学习环境下。本文研究在标记数据稀缺的半监督对抗训练环境下进行。我们提出了两个鲁棒风险的上界，并通过这两个上界提出了一个适用于无标签数据的正则化项。然后，我们开发了一个半监督对抗训练算法，通过将提出的正则化项与使用半监督学习算法训练的半监督教师模型进行知识蒸馏相结合。我们的实验结果表明，我们提出的算法在性能上具有显著优势，超过了现有算法。尤其是与监督学习算法相比，我们的算法表现出更高的性能。

    Adversarial robustness is a research area that has recently received a lot of attention in the quest for trustworthy artificial intelligence. However, recent works on adversarial robustness have focused on supervised learning where it is assumed that labeled data is plentiful. In this paper, we investigate semi-supervised adversarial training where labeled data is scarce. We derive two upper bounds for the robust risk and propose a regularization term for unlabeled data motivated by these two upper bounds. Then, we develop a semi-supervised adversarial training algorithm that combines the proposed regularization term with knowledge distillation using a semi-supervised teacher (i.e., a teacher model trained using a semi-supervised learning algorithm). Our experiments show that our proposed algorithm achieves state-of-the-art performance with significant margins compared to existing algorithms. In particular, compared to supervised learning algorithms, performance of our proposed algorit
    
[^41]: 改进利用聚类方法进行新西兰儿童福利系统的预测风险建模

    Toward Improving Predictive Risk Modelling for New Zealand's Child Welfare System Using Clustering Methods. (arXiv:2308.04060v1 [stat.ML])

    [http://arxiv.org/abs/2308.04060](http://arxiv.org/abs/2308.04060)

    本文利用主成分分析和K-Means聚类方法，初步研究了新西兰儿童福利系统的预测风险建模，发现了一些特征并了解了其对当前风险建模框架的潜在影响。

    

    临床判断和预测风险模型的结合对社工在划分处于虐待风险中的儿童并决定何时采取干预措施至关重要。政府福利机构利用行政数据和机器学习算法已经开始了解决这个问题的预测风险建模工作。虽然以往的研究已经调查了与儿童虐待有关的风险因素，但仍存在很多空白，尚不清楚这些风险因素如何相互作用以及预测风险模型在具有不同特征的儿童中是否表现不同。本文通过整合主成分分析和K-Means聚类，初步发现了我们在确定这些特征及其对当前风险建模框架的潜在影响的工作。这种方法可以对新西兰（NZ）被报告有护理和保护问题的儿童的现存、尚未确定的聚类进行研究。

    The combination of clinical judgement and predictive risk models crucially assist social workers to segregate children at risk of maltreatment and decide when authorities should intervene. Predictive risk modelling to address this matter has been initiated by several governmental welfare authorities worldwide involving administrative data and machine learning algorithms. While previous studies have investigated risk factors relating to child maltreatment, several gaps remain as to understanding how such risk factors interact and whether predictive risk models perform differently for children with different features. By integrating Principal Component Analysis and K-Means clustering, this paper presents initial findings of our work on the identification of such features as well as their potential effect on current risk modelling frameworks. This approach allows examining existent, unidentified yet, clusters of New Zealand (NZ) children reported with care and protection concerns, as well
    
[^42]: 五美元模型：从句子嵌入生成游戏地图和精灵角色

    The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings. (arXiv:2308.04052v1 [cs.LG])

    [http://arxiv.org/abs/2308.04052](http://arxiv.org/abs/2308.04052)

    五美元模型是一种轻量级的文本到图像生成架构，可以从编码的文本提示中生成低维度的图片，并在有限数据集上保持语义含义。

    

    五美元模型是一种轻量级的文本到图像生成架构，可以从编码的文本提示中生成低维度的图片。这个模型可以在低维度领域中成功生成准确且美观的内容，即使只有有限的训练数据。尽管模型和数据集都很小，但生成的图片仍然能够保持文本提示的语义含义。我们将这个模型应用于三个小型数据集：像素艺术的游戏地图、游戏角色精灵图像和缩小的表情符号图像，并应用了新颖的扩充策略来提高模型在这些有限数据集上的性能。我们使用CLIP VIT-B/32模型生成的文本-图像对之间的余弦相似度评估了我们模型的性能。

    The five-dollar model is a lightweight text-to-image generative architecture that generates low dimensional images from an encoded text prompt. This model can successfully generate accurate and aesthetically pleasing content in low dimensional domains, with limited amounts of training data. Despite the small size of both the model and datasets, the generated images are still able to maintain the encoded semantic meaning of the textual prompt. We apply this model to three small datasets: pixel art video game maps, video game sprite images, and down-scaled emoji images and apply novel augmentation strategies to improve the performance of our model on these limited datasets. We evaluate our models performance using cosine similarity score between text-image pairs generated by the CLIP VIT-B/32 model.
    
[^43]: 形状优化中的异常检测和设计空间维度降低的生成模型

    Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization. (arXiv:2308.04051v1 [stat.ML])

    [http://arxiv.org/abs/2308.04051](http://arxiv.org/abs/2308.04051)

    该论文提出了一种新的形状优化方法，通过降低设计空间维度和建模数据的生成过程，实现了提高全局优化算法效率和生成无几何异常的高质量设计。

    

    我们的工作提出了一种新颖的形状优化方法，其两个目标是提高全局优化算法的效率，同时在优化过程中生成没有几何异常的高质量设计。通过减少定义新的减少子空间的原始设计变量的数量，并使用概率线性潜变量模型来建模数据的底层生成过程，如因子分析和概率主成分分析，来实现这一目标。我们展示了当形状修改方法是线性的且设计变量在均匀随机采样时，数据近似服从高斯分布，这是由于直接应用了中心极限定理。利用马氏距离来衡量模型不确定性，并且论文证明异常设计往往具有较高的该度量值。

    Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This en
    
[^44]: TF-IDF特征加权方法的比较研究及其在非结构化数据集中的分析

    A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset. (arXiv:2308.04037v1 [cs.CL])

    [http://arxiv.org/abs/2308.04037](http://arxiv.org/abs/2308.04037)

    该论文比较研究了TF-IDF特征加权方法并使用非结构化数据集进行了分析，结果发现相比于N-Gram，使用TF-IDF特征可以显著提高特征提取效果。

    

    文本分类是将文本分类到相关类别中的过程，其算法是自然语言处理 (NLP) 的核心。在文本分类中，术语频率-逆文件频率 (TF-IDF) 和 NLP 是最常用的信息检索方法。我们研究和分析了在非结构化数据上进行文本分类的特征加权方法。提出的模型考虑了两个特征 N-Gram 和 TF-IDF，用于情感分析的 IMDB 电影评论和亚马逊 Alexa 评论数据集。然后我们使用了最先进的分类器来验证该方法，即支持向量机 (SVM)、逻辑回归、多项式朴素贝叶斯 (Multinomial NB)、随机森林、决策树和 K 最近邻 (KNN)。从这两个特征提取中，使用 TF-IDF 特征相比基于 N-Gram 有了显著的特征提取增加。TF-IDF 获得了最高的准确率 (93.81%)、精确率 (94.20%)、召回率 (93.81%)，

    Text Classification is the process of categorizing text into the relevant categories and its algorithms are at the core of many Natural Language Processing (NLP). Term Frequency-Inverse Document Frequency (TF-IDF) and NLP are the most highly used information retrieval methods in text classification. We have investigated and analyzed the feature weighting method for text classification on unstructured data. The proposed model considered two features N-Grams and TF-IDF on the IMDB movie reviews and Amazon Alexa reviews dataset for sentiment analysis. Then we have used the state-of-the-art classifier to validate the method i.e., Support Vector Machine (SVM), Logistic Regression, Multinomial Naive Bayes (Multinomial NB), Random Forest, Decision Tree, and k-nearest neighbors (KNN). From those two feature extractions, a significant increase in feature extraction with TF-IDF features rather than based on N-Gram. TF-IDF got the maximum accuracy (93.81%), precision (94.20%), recall (93.81%), an
    
[^45]: 生物医学问题回答的Top K相关段落检索

    Top K Relevant Passage Retrieval for Biomedical Question Answering. (arXiv:2308.04028v1 [cs.CL])

    [http://arxiv.org/abs/2308.04028](http://arxiv.org/abs/2308.04028)

    这篇论文提出了一种用于生物医学问题回答的Top K相关段落检索方法，传统的稀疏向量空间模型不适用于这个任务。然而，对于临床领域来说，这个问题还没有得到很好的解决。

    

    问答是一项利用大量文档回答事实性问题的任务。它旨在以自然语言回答用户的问题并提供准确的答案。问答依赖于高效的段落检索来选择候选上下文，传统的稀疏向量空间模型，如TF-IDF或BM25，是事实上的方法。在网络上，没有一篇文章可以提供所有可能的答案，以回答用户所提出的问题。现有的稠密段落检索模型已经对维基百科2018年12月20日的倾销进行了训练，用作回答问题的源文档。问答系统在多个开放领域和机器理解系统上取得了重大进展，使用了大规模的注释数据集。然而，在临床领域，这个问题仍然相对未被探索。根据多项调查，无法从维基百科准确回答生物医学问题。

    Question answering is a task that answers factoid questions using a large collection of documents. It aims to provide precise answers in response to the user's questions in natural language. Question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. On the web, there is no single article that could provide all the possible answers available on the internet to the question of the problem asked by the user. The existing Dense Passage Retrieval model has been trained on Wikipedia dump from Dec. 20, 2018, as the source documents for answering questions. Question answering (QA) has made big strides with several open-domain and machine comprehension systems built using large-scale annotated datasets. However, in the clinical domain, this problem remains relatively unexplored. According to multiple surveys, Biomedical Questions cannot be answered correctly from Wikipedia 
    
[^46]: 不平衡分类和RL探索的范围损失

    Scope Loss for Imbalanced Classification and RL Exploration. (arXiv:2308.04024v1 [cs.LG])

    [http://arxiv.org/abs/2308.04024](http://arxiv.org/abs/2308.04024)

    本文介绍了范围损失，这是一种新的适用于强化学习和监督分类的损失函数，它能够解决探索利用权衡和数据集不平衡问题，并在实验中表现出优于其他损失函数的性能。

    

    我们展示了强化学习问题和监督分类问题之间的等价性。我们因此将强化学习中的探索利用权衡等同于监督分类中的数据集不平衡问题，并找出了它们在解决方式上的相似之处。通过对上述问题的分析，我们提出了一种新的适用于强化学习和监督分类的损失函数- 范围损失。范围损失可以调整梯度，以防止过度利用和数据集不平衡引起的性能损失，而无需进行任何调整。我们在一系列基准强化学习任务和一个偏斜的分类数据集上测试了范围损失，结果显示范围损失优于其他损失函数。

    We demonstrate equivalence between the reinforcement learning problem and the supervised classification problem. We consequently equate the exploration exploitation trade-off in reinforcement learning to the dataset imbalance problem in supervised classification, and find similarities in how they are addressed. From our analysis of the aforementioned problems we derive a novel loss function for reinforcement learning and supervised classification. Scope Loss, our new loss function, adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances, without the need for any tuning. We test Scope Loss against SOTA loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset, and show that Scope Loss outperforms other loss functions.
    
[^47]: 通过对抗攻击改进半监督学习的性能

    Improving Performance of Semi-Supervised Learning by Adversarial Attacks. (arXiv:2308.04018v1 [cs.LG])

    [http://arxiv.org/abs/2308.04018](http://arxiv.org/abs/2308.04018)

    本文提出了一个名为SCAR的通用框架，通过对预训练模型进行对抗攻击来改进半监督学习算法的性能，显著提高了图像分类的准确性。

    

    半监督学习算法是建立在一个现实的假设上，即访问大量标记数据很困难。本研究提出了一个名为SCAR的通用框架，用于改进最近的半监督学习算法的性能。通过对预训练模型进行对抗攻击，我们的框架在图像分类方面取得了显著进展。我们介绍了对抗攻击如何成功选择高置信度的未标记数据，并与当前预测的进行标记。在CIFAR10数据集上，三个最近的半监督学习算法与SCAR框架相结合，显著提高了图像分类的性能。

    Semi-supervised learning (SSL) algorithm is a setup built upon a realistic assumption that access to a large amount of labeled data is tough. In this study, we present a generalized framework, named SCAR, standing for Selecting Clean samples with Adversarial Robustness, for improving the performance of recent SSL algorithms. By adversarially attacking pre-trained models with semi-supervision, our framework shows substantial advances in classifying images. We introduce how adversarial attacks successfully select high-confident unlabeled data to be labeled with current predictions. On CIFAR10, three recent SSL algorithms with SCAR result in significantly improved image classification.
    
[^48]: 大型语言模型的持续预训练：如何（重新）热启动模型？

    Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v1 [cs.CL])

    [http://arxiv.org/abs/2308.04014](http://arxiv.org/abs/2308.04014)

    该论文研究了大型语言模型的持续预训练问题，探讨了热启动策略对于解决分布变化和提高计算效率的影响。

    

    大型语言模型通常会对数十亿个标记进行预训练，一旦有新数据可用，就会重新开始这个过程。一种更廉价和高效的解决方案是实现这些模型的持续预训练，即用新数据更新预训练模型而不是从头开始重新训练。然而，新数据引起的分布变化通常会导致过去数据的性能下降。在本研究中，我们研究了不同的热启动策略对持续预训练的影响。我们的假设是，在训练新数据集时，需要重新增加学习率以提高计算效率。我们在Pile（上游数据，300B标记）上持续预训练模型在SlimPajama（下游数据，297B标记）上进行了线性热启动和余弦衰减的调度。我们在Pythia 410M语言模型架构上进行了所有实验。

    Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and ev
    
[^49]: 从观测网络数据中估计因果效应的泛化界限

    Generalization bound for estimating causal effects from observational network data. (arXiv:2308.04011v1 [cs.LG])

    [http://arxiv.org/abs/2308.04011](http://arxiv.org/abs/2308.04011)

    该论文提出了一种从观测网络数据中估计因果效应的泛化界限，通过利用联合倾向得分的重新加权模式和积分概率度量的表示学习模式进行推导，从而支持缓解混淆偏差和指导学习目标的设计。

    

    从观测网络数据中估计因果效应是一个重要而具有挑战性的问题。现有的因果推断相关的研究缺乏对泛化界限的分析，而泛化界限在理论上可以支持缓解复杂的混淆偏差，并且可以在实际中以原则性的方式指导学习目标的设计。为了填补这一空白，我们通过利用基于联合倾向得分的重新加权模式和基于积分概率度量（IPM）的表示学习模式，推导出了用于网络场景中因果效应估计的泛化界限。我们从重新加权和表示学习两个角度提供了关于泛化界限的理解。在界限分析的驱动下，我们提出了一种基于联合倾向得分和表示学习的加权回归方法。通过对两个实际网络和半合成数据的广泛实验研究进行评估。

    Estimating causal effects from observational network data is a significant but challenging problem. Existing works in causal inference for observational network data lack an analysis of the generalization bound, which can theoretically provide support for alleviating the complex confounding bias and practically guide the design of learning objectives in a principled manner. To fill this gap, we derive a generalization bound for causal effect estimation in network scenarios by exploiting 1) the reweighting schema based on joint propensity score and 2) the representation learning schema based on Integral Probability Metric (IPM). We provide two perspectives on the generalization bound in terms of reweighting and representation learning, respectively. Motivated by the analysis of the bound, we propose a weighting regression method based on the joint propensity score augmented with representation learning. Extensive experimental studies on two real-world networks with semi-synthetic data d
    
[^50]: 使用结构化背景知识和演绎推理理解CNN隐藏神经元激活

    Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v1 [cs.LG])

    [http://arxiv.org/abs/2308.03999](http://arxiv.org/abs/2308.03999)

    本文提供了一种使用结构化背景知识和演绎推理的方法，用于解释CNN隐藏神经元的激活。该方法能够提供有意义的解释，解决了深度学习系统黑盒特性的问题。

    

    Explainable AI中的一个主要挑战是准确解释隐藏神经元的激活：准确的解释将为深度学习系统内部检测到的输入相关内容提供洞察力，揭示深度学习系统的黑盒特性。现有技术表明，在某些情况下，隐藏节点的激活可以被人类理解，但是对隐藏神经元激活的解释进行假设和验证的系统化自动化方法尚未充分研究。在本文中，我们提供了这样一种方法，并证明它提供了有意义的解释。我们的方法基于使用大规模的背景知识，从维基百科概念层次结构中筛选出的约200万个类别，以及一个称为概念归纳的符号推理方法，这种方法最初是为语义Web领域的应用而开发的。

    A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, de-mystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Ou
    
[^51]: 合作式多类型多智能体深度强化学习在空天地一体化网络资源管理中的应用

    Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks. (arXiv:2308.03995v1 [cs.MA])

    [http://arxiv.org/abs/2308.03995](http://arxiv.org/abs/2308.03995)

    本文提出了一种合作式多类型多智能体深度强化学习方法，应用于空天地一体化网络的资源管理，实验结果表明其有效性和潜在价值。

    

    空天地一体化网络（SAGIN）将包括低地球轨道卫星（LEO）、无人机（UAV）和地面用户（GU）在内的异构设备整合起来，有望推动智能城市应用的发展。然而，SAGIN的资源管理是一个挑战，需要紧急研究，因为不恰当的资源管理会导致数据传输质量差，进而影响智能城市的服务。本文开发了一个综合的SAGIN系统，包括五种不同的通信链路，并提出了一种高效的合作式多类型多智能体深度强化学习（CMT-MARL）方法来解决资源管理问题。实验结果突出了所提出的CMT-MARL的有效性，如整体传输速率和传输成功率等关键性能指标。这些结果强调了未来SAGIN实施的潜在价值和可行性。

    The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous devices including low earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users (GUs), holds significant promise for advancing smart city applications. However, resource management of the SAGIN is a challenge requiring urgent study in that inappropriate resource management will cause poor data transmission, and hence affect the services in smart cities. In this paper, we develop a comprehensive SAGIN system that encompasses five distinct communication links and propose an efficient cooperative multi-type multi-agent deep reinforcement learning (CMT-MARL) method to address the resource management issue. The experimental results highlight the efficacy of the proposed CMT-MARL, as evidenced by key performance indicators such as the overall transmission rate and transmission success rate. These results underscore the potential value and feasibility of future implementation of the SAGIN.
    
[^52]: 傅里叶神经运算器用于实时模拟3D动态城市微气候

    Fourier neural operator for real-time simulation of 3D dynamic urban microclimate. (arXiv:2308.03985v1 [cs.LG])

    [http://arxiv.org/abs/2308.03985](http://arxiv.org/abs/2308.03985)

    该论文介绍了傅里叶神经运算器（FNO）用于实时模拟3D动态城市微气候。通过深度学习技术，FNO在加速解决复杂非线性相互作用和系统动力学建模方面表现出很大的潜力。

    

    全球城市化凸显了城市微气候对人类舒适度、健康和建筑/城市能效的重要性。它们对建筑设计和城市规划产生重大的环境影响。理解局部微气候对于城市应对气候变化和有效实施弹性措施至关重要。然而，分析城市微气候需要在计算域内考虑复杂的室外参数，涵盖较长时期，并涵盖城市规模。因此，数值方法如计算流体力学（CFD）在评估城市微气候的影响时变得计算复杂。深度学习技术的兴起为加速复杂非线性相互作用和系统动力学建模提供了新机会。最近，傅里叶神经运算器（FNO）在加速解决偏微分方程方面表现出了非常有希望的结果。

    Global urbanization has underscored the significance of urban microclimates for human comfort, health, and building/urban energy efficiency. They profoundly influence building design and urban planning as major environmental impacts. Understanding local microclimates is essential for cities to prepare for climate change and effectively implement resilience measures. However, analyzing urban microclimates requires considering a complex array of outdoor parameters within computational domains at the city scale over a longer period than indoors. As a result, numerical methods like Computational Fluid Dynamics (CFD) become computationally expensive when evaluating the impact of urban microclimates. The rise of deep learning techniques has opened new opportunities for accelerating the modeling of complex non-linear interactions and system dynamics. Recently, the Fourier Neural Operator (FNO) has been shown to be very promising in accelerating solving the Partial Differential Equations (PDEs
    
[^53]: PUG:用于表示学习的逼真且语义可控的合成数据

    PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning. (arXiv:2308.03977v1 [cs.CV])

    [http://arxiv.org/abs/2308.03977](http://arxiv.org/abs/2308.03977)

    我们提出了一种使用逼真且语义可控的合成数据的方法，用于表示学习研究，该方法具有渲染所需数量的数据样本、精确控制场景和分布转变以及精细的真实标签的优点。

    

    合成图像数据集在设计和评估深度神经网络方面具有独特的优势：它们可以渲染所需数量的数据样本，精确控制每个场景并提供精细的真实标签（和标题），并可以精确控制训练和测试之间的分布转变，以隔离感兴趣的变量进行可靠实验。尽管具有如此优势，但合成图像数据的使用仍受限制，并且通常由于其缺乏真实性而被忽视。因此，大多数工作仍依赖于来自互联网上公开图像的真实图像数据集，并且可能存在隐私、偏见和版权问题，且对于对象的精确呈现方式控制能力较小。在这项工作中，我们提出了利用逼真的合成数据解决该问题的途径：我们开发了一种用于表示学习研究的新一代交互环境，提供了可控性和逼真度。

    Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and r
    
[^54]: 高摊还全局搜索方法在带有深度生成模型的有效初步轨迹设计中的应用

    Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models. (arXiv:2308.03960v1 [cs.LG])

    [http://arxiv.org/abs/2308.03960](http://arxiv.org/abs/2308.03960)

    本文提出了一种摊还全局搜索框架（AmorGS），利用深度生成模型加速对初步轨迹设计问题的全局搜索。该方法通过预测具有相似结构的轨迹解，能够在高维度和非凸性问题中更高效地寻找多个不同特征的解。通过在两个实际问题上的评估，证明了该方法的有效性。

    

    初步轨迹设计是一种全局搜索问题，旨在寻找多个在轨迹优化问题中具有不同特征的解。由于其高维度和非凸性，以及问题参数的频繁调整，全局搜索变得计算上具有挑战性。本文利用解的聚类结构，并提出了一种摊还全局搜索（AmorGS）框架。我们使用深度生成模型来预测与先前解决问题具有相似结构的轨迹解，从而加速对未见参数值的全局搜索。我们通过使用De Jong的第五函数和低推力圆形限制性三体问题对我们的方法进行评估。

    Preliminary trajectory design is a global search problem that seeks multiple qualitatively different solutions to a trajectory optimization problem. Due to its high dimensionality and non-convexity, and the frequent adjustment of problem parameters, the global search becomes computationally demanding. In this paper, we exploit the clustering structure in the solutions and propose an amortized global search (AmorGS) framework. We use deep generative models to predict trajectory solutions that share similar structures with previously solved problems, which accelerates the global search for unseen parameter values. Our method is evaluated using De Jong's 5th function and a low-thrust circular restricted three-body problem.
    
[^55]: 固定的神经元协变性引发了对抗性鲁棒性

    Fixed Inter-Neuron Covariability Induces Adversarial Robustness. (arXiv:2308.03956v1 [cs.LG])

    [http://arxiv.org/abs/2308.03956](http://arxiv.org/abs/2308.03956)

    该论文研究了固定的神经元协变性对深度神经网络（DNN）的对抗性鲁棒性的影响，提出了自洽激活（SCA）层，其激活具有固定但可学习的协变性模式，以提高DNN的鲁棒性。

    

    与对抗性扰动的脆弱性是深度神经网络（DNN）的一个主要缺陷，这引发了关于它们在现实世界场景中可靠性的质疑。然而，DNN被认为是模拟人类感知的，而人类感知对这种扰动具有很高的鲁棒性，这表明可能存在让人类感知具有鲁棒性但在当前DNN类别中没有表示的特征。其中一种特征是生物神经元的活动具有相关性，并且这种相关性的结构在较长时间跨度上往往是相当稳定的，即使它会影响性能和学习。我们假设将这种对激活的约束集成到DNN中会提高其对抗性鲁棒性，并为了测试这个假设，我们开发了自洽激活（SCA）层，它由激活彼此一致的神经元组成，因为它们符合固定但可以学习的协变性模式。

    The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated
    
[^56]: 基于深度迁移学习的PMU测量的电力系统短期电压稳定性评估

    PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning. (arXiv:2308.03953v1 [cs.LG])

    [http://arxiv.org/abs/2308.03953](http://arxiv.org/abs/2308.03953)

    本研究提出了一种基于PMU测量的电力系统短期电压稳定性评估方法，利用深度迁移学习解决了拓扑变化、样本标注和小规模数据集处理等挑战，并且在实验中取得了较好的模型评估准确性。

    

    深度学习已经成为解决电力系统短期电压稳定性评估（STVSA）挑战的有效方法。然而，现有的基于深度学习的STVSA方法在适应拓扑变化、样本标注和处理小规模数据集方面存在局限性。为了克服这些挑战，本文提出了一种基于PMU测量的STVSA方法，利用深度迁移学习。该方法利用PMUs捕获的实时动态信息创建初始数据集。它采用时间集成进行样本标注，并利用最小二乘生成对抗网络（LSGAN）进行数据增强，实现对小规模数据集的有效深度学习。此外，该方法通过探索不同故障之间的连接增强了对拓扑变化的适应性。在IEEE 39节点测试系统上的实验结果表明，该方法提高了模型评估准确性。

    Deep learning has emerged as an effective solution for addressing the challenges of short-term voltage stability assessment (STVSA) in power systems. However, existing deep learning-based STVSA approaches face limitations in adapting to topological changes, sample labeling, and handling small datasets. To overcome these challenges, this paper proposes a novel phasor measurement unit (PMU) measurements-based STVSA method by using deep transfer learning. The method leverages the real-time dynamic information captured by PMUs to create an initial dataset. It employs temporal ensembling for sample labeling and utilizes least squares generative adversarial networks (LSGAN) for data augmentation, enabling effective deep learning on small-scale datasets. Additionally, the method enhances adaptability to topological changes by exploring connections between different faults. Experimental results on the IEEE 39-bus test system demonstrate that the proposed method improves model evaluation accura
    
[^57]: 通过Transformer增强大规模异构联邦学习的前景

    The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers. (arXiv:2308.03945v1 [cs.LG])

    [http://arxiv.org/abs/2308.03945](http://arxiv.org/abs/2308.03945)

    本文研究了在大规模异构联邦学习中，通过Transformer模型实现泛化和个性化的前景，并通过广泛的比较实验证明了Transformer在大规模异构FL任务中相对于深度神经网络的优势，并通过分析中心核对齐（CKA）表示相似性来深入了解Transformer有前景的能力背后的原因。

    

    联邦学习（FL）通过实现跨分布式数据所有者的AI模型的协作训练来解决数据隐私问题。FL的广泛采用面临着数据异构和涉及到的数据所有者规模庞大的根本挑战。本文研究了在这种情况下，基于Transformer的FL模型在实现泛化和个性化方面的前景。我们在不同场景下进行了广泛的比较实验，涉及到了FL与Transformer、ResNet和个性化ResNet-based FL方法。这些实验考虑了不同数量的数据所有者，以展示Transformer在大规模异构FL任务中相对于深度神经网络的优势。此外，我们通过比较不同层和FL模型之间的中心核对齐（CKA）表示相似性来分析Transformer的出色性能，以深入了解其有前景的能力背后的原因。

    Federated learning (FL) addresses data privacy concerns by enabling collaborative training of AI models across distributed data owners. Wide adoption of FL faces the fundamental challenges of data heterogeneity and the large scale of data owners involved. In this paper, we investigate the prospect of Transformer-based FL models for achieving generalization and personalization in this setting. We conduct extensive comparative experiments involving FL with Transformers, ResNet, and personalized ResNet-based FL approaches under various scenarios. These experiments consider varying numbers of data owners to demonstrate Transformers' advantages over deep neural networks in large-scale heterogeneous FL tasks. In addition, we analyze the superior performance of Transformers by comparing the Centered Kernel Alignment (CKA) representation similarity across different layers and FL models to gain insight into the reasons behind their promising capabilities.
    
[^58]: GraPhSyM: 图形物理综合模型

    GraPhSyM: Graph Physical Synthesis Model. (arXiv:2308.03944v1 [cs.LG])

    [http://arxiv.org/abs/2308.03944](http://arxiv.org/abs/2308.03944)

    GraPhSyM是一种用于从物理合成电路网表中快速准确地估计后物理合成电路延迟和面积指标的模型，提供了准确的指标可见性给早期的EDA阶段，可用于全局协同优化，并对基于机器学习的EDA优化框架具有重要的作用。

    

    在这项工作中，我们介绍了GraPhSyM，一种用于从物理合成电路网表中快速准确地估计后物理合成电路延迟和面积指标的图形注意力网络（GATv2）模型。一旦训练完毕，GraPhSyM可以提供准确的设计指标可见性给早期的EDA阶段，如逻辑综合，而无需运行缓慢的物理合成流程，从而实现跨阶段的全局协同优化。此外，GraPhSym提供的快速而精确的反馈对基于机器学习的EDA优化框架至关重要。给定一个表示为图形的电路门级网表，GraPhSyM利用图形结构、连接性和电性特征来预测物理合成转换（如缓冲器插入和门尺寸调整）对电路的影响。当在一个包含6000个前缀加法器设计的数据集上训练（合成到激进延迟目标），GraPhSyM可以准确预测后合成的延迟（98.3%）和面积（96.1%）。

    In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model for fast and accurate estimation of post-physical synthesis circuit delay and area metrics from pre-physical synthesis circuit netlists. Once trained, GraPhSyM provides accurate visibility of final design metrics to early EDA stages, such as logic synthesis, without running the slow physical synthesis flow, enabling global co-optimization across stages. Additionally, the swift and precise feedback provided by GraPhSym is instrumental for machine-learning-based EDA optimization frameworks. Given a gate-level netlist of a circuit represented as a graph, GraPhSyM utilizes graph structure, connectivity, and electrical property features to predict the impact of physical synthesis transformations such as buffer insertion and gate sizing. When trained on a dataset of 6000 prefix adder designs synthesized at an aggressive delay target, GraPhSyM can accurately predict the post-synthesis delay (98.3%) and area (96.1%) m
    
[^59]: 在单克隆抗体生产中优化切换操作：经济模型预测控制和强化学习

    Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning. (arXiv:2308.03928v1 [cs.LG])

    [http://arxiv.org/abs/2308.03928](http://arxiv.org/abs/2308.03928)

    本论文提出了在单克隆抗体生产中优化切换操作的方法，通过经济模型预测控制和强化学习来提高连续生产过程的效率和质量。

    

    单克隆抗体（mAbs）已成为医学中不可或缺的资产，目前处于生物制药产品开发的前沿。然而，不断增长的市场需求和mAb临床治疗所需的大量剂量使其大规模生产取得了重要进展。工业mAb生产中的大部分过程依赖于批处理操作，导致显著的停机时间。转向完全连续和集成的制造过程可以提高产品产量和质量，并消除存储中间产品所需的额外费用。集成连续mAb生产过程可以分为上游和下游过程。确保集成过程连续性的一个关键方面是捕获柱的切换，通常是在下游以满批方式操作的色谱柱。由于切换操作的离散性特性

    Monoclonal antibodies (mAbs) have emerged as indispensable assets in medicine, and are currently at the forefront of biopharmaceutical product development. However, the growing market demand and the substantial doses required for mAb clinical treatments necessitate significant progress in its large-scale production. Most of the processes for industrial mAb production rely on batch operations, which result in significant downtime. The shift towards a fully continuous and integrated manufacturing process holds the potential to boost product yield and quality, while eliminating the extra expenses associated with storing intermediate products. The integrated continuous mAb production process can be divided into the upstream and downstream processes. One crucial aspect that ensures the continuity of the integrated process is the switching of the capture columns, which are typically chromatography columns operated in a fed-batch manner downstream. Due to the discrete nature of the switching 
    
[^60]: 使用具有内部变量的深度物理引导神经网络预测和解释非线性材料响应

    Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables. (arXiv:2308.03915v1 [cs.LG])

    [http://arxiv.org/abs/2308.03915](http://arxiv.org/abs/2308.03915)

    通过使用具有内部变量的深度物理引导神经网络，在只使用测量的力-位移数据进行训练的情况下，本文发现了非线性材料的本构定律。这一方法能够预测未见的加载情况下的内部和外部变量，无论材料的性质如何。

    

    常常很难用经典的状态模型来建模非线性材料的原因是它们具有复杂且不准确的物理和数学描述，或者我们根本不知道如何从外部和内部变量之间的关系来描述这些材料。在许多学科中，神经网络方法已经成为识别非常复杂和非线性相关性的强大工具。在这项工作中，我们使用最新开发的具有内部变量的物理引导神经网络（PGNNIV）的概念，以无模型的方法和仅使用测量的力-位移数据进行训练来发现本构定律。PGNNIV通过将问题的物理特性应用于特定的隐藏层来强制执行约束条件，并能够在不使用内部变量数据的情况下进行预测。我们证明，PGNNIV能够在未见过的加载场景下预测内部和外部变量，无论材料的性质如何。

    Nonlinear materials are often difficult to model with classical state model theory because they have a complex and sometimes inaccurate physical and mathematical description or we simply do not know how to describe such materials in terms of relations between external and internal variables. In many disciplines, Neural Network methods have arisen as powerful tools to identify very complex and non-linear correlations. In this work, we use the very recently developed concept of Physically Guided Neural Networks with Internal Variables (PGNNIV) to discover constitutive laws using a model-free approach and training solely with measured force-displacement data. PGNNIVs make a particular use of the physics of the problem to enforce constraints on specific hidden layers and are able to make predictions without internal variable data. We demonstrate that PGNNIVs are capable of predicting both internal and external variables under unseen load scenarios, regardless of the nature of the material 
    
[^61]: ViLP：使用视觉、语言和姿势嵌入进行视频动作识别的知识探索

    ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition. (arXiv:2308.03908v1 [cs.CV])

    [http://arxiv.org/abs/2308.03908](http://arxiv.org/abs/2308.03908)

    本论文提出了一种基于姿势增强的视觉语言模型(VLM)，用于视频动作识别。实验结果表明，该模型能够取得令人期待的准确率，并在两个流行的动作识别数据集上取得了优异的性能。

    

    视频动作识别是一项具有挑战性的任务，由于其固有的复杂性。尽管文献中已经探索了不同的方法，但设计一个统一的框架来识别大量的人类动作仍然是一个具有挑战性的问题。最近，在这个领域中，多模态学习(MML)显示出了令人期待的结果。在文献中，2D骨骼或姿势模态经常被用于这个任务，要么独立使用，要么与视频中存在的视觉信息（RGB模态）结合使用。然而，尽管文本和姿势属性在许多计算机视觉任务中都被证明是有效的，但是尚未探索过姿势、视觉信息和文本属性的组合。在本文中，我们提出了第一个用于VAR的姿势增强的视觉语言模型(VLM)。值得注意的是，我们的方案在两个流行的人类视频动作识别基准数据集UCF-101和HMDB-51上分别达到了92.81%和73.02%的准确率。

    Video Action Recognition (VAR) is a challenging task due to its inherent complexities. Though different approaches have been explored in the literature, designing a unified framework to recognize a large number of human actions is still a challenging problem. Recently, Multi-Modal Learning (MML) has demonstrated promising results in this domain. In literature, 2D skeleton or pose modality has often been used for this task, either independently or in conjunction with the visual information (RGB modality) present in videos. However, the combination of pose, visual information, and text attributes has not been explored yet, though text and pose attributes independently have been proven to be effective in numerous computer vision tasks. In this paper, we present the first pose augmented Vision-language model (VLM) for VAR. Notably, our scheme achieves an accuracy of 92.81% and 73.02% on two popular human video action recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even w
    
[^62]: 众包监控系统的进展：系统方法和自动化算法的综合分析：现状综述。

    Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art. (arXiv:2308.03907v1 [cs.HC])

    [http://arxiv.org/abs/2308.03907](http://arxiv.org/abs/2308.03907)

    众包监控系统是解决公共安全问题的关键，本研究对基于视觉和非基于视觉的技术进行了深入分析。

    

    全球各国政府和安全机构对公共安全的日益担忧已经引起了他们的注意。这些机构越来越意识到需要可靠和安全的众包监控系统来解决这些问题。有效管理人员聚集需要采取积极的措施来防止意外事件或复杂情况，确保一个安全和协调的环境。由于对众包监控系统及其安全影响缺乏研究，这一领域的研究日益增长，探索有效保护人员聚集的潜在方法。众包监控系统依赖于基于视觉和非基于视觉的技术。本研究将对这两种方法进行深入分析。这些方法的功效取决于其部署的具体环境和时间背景。

    Growing apprehensions surrounding public safety have captured the attention of numerous governments and security agencies across the globe. These entities are increasingly acknowledging the imperative need for reliable and secure crowd-monitoring systems to address these concerns. Effectively managing human gatherings necessitates proactive measures to prevent unforeseen events or complications, ensuring a safe and well-coordinated environment. The scarcity of research focusing on crowd monitoring systems and their security implications has given rise to a burgeoning area of investigation, exploring potential approaches to safeguard human congregations effectively. Crowd monitoring systems depend on a bifurcated approach, encompassing vision-based and non-vision-based technologies. An in-depth analysis of these two methodologies will be conducted in this research. The efficacy of these approaches is contingent upon the specific environment and temporal context in which they are deploye
    
[^63]: 在设备上的智能助手语言理解

    Intelligent Assistant Language Understanding On Device. (arXiv:2308.03905v1 [cs.CL])

    [http://arxiv.org/abs/2308.03905](http://arxiv.org/abs/2308.03905)

    本论文描述了一种在设备上运行的自然语言理解系统的设计，相比于基于服务器的助手，该系统更加私密、可靠、快速、表达更强、准确性更高。通过分享实践经验，为研究界的未来工作提供参考。

    

    最近，将个人数字助手应用于手机和其他个人设备已成为可能。在本文中，我们描述了一个在设备上运行的自然语言理解系统的设计。与基于服务器的助手相比，该系统更具私密性、可靠性、速度快、表达更强、准确性更高。我们描述了在架构和技术方面做出的关键选择。例如，对话系统文献中的一些方法在部署环境中难以长期维护。我们希望通过分享实践经验，为研究界的未来工作提供参考。

    It has recently become feasible to run personal digital assistants on phones and other personal devices. In this paper we describe a design for a natural language understanding system that runs on device. In comparison to a server-based assistant, this system is more private, more reliable, faster, more expressive, and more accurate. We describe what led to key choices about architecture and technologies. For example, some approaches in the dialog systems literature are difficult to maintain over time in a deployment setting. We hope that sharing learnings from our practical experiences may help inform future work in the research community.
    
[^64]: 关于不使用权重绑定的真正不变性学习

    On genuine invariance learning without weight-tying. (arXiv:2308.03904v1 [cs.LG])

    [http://arxiv.org/abs/2308.03904](http://arxiv.org/abs/2308.03904)

    本文研究了神经网络从数据中学习到的不变性与通过权重绑定实现的真正不变性之间的区别，并提出了正则化方法来指导学习真正的不变性，实现了在输入数据分布发生变化时仍然可靠的不变性模型。

    

    本文研究神经网络从数据中学习到的不变性与通过不变权重绑定实现的真正不变性的属性和限制。为了做到这一点，我们采用了群论的视角，并分析了没有权重绑定约束的神经网络中的不变性学习。我们证明，即使网络学会了在群轨道上正确分类样本，这种模型中的决策过程并没有达到真正的不变性。相反，学习到的不变性在很大程度上取决于输入数据，如果输入分布发生变化，它将变得不可靠。接下来，我们演示了如何通过在训练中对模型的不变性进行正则化来引导不变性学习朝向真正的不变性。为此，我们提出了几个指标来量化学习到的不变性：（i）预测分布不变性，（ii）logit不变性和（iii）显著性不变性相似性。我们展示了通过不变性正规化学习到的不变性。

    In this paper, we investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying. To do so, we adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints. We demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance. Instead, learned invariance is strongly conditioned on the input data, rendering it unreliable if the input distribution shifts. We next demonstrate how to guide invariance learning toward genuine invariance by regularizing the invariance of a model at the training. To this end, we propose several metrics to quantify learned invariance: (i) predictive distribution invariance, (ii) logit invariance, and (iii) saliency invariance similarity. We show that the invariance learned with the invarianc
    
[^65]: FLIPS: 使用智能参与者选择的联邦学习

    FLIPS: Federated Learning using Intelligent Participant Selection. (arXiv:2308.03901v1 [cs.LG])

    [http://arxiv.org/abs/2308.03901](http://arxiv.org/abs/2308.03901)

    本文介绍了FLIPS，这是一个用于管理联邦学习中数据和参与者异质性的中间件系统。FLIPS通过标签分布聚类和智能参与者选择，并使用可信执行环境来确保隐私保护。实证评估表明，FLIPS相比随机方法有更好的性能。

    

    本文介绍了FLIPS的设计和实现，这是一个用于管理联邦学习中数据和参与者异质性的中间件系统。特别地，我们研究了标签分布聚类在联邦学习中参与者选择中的好处。FLIPS根据数据的标签分布预先对参与FL训练作业的各方进行聚类，并在FL训练期间确保每个聚类在被选中的参与者中公平地表示。FLIPS可以支持最常见的FL算法，包括FedAvg，FedProx，FedDyn，FedOpt和FedYogi。为了管理平台的异构性和动态资源可用性，FLIPS还结合了一种处理分布式智能社区应用中容量变化的拖累管理机制。标签分布、聚类和参与者选择的隐私通过可信执行环境(TEE)来确保。我们全面的实证评估将FLIPS与随机方法进行了比较。

    This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random p
    
[^66]: 一种评估内部聚类验证指标的新方法

    A new approach for evaluating internal cluster validation indices. (arXiv:2308.03894v1 [cs.LG])

    [http://arxiv.org/abs/2308.03894](http://arxiv.org/abs/2308.03894)

    本文回顾了现有的聚类验证方法并提出了一种新方法，用于评估无监督分类算法在不同类型的数据中的表现。

    

    无监督分类有很多不同的方法可供选择。由于没有一个算法和参数设置在所有类型的数据中表现最佳，因此需要进行聚类验证来选择真正表现最好的算法。为此，提出了几种不使用任何额外（外部）信息的内部验证指标。可以通过将它们应用于具有已知聚类结构的数据集的分类来评估这些内部验证指标。评估方法在如何使用真实分类信息方面存在差异。本文回顾了这些方法，考虑了它们的优势和劣势，然后提出了一种新方法。

    A vast number of different methods are available for unsupervised classification. Since no algorithm and parameter setting performs best in all types of data, there is a need for cluster validation to select the actually best-performing algorithm. Several indices were proposed for this purpose without using any additional (external) information. These internal validation indices can be evaluated by applying them to classifications of datasets with a known cluster structure. Evaluation approaches differ in how they use the information on the ground-truth classification. This paper reviews these approaches, considering their advantages and disadvantages, and then suggests a new approach.
    
[^67]: 可扩展且公平的大规模教育数据中数学问题解决策略预测

    Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data. (arXiv:2308.03892v1 [cs.LG])

    [http://arxiv.org/abs/2308.03892](http://arxiv.org/abs/2308.03892)

    本研究通过机器学习和人工智能方法实现了可扩展且公平的大规模教育数据中数学问题解决策略预测。

    

    理解学生的问题解决策略对于使用智能辅导系统和自适应教学系统具有重要影响。然而，在大规模数据中手动识别策略是不可行的，因此我们利用机器学习和人工智能方法进行可扩展且公平的策略预测。具体而言，我们开发了一种称为MVec的嵌入，通过学生掌握程度来学习表示，并对学生进行聚类。

    Understanding a student's problem-solving strategy can have a significant impact on effective math learning using Intelligent Tutoring Systems (ITSs) and Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better personalize itself to correct specific misconceptions that are indicated by incorrect strategies, specific problems can be designed to improve strategies and frustration can be minimized by adapting to a student's natural way of thinking rather than trying to fit a standard strategy for all. While it may be possible for human experts to identify strategies manually in classroom settings with sufficient student interaction, it is not possible to scale this up to big data. Therefore, we leverage advances in Machine Learning and AI methods to perform scalable strategy prediction that is also fair to students at all skill levels. Specifically, we develop an embedding called MVec where we learn a representation based on the mastery of students. We then cluster thes
    
[^68]: 从遍历理论的角度看深度神经网络

    Deep neural networks from the perspective of ergodic theory. (arXiv:2308.03888v1 [cs.LG])

    [http://arxiv.org/abs/2308.03888](http://arxiv.org/abs/2308.03888)

    本论文从遍历理论的角度出发，将深度神经网络视为动力系统的时间演化，通过引入一些经验法则，解释了神经网络设计中的一些启发式方法。

    

    对于深度神经网络的设计来说，仍然更多地是一门艺术而不是精确的科学。通过将遍历理论考虑引入到将网络视为动力系统时间演化的观点上，其中每一层对应于一个时间实例，我们展示了一些经验法则可以归属为启发式方法，从而使得这些方法的神秘性得以解释。

    The design of deep neural networks remains somewhat of an art rather than precise science. By tentatively adopting ergodic theory considerations on top of viewing the network as the time evolution of a dynamical system, with each layer corresponding to a temporal instance, we show that some rules of thumb, which might otherwise appear mysterious, can be attributed heuristics.
    
[^69]: 用一种时间对称的深度学习方法提升细胞跟踪能力

    Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach. (arXiv:2308.03887v1 [eess.IV])

    [http://arxiv.org/abs/2308.03887](http://arxiv.org/abs/2308.03887)

    本论文提出了一种使用时间对称的深度学习方法来提升细胞跟踪的准确性。该方法不依赖于连续帧跟踪，而是基于细胞的时空邻域进行跟踪，具有学习细胞运动模式的能力，并能处理具有严重伪影的大量视频帧。

    

    使用视频显微镜记录准确跟踪活细胞仍然是目前流行的最先进图像处理技术方法的一个具有挑战性的任务。近年来，已有几个现有和新的应用尝试将基于深度学习的框架整合到该任务中，但大部分仍然严重依赖于嵌入其架构或其他前提条件中的连续帧跟踪，从而限制了广义学习。为了解决这个问题，我们旨在开发一种新的基于深度学习的跟踪方法，该方法仅依赖于细胞可以根据其时空邻域进行跟踪的假设，而非仅限于连续帧。所提出的方法的额外优点是细胞的运动模式可以完全由预测器在没有任何先验假设的情况下学习，并且具有处理大量具有严重伪影的视频帧的潜力。

    The accurate tracking of live cells using video microscopy recordings remains a challenging task for popular state-of-the-art image processing based object tracking methods. In recent years, several existing and new applications have attempted to integrate deep-learning based frameworks for this task, but most of them still heavily rely on consecutive frame based tracking embedded in their architecture or other premises that hinder generalized learning. To address this issue, we aimed to develop a new deep-learning based tracking method that relies solely on the assumption that cells can be tracked based on their spatio-temporal neighborhood, without restricting it to consecutive frames. The proposed method has the additional benefit that the motion patterns of the cells can be learned completely by the predictor without any prior assumptions, and it has the potential to handle a large number of video frames with heavy artifacts. The efficacy of the proposed method is demonstrated thro
    
[^70]: 表联合搜索生成性基准创建

    Generative Benchmark Creation for Table Union Search. (arXiv:2308.03883v1 [cs.DB])

    [http://arxiv.org/abs/2308.03883](http://arxiv.org/abs/2308.03883)

    采用生成型AI模型为表联合搜索创建结构化数据基准

    

    数据管理传统上依靠合成数据生成器生成结构化基准，如TPC套件，我们可以精确控制重要参数如数据大小和分布。这些基准对于数据库管理系统的成功和采用至关重要。然而，越来越多的数据管理问题属于语义性质。一个重要的例子是找到可以联合的表。虽然任何具有相同基数的两个表都可以联合，表联合搜索是找到其联合在语义上连贯的表的问题。语义问题无法使用合成数据进行基准测试。我们目前创建的基准的方法涉及实际数据的手动策划和标记。这些方法不稳健且不可扩展，而且更重要的是，不清楚所创建的基准的稳健性如何。我们提议使用生成型AI模型为表联合搜索创建结构化数据基准。我们提出了一种新的方法

    Data management has traditionally relied on synthetic data generators to generate structured benchmarks, like the TPC suite, where we can control important parameters like data size and its distribution precisely. These benchmarks were central to the success and adoption of database management systems. But more and more, data management problems are of a semantic nature. An important example is finding tables that can be unioned. While any two tables with the same cardinality can be unioned, table union search is the problem of finding tables whose union is semantically coherent. Semantic problems cannot be benchmarked using synthetic data. Our current methods for creating benchmarks involve the manual curation and labeling of real data. These methods are not robust or scalable and perhaps more importantly, it is not clear how robust the created benchmarks are. We propose to use generative AI models to create structured data benchmarks for table union search. We present a novel method 
    
[^71]: 通过未见过的状态增强利用广义化在离线强化学习中

    Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])

    [http://arxiv.org/abs/2308.03882](http://arxiv.org/abs/2308.03882)

    本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。

    

    离线强化学习方法通过对未见过的状态和动作进行保守价值评估来平衡探索和利用。无模型方法会对所有未见过的动作进行惩罚，而有模型方法可以进一步通过模型展开对未见过的状态进行利用。然而，由于两个因素，这些方法在找到离线数据之外的未见过的状态时存在困难：(a)由于级联模型误差，模型的展开范围非常短，(b)模型展开仅以离线数据中观察到的状态为起点。我们放宽了第二个假设，并提出了一种新颖的未见过状态增强策略，以允许学得的模型和价值估计在未见状态中泛化。我们的策略通过对观察到的状态进行基于价值的扰动来找到未见过的状态，然后通过过滤具有过高的启发性不确定性估计（高误差）或过低的（过于相似）

    Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to
    
[^72]: 评估和解释大型语言模型在代码中使用语法结构的效果

    Evaluating and Explaining Large Language Models for Code Using Syntactic Structures. (arXiv:2308.03873v1 [cs.SE])

    [http://arxiv.org/abs/2308.03873](http://arxiv.org/abs/2308.03873)

    本文介绍了一种针对代码的大型语言模型（LLM）的解释方法ASTxplainer，该方法能够可靠地将模型的预测映射到可理解的概念上，从而实现模型的可解释性。

    

    代码的大型语言模型（LLM）是一类基于变换器的高参数神经网络，预训练于海量自然语言和编程语言数据集。这些模型正在快速应用于商业化的基于人工智能的开发者工具，如GitHub CoPilot。然而，鉴于其规模和复杂性，衡量和解释它们在程序任务上的有效性是一项具有挑战性的任务。评估和解释代码的LLM方法是密不可分的。也就是说，为了解释模型的预测，必须将其可靠地映射到细粒度、可理解的概念上。一旦实现了这种映射，就可以开展新的详细模型评估方法。然而，目前大多数的解释能力技术和评估基准都集中在模型的健壮性或单个任务性能上，而非解释模型预测。为此，本文介绍了ASTxplainer，一种针对代码的LLM的解释方法，可以实现模型的可解释性。

    Large Language Models (LLMs) for code are a family of high-parameter, transformer-based neural networks pre-trained on massive datasets of both natural and programming languages. These models are rapidly being employed in commercial AI-based developer tools, such as GitHub CoPilot. However, measuring and explaining their effectiveness on programming tasks is a challenging proposition, given their size and complexity. The methods for evaluating and explaining LLMs for code are inextricably linked. That is, in order to explain a model's predictions, they must be reliably mapped to fine-grained, understandable concepts. Once this mapping is achieved, new methods for detailed model evaluations are possible. However, most current explainability techniques and evaluation benchmarks focus on model robustness or individual task performance, as opposed to interpreting model predictions.  To this end, this paper introduces ASTxplainer, an explainability method specific to LLMs for code that enab
    
[^73]: 电子商务查询的语义等价性

    Semantic Equivalence of e-Commerce Queries. (arXiv:2308.03869v1 [cs.IR])

    [http://arxiv.org/abs/2308.03869](http://arxiv.org/abs/2308.03869)

    本文介绍了一种识别和利用电子商务查询等价性的框架，以提升搜索者和商业结果。该框架解决了将查询映射为搜索意图向量表示、识别等价或相似意图的最近邻查询以及优化用户或商业目标等三个关键问题。通过表面相似性和行为相似性来确定查询的等价性。

    

    电子商务搜索中，查询变化会带来挑战，因为相同的搜索意图可以通过具有表层差异的不同查询来表达。本文介绍了一个框架来识别和利用查询等价性以提升搜索者和商业结果。所提出的方法解决了三个关键问题：将查询映射到搜索意图的向量表示，识别表达等价或相似意图的最近邻查询，以及优化用户或商业目标。该框架利用表面相似性和行为相似性来确定查询的等价性。表面相似性涉及基于词的变形、词序、复合和噪声词来规范化查询。行为相似性利用历史搜索行为生成查询意图的向量表示。离线过程用于训练句子相似性模型，而在线最近邻方法支持对未见查询的处理。

    Search query variation poses a challenge in e-commerce search, as equivalent search intents can be expressed through different queries with surface-level differences. This paper introduces a framework to recognize and leverage query equivalence to enhance searcher and business outcomes. The proposed approach addresses three key problems: mapping queries to vector representations of search intent, identifying nearest neighbor queries expressing equivalent or similar intent, and optimizing for user or business objectives. The framework utilizes both surface similarity and behavioral similarity to determine query equivalence. Surface similarity involves canonicalizing queries based on word inflection, word order, compounding, and noise words. Behavioral similarity leverages historical search behavior to generate vector representations of query intent. An offline process is used to train a sentence similarity model, while an online nearest neighbor approach supports processing of unseen qu
    
[^74]: 通过声明式众包重新审视提示工程

    Revisiting Prompt Engineering via Declarative Crowdsourcing. (arXiv:2308.03854v1 [cs.DB])

    [http://arxiv.org/abs/2308.03854](http://arxiv.org/abs/2308.03854)

    本研究通过借鉴声明式众包的思想，提出了一种声明式提示工程的方法，旨在解决大型语言模型在数据处理中的质量优化和成本控制问题。

    

    大型语言模型(LLM)在理解和生成文本数据方面具有极大的能力，但也容易脆弱和错误。近年来涌现了以所谓的提示工程为中心的工具包和技术方法，通过一系列提示向LLM提出要求。然而，在LLM驱动的数据处理工作流中，优化质量并保持成本有限是一项繁琐的手动过程。我们提出了一个声明式提示工程的愿景。我们将LLM视为众包工人，并借鉴了声明式众包文献中的思想，包括利用多种提示策略，确保内部一致性以及探索混合LLM非LLM方法，以使提示工程过程更加原则性。对排序、实体解析和插补的初步案例研究展示了我们方法的潜力。

    Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach
    
[^75]: 使用JinaAI构建音乐行业的搜索引擎和推荐系统

    Search Engine and Recommendation System for the Music Industry built with JinaAI. (arXiv:2308.03842v1 [cs.LG])

    [http://arxiv.org/abs/2308.03842](http://arxiv.org/abs/2308.03842)

    该论文介绍了使用JinaAI构建音乐行业的搜索引擎和推荐系统的研究，通过匹配歌曲歌词和提供准确的搜索结果来解决现有搜索引擎的问题。

    

    关于音乐行业中搜索引擎和基于推荐的系统的发展是一个最引人注目的辩论之一。研究表明，在搜索引擎领域存在着严重的抑郁，这是由于诸如速度、准确性以及查询数据的格式等令人担忧的因素所导致的。人们经常在仅根据标题搜索歌曲时遇到困难，因此提出了一种解决方案，通过单个查询输入完成搜索分析，并与数据库中的歌曲歌词进行匹配。因此，引入前沿技术工具以开发用户友好的搜索引擎至关重要。Jina AI是用于构建神经搜索引擎的MLOps框架，它被用于帮助用户获得准确的结果。Jina AI有效地帮助维护和提升搜索引擎对给定查询的性能质量。通过使用JinaAI构建了一个高效的音乐行业搜索引擎和推荐系统。

    One of the most intriguing debates regarding a novel task is the development of search engines and recommendation-based systems in the music industry. Studies have shown a drastic depression in the search engine fields, due to concerning factors such as speed, accuracy and the format of data given for querying. Often people face difficulty in searching for a song solely based on the title, hence a solution is proposed to complete a search analysis through a single query input and is matched with the lyrics of the songs present in the database. Hence it is essential to incorporate cutting-edge technology tools for developing a user-friendly search engine. Jina AI is an MLOps framework for building neural search engines that are utilized, in order for the user to obtain accurate results. Jina AI effectively helps to maintain and enhance the quality of performance for the search engine for the query given. An effective search engine and a recommendation system for the music industry, buil
    
[^76]: 对大规模语言模型中野外越狱提示的特征化和评估

    "Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models. (arXiv:2308.03825v1 [cs.CR])

    [http://arxiv.org/abs/2308.03825](http://arxiv.org/abs/2308.03825)

    本文对大规模语言模型中的越狱提示进行了特征化和评估研究。通过测量野外越狱提示的唯一特征和主要攻击策略，我们发现越狱提示越来越多地从公共平台转移到私人平台，给LLM供应商在主动检测方面带来了新的挑战。

    

    大型语言模型（LLM）的滥用已引起了公众和LLM供应商的重视。为了回应这一问题，一些努力已经被做出来，使LLM与人类价值观和意图一致。然而，一种特定类型的对抗性提示，即越狱提示，已经出现并不断演变以绕过保障并引发LLM中的有害内容。本文中，我们首次对野外越狱提示进行了测量研究，收集了6,387个在六个月内从四个平台上获得的提示。通过利用自然语言处理技术和基于图的社区检测方法，我们发现了越狱提示的独特特征及其主要攻击策略，如提示注入和权限提升。我们还观察到，越狱提示越来越多地从公共平台转移到私人平台，给LLM供应商在主动检测方面带来了新的挑战。为了评估越狱提示可能造成的危害，我们创建了

    The misuse of large language models (LLMs) has garnered significant attention from the general public and LLM vendors. In response, efforts have been made to align LLMs with human values and intent use. However, a particular type of adversarial prompts, known as jailbreak prompt, has emerged and continuously evolved to bypass the safeguards and elicit harmful content from LLMs. In this paper, we conduct the first measurement study on jailbreak prompts in the wild, with 6,387 prompts collected from four platforms over six months. Leveraging natural language processing technologies and graph-based community detection methods, we discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from public platforms to private ones, posing new challenges for LLM vendors in proactive detection. To assess the potential harm caused by jailbreak prompts, we create
    
[^77]: 基于数据预算的分布鲁棒分类

    Distributionally Robust Classification on a Data Budget. (arXiv:2308.03821v1 [cs.CV])

    [http://arxiv.org/abs/2308.03821](http://arxiv.org/abs/2308.03821)

    本研究介绍了一种基于数据预算的分布鲁棒分类方法，在有限的数据情况下，通过精心设计的训练集和控制实验，证明了在240万个图像样本上的训练可以获得与在4亿个图像样本上训练相媲美的鲁棒性。

    

    深度学习在现实世界的应用中需要在分布转变下具有可预测的模型行为。像CLIP这样的模型展现出了与人类相媲美的自然分布鲁棒性，但可能需要数亿个训练样本。我们能否在数据有限的领域训练鲁棒的学习者？为了严格回答这个问题，我们引入了JANuS（联合注释和名称集），这是一个包含图像、标签和相应标题的四个新训练数据集，然后通过一系列精心控制的调查研究了影响图像分类鲁棒性的因素，并将这些结果与大规模元分析的发现进行了比较。通过这种方法，我们证明了在240万个图像样本的交叉熵损失上训练的标准ResNet-50可以达到与在4亿个样本上训练的CLIP ResNet-50相媲美的鲁棒性。据我们所知，这是首次展示（接近）最先进的分布鲁棒性的结果。

    Real world uses of deep learning require predictable model behavior under distribution shifts. Models such as CLIP show emergent natural distributional robustness comparable to humans, but may require hundreds of millions of training samples. Can we train robust learners in a domain where data is limited? To rigorously address this question, we introduce JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and perform a series of carefully controlled investigations of factors contributing to robustness in image classification, then compare those results to findings derived from a large-scale meta-analysis. Using this approach, we show that standard ResNet-50 trained with the cross-entropy loss on 2.4 million image samples can attain comparable robustness to a CLIP ResNet-50 trained on 400 million samples. To our knowledge, this is the first result showing (near) state-of-the-art distributional robustness on
    
[^78]: XFlow: 在图上评估流行为的基准测试

    XFlow: Benchmarking Flow Behaviors over Graphs. (arXiv:2308.03819v1 [cs.SI])

    [http://arxiv.org/abs/2308.03819](http://arxiv.org/abs/2308.03819)

    XFlow是一种在图上评估流行为的基准测试方法，解决了流动行为的理解和算法评估的问题。

    

    图上的扩散现象是普遍而重要的，例如谣言传播、类似流感病毒的传播、智能电网故障等。理解流动行为是一项艰巨的任务，因为种子的分布、传播模型和图的拓扑之间存在复杂的相互作用。网络研究涵盖了数学、物理、社会科学和计算机科学等多个学科领域。这种跨学科的特性使得网络研究具有高度专业化和分割，由此带来的合作是不足够的。从机器学习的角度来看，目前缺乏一个统一的平台来评估不同领域的算法。当前研究在该领域的一个主要障碍是缺乏一个全面的策划好的基准测试套件来研究流动行为。

    The occurrence of diffusion on a graph is a prevalent and significant phenomenon, as evidenced by the spread of rumors, influenza-like viruses, smart grid failures, and similar events. Comprehending the behaviors of flow is a formidable task, due to the intricate interplay between the distribution of seeds that initiate flow propagation, the propagation model, and the topology of the graph. The study of networks encompasses a diverse range of academic disciplines, including mathematics, physics, social science, and computer science. This interdisciplinary nature of network research is characterized by a high degree of specialization and compartmentalization, and the cooperation facilitated by them is inadequate. From a machine learning standpoint, there is a deficiency in a cohesive platform for assessing algorithms across various domains. One of the primary obstacles to current research in this field is the absence of a comprehensive curated benchmark suite to study the flow behaviors
    
[^79]: 基于稀疏编码的逆问题方法及在微波断层成像中的应用

    A sparse coding approach to inverse problems with application to microwave tomography imaging. (arXiv:2308.03818v1 [eess.IV])

    [http://arxiv.org/abs/2308.03818](http://arxiv.org/abs/2308.03818)

    本文介绍了基于稀疏编码的逆问题方法，并将其应用于微波断层成像，为现有算法的改进提供了可能。

    

    在科学和技术的多个领域中，我们会遇到一些不适定的逆问题图像，这些领域包括医学诊断和天文研究等。为了从不完整和失真的数据中重建图像，需要创建算法，可以同时考虑生成这些测量的物理机制和所分析图像的本质特性。本文回顾了图像的稀疏表示，它是受哺乳动物视觉系统启发的一种实际、紧凑和有效的生成模型。通过在大量图像集上训练这个模型，我们可以解决不适定的线性逆问题。此外，我们将稀疏编码的应用扩展到解决微波断层成像中的非线性和不适定问题，这可能会显著改进现有的算法水平。

    Inverse imaging problems that are ill-posed can be encountered across multiple domains of science and technology, ranging from medical diagnosis to astronomical studies. To reconstruct images from incomplete and distorted data, it is necessary to create algorithms that can take into account both, the physical mechanisms responsible for generating these measurements and the intrinsic characteristics of the images being analyzed. In this work, the sparse representation of images is reviewed, which is a realistic, compact and effective generative model for natural images inspired by the visual system of mammals. It enables us to address ill-posed linear inverse problems by training the model on a vast collection of images. Moreover, we extend the application of sparse coding to solve the non-linear and ill-posed problem in microwave tomography imaging, which could lead to a significant improvement of the state-of-the-arts algorithms.
    
[^80]: 通过迭代的低分辨率点云完成变换器进行高分辨率颅缺损重建

    High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers. (arXiv:2308.03813v1 [eess.IV])

    [http://arxiv.org/abs/2308.03813](http://arxiv.org/abs/2308.03813)

    该论文提出了一种新的方法来增加个性化颅骨重建的可用性，通过点云完成任务实现高分辨率颅缺损重建，并在训练和推理过程中快速且资源高效。

    

    每年都有成千上万的人遭受各种类型的颅骨伤害，需要个性化植入物，手工设计昂贵且费时。因此，一个自动化的专用系统来增加个性化颅骨重建的可用性非常有必要。自动颅骨缺损重建的问题可以被描述为形状完成任务，并使用专用深度网络来解决。目前，最常见的方法是使用体积表示法并应用于图像分割的深度网络。然而，这种方法存在一些限制，不能很好地适应高分辨率体积，并没有考虑到数据的稀疏性。在我们的工作中，我们将问题重新表述为点云完成任务。我们提出了一种迭代的基于变换器的方法，可以在任何分辨率下重建颅缺损，并在训练和推理过程中快速且资源高效。我们比较了所提出的方法。

    Each year thousands of people suffer from various types of cranial injuries and require personalized implants whose manual design is expensive and time-consuming. Therefore, an automatic, dedicated system to increase the availability of personalized cranial reconstruction is highly desirable. The problem of the automatic cranial defect reconstruction can be formulated as the shape completion task and solved using dedicated deep networks. Currently, the most common approach is to use the volumetric representation and apply deep networks dedicated to image segmentation. However, this approach has several limitations and does not scale well into high-resolution volumes, nor takes into account the data sparsity. In our work, we reformulate the problem into a point cloud completion task. We propose an iterative, transformer-based method to reconstruct the cranial defect at any resolution while also being fast and resource-efficient during training and inference. We compare the proposed meth
    
[^81]: 非紧致统一逼近

    Noncompact uniform universal approximation. (arXiv:2308.03812v1 [cs.LG])

    [http://arxiv.org/abs/2308.03812](http://arxiv.org/abs/2308.03812)

    这篇论文将通用逼近定理推广到非紧致输入空间，并确定了在有界激活函数条件下可以通过神经网络一致逼近的函数类别，并提出了代数结构的意外结果。

    

    将通用逼近定理推广到在（非紧致）输入空间 \(\mathbb R^n\) 上的一致收敛。所有在无穷远处为零的连续函数都可以用具有一个隐藏层的神经网络进行一致逼近，对于所有具有渐近线性行为的连续激活函数 \(\varphi\neq0\)。当 \(\varphi\) 还被限制在有界时，我们准确确定了哪些函数可以通过神经网络进行一致逼近，得到了以下意想不到的结果。让 \(\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}\) 表示可以通过具有 \(l\) 个隐藏层和 \(n\) 个输入的神经网络进行一致逼近的函数的向量空间。对于所有的 \(n\) 和所有的 \(l\geq2\)，\(\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}\) 在逐点乘积下是一个代数。如果 \(\varphi\) 的左极限不等于其右极限（例如，当 \(\varphi\) 是sigmoid函数时），代数 \(\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}\)（\(l\geq2\)）会产生一些意外的结果。

    The universal approximation theorem is generalised to uniform convergence on the (noncompact) input space $\mathbb R^n$. All continuous functions that vanish at infinity can be uniformly approximated by neural networks with one hidden layer, for all continuous activation functions $\varphi\neq0$ with asymptotically linear behaviour at $\pm\infty$. When $\varphi$ is moreover bounded, we exactly determine which functions can be uniformly approximated by neural networks, with the following unexpected results. Let $\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ denote the vector space of functions that are uniformly approximable by neural networks with $l$ hidden layers and $n$ inputs. For all $n$ and all $l\geq2$, $\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ turns out to be an algebra under the pointwise product. If the left limit of $\varphi$ differs from its right limit (for instance, when $\varphi$ is sigmoidal) the algebra $\overline{\mathcal{N}_\varphi^l(\mathbb R^n)}$ ($l\geq2$) 
    
[^82]: 非凸双层优化和时变目标函数

    Non-Convex Bilevel Optimization with Time-Varying Objective Functions. (arXiv:2308.03811v1 [math.OC])

    [http://arxiv.org/abs/2308.03811](http://arxiv.org/abs/2308.03811)

    本论文研究了在线双层优化问题，提出了一种基于窗口平均的单循环在线双层优化器（SOBOW），它能在处理函数变化和真实超梯度不可用的情况下高效更新决策。

    

    双层优化已经成为机器学习问题中的一个强大工具，然而，当前的非凸双层优化考虑的是离线数据集和静态函数，在新兴的在线应用中，这可能无法很好地处理流式数据和时变函数。在这项工作中，我们研究了在线双层优化（OBO），其中函数可以时变，并且代理不断根据在线流数据更新决策。为了处理OBO中的函数变化和真实超梯度不可用的问题，我们提出了一种基于窗口平均的单循环在线双层优化器（SOBOW），它根据内层窗口平均的最近超梯度估计值来更新外层的决策。与现有算法相比，SOBOW计算效率高，并且不需要知道先前的函数。为了处理单循环更新和函数变化带来的独特技术困难，我们还提出了一种深度学习方法，重点是通过增加稀疏性以及结构和全局信息来减少预测误差。

    Bilevel optimization has become a powerful tool in a wide variety of machine learning problems. However, the current nonconvex bilevel optimization considers an offline dataset and static functions, which may not work well in emerging online applications with streaming data and time-varying functions. In this work, we study online bilevel optimization (OBO) where the functions can be time-varying and the agent continuously updates the decisions with online streaming data. To deal with the function variations and the unavailability of the true hypergradients in OBO, we propose a single-loop online bilevel optimizer with window averaging (SOBOW), which updates the outer-level decision based on a window average of the most recent hypergradient estimations stored in the memory. Compared to existing algorithms, SOBOW is computationally efficient and does not need to know previous functions. To handle the unique technical difficulties rooted in single-loop update and function variations for 
    
[^83]: AdaER: 一种用于连续终身学习的自适应经验重播方法

    AdaER: An Adaptive Experience Replay Approach for Continual Lifelong Learning. (arXiv:2308.03810v1 [cs.LG])

    [http://arxiv.org/abs/2308.03810](http://arxiv.org/abs/2308.03810)

    AdaER是一种自适应经验重播方法，用于解决连续终身学习中的灾难性遗忘问题。它采用上下文提示的记忆回忆策略，选择性地重播最冲突的记忆。

    

    连续终身学习是一种受人类学习启发的机器学习框架，学习者会以顺序方式持续获取新知识。然而，流式训练数据的非稳态性给这个过程带来了一个重要挑战，即灾难性遗忘，指的是在引入新任务时快速遗忘先前学习的知识。虽然一些方法，如经验重播(ER)，已被提出来缓解这个问题，但它们的性能仍然有限，尤其在增量分类场景中，这被认为是自然而极具挑战性的。在本文中，我们提出了一种新颖的算法，称为自适应经验重播(AdaER)，以解决连续终身学习的挑战。AdaER包括两个阶段：记忆重播和记忆更新。在记忆重播阶段，AdaER引入了一种上下文提示的记忆回忆策略(C-CMR)，选择性地重播最冲突的记忆。

    Continual lifelong learning is an machine learning framework inspired by human learning, where learners are trained to continuously acquire new knowledge in a sequential manner. However, the non-stationary nature of streaming training data poses a significant challenge known as catastrophic forgetting, which refers to the rapid forgetting of previously learned knowledge when new tasks are introduced. While some approaches, such as experience replay (ER), have been proposed to mitigate this issue, their performance remains limited, particularly in the class-incremental scenario which is considered natural and highly challenging. In this paper, we present a novel algorithm, called adaptive-experience replay (AdaER), to address the challenge of continual lifelong learning. AdaER consists of two stages: memory replay and memory update. In the memory replay stage, AdaER introduces a contextually-cued memory recall (C-CMR) strategy, which selectively replays memories that are most conflictin
    
[^84]: Nest-DGIL: Nesterov优化的深度几何增量学习用于CS图像重构

    Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction. (arXiv:2308.03807v1 [eess.IV])

    [http://arxiv.org/abs/2308.03807](http://arxiv.org/abs/2308.03807)

    提出了一种基于第二Nesterov近端梯度优化的深度几何增量学习框架，能够在图像重建时减轻伪影，同时实现快速收敛。

    

    近端梯度优化是解决图像反问题的常用策略之一，易于实现。然而，这些技术在图像重构中通常会产生严重的伪影。一种常用的改进方法是通过微调正则化参数来减轻这些伪影，但由于增加了计算成本，这种方法并不总是足够或适用。在这项工作中，我们提出了一种基于第二Nesterov近端梯度优化的深度几何增量学习框架。所提出的端到端网络不仅具有对高/低频图像特征的强大学习能力，还可以在初步线性重建中从理论上保证几何纹理细节的重建。此外，它可以避免中间重建结果超出几何分解域的风险，并实现快速收敛。我们的重建框架被分解为两个子问题:图像初步线性重建和深度增量学习。

    Proximal gradient-based optimization is one of the most common strategies for solving image inverse problems as well as easy to implement. However, these techniques often generate heavy artifacts in image reconstruction. One of the most popular refinement methods is to fine-tune the regularization parameter to alleviate such artifacts, but it may not always be sufficient or applicable due to increased computational costs. In this work, we propose a deep geometric incremental learning framework based on second Nesterov proximal gradient optimization. The proposed end-to-end network not only has the powerful learning ability for high/low frequency image features,but also can theoretically guarantee that geometric texture details will be reconstructed from preliminary linear reconstruction.Furthermore, it can avoid the risk of intermediate reconstruction results falling outside the geometric decomposition domains and achieve fast convergence. Our reconstruction framework is decomposed int
    
[^85]: 通过可穿戴设备进行人体活动分析的弱监督多任务表示学习

    Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables. (arXiv:2308.03805v1 [cs.LG])

    [http://arxiv.org/abs/2308.03805](http://arxiv.org/abs/2308.03805)

    提出了一种使用弱监督多任务表示学习的方法，通过将数据映射到多个表示空间并根据多个方面对数据进行聚类，实现了同时解决多个任务的能力。

    

    来自可穿戴设备和智能环境的传感器数据流在人体活动识别（HAR）、人员识别或健康监测等领域得到广泛研究。然而，在活动和传感器流分析方面的大部分先前工作都侧重于数据的某一方面，例如仅识别活动类型或仅识别执行活动的人员。相反，我们提出一种方法，该方法使用弱监督的多输出孪生网络，学习将数据映射到多个表示空间，其中每个表示空间侧重于数据的一个方面。数据样本的表示向量在空间中的位置使得在该方面具有相同语义意义的数据彼此靠近。因此，正如一系列实验所证明的那样，训练好的模型可以基于多个方面为数据聚类提供度量指标，从而使其能够同时解决多个任务。

    Sensor data streams from wearable devices and smart environments are widely studied in areas like human activity recognition (HAR), person identification, or health monitoring. However, most of the previous works in activity and sensor stream analysis have been focusing on one aspect of the data, e.g. only recognizing the type of the activity or only identifying the person who performed the activity. We instead propose an approach that uses a weakly supervised multi-output siamese network that learns to map the data into multiple representation spaces, where each representation space focuses on one aspect of the data. The representation vectors of the data samples are positioned in the space such that the data with the same semantic meaning in that aspect are closely located to each other. Therefore, as demonstrated with a set of experiments, the trained model can provide metrics for clustering data based on multiple aspects, allowing it to address multiple tasks simultaneously and eve
    
[^86]: 金融欺诈检测的文本数据挖掘：一种深度学习方法

    Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach. (arXiv:2308.03800v1 [cs.CL])

    [http://arxiv.org/abs/2308.03800](http://arxiv.org/abs/2308.03800)

    该论文提出了一种深度学习方法，用于分析金融欺诈文本并进行分类。通过比较多种神经网络模型的准确性，该研究对金融欺诈检测具有重要意义

    

    在本报告中，我提出了一种深度学习方法，用于进行自然语言处理（以下简称NLP）的二元分类任务，以分析金融欺诈文本。首先，我搜索了港交所新闻的监管公告和执法公告，以定义欺诈公司并提取其MD＆A报告，然后整理了报告中的句子，并标记了报告时间。我的方法包括各种神经网络模型，包括具有嵌入层的多层感知器（MLP），基本循环神经网络（RNN），长短期记忆（LSTM）和门限循环单元（GRU）用于文本分类任务。通过利用这个多样化的模型集合，我旨在全面比较它们在检测金融欺诈方面的准确性。我的结果对于金融欺诈检测具有重要意义，因为这项工作为深度学习，NLP和金融交叉研究的不断增长贡献了有价值的研究成果

    In this report, I present a deep learning approach to conduct a natural language processing (hereafter NLP) binary classification task for analyzing financial-fraud texts. First, I searched for regulatory announcements and enforcement bulletins from HKEX news to define fraudulent companies and to extract their MD&A reports before I organized the sentences from the reports with labels and reporting time. My methodology involved different kinds of neural network models, including Multilayer Perceptrons with Embedding layers, vanilla Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM), and Gated Recurrent Unit (GRU) for the text classification task. By utilizing this diverse set of models, I aim to perform a comprehensive comparison of their accuracy in detecting financial fraud. My results bring significant implications for financial fraud detection as this work contributes to the growing body of research at the intersection of deep learning, NLP, and finance, providing valuabl
    
[^87]: 多重攻击: 多张图像+相同的对抗攻击 -> 多个目标标签

    Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels. (arXiv:2308.03792v1 [cs.CV])

    [http://arxiv.org/abs/2308.03792](http://arxiv.org/abs/2308.03792)

    本文展示了通过设计一个单一的对抗扰动P，在多个图像上实现将其原始类别改变为不同目标类别的多重攻击。研究发现在像素空间中存在大量高类别置信度的区域，对全面的防御策略构成重要挑战。

    

    我们展示了一个简单的对抗扰动P可以将n个图像X1，X2，...，Xn从原始的未受扰动的类别c1，c2，...，cn改变为期望的（不一定相同的）类别c^*_1，c^*_2，...，c^*_n。我们称之为"多重攻击"。在不同条件下，如图像分辨率等，我们估计在像素空间中某个图像周围存在高类别置信度的区域数量大约为10^（O（100）），这对于全面的防御策略构成了重要挑战。我们展示了几个立即产生的影响：根据强度改变结果类别的对抗攻击，以及与尺度无关的对抗样本。为了展示像素空间中类别决策边界的冗余和丰富性，我们寻找了其在二维平面上追踪图像和拼写的部分。

    We show that we can easily design a single adversarial perturbation $P$ that changes the class of $n$ images $X_1,X_2,\dots,X_n$ from their original, unperturbed classes $c_1, c_2,\dots,c_n$ to desired (not necessarily all the same) classes $c^*_1,c^*_2,\dots,c^*_n$ for up to hundreds of images and target classes at once. We call these \textit{multi-attacks}. Characterizing the maximum $n$ we can achieve under different conditions such as image resolution, we estimate the number of regions of high class confidence around a particular image in the space of pixels to be around $10^{\mathcal{O}(100)}$, posing a significant problem for exhaustive defense strategies. We show several immediate consequences of this: adversarial attacks that change the resulting class based on their intensity, and scale-independent adversarial examples. To demonstrate the redundancy and richness of class decision boundaries in the pixel space, we look for its two-dimensional sections that trace images and spel
    
[^88]: Bio+Clinical BERT、BERT Base和CNN在预测药物评论满意度方面的性能比较

    Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction. (arXiv:2308.03782v1 [cs.CL])

    [http://arxiv.org/abs/2308.03782](http://arxiv.org/abs/2308.03782)

    该研究比较了Bio+Clinical BERT、BERT Base和CNN在预测药物评价满意度方面的性能，结果显示医学领域特定的Bio+Clinical BERT模型在整体性能上优于通用领域的BERT Base模型，提高了11%的Macro F1和召回率得分。

    

    该研究的目标是开发能够分析患者药物评论并准确分类满意程度为积极、中性或消极的自然语言处理（NLP）模型。这样的模型将减轻医疗保健专业人员的工作负担，并提供更多关于患者生活质量的见解，这是治疗效果的重要指标。为了实现这一目标，我们实施和评估了多个分类模型，包括BERT base模型、Bio+Clinical BERT以及一个更简单的CNN。结果表明，医学领域特定的Bio+Clinical BERT模型在整体性能上显著优于通用领域的BERT base模型，如表2所示，它在Macro F1和召回率得分上提升了11%。未来的研究可以探索如何充分利用每个模型的特定优势。Bio+Clinical BERT在整体性能上表现出色，特别是在处理医学行话方面，而更简单的CNN则展现出识别关键词和上下文的能力。

    The objective of this study is to develop natural language processing (NLP) models that can analyze patients' drug reviews and accurately classify their satisfaction levels as positive, neutral, or negative. Such models would reduce the workload of healthcare professionals and provide greater insight into patients' quality of life, which is a critical indicator of treatment effectiveness. To achieve this, we implemented and evaluated several classification models, including a BERT base model, Bio+Clinical BERT, and a simpler CNN. Results indicate that the medical domain-specific Bio+Clinical BERT model significantly outperformed the general domain base BERT model, achieving macro f1 and recall score improvement of 11%, as shown in Table 2. Future research could explore how to capitalize on the specific strengths of each model. Bio+Clinical BERT excels in overall performance, particularly with medical jargon, while the simpler CNN demonstrates the ability to identify crucial words and a
    
[^89]: 属性概率图生成模型的拟合优度研究

    Goodness-of-Fit of Attributed Probabilistic Graph Generative Models. (arXiv:2308.03773v1 [cs.LG])

    [http://arxiv.org/abs/2308.03773](http://arxiv.org/abs/2308.03773)

    本文研究了属性概率图生成模型的拟合优度，并以均方互信息系数为指标进行了评估和验证。

    

    图的概率生成模型是能够进行表示和抽样的重要工具。许多最近的研究已经创建了能够表示实体间相互作用和属性的图的概率模型。然而，对于一个随机属性图的生成模型，确定其拟合优度的一般条件并不明确。在本文中，我们以随机二进制网络的均方互信息系数为基准来定义拟合优度。对于这个统计量，我们概述了一种用于评估学习到的属性图结构质量的过程，确保均方互信息系数的偏差最小，并且高概率下保持恒定或随机。我们将这些准则应用于验证概率生成模型在各种流行的图模型中的表示能力。

    Probabilistic generative models of graphs are important tools that enable representation and sampling. Many recent works have created probabilistic models of graphs that are capable of representing not only entity interactions but also their attributes. However, given a generative model of random attributed graph(s), the general conditions that establish goodness of fit are not clear a-priori. In this paper, we define goodness of fit in terms of the mean square contingency coefficient for random binary networks. For this statistic, we outline a procedure for assessing the quality of the structure of a learned attributed graph by ensuring that the discrepancy of the mean square contingency coefficient (constant, or random) is minimal with high probability. We apply these criteria to verify the representation capability of a probabilistic generative model for various popular types of graph models.
    
[^90]: 使用伪深度和融合技术改进神经光辐射场

    Improved Neural Radiance Fields Using Pseudo-depth and Fusion. (arXiv:2308.03772v1 [cs.CV])

    [http://arxiv.org/abs/2308.03772](http://arxiv.org/abs/2308.03772)

    本文提出了一种改进神经光辐射场的方法，通过构建多尺度编码体和提供多尺度几何信息，同时进行深度预测和辐射场重建，以实现对真实场景中物体的准确建模和视角合成。

    

    自从神经光辐射场技术问世以来，新颖的视角合成引起了广泛的关注。现有的辐射场重建通常通过从附近的源图像中构建一个编码体作为额外的输入来实现。然而，这些方法无法有效地编码真实场景中各种规模的物体/结构的几何信息。本文提出了构建多尺度编码体并为NeRF模型提供多尺度几何信息的方法。为使构建的编码体尽可能接近场景中物体的表面和渲染深度更准确，我们提出同时进行深度预测和辐射场重建。预测的深度图将用于监督渲染深度、缩小深度范围并引导点采样。最后，由于遮挡、光照等原因，点体特征中包含的几何信息可能不准确。

    Since the advent of Neural Radiance Fields, novel view synthesis has received tremendous attention. The existing approach for the generalization of radiance field reconstruction primarily constructs an encoding volume from nearby source images as additional inputs. However, these approaches cannot efficiently encode the geometric information of real scenes with various scale objects/structures. In this work, we propose constructing multi-scale encoding volumes and providing multi-scale geometry information to NeRF models. To make the constructed volumes as close as possible to the surfaces of objects in the scene and the rendered depth more accurate, we propose to perform depth prediction and radiance field reconstruction simultaneously. The predicted depth map will be used to supervise the rendered depth, narrow the depth range, and guide points sampling. Finally, the geometric information contained in point volume features may be inaccurate due to occlusion, lighting, etc. To this en
    
[^91]: 将机器学习应用于建模和分析动力系统的应用

    Applications of Machine Learning to Modelling and Analysing Dynamical Systems. (arXiv:2308.03763v1 [cs.LG])

    [http://arxiv.org/abs/2308.03763](http://arxiv.org/abs/2308.03763)

    本论文介绍了将机器学习应用于模拟和分析动力系统的方法，并提出了一种结合了哈密顿神经网络结构的可调节辛形状神经网络的架构，该架构在预测动力学时保留了哈密顿方程和相空间的辛结构。这种方法在预测哈密顿动力学中表现出很高的精确性和鲁棒性。

    

    我们探索了使用物理信息神经网络来分析具有运动第一积分的非线性哈密顿动力系统。在这项工作中，我们提出了一种将现有的哈密顿神经网络结构结合到可调节的辛形状神经网络中的方法，该方法在预测整个参数空间的动力学时保留了哈密顿方程和相空间的辛结构。我们发现，这种架构在预测哈密顿动力学，特别是包含多个参数的势能下，显著优于之前提出的神经网络。我们使用非线性的Henon-Heiles势能在混沌、准周期和周期条件下证明了其鲁棒性。我们试图利用神经网络的高维非线性能力来预测仅凭部分信息即可获取哈密顿系统的动力学。

    We explore the use of Physics Informed Neural Networks to analyse nonlinear Hamiltonian Dynamical Systems with a first integral of motion. In this work, we propose an architecture which combines existing Hamiltonian Neural Network structures into Adaptable Symplectic Recurrent Neural Networks which preserve Hamilton's equations as well as the symplectic structure of phase space while predicting dynamics for the entire parameter space. This architecture is found to significantly outperform previously proposed neural networks when predicting Hamiltonian dynamics especially in potentials which contain multiple parameters. We demonstrate its robustness using the nonlinear Henon-Heiles potential under chaotic, quasiperiodic and periodic conditions.  The second problem we tackle is whether we can use the high dimensional nonlinear capabilities of neural networks to predict the dynamics of a Hamiltonian system given only partial information of the same. Hence we attempt to take advantage of L
    
[^92]: 随机算法用于精确测量差分隐私的个性化推荐

    Randomized algorithms for precise measurement of differentially-private, personalized recommendations. (arXiv:2308.03735v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2308.03735](http://arxiv.org/abs/2308.03735)

    这项研究提出了一种随机算法，用于精确测量差分隐私的个性化推荐。通过离线实验，该算法在关键指标上与私密的非个性化和非私密的个性化实现进行了比较。

    

    个性化推荐是当今互联网生态系统的重要组成部分，它帮助艺术家和创作者吸引感兴趣的用户，同时也帮助用户发现新的有趣内容。然而，由于个人数据和数据隐私的历史上粗心对待，许多用户对个性化推荐平台持怀疑态度。现在，依赖于个性化推荐的企业正进入一个新的范例，需要对他们的系统进行改进，以保护隐私。本文提出了一种个性化推荐算法，既可以实现精确测量，又可以保护差分隐私。我们以广告为例应用，并进行离线实验，量化提出的隐私保护算法对用户体验、广告商价值和平台收入等关键指标的影响，与（私密的）非个性化和非私密的个性化实现的极端情况进行对比。

    Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content. However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy. Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first. In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement. We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations.
    
[^93]: 分布式图像语义无线传输的通信高效框架

    Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission. (arXiv:2308.03713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.03713](http://arxiv.org/abs/2308.03713)

    本文提出了一个基于联邦学习的语义通信框架，用于多任务分布式图像传输，通过全局聚合改进了语义提取和任务性能。

    

    多节点通信在物联网场景中引起了广泛关注，但其庞大的数据流量和任务扩展的不灵活性，促使了对通信高效的分布式数据传输框架的迫切需求。本文针对物联网设备的多任务分布式图像传输，提出了基于联邦学习的语义通信（FLSC）框架。联邦学习通过全局聚合，实现了每个用户独立的语义通信链路设计，同时进一步提高了语义提取和任务性能。FLSC中的每个链路由基于层次视觉变换器（HVT）的提取器和根据特定内容进行粗到细的语义提取和意义转换的任务自适应翻译器组成。

    Multi-node communication, which refers to the interaction among multiple devices, has attracted lots of attention in many Internet-of-Things (IoT) scenarios. However, its huge amounts of data flows and inflexibility for task extension have triggered the urgent requirement of communication-efficient distributed data transmission frameworks. In this paper, inspired by the great superiorities on bandwidth reduction and task adaptation of semantic communications, we propose a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices. Federated learning enables the design of independent semantic communication link of each user while further improves the semantic extraction and task performance through global aggregation. Each link in FLSC is composed of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation according to specific
    
[^94]: MedMine: 检验预训练语言模型在药物挖掘中的应用

    MedMine: Examining Pre-trained Language Models on Medication Mining. (arXiv:2308.03629v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03629](http://arxiv.org/abs/2308.03629)

    MedMine通过检验预训练语言模型在药物挖掘中的应用，发现了它们在不同实体类型和临床事件上的不平衡表现，并提供了解决这些问题的研究方向。

    

    自动从临床和生物医学文本中进行药物挖掘已成为一个热门话题，这是由于其对医疗应用的真实影响以及强大语言模型的最新发展。然而，全自动提取模型仍然面临一些障碍，以便可以直接部署到临床实践中以获得更好的影响。这些障碍包括它们在不同实体类型和临床事件上的不平衡表现。在本研究中，我们通过微调，包括基于单语言模型Med7和多语言大型语言模型XLM-RoBERTa的方式，检验了当前最先进的预训练语言模型在这些任务上的表现。我们使用n2c2-2018挑战赛的历史药物挖掘共享任务数据集进行了它们的优劣比较。我们报告了这些微调实验的结果，以便促进未来研究解决这些问题，比如如何结合它们的输出，合并这些模型，或者改进其性能。

    Automatic medication mining from clinical and biomedical text has become a popular topic due to its real impact on healthcare applications and the recent development of powerful language models (LMs). However, fully-automatic extraction models still face obstacles to be overcome such that they can be deployed directly into clinical practice for better impacts. Such obstacles include their imbalanced performances on different entity types and clinical events. In this work, we examine current state-of-the-art pre-trained language models (PLMs) on such tasks, via fine-tuning including the monolingual model Med7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their advantages and drawbacks using historical medication mining shared task data sets from n2c2-2018 challenges. We report the findings we get from these fine-tuning experiments such that they can facilitate future research on addressing them, for instance, how to combine their outputs, merge such models, or impr
    
[^95]: 使用生成对抗网络生成逼真的合成毫米波雷达数据，用于自动驾驶应用

    Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks. (arXiv:2308.02632v1 [cs.CV])

    [http://arxiv.org/abs/2308.02632](http://arxiv.org/abs/2308.02632)

    本研究提出了一种使用生成对抗网络生成合成毫米波雷达数据的快速方法，可以增加数据增强的潜力，并进一步开发雷达数据处理算法。

    

    目前模拟FMCW雷达的主要方法是基于射线追踪，通常计算密集且不能考虑背景噪声。本研究提出了一种更快速的FMCW雷达模拟方法，能够使用生成对抗网络（GAN）生成合成的原始雷达数据。代码和预训练的权重是开源的，并可在GitHub上获得。该方法生成了16个同时的脉冲，可以用于进一步开发用于处理雷达数据（滤波和聚类）的算法。这可以增加数据增强的潜力，例如通过生成在实际生活中不可复现的不存在或安全关键场景的数据。在本研究中，使用摩托车的雷达测量数据对GAN进行训练，并生成摩托车直线行驶的合成原始雷达数据。生成这些数据时，使用了摩托车的距离和高斯噪声作为输入。

    The main approaches for simulating FMCW radar are based on ray tracing, which is usually computationally intensive and do not account for background noise. This work proposes a faster method for FMCW radar simulation capable of generating synthetic raw radar data using generative adversarial networks (GAN). The code and pre-trained weights are open-source and available on GitHub. This method generates 16 simultaneous chirps, which allows the generated data to be used for the further development of algorithms for processing radar data (filtering and clustering). This can increase the potential for data augmentation, e.g., by generating data in non-existent or safety-critical scenarios that are not reproducible in real life. In this work, the GAN was trained with radar measurements of a motorcycle and used to generate synthetic raw radar data of a motorcycle traveling in a straight line. For generating this data, the distance of the motorcycle and Gaussian noise are used as input to the 
    
[^96]: 通过领域适应的最少到最多提示的方式实现文本到SQL的高效泛化

    Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v1 [cs.CL])

    [http://arxiv.org/abs/2308.02582](http://arxiv.org/abs/2308.02582)

    该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。

    

    跨领域和跨组合式的文本到SQL语义解析的泛化是一项具有挑战性的任务。现有的基于大型语言模型（LLM）的解决方案依赖于从训练集中推理出少量样本，以合成每个自然语言（NL）测试查询的运行时提示。与此相反，我们设计了一种算法，该算法通过离线抽样从训练数据中获取少量样本，完全覆盖SQL子句、运算符和函数，并在允许的令牌长度范围内实现最大领域覆盖。这样可以合成一个固定的通用提示（GP），其中包含NL测试查询之间共用的多样化样本集，避免了昂贵的测试时间样本检索。我们还将GP自适应到目标数据库领域（DA-GP），以更好地处理跨领域泛化；然后采用分解的最少到最多提示（LTMP-DA-GP）来处理跨组合泛化。LTMP-DA-GP的合成是离线任务，

    Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to
    
[^97]: 面向自动语音识别的联邦表示学习

    Federated Representation Learning for Automatic Speech Recognition. (arXiv:2308.02013v1 [cs.SD])

    [http://arxiv.org/abs/2308.02013](http://arxiv.org/abs/2308.02013)

    使用联邦学习和自监督学习的结合方法，研究了面向自动语音识别的联邦表示学习，将边缘设备上的隐私数据用于学习健壮的音频表示，并取得了显著的性能改善。

    

    联邦学习（FL）是一种保护隐私的模式，允许边缘设备在不共享数据的情况下进行协作学习。像Alexa和Siri这样的边缘设备是潜在的非标记音频数据来源，可以用来学习健壮的音频表示。在这项工作中，我们将自监督学习（SSL）和FL结合起来，以遵守数据隐私约束条件，学习用于自动语音识别的表示。我们使用未标记的语音数据集Libri-Light中的说话者和章节信息，模拟非独立同分布的说话者隔离数据分布，并使用FedSGD在对比预测编码框架下进行LSTM编码器的预训练。我们展示了在FL中预训练的ASR编码器的性能与中心预训练模型相当，并且相比没有预训练，有12-15%（WER）的改善。我们进一步将联邦预训练模型适应到一种新的语言，法语，并且相比没有预训练，实现了20%（WER）的改善。

    Federated Learning (FL) is a privacy-preserving paradigm, allowing edge devices to learn collaboratively without sharing data. Edge devices like Alexa and Siri are prospective sources of unlabeled audio data that can be tapped to learn robust audio representations. In this work, we bring Self-supervised Learning (SSL) and FL together to learn representations for Automatic Speech Recognition respecting data privacy constraints. We use the speaker and chapter information in the unlabeled speech dataset, Libri-Light, to simulate non-IID speaker-siloed data distributions and pre-train an LSTM encoder with the Contrastive Predictive Coding framework with FedSGD. We show that the pre-trained ASR encoder in FL performs as well as a centrally pre-trained model and produces an improvement of 12-15% (WER) compared to no pre-training. We further adapt the federated pre-trained models to a new language, French, and show a 20% (WER) improvement over no pre-training.
    
[^98]: 有限分类模型的精确核等价性

    An Exact Kernel Equivalence for Finite Classification Models. (arXiv:2308.00824v1 [cs.LG])

    [http://arxiv.org/abs/2308.00824](http://arxiv.org/abs/2308.00824)

    本研究推导出梯度下降训练的有限分类模型的精确核表示，揭示了神经网络和核方法之间的等价性，并通过实验证明了精确核对神经网络预测的指导作用。

    

    本研究通过推导梯度下降训练的任意有限大小参数分类模型的精确表示，探索神经网络和核方法之间的等价性。我们将我们的精确表示与著名的神经切向核（NTK）进行比较，并讨论相对于NTK和其他非精确路径核公式的近似误差。我们通过实验证明，可以计算出逼真网络的核到机器精度。我们利用这个精确核来展示我们的理论贡献如何为神经网络的预测提供有用的见解，特别是它们的泛化方式。

    We explore the equivalence between neural networks and kernel methods by deriving the first exact representation of any finite-size parametric classification model trained with gradient descent as a kernel machine. We compare our exact representation to the well-known Neural Tangent Kernel (NTK) and discuss approximation error relative to the NTK and other non-exact path kernel formulations. We experimentally demonstrate that the kernel can be computed for realistic networks up to machine precision. We use this exact kernel to show that our theoretical contribution can provide useful insights into the predictions made by neural networks, particularly the way in which they generalize.
    
[^99]: ProtoFL: 通过原型蒸馏实现无监督的联邦学习

    ProtoFL: Unsupervised Federated Learning via Prototypical Distillation. (arXiv:2307.12450v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.12450](http://arxiv.org/abs/2307.12450)

    本文提出了ProtoFL，一种基于原型蒸馏的无监督联邦学习方法，用于提高全局模型的表示能力并减少通信成本。此外，引入了基于正规流的本地单类分类器以提高有限数据下的性能。在五个基准数据集上的实验证明了该方法相较于先前方法具有超越性能。

    

    联邦学习（FL）是一种提高数据隐私保护的有潜力的方法，特别适用于身份验证系统。然而，有限的通信轮次、稀缺的表示和可扩展性给其部署带来了重大挑战，限制了其发挥全部潜力的能力。在本文中，我们提出了"ProtoFL"，基于原型表示蒸馏的无监督联邦学习，以增强全局模型的表示能力并降低通信成本。此外，我们引入了基于正规流的本地单类分类器，以在有限数据下改善性能。我们的研究首次探讨了使用FL来提高单类分类性能。我们在广泛使用的五个基准数据集上进行了大量实验，分别是MNIST、CIFAR-10、CIFAR-100、ImageNet-30和Keystroke-Dynamics，以展示我们提出的框架在文献中的先前方法上具有卓越的性能。

    Federated learning (FL) is a promising approach for enhancing data privacy preservation, particularly for authentication systems. However, limited round communications, scarce representation, and scalability pose significant challenges to its deployment, hindering its full potential. In this paper, we propose 'ProtoFL', Prototypical Representation Distillation based unsupervised Federated Learning to enhance the representation power of a global model and reduce round communication costs. Additionally, we introduce a local one-class classifier based on normalizing flows to improve performance with limited data. Our study represents the first investigation of using FL to improve one-class classification performance. We conduct extensive experiments on five widely used benchmarks, namely MNIST, CIFAR-10, CIFAR-100, ImageNet-30, and Keystroke-Dynamics, to demonstrate the superior performance of our proposed framework over previous methods in the literature.
    
[^100]: 错误的原因而正确的：可解释的机器学习技术能够检测到虚假相关性吗？

    Right for the Wrong Reason: Can Interpretable ML Techniques Detect Spurious Correlations?. (arXiv:2307.12344v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.12344](http://arxiv.org/abs/2307.12344)

    本研究在胸透诊断任务中评估了五种事后解释技术和一种本质上可解释的方法对于检测虚假相关性的能力，发现SHAP和Attri-Net可以有效地检测出这种类型的依赖关系。

    

    虽然深度神经网络模型可以提供无与伦比的分类性能，但它们很容易学习到数据中的虚假相关性。如果测试数据与训练数据来自相同的分布，那么这种对混淆信息的依赖会很难通过性能指标来检测出来。可解释的机器学习方法，如事后解释或本质上可解释的分类器，承诺可以识别出错误的模型推理。然而，目前对于这些技术是否真的能够做到这一点存在着一些混合的证据。本文提出了一种严格的评估策略，以评估解释技术正确识别虚假相关性的能力。使用这种策略，我们评估了五种事后解释技术和一种本质上可解释的方法对于在胸透诊断任务中检测三种人为添加的混淆因子的能力。我们发现事后解释技术SHAP以及本质上可解释的Attri-Net方法可以有效地检测出虚假相关性。

    While deep neural network models offer unmatched classification performance, they are prone to learning spurious correlations in the data. Such dependencies on confounding information can be difficult to detect using performance metrics if the test data comes from the same distribution as the training data. Interpretable ML methods such as post-hoc explanations or inherently interpretable classifiers promise to identify faulty model reasoning. However, there is mixed evidence whether many of these techniques are actually able to do so. In this paper, we propose a rigorous evaluation strategy to assess an explanation technique's ability to correctly identify spurious correlations. Using this strategy, we evaluate five post-hoc explanation techniques and one inherently interpretable method for their ability to detect three types of artificially added confounders in a chest x-ray diagnosis task. We find that the post-hoc technique SHAP, as well as the inherently interpretable Attri-Net pr
    
[^101]: 用GPT-4增强CLIP：利用视觉描述作为提示

    Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts. (arXiv:2307.11661v1 [cs.CV])

    [http://arxiv.org/abs/2307.11661](http://arxiv.org/abs/2307.11661)

    本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。

    

    对比预训练的大型视觉-语言模型（VLMs）如CLIP在下游数据集上提供了良好性能，从而革新了视觉表示学习。VLMs通过设计与数据集相关的提示来0-shot适应下游数据集。这种提示工程利用了领域专业知识和验证数据集。同时，像GPT-4这样的生成预训练模型的最新发展意味着它们可以用作先进的互联网搜索工具。它们还可以被操作以提供任何结构化的视觉信息。在这项工作中，我们展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，我们在专门细粒度数据集（如EuroSAT（~7％）、DTD（~7％）、SUN397（~4.6％）和CUB（~3.3％））上显示出了较大的0-shot迁移准确性改进。我们还设计了一个简单的少量样本适配器，它可以学习选择最佳的s

    Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have revolutionized visual representation learning by providing good performance on downstream datasets. VLMs are 0-shot adapted to a downstream dataset by designing prompts that are relevant to the dataset. Such prompt engineering makes use of domain expertise and a validation dataset. Meanwhile, recent developments in generative pretrained models like GPT-4 mean they can be used as advanced internet search tools. They can also be manipulated to provide visual information in any structure. In this work, we show that GPT-4 can be used to generate text that is visually descriptive and how this can be used to adapt CLIP to downstream tasks. We show considerable improvements in 0-shot transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD (~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt. We also design a simple few-shot adapter that learns to choose the best possible s
    
[^102]: 通过多目标联邦学习对SecureBoost超参数进行调优的方法

    SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning. (arXiv:2307.10579v1 [cs.LG])

    [http://arxiv.org/abs/2307.10579](http://arxiv.org/abs/2307.10579)

    提出了一种通过多目标联邦学习来调优SecureBoost超参数的方法，以找到在效用、效率和隐私之间最佳平衡的一组超参数解决方案。

    

    SecureBoost是一种利用同态加密保护垂直联邦学习中数据隐私的树提升算法。由于其可解释性、效果和隐私保护能力，在金融和医疗保健等领域广泛应用。然而，SecureBoost存在计算复杂性高和标签泄漏风险的问题。为了充分发挥SecureBoost的潜力，需要仔细选择SecureBoost的超参数，以在效用、效率和隐私之间达到最佳平衡。现有方法要么经验性地设置超参数，要么启发式地设置超参数，远未达到最优。为了弥补这一差距，我们提出了一种约束多目标SecureBoost (CMOSB) 算法，以寻找每个解都是在效用损失、训练成本和隐私泄漏之间实现最佳权衡的一组超参数的Pareto最优解。我们设计了三个目标的度量方法。特别是，隐私泄漏是用... (此处省略)

    SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting. It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability. However, SecureBoost suffers from high computational complexity and risk of label leakage. To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy. Existing methods either set hyperparameters empirically or heuristically, which are far from optimal. To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage. We design measurements of the three objectives. In particular, the privacy leakage is measured using 
    
[^103]: 我们能相信种族预测吗？

    Can We Trust Race Prediction?. (arXiv:2307.08496v1 [cs.LG])

    [http://arxiv.org/abs/2307.08496](http://arxiv.org/abs/2307.08496)

    本文研究了在没有敏感的种族和族裔数据的情况下，使用代理模型进行种族预测的问题。研究者训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，还构建了美国最全面的姓氏和名字分布数据库，并提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。

    

    在没有敏感的种族和族裔数据的情况下，研究人员、监管机构和公司都借助代理模型。在本文中，我使用来自美国50个州的选民注册数据训练了一个双向长短时记忆（BiLSTM）模型，并创建了一个集成模型，其在外样本（OOS）F1得分上比文献中表现最好的机器学习模型高出36.8%。此外，我构建了美国最全面的姓氏和名字分布数据库，以改进贝叶斯改进姓氏地理编码（BISG）和贝叶斯改进名字姓氏地理编码（BIFSG）的覆盖和准确性。最后，我提供了第一个高质量的基准数据集，以公正比较现有模型，并帮助未来的模型开发者。

    In the absence of sensitive race and ethnicity data, researchers, regulators, and firms alike turn to proxies. In this paper, I train a Bidirectional Long Short-Term Memory (BiLSTM) model on a novel dataset of voter registration data from all 50 US states and create an ensemble that achieves up to 36.8% higher out of sample (OOS) F1 scores than the best performing machine learning models in the literature. Additionally, I construct the most comprehensive database of first and surname distributions in the US in order to improve the coverage and accuracy of Bayesian Improved Surname Geocoding (BISG) and Bayesian Improved Firstname Surname Geocoding (BIFSG). Finally, I provide the first high-quality benchmark dataset in order to fairly compare existing models and aid future model developers.
    
[^104]: 探索从替代训练中理解对抗性可转移性

    Towards Understanding Adversarial Transferability From Surrogate Training. (arXiv:2307.07873v1 [cs.LG])

    [http://arxiv.org/abs/2307.07873](http://arxiv.org/abs/2307.07873)

    本论文探索了对抗性可转移性的理解，特别关注替代训练。通过研究模型的平滑性和梯度相似性之间的权衡，发现对抗训练可以提高模型的替代能力。研究结果对数据分布的转变提出了新的推测。

    

    对DNNs的对抗样本(AEs)已经表明是可转移的：成功欺骗白盒子替代模型的AEs也可以欺骗具有不同架构的其他黑盒模型。虽然许多经验研究提供了生成高度可转移AE的指导，但这些研究缺乏解释甚至导致不一致的建议。本文在理解对抗性可转移性方面迈出了一步，特别关注替代方面。从着名的小健壮性现象开始，通过以轻微扰动的对抗性样本对模型进行对抗训练可以得到更好的替代模型，我们将其归因于两个主要因素之间的权衡：模型的平滑性和梯度相似性。我们的研究集中在它们的共同效果上，而不是它们与可转移性的单独相关性。通过一系列理论和实证分析，我们推测数据分布的转变。

    Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in
    
[^105]: 使用大型语言模型实现无监督校准的文本分类方法的先验适应

    Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])

    [http://arxiv.org/abs/2307.06713](http://arxiv.org/abs/2307.06713)

    本文提出了一种使用大型语言模型进行文本分类的无监督校准方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行任务。

    

    当前有许多自然语言任务正在使用大规模语言模型（LLM）进行研究。这些模型通常通过大量无监督文本数据进行训练，并通过微调、校准或上下文学习等方法进行适应以执行下游自然语言任务。在本研究中，我们提出了一种方法，通过调整先验类别分布，实现在没有标记样本和仅少量领域内样本查询的情况下执行文本分类任务。该方法将LLM视为黑盒，在模型屏障中添加了一个阶段，用于校准模型后验以完成任务。结果表明，这些方法在不同数量的提示训练样本和无适应数据下的校准方法中优于未适应的模型。

    A wide variety of natural language tasks are currently being addressed with large-scale language models (LLMs). These models are usually trained with a very large amount of unsupervised text data and adapted to perform a downstream natural language task using methods like fine-tuning, calibration or in-context learning. In this work, we propose an approach to adapt the prior class distribution to perform text classification tasks without the need for labelled samples and only few in-domain sample queries. The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task. Results show that these methods outperform the un-adapted model for different number of training shots in the prompt and a previous approach were calibration is performed without using any adaptation data.
    
[^106]: 平滑边缘：利用Hadamard超参数化在稀疏正则化的平滑优化中的一般框架

    Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization. (arXiv:2307.03571v1 [cs.LG])

    [http://arxiv.org/abs/2307.03571](http://arxiv.org/abs/2307.03571)

    本文介绍了一种通用框架，可以在稀疏正则化中进行平滑优化，与主流的一阶优化方法兼容，并且能够得到匹配的全局最小值和等价的局部最小值。

    

    本文介绍了一种用于（结构化）稀疏正则化问题中的$\ell_q$和$\ell_{p,q}$正则化的平滑方法。这些非平滑且可能非凸的问题的优化通常依赖于专门的过程。相比之下，我们的一般框架与主流的一阶优化方法（如随机梯度下降和加速变体）兼容，无需任何修改。这是通过平滑优化转移实现的，其中选定模型参数的超参数化使用Hadamard乘积和惩罚的改变。在超参数问题中，通过用替代参数进行平滑和凸性的$\ell_2$正则化，能够在原始参数化中引入非平滑和非凸性的$\ell_q$或$\ell_{p,q}$正则化。我们证明了我们的方法不仅能够得到匹配的全局最小值，还能得到等价的局部最小值。这在非凸稀疏正则化中尤其有用，因为在这种情况下找到全局最小值非常困难。

    This paper introduces a smooth method for (structured) sparsity in $\ell_q$ and $\ell_{p,q}$ regularized optimization problems. Optimization of these non-smooth and possibly non-convex problems typically relies on specialized procedures. In contrast, our general framework is compatible with prevalent first-order optimization methods like Stochastic Gradient Descent and accelerated variants without any required modifications. This is accomplished through a smooth optimization transfer, comprising an overparametrization of selected model parameters using Hadamard products and a change of penalties. In the overparametrized problem, smooth and convex $\ell_2$ regularization of the surrogate parameters induces non-smooth and non-convex $\ell_q$ or $\ell_{p,q}$ regularization in the original parametrization. We show that our approach yields not only matching global minima but also equivalent local minima. This is particularly useful in non-convex sparse regularization, where finding global m
    
[^107]: 评估文本到图像模型的数据归因

    Evaluating Data Attribution for Text-to-Image Models. (arXiv:2306.09345v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.09345](http://arxiv.org/abs/2306.09345)

    本论文评估了文本到图像模型的数据归因问题，通过定制方法，我们可以有效地创建受典型对象影响的合成图像，并通过调整标准模型，解决归因问题。

    

    虽然大型文本到图像模型能够合成“新颖”的图像，但这些图像必然是训练数据的反映。在这种模型中，数据归因的问题——在训练集中哪些图像对于生成的图像外观最负责——是一个困难但重要的问题。作为该问题的初步步骤，我们通过“定制”方法来评估归因，该方法将现有的大规模模型调整到给定的典型对象或风格。我们的关键见解是，这样可以通过构造有效地创建受典型对象影响的合成图像。通过我们的新数据集，我们可以评估各种数据归因算法和不同可能的特征空间。此外，通过在我们的数据集上进行训练，我们可以让DINO、CLIP和ViT等标准模型针对归因问题进行调整。

    While large text-to-image models are able to synthesize "novel" images, these images are necessarily a reflection of the training data. The problem of data attribution in such models -- which of the images in the training set are most responsible for the appearance of a given generated image -- is a difficult yet important one. As an initial step toward this problem, we evaluate attribution through "customization" methods, which tune an existing large-scale model toward a given exemplar object or style. Our key insight is that this allows us to efficiently create synthetic images that are computationally influenced by the exemplar by construction. With our new dataset of such exemplar-influenced images, we are able to evaluate various data attribution algorithms and different possible feature spaces. Furthermore, by training on our dataset, we can tune standard models, such as DINO, CLIP, and ViT, toward the attribution problem. Even though the procedure is tuned towards small exemplar
    
[^108]: GCformer:一种用于准确和可扩展的长期多元时间序列预测的高效框架

    GCformer: An Efficient Framework for Accurate and Scalable Long-Term Multivariate Time Series Forecasting. (arXiv:2306.08325v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08325](http://arxiv.org/abs/2306.08325)

    GCformer是一个结合了全局卷积和局部Transformer分支的框架，旨在解决长期多元时间序列预测的精确性和可扩展性问题。通过引入具有亚线性复杂度的结构化卷积核，GCformer在各种基准数据集上实现了优于其他方法的性能。

    

    基于Transformer的模型已经成为时间序列预测的有希望的工具。然而，这些模型对于长输入时间序列的预测不够准确。一方面，它们未能捕捉时间序列数据中的全局依赖关系。另一方面，长输入序列通常导致模型尺寸大和时间复杂度高。为了解决这些限制，我们提出了GCformer，它将用于处理长输入序列的结构化全局卷积分支与用于捕捉短期近期信号的局部Transformer分支相结合。引入了一个全局卷积核的连贯框架，利用了三种不同的参数化方法。全局分支中选择的结构化卷积核经过特殊设计，具有亚线性复杂度，从而可以高效和有效地处理长而嘈杂的输入信号。对六个基准数据集进行的实证研究表明，GCformer的性能优于其他方法。

    Transformer-based models have emerged as promising tools for time series forecasting.  However, these model cannot make accurate prediction for long input time series. On the one hand, they failed to capture global dependencies within time series data. On the other hand, the long input sequence usually leads to large model size and high time complexity.  To address these limitations, we present GCformer, which combines a structured global convolutional branch for processing long input sequences with a local Transformer-based branch for capturing short, recent signals. A cohesive framework for a global convolution kernel has been introduced, utilizing three distinct parameterization methods. The selected structured convolutional kernel in the global branch has been specifically crafted with sublinear complexity, thereby allowing for the efficient and effective processing of lengthy and noisy input signals. Empirical studies on six benchmark datasets demonstrate that GCformer outperforms
    
[^109]: Shuffle SGD总是比SGD更好：对具有任意数据顺序的SGD进行改进分析

    Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])

    [http://arxiv.org/abs/2305.19259](http://arxiv.org/abs/2305.19259)

    本论文研究了一种允许任意数据排序的普通SGD算法,并表明在非凸函数情况下，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。

    

    随机梯度下降（SGD）算法被广泛用于优化神经网络，随机重排（RR）和单次洗牌（SS）是通过循环遍历训练数据的随机或单个排列的常见选择，然而这些算法在非凸情况下的收敛性质尚未完全理解。现有结果表明，在实际的训练场景中，当时代的数量小于训练集大小时，RR可能表现不如SGD。本文分析了一种允许任意数据排序的普通SGD算法，并展示了在非凸函数情况下的改进收敛速度。具体而言，我们的分析表明，随机和单次洗牌的SGD比经典替换的SGD更快或至少与其一样好，无论迭代次数如何。总的来说，我们的研究凸显了使用随机/单次洗牌的SGD的好处，并为其非凸收敛性质提供了新的见解。

    Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
    
[^110]: UMD: 无监督模型检测X2X后门攻击

    UMD: Unsupervised Model Detection for X2X Backdoor Attacks. (arXiv:2305.18651v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18651](http://arxiv.org/abs/2305.18651)

    UMD是一种无监督的模型检测方法，能够有效地检测X2X后门攻击，对抗（源，目标）类别对进行联合推断，该方法定义了新的可转移性统计量，并使用聚类方法来测量和选择潜在的后门类别对的子集。

    

    后门（特洛伊）攻击是深度神经网络面临的常见威胁，其中嵌入后门触发器的一个或多个源类别的样本会被错误分类为对抗目标类别。现有的检测分类器是否遭受后门攻击的方法主要是针对单一对抗目标的攻击设计的（例如，全对一攻击）。据我们所知，没有现有的方法可以在没有监督的情况下有效地解决具有任意数量的源类别的更普遍的X2X攻击，每个源类别都与任意目标类别配对。在本文中，我们提出了UMD，第一个通过联合推断对抗（源，目标）类别对来有效检测X2X后门攻击的无监督模型检测方法。特别地，我们首先定义一种新颖的可转移性统计方法，通过提出的聚类方法来量度和选择一组潜在的后门类别对的子集。然后，这些选择的类别对是基于联合评估进行评估的。

    Backdoor (Trojan) attack is a common threat to deep neural networks, where samples from one or more source classes embedded with a backdoor trigger will be misclassified to adversarial target classes. Existing methods for detecting whether a classifier is backdoor attacked are mostly designed for attacks with a single adversarial target (e.g., all-to-one attack). To the best of our knowledge, without supervision, no existing methods can effectively address the more general X2X attack with an arbitrary number of source classes, each paired with an arbitrary target class. In this paper, we propose UMD, the first Unsupervised Model Detection method that effectively detects X2X backdoor attacks via a joint inference of the adversarial (source, target) class pairs. In particular, we first define a novel transferability statistic to measure and select a subset of putative backdoor class pairs based on a proposed clustering approach. Then, these selected class pairs are jointly assessed based
    
[^111]: 测量和建模身体内在动机

    Measuring and Modeling Physical Intrinsic Motivation. (arXiv:2305.13452v1 [cs.AI])

    [http://arxiv.org/abs/2305.13452](http://arxiv.org/abs/2305.13452)

    本文对身体内在动机进行了量化建模，发现对抗性奖励模型可以最好地预测人类对物理情境的趣味反应，还发现简单场景特征模型无法在所有情境中预测人类反应，将对抗模型和场景中碰撞数量进行线性组合，能够显著提高对人类反应的预测能力，表明人类追求高信息增益和身体活动的情况。

    

    人类是有驱动力的互动性代理，他们追求有趣的物理动力学情境。本文探讨了形式化的物理内在动机形式。我们首先收集了人类对多种物理情境的评分。接着，我们通过实现依赖于简单场景特征的模型到依赖于前向物理预测的模型的各种内在动机假设来建模人类的趣味反应。我们发现，对于人类反应的单一最佳预测器是针对物理预测损失推导出的对抗性奖励模型。我们还发现，简单的场景特征模型不能在所有情境中推广他们对人类反应的预测。最后，将对抗模型与场景中碰撞数量进行线性组合，可显著提高对人类反应的预测能力，表明人类倾向于追求高信息增益和身体活动的情况。

    Humans are interactive agents driven to seek out situations with interesting physical dynamics. Here we formalize the functional form of physical intrinsic motivation. We first collect ratings of how interesting humans find a variety of physics scenarios. We then model human interestingness responses by implementing various hypotheses of intrinsic motivation including models that rely on simple scene features to models that depend on forward physics prediction. We find that the single best predictor of human responses is adversarial reward, a model derived from physical prediction loss. We also find that simple scene feature models do not generalize their prediction of human responses across all scenarios. Finally, linearly combining the adversarial model with the number of collisions in a scene leads to the greatest improvement in predictivity of human responses, suggesting humans are driven towards scenarios that result in high information gain and physical activity.
    
[^112]: P-NOC:对弱监督语义分割进行对抗性CAM生成的研究

    P-NOC: Adversarial CAM Generation for Weakly Supervised Semantic Segmentation. (arXiv:2305.12522v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12522](http://arxiv.org/abs/2305.12522)

    本文提出了一种新的弱监督语义分割策略，通过对抗性CAM生成网络生成稳健的语义分割提议，结果表明该方法显著提高了分割效果。

    

    为了减少对大量有监督分割注释集的依赖，已经提出了多种弱监督语义分割（WSSS）策略。这些策略通常依赖于先进的数据和模型正则化策略，以激发分割先验中有用属性（例如，预测完整性和对语义边界的忠实度）的发展，而不考虑注释信息的缺乏。在这项工作中，我们首先通过分析互补的WSSS技术和正则化策略，考虑它们的优点和局限性，建立了一个强大的基准。然后，我们提出了一种新的类别特定的对抗性擦除策略，包括逐渐改进的两个对抗性CAM生成网络，以产生稳健的语义分割提议。实证结果表明，我们的方法显著提高了基准的效果，在Pascal VOC 2012和MS COCO 2014数据集上都取得了显著的改进。

    To mitigate the necessity for large amounts of supervised segmentation annotation sets, multiple Weakly Supervised Semantic Segmentation (WSSS) strategies have been devised. These will often rely on advanced data and model regularization strategies to instigate the development of useful properties (e.g., prediction completeness and fidelity to semantic boundaries) in segmentation priors, notwithstanding the lack of annotated information. In this work, we first create a strong baseline by analyzing complementary WSSS techniques and regularizing strategies, considering their strengths and limitations. We then propose a new Class-specific Adversarial Erasing strategy, comprising two adversarial CAM generating networks being gradually refined to produce robust semantic segmentation proposals. Empirical results suggest that our approach induces substantial improvement in the effectiveness of the baseline, resulting in a noticeable improvement over both Pascal VOC 2012 and MS COCO 2014 datas
    
[^113]: 学习在存在隐性混淆因素的情况下从不确定数据中恢复因果关系

    Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders. (arXiv:2305.02640v1 [cs.LG])

    [http://arxiv.org/abs/2305.02640](http://arxiv.org/abs/2305.02640)

    本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。

    

    在具有潜在变量的因果发现中，我们定义了两个数据范式：确定数据：具有观察节点单值的单个骨架结构，和不确定数据：具有观察节点多值的一组多骨架结构。多个骨架引入低样本利用率，多个值引入了分布假设的无能力，这两者导致从不确定数据中恢复因果关系至今仍然未被充分探索。我们设计了因果强度变分模型来解决这两个问题。具体地，我们利用因果强度而不是独立噪声作为潜变量来调节证据下界。通过这种设计思想，不同骨架的因果强度被看作是一个分布，并可以表示为单值因果图矩阵。此外，考虑到潜在混淆因素，我们将因果图G分解为两个相关子图O和C。O包含观察节点之间的纯关系，而C表示混淆因素。

    In Causal Discovery with latent variables, We define two data paradigms: definite data: a single-skeleton structure with observed nodes single-value, and indefinite data: a set of multi-skeleton structures with observed nodes multi-value. Multi,skeletons induce low sample utilization and multi values induce incapability of the distribution assumption, both leading that recovering causal relations from indefinite data is, as of yet, largely unexplored. We design the causal strength variational model to settle down these two problems. Specifically, we leverage the causal strength instead of independent noise as latent variable to mediate evidence lower bound. By this design ethos, The causal strength of different skeletons is regarded as a distribution and can be expressed as a single-valued causal graph matrix. Moreover, considering the latent confounders, we disentangle the causal graph G into two relatisubgraphs O and C. O contains pure relations between observed nodes, while C repres
    
[^114]: 最大化潜在特征和真实标签之间的互信息实现长尾识别

    Long-Tailed Recognition by Mutual Information Maximization between Latent Features and Ground-Truth Labels. (arXiv:2305.01160v1 [cs.LG])

    [http://arxiv.org/abs/2305.01160](http://arxiv.org/abs/2305.01160)

    本论文提出了一种名为LC的新长尾识别方法，它能够更好地模拟真实标签分布，同时解决类别标签不平衡问题，从而在CIFAR-10，CIFAR-100和ImageNet基准数据集上显着优于现有方法。

    

    尽管对比学习方法在各种表示学习任务中表现出了优越的性能，但当训练数据集是长尾分布时，它们会遇到困难。许多研究人员已经将对比学习和逻辑斯蒂调整技术相结合来解决这个问题，但这些组合是临时的，并没有提供理论背景。本文的目的是提供背景并进一步提高性能。首先，我们证明了对比学习方法在长尾任务中遇到困难的根本原因是它们试图最大化潜在特征和输入数据之间的互信息最大化。由于不考虑真实标签的最大化，它们无法解决类别标签之间的不平衡问题。相反，我们将长尾识别任务解释为潜在特征和真实标签之间的互信息最大化。这种方法以一种有原则的方式集成了对比学习和逻辑斯蒂调整技术。其次，我们提出了一种新方法，称为潜在类别（LC）方法，它明确地模拟了真实标签的分布，并联合最大化潜在特征和真实标签之间的互信息。对包括CIFAR-10，CIFAR-100和ImageNet在内的基准数据集进行的大量实验表明，我们提出的方法在长尾识别任务上显着优于现有方法。

    Although contrastive learning methods have shown prevailing performance on a variety of representation learning tasks, they encounter difficulty when the training dataset is long-tailed. Many researchers have combined contrastive learning and a logit adjustment technique to address this problem, but the combinations are done ad-hoc and a theoretical background has not yet been provided. The goal of this paper is to provide the background and further improve the performance. First, we show that the fundamental reason contrastive learning methods struggle with long-tailed tasks is that they try to maximize the mutual information maximization between latent features and input data. As ground-truth labels are not considered in the maximization, they are not able to address imbalances between class labels. Rather, we interpret the long-tailed recognition task as a mutual information maximization between latent features and ground-truth labels. This approach integrates contrastive learning a
    
[^115]: 解决面部验证边缘案例：深度分析和人机融合方法

    Tackling Face Verification Edge Cases: In-Depth Analysis and Human-Machine Fusion Approach. (arXiv:2304.08134v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.08134](http://arxiv.org/abs/2304.08134)

    本文研究了临近边缘案例的面部验证问题，发现结合人机决策可以进一步提高最先进的面部验证系统在各种基准数据集上的性能。

    

    目前，面部识别系统在几个数据集上已经超过了人类表现。然而，仍然存在一些机器无法正确分类的边缘案例。本文研究了机器和人操作员在面部验证任务中的组合效应。首先，我们仔细研究了几个最先进模型的边缘案例，以发现常见数据集的挑战性设置。然后，我们对这些选定任务中的60个参与者进行了一项人类研究，并提供了广泛的分析。最后，我们展示了将机器和人类决策结合起来，可以进一步提高最先进的面部验证系统在各种基准数据集上的性能。代码和数据可在GitHub上公开获取。

    Nowadays, face recognition systems surpass human performance on several datasets. However, there are still edge cases that the machine can't correctly classify. This paper investigates the effect of a combination of machine and human operators in the face verification task. First, we look closer at the edge cases for several state-of-the-art models to discover common datasets' challenging settings. Then, we conduct a study with 60 participants on these selected tasks with humans and provide an extensive analysis. Finally, we demonstrate that combining machine and human decisions can further improve the performance of state-of-the-art face verification systems on various benchmark datasets. Code and data are publicly available on GitHub.
    
[^116]: PMAA：一种基于渐进式多尺度注意力自编码器模型的高性能卫星遥感云去除方法

    PMAA: A Progressive Multi-scale Attention Autoencoder Model for High-Performance Cloud Removal from Multi-temporal Satellite Imagery. (arXiv:2303.16565v1 [cs.CV])

    [http://arxiv.org/abs/2303.16565](http://arxiv.org/abs/2303.16565)

    PMAA是一种利用全局和局部信息的高性能卫星遥感云去除架构。其中，独特的多尺度注意力模块和局部交互模块能够同时表示细粒度和粗粒度特征，相比现有方法表现更优。

    

    卫星遥感图像分析在远程感知中起着至关重要的作用，但由云层引起的信息丢失严重阻碍了其应用。本研究提出了一种名为“渐进式多尺度注意力自编码器”（PMAA）的高性能云去除架构，同时利用全局和局部信息。其主要包括云检测和云去除模块。云检测通过云掩模加强云区域以促进云去除。云去除模块主要包括新颖的多尺度注意力模块（MAM）和局部交互模块（LIM）。PMAA通过MAM建立多尺度特征的长程依赖性，并通过LIM调节细粒度细节的重建，从而实现在同一级别上同时呈现细粒度和粗粒度特征。在各种数据集上，借助不同和多尺度特征表示的帮助下，PMAA在定量和视觉评估方面均优于先前的现有方法，展示了其高效性和鲁棒性。

    Satellite imagery analysis plays a vital role in remote sensing, but the information loss caused by cloud cover seriously hinders its application. This study presents a high-performance cloud removal architecture called Progressive Multi-scale Attention Autoencoder (PMAA), which simultaneously leverages global and local information. It mainly consists of a cloud detection backbone and a cloud removal module. The cloud detection backbone uses cloud masks to reinforce cloudy areas to prompt the cloud removal module. The cloud removal module mainly comprises a novel Multi-scale Attention Module (MAM) and a Local Interaction Module (LIM). PMAA establishes the long-range dependency of multi-scale features using MAM and modulates the reconstruction of the fine-grained details using LIM, allowing for the simultaneous representation of fine- and coarse-grained features at the same level. With the help of diverse and multi-scale feature representation, PMAA outperforms the previous state-of-the
    
[^117]: GNNBuilder：通用图神经网络加速器生成、模拟和优化的自动化框架

    GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization. (arXiv:2303.16459v1 [cs.AR])

    [http://arxiv.org/abs/2303.16459](http://arxiv.org/abs/2303.16459)

    GNNBuilder是一个自动化的、通用的、端到端的GNN加速器生成框架，它可以为用户任意定义的广泛的GNN模型自动生成加速器，且运行速度比软件基准快多达12.95倍。

    

    目前有很多图神经网络（GNN）加速器被提出。然而，它们高度依赖于用户的硬件专业知识，并且通常针对一种特定的GNN模型进行优化，使它们难以实际使用。因此，在这项工作中，我们提出了GNNBuilder，这是第一个自动化的、通用的、端到端的GNN加速器生成框架。它具有四个优点：（1）GNNBuilder可以自动为用户任意定义的广泛的GNN模型生成GNN加速器；（2）GNNBuilder采用标准的PyTorch编程接口，为算法开发人员提供零开销；（3）GNNBuilder支持端到端的代码生成、模拟、加速器优化和硬件部署，实现了GNN加速器设计的一键式操作；（4）GNNBuilder配备了其所生成的加速器的准确性能模型，使得设计空间探索（DSE）快速而灵活。在实验中，首先我们展示了我们的加速器在6个基准数据集上与最先进的GNN加速器相比表现出色，运行速度比软件基准快了多达12.95倍。其次，对不规则图处理的案例研究展示了GNNBuilder的出色可扩展性和适应性。最后，在单个GPU的服务器上，我们对400个GNN模型进行了30分钟的DSE研究，验证了GNNBuilder的效率和有效性。

    There are plenty of graph neural network (GNN) accelerators being proposed. However, they highly rely on users' hardware expertise and are usually optimized for one specific GNN model, making them challenging for practical use . Therefore, in this work, we propose GNNBuilder, the first automated, generic, end-to-end GNN accelerator generation framework. It features four advantages: (1) GNNBuilder can automatically generate GNN accelerators for a wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes standard PyTorch programming interface, introducing zero overhead for algorithm developers; (3) GNNBuilder supports end-to-end code generation, simulation, accelerator optimization, and hardware deployment, realizing a push-button fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate performance models of its generated accelerator, enabling fast and flexible design space exploration (DSE). In the experiments, first, we show that our accelerator pe
    
[^118]: 以类别特定的对抗事实为基础的内在可解释多标签分类

    Inherently Interpretable Multi-Label Classification Using Class-Specific Counterfactuals. (arXiv:2303.00500v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.00500](http://arxiv.org/abs/2303.00500)

    提出了一种名为Attri-Net的内在可解释模型，用于多标签分类，它能提供透明、可信赖和人可理解的解释。该模型通过生成类别特定的归因图，基于对抗事实来确定图像中对应于特定医疗发现的区域，并使用逻辑回归模型对归因图进行分类预测。

    

    在高风险应用领域，如医学影像分析中，可解释性对于机器学习算法至关重要。然而，高性能的黑盒神经网络不会提供其预测的解释，这可能导致人与机器学习的合作不可信任和次优。目前的后处理解释技术在多标签情景下表现不佳，其中同一图像中可能同时出现多个医疗发现。我们提出了一种名为Attri-Net的内在可解释模型，用于多标签分类。Attri-Net是一个强大的分类器，提供透明、可信赖和人可理解的解释。该模型首先基于对抗事实生成类别特定的归因图，以确定哪些图像区域对应于特定的医疗发现。然后，使用简单的逻辑回归模型对归因图进行分类预测。

    Interpretability is essential for machine learning algorithms in high-stakes application fields such as medical image analysis. However, high-performing black-box neural networks do not provide explanations for their predictions, which can lead to mistrust and suboptimal human-ML collaboration. Post-hoc explanation techniques, which are widely used in practice, have been shown to suffer from severe conceptual problems. Furthermore, as we show in this paper, current explanation techniques do not perform adequately in the multi-label scenario, in which multiple medical findings may co-occur in a single image. We propose Attri-Net, an inherently interpretable model for multi-label classification. Attri-Net is a powerful classifier that provides transparent, trustworthy, and human-understandable explanations. The model first generates class-specific attribution maps based on counterfactuals to identify which image regions correspond to certain medical findings. Then a simple logistic regre
    
[^119]: 针对链接预测，对待不同的负样本有差异性：利用领域和范围约束丰富损失函数

    Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction. (arXiv:2303.00286v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00286](http://arxiv.org/abs/2303.00286)

    通过引入领域和范围约束，我们提出了基于语义的损失函数来区分不同质量的负样本，实验证明在链接预测任务上有效。

    

    知识图谱嵌入模型（KGEMs）用于与知识图谱（KGs）相关的各种任务，包括链接预测。它们使用考虑了一批得分三元组及其相应标签的损失函数进行训练。传统方法认为三元组的标签要么为真，要么为假。然而，最近的研究表明，并非所有的负样本应该被平等对待。与这一最近的假设一致，我们认为基于领域和范围约束在语义上有效的负样本可能是高质量的负样本。因此，损失函数应该将它们与语义上无效的负样本区别对待。为此，我们针对链接预测的三个主要损失函数提出了基于语义的版本。通过广泛和受控的实验设置，我们展示了所提出的损失函数在三个具有不同模式的公共基准KG上系统地提供了令人满意的结果。

    Knowledge graph embedding models (KGEMs) are used for various tasks related to knowledge graphs (KGs), including link prediction. They are trained with loss functions that are computed considering a batch of scored triples and their corresponding labels. Traditional approaches consider the label of a triple to be either true or false. However, recent works suggest that all negative triples should not be valued equally. In line with this recent assumption, we posit that negative triples that are semantically valid w.r.t. domain and range constraints might be high-quality negative triples. As such, loss functions should treat them differently from semantically invalid negative ones. To this aim, we propose semantic-driven versions for the three main loss functions for link prediction. In an extensive and controlled experimental setting, we show that the proposed loss functions systematically provide satisfying results on three public benchmark KGs underpinned with different schemas, whic
    
[^120]: 对图卷积网络的语义后门攻击

    A semantic backdoor attack against Graph Convolutional Networks. (arXiv:2302.14353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14353](http://arxiv.org/abs/2302.14353)

    该论文研究了图卷积网络（GCNs）是否容易受到语义后门攻击，提出了一种针对GCNs的语义后门攻击方法（SBAG），通过在样本中的特定节点作为触发器，并注入隐藏的后门来攻击GCNs模型。

    

    图卷积网络（GCNs）在解决各种图结构相关任务（如节点分类和图分类）方面非常有效。然而，最近的研究表明，GCNs容易受到一种新型威胁，称为后门攻击。攻击者可以将隐藏的后门注入GCNs中，使得攻击模型在良性样本上表现良好，但是如果攻击者定义的触发器激活了隐藏的后门，其预测结果将被恶意地修改为攻击者指定的目标标签。本文研究了GCNs是否容易受到这种语义后门攻击，并提出了一种针对GCNs的语义后门攻击（SBAG）来揭示GCNs中存在的安全漏洞。SBAG使用样本中的某种节点作为后门触发器，并通过污染训练数据将隐藏的后门注入到GCNs模型中。

    Graph Convolutional Networks (GCNs) have been very effective in addressing the issue of various graph-structured related tasks, such as node classification and graph classification. However, recent research has shown that GCNs are vulnerable to a new type of threat called the backdoor attack, where the adversary can inject hidden backdoor into the GCNs so that the attacked model performs well on benign samples, whereas its prediction will be maliciously changed to the attacker-specified target label if the hidden backdoor is activated by the attacker-defined trigger. In this paper, we investigate whether such semantic backdoor attacks are possible for GCNs and propose a Semantic Backdoor Attack against GCNs(SBAG) under the context of graph classification to reveal the existence of this security vulnerability in GCNs. The SBAG uses a certain type of node in the samples as a backdoor trigger and injects hidden backdoor into GCNs models through poisoning training data. The backdoor will b
    
[^121]: 因果剃刀

    Causal Razors. (arXiv:2302.10331v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10331](http://arxiv.org/abs/2302.10331)

    本文比较了许多出现在文献中的因果剃刀，并特别研究了在多项式因果模型中不太受欢迎的因果剃刀——参数最小性。逻辑结果揭示了选择合理得分标准时的困境。

    

    在进行因果推断时，必须对真实因果机制如何与底层联合概率分布相对应做出假设。本文将这些假设称为因果剃刀。我们回顾了许多出现在文献中的因果剃刀，对它们进行了全面的逻辑比较。特别地，我们对在多项式因果模型中不太受欢迎的因果剃刀——参数最小性进行了深入的研究，并研究了它与其他广泛研究的因果剃刀之间的逻辑关系。我们的逻辑结果在为基于分数的因果搜索算法选择合理得分标准时提出了困境。

    When performing causal discovery, assumptions have to be made on how the true causal mechanism corresponds to the underlying joint probability distribution. These assumptions are labeled as causal razors in this work. We review numerous causal razors that appeared in the literature, and offer a comprehensive logical comparison of them. In particular, we scrutinize an unpopular causal razor, namely parameter minimality, in multinomial causal models and its logical relations with other well-studied causal razors. Our logical result poses a dilemma in selecting a reasonable scoring criterion for score-based casual search algorithms.
    
[^122]: MonoFlow: 从Wasserstein梯度流的角度重新思考Divergence GANs

    MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.01075](http://arxiv.org/abs/2302.01075)

    本文提出了一个新的GAN生成建模框架MonoFlow，通过Wasserstein梯度流获得理论洞见和算法启示。该框架使用密度比例的单调递增映射重新缩放粒子演化，并通过训练鉴别器获得MonoFlow的向量场，利用相应的向量场进行粒子流的生成。

    

    传统上，生成对抗网络（GANs）的对抗训练是通过判别器来估计离散度，生成器学习最小化这个离散度。我们认为，尽管许多GANs变体都是按照这个范例开发的，但当前GANs的理论理解和实际算法是不一致的。在本文中，通过利用展示了样本空间内粒子演化的Wasserstein梯度流来获得GANs的理论洞见和算法启示，我们介绍了一个统一的生成建模框架MonoFlow：粒子演化通过密度比例的单调递增映射进行重新缩放。在我们的框架下，对抗性训练可以被视为一个过程，首先通过训练鉴别器获得MonoFlow的向量场，然后生成器学习由相应向量场所定义的粒子流。

    The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework - MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We al
    
[^123]: 权重预测提升AdamW的收敛性

    Weight Prediction Boosts the Convergence of AdamW. (arXiv:2302.00195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00195](http://arxiv.org/abs/2302.00195)

    本文通过将权重预测技术引入AdamW优化器，加速了深度神经网络的收敛过程，实验结果表明，该方法提升了AdamW的收敛性并在训练DNN模型时获得更高的准确性。

    

    本文将权重预测引入AdamW优化器，以加速深度神经网络（DNN）模型的收敛过程。在每个小批量训练之前，我们根据AdamW的更新规则预测未来的权重，并将预测的未来权重应用于前向传播和反向传播。通过这种方式，AdamW优化器始终利用与未来权重相关的梯度而不是当前权重来更新DNN参数，使得AdamW优化器能够实现更好的收敛性。我们的提议简单直观，易于实现，但在加速DNN训练的收敛性方面非常有效。我们在图像分类和语言建模任务上进行了大量的实验评估，结果验证了我们的提议可以提升AdamW的收敛性，并在训练DNN模型时实现更高的准确性。

    In this paper, we introduce weight prediction into the AdamW optimizer to boost its convergence when training the deep neural network (DNN) models. In particular, ahead of each mini-batch training, we predict the future weights according to the update rule of AdamW and then apply the predicted future weights to do both forward pass and backward propagation. In this way, the AdamW optimizer always utilizes the gradients w.r.t. the future weights instead of current weights to update the DNN parameters, making the AdamW optimizer achieve better convergence. Our proposal is simple and straightforward to implement but effective in boosting the convergence of DNN training. We performed extensive experimental evaluations on image classification and language modeling tasks to verify the effectiveness of our proposal. The experimental results validate that our proposal can boost the convergence of AdamW and achieve better accuracy than AdamW when training the DNN models.
    
[^124]: 用于生成逼真完全标注显微镜图像数据集的去噪扩散概率模型

    Denoising Diffusion Probabilistic Models for Generation of Realistic Fully-Annotated Microscopy Image Data Sets. (arXiv:2301.10227v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.10227](http://arxiv.org/abs/2301.10227)

    本研究证明，去噪扩散概率模型可以通过无监督和直观的方法生成完全标注的显微镜图像数据集，有助于减少对人工标注的依赖，并且能够对多样的数据集进行分割。

    

    最近计算机视觉的进展在逼真图像数据的生成方面取得了显著的进步，

    Recent advances in computer vision have led to significant progress in the generation of realistic image data, with denoising diffusion probabilistic models proving to be a particularly effective method. In this study, we demonstrate that diffusion models can effectively generate fully-annotated microscopy image data sets through an unsupervised and intuitive approach, using rough sketches of desired structures as the starting point. The proposed pipeline helps to reduce the reliance on manual annotations when training deep learning-based segmentation approaches and enables the segmentation of diverse datasets without the need for human annotations. This approach holds great promise in streamlining the data generation process and enabling a more efficient and scalable training of segmentation models, as we show in the example of different practical experiments involving various organisms and cell types.
    
[^125]: 面向时序表格数据的动态特征工程和模型选择方法在制度变化下的应用

    Dynamic Feature Engineering and model selection methods for temporal tabular datasets with regime changes. (arXiv:2301.00790v2 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2301.00790](http://arxiv.org/abs/2301.00790)

    本文提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。使用梯度提升决策树（GBDT）并结合dropout技术的模型具有良好的性能和泛化能力，而动态特征中和则是一种高效而不需要重新训练模型就可以应用于任何机器学习模型中的后处理技术。

    

    由于严重的非平稳性，将深度学习算法应用于时序面板数据集是困难的，这可能导致过度拟合的模型在制度变化下性能不佳。在本文中，我们提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。管道评估不同的机器学习模型，包括梯度提升决策树（GBDT）和具有和不具有简单特征工程的神经网络。我们发现，具有dropout的GBDT模型具有高性能、稳健性和泛化能力，而且相对复杂度较低、计算成本较低。然后，我们展示了在线学习技术可以在预测后处理中用于增强结果。特别地，我们提出了动态特征中和，这是一种无需重新训练模型就可以应用于任何机器学习模型的高效过程。

    The application of deep learning algorithms to temporal panel datasets is difficult due to heavy non-stationarities which can lead to over-fitted models that under-perform under regime changes. In this work we propose a new machine learning pipeline for ranking predictions on temporal panel datasets which is robust under regime changes of data. Different machine-learning models, including Gradient Boosting Decision Trees (GBDTs) and Neural Networks with and without simple feature engineering are evaluated in the pipeline with different settings. We find that GBDT models with dropout display high performance, robustness and generalisability with relatively low complexity and reduced computational cost. We then show that online learning techniques can be used in post-prediction processing to enhance the results. In particular, dynamic feature neutralisation, an efficient procedure that requires no retraining of models and can be applied post-prediction to any machine learning model, impr
    
[^126]: Genie: 展示我量化的数据

    Genie: Show Me the Data for Quantization. (arXiv:2212.04780v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04780](http://arxiv.org/abs/2212.04780)

    Genie提出了一个后训练量化方案，用于开发轻量级深度神经网络，并提出了一个用于生成适合零样本量化的数据的框架。

    

    当数据因为各种原因（包括成本和隐私问题）无法访问时，零样本量化是开发轻量级深度神经网络的一种有前途的方法。通过利用FP32预训练模型中批归一化层的学习参数（$\mu$和$\sigma$），零样本量化方案专注于生成合成数据。随后，它们从预训练模型（教师）中提取知识，传递给量化模型（学生），使得量化模型可以使用合成数据集进行优化。然而，到目前为止，零样本量化主要在量化感知训练方法的上下文中讨论，这些方法需要任务特定的损失和长期的优化，就像需要重新训练一样。因此，我们引入了一个后训练量化方案，用于零样本量化，可以在几小时内生成高质量的量化网络。此外，我们提出了一个名为“Genie”的框架，用于生成适合零样本量化的数据。

    Zero-shot quantization is a promising approach for developing lightweight deep neural networks when data is inaccessible owing to various reasons, including cost and issues related to privacy. By exploiting the learned parameters ($\mu$ and $\sigma$) of batch normalization layers in an FP32-pre-trained model, zero-shot quantization schemes focus on generating synthetic data. Subsequently, they distill knowledge from the pre-trained model (teacher) to the quantized model (student) such that the quantized model can be optimized with the synthetic dataset. However, thus far, zero-shot quantization has primarily been discussed in the context of quantization-aware training methods, which require task-specific losses and long-term optimization as much as retraining. We thus introduce a post-training quantization scheme for zero-shot quantization that produces high-quality quantized networks within a few hours. Furthermore, we propose a framework called \genie~that generates data suited for q
    
[^127]: 选择性记忆递归最小二乘法：将遗忘转化为径向基神经网络实时学习中的记忆 (arXiv:2211.07909v2 [eess.SY] UPDATED)

    Selective Memory Recursive Least Squares: Recast Forgetting into Memory in RBF Neural Network Based Real-Time Learning. (arXiv:2211.07909v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2211.07909](http://arxiv.org/abs/2211.07909)

    本文提出了一种名为选择性记忆递归最小二乘法（SMRLS）的实时训练方法，将经典遗忘机制转化为记忆机制，通过综合评估样本的采集时间和时空分布来评估样本的重要性。

    

    在基于径向基函数神经网络（RBFNN）的实时学习任务中，广泛使用遗忘机制以使神经网络对新数据保持敏感性。然而，通过遗忘机制，一些有用的知识会因为它们学习很久以前而被遗忘，这被称为被动知识遗忘现象。为了解决这个问题，本文提出了一种实时训练方法，名为选择性记忆递归最小二乘法（SMRLS），其中将经典遗忘机制转化为一种记忆机制。与遗忘机制不同，该记忆机制主要通过样本的采集时间以及时空分布评估样本的重要性。通过SMRLS，RBFNN的输入空间被均匀划分为有限数量的分区，并使用综合目标函数进行综合开发。

    In radial basis function neural network (RBFNN) based real-time learning tasks, forgetting mechanisms are widely used such that the neural network can keep its sensitivity to new data. However, with forgetting mechanisms, some useful knowledge will get lost simply because they are learned a long time ago, which we refer to as the passive knowledge forgetting phenomenon. To address this problem, this paper proposes a real-time training method named selective memory recursive least squares (SMRLS) in which the classical forgetting mechanisms are recast into a memory mechanism. Different from the forgetting mechanism, which mainly evaluates the importance of samples according to the time when samples are collected, the memory mechanism evaluates the importance of samples through both temporal and spatial distribution of samples. With SMRLS, the input space of the RBFNN is evenly divided into a finite number of partitions and a synthesized objective function is developed using synthesized 
    
[^128]: 在Airbnb上学习多样化的排序方法

    Learning To Rank Diversely At Airbnb. (arXiv:2210.07774v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.07774](http://arxiv.org/abs/2210.07774)

    这篇论文研究了在Airbnb上学习多样化的排序方法。通过纠正传统排序框架中的假设，提出了一种基于高效神经网络架构的排序策略，以实现更准确的房源匹配，并加入了考虑房源相似性的方法以实现多样化的排序。

    

    Airbnb是一个双边市场，将出租房源的房东与来自全球的潜在客人联系在一起。将基于神经网络的学习排序技术应用到匹配客人与房东的过程中已经取得了显著的改进。这些排序改进是通过一种核心策略驱动的：按照其预计的预订概率对房源进行排序，然后迭代地改进这些预订概率估计的技术。然而，这一策略暗含的一个假设是，搜索结果中的每个房源的预订概率可以独立确定。本文讨论了这个假设的错误，并提供了一个纠正这个假设的理论基础，以及基于该理论的高效神经网络架构。通过显式考虑房源之间的可能相似性并减小它们的方法，实现了多样化排序。

    Airbnb is a two-sided marketplace, bringing together hosts who own listings for rent, with prospective guests from around the globe. Applying neural network-based learning to rank techniques has led to significant improvements in matching guests with hosts. These improvements in ranking were driven by a core strategy: order the listings by their estimated booking probabilities, then iterate on techniques to make these booking probability estimates more and more accurate. Embedded implicitly in this strategy was an assumption that the booking probability of a listing could be determined independently of other listings in search results. In this paper we discuss how this assumption, pervasive throughout the commonly-used learning to rank frameworks, is false. We provide a theoretical foundation correcting this assumption, followed by efficient neural network architectures based on the theory. Explicitly accounting for possible similarities between listings, and reducing them to diversify
    
[^129]: 基于脉冲神经网络的事件驱动动作识别：理解其优势的新任务

    Spiking Neural Networks for event-based action recognition: A new task to understand their advantage. (arXiv:2209.14915v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.14915](http://arxiv.org/abs/2209.14915)

    本文通过提出新任务DVS-GC并进行实证研究，展示了脉冲神经网络在事件驱动动作识别中的优势，包括实现时间特征提取和对事件顺序的理解。

    

    脉冲神经网络具有独特的时间动态特性，但是这种计算的性质和优势仍然不太被了解。为了提供答案，本文展示了如何在前馈神经网络中利用脉冲神经元实现时间特征提取，无需递归突触，并展示了它们与传统神经元的差异。通过提出一个新任务DVS-Gesture-Chain（DVS-GC），我们首次对现实中的事件驱动动作识别数据集中的时间依赖进行了评估。我们的研究证明了广泛使用的DVS Gesture基准可以被不进行时间特征提取的网络解决，而新的DVS-GC则需要对事件的顺序进行理解。

    Spiking Neural Networks (SNN) are characterised by their unique temporal dynamics, but the properties and advantages of such computations are still not well understood. In order to provide answers, in this work we demonstrate how Spiking neurons can enable temporal feature extraction in feed-forward neural networks without the need for recurrent synapses, showing how their bio-inspired computing principles can be successfully exploited beyond energy efficiency gains and evidencing their differences with respect to conventional neurons. This is demonstrated by proposing a new task, DVS-Gesture-Chain (DVS-GC), which allows, for the first time, to evaluate the perception of temporal dependencies in a real event-based action recognition dataset. Our study proves how the widely used DVS Gesture benchmark could be solved by networks without temporal feature extraction, unlike the new DVS-GC which demands an understanding of the ordering of the events. Furthermore, this setup allowed us to un
    
[^130]: 针对高效稳健训练的对抗性核心集选择

    Adversarial Coreset Selection for Efficient Robust Training. (arXiv:2209.05785v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.05785](http://arxiv.org/abs/2209.05785)

    本文提出了一种对抗性核心集选择的方法，通过选择训练数据的小子集来降低稳健训练的时间复杂度，并提供了收敛保证。

    

    神经网络对对抗攻击具有脆弱性：向其输入加入微小但精心制作的扰动可以改变其输出。对抗训练是训练抵御此类攻击的最有效方法之一。不幸的是，这种方法比原始神经网络的训练慢得多，因为它需要在每次迭代中为整个训练数据构建对抗性示例。通过利用核心集选择理论，我们展示了选择训练数据的一个小子集是减少稳健训练时间复杂度的一个有原则方法。为此，我们首先提供了对抗性核心集选择的收敛保证。特别地，我们展示了收敛上界与核心集能够近似计算整个训练数据梯度的能力之间的直接关系。受到我们的理论分析的启发，我们提出使用梯度近似误差作为对抗性核心集选择目标。

    Neural networks are vulnerable to adversarial attacks: adding well-crafted, imperceptible perturbations to their input can modify their output. Adversarial training is one of the most effective approaches to training robust models against such attacks. Unfortunately, this method is much slower than vanilla training of neural networks since it needs to construct adversarial examples for the entire training data at every iteration. By leveraging the theory of coreset selection, we show how selecting a small subset of training data provides a principled approach to reducing the time complexity of robust training. To this end, we first provide convergence guarantees for adversarial coreset selection. In particular, we show that the convergence bound is directly related to how well our coresets can approximate the gradient computed over the entire training data. Motivated by our theoretical analysis, we propose using this gradient approximation error as our adversarial coreset selection obj
    
[^131]: 机器学习和计算机视觉技术在蜜蜂监测应用中的应用

    Machine Learning and Computer Vision Techniques in Bee Monitoring Applications. (arXiv:2208.00085v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2208.00085](http://arxiv.org/abs/2208.00085)

    本文介绍了机器学习和计算机视觉在蜜蜂监测中的最新应用，展示了自动化蜜蜂计数算法的潜力，并希望能够激发其他科学家的灵感和兴趣。

    

    机器学习和计算机视觉是快速发展的领域，已经证明能够解决非常复杂的任务。它们可以用于监测蜜蜂群体并检查其健康状况，从而在情况变得严重之前，识别出潜在危险状态，或者更好地计划定期蜜蜂群体检查，从而节省重要的成本。本文概述了用于蜜蜂监测的最先进的计算机视觉和机器学习应用，并以自动化蜜蜂计数算法为例展示了这些方法的潜力。本文面向兽医学和蜜蜂学专业人员和专家，旨在向他们介绍机器学习的可能性，因此每个应用类别都以简要的理论介绍和与其基本方法相关的动机开篇。我们希望这篇论文能激发其他科学家的灵感...

    Machine learning and computer vision are dynamically growing fields, which have proven to be able to solve very complex tasks. They could also be used for the monitoring of the honeybee colonies and for the inspection of their health state, which could identify potentially dangerous states before the situation is critical, or to better plan periodic bee colony inspections and therefore save significant costs. In this paper, we present an overview of the state-of-the-art computer vision and machine learning applications used for bee monitoring. We also demonstrate the potential of those methods as an example of an automated bee counter algorithm. The paper is aimed at veterinary and apidology professionals and experts, who might not be familiar with machine learning to introduce to them its possibilities, therefore each family of applications is opened by a brief theoretical introduction and motivation related to its base method. We hope that this paper will inspire other scientists to 
    
[^132]: 非平稳马尔可夫环境中基于集合的值运算符

    Set-based value operators for non-stationary Markovian environments. (arXiv:2207.07271v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.07271](http://arxiv.org/abs/2207.07271)

    本文将Bellman算子和策略评估算子推广为值函数空间上的压缩算子，并将其提升为作用于值函数集合的基于集合的值运算符。利用集合论的见解，我们将经典鲁棒MDP文献中的矩形条件推广为适用于更多参数不确定MDP和动态规划中的压缩算子的包含条件。研究结果表明，基于集合的值运算符具有压缩性。

    

    本文分析了具有不确定参数的有限状态马尔可夫决策过程（MDP），并通过基于集合的不动点理论重新审视了鲁棒MDP的结果。为此，我们将Bellman算子和策略评估算子推广为值函数空间上的压缩算子，并称之为“值运算符”。我们将这些值运算符提升为作用于值函数集合的“基于集合的值运算符”。我们证明了在紧致值函数集合空间中，基于集合的值运算符是“压缩”运算符。借助集合论的见解，我们将经典鲁棒MDP文献中的矩形条件推广为适用于更多参数不确定MDP和动态规划中的压缩算子的包含条件，该条件相对较弱。我们证明了矩形条件和包含条件都足以确保基于集合的值运算符的奇性。

    This paper analyzes finite state Markov Decision Processes (MDPs) with uncertain parameters in compact sets and re-examines results from robust MDP via set-based fixed point theory. To this end, we generalize the Bellman and policy evaluation operators to contracting operators on the value function space and denote them as \emph{value operators}. We lift these value operators to act on \emph{sets} of value functions and denote them as \emph{set-based value operators}. We prove that the set-based value operators are \emph{contractions} in the space of compact value function sets. Leveraging insights from set theory, we generalize the rectangularity condition in classic robust MDP literature to a containment condition for all value operators, which is weaker and can be applied to a larger set of parameter-uncertain MDPs and contracting operators in dynamic programming. We prove that both the rectangularity condition and the containment condition sufficiently ensure that the set-based val
    
[^133]: 自动编码对抗性模仿学习

    Auto-Encoding Adversarial Imitation Learning. (arXiv:2206.11004v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.11004](http://arxiv.org/abs/2206.11004)

    自动编码对抗性模仿学习（AEAIL）是一种稳健且可扩展的方法，利用自动编码器的重构误差作为奖励信号来优化策略。在基于状态和基于图像的环境中，AEAIL比现有方法表现更好，并且对于噪声示范专家具有更好的稳健性。

    

    强化学习（RL）提供了一个强大的决策框架，但在实践中，其应用通常需要精心设计的奖励函数。对抗性模仿学习（AIL）揭示了在没有来自环境的奖励信号的情况下自动获取策略的方法。在这项工作中，我们提出了一种稳健且可扩展的自动编码对抗性模仿学习（AEAIL）框架。为了从示范中推导出专家策略，AEAIL利用自动编码器的重构误差作为奖励信号，这比之前基于鉴别器的方法提供了更多用于优化策略的信息。随后，我们使用所得到的目标函数训练自动编码器和智能体策略。实验证明，我们的AEAIL在基于状态和基于图像的环境中表现优于现有方法。更重要的是，当示范专家具有噪声时，AEAIL表现出更好的稳健性。

    Reinforcement learning (RL) provides a powerful framework for decision-making, but its application in practice often requires a carefully designed reward function. Adversarial Imitation Learning (AIL) sheds light on automatic policy acquisition without access to the reward signal from the environment. In this work, we propose Auto-Encoding Adversarial Imitation Learning (AEAIL), a robust and scalable AIL framework. To induce expert policies from demonstrations, AEAIL utilizes the reconstruction error of an auto-encoder as a reward signal, which provides more information for optimizing policies than the prior discriminator-based ones. Subsequently, we use the derived objective functions to train the auto-encoder and the agent policy. Experiments show that our AEAIL performs superior compared to state-of-the-art methods on both state and image based environments. More importantly, AEAIL shows much better robustness when the expert demonstrations are noisy.
    
[^134]: ORC: 利用在线角色变换的网络群组知识蒸馏

    ORC: Network Group-based Knowledge Distillation using Online Role Change. (arXiv:2206.01186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01186](http://arxiv.org/abs/2206.01186)

    本文提出了一种利用在线角色变换的网络群组知识蒸馏方法，通过将多个网络分成教师组和学生组，学生组学习教师的知识，使用在线角色变换策略将学生组中排名靠前的网络晋升为教师组，通过训练教师组以改进其知识，实现了更好的知识蒸馏效果。

    

    在知识蒸馏中，由于单一的全能教师网络无法解决所有问题，最近研究了基于多个教师的知识蒸馏。然而，有时它们的改进效果并不如预期，因为一些不成熟的教师可能会将错误的知识传输给学生。为了克服这个限制并利用多个网络的能力，本文将多个网络分成教师组和学生组。学生组由需要学习教师知识的不成熟网络组成，而教师组则由能够成功教授的选中网络组成。我们提出了在线角色变换策略，在每次迭代中将学生组中排名靠前的网络晋升为教师组。通过使用学生组的错误样本训练教师组以改进其知识，我们转移协作知识。

    In knowledge distillation, since a single, omnipotent teacher network cannot solve all problems, multiple teacher-based knowledge distillations have been studied recently. However, sometimes their improvements are not as good as expected because some immature teachers may transfer the false knowledge to the student. In this paper, to overcome this limitation and take the efficacy of the multiple networks, we divide the multiple networks into teacher and student groups, respectively. That is, the student group is a set of immature networks that require learning the teacher's knowledge, while the teacher group consists of the selected networks that are capable of teaching successfully. We propose our online role change strategy where the top-ranked networks in the student group are able to promote to the teacher group at every iteration. After training the teacher group using the error samples of the student group to refine the teacher group's knowledge, we transfer the collaborative kno
    
[^135]: 可微分合成孔径雷达成像标题

    Differentiable Rendering for Synthetic Aperture Radar Imagery. (arXiv:2204.01248v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2204.01248](http://arxiv.org/abs/2204.01248)

    本研究提出了一种可微分合成孔径雷达成像方法，用于三维物体重建，通过结合三维计算机图形学方法和神经渲染技术，使用高保真度的模拟SAR数据进行验证。

    

    最近对于可微分合成孔径雷达（SAR）成像的兴趣日益增加，这种方法允许使用反向传播等一阶方法来明确地建模几何先验和约束，以优化流水线。将领域知识纳入其中可以训练出更稳健且数据需求较小的深度神经网络，同时能够解决病态的逆问题。现有的可微分合成孔径雷达成像工作主要集中在电光传感器成像，特别是传统的RGB成像。本文提出了一种可微分合成孔径雷达成像方法，将三维计算机图形学方法与神经渲染相结合。我们通过使用高保真度的模拟SAR数据，以有限的SAR成像来实现了对三维物体重建的逆图形学问题的方法。

    There is rising interest in differentiable rendering, which allows explicitly modeling geometric priors and constraints in optimization pipelines using first-order methods such as backpropagation. Incorporating such domain knowledge can lead to deep neural networks that are trained more robustly and with limited data, as well as the capability to solve ill-posed inverse problems. Existing efforts in differentiable rendering have focused on imagery from electro-optical sensors, particularly conventional RGB-imagery. In this work, we propose an approach for differentiable rendering of Synthetic Aperture Radar (SAR) imagery, which combines methods from 3D computer graphics with neural rendering. We demonstrate the approach on the inverse graphics problem of 3D Object Reconstruction from limited SAR imagery using high-fidelity simulated SAR data.
    
[^136]: 图神经网络的可传递性特性

    Transferability Properties of Graph Neural Networks. (arXiv:2112.04629v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.04629](http://arxiv.org/abs/2112.04629)

    本文研究了将图神经网络（GNNs）从中等规模图迁移到大规模图的问题，并通过引入图核密度滤波器和图核密度神经网络（WNNs）的概念，提出了逼近方法以限定迁移误差。

    

    图神经网络（GNNs）由图卷积和逐点非线性层组成。由于它们的不变性和稳定性特性，GNNs在学习基于中等规模图的数据表示方面被证明是成功的。然而，它们在大规模图上的学习很困难。本文研究了在中等规模图上训练GNNs并将它们迁移到大规模图上的问题。我们使用称为图核密度的图限制来定义图滤波器和GNNs的极限对象 - 图核密度滤波器和图核密度神经网络（WNNs），我们将它们解释为图滤波器和GNNs的生成模型。然后，我们展示了图核密度滤波器和WNNs可以通过从它们上进行采样的图滤波器和GNNs在加权和随机图上进行逼近。由于这些逼近的误差可以得到上界，通过三角不等式的论证我们可以进一步界定在不同图之间传递图滤波器或GNN的误差。

    Graph neural networks (GNNs) are composed of layers consisting of graph convolutions and pointwise nonlinearities. Due to their invariance and stability properties, GNNs are provably successful at learning representations from data supported on moderate-scale graphs. However, they are difficult to learn on large-scale graphs. In this paper, we study the problem of training GNNs on graphs of moderate size and transferring them to large-scale graphs. We use graph limits called graphons to define limit objects for graph filters and GNNs -- graphon filters and graphon neural networks (WNNs) -- which we interpret as generative models for graph filters and GNNs. We then show that graphon filters and WNNs can be approximated by graph filters and GNNs sampled from them on weighted and stochastic graphs. Because the error of these approximations can be upper bounded, by a triangle inequality argument we can further bound the error of transferring a graph filter or a GNN across graphs. Our resul
    
[^137]: 带有核的复合适合性检验方法

    Composite Goodness-of-fit Tests with Kernels. (arXiv:2111.10275v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.10275](http://arxiv.org/abs/2111.10275)

    本文提出了一种基于核的假设检验方法，可以解决具有挑战性的复合检验问题，其核心思想是在正确的模型规范的零假设下，非参数地估计参数（或模拟器）分布。

    

    模型错误说明可能会对概率模型的实现造成重大挑战，这促使开发出一些直接解决此问题的鲁棒方法。但是，这些更为复杂的方法是否需要取决于模型是否真的错误，目前缺乏通用的方法回答这个问题。在本文中，我们提出了一种方法。更具体地说，我们提出了基于核的假设检验方法，用于具有挑战性的复合检验问题，即我们是否感兴趣的数据来自某些参数模型族中的任何分布。我们的测试利用基于最大均值差异和核Stein差异的最小距离估计器。它们具有广泛的适用性，包括当参数模型的密度已知除标准化常数外，或者如果模型采用模拟器形式。作为我们的主要结果，我们展示了在正确的模型规范的零假设下，我们能够非参数地估计参数（或模拟器）分布。我们提供了建立我们方法有效性的理论，并通过模拟和异常检测应用案例演示了其性能。

    Model misspecification can create significant challenges for the implementation of probabilistic models, and this has led to development of a range of robust methods which directly account for this issue. However, whether these more involved methods are required will depend on whether the model is really misspecified, and there is a lack of generally applicable methods to answer this question. In this paper, we propose one such method. More precisely, we propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on the maximum mean discrepancy and the kernel Stein discrepancy. They are widely applicable, including whenever the density of the parametric model is known up to normalisation constant, or if the model takes the form of a simulator. As our main result, we show that we are able to estimate the param
    
[^138]: 在巴拿赫空间中对线性函数数据的正则化学习的分析

    Analysis of Regularized Learning for Linear-functional Data in Banach Spaces. (arXiv:2109.03159v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.03159](http://arxiv.org/abs/2109.03159)

    本文研究了巴拿赫空间中线性函数数据的正则化学习的整个理论，包括表示定理、伪逼近定理和收敛定理。正则化学习通过最小化正则化经验风险来逼近未知或未明确的原问题的精确解，并且可以应用于解决多种问题。

    

    本文研究了巴拿赫空间中线性函数数据的正则化学习的整个理论，包括表示定理、伪逼近定理和收敛定理。输入的训练数据由巴拿赫空间的前对偶空间中的线性函数组成，以表示多模型数据和多尺度模型的离散局部信息。训练数据和多损失函数被用来计算经验风险以逼近期望风险，而正则化学习则是通过最小化巴拿赫空间上的正则化经验风险来实现的。即使原问题未知或未明确，正则化学习也可以全局逼近原问题的精确解。在收敛定理中，我们通过巴拿赫空间的弱*拓扑证明了近似解收敛于精确解。此外，正则化学习定理被应用于解决许多问题。

    In this article, we study the whole theory of regularized learning for linear-functional data in Banach spaces including representer theorems, pseudo-approximation theorems, and convergence theorems. The input training data are composed of linear functionals in the predual space of the Banach space to represent the discrete local information of multimodel data and multiscale models. The training data and the multi-loss functions are used to compute the empirical risks to approximate the expected risks, and the regularized learning is to minimize the regularized empirical risks over the Banach spaces. The exact solutions of the original problems are approximated globally by the regularized learning even if the original problems are unknown or unformulated. In the convergence theorems, we show the convergence of the approximate solutions to the exact solutions by the weak* topology of the Banach space. Moreover, the theorems of the regularized learning are applied to solve many problems 
    
[^139]: 高斯过程回归的实用且严格的不确定性界限

    Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression. (arXiv:2105.02796v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.02796](http://arxiv.org/abs/2105.02796)

    高斯过程回归提供了不确定性估计，但其贝叶斯性质限制了其在某些重要应用中的使用。为解决这一问题，我们提出了实用且严格的不确定性界限，相比现有结果更准确，并且对模型偏差有优雅的退化。

    

    高斯过程回归是一种基于贝叶斯原理的流行的非参数回归方法，可以提供其预测的不确定性估计。然而，这些估计是贝叶斯性质的，对于一些重要的应用，如具有安全保证的基于学习的控制，需要频率的不确定性界限。尽管对于高斯过程，这样严格的界限有可用，但它们过于保守，在应用中没有用处。这通常导致实践者用启发式方法替代这些界限，从而破坏了所有的理论保证。为了解决这个问题，我们引入了新的不确定性界限，既严格又实用。特别地，这些界限可以明确地评估，并且比现有结果要保守得多。此外，我们还展示了某些模型偏差只会引起优雅的退化。我们展示了这些优势以及我们结果在基于学习的控制中的实用性。

    Gaussian Process Regression is a popular nonparametric regression method based on Bayesian principles that provides uncertainty estimates for its predictions. However, these estimates are of a Bayesian nature, whereas for some important applications, like learning-based control with safety guarantees, frequentist uncertainty bounds are required. Although such rigorous bounds are available for Gaussian Processes, they are too conservative to be useful in applications. This often leads practitioners to replacing these bounds by heuristics, thus breaking all theoretical guarantees. To address this problem, we introduce new uncertainty bounds that are rigorous, yet practically useful at the same time. In particular, the bounds can be explicitly evaluated and are much less conservative than state of the art results. Furthermore, we show that certain model misspecifications lead to only graceful degradation. We demonstrate these advantages and the usefulness of our results for learning-based
    
[^140]: 用于快速发现增强传热的层流流道壁修饰的机器学习

    Machine learning for rapid discovery of laminar flow channel wall modifications that enhance heat transfer. (arXiv:2101.08130v2 [physics.flu-dyn] UPDATED)

    [http://arxiv.org/abs/2101.08130](http://arxiv.org/abs/2101.08130)

    本文提出了一种组合精确数值模拟和机器学习模型的方法，用于快速发现增强传热的层流流道壁修饰。通过卷积神经网络的预测，可以在较短时间内准确评估壁面性能，并且可以应用于大规模的壁面结构筛选。

    

    流体的数值模拟在建模许多物理现象中起着重要作用，它促进了技术的进步，有助于可持续发展的实践，并扩大了我们对各种自然和工程系统的理解。在简单平板流道中的流体传热计算对于各种模拟方法来说是相对容易的任务。然而，一旦流道几何形状变得更加复杂，数值模拟就成为优化壁面几何的瓶颈。我们提出了精确的数值模拟任意平板和非平板流道以及预测阻力系数和斯坦顿数的机器学习模型的组合。我们展示了卷积神经网络 (CNN) 可以准确地预测目标性质，且所需时间仅是数值模拟的一小部分。我们将这些 CNN 模型用于虚拟高通量筛选方法，以探索大量可能的随机生成的壁面结构。数据增强是一项重要的技术...

    Numerical simulation of fluids plays an essential role in modeling many physical phenomena, which enables technological advancements, contributes to sustainable practices, and expands our understanding of various natural and engineered systems. The calculation of heat transfer in fluid flow in simple flat channels is a relatively easy task for various simulation methods. However, once the channel geometry becomes more complex, numerical simulations become a bottleneck in optimizing wall geometries. We present a combination of accurate numerical simulations of arbitrary, flat, and non-flat channels and machine learning models predicting drag coefficient and Stanton number. We show that convolutional neural networks (CNN) can accurately predict the target properties at a fraction of the time of numerical simulations. We use the CNN models in a virtual high-throughput screening approach to explore a large number of possible, randomly generated wall architectures. Data Augmentation was app
    
[^141]: 用模拟退火机器学习贝叶斯网络

    Learning Bayesian Networks with Annealing Machine. (arXiv:2006.06926v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.06926](http://arxiv.org/abs/2006.06926)

    本文提出了一种用于贝叶斯网络结构学习的模拟退火机器方法，通过先进的候选父节点集合的确定和分解，以及整数规划问题的解决，能够在比特容量有限的情况下高效地解决基于评分的学习问题。

    

    最近的研究表明，模拟退火机器能够高精度地解决组合优化问题。模拟退火机器有潜力用于基于评分的贝叶斯网络结构学习。然而，模拟退火机器的比特容量目前有限。为了利用模拟退火技术，需要将基于评分的学习问题转化为在比特容量内的二次无约束二元优化问题。在本文中，我们提出了一种高效的转化方法，通过先进的候选父节点集合的确定和其分解。我们还提供了一个整数规划问题，以找到最小化所需比特数的分解。在包含变量从75到223的7个基准数据集上的实验结果表明，我们的方法所需的比特数比四代富士通数字退火器（一种采用半导体技术开发的全耦合模拟退火机器）的100K比特容量少。

    Recent studies have reported that annealing machines are capable of solving combinatorial optimization problems with high accuracy. Annealing machines can potentially be applied to score-based Bayesian network structure learning. However, the bit capacity of an annealing machine is currently limited. To utilize the annealing technology, converting score-based learning problems into quadratic unconstrained binary optimizations within the bit capacity is necessary. In this paper, we propose an efficient conversion method with the advanced identification of candidate parent sets and their decomposition. We also provide an integer programming problem to find the decomposition that minimizes the number of required bits. Experimental results on $7$ benchmark datasets with variables from $75$ to $223$ show that our approach requires less bits than the $100$K bit capacity of the fourth-generation Fujitsu Digital Annealer, a fully coupled annealing machine developed with semiconductor technolog
    
[^142]: 判别器最优输运

    Discriminator optimal transport. (arXiv:1910.06832v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/1910.06832](http://arxiv.org/abs/1910.06832)

    这篇论文研究了判别器优化过程如何增加生成对抗网络中Wasserstein距离的对偶代价函数的下限，从而使训练好的判别器能够近似最优输运。作者提出了一种判别器最优输运（DOT）方案，通过实验证明了在不同数据集上的生成图像质量有所提升。

    

    在广泛的生成对抗网络中，我们展示了判别器优化过程增加了目标分布$p$和生成器分布$p_G$之间Wasserstein距离的对偶代价函数的下限。这意味着训练好的判别器可以近似从$p_G$到$p$的最优输运。基于一些实验和一点输运理论，我们提出了一种判别器最优输运（DOT）方案来改进生成的图像。我们展示了它在CIFAR-10、STL-10和一个以ImageNet为条件的预训练模型训练的无条件GAN计算的内涵分数和FID上的改进。

    Within a broad class of generative adversarial networks, we show that discriminator optimization process increases a lower bound of the dual cost function for the Wasserstein distance between the target distribution $p$ and the generator distribution $p_G$. It implies that the trained discriminator can approximate optimal transport (OT) from $p_G$ to $p$.Based on some experiments and a bit of OT theory, we propose a discriminator optimal transport (DOT) scheme to improve generated images. We show that it improves inception score and FID calculated by un-conditional GAN trained by CIFAR-10, STL-10 and a public pre-trained model of conditional GAN by ImageNet.
    

