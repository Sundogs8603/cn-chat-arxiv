# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Foundation Model is Efficient Multimodal Multitask Model Selector.](http://arxiv.org/abs/2308.06262) | 本文提出了一种高效的多模态多任务模型选择器（EMMS），它使用大规模的基础模型将不同任务的标签格式转换为统一的噪声标签嵌入，通过简单的加权线性回归来估计模型的可迁移性。 |
| [^2] | [FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods.](http://arxiv.org/abs/2308.06248) | FunnyBirds是一种合成视觉数据集，用于分析可解释AI方法。它允许对图像进行语义上有意义的干预，并可以在部分级别上对解释进行评估和分析。 |
| [^3] | [Private Distribution Learning with Public Data: The View from Sample Compression.](http://arxiv.org/abs/2308.06239) | 本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。 |
| [^4] | [MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features.](http://arxiv.org/abs/2308.06228) | MaxFloodCast是一个用于预测洪水淹没深度和解读影响因素的机器学习模型，通过基于物理的水动力模拟进行训练，在预测峰值洪水淹没深度方面表现出可靠性。它还显示了在支持洪水管理和应急行动方面的潜力，同时通过提供关键信息帮助决策者制定洪水防治策略和优先考虑临界设施区域的重要性，并研究其他流域降雨对洪水暴露的影响。 |
| [^5] | [Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms.](http://arxiv.org/abs/2308.06221) | 该论文提出了一种多步训练方法，用于设计深度自编码器，并通过修剪和增长方法以及优化隐藏层大小和训练时长来改善其性能。 |
| [^6] | [Change Point Detection With Conceptors.](http://arxiv.org/abs/2308.06213) | 我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。 |
| [^7] | [Safety in Traffic Management Systems: A Comprehensive Survey.](http://arxiv.org/abs/2308.06204) | 本研究综述了交通管理系统安全性的文献，总结了交通管理系统中的安全问题、当前的研究现状以及确保安全性的技术和方法。这项综述还提出了现有研究的局限性，并提出了未来研究的方向。 |
| [^8] | [Towards a Causal Probabilistic Framework for Prediction, Action-Selection & Explanations for Robot Block-Stacking Tasks.](http://arxiv.org/abs/2308.06203) | 这项工作提出了一个新颖的因果性概率框架，用于解决机器人堆积方块任务的问题，通过结合因果推断，使机器人能够理解、推理和解释其环境。 |
| [^9] | [Exploring Predicate Visual Context in Detecting of Human-Object Interactions.](http://arxiv.org/abs/2308.06202) | 本文研究了在人物和物体交互检测中的谓词视觉背景问题，并通过交叉注意力和盒子配对位置嵌入等方式来改进模型，取得了比现有方法更好的性能。 |
| [^10] | [Complex Facial Expression Recognition Using Deep Knowledge Distillation of Basic Features.](http://arxiv.org/abs/2308.06197) | 这项研究提出了一种基于深度知识蒸馏的新颖持续学习方法，通过使用少量训练样本，能够准确识别新的复合表情类别。 |
| [^11] | [Assessing Guest Nationality Composition from Hotel Reviews.](http://arxiv.org/abs/2308.06175) | 本文利用机器学习从非结构化文本评论中提取客人国籍的引用，并展示了一个相对简单的架构可以提供更好的性能和运行时间的权衡。 |
| [^12] | [Physical Adversarial Attacks For Camera-based Smart Systems: Current Trends, Categorization, Applications, Research Challenges, and Future Outlook.](http://arxiv.org/abs/2308.06173) | 本文调查了当前的物理对抗攻击趋势，分析了物理对抗攻击的特点和挑战。研究了不同应用中的攻击方法，并评估了它们的效果和鲁棒性。此外，讨论了未来的研究方向。 |
| [^13] | [Phased Deep Spatio-temporal Learning for Highway Traffic Volume Prediction.](http://arxiv.org/abs/2308.06155) | 本论文提出了一种基于阶段性深度时空学习方法，用于预测城际高速公路的每日交通量。该方法通过精心的数据规范化、混合模型结合以及考虑来自异构数据的多个要素，有效解决了交通量预测中的时空特征和数据不平衡问题。 |
| [^14] | [Gaussian Process Regression for Maximum Entropy Distribution.](http://arxiv.org/abs/2308.06149) | 本论文研究了高斯过程回归用于近似最大熵分布中的拉格朗日乘子，通过优化超参数来实现数据驱动的最大熵闭合。通过对比多个测试案例，验证了该方法的有效性。 |
| [^15] | [Identification of the Relevance of Comments in Codes Using Bag of Words and Transformer Based Models.](http://arxiv.org/abs/2308.06144) | 本研究通过使用词袋和基于Transformer的模型，对代码注释的相关性进行识别。在训练语料库中，探索了不同的特征工程和文本分类技术，并比较了传统词袋模型和Transformer模型的性能。 |
| [^16] | [CompTLL-UNet: Compressed Domain Text-Line Localization in Challenging Handwritten Documents using Deep Feature Learning from JPEG Coefficients.](http://arxiv.org/abs/2308.06142) | 本文提出了一种使用JPEG压缩系数进行深度特征学习的方法，实现在具有挑战性的手写文件中的文本行定位。通过设计改进的CompTLL-UNet架构，在JPEG压缩域中直接定位文本行，并在ICDAR2017和ICDAR2019基准数据集上进行了测试和验证。 |
| [^17] | [Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling.](http://arxiv.org/abs/2308.06138) | 这项研究利用人工神经网络模型成功预测了锌生产压力过滤过程中的滤饼含水率，为锌生产工艺提供了可靠的预测手段。 |
| [^18] | [PDE Discovery for Soft Sensors Using Coupled Physics-Informed Neural Network with Akaike's Information Criterion.](http://arxiv.org/abs/2308.06132) | 本文提出了一种使用带有Akaike信息准则的耦合物理信息神经网络（CPINN-AIC）的方法，用于发现软传感器的偏微分方程（PDE）。该方法能够发现PDE的适当结构，包括微分算子和源项，以弥补理想化的PDE与实际情况之间的差距。 |
| [^19] | [Uncertainty Quantification for Image-based Traffic Prediction across Cities.](http://arxiv.org/abs/2308.06129) | 本研究调查了不确定性量化方法在跨城市交通预测中的应用，发现存在的UQ方法可以提供有意义的不确定性估计，并可以用于无监督异常检测。 |
| [^20] | [Learning Control Policies for Variable Objectives from Offline Data.](http://arxiv.org/abs/2308.06127) | 本文介绍了一种基于模型的策略搜索方法的扩展——可变目标策略（VOP），通过该方法，策略可以有效地泛化多种参数化奖励函数的目标。通过改变策略的输入目标，用户可以在运行时自由调整其行为或重新平衡优化目标，无需收集额外的观测数据批次或重新训练。 |
| [^21] | [Hawkes Processes with Delayed Granger Causality.](http://arxiv.org/abs/2308.06106) | 本论文提出了一个基于霍克斯过程的延迟格兰杰因果效应模型，通过显式地建模时间延迟，增加了模型的灵活性，并推断出时间延迟的后验分布，有助于追踪原始因果时间。 |
| [^22] | [Composable Function-preserving Expansions for Transformer Architectures.](http://arxiv.org/abs/2308.06103) | 提出了六个可组合的转换方法，逐渐增加基于Transformer的神经网络的规模，同时保持功能，充分利用现有知识，实现更大和更强大模型的高效培训流程。 |
| [^23] | [Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation.](http://arxiv.org/abs/2308.06100) | 这项研究提出了一个用于对视觉对抗性解释方法进行系统性定量评估的框架，并在最新的生成模型中探索了关键设计选择的影响。研究结果为未来改进VCE方法指明了多个方向。 |
| [^24] | [Neural Conversation Models and How to Rein Them in: A Survey of Failures and Fixes.](http://arxiv.org/abs/2308.06095) | 这项综述研究了以强大语言模型为基础的开放领域对话系统，并探讨了如何通过干预底层语言模型的不同方面，如数据、训练制度或解码，来保证模型的流畅性、信息丰富性、一致性、连贯性以及遵循社会准则的特性。 |
| [^25] | [Reinforcement Logic Rule Learning for Temporal Point Processes.](http://arxiv.org/abs/2308.06094) | 该论文提出了一个用于时间点过程的强化逻辑规则学习框架，利用逐步优化的方法扩展解释性的规则集来解释时间事件的发生。通过使用神经搜索策略和强化学习框架，可以高效地生成新的规则内容和权重。 |
| [^26] | [Experts Weights Averaging: A New General Training Scheme for Vision Transformers.](http://arxiv.org/abs/2308.06093) | 本文提出了一种新的通用训练策略，利用专家权重平均化实现了对ViTs的性能提升，而不增加推断成本。 |
| [^27] | [Toward a Better Understanding of Loss Functions for Collaborative Filtering.](http://arxiv.org/abs/2308.06091) | 现有研究已经表明，通过改进对齐和均匀性设计的损失函数可以实现显著的性能提升。本文提出了一种新的损失函数，称为MAWU，它考虑了数据集的独特模式。 |
| [^28] | [Safeguarding Learning-based Control for Smart Energy Systems with Sampling Specifications.](http://arxiv.org/abs/2308.06069) | 本研究研究了在能源系统控制中使用强化学习所面临的挑战，提出了一种通过离散化加强安全要求的方法。离散化使得可以使用先进的工程方法并进行形式验证，其中概率保证形成了满足原始安全要求的下界。 |
| [^29] | [Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction.](http://arxiv.org/abs/2308.06058) | 本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。 |
| [^30] | [Cost-effective On-device Continual Learning over Memory Hierarchy with Miro.](http://arxiv.org/abs/2308.06053) | 这项工作是首次探索基于层次内存回放的持续学习的设计空间，旨在在边缘设备上实现成本效益。提出了Miro，一个通过动态配置持续学习系统的新颖系统运行时，以实现最佳的成本效益。广泛的评估显示Miro明显优于其他方案。 |
| [^31] | [Towards Instance-adaptive Inference for Federated Learning.](http://arxiv.org/abs/2308.06051) | 本文提出了一种面向实例自适应推理的联邦学习算法，通过使用缩放和位移深度特征（SSF）实现了处理客户端数据异质性的能力。 |
| [^32] | [Controlling Character Motions without Observable Driving Source.](http://arxiv.org/abs/2308.06025) | 本文提出了一个系统框架，结合了VQ-VAE和使用强化学习训练的一种新型基于令牌级控制策略，通过在顶部注入高级先验模型来生成无限长且多样化的序列。 |
| [^33] | [Large Language Models for Telecom: Forthcoming Impact on the Industry.](http://arxiv.org/abs/2308.06013) | 大型语言模型在电信行业将产生重要的影响。它们可以提高运营效率，简化任务，并需要解决使用中的挑战。 |
| [^34] | [Does AI for science need another ImageNet Or totally different benchmarks? A case study of machine learning force fields.](http://arxiv.org/abs/2308.05999) | 本文研究了AI为科学是否需要新的基准测试方法，并以机器学习势场为案例研究。通过发现并解决在科学基准测试中存在的问题，我们提出了评估MLFF模型的解决方案，包括样本效率、时间域敏感性和数据集之间的泛化能力。 |
| [^35] | [Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance.](http://arxiv.org/abs/2308.05986) | 本论文提出了一种通过评估类内特征方差快速准确地测量可转移性的方法，该方法能够用于选择最适合下游任务的预训练模型，包括有和无分类器的模型，并且适用于选择目标任务的最佳转移层。 |
| [^36] | [Learning nonparametric DAGs with incremental information via high-order HSIC.](http://arxiv.org/abs/2308.05969) | 本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。 |
| [^37] | [Learned Point Cloud Compression for Classification.](http://arxiv.org/abs/2308.05959) | 这篇论文提出了一种针对分类任务的新型点云编解码器，在不牺牲准确性的情况下实现了更高的压缩比，相比其他方法在速度和准确性上取得了更好的对比度-精度平衡，并且在ModelNet40数据集上实现了94%的BD比特率降低。 |
| [^38] | [Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random walks by Graph Edge Weights.](http://arxiv.org/abs/2308.05957) | 提出了一种名为ARGEW的增强随机游走方法，用于生成能够更好反映节点之间边权重的节点嵌入。 |
| [^39] | [INR-Arch: A Dataflow Architecture and Compiler for Arbitrary-Order Gradient Computations in Implicit Neural Representation Processing.](http://arxiv.org/abs/2308.05930) | 本论文提出了INR-Arch，这是一种用于隐式神经表征处理中任意阶梯度计算的数据流架构和编译器。该工作通过将计算图转化为硬件优化的数据流架构来解决了传统架构在高阶梯度计算上的挑战，为FPGA加速提供了有希望的目标。 |
| [^40] | [On the equivalence of Occam algorithms.](http://arxiv.org/abs/2308.05906) | 该论文证明了对于具有独立于δ的复杂度的Occam算法，其部分逆命题适用于闭合于例外列表的概念类，从而为相关的理论结果和算法设计方法提供了事后的理论依据。 |
| [^41] | [Comparing the quality of neural network uncertainty estimates for classification problems.](http://arxiv.org/abs/2308.05903) | 本研究比较了用于分类问题的神经网络的不确定性估计质量，并通过统计方法和指标对不同方法进行了评估。研究展示了这些估计方法的一致性问题。 |
| [^42] | [Learning to Team-Based Navigation: A Review of Deep Reinforcement Learning Techniques for Multi-Agent Pathfinding.](http://arxiv.org/abs/2308.05893) | 本文综述了在多智能体路径规划中深度强化学习技术的应用。与其他研究不同，我们重点介绍了DRL方法在MAPF中的整合，并解决了MAPF解决方案评估指标缺乏统一性的问题。我们讨论了基于模型的DRL作为未来发展方向，并提供了解决MAPF当前挑战所需的基础理解。 |
| [^43] | [DF2: Distribution-Free Decision-Focused Learning.](http://arxiv.org/abs/2308.05889) | DF2是一种无分布的决策焦点学习方法，特别解决了模型不匹配错误、样本平均逼近误差和梯度逼近误差三个瓶颈问题。 |
| [^44] | [GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics Identification through Deep Autoencoder.](http://arxiv.org/abs/2308.05882) | GPLaSDI是一种基于高斯过程的可解释潜空间动力学识别方法，通过深度自动编码器将完全阶数的PDE解映射到潜空间，并使用插值和解决ODE系统进行快速和准确的ROM预测。 |
| [^45] | [Aphid Cluster Recognition and Detection in the Wild Using Deep Learning Models.](http://arxiv.org/abs/2308.05881) | 该论文使用深度学习模型识别和检测野外的蚜虫集群，提出了一种新的方法来估计感染水平，并通过采集大规模数据集进行了验证和比较。 |
| [^46] | [Composable Core-sets for Diversity Approximation on Multi-Dataset Streams.](http://arxiv.org/abs/2308.05878) | 本文介绍了一种用于流式数据的可组合核心集构建算法，其核心子集可以相互合并，用于主动学习环境中。这种核心集可以通过结合CRAIG和加速构建的启发式技术，用于实时训练。 |
| [^47] | [Revisiting N-CNN for Clinical Practice.](http://arxiv.org/abs/2308.05877) | 本文通过优化N-CNN的超参数，并应用软标签得到了一种新的方法来训练新生儿疼痛评估的面部表情分类模型，结果表明在分类指标和可解释性方面有改善，但没有直接转化为校准性能。 |
| [^48] | [UFed-GAN: A Secure Federated Learning Framework with Constrained Computation and Unlabeled Data.](http://arxiv.org/abs/2308.05870) | 本研究提出了一种名为UFed-GAN的框架，它是一个无监督的联邦生成对抗网络，可以在限制计算资源和无标签数据的情况下进行联邦学习，并保护数据隐私。 |
| [^49] | [Using Twitter Data to Determine Hurricane Category: An Experiment.](http://arxiv.org/abs/2308.05866) | 本研究通过研究社交媒体数据和自然灾害之间的关系，找到了Twitter数据与飓风严重程度之间的正相关性，并提出了一种使用相关的Twitter数据来预测特定地区飓风等级的方法。 |
| [^50] | [The Multi-modality Cell Segmentation Challenge: Towards Universal Solutions.](http://arxiv.org/abs/2308.05864) | 本研究提出了一个多模态细胞分割基准，采用Transformer-based深度学习算法，不仅超越了现有方法，而且可以应用于各种显微成像平台和组织类型的图像，无需手动参数调整，为显微成像中更准确和多功能的细胞分析提供了有希望的途径。 |
| [^51] | [Knowledge Propagation over Conditional Independence Graphs.](http://arxiv.org/abs/2308.05857) | 这项工作提出了在条件独立图上进行知识传播的算法，并通过在Cora和PubMed数据集上的实验证明了其优于现有方法的效果。 |
| [^52] | [GaborPINN: Efficient physics informed neural networks using multiplicative filtered networks.](http://arxiv.org/abs/2308.05843) | 通过使用乘法滤波网络和嵌入波场的已知特性，GaborPINN方法实现了比传统PINN方法高两个数量级的收敛速度提升。 |
| [^53] | [FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks.](http://arxiv.org/abs/2308.05832) | 本文提出了一种名为FLShield的新型联邦学习框架，利用FL参与者的良性数据对本地模型进行验证，以防御恶意参与者的投毒攻击，并确保FL系统的安全性和效用。 |
| [^54] | [An Interpretable and Attention-based Method for Gaze Estimation Using Electroencephalography.](http://arxiv.org/abs/2308.05768) | 本文提出了一种基于注意力机制的深度学习框架，用于从脑电图数据中解读凝视信息，其在准确性和可解释性方面优于当前方法。 |
| [^55] | [EEG-based Emotion Style Transfer Network for Cross-dataset Emotion Recognition.](http://arxiv.org/abs/2308.05767) | 本文提出了一种基于脑电的情绪风格转换网络 (E2STN)，用于解决跨数据集脑电情绪识别中源域和目标域样本样式不匹配的问题。这种转换网络能够生成风格化的情绪脑电表示，有助于进行跨数据集的判别预测。 |
| [^56] | [Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients.](http://arxiv.org/abs/2308.05765) | 通过利用数据预处理技术和Extra-Tree特征选择方法与Random Forest分类器相结合，本研究提高了心力衰竭患者生存预测能力，并取得了98.33%的准确率 |
| [^57] | [Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI.](http://arxiv.org/abs/2308.05764) | 该论文提出了一种通过从心脏MRI中的知识转移解锁心电图的诊断潜力的方法。通过将CMR图像中的领域特定信息转移到ECG嵌入中，该方法实现了仅根据ECG数据进行全面的心脏筛查，并能预测心血管疾病的个体风险和确定心脏表型。 |
| [^58] | [A machine-learning sleep-wake classification model using a reduced number of features derived from photoplethysmography and activity signals.](http://arxiv.org/abs/2308.05759) | 这项研究提出了一种基于机器学习的睡眠-清醒分类模型，利用光电流血容积波形和活动信号提取的特征，可以评估睡眠质量，识别睡眠问题和改善整体健康。 |
| [^59] | [OrcoDCS: An IoT-Edge Orchestrated Online Deep Compressed Sensing Framework.](http://arxiv.org/abs/2308.05757) | OrcoDCS是一种物联网边缘编排的在线深度压缩感知框架，通过特殊设计的非对称自编码器实现高度灵活性和适应性，可处理不同的物联网设备组和它们的感知任务，并在后续应用中提供高性能。 |
| [^60] | [WeldMon: A Cost-effective Ultrasonic Welding Machine Condition Monitoring System.](http://arxiv.org/abs/2308.05756) | WeldMon是一种成本效益高的超声波焊接机状态监测系统，利用自定义数据采集系统和实时分析流程实现高质量的焊接，通过结合自动生成的特征和手工制作的特征的分类算法，显著提高了状态分类准确性。数据增强方法还减轻了概念漂移问题，提升了工具状态分类准确性。 |
| [^61] | [Turning hazardous volatile matter compounds into fuel by catalytic steam reforming: An evolutionary machine learning approach.](http://arxiv.org/abs/2308.05750) | 本论文利用进化的机器学习方法，首次开发了一个基于机器学习的研究框架，用于对危险的挥发物化合物的催化蒸汽重整进行建模、理解和优化。通过甲苯催化蒸汽重整作为案例研究，展示了利用化学/纹理分析来获取机器学习模型的输入特征。六个机器学习模型被用来对该过程进行深入分析和建模。 |
| [^62] | [Introducing Hybrid Modeling with Time-series-Transformers: A Comparative Study of Series and Parallel Approach in Batch Crystallization.](http://arxiv.org/abs/2308.05749) | 本研究引入混合建模的方法，将基于物理原理的动力学与机器学习模型相结合，以解决直接部署黑箱模型的安全和操作问题。相比简单的深度神经网络模型，最近的时间序列Transformer模型利用注意力机制和位置编码，能更好地预测长期时间序列，并利用过程动力学轨迹的上下文信息。 |
| [^63] | [LLM As DBA.](http://arxiv.org/abs/2308.05481) | LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。 |
| [^64] | [Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis.](http://arxiv.org/abs/2308.05476) | 本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。 |
| [^65] | [Homophily-enhanced Structure Learning for Graph Clustering.](http://arxiv.org/abs/2308.05309) | 提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。 |
| [^66] | [Deep Learning for Diverse Data Types Steganalysis: A Review.](http://arxiv.org/abs/2308.04522) | 本综述论文详细综述了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的最新研究进展。 |
| [^67] | [SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling.](http://arxiv.org/abs/2308.04365) | SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。 |
| [^68] | [Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts.](http://arxiv.org/abs/2308.03921) | Spellburst是一个基于节点的界面，利用大型语言模型（LLM）提供创意编码环境，艺术家可以通过分支和合并操作探索生成艺术的变化，通过基于表达式的提示交互进行语义编程，并且能够在语义和句法探索之间无缝切换。 |
| [^69] | [Machine learning methods for the search for L&T brown dwarfs in the data of modern sky surveys.](http://arxiv.org/abs/2308.03045) | 在这项研究中，我们使用机器学习方法对PanStarrs DR1、2MASS和WISE数据进行分析，以区分L类和T类棕矮星和其他光谱和亮度类别的天体。这有助于建立一个均匀且完整的棕矮星样本，为研究提供可靠的数据集。 |
| [^70] | [Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket.](http://arxiv.org/abs/2308.02916) | 本文介绍了一种利用对抗抹除的方法来增强图彩票的性能。通过重新考虑修剪信息中的有价值的信息，我们提出了ACE-GLT，这是一种更强大的图彩票方法。 |
| [^71] | [Causality Guided Disentanglement for Cross-Platform Hate Speech Detection.](http://arxiv.org/abs/2308.02080) | 本研究提出了一种跨平台仇恨言论检测模型，通过解缠输入表示为不变特征和平台相关特征，实现了对多个未见平台的良好泛化能力。 |
| [^72] | [A Survey on Popularity Bias in Recommender Systems.](http://arxiv.org/abs/2308.01118) | 这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。 |
| [^73] | [Spatio-Temporal Branching for Motion Prediction using Motion Increments.](http://arxiv.org/abs/2308.01097) | 本论文提出了一种利用运动增量进行时空分支的运动预测网络，通过解耦时域和空域特征的学习，提取更多的运动信息。 |
| [^74] | [CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering.](http://arxiv.org/abs/2308.00284) | 本研究提出一种名为CLAMS的聚类模糊度测量方法，用于估计视觉聚类中的感知变异性。通过定性研究，我们确定了影响聚类的关键因素，并通过回归模块对聚类的模糊度进行估计。 |
| [^75] | [ZADU: A Python Library for Evaluating the Reliability of Dimensionality Reduction Embeddings.](http://arxiv.org/abs/2308.00282) | ZADU是一个Python库，通过提供扭曲度量方法可以高效评估降维嵌入的可靠性，并通过优化执行和分析各个数据点的贡献提供全面评估。 |
| [^76] | [Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction.](http://arxiv.org/abs/2308.00278) | 本文提出了两种新的质量度量方法--标签可信度和标签连续性（Label-T&C）--改进了基于类别标签的降维评估的过程，不再假设类别在原始空间中形成良好的聚类，而是通过估计类别在原始空间和嵌入空间中形成聚类的程度和评估两者之间的差异来工作。 |
| [^77] | [AI Increases Global Access to Reliable Flood Forecasts.](http://arxiv.org/abs/2307.16104) | 本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。 |
| [^78] | [Initial State Interventions for Deconfounded Imitation Learning.](http://arxiv.org/abs/2307.15980) | 本文介绍了一种针对模仿学习中因果混淆问题的初始化状态干预算法，该算法能够遮蔽观测中的混淆因素并提高性能表现。 |
| [^79] | [NIPD: A Federated Learning Person Detection Benchmark Based on Real-World Non-IID Data.](http://arxiv.org/abs/2306.15932) | NIPD是一个基于真实世界非独立与同分布数据的联邦学习人体检测基准，开源了一个非独立和同分布的物联网人体检测数据集。 |
| [^80] | [Hard Sample Mining Enabled Supervised Contrastive Feature Learning for Wind Turbine Pitch System Fault Diagnosis.](http://arxiv.org/abs/2306.14701) | 本文提出了一种基于困难样本挖掘的监督对比特征学习方法，用于风力发电机桨叶系统故障诊断。该方法利用余弦相似度识别困难样本，并通过构建困难样本对来学习更具区分性的表示，进一步提高了多层感知机的训练效果。 |
| [^81] | [Trained Transformers Learn Linear Models In-Context.](http://arxiv.org/abs/2306.09927) | 本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。 |
| [^82] | [RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows.](http://arxiv.org/abs/2306.06034) | 本研究提出了RANS-PINN模型，通过引入2方程涡粘度模型，可预测高雷诺数湍流流动中的流场，从而提高流体动力学模拟计算效率。 |
| [^83] | [A Cover Time Study of a non-Markovian Algorithm.](http://arxiv.org/abs/2306.04902) | 本文研究了一个遍历算法中的覆盖时间问题，通过一种基于计数的负反馈策略，实现在任意图中局部提高搜索效率，并在特殊的图形中实现更小的覆盖时间。 |
| [^84] | [On the Design Fundamentals of Diffusion Models: A Survey.](http://arxiv.org/abs/2306.04542) | 本文综述了扩散模型的设计基础，即其三个关键组件：正向过程、逆向过程和采样过程，为未来的研究提供了有益的细粒度透视。 |
| [^85] | [Faithful Knowledge Distillation.](http://arxiv.org/abs/2306.04431) | 本文研究了知识蒸馏中教师和学生之间的相对校准问题，提出了一个忠实的模仿框架来解决学生置信度和软标签的问题，并提供了一种实证和认证的方法来评估学生模型的鲁棒性。 |
| [^86] | [Robust Lane Detection through Self Pre-training with Masked Sequential Autoencoders and Fine-tuning with Customized PolyLoss.](http://arxiv.org/abs/2305.17271) | 本论文提出了一种鲁棒车道检测流水线，该流水线包括自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩膜图像中的丢失像素为目标来预训练神经网络模型，提升了车道检测性能。 |
| [^87] | [Beyond invariant representation learning: linearly alignable latent spaces for efficient closed-form domain adaptation.](http://arxiv.org/abs/2305.07500) | 本文提出了一种新的基于最优输运（OT）的领域自适应（DA）方法，通过学习一个嵌入空间，使得OT问题的解是最优且计算量较少的，适用于同质和异质的DA设置。 |
| [^88] | [Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders.](http://arxiv.org/abs/2305.02640) | 本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。 |
| [^89] | [MAMAF-Net: Motion-Aware and Multi-Attention Fusion Network for Stroke Diagnosis.](http://arxiv.org/abs/2304.09466) | 本研究提出了一个名为MAMAF-Net的网络用于检测多模态检查视频中的中风情况，并提出了一个多数采样的数据集。这是第一个提供端到端解决方案的视频分析中的中风检测研究。 |
| [^90] | [Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations.](http://arxiv.org/abs/2303.16618) | 本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。 |
| [^91] | [Physics-guided adversarial networks for artificial digital image correlation data generation.](http://arxiv.org/abs/2303.15939) | 本文提出一种使用具有物理引导鉴别器的生成式对抗网络来生成人造DIC位移数据的方法， 以训练更精确可靠的机器学习模型，从而实现更准确可靠的疲劳裂纹增长评估的发展。 |
| [^92] | [Improving the Transferability of Adversarial Examples via Direction Tuning.](http://arxiv.org/abs/2303.15109) | 该论文提出了一种新的基于迁移的攻击方法，通过方向调整来改进对抗性样本的可迁移性。该方法既能减小大步长中的更新偏差，又能减轻小步长中的更新振荡。 |
| [^93] | [PENTACET data -- 23 Million Contextual Code Comments and 500,000 SATD comments.](http://arxiv.org/abs/2303.14029) | 本文介绍了PENTACET数据集，该数据集包含了2300万个上下文代码注释和50万个自我承认技术债务注释，并提供了详细的上下文数据，将进一步推动使用人工智能技术的SATD研究。 |
| [^94] | [ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions.](http://arxiv.org/abs/2303.12364) | ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。 |
| [^95] | [BODEGA: Benchmark for Adversarial Example Generation in Credibility Assessment.](http://arxiv.org/abs/2303.08032) | BODEGA是一个基准测试，用于模拟真实的内容管理场景，在四个误传检测任务上测试受害模型和攻击方法。测试结果表明，在某些情况下，即使进行微小的文本修改，也可以欺骗最准确的分类器。 |
| [^96] | [Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models.](http://arxiv.org/abs/2303.06628) | 本文提出了一种新的方法ZSCL，旨在解决连续学习视觉语言模型中零样例转移降级的问题。通过在特征空间中引入参考数据集进行蒸馏，该方法能够有效地防止模型的零样例转移能力的降低。 |
| [^97] | [Collaborative Learning with a Drone Orchestrator.](http://arxiv.org/abs/2303.02266) | 本文研究了无人机辅助的协同学习问题，提出了一种通过智能设备群与无人机协同训练神经网络模型的方法。在考虑数据异质性和通信错误的情况下，导出了协同学习的收敛速度，并通过优化无人机轨迹来提高训练准确率。 |
| [^98] | [Completeness of Atomic Structure Representations.](http://arxiv.org/abs/2302.14770) | 本文解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，并提出了一种构造有限子集描述符的新方法。 |
| [^99] | [Cross-modal Contrastive Learning for Multimodal Fake News Detection.](http://arxiv.org/abs/2302.14057) | 这项研究提出了COOLANT，一个用于跨模态假新闻检测的对比学习框架，旨在提升图像和文本的对齐精度，并通过跨模态融合和注意力机制实现更准确和可解释的特征聚合。 |
| [^100] | [Detection and classification of vocal productions in large scale audio recordings.](http://arxiv.org/abs/2302.07640) | 我们提出了一种自动数据处理流程，用于从大规模自然音频录音中提取声音产生并分类，该方法能够在不需要大量标注数据和重要计算资源的情况下训练一个准确率较高的神经网络模型，并且适用于不同录音条件下的嘈杂录音。 |
| [^101] | [Unconstrained Dynamic Regret via Sparse Coding.](http://arxiv.org/abs/2301.13349) | 本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。 |
| [^102] | [Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning.](http://arxiv.org/abs/2301.08427) | 该论文研究了CodeBert在源码表示学习中学到了哪些特征，发现当前方法无法有效理解源代码的逻辑，而源代码的表示依赖于程序员定义的变量和函数名。 |
| [^103] | [A Dynamics Theory of Implicit Regularization in Deep Low-Rank Matrix Factorization.](http://arxiv.org/abs/2212.14150) | 本文提出了一种新的解释神经网络隐式正则化的方法，通过离散梯度动力学和景观分析揭示了深度低秩矩阵分解中的隐式正则化机制。 |
| [^104] | [RT-1: Robotics Transformer for Real-World Control at Scale.](http://arxiv.org/abs/2212.06817) | 本文提出了机器人变压器模型，通过从大规模、多样化、任务无关的数据集中获取知识，并结合高容量架构，实现了在实际控制领域的高性能泛化能力。 |
| [^105] | [On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural Networks.](http://arxiv.org/abs/2212.02374) | 过度平滑和过度压缩是深度图神经网络中的关键挑战，我们提出了添加和删除边缘的方法来解决这个问题。 |
| [^106] | [A Neural-Network-Based Convex Regularizer for Image Reconstruction.](http://arxiv.org/abs/2211.12461) | 本研究提出了基于神经网络的凸规则化器用于图像重建。该方法通过重新审视由凸脊函数组成的规则化器，并使用具有单个隐藏层的神经网络对其梯度进行参数化。实验证明，在去噪、CT和MRI重建方面，该方法在提供类似可靠性保证的情况下，能够取得更好的结果。 |
| [^107] | [Inverse Kernel Decomposition.](http://arxiv.org/abs/2211.05961) | 本文提出了一种新的非线性降维方法——逆核分解（IKD），通过特征值分解样本协方差矩阵实现。该方法受到高斯过程潜变量模型（GPLVMs）的启发，并在处理噪声数据方面提供了两种解决方案，具有良好的性能。 |
| [^108] | [There is more than one kind of robustness: Fooling Whisper with adversarial examples.](http://arxiv.org/abs/2210.17316) | 本研究展示了Whisper模型虽然在分布外输入和随机噪声方面显示出了出色的稳健性，但却容易受到对抗干扰的影响。我们通过生成极小的输入扰动来大幅降低Whisper的性能，并对多语言模型的性能产生了影响。这些发现对于实际的安全问题和对抗性稳健ASR的需求具有重要意义。 |
| [^109] | [A Law of Data Separation in Deep Learning.](http://arxiv.org/abs/2210.17020) | 深度学习中存在一个简单而定量的数据分离定律，每一层都以恒定的几何速率改善数据的分离程度。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。 |
| [^110] | [Learning Audio Features with Metadata and Contrastive Learning.](http://arxiv.org/abs/2210.16192) | 本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。在呼吸音分类数据集上，仅使用元数据学习表示可以获得与仅使用类标签的交叉熵相似的性能。在使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。 |
| [^111] | [Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation.](http://arxiv.org/abs/2209.10510) | 这个论文提出了一种在不需要光台的情况下进行肖像图像重新照明的方法，并能够与最先进的方法相媲美。该方法基于物理原理，并能够产生高质量的结果。 |
| [^112] | [Self-Supervised Coordinate Projection Network for Sparse-View Computed Tomography.](http://arxiv.org/abs/2209.05483) | 本文提出了一种自监督坐标投影网络（SCOPE），通过引入重投影策略改善了稀疏视角计算机体层摄影的图像重建质量。 |
| [^113] | [Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting.](http://arxiv.org/abs/2208.03063) | 通过对抗学习和联合时空嵌入，我们提出了TrendGCN来增强交通预测的鲁棒性，该模型能够平衡动态性和鲁棒性，并在处理具有统计相关性的顺序数据时表现出较好的效果。 |
| [^114] | [How many perturbations break this model? Evaluating robustness beyond adversarial accuracy.](http://arxiv.org/abs/2207.04129) | 这项工作介绍了一种评估神经网络鲁棒性的替代方法-对抗稀疏性，它量化了成功扰动的难度。稀疏性揭示了鲁棒模型之间的重要差异并提出了改进鲁棒性的方法。 |
| [^115] | [HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object Detection.](http://arxiv.org/abs/2206.15157) | HRFuser是一种多分辨率传感器融合架构，可用于二维物体检测，基于高分辨率网络和新型多窗口交叉注意力块进行多模态多分辨率融合。在nuScenes和DENSE上的实验证明了其有效性。 |
| [^116] | [ECLAD: Extracting Concepts with Local Aggregated Descriptors.](http://arxiv.org/abs/2206.04531) | 本文提出了一种使用本地聚合描述符提取概念的方法，并介绍了一种基于合成数据集的验证过程，用于减少概念提取方法的人工干预需求。 |
| [^117] | [Trainable Weight Averaging: A General Approach for Subspace Training.](http://arxiv.org/abs/2205.13104) | 可训练的权重平均值是一种通用的子空间训练方法，通过连接子空间训练和权重平均值，提供高效的训练和易于使用的方法。这种方法可以用于改进神经网络训练效果和降低计算负担。 |
| [^118] | [Joint Multi-view Unsupervised Feature Selection and Graph Learning.](http://arxiv.org/abs/2204.08247) | 本文提出了一种联合多视图无监督特征选择和图学习的方法，通过正交分解建模多视图特征选择，应用跨空间局部保持进行聚类结构学习和相似性学习的连接。 |
| [^119] | [Con$^{2}$DA: Simplifying Semi-supervised Domain Adaptation by Learning Consistent and Contrastive Feature Representations.](http://arxiv.org/abs/2204.01558) | Con$^{2}$DA是一个简单的框架，通过学习一致性和对比特征表示，解决了半监督领域自适应问题，并实现了最先进的性能。 |
| [^120] | [Graph Neural Network Sensitivity Under Probabilistic Error Model.](http://arxiv.org/abs/2203.07831) | 本文研究了概率误差模型对图卷积网络（GCN）性能的影响，并证明了误差模型下邻接矩阵的受限性。通过实验验证了这种误差界限，并研究了GCN在这种概率误差模型下的准确性敏感性。 |
| [^121] | [Robust Graph Representation Learning for Local Corruption Recovery.](http://arxiv.org/abs/2202.04936) | 该论文提出了一种鲁棒性图表示学习的方法，通过检测局部异常和恢复鲁棒嵌入来提升预测任务的准确性。使用图自编码器进行检测操作，通过稀疏促进正则化恢复鲁棒估计。实验证明该方法能够在黑盒攻击下恢复鲁棒的图表示并取得优秀的预测性能。 |
| [^122] | [Oracle Teacher: Leveraging Target Information for Better Knowledge Distillation of CTC Models.](http://arxiv.org/abs/2111.03664) | Oracle Teacher是一种新型教师模型，利用基于CTC的序列模型的目标信息来提供更准确的指导，以实现更好的知识蒸馏效果。 |
| [^123] | [Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score.](http://arxiv.org/abs/2111.02302) | 本文提出了一种基于二次判别得分的统一方法，用于选择聚类数目、聚类模型和算法。我们定义了基于二次判别得分函数和参数的参考聚类概念，并开发了两个一致性准则。这种方法适用于可以通过二次或线性边界很好分隔的群组，对于应用中寻找这种类型的群组很有帮助。 |
| [^124] | [Neural Model Reprogramming with Similarity Based Mapping for Low-Resource Spoken Command Classification.](http://arxiv.org/abs/2110.03894) | 本文提出了一种基于相似性映射的神经模型重编程方法，用于低资源口语命令分类。实验证明，在有限的数据条件下，该方法在阿拉伯语和立陶宛语命令数据集上表现优于当前最先进的结果。 |
| [^125] | [Combining Machine Learning Classifiers for Stock Trading with Effective Feature Extraction.](http://arxiv.org/abs/2107.13148) | 该论文研究了结合机器学习分类器和有效特征提取进行股票交易的方法。通过性能筛选出最佳特征，并使用集成学习的四个分类器进行交易决策。最佳模型在2011年7月至2019年1月期间每日交易中获得了54.35%的利润。 |
| [^126] | [Constraining Linear-chain CRFs to Regular Languages.](http://arxiv.org/abs/2106.07306) | 本文提出了一种将线性链条件随机场（CRFs）限制到正则语言的方法，该方法可以对广泛的约束进行建模，并允许在训练过程中引入这些约束。 |
| [^127] | [Robust Quadruped Jumping via Deep Reinforcement Learning.](http://arxiv.org/abs/2011.07089) | 通过深度强化学习，本文提出了一种鲁棒的四足跳跃方法，可以在嘈杂环境中跳跃不同距离和高度，并能应对不平坦地形和可变机器人动力学参数的挑战。 |
| [^128] | [Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers.](http://arxiv.org/abs/2010.11750) | 本文利用随机矩阵理论在线性回归设置中，对于具有两个任务的高维情况下的常用估计量的超额风险进行了精确渐近分析。 |
| [^129] | [A method for escaping limit cycles in training GANs.](http://arxiv.org/abs/2010.03322) | 本文提出了一种用于逃逸训练GAN中的极限周期的方法，通过预测离心加速度算法（PCAA）和自适应矩估计算法（Adam）相结合，有效改善了训练过程中的极限周期行为问题。 |
| [^130] | [Non-linear Neurons with Human-like Apical Dendrite Activations.](http://arxiv.org/abs/2003.03229) | 本论文提出了一种新的人工神经元模型和激活函数，通过使用单个神经元学习非线性决策边界，并在多个基准数据集上取得了优于传统方法的结果。 |
| [^131] | [Nonparametric Inference under B-bits Quantization.](http://arxiv.org/abs/1901.08571) | 本文提出了一种基于B位量化的非参数推断方法，通过一种高效的算法对样本进行量化处理。结果表明，当B超过阈值时，所提出的方法在样条模型中能够达到经典极小极值率的测试水平。另外，本文还拓展了方法的适用性，包括非参数直线性检验和自适应非参数检验。通过广泛的模拟研究和实际数据分析，证明了方法的有效性和效果。 |

# 详细

[^1]: Foundation Model是一个高效的多模态多任务模型选择器

    Foundation Model is Efficient Multimodal Multitask Model Selector. (arXiv:2308.06262v1 [cs.LG])

    [http://arxiv.org/abs/2308.06262](http://arxiv.org/abs/2308.06262)

    本文提出了一种高效的多模态多任务模型选择器（EMMS），它使用大规模的基础模型将不同任务的标签格式转换为统一的噪声标签嵌入，通过简单的加权线性回归来估计模型的可迁移性。

    

    本文研究了一个不常见但非常重要的问题：在给定一组预训练的神经网络的情况下，如何在不对它们进行微调的情况下预测它们在每个多模态任务上的性能，比如图像识别、指代、字幕生成、视觉问答和文字问答。一种蛮力的方法是对所有模型在所有目标数据集上进行微调，这会带来高计算成本。虽然最近的一些先进方法采用轻量级指标来衡量模型的可迁移性，但它们往往严重依赖于单个任务的先验知识，使得它们在多模态多任务的场景中不适用。为了解决这个问题，我们提出了一种高效的多任务模型选择器（EMMS），它使用大规模的基于基础模型，将不同下游任务的各种标签格式，如类别、文本和边界框转换为统一的噪声标签嵌入。EMMS可以通过简单的加权线性回归来估计模型的可迁移性。

    This paper investigates an under-explored but important problem: given a collection of pre-trained neural networks, predicting their performance on each multi-modal task without fine-tuning them, such as image recognition, referring, captioning, visual question answering, and text question answering. A brute-force approach is to finetune all models on all target datasets, bringing high computational costs. Although recent-advanced approaches employed lightweight metrics to measure models' transferability,they often depend heavily on the prior knowledge of a single task, making them inapplicable in a multi-modal multi-task scenario. To tackle this issue, we propose an efficient multi-task model selector (EMMS), which employs large-scale foundation models to transform diverse label formats such as categories, texts, and bounding boxes of different downstream tasks into a unified noisy label embedding. EMMS can estimate a model's transferability through a simple weighted linear regression
    
[^2]: FunnyBirds: 一种用于可解释AI方法的基于部分分析的合成视觉数据集

    FunnyBirds: A Synthetic Vision Dataset for a Part-Based Analysis of Explainable AI Methods. (arXiv:2308.06248v1 [cs.CV])

    [http://arxiv.org/abs/2308.06248](http://arxiv.org/abs/2308.06248)

    FunnyBirds是一种合成视觉数据集，用于分析可解释AI方法。它允许对图像进行语义上有意义的干预，并可以在部分级别上对解释进行评估和分析。

    

    可解释人工智能（XAI）领域旨在揭示复杂深度神经模型的内部工作原理。尽管在安全关键领域至关重要，但XAI固有地缺乏真实解释，使其自动评估成为一个未解决的问题。我们通过提出一种新的合成视觉数据集FunnyBirds及其伴随的自动评估协议来应对这一挑战。我们的数据集允许进行语义上有意义的图像干预，例如，移除单个物体部分，这有三个重要的含义。首先，它使得能够对部分级别的解释进行分析，比现有方法在像素级别进行评估更接近于人类理解。其次，通过比较去除部分的输入的模型输出，我们可以估计应该反映在解释中的真实部分重要性。第三，通过将单个解释映射到共同的部分重要性空间，我们可以分析不同的解释。

    The field of explainable artificial intelligence (XAI) aims to uncover the inner workings of complex deep neural models. While being crucial for safety-critical domains, XAI inherently lacks ground-truth explanations, making its automatic evaluation an unsolved problem. We address this challenge by proposing a novel synthetic vision dataset, named FunnyBirds, and accompanying automatic evaluation protocols. Our dataset allows performing semantically meaningful image interventions, e.g., removing individual object parts, which has three important implications. First, it enables analyzing explanations on a part level, which is closer to human comprehension than existing methods that evaluate on a pixel level. Second, by comparing the model output for inputs with removed parts, we can estimate ground-truth part importances that should be reflected in the explanations. Third, by mapping individual explanations into a common space of part importances, we can analyze a variety of different e
    
[^3]: 具有公共数据的私有分布学习：基于样本压缩的视角

    Private Distribution Learning with Public Data: The View from Sample Compression. (arXiv:2308.06239v1 [cs.LG])

    [http://arxiv.org/abs/2308.06239](http://arxiv.org/abs/2308.06239)

    本论文研究了在具有公共数据的情况下的私有分布学习问题，通过压缩样本和列表学习的方式，我们对高斯分布以及高斯混合分布进行了学习上限的分析，并提出了对不可知学习和分布变化抵抗学习的新结果。

    

    我们研究了在可以访问公共数据的情况下的私有分布学习问题。在这个设置中，我们称之为公私学习，学习器被给予来自未知分布p的属于类$\mathcal Q$的公共样本和私有样本，目标是输出一个对p的估计，同时遵守与私有样本相关的隐私约束（这里是纯差分隐私）。我们展示了类$\mathcal Q$的公私可学习性与$\mathcal Q$的样本压缩方案以及中间概念——列表学习的存在性有关。利用这个联系：（1）近似恢复了关于$\mathbb R^d$上高斯分布的先前结果；（2）得出了新的结果，包括对任意$k$-高斯混合分布在$\mathbb R^d$上的样本复杂度上界，以及对不可知和分布变化抵抗学习器的结果，以及公私可学习性的闭包性质。

    We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.  We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability
    
[^4]: MaxFloodCast: 用于预测峰值淹没深度和解读影响因素的集成机器学习模型

    MaxFloodCast: Ensemble Machine Learning Model for Predicting Peak Inundation Depth And Decoding Influencing Features. (arXiv:2308.06228v1 [cs.LG])

    [http://arxiv.org/abs/2308.06228](http://arxiv.org/abs/2308.06228)

    MaxFloodCast是一个用于预测洪水淹没深度和解读影响因素的机器学习模型，通过基于物理的水动力模拟进行训练，在预测峰值洪水淹没深度方面表现出可靠性。它还显示了在支持洪水管理和应急行动方面的潜力，同时通过提供关键信息帮助决策者制定洪水防治策略和优先考虑临界设施区域的重要性，并研究其他流域降雨对洪水暴露的影响。

    

    及时、准确和可靠的信息对于决策者、应急管理人员和基础设施运营商在洪灾事件中至关重要。本研究演示了一种名为MaxFloodCast的机器学习模型，该模型在哈里斯县的基于物理的水动力模拟中进行训练，能够高效和可解释地预测洪水淹没深度。在未见数据上达到0.949的平均R-squared和0.61英尺的均方根误差，证明其在预测洪水峰值淹没深度方面的可靠性。通过与飓风哈维和伊梅尔达风暴进行验证，MaxFloodCast显示了在支持近时洪水平原管理和紧急行动方面的潜力。模型的可解释性有助于决策者提供关键信息，以制定洪水防治策略，优先考虑临界设施区域，并研究其他流域降雨如何影响某一区域的洪水暴露。MaxFloodCast模型使淹没深度的预测准确且可解释。

    Timely, accurate, and reliable information is essential for decision-makers, emergency managers, and infrastructure operators during flood events. This study demonstrates a proposed machine learning model, MaxFloodCast, trained on physics-based hydrodynamic simulations in Harris County, offers efficient and interpretable flood inundation depth predictions. Achieving an average R-squared of 0.949 and a Root Mean Square Error of 0.61 ft on unseen data, it proves reliable in forecasting peak flood inundation depths. Validated against Hurricane Harvey and Storm Imelda, MaxFloodCast shows the potential in supporting near-time floodplain management and emergency operations. The model's interpretability aids decision-makers in offering critical information to inform flood mitigation strategies, to prioritize areas with critical facilities and to examine how rainfall in other watersheds influences flood exposure in one area. The MaxFloodCast model enables accurate and interpretable inundation 
    
[^5]: 使用二阶算法自动调整和训练高效的深度自编码器

    Automated Sizing and Training of Efficient Deep Autoencoders using Second Order Algorithms. (arXiv:2308.06221v1 [cs.LG])

    [http://arxiv.org/abs/2308.06221](http://arxiv.org/abs/2308.06221)

    该论文提出了一种多步训练方法，用于设计深度自编码器，并通过修剪和增长方法以及优化隐藏层大小和训练时长来改善其性能。

    

    我们提出了一种多步训练方法，用于设计广义线性分类器。首先，通过回归找到一个初始的多类线性分类器。然后通过修剪不必要的输入来最小化验证误差。同时，通过类似于Ho-Kashyap规则的方法改善期望输出。接下来，将输出判别式缩放为广义线性分类器中S型输出单元的网络函数。然后，我们开发了一族批量训练算法，用于优化多层感知机的隐藏层大小和训练时长。接着，我们将修剪与增长方法相结合。然后，将输入单元缩放为S型输出单元的网络函数，然后将其作为输入馈送到MLP中。最后，我们提出了深度学习模块中的改进，从而提高了深度架构的整体性能。我们讨论了关于d的学习算法的原则和公式。

    We propose a multi-step training method for designing generalized linear classifiers. First, an initial multi-class linear classifier is found through regression. Then validation error is minimized by pruning of unnecessary inputs. Simultaneously, desired outputs are improved via a method similar to the Ho-Kashyap rule. Next, the output discriminants are scaled to be net functions of sigmoidal output units in a generalized linear classifier. We then develop a family of batch training algorithm for the multi layer perceptron that optimizes its hidden layer size and number of training epochs. Next, we combine pruning with a growing approach. Later, the input units are scaled to be the net function of the sigmoidal output units that are then feed into as input to the MLP. We then propose resulting improvements in each of the deep learning blocks thereby improving the overall performance of the deep architecture. We discuss the principles and formulation regarding learning algorithms for d
    
[^6]: 使用概念器进行变点检测

    Change Point Detection With Conceptors. (arXiv:2308.06213v1 [stat.ML])

    [http://arxiv.org/abs/2308.06213](http://arxiv.org/abs/2308.06213)

    我们提出了一种使用概念器矩阵进行变点检测的方法，通过学习时间序列中的特征动态，并利用单变量量化来识别变点。该方法在条件和无条件的变点检测问题上进行了测试，可以提供潜在的需要进一步研究的感兴趣位置。

    

    离线变点检测旨在识别时间序列中数据生成过程发生变化的点。对于单变量独立同分布数据，这个问题已经得到了较好的研究，但是随着维度和时间依赖性的增加，变得具有挑战性。针对至多一个变点的问题，我们提出使用概念器矩阵来学习时间序列中指定训练窗口的特征动态。相关的随机递归神经网络作为数据的特征提取器，并且通过计算特征化与代表性概念器矩阵所张成空间之间的距离的单变量量化来识别变点。这种模型无关的方法可以提示可能需要进一步研究的感兴趣的位置。我们证明，在温和的假设下，该方法提供了真实变点的一致估计，并通过对原始数据进行移动块自助法产生统计量的分位数估计。该方法在条件和无条件的变点检测问题上进行了测试。

    Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on si
    
[^7]: 交通管理系统的安全性：一项全面调查

    Safety in Traffic Management Systems: A Comprehensive Survey. (arXiv:2308.06204v1 [eess.SY])

    [http://arxiv.org/abs/2308.06204](http://arxiv.org/abs/2308.06204)

    本研究综述了交通管理系统安全性的文献，总结了交通管理系统中的安全问题、当前的研究现状以及确保安全性的技术和方法。这项综述还提出了现有研究的局限性，并提出了未来研究的方向。

    

    交通管理系统在保障道路上的安全和高效交通方面起着至关重要的作用。然而，交通管理系统中的先进技术引入了新的安全挑战。因此，确保这些系统的安全性是重要的，以防止事故并减小对道路用户的影响。本调查综述了关于交通管理系统安全性的文献，具体讨论了交通管理系统中涉及的不同安全问题、当前关于这些系统安全性的研究现状以及确保这些系统安全性的技术和方法。我们还指出了现有研究的局限性，并提出了未来研究方向的建议。

    Traffic management systems play a vital role in ensuring safe and efficient transportation on roads. However, the use of advanced technologies in traffic management systems has introduced new safety challenges. Therefore, it is important to ensure the safety of these systems to prevent accidents and minimize their impact on road users. In this survey, we provide a comprehensive review of the literature on safety in traffic management systems. Specifically, we discuss the different safety issues that arise in traffic management systems, the current state of research on safety in these systems, and the techniques and methods proposed to ensure the safety of these systems. We also identify the limitations of the existing research and suggest future research directions.
    
[^8]: 为机器人堆积方块任务构建因果性概率框架

    Towards a Causal Probabilistic Framework for Prediction, Action-Selection & Explanations for Robot Block-Stacking Tasks. (arXiv:2308.06203v1 [cs.RO])

    [http://arxiv.org/abs/2308.06203](http://arxiv.org/abs/2308.06203)

    这项工作提出了一个新颖的因果性概率框架，用于解决机器人堆积方块任务的问题，通过结合因果推断，使机器人能够理解、推理和解释其环境。

    

    现实世界中的不确定性意味着系统设计者无法预测并明确设计出机器人可能遇到的所有场景。因此，以这种方式设计的机器人在高度受控的环境之外容易出现故障。因果模型提供了一个原则性的框架，用于编码机器人与其环境相互作用的因果关系的形式化知识，并结合现实世界机器人通常遇到的噪声和不确定性的概率表示。结合因果推断，这些模型使自主代理能够理解、推理和解释其环境。在这项工作中，我们关注机器人堆积方块任务的问题，因为它展示了许多应用所需的基本感知和操作能力，包括仓库物流和家庭人工支持机器人。我们提出了一个新颖的因果性概率框架，将物理模拟功能嵌入到这个任务中。

    Uncertainties in the real world mean that is impossible for system designers to anticipate and explicitly design for all scenarios that a robot might encounter. Thus, robots designed like this are fragile and fail outside of highly-controlled environments. Causal models provide a principled framework to encode formal knowledge of the causal relationships that govern the robot's interaction with its environment, in addition to probabilistic representations of noise and uncertainty typically encountered by real-world robots. Combined with causal inference, these models permit an autonomous agent to understand, reason about, and explain its environment. In this work, we focus on the problem of a robot block-stacking task due to the fundamental perception and manipulation capabilities it demonstrates, required by many applications including warehouse logistics and domestic human support robotics. We propose a novel causal probabilistic framework to embed a physics simulation capability int
    
[^9]: 在检测人物和物体交互中探索谓词视觉背景

    Exploring Predicate Visual Context in Detecting of Human-Object Interactions. (arXiv:2308.06202v1 [cs.CV])

    [http://arxiv.org/abs/2308.06202](http://arxiv.org/abs/2308.06202)

    本文研究了在人物和物体交互检测中的谓词视觉背景问题，并通过交叉注意力和盒子配对位置嵌入等方式来改进模型，取得了比现有方法更好的性能。

    

    最近，DETR框架已成为人物和物体交互（HOI）研究的主要方法。特别是，基于两阶段变换器的HOI检测器是性能最好和训练最高效的方法之一。然而，这些方法通常以缺乏细粒度上下文信息的物体特征作为HOI分类的条件，而忽视了姿势和方向信息，而更注重关于物体身份和边界的视觉提示。这自然地阻碍了对复杂或模糊交互的识别。本文通过可视化和精心设计的实验研究了这些问题。因此，我们通过交叉注意力重新引入图像特征，并改进了查询设计，广泛探索了键和值，以及使用盒子配对位置嵌入作为空间指导。我们的改进谓词视觉背景（PViC）模型在HICO-DET和V-COCO基准测试上优于现有方法，同时保持了性能。

    Recently, the DETR framework has emerged as the dominant approach for human--object interaction (HOI) research. In particular, two-stage transformer-based HOI detectors are amongst the most performant and training-efficient approaches. However, these often condition HOI classification on object features that lack fine-grained contextual information, eschewing pose and orientation information in favour of visual cues about object identity and box extremities. This naturally hinders the recognition of complex or ambiguous interactions. In this work, we study these issues through visualisations and carefully designed experiments. Accordingly, we investigate how best to re-introduce image features via cross-attention. With an improved query design, extensive exploration of keys and values, and box pair positional embeddings as spatial guidance, our model with enhanced predicate visual context (PViC) outperforms state-of-the-art methods on the HICO-DET and V-COCO benchmarks, while maintaini
    
[^10]: 使用深度知识蒸馏基本特征进行复杂面部表情识别

    Complex Facial Expression Recognition Using Deep Knowledge Distillation of Basic Features. (arXiv:2308.06197v1 [cs.CV])

    [http://arxiv.org/abs/2308.06197](http://arxiv.org/abs/2308.06197)

    这项研究提出了一种基于深度知识蒸馏的新颖持续学习方法，通过使用少量训练样本，能够准确识别新的复合表情类别。

    

    复杂情绪识别是一项认知任务，迄今为止，其表现在与人类认知水平相等或以上的其他任务中表现优秀的程度已经被证明是较为困难的。由于人脸表达的情绪复杂性，通过面部表情进行情绪识别特别困难。为了使机器在这一领域达到与人类相同的表现水平，它可能需要实时合成知识并理解新概念。人类能够仅仅使用几个例子学习新概念，通过从记忆中提取重要信息并丢弃其余信息。同样，持续学习方法可以在保留已知类别知识的同时学习新类别，而少样本学习方法能够使用非常少的训练样本学习新类别。我们提出了一种新颖的持续学习方法，受到人类认知和学习的启发，可以使用少量的训练样本准确地识别新的复合表情类别。

    Complex emotion recognition is a cognitive task that has so far eluded the same excellent performance of other tasks that are at or above the level of human cognition. Emotion recognition through facial expressions is particularly difficult due to the complexity of emotions expressed by the human face. For a machine to approach the same level of performance in this domain as a human, it may need to synthesise knowledge and understand new concepts in real-time as humans do. Humans are able to learn new concepts using only few examples, by distilling the important information from memories and discarding the rest. Similarly, continual learning methods learn new classes whilst retaining the knowledge of known classes, whilst few-shot learning methods are able to learn new classes using very few training examples. We propose a novel continual learning method inspired by human cognition and learning that can accurately recognise new compound expression classes using few training samples, by
    
[^11]: 从酒店评论中评估客人的国籍构成

    Assessing Guest Nationality Composition from Hotel Reviews. (arXiv:2308.06175v1 [cs.CL])

    [http://arxiv.org/abs/2308.06175](http://arxiv.org/abs/2308.06175)

    本文利用机器学习从非结构化文本评论中提取客人国籍的引用，并展示了一个相对简单的架构可以提供更好的性能和运行时间的权衡。

    

    许多酒店通过针对特定市场的客户获取努力，以最好地预测客人的个人偏好和需求。同样，这种战略定位是有效的营销预算分配的先决条件。官方统计数据报告了来自不同国家的游客数量，但没有关于个别企业客人构成的细粒度信息。然而，竞争对手、供应商、研究人员和普通公众对这些数据的兴趣越来越大。我们展示了如何利用机器学习从非结构化文本评论中提取客人国籍的引用，以动态评估和监测个别企业客人构成的动态变化。特别是，我们证明了预训练嵌入和堆叠的LSTM层的相当简单的架构提供了比复杂的最先进语言模型更好的性能和运行时间的权衡。

    Many hotels target guest acquisition efforts to specific markets in order to best anticipate individual preferences and needs of their guests. Likewise, such strategic positioning is a prerequisite for efficient marketing budget allocation. Official statistics report on the number of visitors from different countries, but no fine-grained information on the guest composition of individual businesses exists. There is, however, growing interest in such data from competitors, suppliers, researchers and the general public. We demonstrate how machine learning can be leveraged to extract references to guest nationalities from unstructured text reviews in order to dynamically assess and monitor the dynamics of guest composition of individual businesses. In particular, we show that a rather simple architecture of pre-trained embeddings and stacked LSTM layers provides a better performance-runtime tradeoff than more complex state-of-the-art language models.
    
[^12]: 基于摄像头的智能系统的物理对抗攻击：当前趋势，分类，应用，研究挑战和未来展望

    Physical Adversarial Attacks For Camera-based Smart Systems: Current Trends, Categorization, Applications, Research Challenges, and Future Outlook. (arXiv:2308.06173v1 [cs.CR])

    [http://arxiv.org/abs/2308.06173](http://arxiv.org/abs/2308.06173)

    本文调查了当前的物理对抗攻击趋势，分析了物理对抗攻击的特点和挑战。研究了不同应用中的攻击方法，并评估了它们的效果和鲁棒性。此外，讨论了未来的研究方向。

    

    本文针对物理对抗攻击提出了一个综合调查研究，重点关注当前的趋势。我们旨在提供对物理对抗攻击概念的全面理解，分析其关键特征和区别性特点。此外，我们探讨了在物理世界中执行攻击所涉及的具体需求和挑战。本文深入研究了各种物理对抗攻击方法，根据它们在不同应用中的目标任务进行分类，包括分类，检测，人脸识别，语义分割和深度估计。我们评估了这些攻击方法在效果、隐蔽性和鲁棒性方面的性能。我们研究了每种技术如何努力确保成功操作深度神经网络，同时减小被检测的风险和承受真实世界的干扰。最后，我们讨论了当前的挑战，并勾画了未来的研究方向。

    In this paper, we present a comprehensive survey of the current trends focusing specifically on physical adversarial attacks. We aim to provide a thorough understanding of the concept of physical adversarial attacks, analyzing their key characteristics and distinguishing features. Furthermore, we explore the specific requirements and challenges associated with executing attacks in the physical world. Our article delves into various physical adversarial attack methods, categorized according to their target tasks in different applications, including classification, detection, face recognition, semantic segmentation and depth estimation. We assess the performance of these attack methods in terms of their effectiveness, stealthiness, and robustness. We examine how each technique strives to ensure the successful manipulation of DNNs while mitigating the risk of detection and withstanding real-world distortions. Lastly, we discuss the current challenges and outline potential future research 
    
[^13]: 基于阶段性深度时空学习的高速公路交通量预测

    Phased Deep Spatio-temporal Learning for Highway Traffic Volume Prediction. (arXiv:2308.06155v1 [cs.LG])

    [http://arxiv.org/abs/2308.06155](http://arxiv.org/abs/2308.06155)

    本论文提出了一种基于阶段性深度时空学习方法，用于预测城际高速公路的每日交通量。该方法通过精心的数据规范化、混合模型结合以及考虑来自异构数据的多个要素，有效解决了交通量预测中的时空特征和数据不平衡问题。

    

    城际高速公路交通对于现代都市生活至关重要，并生成带有时空特征的异构感知数据。作为交通领域的例行分析，每日交通量估计面临着挑战，包括缺乏对相关时空特征的长期考察和处理数据不平衡的有效手段，后者会恶化预测性能。本文提出了一种阶段性深度时空学习方法，用于预测每日交通量。在特征预处理阶段，根据潜在的长尾分布精心进行数据规范化。在时空学习阶段，采用了一种混合模型，将全卷积网络（FCN）和长短期记忆网络（LSTM）结合起来，考虑了来自异构数据的时间、空间、气象和日历信息。在决策阶段，预测了网络范围收费卡口未来一天的交通量。

    Inter-city highway transportation is significant for citizens' modern urban life and generates heterogeneous sensory data with spatio-temporal characteristics. As a routine analysis in transportation domain, daily traffic volume estimation faces challenges for highway toll stations including lacking of exploration of correlative spatio-temporal features from a long-term perspective and effective means to deal with data imbalance which always deteriorates the predictive performance. In this paper, a deep spatio-temporal learning method is proposed to predict daily traffic volume in three phases. In feature pre-processing phase, data is normalized elaborately according to latent long-tail distribution. In spatio-temporal learning phase, a hybrid model is employed combining fully convolution network (FCN) and long short-term memory (LSTM), which considers time, space, meteorology, and calendar from heterogeneous data. In decision phase, traffic volumes on a coming day at network-wide toll
    
[^14]: 高斯过程回归用于最大熵分布

    Gaussian Process Regression for Maximum Entropy Distribution. (arXiv:2308.06149v1 [stat.ML])

    [http://arxiv.org/abs/2308.06149](http://arxiv.org/abs/2308.06149)

    本论文研究了高斯过程回归用于近似最大熵分布中的拉格朗日乘子，通过优化超参数来实现数据驱动的最大熵闭合。通过对比多个测试案例，验证了该方法的有效性。

    

    最大熵分布提供了一类适用于矩闭合问题的吸引人的概率密度函数。然而，找到参数化这些分布的拉格朗日乘子对于实际闭合设置来说却是一个计算瓶颈。受到高斯过程的最近成功的启发，我们研究了使用高斯先验来近似拉格朗日乘子作为给定一组矩的映射的适用性。通过最大化对数似然函数，优化了各种核函数的超参数。研究了所设计的数据驱动最大熵闭合在包括由Bhatnagar-Gross-Krook和Boltzmann动力学方程控制的非平衡分布松弛的几个测试案例中的性能。

    Maximum-Entropy Distributions offer an attractive family of probability densities suitable for moment closure problems. Yet finding the Lagrange multipliers which parametrize these distributions, turns out to be a computational bottleneck for practical closure settings. Motivated by recent success of Gaussian processes, we investigate the suitability of Gaussian priors to approximate the Lagrange multipliers as a map of a given set of moments. Examining various kernel functions, the hyperparameters are optimized by maximizing the log-likelihood. The performance of the devised data-driven Maximum-Entropy closure is studied for couple of test cases including relaxation of non-equilibrium distributions governed by Bhatnagar-Gross-Krook and Boltzmann kinetic equations.
    
[^15]: 使用词袋和基于Transformer的模型识别代码评论的相关性

    Identification of the Relevance of Comments in Codes Using Bag of Words and Transformer Based Models. (arXiv:2308.06144v1 [cs.IR])

    [http://arxiv.org/abs/2308.06144](http://arxiv.org/abs/2308.06144)

    本研究通过使用词袋和基于Transformer的模型，对代码注释的相关性进行识别。在训练语料库中，探索了不同的特征工程和文本分类技术，并比较了传统词袋模型和Transformer模型的性能。

    

    今年，信息检索论坛(FIRE)启动了一个共享任务，用于对不同代码段的评论进行分类。这是一个二元文本分类任务，目标是确定给定代码段的评论是否相关。印度科学教育与研究院博帕尔分院(IISERB)的BioNLP-IISERB小组参与了这项任务，并为五种不同的模型提交了五种运行结果。本文介绍了这些模型的概况和在训练语料库上的其他重要发现。这些方法涉及不同的特征工程方案和文本分类技术。对于词袋模型，我们探索了不同的分类器，如随机森林、支持向量机和逻辑回归，以识别给定训练语料库中的重要特征。此外，还研究了基于预训练Transformer的模型。

    The Forum for Information Retrieval (FIRE) started a shared task this year for classification of comments of different code segments. This is binary text classification task where the objective is to identify whether comments given for certain code segments are relevant or not. The BioNLP-IISERB group at the Indian Institute of Science Education and Research Bhopal (IISERB) participated in this task and submitted five runs for five different models. The paper presents the overview of the models and other significant findings on the training corpus. The methods involve different feature engineering schemes and text classification techniques. The performance of the classical bag of words model and transformer-based models were explored to identify significant features from the given training corpus. We have explored different classifiers viz., random forest, support vector machine and logistic regression using the bag of words model. Furthermore, the pre-trained transformer based models 
    
[^16]: CompTLL-UNet: 使用JPEG系数深度特征学习在具挑战性手写文件中压缩领域文本行定位

    CompTLL-UNet: Compressed Domain Text-Line Localization in Challenging Handwritten Documents using Deep Feature Learning from JPEG Coefficients. (arXiv:2308.06142v1 [cs.CV])

    [http://arxiv.org/abs/2308.06142](http://arxiv.org/abs/2308.06142)

    本文提出了一种使用JPEG压缩系数进行深度特征学习的方法，实现在具有挑战性的手写文件中的文本行定位。通过设计改进的CompTLL-UNet架构，在JPEG压缩域中直接定位文本行，并在ICDAR2017和ICDAR2019基准数据集上进行了测试和验证。

    

    自动定位手写文件中的文本行仍然是一个开放且具有挑战性的研究问题。当考虑到复杂手写文件图像的情况下，各种书写问题如行间不均匀间距、振荡和接触文字以及倾斜的存在，将更加具有挑战性，因为传统的处理压缩文件的方法是通过解压缩，但在本文中，我们提出了一种直接从JPEG压缩系数中进行深度特征学习而无需完全解压缩来实现JPEG压缩域中的文本行定位。设计了一种改进的U-Net架构，称为Compressed Text-Line Localization Network（CompTLL-UNet）来实现这一目标。该模型经过训练和测试，使用包括ICDAR2017（cBAD）和ICDAR2019（cBAD）在内的基准数据集的JPEG压缩版本进行了报告。

    Automatic localization of text-lines in handwritten documents is still an open and challenging research problem. Various writing issues such as uneven spacing between the lines, oscillating and touching text, and the presence of skew become much more challenging when the case of complex handwritten document images are considered for segmentation directly in their respective compressed representation. This is because, the conventional way of processing compressed documents is through decompression, but here in this paper, we propose an idea that employs deep feature learning directly from the JPEG compressed coefficients without full decompression to accomplish text-line localization in the JPEG compressed domain. A modified U-Net architecture known as Compressed Text-Line Localization Network (CompTLL-UNet) is designed to accomplish it. The model is trained and tested with JPEG compressed version of benchmark datasets including ICDAR2017 (cBAD) and ICDAR2019 (cBAD), reporting the state
    
[^17]: 应用人工神经网络研究压力过滤性能的探索和锌浸出滤饼含水率建模

    Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling. (arXiv:2308.06138v1 [cs.LG])

    [http://arxiv.org/abs/2308.06138](http://arxiv.org/abs/2308.06138)

    这项研究利用人工神经网络模型成功预测了锌生产压力过滤过程中的滤饼含水率，为锌生产工艺提供了可靠的预测手段。

    

    机器学习是材料科学应用中的强大工具。人工神经网络是一种能够提供高预测准确性的机器学习技术。本研究旨在开发一种人工神经网络模型，用于预测锌生产的压力过滤过程中的滤饼含水率。滤饼含水率受到七个参数的影响：温度（35摄氏度和65摄氏度），固体浓度（0.2克/升和0.38克/升），pH值（2、3.5和5），吹气时间（2分钟、10分钟和15分钟），滤饼厚度（14毫米、20毫米、26毫米和34毫米），压力和过滤时间。本研究使用两种类型的织物进行了288次测试：聚丙烯（S1）和涤纶（S2）。通过决定系数（R2）、均方误差（MSE）和平均绝对误差（MAE）指标评估了人工神经网络模型在两个数据集上的性能。结果显示，对于S1和S2，R2值分别为0.88和0.83，MSE值分别为6.243x10-07和1.086x10-06，MAE值分别为0.00056和0.00088。

    Machine Learning (ML) is a powerful tool for material science applications. Artificial Neural Network (ANN) is a machine learning technique that can provide high prediction accuracy. This study aimed to develop an ANN model to predict the cake moisture of the pressure filtration process of zinc production. The cake moisture was influenced by seven parameters: temperature (35 and 65 Celsius), solid concentration (0.2 and 0.38 g/L), pH (2, 3.5, and 5), air-blow time (2, 10, and 15 min), cake thickness (14, 20, 26, and 34 mm), pressure, and filtration time. The study conducted 288 tests using two types of fabrics: polypropylene (S1) and polyester (S2). The ANN model was evaluated by the Coefficient of determination (R2), the Mean Square Error (MSE), and the Mean Absolute Error (MAE) metrics for both datasets. The results showed R2 values of 0.88 and 0.83, MSE values of 6.243x10-07 and 1.086x10-06, and MAE values of 0.00056 and 0.00088 for S1 and S2, respectively. These results indicated t
    
[^18]: 使用带有Akaike信息准则的耦合物理信息神经网络进行软传感器的PDE发现

    PDE Discovery for Soft Sensors Using Coupled Physics-Informed Neural Network with Akaike's Information Criterion. (arXiv:2308.06132v1 [cs.LG])

    [http://arxiv.org/abs/2308.06132](http://arxiv.org/abs/2308.06132)

    本文提出了一种使用带有Akaike信息准则的耦合物理信息神经网络（CPINN-AIC）的方法，用于发现软传感器的偏微分方程（PDE）。该方法能够发现PDE的适当结构，包括微分算子和源项，以弥补理想化的PDE与实际情况之间的差距。

    

    软传感器广泛应用于使用易于测量的变量和数学模型来监测关键变量。对于具有时空依赖性的工业过程中的软传感器，偏微分方程（PDE）是模型候选。然而，理想化的PDE和实际情况之间通常存在差距。发现包括微分算子和源项在内的PDE的适当结构可以弥补这些差距。为此，提出了一种使用Akaike准则的耦合物理信息神经网络（CPINN-AIC）来发现软传感器的PDE。首先，采用CPINN获得满足PDE的解和源项。然后，我们提出了一个数据-物理混合损失函数来训练CPINN，其中涉及未确定的微分算子的组合。最后，人工和实际数据集被用来验证可行性和效果。

    Soft sensors have been extensively used to monitor key variables using easy-to-measure variables and mathematical models. Partial differential equations (PDEs) are model candidates for soft sensors in industrial processes with spatiotemporal dependence. However, gaps often exist between idealized PDEs and practical situations. Discovering proper structures of PDEs, including the differential operators and source terms, can remedy the gaps. To this end, a coupled physics-informed neural network with Akaike's criterion information (CPINN-AIC) is proposed for PDE discovery of soft sensors. First, CPINN is adopted for obtaining solutions and source terms satisfying PDEs. Then, we propose a data-physics-hybrid loss function for training CPINN, in which undetermined combinations of differential operators are involved. Consequently, AIC is used to discover the proper combination of differential operators. Finally, the artificial and practical datasets are used to verify the feasibility and ef
    
[^19]: 基于图像的跨城市交通预测的不确定性量化

    Uncertainty Quantification for Image-based Traffic Prediction across Cities. (arXiv:2308.06129v1 [cs.CV])

    [http://arxiv.org/abs/2308.06129](http://arxiv.org/abs/2308.06129)

    本研究调查了不确定性量化方法在跨城市交通预测中的应用，发现存在的UQ方法可以提供有意义的不确定性估计，并可以用于无监督异常检测。

    

    尽管深度学习模型在交通预测方面具有较强的预测性能，但由于解释性的缺乏，它们在实际智能交通系统中的普遍部署受到了限制。不确定性量化（UQ）方法提供了一种引入概率推理、改进决策和提高模型部署潜力的方法。为了全面了解现有UQ方法在交通预测中的有用性以及获得的不确定性与城市范围内交通动态之间的关系，我们对跨越多个城市和时间段的大规模基于图像的交通数据集应用了这些方法。我们比较了两种认知不确定性和两种重要性不确定性UQ方法在时间和时空转换任务上的表现，并发现可以获得有意义的不确定性估计。我们进一步展示了如何利用不确定性估计来进行城市交通动态变化的无监督异常检测。我们发现我们的方法可以在城市交通动态变化方面发现异常。

    Despite the strong predictive performance of deep learning models for traffic prediction, their widespread deployment in real-world intelligent transportation systems has been restrained by a lack of interpretability. Uncertainty quantification (UQ) methods provide an approach to induce probabilistic reasoning, improve decision-making and enhance model deployment potential. To gain a comprehensive picture of the usefulness of existing UQ methods for traffic prediction and the relation between obtained uncertainties and city-wide traffic dynamics, we investigate their application to a large-scale image-based traffic dataset spanning multiple cities and time periods. We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered. We further demonstrate how uncertainty estimates can be employed for unsupervised outlier detection on changes in city traffic dynamics. We find that our 
    
[^20]: 从离线数据中学习可变目标的控制策略

    Learning Control Policies for Variable Objectives from Offline Data. (arXiv:2308.06127v1 [cs.LG])

    [http://arxiv.org/abs/2308.06127](http://arxiv.org/abs/2308.06127)

    本文介绍了一种基于模型的策略搜索方法的扩展——可变目标策略（VOP），通过该方法，策略可以有效地泛化多种参数化奖励函数的目标。通过改变策略的输入目标，用户可以在运行时自由调整其行为或重新平衡优化目标，无需收集额外的观测数据批次或重新训练。

    

    离线强化学习为获取动态系统的先进控制策略提供了一种可行的方法，尤其是在无法与环境直接交互时。本文介绍了一种基于模型的策略搜索方法的概念扩展，称为可变目标策略（VOP）。通过这种方法，策略被训练以有效地泛化多种参数化奖励函数的目标。我们证明，通过改变作为策略输入的目标，用户可以在运行时自由调整其行为或重新平衡优化目标，而无需收集额外的观测数据批次或重新训练。

    Offline reinforcement learning provides a viable approach to obtain advanced control strategies for dynamical systems, in particular when direct interaction with the environment is not available. In this paper, we introduce a conceptual extension for model-based policy search methods, called variable objective policy (VOP). With this approach, policies are trained to generalize efficiently over a variety of objectives, which parameterize the reward function. We demonstrate that by altering the objectives passed as input to the policy, users gain the freedom to adjust its behavior or re-balance optimization targets at runtime, without need for collecting additional observation batches or re-training.
    
[^21]: 延迟格兰杰因果性的霍克斯过程

    Hawkes Processes with Delayed Granger Causality. (arXiv:2308.06106v1 [cs.LG])

    [http://arxiv.org/abs/2308.06106](http://arxiv.org/abs/2308.06106)

    本论文提出了一个基于霍克斯过程的延迟格兰杰因果效应模型，通过显式地建模时间延迟，增加了模型的灵活性，并推断出时间延迟的后验分布，有助于追踪原始因果时间。

    

    我们旨在基于多元霍克斯过程明确地建模延迟的格兰杰因果效应。这个想法的灵感来自于因果事件通常需要一些时间才能产生影响。研究这个时间延迟本身就很有意义。在提出的模型中，我们首先证明了在适当条件下的延迟参数的可辨识性。我们进一步研究了在复杂情况下的模型估计方法，其中我们希望推断出时间延迟的后验分布，并了解该分布在不同情况下的变化。我们将时间延迟视为潜在变量，并制定了一个变分自编码器（VAE）算法来近似时间延迟的后验分布。通过明确地建模霍克斯过程中的时间延迟，我们为模型增加了灵活性。推断出的时间延迟后验分布具有科学意义，并有助于追踪支持根本原因分析的原始因果时间。我们对模型进行了实证评估。

    We aim to explicitly model the delayed Granger causal effects based on multivariate Hawkes processes. The idea is inspired by the fact that a causal event usually takes some time to exert an effect. Studying this time lag itself is of interest. Given the proposed model, we first prove the identifiability of the delay parameter under mild conditions. We further investigate a model estimation method under a complex setting, where we want to infer the posterior distribution of the time lags and understand how this distribution varies across different scenarios. We treat the time lags as latent variables and formulate a Variational Auto-Encoder (VAE) algorithm to approximate the posterior distribution of the time lags. By explicitly modeling the time lags in Hawkes processes, we add flexibility to the model. The inferred time-lag posterior distributions are of scientific meaning and help trace the original causal time that supports the root cause analysis. We empirically evaluate our model
    
[^22]: Transformer架构的可组合函数保持扩展方法

    Composable Function-preserving Expansions for Transformer Architectures. (arXiv:2308.06103v1 [cs.LG])

    [http://arxiv.org/abs/2308.06103](http://arxiv.org/abs/2308.06103)

    提出了六个可组合的转换方法，逐渐增加基于Transformer的神经网络的规模，同时保持功能，充分利用现有知识，实现更大和更强大模型的高效培训流程。

    

    训练最新的神经网络需要大量的计算和时间成本。模型规模被认为是实现和提升最新技术的关键因素。增加神经网络的规模通常需要从头开始，通过随机初始化模型的所有参数，因为这意味着架构参数的变化，不允许从更小的模型中直接传递知识。在这项工作中，我们提出了六个可组合的转换方法，逐渐增加基于Transformer的神经网络的规模，同时保持功能，允许根据需要扩展模型的容量。我们提供了对每个转换的最小初始化约束下精确功能保持的证明。所提出的方法可以通过在训练过程中逐步扩展架构，实现更大和更强大模型的高效培训流程。

    Training state-of-the-art neural networks requires a high cost in terms of compute and time. Model scale is recognized to be a critical factor to achieve and improve the state-of-the-art. Increasing the scale of a neural network normally requires restarting from scratch by randomly initializing all the parameters of the model, as this implies a change of architecture's parameters that does not allow for a straightforward transfer of knowledge from smaller size models. In this work, we propose six composable transformations to incrementally increase the size of transformer-based neural networks while preserving functionality, allowing to expand the capacity of the model as needed. We provide proof of exact function preservation under minimal initialization constraints for each transformation. The proposed methods may enable efficient training pipelines for larger and more powerful models by progressively expanding the architecture throughout training.
    
[^23]: 基于扩散的视觉对抗性解释 - 实现系统性定量评估

    Diffusion-based Visual Counterfactual Explanations -- Towards Systematic Quantitative Evaluation. (arXiv:2308.06100v1 [cs.CV])

    [http://arxiv.org/abs/2308.06100](http://arxiv.org/abs/2308.06100)

    这项研究提出了一个用于对视觉对抗性解释方法进行系统性定量评估的框架，并在最新的生成模型中探索了关键设计选择的影响。研究结果为未来改进VCE方法指明了多个方向。

    

    最新的视觉对抗性解释(VCE)方法利用深度生成模型的能力合成了高维图像的新示例，质量令人印象深刻。然而，目前很难比较这些VCE方法的性能，因为评估程序在很大程度上存在差异，通常仅限于对个别示例的可视化检查和小规模用户研究。在本工作中，我们提出了一个用于VCE方法系统性定量评估的框架和一套最小指标集。我们使用该框架探索了最新基于扩散的生成模型在自然图像分类（ImageNet）中VCE方法的某些关键设计选择的影响。我们进行了一系列类似削弱实验的测试，为各种复杂度、准确性和稳健性的分类器生成了数千个VCE。我们的研究结果对于未来改进VCE方法提供了多个方向。通过分享我们的方法论和

    Latest methods for visual counterfactual explanations (VCE) harness the power of deep generative models to synthesize new examples of high-dimensional images of impressive quality. However, it is currently difficult to compare the performance of these VCE methods as the evaluation procedures largely vary and often boil down to visual inspection of individual examples and small scale user studies. In this work, we propose a framework for systematic, quantitative evaluation of the VCE methods and a minimal set of metrics to be used. We use this framework to explore the effects of certain crucial design choices in the latest diffusion-based generative models for VCEs of natural image classification (ImageNet). We conduct a battery of ablation-like experiments, generating thousands of VCEs for a suite of classifiers of various complexity, accuracy and robustness. Our findings suggest multiple directions for future advancements and improvements of VCE methods. By sharing our methodology and
    
[^24]: 神经对话模型及其控制方法：失败和修复的综述

    Neural Conversation Models and How to Rein Them in: A Survey of Failures and Fixes. (arXiv:2308.06095v1 [cs.CL])

    [http://arxiv.org/abs/2308.06095](http://arxiv.org/abs/2308.06095)

    这项综述研究了以强大语言模型为基础的开放领域对话系统，并探讨了如何通过干预底层语言模型的不同方面，如数据、训练制度或解码，来保证模型的流畅性、信息丰富性、一致性、连贯性以及遵循社会准则的特性。

    

    最近，以强大语言模型为基础的条件语言模型能够以看似流利的方式延续任何类型的文本来源。这个事实促进了对基于强大语言模型的开放领域对话系统的研究，旨在通过生成适当的对话内容来模仿对话方的行为。然而，从语言学的角度来看，参与对话的复杂性很高。在这项综述中，我们从这一特定研究领域的角度解释了Grice的合作性对话最大规则，并将文献系统化地归纳为一个贡献何种内容是适当的方面：神经对话模型必须流畅、信息丰富、一致、连贯，并遵循社会准则。为了确保这些特性，最近的方法尝试在数据、训练制度或解码等各个干预点上控制底层语言模型。按照这些类别和干预点进行排序，我们讨论了一些有希望的方法。

    Recent conditional language models are able to continue any kind of text source in an often seemingly fluent way. This fact encouraged research in the area of open-domain conversational systems that are based on powerful language models and aim to imitate an interlocutor by generating appropriate contributions to a written dialogue. From a linguistic perspective, however, the complexity of contributing to a conversation is high. In this survey, we interpret Grice's maxims of cooperative conversation from the perspective of this specific research area and systematize the literature under the aspect of what makes a contribution appropriate: A neural conversation model has to be fluent, informative, consistent, coherent, and follow social norms. In order to ensure these qualities, recent approaches try to tame the underlying language models at various intervention points, such as data, training regime or decoding. Sorted by these categories and intervention points, we discuss promising at
    
[^25]: 强化逻辑规则学习用于时间点过程

    Reinforcement Logic Rule Learning for Temporal Point Processes. (arXiv:2308.06094v1 [cs.LG])

    [http://arxiv.org/abs/2308.06094](http://arxiv.org/abs/2308.06094)

    该论文提出了一个用于时间点过程的强化逻辑规则学习框架，利用逐步优化的方法扩展解释性的规则集来解释时间事件的发生。通过使用神经搜索策略和强化学习框架，可以高效地生成新的规则内容和权重。

    

    我们提出了一个框架，可以逐步扩展解释性的时间逻辑规则集，以解释时间事件的发生。利用时间点过程建模和学习框架，规则内容和权重将逐渐优化，直到观测事件序列的似然性最优。所提出的算法在当前规则集权重更新的主问题和搜索并包含最佳增加似然性的新规则的子问题之间交替进行。所制定的主问题是凸的，使用连续优化相对容易求解，而子问题则需要搜索巨大的组合规则谓词和关系空间。为解决这个挑战，我们提出了一个神经搜索策略，学习生成新规则内容的一系列动作。策略参数将使用强化学习框架进行端到端训练，其中奖励信号可以高效地得到。

    We propose a framework that can incrementally expand the explanatory temporal logic rule set to explain the occurrence of temporal events. Leveraging the temporal point process modeling and learning framework, the rule content and weights will be gradually optimized until the likelihood of the observational event sequences is optimal. The proposed algorithm alternates between a master problem, where the current rule set weights are updated, and a subproblem, where a new rule is searched and included to best increase the likelihood. The formulated master problem is convex and relatively easy to solve using continuous optimization, whereas the subproblem requires searching the huge combinatorial rule predicate and relationship space. To tackle this challenge, we propose a neural search policy to learn to generate the new rule content as a sequence of actions. The policy parameters will be trained end-to-end using the reinforcement learning framework, where the reward signals can be effic
    
[^26]: 专家权重平均化: 一种视觉Transformer的新通用训练方案

    Experts Weights Averaging: A New General Training Scheme for Vision Transformers. (arXiv:2308.06093v1 [cs.CV])

    [http://arxiv.org/abs/2308.06093](http://arxiv.org/abs/2308.06093)

    本文提出了一种新的通用训练策略，利用专家权重平均化实现了对ViTs的性能提升，而不增加推断成本。

    

    结构重参数化是一种用于卷积神经网络（CNNs）的通用训练方案，可以在不增加推断成本的情况下提高性能。随着视觉Transformer (ViTs)在各种视觉任务中逐渐超越CNNs，一个问题出现了: 是否存在一种专门用于ViTs的训练方案，可以在不增加推断成本的情况下提高性能？最近，混合专家（MoE）引起了越来越多的关注，因为它可以通过稀疏激活的专家有效地扩展Transformer的容量，而成本保持不变。考虑到MoE也可以看作是一种多支系结构，我们能否利用MoE来实现类似结构重参数化的ViT训练方案呢？在本文中，我们肯定地回答了这些问题，并提出了一种新的ViTs通用训练策略。具体来说，我们分离了ViTs的训练和推断阶段。在训练阶段，我们替换了一些前馈网络（FFNs）

    Structural re-parameterization is a general training scheme for Convolutional Neural Networks (CNNs), which achieves performance improvement without increasing inference cost. As Vision Transformers (ViTs) are gradually surpassing CNNs in various visual tasks, one may question: if a training scheme specifically for ViTs exists that can also achieve performance improvement without increasing inference cost? Recently, Mixture-of-Experts (MoE) has attracted increasing attention, as it can efficiently scale up the capacity of Transformers at a fixed cost through sparsely activated experts. Considering that MoE can also be viewed as a multi-branch structure, can we utilize MoE to implement a ViT training scheme similar to structural re-parameterization? In this paper, we affirmatively answer these questions, with a new general training strategy for ViTs. Specifically, we decouple the training and inference phases of ViTs. During training, we replace some Feed-Forward Networks (FFNs) of the 
    
[^27]: 对协同过滤丢失函数的更好理解

    Toward a Better Understanding of Loss Functions for Collaborative Filtering. (arXiv:2308.06091v1 [cs.IR])

    [http://arxiv.org/abs/2308.06091](http://arxiv.org/abs/2308.06091)

    现有研究已经表明，通过改进对齐和均匀性设计的损失函数可以实现显著的性能提升。本文提出了一种新的损失函数，称为MAWU，它考虑了数据集的独特模式。

    

    协同过滤（CF）是现代推荐系统中的关键技术。CF模型的学习过程通常由三个组件组成：交互编码器、损失函数和负采样。尽管许多现有研究已经提出了各种CF模型来设计复杂的交互编码器，但最近的工作表明，简单地重新制定损失函数可以实现显著的性能提升。本文深入分析了现有损失函数之间的关系。我们的数学分析揭示了先前的损失函数可以解释为对齐和均匀性函数：（i）对齐匹配用户和物品表示，（ii）均匀性分散用户和物品分布。受到这个分析的启示，我们提出了一种改进对齐和均匀性设计的损失函数，考虑到数据集的独特模式，称为Margin-aware Alignment and Weighted Uniformity（MAWU）。MAWU的关键创新是

    Collaborative filtering (CF) is a pivotal technique in modern recommender systems. The learning process of CF models typically consists of three components: interaction encoder, loss function, and negative sampling. Although many existing studies have proposed various CF models to design sophisticated interaction encoders, recent work shows that simply reformulating the loss functions can achieve significant performance gains. This paper delves into analyzing the relationship among existing loss functions. Our mathematical analysis reveals that the previous loss functions can be interpreted as alignment and uniformity functions: (i) the alignment matches user and item representations, and (ii) the uniformity disperses user and item distributions. Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty of MAWU 
    
[^28]: 用采样规范保护智能能源系统中基于学习的控制

    Safeguarding Learning-based Control for Smart Energy Systems with Sampling Specifications. (arXiv:2308.06069v1 [cs.SE])

    [http://arxiv.org/abs/2308.06069](http://arxiv.org/abs/2308.06069)

    本研究研究了在能源系统控制中使用强化学习所面临的挑战，提出了一种通过离散化加强安全要求的方法。离散化使得可以使用先进的工程方法并进行形式验证，其中概率保证形成了满足原始安全要求的下界。

    

    我们研究了在能源系统控制中使用强化学习所面临的挑战，除了性能要求外，还有额外的安全要求，如避免停电。我们详细介绍了如何通过将安全要求在实时时态逻辑中进行离散化加强，使得LTL公式的满足意味着满足原始的安全要求。离散化使得可以使用先进的工程方法，如为安全强化学习合成盾牌以及形式验证，其中对于统计模型检验，LTL模型检验得到的概率保证形成了满足原始实时安全要求的下界。

    We study challenges using reinforcement learning in controlling energy systems, where apart from performance requirements, one has additional safety requirements such as avoiding blackouts. We detail how these safety requirements in real-time temporal logic can be strengthened via discretization into linear temporal logic (LTL), such that the satisfaction of the LTL formulae implies the satisfaction of the original safety requirements. The discretization enables advanced engineering methods such as synthesizing shields for safe reinforcement learning as well as formal verification, where for statistical model checking, the probabilistic guarantee acquired by LTL model checking forms a lower bound for the satisfaction of the original real-time safety requirements.
    
[^29]: 带有Polyak步长和线性搜索的自适应SGD: 鲁棒收敛和方差减小

    Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction. (arXiv:2308.06058v1 [cs.LG])

    [http://arxiv.org/abs/2308.06058](http://arxiv.org/abs/2308.06058)

    本文提出了AdaSPS和AdaSLS两种新的变种算法，用于解决SGD在非插值环境下的收敛问题，并在训练超参数模型时保持线性和亚线性的收敛速度。

    

    最近提出的随机Polyak步长 (SPS) 和随机线性搜索 (SLS) 在训练超参数模型时显示出了显著的有效性。然而，在非插值环境下，这两种算法只能保证收敛到一个解的邻域，可能导致比初始猜测更差的输出结果。尽管已经提出了人为减小自适应步长的方法来解决这个问题 (Orvieto et al. [2022])，但这种方法会导致凸函数和超参数模型的收敛速度变慢。在本文中，我们做出了两个贡献：首先，我们提出了两种新的SPS和SLS变种，分别称为AdaSPS和AdaSLS，它们在非插值环境中保证收敛，并且在训练超参数模型时保持凸函数和强凸函数的亚线性和线性收敛速度。AdaSLS不需要对问题相关参数的了解，而AdaSPS只需要最优函数值的下界。

    The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value 
    
[^30]: 在内存层次结构上具有MiRo的成本效益的设备上的持续学习

    Cost-effective On-device Continual Learning over Memory Hierarchy with Miro. (arXiv:2308.06053v1 [cs.LG])

    [http://arxiv.org/abs/2308.06053](http://arxiv.org/abs/2308.06053)

    这项工作是首次探索基于层次内存回放的持续学习的设计空间，旨在在边缘设备上实现成本效益。提出了Miro，一个通过动态配置持续学习系统的新颖系统运行时，以实现最佳的成本效益。广泛的评估显示Miro明显优于其他方案。

    

    持续学习是从持续的任务流中逐步训练神经网络模型。为了记住先前学到的知识，之前的研究将旧样本存储在一个内存层次结构中，并在新任务到来时进行回放。采用持续学习以保护数据隐私的边缘设备通常对能源敏感，因此需要在不损害能源效率的情况下保持高模型准确度，即成本效益。我们的工作是首次探索基于层次内存回放的持续学习的设计空间，以获得在边缘设备上的成本效益。我们提出了Miro，一个新颖的系统运行时，通过使其能够根据资源状态动态配置持续学习系统，从而将我们的见解精确地整合到持续学习框架中，以实现最佳成本效益。为了实现这个目标，Miro还对带有明确准确度-能量平衡的参数进行在线分析，并以低开销地适应最佳值。广泛的评估显示Miro明显优于其他方案。

    Continual learning (CL) trains NN models incrementally from a continuous stream of tasks. To remember previously learned knowledge, prior studies store old samples over a memory hierarchy and replay them when new tasks arrive. Edge devices that adopt CL to preserve data privacy are typically energy-sensitive and thus require high model accuracy while not compromising energy efficiency, i.e., cost-effectiveness. Our work is the first to explore the design space of hierarchical memory replay-based CL to gain insights into achieving cost-effectiveness on edge devices. We present Miro, a novel system runtime that carefully integrates our insights into the CL framework by enabling it to dynamically configure the CL system based on resource states for the best cost-effectiveness. To reach this goal, Miro also performs online profiling on parameters with clear accuracy-energy trade-offs and adapts to optimal values with low overhead. Extensive evaluations show that Miro significantly outperfo
    
[^31]: 面向实例自适应推理的联邦学习

    Towards Instance-adaptive Inference for Federated Learning. (arXiv:2308.06051v1 [cs.LG])

    [http://arxiv.org/abs/2308.06051](http://arxiv.org/abs/2308.06051)

    本文提出了一种面向实例自适应推理的联邦学习算法，通过使用缩放和位移深度特征（SSF）实现了处理客户端数据异质性的能力。

    

    联邦学习是一种分布式学习范式，通过汇集本地训练来使多个客户端学习一个强大的全局模型。然而，全局模型的性能通常受到客户端之间的非独立同分布分布的影响，需要大量的努力来减轻客户端数据异质性。超越客户端数据异质性，我们注意到在复杂的现实世界数据中也可以观察到客户端内部的异质性，严重影响联邦学习的性能。在本文中，我们提出了一种新颖的联邦学习算法，即FedIns，在联邦学习框架中实现了实例自适应推理来处理客户端数据的异质性。我们不使用庞大的实例自适应模型，而是采用了一种参数高效的精细调整方法——缩放和位移深度特征（SSF），并在预训练模型上进行。具体而言，我们首先为每个客户端训练一个SSF池，在服务器端汇集这些SSF池，从而仍然保持低通信成本。

    Federated learning (FL) is a distributed learning paradigm that enables multiple clients to learn a powerful global model by aggregating local training. However, the performance of the global model is often hampered by non-i.i.d. distribution among the clients, requiring extensive efforts to mitigate inter-client data heterogeneity. Going beyond inter-client data heterogeneity, we note that intra-client heterogeneity can also be observed on complex real-world data and seriously deteriorate FL performance. In this paper, we present a novel FL algorithm, i.e., FedIns, to handle intra-client data heterogeneity by enabling instance-adaptive inference in the FL framework. Instead of huge instance-adaptive models, we resort to a parameter-efficient fine-tuning method, i.e., scale and shift deep features (SSF), upon a pre-trained model. Specifically, we first train an SSF pool for each client, and aggregate these SSF pools on the server side, thus still maintaining a low communication cost. T
    
[^32]: 不可观测的驱动源下控制角色动作的方法

    Controlling Character Motions without Observable Driving Source. (arXiv:2308.06025v1 [cs.AI])

    [http://arxiv.org/abs/2308.06025](http://arxiv.org/abs/2308.06025)

    本文提出了一个系统框架，结合了VQ-VAE和使用强化学习训练的一种新型基于令牌级控制策略，通过在顶部注入高级先验模型来生成无限长且多样化的序列。

    

    如何在没有任何驱动源的情况下生成多样化、逼真且无限长的头部/身体序列？我们认为这个未经充分探究的研究问题并不是一件轻松的事，并且存在着独特的技术挑战。在没有来自驱动源的语义约束的情况下，使用标准的自回归模型生成无限长序列很容易导致以下问题：1）由于累积误差产生了超出分布（OOD）问题；2）生成的运动序列缺乏多样性，无法产生逼真和生动的动作序列；3）时间上出现了不期望的周期性模式。为了解决上述挑战，我们提出了一个系统框架，将VQ-VAE的优点与使用经过精心设计的奖励函数训练的一种新型基于令牌级控制策略相结合，通过在顶部注入高级先验模型来生成无限长且多样化的序列。尽管我们现在关注于没有驱动源，但我们的框架可以推广到受控合成场景。

    How to generate diverse, life-like, and unlimited long head/body sequences without any driving source? We argue that this under-investigated research problem is non-trivial at all, and has unique technical challenges behind it. Without semantic constraints from the driving sources, using the standard autoregressive model to generate infinitely long sequences would easily result in 1) out-of-distribution (OOD) issue due to the accumulated error, 2) insufficient diversity to produce natural and life-like motion sequences and 3) undesired periodic patterns along the time. To tackle the above challenges, we propose a systematic framework that marries the benefits of VQ-VAE and a novel token-level control policy trained with reinforcement learning using carefully designed reward functions. A high-level prior model can be easily injected on top to generate unlimited long and diverse sequences. Although we focus on no driving sources now, our framework can be generalized for controlled synthe
    
[^33]: 大型语言模型在电信行业的未来影响

    Large Language Models for Telecom: Forthcoming Impact on the Industry. (arXiv:2308.06013v1 [cs.IT])

    [http://arxiv.org/abs/2308.06013](http://arxiv.org/abs/2308.06013)

    大型语言模型在电信行业将产生重要的影响。它们可以提高运营效率，简化任务，并需要解决使用中的挑战。

    

    大型语言模型（LLMs）已经成为一股变革的力量，不仅在自然语言处理（NLP）的传统领域之外，还在许多领域引起了革命性的关注。随着LLM技术的不断发展，电信行业面临着潜在影响的前景。为了阐明这些影响，我们深入研究LLMs的内部机制，提供了关于它们目前的能力和局限性的见解。我们还研究了在电信行业可以方便实施的使用案例，简化了目前妨碍运营效率并需要大量人力和工程专业知识的任务。此外，我们还揭示了在电信领域利用LLMs所面临的独特挑战的重要研究方向。解决这些挑战是充分利用LLMs潜力和发挥其能力的重要进展。

    Large Language Models (LLMs) have emerged as a transformative force, revolutionizing numerous fields well beyond the conventional domain of Natural Language Processing (NLP) and garnering unprecedented attention. As LLM technology continues to progress, the telecom industry is facing the prospect of its potential impact on its landscape. To elucidate these implications, we delve into the inner workings of LLMs, providing insights into their current capabilities and limitations. We also examine the use cases that can be readily implemented in the telecom industry, streamlining numerous tasks that currently hinder operational efficiency and demand significant manpower and engineering expertise. Furthermore, we uncover essential research directions that deal with the distinctive challenges of utilizing the LLMs within the telecom domain. Addressing these challenges represents a significant stride towards fully harnessing the potential of LLMs and unlocking their capabilities to the fulles
    
[^34]: AI为科学是否需要另一个ImageNet或完全不同的基准？机器学习势场的案例研究。

    Does AI for science need another ImageNet Or totally different benchmarks? A case study of machine learning force fields. (arXiv:2308.05999v1 [cs.LG])

    [http://arxiv.org/abs/2308.05999](http://arxiv.org/abs/2308.05999)

    本文研究了AI为科学是否需要新的基准测试方法，并以机器学习势场为案例研究。通过发现并解决在科学基准测试中存在的问题，我们提出了评估MLFF模型的解决方案，包括样本效率、时间域敏感性和数据集之间的泛化能力。

    

    AI for science (AI4S)是一个新兴的研究领域，旨在使用机器学习方法提高科学计算任务的准确性和速度。传统的AI基准方法在适应AI4S领域的独特挑战上存在困难，因为它们假设训练、测试和未来的真实查询数据是独立同分布的，而AI4S工作负载则预期存在分布不同的问题实例。本文以机器学习势场（MLFF）为案例研究，探讨了有效评估AI for science需要新方法的必要性。MLFF是一种低计算成本和高精度的加速分子动力学（MD）模拟的方法。我们发现在科学意义上的基准测试中存在各种错失的机会，并提出解决方案来评估MLFF模型的样本效率、时间域敏感性和跨数据集的泛化能力。

    AI for science (AI4S) is an emerging research field that aims to enhance the accuracy and speed of scientific computing tasks using machine learning methods. Traditional AI benchmarking methods struggle to adapt to the unique challenges posed by AI4S because they assume data in training, testing, and future real-world queries are independent and identically distributed, while AI4S workloads anticipate out-of-distribution problem instances. This paper investigates the need for a novel approach to effectively benchmark AI for science, using the machine learning force field (MLFF) as a case study. MLFF is a method to accelerate molecular dynamics (MD) simulation with low computational cost and high accuracy. We identify various missed opportunities in scientifically meaningful benchmarking and propose solutions to evaluate MLFF models, specifically in the aspects of sample efficiency, time domain sensitivity, and cross-dataset generalization capabilities. By setting up the problem instant
    
[^35]: 通过评估类内特征方差快速准确地测量可转移性

    Fast and Accurate Transferability Measurement by Evaluating Intra-class Feature Variance. (arXiv:2308.05986v1 [cs.LG])

    [http://arxiv.org/abs/2308.05986](http://arxiv.org/abs/2308.05986)

    本论文提出了一种通过评估类内特征方差快速准确地测量可转移性的方法，该方法能够用于选择最适合下游任务的预训练模型，包括有和无分类器的模型，并且适用于选择目标任务的最佳转移层。

    

    给定一组预训练模型，如何快速准确地找到最适合下游任务的预训练模型？可转移性测量是评估一个在源任务上学习的预训练模型对于目标任务的可转移性的指标。它用于快速对给定任务的预训练模型进行排名，因此成为迁移学习中至关重要的一步。现有的方法将可转移性定义为在迁移学习之前，源模型对于目标数据的区分能力，无法准确估计微调性能。其中一些方法限制了可转移性测量在选择具有分类器的最佳有监督预训练模型中的应用。能够在各种情况下应用的通用可转移性测量方法十分重要，例如选择没有分类器的最佳自监督预训练模型，以及选择目标任务的最佳转移层。

    Given a set of pre-trained models, how can we quickly and accurately find the most useful pre-trained model for a downstream task? Transferability measurement is to quantify how transferable is a pre-trained model learned on a source task to a target task. It is used for quickly ranking pre-trained models for a given task and thus becomes a crucial step for transfer learning. Existing methods measure transferability as the discrimination ability of a source model for a target data before transfer learning, which cannot accurately estimate the fine-tuning performance. Some of them restrict the application of transferability measurement in selecting the best supervised pre-trained models that have classifiers. It is important to have a general method for measuring transferability that can be applied in a variety of situations, such as selecting the best self-supervised pre-trained models that do not have classifiers, and selecting the best transferring layer for a target task. In this wo
    
[^36]: 通过高阶HSIC学习具有增量信息的非参数DAGs

    Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v1 [cs.LG])

    [http://arxiv.org/abs/2308.05969](http://arxiv.org/abs/2308.05969)

    本文提出了一个基于高阶HSIC的方法，在学习Bayesian网络中解决了局部变量同时具有直接和间接依赖关系的问题，通过确定子集和两阶段算法来进行局部修正，取得了良好的效果。

    

    针对学习贝叶斯网络（BN）的基于评分的方法，目标是最大化全局评分函数。然而，如果局部变量同时具有直接和间接依赖关系，那么基于评分函数的全局优化将忽略具有间接依赖关系的变量之间的边缘，其得分小于具有直接依赖关系的边缘。本文提出了一个基于确定子集的可辨识性条件，以识别潜在的DAG。通过可辨识性条件，我们开发了一个两阶段算法，即最优调整（OT）算法，以在全局优化的基础上进行局部修正。在最优阶段，基于一阶Hilbert-Schmidt独立性准则（HSIC）的优化问题给出了一个估计的骨架作为初始确定的父节点子集。在调整阶段，根据高阶HSIC的理论证明增量特性，对骨架进行局部调整，包括删除、添加和DAG格式化策略。

    Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HS
    
[^37]: 学习的点云压缩用于分类

    Learned Point Cloud Compression for Classification. (arXiv:2308.05959v1 [eess.IV])

    [http://arxiv.org/abs/2308.05959](http://arxiv.org/abs/2308.05959)

    这篇论文提出了一种针对分类任务的新型点云编解码器，在不牺牲准确性的情况下实现了更高的压缩比，相比其他方法在速度和准确性上取得了更好的对比度-精度平衡，并且在ModelNet40数据集上实现了94%的BD比特率降低。

    

    深度学习越来越多地用于在3D点云数据上进行分类，物体检测和分割等机器视觉任务。然而，深度学习推断是计算密集型的。终端设备的有限计算能力因此需要一种编解码器，用于在网络上传输点云数据进行服务器端处理。这样的编解码器必须轻巧且能够在不牺牲准确性的情况下实现高压缩比。受此激发，我们提出了一种新颖的点云编解码器，专门用于分类任务。我们的编解码器基于PointNet，相比其他方法在速度和准确性上取得了更好的对比度-精度平衡。特别是，在ModelNet40数据集上，与非专用编解码器相比，BD比特率降低了94%。对于资源有限的终端设备，我们还提出了两种轻量级配置的编码器，其BD比特率削减率分别为93%和92%。

    Deep learning is increasingly being used to perform machine vision tasks such as classification, object detection, and segmentation on 3D point cloud data. However, deep learning inference is computationally expensive. The limited computational capabilities of end devices thus necessitate a codec for transmitting point cloud data over the network for server-side processing. Such a codec must be lightweight and capable of achieving high compression ratios without sacrificing accuracy. Motivated by this, we present a novel point cloud codec that is highly specialized for the machine task of classification. Our codec, based on PointNet, achieves a significantly better rate-accuracy trade-off in comparison to alternative methods. In particular, it achieves a 94% reduction in BD-bitrate over non-specialized codecs on the ModelNet40 dataset. For low-resource end devices, we also propose two lightweight configurations of our encoder that achieve similar BD-bitrate reductions of 93% and 92% wi
    
[^38]: 带有ARGEW的同质图节点嵌入：通过图边权重增强的随机游走

    Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random walks by Graph Edge Weights. (arXiv:2308.05957v1 [cs.SI])

    [http://arxiv.org/abs/2308.05957](http://arxiv.org/abs/2308.05957)

    提出了一种名为ARGEW的增强随机游走方法，用于生成能够更好反映节点之间边权重的节点嵌入。

    

    将网络中的节点表示为密集向量节点嵌入对于理解给定网络和解决许多下游任务非常重要。特别是对于权重同质图，其中具有相似节点的边缘权重较大，我们希望节点嵌入中具有强权重的节点对具有更接近的嵌入。虽然基于随机游走的节点嵌入方法，如node2vec和node2vec+，通过将边权重包含在行走转移概率中，可以适用于加权网络，但我们的实验证明嵌入结果不足以反映边权重。在本文中，我们提出了ARGEW（通过图边权重增强的随机游走），这是一种新颖的随机游走增强方法，通过扩展语料库使具有较大边权重的节点最终具有更接近的嵌入。ARGEW可以与任何基于随机游走的节点嵌入方法一起使用，因为它独立于随机采样策略本身并在已有方法的基础上工作。

    Representing nodes in a network as dense vectors node embeddings is important for understanding a given network and solving many downstream tasks. In particular, for weighted homophilous graphs where similar nodes are connected with larger edge weights, we desire node embeddings where node pairs with strong weights have closer embeddings. Although random walk based node embedding methods like node2vec and node2vec+ do work for weighted networks via including edge weights in the walk transition probabilities, our experiments show that the embedding result does not adequately reflect edge weights. In this paper, we propose ARGEW (Augmentation of Random walks by Graph Edge Weights), a novel augmentation method for random walks that expands the corpus in such a way that nodes with larger edge weights end up with closer embeddings. ARGEW can work with any random walk based node embedding method, because it is independent of the random sampling strategy itself and works on top of the already
    
[^39]: INR-Arch：一种用于隐式神经表征处理中任意阶梯度计算的数据流架构和编译器

    INR-Arch: A Dataflow Architecture and Compiler for Arbitrary-Order Gradient Computations in Implicit Neural Representation Processing. (arXiv:2308.05930v1 [cs.AR])

    [http://arxiv.org/abs/2308.05930](http://arxiv.org/abs/2308.05930)

    本论文提出了INR-Arch，这是一种用于隐式神经表征处理中任意阶梯度计算的数据流架构和编译器。该工作通过将计算图转化为硬件优化的数据流架构来解决了传统架构在高阶梯度计算上的挑战，为FPGA加速提供了有希望的目标。

    

    越来越多的研究人员发现了对各种应用的n阶梯度计算的用途，包括图形、元学习（MAML）、科学计算以及最近的隐式神经表征（INR）。最近的工作表明，INR的梯度可以直接用于编辑其所代表的数据，而无需将其转换回离散表示。然而，对于表示为计算图的函数，传统架构在高阶梯度的高需求和数据移动的高复杂度下面临挑战，这使得它成为FPGA加速的有希望的目标。在这项工作中，我们引入了INR-Arch，这是一个将n阶梯度的计算图转化为硬件优化的数据流架构的框架。我们通过两个阶段来解决这个问题。首先，我们设计了一个使用FIFO流和优化的计算内核的数据流架构。

    An increasing number of researchers are finding use for nth-order gradient computations for a wide variety of applications, including graphics, meta-learning (MAML), scientific computing, and most recently, implicit neural representations (INRs). Recent work shows that the gradient of an INR can be used to edit the data it represents directly without needing to convert it back to a discrete representation. However, given a function represented as a computation graph, traditional architectures face challenges in efficiently computing its nth-order gradient due to the higher demand for computing power and higher complexity in data movement. This makes it a promising target for FPGA acceleration. In this work, we introduce INR-Arch, a framework that transforms the computation graph of an nth-order gradient into a hardware-optimized dataflow architecture. We address this problem in two phases. First, we design a dataflow architecture that uses FIFO streams and an optimized computation kern
    
[^40]: 关于Occam算法的等价性

    On the equivalence of Occam algorithms. (arXiv:2308.05906v1 [cs.LG])

    [http://arxiv.org/abs/2308.05906](http://arxiv.org/abs/2308.05906)

    该论文证明了对于具有独立于δ的复杂度的Occam算法，其部分逆命题适用于闭合于例外列表的概念类，从而为相关的理论结果和算法设计方法提供了事后的理论依据。

    

    Blumer等人（1987年、1989年）证明了任何可以由Occam算法学习的概念类都是PAC可学习的。Board和Pitt（1990年）证明了这个定理的一个部分逆命题：对于闭合于例外列表的概念类，任何可以PAC学习的类都可以通过Occam算法学习。然而，他们的Occam算法输出的假设复杂度依赖于δ，这是一个重要的限制。在本文中，我们证明了他们的部分逆命题也适用于具有独立于δ的复杂度的Occam算法。因此，我们为使用部分逆命题作为其工作基础的各种理论结果和算法设计方法提供了事后的理论依据。

    Blumer et al. (1987, 1989) showed that any concept class that is learnable by Occam algorithms is PAC learnable. Board and Pitt (1990) showed a partial converse of this theorem: for concept classes that are closed under exception lists, any class that is PAC learnable is learnable by an Occam algorithm. However, their Occam algorithm outputs a hypothesis whose complexity is $\delta$-dependent, which is an important limitation. In this paper, we show that their partial converse applies to Occam algorithms with $\delta$-independent complexities as well. Thus, we provide a posteriori justification of various theoretical results and algorithm design methods which use the partial converse as a basis for their work.
    
[^41]: 比较神经网络分类问题的不确定性估计质量

    Comparing the quality of neural network uncertainty estimates for classification problems. (arXiv:2308.05903v1 [cs.LG])

    [http://arxiv.org/abs/2308.05903](http://arxiv.org/abs/2308.05903)

    本研究比较了用于分类问题的神经网络的不确定性估计质量，并通过统计方法和指标对不同方法进行了评估。研究展示了这些估计方法的一致性问题。

    

    传统的深度学习模型是强大的分类器，但许多方法没有提供对其估计结果的不确定性。不确定性量化（UQ）方法对于深度学习模型在决策中的有用性引起了文献中的关注，尤其是对于高风险决策。然而，目前对这些方法的质量评估研究很少。我们使用经验主义置信区间覆盖率和区间宽度的统计方法来评估置信区间的质量，并使用期望校准误差评估分类预测的置信度。我们将这些不同的UQ方法应用于使用马尔科夫链蒙特卡洛（MCMC）和变分推断（VI）拟合的贝叶斯神经网络（BNN），自助式神经网络（NN），深度集成（DE）和蒙特卡洛（MC）dropout的高光谱图像目标检测问题，并展示了不同方法结果的一致性问题。

    Traditional deep learning (DL) models are powerful classifiers, but many approaches do not provide uncertainties for their estimates. Uncertainty quantification (UQ) methods for DL models have received increased attention in the literature due to their usefulness in decision making, particularly for high-consequence decisions. However, there has been little research done on how to evaluate the quality of such methods. We use statistical methods of frequentist interval coverage and interval width to evaluate the quality of credible intervals, and expected calibration error to evaluate classification predicted confidence. These metrics are evaluated on Bayesian neural networks (BNN) fit using Markov Chain Monte Carlo (MCMC) and variational inference (VI), bootstrapped neural networks (NN), Deep Ensembles (DE), and Monte Carlo (MC) dropout. We apply these different UQ for DL methods to a hyperspectral image target detection problem and show the inconsistency of the different methods' resu
    
[^42]: 学习基于团队导航：深度强化学习技术在多智能体路径规划中的综述

    Learning to Team-Based Navigation: A Review of Deep Reinforcement Learning Techniques for Multi-Agent Pathfinding. (arXiv:2308.05893v1 [cs.AI])

    [http://arxiv.org/abs/2308.05893](http://arxiv.org/abs/2308.05893)

    本文综述了在多智能体路径规划中深度强化学习技术的应用。与其他研究不同，我们重点介绍了DRL方法在MAPF中的整合，并解决了MAPF解决方案评估指标缺乏统一性的问题。我们讨论了基于模型的DRL作为未来发展方向，并提供了解决MAPF当前挑战所需的基础理解。

    

    多智能体路径规划(MAPF)是许多大规模机器人应用中的关键领域，通常是多智能体系统的基本步骤。然而，在复杂和拥挤的环境中，MAPF的复杂性不断增加，已有解决方案的有效性严重降低。与其他研究不同，我们在本综述论文中重点介绍了DRL方法在MAPF中的应用。此外，我们旨在填补目前在评估MAPF解决方案方面的缺口，通过解决缺乏统一评估指标的问题并对这些指标进行全面阐释。最后，我们的论文讨论了作为未来方向的基于模型的DRL的潜力，并提供了必要的基础理解以应对MAPF中的当前挑战。

    Multi-agent pathfinding (MAPF) is a critical field in many large-scale robotic applications, often being the fundamental step in multi-agent systems. The increasing complexity of MAPF in complex and crowded environments, however, critically diminishes the effectiveness of existing solutions. In contrast to other studies that have either presented a general overview of the recent advancements in MAPF or extensively reviewed Deep Reinforcement Learning (DRL) within multi-agent system settings independently, our work presented in this review paper focuses on highlighting the integration of DRL-based approaches in MAPF. Moreover, we aim to bridge the current gap in evaluating MAPF solutions by addressing the lack of unified evaluation metrics and providing comprehensive clarification on these metrics. Finally, our paper discusses the potential of model-based DRL as a promising future direction and provides its required foundational understanding to address current challenges in MAPF. Our o
    
[^43]: DF2: 无分布的决策焦点学习

    DF2: Distribution-Free Decision-Focused Learning. (arXiv:2308.05889v1 [cs.LG])

    [http://arxiv.org/abs/2308.05889](http://arxiv.org/abs/2308.05889)

    DF2是一种无分布的决策焦点学习方法，特别解决了模型不匹配错误、样本平均逼近误差和梯度逼近误差三个瓶颈问题。

    

    最近决策焦点学习（DFL）作为一种强大的方法在解决预测-优化问题时，通过将预测模型定制到一个下游优化任务。然而，现有的端到端DFL方法受到三个重要瓶颈的制约：模型不匹配错误、样本平均逼近误差和梯度逼近误差。模型不匹配错误源于模型参数化的预测分布与真实概率分布之间的不协调。样本平均逼近误差是使用有限样本来近似期望优化目标时产生的。梯度逼近误差发生在DFL依靠KKT条件进行精确梯度计算时，而大多数方法在非凸目标中近似梯度进行反向传播。在本文中，我们提出DF2 - 第一个明确设计来解决这三个瓶颈的无分布决策焦点学习方法。

    Decision-focused learning (DFL) has recently emerged as a powerful approach for predict-then-optimize problems by customizing a predictive model to a downstream optimization task. However, existing end-to-end DFL methods are hindered by three significant bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs as DFL relies on the KKT condition for exact gradient computation, while most methods approximate the gradient for backpropagation in non-convex objectives. In this paper, we present DF2 -- the first \textit{distribution-free} decision-focused learning method explicitly designed to address these three bottlenecks. Rather than depending 
    
[^44]: GPLaSDI: 基于高斯过程的可解释潜空间动力学识别方法通过深度自动编码器

    GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics Identification through Deep Autoencoder. (arXiv:2308.05882v1 [cs.CE])

    [http://arxiv.org/abs/2308.05882](http://arxiv.org/abs/2308.05882)

    GPLaSDI是一种基于高斯过程的可解释潜空间动力学识别方法，通过深度自动编码器将完全阶数的PDE解映射到潜空间，并使用插值和解决ODE系统进行快速和准确的ROM预测。

    

    数值求解偏微分方程(PDEs)可能具有挑战性且计算成本高。这导致了减少阶数模型(ROMs)的发展，其精确性高于完全阶数模型(FOMs)但计算速度更快。最近，机器学习的进展实现了非线性投影方法的创建，例如潜空间动力学识别(LaSDI)。LaSDI使用自动编码器将完全阶数的PDE解映射到潜空间，并学习潜空间动力学的ODE系统。通过在减少的潜空间中插值和解决ODE系统，可以通过将预测的潜空间动力学输入解码器来进行快速且准确的ROM预测。在本文中，我们介绍了一种基于高斯过程(GP)的新型LaSDI框架，用于潜空间ODE插值。使用GP带来两个重要优势。首先，它能够量化ROM预测的不确定性。其次，利用这个预测。

    Numerically solving partial differential equations (PDEs) can be challenging and computationally expensive. This has led to the development of reduced-order models (ROMs) that are accurate but faster than full order models (FOMs). Recently, machine learning advances have enabled the creation of non-linear projection methods, such as Latent Space Dynamics Identification (LaSDI). LaSDI maps full-order PDE solutions to a latent space using autoencoders and learns the system of ODEs governing the latent space dynamics. By interpolating and solving the ODE system in the reduced latent space, fast and accurate ROM predictions can be made by feeding the predicted latent space dynamics into the decoder. In this paper, we introduce GPLaSDI, a novel LaSDI-based framework that relies on Gaussian process (GP) for latent space ODE interpolations. Using GPs offers two significant advantages. First, it enables the quantification of uncertainty over the ROM predictions. Second, leveraging this predict
    
[^45]: 采用深度学习模型在野外识别和检测蚜虫集群

    Aphid Cluster Recognition and Detection in the Wild Using Deep Learning Models. (arXiv:2308.05881v1 [cs.CV])

    [http://arxiv.org/abs/2308.05881](http://arxiv.org/abs/2308.05881)

    该论文使用深度学习模型识别和检测野外的蚜虫集群，提出了一种新的方法来估计感染水平，并通过采集大规模数据集进行了验证和比较。

    

    蚜虫侵害对农作物生产、农村社区和全球粮食安全构成重大威胁。虽然化学杀虫剂对于最大化产量至关重要，但在整个田地上施药既不环保也昂贵。因此，准确定位和管理蚜虫对于有针对性地施药至关重要。该论文主要关注使用深度学习模型来检测蚜虫集群。我们提出了一种新颖的方法，通过检测蚜虫集群来估计感染水平。为了促进这项研究，我们从高粱田采集了一组大规模的数据集，手动选择了5,447张包含蚜虫的图像，并在这些图像中注释了每个单独的蚜虫集群。为了方便机器学习模型的使用，我们进一步将这些图像裁剪成小块进行处理，得到一个包含151,380个图像块的标记数据集。然后，我们实现并比较了四种最先进的目标检测算法的性能。

    Aphid infestation poses a significant threat to crop production, rural communities, and global food security. While chemical pest control is crucial for maximizing yields, applying chemicals across entire fields is both environmentally unsustainable and costly. Hence, precise localization and management of aphids are essential for targeted pesticide application. The paper primarily focuses on using deep learning models for detecting aphid clusters. We propose a novel approach for estimating infection levels by detecting aphid clusters. To facilitate this research, we have captured a large-scale dataset from sorghum fields, manually selected 5,447 images containing aphids, and annotated each individual aphid cluster within these images. To facilitate the use of machine learning models, we further process the images by cropping them into patches, resulting in a labeled dataset comprising 151,380 image patches. Then, we implemented and compared the performance of four state-of-the-art obj
    
[^46]: 可组合核心集用于多数据集流的多样性近似

    Composable Core-sets for Diversity Approximation on Multi-Dataset Streams. (arXiv:2308.05878v1 [cs.LG])

    [http://arxiv.org/abs/2308.05878](http://arxiv.org/abs/2308.05878)

    本文介绍了一种用于流式数据的可组合核心集构建算法，其核心子集可以相互合并，用于主动学习环境中。这种核心集可以通过结合CRAIG和加速构建的启发式技术，用于实时训练。

    

    核心集是指最大化某些功能的数据子集，常用于多样性或群组要求。这些子集替代原始数据执行给定任务，如果去除偏见，性能可媲美甚至优于原始数据。可组合核心集是一种具有属性的核心集，其核心子集可以相互合并以获得对原始数据的近似，适用于流式或分布式数据。最近的工作集中在使用核心集训练机器学习模型。以CRAIG为代表的之前的解决方案已被证明能够近似梯度下降并提供缩短训练时间。在本文中，我们介绍了一种用于构建可组合核心集的核心集构建算法，以概括流式数据，用于主动学习环境。如果结合CRAIG和加速构建的启发式技术，可组合核心集可以用于实时训练。

    Core-sets refer to subsets of data that maximize some function that is commonly a diversity or group requirement. These subsets are used in place of the original data to accomplish a given task with comparable or even enhanced performance if biases are removed. Composable core-sets are core-sets with the property that subsets of the core set can be unioned together to obtain an approximation for the original data; lending themselves to be used for streamed or distributed data. Recent work has focused on the use of core-sets for training machine learning models. Preceding solutions such as CRAIG have been proven to approximate gradient descent while providing a reduced training time. In this paper, we introduce a core-set construction algorithm for constructing composable core-sets to summarize streamed data for use in active learning environments. If combined with techniques such as CRAIG and heuristics to enhance construction speed, composable core-sets could be used for real time tra
    
[^47]: 重新审视N-CNN在临床实践中的应用

    Revisiting N-CNN for Clinical Practice. (arXiv:2308.05877v1 [cs.LG])

    [http://arxiv.org/abs/2308.05877](http://arxiv.org/abs/2308.05877)

    本文通过优化N-CNN的超参数，并应用软标签得到了一种新的方法来训练新生儿疼痛评估的面部表情分类模型，结果表明在分类指标和可解释性方面有改善，但没有直接转化为校准性能。

    

    本文通过优化N-CNN的超参数并评估其对分类指标、可解释性和可靠性的影响，讨论了它们在临床实践中的潜在影响。我们选择了不改变原始N-CNN架构的超参数，主要修改了其学习率和训练正则化。通过评估每个超参数对F1得分的改进，选择了最佳超参数来创建调整后的N-CNN。我们还应用了根据新生儿面部编码系统得出的软标签，提出了一种新的方法来训练新生儿疼痛评估的面部表情分类模型。有趣的是，尽管调整后的N-CNN的结果表明在分类指标和可解释性方面有改善，但这些改善并没有直接转化为校准性能。我们相信这样的见解可能具有重要意义。

    This paper revisits the Neonatal Convolutional Neural Network (N-CNN) by optimizing its hyperparameters and evaluating how they affect its classification metrics, explainability and reliability, discussing their potential impact in clinical practice. We have chosen hyperparameters that do not modify the original N-CNN architecture, but mainly modify its learning rate and training regularization. The optimization was done by evaluating the improvement in F1 Score for each hyperparameter individually, and the best hyperparameters were chosen to create a Tuned N-CNN. We also applied soft labels derived from the Neonatal Facial Coding System, proposing a novel approach for training facial expression classification models for neonatal pain assessment. Interestingly, while the Tuned N-CNN results point towards improvements in classification metrics and explainability, these improvements did not directly translate to calibration performance. We believe that such insights might have the potent
    
[^48]: UFed-GAN：一种具有受限计算和无标签数据的安全联邦学习框架

    UFed-GAN: A Secure Federated Learning Framework with Constrained Computation and Unlabeled Data. (arXiv:2308.05870v1 [cs.LG])

    [http://arxiv.org/abs/2308.05870](http://arxiv.org/abs/2308.05870)

    本研究提出了一种名为UFed-GAN的框架，它是一个无监督的联邦生成对抗网络，可以在限制计算资源和无标签数据的情况下进行联邦学习，并保护数据隐私。

    

    为了满足广泛的应用需求和对在基于云的环境中部署低延迟多媒体数据分类和数据隐私的需求，联邦学习（FL）已成为重要的学习范式。针对许多无线通信应用中的限制计算能力和仅有无标签数据的实际案例，本文研究了资源受限和标签缺失环境中的联邦学习范式。具体而言，我们提出了一种新的UFed-GAN框架：无监督的联邦生成对抗网络，可以捕捉用户端数据分布而无需进行本地分类训练。同时，我们还分析了所提出的UFed-GAN的收敛性和隐私性。我们的实验结果表明，UFed-GAN在处理限制的计算资源和无标签数据的同时保护隐私方面具有很大的潜力。

    To satisfy the broad applications and insatiable hunger for deploying low latency multimedia data classification and data privacy in a cloud-based setting, federated learning (FL) has emerged as an important learning paradigm. For the practical cases involving limited computational power and only unlabeled data in many wireless communications applications, this work investigates FL paradigm in a resource-constrained and label-missing environment. Specifically, we propose a novel framework of UFed-GAN: Unsupervised Federated Generative Adversarial Network, which can capture user-side data distribution without local classification training. We also analyze the convergence and privacy of the proposed UFed-GAN. Our experimental results demonstrate the strong potential of UFed-GAN in addressing limited computational resources and unlabeled data while preserving privacy.
    
[^49]: 使用Twitter数据确定飓风等级：一个实验

    Using Twitter Data to Determine Hurricane Category: An Experiment. (arXiv:2308.05866v1 [cs.SI])

    [http://arxiv.org/abs/2308.05866](http://arxiv.org/abs/2308.05866)

    本研究通过研究社交媒体数据和自然灾害之间的关系，找到了Twitter数据与飓风严重程度之间的正相关性，并提出了一种使用相关的Twitter数据来预测特定地区飓风等级的方法。

    

    社交媒体帖子包含大量关于公众对重大事件的观点信息，尤其是自然灾害如飓风。与事件相关的帖子通常是由居住在事件发生地附近的用户在事件发生时发布的。可以使用数据挖掘方法获得社交媒体数据与事件之间的特殊相关性。本文介绍了一项研究工作，旨在找到社交媒体数据与灾害严重程度之间的映射关系。具体而言，我们调查了飓风哈维和欧文期间发布的Twitter数据，并尝试找到特定地区的Twitter数据与该地区的飓风级别之间的关联。我们的实验结果表明它们之间存在正相关性。我们还提出了一种使用相关的Twitter数据来预测特定地区飓风等级的方法。

    Social media posts contain an abundant amount of information about public opinion on major events, especially natural disasters such as hurricanes. Posts related to an event, are usually published by the users who live near the place of the event at the time of the event. Special correlation between the social media data and the events can be obtained using data mining approaches. This paper presents research work to find the mappings between social media data and the severity level of a disaster. Specifically, we have investigated the Twitter data posted during hurricanes Harvey and Irma, and attempted to find the correlation between the Twitter data of a specific area and the hurricane level in that area. Our experimental results indicate a positive correlation between them. We also present a method to predict the hurricane category for a specific area using relevant Twitter data.
    
[^50]: 多模态细胞分割挑战：迈向通用解决方案

    The Multi-modality Cell Segmentation Challenge: Towards Universal Solutions. (arXiv:2308.05864v1 [eess.IV])

    [http://arxiv.org/abs/2308.05864](http://arxiv.org/abs/2308.05864)

    本研究提出了一个多模态细胞分割基准，采用Transformer-based深度学习算法，不仅超越了现有方法，而且可以应用于各种显微成像平台和组织类型的图像，无需手动参数调整，为显微成像中更准确和多功能的细胞分析提供了有希望的途径。

    

    细胞分割是显微镜图像中进行定量单细胞分析的关键步骤。现有的细胞分割方法通常针对特定模态或需要手动干预来指定不同实验设置中的超参数。在这里，我们提出了一个多模态细胞分割基准，包括来自50多个不同生物实验的1500多个标记图像。前几名参与者开发了一种基于Transformer的深度学习算法，不仅超过了现有的方法，而且还可以应用于不同显微成像平台和组织类型的多样显微镜图像，无需手动参数调整。这个基准和改进的算法为显微成像中更准确和多功能的细胞分析提供了有希望的途径。

    Cell segmentation is a critical step for quantitative single-cell analysis in microscopy images. Existing cell segmentation methods are often tailored to specific modalities or require manual interventions to specify hyperparameters in different experimental settings. Here, we present a multi-modality cell segmentation benchmark, comprising over 1500 labeled images derived from more than 50 diverse biological experiments. The top participants developed a Transformer-based deep-learning algorithm that not only exceeds existing methods, but can also be applied to diverse microscopy images across imaging platforms and tissue types without manual parameter adjustments. This benchmark and the improved algorithm offer promising avenues for more accurate and versatile cell analysis in microscopy imaging.
    
[^51]: 在条件独立图上的知识传播

    Knowledge Propagation over Conditional Independence Graphs. (arXiv:2308.05857v1 [cs.AI])

    [http://arxiv.org/abs/2308.05857](http://arxiv.org/abs/2308.05857)

    这项工作提出了在条件独立图上进行知识传播的算法，并通过在Cora和PubMed数据集上的实验证明了其优于现有方法的效果。

    

    条件独立（CI）图是一种特殊类型的概率图模型（PGM），其中特征连接使用无向图建模，边权重表示特征之间的部分相关性强度。由于CI图捕捉了特征之间的直接依赖关系，它们在研究社区中引起了越来越多的关注，特别是在发现领域拓扑方面。在这项工作中，我们提出了在CI图上执行知识传播的算法。我们的实验证明，我们的技术在公开的Cora和PubMed数据集上超过了最先进的方法。

    Conditional Independence (CI) graph is a special type of a Probabilistic Graphical Model (PGM) where the feature connections are modeled using an undirected graph and the edge weights show the partial correlation strength between the features. Since the CI graphs capture direct dependence between features, they have been garnering increasing interest within the research community for gaining insights into the systems from various domains, in particular discovering the domain topology. In this work, we propose algorithms for performing knowledge propagation over the CI graphs. Our experiments demonstrate that our techniques improve upon the state-of-the-art on the publicly available Cora and PubMed datasets.
    
[^52]: GaborPINN: 使用乘法滤波网络的高效物理具体神经网络

    GaborPINN: Efficient physics informed neural networks using multiplicative filtered networks. (arXiv:2308.05843v1 [physics.geo-ph])

    [http://arxiv.org/abs/2308.05843](http://arxiv.org/abs/2308.05843)

    通过使用乘法滤波网络和嵌入波场的已知特性，GaborPINN方法实现了比传统PINN方法高两个数量级的收敛速度提升。

    

    通过求解 Helmholtz 方程计算地震波场对许多实际应用至关重要，如全波形反演。物理信息神经网络（PINN）用神经网络（NN）表示波场解的函数形式，但其收敛速度慢。为了解决这个问题，我们提出了一种改进的 PINN 方法，使用乘法滤波网络，在训练中嵌入了一些波场的已知特性，例如频率，以实现更快的收敛。具体而言，我们使用 Gabor 基函数，因为其已被证明能够准确表示波场，并将其实现称为 GaborPINN。同时，我们将波场频率的先验信息纳入方法的设计中，以减轻 GaborPINN 表示的波场的不连续性的影响。与传统 PINN 方法相比，所提出的方法实现了收敛速度高达两个数量级的提升。

    The computation of the seismic wavefield by solving the Helmholtz equation is crucial to many practical applications, e.g., full waveform inversion. Physics-informed neural networks (PINNs) provide functional wavefield solutions represented by neural networks (NNs), but their convergence is slow. To address this problem, we propose a modified PINN using multiplicative filtered networks, which embeds some of the known characteristics of the wavefield in training, e.g., frequency, to achieve much faster convergence. Specifically, we use the Gabor basis function due to its proven ability to represent wavefields accurately and refer to the implementation as GaborPINN. Meanwhile, we incorporate prior information on the frequency of the wavefield into the design of the method to mitigate the influence of the discontinuity of the represented wavefield by GaborPINN. The proposed method achieves up to a two-magnitude increase in the speed of convergence as compared with conventional PINNs.
    
[^53]: FLShield：一种基于验证的联邦学习框架，用于防御投毒攻击

    FLShield: A Validation Based Federated Learning Framework to Defend Against Poisoning Attacks. (arXiv:2308.05832v1 [cs.CR])

    [http://arxiv.org/abs/2308.05832](http://arxiv.org/abs/2308.05832)

    本文提出了一种名为FLShield的新型联邦学习框架，利用FL参与者的良性数据对本地模型进行验证，以防御恶意参与者的投毒攻击，并确保FL系统的安全性和效用。

    

    联邦学习（FL）正在改变我们从数据中学习的方式。随着它的日益流行，它现在被应用于许多安全关键的领域，如自动驾驶和医疗保健。由于成千上万的参与者可以在这种协作环境中贡献数据，确保这种系统的安全性和可靠性变得具有挑战性。这突显了设计安全和鲁棒的FL系统的需求，以抵御恶意参与者的行为，同时确保高效的效用、本地数据的隐私和效率。在本文中，我们提出了一种新颖的FL框架，称为FLShield，它利用FL参与者的良性数据在将其考虑进全局模型生成之前对本地模型进行验证。这与现有的依赖于服务器对清洁数据集的访问的防御方法形成鲜明对比，这种假设在现实场景中经常是不切实际的，并且与FL的基本原理相冲突。我们进行了大量实验证明了我们的FLShield的有效性。

    Federated learning (FL) is revolutionizing how we learn from data. With its growing popularity, it is now being used in many safety-critical domains such as autonomous vehicles and healthcare. Since thousands of participants can contribute in this collaborative setting, it is, however, challenging to ensure security and reliability of such systems. This highlights the need to design FL systems that are secure and robust against malicious participants' actions while also ensuring high utility, privacy of local data, and efficiency. In this paper, we propose a novel FL framework dubbed as FLShield that utilizes benign data from FL participants to validate the local models before taking them into account for generating the global model. This is in stark contrast with existing defenses relying on server's access to clean datasets -- an assumption often impractical in real-life scenarios and conflicting with the fundamentals of FL. We conduct extensive experiments to evaluate our FLShield f
    
[^54]: 使用脑电图的可解释和基于注意力机制的凝视估计方法

    An Interpretable and Attention-based Method for Gaze Estimation Using Electroencephalography. (arXiv:2308.05768v1 [eess.SP])

    [http://arxiv.org/abs/2308.05768](http://arxiv.org/abs/2308.05768)

    本文提出了一种基于注意力机制的深度学习框架，用于从脑电图数据中解读凝视信息，其在准确性和可解释性方面优于当前方法。

    

    眼动可以揭示人类心理过程、身体健康和行为的宝贵洞察力。最近，一些同时记录脑电活动和眼动的数据集可用，这引发了基于脑活动预测凝视方向的各种方法的发展。然而，大多数这些方法缺乏可解释性，从而限制了它们的技术可接受性。在本文中，我们利用同时测量的脑电图（EEG）和眼动跟踪的大型数据集，提出了一种从EEG数据估计凝视的可解释模型。具体而言，我们提出了一种基于注意力机制的深度学习框架来分析EEG信号，该框架允许网络将注意力集中在信号中最相关的信息上，并且忽略有问题的通道。此外，我们对所提出的框架进行了全面的评估，并展示了它在准确性和鲁棒性方面优于当前方法的优势。

    Eye movements can reveal valuable insights into various aspects of human mental processes, physical well-being, and actions. Recently, several datasets have been made available that simultaneously record EEG activity and eye movements. This has triggered the development of various methods to predict gaze direction based on brain activity. However, most of these methods lack interpretability, which limits their technology acceptance. In this paper, we leverage a large data set of simultaneously measured Electroencephalography (EEG) and Eye tracking, proposing an interpretable model for gaze estimation from EEG data. More specifically, we present a novel attention-based deep learning framework for EEG signal analysis, which allows the network to focus on the most relevant information in the signal and discard problematic channels. Additionally, we provide a comprehensive evaluation of the presented framework, demonstrating its superiority over current methods in terms of accuracy and rob
    
[^55]: 基于脑电的情绪风格转换网络用于跨数据集情绪识别

    EEG-based Emotion Style Transfer Network for Cross-dataset Emotion Recognition. (arXiv:2308.05767v1 [eess.SP])

    [http://arxiv.org/abs/2308.05767](http://arxiv.org/abs/2308.05767)

    本文提出了一种基于脑电的情绪风格转换网络 (E2STN)，用于解决跨数据集脑电情绪识别中源域和目标域样本样式不匹配的问题。这种转换网络能够生成风格化的情绪脑电表示，有助于进行跨数据集的判别预测。

    

    作为实现大脑-计算机界面(BCIs)的关键，脑电情绪识别已经被许多研究人员广泛研究。先前的方法在同一受试者脑电情绪识别方面表现良好。然而，由于巨大的跨领域差异导致的源域(训练数据)和目标域(测试数据)脑电样本之间的样式不匹配仍然是脑电情绪识别的关键问题。为了解决跨数据集脑电情绪识别的问题，本文提出了一种基于脑电的情绪风格转换网络（E2STN），用于获得包含源域内容信息和目标域风格信息的脑电表示，被称为风格化的情绪脑电表示。这些表示对于跨数据集的判别预测是有帮助的。具体而言，E2STN由三个模块组成，即转换模块，转换评估模块和判别预测模块。转换模块对源域和目标域的领域特定信息进行编码。

    As the key to realizing aBCIs, EEG emotion recognition has been widely studied by many researchers. Previous methods have performed well for intra-subject EEG emotion recognition. However, the style mismatch between source domain (training data) and target domain (test data) EEG samples caused by huge inter-domain differences is still a critical problem for EEG emotion recognition. To solve the problem of cross-dataset EEG emotion recognition, in this paper, we propose an EEG-based Emotion Style Transfer Network (E2STN) to obtain EEG representations that contain the content information of source domain and the style information of target domain, which is called stylized emotional EEG representations. The representations are helpful for cross-dataset discriminative prediction. Concretely, E2STN consists of three modules, i.e., transfer module, transfer evaluation module, and discriminative prediction module. The transfer module encodes the domain-specific information of source and targe
    
[^56]: 发挥特征选择和随机森林分类器的作用，提高心力衰竭患者生存预测能力

    Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients. (arXiv:2308.05765v1 [cs.LG])

    [http://arxiv.org/abs/2308.05765](http://arxiv.org/abs/2308.05765)

    通过利用数据预处理技术和Extra-Tree特征选择方法与Random Forest分类器相结合，本研究提高了心力衰竭患者生存预测能力，并取得了98.33%的准确率

    

    心力衰竭是一种危及生命的疾病，全球数百万人受到影响。准确预测患者的生存能力可以帮助及早干预，并改善患者预后。本研究探讨利用数据预处理技术和Extra-Tree (ET) 特征选择方法与Random Forest (RF) 分类器相结合，以提高心力衰竭患者的生存预测能力的潜力。通过发挥ET特征选择的优势，我们的目标是识别与心力衰竭生存相关的最重要的预测因子。利用公开的UCL心力衰竭 (HF) 生存数据集，我们采用ET特征选择算法来识别最具信息量的特征。然后，将这些特征用作RF的网格搜索的输入。最后，使用不同的指标对调优后的RF模型进行训练和评估。所采用的方法取得了98.33%的准确率，是目前的最高水平。

    Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
    
[^57]: 通过从心脏MRI中的知识转移解锁心电图的诊断潜力

    Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI. (arXiv:2308.05764v1 [eess.SP])

    [http://arxiv.org/abs/2308.05764](http://arxiv.org/abs/2308.05764)

    该论文提出了一种通过从心脏MRI中的知识转移解锁心电图的诊断潜力的方法。通过将CMR图像中的领域特定信息转移到ECG嵌入中，该方法实现了仅根据ECG数据进行全面的心脏筛查，并能预测心血管疾病的个体风险和确定心脏表型。

    

    心电图 (ECG) 是一种广泛可用的诊断工具，可以快速和经济高效地评估心血管健康状况。然而，在心血管疾病的诊断中，通常更喜欢使用昂贵的心脏磁共振 (CMR) 成像进行更详细的检查。虽然 CMR 成像可以提供详细的心脏解剖可视化，但由于长时间扫描和高昂的费用，它并不广泛可用。为了解决这个问题，我们提出了一种第一种自监督对比方法，将CMR图像中的领域特定信息转移到ECG嵌入中。我们的方法将多模态对比学习与屏蔽数据建模相结合，实现了仅根据ECG数据进行全面的心脏筛查。在使用来自40044名UK Biobank受试者的数据进行的广泛实验证明了我们方法的实用性和可推广性。我们预测了各种心血管疾病的个体风险，并仅根据ECG数据确定了不同的心脏表型。

    The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from E
    
[^58]: 一种利用从光电流血容积波形和活动信号中提取的少量特征的基于机器学习的睡眠-清醒分类模型

    A machine-learning sleep-wake classification model using a reduced number of features derived from photoplethysmography and activity signals. (arXiv:2308.05759v1 [eess.SP])

    [http://arxiv.org/abs/2308.05759](http://arxiv.org/abs/2308.05759)

    这项研究提出了一种基于机器学习的睡眠-清醒分类模型，利用光电流血容积波形和活动信号提取的特征，可以评估睡眠质量，识别睡眠问题和改善整体健康。

    

    睡眠对我们的整体健康和幸福感至关重要。它在调节我们的心理和身体健康方面起着至关重要的作用，对我们的情绪、记忆和认知功能以及身体的韧性和免疫系统都有影响。睡眠阶段的分类是评估睡眠质量的必要步骤，提供了估计睡眠质量和我们的身体在这个重要的休息时期内功能如何的指标。光电流血容积波形（PPG）已被证明是有效的睡眠阶段推断信号，意味着它可以单独使用或与其他信号结合使用来确定睡眠阶段。这些信息对于识别潜在的睡眠问题和制定改善睡眠质量和整体健康策略非常有价值。在这项工作中，我们提出了一种基于eXtreme Gradient Boosting（XGBoost）算法和从PPG信号和活动计数中提取的特征的机器学习睡眠-清醒分类模型。

    Sleep is a crucial aspect of our overall health and well-being. It plays a vital role in regulating our mental and physical health, impacting our mood, memory, and cognitive function to our physical resilience and immune system. The classification of sleep stages is a mandatory step to assess sleep quality, providing the metrics to estimate the quality of sleep and how well our body is functioning during this essential period of rest. Photoplethysmography (PPG) has been demonstrated to be an effective signal for sleep stage inference, meaning it can be used on its own or in a combination with others signals to determine sleep stage. This information is valuable in identifying potential sleep issues and developing strategies to improve sleep quality and overall health. In this work, we present a machine learning sleep-wake classification model based on the eXtreme Gradient Boosting (XGBoost) algorithm and features extracted from PPG signal and activity counts. The performance of our met
    
[^59]: OrcoDCS:一种物联网边缘编排的在线深度压缩感知框架

    OrcoDCS: An IoT-Edge Orchestrated Online Deep Compressed Sensing Framework. (arXiv:2308.05757v1 [eess.SP])

    [http://arxiv.org/abs/2308.05757](http://arxiv.org/abs/2308.05757)

    OrcoDCS是一种物联网边缘编排的在线深度压缩感知框架，通过特殊设计的非对称自编码器实现高度灵活性和适应性，可处理不同的物联网设备组和它们的感知任务，并在后续应用中提供高性能。

    

    通过使用特殊设计的非对称自编码器，我们提出了一种物联网边缘编排的在线深度压缩感知框架OrcoDCS，该框架具有高度的灵活性和适应性，可以处理不同的物联网设备组和它们的感知任务，并能在后续应用中提供高性能。

    Compressed data aggregation (CDA) over wireless sensor networks (WSNs) is task-specific and subject to environmental changes. However, the existing compressed data aggregation (CDA) frameworks (e.g., compressed sensing-based data aggregation, deep learning(DL)-based data aggregation) do not possess the flexibility and adaptivity required to handle distinct sensing tasks and environmental changes. Additionally, they do not consider the performance of follow-up IoT data-driven deep learning (DL)-based applications. To address these shortcomings, we propose OrcoDCS, an IoT-Edge orchestrated online deep compressed sensing framework that offers high flexibility and adaptability to distinct IoT device groups and their sensing tasks, as well as high performance for follow-up applications. The novelty of our work is the design and deployment of IoT-Edge orchestrated online training framework over WSNs by leveraging an specially-designed asymmetric autoencoder, which can largely reduce the enco
    
[^60]: WeldMon: 一种成本效益高的超声波焊接机状态监测系统

    WeldMon: A Cost-effective Ultrasonic Welding Machine Condition Monitoring System. (arXiv:2308.05756v1 [eess.SP])

    [http://arxiv.org/abs/2308.05756](http://arxiv.org/abs/2308.05756)

    WeldMon是一种成本效益高的超声波焊接机状态监测系统，利用自定义数据采集系统和实时分析流程实现高质量的焊接，通过结合自动生成的特征和手工制作的特征的分类算法，显著提高了状态分类准确性。数据增强方法还减轻了概念漂移问题，提升了工具状态分类准确性。

    

    超声波焊接机在锂电池行业起着关键作用，用于将电池与导体进行连接。确保高质量的焊接至关重要，因此工具状态监测系统对于早期质量控制是必不可少的。然而，现有的监测方法在成本、停机时间和适应性方面面临挑战。本文提出了一种成本效益高的超声波焊接机状态监测系统WeldMon，该系统利用自定义数据采集系统和实时分析设计的数据分析流程。我们的分类算法结合了自动生成的特征和手工制作的特征，在状态分类任务中实现了优越的交叉验证准确性(平均达到95.8%的测试任务)相比于现有技术方法(92.5%)。我们的数据增强方法减轻了概念漂移问题，将工具状态分类准确性提高了8.3%。所有算法都在本地运行，仅需要385毫秒。

    Ultrasonic welding machines play a critical role in the lithium battery industry, facilitating the bonding of batteries with conductors. Ensuring high-quality welding is vital, making tool condition monitoring systems essential for early-stage quality control. However, existing monitoring methods face challenges in cost, downtime, and adaptability. In this paper, we present WeldMon, an affordable ultrasonic welding machine condition monitoring system that utilizes a custom data acquisition system and a data analysis pipeline designed for real-time analysis. Our classification algorithm combines auto-generated features and hand-crafted features, achieving superior cross-validation accuracy (95.8% on average over all testing tasks) compared to the state-of-the-art method (92.5%) in condition classification tasks. Our data augmentation approach alleviates the concept drift problem, enhancing tool condition classification accuracy by 8.3%. All algorithms run locally, requiring only 385 mil
    
[^61]: 将危险的挥发物化合物转化为燃料的催化蒸汽重整：一种进化机器学习方法

    Turning hazardous volatile matter compounds into fuel by catalytic steam reforming: An evolutionary machine learning approach. (arXiv:2308.05750v1 [cs.LG])

    [http://arxiv.org/abs/2308.05750](http://arxiv.org/abs/2308.05750)

    本论文利用进化的机器学习方法，首次开发了一个基于机器学习的研究框架，用于对危险的挥发物化合物的催化蒸汽重整进行建模、理解和优化。通过甲苯催化蒸汽重整作为案例研究，展示了利用化学/纹理分析来获取机器学习模型的输入特征。六个机器学习模型被用来对该过程进行深入分析和建模。

    

    化学和生物质处理系统每天都将挥发性物质化合物排放到环境中。催化重整可以将这些化合物转化为有价值的燃料，但开发稳定和高效的催化剂具有挑战性。机器学习可以处理大数据中的复杂关系并优化反应条件，因此是解决这些问题的有效解决方案。本研究是第一个基于机器学习的研究框架，用于对挥发性物质化合物的催化蒸汽重整进行建模、理解和优化。以甲苯催化蒸汽重整为案例研究，展示了化学/纹理分析（例如X射线衍射分析）如何用于获取机器学习模型的输入特征。利用文献编制了一个涵盖各种催化剂特性和反应条件的数据库。通过六个机器学习模型对该过程进行了深入分析、机理讨论和建模，最终得出相关结果。

    Chemical and biomass processing systems release volatile matter compounds into the environment daily. Catalytic reforming can convert these compounds into valuable fuels, but developing stable and efficient catalysts is challenging. Machine learning can handle complex relationships in big data and optimize reaction conditions, making it an effective solution for addressing the mentioned issues. This study is the first to develop a machine-learning-based research framework for modeling, understanding, and optimizing the catalytic steam reforming of volatile matter compounds. Toluene catalytic steam reforming is used as a case study to show how chemical/textural analyses (e.g., X-ray diffraction analysis) can be used to obtain input features for machine learning models. Literature is used to compile a database covering a variety of catalyst characteristics and reaction conditions. The process is thoroughly analyzed, mechanistically discussed, modeled by six machine learning models, and o
    
[^62]: 通过时间序列-Transformer引入混合建模：关于串行与并行方法在批结晶中的比较研究

    Introducing Hybrid Modeling with Time-series-Transformers: A Comparative Study of Series and Parallel Approach in Batch Crystallization. (arXiv:2308.05749v1 [physics.chem-ph])

    [http://arxiv.org/abs/2308.05749](http://arxiv.org/abs/2308.05749)

    本研究引入混合建模的方法，将基于物理原理的动力学与机器学习模型相结合，以解决直接部署黑箱模型的安全和操作问题。相比简单的深度神经网络模型，最近的时间序列Transformer模型利用注意力机制和位置编码，能更好地预测长期时间序列，并利用过程动力学轨迹的上下文信息。

    

    大多数现有的数字孪生依赖于数据驱动的黑箱模型，主要使用深度神经网络递归和卷积神经网络（DNN，RNN和CNN）来捕捉化学系统的动态。然而，考虑到安全和操作问题，这些模型尚未被实际部署。为了解决这个难题，将基于第一原理的物理动力学与机器学习（ML）模型相结合的混合模型因其被认为是一种“两全其美”的方法而越来越受欢迎。然而，现有简单的DNN模型在长期时间序列预测和利用过程动力学轨迹的上下文信息方面并不擅长。最近，基于注意力机制和位置编码的时间序列Transformer（TST）在捕捉过程状态的长期和短期变化方面表现出高预测性能。

    Most existing digital twins rely on data-driven black-box models, predominantly using deep neural recurrent, and convolutional neural networks (DNNs, RNNs, and CNNs) to capture the dynamics of chemical systems. However, these models have not seen the light of day, given the hesitance of directly deploying a black-box tool in practice due to safety and operational issues. To tackle this conundrum, hybrid models combining first-principles physics-based dynamics with machine learning (ML) models have increased in popularity as they are considered a 'best of both worlds' approach. That said, existing simple DNN models are not adept at long-term time-series predictions and utilizing contextual information on the trajectory of the process dynamics. Recently, attention-based time-series transformers (TSTs) that leverage multi-headed attention mechanism and positional encoding to capture long-term and short-term changes in process states have shown high predictive performance. Thus, a first-of
    
[^63]: LLM变成DBA

    LLM As DBA. (arXiv:2308.05481v1 [cs.DB])

    [http://arxiv.org/abs/2308.05481](http://arxiv.org/abs/2308.05481)

    LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。

    

    数据库管理员（DBA）在管理、维护和优化数据库系统以确保数据可用性、性能和可靠性方面起着至关重要的作用。然而，对于DBA来说，管理大量数据库实例（例如，云数据库上的数百万个实例）是困难和繁琐的。最近，大型语言模型（LLMs）已经显示出了理解有价值文件并生成合理答案的巨大潜力。因此，我们提出了D-Bot，一种基于LLM的数据库管理员，它可以持续从文本来源中获取数据库维护经验，并为目标数据库提供合理、有理、及时的诊断和优化建议。本文介绍了一个革命性的以LLM为中心的数据库维护框架，包括（i）从文档和工具中检测数据库维护知识，（ii）根本原因分析的思维树，和（iii）多个LLM之间的协作诊断。我们进行了初步实验。

    Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experiment
    
[^64]: 探索机器学习和基于Transformer的方法用于欺诈性文本分类：一项比较分析

    Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v1 [cs.CL])

    [http://arxiv.org/abs/2308.05476](http://arxiv.org/abs/2308.05476)

    本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。

    

    欺诈性文本分类是自然语言处理中的一项关键任务，旨在识别欺诈或欺骗性内容。本研究对机器学习和基于Transformer的方法进行了比较分析，用于欺诈性文本分类。我们研究了传统机器学习算法和最先进的Transformer模型（如BERT，XLNET，DistilBERT和RoBERTa）在检测欺诈性文本方面的有效性。我们使用一个带标签的数据集，其中包含欺诈性和非欺诈性文本，用于训练和评估目的。通过广泛的实验，我们比较了不同方法的性能指标，包括准确率，精确率，召回率和F1得分。本研究的结果揭示了机器学习和基于Transformer的方法在欺诈性文本分类中的优势和局限性，使研究人员和实践者能够在处理欺诈内容时做出明智的决策。

    Deceptive text classification is a critical task in natural language processing that aims to identify deceptive or fraudulent content. This study presents a comparative analysis of machine learning and transformer-based approaches for deceptive text classification. We investigate the effectiveness of traditional machine learning algorithms and state-of-the-art transformer models, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive text. A labeled dataset consisting of deceptive and non-deceptive texts is used for training and evaluation purposes. Through extensive experimentation, we compare the performance metrics, including accuracy, precision, recall, and F1 score, of the different approaches. The results of this study shed light on the strengths and limitations of machine learning and transformer-based methods for deceptive text classification, enabling researchers and practitioners to make informed decisions when dealing with deceptive content
    
[^65]: 图聚类的同类性增强结构学习

    Homophily-enhanced Structure Learning for Graph Clustering. (arXiv:2308.05309v1 [cs.LG])

    [http://arxiv.org/abs/2308.05309](http://arxiv.org/abs/2308.05309)

    提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。

    

    图聚类是图分析中的一个基本任务，在利用图神经网络（GNNs）方面的最新进展已经取得了令人印象深刻的成果。尽管现有的基于GNN的图聚类方法取得了成功，但它们往往忽视了图结构的质量，这是由于现实世界图的稀疏性和多样性所固有的，从而导致了次优的性能。图结构学习可以通过添加缺失的连接和删除错误的连接来优化输入图。然而，以往的图结构学习工作主要集中在有监督的设置上，并且由于缺乏真实标签，不能直接应用于我们的特定聚类任务。为了弥补这个差距，我们提出了一种新颖的方法，称为同类性增强结构学习图聚类（HoLe）。我们的动机源于观察到，微妙地增强图结构中的同类性程度可以显著提升GNNs的性能。

    Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \textbf{ho}mophily-enhanced structure \textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve G
    
[^66]: 深度学习在不同数据类型隐写分析中的应用：综述

    Deep Learning for Diverse Data Types Steganalysis: A Review. (arXiv:2308.04522v1 [cs.CR])

    [http://arxiv.org/abs/2308.04522](http://arxiv.org/abs/2308.04522)

    本综述论文详细综述了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的最新研究进展。

    

    隐写术和隐写分析是信息安全领域的两个相关方面。隐写术旨在隐藏通信，而隐写分析则旨在找到这些隐藏信息，甚至尝试恢复其所包含的数据。隐写术和隐写分析引起了广泛的关注，特别受到执法部门的关注。隐写术常被网络犯罪分子甚至恐怖分子用来避免在拥有证据时被捕，即使加密也一样，因为在许多国家禁止或限制使用密码学。因此，了解揭示隐藏信息的尖端技术对揭露非法行为至关重要。在过去几年中，文献中引入了许多强大可靠的隐写术和隐写分析技术。本综述论文提供了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的全面概述。

    Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper cove
    
[^67]: SLEM：机器学习用于路径建模和因果推断的超级学习者方程模型

    SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])

    [http://arxiv.org/abs/2308.04365](http://arxiv.org/abs/2308.04365)

    SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。

    

    因果推断是科学的关键目标，使研究人员能够通过观察数据得出关于对假定干预的预测的有意义的结论。路径模型、结构方程模型(SEMs)以及更一般的有向无环图(DAGs)能够明确地指定关于现象背后的因果结构的假设。与DAGs不同，SEMs假设线性关系，这可能导致函数错误规范，从而阻碍研究人员进行可靠的效果大小估计。相反，我们提出了超级学习者方程模型（SLEM），一种集成了机器学习超级学习者集成的路径建模技术。我们通过实证研究，证明了SLEM能够提供一致且无偏的因果效应估计，在与SEMs进行线性模型比较时表现出竞争力，并且在处理非线性关系时优于SEMs。

    Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
    
[^68]: Spellburst：基于节点的自然语言提示的探索性创意编码界面

    Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts. (arXiv:2308.03921v1 [cs.SE] CROSS LISTED)

    [http://arxiv.org/abs/2308.03921](http://arxiv.org/abs/2308.03921)

    Spellburst是一个基于节点的界面，利用大型语言模型（LLM）提供创意编码环境，艺术家可以通过分支和合并操作探索生成艺术的变化，通过基于表达式的提示交互进行语义编程，并且能够在语义和句法探索之间无缝切换。

    

    创意编码任务通常是探索性的。在制作数字艺术品时，艺术家通常从高级语义构造开始，如“玻璃窗滤镜”，并通过改变代码参数（如形状、颜色、线条和不透明度）来实现它以产生视觉吸引力的结果。根据与艺术家的访谈，将语义构造转化为程序语法可能是费力的，目前的编程工具不利于快速的创造性探索。为了解决这些挑战，我们引入了Spellburst，一个以大型语言模型（LLM）为动力的创意编码环境。Spellburst提供（1）基于节点的界面，允许艺术家创建生成艺术并通过分支和合并操作进行变化探索，（2）基于表达式的提示交互，用于进行语义编程交互，以及（3）基于提示驱动的界面和直接代码编辑，以在语义和句法探索之间无缝切换。

    Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a "stained glass filter" and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don't lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation
    
[^69]: 用于在现代星空调查数据中搜索L＆T类棕矮星的机器学习方法

    Machine learning methods for the search for L&T brown dwarfs in the data of modern sky surveys. (arXiv:2308.03045v2 [astro-ph.SR] UPDATED)

    [http://arxiv.org/abs/2308.03045](http://arxiv.org/abs/2308.03045)

    在这项研究中，我们使用机器学习方法对PanStarrs DR1、2MASS和WISE数据进行分析，以区分L类和T类棕矮星和其他光谱和亮度类别的天体。这有助于建立一个均匀且完整的棕矮星样本，为研究提供可靠的数据集。

    

    根据各种估计，棕矮星（BD）应占银河系中所有天体的25％。然而，很少有棕矮星被发现并得到深入研究，无论是个体还是整体。这些研究需要均匀和完整的棕矮星样本。由于其弱信号，棕矮星的光谱研究相当耗费精力。因此，通过光谱观测确认的大量可靠的棕矮星样本似乎在目前是不可企及的。已经尝试了许多方法来利用其颜色作为决策规则应用于大量的勘测数据来搜索和创建一组棕矮星。在这项工作中，我们使用随机森林分类器、XGBoost、支持向量机分类器和TabNet等机器学习方法在PanStarrs DR1、2MASS和WISE数据上区分L类和T类棕矮星与其他光谱和亮度类别的天体。讨论了模型的解释。我们还将我们的模型与其他方法进行了比较。

    According to various estimates, brown dwarfs (BD) should account for up to 25 percent of all objects in the Galaxy. However, few of them are discovered and well-studied, both individually and as a population. Homogeneous and complete samples of brown dwarfs are needed for these kinds of studies. Due to their weakness, spectral studies of brown dwarfs are rather laborious. For this reason, creating a significant reliable sample of brown dwarfs, confirmed by spectroscopic observations, seems unattainable at the moment. Numerous attempts have been made to search for and create a set of brown dwarfs using their colours as a decision rule applied to a vast amount of survey data. In this work, we use machine learning methods such as Random Forest Classifier, XGBoost, SVM Classifier and TabNet on PanStarrs DR1, 2MASS and WISE data to distinguish L and T brown dwarfs from objects of other spectral and luminosity classes. The explanation of the models is discussed. We also compare our models wi
    
[^70]: 利用修剪元素的对抗抹除：迈向更好的图彩票

    Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket. (arXiv:2308.02916v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.02916](http://arxiv.org/abs/2308.02916)

    本文介绍了一种利用对抗抹除的方法来增强图彩票的性能。通过重新考虑修剪信息中的有价值的信息，我们提出了ACE-GLT，这是一种更强大的图彩票方法。

    

    图彩票（GLT）是核心子图和稀疏子网络的组合，旨在减轻大型输入图上深度图神经网络（GNN）的计算成本，同时保持原始性能。然而，现有研究中获胜的GLT是通过应用迭代幅值修剪（IMP）而得到的，而无需重新评估和重新考虑修剪信息，这忽视了在图/模型结构修剪过程中边缘/权重重要性的动态变化，从而限制了获胜的彩票的吸引力。在本文中，我们提出了一个猜想，即修剪图连接和模型参数中存在被忽视的有价值信息，这些信息可以重新分组到GLT中以增强最终性能。具体而言，我们提出了一个对抗性补充抹除（ACE）框架，以从修剪组件中探索有价值的信息，从而开发出更强大的GLT，称为ACE-GLT。

    Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main
    
[^71]: 跨平台仇恨言论检测中的因果引导解缠问题

    Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v1 [cs.CL])

    [http://arxiv.org/abs/2308.02080](http://arxiv.org/abs/2308.02080)

    本研究提出了一种跨平台仇恨言论检测模型，通过解缠输入表示为不变特征和平台相关特征，实现了对多个未见平台的良好泛化能力。

    

    尽管社交媒体平台在促进公开对话方面具有价值，但他们经常被利用来传播有害内容。目前用于检测这种有害内容的深度学习和自然语言处理模型过度依赖于领域特定术语，影响到了它们适应泛化仇恨言论检测的能力。这是因为它们倾向于过于狭隘地关注特定的语言信号或某些词语类别的使用。当平台缺乏高质量的标记数据用于训练时，另一个重要的挑战出现了，需要跨平台模型来适应不同的分布转化。我们的研究引入了一个跨平台仇恨言论检测模型，能够在一个平台的数据上训练并推广到多个未见平台。为了实现对不同平台的良好泛化性能，一种方法是将输入表示解缠为不变特征和平台相关特征。我们还认为学习因果关系是提供更好解缠和泛化性能的关键。

    Social media platforms, despite their value in promoting open discourse, are often exploited to spread harmful content. Current deep learning and natural language processing models used for detecting this harmful content overly rely on domain-specific terms affecting their capabilities to adapt to generalizable hate speech detection. This is because they tend to focus too narrowly on particular linguistic signals or the use of certain categories of words. Another significant challenge arises when platforms lack high-quality annotated data for training, leading to a need for cross-platform models that can adapt to different distribution shifts. Our research introduces a cross-platform hate speech detection model capable of being trained on one platform's data and generalizing to multiple unseen platforms. To achieve good generalizability across platforms, one way is to disentangle the input representations into invariant and platform-dependent features. We also argue that learning causa
    
[^72]: 推荐系统中的流行偏差综述

    A Survey on Popularity Bias in Recommender Systems. (arXiv:2308.01118v1 [cs.IR])

    [http://arxiv.org/abs/2308.01118](http://arxiv.org/abs/2308.01118)

    这篇综述论文讨论了推荐系统中的流行偏差问题，并回顾了现有的方法来检测、量化和减少流行偏差。它同时提供了计算度量的概述和主要技术方法的回顾。

    

    推荐系统以个性化的方式帮助人们找到相关内容。这些系统的一个主要承诺是能够增加目录中较少知名的物品的可见性。然而，现有研究表明，在许多情况下，现今的推荐算法反而表现出流行偏差，即它们在推荐中经常关注相当流行的物品。这种偏差不仅可能导致短期内对消费者和提供者的推荐价值有限，而且还可能引起不希望的强化效应。在本文中，我们讨论了流行偏差的潜在原因，并回顾了现有的检测、量化和减少推荐系统中流行偏差的方法。因此，我们的综述既包括了文献中使用的计算度量的概述，也包括了减少偏差的主要技术方法的回顾。我们还对这些方法进行了批判性讨论。

    Recommender systems help people find relevant content in a personalized way. One main promise of such systems is that they are able to increase the visibility of items in the long tail, i.e., the lesser-known items in a catalogue. Existing research, however, suggests that in many situations today's recommendation algorithms instead exhibit a popularity bias, meaning that they often focus on rather popular items in their recommendations. Such a bias may not only lead to limited value of the recommendations for consumers and providers in the short run, but it may also cause undesired reinforcement effects over time. In this paper, we discuss the potential reasons for popularity bias and we review existing approaches to detect, quantify and mitigate popularity bias in recommender systems. Our survey therefore includes both an overview of the computational metrics used in the literature as well as a review of the main technical approaches to reduce the bias. We furthermore critically discu
    
[^73]: 利用运动增量进行时空分支的运动预测

    Spatio-Temporal Branching for Motion Prediction using Motion Increments. (arXiv:2308.01097v1 [cs.CV])

    [http://arxiv.org/abs/2308.01097](http://arxiv.org/abs/2308.01097)

    本论文提出了一种利用运动增量进行时空分支的运动预测网络，通过解耦时域和空域特征的学习，提取更多的运动信息。

    

    人体运动预测已成为一个热门的研究课题，但由于未来姿势的随机和不规则性质，这仍然是一个具有挑战性的任务。传统方法依赖于手工特征和机器学习技术，往往难以建模人体运动的复杂动力学。最近基于深度学习的方法通过学习运动的时空表示取得了成功，但这些模型常常忽视运动数据的可靠性。此外，骨架节点的时域和空域依赖性是不同的。时域关系捕捉到随时间的运动信息，而空域关系描述了身体结构和不同节点之间的关系。在本文中，我们提出了一种新颖的利用增量信息进行时空分支的运动预测网络，它解耦了时域和空域特征的学习，提取了更多的运动信息。

    Human motion prediction (HMP) has emerged as a popular research topic due to its diverse applications, but it remains a challenging task due to the stochastic and aperiodic nature of future poses. Traditional methods rely on hand-crafted features and machine learning techniques, which often struggle to model the complex dynamics of human motion. Recent deep learning-based methods have achieved success by learning spatio-temporal representations of motion, but these models often overlook the reliability of motion data. Additionally, the temporal and spatial dependencies of skeleton nodes are distinct. The temporal relationship captures motion information over time, while the spatial relationship describes body structure and the relationships between different nodes. In this paper, we propose a novel spatio-temporal branching network using incremental information for HMP, which decouples the learning of temporal-domain and spatial-domain features, extracts more motion information, and ac
    
[^74]: CLAMS:一种用于估计视觉聚类中感知变异性的聚类模糊度测量方法

    CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering. (arXiv:2308.00284v1 [cs.HC])

    [http://arxiv.org/abs/2308.00284](http://arxiv.org/abs/2308.00284)

    本研究提出一种名为CLAMS的聚类模糊度测量方法，用于估计视觉聚类中的感知变异性。通过定性研究，我们确定了影响聚类的关键因素，并通过回归模块对聚类的模糊度进行估计。

    

    视觉聚类是散点图中常见的感知任务，支持各种分析任务（例如聚类识别）。然而，即使使用相同的散点图，由于个体间的差异和模糊的聚类边界，感知聚类的方式（即进行视觉聚类）可能会有所不同。尽管这种感知变异性对于基于视觉聚类的数据分析的可靠性提出了疑问，但我们缺乏一种系统评估这种变异性的有效方法。在这项研究中，我们研究了进行视觉聚类中的感知变异性，我们称之为聚类模糊度。为此，我们引入CLAMS，一种用于自动预测单色散点图中聚类模糊度的数据驱动的视觉质量测量方法。我们首先进行了定性研究，以确定影响聚类的视觉分离的关键因素（例如聚类间的接近度或大小差异）。基于研究结果，我们部署了一个回归模块来估计聚类的模糊度。

    Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates t
    
[^75]: ZADU: 评估降维嵌入可靠性的Python库

    ZADU: A Python Library for Evaluating the Reliability of Dimensionality Reduction Embeddings. (arXiv:2308.00282v1 [cs.LG])

    [http://arxiv.org/abs/2308.00282](http://arxiv.org/abs/2308.00282)

    ZADU是一个Python库，通过提供扭曲度量方法可以高效评估降维嵌入的可靠性，并通过优化执行和分析各个数据点的贡献提供全面评估。

    

    降维技术本质上会扭曲原始高维数据的结构，产生不完美的低维嵌入。为了评估降维嵌入的可靠性，提出了各种扭曲度量方法。然而，在实践中实现和执行扭曲度量一直是耗时且繁琐的。为了解决这个问题，本文介绍了一个Python库ZADU，提供了扭曲度量方法。ZADU不仅易于安装和执行，还通过三个关键特性实现了对降维嵌入的全面评估。首先，该库涵盖了各种扭曲度量方法。其次，它自动优化扭曲度量的执行，大大减少了执行多个度量所需的运行时间。最后，该库可显示个别数据点对整体扭曲的贡献，便于对降维嵌入进行详细分析。

    Dimensionality reduction (DR) techniques inherently distort the original structure of input high-dimensional data, producing imperfect low-dimensional embeddings. Diverse distortion measures have thus been proposed to evaluate the reliability of DR embeddings. However, implementing and executing distortion measures in practice has so far been time-consuming and tedious. To address this issue, we present ZADU, a Python library that provides distortion measures. ZADU is not only easy to install and execute but also enables comprehensive evaluation of DR embeddings through three key features. First, the library covers a wide range of distortion measures. Second, it automatically optimizes the execution of distortion measures, substantially reducing the running time required to execute multiple measures. Last, the library informs how individual points contribute to the overall distortions, facilitating the detailed analysis of DR embeddings. By simulating a real-world scenario of optimizin
    
[^76]: 类别不等于聚类：改进基于标签的降维评估

    Classes are not Clusters: Improving Label-based Evaluation of Dimensionality Reduction. (arXiv:2308.00278v1 [cs.LG])

    [http://arxiv.org/abs/2308.00278](http://arxiv.org/abs/2308.00278)

    本文提出了两种新的质量度量方法--标签可信度和标签连续性（Label-T&C）--改进了基于类别标签的降维评估的过程，不再假设类别在原始空间中形成良好的聚类，而是通过估计类别在原始空间和嵌入空间中形成聚类的程度和评估两者之间的差异来工作。

    

    评估降维嵌入的可靠性的一种常见方法是量化标记类别在嵌入中如何形成紧凑且相互分离的聚类。这种方法基于一个假设，即类别在原始的高维空间中仍然是清晰的聚类。然而，在现实中，这个假设可能不成立；一个类别可能被分解成多个分离的聚类，多个类别可能合并成一个聚类。因此，我们不能总是保证使用类别标签进行评估的可信度。在本文中，我们引入了两种新的质量度量方法--标签可信度和标签连续性（Label-T&C）--改进了基于类别标签的降维评估的过程。Label-T&C不再假设类别在原始空间中形成良好的聚类，而是通过（1）估计类别在原始空间和嵌入空间中形成聚类的程度和（2）评估两者之间的差异来工作。

    A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures -- Label-Trustworthiness and Label-Continuity (Label-T&C) -- advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative e
    
[^77]: 人工智能提高了全球可靠洪水预警的覆盖范围

    AI Increases Global Access to Reliable Flood Forecasts. (arXiv:2307.16104v1 [cs.LG])

    [http://arxiv.org/abs/2307.16104](http://arxiv.org/abs/2307.16104)

    本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。

    

    洪水是最常见和影响最大的自然灾害之一，对发展中国家尤其具有不对称的影响，这些国家往往缺乏密集的水流监测网络。准确及时的预警对于减轻洪水风险至关重要，但准确的水文模拟模型通常需要根据每个应用的流域中的长时间数据记录进行校准。我们开发了一个人工智能（AI）模型，可以预测7天内的极端水文事件。该模型在所有大洲、前导时间和重现期中均明显优于当前最先进的全球水文模型（Copernicus应急管理服务全球洪水意识系统）。AI在未经测量的流域中的预测尤其有效，这很重要，因为全球只有百分之几的流域具有流量观测站，而发展中国家的未经测量的流域数量占比很高，对人类特别脆弱。

    Floods are one of the most common and impactful natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow monitoring networks. Accurate and timely warnings are critical for mitigating flood risks, but accurate hydrological simulation models typically must be calibrated to long data records in each watershed where they are applied. We developed an Artificial Intelligence (AI) model to predict extreme hydrological events at timescales up to 7 days in advance. This model significantly outperforms current state of the art global hydrology models (the Copernicus Emergency Management Service Global Flood Awareness System) across all continents, lead times, and return periods. AI is especially effective at forecasting in ungauged basins, which is important because only a few percent of the world's watersheds have stream gauges, with a disproportionate number of ungauged basins in developing countries that are especially vulnerable to the human 
    
[^78]: 初始化状态干预对解决去除混淆的模仿学习问题的影响

    Initial State Interventions for Deconfounded Imitation Learning. (arXiv:2307.15980v1 [cs.LG])

    [http://arxiv.org/abs/2307.15980](http://arxiv.org/abs/2307.15980)

    本文介绍了一种针对模仿学习中因果混淆问题的初始化状态干预算法，该算法能够遮蔽观测中的混淆因素并提高性能表现。

    

    模仿学习存在因果混淆问题，即学习策略关注的特征并不因果地影响专家的行为，而是表面上的相关性。因果混淆的智能体在训练中产生了低的开环监督损失，但在部署时表现出差的闭环性能。我们考虑在观测空间的分离表示中遮蔽已观测到的混淆因素的问题。我们提出了一种新的遮蔽算法，利用了对初始系统状态进行干预的能力，避免了对专家查询、专家奖励函数或因果图规范的任何要求。在一定的假设下，我们在理论上证明了该算法是保守的，即不会错误地遮蔽因果相关的观测；此外，对初始状态的干预能够严格减少过度保守性。该遮蔽算法被应用于两个示例控制系统的行为克隆中。

    Imitation learning suffers from causal confusion. This phenomenon occurs when learned policies attend to features that do not causally influence the expert actions but are instead spuriously correlated. Causally confused agents produce low open-loop supervised loss but poor closed-loop performance upon deployment. We consider the problem of masking observed confounders in a disentangled representation of the observation space. Our novel masking algorithm leverages the usual ability to intervene in the initial system state, avoiding any requirement involving expert querying, expert reward functions, or causal graph specification. Under certain assumptions, we theoretically prove that this algorithm is conservative in the sense that it does not incorrectly mask observations that causally influence the expert; furthermore, intervening on the initial state serves to strictly reduce excess conservatism. The masking algorithm is applied to behavior cloning for two illustrative control system
    
[^79]: NIPD（一种基于真实世界非独立与同分布数据的联邦学习人体检测基准）

    NIPD: A Federated Learning Person Detection Benchmark Based on Real-World Non-IID Data. (arXiv:2306.15932v1 [cs.CV])

    [http://arxiv.org/abs/2306.15932](http://arxiv.org/abs/2306.15932)

    NIPD是一个基于真实世界非独立与同分布数据的联邦学习人体检测基准，开源了一个非独立和同分布的物联网人体检测数据集。

    

    联邦学习（FL）是一种保护隐私的分布式机器学习方法，已被广泛应用于无线通信网络。FL使得物联网客户端可以在防止隐私泄漏的情况下获得良好训练的模型。如果将FL与边缘设备结合使用，可以在边缘直接处理视频数据，从而将人员检测部署在计算能力有限的边缘设备上。然而，由于不同相机的硬件和部署场景不同，相机所收集的数据呈现非独立和同分布（non-IID）的特性，FL聚合得到的全局模型的效果较差。同时，现有研究缺乏用于研究物联网相机上非独立和同分布问题的公共数据集。因此，我们开源了一个非独立和同分布的物联网人体检测（NIPD）数据集，该数据集由五个不同的相机收集而来。据我们所知，这是第一个真正基于设备的非独立和同分布的人体检测数据集。

    Federated learning (FL), a privacy-preserving distributed machine learning, has been rapidly applied in wireless communication networks. FL enables Internet of Things (IoT) clients to obtain well-trained models while preventing privacy leakage. Person detection can be deployed on edge devices with limited computing power if combined with FL to process the video data directly at the edge. However, due to the different hardware and deployment scenarios of different cameras, the data collected by the camera present non-independent and identically distributed (non-IID), and the global model derived from FL aggregation is less effective. Meanwhile, existing research lacks public data set for real-world FL object detection, which is not conducive to studying the non-IID problem on IoT cameras. Therefore, we open source a non-IID IoT person detection (NIPD) data set, which is collected from five different cameras. To our knowledge, this is the first true device-based non-IID person detection 
    
[^80]: 基于困难样本挖掘的监督对比特征学习用于风力发电机桨叶系统故障诊断

    Hard Sample Mining Enabled Supervised Contrastive Feature Learning for Wind Turbine Pitch System Fault Diagnosis. (arXiv:2306.14701v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.14701](http://arxiv.org/abs/2306.14701)

    本文提出了一种基于困难样本挖掘的监督对比特征学习方法，用于风力发电机桨叶系统故障诊断。该方法利用余弦相似度识别困难样本，并通过构建困难样本对来学习更具区分性的表示，进一步提高了多层感知机的训练效果。

    

    风力发电机有效利用风能依赖于其桨叶系统能够根据风速变化调整桨叶角度的能力。然而，由于长期磨损导致的桨叶系统中存在多种健康问题，给准确分类造成了挑战，进而增加了风力发电机的维护成本甚至可能损坏它们。本文提出了一种基于困难样本挖掘的监督对比学习（HSMSCL）的新方法来解决这个问题。该方法利用余弦相似度识别困难样本，然后利用监督对比学习通过构建困难样本对来学习更具区分性的表示。此外，该方法中的困难样本挖掘框架还用学到的表示构建困难样本，使多层感知机（MLP）的训练过程更具挑战性并使其成为更有效的分类器。

    The efficient utilization of wind power by wind turbines relies on the ability of their pitch systems to adjust blade pitch angles in response to varying wind speeds. However, the presence of multiple health conditions in the pitch system due to the long-term wear and tear poses challenges in accurately classifying them, thus increasing the maintenance cost of wind turbines or even damaging them. This paper proposes a novel method based on hard sample mining-enabled supervised contrastive learning (HSMSCL) to address this problem. The proposed method employs cosine similarity to identify hard samples and subsequently, leverages supervised contrastive learning to learn more discriminative representations by constructing hard sample pairs. Furthermore, the hard sample mining framework in the proposed method also constructs hard samples with learned representations to make the training process of the multilayer perceptron (MLP) more challenging and make it a more effective classifier. The
    
[^81]: 训练好的Transformer在上下文中学习线性模型

    Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v1 [stat.ML])

    [http://arxiv.org/abs/2306.09927](http://arxiv.org/abs/2306.09927)

    本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。

    

    基于注意力的神经网络，例如Transformers，在上下文学习（ICL）方面表现出了非凡的能力：给定一个来自未见过的任务的短语序列的提示，它们可以制定相关的每个令牌和下一个令牌的预测，而不需要任何参数更新。通过将标记的训练数据和未标记的测试数据序列嵌入到提示中，这使得Transformer表现得像有监督学习算法。事实上，最近的工作表明，在随机实例上训练Transformer体系结构的线性回归问题时，这些模型的预测会模仿普通最小二乘法的预测。

    Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models' predictions mimic those of ordinary least squares.  Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this 
    
[^82]: 基于RANS-PINN的模拟代理预测湍流流动

    RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows. (arXiv:2306.06034v1 [cs.LG])

    [http://arxiv.org/abs/2306.06034](http://arxiv.org/abs/2306.06034)

    本研究提出了RANS-PINN模型，通过引入2方程涡粘度模型，可预测高雷诺数湍流流动中的流场，从而提高流体动力学模拟计算效率。

    

    物理知识引导的神经网络（PINN）为建立由微分方程控制的动态系统的代理模型提供了框架。 PINN在学习过程中会通过损失函数中的物理基础正则化项来增强泛化性能。由于模拟由偏微分方程（PDEs）控制的动态可能计算成本过高，PINN已经在学习由Navier-Stokes方程控制的液体流动问题的参数代理方面广受欢迎。在这项工作中，我们介绍了RANS-PINN，一种修改后的PINN框架，用于预测高雷诺数湍流流动中的流场（即速度和压力）。为了考虑湍流引入的额外复杂性，RANS-PINN采用基于雷诺平均Navier-Stokes（RANS）的2方程涡粘度模型。此外，我们采用了一种新的训练方法，确保各个组成部分的有效初始化和平衡。

    Physics-informed neural networks (PINNs) provide a framework to build surrogate models for dynamical systems governed by differential equations. During the learning process, PINNs incorporate a physics-based regularization term within the loss function to enhance generalization performance. Since simulating dynamics controlled by partial differential equations (PDEs) can be computationally expensive, PINNs have gained popularity in learning parametric surrogates for fluid flow problems governed by Navier-Stokes equations. In this work, we introduce RANS-PINN, a modified PINN framework, to predict flow fields (i.e., velocity and pressure) in high Reynolds number turbulent flow regime. To account for the additional complexity introduced by turbulence, RANS-PINN employs a 2-equation eddy viscosity model based on a Reynolds-averaged Navier-Stokes (RANS) formulation. Furthermore, we adopt a novel training approach that ensures effective initialization and balance among the various component
    
[^83]: 一种非马尔可夫算法的覆盖时间研究

    A Cover Time Study of a non-Markovian Algorithm. (arXiv:2306.04902v1 [cs.DS])

    [http://arxiv.org/abs/2306.04902](http://arxiv.org/abs/2306.04902)

    本文研究了一个遍历算法中的覆盖时间问题，通过一种基于计数的负反馈策略，实现在任意图中局部提高搜索效率，并在特殊的图形中实现更小的覆盖时间。

    

    在给定的图中，覆盖时间是访问所有节点所需的期望步数。更小的覆盖时间意味着遍历算法的探索效率更高。尽管对于随机游走算法已有大量研究，但对于任何非马尔可夫方法尚无覆盖时间结果。本研究从理论角度出发，表明负反馈策略（一种基于计数的探索方法）比朴素的随机漫步搜索策略更好。特别地，前者可以在任意图中局部提高搜索效率。它还可以在特殊但重要的图形中实现更小的覆盖时间，包括团簇图和树图等。此外，我们将结果与强化学习文献联系起来，以揭示为什么经典的UCB和MCTS算法如此有用。各种数值结果证实了我们的理论发现。

    Given a traversal algorithm, cover time is the expected number of steps needed to visit all nodes in a given graph. A smaller cover time means a higher exploration efficiency of traversal algorithm. Although random walk algorithms have been studied extensively in the existing literature, there has been no cover time result for any non-Markovian method. In this work, we stand on a theoretical perspective and show that the negative feedback strategy (a count-based exploration method) is better than the naive random walk search. In particular, the former strategy can locally improve the search efficiency for an arbitrary graph. It also achieves smaller cover times for special but important graphs, including clique graphs, tree graphs, etc. Moreover, we make connections between our results and reinforcement learning literature to give new insights on why classical UCB and MCTS algorithms are so useful. Various numerical results corroborate our theoretical findings.
    
[^84]: 关于扩散模型的设计基础：综述

    On the Design Fundamentals of Diffusion Models: A Survey. (arXiv:2306.04542v1 [cs.LG])

    [http://arxiv.org/abs/2306.04542](http://arxiv.org/abs/2306.04542)

    本文综述了扩散模型的设计基础，即其三个关键组件：正向过程、逆向过程和采样过程，为未来的研究提供了有益的细粒度透视。

    

    扩散模型是一种生成模型，通过逐渐添加和删除噪声来学习训练数据的潜在分布以生成数据。扩散模型的组成部分已经受到了广泛的关注，许多设计选择被提出。现有的评论主要关注高层次的解决方案，对组件的设计基础覆盖较少。本研究旨在通过提供一个全面而连贯的综述，针对扩散模型的组件设计选择进行分析。具体来说，我们将这个综述按照三个关键组件进行组织，即正向过程、逆向过程和采样过程。这使得我们可以提供扩散模型的细粒度透视，有助于未来研究分析个体组件、设计选择的适用性以及扩散模型的实现。

    Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.
    
[^85]: 忠实知识蒸馏

    Faithful Knowledge Distillation. (arXiv:2306.04431v1 [cs.LG])

    [http://arxiv.org/abs/2306.04431](http://arxiv.org/abs/2306.04431)

    本文研究了知识蒸馏中教师和学生之间的相对校准问题，提出了一个忠实的模仿框架来解决学生置信度和软标签的问题，并提供了一种实证和认证的方法来评估学生模型的鲁棒性。

    

    知识蒸馏是一种压缩神经网络使其能够在资源受限的系统中部署的成功方法，但过去的研究忽略了教师与学生之间在软置信度方面的相对校准问题。本文聚焦于一个教师-学生对中两个关键问题：（i）教师和学生是否在接近正确分类的数据样本时存在分歧，（ii）在数据样本周围，经过蒸馏的学生是否像教师一样自信。这些都是在安全关键环境中考虑从鲁棒教师中训练较小学生网络的部署时非常关键的问题。为了解决这些问题，我们引入了一个忠实的模仿框架来讨论置信度的相对校准，并提供实证和认证方法来评估学生的训练。

    Knowledge distillation (KD) has received much attention due to its success in compressing networks to allow for their deployment in resource-constrained systems. While the problem of adversarial robustness has been studied before in the KD setting, previous works overlook what we term the relative calibration of the student network with respect to its teacher in terms of soft confidences. In particular, we focus on two crucial questions with regard to a teacher-student pair: (i) do the teacher and student disagree at points close to correctly classified dataset examples, and (ii) is the distilled student as confident as the teacher around dataset examples? These are critical questions when considering the deployment of a smaller student network trained from a robust teacher within a safety-critical setting. To address these questions, we introduce a faithful imitation framework to discuss the relative calibration of confidences, as well as provide empirical and certified methods to eva
    
[^86]: 通过自预训练掩模序列自编码器和使用定制PolyLoss微调的方法实现鲁棒车道检测

    Robust Lane Detection through Self Pre-training with Masked Sequential Autoencoders and Fine-tuning with Customized PolyLoss. (arXiv:2305.17271v1 [cs.CV])

    [http://arxiv.org/abs/2305.17271](http://arxiv.org/abs/2305.17271)

    本论文提出了一种鲁棒车道检测流水线，该流水线包括自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩膜图像中的丢失像素为目标来预训练神经网络模型，提升了车道检测性能。

    

    车道检测是车辆定位的关键，是实现自动驾驶和许多智能高级驾驶辅助系统的基础。现有的基于视觉的车道检测方法未充分利用有价值的特征和聚合的上下文信息，尤其是车道线和图像中其他区域之间的相互关系。为填补这一研究空白并提升车道检测性能，本文提出了一种流水线，其中包括使用自预训练掩模序列自编码器和使用定制PolyLoss微调的端到端神经网络模型。掩模序列自编码器被采用以通过重构随机掩模图像中的丢失像素为目标来预训练神经网络模型。然后，在细调分割阶段中，连续的图像帧被用作输入，

    Lane detection is crucial for vehicle localization which makes it the foundation for automated driving and many intelligent and advanced driving assistant systems. Available vision-based lane detection methods do not make full use of the valuable features and aggregate contextual information, especially the interrelationships between lane lines and other regions of the images in continuous frames. To fill this research gap and upgrade lane detection performance, this paper proposes a pipeline consisting of self pre-training with masked sequential autoencoders and fine-tuning with customized PolyLoss for the end-to-end neural network models using multi-continuous image frames. The masked sequential autoencoders are adopted to pre-train the neural network models with reconstructing the missing pixels from a random masked image as the objective. Then, in the fine-tuning segmentation phase where lane detection segmentation is performed, the continuous image frames are served as the inputs,
    
[^87]: 超越不变表示学习：线性可对齐的潜在空间用于高效闭合形式领域自适应

    Beyond invariant representation learning: linearly alignable latent spaces for efficient closed-form domain adaptation. (arXiv:2305.07500v1 [cs.LG])

    [http://arxiv.org/abs/2305.07500](http://arxiv.org/abs/2305.07500)

    本文提出了一种新的基于最优输运（OT）的领域自适应（DA）方法，通过学习一个嵌入空间，使得OT问题的解是最优且计算量较少的，适用于同质和异质的DA设置。

    

    最优输运（OT）是一种强大的几何工具，用于比较和对齐概率测度，遵循最小努力原则。在机器学习（ML）中，OT的许多成功应用之一是领域自适应（DA），这是一种研究领域，其目标是将分类器从一个带标签的领域转移到另一个类似但不同的未标记或稀疏标记的领域。我们提出了一种全新的基于OT的DA方法，该方法使用由仿射映射给出的OT问题的闭式解，并学习了一个嵌入空间，使得该解是最优且计算量较少。我们展示了我们的方法适用于同质和异质的DA设置。

    Optimal transport (OT) is a powerful geometric tool used to compare and align probability measures following the least effort principle. Among many successful applications of OT in machine learning (ML), domain adaptation (DA) -- a field of study where the goal is to transfer a classifier from one labelled domain to another similar, yet different unlabelled or scarcely labelled domain -- has been historically among the most investigated ones. This success is due to the ability of OT to provide both a meaningful discrepancy measure to assess the similarity of two domains' distributions and a mapping that can project source domain data onto the target one. In this paper, we propose a principally new OT-based approach applied to DA that uses the closed-form solution of the OT problem given by an affine mapping and learns an embedding space for which this solution is optimal and computationally less complex. We show that our approach works in both homogeneous and heterogeneous DA settings 
    
[^88]: 学习在存在隐性混淆因素的情况下从不确定数据中恢复因果关系

    Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders. (arXiv:2305.02640v1 [cs.LG])

    [http://arxiv.org/abs/2305.02640](http://arxiv.org/abs/2305.02640)

    本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。

    

    在具有潜在变量的因果发现中，我们定义了两个数据范式：确定数据：具有观察节点单值的单个骨架结构，和不确定数据：具有观察节点多值的一组多骨架结构。多个骨架引入低样本利用率，多个值引入了分布假设的无能力，这两者导致从不确定数据中恢复因果关系至今仍然未被充分探索。我们设计了因果强度变分模型来解决这两个问题。具体地，我们利用因果强度而不是独立噪声作为潜变量来调节证据下界。通过这种设计思想，不同骨架的因果强度被看作是一个分布，并可以表示为单值因果图矩阵。此外，考虑到潜在混淆因素，我们将因果图G分解为两个相关子图O和C。O包含观察节点之间的纯关系，而C表示混淆因素。

    In Causal Discovery with latent variables, We define two data paradigms: definite data: a single-skeleton structure with observed nodes single-value, and indefinite data: a set of multi-skeleton structures with observed nodes multi-value. Multi,skeletons induce low sample utilization and multi values induce incapability of the distribution assumption, both leading that recovering causal relations from indefinite data is, as of yet, largely unexplored. We design the causal strength variational model to settle down these two problems. Specifically, we leverage the causal strength instead of independent noise as latent variable to mediate evidence lower bound. By this design ethos, The causal strength of different skeletons is regarded as a distribution and can be expressed as a single-valued causal graph matrix. Moreover, considering the latent confounders, we disentangle the causal graph G into two relatisubgraphs O and C. O contains pure relations between observed nodes, while C repres
    
[^89]: MAMAF-Net：用于中风诊断的运动感知和多关注融合网络

    MAMAF-Net: Motion-Aware and Multi-Attention Fusion Network for Stroke Diagnosis. (arXiv:2304.09466v1 [eess.IV])

    [http://arxiv.org/abs/2304.09466](http://arxiv.org/abs/2304.09466)

    本研究提出了一个名为MAMAF-Net的网络用于检测多模态检查视频中的中风情况，并提出了一个多数采样的数据集。这是第一个提供端到端解决方案的视频分析中的中风检测研究。

    

    中风是全球死亡率和残疾率的主要原因，每四人中就有一人有中风的危险。预先医院中风评估在准确识别中风患者以加速进一步检查和治疗方面发挥着关键作用。本文提出了一种名为MAMAF-Net的运动感知和多关注融合网络，可以检测多模式检查视频中的中风情况。与其他视频分析中的中风检测研究不同，我们提出了一个多数采样的数据集，用于从每个被试者的多个视频记录中进行端到端的解决方案，包括中风、短暂性缺血性发作（TIA）和健康对照。

    Stroke is a major cause of mortality and disability worldwide from which one in four people are in danger of incurring in their lifetime. The pre-hospital stroke assessment plays a vital role in identifying stroke patients accurately to accelerate further examination and treatment in hospitals. Accordingly, the National Institutes of Health Stroke Scale (NIHSS), Cincinnati Pre-hospital Stroke Scale (CPSS) and Face Arm Speed Time (F.A.S.T.) are globally known tests for stroke assessment. However, the validity of these tests is skeptical in the absence of neurologists. Therefore, in this study, we propose a motion-aware and multi-attention fusion network (MAMAF-Net) that can detect stroke from multimodal examination videos. Contrary to other studies on stroke detection from video analysis, our study for the first time proposes an end-to-end solution from multiple video recordings of each subject with a dataset encapsulating stroke, transient ischemic attack (TIA), and healthy controls. T
    
[^90]: 使用丰富的元数据注释的屏幕角色的个性化语言建模

    Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations. (arXiv:2303.16618v1 [cs.CL])

    [http://arxiv.org/abs/2303.16618](http://arxiv.org/abs/2303.16618)

    本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。

    

    语言模型的个性化为对话敏感，能更好地捕捉特定特征的人员和/或特定环境中的说话模式。然而，丰富的角色注释难以得到和成功利用。在此工作中，我们发布并描述了一组新颖的手动注释，涵盖了来自流行的 Cornell 电影对话语料库的 863 名演讲者，包括特征引用和角色描述，以及超过 95％ 的特色电影的一组自动提取的六个元数据。我们对两个语料库进行了广泛的实验，并表明可以有效地使用此类注释来个性化语言模型，将困惑减少高达 8.5％。我们的方法甚至可以应用于零样本的演讲者，即对于没有先前培训数据的演讲者，依赖于角色的人口特征的组合。由于收集此类元数据成本高昂，因此我们还贡献了一项成本效益分析，以突出显示

    Personalisation of language models for dialogue sensitises them to better capture the speaking patterns of people of specific characteristics, and/or in specific environments. However, rich character annotations are difficult to come by and to successfully leverage. In this work, we release and describe a novel set of manual annotations for 863 speakers from the popular Cornell Movie Dialog Corpus, including features like characteristic quotes and character descriptions, and a set of six automatically extracted metadata for over 95% of the featured films. We perform extensive experiments on two corpora and show that such annotations can be effectively used to personalise language models, reducing perplexity by up to 8.5%. Our method can be applied even zero-shot for speakers for whom no prior training data is available, by relying on combinations of characters' demographic characteristics. Since collecting such metadata is costly, we also contribute a cost-benefit analysis to highlight
    
[^91]: 物理引导的对抗神经网络用于人造数字图像相关数据生成

    Physics-guided adversarial networks for artificial digital image correlation data generation. (arXiv:2303.15939v1 [eess.IV])

    [http://arxiv.org/abs/2303.15939](http://arxiv.org/abs/2303.15939)

    本文提出一种使用具有物理引导鉴别器的生成式对抗网络来生成人造DIC位移数据的方法， 以训练更精确可靠的机器学习模型，从而实现更准确可靠的疲劳裂纹增长评估的发展。

    

    数字图像相关（DIC）已成为评估力学实验的有价值工具，特别是疲劳裂纹增长实验。评估需要准确的裂纹路径和裂纹尖端位置信息，由于固有噪声和伪影的原因，这很难获得。机器学习模型在给定标记的DIC位移数据的情况下识别此相关信息非常成功。为了训练具有广泛泛化能力的强大模型，需要大数据。然而，由于实验昂贵且耗时，材料科学和工程领域的数据通常很少。 我们提出了一种使用具有物理引导鉴别器的生成式对抗网络来生成人造DIC位移数据的方法。为了决定数据样本是真实还是假的，该鉴别器另外接收导出的von Mises等效应变。我们显示，这种物理引导方法相比传统GAN产生了更准确和稳健的结果。我们的方法允许产生大量的人造DIC数据，以训练机器学习模型，从而实现更准确可靠的疲劳裂纹增长评估的发展。

    Digital image correlation (DIC) has become a valuable tool in the evaluation of mechanical experiments, particularly fatigue crack growth experiments. The evaluation requires accurate information of the crack path and crack tip position, which is difficult to obtain due to inherent noise and artefacts. Machine learning models have been extremely successful in recognizing this relevant information given labelled DIC displacement data. For the training of robust models, which generalize well, big data is needed. However, data is typically scarce in the field of material science and engineering because experiments are expensive and time-consuming. We present a method to generate synthetic DIC displacement data using generative adversarial networks with a physics-guided discriminator. To decide whether data samples are real or fake, this discriminator additionally receives the derived von Mises equivalent strain. We show that this physics-guided approach leads to improved results in terms 
    
[^92]: 通过方向调整改进对抗性样本的可迁移性

    Improving the Transferability of Adversarial Examples via Direction Tuning. (arXiv:2303.15109v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15109](http://arxiv.org/abs/2303.15109)

    该论文提出了一种新的基于迁移的攻击方法，通过方向调整来改进对抗性样本的可迁移性。该方法既能减小大步长中的更新偏差，又能减轻小步长中的更新振荡。

    

    在基于迁移的对抗攻击中，对抗性样本仅由替代模型生成，并在受害模型中实现有效扰动。虽然已经有相当多的工作在改进基于迁移的对抗攻击生成的对抗性样本的可迁移性，但我们的研究发现，当前基于迁移的对抗攻击的实际更新方向与最陡的更新方向之间存在巨大偏差，这是由于大的更新步长导致生成的对抗性样本无法很好地收敛。然而，直接减小更新步长会导致严重的更新振荡，从而使生成的对抗性样本也无法在受害模型中达到很好的可迁移性。为解决这些问题，提出了一种新的基于迁移的攻击方法，即方向调整攻击，旨在减小大步长中的更新偏差，并减轻小步长中的更新振荡。

    In the transfer-based adversarial attacks, adversarial examples are only generated by the surrogate models and achieve effective perturbation in the victim models. Although considerable efforts have been developed on improving the transferability of adversarial examples generated by transfer-based adversarial attacks, our investigation found that, the big deviation between the actual and steepest update directions of the current transfer-based adversarial attacks is caused by the large update step length, resulting in the generated adversarial examples can not converge well. However, directly reducing the update step length will lead to serious update oscillation so that the generated adversarial examples also can not achieve great transferability to the victim models. To address these issues, a novel transfer-based attack, namely direction tuning attack, is proposed to not only decrease the update deviation in the large step length, but also mitigate the update oscillation in the smal
    
[^93]: PENTACET数据——2300万个上下文代码注释和50万个自我承认技术债务注释

    PENTACET data -- 23 Million Contextual Code Comments and 500,000 SATD comments. (arXiv:2303.14029v1 [cs.SE])

    [http://arxiv.org/abs/2303.14029](http://arxiv.org/abs/2303.14029)

    本文介绍了PENTACET数据集，该数据集包含了2300万个上下文代码注释和50万个自我承认技术债务注释，并提供了详细的上下文数据，将进一步推动使用人工智能技术的SATD研究。

    

    大多数自我承认技术债务（SATD）研究使用如“TODO”和“FIXME”之类的显式SATD特征进行SATD检测。更仔细地观察发现，一些SATD研究使用简单的SATD（“易于发现的”）代码注释而没有上下文数据（前文和后文源代码上下文）。本研究通过PENTACET（或5C数据集）数据填补了这一空白。PENTACET是一个由贡献者进行筛选的大型上下文代码注释数据库，是最全面的SATD数据。我们从9,096个开源软件Java项目中挖掘了总共435百万行代码。结果是一个数据集，包含了2300万个代码注释，并为每个注释提供了前后源代码上下文，以及50万个被标记为SATD的注释，包括“易于发现的”和“难于发现的” SATD。我们相信PENTACET数据集将进一步推动使用人工智能技术的SATD研究。

    Most Self-Admitted Technical Debt (SATD) research utilizes explicit SATD features such as 'TODO' and 'FIXME' for SATD detection. A closer look reveals several SATD research uses simple SATD ('Easy to Find') code comments without the contextual data (preceding and succeeding source code context). This work addresses this gap through PENTACET (or 5C dataset) data. PENTACET is a large Curated Contextual Code Comments per Contributor and the most extensive SATD data. We mine 9,096 Open Source Software Java projects with a total of 435 million LOC. The outcome is a dataset with 23 million code comments, preceding and succeeding source code context for each comment, and more than 500,000 comments labeled as SATD, including both 'Easy to Find' and 'Hard to Find' SATD. We believe PENTACET data will further SATD research using Artificial Intelligence techniques.
    
[^94]: ExBEHRT：基于电子病历的扩展Transformer预测疾病亚型和进展

    ExBEHRT: Extended Transformer for Electronic Health Records to Predict Disease Subtypes & Progressions. (arXiv:2303.12364v1 [cs.LG])

    [http://arxiv.org/abs/2303.12364](http://arxiv.org/abs/2303.12364)

    ExBEHRT是一种扩展Transformer模型，应用于电子病历数据，将多种类型的记录包括在特征空间中，可以预测不同疾病下游任务的性能更好，并使用预期梯度对结果进行更细粒度的解释。

    

    本研究引入了ExBEHRT，它是BEHRT（应用于电子病历的BERT）的扩展版本，并应用不同的算法来解释其结果。我们将特征空间从仅考虑诊断和患者年龄扩展到包括多种类型的记录，包括人口统计学、临床特征、生命体征、吸烟状态、诊断、手术、药物和实验室检查，并采用一种新方法来统一不同特征的频率和时间维度。我们展示了附加特征可以显著改善不同疾病下游任务的模型性能。为了保证模型的稳健性，我们使用了预期梯度的改进方法对模型预测结果进行解释，该方法以前未应用于将EHR数据与Transformer相结合，提供了比以前方法更细粒度的解释，如特征和令牌重要性。此外，通过对肿瘤学患者的模型表示进行聚类，我们展示了ExBEHRT可以用于预测疾病亚型和进展。

    In this study, we introduce ExBEHRT, an extended version of BEHRT (BERT applied to electronic health records), and apply different algorithms to interpret its results. While BEHRT considers only diagnoses and patient age, we extend the feature space to several multimodal records, namely demographics, clinical characteristics, vital signs, smoking status, diagnoses, procedures, medications, and laboratory tests, by applying a novel method to unify the frequencies and temporal dimensions of the different features. We show that additional features significantly improve model performance for various downstream tasks in different diseases. To ensure robustness, we interpret model predictions using an adaptation of expected gradients, which has not been previously applied to transformers with EHR data and provides more granular interpretations than previous approaches such as feature and token importances. Furthermore, by clustering the model representations of oncology patients, we show tha
    
[^95]: BODEGA: 针对可信度评估中对抗性样本生成的基准测试

    BODEGA: Benchmark for Adversarial Example Generation in Credibility Assessment. (arXiv:2303.08032v1 [cs.CL])

    [http://arxiv.org/abs/2303.08032](http://arxiv.org/abs/2303.08032)

    BODEGA是一个基准测试，用于模拟真实的内容管理场景，在四个误传检测任务上测试受害模型和攻击方法。测试结果表明，在某些情况下，即使进行微小的文本修改，也可以欺骗最准确的分类器。

    

    文本分类方法被广泛应用于检测不可信内容，如假新闻、社交媒体机器人、宣传等。较为准确的模型（可能基于深度神经网络）有助于管理公共电子平台，并经常导致内容创建者面临提交拒绝或已发布文本的撤下。为了避免进一步被检测，内容创建者尝试产生一个稍微修改过的文本版本（即攻击对抗性样本），利用分类器的弱点导致不同的输出。本文介绍了BODEGA：一个基准测试，用于在模拟内容管理的真实用例中测试受害模型和攻击方法在四个误传检测任务上的表现。我们还系统地测试了受欢迎的文本分类器对可用攻击技术的鲁棒性，并发现在某些情况下，即使在文本中进行微小的修改也可以欺骗最准确的分类器。

    Text classification methods have been widely investigated as a way to detect content of low credibility: fake news, social media bots, propaganda, etc. Quite accurate models (likely based on deep neural networks) help in moderating public electronic platforms and often cause content creators to face rejection of their submissions or removal of already published texts. Having the incentive to evade further detection, content creators try to come up with a slightly modified version of the text (known as an attack with an adversarial example) that exploit the weaknesses of classifiers and result in a different output. Here we introduce BODEGA: a benchmark for testing both victim models and attack methods on four misinformation detection tasks in an evaluation framework designed to simulate real use-cases of content moderation. We also systematically test the robustness of popular text classifiers against available attacking techniques and discover that, indeed, in some cases barely signif
    
[^96]: 防止视觉语言模型在不断学习中出现零样例转移降级

    Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models. (arXiv:2303.06628v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.06628](http://arxiv.org/abs/2303.06628)

    本文提出了一种新的方法ZSCL，旨在解决连续学习视觉语言模型中零样例转移降级的问题。通过在特征空间中引入参考数据集进行蒸馏，该方法能够有效地防止模型的零样例转移能力的降低。

    

    连续学习（CL）可以帮助预训练的视觉语言模型在不重新训练的情况下高效地适应新的或未经训练的数据分布。然而，在对比语言-图像预训练（CLIP）模型的连续训练过程中，我们观察到由于灾难性遗忘，模型的零样例转移能力显著降低。现有的CL方法可以通过回放先前的数据来减轻遗忘。然而，由于CLIP数据集是私有的，回放方法无法访问预训练数据集。此外，回放先前学习的下游任务数据可以提高它们的性能，但会损耗零样例性能。为了解决这个挑战，在特征空间和参数空间中，我们提出了一种新颖的方法ZSCL，以防止在连续学习视觉语言模型时出现零样例转移降级。在特征空间中，引入了一个参考数据集，用于当前和初始模型之间的蒸馏。

    Continual learning (CL) can help pre-trained vision-language models efficiently adapt to new or under-trained data distributions without re-training. Nevertheless, during the continual training of the Contrastive Language-Image Pre-training (CLIP) model, we observe that the model's zero-shot transfer ability significantly degrades due to catastrophic forgetting. Existing CL methods can mitigate forgetting by replaying previous data. However, since the CLIP dataset is private, replay methods cannot access the pre-training dataset. In addition, replaying data of previously learned downstream tasks can enhance their performance but comes at the cost of sacrificing zero-shot performance. To address this challenge, we propose a novel method ZSCL to prevent zero-shot transfer degradation in the continual learning of vision-language models in both feature and parameter space. In the feature space, a reference dataset is introduced for distillation between the current and initial models. The r
    
[^97]: 采用机载协调器进行协同学习

    Collaborative Learning with a Drone Orchestrator. (arXiv:2303.02266v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2303.02266](http://arxiv.org/abs/2303.02266)

    本文研究了无人机辅助的协同学习问题，提出了一种通过智能设备群与无人机协同训练神经网络模型的方法。在考虑数据异质性和通信错误的情况下，导出了协同学习的收敛速度，并通过优化无人机轨迹来提高训练准确率。

    

    本文考虑了无人机辅助协同学习的问题。在这种场景下，智能无线设备群通过无人机共同训练一个共享的神经网络模型。每个设备使用其传感器记录来自环境的样本，以获取用于训练的本地数据集。由于各设备的数据量和传感器噪声水平不同，训练数据具有严重的异质性。智能设备对其本地数据集进行迭代训练，并将模型参数与无人机进行交换以进行聚合。在考虑数据异质性、传感器噪声水平和通信错误的情况下，导出了协同学习的收敛速率，并获得了最大化训练的神经网络的最终准确率的无人机轨迹。所提出的轨迹优化方法考虑了设备的数据特性（即本地数据集大小和噪声水平）以及其无线通信条件。

    In this paper, the problem of drone-assisted collaborative learning is considered. In this scenario, swarm of intelligent wireless devices train a shared neural network (NN) model with the help of a drone. Using its sensors, each device records samples from its environment to gather a local dataset for training. The training data is severely heterogeneous as various devices have different amount of data and sensor noise level. The intelligent devices iteratively train the NN on their local datasets and exchange the model parameters with the drone for aggregation. For this system, the convergence rate of collaborative learning is derived while considering data heterogeneity, sensor noise levels, and communication errors, then, the drone trajectory that maximizes the final accuracy of the trained NN is obtained. The proposed trajectory optimization approach is aware of both the devices data characteristics (i.e., local dataset size and noise level) and their wireless channel conditions, 
    
[^98]: 原子结构表征的完备性

    Completeness of Atomic Structure Representations. (arXiv:2302.14770v2 [physics.chem-ph] UPDATED)

    [http://arxiv.org/abs/2302.14770](http://arxiv.org/abs/2302.14770)

    本文解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，并提出了一种构造有限子集描述符的新方法。

    

    在本文中，我们解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，这在物理学和理论化学中非常重要。随着机器学习技术在科学中的广泛应用，这个问题变得更加重要，因为它支撑了模型准确复现物理关系并与基本对称性和守恒定律一致的能力。然而，通常用于表示点云的描述符（尤其是用于描述原子尺度上物质的描述符）无法区分特殊的粒子排列。这使得无法用机器学习来学习它们的属性。存在可证明完备性的框架，但仅在同时描述所有原子之间的相互关系的极限情况下才是如此，这在实践中是不可行的。我们提出了一种构造有限子集描述符的新方法。

    In this paper, we address the challenge of obtaining a comprehensive and symmetric representation of point particle groups, such as atoms in a molecule, which is crucial in physics and theoretical chemistry. The problem has become even more important with the widespread adoption of machine-learning techniques in science, as it underpins the capacity of models to accurately reproduce physical relationships while being consistent with fundamental symmetries and conservation laws. However, the descriptors that are commonly used to represent point clouds -- most notably those adopted to describe matter at the atomic scale -- are unable to distinguish between special arrangements of particles. This makes it impossible to machine learn their properties. Frameworks that are provably complete exist but are only so in the limit in which they simultaneously describe the mutual relationship between all atoms, which is impractical. We present a novel approach to construct descriptors of finite cor
    
[^99]: 跨模态对比学习用于多模态假新闻检测

    Cross-modal Contrastive Learning for Multimodal Fake News Detection. (arXiv:2302.14057v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14057](http://arxiv.org/abs/2302.14057)

    这项研究提出了COOLANT，一个用于跨模态假新闻检测的对比学习框架，旨在提升图像和文本的对齐精度，并通过跨模态融合和注意力机制实现更准确和可解释的特征聚合。

    

    自动检测多模态假新闻近来引起了广泛关注。许多现有方法致力于融合单模特征以产生多模态新闻表达。然而，强大的跨模态对比学习方法在假新闻检测方面的潜力尚未充分利用。此外，如何聚合不同模态的特征以提升决策过程的性能仍然是一个未解决的问题。为了解决这个问题，我们提出了COOLANT，一个用于多模态假新闻检测的跨模态对比学习框架，旨在实现更准确的图像-文本对齐。为了进一步提高对齐精度，我们利用辅助任务在对比过程中软化负样本的损失项。我们开发了一个跨模态融合模块来学习跨模态之间的相关性。我们实现了一个带有注意力引导模块的注意力机制，以帮助有效且可解释地聚合对齐的单模信息。

    Automatic detection of multimodal fake news has gained a widespread attention recently. Many existing approaches seek to fuse unimodal features to produce multimodal news representations. However, the potential of powerful cross-modal contrastive learning methods for fake news detection has not been well exploited. Besides, how to aggregate features from different modalities to boost the performance of the decision-making process is still an open question. To address that, we propose COOLANT, a cross-modal contrastive learning framework for multimodal fake news detection, aiming to achieve more accurate image-text alignment. To further improve the alignment precision, we leverage an auxiliary task to soften the loss term of negative samples during the contrast process. A cross-modal fusion module is developed to learn the cross-modality correlations. An attention mechanism with an attention guidance module is implemented to help effectively and interpretably aggregate the aligned unimo
    
[^100]: 大规模音频录音的声音产生检测与分类

    Detection and classification of vocal productions in large scale audio recordings. (arXiv:2302.07640v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2302.07640](http://arxiv.org/abs/2302.07640)

    我们提出了一种自动数据处理流程，用于从大规模自然音频录音中提取声音产生并分类，该方法能够在不需要大量标注数据和重要计算资源的情况下训练一个准确率较高的神经网络模型，并且适用于不同录音条件下的嘈杂录音。

    

    我们提出了一种自动数据处理流程，用于从大规模自然音频录音中提取声音产生并对其进行分类。该流程基于深度神经网络，可以同时解决这两个问题。通过一系列的计算步骤（窗口化、噪音类别创建、数据增强、重采样、迁移学习、贝叶斯优化），它能够在不需要大量标注数据和重要计算资源的情况下自动训练一个神经网络。我们的端到端方法可以处理在不同录音条件下采集的嘈杂录音。我们在两个不同的自然音频数据集上进行了测试，一个是来自几内亚狒狒在灵长类研究中心的录音，另一个是来自在家中录制的婴儿的录音。该流程使用了72分钟和77分钟的标注音频录音训练模型，准确率分别为94.58%和99.76%。然后，它被用于处理443小时和174小时的自然连续录音，并创建/>

    We propose an automatic data processing pipeline to extract vocal productions from large-scale natural audio recordings and classify these vocal productions. The pipeline is based on a deep neural network and adresses both issues simultaneously. Though a series of computationel steps (windowing, creation of a noise class, data augmentation, re-sampling, transfer learning, Bayesian optimisation), it automatically trains a neural network without requiring a large sample of labeled data and important computing resources. Our end-to-end methodology can handle noisy recordings made under different recording conditions. We test it on two different natural audio data sets, one from a group of Guinea baboons recorded from a primate research center and one from human babies recorded at home. The pipeline trains a model on 72 and 77 minutes of labeled audio recordings, with an accuracy of 94.58% and 99.76%. It is then used to process 443 and 174 hours of natural continuous recordings and it crea
    
[^101]: 通过稀疏编码实现无约束动态遗憾

    Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13349](http://arxiv.org/abs/2301.13349)

    本文探讨了在线线性优化（OLO）涉及无约束问题和动态遗憾问题的复杂性，提出了一种通过重新构造问题为稀疏编码的复杂度度量方式，在适应性和应用上有较好的应用价值。

    

    受时间序列预测的影响，本研究探讨了在线线性优化（OLO）在两个问题结构的耦合下的情况：域无界，而算法的性能是通过动态遗憾来衡量的。处理任一问题都要求遗憾界限依赖于比较序列的某些复杂度量度 - 特别是无约束OLO中的比较器范数，以及动态遗憾中的路径长度。与最近一篇文章(Jacobsen& Cutkosky，2022)适应这两个复杂度量度相比，我们提出了一种通过重新构造问题为稀疏编码的复杂度度量方式。可以通过一个简单的模块化框架实现适应性，这个框架自然地利用了环境更复杂的前置知识。同时，我们还提出了一种新的静态无约束OLO梯度自适应算法，使用了新颖的连续时间机制设计。这可能是具有独立兴趣的。

    Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen & Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
    
[^102]: CodeBert能学到哪些特征：BERT基于源码表示学习的实证研究

    Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning. (arXiv:2301.08427v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08427](http://arxiv.org/abs/2301.08427)

    该论文研究了CodeBert在源码表示学习中学到了哪些特征，发现当前方法无法有效理解源代码的逻辑，而源代码的表示依赖于程序员定义的变量和函数名。

    

    双向编码器表示转换(BERT)在自然语言处理(NLP)领域提出，并显示出了良好的结果。最近，研究人员将BERT应用于源码表示学习，并在几个下游任务中取得了一些好消息。然而，在本文中，我们说明了当前方法无法有效理解源代码的逻辑。源代码的表示在很大程度上依赖于程序员定义的变量和函数名。我们设计并实施了一系列实验来验证我们的猜想，并为未来的工作提供一些见解。

    The Bidirectional Encoder Representations from Transformers (BERT) were proposed in the natural language process (NLP) and shows promising results. Recently researchers applied the BERT to source-code representation learning and reported some good news on several downstream tasks. However, in this paper, we illustrated that current methods cannot effectively understand the logic of source codes. The representation of source code heavily relies on the programmer-defined variable and function names. We design and implement a set of experiments to demonstrate our conjecture and provide some insights for future works.
    
[^103]: 深度低秩矩阵分解中隐式正则化的动力学理论

    A Dynamics Theory of Implicit Regularization in Deep Low-Rank Matrix Factorization. (arXiv:2212.14150v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.14150](http://arxiv.org/abs/2212.14150)

    本文提出了一种新的解释神经网络隐式正则化的方法，通过离散梯度动力学和景观分析揭示了深度低秩矩阵分解中的隐式正则化机制。

    

    隐式正则化是解释神经网络的重要方法。最近的理论开始用深度矩阵分解模型(DMF)来解释隐式正则化，并分析了优化过程中离散梯度动力学的轨迹。这些离散梯度动力学相对较小但不是无穷小，因此很好地适应了神经网络的实际实现。目前，离散梯度动力学分析已成功应用于浅层网络，但在深层网络中遇到了复杂计算的困难。在这项工作中，我们引入了另一种解释隐式正则化的离散梯度动力学方法，即景观分析。它主要关注梯度区域，如鞍点和局部最小值。我们在理论上建立了鞍点逃逸(SPE)阶段和DMF中矩阵秩之间的联系。我们证明，对于秩为R的矩阵重构，DMF将收敛到二阶临界点。

    Implicit regularization is an important way to interpret neural networks. Recent theory starts to explain implicit regularization with the model of deep matrix factorization (DMF) and analyze the trajectory of discrete gradient dynamics in the optimization process. These discrete gradient dynamics are relatively small but not infinitesimal, thus fitting well with the practical implementation of neural networks. Currently, discrete gradient dynamics analysis has been successfully applied to shallow networks but encounters the difficulty of complex computation for deep networks. In this work, we introduce another discrete gradient dynamics approach to explain implicit regularization, i.e. landscape analysis. It mainly focuses on gradient regions, such as saddle points and local minima. We theoretically establish the connection between saddle point escaping (SPE) stages and the matrix rank in DMF. We prove that, for a rank-R matrix reconstruction, DMF will converge to a second-order criti
    
[^104]: RT-1: 用于实际控制的机器人变压器.

    RT-1: Robotics Transformer for Real-World Control at Scale. (arXiv:2212.06817v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2212.06817](http://arxiv.org/abs/2212.06817)

    本文提出了机器人变压器模型，通过从大规模、多样化、任务无关的数据集中获取知识，并结合高容量架构，实现了在实际控制领域的高性能泛化能力。

    

    通过从大规模、多样化、任务无关的数据集中获取知识，现代机器学习模型可以在零样本学习或使用少量特定任务的数据集来高水平地解决具体的下游任务。虽然这种能力已经在计算机视觉、自然语言处理或语音识别等其他领域得到证明，但在机器人领域尚未展示出来。这是因为模型的泛化能力在机器人领域尤为关键，由于收集现实世界的机器人数据的难度较大。我们认为，这种通用机器人模型成功的一个关键因素在于任务不可知的开放式训练，结合可以吸收所有多样化机器人数据的高容量架构。在本文中，我们提出了一种称为机器人变压器的模型类，具有良好的可扩展模型特性。我们通过研究不同模型类别及其随数据大小而推广的能力来验证我们的结论。

    By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, mod
    
[^105]: 深度图神经网络中过度平滑和过度压缩的权衡研究

    On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural Networks. (arXiv:2212.02374v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.02374](http://arxiv.org/abs/2212.02374)

    过度平滑和过度压缩是深度图神经网络中的关键挑战，我们提出了添加和删除边缘的方法来解决这个问题。

    

    图神经网络（GNN）在各种计算机科学应用中取得了成功，但是深度GNN在应用中表现不佳，尽管深度学习在其他领域取得了成功。当堆叠图卷积层时，过度平滑和过度压缩是深度表示学习和从远处节点传播信息的关键挑战。我们的工作揭示了过度平滑和过度压缩与图拉普拉斯算符的谱间隔有内在联系，导致这两个问题之间存在必然的权衡，无法同时缓解。为了达到合适的折中，我们提出了添加和删除边缘作为可行的方法。我们引入了随机Jost和Liu曲率重连（SJLR）算法，它在速度上具有计算效率，并与以前基于曲率的方法相比保持了基本特性。与现有方法不同，SJLR在GNN训练过程中执行边缘添加和删除，同时保持了基本特性。

    Graph Neural Networks (GNNs) have succeeded in various computer science applications, yet deep GNNs underperform their shallow counterparts despite deep learning's success in other domains. Over-smoothing and over-squashing are key challenges when stacking graph convolutional layers, hindering deep representation learning and information propagation from distant nodes. Our work reveals that over-smoothing and over-squashing are intrinsically related to the spectral gap of the graph Laplacian, resulting in an inevitable trade-off between these two issues, as they cannot be alleviated simultaneously. To achieve a suitable compromise, we propose adding and removing edges as a viable approach. We introduce the Stochastic Jost and Liu Curvature Rewiring (SJLR) algorithm, which is computationally efficient and preserves fundamental properties compared to previous curvature-based methods. Unlike existing approaches, SJLR performs edge addition and removal during GNN training while maintaining
    
[^106]: 基于神经网络的凸规则化器用于图像重建

    A Neural-Network-Based Convex Regularizer for Image Reconstruction. (arXiv:2211.12461v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2211.12461](http://arxiv.org/abs/2211.12461)

    本研究提出了基于神经网络的凸规则化器用于图像重建。该方法通过重新审视由凸脊函数组成的规则化器，并使用具有单个隐藏层的神经网络对其梯度进行参数化。实验证明，在去噪、CT和MRI重建方面，该方法在提供类似可靠性保证的情况下，能够取得更好的结果。

    

    深度学习方法在解决图像重建问题上的出现，使得重建质量有了显著提高。然而，这些新方法往往缺乏可靠性和可解释性，因此人们越来越关注如何在保持性能提升的同时解决这些问题。本研究通过重新审视由凸脊函数组成的规则化器来解决这个问题。这些规则化器的梯度由一个具有单个隐藏层的神经网络参数化，其中包含逐渐增加和可学习的激活函数。该神经网络作为多步高斯去噪器在几分钟内进行训练。去噪、CT和MRI重建的数值实验显示，与提供类似可靠性保证的方法相比，本方法具有改进。

    The emergence of deep-learning-based methods to solve image-reconstruction problems has enabled a significant increase in reconstruction quality. Unfortunately, these new methods often lack reliability and explainability, and there is a growing interest to address these shortcomings while retaining the boost in performance. In this work, we tackle this issue by revisiting regularizers that are the sum of convex-ridge functions. The gradient of such regularizers is parameterized by a neural network that has a single hidden layer with increasing and learnable activation functions. This neural network is trained within a few minutes as a multistep Gaussian denoiser. The numerical experiments for denoising, CT, and MRI reconstruction show improvements over methods that offer similar reliability guarantees.
    
[^107]: 反向核分解

    Inverse Kernel Decomposition. (arXiv:2211.05961v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05961](http://arxiv.org/abs/2211.05961)

    本文提出了一种新的非线性降维方法——逆核分解（IKD），通过特征值分解样本协方差矩阵实现。该方法受到高斯过程潜变量模型（GPLVMs）的启发，并在处理噪声数据方面提供了两种解决方案，具有良好的性能。

    

    最先进的降维方法在很大程度上依赖于复杂的优化过程。而仅需特征值分解的闭式方法在复杂性和非线性方面不够。在本文中，我们提出了一种新的非线性降维方法——逆核分解（IKD），基于数据的样本协方差矩阵的特征值分解。该方法受到高斯过程潜变量模型（GPLVMs）的启发，具有与GPLVMs相当的性能。为了处理具有较弱相关性的噪声数据，我们提出了两种解决方案——分块和测地线——以利用局部相关的数据点并提供更好和数值上更稳定的潜变量估计。我们使用合成数据集和四个真实数据集表明，IKD是一种比其他基于特征值分解的方法更好的降维方法，并且在优化方法方面具有相当的性能。

    The state-of-the-art dimensionality reduction approaches largely rely on complicated optimization procedures. On the other hand, closed-form approaches requiring merely eigen-decomposition do not have enough sophistication and nonlinearity. In this paper, we propose a novel nonlinear dimensionality reduction method -- Inverse Kernel Decomposition (IKD) -- based on an eigen-decomposition of the sample covariance matrix of data. The method is inspired by Gaussian process latent variable models (GPLVMs) and has comparable performance with GPLVMs. To deal with very noisy data with weak correlations, we propose two solutions -- blockwise and geodesic -- to make use of locally correlated data points and provide better and numerically more stable latent estimations. We use synthetic datasets and four real-world datasets to show that IKD is a better dimensionality reduction method than other eigen-decomposition-based methods, and achieves comparable performance against optimization-based metho
    
[^108]: 有不止一种稳健性：用对抗样本欺骗Whisper模型

    There is more than one kind of robustness: Fooling Whisper with adversarial examples. (arXiv:2210.17316v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.17316](http://arxiv.org/abs/2210.17316)

    本研究展示了Whisper模型虽然在分布外输入和随机噪声方面显示出了出色的稳健性，但却容易受到对抗干扰的影响。我们通过生成极小的输入扰动来大幅降低Whisper的性能，并对多语言模型的性能产生了影响。这些发现对于实际的安全问题和对抗性稳健ASR的需求具有重要意义。

    

    Whisper是一种最近的自动语音识别（ASR）模型，对于分布外输入和随机噪声都展示出了令人印象深刻的稳健性。在这项工作中，我们展示了这种稳健性在对抗干扰下并不适用。我们展示了通过生成极小的输入扰动（信噪比为35-45dB），我们可以大幅降低Whisper的性能，甚至转录我们选择的目标句子。我们还展示了通过欺骗Whisper语言检测器，我们可以轻松降低多语言模型的性能。这些对一个广受欢迎的开源模型的脆弱性具有实际的安全影响，并强调了对抗性稳健ASR的需求。

    Whisper is a recent Automatic Speech Recognition (ASR) model displaying impressive robustness to both out-of-distribution inputs and random noise. In this work, we show that this robustness does not carry over to adversarial noise. We show that we can degrade Whisper performance dramatically, or even transcribe a target sentence of our choice, by generating very small input perturbations with Signal Noise Ratio of 35-45dB. We also show that by fooling the Whisper language detector we can very easily degrade the performance of multilingual models. These vulnerabilities of a widely popular open-source model have practical security implications and emphasize the need for adversarially robust ASR.
    
[^109]: 深度学习中的数据分离定律

    A Law of Data Separation in Deep Learning. (arXiv:2210.17020v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.17020](http://arxiv.org/abs/2210.17020)

    深度学习中存在一个简单而定量的数据分离定律，每一层都以恒定的几何速率改善数据的分离程度。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。

    

    虽然深度学习在科学的许多领域取得了重大进展，但其黑盒特性阻碍了未来人工智能应用的架构设计和高风险决策的解释。我们通过研究深度神经网络在中间层中如何处理数据来解决这个问题。我们的发现是一个简单而定量的定律，它规定了深度神经网络如何根据类别成员将数据在所有层中分离出来进行分类。这个定律表明，每一层都以恒定的几何速率改善数据的分离程度，并且在训练过程中观察到了它的出现，无论是在一系列网络架构还是数据集上。这个定律为架构设计、提高模型的健壮性和样本外性能以及预测的解释提供了实际的指导。

    While deep learning has enabled significant advances in many areas of science, its black-box nature hinders architecture design for future artificial intelligence applications and interpretation for high-stakes decision makings. We addressed this issue by studying the fundamental question of how deep neural networks process data in the intermediate layers. Our finding is a simple and quantitative law that governs how deep neural networks separate data according to class membership throughout all layers for classification. This law shows that each layer improves data separation at a constant geometric rate, and its emergence is observed in a collection of network architectures and datasets during training. This law offers practical guidelines for designing architectures, improving model robustness and out-of-sample performance, as well as interpreting the predictions.
    
[^110]: 利用元数据和对比学习学习音频特征

    Learning Audio Features with Metadata and Contrastive Learning. (arXiv:2210.16192v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.16192](http://arxiv.org/abs/2210.16192)

    本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。在呼吸音分类数据集上，仅使用元数据学习表示可以获得与仅使用类标签的交叉熵相似的性能。在使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。

    This study uses supervised contrastive learning combined with available metadata to solve multiple pretext tasks that learn a good representation of data. Learning representations using only metadata obtains similar performance as using cross entropy with class labels only. State-of-the-art score is obtained when combining class labels with metadata using multiple supervised contrastive learning.

    基于注释的监督学习方法一直是分类问题的最先进技术，但是在低数据情况下，它们的泛化能力可能受到限制。本研究使用监督对比学习结合可用元数据解决多个前置任务，学习数据的良好表示。我们将我们的方法应用于ICBHI，这是一个适合这种情况的呼吸音分类数据集。我们表明，仅使用元数据学习表示，而不使用类标签，可以获得与仅使用这些标签的交叉熵相似的性能。此外，我们使用多个监督对比学习将类标签与元数据相结合时，获得了最先进的得分。这项工作表明，在监督对比设置中使用多个元数据源的潜力，特别是在类不平衡和少量数据的情况下。我们的代码已发布。

    Methods based on supervised learning using annotations in an end-to-end fashion have been the state-of-the-art for classification problems. However, they may be limited in their generalization capability, especially in the low data regime. In this study, we address this issue using supervised contrastive learning combined with available metadata to solve multiple pretext tasks that learn a good representation of data. We apply our approach on ICBHI, a respiratory sound classification dataset suited for this setting. We show that learning representations using only metadata, without class labels, obtains similar performance as using cross entropy with those labels only. In addition, we obtain state-of-the-art score when combining class labels with metadata using multiple supervised contrastive learning. This work suggests the potential of using multiple metadata sources in supervised contrastive settings, in particular in settings with class imbalance and few data. Our code is released 
    
[^111]: 通过虚拟光台和合成到实际适应学习对肖像图像重新照明

    Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation. (arXiv:2209.10510v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.10510](http://arxiv.org/abs/2209.10510)

    这个论文提出了一种在不需要光台的情况下进行肖像图像重新照明的方法，并能够与最先进的方法相媲美。该方法基于物理原理，并能够产生高质量的结果。

    

    给定一个人的肖像图像和目标照明的环境图，肖像照明旨在重新照明图像中的人物，好像该人出现在具有目标照明的环境中。为了实现高质量的结果，最近的方法依赖于深度学习。一种有效的方法是使用具有高保真度的输入-输出配对的数据集来监督训练深度神经网络，该数据集是利用光台捕捉到的。然而，获取这样的数据需要昂贵的特殊捕捉设备和耗时的努力，限制只有少数资源丰富的实验室才能使用。为了解决这个限制，我们提出了一种新的方法，可以在不需要光台的情况下与最先进的重新照明方法相媲美。我们的方法基于一个认识，即肖像图像的成功重新照明取决于两个条件。首先，该方法需要模仿基于物理原理的重新照明的行为。其次，输出必须是照片质量的。

    Given a portrait image of a person and an environment map of the target lighting, portrait relighting aims to re-illuminate the person in the image as if the person appeared in an environment with the target lighting. To achieve high-quality results, recent methods rely on deep learning. An effective approach is to supervise the training of deep neural networks with a high-fidelity dataset of desired input-output pairs, captured with a light stage. However, acquiring such data requires an expensive special capture rig and time-consuming efforts, limiting access to only a few resourceful laboratories. To address the limitation, we propose a new approach that can perform on par with the state-of-the-art (SOTA) relighting methods without requiring a light stage. Our approach is based on the realization that a successful relighting of a portrait image depends on two conditions. First, the method needs to mimic the behaviors of physically-based relighting. Second, the output has to be photo
    
[^112]: 自监督坐标投影网络用于稀疏视角计算机体层摄影的翻译标题

    Self-Supervised Coordinate Projection Network for Sparse-View Computed Tomography. (arXiv:2209.05483v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.05483](http://arxiv.org/abs/2209.05483)

    本文提出了一种自监督坐标投影网络（SCOPE），通过引入重投影策略改善了稀疏视角计算机体层摄影的图像重建质量。

    

    在本研究中，我们提出了一种自监督坐标投影网络（SCOPE），通过解决逆体层摄影成像问题从单个稀疏视角正弦图中重建无伪影的CT图像。与最近使用隐式神经表示网络（INR）解决类似问题的相关工作相比，我们的主要贡献是一种有效而简单的重投影策略，能够提高监督式深度学习CT重建工作的摄影图像重建质量。所提出的策略受到线性代数和逆问题之间简单关系的启发。为了解决欠定线性方程组，我们首先引入INR通过图像连续性先验约束解空间并获得粗糙解。其次，我们提出生成一种密集视角正弦图，以改善线性方程组的秩，并产生更稳定的CT图像解空间。我们的实验结果表明，重新投影策略可以显著改善稀疏视角CT图像的重建质量。

    In the present work, we propose a Self-supervised COordinate Projection nEtwork (SCOPE) to reconstruct the artifacts-free CT image from a single SV sinogram by solving the inverse tomography imaging problem. Compared with recent related works that solve similar problems using implicit neural representation network (INR), our essential contribution is an effective and simple re-projection strategy that pushes the tomography image reconstruction quality over supervised deep learning CT reconstruction works. The proposed strategy is inspired by the simple relationship between linear algebra and inverse problems. To solve the under-determined linear equation system, we first introduce INR to constrain the solution space via image continuity prior and achieve a rough solution. And secondly, we propose to generate a dense view sinogram that improves the rank of the linear equation system and produces a more stable CT image solution space. Our experiment results demonstrate that the re-projec
    
[^113]: 通过对抗学习和联合时空嵌入增强交通预测的鲁棒性

    Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting. (arXiv:2208.03063v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03063](http://arxiv.org/abs/2208.03063)

    通过对抗学习和联合时空嵌入，我们提出了TrendGCN来增强交通预测的鲁棒性，该模型能够平衡动态性和鲁棒性，并在处理具有统计相关性的顺序数据时表现出较好的效果。

    

    交通预测是城市规划和计算中的一个重要问题。交通对象（例如传感器和道路段）之间存在复杂的动态时空依赖关系，这要求使用高度灵活的模型。然而，复杂模型在捕捉时间序列趋势（一阶导数随时间变化）方面可能表现出较差的鲁棒性，从而导致不现实的预测结果。为解决动态性和鲁棒性的平衡难题，我们提出了TrendGCN，这是一种新的方案，扩展了GCN的灵活性和生成对抗损失的分布保持能力，用于处理具有固有统计相关性的顺序数据。我们的模型同时结合了空间（节点级）嵌入和时间（时间级）嵌入，以考虑异质的时空卷积；同时，它使用GAN结构来系统评估实际数据和预测数据之间的统计一致性。

    Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the pre
    
[^114]: 这个模型有多少扰动会破坏它？评估超越对抗准确度的鲁棒性。

    How many perturbations break this model? Evaluating robustness beyond adversarial accuracy. (arXiv:2207.04129v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04129](http://arxiv.org/abs/2207.04129)

    这项工作介绍了一种评估神经网络鲁棒性的替代方法-对抗稀疏性，它量化了成功扰动的难度。稀疏性揭示了鲁棒模型之间的重要差异并提出了改进鲁棒性的方法。

    

    对抗攻击的鲁棒性通常通过对抗准确度来评估。然而，这个度量标准并不能完全捕捉到鲁棒性的所有方面，尤其是忽略了针对每个数据点可以找到多少扰动的问题。在这项工作中，我们引入了一种替代方法，即对抗稀疏性，它量化了在给定输入点和扰动方向约束的情况下找到成功扰动的难度。我们展示了稀疏性在多个方面对神经网络提供了有价值的洞察力：例如，它揭示了当前最先进的鲁棒模型之间的重要差异，这是精确度分析所不具备的，并且提出了提高它们鲁棒性的方法。当应用对弱攻击有效但对强攻击无效的破解防御时，稀疏性可以区分完全无效和部分有效的防御。最后，通过稀疏性，我们可以度量鲁棒性的增加。

    Robustness to adversarial attacks is typically evaluated with adversarial accuracy. While essential, this metric does not capture all aspects of robustness and in particular leaves out the question of how many perturbations can be found for each point. In this work, we introduce an alternative approach, adversarial sparsity, which quantifies how difficult it is to find a successful perturbation given both an input point and a constraint on the direction of the perturbation. We show that sparsity provides valuable insight into neural networks in multiple ways: for instance, it illustrates important differences between current state-of-the-art robust models them that accuracy analysis does not, and suggests approaches for improving their robustness. When applying broken defenses effective against weak attacks but not strong ones, sparsity can discriminate between the totally ineffective and the partially effective defenses. Finally, with sparsity we can measure increases in robustness th
    
[^115]: HRFuser: 一种用于二维物体检测的多分辨率传感器融合架构

    HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object Detection. (arXiv:2206.15157v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.15157](http://arxiv.org/abs/2206.15157)

    HRFuser是一种多分辨率传感器融合架构，可用于二维物体检测，基于高分辨率网络和新型多窗口交叉注意力块进行多模态多分辨率融合。在nuScenes和DENSE上的实验证明了其有效性。

    

    自动驾驶车辆除了标准相机外，通常还包括多个其他传感器，如激光雷达和雷达，这些传感器帮助获取感知驾驶场景的更丰富信息。虽然最近有几项工作着重于将某些传感器对进行融合，如相机与激光雷达或雷达，但缺乏一种通用且模块化的传感器融合架构。在本文中，我们提出了HRFuser，一种多模态二维物体检测的模块化架构。它以多分辨率方式融合多个传感器并可扩展到任意数量的输入模式。HRFuser的设计基于用于仅图像密集预测的最先进高分辨率网络，并采用新型的多窗口交叉注意力块作为执行多模态多分辨率融合的手段。通过对nuScenes和恶劣条件DENSE进行的大量实验，我们证明了HRFuser的有效性。

    Besides standard cameras, autonomous vehicles typically include multiple additional sensors, such as lidars and radars, which help acquire richer information for perceiving the content of the driving scene. While several recent works focus on fusing certain pairs of sensors - such as camera with lidar or radar - by using architectural components specific to the examined setting, a generic and modular sensor fusion architecture is missing from the literature. In this work, we propose HRFuser, a modular architecture for multi-modal 2D object detection. It fuses multiple sensors in a multi-resolution fashion and scales to an arbitrary number of input modalities. The design of HRFuser is based on state-of-the-art high-resolution networks for image-only dense prediction and incorporates a novel multi-window cross-attention block as the means to perform fusion of multiple modalities at multiple resolutions. We demonstrate via extensive experiments on nuScenes and the adverse conditions DENSE
    
[^116]: ECLAD: 使用本地聚合描述符提取概念

    ECLAD: Extracting Concepts with Local Aggregated Descriptors. (arXiv:2206.04531v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.04531](http://arxiv.org/abs/2206.04531)

    本文提出了一种使用本地聚合描述符提取概念的方法，并介绍了一种基于合成数据集的验证过程，用于减少概念提取方法的人工干预需求。

    

    卷积神经网络（CNN）在关键系统中的应用越来越多，其中鲁棒性和对齐性至关重要。在这个背景下，可解释的人工智能领域提出了通过概念提取来生成CNN预测过程的高级解释。虽然这些方法可以检测图像中是否存在概念，但无法确定其位置。此外，由于缺乏适当的验证程序，很难对这些方法进行公平比较。为了解决这些问题，我们提出了一种基于CNN激活图像的像素聚合表示的自动概念提取和定位方法。此外，我们引入了一种基于合成数据集的概念提取技术验证过程，该数据集具有其主要组件的像素注释，减少了人工干预的需求。我们在合成和真实数据上进行了广泛的实验验证。

    Convolutional neural networks (CNNs) are increasingly being used in critical systems, where robustness and alignment are crucial. In this context, the field of explainable artificial intelligence has proposed the generation of high-level explanations of the prediction process of CNNs through concept extraction. While these methods can detect whether or not a concept is present in an image, they are unable to determine its location. What is more, a fair comparison of such approaches is difficult due to a lack of proper validation procedures. To address these issues, we propose a novel method for automatic concept extraction and localization based on representations obtained through pixel-wise aggregations of CNN activation maps. Further, we introduce a process for the validation of concept-extraction techniques based on synthetic datasets with pixel-wise annotations of their main components, reducing the need for human intervention. Extensive experimentation on both synthetic and real-w
    
[^117]: 可训练的权重平均值：子空间训练的一般方法

    Trainable Weight Averaging: A General Approach for Subspace Training. (arXiv:2205.13104v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13104](http://arxiv.org/abs/2205.13104)

    可训练的权重平均值是一种通用的子空间训练方法，通过连接子空间训练和权重平均值，提供高效的训练和易于使用的方法。这种方法可以用于改进神经网络训练效果和降低计算负担。

    

    在低维子空间中训练深度神经网络(DNNs)是实现高效训练和更好的泛化性能的一个有前景的方向。以往的工作通过使用随机投影或在训练轨迹上执行降维方法来提取子空间，但这些方法在维度和数值运算方面可能效率低下或不稳定。在本文中，我们将子空间训练与权重平均值联系起来，并提出了可训练权重平均值(TWA)，这是一种泛化以前努力的子空间训练的一般方法。TWA在维度方面具有高效性，并且易于使用，使其成为一种有前景的子空间训练新方法。我们进一步设计了一个有效的方案来应对大规模问题的子空间训练，它允许多个节点上的并行训练，并将内存和计算负担均匀分配给每个节点。我们将TWA应用于高效的神经网络训练和改进

    Training deep neural networks (DNNs) in low-dimensional subspaces is a promising direction for achieving efficient training and better generalization performance. Previous works extract the subspaces by using random projection or performing dimensionality reduction method on the training trajectory, but these methods can be inefficient or unstable in terms of dimensionality and numerical operations. In this paper, we connect subspace training to weight averaging and propose Trainable Weight Averaging (TWA), a general approach for subspace training that generalizes the previous efforts. TWA is efficient in terms of dimensionality and also easy to use, making it a promising new method for subspace training. We further design an efficient scheme for subspace training to cope with large-scale problems, which allows parallel training across multiple nodes and evenly distributing the memory and computation burden to each node. We apply TWA to efficient neural network training and improving f
    
[^118]: 多视图无监督特征选择与图学习的联合方法

    Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.08247](http://arxiv.org/abs/2204.08247)

    本文提出了一种联合多视图无监督特征选择和图学习的方法，通过正交分解建模多视图特征选择，应用跨空间局部保持进行聚类结构学习和相似性学习的连接。

    

    尽管取得了一定的进展，但之前的多视图无监督特征选择方法主要存在两个限制。首先，它们通常使用聚类结构或相似性结构来指导特征选择，忽略了联合公式可能带来的互惠效益。其次，它们通常通过全局结构学习或局部结构学习来学习相似性结构，缺乏同时具备全局和局部结构感知的图学习能力。鉴于此，本文提出了一种联合多视图无监督特征选择和图学习的方法（JMVFG）。具体而言，我们采用正交分解对多视图特征选择进行建模，其中每个目标矩阵被分解为一个视图特定的基矩阵和一个视图一致的聚类指示器。跨空间局部保持被应用于在投影空间中进行聚类结构学习和相似性学习的连接。

    Despite significant progress, previous multi-view unsupervised feature selection methods mostly suffer from two limitations. First, they generally utilize either cluster structure or similarity structure to guide the feature selection, which neglect the possibility of a joint formulation with mutual benefits. Second, they often learn the similarity structure by either global structure learning or local structure learning, which lack the capability of graph learning with both global and local structural awareness. In light of this, this paper presents a joint multi-view unsupervised feature selection and graph learning (JMVFG) approach. Particularly, we formulate the multi-view feature selection with orthogonal decomposition, where each target matrix is decomposed into a view-specific basis matrix and a view-consistent cluster indicator. The cross-space locality preservation is incorporated to bridge the cluster structure learning in the projected space and the similarity learning (i.e.
    
[^119]: Con$^{2}$DA：通过学习一致性和对比特征表示简化半监督领域自适应

    Con$^{2}$DA: Simplifying Semi-supervised Domain Adaptation by Learning Consistent and Contrastive Feature Representations. (arXiv:2204.01558v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.01558](http://arxiv.org/abs/2204.01558)

    Con$^{2}$DA是一个简单的框架，通过学习一致性和对比特征表示，解决了半监督领域自适应问题，并实现了最先进的性能。

    

    在这项工作中，我们提出了Con$^{2}$DA，一个简单的框架，将半监督学习的最新进展扩展到半监督领域自适应问题。我们的框架通过对给定输入进行随机数据转换生成配对的相关样本。关联的数据对通过特征提取器映射到特征表示空间。我们使用不同的损失函数来强制保持关联数据对样本的特征表示一致性。我们展示了这些学到的表示对于处理领域自适应问题中的数据分布差异是有用的。我们进行了实验来研究我们模型的主要组件，并展示了：(i) 学习一致性和对比特征表示对于跨不同领域提取好的判别特征至关重要，和(ii) 我们的模型从使用强数据增强策略中获益。基于这些发现，我们的方法实现了最先进的水平。

    In this work, we present Con$^{2}$DA, a simple framework that extends recent advances in semi-supervised learning to the semi-supervised domain adaptation (SSDA) problem. Our framework generates pairs of associated samples by performing stochastic data transformations to a given input. Associated data pairs are mapped to a feature representation space using a feature extractor. We use different loss functions to enforce consistency between the feature representations of associated data pairs of samples. We show that these learned representations are useful to deal with differences in data distributions in the domain adaptation problem. We performed experiments to study the main components of our model and we show that (i) learning of the consistent and contrastive feature representations is crucial to extract good discriminative features across different domains, and ii) our model benefits from the use of strong augmentation policies. With these findings, our method achieves state-of-t
    
[^120]: 图形神经网络在概率误差模型下的敏感性

    Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.07831](http://arxiv.org/abs/2203.07831)

    本文研究了概率误差模型对图卷积网络（GCN）性能的影响，并证明了误差模型下邻接矩阵的受限性。通过实验验证了这种误差界限，并研究了GCN在这种概率误差模型下的准确性敏感性。

    

    图卷积网络（GCN）可以通过图卷积成功学习图信号表示。图卷积依赖于图滤波器，其中包含数据的拓扑依赖关系并传播数据特征。然而，在传播矩阵（例如邻接矩阵）中的估计误差可能对图滤波器和GCNs产生重大影响。本文研究概率图误差模型对GCN性能的影响。我们证明了在误差模型下的邻接矩阵受到图大小和误差概率函数的限制。我们进一步分析了带有自循环的归一化邻接矩阵的上界。最后，我们通过在合成数据集上运行实验来说明误差界限，并研究简单GCN在这种概率误差模型下的准确性敏感性。

    Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.
    
[^121]: 鲁棒性图表示学习用于本地错误恢复

    Robust Graph Representation Learning for Local Corruption Recovery. (arXiv:2202.04936v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04936](http://arxiv.org/abs/2202.04936)

    该论文提出了一种鲁棒性图表示学习的方法，通过检测局部异常和恢复鲁棒嵌入来提升预测任务的准确性。使用图自编码器进行检测操作，通过稀疏促进正则化恢复鲁棒估计。实验证明该方法能够在黑盒攻击下恢复鲁棒的图表示并取得优秀的预测性能。

    

    图表示学习的性能受到图输入质量的影响。现有的研究通常追求全局平滑的图嵌入，然而我们认为很少观察到的异常同样对准确预测有害。本研究建立了一个图学习方案，自动检测（局部）损坏的特征属性，并为预测任务恢复鲁棒嵌入。检测操作利用图自编码器，不对本地损坏的分布做任何假设。它在一个无偏的掩码矩阵中定位异常节点属性的位置，通过稀疏促进正则化恢复鲁棒估计。优化器接近于在Framelet域中稀疏且在输入观测条件下接近的新嵌入。大量实验证明我们提出的模型能够从黑盒中恢复鲁棒的图表示并实现异常污染下的优秀预测性能。

    The performance of graph representation learning is affected by the quality of graph input. While existing research usually pursues a globally smoothed graph embedding, we believe the rarely observed anomalies are as well harmful to an accurate prediction. This work establishes a graph learning scheme that automatically detects (locally) corrupted feature attributes and recovers robust embedding for prediction tasks. The detection operation leverages a graph autoencoder, which does not make any assumptions about the distribution of the local corruptions. It pinpoints the positions of the anomalous node attributes in an unbiased mask matrix, where robust estimations are recovered with sparsity promoting regularizer. The optimizer approaches a new embedding that is sparse in the framelet domain and conditionally close to input observations. Extensive experiments are provided to validate our proposed model can recover a robust graph representation from black-box poisoning and achieve exce
    
[^122]: Oracle Teacher: 利用目标信息更好地进行基于CTC模型的知识蒸馏

    Oracle Teacher: Leveraging Target Information for Better Knowledge Distillation of CTC Models. (arXiv:2111.03664v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.03664](http://arxiv.org/abs/2111.03664)

    Oracle Teacher是一种新型教师模型，利用基于CTC的序列模型的目标信息来提供更准确的指导，以实现更好的知识蒸馏效果。

    

    知识蒸馏（KD）是一种有效的模型压缩方法，旨在将更大的网络（教师）的知识传递给更小的网络（学生）。传统的KD方法通常使用以监督方式训练的教师模型，其中输出标签仅被视为目标。在进一步扩展这种监督方案的基础上，我们引入了一种针对基于连接主义时序分类（CTC）的序列模型的新类型教师模型，即Oracle Teacher，该模型利用源输入和输出标签作为教师模型的输入。由于Oracle Teacher通过参考目标信息学习更准确的CTC对齐，因此它可以为学生提供更优化的指导。所提出方法的一个潜在风险是模型的输出直接复制目标输入。基于CTC算法的多对一映射特性，我们提出了一种训练策略，可以有效防止这种情况的发生。

    Knowledge distillation (KD), best known as an effective method for model compression, aims at transferring the knowledge of a bigger network (teacher) to a much smaller network (student). Conventional KD methods usually employ the teacher model trained in a supervised manner, where output labels are treated only as targets. Extending this supervised scheme further, we introduce a new type of teacher model for connectionist temporal classification (CTC)-based sequence models, namely Oracle Teacher, that leverages both the source inputs and the output labels as the teacher model's input. Since the Oracle Teacher learns a more accurate CTC alignment by referring to the target information, it can provide the student with more optimal guidance. One potential risk for the proposed approach is a trivial solution that the model's output directly copies the target input. Based on a many-to-one mapping property of the CTC algorithm, we present a training strategy that can effectively prevent the
    
[^123]: 选择聚类数目、聚类模型和算法：基于二次判别得分的统一方法

    Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score. (arXiv:2111.02302v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2111.02302](http://arxiv.org/abs/2111.02302)

    本文提出了一种基于二次判别得分的统一方法，用于选择聚类数目、聚类模型和算法。我们定义了基于二次判别得分函数和参数的参考聚类概念，并开发了两个一致性准则。这种方法适用于可以通过二次或线性边界很好分隔的群组，对于应用中寻找这种类型的群组很有帮助。

    

    聚类分析需要做出许多决策：聚类方法和隐含的参考模型、聚类数目，以及通常还有一些超参数和算法的调整。在实践中，我们会得到多个划分，最终根据验证或选择准则选择一个最终的划分。存在大量的验证方法，它们隐式或显式地假设某种聚类概念。此外，它们常常被限制在特定方法得到的划分上进行操作。本文聚焦于可以通过二次或线性边界很好分隔的群组。基于二次判别得分函数和描述聚类大小、中心和散布的参数，我们定义了参考聚类概念。我们开发了两个聚类质量准则，称为二次得分。我们展示了这些准则与一般类别的椭圆对称分布生成的群组一致。在应用中，寻找这种类型的群组是常见的。

    Cluster analysis requires many decisions: the clustering method and the implied reference model, the number of clusters and, often, several hyper-parameters and algorithms' tunings. In practice, one produces several partitions, and a final one is chosen based on validation or selection criteria. There exist an abundance of validation methods that, implicitly or explicitly, assume a certain clustering notion. Moreover, they are often restricted to operate on partitions obtained from a specific method. In this paper, we focus on groups that can be well separated by quadratic or linear boundaries. The reference cluster concept is defined through the quadratic discriminant score function and parameters describing clusters' size, center and scatter. We develop two cluster-quality criteria called quadratic scores. We show that these criteria are consistent with groups generated from a general class of elliptically-symmetric distributions. The quest for this type of groups is common in applic
    
[^124]: 基于相似性映射的神经模型重编程用于低资源口语命令分类

    Neural Model Reprogramming with Similarity Based Mapping for Low-Resource Spoken Command Classification. (arXiv:2110.03894v4 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2110.03894](http://arxiv.org/abs/2110.03894)

    本文提出了一种基于相似性映射的神经模型重编程方法，用于低资源口语命令分类。实验证明，在有限的数据条件下，该方法在阿拉伯语和立陶宛语命令数据集上表现优于当前最先进的结果。

    

    本研究提出了一种新颖的对抗重编程（AR）方法，用于低资源口语命令识别（SCR），并构建了一个AR-SCR系统。AR过程旨在修改来自目标领域的声学信号，以重新调整预训练的SCR模型，从而实现重编程。为了解决源域和目标域之间的标签不匹配问题，并进一步提高AR的稳定性，我们提出了一种新颖的基于相似性的标签映射技术来对齐类别。此外，将迁移学习（TL）技术与原始AR过程相结合，以提高模型的适应能力。我们在三个低资源SCR数据集上评估了提出的AR-SCR系统，包括阿拉伯语、立陶宛语和言语障碍性普通话。实验结果表明，在大规模英语数据集上训练的预训练AM的基础上，提出的AR-SCR系统在阿拉伯语和立陶宛语命令数据集上表现优于当前最先进的结果，且仅使用有限数量的数据。

    In this study, we propose a novel adversarial reprogramming (AR) approach for low-resource spoken command recognition (SCR), and build an AR-SCR system. The AR procedure aims to modify the acoustic signals (from the target domain) to repurpose a pretrained SCR model (from the source domain). To solve the label mismatches between source and target domains, and further improve the stability of AR, we propose a novel similarity-based label mapping technique to align classes. In addition, the transfer learning (TL) technique is combined with the original AR process to improve the model adaptation capability. We evaluate the proposed AR-SCR system on three low-resource SCR datasets, including Arabic, Lithuanian, and dysarthric Mandarin speech. Experimental results show that with a pretrained AM trained on a large-scale English dataset, the proposed AR-SCR system outperforms the current state-of-the-art results on Arabic and Lithuanian speech commands datasets, with only a limited amount of 
    
[^125]: 结合机器学习分类器与有效的特征提取进行股票交易

    Combining Machine Learning Classifiers for Stock Trading with Effective Feature Extraction. (arXiv:2107.13148v3 [q-fin.TR] UPDATED)

    [http://arxiv.org/abs/2107.13148](http://arxiv.org/abs/2107.13148)

    该论文研究了结合机器学习分类器和有效特征提取进行股票交易的方法。通过性能筛选出最佳特征，并使用集成学习的四个分类器进行交易决策。最佳模型在2011年7月至2019年1月期间每日交易中获得了54.35%的利润。

    

    股票市场的不可预测性和波动性使得用任何泛化方案获得可观利润变得具有挑战性。许多先前的研究尝试使用不同的技术构建机器学习模型，通过实时交易在美国股市中获得可观利润。然而，很少有研究关注找到特定交易期间的最佳特征的重要性。我们的最佳方法通过性能来将特征从148个缩小到约30个。此外，在每次训练机器学习模型之前，我们会动态选择前25个特征。它使用了四个分类器的集成学习：高斯朴素贝叶斯、决策树、具有L1正则化的逻辑回归和随机梯度下降，以决定是否对特定股票进行做多或做空交易。我们的最佳模型在2011年7月至2019年1月之间进行每日交易，获得了54.35%的利润。最后，我们的工作展示了混合机器学习分类器与有效特征提取在股票交易中的应用潜力。

    The unpredictability and volatility of the stock market render it challenging to make a substantial profit using any generalised scheme. Many previous studies tried different techniques to build a machine learning model, which can make a significant profit in the US stock market by performing live trading. However, very few studies have focused on the importance of finding the best features for a particular trading period. Our top approach used the performance to narrow down the features from a total of 148 to about 30. Furthermore, the top 25 features were dynamically selected before each time training our machine learning model. It uses ensemble learning with four classifiers: Gaussian Naive Bayes, Decision Tree, Logistic Regression with L1 regularization, and Stochastic Gradient Descent, to decide whether to go long or short on a particular stock. Our best model performed daily trade between July 2011 and January 2019, generating 54.35% profit. Finally, our work showcased that mixtu
    
[^126]: 限制线性链条件随机场到正则语言的方法

    Constraining Linear-chain CRFs to Regular Languages. (arXiv:2106.07306v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.07306](http://arxiv.org/abs/2106.07306)

    本文提出了一种将线性链条件随机场（CRFs）限制到正则语言的方法，该方法可以对广泛的约束进行建模，并允许在训练过程中引入这些约束。

    

    结构预测中的一个重要挑战是表示输出结构中的相互依赖关系。当输出以序列形式结构化时，线性链条件随机场（CRFs）是一种广泛使用的模型类，可以学习输出中的“局部”依赖关系。然而，CRF的马尔可夫假设使得CRFs无法表示具有“非局部”依赖关系的分布，并且标准CRFs无法满足数据的非局部约束（例如输出标签的全局性约束）。我们提出了一种CRFs的推广形式，可以通过将可能的输出结构空间指定为正则语言$\mathcal{L}$来强制执行广泛的约束，包括非局部约束。结果的正则约束CRF（RegCCRF）具有与标准CRF相同的形式属性，但对于不在$\mathcal{L}$中的所有标签序列分配零概率。值得注意的是，RegCCRFs可以在训练过程中引入约束，与相关模型不同。

    A major challenge in structured prediction is to represent the interdependencies within output structures. When outputs are structured as sequences, linear-chain conditional random fields (CRFs) are a widely used model class which can learn \textit{local} dependencies in the output. However, the CRF's Markov assumption makes it impossible for CRFs to represent distributions with \textit{nonlocal} dependencies, and standard CRFs are unable to respect nonlocal constraints of the data (such as global arity constraints on output labels). We present a generalization of CRFs that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language $\mathcal{L}$. The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in $\mathcal{L}$. Notably, RegCCRFs can incorporate their constraints during training, while related models
    
[^127]: 通过深度强化学习实现鲁棒性四足跳跃

    Robust Quadruped Jumping via Deep Reinforcement Learning. (arXiv:2011.07089v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2011.07089](http://arxiv.org/abs/2011.07089)

    通过深度强化学习，本文提出了一种鲁棒的四足跳跃方法，可以在嘈杂环境中跳跃不同距离和高度，并能应对不平坦地形和可变机器人动力学参数的挑战。

    

    本文针对四足机器人在嘈杂环境中跳跃不同距离和高度的一般任务进行了研究，如不平坦地形和可变机器人动力学参数。为了在这样的条件下准确跳跃，我们提出了一种利用深度强化学习的框架，该框架借鉴并增强了四足跳跃的非线性轨迹优化的复杂解决方案。与独立优化方法相比，该方法不仅限制了跳跃起跳点必须在平坦地面上，还要求准确的机器人动力学假设。我们的方法改进了对极不平坦地形和可变机器人动力学参数以及环境条件的跳跃鲁棒性。与行走和奔跑相比，在硬件上实现积极跳跃需要考虑电机的扭矩-速度关系以及机器人的总功率限制。通过将这些约束条件纳入我们的学习框架中，我们成功地部署了我们的方法。

    In this paper, we consider a general task of jumping varying distances and heights for a quadrupedal robot in noisy environments, such as off of uneven terrain and with variable robot dynamics parameters. To accurately jump in such conditions, we propose a framework using deep reinforcement learning that leverages and augments the complex solution of nonlinear trajectory optimization for quadrupedal jumping. While the standalone optimization limits jumping to take-off from flat ground and requires accurate assumptions of robot dynamics, our proposed approach improves the robustness to allow jumping off of significantly uneven terrain with variable robot dynamical parameters and environmental conditions. Compared with walking and running, the realization of aggressive jumping on hardware necessitates accounting for the motors' torque-speed relationship as well as the robot's total power limits. By incorporating these constraints into our learning framework, we successfully deploy our po
    
[^128]: 量化异构转移的精确高维渐近分析

    Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers. (arXiv:2010.11750v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.11750](http://arxiv.org/abs/2010.11750)

    本文利用随机矩阵理论在线性回归设置中，对于具有两个任务的高维情况下的常用估计量的超额风险进行了精确渐近分析。

    

    最近，学习一个任务时使用来自另一个任务的样本的问题引起了广泛关注。本文提出了一个基本问题：什么时候将来自两个任务的数据合并比单独学习一个任务更好？直观上，从一个任务到另一个任务的转移效应取决于数据集的转移，如样本大小和协方差矩阵。然而，量化这种转移效应是具有挑战性的，因为我们需要比较联合学习和单任务学习之间的风险，并且一个任务是否比另一个任务具有比较优势取决于两个任务之间确切的数据集转移类型。本文利用随机矩阵理论在具有两个任务的线性回归设置中解决了这一挑战。我们给出了在高维情况下一些常用估计量的超额风险的精确渐近分析，当样本大小与特征维度成比例增加时，固定比例。精确渐近分析以样本大小的函数形式给出。

    The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes 
    
[^129]: 一种用于逃逸训练GAN中的极限周期的方法

    A method for escaping limit cycles in training GANs. (arXiv:2010.03322v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2010.03322](http://arxiv.org/abs/2010.03322)

    本文提出了一种用于逃逸训练GAN中的极限周期的方法，通过预测离心加速度算法（PCAA）和自适应矩估计算法（Adam）相结合，有效改善了训练过程中的极限周期行为问题。

    

    本文通过提出的预测离心加速度算法（PCAA），对训练生成对抗网络（GANs）中极限周期行为问题进行深入研究。具体而言，我们首先推导了PCAA在一般双线性博弈的最后迭代收敛速率的上下界，在上界方面得到了显著改进。然后，我们将PCAA与自适应矩估计算法（Adam）相结合，提出了一种用于训练GANs的实用方法PCAA-Adam。最后，我们通过在双线性博弈、多元高斯分布和CelebA数据集上进行的实验证明了所提出算法的有效性。

    This paper mainly conducts further research to alleviate the issue of limit cycling behavior in training generative adversarial networks (GANs) through the proposed predictive centripetal acceleration algorithm (PCAA). Specifically, we first derive the upper and lower bounds on the last-iterate convergence rates of PCAA for the general bilinear game, with the upper bound notably improving upon previous results. Then, we combine PCAA with the adaptive moment estimation algorithm (Adam) to propose PCAA-Adam, a practical approach for training GANs. Finally, we validate the effectiveness of the proposed algorithm through experiments conducted on bilinear games, multivariate Gaussian distributions, and the CelebA dataset, respectively.
    
[^130]: 具有类人类树突激活的非线性神经元

    Non-linear Neurons with Human-like Apical Dendrite Activations. (arXiv:2003.03229v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2003.03229](http://arxiv.org/abs/2003.03229)

    本论文提出了一种新的人工神经元模型和激活函数，通过使用单个神经元学习非线性决策边界，并在多个基准数据集上取得了优于传统方法的结果。

    

    为了对线性不可分的数据进行分类，通常将神经元组织成至少包含一个隐藏层的多层神经网络。受神经科学的一些最新发现的启发，我们提出了一种新的人工神经元模型和一种新颖的激活函数，可使用单个神经元学习非线性决策边界。我们展示了一个标准神经元接上我们的新型树突激活函数（ADA）可以以100%的准确率学习XOR逻辑函数。此外，我们对计算机视觉、信号处理和自然语言处理领域的六个基准数据集进行了实验，即MOROCO、UTKFace、CREMA-D、Fashion-MNIST、Tiny ImageNet和ImageNet，结果显示ADA和漏电ADA函数在各种神经网络结构（如一层或两层隐藏层的多层感知机和卷积神经网络）上优于修正线性单元（ReLU）、漏电ReLU、径向基函数（RBF）和Swish。

    In order to classify linearly non-separable data, neurons are typically organized into multi-layer neural networks that are equipped with at least one hidden layer. Inspired by some recent discoveries in neuroscience, we propose a new model of artificial neuron along with a novel activation function enabling the learning of nonlinear decision boundaries using a single neuron. We show that a standard neuron followed by our novel apical dendrite activation (ADA) can learn the XOR logical function with 100% accuracy. Furthermore, we conduct experiments on six benchmark data sets from computer vision, signal processing and natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST, Tiny ImageNet and ImageNet, showing that the ADA and the leaky ADA functions provide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF and Swish, for various neural network architectures, e.g. one-hidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) and convolutional ne
    
[^131]: B位量化下的非参数推断

    Nonparametric Inference under B-bits Quantization. (arXiv:1901.08571v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/1901.08571](http://arxiv.org/abs/1901.08571)

    本文提出了一种基于B位量化的非参数推断方法，通过一种高效的算法对样本进行量化处理。结果表明，当B超过阈值时，所提出的方法在样条模型中能够达到经典极小极值率的测试水平。另外，本文还拓展了方法的适用性，包括非参数直线性检验和自适应非参数检验。通过广泛的模拟研究和实际数据分析，证明了方法的有效性和效果。

    

    在信号/图像处理、医学图像存储、遥感、信号传输等研究领域中，常常需要基于有损或不完整样本的统计推断。本文提出了一种基于经计算效率高的算法对样本进行B位量化的非参数检验程序。在一些温和技术条件下，我们建立了所提出的检验统计量的渐近性质，并研究了检验功率在B增加时的变化。特别地，我们表明如果B超过某个阈值，则所提出的非参数检验程序在样条模型中实现了经典极小极值率的测试（Shang和Cheng，2015）。我们还进一步将理论研究扩展到了非参数直线性检验和自适应非参数检验，拓展了所提方法的适用性。我们使用广泛的模拟研究和实际数据分析来证明所提方法的有效性和效果。

    Statistical inference based on lossy or incomplete samples is often needed in research areas such as signal/image processing, medical image storage, remote sensing, signal transmission. In this paper, we propose a nonparametric testing procedure based on samples quantized to $B$ bits through a computationally efficient algorithm. Under mild technical conditions, we establish the asymptotic properties of the proposed test statistic and investigate how the testing power changes as $B$ increases. In particular, we show that if $B$ exceeds a certain threshold, the proposed nonparametric testing procedure achieves the classical minimax rate of testing (Shang and Cheng, 2015) for spline models. We further extend our theoretical investigations to a nonparametric linearity test and an adaptive nonparametric test, expanding the applicability of the proposed methods. Extensive simulation studies {together with a real-data analysis} are used to demonstrate the validity and effectiveness of the pr
    

