# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations.](http://arxiv.org/abs/2401.13662) | 本文提供了一个深度强化学习中策略梯度算法的综合指南，包括理论基础、实际实现和比较结果，并对正则化的益处进行了讨论。 |
| [^2] | [MambaByte: Token-free Selective State Space Model.](http://arxiv.org/abs/2401.13660) | MambaByte是一种无标记的选择性状态空间模型，通过在字节级别上进行自回归训练，解决了标准自回归Transformer在处理长序列时的性能问题，并展现了与最先进的子词Transformer相媲美甚至更优的性能，从而证明了MambaByte在无标记语言建模方面的有效性。 |
| [^3] | [Inadequacy of common stochastic neural networks for reliable clinical decision support.](http://arxiv.org/abs/2401.13657) | 本研究调查了随机神经网络在临床应用中的可靠性，并发现常见的深度学习方法在数据转移情况下过于自信。这强调了对本地不确定性可靠估计及其向最终用户传达的重要性。 |
| [^4] | [Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors.](http://arxiv.org/abs/2401.13652) | 本文提出了一种利用图信息神经网络和稀疏网格来检测不连续函数不连续界面的新方法，该方法在维度大于3的情况下表现出高效且准确的不连续性检测能力，在维度n = 2和n = 4的函数上进行的实验验证了其高效性和泛化能力，并具有可移植性和多功能性。 |
| [^5] | [VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks.](http://arxiv.org/abs/2401.13649) | VisualWebArena是一个评估多模态Web代理性能的基准，在真实的“视觉基础任务”上对代理进行了测试。它要求代理准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作来完成用户定义的目标。 |
| [^6] | [How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability.](http://arxiv.org/abs/2401.13641) | 本研究初步探索了基于GPT-4的ChatGPT在面部生物识别中的表现。研究分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT的应用有望提高自动决策在人类场景中的解释性和透明度。 |
| [^7] | [Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint.](http://arxiv.org/abs/2401.13624) | 过拟合的深度神经网络在对抗训练中能够泛化，而且可以通过合适的条件获得良好的鲁棒泛化性能。 |
| [^8] | [Prompt Weight Experiments for LLM Instruction Fine-Tuning.](http://arxiv.org/abs/2401.13586) | LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。 |
| [^9] | [CNN architecture extraction on edge GPU.](http://arxiv.org/abs/2401.13575) | 本文研究了在边缘GPU上进行CNN架构提取的攻击，通过分析GPU的电磁辐射，使用深度学习的侧信道分析可轻松区分不同的神经网络架构。 |
| [^10] | [Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials.](http://arxiv.org/abs/2401.13570) | 本论文提出了一种快速的反向设计方法，使用先进的深度生成人工智能算法来生成基于体素的机械超材料。这种方法可以在短短3秒内生成具有高分辨率的微结构，用于逼近指定的均质化张量矩阵。这一快速的反向设计工具有助于探索极端超材料、超材料中的序列插值，以及生成多尺度的多样微结构。 |
| [^11] | [Task structure and nonlinearity jointly determine learned representational geometry.](http://arxiv.org/abs/2401.13558) | 学习得到的神经表示的几何结构对下游任务性能很重要。研究发现激活函数对几何结构有重要影响：Tanh网络学到的表示反映了目标输出的结构，而ReLU网络保留了原始输入结构的信息。 |
| [^12] | [Benchmarking the Fairness of Image Upsampling Methods.](http://arxiv.org/abs/2401.13555) | 这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。 |
| [^13] | [Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?.](http://arxiv.org/abs/2401.13544) | 本文介绍了一种超越概念瓶颈模型的方法，可以使黑盒模型可干预。通过基于概念的干预来影响模型的输出，并利用这种方法对黑盒模型进行微调。实验证明，微调可以提高干预的效果，并产生更好校准的预测。 |
| [^14] | [Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models.](http://arxiv.org/abs/2401.13537) | 本文提出了一种称为遮蔽粒子建模（MPM）的自监督方法，用于学习高能物理科学数据中无序输入的通用表示。该方法通过预训练学习置换不变的函数，在构建适用于多种任务的高能物理基础模型方面具有潜力。 |
| [^15] | [Finetuning Foundation Models for Joint Analysis Optimization.](http://arxiv.org/abs/2401.13536) | 本论文中展示了在高能物理学中，通过超越顺序优化或重建和分析组件的标准范 paradigm，可以实现性能和数据效率的显著提升。通过搜索通过中间 di-Higgs 系统衰变的重共振体为四个 $b$-喷注的示例用例，我们将高能物理学重建和分析与现代机器学习工作流进行了连接，并量化了其收益。 |
| [^16] | [Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space.](http://arxiv.org/abs/2401.13530) | 本文研究了在Wasserstein概率空间上的Riemannian SGD和SVRG流的优化方法，通过构建随机微分方程来丰富Wasserstein空间中的连续优化方法。 |
| [^17] | [Tissue Cross-Section and Pen Marking Segmentation in Whole Slide Images.](http://arxiv.org/abs/2401.13511) | 该论文介绍了一种使用卷积神经网络进行组织和笔标记分割的方法，并提出了一种基于聚类的创新后处理方法来分离组织横截面。 |
| [^18] | [Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting.](http://arxiv.org/abs/2401.13498) | 本文提出了一种采用乐器特定输入表示和扩散外扩技术的表现力丰富的声学吉他声音合成模型，通过定量和定性评估，展示了该模型比其他模型具有更高的音频质量和更加逼真的音色声音。 |
| [^19] | [Separable Physics-Informed Neural Networks for the solution of elasticity problems.](http://arxiv.org/abs/2401.13486) | 本文提出了一种基于分离的物理信息神经网络（SPINN）和深度能量方法（DEM）的弹性问题求解方法，该方法在收敛速度和精度上显著优于传统的物理信息神经网络（PINN），并且在复杂几何体上的线性弹性理论问题方面具有应用潜力。 |
| [^20] | [Multi-Agent Diagnostics for Robustness via Illuminated Diversity.](http://arxiv.org/abs/2401.13460) | MADRID是一种新方法，通过生成多样化的对抗场景来揭示预训练多Agent策略的战略漏洞，并通过遗憾值衡量漏洞的程度。 |
| [^21] | [Symbolic Equation Solving via Reinforcement Learning.](http://arxiv.org/abs/2401.13447) | 本文利用强化学习和深度神经网络自动化地找到基本变换规则和逐步解决方案，实现了符号方程的求解。 |
| [^22] | [Detection of Correlated Random Vectors.](http://arxiv.org/abs/2401.13429) | 本文研究了判断两个标准正态随机向量是否相关的问题，提出了一种新的方法来评估似然比的二阶矩，并发现了与整数分割函数之间的联系。 |
| [^23] | [Federated learning with distributed fixed design quantum chips and quantum channels.](http://arxiv.org/abs/2401.13421) | 本论文提出了一种具有分布式固定设计量子芯片和量子信道的量子联邦学习模型，通过量子态的传递和聚合梯度来更新参数，提供更高的隐私保护和指数级的效率。 |
| [^24] | [How to Forget Clients in Federated Online Learning to Rank?.](http://arxiv.org/abs/2401.13410) | 本文研究了如何在联邦在线学习排序中删除客户的贡献，提出了一种有效和高效的取消学习方法。 |
| [^25] | [Text Categorization Can Enhance Domain-Agnostic Stopword Extraction.](http://arxiv.org/abs/2401.13398) | 本文研究了文本分类在自然语言处理中简化停用词提取的作用，通过混合统计和语言学方法创建全面的停用词列表，提高了非洲语言的自然语言处理水平。 |
| [^26] | [Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics.](http://arxiv.org/abs/2401.13391) | 本文对评估偏见缓解技术的流行度指标提出质疑，认为它们没有考虑到群组内的变化，并且导致的预测标签不能完全反映现实情况。 |
| [^27] | [Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems.](http://arxiv.org/abs/2401.13366) | 该论文提出了一种在资源受限的异步联邦学习系统中减轻系统偏差的动态全局模型聚合方法，通过根据客户端的上传频率评分和调整模型更新的权重，以适应异构设备和非同分布数据的挑战。实验结果表明，在仿真环境中，与最先进的方法相比，该方法在全局模型准确性上有显著的改善。 |
| [^28] | [Debiased Sample Selection for Combating Noisy Labels.](http://arxiv.org/abs/2401.13360) | 本文提出了一个无噪声专家模型（ITEM）来解决样本选择中的训练偏差和数据偏差问题。通过设计一个鲁棒的网络架构来集成多个专家，可以减少选择集不平衡和累积错误，并在使用更少参数的情况下实现更好的选择和预测性能。 |
| [^29] | [Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD.](http://arxiv.org/abs/2401.13343) | 这项研究提出了机器学习在符号计算中的应用经验教训，包括在机器学习之前对数据集进行分析的重要性以及不同机器学习范式的选择。通过在柱面代数分解中的变量排序选择中的案例研究，发现了数据集中的不平衡问题，并引入了增强技术来改善数据集的平衡性。 |
| [^30] | [Full Bayesian Significance Testing for Neural Networks.](http://arxiv.org/abs/2401.13335) | 该论文提出了一种全贝叶斯神经网络显著性检验方法（nFBST），通过利用贝叶斯神经网络拟合非线性和多维关系，并计算证据值来替代传统方法中的理论推导，该方法能够测试全局、局部和实例级的显著性。 |
| [^31] | [Explainable Bayesian Optimization.](http://arxiv.org/abs/2401.13334) | 本论文介绍了一种可解释性贝叶斯优化的方法，通过TNTRules生成高质量的解释，填补了贝叶斯优化和可解释人工智能之间的间隙。 |
| [^32] | [NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks.](http://arxiv.org/abs/2401.13330) | NACHOS 是一种面向硬件受限的早期退出神经网络的神经架构搜索方法，可以自动化设计早期退出神经网络并考虑骨干和早期退出分类器之间的关系。 |
| [^33] | [Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection.](http://arxiv.org/abs/2401.13327) | 本论文介绍了一种隐私保护的合成健康传感器数据的方法，通过生成对抗网络（GANs）和差分隐私（DP）防护，生成与压力时刻相关的合成序列数据，确保患者信息的保护，并对合成数据进行质量评估。在压力检测数据集上验证了该方法的有效性。 |
| [^34] | [ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models.](http://arxiv.org/abs/2401.13311) | 本文介绍了一个新颖的基准ConTextual，用于评估能够进行上下文敏感的文本富有视觉推理的大型多模态模型。研究发现，目前最好的模型GPT-4V在抽象类别表现出色，但在整体性能上仍然落后于人类，存在改进的空间。 |
| [^35] | [Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques.](http://arxiv.org/abs/2401.13301) | 这项研究使用机器学习技术对放射学孤立综合征（RIS）和临床孤立综合征（CIS）进行分类，通过结合多模态3T MRI的生物标志物，提高了对亚临床形式的检测，有助于区分患者。 |
| [^36] | [RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing.](http://arxiv.org/abs/2401.13282) | RefreshNet是一个多尺度框架，通过分层刷新机制来学习复杂系统的动态，实现了计算效率和预测准确性的平衡。 |
| [^37] | [Adaptive Crowdsourcing Via Self-Supervised Learning.](http://arxiv.org/abs/2401.13239) | 本论文介绍了一种新的自适应众包方法，通过利用自监督学习和新颖的聚合方案，根据众包工作者对先前数量的估计调整权重，实现更准确的集体估计。该方法适应复杂模型和其他实际挑战，并通过理论和计算研究进行了验证。 |
| [^38] | [How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning.](http://arxiv.org/abs/2401.13236) | 本文研究了异构数据联邦学习中的合作问题。通过推导出每个客户端的泛化界限，发现只有与拥有更多训练数据和相似数据分布的客户端合作，才能改善模型的泛化性能。根据这一分析，提出了基于层次聚类的合作训练方案。 |
| [^39] | [From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning.](http://arxiv.org/abs/2401.13229) | 该论文介绍了一种基于多样性的方法，从而优化人类注释和少样本学习。传统的随机选择数据方法忽视了数据的特征和模型的需求，而该方法将考虑这些因素，以提高数据选择的效率。 |
| [^40] | [Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models.](http://arxiv.org/abs/2401.13227) | 本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。 |
| [^41] | [TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification.](http://arxiv.org/abs/2401.13219) | 本研究提出了一种针对稀缺标记的零样本基因组分类问题的解决方法，称为TEPI。通过将基因组表示为伪图像并将其映射到分类感知的嵌入空间，我们能够捕捉物种的组成和系统分类关系，实现了零样本学习。 |
| [^42] | [On Principled Local Optimization Methods for Federated Learning.](http://arxiv.org/abs/2401.13216) | 本论文提出了关于联邦学习中局部优化方法的研究，主要包括对FedAvg算法的界限探索以及提出了联邦加速随机梯度下降（FedAc）方法。 |
| [^43] | [AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network.](http://arxiv.org/abs/2401.13214) | 本文提出了一种自适应多层次注意力网络(AMANet)，用于合成孔径雷达(SAR)图像中的船舶检测。该方法通过学习多尺度特征和自适应聚合显著特征，解决了海岸环境中小型和沿海船舶检测的挑战。 |
| [^44] | [AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation.](http://arxiv.org/abs/2401.13212) | AdCorDA方法通过对抗修正和领域适应改进预训练分类器网络，实验证明在CIFAR-100数据集上能够显著提升准确率，并且在权重量化的神经网络上也表现出显著的性能提升。 |
| [^45] | [Multitask Active Learning for Graph Anomaly Detection.](http://arxiv.org/abs/2401.13210) | 提出了一种名为MITIGATE的多任务主动学习的图异常检测框架，通过耦合节点分类任务，它能够检测到没有已知异常的离群节点，并利用多个任务的共享表示来提升检测性能。 |
| [^46] | [Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification.](http://arxiv.org/abs/2401.13206) | 本文提出了一种基于深度学习与不确定性量化的自我改进干扰管理框架，通过学习模型预测最优解决方案，并通过不确定性量化的方法评估其可信度。实验证明，该方法能够有效改进无线通信中的干扰管理性能。 |
| [^47] | [Topology-aware Embedding Memory for Learning on Expanding Graphs.](http://arxiv.org/abs/2401.13200) | 这篇论文提出了一个基于拓扑感知嵌入记忆的学习扩展图的框架，该框架可以解决在不断扩展的图上应用记忆回放技术导致的内存爆炸问题。 |
| [^48] | [Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model.](http://arxiv.org/abs/2401.13192) | 本研究提出了一种基于点云和扩散模型的晶体结构生成设计框架，并通过重建输入结构和生成全新材料的实验证明了其有效性和潜力。 |
| [^49] | [Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments.](http://arxiv.org/abs/2401.13185) | 本文提出了三种高效计算训练集$\mathbf{X}^\mathbf{T}\mathbf{X}$和$\mathbf{X}^\mathbf{T}\mathbf{Y}$的算法，相比于以前的工作，这些算法能够显著加速交叉验证，而无需重新计算矩阵乘积或统计量。 |
| [^50] | [AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents.](http://arxiv.org/abs/2401.13178) | AgentBoard是一个综合的基准测试和评估框架，专为分析评估LLM智能体而设计，解决了在多轮交互和部分可观察环境中对智能体性能进行基准测试的挑战，并提供了细粒度的进展率指标和评估工具包。 |
| [^51] | [Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends.](http://arxiv.org/abs/2401.13177) | 本研究通过对HuggingFace社区的讨论论坛和模型中心进行定性和定量分析，揭示了在社区中重用预训练模型的挑战和益处，并发现了一些有趣的模型趋势。 |
| [^52] | [Compositional Generative Inverse Design.](http://arxiv.org/abs/2401.13171) | 逆向设计起到优化底层目标函数的作用，最近的研究利用了学习的动力学模型进行优化。通过优化扩散模型捕获的学习能量函数，可以避免对抗示例，并显著提高设计性能。这一设计系统是组合性的，使得可以设计具有每个指定组件的系统。 |
| [^53] | [SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection.](http://arxiv.org/abs/2401.13160) | 本文提出了一种新的训练方法SpacTor-T5，结合了跨度破坏和替换词汇检测的混合目标函数，并采用两阶段课程表进行预训练。在实验中，SpacTor-T5在各种NLP任务中取得了与标准SC预训练相同的下游性能，同时大大减少了预训练迭代次数和总FLOP。 |
| [^54] | [Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence.](http://arxiv.org/abs/2401.13157) | 本论文提出了一种新的时间感知知识表示机制，聚焦于多维拓扑信息和隐含的时间相关信息。该方法通过使用单参数拓扑摘要生成数据的多维拓扑指纹。 |
| [^55] | [NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning.](http://arxiv.org/abs/2401.13148) | 本文介绍了一个基于神经常微分方程的NLBAC框架，用于稳定和安全的强化学习。该框架利用神经常微分方程来近似系统动力学，并将控制屏障函数（CBF）和控制Lyapunov函数（CLF）框架与演员-评论家方法集成，以维持系统的安全性和稳定性。 |
| [^56] | [Contractive Diffusion Probabilistic Models.](http://arxiv.org/abs/2401.13115) | 收缩扩散概率模型（CDPMs）是一种新颖的生成建模技术，通过收缩后向采样并克服分数匹配误差和离散化误差的问题，提高了模型的鲁棒性。实验证明收缩子方差保持（sub-VP）是表现最佳的一种CDPMs。 |
| [^57] | [Sparse identification of nonlinear dynamics in the presence of library and system uncertainty.](http://arxiv.org/abs/2401.13099) | 针对系统变量和函数库不确定性，本文提出了增强的SINDy算法，可以更好地识别稀疏非线性动力学。 |
| [^58] | [Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge.](http://arxiv.org/abs/2401.13098) | 通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。 |
| [^59] | [Probabilistic Demand Forecasting with Graph Neural Networks.](http://arxiv.org/abs/2401.13096) | 本文提出了一种使用图神经网络进行概率需求预测的方法。该方法在现有的DeepAR模型中集成了GNN编码器，并采用基于文章属性相似性构建图的策略，实验结果表明该方法优于传统方法。 |
| [^60] | [Towards Trustable Language Models: Investigating Information Quality of Large Language Models.](http://arxiv.org/abs/2401.13086) | 这项研究探讨了大规模语言模型的信息质量问题，发现标记化不可靠、偏见以及信息质量下降可能导致幻觉、捏造信息，从而对企业决策产生错误影响。 |
| [^61] | [IndiText Boost: Text Augmentation for Low Resource India Languages.](http://arxiv.org/abs/2401.13085) | 本论文研究了针对低资源印度语言的文本增强方法，包括Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术。通过二元和多类文本分类实验，研究发现基本的数据增强技术可以显著提升性能。 |
| [^62] | [Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs.](http://arxiv.org/abs/2401.13054) | 本文提出了一种基于随机游走的方法，用于快速计算超图节点之间的距离并进行标签传播。该方法解决了超图中节点距离计算的问题，进一步拓展了超图的应用领域。 |
| [^63] | [CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention.](http://arxiv.org/abs/2401.13049) | 本研究提出了一种称为CIS-UNet的深度学习模型，用于主动脉和主动脉分支的多类分割。该模型结合了CNN和Swin transformers的优势，采用了上下文感知的平移窗口自注意力，能够准确地识别主动脉的各个分支。 |
| [^64] | [Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?.](http://arxiv.org/abs/2401.13045) | 该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。 |
| [^65] | [Locality Sensitive Sparse Encoding for Learning World Models Online.](http://arxiv.org/abs/2401.13034) | 本文提出了一种基于局部敏感稀疏编码的线性回归模型，通过非线性随机特征实现对复杂环境的拟合。这种模型能够高效地进行稀疏更新，实现了优化拟合先前经验的Follow-The-Leader（FTL）世界模型。 |
| [^66] | [A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants.](http://arxiv.org/abs/2401.13020) | 这篇论文提出了一种基于Proximal Policy Optimization的机会约束强化学习算法，用于电厂监控的监督控制。通过使用Lagrangian relaxation，我们将约束优化问题转化为无约束的目标函数，并通过可训练的拉格朗日乘子实施状态约束。 |
| [^67] | [Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders.](http://arxiv.org/abs/2401.13009) | 对于循环模型中含有隐藏因变量的因果发现，已经出现了能够处理这种情况的多种技术方法。 |
| [^68] | [CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data.](http://arxiv.org/abs/2401.13006) | 本文提出的方法利用预训练生成模型对受限数据进行微调，实现了可控的图像操作。通过修改语义地图，可以方便地插入、删除或替换图像中的对象。该方法在图像伪造和图像编辑领域具有潜在的应用价值和有效性。 |
| [^69] | [PatternPortrait: Draw Me Like One of Your Scribbles.](http://arxiv.org/abs/2401.13001) | 本论文介绍了一种从图片生成抽象肖像绘画的方法，通过利用单一的手绘图案素描和图形神经网络架构，实现了生成多样化的笔触变化，创造出风格独特的充满喜悦的抽象绘画。 |
| [^70] | [Quantum-Inspired Machine Learning for Molecular Docking.](http://arxiv.org/abs/2401.12999) | 量子启发的机器学习方法在分子对接中取得了显著的改进，通过结合量子特性和深度学习在编码的分子空间中学习的梯度，提高了盲目对接的成功率。 |
| [^71] | [A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes.](http://arxiv.org/abs/2401.12996) | 通过翻译了的临床记录进行自然语言处理，发现了存在问题的鸦片使用的退伍军人。与仅通过诊断代码识别的鸦片使用障碍患者相比，这些患者具有不同的人口统计学和临床特征。 |
| [^72] | [Topic Modelling: Going Beyond Token Outputs.](http://arxiv.org/abs/2401.12990) | 这篇论文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。 |
| [^73] | [TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation.](http://arxiv.org/abs/2401.12987) | TelME是一种教师导向的多模融合网络，通过跨模态知识蒸馏实现对话中情绪识别的优化，取得了在多说话人数据集MELD上的最先进性能。 |
| [^74] | [Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\mathcal{O}(1/k)$ Finite-Sample Complexity.](http://arxiv.org/abs/2401.12764) | 本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，并且在强单调条件下证明了该方法的优化收敛速率为$\mathcal{O}(1/k)$。 |
| [^75] | [Falcon: Fair Active Learning using Multi-armed Bandits.](http://arxiv.org/abs/2401.12722) | Falcon是一个使用多臂赌博机的公平主动学习框架，通过策略性样本选择来改善机器学习模型的公平性。它通过识别对于提高公平性最具信息量的“目标群体”样本，并采用一种试错方法来解决样本选择中没有ground truth标签的挑战。 |
| [^76] | [The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model.](http://arxiv.org/abs/2401.12617) | 本文研究了任务相似性和过参数化如何联合影响连续学习中的灾难性遗忘，并发现在过参数化模型中，中等任务相似性导致最多的遗忘，而在插值阈值附近，遗忘随期望任务相似性单调减少。 |
| [^77] | [Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread.](http://arxiv.org/abs/2401.12509) | 本研究开发了一个基于代理建模和自然语言处理技术的仿真框架，用于研究在线社交网络中的误信息传播。通过数字克隆已知的误信息共享网络，我们提高了模拟的真实性和普适性，并且考虑到了讨论主题、用户偏好和在线社区动态等因素。 |
| [^78] | [Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network.](http://arxiv.org/abs/2401.12435) | 本文提出了一种使用物理信息神经网络对细胞外间隙中分子传输进行定量分析的新方法，解决了对分子传输形式不清楚的挑战，并实现了自动计算扩散系数和分子速度的优化功能。 |
| [^79] | [Memorization in Self-Supervised Learning Improves Downstream Generalization.](http://arxiv.org/abs/2401.12233) | 自监督学习中的记忆化问题一直是一个挑战，本文提出了SSLMem框架，用于定义自监督学习中的记忆化，并通过实证分析证明了在大规模数据集和强数据增强的情况下，记忆化仍然存在。 |
| [^80] | [Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction.](http://arxiv.org/abs/2401.11798) | 本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。 |
| [^81] | [Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations.](http://arxiv.org/abs/2401.11792) | 本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。 |
| [^82] | [Parametric Matrix Models.](http://arxiv.org/abs/2401.11694) | 参数矩阵模型是一种通用机器学习算法，基于矩阵方程设计，通过简化基础方法进行近似解参数方程。它可以仅使用经验数据进行训练，适用于各种机器学习问题，并在计算框架内产生准确的结果。 |
| [^83] | [Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation.](http://arxiv.org/abs/2401.11648) | 通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。 |
| [^84] | [Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media.](http://arxiv.org/abs/2401.10841) | 这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。 |
| [^85] | [Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach.](http://arxiv.org/abs/2401.10451) | 本研究提出了一种学习辅助的贝叶斯优化方法，用于解决大规模容量扩展问题。通过构建和求解可行的时间聚合代理问题，识别出低成本的规划决策。通过在验证集和测试预测上评估解决的规划结果，实现了随机容量扩展问题的可行解决。 |
| [^86] | [PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection.](http://arxiv.org/abs/2401.09793) | PatchAD是一种新颖的基于块的MLP-Mixer体系结构，利用对比学习进行时间序列异常检测。它具有高效和轻量级的架构，并采用创新的双项目约束模块来提高表示能力。 |
| [^87] | [Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification.](http://arxiv.org/abs/2401.09493) | 本研究利用线性变分编码器-解码器来学习云辐射反馈对早期热带气旋强化的影响，发现内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流的影响最大。 |
| [^88] | [DiConStruct: Causal Concept-based Explanations through Black-Box Distillation.](http://arxiv.org/abs/2401.08534) | DiConStruct是一种基于黑盒模型的因果概念解释方法，通过创建结构性因果模型和概念归因方式提供更具可解释性的局部解释。 |
| [^89] | [OpenDPD: An Open-Source End-to-End Learning & Benchmarking Framework for Wideband Power Amplifier Modeling and Digital Pre-Distortion.](http://arxiv.org/abs/2401.08318) | OpenDPD 是一个用于宽带功放建模和数字预失真的开源端到端学习和基准框架，通过引入DGRU-DPD模型和新型学习架构，实现了在新的数字发射器架构下的优于以前模型的结果。 |
| [^90] | [Formal Logic Enabled Personalized Federated Learning Through Property Inference.](http://arxiv.org/abs/2401.07448) | 本论文提出了一种通过引入时态逻辑推理来实现个性化的形式逻辑启用的联邦学习，以解决异质性客户设备带来的挑战，并提出了聚合群集的概念。 |
| [^91] | [Improving the Accuracy and Interpretability of Random Forests via Forest Pruning.](http://arxiv.org/abs/2401.05535) | 通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。 |
| [^92] | [SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge.](http://arxiv.org/abs/2401.00496) | 该论文介绍了SAR-RARP50挑战，该挑战提供了第一个多模态、公开的、体内的手术动作识别和语义仪器分割数据集，旨在让研究人员开发出稳健且准确的单任务动作识别方法。 |
| [^93] | [Fast Cell Library Characterization for Design Technology Co-Optimization Based on Graph Neural Networks.](http://arxiv.org/abs/2312.12784) | 提出了一种基于图神经网络的快速准确芯片库特征化的机器学习模型，通过结合芯片结构，在各种工艺参数下预测精度高，并且相较于传统方法具有100倍的加速。 |
| [^94] | [A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection.](http://arxiv.org/abs/2312.09442) | 本研究提出了一个紧凑型的LSTM-SVM融合模型，实现了对心血管疾病的早期检测。该模型采用了一种流程优化方法将心电图信号预处理为一致的10秒持续时间，同时利用LSTM和SVM实现了最先进的结果。 |
| [^95] | [Language Modeling on a SpiNNaker 2 Neuromorphic Chip.](http://arxiv.org/abs/2312.09084) | 该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。 |
| [^96] | [HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning.](http://arxiv.org/abs/2312.01878) | 此论文提出了一种名为HGPROMPT的方法，用于连接同质和异质图，在少样本设置下进行提示学习，并通过预训练的同质和异质图来提高性能。 |
| [^97] | [Visual cognition in multimodal large language models.](http://arxiv.org/abs/2311.16093) | 本文评估了基于视觉的大语言模型在直观物理、因果推理和直观心理领域的当前状态，并通过一系列的对照实验发现，虽然这些模型在处理和解释视觉数据方面表现出显著的熟练性，然而它们在直观物理、因果推理和直观心理方面的表现还有待提高。 |
| [^98] | [Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning.](http://arxiv.org/abs/2311.14828) | 该论文介绍了一种称为深度潜在力模型(DLFM)的通用域模型，使用了基于物理信息核的深度高斯过程，通过过程卷积方法从普通微分方程推导出来。DLFM能够捕捉高度非线性实际多输出时间序列中的动态性，并在基准测试上达到与一系列非物理综合概率模型相当的性能。 |
| [^99] | [A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift.](http://arxiv.org/abs/2311.14743) | 本论文基于奖励模型的准确性和校准度评估了基础模型在分布转移下的性能。实验结果显示奖励模型对于提示和响应的转移具有不同的敏感性，并呈现出新颖的校准模式和准确性下降。同时，将常用的OOD检测技术引入到奖励模型设置中，用于检测分布转移。 |
| [^100] | [Linear Log-Normal Attention with Unbiased Concentration.](http://arxiv.org/abs/2311.13541) | 本论文研究了自注意机制，并分析了注意力矩阵的分布和集中能力。通过引入线性对数正态注意力来模拟原始自注意力的分布和集中行为，提高了Transformer模型的可扩展性。 |
| [^101] | [How False Data Affects Machine Learning Models in Electrochemistry?.](http://arxiv.org/abs/2311.10795) | 本研究研究了虚假数据对机器学习模型在电化学中的影响。发现线性模型在处理噪声方面效果好，而基于树的模型在噪声处理方面效果较差，但能提供更高的预测准确性。 |
| [^102] | [UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields.](http://arxiv.org/abs/2311.05836) | UMedNeRF是一种针对医学神经辐射场的不确定性感知单视角体积渲染网络，能够从2D X射线图像中学习CT投影的连续表示，并通过使用自适应损失权重确保生成图像的质量。 |
| [^103] | [Efficient kernel surrogates for neural network-based regression.](http://arxiv.org/abs/2310.18612) | 本论文研究了一种高效近似方法，称为共轭核（CK），用于替代深度神经网络的神经切向核（NTK）。该方法能够在计算成本较低的情况下产生与NTK相似的结果。 |
| [^104] | [Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in Fine Motor Skill Acquisition.](http://arxiv.org/abs/2310.10280) | 本研究探索了虚拟人工智能教师在模仿人类教育者技术方面在运动技能习得中的潜力，并通过验证四个指导性假设，证实了在合成学习者上的改进。 |
| [^105] | [Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data.](http://arxiv.org/abs/2310.07223) | 这项研究利用MODIS多光谱时间序列数据和深度学习模型，首次实现了对LULC类别的盲目光谱分离。通过添加地理加地形和气候辅助信息，进一步提高了模型的性能。 |
| [^106] | [Boosting Continuous Control with Consistency Policy.](http://arxiv.org/abs/2310.06343) | 该论文提出了一种名为一致性策略与Q-Learning （CPQL）的新方法，通过建立从反向扩散轨迹到期望策略的映射，同时解决了基于扩散模型方法的时间效率和准确指导问题。 |
| [^107] | [Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets.](http://arxiv.org/abs/2310.03258) | 通过转移反事实学习的方法，我们在大规模停电数据集上研究了电力服务的公平性问题，发现低收入和老年人口区域经常遭受较长的停电时间，揭示了电力系统中的偏见存在并强调了改善的需求。 |
| [^108] | [Adversarial Imitation Learning from Visual Observations using Latent Information.](http://arxiv.org/abs/2309.17371) | 本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。 |
| [^109] | [Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering.](http://arxiv.org/abs/2309.17249) | 本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。 |
| [^110] | [Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription.](http://arxiv.org/abs/2309.15717) | Timbre-Trap是一个低资源框架，将音乐转录和音频重构统一起来，通过利用音高和音色的强分离性，同时估计音高显著度和重构频谱系数，取得优越性能。 |
| [^111] | [Revisiting Softmax Masking for Stability in Continual Learning.](http://arxiv.org/abs/2309.14808) | 本文重新审视了用于连续学习中的Softmax掩码的影响，并提出了一种利用其置信度保持效果的方法，通过增加稳定性同时保持准确性。 |
| [^112] | [Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks.](http://arxiv.org/abs/2309.07937) | Voxtlm是一个统一的只解码模型，能够在语音识别、语音合成、文本生成和语音延续等任务上取得显著的改善。 |
| [^113] | [Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction.](http://arxiv.org/abs/2309.03619) | 通过标准化潜变量和调整目标函数，我们提出了Modified Barlow Twins (MBT) 方法来改善自监督学习中的语音表示泛化能力，尤其是在有限的目标数据上微调时。这项研究为发展可重用的自监督语音表示迈出了重要的一步。 |
| [^114] | [Inferring effective couplings with Restricted Boltzmann Machines.](http://arxiv.org/abs/2309.02292) | 本研究通过实现受限玻尔兹曼机的能量函数与有效伊辛自旋哈密顿量之间的直接映射，提供了一种用于推断复杂数据中高阶相互作用的方法。 |
| [^115] | [Pure Message Passing Can Estimate Common Neighbor for Link Prediction.](http://arxiv.org/abs/2309.00976) | 这篇论文提出了一种纯粹的消息传递方法，用于估计共同邻居进行链路预测。该方法通过利用输入向量的正交性来捕捉联合结构特征，提出了一种新的链路预测模型MPLP，该模型利用准正交向量估计链路级结构特征，同时保留了节点级复杂性。 |
| [^116] | [Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models.](http://arxiv.org/abs/2308.15812) | 本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。 |
| [^117] | [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias.](http://arxiv.org/abs/2308.12539) | CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。 |
| [^118] | [GaitPT: Skeletons Are All You Need For Gait Recognition.](http://arxiv.org/abs/2308.10623) | GaitPT是一种利用姿势估计骨骼进行步态识别的新方法，它在控制场景和野外场景中均展现出最先进的性能。 |
| [^119] | [The Initial Screening Order Problem.](http://arxiv.org/abs/2307.15398) | 本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。 |
| [^120] | [EasyTPP: Towards Open Benchmarking Temporal Point Processes.](http://arxiv.org/abs/2307.08097) | EasyTPP是第一个关于事件序列建模领域的中心资源库，提供统一的数据集使用界面和广泛的评估程序，解决了该领域缺乏标准化的问题，推动了研究和应用的进展。 |
| [^121] | [Graph Neural Networks based Log Anomaly Detection and Explanation.](http://arxiv.org/abs/2307.00527) | 提出了一种基于图神经网络的无监督日志异常检测方法，该方法将事件日志转换为带属性、有向和加权的图，并利用图神经网络进行图级别的异常检测。引入了一种新的图神经网络模型OCDiGCN来检测一组带属性、有向和加权的图中的图级别异常，并提供对异常的解释能力。 |
| [^122] | [Differentially Private Distributed Estimation and Learning.](http://arxiv.org/abs/2306.15865) | 本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。 |
| [^123] | [Split Learning in 6G Edge Networks.](http://arxiv.org/abs/2306.12194) | Split learning (SL) enables servers to handle the major training workload while still enhancing data privacy, which is an important approach in 6G edge networks. This article provides an overview of the tailored 6G architecture to support edge SL, the critical design issues for edge SL, and presents future research direction and exciting applications of SL in 6G edge networks. |
| [^124] | [$\pi2\text{vec}$: Policy Representations with Successor Features.](http://arxiv.org/abs/2306.09800) | 本文提出了$\pi2\text{vec}$方法，它可以将黑盒策略行为表示为特征向量，并可以用于离线策略选择。该方法为现代研究方向中的离线策略评估、基础模型状态表示和资源受限制的策略选择提供了重要的支持。 |
| [^125] | [Reward-Free Curricula for Training Robust World Models.](http://arxiv.org/abs/2306.09205) | 通过无奖励课程进行训练可以实现鲁棒世界模型。我们提出了WAKER算法，通过根据世界模型在不同环境中的估计误差选择数据收集环境，从而提升模型的鲁棒性。 |
| [^126] | [TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models.](http://arxiv.org/abs/2306.08013) | 本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。 |
| [^127] | [Learning DAGs from Data with Few Root Causes.](http://arxiv.org/abs/2305.15936) | 该论文提出了一种新的算法，能够从仅有少量根因的数据中学习DAGs，并证明了其可识别性，并在性能上优于以前的方法。 |
| [^128] | [Empirical Optimal Transport between Conditional Distributions.](http://arxiv.org/abs/2305.15901) | 本文考虑在一个公共变量的条件下，相应分布之间的最优输运问题。通过采用基于 MMD 的核正则化器，克服了条件变量是连续的和两个分布中该变量的边缘是不同的挑战。 |
| [^129] | [SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes.](http://arxiv.org/abs/2305.13998) | SMT 2.0是一个开源的代理模型工具包，引入了处理混合变量和层次变量的能力，并通过扩展采样方法、添加新的代理模型以及计算Kriging的方差和核导数来改进了SMT。 |
| [^130] | [Learning in Inverse Optimization: Incenter Cost, Augmented Suboptimality Loss, and Algorithms.](http://arxiv.org/abs/2305.07730) | 本论文提出了逆优化学习的新概念——内心概念，以及相应的可行凸形式，并开发了新型损失函数ASL以及一阶算法Stochastic Approximate Mirror Descent（SAM）来学习专家的成本函数。 |
| [^131] | [Tensor PCA from basis in tensor space.](http://arxiv.org/abs/2305.02803) | 本文提出了一种张量PCA的数学框架，通过自伴张量算子导出张量空间中的基础以解决以往方法的局限性，实验结果表明了该方法的有效性。 |
| [^132] | [Collective Relational Inference for learning physics-consistent heterogeneous particle interactions.](http://arxiv.org/abs/2305.00557) | 本论文提出了一种新的概率方法用于学习异质性粒子相互作用的集体关系推断，与现有方法相比，该方法集体地推断不同边的相互作用类型，使用物理感应的图神经网络来学习具有物理一致性的成对相互作用，并在推断准确性和保持物理保真度方面一致优于现有方法。 |
| [^133] | [Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method.](http://arxiv.org/abs/2304.03468) | 文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。 |
| [^134] | [Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks.](http://arxiv.org/abs/2303.15991) | 本文提出了面向资源受限的无线边缘网络的高效并行分裂学习（EPSL）框架，旨在加速模型训练。EPSL并行化客户端模型训练，通过聚合梯度降低了反向传播的局部梯度维度，从而显著减少了服务器端的训练和通信延迟。同时，EPSL还设计了资源分配算法以优化计算和通信资源分配。 |
| [^135] | [Training Deep Boltzmann Networks with Sparse Ising Machines.](http://arxiv.org/abs/2303.10728) | 本文展示了使用稀疏伊辛机器训练深度玻尔兹曼网络的新应用领域，通过在硬件感知的网络拓扑中使用伊辛机器，我们实现了与优化的软件模型相同的分类准确率。 |
| [^136] | [cito: An R package for training neural networks using torch.](http://arxiv.org/abs/2303.09599) | cito是一个用户友好的R包，使用torch进行深度神经网络的训练，包括许多对预测和评估模型有用的用户友好功能。 |
| [^137] | [DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks.](http://arxiv.org/abs/2303.04878) | DeepGD是一种用于深度神经网络的多目标黑盒测试选择方法，通过优先选择具有高错误暴露能力的测试输入来降低标记成本，同时选择具有高不确定性分数的测试输入以尽可能触发更多的误预测输入，并通过最大化揭示DNN模型中不同缺陷的概率来增加测试的多样性。 |
| [^138] | [Digital Over-the-Air Federated Learning in Multi-Antenna Systems.](http://arxiv.org/abs/2302.14648) | 本文研究了在多天线系统中采用数字调制和空中计算的情况下，联邦学习的性能优化问题。通过结合数字调制和AirComp，提出了一种改进的联邦平均算法，以解决无线信道衰落导致的总体失真问题。 |
| [^139] | [Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters.](http://arxiv.org/abs/2302.13711) | 本文提出了一种新的策略，用于在内部坐标中建模蛋白质密度。通过约束来诱导内部自由度之间的协方差结构，在三维空间中满足结构约束，并通过构建一个全协方差输出的变分自编码器来验证该方法的潜力，并成功将内部坐标的密度模型扩展到完整的蛋白质骨架。 |
| [^140] | [A Multimodal Graph Neural Network Framework of Cancer Molecular Subtype Classification.](http://arxiv.org/abs/2302.12838) | 这项研究提出了一个多模态图神经网络框架用于癌症分子亚型分类。与现有方法相比，该框架在连接类型、GNN层和复杂分类测试方面有不同，从而取得了更好的结果。 |
| [^141] | [Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization.](http://arxiv.org/abs/2302.08298) | 该论文考察了在高维贝叶斯优化中，收购功能最大化器初始化对利用收购功能能力的影响。研究发现随机初始化方法不能充分发挥收购功能的潜力，因此提出了一种更好的初始化方法来利用历史数据。 |
| [^142] | [PECAN: A Deterministic Certified Defense Against Backdoor Attacks.](http://arxiv.org/abs/2301.11824) | PECAN是一种有效且经过认证的后门攻击防御方法，通过在不相交分区上训练一组神经网络并应用测试时间逃避认证技术，可以显著提高防御强度和效率，降低攻击成功率。 |
| [^143] | [Fast Algorithm for Constrained Linear Inverse Problems.](http://arxiv.org/abs/2212.01068) | 本文提出了一种快速算法，用于解决约束线性逆问题。该算法通过将问题转化为凸优化问题或极小极大问题，并应用现有的优化方法，提供了更好的理论收敛保证。同时，本文还介绍了一种名为FLIPS的算法，该算法针对问题结构进行了优化，并展示了在多个经典问题上的性能。 |
| [^144] | [Adversarial Detection by Approximation of Ensemble Boundary.](http://arxiv.org/abs/2211.10227) | 本论文提出了一种使用Walsh系数逼近决策边界的对抗攻击检测方法，通过观察清晰图像和对抗图像之间的Walsh系数逼近差异，实现了对对抗攻击的检测。 |
| [^145] | [A mixed-categorical correlation kernel for Gaussian process.](http://arxiv.org/abs/2211.08262) | 提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。 |
| [^146] | [Risk-Aware Linear Bandits: Theory and Applications in Smart Order Routing.](http://arxiv.org/abs/2208.02389) | 本论文研究了风险意识线性赌博机在智能订单路由中的应用，并提出了两种算法来最小化遗憾。分析表明，这些算法在近乎最优的情况下能够通过利用线性结构来提高性能。 |
| [^147] | [TE2Rules: Explaining Tree Ensembles using Rules.](http://arxiv.org/abs/2206.14359) | 本文介绍了一种将二元分类任务中的树集合模型转换为可解释规则列表的方法，该方法可以有效解释模型对于少数类别的预测。实验证明，TE2Rules方法生成的规则列表准确性较高，并且运行时间与其他基线方法相当。 |
| [^148] | [Relative Policy-Transition Optimization for Fast Policy Transfer.](http://arxiv.org/abs/2206.06009) | 本论文介绍了相对策略过渡优化的方法，通过引入一个基于强化学习的引理衡量两个MDP之间的相对差距，并提出了相对策略优化和相对转移优化两个算法来实现快速策略转移和动态建模。同时，将这两个算法集成在一起形成完整的相对策略过渡优化算法。 |
| [^149] | [Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities.](http://arxiv.org/abs/2203.13883) | 这项研究总结了多模式虚假信息检测的方法、挑战和机遇。由于社交媒体平台的转变，虚假信息的性质也发生了变化。研究人员已经开发出自动检测跨模态不协调的技术，但仍面临挑战和不足之处，进一步的研究机会也在等待着挖掘。 |
| [^150] | [Decentralized Personalized Federated Learning for Min-Max Problems.](http://arxiv.org/abs/2106.07289) | 该论文首次研究了个性化联邦学习在鞍点问题上的应用，提出了分散的设置，并通过提出新算法解决了这一问题。 |
| [^151] | [MNL-Bandit with Knapsacks: a near-optimal algorithm.](http://arxiv.org/abs/2106.01135) | 这篇论文介绍了一种解决动态商品选择问题的算法，通过使用近似最优策略，可在未知需求情况下最大化总体预期收入。在大库存环境下，该算法能够接近最优解。 |
| [^152] | [MMD-regularized Unbalanced Optimal Transport.](http://arxiv.org/abs/2011.05001) | 本文研究了使用MMD正则化的非平衡最优输运问题，提出了基于Fenchel对偶性的新度量方法，还提出了基于有限样本的凸规划用于估算问题，证明了估计量的一致性和误差速率。 |
| [^153] | [The Power of Linear Recurrent Neural Networks.](http://arxiv.org/abs/1802.03308) | 本研究展示了线性递归神经网络(LRNNs)可以逼近任何时变函数f(t)。通过检查网络转移矩阵的主要特征值，可以显著降低LRNN的规模。LRNNs具有以椭圆轨迹结束的有趣特性，并允许预测进一步的值和函数的紧凑表示。 |

# 详细

[^1]: 深度强化学习中策略梯度的终极指南：理论、算法和实现

    The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations. (arXiv:2401.13662v1 [cs.LG])

    [http://arxiv.org/abs/2401.13662](http://arxiv.org/abs/2401.13662)

    本文提供了一个深度强化学习中策略梯度算法的综合指南，包括理论基础、实际实现和比较结果，并对正则化的益处进行了讨论。

    

    最近几年，在深度强化学习中提出了各种强大的策略梯度算法。虽然所有这些算法都建立在策略梯度定理的基础上，但具体的设计选择在算法之间有很大的差异。我们提供了一个整体的视角来概述在线策略梯度算法，以便理解它们的理论基础和实际实现。在这个概述中，我们包括了连续版本的策略梯度定理的详细证明、收敛结果和对实际算法的全面讨论。我们比较了连续控制环境中最重要的算法，并对正则化的益处提供了深入的见解。所有的代码都可以在https://github.com/Matt00n/PolicyGradientsJax获得。

    In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.
    
[^2]: MambaByte: 无标记选择性状态空间模型

    MambaByte: Token-free Selective State Space Model. (arXiv:2401.13660v1 [cs.CL])

    [http://arxiv.org/abs/2401.13660](http://arxiv.org/abs/2401.13660)

    MambaByte是一种无标记的选择性状态空间模型，通过在字节级别上进行自回归训练，解决了标准自回归Transformer在处理长序列时的性能问题，并展现了与最先进的子词Transformer相媲美甚至更优的性能，从而证明了MambaByte在无标记语言建模方面的有效性。

    

    无标记语言模型直接从原始字节学习，消除了子词标记化的偏差。然而，操作字节会导致序列长度显著增加，在这种情况下，标准自回归Transformer的扩展性较差。我们尝试了MambaByte，它是基于字节序列自回归训练的无标记适应Mamba状态空间模型。我们的实验表明，与其他字节级模型相比，MambaByte具有计算效率。我们还发现，MambaByte在性能上与甚至胜过最先进的子词Transformer。此外，由于长度的线性扩展，MambaByte在推理过程中获得了快速性能，相比之下，Transformer则没有。我们的研究结果证实了MambaByte在实现无标记语言建模方面的可行性。

    Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.
    
[^3]: 常见的随机神经网络在可靠性临床决策支持方面的不足

    Inadequacy of common stochastic neural networks for reliable clinical decision support. (arXiv:2401.13657v1 [cs.LG])

    [http://arxiv.org/abs/2401.13657](http://arxiv.org/abs/2401.13657)

    本研究调查了随机神经网络在临床应用中的可靠性，并发现常见的深度学习方法在数据转移情况下过于自信。这强调了对本地不确定性可靠估计及其向最终用户传达的重要性。

    

    由于伦理和安全相关的关切，人工智能的广泛应用于医学决策仍然受阻。对于基于人工智能的医疗决策支持系统来说，可靠性和可信度至关重要。然而，常见的深度学习方法在数据转移下往往过于自信。这种在基于证据的场景之外不恰当的推理可能会产生严重后果。这凸显了对本地不确定性可靠估计及其向最终用户传达的重要性。尽管随机神经网络被誉为这些问题的潜在解决方案，但本研究调查了其在临床应用中的实际可靠性。我们以从MIMIC3研究中使用的EHR的ICU住院病死率预测为例来进行分析。对于EHR时间序列的预测，我们采用了仅编码器的Transformer模型。通过纳入常见方法来实现模型函数的随机性。

    Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns. For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy. Common deep learning approaches, however, have the tendency towards overconfidence under data shift. Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences. This highlights the importance of reliable estimation of local uncertainty and its communication to the end user. While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications. We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study. For predictions on the EHR time series, Encoder-Only Transformer models were employed. Stochasticity of model functions was achieved by incorporating common methods such 
    
[^4]: 基于稀疏网格的不连续性检测的图信息神经网络

    Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity Detectors. (arXiv:2401.13652v1 [cs.LG])

    [http://arxiv.org/abs/2401.13652](http://arxiv.org/abs/2401.13652)

    本文提出了一种利用图信息神经网络和稀疏网格来检测不连续函数不连续界面的新方法，该方法在维度大于3的情况下表现出高效且准确的不连续性检测能力，在维度n = 2和n = 4的函数上进行的实验验证了其高效性和泛化能力，并具有可移植性和多功能性。

    

    本文提出了一种新颖的方法来检测不连续函数的不连续界面。该方法利用了基于图的神经网络（GINNs）和稀疏网格来解决维度大于3的情况下的不连续性检测。训练过的GINNs在稀疏网格上识别有问题的点，并利用构建在网格上的图结构实现高效准确的不连续性检测性能。我们还引入了一种递归算法用于一般的基于稀疏网格的检测器，具有收敛性和易于应用性。在维度n=2和n=4的函数上进行的数值实验证明了GINNs在检测不连续界面方面的高效性和鲁棒泛化能力。值得注意的是，经过训练的GINNs具有可移植性和多功能性，可以集成到各种算法中并共享给用户。

    In this paper, we present a novel approach for detecting the discontinuity interfaces of a discontinuous function. This approach leverages Graph-Informed Neural Networks (GINNs) and sparse grids to address discontinuity detection also in domains of dimension larger than 3. GINNs, trained to identify troubled points on sparse grids, exploit graph structures built on the grids to achieve efficient and accurate discontinuity detection performances. We also introduce a recursive algorithm for general sparse grid-based detectors, characterized by convergence properties and easy applicability. Numerical experiments on functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust generalization of GINNs in detecting discontinuity interfaces. Notably, the trained GINNs offer portability and versatility, allowing integration into various algorithms and sharing among users.
    
[^5]: VisualWebArena: 在真实视觉Web任务上评估多模态代理

    VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks. (arXiv:2401.13649v1 [cs.LG])

    [http://arxiv.org/abs/2401.13649](http://arxiv.org/abs/2401.13649)

    VisualWebArena是一个评估多模态Web代理性能的基准，在真实的“视觉基础任务”上对代理进行了测试。它要求代理准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作来完成用户定义的目标。

    

    能够在网络上进行计划、推理和执行动作的自主代理为自动化计算机任务提供了一个有前途的途径。然而，现有的大多数基准主要关注基于文本的代理，在效果上忽视了许多需要视觉信息才能有效解决的自然任务。鉴于大多数计算机界面是为人类感知而设计的，视觉信息往往以文本数据无法有效利用的方式增强文本数据。为了弥补这一差距，我们引入了VisualWebArena，这是一个设计用于评估多模态Web代理在真实的“视觉基础任务”上性能的基准。VisualWebArena包括一组多样且复杂的基于Web的任务，评估自主多模态代理的各种能力。为了在这个基准上执行，代理需要准确处理图像-文本输入，解释自然语言指令，并在网站上执行动作以完成用户定义的目标。

    Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents. To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives. We conduct an ext
    
[^6]: ChatGPT在面部生物识别中的表现有多好？对识别、软生物特征和可解释性的初步探索。

    How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability. (arXiv:2401.13641v1 [cs.CV])

    [http://arxiv.org/abs/2401.13641](http://arxiv.org/abs/2401.13641)

    本研究初步探索了基于GPT-4的ChatGPT在面部生物识别中的表现。研究分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT的应用有望提高自动决策在人类场景中的解释性和透明度。

    

    诸如OpenAI开发的GPT这样的大型语言模型已经展现出令人惊讶的结果，为我们的社会引入了快速变革。ChatGPT的发布进一步加强了这一影响，它使任何人都能以简单的对话方式与语言模型进行交互，不需要任何领域经验。因此，ChatGPT已被迅速应用于许多不同的任务，如代码和歌曲创作、教育、虚拟助手等，展示了对于未经过训练的任务而言令人印象深刻的结果（零样本学习）。本研究旨在探讨基于最新的GPT-4多模态语言模型的ChatGPT在面部生物识别任务中的能力。具体而言，我们分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT对于进一步增加人类场景中自动决策的解释性和透明度非常有价值。实验被进行以评估ChatGPT的表现。

    Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning).  The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios. Experiments are carried out in order
    
[^7]: 深度神经网络在对抗训练中的过拟合现象能否泛化？——一个近似视角

    Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])

    [http://arxiv.org/abs/2401.13624](http://arxiv.org/abs/2401.13624)

    过拟合的深度神经网络在对抗训练中能够泛化，而且可以通过合适的条件获得良好的鲁棒泛化性能。

    

    对抗训练是一种广泛应用的方法，用于提高深度神经网络(DNNs)对对抗扰动的鲁棒性。然而，经验观察表明，在过参数化网络上进行对抗训练往往会遭受"鲁棒性过拟合"：它可以实现几乎零的对抗训练误差，而鲁棒泛化性能并不理想。本文从近似的角度提供了关于在对抗训练中过拟合的DNNs能否泛化的理论理解。具体而言，我们的主要结果总结为三个方面：i) 对于分类问题，我们证明了在过参数化的DNNs上可以构造出无限多个对抗训练分类器，其能够在满足一定条件下（涉及数据质量，良好分离和扰动程度）获得任意小的对抗训练误差（过拟合），同时在鲁棒泛化误差方面表现良好。ii) 线性超过拟合的DNNs也可以实现鲁棒泛化。iii) 我们通过数值实验验证了所提出的理论结果。

    Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear ove
    
[^8]: LLM指令微调中的提示权重实验

    Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])

    [http://arxiv.org/abs/2401.13586](http://arxiv.org/abs/2401.13586)

    LLM指令微调中，对于短提示完成数据集，提示词标记分类损失加权（PLW）与性能呈负二次关系，而长提示完成数据集则不受PLW影响。

    

    我们进行了一项小型研究，分析了提示词标记分类损失加权（PLW）如何影响在指令任务上进行微调的7B大小的LLaMA模型的性能。我们使用多个指令数据集重现了斯坦福大学的Alpaca实验，其中包括LLaMA 1和LLaMA 2。我们发现，在我们的短提示完成数据集上微调的模型与PLW之间存在负二次关系，而在长提示完成数据集上微调的模型不受PLW的影响。

    We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.
    
[^9]: 边缘GPU上的CNN架构提取

    CNN architecture extraction on edge GPU. (arXiv:2401.13575v1 [cs.CR])

    [http://arxiv.org/abs/2401.13575](http://arxiv.org/abs/2401.13575)

    本文研究了在边缘GPU上进行CNN架构提取的攻击，通过分析GPU的电磁辐射，使用深度学习的侧信道分析可轻松区分不同的神经网络架构。

    

    由于其多功能性和在许多应用中的最新结果（如图像分类、自然语言处理、语音识别、预测等），神经网络变得越来越受欢迎。这些应用也被用于资源受限的嵌入式设备。本研究通过侧信道分析，探讨了神经网络实现对逆向工程的敏感性，使用NVIDIA Jetson Nano微型计算机进行研究。为此，提出了一种架构提取攻击。在攻击中，将15种流行的卷积神经网络架构（EfficientNets、MobileNets、NasNet等）在Jetson Nano的GPU上实现，并在神经网络推理操作期间分析GPU的电磁辐射。分析结果表明，使用基于深度学习的侧信道分析可以轻松区分神经网络架构。

    Neural networks have become popular due to their versatility and state-of-the-art results in many applications, such as image classification, natural language processing, speech recognition, forecasting, etc. These applications are also used in resource-constrained environments such as embedded devices. In this work, the susceptibility of neural network implementations to reverse engineering is explored on the NVIDIA Jetson Nano microcomputer via side-channel analysis. To this end, an architecture extraction attack is presented. In the attack, 15 popular convolutional neural network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is analyzed during the inference operation of the neural networks. The results of the analysis show that neural network architectures are easily distinguishable using deep learning-based side-channel analysis.
    
[^10]: 导向扩散用于快速反向设计基于密度的机械超材料

    Guided Diffusion for Fast Inverse Design of Density-based Mechanical Metamaterials. (arXiv:2401.13570v1 [cs.CE])

    [http://arxiv.org/abs/2401.13570](http://arxiv.org/abs/2401.13570)

    本论文提出了一种快速的反向设计方法，使用先进的深度生成人工智能算法来生成基于体素的机械超材料。这种方法可以在短短3秒内生成具有高分辨率的微结构，用于逼近指定的均质化张量矩阵。这一快速的反向设计工具有助于探索极端超材料、超材料中的序列插值，以及生成多尺度的多样微结构。

    

    机械超材料是一种通过精心设计其内部结构，可以具有异常弹性、刚度和稳定性等非凡物理特性的合成材料。为了使超材料包含具有独特机械性能的精细局部结构，使用高分辨率体素来表示它们是一种潜在方法。然而，这会带来巨大的计算负担。为此，本论文提出了一种快速的反向设计方法，其核心是先进的深度生成人工智能算法，用于生成基于体素的机械超材料。具体而言，我们使用自条件扩散模型，在仅需3秒的时间内生成分辨率为 $128^3$ 的微结构，以逼近指定的均质化张量矩阵。因此，这种快速的反向设计工具有助于探索极端超材料、超材料中的序列插值以及生成多尺度的多样微结构。

    Mechanical metamaterial is a synthetic material that can possess extraordinary physical characteristics, such as abnormal elasticity, stiffness, and stability, by carefully designing its internal structure. To make metamaterials contain delicate local structures with unique mechanical properties, it is a potential method to represent them through high-resolution voxels. However, it brings a substantial computational burden. To this end, this paper proposes a fast inverse design method, whose core is an advanced deep generative AI algorithm, to generate voxel-based mechanical metamaterials. Specifically, we use the self-conditioned diffusion model, capable of generating a microstructure with a resolution of $128^3$ to approach the specified homogenized tensor matrix in just 3 seconds. Accordingly, this rapid reverse design tool facilitates the exploration of extreme metamaterials, the sequence interpolation in metamaterials, and the generation of diverse microstructures for multi-scale 
    
[^11]: 任务结构和非线性共同决定了学习的表示几何关系

    Task structure and nonlinearity jointly determine learned representational geometry. (arXiv:2401.13558v1 [cs.LG])

    [http://arxiv.org/abs/2401.13558](http://arxiv.org/abs/2401.13558)

    学习得到的神经表示的几何结构对下游任务性能很重要。研究发现激活函数对几何结构有重要影响：Tanh网络学到的表示反映了目标输出的结构，而ReLU网络保留了原始输入结构的信息。

    

    一个学习出的神经表示的效用取决于它的几何结构对下游任务性能的支持程度。这个几何结构取决于输入的结构、目标输出的结构以及网络的结构。通过研究具有一个隐藏层的网络的学习动力学，我们发现网络的激活函数对表示几何有一个意外的强烈影响：Tanh网络倾向于学习反映目标输出结构的表示，而ReLU网络保留了更多关于原始输入结构的信息。在一个参数化任务类中，我们调整任务输入的几何结构和任务标签的几何结构之间的对齐程度，发现这种差异在所有任务上都是一致的。我们分析了权重空间中的学习动力学，并展示了Tanh和ReLU非线性网络之间的差异是由于它们的渐进行为的不对称性引起的。

    The utility of a learned neural representation depends on how well its geometry supports performance in downstream tasks. This geometry depends on the structure of the inputs, the structure of the target outputs, and the architecture of the network. By studying the learning dynamics of networks with one hidden layer, we discovered that the network's activation function has an unexpectedly strong impact on the representational geometry: Tanh networks tend to learn representations that reflect the structure of the target outputs, while ReLU networks retain more information about the structure of the raw inputs. This difference is consistently observed across a broad class of parameterized tasks in which we modulated the degree of alignment between the geometry of the task inputs and that of the task labels. We analyzed the learning dynamics in weight space and show how the differences between the networks with Tanh and ReLU nonlinearities arise from the asymmetric asymptotic behavior of 
    
[^12]: 图像上采样方法的公平性基准测试

    Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])

    [http://arxiv.org/abs/2401.13555](http://arxiv.org/abs/2401.13555)

    这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。

    

    近年来，深度生成模型在创建合成媒体（如图像和视频）方面取得了快速发展。虽然这些模型在日常任务中的实际应用非常诱人，但评估其公平性相关的潜在风险至关重要。在这项工作中，我们引入了一个全面的框架，用于评估有条件生成模型的性能和公平性。我们开发了一套度量标准——受监督公平性的灵感来源——来评估模型的公平性和多样性。我们针对图像上采样这个特定应用，创建了一个涵盖各种现代上采样方法的基准测试。作为基准测试的一部分，我们引入了UnfairFace，这是FairFace的一个子集，复制了常见大规模人脸数据集的种族分布。我们的实证研究凸显了使用无偏训练集的重要性，并揭示了算法对该问题的响应变化。

    Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\unicode{x2013}$inspired by their supervised fairness counterparts$\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to 
    
[^13]: 超越概念瓶颈模型：如何使黑盒模型可干预？

    Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?. (arXiv:2401.13544v1 [cs.LG])

    [http://arxiv.org/abs/2401.13544](http://arxiv.org/abs/2401.13544)

    本文介绍了一种超越概念瓶颈模型的方法，可以使黑盒模型可干预。通过基于概念的干预来影响模型的输出，并利用这种方法对黑盒模型进行微调。实验证明，微调可以提高干预的效果，并产生更好校准的预测。

    

    最近，可解释的机器学习重新探索了概念瓶颈模型（CBM），包括从原始特征中逐步预测高级概念和从预测的概念中预测目标变量。这个模型类别的一个引人注目的优势是用户能够对预测的概念值进行干预，从而影响模型的下游输出。在这项工作中，我们介绍了一种方法，在已经训练好但本质上不可解释的神经网络上进行基于概念的干预，给定一个带有注释的验证集。此外，我们将模型的可干预性定义为基于概念干预的有效性的度量，并利用这个定义来对黑盒模型进行微调。实证上，我们探索了合成表格数据和自然图像基准上黑盒分类器的干预性。我们证明，微调提高了干预的效果，并经常产生更好校准的预测。

    Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the 
    
[^14]: 基于集合的遮蔽粒子建模：走向自监督高能物理基础模型

    Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models. (arXiv:2401.13537v1 [hep-ph])

    [http://arxiv.org/abs/2401.13537](http://arxiv.org/abs/2401.13537)

    本文提出了一种称为遮蔽粒子建模（MPM）的自监督方法，用于学习高能物理科学数据中无序输入的通用表示。该方法通过预训练学习置换不变的函数，在构建适用于多种任务的高能物理基础模型方面具有潜力。

    

    本文提出了一种称为"遮蔽粒子建模"（MPM）的自监督方法，用于学习高能物理（HEP）科学数据中无序输入的通用、可转移和可重用表示。这项工作提供了一种新颖的方案，通过基于遮蔽建模的预训练来学习集合上的置换不变函数。更一般地，这项工作在构建可以通过自监督学习进行通用预训练并稍后精调用于各种下游任务的HEP大型基础模型方面迈出了一步。在MPM中，集合中的粒子被遮蔽，训练的目标是恢复它们的身份，身份由预训练的向量量化变分自动编码器的离散化标记表示定义。我们研究了该方法在对撞机物理实验中高能喷注样本上的有效性，包括离散化、置换不变性和排序的影响。

    We propose \textit{masked particle modeling} (MPM) as a self-supervised method for learning generic, transferable, and reusable representations on unordered sets of inputs for use in high energy physics (HEP) scientific data. This work provides a novel scheme to perform masked modeling based pre-training to learn permutation invariant functions on sets. More generally, this work provides a step towards building large foundation models for HEP that can be generically pre-trained with self-supervised learning and later fine-tuned for a variety of down-stream tasks. In MPM, particles in a set are masked and the training objective is to recover their identity, as defined by a discretized token representation of a pre-trained vector quantized variational autoencoder. We study the efficacy of the method in samples of high energy jets at collider physics experiments, including studies on the impact of discretization, permutation invariance, and ordering. We also study the fine-tuning capabili
    
[^15]: 为联合分析优化调整基础模型

    Finetuning Foundation Models for Joint Analysis Optimization. (arXiv:2401.13536v1 [hep-ex])

    [http://arxiv.org/abs/2401.13536](http://arxiv.org/abs/2401.13536)

    本论文中展示了在高能物理学中，通过超越顺序优化或重建和分析组件的标准范 paradigm，可以实现性能和数据效率的显著提升。通过搜索通过中间 di-Higgs 系统衰变的重共振体为四个 $b$-喷注的示例用例，我们将高能物理学重建和分析与现代机器学习工作流进行了连接，并量化了其收益。

    

    在这项工作中，我们展示了在高能物理学中可以通过超越顺序优化或重建和分析组件的标准范 paradigm，实现性能和数据效率的显著提升。我们将高能物理学重建和分析与现代机器学习工作流（如预训练、微调、领域适应和高维嵌入空间）进行了概念上的连接，并量化了通过搜索通过中间 di-Higgs 系统衰变的重共振体为四个 $b$-喷注的示例用例中的收益。

    In this work we demonstrate that significant gains in performance and data efficiency can be achieved in High Energy Physics (HEP) by moving beyond the standard paradigm of sequential optimization or reconstruction and analysis components. We conceptually connect HEP reconstruction and analysis to modern machine learning workflows such as pretraining, finetuning, domain adaptation and high-dimensional embedding spaces and quantify the gains in the example usecase of searches of heavy resonances decaying via an intermediate di-Higgs system to four $b$-jets.
    
[^16]: 在Wasserstein概率空间上理解Riemannian SGD和SVRG流的研究

    Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein Probabilistic Space. (arXiv:2401.13530v1 [cs.LG])

    [http://arxiv.org/abs/2401.13530](http://arxiv.org/abs/2401.13530)

    本文研究了在Wasserstein概率空间上的Riemannian SGD和SVRG流的优化方法，通过构建随机微分方程来丰富Wasserstein空间中的连续优化方法。

    

    最近，对于Riemannian流形上的优化研究为优化领域提供了新的见解。在这方面，概率测度度量空间作为流形，配备第二阶Wasserstein距离，尤其引人关注，因为在其上的优化可以与实际的采样过程相关联。一般来说，Wasserstein空间上的最优化方法是Riemannian梯度流（即，在最小化KL散度时的Langevin动力学）。在本文中，我们旨在通过将梯度流延展到随机梯度下降（SGD）流和随机方差减少梯度（SVRG）流，丰富Wasserstein空间中的连续优化方法。Euclidean空间上的这两种流是标准的随机优化方法，而它们在Riemannian空间中的对应方法尚未被探索。通过利用Wasserstein空间中的结构，我们构建了一个随机微分方程（SDE）来近似离散动态。

    Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamic
    
[^17]: 组织横截面和笔标记在全切片图像中的分割

    Tissue Cross-Section and Pen Marking Segmentation in Whole Slide Images. (arXiv:2401.13511v1 [eess.IV])

    [http://arxiv.org/abs/2401.13511](http://arxiv.org/abs/2401.13511)

    该论文介绍了一种使用卷积神经网络进行组织和笔标记分割的方法，并提出了一种基于聚类的创新后处理方法来分离组织横截面。

    

    组织分割是整个切片图像（WSI）分析的常规预处理步骤，通过排除背景区域来减少计算成本。传统的图像处理技术通常用于组织分割，但常常需要手动调整参数值来处理非典型情况，无法完全排除幻灯片和扫描工件对背景的影响，并且无法分割脂肪组织。特别是笔标记工件如果不移除可能成为后续分析的潜在偏差源。此外，一些应用需要分离单个横截面，但由于组织破碎和相邻定位的问题，这可能具有挑战性。

    Tissue segmentation is a routine preprocessing step to reduce the computational cost of whole slide image (WSI) analysis by excluding background regions. Traditional image processing techniques are commonly used for tissue segmentation, but often require manual adjustments to parameter values for atypical cases, fail to exclude all slide and scanning artifacts from the background, and are unable to segment adipose tissue. Pen marking artifacts in particular can be a potential source of bias for subsequent analyses if not removed. In addition, several applications require the separation of individual cross-sections, which can be challenging due to tissue fragmentation and adjacent positioning. To address these problems, we develop a convolutional neural network for tissue and pen marking segmentation using a dataset of 200 H&E stained WSIs. For separating tissue cross-sections, we propose a novel post-processing method based on clustering predicted centroid locations of the cross-sectio
    
[^18]: 采用乐器特定输入表示和扩散外扩技术的表现力丰富的声学吉他声音合成

    Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting. (arXiv:2401.13498v1 [cs.SD])

    [http://arxiv.org/abs/2401.13498](http://arxiv.org/abs/2401.13498)

    本文提出了一种采用乐器特定输入表示和扩散外扩技术的表现力丰富的声学吉他声音合成模型，通过定量和定性评估，展示了该模型比其他模型具有更高的音频质量和更加逼真的音色声音。

    

    由于复音和表现的高度变异，合成演奏吉他声音是一项极具挑战性的任务。最近，深度生成模型在从音乐乐谱中合成表现力丰富的多音乐器声音方面显示出了有希望的结果，通常使用通用的MIDI输入。在这项工作中，我们提出了一种具有自定义乐器输入表示的表现力丰富的声学吉他声音合成模型，我们称之为guitarroll。我们使用基于扩散的外扩技术实现了所提出的方法，该技术可以生成具有长期一致性的音频。为了克服缺乏MIDI/音频配对数据集的问题，我们不仅使用了现有的吉他数据集，还从高质量的基于样本的吉他合成器中收集了数据。通过定量和定性评估，我们展示了我们提出的模型比基准模型具有更高的音频质量，并且比先前的领先工作生成更加逼真的音色声音。

    Synthesizing performing guitar sound is a highly challenging task due to the polyphony and high variability in expression. Recently, deep generative models have shown promising results in synthesizing expressive polyphonic instrument sounds from music scores, often using a generic MIDI input. In this work, we propose an expressive acoustic guitar sound synthesis model with a customized input representation to the instrument, which we call guitarroll. We implement the proposed approach using diffusion-based outpainting which can generate audio with long-term consistency. To overcome the lack of MIDI/audio-paired datasets, we used not only an existing guitar dataset but also collected data from a high quality sample-based guitar synthesizer. Through quantitative and qualitative evaluations, we show that our proposed model has higher audio quality than the baseline model and generates more realistic timbre sounds than the previous leading work.
    
[^19]: 分离的物理信息神经网络用于弹性问题的求解

    Separable Physics-Informed Neural Networks for the solution of elasticity problems. (arXiv:2401.13486v1 [math.NA])

    [http://arxiv.org/abs/2401.13486](http://arxiv.org/abs/2401.13486)

    本文提出了一种基于分离的物理信息神经网络（SPINN）和深度能量方法（DEM）的弹性问题求解方法，该方法在收敛速度和精度上显著优于传统的物理信息神经网络（PINN），并且在复杂几何体上的线性弹性理论问题方面具有应用潜力。

    

    本文提出了一种基于分离的物理信息神经网络（SPINN）和深度能量方法（DEM）的弹性问题求解方法。通过数值实验，证明该方法的收敛速度和精度显著高于传统的物理信息神经网络（PINN）以及基于偏微分方程（PDEs）的SPINN。此外，利用SPINN在DEM方法框架下，还可以解决复杂几何体上的线性弹性理论问题，而传统的PINN在偏微分方程框架下无法实现。所考虑的问题在几何形状、加载和材料参数方面非常接近工业问题。

    A method for solving elasticity problems based on separable physics-informed neural networks (SPINN) in conjunction with the deep energy method (DEM) is presented. Numerical experiments have been carried out for a number of problems showing that this method has a significantly higher convergence rate and accuracy than the vanilla physics-informed neural networks (PINN) and even SPINN based on a system of partial differential equations (PDEs). In addition, using the SPINN in the framework of DEM approach it is possible to solve problems of the linear theory of elasticity on complex geometries, which is unachievable with the help of PINNs in frames of partial differential equations. Considered problems are very close to the industrial problems in terms of geometry, loading, and material parameters.
    
[^20]: 通过多样性启示的多Agent诊断方法用于稳健性

    Multi-Agent Diagnostics for Robustness via Illuminated Diversity. (arXiv:2401.13460v1 [cs.LG])

    [http://arxiv.org/abs/2401.13460](http://arxiv.org/abs/2401.13460)

    MADRID是一种新方法，通过生成多样化的对抗场景来揭示预训练多Agent策略的战略漏洞，并通过遗憾值衡量漏洞的程度。

    

    在快速发展的多Agent系统领域中，确保在陌生和敌对环境中的稳健性至关重要。尽管这些系统在熟悉环境中表现出色，但在新情况下往往会因为训练阶段的过拟合而失败。在既包含合作又包含竞争行为的环境中，这一问题尤为突出，体现了过拟合和泛化挑战的双重性质。为了解决这个问题，我们提出了通过多样性启示的多Agent稳健性诊断（MADRID），这是一种生成多Agent策略中暴露战略漏洞的多样化对抗场景的新方法。MADRID利用开放式学习的概念，导航对抗环境的广阔空间，使用目标策略的遗憾值来衡量这些环境的漏洞。我们在11vs11版的Google Research Football上评估了MADRID的有效性。

    In the rapidly advancing field of multi-agent systems, ensuring robustness in unfamiliar and adversarial settings is crucial. Notwithstanding their outstanding performance in familiar environments, these systems often falter in new situations due to overfitting during the training phase. This is especially pronounced in settings where both cooperative and competitive behaviours are present, encapsulating a dual nature of overfitting and generalisation challenges. To address this issue, we present Multi-Agent Diagnostics for Robustness via Illuminated Diversity (MADRID), a novel approach for generating diverse adversarial scenarios that expose strategic vulnerabilities in pre-trained multi-agent policies. Leveraging the concepts from open-ended learning, MADRID navigates the vast space of adversarial settings, employing a target policy's regret to gauge the vulnerabilities of these settings. We evaluate the effectiveness of MADRID on the 11vs11 version of Google Research Football, one o
    
[^21]: 通过强化学习求解符号方程

    Symbolic Equation Solving via Reinforcement Learning. (arXiv:2401.13447v1 [cs.LG])

    [http://arxiv.org/abs/2401.13447](http://arxiv.org/abs/2401.13447)

    本文利用强化学习和深度神经网络自动化地找到基本变换规则和逐步解决方案，实现了符号方程的求解。

    

    机器学习方法逐渐在各种社会、经济和科学环境中得到应用，然而在精确数学上它们常常遇到困难。一个典型的例子是计算机代数，包括简化数学术语、计算形式导数或找到代数方程的精确解等任务。传统的软件包通常基于一个巨大的规则数据库，这些规则描述了一个特定操作（例如导数）如何将一个术语（例如正弦函数）转化为另一个（例如余弦函数）。迄今为止，这些规则通常需要人类发现并编程。重点讨论解决符号形式的线性方程的范例，我们展示了如何利用深度神经网络的强化学习自动化地找到基本变换规则和逐步解决方案的过程。

    Machine-learning methods are gradually being adopted in a great variety of social, economic, and scientific contexts, yet they are notorious for struggling with exact mathematics. A typical example is computer algebra, which includes tasks like simplifying mathematical terms, calculating formal derivatives, or finding exact solutions of algebraic equations. Traditional software packages for these purposes are commonly based on a huge database of rules for how a specific operation (e.g., differentiation) transforms a certain term (e.g., sine function) into another one (e.g., cosine function). Thus far, these rules have usually needed to be discovered and subsequently programmed by humans. Focusing on the paradigmatic example of solving linear equations in symbolic form, we demonstrate how the process of finding elementary transformation rules and step-by-step solutions can be automated using reinforcement learning with deep neural networks.
    
[^22]: 相关随机向量的检测

    Detection of Correlated Random Vectors. (arXiv:2401.13429v1 [cs.IT])

    [http://arxiv.org/abs/2401.13429](http://arxiv.org/abs/2401.13429)

    本文研究了判断两个标准正态随机向量是否相关的问题，提出了一种新的方法来评估似然比的二阶矩，并发现了与整数分割函数之间的联系。

    

    在本文中，我们研究了判断两个标准正态随机向量$\mathsf{X}\in\mathbb{R}^{n}$和$\mathsf{Y}\in\mathbb{R}^{n}$是否相关的问题。这被表述为一个假设检验问题，在零假设下，这些向量是统计独立的，而在备择假设下，$\mathsf{X}$和随机均匀置换的$\mathsf{Y}$是具有相关系数$\rho$的。我们分析了信息论上不可能和可能的最优测试阈值，作为$n$和$\rho$的函数。为了得出我们的信息论下界，我们开发了一种利用正交多项式展开来评估似然比的二阶矩的新技术，该技术揭示了与整数分割函数之间的一个令人惊讶的联系。我们还研究了上述设置的多维泛化，其中我们观察到两个数据库/矩阵，而不是两个向量。

    In this paper, we investigate the problem of deciding whether two standard normal random vectors $\mathsf{X}\in\mathbb{R}^{n}$ and $\mathsf{Y}\in\mathbb{R}^{n}$ are correlated or not. This is formulated as a hypothesis testing problem, where under the null hypothesis, these vectors are statistically independent, while under the alternative, $\mathsf{X}$ and a randomly and uniformly permuted version of $\mathsf{Y}$, are correlated with correlation $\rho$. We analyze the thresholds at which optimal testing is information-theoretically impossible and possible, as a function of $n$ and $\rho$. To derive our information-theoretic lower bounds, we develop a novel technique for evaluating the second moment of the likelihood ratio using an orthogonal polynomials expansion, which among other things, reveals a surprising connection to integer partition functions. We also study a multi-dimensional generalization of the above setting, where rather than two vectors we observe two databases/matrices
    
[^23]: 具有分布式固定设计量子芯片和量子信道的联邦学习

    Federated learning with distributed fixed design quantum chips and quantum channels. (arXiv:2401.13421v1 [quant-ph])

    [http://arxiv.org/abs/2401.13421](http://arxiv.org/abs/2401.13421)

    本论文提出了一种具有分布式固定设计量子芯片和量子信道的量子联邦学习模型，通过量子态的传递和聚合梯度来更新参数，提供更高的隐私保护和指数级的效率。

    

    经过客户端的精心设计查询，经典联邦学习中的隐私可以被突破。然而，由于数据中的测量会导致信息的丢失，量子通信信道被认为更加安全，因为可以检测到这种信息丢失。因此，量子版本的联邦学习可以提供更多的隐私保护。此外，通过量子信道发送N维数据向量需要发送log N个纠缠态量子比特，如果数据向量作为量子态获取，这可以提供指数级的效率。在本文中，我们提出了一种量子联邦学习模型，其中基于由集中式服务器发送的量子态，操作固定设计的量子芯片。基于接收到的叠加态，客户端计算并将其本地梯度作为量子态发送到服务器，服务器将这些梯度聚合以更新参数。由于服务器不发送模型信息，

    The privacy in classical federated learning can be breached through the use of local gradient results by using engineered queries from the clients. However, quantum communication channels are considered more secure because the use of measurements in the data causes some loss of information, which can be detected. Therefore, the quantum version of federated learning can be used to provide more privacy. Additionally, sending an $N$ dimensional data vector through a quantum channel requires sending $\log N$ entangled qubits, which can provide exponential efficiency if the data vector is obtained as quantum states.  In this paper, we propose a quantum federated learning model where fixed design quantum chips are operated based on the quantum states sent by a centralized server. Based on the coming superposition states, the clients compute and then send their local gradients as quantum states to the server, where they are aggregated to update parameters. Since the server does not send model
    
[^24]: 如何在联邦在线学习排序中忘记客户？

    How to Forget Clients in Federated Online Learning to Rank?. (arXiv:2401.13410v1 [cs.CR])

    [http://arxiv.org/abs/2401.13410](http://arxiv.org/abs/2401.13410)

    本文研究了如何在联邦在线学习排序中删除客户的贡献，提出了一种有效和高效的取消学习方法。

    

    数据保护法规如欧盟的《通用数据保护条例》（GDPR）建立了“被遗忘的权利”：用户（客户）可以要求将使用他们的数据进行的贡献从学习的模型中删除。本文研究了如何删除参与联邦在线学习排序（FOLTR）系统中客户所做的贡献。在FOLTR系统中，通过聚合局部更新到全局排序模型来学习排序器。局部更新是以在线方式在客户级别上使用查询和隐式交互来学习的，这些查询和交互发生在特定客户内部。通过这样做，每个客户的本地数据不会与其他客户或集中式搜索服务共享，同时客户可以从联邦中的每个客户的贡献中受益。在本文中，我们研究了一种有效和高效的取消学习方法，可以删除客户的贡献。

    Data protection legislation like the European Union's General Data Protection Regulation (GDPR) establishes the \textit{right to be forgotten}: a user (client) can request contributions made using their data to be removed from learned models. In this paper, we study how to remove the contributions made by a client participating in a Federated Online Learning to Rank (FOLTR) system. In a FOLTR system, a ranker is learned by aggregating local updates to the global ranking model. Local updates are learned in an online manner at a client-level using queries and implicit interactions that have occurred within that specific client. By doing so, each client's local data is not shared with other clients or with a centralised search service, while at the same time clients can benefit from an effective global ranking model learned from contributions of each client in the federation.  In this paper, we study an effective and efficient unlearning method that can remove a client's contribution with
    
[^25]: 文本分类可以增强领域无关的停用词提取

    Text Categorization Can Enhance Domain-Agnostic Stopword Extraction. (arXiv:2401.13398v1 [cs.CL])

    [http://arxiv.org/abs/2401.13398](http://arxiv.org/abs/2401.13398)

    本文研究了文本分类在自然语言处理中简化停用词提取的作用，通过混合统计和语言学方法创建全面的停用词列表，提高了非洲语言的自然语言处理水平。

    

    本文研究了文本分类在自然语言处理中简化停用词提取的作用，特别关注了包括法语在内的9种非洲语言。通过利用MasakhaNEWS、African Stopwords Project和MasakhaPOS数据集，我们发现，文本分类可以有效地识别大多数考察语言中超过80％的领域无关的停用词。然而，语言变异导致某些语言的识别率较低。有趣的是，我们发现虽然超过40％的停用词在各类新闻中都是共同的，但少于15％的停用词是某一类别独有的。不常见的停用词增加了文本的深度，但它们是否被分类为停用词则取决于上下文。因此，结合统计和语言学方法可以创建全面的停用词列表，凸显了我们混合方法的价值。这项研究提高了非洲语言的自然语言处理水平，并强调了文本分类的重要性。

    This paper investigates the role of text categorization in streamlining stopword extraction in natural language processing (NLP), specifically focusing on nine African languages alongside French. By leveraging the MasakhaNEWS, African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that text categorization effectively identifies domain-agnostic stopwords with over 80% detection success rate for most examined languages. Nevertheless, linguistic variances result in lower detection rates for certain languages. Interestingly, we find that while over 40% of stopwords are common across news categories, less than 15% are unique to a single category. Uncommon stopwords add depth to text but their classification as stopwords depends on context. Therefore combining statistical and linguistic approaches creates comprehensive stopword lists, highlighting the value of our hybrid method. This research enhances NLP for African languages and underscores the importance of text catego
    
[^26]: 超越准确性和公平性：停止仅根据群组间指标评估偏见缓解方法

    Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely on between-group metrics. (arXiv:2401.13391v1 [cs.LG])

    [http://arxiv.org/abs/2401.13391](http://arxiv.org/abs/2401.13391)

    本文对评估偏见缓解技术的流行度指标提出质疑，认为它们没有考虑到群组内的变化，并且导致的预测标签不能完全反映现实情况。

    

    人工智能在各个领域得到广泛应用，引发了对其公平性的关注。虽然公平性在人工智能中仍然是一个核心关注点，但目前的讨论往往强调基于结果的指标，而没有对子群体中的差异影响进行细致考虑。偏见缓解技术不仅影响敏感群组之间的实例排序，而且通常还显著影响这些群组内实例的排序。这些变化难以解释，并引起了对干预的有效性的担忧。不幸的是，这些效应在通常应用的准确性-公平性评估框架中往往被忽视。本文对评估偏见缓解技术的流行度指标提出了质疑，认为它们没有考虑到群组内的变化，并且导致的预测标签不能完全反映现实情况。

    Artificial Intelligence (AI) finds widespread applications across various domains, sparking concerns about fairness in its deployment. While fairness in AI remains a central concern, the prevailing discourse often emphasizes outcome-based metrics without a nuanced consideration of the differential impacts within subgroups. Bias mitigation techniques do not only affect the ranking of pairs of instances across sensitive groups, but often also significantly affect the ranking of instances within these groups. Such changes are hard to explain and raise concerns regarding the validity of the intervention. Unfortunately, these effects largely remain under the radar in the accuracy-fairness evaluation framework that is usually applied. This paper challenges the prevailing metrics for assessing bias mitigation techniques, arguing that they do not take into account the changes within-groups and that the resulting prediction labels fall short of reflecting real-world scenarios. We propose a para
    
[^27]: 在资源受限的异步联邦学习系统中减轻系统偏差

    Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems. (arXiv:2401.13366v1 [cs.LG])

    [http://arxiv.org/abs/2401.13366](http://arxiv.org/abs/2401.13366)

    该论文提出了一种在资源受限的异步联邦学习系统中减轻系统偏差的动态全局模型聚合方法，通过根据客户端的上传频率评分和调整模型更新的权重，以适应异构设备和非同分布数据的挑战。实验结果表明，在仿真环境中，与最先进的方法相比，该方法在全局模型准确性上有显著的改善。

    

    联邦学习系统在处理异构设备和客户端非同分布数据时面临性能挑战。我们提出一种动态全局模型聚合方法来解决这些问题。我们的聚合方法根据客户端的上传频率对其模型更新进行评分和调整权重，以适应设备能力的差异。此外，我们还在客户端上传本地模型后立即向其提供更新的全局模型，以减少空闲时间并提高训练效率。我们在一个包含10个模拟客户端的异步联邦学习部署中评估了我们的方法，这些客户端具有异构计算约束和非IID数据。使用FashionMNIST数据集的仿真结果表明，与最先进的方法PAPAYA和FedAsync相比，全局模型的准确性改善了10%和19%。我们的动态聚合方法可以实现可靠的全局模型更新。

    Federated learning (FL) systems face performance challenges in dealing with heterogeneous devices and non-identically distributed data across clients. We propose a dynamic global model aggregation method within Asynchronous Federated Learning (AFL) deployments to address these issues. Our aggregation method scores and adjusts the weighting of client model updates based on their upload frequency to accommodate differences in device capabilities. Additionally, we also immediately provide an updated global model to clients after they upload their local models to reduce idle time and improve training efficiency. We evaluate our approach within an AFL deployment consisting of 10 simulated clients with heterogeneous compute constraints and non-IID data. The simulation results, using the FashionMNIST dataset, demonstrate over 10% and 19% improvement in global model accuracy compared to state-of-the-art methods PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows reliable g
    
[^28]: 对抗噪声标签的无偏样本选择

    Debiased Sample Selection for Combating Noisy Labels. (arXiv:2401.13360v1 [cs.LG])

    [http://arxiv.org/abs/2401.13360](http://arxiv.org/abs/2401.13360)

    本文提出了一个无噪声专家模型（ITEM）来解决样本选择中的训练偏差和数据偏差问题。通过设计一个鲁棒的网络架构来集成多个专家，可以减少选择集不平衡和累积错误，并在使用更少参数的情况下实现更好的选择和预测性能。

    

    学习使用噪声标签旨在确保模型在标签错误的训练集上具有泛化能力。样本选择策略通过选择可靠的标签子集来实现有希望的性能。本文实证表明，现有的样本选择方法在实践中存在数据和训练偏差，分别表示为选择集不平衡和累积错误。然而，先前的研究只处理了训练偏差。为了解决这个局限性，我们提出了一个适用于样本选择的无噪声专家模型（ITEM）。具体来说，为了减轻训练偏差，我们设计了一个鲁棒的网络架构，与多个专家集成。与目前的双分支网络相比，我们的网络在训练更少参数的情况下，通过集成这些专家来实现更好的选择和预测性能。同时，为了减轻数据偏差，我们提出了一种混合采样策略。

    Learning with noisy labels aims to ensure model generalization given a label-corrupted training set. The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training. In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively. However, only the training bias was handled in previous studies. To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection. Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts. Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling strat
    
[^29]: 机器学习在符号计算中的数据集和范式的教训：基于CAD的案例研究

    Lessons on Datasets and Paradigms in Machine Learning for Symbolic Computation: A Case Study on CAD. (arXiv:2401.13343v1 [cs.SC])

    [http://arxiv.org/abs/2401.13343](http://arxiv.org/abs/2401.13343)

    这项研究提出了机器学习在符号计算中的应用经验教训，包括在机器学习之前对数据集进行分析的重要性以及不同机器学习范式的选择。通过在柱面代数分解中的变量排序选择中的案例研究，发现了数据集中的不平衡问题，并引入了增强技术来改善数据集的平衡性。

    

    符号计算算法及其在计算机代数系统中的实现通常包含一些选择，这些选择不会影响结果的正确性，但对所需资源有显著影响：利用机器学习模型可以针对每个问题单独做出这些选择。本研究报告了在符号计算中使用机器学习的经验教训，特别是在机器学习之前对数据集进行分析的重要性，以及可能使用的不同机器学习范式。下面以柱面代数分解中的变量排序选择作为一个具体案例研究的结果来展示，但认为所学到的教训适用于符号计算中的其他决策。我们利用一个现有的从应用中导出的示例数据集，发现该数据集在变量排序决策方面存在不平衡。我们引入了一个多项式系统问题的增强技术，使得每个问题可以有多个示例以增强数据集的平衡性。

    Symbolic Computation algorithms and their implementation in computer algebra systems often contain choices which do not affect the correctness of the output but can significantly impact the resources required: such choices can benefit from having them made separately for each problem via a machine learning model. This study reports lessons on such use of machine learning in symbolic computation, in particular on the importance of analysing datasets prior to machine learning and on the different machine learning paradigms that may be utilised. We present results for a particular case study, the selection of variable ordering for cylindrical algebraic decomposition, but expect that the lessons learned are applicable to other decisions in symbolic computation.  We utilise an existing dataset of examples derived from applications which was found to be imbalanced with respect to the variable ordering decision. We introduce an augmentation technique for polynomial systems problems that allow
    
[^30]: 全贝叶斯神经网络显著性检验

    Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])

    [http://arxiv.org/abs/2401.13335](http://arxiv.org/abs/2401.13335)

    该论文提出了一种全贝叶斯神经网络显著性检验方法（nFBST），通过利用贝叶斯神经网络拟合非线性和多维关系，并计算证据值来替代传统方法中的理论推导，该方法能够测试全局、局部和实例级的显著性。

    

    显著性检验旨在确定给定观测结果，关于总体分布的命题是否为真。然而，传统的显著性检验通常需要推导出检验统计量的分布，无法处理复杂的非线性关系。本文提出了一种用于神经网络的全贝叶斯显著性检验方法，称为nFBST，旨在克服传统方法在关系表征方面的局限性。利用贝叶斯神经网络拟合非线性和多维关系，并通过计算证据值而不是进行繁琐的理论推导来避免错误。此外，nFBST还可以测试全局、局部和实例级的显著性，这是之前的检验方法所不关注的。此外，nFBST是一个通用框架，可以根据所选的度量进行扩展，如Grad-nFBST，LRP-nFBST，DeepLIFT-nFBST。

    Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\textit{n}FBST, LRP-\textit{n}FBST, DeepLIFT-\t
    
[^31]: 可解释性贝叶斯优化

    Explainable Bayesian Optimization. (arXiv:2401.13334v1 [cs.LG])

    [http://arxiv.org/abs/2401.13334](http://arxiv.org/abs/2401.13334)

    本论文介绍了一种可解释性贝叶斯优化的方法，通过TNTRules生成高质量的解释，填补了贝叶斯优化和可解释人工智能之间的间隙。

    

    在工业领域，贝叶斯优化（BO）被广泛应用于人工智能协作参数调优的控制系统中。然而，由于近似误差和简化目标，BO的解决方案可能偏离人类专家的真实目标，需要后续调整。BO的黑盒特性限制了协作调优过程，因为专家不信任BO的建议。目前的可解释人工智能（XAI）方法不适用于优化问题，因此无法解决此间隙。为了填补这一间隙，我们提出了TNTRules（TUNE-NOTUNE规则），一种事后基于规则的可解释性方法，通过多目标优化生成高质量的解释。我们对基准优化问题和实际超参数优化任务的评估表明，TNTRules在生成高质量解释方面优于最先进的XAI方法。这项工作对BO和XAI的交叉领域做出了贡献，提供了可解释的优化方法。

    In industry, Bayesian optimization (BO) is widely applied in the human-AI collaborative parameter tuning of cyber-physical systems. However, BO's solutions may deviate from human experts' actual goal due to approximation errors and simplified objectives, requiring subsequent tuning. The black-box nature of BO limits the collaborative tuning process because the expert does not trust the BO recommendations. Current explainable AI (XAI) methods are not tailored for optimization and thus fall short of addressing this gap. To bridge this gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-based explainability method that produces high quality explanations through multiobjective optimization. Our evaluation of benchmark optimization problems and real-world hyperparameter optimization tasks demonstrates TNTRules' superiority over state-of-the-art XAI methods in generating high quality explanations. This work contributes to the intersection of BO and XAI, providing interpretable opt
    
[^32]: NACHOS: 硬件受限的早期退出神经网络的神经架构搜索

    NACHOS: Neural Architecture Search for Hardware Constrained Early Exit Neural Networks. (arXiv:2401.13330v1 [cs.LG])

    [http://arxiv.org/abs/2401.13330](http://arxiv.org/abs/2401.13330)

    NACHOS 是一种面向硬件受限的早期退出神经网络的神经架构搜索方法，可以自动化设计早期退出神经网络并考虑骨干和早期退出分类器之间的关系。

    

    早期退出神经网络（EENNs）为标准的深度神经网络（DNN）配备早期退出分类器（EECs），在处理的中间点上提供足够的分类置信度时进行预测。这在效果和效率方面带来了许多好处。目前，EENNs的设计是由专家手动完成的，这是一项复杂和耗时的任务，需要考虑许多方面，包括正确的放置、阈值设置和EECs的计算开销。因此，研究正在探索使用神经架构搜索（NAS）自动化设计EENNs。目前，文献中提出了几个完整的NAS解决方案用于EENNs，并且一个完全自动化的综合设计策略，同时考虑骨干和EECs仍然是一个未解决的问题。为此，本研究呈现了面向硬件受限的早期退出神经网络的神经架构搜索（NACHOS）。

    Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN) with Early Exit Classifiers (EECs), to provide predictions at intermediate points of the processing when enough confidence in classification is achieved. This leads to many benefits in terms of effectiveness and efficiency. Currently, the design of EENNs is carried out manually by experts, a complex and time-consuming task that requires accounting for many aspects, including the correct placement, the thresholding, and the computational overhead of the EECs. For this reason, the research is exploring the use of Neural Architecture Search (NAS) to automatize the design of EENNs. Currently, few comprehensive NAS solutions for EENNs have been proposed in the literature, and a fully automated, joint design strategy taking into consideration both the backbone and the EECs remains an open problem. To this end, this work presents Neural Architecture Search for Hardware Constrained Early Exit Neural Networks (NACHOS),
    
[^33]: 为隐私保护可穿戴压力检测生成合成健康传感器数据

    Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable Stress Detection. (arXiv:2401.13327v1 [cs.LG])

    [http://arxiv.org/abs/2401.13327](http://arxiv.org/abs/2401.13327)

    本论文介绍了一种隐私保护的合成健康传感器数据的方法，通过生成对抗网络（GANs）和差分隐私（DP）防护，生成与压力时刻相关的合成序列数据，确保患者信息的保护，并对合成数据进行质量评估。在压力检测数据集上验证了该方法的有效性。

    

    智能手表的健康传感器数据在智能健康应用和患者监测中越来越被使用，包括压力检测。然而，这类医疗数据往往包含敏感的个人信息，并且获取这些数据以进行研究是资源密集型的。为了应对这一挑战，我们介绍了一种关注隐私的合成多传感器智能手表健康读数与压力时刻相关的方法。我们的方法包括通过生成对抗网络（GANs）生成合成序列数据，并在模型训练过程中实施差分隐私（DP）防护以保护患者信息。为了确保合成数据的完整性，我们采用一系列质量评估，并监测合成数据与原始数据之间的合理性。为了测试其有用性，我们在一个常用但规模较小的压力检测数据集上创建了私有机器学习模型，并探索了增强现有数据基础的策略。

    Smartwatch health sensor data is increasingly utilized in smart health applications and patient monitoring, including stress detection. However, such medical data often comprises sensitive personal information and is resource-intensive to acquire for research purposes. In response to this challenge, we introduce the privacy-aware synthetization of multi-sensor smartwatch health readings related to moments of stress. Our method involves the generation of synthetic sequence data through Generative Adversarial Networks (GANs), coupled with the implementation of Differential Privacy (DP) safeguards for protecting patient information during model training. To ensure the integrity of our synthetic data, we employ a range of quality assessments and monitor the plausibility between synthetic and original data. To test the usefulness, we create private machine learning models on a commonly used, albeit small, stress detection dataset, exploring strategies for enhancing the existing data foundat
    
[^34]: ConTextual: 在大型多模态模型中评估上下文敏感的文本富有视觉推理

    ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models. (arXiv:2401.13311v1 [cs.CV])

    [http://arxiv.org/abs/2401.13311](http://arxiv.org/abs/2401.13311)

    本文介绍了一个新颖的基准ConTextual，用于评估能够进行上下文敏感的文本富有视觉推理的大型多模态模型。研究发现，目前最好的模型GPT-4V在抽象类别表现出色，但在整体性能上仍然落后于人类，存在改进的空间。

    

    最近人工智能的进步导致了大型多模态模型（LMMs）的发展，这些模型能够处理涉及文本和图像内容的复杂任务，例如在公共场所导航地图。本文介绍了ConTextual，这是一个新颖的基准，包括专门设计的指令，用于评估LMMs在执行上下文敏感的文本富有视觉推理方面的能力。ConTextual强调了多样的现实世界场景（例如时间阅读、导航、购物等），要求更深入地理解文本和视觉元素之间的相互作用。我们的研究结果显示，最佳表现的LMM，GPT-4V(ision)，与人类能力之间存在30.8%的性能差距，使用人类评估指出在上下文敏感的文本富有视觉推理方面还有很大的改进空间。值得注意的是，虽然GPT-4V在抽象类别（如模因和引文解释）中表现出色，但其整体性能仍然落后于人类。

    Recent advancements in AI have led to the development of large multimodal models (LMMs) capable of processing complex tasks involving joint reasoning over text and visual content in the image (e.g., navigating maps in public places). This paper introduces ConTextual, a novel benchmark comprising instructions designed explicitly to evaluate LMMs' ability to perform context-sensitive text-rich visual reasoning. ConTextual emphasizes diverse real-world scenarios (e.g., time-reading, navigation, shopping and more) demanding a deeper understanding of the interactions between textual and visual elements. Our findings reveal a significant performance gap of 30.8% between the best-performing LMM, GPT-4V(ision), and human capabilities using human evaluation indicating substantial room for improvement in context-sensitive text-rich visual reasoning. Notably, while GPT-4V excelled in abstract categories like meme and quote interpretation, its overall performance still lagged behind humans. In add
    
[^35]: 通过机器学习技术对放射学孤立综合征和临床孤立综合征进行分类

    Classification of Radiologically Isolated Syndrome and Clinically Isolated Syndrome with Machine-Learning Techniques. (arXiv:2401.13301v1 [cs.LG])

    [http://arxiv.org/abs/2401.13301](http://arxiv.org/abs/2401.13301)

    这项研究使用机器学习技术对放射学孤立综合征（RIS）和临床孤立综合征（CIS）进行分类，通过结合多模态3T MRI的生物标志物，提高了对亚临床形式的检测，有助于区分患者。

    

    背景和目的：在磁共振成像中，无症状主题的大脑白质病变被称为放射学孤立综合征（RIS）。早期多发性硬化症（MS）[即临床孤立综合征（CIS）]与RIS之间的区别在于是否发生临床事件，因此，在不干扰MRI的情况下，提高对亚临床形式的检测是合理的，因为已有放射学诊断标准。我们的目标是使用机器学习分类方法识别形态测量指标，帮助区分RIS患者和CIS患者。方法：我们使用多模态3T MRI方法，结合MRI生物标志物（皮层厚度、皮层和皮质下灰质体积以及白质完整性），对17名RIS患者和17名CIS患者的单个患者进行分类。结果：预测dia

    Background and purpose: The unanticipated detection by magnetic resonance imaging (MRI) in the brain of asymptomatic subjects of white matter lesions suggestive of multiple sclerosis (MS) has been named radiologically isolated syndrome (RIS). As the difference between early MS [i.e. clinically isolated syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to improve detection of the subclinical form without interfering with MRI as there are radiological diagnostic criteria for that. Our objective was to use machine-learning classification methods to identify morphometric measures that help to discriminate patients with RIS from those with CIS.  Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers (cortical thickness, cortical and subcortical grey matter volume, and white matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS for single-subject level classification.  Results: The best proposed models to predict the dia
    
[^36]: RefreshNet: 通过分层刷新学习多尺度动态

    RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing. (arXiv:2401.13282v1 [cs.LG])

    [http://arxiv.org/abs/2401.13282](http://arxiv.org/abs/2401.13282)

    RefreshNet是一个多尺度框架，通过分层刷新机制来学习复杂系统的动态，实现了计算效率和预测准确性的平衡。

    

    预测复杂系统动力学，特别是对于长期预测，始终受到误差累积和计算负担的限制。本研究提出了RefreshNet，这是一个多尺度框架，旨在克服这些挑战，提供了计算效率和预测准确性之间的前所未有的平衡。RefreshNet结合了卷积自动编码器，用于识别捕捉动态的基本特征的降阶潜在空间，并在潜在空间内策略性地使用多个时间分辨率不同的递归神经网络（RNN）块，从而允许多个时间尺度上捕捉潜在动态。RefreshNet中的独特的“刷新”机制允许较粗糙的块重新设置较细块的输入，有效控制和减轻误差累积。这种设计在计算效率和预测准确性方面表现出优越性，特别是在长期预测中。

    Forecasting complex system dynamics, particularly for long-term predictions, is persistently hindered by error accumulation and computational burdens. This study presents RefreshNet, a multiscale framework developed to overcome these challenges, delivering an unprecedented balance between computational efficiency and predictive accuracy. RefreshNet incorporates convolutional autoencoders to identify a reduced order latent space capturing essential features of the dynamics, and strategically employs multiple recurrent neural network (RNN) blocks operating at varying temporal resolutions within the latent space, thus allowing the capture of latent dynamics at multiple temporal scales. The unique "refreshing" mechanism in RefreshNet allows coarser blocks to reset inputs of finer blocks, effectively controlling and alleviating error accumulation. This design demonstrates superiority over existing techniques regarding computational efficiency and predictive accuracy, especially in long-term
    
[^37]: 自适应众包通过自监督学习

    Adaptive Crowdsourcing Via Self-Supervised Learning. (arXiv:2401.13239v1 [cs.LG])

    [http://arxiv.org/abs/2401.13239](http://arxiv.org/abs/2401.13239)

    本论文介绍了一种新的自适应众包方法，通过利用自监督学习和新颖的聚合方案，根据众包工作者对先前数量的估计调整权重，实现更准确的集体估计。该方法适应复杂模型和其他实际挑战，并通过理论和计算研究进行了验证。

    

    通常的众包系统通过对众多众包工作者提供的潜在利益数量的估计进行平均得到集体估计。我们开发了一种新方法--只预测其他人--利用自监督学习和一种新颖的聚合方案。这种方法根据他们对先前数量的估计给予众包工作者分配的权重来调整。当众包工作者的技能变化或他们的估计相关时，加权求和比平均求和提供更准确的集体估计。现有的算法，如期望最大化，至少在原则上可以产生类似准确的集体估计。然而，当需要使用诸如神经网络之类的复杂模型来表示众包工作者之间的关系时，它们的计算需求变得繁重。只预测其他人适应了这种复杂性以及许多其他实际挑战。我们通过理论和计算研究分析了只预测其他人的功效。其中

    Common crowdsourcing systems average estimates of a latent quantity of interest provided by many crowdworkers to produce a group estimate. We develop a new approach -- just-predict-others -- that leverages self-supervised learning and a novel aggregation scheme. This approach adapts weights assigned to crowdworkers based on estimates they provided for previous quantities. When skills vary across crowdworkers or their estimates correlate, the weighted sum offers a more accurate group estimate than the average. Existing algorithms such as expectation maximization can, at least in principle, produce similarly accurate group estimates. However, their computational requirements become onerous when complex models, such as neural networks, are required to express relationships among crowdworkers. Just-predict-others accommodates such complexity as well as many other practical challenges. We analyze the efficacy of just-predict-others through theoretical and computational studies. Among other 
    
[^38]: 如何合作：朝着最大化异构数据联邦学习的泛化性能迈进

    How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning. (arXiv:2401.13236v1 [cs.LG])

    [http://arxiv.org/abs/2401.13236](http://arxiv.org/abs/2401.13236)

    本文研究了异构数据联邦学习中的合作问题。通过推导出每个客户端的泛化界限，发现只有与拥有更多训练数据和相似数据分布的客户端合作，才能改善模型的泛化性能。根据这一分析，提出了基于层次聚类的合作训练方案。

    

    联邦学习（FL）作为一种保护隐私的分布式学习框架，吸引了广泛的关注。本文关注交叉数据源的FL，其中客户端在训练后成为模型所有者，并且只关心模型在本地数据上的泛化性能。由于数据异质性问题，要求所有客户端参加单一的FL训练过程可能会导致模型性能下降。为了调查合作的有效性，我们首先推导了每个客户端在与其他客户端合作或独立训练时的泛化界限。我们展示了仅通过与具有更多训练数据和相似数据分布的其他客户端合作，可以改善客户端的泛化性能。我们的分析使我们能够通过将客户端分成多个合作组来制定客户端效用最大化问题。然后提出了一种基于层次聚类的合作训练（HCCT）方案。

    Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework. In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data. Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation. To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently. We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution. Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups. A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, wh
    
[^39]: 从随机到有信息选择数据：基于多样性的方法优化人类注释和少样本学习

    From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])

    [http://arxiv.org/abs/2401.13229](http://arxiv.org/abs/2401.13229)

    该论文介绍了一种基于多样性的方法，从而优化人类注释和少样本学习。传统的随机选择数据方法忽视了数据的特征和模型的需求，而该方法将考虑这些因素，以提高数据选择的效率。

    

    自然语言处理中的一个主要挑战是获取用于监督学习的注释数据。一种选择是使用众包平台进行数据注释。然而，众包引入了与注释者的经验、一致性和偏见相关的问题。另一种选择是使用零样本方法，但与少样本或完全监督的方法相比，零样本方法有其局限性。最近由大型语言模型推动的最新进展显示出潜力，但在数据严重受限的专业领域中，它们往往难以适应。因此，最常见的方法是人类随机注释一组数据点来构建初始数据集。然而，随机抽样数据进行注释通常效率低下，因为它忽视了数据的特征和模型的特定需求。当处理不平衡数据集时，情况更加糟糕，因为随机抽样倾向于严重偏向多数类别，导致过多的注释数据。

    A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To
    
[^40]: 大规模异构图上基于大型语言模型的链接预测的可扩展性研究

    Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models. (arXiv:2401.13227v1 [cs.CL])

    [http://arxiv.org/abs/2401.13227](http://arxiv.org/abs/2401.13227)

    本研究探索了在大规模异构图上应用大型语言模型进行图学习的方法，提出了LPNL框架用于可扩展链接预测。通过创新的提示语和采样流程，以及分而治之的策略，成功解决了大规模图中的信息过载问题，并在实验中表现出了优越的性能。

    

    探索将大规模语言模型应用于图学习是一项新颖的努力。然而，大图中蕴含的大量信息给这一过程带来了重大挑战。本文侧重于链接预测任务，并介绍了LPNL（Link Prediction via Natural Language），这是一个基于大型语言模型的框架，用于大规模异构图上的可扩展链接预测。我们设计了能以自然语言表达图细节的创新提示语。我们提出了一个两阶段的采样流程，从大规模异构图中提取关键信息，并采用分而治之的策略来控制输入令牌数量在预定限制内，解决了信息过载的挑战。我们还通过自监督学习设计了一个用于链接预测的T5模型进行微调。在大型公共异构图上进行的广泛实验表明，LPNL的性能超过了各种先进的基准模型。

    Exploring the application of large-scale language models to graph learning is a novel endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This paper focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on a large language model designed for scalable link prediction on large-scale heterogeneous graphs.We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from large-scale heterogeneous graphs, and a divide-and-conquer strategy to control the input token count within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for for link prediction. Extensive experiments on a large public heterogeneous graphs demonstrate that LPNL outperforms various advanced baselin
    
[^41]: TEPI: 对稀缺标记的零样本基因组分类进行分类感知嵌入和伪成像

    TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification. (arXiv:2401.13219v1 [q-bio.GN])

    [http://arxiv.org/abs/2401.13219](http://arxiv.org/abs/2401.13219)

    本研究提出了一种针对稀缺标记的零样本基因组分类问题的解决方法，称为TEPI。通过将基因组表示为伪图像并将其映射到分类感知的嵌入空间，我们能够捕捉物种的组成和系统分类关系，实现了零样本学习。

    

    物种的基因组编码了有价值的进化、生物和系统分类信息，有助于物种识别、分类和理解基因易感性，如药物抗性和毒力。然而，巨大的物种数量给开发通用的全基因组分类工具带来了重大挑战。传统的生物信息学工具取得了显著进展，但缺乏可扩展性并且计算成本高。基于机器学习的框架显示出潜力，但必须解决具有长尾分布的大分类词汇的问题。在本研究中，我们通过使用TEPI，即分类感知嵌入和伪成像，来解决这个问题。我们将每个基因组表示为伪图像，并将其映射到分类感知的嵌入空间进行推理和分类。这个嵌入空间捕捉了物种的组成和系统分类关系，实现了零样本学习。

    A species' genetic code or genome encodes valuable evolutionary, biological, and phylogenetic information that aids in species recognition, taxonomic classification, and understanding genetic predispositions like drug resistance and virulence. However, the vast number of potential species poses significant challenges in developing a general-purpose whole genome classification tool. Traditional bioinformatics tools have made notable progress but lack scalability and are computationally expensive. Machine learning-based frameworks show promise but must address the issue of large classification vocabularies with long-tail distributions. In this study, we propose addressing this problem through zero-shot learning using TEPI, Taxonomy-aware Embedding and Pseudo-Imaging. We represent each genome as pseudo-images and map them to a taxonomy-aware embedding space for reasoning and classification. This embedding space captures compositional and phylogenetic relationships of species, enabling pre
    
[^42]: 关于联邦学习的原则性局部优化方法的研究

    On Principled Local Optimization Methods for Federated Learning. (arXiv:2401.13216v1 [cs.LG])

    [http://arxiv.org/abs/2401.13216](http://arxiv.org/abs/2401.13216)

    本论文提出了关于联邦学习中局部优化方法的研究，主要包括对FedAvg算法的界限探索以及提出了联邦加速随机梯度下降（FedAc）方法。

    

    联邦学习是一种分布式学习范式，通过在设备上协同进行学习，已经成为去中心化人工智能应用的一种有前景的方法。像联邦平均（FedAvg）这样的局部优化方法是联邦学习应用中最突出的方法。尽管这些方法简单且受欢迎，但对局部优化方法的理论理解仍然不够清晰。本论文旨在推进局部方法的理论基础，主要包括以下三个方面。首先，我们为FedAvg建立了严格的界限，这是联邦学习中最流行的算法。我们展示了FedAvg可能受到的一个我们称之为迭代偏见的概念，并且说明了额外的三阶平滑性假设如何减轻这种影响并导致更好的收敛速度。我们从随机微分方程的角度解释了这一现象。其次，我们提出了联邦加速随机梯度下降（FedAc），这是第一个有原则性且速度更快的联邦学习优化方法。

    Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions.  First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective.  Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled a
    
[^43]: AMANet：利用自适应多层次注意力网络提升SAR船舶检测

    AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network. (arXiv:2401.13214v1 [cs.CV])

    [http://arxiv.org/abs/2401.13214](http://arxiv.org/abs/2401.13214)

    本文提出了一种自适应多层次注意力网络(AMANet)，用于合成孔径雷达(SAR)图像中的船舶检测。该方法通过学习多尺度特征和自适应聚合显著特征，解决了海岸环境中小型和沿海船舶检测的挑战。

    

    最近，基于深度学习的方法已成功应用于合成孔径雷达(SAR)图像的船舶检测。尽管已经开发了许多船舶检测方法，但由于海岸环境中特征有限和杂乱干扰的原因，检测小型和沿海船舶仍然是一个重要挑战。为此，提出了一种新颖的自适应多层次注意力模块(AMAM)，用于学习多尺度特征，并在复杂环境中自适应地聚合显著特征。具体而言，我们首先融合相邻特征层的信息，增强对较小目标的检测，从而实现多尺度特征增强。然后，为了滤除复杂背景的负面效果，我们在通道上解剖之前融合的多级特征，单独挖掘显著区域，并自适应地汇集来自不同通道的特征。第三，我们提出了一种新颖的自适应多层次注意力网络(AMANet)，用于综合建模和船舶检测。

    Recently, methods based on deep learning have been successfully applied to ship detection for synthetic aperture radar (SAR) images. Despite the development of numerous ship detection methodologies, detecting small and coastal ships remains a significant challenge due to the limited features and clutter in coastal environments. For that, a novel adaptive multi-hierarchical attention module (AMAM) is proposed to learn multi-scale features and adaptively aggregate salient features from various feature layers, even in complex environments. Specifically, we first fuse information from adjacent feature layers to enhance the detection of smaller targets, thereby achieving multi-scale feature enhancement. Then, to filter out the adverse effects of complex backgrounds, we dissect the previously fused multi-level features on the channel, individually excavate the salient regions, and adaptively amalgamate features originating from different channels. Thirdly, we present a novel adaptive multi-h
    
[^44]: AdCorDA: 通过对抗修正和领域适应进行分类器改进

    AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation. (arXiv:2401.13212v1 [cs.CV])

    [http://arxiv.org/abs/2401.13212](http://arxiv.org/abs/2401.13212)

    AdCorDA方法通过对抗修正和领域适应改进预训练分类器网络，实验证明在CIFAR-100数据集上能够显著提升准确率，并且在权重量化的神经网络上也表现出显著的性能提升。

    

    本文描述了一种简单而有效的技术，用于改进预训练分类器网络。所提出的AdCorDA方法基于修改训练集，并利用网络权重和层输入之间的对偶性。我们称之为输入空间训练。该方法由两个阶段组成 - 对抗修正，然后进行领域适应。对抗修正使用对抗性攻击来修正错误的训练集分类。将训练集中错误分类的样本移除，并用对抗修正的样本替换，形成新的训练集，然后在第二阶段，进行领域适应回到原始训练集。大量的实验证明，在CIFAR-100数据集上，准确率提升超过5%。该技术可以直接应用于权重量化的神经网络的改进，实验证明在基线上性能得到了显著提升。

    This paper describes a simple yet effective technique for refining a pretrained classifier network. The proposed AdCorDA method is based on modification of the training set and making use of the duality between network weights and layer inputs. We call this input space training. The method consists of two stages - adversarial correction followed by domain adaptation. Adversarial correction uses adversarial attacks to correct incorrect training-set classifications. The incorrectly classified samples of the training set are removed and replaced with the adversarially corrected samples to form a new training set, and then, in the second stage, domain adaptation is performed back to the original training set. Extensive experimental validations show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The technique can be straightforwardly applied to refinement of weight-quantized neural networks, where experiments show substantial enhancement in performance over the baseline. T
    
[^45]: 图异常检测的多任务主动学习

    Multitask Active Learning for Graph Anomaly Detection. (arXiv:2401.13210v1 [cs.LG])

    [http://arxiv.org/abs/2401.13210](http://arxiv.org/abs/2401.13210)

    提出了一种名为MITIGATE的多任务主动学习的图异常检测框架，通过耦合节点分类任务，它能够检测到没有已知异常的离群节点，并利用多个任务的共享表示来提升检测性能。

    

    在网络时代，图机器学习已广泛应用于无处不在的图结构数据上。作为支持网络安全和提高基于图的应用程序鲁棒性的关键组件，图异常检测的重要性不断增加。虽然图神经网络（GNNs）在监督和半监督图异常检测方面表现出了效果，但其性能取决于足够的真实标签的可用性。在识别复杂图结构中的异常点方面，劳动密集型的特性在实际应用中带来了重大挑战。尽管如此，来自其他任务（例如节点分类）的间接监督信号相对丰富。本文提出了一种新颖的多任务主动图异常检测框架，名为MITIGATE。首先，通过耦合节点分类任务，MITIGATE能够检测到没有已知异常的离群节点。其次，利用多个任务的共享表示来提升检测性能。

    In the web era, graph machine learning has been widely used on ubiquitous graph-structured data. As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing. While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels. The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications. Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant. In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE. Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies. Secondly, MI
    
[^46]: 基于深度学习与不确定性量化的自我改进干扰管理

    Self-Improving Interference Management Based on Deep Learning With Uncertainty Quantification. (arXiv:2401.13206v1 [cs.LG])

    [http://arxiv.org/abs/2401.13206](http://arxiv.org/abs/2401.13206)

    本文提出了一种基于深度学习与不确定性量化的自我改进干扰管理框架，通过学习模型预测最优解决方案，并通过不确定性量化的方法评估其可信度。实验证明，该方法能够有效改进无线通信中的干扰管理性能。

    

    本文提出了一种基于深度学习与不确定性量化的突破性自我改进干扰管理框架，针对无线通信进行了定制化处理，以提高系统性能。我们的方法通过利用深度学习模型来预测最优干扰管理解决方案，解决了传统基于优化的算法所固有的计算挑战。该框架的一个重大突破是承认数据驱动模型的限制，特别是在训练数据集没有充分代表的场景中。为了克服这些挑战，我们提出了一种不确定性量化的方法，并伴随着一个资格标准，以评估模型预测的可信度。该框架根据量化的不确定性的预测可信度，策略性地在模型生成的解决方案和传统算法之间进行交替。实证结果表明，我们的方法在不确定性中引导下能够有效地改进干扰管理性能。

    This paper presents a groundbreaking self-improving interference management framework tailored for wireless communications, integrating deep learning with uncertainty quantification to enhance overall system performance. Our approach addresses the computational challenges inherent in traditional optimization-based algorithms by harnessing deep learning models to predict optimal interference management solutions. A significant breakthrough of our framework is its acknowledgment of the limitations inherent in data-driven models, particularly in scenarios not adequately represented by the training dataset. To overcome these challenges, we propose a method for uncertainty quantification, accompanied by a qualifying criterion, to assess the trustworthiness of model predictions. This framework strategically alternates between model-generated solutions and traditional algorithms, guided by a criterion that assesses the prediction credibility based on quantified uncertainties. Experimental res
    
[^47]: 基于拓扑感知嵌入记忆的学习扩展图

    Topology-aware Embedding Memory for Learning on Expanding Graphs. (arXiv:2401.13200v1 [cs.LG])

    [http://arxiv.org/abs/2401.13200](http://arxiv.org/abs/2401.13200)

    这篇论文提出了一个基于拓扑感知嵌入记忆的学习扩展图的框架，该框架可以解决在不断扩展的图上应用记忆回放技术导致的内存爆炸问题。

    

    基于记忆回放的技术在连续学习中应用广泛，但是直接应用于不断扩展的图会导致潜在的内存爆炸问题。为了解决这个问题，我们系统分析了内存爆炸问题的关键挑战，并提出了一个通用框架，即Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM)，来解决这个问题。该框架不仅将内存空间复杂度从$\mathcal{O}(nd^L)$降低到$\mathcal{O}(n)$，还充分利用了拓扑信息进行记忆回放。

    Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding graphs, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from $\mathcal{O}(nd^L)$ to $\mathcal{O}(n)$~\footnote{$n$: memory budget, $d$: average node degree, $L$: the radius of the GNN receptive field}, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subgraph via \textit{Topology-aware Embeddings} 
    
[^48]: 基于点云表示和扩散模型的晶体结构生成设计

    Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model. (arXiv:2401.13192v1 [cs.AI])

    [http://arxiv.org/abs/2401.13192](http://arxiv.org/abs/2401.13192)

    本研究提出了一种基于点云和扩散模型的晶体结构生成设计框架，并通过重建输入结构和生成全新材料的实验证明了其有效性和潜力。

    

    在材料设计中，高效地生成能量稳定的晶体结构一直是个挑战，主要是因为晶格中原子的巨大排列。为了促进稳定材料的发现，我们提出了一个用于生成可合成材料的框架，利用点云表示来编码复杂的结构信息。在这个框架的核心是引入扩散模型作为基础支柱。为了评估我们方法的有效性，我们使用它来重建训练数据集中的输入结构，并严格验证其高重建性能。此外，我们通过生成全新的材料，重点强调了基于点云的晶体扩散(PCCD)的巨大潜力，并展示了其可合成性。我们的研究在材料设计和合成的推进中，通过先进的生成设计方法，做出了显著贡献。

    Efficiently generating energetically stable crystal structures has long been a challenge in material design, primarily due to the immense arrangement of atoms in a crystal lattice. To facilitate the discovery of stable material, we present a framework for the generation of synthesizable materials, leveraging a point cloud representation to encode intricate structural information. At the heart of this framework lies the introduction of a diffusion model as its foundational pillar. To gauge the efficacy of our approach, we employ it to reconstruct input structures from our training datasets, rigorously validating its high reconstruction performance. Furthermore, we demonstrate the profound potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely new materials, emphasizing their synthesizability. Our research stands as a noteworthy contribution to the advancement of materials design and synthesis through the cutting-edge avenue of generative design instead of the con
    
[^49]: 简化交叉验证：高效地计算不需要全量重新计算矩阵乘积或统计量的列向中心化和标准化训练集$\mathbf{X}^\mathbf{T}\mathbf{X}$和$\mathbf{X}^\mathbf{T}\mathbf{Y}$

    Shortcutting Cross-Validation: Efficiently Deriving Column-Wise Centered and Scaled Training Set $\mathbf{X}^\mathbf{T}\mathbf{X}$ and $\mathbf{X}^\mathbf{T}\mathbf{Y}$ Without Full Recomputation of Matrix Products or Statistical Moments. (arXiv:2401.13185v1 [cs.LG])

    [http://arxiv.org/abs/2401.13185](http://arxiv.org/abs/2401.13185)

    本文提出了三种高效计算训练集$\mathbf{X}^\mathbf{T}\mathbf{X}$和$\mathbf{X}^\mathbf{T}\mathbf{Y}$的算法，相比于以前的工作，这些算法能够显著加速交叉验证，而无需重新计算矩阵乘积或统计量。

    

    交叉验证是一种广泛使用的评估预测模型在未知数据上表现的技术。许多预测模型，如基于核的偏最小二乘（PLS）模型，需要仅使用输入矩阵$\mathbf{X}$和输出矩阵$\mathbf{Y}$中的训练集样本来计算$\mathbf{X}^{\mathbf{T}}\mathbf{X}$和$\mathbf{X}^{\mathbf{T}}\mathbf{Y}$。在这项工作中，我们提出了三种高效计算这些矩阵的算法。第一种算法不需要列向预处理。第二种算法允许以训练集均值为中心化点进行列向中心化。第三种算法允许以训练集均值和标准差为中心化点和标准化点进行列向中心化和标准化。通过证明正确性和优越的计算复杂度，它们相比于直接交叉验证和以前的快速交叉验证工作，提供了显著的交叉验证加速，而无需数据泄露。它们适合并行计算。

    Cross-validation is a widely used technique for assessing the performance of predictive models on unseen data. Many predictive models, such as Kernel-Based Partial Least-Squares (PLS) models, require the computation of $\mathbf{X}^{\mathbf{T}}\mathbf{X}$ and $\mathbf{X}^{\mathbf{T}}\mathbf{Y}$ using only training set samples from the input and output matrices, $\mathbf{X}$ and $\mathbf{Y}$, respectively. In this work, we present three algorithms that efficiently compute these matrices. The first one allows no column-wise preprocessing. The second one allows column-wise centering around the training set means. The third one allows column-wise centering and column-wise scaling around the training set means and standard deviations. Demonstrating correctness and superior computational complexity, they offer significant cross-validation speedup compared with straight-forward cross-validation and previous work on fast cross-validation - all without data leakage. Their suitability for paralle
    
[^50]: AgentBoard: 一种多轮LLM智能体的分析评估板

    AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])

    [http://arxiv.org/abs/2401.13178](http://arxiv.org/abs/2401.13178)

    AgentBoard是一个综合的基准测试和评估框架，专为分析评估LLM智能体而设计，解决了在多轮交互和部分可观察环境中对智能体性能进行基准测试的挑战，并提供了细粒度的进展率指标和评估工具包。

    

    评估大型语言模型（LLM）作为通用智能体对于理解其能力并促进其融入实际应用至关重要。然而，评估过程面临重大挑战。主要障碍之一是在统一框架内对智能体在不同场景下的性能进行基准测试，特别是在维护部分可观察环境和确保多轮交互方面。此外，当前的评估框架主要关注最终成功率，过程中提供的见解很少，无法深入理解模型的能力。为了解决这些挑战，我们引入了AgentBoard，这是一个创新的综合基准和伴随的开源评估框架，专为LLM智能体的分析评估而设计。AgentBoard提供了一种细粒度的进展率指标，捕捉逐步的进展，以及一个综合的评估工具包，具有易于评估和分析模型能力的功能。

    Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assess
    
[^51]: 在HuggingFace社区中的深度学习模型重用：挑战、益处和趋势

    Deep Learning Model Reuse in the HuggingFace Community: Challenges, Benefit and Trends. (arXiv:2401.13177v1 [cs.SE])

    [http://arxiv.org/abs/2401.13177](http://arxiv.org/abs/2401.13177)

    本研究通过对HuggingFace社区的讨论论坛和模型中心进行定性和定量分析，揭示了在社区中重用预训练模型的挑战和益处，并发现了一些有趣的模型趋势。

    

    大规模预训练模型（PTM）的普及日益增加，引发了对模型中心和专门用于托管PTM的平台的兴趣。尽管存在这一趋势，但关于用户遇到的挑战以及社区如何利用PTM的全面探索仍然缺乏。为了弥补这一空白，我们进行了一项广泛的混合方法实证研究，重点关注HuggingFace的讨论论坛和模型中心，这是最大的公共模型中心。根据我们的定性分析，我们提出了在该社区中重用PTM所涉及的挑战和益处的分类法。然后，我们进行了一项定量研究，跟踪模型类型的趋势和模型文档的演进。我们的研究结果突出了一些普遍存在的挑战，例如给初学者提供有限的指导，模型在训练或推理中的输出理解困难以及缺乏模型理解。我们还发现了一些有趣的模型趋势，其中一些模型保持着高上传率。

    The ubiquity of large-scale Pre-Trained Models (PTMs) is on the rise, sparking interest in model hubs, and dedicated platforms for hosting PTMs. Despite this trend, a comprehensive exploration of the challenges that users encounter and how the community leverages PTMs remains lacking. To address this gap, we conducted an extensive mixed-methods empirical study by focusing on discussion forums and the model hub of HuggingFace, the largest public model hub. Based on our qualitative analysis, we present a taxonomy of the challenges and benefits associated with PTM reuse within this community. We then conduct a quantitative study to track model-type trends and model documentation evolution over time. Our findings highlight prevalent challenges such as limited guidance for beginner users, struggles with model output comprehensibility in training or inference, and a lack of model understanding. We also identified interesting trends among models where some models maintain high upload rates de
    
[^52]: 组合式生成逆设计

    Compositional Generative Inverse Design. (arXiv:2401.13171v1 [cs.LG])

    [http://arxiv.org/abs/2401.13171](http://arxiv.org/abs/2401.13171)

    逆向设计起到优化底层目标函数的作用，最近的研究利用了学习的动力学模型进行优化。通过优化扩散模型捕获的学习能量函数，可以避免对抗示例，并显著提高设计性能。这一设计系统是组合性的，使得可以设计具有每个指定组件的系统。

    

    逆设计是一种寻求设计输入变量以优化底层目标函数的重要问题，在机械工程到航天工程等领域都有应用。逆设计通常被构建成一个优化问题，最近的研究利用了学习的动力学模型进行优化。然而，由于模型的优化往往会陷入对抗模式，阻碍有效的抽样。我们证明，通过优化扩散模型捕获的学习能量函数，我们可以避免这种对抗性示例，并显著提高设计性能。我们进一步展示了这样一个设计系统是组合性的，使我们能够结合多个不同的扩散模型来代表所需系统的子组件，从而设计具有每个指定组件的系统。在一个N体相互作用任务和一个具有挑战性的二维多翼型设计任务中，我们证明通过组合学习的能量函数，可以实现更好的设计性能。

    Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learn
    
[^53]: SpacTor-T5：使用跨度破坏和替换词汇检测进行T5模型的预训练

    SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection. (arXiv:2401.13160v1 [cs.LG])

    [http://arxiv.org/abs/2401.13160](http://arxiv.org/abs/2401.13160)

    本文提出了一种新的训练方法SpacTor-T5，结合了跨度破坏和替换词汇检测的混合目标函数，并采用两阶段课程表进行预训练。在实验中，SpacTor-T5在各种NLP任务中取得了与标准SC预训练相同的下游性能，同时大大减少了预训练迭代次数和总FLOP。

    

    预训练大型语言模型被认为是极其耗费资源且经常低效，未能充分利用训练文本序列中所蕴含的信息。本文提出了SpacTor，一种新的训练方法，包括(1)将跨度破坏(SC)和替换词汇检测(RTD)结合的混合目标函数，和(2)一个两阶段课程表，首先在初始的$\tau$迭代中优化混合目标函数，然后过渡到标准的SC损失。我们通过实验证明，混合目标函数的有效性与两阶段预训练进度表密切相关，并对此进行了详细分析。在我们对各种NLP任务进行的编码器-解码器架构(T5)的实验中，SpacTor-T5与标准的SC预训练具有相同的下游性能，同时使预训练迭代减少50%，总FLOP减少40%。另外，在给定相同的计算预算的情况下，我们发现SpacTor具有比标准SC预训练更好的性能。

    Pre-training large language models is known to be extremely resource intensive and often times inefficient, under-utilizing the information encapsulated in the training text sequences. In this paper, we present SpacTor, a new training procedure consisting of (1) a hybrid objective combining span corruption (SC) and token replacement detection (RTD), and (2) a two-stage curriculum that optimizes the hybrid objective over the initial $\tau$ iterations, then transitions to standard SC loss. We show empirically that the effectiveness of the hybrid objective is tied to the two-stage pre-training schedule, and provide extensive analysis on why this is the case. In our experiments with encoder-decoder architectures (T5) on a variety of NLP tasks, SpacTor-T5 yields the same downstream performance as standard SC pre-training, while enabling a 50% reduction in pre-training iterations and 40% reduction in total FLOPs. Alternatively, given the same amount of computing budget, we find that SpacTor 
    
[^54]: 具有多维持久性的动态对象的时间感知知识表示

    Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence. (arXiv:2401.13157v1 [cs.LG])

    [http://arxiv.org/abs/2401.13157](http://arxiv.org/abs/2401.13157)

    本论文提出了一种新的时间感知知识表示机制，聚焦于多维拓扑信息和隐含的时间相关信息。该方法通过使用单参数拓扑摘要生成数据的多维拓扑指纹。

    

    学习多变量时间序列和动态网络等时间变化的对象需要开发新的知识表示机制和神经网络架构，以捕捉数据中的隐含的时间相关信息。这些信息通常不直接观察到，但在学习任务性能中起着关键作用。然而，对于时间相关数据而言，知识编码机制中缺少时间维度会导致频繁的模型更新，学习性能差，从而影响决策的质量。在这里，我们提出了一种新的时间感知知识表示机制的方法，特别关注多个几何维度上的隐含时间相关拓扑信息。具体而言，我们提出了一种名为 \textit{Temporal MultiPersistence} (TMP) 的新方法，通过使用现有的单参数拓扑摘要，生成数据的多维拓扑指纹。

    Learning time-evolving objects such as multivariate time series and dynamic networks requires the development of novel knowledge representation mechanisms and neural network architectures, which allow for capturing implicit time-dependent information contained in the data. Such information is typically not directly observed but plays a key role in the learning task performance. In turn, lack of time dimension in knowledge encoding mechanisms for time-dependent data leads to frequent model updates, poor learning performance, and, as a result, subpar decision-making. Here we propose a new approach to a time-aware knowledge representation mechanism that notably focuses on implicit time-dependent topological information along multiple geometric dimensions. In particular, we propose a new approach, named \textit{Temporal MultiPersistence} (TMP), which produces multidimensional topological fingerprints of the data by using the existing single parameter topological summaries. The main idea be
    
[^55]: NLBAC: 基于神经常微分方程的稳定和安全强化学习框架

    NLBAC: A Neural Ordinary Differential Equations-based Framework for Stable and Safe Reinforcement Learning. (arXiv:2401.13148v1 [cs.LG])

    [http://arxiv.org/abs/2401.13148](http://arxiv.org/abs/2401.13148)

    本文介绍了一个基于神经常微分方程的NLBAC框架，用于稳定和安全的强化学习。该框架利用神经常微分方程来近似系统动力学，并将控制屏障函数（CBF）和控制Lyapunov函数（CLF）框架与演员-评论家方法集成，以维持系统的安全性和稳定性。

    

    强化学习在视频游戏和机器人等应用中表现出色，但在使用强化学习控制真实世界系统时，确保安全和稳定性仍然具有挑战性。本文首先给出了强化学习系统的安全和稳定性定义，然后引入了一个基于神经常微分方程的Lyapunov屏障演员-评论家（NLBAC）框架，利用神经常微分方程来近似系统动力学，并将控制屏障函数（CBF）和控制Lyapunov函数（CLF）框架与演员-评论家方法集成，以帮助维持系统的安全性和稳定性。在该框架中，我们采用增广Lagrangian方法来更新基于强化学习的控制器参数。此外，在CBF约束用于安全性和CLF约束用于稳定性的情况下，我们引入了一个额外的备份控制器。

    Reinforcement learning (RL) excels in applications such as video games and robotics, but ensuring safety and stability remains challenging when using RL to control real-world systems where using model-free algorithms suffering from low sample efficiency might be prohibitive. This paper first provides safety and stability definitions for the RL system, and then introduces a Neural ordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC) framework that leverages Neural Ordinary Differential Equations (NODEs) to approximate system dynamics and integrates the Control Barrier Function (CBF) and Control Lyapunov Function (CLF) frameworks with the actor-critic method to assist in maintaining the safety and stability for the system. Within this framework, we employ the augmented Lagrangian method to update the RL-based controller parameters. Additionally, we introduce an extra backup controller in situations where CBF constraints for safety and the CLF constraint for stabili
    
[^56]: 收缩扩散概率模型

    Contractive Diffusion Probabilistic Models. (arXiv:2401.13115v1 [cs.LG])

    [http://arxiv.org/abs/2401.13115](http://arxiv.org/abs/2401.13115)

    收缩扩散概率模型（CDPMs）是一种新颖的生成建模技术，通过收缩后向采样并克服分数匹配误差和离散化误差的问题，提高了模型的鲁棒性。实验证明收缩子方差保持（sub-VP）是表现最佳的一种CDPMs。

    

    收缩扩散概率模型（DPMs）已经成为生成建模中一种有前途的技术。DPMs的成功依赖于两个要素：马尔科夫扩散过程的时间反演和分数匹配。大多数现有的工作隐含地假设分数匹配是接近完美的，而这个假设是值得怀疑的。鉴于可能无法保证的分数匹配，我们在DPMs的设计中提出了一个新的准则——收缩后向采样。这导致了一种新的收缩DPMs（CDPMs）类，包括收缩奥恩斯坦-乌伦贝克（OU）过程和收缩子方差保持（sub-VP）随机微分方程（SDEs）。关键洞察力是后向过程的收缩能够缩小分数匹配误差和离散化误差。因此，所提出的CDPMs对于这两种误差都具有鲁棒性。我们的提议得到了理论结果的支持，并且通过实验进行了验证。值得注意的是，收缩子方差保持在表现上最佳。

    Diffusion probabilistic models (DPMs) have emerged as a promising technology in generative modeling. The success of DPMs relies on two ingredients: time reversal of Markov diffusion processes and score matching. Most existing work implicitly assumes that score matching is close to perfect, while this assumption is questionable. In view of possibly unguaranteed score matching, we propose a new criterion -- the contraction of backward sampling in the design of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance preserving (sub-VP) stochastic differential equations (SDEs). The key insight is that the contraction in the backward process narrows score matching errors, as well as discretization error. Thus, the proposed CDPMs are robust to both sources of error. Our proposal is supported by theoretical results, and is corroborated by experiments. Notably, contractive sub-VP shows the best performa
    
[^57]: 在库和系统不确定性存在的情况下，稀疏非线性动力学的识别

    Sparse identification of nonlinear dynamics in the presence of library and system uncertainty. (arXiv:2401.13099v1 [cs.LG])

    [http://arxiv.org/abs/2401.13099](http://arxiv.org/abs/2401.13099)

    针对系统变量和函数库不确定性，本文提出了增强的SINDy算法，可以更好地识别稀疏非线性动力学。

    

    SINDy算法已成功地用于从时间序列数据中识别动力系统的控制方程。然而，SINDy假设用户对系统中的变量和能够作为系统基础的函数库具有先验知识。在本文中，我们通过真实世界数据演示了增强SINDy算法在系统变量不确定性存在的情况下优于SINDy的性能。然后，我们展示了当两种不确定性同时存在时，SINDy可以进一步增强以实现稳健性能。

    The SINDy algorithm has been successfully used to identify the governing equations of dynamical systems from time series data. However, SINDy assumes the user has prior knowledge of the variables in the system and of a function library that can act as a basis for the system. In this paper, we demonstrate on real world data how the Augmented SINDy algorithm outperforms SINDy in the presence of system variable uncertainty. We then show SINDy can be further augmented to perform robustly when both kinds of uncertainty are present.
    
[^58]: 通过重力信息驱动的深度学习框架预测非本地物种船舶交通流量和入侵风险

    Gravity-Informed Deep Learning Framework for Predicting Ship Traffic Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge. (arXiv:2401.13098v1 [cs.LG])

    [http://arxiv.org/abs/2401.13098](http://arxiv.org/abs/2401.13098)

    通过考虑航运通量密度、港口距离、贸易流量和交通枢纽的中心性指标等因素，本研究开发了一个受物理启发的模型来预测海事航运流量，并用于指导全球交通网络中入侵物种的风险评估和管理。

    

    水体中的入侵物种对全球环境和生物多样性构成了重大威胁。由于交通和贸易增加，非本土物种已经引入了新的环境，导致生态系统破坏，并导致农业、林业和渔业方面的经济损失。因此，迫切需要风险评估和管理技术以减轻这些入侵的影响。本研究旨在开发一种新的受物理启发的模型，用于预测海事航运交通流量，并以此指导通过全球交通网络传播的入侵物种风险评估。受国际贸易重力模型的启发，我们的模型考虑了影响船舶活动可能性和影响的各种因素，如航运通量密度、港口之间的距离、贸易流量和交通枢纽的中心性指标。此外，通过分析入侵物种的风险网络，我们为评估和管理入侵提供了全面的框架。

    Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for as
    
[^59]: 使用图神经网络进行概率需求预测

    Probabilistic Demand Forecasting with Graph Neural Networks. (arXiv:2401.13096v1 [cs.LG])

    [http://arxiv.org/abs/2401.13096](http://arxiv.org/abs/2401.13096)

    本文提出了一种使用图神经网络进行概率需求预测的方法。该方法在现有的DeepAR模型中集成了GNN编码器，并采用基于文章属性相似性构建图的策略，实验结果表明该方法优于传统方法。

    

    需求预测是一种重要的商业应用案例，它可以帮助零售商优化库存规划、物流和核心业务决策。需求预测的一个关键挑战是考虑文章之间的关系和互动。大多数现代预测方法提供独立的文章级预测，不考虑相关文章的影响。最近的研究尝试使用图神经网络（GNNs）来解决这个挑战，并取得了有希望的结果。本文在之前的GNNs研究基础上做出了两个贡献。首先，我们将GNN编码器集成到最先进的DeepAR模型中。这个组合模型产生概率预测，这在不确定性下的决策制定中至关重要。其次，我们提出使用文章属性相似性构建图，避免依赖预定义的图结构。对三个实际数据集的实验表明，所提出的方法始终优于现有方法。

    Demand forecasting is a prominent business use case that allows retailers to optimize inventory planning, logistics, and core business decisions. One of the key challenges in demand forecasting is accounting for relationships and interactions between articles. Most modern forecasting approaches provide independent article-level predictions that do not consider the impact of related articles. Recent research has attempted addressing this challenge using Graph Neural Networks (GNNs) and showed promising results. This paper builds on previous research on GNNs and makes two contributions. First, we integrate a GNN encoder into a state-of-the-art DeepAR model. The combined model produces probabilistic forecasts, which are crucial for decision-making under uncertainty. Second, we propose to build graphs using article attribute similarity, which avoids reliance on a pre-defined graph structure. Experiments on three real-world datasets show that the proposed approach consistently outperforms n
    
[^60]: 向可信赖的语言模型迈进：探究大规模语言模型的信息质量

    Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])

    [http://arxiv.org/abs/2401.13086](http://arxiv.org/abs/2401.13086)

    这项研究探讨了大规模语言模型的信息质量问题，发现标记化不可靠、偏见以及信息质量下降可能导致幻觉、捏造信息，从而对企业决策产生错误影响。

    

    大规模语言模型（LLM）正在迅速生成大量信息，用户越来越依赖和信任这些数据。尽管LLM取得了显著进展，但由于信息质量的挑战，LLM生成的信息并不完全可信。具体而言，LLM在预训练过程中的标记化不可靠、存在偏见，导致信息质量的完整性下降。此外，由于信息质量下降的问题，LLM可能会产生幻觉、捏造信息。不可靠的信息可能导致企业做出错误决策，影响经济活动。在这项工作中，我们引入了LLM的新颖数学信息质量评估方法，进一步分析和突出了信息质量挑战，以系统地扩展语言模型。

    Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.
    
[^61]: IndiText Boost: 低资源条件下印度语言的文本增强

    IndiText Boost: Text Augmentation for Low Resource India Languages. (arXiv:2401.13085v1 [cs.CL])

    [http://arxiv.org/abs/2401.13085](http://arxiv.org/abs/2401.13085)

    本论文研究了针对低资源印度语言的文本增强方法，包括Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术。通过二元和多类文本分类实验，研究发现基本的数据增强技术可以显著提升性能。

    

    文本增强是低资源语言中重要的任务，它有助于解决数据稀缺问题。通过数据增强策略来应对数据稀缺问题。多年来，已经对英语进行了大量的数据增强工作，而在印度语言方面却做得很少。这与使用数据增强来处理数据稀缺的事实相反。在这项工作中，我们重点实施Easy Data Augmentation、Back Translation、Paraphrasing、使用LLMs进行文本生成以及使用LLMs进行文本扩展等技术，用于不同语言的文本分类。我们重点关注6种印度语言：信德语、马拉地语、印地语、古吉拉特语、泰卢固语和梵语。据我们所知，目前没有类似的工作用于印度语言的文本增强。我们进行了二元和多类文本分类，以使我们的结果更具可比性。我们得到了令人惊讶的结果，基本的数据增强技术可显著提升性能。

    Text Augmentation is an important task for low-resource languages. It helps deal with the problem of data scarcity. A data augmentation strategy is used to deal with the problem of data scarcity. Through the years, much work has been done on data augmentation for the English language. In contrast, very less work has been done on Indian languages. This is contrary to the fact that data augmentation is used to deal with data scarcity. In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages. We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to our knowledge, no such work exists for text augmentation on Indian languages. We carry out binary as well as multi-class text classification to make our results more comparable. We get surprising results as basic data augmentation techniq
    
[^62]: 无计算困难的快速计算超图节点距离的方法

    Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs. (arXiv:2401.13054v1 [cs.SI])

    [http://arxiv.org/abs/2401.13054](http://arxiv.org/abs/2401.13054)

    本文提出了一种基于随机游走的方法，用于快速计算超图节点之间的距离并进行标签传播。该方法解决了超图中节点距离计算的问题，进一步拓展了超图的应用领域。

    

    超图是图的推广，当考虑实体间的属性共享时会自然产生。尽管可以通过将超边扩展为完全连接的子图来将超图转换为图，但逆向操作在计算上非常复杂且属于NP-complete问题。因此，我们假设超图包含比图更多的信息。此外，直接操作超图比将其扩展为图更为方便。超图中的一个开放问题是如何精确高效地计算节点之间的距离。通过估计节点距离，我们能够找到节点的最近邻居，并使用K最近邻（KNN）方法在超图上执行标签传播。在本文中，我们提出了一种基于随机游走的新方法，实现了在超图上进行标签传播。我们将节点距离估计为随机游走的预期到达时间。我们注意到简单随机游走（SRW）无法准确描述节点之间的距离，因此我们引入了"frustrated"的概念。

    A hypergraph is a generalization of a graph that arises naturally when attribute-sharing among entities is considered. Although a hypergraph can be converted into a graph by expanding its hyperedges into fully connected subgraphs, going the reverse way is computationally complex and NP-complete. We therefore hypothesize that a hypergraph contains more information than a graph. In addition, it is more convenient to manipulate a hypergraph directly, rather than expand it into a graph. An open problem in hypergraphs is how to accurately and efficiently calculate their node distances. Estimating node distances enables us to find a node's nearest neighbors, and perform label propagation on hypergraphs using a K-nearest neighbors (KNN) approach. In this paper, we propose a novel approach based on random walks to achieve label propagation on hypergraphs. We estimate node distances as the expected hitting times of random walks. We note that simple random walks (SRW) cannot accurately describe 
    
[^63]: CIS-UNet: 基于上下文感知的平移窗口自注意力的CTA主动脉多类分割

    CIS-UNet: Multi-Class Segmentation of the Aorta in Computed Tomography Angiography via Context-Aware Shifted Window Self-Attention. (arXiv:2401.13049v1 [eess.IV])

    [http://arxiv.org/abs/2401.13049](http://arxiv.org/abs/2401.13049)

    本研究提出了一种称为CIS-UNet的深度学习模型，用于主动脉和主动脉分支的多类分割。该模型结合了CNN和Swin transformers的优势，采用了上下文感知的平移窗口自注意力，能够准确地识别主动脉的各个分支。

    

    医学成像和内衬血管膜技术的进步促进了主动脉疾病的微创治疗。准确地对主动脉及其分支进行3D分割对于干预至关重要，因为不准确的分割可能导致错误的手术规划和内部支架构造。之前的方法将主动脉分割简化为二值图像分割问题，忽视了区分各个主动脉分支的必要性。在本文中，我们介绍了一种称为Context Infused Swin-UNet（CIS-UNet）的深度学习模型，用于主动脉和十三个主动脉分支的多类分割。CIS-UNet结合了卷积神经网络（CNNs）和Swin transformers的优势，采用了层次化的编码器-解码器结构，包括CNN编码器、对称解码器、跳跃连接，以及一种新颖的基于上下文感知的平移窗口自注意力（CSW-SA）作为瓶颈模块。值得注意的是，CSW-SA引入了一种独特的方法来利用图像中的补丁信息。

    Advancements in medical imaging and endovascular grafting have facilitated minimally invasive treatments for aortic diseases. Accurate 3D segmentation of the aorta and its branches is crucial for interventions, as inaccurate segmentation can lead to erroneous surgical planning and endograft construction. Previous methods simplified aortic segmentation as a binary image segmentation problem, overlooking the necessity of distinguishing between individual aortic branches. In this paper, we introduce Context Infused Swin-UNet (CIS-UNet), a deep learning model designed for multi-class segmentation of the aorta and thirteen aortic branches. Combining the strengths of Convolutional Neural Networks (CNNs) and Swin transformers, CIS-UNet adopts a hierarchical encoder-decoder structure comprising a CNN encoder, symmetric decoder, skip connections, and a novel Context-aware Shifted Window Self-Attention (CSW-SA) as the bottleneck block. Notably, CSW-SA introduces a unique utilization of the patch
    
[^64]: 评估女性运动员脑震荡：神经信息学的作用？

    Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])

    [http://arxiv.org/abs/2401.13045](http://arxiv.org/abs/2401.13045)

    该论文提出了通过神经信息学和机器学习来评估女性运动员脑震荡的方法。相比传统的临床方法，在女性运动员中诊断脑震荡存在一些局限性，而这些新技术可以通过数据分析找出与性别相关的生物机制，从而填补这一差距。

    

    在过去的十年中，女性运动员脑震荡的复杂性变得明显。传统的临床诊断脑震荡的方法在应用于女性运动员时存在局限性，往往无法捕捉到脑结构和功能的细微变化。先进的神经信息学技术和机器学习模型在这方面已经成为宝贵的资产。虽然这些技术在理解男性运动员的脑震荡方面已经被广泛应用，但在我们对于它们对女性运动员的有效性的理解上仍存在显著差距。通过利用机器学习的强大数据分析能力，研究人员可以将观察到的表型神经影像数据联系到特定于性别的生物机制，揭示女性运动员脑震荡的奥秘。此外，嵌入机器学习的方法还可以在研究中进行交叉验证，进一步检验性别差异。

    Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining b
    
[^65]: 在线学习世界模型的局部敏感稀疏编码

    Locality Sensitive Sparse Encoding for Learning World Models Online. (arXiv:2401.13034v1 [cs.LG])

    [http://arxiv.org/abs/2401.13034](http://arxiv.org/abs/2401.13034)

    本文提出了一种基于局部敏感稀疏编码的线性回归模型，通过非线性随机特征实现对复杂环境的拟合。这种模型能够高效地进行稀疏更新，实现了优化拟合先前经验的Follow-The-Leader（FTL）世界模型。

    

    为了解决神经网络在在线学习中遇到的数据非平稳性问题，本文提出了一种基于局部敏感稀疏编码的线性回归模型，该模型通过非线性随机特征实现了对复杂环境的拟合。通过引入局部敏感稀疏编码，我们能够进行高效的稀疏更新，在平衡模型容量和计算效率的同时实现优化拟合所有先前经验的Follow-The-Leader（FTL）世界模型。

    Acquiring an accurate world model online for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even 
    
[^66]: 电厂监控的安全强化学习算法

    A Safe Reinforcement Learning Algorithm for Supervisory Control of Power Plants. (arXiv:2401.13020v1 [cs.SY])

    [http://arxiv.org/abs/2401.13020](http://arxiv.org/abs/2401.13020)

    这篇论文提出了一种基于Proximal Policy Optimization的机会约束强化学习算法，用于电厂监控的监督控制。通过使用Lagrangian relaxation，我们将约束优化问题转化为无约束的目标函数，并通过可训练的拉格朗日乘子实施状态约束。

    

    传统的控制理论方法需要为每个系统进行定制化工程和不断的微调。在电厂控制中，经常需要精确地获取系统动力学的表示并相应地设计控制方案。无模型强化学习（RL）由于其能够通过与环境的试错交互学习而成为控制任务的有希望解决方案。它消除了对明确建模环境动态的需求，这可能是不准确的。然而，在电厂控制中直接施加状态约束对标准RL方法提出了挑战。为了解决这个问题，我们提出了一种基于近端策略优化的机会约束RL算法，用于监控控制。我们的方法采用拉格朗日松弛，将约束优化问题转化为无约束的目标函数，其中可训练的拉格朗日乘子强制执行状态约束。

    Traditional control theory-based methods require tailored engineering for each system and constant fine-tuning. In power plant control, one often needs to obtain a precise representation of the system dynamics and carefully design the control scheme accordingly. Model-free Reinforcement learning (RL) has emerged as a promising solution for control tasks due to its ability to learn from trial-and-error interactions with the environment. It eliminates the need for explicitly modeling the environment's dynamics, which is potentially inaccurate. However, the direct imposition of state constraints in power plant control raises challenges for standard RL methods. To address this, we propose a chance-constrained RL algorithm based on Proximal Policy Optimization for supervisory control. Our method employs Lagrangian relaxation to convert the constrained optimization problem into an unconstrained objective, where trainable Lagrange multipliers enforce the state constraints. Our approach achiev
    
[^67]: 循环模型中含有隐藏因变量的因果发现方法的比较研究

    Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders. (arXiv:2401.13009v1 [cs.LG])

    [http://arxiv.org/abs/2401.13009](http://arxiv.org/abs/2401.13009)

    对于循环模型中含有隐藏因变量的因果发现，已经出现了能够处理这种情况的多种技术方法。

    

    如今，对因果发现的需求无处不在。理解系统中部分之间的随机依赖性以及实际的因果关系对科学的各个部分都至关重要。因此，寻找可靠的方法来检测因果方向的需求不断增长。在过去的50年里，出现了许多因果发现算法，但大多数仅适用于系统没有反馈环路并且具有因果充分性的假设，即没有未测量的子系统能够影响多个已测量变量。这是不幸的，因为这些限制在实践中往往不能假定。反馈是许多过程的一个重要特性，现实世界的系统很少是完全隔离和完全测量的。幸运的是，在最近几年中，已经发展了几种能够处理循环的、因果不充分的系统的技术。随着多种方法的出现，一种实际的应用方法开始变得可能。

    Nowadays, the need for causal discovery is ubiquitous. A better understanding of not just the stochastic dependencies between parts of a system, but also the actual cause-effect relations, is essential for all parts of science. Thus, the need for reliable methods to detect causal directions is growing constantly. In the last 50 years, many causal discovery algorithms have emerged, but most of them are applicable only under the assumption that the systems have no feedback loops and that they are causally sufficient, i.e. that there are no unmeasured subsystems that can affect multiple measured variables. This is unfortunate since those restrictions can often not be presumed in practice. Feedback is an integral feature of many processes, and real-world systems are rarely completely isolated and fully measured. Fortunately, in recent years, several techniques, that can cope with cyclic, causally insufficient systems, have been developed. And with multiple methods available, a practical ap
    
[^68]: CIMGEN: 受限数据上对预训练生成模型进行微调的可控图像操作

    CIMGEN: Controlled Image Manipulation by Finetuning Pretrained Generative Models on Limited Data. (arXiv:2401.13006v1 [cs.AI])

    [http://arxiv.org/abs/2401.13006](http://arxiv.org/abs/2401.13006)

    本文提出的方法利用预训练生成模型对受限数据进行微调，实现了可控的图像操作。通过修改语义地图，可以方便地插入、删除或替换图像中的对象。该方法在图像伪造和图像编辑领域具有潜在的应用价值和有效性。

    

    内容创作和图像编辑可以受益于用户的灵活控制。条件图像生成的常见中间表示是语义地图，其中包含图像中存在的对象的信息。与原始RGB像素相比，修改语义地图要容易得多。可以采用语义地图并轻松修改地图以选择性地插入、删除或替换地图中的对象。本文提出的方法接受修改后的语义地图，并根据修改后的地图调整原始图像。该方法利用传统的预训练图像到图像转换生成对抗网络（GAN），如CycleGAN或Pix2Pix GAN，在与语义地图相关的参考图像的有限数据集上进行微调。我们讨论了我们的技术的定性和定量性能，以说明它在图像伪造和图像编辑领域的能力和可能的应用。我们还展示了提议的图像伪造方法的有效性。

    Content creation and image editing can benefit from flexible user controls. A common intermediate representation for conditional image generation is a semantic map, that has information of objects present in the image. When compared to raw RGB pixels, the modification of semantic map is much easier. One can take a semantic map and easily modify the map to selectively insert, remove, or replace objects in the map. The method proposed in this paper takes in the modified semantic map and alter the original image in accordance to the modified map. The method leverages traditional pre-trained image-to-image translation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on a limited dataset of reference images associated with the semantic maps. We discuss the qualitative and quantitative performance of our technique to illustrate its capacity and possible applications in the fields of image forgery and image editing. We also demonstrate the effectiveness of the proposed image forgery
    
[^69]: PatternPortrait：用你的涂鸦画出我。 (arXiv:2401.13001v1 [cs.GR])

    PatternPortrait: Draw Me Like One of Your Scribbles. (arXiv:2401.13001v1 [cs.GR])

    [http://arxiv.org/abs/2401.13001](http://arxiv.org/abs/2401.13001)

    本论文介绍了一种从图片生成抽象肖像绘画的方法，通过利用单一的手绘图案素描和图形神经网络架构，实现了生成多样化的笔触变化，创造出风格独特的充满喜悦的抽象绘画。

    

    本论文介绍了一种从图片生成抽象肖像绘画的方法。其独特的风格是通过利用单一的手绘图案素描作为参考来生成用于阴影的独特图案。该方法涉及从图像中提取面部和身体特征，并将其转化为向量线条。研究的一个关键方面是开发一种图形神经网络架构，旨在学习向量形式的素描笔触表示，从而实现生成多样化的笔触变化。这两种方法的组合创造了充满喜悦的抽象绘画，通过钢笔绘图仪实现。所介绍的过程在大约280名参与者中获得了积极的反馈。

    This paper introduces a process for generating abstract portrait drawings from pictures. Their unique style is created by utilizing single freehand pattern sketches as references to generate unique patterns for shading. The method involves extracting facial and body features from images and transforming them into vector lines. A key aspect of the research is the development of a graph neural network architecture designed to learn sketch stroke representations in vector form, enabling the generation of diverse stroke variations. The combination of these two approaches creates joyful abstract drawings that are realized via a pen plotter. The presented process garnered positive feedback from an audience of approximately 280 participants.
    
[^70]: 量子启发的机器学习用于分子对接

    Quantum-Inspired Machine Learning for Molecular Docking. (arXiv:2401.12999v1 [physics.chem-ph])

    [http://arxiv.org/abs/2401.12999](http://arxiv.org/abs/2401.12999)

    量子启发的机器学习方法在分子对接中取得了显著的改进，通过结合量子特性和深度学习在编码的分子空间中学习的梯度，提高了盲目对接的成功率。

    

    分子对接是构建基于结构的药物设计的重要工具，可以加快药物开发的效率。蛋白质和小分子之间的复杂和动态结合过程需要在广泛的空间范围内进行搜索和采样。传统的对接方法通过搜索可能的结合位点和构象来实现，计算复杂度高，在盲目对接中效果不佳。受到这一点的启发，我们通过将量子启发算法与通过深度学习在编码的分子空间中学习的梯度相结合，实现了在盲目对接中的改进。数值仿真结果表明，我们的方法在传统的对接算法和基于深度学习的算法上表现出了超过10%的提升。与目前最先进的基于深度学习的对接算法DiffDock相比，Top-1（RMSD<2）的成功率从33%提高到35%。

    Molecular docking is an important tool for structure-based drug design, accelerating the efficiency of drug development. Complex and dynamic binding processes between proteins and small molecules require searching and sampling over a wide spatial range. Traditional docking by searching for possible binding sites and conformations is computationally complex and results poorly under blind docking. Quantum-inspired algorithms combining quantum properties and annealing show great advantages in solving combinatorial optimization problems. Inspired by this, we achieve an improved in blind docking by using quantum-inspired combined with gradients learned by deep learning in the encoded molecular space. Numerical simulation shows that our method outperforms traditional docking algorithms and deep learning-based algorithms over 10\%. Compared to the current state-of-the-art deep learning-based docking algorithm DiffDock, the success rate of Top-1 (RMSD<2) achieves an improvement from 33\% to 35
    
[^71]: 通过临床记录的自然语言处理与使用诊断代码对比发现存在问题的疗效性鸦片使用的退伍军人：一项比较研究

    A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes. (arXiv:2401.12996v1 [cs.CL])

    [http://arxiv.org/abs/2401.12996](http://arxiv.org/abs/2401.12996)

    通过翻译了的临床记录进行自然语言处理，发现了存在问题的鸦片使用的退伍军人。与仅通过诊断代码识别的鸦片使用障碍患者相比，这些患者具有不同的人口统计学和临床特征。

    

    背景：电子健康记录是鸦片类药物研究的数据来源。众所周知，鸦片类药物滥用难以通过诊断代码进行编码，但是存在问题的鸦片使用可以记录在临床记录中。目标：我们的目标是1）从各种临床记录中识别存在问题的鸦片使用；2）比较仅通过临床记录记录存在问题鸦片使用的患者与使用ICD鸦片使用障碍诊断代码的患者的特征。材料与方法：我们开发并使用自然语言处理（NLP）工具，对来自两个退伍军人事务所区域的患者队列（n=222,371）的临床记录进行分析以识别存在问题的鸦片使用的患者。我们还使用一组ICD诊断代码来识别来自相同队列的患有鸦片使用障碍的患者。我们比较了仅通过NLP识别出的患者与通过诊断代码识别出的患者的人口统计学和临床特征。

    Background: Electronic health records (EHRs) are a data source for opioid research. Opioid use disorder is known to be under-coded as a diagnosis, yet problematic opioid use can be documented in clinical notes.  Objectives: Our goals were 1) to identify problematic opioid use from a full range of clinical notes; and 2) to compare the characteristics of patients identified as having problematic opioid use, exclusively documented in clinical notes, to those having documented ICD opioid use disorder diagnostic codes.  Materials and Methods: We developed and applied a natural language processing (NLP) tool to the clinical notes of a patient cohort (n=222,371) from two Veteran Affairs service regions to identify patients with problematic opioid use. We also used a set of ICD diagnostic codes to identify patients with opioid use disorder from the same cohort. We compared the demographic and clinical characteristics of patients identified only through NLP, to those of patients identified thro
    
[^72]: 主题建模：超越令牌输出

    Topic Modelling: Going Beyond Token Outputs. (arXiv:2401.12990v1 [cs.CL])

    [http://arxiv.org/abs/2401.12990](http://arxiv.org/abs/2401.12990)

    这篇论文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。

    

    主题建模是一种文本挖掘技术，用于从多个文档中识别显著主题。通常输出是由常常共同出现在这些文档中的隔离令牌组成的主题集合。从人类的角度来看，这些输出可能不足以充分推断主题的含义；因此，它们的可解释性常常被错误地理解。尽管有几项研究试图自动扩展主题描述以增强主题模型的解释性，但它们依赖于可能不可用的外部语言资源，并需要保持最新以生成相关结果，并在训练或处理数据时存在隐私问题。本文提出了一种将传统主题建模方法的输出扩展到仅限于隔离令牌列表之外的新方法。

    Topic modelling is a text mining technique for identifying salient themes from a number of documents. The output is commonly a set of topics consisting of isolated tokens that often co-occur in such documents. Manual effort is often associated with interpreting a topic's description from such tokens. However, from a human's perspective, such outputs may not adequately provide enough information to infer the meaning of the topics; thus, their interpretability is often inaccurately understood. Although several studies have attempted to automatically extend topic descriptions as a means of enhancing the interpretation of topic models, they rely on external language sources that may become unavailable, must be kept up-to-date to generate relevant results, and present privacy issues when training on or processing data. This paper presents a novel approach towards extending the output of traditional topic modelling methods beyond a list of isolated tokens. This approach removes the dependenc
    
[^73]: TelME：教师导向的多模融合网络用于对话中的情绪识别

    TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])

    [http://arxiv.org/abs/2401.12987](http://arxiv.org/abs/2401.12987)

    TelME是一种教师导向的多模融合网络，通过跨模态知识蒸馏实现对话中情绪识别的优化，取得了在多说话人数据集MELD上的最先进性能。

    

    对话中的情绪识别在使对话系统能够有效回应用户请求方面起着至关重要的作用。对话中的情绪可以通过音频、视觉和文本等多种模态的表示进行识别。然而，由于非语言模态对识别情绪的贡献较弱，多模态情绪识别一直被认为是一项具有挑战性的任务。本文提出了一种用于对话中情绪识别的教师导向多模融合网络（TelME）。TelME通过跨模态知识蒸馏将信息从作为教师的语言模型传递给非语言的学生，从而优化了弱模态的效能。然后，我们采用一种移动融合方法将多模态特征组合起来，其中学生网络支持教师。TelME在MELD（一种用于对话情绪识别的多说话人数据集）上实现了最先进的性能。最后，我们通过额外的实验论证了我们组件的有效性。

    Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue systems to effectively respond to user requests. The emotions in a conversation can be identified by the representations from various modalities, such as audio, visual, and text. However, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a language model acting as the teacher to the non-verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multimodal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effectiveness of our components through additional expe
    
[^74]: 快速非线性的两时间尺度随机逼近：实现$\mathcal{O}(1/k)$有限样本复杂度

    Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\mathcal{O}(1/k)$ Finite-Sample Complexity. (arXiv:2401.12764v1 [math.OC])

    [http://arxiv.org/abs/2401.12764](http://arxiv.org/abs/2401.12764)

    本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，并且在强单调条件下证明了该方法的优化收敛速率为$\mathcal{O}(1/k)$。

    

    本文提出了一种新型的两时间尺度随机逼近方法，用于寻找耦合非线性算子的根，仅假设可以观测到这些算子的噪声样本。我们的关键思想是利用经典的Ruppert-Polyak平均技术通过样本动态估计算子的值。然后，这些平均步骤的估计值将用于两时间尺度随机逼近更新以找到所需的解。我们的主要理论结果是在底层非线性算子的强单调条件下，所提出方法产生的迭代的均方误差以优化的速率$\mathcal{O}(1/k)$收敛于零，其中$k$为迭代次数。我们的结果显著改进了现有的两时间尺度随机逼近结果，最佳已知有限时间收敛速率为$\mathcal{O}(1/k^{2/3})$。

    This paper proposes to develop a new variant of the two-time-scale stochastic approximation to find the roots of two coupled nonlinear operators, assuming only noisy samples of these operators can be observed. Our key idea is to leverage the classic Ruppert-Polyak averaging technique to dynamically estimate the operators through their samples. The estimated values of these averaging steps will then be used in the two-time-scale stochastic approximation updates to find the desired solution. Our main theoretical result is to show that under the strongly monotone condition of the underlying nonlinear operators the mean-squared errors of the iterates generated by the proposed method converge to zero at an optimal rate $\mathcal{O}(1/k)$, where $k$ is the number of iterations. Our result significantly improves the existing result of two-time-scale stochastic approximation, where the best known finite-time convergence rate is $\mathcal{O}(1/k^{2/3})$.
    
[^75]: Falcon: 使用多臂赌博机进行公平主动学习

    Falcon: Fair Active Learning using Multi-armed Bandits. (arXiv:2401.12722v1 [cs.LG])

    [http://arxiv.org/abs/2401.12722](http://arxiv.org/abs/2401.12722)

    Falcon是一个使用多臂赌博机的公平主动学习框架，通过策略性样本选择来改善机器学习模型的公平性。它通过识别对于提高公平性最具信息量的“目标群体”样本，并采用一种试错方法来解决样本选择中没有ground truth标签的挑战。

    

    偏倚数据可能导致不公平的机器学习模型，强调在数据分析的开始阶段嵌入公平性的重要性，特别是在数据集的筛选和标定过程中。为此，我们提出了一种可扩展的公平主动学习框架Falcon。Falcon采用了一种以数据为中心的方法，通过策略性样本选择来改善机器学习模型的公平性。给定用户指定的群体公平度量，Falcon确定了对提高公平性最有信息量的“目标群体”样本（例如（属性=女性，标签=正面））。然而，由于在样本选择过程中不可用ground truth标签来定义这些目标群体，出现了挑战。为了解决这个问题，我们提出了一种新颖的试错方法，在预测标签与期望标签不同时并落在目标群体之外时，我们推迟使用该样本。我们还观察到这样做会产生权衡，选择更有信息量的样本会增加样本进入目标群体之外的可能性。

    Biased data can lead to unfair machine learning models, highlighting the importance of embedding fairness at the beginning of data analysis, particularly during dataset curation and labeling. In response, we propose Falcon, a scalable fair active learning framework. Falcon adopts a data-centric approach that improves machine learning model fairness via strategic sample selection. Given a user-specified group fairness measure, Falcon identifies samples from "target groups" (e.g., (attribute=female, label=positive)) that are the most informative for improving fairness. However, a challenge arises since these target groups are defined using ground truth labels that are not available during sample selection. To handle this, we propose a novel trial-and-error method, where we postpone using a sample if the predicted label is different from the expected one and falls outside the target group. We also observe the trade-off that selecting more informative samples results in higher likelihood o
    
[^76]: 任务相似性和过参数化对灾难性遗忘的联合影响 - 一种分析模型

    The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting -- An Analytical Model. (arXiv:2401.12617v1 [cs.LG])

    [http://arxiv.org/abs/2401.12617](http://arxiv.org/abs/2401.12617)

    本文研究了任务相似性和过参数化如何联合影响连续学习中的灾难性遗忘，并发现在过参数化模型中，中等任务相似性导致最多的遗忘，而在插值阈值附近，遗忘随期望任务相似性单调减少。

    

    在连续学习中，灾难性遗忘受到多个任务方面的影响。以往的研究分别分析了遗忘受任务相似性或过参数化的影响。相反，我们的论文在可分析的模型中研究了任务相似性和过参数化如何共同影响遗忘。具体而言，我们关注双任务连续线性回归，其中第二个任务是任意第一个任务的随机正交变换（随机排列任务的抽象）。我们推导了期望遗忘的精确解析表达式，并揭示了一个微妙的模式。在过参数化模型中，中等任务相似性导致最多的遗忘。然而，在插值阈值附近，遗忘随期望任务相似性单调减少。我们用合成数据上的线性回归和已建立的排列任务基准上的神经网络验证了我们的发现。

    In continual learning, catastrophic forgetting is affected by multiple aspects of the tasks. Previous works have analyzed separately how forgetting is affected by either task similarity or overparameterization. In contrast, our paper examines how task similarity and overparameterization jointly affect forgetting in an analyzable model. Specifically, we focus on two-task continual linear regression, where the second task is a random orthogonal transformation of an arbitrary first task (an abstraction of random permutation tasks). We derive an exact analytical expression for the expected forgetting - and uncover a nuanced pattern. In highly overparameterized models, intermediate task similarity causes the most forgetting. However, near the interpolation threshold, forgetting decreases monotonically with the expected task similarity. We validate our findings with linear regression on synthetic data, and with neural networks on established permutation task benchmarks.
    
[^77]: 在线社交网络数字克隆的语言敏感代理建模研究误信息传播

    Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread. (arXiv:2401.12509v1 [cs.SI])

    [http://arxiv.org/abs/2401.12509](http://arxiv.org/abs/2401.12509)

    本研究开发了一个基于代理建模和自然语言处理技术的仿真框架，用于研究在线社交网络中的误信息传播。通过数字克隆已知的误信息共享网络，我们提高了模拟的真实性和普适性，并且考虑到了讨论主题、用户偏好和在线社区动态等因素。

    

    我们开发了一个仿真框架，将代理建模和自然语言处理技术相结合，研究在线社交网络中的误信息传播。虽然在这个领域中存在许多其他的代理建模仿真，但它们在提供可操作的见解方面受限于其对现有网络的真实性和普适性的不足。为了部分解决这些问题，我们通过下载超过一万名用户的社交媒体历史记录，创建了一个已知误信息共享网络的“数字克隆”。我们解析这些历史记录，提取出网络的结构，并对成员之间信息分享和传播的微妙方式进行建模。与这个领域中许多其他的代理建模方法不同，我们框架中用户之间的信息分享对讨论主题、用户偏好和在线社区动态都非常敏感。为了评估我们方法的真实性，我们用一组记录在 t 中的帖子对克隆网络进行了种子设置。

    We develop a simulation framework for studying misinformation spread within online social networks that blends agent-based modeling and natural language processing techniques. While many other agent-based simulations exist in this space, their ability to provide actionable insights in in part limited by their lack of fidelity and generalizability to existing networks. To partially address these concerns, we create a 'digital clone' of a known misinformation sharing network by downloading social media histories for over ten thousand of its users. We parse these histories to both extract the structure of the network and model the nuanced ways in which information is shared and spread among its members. Unlike many other agent-based methods in this space, information sharing between users in our framework is sensitive to topic of discussion, user preferences, and online community dynamics. To evaluate the fidelity of our method, we seed our cloned network with a set of posts recorded in t
    
[^78]: 使用物理信息神经网络对细胞外间隙中的分子传输进行定量分析

    Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network. (arXiv:2401.12435v1 [cs.AI])

    [http://arxiv.org/abs/2401.12435](http://arxiv.org/abs/2401.12435)

    本文提出了一种使用物理信息神经网络对细胞外间隙中分子传输进行定量分析的新方法，解决了对分子传输形式不清楚的挑战，并实现了自动计算扩散系数和分子速度的优化功能。

    

    大脑的细胞外间隙 (ECS)是位于细胞之间或细胞与血管之间的不规则、极其迂回的纳米级空间，对神经细胞的生存至关重要。它在记忆、情绪和感觉等高级脑功能中起着关键作用。然而，ECS内分子传输的具体形式仍然不清楚。为了解决这个问题，本文提出了一种新的方法，通过使用物理信息神经网络 (PINN) 解决从对流-扩散方程 (ADE) 导出的一个逆问题，定量分析ECS内的分子传输。PINN为ADE提供了一个简化的解决方案，而无需复杂的数学公式或网格设置。此外，PINN的优化功能可自动计算决定长期分子传输的扩散系数和由对流驱动的分子速度。因此，所提出的方法允许进行定量分析。

    The brain extracellular space (ECS), an irregular, extremely tortuous nanoscale space located between cells or between cells and blood vessels, is crucial for nerve cell survival. It plays a pivotal role in high-level brain functions such as memory, emotion, and sensation. However, the specific form of molecular transport within the ECS remain elusive. To address this challenge, this paper proposes a novel approach to quantitatively analyze the molecular transport within the ECS by solving an inverse problem derived from the advection-diffusion equation (ADE) using a physics-informed neural network (PINN). PINN provides a streamlined solution to the ADE without the need for intricate mathematical formulations or grid settings. Additionally, the optimization of PINN facilitates the automatic computation of the diffusion coefficient governing long-term molecule transport and the velocity of molecules driven by advection. Consequently, the proposed method allows for the quantitative analy
    
[^79]: 自监督学习中的记忆化提高了下游概括能力

    Memorization in Self-Supervised Learning Improves Downstream Generalization. (arXiv:2401.12233v1 [cs.LG])

    [http://arxiv.org/abs/2401.12233](http://arxiv.org/abs/2401.12233)

    自监督学习中的记忆化问题一直是一个挑战，本文提出了SSLMem框架，用于定义自监督学习中的记忆化，并通过实证分析证明了在大规模数据集和强数据增强的情况下，记忆化仍然存在。

    

    自监督学习（SSL）最近因其在无标签数据上训练高性能编码器的能力而受到重视，这些数据通常来源于互联网的抓取。然而，经验证据表明，SSL编码器会记忆其训练数据的私人信息，并在推理时泄露这些信息。现有的监督学习记忆化的理论定义依赖于标签，因此无法适用于SSL。为了填补这一空白，我们提出了SSLMem，一个在SSL内定义记忆化的框架。我们的定义通过比较训练在这些数据点上的编码器和未被训练在这些数据点上的编码器返回的数据点和他们的增强视图的表示的对齐差异。通过对不同编码器架构和数据集的综合实证分析，我们强调了即使SSL依赖于大型数据集和强大的数据增强，这都是监督学习中作为正则化手段的已知技术，记忆化仍然存在。

    Self-supervised learning (SSL) has recently received significant attention due to its ability to train high-performance encoders purely on unlabeled data-often scraped from the internet. This data can still be sensitive and empirical evidence suggests that SSL encoders memorize private information of their training data and can disclose them at inference time. Since existing theoretical definitions of memorization from supervised learning rely on labels, they do not transfer to SSL. To address this gap, we propose SSLMem, a framework for defining memorization within SSL. Our definition compares the difference in alignment of representations for data points and their augmented views returned by both encoders that were trained on these data points and encoders that were not. Through comprehensive empirical analysis on diverse encoder architectures and datasets we highlight that even though SSL relies on large datasets and strong augmentations-both known in supervised learning as regulari
    
[^80]: 空间-时间图卷积网络在交通预测上的知识蒸馏

    Knowledge Distillation on Spatial-Temporal Graph Convolutional Network for Traffic Prediction. (arXiv:2401.11798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11798](http://arxiv.org/abs/2401.11798)

    本论文研究了在交通预测中应用空间-时间图卷积网络和知识蒸馏的方法。知识蒸馏的思想能够实现在减少参数和保持准确性的同时提高执行效率。通过引入教师网络的空间-时间相关性，我们的方法能够使学生网络学习到复杂的交通模式。

    

    高效实时交通预测对减少交通时间至关重要。为了预测交通状况，我们采用了空间-时间图神经网络（ST-GNN）将实时交通数据建模为时间图。尽管ST-GNN具有强大的能力，但在为实际交通数据进行高效实时预测时经常面临挑战。鉴于实时数据动态性的重要性，我们采用知识蒸馏（KD）作为解决方案，以提高ST-GNN在交通预测中的执行时间。本文介绍了一个成本函数，旨在使用复杂网络（教师）的蒸馏数据来训练具有较少参数的网络（学生），同时保持其准确性接近教师的准确性。我们使用知识蒸馏，将教师网络的空间-时间相关性融入学生网络，使学生能够学习到教师感知的复杂模式。然而，面临一个挑战。

    Efficient real-time traffic prediction is crucial for reducing transportation time. To predict traffic conditions, we employ a spatio-temporal graph neural network (ST-GNN) to model our real-time traffic data as temporal graphs. Despite its capabilities, it often encounters challenges in delivering efficient real-time predictions for real-world traffic data. Recognizing the significance of timely prediction due to the dynamic nature of real-time data, we employ knowledge distillation (KD) as a solution to enhance the execution time of ST-GNNs for traffic prediction. In this paper, We introduce a cost function designed to train a network with fewer parameters (the student) using distilled data from a complex network (the teacher) while maintaining its accuracy close to that of the teacher. We use knowledge distillation, incorporating spatial-temporal correlations from the teacher network to enable the student to learn the complex patterns perceived by the teacher. However, a challenge a
    
[^81]: 安全且广义的端到端自主驾驶系统：基于强化学习和示范的研究

    Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations. (arXiv:2401.11792v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.11792](http://arxiv.org/abs/2401.11792)

    本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。

    

    一个智能驾驶系统应该能够根据当前环境和车辆状态动态制定适当的驾驶策略，同时确保系统的安全性和可靠性。然而，基于强化学习和模仿学习的现有方法存在安全性低、泛化能力差和采样效率低的问题。此外，它们无法准确预测未来的驾驶轨迹，而准确预测未来的驾驶轨迹是做出最优决策的前提。为了解决这些问题，本文引入了一种复杂而多样场景下的安全且广义的端到端自主驾驶系统 (SGADS)。我们的SGADS与变分推理和归一化流结合，使智能车辆能够准确预测未来的驾驶轨迹。此外，我们提出了鲁棒性安全约束的制定。此外，我们将强化学习与示范相结合进行增强学习。

    An intelligent driving system should be capable of dynamically formulating appropriate driving strategies based on the current environment and vehicle status, while ensuring the security and reliability of the system. However, existing methods based on reinforcement learning and imitation learning suffer from low safety, poor generalization, and inefficient sampling. Additionally, they cannot accurately predict future driving trajectories, and the accurate prediction of future driving trajectories is a precondition for making optimal decisions. To solve these problems, in this paper, we introduce a Safe and Generalized end-to-end Autonomous Driving System (SGADS) for complex and various scenarios. Our SGADS incorporates variational inference with normalizing flows, enabling the intelligent vehicle to accurately predict future driving trajectories. Moreover, we propose the formulation of robust safety constraints. Furthermore, we combine reinforcement learning with demonstrations to aug
    
[^82]: 参数矩阵模型

    Parametric Matrix Models. (arXiv:2401.11694v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11694](http://arxiv.org/abs/2401.11694)

    参数矩阵模型是一种通用机器学习算法，基于矩阵方程设计，通过简化基础方法进行近似解参数方程。它可以仅使用经验数据进行训练，适用于各种机器学习问题，并在计算框架内产生准确的结果。

    

    我们提出了一种称为参数矩阵模型的通用机器学习算法。参数矩阵模型基于矩阵方程，并且其设计受到了用于近似解参数方程的简化基础方法的效率启发。依赖变量可以隐式或显式定义，并且方程可以使用代数、微分或积分关系。参数矩阵模型可以仅使用经验数据进行训练，不需要高保真度模型计算。虽然最初设计用于科学计算，但参数矩阵模型是一种可以应用于通用机器学习问题的通用函数逼近器。在介绍基础理论之后，我们将参数矩阵模型应用于一系列不同的挑战，展示了它们在各种问题上的性能。对于所有在这里测试的挑战，参数矩阵模型在允许计算的框架内产生准确的结果。

    We present a general class of machine learning algorithms called parametric matrix models. Parametric matrix models are based on matrix equations, and the design is motivated by the efficiency of reduced basis methods for approximating solutions of parametric equations. The dependent variables can be defined implicitly or explicitly, and the equations may use algebraic, differential, or integral relations. Parametric matrix models can be trained with empirical data only, and no high-fidelity model calculations are needed. While originally designed for scientific computing, parametric matrix models are universal function approximators that can be applied to general machine learning problems. After introducing the underlying theory, we apply parametric matrix models to a series of different challenges that show their performance for a wide range of problems. For all the challenges tested here, parametric matrix models produce accurate results within a computational framework that allows 
    
[^83]: 通过具有分层正则化的医学代码中心的多模态对比EHR建模预测下次就诊诊断

    Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation. (arXiv:2401.11648v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11648](http://arxiv.org/abs/2401.11648)

    通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。

    

    在医疗保健中，利用电子健康记录（EHR）预测下次就诊的诊断是一项必要的任务，对于制定医疗保健提供者和患者的主动未来计划至关重要。然而，之前的许多研究并没有充分解决EHR数据固有的异构和分层特征，必然导致次优的性能。为此，我们提出了NECHO，一种新颖的医学代码中心的多模态对比EHR学习框架，其中包括分层正则化。首先，我们使用定制的网络设计和一对双模态对比损失融合涵盖医学代码、人口统计数据和临床笔记的多方面信息，所有这些都围绕着医学代码表现。我们还使用医学本体中的父级信息来规范特定模态的编码器，以学习EHR数据的层次结构。对MIMIC-III数据进行的一系列实验证明了我们方法的有效性。

    Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical code representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.
    
[^84]: 使用LLMs发现极端社交媒体中的编码反犹太恶意言论的出现

    Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media. (arXiv:2401.10841v1 [cs.CL])

    [http://arxiv.org/abs/2401.10841](http://arxiv.org/abs/2401.10841)

    这项研究提出了一种方法，可以检测新出现的编码恶意术语，为极端社交媒体中的反犹太恶意言论提供了解决方案。

    

    网络仇恨言论的蔓延给社交媒体平台带来了一个难题。一个特殊的挑战与使用编码语言的群体有关，这些群体既想为其用户创造归属感，又想回避检测。编码语言发展迅速，并且随着时间的推移使用方式不同。本文提出了一种检测新出现的编码恶意术语的方法论。该方法在在线反犹太言论的环境中进行了测试。该方法考虑了从社交媒体平台上抓取的帖子，通常是极端主义用户使用的。帖子是使用与以前已知的针对犹太人的仇恨言论相关的种子表达式进行抓取的。该方法首先通过识别每个帖子最具代表性的表达式，并计算它们在整个语料库中的频率。过滤掉语法不一致的表达式和之前遇到过的表达式，以便关注新出现的良好形式的术语。然后进行了语义评估。

    Online hate speech proliferation has created a difficult problem for social media platforms. A particular challenge relates to the use of coded language by groups interested in both creating a sense of belonging for its users and evading detection. Coded language evolves quickly and its use varies over time. This paper proposes a methodology for detecting emerging coded hate-laden terminology. The methodology is tested in the context of online antisemitic discourse. The approach considers posts scraped from social media platforms, often used by extremist users. The posts are scraped using seed expressions related to previously known discourse of hatred towards Jews. The method begins by identifying the expressions most representative of each post and calculating their frequency in the whole corpus. It filters out grammatically incoherent expressions as well as previously encountered ones so as to focus on emergent well-formed terminology. This is followed by an assessment of semantic s
    
[^85]: 学习辅助的随机容量扩展规划：一种贝叶斯优化方法

    Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach. (arXiv:2401.10451v1 [eess.SY])

    [http://arxiv.org/abs/2401.10451](http://arxiv.org/abs/2401.10451)

    本研究提出了一种学习辅助的贝叶斯优化方法，用于解决大规模容量扩展问题。通过构建和求解可行的时间聚合代理问题，识别出低成本的规划决策。通过在验证集和测试预测上评估解决的规划结果，实现了随机容量扩展问题的可行解决。

    

    解决大规模的容量扩展问题对于区域能源系统的成本效益低碳化至关重要。为了确保容量扩展问题的预期结果，建模考虑到天气相关的可再生能源供应和能源需求的不确定性变得至关重要。然而，由此产生的随机优化模型通常比确定性模型难以计算。在这里，我们提出了一种学习辅助的近似解法来可行地解决两阶段随机容量扩展问题。我们的方法通过构建和求解一系列可行的时间聚合代理问题，识别出低成本的规划决策。我们采用贝叶斯优化方法搜索时间序列聚合超参数的空间，并计算在供需预测的验证集上最小化成本的近似解。重要的是，我们在一组保留的测试预测上评估解决的规划结果。

    Solving large-scale capacity expansion problems (CEPs) is central to cost-effective decarbonization of regional-scale energy systems. To ensure the intended outcomes of CEPs, modeling uncertainty due to weather-dependent variable renewable energy (VRE) supply and energy demand becomes crucially important. However, the resulting stochastic optimization models are often less computationally tractable than their deterministic counterparts. Here, we propose a learning-assisted approximate solution method to tractably solve two-stage stochastic CEPs. Our method identifies low-cost planning decisions by constructing and solving a sequence of tractable temporally aggregated surrogate problems. We adopt a Bayesian optimization approach to searching the space of time series aggregation hyperparameters and compute approximate solutions that minimize costs on a validation set of supply-demand projections. Importantly, we evaluate solved planning outcomes on a held-out set of test projections. We 
    
[^86]: PatchAD: 基于块的MLP-Mixer的时间序列异常检测

    PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection. (arXiv:2401.09793v1 [cs.LG])

    [http://arxiv.org/abs/2401.09793](http://arxiv.org/abs/2401.09793)

    PatchAD是一种新颖的基于块的MLP-Mixer体系结构，利用对比学习进行时间序列异常检测。它具有高效和轻量级的架构，并采用创新的双项目约束模块来提高表示能力。

    

    异常检测是时间序列分析的关键方面，旨在识别时间序列样本中的异常事件。这一任务的核心挑战在于在缺乏标签的情况下有效地学习正常和异常模式的表示。先前的研究大多依赖于基于重构的方法，限制了模型的表征能力。此外，大多数当前的深度学习方法不够轻量级，这促使我们设计一个更高效的异常检测框架。本研究中，我们介绍了PatchAD，一种新颖的多尺度基于块的MLP-Mixer体系结构，利用对比学习进行表征提取和异常检测。具体而言，PatchAD由四个独特的MLP Mixer组成，专门利用MLP架构实现高效和轻量级的架构。此外，我们还创新地设计了一个双项目约束模块来缓解潜在的问题。

    Anomaly detection stands as a crucial aspect of time series analysis, aiming to identify abnormal events in time series samples. The central challenge of this task lies in effectively learning the representations of normal and abnormal patterns in a label-lacking scenario. Previous research mostly relied on reconstruction-based approaches, restricting the representational abilities of the models. In addition, most of the current deep learning-based methods are not lightweight enough, which prompts us to design a more efficient framework for anomaly detection. In this study, we introduce PatchAD, a novel multi-scale patch-based MLP-Mixer architecture that leverages contrastive learning for representational extraction and anomaly detection. Specifically, PatchAD is composed of four distinct MLP Mixers, exclusively utilizing the MLP architecture for high efficiency and lightweight architecture. Additionally, we also innovatively crafted a dual project constraint module to mitigate potenti
    
[^87]: 识别与早期热带气旋强化有关的三维辐射模式

    Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification. (arXiv:2401.09493v1 [physics.ao-ph])

    [http://arxiv.org/abs/2401.09493](http://arxiv.org/abs/2401.09493)

    本研究利用线性变分编码器-解码器来学习云辐射反馈对早期热带气旋强化的影响，发现内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流的影响最大。

    

    云辐射反馈影响了早期热带气旋的强化，但现有诊断框架的局限性使其无法用来研究不对称或瞬态的辐射加热。我们提出了一种线性变分编码器-解码器（VED）来学习辐射与实际模拟的气旋表面强化之间的隐藏关系。限制VED模型的输入可以利用其不确定性来识别辐射对强化更重要的时期。对提取的三维辐射结构的细致检查表明，内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流在整体上具有最大的影响。我们发现，在浅云的下风处的深对流对海燕的强化至关重要。我们的工作表明，机器学习可以发现热力-动力学关系，而不依赖于轴对称或确定性的方案。

    Cloud radiative feedback impacts early tropical cyclone (TC) intensification, but limitations in existing diagnostic frameworks make them unsuitable for studying asymmetric or transient radiative heating. We propose a linear Variational Encoder-Decoder (VED) to learn the hidden relationship between radiation and the surface intensification of realistic simulated TCs. Limiting VED model inputs enables using its uncertainty to identify periods when radiation has more importance for intensification. A close examination of the extracted 3D radiative structures suggests that longwave radiative forcing from inner core deep convection and shallow clouds both contribute to intensification, with the deep convection having the most impact overall. We find that deep convection downwind of the shallow clouds is critical to the intensification of Haiyan. Our work demonstrates that machine learning can discover thermodynamic-kinematic relationships without relying on axisymmetric or deterministic as
    
[^88]: DiConStruct: 基于黑盒精华的因果概念解释

    DiConStruct: Causal Concept-based Explanations through Black-Box Distillation. (arXiv:2401.08534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.08534](http://arxiv.org/abs/2401.08534)

    DiConStruct是一种基于黑盒模型的因果概念解释方法，通过创建结构性因果模型和概念归因方式提供更具可解释性的局部解释。

    

    模型可解释性在人工智能决策系统中起着核心作用。理想情况下，解释应该使用人可解释的语义概念来表达。此外，解释器应该捕捉这些概念之间的因果关系，以便对解释进行推理。最后，解释方法应该高效，并不损害预测任务的性能。尽管近年来AI解释性取得了快速进展，但据我们所知，至今没有一种方法满足这三个条件。事实上，主流的局部概念可解释性方法不产生因果解释，并在解释性和预测性能之间存在权衡。我们提出了DiConStruct，一种既基于概念又具有因果性的解释方法，旨在通过结构性因果模型和概念归因方式创建更具可解释性的局部解释。我们的解释器作为一个精华模型适用于任何黑盒机器学习模型。

    Model interpretability plays a central role in human-AI decision-making systems. Ideally, explanations should be expressed using human-interpretable semantic concepts. Moreover, the causal relations between these concepts should be captured by the explainer to allow for reasoning about the explanations. Lastly, explanation methods should be efficient and not compromise the performance of the predictive task. Despite the rapid advances in AI explainability in recent years, as far as we know to date, no method fulfills these three properties. Indeed, mainstream methods for local concept explainability do not produce causal explanations and incur a trade-off between explainability and prediction performance. We present DiConStruct, an explanation method that is both concept-based and causal, with the goal of creating more interpretable local explanations in the form of structural causal models and concept attributions. Our explainer works as a distillation model to any black-box machine l
    
[^89]: OpenDPD: 用于宽带功放建模和数字预失真的开源端到端学习和基准框架

    OpenDPD: An Open-Source End-to-End Learning & Benchmarking Framework for Wideband Power Amplifier Modeling and Digital Pre-Distortion. (arXiv:2401.08318v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.08318](http://arxiv.org/abs/2401.08318)

    OpenDPD 是一个用于宽带功放建模和数字预失真的开源端到端学习和基准框架，通过引入DGRU-DPD模型和新型学习架构，实现了在新的数字发射器架构下的优于以前模型的结果。

    

    随着通信能力的提升，用于纠正宽带功放器中的非线性的数字预失真（DPD）的深度神经网络（DNN）变得突出。然而，当前缺乏一个独立于测量设置、用于快速DPD探索和客观DPD模型比较的开源平台。本文提出了一个基于PyTorch的开源框架OpenDPD，并附带一个用于功放建模和DPD学习的数据集。我们引入了一种名为Dense Gated Recurrent Unit (DGRU)-DPD的新型端到端学习架构，相较于模拟功放器，在新的数字发射器（DTX）架构下，具有非常规传输特性，表现优于以前的DPD模型。实验结果显示，我们的DGRU-DPD对于200 MHz OFDM信号，实现了-44.69/-44.47 dBc的ACPR和-35.22 dB的EVM。OpenDPD的代码、数据集和文档可在https://github.com/lab-emi/OpenDPD上公开获取。

    With the rise in communication capacity, deep neural networks (DNN) for digital pre-distortion (DPD) to correct non-linearity in wideband power amplifiers (PAs) have become prominent. Yet, there is a void in open-source and measurement-setup-independent platforms for fast DPD exploration and objective DPD model comparison. This paper presents an open-source framework, OpenDPD, crafted in PyTorch, with an associated dataset for PA modeling and DPD learning. We introduce a Dense Gated Recurrent Unit (DGRU)-DPD, trained via a novel end-to-end learning architecture, outperforming previous DPD models on a digital PA (DPA) in the new digital transmitter (DTX) architecture with unconventional transfer characteristics compared to analog PAs. Measurements show our DGRU-DPD achieves an ACPR of -44.69/-44.47 dBc and an EVM of -35.22 dB for 200 MHz OFDM signals. OpenDPD code, datasets, and documentation are publicly available at https://github.com/lab-emi/OpenDPD.
    
[^90]: 借助属性推理实现个性化的形式逻辑启用的联邦学习

    Formal Logic Enabled Personalized Federated Learning Through Property Inference. (arXiv:2401.07448v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.07448](http://arxiv.org/abs/2401.07448)

    本论文提出了一种通过引入时态逻辑推理来实现个性化的形式逻辑启用的联邦学习，以解决异质性客户设备带来的挑战，并提出了聚合群集的概念。

    

    近期对联邦学习（FL）的不断研究进展极大地促进了分布式协作应用的发展，特别是在物联网人工智能（AIoT）领域。然而，当前研究领域中一个缺失的关键方面是使具有符号推理能力的数据驱动客户模型能够工作。具体而言，参与联邦学习的客户设备的异质性构成了一个重要挑战，因为每个客户都具有独特的逻辑推理特性。忽视这些设备特定的规范可能会导致客户端预测中遗漏关键属性，从而导致性能不佳。在本研究中，我们提出了一种新的训练范式，利用时态逻辑推理来解决这个问题。我们的方法涉及通过为每个FL客户端加入机械生成的逻辑表达式来增强训练过程。此外，我们引入了聚合群集的概念。

    Recent advancements in federated learning (FL) have greatly facilitated the development of decentralized collaborative applications, particularly in the domain of Artificial Intelligence of Things (AIoT). However, a critical aspect missing from the current research landscape is the ability to enable data-driven client models with symbolic reasoning capabilities. Specifically, the inherent heterogeneity of participating client devices poses a significant challenge, as each client exhibits unique logic reasoning properties. Failing to consider these device-specific specifications can result in critical properties being missed in the client predictions, leading to suboptimal performance. In this work, we propose a new training paradigm that leverages temporal logic reasoning to address this issue. Our approach involves enhancing the training process by incorporating mechanically generated logic expressions for each FL client. Additionally, we introduce the concept of aggregation clusters 
    
[^91]: 通过森林修剪提高随机森林的准确性和可解释性

    Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])

    [http://arxiv.org/abs/2401.05535](http://arxiv.org/abs/2401.05535)

    通过森林修剪方法，本研究提出了一种兼顾随机森林准确性和决策树可解释性的方法。实验证明，在大多数情景下，这种方法能够显著提高随机森林的性能。

    

    接近几十年的发展之后，随机森林仍然在各种学习问题中提供最先进的准确性，在这方面超越了决策树甚至神经网络等替代机器学习算法。然而，作为一种集成方法，随机森林在解释性方面往往比决策树表现不佳。在本研究中，我们提出了一种事后方法，旨在兼顾随机森林的准确性和决策树的可解释性。为此，我们提出了两种森林修剪方法，以在给定的随机森林内找到最佳子森林，然后在适用的情况下将选定的树合并为一棵。我们的第一种方法依赖于约束穷举搜索，而第二种方法基于LASSO方法的改进。在合成和真实世界数据集上进行的大量实验证明，在大多数情景下，这两种方法中至少有一种能够显著提高随机森林的准确性和可解释性。

    Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
    
[^92]: SAR-RARP50:机器人辅助根治性前列腺切除术中手术器械的分割和动作识别挑战

    SAR-RARP50: Segmentation of surgical instrumentation and Action Recognition on Robot-Assisted Radical Prostatectomy Challenge. (arXiv:2401.00496v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.00496](http://arxiv.org/abs/2401.00496)

    该论文介绍了SAR-RARP50挑战，该挑战提供了第一个多模态、公开的、体内的手术动作识别和语义仪器分割数据集，旨在让研究人员开发出稳健且准确的单任务动作识别方法。

    

    手术工具分割和动作识别是许多计算机辅助干预应用的基本构建模块，从手术技能评估到决策支持系统。现在，基于学习的动作识别和分割方法在性能上优于传统方法，但依赖于大规模的注释数据集。此外，动作识别和工具分割算法通常是在彼此孤立地训练和预测，没有利用潜在的交叉任务关系。通过EndoVis 2022 SAR-RARP50挑战，我们发布了第一个多模态的、公开的、体内的手术动作识别和语义仪器分割数据集，其中包含50个机器人辅助根治性前列腺切除术（RARP）的缝合视频片段。挑战的目标是两方面的。首先，让研究人员利用提供的数据集规模，开发出稳健且高准确性的单任务动作识别方法。

    Surgical tool segmentation and action recognition are fundamental building blocks in many computer-assisted intervention applications, ranging from surgical skills assessment to decision support systems. Nowadays, learning-based action recognition and segmentation approaches outperform classical methods, relying, however, on large, annotated datasets. Furthermore, action recognition and tool segmentation algorithms are often trained and make predictions in isolation from each other, without exploiting potential cross-task relationships. With the EndoVis 2022 SAR-RARP50 challenge, we release the first multimodal, publicly available, in-vivo, dataset for surgical action recognition and semantic instrumentation segmentation, containing 50 suturing video segments of Robotic Assisted Radical Prostatectomy (RARP). The aim of the challenge is twofold. First, to enable researchers to leverage the scale of the provided dataset and develop robust and highly accurate single-task action recognitio
    
[^93]: 基于图神经网络的快速芯片库特征化用于设计技术共优化

    Fast Cell Library Characterization for Design Technology Co-Optimization Based on Graph Neural Networks. (arXiv:2312.12784v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.12784](http://arxiv.org/abs/2312.12784)

    提出了一种基于图神经网络的快速准确芯片库特征化的机器学习模型，通过结合芯片结构，在各种工艺参数下预测精度高，并且相较于传统方法具有100倍的加速。

    

    设计技术共优化在先进半导体工艺开发中实现功耗、性能和面积（PPA）的最佳化发挥着关键作用。芯片库特征化在设计技术共优化流程中至关重要，但传统方法耗时且昂贵。为了克服这些挑战，我们提出了一种基于图神经网络（GNN）的快速准确的芯片库特征化的机器学习模型。我们的模型考虑了芯片结构，并在各种工艺-电压-温度（PVT）角和技术参数上展示出高预测精度。在512个未见过的工艺角和一百万个测试数据点的验证中，我们的模型对于33种类型的单元的延迟、功率和输入引脚电容具有准确的预测，均方绝对百分比误差（MAPE）≤ 0.95%，与SPICE仿真相比加速了100倍。此外，我们还研究了系统级指标，如最差负松弛（WNS）、漏电功耗和动态...

    Design technology co-optimization (DTCO) plays a critical role in achieving optimal power, performance, and area (PPA) for advanced semiconductor process development. Cell library characterization is essential in DTCO flow, but traditional methods are time-consuming and costly. To overcome these challenges, we propose a graph neural network (GNN)-based machine learning model for rapid and accurate cell library characterization. Our model incorporates cell structures and demonstrates high prediction accuracy across various process-voltage-temperature (PVT) corners and technology parameters. Validation with 512 unseen technology corners and over one million test data points shows accurate predictions of delay, power, and input pin capacitance for 33 types of cells, with a mean absolute percentage error (MAPE) $\le$ 0.95% and a speed-up of 100X compared with SPICE simulations. Additionally, we investigate system-level metrics such as worst negative slack (WNS), leakage power, and dynamic 
    
[^94]: 一种用于长时间心血管疾病检测的紧凑型LSTM-SVM融合模型

    A Compact LSTM-SVM Fusion Model for Long-Duration Cardiovascular Diseases Detection. (arXiv:2312.09442v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2312.09442](http://arxiv.org/abs/2312.09442)

    本研究提出了一个紧凑型的LSTM-SVM融合模型，实现了对心血管疾病的早期检测。该模型采用了一种流程优化方法将心电图信号预处理为一致的10秒持续时间，同时利用LSTM和SVM实现了最先进的结果。

    

    全球范围内，心血管疾病是致死的主要原因，每年约有1790万人死于该病。早期检测心血管疾病是关键的临床目标，电心图（ECG）数据是一个受到研究界关注的领域。最近基于机器学习和深度学习的进展在该领域取得了巨大的进展。然而，现有的方法存在固有的局限性，包括不适当的模型评估和数据泄漏的实例。在本研究中，我们提出了一个简化的工作流程范式，将ECG信号预处理为一致的10秒持续时间，消除了手动特征提取/心搏检测的需要。我们还提出了一种混合模型，利用长短期记忆网络（LSTM）与支持向量机（SVM）进行欺诈检测。该架构包括两个LSTM层和一个SVM分类器，实现了SOTA结果，平均精确度评分为...

    Globally, cardiovascular diseases (CVDs) are the leading cause of mortality, accounting for an estimated 17.9 million deaths annually. One critical clinical objective is the early detection of CVDs using electrocardiogram (ECG) data, an area that has received significant attention from the research community. Recent advancements based on machine learning and deep learning have achieved great progress in this domain. However, existing methodologies exhibit inherent limitations, including inappropriate model evaluations and instances of data leakage. In this study, we present a streamlined workflow paradigm for preprocessing ECG signals into consistent 10-second durations, eliminating the need for manual feature extraction/beat detection. We also propose a hybrid model of Long Short-Term Memory (LSTM) with Support Vector Machine (SVM) for fraud detection. This architecture consists of two LSTM layers and an SVM classifier, which achieves a SOTA results with an Average precision score of 
    
[^95]: 在SpiNNaker 2神经形态芯片上进行语言建模

    Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2312.09084](http://arxiv.org/abs/2312.09084)

    该论文介绍了在SpiNNaker 2神经形态芯片上实现语言建模的首次尝试。通过利用基于事件的架构和大规模异步处理的硬件，该方法有望在减少能耗的同时保持竞争任务性能。

    

    随着大型语言模型的规模迅速增长，所需的计算能力也在增加。基于神经形态设备上的事件驱动网络提供了一种显著降低推理能耗的潜在方式。然而，迄今为止，大多数可以在神经形态硬件上运行的基于事件的网络，包括脉冲神经网络(SNN)，在语言建模方面的任务性能甚至不能与LSTM模型相媲美。因此，在神经形态设备上进行语言建模似乎是一个遥远的可能性。在这项工作中，我们首次在神经形态设备上实现了一个语言模型 - 具体来说是基于最近发布的名为EGRU的基于事件的架构的SpiNNaker 2芯片。SpiNNaker 2是一个设计用于大规模异步处理的众核神经形态芯片，而EGRU是为了在保持竞争任务性能的同时高效利用这种硬件而设计的。这个实现标志着在神经形态设备上进行语言建模的第一个

    As large language models continue to scale in size rapidly, so too does the computational power required to run them. Event-based networks on neuromorphic devices offer a potential way to reduce energy consumption for inference significantly. However, to date, most event-based networks that can run on neuromorphic hardware, including spiking neural networks (SNNs), have not achieved task performance even on par with LSTM models for language modeling. As a result, language modeling on neuromorphic devices has seemed a distant prospect. In this work, we demonstrate the first-ever implementation of a language model on a neuromorphic device - specifically the SpiNNaker 2 chip based on a recently published event-based architecture called the EGRU. SpiNNaker 2 is a many-core neuromorphic chip designed for large-scale asynchronous processing, while the EGRU is architected to leverage such hardware efficiently while maintaining competitive task performance. This implementation marks the firs
    
[^96]: HGPROMPT: 少样本提示学习中用于连接同质和异质图的方法

    HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning. (arXiv:2312.01878v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.01878](http://arxiv.org/abs/2312.01878)

    此论文提出了一种名为HGPROMPT的方法，用于连接同质和异质图，在少样本设置下进行提示学习，并通过预训练的同质和异质图来提高性能。

    

    图神经网络（GNNs）和异质图神经网络（HGNNs）是同质和异质图表示学习的重要技术，然而它们在端到端的监督框架中的性能很大程度上取决于任务特定监督的可用性。为了减少标注成本，对自我监督预训练的研究成为一种流行的范式，但是预训练模型和下游任务之间常常存在差距，导致目标的不一致。为了弥合这个差距，提示学习作为一种有前景的方法在少样本设置下正在崛起，而不需要对预训练模型进行完全微调。虽然早期已经对图上基于提示的学习进行了一些探索，但它们主要涉及同质图，忽略了在下游应用中普遍存在的异质图。在本文中，我们提出了HGPROMPT，一种新颖的预训练和提示框架，以统一预先训练的同质和异质图，以实现更好的性能提升。

    Graph neural networks (GNNs) and heterogeneous graph neural networks (HGNNs) are prominent techniques for homogeneous and heterogeneous graph representation learning, yet their performance in an end-to-end supervised framework greatly depends on the availability of task-specific supervision. To reduce the labeling cost, pre-training on self-supervised pretext tasks has become a popular paradigm,but there is often a gap between the pre-trained model and downstream tasks, stemming from the divergence in their objectives. To bridge the gap, prompt learning has risen as a promising direction especially in few-shot settings, without the need to fully fine-tune the pre-trained model. While there has been some early exploration of prompt-based learning on graphs, they primarily deal with homogeneous graphs, ignoring the heterogeneous graphs that are prevalent in downstream applications. In this paper, we propose HGPROMPT, a novel pre-training and prompting framework to unify not only pre-trai
    
[^97]: 多模态大语言模型中的视觉认知

    Visual cognition in multimodal large language models. (arXiv:2311.16093v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.16093](http://arxiv.org/abs/2311.16093)

    本文评估了基于视觉的大语言模型在直观物理、因果推理和直观心理领域的当前状态，并通过一系列的对照实验发现，虽然这些模型在处理和解释视觉数据方面表现出显著的熟练性，然而它们在直观物理、因果推理和直观心理方面的表现还有待提高。

    

    人工智能的一个主要目标是构建像人类一样思考的机器。然而据认为，深度神经网络架构无法实现这一目标。研究人员指出这些模型在因果推理、直观物理和直观心理等领域存在局限性。然而，最近的进展，特别是面向视觉处理的大语言模型的兴起，重新引起了对模拟人类类似认知能力潜力的兴趣。本文评估了基于视觉的大语言模型在直观物理、因果推理和直观心理领域的当前状态。通过一系列的对照实验，我们调查了这些现代模型在理解复杂物理相互作用、因果关系和对他人偏好的直观理解程度。我们的研究发现,虽然这些模型在处理和解释视觉数据方面表现出显著的熟练性,然而它们在直观物理、因果推理和直观心理方面的表现还有待提高。

    A chief goal of artificial intelligence is to build machines that think like people. Yet it has been argued that deep neural network architectures fail to accomplish this. Researchers have asserted these models' limitations in the domains of causal reasoning, intuitive physics, and intuitive psychology. Yet recent advancements, namely the rise of large language models, particularly those designed for visual processing, have rekindled interest in the potential to emulate human-like cognitive abilities. This paper evaluates the current state of vision-based large language models in the domains of intuitive physics, causal reasoning, and intuitive psychology. Through a series of controlled experiments, we investigate the extent to which these modern models grasp complex physical interactions, causal relationships, and intuitive understanding of others' preferences. Our findings reveal that, while these models demonstrate a notable proficiency in processing and interpreting visual data, th
    
[^98]: 深度潜在力模型：基于ODE的过程卷积用于贝叶斯深度学习

    Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning. (arXiv:2311.14828v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.14828](http://arxiv.org/abs/2311.14828)

    该论文介绍了一种称为深度潜在力模型(DLFM)的通用域模型，使用了基于物理信息核的深度高斯过程，通过过程卷积方法从普通微分方程推导出来。DLFM能够捕捉高度非线性实际多输出时间序列中的动态性，并在基准测试上达到与一系列非物理综合概率模型相当的性能。

    

    建模高度非线性动态系统并具有稳健的不确定性量化是一项具有挑战性的任务，通常需要专门设计的方法来解决问题。我们引入了一个通用域模型来解决这个问题，称为深度潜在力模型(DLFM)，它是一个深度高斯过程，每个层次都具有物理信息核，使用过程卷积的普通微分方程推导出。提出了DLFM的两种不同形式，它们利用基于权空间和基于变分感应点的高斯过程近似方法，都适用于双重随机变分推断。我们提供了DLFM捕捉高度非线性实际多输出时间序列数据中存在的动态性的经验证据。此外，我们发现DLFM能够在基准测试上达到与一系列非物理综合概率模型相当的性能。

    Modelling the behaviour of highly nonlinear dynamical systems with robust uncertainty quantification is a challenging task which typically requires approaches specifically designed to address the problem at hand. We introduce a domain-agnostic model to address this issue termed the deep latent force model (DLFM), a deep Gaussian process with physics-informed kernels at each layer, derived from ordinary differential equations using the framework of process convolutions. Two distinct formulations of the DLFM are presented which utilise weight-space and variational inducing points-based Gaussian process approximations, both of which are amenable to doubly stochastic variational inference. We present empirical evidence of the capability of the DLFM to capture the dynamics present in highly nonlinear real-world multi-output time series data. Additionally, we find that the DLFM is capable of achieving comparable performance to a range of non-physics-informed probabilistic models on benchmark
    
[^99]: 基准分析奖励模型在分布转移下准确分析基础模型的能力的能力

    A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift. (arXiv:2311.14743v7 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.14743](http://arxiv.org/abs/2311.14743)

    本论文基于奖励模型的准确性和校准度评估了基础模型在分布转移下的性能。实验结果显示奖励模型对于提示和响应的转移具有不同的敏感性，并呈现出新颖的校准模式和准确性下降。同时，将常用的OOD检测技术引入到奖励模型设置中，用于检测分布转移。

    

    最近，基础模型，特别是大型语言模型（LLM），引起了广泛的关注和应用。利用人类反馈进行强化学习（RLHF）包括训练奖励模型来捕捉期望的行为，然后用于对齐LLM。这些奖励模型还在推断时用于估计LLM响应与期望行为的一致性。然而，很少有工作来衡量这些奖励模型在分布转移下的鲁棒性。在这项工作中，我们评估了通过准确性和校准度（即准确性和信心的匹配程度）衡量的奖励模型性能如何受到分布转移的影响。我们展示了由于OOD提示和响应而产生的新型校准模式和准确性下降，并且发现奖励模型对响应的转移比提示更敏感。此外，我们还将常用于分类的OOD检测技术适应到奖励模型设置中，以检测这些提示和响应的分布转移。

    Foundation models, specifically Large Language Models (LLMs), have lately gained wide-spread attention and adoption. Reinforcement Learning with Human Feedback (RLHF) involves training a reward model to capture desired behaviors, which is then used to align LLM's. These reward models are additionally used at inference-time to estimate LLM responses' adherence to those desired behaviors. However, there is little work measuring how robust these reward models are to distribution shifts. In this work, we evaluate how reward model performance measured via accuracy and calibration (i.e. alignment between accuracy and confidence) - is affected by distribution shift. We show novel calibration patterns and accuracy drops due to OOD prompts and responses, and that the reward model is more sensitive to shifts in responses than prompts. Additionally, we adapt an OOD detection technique commonly used in classification to the reward model setting to detect these distribution shifts in prompts and 
    
[^100]: 线性对数正态注意力与无偏集中力

    Linear Log-Normal Attention with Unbiased Concentration. (arXiv:2311.13541v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.13541](http://arxiv.org/abs/2311.13541)

    本论文研究了自注意机制，并分析了注意力矩阵的分布和集中能力。通过引入线性对数正态注意力来模拟原始自注意力的分布和集中行为，提高了Transformer模型的可扩展性。

    

    Transformer模型在各种应用中取得了显著的成果。然而，由于自注意机制的时间和内存复杂度与序列长度的二次关系，其可扩展性受到限制。当处理长文档或高分辨率图像时，这一限制构成了重大障碍。本研究通过分析注意力矩阵的分布和集中能力，对自注意机制进行了研究。此外，我们提出了衡量这些数量的工具，并引入了一种新的自注意机制，即线性对数正态注意力，旨在模拟原始自注意力的分布和集中行为。我们在常用的自然语言基准测试上的实验证明，我们提出的线性对数正态注意力优于其他线性化注意力替代方法，为增强Transformer模型的可扩展性提供了一个有前途的途径。我们的代码附在补充材料中。

    Transformer models have achieved remarkable results in a wide range of applications. However, their scalability is hampered by the quadratic time and memory complexity of the self-attention mechanism concerning the sequence length. This limitation poses a substantial obstacle when dealing with long documents or high-resolution images. In this work, we study the self-attention mechanism by analyzing the distribution of the attention matrix and its concentration ability. Furthermore, we propose instruments to measure these quantities and introduce a novel self-attention mechanism, Linear Log-Normal Attention, designed to emulate the distribution and concentration behavior of the original self-attention. Our experimental results on popular natural language benchmarks reveal that our proposed Linear Log-Normal Attention outperforms other linearized attention alternatives, offering a promising avenue for enhancing the scalability of transformer models. Our code is available in supplementary
    
[^101]: 机器学习模型在电化学中如何受到虚假数据的影响？

    How False Data Affects Machine Learning Models in Electrochemistry?. (arXiv:2311.10795v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.10795](http://arxiv.org/abs/2311.10795)

    本研究研究了虚假数据对机器学习模型在电化学中的影响。发现线性模型在处理噪声方面效果好，而基于树的模型在噪声处理方面效果较差，但能提供更高的预测准确性。

    

    最近，仅基于数据分布而不考虑数据噪声选取机器学习模型。本研究旨在区分哪些模型在噪声数据下表现良好，并确定堆叠机器学习模型是否确实为原本对噪声敏感的模型提供了鲁棒性。使用12个独立模型和堆叠模型对电化学数据进行测试，包括XGB、LGBM、RF、GB、ADA、NN、ELAS、LASS、RIDGE、SVM、KNN、DT和堆叠模型。发现线性模型能够很好地处理噪声，平均误差为1.75 F g-1，在添加100%噪声时误差最小，平均为60.19 F g-1。而基于树的模型在噪声处理方面失败（100%噪声时平均斜率为55.24 F g-1），但它可以提供更高的预测准确性（最低误差为23.9 F g-1）。

    Recently, the selection of machine learning model based on only the data distribution without concerning the noise of the data. This study aims to distinguish, which models perform well under noisy data, and establish whether stacking machine learning models actually provide robustness to otherwise weak-to-noise models. The electrochemical data were tested with 12 standalone models and stacking model. This includes XGB, LGBM, RF, GB, ADA, NN, ELAS, LASS, RIDGE, SVM, KNN, DT, and the stacking model. It is found that linear models handle noise well with the average error of (slope) to 1.75 F g-1 up to error per 100% percent noise added; but it suffers from prediction accuracy due to having an average of 60.19 F g-1 estimated at minimal error at 0% noise added. Tree-based models fail in terms of noise handling (average slope is 55.24 F g-1 at 100% percent noise), but it can provide higher prediction accuracy (lowest error of 23.9 F g-1) than that of linear. To address the controversial be
    
[^102]: UMedNeRF：针对医学神经辐射场的不确定性感知单视角体积渲染

    UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical Neural Radiance Fields. (arXiv:2311.05836v5 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2311.05836](http://arxiv.org/abs/2311.05836)

    UMedNeRF是一种针对医学神经辐射场的不确定性感知单视角体积渲染网络，能够从2D X射线图像中学习CT投影的连续表示，并通过使用自适应损失权重确保生成图像的质量。

    

    在临床医学领域，计算机断层扫描（CT）是一种用于诊断各种疾病的有效医学影像模态。与X射线图像相比，CT图像可以提供更多信息，包括多平面切片和三维结构，用于临床诊断。然而，CT成像需要患者长时间暴露于大剂量的电离辐射，可能会导致不可逆的身体损伤。本文提出了一种基于生成的辐射场的不确定性感知MedNeRF（UMedNeRF）网络。该网络可以通过获取内部结构和深度信息，并使用自适应损失权重来确保生成图像的质量，学习2D X射线图像的CT投影的连续表示。我们的模型在公开可用的膝盖和胸部数据集上进行训练，并展示了使用单个X射线进行CT投影渲染的结果，并将我们的方法与基于生成的辐射场的其他方法进行比较。

    In the field of clinical medicine, computed tomography (CT) is an effective medical imaging modality for the diagnosis of various pathologies. Compared with X-ray images, CT images can provide more information, including multi-planar slices and three-dimensional structures for clinical diagnosis. However, CT imaging requires patients to be exposed to large doses of ionizing radiation for a long time, which may cause irreversible physical harm. In this paper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on generated radiation fields. The network can learn a continuous representation of CT projections from 2D X-ray images by obtaining the internal structure and depth information and using adaptive loss weights to ensure the quality of the generated images. Our model is trained on publicly available knee and chest datasets, and we show the results of CT projection rendering with a single X-ray and compare our method with other methods based on generated radiation field
    
[^103]: 神经网络回归的高效核替代方法

    Efficient kernel surrogates for neural network-based regression. (arXiv:2310.18612v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.18612](http://arxiv.org/abs/2310.18612)

    本论文研究了一种高效近似方法，称为共轭核（CK），用于替代深度神经网络的神经切向核（NTK）。该方法能够在计算成本较低的情况下产生与NTK相似的结果。

    

    尽管深度神经网络在执行各种学习任务方面具有巨大潜力，但至今仍无法理解其局限性。这部分是由于无法确定学习函数的闭合形式，这使得在未见数据集上研究它们的泛化属性更加困难。最近的研究表明，在无限宽度限制下，随机初始化的深度神经网络会收敛到依赖于已知闭合形式的神经切向核（Neural Tangent Kernel，NTK）的核机器。这些结果暗示并得到实验证据证明，经验核机器也可以作为有限宽度深度神经网络的替代品。然而，组装完整的NTK的高计算成本使得此方法在实践中不可行，这促使我们需要低成本的近似方法。在当前的工作中，我们研究了共轭核（Conjugate Kernel，CK）的性能，这是一种对NTK的高效近似，据观察，它能产生相当相似的结果。

    Despite their immense promise in performing a variety of learning tasks, a theoretical understanding of the limitations of Deep Neural Networks (DNNs) has so far eluded practitioners. This is partly due to the inability to determine the closed forms of the learned functions, making it harder to study their generalization properties on unseen datasets. Recent work has shown that randomly initialized DNNs in the infinite width limit converge to kernel machines relying on a Neural Tangent Kernel (NTK) with known closed form. These results suggest, and experimental evidence corroborates, that empirical kernel machines can also act as surrogates for finite width DNNs. The high computational cost of assembling the full NTK, however, makes this approach infeasible in practice, motivating the need for low-cost approximations. In the current work, we study the performance of the Conjugate Kernel (CK), an efficient approximation to the NTK that has been observed to yield fairly similar results. 
    
[^104]: 模仿大师：探索虚拟人工智能教师在精细运动技能习得中的效能

    Mimicking the Maestro: Exploring the Efficacy of a Virtual AI Teacher in Fine Motor Skill Acquisition. (arXiv:2310.10280v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.10280](http://arxiv.org/abs/2310.10280)

    本研究探索了虚拟人工智能教师在模仿人类教育者技术方面在运动技能习得中的潜力，并通过验证四个指导性假设，证实了在合成学习者上的改进。

    

    精细运动技能，尤其是书写等技能，在学术和日常生活中起着重要作用。传统的教学方法虽然有效，但耗时且不一致。随着机器人和人工智能等先进技术的兴起，越来越多的人开始关注利用这些技术自动化教学过程，通过人机和人机交互。本研究探讨了虚拟人工智能教师在模仿人类教育者技术方面对于运动技能习得的潜力。我们引入了一种捕捉到人类教师独特特征的人工智能教师模型。通过使用适应于模仿教师-学习者交互的强化学习环境测试我们的人工智能模型，我们验证了四个指导性假设，强调学习者表现的提升、技能习得速度的增强以及学习结果的变异性的减少。我们的研究发现在合成学习者上进行了验证。

    Motor skills, especially fine motor skills like handwriting, play an essential role in academic pursuits and everyday life. Traditional methods to teach these skills, although effective, can be time-consuming and inconsistent. With the rise of advanced technologies like robotics and artificial intelligence, there is increasing interest in automating such teaching processes using these technologies, via human-robot and human-computer interactions. In this study, we examine the potential of a virtual AI teacher in emulating the techniques of human educators for motor skill acquisition. We introduce an AI teacher model that captures the distinct characteristics of human instructors. Using a Reinforcement Learning environment tailored to mimic teacher-learner interactions, we tested our AI model against four guiding hypotheses, emphasizing improved learner performance, enhanced rate of skill acquisition, and reduced variability in learning outcomes. Our findings, validated on synthetic lea
    
[^105]: 用MODIS多光谱时间序列和辅助数据进行盲目光谱分离的深度学习研究

    Deep Learning for blind spectral unmixing of LULC classes with MODIS multispectral time series and ancillary data. (arXiv:2310.07223v1 [cs.CV])

    [http://arxiv.org/abs/2310.07223](http://arxiv.org/abs/2310.07223)

    这项研究利用MODIS多光谱时间序列数据和深度学习模型，首次实现了对LULC类别的盲目光谱分离。通过添加地理加地形和气候辅助信息，进一步提高了模型的性能。

    

    遥感数据中LULC类别通常存在混合情况，光谱分离是一种从混合像素中提取信息到其组成LULC类型和相应丰度分数的技术。传统上，解决这一任务要么依赖于需要先验知识的经典方法，要么依赖于避免显式成分计算的机器学习方法，也就是盲目光谱分离（BSU）。大多数基于深度学习（DL）的BSU研究侧重于单个时间步的高光谱数据，然而与多光谱数据相比，其获取成本仍然相当高昂。据我们所知，我们在这里提供了第一项关于使用多光谱时间序列数据和DL模型进行LULC类别的BSU研究。我们进一步通过添加地理加地形（geo-topographic）和气候辅助信息来提升基于长短时记忆（LSTM）的模型的性能。我们的实验结果表明，将光谱时间输入数据与地理时态数据相结合可以提高模型性能。

    Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC) types. Spectral unmixing is a technique to extract information from mixed pixels into their constituent LULC types and corresponding abundance fractions. Traditionally, solving this task has relied on either classical methods that require prior knowledge of endmembers or machine learning methods that avoid explicit endmembers calculation, also known as blind spectral unmixing (BSU). Most BSU studies based on Deep Learning (DL) focus on one time-step hyperspectral data, yet its acquisition remains quite costly compared with multispectral data. To our knowledge, here we provide the first study on BSU of LULC classes using multispectral time series data with DL models. We further boost the performance of a Long-Short Term Memory (LSTM)-based model by incorporating geographic plus topographic (geo-topographic) and climatic ancillary information. Our experiments show that combining spectral-temporal input data togeth
    
[^106]: 用一致性策略提升连续控制

    Boosting Continuous Control with Consistency Policy. (arXiv:2310.06343v1 [cs.LG])

    [http://arxiv.org/abs/2310.06343](http://arxiv.org/abs/2310.06343)

    该论文提出了一种名为一致性策略与Q-Learning （CPQL）的新方法，通过建立从反向扩散轨迹到期望策略的映射，同时解决了基于扩散模型方法的时间效率和准确指导问题。

    

    由于其训练稳定性和强大表达能力，扩散模型在离线强化学习中受到了相当大的关注。然而，它也带来了几个挑战：1）对大量扩散步骤的需求使得基于扩散模型的方法在实时控制中效率低下，限制了它们的应用；2）如何提供准确指导以实现基于扩散模型的策略改进仍然是一个未解决的问题。受一致性模型的启发，我们提出了一种新颖的时间效率方法，称为一致性策略与Q-Learning（CPQL），它通过单步从噪声中导出动作。通过建立从反向扩散轨迹到期望策略的映射，我们同时解决了使用学习到的Q函数更新基于扩散模型的策略时的时间效率和准确指导的问题。我们证明了CPQL可以通过准确指导实现离线强化学习的策略改进。

    Due to its training stability and strong expression, the diffusion model has attracted considerable attention in offline reinforcement learning. However, several challenges have also come with it: 1) The demand for a large number of diffusion steps makes the diffusion-model-based methods time inefficient and limits their applications in real-time control; 2) How to achieve policy improvement with accurate guidance for diffusion model-based policy is still an open problem. Inspired by the consistency model, we propose a novel time-efficiency method named Consistency Policy with Q-Learning (CPQL), which derives action from noise by a single step. By establishing a mapping from the reverse diffusion trajectories to the desired policy, we simultaneously address the issues of time efficiency and inaccurate guidance when updating diffusion model-based policy with the learned Q-function. We demonstrate that CPQL can achieve policy improvement with accurate guidance for offline reinforcement l
    
[^107]: 利用大规模停电数据集上的转移反事实学习，检测电力服务公平性问题

    Detecting Electricity Service Equity Issues with Transfer Counterfactual Learning on Large-Scale Outage Datasets. (arXiv:2310.03258v1 [cs.LG])

    [http://arxiv.org/abs/2310.03258](http://arxiv.org/abs/2310.03258)

    通过转移反事实学习的方法，我们在大规模停电数据集上研究了电力服务的公平性问题，发现低收入和老年人口区域经常遭受较长的停电时间，揭示了电力系统中的偏见存在并强调了改善的需求。

    

    能源公正是跨学科能源研究的一个不断发展的领域。然而，由于混淆变量、治疗效应的复杂异质性和有限的数据可用性，识别能源部门中的系统偏见仍然具有挑战性。为了解决这些挑战，我们引入了一种围绕能源公正的反事实因果分析的新方法。我们使用子组分析来管理各种因素，并利用转移学习的思想来缓解每个子组中的数据稀缺问题。在我们的数值分析中，我们将我们的方法应用于一个大规模的客户级停电数据集，并研究人口因素（如收入和年龄）对停电持续时间的反事实效应。我们的结果表明，低收入和老年人口区域总是经历较长的停电时间，无论天气条件如何。这表明电力系统存在偏见，并强调了专注改善这些问题的需要。

    Energy justice is a growing area of interest in interdisciplinary energy research. However, identifying systematic biases in the energy sector remains challenging due to confounding variables, intricate heterogeneity in treatment effects, and limited data availability. To address these challenges, we introduce a novel approach for counterfactual causal analysis centered on energy justice. We use subgroup analysis to manage diverse factors and leverage the idea of transfer learning to mitigate data scarcity in each subgroup. In our numerical analysis, we apply our method to a large-scale customer-level power outage data set and investigate the counterfactual effect of demographic factors, such as income and age of the population, on power outage durations. Our results indicate that low-income and elderly-populated areas consistently experience longer power outages, regardless of weather conditions. This points to existing biases in the power system and highlights the need for focused im
    
[^108]: 利用潜在信息从视觉观察中进行对抗性模仿学习

    Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v1 [cs.LG])

    [http://arxiv.org/abs/2309.17371](http://arxiv.org/abs/2309.17371)

    本文研究了从视觉观察中进行模仿学习的问题，提出了一种名为潜在对抗观察模仿的算法，通过结合离策略对抗学习技术和从观察序列中学习的代理状态的潜在表示来解决这个问题。实验证明，这种算法能与最先进的方法相匹配。

    

    我们专注于从视觉观察中进行模仿学习的问题，学习代理只能访问专家的视频作为其唯一的学习源。这个框架的挑战包括缺乏专家的动作和环境的局部可观测性，因为地面真实状态只能从像素中推断出来。为了解决这个问题，我们首先对部分可观测环境中的模仿学习进行了理论分析。我们在专家和代理潜在状态转换分布之间的差异度上建立了学习代理子优度的上界。受到这个分析的启发，我们引入了一种称为潜在对抗观察模仿的算法，它将离策略对抗学习技术与从观察序列中学习的代理状态的潜在表示相结合。在高维连续机器人任务的实验证明，我们的算法与最先进的方法相匹配。

    We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-t
    
[^109]: 批量校准：重新思考上下文学习和提示工程的校准方法

    Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v1 [cs.CL])

    [http://arxiv.org/abs/2309.17249](http://arxiv.org/abs/2309.17249)

    本研究提出了一种名为批量校准（BC）的方法，用于解决大型语言模型中提示脆弱性和偏见因素导致的性能下降问题。BC通过控制批量输入的上下文偏见，统一了现有的校准方法，并具有零-shot和仅推理的特点。

    

    提示和上下文学习已成为大型语言模型（LLM）的高效学习范式。然而，LLM存在提示脆弱性和各种偏见因素，包括但不限于格式、选择性的表达方式和上下文学习示例。为解决这个导致性能下降的问题，已经开发了校准方法来减轻这些偏见的影响并恢复LLM的性能。在这项工作中，我们首先对现有的校准方法进行了系统分析，提供了统一的观点并揭示了失败案例。受这些分析的启发，我们提出了批量校准（BC），这是一种简单而直观的方法，可以从批量输入中控制上下文偏见，统一了各种先前的方法，并有效地解决了上述问题。BC是零-shot、仅推理和额外成本可忽略。在少-shot设置中，我们进一步扩展BC以实现全部翻译

    Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches, and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allo
    
[^110]: Timbre-Trap:一种低资源框架用于与乐器无关的音乐转录

    Timbre-Trap: A Low-Resource Framework for Instrument-Agnostic Music Transcription. (arXiv:2309.15717v1 [eess.AS])

    [http://arxiv.org/abs/2309.15717](http://arxiv.org/abs/2309.15717)

    Timbre-Trap是一个低资源框架，将音乐转录和音频重构统一起来，通过利用音高和音色的强分离性，同时估计音高显著度和重构频谱系数，取得优越性能。

    

    近年来，音乐转录的研究主要集中在架构设计和乐器特定数据采集上。由于多样化数据集的不足，进展通常仅限于钢琴转录等单乐器任务。一些研究探索了多乐器转录作为一种增强模型在低资源任务上性能的手段，但这些方法面临着同样的数据可用性问题。我们提出了一种新颖的框架Timbre-Trap，它通过利用音高和音色之间的强分离性将音乐转录和音频重构统一起来。我们训练一个单独的U-Net来同时估计音高显著度和重构复杂的频谱系数，通过一个简单的切换机制在解码阶段选择两者之一的输出。这样，模型学会了产生对应于没有音色的音频的系数，可以被解释为音高显著度。我们证明了该框架能够取得优越的性能。

    In recent years, research on music transcription has focused mainly on architecture design and instrument-specific data acquisition. With the lack of availability of diverse datasets, progress is often limited to solo-instrument tasks such as piano transcription. Several works have explored multi-instrument transcription as a means to bolster the performance of models on low-resource tasks, but these methods face the same data availability issues. We propose Timbre-Trap, a novel framework which unifies music transcription and audio reconstruction by exploiting the strong separability between pitch and timbre. We train a single U-Net to simultaneously estimate pitch salience and reconstruct complex spectral coefficients, selecting between either output during the decoding stage via a simple switch mechanism. In this way, the model learns to produce coefficients corresponding to timbre-less audio, which can be interpreted as pitch salience. We demonstrate that the framework leads to perf
    
[^111]: 重新审视用于连续学习中的Softmax掩码以提高稳定性

    Revisiting Softmax Masking for Stability in Continual Learning. (arXiv:2309.14808v1 [cs.LG])

    [http://arxiv.org/abs/2309.14808](http://arxiv.org/abs/2309.14808)

    本文重新审视了用于连续学习中的Softmax掩码的影响，并提出了一种利用其置信度保持效果的方法，通过增加稳定性同时保持准确性。

    

    在连续学习中，许多分类器使用Softmax函数来学习置信度。然而，许多研究指出其无法准确确定离群值的置信度分布，通常称为认识不确定性。这种固有限制还限制了在连续学习过程中选择何时忘记和保留先前训练的置信度分布的准确决策。为了解决这个问题，我们重新审视了掩码Softmax函数的影响。尽管这种方法在文献中既简单又普遍，但对于在连续学习过程中保持置信度分布（也称为稳定性）的影响尚未得到充分调查。在本文中，我们重新审视了Softmax掩码的影响，并引入了一种利用其置信度保持效果的方法。在具有和不具有记忆重放的类-和任务增量学习基准测试中，我们的方法显著增加了稳定性同时保持了足够大的准确性。

    In continual learning, many classifiers use softmax function to learn confidence. However, numerous studies have pointed out its inability to accurately determine confidence distributions for outliers, often referred to as epistemic uncertainty. This inherent limitation also curtails the accurate decisions for selecting what to forget and keep in previously trained confidence distributions over continual learning process. To address the issue, we revisit the effects of masking softmax function. While this method is both simple and prevalent in literature, its implication for retaining confidence distribution during continual learning, also known as stability, has been under-investigated. In this paper, we revisit the impact of softmax masking, and introduce a methodology to utilize its confidence preservation effects. In class- and task-incremental learning benchmarks with and without memory replay, our approach significantly increases stability while maintaining sufficiently large pla
    
[^112]: Voxtlm: 统一的只解码模型，用于合并语音识别/合成和语音/文本补充任务

    Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks. (arXiv:2309.07937v1 [eess.AS])

    [http://arxiv.org/abs/2309.07937](http://arxiv.org/abs/2309.07937)

    Voxtlm是一个统一的只解码模型，能够在语音识别、语音合成、文本生成和语音延续等任务上取得显著的改善。

    

    我们提出了一个只解码语言模型VoxtLM，能够执行四个任务：语音识别、语音合成、文本生成和语音延续。VoxtLM将文本词汇与自监督语音特征中的离散语音令牌进行整合，并使用特殊令牌实现多任务学习。与单任务模型相比，VoxtLM在语音合成方面显示了显著的改善，语音可理解性从28.9提高到5.6，客观质量从2.68提高到3.90。VoxtLM还改善了语音生成和语音识别性能。VoxtLM使用公开可用的数据进行训练，并将提供训练脚本和模型检查点的开源代码，以实现完全可复现的工作。

    We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. VoxtLM is trained with publicly available data and training recipes and model checkpoints will be open-sourced to make fully reproducible work.
    
[^113]: 通过不变性和冗余减少理解自监督学习的语音表示

    Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction. (arXiv:2309.03619v1 [cs.SD])

    [http://arxiv.org/abs/2309.03619](http://arxiv.org/abs/2309.03619)

    通过标准化潜变量和调整目标函数，我们提出了Modified Barlow Twins (MBT) 方法来改善自监督学习中的语音表示泛化能力，尤其是在有限的目标数据上微调时。这项研究为发展可重用的自监督语音表示迈出了重要的一步。

    

    目标函数的选择在自监督学习中生成高质量表示的过程中至关重要。本文研究了Barlow Twins (BT) 目标的不同表达形式如何影响语音数据下游任务的性能。我们提出了带有标准化潜变量的Modified Barlow Twins (MBT) 来强制尺度不变，并在说话人识别、性别识别和关键词检测任务上进行了评估。我们的结果表明，MBT在有限的目标数据上微调时，改善了表示泛化能力，尤其是相对于原始BT。这凸显了设计鼓励不变性和可传输表示的目标的重要性。我们的分析提供了关于如何调整BT学习目标以生成在适用于新的下游任务中表现出色的语音表示的见解。这项研究是发展可重用的自监督语音表示的重要一步。

    The choice of the objective function is crucial in emerging high-quality representations from self-supervised learning. This paper investigates how different formulations of the Barlow Twins (BT) objective impact downstream task performance for speech data. We propose Modified Barlow Twins (MBT) with normalized latents to enforce scale-invariance and evaluate on speaker identification, gender recognition and keyword spotting tasks. Our results show MBT improves representation generalization over original BT, especially when fine-tuning with limited target data. This highlights the importance of designing objectives that encourage invariant and transferable representations. Our analysis provides insights into how the BT learning objective can be tailored to produce speech representations that excel when adapted to new downstream tasks. This study is an important step towards developing reusable self-supervised speech representations.
    
[^114]: 使用受限玻尔兹曼机推断有效耦合

    Inferring effective couplings with Restricted Boltzmann Machines. (arXiv:2309.02292v2 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2309.02292](http://arxiv.org/abs/2309.02292)

    本研究通过实现受限玻尔兹曼机的能量函数与有效伊辛自旋哈密顿量之间的直接映射，提供了一种用于推断复杂数据中高阶相互作用的方法。

    

    生成模型为我们提供了一种直接建模复杂数据的方法。在这些模型中，基于能量的模型为我们提供了一个神经网络模型，旨在以模型的玻尔兹曼权重的水平准确重现数据中观察到的所有统计相关性。然而，一个挑战是理解这些模型的物理解释。在本研究中，我们通过实现受限玻尔兹曼机的能量函数与包含自旋之间高阶相互作用的有效伊辛自旋哈密顿量之间的直接映射，提出了一个简单的解决方案。这种映射包括所有可能阶的相互作用，超越了逆伊辛方法中通常考虑的传统二次相互作用，使其能够描述复杂的数据集。早期的研究试图实现这个目标，但所提出的映射没有正确处理问题的复杂性，或者没有具体的实际应用指导。

    Generative models offer a direct way to model complex data. Among them, energy-based models provide us with a neural network model that aims to accurately reproduce all statistical correlations observed in the data at the level of the Boltzmann weight of the model. However, one challenge is to understand the physical interpretation of such models. In this study, we propose a simple solution by implementing a direct mapping between the energy function of the Restricted Boltzmann Machine and an effective Ising spin Hamiltonian that includes high-order interactions between spins. This mapping includes interactions of all possible orders, going beyond the conventional pairwise interactions typically considered in the inverse Ising approach, and allowing the description of complex datasets. Earlier works attempted to achieve this goal, but the proposed mappings did not do properly treat the complexity of the problem or did not contain direct prescriptions for practical application. To valid
    
[^115]: 纯粹的消息传递可以估计共同邻居进行链路预测

    Pure Message Passing Can Estimate Common Neighbor for Link Prediction. (arXiv:2309.00976v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.00976](http://arxiv.org/abs/2309.00976)

    这篇论文提出了一种纯粹的消息传递方法，用于估计共同邻居进行链路预测。该方法通过利用输入向量的正交性来捕捉联合结构特征，提出了一种新的链路预测模型MPLP，该模型利用准正交向量估计链路级结构特征，同时保留了节点级复杂性。

    

    消息传递神经网络（MPNN）已成为图表示学习中的事实标准。然而，在链路预测方面，它们往往表现不佳，被简单的启发式算法如共同邻居（CN）所超越。这种差异源于一个根本限制：尽管MPNN在节点级表示方面表现出色，但在编码链路预测中至关重要的联合结构特征（如CN）方面则遇到困难。为了弥合这一差距，我们认为通过利用输入向量的正交性，纯粹的消息传递确实可以捕捉到联合结构特征。具体而言，我们研究了MPNN在近似CN启发式算法方面的能力。基于我们的发现，我们引入了一种新的链路预测模型——消息传递链路预测器（MPLP）。MPLP利用准正交向量估计链路级结构特征，同时保留节点级复杂性。此外，我们的方法表明利用消息传递捕捉结构特征能够改善链路预测性能。

    Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto} standard in graph representation learning. However, when it comes to link prediction, they often struggle, surpassed by simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. Moreover, our approach demonstrates that leveraging message-passing to capture stru
    
[^116]: 透过偏好看大型语言模型的反馈获取：揭示对齐的重要性

    Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v1 [cs.LG])

    [http://arxiv.org/abs/2308.15812](http://arxiv.org/abs/2308.15812)

    本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。

    

    大型语言模型（LLMs）与人类价值观和意图的对齐承诺涉及使用人工智能或人类反馈。稠密的反馈注释获取和整合成本较高，而稀疏的反馈则涉及结构性设计选择，即评分（例如，在1-7的范围内对回答A进行评分）和排名（例如，回答A是否比回答B更好？）。在这项工作中，我们分析了这种设计选择对LLMs的对齐和评估的影响。我们发现，评分和排名所推断出的偏好在人类和AI注释者中都存在严重的不一致问题，达到了60%。我们的后续分析确定了解释这个现象的各种注释者偏见方面，比如人类注释者更喜欢密集回答并在两个选项之间更青睐准确性。令我们惊讶的是，我们还观察到反馈协议的选择对对齐的LLMs的评估也有显著影响。特别是，我们发现LLMs的评估结果因为反馈协议的选择而有所不同。

    Aligning large language models (LLMs) with human values and intents critically involves the use of human or AI feedback. While dense feedback annotations are expensive to acquire and integrate, sparse feedback presents a structural design choice between ratings (e.g., score Response A on a scale of 1-7) and rankings (e.g., is Response A better than Response B?). In this work, we analyze the effect of this design choice for the alignment and evaluation of LLMs. We uncover an inconsistency problem wherein the preferences inferred from ratings and rankings significantly disagree 60% for both human and AI annotators. Our subsequent analysis identifies various facets of annotator biases that explain this phenomena, such as human annotators would rate denser responses higher while preferring accuracy during pairwise judgments. To our surprise, we also observe that the choice of feedback protocol also has a significant effect on the evaluation of aligned LLMs. In particular, we find that LLMs
    
[^117]: CALM: 一种用于全面评估语言模型偏见的多任务基准数据集

    CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])

    [http://arxiv.org/abs/2308.12539](http://arxiv.org/abs/2308.12539)

    CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。

    

    随着语言模型（LMs）的不断增强，量化和比较它们在社会和人口学偏见方面的能力以及潜在的危害变得越来越重要。先前的偏见测量数据集对于人工设计模板的扰动敏感，因此不可靠。为了保证可靠性，我们引入了全面评估语言模型偏见（CALM）的基准数据集，用于量化LMs在三个任务上的偏见。我们整合了来自不同领域（如维基百科和新闻文章）的16个现有数据集，过滤出224个模板，并构建了一个包含78,400个示例的数据集。我们通过平均语义相似性和模板长度的变异程度等指标，比较CALM与先前数据集的多样性，并测试其对细微扰动的敏感性。我们展示了我们的数据集相对于先前数据集更加多样和可靠，因此能更好地捕捉评估模型偏见所需的语言变化的广度。我们评估了20个大型语言模型的偏见。

    As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language 
    
[^118]: GaitPT: 使用骨骼进行步态识别的全部需要。

    GaitPT: Skeletons Are All You Need For Gait Recognition. (arXiv:2308.10623v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.10623](http://arxiv.org/abs/2308.10623)

    GaitPT是一种利用姿势估计骨骼进行步态识别的新方法，它在控制场景和野外场景中均展现出最先进的性能。

    

    步态分析是一个重要的研究领域，具有在安全、医疗、体育和人机交互等方面的众多应用。最近，步态模式被视为一种远距离自动人员识别的独特指纹方法。在这项工作中，我们提出了一种名为Gait Pyramid Transformer（GaitPT）的新型步态识别架构，它利用姿势估计骨骼来捕捉独特的步态模式，而不依赖外貌信息。GaitPT采用分层变压器架构，在解剖学上一致地提取运动的空间和时间特征，通过人体骨骼结构进行引导。我们的结果表明，与其他基于骨骼的步态识别方法相比，GaitPT在控制场景和野外场景中均实现了最先进的性能。GaitPT在CASIA-B上获得了82.6%的平均准确率，优于其他作品6%的差距。

    The analysis of patterns of walking is an important area of research that has numerous applications in security, healthcare, sports and human-computer interaction. Lately, walking patterns have been regarded as a unique fingerprinting method for automatic person identification at a distance. In this work, we propose a novel gait recognition architecture called Gait Pyramid Transformer (GaitPT) that leverages pose estimation skeletons to capture unique walking patterns, without relying on appearance information. GaitPT adopts a hierarchical transformer architecture that effectively extracts both spatial and temporal features of movement in an anatomically consistent manner, guided by the structure of the human skeleton. Our results show that GaitPT achieves state-of-the-art performance compared to other skeleton-based gait recognition works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6% average accuracy on CASIA-B, surpassing other works by a margin of 6%. Moreover,
    
[^119]: 初始筛选顺序问题

    The Initial Screening Order Problem. (arXiv:2307.15398v1 [cs.LG])

    [http://arxiv.org/abs/2307.15398](http://arxiv.org/abs/2307.15398)

    本文研究了初始筛选顺序问题，在候选人筛选中起到关键作用。我们证明在候选人池不平衡情况下，类人筛选者可能对受保护、代表性不足的群体做出不公平的决策。这项研究的目的是与一家大公司合作，以更好地理解其潜在的自动化招聘流程。

    

    本文介绍了初始筛选顺序问题，这是候选人筛选中的关键步骤。它涉及一个类似人类的筛选者，其目标是在给定初始筛选顺序的候选人池中找到前k个适合的候选人，而不是最好的k个适合的候选人。初始筛选顺序表示类人筛选者在筛选之前如何安排候选人池。初始筛选顺序的选择对所选的k个候选人有重要影响。我们证明，在候选人池不平衡的情况下（例如，男性候选人多于女性候选人），类人筛选者可能在决策过程中对受保护的、代表性不足的群体产生不平等的努力。其他公平性结果也在类人筛选者下得到证明。这项研究是与一家大公司合作的，旨在更好地了解其潜在自动化的招聘流程。

    In this paper we present the initial screening order problem, a crucial step within candidate screening. It involves a human-like screener with an objective to find the first k suitable candidates rather than the best k suitable candidates in a candidate pool given an initial screening order. The initial screening order represents the way in which the human-like screener arranges the candidate pool prior to screening. The choice of initial screening order has considerable effects on the selected set of k candidates. We prove that under an unbalanced candidate pool (e.g., having more male than female candidates), the human-like screener can suffer from uneven efforts that hinder its decision-making over the protected, under-represented group relative to the non-protected, over-represented group. Other fairness results are proven under the human-like screener. This research is based on a collaboration with a large company to better understand its hiring process for potential automation. 
    
[^120]: EasyTPP: 迈向开放基准测试时间点过程模型

    EasyTPP: Towards Open Benchmarking Temporal Point Processes. (arXiv:2307.08097v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.08097](http://arxiv.org/abs/2307.08097)

    EasyTPP是第一个关于事件序列建模领域的中心资源库，提供统一的数据集使用界面和广泛的评估程序，解决了该领域缺乏标准化的问题，推动了研究和应用的进展。

    

    连续时间事件序列在诸如医疗保健、金融、在线购物、社交网络等现实世界领域中发挥着重要作用。为了对这类数据进行建模，时间点过程模型（TPPs）已成为最自然和有竞争力的模型，在学术界和应用界都产生了重要影响。尽管近年来出现了许多强大的模型，但这些模型和未来的研究尝试之间缺乏一个中心基准。这种缺乏标准化的情况阻碍了研究人员和从业者对方法进行比较和结果的再现，可能会减慢该领域的进展。在本文中，我们提出了EasyTPP，这是第一个关于事件序列建模领域的研究资产（例如数据、模型、评估程序、文档）的集中存储库。我们的EasyTPP对此领域有几个独特的贡献：统一的使用现有数据集和添加新数据集的界面；广泛的评估程序，包括...

    Continuous-time event sequences play a vital role in real-world domains such as healthcare, finance, online shopping, social networks, and so on. To model such data, temporal point processes (TPPs) have emerged as the most natural and competitive models, making a significant impact in both academic and application communities. Despite the emergence of many powerful models in recent years, there hasn't been a central benchmark for these models and future research endeavors. This lack of standardization impedes researchers and practitioners from comparing methods and reproducing results, potentially slowing down progress in this field. In this paper, we present EasyTPP, the first central repository of research assets (e.g., data, models, evaluation programs, documentations) in the area of event sequence modeling. Our EasyTPP makes several unique contributions to this area: a unified interface of using existing datasets and adding new datasets; a wide range of evaluation programs that are
    
[^121]: 基于图神经网络的日志异常检测与解释

    Graph Neural Networks based Log Anomaly Detection and Explanation. (arXiv:2307.00527v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.00527](http://arxiv.org/abs/2307.00527)

    提出了一种基于图神经网络的无监督日志异常检测方法，该方法将事件日志转换为带属性、有向和加权的图，并利用图神经网络进行图级别的异常检测。引入了一种新的图神经网络模型OCDiGCN来检测一组带属性、有向和加权的图中的图级别异常，并提供对异常的解释能力。

    

    事件日志被广泛用于记录高科技系统的状态，因此日志异常检测对于监控这些系统非常重要。大多数现有的日志异常检测方法将日志事件计数矩阵或日志事件序列作为输入，利用日志事件之间的定量和/或顺序关系来检测异常。然而，仅考虑定量或顺序关系可能导致检测准确性较低。为了缓解这个问题，我们提出了一种基于图的无监督日志异常检测方法，称为Logs2Graphs，它首先将事件日志转换为带属性、有向和加权的图，然后利用图神经网络进行图级别的异常检测。具体而言，我们提出了一种全新的图神经网络模型One-Class Digraph Inception Convolutional Networks（OCDiGCN），用于在一组带属性、有向和加权的图中检测图级别的异常。通过将图表示与属性表示耦合起来，在图级别上进行异常检测的同时提供了对异常的解释能力。

    Event logs are widely used to record the status of high-tech systems, making log anomaly detection important for monitoring those systems. Most existing log anomaly detection methods take a log event count matrix or log event sequences as input, exploiting quantitative and/or sequential relationships between log events to detect anomalies. Unfortunately, only considering quantitative or sequential relationships may result in low detection accuracy. To alleviate this problem, we propose a graph-based method for unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts event logs into attributed, directed, and weighted graphs, and then leverages graph neural networks to perform graph-level anomaly detection. Specifically, we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as OCDiGCN, a novel graph neural network model for detecting graph-level anomalies in a collection of attributed, directed, and weighted graphs. By coupling the graph represe
    
[^122]: 差分隐私分布式估计和学习

    Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])

    [http://arxiv.org/abs/2306.15865](http://arxiv.org/abs/2306.15865)

    本文研究了在网络环境中的分布式估计和学习问题，通过交换私有观测信息，代理可以集体估计未知数量，而保护隐私。通过线性聚合方案和差分隐私（DP）调整的随机化方案，本研究提出了一种能够在保证隐私的同时高效组合观测数据的算法。

    

    我们研究了在网络环境中的分布式估计和学习问题，其中代理通过交换信息来估计从其私下观察的样本中未知的统计属性。通过交换私有观测信息，代理可以集体估计未知数量，但他们也面临隐私风险。我们的聚合方案的目标是在时间和网络中高效地组合观测数据，同时满足代理的隐私需求，而不需要任何超越他们本地附近的协调。我们的算法使参与的代理能够从离线或随时间在线获取的私有信号中估计完整的充分统计量，并保护其信号和网络附近的隐私。这是通过线性聚合方案和调整的随机化方案实现的，将噪声添加到交换的估计数据中以满足差分隐私（DP）。

    We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
    
[^123]: 6G边缘网络中的Split Learning

    Split Learning in 6G Edge Networks. (arXiv:2306.12194v1 [cs.LG])

    [http://arxiv.org/abs/2306.12194](http://arxiv.org/abs/2306.12194)

    Split learning (SL) enables servers to handle the major training workload while still enhancing data privacy, which is an important approach in 6G edge networks. This article provides an overview of the tailored 6G architecture to support edge SL, the critical design issues for edge SL, and presents future research direction and exciting applications of SL in 6G edge networks.

    

    随着分布式边缘计算资源的普及，6G移动网络将发展成为一个连接智能的网络。在这条线路上，将联邦学习纳入移动边缘的提议近年来引起了相当大的兴趣。然而，联邦学习的部署面临着重大的挑战，因为庞大的资源受限的物联网设备几乎无法支持设备上的模型训练。这导致了Split Learning (SL)的出现，它使服务器处理主要的训练工作负载，同时增强数据隐私。在本文中，我们简要概述了SL的关键发展，并阐述了其与无线边缘网络的无缝集成。我们首先说明了定制的6G体系结构，以支持边缘SL。然后，我们研究了边缘SL的关键设计问题，包括创新的资源高效学习框架和在单个边缘服务器下的资源管理策略。此外，我们扩展了Split Learning模型的多边缘服务器方案。最后，我们提出了全面的未来研究方向和一些刺激人心的SL在6G边缘网络中的应用。

    With the proliferation of distributed edge computing resources, the 6G mobile network will evolve into a network for connected intelligence. Along this line, the proposal to incorporate federated learning into the mobile edge has gained considerable interest in recent years. However, the deployment of federated learning faces substantial challenges as massive resource-limited IoT devices can hardly support on-device model training. This leads to the emergence of split learning (SL) which enables servers to handle the major training workload while still enhancing data privacy. In this article, we offer a brief overview of key advancements in SL and articulate its seamless integration with wireless edge networks. We begin by illustrating the tailored 6G architecture to support edge SL. Then, we examine the critical design issues for edge SL, including innovative resource-efficient learning frameworks and resource management strategies under a single edge server. Additionally, we expand t
    
[^124]: $\pi2\text{vec}$：基于继承特征的策略表示方法

    $\pi2\text{vec}$: Policy Representations with Successor Features. (arXiv:2306.09800v1 [cs.LG])

    [http://arxiv.org/abs/2306.09800](http://arxiv.org/abs/2306.09800)

    本文提出了$\pi2\text{vec}$方法，它可以将黑盒策略行为表示为特征向量，并可以用于离线策略选择。该方法为现代研究方向中的离线策略评估、基础模型状态表示和资源受限制的策略选择提供了重要的支持。

    

    本文描述了$\pi2\text{vec}$，一种将黑盒策略行为表示为特征向量的方法。策略表示以任务无关的方式捕捉了基础模型特征统计数据在策略行为响应中的变化，并可以从离线数据中进行训练，从而可以用于离线策略选择。本研究为融合三个现代研究方向提供了重要的支持：作为离线强化学习的补充的离线策略评估，作为通用强大状态表示的基础模型，以及在资源受限制的环境中进行有效策略选择的方法。

    This paper describes $\pi2\text{vec}$, a method for representing behaviors of black box policies as feature vectors. The policy representations capture how the statistics of foundation model features change in response to the policy behavior in a task agnostic way, and can be trained from offline data, allowing them to be used in offline policy selection. This work provides a key piece of a recipe for fusing together three modern lines of research: Offline policy evaluation as a counterpart to offline RL, foundation models as generic and powerful state representations, and efficient policy selection in resource constrained environments.
    
[^125]: 无奖励训练鲁棒世界模型的无奖励课程

    Reward-Free Curricula for Training Robust World Models. (arXiv:2306.09205v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09205](http://arxiv.org/abs/2306.09205)

    通过无奖励课程进行训练可以实现鲁棒世界模型。我们提出了WAKER算法，通过根据世界模型在不同环境中的估计误差选择数据收集环境，从而提升模型的鲁棒性。

    

    最近人们对开发能够适应新任务而无需在环境中进行额外训练的通用能力代理产生了浓厚的兴趣。从无奖励探索中学习世界模型是一种有前景的方法，它使得可以使用想象的经验来训练新任务的策略。然而，实现一个通用的代理需要在不同环境下具有鲁棒性。在这项工作中，我们解决了在无奖励设置中生成课程以训练鲁棒性世界模型的新问题。我们从极小极大后悔的角度考虑鲁棒性，并展示了极小极大后悔与在不同环境实例中世界模型的最大误差最小化之间的联系。这个结果为我们的算法WAKER（基于鲁棒性的环境中的知识加权获取）提供了指导。WAKER根据每个环境中世界模型的估计误差选择数据收集的环境。我们的实验表明WAKER能够提升鲁棒性模型的质量。

    There has been a recent surge of interest in developing generally-capable agents that can adapt to new tasks without additional training in the environment. Learning world models from reward-free exploration is a promising approach, and enables policies to be trained using imagined experience for new tasks. However, achieving a general agent requires robustness across different environments. In this work, we address the novel problem of generating curricula in the reward-free setting to train robust world models. We consider robustness in terms of minimax regret over all environment instantiations and show that the minimax regret can be connected to minimising the maximum error in the world model across environment instances. This result informs our algorithm, WAKER: Weighted Acquisition of Knowledge across Environments for Robustness. WAKER selects environments for data collection based on the estimated error of the world model for each environment. Our experiments demonstrate that WA
    
[^126]: TopP\&R: 具有鲁棒性的支持估计方法，用于评估生成模型中的保真度和多样性

    TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models. (arXiv:2306.08013v1 [cs.LG])

    [http://arxiv.org/abs/2306.08013](http://arxiv.org/abs/2306.08013)

    本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。

    

    本文提出了一种鲁棒可靠的生成模型评估指标，通过引入拓扑和统计处理进行严格的支持估计。现有的度量标准，如Inception Score（IS），Fr\'echet Inception Distance（FID）以及Precision and Recall（P\&R）的变体，严重依赖于从样本特征估计的支持。然而，尽管评估的质量完全取决于其可靠性，但其估计的可靠性并没有得到严肃的讨论（并被忽视）。本文提出了拓扑精度和召回率（TopP\&R，发音为“topper”），它提供了一种系统的方法来估计支持，仅保留具有一定置信水平的具有拓扑和统计上重要性的特征。这不仅使TopP\&R对于噪声特征具有强大的鲁棒性，而且还提供了统计一致性。我们的理论和实验结果表明，TopP\&R对于离群值和非独立同分布具有鲁棒性。

    We propose a robust and reliable evaluation metric for generative models by introducing topological and statistical treatments for rigorous support estimation. Existing metrics, such as Inception Score (IS), Fr\'echet Inception Distance (FID), and the variants of Precision and Recall (P\&R), heavily rely on supports that are estimated from sample features. However, the reliability of their estimation has not been seriously discussed (and overlooked) even though the quality of the evaluation entirely depends on it. In this paper, we propose Topological Precision and Recall (TopP\&R, pronounced 'topper'), which provides a systematic approach to estimating supports, retaining only topologically and statistically important features with a certain level of confidence. This not only makes TopP\&R strong for noisy features, but also provides statistical consistency. Our theoretical and experimental results show that TopP\&R is robust to outliers and non-independent and identically distributed
    
[^127]: 从少量根因的数据中学习DAGs

    Learning DAGs from Data with Few Root Causes. (arXiv:2305.15936v1 [cs.LG])

    [http://arxiv.org/abs/2305.15936](http://arxiv.org/abs/2305.15936)

    该论文提出了一种新的算法，能够从仅有少量根因的数据中学习DAGs，并证明了其可识别性，并在性能上优于以前的方法。

    

    我们提出了一种新的角度和算法，用于从线性结构方程模型(SEM)生成的数据中学习有向无环图(DAGs)。我们首先展示线性SEM可以被视为一种线性变换，先前的工作使用一个由与节点关联的随机值根因(我们将其称为)的稠密输入向量计算数据。我们考虑仅存在几个根因(近似)的情况，并在数据的测量中引入噪声。从直觉上讲，这意味着DAG数据是由少数数据生成事件产生的，其效果通过DAG传播。我们在这种新设置中证明可识别性，并表明真正的DAG是根因向量L0-范数的全局最小化者。对于具有少量根因的数据，有和没有噪音的情况下，我们表现出比以前的DAG学习方法更优异的性能。

    We present a novel perspective and algorithm for learning directed acyclic graphs (DAGs) from data generated by a linear structural equation model (SEM). First, we show that a linear SEM can be viewed as a linear transform that, in prior work, computes the data from a dense input vector of random valued root causes (as we will call them) associated with the nodes. Instead, we consider the case of (approximately) few root causes and also introduce noise in the measurement of the data. Intuitively, this means that the DAG data is produced by few data-generating events whose effect percolates through the DAG. We prove identifiability in this new setting and show that the true DAG is the global minimizer of the $L^0$-norm of the vector of root causes. For data with few root causes, with and without noise, we show superior performance compared to prior DAG learning methods.
    
[^128]: 条件分布之间的经验最优输运

    Empirical Optimal Transport between Conditional Distributions. (arXiv:2305.15901v1 [cs.LG])

    [http://arxiv.org/abs/2305.15901](http://arxiv.org/abs/2305.15901)

    本文考虑在一个公共变量的条件下，相应分布之间的最优输运问题。通过采用基于 MMD 的核正则化器，克服了条件变量是连续的和两个分布中该变量的边缘是不同的挑战。

    

    给定两个联合分布的样本，考虑在一个公共变量的条件下，相应分布之间的最优输运问题。本文的目标是估计伴随条件值的输运成本（Wasserstein 距离），以及条件分布间的输运计划。由于匹配条件分布是监督训练判别模型和（隐式）条件生成模型的核心，条件分布之间的最优输运具有在不同的机器学习应用中被应用的潜力。然而，由于涉及到隐式特定于联合（样本）的条件分布，因此制定这个问题是具有挑战性的，特别是在（i）条件变量是连续的和（ii）两个分布中该变量的边缘是不同的情况下。我们通过采用特定的基于 MMD（最大均值差异）的核正则化器来克服这些挑战。

    Given samples from two joint distributions, we consider the problem of Optimal Transportation (OT) between the corresponding distributions conditioned on a common variable. The objective of this work is to estimate the associated transport cost (Wasserstein distance) as well as the transport plan between the conditionals as a function of the conditioned value. Since matching conditional distributions is at the core of supervised training of discriminative models and (implicit) conditional-generative models, OT between conditionals has the potential to be employed in diverse machine learning applications. However, since the conditionals involved in OT are implicitly specified via the joint samples, it is challenging to formulate this problem, especially when (i) the variable conditioned on is continuous and (ii) the marginal of this variable in the two distributions is different. We overcome these challenges by employing a specific kernel MMD (Maximum Mean Discrepancy) based regularizer
    
[^129]: SMT 2.0：一个关注层次和混合变量高斯过程的代理模型工具包

    SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and Mixed Variables Gaussian Processes. (arXiv:2305.13998v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.13998](http://arxiv.org/abs/2305.13998)

    SMT 2.0是一个开源的代理模型工具包，引入了处理混合变量和层次变量的能力，并通过扩展采样方法、添加新的代理模型以及计算Kriging的方差和核导数来改进了SMT。

    

    Surrogate Modeling Toolbox (SMT)是一个开源的Python包，提供了一系列代理建模方法、采样技术和一套示例问题。本文介绍了SMT 2.0，这是SMT的一个重要新版本，引入了显著的升级和新功能。这个版本增加了处理混合变量代理模型和层次变量的能力。这些类型的变量在多个代理建模应用中变得越来越重要。SMT 2.0还通过扩展采样方法、添加新的代理模型以及计算Kriging的方差和核导数来改进了SMT。这个版本还包括了处理带噪声和使用多保真度数据的新函数。据我们所知，SMT 2.0是第一个提出层次和混合输入的开源代理库。这个开源软件采用New BSD许可证进行分发。

    The Surrogate Modeling Toolbox (SMT) is an open-source Python package that offers a collection of surrogate modeling methods, sampling techniques, and a set of sample problems. This paper presents SMT 2.0, a major new release of SMT that introduces significant upgrades and new features to the toolbox. This release adds the capability to handle mixed-variable surrogate models and hierarchical variables. These types of variables are becoming increasingly important in several surrogate modeling applications. SMT 2.0 also improves SMT by extending sampling methods, adding new surrogate models, and computing variance and kernel derivatives for Kriging. This release also includes new functions to handle noisy and use multifidelity data. To the best of our knowledge, SMT 2.0 is the first open-source surrogate library to propose surrogate models for hierarchical and mixed inputs. This open-source software is distributed under the New BSD license.
    
[^130]: 逆优化学习：内心成本、增强次优损失和算法

    Learning in Inverse Optimization: Incenter Cost, Augmented Suboptimality Loss, and Algorithms. (arXiv:2305.07730v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2305.07730](http://arxiv.org/abs/2305.07730)

    本论文提出了逆优化学习的新概念——内心概念，以及相应的可行凸形式，并开发了新型损失函数ASL以及一阶算法Stochastic Approximate Mirror Descent（SAM）来学习专家的成本函数。

    

    在逆优化学习中，专家代理人解决参数化于外部信号的优化问题。从学习的角度，目标是在给定一个信号和相应最优行动的数据集的情况下，学习专家的成本函数。受到与逆优化集一致的成本向量的几何形状的启发，我们引入了类似于Besbes等人最近提出的外心概念的 "内心"概念。我们讨论了内心成本向量的几何和鲁棒性解释，并开发了相应的可行凸形式，与外心相反，我们展示了外接圆等效于一个难以处理的优化程序。我们进一步提出了一种新型的损失函数，称为增强次优损失（ASL），作为内心概念的一种松弛形式，用于处理不一致数据的问题。利用ASL的结构，我们提出了一种新颖的一阶算法，命名为随机逼近镜像下降。这种算法带来了比现有算法更好的性能。

    In Inverse Optimization (IO), an expert agent solves an optimization problem parametric in an exogenous signal. From a learning perspective, the goal is to learn the expert's cost function given a dataset of signals and corresponding optimal actions. Motivated by the geometry of the IO set of consistent cost vectors, we introduce the "incenter" concept, a new notion akin to circumcenter recently proposed by Besbes et al. [2022]. Discussing the geometric and robustness interpretation of the incenter cost vector, we develop corresponding tractable convex reformulations, which are in contrast with the circumcenter, which we show is equivalent to an intractable optimization program. We further propose a novel loss function called Augmented Suboptimality Loss (ASL), as a relaxation of the incenter concept, for problems with inconsistent data. Exploiting the structure of the ASL, we propose a novel first-order algorithm, which we name Stochastic Approximate Mirror Descent. This algorithm com
    
[^131]: 张量空间中的基础张量PCA

    Tensor PCA from basis in tensor space. (arXiv:2305.02803v1 [math.NA])

    [http://arxiv.org/abs/2305.02803](http://arxiv.org/abs/2305.02803)

    本文提出了一种张量PCA的数学框架，通过自伴张量算子导出张量空间中的基础以解决以往方法的局限性，实验结果表明了该方法的有效性。

    

    本文提出了一种张量PCA的数学框架，该方法能够克服以前通过迭代求解优化问题来提取低维子空间的方法的局限性。该方法的核心是从实自伴张量算子中导出张量空间中的基础，从而将基础的导出问题转化为特征值问题。本文研究了三种不同情况的导出：i）从自伴张量算子中导出基础；ii）导出秩为1的基础；iii）从子空间中导出基础。特别是，证明了实自伴张量算子的特征值方程与标准矩阵特征值方程的等价性。针对所考虑的三种情况，采用了子空间方法来导出张量PCA。基于图像数据集的实验验证了所提出的数学框架。

    The aim of this paper is to present a mathematical framework for tensor PCA. The proposed approach is able to overcome the limitations of previous methods that extract a low dimensional subspace by iteratively solving an optimization problem. The core of the proposed approach is the derivation of a basis in tensor space from a real self-adjoint tensor operator, thus reducing the problem of deriving a basis to an eigenvalue problem. Three different cases have been studied to derive: i) a basis from a self-adjoint tensor operator; ii) a rank-1 basis; iii) a basis in a subspace. In particular, the equivalence between eigenvalue equation for a real self-adjoint tensor operator and standard matrix eigenvalue equation has been proven. For all the three cases considered, a subspace approach has been adopted to derive a tensor PCA. Experiments on image datasets validate the proposed mathematical framework.
    
[^132]: 学习具有物理一致性的异质性粒子相互作用的集体关系推断

    Collective Relational Inference for learning physics-consistent heterogeneous particle interactions. (arXiv:2305.00557v1 [cs.LG])

    [http://arxiv.org/abs/2305.00557](http://arxiv.org/abs/2305.00557)

    本论文提出了一种新的概率方法用于学习异质性粒子相互作用的集体关系推断，与现有方法相比，该方法集体地推断不同边的相互作用类型，使用物理感应的图神经网络来学习具有物理一致性的成对相互作用，并在推断准确性和保持物理保真度方面一致优于现有方法。

    

    相互作用粒子系统在自然界和工程中无处不在。揭示粒子相互作用定律具有基本重要性，但由于底层配置复杂性而具有极大的挑战性。最近开发的机器学习方法在发现同质系统粒子轨迹中的成对相互作用方面显示出极大的潜力。然而，它们无法揭示异质系统中的相互作用，而这种系统在现实中普遍存在，其中多个相互作用类型同时存在，并且需要关系推断。在这里，我们提出了一种新的概率方法用于关系推断，与现有方法相比，具有两个独特的特征：首先，它集体地推断不同边的相互作用类型；其次，它使用物理感应的图神经网络来学习具有物理一致性的成对相互作用。我们在几个基准数据集上评估了所提出的方法，并证明其在推断的相互作用准确性和保持物理保真度方面一致优于现有方法。具体而言，我们的方法确定了具有重要物理意义的新型相互作用类型，揭示了统治系统的隐藏物理原理，并在提高物理性质的预测方面显示出极大的潜力。

    Interacting particle systems are ubiquitous in nature and engineering. Revealing particle interaction laws is of fundamental importance but also particularly challenging due to underlying configurational complexities. Recently developed machine learning methods show great potential in discovering pairwise interactions from particle trajectories in homogeneous systems. However, they fail to reveal interactions in heterogeneous systems that are prevalent in reality, where multiple interaction types coexist simultaneously and relational inference is required. Here, we propose a novel probabilistic method for relational inference, which possesses two distinctive characteristics compared to existing methods. First, it infers the interaction types of different edges collectively, and second, it uses a physics-induced graph neural network to learn physics-consistent pairwise interactions. We evaluate the proposed methodology across several benchmark datasets and demonstrate that it is consist
    
[^133]: 重新考虑基于GNN的异构知识图谱实体对齐：新数据集和新方法

    Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method. (arXiv:2304.03468v1 [cs.LG])

    [http://arxiv.org/abs/2304.03468](http://arxiv.org/abs/2304.03468)

    文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。

    

    知识图谱（KG）应用的发展导致了需要从各种来源提取的异构KG之间的实体对齐（EA）的不断增长需求。近来，由于GNN的出色结构信息捕捉能力，在EA任务中广泛采用GNN。然而，我们观察到现有常见EA数据集的过于简单化的设置与现实场景相距甚远，这妨碍了对最近方法所取得进展的全面理解。这种现象使我们深思：现有基于GNN的EA方法是否真的取得了伟大进展？为了研究EA方法在现实情况下的性能，本文聚焦于高度异构的KG（HHKG）（例如，事件KG和通用KG）的对齐，这些KG在规模和结构上不同，并共享更少的重叠实体。首先，我们清理了不合理的设置，并提出了两个新的HHKG数据集，其密切地模拟了现实世界场景。

    The development of knowledge graph (KG) applications has led to a rising need for entity alignment (EA) between heterogeneous KGs that are extracted from various sources. Recently, graph neural networks (GNNs) have been widely adopted in EA tasks due to GNNs' impressive ability to capture structure information. However, we have observed that the oversimplified settings of the existing common EA datasets are distant from real-world scenarios, which obstructs a full understanding of the advancements achieved by recent methods. This phenomenon makes us ponder: Do existing GNN-based EA methods really make great progress?  In this paper, to study the performance of EA methods in realistic settings, we focus on the alignment of highly heterogeneous KGs (HHKGs) (e.g., event KGs and general KGs) which are different with regard to the scale and structure, and share fewer overlapping entities. First, we sweep the unreasonable settings, and propose two new HHKG datasets that closely mimic real-wo
    
[^134]: 面向资源受限的无线边缘网络的高效并行分裂学习

    Efficient Parallel Split Learning over Resource-constrained Wireless Edge Networks. (arXiv:2303.15991v1 [cs.LG])

    [http://arxiv.org/abs/2303.15991](http://arxiv.org/abs/2303.15991)

    本文提出了面向资源受限的无线边缘网络的高效并行分裂学习（EPSL）框架，旨在加速模型训练。EPSL并行化客户端模型训练，通过聚合梯度降低了反向传播的局部梯度维度，从而显著减少了服务器端的训练和通信延迟。同时，EPSL还设计了资源分配算法以优化计算和通信资源分配。

    

    随着神经网络越来越深，这阻碍了联合学习等隐私增强分布式学习方式（如联邦学习）在资源受限的设备上的民主化。为了解决这个挑战，本文倡导将边缘计算范式和并行分裂学习（PSL）相结合，允许多个客户端设备通过逐层模型分裂将大量的训练工作负载卸载到边缘服务器上。通过观察到现有的PSL方案会产生过多的训练延迟和大量的数据传输，我们提出了一种创新的PSL框架——高效并行分裂学习（EPSL），以加速模型训练。具体而言，EPSL将客户端模型训练并行化，并通过最后一层梯度聚合降低了反向传播（BP）的局部梯度维度，从而显著减少了服务器端的训练和通信延迟。此外，通过考虑边缘设备的异构通道条件和计算能力，我们设计了资源分配算法以优化计算和通信资源分配。实验结果表明，EPSL通过将通信成本和训练时间分别降低76％和63％，优于最先进的PSL方法。

    The increasingly deeper neural networks hinder the democratization of privacy-enhancing distributed learning, such as federated learning (FL), to resource-constrained devices. To overcome this challenge, in this paper, we advocate the integration of edge computing paradigm and parallel split learning (PSL), allowing multiple client devices to offload substantial training workloads to an edge server via layer-wise model split. By observing that existing PSL schemes incur excessive training latency and large volume of data transmissions, we propose an innovative PSL framework, namely, efficient parallel split learning (EPSL), to accelerate model training. To be specific, EPSL parallelizes client-side model training and reduces the dimension of local gradients for back propagation (BP) via last-layer gradient aggregation, leading to a significant reduction in server-side training and communication latency. Moreover, by considering the heterogeneous channel conditions and computing capabil
    
[^135]: 使用稀疏伊辛机器训练深度玻尔兹曼网络

    Training Deep Boltzmann Networks with Sparse Ising Machines. (arXiv:2303.10728v2 [cs.ET] UPDATED)

    [http://arxiv.org/abs/2303.10728](http://arxiv.org/abs/2303.10728)

    本文展示了使用稀疏伊辛机器训练深度玻尔兹曼网络的新应用领域，通过在硬件感知的网络拓扑中使用伊辛机器，我们实现了与优化的软件模型相同的分类准确率。

    

    随着摩尔定律放缓，开发非传统计算范式成为趋势，其中包括专门用于解决组合优化问题的伊辛机器。本文展示了一种新的应用领域，即使用伊辛机器训练深度生成式人工智能模型。我们使用稀疏、异步和大规模并行的伊辛机器，在混合概率-经典计算环境中训练深度玻尔兹曼网络。我们在中等规模的可编程门阵列（FPGA）上实现硬件感知的网络拓扑结构，使用完整的MNIST和Fashion MNIST（FMNIST）数据集，没有任何降采样，并对CIFAR-10数据集进行了缩减。对于MNIST而言，我们的机器仅使用4,264个节点（p-bits）和大约30,000个参数，就实现了与优化的基于软件的受限玻尔兹曼机器（RBM）相同的分类准确率（90%），后续的FMNIST和CIFAR-10结果类似。

    The slowing down of Moore's law has driven the development of unconventional computing paradigms, such as specialized Ising machines tailored to solve combinatorial optimization problems. In this paper, we show a new application domain for probabilistic bit (p-bit) based Ising machines by training deep generative AI models with them. Using sparse, asynchronous, and massively parallel Ising machines we train deep Boltzmann networks in a hybrid probabilistic-classical computing setup. We use the full MNIST and Fashion MNIST (FMNIST) dataset without any downsampling and a reduced version of CIFAR-10 dataset in hardware-aware network topologies implemented in moderately sized Field Programmable Gate Arrays (FPGA). For MNIST, our machine using only 4,264 nodes (p-bits) and about 30,000 parameters achieves the same classification accuracy (90%) as an optimized software-based restricted Boltzmann Machine (RBM) with approximately 3.25 million parameters. Similar results follow for FMNIST and C
    
[^136]: cito: 使用torch进行神经网络训练的R包

    cito: An R package for training neural networks using torch. (arXiv:2303.09599v1 [cs.LG])

    [http://arxiv.org/abs/2303.09599](http://arxiv.org/abs/2303.09599)

    cito是一个用户友好的R包，使用torch进行深度神经网络的训练，包括许多对预测和评估模型有用的用户友好功能。

    

    深度神经网络(DNN)已成为回归和分类任务的中心算法类别。虽然一些包允许用户在R中指定DNN，但它们在功能上相当有限。因此，大多数当前的深度学习应用程序依赖于主要的深度学习框架PyTorch或TensorFlow来构建和训练DNN。然而，与R环境中可比的回归或机器学习包相比，使用这些框架需要更多的培训和时间。我们在这里介绍了cito，这是一个用户友好的R包，用于深度学习。cito允许R用户使用大多数R建模函数中使用的熟悉的公式语法来指定深度神经网络。在后台，cito使用torch来拟合模型，利用torch库的所有数值优化，包括在CPU或GPU上切换训练模型的能力。此外，cito包括许多用于预测和评估模型的用户友好功能。

    1. Deep neural networks (DNN) have become a central class of algorithms for regression and classification tasks. Although some packages exist that allow users to specify DNN in R, those are rather limited in their functionality. Most current deep learning applications therefore rely on one of the major deep learning frameworks, PyTorch or TensorFlow, to build and train DNN. However, using these frameworks requires substantially more training and time than comparable regression or machine learning packages in the R environment.  2. Here, we present cito, an user-friendly R package for deep learning. cito allows R users to specify deep neural networks in the familiar formula syntax used by most modeling functions in R. In the background, cito uses torch to fit the models, taking advantage of all the numerical optimizations of the torch library, including the ability to switch between training models on CPUs or GPUs. Moreover, cito includes many user-friendly functions for predictions and
    
[^137]: DeepGD: 一种用于深度神经网络的多目标黑盒测试选择方法

    DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks. (arXiv:2303.04878v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04878](http://arxiv.org/abs/2303.04878)

    DeepGD是一种用于深度神经网络的多目标黑盒测试选择方法，通过优先选择具有高错误暴露能力的测试输入来降低标记成本，同时选择具有高不确定性分数的测试输入以尽可能触发更多的误预测输入，并通过最大化揭示DNN模型中不同缺陷的概率来增加测试的多样性。

    

    深度神经网络（DNN）被广泛应用于图像处理、语音识别和自然语言处理等各个应用领域。然而，由于其输入域的复杂性和规模，测试DNN模型可能具有挑战性。特别地，测试DNN模型通常需要生成或探索大规模的未标记数据集。在实践中，DNN测试神谕通常需要昂贵的人工工作来标记测试数据，可能涉及多个专家以确保标记的正确性。在本文中，我们提出了DeepGD，一种用于DNN模型的黑盒多目标测试选择方法。它通过优先选择具有高错误暴露能力的测试输入来降低标记成本，同时选择具有高不确定性分数的测试输入以尽可能触发更多的误预测输入，并通过最大化揭示DNN模型中不同缺陷的概率来增加测试的多样性。

    Deep neural networks (DNNs) are widely used in various application domains such as image processing, speech recognition, and natural language processing. However, testing DNN models may be challenging due to the complexity and size of their input domain. Particularly, testing DNN models often requires generating or exploring large unlabeled datasets. In practice, DNN test oracles, which identify the correct outputs for inputs, often require expensive manual effort to label test data, possibly involving multiple experts to ensure labeling correctness. In this paper, we propose DeepGD, a black-box multi-objective test selection approach for DNN models. It reduces the cost of labeling by prioritizing the selection of test inputs with high fault revealing power from large unlabeled datasets. DeepGD not only selects test inputs with high uncertainty scores to trigger as many mispredicted inputs as possible but also maximizes the probability of revealing distinct faults in the DNN model by s
    
[^138]: 多天线系统中数字无线协作联邦学习的研究

    Digital Over-the-Air Federated Learning in Multi-Antenna Systems. (arXiv:2302.14648v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2302.14648](http://arxiv.org/abs/2302.14648)

    本文研究了在多天线系统中采用数字调制和空中计算的情况下，联邦学习的性能优化问题。通过结合数字调制和AirComp，提出了一种改进的联邦平均算法，以解决无线信道衰落导致的总体失真问题。

    

    本文研究了在实际的无线多输入多输出（MIMO）通信系统中，采用数字调制和空中计算（AirComp）的情况下，联邦学习（FL）的性能优化。特别考虑了一个MIMO系统，在该系统中，边缘设备使用波束形成将其本地收集的数据训练的本地FL模型传输给参数服务器（PS），以最大化可调度传输的设备数量。PS作为中央控制器，使用接收到的本地FL模型生成一个全局FL模型并广播给所有设备。由于无线网络中的带宽有限，采用了AirComp以实现高效的无线数据聚合。然而，无线信道的衰落会产生基于AirComp的FL方案中的总体失真。为了克服这一挑战，我们提出了一种改进的联邦平均（FedAvg）算法，将数字调制与AirComp相结合以减轻失真问题。

    In this paper, the performance optimization of federated learning (FL), when deployed over a realistic wireless multiple-input multiple-output (MIMO) communication system with digital modulation and over-the-air computation (AirComp) is studied. In particular, a MIMO system is considered in which edge devices transmit their local FL models (trained using their locally collected data) to a parameter server (PS) using beamforming to maximize the number of devices scheduled for transmission. The PS, acting as a central controller, generates a global FL model using the received local FL models and broadcasts it back to all devices. Due to the limited bandwidth in a wireless network, AirComp is adopted to enable efficient wireless data aggregation. However, fading of wireless channels can produce aggregate distortions in an AirComp-based FL scheme. To tackle this challenge, we propose a modified federated averaging (FedAvg) algorithm that combines digital modulation with AirComp to mitigate
    
[^139]: 蛋白质结构的内部坐标密度建模：协方差的重要性

    Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters. (arXiv:2302.13711v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13711](http://arxiv.org/abs/2302.13711)

    本文提出了一种新的策略，用于在内部坐标中建模蛋白质密度。通过约束来诱导内部自由度之间的协方差结构，在三维空间中满足结构约束，并通过构建一个全协方差输出的变分自编码器来验证该方法的潜力，并成功将内部坐标的密度模型扩展到完整的蛋白质骨架。

    

    在蛋白质结构预测方面取得重大突破后，蛋白质机器学习中仍面临着一个挑战：可靠地预测结构状态的分布。由于蛋白质链中自由度之间复杂的协方差结构，参数模型的拟合变得困难，通常导致模型违反局部或全局的结构约束。本文提出了一种在内部坐标中建模蛋白质密度的新策略，其中利用三维空间中的约束来诱导内部自由度之间的协方差结构。通过构建一个由三维条件均值所蕴含的约束引发的全协方差输出的变分自编码器，我们验证了该方法的潜力，并证明了我们的方法可以将内部坐标的密度模型扩展到完整的蛋白质骨架，有两种设置：1)针对展现小波动的蛋白质的单峰设置

    After the recent ground-breaking advances in protein structure prediction, one of the remaining challenges in protein machine learning is to reliably predict distributions of structural states. Parametric models of fluctuations are difficult to fit due to complex covariance structures between degrees of freedom in the protein chain, often causing models to either violate local or global structural constraints. In this paper, we present a new strategy for modelling protein densities in internal coordinates, which uses constraints in 3D space to induce covariance structure between the internal degrees of freedom. We illustrate the potential of the procedure by constructing a variational autoencoder with full covariance output induced by the constraints implied by the conditional mean in 3D, and demonstrate that our approach makes it possible to scale density models of internal coordinates to full protein backbones in two settings: 1) a unimodal setting for proteins exhibiting small fluct
    
[^140]: 癌症分子亚型分类的多模态图神经网络框架

    A Multimodal Graph Neural Network Framework of Cancer Molecular Subtype Classification. (arXiv:2302.12838v2 [q-bio.GN] UPDATED)

    [http://arxiv.org/abs/2302.12838](http://arxiv.org/abs/2302.12838)

    这项研究提出了一个多模态图神经网络框架用于癌症分子亚型分类。与现有方法相比，该框架在连接类型、GNN层和复杂分类测试方面有不同，从而取得了更好的结果。

    

    高通量测序技术的发展使得研究人员能够更好地研究癌症分子特征和基于分子亚型的癌症分类。整合多组学数据已被证明对构建更精准的分类模型非常有效。目前的多组学整合模型主要使用早期融合（串联）或者基于深度神经网络的晚期融合。由于生物系统的特性，图是生物医学数据的更好表示形式。尽管已经提出了一些基于图神经网络（GNN）的多组学整合方法，但它们存在三个常见的不足之处。一是大多数方法只使用一种类型的连接，要么是组间连接，要么是组内连接；二是它们只考虑一种类型的GNN层，要么是图卷积网络（GCN），要么是图注意力网络（GAT）；三是大多数方法缺乏更复杂的癌症分类测试。

    The recent development of high-throughput sequencing creates a large collection of multi-omics data, which enables researchers to better investigate cancer molecular profiles and cancer taxonomy based on molecular subtypes. Integrating multi-omics data has been proven to be effective for building more precise classification models. Current multi-omics integrative models mainly use early fusion by concatenation or late fusion based on deep neural networks. Due to the nature of biological systems, graphs are a better representation of bio-medical data. Although few graph neural network (GNN) based multi-omics integrative methods have been proposed, they suffer from three common disadvantages. One is most of them use only one type of connection, either inter-omics or intra-omic connection; second, they only consider one kind of GNN layer, either graph convolution network (GCN) or graph attention network (GAT); and third, most of these methods lack testing on a more complex cancer classifi
    
[^141]: 在高维贝叶斯优化中释放收购功能的潜力

    Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization. (arXiv:2302.08298v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08298](http://arxiv.org/abs/2302.08298)

    该论文考察了在高维贝叶斯优化中，收购功能最大化器初始化对利用收购功能能力的影响。研究发现随机初始化方法不能充分发挥收购功能的潜力，因此提出了一种更好的初始化方法来利用历史数据。

    

    贝叶斯优化（BO）被广泛用于优化昂贵的黑盒函数。BO首先构建一个代理模型来表示目标函数并评估其不确定性。然后，它通过最大化基于代理模型的收购函数（AF）来决定采样位置。然而，在处理高维问题时，找到AF的全局最大值变得越来越具有挑战性。在这种情况下，AF最大化器的初始化发挥了关键作用，因为不恰当的设置可能严重影响AF的有效性。本文研究了一个很大程度上未被研究的问题，即AF最大化器初始化对利用AF能力的影响。我们的大规模实证研究表明，广泛使用的随机初始化策略往往无法充分发挥AF的潜力。基于此，我们提出了一种更好的初始化方法，通过使用多个启发式优化器来利用黑盒的历史数据。

    Bayesian optimization (BO) is widely used to optimize expensive-to-evaluate black-box functions.BO first builds a surrogate model to represent the objective function and assesses its uncertainty. It then decides where to sample by maximizing an acquisition function (AF) based on the surrogate model. However, when dealing with high-dimensional problems, finding the global maximum of the AF becomes increasingly challenging. In such cases, the initialization of the AF maximizer plays a pivotal role, as an inadequate setup can severely hinder the effectiveness of the AF.  This paper investigates a largely understudied problem concerning the impact of AF maximizer initialization on exploiting AFs' capability. Our large-scale empirical study shows that the widely used random initialization strategy often fails to harness the potential of an AF. In light of this, we propose a better initialization approach by employing multiple heuristic optimizers to leverage the historical data of black-box
    
[^142]: PECAN: 一种针对后门攻击的确定性认证防御方法

    PECAN: A Deterministic Certified Defense Against Backdoor Attacks. (arXiv:2301.11824v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2301.11824](http://arxiv.org/abs/2301.11824)

    PECAN是一种有效且经过认证的后门攻击防御方法，通过在不相交分区上训练一组神经网络并应用测试时间逃避认证技术，可以显著提高防御强度和效率，降低攻击成功率。

    

    神经网络容易受到后门攻击，攻击者恶意污染训练集并在测试输入中插入触发器以改变受害模型的预测结果。现有的后门攻击防御方法要么没有提供正式的保证，要么具有计算昂贵且无效的概率保证。我们提出了一种有效且经过认证的后门攻击防御方法PECAN。PECAN的核心洞见是在数据的不相交分区上训练一组神经网络，并应用现成的测试时间逃避认证技术。我们在图像分类和恶意软件检测数据集上评估了PECAN。结果表明PECAN在防御强度和效率方面显著优于现有的经过认证的后门防御方法，并且在真实后门攻击中，与文献中的一系列基线相比，PECAN可以将攻击成功率降低一个数量级。

    Neural networks are vulnerable to backdoor poisoning attacks, where the attackers maliciously poison the training set and insert triggers into the test input to change the prediction of the victim model. Existing defenses for backdoor attacks either provide no formal guarantees or come with expensive-to-compute and ineffective probabilistic guarantees. We present PECAN, an efficient and certified approach for defending against backdoor attacks. The key insight powering PECAN is to apply off-the-shelf test-time evasion certification techniques on a set of neural networks trained on disjoint partitions of the data. We evaluate PECAN on image classification and malware detection datasets. Our results demonstrate that PECAN can (1) significantly outperform the state-of-the-art certified backdoor defense, both in defense strength and efficiency, and (2) on real back-door attacks, PECAN can reduce attack success rate by order of magnitude when compared to a range of baselines from the litera
    
[^143]: 用于约束线性逆问题的快速算法

    Fast Algorithm for Constrained Linear Inverse Problems. (arXiv:2212.01068v6 [math.OC] UPDATED)

    [http://arxiv.org/abs/2212.01068](http://arxiv.org/abs/2212.01068)

    本文提出了一种快速算法，用于解决约束线性逆问题。该算法通过将问题转化为凸优化问题或极小极大问题，并应用现有的优化方法，提供了更好的理论收敛保证。同时，本文还介绍了一种名为FLIPS的算法，该算法针对问题结构进行了优化，并展示了在多个经典问题上的性能。

    

    本文考虑约束线性逆问题 (LIP)，在二次约束条件下最小化某个原子范数（如$\ell_1$范数)。通常，这样的成本函数是不可微分的，这使得它们不适合现有的快速优化方法。我们提出了两种等效的约束LIP改进的凸正则化重述：(i)一个光滑的凸优化问题，和(ii)一个强凸的极小极大问题。这些问题可以通过应用现有的基于加速的凸优化方法来解决，这些方法提供更好的$O \left( \frac{1}{k^2} \right)$理论收敛保证，改进了当前最佳速率 $O \left( \frac{1}{k} \right)$。我们还提供了一种名为快速线性逆问题求解器（FLIPS）的新算法，该算法特别针对重述结构进行最大化利用。我们展示了FLIPS在经典的二进制选择问题、压缩感知和图像恢复问题上的性能。

    We consider the constrained Linear Inverse Problem (LIP), where a certain atomic norm (like the $\ell_1 $ norm) is minimized subject to a quadratic constraint. Typically, such cost functions are non-differentiable which makes them not amenable to the fast optimization methods existing in practice. We propose two equivalent reformulations of the constrained LIP with improved convex regularity: (i) a smooth convex minimization problem, and (ii) a strongly convex min-max problem. These problems could be solved by applying existing acceleration-based convex optimization methods which provide better $ O \left( \frac{1}{k^2} \right) $ theoretical convergence guarantee, improving upon the current best rate of $ O \left( \frac{1}{k} \right) $. We also provide a novel algorithm named the Fast Linear Inverse Problem Solver (FLIPS), which is tailored to maximally exploit the structure of the reformulations. We demonstrate the performance of FLIPS on the classical problems of Binary Selection, Com
    
[^144]: 使用集成边界逼近的对抗检测方法

    Adversarial Detection by Approximation of Ensemble Boundary. (arXiv:2211.10227v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.10227](http://arxiv.org/abs/2211.10227)

    本论文提出了一种使用Walsh系数逼近决策边界的对抗攻击检测方法，通过观察清晰图像和对抗图像之间的Walsh系数逼近差异，实现了对对抗攻击的检测。

    

    本论文提出了一种新的对抗攻击检测方法，针对解决两类模式识别问题的深度神经网络（DNN）集成。该集成使用Walsh系数进行组合，能够逼近布尔函数并控制集成决策边界的复杂性。本文的假设是高曲率的决策边界允许找到对抗扰动，但会改变决策边界的曲率，而与清晰图像相比，使用Walsh系数对其进行逼近的方式也有所不同。通过观察清晰图像和对抗图像之间的Walsh系数逼近差异，实验证明了攻击的可迁移性可用于检测。此外，逼近决策边界可能有助于理解DNN的学习和可迁移性特性。尽管本文的实验使用图像，所提出的方法可以用于建模两类模式识别问题的集成边界逼近。

    A new method of detecting adversarial attacks is proposed for an ensemble of Deep Neural Networks (DNNs) solving two-class pattern recognition problems. The ensemble is combined using Walsh coefficients which are capable of approximating Boolean functions and thereby controlling the complexity of the ensemble decision boundary. The hypothesis in this paper is that decision boundaries with high curvature allow adversarial perturbations to be found, but change the curvature of the decision boundary, which is then approximated in a different way by Walsh coefficients compared to the clean images. By observing the difference in Walsh coefficient approximation between clean and adversarial images, it is shown experimentally that transferability of attack may be used for detection. Furthermore, approximating the decision boundary may aid in understanding the learning and transferability properties of DNNs. While the experiments here use images, the proposed approach of modelling two-class en
    
[^145]: 一种混合类别相关核的高斯过程

    A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.08262](http://arxiv.org/abs/2211.08262)

    提出一种新的混合类别相关核的高斯过程代理，相较于其他现有模型在分析和工程问题上表现更好。

    

    近年来，基于高斯过程代理的混合类别元模型引起了越来越多的关注。在这种情况下，一些现有的方法使用不同的策略，通过使用连续核（例如，连续松弛和Gower距离基于高斯过程）或通过直接估计相关矩阵。在本文中，我们提出了一种基于核的方法，将连续指数核扩展为处理混合类别变量。所提出的核引导到了一个新的高斯代理，它概括了连续松弛和Gower距离基于高斯过程模型。我们在分析和工程问题上证明了，我们的提出的高斯过程模型比其他基于核的现有模型具有更高的可能性和更小的残差误差。我们的方法可使用开源软件SMT。

    Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
    
[^146]: 风险意识的线性赌博机：理论和在智能订单路由中的应用

    Risk-Aware Linear Bandits: Theory and Applications in Smart Order Routing. (arXiv:2208.02389v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.02389](http://arxiv.org/abs/2208.02389)

    本论文研究了风险意识线性赌博机在智能订单路由中的应用，并提出了两种算法来最小化遗憾。分析表明，这些算法在近乎最优的情况下能够通过利用线性结构来提高性能。

    

    受金融决策中机器学习的实际考虑（如风险厌恶和大型操作空间）的驱动，我们考虑了具有智能订单路由（SOR）应用的风险意识赌博机优化。具体来说，基于从纳斯达克ITCH数据集中对线性价格影响的初步观察，我们开展了风险意识线性赌博机的研究。在这种设置中，我们旨在在面对一组（最初）未知参数的线性函数作为奖励的行动时，通过使用均值方差度量来最小化遗憾，该度量反映了我们的表现与最优解之间的差距。基于方差最小化的全局最优（G-最优）设计，我们提出了独立于实例的全新的风险意识探索-承诺（RISE）算法和依赖于实例的风险意识连续淘汰（RISE++）算法。然后，我们通过严格分析它们近乎最优的遗憾上界，展示了通过利用线性结构，我们的算法的性能。

    Motivated by practical considerations in machine learning for financial decision-making, such as risk aversion and large action space, we consider risk-aware bandits optimization with applications in smart order routing (SOR). Specifically, based on preliminary observations of linear price impacts made from the NASDAQ ITCH dataset, we initiate the study of risk-aware linear bandits. In this setting, we aim at minimizing regret, which measures our performance deficit compared to the optimum's, under the mean-variance metric when facing a set of actions whose rewards are linear functions of (initially) unknown parameters. Driven by the variance-minimizing globally-optimal (G-optimal) design, we propose the novel instance-independent Risk-Aware Explore-then-Commit (RISE) algorithm and the instance-dependent Risk-Aware Successive Elimination (RISE++) algorithm. Then, we rigorously analyze their near-optimal regret upper bounds to show that, by leveraging the linear structure, our algorithm
    
[^147]: TE2Rules: 使用规则解释树集合模型

    TE2Rules: Explaining Tree Ensembles using Rules. (arXiv:2206.14359v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14359](http://arxiv.org/abs/2206.14359)

    本文介绍了一种将二元分类任务中的树集合模型转换为可解释规则列表的方法，该方法可以有效解释模型对于少数类别的预测。实验证明，TE2Rules方法生成的规则列表准确性较高，并且运行时间与其他基线方法相当。

    

    树集合（如梯度提升树）通常相比单棵决策树具有更高的预测性能，然而，树集合模型通常缺乏透明度和可解释性，因为人类难以理解它们的决策逻辑。本文提出一种新颖的方法，将用于二元分类任务的树集合模型转换为接近树集合的可解释规则列表，并且有效地解释模型对于模型预测的少数类别。在基准数据集上的实验表明，TE2Rules生成的规则列表相对于现有方法具有更高的准确性，TE2Rules的运行时间与其他类似基线方法相当，TE2Rules算法的运行时间可以以稍微降低的准确性为代价进行权衡。

    Tree Ensemble (TE) models (like Gradient Boosted Trees) often provide higher prediction performance compared to single decision trees. However, TE models generally lack transparency and interpretability, as humans have difficulty understanding their decision logic. This paper presents a novel approach to convert a TE trained for a binary classification task, to a rule list (RL) that closely approximates the TE and is interpretable for a human. This RL can effectively explain the model even on the minority class predicted by the model. Experiments on benchmark datasets demonstrate that, (i) predictions from the RL generated by TE2Rules have higher fidelity (with respect to the original TE) compared to state-of-the-art methods, (ii) the run-time of TE2Rules is comparable to that of some other similar baselines and (iii) the run-time of TE2Rules algorithm can be traded off at the cost of a slightly lower fidelity.
    
[^148]: 快速策略转移的相对策略过渡优化

    Relative Policy-Transition Optimization for Fast Policy Transfer. (arXiv:2206.06009v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.06009](http://arxiv.org/abs/2206.06009)

    本论文介绍了相对策略过渡优化的方法，通过引入一个基于强化学习的引理衡量两个MDP之间的相对差距，并提出了相对策略优化和相对转移优化两个算法来实现快速策略转移和动态建模。同时，将这两个算法集成在一起形成完整的相对策略过渡优化算法。

    

    本文考虑了在两个马尔可夫决策过程之间的策略转移问题。我们引入了一个基于强化学习中现有理论结果的引理，用于衡量任意两个MDP之间的相对差距，即不同策略和环境动态下累积预期回报的差异。基于该引理，我们提出了两个新算法，分别为相对策略优化（RPO）和相对转移优化（RTO），分别提供了快速策略转移和动态建模。RPO通过将在一个环境中评估的策略转移以最大化在另一个环境中的回报，而RTO则通过更新参数化的动态模型来减小两个环境动态之间的差距。将这两个算法集成在一起可以得到完整的相对策略过渡优化（RPTO）算法，其中策略同时与两个环境进行交互，从而从两个环境中收集数据。

    We consider the problem of policy transfer between two Markov Decision Processes (MDPs). We introduce a lemma based on existing theoretical results in reinforcement learning to measure the relativity gap between two arbitrary MDPs, that is the difference between any two cumulative expected returns defined on different policies and environment dynamics. Based on this lemma, we propose two new algorithms referred to as Relative Policy Optimization (RPO) and Relative Transition Optimization (RTO), which offer fast policy transfer and dynamics modelling, respectively. RPO transfers the policy evaluated in one environment to maximize the return in another, while RTO updates the parameterized dynamics model to reduce the gap between the dynamics of the two environments. Integrating the two algorithms results in the complete Relative Policy-Transition Optimization (RPTO) algorithm, in which the policy interacts with the two environments simultaneously, such that data collections from two envi
    
[^149]: 多模式的虚假信息检测：方法、挑战与机遇

    Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities. (arXiv:2203.13883v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.13883](http://arxiv.org/abs/2203.13883)

    这项研究总结了多模式虚假信息检测的方法、挑战和机遇。由于社交媒体平台的转变，虚假信息的性质也发生了变化。研究人员已经开发出自动检测跨模态不协调的技术，但仍面临挑战和不足之处，进一步的研究机会也在等待着挖掘。

    

    随着社交媒体平台从文本为主的论坛转向多模式环境，社交媒体中的虚假信息的性质也相应发生了变化。利用图像和视频等视觉模态更受用户青睐和吸引力的事实，以及文本内容有时被粗略浏览的情况，虚假信息传播者最近开始针对模态之间的上下文连接，例如文本和图像之间的关系。因此，许多研究人员已经开发出自动检测网页内容中可能存在的跨模态不协调的技术。我们分析、分类和识别现有的方法，以及它们面临的挑战和不足之处，以揭示多模式虚假信息检测领域的新研究机会。

    As social media platforms are evolving from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Taking advantage of the fact that visual modalities such as images and videos are more favorable and attractive to the users and textual contents are sometimes skimmed carelessly, misinformation spreaders have recently targeted contextual connections between the modalities e.g., text and image. Hence many researchers have developed automatic techniques for detecting possible cross-modal discordance in web-based content. We analyze, categorize and identify existing approaches in addition to challenges and shortcomings they face in order to unearth new research opportunities in the field of multi-modal misinformation detection.
    
[^150]: 分散个性化联邦学习用于极值问题

    Decentralized Personalized Federated Learning for Min-Max Problems. (arXiv:2106.07289v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.07289](http://arxiv.org/abs/2106.07289)

    该论文首次研究了个性化联邦学习在鞍点问题上的应用，提出了分散的设置，并通过提出新算法解决了这一问题。

    

    个性化联邦学习（PFL）已经取得了显著的进展，实现了保护训练数据隐私的创新机器学习应用的发展。然而，现有的理论研究主要集中在极小化问题的分布式优化上。本文首次研究了PFL应用于鞍点问题，这种问题涵盖了更广泛的优化问题，需要解决的不仅仅是极小化问题。在这项工作中，我们考虑了最近提出的PFL设置，其中包括混合目标函数的方法，即全局模型学习与本地分布式学习器相结合。与大多数先前的工作只考虑集中式设置不同，我们在一个更一般和分散的设置中工作，这使我们能够设计和分析更实用和联邦化的设备连接方式。我们提出了新的算法来解决这个问题，并提供了理论分析。

    Personalized Federated Learning (PFL) has witnessed remarkable advancements, enabling the development of innovative machine learning applications that preserve the privacy of training data. However, existing theoretical research in this field has primarily focused on distributed optimization for minimization problems. This paper is the first to study PFL for saddle point problems encompassing a broader range of optimization problems, that require more than just solving minimization problems. In this work, we consider a recently proposed PFL setting with the mixing objective function, an approach combining the learning of a global model together with locally distributed learners. Unlike most previous work, which considered only the centralized setting, we work in a more general and decentralized setup that allows us to design and analyze more practical and federated ways to connect devices to the network. We proposed new algorithms to address this problem and provide a theoretical analy
    
[^151]: MNL-带有背包的剧集挑选问题：一种近似最优算法

    MNL-Bandit with Knapsacks: a near-optimal algorithm. (arXiv:2106.01135v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.01135](http://arxiv.org/abs/2106.01135)

    这篇论文介绍了一种解决动态商品选择问题的算法，通过使用近似最优策略，可在未知需求情况下最大化总体预期收入。在大库存环境下，该算法能够接近最优解。

    

    我们考虑一种动态的商品选择问题，其中卖方拥有固定库存的N种可替代产品，并面临在T个时期内顺序到达的未知需求。在每个时期，卖方需要决定要向客户提供的产品组合（基数最多为K）。顾客的反应遵循具有参数v的未知多项式对数模型（MNL）。卖方的目标是在给定固定初始库存的情况下最大化总体预期收入。我们给出了一种策略，达到了$\tilde O\Big(K \sqrt{KN T}\Big(\sqrt{v_{\text{max}}} + \frac{1}{q_{\text{min}}}\text{OPT}\Big)\Big)$的遗憾值，在模型参数的一种温和假设下。特别地，我们的策略在高库存环境下达到了接近最优的$\tilde O(\sqrt{T})$遗憾值。我们的策略基于基于UCB的方法。

    We consider a dynamic assortment selection problem where a seller has a fixed inventory of $N$ substitutable products and faces an unknown demand that arrives sequentially over $T$ periods. In each period, the seller needs to decide on the assortment of products (of cardinality at most $K$) to offer to the customers. The customer's response follows an unknown multinomial logit model (MNL) with parameters $v$. The goal of the seller is to maximize the total expected revenue given the fixed initial inventory of $N$ products. We give a policy that achieves a regret of $\tilde O\Big(K \sqrt{KN T}\Big(\sqrt{v_{\text{max}}} + \frac{1}{q_{\text{min}}}\text{OPT}\Big)\Big)$, where $v_{\text{max}}\leq 1$ is the maximum utility for any product and $q_{\text{min}}$ the minimum inventory level, under a mild assumption on the model parameters. In particular, our policy achieves a near-optimal $\tilde O(\sqrt{T})$ regret in a large-inventory setting.  Our policy builds upon the UCB-based approach for
    
[^152]: MMD正则化的非平衡最优输运问题

    MMD-regularized Unbalanced Optimal Transport. (arXiv:2011.05001v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.05001](http://arxiv.org/abs/2011.05001)

    本文研究了使用MMD正则化的非平衡最优输运问题，提出了基于Fenchel对偶性的新度量方法，还提出了基于有限样本的凸规划用于估算问题，证明了估计量的一致性和误差速率。

    

    本文研究了非平衡最优输运（UOT）问题，其中使用最大平均偏差（MMD）正则化来实现边际约束。我们的研究动机在于观察到，现有的UOT研究主要关注基于$\phi$-散度（例如KL）的正则化。MMD作为互补的积分概率度量（IPM）家族之一，在UOT上的作用似乎不太被理解。我们的主要结果基于Fenchel对偶性，利用它我们能够研究MMD正则化的UOT（MMD-UOT）的特性。这种对偶结果的一个有趣结果是MMD-UOT诱导了一种新的度量方法，也属于IPM家族。此外，我们提出了基于有限样本的凸规划，用于估算MMD-UOT和相应的重心。在温和的条件下，我们证明了我们基于凸规划的估计量是一致的，而且估计误差以$\mathcal{O}(m^{-1/2})$的速率衰减。

    We study the unbalanced optimal transport (UOT) problem, where the marginal constraints are enforced using Maximum Mean Discrepancy (MMD) regularization. Our study is motivated by the observation that existing works on UOT have mainly focused on regularization based on $\phi$-divergence (e.g., KL). The role of MMD, which belongs to the complementary family of integral probability metrics (IPMs), as a regularizer in the context of UOT seems to be less understood. Our main result is based on Fenchel duality, using which we are able to study the properties of MMD-regularized UOT (MMD-UOT). One interesting outcome of this duality result is that MMD-UOT induces a novel metric over measures, which again belongs to the IPM family. Further, we present finite-sample-based convex programs for estimating MMD-UOT and the corresponding barycenter. Under mild conditions, we prove that our convex-program-based estimators are consistent, and the estimation error decays at a rate $\mathcal{O}\left(m^{-
    
[^153]: 线性递归神经网络的力量

    The Power of Linear Recurrent Neural Networks. (arXiv:1802.03308v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1802.03308](http://arxiv.org/abs/1802.03308)

    本研究展示了线性递归神经网络(LRNNs)可以逼近任何时变函数f(t)。通过检查网络转移矩阵的主要特征值，可以显著降低LRNN的规模。LRNNs具有以椭圆轨迹结束的有趣特性，并允许预测进一步的值和函数的紧凑表示。

    

    循环神经网络是处理时间序列的有力工具。我们展示了autoregressive linear,即线性激活循环神经网络(LRNNs)可以逼近由多个函数值给出的任何时变函数f(t)。逼近可以通过简单地解决一个线性方程组来有效学习；不需要反向传播或类似的方法。此外，这可能是本文的主要贡献，通过检查网络转移矩阵的频谱，即它的特征值，只取最相关的组件，可以在一步中显著降低LRNN的规模。因此，与其他方法不同，我们不仅可以学习网络权重，还可以学习网络架构。LRNNs具有有趣的特性：它们最终会以椭圆轨迹结束，并允许预测进一步的值和函数的紧凑表示。我们通过几个实验演示了这一点。

    Recurrent neural networks are a powerful means to cope with time series. We show how autoregressive linear, i.e., linearly activated recurrent neural networks (LRNNs) can approximate any time-dependent function f(t) given by a number of function values. The approximation can effectively be learned by simply solving a linear equation system; no backpropagation or similar methods are needed. Furthermore, and this is probably the main contribution of this article, the size of an LRNN can be reduced significantly in one step after inspecting the spectrum of the network transition matrix, i.e., its eigenvalues, by taking only the most relevant components. Therefore, in contrast to other approaches, we do not only learn network weights but also the network architecture. LRNNs have interesting properties: They end up in ellipse trajectories in the long run and allow the prediction of further values and compact representations of functions. We demonstrate this by several experiments, among the
    

