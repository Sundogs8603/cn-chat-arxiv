# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TEDDY: Trimming Edges with Degree-based Discrimination strategY](https://rss.arxiv.org/abs/2402.01261) | TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。 |
| [^2] | [Strong and Controllable Blind Image Decomposition](https://arxiv.org/abs/2403.10520) | 该论文提出了一种具有可控性的盲图像分解方法，允许用户选择移除或保留特定类型的降解，实现了在 minimal computational cost的情况下对输入图像进行部分或完全恢复 |
| [^3] | [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://arxiv.org/abs/2403.10516) | FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。 |
| [^4] | [HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation](https://arxiv.org/abs/2403.10506) | 提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。 |
| [^5] | [Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study](https://arxiv.org/abs/2403.10499) | 本研究通过对多模态基础模型CLIP进行大规模鲁棒性基准测试，揭示了其在涵盖自然分布偏移、合成分布偏移和对抗攻击等多个方面的优异表现。 |
| [^6] | [Data-Driven Distributionally Robust Safety Verification Using Barrier Certificates and Conditional Mean Embeddings](https://arxiv.org/abs/2403.10497) | 本研究采用屏障证明概念，并直接从系统轨迹集中学习证明，开发了可扩展的形式验证算法。 |
| [^7] | [Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild](https://arxiv.org/abs/2403.10488) | 该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。 |
| [^8] | [Approximate Nullspace Augmented Finetuning for Robust Vision Transformers](https://arxiv.org/abs/2403.10476) | 本研究提出了一种启发自线性代数零空间概念的视觉变换器鲁棒性增强微调方法，通过合成近似零空间元素来提高模型的鲁棒性。 |
| [^9] | [Introducing Adaptive Continuous Adversarial Training (ACAT) to Enhance ML Robustness](https://arxiv.org/abs/2403.10461) | 引入了自适应连续对抗训练（ACAT）来持续集成对抗训练样本到模型中，使用实际检测到的对抗数据，增强模型对不断演变的对抗威胁的抵抗能力。 |
| [^10] | [Understanding the Double Descent Phenomenon in Deep Learning](https://arxiv.org/abs/2403.10459) | 在现代深度学习中，庞大的过参数化模型通过增加模型复杂度来降低测试误差，这就是双下降现象。 |
| [^11] | [Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases](https://arxiv.org/abs/2403.10446) | 利用RAG系统增强LLMs，提高其对私人知识库中特定领域和时效查询的事实准确性，尤其在使用外部数据集方面表现出潜力。 |
| [^12] | [Optimal Block-Level Draft Verification for Accelerating Speculative Decoding](https://arxiv.org/abs/2403.10444) | 提出了一种更好的草稿验证算法，通过将验证步骤制定为块级最优传输问题，实现了额外的墙钟速度提升，而不增加额外的计算成本和草稿标记 |
| [^13] | [Structured Evaluation of Synthetic Tabular Data](https://arxiv.org/abs/2403.10424) | 提出了一个具有单一数学目标的评估框架，用于确定合成数据应该从与观测数据相同的分布中提取，并且推理了任何一组指标的完整性，统一了现有的指标，并鼓励新的模型无关基线和指标。 |
| [^14] | [Quantization Avoids Saddle Points in Distributed Optimization](https://arxiv.org/abs/2403.10423) | 量化方法在分布式非凸优化中能够避免收敛到鞍点，确保收敛到二阶稳定点。 |
| [^15] | [Robust Sparse Estimation for Gaussians with Optimal Error under Huber Contamination](https://arxiv.org/abs/2403.10416) | 我们提出了在Huber污染模型下进行高斯稀疏估计任务的鲁棒估计器，为均值估计、主成分分析和线性回归提供了具有最优误差保证的高效算法，同时引入了一种新颖的多维滤波方法。 |
| [^16] | [SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores](https://arxiv.org/abs/2403.10408) | SocialGenPod提出了一种隐私友好的生成式AI社交网络应用部署方式，通过使用分布式的Solid规范来解耦用户数据与应用程序，实现用户在个人Pod中安全存储所有数据的控制。 |
| [^17] | [A comparative study on machine learning approaches for rock mass classification using drilling data](https://arxiv.org/abs/2403.10404) | 该研究利用大规模和地质多样性的钻孔数据集，引入了模型用于准确地在实际隧道施工环境中对岩体质量进行分类，提供关键的决策支持。 |
| [^18] | [Energy Correction Model in the Feature Space for Out-of-Distribution Detection](https://arxiv.org/abs/2403.10403) | 通过在特征空间中学习内部分布特征密度的能量校正模型，本文提出了一种在异常检测中取得竞争性结果的方法 |
| [^19] | [Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding](https://arxiv.org/abs/2403.10395) | Isotropic3D是一个图像到3D生成的新方法，通过仅使用图像CLIP嵌入作为输入，让优化相对于方位角是各向同性，避免过分依赖图像导致生成的扁平或扭曲。 |
| [^20] | [Regret Minimization via Saddle Point Optimization](https://arxiv.org/abs/2403.10379) | 通过重新参数化DEC并求解相应的极小-极大程序，提出了Estimation-To-Decisions（E2D）算法的任何时候变体，成功将在线优化探索-利用权衡转化为实用算法。 |
| [^21] | [Towards a general framework for improving the performance of classifiers using XAI methods](https://arxiv.org/abs/2403.10373) | 本文提出了一个通用框架，利用XAI方法自动改善预先训练的深度学习分类器的性能，避免了重新训练复杂模型的计算开销。 |
| [^22] | [An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications](https://arxiv.org/abs/2403.10371) | 提出了一种用于缓解物联网应用中数据不完整性的节能集成方法ENAMLE，旨在解决SECOE的能源瓶颈问题 |
| [^23] | [Conformal Predictions for Probabilistically Robust Scalable Machine Learning Classification](https://arxiv.org/abs/2403.10368) | 通过引入得分函数和定义适应性安全集，将可扩展分类器和适应性预测相结合，定义了一种可靠的学习框架，能够在设计初期就为分类提供稳健的算法。 |
| [^24] | [Scalable Algorithms for Individual Preference Stable Clustering](https://arxiv.org/abs/2403.10365) | 研究了个人偏好稳定聚类的可扩展算法，通过局部搜索获得了 $O(\log n)$-IP 稳定性保证，并且在几乎线性时间内运行。 |
| [^25] | [Denoising Task Difficulty-based Curriculum for Training Diffusion Models](https://arxiv.org/abs/2403.10348) | 研究通过全面研究任务难度，发现较早时间步长的去噪任务更具挑战性，提出了基于去噪任务难度的渐进式课程训练方法。 |
| [^26] | [Generation is better than Modification: Combating High Class Homophily Variance in Graph Anomaly Detection](https://arxiv.org/abs/2403.10339) | 首次引入类同质性方差这一新度量，在图异常检测中提出了Homophily Edge Generation Graph Neural Network (HedGe)模型，强调生成新关系以降低类同质性方差。 |
| [^27] | [GreedyML: A Parallel Algorithm for Maximizing Submodular Functions](https://arxiv.org/abs/2403.10332) | 提出了一种用于在分布式存储多处理器上最大化子模函数的并行近似算法，以解决实际应用领域中海量数据集上的子模优化问题。 |
| [^28] | [Towards Non-Adversarial Algorithmic Recourse](https://arxiv.org/abs/2403.10330) | 在高风险情况下，重要性获得不具有对抗性特征的反事实解释。 |
| [^29] | [CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model](https://arxiv.org/abs/2403.10326) | 本文研究了通过应用预训练语言模型作为候选干扰项生成的替代方法来自动生成填空干扰项，并展示了这种PLM增强模型显著提高了性能。 |
| [^30] | [Anytime Neural Architecture Search on Tabular Data](https://arxiv.org/abs/2403.10318) | ATLAS是第一个专为表格数据设计的任意时间神经网络架构搜索方法，引入了过滤和优化方案，结合了训练-free和基于训练的架构评估两种范式的优势 |
| [^31] | [Rough Transformers for Continuous and Efficient Time-Series Modelling](https://arxiv.org/abs/2403.10288) | 提出了粗糙Transformer，用于在连续时间表示的输入序列上进行操作，大大降低了计算成本，对于处理医疗情境中的长程依赖性至关重要。 |
| [^32] | [Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning](https://arxiv.org/abs/2403.10281) | Team Trifecta在Factify 5WQA上以Fine-Tuning取得了首要地位，成功超越基准准确率103％，并保持了对第二名竞争者的70%领先优势。 |
| [^33] | [DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers](https://arxiv.org/abs/2403.10266) | 动态序列并行性（DSP）为多维Transformer模型引入了一种高效的序列并行方法，通过动态切换并行维度实现对多维注意力模型的优化。 |
| [^34] | [Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model](https://arxiv.org/abs/2403.10259) | 该研究探讨利用分类模型和LSTM模型在工业中进行预测性维护的方法，通过人工智能技术实现对机器故障更准确和高效的预测和分析。 |
| [^35] | [Open Continual Feature Selection via Granular-Ball Knowledge Transfer](https://arxiv.org/abs/2403.10253) | 提出了一种开放环境下的持续特征选择方法，结合持续学习和粒球计算技术，以检测未知类别并促进先前学习到的知识转移。 |
| [^36] | [Interpretable Machine Learning for Survival Analysis](https://arxiv.org/abs/2403.10250) | 可解释的机器学习在生存分析中的应用促进了透明度和公平性，揭示了模型的潜在偏见和限制，并提供了更符合数学原理的特征影响和风险因素预测方法。 |
| [^37] | [Matrix Completion via Nonsmooth Regularization of Fully Connected Neural Networks](https://arxiv.org/abs/2403.10232) | 通过对全连接神经网络进行非光滑正则化，可以控制过拟合问题，提高矩阵补全性能。 |
| [^38] | [Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs](https://arxiv.org/abs/2403.10231) | 提出了一种在大规模知识图谱上进行高效和自适应预测的一次性子图链接预测方法，通过将预测过程分解为从查询中提取一个子图并在该单个、查询相关子图上进行预测的两个步骤，利用非参数化和计算高效的启发式方法来提高效率。 |
| [^39] | [From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations](https://arxiv.org/abs/2403.10220) | 提出了AERO，一个专为天文观测中无监督异常检测量身定制的新颖两阶段框架，擅长处理天文观测中独立但受到随机并发噪声干扰的特征。 |
| [^40] | [Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes](https://arxiv.org/abs/2403.10202) | 在这篇论文中，提出了一种在JPEG-LDPC压缩图像上进行分类的方法，通过利用LDPC码的内部代码结构，使用GRU进行训练，从而实现了高效的图像分类。 |
| [^41] | [Perceptual Quality-based Model Training under Annotator Label Uncertainty](https://arxiv.org/abs/2403.10190) | 标注者标签不确定性影响模型泛化能力和预测不确定性，现有不确定性估计算法无法应对，提出一种基于感知质量的训练方法以缓解性能下降 |
| [^42] | [Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects](https://arxiv.org/abs/2403.10187) | 提出了一种新颖的两阶段学习框架TAPG，将强化学习和策略蒸馏相结合，在抓取任意物体时取得了良好表现。 |
| [^43] | [Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification](https://arxiv.org/abs/2403.10182) | 研究在工业零部件分类中探讨了利用更便宜的神经网络集成实现可靠的不确定性估计的方法 |
| [^44] | [A Short Survey on Importance Weighting for Machine Learning](https://arxiv.org/abs/2403.10175) | 重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质 |
| [^45] | [Explainability through uncertainty: Trustworthy decision-making with neural networks](https://arxiv.org/abs/2403.10168) | 本文提出了一个通用的不确定性框架，将机器学习模型中的不确定性估计定位为XAI技术，并提供了解释输出结果时是否应该信任的方法。 |
| [^46] | [CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis](https://arxiv.org/abs/2403.10164) | CoReEcho提出了针对直接EF回归的连续表示学习框架，在最大的超声心动图数据集上表现优越。 |
| [^47] | [Online Policy Learning from Offline Preferences](https://arxiv.org/abs/2403.10160) | 引入了一个框架，将离线偏好和虚拟偏好结合起来用于基于偏好的强化学习，以解决在线学习中奖励函数泛化性问题。 |
| [^48] | [Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights](https://arxiv.org/abs/2403.10158) | 该论文提出了一个新颖的函数图卷积网络框架，结合了函数数据分析和图卷积网络，解决了数字健康和纵向研究中的多任务和多模态学习复杂性，关键创新包括任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图进行数据解释。 |
| [^49] | [Improving Medical Multi-modal Contrastive Learning with Expert Annotations](https://arxiv.org/abs/2403.10153) | eCLIP是一种改进的CLIP模型，通过集成专家注释和混合增强来应对医学影像分析中的数据稀缺和模态差距挑战，提高了模型学习效果 |
| [^50] | [NLP Verification: Towards a General Methodology for Certifying Robustness](https://arxiv.org/abs/2403.10144) | 本文尝试总结和评估由该领域迄今进展而形成的NLP验证流程的一般组成部分，贡献在于提出了将句子嵌入连续空间得到的可验证子空间的一般描述。 |
| [^51] | [Regularization-Based Efficient Continual Learning in Deep State-Space Models](https://arxiv.org/abs/2403.10123) | 提出了一种正则化驱动的深度状态空间模型，实现了高效的持续学习，能够在多个动态系统建模时进行有效更新，并且通过实验证实了其有效性 |
| [^52] | [Meta Operator for Complex Query Answering on Knowledge Graphs](https://arxiv.org/abs/2403.10110) | 本研究提出了一种元学习算法，用于在知识图谱上回答复杂查询，通过学习元算子并将其适应于各种复杂查询，实现了泛化性能的提升。 |
| [^53] | [Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots](https://arxiv.org/abs/2403.10105) | 使用BNBRL+算法，结合部分可观察马尔可夫决策过程和贝叶斯神经网络，实现了在不可观察区域评估风险和制定移动策略的目的，并通过整合动态关系和社会规范，实现了社交感知导航。 |
| [^54] | [Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks](https://arxiv.org/abs/2403.10097) | 提出了一种名为AdaRand的简单方法，在微调深度神经网络时可以自适应地改变特征向量分布，从而提高性能而不需要辅助源信息。 |
| [^55] | [Approximation and bounding techniques for the Fisher-Rao distances](https://arxiv.org/abs/2403.10089) | 本文考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术，包括基于闭合形式1D子模型Fisher-Rao距离的通用上界以及取决于测地线或预测测地线是否闭合形式获得的几种通用近似方案，并提出了一种通用方法保证近似误差任意小。 |
| [^56] | [A survey of synthetic data augmentation methods in computer vision](https://arxiv.org/abs/2403.10075) | 该论文调查了计算机视觉中合成数据增强方法，涵盖了基于逼真3D图形建模、神经风格转移、差分神经渲染和生成的数据合成方法。 |
| [^57] | [A Structure-Preserving Kernel Method for Learning Hamiltonian Systems](https://arxiv.org/abs/2403.10070) | 提出了一种保结构的核岭回归方法，可以从噪声观测数据中恢复哈密顿函数，拓展了核回归方法，并具有出色的数值性能和收敛速度。 |
| [^58] | [Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization](https://arxiv.org/abs/2403.10063) | 本文提出了统一的无投影Frank-Wolfe类型算法，用于对抗性DR-次模优化，在不同场景下取得了令人瞩目的次线性 $\alpha$-后悔上界，并在单调设置中实现了无投影算法的最新次线性 $\alpha$-后悔上界。 |
| [^59] | [Towards Adversarially Robust Dataset Distillation by Curvature Regularization](https://arxiv.org/abs/2403.10045) | 本文探讨了如何通过曲率正则化方法在精炼数据集中嵌入对抗鲁棒性，以保持模型高准确性并获得更好的对抗鲁棒性。 |
| [^60] | [Accurate and Data-Efficient Micro-XRD Phase Identification Using Multi-Task Learning: Application to Hydrothermal Fluids](https://arxiv.org/abs/2403.10042) | 深度学习与多任务学习结合在微型X射线衍射相位识别中取得突破，模型训练减少了实验数据标记和预处理步骤，性能优于传统CNN分类器。 |
| [^61] | [MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage](https://arxiv.org/abs/2403.10024) | 提出了MR-MT3模型来减少乐器泄漏问题，采用了存储保留机制、先前令牌采样和令牌混洗等增强方法，在Slakh2100数据集上展示了改进的效果。 |
| [^62] | [Linear optimal transport subspaces for point set classification](https://arxiv.org/abs/2403.10015) | 提出了一种用于点集分类的线性最优输运子空间框架，通过线性嵌入集合结构数据，展示了其在处理空间变形中的能力，以简化点集分类问题。 |
| [^63] | [LyZNet: A Lightweight Python Tool for Learning and Verifying Neural Lyapunov Functions and Regions of Attraction](https://arxiv.org/abs/2403.10013) | LyZNet是一个轻量级Python工具，利用物理信息神经网络学习神经李亚普诺夫函数，并通过SMT求解器验证，能够提供验证范围接近吸引力域的特点 |
| [^64] | [Graph Enhanced Reinforcement Learning for Effective Group Formation in Collaborative Problem Solving](https://arxiv.org/abs/2403.10006) | 通过图论和强化学习，在协作问题解决中形成有效群组，并提供潜在改进和冲突减少的见解 |
| [^65] | [AD3: Implicit Action is the Key for World Models to Distinguish the Diverse Visual Distractors](https://arxiv.org/abs/2403.09976) | 提出了一种名为AD3的算法，通过隐式动作生成器(IAG)学习视觉干扰因素的隐式动作，实现了在区分任务不相关组件上的卓越性能。 |
| [^66] | [GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery](https://arxiv.org/abs/2403.09974) | 本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。 |
| [^67] | [Prediction of Vessel Arrival Time to Pilotage Area Using Multi-Data Fusion and Deep Learning](https://arxiv.org/abs/2403.09969) | 使用MKDE和聚类提取船舶到达轮廓，融合多数据源，并采用TCN框架学习隐藏到达模式，有效提高了船舶到引航区的到达时间预测准确性。 |
| [^68] | [Thermal Earth Model for the Conterminous United States Using an Interpolative Physics-Informed Graph Neural Network (InterPIGNN)](https://arxiv.org/abs/2403.09961) | 利用插值物理信息图神经网络，本研究开发出一种基于数据驱动的空间插值算法，构建了美国本土温度-深度地图，同时精确预测地下温度、地表热流和岩石导热率。 |
| [^69] | [Online GNN Evaluation Under Test-time Graph Distribution Shifts](https://arxiv.org/abs/2403.09953) | 在线GNN评估研究了如何在测试时间图分布转移的情况下，衡量经过充分训练的GNN模型对真实世界无标签图的泛化能力。 |
| [^70] | [Attention-Enhanced Hybrid Feature Aggregation Network for 3D Brain Tumor Segmentation](https://arxiv.org/abs/2403.09942) | 在医疗保健中，利用增强注意力的混合特征聚合网络GLIMS进行3D脑肿瘤分割，使用多尺度特征提取和Swin Transformer块改善了全局特征聚合。 |
| [^71] | [Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries](https://arxiv.org/abs/2403.09940) | 该方法提出了一种基于策略梯度的联邦学习方法，可以在存在对手代理的情况下实现全局收敛保证，并具有对对手的鲁棒性。 |
| [^72] | [Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics](https://arxiv.org/abs/2403.09930) | QDAC是一种基于离策略演员-评论家深度强化学习算法，通过价值函数评论家和继承特征评论家学习高性能和多样性行为。 |
| [^73] | [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](https://arxiv.org/abs/2403.09919) | 本文介绍了一种适用于大型语言模型的循环草稿机制，结合了经典双模型和最新单模型方法，通过运用循环依赖设计，实现了高效的推测解码。 |
| [^74] | [Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptive Object Detection](https://arxiv.org/abs/2403.09918) | 提出了一种基于注意力的类别条件对齐方案，用于多源领域自适应目标检测，在跨领域对齐每个对象类别的实例。 |
| [^75] | [FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models](https://arxiv.org/abs/2403.09904) | FedComLoc利用Scaffnew算法的基础，引入了压缩和本地训练，显著降低了分布式训练中的通信开销。 |
| [^76] | [Robust Subgraph Learning by Monitoring Early Training Representations](https://arxiv.org/abs/2403.09901) | 本文引入了一种名为SHERD的新技术，通过监控图神经网络(GNNs)早期训练表示中的信息，利用标准距离度量检测易受攻击节点，从而在图输入中实现性能和对抗鲁棒性。 |
| [^77] | [TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting](https://arxiv.org/abs/2403.09898) | TimeMachine是一种创新模型，利用Mamba捕捉多变量时间序列数据中的长期依赖关系，同时保持线性可扩展性和较小的内存占用，通过全面验证，表现出优越的预测、可扩展性和内存效率。 |
| [^78] | [Fisher Mask Nodes for Language Model Merging](https://arxiv.org/abs/2403.09891) | 介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。 |
| [^79] | [Generalization of Scaled Deep ResNets in the Mean-Field Regime](https://arxiv.org/abs/2403.09889) | 本研究通过研究在无限深和宽神经网络的极限下的缩放ResNet，推导出了在均场极限中泛化界限的全局下界和Kullback-Leibler散度的动态跟踪，为深度ResNet的泛化性质提供了新的认识。 |
| [^80] | [ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image](https://arxiv.org/abs/2403.09871) | ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。 |
| [^81] | [Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors](https://arxiv.org/abs/2403.09869) | 开发了一族组感知先验分布，可以改进神经网络模型在数据分布的亚群体偏移下的泛化能力，并展示了即使只重新训练非鲁棒模型的最后一层，使用这种先验进行训练也能获得最先进的性能。 |
| [^82] | [iBRF: Improved Balanced Random Forest Classifier](https://arxiv.org/abs/2403.09867) | 该研究提出了一种对平衡随机森林分类器的修改，以增强预测性能。 |
| [^83] | [A Conceptual Framework For White Box Neural Networks](https://arxiv.org/abs/2403.09863) | 引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。 |
| [^84] | [MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning](https://arxiv.org/abs/2403.09859) | MAMBA提出了一种新的基于模型的元强化学习方法，能够在常见的基准测试领域上实现更大的回报和更好的样本效率，同时只需很少的超参数调整。 |
| [^85] | [Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt](https://arxiv.org/abs/2403.09857) | 提出了一个名为ASP的框架，通过注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识，并通过信息瓶颈学习目标从旧类到新类传递知识。 |
| [^86] | [Towards the Reusability and Compositionality of Causal Representations](https://arxiv.org/abs/2403.09830) | 该研究提出了DECAF框架，旨在从时间序列图像中学习因果表示，使其能够在新环境中进行调整，并在多个相关环境中进行组合，通过与四种最先进的CRL方法结合，能够在新环境中使用少量样本即可获得准确的表示。 |
| [^87] | [Adapting OC20-trained EquiformerV2 Models for High-Entropy Materials](https://arxiv.org/abs/2403.09811) | 将OC20训练的EquiformerV2模型成功调整并微调，用于推断高熵合金上*OH和*O的吸附能，通过能量过滤器和少量微调获得最先进的准确性。 |
| [^88] | [LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems](https://arxiv.org/abs/2403.09810) | 该论文探讨了如何利用即时AI干预来提升众包平台中人类标注质量和领域知识，介绍了LabelAId模型，与传统方法相比，其能够显著提高错误推断准确性。 |
| [^89] | [Self-Supervised Learning for Time Series: Contrastive or Generative?](https://arxiv.org/abs/2403.09809) | 本文对时间序列中的对比和生成自监督学习方法进行了全面比较研究，提供了各种方法的优势和劣势洞察，并为选择合适的SSL方法提供了实用建议。 |
| [^90] | [On the Utility of 3D Hand Poses for Action Recognition](https://arxiv.org/abs/2403.09805) | 提出了一种名为HandFormer的新型多模态Transformer模型，结合了高时间分辨率的3D手部姿势和稀疏采样的RGB帧，用于有效建模手部和物体之间的相互作用，取得了很高的准确性。 |
| [^91] | [Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning](https://arxiv.org/abs/2403.09793) | 提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。 |
| [^92] | [Emotional Intelligence Through Artificial Intelligence : NLP and Deep Learning in the Analysis of Healthcare Texts](https://arxiv.org/abs/2403.09762) | 本文系统考察了人工智能在医疗文本中情感分析方面的应用，展示了算法精度、神经退行性疾病预测以及临床决策支持方面的显著进展。 |
| [^93] | [Reconstructing Blood Flow in Data-Poor Regimes: A Vasculature Network Kernel for Gaussian Process Regression](https://arxiv.org/abs/2403.09758) | 提出了一种基于物理信息核的高斯过程回归方法，可以在数据匮乏环境中实现几乎实时的血流重建。 |
| [^94] | [Estimating the history of a random recursive tree](https://arxiv.org/abs/2403.09755) | 本文研究了估计随机递归树中顶点到达顺序的问题，提出了基于Jordan中心性度量的顺序估计器，并证明其几乎是最优的。 |
| [^95] | [Towards Diverse Perspective Learning with Selection over Multiple Temporal Poolings](https://arxiv.org/abs/2403.09749) | 提出了一种新颖的时间池化方法SoM-TP，通过多元视角学习实现动态选择最佳时间池化，在单个分类器内实现非迭代池化集成。 |
| [^96] | [The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions](https://arxiv.org/abs/2403.09743) | 人工智能领域中，这项研究探索了人类因素在检测大型语言模型的错误输出中的作用，有助于减轻其在专业环境中使用时所带来的风险。 |
| [^97] | [A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms](https://arxiv.org/abs/2403.09742) | 该综述回顾了解决最大团问题的经典算法，同时也涵盖了图神经网络和量子算法的最新进展，并提出了用于测试这些算法的基准。 |
| [^98] | [Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems](https://arxiv.org/abs/2403.09727) | RAG-based constructions are more efficient than models produced with FN for the development of AI-driven knowledge-based systems. |
| [^99] | [ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs](https://arxiv.org/abs/2403.09724) | ClaimVer是一个人为中心的框架，通过知识图谱实现可解释的声明级验证和证据归因，致力于提高用户对文本验证方法的信任并强调细粒度证据的重要性。 |
| [^100] | [Textual analysis of End User License Agreement for red-flagging potentially malicious software](https://arxiv.org/abs/2403.09715) | 该论文提出了一种通过文本分析用户许可协议，识别潜在恶意软件的方法，并使用监督分类器对其进行分类，为解决EULA过长且难以理解的问题提供了一种解决方案。 |
| [^101] | [Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs Using a Novel Natural Language Processing Algorithmic Pipeline](https://arxiv.org/abs/2403.09708) | 通过新型自然语言处理算法管道，研究对108,280份临床记录进行分析，发现ICIs治疗患者中IrAEs的发生情况，并进行了治疗中断率和生存曲线的构建。 |
| [^102] | [Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations](https://arxiv.org/abs/2403.09704) | 本文提出了 Alignment Studio 架构，使应用开发者能够调整大型语言模型至他们特定的价值观、社会规范、法律和其他法规，并协调潜在冲突的需求。 |
| [^103] | [A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage](https://arxiv.org/abs/2403.09701) | 混合强化学习算法中，通过将离线数据集包含在在线算法的经验重放缓冲区中进行启动，可以实现类似于基于离线数据分布引导在线探索的可证明收益，即使离线数据集没有单一策略可集中性。 |
| [^104] | [Counterfactual Image Editing](https://arxiv.org/abs/2403.09683) | 本文提出了对事实图像编辑的形式化方法，展示了基于i.i.d.图像样本和标签进行对事实编辑的不可能性，并指出即使知晓潜在生成因素与图像之间的因果关系，也无法提供关于模型输出结果的任何保证。 |
| [^105] | [ViT-MUL: A Baseline Study on Recent Machine Unlearning Methods Applied to Vision Transformers](https://arxiv.org/abs/2403.09681) | 该论文通过对最新机器遗忘算法和数据集在Vision Transformers上的实验，为Vision Transformers定制的机器遗忘（MUL）方法进行了基线研究，为该领域的进一步研究提供了有价值的见解。 |
| [^106] | [Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)](https://arxiv.org/abs/2403.09680) | 该论文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段方法，在MNIST级别的分类问题上取得了显著的精度提升，以及训练时间和推理时间大幅度减少。 |
| [^107] | [Navigating the Peril of Generated Alternative Facts: A ChatGPT-4 Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation](https://arxiv.org/abs/2403.09674) | 本研究展示了AI（ChatGPT-4）如何轻松制造令人信服但完全虚构的科学数据，以制造出一个完全虚构的医学案例来警示医学误信息的危害。 |
| [^108] | [FoldToken: Learning Protein Language via Vector Quantization and Beyond](https://arxiv.org/abs/2403.09673) | 通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。 |
| [^109] | [COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced Medical Image Representation](https://arxiv.org/abs/2403.09672) | COMPRER提出了一种新颖的多模态、多目标预训练框架，可以增强医学图像表征，并通过多目标训练提高了特定任务的结果。 |
| [^110] | [On Unsupervised Image-to-image translation and GAN stability](https://arxiv.org/abs/2403.09646) | 本文研究了图像到图像转换中一个经典工作CycleGAN的一些失败案例，并假设这些失败与GAN的稳定性有关。 |
| [^111] | [Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539) | 大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能 |
| [^112] | [Variational Inference with Sequential Sample-Average Approximations](https://arxiv.org/abs/2403.09429) | VISA方法通过顺序样本均值逼近在计算密集型模型中实现近似推断，能够在保守选择学习率的情况下以较小的计算成本达到与标准方法相当的逼近精度。 |
| [^113] | [Rethinking Autoencoders for Medical Anomaly Detection from A Theoretical Perspective](https://arxiv.org/abs/2403.09303) | 该研究从理论角度为医学异常检测中基于自编码器的重建方法提供了基础，揭示了改进AE在异常检测中的关键在于最小化信息。 |
| [^114] | [Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation](https://arxiv.org/abs/2403.08838) | 提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。 |
| [^115] | [Physics-informed generative model for drug-like molecule conformers](https://arxiv.org/abs/2403.07925) | 该模型基于扩散生成，结合深度学习技术从大型数据集中推断原子类型和几何参数，实现了类药分子构象的高精度生成，优于传统方法。 |
| [^116] | [Fast and Simple Explainability for Point Cloud Networks](https://arxiv.org/abs/2403.07706) | 该方法提出了一种基于特征的解释（FBI）方法，通过计算每个点在瓶颈层之前的特征范数，实现了与当前XAI方法至少三个数量级的速度提升，适用于大型点云或大规模架构。 |
| [^117] | [SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression](https://arxiv.org/abs/2403.07378) | SVD-LLM是一种新的基于SVD的LLM压缩方法，通过截断感知数据白化策略和逐层闭式模型参数更新策略，解决了现有方法的限制，实现了直接映射奇异值和压缩损失之间的关系。 |
| [^118] | [AdaNovo: Adaptive \emph{De Novo} Peptide Sequencing with Conditional Mutual Information](https://arxiv.org/abs/2403.07013) | AdaNovo 提出了一个新的框架，通过计算光谱和每个氨基酸/肽段之间的条件互信息，实现了自适应模型训练。 |
| [^119] | [$\mathtt{tsGT}$: Stochastic Time Series Modeling With Transformer](https://arxiv.org/abs/2403.05713) | $\mathtt{tsGT}$是一种基于通用Transformer架构的随机时间序列模型，表现优于最先进模型，并超过其随机同行，特别在数据分布建模和边际分位值预测方面具备优势。 |
| [^120] | [Learning Constrained Optimization with Deep Augmented Lagrangian Methods](https://arxiv.org/abs/2403.03454) | 本文提出了一种使用深度增广拉格朗日方法的学习受限制优化的方法，通过训练机器学习模型直接预测对偶解估计，并构建原始估计，从而实现对偶可行解对，同时迭代向原始可行性，模拟对偶上升方法。 |
| [^121] | [RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging](https://arxiv.org/abs/2403.03359) | 该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。 |
| [^122] | [Pooling Image Datasets With Multiple Covariate Shift and Imbalance](https://arxiv.org/abs/2403.02598) | 本文从范畴论的角度提供了一个简单而有效的解决方案，完全避免了复杂的多阶段训练流程。 |
| [^123] | [Open-world Machine Learning: A Review and New Outlooks](https://arxiv.org/abs/2403.01759) | 通过研究未知拒绝、新类别发现和类别增量学习，本文拓展了开放世界机器学习领域，提出了未来研究的多个潜在方向 |
| [^124] | [End-to-end Graph-Sequential Representation Learning for Accurate Recommendations](https://arxiv.org/abs/2403.00895) | 本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。 |
| [^125] | [Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation](https://arxiv.org/abs/2402.15656) | 提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。 |
| [^126] | [Human Brain Exhibits Distinct Patterns When Listening to Fake Versus Real Audio: Preliminary Evidence](https://arxiv.org/abs/2402.14982) | 人类大脑对真实和虚假音频有不同的反应模式，与深度伪造音频检测算法不同，这为深度伪造音频检测等领域的未来研究方向提供了重要的初步证据。 |
| [^127] | [Structure-Based Drug Design via 3D Molecular Generative Pre-training and Sampling](https://arxiv.org/abs/2402.14315) | 本研究提出了MolEdit3D，将3D分子生成与优化框架相结合，解决了现有基于优化的方法编辑分子时选择在2D空间中的问题。 |
| [^128] | [Robust agents learn causal world models](https://arxiv.org/abs/2402.10877) | 智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。 |
| [^129] | [Signed Diverse Multiplex Networks: Clustering and Inference](https://arxiv.org/abs/2402.10242) | 保留边的符号在网络构建过程中提高了估计和聚类精度，有助于解决现实世界问题。 |
| [^130] | [Grounding Data Science Code Generation with Input-Output Specifications](https://arxiv.org/abs/2402.08073) | 该论文提出了一种方法，通过使用输入输出规范来解决大型语言模型在生成代码时与自然语言提示和I/O规范对齐困难的问题，并在数据科学编程任务上进行了评估。 |
| [^131] | [Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving](https://arxiv.org/abs/2402.05359) | 该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。 |
| [^132] | [Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain](https://arxiv.org/abs/2402.03388) | 在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。 |
| [^133] | [CT-based Anatomical Segmentation for Thoracic Surgical Planning: A Benchmark Study for 3D U-shaped Deep Learning Models](https://arxiv.org/abs/2402.03230) | 本研究为基于CT的胸部手术规划中的解剖分割提供了针对3D U-shaped深度学习模型的基准研究，为临床应用和未来模型设计提供了宝贵的见解。 |
| [^134] | [Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning](https://arxiv.org/abs/2402.02340) | 本论文提出了一种基于学习视觉提示的参数高效微调方法，能够在深度度量学习任务中使预训练模型适应本地数据域并保留先前获得的知识。 |
| [^135] | [Detecting Brain Tumors through Multimodal Neural Networks](https://arxiv.org/abs/2402.00038) | 通过多模态神经网络检测脑肿瘤，在图像处理和分类中取得了令人满意的结果，并具有98%的准确率。 |
| [^136] | [Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer](https://arxiv.org/abs/2312.12467) | 本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习长距离依赖关系，以处理灵活体动力学挑战。 |
| [^137] | [Simplicial Representation Learning with Neural $k$-Forms](https://arxiv.org/abs/2312.08515) | 本文提出了一种使用神经$k$-形式进行单纯复合物表示学习的方法，无需消息传递即可获取几何信息，具有解释性和几何一致性，并能应用微分几何工具实现通用逼近。 |
| [^138] | [Modeling non-genetic information dynamics in cells using reservoir computing](https://arxiv.org/abs/2312.07977) | 离子梯度可能使细胞形成动态多功能的生物系统，促使细胞获取、分析和响应环境信息。 |
| [^139] | [The Generalization Gap in Offline Reinforcement Learning](https://arxiv.org/abs/2312.05742) | 该研究比较了在线和离线学习方法在泛化能力上的差异，发现离线学习算法在新环境中表现不如在线学习算法，并引入了用于评估泛化能力的第一个基准测试。 |
| [^140] | [GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping](https://arxiv.org/abs/2312.01490) | 这项研究在神经网络服装成衣模型中引入了几何约束，使得服装只有在覆盖更大的身体时才发生伸展，解决了现有方法中出现的不真实、不一致的问题。 |
| [^141] | [Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation](https://arxiv.org/abs/2311.14120) | 该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。 |
| [^142] | [Creating and Leveraging a Synthetic Dataset of Cloud Optical Thickness Measures for Cloud Detection in MSI](https://arxiv.org/abs/2311.14024) | 本论文提出了一种利用合成数据集进行云光学厚度测量的方法，以解决在地球观测背景下标记数据稀缺的问题。 |
| [^143] | [zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2311.10112) | 本文提出了一种在时间知识图上进行零样本关系学习的方法，该方法利用大型语言模型(LLM)生成关系表示，并将其引入基于嵌入的TKGF方法中，能够捕捉关系描述中的语义信息，从而使得关系在建模时能具有相似的语义含义。 |
| [^144] | [Finetuning Text-to-Image Diffusion Models for Fairness](https://arxiv.org/abs/2311.07604) | 将公平性视为分布对齐问题，通过分布对齐损失和调整DFT两项技术贡献，显著减少文本到图像扩散模型中的性别、种族和其交叉偏见。 |
| [^145] | [Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification](https://arxiv.org/abs/2311.07593) | 提出了一种零样本方法Follow-up Differential Descriptions（FuDD），通过为每个图像确定模糊类，并使用大型语言模型生成新的类描述，以更好地区分目标类。 |
| [^146] | [LILO: Learning Interpretable Libraries by Compressing and Documenting Code](https://arxiv.org/abs/2310.19791) | LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。 |
| [^147] | [Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?](https://arxiv.org/abs/2310.09562) | CLIP在经过重现ImageNet训练-测试相似性的剪枝LAION分割重新训练后，虽然在某些基准上表现有所下降，但整体性能仍然很高 |
| [^148] | [Differentiable Euler Characteristic Transforms for Shape Classification](https://arxiv.org/abs/2310.07630) | 提出了一种不同iable Euler Characteristic Transform（DECT）计算层，能够实现端到端学习ECT，展现出与更复杂模型相当的性能。 |
| [^149] | [Automated ensemble method for pediatric brain tumor segmentation](https://arxiv.org/abs/2308.07212) | 通过引入新型集成方法和创新的损失函数，利用深度学习技术实现了针对儿科患者的脑瘤精确分割模型。 |
| [^150] | [Machine Unlearning: Solutions and Challenges](https://arxiv.org/abs/2308.07061) | 本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。 |
| [^151] | [A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors](https://arxiv.org/abs/2305.08752) | 不同的标记方法对数据质量和深度学习分类器的性能有直接影响，原位方法产生的标签较少但更精确。 |
| [^152] | [Learning to Detect Slip through Tactile Estimation of the Contact Force Field and its Entropy](https://arxiv.org/abs/2303.00935) | 通过光学触觉传感器结合物理数据驱动方法，实时连续检测滑动，从滑动事件中提取不均匀特征解决滑动检测问题。 |
| [^153] | [Cross-domain Random Pre-training with Prototypes for Reinforcement Learning](https://arxiv.org/abs/2302.05614) | 提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。 |
| [^154] | [Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw](https://arxiv.org/abs/2301.10164) | 通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。 |
| [^155] | [DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy](https://arxiv.org/abs/2210.04442) | 本研究提出了一种名为DPAR的分离图神经网络，能实现对GNNs进行节点级差分隐私，从而保护节点及其边缘。 |
| [^156] | [Continuous QA Learning with Structured Prompts](https://arxiv.org/abs/2208.14602) | 提出了一种名为Diana的动态架构终身QA模型，通过增强语言模型学习一系列QA任务，并使用四种层次组织的提示来捕获不同粒度的QA知识，以提高模型的泛化性能。 |
| [^157] | [StyleTalker: One-shot Style-based Audio-driven Talking Head Video Generation](https://arxiv.org/abs/2208.10922) | 提出了StyleTalker，一种能够从单个参考图像合成具有准确音频同步的说话人视频的模型，并且具有几个新设计的组件来实现这一目标。 |
| [^158] | [Learning Markov State Abstractions for Deep Reinforcement Learning](https://arxiv.org/abs/2106.04379) | 引入了一组新颖条件，证明了学习马尔可夫抽象状态表示的充分性，并提出了结合逆模型估计和时间对比学习的实用训练过程，该方法适用于在线和离线训练，不依赖奖励信号但可以利用奖励信息。 |
| [^159] | [Within-basket Recommendation via Neural Pattern Associator.](http://arxiv.org/abs/2401.16433) | 本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。 |
| [^160] | [Energy-based Automated Model Evaluation.](http://arxiv.org/abs/2401.12689) | 提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。 |
| [^161] | [Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control.](http://arxiv.org/abs/2401.01085) | Imperio是一个使用语言引导的后门攻击工具，可以通过语言指令实现任意模型的控制，扩展了NLP模型的后门攻击能力。 |
| [^162] | [Intriguing Properties of Data Attribution on Diffusion Models.](http://arxiv.org/abs/2311.00500) | 本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。 |
| [^163] | [Compositional preference models for aligning LMs.](http://arxiv.org/abs/2310.13011) | 用于对齐语言模型的组合偏好模型（CPMs）是一种新颖的偏好模型框架，可以分解全局偏好评估并根据可解释的特征进行标量评分，得到更好的泛化能力和鲁棒性。 |
| [^164] | [How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?.](http://arxiv.org/abs/2310.08391) | 本文研究了在线性回归中的上下文学习，并发现有效的预训练只需要少量独立任务，预训练模型与贝叶斯最优算法接近。这些理论发现对ICL的统计基础提供了启示。 |
| [^165] | [Score Regularized Policy Optimization through Diffusion Behavior.](http://arxiv.org/abs/2310.07297) | 通过利用扩散行为模型，我们提出了一种在离线强化学习中用于优化策略的得分正则化方法，从而避免了耗时且计算密集的扩散采样方案，并在D4RL任务上实现了超过25倍的动作采样速度提升。 |
| [^166] | [DyST: Towards Dynamic Neural Scene Representations on Real-World Videos.](http://arxiv.org/abs/2310.06020) | DyST模型通过学习动态场景的潜在分解，从实际视频中捕捉到了场景的3D结构和动态特性，并实现了对相机和场景内容的独立控制视图生成。 |
| [^167] | [Post-hoc Bias Scoring Is Optimal For Fair Classification.](http://arxiv.org/abs/2310.05725) | 本研究提出了一种后验偏差评分的方法，在满足公平性约束的情况下保持高准确性，并给出了基于偏差分数的修改规则。该方法适用于各种类型的公平性约束问题。 |
| [^168] | [Neur2RO: Neural Two-Stage Robust Optimization.](http://arxiv.org/abs/2310.04345) | Neur2RO是一种神经网络驱动的二阶段鲁棒优化算法，通过学习估计第二阶段问题的值函数，并嵌入到经典的列-约束生成算法中，能够高效地求解嵌套的最小-最大-最小优化问题。 |
| [^169] | [Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space.](http://arxiv.org/abs/2310.02970) | 该论文通过在位置-方向空间中共享权重，提出了一种快速、表达力强的SE$(n)$等变网络。他们基于同态空间理论，推导出几何优化的边属性，并将权重共享形式化为对等处理相同点对的消息函数。他们在处理3D点云时，开发了一个高效的等变群卷积网络，并选择了$\mathbb{R}^3 {\times} S^2$作为最佳的处理空间。 |
| [^170] | [SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training.](http://arxiv.org/abs/2310.02227) | SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。 |
| [^171] | [DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training.](http://arxiv.org/abs/2310.02025) | DeepZero是一个扩展零阶优化到深度神经网络训练的深度学习框架，通过创新的坐标梯度估计和稀疏诱导的零阶训练协议，实现了高准确性和计算效率的优化。 |
| [^172] | [JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention.](http://arxiv.org/abs/2310.00535) | 本文提出了联合MLP/注意力（JoMA）动态，用于解析多层Transformer架构的训练过程。通过预测非线性激活情况下注意力的行为，我们解释了多层Transformer中标记的层次组合方法。实验证实了我们的理论发现。 |
| [^173] | [Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning.](http://arxiv.org/abs/2309.16984) | 这篇论文介绍了一种基于一致性模型的策略表示方法，在强化学习中具有高效且表达力强的特点。实验表明，一致性策略在各种RL设置中都具有良好的性能表现。 |
| [^174] | [Identifying confounders in deep-learning-based model predictions using DeepRepViz.](http://arxiv.org/abs/2309.15551) | 这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。 |
| [^175] | [Transferring climate change knowledge.](http://arxiv.org/abs/2309.14780) | 通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。 |
| [^176] | [Guess & Sketch: Language Model Guided Transpilation.](http://arxiv.org/abs/2309.14396) | 本论文通过结合概率性神经语言模型和符号化方法，提出了一种语言模型引导的转译方法，用于自动翻译汇编代码程序，以缩短维护遗留软件的时间和工程成本。 |
| [^177] | [Understanding the limitations of self-supervised learning for tabular anomaly detection.](http://arxiv.org/abs/2309.08374) | 本研究探讨了自监督学习在表格异常检测中的限制。通过多个实验发现，自监督学习得到的表征并不能提高表格异常检测的性能，这是由于神经网络引入了无关的特征。然而，使用神经网络表示的子空间可以恢复性能。 |
| [^178] | [Traveling Waves Encode the Recent Past and Enhance Sequence Learning.](http://arxiv.org/abs/2309.08045) | 本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。 |
| [^179] | [Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations.](http://arxiv.org/abs/2309.04849) | 该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。 |
| [^180] | [Viewing the process of generating counterfactuals as a source of knowledge -- Application to the Naive Bayes classifier.](http://arxiv.org/abs/2309.04284) | 将生成对立假设的过程视为知识来源，并应用于朴素贝叶斯分类器，展示其有趣属性。 |
| [^181] | [Cognitive Architectures for Language Agents.](http://arxiv.org/abs/2309.02427) | 本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。 |
| [^182] | [Can transformers learn the greatest common divisor?.](http://arxiv.org/abs/2308.15594) | 本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。 |
| [^183] | [Price-Discrimination Game for Distributed Resource Management in Federated Learning.](http://arxiv.org/abs/2308.13838) | 本论文提出了一种价格差异化游戏（PDG），通过对不同客户提供的服务进行定价差异化，改善了联合学习的性能并降低了激励客户参与联合学习的成本。 |
| [^184] | [Self-Compatibility: Evaluating Causal Discovery without Ground Truth.](http://arxiv.org/abs/2307.09552) | 本论文提出了一种在没有基准数据的情况下评估因果发现方法的新方法，通过在不同变量子集上学习的因果图之间的兼容性检测，来伪证因果关系的推断正确性。 |
| [^185] | [Voting-based Multimodal Automatic Deception Detection.](http://arxiv.org/abs/2307.07516) | 本文提出了一种基于投票的多模态方法用于自动欺骗检测，通过视频的音频、视觉和文本特征进行检测。实验结果表明，我们的解决方案在欺骗检测中表现优于现有技术。 |
| [^186] | [Boosting Multitask Learning on Graphs through Higher-Order Task Affinities.](http://arxiv.org/abs/2306.14009) | 本文从多任务学习的角度重新审视在给定图上预测节点标签的问题，提出通过更高级任务相似性来加强多任务学习，并开发了一种算法来将任务分组以应对负迁移问题。 |
| [^187] | [Unprocessing Seven Years of Algorithmic Fairness.](http://arxiv.org/abs/2306.07261) | 该论文取消了算法公平性中的后处理方法，并发现后处理实现的公平性-准确性Pareto边界包含了可评估的所有其他方法。 |
| [^188] | [Generative Diffusion for 3D Turbulent Flows.](http://arxiv.org/abs/2306.01776) | 该论文提出了一种生成模型，可以在任意三维空间中模拟湍流现象，避免了湍流流动的不可预测性，能够快速生成高质量的流场。 |
| [^189] | [Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs.](http://arxiv.org/abs/2305.18702) | 本研究提出了一种新的深度生成模型来调整训练集中的随机样本，以使PDE解的残余在最小化时能保持平滑的轮廓，并通过引入对抗性损失项优化PINN模型，从而使神经网络学习稳定的解。同时本文还展示了该方法可以扩展到纳入最优传输约束，从而形成了将PINN和最优传输的优点结合起来的统一框架，用于PDE近似。 |
| [^190] | [Generalization Error without Independence: Denoising, Linear Regression, and Transfer Learning.](http://arxiv.org/abs/2305.17297) | 本论文研究了具有低秩结构但非独立同分布数据的情况，在分离训练和测试分布的假设下，解决了分布偏移问题，实验结果表明，在分布偏移的情况下，本方法显著提高了泛化误差的性能。 |
| [^191] | [Distilling Knowledge for Short-to-Long Term Trajectory Prediction.](http://arxiv.org/abs/2305.08553) | 本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。 |
| [^192] | [Softmax-free Linear Transformers.](http://arxiv.org/abs/2207.03341) | 这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。 |
| [^193] | [Stability to Deformations of Manifold Filters and Manifold Neural Networks.](http://arxiv.org/abs/2106.03725) | 本文定义了流形滤波器和流形神经网络，并通过分析它们在流形变形下的稳定性，推广了图滤波器和标准卷积滤波器的已知稳定性性质。 |

# 详细

[^1]: TEDDY: 基于度量判别策略的边缘修剪方法

    TEDDY: Trimming Edges with Degree-based Discrimination strategY

    [https://rss.arxiv.org/abs/2402.01261](https://rss.arxiv.org/abs/2402.01261)

    TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。

    

    自从Chen等人在2021年提出用于图神经网络（GNNs）的抽奖票假设的开创性工作以来，寻找图抽奖票（GLT）的研究已成为GNN社区的重要关注点之一，激发了研究人员在实现与原始密集网络相当性能的同时，发现更稀疏的GLT。同时，图结构作为GNN训练动力学的重要因素，也受到了广泛关注，并得到了最近几项研究的阐明。尽管如此，目前关于GLT的研究通常没有充分利用图结构中的内在路径，并以迭代方式识别票数，这种方法耗时且效率低下。为解决这些限制，我们引入TEDDY，一种利用结构信息并整合边缘度量信息的一次性边缘稀疏化框架。在进行边缘稀疏化后，我们通过简单的投影梯度下降方法鼓励参数稀疏化训练。

    Since the pioneering work on the lottery ticket hypothesis for graph neural networks (GNNs) was proposed in Chen et al. (2021), the study on finding graph lottery tickets (GLT) has become one of the pivotal focus in the GNN community, inspiring researchers to discover sparser GLT while achieving comparable performance to original dense networks. In parallel, the graph structure has gained substantial attention as a crucial factor in GNN training dynamics, also elucidated by several recent studies. Despite this, contemporary studies on GLT, in general, have not fully exploited inherent pathways in the graph structure and identified tickets in an iterative manner, which is time-consuming and inefficient. To address these limitations, we introduce TEDDY, a one-shot edge sparsification framework that leverages structural information by incorporating edge-degree information. Following edge sparsification, we encourage the parameter sparsity during training via simple projected gradient desc
    
[^2]: 强大且可控的盲图像分解

    Strong and Controllable Blind Image Decomposition

    [https://arxiv.org/abs/2403.10520](https://arxiv.org/abs/2403.10520)

    该论文提出了一种具有可控性的盲图像分解方法，允许用户选择移除或保留特定类型的降解，实现了在 minimal computational cost的情况下对输入图像进行部分或完全恢复

    

    盲图像分解旨在分解图像中的所有组成部分，通常用于恢复一个多重降低的输入图像。虽然完全恢复干净的图像很吸引人，但在某些情况下，用户可能希望保留某些降解，例如水印，以进行版权保护。为了满足这种需要，我们在盲图像分解过程中添加了可控性，允许用户输入要移除或保留的降解类型。我们设计了一个名为可控盲图像分解网络的架构。我们的方法首先将输入的特征图分解，然后根据用户的指令重新组合它们。有利的是，这种功能以极小的计算成本实现：分解和重组都是无参数的。实验结果表明，我们的系统在盲图像分解任务中表现出色，并能输出部分或完全恢复的图像。

    arXiv:2403.10520v1 Announce Type: cross  Abstract: Blind image decomposition aims to decompose all components present in an image, typically used to restore a multi-degraded input image. While fully recovering the clean image is appealing, in some scenarios, users might want to retain certain degradations, such as watermarks, for copyright protection. To address this need, we add controllability to the blind image decomposition process, allowing users to enter which types of degradation to remove or retain. We design an architecture named controllable blind image decomposition network. Inserted in the middle of U-Net structure, our method first decomposes the input feature maps and then recombines them according to user instructions. Advantageously, this functionality is implemented at minimal computational cost: decomposition and recombination are all parameter-free. Experimentally, our system excels in blind image decomposition tasks and can outputs partially or fully restored images
    
[^3]: FeatUp: 一个与模型无关的特征任意分辨率框架

    FeatUp: A Model-Agnostic Framework for Features at Any Resolution

    [https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)

    FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。

    

    深度特征是计算机视觉研究的基石，捕捉图像语义并使社区能够解决下游任务，即使在零或少样本情况下也能做到。然而，这些特征通常缺乏空间分辨率，无法直接执行像分割和深度预测这样的稠密预测任务，因为模型会过于聚合大范围的信息。在这项工作中，我们介绍了FeatUp，一个任务和模型无关的框架，用于恢复深度特征中丢失的空间信息。我们介绍了FeatUp的两个变体：一个在单次前向传递中引导具有高分辨率信号的特征，另一个适应单个图像并以任何分辨率重构特征的隐式模型。这两种方法都使用了一个具有与 NeRF 类似的深度类比的多视图一致性损失。我们的特征保留其原始语义，并可以替换现有应用程序，即使不重新

    arXiv:2403.10516v1 Announce Type: cross  Abstract: Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-
    
[^4]: HumanoidBench：用于全身运动和操作的仿真人型机器人基准测试

    HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation

    [https://arxiv.org/abs/2403.10506](https://arxiv.org/abs/2403.10506)

    提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。

    

    人型机器人在协助人类在不同环境和任务中有着巨大潜力，由于其灵活性和适应性，可以利用类人形态。然而，人型机器人的研究常常受到昂贵且易损的硬件设置的限制。为了加速人型机器人算法研究，我们提出了一个高维度的仿真机器人学习基准测试，HumanoidBench，该测试包括一个配备灵巧手部和各种具有挑战性的全身操作和运动任务的人型机器人。我们的研究发现表明，最先进的强化学习算法在大多数任务上表现不佳，而具备鲁棒的低级策略支持的分层学习基线在行走或到达等任务中表现优异。借助HumanoidBench，我们为机器人社区提供了一个平台，用于识别解决人型机器人在解决各种任务时面临的挑战，促进算法研究。

    arXiv:2403.10506v1 Announce Type: cross  Abstract: Humanoid robots hold great promise in assisting humans in diverse environments and tasks, due to their flexibility and adaptability leveraging human-like morphology. However, research in humanoid robots is often bottlenecked by the costly and fragile hardware setups. To accelerate algorithmic research in humanoid robots, we present a high-dimensional, simulated robot learning benchmark, HumanoidBench, featuring a humanoid robot equipped with dexterous hands and a variety of challenging whole-body manipulation and locomotion tasks. Our findings reveal that state-of-the-art reinforcement learning algorithms struggle with most tasks, whereas a hierarchical learning baseline achieves superior performance when supported by robust low-level policies, such as walking or reaching. With HumanoidBench, we provide the robotics community with a platform to identify the challenges arising when solving diverse tasks with humanoid robots, facilitatin
    
[^5]: 基于多模态基础模型的零样本鲁棒性基准测试：一项试点研究

    Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study

    [https://arxiv.org/abs/2403.10499](https://arxiv.org/abs/2403.10499)

    本研究通过对多模态基础模型CLIP进行大规模鲁棒性基准测试，揭示了其在涵盖自然分布偏移、合成分布偏移和对抗攻击等多个方面的优异表现。

    

    通过从关于图像的原始文本中预训练图像表示，使得零样本视觉传输至下游任务成为可能。通过在互联网上采集的数百万样本上进行预训练，如CLIP之类的多模态基础模型产生了最先进的零样本结果，通常在无需任务特定训练的情况下达到与完全监督方法竞争力相当的水平。除了在分类准确性上表现鼓舞人心之外，报道称这些模型通过在自然分布偏移下与在ImageNet上训练的监督模型的表现相匹配来缩小鲁棒性差距。由于鲁棒性对于现实世界的应用至关重要，特别是对于安全关键的应用，本文提出了基于涵盖7种自然、3种合成分布偏移和11种对抗攻击的大规模鲁棒性基准测试的全面评估。我们以CLIP作为试点研究。我们展示了CLIP导致了显著

    arXiv:2403.10499v1 Announce Type: cross  Abstract: Pre-training image representations from the raw text about images enables zero-shot vision transfer to downstream tasks. Through pre-training on millions of samples collected from the internet, multimodal foundation models, such as CLIP, produce state-of-the-art zero-shot results that often reach competitiveness with fully supervised methods without the need for task-specific training. Besides the encouraging performance on classification accuracy, it is reported that these models close the robustness gap by matching the performance of supervised models trained on ImageNet under natural distribution shift. Because robustness is critical to real-world applications, especially safety-critical ones, in this paper, we present a comprehensive evaluation based on a large-scale robustness benchmark covering 7 natural, 3 synthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a pilot study. We show that CLIP leads to a signif
    
[^6]: 使用屏障证明和条件均值嵌入的基于数据驱动的分布鲁棒安全验证

    Data-Driven Distributionally Robust Safety Verification Using Barrier Certificates and Conditional Mean Embeddings

    [https://arxiv.org/abs/2403.10497](https://arxiv.org/abs/2403.10497)

    本研究采用屏障证明概念，并直接从系统轨迹集中学习证明，开发了可扩展的形式验证算法。

    

    实际系统的算法验证需要满足安全和其他时间要求，但所采用的形式方法的可扩展性较差。为设计具有严格保证的系统，许多方法仍依赖于底层系统的精确模型。由于这一假设在实践中很少能得到满足，因此必须从测量数据中推断模型或完全绕过模型。为了开发可扩展的形式验证算法而不将问题转移到不切实际的假设上，我们运用了屏障证明的概念，该证明可以保证系统的安全性，并直接从紧凑系统轨迹集中学习证明。

    arXiv:2403.10497v1 Announce Type: cross  Abstract: Algorithmic verification of realistic systems to satisfy safety and other temporal requirements has suffered from poor scalability of the employed formal approaches. To design systems with rigorous guarantees, many approaches still rely on exact models of the underlying systems. Since this assumption can rarely be met in practice, models have to be inferred from measurement data or are bypassed completely. Whilst former usually requires the model structure to be known a-priori and immense amounts of data to be available, latter gives rise to a plethora of restrictive mathematical assumptions about the unknown dynamics. In a pursuit of developing scalable formal verification algorithms without shifting the problem to unrealistic assumptions, we employ the concept of barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a compact set of system trajectories. We use conditional mean embeddi
    
[^7]: 野外情感维度识别的联合多模态Transformer

    Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild

    [https://arxiv.org/abs/2403.10488](https://arxiv.org/abs/2403.10488)

    该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。

    

    在视频中进行音视频情感识别对于单模性能具有巨大潜力。它有效地利用了视觉和听觉模态之间以及模态内部的依赖关系。本工作提出了一种利用关键交叉注意力的联合多模态Transformer架构的音视频情感识别系统。该框架旨在利用视频中音频和视觉线索（面部表情和语音模式）的互补性，相较于仅依赖于单一模态，实现了更优越的性能。所提出的模型利用单独的主干网络来捕获每种模态（音频和视觉）内部的时间依赖关系。随后，一个联合多模态Transformer架构集成了各自模态的嵌入，使该模型能够有效地捕获模态间（音频和视觉之间）和模态内部（每种模态内部）的关系。

    arXiv:2403.10488v1 Announce Type: cross  Abstract: Audiovisual emotion recognition (ER) in videos has immense potential over unimodal performance. It effectively leverages the inter- and intra-modal dependencies between visual and auditory modalities. This work proposes a novel audio-visual emotion recognition system utilizing a joint multimodal transformer architecture with key-based cross-attention. This framework aims to exploit the complementary nature of audio and visual cues (facial expressions and vocal patterns) in videos, leading to superior performance compared to solely relying on a single modality. The proposed model leverages separate backbones for capturing intra-modal temporal dependencies within each modality (audio and visual). Subsequently, a joint multimodal transformer architecture integrates the individual modality embeddings, enabling the model to effectively capture inter-modal (between audio and visual) and intra-modal (within each modality) relationships. Exten
    
[^8]: 增强鲁棒性的近似零空间增强微调方法用于视觉变换器

    Approximate Nullspace Augmented Finetuning for Robust Vision Transformers

    [https://arxiv.org/abs/2403.10476](https://arxiv.org/abs/2403.10476)

    本研究提出了一种启发自线性代数零空间概念的视觉变换器鲁棒性增强微调方法，通过合成近似零空间元素来提高模型的鲁棒性。

    

    增强深度学习模型的鲁棒性，特别是在视觉变换器（ViTs）领域中，对于它们在现实世界中的部署至关重要。在这项工作中，我们提供了一种启发自线性代数中零空间概念的视觉变换器鲁棒性增强微调方法。我们的研究集中在一个问题上，即视觉变换器是否可以展现出类似于线性映射中的零空间属性的输入变化韧性，这意味着从该零空间中采样的扰动添加到输入时不会影响模型的输出。首先，我们展示了对于许多预训练的ViTs，存在一个非平凡的零空间，这是由于存在修补嵌入层。其次，由于零空间是与线性代数相关的概念，我们表明可以利用优化策略为ViTs的非线性块合成近似零空间元素。最后，我们提出了一种细致的方法

    arXiv:2403.10476v1 Announce Type: cross  Abstract: Enhancing the robustness of deep learning models, particularly in the realm of vision transformers (ViTs), is crucial for their real-world deployment. In this work, we provide a finetuning approach to enhance the robustness of vision transformers inspired by the concept of nullspace from linear algebra. Our investigation centers on whether a vision transformer can exhibit resilience to input variations akin to the nullspace property in linear mappings, implying that perturbations sampled from this nullspace do not influence the model's output when added to the input. Firstly, we show that for many pretrained ViTs, a non-trivial nullspace exists due to the presence of the patch embedding layer. Secondly, as nullspace is a concept associated with linear algebra, we demonstrate that it is possible to synthesize approximate nullspace elements for the non-linear blocks of ViTs employing an optimisation strategy. Finally, we propose a fine-t
    
[^9]: 引入自适应连续对抗训练（ACAT）以增强机器学习的鲁棒性

    Introducing Adaptive Continuous Adversarial Training (ACAT) to Enhance ML Robustness

    [https://arxiv.org/abs/2403.10461](https://arxiv.org/abs/2403.10461)

    引入了自适应连续对抗训练（ACAT）来持续集成对抗训练样本到模型中，使用实际检测到的对抗数据，增强模型对不断演变的对抗威胁的抵抗能力。

    

    机器学习（ML）易受针对ML模型的对抗攻击影响，这些攻击旨在欺骗ML模型，使其产生错误预测。 对抗训练被发现能提高ML模型对这些攻击的鲁棒性。然而，在网络和网络安全领域，获取标记训练和对抗训练数据是具有挑战性且昂贵的。此外，概念漂移加深了挑战，特别是在诸如网络和网络安全等动态领域中，需要各种模型进行定期重新训练。本文介绍了自适应连续对抗训练（ACAT），以在持续的学习会话期间持续将对抗训练样本整合到模型中，使用实际检测到的对抗数据，以增强模型对不断演变的对抗威胁的抵抗能力。 ACAT是一种自适应的防御机制，利用定期重新训练来有效对抗对抗攻击，同时减轻灾难性后果。

    arXiv:2403.10461v1 Announce Type: new  Abstract: Machine Learning (ML) is susceptible to adversarial attacks that aim to trick ML models, making them produce faulty predictions. Adversarial training was found to increase the robustness of ML models against these attacks. However, in network and cybersecurity, obtaining labeled training and adversarial training data is challenging and costly. Furthermore, concept drift deepens the challenge, particularly in dynamic domains like network and cybersecurity, and requires various models to conduct periodic retraining. This letter introduces Adaptive Continuous Adversarial Training (ACAT) to continuously integrate adversarial training samples into the model during ongoing learning sessions, using real-world detected adversarial data, to enhance model resilience against evolving adversarial threats. ACAT is an adaptive defense mechanism that utilizes periodic retraining to effectively counter adversarial attacks while mitigating catastrophic f
    
[^10]: 深度学习中的双下降现象探究

    Understanding the Double Descent Phenomenon in Deep Learning

    [https://arxiv.org/abs/2403.10459](https://arxiv.org/abs/2403.10459)

    在现代深度学习中，庞大的过参数化模型通过增加模型复杂度来降低测试误差，这就是双下降现象。

    

    将经验风险最小化与容量控制相结合是机器学习中经典的策略，用于控制泛化差距并避免过拟合，因为模型类容量变大。然而，在现代深度学习实践中，非常庞大的过参数化模型（如神经网络）被优化以完美拟合训练数据，并且仍然可以获得良好的泛化性能。超越插值点后，增加模型复杂度似乎实际上会降低测试误差。在本教程中，我们解释了双下降的概念及其机制。第一部分建立了经典的统计学习框架并介绍了双下降现象。通过观察多个示例，第二部分介绍了归纳偏差，在双下降中选择平滑的经验风险最小化器起着关键作用。最后，第三部分探讨了t

    arXiv:2403.10459v1 Announce Type: new  Abstract: Combining empirical risk minimization with capacity control is a classical strategy in machine learning when trying to control the generalization gap and avoid overfitting, as the model class capacity gets larger. Yet, in modern deep learning practice, very large over-parameterized models (e.g. neural networks) are optimized to fit perfectly the training data and still obtain great generalization performance. Past the interpolation point, increasing model complexity seems to actually lower the test error.   In this tutorial, we explain the concept of double descent and its mechanisms. The first section sets the classical statistical learning framework and introduces the double descent phenomenon. By looking at a number of examples, section 2 introduces inductive biases that appear to have a key role in double descent by selecting, among the multiple interpolating solutions, a smooth empirical risk minimizer. Finally, section 3 explores t
    
[^11]: 利用RAG增强LLM事实准确性以消除幻觉：私人知识库中特定领域查询的案例研究

    Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases

    [https://arxiv.org/abs/2403.10446](https://arxiv.org/abs/2403.10446)

    利用RAG系统增强LLMs，提高其对私人知识库中特定领域和时效查询的事实准确性，尤其在使用外部数据集方面表现出潜力。

    

    我们提出了一个端到端系统设计，利用检索增强生成（RAG）来提高大型语言模型（LLMs）对私人知识库中与特定领域和时效查询相关的事实准确性。我们的系统将RAG管道与上游数据集处理和下游性能评估整合在一起。解决LLM幻觉的挑战，我们用源自CMU广泛资源并用教师模型注释的筛选数据集对模型进行微调。我们的实验表明该系统在生成更准确的特定领域和时效查询答案方面的有效性。结果还揭示了使用小规模和倾斜数据集微调LLMs的局限性。这项研究突显了RAG系统在增强LLMs与外部数据集以改进知识密集型任务性能方面的潜力。我们的代码和模型可供使用。

    arXiv:2403.10446v1 Announce Type: new  Abstract: We proposed an end-to-end system design towards utilizing Retrieval Augmented Generation (RAG) to improve the factual accuracy of Large Language Models (LLMs) for domain-specific and time-sensitive queries related to private knowledge-bases. Our system integrates RAG pipeline with upstream datasets processing and downstream performance evaluation. Addressing the challenge of LLM hallucinations, we finetune models with a curated dataset which originates from CMU's extensive resources and annotated with the teacher model. Our experiments demonstrate the system's effectiveness in generating more accurate answers to domain-specific and time-sensitive inquiries. The results also revealed the limitations of fine-tuning LLMs with small-scale and skewed datasets. This research highlights the potential of RAG systems in augmenting LLMs with external datasets for improved performance in knowledge-intensive tasks. Our code and models are available 
    
[^12]: 用于加速推测解码的最佳块级草稿验证

    Optimal Block-Level Draft Verification for Accelerating Speculative Decoding

    [https://arxiv.org/abs/2403.10444](https://arxiv.org/abs/2403.10444)

    提出了一种更好的草稿验证算法，通过将验证步骤制定为块级最优传输问题，实现了额外的墙钟速度提升，而不增加额外的计算成本和草稿标记

    

    推测解码已被证明是在推理过程中加速大型语言模型（LLMs）无损加速的有效方法。 在每次迭代中，算法首先使用一个较小的模型起草一块标记。这些标记然后由大型模型并行验证，只有一部分标记将被保留，以确保最终输出遵循大型模型的分布。 在以往的所有推测解码工作中，起草验证是独立地逐个标记执行的。 在本工作中，我们提出了一个更好的起草验证算法，可提供额外的墙钟加速，而不需要额外的计算成本和起草标记。 我们首先将起草验证步骤制定为一个块级最优传输问题。 块级制定允许我们考虑更广泛的起草验证算法，并在一个起草中预期获得更多接受的标记数量

    arXiv:2403.10444v1 Announce Type: cross  Abstract: Speculative decoding has shown to be an effective method for lossless acceleration of large language models (LLMs) during inference. In each iteration, the algorithm first uses a smaller model to draft a block of tokens. The tokens are then verified by the large model in parallel and only a subset of tokens will be kept to guarantee that the final output follows the distribution of the large model. In all of the prior speculative decoding works, the draft verification is performed token-by-token independently. In this work, we propose a better draft verification algorithm that provides additional wall-clock speedup without incurring additional computation cost and draft tokens. We first formulate the draft verification step as a block-level optimal transport problem. The block-level formulation allows us to consider a wider range of draft verification algorithms and obtain a higher number of accepted tokens in expectation in one draft 
    
[^13]: 结构化评估合成表格数据

    Structured Evaluation of Synthetic Tabular Data

    [https://arxiv.org/abs/2403.10424](https://arxiv.org/abs/2403.10424)

    提出了一个具有单一数学目标的评估框架，用于确定合成数据应该从与观测数据相同的分布中提取，并且推理了任何一组指标的完整性，统一了现有的指标，并鼓励新的模型无关基线和指标。

    

    表格数据通常存在但往往不完整，数据量较小，并且由于隐私原因受限于访问。合成数据生成提供了潜在解决方案。存在许多用于评估合成表格式数据质量的指标；然而，我们缺乏对这些指标的客观、连贯的解释。为解决这一问题，我们提出了一个具有单一数学目标的评估框架，认为合成数据应该从与观测数据相同的分布中提取。通过对目标的各种结构分解，该框架首次允许我们推理任何一组指标的完整性，并统一现有的指标，包括源自忠实性考虑、下游应用和基于模型方法的指标。此外，该框架激励了无模型基线和一系列新的指标。我们评估了结构化信息合成器和合成器。

    arXiv:2403.10424v1 Announce Type: new  Abstract: Tabular data is common yet typically incomplete, small in volume, and access-restricted due to privacy concerns. Synthetic data generation offers potential solutions. Many metrics exist for evaluating the quality of synthetic tabular data; however, we lack an objective, coherent interpretation of the many metrics. To address this issue, we propose an evaluation framework with a single, mathematical objective that posits that the synthetic data should be drawn from the same distribution as the observed data. Through various structural decomposition of the objective, this framework allows us to reason for the first time the completeness of any set of metrics, as well as unifies existing metrics, including those that stem from fidelity considerations, downstream application, and model-based approaches. Moreover, the framework motivates model-free baselines and a new spectrum of metrics. We evaluate structurally informed synthesizers and syn
    
[^14]: 分布式优化中避免鞍点的量化方法

    Quantization Avoids Saddle Points in Distributed Optimization

    [https://arxiv.org/abs/2403.10423](https://arxiv.org/abs/2403.10423)

    量化方法在分布式非凸优化中能够避免收敛到鞍点，确保收敛到二阶稳定点。

    

    分布式非凸优化支撑着众多分布式系统的关键功能，从电力系统、智能建筑、协作机器人、车辆网络到传感器网络等等。最近，它也作为一个有前途的解决方案，用来处理深度学习中数据量和模型规模的巨大增长。分布式非凸优化中的一个基本问题是避免收敛到鞍点，鞍点会显著降低优化精度。我们发现量化过程，对于所有数字通信都是必需的，可以被利用来实现避免鞍点。具体来说，我们提出了一种随机量化方案，并证明它可以有效地避开鞍点，确保在分布式非凸优化中收敛到二阶稳定点。这种方法允许用户通过轻松调整量化粒度来控制位数。

    arXiv:2403.10423v1 Announce Type: cross  Abstract: Distributed nonconvex optimization underpins key functionalities of numerous distributed systems, ranging from power systems, smart buildings, cooperative robots, vehicle networks to sensor networks. Recently, it has also merged as a promising solution to handle the enormous growth in data and model sizes in deep learning. A fundamental problem in distributed nonconvex optimization is avoiding convergence to saddle points, which significantly degrade optimization accuracy. We discover that the process of quantization, which is necessary for all digital communications, can be exploited to enable saddle-point avoidance. More specifically, we propose a stochastic quantization scheme and prove that it can effectively escape saddle points and ensure convergence to a second-order stationary point in distributed nonconvex optimization. With an easily adjustable quantization granularity, the approach allows a user to control the number of bits
    
[^15]: 在Huber污染模型下具有最优误差的高斯稀疏估计的鲁棒估计

    Robust Sparse Estimation for Gaussians with Optimal Error under Huber Contamination

    [https://arxiv.org/abs/2403.10416](https://arxiv.org/abs/2403.10416)

    我们提出了在Huber污染模型下进行高斯稀疏估计任务的鲁棒估计器，为均值估计、主成分分析和线性回归提供了具有最优误差保证的高效算法，同时引入了一种新颖的多维滤波方法。

    

    我们在Huber的污染模型中研究了高斯稀疏估计任务，重点关注均值估计、主成分分析和线性回归。针对这些任务，我们提供了第一个样本和计算高效的鲁棒估计器，具有最优的误差保证，且在常数因子内。所有先前用于这些任务的高效算法都导致量化的次优误差。具体来说，对于在$\mathbb{R}^d$上带有污染率$\epsilon>0$的高斯稳健$k$-稀疏均值估计，我们的算法具有样本复杂度$(k^2/\epsilon^2)\mathrm{polylog}(d/\epsilon)$，在样本多项式时间内运行，并在$\ell_2$-误差为$O(\epsilon)$的情况下逼近目标均值。先前的高效算法固有地产生误差为$\Omega(\epsilon \sqrt{\log(1/\epsilon)})$。在技术层面上，我们开发了一种在稀疏领域中可能具有其他应用的新颖的多维滤波方法。

    arXiv:2403.10416v1 Announce Type: new  Abstract: We study Gaussian sparse estimation tasks in Huber's contamination model with a focus on mean estimation, PCA, and linear regression. For each of these tasks, we give the first sample and computationally efficient robust estimators with optimal error guarantees, within constant factors. All prior efficient algorithms for these tasks incur quantitatively suboptimal error. Concretely, for Gaussian robust $k$-sparse mean estimation on $\mathbb{R}^d$ with corruption rate $\epsilon>0$, our algorithm has sample complexity $(k^2/\epsilon^2)\mathrm{polylog}(d/\epsilon)$, runs in sample polynomial time, and approximates the target mean within $\ell_2$-error $O(\epsilon)$. Previous efficient algorithms inherently incur error $\Omega(\epsilon \sqrt{\log(1/\epsilon)})$. At the technical level, we develop a novel multidimensional filtering method in the sparse regime that may find other applications.
    
[^16]: SocialGenPod: 隐私友好的分布式个人数据存储的生成式AI社交网络应用

    SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores

    [https://arxiv.org/abs/2403.10408](https://arxiv.org/abs/2403.10408)

    SocialGenPod提出了一种隐私友好的生成式AI社交网络应用部署方式，通过使用分布式的Solid规范来解耦用户数据与应用程序，实现用户在个人Pod中安全存储所有数据的控制。

    

    我们提出了SocialGenPod，这是一种分布式且隐私友好的方式用于部署生成式AI Web应用。我们展示了如何利用Solid规范来将用户数据与生成式AI应用程序解耦，与保持用户数据与应用程序和服务提供商绑定的集中式Web和数据架构不同。我们使用一个原型演示了SocialGenPod，允许用户与不同的大型语言模型对话，可选择利用检索增强生成技术生成以用户被允许直接或间接访问的任何Solid Pod中存储的私人文档为基础的答案。SocialGenPod利用Solid访问控制机制，让用户完全控制确定谁可以访问存储在他们Pod中的数据。SocialGenPod将所有用户数据（聊天记录，应用程序配置，个人文档等）安全地存储在用户的个人Pod中；与特定模型分开。

    arXiv:2403.10408v1 Announce Type: cross  Abstract: We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid -- a decentralised Web specification -- to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user's personal Pod; separate from specific model 
    
[^17]: 基于钻井数据的岩体分类机器学习方法的比较研究

    A comparative study on machine learning approaches for rock mass classification using drilling data

    [https://arxiv.org/abs/2403.10404](https://arxiv.org/abs/2403.10404)

    该研究利用大规模和地质多样性的钻孔数据集，引入了模型用于准确地在实际隧道施工环境中对岩体质量进行分类，提供关键的决策支持。

    

    目前，在敲击爆破隧道的岩石工程设计主要依赖于工程师的观测评估。在隧道挖掘期间收集的高分辨率传感器数据——钻进时测量（MWD）数据被低估了，主要用于地质可视化。本研究旨在自动将MWD数据转化为可操作的岩石工程指标。它旨在将数据与特定的工程行动联系起来，为隧道推进前面的地质挑战提供至关重要的决策支持。利用来自15个隧道的50万个钻孔的大规模和地质多样性数据集，该研究在实际隧道施工环境中为准确的岩体质量分类引入了模型。研究探讨了传统的机器学习方法和基于图像的深度学习方法，将MWD数据分类为Q类和Q值，这些指标描述了岩石质量的稳定性。

    arXiv:2403.10404v1 Announce Type: new  Abstract: Current rock engineering design in drill and blast tunnelling primarily relies on engineers' observational assessments. Measure While Drilling (MWD) data, a high-resolution sensor dataset collected during tunnel excavation, is underutilised, mainly serving for geological visualisation. This study aims to automate the translation of MWD data into actionable metrics for rock engineering. It seeks to link data to specific engineering actions, thus providing critical decision support for geological challenges ahead of the tunnel face. Leveraging a large and geologically diverse dataset of 500,000 drillholes from 15 tunnels, the research introduces models for accurate rock mass quality classification in a real-world tunnelling context. Both conventional machine learning and image-based deep learning are explored to classify MWD data into Q-classes and Q-values, examples of metrics describing the stability of the rock mass, using both tabular 
    
[^18]: 特征空间中的能量校正模型用于异常检测

    Energy Correction Model in the Feature Space for Out-of-Distribution Detection

    [https://arxiv.org/abs/2403.10403](https://arxiv.org/abs/2403.10403)

    通过在特征空间中学习内部分布特征密度的能量校正模型，本文提出了一种在异常检测中取得竞争性结果的方法

    

    在这项工作中，我们通过使用预训练深度分类器的特征空间研究了基于能量的模型（EBM）学习内部分布（ID）特征的密度，发现在EBM训练过程中MCMC采样的非混合性会削弱其检测性能。为了克服这一问题，我们提出了一种由混合类条件高斯分布组成的能量校正模型，与CIFAR-10/CIFAR-100 OOD检测基准上的强基线KNN检测器相比取得了良好的结果。

    arXiv:2403.10403v1 Announce Type: cross  Abstract: In this work, we study the out-of-distribution (OOD) detection problem through the use of the feature space of a pre-trained deep classifier. We show that learning the density of in-distribution (ID) features with an energy-based models (EBM) leads to competitive detection results. However, we found that the non-mixing of MCMC sampling during the EBM's training undermines its detection performance. To overcome this an energy-based correction of a mixture of class-conditional Gaussian distributions. We obtains favorable results when compared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100 OOD detection benchmarks.
    
[^19]: Isotropic3D：基于单个CLIP嵌入的图像到3D生成

    Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding

    [https://arxiv.org/abs/2403.10395](https://arxiv.org/abs/2403.10395)

    Isotropic3D是一个图像到3D生成的新方法，通过仅使用图像CLIP嵌入作为输入，让优化相对于方位角是各向同性，避免过分依赖图像导致生成的扁平或扭曲。

    

    鼓舞于越来越多预训练的2D扩散模型的可用性，通过利用分数蒸馏采样（SDS）进行图像到3D生成正在取得显著进展。大多数现有方法将新视角提升到2D扩散模型，通常以参考图像作为条件，同时在参考视图上应用严格的L2图像监督。然而过分依赖图像容易破坏2D扩散模型的归纳知识，经常导致生成平坦或扭曲的3D。在这项工作中，我们以一种新颖的角度重新审视图像到3D，并呈现Isotropic3D，一个仅以图像CLIP嵌入作为输入的图像到3D生成流水线。Isotropic3D允许优化相对于方位角是各向同性，因为仅依赖于SDS损失。我们框架的核心在于两阶段扩散模型微调。首先，我们通过替换 fine-tune了一个文本到3D扩散模型

    arXiv:2403.10395v1 Announce Type: cross  Abstract: Encouraged by the growing availability of pre-trained 2D diffusion models, image-to-3D generation by leveraging Score Distillation Sampling (SDS) is making remarkable progress. Most existing methods combine novel-view lifting from 2D diffusion models which usually take the reference image as a condition while applying hard L2 image supervision at the reference view. Yet heavily adhering to the image is prone to corrupting the inductive knowledge of the 2D diffusion model leading to flat or distorted 3D generation frequently. In this work, we reexamine image-to-3D in a novel perspective and present Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input. Isotropic3D allows the optimization to be isotropic w.r.t. the azimuth angle by solely resting on the SDS loss. The core of our framework lies in a two-stage diffusion model fine-tuning. Firstly, we fine-tune a text-to-3D diffusion model by subst
    
[^20]: 通过鞍点优化实现遗憾最小化

    Regret Minimization via Saddle Point Optimization

    [https://arxiv.org/abs/2403.10379](https://arxiv.org/abs/2403.10379)

    通过重新参数化DEC并求解相应的极小-极大程序，提出了Estimation-To-Decisions（E2D）算法的任何时候变体，成功将在线优化探索-利用权衡转化为实用算法。

    

    一系列作品通过极小-极大程序表征了遗憾最小化在顺序决策中的样本复杂性。在相应的鞍点博弈中，极小玩家针对选择引发大遗憾的混乱模型进行采样分布的优化。这个想法的最新实例是决策-估计系数（DEC），已被证明在结构化赌博机和强化学习中几乎提供了最紧的下界和上界。通过重新参数化带有置信半径的DEC偏移量，并解决相应的极小-极大程序，我们得出了Estimation-To-Decisions（E2D）算法的任何时候变体。重要的是，该算法在线优化探索-利用权衡，而不是通过分析来进行。我们的公式导致了一个适用于有限模型类和线性反馈模型的实用算法。

    arXiv:2403.10379v1 Announce Type: new  Abstract: A long line of works characterizes the sample complexity of regret minimization in sequential decision-making by min-max programs. In the corresponding saddle-point game, the min-player optimizes the sampling distribution against an adversarial max-player that chooses confusing models leading to large regret. The most recent instantiation of this idea is the decision-estimation coefficient (DEC), which was shown to provide nearly tight lower and upper bounds on the worst-case expected regret in structured bandits and reinforcement learning. By re-parametrizing the offset DEC with the confidence radius and solving the corresponding min-max program, we derive an anytime variant of the Estimation-To-Decisions (E2D) algorithm. Importantly, the algorithm optimizes the exploration-exploitation trade-off online instead of via the analysis. Our formulation leads to a practical algorithm for finite model classes and linear feedback models. We fur
    
[^21]: 通过XAI方法改善分类器性能的通用框架

    Towards a general framework for improving the performance of classifiers using XAI methods

    [https://arxiv.org/abs/2403.10373](https://arxiv.org/abs/2403.10373)

    本文提出了一个通用框架，利用XAI方法自动改善预先训练的深度学习分类器的性能，避免了重新训练复杂模型的计算开销。

    

    现代人工智能系统，特别是深度学习模型，难以理解其内部运作，因此人工智能研究人员面临挑战。可解释人工智能（XAI）检查人工智能模型的内部机制，提供有关其决策的解释。本文提出了一个通用框架，用于利用XAI方法自动改善预先训练的深度学习分类器的性能，避免了重新训练复杂模型的计算开销。具体而言，我们概述了两种不同的学习策略的可能性，分别称为基于自动编码器和编码器-解码器的，讨论了它们的关键方面。

    arXiv:2403.10373v1 Announce Type: new  Abstract: Modern Artificial Intelligence (AI) systems, especially Deep Learning (DL) models, poses challenges in understanding their inner workings by AI researchers. eXplainable Artificial Intelligence (XAI) inspects internal mechanisms of AI models providing explanations about their decisions. While current XAI research predominantly concentrates on explaining AI systems, there is a growing interest in using XAI techniques to automatically improve the performance of AI systems themselves. This paper proposes a general framework for automatically improving the performance of pre-trained DL classifiers using XAI methods, avoiding the computational overhead associated with retraining complex models from scratch. In particular, we outline the possibility of two different learning strategies for implementing this architecture, which we will call auto-encoder-based and encoder-decoder-based, and discuss their key aspects.
    
[^22]: 一种用于减轻物联网应用中数据不完整性的节能集成方法

    An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications

    [https://arxiv.org/abs/2403.10371](https://arxiv.org/abs/2403.10371)

    提出了一种用于缓解物联网应用中数据不完整性的节能集成方法ENAMLE，旨在解决SECOE的能源瓶颈问题

    

    机器学习在基于物联网的应用中变得越来越重要。然而，许多物联网生态系统的动态性和临时性对机器学习算法的有效性提出了独特挑战。其中之一是数据不完整性，即缺失的传感器读数。许多因素，包括传感器故障和/或网络中断，都可能导致数据不完整性。此外，大多数物联网系统受到严重的电力限制。重要的是，我们构建针对数据不完整性鲁棒且节能的物联网机器学习系统。本文对SECOE进行了一项实证研究-一种用于减轻物联网中数据不完整性的最新技术，关注其能源瓶颈。为了解决SECOE的能源瓶颈，我们提出了ENAMLE-一种主动的、能源感知的技术，用于减轻同时缺失数据的影响。ENAMLE在这样的意义上是独特的

    arXiv:2403.10371v1 Announce Type: cross  Abstract: Machine Learning (ML) is becoming increasingly important for IoT-based applications. However, the dynamic and ad-hoc nature of many IoT ecosystems poses unique challenges to the efficacy of ML algorithms. One such challenge is data incompleteness, which is manifested as missing sensor readings. Many factors, including sensor failures and/or network disruption, can cause data incompleteness. Furthermore, most IoT systems are severely power-constrained. It is important that we build IoT-based ML systems that are robust against data incompleteness while simultaneously being energy efficient. This paper presents an empirical study of SECOE - a recent technique for alleviating data incompleteness in IoT - with respect to its energy bottlenecks. Towards addressing the energy bottlenecks of SECOE, we propose ENAMLE - a proactive, energy-aware technique for mitigating the impact of concurrent missing data. ENAMLE is unique in the sense that it
    
[^23]: 面向概率鲁棒可扩展机器学习分类的适应性预测

    Conformal Predictions for Probabilistically Robust Scalable Machine Learning Classification

    [https://arxiv.org/abs/2403.10368](https://arxiv.org/abs/2403.10368)

    通过引入得分函数和定义适应性安全集，将可扩展分类器和适应性预测相结合，定义了一种可靠的学习框架，能够在设计初期就为分类提供稳健的算法。

    

    适应性预测可以定义可靠且稳健的学习算法，从设计初期就为分类定义了可靠的学习框架，通过将可扩展分类器的概念与统计排序理论和概率学习理论联系起来。本文通过引入得分函数的新定义和定义一组特殊的输入变量，即适应性安全集，来分析可扩展分类器和适应性预测之间的相似之处，该安全集能够识别在输入空间中满足误差覆盖保证的模式，即对于属于该集合的点观察到错误（可能不安全）标签的概率受到预定义的$\varepsilon$错误水平的限制。

    arXiv:2403.10368v1 Announce Type: cross  Abstract: Conformal predictions make it possible to define reliable and robust learning algorithms. But they are essentially a method for evaluating whether an algorithm is good enough to be used in practice. To define a reliable learning framework for classification from the very beginning of its design, the concept of scalable classifier was introduced to generalize the concept of classical classifier by linking it to statistical order theory and probabilistic learning theory. In this paper, we analyze the similarities between scalable classifiers and conformal predictions by introducing a new definition of a score function and defining a special set of input variables, the conformal safety set, which can identify patterns in the input space that satisfy the error coverage guarantee, i.e., that the probability of observing the wrong (possibly unsafe) label for points belonging to this set is bounded by a predefined $\varepsilon$ error level. W
    
[^24]: 可扩展的个人偏好稳定聚类算法

    Scalable Algorithms for Individual Preference Stable Clustering

    [https://arxiv.org/abs/2403.10365](https://arxiv.org/abs/2403.10365)

    研究了个人偏好稳定聚类的可扩展算法，通过局部搜索获得了 $O(\log n)$-IP 稳定性保证，并且在几乎线性时间内运行。

    

    在本文中，我们研究了个人偏好（IP）稳定性，这是一个捕捉聚类中个人公平性和稳定性的概念。在这个设定中，当每个数据点到其簇的平均距离不超过其到任何其他簇的平均距离的 $\alpha$ 倍时，一个聚类是 $\alpha$-IP 稳定的。在本文中，我们研究了用于 IP 稳定聚类的自然局部搜索算法。我们的分析证实了此算法的 $O(\log n)$-IP 稳定性保证，其中 $n$ 表示输入中的数据点数量。此外，通过改进局部搜索方法，我们表明其运行时间几乎是线性的，为 $\tilde{O}(nk)$。

    arXiv:2403.10365v1 Announce Type: cross  Abstract: In this paper, we study the individual preference (IP) stability, which is an notion capturing individual fairness and stability in clustering. Within this setting, a clustering is $\alpha$-IP stable when each data point's average distance to its cluster is no more than $\alpha$ times its average distance to any other cluster. In this paper, we study the natural local search algorithm for IP stable clustering. Our analysis confirms a $O(\log n)$-IP stability guarantee for this algorithm, where $n$ denotes the number of points in the input. Furthermore, by refining the local search approach, we show it runs in an almost linear time, $\tilde{O}(nk)$.
    
[^25]: 基于去噪任务难度的渐进式课程训练扩散模型

    Denoising Task Difficulty-based Curriculum for Training Diffusion Models

    [https://arxiv.org/abs/2403.10348](https://arxiv.org/abs/2403.10348)

    研究通过全面研究任务难度，发现较早时间步长的去噪任务更具挑战性，提出了基于去噪任务难度的渐进式课程训练方法。

    

    基于扩散的生成模型已成为生成建模领域强大的工具。尽管对各个时间步长和噪声水平之间的去噪进行了广泛研究，但关于去噪任务的相对难度仍存在争议。我们的研究对任务难度进行了全面的研究，重点关注收敛行为和时间步长间连续概率分布的相对熵变化。我们的观察显示，较早时间步长的去噪存在收敛缓慢和较高的相对熵，表明在这些较低时间步长上任务难度增加。基于这些观察，我们引入了一种由易到难的学习方案，借鉴渐进式学习的思想。

    arXiv:2403.10348v1 Announce Type: cross  Abstract: Diffusion-based generative models have emerged as powerful tools in the realm of generative modeling. Despite extensive research on denoising across various timesteps and noise levels, a conflict persists regarding the relative difficulties of the denoising tasks. While various studies argue that lower timesteps present more challenging tasks, others contend that higher timesteps are more difficult. To address this conflict, our study undertakes a comprehensive examination of task difficulties, focusing on convergence behavior and changes in relative entropy between consecutive probability distributions across timesteps. Our observational study reveals that denoising at earlier timesteps poses challenges characterized by slower convergence and higher relative entropy, indicating increased task difficulty at these lower timesteps. Building on these observations, we introduce an easy-to-hard learning scheme, drawing from curriculum learn
    
[^26]: 比起修改，生成更好：在图异常检测中对抗高类同性方差

    Generation is better than Modification: Combating High Class Homophily Variance in Graph Anomaly Detection

    [https://arxiv.org/abs/2403.10339](https://arxiv.org/abs/2403.10339)

    首次引入类同质性方差这一新度量，在图异常检测中提出了Homophily Edge Generation Graph Neural Network (HedGe)模型，强调生成新关系以降低类同质性方差。

    

    基于图的异常检测是图神经网络（GNNs）领域中一个重要的研究课题。我们发现，在图异常检测中，不同类别之间的同质性分布差异显著大于同质性和异质性图中的差异。我们首次引入了一个称为类同质性方差的新度量，定量描述了这一现象。为了减轻其影响，我们提出了一种名为同质性边生成图神经网络（HedGe）的新型GNN模型。以前的研究通常侧重于对原始关系进行修剪、选择或连接，我们称这些方法为修改。与这些工作不同，我们的方法强调生成新的关系，使类同质性方差较低，同时使用原始关系作为辅助。HedGe使用自关注机制从头开始对同质性邻接矩阵进行采样，并利用...

    arXiv:2403.10339v1 Announce Type: new  Abstract: Graph-based anomaly detection is currently an important research topic in the field of graph neural networks (GNNs). We find that in graph anomaly detection, the homophily distribution differences between different classes are significantly greater than those in homophilic and heterophilic graphs. For the first time, we introduce a new metric called Class Homophily Variance, which quantitatively describes this phenomenon. To mitigate its impact, we propose a novel GNN model named Homophily Edge Generation Graph Neural Network (HedGe). Previous works typically focused on pruning, selecting or connecting on original relationships, and we refer to these methods as modifications. Different from these works, our method emphasizes generating new relationships with low class homophily variance, using the original relationships as an auxiliary. HedGe samples homophily adjacency matrices from scratch using a self-attention mechanism, and leverage
    
[^27]: GreedyML：一种用于最大化子模函数的并行算法

    GreedyML: A Parallel Algorithm for Maximizing Submodular Functions

    [https://arxiv.org/abs/2403.10332](https://arxiv.org/abs/2403.10332)

    提出了一种用于在分布式存储多处理器上最大化子模函数的并行近似算法，以解决实际应用领域中海量数据集上的子模优化问题。

    

    我们描述了一种用于在分布式存储多处理器上最大化单调子模函数的并行近似算法。我们的工作受到在海量数据集上解决子模优化问题的需求的启发，用于实际应用领域，如数据摘要，机器学习和图稀疏化。我们的工作基于Barbosa、Ene、Nguyen和Ward（2015）提出的随机分布式RandGreedI算法。该算法通过将数据随机分区到所有处理器中，然后使用单个累积步骤计算分布式解决方案，其中所有处理器将它们的部分解决方案发送给一个处理器。然而，对于大问题，累积步骤可能超过处理器上可用的内存，并且执行累积的处理器可能成为计算瓶颈。

    arXiv:2403.10332v1 Announce Type: cross  Abstract: We describe a parallel approximation algorithm for maximizing monotone submodular functions subject to hereditary constraints on distributed memory multiprocessors. Our work is motivated by the need to solve submodular optimization problems on massive data sets, for practical applications in areas such as data summarization, machine learning, and graph sparsification. Our work builds on the randomized distributed RandGreedI algorithm, proposed by Barbosa, Ene, Nguyen, and Ward (2015). This algorithm computes a distributed solution by randomly partitioning the data among all the processors and then employing a single accumulation step in which all processors send their partial solutions to one processor. However, for large problems, the accumulation step could exceed the memory available on a processor, and the processor which performs the accumulation could become a computational bottleneck.   Here, we propose a generalization of the R
    
[^28]: 朝向非对抗性算法补偿

    Towards Non-Adversarial Algorithmic Recourse

    [https://arxiv.org/abs/2403.10330](https://arxiv.org/abs/2403.10330)

    在高风险情况下，重要性获得不具有对抗性特征的反事实解释。

    

    对抗性样本和反事实解释的研究方向基本上是独立增长的。 这导致最近有几项研究试图阐明它们的相似之处和差异。 最重要的是，有人认为，与反事实解释相反，对抗性样本具有独特的特征，即与基本事实相比，它们会导致误分类。 但是，现有的反事实解释和对抗性样本生成方法中所使用的计算目标和方法往往缺乏与此要求的对齐。 使用对抗性样本和反事实解释的正式定义，我们介绍了非对抗性的算法补偿，并概述了在高风险情况下，获得不具有对抗性特征的反事实解释是至关重要的。 我们随后调查了客体中不同组件的行为。

    arXiv:2403.10330v1 Announce Type: new  Abstract: The streams of research on adversarial examples and counterfactual explanations have largely been growing independently. This has led to several recent works trying to elucidate their similarities and differences. Most prominently, it has been argued that adversarial examples, as opposed to counterfactual explanations, have a unique characteristic in that they lead to a misclassification compared to the ground truth. However, the computational goals and methodologies employed in existing counterfactual explanation and adversarial example generation methods often lack alignment with this requirement. Using formal definitions of adversarial examples and counterfactual explanations, we introduce non-adversarial algorithmic recourse and outline why in high-stakes situations, it is imperative to obtain counterfactual explanations that do not exhibit adversarial characteristics. We subsequently investigate how different components in the objec
    
[^29]: 基于预训练语言模型的自动填空干扰项生成

    CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model

    [https://arxiv.org/abs/2403.10326](https://arxiv.org/abs/2403.10326)

    本文研究了通过应用预训练语言模型作为候选干扰项生成的替代方法来自动生成填空干扰项，并展示了这种PLM增强模型显著提高了性能。

    

    手动设计填空测试耗费大量时间和精力。主要挑战在于错误选项（干扰项）的选择。精心设计的干扰项提高了学习者能力评估的有效性。因此，自动生成填空干扰项的想法应运而生。本文通过探索预训练语言模型（PLMs）的应用作为候选干扰项生成的替代方法来研究填空干扰项生成。实验表明，PLM增强模型带来了显著的性能提升。我们的最佳模型将最先进的结果从14.94提升至34.17（NDCG@10分数）。我们的代码和数据集可在https://github.com/AndyChiangSH/CDGP 获取。

    arXiv:2403.10326v1 Announce Type: cross  Abstract: Manually designing cloze test consumes enormous time and efforts. The major challenge lies in wrong option (distractor) selection. Having carefully-design distractors improves the effectiveness of learner ability assessment. As a result, the idea of automatically generating cloze distractor is motivated. In this paper, we investigate cloze distractor generation by exploring the employment of pre-trained language models (PLMs) as an alternative for candidate distractor generation. Experiments show that the PLM-enhanced model brings a substantial performance improvement. Our best performing model advances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our code and dataset is available at https://github.com/AndyChiangSH/CDGP.
    
[^30]: 基于表格数据的任意时间神经网络架构搜索

    Anytime Neural Architecture Search on Tabular Data

    [https://arxiv.org/abs/2403.10318](https://arxiv.org/abs/2403.10318)

    ATLAS是第一个专为表格数据设计的任意时间神经网络架构搜索方法，引入了过滤和优化方案，结合了训练-free和基于训练的架构评估两种范式的优势

    

    随着对表格数据分析的需求增加，从手动架构设计转变为神经网络架构搜索(NAS)。这种转变需要一种高效且响应灵敏的任意时间NAS方法，能够在任何给定的时间预算内返回当前的最佳架构，并随着预算分配的增加逐渐提高架构质量。然而，关于表格数据的任意时间NAS领域仍未被探索。为此，我们引入了ATLAS，第一个专为表格数据量身定制的任意时间NAS方法。ATLAS引入了一种新颖的两阶段过滤和优化方案，结合了训练-free和基于训练的架构评估两种范式的优势。具体来说，在过滤阶段，ATLAS采用了一种新的为表格数据专门设计的零成本代理，用于高效估计候选架构的性能。

    arXiv:2403.10318v1 Announce Type: new  Abstract: The increasing demand for tabular data analysis calls for transitioning from manual architecture design to Neural Architecture Search (NAS). This transition demands an efficient and responsive anytime NAS approach that is capable of returning current optimal architectures within any given time budget while progressively enhancing architecture quality with increased budget allocation. However, the area of research on Anytime NAS for tabular data remains unexplored. To this end, we introduce ATLAS, the first anytime NAS approach tailored for tabular data. ATLAS introduces a novel two-phase filtering-and-refinement optimization scheme with joint optimization, combining the strengths of both paradigms of training-free and training-based architecture evaluation. Specifically, in the filtering phase, ATLAS employs a new zero-cost proxy specifically designed for tabular data to efficiently estimate the performance of candidate architectures, th
    
[^31]: 用于连续和高效时间序列建模的粗糙Transformer

    Rough Transformers for Continuous and Efficient Time-Series Modelling

    [https://arxiv.org/abs/2403.10288](https://arxiv.org/abs/2403.10288)

    提出了粗糙Transformer，用于在连续时间表示的输入序列上进行操作，大大降低了计算成本，对于处理医疗情境中的长程依赖性至关重要。

    

    在真实世界的医疗环境中，时间序列数据通常表现出长程依赖性，并且以不均匀间隔观察到。在这种情况下，传统的基于序列的循环模型很难处理。为了克服这一问题，研究人员用基于神经ODE的模型替换循环架构来建模非均匀采样的数据，并使用Transformer架构来考虑长程依赖。尽管这两种方法取得了成功，但对于中等长度及更长输入序列，两者都需要非常高的计算成本。为了缓解这一问题，我们引入了粗糙Transformer，这是Transformer模型的一种变体，其在输入序列的连续时间表示上运行，并且减少了计算成本，对于处理医疗情境中常见的长程依赖性至关重要。特别地，我们提出了多视图签名注意力，利用路径签名来增强传统的注意力。

    arXiv:2403.10288v1 Announce Type: cross  Abstract: Time-series data in real-world medical settings typically exhibit long-range dependencies and are observed at non-uniform intervals. In such contexts, traditional sequence-based recurrent models struggle. To overcome this, researchers replace recurrent architectures with Neural ODE-based models to model irregularly sampled data and use Transformer-based architectures to account for long-range dependencies. Despite the success of these two approaches, both incur very high computational costs for input sequences of moderate lengths and greater. To mitigate this, we introduce the Rough Transformer, a variation of the Transformer model which operates on continuous-time representations of input sequences and incurs significantly reduced computational costs, critical for addressing long-range dependencies common in medical contexts. In particular, we propose multi-view signature attention, which uses path signatures to augment vanilla attent
    
[^32]: Team Trifecta在Factify 5WQA上设定了细化调整中事实验证的标准

    Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning

    [https://arxiv.org/abs/2403.10281](https://arxiv.org/abs/2403.10281)

    Team Trifecta在Factify 5WQA上以Fine-Tuning取得了首要地位，成功超越基准准确率103％，并保持了对第二名竞争者的70%领先优势。

    

    在本文中，我们介绍了Pre-CoFactv3，这是一个由问答和文本分类组件组成的全面框架，用于事实验证。通过利用上下文学习、微调大型语言模型（LLMs）和FakeNet模型，我们解决了事实验证面临的挑战。我们的实验探讨了不同的方法，比较了不同的预训练LLMs，引入了FakeNet，并实施了各种集成方法。值得注意的是，我们的团队Trifecta在AAAI-24 Factify 3.0研讨会上获得了第一名，比基准准确率高出103%，并保持了对第二名竞争对手的70%领先优势。这一成功突显了我们方法的有效性及其对推进事实验证研究的潜在贡献。

    arXiv:2403.10281v1 Announce Type: cross  Abstract: In this paper, we present Pre-CoFactv3, a comprehensive framework comprised of Question Answering and Text Classification components for fact verification. Leveraging In-Context Learning, Fine-tuned Large Language Models (LLMs), and the FakeNet model, we address the challenges of fact verification. Our experiments explore diverse approaches, comparing different Pre-trained LLMs, introducing FakeNet, and implementing various ensemble methods. Notably, our team, Trifecta, secured first place in the AAAI-24 Factify 3.0 Workshop, surpassing the baseline accuracy by 103% and maintaining a 70% lead over the second competitor. This success underscores the efficacy of our approach and its potential contributions to advancing fact verification research.
    
[^33]: DSP：多维Transformer的动态序列并行性

    DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers

    [https://arxiv.org/abs/2403.10266](https://arxiv.org/abs/2403.10266)

    动态序列并行性（DSP）为多维Transformer模型引入了一种高效的序列并行方法，通过动态切换并行维度实现对多维注意力模型的优化。

    

    通过本文介绍的动态序列并行性（DSP）方法，可以为多维Transformer模型实现高效的序列并行性。其关键思想是根据当前计算阶段动态切换并行性维度，利用多维注意力的潜在特性。这种动态维度切换使得序列并行性在多维模型中具有最小的通信开销。

    arXiv:2403.10266v1 Announce Type: cross  Abstract: Scaling large models with long sequences across applications like language generation, video generation and multimodal tasks requires efficient sequence parallelism. However, existing sequence parallelism methods all assume a single sequence dimension and fail to adapt to multi-dimensional transformer architectures that perform attention calculations across different dimensions. This paper introduces Dynamic Sequence Parallelism (DSP), a novel approach to enable efficient sequence parallelism for multi-dimensional transformer models. The key idea is to dynamically switch the parallelism dimension according to the current computation stage, leveraging the potential characteristics of multi-dimensional attention. This dynamic dimension switching allows sequence parallelism with minimal communication overhead compared to applying traditional single-dimension parallelism to multi-dimensional models. Experiments show DSP improves end-to-end
    
[^34]: 利用分类模型和LSTM模型在工业中进行预测性维护的综合研究

    Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model

    [https://arxiv.org/abs/2403.10259](https://arxiv.org/abs/2403.10259)

    该研究探讨利用分类模型和LSTM模型在工业中进行预测性维护的方法，通过人工智能技术实现对机器故障更准确和高效的预测和分析。

    

    在当今技术驱动的时代，对预测性维护和先进诊断的迫切需求不仅仅限于航空领域，还包括对旋转和移动机器中损坏、故障和操作缺陷的识别。实施这样的服务不仅可以缩减维护成本，还可以延长机器寿命，确保卓越的操作效率。此外，这也是一种防范潜在事故或灾难性事件的预防措施。人工智能的出现彻底改变了各行业的维护方式，实现了对机器故障更准确和高效的预测和分析，从而节约了时间和资源。我们提出的研究旨在探讨各种机器学习分类技术，包括支持向量机（SVM）、随机森林、逻辑回归以及基于卷积神经网络LSTM的机器性能预测与分析。

    arXiv:2403.10259v1 Announce Type: cross  Abstract: In today's technology-driven era, the imperative for predictive maintenance and advanced diagnostics extends beyond aviation to encompass the identification of damages, failures, and operational defects in rotating and moving machines. Implementing such services not only curtails maintenance costs but also extends machine lifespan, ensuring heightened operational efficiency. Moreover, it serves as a preventive measure against potential accidents or catastrophic events. The advent of Artificial Intelligence (AI) has revolutionized maintenance across industries, enabling more accurate and efficient prediction and analysis of machine failures, thereby conserving time and resources. Our proposed study aims to delve into various machine learning classification techniques, including Support Vector Machine (SVM), Random Forest, Logistic Regression, and Convolutional Neural Network LSTM-Based, for predicting and analyzing machine performance. 
    
[^35]: 开放的粒球知识迁移下的持续特征选择

    Open Continual Feature Selection via Granular-Ball Knowledge Transfer

    [https://arxiv.org/abs/2403.10253](https://arxiv.org/abs/2403.10253)

    提出了一种开放环境下的持续特征选择方法，结合持续学习和粒球计算技术，以检测未知类别并促进先前学习到的知识转移。

    

    本文提出了一个新颖的框架用于在数据预处理中持续进行特征选择（CFS），特别是在一个开放动态的环境中，未知类别可能会出现。该方法结合了持续学习（CL）和粒球计算（GBC）的优势，旨在构建一个粒球知识库以检测未知类别，并促进先前学习到的知识的转移，进一步进行特征选择。

    arXiv:2403.10253v1 Announce Type: new  Abstract: This paper presents a novel framework for continual feature selection (CFS) in data preprocessing, particularly in the context of an open and dynamic environment where unknown classes may emerge. CFS encounters two primary challenges: the discovery of unknown knowledge and the transfer of known knowledge. To this end, the proposed CFS method combines the strengths of continual learning (CL) with granular-ball computing (GBC), which focuses on constructing a granular-ball knowledge base to detect unknown classes and facilitate the transfer of previously learned knowledge for further feature selection. CFS consists of two stages: initial learning and open learning. The former aims to establish an initial knowledge base through multi-granularity representation using granular-balls. The latter utilizes prior granular-ball knowledge to identify unknowns, updates the knowledge base for granular-ball knowledge transfer, reinforces old knowledge
    
[^36]: 可解释的机器学习用于生存分析

    Interpretable Machine Learning for Survival Analysis

    [https://arxiv.org/abs/2403.10250](https://arxiv.org/abs/2403.10250)

    可解释的机器学习在生存分析中的应用促进了透明度和公平性，揭示了模型的潜在偏见和限制，并提供了更符合数学原理的特征影响和风险因素预测方法。

    

    随着黑盒机器学习模型的传播和快速进步，可解释的机器学习（IML）领域或可解释的人工智能（XAI）在过去十年中变得越来越重要。 这在生存分析领域尤为重要，其中采用IML技术促进了透明度、问责制和公平性，特别是在临床决策过程、有针对性疗法的开发、干预或其他医学或与医疗保健相关的环境中。 具体来说，可解释性可以揭示生存模型的潜在偏见和局限性，并提供更符合数学原理的方法来理解哪些特征对预测有影响或构成风险因素。 然而，缺乏即时可用的IML方法可能已经阻碍了医学从业者和公共卫生政策制定者充分利用机器学习的潜力。

    arXiv:2403.10250v1 Announce Type: cross  Abstract: With the spread and rapid advancement of black box machine learning models, the field of interpretable machine learning (IML) or explainable artificial intelligence (XAI) has become increasingly important over the last decade. This is particularly relevant for survival analysis, where the adoption of IML techniques promotes transparency, accountability and fairness in sensitive areas, such as clinical decision making processes, the development of targeted therapies, interventions or in other medical or healthcare related contexts. More specifically, explainability can uncover a survival model's potential biases and limitations and provide more mathematically sound ways to understand how and which features are influential for prediction or constitute risk factors. However, the lack of readily available IML methods may have deterred medical practitioners and policy makers in public health from leveraging the full potential of machine lea
    
[^37]: 通过对全连接神经网络进行非光滑正则化的矩阵补全

    Matrix Completion via Nonsmooth Regularization of Fully Connected Neural Networks

    [https://arxiv.org/abs/2403.10232](https://arxiv.org/abs/2403.10232)

    通过对全连接神经网络进行非光滑正则化，可以控制过拟合问题，提高矩阵补全性能。

    

    传统的矩阵补全方法通过假设矩阵具有低秩来逼近缺失值，从而导致缺失值的线性逼近。已经表明，使用非线性估计器（如深度神经网络）可以获得更好的性能。深度全连接神经网络（FCNN）是矩阵补全最适合的架构之一，由于其高容量而导致过拟合，进而导致泛化能力低。本文通过在中间表示的 $\ell_{1}$ 范数和权重矩阵的核范数方面对FCNN模型进行正则化来控制过拟合。因此，得到的正则化目标函数变得非光滑和非凸，即现有的基于梯度的方法无法应用于我们的模型。我们提出了一种近端梯度方法的变体，并研究其收敛到临界点。在FCNN的初始时期。

    arXiv:2403.10232v1 Announce Type: cross  Abstract: Conventional matrix completion methods approximate the missing values by assuming the matrix to be low-rank, which leads to a linear approximation of missing values. It has been shown that enhanced performance could be attained by using nonlinear estimators such as deep neural networks. Deep fully connected neural networks (FCNNs), one of the most suitable architectures for matrix completion, suffer from over-fitting due to their high capacity, which leads to low generalizability. In this paper, we control over-fitting by regularizing the FCNN model in terms of the $\ell_{1}$ norm of intermediate representations and nuclear norm of weight matrices. As such, the resulting regularized objective function becomes nonsmooth and nonconvex, i.e., existing gradient-based methods cannot be applied to our model. We propose a variant of the proximal gradient method and investigate its convergence to a critical point. In the initial epochs of FCNN
    
[^38]: 少即是多：大规模知识图谱上的一次性子图推理

    Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs

    [https://arxiv.org/abs/2403.10231](https://arxiv.org/abs/2403.10231)

    提出了一种在大规模知识图谱上进行高效和自适应预测的一次性子图链接预测方法，通过将预测过程分解为从查询中提取一个子图并在该单个、查询相关子图上进行预测的两个步骤，利用非参数化和计算高效的启发式方法来提高效率。

    

    要在知识图谱（KG）上推导新的事实，链接预测器从图结构中学习，并收集局部证据以找到对给定查询的答案。然而，现有方法由于利用整个KG进行预测而存在严重的可扩展性问题，这阻碍了它们在大规模KG上的应用，并且无法直接通过常规抽样方法解决。 在这项工作中，我们提出了一次性子图链接预测以实现高效且自适应的预测。 设计原则是，预测过程不直接作用于整个KG，而是分为两个步骤，即（i）根据查询仅提取一个子图和（ii）在这个单一的、查询相关的子图上进行预测。 我们发现，非参数化和计算高效的启发式方法个性化PageRank（PPR）可以有效地识别潜在答案和支持证据。

    arXiv:2403.10231v1 Announce Type: cross  Abstract: To deduce new facts on a knowledge graph (KG), a link predictor learns from the graph structure and collects local evidence to find the answer to a given query. However, existing methods suffer from a severe scalability problem due to the utilization of the whole KG for prediction, which hinders their promise on large scale KGs and cannot be directly addressed by vanilla sampling methods. In this work, we propose the one-shot-subgraph link prediction to achieve efficient and adaptive prediction. The design principle is that, instead of directly acting on the whole KG, the prediction procedure is decoupled into two steps, i.e., (i) extracting only one subgraph according to the query and (ii) predicting on this single, query dependent subgraph. We reveal that the non-parametric and computation-efficient heuristics Personalized PageRank (PPR) can effectively identify the potential answers and supporting evidence. With efficient subgraph-b
    
[^39]: 从混沌到清晰：天文观测中的时间序列异常检测

    From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations

    [https://arxiv.org/abs/2403.10220](https://arxiv.org/abs/2403.10220)

    提出了AERO，一个专为天文观测中无监督异常检测量身定制的新颖两阶段框架，擅长处理天文观测中独立但受到随机并发噪声干扰的特征。

    

    随着天文设施的发展，这些设施观测到的大规模时间序列数据被收集起来。分析这些天文观测中的异常对于揭示潜在的天体事件和物理现象至关重要，从而推动科学研究过程。然而，现有的时间序列异常检测方法在处理天文观测的独特特征方面存在不足，其中每颗星体本质上是独立的，但受到随机并发噪声的干扰，导致假警报率较高。为了克服这些挑战，我们提出了AERO，这是一个专为天文观测中的无监督异常检测量身定制的新颖两阶段框架。在第一阶段，我们采用基于Transformer的编码器-解码器架构来学习每个变量（即星体）上的正常时间模式，以与变量独立性的特征保持一致。在第二阶段，我们e

    arXiv:2403.10220v1 Announce Type: cross  Abstract: With the development of astronomical facilities, large-scale time series data observed by these facilities is being collected. Analyzing anomalies in these astronomical observations is crucial for uncovering potential celestial events and physical phenomena, thus advancing the scientific research process. However, existing time series anomaly detection methods fall short in tackling the unique characteristics of astronomical observations where each star is inherently independent but interfered by random concurrent noise, resulting in a high rate of false alarms. To overcome the challenges, we propose AERO, a novel two-stage framework tailored for unsupervised anomaly detection in astronomical observations. In the first stage, we employ a Transformer-based encoder-decoder architecture to learn the normal temporal patterns on each variate (i.e., star) in alignment with the characteristic of variate independence. In the second stage, we e
    
[^40]: 在JPEG-LDPC压缩图像上学习：利用综合症状进行分类

    Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes

    [https://arxiv.org/abs/2403.10202](https://arxiv.org/abs/2403.10202)

    在这篇论文中，提出了一种在JPEG-LDPC压缩图像上进行分类的方法，通过利用LDPC码的内部代码结构，使用GRU进行训练，从而实现了高效的图像分类。

    

    在面向目标的通信中，接收者的目标通常是应用深度学习模型，而不是重建原始数据。 在这种情况下，在接收器上无需进行任何先前解码即可直接对压缩数据进行学习，有望增强推断模型的时间效率。 本文提出了一种替代方法，其中经熵编码是用低密度奇偶校验（LDPC）码实现的。我们假设深度学习模型可以更有效地利用LDPC码的内部代码结构。 在接收器端，我们利用一种特定类型的循环神经网络（RNN），具体来说是用于图像分类的门控循环单元（GRU）进行训练。 我们的数值结果表明，基于LDPC的分类有望通过基于数据综合症状的图像分类明显地提高性能。

    arXiv:2403.10202v1 Announce Type: cross  Abstract: In goal-oriented communications, the objective of the receiver is often to apply a Deep-Learning model, rather than reconstructing the original data. In this context, direct learning over compressed data, without any prior decoding, holds promise for enhancing the time-efficient execution of inference models at the receiver. However, conventional entropic-coding methods like Huffman and Arithmetic break data structure, rendering them unsuitable for learning without decoding. In this paper, we propose an alternative approach in which entropic coding is realized with Low-Density Parity Check (LDPC) codes. We hypothesize that Deep Learning models can more effectively exploit the internal code structure of LDPC codes. At the receiver, we leverage a specific class of Recurrent Neural Networks (RNNs), specifically Gated Recurrent Unit (GRU), trained for image classification. Our numerical results indicate that classification based on LDPC-co
    
[^41]: 基于感知质量的模型训练在标注者标签不确定性下

    Perceptual Quality-based Model Training under Annotator Label Uncertainty

    [https://arxiv.org/abs/2403.10190](https://arxiv.org/abs/2403.10190)

    标注者标签不确定性影响模型泛化能力和预测不确定性，现有不确定性估计算法无法应对，提出一种基于感知质量的训练方法以缓解性能下降

    

    arXiv:2403.10190v1 公告类型:跨领域. 标注者在数据标记过程中存在分歧，可称为标注者标签不确定性。标注者标签不确定性表现为标记质量的变化。每个样本使用单个低质量标注进行训练会导致模型可靠性下降。本研究首先考察了标注者标签不确定性对模型的泛化能力和预测不确定性的影响。我们观察到，模型的泛化能力和预测不确定性会随着低质量的嘈杂标签的存在而降低。同时，我们评估现有的不确定性估计算法表明它们无法应对标注者标签不确定性。为了减轻性能下降，先前的方法表明使用来自多个独立标注者收集的标签进行训练可以增强泛化能力。然而，它们需要大量标注。因此，我们引入一种新的基于感知质量的方法

    arXiv:2403.10190v1 Announce Type: cross  Abstract: Annotators exhibit disagreement during data labeling, which can be termed as annotator label uncertainty. Annotator label uncertainty manifests in variations of labeling quality. Training with a single low-quality annotation per sample induces model reliability degradations. In this work, we first examine the effects of annotator label uncertainty in terms of the model's generalizability and prediction uncertainty. We observe that the model's generalizability and prediction uncertainty degrade with the presence of low-quality noisy labels. Meanwhile, our evaluation of existing uncertainty estimation algorithms indicates their incapability in response to annotator label uncertainty. To mitigate performance degradation, prior methods show that training models with labels collected from multiple independent annotators can enhance generalizability. However, they require massive annotations. Hence, we introduce a novel perceptual quality-ba
    
[^42]: 抓住一切：将教师增强策略梯度学习与实例分割相结合，用于抓取任意物体

    Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects

    [https://arxiv.org/abs/2403.10187](https://arxiv.org/abs/2403.10187)

    提出了一种新颖的两阶段学习框架TAPG，将强化学习和策略蒸馏相结合，在抓取任意物体时取得了良好表现。

    

    交互式从混乱环境中抓取物体，类似于人类灵巧，是机器人学习中存在已久的问题之一。挑战源于视觉感知的复杂性，对精准运动技能的需求，以及两者之间的复杂相互作用。本文介绍了一种新颖的两阶段学习框架Teacher-Augmented Policy Gradient (TAPG)，该框架将强化学习和策略蒸馏相结合。通过训练一个教师策略来掌握基于物体位置信息的运动控制，TAPG促进了基于物体分割的感觉运动策略的指导性但自适应学习。我们通过使用Segment Anything模型进行零样本从仿真到实际机器人的传输，实现了对各种物体的熟练抓取。此外，我们展示了在仿真和真实世界中基于人类可理解提示的混乱场景中训练的策略能够熟练地抓取各种物体。

    arXiv:2403.10187v1 Announce Type: cross  Abstract: Interactive grasping from clutter, akin to human dexterity, is one of the longest-standing problems in robot learning. Challenges stem from the intricacies of visual perception, the demand for precise motor skills, and the complex interplay between the two. In this work, we present Teacher-Augmented Policy Gradient (TAPG), a novel two-stage learning framework that synergizes reinforcement learning and policy distillation. After training a teacher policy to master the motor control based on object pose information, TAPG facilitates guided, yet adaptive, learning of a sensorimotor policy, based on object segmentation. We zero-shot transfer from simulation to a real robot by using Segment Anything Model for promptable object segmentation. Our trained policies adeptly grasp a wide variety of objects from cluttered scenarios in simulation and the real world based on human-understandable prompts. Furthermore, we show robust zero-shot transfe
    
[^43]: 用更便宜的神经网络集成实现可靠的不确定性：工业零部件分类案例研究

    Reliable uncertainty with cheaper neural network ensembles: a case study in industrial parts classification

    [https://arxiv.org/abs/2403.10182](https://arxiv.org/abs/2403.10182)

    研究在工业零部件分类中探讨了利用更便宜的神经网络集成实现可靠的不确定性估计的方法

    

    在运筹学(OR)中，预测模型经常会遇到数据分布与训练数据分布不同的场景。近年来，神经网络(NNs)在图像分类等领域的出色性能使其在OR中备受关注。然而，当面对OOD数据时，NNs往往会做出自信但不正确的预测。不确定性估计为自信的模型提供了一个解决方案，当输出应(不应)被信任时进行通信。因此，在OR领域中，NNs中的可靠不确定性量化至关重要。由多个独立NNs组成的深度集合已经成为一种有前景的方法，不仅提供强大的预测准确性，还能可靠地估计不确定性。然而，它们的部署由于较大的计算需求而具有挑战性。最近的基础研究提出了更高效的NN集成，即sna

    arXiv:2403.10182v1 Announce Type: new  Abstract: In operations research (OR), predictive models often encounter out-of-distribution (OOD) scenarios where the data distribution differs from the training data distribution. In recent years, neural networks (NNs) are gaining traction in OR for their exceptional performance in fields such as image classification. However, NNs tend to make confident yet incorrect predictions when confronted with OOD data. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Hence, reliable uncertainty quantification in NNs is crucial in the OR domain. Deep ensembles, composed of multiple independent NNs, have emerged as a promising approach, offering not only strong predictive accuracy but also reliable uncertainty estimation. However, their deployment is challenging due to substantial computational demands. Recent fundamental research has proposed more efficient NN ensembles, namely the sna
    
[^44]: 机器学习中的重要性加权简要调查

    A Short Survey on Importance Weighting for Machine Learning

    [https://arxiv.org/abs/2403.10175](https://arxiv.org/abs/2403.10175)

    重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质

    

    重要性加权是统计学和机器学习中的一项基本程序，根据某种意义上实例的重要性对目标函数或概率分布进行加权。这一简单而有用的思想的广泛应用导致了许多重要性加权的应用。例如，据知，在关于训练和测试分布之间差异的假设下的监督学习，通过密度比的重要性加权可以保证统计上期望的性质。这项调查总结了机器学习和相关研究中重要性加权的广泛应用。

    arXiv:2403.10175v1 Announce Type: cross  Abstract: Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research.
    
[^45]: 通过不确定性实现可解释性：神经网络中可信赖的决策制定

    Explainability through uncertainty: Trustworthy decision-making with neural networks

    [https://arxiv.org/abs/2403.10168](https://arxiv.org/abs/2403.10168)

    本文提出了一个通用的不确定性框架，将机器学习模型中的不确定性估计定位为XAI技术，并提供了解释输出结果时是否应该信任的方法。

    

    不确定性是任何机器学习模型的一个关键特征，尤其在神经网络中尤为重要，因为神经网络往往过于自信。不确定性在数据分布发生变化时尤为令人担忧，当数据分布偏离训练数据分布时，模型性能会悄无声息地下降。不确定性估计提供了解决过于自信模型的方法，指示何时应该（不应该）信任输出结果。虽然关于不确定性估计的方法已经得到发展，但尚未明确定义与可解释人工智能（XAI）领域的关系。此外，运筹学领域的文献忽略了不确定性估计的可操作性组成部分，并且未考虑到数据分布的变化。本文提出了一个通用的不确定性框架，贡献主要体现在三个方面：（i）将机器学习模型中的不确定性估计定位为XAI技术，提供局部的，模型特定的解释

    arXiv:2403.10168v1 Announce Type: new  Abstract: Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific expla
    
[^46]: CoReEcho: 2D+时间超声心动图分析的连续表示学习

    CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis

    [https://arxiv.org/abs/2403.10164](https://arxiv.org/abs/2403.10164)

    CoReEcho提出了针对直接EF回归的连续表示学习框架，在最大的超声心动图数据集上表现优越。

    

    深度学习模型一直在不同模态的医学图像分析方面取得进展，包括超声心动图，在提供全面的端到端训练流水线的同时。然而，端到端训练流水线使得学习到的表示难以解释，并且可能无法捕获超声心动图片段之间的连续关系，导致存在虚假相关性，可能对泛化能力产生负面影响。为了缓解这一问题，我们提出了CoReEcho，这是一个强调针对直接EF回归的连续表示的新型训练框架。我们的广泛实验证明CoReEcho：1）在最大的超声心动图数据集（EchoNet-Dynamic）上表现优于当前的最先进技术（SOTA），平均绝对误差为3.90和R2 o

    arXiv:2403.10164v1 Announce Type: cross  Abstract: Deep learning (DL) models have been advancing automatic medical image analysis on various modalities, including echocardiography, by offering a comprehensive end-to-end training pipeline. This approach enables DL models to regress ejection fraction (EF) directly from 2D+time echocardiograms, resulting in superior performance. However, the end-to-end training pipeline makes the learned representations less explainable. The representations may also fail to capture the continuous relation among echocardiogram clips, indicating the existence of spurious correlations, which can negatively affect the generalization. To mitigate this issue, we propose CoReEcho, a novel training framework emphasizing continuous representations tailored for direct EF regression. Our extensive experiments demonstrate that CoReEcho: 1) outperforms the current state-of-the-art (SOTA) on the largest echocardiography dataset (EchoNet-Dynamic) with MAE of 3.90 & R2 o
    
[^47]: 从离线偏好中学习在线策略

    Online Policy Learning from Offline Preferences

    [https://arxiv.org/abs/2403.10160](https://arxiv.org/abs/2403.10160)

    引入了一个框架，将离线偏好和虚拟偏好结合起来用于基于偏好的强化学习，以解决在线学习中奖励函数泛化性问题。

    

    在基于偏好的强化学习（PbRL）中，人类反馈被称为偏好，用于学习奖励函数。为了加快偏好收集的速度，最近的研究利用了离线偏好，即收集用于某些离线数据的偏好。在这种情况下，学习的奖励函数适合于离线数据。如果学习代理展现出与离线数据不重叠的行为，学习的奖励函数可能会遇到泛化问题。为了解决这个问题，本研究引入了一个框架，将离线偏好和虚拟偏好结合起来，用于PbRL，虚拟偏好是代理的行为与离线数据之间的比较。关键是，奖励函数可以使用虚拟偏好追踪代理的行为，从而为代理提供良好对齐的指导。通过连续控制任务的实验，本研究展示了效果。

    arXiv:2403.10160v1 Announce Type: new  Abstract: In preference-based reinforcement learning (PbRL), a reward function is learned from a type of human feedback called preference. To expedite preference collection, recent works have leveraged \emph{offline preferences}, which are preferences collected for some offline data. In this scenario, the learned reward function is fitted on the offline data. If a learning agent exhibits behaviors that do not overlap with the offline data, the learned reward function may encounter generalizability issues. To address this problem, the present study introduces a framework that consolidates offline preferences and \emph{virtual preferences} for PbRL, which are comparisons between the agent's behaviors and the offline data. Critically, the reward function can track the agent's behaviors using the virtual preferences, thereby offering well-aligned guidance to the agent. Through experiments on continuous control tasks, this study demonstrates the effect
    
[^48]: 函数图卷积网络：一个统一的多任务和多模态学习框架，促进健康和社会关怀洞见

    Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights

    [https://arxiv.org/abs/2403.10158](https://arxiv.org/abs/2403.10158)

    该论文提出了一个新颖的函数图卷积网络框架，结合了函数数据分析和图卷积网络，解决了数字健康和纵向研究中的多任务和多模态学习复杂性，关键创新包括任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图进行数据解释。

    

    本文介绍了一种新颖的函数图卷积网络（funGCN）框架，将函数数据分析和图卷积网络相结合，以解决数字健康和纵向研究中的多任务和多模态学习的复杂性。随着健康解决方案对改善医疗保健和社会支持的重要性日益增长，确保各年龄段的健康生活和促进幸福感，funGCN提供了一种统一的方法来处理多个实体的多元纵向数据，并确保即使在样本量较小的情况下也具有可解释性。关键创新包括管理不同数据类型的任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图以获取洞察性数据解释。通过模拟实验和实际数据应用验证了funGCN的有效性。

    arXiv:2403.10158v1 Announce Type: cross  Abstract: This paper introduces a novel Functional Graph Convolutional Network (funGCN) framework that combines Functional Data Analysis and Graph Convolutional Networks to address the complexities of multi-task and multi-modal learning in digital health and longitudinal studies. With the growing importance of health solutions to improve health care and social support, ensure healthy lives, and promote well-being at all ages, funGCN offers a unified approach to handle multivariate longitudinal data for multiple entities and ensures interpretability even with small sample sizes. Key innovations include task-specific embedding components that manage different data types, the ability to perform classification, regression, and forecasting, and the creation of a knowledge graph for insightful data interpretation. The efficacy of funGCN is validated through simulation experiments and a real-data application.
    
[^49]: 改进医学多模态对比学习与专家注释

    Improving Medical Multi-modal Contrastive Learning with Expert Annotations

    [https://arxiv.org/abs/2403.10153](https://arxiv.org/abs/2403.10153)

    eCLIP是一种改进的CLIP模型，通过集成专家注释和混合增强来应对医学影像分析中的数据稀缺和模态差距挑战，提高了模型学习效果

    

    我们介绍了一种增强版CLIP模型——eCLIP，它集成了放射科医生眼球注视热图形式的专家注释。它解决了对比多模态医学影像分析中的关键挑战，尤其是数据稀缺和“模态差距”——图像和文本嵌入之间存在的显著差异，降低了表示的质量并阻碍了跨模态互操作性。eCLIP集成了一个热图处理器，并利用混合增强来有效利用稀缺的专家注释，从而提高模型的学习效果。eCLIP设计为通用的，适用于任何形式的CLIP变体，无需修改核心架构。通过对多个任务的详细评估，包括零样本推断、线性探针、跨模态检索以及使用冻结的大型语言模型进行放射学报告的检索增强生成（RAG），eCLIP展示了其...

    arXiv:2403.10153v1 Announce Type: cross  Abstract: We introduce eCLIP, an enhanced version of the CLIP model that integrates expert annotations in the form of radiologist eye-gaze heatmaps. It tackles key challenges in contrastive multi-modal medical imaging analysis, notably data scarcity and the "modality gap" -- a significant disparity between image and text embeddings that diminishes the quality of representations and hampers cross-modal interoperability. eCLIP integrates a heatmap processor and leverages mixup augmentation to efficiently utilize the scarce expert annotations, thus boosting the model's learning effectiveness. eCLIP is designed to be generally applicable to any variant of CLIP without requiring any modifications of the core architecture. Through detailed evaluations across several tasks, including zero-shot inference, linear probing, cross-modal retrieval, and Retrieval Augmented Generation (RAG) of radiology reports using a frozen Large Language Model, eCLIP showca
    
[^50]: NLP验证：走向一种通用的用于认证鲁棒性的方法论

    NLP Verification: Towards a General Methodology for Certifying Robustness

    [https://arxiv.org/abs/2403.10144](https://arxiv.org/abs/2403.10144)

    本文尝试总结和评估由该领域迄今进展而形成的NLP验证流程的一般组成部分，贡献在于提出了将句子嵌入连续空间得到的可验证子空间的一般描述。

    

    深度神经网络在自然语言处理（NLP）领域取得了显著成功，确保它们的安全性和可靠性至关重要：在安全关键的情境中，这些模型必须对变化或攻击具有鲁棒性，并能对其输出给出保证。与计算机视觉不同，NLP缺乏一个统一的验证方法论，尽管近年来文献中取得了一些进展，但对于NLP验证的实用问题常常涉及不深。在本文中，我们尝试提炼和评估一个NLP验证流程的一般组成部分，该流程来源于迄今为止该领域的进展。我们的贡献有两方面：首先，我们给出了将句子嵌入连续空间得到的可验证子空间的一般描述。我们确定了可验证子空间的语义泛化技术挑战，并提出了一种有效处理的方法。

    arXiv:2403.10144v1 Announce Type: cross  Abstract: Deep neural networks have exhibited substantial success in the field of Natural Language Processing (NLP) and ensuring their safety and reliability is crucial: there are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Unlike Computer Vision, NLP lacks a unified verification methodology and, despite recent advancements in literature, they are often light on the pragmatical issues of NLP verification. In this paper, we make an attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we give a general characterisation of verifiable subspaces that result from embedding sentences into continuous spaces. We identify, and give an effective method to deal with, the technical challenge of semantic generalisability of verified subspaces; and propose it a
    
[^51]: 正则化驱动的深度状态空间模型中的高效持续学习

    Regularization-Based Efficient Continual Learning in Deep State-Space Models

    [https://arxiv.org/abs/2403.10123](https://arxiv.org/abs/2403.10123)

    提出了一种正则化驱动的深度状态空间模型，实现了高效的持续学习，能够在多个动态系统建模时进行有效更新，并且通过实验证实了其有效性

    

    最近几年，由于其对动态系统具有强大的建模能力，深度状态空间模型（DSSMs）已经变得越来越受欢迎。然而，现有的DSSM工作局限于单任务建模，这需要在重新访问之前的任务时利用历史任务数据进行重新训练。为了解决这一局限性，我们提出了持续学习DSSMs（CLDSSMs），能够适应不断变化的任务而不会发生灾难性遗忘。我们提出的CLDSSMs集成了主流基于正则化的持续学习（CL）方法，确保在对多个动态系统建模时高效更新，保持不变的计算和内存成本。我们还对应用于各自CLDSSMs的每种CL方法进行了全面的成本分析，并通过对真实世界数据集的实验来展示CLDSSMs的有效性。结果证实，虽然各种竞争的CL方法具有不同的优点，但所提出的CLDSSMs始终保持一致。

    arXiv:2403.10123v1 Announce Type: new  Abstract: Deep state-space models (DSSMs) have gained popularity in recent years due to their potent modeling capacity for dynamic systems. However, existing DSSM works are limited to single-task modeling, which requires retraining with historical task data upon revisiting a forepassed task. To address this limitation, we propose continual learning DSSMs (CLDSSMs), which are capable of adapting to evolving tasks without catastrophic forgetting. Our proposed CLDSSMs integrate mainstream regularization-based continual learning (CL) methods, ensuring efficient updates with constant computational and memory costs for modeling multiple dynamic systems. We also conduct a comprehensive cost analysis of each CL method applied to the respective CLDSSMs, and demonstrate the efficacy of CLDSSMs through experiments on real-world datasets. The results corroborate that while various competing CL methods exhibit different merits, the proposed CLDSSMs consistentl
    
[^52]: 知识图谱上复杂查询回答的元算子

    Meta Operator for Complex Query Answering on Knowledge Graphs

    [https://arxiv.org/abs/2403.10110](https://arxiv.org/abs/2403.10110)

    本研究提出了一种元学习算法，用于在知识图谱上回答复杂查询，通过学习元算子并将其适应于各种复杂查询，实现了泛化性能的提升。

    

    知识图谱包含有信息性的事实知识，但通常被认为是不完整的。为了在不完整知识下回答复杂查询，提出了基于学习的复杂查询回答（CQA）模型，直接从查询-答案样本中学习，避免直接遍历不完整的图数据。现有研究将复杂查询回答模型的训练制定为多任务学习，并需要大量的训练样本。在这项工作中，我们探讨了复杂查询的组合结构，并认为不同的逻辑运算符类型，而不是不同的复杂查询类型，是改进泛化性能的关键。因此，我们提出了一种元学习算法，学习元运算符并将其适应于各种复杂查询下的不同运算符实例。实证结果表明，学习元算子比学习原始CQA或元更为有效。

    arXiv:2403.10110v1 Announce Type: cross  Abstract: Knowledge graphs contain informative factual knowledge but are considered incomplete. To answer complex queries under incomplete knowledge, learning-based Complex Query Answering (CQA) models are proposed to directly learn from the query-answer samples to avoid the direct traversal of incomplete graph data. Existing works formulate the training of complex query answering models as multi-task learning and require a large number of training samples. In this work, we explore the compositional structure of complex queries and argue that the different logical operator types, rather than the different complex query types, are the key to improving generalizability. Accordingly, we propose a meta-learning algorithm to learn the meta-operators with limited data and adapt them to different instances of operators under various complex queries. Empirical results show that learning meta-operators is more effective than learning original CQA or meta
    
[^53]: 使用贝叶斯强化学习的信念辅助导航以避免盲点中的人类

    Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots

    [https://arxiv.org/abs/2403.10105](https://arxiv.org/abs/2403.10105)

    使用BNBRL+算法，结合部分可观察马尔可夫决策过程和贝叶斯神经网络，实现了在不可观察区域评估风险和制定移动策略的目的，并通过整合动态关系和社会规范，实现了社交感知导航。

    

    移动机器人导航的最新研究集中在拥挤环境中的社交感知导航。然而，现有方法未能充分考虑人机交互，并要求来自全向传感器的准确位置信息，使它们不适用于实际应用。针对这一需求，本研究引入了一种新颖算法BNBRL+，基于部分可观察马尔可夫决策过程框架，评估不可观察区域的风险，并在不确定性下制定移动策略。BNBRL+将信念算法与贝叶斯神经网络结合，根据人类的位置数据概率推断信念。它进一步整合了机器人、人类和推断信念之间的动态关系，确定导航路径，并在奖励函数内嵌入社会规范，从而促进社交感知导航。通过不同风险的实验

    arXiv:2403.10105v1 Announce Type: cross  Abstract: Recent research on mobile robot navigation has focused on socially aware navigation in crowded environments. However, existing methods do not adequately account for human robot interactions and demand accurate location information from omnidirectional sensors, rendering them unsuitable for practical applications. In response to this need, this study introduces a novel algorithm, BNBRL+, predicated on the partially observable Markov decision process framework to assess risks in unobservable areas and formulate movement strategies under uncertainty. BNBRL+ consolidates belief algorithms with Bayesian neural networks to probabilistically infer beliefs based on the positional data of humans. It further integrates the dynamics between the robot, humans, and inferred beliefs to determine the navigation paths and embeds social norms within the reward function, thereby facilitating socially aware navigation. Through experiments in various risk
    
[^54]: 在微调深度神经网络上的自适应随机特征正则化

    Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks

    [https://arxiv.org/abs/2403.10097](https://arxiv.org/abs/2403.10097)

    提出了一种名为AdaRand的简单方法，在微调深度神经网络时可以自适应地改变特征向量分布，从而提高性能而不需要辅助源信息。

    

    虽然微调是训练深度神经网络的一种事实标准方法，但在使用小型目标数据集时仍然存在过拟合问题。先前的方法通过保持对源数据集的知识或引入诸如对比损失之类的正则化项来提高微调性能。然而，这些方法需要辅助源信息（例如，源标签或数据集）或重复附加计算。在本文中，我们提出了一种称为自适应随机特征正则化（AdaRand）的简单方法。AdaRand可以帮助训练模型的特征提取器在没有辅助源信息的情况下，通过适度的计算成本，自适应地改变下游分类任务的特征向量分布。为此，AdaRand通过最小化特征向量和从类条件高斯分布中采样的随机参考向量之间的差距。

    arXiv:2403.10097v1 Announce Type: cross  Abstract: While fine-tuning is a de facto standard method for training deep neural networks, it still suffers from overfitting when using small target datasets. Previous methods improve fine-tuning performance by maintaining knowledge of the source datasets or introducing regularization terms such as contrastive loss. However, these methods require auxiliary source information (e.g., source labels or datasets) or heavy additional computations. In this paper, we propose a simple method called adaptive random feature regularization (AdaRand). AdaRand helps the feature extractors of training models to adaptively change the distribution of feature vectors for downstream classification tasks without auxiliary source information and with reasonable computation costs. To this end, AdaRand minimizes the gap between feature vectors and random reference vectors that are sampled from class conditional Gaussian distributions. Furthermore, AdaRand dynamicall
    
[^55]: 用于Fisher-Rao距离的近似和界定技术

    Approximation and bounding techniques for the Fisher-Rao distances

    [https://arxiv.org/abs/2403.10089](https://arxiv.org/abs/2403.10089)

    本文考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术，包括基于闭合形式1D子模型Fisher-Rao距离的通用上界以及取决于测地线或预测测地线是否闭合形式获得的几种通用近似方案，并提出了一种通用方法保证近似误差任意小。

    

    统计模型的两个概率分布之间的Fisher-Rao距离被定义为Fisher信息度量诱导的Riemannian测地距离。为了以闭合形式计算Fisher-Rao距离，我们需要（1）推导出Fisher-Rao测地线的公式，以及（2）沿着这些测地线积分Fisher长度元素。我们考虑了几种数值上稳健的Fisher-Rao距离的近似和界定技术：首先，我们基于子模型的闭合形式1D Fisher-Rao距离报告了Fisher-Rao距离的通用上界。其次，我们描述了几种通用的近似方案，取决于Fisher-Rao测地线或预测测地线是否能以闭合形式获得。特别地，我们获得了一种通用的方法，可以保证在提供Fisher-Rao预测测地线和严格的下界和上界时近似产生任意小的附加误差。

    arXiv:2403.10089v1 Announce Type: cross  Abstract: The Fisher-Rao distance between two probability distributions of a statistical model is defined as the Riemannian geodesic distance induced by the Fisher information metric. In order to calculate the Fisher-Rao distance in closed-form, we need (1) to elicit a formula for the Fisher-Rao geodesics, and (2) to integrate the Fisher length element along those geodesics. We consider several numerically robust approximation and bounding techniques for the Fisher-Rao distances: First, we report generic upper bounds on Fisher-Rao distances based on closed-form 1D Fisher-Rao distances of submodels. Second, we describe several generic approximation schemes depending on whether the Fisher-Rao geodesics or pregeodesics are available in closed-form or not. In particular, we obtain a generic method to guarantee an arbitrarily small additive error on the approximation provided that Fisher-Rao pregeodesics and tight lower and upper bounds are available
    
[^56]: 计算机视觉中合成数据增强方法的调查

    A survey of synthetic data augmentation methods in computer vision

    [https://arxiv.org/abs/2403.10075](https://arxiv.org/abs/2403.10075)

    该论文调查了计算机视觉中合成数据增强方法，涵盖了基于逼真3D图形建模、神经风格转移、差分神经渲染和生成的数据合成方法。

    

    处理计算机视觉问题的标准方法是使用代表目标任务的大规模图像数据集训练深度卷积神经网络（CNN）模型。然而，在许多情况下，很难获取足够的目标任务图像数据。数据增强是缓解这一挑战的一种方法。一种常见做法是明确地以所需的方式转换现有图像，以创建实现良好泛化性能所需的训练数据的数量和变化性。在无法访问目标领域数据的情况下，一个可行的解决方法是从零开始合成训练数据--即合成数据增强。本文介绍了合成数据增强技术的广泛评估。它涵盖了基于逼真3D图形建模、神经风格转移（NST）、差分神经渲染和生成的数据合成方法。

    arXiv:2403.10075v1 Announce Type: cross  Abstract: The standard approach to tackling computer vision problems is to train deep convolutional neural network (CNN) models using large-scale image datasets which are representative of the target task. However, in many scenarios, it is often challenging to obtain sufficient image data for the target task. Data augmentation is a way to mitigate this challenge. A common practice is to explicitly transform existing images in desired ways so as to create the required volume and variability of training data necessary to achieve good generalization performance. In situations where data for the target domain is not accessible, a viable workaround is to synthesize training data from scratch--i.e., synthetic data augmentation. This paper presents an extensive review of synthetic data augmentation techniques. It covers data synthesis approaches based on realistic 3D graphics modeling, neural style transfer (NST), differential neural rendering, and gen
    
[^57]: 用于学习哈密顿系统的保结构核方法

    A Structure-Preserving Kernel Method for Learning Hamiltonian Systems

    [https://arxiv.org/abs/2403.10070](https://arxiv.org/abs/2403.10070)

    提出了一种保结构的核岭回归方法，可以从噪声观测数据中恢复哈密顿函数，拓展了核回归方法，并具有出色的数值性能和收敛速度。

    

    提出了一种保结构的核岭回归方法，允许从包含哈密顿向量场的噪声观测数据集中恢复潜在的高维非线性哈密顿函数。该方法提出了一个闭式解，在这一设置中表现出优秀的数值性能，超越了文献中提出的其他技术。从方法论的角度看，该论文扩展了核回归方法，解决需要包含梯度线性函数的损失函数的问题，特别地，在这一背景下证明了微分再现属性和表示定理。分析了保结构核估计器和高斯后验均值估计器之间的关系。进行了完整的误差分析，提供使用固定和自适应正则化参数的收敛速度。所提出方法的优良性能得到了确认。

    arXiv:2403.10070v1 Announce Type: cross  Abstract: A structure-preserving kernel ridge regression method is presented that allows the recovery of potentially high-dimensional and nonlinear Hamiltonian functions out of datasets made of noisy observations of Hamiltonian vector fields. The method proposes a closed-form solution that yields excellent numerical performances that surpass other techniques proposed in the literature in this setup. From the methodological point of view, the paper extends kernel regression methods to problems in which loss functions involving linear functions of gradients are required and, in particular, a differential reproducing property and a Representer Theorem are proved in this context. The relation between the structure-preserving kernel estimator and the Gaussian posterior mean estimator is analyzed. A full error analysis is conducted that provides convergence rates using fixed and adaptive regularization parameters. The good performance of the proposed 
    
[^58]: 统一的无投影算法用于对抗性DR-次模优化

    Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization

    [https://arxiv.org/abs/2403.10063](https://arxiv.org/abs/2403.10063)

    本文提出了统一的无投影Frank-Wolfe类型算法，用于对抗性DR-次模优化，在不同场景下取得了令人瞩目的次线性 $\alpha$-后悔上界，并在单调设置中实现了无投影算法的最新次线性 $\alpha$-后悔上界。

    

    本文介绍了统一的无投影Frank-Wolfe类型算法，用于对抗性连续DR-次模优化，涵盖了诸如全信息和（半）强敌反馈、单调和非单调函数、不同约束以及类型的随机查询等场景。在非单调设置中考虑的每个问题中，所提出的算法要么是第一个具有证明的次线性 $\alpha$-后悔上界的算法，要么具有比现有技术更好的 $\alpha$-后悔上界，其中 $\alpha$ 是离线设置中的相应近似上界。在单调设置中，所提出的方法在8个考虑的情况中的7种中是无投影算法的最新次线性 $\alpha$-后悔上界，同时与剩余情况的结果相匹配。此外，本文还研究了对抗性DR-次模优化的半强敌和强敌反馈，推进了对这一问题的理解。

    arXiv:2403.10063v1 Announce Type: cross  Abstract: This paper introduces unified projection-free Frank-Wolfe type algorithms for adversarial continuous DR-submodular optimization, spanning scenarios such as full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. For every problem considered in the non-monotone setting, the proposed algorithms are either the first with proven sub-linear $\alpha$-regret bounds or have better $\alpha$-regret bounds than the state of the art, where $\alpha$ is a corresponding approximation bound in the offline setting. In the monotone setting, the proposed approach gives state-of-the-art sub-linear $\alpha$-regret bounds among projection-free algorithms in 7 of the 8 considered cases while matching the result of the remaining case. Additionally, this paper addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization, advancing the understanding of this
    
[^59]: 通过曲率正则化实现对抗鲁棒性数据集精炼

    Towards Adversarially Robust Dataset Distillation by Curvature Regularization

    [https://arxiv.org/abs/2403.10045](https://arxiv.org/abs/2403.10045)

    本文探讨了如何通过曲率正则化方法在精炼数据集中嵌入对抗鲁棒性，以保持模型高准确性并获得更好的对抗鲁棒性。

    

    数据集精炼（DD）允许将数据集精炼为原始大小的分数，同时保留丰富的分布信息，使得在精炼数据集上训练的模型可以在节省显著计算负载的同时达到可比的准确性。最近在这一领域的研究集中在提高在精炼数据集上训练的模型的准确性。在本文中，我们旨在探索DD的一种新视角。我们研究如何在精炼数据集中嵌入对抗鲁棒性，以使在这些数据集上训练的模型保持高精度的同时获得更好的对抗鲁棒性。我们提出了一种通过将曲率正则化纳入到精炼过程中来实现这一目标的新方法，而这种方法的计算开销比标准的对抗训练要少得多。大量的实证实验表明，我们的方法不仅在准确性上优于标准对抗训练，同时在对抗性能方面也取得了显著改进。

    arXiv:2403.10045v1 Announce Type: new  Abstract: Dataset distillation (DD) allows datasets to be distilled to fractions of their original size while preserving the rich distributional information so that models trained on the distilled datasets can achieve a comparable accuracy while saving significant computational loads. Recent research in this area has been focusing on improving the accuracy of models trained on distilled datasets. In this paper, we aim to explore a new perspective of DD. We study how to embed adversarial robustness in distilled datasets, so that models trained on these datasets maintain the high accuracy and meanwhile acquire better adversarial robustness. We propose a new method that achieves this goal by incorporating curvature regularization into the distillation process with much less computational overhead than standard adversarial training. Extensive empirical experiments suggest that our method not only outperforms standard adversarial training on both accur
    
[^60]: 使用多任务学习准确高效地识别微型XRD相位：以热液流体为例

    Accurate and Data-Efficient Micro-XRD Phase Identification Using Multi-Task Learning: Application to Hydrothermal Fluids

    [https://arxiv.org/abs/2403.10042](https://arxiv.org/abs/2403.10042)

    深度学习与多任务学习结合在微型X射线衍射相位识别中取得突破，模型训练减少了实验数据标记和预处理步骤，性能优于传统CNN分类器。

    

    传统的高度扭曲的微型X射线衍射（μ-XRD）图样的分析在热液环境中是一个耗时的过程，通常需要大量的数据预处理和标记的实验数据。本研究展示了深度学习与多任务学习（MTL）架构克服这些限制的潜力。我们训练了MTL模型来识别μ-XRD图样中的相位信息，最大程度减少了对标记实验数据和掩盖预处理步骤的需要。 值得注意的是，MTL模型相比于二元分类CNN表现出更高的准确性。此外，引入定制的交叉熵损失函数提高了MTL模型的性能。最重要的是，调整为分析原始和未掩盖XRD图样的MTL模型实现了与分析预处理数据的模型紧密的性能，准确性差异极小。这项工作表明，像MTL这样的先进深度学习架构可以实现

    arXiv:2403.10042v1 Announce Type: cross  Abstract: Traditional analysis of highly distorted micro-X-ray diffraction ({\mu}-XRD) patterns from hydrothermal fluid environments is a time-consuming process, often requiring substantial data preprocessing and labeled experimental data. This study demonstrates the potential of deep learning with a multitask learning (MTL) architecture to overcome these limitations. We trained MTL models to identify phase information in {\mu}-XRD patterns, minimizing the need for labeled experimental data and masking preprocessing steps. Notably, MTL models showed superior accuracy compared to binary classification CNNs. Additionally, introducing a tailored cross-entropy loss function improved MTL model performance. Most significantly, MTL models tuned to analyze raw and unmasked XRD patterns achieved close performance to models analyzing preprocessed data, with minimal accuracy differences. This work indicates that advanced deep learning architectures like MT
    
[^61]: MR-MT3:存储保留的多轨音乐转录以减少乐器泄漏

    MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage

    [https://arxiv.org/abs/2403.10024](https://arxiv.org/abs/2403.10024)

    提出了MR-MT3模型来减少乐器泄漏问题，采用了存储保留机制、先前令牌采样和令牌混洗等增强方法，在Slakh2100数据集上展示了改进的效果。

    

    这篇论文介绍了MT3模型的改进，MT3是一种最先进的基于令牌的多乐器自动音乐转录模型。尽管MT3性能最先进，但存在乐器泄漏问题，即转录在不同乐器之间片段化。为了减少这种问题，我们提出了MR-MT3，其中包括存储保留机制、先前令牌采样和令牌混洗等增强方法。这些方法在Slakh2100数据集上进行了评估，展示了改进的起始F1分数和减少的乐器泄漏。除了传统的多乐器转录F1分数，还引入了诸如乐器泄漏比率和乐器检测F1分数等新指标，以更全面地评估转录质量。该研究还探讨了通过在单乐器单声道数据集（如ComMU和NSynth）上评估MT3来评估域过度拟合的问题。

    arXiv:2403.10024v1 Announce Type: cross  Abstract: This paper presents enhancements to the MT3 model, a state-of-the-art (SOTA) token-based multi-instrument automatic music transcription (AMT) model. Despite SOTA performance, MT3 has the issue of instrument leakage, where transcriptions are fragmented across different instruments. To mitigate this, we propose MR-MT3, with enhancements including a memory retention mechanism, prior token sampling, and token shuffling are proposed. These methods are evaluated on the Slakh2100 dataset, demonstrating improved onset F1 scores and reduced instrument leakage. In addition to the conventional multi-instrument transcription F1 score, new metrics such as the instrument leakage ratio and the instrument detection F1 score are introduced for a more comprehensive assessment of transcription quality. The study also explores the issue of domain overfitting by evaluating MT3 on single-instrument monophonic datasets such as ComMU and NSynth. The findings,
    
[^62]: 点集分类的线性最优输运子空间

    Linear optimal transport subspaces for point set classification

    [https://arxiv.org/abs/2403.10015](https://arxiv.org/abs/2403.10015)

    提出了一种用于点集分类的线性最优输运子空间框架，通过线性嵌入集合结构数据，展示了其在处理空间变形中的能力，以简化点集分类问题。

    

    从点集中学习在许多计算机视觉和机器学习应用中是一个重要组成部分。原生的、无序的、置换不变的集合结构空间很难建模，特别是在空间形变下进行点集分类。在这里，我们提出一个框架，用于分类经历特定类型空间形变的点集，特别强调包含仿射形变数据集。我们的方法利用线性最优输运（LOT）变换来获得集合结构化数据的线性嵌入。利用LOT变换的数学性质，我们展示了它适应点集变化的能力，通过构建一个凸数据空间，有效简化了点集分类问题。我们的方法在LOT空间中采用最近子空间算法，表现出标签效率、非迭代行为，而且不需要超参数。

    arXiv:2403.10015v1 Announce Type: cross  Abstract: Learning from point sets is an essential component in many computer vision and machine learning applications. Native, unordered, and permutation invariant set structure space is challenging to model, particularly for point set classification under spatial deformations. Here we propose a framework for classifying point sets experiencing certain types of spatial deformations, with a particular emphasis on datasets featuring affine deformations. Our approach employs the Linear Optimal Transport (LOT) transform to obtain a linear embedding of set-structured data. Utilizing the mathematical properties of the LOT transform, we demonstrate its capacity to accommodate variations in point sets by constructing a convex data space, effectively simplifying point set classification problems. Our method, which employs a nearest-subspace algorithm in the LOT space, demonstrates label efficiency, non-iterative behavior, and requires no hyper-parameter
    
[^63]: LyZNet: 一个用于学习和验证神经李亚普诺夫函数和吸引力区域的轻量级Python工具

    LyZNet: A Lightweight Python Tool for Learning and Verifying Neural Lyapunov Functions and Regions of Attraction

    [https://arxiv.org/abs/2403.10013](https://arxiv.org/abs/2403.10013)

    LyZNet是一个轻量级Python工具，利用物理信息神经网络学习神经李亚普诺夫函数，并通过SMT求解器验证，能够提供验证范围接近吸引力域的特点

    

    在本文中，我们描述了一个轻量级的Python框架，它提供了神经李亚普诺夫函数的学习和验证，用于稳定性分析。提出的工具名为LyZNet，使用物理信息神经网络（PINN）学习神经李亚普诺夫函数来解决祖博夫方程，并使用可满足性模理论（SMT）求解器进行验证。该工具与文献中的其他工具的区别在于其能够提供接近吸引力域附近的验证区域。这是通过将祖博夫的偏微分方程（PDE）编码到PINN方法中来实现的。通过拥抱潜在优化问题的非凸性质，我们展示了在凸优化失败捕捉吸引力域的情况下，我们的神经网络框架证明更成功。该工具还提供耦合非线性系统的自动分解。

    arXiv:2403.10013v1 Announce Type: cross  Abstract: In this paper, we describe a lightweight Python framework that provides integrated learning and verification of neural Lyapunov functions for stability analysis. The proposed tool, named LyZNet, learns neural Lyapunov functions using physics-informed neural networks (PINNs) to solve Zubov's equation and verifies them using satisfiability modulo theories (SMT) solvers. What distinguishes this tool from others in the literature is its ability to provide verified regions of attraction close to the domain of attraction. This is achieved by encoding Zubov's partial differential equation (PDE) into the PINN approach. By embracing the non-convex nature of the underlying optimization problems, we demonstrate that in cases where convex optimization, such as semidefinite programming, fails to capture the domain of attraction, our neural network framework proves more successful. The tool also offers automatic decomposition of coupled nonlinear sy
    
[^64]: 基于图增强强化学习的协作问题解决中有效群组形成研究

    Graph Enhanced Reinforcement Learning for Effective Group Formation in Collaborative Problem Solving

    [https://arxiv.org/abs/2403.10006](https://arxiv.org/abs/2403.10006)

    通过图论和强化学习，在协作问题解决中形成有效群组，并提供潜在改进和冲突减少的见解

    

    这项研究解决了在协作解决问题的环境中形成有效群组的挑战。认识到人际互动的复杂性和有效协作的必要性，我们提出了一种新颖的方法，利用图论和强化学习。我们的方法涉及从数据集构建图，其中节点表示参与者，边表示它们之间的交互。我们将每个参与者概念化为强化学习框架中的一个代理，旨在学习反映有效群体动态的最佳图结构。聚类技术被用来根据学习的图界定清晰的群组结构。我们的方法提供基于评估指标和图测量的理论解决方案，为群组效率的潜在改进和冲突事件的减少提供见解。这项研究为领域做出了贡献

    arXiv:2403.10006v1 Announce Type: cross  Abstract: This study addresses the challenge of forming effective groups in collaborative problem-solving environments. Recognizing the complexity of human interactions and the necessity for efficient collaboration, we propose a novel approach leveraging graph theory and reinforcement learning. Our methodology involves constructing a graph from a dataset where nodes represent participants, and edges signify the interactions between them. We conceptualize each participant as an agent within a reinforcement learning framework, aiming to learn an optimal graph structure that reflects effective group dynamics. Clustering techniques are employed to delineate clear group structures based on the learned graph. Our approach provides theoretical solutions based on evaluation metrics and graph measurements, offering insights into potential improvements in group effectiveness and reductions in conflict incidences. This research contributes to the fields of
    
[^65]: AD3:隐式动作是世界模型区分不同视觉干扰因素的关键

    AD3: Implicit Action is the Key for World Models to Distinguish the Diverse Visual Distractors

    [https://arxiv.org/abs/2403.09976](https://arxiv.org/abs/2403.09976)

    提出了一种名为AD3的算法，通过隐式动作生成器(IAG)学习视觉干扰因素的隐式动作，实现了在区分任务不相关组件上的卓越性能。

    

    基于模型的方法在区分视觉控制中的任务不相关干扰因素方面做出了显著贡献。然而，先前的研究主要集中在异质干扰因素，如嘈杂的背景视频上，对密切类似可控制代理的均质干扰因素的研究很少，这给现有方法带来了重大挑战。为解决这一问题，我们提出了隐式动作生成器（IAG）来学习视觉干扰因素的隐式动作，并提出了一种名为隐式动作通知的多样化视觉干扰因素区分器（AD3）的新算法，利用IAG推断的动作来训练分离的世界模型。隐式动作有效地捕捉了背景干扰因素的行为，有助于区分任务不相关的组件，代理可以优化任务相关状态空间内的策略。我们的方法在各种视觉控制任务中表现出优越性能。

    arXiv:2403.09976v1 Announce Type: new  Abstract: Model-based methods have significantly contributed to distinguishing task-irrelevant distractors for visual control. However, prior research has primarily focused on heterogeneous distractors like noisy background videos, leaving homogeneous distractors that closely resemble controllable agents largely unexplored, which poses significant challenges to existing methods. To tackle this problem, we propose Implicit Action Generator (IAG) to learn the implicit actions of visual distractors, and present a new algorithm named implicit Action-informed Diverse visual Distractors Distinguisher (AD3), that leverages the action inferred by IAG to train separated world models. Implicit actions effectively capture the behavior of background distractors, aiding in distinguishing the task-irrelevant components, and the agent can optimize the policy within the task-relevant state space. Our method achieves superior performance on various visual control 
    
[^66]: GET：解锁CLIP的多模态潜力，用于广义类别发现

    GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery

    [https://arxiv.org/abs/2403.09974](https://arxiv.org/abs/2403.09974)

    本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。

    

    给定包含旧类别和新类别的无标签数据集，广义类别发现（GCD）旨在准确发现新类别，并正确分类旧类别，利用从有标签样本中学习的类别概念。当前的GCD方法只使用单一的视觉信息模态，导致在视觉上相似类别的分类效果不佳。虽然某些类别在视觉上容易混淆，但它们的文本信息可能是不同的，这促使我们将文本信息引入到GCD任务中。然而，无标签数据缺乏类别名称，使得利用文本信息变得不切实际。为了解决这一具有挑战性的问题，在本文中，我们提出了一种文本嵌入合成器（TES），用于为无标签样本生成伪文本嵌入。具体而言，我们的TES利用CLIP可以生成对齐的视觉-语言特征这一特性，将视觉嵌入转换为CLIP文本模型的标记。

    arXiv:2403.09974v1 Announce Type: cross  Abstract: Given unlabelled datasets containing both old and new categories, generalized category discovery (GCD) aims to accurately discover new classes while correctly classifying old classes, leveraging the class concepts learned from labeled samples. Current GCD methods only use a single visual modality of information, resulting in poor classification of visually similar classes. Though certain classes are visually confused, their text information might be distinct, motivating us to introduce text information into the GCD task. However, the lack of class names for unlabelled data makes it impractical to utilize text information. To tackle this challenging problem, in this paper, we propose a Text Embedding Synthesizer (TES) to generate pseudo text embeddings for unlabelled samples. Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text e
    
[^67]: 使用多数据融合和深度学习预测船舶到引航区的到达时间

    Prediction of Vessel Arrival Time to Pilotage Area Using Multi-Data Fusion and Deep Learning

    [https://arxiv.org/abs/2403.09969](https://arxiv.org/abs/2403.09969)

    使用MKDE和聚类提取船舶到达轮廓，融合多数据源，并采用TCN框架学习隐藏到达模式，有效提高了船舶到引航区的到达时间预测准确性。

    

    本文研究了使用多数据融合和深度学习方法预测船舶到达引航区的到达时间。首先，基于多元核密度估计（MKDE）和聚类提取船舶到达轮廓。其次，在潜在特征提取之前融合了多个数据源，包括自动识别系统（AIS）、引航预订信息和气象数据。第三，在构建了一个结合残差机制的时间卷积网络（TCN）框架来学习船舶的隐藏到达模式。在新加坡的两个真实世界数据集上进行了广泛测试，取得了以下有希望的结果：1）引航预订信息和气象数据的融合提高了预测准确性，其中引航预订信息影响更显著；2）使用离散嵌入进行气象预测

    arXiv:2403.09969v1 Announce Type: new  Abstract: This paper investigates the prediction of vessels' arrival time to the pilotage area using multi-data fusion and deep learning approaches. Firstly, the vessel arrival contour is extracted based on Multivariate Kernel Density Estimation (MKDE) and clustering. Secondly, multiple data sources, including Automatic Identification System (AIS), pilotage booking information, and meteorological data, are fused before latent feature extraction. Thirdly, a Temporal Convolutional Network (TCN) framework that incorporates a residual mechanism is constructed to learn the hidden arrival patterns of the vessels. Extensive tests on two real-world data sets from Singapore have been conducted and the following promising results have been obtained: 1) fusion of pilotage booking information and meteorological data improves the prediction accuracy, with pilotage booking information having a more significant impact; 2) using discrete embedding for the meteoro
    
[^68]: 利用插值物理信息图神经网络（InterPIGNN）建立美国本土热地球模型

    Thermal Earth Model for the Conterminous United States Using an Interpolative Physics-Informed Graph Neural Network (InterPIGNN)

    [https://arxiv.org/abs/2403.09961](https://arxiv.org/abs/2403.09961)

    利用插值物理信息图神经网络，本研究开发出一种基于数据驱动的空间插值算法，构建了美国本土温度-深度地图，同时精确预测地下温度、地表热流和岩石导热率。

    

    这项研究提出了一种基于物理信息图神经网络的数据驱动空间插值算法，用于开发美国本土的温度-深度地图。该模型经过训练，同时预测地下温度、地表热流和岩石导热率，以近似满足三维传热定律。除了底孔温度测量值，我们还将其他物理量作为模型输入，例如深度、地理坐标、海拔、沉积物厚度、磁异常、重力异常、放射性元素的γ射线通量、地震活动和电导率。我们构建了深度为0-7公里，间隔为1公里，空间分辨率为每个18平方公里格网单元的地表热流、温度和导热率预测。我们的模型展现了卓越的温度、地表热流和导热率预测性能。

    arXiv:2403.09961v1 Announce Type: cross  Abstract: This study presents a data-driven spatial interpolation algorithm based on physics-informed graph neural networks used to develop national temperature-at-depth maps for the conterminous United States. The model was trained to approximately satisfy the three-dimensional heat conduction law by simultaneously predicting subsurface temperature, surface heat flow, and rock thermal conductivity. In addition to bottomhole temperature measurements, we incorporated other physical quantities as model inputs, such as depth, geographic coordinates, elevation, sediment thickness, magnetic anomaly, gravity anomaly, gamma-ray flux of radioactive elements, seismicity, and electric conductivity. We constructed surface heat flow, and temperature and thermal conductivity predictions for depths of 0-7 km at an interval of 1 km with spatial resolution of 18 km$^2$ per grid cell. Our model showed superior temperature, surface heat flow and thermal conductiv
    
[^69]: 在测试时间图分布转移下的在线GNN评估

    Online GNN Evaluation Under Test-time Graph Distribution Shifts

    [https://arxiv.org/abs/2403.09953](https://arxiv.org/abs/2403.09953)

    在线GNN评估研究了如何在测试时间图分布转移的情况下，衡量经过充分训练的GNN模型对真实世界无标签图的泛化能力。

    

    评估一个经过充分训练的GNN模型在真实世界图上的表现是可靠的GNN在线部署和服务的关键步骤。由于缺乏测试节点标签和未知潜在的训练-测试图数据分布转移，传统模型评估在计算性能指标（如测试错误）和测量图数据级别差异方面存在局限性，特别是在测试时所使用的训练图仍未被观察到。本文研究了一个新的研究问题，即在线GNN评估，旨在为经过充分训练的GNN在测试时间图分布转移下有效推广到真实世界无标签图提供宝贵见解。具体来说，我们开发了一种有效的学习行为差异评分，称为LeBeD，来估计经过充分训练的GNN模型的测试时间泛化错误。通过一种新颖的GNN重新训练策略

    arXiv:2403.09953v1 Announce Type: new  Abstract: Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. Due to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time. In this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts. Concretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. Through a novel GNN re-training strategy
    
[^70]: 增强注意力的混合特征聚合网络用于3D脑肿瘤分割

    Attention-Enhanced Hybrid Feature Aggregation Network for 3D Brain Tumor Segmentation

    [https://arxiv.org/abs/2403.09942](https://arxiv.org/abs/2403.09942)

    在医疗保健中，利用增强注意力的混合特征聚合网络GLIMS进行3D脑肿瘤分割，使用多尺度特征提取和Swin Transformer块改善了全局特征聚合。

    

    Glioblastoma是一种高度侵略性和恶性的脑肿瘤类型，需要及早诊断和及时干预。由于其外观上的异质性，开发自动检测方法具有挑战性。为解决这一挑战，医疗保健中基于人工智能的方法引起了人们的兴趣，以有效诊断和评估脑肿瘤。Brain Tumor Segmentation Challenge (BraTS)是一个开发和评估使用高质量临床获得的MRI数据进行肿瘤分析的自动化技术的平台。在我们的方法中，我们利用了多尺度、注意力引导和混合U-Net形状模型--GLIMS--在三个区域：增强肿瘤（ET）、肿瘤核心（TC）和整个肿瘤（WT）中执行3D脑肿瘤分割。多尺度特征提取在高分辨率中提供更好的上下文特征聚合，而Swin Transformer块改善了全局特征。

    arXiv:2403.09942v1 Announce Type: cross  Abstract: Glioblastoma is a highly aggressive and malignant brain tumor type that requires early diagnosis and prompt intervention. Due to its heterogeneity in appearance, developing automated detection approaches is challenging. To address this challenge, Artificial Intelligence (AI)-driven approaches in healthcare have generated interest in efficiently diagnosing and evaluating brain tumors. The Brain Tumor Segmentation Challenge (BraTS) is a platform for developing and assessing automated techniques for tumor analysis using high-quality, clinically acquired MRI data. In our approach, we utilized a multi-scale, attention-guided and hybrid U-Net-shaped model -- GLIMS -- to perform 3D brain tumor segmentation in three regions: Enhancing Tumor (ET), Tumor Core (TC), and Whole Tumor (WT). The multi-scale feature extraction provides better contextual feature aggregation in high resolutions and the Swin Transformer blocks improve the global feature 
    
[^71]: 具有对手的联邦策略梯度方法的全局收敛保证

    Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries

    [https://arxiv.org/abs/2403.09940](https://arxiv.org/abs/2403.09940)

    该方法提出了一种基于策略梯度的联邦学习方法，可以在存在对手代理的情况下实现全局收敛保证，并具有对对手的鲁棒性。

    

    Federated Reinforcement Learning (FRL)允许多个代理共同构建决策制定策略，而无需共享原始轨迹。然而，如果这些代理中只有少部分是对手，可能会导致灾难性结果。我们提出了一种基于策略梯度的方法，该方法对对手代理具有鲁棒性，可以向服务器发送任意值。在这种设置下，我们的结果形成了具有一般参数化的首个全局收敛保证。这些结果展示了对手的弹性，同时达到了样本复杂度的$\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \frac{f^2}{(N-f)^2}\right)\right)$，其中$N$是代理的总数，$f$是对手代理的数量。

    arXiv:2403.09940v1 Announce Type: cross  Abstract: Federated Reinforcement Learning (FRL) allows multiple agents to collaboratively build a decision making policy without sharing raw trajectories. However, if a small fraction of these agents are adversarial, it can lead to catastrophic results. We propose a policy gradient based approach that is robust to adversarial agents which can send arbitrary values to the server. Under this setting, our results form the first global convergence guarantees with general parametrization. These results demonstrate resilience with adversaries, while achieving sample complexity of order $\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \frac{f^2}{(N-f)^2}\right)\right)$, where $N$ is the total number of agents and $f$ is the number of adversarial agents.
    
[^72]: 质量多样性演员-评论家：通过值和继承特征评论家学习高性能和多样性行为

    Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics

    [https://arxiv.org/abs/2403.09930](https://arxiv.org/abs/2403.09930)

    QDAC是一种基于离策略演员-评论家深度强化学习算法，通过价值函数评论家和继承特征评论家学习高性能和多样性行为。

    

    智能的一个关键方面是表现出适应意外情况的广泛行为谱。过去十年，深度强化学习的进步取得了突破性成就，用于解决复杂的连续控制任务。然而，大多数方法只返回一个专门针对特定问题的解决方案。我们引入了质量多样性演员-评论家（QDAC），这是一种基于离策略演员-评论家深度强化学习算法，利用价值函数评论家和继承特征评论家学习高性能和多样性行为。在这个框架中，演员通过受限优化来最大化回报并执行多样性技能的客观函数，无缝统一了两个评论家。与其他质量多样性方法相比，QDAC在六个具有挑战性的连续控制运动任务上实现了显着更高的性能和更多样性的行为。

    arXiv:2403.09930v1 Announce Type: cross  Abstract: A key aspect of intelligence is the ability to demonstrate a broad spectrum of behaviors for adapting to unexpected situations. Over the past decade, advancements in deep reinforcement learning have led to groundbreaking achievements to solve complex continuous control tasks. However, most approaches return only one solution specialized for a specific problem. We introduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic deep reinforcement learning algorithm that leverages a value function critic and a successor features critic to learn high-performing and diverse behaviors. In this framework, the actor optimizes an objective that seamlessly unifies both critics using constrained optimization to (1) maximize return, while (2) executing diverse skills. Compared with other Quality-Diversity methods, QDAC achieves significantly higher performance and more diverse behaviors on six challenging continuous control locomotion 
    
[^73]: 大型语言模型中用于快速推测解码的循环草稿机制

    Recurrent Drafter for Fast Speculative Decoding in Large Language Models

    [https://arxiv.org/abs/2403.09919](https://arxiv.org/abs/2403.09919)

    本文介绍了一种适用于大型语言模型的循环草稿机制，结合了经典双模型和最新单模型方法，通过运用循环依赖设计，实现了高效的推测解码。

    

    在本文中，我们介绍一种改进的推测解码方法，旨在提高大型语言模型的效率。我们的方法利用了两种成熟技术的优势：经典的双模型推测解码方法和较新的单模型方法Medusa。从Medusa得到灵感，我们的方法采用了单模型策略进行推测解码。然而，我们的方法通过使用具有循环依赖设计的单个轻量级草稿头来区分自己，本质上类似于经典推测解码中使用的小型草稿模型，但避免了完整transformer架构的复杂性。由于循环依赖，我们可以使用波束搜索快速过滤出草稿头中不需要的候选项。其结果是一种结合了单模型设计简易性并避免了创建数据相关树依赖的方法。

    arXiv:2403.09919v1 Announce Type: new  Abstract: In this paper, we introduce an improved approach of speculative decoding aimed at enhancing the efficiency of serving large language models. Our method capitalizes on the strengths of two established techniques: the classic two-model speculative decoding approach, and the more recent single-model approach, Medusa. Drawing inspiration from Medusa, our approach adopts a single-model strategy for speculative decoding. However, our method distinguishes itself by employing a single, lightweight draft head with a recurrent dependency design, akin in essence to the small, draft model uses in classic speculative decoding, but without the complexities of the full transformer architecture. And because of the recurrent dependency, we can use beam search to swiftly filter out undesired candidates with the draft head. The outcome is a method that combines the simplicity of single-model design and avoids the need to create a data-dependent tree attent
    
[^74]: 基于注意力的多源领域自适应目标检测的类别条件对齐

    Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptive Object Detection

    [https://arxiv.org/abs/2403.09918](https://arxiv.org/abs/2403.09918)

    提出了一种基于注意力的类别条件对齐方案，用于多源领域自适应目标检测，在跨领域对齐每个对象类别的实例。

    

    目标检测（OD）的领域自适应方法致力于通过促进源域和目标域之间的特征对齐来缓解分布转移的影响。多源领域自适应（MSDA）允许利用多个带注释的源数据集和未标记的目标数据来提高检测模型的准确性和鲁棒性。大多数最先进的OD MSDA方法以一种与类别无关的方式执行特征对齐。最近提出的基于原型的方法提出了一种按类别对齐的方法，但由于嘈杂的伪标签而导致错误积累，这可能会对不平衡数据的自适应产生负面影响。为克服这些限制，我们提出了一种基于注意力的类别条件对齐方案，用于MSDA，该方案在跨领域对齐每个对象类别的实例。

    arXiv:2403.09918v1 Announce Type: cross  Abstract: Domain adaptation methods for object detection (OD) strive to mitigate the impact of distribution shifts by promoting feature alignment across source and target domains. Multi-source domain adaptation (MSDA) allows leveraging multiple annotated source datasets, and unlabeled target data to improve the accuracy and robustness of the detection model. Most state-of-the-art MSDA methods for OD perform feature alignment in a class-agnostic manner. This is challenging since the objects have unique modal information due to variations in object appearance across domains. A recent prototype-based approach proposed a class-wise alignment, yet it suffers from error accumulation due to noisy pseudo-labels which can negatively affect adaptation with imbalanced data. To overcome these limitations, we propose an attention-based class-conditioned alignment scheme for MSDA that aligns instances of each object category across domains. In particular, an 
    
[^75]: FedComLoc: 稀疏和量化模型的通信高效分布式训练

    FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models

    [https://arxiv.org/abs/2403.09904](https://arxiv.org/abs/2403.09904)

    FedComLoc利用Scaffnew算法的基础，引入了压缩和本地训练，显著降低了分布式训练中的通信开销。

    

    联邦学习（FL）由于其允许异构客户端在本地处理其私有数据并与中央服务器互动，同时尊重隐私的独特特点而受到越来越多的关注。我们的工作受到了创新的Scaffnew算法的启发，该算法在FL中大大推动了通信复杂性的降低。我们引入了FedComLoc（联邦压缩和本地训练），将实用且有效的压缩集成到Scaffnew中，以进一步增强通信效率。广泛的实验证明，使用流行的TopK压缩器和量化，它在大幅减少异构中的通信开销方面具有卓越的性能。

    arXiv:2403.09904v1 Announce Type: cross  Abstract: Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is \emph{Local Training}, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative \emph{Scaffnew} algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into \emph{Scaffnew} to further enhance communication efficiency. Extensive experiments, using the popular TopK compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heter
    
[^76]: 通过监控早期训练表示来实现鲁棒的子图学习

    Robust Subgraph Learning by Monitoring Early Training Representations

    [https://arxiv.org/abs/2403.09901](https://arxiv.org/abs/2403.09901)

    本文引入了一种名为SHERD的新技术，通过监控图神经网络(GNNs)早期训练表示中的信息，利用标准距离度量检测易受攻击节点，从而在图输入中实现性能和对抗鲁棒性。

    

    引文:2403.09901v1 公告类型:新摘要:图神经网络(GNNs)因在图学习和节点分类任务中表现出色而引起了广泛关注。然而，它们对对抗性攻击的脆弱性，特别是通过易受攻击的节点，给决策制定带来了挑战。鲁棒的图摘要需求在于对抗性挑战会导致攻击在整个图中传播。在本文中，我们通过引入新颖的技术SHERD (通过早期训练表示距离进行子图学习)来解决图输入中的性能和对抗鲁棒性。SHERD利用部分训练的图卷积网络(GCN)的层信息，通过标准距离度量来检测对抗攻击期间易受攻击的节点。该方法识别出"易受攻击的(坏)"节点并移除这些节点，形成一个鲁棒的子图，同时保持节点分类性能。

    arXiv:2403.09901v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have attracted significant attention for their outstanding performance in graph learning and node classification tasks. However, their vulnerability to adversarial attacks, particularly through susceptible nodes, poses a challenge in decision-making. The need for robust graph summarization is evident in adversarial challenges resulting from the propagation of attacks throughout the entire graph. In this paper, we address both performance and adversarial robustness in graph input by introducing the novel technique SHERD (Subgraph Learning Hale through Early Training Representation Distances). SHERD leverages information from layers of a partially trained graph convolutional network (GCN) to detect susceptible nodes during adversarial attacks using standard distance metrics. The method identifies "vulnerable (bad)" nodes and removes such nodes to form a robust subgraph while maintaining node classification perf
    
[^77]: TimeMachine: 一种用于长期预测的时间序列价值相当于4条眼镜蛇

    TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting

    [https://arxiv.org/abs/2403.09898](https://arxiv.org/abs/2403.09898)

    TimeMachine是一种创新模型，利用Mamba捕捉多变量时间序列数据中的长期依赖关系，同时保持线性可扩展性和较小的内存占用，通过全面验证，表现出优越的预测、可扩展性和内存效率。

    

    长期时间序列预测由于捕捉长期依赖关系、实现线性可扩展性和保持计算效率方面的困难而仍然具有挑战性。我们引入了TimeMachine，这是一种创新模型，利用Mamba，一种状态空间模型，来捕捉多变量时间序列数据中的长期依赖关系，同时保持线性可扩展性和较小的内存占用。TimeMachine利用时间序列数据的独特属性，在多个尺度上产生显著的上下文线索，并利用创新的整合四重Mamba架构来统一处理通道混合和通道独立情况，从而实现对全局和本地情境在不同尺度下进行有效内容选择进行预测。实验证明，TimeMachine在预测准确性、可扩展性和内存效率方面表现出优越性能，并且通过使用基准数据集进行广泛验证。

    arXiv:2403.09898v1 Announce Type: new  Abstract: Long-term time-series forecasting remains challenging due to the difficulty in capturing long-term dependencies, achieving linear scalability, and maintaining computational efficiency. We introduce TimeMachine, an innovative model that leverages Mamba, a state-space model, to capture long-term dependencies in multivariate time series data while maintaining linear scalability and small memory footprints. TimeMachine exploits the unique properties of time series data to produce salient contextual cues at multi-scales and leverage an innovative integrated quadruple-Mamba architecture to unify the handling of channel-mixing and channel-independence situations, thus enabling effective selection of contents for prediction against global and local contexts at different scales. Experimentally, TimeMachine achieves superior performance in prediction accuracy, scalability, and memory efficiency, as extensively validated using benchmark datasets. C
    
[^78]: Fisher Mask节点用于语言模型合并

    Fisher Mask Nodes for Language Model Merging

    [https://arxiv.org/abs/2403.09891](https://arxiv.org/abs/2403.09891)

    介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。

    

    微调预训练模型在下游性能方面具有显著优势。预训练模型（如BERT及其衍生物）在自然语言处理中的普遍性也导致了任务特定微调模型的激增。在多任务场景中，由于这些模型通常只能很好地执行一项任务，因此需要额外的训练或集成。模型合并这一不断增长的领域提供了一个解决方案，解决了将多个任务特定模型合并为单个多任务模型的挑战。在本研究中，我们引入了一种新颖的用于Transformers的模型合并方法，结合了先前Fisher加权平均和Fisher信息在模型修剪中的应用的见解。通过利用Transformer架构内的mask节点的Fisher信息，我们设计了一个计算效率高的加权平均方案。我们的方法展现出了稳定且显著的性能。

    arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
    
[^79]: 在均场极限中缩放的深度ResNets的泛化

    Generalization of Scaled Deep ResNets in the Mean-Field Regime

    [https://arxiv.org/abs/2403.09889](https://arxiv.org/abs/2403.09889)

    本研究通过研究在无限深和宽神经网络的极限下的缩放ResNet，推导出了在均场极限中泛化界限的全局下界和Kullback-Leibler散度的动态跟踪，为深度ResNet的泛化性质提供了新的认识。

    

    尽管ResNet在经验上取得了广泛的成功，但深度ResNet的泛化特性在懒惰训练阶段之外很少被探索。在这项工作中，我们研究了在无限深和宽神经网络的极限下的\emph{缩放}ResNet，其中梯度流被描述为大神经网络极限下的偏微分方程，即\emph{均场}极限。为了在这种设置下推导出泛化界限，我们的分析需要从懒惰训练阶段采用的传统时间不变Gram矩阵转变为一个时间变量、依赖于分布的版本。为此，我们在均场极限下提供了Gram矩阵最小特征值的全局下界。此外，为了追踪Kullback-Leibler（KL）散度的动态，我们建立了经验误差的线性收敛性，并估计了KL散度在参数上的上界。

    arXiv:2403.09889v1 Announce Type: new  Abstract: Despite the widespread empirical success of ResNet, the generalization properties of deep ResNet are rarely explored beyond the lazy training regime. In this work, we investigate \emph{scaled} ResNet in the limit of infinitely deep and wide neural networks, of which the gradient flow is described by a partial differential equation in the large-neural network limit, i.e., the \emph{mean-field} regime. To derive the generalization bounds under this setting, our analysis necessitates a shift from the conventional time-invariant Gram matrix employed in the lazy training regime to a time-variant, distribution-dependent version. To this end, we provide a global lower bound on the minimum eigenvalue of the Gram matrix under the mean-field regime. Besides, for the traceability of the dynamic of Kullback-Leibler (KL) divergence, we establish the linear convergence of the empirical error and estimate the upper bound of the KL divergence over param
    
[^80]: ThermoHands：一种用于从主观视角热图中估计3D手部姿势的基准

    ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image

    [https://arxiv.org/abs/2403.09871](https://arxiv.org/abs/2403.09871)

    ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。

    

    在这项工作中，我们提出了ThermoHands，这是一个针对基于热图的主观视角3D手部姿势估计的新基准，旨在克服诸如光照变化和遮挡（例如手部穿戴物）等挑战。该基准包括来自28名主体进行手-物体和手-虚拟交互的多样数据集，经过自动化过程准确标注了3D手部姿势。我们引入了一个定制的基线方法TheFormer，利用双transformer模块在热图中实现有效的主观视角3D手部姿势估计。我们的实验结果突显了TheFormer的领先性能，并确认了热成像在实现恶劣条件下稳健的3D手部姿势估计方面的有效性。

    arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
    
[^81]: 对亚群体偏移的鲁棒性改进：使用组感知先验

    Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors

    [https://arxiv.org/abs/2403.09869](https://arxiv.org/abs/2403.09869)

    开发了一族组感知先验分布，可以改进神经网络模型在数据分布的亚群体偏移下的泛化能力，并展示了即使只重新训练非鲁棒模型的最后一层，使用这种先验进行训练也能获得最先进的性能。

    

    机器学习模型在数据分布的亚群体偏移下往往表现不佳。开发能够让机器学习模型更好地泛化到这种偏移的方法对于在现实世界中安全部署至关重要。在这篇论文中，我们提出了一族针对神经网络参数的组感知先验（GAP）分布，明确支持在数据分布的亚群体偏移下泛化良好的模型。我们设计了一个简单的组感知先验，只需要访问一小部分包含组信息的数据，证明了在此先验下训练会获得最先进的性能——即使只重新训练先前训练的非鲁棒模型的最后一层。组感知先验在概念上简单，与现有方法（如属性伪标记和数据重新加权）互补，为利用贝叶斯推断以实现对亚群体偏移的鲁棒性开辟了有前景的新途径。

    arXiv:2403.09869v1 Announce Type: cross  Abstract: Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance -- even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation
    
[^82]: iBRF: 改进的平衡随机森林分类器

    iBRF: Improved Balanced Random Forest Classifier

    [https://arxiv.org/abs/2403.09867](https://arxiv.org/abs/2403.09867)

    该研究提出了一种对平衡随机森林分类器的修改，以增强预测性能。

    

    类别不平衡在不同分类任务中是一个重要挑战，在许多现实世界应用中经常出现。数据重采样被认为是解决这一问题的标准方法。该技术的目标是通过生成新样本或从数据中消除样本来平衡类别分布。多年来已提出了各种各样的采样技术来应对这一具有挑战性的问题。采样技术也可以纳入集成学习框架中，以获得更广义的预测性能。平衡随机森林（BRF）和SMOTE-Bagging是一些流行的集成方法。在本研究中，我们提出了对BRF分类器的修改以增强预测性能。在原始算法中，使用了随机欠采样（RUS）技术来平衡自举样本。

    arXiv:2403.09867v1 Announce Type: new  Abstract: Class imbalance poses a major challenge in different classification tasks, which is a frequently occurring scenario in many real-world applications. Data resampling is considered to be the standard approach to address this issue. The goal of the technique is to balance the class distribution by generating new samples or eliminating samples from the data. A wide variety of sampling techniques have been proposed over the years to tackle this challenging problem. Sampling techniques can also be incorporated into the ensemble learning framework to obtain more generalized prediction performance. Balanced Random Forest (BRF) and SMOTE-Bagging are some of the popular ensemble approaches. In this study, we propose a modification to the BRF classifier to enhance the prediction performance. In the original algorithm, the Random Undersampling (RUS) technique was utilized to balance the bootstrap samples. However, randomly eliminating too many sampl
    
[^83]: 一个白盒神经网络的概念框架

    A Conceptual Framework For White Box Neural Networks

    [https://arxiv.org/abs/2403.09863](https://arxiv.org/abs/2403.09863)

    引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。

    

    本文引入语义特征作为完全可解释神经网络层的通用概念框架。一个充分动机的MNIST相关子问题的概念验证模型包括4个这样的层，总共4800个可学习参数。该模型易于解释，无需任何形式的对抗训练即可实现人类水平的对抗测试准确率，需要较少的超参数调节，并且可以在单个CPU上快速训练。该技术的通用性承诺为彻底民主化和真正通用的白盒神经网络带来了希望。代码可在https://github.com/314-Foundation/white-box-nn找到。

    arXiv:2403.09863v1 Announce Type: cross  Abstract: This paper introduces semantic features as a general conceptual framework for fully explainable neural network layers. A well-motivated proof of concept model for relevant subproblem of MNIST consists of 4 such layers with the total of 4.8K learnable parameters. The model is easily interpretable, achieves human-level adversarial test accuracy with no form of adversarial training, requires little hyperparameter tuning and can be quickly trained on a single CPU. The general nature of the technique bears promise for a paradigm shift towards radically democratised and truly generalizable white box neural networks. The code is available at https://github.com/314-Foundation/white-box-nn
    
[^84]: MAMBA：一种用于元强化学习的有效世界模型方法

    MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning

    [https://arxiv.org/abs/2403.09859](https://arxiv.org/abs/2403.09859)

    MAMBA提出了一种新的基于模型的元强化学习方法，能够在常见的基准测试领域上实现更大的回报和更好的样本效率，同时只需很少的超参数调整。

    

    Meta强化学习(meta-RL)是解决需要高效探索的具有挑战性领域的有前途的框架。现有的meta-RL算法以低样本效率为特征，主要关注低维任务分布。与此同时，基于模型的RL方法在解决部分可观察MDP方面取得了成功，其中meta-RL是一个特殊情况。在这项工作中，我们利用这一成功并提出了一种新的基于模型的meta-RL方法，该方法基于现有的最先进的基于模型和meta-RL方法的元素。我们在常见的meta-RL基准领域上展示了我们方法的有效性，实现了更大回报和更好样本效率(最高提升$15\times$)，同时需要非常少的超参数调整。此外，我们在一系列更具挑战性的、更高维度的领域上验证了我们的方法，迈出了通向真实世界泛化代理的一步。

    arXiv:2403.09859v1 Announce Type: new  Abstract: Meta-reinforcement learning (meta-RL) is a promising framework for tackling challenging domains requiring efficient exploration. Existing meta-RL algorithms are characterized by low sample efficiency, and mostly focus on low-dimensional task distributions. In parallel, model-based RL methods have been successful in solving partially observable MDPs, of which meta-RL is a special case. In this work, we leverage this success and propose a new model-based approach to meta-RL, based on elements from existing state-of-the-art model-based and meta-RL methods. We demonstrate the effectiveness of our approach on common meta-RL benchmark domains, attaining greater return with better sample efficiency (up to $15\times$) while requiring very little hyperparameter tuning. In addition, we validate our approach on a slate of more challenging, higher-dimensional domains, taking a step towards real-world generalizing agents.
    
[^85]: 带有注意力感知自适应提示的少样本类增量学习

    Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt

    [https://arxiv.org/abs/2403.09857](https://arxiv.org/abs/2403.09857)

    提出了一个名为ASP的框架，通过注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识，并通过信息瓶颈学习目标从旧类到新类传递知识。

    

    少样本类增量学习（FSCIL）模型旨在在保留旧类知识的同时，逐步学习新类别的稀缺样本。现有的FSCIL方法通常对整个骨干进行微调，导致过拟合并阻碍学习新类别的潜力。另一方面，最近基于提示的CIL方法通过在每个任务中用足够的数据训练提示来减轻遗忘。在这项工作中，我们提出了一个名为注意力感知自适应提示（ASP）的新框架。ASP通过从注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识。此外，ASP中的自适应任务特定提示提供特定信息，并通过信息瓶颈学习目标从旧类到新类传递知识。总之，ASP防止了在基础任务上的过拟合，并不需要在少样本增量任务中使用大量数据。

    arXiv:2403.09857v1 Announce Type: cross  Abstract: Few-Shot Class-Incremental Learning (FSCIL) models aim to incrementally learn new classes with scarce samples while preserving knowledge of old ones. Existing FSCIL methods usually fine-tune the entire backbone, leading to overfitting and hindering the potential to learn new classes. On the other hand, recent prompt-based CIL approaches alleviate forgetting by training prompts with sufficient data in each task. In this work, we propose a novel framework named Attention-aware Self-adaptive Prompt (ASP). ASP encourages task-invariant prompts to capture shared knowledge by reducing specific information from the attention aspect. Additionally, self-adaptive task-specific prompts in ASP provide specific information and transfer knowledge from old classes to new classes with an Information Bottleneck learning objective. In summary, ASP prevents overfitting on base task and does not require enormous data in few-shot incremental tasks. Extensi
    
[^86]: 旨在实现因果表示的可重用性和可组合性

    Towards the Reusability and Compositionality of Causal Representations

    [https://arxiv.org/abs/2403.09830](https://arxiv.org/abs/2403.09830)

    该研究提出了DECAF框架，旨在从时间序列图像中学习因果表示，使其能够在新环境中进行调整，并在多个相关环境中进行组合，通过与四种最先进的CRL方法结合，能够在新环境中使用少量样本即可获得准确的表示。

    

    Causal Representation Learning（CRL）旨在从高维观测中识别高级因果因素及其关系，例如图像。大多数CRL作品侧重于在单个环境中学习因果表示，而本研究提出了一个新方向，即从图像的时间序列中学习因果表示，可以在新环境中进行调整，或者跨多个相关环境进行组合。具体而言，我们介绍了DECAF，一个框架，用于检测哪些因果因素可以重复使用，哪些需要从先前学习的因果表示中进行调整。我们的方法基于干预目标的可用性，这些目标指示每个时间步骤上被扰动的变量。在三个基准数据集上的实验表明，将我们的框架与四种最先进的CRL方法结合使用，可以在新环境中仅使用少量样本即可获得准确的表示。

    arXiv:2403.09830v1 Announce Type: cross  Abstract: Causal Representation Learning (CRL) aims at identifying high-level causal factors and their relationships from high-dimensional observations, e.g., images. While most CRL works focus on learning causal representations in a single environment, in this work we instead propose a first step towards learning causal representations from temporal sequences of images that can be adapted in a new environment, or composed across multiple related environments. In particular, we introduce DECAF, a framework that detects which causal factors can be reused and which need to be adapted from previously learned causal representations. Our approach is based on the availability of intervention targets, that indicate which variables are perturbed at each time step. Experiments on three benchmark datasets show that integrating our framework with four state-of-the-art CRL approaches leads to accurate representations in a new environment with only a few sam
    
[^87]: 将OC20训练的EquiformerV2模型应用于高熵材料的调整

    Adapting OC20-trained EquiformerV2 Models for High-Entropy Materials

    [https://arxiv.org/abs/2403.09811](https://arxiv.org/abs/2403.09811)

    将OC20训练的EquiformerV2模型成功调整并微调，用于推断高熵合金上*OH和*O的吸附能，通过能量过滤器和少量微调获得最先进的准确性。

    

    计算高通量研究，特别是对高熵材料和催化剂的研究，受到高维组成空间和多样的结构微状态的阻碍。它们对密度泛函理论计算的传统使用构成了瓶颈，因此，机器学习势在原子结构模拟中的应用日益普遍。在本文中，我们展示了将开放催化剂项目的预训练EquiformerV2模型调整和微调以推断出域高熵合金Ag-Ir-Pd-Pt-Ru上*OH和*O的吸附能的结果。通过应用基于结合位点局部环境的能量过滤器，零-shot推断显着提高，并通过少量微调，模型产生了最先进的准确性。还发现EquiformerV2，作为通用机器学习势的角色，能够

    arXiv:2403.09811v1 Announce Type: cross  Abstract: Computational high-throughput studies, especially in research on high-entropy materials and catalysts, are hampered by high-dimensional composition spaces and myriad structural microstates. They present bottlenecks to the conventional use of density functional theory calculations, and consequently, the use of machine-learned potentials is becoming increasingly prevalent in atomic structure simulations. In this communication, we show the results of adjusting and fine-tuning the pretrained EquiformerV2 model from the Open Catalyst Project to infer adsorption energies of *OH and *O on the out-of-domain high-entropy alloy Ag-Ir-Pd-Pt-Ru. By applying an energy filter based on the local environment of the binding site the zero-shot inference is markedly improved and through few-shot fine-tuning the model yields state-of-the-art accuracy. It is also found that EquiformerV2, assuming the role of general machine learning potential, is able to i
    
[^88]: LabelAId: 用于改善众包系统中人类标注质量和领域知识的及时AI干预

    LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems

    [https://arxiv.org/abs/2403.09810](https://arxiv.org/abs/2403.09810)

    该论文探讨了如何利用即时AI干预来提升众包平台中人类标注质量和领域知识，介绍了LabelAId模型，与传统方法相比，其能够显著提高错误推断准确性。

    

    众包平台已经改变了分布式问题解决，但质量控制仍然是一个持久的挑战。传统的质量控制措施，如对工作者进行预筛选和完善说明，通常只专注于优化经济产出。本文探讨了即时AI干预，以增强众包工作者的标注质量和领域特定知识。我们引入了LabelAId，一种先进的推断模型，它结合了程序化弱监督（PWS）和FT-Transformers，根据用户行为和领域知识推断标签的正确性。我们的技术评估显示，我们的LabelAId管道始终优于最先进的ML基线，使用50个下游样本提高了36.7%的错误推断准确性。然后，我们将LabelAId实现到Project Sidewalk中，这是一个面向城市可访问性的开源众包平台。一项涉及34名参与者的实验表明

    arXiv:2403.09810v1 Announce Type: cross  Abstract: Crowdsourcing platforms have transformed distributed problem-solving, yet quality control remains a persistent challenge. Traditional quality control measures, such as prescreening workers and refining instructions, often focus solely on optimizing economic output. This paper explores just-in-time AI interventions to enhance both labeling quality and domain-specific knowledge among crowdworkers. We introduce LabelAId, an advanced inference model combining Programmatic Weak Supervision (PWS) with FT-Transformers to infer label correctness based on user behavior and domain knowledge. Our technical evaluation shows that our LabelAId pipeline consistently outperforms state-of-the-art ML baselines, improving mistake inference accuracy by 36.7% with 50 downstream samples. We then implemented LabelAId into Project Sidewalk, an open-source crowdsourcing platform for urban accessibility. A between-subjects study with 34 participants demonstrate
    
[^89]: 自监督学习用于时间序列：对比或生成？

    Self-Supervised Learning for Time Series: Contrastive or Generative?

    [https://arxiv.org/abs/2403.09809](https://arxiv.org/abs/2403.09809)

    本文对时间序列中的对比和生成自监督学习方法进行了全面比较研究，提供了各种方法的优势和劣势洞察，并为选择合适的SSL方法提供了实用建议。

    

    自监督学习（SSL）最近已经被证明是一种从大规模未标记数据中学习表示的强大方法，在时间序列分析中表现出有希望的结果。自监督表示学习可以分为两个主流：对比和生成。在本文中，我们将对时间序列中的对比和生成方法进行全面的比较研究。首先，我们分别介绍了对比和生成SSL的基本框架，并讨论了如何获得指导模型优化的监督信号。然后，我们分别为每种类型实现了经典算法（SimCLR vs. MAE），并在公平设置下进行了比较分析。我们的结果提供了对每种方法的优势和劣势的深入洞察，并为选择合适的SSL方法提供了实用建议。我们还讨论了我们的发现对更广泛的表示学习领域的影响。

    arXiv:2403.09809v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has recently emerged as a powerful approach to learning representations from large-scale unlabeled data, showing promising results in time series analysis. The self-supervised representation learning can be categorized into two mainstream: contrastive and generative. In this paper, we will present a comprehensive comparative study between contrastive and generative methods in time series. We first introduce the basic frameworks for contrastive and generative SSL, respectively, and discuss how to obtain the supervision signal that guides the model optimization. We then implement classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative analysis in fair settings. Our results provide insights into the strengths and weaknesses of each approach and offer practical recommendations for choosing suitable SSL methods. We also discuss the implications of our findings for the broader field of rep
    
[^90]: 关于3D手部姿势在动作识别中的作用

    On the Utility of 3D Hand Poses for Action Recognition

    [https://arxiv.org/abs/2403.09805](https://arxiv.org/abs/2403.09805)

    提出了一种名为HandFormer的新型多模态Transformer模型，结合了高时间分辨率的3D手部姿势和稀疏采样的RGB帧，用于有效建模手部和物体之间的相互作用，取得了很高的准确性。

    

    3D手部姿势是一种未充分探索的动作识别模态。姿势既紧凑又信息丰富，并且可以极大地受益于计算预算有限的应用。然而，单独的姿势不能完全理解人类与之交互的物体和环境。为了有效建模手部物体相互作用，我们提出了HandFormer，一种新颖的多模态Transformer。HandFormer结合了高时间分辨率的3D手部姿势，用于精细运动建模，并使用稀疏采样的RGB帧来编码场景语义。观察手部姿势的独特特征，我们对手部建模进行了时间分解，并通过其短期轨迹表示每个关节点。这种被分解的姿势表示与稀疏的RGB采样相结合，效率非常高，并且达到了很高的准确性。仅有手部姿势的单模HandFormer在5倍更少的FLO下胜过现有基于骨架的方法。

    arXiv:2403.09805v1 Announce Type: cross  Abstract: 3D hand poses are an under-explored modality for action recognition. Poses are compact yet informative and can greatly benefit applications with limited compute budgets. However, poses alone offer an incomplete understanding of actions, as they cannot fully capture objects and environments with which humans interact. To efficiently model hand-object interactions, we propose HandFormer, a novel multimodal transformer. HandFormer combines 3D hand poses at a high temporal resolution for fine-grained motion modeling with sparsely sampled RGB frames for encoding scene semantics. Observing the unique characteristics of hand poses, we temporally factorize hand modeling and represent each joint by its short-term trajectories. This factorized pose representation combined with sparse RGB samples is remarkably efficient and achieves high accuracy. Unimodal HandFormer with only hand poses outperforms existing skeleton-based methods at 5x fewer FLO
    
[^91]: 社会整合导航：具有深度强化学习的社交行动机器人

    Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.09793](https://arxiv.org/abs/2403.09793)

    提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。

    

    移动机器人正在广泛应用于各种拥挤场景，并成为我们社会的一部分。一个具有个体人类考虑的社会可接受的导航行为对于可扩展的应用和人类接受至关重要。最近使用深度强化学习（DRL）方法来学习机器人的导航策略，并对机器人与人类之间的复杂交互进行建模。我们建议根据机器人展示的社交行为将现有基于DRL的导航方法分为具有缺乏社交行为的社会碰撞回避和具有明确预定义社交行为的社会意识方法。此外，我们提出了一种新颖的社会整合导航方法，其中机器人的社交行为是自适应的，并且是通过与人类的互动而产生的。我们的方法的构式源自社会学定义，

    arXiv:2403.09793v1 Announce Type: cross  Abstract: Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, 
    
[^92]: 通过人工智能实现情绪智能：自然语言处理和深度学习在医疗文本分析中的应用

    Emotional Intelligence Through Artificial Intelligence : NLP and Deep Learning in the Analysis of Healthcare Texts

    [https://arxiv.org/abs/2403.09762](https://arxiv.org/abs/2403.09762)

    本文系统考察了人工智能在医疗文本中情感分析方面的应用，展示了算法精度、神经退行性疾病预测以及临床决策支持方面的显著进展。

    

    本文介绍了人工智能在评估与医疗相关文本中情绪方面的应用的方法论检查，特别关注了自然语言处理和深度学习技术的融合。我们审查了许多利用人工智能增强情感分析、对情绪进行分类以及基于临床叙事、患者对药物的反馈和在线健康讨论所获得的文本信息预测患者结果的研究。综述展示了用于情感分类的算法精度、用于神经退行性疾病的AI模型预测能力以及支持临床决策的AI系统的显著进展。值得注意的是，人工智能应用的利用提高了个性化治疗计划，通过整合患者情绪并

    arXiv:2403.09762v1 Announce Type: cross  Abstract: This manuscript presents a methodical examination of the utilization of Artificial Intelligence in the assessment of emotions in texts related to healthcare, with a particular focus on the incorporation of Natural Language Processing and deep learning technologies. We scrutinize numerous research studies that employ AI to augment sentiment analysis, categorize emotions, and forecast patient outcomes based on textual information derived from clinical narratives, patient feedback on medications, and online health discussions. The review demonstrates noteworthy progress in the precision of algorithms used for sentiment classification, the prognostic capabilities of AI models for neurodegenerative diseases, and the creation of AI-powered systems that offer support in clinical decision-making. Remarkably, the utilization of AI applications has exhibited an enhancement in personalized therapy plans by integrating patient sentiment and contri
    
[^93]: 在数据匮乏环境中重建血流：用于高斯过程回归的血管网络核

    Reconstructing Blood Flow in Data-Poor Regimes: A Vasculature Network Kernel for Gaussian Process Regression

    [https://arxiv.org/abs/2403.09758](https://arxiv.org/abs/2403.09758)

    提出了一种基于物理信息核的高斯过程回归方法，可以在数据匮乏环境中实现几乎实时的血流重建。

    

    在临床设置中，血流重建对许多临床应用非常重要。然而，临床环境中可用的数据通常非常有限。本文提出了一种基于受物理启发的核的高斯过程回归方法，实现了在数据匮乏环境中几乎实时重建血流。我们介绍了一种在血管网络内重建核的新方法，血管网络是一个非欧几里得空间。所提出的核编码了时空和血管之间的相关性，从而实现在数据匮乏环境中的血流重建。

    arXiv:2403.09758v1 Announce Type: cross  Abstract: Blood flow reconstruction in the vasculature is important for many clinical applications. However, in clinical settings, the available data are often quite limited. For instance, Transcranial Doppler ultrasound (TCD) is a noninvasive clinical tool that is commonly used in the clinical settings to measure blood velocity waveform at several locations on brain's vasculature. This amount of data is grossly insufficient for training machine learning surrogate models, such as deep neural networks or Gaussian process regression. In this work, we propose a Gaussian process regression approach based on physics-informed kernels, enabling near-real-time reconstruction of blood flow in data-poor regimes. We introduce a novel methodology to reconstruct the kernel within the vascular network, which is a non-Euclidean space. The proposed kernel encodes both spatiotemporal and vessel-to-vessel correlations, thus enabling blood flow reconstruction in v
    
[^94]: 估计随机递归树的历史

    Estimating the history of a random recursive tree

    [https://arxiv.org/abs/2403.09755](https://arxiv.org/abs/2403.09755)

    本文研究了估计随机递归树中顶点到达顺序的问题，提出了基于Jordan中心性度量的顺序估计器，并证明其几乎是最优的。

    

    本文研究了估计随机递归树中顶点到达顺序的问题。具体来说，我们研究了两个基本模型：均匀连接模型和线性优先连接模型。我们提出了一种基于Jordan中心性度量的顺序估计器，并定义了一族风险度量来量化排序过程的质量。此外，我们为这个问题建立了极小-最大下界，并证明所提出的估计器几乎是最优的。最后，我们通过数值实验表明所提出的估计器优于基于度数和谱排序程序。

    arXiv:2403.09755v1 Announce Type: cross  Abstract: This paper studies the problem of estimating the order of arrival of the vertices in a random recursive tree. Specifically, we study two fundamental models: the uniform attachment model and the linear preferential attachment model. We propose an order estimator based on the Jordan centrality measure and define a family of risk measures to quantify the quality of the ordering procedure. Moreover, we establish a minimax lower bound for this problem, and prove that the proposed estimator is nearly optimal. Finally, we numerically demonstrate that the proposed estimator outperforms degree-based and spectral ordering procedures.
    
[^95]: 实现多元视角学习：基于多个时间池化的选择

    Towards Diverse Perspective Learning with Selection over Multiple Temporal Poolings

    [https://arxiv.org/abs/2403.09749](https://arxiv.org/abs/2403.09749)

    提出了一种新颖的时间池化方法SoM-TP，通过多元视角学习实现动态选择最佳时间池化，在单个分类器内实现非迭代池化集成。

    

    在时间序列分类（TSC）中，提出了考虑顺序信息的时间池化方法。然而，我们发现每个时间池化具有不同的机制，并且根据时间序列数据的不同情况可能效果好坏不一。我们将这种固定池化机制称为单一视角的时间池化。在本文中，我们提出了一种具有多元视角学习的新型时间池化方法：选择多个时间池化（SoM-TP）。SoM-TP通过注意力动态选择多种方法中针对每个数据的最佳时间池化。SoM-TP的动态池化选择受到多选学习（MCL）集成概念的启发，该概念从多个输出中选择最佳输出。SoM-TP的注意力池化选择实现了单个分类器内的非迭代池化集成。此外，我们定义了一个视角损失和多元视角学习网络（DPLN）。

    arXiv:2403.09749v1 Announce Type: cross  Abstract: In Time Series Classification (TSC), temporal pooling methods that consider sequential information have been proposed. However, we found that each temporal pooling has a distinct mechanism, and can perform better or worse depending on time series data. We term this fixed pooling mechanism a single perspective of temporal poolings. In this paper, we propose a novel temporal pooling method with diverse perspective learning: Selection over Multiple Temporal Poolings (SoM-TP). SoM-TP dynamically selects the optimal temporal pooling among multiple methods for each data by attention. The dynamic pooling selection is motivated by the ensemble concept of Multiple Choice Learning (MCL), which selects the best among multiple outputs. The pooling selection by SoM-TP's attention enables a non-iterative pooling ensemble within a single classifier. Additionally, we define a perspective loss and Diverse Perspective Learning Network (DPLN). The loss w
    
[^96]: 大型语言模型中的人为因素：系统文献综述与未来研究方向

    The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions

    [https://arxiv.org/abs/2403.09743](https://arxiv.org/abs/2403.09743)

    人工智能领域中，这项研究探索了人类因素在检测大型语言模型的错误输出中的作用，有助于减轻其在专业环境中使用时所带来的风险。

    

    OpenAI在2022年11月推出的ChatGPT标志着人工智能的一个关键时刻，将大型语言模型（LLMs）引入主流，并在用户采用方面创造了新记录。尤其是ChatGPT，经过广泛的互联网数据训练，展示出在各个领域具有显著的对话能力，暗示对劳动力产生了重大影响。然而，这些模型容易出现错误-“幻觉”和遗漏，产生不正确或不完整的信息。这在准确性至关重要的环境中尤为危险，比如法律合规、医学或精细的流程框架。

    arXiv:2403.09743v1 Announce Type: cross  Abstract: The launch of ChatGPT by OpenAI in November 2022 marked a pivotal moment for Artificial Intelligence, introducing Large Language Models (LLMs) to the mainstream and setting new records in user adoption. LLMs, particularly ChatGPT, trained on extensive internet data, demonstrate remarkable conversational capabilities across various domains, suggesting a significant impact on the workforce. However, these models are susceptible to errors - "hallucinations" and omissions, generating incorrect or incomplete information. This poses risks especially in contexts where accuracy is crucial, such as legal compliance, medicine or fine-grained process frameworks.   There are both technical and human solutions to cope with this isse. This paper explores the human factors that enable users to detect errors in LLM outputs, a critical component in mitigating risks associated with their use in professional settings. Understanding these factors is essen
    
[^97]: 最大团问题的新方法简要回顾：从经典算法到图神经网络和量子算法

    A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms

    [https://arxiv.org/abs/2403.09742](https://arxiv.org/abs/2403.09742)

    该综述回顾了解决最大团问题的经典算法，同时也涵盖了图神经网络和量子算法的最新进展，并提出了用于测试这些算法的基准。

    

    这篇手稿全面回顾了最大团问题，这是一个涉及在图中找到所有两两相邻的顶点子集的计算问题。手稿以简单的方式涵盖了解决该问题的经典算法，并包括了对图神经网络和量子算法最近发展的审查。该综述以基准测试来评估经典以及新的学习和量子算法。

    arXiv:2403.09742v1 Announce Type: new  Abstract: This manuscript provides a comprehensive review of the Maximum Clique Problem, a computational problem that involves finding subsets of vertices in a graph that are all pairwise adjacent to each other. The manuscript covers in a simple way classical algorithms for solving the problem and includes a review of recent developments in graph neural networks and quantum algorithms. The review concludes with benchmarks for testing classical as well as new learning, and quantum algorithms.
    
[^98]: 探究检索增强生成和微调在发展基于人工智能的知识系统中的表现

    Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems

    [https://arxiv.org/abs/2403.09727](https://arxiv.org/abs/2403.09727)

    RAG-based constructions are more efficient than models produced with FN for the development of AI-driven knowledge-based systems.

    

    arXiv:2403.09727v1 公告类型: 交叉领域 摘要: 生成式大型语言模型(G-LLM)的发展为类似ChatGPT、Bing或Gemini的新型知识系统的开发打开了新的机会。微调(FN)和检索增强生成(RAG)是可用于实现基于G-LLM的知识系统领域自适应的技术。在我们的研究中，利用ROUGE、BLEU、METEOR分数和余弦相似度，我们比较并检验了GPT-J-6B、OPT-6.7B、LlaMA、LlaMA-2语言模型的RAG和FN的表现。基于在不同数据集上展示的测量结果，我们展示了基于RAG的构建比使用FN产生的模型更有效。我们指出将RAG和FN连接起来并不是轻而易举的，因为将FN模型与RAG连接可能会导致性能下降。此外，我们概述了一个简单的基于RAG的架构，平均在RO方面优于FN模型16%

    arXiv:2403.09727v1 Announce Type: cross  Abstract: The development of generative large language models (G-LLM) opened up new opportunities for the development of new types of knowledge-based systems similar to ChatGPT, Bing, or Gemini. Fine-tuning (FN) and Retrieval-Augmented Generation (RAG) are the techniques that can be used to implement domain adaptation for the development of G-LLM-based knowledge systems. In our study, using ROUGE, BLEU, METEOR scores, and cosine similarity, we compare and examine the performance of RAG and FN for the GPT-J-6B, OPT-6.7B, LlaMA, LlaMA-2 language models. Based on measurements shown on different datasets, we demonstrate that RAG-based constructions are more efficient than models produced with FN. We point out that connecting RAG and FN is not trivial, because connecting FN models with RAG can cause a decrease in performance. Furthermore, we outline a simple RAG-based architecture which, on average, outperforms the FN models by 16% in terms of the RO
    
[^99]: ClaimVer：通过知识图谱实现可解释的声明级验证和证据归因

    ClaimVer: Explainable Claim-Level Verification and Evidence Attribution of Text Through Knowledge Graphs

    [https://arxiv.org/abs/2403.09724](https://arxiv.org/abs/2403.09724)

    ClaimVer是一个人为中心的框架，通过知识图谱实现可解释的声明级验证和证据归因，致力于提高用户对文本验证方法的信任并强调细粒度证据的重要性。

    

    在广泛传播的信息误导和社交媒体以及人工智能生成的文本的激增中，验证和信任所遇到的信息变得日益困难。许多事实核查方法和工具已被开发，但它们往往缺乏适当的可解释性或细粒度，无法在各种情境中发挥作用。一种易于使用、可访问且能够执行细粒度证据归因的文本验证方法变得至关重要。更重要的是，建立用户对这种方法的信任需要呈现每个预测背后的理由，因为研究表明这显著影响人们对自动化系统的信任。将用户关注重点放在具体的问题内容上，而不是提供简单的笼统标签也非常重要。在本文中，我们提出了$\textit{ClaimVer，一个以人为中心的框架}$，旨在满足用户的信息需求。

    arXiv:2403.09724v1 Announce Type: new  Abstract: In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\textit{ClaimVer, a human-centric framework}$ tailored to meet users' info
    
[^100]: 文本分析用户许可协议用于标记潜在恶意软件

    Textual analysis of End User License Agreement for red-flagging potentially malicious software

    [https://arxiv.org/abs/2403.09715](https://arxiv.org/abs/2403.09715)

    该论文提出了一种通过文本分析用户许可协议，识别潜在恶意软件的方法，并使用监督分类器对其进行分类，为解决EULA过长且难以理解的问题提供了一种解决方案。

    

    每天用户会下载新软件和更新，每个下载的软件都附带一份用户许可协议（EULA），但这经常被忽略。EULA包含的信息是为了避免法律责任，然而，这可能带来一系列潜在问题，比如间谍软件或对目标系统产生非预期影响。用户不读EULA是因为文档太长，难以理解，文本摘要是这种问题的一个解决方案。我们提出了一个解决方案，可以概括EULA并将其分类为“良性”或“恶意”。我们提取了不同软件的EULA文本，然后使用八种监督分类器对文本进行分类。我们使用集成学习将EULA分类为良性或恶意。

    arXiv:2403.09715v1 Announce Type: cross  Abstract: New software and updates are downloaded by end users every day. Each dowloaded software has associated with it an End Users License Agreements (EULA), but this is rarely read. An EULA includes information to avoid legal repercussions. However,this proposes a host of potential problems such as spyware or producing an unwanted affect in the target system. End users do not read these EULA's because of length of the document and users find it extremely difficult to understand. Text summarization is one of the relevant solution to these kind of problems. This require a solution which can summarize the EULA and classify the EULA as "Benign" or "Malicious". We propose a solution in which we have summarize the EULA and classify the EULA as "Benign" or "Malicious". We extract EULA text of different sofware's then we classify the text using eight different supervised classifiers. we use ensemble learning to classify the EULA as benign or malicio
    
[^101]: 利用新型自然语言处理算法管道对免疫检查点抑制剂IrAEs进行机构级监测

    Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs Using a Novel Natural Language Processing Algorithmic Pipeline

    [https://arxiv.org/abs/2403.09708](https://arxiv.org/abs/2403.09708)

    通过新型自然语言处理算法管道，研究对108,280份临床记录进行分析，发现ICIs治疗患者中IrAEs的发生情况，并进行了治疗中断率和生存曲线的构建。

    

    背景：免疫检查点抑制剂（ICIs）已经彻底改变了癌症治疗，但可能导致严重的免疫相关不良事件（IrAEs）。监测IrAEs的发生对于个性化风险评估以及协助治疗决策至关重要。本研究通过分析接受ICIs治疗的Tel Aviv Sourasky医疗中心患者的临床记录，利用自然语言处理算法管道系统性地识别了七种常见或严重的IrAEs。我们研究了皮质类固醇的使用情况，以及IrAEs后的治疗中断率，并构建了生存曲线以可视化治疗过程中不良事件的发生。

    arXiv:2403.09708v1 Announce Type: new  Abstract: Background: Immune checkpoint inhibitors (ICIs) have revolutionized cancer treatment but can result in severe immune-related adverse events (IrAEs). Monitoring IrAEs on a large scale is essential for personalized risk profiling and assisting in treatment decisions.   Methods: In this study, we conducted an analysis of clinical notes from patients who received ICIs at the Tel Aviv Sourasky Medical Center. By employing a Natural Language Processing algorithmic pipeline, we systematically identified seven common or severe IrAEs. We examined the utilization of corticosteroids, treatment discontinuation rates following IrAEs, and constructed survival curves to visualize the occurrence of adverse events during treatment.   Results: Our analysis encompassed 108,280 clinical notes associated with 1,635 patients who had undergone ICI therapy. The detected incidence of IrAEs was consistent with previous reports, exhibiting substantial variation ac
    
[^102]: 对齐大型语言模型至特定情境规范的 Alignment Studio

    Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations

    [https://arxiv.org/abs/2403.09704](https://arxiv.org/abs/2403.09704)

    本文提出了 Alignment Studio 架构，使应用开发者能够调整大型语言模型至他们特定的价值观、社会规范、法律和其他法规，并协调潜在冲突的需求。

    

    大型语言模型的对齐通常由模型提供者进行，以添加或控制跨用例和情境中通用或普遍理解的行为。相比之下，本文提出了一种方法和架构，赋予应用开发者调整模型至其特定价值观、社会规范、法律和其他法规的能力，并在情境中协调潜在冲突的需求。我们阐述了这种对齐工作室架构的三个主要组成部分：构架者、指导者和审核者共同作用于控制语言模型的行为。我们通过一个企业内部聊天机器人对齐到业务行为准则的实例来说明这种方法。

    arXiv:2403.09704v1 Announce Type: cross  Abstract: The alignment of large language models is usually done by model providers to add or control behaviors that are common or universally understood across use cases and contexts. In contrast, in this article, we present an approach and architecture that empowers application developers to tune a model to their particular values, social norms, laws and other regulations, and orchestrate between potentially conflicting requirements in context. We lay out three main components of such an Alignment Studio architecture: Framers, Instructors, and Auditors that work in concert to control the behavior of a language model. We illustrate this approach with a running example of aligning a company's internal-facing enterprise chatbot to its business conduct guidelines.
    
[^103]: 一种对有限覆盖的混合RL在线算法的自然扩展

    A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage

    [https://arxiv.org/abs/2403.09701](https://arxiv.org/abs/2403.09701)

    混合强化学习算法中，通过将离线数据集包含在在线算法的经验重放缓冲区中进行启动，可以实现类似于基于离线数据分布引导在线探索的可证明收益，即使离线数据集没有单一策略可集中性。

    

    混合强化学习（RL）结合在线和离线数据，近年来引起了广泛关注，但关于其可证明益处的研究仍然很少。许多现有的混合RL算法对离线数据集施加覆盖假设，但我们表明这是不必要的。一个设计良好的在线算法应该在离线数据集中“填补空白”，探索行为策略未探索的状态和动作。与先前侧重于估计离线数据分布以引导在线探索的方法不同，我们表明对标准乐观在线算法的一个自然扩展——通过将离线数据集包含在经验重放缓冲区中来启动它们——即使离线数据集没有单一策略可集中性，也可实现混合数据的类似可证明收益。我们完成

    arXiv:2403.09701v1 Announce Type: new  Abstract: Hybrid Reinforcement Learning (RL), leveraging both online and offline data, has garnered recent interest, yet research on its provable benefits remains sparse. Additionally, many existing hybrid RL algorithms (Song et al., 2023; Nakamoto et al., 2023; Amortila et al., 2024) impose coverage assumptions on the offline dataset, but we show that this is unnecessary. A well-designed online algorithm should "fill in the gaps" in the offline dataset, exploring states and actions that the behavior policy did not explore. Unlike previous approaches that focus on estimating the offline data distribution to guide online exploration (Li et al., 2023b), we show that a natural extension to standard optimistic online algorithms -- warm-starting them by including the offline dataset in the experience replay buffer -- achieves similar provable gains from hybrid data even when the offline dataset does not have single-policy concentrability. We accomplish
    
[^104]: 对事实图像编辑

    Counterfactual Image Editing

    [https://arxiv.org/abs/2403.09683](https://arxiv.org/abs/2403.09683)

    本文提出了对事实图像编辑的形式化方法，展示了基于i.i.d.图像样本和标签进行对事实编辑的不可能性，并指出即使知晓潜在生成因素与图像之间的因果关系，也无法提供关于模型输出结果的任何保证。

    

    对事实图像编辑是生成人工智能中的一项重要任务，它询问了如果某些特征不同，图像将会呈现怎样的外观。目前关于这个话题的文献主要集中在改变单个特征上，却不谈论这些特征之间的因果关系，而这是真实世界中所存在的。本文使用形式语言对对事实图像编辑任务加以形式化，并通过一种称为增强结构因果模型（ASCMs）的特殊模型来对潜在生成因素与图像之间的因果关系进行建模。其次，我们展示了两个基本的不可能结果：（1）仅仅依靠i.i.d.图像样本及其对应标签是不可能进行对事实编辑的；（2）即使潜在生成因素与图像之间的因果关系是可用的，也无法保证模型输出的结果。第三，我们为这一问题提出了一种放松的解决方案。

    arXiv:2403.09683v1 Announce Type: cross  Abstract: Counterfactual image editing is an important task in generative AI, which asks how an image would look if certain features were different. The current literature on the topic focuses primarily on changing individual features while remaining silent about the causal relationships between these features, as present in the real world. In this paper, we formalize the counterfactual image editing task using formal language, modeling the causal relationships between latent generative factors and images through a special type of model called augmented structural causal models (ASCMs). Second, we show two fundamental impossibility results: (1) counterfactual editing is impossible from i.i.d. image samples and their corresponding labels alone; (2) even when the causal relationships between the latent generative factors and images are available, no guarantees regarding the output of the model can be provided. Third, we propose a relaxation for th
    
[^105]: ViT-MUL：最近应用于视觉Transformer的机器遗忘方法的基线研究

    ViT-MUL: A Baseline Study on Recent Machine Unlearning Methods Applied to Vision Transformers

    [https://arxiv.org/abs/2403.09681](https://arxiv.org/abs/2403.09681)

    该论文通过对最新机器遗忘算法和数据集在Vision Transformers上的实验，为Vision Transformers定制的机器遗忘（MUL）方法进行了基线研究，为该领域的进一步研究提供了有价值的见解。

    

    机器遗忘（MUL）是机器学习中一个新兴领域，旨在从训练模型中删除特定训练数据点的学习信息。尽管近年来计算机视觉领域对MUL的研究较为活跃，但大部分工作集中在基于ResNet的模型上。鉴于Vision Transformer（ViT）已经成为主要的模型架构，特定于ViT的MUL的详细研究是必不可少的。本文通过使用最新的MUL算法和数据集对ViTs进行了全面实验。我们预期，我们的实验、消融研究和发现可以提供有价值的见解，并激发该领域的进一步研究。

    arXiv:2403.09681v1 Announce Type: cross  Abstract: Machine unlearning (MUL) is an arising field in machine learning that seeks to erase the learned information of specific training data points from a trained model. Despite the recent active research in MUL within computer vision, the majority of work has focused on ResNet-based models. Given that Vision Transformers (ViT) have become the predominant model architecture, a detailed study of MUL specifically tailored to ViT is essential. In this paper, we present comprehensive experiments on ViTs using recent MUL algorithms and datasets. We anticipate that our experiments, ablation studies, and findings could provide valuable insights and inspire further research in this field.
    
[^106]: 预排序Tsetlin机器（基因K-Medoid方法）

    Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)

    [https://arxiv.org/abs/2403.09680](https://arxiv.org/abs/2403.09680)

    该论文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段方法，在MNIST级别的分类问题上取得了显著的精度提升，以及训练时间和推理时间大幅度减少。

    

    本文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段。首先，利用快速遗传算法从数据集中确定N个数据点，以解决最大离散化问题。然后，这些被用作运行K-Medoid聚类算法的初始放置。最后，利用快速遗传算法通过最大化汉明距离来对齐N个独立的Tsetlin Machines。对于MNIST级别的分类问题，结果显示准确度提高了高达10％，训练时间减少了约383倍，推理时间减少了约86倍。

    arXiv:2403.09680v1 Announce Type: cross  Abstract: This paper proposes a machine learning pre-sort stage to traditional supervised learning using Tsetlin Machines. Initially, N data-points are identified from the dataset using an expedited genetic algorithm to solve the maximum dispersion problem. These are then used as the initial placement to run the K-Medoid clustering algorithm. Finally, an expedited genetic algorithm is used to align N independent Tsetlin Machines by maximising hamming distance. For MNIST level classification problems, results demonstrate up to 10% improvement in accuracy, approx. 383X reduction in training time and approx. 86X reduction in inference time.
    
[^107]: 避开生成的替代事实的危险：以ChatGPT-4制造的Ω变种案例作为医学误信息的警示故事

    Navigating the Peril of Generated Alternative Facts: A ChatGPT-4 Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation

    [https://arxiv.org/abs/2403.09674](https://arxiv.org/abs/2403.09674)

    本研究展示了AI（ChatGPT-4）如何轻松制造令人信服但完全虚构的科学数据，以制造出一个完全虚构的医学案例来警示医学误信息的危害。

    

    在人工智能与医学研究交织的时代，真相的披露变得日益复杂。本研究表面上审查了一种所谓的新型SARS-CoV-2变种，被称为Ω变种，展示在S基因区域中有31个独特突变。然而，这个故事的真正潜台词是展示了AI（具体来说是ChatGPT-4）可以如何轻松地制造令人信服但完全虚构的科学数据。所谓的Ω变种在一个完全接种疫苗、之前感染过的35岁男性中被鉴定出现严重COVID-19症状。通过详细的，尽管是虚拟的，基因组分析和接触者追踪，本研究模拟了真实病例报告的严谨方法，从而为一个引人入胜但完全构造的叙述奠定了基础。整个病例研究是由OpenAI的大型语言模型ChatGPT-4生成的Ω变种。

    arXiv:2403.09674v1 Announce Type: new  Abstract: In an era where artificial intelligence (AI) intertwines with medical research, the delineation of truth becomes increasingly complex. This study ostensibly examines a purported novel SARS-CoV-2 variant, dubbed the Omega variant, showcasing 31 unique mutations in the S gene region. However, the real undercurrent of this narrative is a demonstration of the ease with which AI, specifically ChatGPT-4, can fabricate convincing yet entirely fictional scientific data. The so-called Omega variant was identified in a fully vaccinated, previously infected 35-year-old male presenting with severe COVID-19 symptoms. Through a detailed, albeit artificial, genomic analysis and contact tracing, this study mirrors the rigorous methodology of genuine case reports, thereby setting the stage for a compelling but entirely constructed narrative. The entire case study was generated by ChatGPT-4, a large language model by OpenAI. The fabricated Omega variant f
    
[^108]: FoldToken：通过矢量量化及更多方法学习蛋白质语言

    FoldToken: Learning Protein Language via Vector Quantization and Beyond

    [https://arxiv.org/abs/2403.09673](https://arxiv.org/abs/2403.09673)

    通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。

    

    是否存在一种同时描述蛋白质序列和结构的外语？由于连续3D点表示的蛋白质结构与离散序列的对比建模方式，长期以来一直存在挑战。我们引入了\textbf{FoldTokenizer}，将蛋白质序列-结构表示为离散符号。这种创新方法涉及将残基类型和结构投射到一个离散空间中，通过一个信息保存的重构损失进行指导。我们将学习到的离散符号称为\textbf{FoldToken}，而FoldTokens的序列则成为一种新的蛋白质语言，将蛋白质序列-结构转化为一种统一的形态。我们将创建的蛋白质语言应用于普通主干修补和抗体设计任务，构建了首个GPT风格模型(\textbf{FoldGPT})用于具有良好结果的序列-结构共生产。我们成功的关键在于显著的增强

    arXiv:2403.09673v1 Announce Type: cross  Abstract: Is there a foreign language describing protein sequences and structures simultaneously? Protein structures, represented by continuous 3D points, have long posed a challenge due to the contrasting modeling paradigms of discrete sequences. We introduce \textbf{FoldTokenizer} to represent protein sequence-structure as discrete symbols. This innovative approach involves projecting residue types and structures into a discrete space, guided by a reconstruction loss for information preservation. We refer to the learned discrete symbols as \textbf{FoldToken}, and the sequence of FoldTokens serves as a new protein language, transforming the protein sequence-structure into a unified modality. We apply the created protein language on general backbone inpainting and antibody design tasks, building the first GPT-style model (\textbf{FoldGPT}) for sequence-structure co-generation with promising results. Key to our success is the substantial enhancem
    
[^109]: COMPRER：增强医学图像表征的多模态多目标预训练框架

    COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced Medical Image Representation

    [https://arxiv.org/abs/2403.09672](https://arxiv.org/abs/2403.09672)

    COMPRER提出了一种新颖的多模态、多目标预训练框架，可以增强医学图像表征，并通过多目标训练提高了特定任务的结果。

    

    多模态人工智能（AI）的实质性进展促进了将不同医学模态相结合以实现整体健康评估。我们提出了COMPRER，一个新颖的多模态、多目标预训练框架，可以增强医学图像表征、诊断推断和疾病预后。COMPRER采用多目标训练框架，其中每个目标向模型引入不同的知识。其中包括整合不同成像模态信息的多模态损失；赋予模型识别时间模式的时间损失；添加适当的医学洞见的医学测量预测；最后，通过重建损失保证潜在空间内的图像结构完整性。尽管存在多个目标可能削弱任务性能的担忧，但我们的研究结果表明，这种组合实际上提高了特定任务的结果。

    arXiv:2403.09672v1 Announce Type: cross  Abstract: Substantial advances in multi-modal Artificial Intelligence (AI) facilitate the combination of diverse medical modalities to achieve holistic health assessments. We present COMPRER , a novel multi-modal, multi-objective pretraining framework which enhances medical-image representation, diagnostic inferences, and prognosis of diseases. COMPRER employs a multi-objective training framework, where each objective introduces distinct knowledge to the model. This includes a multimodal loss that consolidates information across different imaging modalities; A temporal loss that imparts the ability to discern patterns over time; Medical-measure prediction adds appropriate medical insights; Lastly, reconstruction loss ensures the integrity of image structure within the latent space. Despite the concern that multiple objectives could weaken task performance, our findings show that this combination actually boosts outcomes on certain tasks. Here, w
    
[^110]: 关于无监督图像到图像转换和GAN稳定性

    On Unsupervised Image-to-image translation and GAN stability

    [https://arxiv.org/abs/2403.09646](https://arxiv.org/abs/2403.09646)

    本文研究了图像到图像转换中一个经典工作CycleGAN的一些失败案例，并假设这些失败与GAN的稳定性有关。

    

    图像到图像转换的问题既有趣又具有挑战性，因为它对其他计算机视觉应用（如着色、修补、分割等）具有潜在的影响。在完全无监督（非配对）的情况下，需要高度复杂的技术从一个领域中提取模式并成功应用到另一个领域，近年来，这个问题引起了广泛关注。这是其中一个首次成功应用于深度生成模型的问题，尤其是生成对抗网络，取得了实际影响而非仅仅是理论实力展示的惊人结果，这种结果主导了GAN的世界。在这项工作中，我们研究了该领域的一个经典工作CycleGAN [1] 的一些失败案例，并假设这些失败与GAN的稳定性有关。

    arXiv:2403.09646v1 Announce Type: cross  Abstract: The problem of image-to-image translation is one that is intruiging and challenging at the same time, for the impact potential it can have on a wide variety of other computer vision applications like colorization, inpainting, segmentation and others. Given the high-level of sophistication needed to extract patterns from one domain and successfully applying them to another, especially, in a completely unsupervised (unpaired) manner, this problem has gained much attention as of the last few years. It is one of the first problems where successful applications to deep generative models, and especially Generative Adversarial Networks achieved astounding results that are actually of realworld impact, rather than just a show of theoretical prowess; the such that has been dominating the GAN world. In this work, we study some of the failure cases of a seminal work in the field, CycleGAN [1] and hypothesize that they are GAN-stability related, a
    
[^111]: API保护的LLMs的标志泄露专有信息

    Logits of API-Protected LLMs Leak Proprietary Information

    [https://arxiv.org/abs/2403.09539](https://arxiv.org/abs/2403.09539)

    大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能

    

    大型语言模型（LLMs）的商业化导致了高级API-only接入专有模型的常见实践。在这项工作中，我们展示了即使对于模型架构有保守的假设，也可以从相对较少的API查询中学习关于API保护的LLM的大量非公开信息（例如，使用OpenAI的gpt-3.5-turbo仅花费不到1000美元）。我们的发现集中在一个关键观察上：大多数现代LLM受到了softmax瓶颈的影响，这限制了模型输出到完整输出空间的线性子空间。我们表明，这导致了一个模型图像或模型签名，从而以较低的成本解锁了几种功能：有效发现LLM的隐藏大小，获取完整词汇输出，检测和消除不同模型更新，识别给定单个完整LLM输出的源LLM，以及...

    arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
    
[^112]: 具有顺序样本均值逼近的变分推断

    Variational Inference with Sequential Sample-Average Approximations

    [https://arxiv.org/abs/2403.09429](https://arxiv.org/abs/2403.09429)

    VISA方法通过顺序样本均值逼近在计算密集型模型中实现近似推断，能够在保守选择学习率的情况下以较小的计算成本达到与标准方法相当的逼近精度。

    

    我们提出了一种具有顺序样本均值逼近（VISA）的变分推断方法，用于在计算密集型模型中进行近似推断，例如基于数值模拟的模型。VISA通过采用一系列样本均值逼近来扩展重要性加权的前向KL变分推断，这些逼近在信任区域内被视为有效。这使得可以在多个梯度步骤中重复使用模型评估，从而降低计算成本。我们在高维高斯分布、Lotka-Volterra动力学和Pickover吸引子上进行实验，结果表明，VISA可以在选择保守的学习率的情况下，以两倍或更高的计算节约达到与标准重要性加权前向KL变分推断相当的逼近精度。

    arXiv:2403.09429v1 Announce Type: cross  Abstract: We present variational inference with sequential sample-average approximation (VISA), a method for approximate inference in computationally intensive models, such as those based on numerical simulations. VISA extends importance-weighted forward-KL variational inference by employing a sequence of sample-average approximations, which are considered valid inside a trust region. This makes it possible to reuse model evaluations across multiple gradient steps, thereby reducing computational cost. We perform experiments on high-dimensional Gaussians, Lotka-Volterra dynamics, and a Pickover attractor, which demonstrate that VISA can achieve comparable approximation accuracy to standard importance-weighted forward-KL variational inference with computational savings of a factor two or more for conservatively chosen learning rates.
    
[^113]: 用理论视角重新思考医学异常检测中的自编码器

    Rethinking Autoencoders for Medical Anomaly Detection from A Theoretical Perspective

    [https://arxiv.org/abs/2403.09303](https://arxiv.org/abs/2403.09303)

    该研究从理论角度为医学异常检测中基于自编码器的重建方法提供了基础，揭示了改进AE在异常检测中的关键在于最小化信息。

    

    医学异常检测旨在仅使用正常训练数据识别异常发现，对健康筛查和识别罕见疾病至关重要。基于重建的方法，特别是利用自编码器（AEs）的方法在这一领域占主导地位。它们基于这样的假设工作：仅使用正常数据训练的AEs不能很好地重建看不见的异常区域，从而实现基于重建错误的异常检测。然而，由于重建训练目标与异常检测任务目标之间的不匹配，这一假设并不总是成立，使得这些方法在理论上不够合理。该研究侧重于为基于AE的重建方法在异常检测中提供理论基础。通过利用信息论，我们阐明了这些方法的原则，并揭示了改进AE在异常检测中的关键在于最小化信息。

    arXiv:2403.09303v1 Announce Type: new  Abstract: Medical anomaly detection aims to identify abnormal findings using only normal training data, playing a crucial role in health screening and recognizing rare diseases. Reconstruction-based methods, particularly those utilizing autoencoders (AEs), are dominant in this field. They work under the assumption that AEs trained on only normal data cannot reconstruct unseen abnormal regions well, thereby enabling the anomaly detection based on reconstruction errors. However, this assumption does not always hold due to the mismatch between the reconstruction training objective and the anomaly detection task objective, rendering these methods theoretically unsound. This study focuses on providing a theoretical foundation for AE-based reconstruction methods in anomaly detection. By leveraging information theory, we elucidate the principles of these methods and reveal that the key to improving AE in anomaly detection lies in minimizing the informati
    
[^114]: 基于分层轨迹表示的船舶行为预测聚类

    Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation

    [https://arxiv.org/abs/2403.08838](https://arxiv.org/abs/2403.08838)

    提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。

    

    船舶轨迹聚类旨在寻找相似的轨迹模式，在海上应用中被广泛应用。大多数传统方法使用预定义的规则和阈值来识别离散的船舶行为，但存在无法表示演变过程的问题。为解决这一问题，本文提出了一种基于分层船舶行为预测聚类（PC-HiV）的方法。PC-HiV首先使用分层表示将每条轨迹转换为行为序列，然后基于这些表示在每个时间戳预测演化。通过应用预测聚类和潜在编码，PC-HiV可以同时改善聚类和预测。在真实AIS数据集上的实验证明了PC-HiV相对于现有方法的优越性，展示了其在捕捉船舶行为模式方面的有效性。

    arXiv:2403.08838v1 Announce Type: cross  Abstract: Vessel trajectory clustering, which aims to find similar trajectory patterns, has been widely leveraged in overwater applications. Most traditional methods use predefined rules and thresholds to identify discrete vessel behaviors. They aim for high-quality clustering and conduct clustering on entire sequences, whether the original trajectory or its sub-trajectories, failing to represent their evolution. To resolve this problem, we propose a Predictive Clustering of Hierarchical Vessel Behavior (PC-HiV). PC-HiV first uses hierarchical representations to transform every trajectory into a behavioral sequence. Then, it predicts evolution at each timestamp of the sequence based on the representations. By applying predictive clustering and latent encoding, PC-HiV improves clustering and predictions simultaneously. Experiments on real AIS datasets demonstrate PC-HiV's superiority over existing methods, showcasing its effectiveness in capturin
    
[^115]: 物理信息生成模型用于类药分子构象

    Physics-informed generative model for drug-like molecule conformers

    [https://arxiv.org/abs/2403.07925](https://arxiv.org/abs/2403.07925)

    该模型基于扩散生成，结合深度学习技术从大型数据集中推断原子类型和几何参数，实现了类药分子构象的高精度生成，优于传统方法。

    

    我们提出了一个基于扩散的生成模型，用于构象生成。我们的模型侧重于重现成键结构，并且是从传统力场中通常找到的相关项构建的，以确保物理相关性表示。深度学习技术被用来从训练集中推断出原子类型和几何参数。通过利用最近在扩散生成方面的进展实现构象采样。通过对大型的、多样化的、类药分子的合成数据集进行训练，优化了半经验GFN2-xTB方法，实现了对成键参数的高精度预测，超过了传统的基于知识的方法。结果还与蛋白质数据库（PDB）和剑桥结构数据库（CSD）中的实验结构进行了比较。

    arXiv:2403.07925v1 Announce Type: cross  Abstract: We present a diffusion-based, generative model for conformer generation. Our model is focused on the reproduction of bonded structure and is constructed from the associated terms traditionally found in classical force fields to ensure a physically relevant representation. Techniques in deep learning are used to infer atom typing and geometric parameters from a training set. Conformer sampling is achieved by taking advantage of recent advancements in diffusion-based generation. By training on large, synthetic data sets of diverse, drug-like molecules optimized with the semiempirical GFN2-xTB method, high accuracy is achieved for bonded parameters, exceeding that of conventional, knowledge-based methods. Results are also compared to experimental structures from the Protein Databank (PDB) and Cambridge Structural Database (CSD).
    
[^116]: 点云网络的快速简单可解释性

    Fast and Simple Explainability for Point Cloud Networks

    [https://arxiv.org/abs/2403.07706](https://arxiv.org/abs/2403.07706)

    该方法提出了一种基于特征的解释（FBI）方法，通过计算每个点在瓶颈层之前的特征范数，实现了与当前XAI方法至少三个数量级的速度提升，适用于大型点云或大规模架构。

    

    我们提出了一种针对点云数据的快速简单可解释的人工智能（XAI）方法。它计算了相对于已经训练好的网络下游任务的每个点的重要性。这有助于更好地理解网络的特性，对于安全关键应用至关重要。除了调试和可视化之外，我们的低计算复杂度有助于在线反馈到网络进行推断。这可以用于减少不确定性并提高鲁棒性。在这项工作中，我们引入了“基于特征的解释”（FBI），在瓶颈层之前计算每个点的特征范数。我们分析了梯度的使用以及后瓶颈和前瓶颈策略，结果显示前瓶颈更受青睐，从平滑度和排名角度来看。与当前的XAI方法相比，我们实现了至少三个数量级的速度提升，因此适用于大型点云或大规模架构。我们的方法实现了SOTA水平。

    arXiv:2403.07706v1 Announce Type: cross  Abstract: We propose a fast and simple explainable AI (XAI) method for point cloud data. It computes pointwise importance with respect to a trained network downstream task. This allows better understanding of the network properties, which is imperative for safety-critical applications. In addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. This can be used to reduce uncertainty and to increase robustness. In this work, we introduce \emph{Feature Based Interpretability} (FBI), where we compute the features' norm, per point, before the bottleneck. We analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. We obtain at least three orders of magnitude speedup, compared to current XAI methods, thus, scalable for big point clouds or large-scale architectures. Our approach achieves SOTA re
    
[^117]: SVD-LLM: 针对大型语言模型压缩的截断感知奇异值分解

    SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression

    [https://arxiv.org/abs/2403.07378](https://arxiv.org/abs/2403.07378)

    SVD-LLM是一种新的基于SVD的LLM压缩方法，通过截断感知数据白化策略和逐层闭式模型参数更新策略，解决了现有方法的限制，实现了直接映射奇异值和压缩损失之间的关系。

    

    大型语言模型（LLMs）的进展受到其庞大尺寸的限制，这需要LLM压缩方法以实现实际部署。奇异值分解（SVD）为LLM压缩提供了一个有希望的解决方案。然而，现有的基于SVD的LLM压缩方法存在两个关键限制：截断较小的奇异值可能导致更高的压缩损失，并且在SVD截断后剩余模型参数的更新缺失。在这项工作中，我们提出了SVD-LLM，一种新的基于SVD的LLM压缩方法，解决了现有方法的限制。SVD-LLM采用了一种截断感知的数据白化策略，以确保奇异值和压缩损失之间的直接映射。此外，SVD-LLM采用一种逐层闭式模型参数更新策略，以弥补SVD截断引起的准确性降低。我们在总共11个数据集和七个m上评估了SVD-LLM。

    arXiv:2403.07378v1 Announce Type: new  Abstract: The advancements in Large Language Models (LLMs) have been hindered by their substantial sizes, which necessitate LLM compression methods for practical deployment. Singular Value Decomposition (SVD) offers a promising solution for LLM compression. However, state-of-the-art SVD-based LLM compression methods have two key limitations: truncating smaller singular values may lead to higher compression loss, and the lack of update on the remaining model parameters after SVD truncation. In this work, we propose SVD-LLM, a new SVD-based LLM compression method that addresses the limitations of existing methods. SVD-LLM incorporates a truncation-aware data whitening strategy to ensure a direct mapping between singular values and compression loss. Moreover, SVD-LLM adopts a layer-wise closed-form model parameter update strategy to compensate for accuracy degradation caused by SVD truncation. We evaluate SVD-LLM on a total of 11 datasets and seven m
    
[^118]: AdaNovo：具有条件互信息的自适应\emph{De Novo}肽片段测序

    AdaNovo: Adaptive \emph{De Novo} Peptide Sequencing with Conditional Mutual Information

    [https://arxiv.org/abs/2403.07013](https://arxiv.org/abs/2403.07013)

    AdaNovo 提出了一个新的框架，通过计算光谱和每个氨基酸/肽段之间的条件互信息，实现了自适应模型训练。

    

    质谱联用已在促进蛋白质组学方面发挥关键作用，使得可以分析生物样本中的蛋白质组成。尽管已开发了各种深度学习方法用于识别导致观察光谱的氨基酸序列（肽段），但\emph{de novo}肽段测序仍然存在挑战。为了解决这些挑战，我们提出了AdaNovo，这是一个新颖的框架，它计算了光谱和每个氨基酸/肽段之间的条件互信息（CMI），并利用CMI进行自适应模型训练。

    arXiv:2403.07013v1 Announce Type: cross  Abstract: Tandem mass spectrometry has played a pivotal role in advancing proteomics, enabling the analysis of protein composition in biological samples. Despite the development of various deep learning methods for identifying amino acid sequences (peptides) responsible for observed spectra, challenges persist in \emph{de novo} peptide sequencing. Firstly, prior methods struggle to identify amino acids with post-translational modifications (PTMs) due to their lower frequency in training data compared to canonical amino acids, further resulting in decreased peptide-level identification precision. Secondly, diverse types of noise and missing peaks in mass spectra reduce the reliability of training data (peptide-spectrum matches, PSMs). To address these challenges, we propose AdaNovo, a novel framework that calculates conditional mutual information (CMI) between the spectrum and each amino acid/peptide, using CMI for adaptive model training. Extens
    
[^119]: $\mathtt{tsGT}$：具有Transformer的随机时间序列建模

    $\mathtt{tsGT}$: Stochastic Time Series Modeling With Transformer

    [https://arxiv.org/abs/2403.05713](https://arxiv.org/abs/2403.05713)

    $\mathtt{tsGT}$是一种基于通用Transformer架构的随机时间序列模型，表现优于最先进模型，并超过其随机同行，特别在数据分布建模和边际分位值预测方面具备优势。

    

    时间序列方法在几乎所有处理时间结构化数据的科学领域中都具有基础重要性。最近，出现了一大批具有时间序列特定架构偏见的确定性Transformer模型。本文采取了不同的方向，引入了$\mathtt{tsGT}$，这是一种基于通用Transformer架构构建的随机时间序列模型。我们专注于使用一个众所周知且理论上合理的滚动窗口回测和评估协议。我们展示了$\mathtt{tsGT}$在四个常用数据集上在MAD和RMSE方面优于最先进模型，并在QL和CRPS方面超过了其随机同行。我们通过详细分析$\mathtt{tsGT}$在建模数据分布和预测边际分位值方面的能力来补充这些结果。

    arXiv:2403.05713v1 Announce Type: new  Abstract: Time series methods are of fundamental importance in virtually any field of science that deals with temporally structured data. Recently, there has been a surge of deterministic transformer models with time series-specific architectural biases. In this paper, we go in a different direction by introducing $\mathtt{tsGT}$, a stochastic time series model built on a general-purpose transformer architecture. We focus on using a well-known and theoretically justified rolling window backtesting and evaluation protocol. We show that $\mathtt{tsGT}$ outperforms the state-of-the-art models on MAD and RMSE, and surpasses its stochastic peers on QL and CRPS, on four commonly used datasets. We complement these results with a detailed analysis of $\mathtt{tsGT}$'s ability to model the data distribution and predict marginal quantile values.
    
[^120]: 使用深度增广拉格朗日方法学习受限制优化

    Learning Constrained Optimization with Deep Augmented Lagrangian Methods

    [https://arxiv.org/abs/2403.03454](https://arxiv.org/abs/2403.03454)

    本文提出了一种使用深度增广拉格朗日方法的学习受限制优化的方法，通过训练机器学习模型直接预测对偶解估计，并构建原始估计，从而实现对偶可行解对，同时迭代向原始可行性，模拟对偶上升方法。

    

    学习优化（LtO）是一个问题设置，在此设置中，一个机器学习（ML）模型被训练成模拟一个受限制优化求解器。学习产生最优和符合复杂约束的解决方案是一项困难的任务，但通常可以通过将输入空间限制为一组相关问题的分布来实现。大多数LtO方法侧重于直接学习原始问题的解决方案，并应用校正方案或损失函数惩罚来鼓励可行性。本文提出了一种替代方法，即训练ML模型直接预测对偶解估计，从而构建原始估计以形成对偶可行解对。这使得能够进行端到端训练方案，在这种方案中对偶目标被最大化作为损失函数，解决方案估计向原始可行性迭代，模拟对偶上升方法。

    arXiv:2403.03454v1 Announce Type: new  Abstract: Learning to Optimize (LtO) is a problem setting in which a machine learning (ML) model is trained to emulate a constrained optimization solver. Learning to produce optimal and feasible solutions subject to complex constraints is a difficult task, but is often made possible by restricting the input space to a limited distribution of related problems. Most LtO methods focus on directly learning solutions to the primal problem, and applying correction schemes or loss function penalties to encourage feasibility. This paper proposes an alternative approach, in which the ML model is trained instead to predict dual solution estimates directly, from which primal estimates are constructed to form dual-feasible solution pairs. This enables an end-to-end training scheme is which the dual objective is maximized as a loss function, and solution estimates iterate toward primal feasibility, emulating a Dual Ascent method. First it is shown that the poo
    
[^121]: RACE-SM:基于强化学习的社交式匝道合流自主控制

    RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging

    [https://arxiv.org/abs/2403.03359](https://arxiv.org/abs/2403.03359)

    该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。

    

    自主并行式匝道合流在人控车辆交通中仍然是自主车辆控制中存在的问题。现有非学习型车辆控制解决方案主要依赖规则和优化，但这些方法往往面临重大挑战。最近深度强化学习的进展展现了希望，并受到了重要学术关注，然而现有的基于学习的方法对其他高速公路车辆关注不足，且经常依赖不准确的道路交通假设。此外，并行式情况很少被考虑。提出了一种新颖的学习模型，用于加速和变道决策制定，该模型明确考虑了对于车辆本身及其周围车辆（可能合作或不合作）的效用，以产生符合社会规范的行为。这种新颖的奖励函数利用社交

    arXiv:2403.03359v1 Announce Type: new  Abstract: Autonomous parallel-style on-ramp merging in human controlled traffic continues to be an existing issue for autonomous vehicle control. Existing non-learning based solutions for vehicle control rely on rules and optimization primarily. These methods have been seen to present significant challenges. Recent advancements in Deep Reinforcement Learning have shown promise and have received significant academic interest however the available learning based approaches show inadequate attention to other highway vehicles and often rely on inaccurate road traffic assumptions. In addition, the parallel-style case is rarely considered. A novel learning based model for acceleration and lane change decision making that explicitly considers the utility to both the ego vehicle and its surrounding vehicles which may be cooperative or uncooperative to produce behaviour that is socially acceptable is proposed. The novel reward function makes use of Social 
    
[^122]: 具有多个协变量转移和不平衡的图像数据集聚合

    Pooling Image Datasets With Multiple Covariate Shift and Imbalance

    [https://arxiv.org/abs/2403.02598](https://arxiv.org/abs/2403.02598)

    本文从范畴论的角度提供了一个简单而有效的解决方案，完全避免了复杂的多阶段训练流程。

    

    许多学科中常见小样本大小，这需要跨多个机构汇总大致相似的数据集来研究图像与疾病结果之间的弱但相关关联。这些数据通常体现出协变量（即次要的非成像数据）的转移/不平衡。在标准统计分析中控制这些无用变量是常见的，但这些思想并不直接适用于参数过多的模型。因此，最近的工作表明，从不变表示学习中提供了一个有意义的起点，但目前的方法库仅限于一次考虑几个协变量的转移/不平衡。本文展示了如何从范畴论的角度看待这一问题，提供了一个简单而有效的解决方案，完全避免了原本需要复杂的多阶段训练流程。我们展示了该方法的效果。

    arXiv:2403.02598v1 Announce Type: new  Abstract: Small sample sizes are common in many disciplines, which necessitates pooling roughly similar datasets across multiple institutions to study weak but relevant associations between images and disease outcomes. Such data often manifest shift/imbalance in covariates (i.e., secondary non-imaging data). Controlling for such nuisance variables is common within standard statistical analysis, but the ideas do not directly apply to overparameterized models. Consequently, recent work has shown how strategies from invariant representation learning provides a meaningful starting point, but the current repertoire of methods is limited to accounting for shifts/imbalances in just a couple of covariates at a time. In this paper, we show how viewing this problem from the perspective of Category theory provides a simple and effective solution that completely avoids elaborate multi-stage training pipelines that would otherwise be needed. We show the effect
    
[^123]: 开放世界机器学习：回顾与新展望

    Open-world Machine Learning: A Review and New Outlooks

    [https://arxiv.org/abs/2403.01759](https://arxiv.org/abs/2403.01759)

    通过研究未知拒绝、新类别发现和类别增量学习，本文拓展了开放世界机器学习领域，提出了未来研究的多个潜在方向

    

    机器学习在许多应用中取得了显著成功。然而，现有研究主要基于封闭世界假设，即假定环境是静态的，模型一旦部署就是固定的。在许多现实应用中，这种基本且相当幼稚的假设可能不成立，因为开放环境复杂、动态且充满未知。在这种情况下，拒绝未知、发现新奇点，然后逐步学习，可以使模型像生物系统一样安全地并持续进化。本文通过研究未知拒绝、新类别发现和类别增量学习在统一范式中，提供了对开放世界机器学习的整体观点。详细讨论了当前方法的挑战、原则和局限性。最后，我们讨论了几个未来研究的潜在方向。本文旨在提供一份综述

    arXiv:2403.01759v1 Announce Type: new  Abstract: Machine learning has achieved remarkable success in many applications. However, existing studies are largely based on the closed-world assumption, which assumes that the environment is stationary, and the model is fixed once deployed. In many real-world applications, this fundamental and rather naive assumption may not hold because an open environment is complex, dynamic, and full of unknowns. In such cases, rejecting unknowns, discovering novelties, and then incrementally learning them, could enable models to be safe and evolve continually as biological systems do. This paper provides a holistic view of open-world machine learning by investigating unknown rejection, novel class discovery, and class-incremental learning in a unified paradigm. The challenges, principles, and limitations of current methodologies are discussed in detail. Finally, we discuss several potential directions for future research. This paper aims to provide a compr
    
[^124]: 精确推荐的端到端图-序列表示学习

    End-to-end Graph-Sequential Representation Learning for Accurate Recommendations

    [https://arxiv.org/abs/2403.00895](https://arxiv.org/abs/2403.00895)

    本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。

    

    近年来推荐系统的许多新进展集中在开发基于序列和基于图的方法上。这两种方法在建模行为数据中的复杂关系方面都证明了其有效性，从而在个性化排名和下一个推荐任务中取得了有益的成果，同时保持了良好的可扩展性。然而，它们从数据中捕捉到的信号截然不同。前者直接通过与最近物品的有序交互来表示用户，而后者旨在捕捉交互图中的间接依赖关系。本文提出了一个新颖的多重表示学习框架，利用这两种范式之间的协同作用。我们在几个数据集上的实证评估表明，利用所提出的框架相互训练序列和图组件显著改善了推荐性能。

    arXiv:2403.00895v1 Announce Type: cross  Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.
    
[^125]: 学习半线性神经算子：预测和数据同化的统一递归框架

    Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation

    [https://arxiv.org/abs/2402.15656](https://arxiv.org/abs/2402.15656)

    提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。

    

    最近神经算子（NOs）理论的进展使得能够快速而准确地计算由偏微分方程（PDEs）描述的复杂系统的解成为可能。尽管取得了巨大成功，但当前基于NO的解决方案在处理长时间尺度上的时空PDE时面临重要挑战。具体而言，当前的NO理论没有提出一个系统框架，以便根据稀疏采样的嘈杂测量有效地纠正PDE解的演化。本文提出了一种基于学习的状态空间方法来计算无限维半线性PDE的解算子。利用半线性PDE的结构和函数空间中的非线性观测者理论，我们开发了一种灵活的递归方法，通过结合预测和校正操作，允许同时进行预测和数据同化。

    arXiv:2402.15656v1 Announce Type: cross  Abstract: Recent advances in the theory of Neural Operators (NOs) have enabled fast and accurate computation of the solutions to complex systems described by partial differential equations (PDEs). Despite their great success, current NO-based solutions face important challenges when dealing with spatio-temporal PDEs over long time scales. Specifically, the current theory of NOs does not present a systematic framework to perform data assimilation and efficiently correct the evolution of PDE solutions over time based on sparsely sampled noisy measurements. In this paper, we propose a learning-based state-space approach to compute the solution operators to infinite-dimensional semilinear PDEs. Exploiting the structure of semilinear PDEs and the theory of nonlinear observers in function spaces, we develop a flexible recursive method that allows for both prediction and data assimilation by combining prediction and correction operations. The proposed 
    
[^126]: 人类大脑在听取真实和虚假音频时展现出不同模式：初步证据

    Human Brain Exhibits Distinct Patterns When Listening to Fake Versus Real Audio: Preliminary Evidence

    [https://arxiv.org/abs/2402.14982](https://arxiv.org/abs/2402.14982)

    人类大脑对真实和虚假音频有不同的反应模式，与深度伪造音频检测算法不同，这为深度伪造音频检测等领域的未来研究方向提供了重要的初步证据。

    

    本文研究了人类听取真实和虚假音频时大脑活动的变化。我们的初步结果表明，一种最先进的深度伪造音频检测算法所学习的表示，并没有显示出真实和虚假音频之间的清晰不同模式。相反，人类大脑活动，通过 EEG 测量，在个体接触虚假与真实音频时显示出不同的模式。这些初步证据为未来在深度伪造音频检测等领域提供了研究方向。

    arXiv:2402.14982v1 Announce Type: cross  Abstract: In this paper we study the variations in human brain activity when listening to real and fake audio. Our preliminary results suggest that the representations learned by a state-of-the-art deepfake audio detection algorithm, do not exhibit clear distinct patterns between real and fake audio. In contrast, human brain activity, as measured by EEG, displays distinct patterns when individuals are exposed to fake versus real audio. This preliminary evidence enables future research directions in areas such as deepfake audio detection.
    
[^127]: 通过三维分子生成的预训练和采样进行基于结构的药物设计

    Structure-Based Drug Design via 3D Molecular Generative Pre-training and Sampling

    [https://arxiv.org/abs/2402.14315](https://arxiv.org/abs/2402.14315)

    本研究提出了MolEdit3D，将3D分子生成与优化框架相结合，解决了现有基于优化的方法编辑分子时选择在2D空间中的问题。

    

    结构基药物设计旨在在先验知识下生成具有高亲和力的配体，并了解3D靶标结构。现有方法要么使用条件生成模型来学习给定目标结合位点的3D配体分布，要么迭代修改分子以优化基于结构的活性估计器。本文提出将3D分子生成与优化框架相结合，以解决现有基于优化的方法在编辑分子时选择在2D空间中，并使用分子对接来估计活性的问题。

    arXiv:2402.14315v1 Announce Type: cross  Abstract: Structure-based drug design aims at generating high affinity ligands with prior knowledge of 3D target structures. Existing methods either use conditional generative model to learn the distribution of 3D ligands given target binding sites, or iteratively modify molecules to optimize a structure-based activity estimator. The former is highly constrained by data quantity and quality, which leaves optimization-based approaches more promising in practical scenario. However, existing optimization-based approaches choose to edit molecules in 2D space, and use molecular docking to estimate the activity using docking predicted 3D target-ligand complexes. The misalignment between the action space and the objective hinders the performance of these models, especially for those employ deep learning for acceleration. In this work, we propose MolEdit3D to combine 3D molecular generation with optimization frameworks. We develop a novel 3D graph editi
    
[^128]: 强健的智能体学习因果世界模型

    Robust agents learn causal world models

    [https://arxiv.org/abs/2402.10877](https://arxiv.org/abs/2402.10877)

    智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。

    

    一直有人假设因果推理在强健且具有通用智能中起着基础作用，然而不清楚智能体是否必须学习因果模型才能推广到新的领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布转变下满足后悔界限的智能体必须学习数据生成过程的近似因果模型，对于优化智能体来说，该近似模型会收敛到真实的因果模型。我们讨论了这一结果对于多个研究领域，包括迁移学习和因果推断的影响。

    arXiv:2402.10877v1 Announce Type: new  Abstract: It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.
    
[^129]: 有符号多样化多重网络：聚类和推断

    Signed Diverse Multiplex Networks: Clustering and Inference

    [https://arxiv.org/abs/2402.10242](https://arxiv.org/abs/2402.10242)

    保留边的符号在网络构建过程中提高了估计和聚类精度，有助于解决现实世界问题。

    

    该论文介绍了一种有符号的广义随机点积图（SGRDPG）模型，这是广义随机点积图（GRDPG）的一个变种，其中边可以是正的也可以是负的。该设置被扩展为多重网络版本，其中所有层具有相同的节点集合并遵循SGRDPG。网络层的唯一公共特征是它们可以被划分为具有共同子空间结构的组，而其他情况下所有连接概率矩阵可能是完全不同的。上述设置非常灵活，并包括各种现有多重网络模型作为其特例。论文实现了两个目标。首先，它表明在网络构建过程中保留边的符号会导致更好的估计和聚类精度，因此有助于应对诸如大脑网络分析之类的现实问题。

    arXiv:2402.10242v1 Announce Type: cross  Abstract: The paper introduces a Signed Generalized Random Dot Product Graph (SGRDPG) model, which is a variant of the Generalized Random Dot Product Graph (GRDPG), where, in addition, edges can be positive or negative. The setting is extended to a multiplex version, where all layers have the same collection of nodes and follow the SGRDPG. The only common feature of the layers of the network is that they can be partitioned into groups with common subspace structures, while otherwise all matrices of connection probabilities can be all different. The setting above is extremely flexible and includes a variety of existing multiplex network models as its particular cases. The paper fulfills two objectives. First, it shows that keeping signs of the edges in the process of network construction leads to a better precision of estimation and clustering and, hence, is beneficial for tackling real world problems such as analysis of brain networks. Second, b
    
[^130]: 使用输入输出规范来支撑数据科学代码生成

    Grounding Data Science Code Generation with Input-Output Specifications

    [https://arxiv.org/abs/2402.08073](https://arxiv.org/abs/2402.08073)

    该论文提出了一种方法，通过使用输入输出规范来解决大型语言模型在生成代码时与自然语言提示和I/O规范对齐困难的问题，并在数据科学编程任务上进行了评估。

    

    最近，大型语言模型(LLM)展示了从自然语言(NL)提示生成代码的卓越能力。然而，在现实世界中，NL往往过于模糊，无法捕捉编程问题背后的真实意图，需要额外的输入输出(I/O)规范。不幸的是，LLM可能难以将其输出与NL提示和I/O规范对齐。在这篇论文中，我们提出了一种方法来缓解数据科学编程中的这个问题，其中任务需要明确的I/O规范以保证清晰度。具体而言，我们提出了GIFT4Code，一种用于基于I/O规范进行指导微调的LLM的新方法。我们的方法利用LLM本身产生的合成数据，并利用执行派生的反馈作为关键的学习信号。将该反馈以程序I/O规范的形式提供给LLM以促进指导微调。我们在两个具有挑战性的数据科学任务上评估了我们的方法。

    Large language models (LLMs) have recently demonstrated a remarkable ability to generate code from natural language (NL) prompts. However, in the real world, NL is often too ambiguous to capture the true intent behind programming problems, requiring additional input-output (I/O) specifications. Unfortunately, LLMs can have difficulty aligning their outputs with both the NL prompt and the I/O specification. In this paper, we give a way to mitigate this issue in the context of data science programming, where tasks require explicit I/O specifications for clarity. Specifically, we propose GIFT4Code, a novel approach for the instruction fine-tuning of LLMs with respect to I/O specifications. Our method leverages synthetic data produced by the LLM itself and utilizes execution-derived feedback as a key learning signal. This feedback, in the form of program I/O specifications, is provided to the LLM to facilitate instruction fine-tuning. We evaluated our approach on two challenging data scien
    
[^131]: 利用分治程序指导大型语言模型对问题求解进行引导

    Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving

    [https://arxiv.org/abs/2402.05359](https://arxiv.org/abs/2402.05359)

    该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。

    

    基础模型，如大型语言模型（LLMs），因其广泛的应用而引起了广泛的关注。现有的研究表明，适当的提示设计，如思维链，可以释放LLM在不同领域的强大能力。然而，对于处理涉及重复子任务和/或具有欺骗性内容的任务（如算术计算和文章级虚假新闻检测），现有的提示策略要么表现出表达能力不足，要么由幻觉引发中间错误。为了使LLM对这些中间错误更具辨别力，我们提出了一种以分治程序引导LLM的方法，同时确保优越的表达能力和任务分解、子任务解决和解决组装过程的分离。理论分析表明，我们的策略可以引导LLM扩展固定深度Transformer的表达能力。实验表明，我们提出的方法可以实现

    Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achiev
    
[^132]: 在预算限制下行为用户分割中的优化传递发现

    Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain

    [https://arxiv.org/abs/2402.03388](https://arxiv.org/abs/2402.03388)

    在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。

    

    用户在线行为足迹可以使公司发现基于行为的用户细分，并向用户发送特定细分的信息。在发现细分之后，通过像Facebook和Google这样的首选媒体渠道向用户发送信息可能具有挑战性，因为只有部分行为细分中的用户在媒体上找到匹配，并且只有其中一小部分看到消息（曝光）。即使高质量的发现也会在传递失败时变得无用。许多复杂的算法用于发现行为细分，然而这些算法忽略了传递组件。问题变得复杂是因为（i）发现是在公司数据（例如用户点击）的行为数据空间中进行的，而传递则是基于媒体定义的静态数据空间（例如地理位置，年龄）进行的；（ii）公司在预算限制下运作。我们引入了一种基于随机优化的算法，用于在预算限制下优化传递发现行为用户细分。

    Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral u
    
[^133]: 基于CT的胸部手术规划的解剖分割：针对3D U-shaped深度学习模型的基准研究

    CT-based Anatomical Segmentation for Thoracic Surgical Planning: A Benchmark Study for 3D U-shaped Deep Learning Models

    [https://arxiv.org/abs/2402.03230](https://arxiv.org/abs/2402.03230)

    本研究为基于CT的胸部手术规划中的解剖分割提供了针对3D U-shaped深度学习模型的基准研究，为临床应用和未来模型设计提供了宝贵的见解。

    

    最近对患者特定胸部手术规划和仿真的兴趣日益增长，需要从自动医学图像分割算法中高效、稳健地创建数字解剖模型。深度学习(DL)现在是各种放射学任务的最先进技术，而U-shaped DL模型在医学图像分割方面表现出色，自2D UNet以来就一直如此。迄今为止，通过整合不同的注意力机制和网络配置，已经提出了许多U-shaped模型的变体。借助最近大型多标签数据库的发展，对这些模型的系统基准研究可以为临床部署和未来模型设计提供宝贵的见解，但此类研究仍然很少。我们进行了针对3D U-shaped模型(3DUNet、STUNet、AttentionUNet、SwinUNETR、FocalSegNet和一种新的具有四个变体的3D SwinUnet)的第一项基准研究，重点是基于CT的胸部解剖分割。

    Recent rising interests in patient-specific thoracic surgical planning and simulation require efficient and robust creation of digital anatomical models from automatic medical image segmentation algorithms. Deep learning (DL) is now state-of-the-art in various radiological tasks, and U-shaped DL models have particularly excelled in medical image segmentation since the inception of the 2D UNet. To date, many variants of U-shaped models have been proposed by the integration of different attention mechanisms and network configurations. Leveraging the recent development of large multi-label databases, systematic benchmark studies for these models can provide valuable insights for clinical deployment and future model designs, but such studies are still rare. We conduct the first benchmark study for variants of 3D U-shaped models (3DUNet, STUNet, AttentionUNet, SwinUNETR, FocalSegNet, and a novel 3D SwinUnet with four variants) with a focus on CT-based anatomical segmentation for thoracic su
    
[^134]: 从视觉提示中学习语义代理，为深度度量学习中的参数高效微调

    Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning

    [https://arxiv.org/abs/2402.02340](https://arxiv.org/abs/2402.02340)

    本论文提出了一种基于学习视觉提示的参数高效微调方法，能够在深度度量学习任务中使预训练模型适应本地数据域并保留先前获得的知识。

    

    深度度量学习(DML)一直是机器学习社区关注的重点目标。现有解决方案集中于对传统图像数据集上进行预训练模型的微调。由于最近从更大规模数据集训练的预训练模型取得成功，将该模型适应本地数据域的DML任务，同时保留先前获得的知识，是具有挑战性的。在本文中，我们研究了用于DML任务的预训练模型的参数高效微调方法。特别是，我们提出了一种基于学习预训练视觉转换器(ViT)中的视觉提示(VPT)的新颖有效的框架。基于传统的基于代理的DML范例，我们通过将输入图像和ViT的语义信息结合到代理中来优化每个类别的视觉提示。我们证明了我们的新逼近方法在语义信息方面优于代表能力。

    Deep Metric Learning (DML) has long attracted the attention of the machine learning community as a key objective. Existing solutions concentrate on fine-tuning the pre-trained models on conventional image datasets. As a result of the success of recent pre-trained models trained from larger-scale datasets, it is challenging to adapt the model to the DML tasks in the local data domain while retaining the previously gained knowledge. In this paper, we investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks. In particular, we propose a novel and effective framework based on learning Visual Prompts (VPT) in the pre-trained Vision Transformers (ViT). Based on the conventional proxy-based DML paradigm, we augment the proxy by incorporating the semantic information from the input image and the ViT, in which we optimize the visual prompts for each class. We demonstrate that our new approximations with semantic information are superior to representative capabi
    
[^135]: 通过多模态神经网络检测脑肿瘤

    Detecting Brain Tumors through Multimodal Neural Networks

    [https://arxiv.org/abs/2402.00038](https://arxiv.org/abs/2402.00038)

    通过多模态神经网络检测脑肿瘤，在图像处理和分类中取得了令人满意的结果，并具有98%的准确率。

    

    肿瘤可以以各种形式出现在人体的不同部位。由于脑组织的复杂性，脑肿瘤的诊断和治疗特别困难。及时检测肿瘤可以降低死亡风险，并为患者的治疗过程提供便利。使用人工智能（AI）和深度学习等技术，可以显著减少通过成像技术获取图像来发现和识别肿瘤的时间和资源成本。本研究旨在评估一种多模态模型在将处理成灰度图像的磁共振成像（MRI）扫描用于分类时的性能。结果令人鼓舞，并与类似研究一致，模型准确率约为98％。我们还强调了解释性和透明性的必要性，以确保人类控制和安全性。

    Tumors can manifest in various forms and in different areas of the human body. Brain tumors are specifically hard to diagnose and treat because of the complexity of the organ in which they develop. Detecting them in time can lower the chances of death and facilitate the therapy process for patients. The use of Artificial Intelligence (AI) and, more specifically, deep learning, has the potential to significantly reduce costs in terms of time and resources for the discovery and identification of tumors from images obtained through imaging techniques. This research work aims to assess the performance of a multimodal model for the classification of Magnetic Resonance Imaging (MRI) scans processed as grayscale images. The results are promising, and in line with similar works, as the model reaches an accuracy of around 98\%. We also highlight the need for explainability and transparency to ensure human control and safety.
    
[^136]: 使用分层接触网格变换器学习灵活身体碰撞动力学

    Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer

    [https://arxiv.org/abs/2312.12467](https://arxiv.org/abs/2312.12467)

    本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习长距离依赖关系，以处理灵活体动力学挑战。

    

    最近，许多基于网格的图神经网络（GNN）模型已被提出用来建模复杂的高维物理系统。与传统数值求解器相比，这些方法取得了显着的成就，大大减少了求解时间。然而，目前尚未得到充分探讨的是它们是否有效地应对灵活体动力学的挑战，即瞬时碰撞发生在极短时间内的情况下。本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习身体空间位置之间（由碰撞引起的）长距离依赖关系--在更高级别网格中的两个接近位置对应于身体中的两个远距位置。

    arXiv:2312.12467v2 Announce Type: replace-cross  Abstract: Recently, many mesh-based graph neural network (GNN) models have been proposed for modeling complex high-dimensional physical systems. Remarkable achievements have been made in significantly reducing the solving time compared to traditional numerical solvers. These methods are typically designed to i) reduce the computational cost in solving physical dynamics and/or ii) propose techniques to enhance the solution accuracy in fluid and rigid body dynamics. However, it remains under-explored whether they are effective in addressing the challenges of flexible body dynamics, where instantaneous collisions occur within a very short timeframe. In this paper, we present Hierarchical Contact Mesh Transformer (HCMT), which uses hierarchical mesh structures and can learn long-range dependencies (occurred by collisions) among spatially distant positions of a body -- two close positions in a higher-level mesh corresponds to two distant posi
    
[^137]: 用神经$k$-形式进行单纯表示学习

    Simplicial Representation Learning with Neural $k$-Forms

    [https://arxiv.org/abs/2312.08515](https://arxiv.org/abs/2312.08515)

    本文提出了一种使用神经$k$-形式进行单纯复合物表示学习的方法，无需消息传递即可获取几何信息，具有解释性和几何一致性，并能应用微分几何工具实现通用逼近。

    

    Geometric deep learning扩展了深度学习，能够融合关于几何和拓扑数据的信息，特别是在复杂领域，如图形中。尽管消息传递在这一领域很受欢迎，但存在诸如需要重连图、数据解释模糊和过度平滑等限制。本文采用了一种不同的方法，专注于利用嵌入在$\mathbb{R}^n$中的单纯复合物的几何信息，利用节点坐标。我们使用$\mathbb{R}^n$中的微分k-形式来创建对单纯体的表示，提供了可解释性和几何一致性，无需消息传递。该方法还使我们能够应用微分几何工具，并实现了通用逼近。我们的方法高效、多功能，并适用于各种输入复合物，包括图形、单纯复合物和胞复合物。它胜过了现有的消息传递神经网络。

    arXiv:2312.08515v2 Announce Type: replace  Abstract: Geometric deep learning extends deep learning to incorporate information about the geometry and topology data, especially in complex domains like graphs. Despite the popularity of message passing in this field, it has limitations such as the need for graph rewiring, ambiguity in interpreting data, and over-smoothing. In this paper, we take a different approach, focusing on leveraging geometric information from simplicial complexes embedded in $\mathbb{R}^n$ using node coordinates. We use differential k-forms in \mathbb{R}^n to create representations of simplices, offering interpretability and geometric consistency without message passing. This approach also enables us to apply differential geometry tools and achieve universal approximation. Our method is efficient, versatile, and applicable to various input complexes, including graphs, simplicial complexes, and cell complexes. It outperforms existing message passing neural networks i
    
[^138]: 使用储层计算模型细胞中的非遗传信息动态

    Modeling non-genetic information dynamics in cells using reservoir computing

    [https://arxiv.org/abs/2312.07977](https://arxiv.org/abs/2312.07977)

    离子梯度可能使细胞形成动态多功能的生物系统，促使细胞获取、分析和响应环境信息。

    

    几乎所有细胞都使用能量和离子特异性膜泵来维持Na$^+$、K$^+$、Cl$^-$、Mg$^{++}$和Ca$^{++}$的跨膜梯度。虽然它们消耗多达细胞能量预算的1/3，但跨膜离子梯度的相应进化优势仍不清楚。在这里，我们提出离子梯度使得一个动态且多功能的生物系统成为可能，该系统获取、分析并响应环境信息。我们假设环境信号通过沿着预先存在的梯度的离子通量通过门控离子特异性膜通道传入细胞内。由此产生的细胞质离子浓度的改变可以产生局部响应，并通过沿着预先存在的和自组装的细胞骨架进行线状离子流与内质网、线粒体和细胞核交互以编排全局或区域性反应。在这里，我们通过一种准物理假设来表达我们的假设

    arXiv:2312.07977v2 Announce Type: replace-cross  Abstract: Virtually all cells use energy and ion-specific membrane pumps to maintain large transmembrane gradients of Na$^+$, K$^+$, Cl$^-$, Mg$^{++}$, and Ca$^{++}$. Although they consume up to 1/3 of a cell's energy budget, the corresponding evolutionary benefit of transmembrane ion gradients remain unclear. Here, we propose that ion gradients enable a dynamic and versatile biological system that acquires, analyzes, and responds to environmental information. We hypothesize environmental signals are transmitted into the cell by ion fluxes along pre-existing gradients through gated ion-specific membrane channels. The consequent changes of cytoplasmic ion concentration can generate a local response and orchestrate global or regional responses through wire-like ion fluxes along pre-existing and self-assembling cytoskeleton to engage the endoplasmic reticulum, mitochondria, and nucleus.   Here, we frame our hypothesis through a quasi-physic
    
[^139]: 离线强化学习中的泛化差距

    The Generalization Gap in Offline Reinforcement Learning

    [https://arxiv.org/abs/2312.05742](https://arxiv.org/abs/2312.05742)

    该研究比较了在线和离线学习方法在泛化能力上的差异，发现离线学习算法在新环境中表现不如在线学习算法，并引入了用于评估泛化能力的第一个基准测试。

    

    尽管近年来离线学习取得了一些进展，这些方法仍然是在相同的环境上进行训练和测试的。在本文中，我们比较了广泛使用的在线和离线学习方法（如在线强化学习（RL）、离线RL、序列建模和行为克隆）的泛化能力。我们的实验表明，离线学习算法在新环境中的表现不如在线学习算法。我们还引入了第一个用于评估离线学习中泛化能力的基准测试，从Procgen（2D视频游戏）和WebShop（电子商务网站）收集了多种大小和技能水平的数据集。这些数据集包含了有限数量的游戏关卡或自然语言指令的轨迹，测试时，代理要能够泛化到新的关卡或指令。我们的实验证明，现有的离线学习算法在这两个方面都很难与在线RL的表现相匹配。

    arXiv:2312.05742v2 Announce Type: replace-cross  Abstract: Despite recent progress in offline learning, these methods are still trained and tested on the same environment. In this paper, we compare the generalization abilities of widely used online and offline learning methods such as online reinforcement learning (RL), offline RL, sequence modeling, and behavioral cloning. Our experiments show that offline learning algorithms perform worse on new environments than online learning ones. We also introduce the first benchmark for evaluating generalization in offline learning, collecting datasets of varying sizes and skill-levels from Procgen (2D video games) and WebShop (e-commerce websites). The datasets contain trajectories for a limited number of game levels or natural language instructions and at test time, the agent has to generalize to new levels or instructions. Our experiments reveal that existing offline learning algorithms struggle to match the performance of online RL on both 
    
[^140]: GAPS: 几何意识、基于物理的、自监督的神经服装成衣

    GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment Draping

    [https://arxiv.org/abs/2312.01490](https://arxiv.org/abs/2312.01490)

    这项研究在神经网络服装成衣模型中引入了几何约束，使得服装只有在覆盖更大的身体时才发生伸展，解决了现有方法中出现的不真实、不一致的问题。

    

    近期神经网络、基于物理的模型可以更快速地展示服装变形，并且看起来更美观，相较于现有的方法。通过使用特定材质参数控制服装的不可伸缩性，这种配方产生了具有物理不可信伸展的不真实结果。经常被遮挡的服装被推到人体内部，这要么通过昂贵的后期处理被纠正，从而增加不一致的伸展；要么通过为每种体型部署独立的训练制度来进行修正，这限制了其可伸缩性。此外，现有方法部署的有缺陷的皮肤处理过程在松散的服装上产生不正确的结果。在本文中，我们向现有的配方引入了一个几何约束，它是碰撞感知的，并在可能的情况下强制服装不能伸展。因此，我们获得了现实的结果，其中遮挡的服装只在覆盖更大的身体时会伸展。

    arXiv:2312.01490v2 Announce Type: replace-cross  Abstract: Recent neural, physics-based modeling of garment deformations allows faster and visually aesthetic results as opposed to the existing methods. Material-specific parameters are used by the formulation to control the garment inextensibility. This delivers unrealistic results with physically implausible stretching. Oftentimes, the draped garment is pushed inside the body which is either corrected by an expensive post-processing, thus adding to further inconsistent stretching; or by deploying a separate training regime for each body type, restricting its scalability. Additionally, the flawed skinning process deployed by existing methods produces incorrect results on loose garments. In this paper, we introduce a geometrical constraint to the existing formulation that is collision-aware and imposes garment inextensibility wherever possible. Thus, we obtain realistic results where draped clothes stretch only while covering bigger body
    
[^141]: (深)线性神经网络中的权重波动和逆方差平直关系的推导

    Weight fluctuations in (deep) linear neural networks and a derivation of the inverse-variance flatness relation

    [https://arxiv.org/abs/2311.14120](https://arxiv.org/abs/2311.14120)

    该研究探讨了单层和双层线性神经网络在随机梯度下降中的稳定训练规则，并发现了权重波动在各种情况下的各向异性特征，其中双层网络中的权重波动受到层间耦合的影响，并呈现出各向异性损失。

    

    我们在合成高斯数据的随机梯度下降（SGD）的连续极限内，研究了单层和双层线性欠参数化神经网络的稳定（末态）训练规则。对于 schwach欠参数化区域中的单层网络，噪声协方差矩阵的谱明显偏离Hessian，可以归因于SGD动态的破坏详细平衡。在这种情况下，权重波动通常是各向异性的，但受各向同性损失限制。对于双层网络，我们获得了每层权重的随机动力学，并分析了相关的稳定协方差。我们确定了层间耦合作为权重波动的各向异性的新来源。与单层情况相反，权重波动经历各向异性损失，其平直度与波动的方差成反比。

    arXiv:2311.14120v2 Announce Type: replace  Abstract: We investigate the stationary (late-time) training regime of single- and two-layer linear underparameterized neural networks within the continuum limit of stochastic gradient descent (SGD) for synthetic Gaussian data. In the case of a single-layer network in the weakly underparameterized regime, the spectrum of the noise covariance matrix deviates notably from the Hessian, which can be attributed to the broken detailed balance of SGD dynamics. The weight fluctuations are in this case generally anisotropic, but are subject to an isotropic loss. For a two-layer network, we obtain the stochastic dynamics of the weights in each layer and analyze the associated stationary covariances. We identify the inter-layer coupling as a new source of anisotropy for the weight fluctuations. In contrast to the single-layer case, the weight fluctuations experience an anisotropic loss, the flatness of which is inversely related to the fluctuation varian
    
[^142]: 利用合成数据集进行云光学厚度测量的多光谱成像仪云检测

    Creating and Leveraging a Synthetic Dataset of Cloud Optical Thickness Measures for Cloud Detection in MSI

    [https://arxiv.org/abs/2311.14024](https://arxiv.org/abs/2311.14024)

    本论文提出了一种利用合成数据集进行云光学厚度测量的方法，以解决在地球观测背景下标记数据稀缺的问题。

    

    云团通常会遮蔽地球表面的光学卫星监测，从而限制了土地覆盖映射、海洋色彩分析和农田监测等地球观测活动。 在遥感领域内整合机器学习方法显著提高了各种地球观测任务的性能，包括云检测和过滤，但仍有很大改进空间。 ML方法通常依赖大量标记数据进行训练，这在地球观测背景下通常很难获得，这在云光学厚度（COT）估算方面尤为明显。 可靠的COT估计相比使用常规云类别能更精细和应用相关地控制。 为了缓解COT数据稀缺问题，本研究提出了一种新颖的合成数据集方法。

    arXiv:2311.14024v2 Announce Type: replace-cross  Abstract: Cloud formations often obscure optical satellite-based monitoring of the Earth's surface, thus limiting Earth observation (EO) activities such as land cover mapping, ocean color analysis, and cropland monitoring. The integration of machine learning (ML) methods within the remote sensing domain has significantly improved performance on a wide range of EO tasks, including cloud detection and filtering, but there is still much room for improvement. A key bottleneck is that ML methods typically depend on large amounts of annotated data for training, which is often difficult to come by in EO contexts. This is especially true when it comes to cloud optical thickness (COT) estimation. A reliable estimation of COT enables more fine-grained and application-dependent control compared to using pre-specified cloud categories, as is commonly done in practice. To alleviate the COT data scarcity problem, in this work we propose a novel synthe
    
[^143]: zrLLM：在具有大型语言模型的时间知识图上进行零样本关系学习

    zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models

    [https://arxiv.org/abs/2311.10112](https://arxiv.org/abs/2311.10112)

    本文提出了一种在时间知识图上进行零样本关系学习的方法，该方法利用大型语言模型(LLM)生成关系表示，并将其引入基于嵌入的TKGF方法中，能够捕捉关系描述中的语义信息，从而使得关系在建模时能具有相似的语义含义。

    

    模型化随时间变化的知识在时间知识图(TKGs)上已成为一个炽热话题。已经提出了各种方法来预测TKGs上的链接。其中大多数是基于嵌入的，其中学习隐藏表示以基于观察到的图上下文来表示知识图(KG)实体和关系。尽管这些方法在传统的TKG预测(TKGF)基准上表现出色，但它们在建模没有先前图上下文的未见过的零样本关系上面临强烈挑战。本文尝试解决这个问题的方法如下。我们首先将KG关系的文本描述输入大型语言模型(LLMs)中以生成关系表示，然后将它们引入基于嵌入的TKGF方法中。LLM增强的表示可以捕捉关系描述中的语义信息。这使得关系，无论是已见还是未见的，都能够获得类似的语义含义。

    arXiv:2311.10112v2 Announce Type: replace  Abstract: Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the unseen zero-shot relations that have no prior graph context. In this paper, we try to mitigate this problem as follows. We first input the text descriptions of KG relations into large language models (LLMs) for generating relation representations, and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic mean
    
[^144]: 为公平性调整文本到图像扩散模型

    Finetuning Text-to-Image Diffusion Models for Fairness

    [https://arxiv.org/abs/2311.07604](https://arxiv.org/abs/2311.07604)

    将公平性视为分布对齐问题，通过分布对齐损失和调整DFT两项技术贡献，显著减少文本到图像扩散模型中的性别、种族和其交叉偏见。

    

    社会对文本到图像扩散模型的快速采用凸显了解决其偏见的迫切需求。如果不进行干预，这些偏见可能传播出扭曲的世界观，并限制少数群体的机会。在这项工作中，我们将公平性视为一个分布对齐问题。我们的解决方案包括两个主要技术贡献：(1)一个分布对齐损失，将生成的图像的特定特征引向用户定义的目标分布，以及(2)调整了扩散模型采样过程的直接微调（调整DFT），它利用调整后的梯度直接优化在生成的图像上定义的损失。实证上，我们的方法显著减少了职业提示的性别、种族及其交叉偏见。即使只对五个软标记进行微调，性别偏见也大大减少。至关重要的是，我们的方法支持多元视角。

    arXiv:2311.07604v2 Announce Type: replace-cross  Abstract: The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives 
    
[^145]: 跟进差分描述：语言模型解决图像分类中的歧义问题

    Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification

    [https://arxiv.org/abs/2311.07593](https://arxiv.org/abs/2311.07593)

    提出了一种零样本方法Follow-up Differential Descriptions（FuDD），通过为每个图像确定模糊类，并使用大型语言模型生成新的类描述，以更好地区分目标类。

    

    一种改善视觉-语言模型（如CLIP）在图像分类中性能的有希望的方法是通过扩展类描述（即提示）的相关属性，例如使用棕色麻雀代替麻雀。然而，当前的零样本方法无论目标类之间的共同之处如何，都会选择一组属性，可能提供没有帮助区分它们的有用信息。我们提出了Follow-up Differential Descriptions（FuDD），这是一种零样本方法，可以根据每个数据集量身定制类描述，并提供更好区分目标类的附加属性。FuDD首先为每个图像确定模糊类，然后使用大型语言模型（LLM）生成新的类描述，以区分它们。

    arXiv:2311.07593v2 Announce Type: replace  Abstract: A promising approach for improving the performance of vision-language models like CLIP for image classification is to extend the class descriptions (i.e., prompts) with related attributes, e.g., using brown sparrow instead of sparrow. However, current zero-shot methods select a subset of attributes regardless of commonalities between the target classes, potentially providing no useful information that would have helped to distinguish between them. For instance, they may use color instead of bill shape to distinguish between sparrows and wrens, which are both brown. We propose Follow-up Differential Descriptions (FuDD), a zero-shot approach that tailors the class descriptions to each dataset and leads to additional attributes that better differentiate the target classes. FuDD first identifies the ambiguous classes for each image, and then uses a Large Language Model (LLM) to generate new class descriptions that differentiate between t
    
[^146]: LILO：通过压缩和文档化代码学习可解释库

    LILO: Learning Interpretable Libraries by Compressing and Documenting Code

    [https://arxiv.org/abs/2310.19791](https://arxiv.org/abs/2310.19791)

    LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。

    

    尽管大型语言模型（LLMs）在代码生成方面表现出色，但软件开发的关键方面是重构的艺术：将代码整合到可重用和可读的程序库中。本文介绍了一种名为LILO的神经符号框架，它通过迭代地合成、压缩和文档化代码来构建适合特定问题领域的库。LILO将LLM引导的程序合成与Stitch自动重构的近期算法进展相结合：Stitch是一个符号压缩系统，可以高效地识别大型代码语料库中的最佳lambda抽象。为了使这些抽象可解释，我们引入了一种自动文档（AutoDoc）过程，它根据上下文中的使用示例推断出自然语言名称和文档字符串。除了提高人类可读性外，我们发现AutoDoc通过帮助LILO的合成器解释和部署学习到的抽象来提高性能。我们对LILO进行了三个归纳式程序综合的评估。

    While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce LILO, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. LILO combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal lambda abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping LILO's synthesizer to interpret and deploy learned abstractions. We evaluate LILO on three inductive program synth
    
[^147]: CLIP的泛化性能主要源于训练-测试之间的高相似性吗？

    Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?

    [https://arxiv.org/abs/2310.09562](https://arxiv.org/abs/2310.09562)

    CLIP在经过重现ImageNet训练-测试相似性的剪枝LAION分割重新训练后，虽然在某些基准上表现有所下降，但整体性能仍然很高

    

    基于 CLIP 等基础模型被训练在数亿样本上，能够轻松泛化到新任务和输入。CLIP 出色地展示了在广泛的超出分布（OOD）基准上的零样本和少样本能力，而先前的研究主要将其归因于当今的大规模和全面的训练数据集（如 LAION）。然而，对于 CLIP 来说，像超出分布泛化这样的术语是否具有意义是值得怀疑的，因为像 LAION 这样的网页规模数据集可能只是包含许多与最初为 ImageNet 设计的常见 OOD 基准相似的样本。为了测试这一假设，我们在复制 ImageNet 的训练-测试相似性相对于常见 OOD 基准的剪枝 LAION 分割上重新训练 CLIP。虽然我们观察到在一些基准上的性能下降，但令人惊讶的是，CLIP 的整体性能仍然很高。这表明高训练-测试相似性是不足以...

    arXiv:2310.09562v2 Announce Type: replace-cross  Abstract: Foundation models like CLIP are trained on hundreds of millions of samples and effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows stellar zero-shot and few-shot capabilities on a wide range of out-of-distribution (OOD) benchmarks, which prior works attribute mainly to today's large and comprehensive training dataset (like LAION). However, it is questionable how meaningful terms like out-of-distribution generalization are for CLIP as it seems likely that web-scale datasets like LAION simply contain many samples that are similar to common OOD benchmarks originally designed for ImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that replicate ImageNet's train-test similarity with respect to common OOD benchmarks. While we observe a performance drop on some benchmarks, surprisingly, CLIP's overall performance remains high. This shows that high train-test similarity is insufficient to 
    
[^148]: 可微分欧拉特征变换用于形状分类

    Differentiable Euler Characteristic Transforms for Shape Classification

    [https://arxiv.org/abs/2310.07630](https://arxiv.org/abs/2310.07630)

    提出了一种不同iable Euler Characteristic Transform（DECT）计算层，能够实现端到端学习ECT，展现出与更复杂模型相当的性能。

    

    欧拉特征变换（ECT）已被证明是一种强大的表示方法，结合了形状和图形的几何和拓扑特征。然而，迄今为止，ECT无法学习特定任务的表示。我们克服了这一问题，并开发了一种新颖的计算层，可以使ECT以端到端的方式进行学习。我们的方法，Differentiable Euler Characteristic Transform（DECT），速度快，计算高效，同时在图形和点云分类任务中表现出与更复杂模型相当的性能。此外，我们展示了这种看似简单的统计量提供了与更复杂的拓扑深度学习层相同的拓扑表达能力。

    arXiv:2310.07630v2 Announce Type: replace  Abstract: The Euler Characteristic Transform (ECT) has proven to be a powerful representation, combining geometrical and topological characteristics of shapes and graphs. However, the ECT was hitherto unable to learn task-specific representations. We overcome this issue and develop a novel computational layer that enables learning the ECT in an end-to-end fashion. Our method, the Differentiable Euler Characteristic Transform (DECT), is fast and computationally efficient, while exhibiting performance on a par with more complex models in both graph and point cloud classification tasks. Moreover, we show that this seemingly simple statistic provides the same topological expressivity as more complex topological deep learning layers.
    
[^149]: 儿童脑瘤分割的自动集成方法

    Automated ensemble method for pediatric brain tumor segmentation

    [https://arxiv.org/abs/2308.07212](https://arxiv.org/abs/2308.07212)

    通过引入新型集成方法和创新的损失函数，利用深度学习技术实现了针对儿科患者的脑瘤精确分割模型。

    

    脑瘤仍然是全球健康领域的一个关键挑战，需要在诊断技术和治疗方法方面取得进展。本研究探讨了部署深度学习技术利用磁共振成像（MRI）模态，以针对儿科患者特定年龄段的分割模型的需求。通过引入使用ONet和UNet修改版本的新型集成方法，并结合创新的损失函数，该研究实现了对BraTS-PEDs 2023挑战的精确分割模型。数据增强包括单一和复合转换，确保模型在不同扫描协议下的鲁棒性和准确性。集成策略将ONet和UNet模型整合在一起，显示出更好的效果来捕捉特定的

    arXiv:2308.07212v2 Announce Type: replace-cross  Abstract: Brain tumors remain a critical global health challenge, necessitating advancements in diagnostic techniques and treatment methodologies. A tumor or its recurrence often needs to be identified in imaging studies and differentiated from normal brain tissue. In response to the growing need for age-specific segmentation models, particularly for pediatric patients, this study explores the deployment of deep learning techniques using magnetic resonance imaging (MRI) modalities. By introducing a novel ensemble approach using ONet and modified versions of UNet, coupled with innovative loss functions, this study achieves a precise segmentation model for the BraTS-PEDs 2023 Challenge. Data augmentation, including both single and composite transformations, ensures model robustness and accuracy across different scanning protocols. The ensemble strategy, integrating the ONet and UNet models, shows greater effectiveness in capturing specific
    
[^150]: 机器遗忘：解决方案与挑战

    Machine Unlearning: Solutions and Challenges

    [https://arxiv.org/abs/2308.07061](https://arxiv.org/abs/2308.07061)

    本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。

    

    机器学习模型可能无意中记住敏感、未经授权或恶意数据，存在隐私泄露、安全漏洞和性能降级的风险。为了解决这些问题，机器遗忘已经成为一种重要的技术，可以有选择地消除特定训练数据点对训练模型的影响。本文对机器遗忘中的解决方案进行了全面分类和分析。我们将现有解决方案分为完全遗忘方法和有效减少数据影响的近似遗忘方法。通过全面回顾解决方案，我们确定并讨论它们的优势和局限性。此外，我们提出了未来的发展方向，以推进机器遗忘并将其建立为值得信赖和适应性机器学习模型的重要能力。本文为研究人员提供了一份路线图。

    arXiv:2308.07061v2 Announce Type: replace-cross  Abstract: Machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy breaches, security vulnerabilities, and performance degradation. To address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. This paper provides a comprehensive taxonomy and analysis of the solutions in machine unlearning. We categorize existing solutions into exact unlearning approaches that remove data influence thoroughly and approximate unlearning approaches that efficiently minimize data influence. By comprehensively reviewing solutions, we identify and discuss their strengths and limitations. Furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning models. This paper provides researchers with a roadmap
    
[^151]: 注释问题：来自可穿戴传感器的原位和自我回忆活动注释的实证研究

    A Matter of Annotation: An Empirical Study on In Situ and Self-Recall Activity Annotations from Wearable Sensors

    [https://arxiv.org/abs/2305.08752](https://arxiv.org/abs/2305.08752)

    不同的标记方法对数据质量和深度学习分类器的性能有直接影响，原位方法产生的标签较少但更精确。

    

    人们对从可穿戴传感器中检测人类活动的研究是一个高度活跃的领域，使许多应用受益，从通过健康护理患者的步行监测到健身指导再到简化手工作业流程。我们提出了一项实证研究，比较了在野外数据用户研究中使用的4种不同常用的注释方法。这些方法可以分为用户驱动的、原位注释-即在记录活动之前或期间执行的注释-和回忆方法-参与者在当天结束时追溯地对其数据进行标注。我们的研究表明，不同的标记方法直接影响注释的质量，以及相应数据训练的深度学习分类器的能力。我们注意到，原位方法产生的标签较少，但更精确，而回忆方法产生的标签较多，但不够精确。此外，我们还结合了一本活动日记

    arXiv:2305.08752v2 Announce Type: replace-cross  Abstract: Research into the detection of human activities from wearable sensors is a highly active field, benefiting numerous applications, from ambulatory monitoring of healthcare patients via fitness coaching to streamlining manual work processes. We present an empirical study that compares 4 different commonly used annotation methods utilized in user studies that focus on in-the-wild data. These methods can be grouped in user-driven, in situ annotations - which are performed before or during the activity is recorded - and recall methods - where participants annotate their data in hindsight at the end of the day. Our study illustrates that different labeling methodologies directly impact the annotations' quality, as well as the capabilities of a deep learning classifier trained with the data respectively. We noticed that in situ methods produce less but more precise labels than recall methods. Furthermore, we combined an activity diary
    
[^152]: 通过接触力场和熵的触觉估计学习检测滑动

    Learning to Detect Slip through Tactile Estimation of the Contact Force Field and its Entropy

    [https://arxiv.org/abs/2303.00935](https://arxiv.org/abs/2303.00935)

    通过光学触觉传感器结合物理数据驱动方法，实时连续检测滑动，从滑动事件中提取不均匀特征解决滑动检测问题。

    

    在物体抓取和操作过程中检测滑动对于物体处理起着至关重要的作用。我们提出了一种新颖的受物理启发的数据驱动方法来实时连续检测滑动。我们使用GelSight Mini，一种光学触觉传感器，连接到自定义设计的夹具上以收集触觉数据。我们利用滑动事件期间触觉传感器读数的不均匀性来开发独特特征，将滑动检测建模为一个分类问题。

    arXiv:2303.00935v3 Announce Type: replace-cross  Abstract: Detection of slip during object grasping and manipulation plays a vital role in object handling. Existing solutions primarily rely on visual information to devise a strategy for grasping. However, for robotic systems to attain a level of proficiency comparable to humans, especially in consistently handling and manipulating unfamiliar objects, integrating artificial tactile sensing is increasingly essential. We introduce a novel physics-informed, data-driven approach to detect slip continuously in real time. We employ the GelSight Mini, an optical tactile sensor, attached to custom-designed grippers to gather tactile data. Our work leverages the inhomogeneity of tactile sensor readings during slip events to develop distinctive features and formulates slip detection as a classification problem. To evaluate our approach, we test multiple data-driven models on 10 common objects under different loading conditions, textures, and mate
    
[^153]: 具有原型的跨领域随机预训练用于强化学习

    Cross-domain Random Pre-training with Prototypes for Reinforcement Learning

    [https://arxiv.org/abs/2302.05614](https://arxiv.org/abs/2302.05614)

    提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。

    

    此工作已提交给IEEE进行可能的出版。 CRPTpro提出了一种用于基于图像的RL的跨领域自监督随机预训练框架，利用原型。 CRPTpro采用了跨领域随机策略，可以轻松快速地从多个领域中抽样多样化数据，以提高预训练效率。此外，通过提出一种新颖的内在损失进行原型表示学习，以在不同领域中预训练有效且通用的编码器。在没有微调的情况下，跨领域编码器可以高效地应用于不同领域中定义的具有挑战性的下游视觉控制RL任务。 与以前的方法如APT和Proto-RL相比，CRP

    arXiv:2302.05614v2 Announce Type: replace-cross  Abstract: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Task-agnostic cross-domain pre-training shows great potential in image-based Reinforcement Learning (RL) but poses a big challenge. In this paper, we propose CRPTpro, a Cross-domain self-supervised Random Pre-Training framework with prototypes for image-based RL. CRPTpro employs cross-domain random policy to easily and quickly sample diverse data from multiple domains, to improve pre-training efficiency. Moreover, prototypical representation learning with a novel intrinsic loss is proposed to pre-train an effective and generic encoder across different domains. Without finetuning, the cross-domain encoder can be implemented for challenging downstream visual-control RL tasks defined in different domains efficiently. Compared with prior arts like APT and Proto-RL, CRP
    
[^154]: 基于传感器增强快挂的朝向的攀岩中下降行为的检测

    Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw

    [https://arxiv.org/abs/2301.10164](https://arxiv.org/abs/2301.10164)

    通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。

    

    跟踪攀岩者的活动以改善服务并最大限度地利用他们的基础设施是攀岩健身房关注的焦点。必须从开始分析每个攀岩活动直到攀登者降下来。因此，发现攀岩者下降是至关重要的，因为这标志着攀登结束。必须在保护攀岩者和健身房成本隐私和便利性的同时解决这个问题。为此，开发了一个硬件原型，使用附在墙上的攀岩设备上的加速度传感器收集数据，称为快挂，它连接攀岩绳和螺栓锚点。相应的传感器被配置为节能，因此在攀岩健身房大量使用时在费用和更换所需时间方面变得实用。本文描述了硬件规格，并研究了传感器测得的数据。

    arXiv:2301.10164v2 Announce Type: replace-cross  Abstract: Tracking climbers' activity to improve services and make the best use of their infrastructure is a concern for climbing gyms. Each climbing session must be analyzed from beginning till lowering of the climber. Therefore, spotting the climbers descending is crucial since it indicates when the ascent has come to an end. This problem must be addressed while preserving privacy and convenience of the climbers and the costs of the gyms. To this aim, a hardware prototype is developed to collect data using accelerometer sensors attached to a piece of climbing equipment mounted on the wall, called quickdraw, that connects the climbing rope to the bolt anchors. The corresponding sensors are configured to be energy-efficient, hence become practical in terms of expenses and time consumption for replacement when using in large quantity in a climbing gym. This paper describes hardware specifications, studies data measured by the sensors in u
    
[^155]: DPAR: 具有节点级差分隐私的分离图神经网络

    DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy

    [https://arxiv.org/abs/2210.04442](https://arxiv.org/abs/2210.04442)

    本研究提出了一种名为DPAR的分离图神经网络，能实现对GNNs进行节点级差分隐私，从而保护节点及其边缘。

    

    图神经网络（GNNs）在学习图结构数据方面取得了巨大成功。 还提出了对训练模型的隐私问题，这可能暴露图的敏感信息，包括节点特征和结构信息。 本文旨在实现对GNNs进行节点级差分隐私（DP），以保护节点及其边缘。 GNNs的节点DP在本质上是困难的，因为所有直接和多跳邻居通过逐层消息传递参与每个节点的梯度计算，并且节点可以具有多少直接和多跳邻居，因此现有的DP方法将导致很高的隐私成本或由于节点敏感性高而效用不佳。 我们提出了具有差异性私人化调整页面排名（DPAR）的\textbf{D}ecoupled GNN，用于训练带有增强隐私效用

    arXiv:2210.04442v2 Announce Type: replace  Abstract: Graph Neural Networks (GNNs) have achieved great success in learning with graph-structured data. Privacy concerns have also been raised for the trained models which could expose the sensitive information of graphs including both node features and the structure information. In this paper, we aim to achieve node-level differential privacy (DP) for training GNNs so that a node and its edges are protected. Node DP is inherently difficult for GNNs because all direct and multi-hop neighbors participate in the calculation of gradients for each node via layer-wise message passing and there is no bound on how many direct and multi-hop neighbors a node can have, so existing DP methods will result in high privacy cost or poor utility due to high node sensitivity. We propose a \textbf{D}ecoupled GNN with Differentially \textbf{P}rivate \textbf{A}pproximate Personalized Page\textbf{R}ank (DPAR) for training GNNs with an enhanced privacy-utility t
    
[^156]: 具有结构化提示的持续问答学习

    Continuous QA Learning with Structured Prompts

    [https://arxiv.org/abs/2208.14602](https://arxiv.org/abs/2208.14602)

    提出了一种名为Diana的动态架构终身QA模型，通过增强语言模型学习一系列QA任务，并使用四种层次组织的提示来捕获不同粒度的QA知识，以提高模型的泛化性能。

    

    具有终身学习（LL）能力的QA模型对于实际的QA应用至关重要，并且基于架构的LL方法被报告为这些模型的有效实现。然而，将先前的方法扩展到QA任务并不是一件简单的事情，因为它们要么在测试阶段需要访问任务标识，要么不明确地对来自未见任务的样本进行建模。在本文中，我们提出了Diana：一种基于动态架构的终身QA模型，试图通过增强语言模型学习一系列QA任务。在Diana中使用了四种层次组织的提示来捕获不同粒度的QA知识。具体来说，我们将任务级提示用于捕获任务特定知识，以保持高LL性能，并保持实例级提示来学习跨不同输入样本共享的知识以提高模型的泛化性能。

    arXiv:2208.14602v3 Announce Type: replace-cross  Abstract: QA models with lifelong learning (LL) abilities are important for practical QA applications, and architecture-based LL methods are reported to be an effective implementation for these models. However, it is non-trivial to extend previous approaches to QA tasks since they either require access to task identities in the testing phase or do not explicitly model samples from unseen tasks. In this paper, we propose Diana: a dynamic architecture-based lifelong QA model that tries to learn a sequence of QA tasks with a prompt enhanced language model. Four types of hierarchically organized prompts are used in Diana to capture QA knowledge from different granularities. Specifically, we dedicate task-level prompts to capture task-specific knowledge to retain high LL performances and maintain instance-level prompts to learn knowledge shared across different input samples to improve the model's generalization performance. Moreover, we dedi
    
[^157]: StyleTalker: 一次样式驱动的音频驱动的说话头视频生成

    StyleTalker: One-shot Style-based Audio-driven Talking Head Video Generation

    [https://arxiv.org/abs/2208.10922](https://arxiv.org/abs/2208.10922)

    提出了StyleTalker，一种能够从单个参考图像合成具有准确音频同步的说话人视频的模型，并且具有几个新设计的组件来实现这一目标。

    

    我们提出了StyleTalker，一种新颖的音频驱动的说话头生成模型，可以从单个参考图像合成一个说话人的视频，其中包含准确音频同步的唇形、逼真的头部姿态和眨眼动作。具体地，通过利用预训练的图像生成器和图像编码器，我们估算了言语头部视频的潜在代码，忠实地反映了给定音频。这得益于几个新设计的组件：1）用于准确唇部同步的对比度唇同步鉴别器，2）学习与唇部运动分离的潜在运动空间的有条件序列变分自动编码器，这样我们可以独立地操纵运动和嘴唇运动，同时保持身份。3）配备了正规化流的自回归先验，学习了复杂的音频到运动多模潜在空间。借助这些组件，StyleTalker可以生成...

    arXiv:2208.10922v2 Announce Type: replace-cross  Abstract: We propose StyleTalker, a novel audio-driven talking head generation model that can synthesize a video of a talking person from a single reference image with accurately audio-synced lip shapes, realistic head poses, and eye blinks. Specifically, by leveraging a pretrained image generator and an image encoder, we estimate the latent codes of the talking head video that faithfully reflects the given audio. This is made possible with several newly devised components: 1) A contrastive lip-sync discriminator for accurate lip synchronization, 2) A conditional sequential variational autoencoder that learns the latent motion space disentangled from the lip movements, such that we can independently manipulate the motions and lip movements while preserving the identity. 3) An auto-regressive prior augmented with normalizing flow to learn a complex audio-to-motion multi-modal latent space. Equipped with these components, StyleTalker can g
    
[^158]: 学习马尔可夫状态抽象以用于深度强化学习

    Learning Markov State Abstractions for Deep Reinforcement Learning

    [https://arxiv.org/abs/2106.04379](https://arxiv.org/abs/2106.04379)

    引入了一组新颖条件，证明了学习马尔可夫抽象状态表示的充分性，并提出了结合逆模型估计和时间对比学习的实用训练过程，该方法适用于在线和离线训练，不依赖奖励信号但可以利用奖励信息。

    

    强化学习在马尔可夫决策过程（MDPs）中的一个基本假设是，相关的决策过程实际上是马尔可夫的。然而，当MDPs具有丰富的观测时，代理通常通过抽象状态表示学习，这种表示未必能保持马尔可夫性质。我们引入了一组新颖的条件，并证明它们足以学习马尔可夫抽象状态表示。然后，我们描述了一个实用的训练过程，结合了逆模型估计和时间对比学习，以学习一个近似满足这些条件的抽象。我们的新颖训练目标适用于在线和离线训练：它不需要奖励信号，但当可用时，代理可以利用奖励信息。我们在一个视觉格子世界域和一组连续控制基准任务上对我们的方法进行了实证评估。

    arXiv:2106.04379v4 Announce Type: replace-cross  Abstract: A fundamental assumption of reinforcement learning in Markov decision processes (MDPs) is that the relevant decision process is, in fact, Markov. However, when MDPs have rich observations, agents typically learn by way of an abstract state representation, and such representations are not guaranteed to preserve the Markov property. We introduce a novel set of conditions and prove that they are sufficient for learning a Markov abstract state representation. We then describe a practical training procedure that combines inverse model estimation and temporal contrastive learning to learn an abstraction that approximately satisfies these conditions. Our novel training objective is compatible with both online and offline training: it does not require a reward signal, but agents can capitalize on reward information when available. We empirically evaluate our approach on a visual gridworld domain and a set of continuous control benchmar
    
[^159]: 通过神经模式关联器进行篮内推荐

    Within-basket Recommendation via Neural Pattern Associator. (arXiv:2401.16433v1 [cs.IR])

    [http://arxiv.org/abs/2401.16433](http://arxiv.org/abs/2401.16433)

    本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。

    

    篮内推荐（WBR）是指在购物过程中为了完成一个非空购物篮而推荐商品的任务。尽管这个领域的最新创新在基准数据集上表现出了显著的性能提升，但它们常常忽视了实际用户行为的复杂性，比如1）多个购物意图的共存，2）这些意图的多粒度和3）购物过程中的交织行为（切换意图）。本文提出了一种名为神经模式关联器（NPA）的深度商品关联挖掘模型，明确地建模了上述因素。具体来说，受到向量量化的启发，NPA模型学习将常见的用户意图（或商品组合模式）编码为量化表示（也称为码本），这允许在推理阶段通过注意力驱动的查找来识别用户的购物意图。这样产生的推荐结果连贯且自解释。

    Within-basket recommendation (WBR) refers to the task of recommending items to the end of completing a non-empty shopping basket during a shopping session. While the latest innovations in this space demonstrate remarkable performance improvement on benchmark datasets, they often overlook the complexity of user behaviors in practice, such as 1) co-existence of multiple shopping intentions, 2) multi-granularity of such intentions, and 3) interleaving behavior (switching intentions) in a shopping session. This paper presents Neural Pattern Associator (NPA), a deep item-association-mining model that explicitly models the aforementioned factors. Specifically, inspired by vector quantization, the NPA model learns to encode common user intentions (or item-combination patterns) as quantized representations (a.k.a. codebook), which permits identification of users's shopping intentions via attention-driven lookup during the reasoning phase. This yields coherent and self-interpretable recommendat
    
[^160]: 基于能量的自动化模型评估

    Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])

    [http://arxiv.org/abs/2401.12689](http://arxiv.org/abs/2401.12689)

    提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。

    

    传统的机器学习模型评估协议依赖于标记的、假设独立同分布的测试数据集，而这在实际应用中往往并不常见。自动模型评估（AutoEval）提出了一种替代传统工作流程的方法，通过形成一个接近预测性能的测试管线，而无需真实标签的存在。尽管AutoEval框架近年来取得了一些成功，但仍存在过度自信、存储和计算成本高的问题。因此，我们提出了一种新颖的度量方式——元分布能量（MDE），它可以使AutoEval框架更加高效和有效。MDE的核心是建立一个关于个体样本相关信息（能量）的元分布统计量，然后通过基于能量的学习提供更平滑的表示能力。我们通过将MDE与分类损失相连接，进一步提供了理论洞见。我们还提供了大量实验证据来验证我们的方法。

    The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive
    
[^161]: Imperio: 使用语言引导的后门攻击实现任意模型控制

    Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control. (arXiv:2401.01085v1 [cs.CR])

    [http://arxiv.org/abs/2401.01085](http://arxiv.org/abs/2401.01085)

    Imperio是一个使用语言引导的后门攻击工具，可以通过语言指令实现任意模型的控制，扩展了NLP模型的后门攻击能力。

    

    在transformer架构的革命下，自然语言处理（NLP）受到了前所未有的关注。虽然NLP模型的进展已经引起了对其后门漏洞的广泛研究，但这些进展可能引入新的后门威胁还未被探索。本文提出了Imperio，它利用NLP模型的语言理解能力来丰富后门攻击。Imperio提供了一种新的模型控制体验，使对手通过语言引导的指令可以任意控制受害模型的输出。为此，我们使用语言模型来驱动条件触发生成器，并对其进行了优化，以扩展其对后门指令解释和执行的语言理解能力。我们在三个数据集、五种攻击和九种防御的实验中验证了Imperio的有效性。它可以从文本描述中产生上下文适应的触发器，并控制被攻击模型的输出。

    Revolutionized by the transformer architecture, natural language processing (NLP) has received unprecedented attention. While advancements in NLP models have led to extensive research into their backdoor vulnerabilities, the potential for these advancements to introduce new backdoor threats remains unexplored. This paper proposes Imperio, which harnesses the language understanding capabilities of NLP models to enrich backdoor attacks. Imperio provides a new model control experience. It empowers the adversary to control the victim model with arbitrary output through language-guided instructions. This is achieved using a language model to fuel a conditional trigger generator, with optimizations designed to extend its language understanding capabilities to backdoor instruction interpretation and execution. Our experiments across three datasets, five attacks, and nine defenses confirm Imperio's effectiveness. It can produce contextually adaptive triggers from text descriptions and control 
    
[^162]: 扩散模型的数据归因的有趣特性

    Intriguing Properties of Data Attribution on Diffusion Models. (arXiv:2311.00500v1 [cs.LG])

    [http://arxiv.org/abs/2311.00500](http://arxiv.org/abs/2311.00500)

    本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。

    

    数据归因旨在将模型输出追溯到训练数据。随着扩散模型的最新发展，数据归因已成为一个理想的模块，可以为高质量或版权保护的训练样本正确分配价值，确保数据贡献者得到公平的补偿或认可。已经提出了几种在理论上有动机的方法来实现数据归因，以改善计算可扩展性和效果之间的权衡。在这项工作中，我们对扩散模型进行了广泛的实验和消融研究，特别关注在CIFAR-10和CelebA上训练的DDPM以及在ArtBench上进行细调的稳定扩散模型LoRA的归因。有趣的是，我们报告了理论上不合理的设计选择在实际中大幅超越了以前的基线，无论是在线性数据建模得分还是反事实评估方面。我们的工作呈现了一个重要的创新点。

    Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a signific
    
[^163]: 用于对齐语言模型的组合偏好模型

    Compositional preference models for aligning LMs. (arXiv:2310.13011v1 [cs.CL])

    [http://arxiv.org/abs/2310.13011](http://arxiv.org/abs/2310.13011)

    用于对齐语言模型的组合偏好模型（CPMs）是一种新颖的偏好模型框架，可以分解全局偏好评估并根据可解释的特征进行标量评分，得到更好的泛化能力和鲁棒性。

    

    随着语言模型的能力越来越强，将其与人类偏好进行对齐变得越来越重要。然而，用于训练偏好模型的主流范式存在根本性的限制，例如缺乏透明度和可扩展性，以及对偏好数据集过拟合的敏感性。我们提出了组合偏好模型（CPMs），这是一个新颖的偏好模型框架，将一个全局偏好评估分解为多个可解释的特征，从一个提示的语言模型中获取这些特征的标量评分，并使用逻辑回归分类器聚合这些评分。CPMs允许控制从偏好数据中使用哪些属性来训练偏好模型，并基于被认为是人类偏好判断基础的特征构建模型。我们的实验表明，CPMs不仅改善了泛化能力，比标准偏好模型更具鲁棒性，并且使用CPMs获得的最佳n个样本比使用标准PMs的表现更好。

    As language models (LMs) become more capable, it is increasingly important to align them with human preferences. However, the dominant paradigm for training Preference Models (PMs) for that purpose suffers from fundamental limitations, such as lack of transparency and scalability, along with susceptibility to overfitting the preference dataset. We propose Compositional Preference Models (CPMs), a novel PM framework that decomposes one global preference assessment into several interpretable features, obtains scalar scores for these features from a prompted LM, and aggregates these scores using a logistic regression classifier. CPMs allow to control which properties of the preference data are used to train the preference model and to build it based on features that are believed to underlie the human preference judgment. Our experiments show that CPMs not only improve generalization and are more robust to overoptimization than standard PMs, but also that best-of-n samples obtained using C
    
[^164]: 多少个预训练任务需要用于线性回归的上下文学习？

    How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?. (arXiv:2310.08391v1 [stat.ML])

    [http://arxiv.org/abs/2310.08391](http://arxiv.org/abs/2310.08391)

    本文研究了在线性回归中的上下文学习，并发现有效的预训练只需要少量独立任务，预训练模型与贝叶斯最优算法接近。这些理论发现对ICL的统计基础提供了启示。

    

    在多样任务上进行预训练的Transformer展现了非凡的上下文学习（ICL）能力，使其能够仅基于输入上下文解决未见任务，而无需调整模型参数。本文研究了其中最简单设置的ICL：预训练线性参数化的单层线性注意力模型，用于具有高斯先验的线性回归。我们为注意力模型预训练建立了一个统计任务复杂度界，表明有效的预训练只需要少量独立任务。此外，我们证明了预训练模型与贝叶斯最优算法非常接近，即几乎实现了固定上下文长度下未见任务的贝叶斯最优风险。这些理论发现对之前的实验研究进行了补充，并为ICL的统计基础提供了启示。

    Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a linearly parameterized single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.
    
[^165]: 通过扩散行为实现得分正则化策略优化

    Score Regularized Policy Optimization through Diffusion Behavior. (arXiv:2310.07297v1 [cs.LG])

    [http://arxiv.org/abs/2310.07297](http://arxiv.org/abs/2310.07297)

    通过利用扩散行为模型，我们提出了一种在离线强化学习中用于优化策略的得分正则化方法，从而避免了耗时且计算密集的扩散采样方案，并在D4RL任务上实现了超过25倍的动作采样速度提升。

    

    最近的离线强化学习研究展示了扩散建模的巨大潜力，这充分展现了其在表达异质行为策略方面的优越性。然而，从扩散策略中采样非常缓慢，因为需要数十到数百次迭代推理步骤来进行一次动作采样。为了解决这个问题，我们提出了一种从评论家模型和预训练的扩散行为模型中提取高效确定性推理策略的方法，在优化过程中利用后者直接对策略梯度进行正则化，使用行为分布的得分函数。我们的方法在训练和评估过程中充分发挥了扩散建模的强大生成能力，同时完全绕过了计算密集和耗时的扩散采样方案。在D4RL任务上的广泛结果显示，我们的方法将动作采样速度提高了超过25倍，相比于各种领先的基于扩散的方法在运动任务中。

    Recent developments in offline reinforcement learning have uncovered the immense potential of diffusion modeling, which excels at representing heterogeneous behavior policies. However, sampling from diffusion policies is considerably slow because it necessitates tens to hundreds of iterative inference steps for one action. To address this issue, we propose to extract an efficient deterministic inference policy from critic models and pretrained diffusion behavior models, leveraging the latter to directly regularize the policy gradient with the behavior distribution's score function during optimization. Our method enjoys powerful generative capabilities of diffusion modeling while completely circumventing the computationally intensive and time-consuming diffusion sampling scheme, both during training and evaluation. Extensive results on D4RL tasks show that our method boosts action sampling speed by more than 25 times compared with various leading diffusion-based methods in locomotion ta
    
[^166]: DyST：面向实际视频的动态神经场景表示

    DyST: Towards Dynamic Neural Scene Representations on Real-World Videos. (arXiv:2310.06020v1 [cs.CV])

    [http://arxiv.org/abs/2310.06020](http://arxiv.org/abs/2310.06020)

    DyST模型通过学习动态场景的潜在分解，从实际视频中捕捉到了场景的3D结构和动态特性，并实现了对相机和场景内容的独立控制视图生成。

    

    对世界的视觉理解超越了单个图像的语义和平面结构。我们的目标是从单目实际视频中捕捉到实际场景的3D结构和动态特性。我们的Dynamic Scene Transformer（DyST）模型利用了最近的神经场景表示研究成果，学习了单目实际视频的潜在分解，包括场景内容、每个视角的场景动态和相机姿态。通过在单目视频和我们的新的合成数据集DySO上进行一种新颖的协同训练，实现了这种分离。DyST学习到了动态场景的具体潜在表示，使得可以对场景的相机和内容进行独立控制的视图生成成为可能。

    Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.
    
[^167]: 后验偏差评分对公平分类最优

    Post-hoc Bias Scoring Is Optimal For Fair Classification. (arXiv:2310.05725v1 [stat.ML])

    [http://arxiv.org/abs/2310.05725](http://arxiv.org/abs/2310.05725)

    本研究提出了一种后验偏差评分的方法，在满足公平性约束的情况下保持高准确性，并给出了基于偏差分数的修改规则。该方法适用于各种类型的公平性约束问题。

    

    我们考虑了一个在群体公平性约束下的二元分类问题，该问题可以是人口统计学公平性（DP），机会均等（EOp）或等概率（EO）之一。我们提出了在公平性约束下贝叶斯最优分类器的明确特征化，结果是不受约束分类器的简单修改规则。即，我们引入了一种新的实例级别的偏差度量，称为偏差分数，而修改规则则是在有限量的偏差分数之上的简单线性规则。基于这个特征化，我们开发了一种后验方法，使我们能够适应公平性约束同时保持较高的准确性。在DP和EOp约束的情况下，修改规则是基于单个偏差分数的阈值选择，而在EO约束的情况下，我们需要调整具有2个参数的线性修改规则。该方法还可以用于包含多个敏感属性的复合群体公平性标准的情况。

    We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive att
    
[^168]: Neur2RO: 神经二阶段鲁棒优化

    Neur2RO: Neural Two-Stage Robust Optimization. (arXiv:2310.04345v1 [math.OC])

    [http://arxiv.org/abs/2310.04345](http://arxiv.org/abs/2310.04345)

    Neur2RO是一种神经网络驱动的二阶段鲁棒优化算法，通过学习估计第二阶段问题的值函数，并嵌入到经典的列-约束生成算法中，能够高效地求解嵌套的最小-最大-最小优化问题。

    

    鲁棒优化提供了一个数学框架，用于在最坏情况下的不确定性下建模和解决决策问题。本工作解决了二阶段鲁棒优化（也称为可调整鲁棒优化）问题，在不确定性实现之前和之后进行第一阶段和第二阶段的决策。这导致了一个嵌套的最小-最大-最小优化问题，从计算上来说是非常具有挑战性的，尤其是当决策是离散的时候。我们提出了Neur2RO，这是一种高效的基于机器学习的列-约束生成（CCG）的实例算法，CCG是二阶段鲁棒优化的经典迭代算法。具体而言，我们通过一种新颖的神经网络架构来学习估计第二阶段问题的值函数，这种架构易于优化。将我们的神经网络嵌入到CCG算法中，可以快速得到高质量的解，这在两个二阶段鲁棒优化基准测试（背包问题和资本预算）的实验证明了。

    Robust optimization provides a mathematical framework for modeling and solving decision-making problems under worst-case uncertainty. This work addresses two-stage robust optimization (2RO) problems (also called adjustable robust optimization), wherein first-stage and second-stage decisions are made before and after uncertainty is realized, respectively. This results in a nested min-max-min optimization problem which is extremely challenging computationally, especially when the decisions are discrete. We propose Neur2RO, an efficient machine learning-driven instantiation of column-and-constraint generation (CCG), a classical iterative algorithm for 2RO. Specifically, we learn to estimate the value function of the second-stage problem via a novel neural network architecture that is easy to optimize over by design. Embedding our neural network into CCG yields high-quality solutions quickly as evidenced by experiments on two 2RO benchmarks, knapsack and capital budgeting. For knapsack, Ne
    
[^169]: 快速、表达力强的SE$(n)$等变网络通过在位置-方向空间中共享权重

    Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space. (arXiv:2310.02970v1 [cs.LG])

    [http://arxiv.org/abs/2310.02970](http://arxiv.org/abs/2310.02970)

    该论文通过在位置-方向空间中共享权重，提出了一种快速、表达力强的SE$(n)$等变网络。他们基于同态空间理论，推导出几何优化的边属性，并将权重共享形式化为对等处理相同点对的消息函数。他们在处理3D点云时，开发了一个高效的等变群卷积网络，并选择了$\mathbb{R}^3 {\times} S^2$作为最佳的处理空间。

    

    我们基于同态空间理论推导出用于灵活的消息传递框架的“几何优化边属性”。我们将卷积神经网络中的权重共享形式化为对等地处理并且应该被平等对待的点对的消息函数共享。我们定义了等价类，这些等价类在群中进行变换时是相同的，并且推导出唯一标识这些类别的属性。通过在这些属性上进行条件化，可以实现权重共享。作为该理论的应用，我们开发了一个高效的等变群卷积网络来处理3D点云。同态空间理论告诉我们如何在位置$\mathbb{R}^3$、位置和方向$\mathbb{R}^3 {\times} S^2$的同态空间以及群SE$(3)$上的特征图上进行群卷积。在这些选择中，$\mathbb{R}^3 {\times} S^2$是一个最佳选择，因为它具有处理方向信息的能力。

    Based on the theory of homogeneous spaces we derive \textit{geometrically optimal edge attributes} to be used within the flexible message passing framework. We formalize the notion of weight sharing in convolutional networks as the sharing of message functions over point-pairs that should be treated equally. We define equivalence classes of point-pairs that are identical up to a transformation in the group and derive attributes that uniquely identify these classes. Weight sharing is then obtained by conditioning message functions on these attributes. As an application of the theory, we develop an efficient equivariant group convolutional network for processing 3D point clouds. The theory of homogeneous spaces tells us how to do group convolutions with feature maps over the homogeneous space of positions $\mathbb{R}^3$, position and orientations $\mathbb{R}^3 {\times} S^2$, and the group SE$(3)$ itself. Among these, $\mathbb{R}^3 {\times} S^2$ is an optimal choice due to the ability to 
    
[^170]: SNIP: 用统一的预训练框架连接数学符号和数值领域

    SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.02227](http://arxiv.org/abs/2310.02227)

    SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。

    

    在一个无法缺少符号数学方程来建模复杂自然现象的时代，科学探究往往涉及到收集观察数据并将其转化为数学表达式。最近，深度学习已经成为从数据中提取洞察力的强大工具。然而，现有模型通常特化于数值领域或符号领域，并且通常在为特定任务量身定制的监督式训练中进行训练。这种方法忽视了符号方程和其数值对应物之间可能产生的重大好处。为了弥合这种差距，我们引入了SNIP，一种符号-数值集成预训练的方法，它通过在符号和数值领域之间进行联合对比学习，增强了它们在预训练嵌入中的相互相似性。通过进行潜空间分析，我们观察到SNIP提供了跨领域的表示洞察力，揭示了符号和数值之间的关联关系。

    In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic 
    
[^171]: DeepZero: 将零阶优化应用于深度模型训练的扩展

    DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training. (arXiv:2310.02025v1 [cs.LG])

    [http://arxiv.org/abs/2310.02025](http://arxiv.org/abs/2310.02025)

    DeepZero是一个扩展零阶优化到深度神经网络训练的深度学习框架，通过创新的坐标梯度估计和稀疏诱导的零阶训练协议，实现了高准确性和计算效率的优化。

    

    在无法获取一阶信息时，零阶优化已成为解决机器学习问题的一种常用技术。然而，零阶优化的可扩展性仍然是一个待解决的问题：其应用主要局限在相对小规模的机器学习问题上。我们开发了DeepZero，一个基于零阶优化的深度学习框架，通过三个主要创新将零阶优化扩展到从零开始的深度神经网络训练中。

    Zeroth-order (ZO) optimization has become a popular technique for solving machine learning (ML) problems when first-order (FO) information is difficult or impossible to obtain. However, the scalability of ZO optimization remains an open problem: Its use has primarily been limited to relatively small-scale ML problems, such as sample-wise adversarial attack generation. To our best knowledge, no prior work has demonstrated the effectiveness of ZO optimization in training deep neural networks (DNNs) without a significant decrease in performance. To overcome this roadblock, we develop DeepZero, a principled ZO deep learning (DL) framework that can scale ZO optimization to DNN training from scratch through three primary innovations. First, we demonstrate the advantages of coordinate-wise gradient estimation (CGE) over randomized vector-wise gradient estimation in training accuracy and computational efficiency. Second, we propose a sparsity-induced ZO training protocol that extends the model
    
[^172]: JoMA: 通过MLP和注意力的联合动力学来解密多层Transformer

    JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention. (arXiv:2310.00535v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00535](http://arxiv.org/abs/2310.00535)

    本文提出了联合MLP/注意力（JoMA）动态，用于解析多层Transformer架构的训练过程。通过预测非线性激活情况下注意力的行为，我们解释了多层Transformer中标记的层次组合方法。实验证实了我们的理论发现。

    

    我们提出了联合MLP/注意力（JoMA）动态，这是一种新颖的数学框架，用于理解多层Transformer架构的训练过程。通过在Transformer中去除自注意力层，我们得到仅包含MLP层的修改后动态。JoMA消除了先前分析中的不切实际的假设（例如缺乏残差连接），并预测注意力在非线性激活的情况下首先变得稀疏（为了学习重要的标记），然后变得密集（为了学习不那么重要的标记），而在线性情况下，它与现有研究一致，显示出注意力随时间变得稀疏。我们利用JoMA定性地解释了多层Transformer中如何将标记组合成层次结构，当输入标记是由潜在的层次生成模型生成时。在从现实世界数据集（Wikitext2/Wikitext103）训练的模型和各种预训练模型（OPT，Pythia）上进行的实验证实了我们的理论发现。

    We propose Joint MLP/Attention (JoMA) dynamics, a novel mathematical framework to understand the training procedure of multilayer Transformer architectures. This is achieved by integrating out the self-attention layer in Transformers, producing a modified dynamics of MLP layers only. JoMA removes unrealistic assumptions in previous analysis (e.g., lack of residual connection) and predicts that the attention first becomes sparse (to learn salient tokens), then dense (to learn less salient tokens) in the presence of nonlinear activations, while in the linear case, it is consistent with existing works that show attention becomes sparse over time. We leverage JoMA to qualitatively explains how tokens are combined to form hierarchies in multilayer Transformers, when the input tokens are generated by a latent hierarchical generative model. Experiments on models trained from real-world dataset (Wikitext2/Wikitext103) and various pre-trained models (OPT, Pythia) verify our theoretical findings
    
[^173]: 一种作为丰富高效的策略类别的一致性模型在强化学习中的应用

    Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning. (arXiv:2309.16984v1 [cs.LG])

    [http://arxiv.org/abs/2309.16984](http://arxiv.org/abs/2309.16984)

    这篇论文介绍了一种基于一致性模型的策略表示方法，在强化学习中具有高效且表达力强的特点。实验表明，一致性策略在各种RL设置中都具有良好的性能表现。

    

    基于分数的生成模型（如扩散模型）在建模多模态数据方面被证明是有效的，从图像生成到强化学习（RL）。然而，扩散模型的推理过程可能会很慢，这阻碍了它在具有迭代采样的RL中的使用。我们提出使用一致性模型作为一种高效且表达力强的策略表示，即一致性策略，并结合演员-评论家风格的算法将其应用于三种典型的RL设置：离线、离线到在线和在线。对于离线RL，我们展示了生成模型作为多模态数据中的策略的表达能力。对于离线到在线RL，一致性策略显示出比扩散策略更高的计算效率，并且性能可比。对于在线RL，一致性策略显示出显著的加速效果，甚至比扩散策略具有更高的平均性能。

    Score-based generative models like the diffusion model have been testified to be effective in modeling multi-modal data from image generation to reinforcement learning (RL). However, the inference process of diffusion model can be slow, which hinders its usage in RL with iterative sampling. We propose to apply the consistency model as an efficient yet expressive policy representation, namely consistency policy, with an actor-critic style algorithm for three typical RL settings: offline, offline-to-online and online. For offline RL, we demonstrate the expressiveness of generative models as policies from multi-modal data. For offline-to-online RL, the consistency policy is shown to be more computational efficient than diffusion policy, with a comparable performance. For online RL, the consistency policy demonstrates significant speedup and even higher average performances than the diffusion policy.
    
[^174]: 使用DeepRepViz来识别基于深度学习模型预测中的混淆因素

    Identifying confounders in deep-learning-based model predictions using DeepRepViz. (arXiv:2309.15551v1 [cs.LG])

    [http://arxiv.org/abs/2309.15551](http://arxiv.org/abs/2309.15551)

    这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。

    

    越来越多地使用深度学习模型分析神经影像数据，揭示大脑、大脑病理和心理特征的见解。然而，诸如参与者年龄、性别或影像伪影等外部的“混淆因素”变量可能会偏导致模型预测，从而阻碍模型学习相关的脑-表型关系。在本研究中，我们提出了一种名为“DeepRepViz”的解决方案，使研究人员能够系统地检测DL模型预测中的混淆因素。该框架包括(1)度量可能混淆因素的影响程度的指标和(2)允许研究人员定性检查DL模型学习内容的可视化工具。通过在模拟和神经影像数据集上进行实验证明了使用DeepRepViz与DL模型结合的益处。例如，神经影像数据集的实验揭示了性别是DL模型预测中的一个显著混淆因素。

    Deep Learning (DL) models are increasingly used to analyze neuroimaging data and uncover insights about the brain, brain pathologies, and psychological traits. However, extraneous `confounders' variables such as the age of the participants, sex, or imaging artifacts can bias model predictions, preventing the models from learning relevant brain-phenotype relationships. In this study, we provide a solution called the `DeepRepViz' framework that enables researchers to systematically detect confounders in their DL model predictions. The framework consists of (1) a metric that quantifies the effect of potential confounders and (2) a visualization tool that allows researchers to qualitatively inspect what the DL model is learning. By performing experiments on simulated and neuroimaging datasets, we demonstrate the benefits of using DeepRepViz in combination with DL models. For example, experiments on the neuroimaging datasets reveal that sex is a significant confounder in a DL model predicti
    
[^175]: 转移气候变化知识

    Transferring climate change knowledge. (arXiv:2309.14780v1 [physics.ao-ph])

    [http://arxiv.org/abs/2309.14780](http://arxiv.org/abs/2309.14780)

    通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。

    

    准确的气候预测对于气候适应和减缓至关重要。用于预测气候变化的地球系统模型模拟在对小尺度物理过程（例如云）的表示中本质上进行了近似，这是全球平均温度对增加的温室气体浓度的响应中不确定性的根源。已经开发了多种方法，用于使用历史观测约束未来预测，并减少气候预测和气候反馈的不确定性。然而，这些方法无法捕捉气候系统固有的非线性复杂性。通过使用转移学习方法，我们展示了机器学习，特别是深度神经网络，可以用于最大程度地利用和整合从地球系统模型模拟和历史观测中获得的知识，以更准确地预测21世纪全球表面温度场。

    Accurate climate projections are required for climate adaptation and mitigation. Earth system model simulations, used to project climate change, inherently make approximations in their representation of small-scale physical processes, such as clouds, that are at the root of the uncertainties in global mean temperature's response to increased greenhouse gas concentrations. Several approaches have been developed to use historical observations to constrain future projections and reduce uncertainties in climate projections and climate feedbacks. Yet those methods cannot capture the non-linear complexity inherent in the climate system. Using a Transfer Learning approach, we show that Machine Learning, in particular Deep Neural Networks, can be used to optimally leverage and merge the knowledge gained from Earth system model simulations and historical observations to more accurately project global surface temperature fields in the 21st century. For the Shared Socioeconomic Pathways (SSPs) 2-
    
[^176]: 猜测与绘图：语言模型引导的转译

    Guess & Sketch: Language Model Guided Transpilation. (arXiv:2309.14396v1 [cs.SE])

    [http://arxiv.org/abs/2309.14396](http://arxiv.org/abs/2309.14396)

    本论文通过结合概率性神经语言模型和符号化方法，提出了一种语言模型引导的转译方法，用于自动翻译汇编代码程序，以缩短维护遗留软件的时间和工程成本。

    

    维护遗留软件需要大量的软件和系统工程时间。汇编代码程序对于人类来说特别难以分析，因为它们对计算机机器状态需要低级别的控制，并且没有变量名称。现有的传统程序转换器保证正确性，但是它们是针对特定的源语言和目标编程语言进行手工工程设计的。学习式转译，即代码的自动翻译，提供了手动重写和工程努力的替代方案。自动化的符号程序转换方法保证了正确性，但是由于搜索空间指数级增长，很难扩展到较长的程序。它们刚性的基于规则的系统也限制了它们的表达能力，因此它们只能推理出一小部分程序空间。概率性神经语言模型（LMs）为每个输入生成合理的输出，但是以确保正确性为代价。在这项工作中，我们充分利用了LMs和符号化方法的优势。

    Maintaining legacy software requires many software and systems engineering hours. Assembly code programs, which demand low-level control over the computer machine state and have no variable names, are particularly difficult for humans to analyze. Existing conventional program translators guarantee correctness, but are hand-engineered for the source and target programming languages in question. Learned transpilation, i.e. automatic translation of code, offers an alternative to manual re-writing and engineering efforts. Automated symbolic program translation approaches guarantee correctness but struggle to scale to longer programs due to the exponentially large search space. Their rigid rule-based systems also limit their expressivity, so they can only reason about a reduced space of programs. Probabilistic neural language models (LMs) produce plausible outputs for every input, but do so at the cost of guaranteed correctness. In this work, we leverage the strengths of LMs and symbolic so
    
[^177]: 理解自监督学习在表格异常检测中的限制

    Understanding the limitations of self-supervised learning for tabular anomaly detection. (arXiv:2309.08374v1 [cs.LG])

    [http://arxiv.org/abs/2309.08374](http://arxiv.org/abs/2309.08374)

    本研究探讨了自监督学习在表格异常检测中的限制。通过多个实验发现，自监督学习得到的表征并不能提高表格异常检测的性能，这是由于神经网络引入了无关的特征。然而，使用神经网络表示的子空间可以恢复性能。

    

    尽管自监督学习已经改进了计算机视觉和自然语言处理中的异常检测，但表格数据是否可以从中受益尚不清楚。本文探讨了自监督学习在表格异常检测中的限制。我们在26个基准数据集上进行了多个实验，涉及各种预训练任务，以了解这种情况的原因。我们的结果证实，与使用原始数据表示相比，通过自监督学习得到的表征并不能提高表格异常检测的性能。我们展示了这是由于神经网络引入了无关的特征，从而降低了异常检测器的有效性。然而，我们证明了使用神经网络表示的子空间可以恢复性能。

    While self-supervised learning has improved anomaly detection in computer vision and natural language processing, it is unclear whether tabular data can benefit from it. This paper explores the limitations of self-supervision for tabular anomaly detection. We conduct several experiments spanning various pretext tasks on 26 benchmark datasets to understand why this is the case. Our results confirm representations derived from self-supervision do not improve tabular anomaly detection performance compared to using the raw representations of the data. We show this is due to neural networks introducing irrelevant features, which reduces the effectiveness of anomaly detectors. However, we demonstrate that using a subspace of the neural network's representation can recover performance.
    
[^178]: 旅行波编码最近的过去并增强序列学习

    Traveling Waves Encode the Recent Past and Enhance Sequence Learning. (arXiv:2309.08045v1 [cs.NE])

    [http://arxiv.org/abs/2309.08045](http://arxiv.org/abs/2309.08045)

    本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。

    

    神经活动的旅行波现象在大脑的不同区域和尺度上都有所观察到，然而，它们在计算角色上的具体作用仍存在争议。一个基于物理的假设认为，皮质层可以像波动场一样，通过沿着皮质表面传播的波动来存储顺序刺激的短期记忆。然而，由于缺乏一个简单的递归神经网络架构能够展现出这种波动，迄今为止，这个想法的计算意义一直是假设性的。在这项工作中，我们引入了一个模型来填补这个空白，我们称之为Wave-RNN (wRNN)，并展示了连通性约束和初始化在波动动力学出现中起到了关键作用。然后，我们经验证实了这样的架构的确通过一系列合成记忆任务有效地编码了最近的过去，在这些任务中，wRNN比波动模型学习更快、表现更好。

    Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically grounded hypothesis suggests that the cortical sheet may act like a wave-field capable of storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both connectivity constraints and initialization play a crucial role in the emergence of wave-like dynamics. We then empirically show how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and perform significantly better than wave-
    
[^179]: 通过提取精炼的语音和语言情感表示进行语音情感识别

    Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations. (arXiv:2309.04849v1 [cs.CL])

    [http://arxiv.org/abs/2309.04849](http://arxiv.org/abs/2309.04849)

    该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。

    

    我们提出了EmoDistill，这是一个新颖的语音情感识别（SER）框架，利用跨模态知识蒸馏来学习从语音中获取情感的强大的语言和语音表示。在推理过程中，我们的方法仅使用一串语音信号来进行单模态SER，从而减少计算开销并避免运行时的转录和语音特征提取错误。在训练过程中，我们的方法从一对经过SER微调的预训练的语音和语言教师中的嵌入和逻辑层面蒸馏信息。在IEMOCAP基准测试中的实验表明，我们的方法在准确率上优于其他单模态和多模态技术，并达到了77.49％的无权重准确率和78.91％的加权准确率的最新成绩。详细的消融研究还展示了我们方法的每个组件的影响。

    We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
    
[^180]: 将生成对立假设的过程视为知识来源 - 应用于朴素贝叶斯分类器

    Viewing the process of generating counterfactuals as a source of knowledge -- Application to the Naive Bayes classifier. (arXiv:2309.04284v1 [cs.LG])

    [http://arxiv.org/abs/2309.04284](http://arxiv.org/abs/2309.04284)

    将生成对立假设的过程视为知识来源，并应用于朴素贝叶斯分类器，展示其有趣属性。

    

    现在有许多理解算法可以理解机器学习算法的决策，其中包括基于生成对立假设示例的算法。本文提出将这个生成过程视为一种创造一定量知识的方法，这些知识可以存储并在以后以不同的方式使用。本文在加法模型中进行了说明，具体而言，是在朴素贝叶斯分类器的情况下，展示了其在此目的上的有趣属性。

    There are now many comprehension algorithms for understanding the decisions of a machine learning algorithm. Among these are those based on the generation of counterfactual examples. This article proposes to view this generation process as a source of creating a certain amount of knowledge that can be stored to be used, later, in different ways. This process is illustrated in the additive model and, more specifically, in the case of the naive Bayes classifier, whose interesting properties for this purpose are shown.
    
[^181]: 语言代理的认知架构

    Cognitive Architectures for Language Agents. (arXiv:2309.02427v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.02427](http://arxiv.org/abs/2309.02427)

    本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。

    

    最近的研究在大规模语言模型（LLMs）中增加了外部资源（例如互联网）或内部控制流（例如提示链），用于需要基于语境或推理的任务，从而产生了一类新的语言代理。尽管这些代理取得了实证成功，但我们缺乏一个系统的框架来组织现有代理并规划未来的发展。在本文中，我们借鉴了认知科学和符号人工智能的丰富历史，提出了语言代理的认知架构（CoALA）。CoALA描述了一个具有模块化记忆组件、用于与内部记忆和外部环境交互的结构化行动空间以及选择行动的通用决策过程的语言代理。我们使用CoALA对最近的大量研究进行了回顾和组织，并展望了更强大代理的可行方向。总的来说，CoALA将当今的语言代理置于上下文中。

    Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within th
    
[^182]: 变形金刚是否能学会最大公约数？

    Can transformers learn the greatest common divisor?. (arXiv:2308.15594v1 [cs.LG])

    [http://arxiv.org/abs/2308.15594](http://arxiv.org/abs/2308.15594)

    本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。

    

    本文研究小型变形金刚模型计算两个正整数的最大公约数（GCD）的能力。当训练分布和表示基准仔细选择时，模型可以达到98%的准确率，并且正确预测前100个GCD中的91个。模型的预测是确定性的，并且完全可解释的。在训练过程中，模型学会将具有相同GCD的输入对聚类，并通过其除数进行分类。基本模型通过使用小型基数编码的均匀操作数仅计算少数GCD（最多100个中的38个）：基数的除数乘积。更长的训练时间和更大的基数允许一些模型“了解”小的素数GCD。使用对数均匀操作数进行训练将性能提升到正确的73个GCD，并通过从倒数平方到对数均匀的GCD训练分布的平衡，使性能达到91个GCD。从GCD的均匀分布进行训练模型破坏了确定性模型行为。

    I investigate the capability of small transformers to compute the greatest common divisor (GCD) of two positive integers. When the training distribution and the representation base are carefully chosen, models achieve 98% accuracy and correctly predict 91 of the 100 first GCD. Model predictions are deterministic and fully interpretable. During training, the models learn to cluster input pairs with the same GCD, and classify them by their divisors. Basic models, trained from uniform operands encoded on small bases, only compute a handful of GCD (up to 38 out of 100): the products of divisors of the base. Longer training and larger bases allow some models to "grok" small prime GCD. Training from log-uniform operands boosts performance to 73 correct GCD, and balancing the training distribution of GCD, from inverse square to log-uniform, to 91 GCD. Training models from a uniform distribution of GCD breaks the deterministic model behavior.
    
[^183]: 分布式资源管理中的价格差异化游戏对联合学习的影响

    Price-Discrimination Game for Distributed Resource Management in Federated Learning. (arXiv:2308.13838v1 [cs.LG])

    [http://arxiv.org/abs/2308.13838](http://arxiv.org/abs/2308.13838)

    本论文提出了一种价格差异化游戏（PDG），通过对不同客户提供的服务进行定价差异化，改善了联合学习的性能并降低了激励客户参与联合学习的成本。

    

    在传统的联合学习中，参数服务器和多个分布式客户端可以形成典型的买方市场，其中PS/买家数量远远少于客户端/卖家数量。为了改善联合学习的性能并减少激励客户参与联合学习的成本，本文提出了对不同客户提供的服务进行定价差异化，而不是简单地为不同客户提供相同的服务定价。价格差异化基于对联合学习带来的性能改进和计算通信能力的异质性。为此，本文提出了一个价格差异化游戏（PDG），全面解决了联合学习中的分布式资源管理问题，包括多目标权衡、客户端选择和激励机制。由于PDG是一个混合整数非线性规划（MINLP）问题，本文提出了一个具有低计算成本的分布式半启发式算法来解决该问题。

    In vanilla federated learning (FL) such as FedAvg, the parameter server (PS) and multiple distributed clients can form a typical buyer's market, where the number of PS/buyers of FL services is far less than the number of clients/sellers. In order to improve the performance of FL and reduce the cost of motivating clients to participate in FL, this paper proposes to differentiate the pricing for services provided by different clients rather than simply providing the same service pricing for different clients. The price is differentiated based on the performance improvements brought to FL and their heterogeneity in computing and communication capabilities. To this end, a price-discrimination game (PDG) is formulated to comprehensively address the distributed resource management problems in FL, including multi-objective trade-off, client selection, and incentive mechanism. As the PDG is a mixed-integer nonlinear programming (MINLP) problem, a distributed semi-heuristic algorithm with low c
    
[^184]: 自我兼容性：在没有基准数据的情况下评估因果发现的方法。

    Self-Compatibility: Evaluating Causal Discovery without Ground Truth. (arXiv:2307.09552v1 [cs.LG])

    [http://arxiv.org/abs/2307.09552](http://arxiv.org/abs/2307.09552)

    本论文提出了一种在没有基准数据的情况下评估因果发现方法的新方法，通过在不同变量子集上学习的因果图之间的兼容性检测，来伪证因果关系的推断正确性。

    

    鉴于因果基本事实非常罕见，因果发现算法通常只在模拟数据上进行评估。这令人担忧，因为模拟反映了关于噪声分布、模型类别等生成过程的常见假设。在这项工作中，我们提出了一种新的方法，用于在没有基准数据的情况下对因果发现算法的输出进行伪证。我们的关键见解是，尽管统计学习寻求数据点子集之间的稳定性，但因果学习应该寻求变量子集之间的稳定性。基于这个见解，我们的方法依赖于在不同变量子集上学习的因果图之间的兼容性概念。我们证明了检测不兼容性可以伪证因果关系被错误推断的原因，这是因为假设违反或有限样本效应带来的错误。虽然通过这种兼容性测试只是对良好性能的必要条件，但我们认为它提供了强有力的证据。

    As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidenc
    
[^185]: 基于投票的多模态自动欺骗检测

    Voting-based Multimodal Automatic Deception Detection. (arXiv:2307.07516v1 [cs.LG])

    [http://arxiv.org/abs/2307.07516](http://arxiv.org/abs/2307.07516)

    本文提出了一种基于投票的多模态方法用于自动欺骗检测，通过视频的音频、视觉和文本特征进行检测。实验结果表明，我们的解决方案在欺骗检测中表现优于现有技术。

    

    自动欺骗检测一直是一个热门的研究课题，利用机器学习和深度学习自动检测欺骗给这一旧领域带来了新的光明。在本文中，我们提出了一种基于投票的方法，用于从视频中使用音频、视觉和文本特征进行自动欺骗检测。我们在两个数据集上进行了实验，分别是密歇根大学的真实试验数据集和迈阿密大学的欺骗检测数据集。视频样本被分成图像、音频和手稿的帧。我们提出的多模态投票解决方案包括三个模型。第一个模型是用于从图像中检测欺骗的卷积神经网络（CNN），第二个模型是用于从音频中检测欺骗的Mel频谱图上的支持向量机（SVM），第三个模型是用于从手稿中检测欺骗的支持向量机（SVM）上的Word2Vec。我们提出的解决方案优于现有技术水平。在图像、音频和文本上取得的最佳结果分别为97％、96％、9

    Automatic Deception Detection has been a hot research topic for a long time, using machine learning and deep learning to automatically detect deception, brings new light to this old field. In this paper, we proposed a voting-based method for automatic deception detection from videos using audio, visual and lexical features. Experiments were done on two datasets, the Real-life trial dataset by Michigan University and the Miami University deception detection dataset. Video samples were split into frames of images, audio, and manuscripts. Our Voting-based Multimodal proposed solution consists of three models. The first model is CNN for detecting deception from images, the second model is Support Vector Machine (SVM) on Mel spectrograms for detecting deception from audio and the third model is Word2Vec on Support Vector Machine (SVM) for detecting deception from manuscripts. Our proposed solution outperforms state of the art. Best results achieved on images, audio and text were 97%, 96%, 9
    
[^186]: 通过更高级任务相似性加强图上的多任务学习

    Boosting Multitask Learning on Graphs through Higher-Order Task Affinities. (arXiv:2306.14009v1 [cs.LG])

    [http://arxiv.org/abs/2306.14009](http://arxiv.org/abs/2306.14009)

    本文从多任务学习的角度重新审视在给定图上预测节点标签的问题，提出通过更高级任务相似性来加强多任务学习，并开发了一种算法来将任务分组以应对负迁移问题。

    

    在给定图上预测节点标签是一个被广泛研究的问题，有许多应用，包括社区检测和分子图预测。本文从多任务学习的角度重新审视此问题，考虑同时在图上预测多个节点标签函数。为了具体说明，考虑重叠社区检测：每个社区成员身份是一个二进制节点分类任务。由于复杂的重叠模式，当我们将多个社区检测应用到naive多任务学习时，我们发现负迁移很普遍，因为不同的节点标签之间的任务关系高度非线性。为了解决这个挑战，我们开发了一种算法，基于更高级的任务相似性度量来将任务分组。然后我们在每个任务组上拟合多任务模型，产生在基线模型上的增强过程。我们将两个任务之间的更高级的任务相似性度量估计为预测损失。

    Predicting node labels on a given graph is a widely studied problem with many applications, including community detection and molecular graph prediction. This paper considers predicting multiple node labeling functions on graphs simultaneously and revisits this problem from a multitask learning perspective. For a concrete example, consider overlapping community detection: each community membership is a binary node classification task. Due to complex overlapping patterns, we find that negative transfer is prevalent when we apply naive multitask learning to multiple community detection, as task relationships are highly nonlinear across different node labeling. To address the challenge, we develop an algorithm to cluster tasks into groups based on a higher-order task affinity measure. We then fit a multitask model on each task group, resulting in a boosting procedure on top of the baseline model. We estimate the higher-order task affinity measure between two tasks as the prediction loss o
    
[^187]: 取消七年的算法公平性后处理

    Unprocessing Seven Years of Algorithmic Fairness. (arXiv:2306.07261v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.07261](http://arxiv.org/abs/2306.07261)

    该论文取消了算法公平性中的后处理方法，并发现后处理实现的公平性-准确性Pareto边界包含了可评估的所有其他方法。

    

    七年前，研究人员提出了一种后处理方法，以使模型在不同人口群体中的误差率相等。这项工作启动了数百篇论文，声称能够改进后处理基线。我们通过对几个表格数据集上数千个模型评估的实证评估来评估这些声明。我们发现，后处理实现的公平性-准确性Pareto边界包含我们可以评估的所有其他方法。这样做，我们解决了两个常见的方法论错误，这些错误困扰了以前的观察结果。一个与使用不同的无约束基础模型比较方法有关。另一个涉及实现不同的约束放松水平的方法。我们研究的核心是一种简单的想法，我们称之为取消处理，大致对应于后处理的反演。取消处理允许直接比较使用不同基础模型和放松级别的方法。解读我们的发现。

    Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation. Interpreting our findi
    
[^188]: 生成扩散在三维湍流流动中的应用

    Generative Diffusion for 3D Turbulent Flows. (arXiv:2306.01776v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2306.01776](http://arxiv.org/abs/2306.01776)

    该论文提出了一种生成模型，可以在任意三维空间中模拟湍流现象，避免了湍流流动的不可预测性，能够快速生成高质量的流场。

    

    湍流流动通常难以预测，但二维和三维的湍流流动性质不同。在二维情况下，湍流会形成大的、连续的结构，而在三维情况下，旋涡级联成越来越小的尺度，形成许多快速变化的小尺度结构，加剧了不可预测性，难以使用回归方法。本文提出了第一个生成模型，可以在任意三维空间中模拟湍流现象，并引入了一种基于Wasserstein距离的流场质量度量方法。在多个实验中，我们证明了我们的生成扩散模型可以避免湍流流动的不可预测性，并且可以只依靠几何信息生成高质量的样本。此外，我们还展示了我们的模型可以比工业级数值求解器更快地生成湍流流场。

    Turbulent flows are well known to be chaotic and hard to predict; however, their dynamics differ between two and three dimensions. While 2D turbulence tends to form large, coherent structures, in three dimensions vortices cascade to smaller and smaller scales. This cascade creates many fast-changing, small-scale structures and amplifies the unpredictability, making regression-based methods infeasible. We propose the first generative model for forced turbulence in arbitrary 3D geometries and introduce a sample quality metric for turbulent flows based on the Wasserstein distance of the generated velocity-vorticity distribution. In several experiments, we show that our generative diffusion model circumvents the unpredictability of turbulent flows and produces high-quality samples based solely on geometric information. Furthermore, we demonstrate that our model beats an industrial-grade numerical solver in the time to generate a turbulent flow field from scratch by an order of magnitude.
    
[^189]: 对抗式自适应采样：将PINN和最优传输统一用于PDE近似

    Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs. (arXiv:2305.18702v1 [stat.ML])

    [http://arxiv.org/abs/2305.18702](http://arxiv.org/abs/2305.18702)

    本研究提出了一种新的深度生成模型来调整训练集中的随机样本，以使PDE解的残余在最小化时能保持平滑的轮廓，并通过引入对抗性损失项优化PINN模型，从而使神经网络学习稳定的解。同时本文还展示了该方法可以扩展到纳入最优传输约束，从而形成了将PINN和最优传输的优点结合起来的统一框架，用于PDE近似。

    

    求解偏微分方程（PDE）是科学计算的一个核心任务。近年来，使用神经网络逼近PDE引起了越来越多的关注，具有无网格离散的灵活性和解决高维问题的潜力。一个基本的计算困难是训练集中的随机样本引入了统计错误，可能成为最终逼近中占主导的误差，从而掩盖了神经网络的建模能力。本文提出了一种新的minmax公式，同时优化近似的解和由深度生成模型提供的训练集中的随机样本。关键思想是使用深度生成模型调整训练集中的随机样本，使近似PDE解引起的残余在最小化时能保持平滑的轮廓。这种想法是通过在PINN优化过程中引入对抗性损失项来实现的，该损失项鼓励神经网络学习稳定的解，即使训练集中的样本有限或输入含噪声。我们进一步展示，所提出的方法可以自然地扩展到纳入最优传输约束，从而形成将PINN和最优传输的优点结合起来的统一框架，用于PDE近似。

    Solving partial differential equations (PDEs) is a central task in scientific computing. Recently, neural network approximation of PDEs has received increasing attention due to its flexible meshless discretization and its potential for high-dimensional problems. One fundamental numerical difficulty is that random samples in the training set introduce statistical errors into the discretization of loss functional which may become the dominant error in the final approximation, and therefore overshadow the modeling capability of the neural network. In this work, we propose a new minmax formulation to optimize simultaneously the approximate solution, given by a neural network model, and the random samples in the training set, provided by a deep generative model. The key idea is to use a deep generative model to adjust random samples in the training set such that the residual induced by the approximate PDE solution can maintain a smooth profile when it is being minimized. Such an idea is ach
    
[^190]: 无独立性的泛化误差：去噪、线性回归和迁移学习

    Generalization Error without Independence: Denoising, Linear Regression, and Transfer Learning. (arXiv:2305.17297v1 [cs.LG])

    [http://arxiv.org/abs/2305.17297](http://arxiv.org/abs/2305.17297)

    本论文研究了具有低秩结构但非独立同分布数据的情况，在分离训练和测试分布的假设下，解决了分布偏移问题，实验结果表明，在分布偏移的情况下，本方法显著提高了泛化误差的性能。

    

    研究线性模型在真实数据中的泛化能力是统计学习中的一个核心问题。先前的一些重要工作验证了理论工作与真实数据的相关性，但这些工作由于技术假设存在限制，这些假设包括具有良好条件的协方差矩阵以及具有独立同分布数据，这些假设在真实数据中并不一定成立。此外，以前的一些关于分布偏移的工作通常对训练和测试数据的联合分布进行技术假设，并且不在真实数据上进行测试。为了解决这些问题并更好地对真实数据进行建模，我们研究了具有低秩结构但非独立同分布数据的情况，同时通过分离训练和测试分布的假设来解决分布偏移问题。我们还在这些松弛的假设下，研究了去噪问题、线性回归和迁移学习。我们的实验结果表明，相比以前的方法，在分布偏移的情况下，我们的方法显著提高了泛化误差的性能。

    Studying the generalization abilities of linear models with real data is a central question in statistical learning. While there exist a limited number of prior important works (Loureiro et al. (2021A, 2021B), Wei et al. 2022) that do validate theoretical work with real data, these works have limitations due to technical assumptions. These assumptions include having a well-conditioned covariance matrix and having independent and identically distributed data. These assumptions are not necessarily valid for real data. Additionally, prior works that do address distributional shifts usually make technical assumptions on the joint distribution of the train and test data (Tripuraneni et al. 2021, Wu and Xu 2020), and do not test on real data.  In an attempt to address these issues and better model real data, we look at data that is not I.I.D. but has a low-rank structure. Further, we address distributional shift by decoupling assumptions on the training and test distribution. We provide anal
    
[^191]: 将知识蒸馏用于短期到长期轨迹预测

    Distilling Knowledge for Short-to-Long Term Trajectory Prediction. (arXiv:2305.08553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08553](http://arxiv.org/abs/2305.08553)

    本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。

    

    长期轨迹预测是计算机视觉、机器学习和机器人领域中一个重要且具有挑战性的问题。其中一个基本困难在于随着时间范围的增长，轨迹的演变变得越来越不确定和不可预测，从而增加了问题的复杂性。为了克服这个问题，在本文中，我们提出了Di-Long，一种新的方法，它利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。给定一个包含学生网络允许的观测序列和补充目标序列的总序列长度，我们让学生和教师对同一个完整轨迹定义两个不同但相关的任务：学生观察一个短序列并预测一个长轨迹，而教师观察一个更长的序列并预测剩下的短目标轨迹。

    Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The
    
[^192]: 无Softmax的线性变换器

    Softmax-free Linear Transformers. (arXiv:2207.03341v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.03341](http://arxiv.org/abs/2207.03341)

    这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。

    

    视觉变换器(ViTs)在视觉感知任务的最新成果中起到了推动作用。ViTs的核心自注意机制在计算和内存使用方面具有二次复杂度。这促使我们开发出在线性复杂度下逼近自注意的方法。然而，本研究的深入分析发现，现有方法在视觉识别方面要么在理论上有缺陷，要么在实践中无效。我们发现它们的局限性来源于在逼近过程中继承了基于softmax的自注意机制，即使用softmax函数对令牌特征向量之间的缩放点积进行归一化。由于存在这个softmax操作，挑战了任何后续的线性化工作。基于这一观点，我们提出了一系列无softmax的变换器(SOFT)。具体而言，我们采用高斯核函数来替代点积相似度，从而实现全自注意矩阵的逼近。

    Vision transformers (ViTs) have pushed the state-of-the-art for visual perception tasks. The self-attention mechanism underpinning the strength of ViTs has a quadratic complexity in both computation and memory usage. This motivates the development of approximating the self-attention at linear complexity. However, an in-depth analysis in this work reveals that existing methods are either theoretically flawed or empirically ineffective for visual recognition. We identify that their limitations are rooted in the inheritance of softmax-based self-attention during approximations, that is, normalizing the scaled dot-product between token feature vectors using the softmax function. As preserving the softmax operation challenges any subsequent linearization efforts. By this insight, a family of Softmax-Free Transformers (SOFT) are proposed. Specifically, a Gaussian kernel function is adopted to replace the dot-product similarity, enabling a full self-attention matrix to be approximated under l
    
[^193]: 《流形滤波器和流形神经网络的变形稳定性》

    Stability to Deformations of Manifold Filters and Manifold Neural Networks. (arXiv:2106.03725v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.03725](http://arxiv.org/abs/2106.03725)

    本文定义了流形滤波器和流形神经网络，并通过分析它们在流形变形下的稳定性，推广了图滤波器和标准卷积滤波器的已知稳定性性质。

    

    本文定义并研究了流形（M）卷积滤波器和神经网络（NN）。流形滤波器和MNN是基于拉普拉斯-贝尔特拉米算子指数定义的，并且在流形被采样时，可以恢复为图（G）滤波器和神经网络（NN）的离散近似。这些滤波器具有谱表示，它是图滤波器的谱表示和连续时间中标准卷积滤波器的频率响应的推广。本文的主要技术贡献是分析流形滤波器和MNN在流形光滑变形下的稳定性。这种分析推广了图滤波器和GNN的已知稳定性性质，并且也是连续时间中标准卷积滤波器和神经网络已知稳定性性质的推广。从这种分析中得出的最重要的观察是，流形滤波器和图滤波器一样，同时也具有稳定性。

    The paper defines and studies manifold (M) convolutional filters and neural networks (NNs). \emph{Manifold} filters and MNNs are defined in terms of the Laplace-Beltrami operator exponential and are such that \emph{graph} (G) filters and neural networks (NNs) are recovered as discrete approximations when the manifold is sampled. These filters admit a spectral representation which is a generalization of both the spectral representation of graph filters and the frequency response of standard convolutional filters in continuous time. The main technical contribution of the paper is to analyze the stability of manifold filters and MNNs to smooth deformations of the manifold. This analysis generalizes known stability properties of graph filters and GNNs and it is also a generalization of known stability properties of standard convolutional filters and neural networks in continuous time. The most important observation that follows from this analysis is that manifold filters, same as graph fil
    

