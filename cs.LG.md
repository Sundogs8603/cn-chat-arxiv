# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generalized partitioned local depth.](http://arxiv.org/abs/2303.10167) | 本文提出了一个广义的凝聚概念，构建在分区局部深度的技术基础上，扩展了早期结果并应用于具有不确定性的数据的社区发现中。 |
| [^2] | [Visual Information Matters for ASR Error Correction.](http://arxiv.org/abs/2303.10160) | 这篇论文提出了用于改善自动语音识别（ASR）输出的ASR错误纠正（EC）技术，该技术通过融入视觉信息，使用门控融合和图像标题作为提示的方法，提高了EC的性能。同时，本文提供了一个基准数据集Visual-ASR-EC。 |
| [^3] | [Data-centric Artificial Intelligence: A Survey.](http://arxiv.org/abs/2303.10158) | 本文讨论了数据中心人工智能的必要性并从三个一般性数据中心目标和代表性方法的全面视角进行了介绍。该综述从自动化和协作的角度组织了现有文献并讨论了挑战。 |
| [^4] | [Epigenetics Algorithms: Self-Reinforcement-Attention mechanism to regulate chromosomes expression.](http://arxiv.org/abs/2303.10154) | 本文提出了一种新的表观遗传算法，利用注意机制和深度学习模拟DNA甲基化，通过增强/沉默基因的概念提高了遗传算法效果，解决了复杂的优化问题。 |
| [^5] | [Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting.](http://arxiv.org/abs/2303.10144) | 提出了一种动态调整更新到数据比率（UTD）的方法，根据小规模的未用于训练的连续收集的经验上检测欠拟合和过拟合。该方法应用于最先进的基于模型的强化学习算法DreamerV2，可以更好地平衡欠拟合和过拟合，并且与广泛的超参数搜索具有竞争力。 |
| [^6] | [Geometric Deep Learning for Molecular Crystal Structure Prediction.](http://arxiv.org/abs/2303.10140) | 本研究使用基于分子图形的几何深度学习开发出能够精确、快速评估和适用于不同分子的密度预测和稳定性排名模型，这些模型可用于分子晶体结构预测。同时，我们开发的晶体排名工具具有低成本、灵活部署等优点。 |
| [^7] | [Distill n' Explain: explaining graph neural networks using simple surrogates.](http://arxiv.org/abs/2303.10139) | 本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。 |
| [^8] | [Generate, Transform, Answer: Question Specific Tool Synthesis for Tabular Data.](http://arxiv.org/abs/2303.10138) | 本文提出了一种名为ToolWriter的工具，用于生成查询特定的程序并将其应用于转换表格，以提高表格问答（TQA）的性能。这个工具通过生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术。随着表格尺寸的增加，传统的语言模型在处理表格的过程中存在信息丢失的问题，我们通过利用程序化工具与神经组件相结合的方法来解决这个问题，并展示了这种方法的广泛潜力。 |
| [^9] | [MassNet: A Deep Learning Approach for Body Weight Extraction from A Single Pressure Image.](http://arxiv.org/abs/2303.10136) | 本文提出了一种基于压力映射床垫图像的体重提取方法，使用了深度学习和对比学习模块来提取深度特征和姿势特征以及挖掘姿势之间的相互作用因素。 |
| [^10] | [Efficient and Feasible Robotic Assembly Sequence Planning via Graph Representation Learning.](http://arxiv.org/abs/2303.10135) | 本文提出了一种基于图表示学习的装配序列规划方法，通过GRACE模型可以从装配图中提取信息并预测可行的装配序列。 |
| [^11] | [She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models.](http://arxiv.org/abs/2303.10131) | 本研究使用数据挖掘技术调查了56项与软件开发相关的任务，发现性别代词与不同任务的相关性明显不同。其中，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，帮助他人的任务有91%的相关性与“他”相关联。 |
| [^12] | [Causal Discovery from Temporal Data: An Overview and New Perspectives.](http://arxiv.org/abs/2303.10112) | 本文对于从时间数据中进行因果关系发现进行了综述，提出了两个相关的类别，即多元时间序列因果发现和事件序列因果发现，并提供了新的方法来综合考虑这两个类别。 |
| [^13] | [Data-Centric Learning from Unlabeled Graphs with Diffusion Model.](http://arxiv.org/abs/2303.10108) | 本文提出了一种从无标签图中提取知识并增强属性预测模型的数据中心方法，使用扩散模型和两个新目标进行去噪，实验证明其效果比14种现有方法更好。 |
| [^14] | [Efficient Neural Generation of 4K Masks for Homogeneous Diffusion Inpainting.](http://arxiv.org/abs/2303.10096) | 该论文提出了一种高效生成4K掩膜的神经网络方法，可以实现对高分辨率图像进行快速且高质量的修复。 |
| [^15] | [Enhancing the Role of Context in Region-Word Alignment for Object Detection.](http://arxiv.org/abs/2303.10093) | 本研究提出了一种增强上下文在目标检测区域-词对齐中作用的方法，通过特定的负采样方法提高了属性的作用，从而提高了目标检测的效果。 |
| [^16] | [Robust probabilistic inference via a constrained transport metric.](http://arxiv.org/abs/2303.10085) | 本文提出了一种新颖的鲁棒概率推断方法，基于约束传输度量，利用经验似然结合先验分布，用于鲁棒推断问题，实现对中心分布参数的推断，具有卓越的性能表现。 |
| [^17] | [Fuzziness-tuned: Improving the Transferability of Adversarial Examples.](http://arxiv.org/abs/2303.10078) | 本文提出了一种模糊度调谐方法生成对抗性样本，通过减少模糊领域有效地提高对抗样本的可迁移性，实验证明其相对于现有技术具有卓越性能。 |
| [^18] | [Deep Author Name Disambiguation using DBLP Data.](http://arxiv.org/abs/2303.10067) | 本文提出了一种利用共同作者和研究领域来消除作者名字歧义的方法，并使用DBLP仓库中的数据进行训练。 |
| [^19] | [No Fear of Classifier Biases: Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier.](http://arxiv.org/abs/2303.10058) | 本文提出一种解决合作学习中分类器偏差问题的方案，即在训练过程中使用合成的ETF分类器，使得所有客户端能够学习到统一的最优特征表示。 |
| [^20] | [Posterior Estimation Using Deep Learning: A Simulation Study of Compartmental Modeling in Dynamic PET.](http://arxiv.org/abs/2303.10057) | 本研究利用深度学习有效地估计成像参数的后验分布，提高了 PET 成像参数估计的精度和计算效率，可为诊断和治疗提供有价值的参考。 |
| [^21] | [A Policy Iteration Approach for Flock Motion Control.](http://arxiv.org/abs/2303.10035) | 本文提出了一种基于无模型策略迭代机制的群体运动控制方法，能够在时间变化的图形拓扑下引导代理人遵循命令生成器，并在线调整指导策略以适应实时动态情况。 |
| [^22] | [How robust is randomized blind deconvolution via nuclear norm minimization against adversarial noise?.](http://arxiv.org/abs/2303.10030) | 本文提出了对核范数最小化的稳健性边界进行改进的方法，以应对随机噪声，可以在维度无关的误差边界下，在随机噪声和最坏情况下的扰动下稳定地恢复两个信号。 |
| [^23] | [Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems.](http://arxiv.org/abs/2303.10022) | 本文提出了一种层次-超平面核函数族，能够在高斯过程模型积极学习中使用，以建模非平稳性和非线性特性。 |
| [^24] | [Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices.](http://arxiv.org/abs/2303.10019) | 本文提出一种新的多元概率CRPS学习方法，应用于日前电价预测中，相比于统一组合在CRPS方面取得了显著改进。 |
| [^25] | [A Data-Driven Model-Reference Adaptive Control Approach Based on Reinforcement Learning.](http://arxiv.org/abs/2303.09994) | 本文提出了一种基于强化学习的数据驱动模型参考自适应控制方法，用积分时间差分方程描述过程、采用积分强化学习机制解决问题。 |
| [^26] | [Finding Competence Regions in Domain Generalization.](http://arxiv.org/abs/2303.09989) | 该论文提出了一个“学习拒绝”框架来解决领域泛化中的默默失败问题。通过预测可信度，该方法在测试分布与训练分布不同的情况下接受超出分布的数据，以识别能力区域。研究发现，通过不同的学习表示衡量无能，增加无能得分会预示着降低准确性。 |
| [^27] | [Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning.](http://arxiv.org/abs/2303.09986) | 本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。 |
| [^28] | [Inferring Traffic Models in Terminal Airspace from Flight Tracks and Procedures.](http://arxiv.org/abs/2303.09981) | 本文提出了一种通过收集飞行轨迹和程序数据学习飞行器行为变异性的概率模型，并且可以生成涉及任意数量飞行器的交通模型。 |
| [^29] | [MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation.](http://arxiv.org/abs/2303.09975) | MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。 |
| [^30] | [Neighborhood Averaging for Improving Outlier Detectors.](http://arxiv.org/abs/2303.09972) | 提出了一种名为邻域平均（NA）的异常分数后处理技术，通过将对象及其k个最近邻居的分数相结合来修改其异常分数，使得相似的对象具有比原始分数更相似的异常分数，实验证明在九个真实世界数据集上评估，NA将所有测试的10个基线检测器平均改进了13％。 |
| [^31] | [Stochastic Submodular Maximization via Polynomial Estimators.](http://arxiv.org/abs/2303.09960) | 本文研究了随机子模最大化问题，特别是通过使用多项式估算器实现了随机连续贪心算法的 $(1-1/e) \approx 63\%$ 的近似比效果，同时显著降低了执行时间。 |
| [^32] | [Towards a Foundation Model for Neural Network Wavefunctions.](http://arxiv.org/abs/2303.09949) | 本文提出了一个新的神经网络ansatz，将计算廉价的哈特里-福克轨道映射到高精度神经网络轨道。它能够学习跨化合物和几何结构的单个波函数，并进行广泛的预训练。 |
| [^33] | [An Adaptive Fuzzy Reinforcement Learning Cooperative Approach for the Autonomous Control of Flock Systems.](http://arxiv.org/abs/2303.09946) | 本文提出了一个自适应模糊强化学习协作方法用于群集系统的自主控制。该方法针对跟随领袖、避免碰撞和达到群体速度共识三个目标，具有弹性和鲁棒性，且在实验中性能优于现有方案。 |
| [^34] | [DSDP: A Blind Docking Strategy Accelerated by GPUs.](http://arxiv.org/abs/2303.09916) | 本研究提出了一种由GPU加速的盲对接策略DSDP，其通过利用传统和基于机器学习的方法的优点改进了盲对接的性能。DSDP可以预测蛋白质的结合位点，并提供准确的搜索空间和初始位置，以进行进一步的构象采样。 |
| [^35] | [Short: Basal-Adjust: Trend Prediction Alerts and Adjusted Basal Rates for Hyperglycemia Prevention.](http://arxiv.org/abs/2303.09913) | 该论文提出了一种机器学习方法，能够预测血糖情况及其分类，输出预警消息以让病人更早进行治疗。在预测反弹性高血糖方面表现出较高的预测精准度和准确度，为预防高血糖提供了初步建议。 |
| [^36] | [An evaluation framework for dimensionality reduction through sectional curvature.](http://arxiv.org/abs/2303.09909) | 本文提出了基于分段曲率的高度非平凡维度规约性能评估指标，并利用此指标来评估最先进的维度规约算法的性能 |
| [^37] | [Discovering mesoscopic descriptions of collective movement with neural stochastic modelling.](http://arxiv.org/abs/2303.09906) | 介观集体运动的随机特征对确定性和随机性动力学建模至关重要。作者利用物理启发、神经网络和随机微分方程来研究相互作用个体的群体动力学，并对其进行了鉴定和分析，为这些系统的秩序性质提供了新颖的见解。 |
| [^38] | [mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection.](http://arxiv.org/abs/2303.09901) | 本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。 |
| [^39] | [On the Effects of Self-supervision and Contrastive Alignment in Deep Multi-view Clustering.](http://arxiv.org/abs/2303.09877) | 本论文提出了统一的框架DeepMVC，用于深度多视角聚类，并对其进行了关键观察，发现使用对比学习来对齐表示会对聚类可分性产生负面影响，特别是在视角数量较多时。同时，为了克服这种缺陷，我们开发了一些新的基于自监督方法的DeepMVC实例。 |
| [^40] | [Disentangling the Link Between Image Statistics and Human Perception.](http://arxiv.org/abs/2303.09874) | 本研究直接评估自然图像的概率，并分析它如何影响人类感知。通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性，论文提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。 |
| [^41] | [Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness.](http://arxiv.org/abs/2303.09863) | 本文介绍了一种图表自编码器用于深度非参数估计内部数据结构，并证明了其广义误差保证和去噪能力。 |
| [^42] | [Dual-path Adaptation from Image to Video Transformers.](http://arxiv.org/abs/2303.09857) | 本文提出了一种新的双路径自适应方法，在视频理解中充分利用图像变形器的能力，特别是对于时间动态建模，提出了一个精确模仿视觉变换器的能力的方法。 |
| [^43] | [GADFormer: An Attention-based Model for Group Anomaly Detection on Trajectories.](http://arxiv.org/abs/2303.09841) | 本文提出了一种基于BERT模型的GADFormer模型，能够在轨迹上执行基于注意力的群体异常检测，相比其他深度序列模型，GADFormer表现更优，在多个公开数据集上实验表明GADFormer在检测异常群体方面取得了显著的提高。 |
| [^44] | [Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages.](http://arxiv.org/abs/2303.09823) | 本文提出了一种使用Transformer和Ensemble方法的解决方案，用于阿语恶意言论的检测。实验结果表明，基于多数表决的集成方法具有最佳效果，其在测试集上的准确率为0.86，F1分数为0.60。 |
| [^45] | [Mpox-AISM: AI-Mediated Super Monitoring for Forestalling Monkeypox Spread.](http://arxiv.org/abs/2303.09780) | 本文介绍了一种名为超级监测的远程实现猴痘早期诊断的策略。该策略以人工智能技术为基础，可实现高灵敏度和准确性的病症分类，同时成本低、易用性高，具有广泛的应用前景。 |
| [^46] | [SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization.](http://arxiv.org/abs/2303.09778) | 本论文提出了一个通用且有效的图结构学习框架SE-GSL，通过利用结构熵和编码树中的层次结构来最大化嵌入信息内容，同时提出了一个声慢构建最优编码树的方案。该框架还提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。 |
| [^47] | [QUBO Decision Tree: Annealing Machine Extends Decision Tree Splitting.](http://arxiv.org/abs/2303.09772) | 本论文提出了一种扩展回归树的方法，通过将训练过程转化为QUBO，将决策树的决策规则扩展到多维边界，进而提高了决策树的准确度。使用退火机器解决这一扩展通常的计算限制。 |
| [^48] | [Denoising Diffusion Autoencoders are Unified Self-supervised Learners.](http://arxiv.org/abs/2303.09769) | 本文研究了去噪扩散自编码器 (DDAE) 是否能通过无条件图像生成训练获取强有力的线性可分表示，结果表明DDAE是一个统一的自监督学习器，对于自监督生成和辨别性学习是通用的方法。在多类数据集上实现了95.9％和50.0％的线性探测精度，与掩码自编码器和对比学习相当。 |
| [^49] | [It Is All About Data: A Survey on the Effects of Data on Adversarial Robustness.](http://arxiv.org/abs/2303.09767) | 本文综述了有关数据对抗鲁棒性的研究，系统地总结了最新研究成果，并进一步讨论了未来研究方向和知识差距。 |
| [^50] | [Diffusing the Optimal Topology: A Generative Optimization Approach.](http://arxiv.org/abs/2303.09760) | 该论文提出了一种新的生成式优化方法，将SIMP等经典优化算法作为精制机制整合到深度生成模型生成的拓扑结构中。该方法在基准问题上展现出较传统拓扑优化和其他学习模型更优的性能。 |
| [^51] | [CoLT5: Faster Long-Range Transformers with Conditional Computation.](http://arxiv.org/abs/2303.09752) | CoLT5是一种基于条件计算的Transformer模型，通过优先处理重要标记来加速长距离输入的处理。CoLT5在SCROLLS基准测试上表现最好，并能够有效地处理长达64k输入长度。 |
| [^52] | [Detecting Out-of-distribution Examples via Class-conditional Impressions Reappearing.](http://arxiv.org/abs/2303.09746) | 本文提出了一种数据无关的异常检测方法，称为C2IR，它利用来自固定模型的图像印象来恢复类条件的特征统计信息。实验证明了该方法的有效性并达到了与全数据访问的检测方法相当的性能。 |
| [^53] | [A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games.](http://arxiv.org/abs/2303.09716) | 本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。 |
| [^54] | [Batch Updating of a Posterior Tree Distribution over a Meta-Tree.](http://arxiv.org/abs/2303.09705) | 本文提出了一个更高效的批量更新方法，用于在元树上计算后验分布。 |
| [^55] | [A Bi-LSTM Autoencoder Framework for Anomaly Detection -- A Case Study of a Wind Power Dataset.](http://arxiv.org/abs/2303.09703) | 本文提出了一种双向LSTM自编码器框架用于发现时间序列数据中的异常，可以从两个方向发现隐藏的长期依赖关系。 |
| [^56] | [Delayed and Indirect Impacts of Link Recommendations.](http://arxiv.org/abs/2303.09700) | 本研究研究了链接推荐在动态环境中对社交网络演化的影响，并发现推荐链接有令人惊讶的延迟和间接影响。 |
| [^57] | [Predicting discrete-time bifurcations with deep learning.](http://arxiv.org/abs/2303.09669) | 本研究利用深度学习训练分类器预测离散时间五种本地分岔，在经济、生态、生理学等方面的试验数据中都具有优秀表现，是提前警告关键转变的重要方法。 |
| [^58] | [Tribe or Not? Critical Inspection of Group Differences Using TribalGram.](http://arxiv.org/abs/2303.09664) | 本文提出了一组负责任的群体分析设计指南，并通过开发TribalGram工具使用可解释的机器学习算法和可视化来对群体分析进行推断评估、模型解释、数据协作和理解，以增强对分析群体的深刻理解，并防止因刻板印象和过度概括导致的潜在危害。 |
| [^59] | [Energy Management of Multi-mode Plug-in Hybrid Electric Vehicle using Multi-agent Deep Reinforcement Learning.](http://arxiv.org/abs/2303.09658) | 本论文提出了一种基于多智能体深度强化学习的多模式插电混合动力汽车能量管理的MIMO控制方法，通过握手策略和多目标函数优化全局控制，实验结果表明其在燃料消耗、SOC变化和功率限制方面优于传统方法。 |
| [^60] | [ESCAPE: Countering Systematic Errors from Machine's Blind Spots via Interactive Visual Analysis.](http://arxiv.org/abs/2303.09657) | 本论文提出了ESCAPE，一个交互式视觉分析系统，利用人机交互帮助用户发现并修正机器学习中的系统误差。 |
| [^61] | [SUD$^2$: Supervision by Denoising Diffusion Models for Image Reconstruction.](http://arxiv.org/abs/2303.09642) | 本文提出了一种适用于成对训练数据不足的图像重建网络训练的广义框架，并且在缺少成对训练数据的情况下，使用去噪扩散模型进行网络训练的监督。 |
| [^62] | [Causal Temporal Graph Convolutional Neural Networks (CTGCN).](http://arxiv.org/abs/2303.09634) | CTGCN基于因果关系发现机制，利用分而治之的技术克服计算可伸缩性问题，并通过集成因果性提高了对大规模问题的预测能力。 |
| [^63] | [Hyper-Reduced Autoencoders for Efficient and Accurate Nonlinear Model Reductions.](http://arxiv.org/abs/2303.09630) | 提出一种新的方法使用超降维自编码器来实现高效准确的非线性模型降维，在高保真度的解快照的子采样版本上训练神经网络以克服高计算成本。在2D Burgers问题上演示了方法的有效性。 |
| [^64] | [Online Reinforcement Learning in Periodic MDP.](http://arxiv.org/abs/2303.09629) | 本文提出了用于解决周期性MDP中强化学习问题的四种算法，其中包括PUCRL2，PUCRLB，U-PUCRL2和U-PUCRLB。PUCRLB表现更好，且其遗憾随周期$N$的变化为$O(\sqrt{N})$。 |
| [^65] | [Efficient Learning of High Level Plans from Play.](http://arxiv.org/abs/2303.09628) | 本论文介绍了从游戏中高效学习高层次计划的机器人学习框架，可以实现长期复杂的操作任务。他们利用任务不可知的游戏数据学习基于物体的离散行为先验，然后设计一个高层次的目标条件策略，它使用先验来指导规划和构建复杂长期任务。 |
| [^66] | [HIVE: Harnessing Human Feedback for Instructional Visual Editing.](http://arxiv.org/abs/2303.09618) | 本文提出了一种新的框架，利用人类反馈进行指导性视觉编辑。通过收集被编辑图像的人类反馈，并学习奖励函数捕捉用户的偏好，可以缓解数据限制所带来的偏差，并提高模型性能。 |
| [^67] | [Decentralized Riemannian natural gradient methods with Kronecker-product approximations.](http://arxiv.org/abs/2303.09611) | 本文提出了一种结构化问题类的分散式黎曼自然梯度下降方法，通过Kronecker乘积逼近RFIM，以较低的成本获得高质量的逼近。该方法收敛速度达到$\mathcal{O}(1/K)$的最佳已知水平。 |
| [^68] | [Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics.](http://arxiv.org/abs/2303.09601) | 本文介绍了一种使用强化学习生成心理治疗主题推荐的AI伴侣，能够很好地捕获真实数据，并通过可解释的策略轨迹可视化提供对不同奖励信号和不同临床诊断下训练的策略的独特模式。 |
| [^69] | [cito: An R package for training neural networks using torch.](http://arxiv.org/abs/2303.09599) | cito是一个用户友好的R包，使用torch进行深度神经网络的训练，包括许多对预测和评估模型有用的用户友好功能。 |
| [^70] | [Visual Analytics of Multivariate Networks with Representation Learning and Composite Variable Construction.](http://arxiv.org/abs/2303.09590) | 本文提出了一种用于研究多变量网络的视觉分析工作流程，其中包括神经网络学习阶段、降维和优化阶段以及用户交互式可视化接口进行解释。关键的组合变量构建步骤将非线性特征重塑为线性特征，以方便检查和理解。案例研究表明该工作流程具有有效性和可理解性。 |
| [^71] | [TypeT5: Seq2seq Type Inference using Static Analysis.](http://arxiv.org/abs/2303.09564) | TypeT5是一种利用CodeT5进行静态分析的新型类型推断方法，能够在预测罕见和复杂类型时显著提高准确性，并减少类型错误。 |
| [^72] | [Unsupervised domain adaptation by learning using privileged information.](http://arxiv.org/abs/2303.09350) | 本文提出利用特权信息进行领域适应（DALUPI）算法，以在学习中放宽假设条件并提高样本效率，通过减少错误来促进医学图像分析等应用的发展。 |
| [^73] | [Maximum Margin Learning of t-SPNs for Cell Classification with Filtering.](http://arxiv.org/abs/2303.09065) | 本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。 |
| [^74] | [Bayesian Quadrature for Neural Ensemble Search.](http://arxiv.org/abs/2303.08874) | 本论文介绍了一种使用贝叶斯积分的新方法，可以在架构似然表面有分散、狭窄峰时构建加权集成神经网络，相比当前同类方法，在测试似然性、准确性和期望校准误差方面更为优秀。 |
| [^75] | [On the uncertainty analysis of the data-enabled physics-informed neural network for solving neutron diffusion eigenvalue problem.](http://arxiv.org/abs/2303.08455) | 本文针对数据不可避免带有噪声的情况，研究了DEPINN在求解中子扩散本征值问题方面的可行性，并提出了创新的区间损失函数用于减少噪声影响和提高先验数据利用率，此方法在两个基准问题上得到了验证。 |
| [^76] | [Style Feature Extraction Using Contrastive Conditioned Variational Autoencoders with Mutual Information Constraints.](http://arxiv.org/abs/2303.08068) | 本文提出了一种使用互信息约束下的对比条件变分自编码器进行从未标记数据中提取风格特征的方法，该方法由一个提取风格无关特征的对比学习部分和一个提取风格特征的CVAE部分组成。 |
| [^77] | [Collision Cross-entropy and EM Algorithm for Self-labeled Classification.](http://arxiv.org/abs/2303.07321) | 本论文提出了一种称为碰撞交叉熵的自标注分类损失替代方法，同时提出了一种优化该损失方法的EM-like算法。实验结果表明，该方法在各种自标注分类任务中表现出更好的性能。 |
| [^78] | [InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning.](http://arxiv.org/abs/2303.07269) | 该论文提出了一种不依赖于模型置信度的伪标签方法，用于不平衡的半监督学习，该方法用能量分数判断未标记样本是“内分布”还是“外分布”，随着训练的进行，越来越多的未标记样本成为内部分布并对训练产生贡献，结合伪标签的方法表现出色。 |
| [^79] | [Enhancing COVID-19 Severity Analysis through Ensemble Methods.](http://arxiv.org/abs/2303.07130) | 本文提出了一种基于领域知识的流程，使用图像处理算法和预训练的UNET模型结合从COVID-19患者中提取感染区域，并使用三种机器学习模型的集成将感染的严重程度分类为不同的类别，从而提高COVID-19重症分析。 |
| [^80] | [Transformer Encoder with Multiscale Deep Learning for Pain Classification Using Physiological Signals.](http://arxiv.org/abs/2303.06845) | 本论文提出了一种新的基于生理信号输入的Transformer编码器深度学习框架（PAN）用于疼痛分类，并成功实现了自动疼痛强度分级。研究中使用了多尺度卷积网络 (MSCN)、压缩与激发残余网络(SEResNet)和Transformer编码器等特征提取架构，为客观且自动的疼痛强度评估提供了一种有效途径。 |
| [^81] | [Investigating Stateful Defenses Against Black-Box Adversarial Examples.](http://arxiv.org/abs/2303.06280) | 本文探究了有状态防御黑盒对抗样本的方法，提出了一种新的有状态防御模型，可以在CIFAR10数据集上达到82.2％的准确性，在ImageNet数据集上达到76.5％的准确性。 |
| [^82] | [KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input.](http://arxiv.org/abs/2303.05617) | 本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。 |
| [^83] | [Learning Stationary Markov Processes with Contrastive Adjustment.](http://arxiv.org/abs/2303.05497) | 该论文提出了一种新的优化算法对比调整，用于学习 Markov 转移核，并在噪声核的帮助下进行数据建模，进一步推广了对抗生成网络的应用。使用该算法可以对数据流形进行局部探索并通过人类反馈不断改进输出。 |
| [^84] | [Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation.](http://arxiv.org/abs/2303.03770) | 本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。 |
| [^85] | [Need for Objective Task-based Evaluation of Deep Learning-Based Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT.](http://arxiv.org/abs/2303.02110) | 本研究旨在探讨基于深度学习的图像去噪方法在临床任务中的表现评估，发现使用保真度(FoMs)的评估不一定与任务为基础的评估一致，而基于信号检测理论(SDT)的评估方法提供了更客观、有意义的去噪效果评估方式，并证明虚拟临床试验（VCTs）是评估DL方法的实用工具。 |
| [^86] | [Adaptive Interventions for Global Health: A Case Study of Malaria.](http://arxiv.org/abs/2303.02075) | 介绍了如何通过移动健康应用和机器学习自适应干预来加强疟疾监测和治疗依从性，改善医护质量，提高检测率和公共卫生，减少药品短缺和为政策干预提供信息。 |
| [^87] | [Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision.](http://arxiv.org/abs/2303.00462) | 本研究提出了一种使用跨模态监督学习的新方法，用于精确地估计4D雷达场景流，并在运动分割和自我运动估计等子任务中显示了其实用性。 |
| [^88] | [Learning time-scales in two-layers neural networks.](http://arxiv.org/abs/2303.00055) | 本文研究了两层神经网络的学习动态，发现经验风险的下降速率是非单调的。在分布符合单指数模型的高维宽两层神经网络中，我们通过学习率参数化清晰的阶段转换，并提供了对网络学习动态的全面分析。我们还为早期学习时所学模型的简单性提供了理论解释。 |
| [^89] | [Reproducing kernel Hilbert spaces in the mean field limit.](http://arxiv.org/abs/2302.14446) | 本文研究了作用于具有许多测量变量的数据的内核方法在均场极限下的行为，并给出了极限再生核希尔伯特空间的详细分析。 |
| [^90] | [Performance is not enough: a story of the Rashomon's quartet.](http://arxiv.org/abs/2302.13356) | 本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能，同时其可视化揭示了极其不同的方法来理解数据中的相关性结构。 |
| [^91] | [Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers.](http://arxiv.org/abs/2302.10803) | EAGLE引入了大规模数据集和新模型，其中包括一种新的网格变换器，能够预测具有挑战性的流体动力学数据集中的压力和速度变化。 |
| [^92] | [CADIS: Handling Cluster-skewed Non-IID Data in Federated Learning with Clustered Aggregation and Knowledge DIStilled Regularization.](http://arxiv.org/abs/2302.10413) | 本文提出了一种针对聚类偏斜非独立同分布数据的联邦学习聚合方案和基于知识蒸馏的局部训练正则化方法 |
| [^93] | [LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images.](http://arxiv.org/abs/2302.03008) | LAVA是一个基于颗粒化神经元级别可解释性的 AI 框架，可以直接从静脉荧光成像中评估阿尔茨海默病的进程，验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。 |
| [^94] | [Towards AI-controlled FES-restoration of arm movements: Controlling for progressive muscular fatigue with Gaussian state-space models.](http://arxiv.org/abs/2301.04005) | 本研究利用高斯状态空间模型与循环神经网络处理FES控制中无法观测到的肌肉疲劳问题，提高了强化学习控制器的控制性能。 |
| [^95] | [Towards AI-controlled FES-restoration of arm movements: neuromechanics-based reinforcement learning for 3-D reaching.](http://arxiv.org/abs/2301.04004) | 该论文致力于解决控制FES实现所需运动方向方面的挑战，提出一种基于神经机械学的强化学习方法来进行FES控制，以恢复上肢运动功能。 |
| [^96] | [Invalidator: Automated Patch Correctness Assessment via Semantic and Syntactic Reasoning.](http://arxiv.org/abs/2301.01113) | 本文提出了INVALIDATOR，一种使用语义和语法推理自动评估由APR生成的补丁的正确性的技术。INVALIDATOR利用程序不变量来推理程序的语义并捕获程序的语法，然后判断APR生成的补丁是否过度拟合。我们的实验结果表明INVALIDATOR在检测过度拟合补丁方面优于现有方法。 |
| [^97] | [SIRL: Similarity-based Implicit Representation Learning.](http://arxiv.org/abs/2301.00810) | SIRL是基于人提供相似度判断的任务表示学习方法，能够帮助机器人识别和隔离因果特征并生成适当行为，在各种机器人任务上表现优秀。 |
| [^98] | [Semi-supervised Bladder Tissue Classification in Multi-Domain Endoscopic Images.](http://arxiv.org/abs/2212.11375) | 该论文提出了一种面向多领域的半监督生成对抗网络方法，可以不需要配对注释，同时使用WLI和NBI两个领域来实现膀胱组织分类，取得了竞争性的结果。 |
| [^99] | [CausalEGM: a general causal inference framework by encoding generative modeling.](http://arxiv.org/abs/2212.05925) | 论文提出了基于生成模型的CausalEGM框架，能够同时进行因果效应的解耦以及将混淆变量映射到低维潜变量空间。 |
| [^100] | [Is Bio-Inspired Learning Better than Backprop? Benchmarking Bio Learning vs. Backprop.](http://arxiv.org/abs/2212.04614) | 本研究对比了反向传播和多个生物启发式算法，发现当未提供整个训练数据集时，生物算法比反向传播表现要好得多。 |
| [^101] | [Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling.](http://arxiv.org/abs/2212.03396) | 提出了一种自解释选择模型，使用典型的概念的线性组合来解释其自身的预测，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，为了更好的解释性，还设计了多个约束条件。 |
| [^102] | [Pattern Attention Transformer with Doughnut Kernel.](http://arxiv.org/abs/2211.16961) | 本论文提出了一种新的模式注意力变换器(PAT)，它采用了新的圆环核设计，以解决图像分类中像素高分辨率的问题。 |
| [^103] | [An Isolation-Aware Online Virtual Network Embedding via Deep Reinforcement Learning.](http://arxiv.org/abs/2211.14158) | 本文提出了一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法，以解决虚拟网络环境中多个VN共存可能导致隔离问题的挑战。 |
| [^104] | [An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum.](http://arxiv.org/abs/2211.05207) | 该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。 |
| [^105] | [Comparative layer-wise analysis of self-supervised speech models.](http://arxiv.org/abs/2211.03929) | 本论文通过比较不同自监督语音模型的逐层中间表示，发现了不同模型在编码声学、语音和单词级属性上的差异，并发现这些差异与预训练目标的选择相关。通过比较属性趋势和语音识别和口语理解任务的性能，我们发现CCA趋势为选择层次提供了可靠的指导。 |
| [^106] | [Liability regimes in the age of AI: a use-case driven analysis of the burden of proof.](http://arxiv.org/abs/2211.01817) | 本文通过用例分析探讨了基于AI技术的责任制度下证明负担的挑战和规则改革的建议。 |
| [^107] | [RGMIM: Region-Guided Masked Image Modeling for COVID-19 Detection.](http://arxiv.org/abs/2211.00313) | 本论文提出了一种针对COVID-19检测的新颖区域引导的掩膜图像建模方法，该方法通过利用肺掩模信息来识别有效区域，以学习更有用的COVID-19检测信息。 |
| [^108] | [An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty.](http://arxiv.org/abs/2210.16380) | 在众包图像数据集上的分类是具有挑战性的。本文提出了一种利用集合建模、注释的归一化分布和熵测量的方法，以帮助识别标签不确定的图像，并量化这些样本的可信度。 |
| [^109] | [Leveraging Large Language Models for Multiple Choice Question Answering.](http://arxiv.org/abs/2210.12353) | 本文研究了利用大型语言模型进行多项选择题的答案推断，并探讨了一种更自然的问题提示方式，以提高准确性。 |
| [^110] | [Actor-Critic or Critic-Actor? A Tale of Two Time Scales.](http://arxiv.org/abs/2210.04470) | 这篇论文提出了一种评论演员算法，它在快速和慢速时间尺度上计算价值函数和策略，该算法与演员评论算法在准确性和计算成本方面表现相当。 |
| [^111] | [Self-Distillation for Further Pre-training of Transformers.](http://arxiv.org/abs/2210.02871) | 本文提出了自蒸馏作为进一步预训练阶段的正则化方法，用于解决Vision Transformer在目标未标注数据集上过拟合问题，实现了在多项基准数据集上的最先进结果。 |
| [^112] | [Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels.](http://arxiv.org/abs/2209.13476) | 提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。 |
| [^113] | [AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft Detection and Tracking.](http://arxiv.org/abs/2209.12849) | AirTrack是一个用于小型无人机系统的实时视觉检测和跟踪框架，使用全分辨率图像和深度学习框架以提高检测和跟踪性能。实验结果显示，在Amazon AOT数据集上表现出优越性。同时，多次真实世界中进行的飞行测试均显示该方法的有效性。 |
| [^114] | [Keypoint-GraspNet: Keypoint-based 6-DoF Grasp Generation from the Monocular RGB-D input.](http://arxiv.org/abs/2209.08752) | 本文提出了一种基于关键点的单目RGB-D输入下的六自由度抓取点生成方法，该方法可以通过PnP算法恢复SE(3)姿态。机器人实验表明，我们的方法在抓取点提案的精度、多样性和时间成本方面优于其他方法并具有很强的应用潜力。 |
| [^115] | [Detecting Political Biases of Named Entities and Hashtags on Twitter.](http://arxiv.org/abs/2209.08110) | 本篇论文旨在通过分析Twitter上的命名实体和标签的使用来检测文本中的政治偏见，并分配极性分数进行量化。 |
| [^116] | [Learning-Based Adaptive Control for Stochastic Linear Systems with Input Constraints.](http://arxiv.org/abs/2209.07040) | 本文提出了一种新的自适应控制方案，用于具有输入限制的随机线性系统，无需先验参数信息。 |
| [^117] | [Treeformer: Dense Gradient Trees for Efficient Attention Computation.](http://arxiv.org/abs/2208.09015) | 本文提出了Treeformer，一种基于决策树的分层导航方法，用于高效地计算注意力。与传统的注意力计算方法相比，Treeformer 可以将检索成本从线性降为近似对数级别，并提供两种有效的关注层。算法的目标是处理输入序列长度过长的应用，提高计算效率。 |
| [^118] | [Easy Differentially Private Linear Regression.](http://arxiv.org/abs/2208.07353) | 本文研究了一种简单的差分隐私线性回归算法，它使用指数机制从一组非私有回归模型中选择具有高Tukey深度的模型，并在无需数据边界和超参数选择的数据丰富环境中获得了强大的实证表现。 |
| [^119] | [A Non-Asymptotic Framework for Approximate Message Passing in Spiked Models.](http://arxiv.org/abs/2208.03313) | 本文提出了一个非渐进的AMP理论框架，用于理解高维统计问题，解决了以往AMP理论的不足。我们的方法可以有效地预测AMP在独立初始化和谱初始化情况下的有限样本行为。 |
| [^120] | [Scaling Novel Object Detection with Weakly Supervised Detection Transformers.](http://arxiv.org/abs/2207.05205) | 本篇文章提出了一个新方法：弱监督检测变形器（Weakly Supervised Detection Transformer），可以有效地将大规模预训练数据集的知识转移至数百种新型物品的WSOD微调中，同时提高了多实例学习的准确性。实验结果表明，该方法优于现有的先进模型，在大规模新型物品检测数据集上达到了更好的性能。 |
| [^121] | [Towards More Objective Evaluation of Class Incremental Learning: Representation Learning Perspective.](http://arxiv.org/abs/2206.08101) | 本文提出了利用表示学习对类增量学习进行客观评估的方法，并实验分析了CIL算法训练的神经网络模型，发现大多数最新算法优先考虑高稳定性，但仍然能够实现高测试准确率。 |
| [^122] | [Push--Pull with Device Sampling.](http://arxiv.org/abs/2206.04113) | 我们提出了一种算法，采用梯度跟踪和网络级方差减少相结合的方法来解决异步分布式优化问题。该算法能够实现每个节点跟踪目标函数梯度的平均值，并在局部目标函数强凸的情况下，通过减少预期混合矩阵的温和连接条件实现线性收敛。 |
| [^123] | [Backpropagation through Combinatorial Algorithms: Identity with Projection Works.](http://arxiv.org/abs/2205.15213) | 本文提出了一种基于离散解空间几何的原则方法，将求解器视为负恒等变换，以在反向传播时寻找有意义的替代方案，避免使用通过投影平滑求解器、将求解器松弛为连续问题或者通过技术对损失面貌进行插值等更复杂的方法，从而在离散求解器和深度图等情景中发挥作用。 |
| [^124] | [HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction.](http://arxiv.org/abs/2203.08213) | 本文提出了一种混合展开多尺度网络结构用于加速MRI重建，该结构将变压器和卷积技术相结合，有效地解决了处理高分辨率图像和大块图像时计算和内存成本过高的问题。 |
| [^125] | [Deep learning-based conditional inpainting for restoration of artifact-affected 4D CT images.](http://arxiv.org/abs/2203.06431) | 该研究提出了基于深度学习的条件修复技术，可恢复受损部位的解剖正确的图像信息。研究依据实验结果表明该方法在修复追踪伪影上有效，具备广阔的应用前景。 |
| [^126] | [Transformer Module Networks for Systematic Generalization in Visual Question Answering.](http://arxiv.org/abs/2201.11316) | 本文引入了Transformer模块网络（TMN），它是由Transformer模块组成的新型NMN，能够取得在VQA任务中最先进的系统性能，针对子任务的新组合比标准Transformer提高了30%以上。 |
| [^127] | [Partition-Based Active Learning for Graph Neural Networks.](http://arxiv.org/abs/2201.09391) | 本文提出了一种基于分区的图神经网络主动学习方法GraphPart，该方法在不引入额外超参数的情况下，在多个基准数据集上显著优于现有主动学习方法，并且在不同的注释预算约束下性能稳定。 |
| [^128] | [Tiny, always-on and fragile: Bias propagation through design choices in on-device machine learning workflows.](http://arxiv.org/abs/2201.07677) | 本研究调查了边缘端机器学习工作流程中偏见传递的设计选择。结果表明，在模型训练过程中的技术设计选择，如模型架构和优化算法，会放大和传播可靠性偏见。 |
| [^129] | [Observations on K-image Expansion of Image-Mixing Augmentation for Classification.](http://arxiv.org/abs/2110.04248) | 本文提出一种新的 K-image 混合增强方法，通过基于狄利克雷先验分布的棍子分拆，可以得到更健壮、广义的分类器，并具有更好的对抗鲁棒性。 |
| [^130] | [Combining Physics and Deep Learning to learn Continuous-Time Dynamics Models.](http://arxiv.org/abs/2110.01894) | 本文提出了受物理启发的深度网络DeLaN，结合物理学原理和深度学习来学习具有物理合理性动力学的模型。 |
| [^131] | [Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding.](http://arxiv.org/abs/2109.01636) | 研究开发了一种分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息，实验表明将词的特异性融入NER方法可提高NER的性能。 |
| [^132] | [A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge Domain Adaptation on FPGAs.](http://arxiv.org/abs/2107.12824) | 本文提出了一种低成本的神经ODE和深度可分卷积相结合的DNN模型dsODENet，并将其应用于边缘领域适应。此外，还提出了一种资源高效的FPGA设计，可部署dsODENet。 |
| [^133] | [Learning Augmented Online Facility Location.](http://arxiv.org/abs/2107.08277) | 本文提出了一种用于在线设施选址问题的在线算法，竞争比率能够光滑地随误差减小而从对数级别降低到常数级别。 |
| [^134] | [Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model.](http://arxiv.org/abs/2005.12900) | 本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。 |
| [^135] | [Deep Image Feature Learning with Fuzzy Rules.](http://arxiv.org/abs/1905.10575) | 本论文提出了一种基于模糊规则的深度图像特征学习方法，能够生成更好的解释和可伸缩的特征模型，并且与数据集大小无关。 |

# 详细

[^1]: 广义划分局部深度

    Generalized partitioned local depth. (arXiv:2303.10167v1 [stat.ML])

    [http://arxiv.org/abs/2303.10167](http://arxiv.org/abs/2303.10167)

    本文提出了一个广义的凝聚概念，构建在分区局部深度的技术基础上，扩展了早期结果并应用于具有不确定性的数据的社区发现中。

    

    本文提供了一个最近由Berenhaut、Moore和Melvin [Proccedings of the National Academy of Sciences, 119 (4) (2022)]提出的凝聚概念的概括。所提出的表述基于分区局部深度的技术并提炼了两个关键概率概念：局部相关性和支持分割。早期结果在新的背景下得到扩展，并包括在具有不确定性的数据中揭示社区的应用示例。

    In this paper we provide a generalization of the concept of cohesion as introduced recently by Berenhaut, Moore and Melvin [Proceedings of the National Academy of Sciences, 119 (4) (2022)]. The formulation presented builds on the technique of partitioned local depth by distilling two key probabilistic concepts: local relevance and support division. Earlier results are extended within the new context, and examples of applications to revealing communities in data with uncertainty are included.
    
[^2]: 视觉信息对ASR错误纠正非常重要

    Visual Information Matters for ASR Error Correction. (arXiv:2303.10160v1 [eess.AS])

    [http://arxiv.org/abs/2303.10160](http://arxiv.org/abs/2303.10160)

    这篇论文提出了用于改善自动语音识别（ASR）输出的ASR错误纠正（EC）技术，该技术通过融入视觉信息，使用门控融合和图像标题作为提示的方法，提高了EC的性能。同时，本文提供了一个基准数据集Visual-ASR-EC。

    

    为了提高自动语音识别（ASR）的输出，ASR错误纠正（EC）技术已经得到广泛开发，因其使用并行文本数据的效率高。以往的研究主要集中在使用文本或/和语音数据上，这在没有仅有文本和语音信息的情况下限制了性能提升；而视觉信息等其他形式的数据很少被研究。本文提供了一些简单但有效的方法，即门控融合和图像标题作为提示，用于将视觉信息融入EC中，并且提供了大规模的基准数据集Visual-ASR-EC，其中每个项目的训练数据包括视觉、语音和文本信息，测试数据是...

    Aiming to improve the Automatic Speech Recognition (ASR) outputs with a post-processing step, ASR error correction (EC) techniques have been widely developed due to their efficiency in using parallel text data. Previous works mainly focus on using text or/ and speech data, which hinders the performance gain when not only text and speech information, but other modalities, such as visual information are critical for EC. The challenges are mainly two folds: one is that previous work fails to emphasize visual information, thus rare exploration has been studied. The other is that the community lacks a high-quality benchmark where visual information matters for the EC models. Therefore, this paper provides 1) simple yet effective methods, namely gated fusion and image captions as prompts to incorporate visual information to help EC; 2) large-scale benchmark datasets, namely Visual-ASR-EC, where each item in the training data consists of visual, speech, and text information, and the test data
    
[^3]: 数据中心人工智能综述：一份调查报告。

    Data-centric Artificial Intelligence: A Survey. (arXiv:2303.10158v1 [cs.LG])

    [http://arxiv.org/abs/2303.10158](http://arxiv.org/abs/2303.10158)

    本文讨论了数据中心人工智能的必要性并从三个一般性数据中心目标和代表性方法的全面视角进行了介绍。该综述从自动化和协作的角度组织了现有文献并讨论了挑战。

    

    人工智能（AI）正在几乎所有领域产生深远的影响，其成功的关键之一是可用于构建机器学习模型的丰富高质量数据。最近，数据在AI中的作用得到了显著放大，引发了数据中心AI这一新兴概念的出现。研究人员和从业者的注意力逐渐从推进模型设计转向提高数据质量和数量。在本调查中，我们讨论了数据中心AI的必要性，随后从训练数据开发、推理数据开发和数据维护三个一般性数据中心目标以及代表性方法的全面视角进行了介绍。我们还从自动化和协作的角度组织了现有文献，讨论了挑战，并列出了各种任务的测试基准。我们认为，这是第一份提供跨越各个阶段一系列任务的全球视角的综合性调查。

    Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages o
    
[^4]: 表观遗传算法：自我强化注意机制调节染色体表达

    Epigenetics Algorithms: Self-Reinforcement-Attention mechanism to regulate chromosomes expression. (arXiv:2303.10154v1 [cs.NE])

    [http://arxiv.org/abs/2303.10154](http://arxiv.org/abs/2303.10154)

    本文提出了一种新的表观遗传算法，利用注意机制和深度学习模拟DNA甲基化，通过增强/沉默基因的概念提高了遗传算法效果，解决了复杂的优化问题。

    

    遗传算法是生物启发式方法的一个著名例子。它们通过建模多个操作符，如突变、交叉和选择，来模仿自然选择。最近发现了“在遗传基础之上”或“除遗传基础之外”发生的表观遗传调控过程，它们涉及影响和改善基因表达的变化。这引发了一个问题，即通过建模表观遗传操作符来改善遗传算法（GAs）。本文提出了一种新的表观遗传算法，模拟了被称为DNA甲基化的表观遗传现象。我们的表观遗传算法的创新之处主要在于利用了注意机制和深度学习，这与增强/沉默基因的概念相契合。本文提出了理论论证，并进行了实证研究，展示了所提出的表观遗传算法解决更复杂问题的能力，这是简单遗传算法所不能做到的，例如，面对特定的约束优化问题，我们的算法表现出了更出色的效果。

    Genetic algorithms are a well-known example of bio-inspired heuristic methods. They mimic natural selection by modeling several operators such as mutation, crossover, and selection. Recent discoveries about Epigenetics regulation processes that occur "on top of" or "in addition to" the genetic basis for inheritance involve changes that affect and improve gene expression. They raise the question of improving genetic algorithms (GAs) by modeling epigenetics operators. This paper proposes a new epigenetics algorithm that mimics the epigenetics phenomenon known as DNA methylation. The novelty of our epigenetics algorithms lies primarily in taking advantage of attention mechanisms and deep learning, which fits well with the genes enhancing/silencing concept. The paper develops theoretical arguments and presents empirical studies to exhibit the capability of the proposed epigenetics algorithms to solve more complex problems efficiently than has been possible with simple GAs; for example, fac
    
[^5]: 动态更新数据比率：减少世界模型过拟合

    Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting. (arXiv:2303.10144v1 [cs.LG])

    [http://arxiv.org/abs/2303.10144](http://arxiv.org/abs/2303.10144)

    提出了一种动态调整更新到数据比率（UTD）的方法，根据小规模的未用于训练的连续收集的经验上检测欠拟合和过拟合。该方法应用于最先进的基于模型的强化学习算法DreamerV2，可以更好地平衡欠拟合和过拟合，并且与广泛的超参数搜索具有竞争力。

    

    在监督学习的情境下，基于验证集表现的早期停止是一种流行的方法，可以找到欠拟合和过拟合之间的平衡。然而，在强化学习中，即使在诸如世界模型学习之类的监督子问题中，也不能应用早期停止，因为数据集在不断演变。为此，我们提出了一种新的通用方法，根据在未参与训练的一小部分连续收集的经验上检测欠拟合和过拟合来动态调整训练中的更新到数据比率（UTD）。我们将该方法应用于DreamerV2，这是一种最先进的基于模型的强化学习算法，并在DeepMind Control Suite和Atari $100$k基准测试上进行评估。结果表明，与DreamerV2中的默认设置相比，通过调整UTD比率来平衡欠拟合与过拟合的效果更好，而且具有与广泛超参数搜索竞争的能力。

    Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not applicable as the dataset is continually evolving. As a solution, we propose a new general method that dynamically adjusts the update to data (UTD) ratio during training based on under- and overfitting detection on a small subset of the continuously collected experience not used for training. We apply our method to DreamerV2, a state-of-the-art model-based reinforcement learning algorithm, and evaluate it on the DeepMind Control Suite and the Atari $100$k benchmark. The results demonstrate that one can better balance under- and overestimation by adjusting the UTD ratio with our approach compared to the default setting in DreamerV2 and that it is competitive with an extensive hyperparameter search 
    
[^6]: 分子晶体结构预测中的几何深度学习

    Geometric Deep Learning for Molecular Crystal Structure Prediction. (arXiv:2303.10140v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2303.10140](http://arxiv.org/abs/2303.10140)

    本研究使用基于分子图形的几何深度学习开发出能够精确、快速评估和适用于不同分子的密度预测和稳定性排名模型，这些模型可用于分子晶体结构预测。同时，我们开发的晶体排名工具具有低成本、灵活部署等优点。

    

    我们使用分子图形的几何深度学习工具，开发和测试了新的机器学习策略，加速了分子晶体结构排名和晶体性质预测。利用基于图形的学习和大型分子晶体数据集的发展，我们训练了密度预测和稳定性排名模型，这些模型精确、评估速度快，并且适用于不同大小和成分的分子。我们的密度预测模型MolXtalNet-D实现了最先进的性能，在大而多样的测试数据集上均方根误差小于2%。我们的晶体排名工具MolXtalNet-S能够正确区分实验样品和合成生成的假样品，并通过对剑桥结构数据库盲测试5和6的提交分析进一步验证。我们的新工具计算成本低廉且灵活，可以在现有的晶体结构预测流程中部署。

    We develop and test new machine learning strategies for accelerating molecular crystal structure ranking and crystal property prediction using tools from geometric deep learning on molecular graphs. Leveraging developments in graph-based learning and the availability of large molecular crystal datasets, we train models for density prediction and stability ranking which are accurate, fast to evaluate, and applicable to molecules of widely varying size and composition. Our density prediction model, MolXtalNet-D, achieves state of the art performance, with lower than 2% mean absolute error on a large and diverse test dataset. Our crystal ranking tool, MolXtalNet-S, correctly discriminates experimental samples from synthetically generated fakes and is further validated through analysis of the submissions to the Cambridge Structural Database Blind Tests 5 and 6. Our new tools are computationally cheap and flexible enough to be deployed within an existing crystal structure prediction pipelin
    
[^7]: Distill n' Explain：使用简单替代模型解释图神经网络

    Distill n' Explain: explaining graph neural networks using simple surrogates. (arXiv:2303.10139v1 [cs.LG])

    [http://arxiv.org/abs/2303.10139](http://arxiv.org/abs/2303.10139)

    本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。

    

    解释图神经网络中节点预测的方法通常是找到保持预测的图子结构。这通常意味着反向传播由于GNN的复杂性（例如，层数）而导致解释的成本上升。因此，作者提出了Distill n' Explain (DnX)方法。首先，DnX通过知识蒸馏来学习替代的GNN。然后，DnX通过解决简单的凸规划来提取节点或边级别的解释。同时，作者还提出了FastDnX，这是DnX的更快版本，它利用了我们替代模型的线性分解。实验表明，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。此外，我们还通过理论结果支持了我们的实验发现。

    Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faith
    
[^8]: 对表格数据进行问题特定工具合成：生成、转换、回答

    Generate, Transform, Answer: Question Specific Tool Synthesis for Tabular Data. (arXiv:2303.10138v1 [cs.LG])

    [http://arxiv.org/abs/2303.10138](http://arxiv.org/abs/2303.10138)

    本文提出了一种名为ToolWriter的工具，用于生成查询特定的程序并将其应用于转换表格，以提高表格问答（TQA）的性能。这个工具通过生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术。随着表格尺寸的增加，传统的语言模型在处理表格的过程中存在信息丢失的问题，我们通过利用程序化工具与神经组件相结合的方法来解决这个问题，并展示了这种方法的广泛潜力。

    

    表格问答（TQA）对于神经系统来说是一个具有挑战性的设置，因为它需要自然语言与大量半结构化数据的联合推理。与人类使用程序化工具（如过滤器）在处理之前转换数据不同，TQA中的语言模型直接处理表格，随着表格尺寸的增加，会导致信息丢失。本文提出了ToolWriter，用于生成查询特定的程序，并在需要时检测何时将其应用于转换表格，并将其与TQA模型的能力对齐。将ToolWriter专注于生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术，最大的性能提升出现在长表格上。通过调查空间，我们的工作突出了将程序化工具与神经组件相结合以操作大量结构化数据的广泛潜力。

    Tabular question answering (TQA) presents a challenging setting for neural systems by requiring joint reasoning of natural language with large amounts of semi-structured data. Unlike humans who use programmatic tools like filters to transform data before processing, language models in TQA process tables directly, resulting in information loss as table size increases. In this paper we propose ToolWriter to generate query specific programs and detect when to apply them to transform tables and align them with the TQA model's capabilities. Focusing ToolWriter to generate row-filtering tools improves the state-of-the-art for WikiTableQuestions and WikiSQL with the most performance gained on long tables. By investigating headroom, our work highlights the broader potential for programmatic tools combined with neural components to manipulate large amounts of structured data.
    
[^9]: MassNet：一种基于深度学习的单张压力图像体重提取方法

    MassNet: A Deep Learning Approach for Body Weight Extraction from A Single Pressure Image. (arXiv:2303.10136v1 [cs.HC])

    [http://arxiv.org/abs/2303.10136](http://arxiv.org/abs/2303.10136)

    本文提出了一种基于压力映射床垫图像的体重提取方法，使用了深度学习和对比学习模块来提取深度特征和姿势特征以及挖掘姿势之间的相互作用因素。

    

    人体重量作为一项重要的生理特征，在身体管理、康复和针对特定患者的药物剂量等许多应用中都具有相当重要的意义。以往的研究主要集中于基于视觉的方法，使用 2D/3D、深度或红外图像，面临着照明、遮挡和隐私问题。压力映射床垫是一种非侵入性和隐私保护的工具，可以获取与躺着的人的体重强相关的床面压力分布图像。我们提出了一种基于深度学习的模型，该模型包括一个双分支网络，分别提取深度特征和姿势特征。同时，我们还将对比学习模块与深度特征分支结合起来，以帮助挖掘每一个单独主题的不同姿势之间的相互作用因素。然后将两组特征连接起来，完成体重估计。

    Body weight, as an essential physiological trait, is of considerable significance in many applications like body management, rehabilitation, and drug dosing for patient-specific treatments. Previous works on the body weight estimation task are mainly vision-based, using 2D/3D, depth, or infrared images, facing problems in illumination, occlusions, and especially privacy issues. The pressure mapping mattress is a non-invasive and privacy-preserving tool to obtain the pressure distribution image over the bed surface, which strongly correlates with the body weight of the lying person. To extract the body weight from this image, we propose a deep learning-based model, including a dual-branch network to extract the deep features and pose features respectively. A contrastive learning module is also combined with the deep-feature branch to help mine the mutual factors across different postures of every single subject. The two groups of features are then concatenated for the body weight regres
    
[^10]: 基于图表示学习的高效可行的机器人装配序列规划

    Efficient and Feasible Robotic Assembly Sequence Planning via Graph Representation Learning. (arXiv:2303.10135v1 [cs.RO])

    [http://arxiv.org/abs/2303.10135](http://arxiv.org/abs/2303.10135)

    本文提出了一种基于图表示学习的装配序列规划方法，通过GRACE模型可以从装配图中提取信息并预测可行的装配序列。

    

    自动机器人装配序列规划（RASP）可以显著提高现代制造业的生产力和适应力，随着对更大量化生产需求的不断增长。实现这种自动化的主要挑战之一在于从不断增加的潜在序列中高效地找到解决方案，进行越来越复杂的装配还需要成本昂贵的可行性检查。为了解决这个问题，我们提出了一种包括产品装配图的图形方法和一个名为GRACE的策略架构，用于装配序列生成。其次，我们使用GRACE从图形输入中提取有意义的信息，并逐步预测装配序列。在实验中，我们展示了我们的方法可以根据在模拟中收集的数据，预测铝型材产品变体的可行装配序列。

    Automatic Robotic Assembly Sequence Planning (RASP) can significantly improve productivity and resilience in modern manufacturing along with the growing need for greater product customization. One of the main challenges in realizing such automation resides in efficiently finding solutions from a growing number of potential sequences for increasingly complex assemblies. Besides, costly feasibility checks are always required for the robotic system. To address this, we propose a holistic graphical approach including a graph representation called Assembly Graph for product assemblies and a policy architecture, Graph Assembly Processing Network, dubbed GRACE for assembly sequence generation. Secondly, we use GRACE to extract meaningful information from the graph input and predict assembly sequences in a step-by-step manner. In experiments, we show that our approach can predict feasible assembly sequences across product variants of aluminum profiles based on data collected in simulation of a
    
[^11]: 她收集需求，他进行测试：大型语言模型中的软件工程性别偏见

    She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models. (arXiv:2303.10131v1 [cs.SE])

    [http://arxiv.org/abs/2303.10131](http://arxiv.org/abs/2303.10131)

    本研究使用数据挖掘技术调查了56项与软件开发相关的任务，发现性别代词与不同任务的相关性明显不同。其中，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，帮助他人的任务有91%的相关性与“他”相关联。

    

    软件开发中的隐性性别偏见是一个被广泛研究的问题，比如将技术角色与男性联系在一起。为了解决这种偏见，更详细地了解它是非常重要的。本研究使用数据挖掘技术调查与软件开发相关的56项任务（如分配GitHub问题和测试），以了解嵌入大型语言模型中的隐性性别偏见所产生的影响程度。我们将每个任务从英语系统地翻译成无性别语言，然后再翻译回英语，并调查与每个任务相关的代词。通过在不同排列中反复翻译每个任务100次，我们确定了不同任务与性别代词的显著差异。具体而言，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，涉及帮助他人的任务有91%的相关性与“他”相关联，而执行同样任务的女性则很容易被忽视。

    Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun "he" in only 6% of cases, while testing was associated with "he" in 100% of cases. Additionally, tasks related to helping others had a 91% association with "he" while the same association fo
    
[^12]: 从时间序列数据中进行因果关系发现:综述和新视角

    Causal Discovery from Temporal Data: An Overview and New Perspectives. (arXiv:2303.10112v1 [cs.LG])

    [http://arxiv.org/abs/2303.10112](http://arxiv.org/abs/2303.10112)

    本文对于从时间数据中进行因果关系发现进行了综述，提出了两个相关的类别，即多元时间序列因果发现和事件序列因果发现，并提供了新的方法来综合考虑这两个类别。

    

    时间数据代表着复杂系统的时间顺序观测，可以被许多领域广泛生成，例如工业、医疗和金融。分析这种类型的数据对于各种应用非常有价值。因此，在过去几十年中，提出了不同的时间数据分析任务，例如分类、聚类和预测。其中，从时间数据中学习因果关系的因果发现任务被认为是一个有趣但至关重要的任务，并引起了广泛的研究关注。现有的因果发现工作可以根据时间数据是否被校准来分为两个高度相关的类别，即多元时间序列因果发现和事件序列因果发现。然而，大多数以前的调查仅专注于时间序列因果发现，忽略了第二类。在本文中，我们详细说明了这两个类别之间的相关性，并提供了新的方法来综合考虑这两个类别。

    Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, medicine and finance. Analyzing this type of data is extremely valuable for various applications. Thus, different temporal data analysis tasks, eg, classification, clustering and prediction, have been proposed in the past decades. Among them, causal discovery, learning the causal relations from temporal data, is considered an interesting yet critical task and has attracted much research attention. Existing casual discovery works can be divided into two highly correlated categories according to whether the temporal data is calibrated, ie, multivariate time series casual discovery, and event sequence casual discovery. However, most previous surveys are only focused on the time series casual discovery and ignore the second category. In this paper, we specify the correlation between the two categories and provide
    
[^13]: 基于扩散模型的无标签图数据中心学习

    Data-Centric Learning from Unlabeled Graphs with Diffusion Model. (arXiv:2303.10108v1 [cs.LG])

    [http://arxiv.org/abs/2303.10108](http://arxiv.org/abs/2303.10108)

    本文提出了一种从无标签图中提取知识并增强属性预测模型的数据中心方法，使用扩散模型和两个新目标进行去噪，实验证明其效果比14种现有方法更好。

    

    图属性预测任务非常重要和众多。虽然每个任务只提供少量的标记示例，但无标签图已从各种渠道并大规模收集。传统方法是在自监督任务的无标签图上训练模型，然后在预测任务上微调模型。然而，自监督任务的知识可能无法与预测任务需要的知识相吻合或有时会产生冲突。本文提出了一种从大量无标签图中提取知识作为特定有用数据点的方法，以增强每个属性预测模型。我们使用扩散模型充分利用无标签图，并设计了两个新的目标来指导模型的去噪过程，使用每个任务的标记数据生成任务特定图形示例及其标签。实验证明，我们的数据中心方法比14种现有方法在fi上表现显着优异。

    Graph property prediction tasks are important and numerous. While each task offers a small size of labeled examples, unlabeled graphs have been collected from various sources and at a large scale. A conventional approach is training a model with the unlabeled graphs on self-supervised tasks and then fine-tuning the model on the prediction tasks. However, the self-supervised task knowledge could not be aligned or sometimes conflicted with what the predictions needed. In this paper, we propose to extract the knowledge underlying the large set of unlabeled graphs as a specific set of useful data points to augment each property prediction model. We use a diffusion model to fully utilize the unlabeled graphs and design two new objectives to guide the model's denoising process with each task's labeled data to generate task-specific graph examples and their labels. Experiments demonstrate that our data-centric approach performs significantly better than fourteen existing various methods on fi
    
[^14]: 高效生成4K掩膜用于齐次扩散修复

    Efficient Neural Generation of 4K Masks for Homogeneous Diffusion Inpainting. (arXiv:2303.10096v1 [eess.IV])

    [http://arxiv.org/abs/2303.10096](http://arxiv.org/abs/2303.10096)

    该论文提出了一种高效生成4K掩膜的神经网络方法，可以实现对高分辨率图像进行快速且高质量的修复。

    

    利用优选数据，齐次扩散修复可以重建具有高质量的稀疏数据图像。虽然大小为3840 x 2160的4K彩色图像可以实时修复，但优化已知数据以用于图像压缩等应用仍然具有挑战性：广泛使用的随机策略可能需要数天才能处理单个4K图像。最近，第一个针对这个所谓的掩膜优化问题的神经方法通过神经修复代理帮助训练掩膜生成网络，提供了高速度和良好质量的小型图像。但是，这些掩膜网络只能在它们训练的分辨率和掩膜密度下输出掩膜。我们通过一种神经-显式的自粗到细的策略解决了这些问题，并实现了高分辨率图像的掩膜优化。此外，我们通过直接将数值修复求解器纳入网络中来改进掩膜网络的训练和可解释性。这使得能够在短短几秒钟内生成高质量的4K图像掩膜。

    With well-selected data, homogeneous diffusion inpainting can reconstruct images from sparse data with high quality. While 4K colour images of size 3840 x 2160 can already be inpainted in real time, optimising the known data for applications like image compression remains challenging: Widely used stochastic strategies can take days for a single 4K image. Recently, a first neural approach for this so-called mask optimisation problem offered high speed and good quality for small images. It trains a mask generation network with the help of a neural inpainting surrogate. However, these mask networks can only output masks for the resolution and mask density they were trained for. We solve these problems and enable mask optimisation for high-resolution images through a neuroexplicit coarse-to-fine strategy. Additionally, we improve the training and interpretability of mask networks by including a numerical inpainting solver directly into the network. This allows to generate masks for 4K imag
    
[^15]: 提高上下文在目标检测区域-词对齐中的作用

    Enhancing the Role of Context in Region-Word Alignment for Object Detection. (arXiv:2303.10093v1 [cs.CV])

    [http://arxiv.org/abs/2303.10093](http://arxiv.org/abs/2303.10093)

    本研究提出了一种增强上下文在目标检测区域-词对齐中作用的方法，通过特定的负采样方法提高了属性的作用，从而提高了目标检测的效果。

    

    视觉语言预训练学习图像-标注配对之间的细粒度区域-词对齐，推动了开放词汇目标检测的进展。我们观察到，区域-词对齐方法通常仅针对目标名词在检测中使用，其他上下文，例如属性，对检测的影响不明确。在本研究中，我们探讨了语言上下文如何影响下游目标检测，并提议增强上下文的作用。特别地，我们展示了如何策略性地将接地预训练目标情境化以实现更好的对齐。我们进一步研究了属性作为特别有用的目标上下文并提出了一种新的基于形容词和名词的负采样策略，以增加对它们的对比学习的关注。总的来说，与区域-词预训练的最新技术相比，我们的方法提升了目标检测的效果。我们还通过文本-区域可视化显示属性敏感模型的细粒度实用性。

    Vision-language pretraining to learn a fine-grained, region-word alignment between image-caption pairs has propelled progress in open-vocabulary object detection. We observe that region-word alignment methods are typically used in detection with respect to only object nouns, and the impact of other rich context in captions, such as attributes, is unclear. In this study, we explore how language context affects downstream object detection and propose to enhance the role of context. In particular, we show how to strategically contextualize the grounding pretraining objective for improved alignment. We further hone in on attributes as especially useful object context and propose a novel adjective and noun-based negative sampling strategy for increasing their focus in contrastive learning. Overall, our methods enhance object detection when compared to the state-of-the-art in region-word pretraining. We also highlight the fine-grained utility of an attribute-sensitive model through text-regi
    
[^16]: 通过约束传输度量实现鲁棒概率推断

    Robust probabilistic inference via a constrained transport metric. (arXiv:2303.10085v1 [stat.ME])

    [http://arxiv.org/abs/2303.10085](http://arxiv.org/abs/2303.10085)

    本文提出了一种新颖的鲁棒概率推断方法，基于约束传输度量，利用经验似然结合先验分布，用于鲁棒推断问题，实现对中心分布参数的推断，具有卓越的性能表现。

    

    弹性贝叶斯模型通常是使用具有大量参数且常常不可解释的参数模型的极限构建而成的。本文提出了一种新颖的方法，通过使用倾斜的经验似然的构造，结合一种新型的Wasserstein度量，集中在特定参数族附近，然后结合模型参数的先验分布，从而得到一个鲁棒的后验分布。该方法在许多鲁棒推断问题中找到应用，我们旨在在存在异常值的情况下对与中心分布相关的参数进行推断。我们提出的传输度量具有很高的计算简便性，利用了离散最优传输问题的Sinkhorn正则化，并本质上可以并行化。我们证明了我们的方法与最先进的方法相比具有卓越的性能。

    Flexible Bayesian models are typically constructed using limits of large parametric models with a multitude of parameters that are often uninterpretable. In this article, we offer a novel alternative by constructing an exponentially tilted empirical likelihood carefully designed to concentrate near a parametric family of distributions of choice with respect to a novel variant of the Wasserstein metric, which is then combined with a prior distribution on model parameters to obtain a robustified posterior. The proposed approach finds applications in a wide variety of robust inference problems, where we intend to perform inference on the parameters associated with the centering distribution in presence of outliers. Our proposed transport metric enjoys great computational simplicity, exploiting the Sinkhorn regularization for discrete optimal transport problems, and being inherently parallelizable. We demonstrate superior performance of our methodology when compared against state-of-the-ar
    
[^17]: 模糊调谐：提高对抗样本的可迁移性

    Fuzziness-tuned: Improving the Transferability of Adversarial Examples. (arXiv:2303.10078v1 [cs.LG])

    [http://arxiv.org/abs/2303.10078](http://arxiv.org/abs/2303.10078)

    本文提出了一种模糊度调谐方法生成对抗性样本，通过减少模糊领域有效地提高对抗样本的可迁移性，实验证明其相对于现有技术具有卓越性能。

    

    随着对抗攻击的发展，对抗样本已广泛应用于提高深度神经网络模型的鲁棒性。尽管针对提高对抗样本可迁移性的对抗攻击做出了可观的努力，但在低攻击力度(例如，攻击强度ϵ=8/255)，基于迁移的攻击在代理模型上的攻击成功率远高于受害者模型的攻击成功率。本文首先系统地研究了这个问题，并发现代理模型和受害者模型之间攻击成功率的巨大差异是由一个特殊区域（我们在本文中称之为模糊领域）的存在导致的，该区域中的对抗样本被代理模型错误分类，而被受害者模型正确分类。然后，为了消除这种攻击成功率的巨大差异以提高生成的对抗性样本的可迁移性，我们提出了一种模糊度调谐方法来生成对抗性样本。具体而言，我们引入了一个名为“模糊度”的新参数来控制对抗性样本生成的扰动程度，这可以有效减少模糊领域并促进对抗性样本的可迁移性。多个数据集上的实验结果证明了我们方法相对于现有技术的卓越性能，进一步分析表明，我们的方法可以提高深度神经网络对基于迁移的攻击的鲁棒性。

    With the development of adversarial attacks, adversairal examples have been widely used to enhance the robustness of the training models on deep neural networks. Although considerable efforts of adversarial attacks on improving the transferability of adversarial examples have been developed, the attack success rate of the transfer-based attacks on the surrogate model is much higher than that on victim model under the low attack strength (e.g., the attack strength $\epsilon=8/255$). In this paper, we first systematically investigated this issue and found that the enormous difference of attack success rates between the surrogate model and victim model is caused by the existence of a special area (known as fuzzy domain in our paper), in which the adversarial examples in the area are classified wrongly by the surrogate model while correctly by the victim model. Then, to eliminate such enormous difference of attack success rates for improving the transferability of generated adversarial exa
    
[^18]: 利用DBLP数据进行深度作者姓名消歧

    Deep Author Name Disambiguation using DBLP Data. (arXiv:2303.10067v1 [cs.DL])

    [http://arxiv.org/abs/2303.10067](http://arxiv.org/abs/2303.10067)

    本文提出了一种利用共同作者和研究领域来消除作者名字歧义的方法，并使用DBLP仓库中的数据进行训练。

    

    在学术界中，科学家数量每年都在增加，同名作者数量也相应增加，因此将新发表的论文分配给对应的作者是一项具有挑战性的任务。因此，作者姓名模糊性(ANA) 是数字图书馆中一个关键的开放问题。本文提出了一种作者姓名消歧(AND)方法，通过利用作者的合作者和研究领域，将作者姓名链接到他们的真实实体上。为此，我们使用DBLP仓库中收集的数据，该仓库包含约260万个共同作者撰写的超过500万个文献记录。我们的方法首先将相同姓氏和相同名字首字母的作者分组。在每个组中，通过捕获作者与他/她的合作者和研究领域之间的关系，由对应作者的验证出版物的标题进行表示，以确定每个组中的作者。为此，我们训练了一种神经网络模型，该模型从数据中学习。

    In the academic world, the number of scientists grows every year and so does the number of authors sharing the same names. Consequently, it challenging to assign newly published papers to their respective authors. Therefore, Author Name Ambiguity (ANA) is considered a critical open problem in digital libraries. This paper proposes an Author Name Disambiguation (AND) approach that links author names to their real-world entities by leveraging their co-authors and domain of research. To this end, we use data collected from the DBLP repository that contains more than 5 million bibliographic records authored by around 2.6 million co-authors. Our approach first groups authors who share the same last names and same first name initials. The author within each group is identified by capturing the relation with his/her co-authors and area of research, represented by the titles of the validated publications of the corresponding author. To this end, we train a neural network model that learns from
    
[^19]: 不怕分类器偏差：以神经崩溃为灵感的合作学习中使用合成和固定分类器

    No Fear of Classifier Biases: Neural Collapse Inspired Federated Learning with Synthetic and Fixed Classifier. (arXiv:2303.10058v1 [cs.LG])

    [http://arxiv.org/abs/2303.10058](http://arxiv.org/abs/2303.10058)

    本文提出一种解决合作学习中分类器偏差问题的方案，即在训练过程中使用合成的ETF分类器，使得所有客户端能够学习到统一的最优特征表示。

    

    数据异构性是困扰合作学习性能的内在挑战。最近的研究已经确定了本地模型的偏置分类器是关键瓶颈。以前的尝试利用FL训练后进行分类器校准，但这种方法未能改善训练时分类器偏差导致的差劣特征表示。解决FL中分类器偏差困境需要充分理解分类器背后的机制。神经崩溃的最新进展表明，在完美的训练场景下，分类器和特征原型崩溃为一种称为simplex equiangular tight frame(ETF)的最优结构。基于这种神经崩溃的见解，我们提出了一种解决FL分类器偏差问题的解决方案，即在训练过程中利用合成和固定的ETF分类器。最优分类器结构使得所有客户端甚至在极端异构数据下也能学到统一的和最优的特征表示。

    Data heterogeneity is an inherent challenge that hinders the performance of federated learning (FL). Recent studies have identified the biased classifiers of local models as the key bottleneck. Previous attempts have used classifier calibration after FL training, but this approach falls short in improving the poor feature representations caused by training-time classifier biases. Resolving the classifier bias dilemma in FL requires a full understanding of the mechanisms behind the classifier. Recent advances in neural collapse have shown that the classifiers and feature prototypes under perfect training scenarios collapse into an optimal structure called simplex equiangular tight frame (ETF). Building on this neural collapse insight, we propose a solution to the FL's classifier bias problem by utilizing a synthetic and fixed ETF classifier during training. The optimal classifier structure enables all clients to learn unified and optimal feature representations even under extremely hete
    
[^20]: 使用深度学习进行后验估计： PET 动态模型中分区建模的模拟研究

    Posterior Estimation Using Deep Learning: A Simulation Study of Compartmental Modeling in Dynamic PET. (arXiv:2303.10057v1 [eess.IV])

    [http://arxiv.org/abs/2303.10057](http://arxiv.org/abs/2303.10057)

    本研究利用深度学习有效地估计成像参数的后验分布，提高了 PET 成像参数估计的精度和计算效率，可为诊断和治疗提供有价值的参考。

    

    在医学成像中，图像通常被视为确定性的，而它们的不确定性很大程度上未被探索。本研究旨在利用深度学习有效地估计成像参数的后验分布，这些后验分布可以用来推导出最可能的参数以及它们的不确定性。我们将这些方法应用于 PET 动态脑成像模拟研究中，使用一个基于参考区域的动力学模型。

    Background: In medical imaging, images are usually treated as deterministic, while their uncertainties are largely underexplored. Purpose: This work aims at using deep learning to efficiently estimate posterior distributions of imaging parameters, which in turn can be used to derive the most probable parameters as well as their uncertainties. Methods: Our deep learning-based approaches are based on a variational Bayesian inference framework, which is implemented using two different deep neural networks based on conditional variational auto-encoder (CVAE), CVAE-dual-encoder and CVAE-dual-decoder. The conventional CVAE framework, i.e., CVAE-vanilla, can be regarded as a simplified case of these two neural networks. We applied these approaches to a simulation study of dynamic brain PET imaging using a reference region-based kinetic model. Results: In the simulation study, we estimated posterior distributions of PET kinetic parameters given a measurement of time-activity curve. Our propose
    
[^21]: 群体运动控制的策略迭代方法

    A Policy Iteration Approach for Flock Motion Control. (arXiv:2303.10035v1 [eess.SY])

    [http://arxiv.org/abs/2303.10035](http://arxiv.org/abs/2303.10035)

    本文提出了一种基于无模型策略迭代机制的群体运动控制方法，能够在时间变化的图形拓扑下引导代理人遵循命令生成器，并在线调整指导策略以适应实时动态情况。

    

    群体运动控制旨在管理多代理系统的本地和团队目标之间可能存在的冲突。整个控制过程指导代理，并监控群体凝聚性和定位。然而，忽略与群体动态和形成相关的未建模不确定性可能会降低基础机制的效果。另一方面，各种控制设计的效率取决于它们能够多快地适应实时不同的动态情况。本文提出了一种在线无模型策略迭代机制，以引导一群代理人遵循随时间变化的图形拓扑下的独立命令生成器。通过位置相邻依赖函数确定任意两个代理之间的连接强度或图边缘权重。采用在线递归最小二乘方法来调整指导策略，而不必了解代理或命令生成器的动态。

    The flocking motion control is concerned with managing the possible conflicts between local and team objectives of multi-agent systems. The overall control process guides the agents while monitoring the flock-cohesiveness and localization. The underlying mechanisms may degrade due to overlooking the unmodeled uncertainties associated with the flock dynamics and formation. On another side, the efficiencies of the various control designs rely on how quickly they can adapt to different dynamic situations in real-time. An online model-free policy iteration mechanism is developed here to guide a flock of agents to follow an independent command generator over a time-varying graph topology. The strength of connectivity between any two agents or the graph edge weight is decided using a position adjacency dependent function. An online recursive least squares approach is adopted to tune the guidance strategies without knowing the dynamics of the agents or those of the command generator. It is co
    
[^22]: 随机盲反卷积在核范数最小化中对抗性噪声的稳健性研究

    How robust is randomized blind deconvolution via nuclear norm minimization against adversarial noise?. (arXiv:2303.10030v1 [cs.IT])

    [http://arxiv.org/abs/2303.10030](http://arxiv.org/abs/2303.10030)

    本文提出了对核范数最小化的稳健性边界进行改进的方法，以应对随机噪声，可以在维度无关的误差边界下，在随机噪声和最坏情况下的扰动下稳定地恢复两个信号。

    

    本文研究从卷积中恢复两个未知信号的难题——盲反卷积。将盲反卷积重新表述为一个低秩恢复问题，由于核范数最小化启发式算法的成功，过去十年中已经产生了多重理论恢复保证。然而，如果卷积受到加性有界噪声的干扰，恢复问题的稳定性仍然远未被理解。我们提出了对核范数最小化的稳健性边界进行改进的方法，以应对随机噪声。我们的分析表明，在随机噪声和最坏情况下的扰动下，核范数最小化可以稳定地恢复两个信号，并且具有无关维度的误差边界。

    In this paper, we study the problem of recovering two unknown signals from their convolution, which is commonly referred to as blind deconvolution. Reformulation of blind deconvolution as a low-rank recovery problem has led to multiple theoretical recovery guarantees in the past decade due to the success of the nuclear norm minimization heuristic. In particular, in the absence of noise, exact recovery has been established for sufficiently incoherent signals contained in lower-dimensional subspaces. However, if the convolution is corrupted by additive bounded noise, the stability of the recovery problem remains much less understood. In particular, existing reconstruction bounds involve large dimension factors and therefore fail to explain the empirical evidence for dimension-independent robustness of nuclear norm minimization. Recently, theoretical evidence has emerged for ill-posed behavior of low-rank matrix recovery for sufficiently small noise levels. In this work, we develop improv
    
[^23]: 层次-超平面核在高斯过程模型积极学习中的应用

    Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems. (arXiv:2303.10022v1 [cs.LG])

    [http://arxiv.org/abs/2303.10022](http://arxiv.org/abs/2303.10022)

    本文提出了一种层次-超平面核函数族，能够在高斯过程模型积极学习中使用，以建模非平稳性和非线性特性。

    

    学习复杂计算机模拟和物理机器的精确代理模型通常需要长时间或昂贵的实验。此外，建模的物理依赖关系表现出非线性和非平稳性。因此，用于产生代理模型的机器学习方法应通过提供保持查询数量少的方案（例如使用积极学习），并能够捕获系统的非线性和非平稳特性来解决这些问题。一种建模非平稳性的方法是引入输入分区，这种方法在高斯过程的积极学习中被证明是有优势的。但是，这些方法要么假定已知分区，需要引入复杂的抽样方案，要么依赖于非常简单的几何形状。在本文中，我们提出了一种简单但强大的核函数族，它包括一个可通过基于梯度的方法进行学习的分区，并使用更灵活的几何形状。

    Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible
    
[^24]: 多元概率CRPS学习及其在日前电价预测中的应用

    Multivariate Probabilistic CRPS Learning with an Application to Day-Ahead Electricity Prices. (arXiv:2303.10019v1 [stat.ML])

    [http://arxiv.org/abs/2303.10019](http://arxiv.org/abs/2303.10019)

    本文提出一种新的多元概率CRPS学习方法，应用于日前电价预测中，相比于统一组合在CRPS方面取得了显著改进。

    

    本文提出了一种考虑分位数和协变量依赖关系的多元概率预测的结合方法，并通过平滑过程允许在线学习。通过维数降低和罚函数平滑等两种平滑方法来将标准CRPS学习框架推广到多元维度中。将该方法应用于预测日前电价，相比于统一组合，在CRPS方面取得了显著改进。

    This paper presents a new method for combining (or aggregating or ensembling) multivariate probabilistic forecasts, taking into account dependencies between quantiles and covariates through a smoothing procedure that allows for online learning. Two smoothing methods are discussed: dimensionality reduction using Basis matrices and penalized smoothing. The new online learning algorithm generalizes the standard CRPS learning framework into multivariate dimensions. It is based on Bernstein Online Aggregation (BOA) and yields optimal asymptotic learning properties. We provide an in-depth discussion on possible extensions of the algorithm and several nested cases related to the existing literature on online forecast combination. The methodology is applied to forecasting day-ahead electricity prices, which are 24-dimensional distributional forecasts. The proposed method yields significant improvements over uniform combination in terms of continuous ranked probability score (CRPS). We discuss 
    
[^25]: 基于强化学习的数据驱动模型参考自适应控制方法

    A Data-Driven Model-Reference Adaptive Control Approach Based on Reinforcement Learning. (arXiv:2303.09994v1 [eess.SY])

    [http://arxiv.org/abs/2303.09994](http://arxiv.org/abs/2303.09994)

    本文提出了一种基于强化学习的数据驱动模型参考自适应控制方法，用积分时间差分方程描述过程、采用积分强化学习机制解决问题。

    

    模型参考自适应系统是指平衡装置跟踪所需参考轨迹的技术集合。通常采用的方法基于李亚普诺夫、滑动曲面和反馈等理论，指导自适应控制策略。由此得到的解决方案一般都面临参考模型复杂度和控制策略派生的复杂度的挑战。此外，控制策略明确依赖于过程动力学和参考动力学模型，可能会在面对不确定或未知的动态时降低其效率。本文提出了一种自适应解决方案，用于解决基于误差结构的汉密尔顿-雅可比-贝尔曼方程的自主系统。所提出的方法用一个积分时间差分方程来描述过程，并采用一个积分强化学习机制来解决它。这是在不知道或使用任何动态的情况下实时完成的。

    Model-reference adaptive systems refer to a consortium of techniques that guide plants to track desired reference trajectories. Approaches based on theories like Lyapunov, sliding surfaces, and backstepping are typically employed to advise adaptive control strategies. The resulting solutions are often challenged by the complexity of the reference model and those of the derived control strategies. Additionally, the explicit dependence of the control strategies on the process dynamics and reference dynamical models may contribute in degrading their efficiency in the face of uncertain or unknown dynamics. A model-reference adaptive solution is developed here for autonomous systems where it solves the Hamilton-Jacobi-Bellman equation of an error-based structure. The proposed approach describes the process with an integral temporal difference equation and solves it using an integral reinforcement learning mechanism. This is done in real-time without knowing or employing the dynamics of eith
    
[^26]: 在领域泛化中找到能力区域

    Finding Competence Regions in Domain Generalization. (arXiv:2303.09989v1 [cs.LG])

    [http://arxiv.org/abs/2303.09989](http://arxiv.org/abs/2303.09989)

    该论文提出了一个“学习拒绝”框架来解决领域泛化中的默默失败问题。通过预测可信度，该方法在测试分布与训练分布不同的情况下接受超出分布的数据，以识别能力区域。研究发现，通过不同的学习表示衡量无能，增加无能得分会预示着降低准确性。

    

    我们提出了一个“学习拒绝”框架来解决领域泛化中默默失败的问题，即测试分布与训练分布不同的情况。假设有一个温和的分布偏移，我们希望在模型估计的能力预示着可信响应时接受超出分布的数据，而不是直接拒绝超出分布的数据。可信度通过与分类器性能密切相关的代理无能分数进行预测。我们对分类的无能得分进行了全面的实验评估，并强调了拒绝率与准确率之间的权衡。为了与先前的工作进行比较，我们聚焦于标准领域泛化基准，并考虑在闭合和开放世界环境下通过不同的学习表示来衡量无能。我们的结果表明，增加无能分数确实预示着降低准确性，从而导致显着的...

    We propose a "learning to reject" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significan
    
[^27]: 实现AI控制的FES运动康复：利用强化学习学习循环刺激模式。

    Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning. (arXiv:2303.09986v1 [cs.RO])

    [http://arxiv.org/abs/2303.09986](http://arxiv.org/abs/2303.09986)

    本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。

    

    功能性电刺激（FES）已经越来越多地与其他康复设备（包括机器人）集成在一起。 FES循环是康复治疗中常用的FES应用之一，它通过刺激腿部肌肉以特定模式进行。 适当的模式因人而异，需要手动调整，这可能需要耗费时间并对个体用户具有挑战性。 本文提出了一种基于人工智能的方法，可用于寻找循环刺激模式，而无需额外的硬件或传感器。我们的方法包括两个阶段，首先使用强化学习和详细的肌肉骨骼模型找到基于模型的模式，使用开源软件构建模型，可以通过我们的自动脚本进行定制，并且可以由非技术人员使用而不需要额外费用。接下来，我们的方法使用真实的自行车数据对模式进行微调。 我们在静止三轮车上对我们的方法进行了模拟测试和实验测试。在模拟测试中，我们的方法可以...

    Functional electrical stimulation (FES) has been increasingly integrated with other rehabilitation devices, including robots. FES cycling is one of the common FES applications in rehabilitation, which is performed by stimulating leg muscles in a certain pattern. The appropriate pattern varies across individuals and requires manual tuning which can be time-consuming and challenging for the individual user. Here, we present an AI-based method for finding the patterns, which requires no extra hardware or sensors. Our method has two phases, starting with finding model-based patterns using reinforcement learning and detailed musculoskeletal models. The models, built using open-source software, can be customised through our automated script and can be therefore used by non-technical individuals without extra cost. Next, our method fine-tunes the pattern using real cycling data. We test our both in simulation and experimentally on a stationary tricycle. In the simulation test, our method can 
    
[^28]: 从飞行轨迹和程序中推断终端空域交通模型

    Inferring Traffic Models in Terminal Airspace from Flight Tracks and Procedures. (arXiv:2303.09981v1 [cs.LG])

    [http://arxiv.org/abs/2303.09981](http://arxiv.org/abs/2303.09981)

    本文提出了一种通过收集飞行轨迹和程序数据学习飞行器行为变异性的概率模型，并且可以生成涉及任意数量飞行器的交通模型。

    

    真实的航空器轨迹模型对于空中交通管理（ATM）系统设计和验证很有用。仪表飞行规则（IFR）下操作的飞行器模型需要捕捉飞行器按照标准飞行程序的固有变异性。飞行器行为的变异性在不同的飞行阶段之间各不相同。本文提出了一种概率模型，可以从程序数据和从雷达监视数据收集的飞行轨迹中学习变异性。 对于每个段落，使用高斯混合模型学习飞行器轨迹与其程序之间的偏差。给定新的程序，我们可以通过从经过训练的高斯分布中抽样一系列偏差，并使用偏差和程序重构飞行器轨迹来生成合成轨迹。我们将这种方法扩展到捕捉飞行器之间的成对相关性，并展示如何使用成对模型来生成涉及任意数量飞行器的交通模型。

    Realistic aircraft trajectory models are useful in the design and validation of air traffic management (ATM) systems. Models of aircraft operated under instrument flight rules (IFR) require capturing the variability inherent in how aircraft follow standard flight procedures. The variability in aircraft behavior varies among flight stages. In this paper, we propose a probabilistic model that can learn the variability from the procedural data and flight tracks collected from radar surveillance data. For each segment, a Gaussian mixture model is used to learn the deviations of aircraft trajectories from their procedures. Given new procedures, we can generate synthetic trajectories by sampling a series of deviations from the trained Gaussian distributions and reconstructing the aircraft trajectory using the deviations and the procedures. We extend this method to capture pairwise correlations between aircraft and show how a pairwise model can be used to generate traffic involving an arbitra
    
[^29]: MedNeXt：用于医学图像分割的变压器驱动卷积神经网络的可扩展性

    MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation. (arXiv:2303.09975v1 [eess.IV])

    [http://arxiv.org/abs/2303.09975](http://arxiv.org/abs/2303.09975)

    MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。

    

    近年来，在医学图像分割中使用基于 Transformer 的架构越来越多，但是由于缺乏大规模标注的医学数据集，使得其性能远不如自然图像。相比之下，卷积神经网络具有更高的归纳偏差，因此更容易训练到高性能水平。最近，ConvNeXt 架构尝试通过镜像变压器块来现代化标准卷积神经网络。在这项工作中，我们改进了这一架构，设计了一种现代化且可扩展的卷积神经网络，以应对数据稀缺的医学环境的挑战。我们引入 MedNeXt，这是一个受变压器启发的大核分割网络，其中包括：1）用于医学图像分割的完全 ConvNeXt 3D 编码器 - 解码器网络，2）残差 ConvNeXt 上下采样块，以在各个尺度上保留语义信息，3）一种新的技术，通过上采样小核来迭代增加核大小。

    There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel 
    
[^30]: 邻域平均法用于改进异常检测器

    Neighborhood Averaging for Improving Outlier Detectors. (arXiv:2303.09972v1 [cs.LG])

    [http://arxiv.org/abs/2303.09972](http://arxiv.org/abs/2303.09972)

    提出了一种名为邻域平均（NA）的异常分数后处理技术，通过将对象及其k个最近邻居的分数相结合来修改其异常分数，使得相似的对象具有比原始分数更相似的异常分数，实验证明在九个真实世界数据集上评估，NA将所有测试的10个基线检测器平均改进了13％。

    

    我们假设相似的对象应该有相似的异常分数。据我们所知，所有现有的异常检测器都独立地为每个对象计算异常分数，而不考虑其他对象的异常分数。因此，它们不能保证相似的对象具有相似的异常分数。为了验证我们提出的假设，我们提出了一种名为邻域平均（NA）的异常分数后处理技术，它关注对象及其邻居，并保证它们具有比原始分数更相似的异常分数。给定任何异常检测器中的对象及其异常分数，NA通过将其与其k个最近邻居的分数相结合，修改其异常分数。我们使用知名的k-最近邻（k-NN）证明了NA的有效性。实验结果表明，在九个真实世界数据集上评估，NA将所有测试的10个基线检测器平均改进了13％（从0.70到0.79 AUC）。

    We hypothesize that similar objects should have similar outlier scores. To our knowledge, all existing outlier detectors calculate the outlier score for each object independently regardless of the outlier scores of the other objects. Therefore, they do not guarantee that similar objects have similar outlier scores. To verify our proposed hypothesis, we propose an outlier score post-processing technique for outlier detectors, called neighborhood averaging(NA), which pays attention to objects and their neighbors and guarantees them to have more similar outlier scores than their original scores. Given an object and its outlier score from any outlier detector, NA modifies its outlier score by combining it with its k nearest neighbors' scores. We demonstrate the effectivity of NA by using the well-known k-nearest neighbors (k-NN). Experimental results show that NA improves all 10 tested baseline detectors by 13% (from 0.70 to 0.79 AUC) on average evaluated on nine real-world datasets. Moreo
    
[^31]: 基于多项式估算器的随机子模最大化问题

    Stochastic Submodular Maximization via Polynomial Estimators. (arXiv:2303.09960v1 [cs.LG])

    [http://arxiv.org/abs/2303.09960](http://arxiv.org/abs/2303.09960)

    本文研究了随机子模最大化问题，特别是通过使用多项式估算器实现了随机连续贪心算法的 $(1-1/e) \approx 63\%$ 的近似比效果，同时显著降低了执行时间。

    

    本文研究了在在线学习、团队组建、设施选址、影响最大化、主动学习和感知目标函数等领域中自然而然出现的带有一般拟阵约束的随机子模最大化问题。我们针对一类由未知分布下的子模函数期望定义的随机最大化问题进行了研究。我们展示了对于这种单调函数，使用多项式梯度估算器的随机连续贪心算法可以达到 $(1-1/e) \approx 63\%$ 的近似比（期望值），同时我们也证明了使用多项式估算器代替先前采用采样的算法能够消除一些随机因素并显著降低执行时间。

    In this paper, we study stochastic submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approximation ratio (in expectation) arbitrarily close to $(1-1/e) \approx 63\%$ using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time.
    
[^32]: 为神经网络波函数构建一个基础模型

    Towards a Foundation Model for Neural Network Wavefunctions. (arXiv:2303.09949v1 [physics.comp-ph])

    [http://arxiv.org/abs/2303.09949](http://arxiv.org/abs/2303.09949)

    本文提出了一个新的神经网络ansatz，将计算廉价的哈特里-福克轨道映射到高精度神经网络轨道。它能够学习跨化合物和几何结构的单个波函数，并进行广泛的预训练。

    

    结合变分蒙特卡罗方法来求解电子薛定谔方程，深度神经网络已成为高精度和强大的波函数ansatz。然而，尽管它们成功且具有优良的可伸缩性，但这些方法仍然在计算上过于昂贵以便广泛采用。一个重要的障碍是需要为每个新系统从头开始优化波函数，因此需要长时间的优化。在这项工作中，我们提出了一种新的神经网络ansatz，它可以有效地将无关联的、计算廉价的哈特里-福克轨道映射到相关的高精度神经网络轨道。这种ansatz本质上能够学习跨多种化合物和几何结构的单个波函数，这一点我们通过成功将针对小分子片段预训练的波函数模型转移到较大化合物的实验证据得到了证明。此外，我们提供了充分的实验证据来支持这样一个广义波函数的广泛预训练的想法。

    Deep neural networks have become a highly accurate and powerful wavefunction ansatz in combination with variational Monte Carlo methods for solving the electronic Schr\"odinger equation. However, despite their success and favorable scaling, these methods are still computationally too costly for wide adoption. A significant obstacle is the requirement to optimize the wavefunction from scratch for each new system, thus requiring long optimization. In this work, we propose a novel neural network ansatz, which effectively maps uncorrelated, computationally cheap Hartree-Fock orbitals, to correlated, high-accuracy neural network orbitals. This ansatz is inherently capable of learning a single wavefunction across multiple compounds and geometries, as we demonstrate by successfully transferring a wavefunction model pre-trained on smaller fragments to larger compounds. Furthermore, we provide ample experimental evidence to support the idea that extensive pre-training of a such a generalized wa
    
[^33]: 自适应模糊强化学习协作方法用于群集系统的自主控制

    An Adaptive Fuzzy Reinforcement Learning Cooperative Approach for the Autonomous Control of Flock Systems. (arXiv:2303.09946v1 [eess.SY])

    [http://arxiv.org/abs/2303.09946](http://arxiv.org/abs/2303.09946)

    本文提出了一个自适应模糊强化学习协作方法用于群集系统的自主控制。该方法针对跟随领袖、避免碰撞和达到群体速度共识三个目标，具有弹性和鲁棒性，且在实验中性能优于现有方案。

    

    群集引导问题具有挑战性的结构，需要同时解决多个优化目标。这通常需要不同的控制方法来处理各种目标，例如引导、避碰和凝聚。特别是引导方案长期以来一直受到复杂的跟踪误差动力学的困扰。此外，基于平衡条件获取的线性反馈策略的技术，不可避免地在不确定的动态环境下不协调或者为不稳定状态。预调谐的模糊推理结构缺乏在这样的未建模条件下的鲁棒性。本文介绍了一种自适应分布式技术，用于群集系统的自主控制。它相对灵活的结构基于同时针对一些目标的在线模糊强化学习方案，即跟随领袖、避免碰撞和达到群体速度共识。除了在不确定性和干扰面前的弹性之外，所提出的方法保证了对名义条件的鲁棒和快速收敛性质。在各种实验场景中，所提出的算法在跟踪精度和碰撞避免率方面优于现有方案。

    The flock-guidance problem enjoys a challenging structure where multiple optimization objectives are solved simultaneously. This usually necessitates different control approaches to tackle various objectives, such as guidance, collision avoidance, and cohesion. The guidance schemes, in particular, have long suffered from complex tracking-error dynamics. Furthermore, techniques that are based on linear feedback strategies obtained at equilibrium conditions either may not hold or degrade when applied to uncertain dynamic environments. Pre-tuned fuzzy inference architectures lack robustness under such unmodeled conditions. This work introduces an adaptive distributed technique for the autonomous control of flock systems. Its relatively flexible structure is based on online fuzzy reinforcement learning schemes which simultaneously target a number of objectives; namely, following a leader, avoiding collision, and reaching a flock velocity consensus. In addition to its resilience in the face
    
[^34]: DSDP：一种由GPU加速的盲对接策略

    DSDP: A Blind Docking Strategy Accelerated by GPUs. (arXiv:2303.09916v1 [physics.chem-ph])

    [http://arxiv.org/abs/2303.09916](http://arxiv.org/abs/2303.09916)

    本研究提出了一种由GPU加速的盲对接策略DSDP，其通过利用传统和基于机器学习的方法的优点改进了盲对接的性能。DSDP可以预测蛋白质的结合位点，并提供准确的搜索空间和初始位置，以进行进一步的构象采样。

    

    虚拟筛选，包括分子对接，在药物研发中起着至关重要的作用。许多传统的和基于机器学习的方法可用于完成对接任务。传统的对接方法通常需要大量的时间，并且它们在盲对接中的性能有待改进。虽然基于机器学习的对接运行时间显着缩短，但它们的准确性仍然有限。在本研究中，我们利用传统和基于机器学习的方法的优点，提出了一种深度位点和对接姿态(DSDP)的方法来改进盲对接的性能。对于传统的盲对接，整个蛋白质被一个立方体覆盖，配体的初始位置在立方体中随机生成。相反，DSDP可以预测蛋白质的结合位点并提供准确的搜索空间和初始位置，以进行进一步的构象采样。DSDP的对接任务利用得分函数

    Virtual screening, including molecular docking, plays an essential role in drug discovery. Many traditional and machine-learning based methods are available to fulfil the docking task. The traditional docking methods are normally extensively time-consuming, and their performance in blind docking remains to be improved. Although the runtime of docking based on machine learning is significantly decreased, their accuracy is still limited. In this study, we take the advantage of both traditional and machine-learning based methods, and present a method Deep Site and Docking Pose (DSDP) to improve the performance of blind docking. For the traditional blind docking, the entire protein is covered by a cube, and the initial positions of ligands are randomly generated in the cube. In contract, DSDP can predict the binding site of proteins and provide an accurate searching space and initial positions for the further conformational sampling. The docking task of DSDP makes use of the score function
    
[^35]: 短篇论文: 基础调整: 趋势预测警报和调整基础速率以预防高血糖

    Short: Basal-Adjust: Trend Prediction Alerts and Adjusted Basal Rates for Hyperglycemia Prevention. (arXiv:2303.09913v1 [cs.LG])

    [http://arxiv.org/abs/2303.09913](http://arxiv.org/abs/2303.09913)

    该论文提出了一种机器学习方法，能够预测血糖情况及其分类，输出预警消息以让病人更早进行治疗。在预测反弹性高血糖方面表现出较高的预测精准度和准确度，为预防高血糖提供了初步建议。

    

    在糖尿病治疗方面，最先进的人工胰腺系统（APS）的发展取得了重大进展。然而，尚存在于处理不安全血糖（BG）水平时效性不足的问题，特别是在反弹性高血糖的情况下。我们提出了一种机器学习（ML）方法，用于预测BG情境分类，产生预警信息以让病人更早、更直观地进行治疗。除了标准的低血糖和高血糖预测通知外，我们还介绍了针对BG情境的特定警报信息以及预防反弹性高血糖的精确基础建议的初步措施。在DCLP3临床数据集上的实验评估实现了对于病人警报的反弹性高事件的预测精度> 98％和精度> 79％。

    Significant advancements in type 1 diabetes treatment have been made in the development of state-of-the-art Artificial Pancreas Systems (APS). However, lapses currently exist in the timely treatment of unsafe blood glucose (BG) levels, especially in the case of rebound hyperglycemia. We propose a machine learning (ML) method for predictive BG scenario categorization that outputs messages alerting the patient to upcoming BG trends to allow for earlier, educated treatment. In addition to standard notifications of predicted hypoglycemia and hyperglycemia, we introduce BG scenario-specific alert messages and the preliminary steps toward precise basal suggestions for the prevention of rebound hyperglycemia. Experimental evaluation on the DCLP3 clinical dataset achieves >98% accuracy and >79% precision for predicting rebound high events for patient alerts.
    
[^36]: 基于分段曲率的降维评估框架研究

    An evaluation framework for dimensionality reduction through sectional curvature. (arXiv:2303.09909v1 [cs.LG])

    [http://arxiv.org/abs/2303.09909](http://arxiv.org/abs/2303.09909)

    本文提出了基于分段曲率的高度非平凡维度规约性能评估指标，并利用此指标来评估最先进的维度规约算法的性能

    

    无监督机器学习在定义上缺乏基准，这给评估此类算法的性能设计指标带来了重大困难。与监督学习形成鲜明对比的是，监督学习的质量指标在文献中得到了广泛的研究，而在降维领域中，只提出了一些过于简化的指标。本文旨在介绍一种极其非平凡的降维性能评估指标，该指标基于来自黎曼几何的分段曲率行为。为了测试其可行性，该指标已被用于评估最先进的降维算法的性能。此外，为了使算法评估具有鲁棒性和代表性，利用平面曲线的曲率特性，构造了一种新的参数化问题实例生成器形式的函数生成器。实验结果是一致的。

    Unsupervised machine learning lacks ground truth by definition. This poses a major difficulty when designing metrics to evaluate the performance of such algorithms. In sharp contrast with supervised learning, for which plenty of quality metrics have been studied in the literature, in the field of dimensionality reduction only a few over-simplistic metrics has been proposed. In this work, we aim to introduce the first highly non-trivial dimensionality reduction performance metric. This metric is based on the sectional curvature behaviour arising from Riemannian geometry. To test its feasibility, this metric has been used to evaluate the performance of the most commonly used dimension reduction algorithms in the state of the art. Furthermore, to make the evaluation of the algorithms robust and representative, using curvature properties of planar curves, a new parameterized problem instance generator has been constructed in the form of a function generator. Experimental results are consis
    
[^37]: 用神经随机建模探索集体运动的介观描述

    Discovering mesoscopic descriptions of collective movement with neural stochastic modelling. (arXiv:2303.09906v1 [cs.LG])

    [http://arxiv.org/abs/2303.09906](http://arxiv.org/abs/2303.09906)

    介观集体运动的随机特征对确定性和随机性动力学建模至关重要。作者利用物理启发、神经网络和随机微分方程来研究相互作用个体的群体动力学，并对其进行了鉴定和分析，为这些系统的秩序性质提供了新颖的见解。

    

    集体运动是自然界中普遍存在的现象，启发工程师、物理学家和数学家开发数学模型和生物启发设计。小至中等群体规模（约10-1000个个体，也称“介观尺度”的集体运动，由于随机性而显示出非平凡的特征。因此，在介观尺度集体现象的研究中，表征确定性和随机动力学方面的特征是至关重要的。我们基于物理启发，采用基于神经网络的方法来表征相互作用个体的随机群体动力学，通过控制群体的随机微分方程（SDE）来研究这些系统的群体动力学。我们在合成和真实数据集上应用这种技术，利用漂移和扩散场鉴定系统的确定性和随机性方面的动力学，从而使我们能够针对这些系统的秩序性质做出新颖的推断。

    Collective motion is an ubiquitous phenomenon in nature, inspiring engineers, physicists and mathematicians to develop mathematical models and bio-inspired designs. Collective motion at small to medium group sizes ($\sim$10-1000 individuals, also called the `mesoscale'), can show nontrivial features due to stochasticity. Therefore, characterizing both the deterministic and stochastic aspects of the dynamics is crucial in the study of mesoscale collective phenomena. Here, we use a physics-inspired, neural-network based approach to characterize the stochastic group dynamics of interacting individuals, through a stochastic differential equation (SDE) that governs the collective dynamics of the group. We apply this technique on both synthetic and real-world datasets, and identify the deterministic and stochastic aspects of the dynamics using drift and diffusion fields, enabling us to make novel inferences about the nature of order in these systems.
    
[^38]: SemEval-2023任务3上的mCPT：用于零样本和少样本框架检测的多语言标签感知对比预训练变压器

    mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection. (arXiv:2303.09901v1 [cs.CL])

    [http://arxiv.org/abs/2303.09901](http://arxiv.org/abs/2303.09901)

    本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。

    

    本文介绍了零样本的西班牙语框架检测任务的获胜系统，并在另外八种语言中取得了良好的成绩。框架检测任务的挑战在于在只有少量或零个样本的情况下识别一组14个框架，即多语言多标签的少样本和零样本设置。我们开发的解决方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。除了描述系统外，我们还进行了嵌入空间分析和消融研究，以展示我们的预训练程序如何支持框架检测以推进计算框架分析。

    This paper presents the winning system for the zero-shot Spanish framing detection task, which also achieves competitive places in eight additional languages. The challenge of the framing detection task lies in identifying a set of 14 frames when only a few or zero samples are available, i.e., a multilingual multi-label few- or zero-shot setting. Our developed solution employs a pre-training procedure based on multilingual Transformers using a label-aware contrastive loss function. In addition to describing the system, we perform an embedding space analysis and ablation study to demonstrate how our pre-training procedure supports framing detection to advance computational framing analysis.
    
[^39]: 关于深度多视角聚类中自监督学习和对比对齐的影响

    On the Effects of Self-supervision and Contrastive Alignment in Deep Multi-view Clustering. (arXiv:2303.09877v1 [stat.ML])

    [http://arxiv.org/abs/2303.09877](http://arxiv.org/abs/2303.09877)

    本论文提出了统一的框架DeepMVC，用于深度多视角聚类，并对其进行了关键观察，发现使用对比学习来对齐表示会对聚类可分性产生负面影响，特别是在视角数量较多时。同时，为了克服这种缺陷，我们开发了一些新的基于自监督方法的DeepMVC实例。

    

    自监督学习是近年来深度多视角聚类方法中的核心组成部分。然而，我们发现基于自监督学习的深度多视角聚类方法在发展方面存在巨大差异，这可能会拖慢该领域的进展。为了解决这一问题，我们提出了一个统一的框架DeepMVC，用于深度多视角聚类，其中包括许多最近的方法。我们利用我们的框架对自监督学习的影响进行关键观察，特别是对使用对比学习来对齐表示的缺点的观察。此外，我们证明了对比对齐可能会对聚类可分性产生负面影响，并且当视角的数量增加时，这种影响会变得更加严重。受到我们的发现的启示，我们开发了几种新的DeepMVC实例，具有新形式的自监督学习。我们进行了广泛的实验，并发现（i）与我们的理论发现一致，对比对齐会降低具有许多视角的数据集的性能；（ii）所有方法都受益于一定程度的自监督学习。

    Self-supervised learning is a central component in recent approaches to deep multi-view clustering (MVC). However, we find large variations in the development of self-supervision-based methods for deep MVC, potentially slowing the progress of the field. To address this, we present DeepMVC, a unified framework for deep MVC that includes many recent methods as instances. We leverage our framework to make key observations about the effect of self-supervision, and in particular, drawbacks of aligning representations with contrastive learning. Further, we prove that contrastive alignment can negatively influence cluster separability, and that this effect becomes worse when the number of views increases. Motivated by our findings, we develop several new DeepMVC instances with new forms of self-supervision. We conduct extensive experiments and find that (i) in line with our theoretical findings, contrastive alignments decreases performance on datasets with many views; (ii) all methods benefit
    
[^40]: 图像统计与人类感知之间的关联关系分离

    Disentangling the Link Between Image Statistics and Human Perception. (arXiv:2303.09874v1 [cs.CV])

    [http://arxiv.org/abs/2303.09874](http://arxiv.org/abs/2303.09874)

    本研究直接评估自然图像的概率，并分析它如何影响人类感知。通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性，论文提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。

    

    在20世纪50年代，霍勒斯巴洛和弗雷德阿特纳夫提出了感官系统和它们如何适应环境之间的关系：早期视觉的进化是为了最大限度地传递关于输入信号的信息。按照香农的定义，这些信息是通过自然场景中拍摄的图像的概率来描述的。由于计算能力的限制，以前无法直接准确地预测图像的概率。尽管这种想法的探索是间接的，主要基于图像密度的过度简化模型或系统设计方法，但这些方法在重现各种生理和心理物理现象方面取得了成功。在本文中，我们直接评估自然图像的概率，并分析它如何确定知觉灵敏度。我们使用与人类意见相关性很高的图像质量指标作为人类视觉的代理，以及一个先进的生成模型来直接估计自然图像的概率密度函数。我们的结果表明，根据Barlow和Attneave理论预测的图像统计与人类知觉之间存在系统性的关联。我们通过展示具有更丰富统计特征的自然图像被感知为具有更大的显着性来说明这一发现，这是通过视觉搜索实验测量的。我们的工作提供了直接支持Barlow和Attneave理论的证据，并建立了一个新的框架，用于理解图像统计与知觉之间的关系。

    In the 1950s Horace Barlow and Fred Attneave suggested a connection between sensory systems and how they are adapted to the environment: early vision evolved to maximise the information it conveys about incoming signals. Following Shannon's definition, this information was described using the probability of the images taken from natural scenes. Previously, direct accurate predictions of image probabilities were not possible due to computational limitations. Despite the exploration of this idea being indirect, mainly based on oversimplified models of the image density or on system design methods, these methods had success in reproducing a wide range of physiological and psychophysical phenomena. In this paper, we directly evaluate the probability of natural images and analyse how it may determine perceptual sensitivity. We employ image quality metrics that correlate well with human opinion as a surrogate of human vision, and an advanced generative model to directly estimate the probabil
    
[^41]: 通过图表自编码器进行内部数据结构的深度非参数估计：广义误差和鲁棒性。

    Deep Nonparametric Estimation of Intrinsic Data Structures by Chart Autoencoders: Generalization Error and Robustness. (arXiv:2303.09863v1 [stat.ML])

    [http://arxiv.org/abs/2303.09863](http://arxiv.org/abs/2303.09863)

    本文介绍了一种图表自编码器用于深度非参数估计内部数据结构，并证明了其广义误差保证和去噪能力。

    

    自编码器在学习高维数据的低维潜在特征方面已经在各种应用中展现出了显着的成功。假设数据在低维流形附近采样，我们采用图表自编码器，将数据编码为一组图表上的低维潜在特征，从而保留了数据流形的拓扑和几何。我们的论文为图表自编码器的广义误差建立了统计保证，并且通过考虑$d$维流形上$n$个带噪声训练样本及其无噪声对应物来展示它们的去噪能力。通过训练自编码器，我们展示了图表自编码器能够有效地去噪输入数据和正态分布噪声。我们证明，在适当的网络架构下，图表自编码器实现了一个大致为$\displaystyle n^{-\frac{2}{d+2}}\log^4 n$阶的平方广义误差，该误差取决于流形的内在维度，并且仅弱依赖于样本数量$n$。

    Autoencoders have demonstrated remarkable success in learning low-dimensional latent features of high-dimensional data across various applications. Assuming that data are sampled near a low-dimensional manifold, we employ chart autoencoders, which encode data into low-dimensional latent features on a collection of charts, preserving the topology and geometry of the data manifold. Our paper establishes statistical guarantees on the generalization error of chart autoencoders, and we demonstrate their denoising capabilities by considering $n$ noisy training samples, along with their noise-free counterparts, on a $d$-dimensional manifold. By training autoencoders, we show that chart autoencoders can effectively denoise the input data with normal noise. We prove that, under proper network architectures, chart autoencoders achieve a squared generalization error in the order of $\displaystyle n^{-\frac{2}{d+2}}\log^4 n$, which depends on the intrinsic dimension of the manifold and only weakly
    
[^42]: 图像到视频转换的双路径自适应

    Dual-path Adaptation from Image to Video Transformers. (arXiv:2303.09857v1 [cs.CV])

    [http://arxiv.org/abs/2303.09857](http://arxiv.org/abs/2303.09857)

    本文提出了一种新的双路径自适应方法，在视频理解中充分利用图像变形器的能力，特别是对于时间动态建模，提出了一个精确模仿视觉变换器的能力的方法。

    

    本文提出了一种高效地将视觉基础模型（如ViT和Swin）的优越表示能力转移到视频理解中的方法，仅使用少量可训练参数。我们认为，在以前的自适应方法中，同时考虑空间和时间建模，采用一个可学习的统一模块，但仍然无法充分利用图像变形器的代表性能力。我们认为，在视频模型中广泛采用的双路径（两个流）架构可以缓解这个问题。我们提出了一种新的双路径自适应，分为空间和时间自适应路径，并在每个变形器块中采用轻量级瓶颈适配器。特别是对于时间动态建模，我们将连续的帧组合成类似于网格的帧集，并精确模仿视觉变换器的能力，即推断令牌之间的关系。此外，我们从统一的视角广泛地研究了多个基线在视频理解中的应用。

    In this paper, we efficiently transfer the surpassing representation power of the vision foundation models, such as ViT and Swin, for video understanding with only a few trainable parameters. Previous adaptation methods have simultaneously considered spatial and temporal modeling with a unified learnable module but still suffered from fully leveraging the representative capabilities of image transformers. We argue that the popular dual-path (two-stream) architecture in video models can mitigate this problem. We propose a novel DualPath adaptation separated into spatial and temporal adaptation paths, where a lightweight bottleneck adapter is employed in each transformer block. Especially for temporal dynamic modeling, we incorporate consecutive frames into a grid-like frameset to precisely imitate vision transformers' capability that extrapolates relationships between tokens. In addition, we extensively investigate the multiple baselines from a unified perspective in video understanding
    
[^43]: GADFormer:一种基于注意力机制的轨迹群体异常检测模型

    GADFormer: An Attention-based Model for Group Anomaly Detection on Trajectories. (arXiv:2303.09841v1 [cs.LG])

    [http://arxiv.org/abs/2303.09841](http://arxiv.org/abs/2303.09841)

    本文提出了一种基于BERT模型的GADFormer模型，能够在轨迹上执行基于注意力的群体异常检测，相比其他深度序列模型，GADFormer表现更优，在多个公开数据集上实验表明GADFormer在检测异常群体方面取得了显著的提高。

    

    群体异常检测(GAD)可以揭示由多个成员实例组成的群体中异常行为，然而随着群体成员数量和异构性的增加，实际上的异常群体变得越来越难以检测，尤其是在无监督或半监督设定下。因此，本文提出了一种基于BERT体系结构的GAD专用模型GADFormer，它能够在轨迹上执行基于注意力的群体异常检测,并在公开数据集上展示了其在检测高精度率下的显著改进。

    Group Anomaly Detection (GAD) reveals anomalous behavior among groups consisting of multiple member instances, which are, individually considered, not necessarily anomalous. This task is of major importance across multiple disciplines, in which also sequences like trajectories can be considered as a group. However, with increasing amount and heterogenity of group members, actual abnormal groups get harder to detect, especially in an unsupervised or semi-supervised setting. Recurrent Neural Networks are well established deep sequence models, but recent works have shown that their performance can decrease with increasing sequence lengths. Hence, we introduce with this paper GADFormer, a GAD specific BERT architecture, capable to perform attention-based Group Anomaly Detection on trajectories in an unsupervised and semi-supervised setting. We show formally and experimentally how trajectory outlier detection can be realized as an attention-based Group Anomaly Detection problem. Furthermore
    
[^44]: Transformers和Ensemble方法：阿语恶意言论检测的一种解决方案

    Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages. (arXiv:2303.09823v1 [cs.CL])

    [http://arxiv.org/abs/2303.09823](http://arxiv.org/abs/2303.09823)

    本文提出了一种使用Transformer和Ensemble方法的解决方案，用于阿语恶意言论的检测。实验结果表明，基于多数表决的集成方法具有最佳效果，其在测试集上的准确率为0.86，F1分数为0.60。

    

    本文描述了我们参加CERIST NLP挑战赛2022中恶意言论检测共享任务的实验过程。我们评估了6个Transformer模型及其组合的性能，并使用了2种集成方法。在五折交叉验证的训练集上，基于多数表决的集成方法获得了最佳结果。在测试集上的评估结果为F1分数为0.60，准确性为0.86。

    This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.
    
[^45]: Mpox-AISM：基于人工智能的超级监测以遏制猴痘传播

    Mpox-AISM: AI-Mediated Super Monitoring for Forestalling Monkeypox Spread. (arXiv:2303.09780v1 [eess.IV])

    [http://arxiv.org/abs/2303.09780](http://arxiv.org/abs/2303.09780)

    本文介绍了一种名为超级监测的远程实现猴痘早期诊断的策略。该策略以人工智能技术为基础，可实现高灵敏度和准确性的病症分类，同时成本低、易用性高，具有广泛的应用前景。

    

    针对及时、便捷和准确诊断早期患者是遏制猴痘传播的挑战。我们提出了一种远程、实时的在线可视化策略，称为“超级监测”，用于构建低成本、方便、及时和无专业知识的猴痘早期诊断。通过深度学习、数据增强和自监督学习组装的框架，我们提出了一种基于人工智能介导的“超级监测”（Mpox-AISM），根据数据集特征和猴痘演变趋势以及与高相似度的其他七种皮肤病的专业分类，因此这些功能与合理的程序界面和阈值设置确保了其灵敏度超过95.9％，特异度几乎达到100％。因此，在互联网和通讯终端的云服务的帮助下，这种策略可以潜在地用于实时检测猴痘的早期阶段。

    The challenge on forestalling monkeypox (Mpox) spread is the timely, convenient and accurate diagnosis for earlystage infected individuals. Here, we propose a remote and realtime online visualization strategy, called "Super Monitoring" to construct a low cost, convenient, timely and unspecialized diagnosis of early-stage Mpox. Such AI-mediated "Super Monitoring" (Mpox-AISM) invokes a framework assembled by deep learning, data augmentation and self-supervised learning, as well as professionally classifies four subtypes according to dataset characteristics and evolution trend of Mpox and seven other types of dermatopathya with high similarity, hence these features together with reasonable program interface and threshold setting ensure that its Recall (Sensitivity) was beyond 95.9% and the specificity was almost 100%. As a result, with the help of cloud service on Internet and communication terminal, this strategy can be potentially utilized for the real-time detection of earlystage Mpox 
    
[^46]: SE-GSL：一种通过结构熵优化实现通用有效图结构学习的框架。

    SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization. (arXiv:2303.09778v1 [cs.LG])

    [http://arxiv.org/abs/2303.09778](http://arxiv.org/abs/2303.09778)

    本论文提出了一个通用且有效的图结构学习框架SE-GSL，通过利用结构熵和编码树中的层次结构来最大化嵌入信息内容，同时提出了一个声慢构建最优编码树的方案。该框架还提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。

    

    图神经网络是学习结构化数据的实际解决方案。 然而，它容易受到低质量和不可靠结构的影响，这在真实世界的图中是常态而不是例外。现有的图结构学习框架仍然缺乏鲁棒性和可解释性。本文通过结构熵和编码树中抽象的图层次结构提出了一种通用的GSL框架SE-GSL。特别地，我们利用一维结构熵来最大化嵌入信息内容，当辅助邻域属性被融合以增强原始图时。提出了一种构建最优编码树的新方案，以在分层抽象中最小化图中的不确定性和噪音，同时确保适当的社区划分。我们提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。它增加了更大不确定性的节点之间的连通性。

    Graph Neural Networks (GNNs) are de facto solutions to structural data learning. However, it is susceptible to low-quality and unreliable structure, which has been a norm rather than an exception in real-world graphs. Existing graph structure learning (GSL) frameworks still lack robustness and interpretability. This paper proposes a general GSL framework, SE-GSL, through structural entropy and the graph hierarchy abstracted in the encoding tree. Particularly, we exploit the one-dimensional structural entropy to maximize embedded information content when auxiliary neighbourhood attributes are fused to enhance the original graph. A new scheme of constructing optimal encoding trees is proposed to minimize the uncertainty and noises in the graph whilst assuring proper community partition in hierarchical abstraction. We present a novel sample-based mechanism for restoring the graph structure via node structural entropy distribution. It increases the connectivity among nodes with larger unce
    
[^47]: QUBO决策树：退火机器扩展决策树分裂

    QUBO Decision Tree: Annealing Machine Extends Decision Tree Splitting. (arXiv:2303.09772v1 [cs.LG])

    [http://arxiv.org/abs/2303.09772](http://arxiv.org/abs/2303.09772)

    本论文提出了一种扩展回归树的方法，通过将训练过程转化为QUBO，将决策树的决策规则扩展到多维边界，进而提高了决策树的准确度。使用退火机器解决这一扩展通常的计算限制。

    

    本论文提出了一种通过二次无约束二值优化（QUBO）扩展回归树的方法。回归树是非常流行的预测模型，可用于训练表格数据集，但其准确度不足，因为决策规则过于简单。该方法通过QUBO转换训练过程，将决策树的决策规则扩展到多维边界。这种扩展通常由于计算限制而无法实现，然而，所提出的方法使退火机器能够解决这个问题。

    This paper proposes an extension of regression trees by quadratic unconstrained binary optimization (QUBO). Regression trees are very popular prediction models that are trainable with tabular datasets, but their accuracy is insufficient because the decision rules are too simple. The proposed method extends the decision rules in decision trees to multi-dimensional boundaries. Such an extension is generally unimplementable because of computational limitations, however, the proposed method transforms the training process to QUBO, which enables an annealing machine to solve this problem.
    
[^48]: 去噪扩散自编码器是统一自监督学习器

    Denoising Diffusion Autoencoders are Unified Self-supervised Learners. (arXiv:2303.09769v1 [cs.CV])

    [http://arxiv.org/abs/2303.09769](http://arxiv.org/abs/2303.09769)

    本文研究了去噪扩散自编码器 (DDAE) 是否能通过无条件图像生成训练获取强有力的线性可分表示，结果表明DDAE是一个统一的自监督学习器，对于自监督生成和辨别性学习是通用的方法。在多类数据集上实现了95.9％和50.0％的线性探测精度，与掩码自编码器和对比学习相当。

    

    受扩散模型最近的进展的启发，这些模型类似于去噪自编码器，我们研究它们是否可以通过生成预训练获取分类的辨别性表示。本文展示了扩散模型中的网络，即去噪扩散自编码器(DDAE)是统一的自监督学习器:通过在无条件图像生成上进行预训练，DDAE已经在中间层学习到了强有力的线性可分表示，而无需辅助编码器，从而使扩散预训练成为自监督生成和辨别性学习的通用方法。为了验证这一点，我们在多类数据集上执行线性探测和微调评估。我们基于扩散的方法，在CIFAR-10和Tiny-ImageNet上分别实现了95.9％和50.0％的线性探测精度，与掩码自编码器和对比学习首次可比较。此外，从Image上的转移学习

    Inspired by recent advances in diffusion models, which are reminiscent of denoising autoencoders, we investigate whether they can acquire discriminative representations for classification via generative pre-training. This paper shows that the networks in diffusion models, namely denoising diffusion autoencoders (DDAE), are unified self-supervised learners: by pre-training on unconditional image generation, DDAE has already learned strongly linear-separable representations at its intermediate layers without auxiliary encoders, thus making diffusion pre-training emerge as a general approach for self-supervised generative and discriminative learning. To verify this, we perform linear probe and fine-tuning evaluations on multi-class datasets. Our diffusion-based approach achieves 95.9% and 50.0% linear probe accuracies on CIFAR-10 and Tiny-ImageNet, respectively, and is comparable to masked autoencoders and contrastive learning for the first time. Additionally, transfer learning from Image
    
[^49]: 关于数据的一切：对数据对抗鲁棒性影响的研究综述

    It Is All About Data: A Survey on the Effects of Data on Adversarial Robustness. (arXiv:2303.09767v1 [cs.LG])

    [http://arxiv.org/abs/2303.09767](http://arxiv.org/abs/2303.09767)

    本文综述了有关数据对抗鲁棒性的研究，系统地总结了最新研究成果，并进一步讨论了未来研究方向和知识差距。

    

    对抗性样本是攻击者有意设计用于混淆机器学习模型以便其犯错的输入。这些样本对基于机器学习的系统的适用性，特别是在涉及生命和安全的领域，构成了严重威胁。为了解决这个问题，对抗鲁棒性领域研究对抗攻击机制和防御策略。本综述回顾了有关模型使用的数据对其抗攻击鲁棒性影响的文献。它系统地识别和总结了这个领域内的最新研究，并进一步讨论了知识的差距和有前途的未来研究方向。

    Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to confuse the model into making a mistake. Such examples pose a serious threat to the applicability of machine-learning-based systems, especially in life- and safety-critical domains. To address this problem, the area of adversarial robustness investigates mechanisms behind adversarial attacks and defenses against these attacks. This survey reviews literature that focuses on the effects of data used by a model on the model's adversarial robustness. It systematically identifies and summarizes the state-of-the-art research in this area and further discusses gaps of knowledge and promising future research directions.
    
[^50]: 扩散最优拓扑结构：一种生成式优化方法

    Diffusing the Optimal Topology: A Generative Optimization Approach. (arXiv:2303.09760v1 [cs.LG])

    [http://arxiv.org/abs/2303.09760](http://arxiv.org/abs/2303.09760)

    该论文提出了一种新的生成式优化方法，将SIMP等经典优化算法作为精制机制整合到深度生成模型生成的拓扑结构中。该方法在基准问题上展现出较传统拓扑优化和其他学习模型更优的性能。

    

    拓扑优化旨在寻找在满足一系列约束条件的同时最大化系统性能的最佳设计。传统的迭代优化方法如SIMP可能计算成本高且陷入局部最小值，限制了它们在复杂或大规模问题中的适用性。已经开发了基于学习的方法来加速拓扑优化过程，但是当面临超出分布约束配置时，这些方法可能会生成具有浮动材料和低性能的设计。最近，基于条件约束和物理场的深度生成模型，如生成对抗网络和扩散模型，显示出很好的效果，但它们需要广泛的预处理和代理模型来改善性能。为解决这些问题，我们提出了一种生成式优化方法，将像SIMP这样的经典优化作为拓扑结构的精制机制整合到深度生成模型生成的拓扑结构中。我们还将在基准问题上展示其与传统拓扑优化方法和其他基于学习的模型相比的优良性能。

    Topology Optimization seeks to find the best design that satisfies a set of constraints while maximizing system performance. Traditional iterative optimization methods like SIMP can be computationally expensive and get stuck in local minima, limiting their applicability to complex or large-scale problems. Learning-based approaches have been developed to accelerate the topology optimization process, but these methods can generate designs with floating material and low performance when challenged with out-of-distribution constraint configurations. Recently, deep generative models, such as Generative Adversarial Networks and Diffusion Models, conditioned on constraints and physics fields have shown promise, but they require extensive pre-processing and surrogate models for improving performance. To address these issues, we propose a Generative Optimization method that integrates classic optimization like SIMP as a refining mechanism for the topology generated by a deep generative model. W
    
[^51]: CoLT5: 基于条件计算的快速长距离Transformer模型

    CoLT5: Faster Long-Range Transformers with Conditional Computation. (arXiv:2303.09752v1 [cs.CL])

    [http://arxiv.org/abs/2303.09752](http://arxiv.org/abs/2303.09752)

    CoLT5是一种基于条件计算的Transformer模型，通过优先处理重要标记来加速长距离输入的处理。CoLT5在SCROLLS基准测试上表现最好，并能够有效地处理长达64k输入长度。

    

    许多自然语言处理任务需要处理长输入，但使用Transformer处理长文档很昂贵——这不仅是因为二次注意复杂性，还因为对每个标记应用前馈和投影层。然而，不是所有标记都同样重要，特别是对于较长的文档。我们提出了CoLT5，一种长输入Transformer模型，通过使用条件计算来利用此直觉，在前馈和注意层中为重要标记提供更多资源。我们展示了CoLT5比LongT5表现更强，训练和推理速度更快，在长输入SCROLLS基准测试上达到了SOTA。此外，CoLT5能够有效且可控地利用极长的输入，展示了高达64k输入长度的强大增益。

    Many natural language processing tasks benefit from long inputs, but processing long documents with Transformers is expensive -- not only due to quadratic attention complexity but also from applying feedforward and projection layers to every token. However, not all tokens are equally important, especially for longer documents. We propose CoLT5, a long-input Transformer model that builds on this intuition by employing conditional computation, devoting more resources to important tokens in both feedforward and attention layers. We show that CoLT5 achieves stronger performance than LongT5 with much faster training and inference, achieving SOTA on the long-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably make use of extremely long inputs, showing strong gains up to 64k input length.
    
[^52]: 基于类条件印象再现的异常检测方法

    Detecting Out-of-distribution Examples via Class-conditional Impressions Reappearing. (arXiv:2303.09746v1 [cs.LG])

    [http://arxiv.org/abs/2303.09746](http://arxiv.org/abs/2303.09746)

    本文提出了一种数据无关的异常检测方法，称为C2IR，它利用来自固定模型的图像印象来恢复类条件的特征统计信息。实验证明了该方法的有效性并达到了与全数据访问的检测方法相当的性能。

    

    异常检测旨在提高标准深度神经网络（DNN）的性能，以从原始训练数据中区分异常输入。以往的方法需要在分布内和分布外的数据上进行训练，但是在实际场景中，由于隐私和安全性问题，辅助数据往往不切实际。本文提出了一种不需要自然数据训练的数据无关方法，称为类条件印象再现（C2IR），它利用来自固定模型的图像印象来恢复类条件的特征统计信息。基于此，我们引入积分概率度量，估计层级别的类条件偏差，并通过测量基于梯度的重要性（MGI）获取层权重。实验证明了我们方法的有效性，并表明C2IR优于其他后续方法，并达到了与全访问（ID和OOD）检测方法相当的性能。

    Out-of-distribution (OOD) detection aims at enhancing standard deep neural networks to distinguish anomalous inputs from original training data. Previous progress has introduced various approaches where the in-distribution training data and even several OOD examples are prerequisites. However, due to privacy and security, auxiliary data tends to be impractical in a real-world scenario. In this paper, we propose a data-free method without training on natural data, called Class-Conditional Impressions Reappearing (C2IR), which utilizes image impressions from the fixed model to recover class-conditional feature statistics. Based on that, we introduce Integral Probability Metrics to estimate layer-wise class-conditional deviations and obtain layer weights by Measuring Gradient-based Importance (MGI). The experiments verify the effectiveness of our method and indicate that C2IR outperforms other post-hoc methods and reaches comparable performance to the full access (ID and OOD) detection me
    
[^53]: 零和马尔可夫博弈中强化学习的新政策迭代算法

    A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games. (arXiv:2303.09716v1 [cs.LG])

    [http://arxiv.org/abs/2303.09716](http://arxiv.org/abs/2303.09716)

    本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。

    

    许多基于模型的强化学习算法可以被视为具有两个阶段: 学习阶段和规划阶段。在标准MDPs情况下，可以使用价值迭代或策略迭代来解决学习问题。但在零和马尔可夫博弈的情况下，没有有效的策略迭代算法，以前的尝试都有局限性。本文提出了一种简单的策略迭代变体，能够有效地解决这个问题。

    Many model-based reinforcement learning (RL) algorithms can be viewed as having two phases that are iteratively implemented: a learning phase where the model is approximately learned and a planning phase where the learned model is used to derive a policy. In the case of standard MDPs, the learning problem can be solved using either value iteration or policy iteration. However, in the case of zero-sum Markov games, there is no efficient policy iteration algorithm; e.g., it has been shown in Hansen et al. (2013) that one has to solve Omega(1/(1-alpha)) MDPs, where alpha is the discount factor, to implement the only known convergent version of policy iteration. Another algorithm for Markov zero-sum games, called naive policy iteration, is easy to implement but is only provably convergent under very restrictive assumptions. Prior attempts to fix naive policy iteration algorithm have several limitations. Here, we show that a simple variant of naive policy iteration for games converges, and 
    
[^54]: 在元树上批量更新后验树分布。

    Batch Updating of a Posterior Tree Distribution over a Meta-Tree. (arXiv:2303.09705v1 [cs.LG])

    [http://arxiv.org/abs/2303.09705](http://arxiv.org/abs/2303.09705)

    本文提出了一个更高效的批量更新方法，用于在元树上计算后验分布。

    

    以前，我们提出了一个由不可观察的树和一个序列更新方法表示的概率数据生成模型，用于计算一组树上的后验分布。该集合称为元树。在本文中，我们提出了一种更高效的批量更新方法。

    Previously, we proposed a probabilistic data generation model represented by an unobservable tree and a sequential updating method to calculate a posterior distribution over a set of trees. The set is called a meta-tree. In this paper, we propose a more efficient batch updating method.
    
[^55]: 一种用于异常检测的双向LSTM自编码器框架——以风能数据集为案例研究

    A Bi-LSTM Autoencoder Framework for Anomaly Detection -- A Case Study of a Wind Power Dataset. (arXiv:2303.09703v1 [cs.LG])

    [http://arxiv.org/abs/2303.09703](http://arxiv.org/abs/2303.09703)

    本文提出了一种双向LSTM自编码器框架用于发现时间序列数据中的异常，可以从两个方向发现隐藏的长期依赖关系。

    

    异常指偏离正常和均一事件的数据点或事件，包括欺诈活动、网络渗透、设备故障、工艺变化或其他重要但不频繁发生的事件。及时发现此类事件可以避免潜在的财务、信息和人力资源损失。随着计算能力的提高和大规模数据集的可用性，异常检测已成为一个重要的研究领域。其中，时间序列的异常检测由于时间维度带来的额外复杂性而最近受到更多关注。本研究提出了一种新的时间序列异常检测框架，利用双向长短时记忆(Bi-LSTM)结构和自编码器的组合。Bi-LSTM网络由两个单向LSTM网络组成，可以从两个方向分析时间序列数据，从而有效地发现隐藏的长期依赖关系。

    Anomalies refer to data points or events that deviate from normal and homogeneous events, which can include fraudulent activities, network infiltrations, equipment malfunctions, process changes, or other significant but infrequent events. Prompt detection of such events can prevent potential losses in terms of finances, information, and human resources. With the advancement of computational capabilities and the availability of large datasets, anomaly detection has become a major area of research. Among these, anomaly detection in time series has gained more attention recently due to the added complexity imposed by the time dimension. This study presents a novel framework for time series anomaly detection using a combination of Bidirectional Long Short Term Memory (Bi-LSTM) architecture and Autoencoder. The Bi-LSTM network, which comprises two unidirectional LSTM networks, can analyze the time series data from both directions and thus effectively discover the long-term dependencies hidd
    
[^56]: 推荐链接的延时和间接影响

    Delayed and Indirect Impacts of Link Recommendations. (arXiv:2303.09700v1 [cs.SI])

    [http://arxiv.org/abs/2303.09700](http://arxiv.org/abs/2303.09700)

    本研究研究了链接推荐在动态环境中对社交网络演化的影响，并发现推荐链接有令人惊讶的延迟和间接影响。

    

    推荐链接对社交网络的影响很难评估，迄今为止研究受限于有限的环境。观察性研究受限于它们所能回答的因果问题的种类，天真的 A/B 测试常常会由于未考虑到的网络干扰而导致偏见评估。此外，模拟环境中的评估经常局限于静态网络模型，不考虑链接推荐和有机网络演化之间的潜在反馈。为此，我们在动态环境中研究了推荐对社交网络的影响。采用模拟方法，考虑一个显式的动态形成模型——著名的Jackson-Rogers模型的扩展——并研究链接推荐如何随时间影响网络演化。实证上，我们发现链接推荐对网络结构属性有令人惊讶的延迟和间接影响。

    The impacts of link recommendations on social networks are challenging to evaluate, and so far they have been studied in limited settings. Observational studies are restricted in the kinds of causal questions they can answer and naive A/B tests often lead to biased evaluations due to unaccounted network interference. Furthermore, evaluations in simulation settings are often limited to static network models that do not take into account the potential feedback loops between link recommendation and organic network evolution. To this end, we study the impacts of recommendations on social networks in dynamic settings. Adopting a simulation-based approach, we consider an explicit dynamic formation model -- an extension of the celebrated Jackson-Rogers model -- and investigate how link recommendations affect network evolution over time. Empirically, we find that link recommendations have surprising delayed and indirect effects on the structural properties of networks. Specifically, we find th
    
[^57]: 利用深度学习预测离散时间分歧

    Predicting discrete-time bifurcations with deep learning. (arXiv:2303.09669v1 [q-bio.QM])

    [http://arxiv.org/abs/2303.09669](http://arxiv.org/abs/2303.09669)

    本研究利用深度学习训练分类器预测离散时间五种本地分岔，在经济、生态、生理学等方面的试验数据中都具有优秀表现，是提前警告关键转变的重要方法。

    

    许多自然和人造系统容易发生关键转变-动力学的突然和潜在的破坏性变化。深度学习分类器通过从大规模模拟训练数据集中学习分岔（动力学不稳定性）的通用特征，为关键转变提供提前警告信号（EWS）。到目前为止，分类器只被训练用于预测连续时间分歧，而忽略了离散时间分歧独特的丰富动态特征。本文使用深度学习分类器训练提供 EWS 的五种离散时间、共维度1的本地分岔。我们在生理学、经济学和生态学中使用的离散时间模型的模拟数据以及经历了倍增分岔的鸡心聚集的实验数据进行测试。在广泛的噪声强度和接近分岔的速率范围内，分类器优于常用的 EWS。它也能够正确预测分岔。

    Many natural and man-made systems are prone to critical transitions -- abrupt and potentially devastating changes in dynamics. Deep learning classifiers can provide an early warning signal (EWS) for critical transitions by learning generic features of bifurcations (dynamical instabilities) from large simulated training data sets. So far, classifiers have only been trained to predict continuous-time bifurcations, ignoring rich dynamics unique to discrete-time bifurcations. Here, we train a deep learning classifier to provide an EWS for the five local discrete-time bifurcations of codimension-1. We test the classifier on simulation data from discrete-time models used in physiology, economics and ecology, as well as experimental data of spontaneously beating chick-heart aggregates that undergo a period-doubling bifurcation. The classifier outperforms commonly used EWS under a wide range of noise intensities and rates of approach to the bifurcation. It also predicts the correct bifurcation
    
[^58]: 用TribalGram对群体间差异进行关键检查：部落分析的批判性视察

    Tribe or Not? Critical Inspection of Group Differences Using TribalGram. (arXiv:2303.09664v1 [cs.LG])

    [http://arxiv.org/abs/2303.09664](http://arxiv.org/abs/2303.09664)

    本文提出了一组负责任的群体分析设计指南，并通过开发TribalGram工具使用可解释的机器学习算法和可视化来对群体分析进行推断评估、模型解释、数据协作和理解，以增强对分析群体的深刻理解，并防止因刻板印象和过度概括导致的潜在危害。

    

    随着人工智能和数据挖掘技术的兴起，群体分析和群体层面的分析在包括政策制定和直接营销在内的许多领域中得到了越来越广泛的应用。在一些情况下，从数据中提取的统计信息可能为一个群体的共同特征提供见解；而在其他情况下，群体层面的分析可能会导致刻板印象和系统性压迫。分析工具如何促进更加有意识的群体分析过程？在本研究中，我们确定了一组负责任的群体分析设计指南，以阐明群体差异的需要和防止对群体的过度概括。遵循这些设计指南，我们开发了TribalGram，这是一个利用可解释的机器学习算法和可视化来提供推断评估、模型解释、数据协作和理解的视觉分析工具。通过与领域专家的访谈，我们展示了我们的设计和工具如何带来对分析群体的更深入理解，并防止由于刻板印象和过度概括而带来的潜在危害。

    With the rise of AI and data mining techniques, group profiling and group-level analysis have been increasingly used in many domains including policy making and direct marketing. In some cases, the statistics extracted from data may provide insights to a group's shared characteristics; in others, the group-level analysis can lead to problems including stereotyping and systematic oppression. How can analytic tools facilitate a more conscientious process in group analysis? In this work, we identify a set of accountable group analytics design guidelines to explicate the needs for group differentiation and preventing overgeneralization of a group. Following the design guidelines, we develop TribalGram, a visual analytic suite that leverages interpretable machine learning algorithms and visualization to offer inference assessment, model explanation, data corroboration, and sense-making. Through the interviews with domain experts, we showcase how our design and tools can bring a richer under
    
[^59]: 基于多智能体深度强化学习的多模式插电混合动力汽车能量管理

    Energy Management of Multi-mode Plug-in Hybrid Electric Vehicle using Multi-agent Deep Reinforcement Learning. (arXiv:2303.09658v1 [cs.RO])

    [http://arxiv.org/abs/2303.09658](http://arxiv.org/abs/2303.09658)

    本论文提出了一种基于多智能体深度强化学习的多模式插电混合动力汽车能量管理的MIMO控制方法，通过握手策略和多目标函数优化全局控制，实验结果表明其在燃料消耗、SOC变化和功率限制方面优于传统方法。

    

    近年来出现的多模式插电混合动力汽车(PHEV)技术是减少碳排放的途径之一，其能量管理需要多输入多输出(MIMO)控制。目前，现有的方法通常将MIMO控制解耦为单输出(MISO)控制，并且只能实现其局部最优性能。为了全局优化多模式车辆，本文研究了基于多智能体深度强化学习(MADRL)的多模式PHEV能量管理的MIMO控制方法。通过引入相关比例，提出了一种握手策略，使得两个学习智能体能够在MADRL框架下使用深度确定性策略梯度(DDPG)算法进行协作学习。通过对影响学习性能的影响因素进行灵敏度分析，得到了DDPG智能体的统一设置。握手策略的最优工作模式通过多目标函数得到，考虑燃料消耗、电池SOC变化和功率限制违规。基于硬件在环(HIL)仿真器的实验结果表明，所提出的MADRL能量管理方法在燃料消耗、SOC变化和功率限制违规方面优于传统的基于规则的方法和单个智能体RL方法。

    The recently emerging multi-mode plug-in hybrid electric vehicle (PHEV) technology is one of the pathways making contributions to decarbonization, and its energy management requires multiple-input and multiple-output (MIMO) control. At the present, the existing methods usually decouple the MIMO control into single-output (MISO) control and can only achieve its local optimal performance. To optimize the multi-mode vehicle globally, this paper studies a MIMO control method for energy management of the multi-mode PHEV based on multi-agent deep reinforcement learning (MADRL). By introducing a relevance ratio, a hand-shaking strategy is proposed to enable two learning agents to work collaboratively under the MADRL framework using the deep deterministic policy gradient (DDPG) algorithm. Unified settings for the DDPG agents are obtained through a sensitivity analysis of the influencing factors to the learning performance. The optimal working mode for the hand-shaking strategy is attained thro
    
[^60]: ESCAPE：通过交互式视觉分析消除机器的盲区系统误差

    ESCAPE: Countering Systematic Errors from Machine's Blind Spots via Interactive Visual Analysis. (arXiv:2303.09657v1 [cs.LG])

    [http://arxiv.org/abs/2303.09657](http://arxiv.org/abs/2303.09657)

    本论文提出了ESCAPE，一个交互式视觉分析系统，利用人机交互帮助用户发现并修正机器学习中的系统误差。

    

    分类模型学习推广数据和目标类之间的关联。然而，研究人员越来越多地观察到机器学习实践很容易在AI应用程序中导致系统错误，这种现象称为AI盲区。当模型使用训练样本进行训练（例如，猫/狗分类），其中重要模式（例如，黑猫）缺失或周边/不良模式（例如，草地背景的狗）会误导到某个类时，会出现这些盲区。甚至更复杂的技术也不能保证捕获、理解和防止伪关联。在这项工作中，我们提出了一个名为ESCAPE的视觉分析系统，它促进了消除系统误差的人机交互工作流程。通过允许人类用户轻松检查虚假关联，该系统有助于用户自发地识别与错误分类相关的概念并评估缓解策略。

    Classification models learn to generalize the associations between data samples and their target classes. However, researchers have increasingly observed that machine learning practice easily leads to systematic errors in AI applications, a phenomenon referred to as AI blindspots. Such blindspots arise when a model is trained with training samples (e.g., cat/dog classification) where important patterns (e.g., black cats) are missing or periphery/undesirable patterns (e.g., dogs with grass background) are misleading towards a certain class. Even more sophisticated techniques cannot guarantee to capture, reason about, and prevent the spurious associations. In this work, we propose ESCAPE, a visual analytic system that promotes a human-in-the-loop workflow for countering systematic errors. By allowing human users to easily inspect spurious associations, the system facilitates users to spontaneously recognize concepts associated misclassifications and evaluate mitigation strategies that ca
    
[^61]: SUD$^2$:基于去噪扩散模型的图像重建监督方法

    SUD$^2$: Supervision by Denoising Diffusion Models for Image Reconstruction. (arXiv:2303.09642v1 [cs.CV])

    [http://arxiv.org/abs/2303.09642](http://arxiv.org/abs/2303.09642)

    本文提出了一种适用于成对训练数据不足的图像重建网络训练的广义框架，并且在缺少成对训练数据的情况下，使用去噪扩散模型进行网络训练的监督。

    

    许多图像反问题（如图像修复和去雾）都非常具有挑战性，因为它们的前向模型是未知的，或者依赖于未知的潜在参数。虽然我们可以通过使用大量成对的训练数据来训练神经网络来解决这些问题，但这样的成对训练数据通常是不可用的。本文提出了一种广义的框架，用于在成对训练数据不足的情况下训练图像重建网络。特别地，我们展示了图像去噪算法和去噪扩散模型的能力，在缺少成对训练数据的情况下监督网络训练。

    Many imaging inverse problems$\unicode{x2014}$such as image-dependent in-painting and dehazing$\unicode{x2014}$are challenging because their forward models are unknown or depend on unknown latent parameters. While one can solve such problems by training a neural network with vast quantities of paired training data, such paired training data is often unavailable. In this paper, we propose a generalized framework for training image reconstruction networks when paired training data is scarce. In particular, we demonstrate the ability of image denoising algorithms and, by extension, denoising diffusion models to supervise network training in the absence of paired training data.
    
[^62]: 因果时间图卷积神经网络（CTGCN）

    Causal Temporal Graph Convolutional Neural Networks (CTGCN). (arXiv:2303.09634v1 [cs.LG])

    [http://arxiv.org/abs/2303.09634](http://arxiv.org/abs/2303.09634)

    CTGCN基于因果关系发现机制，利用分而治之的技术克服计算可伸缩性问题，并通过集成因果性提高了对大规模问题的预测能力。

    

    许多大规模应用程序可以使用图形结构进行优雅表示。但是，它们的可伸缩性通常受到应用所需的领域知识的限制。为了解决这个问题，我们提出了一种新颖的因果时间图卷积神经网络（CTGCN）。我们的CTGCN架构基于因果关系发现机制，并能够发现潜在的因果过程。我们的方法的主要优点在于其能够采用分而治之的技术来克服计算可伸缩性问题，并且使用因果模型进行预测的可解释性更高。我们评估了我们的CTGCN在两个数据集上的可伸缩性，以证明我们的方法适用于大规模问题，并表明将因果性集成到TGCN架构中可以比典型的TGCN方法提高最多40％的预测性能。我们的结果是在不需要额外的领域知识的情况下获得的，因此我们的方法是适应性强的。

    Many large-scale applications can be elegantly represented using graph structures. Their scalability, however, is often limited by the domain knowledge required to apply them. To address this problem, we propose a novel Causal Temporal Graph Convolutional Neural Network (CTGCN). Our CTGCN architecture is based on a causal discovery mechanism, and is capable of discovering the underlying causal processes. The major advantages of our approach stem from its ability to overcome computational scalability problems with a divide and conquer technique, and from the greater explainability of predictions made using a causal model. We evaluate the scalability of our CTGCN on two datasets to demonstrate that our method is applicable to large scale problems, and show that the integration of causality into the TGCN architecture improves prediction performance up to 40% over typical TGCN approach. Our results are obtained without requiring additional domain knowledge, making our approach adaptable to
    
[^63]: 高效准确的非线性模型降维的超降维自编码器

    Hyper-Reduced Autoencoders for Efficient and Accurate Nonlinear Model Reductions. (arXiv:2303.09630v1 [physics.comp-ph])

    [http://arxiv.org/abs/2303.09630](http://arxiv.org/abs/2303.09630)

    提出一种新的方法使用超降维自编码器来实现高效准确的非线性模型降维，在高保真度的解快照的子采样版本上训练神经网络以克服高计算成本。在2D Burgers问题上演示了方法的有效性。

    

    最近，投影模型降维在非线性流形上被提出来用于慢速下降Kolmogorov n-width问题的模型降维，如流程主导问题。这些方法通常使用神经网络进行流形学习，并展示出比传统的线性子空间降维模型更好的准确性。先前提出的方法的一个缺点是在高保真度的解快照上训练网络可能导致潜在的高计算成本。在这项工作中，我们提出并分析了一种新方法，通过仅在高保真度的解快照的子采样版本上训练神经网络来克服这个缺点。这种方法与基于重心插值的超降维和Gappy-POD结合使用，可以实现高效准确的代理模型。我们在2D Burgers问题上演示我们方法的有效性。

    Projection-based model order reduction on nonlinear manifolds has been recently proposed for problems with slowly decaying Kolmogorov n-width such as advection-dominated ones. These methods often use neural networks for manifold learning and showcase improved accuracy over traditional linear subspace-reduced order models. A disadvantage of the previously proposed methods is the potential high computational costs of training the networks on high-fidelity solution snapshots. In this work, we propose and analyze a novel method that overcomes this disadvantage by training a neural network only on subsampled versions of the high-fidelity solution snapshots. This method coupled with collocation-based hyper-reduction and Gappy-POD allows for efficient and accurate surrogate models. We demonstrate the validity of our approach on a 2d Burgers problem.
    
[^64]: 周期性MDP中的在线强化学习

    Online Reinforcement Learning in Periodic MDP. (arXiv:2303.09629v1 [cs.LG])

    [http://arxiv.org/abs/2303.09629](http://arxiv.org/abs/2303.09629)

    本文提出了用于解决周期性MDP中强化学习问题的四种算法，其中包括PUCRL2，PUCRLB，U-PUCRL2和U-PUCRLB。PUCRLB表现更好，且其遗憾随周期$N$的变化为$O(\sqrt{N})$。

    

    我们研究了周期性马尔可夫决策过程（MDP）下的强化学习问题，这是一种特殊的非平稳MDP，其中状态转移概率和奖励函数都会周期性变化，在平均奖励最大化的设置下。我们通过在状态空间中添加周期索引来将问题归结为静态MDP，并提出了一种周期性上置信区间强化学习-2（PUCRL2）算法。我们证明了PUCRL2的遗憾值随周期$N$线性变化，并且随着时限长度$T$呈$\mathcal{O}(\sqrt{Tlog T})$的变化。利用增广MDP的转移矩阵的稀疏信息，我们提出另一个算法PUCRLB，它在遗憾（周期的$O(\sqrt{N})$依赖关系）和经验表现方面都比PUCRL2更出色。最后，我们还提出了两个算法U-PUCRL2和U-PUCRLB，用于环境中扩展不确定性，其中周期未知，但已知一组候选周期。数值结果证明，

    We study learning in periodic Markov Decision Process (MDP), a special type of non-stationary MDP where both the state transition probabilities and reward functions vary periodically, under the average reward maximization setting. We formulate the problem as a stationary MDP by augmenting the state space with the period index, and propose a periodic upper confidence bound reinforcement learning-2 (PUCRL2) algorithm. We show that the regret of PUCRL2 varies linearly with the period $N$ and as $\mathcal{O}(\sqrt{Tlog T})$ with the horizon length $T$. Utilizing the information about the sparsity of transition matrix of augmented MDP, we propose another algorithm PUCRLB which enhances upon PUCRL2, both in terms of regret ($O(\sqrt{N})$ dependency on period) and empirical performance. Finally, we propose two other algorithms U-PUCRL2 and U-PUCRLB for extended uncertainty in the environment in which the period is unknown but a set of candidate periods are known. Numerical results demonstrate
    
[^65]: 从游戏中高效学习高层次计划。

    Efficient Learning of High Level Plans from Play. (arXiv:2303.09628v1 [cs.LG])

    [http://arxiv.org/abs/2303.09628](http://arxiv.org/abs/2303.09628)

    本论文介绍了从游戏中高效学习高层次计划的机器人学习框架，可以实现长期复杂的操作任务。他们利用任务不可知的游戏数据学习基于物体的离散行为先验，然后设计一个高层次的目标条件策略，它使用先验来指导规划和构建复杂长期任务。

    

    现实世界中的机器人操作任务仍然是一个棘手的挑战，因为它们涉及到精细的环境交互以及规划长期目标的能力。虽然深度强化学习（RL）方法在高维度环境下规划端到端时显示出了令人鼓舞的结果，但由于探索低效以及长期规划的信用分配复杂性而受到根本性限制。在这项工作中，我们提出了从游戏中高效学习高层次计划（ELF-P），这是一个桥接动作规划和深度RL的机器人学习框架，以实现长期复杂的操作任务。我们利用任务不可知的游戏数据学习基于物体的离散行为先验，建模它们在当前情境下的可行性。然后我们设计一个高层次的目标条件策略，它（1）使用基元作为构建复杂长期任务的基础，（2）利用离散的行为先验来指导规划。

    Real-world robotic manipulation tasks remain an elusive challenge, since they involve both fine-grained environment interaction, as well as the ability to plan for long-horizon goals. Although deep reinforcement learning (RL) methods have shown encouraging results when planning end-to-end in high-dimensional environments, they remain fundamentally limited by poor sample efficiency due to inefficient exploration, and by the complexity of credit assignment over long horizons. In this work, we present Efficient Learning of High-Level Plans from Play (ELF-P), a framework for robotic learning that bridges motion planning and deep RL to achieve long-horizon complex manipulation tasks. We leverage task-agnostic play data to learn a discrete behavioral prior over object-centric primitives, modeling their feasibility given the current context. We then design a high-level goal-conditioned policy which (1) uses primitives as building blocks to scaffold complex long-horizon tasks and (2) leverages
    
[^66]: HIVE：利用人类反馈进行指导性视觉编辑

    HIVE: Harnessing Human Feedback for Instructional Visual Editing. (arXiv:2303.09618v1 [cs.CV])

    [http://arxiv.org/abs/2303.09618](http://arxiv.org/abs/2303.09618)

    本文提出了一种新的框架，利用人类反馈进行指导性视觉编辑。通过收集被编辑图像的人类反馈，并学习奖励函数捕捉用户的偏好，可以缓解数据限制所带来的偏差，并提高模型性能。

    

    研究表明，将人类反馈纳入大型语言模型生成的文本对齐到人类偏好至关重要。本文假设，最先进的指导性图像编辑模型，其输出基于输入图像和编辑指令，同样可以从人类反馈中受益，因为其输出可能不符合用户的正确指令和偏好。本文提出了一种利用人类反馈进行指导性视觉编辑（HIVE）的新框架。具体而言，我们在编辑的图像上收集人类反馈并学习奖励函数以捕捉基础用户偏好。随后，我们引入可扩展的扩散模型微调方法，可根据估计的奖励值融入人类偏好。此外，为减轻数据限制带来的偏差，我们贡献了1M训练数据集，3.6K奖励数据集以用于奖励学习，以及1K评估数据集，以提高指导性图像编辑模型的性能。

    Incorporating human feedback has been shown to be crucial to align text generated by large language models to human preferences. We hypothesize that state-of-the-art instructional image editing models, where outputs are generated based on an input image and an editing instruction, could similarly benefit from human feedback, as their outputs may not adhere to the correct instructions and preferences of users. In this paper, we present a novel framework to harness human feedback for instructional visual editing (HIVE). Specifically, we collect human feedback on the edited images and learn a reward function to capture the underlying user preferences. We then introduce scalable diffusion model fine-tuning methods that can incorporate human preferences based on the estimated reward. Besides, to mitigate the bias brought by the limitation of data, we contribute a new 1M training dataset, a 3.6K reward dataset for rewards learning, and a 1K evaluation dataset to boost the performance of inst
    
[^67]: 具有Kronecker乘积逼近的分散式黎曼自然梯度方法。

    Decentralized Riemannian natural gradient methods with Kronecker-product approximations. (arXiv:2303.09611v1 [math.OC])

    [http://arxiv.org/abs/2303.09611](http://arxiv.org/abs/2303.09611)

    本文提出了一种结构化问题类的分散式黎曼自然梯度下降方法，通过Kronecker乘积逼近RFIM，以较低的成本获得高质量的逼近。该方法收敛速度达到$\mathcal{O}(1/K)$的最佳已知水平。

    

    通过计算效率高的二阶信息逼近，自然梯度方法已成功地解决了大规模结构化优化问题。我们研究了在黎曼流形上的大规模分散式优化问题的自然梯度方法，其中由本地数据集定义的本地目标函数是对数概率类型的。通过利用黎曼费舍尔信息矩阵(RFIM)的结构，我们提出了一种高效的分散式黎曼自然梯度下降(DRNGD)方法。为了克服高维RFIM的通信问题，我们考虑一个结构化问题类，其中RFIM可以通过两个低维矩阵的Kronecker积逼近。通过在Kronecker因子上执行通信，可以以较低的成本获得RFIM的高质量逼近。我们证明DRNGD收敛速度达到$\mathcal{O}(1/K)$的最佳已知水平。

    With a computationally efficient approximation of the second-order information, natural gradient methods have been successful in solving large-scale structured optimization problems. We study the natural gradient methods for the large-scale decentralized optimization problems on Riemannian manifolds, where the local objective function defined by the local dataset is of a log-probability type. By utilizing the structure of the Riemannian Fisher information matrix (RFIM), we present an efficient decentralized Riemannian natural gradient descent (DRNGD) method. To overcome the communication issue of the high-dimension RFIM, we consider a class of structured problems for which the RFIM can be approximated by a Kronecker product of two low-dimension matrices. By performing the communications over the Kronecker factors, a high-quality approximation of the RFIM can be obtained in a low cost. We prove that DRNGD converges to a stationary point with the best-known rate of $\mathcal{O}(1/K)$. Nu
    
[^68]: 强化学习心理治疗AI伴侣与可解释的策略动态

    Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics. (arXiv:2303.09601v1 [cs.LG])

    [http://arxiv.org/abs/2303.09601](http://arxiv.org/abs/2303.09601)

    本文介绍了一种使用强化学习生成心理治疗主题推荐的AI伴侣，能够很好地捕获真实数据，并通过可解释的策略轨迹可视化提供对不同奖励信号和不同临床诊断下训练的策略的独特模式。

    

    本文介绍了一种使用Deep Reinforcement Learning（DRL）生成心理治疗主题推荐的强化学习心理治疗AI伴侣。该系统针对四种不同的精神疾病（焦虑症，抑郁症，精神分裂症和自杀病例）使用多目标策略生成器进行生成，同时通过三个不同的工作联盟评分标准（任务，关系和目标）来检验推荐主题的准确性。我们展示了系统能够相对较好地捕获真实数据（治疗师讨论的历史主题），最佳模型的表现因疾病和评级标准而异。为了获得可解释的洞见，我们在2D主成分分析空间和转移矩阵中可视化策略轨迹。这些可视化呈现了在不同奖励信号和不同临床诊断下训练的策略之间的独特模式。本系统在生成多目标策略心理治疗主题方面的成功表现为开发能够帮助治疗师提供个性化治疗的AI伴侣提供了有希望的方向。

    We introduce a Reinforcement Learning Psychotherapy AI Companion that generates topic recommendations for therapists based on patient responses. The system uses Deep Reinforcement Learning (DRL) to generate multi-objective policies for four different psychiatric conditions: anxiety, depression, schizophrenia, and suicidal cases. We present our experimental results on the accuracy of recommended topics using three different scales of working alliance ratings: task, bond, and goal. We show that the system is able to capture the real data (historical topics discussed by the therapists) relatively well, and that the best performing models vary by disorder and rating scale. To gain interpretable insights into the learned policies, we visualize policy trajectories in a 2D principal component analysis space and transition matrices. These visualizations reveal distinct patterns in the policies trained with different reward signals and trained on different clinical diagnoses. Our system's succe
    
[^69]: cito: 使用torch进行神经网络训练的R包

    cito: An R package for training neural networks using torch. (arXiv:2303.09599v1 [cs.LG])

    [http://arxiv.org/abs/2303.09599](http://arxiv.org/abs/2303.09599)

    cito是一个用户友好的R包，使用torch进行深度神经网络的训练，包括许多对预测和评估模型有用的用户友好功能。

    

    深度神经网络(DNN)已成为回归和分类任务的中心算法类别。虽然一些包允许用户在R中指定DNN，但它们在功能上相当有限。因此，大多数当前的深度学习应用程序依赖于主要的深度学习框架PyTorch或TensorFlow来构建和训练DNN。然而，与R环境中可比的回归或机器学习包相比，使用这些框架需要更多的培训和时间。我们在这里介绍了cito，这是一个用户友好的R包，用于深度学习。cito允许R用户使用大多数R建模函数中使用的熟悉的公式语法来指定深度神经网络。在后台，cito使用torch来拟合模型，利用torch库的所有数值优化，包括在CPU或GPU上切换训练模型的能力。此外，cito包括许多用于预测和评估模型的用户友好功能。

    1. Deep neural networks (DNN) have become a central class of algorithms for regression and classification tasks. Although some packages exist that allow users to specify DNN in R, those are rather limited in their functionality. Most current deep learning applications therefore rely on one of the major deep learning frameworks, PyTorch or TensorFlow, to build and train DNN. However, using these frameworks requires substantially more training and time than comparable regression or machine learning packages in the R environment.  2. Here, we present cito, an user-friendly R package for deep learning. cito allows R users to specify deep neural networks in the familiar formula syntax used by most modeling functions in R. In the background, cito uses torch to fit the models, taking advantage of all the numerical optimizations of the torch library, including the ability to switch between training models on CPUs or GPUs. Moreover, cito includes many user-friendly functions for predictions and
    
[^70]: 用表示学习和组合变量构建多变量网络的视觉分析

    Visual Analytics of Multivariate Networks with Representation Learning and Composite Variable Construction. (arXiv:2303.09590v1 [cs.SI])

    [http://arxiv.org/abs/2303.09590](http://arxiv.org/abs/2303.09590)

    本文提出了一种用于研究多变量网络的视觉分析工作流程，其中包括神经网络学习阶段、降维和优化阶段以及用户交互式可视化接口进行解释。关键的组合变量构建步骤将非线性特征重塑为线性特征，以方便检查和理解。案例研究表明该工作流程具有有效性和可理解性。

    

    多变量网络在真实世界的数据驱动应用中经常被发现。发掘和理解多变量网络中的关系并不是一项简单的任务。本文提出了一种用于研究多变量网络以提取网络不同结构和语义特征之间关联的视觉分析工作流程（例如，什么是在社交网络密度方面与不同属性的组合关系）。该工作流程包括基于神经网络的学习阶段，根据所选输入和输出属性来对数据进行分类，降维和优化阶段以产生一个简化的结果集合以便检查，最后通过用户交互式可视化接口进行解释阶段的操作。我们设计的一个关键部分是组合变量构建步骤，该步骤将由神经网络获得的非线性特征重塑为直观解释的线性特征。我们通过对大型组织员工之间的电子邮件通信数据集进行案例研究，证明了工作流程的有效性和可理解性。

    Multivariate networks are commonly found in real-world data-driven applications. Uncovering and understanding the relations of interest in multivariate networks is not a trivial task. This paper presents a visual analytics workflow for studying multivariate networks to extract associations between different structural and semantic characteristics of the networks (e.g., what are the combinations of attributes largely relating to the density of a social network?). The workflow consists of a neural-network-based learning phase to classify the data based on the chosen input and output attributes, a dimensionality reduction and optimization phase to produce a simplified set of results for examination, and finally an interpreting phase conducted by the user through an interactive visualization interface. A key part of our design is a composite variable construction step that remodels nonlinear features obtained by neural networks into linear features that are intuitive to interpret. We demon
    
[^71]: TypeT5: 基于静态分析的Seq2seq类型推断

    TypeT5: Seq2seq Type Inference using Static Analysis. (arXiv:2303.09564v1 [cs.SE])

    [http://arxiv.org/abs/2303.09564](http://arxiv.org/abs/2303.09564)

    TypeT5是一种利用CodeT5进行静态分析的新型类型推断方法，能够在预测罕见和复杂类型时显著提高准确性，并减少类型错误。

    

    自动预测Python和JavaScript程序中缺少的类型注释越来越受到关注。尽管先前的方法在预测最常见的类型时取得了令人印象深刻的准确度，但在罕见或复杂类型上表现不佳。在本文中，我们提出了一种新的类型推断方法，将类型预测视为代码填充任务，并利用CodeT5，这是一种用于代码的最先进的seq2seq预训练语言模型。我们的方法使用静态分析为每个代码元素构造动态上下文，其类型签名由模型预测。我们还提出了一种迭代解码方案，将先前的类型预测纳入模型的输入上下文中，允许相关代码元素之间进行信息交换。我们的评估表明，所提出的TypeT5方法不仅在整体准确性方面表现更好（特别是在罕见和复杂类型方面），而且产生的结果更具连贯性，类型错误更少。

    There has been growing interest in automatically predicting missing type annotations in programs written in Python and JavaScript. While prior methods have achieved impressive accuracy when predicting the most common types, they often perform poorly on rare or complex types. In this paper, we present a new type inference method that treats type prediction as a code infilling task by leveraging CodeT5, a state-of-the-art seq2seq pre-trained language model for code. Our method uses static analysis to construct dynamic contexts for each code element whose type signature is to be predicted by the model. We also propose an iterative decoding scheme that incorporates previous type predictions in the model's input context, allowing information exchange between related code elements. Our evaluation shows that the proposed approach, TypeT5, not only achieves a higher overall accuracy (particularly on rare and complex types) but also produces more coherent results with fewer type errors -- while
    
[^72]: 利用特权信息进行无监督领域自适应

    Unsupervised domain adaptation by learning using privileged information. (arXiv:2303.09350v1 [cs.LG])

    [http://arxiv.org/abs/2303.09350](http://arxiv.org/abs/2303.09350)

    本文提出利用特权信息进行领域适应（DALUPI）算法，以在学习中放宽假设条件并提高样本效率，通过减少错误来促进医学图像分析等应用的发展。

    

    成功的无监督领域自适应（UDA）只在强假设条件下得以实现，如协变量移位和输入领域之间的重叠。后者在高维应用中经常被违反，比如图像分类，在面对这种挑战时，图像分类仍然是算法开发的灵感和基准。本文表明，获取源域和目标域样本的有关信息能够帮助放宽这些假设，并在学习中提高样本效率，代价是收集更丰富的变量集。我们称之为利用特权信息进行领域适应（DALUPI）。为此，我们提出了一个简单的两阶段学习算法，并提出了一个针对多标签图像分类的实用端到端算法，受到我们分析的启发。通过一系列实验，包括医学图像分析的应用，我们证明了在学习过程中加入特权信息可以减少错误。

    Successful unsupervised domain adaptation (UDA) is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications such as image classification which, despite this challenge, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that access to side information about examples from the source and target domains can help relax these assumptions and increase sample efficiency in learning, at the cost of collecting a richer variable set. We call this domain adaptation by learning using privileged information (DALUPI). Tailored for this task, we propose a simple two-stage learning algorithm inspired by our analysis and a practical end-to-end algorithm for multi-label image classification. In a suite of experiments, including an application to medical image analysis, we demonstrate that incorporating privileged information in learning can reduce errors i
    
[^73]: 基于t-SPN和滤波的细胞分类的最大间隔学习

    Maximum Margin Learning of t-SPNs for Cell Classification with Filtering. (arXiv:2303.09065v1 [cs.LG])

    [http://arxiv.org/abs/2303.09065](http://arxiv.org/abs/2303.09065)

    本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。

    

    本文探讨了一种基于深度概率体系结构的算法，称为树形求和产品网络(t-SPN)，用于细胞分类。构建t-SPN的目的是表示未归一化概率作为最相似的细胞类别的条件概率。通过最大化边缘来学习构建的t-SPN体系结构，该边缘是真实标签和最有竞争力的错误标签之间的条件概率差。为了增强体系结构的泛化能力，在学习过程中考虑了L2正则化（REG）和最大间隔（MM）标准。为了突出细胞特征，本文探讨了两种通用的高通滤波器的有效性：理想高通滤波和拉普拉斯滤波(Log)。在HEp-2和Feulgen基准数据集上，基于最大间隔准则与正则化学习的t-SPN体系结构产生了最高的准确率。

    An algorithm based on a deep probabilistic architecture referred to as a tree-structured sum-product network (t-SPN) is considered for cell classification. The t-SPN is constructed such that the unnormalized probability is represented as conditional probabilities of a subset of most similar cell classes. The constructed t-SPN architecture is learned by maximizing the margin, which is the difference in the conditional probability between the true and the most competitive false label. To enhance the generalization ability of the architecture, L2-regularization (REG) is considered along with the maximum margin (MM) criterion in the learning process. To highlight cell features, this paper investigates the effectiveness of two generic high-pass filters: ideal high-pass filtering and the Laplacian of Gaussian (LOG) filtering. On both HEp-2 and Feulgen benchmark datasets, the t-SPN architecture learned based on the max-margin criterion with regularization produced the highest accuracy rate co
    
[^74]: 基于贝叶斯积分的神经网络集成搜索

    Bayesian Quadrature for Neural Ensemble Search. (arXiv:2303.08874v1 [stat.ML])

    [http://arxiv.org/abs/2303.08874](http://arxiv.org/abs/2303.08874)

    本论文介绍了一种使用贝叶斯积分的新方法，可以在架构似然表面有分散、狭窄峰时构建加权集成神经网络，相比当前同类方法，在测试似然性、准确性和期望校准误差方面更为优秀。

    

    集成方法可以提高神经网络的性能，但现有方法在架构似然表面有分散、狭窄峰时效果不佳。此外，现有方法构建均等加权的集成，这可能容易受到较弱架构的失效模式的影响。通过将集成视为近似边缘化架构，我们使用贝叶斯积分的工具构建集成方法——这些工具非常适合探索架构似然表面有分散、狭窄峰的情况。此外，由此产生的集成由体现其性能的架构加权权重组成。我们通过实证研究——在测试似然性、准确性和期望校准误差方面——表明我们的方法优于现有的基线，并通过削减研究验证其各成分的独立性能。

    Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently.
    
[^75]: 数据驱动的物理知识神经网络求解中子扩散本征值问题的不确定性分析

    On the uncertainty analysis of the data-enabled physics-informed neural network for solving neutron diffusion eigenvalue problem. (arXiv:2303.08455v1 [cs.LG])

    [http://arxiv.org/abs/2303.08455](http://arxiv.org/abs/2303.08455)

    本文针对数据不可避免带有噪声的情况，研究了DEPINN在求解中子扩散本征值问题方面的可行性，并提出了创新的区间损失函数用于减少噪声影响和提高先验数据利用率，此方法在两个基准问题上得到了验证。

    

    在实际工程实验中，通过探测器获得的数据不可避免地带有噪声。本文研究了当先验数据包含不同类型噪声时，已经提出的数据驱动的物理知识神经网络（DEPINN）在计算中子扩散本征值问题时的性能。此外，为了减少噪声的影响，提高噪声先验数据的利用率，本文提出了创新的区间损失函数，并给出了一些严格的数学证明。通过大量的数值结果，本文在两个典型的基准问题上检验了DEPINN的鲁棒性，并通过比较证明了所提出的区间损失函数的有效性。本文确认了改进的DEPINN在核反应堆物理实际工程应用中的可行性。

    In practical engineering experiments, the data obtained through detectors are inevitably noisy. For the already proposed data-enabled physics-informed neural network (DEPINN) \citep{DEPINN}, we investigate the performance of DEPINN in calculating the neutron diffusion eigenvalue problem from several perspectives when the prior data contain different scales of noise. Further, in order to reduce the effect of noise and improve the utilization of the noisy prior data, we propose innovative interval loss functions and give some rigorous mathematical proofs. The robustness of DEPINN is examined on two typical benchmark problems through a large number of numerical results, and the effectiveness of the proposed interval loss function is demonstrated by comparison. This paper confirms the feasibility of the improved DEPINN for practical engineering applications in nuclear reactor physics.
    
[^76]: 使用互信息约束下的对比条件变分自编码器进行风格特征提取

    Style Feature Extraction Using Contrastive Conditioned Variational Autoencoders with Mutual Information Constraints. (arXiv:2303.08068v1 [cs.CV])

    [http://arxiv.org/abs/2303.08068](http://arxiv.org/abs/2303.08068)

    本文提出了一种使用互信息约束下的对比条件变分自编码器进行从未标记数据中提取风格特征的方法，该方法由一个提取风格无关特征的对比学习部分和一个提取风格特征的CVAE部分组成。

    

    在数据分析中，从未标记的数据中提取细粒度特征（如风格）非常重要。无监督方法（如变分自编码器（VAEs））可以提取风格，但提取的风格通常与其他特征混合。我们可以使用分类标签来指导VAEs提取风格，即条件VAEs（CVAEs）。但是，使用未标记数据仅提取风格的方法尚未建立。在本文中，我们构建了一种基于CVAE的方法，使用仅未标记的数据来提取风格特征。所提出的模型大致由两个并行部分组成; 提取风格无关特征的对比学习（CL）部分，以及提取风格特征的CVAE部分。CL模型通常以无需数据扩充的自监督方式学习与样式无关的表示，可以视为样式中的扰动。以提取的风格无关特征为条件，CVAE学习仅提取风格。在训练过程中，先训练CL模型，然后使用训练过的CL模型指导CVAE的训练。在几个数据集上评估了所提出的方法，实验结果表明所提出的方法可以有效地从未标记的数据中提取风格特征。

    It is crucial to extract fine-grained features such as styles from unlabeled data in data analysis. Unsupervised methods, such as variational autoencoders (VAEs), can extract styles, but the extracted styles are usually mixed with other features. We can isolate the styles using VAEs conditioned by class labels, known as conditional VAEs (CVAEs). However, methods to extract only styles using unlabeled data are not established. In this paper, we construct a CVAE-based method that extracts style features using only unlabeled data. The proposed model roughly consists of two parallel parts; a contrastive learning (CL) part that extracts style-independent features and a CVAE part that extracts style features. CL models generally learn representations independent of data augmentation, which can be seen as a perturbation in styles, in a self-supervised way. Taking the style-independent features as a condition, the CVAE learns to extract only styles. In the training procedure, a CL model is tra
    
[^77]: 自标注分类中的碰撞交叉熵损失及EM算法

    Collision Cross-entropy and EM Algorithm for Self-labeled Classification. (arXiv:2303.07321v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.07321](http://arxiv.org/abs/2303.07321)

    本论文提出了一种称为碰撞交叉熵的自标注分类损失替代方法，同时提出了一种优化该损失方法的EM-like算法。实验结果表明，该方法在各种自标注分类任务中表现出更好的性能。

    

    在后验模型的自标注分类背景下，我们提出了“碰撞交叉熵”作为香农交叉熵的一个健壮的替代方案。我们提出了一个EM-like算法来通过交替拟合后验概率y和更新模型预测来优化我们的损失。实验表明，我们的碰撞损失在各种自标注分类任务中优于或至少与现有损失相匹配，包括文本分类、图像分类和目标识别。

    We propose "collision cross-entropy" as a robust alternative to the Shannon's cross-entropy in the context of self-labeled classification with posterior models. Assuming unlabeled data, self-labeling works by estimating latent pseudo-labels, categorical distributions y, that optimize some discriminative clustering criteria, e.g. "decisiveness" and "fairness". All existing self-labeled losses incorporate Shannon's cross-entropy term targeting the model prediction, softmax, at the estimated distribution y. In fact, softmax is trained to mimic the uncertainty in y exactly. Instead, we propose the negative log-likelihood of "collision" to maximize the probability of equality between two random variables represented by distributions softmax and y. We show that our loss satisfies some properties of a generalized cross-entropy. Interestingly, it agrees with the Shannon's cross-entropy for one-hot pseudo-labels y, but the training from softer labels weakens. For example, if y is a uniform dist
    
[^78]: InPL: 伪标签首先标记内点的不平衡半监督学习

    InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning. (arXiv:2303.07269v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2303.07269](http://arxiv.org/abs/2303.07269)

    该论文提出了一种不依赖于模型置信度的伪标签方法，用于不平衡的半监督学习，该方法用能量分数判断未标记样本是“内分布”还是“外分布”，随着训练的进行，越来越多的未标记样本成为内部分布并对训练产生贡献，结合伪标签的方法表现出色。

    

    近来，不平衡半监督学习中的最新先进方法依赖于基于置信度的伪标签和一致性规则。为获得高质量的伪标签，通常采用高置信度阈值。然而，已经证明，在深度网络中，对于远离训练数据的样本，基于softmax的置信度得分可以任意高，因此即使对于高置信度的未标记样本，其伪标签仍可能不可靠。在本文中，我们提出了一种伪标签的新视角，用于不平衡的半监督学习。我们不依赖于模型置信度，而是提出衡量一个未标记 样本很可能属于“内分布”（即接近当前训练数据）的方法。为了确定一个未标记样本是“内分布”还是“外分布”，我们采用来自“外分布检测”文献中的能量分数。随着训练的进行，越来越多的未标记样本成为内部分布并对训练产生贡献，结合伪标签的方法表现出色。

    Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be ``in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is ``in-distribution'' or ``out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combi
    
[^79]: 基于集成学习方法提升COVID-19重症分析

    Enhancing COVID-19 Severity Analysis through Ensemble Methods. (arXiv:2303.07130v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2303.07130](http://arxiv.org/abs/2303.07130)

    本文提出了一种基于领域知识的流程，使用图像处理算法和预训练的UNET模型结合从COVID-19患者中提取感染区域，并使用三种机器学习模型的集成将感染的严重程度分类为不同的类别，从而提高COVID-19重症分析。

    

    计算机断层扫描(CT)提供了肺部的详细图像，允许临床医生观察COVID-19所造成的损伤程度。基于CT的肺部受累程度评分(CTSS)方法用于识别CT扫描中观察到的肺部受累程度。本文提出了一种基于领域知识的流程，使用图像处理算法和预训练的UNET模型结合从COVID-19患者中提取感染区域。然后，使用三种机器学习模型的集成：极端梯度提升、极度随机化树和支持向量机将感染的严重程度分类为不同的类别。该系统在AI-Enabled医学图像分析研讨会和COVID-19诊断大赛(AI-MIA-COV19D)的验证数据集上进行评估，并获得了64\%的宏F1得分。这些结果展示了将领域知识与机器学习技术相结合的精确COVID-19诊断的潜力。

    Computed Tomography (CT) scans provide a detailed image of the lungs, allowing clinicians to observe the extent of damage caused by COVID-19. The CT severity score (CTSS) based scoring method is used to identify the extent of lung involvement observed on a CT scan. This paper presents a domain knowledge-based pipeline for extracting regions of infection in COVID-19 patients using a combination of image-processing algorithms and a pre-trained UNET model. The severity of the infection is then classified into different categories using an ensemble of three machine-learning models: Extreme Gradient Boosting, Extremely Randomized Trees, and Support Vector Machine. The proposed system was evaluated on a validation dataset in the AI-Enabled Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (AI-MIA-COV19D) and achieved a macro F1 score of 64\%. These results demonstrate the potential of combining domain knowledge with machine learning techniques for accurate COVID-19 diagnosis
    
[^80]: 基于生理信号的多尺度深度学习疼痛分类的Transformer编码器

    Transformer Encoder with Multiscale Deep Learning for Pain Classification Using Physiological Signals. (arXiv:2303.06845v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06845](http://arxiv.org/abs/2303.06845)

    本论文提出了一种新的基于生理信号输入的Transformer编码器深度学习框架（PAN）用于疼痛分类，并成功实现了自动疼痛强度分级。研究中使用了多尺度卷积网络 (MSCN)、压缩与激发残余网络(SEResNet)和Transformer编码器等特征提取架构，为客观且自动的疼痛强度评估提供了一种有效途径。

    

    疼痛是世界范围内的一个严重健康问题，它影响着大部分人。为了有效地管理和治疗疼痛，需要准确分类和评估疼痛的严重程度。然而，由于疼痛是主观感受驱动的体验，这可能有一定的挑战性。传统的测量疼痛强度的技术，例如自我报告量表，在某些情况下容易出现偏见且不可靠。因此，需要更客观和自动的疼痛强度评估策略。本文提出了PainAttnNet（PAN），一种基于生理信号输入的用于分类疼痛强度的新型Transformer编码器深度学习框架。所提出的方法由三个特征提取架构组成：多尺度卷积网络（MSCN）、压缩与激发残余网络（SEResNet）和Transformer编码器块。根据疼痛刺激，MSCN提取短时和长时窗口信息，以及序列特征，SEResNet进一步减少道次，然后传递到Transformer编码器进行疼痛分类。结果表明，PAN可为自动疼痛强度分级提供有用信息。

    Pain is a serious worldwide health problem that affects a vast proportion of the population. For efficient pain management and treatment, accurate classification and evaluation of pain severity are necessary. However, this can be challenging as pain is a subjective sensation-driven experience. Traditional techniques for measuring pain intensity, e.g. self-report scales, are susceptible to bias and unreliable in some instances. Consequently, there is a need for more objective and automatic pain intensity assessment strategies. In this paper, we develop PainAttnNet (PAN), a novel transfomer-encoder deep-learning framework for classifying pain intensities with physiological signals as input. The proposed approach is comprised of three feature extraction architectures: multiscale convolutional networks (MSCN), a squeeze-and-excitation residual network (SEResNet), and a transformer encoder block. On the basis of pain stimuli, MSCN extracts short- and long-window information as well as seque
    
[^81]: 探究有状态防御黑盒对抗样本

    Investigating Stateful Defenses Against Black-Box Adversarial Examples. (arXiv:2303.06280v1 [cs.CR])

    [http://arxiv.org/abs/2303.06280](http://arxiv.org/abs/2303.06280)

    本文探究了有状态防御黑盒对抗样本的方法，提出了一种新的有状态防御模型，可以在CIFAR10数据集上达到82.2％的准确性，在ImageNet数据集上达到76.5％的准确性。

    This paper investigates stateful defenses against black-box adversarial examples and proposes a new stateful defense model that achieves 82.2% accuracy on the CIFAR10 dataset and 76.5% accuracy on the ImageNet dataset.

    防御机器学习（ML）模型免受白盒对抗攻击已被证明极为困难。相反，最近的工作提出了有状态防御，试图防御更受限制的黑盒攻击者。这些防御通过跟踪传入模型查询的历史记录，并拒绝那些可疑地相似的查询来操作。目前最先进的有状态防御Blacklight是在USENIX Security '22上提出的，声称可以防止几乎100％的CIFAR10和ImageNet数据集上的攻击。在本文中，我们观察到攻击者可以通过简单调整现有黑盒攻击的参数，显著降低受Blacklight保护的分类器的准确性（例如，在CIFAR10上从82.2％降至6.4％）。受到这一惊人观察的启发，我们提供了有状态防御的系统化，以了解为什么现有的有状态防御模型会失败。最后，我们提出了一种新的有状态防御模型，该模型在CIFAR10数据集上的准确性为82.2％，在ImageNet数据集上的准确性为76.5％。

    Defending machine-learning (ML) models against white-box adversarial attacks has proven to be extremely difficult. Instead, recent work has proposed stateful defenses in an attempt to defend against a more restricted black-box attacker. These defenses operate by tracking a history of incoming model queries, and rejecting those that are suspiciously similar. The current state-of-the-art stateful defense Blacklight was proposed at USENIX Security '22 and claims to prevent nearly 100% of attacks on both the CIFAR10 and ImageNet datasets. In this paper, we observe that an attacker can significantly reduce the accuracy of a Blacklight-protected classifier (e.g., from 82.2% to 6.4% on CIFAR10) by simply adjusting the parameters of an existing black-box attack. Motivated by this surprising observation, since existing attacks were evaluated by the Blacklight authors, we provide a systematization of stateful defenses to understand why existing stateful defense models fail. Finally, we propose a
    
[^82]: KGNv2: 基于关键点的RGB-D输入六自由度抓取合成中的尺度和姿态分离

    KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input. (arXiv:2303.05617v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05617](http://arxiv.org/abs/2303.05617)

    本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。

    

    本文提出了一种6自由度抓取姿态合成方法，该方法基于关键点从2D/2.5D输入中进行。在前期研究中，基于关键点的抓取检测器已经证明了良好的结果，其中彩色图像提供的额外视觉信息弥补了嘈杂的深度感知。然而，它严重依赖于准确预测图像空间中的关键点位置。因此，我们设计了一种新的抓取生成网络，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度。另外，我们还重新设计了关键点输出空间，以减轻关键点预测噪声对透视n点(PnP)算法的负面影响。实验结果表明，所提出的方法在性能上比基线表现出了显著的优越性，验证了我们方法的有效性。最后，尽管是在简单的合成对象上训练的，我们的方法也可以用于真实物体上的抓取。

    We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based on keypoints. Keypoint-based grasp detector from image input has demonstrated promising results in the previous study, where the additional visual information provided by color images compensates for the noisy depth perception. However, it relies heavily on accurately predicting the location of keypoints in the image space. In this paper, we devise a new grasp generation network that reduces the dependency on precise keypoint estimation. Given an RGB-D input, our network estimates both the grasp pose from keypoint detection as well as scale towards the camera. We further re-design the keypoint output space in order to mitigate the negative impact of keypoint prediction noise to Perspective-n-Point (PnP) algorithm. Experiments show that the proposed method outperforms the baseline by a large margin, validating the efficacy of our approach. Finally, despite trained on simple synthetic objects, our method demons
    
[^83]: 使用对比调整学习稳定的 Markov 过程

    Learning Stationary Markov Processes with Contrastive Adjustment. (arXiv:2303.05497v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05497](http://arxiv.org/abs/2303.05497)

    该论文提出了一种新的优化算法对比调整，用于学习 Markov 转移核，并在噪声核的帮助下进行数据建模，进一步推广了对抗生成网络的应用。使用该算法可以对数据流形进行局部探索并通过人类反馈不断改进输出。

    

    我们引入了一种新的优化算法，称为对比调整，用于学习 Markov 转移核，使其稳态分布与数据分布相匹配。对比调整不受限于特定的转移分布家族，并且可以用于建模连续和离散状态空间中的数据。受到最近关于噪声退火采样的工作的启发，我们提出了特定的转移算子，即噪声核，可以在交换速度与样本保真度之间进行权衡。我们发现对比调整在人机设计流程中非常有价值，因为所学的 Markov 链的不变性使得可以对数据流形进行局部探索，并使得可以通过人类反馈来迭代地改进输出。我们将使用对比调整训练的噪声核的性能与当前最先进的生成模型进行比较，并展示在各种图像合成任务中的有 promising 的结果。

    We introduce a new optimization algorithm, termed contrastive adjustment, for learning Markov transition kernels whose stationary distribution matches the data distribution. Contrastive adjustment is not restricted to a particular family of transition distributions and can be used to model data in both continuous and discrete state spaces. Inspired by recent work on noise-annealed sampling, we propose a particular transition operator, the noise kernel, that can trade mixing speed for sample fidelity. We show that contrastive adjustment is highly valuable in human-computer design processes, as the stationarity of the learned Markov chain enables local exploration of the data manifold and makes it possible to iteratively refine outputs by human feedback. We compare the performance of noise kernels trained with contrastive adjustment to current state-of-the-art generative models and demonstrate promising results on a variety of image synthesis tasks.
    
[^84]: 使用不确定性估计指导伪标签的无源自适应域自适应方法研究

    Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation. (arXiv:2303.03770v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03770](http://arxiv.org/abs/2303.03770)

    本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。

    

    标准的无监督域自适应方法假定在适应过程中同时可用源域和目标域数据。在这项工作中，我们研究了无源自适应域自适应（SF-UDA）方法，它是UDA的一个特殊情况，在该情况下，模型在没有访问源数据的情况下适应目标域。我们提出了一种新的方法来处理SF-UDA设置，基于损失重新加权策略，以增强对伪标签的噪声的鲁棒性。该分类损失基于估计其不确定性来重新加权，以指导伪标签的进一步精化，并通过聚集相邻样本的知识来逐步提高其准确性。此外，我们引入了自监督对比框架来作为目标空间的正则化器，以增强知识的聚合。同时，我们提出了一种负样本对排除策略，以识别和排除由共享相同特征的样本构成的负样本对。

    Standard Unsupervised Domain Adaptation (UDA) methods assume the availability of both source and target data during the adaptation. In this work, we investigate Source-free Unsupervised Domain Adaptation (SF-UDA), a specific case of UDA where a model is adapted to a target domain without access to source data. We propose a novel approach for the SF-UDA setting based on a loss reweighting strategy that brings robustness against the noise that inevitably affects the pseudo-labels. The classification loss is reweighted based on the reliability of the pseudo-labels that is measured by estimating their uncertainty. Guided by such reweighting strategy, the pseudo-labels are progressively refined by aggregating knowledge from neighbouring samples. Furthermore, a self-supervised contrastive framework is leveraged as a target space regulariser to enhance such knowledge aggregation. A novel negative pairs exclusion strategy is proposed to identify and exclude negative pairs made of samples shari
    
[^85]: 深度学习去噪方法的客观任务评估的必要性：以心肌灌注SPECT为背景的研究

    Need for Objective Task-based Evaluation of Deep Learning-Based Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT. (arXiv:2303.02110v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2303.02110](http://arxiv.org/abs/2303.02110)

    本研究旨在探讨基于深度学习的图像去噪方法在临床任务中的表现评估，发现使用保真度(FoMs)的评估不一定与任务为基础的评估一致，而基于信号检测理论(SDT)的评估方法提供了更客观、有意义的去噪效果评估方式，并证明虚拟临床试验（VCTs）是评估DL方法的实用工具。

    

    人工智能方法在核医学中引起了广泛的兴趣，其中特别关注使用基于深度学习（DL）的方法去噪低剂量、短采集时间或两者同时获取的图像。这些方法的客观评估对于临床应用至关重要。DL去噪核医学图像通常使用类似RMSE和SSIM这样的保真度（FoMs）进行评估。然而，这些图像是为临床任务而采集的，因此应该根据它们在这些任务中的表现来评估。本研究的目的是(1)调查使用这些FoMs的评估是否与客观的临床任务评估一致; (2)提供用于确定去噪对信号检测任务影响的理论分析; (3)展示虚拟临床试验（VCTs）用于评估DL方法的实用性。使用逼真的模拟器进行了一个VCT来评估DL去噪心肌灌注SPECT图像方法。采用客观的强制选择实验，使用信号检测理论（SDT）的基于任务的指标和FoMs评估了去噪效果。结果表明，使用FoMs评估去噪效果不一定与基于任务的评估相关。SDT指标提供了更客观和有意义的去噪效果评估方式。VCTs可为核医学中基于DL的去噪方法的评估提供有用的工具。

    Artificial intelligence-based methods have generated substantial interest in nuclear medicine. An area of significant interest has been using deep-learning (DL)-based approaches for denoising images acquired with lower doses, shorter acquisition times, or both. Objective evaluation of these approaches is essential for clinical application. DL-based approaches for denoising nuclear-medicine images have typically been evaluated using fidelity-based figures of merit (FoMs) such as RMSE and SSIM. However, these images are acquired for clinical tasks and thus should be evaluated based on their performance in these tasks. Our objectives were to (1) investigate whether evaluation with these FoMs is consistent with objective clinical-task-based evaluation; (2) provide a theoretical analysis for determining the impact of denoising on signal-detection tasks; (3) demonstrate the utility of virtual clinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a DL-based method for denoisi
    
[^86]: 全球健康的自适应干预：以疟疾为例的案例研究

    Adaptive Interventions for Global Health: A Case Study of Malaria. (arXiv:2303.02075v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2303.02075](http://arxiv.org/abs/2303.02075)

    介绍了如何通过移动健康应用和机器学习自适应干预来加强疟疾监测和治疗依从性，改善医护质量，提高检测率和公共卫生，减少药品短缺和为政策干预提供信息。

    

    疟疾是可以预防、诊断和治疗的疾病；但每年仍有超过两亿个病例和两万个可预防死亡。尤其在撒哈拉以南非洲的低收入和中等收入国家，疟疾仍然是一个紧迫的公共卫生问题。我们通过移动健康应用、基于机器学习的自适应干预，可以加强疟疾监测和治疗的依从性，增加检测，衡量提供者的技能和护理质量，通过支持一线工作人员和患者（如容量建设和鼓励行为变化，如使用蚊帐）改善公共卫生，减少药店和诊所的测试库存短缺并为政策干预提供信息。

    Malaria can be prevented, diagnosed, and treated; however, every year, there are more than 200 million cases and 200.000 preventable deaths. Malaria remains a pressing public health concern in low- and middle-income countries, especially in sub-Saharan Africa. We describe how by means of mobile health applications, machine-learning-based adaptive interventions can strengthen malaria surveillance and treatment adherence, increase testing, measure provider skills and quality of care, improve public health by supporting front-line workers and patients (e.g., by capacity building and encouraging behavioral changes, like using bed nets), reduce test stockouts in pharmacies and clinics and informing public health for policy intervention.
    
[^87]: 隐藏的宝石：使用跨模态监督的4D雷达场景流学习

    Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision. (arXiv:2303.00462v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.00462](http://arxiv.org/abs/2303.00462)

    本研究提出了一种使用跨模态监督学习的新方法，用于精确地估计4D雷达场景流，并在运动分割和自我运动估计等子任务中显示了其实用性。

    

    本文提出一种通过跨模态学习进行4D雷达基础场景流量估计的新方法。我们的方法受到现代自动驾驶车辆中同一位置的传感器冗余的启发。这种冗余隐含地为雷达场景流估计提供了各种形式的监督线索。具体来说，我们提出了一个多任务模型，针对已确定的跨模态学习问题，提出了损失函数，以使用多个跨模态约束机会有效地进行场景流量估计进行模型训练。广泛的实验显示了我们方法的最先进性能，并证明了跨模态监督学习用于推断更准确的4D雷达场景流的有效性。我们还展示了它对两个子任务-运动分割和自我运动估计的有用性。我们的源代码将在https://github.com/Toytiny/CMFlow上提供。

    This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on https://github.com/Toytiny/CMFlow.
    
[^88]: 两层神经网络中学习时间尺度的研究

    Learning time-scales in two-layers neural networks. (arXiv:2303.00055v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00055](http://arxiv.org/abs/2303.00055)

    本文研究了两层神经网络的学习动态，发现经验风险的下降速率是非单调的。在分布符合单指数模型的高维宽两层神经网络中，我们通过学习率参数化清晰的阶段转换，并提供了对网络学习动态的全面分析。我们还为早期学习时所学模型的简单性提供了理论解释。

    

    多层神经网络的梯度下降学习具有多个引人注意的特点。尤其是，在大批量数据平均后，经验风险的下降速率是非单调的。几乎没有进展的长周期和快速下降的间隔交替出现。这些连续的学习阶段往往在非常不同的时间尺度上进行。最后，在早期阶段学习的模型通常是“简单的”或“易于学习的”，尽管以难以形式化的方式。本文研究了分布符合单指数模型的高维宽两层神经网络的梯度流动力学，在一系列新的严密结果、非严密数学推导和数值实验的基础上，提供了对网络学习动态的全面分析。我们特别指出，我们通过学习率参数化清晰的阶段转换，并展示了它们与长周期的出现和消失有关。我们还为早期学习时所学模型的简单性提供了理论解释，并证明它们可以用于规范训练过程。

    Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numer
    
[^89]: 均场极限中的再生核希尔伯特空间

    Reproducing kernel Hilbert spaces in the mean field limit. (arXiv:2302.14446v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.14446](http://arxiv.org/abs/2302.14446)

    本文研究了作用于具有许多测量变量的数据的内核方法在均场极限下的行为，并给出了极限再生核希尔伯特空间的详细分析。

    

    内核方法是机器学习中最受欢迎和成功的技术之一，它们有一个成熟的理论和高效的算法支持。从数学角度来看，这些方法基于内核的概念和内核生成的函数空间，即再生核希尔伯特空间。受相互作用粒子系统学习方法最近的发展的推动，我们研究了作用于具有许多测量变量的数据的内核方法。我们展示了内核的严格均场极限，并提供了极限再生核希尔伯特空间的详细分析。此外，我们还提出了几个内核的示例，这些内核允许严格的均场极限。

    Kernel methods, being supported by a well-developed theory and coming with efficient algorithms, are among the most popular and successful machine learning techniques. From a mathematical point of view, these methods rest on the concept of kernels and function spaces generated by kernels, so called reproducing kernel Hilbert spaces. Motivated by recent developments of learning approaches in the context of interacting particle systems, we investigate kernel methods acting on data with many measurement variables. We show the rigorous mean field limit of kernels and provide a detailed analysis of the limiting reproducing kernel Hilbert space. Furthermore, several examples of kernels, that allow a rigorous mean field limit, are presented.
    
[^90]: 表现不足以为盈，深究Rashomon的四重奏

    Performance is not enough: a story of the Rashomon's quartet. (arXiv:2302.13356v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.13356](http://arxiv.org/abs/2302.13356)

    本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能，同时其可视化揭示了极其不同的方法来理解数据中的相关性结构。

    

    预测建模通常被简化为寻找最优模型来优化选定的性能度量。但如果第二优模型能够以完全不同的方式同样描述数据呢？第三个模型呢？最有效的模型会学到完全不同的数据关系吗？受到Anscombe四重奏的启发，本文介绍了Rashomon的四重奏，这是一个合成数据集，其中来自不同类别的四个模型具有几乎相同的预测性能。然而，它们的可视化揭示了极其不同的方法来理解数据中的相关性结构。引入的简单示例旨在进一步促进可视化作为比较预测模型超越性能的必要工具。我们需要开发富有洞察力的技术来解释模型集。

    Predictive modelling is often reduced to finding the best model that optimizes a selected performance measure. But what if the second-best model describes the data equally well but in a completely different way? What about the third? Is it possible that the most effective models learn completely different relationships in the data? Inspired by Anscombe's quartet, this paper introduces Rashomon's quartet, a synthetic dataset for which four models from different classes have practically identical predictive performance. However, their visualization reveals drastically distinct ways of understanding the correlation structure in data. The introduced simple illustrative example aims to further facilitate visualization as a mandatory tool to compare predictive models beyond their performance. We need to develop insightful techniques for the explanatory analysis of model sets.
    
[^91]: Eagle: 基于网格变换器的湍流流体动力学大规模学习

    Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers. (arXiv:2302.10803v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10803](http://arxiv.org/abs/2302.10803)

    EAGLE引入了大规模数据集和新模型，其中包括一种新的网格变换器，能够预测具有挑战性的流体动力学数据集中的压力和速度变化。

    

    传统上通过模拟和计算数值模型解决Navier-Stokes方程来估计流体动力学，即使在高端硬件上也要耗费大量的计算时间和资源，这是一个极其复杂的问题。近年来，机器学习，特别是基于图神经网络（GNN）和变种的方法已经开始尝试解决此类问题，但是这些方法都只针对几何形状固定的静态场景中的静态对象进行了数据集的训练和评估。我们试图超越现有工作的复杂度，引入一种新的模型、方法和基准。我们提出了EAGLE，一个包含1.1百万个二维网格的大规模数据集，这些网格是由一个移动流体源引起的不稳定流体动力学模拟生成的，其相互作用导致了非线性场景结构，其中包括三种不同类型的600个不同场景。为了对这个具有挑战性的EAGLE数据集进行未来的压力和速度预测，我们引入了一种新的网格变换器，它利用了节点聚类、图池化和全局池化。

    Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE, a large-scale dataset of 1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure, comprised of 600 different scenes of three different types. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and glo
    
[^92]: CADIS：采用聚类聚合和知识蒸馏正则化处理联邦学习中的聚类偏斜非独立同分布数据

    CADIS: Handling Cluster-skewed Non-IID Data in Federated Learning with Clustered Aggregation and Knowledge DIStilled Regularization. (arXiv:2302.10413v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10413](http://arxiv.org/abs/2302.10413)

    本文提出了一种针对聚类偏斜非独立同分布数据的联邦学习聚合方案和基于知识蒸馏的局部训练正则化方法

    

    联邦学习使得边缘设备能够协作地训练全局模型，而不暴露它们的数据。然而，在处理非独立同分布数据（IID）时，即由通常不独立且同分布的客户端生成的数据时，联邦学习面临重大挑战。本文针对实际数据集中发现的一种新型非IID数据，称为聚类偏斜非IID进行研究。这种数据现象是指客户端可以被分成具有相似数据分布的群组。通过对分类模型的次级层行为进行深入分析，我们引入了一种度量方法来量化两个客户端数据分布的相似度，同时不违反其隐私权。然后，我们提出了一种聚合方案，确保不同群组之间的平等。此外，我们还提出了一种基于知识蒸馏的新型局部训练正则化方法，

    Federated learning enables edge devices to train a global model collaboratively without exposing their data. Despite achieving outstanding advantages in computing efficiency and privacy protection, federated learning faces a significant challenge when dealing with non-IID data, i.e., data generated by clients that are typically not independent and identically distributed. In this paper, we tackle a new type of Non-IID data, called cluster-skewed non-IID, discovered in actual data sets. The cluster-skewed non-IID is a phenomenon in which clients can be grouped into clusters with similar data distributions. By performing an in-depth analysis of the behavior of a classification model's penultimate layer, we introduce a metric that quantifies the similarity between two clients' data distributions without violating their privacy. We then propose an aggregation scheme that guarantees equality between clusters. In addition, we offer a novel local training regularization based on the knowledge
    
[^93]: LAVA：基于颗粒化神经元级别可解释性的静脉荧光成像诊断阿尔茨海默病的 AI

    LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images. (arXiv:2302.03008v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03008](http://arxiv.org/abs/2302.03008)

    LAVA是一个基于颗粒化神经元级别可解释性的 AI 框架，可以直接从静脉荧光成像中评估阿尔茨海默病的进程，验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。

    

    阿尔茨海默病（AD）是渐进性神经退行性疾病，是痴呆的主要原因。早期诊断对患者从潜在的干预和治疗中获益至关重要。视网膜因其与大脑的解剖联系，被假定为 AD 检测的诊断部位。然而相关的 AI 模型尚未提供关于决策的合理解释，也无法推断疾病进展的阶段。因此，我们提出了一个新颖的模型无关的可解释性 AI 框架，称为 Granular Neuron-level Explainer（LAVA），它是一个解释原型，可以探测卷积神经网络（CNN）模型的中间层以直接从视网膜成像中评估 AD 进程。本方法应用于验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。通过 UK Biobank 认知测试和血管鉴定。

    Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the leading cause of dementia. Early diagnosis is critical for patients to benefit from potential intervention and treatment. The retina has been hypothesized as a diagnostic site for AD detection owing to its anatomical connection with the brain. Developed AI models for this purpose have yet to provide a rational explanation about the decision and neither infer the stage of disease's progression. Along this direction, we propose a novel model-agnostic explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an interpretation prototype that probes into intermediate layers of the Convolutional Neural Network (CNN) models to assess the AD continuum directly from the retinal imaging without longitudinal or clinical evaluation. This method is applied to validate the retinal vasculature as a biomarker and diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank cognitive tests and vascular
    
[^94]: 人工智能控制的表面肌肉电刺激臂部运动恢复：利用高斯状态空间模型控制逐渐加重的肌肉疲劳（arXiv:2301.04005v2 [eess.SY] 已更新）

    Towards AI-controlled FES-restoration of arm movements: Controlling for progressive muscular fatigue with Gaussian state-space models. (arXiv:2301.04005v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2301.04005](http://arxiv.org/abs/2301.04005)

    本研究利用高斯状态空间模型与循环神经网络处理FES控制中无法观测到的肌肉疲劳问题，提高了强化学习控制器的控制性能。

    

    运动障碍会限制个体完成日常任务的能力。表面肌肉电刺激（FES）提供了一种非侵入式的解决方案来恢复失去的能力。然而，使用FES诱导期望的运动仍然是一个开放的工程问题。这个问题由人类臂部神经机械复杂性和个体间差异引起的。强化学习（RL）是一种有希望的方法，可以为不同的受试者和场景制定定制化的控制规则。然而，使用RL控制FES的一个尚未解决的挑战是逐渐变化的肌肉疲劳，它作为刺激的未知函数不断改变，打破了RL的马尔可夫假设。在这项研究中，我们提出了一种方法来解决无法观测到的肌肉疲劳问题，使我们的RL控制器可以实现更高的控制性能。我们的方法基于一个利用循环神经网络学习马尔可夫状态空间的高斯状态空间模型（GSSM）。

    Reaching disability limits an individual's ability in performing daily tasks. Surface Functional Electrical Stimulation (FES) offers a non-invasive solution to restore the lost abilities. However, inducing desired movements using FES is still an open engineering problem. This problem is accentuated by the complexities of human arms' neuromechanics and the variations across individuals. Reinforcement Learning (RL) emerges as a promising approach to govern customised control rules for different subjects and settings. Yet, one remaining challenge of using RL to control FES is unobservable muscle fatigue that progressively changes as an unknown function of the stimulation, breaking the Markovian assumption of RL. In this work, we present a method to address the unobservable muscle fatigue issue, allowing our RL controller to achieve higher control performances. Our method is based on a Gaussian State-Space Model (GSSM) that utilizes recurrent neural networks to learn Markovian state-spaces
    
[^95]: 基于神经机械学的强化学习，实现对上肢运动的FES恢复的AI控制：3D伸手运动

    Towards AI-controlled FES-restoration of arm movements: neuromechanics-based reinforcement learning for 3-D reaching. (arXiv:2301.04004v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2301.04004](http://arxiv.org/abs/2301.04004)

    该论文致力于解决控制FES实现所需运动方向方面的挑战，提出一种基于神经机械学的强化学习方法来进行FES控制，以恢复上肢运动功能。

    

    偏瘫和上肢的运动障碍影响了生活的质量。功能性电刺激（FES）可以恢复失去的肌肉功能。然而，在控制FES以实现所需的运动方向方面仍存在挑战。通过构建神经机械模型来寻找一般方法来调节控制规则，以完成不同任务和受试者的工程挑战。

    Reaching disabilities affect the quality of life. Functional Electrical Stimulation (FES) can restore lost motor functions. Yet, there remain challenges in controlling FES to induce desired movements. Neuromechanical models are valuable tools for developing FES control methods. However, focusing on the upper extremity areas, several existing models are either overly simplified or too computationally demanding for control purposes. Besides the model-related issues, finding a general method for governing the control rules for different tasks and subjects remains an engineering challenge. Here, we present our approach toward FES-based restoration of arm movements to address those fundamental issues in controlling FES. Firstly, we present our surface-FES-oriented neuromechanical models of human arms built using well-accepted, open-source software. The models are designed to capture significant dynamics in FES controls with minimal computational cost. Our models are customisable and can be 
    
[^96]: Invalidator: 通过语义和语法推理实现自动修复程序的正确性评估

    Invalidator: Automated Patch Correctness Assessment via Semantic and Syntactic Reasoning. (arXiv:2301.01113v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2301.01113](http://arxiv.org/abs/2301.01113)

    本文提出了INVALIDATOR，一种使用语义和语法推理自动评估由APR生成的补丁的正确性的技术。INVALIDATOR利用程序不变量来推理程序的语义并捕获程序的语法，然后判断APR生成的补丁是否过度拟合。我们的实验结果表明INVALIDATOR在检测过度拟合补丁方面优于现有方法。

    

    自动程序修复面临测试过度拟合的挑战，即生成的补丁通过验证测试但未能推广。目前的缺陷修复评估方法包括生成新测试或手动检查，这可能耗时或具有偏见。本文提出了一种新的技术INVALIDATOR，通过语义和语法推理自动评估由APR生成的补丁的正确性。INVALIDATOR利用程序不变量推理程序语义，同时通过使用预训练语言模型从大型代码语料库中学习语言语法来捕获程序语法。给定有缺陷的程序和开发人员修复后的程序，INVALIDATOR推断出两个程序中可能的不变量。然后，INVALIDATOR确定APR生成的补丁过度拟合，如果：（1）它违反了正确的规范或（2）保留了原来有缺陷程序的错误行为。在我们的方法根据其程序分析无法确定过度拟合补丁的情况下，INVALIDATOR会回退到生成其他测试以进行进一步验证。我们在一组真实世界的错误基准上评估INVALIDATOR，并显示它在检测过度拟合补丁方面优于现有方法，同时更加高效。

    Automated program repair (APR) faces the challenge of test overfitting, where generated patches pass validation tests but fail to generalize. Existing methods for patch assessment involve generating new tests or manual inspection, which can be time-consuming or biased. In this paper, we propose a novel technique, INVALIDATOR, to automatically assess the correctness of APR-generated patches via semantic and syntactic reasoning. INVALIDATOR leverages program invariants to reason about program semantics while also capturing program syntax through language semantics learned from a large code corpus using a pre-trained language model. Given a buggy program and the developer-patched program, INVALIDATOR infers likely invariants on both programs. Then, INVALIDATOR determines that an APR-generated patch overfits if: (1) it violates correct specifications or (2) maintains erroneous behaviors from the original buggy program. In case our approach fails to determine an overfitting patch based on i
    
[^97]: SIRL: 基于相似度的隐式表示学习

    SIRL: Similarity-based Implicit Representation Learning. (arXiv:2301.00810v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.00810](http://arxiv.org/abs/2301.00810)

    SIRL是基于人提供相似度判断的任务表示学习方法，能够帮助机器人识别和隔离因果特征并生成适当行为，在各种机器人任务上表现优秀。

    

    当机器人使用高容量模型以原始状态作为输入学习奖励函数时，他们需要同时学习任务的“特征”表示及如何将这些特征组合成一个目标。如果他们尝试从用于教授完整奖励函数的输入中同时学习两者，很容易产生包含数据中假相关性的表示，导致不能推广到新的环境中。我们的最终目标是使机器人能够识别和隔离人们实际关心和使用的因果特征，当表示状态和行为时。我们的想法是，我们可以通过询问用户认为相似的行为来调整这种表示：如果关键特征相似，这些行为将相似，即使低层行为有所不同；相反，如果即使有一个关键特征不同，那么这些行为就会有所不同。这正是使机器人能够学习任务目标并生成适当行为的关键。为了实现这一目标，我们提出了基于相似度的隐式表示学习（SIRL）方法，该方法使用由人提供的相似性判断来学习隐式任务表示。我们在各种机器人任务上评估SIRL，并展示它在最终任务性能和泛化能力方面胜过其他表示学习方法。

    When robots learn reward functions using high capacity models that take raw state directly as input, they need to both learn a representation for what matters in the task -- the task ``features" -- as well as how to combine these features into a single objective. If they try to do both at once from input designed to teach the full reward function, it is easy to end up with a representation that contains spurious correlations in the data, which fails to generalize to new settings. Instead, our ultimate goal is to enable robots to identify and isolate the causal features that people actually care about and use when they represent states and behavior. Our idea is that we can tune into this representation by asking users what behaviors they consider similar: behaviors will be similar if the features that matter are similar, even if low-level behavior is different; conversely, behaviors will be different if even one of the features that matter differs. This, in turn, is what enables the rob
    
[^98]: 多区域内窥镜图像中基于半监督生成对抗网络的膀胱组织分类

    Semi-supervised Bladder Tissue Classification in Multi-Domain Endoscopic Images. (arXiv:2212.11375v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2212.11375](http://arxiv.org/abs/2212.11375)

    该论文提出了一种面向多领域的半监督生成对抗网络方法，可以不需要配对注释，同时使用WLI和NBI两个领域来实现膀胱组织分类，取得了竞争性的结果。

    

    目标：在经输尿管膀胱肿瘤切除(TURBT)手术中，准确的膀胱组织视觉分类对于改善早期癌症诊断和治疗至关重要。在TURBT手术中，会使用白光成像（WLI）和窄带成像（NBI）技术来检测病变。每种成像技术都提供了不同的视觉信息，使临床医生能够识别和分类癌性病变。使用同时使用这两个成像技术的计算机视觉方法可以改善内窥诊断。然而，当只有WLI领域中有注释可用，同时内窥镜图像对应于非配对数据时（即两种成像技术之间没有精确的图像对应），识别膀胱组织分类仍然是个挑战。方法：我们提出了一种半监督生成对抗网络（GAN）方法，由三个主要组件组成：一个在有标签WLI数据上训练的教师网络；一个循环一致性GAN用于从一种领域翻译到另一个领域；以及一个使用两个领域来执行最终分类的学生网络。我们使用对抗性和循环一致性损失的组合来在非配对数据上训练网络，以提高分类模型的鲁棒性和泛化能力。结果：我们在一个由497张膀胱组织图像组成的数据集上评估了我们的方法，并将其与单领域和多领域分类的最先进方法进行了比较，在两种情况下均取得了竞争性的结果。结论：我们的方法展示了使用半监督学习和领域转换技术来改善内窥镜图像中的膀胱组织分类的潜力，而不需要配对注释。

    Objective: Accurate visual classification of bladder tissue during Trans-Urethral Resection of Bladder Tumor (TURBT) procedures is essential to improve early cancer diagnosis and treatment. During TURBT interventions, White Light Imaging (WLI) and Narrow Band Imaging (NBI) techniques are used for lesion detection. Each imaging technique provides diverse visual information that allows clinicians to identify and classify cancerous lesions. Computer vision methods that use both imaging techniques could improve endoscopic diagnosis. We address the challenge of tissue classification when annotations are available only in one domain, in our case WLI, and the endoscopic images correspond to an unpaired dataset, i.e. there is no exact equivalent for every image in both NBI and WLI domains. Method: We propose a semi-surprised Generative Adversarial Network (GAN)-based method composed of three main components: a teacher network trained on the labeled WLI data; a cycle-consistency GAN to perform 
    
[^99]: CausalEGM: 基于生成模型的一般性因果推断框架

    CausalEGM: a general causal inference framework by encoding generative modeling. (arXiv:2212.05925v4 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.05925](http://arxiv.org/abs/2212.05925)

    论文提出了基于生成模型的CausalEGM框架，能够同时进行因果效应的解耦以及将混淆变量映射到低维潜变量空间。

    

    尽管理解和表征因果效应已经成为观察研究中至关重要的问题，但当混淆变量具有高维性时，这种问题很具挑战性。本文开发了一个用于通过编码生成建模估计因果效应的通用框架"CausalEGM"，可应用于二元和连续的治疗设置。在潜在结果框架下，我们建立了高维混淆变量空间和已知密度（例如多元正态分布）的低维潜变量空间之间的双向转换。通过这种方式，CausalEGM同时将混淆变量对治疗和结果的依赖关系进行解耦，并映射混淆变量到低维潜变量空间。通过对低维潜特征的调节，CausalEGM可以估计每个个体的因果效应或人群中的平均因果效应。我们的理论分析表明：

    Although understanding and characterizing causal effects have become essential in observational studies, it is challenging when the confounders are high-dimensional. In this article, we develop a general framework $\textit{CausalEGM}$ for estimating causal effects by encoding generative modeling, which can be applied in both binary and continuous treatment settings. Under the potential outcome framework with unconfoundedness, we establish a bidirectional transformation between the high-dimensional confounders space and a low-dimensional latent space where the density is known (e.g., multivariate normal distribution). Through this, CausalEGM simultaneously decouples the dependencies of confounders on both treatment and outcome and maps the confounders to the low-dimensional latent space. By conditioning on the low-dimensional latent features, CausalEGM can estimate the causal effect for each individual or the average causal effect within a population. Our theoretical analysis shows that
    
[^100]: 生物启发式学习是否比反向传播更好？生物学习与反向传播的基准测试。

    Is Bio-Inspired Learning Better than Backprop? Benchmarking Bio Learning vs. Backprop. (arXiv:2212.04614v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04614](http://arxiv.org/abs/2212.04614)

    本研究对比了反向传播和多个生物启发式算法，发现当未提供整个训练数据集时，生物算法比反向传播表现要好得多。

    

    自从反向传播（BP）不被认为是符合生物学原理的以来，生物启发式学习近年来变得越来越流行。文献中提出了许多算法，它们都比BP更符合生物学原理。然而，除了克服BP的生物学不合理性，使用生物启发式算法的强烈动机仍然缺乏。在本研究中，我们进行了BP和多个生物启发式算法的全面比较，以回答生物学习是否比BP提供额外的好处的问题。我们使用不同的设计选择来测试生物算法，如仅使用部分训练数据、训练时资源约束、神经网络参数的稀疏化以及向输入样本添加噪声。通过这些实验，我们发现了两个生物算法超过BP的关键优势。首先，在未提供整个训练数据集时，生物算法比BP表现要好得多。

    Bio-inspired learning has been gaining popularity recently given that Backpropagation (BP) is not considered biologically plausible. Many algorithms have been proposed in the literature which are all more biologically plausible than BP. However, apart from overcoming the biological implausibility of BP, a strong motivation for using Bio-inspired algorithms remains lacking. In this study, we undertake a holistic comparison of BP vs. multiple Bio-inspired algorithms to answer the question of whether Bio-learning offers additional benefits over BP. We test Bio-algorithms under different design choices such as access to only partial training data, resource constraints in terms of the number of training epochs, sparsification of the neural network parameters and addition of noise to input samples. Through these experiments, we notably find two key advantages of Bio-algorithms over BP. Firstly, Bio-algorithms perform much better than BP when the entire training dataset is not supplied. Four 
    
[^101]: 学习选择典型部分以解释序列数据建模

    Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling. (arXiv:2212.03396v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03396](http://arxiv.org/abs/2212.03396)

    提出了一种自解释选择模型，使用典型的概念的线性组合来解释其自身的预测，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，为了更好的解释性，还设计了多个约束条件。

    

    原型解释方法通过将样本与参考集中的典型代表进行相似度比较，提供了模型预测的直观解释。在序列数据建模领域，原型的相似性计算通常基于编码表示向量。然而，由于高度递归的函数，原型解释与原始输入之间通常存在明显差异。在本文中，我们提出了一种自解释选择模型（SESM），它使用典型的概念的线性组合来解释其自身的预测。该模型采用基于案例的推理思想，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，用户可以将其与选择自不同示例输入的子序列进行比较以理解模型决策。为了更好的解释性，我们设计了多个约束条件，包括多样性，稳定性等。

    Prototype-based interpretability methods provide intuitive explanations of model prediction by comparing samples to a reference set of memorized exemplars or typical representatives in terms of similarity. In the field of sequential data modeling, similarity calculations of prototypes are usually based on encoded representation vectors. However, due to highly recursive functions, there is usually a non-negligible disparity between the prototype-based explanations and the original input. In this work, we propose a Self-Explaining Selective Model (SESM) that uses a linear combination of prototypical concepts to explain its own predictions. The model employs the idea of case-based reasoning by selecting sub-sequences of the input that mostly activate different concepts as prototypical parts, which users can compare to sub-sequences selected from different example inputs to understand model decisions. For better interpretability, we design multiple constraints including diversity, stabilit
    
[^102]: 带有圆环核的模式注意力变换器

    Pattern Attention Transformer with Doughnut Kernel. (arXiv:2211.16961v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.16961](http://arxiv.org/abs/2211.16961)

    本论文提出了一种新的模式注意力变换器(PAT)，它采用了新的圆环核设计，以解决图像分类中像素高分辨率的问题。

    

    本文介绍了一种新的体系结构，即Pattern Attention Transformer（PAT），该体系结构由新的圆环核组成。与NLP领域的标记不同，计算机视觉中的Transformer解决了处理图像中像素高分辨率的问题。在ViT中，图像被切成方形的补丁。作为ViT的后续，Swin Transformer提出了一个额外的移位步骤以减少固定边界的存在，这也导致“两个连接的Swin Transformer块”成为模型的最小单位。继承了补丁/窗口的想法，我们的圆环核进一步增强了补丁的设计。它用传感器和更新两种区域代替了线型边界，这是基于自我关注的理解（称为QKVA网格）。圆环核还带来了一个关于核形状的新话题，超越了方形。为了验证其在图像分类上的性能，PAT被设计为由定期八边形形状的Transformer块组成。

    We present in this paper a new architecture, the Pattern Attention Transformer (PAT), that is composed of the new doughnut kernel. Compared with tokens in the NLP field, Transformer in computer vision has the problem of handling the high resolution of pixels in images. In ViT, an image is cut into square-shaped patches. As the follow-up of ViT, Swin Transformer proposes an additional step of shifting to decrease the existence of fixed boundaries, which also incurs 'two connected Swin Transformer blocks' as the minimum unit of the model. Inheriting the patch/window idea, our doughnut kernel enhances the design of patches further. It replaces the line-cut boundaries with two types of areas: sensor and updating, which is based on the comprehension of self-attention (named QKVA grid). The doughnut kernel also brings a new topic about the shape of kernels beyond square. To verify its performance on image classification, PAT is designed with Transformer blocks of regular octagon shape doughn
    
[^103]: 一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法

    An Isolation-Aware Online Virtual Network Embedding via Deep Reinforcement Learning. (arXiv:2211.14158v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2211.14158](http://arxiv.org/abs/2211.14158)

    本文提出了一种基于深度强化学习的隔离感知在线虚拟网络嵌入方法，以解决虚拟网络环境中多个VN共存可能导致隔离问题的挑战。

    

    虚拟化技术是现代ICT基础设施的基础，它使服务提供商能够创建支持各种智能城市应用的专用虚拟网络（VN）。这些VN不断产生大量数据，需要严格的可靠性和安全性要求。然而，在虚拟化网络环境中，多个VN可能共存于同一物理基础设施上，如果隔离不当，则可能相互干扰或提供未经授权的访问。前者会导致性能降低，后者会破坏VN的安全性。当特定VN违反隔离要求时，基础设施提供商的服务保障变得更加复杂。为解决隔离问题，本文提出在虚拟网络嵌入（VNE）期间进行隔离，即将VN分配到物理基础设施上的过程。

    Virtualization technologies are the foundation of modern ICT infrastructure, enabling service providers to create dedicated virtual networks (VNs) that can support a wide range of smart city applications. These VNs continuously generate massive amounts of data, necessitating stringent reliability and security requirements. In virtualized network environments, however, multiple VNs may coexist on the same physical infrastructure and, if not properly isolated, may interfere with or provide unauthorized access to one another. The former causes performance degradation, while the latter compromises the security of VNs. Service assurance for infrastructure providers becomes significantly more complicated when a specific VN violates the isolation requirement.  In an effort to address the isolation issue, this paper proposes isolation during virtual network embedding (VNE), the procedure of allocating VNs onto physical infrastructure. We define a simple abstracted concept of isolation levels t
    
[^104]: 一种可解释的机器学习系统来识别癫痫-间隙-损伤连续状态下的脑电图图案

    An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum. (arXiv:2211.05207v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05207](http://arxiv.org/abs/2211.05207)

    该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。

    

    在许多医学领域，人们呼吁在用于临床工作的机器学习系统中增加可解释性。在本文中，我们设计了一个可解释的深度学习模型，用于预测ICU脑电监测中常见的6种脑波图案（癫痫、LPD、GPD、LRDA、GRDA、其他）的存在。每个预测都配有一个高质量的解释，借助于专门的用户界面提供支持。此新型模型架构学习了一组原型示例（“原型”），并通过将新的EEG片段与这些原型进行比较来做出决策。这些原型可以是单类（仅与一个类相关）或双类（与两个类相关）。我们提出了三种主要的模型解释方法：1）使用全局结构保持方法，将1275维cEEG潜在特征映射到二维空间中，可视化癫痫-间隙-损伤连续状态，从而深入了解其高维结构。2）我们提出了一种交互式解释方法，使人类专家能够查询模型预测的不同方面，并以自然语言接收经过专家验证的解释。3）我们可视化了导致模型做出某个决策的输入的最重要特征，允许详细检查输入和输出之间的关系。总的来说，我们展示了解释性模型分类EEG图案和提供专家友好的解释的实用性，这两个方面对于建立AI的信任和临床采用至关重要。

    In many medical subfields, there is a call for greater interpretability in the machine learning systems used for clinical work. In this paper, we design an interpretable deep learning model to predict the presence of 6 types of brainwave patterns (Seizure, LPD, GPD, LRDA, GRDA, other) commonly encountered in ICU EEG monitoring. Each prediction is accompanied by a high-quality explanation delivered with the assistance of a specialized user interface. This novel model architecture learns a set of prototypical examples (``prototypes'') and makes decisions by comparing a new EEG segment to these prototypes. These prototypes are either single-class (affiliated with only one class) or dual-class (affiliated with two classes).  We present three main ways of interpreting the model: 1) Using global-structure preserving methods, we map the 1275-dimensional cEEG latent features to a 2D space to visualize the ictal-interictal-injury continuum and gain insight into its high-dimensional structure. 2
    
[^105]: 自监督语音模型的逐层比较分析

    Comparative layer-wise analysis of self-supervised speech models. (arXiv:2211.03929v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.03929](http://arxiv.org/abs/2211.03929)

    本论文通过比较不同自监督语音模型的逐层中间表示，发现了不同模型在编码声学、语音和单词级属性上的差异，并发现这些差异与预训练目标的选择相关。通过比较属性趋势和语音识别和口语理解任务的性能，我们发现CCA趋势为选择层次提供了可靠的指导。

    

    在过去几年中，许多不同预训练目标、输入形式和预训练数据的自监督语音模型被提出。尽管在下游任务中取得了惊人的成功，我们仍然对这些模型编码的属性及其差异了解有限。在本研究中，我们使用基于规范相关分析(CCA)的轻量级分析工具，检查了多个最近模型的中间表示。具体而言，我们测量了单个层次中编码的声学、语音和单词级属性，发现这些属性在不同模型中的层次演变方式不同，且变化与预训练目标的选择相关。我们通过比较属性趋势和语音识别和口语理解任务的性能，进一步研究了我们的分析在下游任务中的应用价值。发现CCA趋势为选择层次提供了可靠的指导。

    Many self-supervised speech models, varying in their pre-training objective, input modality, and pre-training data, have been proposed in the last few years. Despite impressive successes on downstream tasks, we still have a limited understanding of the properties encoded by the models and the differences across models. In this work, we examine the intermediate representations for a variety of recent models. Specifically, we measure acoustic, phonetic, and word-level properties encoded in individual layers, using a lightweight analysis tool based on canonical correlation analysis (CCA). We find that these properties evolve across layers differently depending on the model, and the variations relate to the choice of pre-training objective. We further investigate the utility of our analyses for downstream tasks by comparing the property trends with performance on speech recognition and spoken language understanding tasks. We discover that CCA trends provide reliable guidance to choose laye
    
[^106]: AI时代的责任制度：基于用例的证明负担分析

    Liability regimes in the age of AI: a use-case driven analysis of the burden of proof. (arXiv:2211.01817v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.01817](http://arxiv.org/abs/2211.01817)

    本文通过用例分析探讨了基于AI技术的责任制度下证明负担的挑战和规则改革的建议。

    

    由人工智能（AI）驱动的新兴技术有可能为我们的社会带来颠覆性的转型，并推进各种应用领域的多项技术的发展，其中数据驱动的学习方法（即机器学习（ML））是一次真正的革命。但与此同时，人们越来越关注这些方法学固有的某些特征，这些特征可能对安全和基本权利带来潜在风险。尽管在采用过程中有机制来最小化这些风险（例如安全规定），但这并不排除损害发生的可能，如果这种情况发生，受害者应该能够寻求补偿。因此，责任制度将在确保使用或与这些系统交互的受害者的基本保护方面发挥关键作用。然而，使AI系统固有风险的相同特征，例如缺乏因果关系、不透明、不可预测或他们自我和自适应的本质，也使得传统的责任规则难以应用。本文通过对各种用例及其潜在危害的分析，提出了基于用例的责任规则证明负担分析，识别了当前责任规则在AI技术领域面临的挑战，并探讨了改革这些规则的建议。

    New emerging technologies powered by Artificial Intelligence (AI) have the potential to disruptively transform our societies for the better. In particular, data-driven learning approaches (i.e., Machine Learning (ML)) have been a true revolution in the advancement of multiple technologies in various application domains. But at the same time there is growing concern about certain intrinsic characteristics of these methodologies that carry potential risks to both safety and fundamental rights. Although there are mechanisms in the adoption process to minimize these risks (e.g., safety regulations), these do not exclude the possibility of harm occurring, and if this happens, victims should be able to seek compensation. Liability regimes will therefore play a key role in ensuring basic protection for victims using or interacting with these systems. However, the same characteristics that make AI systems inherently risky, such as lack of causality, opacity, unpredictability or their self and 
    
[^107]: RGMIM: 区域引导的掩膜图像建模用于COVID-19检测。

    RGMIM: Region-Guided Masked Image Modeling for COVID-19 Detection. (arXiv:2211.00313v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.00313](http://arxiv.org/abs/2211.00313)

    本论文提出了一种针对COVID-19检测的新颖区域引导的掩膜图像建模方法，该方法通过利用肺掩模信息来识别有效区域，以学习更有用的COVID-19检测信息。

    

    目的：自监督学习正在快速推进医学领域的计算机辅助诊断。掩膜图像建模（MIM）是一种自监督学习方法，它掩盖了一组输入像素并试图预测遮盖的像素。传统的MIM方法通常采用随机掩膜策略。与普通图像相比，医学图像往往具有用于疾病检测的小区域。因此，我们在本文中专注于解决这个问题，在自动COVID-19识别方面进行评估。方法：本文提出了一种新颖的区域引导的掩膜图像建模方法（RGMIM）用于COVID-19检测。在我们的方法中，我们设计了一种新的掩膜策略，利用肺掩模信息来识别有效区域，以学习更有用的COVID-19检测信息。我们将所提出的方法与五种自监督学习技术（MAE，SKD，Cross，BYOL和SimSiam）进行对比。我们提出了定量评估。

    Purpose: Self-supervised learning is rapidly advancing computer-aided diagnosis in the medical field. Masked image modeling (MIM) is one of the self-supervised learning methods that masks a subset of input pixels and attempts to predict the masked pixels. Traditional MIM methods often employ a random masking strategy. In comparison to ordinary images, medical images often have a small region of interest for disease detection. Consequently, we focus on fixing the problem in this work, which is evaluated by automatic COVID-19 identification. Methods: In this study, we propose a novel region-guided masked image modeling method (RGMIM) for COVID-19 detection in this paper. In our method, we devise a new masking strategy that employed lung mask information to identify valid regions to learn more useful information for COVID-19 detection. The proposed method was contrasted with five self-supervised learning techniques (MAE, SKD, Cross, BYOL, and, SimSiam). We present a quantitative evaluatio
    
[^108]: 一种利用集合建模、注释的归一化分布和熵测量的不精确、众包数据集的方法

    An Approach for Noisy, Crowdsourced Datasets Utilizing Ensemble Modeling, Normalized Distributions of Annotations, and Entropic Measures of Uncertainty. (arXiv:2210.16380v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.16380](http://arxiv.org/abs/2210.16380)

    在众包图像数据集上的分类是具有挑战性的。本文提出了一种利用集合建模、注释的归一化分布和熵测量的方法，以帮助识别标签不确定的图像，并量化这些样本的可信度。

    

    在不精确的、众包的图像数据集上进行分类对于最好的神经网络来说都是具有挑战性的。两个问题使得这类数据集上的问题更加复杂，即类别不平衡和标签的不确定性。AL-ALL和AL-PUB数据集--包含来自古希腊纸草的图像的紧密裁剪的单个字符--受到这两个问题的严重影响。将集合建模应用于这样的数据集可以帮助识别标签不确定的图像，并量化这些样本的可信度。因此，我们应用由几乎相同的ResNets组成的堆叠泛化，它们具有不同的损失函数：一个利用稀疏交叉熵（CXE），另一个利用Kullback-Liebler散度（KLD）。两个网络都使用从众包一致性中得出的标签。对于第二个网络，KLD是相对于所提出的注释的归一化分布（NDA）计算的。对于我们的集合模型，我们应用k-近邻算法。

    Performing classification on noisy, crowdsourced image datasets can prove challenging even for the best neural networks. Two issues which complicate the problem on such datasets are class imbalance and ground-truth uncertainty in labeling. The AL-ALL and AL-PUB datasets -- consisting of tightly cropped, individual characters from images of ancient Greek papyri -- are strongly affected by both issues. The application of ensemble modeling to such datasets can help identify images where the ground-truth is questionable and quantify the trustworthiness of those samples. As such, we apply stacked generalization consisting of nearly identical ResNets with different loss functions: one utilizing sparse cross-entropy (CXE) and the other Kullback-Liebler Divergence (KLD). Both networks use labels drawn from the crowdsourced consensus. For the second network, the KLD is calculated with respect to the proposed Normalized Distribution of Annotations (NDA). For our ensemble model, we apply a k-near
    
[^109]: 利用大型语言模型进行多项选择题的答案推断

    Leveraging Large Language Models for Multiple Choice Question Answering. (arXiv:2210.12353v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.12353](http://arxiv.org/abs/2210.12353)

    本文研究了利用大型语言模型进行多项选择题的答案推断，并探讨了一种更自然的问题提示方式，以提高准确性。

    

    大型语言模型如GPT-3在多项选择题答案推断任务中已经取得了令人瞩目的成果。然而，它们通常落后于多项选择题的最新研究成果。本文探讨了一种更自然的问题提示方式，即将问题和答案选项联合呈现给大型语言模型，以便模型能够明确比较答案选项，减少计算成本，降低标记化方案和答案选项表示对答案选择的影响。

    While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks. An LLM is conditioned on a question (without the associated answer options) and its chosen option is the one assigned the highest probability after normalization (for length, etc.). A more natural prompting approach is to present the question and answer options to the LLM jointly and have it output the symbol (e.g., "A") associated with its chosen answer option. This approach allows the model to explicitly compare answer options, reduces computational costs, and mitigates the effects of tokenization scheme and answer option representations on answer selection. For the natural approach to be effective, the LLM it is used with must be able to associate answer options with the symbols that re
    
[^110]: 演员评论或评论演员？两个时间尺度的故事。

    Actor-Critic or Critic-Actor? A Tale of Two Time Scales. (arXiv:2210.04470v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04470](http://arxiv.org/abs/2210.04470)

    这篇论文提出了一种评论演员算法，它在快速和慢速时间尺度上计算价值函数和策略，该算法与演员评论算法在准确性和计算成本方面表现相当。

    

    我们重新审视基于表格的演员评论算法的标准公式，将其视为两个时间尺度的随机逼近，其中价值函数在快速时间尺度上计算，策略在慢速时间尺度上计算。这模拟了策略迭代。我们首先观察到，时间尺度的反转实际上会模拟值迭代，并且是一种合法的算法。我们提供了收敛性证明，并通过带有线性和非线性函数逼近器的函数逼近测试两种方法，并观察到我们提出的评论演员算法在准确性和计算成本方面与演员评论算法相当。

    We revisit the standard formulation of tabular actor-critic algorithm as a two time-scale stochastic approximation with value function computed on a faster time-scale and policy computed on a slower time-scale. This emulates policy iteration. We begin by observing that reversal of the time scales will in fact emulate value iteration and is a legitimate algorithm. We provide a proof of convergence and compare the two empirically with and without function approximation (with both linear and nonlinear function approximators) and observe that our proposed critic-actor algorithm performs on par with actor-critic in terms of both accuracy and computational effort.
    
[^111]: 自蒸馏在Transformer进一步预训练中的应用

    Self-Distillation for Further Pre-training of Transformers. (arXiv:2210.02871v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.02871](http://arxiv.org/abs/2210.02871)

    本文提出了自蒸馏作为进一步预训练阶段的正则化方法，用于解决Vision Transformer在目标未标注数据集上过拟合问题，实现了在多项基准数据集上的最先进结果。

    

    在大量无标注数据上对Transformer模型进行预训练并在标记数据集上进行微调已被证明是一种成功的策略，适用于不同的视觉和自然语言处理任务。然而，如果在预训练和微调之间存在大的数据领域上的差异，则直接微调预训练模型可能是次优的。为了解决这个问题，前人提出了进一步预训练策略，即在目标未标注数据集上继续预训练模型，但所有这些方法都仅关注于语言模型。我们发现在对目标未标注数据集进行预训练时，Vision Transformer容易出现过拟合问题。为解决这一问题，我们提出了自蒸馏作为进一步预训练阶段的正则化。具体地，我们首先在目标未标注数据集上进一步预训练初始预训练模型，然后将从进一步训练模型中提取的知识蒸馏到初始预训练模型中。在三个不同的视觉任务上的实验表明，我们提出的自蒸馏方法始终提高了初始预训练Vision Transformer的性能，优于先前的进一步预训练方法，并在几个基准数据集上实现了最先进的结果。

    Pre-training a large transformer model on a massive amount of unlabeled data and fine-tuning it on labeled datasets for diverse downstream tasks has proven to be a successful strategy, for a variety of vision and natural language processing tasks. However, direct fine-tuning of the pre-trained model may be suboptimal if there exist large discrepancies across data domains for pre-training and fine-tuning. To tackle this issue, several previous studies have proposed further pre-training strategies, where we continue to pre-train the model on the target unlabeled dataset before fine-tuning. However, all of them solely focus on language models and we empirically find that a Vision Transformer is vulnerable to overfitting as we continue to pretrain the model on target unlabeled data. In order to tackle this limitation, we propose self-distillation as a regularization for a further pre-training stage. Specifically, we first further pre-train the initial pre-trained model on the target unlabe
    
[^112]: 重新审视医学图像分割:极度有限标签下的医学图像分割

    Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels. (arXiv:2209.13476v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.13476](http://arxiv.org/abs/2209.13476)

    提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    

    最近，关于对比学习的研究在医学图像分割的背景下仅凭借几个标签取得了卓越的性能。现有方法主要集中在实体区分和不变映射上。然而，它们面临三个常见瓶颈：(1)尾部分布：医学图像数据通常遵循隐含的长尾类分布。盲目利用所有训练像素可能导致数据不平衡问题，并导致性能恶化；(2)一致性：由于不同解剖特征之间的类内变化，分割模型是否学会了有意义且一致的解剖特征仍不清楚；以及(3)多样性：整个数据集内部切片的相关性受到的关注显著较少。这促使我们寻找一个基于数据集本身的策略方法，从不同的解剖视图中发现相似但不同的样本。在本文中，我们介绍了一个新的框架，称为MOAN，用于极度有限标签下的医学图像分割。 MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。前者提取共同依赖的像素区域，而后者强制网络学习有意义的解剖学表示。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    Recent studies on contrastive learning have achieved remarkable performance solely by leveraging few labels in the context of medical image segmentation. Existing methods mainly focus on instance discrimination and invariant mapping. However, they face three common pitfalls: (1) tailness: medical image data usually follows an implicit long-tail class distribution. Blindly leveraging all pixels in training hence can lead to the data imbalance issues, and cause deteriorated performance; (2) consistency: it remains unclear whether a segmentation model has learned meaningful and yet consistent anatomical features due to the intra-class variations between different anatomical features; and (3) diversity: the intra-slice correlations within the entire dataset have received significantly less attention. This motivates us to seek a principled approach for strategically making use of the dataset itself to discover similar yet distinct samples from different anatomical views. In this paper, we i
    
[^113]: AirTrack：用于长程飞机检测和跟踪的机载深度学习框架

    AirTrack: Onboard Deep Learning Framework for Long-Range Aircraft Detection and Tracking. (arXiv:2209.12849v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.12849](http://arxiv.org/abs/2209.12849)

    AirTrack是一个用于小型无人机系统的实时视觉检测和跟踪框架，使用全分辨率图像和深度学习框架以提高检测和跟踪性能。实验结果显示，在Amazon AOT数据集上表现出优越性。同时，多次真实世界中进行的飞行测试均显示该方法的有效性。

    

    无人机系统安全运行需要具备检测和避免碰撞（DAA）能力。本文引入了AirTrack，这是一个实时的、仅使用视觉信息的检测和跟踪框架，考虑了小型无人机系统的大小、重量和功耗（SWaP）限制。鉴于远程飞机的低信噪比（SNR），我们提出使用全分辨率图像，使用深度学习框架对齐连续图像以消除自我运动。对齐后的图像在级联的主要和次要分类器中使用，以提高多个指标的检测和跟踪性能。我们展示了AirTrack在Amazon空中物体跟踪（AOT）数据集上优于最先进的基准线。多次在真实世界中进行的飞行测试，包括与通用航空交通互动的Cessna 182和Bell直升机向受控飞行无人机靠近的附近碰撞飞行测试显示，该方法满足新引入的A要求。

    Detect-and-Avoid (DAA) capabilities are critical for safe operations of unmanned aircraft systems (UAS). This paper introduces, AirTrack, a real-time vision-only detect and tracking framework that respects the size, weight, and power (SWaP) constraints of sUAS systems. Given the low Signal-to-Noise ratios (SNR) of far away aircraft, we propose using full resolution images in a deep learning framework that aligns successive images to remove ego-motion. The aligned images are then used downstream in cascaded primary and secondary classifiers to improve detection and tracking performance on multiple metrics. We show that AirTrack outperforms state-of-the art baselines on the Amazon Airborne Object Tracking (AOT) Dataset. Multiple real world flight tests with a Cessna 182 interacting with general aviation traffic and additional near-collision flight tests with a Bell helicopter flying towards a UAS in a controlled setting showcase that the proposed approach satisfies the newly introduced A
    
[^114]: 基于关键点的单目RGB-D输入下的六自由度抓取点生成

    Keypoint-GraspNet: Keypoint-based 6-DoF Grasp Generation from the Monocular RGB-D input. (arXiv:2209.08752v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.08752](http://arxiv.org/abs/2209.08752)

    本文提出了一种基于关键点的单目RGB-D输入下的六自由度抓取点生成方法，该方法可以通过PnP算法恢复SE(3)姿态。机器人实验表明，我们的方法在抓取点提案的精度、多样性和时间成本方面优于其他方法并具有很强的应用潜力。

    

    目前已经在点云输入的六自由度抓取点学习中取得了很大的成功，但由于点集无序性而导致的计算成本仍然是一个问题。本文探索了从RGB-D输入中生成抓取点的方法。我们提出了Keypoint-GraspNet解决方案，该方案在图像空间中检测夹持器关键点的投影，然后使用PnP算法恢复SE(3)姿态。基于三维形体和抓取家族构建了一个合成数据集来检验我们的想法。基于度量的评估表明，我们的方法在抓取点提案的精度、多样性和时间成本方面优于基线。最后，机器人实验展示了高成功率，证明了这种方法在实际应用中的潜力。

    Great success has been achieved in the 6-DoF grasp learning from the point cloud input, yet the computational cost due to the point set orderlessness remains a concern. Alternatively, we explore the grasp generation from the RGB-D input in this paper. The proposed solution, Keypoint-GraspNet, detects the projection of the gripper keypoints in the image space and then recover the SE(3) poses with a PnP algorithm. A synthetic dataset based on the primitive shape and the grasp family is constructed to examine our idea. Metric-based evaluation reveals that our method outperforms the baselines in terms of the grasp proposal accuracy, diversity, and the time cost. Finally, robot experiments show high success rate, demonstrating the potential of the idea in the real-world applications.
    
[^115]: 在Twitter上检测命名实体和标签的政治偏见

    Detecting Political Biases of Named Entities and Hashtags on Twitter. (arXiv:2209.08110v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2209.08110](http://arxiv.org/abs/2209.08110)

    本篇论文旨在通过分析Twitter上的命名实体和标签的使用来检测文本中的政治偏见，并分配极性分数进行量化。

    

    美国的意识形态分歧在日常交流中变得日益突出。因此，有很多关于政治极化的研究，包括许多最近从计算的角度来看的研究。通过检测文本语料中的政治偏见，可以尝试描述和区分该文本的情感极性。直观地说，文本中的命名实体（即充当名词的名词和短语）和标签通常都携带有关政治观点的信息。在本文中，我们试图揭示社交媒体文本数据中的政治极性，并通过明确地为实体和标签分配极性分数来量化这些极性。尽管这个想法很直观，但是以可信的数量方式执行这样的推断很困难。主要挑战包括实体和标签的数量较少。

    Ideological divisions in the United States have become increasingly prominent in daily communication. Accordingly, there has been much research on political polarization, including many recent efforts that take a computational perspective. By detecting political biases in a corpus of text, one can attempt to describe and discern the polarity of that text. Intuitively, the named entities (i.e., the nouns and the phrases that act as nouns) and hashtags in text often carry information about political views. For example, people who use the term "pro-choice" are likely to be liberal, whereas people who use the term "pro-life" are likely to be conservative. In this paper, we seek to reveal political polarities in social-media text data and to quantify these polarities by explicitly assigning a polarity score to entities and hashtags. Although this idea is straightforward, it is difficult to perform such inference in a trustworthy quantitative way. Key challenges include the small number of k
    
[^116]: 带有输入限制的随机线性系统学习自适应控制

    Learning-Based Adaptive Control for Stochastic Linear Systems with Input Constraints. (arXiv:2209.07040v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2209.07040](http://arxiv.org/abs/2209.07040)

    本文提出了一种新的自适应控制方案，用于具有输入限制的随机线性系统，无需先验参数信息。

    

    本文提出了一种确定等价方案，用于自适应控制受加性、独立同分布高斯扰动和有界控制输入约束的标量线性系统，无需先知道系统参数边界或控制方向。 假设系统最差情况下是边缘稳定的，证明了闭环系统状态的平方均值有界性。最后，提供了数值例子来说明我们的结果。

    We propose a certainty-equivalence scheme for adaptive control of scalar linear systems subject to additive, i.i.d. Gaussian disturbances and bounded control input constraints, without requiring prior knowledge of the bounds of the system parameters, nor the control direction. Assuming that the system is at-worst marginally stable, mean square boundedness of the closed-loop system states is proven. Lastly, numerical examples are presented to illustrate our results.
    
[^117]: Treeformer: 稠密梯度树实现高效注意力计算

    Treeformer: Dense Gradient Trees for Efficient Attention Computation. (arXiv:2208.09015v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2208.09015](http://arxiv.org/abs/2208.09015)

    本文提出了Treeformer，一种基于决策树的分层导航方法，用于高效地计算注意力。与传统的注意力计算方法相比，Treeformer 可以将检索成本从线性降为近似对数级别，并提供两种有效的关注层。算法的目标是处理输入序列长度过长的应用，提高计算效率。

    

    基于Transformer架构的推理和训练的时间复杂度和输入序列长度成二次关系，这对于一些应用如网页翻译和查询-回答等速度要求较高的应用是不可行的。因此，为了加速注意力计算，近期提出了多种方法，如强制使用不同的注意力结构，如稀疏、低秩、使用核函数逼近。本文提出一种将注意力计算看作最近邻检索的方法，利用基于决策树的分层导航，将每个查询标记的检索成本从线性降为近似对数级别。基于这种分层导航，我们设计出Treeformer，它可以使用两种有效的关注层-- TF-Attention和TC-Attention。TF-Attention以细粒度方式计算其中的关注，而TC-Attention是一种更粗粒度的关注层，也确保梯度是“密集”的。

    Standard inference and training with transformer based architectures scale quadratically with input sequence length. This is prohibitively large for a variety of applications especially in web-page translation, query-answering etc. Consequently, several approaches have been developed recently to speedup attention computation by enforcing different attention structures such as sparsity, low-rank, approximating attention using kernels. In this work, we view attention computation as that of nearest neighbor retrieval, and use decision tree based hierarchical navigation to reduce the retrieval cost per query token from linear in sequence length to nearly logarithmic. Based on such hierarchical navigation, we design Treeformer which can use one of two efficient attention layers -- TF-Attention and TC-Attention. TF-Attention computes the attention in a fine-grained style, while TC-Attention is a coarse attention layer which also ensures that the gradients are "dense". To optimize such challe
    
[^118]: 简单的差分隐私线性回归

    Easy Differentially Private Linear Regression. (arXiv:2208.07353v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.07353](http://arxiv.org/abs/2208.07353)

    本文研究了一种简单的差分隐私线性回归算法，它使用指数机制从一组非私有回归模型中选择具有高Tukey深度的模型，并在无需数据边界和超参数选择的数据丰富环境中获得了强大的实证表现。

    

    线性回归是统计分析的基础工具。这促使开发出满足差分隐私的线性回归方法，从而保证学习的模型泄露的个人数据信息很少。然而，现有的差分隐私解决方案假定最终用户可以轻松指定好的数据边界和超参数，但两者都存在实际障碍。在本文中，我们研究了一种算法，该算法使用指数机制从一组非私有回归模型中选择具有高 Tukey 深度的模型。给定用于训练 $m$ 个模型的 $n$ 个 $d$ 维数据样本，我们使用近似的 Tukey 深度构造了一个高效的类比，它的运行时间为 $O(d^2n + dm\log(m))$。我们发现，该算法在无数据边界或超参数选择要求的数据丰富环境中获得了强大的实证表现。

    Linear regression is a fundamental tool for statistical analysis. This has motivated the development of linear regression methods that also satisfy differential privacy and thus guarantee that the learned model reveals little about any one data point used to construct it. However, existing differentially private solutions assume that the end user can easily specify good data bounds and hyperparameters. Both present significant practical obstacles. In this paper, we study an algorithm which uses the exponential mechanism to select a model with high Tukey depth from a collection of non-private regression models. Given $n$ samples of $d$-dimensional data used to train $m$ models, we construct an efficient analogue using an approximate Tukey depth that runs in time $O(d^2n + dm\log(m))$. We find that this algorithm obtains strong empirical performance in the data-rich setting with no data bounds or hyperparameter selection required.
    
[^119]: 不对称模型中近似信息传递的非渐近框架

    A Non-Asymptotic Framework for Approximate Message Passing in Spiked Models. (arXiv:2208.03313v2 [math.ST] UPDATED)

    [http://arxiv.org/abs/2208.03313](http://arxiv.org/abs/2208.03313)

    本文提出了一个非渐进的AMP理论框架，用于理解高维统计问题，解决了以往AMP理论的不足。我们的方法可以有效地预测AMP在独立初始化和谱初始化情况下的有限样本行为。

    

    近似信息传递（AMP）作为一种高效的迭代范式，已经被广泛应用于高维统计问题的求解中。然而，以往AMP理论主要集中在高维渐近性方面，未能预测当迭代次数超过$o\big(\frac{\log n}{\log\log n}\big)$（其中$n$是问题的维度）时AMP的动态。为了解决这个问题，本文建立了一个非渐近的框架，用于理解锥形矩阵估计中的AMP。我们基于新的AMP更新分解和可控残差项，提出了一种分析方法，以表征独立初始化情况下AMP的有限样本行为，并进一步推广到包括谱初始化的情况。作为这种分析方法的两个具体应用，当解决$\mathbb{Z}_2$同步问题时，我们预测了谱初始化AMP的行为，最多可以进行$O\big(\frac{n}{\mathrm{poly}\log n}\big)$个迭代。

    Approximate message passing (AMP) emerges as an effective iterative paradigm for solving high-dimensional statistical problems. However, prior AMP theory -which focused mostly on high-dimensional asymptotics -- fell short of predicting the AMP dynamics when the number of iterations surpasses $o\big(\frac{\log n}{\log\log n}\big)$ (with $n$ the problem dimension). To address this inadequacy, this paper develops a non-asymptotic framework for understanding AMP in spiked matrix estimation. Built upon new decomposition of AMP updates and controllable residual terms, we lay out an analysis recipe to characterize the finite-sample behavior of AMP in the presence of an independent initialization, which is further generalized to allow for spectral initialization. As two concrete consequences of the proposed analysis recipe: (i) when solving $\mathbb{Z}_2$ synchronization, we predict the behavior of spectrally initialized AMP for up to $O\big(\frac{n}{\mathrm{poly}\log n}\big)$ iterations, sh
    
[^120]: 利用弱监督检测变形器扩展新型物品检测

    Scaling Novel Object Detection with Weakly Supervised Detection Transformers. (arXiv:2207.05205v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.05205](http://arxiv.org/abs/2207.05205)

    本篇文章提出了一个新方法：弱监督检测变形器（Weakly Supervised Detection Transformer），可以有效地将大规模预训练数据集的知识转移至数百种新型物品的WSOD微调中，同时提高了多实例学习的准确性。实验结果表明，该方法优于现有的先进模型，在大规模新型物品检测数据集上达到了更好的性能。

    

    目标检测中一个关键任务是微调现有模型以便检测新型物品，但标注边界框需要耗费大量的时间和金钱。弱监督目标检测可以通过使用图像级别标签来训练物品检测器，它提供了一种吸引人的替代方法。然而，当前弱监督模型的实际应用受到限制，因为它们仅适用于小规模数据，并需要多次训练和改进。为了解决这个问题，我们提出了弱监督检测变形器，它能够将大规模预训练数据集的知识有效地转移至数百种新型物品的WSOD微调中。此外，我们还利用预训练知识来改进在WSOD方法中常用的多实例学习（MIL）框架。实验证明，我们的方法在大规模新型物品检测数据集上优于先前的最先进模型，并且我们的扩展研究…

    A critical object detection task is finetuning an existing model to detect novel objects, but the standard workflow requires bounding box annotations which are time-consuming and expensive to collect. Weakly supervised object detection (WSOD) offers an appealing alternative, where object detectors can be trained using image-level labels. However, the practical application of current WSOD models is limited, as they only operate at small data scales and require multiple rounds of training and refinement. To address this, we propose the Weakly Supervised Detection Transformer, which enables efficient knowledge transfer from a large-scale pretraining dataset to WSOD finetuning on hundreds of novel objects. Additionally, we leverage pretrained knowledge to improve the multiple instance learning (MIL) framework often used in WSOD methods. Our experiments show that our approach outperforms previous state-of-the-art models on large-scale novel object detection datasets, and our scaling study r
    
[^121]: 从表示学习的角度探索更客观的评价类增量学习

    Towards More Objective Evaluation of Class Incremental Learning: Representation Learning Perspective. (arXiv:2206.08101v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.08101](http://arxiv.org/abs/2206.08101)

    本文提出了利用表示学习对类增量学习进行客观评估的方法，并实验分析了CIL算法训练的神经网络模型，发现大多数最新算法优先考虑高稳定性，但仍然能够实现高测试准确率。

    

    类增量学习（CIL）是指在不忘记已经学习的类别的情况下，不断地从增量数据中学习新的对象类别的过程。虽然评估CIL算法的常见方法是基于所有已学习类别的平均测试准确率，但我们认为仅仅最大化准确率并不一定能导致有效的CIL算法。本文通过在表示学习中使用各种评估协议实验分析CIL算法训练的神经网络模型，并提出了一种新的分析方法。我们的实验表明，大多数最先进的算法优先考虑高稳定性，且没有显著改变学习的表示，有时甚至学习了比朴素基线更差的表示。但我们观察到这些算法仍然可以实现高测试准确率，因为它们学习了更接近最优分类器的分类器。我们还发现，第一个任务中学习的基模型会有所不同。

    Class incremental learning (CIL) is the process of continually learning new object classes from incremental data while not forgetting past learned classes. While the common method for evaluating CIL algorithms is based on average test accuracy for all learned classes, we argue that maximizing accuracy alone does not necessarily lead to effective CIL algorithms. In this paper, we experimentally analyze neural network models trained by CIL algorithms using various evaluation protocols in representation learning and propose a new analysis method. Our experiments show that most state-of-the-art algorithms prioritize high stability and do not significantly change the learned representation, and sometimes even learn a representation of lower quality than a naive baseline. However, we observe that these algorithms can still achieve high test accuracy because they learn a classifier that is closer to the optimal classifier. We also found that the base model learned in the first task varies in 
    
[^122]: 设备采样下的推拉式分布式优化

    Push--Pull with Device Sampling. (arXiv:2206.04113v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.04113](http://arxiv.org/abs/2206.04113)

    我们提出了一种算法，采用梯度跟踪和网络级方差减少相结合的方法来解决异步分布式优化问题。该算法能够实现每个节点跟踪目标函数梯度的平均值，并在局部目标函数强凸的情况下，通过减少预期混合矩阵的温和连接条件实现线性收敛。

    

    我们考虑分布式优化问题，其中一些代理以交换并通过基础通信图减少其本地函数的平均值。具体而言，我们将自己放在异步模型中，其中每次迭代只有随机部分节点执行计算，而信息交换可以在所有节点之间以非对称的方式进行。针对这种情况，我们提出了一种算法，将梯度跟踪与网络级别的方差减少相结合（与每个节点内的方差减少相对比）。这使每个节点能够跟踪目标函数的梯度平均值。我们的理论分析表明，当局部目标函数强凸时，该算法线性收敛，在预期混合矩阵的温和连接条件下。特别是，我们的结果不要求混合矩阵具有双重随机性。在实验中，我们研究了一个...

    We consider decentralized optimization problems in which a number of agents collaborate to minimize the average of their local functions by exchanging over an underlying communication graph. Specifically, we place ourselves in an asynchronous model where only a random portion of nodes perform computation at each iteration, while the information exchange can be conducted between all the nodes and in an asymmetric fashion. For this setting, we propose an algorithm that combines gradient tracking with a network-level variance reduction (in contrast to variance reduction within each node). This enables each node to track the average of the gradients of the objective functions. Our theoretical analysis shows that the algorithm converges linearly, when the local objective functions are strongly convex, under mild connectivity conditions on the expected mixing matrices. In particular, our result does not require the mixing matrices to be doubly stochastic. In the experiments, we investigate a
    
[^123]: 组合算法的反向传播：使用投影进行的恒等变换。

    Backpropagation through Combinatorial Algorithms: Identity with Projection Works. (arXiv:2205.15213v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15213](http://arxiv.org/abs/2205.15213)

    本文提出了一种基于离散解空间几何的原则方法，将求解器视为负恒等变换，以在反向传播时寻找有意义的替代方案，避免使用通过投影平滑求解器、将求解器松弛为连续问题或者通过技术对损失面貌进行插值等更复杂的方法，从而在离散求解器和深度图等情景中发挥作用。

    

    将离散求解器嵌入可微分层中，赋予了现代深度学习架构组合表达能力和离散推理能力。这些求解器的导数为零或未定义，因此寻找有意义的替代方案对于有效的基于梯度的学习至关重要。之前的作品依赖于使用输入扰动平滑求解器、将求解器松弛为连续问题或者通过技术对损失面貌进行插值，这些方法通常需要额外的求解器调用、引入额外的超参数或者牺牲性能。我们提出了一种基于离散解空间几何的原则方法，以在反向传播时将求解器视为负恒等变换，并提供了理论证明。我们的实验证明，这种简单、无超参数的方法能够在许多实验中与之前更复杂的方法竞争，例如在离散采样器、深度图中进行的反向传播。

    Embedding discrete solvers as differentiable layers has given modern deep learning architectures combinatorial expressivity and discrete reasoning capabilities. The derivative of these solvers is zero or undefined, therefore a meaningful replacement is crucial for effective gradient-based learning. Prior works rely on smoothing the solver with input perturbations, relaxing the solver to continuous problems, or interpolating the loss landscape with techniques that typically require additional solver calls, introduce extra hyper-parameters, or compromise performance. We propose a principled approach to exploit the geometry of the discrete solution space to treat the solver as a negative identity on the backward pass and further provide a theoretical justification. Our experiments demonstrate that such a straightforward hyper-parameter-free approach is able to compete with previous more complex methods on numerous experiments such as backpropagation through discrete samplers, deep graph m
    
[^124]: HUMUS-Net: 混合展开多尺度网络结构用于加速MRI重建

    HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction. (arXiv:2203.08213v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.08213](http://arxiv.org/abs/2203.08213)

    本文提出了一种混合展开多尺度网络结构用于加速MRI重建，该结构将变压器和卷积技术相结合，有效地解决了处理高分辨率图像和大块图像时计算和内存成本过高的问题。

    

    在加速MRI重建中，需要从一组欠采样和噪声测量中恢复患者的解剖结构。深度学习方法已被证明可以成功解决这个逆问题，并能够产生非常高质量的重建。然而，当前的架构严重依赖于卷积，这些卷积是内容无关的，并且难以模拟图像中的长程依赖关系。最近，变压器作为当代自然语言处理的核心，已经成为多种视觉任务的强大构建模块。这些模型将输入图像分割为非重叠的块，并将块嵌入到较低维的令牌中，利用自我注意机制，不受卷积架构的前述缺点的影响。然而，当输入图像分辨率较高且需要将图像分割为较大的块时，变压器会产生极高的计算和内存成本。

    In accelerated MRI reconstruction, the anatomy of a patient is recovered from a set of under-sampled and noisy measurements. Deep learning approaches have been proven to be successful in solving this ill-posed inverse problem and are capable of producing very high quality reconstructions. However, current architectures heavily rely on convolutions, that are content-independent and have difficulties modeling long-range dependencies in images. Recently, Transformers, the workhorse of contemporary natural language processing, have emerged as powerful building blocks for a multitude of vision tasks. These models split input images into non-overlapping patches, embed the patches into lower-dimensional tokens and utilize a self-attention mechanism that does not suffer from the aforementioned weaknesses of convolutional architectures. However, Transformers incur extremely high compute and memory cost when 1) the input image resolution is high and 2) when the image needs to be split into a lar
    
[^125]: 基于深度学习的条件修复技术用于修复受伤迹影响的4D CT图像

    Deep learning-based conditional inpainting for restoration of artifact-affected 4D CT images. (arXiv:2203.06431v2 [physics.med-ph] UPDATED)

    [http://arxiv.org/abs/2203.06431](http://arxiv.org/abs/2203.06431)

    该研究提出了基于深度学习的条件修复技术，可恢复受损部位的解剖正确的图像信息。研究依据实验结果表明该方法在修复追踪伪影上有效，具备广阔的应用前景。

    

    4D CT成像是胸部/腹部肿瘤放疗的重要组成部分。然而，4D CT图像经常受到损伤迹的影响，这会影响治疗规划的质量。本文提出基于深度学习（DL）的条件修复技术，以恢复受损部位的解剖正确的图像信息。修复方法包括两个阶段：DL-based检测常见的插值（INT）和双重结构（DS）伪影，然后应用条件修复技术到伪影部位。在这个语境中，条件指的是通过患者特定的图像数据来指导修复过程，以确保解剖学可靠的结果。该研究基于65名肺癌患者的内部4D CT图像（48名轻微受损，17名明显受损），以及两个公开可用的4D CT数据集作为独立外部测试集。自动伪影检测显示ROC-AUC为0.99的INT和0.97的DS。

    4D CT imaging is an essential component of radiotherapy of thoracic/abdominal tumors. 4D CT images are, however, often affected by artifacts that compromise treatment planning quality. In this work, deep learning (DL)-based conditional inpainting is proposed to restore anatomically correct image information of artifact-affected areas. The restoration approach consists of a two-stage process: DL-based detection of common interpolation (INT) and double structure (DS) artifacts, followed by conditional inpainting applied to the artifact areas. In this context, conditional refers to a guidance of the inpainting process by patient-specific image data to ensure anatomically reliable results. The study is based on 65 in-house 4D CT images of lung cancer patients (48 with only slight artifacts, 17 with pronounced artifacts) and two publicly available 4D CT data sets that serve as independent external test sets. Automated artifact detection revealed a ROC-AUC of 0.99 for INT and of 0.97 for DS 
    
[^126]: Transformer模块网络用于视觉问答中的系统泛化

    Transformer Module Networks for Systematic Generalization in Visual Question Answering. (arXiv:2201.11316v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2201.11316](http://arxiv.org/abs/2201.11316)

    本文引入了Transformer模块网络（TMN），它是由Transformer模块组成的新型NMN，能够取得在VQA任务中最先进的系统性能，针对子任务的新组合比标准Transformer提高了30%以上。

    

    Transformer在视觉问答中取得了非常好的性能，但它们的系统化泛化能力，即处理已知概念的新组合，尚不清楚。我们发现神经模块网络（NMN）可以取得更好或与传统的Transformer相似的系统化泛化性能，即使NMN的模块是基于卷积神经网络的。为了解决Transformer在NMNs方面的不足，本文研究了模块化如何为Transformer带来益处。我们引入了一种新型的NMN，即Transformer模块网络（TMN）是由Transformer模块组成的组合。在三个VQA数据集中，TMN取得了最先进的系统泛化性能，针对子任务的新组合比标准Transformer提高了30%以上。我们展示了不仅模块组合而且每个组件的专业化都是重要的。

    Transformers achieve great performance on Visual Question Answering (VQA). However, their systematic generalization capabilities, i.e., handling novel combinations of known concepts, is unclear. We reveal that Neural Module Networks (NMNs), i.e., question-specific compositions of modules that tackle a sub-task, achieve better or similar systematic generalization performance than the conventional Transformers, even though NMNs' modules are CNN-based. In order to address this shortcoming of Transformers with respect to NMNs, in this paper we investigate whether and how modularity can bring benefits to Transformers. Namely, we introduce Transformer Module Network (TMN), a novel NMN based on compositions of Transformer modules. TMNs achieve state-of-the-art systematic generalization performance in three VQA datasets, improving more than 30% over standard Transformers for novel compositions of sub-tasks. We show that not only the module composition but also the module specialization for eac
    
[^127]: 基于分区的图神经网络主动学习方法研究

    Partition-Based Active Learning for Graph Neural Networks. (arXiv:2201.09391v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.09391](http://arxiv.org/abs/2201.09391)

    本文提出了一种基于分区的图神经网络主动学习方法GraphPart，该方法在不引入额外超参数的情况下，在多个基准数据集上显著优于现有主动学习方法，并且在不同的注释预算约束下性能稳定。

    

    我们研究了在主动学习设置下，使用图神经网络（GNNs）进行半监督学习的问题。我们提出了一种新的基于分区的GNN主动学习方法GraphPart。GraphPart首先将图分成不相交的子图，然后在每个子图中选择代表性节点进行查询。所提出的方法是基于图和节点特征下的现实平滑假设的分类误差的新颖分析。对多个基准数据集的广泛实验表明，该方法在各种注释预算约束下，优于现有的GNN主动学习方法。此外，该方法不会引入额外的超参数，这对于模型训练尤为重要，特别是在没有标记验证集的主动学习设置下。

    We study the problem of semi-supervised learning with Graph Neural Networks (GNNs) in an active learning setup. We propose GraphPart, a novel partition-based active learning approach for GNNs. GraphPart first splits the graph into disjoint partitions and then selects representative nodes within each partition to query. The proposed method is motivated by a novel analysis of the classification error under realistic smoothness assumptions over the graph and the node features. Extensive experiments on multiple benchmark datasets demonstrate that the proposed method outperforms existing active learning methods for GNNs under a wide range of annotation budget constraints. In addition, the proposed method does not introduce additional hyperparameters, which is crucial for model training, especially in the active learning setting where a labeled validation set may not be available.
    
[^128]: 微型、始终在线且易碎: 设计选择中的偏见传递与在线机器学习工作流程。

    Tiny, always-on and fragile: Bias propagation through design choices in on-device machine learning workflows. (arXiv:2201.07677v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.07677](http://arxiv.org/abs/2201.07677)

    本研究调查了边缘端机器学习工作流程中偏见传递的设计选择。结果表明，在模型训练过程中的技术设计选择，如模型架构和优化算法，会放大和传播可靠性偏见。

    

    数十亿个分布式、异构的 IOT 设备，在个人数据上部署的边缘端机器学习，用于私密、快速且离线推理。边缘端的机器学习高度依赖上下文，对用户、用法、硬件和环境属性非常敏感。这种敏感性和机器学习中偏见的倾向使得研究边缘端机器学习中的偏见非常重要。本研究是对这一新兴领域中偏见研究的首次探索，为构建更公平的边缘端机器学习奠定了重要基础。本文通过软件工程角度调查了边缘端机器学习工作流程中偏见传递的设计选择。我们首先将可靠性偏见确定为不公平性的来源，并提出了一种量化可靠性偏见的方法。然后我们进行了一项关键词检测任务的实验，展示了复杂的和相互作用的技术设计选择如何放大和传播可靠性偏见。我们的研究结果验证了模型训练过程中的设计选择，如模型架构和优化算法，会对可靠性偏见的传播产生巨大影响。

    Billions of distributed, heterogeneous and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast and offline inference on personal data. On-device ML is highly context dependent, and sensitive to user, usage, hardware and environment attributes. This sensitivity and the propensity towards bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain, and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, lik
    
[^129]: 论分类问题中图像混合数据增强方法的 K-image 扩展探讨

    Observations on K-image Expansion of Image-Mixing Augmentation for Classification. (arXiv:2110.04248v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2110.04248](http://arxiv.org/abs/2110.04248)

    本文提出一种新的 K-image 混合增强方法，通过基于狄利克雷先验分布的棍子分拆，可以得到更健壮、广义的分类器，并具有更好的对抗鲁棒性。

    

    图像混合增强技术（例如 Mixup 和 CutMix）已成为图像分类训练技术的事实标准。然而，目前文献中并未阐明混合图像数目的问题：只有朴素的 K-image 扩展已被证明会导致性能下降。本研究基于狄利克雷先验分布的棍子分拆过程提出了一种新的 K-image 混合增强方法。通过广泛的实验和分析，我们证明了我们的 K-image 扩展增强方法优于传统的双图像混合增强方法：(1) 产生更健壮和广义的分类器；(2) 更优良的损失景观形状；(3) 更好的对抗鲁棒性。此外，我们展示了我们的概率模型可以衡量每个样本的不确定性，并通过实现搜索时间减少了 7 倍，从而提高了网络架构搜索的效率。

    Image-mixing augmentations (e.g., Mixup and CutMix), which typically involve mixing two images, have become the de-facto training techniques for image classification. Despite their huge success in image classification, the number of images to be mixed has not been elucidated in the literature: only the naive K-image expansion has been shown to lead to performance degradation. This study derives a new K-image mixing augmentation based on the stick-breaking process under Dirichlet prior distribution. We demonstrate the superiority of our K-image expansion augmentation over conventional two-image mixing augmentation methods through extensive experiments and analyses: (1) more robust and generalized classifiers; (2) a more desirable loss landscape shape; (3) better adversarial robustness. Moreover, we show that our probabilistic model can measure the sample-wise uncertainty and boost the efficiency for network architecture search by achieving a 7-fold reduction in the search time. Code wil
    
[^130]: 结合物理和深度学习来学习连续时间动力学模型

    Combining Physics and Deep Learning to learn Continuous-Time Dynamics Models. (arXiv:2110.01894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.01894](http://arxiv.org/abs/2110.01894)

    本文提出了受物理启发的深度网络DeLaN，结合物理学原理和深度学习来学习具有物理合理性动力学的模型。

    

    深度学习已被广泛应用于机器人学习算法中，但深度网络的不足之一在于这些网络是黑盒子表示形式。因此，学习到的近似值忽略了现有的物理或机器人学知识。特别是对于学习动力学模型而言，这些黑盒子模型并不理想，因为基本原理已经被很好地理解，标准深度网络可以学习违反这些原理的动力学。为了使用深度网络学习具有物理合理性动力学的模型，我们引入了受物理启发的深度网络，将物理学的基本原理与深度学习相结合。我们将Lagrangian力学纳入模型学习中，使得所有近似模型都遵循物理定律并保存能量。Deep Lagrangian Networks (DeLaN) 使用两个网络参数化系统能量。通过最小化欧拉-拉格朗日微分方程的平方残差来获得参数。

    Deep learning has been widely used within learning algorithms for robotics. One disadvantage of deep networks is that these networks are black-box representations. Therefore, the learned approximations ignore the existing knowledge of physics or robotics. Especially for learning dynamics models, these black-box models are not desirable as the underlying principles are well understood and the standard deep networks can learn dynamics that violate these principles. To learn dynamics models with deep networks that guarantee physically plausible dynamics, we introduce physics-inspired deep networks that combine first principles from physics with deep learning. We incorporate Lagrangian mechanics within the model learning such that all approximated models adhere to the laws of physics and conserve energy. Deep Lagrangian Networks (DeLaN) parametrize the system energy using two networks. The parameters are obtained by minimizing the squared residual of the Euler-Lagrange differential equatio
    
[^131]: 使用分布感知词嵌入的命名实体识别性能的实证研究。

    Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2109.01636](http://arxiv.org/abs/2109.01636)

    研究开发了一种分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息，实验表明将词的特异性融入NER方法可提高NER的性能。

    

    随着深度学习技术的快速发展，命名实体识别（NER）在信息提取任务中变得越来越重要。NER任务面临的最大困难是即使在NE类型和文档不熟悉的情况下仍然需要保持可检测性。意识到特定性信息可能包含单词的潜在含义并生成词嵌入的语义相关特征，我们开发了一个分布感知词嵌入，并实施了三种不同的方法来利用NER框架中的分布信息。结果表明，如果将词的特异性融入现有的NER方法中，NER的性能将得到提高。

    With the fast development of Deep Learning techniques, Named Entity Recognition (NER) is becoming more and more important in the information extraction task. The greatest difficulty that the NER task faces is to keep the detectability even when types of NE and documents are unfamiliar. Realizing that the specificity information may contain potential meanings of a word and generate semantic-related features for word embedding, we develop a distribution-aware word embedding and implement three different methods to make use of the distribution information in a NER framework. And the result shows that the performance of NER will be improved if the word specificity is incorporated into existing NER methods.
    
[^132]: 一种基于深度可分卷积神经ODE的低成本FPGA边缘领域适应方法

    A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge Domain Adaptation on FPGAs. (arXiv:2107.12824v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.12824](http://arxiv.org/abs/2107.12824)

    本文提出了一种低成本的神经ODE和深度可分卷积相结合的DNN模型dsODENet，并将其应用于边缘领域适应。此外，还提出了一种资源高效的FPGA设计，可部署dsODENet。

    

    在边缘环境中，高性能的基于深度神经网络（DNN）的系统需求量很高。由于其高计算复杂性，将DNN部署到计算资源有严格限制的边缘设备上具有挑战性。因此，本文通过结合最近提出的参数缩减技术：神经ODE（普通微分方程）和DSC（深度可分卷积），导出了一种紧凑且精度高的DNN模型，称为dsODENet。神经ODE利用ResNet和ODE之间的相似性，并在多个层之间共享大部分权重参数，从而大大减少了内存消耗。本文将dsODENet应用于实际情况下的域自适应，并使用图像分类数据集进行了评估。本文还提出了一种针对dsODENet的资源高效的基于FPGA的设计，其中除了预处理和后处理层的所有参数和特征图均可映射到芯片上的内存中。

    High-performance deep neural network (DNN)-based systems are in high demand in edge environments. Due to its high computational complexity, it is challenging to deploy DNNs on edge devices with strict limitations on computational resources. In this paper, we derive a compact while highly-accurate DNN model, termed dsODENet, by combining recently-proposed parameter reduction techniques: Neural ODE (Ordinary Differential Equation) and DSC (Depthwise Separable Convolution). Neural ODE exploits a similarity between ResNet and ODE, and shares most of weight parameters among multiple layers, which greatly reduces the memory consumption. We apply dsODENet to a domain adaptation as a practical use case with image classification datasets. We also propose a resource-efficient FPGA-based design for dsODENet, where all the parameters and feature maps except for pre- and post-processing layers can be mapped onto on-chip memories. It is implemented on Xilinx ZCU104 board and evaluated in terms of do
    
[^133]: 学习增强的在线设施选址问题

    Learning Augmented Online Facility Location. (arXiv:2107.08277v3 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2107.08277](http://arxiv.org/abs/2107.08277)

    本文提出了一种用于在线设施选址问题的在线算法，竞争比率能够光滑地随误差减小而从对数级别降低到常数级别。

    

    本文考虑了在线设施选址问题，在该问题中，需求逐一到达，并且必须在到达时将其（无法撤销地）分配给一个开放的设施，而没有关于未来需求的任何知识。我们提出了一种在线算法，用于处理该问题，并利用对最优设施位置的预测。我们证明了，竞争比率从需求数量的对数级别平滑地降低到常数级别，当错误（即预测位置与最优设施位置之间的总距离）向零降低时。我们配合算法的降低界，建立了算法的竞争比率对误差的依赖关系是最优的，常数接近最优。

    Following the research agenda initiated by Munoz & Vassilvitskii [1] and Lykouris & Vassilvitskii [2] on learning-augmented online algorithms for classical online optimization problems, in this work, we consider the Online Facility Location problem under this framework. In Online Facility Location (OFL), demands arrive one-by-one in a metric space and must be (irrevocably) assigned to an open facility upon arrival, without any knowledge about future demands.  We present an online algorithm for OFL that exploits potentially imperfect predictions on the locations of the optimal facilities. We prove that the competitive ratio decreases smoothly from sublogarithmic in the number of demands to constant, as the error, i.e., the total distance of the predicted locations to the optimal facility locations, decreases towards zero. We complement our analysis with a matching lower bound establishing that the dependence of the algorithm's competitive ratio on the error is optimal, up to constant fa
    
[^134]: 用生成模型突破模型驱动强化学习中的样本大小障碍

    Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.12900](http://arxiv.org/abs/2005.12900)

    本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。

    

    本论文着眼于在有生成模型（或模拟器）的情况下，增强学习的样本效率。首先，考虑带有折扣的无限时间步长马尔科夫决策过程（MDP），其状态空间为$\mathcal{S}$，动作空间为$\mathcal{A}$。尽管有许多先前的研究在解决这个问题，但是在样本复杂度和统计精度之间权衡的完整图景尚未确定。特别是，所有的先前结果都受到严重的样本大小障碍，因为它们声称的统计保证仅在样本大小超过至少$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$时才成立。本文通过证明两个算法——扰动模型驱动算法和保守模型驱动算法——在样本大小超过$\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$的情况下就能证明它们的极小化最大算法优化性能（几乎符合一些对数因子）。除了无限时间步长M解决方案之外，我们还考虑了有限样本和近似价值迭代问题，以在实践中实现算法的应用。

    This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\mathcal{S}$ and action space $\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$ (modulo some log factor). Moving beyond infinite-
    
[^135]: 带模糊规则的深度图像特征学习

    Deep Image Feature Learning with Fuzzy Rules. (arXiv:1905.10575v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/1905.10575](http://arxiv.org/abs/1905.10575)

    本论文提出了一种基于模糊规则的深度图像特征学习方法，能够生成更好的解释和可伸缩的特征模型，并且与数据集大小无关。

    

    提取图像特征的方法是许多图像处理任务的关键。目前，最流行的方法是深度神经网络，它可以通过端到端训练自动提取鲁棒的特征，而不需要手工制作特征提取。然而，深度神经网络当前面临许多挑战：1）它的有效性在很大程度上取决于大型数据集，因此计算复杂度非常高；2）它通常被视为黑匣子模型，解释能力差。为了应对以上挑战，本文提出了一种更具解释性和可伸缩性的特征学习方法，即基于模糊规则的深度图像特征学习（DIFL-FR），该方法结合了基于规则的模糊建模技术和深度堆叠学习策略。该方法通过逐层学习基于模糊规则的图像特征，因此可以通过生成的规则更好地解释特征学习过程。更重要的是，DIFL-FR方法的特征学习与数据集的大小无关，大大降低了计算复杂度。实验结果表明，该方法在几个基准数据集上实现了比其他特征学习方法更好的性能。

    The methods of extracting image features are the key to many image processing tasks. At present, the most popular method is the deep neural network which can automatically extract robust features through end-to-end training instead of hand-crafted feature extraction. However, the deep neural network currently faces many challenges: 1) its effectiveness is heavily dependent on large datasets, so the computational complexity is very high; 2) it is usually regarded as a black box model with poor interpretability. To meet the above challenges, a more interpretable and scalable feature learning method, i.e., deep image feature learning with fuzzy rules (DIFL-FR), is proposed in the paper, which combines the rule-based fuzzy modeling technique and the deep stacked learning strategy. The method progressively learns image features through a layer-by-layer manner based on fuzzy rules, so the feature learning process can be better explained by the generated rules. More importantly, the learning 
    

