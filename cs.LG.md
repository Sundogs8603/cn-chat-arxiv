# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems](https://rss.arxiv.org/abs/2402.01147) | 本研究针对异构排队系统中作业路由问题，提出了ACHQ算法，通过低维度的软阈值策略参数化和基于策略梯度的方法，利用系统的排队结构，实现了高效的强化学习求解策略。实验结果表明，ACHQ算法能够收敛到近似全局最优解。 |
| [^2] | [Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions](https://rss.arxiv.org/abs/2402.01116) | 我们提出了一个层级架构，通过使用对偶交互预测和精简的MPC问题，实现了可扩展的实时模型预测控制，在复杂的多模态交通场景中展示了12倍的速度提升。 |
| [^3] | [Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context](https://arxiv.org/abs/2404.02000) | 这项研究提出了首个仅在非洲语音上进行训练的自监督多语言语音模型，相比于常规方法，更高效并在ASR和LID任务中表现出竞争力。 |
| [^4] | [A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection](https://arxiv.org/abs/2404.01643) | 为解决CT扫描中存在的变异性和OOD切片挑战，提出了一种增强型的空间分割特征学习框架，通过滤除OOD数据和减少冗余来选择关键的空间切片进行分析，并引入了基于核密度的切片采样方法来提高稳定性和加快收敛速度 |
| [^5] | [Machine Learning Robustness: A Primer](https://arxiv.org/abs/2404.00897) | 该章节探讨了机器学习中稳健性的重要概念及关键的技术和因素，以确立人工智能系统的可信度。 |
| [^6] | [YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery](https://arxiv.org/abs/2404.00257) | 该论文提出了基于YOLO架构的YOLOOC检测器，针对开放类别设置引入了标签平滑，有效应对新类别检测和增量学习的挑战。 |
| [^7] | [LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning](https://arxiv.org/abs/2404.00027) | 探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。 |
| [^8] | [Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs](https://arxiv.org/abs/2404.00026) | 研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。 |
| [^9] | [A Review of Graph Neural Networks in Epidemic Modeling](https://arxiv.org/abs/2403.19852) | 图神经网络在流行病建模中作为一种新工具备受关注，本文全面回顾了GNN在流行病研究中的应用，并提出了未来发展方向。 |
| [^10] | [Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning](https://arxiv.org/abs/2403.18985) | 提出了一个通用的强化学习框架，用于从心电图信号分析到图像和视频分类的不同模型类型的对抗攻击，通过识别敏感区域并在最小程度扭曲下诱导错误分类，生成优越的定位掩模，并在鲁棒性和透明度方面取得了显著进展。 |
| [^11] | [Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation](https://arxiv.org/abs/2403.17886) | 基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。 |
| [^12] | [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://arxiv.org/abs/2403.16973) | VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。 |
| [^13] | [Visual Whole-Body Control for Legged Loco-Manipulation](https://arxiv.org/abs/2403.16967) | 这项研究提出了一种利用视觉全身控制的框架，使腿式机器人能够同时控制腿部和手臂，以扩展操作能力，并通过仿真训练和Sim2Real转移实现了在捡起不同物体方面取得显著改进。 |
| [^14] | [Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery](https://arxiv.org/abs/2403.14593) | 重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。 |
| [^15] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^16] | [Machine learning-based system reliability analysis with Gaussian Process Regression](https://arxiv.org/abs/2403.11125) | 本文提出了基于高斯过程回归的机器学习系统可靠性分析方法，并通过几个定理探讨了最优学习策略，包括考虑和忽略样本之间的相关性以及顺序多个训练样本增益的理论最优策略。 |
| [^17] | [Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild](https://arxiv.org/abs/2403.10488) | 该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。 |
| [^18] | [Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative Privacy Risk](https://arxiv.org/abs/2403.09450) | 微调扩散模型可能会增加生成隐私风险，甚至使最先进的成员推理攻击对扩散模型的攻击效果提高5.4％，并可将提取的私有样本数量从几乎0个增加到平均16.3个。 |
| [^19] | [A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology](https://arxiv.org/abs/2403.07945) | 本文提出了一个数学框架，名为认知安全，用于描述和分析神经技术对个体认知隐私和自治可能产生的影响，解决了相关问题描述和分析的障碍。 |
| [^20] | [WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](https://arxiv.org/abs/2403.07718) | 该研究探究了基于大型语言模型的代理在通过web浏览器与软件交互时的能力，提出了WorkArena和BrowserGym两个工具，在29个任务的基准测试中显示出潜力，但也揭示了实现完全任务自动化仍存在挑战。 |
| [^21] | [Bayesian Diffusion Models for 3D Shape Reconstruction](https://arxiv.org/abs/2403.06973) | BDM是一种利用联合扩散过程紧密耦合先验信息与数据驱动过程的预测算法，专注于3D形状重建任务，通过引入独立标签的丰富先验信息来改善自下而上的重建过程。 |
| [^22] | [Advancing Graph Neural Networks with HL-HGAT: A Hodge-Laplacian and Attention Mechanism Approach for Heterogeneous Graph-Structured Data](https://arxiv.org/abs/2403.06687) | 本研究提出了Hodge-Laplacian异构图注意网络（HL-HGAT），通过HL卷积滤波器、单纯投影和单纯注意池化运算符，可以学习跨k-单纯体的异构信号表示。 |
| [^23] | [Dynamic Cross Attention for Audio-Visual Person Verification](https://arxiv.org/abs/2403.04661) | 提出了一种动态交叉注意力（DCA）模型，根据音频和视频模态之间的强弱互补关系，动态选择交叉关注或不关注的特征。 |
| [^24] | [Soft-constrained Schrodinger Bridge: a Stochastic Control Approach](https://arxiv.org/abs/2403.01717) | 提出了软约束薛定谔桥(SSB)控制问题，在允许终端分布与预先指定分布不同的情况下，惩罚两者之间的Kullback-Leibler散度。理论上推导出了SSB解，显示最优控制过程的终端分布是μT和其他分布的几何混合，并将结果扩展到时间序列设置。 |
| [^25] | [Using Graph Neural Networks to Predict Local Culture](https://arxiv.org/abs/2402.17905) | 本研究提出了使用图神经网络（GNN）方法，结合多个信息源来更好地预测社区属性，特别是预测当地文化，结果显示了这一方法在考虑结构相连性方面的潜力。 |
| [^26] | [Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction](https://arxiv.org/abs/2402.15163) | 该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。 |
| [^27] | [An Adversarial Approach to Evaluating the Robustness of Event Identification Models](https://arxiv.org/abs/2402.12338) | 该论文提出了一种基于物理的模态分解方法用于提取事件分类特征，并评估了可解释分类器在面对对抗算法时的鲁棒性。 |
| [^28] | [Self-Consistent Conformal Prediction](https://arxiv.org/abs/2402.07307) | 自洽的符合预测方法能够提供既符合校准的预测又符合以模型预测的动作为条件的预测区间，为决策者提供了严格的、针对具体动作的决策保证。 |
| [^29] | [Peer-review-in-LLMs: Automatic Evaluation Method for LLMs in Open-environment](https://arxiv.org/abs/2402.01830) | 本文提出了一种新的无监督评估方法，利用同行评审机制在开放环境中衡量LLMs。通过为每个LLM分配可学习的能力参数，以最大化各个LLM的能力和得分的一致性。结果表明，高层次的LLM能够更准确地评估其他模型的答案，并能够获得更高的响应得分。 |
| [^30] | [Harnessing Smartwatch Microphone Sensors for Cough Detection and Classification](https://arxiv.org/abs/2401.17738) | 本研究利用智能手表的麦克风传感器监测和分类了各种咳嗽，通过结构化处理和专门的1D卷积神经网络模型，成功实现了98.49%和98.2%的准确率，并成功识别出四种不同的咳嗽类型。 |
| [^31] | [Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation](https://arxiv.org/abs/2401.17484) | 本研究提出了一种学习方法，可以通过车载视角图像实时预测长距离地形高程地图。该方法包括transformer-based编码器、方向感知的位置编码和历史增强的可学习地图嵌入。通过学习视角图像与鸟瞰图高程地图之间的关联，结合车辆姿态信息和视觉图像特征，实现更好的地图预测时序一致性。 |
| [^32] | [Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context](https://arxiv.org/abs/2312.06528) | 本论文证明了Transformers可以在函数空间中自然地学习实现梯度下降，从而学习上下文中的非线性函数，并且展示了最优的非线性激活函数选择取决于需要学习的函数类别。 |
| [^33] | [Domain constraints improve risk prediction when outcome data is missing](https://arxiv.org/abs/2312.03878) | 提出一种贝叶斯模型类，通过领域约束的设置来改善测试和未测试患者的风险预测 |
| [^34] | [Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training](https://arxiv.org/abs/2312.02914) | 该方法提出了UNITE框架，利用图像教师模型和视频学生模型进行遮蔽预训练和协作自训练，在多个视频领域自适应基准上取得显著改进的结果。 |
| [^35] | [PAC Privacy Preserving Diffusion Models](https://arxiv.org/abs/2312.01201) | 提出了一种PAC隐私保护扩散模型，通过将私有分类器指导集成到采样过程中增强隐私保护，并发展了一种新的度量标准来衡量隐私水平，在保护性能方面表现出卓越表现。 |
| [^36] | [Action-slot: Visual Action-centric Representations for Multi-label Atomic Activity Recognition in Traffic Scenes](https://arxiv.org/abs/2311.17948) | 提出了一种名为Action-slot的方法，通过槽注意力学习视觉动作中心表示，在交通场景中实现了多标签原子活动识别。 |
| [^37] | [On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates](https://arxiv.org/abs/2311.13584) | 我们提出了对于基于扩散的生成模型在强对数凹数据分布假设下的完整收敛理论保证，获得了对于参数估计和采样算法的最优上限估计。 |
| [^38] | [Discrete Nonparametric Causal Discovery Under Latent Class Confounding](https://arxiv.org/abs/2311.07454) | 本论文研究了离散非参数隐性类别混淆下的因果发现问题，证明了在有限的潜在类别下，因果发现仍然是可识别的。 |
| [^39] | [Think before you speak: Training Language Models With Pause Tokens](https://arxiv.org/abs/2310.02226) | 引入暂停标记的语言模型训练方法可以让模型在输出标记前处理更多隐藏向量，取得了较好的实验结果 |
| [^40] | [RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation.](http://arxiv.org/abs/2401.10940) | RELIANCE是一个可靠的集成学习系统，用于评估信息和新闻的可信度。它通过整合多个基本模型的优势，提供了对可信和不可信信息源的准确区分，并在信息和新闻可信度评估方面优于基准模型。 |
| [^41] | [Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack.](http://arxiv.org/abs/2401.09673) | 本文提出了一种名为本地自适应对抗颜色攻击（LAACA）的方法，用于保护艺术品免受神经风格转换（NST）的滥用。该方法通过在不可察觉的情况下对图像进行修改，产生对NST具有干扰作用的扰动。 |
| [^42] | [Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification.](http://arxiv.org/abs/2401.09493) | 本研究利用线性变分编码器-解码器来学习云辐射反馈对早期热带气旋强化的影响，发现内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流的影响最大。 |
| [^43] | [Bridging State and History Representations: Understanding Self-Predictive RL.](http://arxiv.org/abs/2401.08898) | 本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。 |
| [^44] | [Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis.](http://arxiv.org/abs/2401.05453) | 这篇论文提出了一种维度感知的异常检测方法DAO，通过全面实验验证了其在800多个数据集上显著优于其他三种流行的异常检测方法。 |
| [^45] | [Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation.](http://arxiv.org/abs/2401.02683) | 这项研究提出了一个几何便利的去噪扩散模型，用于解决3D分子生成中的多体原子关系建模和键的预测问题。 |
| [^46] | [Unraveling the Key Components of OOD Generalization via Diversification.](http://arxiv.org/abs/2312.16313) | 本文研究了通过多样化方法来解决OOD广义化问题，并确定了其关键组件。研究发现，多样化方法对无标签数据的分布非常敏感，且仅仅进行多样化是不足以实现OOD广义化的，学习算法的选择也很重要。 |
| [^47] | [Isolated pulsar population synthesis with simulation-based inference.](http://arxiv.org/abs/2312.14848) | 本论文使用模拟推断方法结合脉冲星种群合成，来限制孤立银河射电脉冲星的磁旋转特性。 |
| [^48] | [Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control.](http://arxiv.org/abs/2311.07202) | 本研究提出了一种基于输入凸LSTM的基于Lyapunov的模型预测控制方法，通过减少收敛时间和缓解梯度消失/爆炸问题来改善MPC的性能。 |
| [^49] | [Discussing the Spectra of Physics-Enhanced Machine Learning via a Survey on Structural Mechanics Applications.](http://arxiv.org/abs/2310.20425) | 本文探讨了物理增强机器学习 (PEML) 的光谱，揭示了其在解决复杂挑战方面的潜力，并通过具体示例演示了不同类型PEML方法的个体特征和动机。 |
| [^50] | [Knowledge Graph Context-Enhanced Diversified Recommendation.](http://arxiv.org/abs/2310.13253) | 该研究在知识图谱背景下探索多样化推荐系统，通过引入创新的度量标准和评分函数，有效提高了知识图谱推荐算法的多样性。 |
| [^51] | [HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning.](http://arxiv.org/abs/2310.11102) | HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。 |
| [^52] | [Uncovering ECG Changes during Healthy Aging using Explainable AI.](http://arxiv.org/abs/2310.07463) | 本文使用可解释的人工智能技术分析了健康个体的心电图数据，并识别出随年龄增长呼吸率的下降及SDANN值异常高作为老年人的指标。 |
| [^53] | [Transformer Fusion with Optimal Transport.](http://arxiv.org/abs/2310.05719) | 本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。 |
| [^54] | [Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels.](http://arxiv.org/abs/2310.05387) | 该论文提出了一种基于核学习和贝叶斯Spike-and-Slab先验的方程式发现方法，通过核回归和贝叶斯稀疏分布，能够有效处理数据稀疏性和噪声问题，并进行不确定性量化和高效的后验推断和函数估计。 |
| [^55] | [Lemur: Integrating Large Language Models in Automated Program Verification.](http://arxiv.org/abs/2310.04870) | 本论文提出了一种将LLMs和自动推理器结合起来进行自动程序验证的通用方法，并证明了其完备性。这个方法在一些合成和竞争基准上取得了实际的改进。 |
| [^56] | [On Prediction Feature Assignment in the Heckman Selection Model.](http://arxiv.org/abs/2309.08043) | 本文研究在非随机缺失样本选择偏差下的预测模型性能降低问题，提出了Heckman-FA框架来获取恰当的预测特征。 |
| [^57] | [Simultaneous inference for generalized linear models with unmeasured confounders.](http://arxiv.org/abs/2309.07261) | 本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。 |
| [^58] | [Masked Transformer for Electrocardiogram Classification.](http://arxiv.org/abs/2309.07136) | 提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。 |
| [^59] | [Let Quantum Neural Networks Choose Their Own Frequencies.](http://arxiv.org/abs/2309.03279) | 该论文提出了一种可训练频率的量子模型，通过在生成器中引入可训练参数，使得模型能够学习具有所需属性的生成器，包括非常规间隔频率和灵活的频谱丰富性。实验证明该方法在解决Navier-Stokes方程时具有较高的准确性。 |
| [^60] | [A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems.](http://arxiv.org/abs/2308.16471) | 本研究提出了一种适用于动态运动生成任务的多任务强化学习算法，可用于适应单个运动类别中的隐式变化，并在头球任务中取得良好的适应效果。 |
| [^61] | [Classification with Deep Neural Networks and Logistic Loss.](http://arxiv.org/abs/2307.16792) | 本文提出了一种新颖的oracle型不等式，通过解决逻辑损失的目标函数无界性限制，推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的最优收敛速率，仅要求数据的条件类概率具有H\"older平滑性，并且考虑了组合假设，使得该方法具有更广泛的适用性。 |
| [^62] | [Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers.](http://arxiv.org/abs/2307.14367) | 提出了一种名为Prot2Text的新方法，通过结合GNNs和Transformers，以自由文本样式预测蛋白质的功能。该方法能够综合蛋白质的序列、结构和文本注释等多种数据类型，超越传统的二进制或分类分类，实现了对蛋白质功能的全面表示。 |
| [^63] | [Explainable Disparity Compensation for Efficient Fair Ranking.](http://arxiv.org/abs/2307.14366) | 这项研究提出了解释性的数据驱动的排名函数补偿措施，通过给予低调群体成员奖励积分来解决公平排序中的不平等问题。 |
| [^64] | [When No-Rejection Learning is Optimal for Regression with Rejection.](http://arxiv.org/abs/2307.02932) | 本文研究了具有拒绝的回归问题，并调查了将其视为标准回归任务来学习预测器的无拒绝学习策略。 |
| [^65] | [End-to-end Autonomous Driving: Challenges and Frontiers.](http://arxiv.org/abs/2306.16927) | 这项研究调查了端到端自动驾驶领域中的关键挑战和未来趋势，包括多模态、可解释性、因果混淆、鲁棒性和世界模型等。通过联合特征优化感知和规划，端到端系统在感知和规划上获得了更好的效果。 |
| [^66] | [Communication-Efficient Federated Learning through Importance Sampling.](http://arxiv.org/abs/2306.12625) | 本文提出了一种通过重要性抽样实现有效通信的联邦学习方法，大大降低了发送模型更新的高通信成本，利用服务器端客户端分布和附加信息的接近关系，只需要较少的通信量即可实现。 |
| [^67] | [PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical Reinforcement Learning.](http://arxiv.org/abs/2306.06394) | PEAR是一种基于原始操作的自适应重标记方法，用于Boosting层次强化学习。它通过对专家演示进行自适应重标记来生成高效的子目标监督，并通过联合优化强化学习和模仿学习来训练分层代理。实验结果显示，PEAR能够在具有挑战性的机器人环境中取得良好的性能。 |
| [^68] | [Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations.](http://arxiv.org/abs/2306.05880) | 该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。 |
| [^69] | [Large-scale Dataset Pruning with Dynamic Uncertainty.](http://arxiv.org/abs/2306.05175) | 本文提出了一种探索预测不确定性和训练动态的简单且有效的大规模数据集修剪方法，以产生信息量丰富的子集用于训练深度模型，实验结果表明优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。 |
| [^70] | [When to Show a Suggestion? Integrating Human Feedback in AI-Assisted Programming.](http://arxiv.org/abs/2306.04930) | 本研究利用先前数据的干预措施提高基于AI的代码推荐系统的有效性，提出了一个CDHF框架来整合人类反馈，预测建议接受程度并决定何时展示哪些建议。 |
| [^71] | [Closing the Gap in High-Risk Pregnancy Care Using Machine Learning and Human-AI Collaboration.](http://arxiv.org/abs/2305.17261) | 本论文介绍了一种基于机器学习和人工智能协作的高危孕产妇计划，提出了早期妊娠检测、准确识别高风险会员和提供可解释指标等三个挑战的解决方案，提高了孕期风险的预测准确率。 |
| [^72] | [Offline Experience Replay for Continual Offline Reinforcement Learning.](http://arxiv.org/abs/2305.13804) | 本论文提出了一个新的场景——连续离线强化学习 (CORL)，解决了代理在离线任务序列学习中可能出现的灾难性遗忘问题。实验结果发现，经验重放 (ER) 是最适合 CORL 问题的算法，但引入 ER 后会遇到新的分布偏移问题。 |
| [^73] | [DermSynth3D: Synthesis of in-the-wild Annotated Dermatology Images.](http://arxiv.org/abs/2305.12621) | 该论文提出了一种名为DermSynth3D的新框架，它使用可微分渲染器将皮肤病变模式混合到人体三维纹理网格上并生成逼真的二维皮肤镜像图像，同时提供对应的密集注释以进行语义分割。 |
| [^74] | [Generalization Bounds for Neural Belief Propagation Decoders.](http://arxiv.org/abs/2305.10540) | 本文研究了神经置信传播译码器的泛化能力，提出了一组新的理论结果，界定了解码器的泛化间隙，结果与解码器的复杂程度有关。 |
| [^75] | [Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression.](http://arxiv.org/abs/2305.00608) | 该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。 |
| [^76] | [Decouple Graph Neural Networks: Train Multiple Simple GNNs Simultaneously Instead of One.](http://arxiv.org/abs/2304.10126) | 本论文提出将多层图神经网络解耦为多个简单模块的方法，以实现更高效的训练。该方法包括经典的前向训练和设计的反向训练。每个模块都可以通过随机算法在前向训练中高效地训练，并且通过反向训练机制来使前面的模块能够感知后面的模块，从而充分训练浅层模块和更深层的模块。 |
| [^77] | [CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs.](http://arxiv.org/abs/2304.04391) | CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。 |
| [^78] | [Linear Optimal Partial Transport Embedding.](http://arxiv.org/abs/2302.03232) | 本文提出了线性最优偏移嵌入技术（LOPT），它扩展了（局部）线性化技术到OPT问题上，提高了正测度对之间的计算速度。并且在点云内插和PCA分析中进行了应用。 |
| [^79] | [Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming.](http://arxiv.org/abs/2210.14306) | 该论文研究了代码推荐系统GitHub Copilot，发现了程序员与该系统交互的一些常见活动，揭示了其低效性和时间成本，从而为改进界面设计和度量方法提供了动力。 |
| [^80] | [Decentralized Online Regularized Learning Over Random Time-Varying Graphs.](http://arxiv.org/abs/2206.03861) | 本文研究了随机时变图上的分散在线正则化线性回归算法，提出了非负超-鞅不等式的估计误差，证明了算法在满足样本路径时空兴奋条件时，节点的估计可以收敛于未知的真实参数向量。 |

# 详细

[^1]: 异构排队系统中用于路由作业的高效强化学习

    Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems

    [https://rss.arxiv.org/abs/2402.01147](https://rss.arxiv.org/abs/2402.01147)

    本研究针对异构排队系统中作业路由问题，提出了ACHQ算法，通过低维度的软阈值策略参数化和基于策略梯度的方法，利用系统的排队结构，实现了高效的强化学习求解策略。实验结果表明，ACHQ算法能够收敛到近似全局最优解。

    

    本研究考虑将到达中央队列的作业高效路由到异构服务器系统中的问题。与同质系统不同，对于一快一慢的双服务器系统，已知阈值策略，即在队列长度超过某一阈值时将作业路由到慢服务器，是最优策略。但多服务器系统的最优策略未知且难以找到。虽然强化学习（RL）已被认为对于学习此类策略具有巨大潜力，但我们的问题具有指数级的状态空间大小，使标准RL效率低下。在这项工作中，我们提出了ACHQ，一种基于策略梯度的高效算法，具有低维度的软阈值策略参数化，利用底层排队结构。我们为一般情况提供了稳态收敛性保证，并且尽管参数化维度较低，但证明了ACHQ收敛到近似全局最优序列。

    We consider the problem of efficiently routing jobs that arrive into a central queue to a system of heterogeneous servers. Unlike homogeneous systems, a threshold policy, that routes jobs to the slow server(s) when the queue length exceeds a certain threshold, is known to be optimal for the one-fast-one-slow two-server system. But an optimal policy for the multi-server system is unknown and non-trivial to find. While Reinforcement Learning (RL) has been recognized to have great potential for learning policies in such cases, our problem has an exponentially large state space size, rendering standard RL inefficient. In this work, we propose ACHQ, an efficient policy gradient based algorithm with a low dimensional soft threshold policy parameterization that leverages the underlying queueing structure. We provide stationary-point convergence guarantees for the general case and despite the low-dimensional parameterization prove that ACHQ converges to an approximate global optimum for the sp
    
[^2]: 可扩展多模型MPC的基于对偶交互预测的层级架构

    Scalable Multi-modal Model Predictive Control via Duality-based Interaction Predictions

    [https://rss.arxiv.org/abs/2402.01116](https://rss.arxiv.org/abs/2402.01116)

    我们提出了一个层级架构，通过使用对偶交互预测和精简的MPC问题，实现了可扩展的实时模型预测控制，在复杂的多模态交通场景中展示了12倍的速度提升。

    

    我们提出了一个层级架构，用于在复杂的多模态交通场景中实现可扩展的实时模型预测控制(MPC)。该架构由两个关键组件组成：1) RAID-Net，一种基于注意力机制的新颖循环神经网络，使用拉格朗日对偶性预测自动驾驶车辆与周围车辆之间在MPC预测范围内的相关交互；2) 一个简化的随机MPC问题，消除不相关的避碰约束，提高计算效率。我们的方法在一个模拟交通路口中演示，展示了解决运动规划问题的12倍速提升。您可以在这里找到展示该架构在多个复杂交通场景中的视频：https://youtu.be/-TcMeolCLWc

    We propose a hierarchical architecture designed for scalable real-time Model Predictive Control (MPC) in complex, multi-modal traffic scenarios. This architecture comprises two key components: 1) RAID-Net, a novel attention-based Recurrent Neural Network that predicts relevant interactions along the MPC prediction horizon between the autonomous vehicle and the surrounding vehicles using Lagrangian duality, and 2) a reduced Stochastic MPC problem that eliminates irrelevant collision avoidance constraints, enhancing computational efficiency. Our approach is demonstrated in a simulated traffic intersection with interactive surrounding vehicles, showcasing a 12x speed-up in solving the motion planning problem. A video demonstrating the proposed architecture in multiple complex traffic scenarios can be found here: https://youtu.be/-TcMeolCLWc
    
[^3]: 非洲中心自监督预训练技术在撒哈拉以南地区的多语言语音表征中的应用

    Africa-Centric Self-Supervised Pre-Training for Multilingual Speech Representation in a Sub-Saharan Context

    [https://arxiv.org/abs/2404.02000](https://arxiv.org/abs/2404.02000)

    这项研究提出了首个仅在非洲语音上进行训练的自监督多语言语音模型，相比于常规方法，更高效并在ASR和LID任务中表现出竞争力。

    

    我们提出了第一个仅在非洲语音上进行训练的自监督多语言语音模型。该模型从撒哈拉以南非洲地区讲话的21种语言和方言中学习了近60,000小时的未标记语音片段。在FLEURS-102数据集的SSA子集上，我们基于HuBERT$_{base}$ (0.09B) 架构的方法展现出了具有竞争力的结果，与FLEURS基准提出的w2v-bert-51 (0.6B) 预训练模型相比，在ASR下游任务中更加高效，使用的数据量少7倍，参数少6倍。此外，在LID下游任务中，我们的方法在准确率上超过FLEURS基线超过22%。

    arXiv:2404.02000v1 Announce Type: new  Abstract: We present the first self-supervised multilingual speech model trained exclusively on African speech. The model learned from nearly 60 000 hours of unlabeled speech segments in 21 languages and dialects spoken in sub-Saharan Africa. On the SSA subset of the FLEURS-102 dataset, our approach based on a HuBERT$_{base}$ (0.09B) architecture shows competitive results, for ASR downstream task, compared to the w2v-bert-51 (0.6B) pre-trained model proposed in the FLEURS benchmark, while being more efficient by using 7x less data and 6x less parameters. Furthermore, in the context of a LID downstream task, our approach outperforms FLEURS baselines accuracy by over 22\%.
    
[^4]: 对COVID-19检测的空间分割特征学习进行更细致的研究

    A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection

    [https://arxiv.org/abs/2404.01643](https://arxiv.org/abs/2404.01643)

    为解决CT扫描中存在的变异性和OOD切片挑战，提出了一种增强型的空间分割特征学习框架，通过滤除OOD数据和减少冗余来选择关键的空间切片进行分析，并引入了基于核密度的切片采样方法来提高稳定性和加快收敛速度

    

    传统的计算机断层扫描（CT）成像识别面临两个重要挑战：（1）每个CT扫描的分辨率和大小经常存在相当大的变异性，需要对输入尺寸和模型的适应性有严格的要求。 （2）CT扫描包含大量的超出分布范围（OOD）切片。关键特性可能仅存在于整个CT扫描的特定空间区域和切片中。我们如何有效地找出这些区域的位置？为了解决这个问题，我们引入了一种针对CT扫描的增强型空间分割特征学习（SSFL ++）框架。它旨在从整个CT扫描中滤除OOD数据，通过完全减少70％的冗余来选择关键的空间切片进行分析。同时，我们提出了一种基于核密度的切片采样（KDS）方法，以提高训练和推断阶段的稳定性，从而加快收敛速度。

    arXiv:2404.01643v1 Announce Type: cross  Abstract: Conventional Computed Tomography (CT) imaging recognition faces two significant challenges: (1) There is often considerable variability in the resolution and size of each CT scan, necessitating strict requirements for the input size and adaptability of models. (2) CT-scan contains large number of out-of-distribution (OOD) slices. The crucial features may only be present in specific spatial regions and slices of the entire CT scan. How can we effectively figure out where these are located? To deal with this, we introduce an enhanced Spatial-Slice Feature Learning (SSFL++) framework specifically designed for CT scan. It aim to filter out a OOD data within whole CT scan, enabling our to select crucial spatial-slice for analysis by reducing 70% redundancy totally. Meanwhile, we proposed Kernel-Density-based slice Sampling (KDS) method to improve the stability when training and inference stage, therefore speeding up the rate of convergence 
    
[^5]: 机器学习鲁棒性：入门指南

    Machine Learning Robustness: A Primer

    [https://arxiv.org/abs/2404.00897](https://arxiv.org/abs/2404.00897)

    该章节探讨了机器学习中稳健性的重要概念及关键的技术和因素，以确立人工智能系统的可信度。

    

    这一章节探讨了机器学习（ML）中稳健性的基本概念及其在确立人工智能（AI）系统的可信度中的重要作用。讨论始于稳健性的详细定义，将其描述为ML模型在各种不同和意外的环境条件下保持稳定性能的能力。ML鲁棒性通过多个视角进行了剖析：其与泛化能力的互补性；其作为可信AI的要求；其对抗性与非对抗性方面；其数量化指标；以及其可复现性和可解释性等指标。章节深入探讨了影响鲁棒性的因素，如数据偏差、模型复杂性以及ML流程不明确的风险。它从广泛的视角调查了鲁棒性评估的关键技术，包括对抗性攻击，包括数字和物理领域。

    arXiv:2404.00897v1 Announce Type: cross  Abstract: This chapter explores the foundational concept of robustness in Machine Learning (ML) and its integral role in establishing trustworthiness in Artificial Intelligence (AI) systems. The discussion begins with a detailed definition of robustness, portraying it as the ability of ML models to maintain stable performance across varied and unexpected environmental conditions. ML robustness is dissected through several lenses: its complementarity with generalizability; its status as a requirement for trustworthy AI; its adversarial vs non-adversarial aspects; its quantitative metrics; and its indicators such as reproducibility and explainability. The chapter delves into the factors that impede robustness, such as data bias, model complexity, and the pitfalls of underspecified ML pipelines. It surveys key techniques for robustness assessment from a broad perspective, including adversarial attacks, encompassing both digital and physical realms.
    
[^6]: YOLOOC: 基于YOLO的开放类别增量目标检测与新类别发现

    YOLOOC: YOLO-based Open-Class Incremental Object Detection with Novel Class Discovery

    [https://arxiv.org/abs/2404.00257](https://arxiv.org/abs/2404.00257)

    该论文提出了基于YOLO架构的YOLOOC检测器，针对开放类别设置引入了标签平滑，有效应对新类别检测和增量学习的挑战。

    

    最近，由于其在实践中的运用，开放世界目标检测（OWOD）受到了很多关注。挑战在于模型如何检测新类别，然后增量学习它们而不会忘记先前已知的类别。先前的方法依赖于强监督或弱监督的新类别数据用于新类别检测，这可能不适用于实际应用。我们构建了一个新的基准，其中新类别只在推断阶段遇到。我们提出了一种基于YOLO架构的新OWOD检测器YOLOOC，专门针对开放类别的设置。我们引入了标签平滑以防止检测器过于自信地将新类别映射到已知类别并发现新类别。在我们更加现实的设置上进行的大量实验表明，我们的方法在我们的新基准下发现新类别的有效性。

    arXiv:2404.00257v1 Announce Type: cross  Abstract: Because of its use in practice, open-world object detection (OWOD) has gotten a lot of attention recently. The challenge is how can a model detect novel classes and then incrementally learn them without forgetting previously known classes. Previous approaches hinge on strongly-supervised or weakly-supervised novel-class data for novel-class detection, which may not apply to real applications. We construct a new benchmark that novel classes are only encountered at the inference stage. And we propose a new OWOD detector YOLOOC, based on the YOLO architecture yet for the Open-Class setup. We introduce label smoothing to prevent the detector from over-confidently mapping novel classes to known classes and to discover novel classes. Extensive experiments conducted on our more realistic setup demonstrate the effectiveness of our method for discovering novel classes in our new benchmark.
    
[^7]: LLM作为写作助手：探讨所有权感和推理的视角

    LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning

    [https://arxiv.org/abs/2404.00027](https://arxiv.org/abs/2404.00027)

    探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。

    

    写作中的所有权感限制了我们对思想、时间和贡献的投入，导致对产出物的依恋。然而，使用写作助手引入了一种心理困境，因为一些内容并非直接我们的创作。我们往往更倾向于在创造性任务中更多地归功于大型语言模型（LLMs），尽管它们对所有任务都是平等的。此外，虽然我们可能不会完全声称对由LLM生成的内容拥有所有权，但却自由地声称作者身份。我们进行了一项简短调查来研究这些问题，并了解潜在的认知过程，以更好地了解人机交互在写作中的应用并改进写作辅助系统。

    arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
    
[^8]: 墨水与个性：在LLMs时代塑造个性化叙事

    Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs

    [https://arxiv.org/abs/2404.00026](https://arxiv.org/abs/2404.00026)

    研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。

    

    个性和个性化构成了使每个作家独特并影响其文字以有效吸引读者同时传达真实性的独特特征。然而，我们日益依赖基于LLM的写作助手可能会危及我们的创造力和个性。我们经常忽视这一趋势对我们的创造力和独特性的负面影响，尽管可能会造成后果。本研究通过进行简要调查探索不同的观点和概念，以及尝试理解人们的观点，结合以往在该领域的研究，来研究这些问题。解决这些问题对于改进人机交互系统和增强个性化和个性化写作助手至关重要。

    arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
    
[^9]: 流行病建模中图神经网络的综述

    A Review of Graph Neural Networks in Epidemic Modeling

    [https://arxiv.org/abs/2403.19852](https://arxiv.org/abs/2403.19852)

    图神经网络在流行病建模中作为一种新工具备受关注，本文全面回顾了GNN在流行病研究中的应用，并提出了未来发展方向。

    

    自新冠疫情爆发以来，人们对流行病学模型的研究越来越感兴趣。传统的机械模型数学描述了传染病的传播机制，但在面对当今不断增长的挑战时往往力不从心。因此，图神经网络（GNNs）已经成为流行病研究中越来越流行的工具。本文试图全面回顾GNN在流行病任务中的应用，并强调潜在的未来发展方向。为实现这一目标，我们为流行病任务和方法论各引入了分层分类法，为该领域内的发展轨迹提供了一个框架。对于流行病任务，我们建立了一个类似于流行病领域通常应用的分类体系。对于方法论，我们将现有研究分为“神经模型”和“混合模型”。

    arXiv:2403.19852v1 Announce Type: new  Abstract: Since the onset of the COVID-19 pandemic, there has been a growing interest in studying epidemiological models. Traditional mechanistic models mathematically describe the transmission mechanisms of infectious diseases. However, they often fall short when confronted with the growing challenges of today. Consequently, Graph Neural Networks (GNNs) have emerged as a progressively popular tool in epidemic research. In this paper, we endeavor to furnish a comprehensive review of GNNs in epidemic tasks and highlight potential future directions. To accomplish this objective, we introduce hierarchical taxonomies for both epidemic tasks and methodologies, offering a trajectory of development within this domain. For epidemic tasks, we establish a taxonomy akin to those typically employed within the epidemic domain. For methodology, we categorize existing work into \textit{Neural Models} and \textit{Hybrid Models}. Following this, we perform an exha
    
[^10]: 强化学习用于黑盒图像、视频和心电图信号分类的鲁棒性和视觉解释

    Robustness and Visual Explanation for Black Box Image, Video, and ECG Signal Classification with Reinforcement Learning

    [https://arxiv.org/abs/2403.18985](https://arxiv.org/abs/2403.18985)

    提出了一个通用的强化学习框架，用于从心电图信号分析到图像和视频分类的不同模型类型的对抗攻击，通过识别敏感区域并在最小程度扭曲下诱导错误分类，生成优越的定位掩模，并在鲁棒性和透明度方面取得了显著进展。

    

    我们提出了一个通用的强化学习（RL）框架，针对从心电图信号分析（1D）、图像分类（2D）到视频分类（3D）等不同模型类型进行对抗攻击的优化。该框架专注于识别敏感区域并在最小程度扭曲和各种扭曲类型下诱导错误分类。新颖的RL方法在所有三个应用中优于最先进的方法，证明了其效率。我们的RL方法生成了优越的定位掩模，增强了图像分类和心电图分析模型的可解释性。对于心电图分析等应用，我们的平台突出了临床医生关注的关键心电图片段，同时确保对流行扭曲的韧性。这一全面的工具旨在通过对抗性训练和透明度提高各种应用和数据类型的韧性。

    arXiv:2403.18985v1 Announce Type: cross  Abstract: We present a generic Reinforcement Learning (RL) framework optimized for crafting adversarial attacks on different model types spanning from ECG signal analysis (1D), image classification (2D), and video classification (3D). The framework focuses on identifying sensitive regions and inducing misclassifications with minimal distortions and various distortion types. The novel RL method outperforms state-of-the-art methods for all three applications, proving its efficiency. Our RL approach produces superior localization masks, enhancing interpretability for image classification and ECG analysis models. For applications such as ECG analysis, our platform highlights critical ECG segments for clinicians while ensuring resilience against prevalent distortions. This comprehensive tool aims to bolster both resilience with adversarial training and transparency across varied applications and data types.
    
[^11]: 压缩多任务嵌入用于地球观测中数据高效下游训练和推断

    Compressed Multi-task embeddings for Data-Efficient Downstream training and inference in Earth Observation

    [https://arxiv.org/abs/2403.17886](https://arxiv.org/abs/2403.17886)

    基于神经嵌入压缩的多任务嵌入方法在地球观测中实现了数据高效的训练和推断，通过压缩率与嵌入效用之间的权衡，取得了数据量显著减少的准确性。

    

    随着地球观测（EO）中大规模数据的存储库增长，模型训练和推断的转移和存储成本也在增加，消耗了大量资源。我们引入了基于神经嵌入压缩（NEC）的方法，该方法基于对数据使用者传输压缩的嵌入而不是原始数据。我们通过学习神经压缩来调整基础模型（FM），生成多任务嵌入，同时在压缩率和嵌入效用之间进行权衡。我们仅针对FM参数的一小部分（10%）进行更新，进行短时间训练（预训练迭代的1%）。我们在两个EO任务上评估了NEC：场景分类和语义分割。与将传统压缩应用于原始数据相比，NEC在减少数据量方面可实现类似的准确性，降低了75%到90%的数据量。即使在99.7%的压缩下，在场景分类任务上性能仅下降了5%。总体而言，NEC是一种数据高效

    arXiv:2403.17886v1 Announce Type: new  Abstract: As repositories of large scale data in earth observation (EO) have grown, so have transfer and storage costs for model training and inference, expending significant resources. We introduce Neural Embedding Compression (NEC), based on the transfer of compressed embeddings to data consumers instead of raw data. We adapt foundation models (FM) through learned neural compression to generate multi-task embeddings while navigating the tradeoff between compression rate and embedding utility. We update only a small fraction of the FM parameters (10%) for a short training period (1% of the iterations of pre-training). We evaluate NEC on two EO tasks: scene classification and semantic segmentation. Compared with applying traditional compression to the raw data, NEC achieves similar accuracy with a 75% to 90% reduction in data. Even at 99.7% compression, performance drops by only 5% on the scene classification task. Overall, NEC is a data-efficient
    
[^12]: VoiceCraft：野外零-shot语音编辑和文本到语音

    VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild

    [https://arxiv.org/abs/2403.16973](https://arxiv.org/abs/2403.16973)

    VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。

    

    我们介绍了VoiceCraft，一个基于标记填充的神经编解码器语言模型，实现了在有声书、互联网视频和播客上语音编辑和零-shot文本到语音（TTS）方面的最新性能。VoiceCraft采用Transformer解码器架构，并引入了一种标记重排过程，结合了因果掩码和延迟堆叠，以实现在现有序列内的生成。在语音编辑任务上，VoiceCraft生成的编辑语音在自然度方面几乎与未编辑的录音难以区分，经人类评估；对于零-shot TTS，我们的模型优于先前的最先进模型，包括VALLE和流行的商业模型XTTS-v2。关键的是，这些模型在具有多样口音、语音风格、录制条件、背景噪音和音乐的具有挑战性和真实性的数据集上进行了评估，我们的模型与其他模型相比表现始终良好。

    arXiv:2403.16973v1 Announce Type: cross  Abstract: We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VoiceCraft produces edited speech that is nearly indistinguishable from unedited recordings in terms of naturalness, as evaluated by humans; for zero-shot TTS, our model outperforms prior SotA models including VALLE and the popular commercial model XTTS-v2. Crucially, the models are evaluated on challenging and realistic datasets, that consist of diverse accents, speaking styles, recording conditions, and background noise and music, and our model performs consistently well compared to other models a
    
[^13]: 用于腿式定点机器人运动操作的视觉全身控制

    Visual Whole-Body Control for Legged Loco-Manipulation

    [https://arxiv.org/abs/2403.16967](https://arxiv.org/abs/2403.16967)

    这项研究提出了一种利用视觉全身控制的框架，使腿式机器人能够同时控制腿部和手臂，以扩展操作能力，并通过仿真训练和Sim2Real转移实现了在捡起不同物体方面取得显著改进。

    

    我们研究了使用配备手臂的腿式机器人进行移动操作的问题，即腿式定点操作。尽管机器人的腿通常用于移动，但通过进行全身控制，可以扩大其操作能力。也就是说，机器人可以同时控制腿部和手臂，以扩展其工作空间。我们提出了一个能够使用视觉观测自主进行全身控制的框架。我们的方法称为\ourFull~(\our)，由一个低级策略和一个高级策略组成。低级策略使用所有自由度来跟踪末端执行器的位置，高级策略根据视觉输入提出末端执行器位置。我们在仿真中训练了两个级别的策略，并进行了从Sim到实物的转移以进行实际机器人部署。我们进行了大量实验证明，在不同配置下（高度、）捡起不同物体方面，相对基线方法取得了显著改进。

    arXiv:2403.16967v1 Announce Type: cross  Abstract: We study the problem of mobile manipulation using legged robots equipped with an arm, namely legged loco-manipulation. The robot legs, while usually utilized for mobility, offer an opportunity to amplify the manipulation capabilities by conducting whole-body control. That is, the robot can control the legs and the arm at the same time to extend its workspace. We propose a framework that can conduct the whole-body control autonomously with visual observations. Our approach, namely \ourFull~(\our), is composed of a low-level policy using all degrees of freedom to track the end-effector manipulator position and a high-level policy proposing the end-effector position based on visual inputs. We train both levels of policies in simulation and perform Sim2Real transfer for real robot deployment. We perform extensive experiments and show significant improvements over baselines in picking up diverse objects in different configurations (heights,
    
[^14]: 重新思考对抗逆强化学习：从策略模仿和可转移奖励恢复的角度

    Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery

    [https://arxiv.org/abs/2403.14593](https://arxiv.org/abs/2403.14593)

    重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。

    

    对抗逆强化学习（AIRL）作为模仿学习中的基石方法。本文重新思考了AIRL的两个不同角度：策略模仿和可转移奖励恢复。我们从用Soft Actor-Critic（SAC）替换AIRL中的内置算法开始，以增强样本效率，这要归功于SAC的离策略形式和相对于AIRL而言可识别的马尔可夫决策过程（MDP）模型。这确实在策略模仿方面表现出显著的改进，但不慎给可转移奖励恢复带来了缺点。为了解决这个问题，我们阐述了SAC算法本身在AIRL训练过程中无法全面解开奖励函数，提出了一个混合框架，PPO-AIRL + SAC，以获得令人满意的转移效果。此外，我们分析了环境提取解开的奖励的能力。

    arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
    
[^15]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^16]: 基于高斯过程回归的机器学习系统可靠性分析

    Machine learning-based system reliability analysis with Gaussian Process Regression

    [https://arxiv.org/abs/2403.11125](https://arxiv.org/abs/2403.11125)

    本文提出了基于高斯过程回归的机器学习系统可靠性分析方法，并通过几个定理探讨了最优学习策略，包括考虑和忽略样本之间的相关性以及顺序多个训练样本增益的理论最优策略。

    

    arXiv:2403.11125v1 公告类型: 交叉 摘要: 基于机器学习的可靠性分析方法在计算效率和准确性方面取得了巨大进展。最近，已经提出许多有效的学习策略来增强计算性能。然而，其中很少有人探讨了理论上的最优学习策略。在这篇文章中，我们提出了几个定理来促进这种探索。具体来说，详细阐述了考虑和忽略候选设计样本之间相关性的情况。此外，我们证明了众所周知的 U 学习函数可以重新制定为在忽略 Kriging 相关性的情况下的最优学习函数。此外，还通过带有相应损失函数的贝叶斯估计数学上探讨了顺序多个训练样本增益的理论上最优学习策略。模拟结果表明最优学习策略……

    arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid
    
[^17]: 野外情感维度识别的联合多模态Transformer

    Joint Multimodal Transformer for Dimensional Emotional Recognition in the Wild

    [https://arxiv.org/abs/2403.10488](https://arxiv.org/abs/2403.10488)

    该工作提出了一种联合多模态Transformer架构的音视频情感识别系统，能够在视频中同时利用音频和视觉线索，实现更优越的性能。

    

    在视频中进行音视频情感识别对于单模性能具有巨大潜力。它有效地利用了视觉和听觉模态之间以及模态内部的依赖关系。本工作提出了一种利用关键交叉注意力的联合多模态Transformer架构的音视频情感识别系统。该框架旨在利用视频中音频和视觉线索（面部表情和语音模式）的互补性，相较于仅依赖于单一模态，实现了更优越的性能。所提出的模型利用单独的主干网络来捕获每种模态（音频和视觉）内部的时间依赖关系。随后，一个联合多模态Transformer架构集成了各自模态的嵌入，使该模型能够有效地捕获模态间（音频和视觉之间）和模态内部（每种模态内部）的关系。

    arXiv:2403.10488v1 Announce Type: cross  Abstract: Audiovisual emotion recognition (ER) in videos has immense potential over unimodal performance. It effectively leverages the inter- and intra-modal dependencies between visual and auditory modalities. This work proposes a novel audio-visual emotion recognition system utilizing a joint multimodal transformer architecture with key-based cross-attention. This framework aims to exploit the complementary nature of audio and visual cues (facial expressions and vocal patterns) in videos, leading to superior performance compared to solely relying on a single modality. The proposed model leverages separate backbones for capturing intra-modal temporal dependencies within each modality (audio and visual). Subsequently, a joint multimodal transformer architecture integrates the individual modality embeddings, enabling the model to effectively capture inter-modal (between audio and visual) and intra-modal (within each modality) relationships. Exten
    
[^18]: 震动泄密：微调扩散模型可能增加生成隐私风险

    Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative Privacy Risk

    [https://arxiv.org/abs/2403.09450](https://arxiv.org/abs/2403.09450)

    微调扩散模型可能会增加生成隐私风险，甚至使最先进的成员推理攻击对扩散模型的攻击效果提高5.4％，并可将提取的私有样本数量从几乎0个增加到平均16.3个。

    

    虽然扩散模型最近在生成逼真图像方面取得了显著进展，但也存在隐私风险：已发布的模型或API可能生成训练图像，从而泄露涉及隐私的训练信息。本文揭示了一种新风险，即Shake-to-Leak (S2L)，即使用操纵数据微调预训练模型可能会增加现有的隐私风险。我们证明了S2L可能发生在各种标准的扩散模型微调策略中，包括概念注入方法（DreamBooth和Textual Inversion）和参数高效方法（LoRA和Hypernetwork），以及它们的组合。在最糟糕的情况下，S2L可以将扩散模型上的最新成员推理攻击（MIA）的AUC提高5.4％（绝对差异），并且可以将每个目标域的提取私有样本从几乎0个样本增加到平均16.3个样本。这一发现强调了

    arXiv:2403.09450v1 Announce Type: new  Abstract: While diffusion models have recently demonstrated remarkable progress in generating realistic images, privacy risks also arise: published models or APIs could generate training images and thus leak privacy-sensitive training information. In this paper, we reveal a new risk, Shake-to-Leak (S2L), that fine-tuning the pre-trained models with manipulated data can amplify the existing privacy risks. We demonstrate that S2L could occur in various standard fine-tuning strategies for diffusion models, including concept-injection methods (DreamBooth and Textual Inversion) and parameter-efficient methods (LoRA and Hypernetwork), as well as their combinations. In the worst case, S2L can amplify the state-of-the-art membership inference attack (MIA) on diffusion models by $5.4\%$ (absolute difference) AUC and can increase extracted private samples from almost $0$ samples to $16.3$ samples on average per target domain. This discovery underscores that
    
[^19]: 一个解决神经技术认知安全问题的数学框架

    A Mathematical Framework for the Problem of Security for Cognition in Neurotechnology

    [https://arxiv.org/abs/2403.07945](https://arxiv.org/abs/2403.07945)

    本文提出了一个数学框架，名为认知安全，用于描述和分析神经技术对个体认知隐私和自治可能产生的影响，解决了相关问题描述和分析的障碍。

    

    近年来神经技术的快速发展在神经技术和安全之间创造了一个新兴的关键交叉点。植入式设备、非侵入式监测和非侵入式治疗都带来了违反个体认知隐私和自治的前景。越来越多的科学家和医生呼吁解决这一问题 -- 我们称之为认知安全 -- 但应用工作受到限制。阻碍科学和工程努力解决认知安全问题的一个主要障碍是缺乏清晰描述和分析相关问题的手段。在本文中，我们开发了认知安全，这是一个数学框架，通过借鉴多个领域的方法和结果，实现这种描述和分析。我们展示了一些对认知安全有重要影响的统计特性，然后提出描述...

    arXiv:2403.07945v1 Announce Type: cross  Abstract: The rapid advancement in neurotechnology in recent years has created an emerging critical intersection between neurotechnology and security. Implantable devices, non-invasive monitoring, and non-invasive therapies all carry with them the prospect of violating the privacy and autonomy of individuals' cognition. A growing number of scientists and physicians have made calls to address this issue -- which we term Cognitive Security -- but applied efforts have been limited. A major barrier hampering scientific and engineering efforts to address Cognitive Security is the lack of a clear means of describing and analyzing relevant problems. In this paper we develop Cognitive Security, a mathematical framework which enables such description and analysis by drawing on methods and results from multiple fields. We demonstrate certain statistical properties which have significant implications for Cognitive Security, and then present descriptions of
    
[^20]: WorkArena：Web代理在解决常见知识工作任务中的能力如何？

    WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?

    [https://arxiv.org/abs/2403.07718](https://arxiv.org/abs/2403.07718)

    该研究探究了基于大型语言模型的代理在通过web浏览器与软件交互时的能力，提出了WorkArena和BrowserGym两个工具，在29个任务的基准测试中显示出潜力，但也揭示了实现完全任务自动化仍存在挑战。

    

    我们研究了基于大型语言模型的代理与软件通过web浏览器交互的应用。与先前的研究不同，我们关注衡量这些代理执行任务的能力，这些任务涵盖了利用企业软件系统的知识工作者的典型日常工作。为此，我们提出了WorkArena，一个基于广泛使用的ServiceNow平台的29个任务的远程主机基准。我们还介绍了BrowserGym，这是一个用于设计和评估这些代理的环境，提供了丰富的行为和多模态观察。我们的实证评估显示，尽管当前的代理在WorkArena上表现出了潜力，但要实现完全任务自动化仍存在相当大的差距。值得注意的是，我们的分析揭示了开源和闭源LLMs之间显著的性能差距，突出了未来探索和发展领域的一个重要领域。

    arXiv:2403.07718v1 Announce Type: cross  Abstract: We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.
    
[^21]: 三维形状重建的贝叶斯扩散模型

    Bayesian Diffusion Models for 3D Shape Reconstruction

    [https://arxiv.org/abs/2403.06973](https://arxiv.org/abs/2403.06973)

    BDM是一种利用联合扩散过程紧密耦合先验信息与数据驱动过程的预测算法，专注于3D形状重建任务，通过引入独立标签的丰富先验信息来改善自下而上的重建过程。

    

    我们提出了贝叶斯扩散模型（BDM），这是一种预测算法，通过联合扩散过程将自上而下（先验）信息与自下而上（数据驱动）过程紧密耦合，实现有效的贝叶斯推断。我们展示了BDM在3D形状重建任务中的有效性。与基于配对（监督）数据标签（例如图像-点云）数据集训练的典型深度学习数据驱动方法相比，我们的BDM通过引入来自独立标签（例如点云）的丰富先验信息来改进自下而上的3D重建。与标准的贝叶斯框架相反，其需要明确的先验和似然进行推断，BDM通过学习的梯度计算网络通过耦合扩散过程执行无缝信息融合。我们BDM的特殊之处在于其能够在自上而下和自下而上的主动有效信息交换和融合。

    arXiv:2403.06973v1 Announce Type: cross  Abstract: We present Bayesian Diffusion Models (BDM), a prediction algorithm that performs effective Bayesian inference by tightly coupling the top-down (prior) information with the bottom-up (data-driven) procedure via joint diffusion processes. We show the effectiveness of BDM on the 3D shape reconstruction task. Compared to prototypical deep learning data-driven approaches trained on paired (supervised) data-labels (e.g. image-point clouds) datasets, our BDM brings in rich prior information from standalone labels (e.g. point clouds) to improve the bottom-up 3D reconstruction. As opposed to the standard Bayesian frameworks where explicit prior and likelihood are required for the inference, BDM performs seamless information fusion via coupled diffusion processes with learned gradient computation networks. The specialty of our BDM lies in its capability to engage the active and effective information exchange and fusion of the top-down and bottom
    
[^22]: 用Hodge-Laplacian和注意机制进展图神经网络：一种针对异构图结构数据的方法

    Advancing Graph Neural Networks with HL-HGAT: A Hodge-Laplacian and Attention Mechanism Approach for Heterogeneous Graph-Structured Data

    [https://arxiv.org/abs/2403.06687](https://arxiv.org/abs/2403.06687)

    本研究提出了Hodge-Laplacian异构图注意网络（HL-HGAT），通过HL卷积滤波器、单纯投影和单纯注意池化运算符，可以学习跨k-单纯体的异构信号表示。

    

    图神经网络（GNNs）在捕捉图中节点之间的关系方面已被证明是有效的。本研究通过考虑将图作为一个单纯复合体的新视角，包含节点、边、三角形和k-单纯体，从而使得可以在任何k-单纯体上定义图结构数据。我们的贡献是Hodge-Laplacian异构图注意网络（HL-HGAT），旨在学习跨k-单纯体的异构信号表示。HL-HGAT包含三个关键组件：HL卷积滤波器（HL-filters）、单纯投影（SP）和单纯注意池化（SAP）运算符，应用于k-单纯体。HL-filters利用由Hodge-Laplacian（HL）算子编码的k-单纯体的独特拓扑结构，在k-th HL算子的频谱域内运作。为了解决计算挑战，我们介绍了一种HL-filters的多项式逼近，展示了在谱域解决异构图注意跨k-单纯体的计算挑战。

    arXiv:2403.06687v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have proven effective in capturing relationships among nodes in a graph. This study introduces a novel perspective by considering a graph as a simplicial complex, encompassing nodes, edges, triangles, and $k$-simplices, enabling the definition of graph-structured data on any $k$-simplices. Our contribution is the Hodge-Laplacian heterogeneous graph attention network (HL-HGAT), designed to learn heterogeneous signal representations across $k$-simplices. The HL-HGAT incorporates three key components: HL convolutional filters (HL-filters), simplicial projection (SP), and simplicial attention pooling (SAP) operators, applied to $k$-simplices. HL-filters leverage the unique topology of $k$-simplices encoded by the Hodge-Laplacian (HL) operator, operating within the spectral domain of the $k$-th HL operator. To address computation challenges, we introduce a polynomial approximation for HL-filters, exhibiting spatia
    
[^23]: 面向音频-视频人员验证的动态交叉注意力

    Dynamic Cross Attention for Audio-Visual Person Verification

    [https://arxiv.org/abs/2403.04661](https://arxiv.org/abs/2403.04661)

    提出了一种动态交叉注意力（DCA）模型，根据音频和视频模态之间的强弱互补关系，动态选择交叉关注或不关注的特征。

    

    尽管人员或身份验证通常使用个体模态（如面部和声音）进行探索，但最近显示出巨大潜力的音视频融合方法可以胜过单模态方法。音频和视觉模态通常被期望具有强烈的互补关系，在有效的音视频融合中起着至关重要的作用。然而，它们并不总是强烈相互补充，它们也可能展现出弱的互补关系，导致音视频特征表示不佳。本文提出了一种动态交叉注意力（DCA）模型，可以根据跨音频和视觉模态之间的强弱互补关系，动态选择交叉关注或不关注的特征。特别地，设计了一个条件门控层来评估交叉注意力机制的贡献，并仅选择跨模态关注的特征。

    arXiv:2403.04661v1 Announce Type: cross  Abstract: Although person or identity verification has been predominantly explored using individual modalities such as face and voice, audio-visual fusion has recently shown immense potential to outperform unimodal approaches. Audio and visual modalities are often expected to pose strong complementary relationships, which plays a crucial role in effective audio-visual fusion. However, they may not always strongly complement each other, they may also exhibit weak complementary relationships, resulting in poor audio-visual feature representations. In this paper, we propose a Dynamic Cross-Attention (DCA) model that can dynamically select the cross-attended or unattended features on the fly based on the strong or weak complementary relationships, respectively, across audio and visual modalities. In particular, a conditional gating layer is designed to evaluate the contribution of the cross-attention mechanism and choose cross-attended features only
    
[^24]: 软约束薛定谔桥：一种随机控制方法

    Soft-constrained Schrodinger Bridge: a Stochastic Control Approach

    [https://arxiv.org/abs/2403.01717](https://arxiv.org/abs/2403.01717)

    提出了软约束薛定谔桥(SSB)控制问题，在允许终端分布与预先指定分布不同的情况下，惩罚两者之间的Kullback-Leibler散度。理论上推导出了SSB解，显示最优控制过程的终端分布是μT和其他分布的几何混合，并将结果扩展到时间序列设置。

    

    薛定谔桥可以被视为一个连续时间的随机控制问题，目标是找到一个最优控制扩散过程，其具有预先指定的终端分布μT。我们提出通过允许终端分布与μT不同但惩罚两个分布之间的Kullback-Leibler散度来泛化这个随机控制问题。我们将这个新的控制问题称为软约束薛定谔桥(SSB)。这项工作的主要贡献是对SSB解的理论推导，表明最优控制过程的终端分布是μT和另一些分布的几何混合。这个结果进一步扩展到时间序列设置。SSB的一个应用是鲁棒生成扩散模型的开发。我们提出了一个基于分数匹配的算法来从几何混合中进行抽样，并展示了其用途

    arXiv:2403.01717v1 Announce Type: cross  Abstract: Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control problem where the goal is to find an optimally controlled diffusion process with a pre-specified terminal distribution $\mu_T$. We propose to generalize this stochastic control problem by allowing the terminal distribution to differ from $\mu_T$ but penalizing the Kullback-Leibler divergence between the two distributions. We call this new control problem soft-constrained Schr\"{o}dinger bridge (SSB). The main contribution of this work is a theoretical derivation of the solution to SSB, which shows that the terminal distribution of the optimally controlled process is a geometric mixture of $\mu_T$ and some other distribution. This result is further extended to a time series setting. One application of SSB is the development of robust generative diffusion models. We propose a score matching-based algorithm for sampling from geometric mixtures and showcase its us
    
[^25]: 使用图神经网络预测当地文化

    Using Graph Neural Networks to Predict Local Culture

    [https://arxiv.org/abs/2402.17905](https://arxiv.org/abs/2402.17905)

    本研究提出了使用图神经网络（GNN）方法，结合多个信息源来更好地预测社区属性，特别是预测当地文化，结果显示了这一方法在考虑结构相连性方面的潜力。

    

    城市研究长期以来一直认识到社区是动态和关联的。然而，缺乏数据、方法论和计算处理能力阻碍了对社区关系动态进行正式定量分析。为了在这个问题上取得进展，本研究提出了一种图神经网络（GNN）方法，允许结合和评估关于社区内部特征、它们的过去特征以及在它们之间流动的群体的多个信息源，潜在地为预测模型提供更大的表达能力。通过探索 Yelp 的公开大规模数据集，我们展示了我们的方法在考虑结构相连性方面对预测社区属性（特别是预测当地文化）的潜力。从实质和方法论角度来看，结果是令人鼓舞的。从实质上讲，我们发现无论是当地区域信息（例如区域人口统计信息）

    arXiv:2402.17905v1 Announce Type: new  Abstract: Urban research has long recognized that neighbourhoods are dynamic and relational. However, lack of data, methodologies, and computer processing power have hampered a formal quantitative examination of neighbourhood relational dynamics. To make progress on this issue, this study proposes a graph neural network (GNN) approach that permits combining and evaluating multiple sources of information about internal characteristics of neighbourhoods, their past characteristics, and flows of groups among them, potentially providing greater expressive power in predictive models. By exploring a public large-scale dataset from Yelp, we show the potential of our approach for considering structural connectedness in predicting neighbourhood attributes, specifically to predict local culture. Results are promising from a substantive and methodologically point of view. Substantively, we find that either local area information (e.g. area demographics) or g
    
[^26]: 研究随机性对深度神经网络在森林火灾预测中评估的影响

    Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction

    [https://arxiv.org/abs/2402.15163](https://arxiv.org/abs/2402.15163)

    该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。

    

    本文首次系统研究了在随机假设下评估深度神经网络（DNNs）用于离散动力系统，重点关注野火预测。我们开发了一个框架来研究随机性对两类评估指标的影响：基于分类的指标，评估对观察地面真相（GT）的忠实度，以及适当的得分规则，测试对统计的忠实度。我们的研究结果表明，在高度随机的情况下，评估对统计的忠实度是一个可靠的替代方案。我们将我们的分析扩展到现实世界的森林火灾数据，突显了传统森林火灾预测评估方法中的局限性，并建议可解释的适用于随机性的替代方法。

    arXiv:2402.15163v1 Announce Type: cross  Abstract: This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction. We develop a framework to study the impact of stochasticity on two classes of evaluation metrics: classification-based metrics, which assess fidelity to observed ground truth (GT), and proper scoring rules, which test fidelity-to-statistic. Our findings reveal that evaluating for fidelity-to-statistic is a reliable alternative in highly stochastic scenarios. We extend our analysis to real-world wildfire data, highlighting limitations in traditional wildfire prediction evaluation methods, and suggest interpretable stochasticity-compatible alternatives.
    
[^27]: 一种对事件识别模型鲁棒性进行评估的对抗方法

    An Adversarial Approach to Evaluating the Robustness of Event Identification Models

    [https://arxiv.org/abs/2402.12338](https://arxiv.org/abs/2402.12338)

    该论文提出了一种基于物理的模态分解方法用于提取事件分类特征，并评估了可解释分类器在面对对抗算法时的鲁棒性。

    

    智能机器学习方法正在积极用于事件检测和识别，可实时获得态势感知。然而，这些机器学习算法已被证明容易受到对传入遥测数据的对抗性攻击。本文考虑了一种基于物理的模态分解方法来提取事件分类的特征，并专注于可解释的分类器，包括逻辑回归和梯度提升，以区分两种类型的事件：负载损失和发电损失。然后，对生成的分类器进行对抗算法测试以评估其鲁棒性。对抗攻击在两种情境下进行测试：白盒设置，攻击者完全了解分类模型；灰盒设置，攻击者可以访问与用于训练分类器的相同网络的历史数据，但不知道分类

    arXiv:2402.12338v1 Announce Type: cross  Abstract: Intelligent machine learning approaches are finding active use for event detection and identification that allow real-time situational awareness. Yet, such machine learning algorithms have been shown to be susceptible to adversarial attacks on the incoming telemetry data. This paper considers a physics-based modal decomposition method to extract features for event classification and focuses on interpretable classifiers including logistic regression and gradient boosting to distinguish two types of events: load loss and generation loss. The resulting classifiers are then tested against an adversarial algorithm to evaluate their robustness. The adversarial attack is tested in two settings: the white box setting, wherein the attacker knows exactly the classification model; and the gray box setting, wherein the attacker has access to historical data from the same network as was used to train the classifier, but does not know the classifica
    
[^28]: 自洽的符合预测

    Self-Consistent Conformal Prediction

    [https://arxiv.org/abs/2402.07307](https://arxiv.org/abs/2402.07307)

    自洽的符合预测方法能够提供既符合校准的预测又符合以模型预测的动作为条件的预测区间，为决策者提供了严格的、针对具体动作的决策保证。

    

    在机器学习指导下的决策中，决策者通常在具有相同预测结果的情境中采取相同的行动。符合预测帮助决策者量化动作的结果不确定性，从而实现更好的风险管理。受这种观点的启发，我们引入了自洽的符合预测，它产生了既符合Venn-Abers校准的预测，又符合以模型预测引发的动作为条件的符合预测区间。我们的方法可以后验地应用于任何黑盒预测器，提供严格的、针对具体动作的决策保证。数值实验表明，我们的方法在区间的效率和条件的有效性之间达到了平衡。

    In decision-making guided by machine learning, decision-makers often take identical actions in contexts with identical predicted outcomes. Conformal prediction helps decision-makers quantify outcome uncertainty for actions, allowing for better risk management. Inspired by this perspective, we introduce self-consistent conformal prediction, which yields both Venn-Abers calibrated predictions and conformal prediction intervals that are valid conditional on actions prompted by model predictions. Our procedure can be applied post-hoc to any black-box predictor to provide rigorous, action-specific decision-making guarantees. Numerical experiments show our approach strikes a balance between interval efficiency and conditional validity.
    
[^29]: LLM中的同行评审方法：开放环境下LLMs的自动评估方法

    Peer-review-in-LLMs: Automatic Evaluation Method for LLMs in Open-environment

    [https://arxiv.org/abs/2402.01830](https://arxiv.org/abs/2402.01830)

    本文提出了一种新的无监督评估方法，利用同行评审机制在开放环境中衡量LLMs。通过为每个LLM分配可学习的能力参数，以最大化各个LLM的能力和得分的一致性。结果表明，高层次的LLM能够更准确地评估其他模型的答案，并能够获得更高的响应得分。

    

    现有的大型语言模型（LLMs）评估方法通常集中于在一些有人工注释的封闭环境和特定领域基准上测试性能。本文探索了一种新颖的无监督评估方法，利用同行评审机制自动衡量LLMs。在这个设置中，开源和闭源的LLMs处于同一环境中，能够回答未标记的问题并互相评估，每个LLM的响应得分由其他匿名的LLMs共同决定。为了获取这些模型之间的能力层次结构，我们为每个LLM分配一个可学习的能力参数来调整最终排序结果。我们将其形式化为一个受约束的优化问题，旨在最大化每个LLM的能力和得分的一致性。背后的关键假设是高层次的LLM能够比低层次的LLM更准确地评估其他模型的答案，而高层次的LLM也可以达到较高的响应得分。

    Existing large language models (LLMs) evaluation methods typically focus on testing the performance on some closed-environment and domain-specific benchmarks with human annotations. In this paper, we explore a novel unsupervised evaluation direction, utilizing peer-review mechanisms to measure LLMs automatically. In this setting, both open-source and closed-source LLMs lie in the same environment, capable of answering unlabeled questions and evaluating each other, where each LLM's response score is jointly determined by other anonymous ones. To obtain the ability hierarchy among these models, we assign each LLM a learnable capability parameter to adjust the final ranking. We formalize it as a constrained optimization problem, intending to maximize the consistency of each LLM's capabilities and scores. The key assumption behind is that high-level LLM can evaluate others' answers more accurately than low-level ones, while higher-level LLM can also achieve higher response scores. Moreover
    
[^30]: 利用智能手表麦克风传感器进行咳嗽检测和分类的研究

    Harnessing Smartwatch Microphone Sensors for Cough Detection and Classification

    [https://arxiv.org/abs/2401.17738](https://arxiv.org/abs/2401.17738)

    本研究利用智能手表的麦克风传感器监测和分类了各种咳嗽，通过结构化处理和专门的1D卷积神经网络模型，成功实现了98.49%和98.2%的准确率，并成功识别出四种不同的咳嗽类型。

    

    本研究探讨了利用内置麦克风传感器的智能手表监测咳嗽并检测各种咳嗽类型的潜力。我们进行了一项涉及32名参与者的研究，并以受控方式收集了9个小时的音频数据。之后，我们采用结构化方法对这些数据进行了处理，得到了223个阳性咳嗽样本。我们通过增强技术进一步改进了数据集，并采用了专门的1D卷积神经网络模型。该模型在非步行时具有令人印象深刻的准确率98.49%，在步行时为98.2%，表明智能手表可以检测到咳嗽。此外，我们的研究成功利用聚类技术识别出了四种不同的咳嗽类型。

    This study investigates the potential of using smartwatches with built-in microphone sensors for monitoring coughs and detecting various cough types. We conducted a study involving 32 participants and collected 9 hours of audio data in a controlled manner. Afterward, we processed this data using a structured approach, resulting in 223 positive cough samples. We further improved the dataset through augmentation techniques and employed a specialized 1D CNN model. This model achieved an impressive accuracy rate of 98.49% while non-walking and 98.2% while walking, showing smartwatches can detect cough. Moreover, our research successfully identified four distinct types of coughs using clustering techniques.
    
[^31]: 像素到高程：使用图像学习预测自主越野导航中的长距离高程地图

    Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation

    [https://arxiv.org/abs/2401.17484](https://arxiv.org/abs/2401.17484)

    本研究提出了一种学习方法，可以通过车载视角图像实时预测长距离地形高程地图。该方法包括transformer-based编码器、方向感知的位置编码和历史增强的可学习地图嵌入。通过学习视角图像与鸟瞰图高程地图之间的关联，结合车辆姿态信息和视觉图像特征，实现更好的地图预测时序一致性。

    

    在离线机器人任务中，长距离理解地形拓扑对于成功至关重要，特别是在高速导航时。目前，几何映射主要依赖于LiDAR传感器，但在更远距离的映射时提供的测量数较少。为了解决这个挑战，我们提出了一种新颖的基于学习的方法，能够仅使用实时车载视角图像预测长距离地形高程地图。我们的方法由三个主要元素组成。首先，引入了一个基于transformer的编码器，该编码器学习车载视角图像与先前的鸟瞰图高程地图预测之间的跨视图关联。其次，提出了一种方向感知的位置编码，将3D车辆姿态信息与多视角视觉图像特征相结合，用于处理复杂的非结构化地形。最后，提出了一种历史增强的可学习地图嵌入，以实现高程地图预测之间的更好时序一致性。

    Understanding terrain topology at long-range is crucial for the success of off-road robotic missions, especially when navigating at high-speeds. LiDAR sensors, which are currently heavily relied upon for geometric mapping, provide sparse measurements when mapping at greater distances. To address this challenge, we present a novel learning-based approach capable of predicting terrain elevation maps at long-range using only onboard egocentric images in real-time. Our proposed method is comprised of three main elements. First, a transformer-based encoder is introduced that learns cross-view associations between the egocentric views and prior bird-eye-view elevation map predictions. Second, an orientation-aware positional encoding is proposed to incorporate the 3D vehicle pose information over complex unstructured terrain with multi-view visual image features. Lastly, a history-augmented learn-able map embedding is proposed to achieve better temporal consistency between elevation map predi
    
[^32]: Transformers实现了功能性梯度下降来学习上下文中的非线性函数

    Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context

    [https://arxiv.org/abs/2312.06528](https://arxiv.org/abs/2312.06528)

    本论文证明了Transformers可以在函数空间中自然地学习实现梯度下降，从而学习上下文中的非线性函数，并且展示了最优的非线性激活函数选择取决于需要学习的函数类别。

    

    许多神经网络架构被认为是图灵完备的，因此原则上可以实现任意算法。然而，Transformers独特之处在于它们可以在简单的参数配置下实现基于梯度的学习算法。本文提供了理论和实证证据，证明（非线性）Transformers自然地学会在函数空间中实现梯度下降，从而使它们能够在上下文中学习非线性函数。我们的结果适用于一大类非线性架构和非线性上下文学习任务的组合。此外，我们展示了非线性激活函数的最优选择以一种自然的方式取决于需要学习的函数类别。

    arXiv:2312.06528v4 Announce Type: replace  Abstract: Many neural network architectures are known to be Turing Complete, and can thus, in principle implement arbitrary algorithms. However, Transformers are unique in that they can implement gradient-based learning algorithms under simple parameter configurations. This paper provides theoretical and empirical evidence that (non-linear) Transformers naturally learn to implement gradient descent in function space, which in turn enable them to learn non-linear functions in context. Our results apply to a broad class of combinations of non-linear architectures and non-linear in-context learning tasks. Additionally, we show that the optimal choice of non-linear activation depends in a natural way on the class of functions that need to be learned.
    
[^33]: 领域约束在缺失结果数据时改善风险预测

    Domain constraints improve risk prediction when outcome data is missing

    [https://arxiv.org/abs/2312.03878](https://arxiv.org/abs/2312.03878)

    提出一种贝叶斯模型类，通过领域约束的设置来改善测试和未测试患者的风险预测

    

    机器学习模型通常用于预测人类决策结果。然而，历史决策决定了观察结果，我们只观察到医生历史上测试的患者的测试结果。我们提出了一种贝叶斯模型类，能够捕捉到这种情况。模型的目的是准确估计测试和未测试患者的风险。由于未测试患者可能出现各种可能性，因此估计这个模型是具有挑战性的。为解决这个问题，我们提出了两个在健康领域合理的领域约束：预valence约束，其中整体疾病患病率是已知的，专业约束，其中人类

    arXiv:2312.03878v2 Announce Type: replace  Abstract: Machine learning models are often trained to predict the outcome resulting from a human decision. For example, if a doctor decides to test a patient for disease, will the patient test positive? A challenge is that historical decision-making determines whether the outcome is observed: we only observe test outcomes for patients doctors historically tested. Untested patients, for whom outcomes are unobserved, may differ from tested patients along observed and unobserved dimensions. We propose a Bayesian model class which captures this setting. The purpose of the model is to accurately estimate risk for both tested and untested patients. Estimating this model is challenging due to the wide range of possibilities for untested patients. To address this, we propose two domain constraints which are plausible in health settings: a prevalence constraint, where the overall disease prevalence is known, and an expertise constraint, where the huma
    
[^34]: 无监督视频域自适应：采用遮蔽预训练和协作自训练

    Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training

    [https://arxiv.org/abs/2312.02914](https://arxiv.org/abs/2312.02914)

    该方法提出了UNITE框架，利用图像教师模型和视频学生模型进行遮蔽预训练和协作自训练，在多个视频领域自适应基准上取得显著改进的结果。

    

    在这项工作中，我们解决了视频动作识别的无监督域自适应（UDA）问题。我们提出的方法称为UNITE，使用图像教师模型来调整视频学生模型到目标域。UNITE首先采用自监督预训练，通过教师引导的遮蔽蒸馏目标得到具有区分性的特征学习。然后我们对目标数据进行遮蔽自训练，利用视频学生模型和图像教师模型一起为未标记的目标视频生成改进的伪标签。我们的自训练过程成功利用了两个模型的优势，实现了跨域强大的转移性能。我们在多个视频域自适应基准上评估了我们的方法，并观察到相比先前报道的结果有显著改进。

    arXiv:2312.02914v3 Announce Type: replace-cross  Abstract: In this work, we tackle the problem of unsupervised domain adaptation (UDA) for video action recognition. Our approach, which we call UNITE, uses an image teacher model to adapt a video student model to the target domain. UNITE first employs self-supervised pre-training to promote discriminative feature learning on target domain videos using a teacher-guided masked distillation objective. We then perform self-training on masked target data, using the video student model and image teacher model together to generate improved pseudolabels for unlabeled target videos. Our self-training process successfully leverages the strengths of both models to achieve strong transfer performance across domains. We evaluate our approach on multiple video domain adaptation benchmarks and observe significant improvements upon previously reported results.
    
[^35]: PAC隐私保护扩散模型

    PAC Privacy Preserving Diffusion Models

    [https://arxiv.org/abs/2312.01201](https://arxiv.org/abs/2312.01201)

    提出了一种PAC隐私保护扩散模型，通过将私有分类器指导集成到采样过程中增强隐私保护，并发展了一种新的度量标准来衡量隐私水平，在保护性能方面表现出卓越表现。

    

    数据隐私保护正在引起研究人员的越来越多的关注。扩散模型（DMs），尤其是具有严格的差分隐私，有可能生成既具有高隐私性又具有良好视觉质量的图像。然而，挑战在于确保在私有化特定数据属性时的强大保护，当前模型在这些方面经常存在不足。为了解决这些挑战，我们引入了PAC隐私保护扩散模型，这是一种利用扩散原理并确保“可能大致正确（PAC）”隐私性的模型。我们通过将私有分类器指导集成到Langevin采样过程中来增强隐私保护。此外，认识到在衡量模型隐私性方面存在差距，我们开发了一种新的度量标准来衡量隐私水平。我们的模型通过这个新度量标准评估，并通过高斯矩阵计算支持PAC界限，表现出更优异的隐私性能。

    arXiv:2312.01201v2 Announce Type: replace-cross  Abstract: Data privacy protection is garnering increased attention among researchers. Diffusion models (DMs), particularly with strict differential privacy, can potentially produce images with both high privacy and visual quality. However, challenges arise such as in ensuring robust protection in privatizing specific data attributes, areas where current models often fall short. To address these challenges, we introduce the PAC Privacy Preserving Diffusion Model, a model leverages diffusion principles and ensure Probably Approximately Correct (PAC) privacy. We enhance privacy protection by integrating a private classifier guidance into the Langevin Sampling Process. Additionally, recognizing the gap in measuring the privacy of models, we have developed a novel metric to gauge privacy levels. Our model, assessed with this new metric and supported by Gaussian matrix computations for the PAC bound, has shown superior performance in privacy p
    
[^36]: 动作槽：交通场景中多标签原子活动识别的视觉动作中心表示

    Action-slot: Visual Action-centric Representations for Multi-label Atomic Activity Recognition in Traffic Scenes

    [https://arxiv.org/abs/2311.17948](https://arxiv.org/abs/2311.17948)

    提出了一种名为Action-slot的方法，通过槽注意力学习视觉动作中心表示，在交通场景中实现了多标签原子活动识别。

    

    在本文中，我们研究了多标签原子活动识别。尽管在动作识别方面取得了显著进展，但由于对多个道路用户动作及其上下文信息的整体理解不足，识别原子活动仍然具有挑战性。我们引入了一种基于槽注意力的方法——动作槽，它学习视觉动作中心表示，捕捉了动作和上下文信息。我们的关键思想是设计能够注意到原子活动发生位置的动作槽，而无需明确的感知引导。为了进一步增强槽的注意力，我们引入了一个背景槽，与动作槽竞争，有助于训练过程中避免不必要地关注缺乏活动的背景区域。然而，现有数据集中不平衡的类分布阻碍了对稀有活动的评估。

    arXiv:2311.17948v1 Announce Type: cross  Abstract: In this paper, we study multi-label atomic activity recognition. Despite the notable progress in action recognition, it is still challenging to recognize atomic activities due to a deficiency in a holistic understanding of both multiple road users' motions and their contextual information. In this paper, we introduce Action-slot, a slot attention-based approach that learns visual action-centric representations, capturing both motion and contextual information. Our key idea is to design action slots that are capable of paying attention to regions where atomic activities occur, without the need for explicit perception guidance. To further enhance slot attention, we introduce a background slot that competes with action slots, aiding the training process in avoiding unnecessary focus on background regions devoid of activities. Yet, the imbalanced class distribution in the existing dataset hampers the assessment of rare activities. To addre
    
[^37]: 关于基于扩散的生成模型及其误差界限：完全收敛估计下的对数凹情况

    On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates

    [https://arxiv.org/abs/2311.13584](https://arxiv.org/abs/2311.13584)

    我们提出了对于基于扩散的生成模型在强对数凹数据分布假设下的完整收敛理论保证，获得了对于参数估计和采样算法的最优上限估计。

    

    我们在强对数凹数据分布的假设下为基于扩散的生成模型的收敛行为提供了完整的理论保证，而我们用于得分估计的逼近函数类由Lipschitz连续函数组成。我们通过一个激励性例子展示了我们方法的强大之处，即从具有未知均值的高斯分布中进行采样。在这种情况下，我们对相关的优化问题，即得分估计，提供了明确的估计，同时将其与相应的采样估计结合起来。因此，我们获得了最好的已知上限估计，涉及关键感兴趣的数量，如数据分布（具有未知均值的高斯分布）与我们的采样算法之间的Wasserstein-2距离的维度和收敛速率。

    arXiv:2311.13584v2 Announce Type: replace  Abstract: We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm.   Beyond the motivating example and in order to allow for the use of a diverse range o
    
[^38]: 离散非参数隐性类别混淆下的因果发现

    Discrete Nonparametric Causal Discovery Under Latent Class Confounding

    [https://arxiv.org/abs/2311.07454](https://arxiv.org/abs/2311.07454)

    本论文研究了离散非参数隐性类别混淆下的因果发现问题，证明了在有限的潜在类别下，因果发现仍然是可识别的。

    

    有向无环图用于建模系统的因果结构。"因果发现"描述了从数据中学习这种结构的问题。当数据是来自多个源（群体或环境）的聚合物时，全局混淆使驱动许多因果发现算法的条件独立性特性变得模糊。这种情况有时被称为混合模型或潜在类别。虽然一些现代因果发现方法能够在特定情况下处理未观察到的混淆，但是目前所知的处理全局混淆的方法都涉及不适用于离散分布的参数假设。以离散和非参数观察变量为重点，我们证明了在有限的潜在类别下，因果发现仍然是可识别的。这个问题的可行性由全局混淆的基数、观察变量的基数等决定。

    arXiv:2311.07454v2 Announce Type: replace Abstract: Directed acyclic graphs are used to model the causal structure of a system. ``Causal discovery'' describes the problem of learning this structure from data. When data is an aggregate from multiple sources (populations or environments), global confounding obscures conditional independence properties that drive many causal discovery algorithms. This setting is sometimes known as a mixture model or a latent class. While some modern methods for causal discovery are able to work around unobserved confounding in specific cases, the only known ways to deal with a global confounder involve parametric assumptions. that are unsuitable for discrete distributions.Focusing on discrete and non-parametric observed variables, we demonstrate that causal discovery can still be identifiable under bounded latent classes. The feasibility of this problem is governed by a trade-off between the cardinality of the global confounder, the cardinalities of the o
    
[^39]: 谨言慎行：使用暂停标记训练语言模型

    Think before you speak: Training Language Models With Pause Tokens

    [https://arxiv.org/abs/2310.02226](https://arxiv.org/abs/2310.02226)

    引入暂停标记的语言模型训练方法可以让模型在输出标记前处理更多隐藏向量，取得了较好的实验结果

    

    语言模型通过立即连续生成一系列标记来生成响应: 第$(K+1)^{th}$个标记是通过操作每层的$K$个隐藏向量得到的，每个向量对应一个前面的标记。如果我们让模型在输出第$(K+1)^{th}$个标记之前操作更多的隐藏向量，比如说$K+10$个呢？我们通过在语言模型上进行训练和推断，引入了一个（可学习的）$\textit{pause}$标记，这一系列标记附加到输入前缀上。然后我们延迟提取模型的输出，直到最后一个暂停标记被看到，从而允许模型在做出答案之前进行额外的计算处理。我们在拥有1B和130M参数的仅解码器模型上进行了$\textit{pause-training}$的实证评估，在C4上进行了因果预训练，并在涵盖推理、问答、普遍理解和事实回忆等下游任务上进行了评估。我们的主要发现是，infer

    arXiv:2310.02226v2 Announce Type: replace-cross  Abstract: Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{th}$ token? We operationalize this idea by performing training and inference on language models with a (learnable) $\textit{pause}$ token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate $\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that infer
    
[^40]: RELIANCE: 可靠的集成学习用于信息和新闻可信度评估

    RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation. (arXiv:2401.10940v1 [cs.IR])

    [http://arxiv.org/abs/2401.10940](http://arxiv.org/abs/2401.10940)

    RELIANCE是一个可靠的集成学习系统，用于评估信息和新闻的可信度。它通过整合多个基本模型的优势，提供了对可信和不可信信息源的准确区分，并在信息和新闻可信度评估方面优于基准模型。

    

    在信息泛滥的时代，辨别新闻内容的可信度越来越具有挑战性。本文介绍了RELIANCE，这是一个专为鲁棒信息和虚假新闻可信度评估而设计的先进的集成学习系统。RELIANCE由五个不同的基本模型组成，包括支持向量机（SVM）、朴素贝叶斯、逻辑回归、随机森林和双向长短期记忆网络（BiLSTMs）。RELIANCE采用了创新的方法来整合它们的优势，利用集成的智能提高准确性。实验证明了RELIANCE在区分可信和不可信信息源方面的优越性，表明其在信息和新闻可信度评估方面超过了单个模型，并成为评估信息源可靠性的有效解决方案。

    In the era of information proliferation, discerning the credibility of news content poses an ever-growing challenge. This paper introduces RELIANCE, a pioneering ensemble learning system designed for robust information and fake news credibility evaluation. Comprising five diverse base models, including Support Vector Machine (SVM), naive Bayes, logistic regression, random forest, and Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs an innovative approach to integrate their strengths, harnessing the collective intelligence of the ensemble for enhanced accuracy. Experiments demonstrate the superiority of RELIANCE over individual models, indicating its efficacy in distinguishing between credible and non-credible information sources. RELIANCE, also surpasses baseline models in information and news credibility assessment, establishing itself as an effective solution for evaluating the reliability of information sources.
    
[^41]: 使用本地自适应对抗颜色攻击对艺术品进行神经风格转换的保护

    Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack. (arXiv:2401.09673v1 [cs.CV])

    [http://arxiv.org/abs/2401.09673](http://arxiv.org/abs/2401.09673)

    本文提出了一种名为本地自适应对抗颜色攻击（LAACA）的方法，用于保护艺术品免受神经风格转换（NST）的滥用。该方法通过在不可察觉的情况下对图像进行修改，产生对NST具有干扰作用的扰动。

    

    神经风格转换（NST）广泛应用于计算机视觉中，用于生成具有任意风格的新图像。这个过程利用神经网络将风格图像的美学元素与内容图像的结构因素融合在一起，形成一个和谐整合的视觉结果。然而，未经授权的NST可能会滥用艺术品。这种滥用引起了关于艺术家权利的社会技术问题，并促使开发技术方法来积极保护原始创作。对抗性攻击主要在机器学习安全中进行探索。我们的工作将这一技术引入到保护艺术家知识产权的领域。本文引入了本地自适应对抗颜色攻击（LAACA）的方法，这种方法可以以对人眼不可察觉但对NST产生干扰的方式修改图像。具体而言，我们设计了针对高频内容丰富区域的扰动，这些扰动由中间特征的破坏产生。我们进行了实验和用户研究。

    Neural style transfer (NST) is widely adopted in computer vision to generate new images with arbitrary styles. This process leverages neural networks to merge aesthetic elements of a style image with the structural aspects of a content image into a harmoniously integrated visual result. However, unauthorized NST can exploit artwork. Such misuse raises socio-technical concerns regarding artists' rights and motivates the development of technical approaches for the proactive protection of original creations. Adversarial attack is a concept primarily explored in machine learning security. Our work introduces this technique to protect artists' intellectual property. In this paper Locally Adaptive Adversarial Color Attack (LAACA), a method for altering images in a manner imperceptible to the human eyes but disruptive to NST. Specifically, we design perturbations targeting image areas rich in high-frequency content, generated by disrupting intermediate features. Our experiments and user study
    
[^42]: 识别与早期热带气旋强化有关的三维辐射模式

    Identifying Three-Dimensional Radiative Patterns Associated with Early Tropical Cyclone Intensification. (arXiv:2401.09493v1 [physics.ao-ph])

    [http://arxiv.org/abs/2401.09493](http://arxiv.org/abs/2401.09493)

    本研究利用线性变分编码器-解码器来学习云辐射反馈对早期热带气旋强化的影响，发现内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流的影响最大。

    

    云辐射反馈影响了早期热带气旋的强化，但现有诊断框架的局限性使其无法用来研究不对称或瞬态的辐射加热。我们提出了一种线性变分编码器-解码器（VED）来学习辐射与实际模拟的气旋表面强化之间的隐藏关系。限制VED模型的输入可以利用其不确定性来识别辐射对强化更重要的时期。对提取的三维辐射结构的细致检查表明，内核深对流和浅云的长波辐射强迫都对强化起到贡献，其中深对流在整体上具有最大的影响。我们发现，在浅云的下风处的深对流对海燕的强化至关重要。我们的工作表明，机器学习可以发现热力-动力学关系，而不依赖于轴对称或确定性的方案。

    Cloud radiative feedback impacts early tropical cyclone (TC) intensification, but limitations in existing diagnostic frameworks make them unsuitable for studying asymmetric or transient radiative heating. We propose a linear Variational Encoder-Decoder (VED) to learn the hidden relationship between radiation and the surface intensification of realistic simulated TCs. Limiting VED model inputs enables using its uncertainty to identify periods when radiation has more importance for intensification. A close examination of the extracted 3D radiative structures suggests that longwave radiative forcing from inner core deep convection and shallow clouds both contribute to intensification, with the deep convection having the most impact overall. We find that deep convection downwind of the shallow clouds is critical to the intensification of Haiyan. Our work demonstrates that machine learning can discover thermodynamic-kinematic relationships without relying on axisymmetric or deterministic as
    
[^43]: 桥接状态和历史表示：理解自预测强化学习

    Bridging State and History Representations: Understanding Self-Predictive RL. (arXiv:2401.08898v1 [cs.LG])

    [http://arxiv.org/abs/2401.08898](http://arxiv.org/abs/2401.08898)

    本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。

    

    表示是所有深度强化学习方法的核心，适用于马尔可夫决策过程（MDP）和部分可观察的马尔可夫决策过程（POMDP）。许多表示学习方法和理论框架被开发用于理解什么构成了有效的表示。然而，这些方法之间的关系和它们之间的共同属性仍然不清楚。在本文中，我们展示了许多看似不同的状态和历史抽象方法和框架实际上基于自预测抽象的共同思想。此外，我们提供了关于广泛采用的目标和优化（如停梯度技术）在学习自预测表示中的理论洞见。这些发现共同产生了一种简化的算法，用于学习状态和历史的自预测表示。我们通过将我们的算法应用于标准MDP、带有dist的MDP进行验证。

    Representations are at the core of all deep reinforcement learning (RL) methods for both Markov decision processes (MDPs) and partially observable Markov decision processes (POMDPs). Many representation learning methods and theoretical frameworks have been developed to understand what constitutes an effective representation. However, the relationships between these methods and the shared properties among them remain unclear. In this paper, we show that many of these seemingly distinct methods and frameworks for state and history abstractions are, in fact, based on a common idea of self-predictive abstraction. Furthermore, we provide theoretical insights into the widely adopted objectives and optimization, such as the stop-gradient technique, in learning self-predictive representations. These findings together yield a minimalist algorithm to learn self-predictive representations for states and histories. We validate our theories by applying our algorithm to standard MDPs, MDPs with dist
    
[^44]: 维度感知的异常检测：理论和实验分析

    Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis. (arXiv:2401.05453v1 [cs.LG])

    [http://arxiv.org/abs/2401.05453](http://arxiv.org/abs/2401.05453)

    这篇论文提出了一种维度感知的异常检测方法DAO，通过全面实验验证了其在800多个数据集上显著优于其他三种流行的异常检测方法。

    

    我们提出了一种非参数异常检测方法，该方法充分考虑了数据集内在维度的局部变化。通过使用局部内在维度（LID）理论，我们得到了一种维度感知的异常检测方法DAO，它被推导为一个包含查询点和随机选择的近邻的渐近局部期望密度比的估计。DAO的维度感知行为是由于它以理论上证明的方式使用局部LID值的局部估计。通过对800多个合成和真实数据集的全面实验，我们证明DAO明显优于三种流行且重要的基准异常检测方法：局部离群因子（LOF），简化版LOF和kNN。

    We present a nonparametric method for outlier detection that takes full account of local variations in intrinsic dimensionality within the dataset. Using the theory of Local Intrinsic Dimensionality (LID), our 'dimensionality-aware' outlier detection method, DAO, is derived as an estimator of an asymptotic local expected density ratio involving the query point and a close neighbor drawn at random. The dimensionality-aware behavior of DAO is due to its use of local estimation of LID values in a theoretically-justified way. Through comprehensive experimentation on more than 800 synthetic and real datasets, we show that DAO significantly outperforms three popular and important benchmark outlier detection methods: Local Outlier Factor (LOF), Simplified LOF, and kNN.
    
[^45]: 用于3D分子生成的几何便利去噪扩散模型

    Geometric-Facilitated Denoising Diffusion Model for 3D Molecule Generation. (arXiv:2401.02683v1 [cs.LG])

    [http://arxiv.org/abs/2401.02683](http://arxiv.org/abs/2401.02683)

    这项研究提出了一个几何便利的去噪扩散模型，用于解决3D分子生成中的多体原子关系建模和键的预测问题。

    

    去噪扩散模型在多个研究领域显示出巨大潜力。现有的面向全新3D分子生成的扩散基于生成方法面临两个主要挑战。由于分子中的大多数重原子通过单键与多个原子相连，仅使用成对距离来模拟分子几何是不足的。因此，第一个挑战涉及提出一个能够捕捉复杂的多体原子间关系和学习高质量特征的有效神经网络作为去噪内核。由于图的离散性质，面对分子的主流扩散方法严重依赖预定义规则，并以间接方式生成边缘。第二个挑战涉及将分子的生成与扩散相结合，并准确预测键的存在。在我们的研究中，我们认为在扩散过程中更新分子构型的迭代方式与分子动力学一致，并引入了新的方法来解决两个挑战。

    Denoising diffusion models have shown great potential in multiple research areas. Existing diffusion-based generative methods on de novo 3D molecule generation face two major challenges. Since majority heavy atoms in molecules allow connections to multiple atoms through single bonds, solely using pair-wise distance to model molecule geometries is insufficient. Therefore, the first one involves proposing an effective neural network as the denoising kernel that is capable to capture complex multi-body interatomic relationships and learn high-quality features. Due to the discrete nature of graphs, mainstream diffusion-based methods for molecules heavily rely on predefined rules and generate edges in an indirect manner. The second challenge involves accommodating molecule generation to diffusion and accurately predicting the existence of bonds. In our research, we view the iterative way of updating molecule conformations in diffusion process is consistent with molecular dynamics and introd
    
[^46]: 通过多样化解析OOD广义化的关键组件

    Unraveling the Key Components of OOD Generalization via Diversification. (arXiv:2312.16313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16313](http://arxiv.org/abs/2312.16313)

    本文研究了通过多样化方法来解决OOD广义化问题，并确定了其关键组件。研究发现，多样化方法对无标签数据的分布非常敏感，且仅仅进行多样化是不足以实现OOD广义化的，学习算法的选择也很重要。

    

    监督学习数据集可能包含多个解释训练集同样良好的线索，即学习其中任何一个都会导致对训练数据的正确预测。然而，其中许多线索可能是虚假的，在分布偏移下失去了预测能力，并因此无法推广到超出分布的数据。最近开发的“多样化”方法通过找到依赖不同特征的多个不同的假设来解决这个问题。本文旨在研究这类方法并确定对其OOD广义化能力的贡献的关键组件。我们发现(1) 多样化方法对于用于多样化的无标签数据的分布非常敏感，当远离方法特定的最佳点时性能会显著下降。(2) 仅仅进行多样化是不足以实现OOD广义化的。所使用的学习算法的选择，例如

    Supervised learning datasets may contain multiple cues that explain the training set equally well, i.e., learning any of them would lead to the correct predictions on the training data. However, many of them can be spurious, i.e., lose their predictive power under a distribution shift and consequently fail to generalize to out-of-distribution (OOD) data. Recently developed "diversification" methods (Lee et al., 2023; Pagliardini et al., 2023) approach this problem by finding multiple diverse hypotheses that rely on different features. This paper aims to study this class of methods and identify the key components contributing to their OOD generalization abilities.  We show that (1) diversification methods are highly sensitive to the distribution of the unlabeled data used for diversification and can underperform significantly when away from a method-specific sweet spot. (2) Diversification alone is insufficient for OOD generalization. The choice of the used learning algorithm, e.g., the
    
[^47]: 用基于模拟推断的孤立脉冲星种群合成

    Isolated pulsar population synthesis with simulation-based inference. (arXiv:2312.14848v1 [astro-ph.HE] CROSS LISTED)

    [http://arxiv.org/abs/2312.14848](http://arxiv.org/abs/2312.14848)

    本论文使用模拟推断方法结合脉冲星种群合成，来限制孤立银河射电脉冲星的磁旋转特性。

    

    我们将脉冲星种群合成与基于模拟推断相结合，以限制孤立银河射电脉冲星的磁旋转特性。我们首先构建了一个灵活的框架来模拟中子星的诞生特性和演化，重点是它们的动力学、旋转和磁性特征。特别是，我们从对数正态分布中采样初始磁场强度B和自转周期P，并用幂律来捕捉后期磁场的衰减。每个对数正态分布由均值μlogB，μlogP和标准差σlogB，σlogP描述，而幂律由指数a_late描述，共计五个自由参数。然后我们模拟了星体的射电发射和观测偏差，以模拟三个射电调查中的探测，并通过改变输入参数产生了一个大型的合成P-Ṗ图数据库。接着我们采用基于模拟推断的方法进行推断

    We combine pulsar population synthesis with simulation-based inference to constrain the magneto-rotational properties of isolated Galactic radio pulsars. We first develop a flexible framework to model neutron-star birth properties and evolution, focusing on their dynamical, rotational and magnetic characteristics. In particular, we sample initial magnetic-field strengths, $B$, and spin periods, $P$, from log-normal distributions and capture the late-time magnetic-field decay with a power law. Each log-normal is described by a mean, $\mu_{\log B}, \mu_{\log P}$, and standard deviation, $\sigma_{\log B}, \sigma_{\log P}$, while the power law is characterized by the index, $a_{\rm late}$, resulting in five free parameters. We subsequently model the stars' radio emission and observational biases to mimic detections with three radio surveys, and produce a large database of synthetic $P$-$\dot{P}$ diagrams by varying our input parameters. We then follow a simulation-based inference approach 
    
[^48]: 输入凸LSTM：一种快速基于Lyapunov模型预测控制的凸方法

    Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model Predictive Control. (arXiv:2311.07202v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.07202](http://arxiv.org/abs/2311.07202)

    本研究提出了一种基于输入凸LSTM的基于Lyapunov的模型预测控制方法，通过减少收敛时间和缓解梯度消失/爆炸问题来改善MPC的性能。

    

    利用输入凸神经网络（ICNN），基于ICNN的模型预测控制（MPC）通过在MPC框架中保持凸性成功实现全局最优解。然而，当前的ICNN架构存在梯度消失/爆炸问题，限制了它们作为复杂任务的深度神经网络的能力。此外，当前基于神经网络的MPC，包括传统的基于神经网络的MPC和基于ICNN的MPC，与基于第一原理模型的MPC相比面临较慢的收敛速度。在本研究中，我们利用ICNN的原理提出了一种新的基于输入凸LSTM的基于Lyapunov的MPC，旨在减少收敛时间、缓解梯度消失/爆炸问题并确保闭环稳定性。通过对非线性化学反应器的模拟研究，我们观察到了梯度消失/爆炸问题的缓解和收敛时间的减少，收敛时间平均降低了一定的百分之。

    Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive Control (MPC) successfully attains globally optimal solutions by upholding convexity within the MPC framework. However, current ICNN architectures encounter the issue of vanishing/exploding gradients, which limits their ability to serve as deep neural networks for complex tasks. Additionally, the current neural network-based MPC, including conventional neural network-based MPC and ICNN-based MPC, faces slower convergence speed when compared to MPC based on first-principles models. In this study, we leverage the principles of ICNNs to propose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific goal of reducing convergence time and mitigating the vanishing/exploding gradient problem while ensuring closed-loop stability. From a simulation study of a nonlinear chemical reactor, we observed a mitigation of vanishing/exploding gradient problem and a reduction in convergence time, with a percentage de
    
[^49]: 通过对结构力学应用的调查，讨论物理增强机器学习的光谱

    Discussing the Spectra of Physics-Enhanced Machine Learning via a Survey on Structural Mechanics Applications. (arXiv:2310.20425v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.20425](http://arxiv.org/abs/2310.20425)

    本文探讨了物理增强机器学习 (PEML) 的光谱，揭示了其在解决复杂挑战方面的潜力，并通过具体示例演示了不同类型PEML方法的个体特征和动机。

    

    物理和机器学习的交叉已经催生了一种我们在这里称之为物理增强机器学习 (PEML) 的范式，旨在提高数据或物理方法的能力和减少各自的缺点。本文通过对其特征、用法和动机的全面探索来讨论物理增强机器学习方法的光谱，涵盖了物理和数据这两个定义轴。在这样做的过程中，本文提供了对PEML技术的最新应用和发展的调查，揭示了PEML在应对复杂挑战方面的潜力。我们进一步演示了在单自由度Duffing振子的简单工作示例上选择这种方法的应用，从而突出了不同“类型”PEML方法的个体特征和动机。为了促进合作和透明度，并为读者提供实际的示例，本文完整地记录了所采取的方法和模型。

    The intersection of physics and machine learning has given rise to a paradigm that we refer to here as physics-enhanced machine learning (PEML), aiming to improve the capabilities and reduce the individual shortcomings of data- or physics-only methods. In this paper, the spectrum of physics-enhanced machine learning methods, expressed across the defining axes of physics and data, is discussed by engaging in a comprehensive exploration of its characteristics, usage, and motivations. In doing so, this paper offers a survey of recent applications and developments of PEML techniques, revealing the potency of PEML in addressing complex challenges. We further demonstrate application of select such schemes on the simple working example of a single-degree-of-freedom Duffing oscillator, which allows to highlight the individual characteristics and motivations of different `genres' of PEML approaches. To promote collaboration and transparency, and to provide practical examples for the reader, the
    
[^50]: 知识图谱增强的多样化推荐

    Knowledge Graph Context-Enhanced Diversified Recommendation. (arXiv:2310.13253v1 [cs.IR])

    [http://arxiv.org/abs/2310.13253](http://arxiv.org/abs/2310.13253)

    该研究在知识图谱背景下探索多样化推荐系统，通过引入创新的度量标准和评分函数，有效提高了知识图谱推荐算法的多样性。

    

    推荐系统领域一直致力于通过利用用户的历史交互来提高准确性。然而，这种追求准确性的同时往往导致了多样性的降低，从而产生了众所周知的“回声室”现象。多样化推荐系统作为一种对策应运而生，将多样性与准确性同等看待，并在学术界和行业实践者中获得了显著的关注。本研究探索了多样化推荐系统在复杂的知识图谱（KG）背景下的应用。这些知识图谱是连接实体和项目的信息库，通过加入深入的上下文信息，提供了增加推荐多样性的有利途径。我们的贡献包括引入了一种创新的度量标准，实体覆盖和关系覆盖，有效地量化了知识图谱领域的多样性。此外，我们还引入了多样化评分函数，该函数通过综合利用实体覆盖和关系覆盖来提高推荐算法的多样性。

    The field of Recommender Systems (RecSys) has been extensively studied to enhance accuracy by leveraging users' historical interactions. Nonetheless, this persistent pursuit of accuracy frequently engenders diminished diversity, culminating in the well-recognized "echo chamber" phenomenon. Diversified RecSys has emerged as a countermeasure, placing diversity on par with accuracy and garnering noteworthy attention from academic circles and industry practitioners. This research explores the realm of diversified RecSys within the intricate context of knowledge graphs (KG). These KGs act as repositories of interconnected information concerning entities and items, offering a propitious avenue to amplify recommendation diversity through the incorporation of insightful contextual information. Our contributions include introducing an innovative metric, Entity Coverage, and Relation Coverage, which effectively quantifies diversity within the KG domain. Additionally, we introduce the Diversified
    
[^51]: HGCVAE: 将生成式学习和对比学习整合为一体的异构图学习方法

    HGCVAE: Integrating Generative and Contrastive Learning for Heterogeneous Graph Learning. (arXiv:2310.11102v1 [cs.LG])

    [http://arxiv.org/abs/2310.11102](http://arxiv.org/abs/2310.11102)

    HGCVAE是一种将生成式学习和对比学习整合为一体的异构图学习方法，通过利用生成式的自监督学习能力来解决异构图学习的挑战。

    

    生成式自监督学习（SSL）在图学习中展示了巨大的潜力和越来越多的关注。本研究旨在探索生成式SSL在异构图学习（HGL）中的问题。以往关于异构图的SSL方法主要依赖对比学习，需要设计复杂的视图来捕捉异质性。然而，现有的生成式SSL方法并未充分利用生成模型的能力来解决HGL的挑战。在本文中，我们提出了HGCVAE，一种新颖的对比变分图自编码器，使HGL摆脱了复杂异质性的负担。HGCVAE不再专注于复杂的异质性，而是充分利用了生成式SSL的潜力。HGCVAE创新地将对比学习与生成式SSL相结合，引入了几个关键创新。首先，我们采用渐进机制生成高质量的hard样本，

    Generative self-supervised learning (SSL) has exhibited significant potential and garnered increasing interest in graph learning. In this study, we aim to explore the problem of generative SSL in the context of heterogeneous graph learning (HGL). The previous SSL approaches for heterogeneous graphs have primarily relied on contrastive learning, necessitating the design of complex views to capture heterogeneity. However, existing generative SSL methods have not fully leveraged the capabilities of generative models to address the challenges of HGL. In this paper, we present HGCVAE, a novel contrastive variational graph auto-encoder that liberates HGL from the burden of intricate heterogeneity capturing. Instead of focusing on complicated heterogeneity, HGCVAE harnesses the full potential of generative SSL. HGCVAE innovatively consolidates contrastive learning with generative SSL, introducing several key innovations. Firstly, we employ a progressive mechanism to generate high-quality hard
    
[^52]: 使用可解释的人工智能揭示健康衰老过程中的心电图变化

    Uncovering ECG Changes during Healthy Aging using Explainable AI. (arXiv:2310.07463v1 [eess.SP])

    [http://arxiv.org/abs/2310.07463](http://arxiv.org/abs/2310.07463)

    本文使用可解释的人工智能技术分析了健康个体的心电图数据，并识别出随年龄增长呼吸率的下降及SDANN值异常高作为老年人的指标。

    

    心血管疾病仍然是全球领先的死因。这需要对心脏衰老过程有深入的了解，以诊断心血管健康状况的限制。传统上，对个体心电图（ECG）特征随年龄变化的分析提供了这些见解。然而，这些特征虽然有信息量，但可能掩盖了底层数据关系。在本文中，我们使用深度学习模型和基于树的模型分析来自健康个体的ECG数据，包括原始信号和ECG特征格式。然后，我们使用可解释的AI技术来识别对于区分年龄组别最有辨别力的ECG特征或原始信号特征。我们的分析与基于树的分类器揭示了随年龄增长呼吸率下降，并识别出SDANN值异常高作为老年人的指标，可将其与年轻人区分开来。

    Cardiovascular diseases remain the leading global cause of mortality. This necessitates a profound understanding of heart aging processes to diagnose constraints in cardiovascular fitness. Traditionally, most of such insights have been drawn from the analysis of electrocardiogram (ECG) feature changes of individuals as they age. However, these features, while informative, may potentially obscure underlying data relationships. In this paper, we employ a deep-learning model and a tree-based model to analyze ECG data from a robust dataset of healthy individuals across varying ages in both raw signals and ECG feature format. Explainable AI techniques are then used to identify ECG features or raw signal characteristics are most discriminative for distinguishing between age groups. Our analysis with tree-based classifiers reveal age-related declines in inferred breathing rates and identifies notably high SDANN values as indicative of elderly individuals, distinguishing them from younger adul
    
[^53]: 使用最优输运器合并Transformer

    Transformer Fusion with Optimal Transport. (arXiv:2310.05719v1 [cs.LG])

    [http://arxiv.org/abs/2310.05719](http://arxiv.org/abs/2310.05719)

    本文介绍了一种使用最优输运来融合基于Transformer的网络的方法，可以对齐各种架构组件并允许不同大小的模型的融合，提供了一种新的高效压缩Transformer的方式。

    

    融合是一种将多个独立训练的神经网络合并以结合它们的能力的技术。过去的尝试仅限于全连接、卷积和残差网络的情况。本文提出了一种系统的方法，利用最优输运来融合两个或多个基于Transformer的网络，以（软）对齐各种架构组件。我们详细描述了一种层对齐的抽象方法，可以推广到任意架构，例如多头自注意力、层归一化和残差连接。我们通过各种消融研究讨论了如何处理这些架构组件。此外，我们的方法允许不同大小的模型进行融合（异构融合），为Transformer的压缩提供了一种新的高效方法。我们通过Vision Transformer进行图像分类任务以及自然语言

    Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language
    
[^54]: 基于贝叶斯Spike-and-Slab先验和高效核函数的方程式发现方法

    Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels. (arXiv:2310.05387v1 [cs.LG])

    [http://arxiv.org/abs/2310.05387](http://arxiv.org/abs/2310.05387)

    该论文提出了一种基于核学习和贝叶斯Spike-and-Slab先验的方程式发现方法，通过核回归和贝叶斯稀疏分布，能够有效处理数据稀疏性和噪声问题，并进行不确定性量化和高效的后验推断和函数估计。

    

    从数据中发现控制方程对于许多科学和工程应用非常重要。然而，尽管有一些有希望的成功案例，现有方法仍然面临着数据稀疏性和噪声问题的挑战，这在实践中随处可见。此外，最先进的方法缺乏不确定性量化和/或训练成本高昂。为了克服这些局限性，我们提出了一种基于核学习和贝叶斯Spike-and-Slab先验（KBASS）的新型方程式发现方法。我们使用核回归来估计目标函数，这种方法具有灵活性、表达力，并且对于数据稀疏性和噪声更加稳健。我们将其与贝叶斯Spike-and-Slab先验结合使用，后者是一种理想的贝叶斯稀疏分布，用于有效的算子选择和不确定性量化。我们开发了一种基于期望传播期望最大化（EP-EM）算法的有效后验推断和函数估计方法。为了克服核回归的计算挑战，我们使用了一种快速方法。

    Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity as well as noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior -- an ideal Bayesian sparse distribution -- for effective operator selection and uncertainty quantification. We develop an expectation propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we pla
    
[^55]: Lemur：在自动程序验证中集成大型语言模型

    Lemur: Integrating Large Language Models in Automated Program Verification. (arXiv:2310.04870v2 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2310.04870](http://arxiv.org/abs/2310.04870)

    本论文提出了一种将LLMs和自动推理器结合起来进行自动程序验证的通用方法，并证明了其完备性。这个方法在一些合成和竞争基准上取得了实际的改进。

    

    LLMs在代码理解能力上的展示引发了一个问题：它们是否可以用于自动程序验证，这是一个通常需要高级抽象推理的任务，对于验证工具来说是具有挑战性的。我们提出了一种将LLMs的能力和自动推理器结合起来进行自动程序验证的通用方法。我们正式描述了这种方法论，将其作为推导规则的集合进行论证其完备性。我们将计算机推理形成为一个完备的自动验证过程，这在一组合成和竞争基准上带来了实际的改进。

    The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that often demands high-level abstract reasoning about program properties, which is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks.
    
[^56]: 关于在Heckman选择模型中的预测特征分配问题

    On Prediction Feature Assignment in the Heckman Selection Model. (arXiv:2309.08043v1 [cs.LG])

    [http://arxiv.org/abs/2309.08043](http://arxiv.org/abs/2309.08043)

    本文研究在非随机缺失样本选择偏差下的预测模型性能降低问题，提出了Heckman-FA框架来获取恰当的预测特征。

    

    在非随机缺失（MNAR）样本选择偏差的情况下，预测模型的性能往往下降。本文关注MNAR样本选择偏差的一个经典例子，即一部分样本具有非随机缺失结果。Heckman选择模型及其变种通常用于处理这种类型的样本选择偏差。Heckman模型使用两个不同的方程来模拟样本的预测和选择，其中选择特征包括所有预测特征。在使用Heckman模型时，必须从选择特征集中正确选择预测特征。然而，对于Heckman模型来说，选择正确的预测特征是一项具有挑战性的任务，尤其是当选择特征的数量较多时。现有的使用Heckman模型的方法通常提供一个手动选择的预测特征集。在本文中，我们提出了Heckman-FA作为一种新的数据驱动框架来获得预测特征。

    Under missing-not-at-random (MNAR) sample selection bias, the performance of a prediction model is often degraded. This paper focuses on one classic instance of MNAR sample selection bias where a subset of samples have non-randomly missing outcomes. The Heckman selection model and its variants have commonly been used to handle this type of sample selection bias. The Heckman model uses two separate equations to model the prediction and selection of samples, where the selection features include all prediction features. When using the Heckman model, the prediction features must be properly chosen from the set of selection features. However, choosing the proper prediction features is a challenging task for the Heckman model. This is especially the case when the number of selection features is large. Existing approaches that use the Heckman model often provide a manually chosen set of prediction features. In this paper, we propose Heckman-FA as a novel data-driven framework for obtaining pr
    
[^57]: 具有未测混淆因素的广义线性模型的同时推断

    Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])

    [http://arxiv.org/abs/2309.07261](http://arxiv.org/abs/2309.07261)

    本文研究了存在混淆效应时的广义线性模型的大规模假设检验问题，并提出了一种利用正交结构和线性投影的统计估计和推断框架，解决了由于未测混淆因素引起的偏差问题。

    

    在基因组研究中，常常进行成千上万个同时假设检验，以确定差异表达的基因。然而，由于存在未测混淆因素，许多标准统计方法可能存在严重的偏差。本文研究了存在混淆效应时的多元广义线性模型的大规模假设检验问题。在任意混淆机制下，我们提出了一个统一的统计估计和推断方法，利用正交结构并将线性投影整合到三个关键阶段中。首先，利用多元响应变量分离边际和不相关的混淆效应，恢复混淆系数的列空间。随后，利用$\ell_1$正则化进行稀疏性估计，并强加正交性限制于混淆系数，联合估计潜在因子和主要效应。最后，我们结合投影和加权偏差校正步骤。

    Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
    
[^58]: 基于掩码Transformer的心电图分类研究

    Masked Transformer for Electrocardiogram Classification. (arXiv:2309.07136v1 [eess.SP])

    [http://arxiv.org/abs/2309.07136](http://arxiv.org/abs/2309.07136)

    提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。

    

    心电图（ECG）是临床应用中最重要的诊断工具之一。随着先进算法的出现，各种深度学习模型已被应用于ECG任务。然而，尽管Transformer在计算机视觉和自然语言处理领域取得了广泛成功，但其在ECG数据上的潜力尚未得到实现。在本研究中，我们提出了一种有用的基于掩码Transformer的ECG分类方法，称为MTECG，它将掩码自动编码器的应用扩展到了ECG时间序列上。我们构建了一个包含220,251个ECG记录的数据集，这些记录由医学专家进行了广泛的诊断注释，以探索MTECG的特性。在提出的训练策略下，一个只有5.7M参数的轻量级模型在广泛的掩码比例（5%-75%）下表现稳定良好。消融研究突出了波动重构目标、训练计划长度、逐层学习率衰减和DropPath率的重要性。实验发现MTECG耗时较少且能够有效分类各种心电图。

    Electrocardiogram (ECG) is one of the most important diagnostic tools in clinical applications. With the advent of advanced algorithms, various deep learning models have been adopted for ECG tasks. However, the potential of Transformers for ECG data is not yet realized, despite their widespread success in computer vision and natural language processing. In this work, we present a useful masked Transformer method for ECG classification referred to as MTECG, which expands the application of masked autoencoders to ECG time series. We construct a dataset comprising 220,251 ECG recordings with a broad range of diagnoses annoated by medical experts to explore the properties of MTECG. Under the proposed training strategies, a lightweight model with 5.7M parameters performs stably well on a broad range of masking ratios (5%-75%). The ablation studies highlight the importance of fluctuated reconstruction targets, training schedule length, layer-wise LR decay and DropPath rate. The experiments o
    
[^59]: 让量子神经网络选择自己的频率

    Let Quantum Neural Networks Choose Their Own Frequencies. (arXiv:2309.03279v1 [quant-ph])

    [http://arxiv.org/abs/2309.03279](http://arxiv.org/abs/2309.03279)

    该论文提出了一种可训练频率的量子模型，通过在生成器中引入可训练参数，使得模型能够学习具有所需属性的生成器，包括非常规间隔频率和灵活的频谱丰富性。实验证明该方法在解决Navier-Stokes方程时具有较高的准确性。

    

    参数化量子电路作为机器学习模型，通常可以通过将输入特征的部分傅立叶级数表示来描述，其中频率由特征映射的生成哈密顿量唯一确定。通常情况下，这些数据编码生成器是提前选择的，固定了可以表示的函数空间。在这项工作中，我们考虑将量子模型推广到生成器中包括一组可训练参数的情况，从而得到一个可训练频率的量子模型。我们通过数值实验证明了可训练频率模型如何学习具有所需属性的生成器，包括其频谱中的非常规间隔频率和灵活的频谱丰富性。最后，我们展示了我们方法在现实世界中的有效性，通过使用仅对每个编码操作添加一个参数的可训练频率模型，提高了求解Navier-Stokes方程的准确性。

    Parameterized quantum circuits as machine learning models are typically well described by their representation as a partial Fourier series of the input features, with frequencies uniquely determined by the feature map's generator Hamiltonians. Ordinarily, these data-encoding generators are chosen in advance, fixing the space of functions that can be represented. In this work we consider a generalization of quantum models to include a set of trainable parameters in the generator, leading to a trainable frequency (TF) quantum model. We numerically demonstrate how TF models can learn generators with desirable properties for solving the task at hand, including non-regularly spaced frequencies in their spectra and flexible spectral richness. Finally, we showcase the real-world effectiveness of our approach, demonstrating an improved accuracy in solving the Navier-Stokes equations using a TF model with only a single parameter added to each encoding operation. Since TF models encompass conven
    
[^60]: 一种适用于隐式多任务强化学习问题的策略适应方法

    A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems. (arXiv:2308.16471v1 [cs.RO])

    [http://arxiv.org/abs/2308.16471](http://arxiv.org/abs/2308.16471)

    本研究提出了一种适用于动态运动生成任务的多任务强化学习算法，可用于适应单个运动类别中的隐式变化，并在头球任务中取得良好的适应效果。

    

    在动态运动生成任务中，包括接触和碰撞，策略参数的小改变可能导致极其不同的回报。例如，在足球中，通过稍微改变踢球位置或施加球的力或者球的摩擦力发生变化，球可以以完全不同的方向飞行。然而，很难想象在不同的方向上头球需要完全不同的技能。在本研究中，我们提出了一种多任务强化学习算法，用于在单个运动类别中适应目标或环境的隐式变化，包括不同的奖励函数或环境的物理参数。我们利用单脚机器人模型对所提出的方法进行了评估，在头球任务中取得了良好的适应效果。结果表明，所提出的方法可以适应目标位置的隐式变化或球的恢复系数的变化，而标准的领域随机化方法则不能。

    In dynamic motion generation tasks, including contact and collisions, small changes in policy parameters can lead to extremely different returns. For example, in soccer, the ball can fly in completely different directions with a similar heading motion by slightly changing the hitting position or the force applied to the ball or when the friction of the ball varies. However, it is difficult to imagine that completely different skills are needed for heading a ball in different directions. In this study, we proposed a multitask reinforcement learning algorithm for adapting a policy to implicit changes in goals or environments in a single motion category with different reward functions or physical parameters of the environment. We evaluated the proposed method on the ball heading task using a monopod robot model. The results showed that the proposed method can adapt to implicit changes in the goal positions or the coefficients of restitution of the ball, whereas the standard domain randomi
    
[^61]: 使用深度神经网络和逻辑损失进行分类

    Classification with Deep Neural Networks and Logistic Loss. (arXiv:2307.16792v1 [stat.ML])

    [http://arxiv.org/abs/2307.16792](http://arxiv.org/abs/2307.16792)

    本文提出了一种新颖的oracle型不等式，通过解决逻辑损失的目标函数无界性限制，推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的最优收敛速率，仅要求数据的条件类概率具有H\"older平滑性，并且考虑了组合假设，使得该方法具有更广泛的适用性。

    

    使用逻辑损失（即交叉熵损失）训练的深度神经网络在各种二分类任务中取得了显著的进展。然而，关于使用深度神经网络和逻辑损失进行二分类的泛化分析仍然很少。逻辑损失的目标函数的无界性是导致推导出令人满意的泛化界限的主要障碍。本文旨在通过建立一种新颖而优雅的oracle型不等式来填补这一空白，该不等式使我们能够处理目标函数的有界性限制，并利用它推导出使用逻辑损失训练的全连接ReLU深度神经网络分类器的收敛速率。特别地，我们仅需要数据的条件类概率$\eta$的H\"older平滑性，就可以获得最优的收敛速率（仅限于对数因子）。此外，我们考虑了一个组合假设，要求$\eta$是若干向量值函数的复合函数，其中每个向量值函数都是独立的。

    Deep neural networks (DNNs) trained with the logistic loss (i.e., the cross entropy loss) have made impressive advancements in various binary classification tasks. However, generalization analysis for binary classification with DNNs and logistic loss remains scarce. The unboundedness of the target function for the logistic loss is the main obstacle to deriving satisfying generalization bounds. In this paper, we aim to fill this gap by establishing a novel and elegant oracle-type inequality, which enables us to deal with the boundedness restriction of the target function, and using it to derive sharp convergence rates for fully connected ReLU DNN classifiers trained with logistic loss. In particular, we obtain optimal convergence rates (up to log factors) only requiring the H\"older smoothness of the conditional class probability $\eta$ of data. Moreover, we consider a compositional assumption that requires $\eta$ to be the composition of several vector-valued functions of which each co
    
[^62]: Prot2Text: 基于GNNs和Transformers的多模态蛋白质功能生成

    Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers. (arXiv:2307.14367v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.14367](http://arxiv.org/abs/2307.14367)

    提出了一种名为Prot2Text的新方法，通过结合GNNs和Transformers，以自由文本样式预测蛋白质的功能。该方法能够综合蛋白质的序列、结构和文本注释等多种数据类型，超越传统的二进制或分类分类，实现了对蛋白质功能的全面表示。

    

    大型生物系统的复杂性使某些科学家将其理解归类为难以想象的任务。不同级别的挑战使这项任务复杂化，其中之一是预测蛋白质的功能。近年来，通过开发各种机器学习方法，在这个领域取得了重大进展。然而，大多数现有的方法将任务表述为多分类问题，即将预定义标签分配给蛋白质。在这项工作中，我们提出了一种新的方法——Prot2Text，以自由文本样式预测蛋白质的功能，超越传统的二进制或分类分类。通过在编码器-解码器框架中结合图神经网络（GNNs）和大型语言模型（LLMs），我们的模型有效地整合了蛋白质序列、结构和文本注释等多种数据类型。这种多模态方法允许对蛋白质功能进行整体表示。

    The complex nature of big biological systems pushed some scientists to classify its understanding under the inconceivable missions. Different leveled challenges complicated this task, one of is the prediction of a protein's function. In recent years, significant progress has been made in this field through the development of various machine learning approaches. However, most existing methods formulate the task as a multi-classification problem, i.e assigning predefined labels to proteins. In this work, we propose a novel approach, \textbf{Prot2Text}, which predicts a protein function's in a free text style, moving beyond the conventional binary or categorical classifications. By combining Graph Neural Networks(GNNs) and Large Language Models(LLMs), in an encoder-decoder framework, our model effectively integrates diverse data types including proteins' sequences, structures, and textual annotations. This multimodal approach allows for a holistic representation of proteins' functions, en
    
[^63]: 解释性差异补偿以实现有效的公平排序

    Explainable Disparity Compensation for Efficient Fair Ranking. (arXiv:2307.14366v1 [cs.LG])

    [http://arxiv.org/abs/2307.14366](http://arxiv.org/abs/2307.14366)

    这项研究提出了解释性的数据驱动的排名函数补偿措施，通过给予低调群体成员奖励积分来解决公平排序中的不平等问题。

    

    决策系统中使用的排名函数往往对不同人群产生不同的结果，因为基础数据存在偏见。解决和补偿这些不同的结果对于公平决策是一个关键问题。最近的补偿措施主要集中在对排名函数进行不透明的转换以满足公平保证，或者使用配额或留位来保证向代表低调群体的成员提供最少数量的积极结果。在本文中，我们提出了一种基于数据驱动的易解释的排名函数补偿措施。我们的措施依赖于给予低调群体成员的奖励积分来解决排名函数中的不平等性。奖励积分可以事先设置，并且可以进行组合，从而考虑到代表交叉，并为利益相关者提供更好的透明度。我们提出了高效的基于抽样的算法来计算数量

    Ranking functions that are used in decision systems often produce disparate results for different populations because of bias in the underlying data. Addressing, and compensating for, these disparate outcomes is a critical problem for fair decision-making. Recent compensatory measures have mostly focused on opaque transformations of the ranking functions to satisfy fairness guarantees or on the use of quotas or set-asides to guarantee a minimum number of positive outcomes to members of underrepresented groups. In this paper we propose easily explainable data-driven compensatory measures for ranking functions. Our measures rely on the generation of bonus points given to members of underrepresented groups to address disparity in the ranking function. The bonus points can be set in advance, and can be combined, allowing for considering the intersections of representations and giving better transparency to stakeholders. We propose efficient sampling-based algorithms to calculate the number
    
[^64]: 当拒绝学习对具有拒绝的回归问题最优时

    When No-Rejection Learning is Optimal for Regression with Rejection. (arXiv:2307.02932v1 [cs.LG])

    [http://arxiv.org/abs/2307.02932](http://arxiv.org/abs/2307.02932)

    本文研究了具有拒绝的回归问题，并调查了将其视为标准回归任务来学习预测器的无拒绝学习策略。

    

    拒绝学习是研究人类和人工智能在预测任务上相互作用的典型模型。该模型包括一个预测器和一个拒绝器。在样本到达时，拒绝器首先决定是否接受它；如果接受，预测器完成预测任务；如果被拒绝，则将预测推迟给人类。学习问题需要同时学习预测器和拒绝器。这改变了传统损失函数的结构，通常导致非凸性和一致性问题。对于带有拒绝的分类问题，一些研究开发了代理损失函数，同时具有可验证的一致性保证；与此同时，关于回归问题的研究较少。我们研究了带有拒绝的回归问题并研究了将其视为标准回归任务来学习预测器的无拒绝学习策略。

    Learning with rejection is a prototypical model for studying the interaction between humans and AI on prediction tasks. The model has two components, a predictor and a rejector. Upon the arrival of a sample, the rejector first decides whether to accept it; if accepted, the predictor fulfills the prediction task, and if rejected, the prediction will be deferred to humans. The learning problem requires learning a predictor and a rejector simultaneously. This changes the structure of the conventional loss function and often results in non-convexity and inconsistency issues. For the classification with rejection problem, several works develop surrogate losses for the jointly learning with provable consistency guarantees; in parallel, there has been less work for the regression counterpart. We study the regression with rejection (RwR) problem and investigate the no-rejection learning strategy which treats the RwR problem as a standard regression task to learn the predictor. We establish tha
    
[^65]: 线束自动驾驶：挑战与前景

    End-to-end Autonomous Driving: Challenges and Frontiers. (arXiv:2306.16927v1 [cs.RO])

    [http://arxiv.org/abs/2306.16927](http://arxiv.org/abs/2306.16927)

    这项研究调查了端到端自动驾驶领域中的关键挑战和未来趋势，包括多模态、可解释性、因果混淆、鲁棒性和世界模型等。通过联合特征优化感知和规划，端到端系统在感知和规划上获得了更好的效果。

    

    自动驾驶领域正在迅速发展，越来越多的方法采用端到端算法框架，利用原始传感器输入生成车辆运动计划，而不是专注于诸如检测和运动预测等单个任务。与模块化流水线相比，端到端系统通过联合特征优化感知和规划来获益。这一领域因大规模数据集的可用性、闭环评估以及自动驾驶算法在挑战性场景中的有效执行所需的需求而蓬勃发展。在本调查中，我们全面分析了250多篇论文，涵盖了端到端自动驾驶的动机、路线图、方法论、挑战和未来趋势。我们深入探讨了多模态、可解释性、因果混淆、鲁棒性和世界模型等几个关键挑战。此外，我们还讨论了基础技术的最新进展。

    The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 250 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation
    
[^66]: 通过重要性抽样实现有效通信的联邦学习

    Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])

    [http://arxiv.org/abs/2306.12625](http://arxiv.org/abs/2306.12625)

    本文提出了一种通过重要性抽样实现有效通信的联邦学习方法，大大降低了发送模型更新的高通信成本，利用服务器端客户端分布和附加信息的接近关系，只需要较少的通信量即可实现。

    

    客户端向服务器发送模型更新的高通信成本是可扩展联邦学习（FL）的重要瓶颈。现有方法中，使用随机压缩方法实现了最先进的比特率-准确性折衷——其中客户端n发送来自仅为该客户端的概率分布qφ（n）的样本，服务器使用这些样本估计客户端分布的平均值。然而，这种方法没有充分利用FL的设置，其中服务器在整个训练过程中具有预数据分布pθ的附加信息，该分布与客户端分布qφ（n）在Kullback-Leibler（KL）发散方面接近。在本文中，我们利用服务器端客户端分布qφ（n)与附加信息pθ之间的这种接近关系，并提出了一种框架，该框架需要大约Dkl（qφ（n）|| pθ）位的通信量。

    The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\theta}$ that is close to the client's distribution $q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the side information $p_{\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of com
    
[^67]: PEAR: 基于原始操作的自适应重标记用于Boosting层次强化学习

    PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical Reinforcement Learning. (arXiv:2306.06394v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06394](http://arxiv.org/abs/2306.06394)

    PEAR是一种基于原始操作的自适应重标记方法，用于Boosting层次强化学习。它通过对专家演示进行自适应重标记来生成高效的子目标监督，并通过联合优化强化学习和模仿学习来训练分层代理。实验结果显示，PEAR能够在具有挑战性的机器人环境中取得良好的性能。

    

    层次强化学习（HRL）利用时间抽象和增加的探索性能解决复杂的长期任务。然而，由于固有的非静态性，分层代理难以训练。我们提出了基于原始操作的自适应重标记（PEAR），这是一个两阶段方法，我们首先对少量专家演示进行自适应重标记，产生高效的子目标监督，然后通过使用强化学习（RL）和模仿学习（IL）联合优化HRL代理。我们进行理论分析来$(i)$限制我们方法的次优性，和$(ii)$推导出使用RL和IL的广义即插即用的框架进行联合优化。PEAR使用一些专家演示，并对任务结构进行最小的限制假设。此外，它可以轻松与典型的模型自由RL算法集成，产生一个实用的HRL算法。我们在具有挑战性的机器人环境上进行了实验。

    Hierarchical reinforcement learning (HRL) has the potential to solve complex long horizon tasks using temporal abstraction and increased exploration. However, hierarchical agents are difficult to train due to inherent non-stationarity. We present primitive enabled adaptive relabeling (PEAR), a two-phase approach where we first perform adaptive relabeling on a few expert demonstrations to generate efficient subgoal supervision, and then jointly optimize HRL agents by employing reinforcement learning (RL) and imitation learning (IL). We perform theoretical analysis to $(i)$ bound the sub-optimality of our approach, and $(ii)$ derive a generalized plug-and-play framework for joint optimization using RL and IL. PEAR uses a handful of expert demonstrations and makes minimal limiting assumptions on the task structure. Additionally, it can be easily integrated with typical model free RL algorithms to produce a practical HRL algorithm. We perform experiments on challenging robotic environments
    
[^68]: 基于Implicit Neural Representations的时间序列连续建模用于插值和预测

    Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations. (arXiv:2306.05880v1 [cs.LG])

    [http://arxiv.org/abs/2306.05880](http://arxiv.org/abs/2306.05880)

    该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。

    

    尽管时间序列建模已被广泛探索，但在面对真实世界的数据时仍面临重大挑战。我们提出了一种新颖的建模方法，利用Implicit Neural Representations (INR)。该方法使我们能够有效地捕捉时间序列的连续性，并提供了自然的解决方案，以处理缺失数据、处理不规则采样或来自多个传感器的不对准观测等重复建模问题。通过引入条件调制INR参数并利用元学习技术，我们解决了模型泛化到未见样本和时间窗口移位的问题。通过大量实验，我们的模型展示了在预测和插值任务中领先的性能，同时在处理许多竞争模型无法处理的各种具有挑战性的场景方面展现了灵活性。

    Although widely explored, time series modeling continues to encounter significant challenges when confronted with real-world data. We propose a novel modeling approach leveraging Implicit Neural Representations (INR). This approach enables us to effectively capture the continuous aspect of time series and provides a natural solution to recurring modeling issues such as handling missing data, dealing with irregular sampling, or unaligned observations from multiple sensors. By introducing conditional modulation of INR parameters and leveraging meta-learning techniques, we address the issue of generalization to both unseen samples and time window shifts. Through extensive experimentation, our model demonstrates state-of-the-art performance in forecasting and imputation tasks, while exhibiting flexibility in handling a wide range of challenging scenarios that competing models cannot.
    
[^69]: 动态不确定性下的大规模数据集修剪方法

    Large-scale Dataset Pruning with Dynamic Uncertainty. (arXiv:2306.05175v1 [cs.LG])

    [http://arxiv.org/abs/2306.05175](http://arxiv.org/abs/2306.05175)

    本文提出了一种探索预测不确定性和训练动态的简单且有效的大规模数据集修剪方法，以产生信息量丰富的子集用于训练深度模型，实验结果表明优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。

    

    在许多学习任务，例如图像分类中，收集更大的数据集并在其上训练更大的模型是推动技术前进的关键因素。由此产生的计算成本逐渐变得难以承受。本文研究了如何修剪大规模数据集，从而产生信息量丰富的子集，用于训练复杂的深度模型，且性能下降可以忽略不计。我们提出了一种简单但有效的数据集修剪方法，通过探索预测不确定性和训练动态来实现。据我们所知，这是第一篇在大规模数据集（ImageNet-1K和ImageNet-21K）和先进模型（Swin Transformer和ConvNeXt）上研究数据集修剪的工作。广泛的实验结果表明，我们的方法优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。代码和修剪后的数据集可在https://github.com/BAAI-DCAI/Dataset-Pruning上获得。

    The state of the art of many learning tasks, e.g., image classification, is advanced by collecting larger datasets and then training larger models on them. As the outcome, the increasing computational cost is becoming unaffordable. In this paper, we investigate how to prune the large-scale datasets, and thus produce an informative subset for training sophisticated deep models with negligible performance drop. We propose a simple yet effective dataset pruning method by exploring both the prediction uncertainty and training dynamics. To our knowledge, this is the first work to study dataset pruning on large-scale datasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin Transformer and ConvNeXt. Extensive experimental results indicate that our method outperforms the state of the art and achieves 75% lossless compression ratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are available at https://github.com/BAAI-DCAI/Dataset-Pruning.
    
[^70]: 何时展示建议？在AI辅助编程中整合人类反馈

    When to Show a Suggestion? Integrating Human Feedback in AI-Assisted Programming. (arXiv:2306.04930v1 [cs.HC])

    [http://arxiv.org/abs/2306.04930](http://arxiv.org/abs/2306.04930)

    本研究利用先前数据的干预措施提高基于AI的代码推荐系统的有效性，提出了一个CDHF框架来整合人类反馈，预测建议接受程度并决定何时展示哪些建议。

    

    基于AI的代码推荐系统，如Copilot和CodeWhisperer，提供程序员环境（例如IDE）内的代码建议，旨在提高他们的生产力。由于在这些场景中，程序员接受和拒绝建议，因此理想情况下，该系统应使用此反馈以促进这一目标。本研究利用程序员与Copilot交互的先前数据，开发可以节省程序员时间的干预措施。我们提出了一个实用理论框架，用于建模与程序员的交互，并决定何时展示哪些建议。我们的框架“基于人类反馈的条件建议展示”（CDHF）基于对程序员操作的预测模型。使用535名程序员的数据，我们构建了可以预测建议接受程度的模型。在对通过AI辅助编程解决的真实世界编程任务的回顾性评估中，我们发现CDHF能够实现有利的权衡。我们的发现表明，整合人类反馈可以显著提高基于AI的代码推荐系统的有效性。

    AI powered code-recommendation systems, such as Copilot and CodeWhisperer, provide code suggestions inside a programmer's environment (e.g., an IDE) with the aim to improve their productivity. Since, in these scenarios, programmers accept and reject suggestions, ideally, such a system should use this feedback in furtherance of this goal. In this work we leverage prior data of programmers interacting with Copilot to develop interventions that can save programmer time. We propose a utility theory framework, which models this interaction with programmers and decides when and which suggestions to display. Our framework Conditional suggestion Display from Human Feedback (CDHF) is based on predictive models of programmer actions. Using data from 535 programmers we build models that predict the likelihood of suggestion acceptance. In a retrospective evaluation on real-world programming tasks solved with AI-assisted programming, we find that CDHF can achieve favorable tradeoffs. Our findings s
    
[^71]: 机器学习和人工智能协作关闭高危孕产妇护理差距

    Closing the Gap in High-Risk Pregnancy Care Using Machine Learning and Human-AI Collaboration. (arXiv:2305.17261v1 [cs.LG])

    [http://arxiv.org/abs/2305.17261](http://arxiv.org/abs/2305.17261)

    本论文介绍了一种基于机器学习和人工智能协作的高危孕产妇计划，提出了早期妊娠检测、准确识别高风险会员和提供可解释指标等三个挑战的解决方案，提高了孕期风险的预测准确率。

    

    健康保险公司通常使用算法来识别会受益于护理和状况管理计划的会员，该计划提供个性化的高端临床支持。算法识别与临床干预之间的及时、准确和无缝集成取决于系统设计师和护理管理员之间的有效协作。我们关注了一个旨在减少孕产妇不良产前、产期和产后事件的高危孕产妇计划，并描述了我们如何克服护理管理员所述的三个HRP计划的挑战：（1）早期检测妊娠，（2）准确识别有影响力的高风险会员，以及（3）提供可解释的指标来补充预测。我们提出了一种新的孕期识别算法，在回顾性研究中比之前基于代码的模型提前了57天识别妊娠。然后我们建立了一个模型来预测会影响孕期的并发症。

    Health insurers often use algorithms to identify members who would benefit from care and condition management programs, which provide personalized, high-touch clinical support. Timely, accurate, and seamless integration between algorithmic identification and clinical intervention depends on effective collaboration between the system designers and nurse care managers. We focus on a high-risk pregnancy (HRP) program designed to reduce the likelihood of adverse prenatal, perinatal, and postnatal events and describe how we overcome three challenges of HRP programs as articulated by nurse care managers; (1) early detection of pregnancy, (2) accurate identification of impactable high-risk members, and (3) provision of explainable indicators to supplement predictions. We propose a novel algorithm for pregnancy identification that identifies pregnancies 57 days earlier than previous code-based models in a retrospective study. We then build a model to predict impactable pregnancy complications 
    
[^72]: 离线体验重放用于连续的离线强化学习

    Offline Experience Replay for Continual Offline Reinforcement Learning. (arXiv:2305.13804v1 [cs.LG])

    [http://arxiv.org/abs/2305.13804](http://arxiv.org/abs/2305.13804)

    本论文提出了一个新的场景——连续离线强化学习 (CORL)，解决了代理在离线任务序列学习中可能出现的灾难性遗忘问题。实验结果发现，经验重放 (ER) 是最适合 CORL 问题的算法，但引入 ER 后会遇到新的分布偏移问题。

    

    代理能够通过一系列预先收集的离线数据集不断学习新技能是理想的。然而，在资源有限的情况下，连续学习一系列离线任务很可能导致灾难性的遗忘问题。本文提出了一个新的场景——连续离线强化学习 (CORL)，代理通过一个小的回放缓冲区学习一系列离线强化学习任务，并在所有学习任务中追求良好的性能，而不探索所有顺序任务的任何环境。为了在所有顺序任务上持续学习，代理需要以离线方式获取新知识，同时保持旧知识。为此，我们引入了连续学习算法，并实验发现经验重放 (ER) 是 CORL 问题最适合的算法。然而，我们观察到将 ER 引入 CORL 会遇到新的分布偏移问题：数据集中不同任务之间的状态分布不一致。

    The capability of continuously learning new skills via a sequence of pre-collected offline datasets is desired for an agent. However, consecutively learning a sequence of offline tasks likely leads to the catastrophic forgetting issue under resource-limited scenarios. In this paper, we formulate a new setting, continual offline reinforcement learning (CORL), where an agent learns a sequence of offline reinforcement learning tasks and pursues good performance on all learned tasks with a small replay buffer without exploring any of the environments of all the sequential tasks. For consistently learning on all sequential tasks, an agent requires acquiring new knowledge and meanwhile preserving old knowledge in an offline manner. To this end, we introduced continual learning algorithms and experimentally found experience replay (ER) to be the most suitable algorithm for the CORL problem. However, we observe that introducing ER into CORL encounters a new distribution shift problem: the mism
    
[^73]: DermSynth3D：野外注释皮肤科图像的综合

    DermSynth3D: Synthesis of in-the-wild Annotated Dermatology Images. (arXiv:2305.12621v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2305.12621](http://arxiv.org/abs/2305.12621)

    该论文提出了一种名为DermSynth3D的新框架，它使用可微分渲染器将皮肤病变模式混合到人体三维纹理网格上并生成逼真的二维皮肤镜像图像，同时提供对应的密集注释以进行语义分割。

    

    近年来，深度学习在皮肤科图像分析领域展现出了巨大的潜力。然而，该领域现有的数据集存在显着限制，包括样本图像数量较少、疾病条件有限、注释不足以及非标准化图像采集。为了解决这些问题，我们提出了一种名为DermSynth3D的新框架。该框架使用可微分渲染器将皮肤病变模式混合到人体的三维纹理网格上，并在各种背景场景下采用不同视角和光照条件生成二维图像。我们的方法遵循自上而下的规则，限制混合和渲染过程，以创建具有野外照片感的皮肤条件的二维图像，确保更有意义的结果。该框架生成逼真的二维皮肤镜像图像，并生成对皮肤、皮肤状况、身体部位和头发区域进行语义分割的对应密集注释。

    In recent years, deep learning (DL) has shown great potential in the field of dermatological image analysis. However, existing datasets in this domain have significant limitations, including a small number of image samples, limited disease conditions, insufficient annotations, and non-standardized image acquisitions. To address these shortcomings, we propose a novel framework called DermSynth3D. DermSynth3D blends skin disease patterns onto 3D textured meshes of human subjects using a differentiable renderer and generates 2D images from various camera viewpoints under chosen lighting conditions in diverse background scenes. Our method adheres to top-down rules that constrain the blending and rendering process to create 2D images with skin conditions that mimic in-the-wild acquisitions, ensuring more meaningful results. The framework generates photo-realistic 2D dermoscopy images and the corresponding dense annotations for semantic segmentation of the skin, skin conditions, body parts, 
    
[^74]: 神经置信传播译码器的泛化边界

    Generalization Bounds for Neural Belief Propagation Decoders. (arXiv:2305.10540v1 [cs.IT])

    [http://arxiv.org/abs/2305.10540](http://arxiv.org/abs/2305.10540)

    本文研究了神经置信传播译码器的泛化能力，提出了一组新的理论结果，界定了解码器的泛化间隙，结果与解码器的复杂程度有关。

    

    越来越多的采用基于机器学习的方法来设计下一代通信系统的解码器。一个广泛使用的框架是神经置信传播（NBP），它将置信传播（BP）迭代展开为深度神经网络，参数以数据驱动方式进行训练。已经证明，NBP解码器相较于传统的解码算法有所改进。本文研究了NBP解码器的泛化能力。具体而言，解码器的泛化间隙是经验和期望误码率之间的差异。我们提出了新的理论结果，界定了这种差距，并表明它与解码器的复杂程度（即代码参数（块长度、消息长度、变量/检查节点度数）、解码迭代次数和训练数据集大小）有关。我们还展示了常规和不规则奇偶校验矩阵的结果。据我们所知，这是第一组关于神经置信传播译码器的理论结果。

    Machine learning based approaches are being increasingly used for designing decoders for next generation communication systems. One widely used framework is neural belief propagation (NBP), which unfolds the belief propagation (BP) iterations into a deep neural network and the parameters are trained in a data-driven manner. NBP decoders have been shown to improve upon classical decoding algorithms. In this paper, we investigate the generalization capabilities of NBP decoders. Specifically, the generalization gap of a decoder is the difference between empirical and expected bit-error-rate(s). We present new theoretical results which bound this gap and show the dependence on the decoder complexity, in terms of code parameters (blocklength, message length, variable/check node degrees), decoding iterations, and the training dataset size. Results are presented for both regular and irregular parity-check matrices. To the best of our knowledge, this is the first set of theoretical results on 
    
[^75]: 使用RePU激活函数的可微分神经网络：在得分估计和保序回归中的应用。

    Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])

    [http://arxiv.org/abs/2305.00608](http://arxiv.org/abs/2305.00608)

    该论文介绍了使用RePU激活函数的可微分神经网络，在近似$C^s$平滑函数及其导数的同时建立了下限误差界，并证明了其在降低维度灾难方面的能力，此外还提出了一种使用RePU网络的惩罚保序回归(PDIR)方法。

    

    我们研究了由修正后的幂单元（RePU）函数激活的可微分神经网络的属性。我们展示了RePU神经网络的偏导数可以由混合激活RePU网络来表示，并推导了导数RePU网络函数类的复杂度的上界。在使用RePU激活的深度神经网络中，我们建立了同时近似$C^s$平滑函数及其导数的误差界。此外，当数据具有近似低维支持时，我们推导出改进的逼近误差界，证明了RePU网络减缓维度灾难的能力。为了说明我们的结果的实用性，我们考虑了深度得分匹配估计器(DSME)，并提出了一种使用RePU网络的惩罚保序回归(PDIR)。我们在假定目标函数属于$C^s$平滑函数类的情况下为DSME和PDIR建立非渐近超额风险界。

    We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
    
[^76]: 解耦图神经网络：同时训练多个简单的GNN，而不是一个。

    Decouple Graph Neural Networks: Train Multiple Simple GNNs Simultaneously Instead of One. (arXiv:2304.10126v1 [cs.LG])

    [http://arxiv.org/abs/2304.10126](http://arxiv.org/abs/2304.10126)

    本论文提出将多层图神经网络解耦为多个简单模块的方法，以实现更高效的训练。该方法包括经典的前向训练和设计的反向训练。每个模块都可以通过随机算法在前向训练中高效地训练，并且通过反向训练机制来使前面的模块能够感知后面的模块，从而充分训练浅层模块和更深层的模块。

    

    图神经网络（GNN）存在严重的效率问题，主要是由于节点依赖随着层数增加呈指数级增长。这极大地限制了随机优化算法的应用，使得GNN的训练通常很耗时。为了解决这个问题，我们提出了将多层GNN解耦为多个简单模块的方法，以实现更高效的训练。该方法由经典的前向训练（FT）和设计的反向训练（BT）组成。在所提出的框架下，每个模块都可以通过随机算法在FT中高效地训练，由于其简单性，不会扭曲图形信息。为避免FT的只单向信息传递，并充分训练浅层模块和更深层的模块，我们开发了一种反向训练机制，使前面的模块能够感知后面的模块。这种反向训练引入了反向信息传递到解耦模块中，同时也会有前向信息传递。

    Graph neural networks (GNN) suffer from severe inefficiency. It is mainly caused by the exponential growth of node dependency with the increase of layers. It extremely limits the application of stochastic optimization algorithms so that the training of GNN is usually time-consuming. To address this problem, we propose to decouple a multi-layer GNN as multiple simple modules for more efficient training, which is comprised of classical forward training (FT)and designed backward training (BT). Under the proposed framework, each module can be trained efficiently in FT by stochastic algorithms without distortion of graph information owing to its simplicity. To avoid the only unidirectional information delivery of FT and sufficiently train shallow modules with the deeper ones, we develop a backward training mechanism that makes the former modules perceive the latter modules. The backward training introduces the reversed information delivery into the decoupled modules as well as the forward i
    
[^77]: CAFIN: 基于节点中心性的公平性增强进程的无监督图表示学习方法

    CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs. (arXiv:2304.04391v1 [cs.LG])

    [http://arxiv.org/abs/2304.04391](http://arxiv.org/abs/2304.04391)

    CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。

    

    由于所学嵌入的紧凑性和丰富性以及未标记图数据的丰富性，无监督学习的图表示在(大型)图上已经受到研究界的重视。当这些节点表示被部署时，必须使用适当的公平性约束条件生成以减少它们对下游任务造成的偏差。因此，对于特定的下游任务，已经调查了图学习算法的群体和个体公平性概念。这些公平性概念的主要局限性是没有考虑连接模式在图中导致的不同节点影响(或中心性能量)。在本文中，我们为归纳图表示学习算法设计了一个基于中心性的公平框架。我们提出了CAFIN（Centrality Aware Fairness inducing IN-processing），一种利用图结构改进GraphSAGE表示的进程技术——无监督图学习文献中的一种流行框架。对真实世界数据集的广泛实验表明，CAFIN在提供具有竞争力或更好的下游任务性能的同时，实现了最先进的公平结果。

    Unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. When deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. Consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. One major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). In this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. We propose CAFIN (Centrality Aware Fairness inducing IN-processing), an in-processing technique that leverages graph structure to improve GraphSAGE's representations - a popular framework in the unsup
    
[^78]: 线性最优偏移嵌入

    Linear Optimal Partial Transport Embedding. (arXiv:2302.03232v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03232](http://arxiv.org/abs/2302.03232)

    本文提出了线性最优偏移嵌入技术（LOPT），它扩展了（局部）线性化技术到OPT问题上，提高了正测度对之间的计算速度。并且在点云内插和PCA分析中进行了应用。

    

    最优传输（OT）由于在机器学习、统计学和信号处理等领域中的广泛应用而变得越来越受欢迎。然而，平衡质量限制了它在实际问题中的性能。为了解决这些问题，已经提出了OT问题的变体，包括不平衡OT，最优偏移传输（OPT）和Hellinger Kantorovich（HK）。在本文中，我们提出了线性最优偏移（LOPT）嵌入技术，它将OT和HK上的（局部）线性化技术扩展到OPT问题上。所提出的嵌入技术提高了正测度对之间的LOPT距离的计算速度。除了我们的理论贡献，我们还展示了LOPT嵌入技术在点云内插和PCA分析中的应用。

    Optimal transport (OT) has gained popularity due to its various applications in fields such as machine learning, statistics, and signal processing. However, the balanced mass requirement limits its performance in practical problems. To address these limitations, variants of the OT problem, including unbalanced OT, Optimal partial transport (OPT), and Hellinger Kantorovich (HK), have been proposed. In this paper, we propose the Linear optimal partial transport (LOPT) embedding, which extends the (local) linearization technique on OT and HK to the OPT problem. The proposed embedding allows for faster computation of OPT distance between pairs of positive measures. Besides our theoretical contributions, we demonstrate the LOPT embedding technique in point-cloud interpolation and PCA analysis.
    
[^79]: 读懂代码背后：模拟AI辅助编程中的用户行为和成本

    Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming. (arXiv:2210.14306v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2210.14306](http://arxiv.org/abs/2210.14306)

    该论文研究了代码推荐系统GitHub Copilot，发现了程序员与该系统交互的一些常见活动，揭示了其低效性和时间成本，从而为改进界面设计和度量方法提供了动力。

    

    代码推荐系统，如Copilot和CodeWhisperer，通过自动建议和自动完成代码，有潜力提高程序员的生产率。然而，要充分发挥它们的潜力，我们必须了解程序员如何与这些系统交互，并确定改进交互的方法。为了取得进展，我们研究了每天由数百万程序员使用的代码推荐系统GitHub Copilot。我们开发了一个常见程序员活动的分类系统CUPS，以便模拟用户与Copilot的交互。我们对21名完成编码任务并回顾性地使用CUPS标记其会话的程序员的研究表明，CUPS可以帮助我们了解程序员如何与代码推荐系统交互，揭示了效率低下和时间成本。我们的洞见揭示了程序员如何与Copilot交互，并激发了新的界面设计和度量方法。

    Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To make progress, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics.
    
[^80]: 随机时变图上的分散在线正则化学习

    Decentralized Online Regularized Learning Over Random Time-Varying Graphs. (arXiv:2206.03861v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03861](http://arxiv.org/abs/2206.03861)

    本文研究了随机时变图上的分散在线正则化线性回归算法，提出了非负超-鞅不等式的估计误差，证明了算法在满足样本路径时空兴奋条件时，节点的估计可以收敛于未知的真实参数向量。

    

    本文研究了在随机时变图上的分散在线正则化线性回归算法。在每个时间步中，每个节点都运行一个在线估计算法，该算法包括创新项（处理自身新测量值）、共识项（加权平均自身及其邻居的估计，带有加性和乘性通信噪声）和正则化项（防止过度拟合）。不要求回归矩阵和图满足特殊的统计假设，如相互独立、时空独立或平稳性。我们发展了非负超-鞅不等式的估计误差，并证明了如果算法增益、图和回归矩阵共同满足样本路径时空兴奋条件，节点的估计几乎可以肯定地收敛于未知的真实参数向量。特别地，通过选择适当的算法增益，该条件成立。

    We study the decentralized online regularized linear regression algorithm over random time-varying graphs. At each time step, every node runs an online estimation algorithm consisting of an innovation term processing its own new measurement, a consensus term taking a weighted sum of estimations of its own and its neighbors with additive and multiplicative communication noises and a regularization term preventing over-fitting. It is not required that the regression matrices and graphs satisfy special statistical assumptions such as mutual independence, spatio-temporal independence or stationarity. We develop the nonnegative supermartingale inequality of the estimation error, and prove that the estimations of all nodes converge to the unknown true parameter vector almost surely if the algorithm gains, graphs and regression matrices jointly satisfy the sample path spatio-temporal persistence of excitation condition. Especially, this condition holds by choosing appropriate algorithm gains 
    

