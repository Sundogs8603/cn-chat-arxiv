# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [CausalChaos! Dataset for Comprehensive Causal Action Question Answering Over Longer Causal Chains Grounded in Dynamic Visual Scenes](https://arxiv.org/abs/2404.01299) | 利用卡通图像构建的CausalChaos!数据集，包含更长因果链的因果问答，通过动态互动和视觉展示挑战性因果关系，为模型提供了更多具挑战性且明确定义的因果关系。 |
| [^2] | [Secure Aggregation is Not Private Against Membership Inference Attacks](https://arxiv.org/abs/2403.17775) | 本文探讨了安全聚合在隐私方面的问题，揭示了其在面对成员推断攻击时并不具备足够的私密性。 |
| [^3] | [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://arxiv.org/abs/2403.16973) | VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。 |
| [^4] | [Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning](https://arxiv.org/abs/2403.07362) | 该论文从对抗的角度提出了一种新的机器遗忘评估方法，通过确定最具挑战性的数据子集，即最坏情况遗忘集，来增强对影响擦除的挑战。 |
| [^5] | [L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification](https://arxiv.org/abs/2403.06064) | 本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。 |
| [^6] | [Architectural Blueprint For Heterogeneity-Resilient Federated Learning](https://arxiv.org/abs/2403.04546) | 提出了一个三层架构用于优化边缘计算环境中的联邦学习，解决了客户端数据异构性和计算约束挑战，提高了非独立同分布数据集管理效率，显著改善了模型准确性，减少了通信开销，促进了联邦学习技术更广泛的应用。 |
| [^7] | [NiNformer: A Network in Network Transformer with Token Mixing Generated Gating Function](https://arxiv.org/abs/2403.02411) | 提出了一种新的计算块，称为NiNformer，具有令牌混合生成门控功能，以解决注意机制在深度学习中的计算成本高昂和数据集要求大的缺点。 |
| [^8] | [Exponential Expressivity of ReLU$^k$ Neural Networks on Gevrey Classes with Point Singularities](https://arxiv.org/abs/2403.02035) | 证明了ReLU$^k$神经网络在具有点奇异性的Gevrey类问题上具有指数表达能力，中间结果表明可以使用ReLU和ReLU$^2$激活组合的神经网络精确模拟高阶有限元。 |
| [^9] | [EUROPA: A Legal Multilingual Keyphrase Generation Dataset](https://arxiv.org/abs/2403.00252) | 提出了一个用于法律领域多语关键词生成的数据集EUROPA，包含所有24种欧盟官方语言，表明在特定领域多语言语料库上仍有改进空间。 |
| [^10] | [Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain](https://arxiv.org/abs/2402.19226) | 该研究通过机器学习算法调查了个性化疼痛护理推荐中的性别公平性，发现在某些患者信息缺失时，女性的疼痛护理推荐质量明显低于男性。 |
| [^11] | [An Interpretable Evaluation of Entropy-based Novelty of Generative Models](https://arxiv.org/abs/2402.17287) | 提出了一种用于评估生成模型新颖性的基于核的熵新颖性 (KEN) 分数 |
| [^12] | [Neural Networks and Friction: Slide, Hold, Learn](https://arxiv.org/abs/2402.14148) | 循环神经网络利用GRU架构学习合成数据中复杂摩擦定律动力学，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。 |
| [^13] | [End-to-end Supervised Prediction of Arbitrary-size Graphs with Partially-Masked Fused Gromov-Wasserstein Matching](https://arxiv.org/abs/2402.12269) | 提出了利用部分掩码融合的Gromov-Wasserstein匹配进行任意大小图的端对端监督预测方法，并展示了其在不同任务上相比竞争者更高的效率和多功能性。 |
| [^14] | [Provably Safe Neural Network Controllers via Differential Dynamic Logic](https://arxiv.org/abs/2402.10998) | 通过差分动态逻辑与神经网络验证相结合的VerSAILLE方法，实现了对神经网络控制系统在无限时间范围上的安全性证明。 |
| [^15] | [HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments](https://arxiv.org/abs/2402.10228) | HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。 |
| [^16] | [Explaining Probabilistic Models with Distributional Values](https://arxiv.org/abs/2402.09947) | 本文介绍了一种用于解释概率模型的方法，通过引入分布值来解决当前方法在解释模型输出时的不匹配问题，并通过案例研究展示了该方法提供的详细和有洞察力的解释。 |
| [^17] | [QuRating: Selecting High-Quality Data for Training Language Models](https://arxiv.org/abs/2402.09739) | QuRating是一种选择高质量数据用于训练语言模型的方法，它能够捕捉人类直观感知的文本的抽象特征。在实验中发现，平衡质量和多样性是很重要的。 |
| [^18] | [Changes by Butterflies: Farsighted Forecasting with Group Reservoir Transformer](https://arxiv.org/abs/2402.09573) | 我们提出了一种群体储备转换器的架构，通过解决历史序列的挑战和初始条件的敏感性，实现更准确、更稳健地预测长期事件。在多元时间序列中，我们的模型相比最先进的DNN模型表现出更高的准确率，最高可减少89.43%的误差。 |
| [^19] | [An Empirical Study Into What Matters for Calibrating Vision-Language Models](https://arxiv.org/abs/2402.07417) | 本研究通过实证研究探索了视觉-语言模型(VLMs)的校准性质，并发现温度缩放可以显著提升校准性能，而且VLMs只需少量示例即可进行校准。 |
| [^20] | [Open-Vocabulary Calibration for Vision-Language Models](https://arxiv.org/abs/2402.04655) | 本文研究了视觉语言模型中的开放词汇校准问题，在提示学习的背景下发现现有的校准方法不足以解决该问题。为此，提出了一种称为 Distance-Aware Ca 的简单而有效的方法来解决问题。 |
| [^21] | [Gradient Coding in Decentralized Learning for Evading Stragglers](https://arxiv.org/abs/2402.04193) | 本文提出了一种新的基于八卦的梯度编码分散式学习方法（GOCO），以解决存在延迟节点的分散式学习问题。与基准方法相比，该方法在学习性能上具有优越性。 |
| [^22] | [Disparate Impact on Group Accuracy of Linearization for Private Inference](https://arxiv.org/abs/2402.03629) | 本文研究了线性化对隐私推断中群体准确性的影响，发现减少ReLU激活函数数量会不成比例地降低少数群体的准确性，而对于多数群体则几乎没有影响。采用简单的微调步骤可以解决这个问题。 |
| [^23] | [ICED: Zero-Shot Transfer in Reinforcement Learning via In-Context Environment Design](https://arxiv.org/abs/2402.03479) | 本研究探索了深度强化学习代理的零样本迁移能力，并发现通过根据值损失优先选择级别，可以改善代理的推广能力。此外，无监督环境设计方法对改善代理表现也具有重要作用。 |
| [^24] | [Future Directions in Foundations of Graph Machine Learning](https://arxiv.org/abs/2402.02287) | 图机器学习领域的未来方向应该是发展一个更加均衡的理论，从更完整的角度探究图神经网络的表达能力、泛化和优化之间的相互关系。 |
| [^25] | [Generative AI to Generate Test Data Generators](https://arxiv.org/abs/2401.17626) | 本研究评估了生成式人工智能在不同领域生成测试数据的能力，并证明它能够在不同的集成级别上生成逼真的测试数据生成器。 |
| [^26] | [In-Context Reinforcement Learning for Variable Action Spaces](https://arxiv.org/abs/2312.13327) | 本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。 |
| [^27] | [Immunohistochemistry guided segmentation of benign epithelial cells, in situ lesions, and invasive epithelial cells in breast cancer slides](https://arxiv.org/abs/2311.13261) | 该研究旨在开发一个用于乳腺癌切片中上皮细胞分割的AI模型，通过免疫组织化学引导分割出良性上皮细胞、原位病变和浸润性上皮细胞。 |
| [^28] | [Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?](https://arxiv.org/abs/2311.07564) | 本文研究了作者归属模型在演讲文本中区分发言人的能力，并提出了以会话演讲文本为重点的发言人归属基准。 |
| [^29] | [Adam through a Second-Order Lens.](http://arxiv.org/abs/2310.14963) | 该论文提出了AdamQLR，它是一个通过将K-FAC中的技术与Adam的更新方法相结合的优化器，通过考虑二阶数据上的Adam行为而得到启发。在回归和分类任务上进行了评估，结果显示AdamQLR在运行时间和推广性能方面表现出良好的竞争力。 |
| [^30] | [SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications.](http://arxiv.org/abs/2310.12768) | 本文提出了一种新颖的技术，语义干扰消除（SemantIC），用于提高6G无线通信网络的信息质量。通过在接收器上使用语义自动编码器，SemantIC能够迭代消除信号中的噪声和语义干扰。仿真结果表明，SemantIC能够在不增加额外信道资源成本的情况下改进性能。 |
| [^31] | [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks.](http://arxiv.org/abs/2310.03684) | SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。 |
| [^32] | [A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions.](http://arxiv.org/abs/2310.00177) | 我们引入了一个用于混合边界条件的泊松方程的神经预处理迭代求解器，核心是一个神经网络，能够近似逆离散结构网格拉普拉斯算子，并且在训练集之外的边界条件下仍然有效。 |
| [^33] | [Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer.](http://arxiv.org/abs/2309.16888) | 这个论文介绍了一种新颖的方法，利用Transformer-based Multivariate Time Series Classifier (TMTSC)来预测风险投资和成长资本的候选公司的成功可能性，以优化投资目标的选择。通过对相关的方法进行了全面回顾和实验验证，证明了该方法的有效性。 |
| [^34] | [Towards the TopMost: A Topic Modeling System Toolkit.](http://arxiv.org/abs/2309.06908) | 本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。 |
| [^35] | [Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation.](http://arxiv.org/abs/2309.06255) | 本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。 |
| [^36] | [Maestro: Uncovering Low-Rank Structures via Trainable Decomposition.](http://arxiv.org/abs/2308.14929) | 本研究提出了一种通过可训练分解揭示低秩结构的方法，解决了深度神经网络训练大模型时的耗时和资源消耗的问题。 |
| [^37] | [Neural Implicit Morphing of Face Images.](http://arxiv.org/abs/2308.13888) | 本论文提出了一种利用神经网络实现人脸图像变形和混合的方法，通过利用网络的平滑性和灵活性，结合经典方法中的能量函数，实现了高效、准确和多样化的人脸变形效果。 |
| [^38] | [NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory.](http://arxiv.org/abs/2308.12970) | 本文提出了一种新的布料模拟方法 NeuralClothSim，使用薄壳理论和神经变形场进行表面演化，克服了现有布料模拟方法的局限性和挑战，为物理合理的布料模拟提供了一种全新的视角。 |
| [^39] | [Neural Operators for Delay-Compensating Control of Hyperbolic PIDEs.](http://arxiv.org/abs/2307.11436) | 该论文提出了延迟补偿超bolic PIDE控制的神经算子框架，扩展了基本PDE控制结果到一个涉及状态和系统延迟的高级超bolic类。使用DeepONet逼近算子，可以在无限维度上建立稳定的闭环反馈，并开发了逼近的观测者和输出反馈定律。 |
| [^40] | [Sparse Graphical Linear Dynamical Systems.](http://arxiv.org/abs/2307.03210) | 该论文提出了一种稀疏图线性动态系统方法，用于处理时间序列数据集。该方法可以利用图形视角来学习模型参数，解决了现有方法的限制，并提供了概率性和可解释性的学习结果。 |
| [^41] | [Unexplainable Explanations: Towards Interpreting tSNE and UMAP Embeddings.](http://arxiv.org/abs/2306.11898) | 本文研究旨在回答ARDR算法的收敛性问题，我们将ARDR方法与传统的降维技术联系起来，可以将PCA嵌入完全恢复，通过稍加修改可以用LLE复现ARDR嵌入，并形式化了一系列猜想，如果成立，可以将2D嵌入中的结构归因于输入分布。 |
| [^42] | [Large-scale Dataset Pruning with Dynamic Uncertainty.](http://arxiv.org/abs/2306.05175) | 本文提出了一种探索预测不确定性和训练动态的简单且有效的大规模数据集修剪方法，以产生信息量丰富的子集用于训练深度模型，实验结果表明优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。 |
| [^43] | [Initial Guessing Bias: How Untrained Networks Favor Some Classes.](http://arxiv.org/abs/2306.00809) | 本文提出了“初始猜测偏差”现象，即在未经过训练的神经网络中，由于架构选择的影响，模型往往会将所有预测指向同一个类别。该现象对架构选择和初始化有实际指导意义，并具有理论后果，例如节点置换对称性的崩溃和深度带来的非平凡差异。 |
| [^44] | [Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection, Calibration, and Accuracy.](http://arxiv.org/abs/2305.11616) | 这项研究提出了一种使用显著性图来促进深度集成多样性的方法，用于改善OOD检测、校准和准确性，能够优于传统的集成技术，并在OpenOOD基准测试上证明了其有效性。 |
| [^45] | [Anatomy-aware and acquisition-agnostic joint registration with SynthMorph.](http://arxiv.org/abs/2301.11329) | SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。 |
| [^46] | [L2XGNN: Learning to Explain Graph Neural Networks.](http://arxiv.org/abs/2209.14402) | L2XGNN提出了一个框架来解释图神经网络，通过选择解释子图（模体）实现忠实的解释。该框架能够识别负责预测图属性的模体，并实现与基线方法相同的分类精度。 |

# 详细

[^1]: CausalChaos!数据集：基于动态视觉场景中更长因果链的全面因果行动问答

    CausalChaos! Dataset for Comprehensive Causal Action Question Answering Over Longer Causal Chains Grounded in Dynamic Visual Scenes

    [https://arxiv.org/abs/2404.01299](https://arxiv.org/abs/2404.01299)

    利用卡通图像构建的CausalChaos!数据集，包含更长因果链的因果问答，通过动态互动和视觉展示挑战性因果关系，为模型提供了更多具挑战性且明确定义的因果关系。

    

    因果视频问答（QA）越来越受到关注，然而现有数据集在因果推理分析方面往往缺乏深度。为了填补这一空白，我们利用卡通的独特属性构建了CausalChaos!，这是一个新颖且具有挑战性的因果问答（Why-QA）数据集，基于标志性的“猫和老鼠”卡通系列。我们的数据集通过周到的问题和多层次答案，包含着嵌入动态互动和视觉中的更长因果链，同时动画原理允许动画师创造定义明确、明了的因果关系。这些因素使模型能够解决更具挑战性但明确定义的因果关系。我们还引入了硬负采样，包括CausalConfusion版本。虽然模型表现良好，但仍有很大改进空间，特别是在开放式答案方面。我们确定了更为先进/明确的因果关系建模和联合建模等改进方向。

    arXiv:2404.01299v1 Announce Type: cross  Abstract: Causal video question answering (QA) has garnered increasing interest, yet existing datasets often lack depth in causal reasoning analysis. To address this gap, we capitalize on the unique properties of cartoons and construct CausalChaos!, a novel, challenging causal Why-QA dataset built upon the iconic "Tom and Jerry" cartoon series. With thoughtful questions and multi-level answers, our dataset contains much longer causal chains embedded in dynamic interactions and visuals, at the same time principles of animation allows animators to create well-defined, unambiguous causal relationships. These factors allow models to solve more challenging, yet well-defined causal relationships. We also introduce hard negative mining, including CausalConfusion version. While models perform well, there is much room for improvement, especially, on open-ended answers. We identify more advanced/explicit causal relationship modeling and joint modeling of 
    
[^2]: 安全聚合在面对成员推断攻击时并非私密的

    Secure Aggregation is Not Private Against Membership Inference Attacks

    [https://arxiv.org/abs/2403.17775](https://arxiv.org/abs/2403.17775)

    本文探讨了安全聚合在隐私方面的问题，揭示了其在面对成员推断攻击时并不具备足够的私密性。

    

    安全聚合（SecAgg）是联邦学习中常用的隐私增强机制，仅允许服务器访问模型更新的聚合结果，同时保护个体更新的机密性。尽管有关SecAgg保护隐私能力的广泛声明，但缺乏对其隐私性的正式分析，因此这些假设是不合理的。本文通过将SecAgg视为每个局部更新的局部差分隐私（LDP）机制，深入探讨了SecAgg的隐私影响。我们设计了一种简单攻击方式，其中对手服务器试图在SecAgg下的联邦学习的单一训练轮中推断出客户端提交的更新向量是两个可能向量中的哪一个。通过进行隐私审核，我们评估了该攻击的成功概率，并量化了SecAgg提供的LDP保证。我们的数字结果揭示了，与普遍声明相反，SecAgg并没有提供私密性。

    arXiv:2403.17775v1 Announce Type: new  Abstract: Secure aggregation (SecAgg) is a commonly-used privacy-enhancing mechanism in federated learning, affording the server access only to the aggregate of model updates while safeguarding the confidentiality of individual updates. Despite widespread claims regarding SecAgg's privacy-preserving capabilities, a formal analysis of its privacy is lacking, making such presumptions unjustified. In this paper, we delve into the privacy implications of SecAgg by treating it as a local differential privacy (LDP) mechanism for each local update. We design a simple attack wherein an adversarial server seeks to discern which update vector a client submitted, out of two possible ones, in a single training round of federated learning under SecAgg. By conducting privacy auditing, we assess the success probability of this attack and quantify the LDP guarantees provided by SecAgg. Our numerical results unveil that, contrary to prevailing claims, SecAgg offer
    
[^3]: VoiceCraft：野外零-shot语音编辑和文本到语音

    VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild

    [https://arxiv.org/abs/2403.16973](https://arxiv.org/abs/2403.16973)

    VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。

    

    我们介绍了VoiceCraft，一个基于标记填充的神经编解码器语言模型，实现了在有声书、互联网视频和播客上语音编辑和零-shot文本到语音（TTS）方面的最新性能。VoiceCraft采用Transformer解码器架构，并引入了一种标记重排过程，结合了因果掩码和延迟堆叠，以实现在现有序列内的生成。在语音编辑任务上，VoiceCraft生成的编辑语音在自然度方面几乎与未编辑的录音难以区分，经人类评估；对于零-shot TTS，我们的模型优于先前的最先进模型，包括VALLE和流行的商业模型XTTS-v2。关键的是，这些模型在具有多样口音、语音风格、录制条件、背景噪音和音乐的具有挑战性和真实性的数据集上进行了评估，我们的模型与其他模型相比表现始终良好。

    arXiv:2403.16973v1 Announce Type: cross  Abstract: We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VoiceCraft produces edited speech that is nearly indistinguishable from unedited recordings in terms of naturalness, as evaluated by humans; for zero-shot TTS, our model outperforms prior SotA models including VALLE and the popular commercial model XTTS-v2. Crucially, the models are evaluated on challenging and realistic datasets, that consist of diverse accents, speaking styles, recording conditions, and background noise and music, and our model performs consistently well compared to other models a
    
[^4]: 挑战遗忘：揭示机器遗忘中最坏情况遗忘集

    Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning

    [https://arxiv.org/abs/2403.07362](https://arxiv.org/abs/2403.07362)

    该论文从对抗的角度提出了一种新的机器遗忘评估方法，通过确定最具挑战性的数据子集，即最坏情况遗忘集，来增强对影响擦除的挑战。

    

    靠谱的机器学习(Machine Learning, ML)社区越来越认识到模型在训练后有选择性地“遗忘”数据点的重要性。这引出了机器遗忘(Machine Unlearning, MU)问题，旨在消除选定数据点对模型性能的影响，同时仍保持模型在遗忘后的实用性。尽管有各种MU方法来擦除数据影响，评估主要集中在随机数据遗忘上，忽视了对于真实衡量遗忘性能的数据子集选择的重要探究。为解决这一问题，我们从对抗的角度引入了一种新的MU评估视角。我们提出确定那些对影响擦除构成最大挑战的数据子集，即找出最坏情况遗忘集。利用双层优化原则，我们增强了在上层优化中的遗忘挑战。

    arXiv:2403.07362v1 Announce Type: cross  Abstract: The trustworthy machine learning (ML) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. This leads to the problem of machine unlearning (MU), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. Despite various MU methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. To tackle this issue, we introduce a new evaluative angle for MU from an adversarial viewpoint. We propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. Utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization 
    
[^5]: L$^2$GC: 洛伦兹线性图卷积网络用于节点分类

    L$^2$GC: Lorentzian Linear Graph Convolutional Networks For Node Classification

    [https://arxiv.org/abs/2403.06064](https://arxiv.org/abs/2403.06064)

    本文提出了一种新颖的洛伦兹线性图卷积网络框架，将双曲空间引入线性GCN，用于捕捉数据的树状结构，并在实验中取得了新的最先进的节点分类结果。

    

    线性图卷积网络（GCNs）用于对图数据中的节点进行分类。然而，我们注意到大多数现有的线性GCN模型在欧几里得空间中执行神经网络操作，这并没有明确捕捉到作为图模型的现实世界数据集中呈现出的类似树状的层次结构。本文尝试将双曲空间引入线性GCN，并提出了一种新颖的洛伦兹线性GCN框架。具体来说，我们将图节点的学习特征映射到双曲空间中，然后进行洛伦兹线性特征变换，以捕获数据的潜在树状结构。在标准引文网络数据集上进行的半监督学习实验结果显示，我们的方法在Citeseer数据集上达到了74.7%的准确度，而在PubMed数据集上达到了81.3%的准确度，创造了新的最先进结果。此外，我们观察到我们的方法可以训练至少达到2个数量级。

    arXiv:2403.06064v1 Announce Type: cross  Abstract: Linear Graph Convolutional Networks (GCNs) are used to classify the node in the graph data. However, we note that most existing linear GCN models perform neural network operations in Euclidean space, which do not explicitly capture the tree-like hierarchical structure exhibited in real-world datasets that modeled as graphs. In this paper, we attempt to introduce hyperbolic space into linear GCN and propose a novel framework for Lorentzian linear GCN. Specifically, we map the learned features of graph nodes into hyperbolic space, and then perform a Lorentzian linear feature transformation to capture the underlying tree-like structure of data. Experimental results on standard citation networks datasets with semi-supervised learning show that our approach yields new state-of-the-art results of accuracy 74.7$\%$ on Citeseer and 81.3$\%$ on PubMed datasets. Furthermore, we observe that our approach can be trained up to two orders of magnitu
    
[^6]: 面向异构鲁棒联邦学习的架构蓝图

    Architectural Blueprint For Heterogeneity-Resilient Federated Learning

    [https://arxiv.org/abs/2403.04546](https://arxiv.org/abs/2403.04546)

    提出了一个三层架构用于优化边缘计算环境中的联邦学习，解决了客户端数据异构性和计算约束挑战，提高了非独立同分布数据集管理效率，显著改善了模型准确性，减少了通信开销，促进了联邦学习技术更广泛的应用。

    

    本文提出了一种新颖的三层架构用于优化边缘计算环境中的联邦学习。该架构解决了与客户端数据异构性和计算约束相关的挑战。它引入了一个可扩展的、隐私保护的框架，增强了分布式机器学习的效率。通过实验，本文展示了该架构相对于传统联邦学习模型更有效地管理非独立同分布数据集的能力。此外，本文强调了这种创新方法显著提高模型准确性、减少通信开销，并促进联邦学习技术的更广泛应用的潜力。

    arXiv:2403.04546v1 Announce Type: new  Abstract: This paper proposes a novel three tier architecture for federated learning to optimize edge computing environments. The proposed architecture addresses the challenges associated with client data heterogeneity and computational constraints. It introduces a scalable, privacy preserving framework that enhances the efficiency of distributed machine learning. Through experimentation, the paper demonstrates the architecture capability to manage non IID data sets more effectively than traditional federated learning models. Additionally, the paper highlights the potential of this innovative approach to significantly improve model accuracy, reduce communication overhead, and facilitate broader adoption of federated learning technologies.
    
[^7]: NiNformer: 一种具有令牌混合生成门控功能的网络中网络变压器

    NiNformer: A Network in Network Transformer with Token Mixing Generated Gating Function

    [https://arxiv.org/abs/2403.02411](https://arxiv.org/abs/2403.02411)

    提出了一种新的计算块，称为NiNformer，具有令牌混合生成门控功能，以解决注意机制在深度学习中的计算成本高昂和数据集要求大的缺点。

    

    注意机制是Transformer架构的主要组件，自引入以来，在深度学习领域取得了显著进展，跨越了许多领域和多个任务。该机制在计算机视觉中被应用为Vision Transformer ViT，并且其用途已扩展到视觉领域的许多任务，如分类、分割、目标检测和图像生成。尽管该机制非常具有表现力和能力，但其缺点是计算成本高昂，需要大规模数据集来有效优化。为了解决这些缺点，文献中提出了许多设计来减轻计算负担和缓解数据大小要求。在视觉领域的一些尝试的例子包括MLP-Mixer、Conv-Mixer、Perciver-IO等。本文介绍了一种新的计算块，作为一种

    arXiv:2403.02411v1 Announce Type: cross  Abstract: The Attention mechanism is the main component of the Transformer architecture, and since its introduction, it has led to significant advancements in Deep Learning that span many domains and multiple tasks. The Attention Mechanism was utilized in Computer Vision as the Vision Transformer ViT, and its usage has expanded into many tasks in the vision domain, such as classification, segmentation, object detection, and image generation. While this mechanism is very expressive and capable, it comes with the drawback of being computationally expensive and requiring datasets of considerable size for effective optimization. To address these shortcomings, many designs have been proposed in the literature to reduce the computational burden and alleviate the data size requirements. Examples of such attempts in the vision domain are the MLP-Mixer, the Conv-Mixer, the Perciver-IO, and many more. This paper introduces a new computational block as an 
    
[^8]: ReLU$^k$神经网络在具有点奇异性的Gevrey类问题上的指数表达能力

    Exponential Expressivity of ReLU$^k$ Neural Networks on Gevrey Classes with Point Singularities

    [https://arxiv.org/abs/2403.02035](https://arxiv.org/abs/2403.02035)

    证明了ReLU$^k$神经网络在具有点奇异性的Gevrey类问题上具有指数表达能力，中间结果表明可以使用ReLU和ReLU$^2$激活组合的神经网络精确模拟高阶有限元。

    

    我们分析了在有界的多面体域$\mathrm{D} \subset \mathbb{R}^d$, $d=2,3$中具有点奇异性的平滑函数的深度神经网络模拟速率。我们证明了在Sobolev空间中的指数模拟速率，这与神经元的数量以及Gevrey正则解类内的非零系数的数量有关，这些解类是根据$\mathrm{D}$中加权Sobolev标度定义的，包括I.M. Babu\v{s}ka和B.Q. Guo的可数范数空间。作为中间结果，我们证明了在任意正则的简单形域$\mathrm{D} \subset \mathbb{R}^d$, $d\geq 2$上的连续、分段多项式高阶(``$p$-version'')有限元，其元素多项式度为$p\in\mathbb{N}$，可以被ReLU和ReLU$^2$激活组合的神经网络精确模拟。在形状正则的多面体域$\mathrm{D}$的简单形域划分上，神经元的数量以及t

    arXiv:2403.02035v1 Announce Type: cross  Abstract: We analyze deep Neural Network emulation rates of smooth functions with point singularities in bounded, polytopal domains $\mathrm{D} \subset \mathbb{R}^d$, $d=2,3$. We prove exponential emulation rates in Sobolev spaces in terms of the number of neurons and in terms of the number of nonzero coefficients for Gevrey-regular solution classes defined in terms of weighted Sobolev scales in $\mathrm{D}$, comprising the countably-normed spaces of I.M. Babu\v{s}ka and B.Q. Guo.   As intermediate result, we prove that continuous, piecewise polynomial high order (``$p$-version'') finite elements with elementwise polynomial degree $p\in\mathbb{N}$ on arbitrary, regular, simplicial partitions of polyhedral domains $\mathrm{D} \subset \mathbb{R}^d$, $d\geq 2$ can be exactly emulated by neural networks combining ReLU and ReLU$^2$ activations. On shape-regular, simplicial partitions of polytopal domains $\mathrm{D}$, both the number of neurons and t
    
[^9]: EUROPA：一个法律多语关键词生成数据集

    EUROPA: A Legal Multilingual Keyphrase Generation Dataset

    [https://arxiv.org/abs/2403.00252](https://arxiv.org/abs/2403.00252)

    提出了一个用于法律领域多语关键词生成的数据集EUROPA，包含所有24种欧盟官方语言，表明在特定领域多语言语料库上仍有改进空间。

    

    关键词生成主要在学术研究文章的背景下进行探索，特别侧重于科学领域和英语。 在这项工作中，我们提出了EUROPA，一个用于法律领域多语关键词生成的数据集。 它源自欧洲法院的法律判决，并包含了所有24种欧盟官方语言中的实例。 我们在我们的语料库上运行多语言模型并分析结果，展示了在像我们提出的特定领域多语言语料库上有改进空间。

    arXiv:2403.00252v1 Announce Type: cross  Abstract: Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a dataset for multilingual keyphrase generation in the legal domain. It is derived from legal judgments from the Court of Justice of the European Union (EU), and contains instances in all 24 EU official languages. We run multilingual models on our corpus and analyze the results, showing room for improvement on a domain-specific multilingual corpus such as the one we present.
    
[^10]: 探究机器学习驱动的慢性疼痛个性化护理中的性别公平性

    Investigating Gender Fairness in Machine Learning-driven Personalized Care for Chronic Pain

    [https://arxiv.org/abs/2402.19226](https://arxiv.org/abs/2402.19226)

    该研究通过机器学习算法调查了个性化疼痛护理推荐中的性别公平性，发现在某些患者信息缺失时，女性的疼痛护理推荐质量明显低于男性。

    

    本研究利用机器学习算法调查了个性化疼痛护理推荐中的性别公平性。利用上下文臂框架，使用LinUCB算法对包含164位患者在每个10次会话中的互动数据集进行了个性化推荐的制定和评估。结果表明，尽管对算法参数进行调整会影响疼痛护理推荐的质量，但这种影响在不同性别间保持一致。然而，当某些患者信息，如自我报告的疼痛测量值，缺失时，女性的疼痛护理推荐质量明显低于男性。

    arXiv:2402.19226v1 Announce Type: new  Abstract: This study investigates gender fairness in personalized pain care recommendations using machine learning algorithms. Leveraging a contextual bandits framework, personalized recommendations are formulated and evaluated using LinUCB algorithm on a dataset comprising interactions with $164$ patients across $10$ sessions each. Results indicate that while adjustments to algorithm parameters influence the quality of pain care recommendations, this impact remains consistent across genders. However, when certain patient information, such as self-reported pain measurements, is absent, the quality of pain care recommendations for women is notably inferior to that for men.
    
[^11]: 一个可解释的生成模型熵值新颖性评估

    An Interpretable Evaluation of Entropy-based Novelty of Generative Models

    [https://arxiv.org/abs/2402.17287](https://arxiv.org/abs/2402.17287)

    提出了一种用于评估生成模型新颖性的基于核的熵新颖性 (KEN) 分数

    

    生成模型框架和架构的巨大发展需要有原则的方法来评估模型相对于参考数据集或基线生成模型的新颖性。 虽然最近的文献已广泛研究了生成模型的质量、多样性和泛化能力的评估，但与基线模型相比的模型新颖性评估在机器学习社区中尚未得到充分研究。在这项工作中，我们关注多模态生成模型下的新颖性评估，并尝试回答以下问题：给定生成模型 $\mathcal{G}$ 的样本和参考数据集 $\mathcal{S}$，我们如何发现并计算 $\mathcal{G}$ 比 $\mathcal{S}$ 中更频繁地表达的模式。 我们介绍了一种谱方法来描述这一任务，并提出了基于核的熵新颖性 (KEN) 分数来量化基于模式的新颖性

    arXiv:2402.17287v1 Announce Type: new  Abstract: The massive developments of generative model frameworks and architectures require principled methods for the evaluation of a model's novelty compared to a reference dataset or baseline generative models. While the recent literature has extensively studied the evaluation of the quality, diversity, and generalizability of generative models, the assessment of a model's novelty compared to a baseline model has not been adequately studied in the machine learning community. In this work, we focus on the novelty assessment under multi-modal generative models and attempt to answer the following question: Given the samples of a generative model $\mathcal{G}$ and a reference dataset $\mathcal{S}$, how can we discover and count the modes expressed by $\mathcal{G}$ more frequently than in $\mathcal{S}$. We introduce a spectral approach to the described task and propose the Kernel-based Entropic Novelty (KEN) score to quantify the mode-based novelty 
    
[^12]: 神经网络与摩擦：滑动、保持、学习

    Neural Networks and Friction: Slide, Hold, Learn

    [https://arxiv.org/abs/2402.14148](https://arxiv.org/abs/2402.14148)

    循环神经网络利用GRU架构学习合成数据中复杂摩擦定律动力学，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。

    

    本研究表明，利用门控循环单元（GRU）架构的循环神经网络（RNNs）具有学习合成数据中速率与状态摩擦定律复杂动力学的能力。用于训练网络的数据通过应用传统速率与状态摩擦方程结合状态演化老化定律生成。我们方法的一个新颖之处在于制定一个损失函数，该函数明确考虑训练过程中的初始条件、直接效应以及状态变量的演变。研究发现，具有GRU架构的RNN能够有效学习预测摩擦系数由于速度跳跃而产生的变化，展示了机器学习模型在理解和模拟摩擦过程物理的潜力。

    arXiv:2402.14148v1 Announce Type: cross  Abstract: In this study, it is demonstrated that Recurrent Neural Networks (RNNs), specifically those utilizing Gated Recurrent Unit (GRU) architecture, possess the capability to learn the complex dynamics of rate-and-state friction laws from synthetic data. The data employed for training the network is generated through the application of traditional rate-and-state friction equations coupled with the aging law for state evolution. A novel aspect of our approach is the formulation of a loss function that explicitly accounts for initial conditions, the direct effect, and the evolution of state variables during training. It is found that the RNN, with its GRU architecture, effectively learns to predict changes in the friction coefficient resulting from velocity jumps, thereby showcasing the potential of machine learning models in understanding and simulating the physics of frictional processes.
    
[^13]: 利用部分掩码融合的Gromov-Wasserstein匹配进行任意大小图的端对端监督预测

    End-to-end Supervised Prediction of Arbitrary-size Graphs with Partially-Masked Fused Gromov-Wasserstein Matching

    [https://arxiv.org/abs/2402.12269](https://arxiv.org/abs/2402.12269)

    提出了利用部分掩码融合的Gromov-Wasserstein匹配进行任意大小图的端对端监督预测方法，并展示了其在不同任务上相比竞争者更高的效率和多功能性。

    

    我们提出了一种新颖的基于端到端深度学习的监督图预测（SGP）方法。我们引入了一种原始的基于最优输运（OT）的损失，部分掩码融合的Gromov-Wasserstein损失（PM-FGW），可以直接利用图表示，比如邻接和特征矩阵。PM-FGW具有SGP的所有理想属性：节点排列不变性，可微分性，通过比较它们的填充表示以及它们的掩码向量处理不同大小的图。此外，我们提出了一个灵活的基于transformer的架构，可以轻松适应不同类型的输入数据。在实验部分，三个不同的任务，一个新颖且具有挑战性的合成数据集（image2graph）和两个真实任务，图像到地图和指纹到分子 - 展示了该方法相比竞争者的效率和多功能性。

    arXiv:2402.12269v1 Announce Type: new  Abstract: We present a novel end-to-end deep learning-based approach for Supervised Graph Prediction (SGP). We introduce an original Optimal Transport (OT)-based loss, the Partially-Masked Fused Gromov-Wasserstein loss (PM-FGW), that allows to directly leverage graph representations such as adjacency and feature matrices. PM-FGW exhibits all the desirable properties for SGP: it is node permutation invariant, sub-differentiable and handles graphs of different sizes by comparing their padded representations as well as their masking vectors. Moreover, we present a flexible transformer-based architecture that easily adapts to different types of input data. In the experimental section, three different tasks, a novel and challenging synthetic dataset (image2graph) and two real-world tasks, image2map and fingerprint2molecule - showcase the efficiency and versatility of the approach compared to competitors.
    
[^14]: 通过差分动态逻辑确保神经网络控制器的安全性

    Provably Safe Neural Network Controllers via Differential Dynamic Logic

    [https://arxiv.org/abs/2402.10998](https://arxiv.org/abs/2402.10998)

    通过差分动态逻辑与神经网络验证相结合的VerSAILLE方法，实现了对神经网络控制系统在无限时间范围上的安全性证明。

    

    虽然神经网络（NN）作为面向目标的控制器在网络物理系统中具有巨大潜力，但验证基于神经网络的控制系统（NNCS）的安全性对于实际应用NN来说面临着重大挑战，特别是当需要对无界时间范围进行安全性验证时。我们引入了VerSAILLE（通过逻辑链接包验证的可验证安全人工智能）：这是差分动态逻辑（dL）和NN验证组合的第一种方法。通过合作，我们可以利用NN验证工具的效率，同时保留dL的严谨性。我们提出了一个控制器信封的安全性证明，以证明无限时间范围上具体NNCS的安全性。VerSAILLE导致的NN验证属性通常需要非线性算术，而高效的NN验证工具仅支持线性算术。

    arXiv:2402.10998v1 Announce Type: cross  Abstract: While neural networks (NNs) have a large potential as goal-oriented controllers for Cyber-Physical Systems, verifying the safety of neural network based control systems (NNCSs) poses significant challenges for the practical use of NNs -- especially when safety is needed for unbounded time horizons. One reason for this is the intractability of NN and hybrid system analysis. We introduce VerSAILLE (Verifiably Safe AI via Logically Linked Envelopes): The first approach for the combination of differential dynamic logic (dL) and NN verification. By joining forces, we can exploit the efficiency of NN verification tools while retaining the rigor of dL. We reflect a safety proof for a controller envelope in an NN to prove the safety of concrete NNCS on an infinite-time horizon. The NN verification properties resulting from VerSAILLE typically require nonlinear arithmetic while efficient NN verification tools merely support linear arithmetic. T
    
[^15]: HyperAgent：一种简单、可扩展、高效且可证明用于复杂环境的强化学习框架

    HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments

    [https://arxiv.org/abs/2402.10228](https://arxiv.org/abs/2402.10228)

    HyperAgent提出了一种简单、高效、可扩展的强化学习框架，在复杂环境下能够实现高效的计算和数据选择，是首个达到可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    

    为了在资源约束下解决复杂任务，强化学习（RL）代理需要简单、高效、可扩展、具有大状态空间和不断积累的交互数据。我们提出了HyperAgent，这是一个具有超模型、索引抽样方案和增量更新机制的RL框架，可以在一般价值函数逼近中进行计算高效的顺序后验逼近和数据高效的动作选择，超越了共轭性。HyperAgent的实现简单，只需要在DDQN中添加一个模块和一行额外代码。在实践中，HyperAgent在大规模深度RL基准测试中表现出稳健的性能，无论是在数据还是计算方面都获得了显着的效率提升。在理论上，在实际可扩展的算法中，HyperAgent是第一个能够实现可证明可扩展的每步计算复杂度以及次线性后悔的方法。

    arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
    
[^16]: 用分布值解释概率模型

    Explaining Probabilistic Models with Distributional Values

    [https://arxiv.org/abs/2402.09947](https://arxiv.org/abs/2402.09947)

    本文介绍了一种用于解释概率模型的方法，通过引入分布值来解决当前方法在解释模型输出时的不匹配问题，并通过案例研究展示了该方法提供的详细和有洞察力的解释。

    

    一个重要的可解释机器学习分支基于合作博弈理论。然而，研究表明博弈理论解释可能会误导或难以解释。我们认为通常存在着一个重要的不匹配，即人们希望解释的内容（例如分类器的输出）与当前的方法（例如SHAP）所解释的内容（例如类别的概率）之间。本文通过推广合作博弈和价值算子，来解决概率模型的这种差距。我们引入了分布值，这是一种随机变量，用于追踪模型输出的变化（例如预测类别的反转），并推导出了在具有高斯、伯努利和分类支付的博弈中的分布值的解析表达式。我们进一步建立了几个特性，并通过对视觉和语言模型的案例研究展示了我们的框架提供了细粒度和有洞察力的解释。

    arXiv:2402.09947v1 Announce Type: new  Abstract: A large branch of explainable machine learning is grounded in cooperative game theory. However, research indicates that game-theoretic explanations may mislead or be hard to interpret. We argue that often there is a critical mismatch between what one wishes to explain (e.g. the output of a classifier) and what current methods such as SHAP explain (e.g. the scalar probability of a class). This paper addresses such gap for probabilistic models by generalising cooperative games and value operators. We introduce the distributional values, random variables that track changes in the model output (e.g. flipping of the predicted class) and derive their analytic expressions for games with Gaussian, Bernoulli and Categorical payoffs. We further establish several characterising properties, and show that our framework provides fine-grained and insightful explanations with case studies on vision and language models.
    
[^17]: 选择高质量数据用于训练语言模型的QuRating方法

    QuRating: Selecting High-Quality Data for Training Language Models

    [https://arxiv.org/abs/2402.09739](https://arxiv.org/abs/2402.09739)

    QuRating是一种选择高质量数据用于训练语言模型的方法，它能够捕捉人类直观感知的文本的抽象特征。在实验中发现，平衡质量和多样性是很重要的。

    

    选择高质量的预训练数据对于创建能力强的语言模型很重要，但现有方法依赖简单的启发式方法。我们介绍了一种名为QuRating的方法，用于选择能够捕捉人类直观感知的文本的抽象特征的预训练文本数据。在本文中，我们研究了四个特征 - 写作风格、所需专业知识、事实和琐事以及教育价值。我们发现，语言模型能够辨别这些特征，并观察到它们在进行文本的配对判断方面比直接评估文本质量更好。我们训练了一个QuRater模型，从配对判断中学习标量评分，并使用它为260B的训练语料库中的每个标准进行质量评级注释。在实验中，我们根据不同的质量评级选择了30B个令牌，并在所选数据上训练了13亿参数的语言模型。我们发现在质量和多样性之间保持平衡是很重要的。

    arXiv:2402.09739v1 Announce Type: new  Abstract: Selecting high-quality pre-training data is important for creating capable language models, but existing methods rely on simple heuristics. We introduce QuRating, a method for selecting pre-training data that captures the abstract qualities of texts which humans intuitively perceive. In this paper, we investigate four qualities - writing style, required expertise, facts & trivia, and educational value. We find that LLMs are able to discern these qualities and observe that they are better at making pairwise judgments of texts than at rating the quality of a text directly. We train a QuRater model to learn scalar ratings from pairwise judgments, and use it to annotate a 260B training corpus with quality ratings for each of the four criteria. In our experiments, we select 30B tokens according to the different quality ratings and train 1.3B-parameter language models on the selected data. We find that it is important to balance quality and di
    
[^18]: 蝴蝶引起的变化：利用群体储备转换器进行远见预测

    Changes by Butterflies: Farsighted Forecasting with Group Reservoir Transformer

    [https://arxiv.org/abs/2402.09573](https://arxiv.org/abs/2402.09573)

    我们提出了一种群体储备转换器的架构，通过解决历史序列的挑战和初始条件的敏感性，实现更准确、更稳健地预测长期事件。在多元时间序列中，我们的模型相比最先进的DNN模型表现出更高的准确率，最高可减少89.43%的误差。

    

    在混沌中，两个初始条件之间的微小差异会随着时间的推移呈指数级放大，导致遥远的结果，也被称为蝴蝶效应。因此，远期充满了不确定性，难以预测。我们引入了群体储备转换器来通过克服混沌中的两个挑战（1）大量的历史序列和（2）对初始条件的敏感性来更准确、更稳健地预测长期事件。将一个储备装置连接到转换器上以高效地处理任意长度的历史数据，并通过扩展一组储备装置来减少由于初始化变化而产生的不确定性。我们的架构在多元时间序列中始终优于最先进的DNN模型，包括NLinear、Pyformer、Informer、Autoformer和基准Transformer，其误差减少高达-89.43％，适用于ETTh、ETTm和空气质量等各个领域。

    arXiv:2402.09573v1 Announce Type: cross  Abstract: In Chaos, a minor divergence between two initial conditions exhibits exponential amplification over time, leading to far-away outcomes, known as the butterfly effect. Thus, the distant future is full of uncertainty and hard to forecast. We introduce Group Reservoir Transformer to predict long-term events more accurately and robustly by overcoming two challenges in Chaos: (1) the extensive historical sequences and (2) the sensitivity to initial conditions. A reservoir is attached to a Transformer to efficiently handle arbitrarily long historical lengths, with an extension of a group of reservoirs to reduce the uncertainty due to the initialization variations. Our architecture consistently outperforms state-of-the-art DNN models in multivariate time series, including NLinear, Pyformer, Informer, Autoformer, and the baseline Transformer, with an error reduction of up to -89.43\% in various fields such as ETTh, ETTm, and air quality, demon
    
[^19]: 一项关于校准视觉-语言模型的实证研究

    An Empirical Study Into What Matters for Calibrating Vision-Language Models

    [https://arxiv.org/abs/2402.07417](https://arxiv.org/abs/2402.07417)

    本研究通过实证研究探索了视觉-语言模型(VLMs)的校准性质，并发现温度缩放可以显著提升校准性能，而且VLMs只需少量示例即可进行校准。

    

    视觉-语言模型（VLMs）已成为零样本识别的主要方法，在处理多样化场景和重要分布变化方面表现出色。然而，将它们应用于风险敏感领域需要对其不确定性估计能力有更深入的了解，这是一个相对未知的领域。在这项研究中，我们探讨了不同架构、数据集和训练策略下VLMs的校准性质。特别是，当在一个领域、标签集或层次级别中进行校准时，我们分析了VLMs在不同领域中的不确定性估计性能。我们的发现表明，虽然VLMs本身并不具备校准不确定性的能力，但温度缩放可以显著且一致地提升校准性能，即使在分布转变和标签集变化的情况下也是如此。此外，VLMs可以通过很少的示例进行校准。通过详细的实验，我们突显了我们的研究的潜在应用和重要性。

    Vision--Language Models (VLMs) have emerged as the dominant approach for zero-shot recognition, adept at handling diverse scenarios and significant distribution changes. However, their deployment in risk-sensitive areas requires a deeper understanding of their uncertainty estimation capabilities, a relatively uncharted area. In this study, we explore the calibration properties of VLMs across different architectures, datasets, and training strategies. In particular, we analyze the uncertainty estimation performance of VLMs when calibrated in one domain, label set or hierarchy level, and tested in a different one. Our findings reveal that while VLMs are not inherently calibrated for uncertainty, temperature scaling significantly and consistently improves calibration, even across shifts in distribution and changes in label set. Moreover, VLMs can be calibrated with a very small set of examples. Through detailed experimentation, we highlight the potential applications and importance of our
    
[^20]: 视觉语言模型的开放词汇校准

    Open-Vocabulary Calibration for Vision-Language Models

    [https://arxiv.org/abs/2402.04655](https://arxiv.org/abs/2402.04655)

    本文研究了视觉语言模型中的开放词汇校准问题，在提示学习的背景下发现现有的校准方法不足以解决该问题。为此，提出了一种称为 Distance-Aware Ca 的简单而有效的方法来解决问题。

    

    视觉语言模型 (VLM) 已经成为强大的工具，在处理图像识别、文本驱动的视觉内容生成、视觉聊天机器人等各种开放词汇任务上展现出了强大的能力。近年来，人们在提高 VLM 下游性能的适应方法上投入了大量的努力和资源，尤其是在参数高效的微调方法（如提示学习）上。然而，一个被大大忽视的关键问题是在微调的 VLM 中的置信度校准问题，在实际部署这样的模型时会大大降低可靠性。本文通过系统地研究提示学习背景下的置信度校准问题，发现现有的校准方法不能解决这个问题，尤其是在开放词汇的设置中。为了解决这个问题，我们提出了一种简单而有效的方法，称为 "Distance-Aware Ca"

    Vision-language models (VLMs) have emerged as formidable tools, showing their strong capability in handling various open-vocabulary tasks in image recognition, text-driven visual content generation, and visual chatbots, to name a few. In recent years, considerable efforts and resources have been devoted to adaptation methods for improving downstream performance of VLMs, particularly on parameter-efficient fine-tuning methods like prompt learning. However, a crucial aspect that has been largely overlooked is the confidence calibration problem in fine-tuned VLMs, which could greatly reduce reliability when deploying such models in the real world. This paper bridges the gap by systematically investigating the confidence calibration problem in the context of prompt learning and reveals that existing calibration methods are insufficient to address the problem, especially in the open-vocabulary setting. To solve the problem, we present a simple and effective approach called Distance-Aware Ca
    
[^21]: 避免延迟节点的分散式学习中的梯度编码

    Gradient Coding in Decentralized Learning for Evading Stragglers

    [https://arxiv.org/abs/2402.04193](https://arxiv.org/abs/2402.04193)

    本文提出了一种新的基于八卦的梯度编码分散式学习方法（GOCO），以解决存在延迟节点的分散式学习问题。与基准方法相比，该方法在学习性能上具有优越性。

    

    本文考虑了存在延迟节点的分散式学习问题。尽管梯度编码技术已经被开发用于分布式学习以避免延迟节点，即设备使用冗余训练数据发送编码梯度，但是将这些技术直接应用于分散式学习场景是困难的。为了解决这个问题，我们提出了一种新的基于八卦的梯度编码分散式学习方法（GOCO）。在这种方法中，为了避免延迟节点的负面影响，参数向量使用基于随机梯度编码框架的编码梯度进行本地更新，然后以八卦方式进行平均。我们分析了GOCO在强凸损失函数下的收敛性能，并通过仿真结果证明了该方法在学习性能上相对于基准方法的优越性。

    In this paper, we consider a decentralized learning problem in the presence of stragglers. Although gradient coding techniques have been developed for distributed learning to evade stragglers, where the devices send encoded gradients with redundant training data, it is difficult to apply those techniques directly to decentralized learning scenarios. To deal with this problem, we propose a new gossip-based decentralized learning method with gradient coding (GOCO). In the proposed method, to avoid the negative impact of stragglers, the parameter vectors are updated locally using encoded gradients based on the framework of stochastic gradient coding and then averaged in a gossip-based manner. We analyze the convergence performance of GOCO for strongly convex loss functions. And we also provide simulation results to demonstrate the superiority of the proposed method in terms of learning performance compared with the baseline methods.
    
[^22]: 私有推断的线性化对群体准确性的不对称影响

    Disparate Impact on Group Accuracy of Linearization for Private Inference

    [https://arxiv.org/abs/2402.03629](https://arxiv.org/abs/2402.03629)

    本文研究了线性化对隐私推断中群体准确性的影响，发现减少ReLU激活函数数量会不成比例地降低少数群体的准确性，而对于多数群体则几乎没有影响。采用简单的微调步骤可以解决这个问题。

    

    确保对具有密码安全性的数据进行隐私保护的推断是一个众所周知的计算挑战。为了减轻非线性激活函数中昂贵的加密计算的瓶颈，最近的方法建议在线性神经网络中线性化目标部分的激活函数。这种技术可以显著减少运行时间，对准确性的影响往往可以忽略不计。在本文中，我们证明了这种计算优势可能导致公平性成本增加。具体而言，我们发现减少ReLU激活函数数量会不成比例地降低少数群体的准确性，而对于多数群体则几乎没有影响。为了解释这些观察结果，我们在对决策边界性质进行限制性假设的基础上提供了数学解释，同时还展示了这个问题在广泛使用的数据集和体系结构中的普遍性。最后，我们展示了如何通过简单的程序改变线性模型的微调步骤来解决这个问题。

    Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models ca
    
[^23]: ICED: 通过上下文环境设计实现强化学习的零样本迁移

    ICED: Zero-Shot Transfer in Reinforcement Learning via In-Context Environment Design

    [https://arxiv.org/abs/2402.03479](https://arxiv.org/abs/2402.03479)

    本研究探索了深度强化学习代理的零样本迁移能力，并发现通过根据值损失优先选择级别，可以改善代理的推广能力。此外，无监督环境设计方法对改善代理表现也具有重要作用。

    

    使用深度强化学习训练的自主代理通常缺乏成功地推广到新环境的能力，即使这些环境与它们在训练过程中遇到的环境具有相似的特征。本研究探讨了个体环境实例（或级别）的采样对强化学习代理的零样本推广能力的影响。我们发现，对于共享基本层的深度演员-评论家架构，根据其值损失优先选择级别，可以最小化代理的内部表示与生成的训练数据中的训练级别之间的互信息。这为某些自适应采样策略实现的隐式正则化提供了新颖的理论解释。然后，我们将注意力转向无监督环境设计（UED）方法，这些方法对数据生成机制具有更多控制。我们发现现有的UED方法可以显著改变训练数据中的环境实例，从而影响代理的表现能力。

    Autonomous agents trained using deep reinforcement learning (RL) often lack the ability to successfully generalise to new environments, even when they share characteristics with the environments they have encountered during training. In this work, we investigate how the sampling of individual environment instances, or levels, affects the zero-shot generalisation (ZSG) ability of RL agents. We discover that, for deep actor-critic architectures sharing their base layers, prioritising levels according to their value loss minimises the mutual information between the agent's internal representation and the set of training levels in the generated training data. This provides a novel theoretical justification for the implicit regularisation achieved by certain adaptive sampling strategies. We then turn our attention to unsupervised environment design (UED) methods, which have more control over the data generation mechanism. We find that existing UED methods can significantly shift the trainin
    
[^24]: 图机器学习基础的未来方向

    Future Directions in Foundations of Graph Machine Learning

    [https://arxiv.org/abs/2402.02287](https://arxiv.org/abs/2402.02287)

    图机器学习领域的未来方向应该是发展一个更加均衡的理论，从更完整的角度探究图神经网络的表达能力、泛化和优化之间的相互关系。

    

    随着图数据在不同学科（从生命科学到社会科学和工程科学）上的广泛应用，图机器学习，尤其是使用图神经网络（GNNs），引起了人们浓厚的兴趣。尽管在实际应用中取得了成功，但我们对GNNs性质的理论理解仍然非常不完整。最近的理论发展主要集中在阐明GNNs粗粒度表达能力方面，主要采用组合技巧。然而，这些研究与实践并不完全一致，特别是在使用随机一阶优化技术训练GNNs时，对GNNs的泛化行为的理解。在这篇定位论文中，我们认为图机器学习领域需要将注意力转移到发展一个更加均衡的图机器学习理论上来，重点关注表达能力、泛化和优化的相互关系的更全面的理解。

    Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization.
    
[^25]: 生成式人工智能生成测试数据生成器

    Generative AI to Generate Test Data Generators

    [https://arxiv.org/abs/2401.17626](https://arxiv.org/abs/2401.17626)

    本研究评估了生成式人工智能在不同领域生成测试数据的能力，并证明它能够在不同的集成级别上生成逼真的测试数据生成器。

    

    生成假数据是现代软件测试的重要维度之一，众多数据伪造库的数量和重要性证明了这一点。然而，伪造库的开发者无法满足不同自然语言和领域所需生成的广泛数据范围。本文评估了生成式人工智能在不同领域生成测试数据的能力。我们设计了三种类型的大型语言模型（LLMs）提示，它们在不同的集成级别上执行测试数据生成任务：1）原始测试数据生成，2）合成特定语言的程序以生成有用的测试数据，3）生成使用尖端伪造库的程序。我们通过提示LLMs为11个领域生成测试数据来评估我们的方法。结果表明，在所有三个集成级别上，LLMs能够成功地生成逼真的测试数据生成器。

    Generating fake data is an essential dimension of modern software testing, as demonstrated by the number and significance of data faking libraries. Yet, developers of faking libraries cannot keep up with the wide range of data to be generated for different natural languages and domains. In this paper, we assess the ability of generative AI for generating test data in different domains. We design three types of prompts for Large Language Models (LLMs), which perform test data generation tasks at different levels of integrability: 1) raw test data generation, 2) synthesizing programs in a specific language that generate useful test data, and 3) producing programs that use state-of-the-art faker libraries. We evaluate our approach by prompting LLMs to generate test data for 11 domains. The results show that LLMs can successfully generate realistic test data generators in a wide range of domains at all three levels of integrability.
    
[^26]: 变化的行动空间中的情境式强化学习

    In-Context Reinforcement Learning for Variable Action Spaces

    [https://arxiv.org/abs/2312.13327](https://arxiv.org/abs/2312.13327)

    本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。

    

    最近的研究表明，预先在多样数据集上进行上下文多情节训练的变形金刚网络可以在情境中泛化到新的强化学习任务。先前提出的模型的一个关键限制是它们依赖于预定义的行动空间大小和结构。引入新的行动空间通常需要数据重新收集和模型重新训练，这对于一些应用来说可能是昂贵的。我们的工作表明，通过提出一种只训练一次的Headless-AD模型，可以缓解这个问题，该模型能够泛化到具有可变大小、语义内容和顺序的离散动作空间。通过在伯努利和上下文赌博机以及一个网格世界环境中进行实验，我们展示了Headless-AD在从未遇到的行动空间上表现出显著的泛化能力，甚至在几个环境配置上胜过专门针对特定行动集训练的模型。

    Recently, it has been shown that transformers pre-trained on diverse datasets with multi-episode contexts can generalize to new reinforcement learning tasks in-context. A key limitation of previously proposed models is their reliance on a predefined action space size and structure. The introduction of a new action space often requires data re-collection and model re-training, which can be costly for some applications. In our work, we show that it is possible to mitigate this issue by proposing the Headless-AD model that, despite being trained only once, is capable of generalizing to discrete action spaces of variable size, semantic content and order. By experimenting with Bernoulli and contextual bandits, as well as a gridworld environment, we show that Headless-AD exhibits significant capability to generalize to action spaces it has never encountered, even outperforming specialized models trained for a specific set of actions on several environment configurations.
    
[^27]: 乳腺癌切片中良性上皮细胞、原位病变和浸润性上皮细胞的免疫组织化学引导分割

    Immunohistochemistry guided segmentation of benign epithelial cells, in situ lesions, and invasive epithelial cells in breast cancer slides

    [https://arxiv.org/abs/2311.13261](https://arxiv.org/abs/2311.13261)

    该研究旨在开发一个用于乳腺癌切片中上皮细胞分割的AI模型，通过免疫组织化学引导分割出良性上皮细胞、原位病变和浸润性上皮细胞。

    

    数字病理学使得可以利用人工智能自动分析组织病理切片。自动评估可以提高诊断效率，并帮助找到形态特征与临床结果之间的关联。为了开发这样的预测模型，辨认浸润性上皮细胞，并将其与良性上皮细胞和原位病变分开将是第一步。在本研究中，我们旨在开发一个用于乳腺癌切片中上皮细胞分割的AI模型。我们通过重新染色血红蛋白和嗜酸性染色细胞角蛋白(CK) AE1/AE3 HE切片，以及病理学家的注释生成了上皮基本真值掩模。HE/CK图像对被用于训练卷积神经网络，数据增强被用来使模型更稳健。839名患者的组织微阵列（TMAs）和两名患者的整张切片图像用于训练

    arXiv:2311.13261v2 Announce Type: replace-cross  Abstract: Digital pathology enables automatic analysis of histopathological sections using artificial intelligence (AI). Automatic evaluation could improve diagnostic efficiency and help find associations between morphological features and clinical outcome. For development of such prediction models, identifying invasive epithelial cells, and separating these from benign epithelial cells and in situ lesions would be the first step. In this study, we aimed to develop an AI model for segmentation of epithelial cells in sections from breast cancer. We generated epithelial ground truth masks by restaining hematoxylin and eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists' annotations. HE/CK image pairs were used to train a convolutional neural network, and data augmentation was used to make the model more robust. Tissue microarrays (TMAs) from 839 patients, and whole slide images from two patients were used for training an
    
[^28]: 作者归属模型能否区分演讲文本中的发言人？

    Can Authorship Attribution Models Distinguish Speakers in Speech Transcripts?

    [https://arxiv.org/abs/2311.07564](https://arxiv.org/abs/2311.07564)

    本文研究了作者归属模型在演讲文本中区分发言人的能力，并提出了以会话演讲文本为重点的发言人归属基准。

    

    作者归属验证是确定两个不同书面样本是否同属一作者的任务，通常涉及对书面文本的归因。本文探讨了转录演讲的归属问题，这带来了新的挑战。其中一个主要挑战是，许多文体特征，如标点和大写，在这种情境下并不具备信息量。另一方面，转录的演讲呈现其他模式，如填充词和回应性声音（例如“嗯”，“嗯，嗯”），这些可能是不同发言人的特征性表现。我们提出了一个新的以会话演讲文本为重点的发言人归属基准。为了限制发言人与话题之间的虚假关联，我们使用会话提示和参与同一对话的发言人构建不同难度的验证试验。通过比较一系列方法，在这一新基准上建立了最新技术水平。

    arXiv:2311.07564v2 Announce Type: replace  Abstract: Authorship verification is the task of determining if two distinct writing samples share the same author and is typically concerned with the attribution of written text. In this paper, we explore the attribution of transcribed speech, which poses novel challenges. The main challenge is that many stylistic features, such as punctuation and capitalization, are not informative in this setting. On the other hand, transcribed speech exhibits other patterns, such as filler words and backchannels (e.g., 'um', 'uh-huh'), which may be characteristic of different speakers. We propose a new benchmark for speaker attribution focused on conversational speech transcripts. To limit spurious associations of speakers with topic, we employ both conversation prompts and speakers participating in the same conversation to construct verification trials of varying difficulties. We establish the state of the art on this new benchmark by comparing a suite of
    
[^29]: 通过二阶透镜看Adam

    Adam through a Second-Order Lens. (arXiv:2310.14963v1 [cs.LG])

    [http://arxiv.org/abs/2310.14963](http://arxiv.org/abs/2310.14963)

    该论文提出了AdamQLR，它是一个通过将K-FAC中的技术与Adam的更新方法相结合的优化器，通过考虑二阶数据上的Adam行为而得到启发。在回归和分类任务上进行了评估，结果显示AdamQLR在运行时间和推广性能方面表现出良好的竞争力。

    

    深度学习优化研究存在一种紧张状态，即第一阶梯度法（如SGD和Adam）的计算效率与第二阶曲率法（如拟牛顿方法和K-FAC）的理论效率之间的紧张关系。我们试图将这两种方法的优点结合到一个计算上高效的算法中。注意到二阶方法通常依赖于稳定的启发式方法（如Levenberg-Marquardt阻尼），我们提出AdamQLR：一个将K-FAC中的阻尼和学习率选择技术与Adam提出的更新方向相结合的优化器，通过考虑Adam在二阶数据上的表现而得到启发。我们在各种规模的回归和分类任务上评估了AdamQLR，在运行时间与竞争性推广性能之间取得了竞争性的结果。

    Research into optimisation for deep learning is characterised by a tension between the computational efficiency of first-order, gradient-based methods (such as SGD and Adam) and the theoretical efficiency of second-order, curvature-based methods (such as quasi-Newton methods and K-FAC). We seek to combine the benefits of both approaches into a single computationally-efficient algorithm. Noting that second-order methods often depend on stabilising heuristics (such as Levenberg-Marquardt damping), we propose AdamQLR: an optimiser combining damping and learning rate selection techniques from K-FAC (Martens and Grosse, 2015) with the update directions proposed by Adam, inspired by considering Adam through a second-order lens. We evaluate AdamQLR on a range of regression and classification tasks at various scales, achieving competitive generalisation performance vs runtime.
    
[^30]: SemantIC: 语义干扰消除在6G无线通信中的应用

    SemantIC: Semantic Interference Cancellation Towards 6G Wireless Communications. (arXiv:2310.12768v1 [eess.SP])

    [http://arxiv.org/abs/2310.12768](http://arxiv.org/abs/2310.12768)

    本文提出了一种新颖的技术，语义干扰消除（SemantIC），用于提高6G无线通信网络的信息质量。通过在接收器上使用语义自动编码器，SemantIC能够迭代消除信号中的噪声和语义干扰。仿真结果表明，SemantIC能够在不增加额外信道资源成本的情况下改进性能。

    

    本文提出了一种新颖的抗干扰技术，即语义干扰消除（SemantIC），用于提高第六代（6G）无线网络中的信息质量。SemantIC只需要接收器将信道解码器与语义自动编码器连接起来。这构建了一个迭代循环，交替消除信号域和语义域中的噪声。从网络信息论的角度来看，语义自动编码器的神经网络通过训练存储了辅助信息，并在迭代解码中提供辅助信息，作为Wyner-Ziv定理的一种实现。仿真结果验证了SemantIC在不增加额外信道资源成本的情况下改进了性能。

    This letter proposes a novel anti-interference technique, semantic interference cancellation (SemantIC), for enhancing information quality towards the sixth-generation (6G) wireless networks. SemantIC only requires the receiver to concatenate the channel decoder with a semantic auto-encoder. This constructs a turbo loop which iteratively and alternately eliminates noise in the signal domain and the semantic domain. From the viewpoint of network information theory, the neural network of the semantic auto-encoder stores side information by training, and provides side information in iterative decoding, as an implementation of the Wyner-Ziv theorem. Simulation results verify the performance improvement by SemantIC without extra channel resource cost.
    
[^31]: SmoothLLM：防御大型语言模型免受越狱攻击

    SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])

    [http://arxiv.org/abs/2310.03684](http://arxiv.org/abs/2310.03684)

    SmoothLLM是第一个用于减轻大型语言模型上越狱攻击的算法，通过在输入提示上随机扰动并汇总预测结果来检测对抗性输入，将攻击成功率降低至不到一个百分点，并提供了可证明的保证。

    

    尽管努力将大型语言模型（LLM）与人类价值观保持一致，但广泛使用的LLM（如GPT、Llama、Claude和PaLM）仍然容易受到越狱攻击，即对目标LLM进行欺骗，以生成不合适的内容。为了解决这个漏洞，我们提出了SmoothLLM，这是第一个旨在减轻LLM上的越狱攻击的算法。基于我们的发现，对抗性生成的提示对字符级别的改变很脆弱，我们的防御首先随机扰动给定输入提示的多个副本，然后汇总相应的预测结果来检测对抗性输入。SmoothLLM将众多热门LLM的攻击成功率降低至不到一个百分点，避免了不必要的保守性，并对攻击缓解提供了可证明的保证。此外，我们的防御使用的查询数量比现有的攻击方法少得多，并且与任何LLM兼容。

    Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
    
[^32]: 一个用于混合迪里切特和诺曼边界条件的神经预处理泊松求解器

    A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions. (arXiv:2310.00177v1 [math.NA])

    [http://arxiv.org/abs/2310.00177](http://arxiv.org/abs/2310.00177)

    我们引入了一个用于混合边界条件的泊松方程的神经预处理迭代求解器，核心是一个神经网络，能够近似逆离散结构网格拉普拉斯算子，并且在训练集之外的边界条件下仍然有效。

    

    我们引入了一个神经预处理的迭代求解器，用于具有混合边界条件的泊松方程。泊松方程在科学计算中是普遍存在的：它控制着广泛的物理现象，在许多数值算法中作为子问题出现，并且作为更广泛的椭圆PDE类的模型问题。最流行的泊松离散化方法可以产生大型稀疏线性系统。在高分辨率和对性能至关重要的应用中，迭代求解器结合强大的预处理器可以提供优势。我们求解器的核心是一个神经网络，该网络经过训练可以近似离散结构网格拉普拉斯算子的逆算子，适用于任意形状的域和混合边界条件。我们展示了该问题的结构激发了一种新颖的网络架构，即使在训练集之外的边界条件下，该架构也表现出高效的预处理器。我们展示了在具有挑战性的测试案例上的效果。

    We introduce a neural-preconditioned iterative solver for Poisson equations with mixed boundary conditions. The Poisson equation is ubiquitous in scientific computing: it governs a wide array of physical phenomena, arises as a subproblem in many numerical algorithms, and serves as a model problem for the broader class of elliptic PDEs. The most popular Poisson discretizations yield large sparse linear systems. At high resolution, and for performance-critical applications, iterative solvers can be advantageous for these -- but only when paired with powerful preconditioners. The core of our solver is a neural network trained to approximate the inverse of a discrete structured-grid Laplace operator for a domain of arbitrary shape and with mixed boundary conditions. The structure of this problem motivates a novel network architecture that we demonstrate is highly effective as a preconditioner even for boundary conditions outside the training set. We show that on challenging test cases aris
    
[^33]: 使用多元时间序列转换器获取风险投资和成长资本的投资目标

    Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer. (arXiv:2309.16888v1 [cs.LG])

    [http://arxiv.org/abs/2309.16888](http://arxiv.org/abs/2309.16888)

    这个论文介绍了一种新颖的方法，利用Transformer-based Multivariate Time Series Classifier (TMTSC)来预测风险投资和成长资本的候选公司的成功可能性，以优化投资目标的选择。通过对相关的方法进行了全面回顾和实验验证，证明了该方法的有效性。

    

    本文探讨了数据驱动方法在私募股权（PE）行业中的应用，特别是在为风险投资（VC）和成长资本（GC）寻找投资目标（即公司）方面。我们对相关方法进行了全面的回顾，并提出了一种新颖的方法，利用基于Transformer的多元时间序列分类器（TMTSC）来预测任何候选公司的成功可能性。我们的研究目标是通过将寻找投资问题正式定义为多元时间序列分类任务，优化VC和GC投资的寻找效果。我们依次介绍了我们实现的关键组成部分，这些部分共同 contribut 到了在VC/GC寻找中成功应用TMTSC：输入特征、模型架构、优化目标以及基于投资者的数据增强和划分。我们在四个数据集上进行了大量实验，并将其与三个流行的基准线进行了对比。

    This paper addresses the growing application of data-driven approaches within the Private Equity (PE) industry, particularly in sourcing investment targets (i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present a comprehensive review of the relevant approaches and propose a novel approach leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for predicting the success likelihood of any candidate company. The objective of our research is to optimize sourcing performance for VC and GC investments by formally defining the sourcing problem as a multivariate time series classification task. We consecutively introduce the key components of our implementation which collectively contribute to the successful application of TMTSC in VC/GC sourcing: input features, model architecture, optimization target, and investor-centric data augmentation and split. Our extensive experiments on four datasets, benchmarked towards three popular baselines, demonstrat
    
[^34]: 走向TopMost：一个主题建模系统工具包

    Towards the TopMost: A Topic Modeling System Toolkit. (arXiv:2309.06908v1 [cs.CL])

    [http://arxiv.org/abs/2309.06908](http://arxiv.org/abs/2309.06908)

    本文提出了一个名为TopMost的主题建模系统工具包，通过涵盖更广泛的主题建模场景和具有高度凝聚力和解耦模块化设计的特点，可以促进主题模型的研究和应用。

    

    主题模型已经在过去几十年中被提出，并且具有各种应用，在神经变分推断的推动下近期得到了更新。然而，这些主题模型采用完全不同的数据集、实现和评估设置，这阻碍了它们的快速利用和公平比较。这严重阻碍了主题模型的研究进展。为了解决这些问题，本文提出了一个主题建模系统工具包（TopMost）。与现有的工具包相比，TopMost通过涵盖更广泛的主题建模场景，包括数据集预处理、模型训练、测试和评估的完整生命周期，脱颖而出。TopMost的高度凝聚力和解耦模块化设计可以快速利用，公平比较，并灵活扩展不同的主题模型，这可以促进主题模型的研究和应用。我们的代码、教程和文档可在https://github.com/bobxwu/topmost 上获得。

    Topic models have been proposed for decades with various applications and recently refreshed by the neural variational inference. However, these topic models adopt totally distinct dataset, implementation, and evaluation settings, which hinders their quick utilization and fair comparisons. This greatly hinders the research progress of topic models. To address these issues, in this paper we propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by covering a wider range of topic modeling scenarios including complete lifecycles with dataset pre-processing, model training, testing, and evaluations. The highly cohesive and decoupled modular design of TopMost enables quick utilization, fair comparisons, and flexible extensions of different topic models. This can facilitate the research and applications of topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.
    
[^35]: 通过精细的模态评估增强多模态协作

    Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation. (arXiv:2309.06255v1 [cs.CV])

    [http://arxiv.org/abs/2309.06255](http://arxiv.org/abs/2309.06255)

    本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。

    

    多模态学习的一个主要问题是如何将来自不同模态的异质信息共同结合起来。然而，大多数模型在多模态协作方面常常存在不尽人意的问题，不能很好地共同利用所有模态。一些方法被提出来识别和增强学习效果较差的模态，但往往难以在理论上提供对样本级别多模态协作的细粒度观察和支持。因此，合理观察和改进模态之间细粒度的协作尤为重要，尤其是在面对模态差异在不同样本之间可能变化的实际场景时。为了实现这一目标，我们引入了一种精细的模态评估指标，以评估每个模态在样本级别的贡献。通过模态评估，我们遗憾地发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。我们进一步分析了这个问题。

    One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this iss
    
[^36]: Maestro: 通过可训练分解揭示低秩结构

    Maestro: Uncovering Low-Rank Structures via Trainable Decomposition. (arXiv:2308.14929v1 [cs.LG])

    [http://arxiv.org/abs/2308.14929](http://arxiv.org/abs/2308.14929)

    本研究提出了一种通过可训练分解揭示低秩结构的方法，解决了深度神经网络训练大模型时的耗时和资源消耗的问题。

    

    深度神经网络(DNNs)近年来推动和促成了人工智能突破性进展。为了提高准确性并应对新兴的应用场景，包括AR/VR和智能助手，这些模型越来越大。然而，这些大模型的训练过程耗时费力，通常只能生成一个适应所有目标的模型。为了缓解这个问题，文献中提出了各种技术，包括模型权重和更新的剪枝、稀疏化或量化。虽然可以实现高压缩率，但往往会造成计算开销或准确性损失。另外，还通过因式分解方法将低秩压缩纳入训练过程中。然而，这些技术(例如SVD)常常依赖于计算昂贵的层次分解，对于非线性模型如DNNs可能不是最优解。在本研究中，我们采用了一种新的方法，通过可训练的分解揭示低秩结构。

    Deep Neural Networks (DNNs) have been a large driver and enabler for AI breakthroughs in recent years. These models have been getting larger in their attempt to become more accurate and tackle new upcoming use-cases, including AR/VR and intelligent assistants. However, the training process of such large models is a costly and time-consuming process, which typically yields a single model to fit all targets. To mitigate this, various techniques have been proposed in the literature, including pruning, sparsification or quantization of the model weights and updates. While able to achieve high compression rates, they often incur computational overheads or accuracy penalties. Alternatively, factorization methods have been leveraged to incorporate low-rank compression in the training process. Similarly, such techniques (e.g.,~SVD) frequently rely on the computationally expensive decomposition of layers and are potentially sub-optimal for non-linear models, such as DNNs. In this work, we take 
    
[^37]: 人脸图像的神经隐式形变

    Neural Implicit Morphing of Face Images. (arXiv:2308.13888v1 [cs.CV])

    [http://arxiv.org/abs/2308.13888](http://arxiv.org/abs/2308.13888)

    本论文提出了一种利用神经网络实现人脸图像变形和混合的方法，通过利用网络的平滑性和灵活性，结合经典方法中的能量函数，实现了高效、准确和多样化的人脸变形效果。

    

    人脸变形是计算机图形学中的一个重要问题，具有众多艺术和取证应用。由于姿态、光照、性别和种族的变化，它一直以来都是一个具有挑战性的问题。通常，这个任务包括特征对齐的变形和无缝过渡的混合。我们提出利用基于坐标的神经网络来表示人脸图像的这种变形和混合。在训练过程中，我们利用这种网络的平滑性和灵活性，结合了经典方法中使用的能量函数，而无需进行离散化。此外，我们的方法是时间依赖的，允许对目标图像进行连续的变形和混合。在变形推理过程中，我们需要时间依赖变形的直接和逆变换。前者负责将目标图像变形为源图像，而后者则用于在相反方向进行变形。我们的神经变形网络具有高效、准确和多样化的性能。

    Face morphing is one of the seminal problems in computer graphics, with numerous artistic and forensic applications. It is notoriously challenging due to pose, lighting, gender, and ethnicity variations. Generally, this task consists of a warping for feature alignment and a blending for a seamless transition between the warped images.  We propose to leverage coordinate-based neural networks to represent such warpings and blendings of face images. During training, we exploit the smoothness and flexibility of such networks, by combining energy functionals employed in classical approaches without discretizations. Additionally, our method is time-dependent, allowing a continuous warping, and blending of the target images.  During warping inference, we need both direct and inverse transformations of the time-dependent warping. The first is responsible for morphing the target image into the source image, while the inverse is used for morphing in the opposite direction. Our neural warping sto
    
[^38]: NeuralClothSim: 神经变形场与Kirchhoff-Love薄壳理论相遇

    NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory. (arXiv:2308.12970v1 [cs.GR])

    [http://arxiv.org/abs/2308.12970](http://arxiv.org/abs/2308.12970)

    本文提出了一种新的布料模拟方法 NeuralClothSim，使用薄壳理论和神经变形场进行表面演化，克服了现有布料模拟方法的局限性和挑战，为物理合理的布料模拟提供了一种全新的视角。

    

    布料模拟是一个广泛研究的问题，在计算机图形学文献中有大量的解决方案。现有的布料模拟器产生符合不同类型边界条件的逼真布料变形。然而，它们的操作原理在几个方面仍然存在局限性：它们在具有固定空间分辨率的显式表面表示上进行操作，执行一系列离散化的更新（限制了它们的时间分辨率），并且需要相对较大的存储空间。此外，通过现有的求解器进行梯度反向传播通常并不直观，这在将其集成到现代神经架构中时造成了额外的挑战。针对上述限制，本文从根本上以一种根本不同的视角来考虑物理合理的布料模拟，并重新思考这个长期存在的问题：我们提出了NeuralClothSim，即一种使用薄壳的新布料模拟方法，其中表面演化通过神经变形场等进行。

    Cloth simulation is an extensively studied problem, with a plethora of solutions available in computer graphics literature. Existing cloth simulators produce realistic cloth deformations that obey different types of boundary conditions. Nevertheless, their operational principle remains limited in several ways: They operate on explicit surface representations with a fixed spatial resolution, perform a series of discretised updates (which bounds their temporal resolution), and require comparably large amounts of storage. Moreover, back-propagating gradients through the existing solvers is often not straightforward, which poses additional challenges when integrating them into modern neural architectures. In response to the limitations mentioned above, this paper takes a fundamentally different perspective on physically-plausible cloth simulation and re-thinks this long-standing problem: We propose NeuralClothSim, i.e., a new cloth simulation approach using thin shells, in which surface ev
    
[^39]: 延迟补偿超bolic PIDE控制的神经算子

    Neural Operators for Delay-Compensating Control of Hyperbolic PIDEs. (arXiv:2307.11436v1 [math.OC])

    [http://arxiv.org/abs/2307.11436](http://arxiv.org/abs/2307.11436)

    该论文提出了延迟补偿超bolic PIDE控制的神经算子框架，扩展了基本PDE控制结果到一个涉及状态和系统延迟的高级超bolic类。使用DeepONet逼近算子，可以在无限维度上建立稳定的闭环反馈，并开发了逼近的观测者和输出反馈定律。

    

    最近引入的DeepONet算子学习框架从基本的超bolic和拟bolic PDE结果扩展到了一个高级超bolic类，其中包括状态和系统输出或输入的延迟。PDE反向设计产生的增益函数是非线性算子的输出，将空间域上的函数映射到空间域上的函数，其中该增益生成算子的输入是PDE的系数。使用DeepONet神经网络逼近该算子，可以证明其任意精度紧密。一旦在无限维度上产生了这个逼近理论结果，我们就可以在使用近似增益的反馈下建立封闭环的稳定性。除了提供全状态反馈下的这些结果外，我们还发展了DeepONet逼近的观测者和输出反馈定律，并证明了它们在神经算子逼近下的稳定性质。

    The recently introduced DeepONet operator-learning framework for PDE control is extended from the results for basic hyperbolic and parabolic PDEs to an advanced hyperbolic class that involves delays on both the state and the system output or input. The PDE backstepping design produces gain functions that are outputs of a nonlinear operator, mapping functions on a spatial domain into functions on a spatial domain, and where this gain-generating operator's inputs are the PDE's coefficients. The operator is approximated with a DeepONet neural network to a degree of accuracy that is provably arbitrarily tight. Once we produce this approximation-theoretic result in infinite dimension, with it we establish stability in closed loop under feedback that employs approximate gains. In addition to supplying such results under full-state feedback, we also develop DeepONet-approximated observers and output-feedback laws and prove their own stabilizing properties under neural operator approximations.
    
[^40]: 稀疏图线性动态系统

    Sparse Graphical Linear Dynamical Systems. (arXiv:2307.03210v1 [cs.LG])

    [http://arxiv.org/abs/2307.03210](http://arxiv.org/abs/2307.03210)

    该论文提出了一种稀疏图线性动态系统方法，用于处理时间序列数据集。该方法可以利用图形视角来学习模型参数，解决了现有方法的限制，并提供了概率性和可解释性的学习结果。

    

    时间序列数据集在科学和工程的众多领域中扮演重要角色，如生物医学、地球观测和网络分析。有关状态空间模型（SSMs）的广泛研究是一个强大的数学工具，它允许对时间序列进行概率性和可解释性的学习。在SSMs中估计模型参数被认为是最复杂的任务之一，先验知识的引入既可以简化解释也可以复杂化推断任务。最近的研究工作试图在一些模型参数中加入图形视角，但存在明显的限制，这项工作解决了这些限制。更一般地说，现有的图模型工具旨在包含静态信息或动态信息，其中静态信息侧重于独立随机变量之间的统计依赖（例如，图形Lasso方法），动态信息侧重于时间序列样本之间的因果关系。

    Time-series datasets are central in numerous fields of science and engineering, such as biomedicine, Earth observation, and network analysis. Extensive research exists on state-space models (SSMs), which are powerful mathematical tools that allow for probabilistic and interpretable learning on time series. Estimating the model parameters in SSMs is arguably one of the most complicated tasks, and the inclusion of prior knowledge is known to both ease the interpretation but also to complicate the inferential tasks. Very recent works have attempted to incorporate a graphical perspective on some of those model parameters, but they present notable limitations that this work addresses. More generally, existing graphical modeling tools are designed to incorporate either static information, focusing on statistical dependencies among independent random variables (e.g., graphical Lasso approach), or dynamic information, emphasizing causal relationships among time series samples (e.g., graphical 
    
[^41]: 无法解释的解释：解释tSNE和UMAP嵌入的方法

    Unexplainable Explanations: Towards Interpreting tSNE and UMAP Embeddings. (arXiv:2306.11898v1 [cs.LG])

    [http://arxiv.org/abs/2306.11898](http://arxiv.org/abs/2306.11898)

    本文研究旨在回答ARDR算法的收敛性问题，我们将ARDR方法与传统的降维技术联系起来，可以将PCA嵌入完全恢复，通过稍加修改可以用LLE复现ARDR嵌入，并形式化了一系列猜想，如果成立，可以将2D嵌入中的结构归因于输入分布。

    

    将神经网络的潜在空间解释为吸引/排斥降维（ARDR）方法（如tSNE和UMAP）已成为标准。这取决于2D表示中的结构与模型潜在空间中的结构一致的先决条件。然而，这是一个未经证明的假设，我们不知道ARDR算法是否有任何收敛保证。本文旨在通过将ARDR方法与传统的降维技术联系起来，来回答这个问题。具体来说，我们展示了可以通过在随机初始化的数据集上应用吸引和排斥来完全恢复PCA嵌入。我们还展示了如果稍加修改，局部线性嵌入（LLE）可以复现ARDR嵌入的方法。最后，我们系统化了一系列猜想，如果这些猜想成立，就可以将2D嵌入中的结构归因于输入分布。

    It has become standard to explain neural network latent spaces with attraction/repulsion dimensionality reduction (ARDR) methods like tSNE and UMAP. This relies on the premise that structure in the 2D representation is consistent with the structure in the model's latent space. However, this is an unproven assumption -- we are unaware of any convergence guarantees for ARDR algorithms. We work on closing this question by relating ARDR methods to classical dimensionality reduction techniques. Specifically, we show that one can fully recover a PCA embedding by applying attractions and repulsions onto a randomly initialized dataset. We also show that, with a small change, Locally Linear Embeddings (LLE) can reproduce ARDR embeddings. Finally, we formalize a series of conjectures that, if true, would allow one to attribute structure in the 2D embedding back to the input distribution.
    
[^42]: 动态不确定性下的大规模数据集修剪方法

    Large-scale Dataset Pruning with Dynamic Uncertainty. (arXiv:2306.05175v1 [cs.LG])

    [http://arxiv.org/abs/2306.05175](http://arxiv.org/abs/2306.05175)

    本文提出了一种探索预测不确定性和训练动态的简单且有效的大规模数据集修剪方法，以产生信息量丰富的子集用于训练深度模型，实验结果表明优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。

    

    在许多学习任务，例如图像分类中，收集更大的数据集并在其上训练更大的模型是推动技术前进的关键因素。由此产生的计算成本逐渐变得难以承受。本文研究了如何修剪大规模数据集，从而产生信息量丰富的子集，用于训练复杂的深度模型，且性能下降可以忽略不计。我们提出了一种简单但有效的数据集修剪方法，通过探索预测不确定性和训练动态来实现。据我们所知，这是第一篇在大规模数据集（ImageNet-1K和ImageNet-21K）和先进模型（Swin Transformer和ConvNeXt）上研究数据集修剪的工作。广泛的实验结果表明，我们的方法优于现有技术，在ImageNet-1K和ImageNet-21K上实现了75％的无损压缩比。代码和修剪后的数据集可在https://github.com/BAAI-DCAI/Dataset-Pruning上获得。

    The state of the art of many learning tasks, e.g., image classification, is advanced by collecting larger datasets and then training larger models on them. As the outcome, the increasing computational cost is becoming unaffordable. In this paper, we investigate how to prune the large-scale datasets, and thus produce an informative subset for training sophisticated deep models with negligible performance drop. We propose a simple yet effective dataset pruning method by exploring both the prediction uncertainty and training dynamics. To our knowledge, this is the first work to study dataset pruning on large-scale datasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin Transformer and ConvNeXt. Extensive experimental results indicate that our method outperforms the state of the art and achieves 75% lossless compression ratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are available at https://github.com/BAAI-DCAI/Dataset-Pruning.
    
[^43]: 初始猜测偏差：未经过训练的神经网络倾向于某些类别

    Initial Guessing Bias: How Untrained Networks Favor Some Classes. (arXiv:2306.00809v1 [cs.LG])

    [http://arxiv.org/abs/2306.00809](http://arxiv.org/abs/2306.00809)

    本文提出了“初始猜测偏差”现象，即在未经过训练的神经网络中，由于架构选择的影响，模型往往会将所有预测指向同一个类别。该现象对架构选择和初始化有实际指导意义，并具有理论后果，例如节点置换对称性的崩溃和深度带来的非平凡差异。

    

    神经网络的初始状态在调节后续的训练过程中扮演重要角色。在分类问题的背景下，我们提供了理论分析，证明神经网络的结构可以在训练之前，甚至在不存在显式偏差的情况下，使模型将所有预测都指向同一个类别。我们展示了这种现象的存在，称为“初始猜测偏差”（Initial Guessing Bias，IGB），这取决于架构选择，例如激活函数、最大池化层和网络深度。我们对IGB进行的分析具有实际意义，可以指导架构的选择和初始化。我们还强调理论后果，例如节点置换对称性的崩溃、自平均的破坏、某些均场近似的有效性以及深度带来的非平凡差异。

    The initial state of neural networks plays a central role in conditioning the subsequent training dynamics. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a neural network can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We show that the presence of this phenomenon, which we call "Initial Guessing Bias" (IGB), depends on architectural choices such as activation functions, max-pooling layers, and network depth. Our analysis of IGB has practical consequences, in that it guides architecture selection and initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging, the validity of some mean-field approximations, and the non-trivial differences arising with depth.
    
[^44]: 多样化深度集成：一种使用显著性图的方法以增强OOD检测、校准和准确性

    Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection, Calibration, and Accuracy. (arXiv:2305.11616v1 [cs.CV])

    [http://arxiv.org/abs/2305.11616](http://arxiv.org/abs/2305.11616)

    这项研究提出了一种使用显著性图来促进深度集成多样性的方法，用于改善OOD检测、校准和准确性，能够优于传统的集成技术，并在OpenOOD基准测试上证明了其有效性。

    

    深度集成在分类和 OOD 检测方面取得了最先进的成果；然而，由于集成中学习的模式的同质性，它们的效果仍然有限。为了克服这一挑战，本研究引入了一种促进集成成员之间多样性的新方法，该方法利用显著性图。通过整合显著性图多样化，我们的方法在多个分类和OOD检测任务中优于传统的集成技术，同时也提高了校准性。在已建立的OpenOOD基准测试上的实验凸显了我们的方法在实际应用中的潜力。

    Deep ensembles achieved state-of-the-art results in classification and out-of-distribution (OOD) detection; however, their effectiveness remains limited due to the homogeneity of learned patterns within the ensemble. To overcome this challenge, our study introduces a novel approach that promotes diversity among ensemble members by leveraging saliency maps. By incorporating saliency map diversification, our method outperforms conventional ensemble techniques in multiple classification and OOD detection tasks, while also improving calibration. Experiments on well-established OpenOOD benchmarks highlight the potential of our method in practical applications.
    
[^45]: SynthMorph实现的考虑解剖结构和无关采集方法的联合配准

    Anatomy-aware and acquisition-agnostic joint registration with SynthMorph. (arXiv:2301.11329v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.11329](http://arxiv.org/abs/2301.11329)

    SynthMorph是一个易于使用的DL工具，用于无需预处理即可直接从MRI扫描仪上对任何脑图像进行联合仿射-可变形配准，采用了从标签图生成具有极大差异图像的策略，实现了更准确和鲁棒的图像配准。

    

    仿射图像配准是医学图像分析的基石。虽然传统算法可以实现优秀的准确性，但它们需要为每一对图像进行耗时的优化。深度学习方法通过学习一个将图像对映射到输出变换的函数来解决这个问题。评估这个函数是快速的，但捕捉大的变换可能是具有挑战性的，而且如果测试图像的特征从训练领域变化，如分辨率，网络往往会出现困难。大多数仿射方法是对解剖结构无知的，意味着如果算法考虑图像中的所有结构，配准会不准确。我们通过SynthMorph解决了这些缺点，它是一个易于使用的DL工具，用于对任何脑图像进行联合仿射-可变形配准，无需预处理即可直接从MRI扫描仪进行操作。首先，我们利用从标签图生成的具有极大差异的图像来训练网络的策略，从而实现对训练过程中未见的多样化采集规范的鲁棒性能。其次，我们优化网络的损失函数，使其能够考虑不同的解剖特征和学习抵制采集特定限制的变换。通过这些创新，我们实现了更准确和鲁棒的图像配准。

    Affine image registration is a cornerstone of medical-image analysis. While classical algorithms can achieve excellent accuracy, they solve a time-consuming optimization for every image pair. Deep-learning (DL) methods learn a function that maps an image pair to an output transform. Evaluating the function is fast, but capturing large transforms can be challenging, and networks tend to struggle if a test-image characteristic shifts from the training domain, such as resolution. Most affine methods are agnostic to anatomy, meaning the registration will be inaccurate if algorithms consider all structures in the image.  We address these shortcomings with SynthMorph, an easy-to-use DL tool for joint affine-deformable registration of any brain image without preprocessing, right off the MRI scanner. First, we leverage a strategy to train networks with wildly varying images synthesized from label maps, yielding robust performance across acquisition specifics unseen at training. Second, we opti
    
[^46]: L2XGNN：学习解释图神经网络

    L2XGNN: Learning to Explain Graph Neural Networks. (arXiv:2209.14402v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14402](http://arxiv.org/abs/2209.14402)

    L2XGNN提出了一个框架来解释图神经网络，通过选择解释子图（模体）实现忠实的解释。该框架能够识别负责预测图属性的模体，并实现与基线方法相同的分类精度。

    

    图神经网络（GNNs）是一类流行的机器学习模型。在学习解释（L2X）范式的启发下，我们提出了L2XGNN，这是一个可解释的GNN框架，通过设计提供忠实的解释。L2XGNN学习一种机制，用于选择解释子图（模体），这些子图仅用于GNN的信息传递操作中。对模体施加这样的限制通常会导致更易解释和更有效的解释。在几种数据集上的实验表明，L2XGNN实现了与基线方法相同的分类精度，同时确保仅使用提供的解释来进行预测。此外，我们还表明L2XGNN能够识别负责预测图属性的模体。

    Graph Neural Networks (GNNs) are a popular class of machine learning models. Inspired by the learning to explain (L2X) paradigm, we propose L2XGNN, a framework for explainable GNNs which provides faithful explanations by design. L2XGNN learns a mechanism for selecting explanatory subgraphs (motifs) which are exclusively used in the GNNs message-passing operations. L2XGNN is able to select, for each input graph, a subgraph with specific properties such as being sparse and connected. Imposing such constraints on the motifs often leads to more interpretable and effective explanations. Experiments on several datasets suggest that L2XGNN achieves the same classification accuracy as baseline methods using the entire input graph while ensuring that only the provided explanations are used to make predictions. Moreover, we show that L2XGNN is able to identify motifs responsible for the graph's properties it is intended to predict.
    

