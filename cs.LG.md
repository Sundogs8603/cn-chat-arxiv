# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer.](http://arxiv.org/abs/2304.07874) | 本文提出了一种基于Vision Transformer的数据中心的解决方案，用于解决非均质去雾问题。传统方法在处理NH-HAZE23数据集等非均质雾图像时存在问题，因为它们无法满足建模均质雾所需的假设之一。同时，本文指出光靠数据增广并不能解决问题，因为需要处理分布差异。 |
| [^2] | [CEBoosting: Online Sparse Identification of Dynamical Systems with Regime Switching by Causation Entropy Boosting.](http://arxiv.org/abs/2304.07863) | 该论文提出一种因果熵增强(CEBoosting)策略，能够通过在线模型识别来检测制度转换和发现新制度相关动力学。它能够高效地计算因果熵来提供逻辑值，检测到制度转换后会改正模型结构，并通过二次优化问题进行参数估计。 |
| [^3] | [Automated Program Repair Based on Code Review: How do Pre-trained Transformer Models Perform?.](http://arxiv.org/abs/2304.07840) | 本研究探究使用大型预训练语言模型，结合自然语言和编程语言，来改善自动程序修复的效果，发现预训练模型通过使用代码审查和代码更改的数据集微调，能显著优于传统方法，并具有更好的泛化能力。 |
| [^4] | [Characterizing the load profile in power grids by Koopman mode decomposition of interconnected dynamics.](http://arxiv.org/abs/2304.07832) | 本论文介绍了一种基于Koopman算子的负载动态分解方法，能够编码电网负载动态的丰富特征，提高预测精度，同时提供有意义的解释。 |
| [^5] | [Time-dependent Iterative Imputation for Multivariate Longitudinal Clinical Data.](http://arxiv.org/abs/2304.07821) | 提出一种新的TDI方法解决临床数据中的缺失值问题，通过集成前向填充和迭代插值器解决多元和纵向数据问题，采用动态加权策略处理缺失率和测量频率。 |
| [^6] | [Comparative Study of MPPT and Parameter Estimation of PV cells.](http://arxiv.org/abs/2304.07817) | 本研究使用机器学习技术，利用人工神经网络算法精确地估计了太阳能电池和光伏模块的PVLIB模型参数，精度超过95％。 |
| [^7] | [VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.](http://arxiv.org/abs/2304.07810) | VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。 |
| [^8] | [Assisting clinical practice with fuzzy probabilistic decision trees.](http://arxiv.org/abs/2304.07788) | 我们提出了一种基于概率树和模糊逻辑的新方法MedFP，用于辅助医学实践。该方法可以完全解释，允许临床医生产生、控制和验证整个诊断过程，并减少误诊率，通过提供不确定性和反事实分析的估计值。 |
| [^9] | [Harnessing Digital Pathology And Causal Learning To Improve Eosinophilic Esophagitis Dietary Treatment Assignment.](http://arxiv.org/abs/2304.07787) | 本研究利用人工智能技术和因果学习模型，推断EoE的组织学特征和制定个性化的食物消除计划，以改进EoE的治疗效果。 |
| [^10] | [A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation.](http://arxiv.org/abs/2304.07772) | 本研究综合评估自然语言到SPARQL查询生成中的复制机制，通过大量实验研究预训练和非预训练模型、问题注释格式以及使用复制机制的影响，并证明了在这些方面的优化可以提高性能。 |
| [^11] | [Regularized Complete Cycle Consistent GAN for Anomaly Detection.](http://arxiv.org/abs/2304.07769) | 本研究提出了RCALAD方法，通过循环一致性和新的鉴别器增强了GAN在异常检测中的效果。同时，利用补充分布引导重建和引入新的异常评分进一步提高了模型性能。 |
| [^12] | [Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value.](http://arxiv.org/abs/2304.07718) | Data-OOB是一种新的数据价值估计方法，它利用out-of-bag估计，并可以在计算上高效处理大型数据集。 |
| [^13] | [Towards Better Evaluation of GNN Expressiveness with BREC Dataset.](http://arxiv.org/abs/2304.07702) | 本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。 |
| [^14] | [Learning Empirical Bregman Divergence for Uncertain Distance Representation.](http://arxiv.org/abs/2304.07689) | 本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。 |
| [^15] | [MLRegTest: A Benchmark for the Machine Learning of Regular Languages.](http://arxiv.org/abs/2304.07687) | 本文提出了一个名为MLRegTest的新基准测试，其包含了来自1,800个正则语言的数据集。该测试根据逻辑复杂度和逻辑文字种类组织语言，并可以帮助我们了解机器学习系统在学习不同种类的长距离依赖方面的性能。 |
| [^16] | [Using Geographic Location-based Public Health Features in Survival Analysis.](http://arxiv.org/abs/2304.07679) | 本文提出了在生存分析中使用基于地理位置的公共卫生特征，提高了患者预测的准确性，特别是在公共卫生数据的地理分辨率较高时，效果更加明显。 |
| [^17] | [Explanations of Black-Box Models based on Directional Feature Interactions.](http://arxiv.org/abs/2304.07670) | 该论文提出了一种双变量解释方法，可以通过方向特征交互捕获黑盒模型中的特征交互。该方法在Shapley值解释中应用，并在多个数据集上证明了其优越性。 |
| [^18] | [FedBlockHealth: A Synergistic Approach to Privacy and Security in IoT-Enabled Healthcare through Federated Learning and Blockchain.](http://arxiv.org/abs/2304.07668) | 本文提出了一种基于联邦学习和区块链技术的创新方法，为IoT医疗保健应用提供安全和隐私保护的解决方案，实现了安全的模型聚合，同时不共享敏感患者数据。 |
| [^19] | [Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling.](http://arxiv.org/abs/2304.07665) | 本文提出了一个新方法，利用贝叶斯分层建模，动态平衡探索-开发权衡，以更好地查询数据点。 |
| [^20] | [Dimensionality Reduction as Probabilistic Inference.](http://arxiv.org/abs/2304.07658) | 该论文提出了ProbDR变分框架，将经典降维算法解释为概率推断算法，通过优化一个证据下界来完成推断操作。该框架不仅可以完成常规降维算法，还支持使用概率编程语言进行降维操作，具有强大的表达能力。 |
| [^21] | [EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks.](http://arxiv.org/abs/2304.07655) | 该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。 |
| [^22] | [Learned Interpolation for Better Streaming Quantile Approximation with Worst-Case Guarantees.](http://arxiv.org/abs/2304.07652) | 本文探索了应用基于学习的插值算法来提高流数据分位数问题的实际性能，同时保持在最坏情况下的可控保障。 |
| [^23] | [LASER: Neuro-Symbolic Learning of Semantic Video Representations.](http://arxiv.org/abs/2304.07647) | LASER提出了一种神经符号学习方法来学习语义视频表示，通过逻辑规范捕捉视频数据中的时空属性，能够对齐原始视频和规范，有效地训练低级感知模型以提取符合所需高级规范的视频表示。 |
| [^24] | [Non-Proportional Parametrizations for Stable Hypernetwork Learning.](http://arxiv.org/abs/2304.07645) | 本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。 |
| [^25] | [Causal models in string diagrams.](http://arxiv.org/abs/2304.07638) | 本文提出了一种使用弦图语言中的网络图来建立因果模型的方法，在对称单调范畴中对这些模型进行了形式化，扩展了因果贝叶斯网络和结构性因果模型，并形式化了对模型的一般干预，提供了一种可直观且严格推理的方法。 |
| [^26] | [TransDocs: Optical Character Recognition with word to word translation.](http://arxiv.org/abs/2304.07637) | 本研究采用LSTM-based seq2seq架构和带有注意力机制的深度学习模型，将OCR技术与词级翻译相结合，提高了文档转换的性能。 |
| [^27] | [Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model.](http://arxiv.org/abs/2304.07633) | 本论文提出了一种可解释的神经符号模型，用于检测上下文不符的虚假多模态信息，帮助事实检查网站进行记录澄清。 |
| [^28] | [Estimation of minimum miscibility pressure (MMP) in impure/pure N2 based enhanced oil recovery process: A comparative study of statistical and machine learning algorithms.](http://arxiv.org/abs/2304.07617) | 本研究比较了统计学和机器学习方法用于估计N2增油过程中的最小相溶压力，表明本研究开发的预测模型具有更好的性能。 |
| [^29] | [High-Speed and Energy-Efficient Non-Binary Computing with Polymorphic Electro-Optic Circuits and Architectures.](http://arxiv.org/abs/2304.07608) | 本文提出了一种基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算，并能处理多种数据格式和卷积神经网络。 |
| [^30] | [Learning in latent spaces improves the predictive accuracy of deep neural operators.](http://arxiv.org/abs/2304.07599) | 该论文研究了潜在深度算子网络(L-DeepONet)，使用自编码器将高维偏微分方程输入和输出函数转换为低维潜在空间中的特征，从而提高了深度神经算子对偏微分方程的预测准确性。 |
| [^31] | [Icospherical Chemical Objects (ICOs) allow for chemical data augmentation and maintain rotational, translation and permutation invariance.](http://arxiv.org/abs/2304.07558) | 本文介绍了一种叫做ICOs的方法，可以旋转不变的方式对3D化学数据进行编码，适用于球形或二十面体神经网络，并能够进行数据集扩展和提高化学预测任务的效果。 |
| [^32] | [Shape is (almost) all!: Persistent homology features (PHFs) are an information rich input for efficient molecular machine learning.](http://arxiv.org/abs/2304.07554) | 持续同调特征是一种编码分子形状的方法，它捕捉了化学分子的拓扑形状特性，并在能量使用效率上比其他编码方法更高效，表明在化学中，精确的机器学习预测主要依赖于分子的三维形状。 |
| [^33] | [Machine Learning Research Trends in Africa: A 30 Years Overview with Bibliometric Analysis Review.](http://arxiv.org/abs/2304.07542) | 本文对非洲地区机器学习的最新发展和相关应用进行了广泛的文献调查及关键的文献计量分析，结果显示了机器学习研究和应用的当前现状及未来趋势，以促进未来的合作研究和知识交流。 |
| [^34] | [From Online Behaviours to Images: A Novel Approach to Social Bot Detection.](http://arxiv.org/abs/2304.07535) | 该论文提出了一种基于算法和卷积神经网络的新方法来检测 Twitter 机器人账号，通过将其行为转换为图片进行分类，通过测试发现该方法比传统的机器人检测方法更加有效。 |
| [^35] | [STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2304.07520) | 提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。 |
| [^36] | [S3M: Scalable Statistical Shape Modeling through Unsupervised Correspondences.](http://arxiv.org/abs/2304.07515) | 该论文提出一种无监督的方法来建立统计形状模型，使用深度几何特征和功能对应来同时学习复杂解剖结构中的局部和全局形状结构，并且该方法足够健壮，能够从噪声神经网络预测中学习。 |
| [^37] | [PI-FL: Personalized and Incentivized Federated Learning.](http://arxiv.org/abs/2304.07514) | PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。 |
| [^38] | [Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis.](http://arxiv.org/abs/2304.07504) | 本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。 |
| [^39] | [Temporal Aggregation and Propagation Graph Neural Networks for Dynamic Representation.](http://arxiv.org/abs/2304.07503) | 本文提出了 TAP-GNN，通过整个邻域的时间聚合和传播来有效地建模动态图中的时间关系，从而在图流场景中支持高效的在线推理。 |
| [^40] | [Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets.](http://arxiv.org/abs/2304.07499) | 本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。 |
| [^41] | [SalientGrads: Sparse Models for Communication Efficient and Data Aware Distributed Federated Training.](http://arxiv.org/abs/2304.07488) | SalientGrads是一个用于联邦学习的稀疏模型，通过选择一个数据感知的子网络和仅传输高度稀疏的梯度来简化稀疏训练过程，可在减少通信成本高达90%和计算成本高达60%的同时，实现与最先进的联邦学习方法相当或更好的模型准确度。 |
| [^42] | [Efficient Convex Algorithms for Universal Kernel Learning.](http://arxiv.org/abs/2304.07472) | 本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。 |
| [^43] | [Few-shot Weakly-supervised Cybersecurity Anomaly Detection.](http://arxiv.org/abs/2304.07470) | 本文提出了一种使用少量标记数据样本训练和调整机器学习模型进行异常检测的少样本弱监督方法，并在多个数据集上表现优越。 |
| [^44] | [Communication and Energy Efficient Wireless Federated Learning with Intrinsic Privacy.](http://arxiv.org/abs/2304.07460) | 本文提出了一种名为PFELS的无线FL方案，通过先压缩模型更新再自适应地设计发送功率来提供客户端级别DP保证，并降低通信和能量开销并提高模型精度。 |
| [^45] | [Context-aware Domain Adaptation for Time Series Anomaly Detection.](http://arxiv.org/abs/2304.07453) | 本论文提出了一个框架，通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这个框架结合了上下文采样和异常检测，既可以进行无监督域适应，也可以进行有监督的异常检测。 |
| [^46] | [Self-supervised Auxiliary Loss for Metric Learning in Music Similarity-based Retrieval and Auto-tagging.](http://arxiv.org/abs/2304.07449) | 本论文提出了一种自监督学习方法，在自动标注方面已经证明其有效性。我们引入了自监督辅助损失的度量学习方法来解决音乐相似度检索问题，并发现同时使用自监督和监督信号训练模型的优势，而不冻结预训练模型。此外，避免在微调阶段使用数据增强可以提高性能。 |
| [^47] | [A framework for fully autonomous design of materials via multiobjective optimization and active learning: challenges and next steps.](http://arxiv.org/abs/2304.07445) | 该研究介绍了一个基于多目标黑盒优化和不断更新的机器学习模型的主动学习过程，实现了材料的全自动设计。通过自主操作实验室，该工作流成功确定了2,2,2-三氟乙基甲基碳酸酯的理想制造条件。 |
| [^48] | [Learning To Optimize Quantum Neural Network Without Gradients.](http://arxiv.org/abs/2304.07442) | 本文提出了一种量子神经网络的无梯度训练算法，该算法名为Meta-Quantum Optimization (MQO)，相比当前依赖于量子设备计算梯度的算法，具有更高的扩展性和稳定性。作者在二元分类和生成建模任务中成功地应用了MQO算法来优化QNNs，为QNNs的训练提供了一种有效的解决方案。 |
| [^49] | [Efficient Quality-Diversity Optimization through Diverse Quality Species.](http://arxiv.org/abs/2304.07425) | 本文提出了一种新的质量多样性优化算法，通过将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案，相对于传统方法，该方法无需存档或预先定义行为范围的限制。 |
| [^50] | [Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition.](http://arxiv.org/abs/2304.07421) | 本文提出了一个点对点联邦学习框架FedPC，其中使用而不影响司机隐私的车内相机数据进行自然驾驶行为识别（NDAR）模型的建立，在不断学习的基础上提供个性化和准确的模型。 |
| [^51] | [Fairness in Visual Clustering: A Novel Transformer Clustering Approach.](http://arxiv.org/abs/2304.07408) | 本文提出了一种新的Transformer聚类方法，通过引入聚类纯度作为指标，采用新的损失函数来维持聚类模型的公平性，同时引入Cross-attention机制提高聚类的纯度。 |
| [^52] | [Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents.](http://arxiv.org/abs/2304.07407) | 本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。 |
| [^53] | [Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models.](http://arxiv.org/abs/2304.07396) | 本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。 |
| [^54] | [Revenue Management without Demand Forecasting: A Data-Driven Approach for Bid Price Generation.](http://arxiv.org/abs/2304.07391) | 本论文提出了一种无需需求预测的基于数据驱动的收益管理方法，该方法能够仅使用历史预订数据来生成竞价价格。 |
| [^55] | [Shape of You: Precise 3D shape estimations for diverse body types.](http://arxiv.org/abs/2304.07389) | 本文提出了一种名为SoY的方法，通过两种损失函数和测试时优化例程，可以在不同的人体类型上提高精确的3D形体估计准确度，为时尚行业的实际应用提供了希望。 |
| [^56] | [The END: An Equivariant Neural Decoder for Quantum Error Correction.](http://arxiv.org/abs/2304.07362) | 本文介绍了一种利用对称性的数据有效型神经解码器，用于量子纠错，通过等变体系结构达到了与先前神经解码器相比的最先进准确性。 |
| [^57] | [PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators.](http://arxiv.org/abs/2304.07361) | PTW是一种预训练生成器水印技术，可以比从头开始水印技术快三个数量级和更好的保留了生成器的图像质量，解决了恶意用户利用提供的模型制作出有害的深度伪造而不会被发现的问题。 |
| [^58] | [Exact Subspace Diffusion for Decentralized Multitask Learning.](http://arxiv.org/abs/2304.07358) | 本论文提出了一种新的分布式多任务学习算法，通过精确扩散算法的推广，并在网络中进行子空间约束。相比于现有的基于近似投影的方法，其性能得到了明显提升。 |
| [^59] | [Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination.](http://arxiv.org/abs/2304.07338) | 本文提出了一种新的光子场网络方法，可以用于实现体积数据可视化的动态实时全局光照。我们的方法可以实现在体积数据中实现动态全局光照和材质变化的交互式帧率，为体积渲染提供了一种新的方式。 |
| [^60] | [HEAT: A Highly Efficient and Affordable Training System for Collaborative Filtering Based Recommendation on CPUs.](http://arxiv.org/abs/2304.07334) | 这篇论文提出了HEAT训练系统，通过优化SimpleX在CPU上的操作，实现协同过滤的高效率训练 |
| [^61] | [Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation.](http://arxiv.org/abs/2304.07314) | 这篇论文详细研究了STEGO方法的内部机制和培训策略，揭示了其进行无监督语义分割的工作原理，可用于新领域的应用。 |
| [^62] | [M2T: Masking Transformers Twice for Faster Decoding.](http://arxiv.org/abs/2304.07313) | 本文证明预定义的确定性调度在图像压缩方面表现良好，使用双向变换器，遮挡注意力和激活缓存可以显著提高模型的速度。 |
| [^63] | [Federated and distributed learning applications for electronic health records and structured medical data: A scoping review.](http://arxiv.org/abs/2304.07310) | 本研究是一份面向电子病历和结构化医疗数据的联邦与分布式学习应用的范围审查，研究发现FL应用于结构化医学数据的研究大多集中在隐私保护方面，未来应该探索FL在降低通信成本和提高模型通用性方面的应用。 |
| [^64] | [Airborne-Sound Analysis for the Detection of Bearing Faults in Railway Vehicles with Real-World Data.](http://arxiv.org/abs/2304.07307) | 本文介绍了一种基于实际数据进行铁路车辆轴承故障检测的声学分析方法，使用Mel频率倒谱系数(MFCC)作为特征，实验表明该方法可以可靠地检测轴承故障。 |
| [^65] | [Learning to Defer with Limited Expert Predictions.](http://arxiv.org/abs/2304.07306) | 本论文提出了一个三步方法，用于降低学习推迟算法所需的专家预测数量。该方法通过训练嵌入模型、使用少量的专家预测和利用样本相似性来提高性能。 |
| [^66] | [1-D Residual Convolutional Neural Network coupled with Data Augmentation and Regularization Techniques for the ICPHM 2023 Data Challenge.](http://arxiv.org/abs/2304.07305) | 本文提出的一维残差卷积神经网络结合了数据增强和正则化技术，在ICPHM 2023数据挑战赛中应用于太阳齿轮故障分类任务。即使面对多个操作条件下获得的数据，该网络仍能准确预测被检测齿轮箱的状态。 |
| [^67] | [Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition.](http://arxiv.org/abs/2304.07304) | 本文探究了基于传感器的人类活动识别中自监督学习框架的深度表示，通过解释这些表示与有监督表示的区别，比较它们的鲁棒性，并使用显著图将其应用于预测不同的活动。 |
| [^68] | [Smart Metro: Deep Learning Approaches to Forecasting the MRT Line 3 Ridership.](http://arxiv.org/abs/2304.07303) | 本研究使用时间序列模型预测菲律宾马尼拉地铁三号线每天乘客量的变化，帮助人们更好地规划出行。 |
| [^69] | [HGWaveNet: A Hyperbolic Graph Neural Network for Temporal Link Prediction.](http://arxiv.org/abs/2304.07302) | HGWaveNet是一种双曲图神经网络，用于时间链接预测。它包括超曲率扩散图卷积和小波时间卷积两个关键模块，可有效聚合邻居信息和捕捉时间依赖，并在真实世界数据集上表现出更好的精度和效率。 |
| [^70] | [Supervised Machine Learning for Breast Cancer Risk Factors Analysis and Survival Prediction.](http://arxiv.org/abs/2304.07299) | 本研究利用机器学习方法预测了乳腺癌患者的5年生存率，并比较了七种分类模型的表现，结果表明这些模型能够准确地预测测试样本的生存率，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。 |
| [^71] | [Road Network Representation Learning: A Dual Graph based Approach.](http://arxiv.org/abs/2304.07298) | 提出了一种基于双重图的方法来解决传统道路网络表示学习模型无法捕捉道路之间高阶和远程关系的问题。 |
| [^72] | [Language Instructed Reinforcement Learning for Human-AI Coordination.](http://arxiv.org/abs/2304.07297) | 本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。 |
| [^73] | [Sub-meter resolution canopy height maps using self-supervised learning and a vision transformer trained on Aerial and GEDI Lidar.](http://arxiv.org/abs/2304.07213) | 本文使用自监督学习和视觉转换器方法，制作了亚米级冠层高度图，可用于细粒度的植被结构监测，为碳通量评估和土地利用管理提供宝贵信息。 |
| [^74] | [Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter.](http://arxiv.org/abs/2304.06858) | 本文介绍了一个推特疫苗数据集Vax-Culture，它旨在找出推广疫苗错误信息的文化和政治信念的重叠部分，帮助开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。 |
| [^75] | [SpectFormer: Frequency and Attention is what you need in a Vision Transformer.](http://arxiv.org/abs/2304.06446) | 本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。 |
| [^76] | [Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model.](http://arxiv.org/abs/2304.06174) | 本文开发了一种物体感知 SE(3) 等变扩散模型，可以在几秒钟内精确地生成过渡态结构，与基于量子化学的优化相比，计算时间大大缩短，其生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差，可以实现反应速率估计所需的精度。 |
| [^77] | [An Edit Friendly DDPM Noise Space: Inversion and Manipulations.](http://arxiv.org/abs/2304.06140) | 本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。 |
| [^78] | [Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling.](http://arxiv.org/abs/2304.06052) | 本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。 |
| [^79] | [Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling.](http://arxiv.org/abs/2304.05365) | 本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。 |
| [^80] | [Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond.](http://arxiv.org/abs/2304.04968) | 本研究提出了Perp-Neg算法，通过利用得分空间的几何特性来解决目前文本到图像扩散模型中负面提示算法存在的问题，使得用户能够编辑掉初始生成图像中不想要的概念，从而提供了更大的灵活性。同时，我们还通过提出基于Perp-Neg的3D负面提示算法，将算法扩展到3D应用中。 |
| [^81] | [SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning.](http://arxiv.org/abs/2304.04738) | 该论文比较了采用深度学习模型的SAM与传统方法BET在MRI脑提取方面的效果，结果表明SAM在信号不均匀、非等向性分辨率或病变靠近脑外区域和脑膜时效果更佳，SAM表现出更准确、更健壮和更多样化的潜力。 |
| [^82] | [Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge.](http://arxiv.org/abs/2304.03392) | 该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。 |
| [^83] | [Deep learning-based image exposure enhancement as a pre-processing for an accurate 3D colon surface reconstruction.](http://arxiv.org/abs/2304.03171) | 本文研究了基于深度学习的三维结肠表面重建，在图像预处理的过程中通过纠正局部欠曝光和过曝光来提高重建精度。 |
| [^84] | [Synthetic Hard Negative Samples for Contrastive Learning.](http://arxiv.org/abs/2304.02971) | 本文提出一种新的方法，称为SSCL，可以更好地利用难以区分出的负样本，提高对比学习的性能。 |
| [^85] | [Learning to Compare Longitudinal Images.](http://arxiv.org/abs/2304.02531) | 本文提出了一种名为PaIRNet的深度学习模型，用于比较带有或不带有预处理的纵向图像对，以检测生物医学应用中与研究问题相关的变化。 |
| [^86] | [Selecting Features by their Resilience to the Curse of Dimensionality.](http://arxiv.org/abs/2304.02455) | 该研究提出了一种新的特征选择方法，通过识别能够区分不同大小数据子集的特征来降低高维数据的复杂性。实验表明，该方法具有竞争力，并通常优于其他已有的特征选择方法。此外，该方法可扩展到由数百万数据点组成的数据集。 |
| [^87] | [Managing power grids through topology actions: A comparative study between advanced rule-based and reinforcement learning agents.](http://arxiv.org/abs/2304.00765) | 本研究分析了使用强化学习和基于规则方法的电力网络运行智能体并提供了新策略。其中最主要的改进是采用N-1策略，考虑到在某条线路断开时的拓扑操作以保持网络稳定。另外，拓扑反转也有利于提高性能。在挑战测试集上，该方法的性能提高了27%。 |
| [^88] | [TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns.](http://arxiv.org/abs/2303.15747) | 提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。 |
| [^89] | [Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches.](http://arxiv.org/abs/2303.11582) | 本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。 |
| [^90] | [MeshDiffusion: Score-based Generative 3D Mesh Modeling.](http://arxiv.org/abs/2303.08133) | 本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。 |
| [^91] | [Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap.](http://arxiv.org/abs/2303.06484) | 本文提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌，并将其分解为两个目标：最小化类内变异性和最大化类间可分性。使用超球统一性作为量化这两个目标的统一框架，并提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。 |
| [^92] | [Disambiguation of Company names via Deep Recurrent Networks.](http://arxiv.org/abs/2303.05391) | 本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。 |
| [^93] | [Evidence-empowered Transfer Learning for Alzheimer's Disease.](http://arxiv.org/abs/2303.01105) | 该研究提出了一种在阿尔茨海默病诊断中使用证据支持的转移学习方法，通过利用AD相关的辅助任务来学习MRI扫描中形态学特征的证据和可转移知识，提高了检测性能，同时更具有数据效率和可信度。 |
| [^94] | [Helpful, Misleading or Confusing: How Humans Perceive Fundamental Building Blocks of Artificial Intelligence Explanations.](http://arxiv.org/abs/2303.00934) | 该论文旨在以人为中心的角度评估人工智能中的解释可理解性，以及评估可解释性的适当方法落后于技术的发展速度。 |
| [^95] | [pyribs: A Bare-Bones Python Library for Quality Diversity Optimization.](http://arxiv.org/abs/2303.00191) | pyribs是一个Python库，可以用于质量多样性优化，支持广泛的研究人员和实践者，具有高度模块化的框架可用于组合算法，是一个灵活易用的框架。 |
| [^96] | [AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation.](http://arxiv.org/abs/2303.00085) | 本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。 |
| [^97] | [CADIS: Handling Cluster-skewed Non-IID Data in Federated Learning with Clustered Aggregation and Knowledge DIStilled Regularization.](http://arxiv.org/abs/2302.10413) | 本文提出了一种针对聚类偏斜非独立同分布数据的联邦学习聚合方案和基于知识蒸馏的局部训练正则化方法 |
| [^98] | [Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation.](http://arxiv.org/abs/2302.09664) | 本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。 |
| [^99] | [Measuring Equality in Machine Learning Security Defenses.](http://arxiv.org/abs/2302.08973) | 本文研究了机器学习安全防御方法的平等性能问题，提出了一种简单的平等度量和分析框架，鼓励进一步探索公平性在该领域的应用。 |
| [^100] | [XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars.](http://arxiv.org/abs/2302.07769) | 本文提出了一种名为XploreNAS的方法，该方法通过两阶段算法-硬件协同优化，针对非理想交叉栏架构探索对抗性强和硬件高效的神经网络结构，通过采样出具有对抗性强度的子网络，实现了在非理想性交叉栏架构下的硬件和对抗性的均衡发展。 |
| [^101] | [Knowledge Enhanced Semantic Communication Receiver.](http://arxiv.org/abs/2302.07727) | 提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，并通过知识提取器和基于GCN的语义解码器实现了更好的性能，不影响发射端的神经网络结构。 |
| [^102] | [Attention-based Domain Adaptation Forecasting of Streamflow in Data-Sparse Regions.](http://arxiv.org/abs/2302.05386) | 本文提出了一种基于注意力机制的领域自适应流量预测模型，用于数据稀缺的区域。通过对抗方法同时训练流量预测和区分两个领域，可在24小时流量预测方面实现性能表现的提高。 |
| [^103] | [Ensemble Value Functions for Efficient Exploration in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2302.03439) | 本论文提出了集成价值函数框架EMAX，用于多智能体强化学习中的探索，使用UCB策略引导探索，并通过训练价值函数集合减少方差和不稳定性，展示了比其他策略更高的学习速度、最终性能和对非静止性的稳健性。 |
| [^104] | [Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness.](http://arxiv.org/abs/2302.03015) | 本论文解决了深度学习模型在进行鲁棒训练时的边界动态问题，提出了动态感知鲁棒训练方法，通过优化边界增加较小边界距离为优先的移动来提升模型的鲁棒性。 |
| [^105] | [A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization.](http://arxiv.org/abs/2302.01539) | BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。 |
| [^106] | [Physics-informed Reduced-Order Learning from the First Principles for Simulation of Quantum Nanostructures.](http://arxiv.org/abs/2302.00100) | 本研究提出了基于第一原理的简化模型学习算法，用于模拟量子纳米结构，实现了高精度和高效率的模拟结果。 |
| [^107] | [Learning Generalized Hybrid Proximity Representation for Image Recognition.](http://arxiv.org/abs/2301.13459) | 该文章提出了一种新的图像识别的监督度量学习方法，能够以混合方法学习更好的距离表示。通过控制几何近邻和概率近邻之间的权衡，从图像数据中学习通用的混合相似特征。 |
| [^108] | [Causal Structural Learning from Time Series: A Convex Optimization Approach.](http://arxiv.org/abs/2301.11336) | 该论文提出了一种数据自适应线性方法，通过凸优化技术解决了时间序列数据中的因果结构学习问题，方法具有非渐近恢复保证，并且在结构恢复方面表现出了优越性。 |
| [^109] | [Learning Deformation Trajectories of Boltzmann Densities.](http://arxiv.org/abs/2301.07388) | 本文介绍了一种学习Boltzmann密度变形轨迹的方法，其中通过插值能量函数等实现Boltzmann密度的变形，然后找到一个时间依赖向量场，将样本从一个分布转移到另一个分布，其表现在高斯混合和量子力学粒子的Boltzmann密度上比KL-反散度更具优势。 |
| [^110] | [A Novel Sparse Regularizer.](http://arxiv.org/abs/2301.07285) | 提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。 |
| [^111] | [GLIGEN: Open-Set Grounded Text-to-Image Generation.](http://arxiv.org/abs/2301.07093) | GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。 |
| [^112] | [Domain Expansion of Image Generators.](http://arxiv.org/abs/2301.05225) | 提出一种新任务——领域扩展，来注入新的概念到一个已经训练好的生成模型，同时保持其现有的结构和知识。发现预训练的生成器具有添加多个新领域的能力，而不需要扩展。 |
| [^113] | [Towards the Identifiability in Noisy Label Learning: A Multinomial Mixture Approach.](http://arxiv.org/abs/2301.01405) | 本文使用多项式混合模型研究了在有噪声标签学习过程中如何识别出干净标签样本，发现每个实例有至少 $2C-1$ 个有噪声标签时，该问题才是可识别的。为了满足这个要求，提出了一种方法，通过估计噪声标签分布自动生成额外的噪声标签以提高可识别性，无需额外的假设。 |
| [^114] | [CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection.](http://arxiv.org/abs/2301.00785) | 本文提出了基于CLIP的通用模型，通过文本嵌入学习解剖学关系，能够分割25种器官和6种肿瘤，具有强大的泛化能力。 |
| [^115] | [Behavioral Cloning via Search in Video PreTraining Latent Space.](http://arxiv.org/abs/2212.13326) | 本文通过基于模仿学习方法中的搜索问题，将控制问题表述为专家演示数据集中的模仿。该方法通过在视频预训练模型的潜表示中进行近邻搜索，可以有效地在Minecraft环境中复制出有意义的演示轨迹并呈现类人行为。 |
| [^116] | [A Review of Speech-centric Trustworthy Machine Learning: Privacy, Safety, and Fairness.](http://arxiv.org/abs/2212.09006) | 本论文综述了基于语音的可信机器学习的主要挑战，包括隐私、安全和公平性，并提出了未来值得研究的方向。 |
| [^117] | [Sliced Optimal Partial Transport.](http://arxiv.org/abs/2212.08049) | 本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。 |
| [^118] | [Accelerating Dataset Distillation via Model Augmentation.](http://arxiv.org/abs/2212.06152) | 本文提出了两种模型增强技术，即使用早期模型和参数扰动，以显着降低训练成本的方式优化数据集蒸馏，实现了高达20倍的加速。 |
| [^119] | [Expressive architectures enhance interpretability of dynamics-based neural population models.](http://arxiv.org/abs/2212.03771) | 研究通过顺序自动编码器从神经数据集中恢复潜在的混沌吸引子，发现采用神经常微分方程为基础的 SAES 在准确率和维度方面优于采用循环神经网络的 SAES。 |
| [^120] | [Interpreting Vulnerabilities of Multi-Instance Learning to Adversarial Perturbations.](http://arxiv.org/abs/2211.17071) | 本文提出了两种对抗性扰动方法以解释多实例学习在该方面的漏洞。其中一种针对每个袋子进行定制，另一种是通用的，可以影响给定数据集中的所有袋子，并且证明了这些方法的有效性。 |
| [^121] | [Generalizable Implicit Neural Representations via Instance Pattern Composers.](http://arxiv.org/abs/2211.13223) | 本文提出了一种使用实例模式组合器实现具有泛化性的隐式神经表示的方法，该方法通过调制早期的多层感知器层中的一小组权重来表示复杂的数据实例，并学习模式组合规则以实现实例的共同表示。 |
| [^122] | [Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation.](http://arxiv.org/abs/2211.12703) | 本文通过实证比较多种公平和稳健的机器学习方法的子群健壮性，并表明基于树的方法具有极强的健壮性，可能比其他稳健或群体公平的方法表现更好。 |
| [^123] | [Sequential Informed Federated Unlearning: Efficient and Provable Client Unlearning in Federated Optimization.](http://arxiv.org/abs/2211.11656) | 本文提出一种名为知情联合消除（IFU）的新颖联邦优化方法，可实现有效且可量化的客户端消除请求，实验结果表明其效率较基本方法和最先进的FU方法更高。 |
| [^124] | [Implications of Regret on Stability of Linear Dynamical Systems.](http://arxiv.org/abs/2211.07411) | 本文研究了在线学习中计算的遗憾与所选策略的闭环系统稳定性之间的关系，结果发现线性遗憾暗示着渐进稳定性。同时，有界输入的有界状态稳定性和状态转移矩阵的可加性也意味着线性遗憾概念。 |
| [^125] | [Fairness and bias correction in machine learning for depression prediction: results from four different study populations.](http://arxiv.org/abs/2211.05321) | 本文研究了设计用于预测抑郁症的机器学习模型的公平性问题，并给出了有效的偏差矫正方法。这项研究强调了分析公平性以及透明报告的重要性。 |
| [^126] | [Scalable Spectral Clustering with Group Fairness Constraints.](http://arxiv.org/abs/2210.16435) | 本文提出了一个带有组公平约束的可扩展谱聚类算法 s-FairSC，并通过稀疏矩阵向量乘积来充分利用其稀疏性。 |
| [^127] | [Universal Adversarial Directions.](http://arxiv.org/abs/2210.15997) | 研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。 |
| [^128] | [Learning to predict arbitrary quantum processes.](http://arxiv.org/abs/2210.14894) | 本论文提出一种用于预测任意量子过程的机器学习算法，该算法对于各种不同分布的输入状态具有小的平均误差，即便在处理指数门时也具有高效率，实验结果证实其有效性，是一种优于现有方法的新算法。 |
| [^129] | [MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling.](http://arxiv.org/abs/2210.13545) | 提出了一种新的基于探索-开发权衡的缓冲区采样策略，可以根据任务的复杂性自适应地调整采样策略，并在经典控制环境中表现出优越性能。 |
| [^130] | [Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction.](http://arxiv.org/abs/2210.10709) | 提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。 |
| [^131] | [RibSeg v2: A Large-scale Benchmark for Rib Labeling and Anatomical Centerline Extraction.](http://arxiv.org/abs/2210.09309) | 本文扩展了RibSeg数据集到大规模基准测试RibSeg v2，加入了手动标注的肋骨标记和解剖中心线提取，共包含660个CT扫描（15,466个独立的肋骨），并提出了深度学习方法用于肋骨标记、基于骨架化方法用于中心线提取、一种稀疏点云表示CT扫描的方法，以及适用于该任务的评估指标。 |
| [^132] | [Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers.](http://arxiv.org/abs/2210.09257) | 该论文介绍了一种神经平衡求解器，可以快速、准确地解决所有固定形状游戏空间的NEs、CEs和CCEs问题，并提供一个灵活的平衡选择框架，有助于加强多智能体算法的实现和应用。 |
| [^133] | [A cusp-capturing PINN for elliptic interface problems.](http://arxiv.org/abs/2210.08424) | 本文提出了一种用于解决椭圆界面问题的尖点捕获PINN，它使用尖点强制水平集函数作为额外特征输入，以锐利地捕获解尖点，同时具有无网格优点。 |
| [^134] | [Learning image representations for anomaly detection: application to discovery of histological alterations in drug development.](http://arxiv.org/abs/2210.07675) | 该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。 |
| [^135] | [Intrinsic Dimension for Large-Scale Geometric Learning.](http://arxiv.org/abs/2210.05301) | 本研究提出了一种计算上可行的方法来确定大规模复杂数据的内在维度，该方法考虑了数据集的几何特性，并在准确性和计算效率方面优于现有方法。 |
| [^136] | [A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning.](http://arxiv.org/abs/2210.03112) | 该论文研究了使用合成指令的大规模扩充方法，通过构建导航轨迹并使用高质量的多语言导航指令生成器Marky生成基于图像的指令，以及使用图像到图像GAN在新的视角上合成图像观察。这些方法得到了更强的视觉语言导航模型。 |
| [^137] | [Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information.](http://arxiv.org/abs/2210.00116) | 本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。 |
| [^138] | [DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases.](http://arxiv.org/abs/2210.00063) | DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。 |
| [^139] | [Deep generative model super-resolves spatially correlated multiregional climate data.](http://arxiv.org/abs/2209.12433) | 本研究展示了一个基于对抗网络的机器学习方法，在超分辨率处理过程中可以正确重构区域间的空间相关性，从而提高气候模拟输出的质量与准确度。 |
| [^140] | [Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks.](http://arxiv.org/abs/2209.12195) | 本文提出了一种基于集成分类器的架构，称作SPRITZ-1.5C，它同时结合了1类分类的安全性和传统2类分类的高性能，在计算机网络等安全型应用中抵御对抗攻击具有挑战性。 |
| [^141] | [Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions.](http://arxiv.org/abs/2209.11215) | 本文对得分式生成模型进行了理论研究，证明其可以有效地从任何实际数据分布中采样。与以往研究不同的是，本文的结果不需要排除实质性非对数凹性的限制性函数不等式条件，并且具有多项式的规模。这是得分式生成模型实证成功的强有力理论证明。 |
| [^142] | [Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning.](http://arxiv.org/abs/2209.08907) | 本文提出了一种通过元学习框架学习模型无关损失函数的方法，并通过对多个监督学习任务的实验证明，该方法学到的损失函数优于目前最优方法和交叉熵损失函数。 |
| [^143] | [Solving Elliptic Problems with Singular Sources using Singularity Splitting Deep Ritz Method.](http://arxiv.org/abs/2209.02931) | 本研究提出一种采用奇异性分离深度Ritz方法求解带奇异源的椭圆问题的高效求解器，成功应对了一般点源、线源以及点线源的组合，在实际应用中效果良好。 |
| [^144] | [UniCon: Unidirectional Split Learning with Contrastive Loss for Visual Question Answering.](http://arxiv.org/abs/2208.11435) | 本文提出了UniCon方法，用于解决多客户VQA任务的保密性约束和客户有限标记训练数据的问题。该方法通过模型共享学习跨模态表示，采用分裂学习架构确保隐私。 |
| [^145] | [FORBID: Fast Overlap Removal By stochastic gradIent Descent for Graph Drawing.](http://arxiv.org/abs/2208.10334) | FORBID提出了一种基于随机梯度下降的算法，用于解决图形可视化中因节点形状而引起的重叠问题，该算法能在维持节点拓扑信息的同时，高效地移除重叠。 |
| [^146] | [Markov Observation Models.](http://arxiv.org/abs/2208.06368) | 本文针对隐马尔可夫模型扩展为允许马尔可夫链观测，研究了相应的期望最大化算法类比算法，并实现了相应的滤波和Viterbi算法。 |
| [^147] | [Proof-of-Learning is Currently More Broken Than You Think.](http://arxiv.org/abs/2208.03567) | 学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。 |
| [^148] | [Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation.](http://arxiv.org/abs/2208.00884) | 本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。 |
| [^149] | [Metropolis Monte Carlo sampling: convergence, localization transition and optimality.](http://arxiv.org/abs/2207.10488) | 本文使用分析和数值方法研究了随机行走Metroplolis方案中向稳定状态的收敛性质，发现随机漫步中的尝试跳变量特征长度可以呈现为局部化转变的形式，收敛后及局部化转变前的弛豫分别受扩散和…（论文重点） |
| [^150] | [Collaborative Learning in Kernel-based Bandits for Distributed Users.](http://arxiv.org/abs/2207.07948) | 本文研究了分布式用户之间的基于内核的赌博机协同学习，并提出了一种使用代理高斯进程模型的算法，以降低通信开销，获得次优遗憾性能。 |
| [^151] | [Deep Contrastive One-Class Time Series Anomaly Detection.](http://arxiv.org/abs/2207.01472) | 本论文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，能够提高检测性能。 |
| [^152] | [Randomized Coordinate Subgradient Method for Nonsmooth Optimization.](http://arxiv.org/abs/2206.14981) | 本文提出了适用于非光滑优化问题的随机坐标半梯度法，该方法在每次迭代只更新一个坐标块，考虑了目标函数的线性有界次梯度假设，并在凸和非凸情况下建立了全面的收敛性分析，收敛速率为$\widetilde{\mathcal{O}}(1/\sqrt{k})$和$\mathcal{O}(1/k)$。 |
| [^153] | [The Integration of Machine Learning into Automated Test Generation: A Systematic Mapping Study.](http://arxiv.org/abs/2206.10210) | 该论文研究了将机器学习应用于自动化测试生成的方法，并总结了目前的研究进展、应用和挑战。其中监督学习和强化学习是主要的技术方法。 |
| [^154] | [Pruning for Feature-Preserving Circuits in CNNs.](http://arxiv.org/abs/2206.01627) | 本论文提出了一种方法，可以从深层CNN中提取“特征保留电路”，这些是能够保留目标特征的子函数，可以用于解释卷积神经网络的图像过滤过程。同时提出了一种工具用于可视化电路图像过滤过程。 |
| [^155] | [Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes.](http://arxiv.org/abs/2205.13589) | 本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。 |
| [^156] | [Uncertainty-Aware Prediction of Battery Energy Consumption for Hybrid Electric Vehicles.](http://arxiv.org/abs/2204.12825) | 该论文针对驾驶员对于给定行程中能源可用性的不确定性问题，提出了一种机器学习方法来建模电池能量消耗，通过减少预测不确定性提高对车辆性能的信任并提升其可用性。 |
| [^157] | [Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation.](http://arxiv.org/abs/2203.11740) | 该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。 |
| [^158] | [Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily.](http://arxiv.org/abs/2203.11200) | 该论文提出了一种基于von Neumann熵的新指标来重新审视GNNs的异质性问题，并从整个邻居可识别的角度研究跨类边的特征聚合。此外，还提出了一个Conv-Agnostic GNN框架，通过学习每个节点的邻居效应，在异质性数据集上增强了大多数GNN的性能。 |
| [^159] | [Dimensionality Reduction and Wasserstein Stability for Kernel Regression.](http://arxiv.org/abs/2203.09347) | 本文研究了在高维回归框架中的降维与Wasserstein稳定性应用，针对在扰动输入数据用于拟合回归函数时出现的误差推导了稳定性结果，并利用主成分分析和核回归文献中的估计，推导了两步法的收敛速度。 |
| [^160] | [How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?.](http://arxiv.org/abs/2203.04450) | 本论文提出了一种新型表示学习框架CIDER，可以利用超球嵌入实现外部分布（OOD）检测，该方法综合优化两个损失以促进强内部-外部类别可分性，并在基准数据集上取得了新的OOD检测性能记录。 |
| [^161] | [Counterfactual inference for sequential experiments.](http://arxiv.org/abs/2202.06891) | 本文针对序列实验的反事实推断问题，提出了一个潜在因子模型，使用非参数方法对反事实均值进行估计，并建立了误差界限。 |
| [^162] | [The Implicit Bias of Benign Overfitting.](http://arxiv.org/abs/2201.11489) | 本文针对善意过拟合现象，提供了非线性回归的最小范数插值预测器在一般情况下偏向于不一致解的证明，从而说明善意过拟合不会发生，同时展示了如何将其扩展到标准线性回归以外。 |
| [^163] | [GNN-Geo: A Graph Neural Network-based Fine-grained IP geolocation Framework.](http://arxiv.org/abs/2112.10767) | 本文提出了一种基于图神经网络的 IP 地理定位框架 GNN-Geo，它通过对连接进行建模来细化节点嵌入，提高了准确性。 |
| [^164] | [Semi-Supervised Contrastive Learning for Remote Sensing: Identifying Ancient Urbanization in the South Central Andes.](http://arxiv.org/abs/2112.06437) | 本文提出了一种利用遥感数据，在半监督对比学习框架下，改善南美南部安第斯地区古城化鉴定的方法。通过结合标注和未标注样本，能够有效地学习高度不平衡的数据集，从而极大地缩短对偏远地区考古遗存鉴定的工时和费用。 |
| [^165] | [TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguistic Reasoning.](http://arxiv.org/abs/2111.10756) | 提出了TraVLR数据集，可以用于评估V+L模型的表现，数据集合成，包括四个V+L推理任务，同时使用双模式冗余编码来评估其泛化能力。 |
| [^166] | [Towards convergence to Nash equilibria in two-team zero-sum games.](http://arxiv.org/abs/2111.04178) | 研究了两支团队博弈的纳什均衡（NE）的解，证明了计算这类博弈的NE是困难的，提出了一组简单但非平凡的游戏基准用于检验在线学习算法在具有全信息反馈的游戏中的能力。 |
| [^167] | [RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System.](http://arxiv.org/abs/2110.11073) | RL4RS是一个新的基于强化学习的推荐系统数据集，为此提供了一种替代使用人造数据集和半仿真推荐系统数据集的方法，并提出了新的系统评估框架。 |
| [^168] | [ML4C: Seeing Causality Through Latent Vicinity.](http://arxiv.org/abs/2110.00637) | 本文提出了一种监督式因果学习方法ML4C，采用了新颖的学习目标，用于分类未屏蔽三元组是否是v-结构，并构建因果关系。 |
| [^169] | [Secure PAC Bayesian Regression via Real Shamir Secret Sharing.](http://arxiv.org/abs/2109.11200) | 该论文提出了一种基于真实Shamir密钥分享的安全PAC Bayesian回归协议，通过解决多方计算和数据共享问题，实现在不违反数据隐私的情况下安全地学习线性模型参数。 |
| [^170] | [FedChain: Chained Algorithms for Near-Optimal Communication Cost in Federated Learning.](http://arxiv.org/abs/2108.06869) | FedChain是一种算法框架，结合了本地方法和全局方法的优点，实现了在通信回合数方面快速收敛，并利用客户之间的相似性。 |
| [^171] | [Differential-Critic GAN: Generating What You Want by a Cue of Preferences.](http://arxiv.org/abs/2107.06700) | 本文提出了一种新的生成对抗网络——差分评论家GAN，它可以在只有部分数据集包含所需特性的情况下，利用本地信息和成对偏好生成满足用户期望的所需数据分布。 |
| [^172] | [Causal Graph Discovery from Self and Mutually Exciting Time Series.](http://arxiv.org/abs/2106.02600) | 该论文提出了一个新的因果图发现方法，结合了广义线性结构因果模型和自适应正则化方法，通过解决凸优化问题来恢复因果DAGs，并建立了置信区间以量化不确定性，经过实验证明其在恢复高度可解释的因果DAGs上表现出竞争性能。 |
| [^173] | [Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning.](http://arxiv.org/abs/2106.01132) | 该研究提出并实现了一个基于三维解剖脑部 MRI 的CNN模型的全面基准测试，包括结构、数据增强和深度集成等方面，基于大型多站点的脑部解剖MRI数据集，该测试为三维脑部解剖MRI数据分析领域的进一步研究提供了参考。 |
| [^174] | [Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle.](http://arxiv.org/abs/2105.14559) | 该论文提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），通过捕捉潜在softmax概率和标签变量的信息平衡，实现了基于平衡熵学习准则的贝叶斯神经网络主动学习，并在多个基准数据集上证明了该方法的有效性和较高的计算效率。 |
| [^175] | [CogDL: A Comprehensive Library for Graph Deep Learning.](http://arxiv.org/abs/2103.00959) | CogDL是一个图深度学习的综合库，针对图数据的稀疏性和复杂任务提供了统一的训练和评估设计和多种训练技术，包括高效和可扩展的实现和实用工具，是进行图深度学习的理想选择。 |
| [^176] | [Flexible Model Aggregation for Quantile Regression.](http://arxiv.org/abs/2103.00083) | 本文研究聚合条件分位数模型的方法，提高分位数回归的准确性和鲁棒性，并提出了能够应用于现代深度学习工具包的多种模型，对许多从业者具有广泛的适用性。 |
| [^177] | [AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles.](http://arxiv.org/abs/2101.06549) | 提出了AdvSim框架，利用对抗性方法生成自动驾驶车辆的安全关键场景，具有可扩展性，适用于任何基于激光雷达的自主系统，可以识别各种具有语义意义的安全关键场景。 |
| [^178] | [Local Minima Structures in Gaussian Mixture Models.](http://arxiv.org/abs/2009.13040) | 研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。 |
| [^179] | [Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model.](http://arxiv.org/abs/2005.12900) | 本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。 |
| [^180] | [Zero-Shot Compositional Policy Learning via Language Grounding.](http://arxiv.org/abs/2004.07200) | 本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。 |
| [^181] | [Open-set learning with augmented category by exploiting unlabeled data (Open-LACU).](http://arxiv.org/abs/2002.01368) | Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。 |
| [^182] | [Neighborhood and Graph Constructions using Non-Negative Kernel Regression.](http://arxiv.org/abs/1910.09383) | 本文提出了一种非负核回归的算法来构建更好的邻域和图，并且在各种应用中展示出其优越性和实用性。 |

# 详细

[^1]: 一种数据中心的、基于Vision Transformer的非均质去雾解决方案。

    A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer. (arXiv:2304.07874v1 [cs.CV])

    [http://arxiv.org/abs/2304.07874](http://arxiv.org/abs/2304.07874)

    本文提出了一种基于Vision Transformer的数据中心的解决方案，用于解决非均质去雾问题。传统方法在处理NH-HAZE23数据集等非均质雾图像时存在问题，因为它们无法满足建模均质雾所需的假设之一。同时，本文指出光靠数据增广并不能解决问题，因为需要处理分布差异。

    

    近年来，图像去雾引起了越来越多的关注。许多深度学习方法已经被提出来应对这一挑战，并在处理均质雾时取得了显著的成就。然而，这些解决方案无法在应用于存在非均质雾的图像时保持类似的性能，例如NTIRE挑战介绍的NH-HAZE23数据集。其中一个失败的原因是非均质雾不符合建模均质雾所需的假设之一。此外，传统的端到端训练方法需要对大量的非均质雾图像与其清晰对应项进行配对，而NH-HAZE23数据集的数量是有限的。尽管可以通过利用其他非均质去雾数据集扩充NH-HAZE23数据集，但我们观察到有必要设计一种适当的数据预处理方法以减少目标数据集之间的分布差距。

    Recent years have witnessed an increased interest in image dehazing. Many deep learning methods have been proposed to tackle this challenge, and have made significant accomplishments dealing with homogeneous haze. However, these solutions cannot maintain comparable performance when they are applied to images with non-homogeneous haze, e.g., NH-HAZE23 dataset introduced by NTIRE challenges. One of the reasons for such failures is that non-homogeneous haze does not obey one of the assumptions that is required for modeling homogeneous haze. In addition, a large number of pairs of non-homogeneous hazy image and the clean counterpart is required using traditional end-to-end training approaches, while NH-HAZE23 dataset is of limited quantities. Although it is possible to augment the NH-HAZE23 dataset by leveraging other non-homogeneous dehazing datasets, we observe that it is necessary to design a proper data-preprocessing approach that reduces the distribution gaps between the target datase
    
[^2]: CEBoosting:基于因果熵增强的动态系统带制度转换的在线稀疏识别

    CEBoosting: Online Sparse Identification of Dynamical Systems with Regime Switching by Causation Entropy Boosting. (arXiv:2304.07863v1 [math.DS])

    [http://arxiv.org/abs/2304.07863](http://arxiv.org/abs/2304.07863)

    该论文提出一种因果熵增强(CEBoosting)策略，能够通过在线模型识别来检测制度转换和发现新制度相关动力学。它能够高效地计算因果熵来提供逻辑值，检测到制度转换后会改正模型结构，并通过二次优化问题进行参数估计。

    

    多尺度特征、混沌行为和极端事件使得制度转换普遍存在于许多复杂动力学系统中。本文提出了一种因果熵增强(CEBoosting)策略，以便通过在线模型识别促进制度转换的检测和新制度相关动力学的发现。通过计算效率高的因果熵，为预先确定的库中的每个候选函数提供一个逻辑值。与当前制度校准的模型相关的少数一个或几个因果熵指标的反转意味着检测到制度转换。尽管由连续数据组成的每个批次的长度很短，但与一系列数据批次对应的因果熵累积值导致了一个稳健的指标。通过检测模型结构的改正，随后的参数估计成为一个二次优化问题，通过计算进行解决。

    Regime switching is ubiquitous in many complex dynamical systems with multiscale features, chaotic behavior, and extreme events. In this paper, a causation entropy boosting (CEBoosting) strategy is developed to facilitate the detection of regime switching and the discovery of the dynamics associated with the new regime via online model identification. The causation entropy, which can be efficiently calculated, provides a logic value of each candidate function in a pre-determined library. The reversal of one or a few such causation entropy indicators associated with the model calibrated for the current regime implies the detection of regime switching. Despite the short length of each batch formed by the sequential data, the accumulated value of causation entropy corresponding to a sequence of data batches leads to a robust indicator. With the detected rectification of the model structure, the subsequent parameter estimation becomes a quadratic optimization problem, which is solved using
    
[^3]: 基于代码审查的自动程序修复: 预训练Transformer模型表现如何？

    Automated Program Repair Based on Code Review: How do Pre-trained Transformer Models Perform?. (arXiv:2304.07840v1 [cs.LG])

    [http://arxiv.org/abs/2304.07840](http://arxiv.org/abs/2304.07840)

    本研究探究使用大型预训练语言模型，结合自然语言和编程语言，来改善自动程序修复的效果，发现预训练模型通过使用代码审查和代码更改的数据集微调，能显著优于传统方法，并具有更好的泛化能力。

    

    序列到序列模型已被用于将错误的程序转换为正确的程序，当它们被训练使用足够大的数据集时。一些最近的研究也证明了代码审查(关于代码中建议性更改的自然语言指令)可以进一步改善程序修复。使用自然语言和计算机程序语料库训练的大型语言模型具有包含两种语言的固有知识的能力。在本研究中，我们探究了是否可以利用代码和自然语言的固有知识来提高自动程序修复的效果。我们将PLBART和CodeT5这两个最先进的语言模型，应用于两个基于自然语言的程序修复数据集，并发现使用包含代码审查和随后代码更改的数据集微调的预训练语言模型，明显优于之前的模型。我们观察到预训练模型具有更好的泛化能力，可以从之前未见过的数据中学习并得到更好的结果，相比之前的方法，我们的方法具有更高的修复能力，相对于之前的SOTA技术，CODET5取得了3%左右的提升

    Sequence-to-sequence models have been used to transform erroneous programs into correct ones when trained with a large enough dataset. Some recent studies also demonstrated strong empirical evidence that code review (natural language instruction about suggestive changes in code) can improve the program repair further. Large language models, trained with Natural Language (NL) and computer program corpora, have the capacity to contain inherent knowledge of both. In this study, we investigate if this inherent knowledge of code and NL can be utilized to improve automated program repair. We applied PLBART and CodeT5, two state-of-the-art language models that are pre-trained with both Programming Language (PL) and Natural Language (NL), on two such natural language-based program repair datasets and found that the pre-trained language models fine-tuned with datasets containing both code review and subsequent code changes notably outperform each of the previous models. We observed that the pre
    
[^4]: 基于Koopman模态分解的电网负载分析

    Characterizing the load profile in power grids by Koopman mode decomposition of interconnected dynamics. (arXiv:2304.07832v1 [cs.LG])

    [http://arxiv.org/abs/2304.07832](http://arxiv.org/abs/2304.07832)

    本论文介绍了一种基于Koopman算子的负载动态分解方法，能够编码电网负载动态的丰富特征，提高预测精度，同时提供有意义的解释。

    

    电力负载预测对于有效管理和优化电网至关重要。本文介绍了一种可解释的机器学习方法，利用算子理论框架内的数据驱动方法识别负载动态。我们使用Koopman算子来表示负载数据，该算子固有于底层动态。通过计算相应的特征函数，我们将负载动态分解为相干的时空模式，这些模式是动态的最强特征。每个模式根据其单一频率独立演化，基于线性动力学的可预测性。我们强调，负载动态是基于固有于动态的相干的时空模式构建的，能够在多个时间尺度上编码丰富的动态特征。这些特征与电网的物理特征（如季节性和小时模式）有关。我们的方法实现了最先进的预测准确性，同时提供了对底层动态的有意义的解释。

    Electricity load forecasting is crucial for effectively managing and optimizing power grids. Over the past few decades, various statistical and deep learning approaches have been used to develop load forecasting models. This paper presents an interpretable machine learning approach that identifies load dynamics using data-driven methods within an operator-theoretic framework. We represent the load data using the Koopman operator, which is inherent to the underlying dynamics. By computing the corresponding eigenfunctions, we decompose the load dynamics into coherent spatiotemporal patterns that are the most robust features of the dynamics. Each pattern evolves independently according to its single frequency, making its predictability based on linear dynamics. We emphasize that the load dynamics are constructed based on coherent spatiotemporal patterns that are intrinsic to the dynamics and are capable of encoding rich dynamical features at multiple time scales. These features are relate
    
[^5]: 多元纵向临床数据的时变迭代插补方法

    Time-dependent Iterative Imputation for Multivariate Longitudinal Clinical Data. (arXiv:2304.07821v1 [cs.LG])

    [http://arxiv.org/abs/2304.07821](http://arxiv.org/abs/2304.07821)

    提出一种新的TDI方法解决临床数据中的缺失值问题，通过集成前向填充和迭代插值器解决多元和纵向数据问题，采用动态加权策略处理缺失率和测量频率。

    

    缺失数据是临床研究中的一个主要挑战。在电子病历中，常常有大量的实验室检查和生命体征数值缺失。缺失数据可能导致偏倚估计并限制我们从数据中得出结论的能力。此外，许多机器学习算法只能应用于完整的数据集。一种常见的解决方案是数据补充，即填补缺失值的过程。然而，一些流行的补充方法在临床数据中表现不佳。我们开发了一种简单的新方法，称为时间依赖迭代插补 (TDI)，为填补时间序列数据提供了实用的解决方案。它通过集成前向填充和迭代插值器来处理多元和纵向数据。该集成采用基于临床数据模式的患者、变量和观测特定的动态加权策略，包括缺失率和测量频率。我们将TDI应用于随机生成的数据集和真实的临床数据集，并将其与几种广泛使用的方法进行比较。

    Missing data is a major challenge in clinical research. In electronic medical records, often a large fraction of the values in laboratory tests and vital signs are missing. The missingness can lead to biased estimates and limit our ability to draw conclusions from the data. Additionally, many machine learning algorithms can only be applied to complete datasets. A common solution is data imputation, the process of filling-in the missing values. However, some of the popular imputation approaches perform poorly on clinical data. We developed a simple new approach, Time-Dependent Iterative imputation (TDI), which offers a practical solution for imputing time-series data. It addresses both multivariate and longitudinal data, by integrating forward-filling and Iterative Imputer. The integration employs a patient, variable, and observation-specific dynamic weighting strategy, based on the clinical patterns of the data, including missing rates and measurement frequency. We tested TDI on random
    
[^6]: MPPT与PV电池参数估计的比较研究

    Comparative Study of MPPT and Parameter Estimation of PV cells. (arXiv:2304.07817v1 [cs.LG])

    [http://arxiv.org/abs/2304.07817](http://arxiv.org/abs/2304.07817)

    本研究使用机器学习技术，利用人工神经网络算法精确地估计了太阳能电池和光伏模块的PVLIB模型参数，精度超过95％。

    

    本研究旨在利用机器学习技术准确估计太阳能电池和光伏模块的PVLIB模型的已知和未知参数的准确值。使用了人工神经网络（ANN）算法，该算法在计算效率方面优于其他元启发式和机器学习算法。通过辐照度和温度基于其他机器学习算法进行比较，进行了布兰德-奥尔特曼（Bland Altman）测试并得出了超过95％的准确度。验证后，使用ANN算法估计参数及其相应值。

    The presented work focuses on utilising machine learning techniques to accurately estimate accurate values for known and unknown parameters of the PVLIB model for solar cells and photovoltaic modules.Finding accurate model parameters of circuits for photovoltaic (PV) cells is important for a variety of tasks. An Artificial Neural Network (ANN) algorithm was employed, which outperformed other metaheuristic and machine learning algorithms in terms of computational efficiency. To validate the consistency of the data and output, the results were compared against other machine learning algorithms based on irradiance and temperature. A Bland Altman test was conducted that resulted in more than 95 percent accuracy rate. Upon validation, the ANN algorithm was utilised to estimate the parameters and their respective values.
    
[^7]: VISAR：一种带有可视化编程和快速草案原型的人工智能论证写作助手

    VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])

    [http://arxiv.org/abs/2304.07810](http://arxiv.org/abs/2304.07810)

    VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。

    

    在辩论写作中，作者必须构思分层写作目标，确保其论点的说服力，并通过起草来修订和组织他们的计划。最近大型语言模型（LLM）的进展使得通过聊天界面进行交互式文本生成（例如ChatGPT）成为可能。然而，这种方法常常忽略了隐含的写作上下文和用户意图，缺乏用户控制和自主权，并且提供有限的帮助来进行意义构建和修订写作计划。为了应对这些挑战，我们引入了VISAR，一种AI支持的写作助手系统，旨在帮助作者在其写作上下文中构思和修订分层目标，通过同步文本编辑和可视化编程组织论证结构，并通过论证火花推荐增强说服力。VISAR允许用户使用自动草案原型探索、实验和验证他们的写作计划。一个受控实验室研究证实，VISAR可以通过客观和主观评估，有效地改善用户的写作体验和结果。

    In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confi
    
[^8]: 基于模糊概率决策树的临床实践辅助研究

    Assisting clinical practice with fuzzy probabilistic decision trees. (arXiv:2304.07788v1 [cs.LG])

    [http://arxiv.org/abs/2304.07788](http://arxiv.org/abs/2304.07788)

    我们提出了一种基于概率树和模糊逻辑的新方法MedFP，用于辅助医学实践。该方法可以完全解释，允许临床医生产生、控制和验证整个诊断过程，并减少误诊率，通过提供不确定性和反事实分析的估计值。

    

    越来越多的人意识到需要完全人类可理解的模型，这是人工智能研究的一个核心主题。当这些模型是可解释的时，接受人工智能模型辅助敏感领域决策的趋势将会增长，并且即将出台的法规将会加强对可解释模型的倾斜。可解释人工智能的切入点之一是医学实践，它可以受益于精确的决策支持方法，这些方法本质上会产生信任。在这项工作中，我们提出了一种新的方法——MedFP，它结合了概率树和模糊逻辑来辅助临床实践。该方法完全可解释，因为它允许临床医生产生、控制和验证整个诊断过程；该方法的一个优点是减少误诊率，通过提供不确定性和反事实分析的估计值。我们的方法作为概念证明应用于两个真实的医学场景中：肿瘤分类和糖尿病类型2的诊断。

    The need for fully human-understandable models is increasingly being recognised as a central theme in AI research. The acceptance of AI models to assist in decision making in sensitive domains will grow when these models are interpretable, and this trend towards interpretable models will be amplified by upcoming regulations. One of the killer applications of interpretable AI is medical practice, which can benefit from accurate decision support methodologies that inherently generate trust. In this work, we propose FPT, (MedFP), a novel method that combines probabilistic trees and fuzzy logic to assist clinical practice. This approach is fully interpretable as it allows clinicians to generate, control and verify the entire diagnosis procedure; one of the methodology's strength is the capability to decrease the frequency of misdiagnoses by providing an estimate of uncertainties and counterfactuals. Our approach is applied as a proof-of-concept to two real medical scenarios: classifying ma
    
[^9]: 利用数字病理学和因果学习改进嗜酸性食管炎膳食治疗分配

    Harnessing Digital Pathology And Causal Learning To Improve Eosinophilic Esophagitis Dietary Treatment Assignment. (arXiv:2304.07787v1 [cs.LG])

    [http://arxiv.org/abs/2304.07787](http://arxiv.org/abs/2304.07787)

    本研究利用人工智能技术和因果学习模型，推断EoE的组织学特征和制定个性化的食物消除计划，以改进EoE的治疗效果。

    

    嗜酸性食管炎（EoE）是一种与食物过敏炎症有关的慢性疾病，与食管嗜酸性粒细胞升高有关。EoE是GERD后慢性吞咽困难的主要原因之一。EoE的诊断依赖于计数组织学切片中的嗜酸性粒细胞，这是一项手动且耗时的任务，限制了提取复杂的患者相关特征的能力。EoE的治疗包括药物和食物消除。个性化的食物消除计划对于患者的参与和治疗效果至关重要，但先前的尝试未能产生显著的结果。在这项工作中，我们一方面利用人工智能从整个活检切片中推断组织学特征，这些特征无法手动提取。另一方面，我们开发了因果学习模型来处理这些丰富的数据。我们将我们的方法应用于“六种食物与一种食物嗜酸性食管炎饮食研究”，针对112名18-60岁的有症状成年患者进行了研究。

    Eosinophilic esophagitis (EoE) is a chronic, food antigen-driven, allergic inflammatory condition of the esophagus associated with elevated esophageal eosinophils. EoE is a top cause of chronic dysphagia after GERD. Diagnosis of EoE relies on counting eosinophils in histological slides, a manual and time-consuming task that limits the ability to extract complex patient-dependent features. The treatment of EoE includes medication and food elimination. A personalized food elimination plan is crucial for engagement and efficiency, but previous attempts failed to produce significant results. In this work, on the one hand, we utilize AI for inferring histological features from the entire biopsy slide, features that cannot be extracted manually. On the other hand, we develop causal learning models that can process this wealth of data. We applied our approach to the 'Six-Food vs. One-Food Eosinophilic Esophagitis Diet Study', where 112 symptomatic adults aged 18-60 years with active EoE were 
    
[^10]: 自然语言到SPARQL查询生成的复制机制综合评估

    A Comprehensive Evaluation of the Copy Mechanism for Natural Language to SPARQL Query Generation. (arXiv:2304.07772v1 [cs.CL])

    [http://arxiv.org/abs/2304.07772](http://arxiv.org/abs/2304.07772)

    本研究综合评估自然语言到SPARQL查询生成中的复制机制，通过大量实验研究预训练和非预训练模型、问题注释格式以及使用复制机制的影响，并证明了在这些方面的优化可以提高性能。

    

    近年来，神经机器翻译（NMT）领域在SPARQL查询生成方面有了显著的增长。最近，将复制机制与传统的编码器-解码器架构相结合，并使用预训练的编码器-解码器，创造了新的性能基准。本文展示了大量的实验，复制并扩展了最近的基于NMT的SPARQL生成研究，比较了预训练和非预训练模型、问题注释格式以及对于非预训练和预训练模型使用复制机制的影响。我们的结果表明，对于非预训练模型和预训练模型，添加复制机制或使用问题注释都可以提高性能，并为三个流行数据集设置了新的基准。

    In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed a significant growth. Recently, the incorporation of the copy mechanism with traditional encoder-decoder architectures and the use of pre-trained encoder-decoders have set new performance benchmarks. This paper presents a large variety of experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained and non-pre-trained models, question annotation formats, and the use of a copy mechanism for non-pre-trained and pre-trained models. Our results show that either adding the copy mechanism or using a question annotation improves performances for nonpre-trained models and for pre-trained models, setting new baselines for three popular datasets.
    
[^11]: 正则化完整循环一致性GAN用于异常检测

    Regularized Complete Cycle Consistent GAN for Anomaly Detection. (arXiv:2304.07769v1 [cs.LG])

    [http://arxiv.org/abs/2304.07769](http://arxiv.org/abs/2304.07769)

    本研究提出了RCALAD方法，通过循环一致性和新的鉴别器增强了GAN在异常检测中的效果。同时，利用补充分布引导重建和引入新的异常评分进一步提高了模型性能。

    

    本研究提出了一种用于实际应用中异常检测的对抗性方法，通过重建误差中循环一致性利用生成对抗神经网络（GAN）的威力。以往的方法由于类别间精度高度差异而未被应用于所有类型的异常情况。RCALAD是一种旨在通过将新的鉴别器引入到结构中来解决这个问题的方法，从而实现更高效的训练过程。此外，RCALAD在输入空间中使用补充分布，将重建引导到正常数据分布，有效地将异常样本与其重建分离，进而实现更准确的异常检测。为了进一步提高模型的性能，引入了两个新的异常评分。在六个不同数据集的大量实验中对所提出的模型进行了全面评估，得出了展示出其优越性能的结果。

    This study presents an adversarial method for anomaly detection in real-world applications, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Previous methods suffer from the high variance between class-wise accuracy which leads to not being applicable for all types of anomalies. The proposed method named RCALAD tries to solve this problem by introducing a novel discriminator to the structure, which results in a more efficient training process. Additionally, RCALAD employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution, effectively separating anomalous samples from their reconstructions and facilitating more accurate anomaly detection. To further enhance the performance of the model, two novel anomaly scores are introduced. The proposed model has been thoroughly evaluated through extensive experiments on six various datasets, yielding results that demonst
    
[^12]: Data-OOB:以无需额外计算的Out-of-bag估计为准的数据价值估计方法

    Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value. (arXiv:2304.07718v1 [cs.LG])

    [http://arxiv.org/abs/2304.07718](http://arxiv.org/abs/2304.07718)

    Data-OOB是一种新的数据价值估计方法，它利用out-of-bag估计，并可以在计算上高效处理大型数据集。

    

    数据评估是一个强大的框架，可以为模型训练提供统计洞察力，以区分哪些数据对于模型训练是有益的，哪些是有害的。纵观各种下游任务，许多以Shapley为基础的数据价值评估方法均显示出了很有前途的结果。然而，由于这需要训练大量的模型，因此众所周知，这是具有挑战性的。因此，将此应用于大型数据集是不可行的。为了解决这个问题，我们提出了Data-OOB，这是一种新的数据价值估计方法，针对bagging模型，它利用了out-of-bag估计。所提出的方法在计算上是高效的，可以通过重复使用训练好的弱学习器来扩展到数百万个数据。具体而言，当评估100个输入维度且存在$10^6$个样本时，Data-OOB仅需要在单个CPU处理器上执行不到2.25个小时。此外，Data-OOB在理论上有坚实的解释，当两个离差值函数相同时，其识别具有相同重要性的数据点。

    Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two d
    
[^13]: 用BREC数据集更好地评估GNN表达力

    Towards Better Evaluation of GNN Expressiveness with BREC Dataset. (arXiv:2304.07702v1 [cs.LG])

    [http://arxiv.org/abs/2304.07702](http://arxiv.org/abs/2304.07702)

    本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    

    关于图神经网络（GNN）的理论表达力的研究得到了快速发展，并提出了许多增强表达力的方法。然而，除了严格遵循k维Weisfeiler-Lehman（k-WL）测试层次结构的少数方法外，大多数方法都没有统一的表达力度量。它们的理论分析通常限于区分某些非同构图族，导致在定量比较表达力方面存在困难。与理论分析相反，衡量表达能力的另一种方法是在包含1-WL不可区分图的特定数据集上评估模型性能。然而，以前专门设计用于此目的的数据集面临着难度（任何超越1-WL的模型准确率几乎达到100％）、粒度（模型倾向于要么完全正确，要么接近随机猜测）和规模（每个数据集中仅有少量本质不同的图）的问题。为了解决这些受限制的评估问题，我们提出了一个新的GNN鲁棒性评估基准（BREC），该基准包含许多结构多样的图，并允许对模型表达力进行更精细的评估。我们使用BREC评估了几种现有的GNN模型的表达力，并展示了一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    Research on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often limited to distinguishing certain families of non-isomorphic graphs, leading to difficulties in quantitatively comparing their expressiveness. In contrast to theoretical analysis, another way to measure expressiveness is by evaluating model performance on certain datasets containing 1-WL-indistinguishable graphs. Previous datasets specifically designed for this purpose, however, face problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only a few essentially different graphs in each dataset). To address these limi
    
[^14]: 学习经验Bregman散度用于不确定距离表示

    Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])

    [http://arxiv.org/abs/2304.07689](http://arxiv.org/abs/2304.07689)

    本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。

    

    深度度量学习技术已应用于各种监督和无监督学习任务，通过深度网络学习样本嵌入来进行视觉表示。然而，经典方法采用固定距离度量作为两个嵌入之间的相似性函数，可能导致捕捉复杂数据分布的亚最优性能。Bregman散度概括了各种距离度量的度量，并在许多深度度量学习领域中产生。本文首先展示了如何从Bregman散度获得深度度量学习损失。然后，我们介绍了一种直接从数据中学习经验Bregman散度的新方法，通过使用深度学习设置对Bregman散度下的凸函数进行参数化。我们进一步实验证明，与其他SOTA深度度量学习方法相比，我们的方法在五个流行公共数据集上表现出色，特别是在模式识别和聚类任务上。

    Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
    
[^15]: MLRegTest：机器学习正则语言的基准测试

    MLRegTest: A Benchmark for the Machine Learning of Regular Languages. (arXiv:2304.07687v1 [cs.LG])

    [http://arxiv.org/abs/2304.07687](http://arxiv.org/abs/2304.07687)

    本文提出了一个名为MLRegTest的新基准测试，其包含了来自1,800个正则语言的数据集。该测试根据逻辑复杂度和逻辑文字种类组织语言，并可以帮助我们了解机器学习系统在学习不同种类的长距离依赖方面的性能。

    

    评估机器学习系统对已知分类器的学习能力允许细致地检查它们可以学习哪些模式，并在将它们应用于未知分类器的学习时建立信心。本文提出了一个名为MLRegTest的新的序列分类机器学习系统基准测试，其中包含来自1,800个正则语言的训练、开发和测试集。不同类型的形式语言代表着不同种类的长距离依赖，并正确地识别序列中的长距离依赖是机器学习系统成功泛化的已知挑战。MLRegTest根据它们的逻辑复杂度（单调二阶，一阶，命题或单项式表达式）和逻辑文字的种类（字符串，定级字符串，子序列或两者的组合）组织其语言。逻辑复杂度和文字的选择提供了一种系统方法来理解不同种类的长距离依赖和机器学习系统在处理它们时的性能。

    Evaluating machine learning (ML) systems on their ability to learn known classifiers allows fine-grained examination of the patterns they can learn, which builds confidence when they are applied to the learning of unknown classifiers. This article presents a new benchmark for ML systems on sequence classification called MLRegTest, which contains training, development, and test sets from 1,800 regular languages.  Different kinds of formal languages represent different kinds of long-distance dependencies, and correctly identifying long-distance dependencies in sequences is a known challenge for ML systems to generalize successfully. MLRegTest organizes its languages according to their logical complexity (monadic second order, first order, propositional, or monomial expressions) and the kind of logical literals (string, tier-string, subsequence, or combinations thereof). The logical complexity and choice of literal provides a systematic way to understand different kinds of long-distance d
    
[^16]: 在生存分析中使用基于地理位置的公共卫生特征

    Using Geographic Location-based Public Health Features in Survival Analysis. (arXiv:2304.07679v1 [cs.LG])

    [http://arxiv.org/abs/2304.07679](http://arxiv.org/abs/2304.07679)

    本文提出了在生存分析中使用基于地理位置的公共卫生特征，提高了患者预测的准确性，特别是在公共卫生数据的地理分辨率较高时，效果更加明显。

    

    时间信息是一种常用的建模方式，通常使用生存分析方法来估计基于输入特征的生存得分。近年来，使用神经网络等现代工具开发更准确的个性化医疗时间预测模型引起了广泛关注。更高质量的特征和更频繁的观测有助于提高患者的预测结果，然而，加入患者基于地理位置的公共卫生统计数据对个体预测的影响尚未研究。本文提出了一种补充改进生存分析模型的方法，即将公共卫生统计信息纳入输入特征。我们证明在包含全国性癌症发病数据的 Surveillance，Epidemiology 和 End Results（SEER）数据集上，包含地理定位的公共健康信息可以显著提高一致性指数。特别是在公共卫生数据的地理分辨率较高时，这种改进效果更加明显，并以亚特兰大和旧金山地区的癌症发病病例研究为例。

    Time elapsed till an event of interest is often modeled using the survival analysis methodology, which estimates a survival score based on the input features. There is a resurgence of interest in developing more accurate prediction models for time-to-event prediction in personalized healthcare using modern tools such as neural networks. Higher quality features and more frequent observations improve the predictions for a patient, however, the impact of including a patient's geographic location-based public health statistics on individual predictions has not been studied. This paper proposes a complementary improvement to survival analysis models by incorporating public health statistics in the input features. We show that including geographic location-based public health information results in a statistically significant improvement in the concordance index evaluated on the Surveillance, Epidemiology, and End Results (SEER) dataset containing nationwide cancer incidence data. The improv
    
[^17]: 基于方向特征交互的黑盒模型解释

    Explanations of Black-Box Models based on Directional Feature Interactions. (arXiv:2304.07670v1 [cs.LG])

    [http://arxiv.org/abs/2304.07670](http://arxiv.org/abs/2304.07670)

    该论文提出了一种双变量解释方法，可以通过方向特征交互捕获黑盒模型中的特征交互。该方法在Shapley值解释中应用，并在多个数据集上证明了其优越性。

    

    随着机器学习算法在各种领域得到广泛应用，使其常常是黑盒模型变得透明化非常重要。几个最近的工作通过抓取每个实例的最具影响力的预测特征来解释黑盒模型;这种解释方法是单变量的，因为它们表征每个特征的重要性。我们将单变量解释扩展到高阶，通过双变量方法增强了可解释性。这种双变量方法可以捕获黑盒模型中的特征交互，并将其表示为有向图。分析这个图可以发现同等重要的特征组，而方向性的概念使我们能够确定最具影响力的特征。我们将我们的双变量方法应用于Shapley值解释，并实验性地展示了方向性解释发现特征交互的能力。我们证明了我们的方法在CIFAR10、IMDB、Census和CelebA数据集上的优越性。

    As machine learning algorithms are deployed ubiquitously to a variety of domains, it is imperative to make these often black-box models transparent. Several recent works explain black-box models by capturing the most influential features for prediction per instance; such explanation methods are univariate, as they characterize importance per feature. We extend univariate explanation to a higher-order; this enhances explainability, as bivariate methods can capture feature interactions in black-box models, represented as a directed graph. Analyzing this graph enables us to discover groups of features that are equally important (i.e., interchangeable), while the notion of directionality allows us to identify the most influential features. We apply our bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. We show the superiority of our method against state-of-the-art on CIFAR10, IMDB, Census,
    
[^18]: FedBlockHealth：基于联邦学习和区块链的IoT医疗保健隐私和安全协同方法

    FedBlockHealth: A Synergistic Approach to Privacy and Security in IoT-Enabled Healthcare through Federated Learning and Blockchain. (arXiv:2304.07668v1 [cs.CR])

    [http://arxiv.org/abs/2304.07668](http://arxiv.org/abs/2304.07668)

    本文提出了一种基于联邦学习和区块链技术的创新方法，为IoT医疗保健应用提供安全和隐私保护的解决方案，实现了安全的模型聚合，同时不共享敏感患者数据。

    

    在医疗保健领域，物联网设备的广泛应用给数据隐私、安全和患者安全带来新的挑战。传统的方法需要保证安全和隐私，同时保持计算效率，特别是对于资源受限的物联网设备。本文提出了一种创新的混合方法，结合了联邦学习和区块链技术，为IoT医疗保健应用提供安全和隐私保护的解决方案。我们的方法利用公钥加密系统为本地模型更新提供语义安全，而区块链技术确保这些更新的完整性并强制访问控制和问责制。联邦学习过程实现了安全的模型聚合，同时不共享敏感患者数据。我们使用EMNIST数据集实现和评估了我们提出的框架，证明了在保持计算效率的同时，有效地保护了数据隐私和安全。

    The rapid adoption of Internet of Things (IoT) devices in healthcare has introduced new challenges in preserving data privacy, security and patient safety. Traditional approaches need to ensure security and privacy while maintaining computational efficiency, particularly for resource-constrained IoT devices. This paper proposes a novel hybrid approach combining federated learning and blockchain technology to provide a secure and privacy-preserved solution for IoT-enabled healthcare applications. Our approach leverages a public-key cryptosystem that provides semantic security for local model updates, while blockchain technology ensures the integrity of these updates and enforces access control and accountability. The federated learning process enables a secure model aggregation without sharing sensitive patient data. We implement and evaluate our proposed framework using EMNIST datasets, demonstrating its effectiveness in preserving data privacy and security while maintaining computatio
    
[^19]: 贝叶斯分层建模中主动学习回归中的动态探索-开发权衡

    Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling. (arXiv:2304.07665v1 [cs.LG])

    [http://arxiv.org/abs/2304.07665](http://arxiv.org/abs/2304.07665)

    本文提出了一个新方法，利用贝叶斯分层建模，动态平衡探索-开发权衡，以更好地查询数据点。

    

    主动学习提供了一种自适应采样最具信息的实验以学习未知的黑盒函数的框架。本文提出了一种贝叶斯分层方法来动态平衡探索-开发权衡，以更好地查询数据点。

    Active learning provides a framework to adaptively sample the most informative experiments towards learning an unknown black-box function. Various approaches of active learning have been proposed in the literature, however, they either focus on exploration or exploitation in the design space. Methods that do consider exploration-exploitation simultaneously employ fixed or ad-hoc measures to control the trade-off that may not be optimal. In this paper, we develop a Bayesian hierarchical approach to dynamically balance the exploration-exploitation trade-off as more data points are queried. We subsequently formulate an approximate Bayesian computation approach based on the linear dependence of data samples in the feature space to sample from the posterior distribution of the trade-off parameter obtained from the Bayesian hierarchical model. Simulated and real-world examples show the proposed approach achieves at least 6% and 11% average improvement when compared to pure exploration and ex
    
[^20]: 作为概率推断的降维方法

    Dimensionality Reduction as Probabilistic Inference. (arXiv:2304.07658v1 [stat.ML])

    [http://arxiv.org/abs/2304.07658](http://arxiv.org/abs/2304.07658)

    该论文提出了ProbDR变分框架，将经典降维算法解释为概率推断算法，通过优化一个证据下界来完成推断操作。该框架不仅可以完成常规降维算法，还支持使用概率编程语言进行降维操作，具有强大的表达能力。

    

    降维算法将高维数据压缩到低维表示中，同时保留数据的重要特征。降维是许多分析流程中的关键步骤，因为它实现了数据的可视化、噪声降低和高效的下游处理。在本文中，我们引入了ProbDR变分框架，将广泛的经典DR算法解释为该框架中的概率推断算法。ProbDR包括PCA、CMDS、LLE、LE、MVU、扩散映射、kPCA、Isomap、(t-)SNE和UMAP。在我们的框架中，一个低维潜变量用于构建协方差、精度或图拉普拉斯矩阵，可以作为数据的生成模型的一部分。推断是通过优化一个证据下界来完成的。我们展示了我们框架的内部一致性，并表明它支持使用概率编程语言（PPL）进行DR。此外，我们证明了该框架可以完成常规DR算法的操作，并赋予了它通过概率变分推断的强大表达力。

    Dimensionality reduction (DR) algorithms compress high-dimensional data into a lower dimensional representation while preserving important features of the data. DR is a critical step in many analysis pipelines as it enables visualisation, noise reduction and efficient downstream processing of the data. In this work, we introduce the ProbDR variational framework, which interprets a wide range of classical DR algorithms as probabilistic inference algorithms in this framework. ProbDR encompasses PCA, CMDS, LLE, LE, MVU, diffusion maps, kPCA, Isomap, (t-)SNE, and UMAP. In our framework, a low-dimensional latent variable is used to construct a covariance, precision, or a graph Laplacian matrix, which can be used as part of a generative model for the data. Inference is done by optimizing an evidence lower bound. We demonstrate the internal consistency of our framework and show that it enables the use of probabilistic programming languages (PPLs) for DR. Additionally, we illustrate that the f
    
[^21]: EEG SN：面向 EEG 的图形脉冲神经网络的高效低延迟解码

    EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks. (arXiv:2304.07655v1 [cs.NE])

    [http://arxiv.org/abs/2304.07655](http://arxiv.org/abs/2304.07655)

    该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。

    

    目前大多数脉冲神经网络（SNN）的训练依赖于归纳偏差，这并不一定适用于多个需要低延迟和功耗效率的关键任务。 基于相关的脑电图（EEG）信号推断大脑行为就是一个这样的例子，学习时空依赖关系会严重影响网络的训练和推断效率。目前，SNN仅仅依靠一般归纳偏差来模拟不同数据流之间的动态关系。在这里，我们提出了一种用于多通道 EEG 分类的图形脉冲神经网络架构（EEGSN），它能够学习分布在 EEG 传感器中的动态关系信息。与现有技术相比，我们的方法将推断计算复杂度降低了20倍，同时在运动执行分类任务上达到了可比较的准确性。总体而言，我们的工作为可解释和高效训练 EEG 数据的图形SNN提供了一个框架，从而实现了低延迟和功耗效率的脑-计算机界面的开发。

    A vast majority of spiking neural networks (SNNs) are trained based on inductive biases that are not necessarily a good fit for several critical tasks that require low-latency and power efficiency. Inferring brain behavior based on the associated electroenchephalography (EEG) signals is an example of how networks training and inference efficiency can be heavily impacted by learning spatio-temporal dependencies. Up to now, SNNs rely solely on general inductive biases to model the dynamic relations between different data streams. Here, we propose a graph spiking neural network architecture for multi-channel EEG classification (EEGSN) that learns the dynamic relational information present in the distributed EEG sensors. Our method reduced the inference computational complexity by $\times 20$ compared to the state-of-the-art SNNs, while achieved comparable accuracy on motor execution classification tasks. Overall, our work provides a framework for interpretable and efficient training of gr
    
[^22]: 基于学习的插值算法在流数据分位数估计中的应用与性能保障（arXiv:2304.07652v1 [cs.DS]）

    Learned Interpolation for Better Streaming Quantile Approximation with Worst-Case Guarantees. (arXiv:2304.07652v1 [cs.DS])

    [http://arxiv.org/abs/2304.07652](http://arxiv.org/abs/2304.07652)

    本文探索了应用基于学习的插值算法来提高流数据分位数问题的实际性能，同时保持在最坏情况下的可控保障。

    

    一种$\varepsilon$近似分位数草图，对于由$n$个输入组成的流，它可以在消耗$o(n)$空间之下，以至少$1-1/\mathrm{poly}(n)$的概率近似计算出任何查询点$q$的排名 - 即小于$q$的输入点数，具有$\varepsilon n$的附加误差。虽然Karnin、Lang和Liberty的KLL算法已被证明可以在最坏情况下实现最优的分位数估计算法，但它在实际应用中所实现的估计往往远远不如最优。事实上，实践中最常用的技术是Dunning的$t$-digest，在真实世界的数据上往往比KLL实现更好的近似效果，但已知在最坏情况下误差可以任意大。本文将插值技术应用于流式取分位数问题，以试图在保持类似的最坏情况保障的同时，在真实世界的数据集上实现更好的近似效果。

    An $\varepsilon$-approximate quantile sketch over a stream of $n$ inputs approximates the rank of any query point $q$ - that is, the number of input points less than $q$ - up to an additive error of $\varepsilon n$, generally with some probability of at least $1 - 1/\mathrm{poly}(n)$, while consuming $o(n)$ space. While the celebrated KLL sketch of Karnin, Lang, and Liberty achieves a provably optimal quantile approximation algorithm over worst-case streams, the approximations it achieves in practice are often far from optimal. Indeed, the most commonly used technique in practice is Dunning's t-digest, which often achieves much better approximations than KLL on real-world data but is known to have arbitrarily large errors in the worst case. We apply interpolation techniques to the streaming quantiles problem to attempt to achieve better approximations on real-world data sets than KLL while maintaining similar guarantees in the worst case.
    
[^23]: LASER：神经符号学习语义视频表示

    LASER: Neuro-Symbolic Learning of Semantic Video Representations. (arXiv:2304.07647v1 [cs.CV])

    [http://arxiv.org/abs/2304.07647](http://arxiv.org/abs/2304.07647)

    LASER提出了一种神经符号学习方法来学习语义视频表示，通过逻辑规范捕捉视频数据中的时空属性，能够对齐原始视频和规范，有效地训练低级感知模型以提取符合所需高级规范的视频表示。

    

    现代涉及视频的AI应用（如视频-文本对齐、视频搜索和视频字幕）受益于对视频语义的细致理解。现有的视频理解方法要么需要大量注释，要么基于不可解释的通用嵌入，可能会忽略重要细节。我们提出了LASER，这是一种神经符号方法，通过利用能够捕捉视频数据中丰富的时空属性的逻辑规范来学习语义视频表示。特别地，我们通过原始视频与规范之间的对齐来公式化问题。对齐过程有效地训练了低层感知模型，以提取符合所需高层规范的细粒度视频表示。我们的流程可以端到端地训练，并可纳入从规范导出的对比和语义损失函数。我们在两个具有丰富空间和时间信息的数据集上评估了我们的方法。

    Modern AI applications involving video, such as video-text alignment, video search, and video captioning, benefit from a fine-grained understanding of video semantics. Existing approaches for video understanding are either data-hungry and need low-level annotation, or are based on general embeddings that are uninterpretable and can miss important details. We propose LASER, a neuro-symbolic approach that learns semantic video representations by leveraging logic specifications that can capture rich spatial and temporal properties in video data. In particular, we formulate the problem in terms of alignment between raw videos and specifications. The alignment process efficiently trains low-level perception models to extract a fine-grained video representation that conforms to the desired high-level specification. Our pipeline can be trained end-to-end and can incorporate contrastive and semantic loss functions derived from specifications. We evaluate our method on two datasets with rich sp
    
[^24]: 针对稳定的超网络学习的非比例参数化

    Non-Proportional Parametrizations for Stable Hypernetwork Learning. (arXiv:2304.07645v1 [cs.LG])

    [http://arxiv.org/abs/2304.07645](http://arxiv.org/abs/2304.07645)

    本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。

    

    超网络是生成另一个神经网络参数的神经网络。在许多情况下，当前的超网络训练策略是不稳定的，收敛速度通常比非超网络模型慢得多。我们展示了这个问题与使用常见的超网络架构和初始化时出现的问题有关。我们在理论上和实验上证明了这种数值问题在训练过程中会导致不稳定性，从而降低甚至阻止收敛。我们还证明了流行的深度学习归一化策略无法解决这些问题。然后，我们提出了一种基于修订的超网络形式的解决方案，该超网络使用非比例加性参数化。我们在几个任务上测试了所提出的重新参数化，并证明它始终可以导致更稳定的训练，实现更快的收敛。

    Hypernetworks are neural networks that generate the parameters of another neural network. In many scenarios, current hypernetwork training strategies are unstable, and convergence is often far slower than for non-hypernetwork models. We show that this problem is linked to an issue that arises when using common choices of hypernetwork architecture and initialization. We demonstrate analytically and experimentally how this numerical issue can lead to an instability during training that slows, and sometimes even prevents, convergence. We also demonstrate that popular deep learning normalization strategies fail to address these issues. We then propose a solution to the problem based on a revised hypernetwork formulation that uses non-proportional additive parametrizations. We test the proposed reparametrization on several tasks, and demonstrate that it consistently leads to more stable training, achieving faster convergence.
    
[^25]: 弦图中的因果模型

    Causal models in string diagrams. (arXiv:2304.07638v1 [cs.LO])

    [http://arxiv.org/abs/2304.07638](http://arxiv.org/abs/2304.07638)

    本文提出了一种使用弦图语言中的网络图来建立因果模型的方法，在对称单调范畴中对这些模型进行了形式化，扩展了因果贝叶斯网络和结构性因果模型，并形式化了对模型的一般干预，提供了一种可直观且严格推理的方法。

    

    因果模型的框架提供了一种原则性的因果推理方法，今天已应用于许多科学领域。在这里，我们使用范畴论来形式化地解释弦图语言中的因果模型。一类称为网络图的弦图与有向无环图一一对应。使用具有“复制-丢弃”结构的对称单调范畴中的随机映射、函数或一般通道作为模型的组件，给出了这样一个图表来表示一个因果模型，将模型转化为一个可以直观并严格推理的单一数学对象。建立在Fong和Jacobs、Kissinger和Zanasi以及Fritz和Klingler之前的工作基础上，我们在cd-范畴中提出了因果模型和功能因果模型的图表定义，这扩展了因果贝叶斯网络和结构性因果模型，分别形式化了对模型的一般干预。

    The framework of causal models provides a principled approach to causal reasoning, applied today across many scientific domains. Here we present this framework in the language of string diagrams, interpreted formally using category theory. A class of string diagrams, called network diagrams, are in 1-to-1 correspondence with directed acyclic graphs. A causal model is given by such a diagram with its components interpreted as stochastic maps, functions, or general channels in a symmetric monoidal category with a 'copy-discard' structure (cd-category), turning a model into a single mathematical object that can be reasoned with intuitively and yet rigorously. Building on prior works by Fong and Jacobs, Kissinger and Zanasi, as well as Fritz and Klingler, we present diagrammatic definitions of causal models and functional causal models in a cd-category, generalising causal Bayesian networks and structural causal models, respectively. We formalise general interventions on a model, including
    
[^26]: TransDocs：基于词级翻译的光学字符识别技术

    TransDocs: Optical Character Recognition with word to word translation. (arXiv:2304.07637v1 [cs.CV])

    [http://arxiv.org/abs/2304.07637](http://arxiv.org/abs/2304.07637)

    本研究采用LSTM-based seq2seq架构和带有注意力机制的深度学习模型，将OCR技术与词级翻译相结合，提高了文档转换的性能。

    

    虽然OCR技术已经应用于各种应用，但其输出并不总是准确的，导致错配字词。本研究旨在运用机器学习技术改善OCR技术，将OCR技术与基于LSTM的序列到序列深度学习模型整合以进行文档翻译，并基于ANKI数据集进行英语到西班牙语的翻译。本研究通过比较使用LSTM-based seq2seq架构和带有注意力机制的深度学习模型预训练OCR的性能，展示了端到端模型的性能表现。本研究面向对OCR技术及其在文档翻译中应用感兴趣的研究人员和实践者。

    While OCR has been used in various applications, its output is not always accurate, leading to misfit words. This research work focuses on improving the optical character recognition (OCR) with ML techniques with integration of OCR with long short-term memory (LSTM) based sequence to sequence deep learning models to perform document translation. This work is based on ANKI dataset for English to Spanish translation. In this work, I have shown comparative study for pre-trained OCR while using deep learning model using LSTM-based seq2seq architecture with attention for machine translation. End-to-end performance of the model has been expressed in BLEU-4 score. This research paper is aimed at researchers and practitioners interested in OCR and its applications in document translation.
    
[^27]: 采用可解释的符号化神经模型检测上下文不符的多模态谣言

    Detecting Out-of-Context Multimodal Misinformation with interpretable neural-symbolic model. (arXiv:2304.07633v1 [cs.CL])

    [http://arxiv.org/abs/2304.07633](http://arxiv.org/abs/2304.07633)

    本论文提出了一种可解释的神经符号模型，用于检测上下文不符的虚假多模态信息，帮助事实检查网站进行记录澄清。

    

    近年来，虚假信息的演化持续增长，旨在影响公众舆论。与传统的谣言或虚假新闻编辑主要依赖于生成和/或伪造的图像、文本和视频不同，当前的虚假信息创作者更倾向于使用上下文不匹配的多媒体内容（例如，不匹配的图像和标题）来欺骗公众和虚假新闻检测系统。这种新型的虚假信息不仅增加了检测的难度，也增加了澄清的难度，因为每个单独的模态都足够接近真实信息。为了解决这个问题，在本文中，我们探讨了如何实现可解释的跨模态去上下文检测，同时识别不匹配的对和跨模态矛盾，这对事实检查网站的记录澄清非常有帮助。所提出的模型首先通过抽象多模态信息，基于Abstract M进行符号化分解，得到一组事实查询。

    Recent years have witnessed the sustained evolution of misinformation that aims at manipulating public opinions. Unlike traditional rumors or fake news editors who mainly rely on generated and/or counterfeited images, text and videos, current misinformation creators now more tend to use out-of-context multimedia contents (e.g. mismatched images and captions) to deceive the public and fake news detection systems. This new type of misinformation increases the difficulty of not only detection but also clarification, because every individual modality is close enough to true information. To address this challenge, in this paper we explore how to achieve interpretable cross-modal de-contextualization detection that simultaneously identifies the mismatched pairs and the cross-modal contradictions, which is helpful for fact-check websites to document clarifications. The proposed model first symbolically disassembles the text-modality information to a set of fact queries based on the Abstract M
    
[^28]: 基于纯净/不纯的N2增油过程中最小相溶压力（MMP）的估计：统计学和机器学习算法的比较研究。

    Estimation of minimum miscibility pressure (MMP) in impure/pure N2 based enhanced oil recovery process: A comparative study of statistical and machine learning algorithms. (arXiv:2304.07617v1 [cs.LG])

    [http://arxiv.org/abs/2304.07617](http://arxiv.org/abs/2304.07617)

    本研究比较了统计学和机器学习方法用于估计N2增油过程中的最小相溶压力，表明本研究开发的预测模型具有更好的性能。

    

    最小相溶压力（MMP）的预测在设计和操作基于氮的增油过程中起着重要作用。本文进行了统计学和机器学习方法用于MMP估计的比较研究。本研究开发的大多数预测模型显示出比文献中报告的相关和预测模型更优越的性能。

    Minimum miscibility pressure (MMP) prediction plays an important role in design and operation of nitrogen based enhanced oil recovery processes. In this work, a comparative study of statistical and machine learning methods used for MMP estimation is carried out. Most of the predictive models developed in this study exhibited superior performance over correlation and predictive models reported in literature.
    
[^29]: 基于多态电光电路与架构的高速、节能的非二进制计算

    High-Speed and Energy-Efficient Non-Binary Computing with Polymorphic Electro-Optic Circuits and Architectures. (arXiv:2304.07608v1 [cs.AR])

    [http://arxiv.org/abs/2304.07608](http://arxiv.org/abs/2304.07608)

    本文提出了一种基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算，并能处理多种数据格式和卷积神经网络。

    

    本文提出了基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算。我们的多态电光电路可以动态编程，在不同时间实现不同的逻辑和算术功能。它们可以提供紧凑性和多态性，从而提高操作数处理能力，减少空闲时间，并增加面积和静态功率开销的摊销。当与柔性光电探测器结合使用时，我们的电路可以支持非二进制格式（如随机/一元和高维储备格式）的数据的节能处理。此外，我们的多态电光电路还可以实现可配置的电光计算加速器架构，用于处理二进制和整数量化的卷积神经网络（CNN）。我们比较了我们设计的多态电光电路

    In this paper, we present microring resonator (MRR) based polymorphic E-O circuits and architectures that can be employed for high-speed and energy-efficient non-binary reconfigurable computing. Our polymorphic E-O circuits can be dynamically programmed to implement different logic and arithmetic functions at different times. They can provide compactness and polymorphism to consequently improve operand handling, reduce idle time, and increase amortization of area and static power overheads. When combined with flexible photodetectors with the innate ability to accumulate a high number of optical pulses in situ, our circuits can support energy-efficient processing of data in non-binary formats such as stochastic/unary and high-dimensional reservoir formats. Furthermore, our polymorphic E-O circuits enable configurable E-O computing accelerator architectures for processing binarized and integer quantized convolutional neural networks (CNNs). We compare our designed polymorphic E-O circuit
    
[^30]: 在潜在空间学习改善了深度神经算子的预测准确性

    Learning in latent spaces improves the predictive accuracy of deep neural operators. (arXiv:2304.07599v1 [cs.LG])

    [http://arxiv.org/abs/2304.07599](http://arxiv.org/abs/2304.07599)

    该论文研究了潜在深度算子网络(L-DeepONet)，使用自编码器将高维偏微分方程输入和输出函数转换为低维潜在空间中的特征，从而提高了深度神经算子对偏微分方程的预测准确性。

    

    算子回归提供了一种强有力的构建描述物理系统的偏微分方程(PDEs)不变离散化仿真器的方法。神经算子特别是利用深度神经网络来逼近无限维Banach空间之间的映射。作为数据驱动模型，神经算子需要生成标记观测数据，在复杂高保真度模型的情况下，这些数据集通常是高维的，包含冗余和噪声特征，这可能会影响基于梯度的优化。将这些高维数据映射到低维潜在特征空间中可以使数据处理更方便，也可以增强学习。在这项工作中，我们研究了潜在深度算子网络(L-DeepONet)，它是标准DeepONet的扩展，利用适当的自编码器识别高维PDE输入和输出函数的潜在表示。我们证明了L-DeepONet优于传统的DeepONet模型，通过在低维潜在空间中学习，提高了对偏微分方程的精确预测能力。

    Operator regression provides a powerful means of constructing discretization-invariant emulators for partial-differential equations (PDEs) describing physical systems. Neural operators specifically employ deep neural networks to approximate mappings between infinite-dimensional Banach spaces. As data-driven models, neural operators require the generation of labeled observations, which in cases of complex high-fidelity models result in high-dimensional datasets containing redundant and noisy features, which can hinder gradient-based optimization. Mapping these high-dimensional datasets to a low-dimensional latent space of salient features can make it easier to work with the data and also enhance learning. In this work, we investigate the latent deep operator network (L-DeepONet), an extension of standard DeepONet, which leverages latent representations of high-dimensional PDE input and output functions identified with suitable autoencoders. We illustrate that L-DeepONet outperforms the 
    
[^31]: Icospherical Chemical Objects（ICOs）允许对化学数据进行扩充并保持旋转、平移和置换不变性。

    Icospherical Chemical Objects (ICOs) allow for chemical data augmentation and maintain rotational, translation and permutation invariance. (arXiv:2304.07558v1 [cs.LG])

    [http://arxiv.org/abs/2304.07558](http://arxiv.org/abs/2304.07558)

    本文介绍了一种叫做ICOs的方法，可以旋转不变的方式对3D化学数据进行编码，适用于球形或二十面体神经网络，并能够进行数据集扩展和提高化学预测任务的效果。

    

    数据集增强是处理小型数据集的常用方法；但化学数据集通常很小。球形卷积神经网络（SphNNs）和二十面体神经网络（IcoNNs）是一种保持旋转对称性的几何机器学习算法。分子结构具有旋转不变性和天然的3D属性，因此需要3D编码方法将分子结构输入机器学习进行分析。本文介绍了Icospherical Chemical Objects（ICOs），以一种旋转不变的方式对3D数据进行编码，可适用于球形或二十面体神经网络，并允许进行数据集增强。我在预测普通分子性质、预测药物类分子的溶解度和蛋白质结合问题等任务中演示了ICO特征提取方法，并发现ICO和SphNN在所有问题上都表现良好。

    Dataset augmentation is a common way to deal with small datasets; Chemistry datasets are often small. Spherical convolutional neural networks (SphNNs) and Icosahedral neural networks (IcoNNs) are a type of geometric machine learning algorithm that maintains rotational symmetry. Molecular structure has rotational invariance and is inherently 3-D, and thus we need 3-D encoding methods to input molecular structure into machine learning. In this paper I present Icospherical Chemical Objects (ICOs) that enable the encoding of 3-D data in a rotationally invariant way which works with spherical or icosahedral neural networks and allows for dataset augmentation. I demonstrate the ICO featurisation method on the following tasks: predicting general molecular properties, predicting solubility of drug like molecules and the protein binding problem and find that ICO and SphNNs perform well on all problems.
    
[^32]: 形状（几乎）是全部！持续同调特征（PHFs）是高效分子机器学习的丰富信息输入。

    Shape is (almost) all!: Persistent homology features (PHFs) are an information rich input for efficient molecular machine learning. (arXiv:2304.07554v1 [cs.LG])

    [http://arxiv.org/abs/2304.07554](http://arxiv.org/abs/2304.07554)

    持续同调特征是一种编码分子形状的方法，它捕捉了化学分子的拓扑形状特性，并在能量使用效率上比其他编码方法更高效，表明在化学中，精确的机器学习预测主要依赖于分子的三维形状。

    

    三维形状对于化学很重要，但有多重要呢？机器学习在输入简单、匹配问题的情况下效果最好。与机器学习普遍使用的数据集相比，化学数据集往往非常小，因此我们需要从每个数据点中获取最多的信息。持续同调测量点云在不同比例下的拓扑形状特性，并用于拓扑数据分析。在这里，我们研究持续同调对分子结构的捕捉能力，并创建持续同调特征（PHFs），用于编码分子的形状，同时失去大多数符号细节，如原子标签、价、电荷、键等。我们在一系列化学数据集上展示了PHFs的有用性：QM7、疏水性、Delaney和Tox21。PHFs和最佳基准一样有效。PHFs非常信息密集，比其他发现的编码方法要小得多，这意味着ML算法更加节能。尽管失去了大量符号信息，PHFs的成功表明，在化学中进行准确的机器学习预测仅需要三维形状（几乎）就足够了。

    3-D shape is important to chemistry, but how important? Machine learning works best when the inputs are simple and match the problem well. Chemistry datasets tend to be very small compared to those generally used in machine learning so we need to get the most from each datapoint. Persistent homology measures the topological shape properties of point clouds at different scales and is used in topological data analysis. Here we investigate what persistent homology captures about molecular structure and create persistent homology features (PHFs) that encode a molecule's shape whilst losing most of the symbolic detail like atom labels, valence, charge, bonds etc. We demonstrate the usefulness of PHFs on a series of chemical datasets: QM7, lipophilicity, Delaney and Tox21. PHFs work as well as the best benchmarks. PHFs are very information dense and much smaller than other encoding methods yet found, meaning ML algorithms are much more energy efficient. PHFs success despite losing a large am
    
[^33]: 非洲机器学习研究趋势：30年文献计量分析综述

    Machine Learning Research Trends in Africa: A 30 Years Overview with Bibliometric Analysis Review. (arXiv:2304.07542v1 [cs.DL])

    [http://arxiv.org/abs/2304.07542](http://arxiv.org/abs/2304.07542)

    本文对非洲地区机器学习的最新发展和相关应用进行了广泛的文献调查及关键的文献计量分析，结果显示了机器学习研究和应用的当前现状及未来趋势，以促进未来的合作研究和知识交流。

    

    本文针对非洲地区机器学习的最新发展和相关应用进行了广泛的文献调查，并进行了关键的文献计量分析研究。该文献计量分析研究共收集了2761篇机器学习相关的文献，其中98％是发表在903个期刊上至少有482次引用的文章，时间跨度为过去的30年。另外，这些文献是从Science Citation Index EXPANDED检索中来自于1993年至2021年之间54个非洲国家的研究出版物。文献计量研究显示了机器学习研究和应用的当前现状和未来趋势的可视化，以促进非洲大陆分布在不同研究机构的作者之间进行未来的合作研究和知识交流。

    In this paper, a critical bibliometric analysis study is conducted, coupled with an extensive literature survey on recent developments and associated applications in machine learning research with a perspective on Africa. The presented bibliometric analysis study consists of 2761 machine learning-related documents, of which 98% were articles with at least 482 citations published in 903 journals during the past 30 decades. Furthermore, the collated documents were retrieved from the Science Citation Index EXPANDED, comprising research publications from 54 African countries between 1993 and 2021. The bibliometric study shows the visualization of the current landscape and future trends in machine learning research and its application to facilitate future collaborative research and knowledge exchange among authors from different research institutions scattered across the African continent.
    
[^34]: 从在线行为到图片：社交机器人检测的新方法

    From Online Behaviours to Images: A Novel Approach to Social Bot Detection. (arXiv:2304.07535v1 [cs.SI])

    [http://arxiv.org/abs/2304.07535](http://arxiv.org/abs/2304.07535)

    该论文提出了一种基于算法和卷积神经网络的新方法来检测 Twitter 机器人账号，通过将其行为转换为图片进行分类，通过测试发现该方法比传统的机器人检测方法更加有效。

    

    在线社交网络彻底改变了我们消费和共享信息的方式，但也带来了一大堆不可靠和不准确的内容。其中一种特殊类型的社交账号，被称为“机器人”，它们通过自动化操作来宣传不可信的内容、过度支持政治派系和宣传机构化信息。我们专注于 Twitter 账号，提出了一种新颖的机器人检测方法，利用一种新的算法将账号执行的操作序列转换成图片，然后利用卷积神经网络的强大功能进行图像分类。

    Online Social Networks have revolutionized how we consume and share information, but they have also led to a proliferation of content not always reliable and accurate. One particular type of social accounts is known to promote unreputable content, hyperpartisan, and propagandistic information. They are automated accounts, commonly called bots. Focusing on Twitter accounts, we propose a novel approach to bot detection: we first propose a new algorithm that transforms the sequence of actions that an account performs into an image; then, we leverage the strength of Convolutional Neural Networks to proceed with image classification. We compare our performances with state-of-the-art results for bot detection on genuine accounts / bot accounts datasets well known in the literature. The results confirm the effectiveness of the proposal, because the detection capability is on par with the state of the art, if not better in some cases.
    
[^35]: STAS: 多智能体强化学习的时空回报分解

    STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning. (arXiv:2304.07520v1 [cs.AI])

    [http://arxiv.org/abs/2304.07520](http://arxiv.org/abs/2304.07520)

    提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。

    

    集中式训练和分散式执行（CTDE）已被证明是合作多智能体强化学习（MARL）中有效的范例。其中一个主要的挑战是赋信用值，即通过代理的贡献来给代理赋信用值。先前的研究集中于隐式地分解联合价值函数或显式地计算所有代理的支付分配。然而，在只有在周期性强化学习设置中，全局奖励只能在周期结束时显示。现有的方法通常不起作用。它们缺乏对延迟全局奖励在时间维度中复杂关系的建模功能，并且受偏差和方差的影响较大。我们提出了一种名为空间时间关注与 Shapley（STAS）的新方法，用于回报分解；STAS 在时间和空间维度上学习信用分配。它首先将全局回报分解回到每个时间步，然后使用Shapley值来评估协作MARL中每个代理的贡献。 STAS 还引入了一种空间 - 时间关注机制，以捕获延迟全局奖励的复杂关系。我们的实验表明，在各种基准环境中，STAS 能够胜过最先进的方法。

    Centralized Training with Decentralized Execution (CTDE) has been proven to be an effective paradigm in cooperative multi-agent reinforcement learning (MARL). One of the major challenges is yet credit assignment, which aims to credit agents by their contributions. Prior studies focus on either implicitly decomposing the joint value function or explicitly computing the payoff distribution of all agents. However, in episodic reinforcement learning settings where global rewards can only be revealed at the end of the episode, existing methods usually fail to work. They lack the functionality of modeling complicated relations of the delayed global reward in the temporal dimension and suffer from large variance and bias. We propose a novel method named Spatial-Temporal Attention with Shapley (STAS) for return decomposition; STAS learns credit assignment in both the temporal and the spatial dimension. It first decomposes the global return back to each time step, then utilizes Shapley Value to
    
[^36]: S3M：通过无监督对应实现可扩展的统计形状建模

    S3M: Scalable Statistical Shape Modeling through Unsupervised Correspondences. (arXiv:2304.07515v1 [cs.CV])

    [http://arxiv.org/abs/2304.07515](http://arxiv.org/abs/2304.07515)

    该论文提出一种无监督的方法来建立统计形状模型，使用深度几何特征和功能对应来同时学习复杂解剖结构中的局部和全局形状结构，并且该方法足够健壮，能够从噪声神经网络预测中学习。

    

    统计形状模型(SSM)是一种几何上表示人群解剖学结构的方法，在临床诊断领域具有广泛应用。但是，通常需要领域专业知识和费力的手动分割或地标注释来生成。对于SSM的对应估计方法通常需要使用这些标签作为监督信号进行学习。我们提出了一种无监督的方法，利用深度几何特征和功能对应来同时学习复杂解剖结构中的局部和全局形状结构。我们的流程显著改进了SSM的无监督对应估计方法，即使在高度不规则的表面拓扑上也是如此。我们用甲状腺和多室心脏数据集展示了这一点。此外，我们的方法足够健壮，能够从噪声神经网络预测中学习，从而实现扩大SSMs规模的目标。

    Statistical shape models (SSMs) are an established way to geometrically represent the anatomy of a population with various clinically relevant applications. However, they typically require domain expertise and labor-intensive manual segmentations or landmark annotations to generate. Methods to estimate correspondences for SSMs typically learn with such labels as supervision signals. We address these shortcomings by proposing an unsupervised method that leverages deep geometric features and functional correspondences to learn local and global shape structures across complex anatomies simultaneously. Our pipeline significantly improves unsupervised correspondence estimation for SSMs compared to baseline methods, even on highly irregular surface topologies. We demonstrate this for two different anatomical structures: the thyroid and a multi-chamber heart dataset. Furthermore, our method is robust enough to learn from noisy neural network predictions, enabling scaling SSMs to larger patien
    
[^37]: PI-FL：个性化和激励联邦学习

    PI-FL: Personalized and Incentivized Federated Learning. (arXiv:2304.07514v1 [cs.LG])

    [http://arxiv.org/abs/2304.07514](http://arxiv.org/abs/2304.07514)

    PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。

    

    个性化联邦学习已被广泛应用于应对非独立同分布数据异质性的挑战。主要问题是考虑来自客户端的个性化过程以保护其自治权。允许客户端参与个性化联邦学习决策变得重要，因为存在隐私和安全问题，客户端可能无法自由共享生成良好质量个性化模型所必需的私人信息。此外，具有高质量数据和资源的客户端不愿意在没有合理激励的情况下参与联邦学习过程。在本文中，我们提出了PI-FL，这是一个一次性个性化解决方案，配合一个基于令牌的激励机制，奖励个性化训练。PI-FL优于其他最先进的方法，并且可以在尊重客户端隐私的同时生成高质量的个性化模型。

    Personalized FL has been widely used to cater to heterogeneity challenges with non-IID data. A primary obstacle is considering the personalization process from the client's perspective to preserve their autonomy. Allowing the clients to participate in personalized FL decisions becomes significant due to privacy and security concerns, where the clients may not be at liberty to share private information necessary for producing good quality personalized models. Moreover, clients with high-quality data and resources are reluctant to participate in the FL process without reasonable incentive. In this paper, we propose PI-FL, a one-shot personalization solution complemented by a token-based incentive mechanism that rewards personalized training. PI-FL outperforms other state-of-the-art approaches and can generate good-quality personalized models while respecting clients' privacy.
    
[^38]: 基于平均二阶相似性的随机分布式优化：算法与分析

    Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])

    [http://arxiv.org/abs/2304.07504](http://arxiv.org/abs/2304.07504)

    本文提出了两种新算法SVRS和AccSVRS，针对分布式优化问题，实现了卓越的通信复杂度。其中，AccSVRS算法实现了完全无平滑性，通信复杂度更是优于现有算法。

    

    本文研究了具有$n$个客户端的有限和分布式优化问题，满足流行的$\delta$-相似性条件和$\mu$-强凸性。我们提出了两种新算法：SVRS和AccSVRS，启发自先前的工作。非加速的SVRS方法结合了梯度滑动和方差缩减技术，实现了卓越的通信复杂度$\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$，与现有的非加速算法相比有所提高。应用Katyusha X提出的框架，我们还建立了一个名为AccSVRS的直接加速实际版本，其完全无平滑性，通信复杂度为$\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$，在病态情况下优于现有算法。此外，我们展示了一种接近匹配的下界，以验证我们的AccSVRS方法的紧密程度。

    We study finite-sum distributed optimization problems with $n$-clients under popular $\delta$-similarity condition and $\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.
    
[^39]: 动态表示的时间聚合和传播图神经网络

    Temporal Aggregation and Propagation Graph Neural Networks for Dynamic Representation. (arXiv:2304.07503v1 [cs.LG])

    [http://arxiv.org/abs/2304.07503](http://arxiv.org/abs/2304.07503)

    本文提出了 TAP-GNN，通过整个邻域的时间聚合和传播来有效地建模动态图中的时间关系，从而在图流场景中支持高效的在线推理。

    

    时间图展示了节点之间在连续时间内的动态交互，其拓扑随时间流逝而演变。节点的整个时间邻域显示了节点的变化偏好。然而，为了简化起见，先前的工作通常使用有限的邻居生成动态表示，这导致性能不佳和在线推理延迟高。因此，在本文中，我们提出了一种基于整个邻域的时间图卷积的新方法，即时间聚合和传播图神经网络（TAP-GNN）。具体而言，我们首先通过展开时间图来分析动态表示问题的计算复杂度，使用聚合和传播（AP）块来显著减少历史邻居的重复计算。最终，TAP-GNN支持在图流场景中进行在线推理，既高效又有效地建模动态图中的时间关系。

    Temporal graphs exhibit dynamic interactions between nodes over continuous time, whose topologies evolve with time elapsing.  The whole temporal neighborhood of nodes reveals the varying preferences of nodes.  However, previous works usually generate dynamic representation with limited neighbors for simplicity, which results in both inferior performance and high latency of online inference.  Therefore, in this paper, we propose a novel method of temporal graph convolution with the whole neighborhood, namely Temporal Aggregation and Propagation Graph Neural Networks (TAP-GNN).  Specifically, we firstly analyze the computational complexity of the dynamic representation problem by unfolding the temporal graph in a message-passing paradigm.  The expensive complexity motivates us to design the AP (aggregation and propagation) block, which significantly reduces the repeated computation of historical neighbors.  The final TAP-GNN supports online inference in the graph stream scenario, which i
    
[^40]: 低资源和不平衡数据集下的鲁棒教育对话行为分类器

    Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets. (arXiv:2304.07499v1 [cs.CL])

    [http://arxiv.org/abs/2304.07499](http://arxiv.org/abs/2304.07499)

    本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。

    

    对话行为可以代表在辅导对话期间发生的教练员或学生的对话动作。在教育对话中自动识别对话行为对于基于对话的智能辅导系统的设计是重要的。许多先前的研究采用机器学习模型对辅导对话中的对话行为进行分类，并投入大量精力使用有限的训练数据（即低资源数据场景）来优化分类准确性。然而，除了分类准确性之外，分类器的鲁棒性也很重要，这可以反映分类器学习不同类别分布的模式的能力。我们注意到，许多先前的教育对话行为分类研究采用交叉熵（CE）损失来优化低资源数据中的DA分类器。这些研究中的DA分类器往往以牺牲少数类的代价来优先考虑大多数类的准确性，从而可能导致在少数类上性能差。在这篇论文中，我们提出了一种新型的DA分类器MIREX，它采用互信息最小化损失来提高DA分类器在不平衡和低资源数据情景下的鲁棒性。实验结果表明，MIREX在不平衡和低资源的DA数据集上优于现有方法。

    Dialogue acts (DAs) can represent conversational actions of tutors or students that take place during tutoring dialogues. Automating the identification of DAs in tutoring dialogues is significant to the design of dialogue-based intelligent tutoring systems. Many prior studies employ machine learning models to classify DAs in tutoring dialogues and invest much effort to optimize the classification accuracy by using limited amounts of training data (i.e., low-resource data scenario). However, beyond the classification accuracy, the robustness of the classifier is also important, which can reflect the capability of the classifier on learning the patterns from different class distributions. We note that many prior studies on classifying educational DAs employ cross entropy (CE) loss to optimize DA classifiers on low-resource data with imbalanced DA distribution. The DA classifiers in these studies tend to prioritize accuracy on the majority class at the expense of the minority class which 
    
[^41]: SalientGrads：面向通信效率和数据感知的分布式联邦学习的稀疏模型

    SalientGrads: Sparse Models for Communication Efficient and Data Aware Distributed Federated Training. (arXiv:2304.07488v1 [cs.LG])

    [http://arxiv.org/abs/2304.07488](http://arxiv.org/abs/2304.07488)

    SalientGrads是一个用于联邦学习的稀疏模型，通过选择一个数据感知的子网络和仅传输高度稀疏的梯度来简化稀疏训练过程，可在减少通信成本高达90%和计算成本高达60%的同时，实现与最先进的联邦学习方法相当或更好的模型准确度。

    

    联邦学习可以在客户端站点利用分散的数据训练模型，同时通过不收集数据来保护隐私。然而，联邦学习面临的一大挑战是资源有限的边缘客户端节点计算和通信带宽不足。为了解决这个问题，近年来提出了几种解决方案，包括传输稀疏模型和迭代学习动态掩码等。然而，许多这些方法在整个训练过程中都需要传输模型权重，因为它们基于特定的剪枝标准。在本研究中，我们提出了 SalientGrads，它可以在训练之前基于本地客户端数据计算模型参数的显着性分数，从而选择一个数据感知的子网络来简化稀疏训练过程。此外，在训练过程中，服务器和客户端模型之间仅传输高度稀疏的梯度，而不像大多数方法需要传输整个模型。实验结果表明，SalientGrads 可以在减少通信成本高达 90% 和计算成本高达 60% 的同时，实现与最先进的联邦学习方法相当或更好的模型准确度。

    Federated learning (FL) enables the training of a model leveraging decentralized data in client sites while preserving privacy by not collecting data. However, one of the significant challenges of FL is limited computation and low communication bandwidth in resource limited edge client nodes. To address this, several solutions have been proposed in recent times including transmitting sparse models and learning dynamic masks iteratively, among others. However, many of these methods rely on transmitting the model weights throughout the entire training process as they are based on ad-hoc or random pruning criteria. In this work, we propose Salient Grads, which simplifies the process of sparse training by choosing a data aware subnetwork before training, based on the model-parameter's saliency scores, which is calculated from the local client data. Moreover only highly sparse gradients are transmitted between the server and client models during the training process unlike most methods that
    
[^42]: 通用核学习的高效凸优化算法

    Efficient Convex Algorithms for Universal Kernel Learning. (arXiv:2304.07472v1 [stat.ML])

    [http://arxiv.org/abs/2304.07472](http://arxiv.org/abs/2304.07472)

    本文提出了一种基于SVD-QCQP原始对偶算法的高效内核学习实现，用于学习半分离核，大大降低了计算复杂度，并在几个基准数据集上展示了其准确性和速度。

    

    基于核优化的机器学习算法的准确性和复杂性取决于它们能够优化的核集。理想的核集应该：具有线性参数化（以便于可处理性）；在所有核集中密集（以便于鲁棒性）；是通用的（以便于准确性）。最近，提出了一种框架，使用正定矩阵来参数化一类正半分离核。尽管此类核能够满足所有三个标准，但之前用于优化此类核的算法仅限于分类，并且还依赖于计算复杂的半定规划（SDP）算法。在本文中，我们将学习半分离核的问题作为极小化极大化优化问题，并提出了一种SVD-QCQP原始对偶算法，其与之前基于SDP的方法相比，大大降低了计算复杂度。此外，我们提供了一种高效的内核学习实现，并在几个基准数据集上展示了其准确性和速度。

    The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of thi
    
[^43]: 少样本弱监督的网络安全异常检测

    Few-shot Weakly-supervised Cybersecurity Anomaly Detection. (arXiv:2304.07470v1 [cs.CR])

    [http://arxiv.org/abs/2304.07470](http://arxiv.org/abs/2304.07470)

    本文提出了一种使用少量标记数据样本训练和调整机器学习模型进行异常检测的少样本弱监督方法，并在多个数据集上表现优越。

    

    随着人们越来越依赖基于网络的技术，攻击者窃取用户敏感数据的网络攻击变得越来越普遍。这种攻击的规模和频率正在迅速升级，并影响与互联网连接的各种系统和设备。传统的防御机制可能无法足够地应对复杂和不断变化的新威胁。机器学习方法包括深度学习的重大突破引起了网络安全研究界的兴趣，希望进一步增强现有的异常检测方法。然而，对于所有新兴和复杂的攻击收集带标签的异常数据是不现实的。使用少量标记数据样本训练和调整机器学习模型进行异常检测是一种务实的方法。因此，少样本弱监督异常检测是一个令人鼓舞的研究方向。本文提出了一种使用少样本弱监督学习方法增强现有异常检测模型的方法。我们的模型结合了有标签和无标签数据以提高检测性能。我们在多个数据集上评估了增强模型的表现，并实验证明我们的模型优于现有最先进的方法。

    With increased reliance on Internet based technologies, cyberattacks compromising users' sensitive data are becoming more prevalent. The scale and frequency of these attacks are escalating rapidly, affecting systems and devices connected to the Internet. The traditional defense mechanisms may not be sufficiently equipped to handle the complex and ever-changing new threats. The significant breakthroughs in the machine learning methods including deep learning, had attracted interests from the cybersecurity research community for further enhancements in the existing anomaly detection methods. Unfortunately, collecting labelled anomaly data for all new evolving and sophisticated attacks is not practical. Training and tuning the machine learning model for anomaly detection using only a handful of labelled data samples is a pragmatic approach. Therefore, few-shot weakly supervised anomaly detection is an encouraging research direction. In this paper, we propose an enhancement to an existing 
    
[^44]: 具有内在隐私保护的高效通信和节能无线联邦学习

    Communication and Energy Efficient Wireless Federated Learning with Intrinsic Privacy. (arXiv:2304.07460v1 [cs.LG])

    [http://arxiv.org/abs/2304.07460](http://arxiv.org/abs/2304.07460)

    本文提出了一种名为PFELS的无线FL方案，通过先压缩模型更新再自适应地设计发送功率来提供客户端级别DP保证，并降低通信和能量开销并提高模型精度。

    

    联邦学习（FL）是一种协同学习框架，使边缘设备在保留原始数据的同时协同学习全局模型。虽然FL避免了从本地数据集泄漏直接信息，但仍可能从共享模型推断出敏感信息。为解决FL中的隐私问题，利用差分隐私（DP）机制提供正式的隐私保证。然而，使用无线边缘部署FL时，确保客户端级别的DP面临着重大挑战。在本文中，我们提出了一种名为带稀疏化的私有联邦边缘学习（PFELS）的新型无线FL方案，以提供具有内在信道噪声的客户端级别DP保证，同时降低通信和能量开销并提高模型精度。PFELS的关键思想是使每个设备先压缩其模型更新，然后根据无线信道自适应设计压缩模型更新的发送功率。

    Federated Learning (FL) is a collaborative learning framework that enables edge devices to collaboratively learn a global model while keeping raw data locally. Although FL avoids leaking direct information from local datasets, sensitive information can still be inferred from the shared models. To address the privacy issue in FL, differential privacy (DP) mechanisms are leveraged to provide formal privacy guarantee. However, when deploying FL at the wireless edge with over-the-air computation, ensuring client-level DP faces significant challenges. In this paper, we propose a novel wireless FL scheme called private federated edge learning with sparsification (PFELS) to provide client-level DP guarantee with intrinsic channel noise while reducing communication and energy overhead and improving model accuracy. The key idea of PFELS is for each device to first compress its model update and then adaptively design the transmit power of the compressed model update according to the wireless cha
    
[^45]: 基于上下文感知的时间序列异常检测领域自适应

    Context-aware Domain Adaptation for Time Series Anomaly Detection. (arXiv:2304.07453v1 [cs.LG])

    [http://arxiv.org/abs/2304.07453](http://arxiv.org/abs/2304.07453)

    本论文提出了一个框架，通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这个框架结合了上下文采样和异常检测，既可以进行无监督域适应，也可以进行有监督的异常检测。

    

    时间序列异常检测是一项具有广泛实际应用的挑战性任务。由于标签稀疏性，训练深度异常检测器通常依赖于无监督方法。最近已经致力于时间序列领域自适应，以利用类似领域中的知识。然而，现有解决方案可能会因其稀疏性和多样性而在异常方面受到负面知识转移的影响。受到两个领域之间上下文对齐的实证研究的启发，我们旨在通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这是具有挑战性的，因为它需要同时建模复杂的域内时间相关性和跨域相关性，并利用源域的标签信息。为此，我们提出了一个框架将上下文采样和异常检测结合到一个联合学习过程中。我们将上下文采样表述为马尔可夫决策过程，并利用源域的标签信息进行无监督域适应和有监督的异常检测。

    Time series anomaly detection is a challenging task with a wide range of real-world applications. Due to label sparsity, training a deep anomaly detector often relies on unsupervised approaches. Recent efforts have been devoted to time series domain adaptation to leverage knowledge from similar domains. However, existing solutions may suffer from negative knowledge transfer on anomalies due to their diversity and sparsity. Motivated by the empirical study of context alignment between two domains, we aim to transfer knowledge between two domains via adaptively sampling context information for two domains. This is challenging because it requires simultaneously modeling the complex in-domain temporal dependencies and cross-domain correlations while exploiting label information from the source domain. To this end, we propose a framework that combines context sampling and anomaly detection into a joint learning procedure. We formulate context sampling into the Markov decision process and ex
    
[^46]: 自监督辅助损失用于基于音乐相似度检索和自动标注的度量学习

    Self-supervised Auxiliary Loss for Metric Learning in Music Similarity-based Retrieval and Auto-tagging. (arXiv:2304.07449v1 [cs.SD])

    [http://arxiv.org/abs/2304.07449](http://arxiv.org/abs/2304.07449)

    本论文提出了一种自监督学习方法，在自动标注方面已经证明其有效性。我们引入了自监督辅助损失的度量学习方法来解决音乐相似度检索问题，并发现同时使用自监督和监督信号训练模型的优势，而不冻结预训练模型。此外，避免在微调阶段使用数据增强可以提高性能。

    

    在音乐信息检索领域，基于相似度的检索和自动标记是关键组成部分。考虑到人类监督信号的限制性和不可扩展性，让模型从其他来源学习以提高其性能变得至关重要。自监督学习，仅依赖于从音乐音频数据中派生的学习信号，在自动标记的背景下已经证明了其有效性。在这项研究中，我们提出了一种模型，采用自监督学习方法来解决基于相似度的检索问题，并引入了我们的度量学习方法，使用自监督辅助损失。此外，与传统的自监督学习方法不同的是，我们发现了同时使用自监督和监督信号训练模型的优点，而不冻结预训练模型。我们还发现，避免在微调阶段使用数据增强可以提高性能。

    In the realm of music information retrieval, similarity-based retrieval and auto-tagging serve as essential components. Given the limitations and non-scalability of human supervision signals, it becomes crucial for models to learn from alternative sources to enhance their performance. Self-supervised learning, which exclusively relies on learning signals derived from music audio data, has demonstrated its efficacy in the context of auto-tagging. In this study, we propose a model that builds on the self-supervised learning approach to address the similarity-based retrieval challenge by introducing our method of metric learning with a self-supervised auxiliary loss. Furthermore, diverging from conventional self-supervised learning methodologies, we discovered the advantages of concurrently training the model with both self-supervision and supervision signals, without freezing pre-trained models. We also found that refraining from employing augmentation during the fine-tuning phase yields
    
[^47]: 多目标优化和主动学习实现材料全自动设计的框架：挑战和下一步

    A framework for fully autonomous design of materials via multiobjective optimization and active learning: challenges and next steps. (arXiv:2304.07445v1 [cs.LG])

    [http://arxiv.org/abs/2304.07445](http://arxiv.org/abs/2304.07445)

    该研究介绍了一个基于多目标黑盒优化和不断更新的机器学习模型的主动学习过程，实现了材料的全自动设计。通过自主操作实验室，该工作流成功确定了2,2,2-三氟乙基甲基碳酸酯的理想制造条件。

    

    为了在数据获取昂贵且存在多个竞争设计标准的实际自动驾驶实验室中部署机器学习，系统需要能够智能采样，平衡性能权衡和约束。因此，我们提出了一种基于多目标黑盒优化和不断更新的机器学习模型的主动学习过程。这个工作流建立在实时数据流和模块化多目标优化软件开发的开源技术之上。我们通过连续流化学实验室的自主操作，证明了这个工作流的概念证明，该实验室确定了2,2,2-三氟乙基甲基碳酸酯的理想制造条件。

    In order to deploy machine learning in a real-world self-driving laboratory where data acquisition is costly and there are multiple competing design criteria, systems need to be able to intelligently sample while balancing performance trade-offs and constraints. For these reasons, we present an active learning process based on multiobjective black-box optimization with continuously updated machine learning models. This workflow is built on open-source technologies for real-time data streaming and modular multiobjective optimization software development. We demonstrate a proof of concept for this workflow through the autonomous operation of a continuous-flow chemistry laboratory, which identifies ideal manufacturing conditions for the electrolyte 2,2,2-trifluoroethyl methyl carbonate.
    
[^48]: 无需梯度的量子神经网络优化算法

    Learning To Optimize Quantum Neural Network Without Gradients. (arXiv:2304.07442v1 [quant-ph])

    [http://arxiv.org/abs/2304.07442](http://arxiv.org/abs/2304.07442)

    本文提出了一种量子神经网络的无梯度训练算法，该算法名为Meta-Quantum Optimization (MQO)，相比当前依赖于量子设备计算梯度的算法，具有更高的扩展性和稳定性。作者在二元分类和生成建模任务中成功地应用了MQO算法来优化QNNs，为QNNs的训练提供了一种有效的解决方案。

    

    量子机器学习是机器学习中的新兴子领域之一，其目标之一是通过将数据编码成量子态来执行模式识别任务。从经典到量子的扩展得以实现是由于混合量子-经典算法的发展，该算法允许使用在经典计算机上运行的基于梯度的算法来优化参数化量子电路。这些混合算法的训练与经典神经网络的相似性进一步促进了量子神经网络（QNN）的发展。然而，在当前的QNN训练过程中，必须在量子设备上计算相对目标函数的梯度。这种计算非常难以扩展，并受到当前量子硬件中存在的硬件和采样噪声的影响。本文提出了一种无需梯度信息的训练算法。具体地，我们介绍了一种新颖的元优化算法Meta-Quantum Optimization（MQO)，可用于训练QNNs。我们通过成功训练二元分类和生成建模任务的QNNs，展示了我们方法的可行性。我们的结果表明，MQO可以成功优化QNNs，并且是训练QNNs的一种有前途的方法。

    Quantum Machine Learning is an emerging sub-field in machine learning where one of the goals is to perform pattern recognition tasks by encoding data into quantum states. This extension from classical to quantum domain has been made possible due to the development of hybrid quantum-classical algorithms that allow a parameterized quantum circuit to be optimized using gradient based algorithms that run on a classical computer. The similarities in training of these hybrid algorithms and classical neural networks has further led to the development of Quantum Neural Networks (QNNs). However, in the current training regime for QNNs, the gradients w.r.t objective function have to be computed on the quantum device. This computation is highly non-scalable and is affected by hardware and sampling noise present in the current generation of quantum hardware. In this paper, we propose a training algorithm that does not rely on gradient information. Specifically, we introduce a novel meta-optimizati
    
[^49]: 通过多样性优质个体实现高效的质量多样性优化

    Efficient Quality-Diversity Optimization through Diverse Quality Species. (arXiv:2304.07425v1 [cs.LG])

    [http://arxiv.org/abs/2304.07425](http://arxiv.org/abs/2304.07425)

    本文提出了一种新的质量多样性优化算法，通过将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案，相对于传统方法，该方法无需存档或预先定义行为范围的限制。

    

    单一目标优化的普遍局限性是它可能会被误导，陷入局部最优解。这可以通过质量多样性(QD)算法来纠正，其中首选问题的高质量和多样性解决方案的人群。大多数传统的QD方法，例如MAP-Elites，明确管理解决方案被分解成预定义的壁龛的行为档案。在这项工作中，我们展示了可以在不需要存档或预先定义行为范围的限制下找到多样化的解决方案种群。相反，我们将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案。我们表明，这可以通过基于梯度的突变来完成，这些突变采取互信息和性能的信息理论视角共同最大化。我们提出了多样性优质物种(DQS)作为存档型QD算法的替代方法。

    A prevalent limitation of optimizing over a single objective is that it can be misguided, becoming trapped in local optimum. This can be rectified by Quality-Diversity (QD) algorithms, where a population of high-quality and diverse solutions to a problem is preferred. Most conventional QD approaches, for example, MAP-Elites, explicitly manage a behavioral archive where solutions are broken down into predefined niches. In this work, we show that a diverse population of solutions can be found without the limitation of needing an archive or defining the range of behaviors in advance. Instead, we break down solutions into independently evolving species and use unsupervised skill discovery to learn diverse, high-performing solutions. We show that this can be done through gradient-based mutations that take on an information theoretic perspective of jointly maximizing mutual information and performance. We propose Diverse Quality Species (DQS) as an alternative to archive-based QD algorithms.
    
[^50]: 自然驾驶行为识别的点对点联邦不断学习

    Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition. (arXiv:2304.07421v1 [cs.LG])

    [http://arxiv.org/abs/2304.07421](http://arxiv.org/abs/2304.07421)

    本文提出了一个点对点联邦学习框架FedPC，其中使用而不影响司机隐私的车内相机数据进行自然驾驶行为识别（NDAR）模型的建立，在不断学习的基础上提供个性化和准确的模型。

    

    自然驾驶行为识别（NDAR）已被证明是一种检测驾驶员分心和减少交通事故风险的有效方法。然而，车内相机的侵入式设计引起了对驾驶员隐私的担忧。为解决这个问题，我们提出了一个新颖的点对点（P2P）联邦学习（FL）框架，即FedPC，它确保了隐私并提高了学习效率，同时减少了通信、计算和存储开销。我们的框架专注于在无服务FL框架中解决客户端的目标，旨在提供个性化和准确的NDAR模型。我们在两个现实世界的NDAR数据集上展示和评估了FedPC的性能，包括2023年AICity挑战赛中的State Farm分心驾驶带检测和Track 3 NDAR数据集。我们实验的结果突出了FedPC相对于传统的客户端到服务器（C2S）FL的强大竞争力。

    Naturalistic driving action recognition (NDAR) has proven to be an effective method for detecting driver distraction and reducing the risk of traffic accidents. However, the intrusive design of in-cabin cameras raises concerns about driver privacy. To address this issue, we propose a novel peer-to-peer (P2P) federated learning (FL) framework with continual learning, namely FedPC, which ensures privacy and enhances learning efficiency while reducing communication, computational, and storage overheads. Our framework focuses on addressing the clients' objectives within a serverless FL framework, with the goal of delivering personalized and accurate NDAR models. We demonstrate and evaluate the performance of FedPC on two real-world NDAR datasets, including the State Farm Distracted Driver Detection and Track 3 NDAR dataset in the 2023 AICity Challenge. The results of our experiments highlight the strong competitiveness of FedPC compared to the conventional client-to-server (C2S) FLs in ter
    
[^51]: 可靠的聚类算法:一种新的Transformer聚类方法

    Fairness in Visual Clustering: A Novel Transformer Clustering Approach. (arXiv:2304.07408v1 [cs.CV])

    [http://arxiv.org/abs/2304.07408](http://arxiv.org/abs/2304.07408)

    本文提出了一种新的Transformer聚类方法，通过引入聚类纯度作为指标，采用新的损失函数来维持聚类模型的公平性，同时引入Cross-attention机制提高聚类的纯度。

    

    在无监督聚类的情景下，为了减少人群偏差而增加深度聚类模型的公平性是一个具有挑战性的目标。本文从聚类纯度的角度评估了深度聚类模型中的人口偏差，聚类纯度是指聚类中正样本与它们的相关程度的比值。我们引入了一种新的损失函数来鼓励所有聚类的纯度一致性以维持学习到的聚类模型的公平性。此外, 我们提出了一种新的Cross-attention机制，用于测量多个聚类之间的相关性，在学习过程中加强远距离的正样本，提高聚类的纯度。在一个大规模的数据集上进行实验，包括多种属性设置。

    Promoting fairness for deep clustering models in unsupervised clustering settings to reduce demographic bias is a challenging goal. This is because of the limitation of large-scale balanced data with well-annotated labels for sensitive or protected attributes. In this paper, we first evaluate demographic bias in deep clustering models from the perspective of cluster purity, which is measured by the ratio of positive samples within a cluster to their correlation degree. This measurement is adopted as an indication of demographic bias. Then, a novel loss function is introduced to encourage a purity consistency for all clusters to maintain the fairness aspect of the learned clustering model. Moreover, we present a novel attention mechanism, Cross-attention, to measure correlations between multiple clusters, strengthening faraway positive samples and improving the purity of clusters during the learning process. Experimental results on a large-scale dataset with numerous attribute settings 
    
[^52]: 未观测到代理奖励的重复负责人代理博弈问题研究

    Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])

    [http://arxiv.org/abs/2304.07407](http://arxiv.org/abs/2304.07407)

    本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    

    本文研究了一个多臂老虎机框架中的重复负责人代理博弈场景，其中代理选择一种老虎机后会获得奖励和激励，但负责人只能观察到代理选择了哪个老虎机以及代理相应的激励，而想要设计一种合适的策略却充满了挑战性。本文提出了一种利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
    
[^53]: 改善临床试验的患者预筛选：利用大型语言模型辅助医生

    Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])

    [http://arxiv.org/abs/2304.07396](http://arxiv.org/abs/2304.07396)

    本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。

    

    考虑到患者的临床试验，医生需要进行繁琐的检查，以确定患者是否符合文本基准。大型语言模型（LLMs）已被证明在临床信息提取和临床推理方面表现良好，但尚未在现实场景中得到应用。本文研究了使用InstructGPT辅助医生根据患者的医疗简况确定其是否符合临床试验的资格。使用一次性、选择-推理和思维链策略相结合的提示策略，我们研究了LLMs在10个合成患者简况上的表现。在四个级别上评估了性能：能否从临床试验中给出的医疗简况中识别筛选资格标准；能否为每个单独的标准分类是否符合患者；整体分类是否符合临床试验资格以及需要筛选资格标准的百分比。

    Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be scr
    
[^54]: 无需需求预测的收益管理：一种基于数据驱动的竞价价格生成方法

    Revenue Management without Demand Forecasting: A Data-Driven Approach for Bid Price Generation. (arXiv:2304.07391v1 [cs.LG])

    [http://arxiv.org/abs/2304.07391](http://arxiv.org/abs/2304.07391)

    本论文提出了一种无需需求预测的基于数据驱动的收益管理方法，该方法能够仅使用历史预订数据来生成竞价价格。

    

    传统收益管理依赖长期稳定的历史数据和可预测的需求模式。然而，满足这些需求并非总是可能的。许多行业都面临持续的需求波动，例如空中货运，它具有更短的预订周期和高度变化的批量到货。即使对于收入管理（RM）成熟的乘客航空公司，应对外部冲击也是一个众所周知的挑战，需要用户监控和手动干预。此外，传统的RM还要求有大量历史预订和价格数据，即使没有任何预订，也需跨越多年。对于没有建立RM惯例的公司来说，这种广泛的数据通常是不可获取的。我们提出了一种基于数据驱动的RM方法，该方法消除了需求预测和优化技术的需求。我们开发了一种方法，仅使用历史预订数据来生成竞价价格。

    Traditional revenue management relies on long and stable historical data and predictable demand patterns. However, meeting those requirements is not always possible. Many industries face demand volatility on an ongoing basis, an example would be air cargo which has much shorter booking horizon with highly variable batch arrivals. Even for passenger airlines where revenue management (RM) is well-established, reacting to external shocks is a well-known challenge that requires user monitoring and manual intervention. Moreover, traditional RM comes with strict data requirements including historical bookings and pricing even in the absence of any bookings, spanning multiple years. For companies that have not established a practice in RM, that type of extensive data is usually not available. We present a data-driven approach to RM which eliminates the need for demand forecasting and optimization techniques. We develop a methodology to generate bid prices using historical booking data only. O
    
[^55]: Shape of You：针对多样化身材的精准3D形体估计

    Shape of You: Precise 3D shape estimations for diverse body types. (arXiv:2304.07389v1 [cs.CV])

    [http://arxiv.org/abs/2304.07389](http://arxiv.org/abs/2304.07389)

    本文提出了一种名为SoY的方法，通过两种损失函数和测试时优化例程，可以在不同的人体类型上提高精确的3D形体估计准确度，为时尚行业的实际应用提供了希望。

    

    本文提出了一种名为SoY的方法，旨在改善基于视觉的服装推荐系统中3D身体形状估计的准确性。尽管现有的方法已经成功地估计了3D姿势，但在精确形状估计方面，尤其是对于不同的人体类型，仍存在缺乏的问题。为了解决这个问题，我们提出了两种损失函数，可以轻松地集成到参数化的3D人体重建管道中。此外，我们还提出了一种测试时优化例程，进一步提高了质量。我们的方法在具有挑战性的SSP-3D数据集上比最近的SHAPY方法提高了17.7％。我们认为我们的工作是朝着更准确的3D形态估计系统迈出的一步，该系统可在不同的体型上可靠地工作，并有望在时尚行业中得到实际应用。

    This paper presents Shape of You (SoY), an approach to improve the accuracy of 3D body shape estimation for vision-based clothing recommendation systems. While existing methods have successfully estimated 3D poses, there remains a lack of work in precise shape estimation, particularly for diverse human bodies. To address this gap, we propose two loss functions that can be readily integrated into parametric 3D human reconstruction pipelines. Additionally, we propose a test-time optimization routine that further improves quality. Our method improves over the recent SHAPY method by 17.7% on the challenging SSP-3D dataset. We consider our work to be a step towards a more accurate 3D shape estimation system that works reliably on diverse body types and holds promise for practical applications in the fashion industry.
    
[^56]: END：一种用于量子纠错的等变神经解码器

    The END: An Equivariant Neural Decoder for Quantum Error Correction. (arXiv:2304.07362v1 [quant-ph])

    [http://arxiv.org/abs/2304.07362](http://arxiv.org/abs/2304.07362)

    本文介绍了一种利用对称性的数据有效型神经解码器，用于量子纠错，通过等变体系结构达到了与先前神经解码器相比的最先进准确性。

    

    量子纠错是扩展量子计算的关键组成部分。对于给定的量子码，最佳解码器将测量到的码违规映射到最有可能发生的错误，但其成本随系统大小呈指数级增长。神经网络解码器是一种吸引人的解决方案，因为它们可以从数据中学习到这种映射的有效近似，并可以自动适应噪声分布。在这项工作中，我们介绍了一种利用问题的对称性的数据有效型神经解码器。我们表征了扭曲码理论的最佳解码器的对称性，并提出了一种实现最先进准确性的等变体系结构，与以前的神经解码器相比。

    Quantum error correction is a critical component for scaling up quantum computing. Given a quantum code, an optimal decoder maps the measured code violations to the most likely error that occurred, but its cost scales exponentially with the system size. Neural network decoders are an appealing solution since they can learn from data an efficient approximation to such a mapping and can automatically adapt to the noise distribution. In this work, we introduce a data efficient neural decoder that exploits the symmetries of the problem. We characterize the symmetries of the optimal decoder for the toric code and propose a novel equivariant architecture that achieves state of the art accuracy compared to previous neural decoders.
    
[^57]: PTW: 针对预训练图像生成器的关键调整型水印技术

    PTW: Pivotal Tuning Watermarking for Pre-Trained Image Generators. (arXiv:2304.07361v1 [cs.LG])

    [http://arxiv.org/abs/2304.07361](http://arxiv.org/abs/2304.07361)

    PTW是一种预训练生成器水印技术，可以比从头开始水印技术快三个数量级和更好的保留了生成器的图像质量，解决了恶意用户利用提供的模型制作出有害的深度伪造而不会被发现的问题。

    

    深度伪造是泛指利用深度生成器综合出来的内容，若被“误用”，可以破坏数字媒体的信任。而制作高质量的深度伪造需要接触大型和复杂的生成器，只有少数实体可以训练和提供这些生成器。威胁的是，恶意用户会利用提供的模型制作出有害的深度伪造，而不会被发现。为了可探测起来，深度伪造需要在生成器中嵌入识别码，以便在后续生成的图像中进行提取。我们提出了Pivotal Tuning Watermarking (PTW)，这是一种预训练生成器水印技术，(i) 比从头开始水印技术快三个数量级，(ii) 不需要任何训练数据。我们改进了现有的水印技术，同时缩放到了比相关工作大4倍的生成器。与现有方法相比，PTW可以嵌入更长的识别码，同时更好地保留了生成器的图像质量。我们提出了严格的基于博弈论的定义来评估水印技术。

    Deepfakes refer to content synthesized using deep generators, which, when \emph{misused}, have the potential to erode trust in digital media. Synthesizing high-quality deepfakes requires access to large and complex generators only few entities can train and provide. The threat are malicious users that exploit access to the provided model and generate harmful deepfakes without risking detection. Watermarking makes deepfakes detectable by embedding an identifiable code into the generator that is later extractable from its generated images. We propose Pivotal Tuning Watermarking (PTW), a method for watermarking pre-trained generators (i) three orders of magnitude faster than watermarking from scratch and (ii) without the need for any training data. We improve existing watermarking methods and scale to generators $4 \times$ larger than related work. PTW can embed longer codes than existing methods while better preserving the generator's image quality. We propose rigorous, game-based defini
    
[^58]: 分布化多任务学习中的精确子空间扩散

    Exact Subspace Diffusion for Decentralized Multitask Learning. (arXiv:2304.07358v1 [cs.LG])

    [http://arxiv.org/abs/2304.07358](http://arxiv.org/abs/2304.07358)

    本论文提出了一种新的分布式多任务学习算法，通过精确扩散算法的推广，并在网络中进行子空间约束。相比于现有的基于近似投影的方法，其性能得到了明显提升。

    

    传统的分布式学习方法，如联邦学习或分散式梯度下降，采用共识机制来强制实现代理之间的同质性。虽然这些策略在独立同分布场景下被证明是有效的，但在代理遵循异构目标或数据时，它们可能导致严重的性能降低。另一方面，多任务学习的分布式策略以更加微妙的方式在代理之间建立关系，并鼓励协作而不是强制共识。我们发展了用于通过网络进行子空间约束的多任务学习的精确扩散算法的推广，并导出了在利用噪声梯度逼近时其均方偏差的准确表达式。我们在数值上验证了预测性能表达式的准确性，以及所提出的方法相对于基于近似投影的其他方法的性能改进。

    Classical paradigms for distributed learning, such as federated or decentralized gradient descent, employ consensus mechanisms to enforce homogeneity among agents. While these strategies have proven effective in i.i.d. scenarios, they can result in significant performance degradation when agents follow heterogeneous objectives or data. Distributed strategies for multitask learning, on the other hand, induce relationships between agents in a more nuanced manner, and encourage collaboration without enforcing consensus. We develop a generalization of the exact diffusion algorithm for subspace constrained multitask learning over networks, and derive an accurate expression for its mean-squared deviation when utilizing noisy gradient approximations. We verify numerically the accuracy of the predicted performance expressions, as well as the improved performance of the proposed approach over alternatives based on approximate projections.
    
[^59]: 光子场网络为动态实时体积全局光照技术提供支持

    Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination. (arXiv:2304.07338v1 [cs.GR])

    [http://arxiv.org/abs/2304.07338](http://arxiv.org/abs/2304.07338)

    本文提出了一种新的光子场网络方法，可以用于实现体积数据可视化的动态实时全局光照。我们的方法可以实现在体积数据中实现动态全局光照和材质变化的交互式帧率，为体积渲染提供了一种新的方式。

    

    体积数据在许多科学学科中常常出现，如医学、物理学和生物学等领域。专家们依赖于强大的科学可视化技术从数据中提取有价值的见解。近年来，路径追踪被认为是体积渲染的首选方法，因为它的实时全球光照效果非常真实。然而，实时体积路径追踪往往会受到随机噪声和长时间的收敛时间的限制，从而限制了交互式探索。在本文中，我们提出了一种新的方法，以实现体积数据可视化的实时全局光照。我们开发了Photon Field Networks——一种相位函数感知、多光源神经表示的间接体积全局光照技术。这些场在我们预先计算的多相光子缓存上进行训练。训练可以在几秒钟内完成，之后这些场就可以用于各种渲染任务。为了展示其潜力，我们开发了一个自定义的神经路径追踪器，使得我们的光子场可以实现在体积数据中实现动态全局光照和材质变化的交互式帧率。

    Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks -- a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achie
    
[^60]: HEAT：一种高效且经济实惠的基于CPU的协同过滤推荐训练系统

    HEAT: A Highly Efficient and Affordable Training System for Collaborative Filtering Based Recommendation on CPUs. (arXiv:2304.07334v1 [cs.DC])

    [http://arxiv.org/abs/2304.07334](http://arxiv.org/abs/2304.07334)

    这篇论文提出了HEAT训练系统，通过优化SimpleX在CPU上的操作，实现协同过滤的高效率训练

    

    协同过滤已被证明是推荐系统中最有效的技术之一。在所有协同过滤方法中，SimpleX是采用了新颖的损失函数和适当数量的负样本的最先进方法。然而，目前还没有对SimpleX在多核CPU上进行了优化，导致性能有限。为了解决这个问题，我们对现有的SimpleX实现进行了深入的分析，并确定了它们的性能瓶颈，包括(1)不规则的内存访问，(2)不必要的内存复制，(3)冗余计算。为了解决这些问题，我们提出了一种高效的CF训练系统(名为HEAT)，它充分发挥了现代CPU的多级缓存和多线程能力。具体而言，HEAT的优化有三个方面：(1)使用瓦片化技术增加数据局部性和减少缓存失效(从而减少读取延迟)；(2)使用随机梯度下降(SGD)和采样优化；(3)使用功能分区优化内存访问和计算

    Collaborative filtering (CF) has been proven to be one of the most effective techniques for recommendation. Among all CF approaches, SimpleX is the state-of-the-art method that adopts a novel loss function and a proper number of negative samples. However, there is no work that optimizes SimpleX on multi-core CPUs, leading to limited performance. To this end, we perform an in-depth profiling and analysis of existing SimpleX implementations and identify their performance bottlenecks including (1) irregular memory accesses, (2) unnecessary memory copies, and (3) redundant computations. To address these issues, we propose an efficient CF training system (called HEAT) that fully enables the multi-level caching and multi-threading capabilities of modern CPUs. Specifically, the optimization of HEAT is threefold: (1) It tiles the embedding matrix to increase data locality and reduce cache misses (thus reduce read latency); (2) It optimizes stochastic gradient descent (SGD) with sampling by par
    
[^61]: 揭示STEGO进行安全无监督语义分割的内部机制

    Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation. (arXiv:2304.07314v1 [cs.CV])

    [http://arxiv.org/abs/2304.07314](http://arxiv.org/abs/2304.07314)

    这篇论文详细研究了STEGO方法的内部机制和培训策略，揭示了其进行无监督语义分割的工作原理，可用于新领域的应用。

    

    最近，自监督预训练策略在计算机视觉中训练通用特征提取骨干网络方面取得了显著的成果。结合Vision Transformer架构，DINO自蒸馏技术具有有趣的新兴特性，如潜在空间中的无监督聚类和生成特征的语义对应，而不需要使用显式的人工标注标签。无监督语义分割的STEGO方法通过对DINO预训练的Vision Transformer的特征对应进行对比蒸馏，最近创造了一个新的最优性。然而，STEGO的详细工作机制尚未得到分解，阻碍了它在安全关键应用中的使用。本文通过进行研究，揭示了STEGO架构和培训策略的工作机制，重现和扩展其实验证，以及研究STEGO在新领域中的应用能力。

    Self-supervised pre-training strategies have recently shown impressive results for training general-purpose feature extraction backbones in computer vision. In combination with the Vision Transformer architecture, the DINO self-distillation technique has interesting emerging properties, such as unsupervised clustering in the latent space and semantic correspondences of the produced features without using explicit human-annotated labels. The STEGO method for unsupervised semantic segmentation contrastively distills feature correspondences of a DINO-pre-trained Vision Transformer and recently set a new state of the art. However, the detailed workings of STEGO have yet to be disentangled, preventing its usage in safety-critical applications. This paper provides a deeper understanding of the STEGO architecture and training strategy by conducting studies that uncover the working mechanisms behind STEGO, reproduce and extend its experimental validation, and investigate the ability of STEGO t
    
[^62]: M2T: 两次掩蔽变换提高解码速度的方法

    M2T: Masking Transformers Twice for Faster Decoding. (arXiv:2304.07313v1 [eess.IV])

    [http://arxiv.org/abs/2304.07313](http://arxiv.org/abs/2304.07313)

    本文证明预定义的确定性调度在图像压缩方面表现良好，使用双向变换器，遮挡注意力和激活缓存可以显著提高模型的速度。

    

    本文展示了双向变换器在遮挡令牌预测上的训练如何应用于神经图像压缩，从而实现了最先进的结果。此类模型以前曾被用于图像生成，采用根据不确定性自适应调度逐步采样遮蔽的令牌组。与这些作品不同，我们证明预定义的确定性调度在图像压缩方面表现良好甚至更好。这种见解使我们能够在训练期间使用遮挡注意力，除了遮挡输入之外，还使用激活缓存进行推理，从而显著提高我们的模型的速度（推理速度约高4倍），同时增加了一点码率。

    We show how bidirectional transformers trained for masked token prediction can be applied to neural image compression to achieve state-of-the-art results. Such models were previously used for image generation by progressivly sampling groups of masked tokens according to uncertainty-adaptive schedules. Unlike these works, we demonstrate that predefined, deterministic schedules perform as well or better for image compression. This insight allows us to use masked attention during training in addition to masked inputs, and activation caching during inference, to significantly speed up our models (~4 higher inference speed) at a small increase in bitrate.
    
[^63]: 面向电子病历和结构化医疗数据的联邦与分布式学习应用：范围审查

    Federated and distributed learning applications for electronic health records and structured medical data: A scoping review. (arXiv:2304.07310v1 [cs.LG])

    [http://arxiv.org/abs/2304.07310](http://arxiv.org/abs/2304.07310)

    本研究是一份面向电子病历和结构化医疗数据的联邦与分布式学习应用的范围审查，研究发现FL应用于结构化医学数据的研究大多集中在隐私保护方面，未来应该探索FL在降低通信成本和提高模型通用性方面的应用。

    

    在近年来的临床研究中，联邦学习（FL）已经在隐私保护协作方面获得了广泛的关注。随着电子健康记录在临床实践中的广泛应用，结构化数据作为最常见的临床数据形式之一，同时也经历了显着的增长。本研究检查了FL应用于结构化医学数据的应用，确定了当代的限制，并讨论了潜在的创新。我们在SCOPUS、MEDLINE、Web of Science、Embase和CINAHL等五个数据库中进行搜索，以识别将FL应用于结构化医学数据并根据PRISMA准则报告结果的文章。每篇选定的出版物从数据质量、建模策略和FL框架三个主要角度进行评估。经过筛选，34篇文章符合纳入标准，每篇文章包括一个或多个使用FL处理结构化临床/医学数据的研究。其中18个研究应用了FL来训练预测模型，而仅有2个研究调查了使用FL进行联邦迁移学习的应用。大多数研究集中在保护隐私方面，只有少数研究探索了FL的其他优点，如降低通信成本和提高模型通用性。本范围审查最后讨论了FL在结构化医疗数据背景下的挑战、限制和未来方向。

    Federated learning (FL) has gained popularity in clinical research in recent years to facilitate privacy-preserving collaboration. Structured data, one of the most prevalent forms of clinical data, has experienced significant growth in volume concurrently, notably with the widespread adoption of electronic health records in clinical practice. This review examines FL applications on structured medical data, identifies contemporary limitations and discusses potential innovations. We searched five databases, SCOPUS, MEDLINE, Web of Science, Embase, and CINAHL, to identify articles that applied FL to structured medical data and reported results following the PRISMA guidelines. Each selected publication was evaluated from three primary perspectives, including data quality, modeling strategies, and FL frameworks. Out of the 1160 papers screened, 34 met the inclusion criteria, with each article consisting of one or more studies that used FL to handle structured clinical/medical data. Of these
    
[^64]: 基于实际数据的铁路车辆轴承故障的声学分析检测

    Airborne-Sound Analysis for the Detection of Bearing Faults in Railway Vehicles with Real-World Data. (arXiv:2304.07307v1 [eess.AS])

    [http://arxiv.org/abs/2304.07307](http://arxiv.org/abs/2304.07307)

    本文介绍了一种基于实际数据进行铁路车辆轴承故障检测的声学分析方法，使用Mel频率倒谱系数(MFCC)作为特征，实验表明该方法可以可靠地检测轴承故障。

    

    本文针对在车辆正常运行期间记录的声学信号分析，探讨了铁路车辆轴承故障检测这一具有挑战性的问题。为此，我们引入了Mel频率倒谱系数(MFCC)作为特征，并作为输入提供给一个简单的多层感知器分类器。所提出的方法是在针对现代通勤铁路车辆进行测量活动中获得的实际数据评估的。实验表明，使用所选择的MFCC特征可以可靠地检测轴承故障，即使出现在训练中未包括的轴承损伤。

    In this paper, we address the challenging problem of detecting bearing faults in railway vehicles by analyzing acoustic signals recorded during regular operation. For this, we introduce Mel Frequency Cepstral Coefficients (MFCCs) as features, which form the input to a simple Multi-Layer Perceptron classifier. The proposed method is evaluated with real-world data that was obtained for state-of-the-art commuter railway vehicles in a measurement campaign. The experiments show that with the chosen MFCC features bearing faults can be reliably detected even for bearing damages that were not included in training.
    
[^65]: 有限专家预测下的学习推迟决策

    Learning to Defer with Limited Expert Predictions. (arXiv:2304.07306v1 [cs.LG])

    [http://arxiv.org/abs/2304.07306](http://arxiv.org/abs/2304.07306)

    本论文提出了一个三步方法，用于降低学习推迟算法所需的专家预测数量。该方法通过训练嵌入模型、使用少量的专家预测和利用样本相似性来提高性能。

    

    最近的研究表明，将人工智能模型与人类专家结合使用可以超出单独应用的性能。他们的能力结合通常通过学习推迟算法实现，这使得人工智能学会决定是否为特定样本做出预测或将其推迟给人类专家。然而，为了准确地学习哪些样本应该推迟给人类专家，需要大量准确反映专家能力的专家预测，除了训练人工智能所需的地面真实标签。这是许多学习推迟算法共享的要求，阻碍了它们在责任专家经常更改或获得足够的专家预测的成本较高的场景中的采用。在本文中，我们提出了一个三步方法来减少学习推迟算法所需的专家预测数量。它包括（1）使用地面真实标签训练嵌入模型，

    Recent research suggests that combining AI models with a human expert can exceed the performance of either alone. The combination of their capabilities is often realized by learning to defer algorithms that enable the AI to learn to decide whether to make a prediction for a particular instance or defer it to the human expert. However, to accurately learn which instances should be deferred to the human expert, a large number of expert predictions that accurately reflect the expert's capabilities are required -- in addition to the ground truth labels needed to train the AI. This requirement shared by many learning to defer algorithms hinders their adoption in scenarios where the responsible expert regularly changes or where acquiring a sufficient number of expert predictions is costly. In this paper, we propose a three-step approach to reduce the number of expert predictions required to train learning to defer algorithms. It encompasses (1) the training of an embedding model with ground 
    
[^66]: 基于数据增强和正则化技术的一维残差卷积神经网络在ICPHM 2023数据挑战赛中的应用

    1-D Residual Convolutional Neural Network coupled with Data Augmentation and Regularization Techniques for the ICPHM 2023 Data Challenge. (arXiv:2304.07305v1 [eess.AS])

    [http://arxiv.org/abs/2304.07305](http://arxiv.org/abs/2304.07305)

    本文提出的一维残差卷积神经网络结合了数据增强和正则化技术，在ICPHM 2023数据挑战赛中应用于太阳齿轮故障分类任务。即使面对多个操作条件下获得的数据，该网络仍能准确预测被检测齿轮箱的状态。

    

    本文介绍了我们在ICPHM 2023挑战赛中对于利用振动分析进行工业系统健康监测的太阳齿轮故障分类任务的贡献。我们提出了一种基于三通道时间域振动信号的残差卷积神经网络。结合数据增强和正则化技术，尽管其可训练参数少于30,000个，该模型在多类别分类场景中使用真实世界数据产生了非常好的结果。即使面对多个操作条件下获得的数据，该网络仍能准确预测被检测齿轮箱的状态。

    In this article, we present our contribution to the ICPHM 2023 Data Challenge on Industrial Systems' Health Monitoring using Vibration Analysis. For the task of classifying sun gear faults in a gearbox, we propose a residual Convolutional Neural Network that operates on raw three-channel time-domain vibration signals. In conjunction with data augmentation and regularization techniques, the proposed model yields very good results in a multi-class classification scenario with real-world data despite its relatively small size, i.e., with less than 30,000 trainable parameters. Even when presented with data obtained from multiple operating conditions, the network is still capable to accurately predict the condition of the gearbox under inspection.
    
[^67]: 自监督学习模型在基于传感器的人类活动识别中的表达解释、分析和探究

    Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition. (arXiv:2304.07304v1 [cs.LG])

    [http://arxiv.org/abs/2304.07304](http://arxiv.org/abs/2304.07304)

    本文探究了基于传感器的人类活动识别中自监督学习框架的深度表示，通过解释这些表示与有监督表示的区别，比较它们的鲁棒性，并使用显著图将其应用于预测不同的活动。

    

    近年来，自监督学习（SSL）框架被广泛应用于基于传感器的人类活动识别（HAR），以便学习深度表示而不需要数据注释。虽然SSL框架的性能几乎与监督模型相当，但对SSL模型学习的表示进行解释的研究却很有限。然而，现代解释方法可以帮助揭示SSL表示与监督表示之间的差异：它们是如何被学习的、它们保留了哪些输入数据属性，以及何时可以选择SSL进行训练。本文旨在分析两个最近的SSL框架SimCLR和VICReg的深度表示。具体而言，重点放在以下几个方面：(i) 比较监督和SSL模型对输入数据中的破坏的鲁棒性；(ii) 使用显著图解释深度学习模型的预测，并突出显示用于预测各种活动的主要输入通道。

    In recent years, self-supervised learning (SSL) frameworks have been extensively applied to sensor-based Human Activity Recognition (HAR) in order to learn deep representations without data annotations. While SSL frameworks reach performance almost comparable to supervised models, studies on interpreting representations learnt by SSL models are limited. Nevertheless, modern explainability methods could help to unravel the differences between SSL and supervised representations: how they are being learnt, what properties of input data they preserve, and when SSL can be chosen over supervised training. In this paper, we aim to analyze deep representations of two recent SSL frameworks, namely SimCLR and VICReg. Specifically, the emphasis is made on (i) comparing the robustness of supervised and SSL models to corruptions in input data; (ii) explaining predictions of deep learning models using saliency maps and highlighting what input channels are mostly used for predicting various activitie
    
[^68]: 智慧地铁：深度学习在预测菲律宾马尼拉地铁三号线乘客量上的应用

    Smart Metro: Deep Learning Approaches to Forecasting the MRT Line 3 Ridership. (arXiv:2304.07303v1 [cs.LG])

    [http://arxiv.org/abs/2304.07303](http://arxiv.org/abs/2304.07303)

    本研究使用时间序列模型预测菲律宾马尼拉地铁三号线每天乘客量的变化，帮助人们更好地规划出行。

    

    自1999年建立以来，菲律宾马尼拉地铁三号线（MRT3）为众多乘客提供了交通选择。菲律宾政府交通部记录每天有超过一千人使用MRT3，预测每天的乘客数量可能相当具有挑战性，受假期、工作日和其他意外问题等变量影响，MRT3的日常乘客量波动较大。乘客无法知道某一天他们所乘路线上有多少其他乘客，这可能会妨碍他们规划高效行程的能力。目前，菲律宾交通运输部依赖包含历史数据的电子表格，这可能难以检查。本研究提出了一种时间序列预测模型，可以预测特定日期某个车站的未来出勤人数。

    Since its establishment in 1999, the Metro Rail Transit Line 3 (MRT3) has served as a transportation option for numerous passengers in Metro Manila, Philippines. The Philippine government's transportation department records more than a thousand people using the MRT3 daily and forecasting the daily passenger count may be rather challenging. The MRT3's daily ridership fluctuates owing to variables such as holidays, working days, and other unexpected issues. Commuters do not know how many other commuters are on their route on a given day, which may hinder their ability to plan an efficient itinerary. Currently, the DOTr depends on spreadsheets containing historical data, which might be challenging to examine. This study presents a time series prediction of daily traffic to anticipate future attendance at a particular station on specific days.
    
[^69]: HGWaveNet: 一种用于时间链接预测的双曲图神经网络

    HGWaveNet: A Hyperbolic Graph Neural Network for Temporal Link Prediction. (arXiv:2304.07302v1 [cs.LG])

    [http://arxiv.org/abs/2304.07302](http://arxiv.org/abs/2304.07302)

    HGWaveNet是一种双曲图神经网络，用于时间链接预测。它包括超曲率扩散图卷积和小波时间卷积两个关键模块，可有效聚合邻居信息和捕捉时间依赖，并在真实世界数据集上表现出更好的精度和效率。

    

    时间链接预测旨在预测动态图中成对节点之间的未来边缘，是各种应用中非常重要的领域。然而，现有方法主要建立在均匀的欧几里得空间上，这与现实世界图形的幂律分布相矛盾，无法有效地表示节点之间的分层连接。针对这种特殊的数据特征，双曲几何提供了一种理想的替代方案，因为它具有指数扩展特性。在本文中，我们提出了HGWaveNet，一种新颖的双曲图神经网络，充分利用了超几何空间与数据分布之间的相适应性，用于时间链接预测。具体而言，我们设计了两个关键模块来分别学习空间拓扑结构和时间演变信息。一方面，超曲率扩散图卷积 (HDGC) 模块有效地聚合了更广泛的邻居信息。另一方面，基于小波的时间卷积 (WTC) 模块通过转换时间域特征来捕捉时间依赖性。在真实世界数据集上的实验表明，HGWaveNet在精度和效率方面优于现有的最先进方法。

    Temporal link prediction, aiming to predict future edges between paired nodes in a dynamic graph, is of vital importance in diverse applications. However, existing methods are mainly built upon uniform Euclidean space, which has been found to be conflict with the power-law distributions of real-world graphs and unable to represent the hierarchical connections between nodes effectively. With respect to the special data characteristic, hyperbolic geometry offers an ideal alternative due to its exponential expansion property. In this paper, we propose HGWaveNet, a novel hyperbolic graph neural network that fully exploits the fitness between hyperbolic spaces and data distributions for temporal link prediction. Specifically, we design two key modules to learn the spatial topological structures and temporal evolutionary information separately. On the one hand, a hyperbolic diffusion graph convolution (HDGC) module effectively aggregates information from a wider range of neighbors. On the ot
    
[^70]: 用于乳腺癌风险分析和生存预测的监督学习机器学习

    Supervised Machine Learning for Breast Cancer Risk Factors Analysis and Survival Prediction. (arXiv:2304.07299v1 [cs.LG])

    [http://arxiv.org/abs/2304.07299](http://arxiv.org/abs/2304.07299)

    本研究利用机器学习方法预测了乳腺癌患者的5年生存率，并比较了七种分类模型的表现，结果表明这些模型能够准确地预测测试样本的生存率，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。

    

    选择最有效的治疗方案可能会受到乳腺癌生存预测的影响。为了预测患者存活的机会，采用了多种技术，如统计学、机器学习和深度学习模型等。本研究利用METABRIC数据集中的1904条患者记录，采用机器学习方法预测5年乳腺癌生存。在本研究中，我们比较了七种分类模型的结果，评估它们的表现如下：召回率、AUC、混淆矩阵、准确度、精确度、假正率和真正率。结果表明，Logistic回归(LR)、支持向量机(SVM)、决策树(DT)、随机森林(RD)、极端随机化树(ET)、K-近邻(KNN)和自适应增强(AdaBoost)的分类器可以准确地预测测试样本的生存率，分别是75.4％、74.7％、71.5％、75.5％、70.3％、72.5％和72.2％。这些结果表明，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。

    The choice of the most effective treatment may eventually be influenced by breast cancer survival prediction. To predict the chances of a patient surviving, a variety of techniques were employed, such as statistical, machine learning, and deep learning models. In the current study, 1904 patient records from the METABRIC dataset were utilized to predict a 5-year breast cancer survival using a machine learning approach. In this study, we compare the outcomes of seven classification models to evaluate how well they perform using the following metrics: recall, AUC, confusion matrix, accuracy, precision, false positive rate, and true positive rate. The findings demonstrate that the classifiers for Logistic Regression (LR), Support Vector Machines (SVM), Decision Tree (DT), Random Forest (RD), Extremely Randomized Trees (ET), K-Nearest Neighbor (KNN), and Adaptive Boosting (AdaBoost) can accurately predict the survival rate of the tested samples, which is 75,4\%, 74,7\%, 71,5\%, 75,5\%, 70,3
    
[^71]: 道路网络表示学习：一种基于双重图的方法

    Road Network Representation Learning: A Dual Graph based Approach. (arXiv:2304.07298v1 [cs.LG])

    [http://arxiv.org/abs/2304.07298](http://arxiv.org/abs/2304.07298)

    提出了一种基于双重图的方法来解决传统道路网络表示学习模型无法捕捉道路之间高阶和远程关系的问题。

    

    道路网络是支撑许多实际应用，包括交通、移动性和物流的关键基础设施。为了利用道路网络在这些不同的应用中的输入，有必要学习道路的向量表示形式，称为道路网络表示学习（RNRL）。虽然已经提出了几种 RNRL 模型，但它们只捕捉道路之间的成对关系 / 连接（即作为简单图），无法捕捉道路之间的高阶关系（例如，那些共同形成本地区域的道路通常具有类似的特征，例如速度限制）和远程关系（例如，一些相距较远的道路可能具有类似的语义，例如是住宅区道路）。出于这个原因，我们提出构建一个“超图”，其中每个超边对应于构成区域的多条道路的集合。构建的超图会自然地捕捉到道路之间的高阶关系和远程关系。

    Road network is a critical infrastructure powering many applications including transportation, mobility and logistics in real life. To leverage the input of a road network across these different applications, it is necessary to learn the representations of the roads in the form of vectors, which is named \emph{road network representation learning} (RNRL). While several models have been proposed for RNRL, they capture the pairwise relationships/connections among roads only (i.e., as a simple graph), and fail to capture among roads the high-order relationships (e.g., those roads that jointly form a local region usually have similar features such as speed limit) and long-range relationships (e.g., some roads that are far apart may have similar semantics such as being roads in residential areas). Motivated by this, we propose to construct a \emph{hypergraph}, where each hyperedge corresponds to a set of multiple roads forming a region. The constructed hypergraph would naturally capture the
    
[^72]: 语言指导下的强化学习以实现人工智能协作

    Language Instructed Reinforcement Learning for Human-AI Coordination. (arXiv:2304.07297v1 [cs.AI])

    [http://arxiv.org/abs/2304.07297](http://arxiv.org/abs/2304.07297)

    本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。

    

    人工智能的一个基本问题是如何让智能体能够和人类有效地协作。本文提出了一种称之为instructRL的新的框架，让人们可以通过自然语言指令来指定对人工智能搭档的预期策略，以此解决在缺乏较高质量的人类行为数据的领域中，由于多智能体强化学习常常会收敛到人类并不偏爱的策略的不足。我们使用预先训练的大型语言模型来生成一个在人类指令下的先验策略，并将其用于约束强化学习目标。这导致强化学习智能体收敛到与人类喜好一致的均衡点。通过概念证明环境和具有挑战性的Hanabi基准，证明了instructRL收敛于满足给定指令的类似人类智能体的策略。最后，我们证明了知道语言指令显著提高了人工智能协作的性能。

    One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination pe
    
[^73]: 利用自监督学习和视觉转换器制作亚米级冠层高度图

    Sub-meter resolution canopy height maps using self-supervised learning and a vision transformer trained on Aerial and GEDI Lidar. (arXiv:2304.07213v1 [cs.CV])

    [http://arxiv.org/abs/2304.07213](http://arxiv.org/abs/2304.07213)

    本文使用自监督学习和视觉转换器方法，制作了亚米级冠层高度图，可用于细粒度的植被结构监测，为碳通量评估和土地利用管理提供宝贵信息。

    

    植被结构的映射对于理解全球碳循环和监测基于自然的气候适应和减缓方法至关重要。本文利用自监督学习和视觉转换器方法，使用航空和GEDI激光遥感数据制作了亚米级冠层高度图。该方法在两个基准数据集上取得了最先进的结果，并具有更高的精度和空间分辨率。制作的冠层高度图可以实现细粒度的植被结构监测，为碳通量评估和土地利用管理提供宝贵信息。

    Vegetation structure mapping is critical for understanding the global carbon cycle and monitoring nature-based approaches to climate adaptation and mitigation. Repeat measurements of these data allow for the observation of deforestation or degradation of existing forests, natural forest regeneration, and the implementation of sustainable agricultural practices like agroforestry. Assessments of tree canopy height and crown projected area at a high spatial resolution are also important for monitoring carbon fluxes and assessing tree-based land uses, since forest structures can be highly spatially heterogeneous, especially in agroforestry systems. Very high resolution satellite imagery (less than one meter (1m) ground sample distance) makes it possible to extract information at the tree level while allowing monitoring at a very large scale. This paper presents the first high-resolution canopy height map concurrently produced for multiple sub-national jurisdictions. Specifically, we produc
    
[^74]: Vax-Culture: 用于研究推特上疫苗讨论的数据集

    Vax-Culture: A Dataset for Studying Vaccine Discourse on Twitter. (arXiv:2304.06858v1 [cs.SI])

    [http://arxiv.org/abs/2304.06858](http://arxiv.org/abs/2304.06858)

    本文介绍了一个推特疫苗数据集Vax-Culture，它旨在找出推广疫苗错误信息的文化和政治信念的重叠部分，帮助开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。

    

    COVID-19疫情期间，疫苗犹豫继续是公共卫生官员面临的主要挑战。由于该犹豫破坏了疫苗运动，许多研究人员试图确定其根本原因，并发现社交媒体平台上反疫苗错误信息的不断增长是该问题的关键因素。我们将推特作为误导内容的来源，并旨在提取推广疫苗错误信息的文化和政治信念的重叠部分。为此，我们收集了一个与疫苗有关的推文数据集，并借助专业沟通和新闻背景的注释人员进行注释。我们最终希望这可以带来有效和有针对性的公共卫生通信策略，以接触那些持反疫苗信仰者。此外，这些信息有助于开发机器学习模型以自动检测疫苗错误信息帖子并应对其负面影响。

    Vaccine hesitancy continues to be a main challenge for public health officials during the COVID-19 pandemic. As this hesitancy undermines vaccine campaigns, many researchers have sought to identify its root causes, finding that the increasing volume of anti-vaccine misinformation on social media platforms is a key element of this problem. We explored Twitter as a source of misleading content with the goal of extracting overlapping cultural and political beliefs that motivate the spread of vaccine misinformation. To do this, we have collected a data set of vaccine-related Tweets and annotated them with the help of a team of annotators with a background in communications and journalism. Ultimately we hope this can lead to effective and targeted public health communication strategies for reaching individuals with anti-vaccine beliefs. Moreover, this information helps with developing Machine Learning models to automatically detect vaccine misinformation posts and combat their negative impa
    
[^75]: SpectFormer: 频率和注意力是视觉Transformer所需要的。

    SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v1 [cs.CV])

    [http://arxiv.org/abs/2304.06446](http://arxiv.org/abs/2304.06446)

    本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。

    

    视觉Transformer已成功地应用于图像识别任务中。其种类包括基于多头自我注意力机制（如ViT、DeIT）和基于谱层（如Fnet、GFNet、AFNO）的模型。本文发现，多头注意力和谱层都对Transformer起到重要作用，将两者结合可以得到更好的性能表现。因此提出了新的Spectformer架构，将多头注意力和谱层融合起来。实验表明，Spectformer可恰当地捕捉特征表示，与其他Transformer表征相比，可以提高top-1准确率2%。

    Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2
    
[^76]: 一种具有物体感知等变基元反应扩散模型的精确过渡态生成方法

    Accurate transition state generation with an object-aware equivariant elementary reaction diffusion model. (arXiv:2304.06174v1 [physics.chem-ph])

    [http://arxiv.org/abs/2304.06174](http://arxiv.org/abs/2304.06174)

    本文开发了一种物体感知 SE(3) 等变扩散模型，可以在几秒钟内精确地生成过渡态结构，与基于量子化学的优化相比，计算时间大大缩短，其生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差，可以实现反应速率估计所需的精度。

    

    过渡态搜索在化学中具有重要作用，可用于阐明反应机理和探索反应网络。但搜索精确的三维过渡态结构需要大量的量子化学计算，因为势能面的复杂性。本文开发了一种物体感知 SE(3) 等变扩散模型，满足生成反应物、过渡态和生成物三种结构的所有物理对称性和约束条件。在已知反应物和生成物的情况下，该模型可以在几秒钟内生成过渡态结构，而不需要进行基于量子化学的优化，从而大大缩短了计算时间。生成的过渡态结构与真实结构的平均误差为 0.13 A 根均方差。通过对不确定性进行评估，并进行置信度评分，可以实现反应速率估计所需的精度 (2.6 kcal/mol)，并且只需对 14% 的结果进行基于量子化学的优化。

    Transition state (TS) search is key in chemistry for elucidating reaction mechanisms and exploring reaction networks. The search for accurate 3D TS structures, however, requires numerous computationally intensive quantum chemistry calculations due to the complexity of potential energy surfaces. Here, we developed an object-aware SE(3) equivariant diffusion model that satisfies all physical symmetries and constraints for generating pairs of structures, i.e., reactant, TS, and product, in an elementary reaction. Provided reactant and product, this model generates a TS structure in seconds instead of the hours required when performing quantum chemistry-based optimizations. The generated TS structures achieve an average error of 0.13 A root mean square deviation compared to true TS. With a confidence scoring model for uncertainty quantification, we approach an accuracy required for reaction rate estimation (2.6 kcal/mol) by only performing quantum chemistry-based optimizations on 14% of th
    
[^77]: 一种易于编辑的DDPM噪声空间：反演与操作

    An Edit Friendly DDPM Noise Space: Inversion and Manipulations. (arXiv:2304.06140v1 [cs.CV])

    [http://arxiv.org/abs/2304.06140](http://arxiv.org/abs/2304.06140)

    本文提出了一种易于编辑的DDPM噪声空间，可以通过简单手段进行广泛的编辑操作，并提出了一种用于提取编辑友好噪声图的反演方法。

    

    降噪扩散概率模型（DDPM）利用一系列白噪声样本生成图像。类似于GAN，这些噪声图可以看作是生成图像相关的潜在代码。然而，这种原始噪声空间没有方便的结构，因此在编辑任务中很难使用。本文提出了一种替代DDPM的潜在噪声空间，可通过简单手段进行广泛的编辑操作，并提出一种用于提取任何给定图像（真实或合成生成）的易于编辑噪声图的反演方法。

    Denoising diffusion probabilistic models (DDPMs) employ a sequence of white Gaussian noise samples to generate an image. In analogy with GANs, those noise maps could be considered as the latent code associated with the generated image. However, this native noise space does not possess a convenient structure, and is thus challenging to work with in editing tasks. Here, we propose an alternative latent noise space for DDPM that enables a wide range of editing operations via simple means, and present an inversion method for extracting these edit-friendly noise maps for any given image (real or synthetically generated). As opposed to the native DDPM noise space, the edit-friendly noise maps do not have a standard normal distribution and are not statistically independent across timesteps. However, they allow perfect reconstruction of any desired image, and simple transformations on them translate into meaningful manipulations of the output image (e.g., shifting, color edits). Moreover, in t
    
[^78]: 基于符合性预测和符合性风险控制的有信心物体检测：铁路信号应用研究

    Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling. (arXiv:2304.06052v1 [cs.LG])

    [http://arxiv.org/abs/2304.06052](http://arxiv.org/abs/2304.06052)

    本文展示了利用符合性预测框架构建可靠、值得信赖的铁路信号预测器的方法，并引入一种基于符合性风险控制的新方法。研究结果表明符合性预测框架有潜力为实现正式保证的不确定性边界提供实用指导。

    

    在实际认证系统中使用深度学习模型需要提供能够准确反映不确定性的置信度估计。本文演示了利用符合性预测框架构建可靠的、值得信赖的检测铁路信号的预测器的方法。我们使用包含火车操作员视角下的图像和最先进的物体检测器的新数据集。我们测试了几种符合性方法，并引入了一种基于符合性风险控制的新方法。研究结果表明符合性预测框架评估模型性能和提供正式保证的不确定性边界具有潜力，为实现这一目标提供了实用指导。

    Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.
    
[^79]: 我们实现了个性化治疗吗？使用重复采样的在线强化学习算法进行个性化评估

    Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])

    [http://arxiv.org/abs/2304.05365](http://arxiv.org/abs/2304.05365)

    本论文提出了一种使用重复采样的政策评估方法，以评估在线 RL 算法实现的个性化程度。该方法可用于优化数字健康的个性化干预。

    

    在数字健康中，使用强化学习（RL）个性化治疗序列以支持用户采取更健康的行为越来越受到关注。这种连续决策问题涉及到基于用户的上下文（例如，先前的活动水平、位置等）在何时治疗以及如何治疗的决定。在线RL算法是这个问题的一个有前途的数据驱动方法，因为它基于每个用户的历史反馈进行学习，并利用这些知识个性化这些决策。然而，要决定是否应在实际部署的“优化”干预中包含RL算法，我们必须评估数据证据，表明RL算法实际上正在将治疗个性化适应其用户。由于RL算法中的随机性，人们可能会对其在某些状态下的学习并使用此学习来提供特定治疗的能力产生误解。我们使用工作定义的个性化，并介绍了一种重复采样政策评估方法来评估在线RL算法实现的个性化水平。我们使用模拟评估了我们提出的方法，并展示了我们的方法可以准确地识别个性化的策略。我们提出的方法在优化数字健康的个性化干预方面具有潜在应用。

    There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
    
[^80]: 重新构想负提示算法：将2D扩散转化为3D，缓解“扬尼斯问题”等等

    Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond. (arXiv:2304.04968v1 [cs.CV])

    [http://arxiv.org/abs/2304.04968](http://arxiv.org/abs/2304.04968)

    本研究提出了Perp-Neg算法，通过利用得分空间的几何特性来解决目前文本到图像扩散模型中负面提示算法存在的问题，使得用户能够编辑掉初始生成图像中不想要的概念，从而提供了更大的灵活性。同时，我们还通过提出基于Perp-Neg的3D负面提示算法，将算法扩展到3D应用中。

    

    尽管文本到图像扩散模型在从文本生成图像方面取得了显著进展，但它们有时更倾向于生成类似于模型训练数据的图像，而不是提供的文本。这限制了它们在2D和3D应用中的使用。为了解决这个问题，我们探索了使用负面提示，但发现当前的实现无法产生期望的结果，特别是当主提示和负面提示之间存在重叠时。为了克服这个问题，我们提出Perp-Neg，一种利用得分空间的几何特性来解决当前负性提示算法缺点的新算法。Perp-Neg不需要对模型进行任何训练或微调。此外，我们通过实验表明，Perp-Neg通过在2D情况下使用户能够编辑掉初始生成的图像中不想要的概念，提供了生成图像更大的灵活性。此外，为了扩展我们的算法到3D应用，我们还提出了一种基于Perp-Neg的3D负面提示算法。

    Although text-to-image diffusion models have made significant strides in generating images from text, they are sometimes more inclined to generate images like the data on which the model was trained rather than the provided text. This limitation has hindered their usage in both 2D and 3D applications. To address this problem, we explored the use of negative prompts but found that the current implementation fails to produce desired results, particularly when there is an overlap between the main and negative prompts. To overcome this issue, we propose Perp-Neg, a new algorithm that leverages the geometrical properties of the score space to address the shortcomings of the current negative prompts algorithm. Perp-Neg does not require any training or fine-tuning of the model. Moreover, we experimentally demonstrate that Perp-Neg provides greater flexibility in generating images by enabling users to edit out unwanted concepts from the initially generated images in 2D cases. Furthermore, to e
    
[^81]: SAM与BET：基于深度学习的磁共振图像脑提取和分割的比较研究

    SAM vs BET: A Comparative Study for Brain Extraction and Segmentation of Magnetic Resonance Images using Deep Learning. (arXiv:2304.04738v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2304.04738](http://arxiv.org/abs/2304.04738)

    该论文比较了采用深度学习模型的SAM与传统方法BET在MRI脑提取方面的效果，结果表明SAM在信号不均匀、非等向性分辨率或病变靠近脑外区域和脑膜时效果更佳，SAM表现出更准确、更健壮和更多样化的潜力。

    

    脑提取是神经成像研究中的关键预处理步骤，涉及使用MRI数据将脑组织与非脑组织分离。FSL的脑提取工具（BET）是当前的金标准，但由于图像质量问题容易出错。Meta AI的Segment Anything Model（SAM）显示出有希望的零样本分割潜力。本文比较了SAM和BET在不同的脑扫描中的脑提取效果，考虑了图像质量、MRI序列和病变位置。结果表明，在各种评估参数方面，SAM胜过BET，特别是在信号不均匀、非等向性体素分辨率或病变靠近脑外区域和脑膜的情况下。SAM优越的性能表明其在脑提取和分割应用中具有更准确、更健壮和更多样化的潜力。

    Brain extraction is a critical preprocessing step in neuroimaging studies, involving the separation of brain tissue from non-brain tissue using MRI data. FSL's Brain Extraction Tool (BET) is the current gold standard but is prone to errors due to image quality issues. The Segment Anything Model (SAM) by Meta AI has shown promising zero-shot segmentation potential. This paper compares SAM with BET for brain extraction on diverse brain scans, considering image quality, MRI sequences, and lesion locations. Results demonstrate that SAM outperforms BET in various evaluation parameters, particularly in cases with signal inhomogeneities, non-isotropic voxel resolutions, or lesions near the brain's outer regions and meninges. SAM's superior performance indicates its potential as a more accurate, robust, and versatile tool for brain extraction and segmentation applications.
    
[^82]: 应用机器学习和领域知识个性化数字健康行为变革干预

    Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge. (arXiv:2304.03392v1 [cs.LG])

    [http://arxiv.org/abs/2304.03392](http://arxiv.org/abs/2304.03392)

    该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。

    

    我们正在开发一种虚拟教练系统，帮助患者坚持行为变革干预（BCI）。我们的系统预测患者是否会执行目标行为，并使用反事实例子进行特征控制，以指导个性化BCI。我们使用具有不同响应水平的模拟患者数据评估了我们的预测模型。

    We are developing a virtual coaching system that helps patients adhere to behavior change interventions (BCI). Our proposed system predicts whether a patient will perform the targeted behavior and uses counterfactual examples with feature control to guide personalizsation of BCI. We evaluated our prediction model using simulated patient data with varying levels of receptivity to intervention.
    
[^83]: 以深度学习为基础的图像曝光增强作为准确的三维结肠表面重建的预处理

    Deep learning-based image exposure enhancement as a pre-processing for an accurate 3D colon surface reconstruction. (arXiv:2304.03171v1 [eess.IV])

    [http://arxiv.org/abs/2304.03171](http://arxiv.org/abs/2304.03171)

    本文研究了基于深度学习的三维结肠表面重建，在图像预处理的过程中通过纠正局部欠曝光和过曝光来提高重建精度。

    

    本文介绍了如何通过适当的图像预处理改善基于深度学习的结肠部分三维重建。假设在内窥镜检查中应该纠正局部欠曝光和过曝光而不是全局图像照明校正。首先概述了包括图像曝光校正和循环神经网络-SLAM的流程。然后，本文比较了在与适当照明校正和无校正的情况下结肠内镜轨迹的重建精度。

    This contribution shows how an appropriate image pre-processing can improve a deep-learning based 3D reconstruction of colon parts. The assumption is that, rather than global image illumination corrections, local under- and over-exposures should be corrected in colonoscopy. An overview of the pipeline including the image exposure correction and a RNN-SLAM is first given. Then, this paper quantifies the reconstruction accuracy of the endoscope trajectory in the colon with and without appropriate illumination correction
    
[^84]: 对比学习中的合成难负样本

    Synthetic Hard Negative Samples for Contrastive Learning. (arXiv:2304.02971v1 [cs.CV])

    [http://arxiv.org/abs/2304.02971](http://arxiv.org/abs/2304.02971)

    本文提出一种新的方法，称为SSCL，可以更好地利用难以区分出的负样本，提高对比学习的性能。

    

    对比学习已成为计算机视觉自监督学习的重要方法。其核心目标是在最大化同一图像的两个增强版本之间的相似性（正对），同时最小化不同图像之间的相似性（负对）。最近的研究表明，难度更大的负样本，即难以从锚定样本中区分出的样本，在对比学习中发挥了更为关键的作用。本文提出了一种新的特征层方法，即用于对比学习的合成难负样本（SSCL）的采样，更有效地利用了更难的负样本。具体地，1）我们通过混合负样本生成更多和更难的负样本，然后通过控制锚点样本与其他负样本之间的对比度来对这些负样本进行采样。2）考虑到通过采样得到的负样本可能存在假负样本的问题，我们建议注重减轻这个问题。

    Contrastive learning has emerged as an essential approach for self-supervised learning in computer vision. The central objective of contrastive learning is to maximize the similarities between two augmented versions of the same image (positive pairs), while minimizing the similarities between different images (negative pairs). Recent studies have demonstrated that harder negative samples, i.e., those that are difficult to distinguish from anchor sample, play a more critical role in contrastive learning. In this paper, we propose a novel featurelevel method, namely sampling synthetic hard negative samples for contrastive learning (SSCL), to exploit harder negative samples more effectively. Specifically, 1) we generate more and harder negative samples by mixing negative samples, and then sample them by controlling the contrast of anchor sample with the other negative samples. 2) Considering that the negative samples obtained by sampling may have the problem of false negative samples, we 
    
[^85]: 学习比较纵向图像

    Learning to Compare Longitudinal Images. (arXiv:2304.02531v1 [eess.IV])

    [http://arxiv.org/abs/2304.02531](http://arxiv.org/abs/2304.02531)

    本文提出了一种名为PaIRNet的深度学习模型，用于比较带有或不带有预处理的纵向图像对，以检测生物医学应用中与研究问题相关的变化。

    

    纵向研究是生物医学应用中研究和描述时间动态的常用技术，其中从相同的人群中在不同时间点获取一系列图像。传统的纵向比较方法是通过预处理来标准化噪声变化，例如图像方向或对比度差异，然后进行统计分析以检测感兴趣的变化。本文提出了一种基于简单机器学习的方法 PaIRNet，它可以减轻这些问题。在我们的方法中，我们训练一个深度学习模型来比较纵向图像对，无论是否进行预处理。PaIRNet学习识别两个图像之间的最具辨别性的区域，并提供相似度得分以反映它们的差异。

    Longitudinal studies, where a series of images from the same set of individuals are acquired at different time-points, represent a popular technique for studying and characterizing temporal dynamics in biomedical applications. The classical approach for longitudinal comparison involves normalizing for nuisance variations, such as image orientation or contrast differences, via pre-processing. Statistical analysis is, in turn, conducted to detect changes of interest, either at the individual or population level. This classical approach can suffer from pre-processing issues and limitations of the statistical modeling. For example, normalizing for nuisance variation might be hard in settings where there are a lot of idiosyncratic changes. In this paper, we present a simple machine learning-based approach that can alleviate these issues. In our approach, we train a deep learning model (called PaIRNet, for Pairwise Image Ranking Network) to compare pairs of longitudinal images, with or witho
    
[^86]: 根据数据的维度鲁棒性选择特征

    Selecting Features by their Resilience to the Curse of Dimensionality. (arXiv:2304.02455v1 [cs.LG])

    [http://arxiv.org/abs/2304.02455](http://arxiv.org/abs/2304.02455)

    该研究提出了一种新的特征选择方法，通过识别能够区分不同大小数据子集的特征来降低高维数据的复杂性。实验表明，该方法具有竞争力，并通常优于其他已有的特征选择方法。此外，该方法可扩展到由数百万数据点组成的数据集。

    

    真实世界中的数据集通常维度很高，并受到维度诅咒的影响，这阻碍了它们的可理解性和可解释性。为了降低复杂度，特征选择旨在识别对于学习数据至关重要的特征。虽然相关性和成对相似性的度量通常被使用，但维度诅咒很少被纳入到选择特征的过程中。本文提出了一种新的方法，通过识别能够区分不同大小数据子集的特征来降低维度诅咒。通过调整最近关于计算内在维度的工作，我们的方法能够选择能够区分数据的特征，并因此减弱维度诅咒。我们的实验表明，我们的方法具有竞争力，并通常优于成熟的特征选择方法。此外，我们提出了一个近似方法，使我们的方法可扩展到由数百万数据点组成的数据集。我们的研究结果表明，特征强度方法更加鲁棒，选择的特征更加适用于高维数据集。

    Real-world datasets are often of high dimension and effected by the curse of dimensionality. This hinders their comprehensibility and interpretability. To reduce the complexity feature selection aims to identify features that are crucial to learn from said data. While measures of relevance and pairwise similarities are commonly used, the curse of dimensionality is rarely incorporated into the process of selecting features. Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes. By adapting recent work on computing intrinsic dimensionalities, our method is able to select the features that can discriminate data and thus weaken the curse of dimensionality. Our experiments show that our method is competitive and commonly outperforms established feature selection methods. Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points. Our findings suggest that fea
    
[^87]: 通过拓扑操作管理电力网络：先进基于规则和强化学习的智能体比较研究

    Managing power grids through topology actions: A comparative study between advanced rule-based and reinforcement learning agents. (arXiv:2304.00765v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.00765](http://arxiv.org/abs/2304.00765)

    本研究分析了使用强化学习和基于规则方法的电力网络运行智能体并提供了新策略。其中最主要的改进是采用N-1策略，考虑到在某条线路断开时的拓扑操作以保持网络稳定。另外，拓扑反转也有利于提高性能。在挑战测试集上，该方法的性能提高了27%。

    

    由于当前形势的动荡和可再生能源生产的增加，电力网络运行变得越来越复杂。因此，传统方法的主动网格管理已经达到了极限。通过“学习运行电力网络”挑战，我们发现增强学习是一种有效可靠的自动化网格运行方法。本文分析了Binbinchen提交的代理，并提供了改进强化学习和基于规则方法的新策略。主要的改进是N-1策略，即考虑到在某条线路断开时，仍可保持网络稳定的拓扑操作。此外，我们还提出了将拓扑结构恢复到原始状态的拓扑反转，证明其有益。基于我们的改进方法，在挑战测试集上，我们的方法能够使基于规则的智能体性能提高27％。

    The operation of electricity grids has become increasingly complex due to the current upheaval and the increase in renewable energy production. As a consequence, active grid management is reaching its limits with conventional approaches. In the context of the Learning to Run a Power Network challenge, it has been shown that Reinforcement Learning (RL) is an efficient and reliable approach with considerable potential for automatic grid operation. In this article, we analyse the submitted agent from Binbinchen and provide novel strategies to improve the agent, both for the RL and the rule-based approach. The main improvement is a N-1 strategy, where we consider topology actions that keep the grid stable, even if one line is disconnected. More, we also propose a topology reversion to the original grid, which proved to be beneficial. The improvements are tested against reference approaches on the challenge test sets and are able to increase the performance of the rule-based agent by 27%. I
    
[^88]: TabRet: 预训练Transformer-based表格模型，支持未知列

    TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. (arXiv:2303.15747v1 [cs.LG])

    [http://arxiv.org/abs/2303.15747](http://arxiv.org/abs/2303.15747)

    提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。

    

    我们提出了一种名为TabRet的可预训练Transformer-based表格模型。TabRet旨在为包含未在预训练中见过的列的下游任务提供支持。与其他方法不同，TabRet在微调之前有一个额外的学习步骤，称为重新标记化，它基于遮蔽自动编码损失来校准特征嵌入。在实验中，我们使用大量的公共健康调查数据对TabRet进行预训练，并在医疗保健分类任务上进行微调，在四个数据集上实现了最佳AUC性能。此外，消融研究表明，在预训练期间进行重新标记化和随机洗牌增强对性能提升有贡献。

    We present \emph{TabRet}, a pre-trainable Transformer-based model for tabular data. TabRet is designed to work on a downstream task that contains columns not seen in pre-training. Unlike other methods, TabRet has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. In experiments, we pre-trained TabRet with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and TabRet achieved the best AUC performance on four datasets. In addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains.
    
[^89]: 大规模适应性实验：灵活批处理的贝叶斯算法

    Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])

    [http://arxiv.org/abs/2303.11582](http://arxiv.org/abs/2303.11582)

    本文提出了一个基于贝叶斯算法的自适应实验框架，可灵活处理任何批处理大小。通过正态近似指导可扩展自适应设计，采用残余时限优化选择采样分配，实现了最先进的性能。

    

    标准的贝叶斯算法假定持续重新分配测量工作，这在实现过程中存在延迟反馈和基础设施/组织难题等挑战。本文针对仅有少数重新分配阶段的实际情况，其中测量结果是以批处理形式测量的，提出了一种新的适应性实验框架，可灵活处理任何批处理大小。我们的主要观察是，在统计推断中普遍使用的正态近似也可以指导可扩展自适应设计。通过推导渐进顺序实验，我们制定了一种动态规划，可以利用平均回报的先验信息。动态规划的状态转移相对于采样分配是可微的，允许使用基于梯度的方法进行规划和策略优化。我们提出了一种简单的迭代规划方法，即残余时限优化，通过优化平衡探索和利用的规划目标来选择采样分配。在合成和真实世界基准测试问题上的实验结果表明，我们的框架实现了最先进的性能，同时具有模块化和易用性。

    Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
    
[^90]: MeshDiffusion：基于分数的生成式3D网格建模

    MeshDiffusion: Score-based Generative 3D Mesh Modeling. (arXiv:2303.08133v1 [cs.GR])

    [http://arxiv.org/abs/2303.08133](http://arxiv.org/abs/2303.08133)

    本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。

    

    本文研究了生成逼真的3D物体的任务，这对于自动场景生成和物理仿真等多种应用非常有用。相比于体素和点云等其他3D表示，网格在实践中更加优越，因为(1)它们可以轻松任意地操纵形状以供重新照明和仿真，(2)可以充分发挥现代图形流水线的能力，而这些流水线大多数针对网格进行了优化。以往可扩展的3D网格生成方法通常依赖于次优的后处理，并且它们往往会产生过于平滑或嘈杂的表面，缺乏精细的几何细节。为了克服这些缺点，我们利用网格的图形结构，使用简单但非常有效的生成式建模方法生成3D网格。具体来说，我们使用可变形四面体网格来表示网格，然后在这个直接参数化的网格上训练扩散模型。

    We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectivene
    
[^91]: 通过超球统一性差填补神经坍塌的泛化和解耦

    Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap. (arXiv:2303.06484v1 [cs.LG])

    [http://arxiv.org/abs/2303.06484](http://arxiv.org/abs/2303.06484)

    本文提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌，并将其分解为两个目标：最小化类内变异性和最大化类间可分性。使用超球统一性作为量化这两个目标的统一框架，并提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。

    This paper proposes a generalized neural collapse hypothesis that effectively subsumes the original neural collapse and decomposes it into two objectives: minimizing intra-class variability and maximizing inter-class separability. The authors use hyperspherical uniformity as a unified framework to quantify these objectives and propose a general objective, hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity.

    神经坍塌现象描述了深度神经网络的底层几何对称性，其中深度学习的特征和分类器都收敛于一个等角紧框架。已经证明，交叉熵损失和均方误差都可以导致神经坍塌。我们消除了神经坍塌对特征维度和类别数量的关键假设，然后提出了一个广义神经坍塌假设，有效地包含了原始神经坍塌。受神经坍塌描述神经网络训练目标的启发，我们将广义神经坍塌分解为两个目标：最小化类内变异性和最大化类间可分性。然后，我们使用超球统一性（它描述了单位超球上均匀性的程度）作为量化这两个目标的统一框架。最后，我们提出了一个通用目标——超球统一性差（HUG），它由类间和类内超球统一性之间的差异定义。

    The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical un
    
[^92]: 基于深度递归网络的公司名称消歧

    Disambiguation of Company names via Deep Recurrent Networks. (arXiv:2303.05391v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05391](http://arxiv.org/abs/2303.05391)

    本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。

    

    命名实体消歧是自然语言处理的一个任务，其目标是识别对应于同一命名实体的文本记录。本研究的任务是根据公司的书面名称消除歧义。我们提出了一种连续LSTM网络方法来提取公司名称字符串的嵌入，进而使用这种表示来识别真正表示同一公司（即相同实体）的公司名称对。考虑到手动标记字符串对是一项费力的任务，我们分析了主动学习方法如何优先选择样本进行标记从而使整个学习流程更加高效。经实证，我们的Siamese网络优于多种基于标准字符串匹配算法的基准方法。

    Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -- via supervised learning -- an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity).  Given that the manual labelling of string pairs is a rather onerous task, we analyse how an Active Learning approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline.  With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms
    
[^93]: 证据支持的转移学习在阿尔茨海默病中的应用

    Evidence-empowered Transfer Learning for Alzheimer's Disease. (arXiv:2303.01105v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2303.01105](http://arxiv.org/abs/2303.01105)

    该研究提出了一种在阿尔茨海默病诊断中使用证据支持的转移学习方法，通过利用AD相关的辅助任务来学习MRI扫描中形态学特征的证据和可转移知识，提高了检测性能，同时更具有数据效率和可信度。

    

    转移学习已经被广泛应用于减轻阿尔茨海默病（AD）领域中的数据匮乏问题。传统的转移学习依赖于重复使用在AD非相关任务（例如自然图像分类）上训练的模型。然而，由于非医学来源和目标医学领域之间的差异，它经常导致负转移。为了解决这个问题，我们提出了一种证据支持的AD诊断转移学习方法。与传统方法不同的是，我们利用AD相关的辅助任务，即形态变化预测，而无需额外的MRI数据。在这个辅助任务中，诊断模型学习来自MRI扫描中形态学特征的证据和可转移知识。实验结果表明，我们的框架不仅可以提高检测性能，而且无论模型容量如何，也更具有数据效率和可信度。

    Transfer learning has been widely utilized to mitigate the data scarcity problem in the field of Alzheimer's disease (AD). Conventional transfer learning relies on re-using models trained on AD-irrelevant tasks such as natural image classification. However, it often leads to negative transfer due to the discrepancy between the non-medical source and target medical domains. To address this, we present evidence-empowered transfer learning for AD diagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary task, namely morphological change prediction, without requiring additional MRI data. In this auxiliary task, the diagnosis model learns the evidential and transferable knowledge from morphological features in MRI scans. Experimental results demonstrate that our framework is not only effective in improving detection performance regardless of model capacity, but also more data-efficient and faithful.
    
[^94]: 有帮助、引导还是让人困惑: 人们如何看待人工智能解释的基本构建块。

    Helpful, Misleading or Confusing: How Humans Perceive Fundamental Building Blocks of Artificial Intelligence Explanations. (arXiv:2303.00934v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2303.00934](http://arxiv.org/abs/2303.00934)

    该论文旨在以人为中心的角度评估人工智能中的解释可理解性，以及评估可解释性的适当方法落后于技术的发展速度。

    

    可解释的人工智能技术正在以惊人的速度发展，但适当的评估方法落后。随着解释器变得越来越复杂，以及缺乏关于如何评估它们效用的共识，评判不同解释的好处和有效性变得具有挑战性。为了填补这一空白，我们退一步研究简单决策模型的可解释性，而不是复杂的预测算法。在这种环境下，我们旨在评估人们如何理解它们的不同表示形式，例如数学公式、图形表示和文本摘要（不同复杂度和范围）。这使我们能够捕捉到各种利益相关者（工程师、研究者、消费者、监管机构等）如何评判更复杂的人工智能解释所构建的基本概念的可理解性。本文介绍我们从以人为中心的角度建立适当的可解释性评估方法的方法。

    Explainable artificial intelligence techniques are developed at breakneck speed, but suitable evaluation approaches lag behind. With explainers becoming increasingly complex and a lack of consensus on how to assess their utility, it is challenging to judge the benefit and effectiveness of different explanations. To address this gap, we take a step back from sophisticated predictive algorithms and instead look into explainability of simple decision-making models. In this setting, we aim to assess how people perceive comprehensibility of their different representations such as mathematical formulation, graphical representation and textual summarisation (of varying complexity and scope). This allows us to capture how diverse stakeholders -engineers, researchers, consumers, regulators and the like -- judge intelligibility of fundamental concepts that more elaborate artificial intelligence explanations are built from. This position paper charts our approach to establishing appropriate eva
    
[^95]: pyribs: 一个Python基础库用于质量多样性优化

    pyribs: A Bare-Bones Python Library for Quality Diversity Optimization. (arXiv:2303.00191v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.00191](http://arxiv.org/abs/2303.00191)

    pyribs是一个Python库，可以用于质量多样性优化，支持广泛的研究人员和实践者，具有高度模块化的框架可用于组合算法，是一个灵活易用的框架。

    

    近年来，质量多样性(QD)优化在优化的分支中变得越来越受欢迎，该分支寻求找到给定问题的多样化高性能解决方案集合。为了进一步发展，我们认为QD社区面临两个挑战：开发一个代表该领域不断增长的算法数组的框架，并在支持一系列研究人员和实践者的软件中实现该框架。为了解决这些挑战，我们开发了一个基于高度模块化的概念QD框架的库pyribs。通过替换概念框架中的组件，因此在pyribs中，用户可以从QD文献中组合算法，同样重要的是，他们可以识别未探索的算法变化。此外，pyribs使这个框架简单，灵活和易于访问，具有用户友好的API，支持广泛的文档和教程。本篇论文重点概述了pyribs的创建过程，着重介绍了概念框架。

    Recent years have seen a rise in the popularity of quality diversity (QD) optimization, a branch of optimization that seeks to find a collection of diverse, high-performing solutions to a given problem. To grow further, we believe the QD community faces two challenges: developing a framework to represent the field's growing array of algorithms, and implementing that framework in software that supports a range of researchers and practitioners. To address these challenges, we have developed pyribs, a library built on a highly modular conceptual QD framework. By replacing components in the conceptual framework, and hence in pyribs, users can compose algorithms from across the QD literature; equally important, they can identify unexplored algorithm variations. Furthermore, pyribs makes this framework simple, flexible, and accessible, with a user-friendly API supported by extensive documentation and tutorials. This paper overviews the creation of pyribs, focusing on the conceptual framework
    
[^96]: AR3n: 一种基于强化学习的机器人康复辅助控制器

    AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation. (arXiv:2303.00085v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.00085](http://arxiv.org/abs/2303.00085)

    本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。

    

    本文提出了AR3n（发音为Aaron），一种采用强化学习的辅助控制器，可在机器人辅助的书写康复任务中提供适应性辅助。与以往的辅助控制器不同，我们的方法不依赖于患者特定的控制器参数或物理模型。我们建议使用虚拟患者模型来使AR3n推广到多个受试者。该系统实时调节机器人辅助力度，同时最小化机器人辅助的量，基于被试的跟踪误差。通过一组仿真实验和人体受试实验对控制器进行实验验证。最后，进行了与传统基于规则的控制器的比较研究，以分析两种控制器的辅助机制的差异。

    In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed (AAN) controller that utilizes reinforcement learning to supply adaptive assistance during a robot assisted handwriting rehabilitation task. Unlike previous AAN controllers, our method does not rely on patient specific controller parameters or physical models. We propose the use of a virtual patient model to generalize AR3n across multiple subjects. The system modulates robotic assistance in realtime based on a subject's tracking error, while minimizing the amount of robotic assistance. The controller is experimentally validated through a set of simulations and human subject experiments. Finally, a comparative study with a traditional rule-based controller is conducted to analyze differences in assistance mechanisms of the two controllers.
    
[^97]: CADIS：采用聚类聚合和知识蒸馏正则化处理联邦学习中的聚类偏斜非独立同分布数据

    CADIS: Handling Cluster-skewed Non-IID Data in Federated Learning with Clustered Aggregation and Knowledge DIStilled Regularization. (arXiv:2302.10413v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10413](http://arxiv.org/abs/2302.10413)

    本文提出了一种针对聚类偏斜非独立同分布数据的联邦学习聚合方案和基于知识蒸馏的局部训练正则化方法

    

    联邦学习使得边缘设备能够协作地训练全局模型，而不暴露它们的数据。然而，在处理非独立同分布数据（IID）时，即由通常不独立且同分布的客户端生成的数据时，联邦学习面临重大挑战。本文针对实际数据集中发现的一种新型非IID数据，称为聚类偏斜非IID进行研究。这种数据现象是指客户端可以被分成具有相似数据分布的群组。通过对分类模型的次级层行为进行深入分析，我们引入了一种度量方法来量化两个客户端数据分布的相似度，同时不违反其隐私权。然后，我们提出了一种聚合方案，确保不同群组之间的平等。此外，我们还提出了一种基于知识蒸馏的新型局部训练正则化方法，

    Federated learning enables edge devices to train a global model collaboratively without exposing their data. Despite achieving outstanding advantages in computing efficiency and privacy protection, federated learning faces a significant challenge when dealing with non-IID data, i.e., data generated by clients that are typically not independent and identically distributed. In this paper, we tackle a new type of Non-IID data, called cluster-skewed non-IID, discovered in actual data sets. The cluster-skewed non-IID is a phenomenon in which clients can be grouped into clusters with similar data distributions. By performing an in-depth analysis of the behavior of a classification model's penultimate layer, we introduce a metric that quantifies the similarity between two clients' data distributions without violating their privacy. We then propose an aggregation scheme that guarantees equality between clusters. In addition, we offer a novel local training regularization based on the knowledge
    
[^98]: 语义不确定性：自然语言生成不确定性估计中的语言不变量

    Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09664](http://arxiv.org/abs/2302.09664)

    本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。

    

    我们介绍了一种测量大型语言模型中不确定性的方法。对于像问答任务这样的任务，了解何时可以信任基础模型的自然语言输出至关重要。我们发现，由于“语义等价性”，测量自然语言的不确定性是有挑战性的——不同的句子可以表示相同的意思。为了克服这些挑战，我们引入了语义熵——一种包含共享含义所创建的语言不变量的熵。我们的方法是无监督的，仅使用单个模型，并且不需要修改现成的语言模型。在全面的消融研究中，我们展示了语义熵对于问题回答数据集上的模型准确性比可比基线更具有预测性。

    We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of "semantic equivalence" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.
    
[^99]: 机器学习安全防御中的平等度量

    Measuring Equality in Machine Learning Security Defenses. (arXiv:2302.08973v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08973](http://arxiv.org/abs/2302.08973)

    本文研究了机器学习安全防御方法的平等性能问题，提出了一种简单的平等度量和分析框架，鼓励进一步探索公平性在该领域的应用。

    

    在过去的十年中，机器学习安全社区已经发展了许多对抗攻击的防御方法。但这个社区中鲜有研究一个问题：这些防御方法为谁提供保护呢？本文考虑了一些常见的防御方法，并研究了当这些防御方法被不同的子群体使用时，它们是否会产生意想不到的平等性能问题。我们提出了一种简单的平等度量和分析框架，通过机器学习安全方法的公平性实证结果来回答这个问题。许多方法可能会直接造成伤害，我们称之为有偏漏洞和有偏排斥。我们的框架和度量方法可以应用于强化训练模型、基于预处理的方法和拒绝方法，以捕捉在安全预算上的行为。我们确定了一个实际的数据集，具有合理的计算成本，适合于测量防御的平等性。通过一个案例研究，我们展示了现代防御方法的准确性和平等性性能的衡量价值。我们希望我们提出的指标和方法能够鼓励和促进机器学习安全和防御领域的公平性探索。

    The machine learning security community has developed myriad defenses for evasion attacks over the past decade. An understudied question in that community is: for whom do these defenses defend? In this work, we consider some common approaches to defending learned systems and whether those approaches may offer unexpected performance inequities when used by different sub-populations. We outline simple parity metrics and a framework for analysis that can begin to answer this question through empirical results of the fairness implications of machine learning security methods. Many methods have been proposed that can cause direct harm, which we describe as biased vulnerability and biased rejection. Our framework and metric can be applied to robustly trained models, preprocessing-based methods, and rejection methods to capture behavior over security budgets. We identify a realistic dataset with a reasonable computational cost suitable for measuring the equality of defenses. Through a case st
    
[^100]: XploreNAS：针对非理想交叉栏架构探索对抗性强和硬件高效的神经网络结构

    XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars. (arXiv:2302.07769v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07769](http://arxiv.org/abs/2302.07769)

    本文提出了一种名为XploreNAS的方法，该方法通过两阶段算法-硬件协同优化，针对非理想交叉栏架构探索对抗性强和硬件高效的神经网络结构，通过采样出具有对抗性强度的子网络，实现了在非理想性交叉栏架构下的硬件和对抗性的均衡发展。

    

    运用计算内存平台，如存储器性交叉栏架，可以加速深度神经网络（DNN）的计算量和效率，但由于计算中精度的不理想性，其性能受到一定限制。此外，DNN容易受到对抗攻击，这会导致在大规模部署DNN时存在严重的安全威胁。因此，为非理想交叉栏架构寻找对抗性强的DNN结构对于在边缘上安全地部署DNN至关重要。本文提出了一种名为XploreNAS的两阶段算法-硬件协同优化方法，该方法寻找适用于非理想交叉栏架构的硬件高效和对抗性强的神经网络结构。我们采用一次性神经网络结构搜索（NAS）方法训练一个具有交叉栏架构感知的大型超网络，并采样出具有对抗性强度的子网络，同时维持具有竞争性的硬件约束。实验结果表明，该方法在为非理想交叉栏架构的DNN实现硬件和对抗性的均衡发展方面具有良好的效果。

    Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hard
    
[^101]: 知识增强的语义通信接收器

    Knowledge Enhanced Semantic Communication Receiver. (arXiv:2302.07727v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07727](http://arxiv.org/abs/2302.07727)

    提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，并通过知识提取器和基于GCN的语义解码器实现了更好的性能，不影响发射端的神经网络结构。

    

    近年来，随着深度学习和自然语言处理技术的快速发展，语义通信已成为通信领域的热门话题。尽管现有的基于深度学习的语义通信方法已经显示出许多优势，但它们仍然没有充分利用先前的知识。此外，大多数现有的语义通信方法侧重于发射端的语义编码，而我们认为，接收方的语义解码能力也应该受到关注。在本文中，我们提出了一个知识增强的语义通信框架，其中接收器可以更积极地利用知识库中的事实进行语义推理和解码，而不影响发射端的神经网络结构，仅影响其参数。具体来说，我们设计了基于transformer的知识提取器，以查找接收到的嘈杂数据中的相关事实三元组，并提出了基于图卷积网络（GCN）的语义解码器以更好地理解单词之间的语义关系。我们在两个常用数据集上评估了我们提出的框架，并实现了最先进的性能。

    In recent years, with the rapid development of deep learning and natural language processing technologies, semantic communication has become a topic of great interest in the field of communication. Although existing deep learning-based semantic communication approaches have shown many advantages, they still do not make sufficient use of prior knowledge. Moreover, most existing semantic communication methods focus on the semantic encoding at the transmitter side, while we believe that the semantic decoding capability of the receiver should also be concerned. In this paper, we propose a knowledge enhanced semantic communication framework in which the receiver can more actively utilize the facts in the knowledge base for semantic reasoning and decoding, on the basis of only affecting the parameters rather than the structure of the neural networks at the transmitter side. Specifically, we design a transformer-based knowledge extractor to find relevant factual triples for the received noisy
    
[^102]: 基于注意力机制的领域自适应方法在水文特征稀缺地区的流量预测中的应用

    Attention-based Domain Adaptation Forecasting of Streamflow in Data-Sparse Regions. (arXiv:2302.05386v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05386](http://arxiv.org/abs/2302.05386)

    本文提出了一种基于注意力机制的领域自适应流量预测模型，用于数据稀缺的区域。通过对抗方法同时训练流量预测和区分两个领域，可在24小时流量预测方面实现性能表现的提高。

    

    流量预测对于指导水资源管理、缓解洪涝灾害以及开发智慧基础设施和治理具有重要意义。然而，许多全球地区缺乏足够的流量观测数据以指导基于证据的管理策略。本文提出了一种基于注意力机制的领域自适应流量预测模型，用于数据稀缺的区域。该方法利用一个数据丰富的源领域的水文特征，采用深度学习框架结合领域自适应技术，通过对抗方法同时训练流量预测和区分两个领域。实验结果表明，该方法在24小时流量预测方面超越了传统的交叉领域模型的性能表现。

    Streamflow forecasts are critical to guide water resource management, mitigate drought and flood effects, and develop climate-smart infrastructure and governance. Many global regions, however, have limited streamflow observations to guide evidence-based management strategies. In this paper, we propose an attention-based domain adaptation streamflow forecaster for data-sparse regions. Our approach leverages the hydrological characteristics of a data-rich source domain to induce effective 24hr lead-time streamflow prediction in a data-constrained target domain. Specifically, we employ a deep-learning framework leveraging domain adaptation techniques to simultaneously train streamflow predictions and discern between both domains using an adversarial method. Experiments against baseline cross-domain forecasting models show improved performance for 24hr lead-time streamflow forecasting.
    
[^103]: 多智能体强化学习中的集成价值函数用于高效探索

    Ensemble Value Functions for Efficient Exploration in Multi-Agent Reinforcement Learning. (arXiv:2302.03439v5 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2302.03439](http://arxiv.org/abs/2302.03439)

    本论文提出了集成价值函数框架EMAX，用于多智能体强化学习中的探索，使用UCB策略引导探索，并通过训练价值函数集合减少方差和不稳定性，展示了比其他策略更高的学习速度、最终性能和对非静止性的稳健性。

    

    合作多智能体强化学习需要智能体进行探索以学习合作的方式。现有的基于价值的多智能体强化学习算法通常依赖于随机探索，如ε-贪心算法，这在发现多智能体合作方面效率低下。此外，由于其他智能体的同时训练，MARL中的环境对于任一单个智能体似乎是非静止的，导致高度不稳定的优化信号。在本文中，我们提出了面向多智能体探索的集成价值函数（EMAX），这是一个通用的框架，可扩展任何基于价值的多智能体强化学习算法。 EMAX为每个智能体训练价值函数集合，以解决探索和非静止性的关键挑战：（1）利用集合中价值估计的不确定性来引导智能体探索需要合作的环境部分的UCB策略。 （2）集合中平均值估计作为目标值。这些目标提供了低方差和稳定的更新，从而增强了训练效率。我们在两个合作任务上展示了EMAX的有效性，并表明在学习速度，最终性能和对非静止性的稳健性方面显着优于现有的探索策略。

    Cooperative multi-agent reinforcement learning (MARL) requires agents to explore to learn to cooperate. Existing value-based MARL algorithms commonly rely on random exploration, such as $\epsilon$-greedy, which is inefficient in discovering multi-agent cooperation. Additionally, the environment in MARL appears non-stationary to any individual agent due to the simultaneous training of other agents, leading to highly variant and thus unstable optimisation signals. In this work, we propose ensemble value functions for multi-agent exploration (EMAX), a general framework to extend any value-based MARL algorithm. EMAX trains ensembles of value functions for each agent to address the key challenges of exploration and non-stationarity: (1) The uncertainty of value estimates across the ensemble is used in a UCB policy to guide the exploration of agents to parts of the environment which require cooperation. (2) Average value estimates across the ensemble serve as target values. These targets exh
    
[^104]: 探究和利用决策边界动态的对抗鲁棒性

    Exploring and Exploiting Decision Boundary Dynamics for Adversarial Robustness. (arXiv:2302.03015v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03015](http://arxiv.org/abs/2302.03015)

    本论文解决了深度学习模型在进行鲁棒训练时的边界动态问题，提出了动态感知鲁棒训练方法，通过优化边界增加较小边界距离为优先的移动来提升模型的鲁棒性。

    

    深层分类器的鲁棒性可以由其边界与自然数据点之间的距离来衡量。然而，目前尚不清楚现有的鲁棒训练方法是否能够在训练过程中有效地增加每个易受攻击的点的边界距离。为了解决这个问题，我们提出了一个连续时间框架来量化决策边界相对于每个个体点的移动速度。通过可视化决策边界在最有效的鲁棒训练算法之一--对抗训练下的移动速度，揭示了一个惊人的移动行为：决策边界从某些易受攻击点移开，但同时也向其他点靠近，从而减小了它们的边界距离。为了缓解决策边界的这种冲突动态，我们提出了动态感知鲁棒训练（DyART），鼓励决策边界以增加较小边界距离为优先的移动。与以往的工作不同，DyART是一个关于决策边界动态的新思路。

    The robustness of a deep classifier can be characterized by its margins: the decision boundary's distances to natural data points. However, it is unclear whether existing robust training methods effectively increase the margin for each vulnerable point during training. To understand this, we propose a continuous-time framework for quantifying the relative speed of the decision boundary with respect to each individual point. Through visualizing the moving speed of the decision boundary under Adversarial Training, one of the most effective robust training algorithms, a surprising moving-behavior is revealed: the decision boundary moves away from some vulnerable points but simultaneously moves closer to others, decreasing their margins. To alleviate these conflicting dynamics of the decision boundary, we propose Dynamics-aware Robust Training (DyART), which encourages the decision boundary to engage in movement that prioritizes increasing smaller margins. In contrast to prior works, DyART
    
[^105]: 一种用于连续超参数优化的Lipschitz乐观策略算法

    A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization. (arXiv:2302.01539v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01539](http://arxiv.org/abs/2302.01539)

    BLiE是一种用于超参数优化的算法，只假设目标函数具有Lipschitz连续性。理论和实验证明BLiE优于现有算法，并且可以应用于搜索扩散模型的噪声调度。

    

    在机器学习中，超参数优化（HPO）是最关键的问题之一，因为超参数的选择对最终模型的性能有重要影响。虽然有许多HPO算法，但它们要么没有理论保证，要么需要强的假设。为此，我们介绍了BLiE——一种基于Lipschitz乐观策略的HPO算法，它只假设目标函数具有Lipschitz连续性。BLiE利用目标函数的景观以自适应地搜索超参数空间。理论上，我们证明了$(i)$ BLiE发现具有$O(\frac{1}{\epsilon})^{d_z+\beta}$个总预算的$\epsilon$最优超参数，其中$d_z$和$\beta$是问题内在的；$(ii)$ BLiE具有高度可并行性。实验上，我们证明了BLiE在基准任务上优于现有的HPO算法。我们还应用BLiE搜索扩散模型的噪声调度。与默认调度相比较，BLiE表现出更好的性能。

    One of the most critical problems in machine learning is HyperParameter Optimization (HPO), since choice of hyperparameters has a significant impact on final model performance. Although there are many HPO algorithms, they either have no theoretical guarantees or require strong assumptions. To this end, we introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes Lipschitz continuity of the objective function. BLiE exploits the landscape of the objective function to adaptively search over the hyperparameter space. Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal hyperparameter with $O \left( \frac{1}{\epsilon} \right)^{d_z + \beta}$ total budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly parallelizable. Empirically, we demonstrate that BLiE outperforms the state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to search for noise schedule of diffusion models. Comparison with the default schedule shows tha
    
[^106]: 基于第一原理的简化模型学习用于量子纳米结构模拟

    Physics-informed Reduced-Order Learning from the First Principles for Simulation of Quantum Nanostructures. (arXiv:2302.00100v2 [cs.CE] UPDATED)

    [http://arxiv.org/abs/2302.00100](http://arxiv.org/abs/2302.00100)

    本研究提出了基于第一原理的简化模型学习算法，用于模拟量子纳米结构，实现了高精度和高效率的模拟结果。

    

    为了设计和分析在生物、医学、材料、电子/光子设备等领域有广泛应用的量子纳米结构，需要进行多维直接数值模拟(Schr\"odinger方程)。在大型纳米结构中，由于自由度(DoF)非常高，进行DNS需要大量的计算工作，这可能是不可行的。本研究提出了一种基于第一原理的简化模型学习算法，用于模拟Schr\"odinger方程以实现高精度和高效率。所提出的模拟方法应用于研究两种量子点结构；一种在外部电场下运行，另一种受间断性边界条件下内部势能变化的影响。前者类似于纳米电子设备的典型操作，而后者则涉及到密度泛函理论的模拟和设计的纳米结构和材料应用。使用基于第一原理的简化模型学习算法，实现了对这两种量子点结构的准确且高效的模拟，证明了所提出方法的有效性。

    Multi-dimensional direct numerical simulation (DNS) of the Schr\"odinger equation is needed for design and analysis of quantum nanostructures that offer numerous applications in biology, medicine, materials, electronic/photonic devices, etc. In large-scale nanostructures, extensive computational effort needed in DNS may become prohibitive due to the high degrees of freedom (DoF). This study employs a reduced-order learning algorithm, enabled by the first principles, for simulation of the Schr\"odinger equation to achieve high accuracy and efficiency. The proposed simulation methodology is applied to investigate two quantum-dot structures; one operates under external electric field, and the other is influenced by internal potential variation with periodic boundary conditions. The former is similar to typical operations of nanoelectronic devices, and the latter is of interest to simulation and design of nanostructures and materials, such as applications of density functional theory. Usin
    
[^107]: 学习用于图像识别的广义混合距离表示

    Learning Generalized Hybrid Proximity Representation for Image Recognition. (arXiv:2301.13459v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13459](http://arxiv.org/abs/2301.13459)

    该文章提出了一种新的图像识别的监督度量学习方法，能够以混合方法学习更好的距离表示。通过控制几何近邻和概率近邻之间的权衡，从图像数据中学习通用的混合相似特征。

    

    近年来，深度度量学习技术受到关注，因为学习到的距离表示可用于捕捉样本之间的相似性关系，并进一步提高各种监督或无监督学习任务的性能。我们提出了一种新的监督度量学习方法，可学习几何和概率空间中的距离度量，用于图像识别。与先前的度量学习方法通常侧重于学习欧几里德空间中的距离度量不同，我们提出的方法能够以混合方法学习更好的距离表示。为了实现这一点，我们提出了广义混合度量损失（GHM-Loss）来通过控制几何近邻和概率近邻之间的权衡从图像数据中学习通用的混合相似特征。为了评估我们方法的有效性，我们首先提供了所提出的损失函数的理论推导和证明，然后在几个基准数据集上进行实验，结果表明我们提出的方法优于这些数据集上的现有最先进方法。

    Recently, deep metric learning techniques received attention, as the learned distance representations are useful to capture the similarity relationship among samples and further improve the performance of various of supervised or unsupervised learning tasks. We propose a novel supervised metric learning method that can learn the distance metrics in both geometric and probabilistic space for image recognition. In contrast to the previous metric learning methods which usually focus on learning the distance metrics in Euclidean space, our proposed method is able to learn better distance representation in a hybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss (GHM-Loss) to learn the general hybrid proximity features from the image data by controlling the trade-off between geometric proximity and probabilistic proximity. To evaluate the effectiveness of our method, we first provide theoretical derivations and proofs of the proposed loss function, then we perform ex
    
[^108]: 时间序列中因果结构的凸优化方法学习

    Causal Structural Learning from Time Series: A Convex Optimization Approach. (arXiv:2301.11336v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11336](http://arxiv.org/abs/2301.11336)

    该论文提出了一种数据自适应线性方法，通过凸优化技术解决了时间序列数据中的因果结构学习问题，方法具有非渐近恢复保证，并且在结构恢复方面表现出了优越性。

    

    结构学习旨在从观察数据中学习有向无环图(DAG)，是因果推理和科学发现的基础。最近的进展将结构学习转化为连续优化问题；然而，DAG学习仍然是一个高度非凸问题，因此很少有工作利用成熟的凸优化技术进行因果结构学习。我们通过提出一种适用于时间序列数据的数据自适应线性方法来填补这一空白，并使用最近提出的单调算子变分不等式(VI)公式方便地将其转化为凸优化问题。此外，我们还建立了VI方法的非渐近恢复保证，并通过大量的数值实验展示了我们提出的方法在结构恢复方面优于现有方法。

    Structural learning, which aims to learn directed acyclic graphs (DAGs) from observational data, is foundational to causal reasoning and scientific discovery. Recent advancements formulate structural learning into a continuous optimization problem; however, DAG learning remains a highly non-convex problem, and there has not been much work on leveraging well-developed convex optimization techniques for causal structural learning. We fill this gap by proposing a data-adaptive linear approach for causal structural learning from time series data, which can be conveniently cast into a convex optimization problem using a recently developed monotone operator variational inequality (VI) formulation. Furthermore, we establish non-asymptotic recovery guarantee of the VI-based approach and show the superior performance of our proposed method on structure recovery over existing methods via extensive numerical experiments.
    
[^109]: 学习Boltzmann密度的变形轨迹

    Learning Deformation Trajectories of Boltzmann Densities. (arXiv:2301.07388v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.07388](http://arxiv.org/abs/2301.07388)

    本文介绍了一种学习Boltzmann密度变形轨迹的方法，其中通过插值能量函数等实现Boltzmann密度的变形，然后找到一个时间依赖向量场，将样本从一个分布转移到另一个分布，其表现在高斯混合和量子力学粒子的Boltzmann密度上比KL-反散度更具优势。

    

    我们提出了一种连续标准化流的训练方法，可以在没有样本但存在能量函数的情况下使用。我们的方法依赖于能量函数$f_1$和广义高斯函数$f_0$之间的预定或学习插值$f_t$。能量函数的插值引起Boltzmann密度$p_t\propto e^{-f_t}$的插值，我们旨在找到一个沿着族$p_t$的时间依赖向量场$V_t$，将样本从一个分布转移到另一个分布。将样本沿着族$p_t$从一个分布转移到另一个分布的条件可以转化为$V_t$和$f_t$之间的PDE，我们优化$V_t$和$f_t$以满足此PDE。我们在高斯混合和双井势的量子力学粒子的Boltzmann密度上实验比较了所提出的训练目标与KL-反散度的差异。

    We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ can be translated to a PDE between $V_t$ and $f_t$ and we optimize $V_t$ and $f_t$ to satisfy this PDE. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.
    
[^110]: 一种新颖的稀疏正则化方法

    A Novel Sparse Regularizer. (arXiv:2301.07285v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07285](http://arxiv.org/abs/2301.07285)

    提出一种新颖的正则化方法，关注权重矩阵内权重的空间排列，可以显著减少模型参数的非零数量。

    

    本文介绍了一种不基于 $L_{p}$-norm 的新颖正则化方法。与传统方法只考虑模型中各权重值的度量不同，这种正则化方法关注权重矩阵内权重的空间排列。该方法的加入项可以用于损失函数中，可微分，简单快速计算，与尺度无关，仅需要微小的额外内存，容易并行化。经实验证明，在相同精度水平下，该方法可以使模型参数的非零数量提高一个数量级。

    $L_{p}$-norm regularization schemes such as $L_{0}$, $L_{1}$, and $L_{2}$-norm regularization and $L_{p}$-norm-based regularization techniques such as weight decay and group LASSO compute a quantity which de pends on model weights considered in isolation from one another. This paper describes a novel regularizer which is not based on an $L_{p}$-norm. In contrast with $L_{p}$-norm-based regularization, this regularizer is concerned with the spatial arrangement of weights within a weight matrix. This regularizer is an additive term for the loss function and is differentiable, simple and fast to compute, scale-invariant, requires a trivial amount of additional memory, and can easily be parallelized. Empirically this method yields approximately a one order-of-magnitude improvement in the number of nonzero model parameters at a given level of accuracy.
    
[^111]: GLIGEN：开放式基于文本的图像生成方法

    GLIGEN: Open-Set Grounded Text-to-Image Generation. (arXiv:2301.07093v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07093](http://arxiv.org/abs/2301.07093)

    GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。

    

    大规模的文本到图像扩散模型取得了令人惊叹的进展。然而，现状是仅使用文本输入，这可能会限制可控性。在这项工作中，我们提出了GLIGEN，基于语言关联的图像生成方法，这是一种新颖的方法，它建立在现有预训练的文本到图像扩散模型的基础上，并使其能够依赖于语言关联性输入。为了保留预训练模型的广泛概念知识，我们冻结所有权重，并通过门控机制将连结信息注入到新的可训练层中。我们的模型实现了开放式基于关键字和边界框的文本到图像生成，而且连结能力在新的空间配置和概念上具有良好的普适性。GLIGEN在COCO和LVIS的零样本表现优于现有的监督布局到图像的基线。

    Large-scale text-to-image diffusion models have made amazing advances. However, the status quo is to use text input alone, which can impede controllability. In this work, we propose GLIGEN, Grounded-Language-to-Image Generation, a novel approach that builds upon and extends the functionality of existing pre-trained text-to-image diffusion models by enabling them to also be conditioned on grounding inputs. To preserve the vast concept knowledge of the pre-trained model, we freeze all of its weights and inject the grounding information into new trainable layers via a gated mechanism. Our model achieves open-world grounded text2img generation with caption and bounding box condition inputs, and the grounding ability generalizes well to novel spatial configurations and concepts. GLIGEN's zero-shot performance on COCO and LVIS outperforms that of existing supervised layout-to-image baselines by a large margin.
    
[^112]: 图像生成器的领域扩展

    Domain Expansion of Image Generators. (arXiv:2301.05225v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.05225](http://arxiv.org/abs/2301.05225)

    提出一种新任务——领域扩展，来注入新的概念到一个已经训练好的生成模型，同时保持其现有的结构和知识。发现预训练的生成器具有添加多个新领域的能力，而不需要扩展。

    

    一个已经训练好的生成模型是否能够注入新的概念，同时保持其现有的结构和知识？我们提出了一个新的任务——领域扩展，来解决这个问题。给定一个预训练的生成器和新领域，我们扩展生成器以共同模拟所有领域，新旧领域和谐地结合。我们发现生成器包含有意义的，并经过了预训练的潜在空间。能否在最小程度上扰动这个辛苦获得的表示，同时最大程度地表示新领域？有趣的是，我们发现潜在空间提供了未使用的“休眠”方向，不影响输出。这提供了一个机会：通过“重定向”这些方向，我们可以表示新的领域而不会扰乱原始表示。事实上，我们发现预训练的生成器有能力添加几个——甚至数百个——新领域！使用我们的扩展方法，一个“扩展”模型可以取代许多特定领域的模型，而不需要扩展。

    Can one inject new concepts into an already trained generative model, while respecting its existing structure and knowledge? We propose a new task - domain expansion - to address this. Given a pretrained generator and novel (but related) domains, we expand the generator to jointly model all domains, old and new, harmoniously. First, we note the generator contains a meaningful, pretrained latent space. Is it possible to minimally perturb this hard-earned representation, while maximally representing the new domains? Interestingly, we find that the latent space offers unused, "dormant" directions, which do not affect the output. This provides an opportunity: By "repurposing" these directions, we can represent new domains without perturbing the original representation. In fact, we find that pretrained generators have the capacity to add several - even hundreds - of new domains! Using our expansion method, one "expanded" model can supersede numerous domain-specific models, without expanding
    
[^113]: 面向有噪声标签学习的可识别性：多项式混合方法研究

    Towards the Identifiability in Noisy Label Learning: A Multinomial Mixture Approach. (arXiv:2301.01405v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01405](http://arxiv.org/abs/2301.01405)

    本文使用多项式混合模型研究了在有噪声标签学习过程中如何识别出干净标签样本，发现每个实例有至少 $2C-1$ 个有噪声标签时，该问题才是可识别的。为了满足这个要求，提出了一种方法，通过估计噪声标签分布自动生成额外的噪声标签以提高可识别性，无需额外的假设。

    

    从有噪声标签中进行学习在深度学习中扮演着至关重要的角色。最有前途的有噪声标签学习方法依赖于从带有噪声注释的数据集中识别出干净标签样本。这种识别具有挑战性，因为传统的有噪声标签学习问题假定每个实例只有一个有噪声标签，是不可识别的，也就是说，没有附加的启发式方法理论上无法估计出干净标签。在本文中，我们旨在使用多项式混合模型正式调查这个可识别性问题，以确定使问题可识别的约束条件。具体来说，我们发现，如果每个实例有至少 $2C-1$ 个有噪声标签，其中 C 是类的数量，则该有噪声标签学习问题就变得可识别。为了满足这个要求，而不依赖于每个实例额外的 $2C-2$ 手动注释，我们提出了一种方法，通过估计基于最近邻的噪声标签分布来自动生成额外的噪声标签。这些额外的噪声标签提高了可识别性，使得可以无需任何其他假设来估计干净标签。我们在各种基准和应用程序上验证了我们的方法的有效性。

    Learning from noisy labels (LNL) plays a crucial role in deep learning. The most promising LNL methods rely on identifying clean-label samples from a dataset with noisy annotations. Such an identification is challenging because the conventional LNL problem, which assumes a single noisy label per instance, is non-identifiable, i.e., clean labels cannot be estimated theoretically without additional heuristics. In this paper, we aim to formally investigate this identifiability issue using multinomial mixture models to determine the constraints that make the problem identifiable. Specifically, we discover that the LNL problem becomes identifiable if there are at least $2C - 1$ noisy labels per instance, where $C$ is the number of classes. To meet this requirement without relying on additional $2C - 2$ manual annotations per instance, we propose a method that automatically generates additional noisy labels by estimating the noisy label distribution based on nearest neighbours. These additio
    
[^114]: 基于CLIP的通用模型用于器官分割和肿瘤检测

    CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection. (arXiv:2301.00785v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2301.00785](http://arxiv.org/abs/2301.00785)

    本文提出了基于CLIP的通用模型，通过文本嵌入学习解剖学关系，能够分割25种器官和6种肿瘤，具有强大的泛化能力。

    

    越来越多的公开数据集在自动化器官分割和肿瘤检测方面产生了显著的影响。然而，由于每个数据集的规模较小且部分标注问题，以及对不同类型肿瘤的有限探究，导致得到的模型通常限于分割特定的器官/肿瘤，并忽略解剖结构的语义，也无法推广到新领域。为了解决这些问题，我们提出了基于CLIP驱动的通用模型，将从对比语言-图像预训练 （CLIP）中学习到的文本嵌入结合到分割模型中。这种基于CLIP的标签编码捕捉了解剖学关系，使模型学习到结构化特征嵌入，并分割25个器官和6种类型的肿瘤。该模型由14个数据集组成，使用3410个CT扫描进行训练，然后在来自3个额外数据集的6162个外部CT扫描上进行评估。我们在医学影像分析的国际准确性基准测试（MIoU）中排名第一。

    An increasing number of public datasets have shown a marked impact on automated organ segmentation and tumor detection. However, due to the small size and partially labeled problem of each dataset, as well as a limited investigation of diverse types of tumors, the resulting models are often limited to segmenting specific organs/tumors and ignore the semantics of anatomical structures, nor can they be extended to novel domains. To address these issues, we propose the CLIP-Driven Universal Model, which incorporates text embedding learned from Contrastive Language-Image Pre-training (CLIP) to segmentation models. This CLIP-based label encoding captures anatomical relationships, enabling the model to learn a structured feature embedding and segment 25 organs and 6 types of tumors. The proposed model is developed from an assembly of 14 datasets, using a total of 3,410 CT scans for training and then evaluated on 6,162 external CT scans from 3 additional datasets. We rank first on the Medical
    
[^115]: 通过视频预训练潜空间搜索的行为克隆

    Behavioral Cloning via Search in Video PreTraining Latent Space. (arXiv:2212.13326v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13326](http://arxiv.org/abs/2212.13326)

    本文通过基于模仿学习方法中的搜索问题，将控制问题表述为专家演示数据集中的模仿。该方法通过在视频预训练模型的潜表示中进行近邻搜索，可以有效地在Minecraft环境中复制出有意义的演示轨迹并呈现类人行为。

    

    本文旨在建立能够解决像Minecraft这样环境中任务的自主智能体。为此，我们使用了基于模仿学习的方法。我们将控制问题表述为基于专家演示数据集的搜索问题，其中代理从类似于图像-动作对的演示轨迹中复制动作。我们在视频预训练模型的潜表示中对BASALT MineRL数据集进行了近邻搜索。只要代理和数据集中选定的专家轨迹的状态表示之间的距离不会分散，代理就会复制专家轨迹中的动作。然后重新进行近邻搜索。我们的方法可以有效地恢复有意义的演示轨迹，并在Minecraft环境中展示出类似于人类的行为。

    Our aim is to build autonomous agents that can solve tasks in environments like Minecraft. To do so, we used an imitation learning-based approach. We formulate our control problem as a search problem over a dataset of experts' demonstrations, where the agent copies actions from a similar demonstration trajectory of image-action pairs. We perform a proximity search over the BASALT MineRL-dataset in the latent representation of a Video PreTraining model. The agent copies the actions from the expert trajectory as long as the distance between the state representations of the agent and the selected expert trajectory from the dataset do not diverge. Then the proximity search is repeated. Our approach can effectively recover meaningful demonstration trajectories and show human-like behavior of an agent in the Minecraft environment.
    
[^116]: 一篇针对基于语音的可信机器学习的综述：隐私、安全和公平性

    A Review of Speech-centric Trustworthy Machine Learning: Privacy, Safety, and Fairness. (arXiv:2212.09006v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2212.09006](http://arxiv.org/abs/2212.09006)

    本论文综述了基于语音的可信机器学习的主要挑战，包括隐私、安全和公平性，并提出了未来值得研究的方向。

    

    基于语音的机器学习系统已经在交通、医疗保健、教育和国防等领域取得了重大进展，深刻改变了人们的生活、工作和互动方式。然而，最近的研究表明，许多语音中心的机器学习系统可能需要更加值得信赖才能更广泛地部署。具体来说，隐私泄露、歧视性能和对敌对攻击的脆弱性都已在机器学习研究领域中被发现。为了解决以上挑战和风险，已经进行了大量的努力，以确保这些机器学习系统是可信赖的，特别是私密、安全和公平的。本文首次对与隐私、安全和公平相关的基于语音的可信机器学习主题进行了全面调查。除了作为研究社区的总结报告外，我们还指出了一些有前途的未来研究方向，以激发研究思路。

    Speech-centric machine learning systems have revolutionized many leading domains ranging from transportation and healthcare to education and defense, profoundly changing how people live, work, and interact with each other. However, recent studies have demonstrated that many speech-centric ML systems may need to be considered more trustworthy for broader deployment. Specifically, concerns over privacy breaches, discriminating performance, and vulnerability to adversarial attacks have all been discovered in ML research fields. In order to address the above challenges and risks, a significant number of efforts have been made to ensure these ML systems are trustworthy, especially private, safe, and fair. In this paper, we conduct the first comprehensive survey on speech-centric trustworthy ML topics related to privacy, safety, and fairness. In addition to serving as a summary report for the research community, we point out several promising future research directions to inspire the researc
    
[^117]: 切片最优偏转运输

    Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08049](http://arxiv.org/abs/2212.08049)

    本文提出了一种适用于一维非负测度之间最优偏转运输问题的高效算法，并通过切片的方式定义了切片最优偏转运输距离。

    

    最优传输（OT）已经在机器学习、数据科学和计算机视觉中变得极其流行。OT问题的核心假设是源和目标测度的总质量相等，这限制了它的应用。最优偏转运输（OPT）是最近提出的解决这个限制的方法。与OT问题类似，OPT的计算依赖于解决线性规划问题（通常在高维度中），这可能会变得计算上困难。在本文中，我们提出了一种计算一维非负测度之间OPT问题的有效算法。接下来，遵循切片OT距离的思想，我们利用切片定义了切片OPT距离。最后，我们展示了切片OPT-based方法在各种数值实验中的计算和精度优势。特别是，我们展示了我们提出的Sliced-OPT在噪声点云配准中的应用。

    Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
    
[^118]: 模型增强下的数据集蒸馏加速

    Accelerating Dataset Distillation via Model Augmentation. (arXiv:2212.06152v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06152](http://arxiv.org/abs/2212.06152)

    本文提出了两种模型增强技术，即使用早期模型和参数扰动，以显着降低训练成本的方式优化数据集蒸馏，实现了高达20倍的加速。

    

    数据集蒸馏（DD）是一个新兴的领域，旨在从大型原始数据集中产生更小但高效的合成训练数据集。现有的基于梯度匹配的DD方法达到了领先的性能；但是，它们非常计算密集，因为他们需要在成千上万个随机初始化模型中不断优化数据集。在本文中，我们假设使用多种模型对合成数据进行训练可以获得更好的泛化性能。因此，我们提出了两种模型增强技术，即使用早期模型和参数扰动来学习具有显着降低训练成本的信息合成集。广泛的实验表明，我们的方法实现了高达20倍的加速，并且与最先进的方法具有相当的性能。

    Dataset Distillation (DD), a newly emerging field, aims at generating much smaller but efficient synthetic training datasets from large ones. Existing DD methods based on gradient matching achieve leading performance; however, they are extremely computationally intensive as they require continuously optimizing a dataset among thousands of randomly initialized models. In this paper, we assume that training the synthetic data with diverse models leads to better generalization performance. Thus we propose two model augmentation techniques, i.e. using early-stage models and parameter perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20x speedup and comparable performance on par with state-of-the-art methods.
    
[^119]: 表现力架构增强基于动力学的神经人群模型的可解释性

    Expressive architectures enhance interpretability of dynamics-based neural population models. (arXiv:2212.03771v3 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2212.03771](http://arxiv.org/abs/2212.03771)

    研究通过顺序自动编码器从神经数据集中恢复潜在的混沌吸引子，发现采用神经常微分方程为基础的 SAES 在准确率和维度方面优于采用循环神经网络的 SAES。

    

    能够从记录的神经活动中恢复潜在动力学的人工神经网络可能为识别和解释生物计算中潜在的动力学模式提供了一种强大的方法。鉴于仅凭神经方差无法唯一确定潜在的动力学系统，具有解释性的架构应该优先考虑准确和低维的潜在动力学。在这项工作中，我们评估了顺序自动编码器（SAEs）在从模拟的神经数据集中恢复潜在的混沌吸引子方面的表现。我们发现，采用广泛使用的循环神经网络（RNN）为动力学基础的SAEs无法在真实的潜在状态维度上推断出准确的发射率，并且更大的RNNs依赖于数据中不存在的动态特征。另一方面，采用神经常微分方程（NODE）为基础的SAEs在真实的潜在状态维度上推断出准确的率，同时还恢复了潜在轨迹和固定点结构。

    Artificial neural networks that can recover latent dynamics from recorded neural activity may provide a powerful avenue for identifying and interpreting the dynamical motifs underlying biological computation. Given that neural variance alone does not uniquely determine a latent dynamical system, interpretable architectures should prioritize accurate and low-dimensional latent dynamics. In this work, we evaluated the performance of sequential autoencoders (SAEs) in recovering latent chaotic attractors from simulated neural datasets. We found that SAEs with widely-used recurrent neural network (RNN)-based dynamics were unable to infer accurate firing rates at the true latent state dimensionality, and that larger RNNs relied upon dynamical features not present in the data. On the other hand, SAEs with neural ordinary differential equation (NODE)-based dynamics inferred accurate rates at the true latent state dimensionality, while also recovering latent trajectories and fixed point structu
    
[^120]: 多实例学习对抗扰动的漏洞解释

    Interpreting Vulnerabilities of Multi-Instance Learning to Adversarial Perturbations. (arXiv:2211.17071v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.17071](http://arxiv.org/abs/2211.17071)

    本文提出了两种对抗性扰动方法以解释多实例学习在该方面的漏洞。其中一种针对每个袋子进行定制，另一种是通用的，可以影响给定数据集中的所有袋子，并且证明了这些方法的有效性。

    

    多实例学习（MIL）是最近一种非常有用的机器学习范式，广泛应用于图像分析、视频异常检测、文本分类等各种实际应用中。众所周知，现有的大多数机器学习分类器都极易受到对抗性扰动的攻击。由于MIL是弱监督学习，只有一个袋子中的实例集合是可访问的，而每个实例都无法获取，对抗性扰动可能是致命的。为了解释MIL方法的漏洞，我们提出了两种对抗性扰动方法。其中一种可以针对每个袋子进行定制，另一种是通用的，可以影响给定数据集中的所有袋子，因此具有一定的泛化性。通过模拟，我们还展示了所提出算法欺骗最先进的MIL方法的有效性。最后，我们使用所提出的技术分析了流行的MIL方法的对抗性漏洞。

    Multi-Instance Learning (MIL) is a recent machine learning paradigm which is immensely useful in various real-life applications, like image analysis, video anomaly detection, text classification, etc. It is well known that most of the existing machine learning classifiers are highly vulnerable to adversarial perturbations. Since MIL is a weakly supervised learning, where information is available for a set of instances, called bag and not for every instances, adversarial perturbations can be fatal. In this paper, we have proposed two adversarial perturbation methods to analyze the effect of adversarial perturbations to interpret the vulnerability of MIL methods. Out of the two algorithms, one can be customized for every bag, and the other is a universal one, which can affect all bags in a given data set and thus has some generalizability. Through simulations, we have also shown the effectiveness of the proposed algorithms to fool the state-of-the-art (SOTA) MIL methods. Finally, we have
    
[^121]: 通过实例模式组合器实现具有泛化性的隐式神经表示

    Generalizable Implicit Neural Representations via Instance Pattern Composers. (arXiv:2211.13223v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13223](http://arxiv.org/abs/2211.13223)

    本文提出了一种使用实例模式组合器实现具有泛化性的隐式神经表示的方法，该方法通过调制早期的多层感知器层中的一小组权重来表示复杂的数据实例，并学习模式组合规则以实现实例的共同表示。

    

    尽管隐式神经表示(INR)取得了一些进展，然而，对于一个基于坐标的多层感知器(INR MLP)来说，在学习跨数据实例的共同表示并将其推广到看不见的实例方面仍然很有挑战性。在本文中，我们提出了一种简单而有效的通用INR框架，它使得基于坐标的MLP仅通过调制早期MLP层中的一小组权重即实例模式组合器，即能够表示复杂的数据实例，而其余的MLP权重则学习适用于实例共同表示的模式组成规则。我们的通用INR框架与现有的元学习和超网络相兼容，可以学习预测看不见实例的调制权重。广泛的实验表明，我们的方法在各种领域(例如音频、图像和3D物体)上都取得了高性能，而消融研究验证了我们的权重调制方法。

    Despite recent advances in implicit neural representations (INRs), it remains challenging for a coordinate-based multi-layer perceptron (MLP) of INRs to learn a common representation across data instances and generalize it for unseen instances. In this work, we introduce a simple yet effective framework for generalizable INRs that enables a coordinate-based MLP to represent complex data instances by modulating only a small set of weights in an early MLP layer as an instance pattern composer; the remaining MLP weights learn pattern composition rules for common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in learning to predict the modulated weight for unseen instances. Extensive experiments demonstrate that our method achieves high performance on a wide range of domains such as an audio, image, and 3D object, while the ablation study validates our weight modulation.
    
[^122]: 基于树的机器学习方法的子群健壮性：一个实证基线调查

    Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation. (arXiv:2211.12703v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12703](http://arxiv.org/abs/2211.12703)

    本文通过实证比较多种公平和稳健的机器学习方法的子群健壮性，并表明基于树的方法具有极强的健壮性，可能比其他稳健或群体公平的方法表现更好。

    

    研究人员提出了许多公平和稳健的机器学习方法，但缺乏对它们的子群健壮性的全面实证评估。本文通过与基于状态-of-the-art树模型的基准线比较，以表格数据为背景，介绍了先前提出的多种公平和稳健学习方法的实证比较。通过在八个数据集上进行超过340,000个模型配置的实验，我们发现基于树的方法具有极强的子群健壮性，即使与稳健性和公平性增强方法进行比较。此外，最佳的基于树的模型往往表现出良好的综合性能，而稳健或群体公平的模型可能表现出脆弱性，对于不同的指标可能存在显著的性能差异。

    Researchers have proposed many methods for fair and robust machine learning, but comprehensive empirical evaluation of their subgroup robustness is lacking. In this work, we address this gap in the context of tabular data, where sensitive subgroups are clearly-defined, real-world fairness problems abound, and prior works often do not compare to state-of-the-art tree-based models as baselines. We conduct an empirical comparison of several previously-proposed methods for fair and robust learning alongside state-of-the-art tree-based methods and other baselines. Via experiments with more than $340{,}000$ model configurations on eight datasets, we show that tree-based methods have strong subgroup robustness, even when compared to robustness- and fairness-enhancing methods. Moreover, the best tree-based models tend to show good performance over a range of metrics, while robust or group-fair models can show brittleness, with significant performance differences across different metrics for a 
    
[^123]: 顺序知情联合消除：联邦优化中高效且可证明的客户端消除

    Sequential Informed Federated Unlearning: Efficient and Provable Client Unlearning in Federated Optimization. (arXiv:2211.11656v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11656](http://arxiv.org/abs/2211.11656)

    本文提出一种名为知情联合消除（IFU）的新颖联邦优化方法，可实现有效且可量化的客户端消除请求，实验结果表明其效率较基本方法和最先进的FU方法更高。

    

    机器消除（MU）旨在提供有关从训练过程中删除给定数据点的贡献的理论保证。联邦消除（FU）是将MU扩展到从联合训练过程中消除给定客户端的贡献。当前的FU方法通常不具有可扩展性，并且没有对消除效果的有效性进行合理的理论量化。在本文中，我们提出了知情联合消除(IFU)，这是一种新颖的高效且可量化的FU方法。在接收到给定客户端的消除请求后，IFU通过随机扰动机制确定了重新初始化FL所需的最佳FL迭代，可以获得消除保证。IFU的理论也可以扩展以解决顺序消除请求。不同任务和数据集上的实验结果表明，与基本重新训练和最先进的FU方法相比，IFU可以实现更高效的消除过程。

    The aim of Machine Unlearning (MU) is to provide theoretical guarantees on the removal of the contribution of a given data point from a training procedure. Federated Unlearning (FU) consists in extending MU to unlearn a given client's contribution from a federated training routine. Current FU approaches are generally not scalable, and do not come with sound theoretical quantification of the effectiveness of unlearning. In this work we present Informed Federated Unlearning (IFU), a novel efficient and quantifiable FU approach. Upon unlearning request from a given client, IFU identifies the optimal FL iteration from which FL has to be reinitialized, with unlearning guarantees obtained through a randomized perturbation mechanism. The theory of IFU is also extended to account for sequential unlearning requests. Experimental results on different tasks and dataset show that IFU leads to more efficient unlearning procedures as compared to basic re-training and state-of-the-art FU approaches.
    
[^124]: 报错对线性动态系统稳定性的影响

    Implications of Regret on Stability of Linear Dynamical Systems. (arXiv:2211.07411v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2211.07411](http://arxiv.org/abs/2211.07411)

    本文研究了在线学习中计算的遗憾与所选策略的闭环系统稳定性之间的关系，结果发现线性遗憾暗示着渐进稳定性。同时，有界输入的有界状态稳定性和状态转移矩阵的可加性也意味着线性遗憾概念。

    

    在最优控制、强化学习和近期的在线学习领域中，代理机器人在不确定性和动态限制下进行决策是很常见的。在在线学习设置中，代理机器人的决策质量通常被遗憾概念所度量，比较所选策略和最优解后悔的差距。虽然遗憾是一个有用的性能度量指标，但当考虑到动态系统时，评估所选策略的闭环系统的稳定性也很重要。在本文中，我们展示了对于线性状态反馈策略和受到对抗性干扰的线性系统，线性遗憾概念在时变和时不变设置下都暗示渐进稳定性。反之，我们也证明了有界输入的有界状态稳定性和状态转移矩阵的可加性意味着线性遗憾。

    The setting of an agent making decisions under uncertainty and under dynamic constraints is common for the fields of optimal control, reinforcement learning, and recently also for online learning. In the online learning setting, the quality of an agent's decision is often quantified by the concept of regret, comparing the performance of the chosen decisions to the best possible ones in hindsight. While regret is a useful performance measure, when dynamical systems are concerned, it is important to also assess the stability of the closed-loop system for a chosen policy. In this work, we show that for linear state feedback policies and linear systems subject to adversarial disturbances, linear regret implies asymptotic stability in both time-varying and time-invariant settings. Conversely, we also show that bounded input bounded state stability and summability of the state transition matrices imply linear regret.
    
[^125]: 机器学习在抑郁症预测中的公平性与偏差矫正：来自四个不同研究人群的结果。

    Fairness and bias correction in machine learning for depression prediction: results from four different study populations. (arXiv:2211.05321v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05321](http://arxiv.org/abs/2211.05321)

    本文研究了设计用于预测抑郁症的机器学习模型的公平性问题，并给出了有效的偏差矫正方法。这项研究强调了分析公平性以及透明报告的重要性。

    

    在心理保健中，尤其是在不受关注的人群中，存在着相当程度的污名化和不平等，这种不平等会扩散到收集的数据中。如果不适当地考虑机器学习(ML)模型所学的数据，这些模型就会强化已经存在于社会中的结构性偏差。在这里，我们对设计用于预测抑郁症的ML模型的偏差进行了有系统的研究，并在四个不同的案例研究中涵盖了不同的国家和人群。我们发现标准的ML方法显示出常规偏差行为。然而，我们展示了标准的缓解技术以及我们自己的事后方法可以有效地降低不公平偏差的级别。我们提供了实用的建议，以开发预测抑郁症风险的ML模型，在真实世界中提高公平性和信任度。没有单一最好的预测抑郁症的ML模型可以提供结果的平等。这强调了在模型选择过程中分析公平性以及透明报告的重要性。

    A significant level of stigma and inequality exists in mental healthcare, especially in under-served populations, which spreads through collected data. When not properly accounted for, machine learning (ML) models learned from data can reinforce the structural biases already present in society. Here, we present a systematic study of bias in ML models designed to predict depression in four different case studies covering different countries and populations. We find that standard ML approaches show regularly biased behaviors. However, we show that standard mitigation techniques, and our own post-hoc method, can be effective in reducing the level of unfair bias. We provide practical recommendations to develop ML models for depression risk prediction with increased fairness and trust in the real world. No single best ML model for depression prediction provides equality of outcomes. This emphasizes the importance of analyzing fairness during model selection and transparent reporting about t
    
[^126]: 带有组公平约束的可扩展谱聚类

    Scalable Spectral Clustering with Group Fairness Constraints. (arXiv:2210.16435v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.16435](http://arxiv.org/abs/2210.16435)

    本文提出了一个带有组公平约束的可扩展谱聚类算法 s-FairSC，并通过稀疏矩阵向量乘积来充分利用其稀疏性。

    

    机器学习中建模公平性和纠正算法偏差的研究兴趣和工业实践协同作用。本文提出了一种带有组公平约束的可扩展谱聚类（SC）算法。组公平也被称为统计平等，即在每个簇中，每个受保护的组别以与整体相同的比例表示。我们通过结合零空间投影和霍特林的缩减的新的谱计算方法，提出了一个名为 s-FairSC 的算法，它只涉及稀疏的矩阵向量乘积，能够充分利用公平 SC 模型的稀疏性。

    There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high costs due to the kernels of computing nullspaces and the square roots of dense matrices explicitly. We present a new formulation of underlying spectral computation by incorporating nullspace projection and Hotelling's deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that s-FairSC
    
[^127]: 通用对抗方向

    Universal Adversarial Directions. (arXiv:2210.15997v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.15997](http://arxiv.org/abs/2210.15997)

    研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。

    

    尽管深度神经网络在图像识别任务中表现出色，但观察到它们容易受到通用对抗干扰 (UAPs) 的影响，这些干扰使用单个扰动向量干扰所有输入样本。然而，UAPs在跨DNN架构转移时通常很困难并导致挑战性优化问题。本文研究了UAP的可Transfer性，通过分析分类器和UAP对手玩家之间在通用对抗示例博弈中的均衡情况。我们表明，在温和的假设下，通用对抗示例博弈缺乏一个纯纳什均衡，这表明UAPs在DNN分类器之间的转移性是次优的。针对这个问题，我们提出了通用对抗方向 (UADs)，只固定对抗干扰的通用方向，允许跨样本自由选择干扰的幅度。我们证明，UAD对抗示例博弈可以具有纳什均衡且该均衡状态纯。

    Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure U
    
[^128]: 学习预测任意量子过程

    Learning to predict arbitrary quantum processes. (arXiv:2210.14894v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2210.14894](http://arxiv.org/abs/2210.14894)

    本论文提出一种用于预测任意量子过程的机器学习算法，该算法对于各种不同分布的输入状态具有小的平均误差，即便在处理指数门时也具有高效率，实验结果证实其有效性，是一种优于现有方法的新算法。

    

    我们提出了一种有效的机器学习算法，用于预测n个量子比特上任意未知量子过程E。对于任意n比特状态上的广泛分布，我们证明这种机器学习算法可以学习预测从未知过程E输出的任何局部性质，并在绘制自分布的输入状态上具有小的平均误差。即使未知过程是具有指数多个门的量子电路，该机器学习算法也具有计算效率。我们的算法结合了学习未知状态属性和学习未知可观察低阶逼近的有效过程。该分析基于证明新的范数不等式，其中包括我们通过提供优化局部哈密顿量的改进算法而导出的经典Bohnenblust-Hille不等式的量子类比。在涉及到10^6演化时间和高达7个量子比特的量子动力学的数值实验中，我们的算法优于现有的机器学习和物理启发式方法。

    We present an efficient machine learning (ML) algorithm for predicting any unknown quantum process $\mathcal{E}$ over $n$ qubits. For a wide range of distributions $\mathcal{D}$ on arbitrary $n$-qubit states, we show that this ML algorithm can learn to predict any local property of the output from the unknown process~$\mathcal{E}$, with a small average error over input states drawn from $\mathcal{D}$. The ML algorithm is computationally efficient even when the unknown process is a quantum circuit with exponentially many gates. Our algorithm combines efficient procedures for learning properties of an unknown state and for learning a low-degree approximation to an unknown observable. The analysis hinges on proving new norm inequalities, including a quantum analogue of the classical Bohnenblust-Hille inequality, which we derive by giving an improved algorithm for optimizing local Hamiltonians. Numerical experiments on predicting quantum dynamics with evolution time up to $10^6$ and system
    
[^129]: MEET: 缓冲区采样的蒙特卡罗探索-开发权衡

    MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling. (arXiv:2210.13545v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13545](http://arxiv.org/abs/2210.13545)

    提出了一种新的基于探索-开发权衡的缓冲区采样策略，可以根据任务的复杂性自适应地调整采样策略，并在经典控制环境中表现出优越性能。

    

    数据选择是任何基于数据的优化技术的关键，例如强化学习。针对回放缓冲区的最新采样策略可以提高强化学习智能体的性能。然而，它们没有考虑Q值估计的不确定性。因此，它们不能根据任务的复杂性自适应地调整采样策略，包括转换的探索和开发。为了解决这个问题，本文提出了一种新的采样策略，这种策略利用了探索-开发权衡。这是通过Q值函数的不确定性估计实现的，它指导采样探索更重要的转换，从而学习更有效的策略。对于经典控制环境的实验表明，在不同环境中平稳的结果。它们表明，在密集奖励的情况下，与收敛和峰值性能相比，所提出的方法的表现比最新的采样策略提高了26％。

    Data selection is essential for any data-based optimization technique, such as Reinforcement Learning. State-of-the-art sampling strategies for the experience replay buffer improve the performance of the Reinforcement Learning agent. However, they do not incorporate uncertainty in the Q-Value estimation. Consequently, they cannot adapt the sampling strategies, including exploration and exploitation of transitions, to the complexity of the task. To address this, this paper proposes a new sampling strategy that leverages the exploration-exploitation trade-off. This is enabled by the uncertainty estimation of the Q-Value function, which guides the sampling to explore more significant transitions and, thus, learn a more efficient policy. Experiments on classical control environments demonstrate stable results across various environments. They show that the proposed method outperforms state-of-the-art sampling strategies for dense rewards w.r.t. convergence and peak performance by 26% on av
    
[^130]: 以架构感知参考作为提示提高了数据有效的知识图谱构建

    Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10709](http://arxiv.org/abs/2210.10709)

    提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。

    

    随着预训练语言模型的发展，许多基于提示的方法被提出并在数据有效的知识图谱构建中取得了令人瞩目的表现。然而，现有的基于提示的学习方法仍存在几个潜在的限制：（i）自然语言和预定义模式的输出结构化知识之间的语义差距，这意味着模型无法充分利用受限模板的语义知识；（ii）基于局部个体实例的表示学习限制了性能，给定了不充足的特征，这些特征不能释放预先训练语言模型的潜在类比能力。受这些观察的启发，我们提出了一种检索增强的方法，使用检索得到的架构感知参考作为提示，提高了数据有效的知识图谱构建的语义连贯性和一致性。在两个标准数据集上的实验结果表明，相比现有的基于提示和非提示的方法，我们提出的方法在数据效率和知识质量方面具有优越性。

    With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have been proposed and achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supe
    
[^131]: RibSeg v2：肋骨标记和解剖中心线提取的大规模基准测试

    RibSeg v2: A Large-scale Benchmark for Rib Labeling and Anatomical Centerline Extraction. (arXiv:2210.09309v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2210.09309](http://arxiv.org/abs/2210.09309)

    本文扩展了RibSeg数据集到大规模基准测试RibSeg v2，加入了手动标注的肋骨标记和解剖中心线提取，共包含660个CT扫描（15,466个独立的肋骨），并提出了深度学习方法用于肋骨标记、基于骨架化方法用于中心线提取、一种稀疏点云表示CT扫描的方法，以及适用于该任务的评估指标。

    

    自动化的肋骨标记和解剖中心线提取是各种临床应用的常见前提条件。以往的研究要么使用内部数据集，无法为社群所共享，要么只关注于肋骨分割而忽略了肋骨标记的临床意义。为了解决这些问题，本文将之前计算机断层扫描（CT）肋骨分割的RibSeg数据集扩展为综合性基准测试RibSeg v2，并加入了肋骨标记和解剖中心线提取的手动标注，共包含了660个CT扫描（15,466个独立的肋骨）。基于RibSeg v2数据集，我们开发了一种包含深度学习方法用于肋骨标记，以及基于骨架化方法用于中心线提取的流程。为了提高计算效率，我们还提出了一种稀疏点云表示CT扫描的方法，与标准的密集体素网格进行了比较。此外，我们还设计和分析评估指标，以解决每个任务的关键挑战。我们的数据集是，…

    Automatic rib labeling and anatomical centerline extraction are common prerequisites for various clinical applications. Prior studies either use in-house datasets that are inaccessible to communities, or focus on rib segmentation that neglects the clinical significance of rib labeling. To address these issues, we extend our prior dataset (RibSeg) on the binary rib segmentation task to a comprehensive benchmark, named RibSeg v2, with 660 CT scans (15,466 individual ribs in total) and annotations manually inspected by experts for rib labeling and anatomical centerline extraction. Based on the RibSeg v2, we develop a pipeline including deep learning-based methods for rib labeling, and a skeletonization-based method for centerline extraction. To improve computational efficiency, we propose a sparse point cloud representation of CT scans and compare it with standard dense voxel grids. Moreover, we design and analyze evaluation metrics to address the key challenges of each task. Our dataset,
    
[^132]: 用神经平衡求解器解决NEs、CEs和CCEs的方法

    Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers. (arXiv:2210.09257v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09257](http://arxiv.org/abs/2210.09257)

    该论文介绍了一种神经平衡求解器，可以快速、准确地解决所有固定形状游戏空间的NEs、CEs和CCEs问题，并提供一个灵活的平衡选择框架，有助于加强多智能体算法的实现和应用。

    

    解决博弈论中的Nash Equilibria、Correlated Equilibria和Coarse Correlated Equilibria等解决方案对于许多多智能体机器学习算法非常有用。然而，解决正则形式的博弈可能需要禁止或非确定性时间收敛，并且可能会失败。我们介绍了神经平衡求解器，它利用一种特殊的等变神经网络结构来近似解决所有固定形状的游戏空间，从而提高速度和确定性。我们定义了一个灵活的平衡选择框架，能够唯一选择最小化相对熵或最大化福利的平衡。网络可以在不需要生成任何监督训练数据的情况下进行训练。我们展示了惊人的零-shot泛化能力，使网络适用于更大的游戏。我们认为这样的网络是许多可能多智能体算法的强大组件。

    Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms.
    
[^133]: 用于椭圆界面问题的尖点捕获PINN

    A cusp-capturing PINN for elliptic interface problems. (arXiv:2210.08424v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2210.08424](http://arxiv.org/abs/2210.08424)

    本文提出了一种用于解决椭圆界面问题的尖点捕获PINN，它使用尖点强制水平集函数作为额外特征输入，以锐利地捕获解尖点，同时具有无网格优点。

    

    本文提出了一种尖点捕获物理信息神经网络(PINN)，用于解决解在界面上具有不连续一阶导数的间断系数椭圆界面问题。为了找到这样的解，使用神经网络表示，我们引入了一个尖点强制水平集函数作为网络的额外特征输入，以保持固有的解性质，即锐利地捕获解尖点(其中导数不连续)。此外，所提出的神经网络具有无网格的优点，因此可以轻松处理不规则域中的问题。我们使用物理信息框架训练网络，其中损失函数包括微分方程的残差以及某些界面和边界条件。我们进行了一系列数值实验，以证明尖点捕获技术的有效性和当前网络模型的准确性。

    In this paper, we propose a cusp-capturing physics-informed neural network (PINN) to solve discontinuous-coefficient elliptic interface problems whose solution is continuous but has discontinuous first derivatives on the interface. To find such a solution using neural network representation, we introduce a cusp-enforced level set function as an additional feature input to the network to retain the inherent solution properties; that is, capturing the solution cusps (where the derivatives are discontinuous) sharply. In addition, the proposed neural network has the advantage of being mesh-free, so it can easily handle problems in irregular domains. We train the network using the physics-informed framework in which the loss function comprises the residual of the differential equation together with certain interface and boundary conditions. We conduct a series of numerical experiments to demonstrate the effectiveness of the cusp-capturing technique and the accuracy of the present network mo
    
[^134]: 学习图像表示以进行异常检测：在药物开发中发现组织学改变的应用

    Learning image representations for anomaly detection: application to discovery of histological alterations in drug development. (arXiv:2210.07675v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07675](http://arxiv.org/abs/2210.07675)

    该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。

    

    我们提出了一种用于组织病理学图像异常检测的系统。在组织学中，正常样本通常是大量存在的，而异常（病理）情况通常很少或不可用。在这种情况下，使用在健康数据上训练的单类分类器可以检测到分布外的异常样本。这样的方法与预训练的卷积神经网络（CNN）图像表示相结合，以前已经用于异常检测（AD）。但是，预训练的现成CNN表示可能对组织中的异常情况不敏感，而健康组织的自然变异可能导致远离的表示。为了使表示适应健康组织中的相关细节，我们建议在辅助任务上训练CNN，该任务区分不同物种、器官和染色试剂的健康组织。几乎不需要额外的标注工作量，因为健康样本可以自动获得上述标签。在训练中，我们强制执行

    We present a system for anomaly detection in histopathological images. In histology, normal samples are usually abundant, whereas anomalous (pathological) cases are scarce or not available. Under such settings, one-class classifiers trained on healthy data can detect out-of-distribution anomalous samples. Such approaches combined with pre-trained Convolutional Neural Network (CNN) representations of images were previously employed for anomaly detection (AD). However, pre-trained off-the-shelf CNN representations may not be sensitive to abnormal conditions in tissues, while natural variations of healthy tissue may result in distant representations. To adapt representations to relevant details in healthy tissue we propose training a CNN on an auxiliary task that discriminates healthy tissue of different species, organs, and staining reagents. Almost no additional labeling workload is required, since healthy samples come automatically with aforementioned labels. During training we enforce
    
[^135]: 大规模几何学习的内在维度

    Intrinsic Dimension for Large-Scale Geometric Learning. (arXiv:2210.05301v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05301](http://arxiv.org/abs/2210.05301)

    本研究提出了一种计算上可行的方法来确定大规模复杂数据的内在维度，该方法考虑了数据集的几何特性，并在准确性和计算效率方面优于现有方法。

    

    维度的概念对于理解数据的复杂性至关重要。确定数据集的维度的一种天真的方法是基于属性的数量。更复杂的方法推导出内在维度（ID）的概念，使用更复杂的特征函数，例如数据点之间的距离。然而，许多这些方法基于经验观察，无法应对当代数据集的几何特性，并且缺乏公理基础。V. Pestov提出了一种不同的方法，将内在维度公理地与数学集中度现象联系起来。首先，对于大规模实际数据集，计算这些内在维度的方法计算上是不可行的。在本研究中，我们推导出了一种计算上可行的方法来确定这些公理的内在维度函数。

    The concept of dimension is essential to grasp the complexity of data. A naive approach to determine the dimension of a dataset is based on the number of attributes. More sophisticated methods derive a notion of intrinsic dimension (ID) that employs more complex feature functions, e.g., distances between data points. Yet, many of these approaches are based on empirical observations, cannot cope with the geometric character of contemporary datasets, and do lack an axiomatic foundation. A different approach was proposed by V. Pestov, who links the intrinsic dimension axiomatically to the mathematical concentration of measure phenomenon. First methods to compute this and related notions for ID were computationally intractable for large-scale real-world datasets. In the present work, we derive a computationally feasible method for determining said axiomatic ID functions. Moreover, we demonstrate how the geometric properties of complex data are accounted for in our modeling. In particular, 
    
[^136]: 一条新路: 用合成指令和模仿学习扩展视觉语言导航模型的规模

    A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. (arXiv:2210.03112v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03112](http://arxiv.org/abs/2210.03112)

    该论文研究了使用合成指令的大规模扩充方法，通过构建导航轨迹并使用高质量的多语言导航指令生成器Marky生成基于图像的指令，以及使用图像到图像GAN在新的视角上合成图像观察。这些方法得到了更强的视觉语言导航模型。

    

    最近在视觉语言导航（VLN）中的研究使用强化学习代理在逼真的环境中执行自然语言导航指令，以实现机器人遵循人类指令的目标。然而，研究表明由于人类指令数据稀缺且训练环境缺乏多样性，这些代理仍然难以理解复杂的语言和空间语言。我们调查了使用合成指令的大规模扩充。我们利用Marky，一种高品质的多语言导航指令生成器，创建了500多个室内环境，通过这些全景图构建导航轨迹，并为每个轨迹生成了一个基于图像的指令。我们还使用图像到图像GAN在新的视角上合成图像观察。通过这些方法得到了更强的视觉语言导航模型。

    Recent studies in Vision-and-Language Navigation (VLN) train RL agents to execute natural-language navigation instructions in photorealistic environments, as a step towards robots that can follow human instructions. However, given the scarcity of human instruction data and limited diversity in the training environments, these agents still struggle with complex language grounding and spatial language understanding. Pretraining on large text and image-text datasets from the web has been extensively explored but the improvements are limited. We investigate large-scale augmentation with synthetic instructions. We take 500+ indoor environments captured in densely-sampled 360 degree panoramas, construct navigation trajectories through these panoramas, and generate a visually-grounded instruction for each trajectory using Marky, a high-quality multilingual navigation instruction generator. We also synthesize image observations from novel viewpoints using an image-to-image GAN. The resulting d
    
[^137]: 利用变分因果推断和精细关系信息预测细胞响应

    Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00116](http://arxiv.org/abs/2210.00116)

    本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。

    

    预测细胞在干扰下的响应可能为药物研发和个性化治疗带来重要好处。在本研究中，我们提出了一种新的图形变分贝叶斯因果推断框架，预测细胞在反事实干扰下（即细胞未真实接收的干扰）的基因表达，利用代表生物学知识的基因调控网络（GRN）信息来辅助个性化细胞响应预测。我们还针对数据自适应GRN开发了邻接矩阵更新技术用于图卷积网络的预训练，在模型性能上提供了更多的基因关系洞见。

    Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
    
[^138]: DecAF：针对知识库问答的答案和逻辑形式联合解码

    DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases. (arXiv:2210.00063v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00063](http://arxiv.org/abs/2210.00063)

    DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。

    

    知识库问答旨在使用知识库中的实体和关系等事实信息回答自然语言问题。先前的方法要么生成可在知识库上执行以获取最终答案的逻辑形式，要么直接预测答案。实验证据表明，前者通常能产生更准确的答案，但由于生成的逻辑形式可能存在语法和语义错误的潜在问题，因此存在无法执行的问题。在本文中，我们提出了一种新颖的框架 DecAF，它联合生成逻辑形式和直接答案，然后将它们的优点结合起来得到最终答案。此外，与大多数先前的方法不同，DecAF 基于简单的自由文本检索，而不依赖任何实体链接工具--这种简化使其适应不同的数据集更加容易。DecAF 在 WebQSP、FreebaseQA 和 GrailQA 基准测试中取得了新的最高准确性，同时在 CommonsenseQA 基准测试上取得了具有竞争力的结果。

    Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results show that the former often produces more accurate answers, but it suffers from non-execution issues due to potential syntactic and semantic errors in the generated logical forms. In this work, we propose a novel framework DecAF that jointly generates both logical forms and direct answers, and then combines the merits of them to get the final answers. Moreover, different from most of the previous methods, DecAF is based on simple free-text retrieval without relying on any entity linking tools -- this simplification eases its adaptation to different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks, while getting competitive results on the Com
    
[^139]: 深度生成模型用于超分辨率多区域气候数据

    Deep generative model super-resolves spatially correlated multiregional climate data. (arXiv:2209.12433v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2209.12433](http://arxiv.org/abs/2209.12433)

    本研究展示了一个基于对抗网络的机器学习方法，在超分辨率处理过程中可以正确重构区域间的空间相关性，从而提高气候模拟输出的质量与准确度。

    

    对全球气候模拟的粗略输出进行超分辨率处理 (downscaling)是制定需要长期气候变化预测的政治和社会决策的关键。然而，现有的快速超分辨率技术尚未保留气候数据的空间相关性，而当我们处理具有空间广度的系统如交通基础设施时，这一点尤为重要。在这里，我们展示一个基于对抗网络的机器学习使得我们可以正确重构超分辨率下降时的区域间空间相关性，并在保持像素平均统计一致性的同时实现高达50倍的放大。通过直接比较温度和降水分布的测量气象数据，我们发现整合气候学意义上的物理信息可以提高超分辨率性能，这促使我们将这种方法称为 $\pi$SRGAN (物理信息超分辨率生成对抗网络)。

    Super-resolving the coarse outputs of global climate simulations, termed downscaling, is crucial in making political and social decisions on systems requiring long-term climate change projections. Existing fast super-resolution techniques, however, have yet to preserve the spatially correlated nature of climatological data, which is particularly important when we address systems with spatial expanse, such as the development of transportation infrastructure. Herein, we show an adversarial network-based machine learning enables us to correctly reconstruct the inter-regional spatial correlations in downscaling with high magnification of up to fifty while maintaining pixel-wise statistical consistency. Direct comparison with the measured meteorological data of temperature and precipitation distributions reveals that integrating climatologically important physical information improves the downscaling performance, which prompts us to call this approach $\pi$SRGAN (Physics Informed Super-Reso
    
[^140]: 使用深度集成学习提升计算机网络对抗攻击的安全性

    Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks. (arXiv:2209.12195v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2209.12195](http://arxiv.org/abs/2209.12195)

    本文提出了一种基于集成分类器的架构，称作SPRITZ-1.5C，它同时结合了1类分类的安全性和传统2类分类的高性能，在计算机网络等安全型应用中抵御对抗攻击具有挑战性。

    

    近年来，卷积神经网络在网络和多媒体安全等各种实际应用中表现出了极大的潜力。然而，这种网络结构的脆弱性使其容易受到攻击，这使得它们在安全性方面不太适用于诸如计算机网络等的安全型应用中。为了保护这些架构免受对抗攻击，需要使用具有挑战攻击能力的安全型架构。本研究提出了一种基于集成分类器的创新架构，该架构在面临攻击时同时结合了增强的一类分类和传统的二类分类的高性能。我们的架构被称为1.5类分类器（SPRITZ-1.5C），由终密集分类器、一个二类分类器（即CNN）和两个并行的一类分类器（即自动编码器）构成。

    In the past few years, Convolutional Neural Networks (CNN) have demonstrated promising performance in various real-world cybersecurity applications, such as network and multimedia security. However, the underlying fragility of CNN structures poses major security problems, making them inappropriate for use in security-oriented applications including such computer networks. Protecting these architectures from adversarial attacks necessitates using security-wise architectures that are challenging to attack.  In this study, we present a novel architecture based on an ensemble classifier that combines the enhanced security of 1-Class classification (known as 1C) with the high performance of conventional 2-Class classification (known as 2C) in the absence of attacks.Our architecture is referred to as the 1.5-Class (SPRITZ-1.5C) classifier and constructed using a final dense classifier, one 2C classifier (i.e., CNNs), and two parallel 1C classifiers (i.e., auto-encoders). In our experiments, 
    
[^141]: 采样与学习分数同样简单：对假设数据最小的扩散模型的理论研究

    Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions. (arXiv:2209.11215v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.11215](http://arxiv.org/abs/2209.11215)

    本文对得分式生成模型进行了理论研究，证明其可以有效地从任何实际数据分布中采样。与以往研究不同的是，本文的结果不需要排除实质性非对数凹性的限制性函数不等式条件，并且具有多项式的规模。这是得分式生成模型实证成功的强有力理论证明。

    

    我们为得分式生成模型提供了理论上的收敛保证，例如去噪扩散概率模型（DDPM），它是大规模实际生成模型（如DALL·E 2）的支柱。我们的主要结果是，在假设得分估计准确时，这样的SGM可以有效地从任何实际数据分布中采样。与之前的研究不同的是，我们的结果：（1）适用于$L^2$准确的分数估计（而不是$L^\infty$准确的）；(2) 不需要排除实质性非对数凹性的限制性函数不等式条件；（3）在所有相关的问题参数中具有多项式的规模；（4）匹配最先进的Langevin扩散的离散化的复杂度保证，前提是评分误差足够小。我们认为这是SGM实证成功的强有力理论证明。我们还检查了基于临界阻尼Langevin扩散（CLD）的SGM，与以往研究结论不同，

    We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\cdot$E 2. Our main result is that, assuming accurate score estimates, such SGMs can efficiently sample from essentially any realistic data distribution. In contrast to prior works, our results (1) hold for an $L^2$-accurate score estimate (rather than $L^\infty$-accurate); (2) do not require restrictive functional inequality conditions that preclude substantial non-log-concavity; (3) scale polynomially in all relevant problem parameters; and (4) match state-of-the-art complexity guarantees for discretization of the Langevin diffusion, provided that the score error is sufficiently small. We view this as strong theoretical justification for the empirical success of SGMs. We also examine SGMs based on the critically damped Langevin diffusion (CLD). Contrary to
    
[^142]: 通过元学习学习符号模型无关损失函数

    Learning Symbolic Model-Agnostic Loss Functions via Meta-Learning. (arXiv:2209.08907v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.08907](http://arxiv.org/abs/2209.08907)

    本文提出了一种通过元学习框架学习模型无关损失函数的方法，并通过对多个监督学习任务的实验证明，该方法学到的损失函数优于目前最优方法和交叉熵损失函数。

    

    本文研究损失函数学习的新兴主题，旨在学习可以显著提高模型性能的损失函数。我们提出了一种新的元学习框架，通过混合神经符号搜索方法学习模型无关的损失函数。该框架首先使用基于进化的方法在原始数学操作空间中搜索符号损失函数的集合。然后，学习到的一组损失函数通过端到端的梯度训练过程进行参数化和优化。所提出的框架的多功能性在一组多样化的监督学习任务上得到了经验证实。结果显示，新提出的方法发现的元学习损失函数在各种神经网络架构和数据集上均优于交叉熵损失和现有最先进的损失函数学习方法。

    In this paper, we develop upon the emerging topic of loss function learning, which aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for learning model-agnostic loss functions via a hybrid neuro-symbolic search approach. The framework first uses evolution-based methods to search the space of primitive mathematical operations to find a set of symbolic loss functions. Second, the set of learned loss functions are subsequently parameterized and optimized via an end-to-end gradient-based training procedure. The versatility of the proposed framework is empirically validated on a diverse set of supervised learning tasks. Results show that the meta-learned loss functions discovered by the newly proposed method outperform both the cross-entropy loss and state-of-the-art loss function learning methods on a diverse range of neural network architectures and datasets.
    
[^143]: 采用奇异性分离深度Ritz方法求解带奇异源的椭圆问题

    Solving Elliptic Problems with Singular Sources using Singularity Splitting Deep Ritz Method. (arXiv:2209.02931v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2209.02931](http://arxiv.org/abs/2209.02931)

    本研究提出一种采用奇异性分离深度Ritz方法求解带奇异源的椭圆问题的高效求解器，成功应对了一般点源、线源以及点线源的组合，在实际应用中效果良好。

    

    本文提出一种基于神经网络的高效求解器，用于具有可变系数和奇异源的二阶椭圆方程。该类问题涵盖了一般点源、线源以及点线源的组合，并具有广泛的实际应用。所提出的方法基于将真实解分解为已知解析奇异部分和满足具有平滑源的适当修改椭圆PDE的常规部分，然后使用深度Ritz方法求解常规部分。建议采用路径跟踪策略选择惩罚参数以强制实施Dirichlet边界条件。在二维和多维空间中展示了大量具有点源、线源或它们组合的数值实验，以说明所提出方法的有效性，并进行比较研究以证明其优越性能。

    In this work, we develop an efficient solver based on neural networks for second-order elliptic equations with variable coefficients and singular sources. This class of problems covers general point sources, line sources and the combination of point-line sources, and has a broad range of practical applications. The proposed approach is based on decomposing the true solution into a singular part that is known analytically using the fundamental solution of the Laplace equation and a regular part that satisfies a suitable modified elliptic PDE with a smoother source, and then solving for the regular part using the deep Ritz method. A path-following strategy is suggested to select the penalty parameter for enforcing the Dirichlet boundary condition. Extensive numerical experiments in two- and multi-dimensional spaces with point sources, line sources or their combinations are presented to illustrate the efficiency of the proposed approach, and a comparative study with several existing appro
    
[^144]: UniCon: 带有对比损失的单向分歧学习用于视觉问答

    UniCon: Unidirectional Split Learning with Contrastive Loss for Visual Question Answering. (arXiv:2208.11435v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.11435](http://arxiv.org/abs/2208.11435)

    本文提出了UniCon方法，用于解决多客户VQA任务的保密性约束和客户有限标记训练数据的问题。该方法通过模型共享学习跨模态表示，采用分裂学习架构确保隐私。

    

    多模式数据的视觉问答（VQA）有助于现实应用，如家庭机器人和医学诊断。然而，面临的一个重要挑战是为各种客户任务设计强大的学习方法。其中一个关键方面是确保隐私，因为由于保密问题，客户数据共享受到限制。本文致力于解决多客户VQA任务的保密性约束和客户有限标记训练数据的问题。我们提出了带有对比损失的单向分歧学习（UniCon）方法来克服这些限制。所提出的方法在不同客户的整个数据分布上训练全局模型，通过模型共享学习精细的跨模态表示来实现隐私保证，利用分裂学习架构确保隐私，其中完整模型分为两个组件进行独立训练。此外，最近发现自我监督学习技术与我们的方法高度兼容。

    Visual Question Answering (VQA) using multi-modal data facilitates real-life applications, such as home robots and medical diagnoses. However, one significant challenge is to design a robust learning method for various client tasks. One critical aspect is to ensure privacy, as client data sharing is limited due to confidentiality concerns. This work focuses on addressing the issue of confidentiality constraints in multi-client VQA tasks and limited labeled training data of clients. We propose the Unidirectional Split Learning with Contrastive Loss (UniCon) method to overcome these limitations. The proposed method trains a global model on the entire data distribution of different clients, learning refined cross-modal representations through model sharing. Privacy is ensured by utilizing a split learning architecture in which a complete model is partitioned into two components for independent training. Moreover, recent self-supervised learning techniques were found to be highly compatibl
    
[^145]: FORBID: 一种快速移除图绘制中重叠的随机梯度下降算法

    FORBID: Fast Overlap Removal By stochastic gradIent Descent for Graph Drawing. (arXiv:2208.10334v2 [cs.CG] UPDATED)

    [http://arxiv.org/abs/2208.10334](http://arxiv.org/abs/2208.10334)

    FORBID提出了一种基于随机梯度下降的算法，用于解决图形可视化中因节点形状而引起的重叠问题，该算法能在维持节点拓扑信息的同时，高效地移除重叠。

    

    许多图绘制算法将节点视为点，而图形可视化工具经常将它们表示为形状。这些形状支持显示标签或使用大小或颜色编码各种数据。然而，它们会产生节点之间的重叠，这会通过隐藏部分信息来阻碍探索过程。因此，消除这些重叠以提高图形可视化的可读性非常重要。本研究提出了一种新颖的算法，将重叠移除看作是一个联合应力和缩放优化问题，并利用高效的随机梯度下降。该方法与现有算法进行比较，多个质量度量证明了它快速移除重叠的有效性，同时保持了图形布局的拓扑信息。

    While many graph drawing algorithms consider nodes as points, graph visualization tools often represent them as shapes. These shapes support the display of information such as labels or encode various data with size or color. However, they can create overlaps between nodes which hinder the exploration process by hiding parts of the information. It is therefore of utmost importance to remove these overlaps to improve graph visualization readability. If not handled by the layout process, Overlap Removal (OR) algorithms have been proposed as layout post-processing. As graph layouts usually convey information about their topology, it is important that OR algorithms preserve them as much as possible. We propose a novel algorithm that models OR as a joint stress and scaling optimization problem, and leverages efficient stochastic gradient descent. This approach is compared with state-of-the-art algorithms, and several quality metrics demonstrate its efficiency to quickly remove overlaps whil
    
[^146]: 马尔科夫观测模型

    Markov Observation Models. (arXiv:2208.06368v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.06368](http://arxiv.org/abs/2208.06368)

    本文针对隐马尔可夫模型扩展为允许马尔可夫链观测，研究了相应的期望最大化算法类比算法，并实现了相应的滤波和Viterbi算法。

    

    本文将隐马尔可夫模型扩展为允许马尔可夫链观测。特别地，假设观测值是具有马尔可夫性质的链，其一步转移概率依赖于隐藏的马尔可夫链。针对这种更加普遍的模型，研究了期望最大化算法与Baum-Welch算法的类比算法，以估计隐藏状态和观测序列的转移概率，以及估计初始联合隐藏状态-观测分布的概率。从期望最大化算法的计算中得出了信念状态或滤波性递推来跟踪隐藏的状态。同时，还开发了动态规划类比的Viterbi算法，以估计给定观测序列的最可能的隐藏状态序列。

    Herein, the Hidden Markov Model is expanded to allow for Markov chain observations. In particular, the observations are assumed to be a Markov chain whose one step transition probabilities depend upon the hidden Markov chain. An Expectation-Maximization analog to the Baum-Welch algorithm is developed for this more general model to estimate the transition probabilities for both the hidden state and for the observations as well as to estimate the probabilities for the initial joint hidden-state-observation distribution. A believe state or filter recursion to track the hidden state then arises from the calculations of this Expectation-Maximization algorithm. A dynamic programming analog to the Viterbi algorithm is also developed to estimate the most likely sequence of hidden states given the sequence of observations.
    
[^147]: 学习证明机制目前存在许多问题

    Proof-of-Learning is Currently More Broken Than You Think. (arXiv:2208.03567v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03567](http://arxiv.org/abs/2208.03567)

    学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。

    

    学习证明（PoL）提出，模型所有者记录训练检查点，以建立为训练耗费的计算提供证明。 PoL的作者放弃了加密方法，以换取深度学习的可扩展性，从而换取了严格的安全保证。他们通过展示盗用模型的计算证明--计算偷来的模型的证明，和真正地训练模型所需要的证明一样昂贵来实证证明了这种方法的优点。但是，最近的研究提供了一个反例，从而使这个观察失效。在这项工作中，我们首先证明，尽管当前PoL验证对于对手来说不稳健是真实的，但是最近的工作大大低估了这种缺乏稳健性。这是因为现有的欺骗策略要么不可重现，要么针对PoL的削弱形式--这意味着它们很容易被更改验证的超参数来挫败。相反，我们引入了第一批欺骗策略，它们可以打破适用于PoL的最新防御方法，但代价很低。

    Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing--computing a proof for a stolen model--is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.  In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL--meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that c
    
[^148]: 基于压力分布分析的婴儿运动分类——研究和临床应用的附加价值

    Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation. (arXiv:2208.00884v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2208.00884](http://arxiv.org/abs/2208.00884)

    本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。

    

    本研究旨在通过使用压力传感设备来对婴儿的一般运动进行分类，从而实现早期的神经肌肉障碍（如脑瘫）的客观检测。本文测试了使用压力数据来区分“坐立不安期”（即坐立不安运动）与“坐立不安前期”（即扭动运动）的典型运动模式的可行性。在此过程中，我们记录了每个婴儿在出生后 4-16 周的间隔期内连续七个实验室会话的多模态传感器数据，包括来自一个 32x32 网格压力传感垫及其 1024 个传感器的压力数据。为了验证概念，从两个目标年龄段中，每个持续 5 秒的 1776 个压力数据片段被用于运动分类。每个片段都是根据相应的同步视频数据由人工评估员进行预注释的，标记为坐立不安存在或不存在。

    Aiming at objective early detection of neuromotor disorders such as cerebral palsy, we proposed an innovative non-intrusive approach using a pressure sensing device to classify infant general movements (GMs). Here, we tested the feasibility of using pressure data to differentiate typical GM patterns of the ''fidgety period'' (i.e., fidgety movements) vs. the ''pre-fidgety period'' (i.e., writhing movements). Participants (N = 45) were sampled from a typically-developing infant cohort. Multi-modal sensor data, including pressure data from a 32x32-grid pressure sensing mat with 1024 sensors, were prospectively recorded for each infant in seven succeeding laboratory sessions in biweekly intervals from 4-16 weeks of post-term age. For proof-of-concept, 1776 pressure data snippets, each 5s long, from the two targeted age periods were taken for movement classification. Each snippet was pre-annotated based on corresponding synchronised video data by human assessors as either fidgety present (
    
[^149]: Metroplolis Monte Carlo采样: 收敛性、局域化转变及最优性

    Metropolis Monte Carlo sampling: convergence, localization transition and optimality. (arXiv:2207.10488v4 [cond-mat.stat-mech] UPDATED)

    [http://arxiv.org/abs/2207.10488](http://arxiv.org/abs/2207.10488)

    本文使用分析和数值方法研究了随机行走Metroplolis方案中向稳定状态的收敛性质，发现随机漫步中的尝试跳变量特征长度可以呈现为局部化转变的形式，收敛后及局部化转变前的弛豫分别受扩散和…（论文重点）

    

    在随机采样方法中，马尔科夫链蒙特卡罗算法是最重要的。使用分析和数值方法相结合，我们研究了随机行走Metroplolis方案中向稳定状态的收敛性质。通过分析一些足够简单以实现分析进展的模型算法的弛豫性质，我们表明，从目标稳态分布偏差的特征长度作为定义随机漫步的尝试跳变量可以呈现为局部化转变的形式。虽然蒙特卡罗算法的迭代对于所有跳变量的选择都会收敛到平衡状态，但局部化转变会显著改变在算法有限步后到达的概率分布与目标平衡分布之间差异的渐近形状。我们认为，局部化转变之前和之后的弛豫分别受扩散和…

    Among random sampling methods, Markov Chain Monte Carlo algorithms are foremost. Using a combination of analytical and numerical approaches, we study their convergence properties towards the steady state, within a random walk Metropolis scheme. Analysing the relaxation properties of some model algorithms sufficiently simple to enable analytic progress, we show that the deviations from the target steady-state distribution can feature a localization transition as a function of the characteristic length of the attempted jumps defining the random walk. While the iteration of the Monte Carlo algorithm converges to equilibrium for all choices of jump parameters, the localization transition changes drastically the asymptotic shape of the difference between the probability distribution reached after a finite number of steps of the algorithm and the target equilibrium distribution. We argue that the relaxation before and after the localisation transition is respectively limited by diffusion and
    
[^150]: 基于内核的赌博机协同学习

    Collaborative Learning in Kernel-based Bandits for Distributed Users. (arXiv:2207.07948v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2207.07948](http://arxiv.org/abs/2207.07948)

    本文研究了分布式用户之间的基于内核的赌博机协同学习，并提出了一种使用代理高斯进程模型的算法，以降低通信开销，获得次优遗憾性能。

    

    本文研究了通过中央服务器协调分布式客户端之间的协同学习。每个客户端都希望最大化其个性化目标函数，该函数是其本地目标函数和全局目标函数的加权和。每个客户端直接访问其本地目标函数的随机赌博反馈，但只有对全局目标函数的部分视图，并对其他客户端进行信息交流以进行协同学习。我们采用基于内核的赌博机框架，其中目标函数属于再生核希尔伯特空间。我们提出了一种基于代理高斯进程（GP）模型的算法，并确定了其（多项式对数因子内）的次优遗憾性能。我们还表明，可以采用GP模型的稀疏逼近来减少客户端之间的通信开销。

    We study collaborative learning among distributed clients facilitated by a central server. Each client is interested in maximizing a personalized objective function that is a weighted sum of its local objective and a global objective. Each client has direct access to random bandit feedback on its local objective, but only has a partial view of the global objective and relies on information exchange with other clients for collaborative learning. We adopt the kernel-based bandit framework where the objective functions belong to a reproducing kernel Hilbert space. We propose an algorithm based on surrogate Gaussian process (GP) models and establish its order-optimal regret performance (up to polylogarithmic factors). We also show that the sparse approximations of the GP models can be employed to reduce the communication overhead across clients.
    
[^151]: 深度对比单类时序异常检测方法

    Deep Contrastive One-Class Time Series Anomaly Detection. (arXiv:2207.01472v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01472](http://arxiv.org/abs/2207.01472)

    本论文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，能够提高检测性能。

    

    由于时间序列数据的累积和标签的缺失，时序异常检测是一个自我监督的深度学习任务。为了克服现有方法的不足，本文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，它通过所谓的"序列对比"来提高检测性能。

    The accumulation of time-series data and the absence of labels make time-series Anomaly Detection (AD) a self-supervised deep learning task. Single-normality-assumption-based methods, which reveal only a certain aspect of the whole normality, are incapable of tasks involved with a large number of anomalies. Specifically, Contrastive Learning (CL) methods distance negative pairs, many of which consist of both normal samples, thus reducing the AD performance. Existing multi-normality-assumption-based methods are usually two-staged, firstly pre-training through certain tasks whose target may differ from AD, limiting their performance. To overcome the shortcomings, a deep Contrastive One-Class Anomaly detection method of time series (COCA) is proposed by authors, following the normality assumptions of CL and one-class classification. It treats the original and reconstructed representations as the positive pair of negative-sample-free CL, namely "sequence contrast". Next, invariance terms a
    
[^152]: 非光滑优化的随机坐标半梯度法

    Randomized Coordinate Subgradient Method for Nonsmooth Optimization. (arXiv:2206.14981v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2206.14981](http://arxiv.org/abs/2206.14981)

    本文提出了适用于非光滑优化问题的随机坐标半梯度法，该方法在每次迭代只更新一个坐标块，考虑了目标函数的线性有界次梯度假设，并在凸和非凸情况下建立了全面的收敛性分析，收敛速率为$\widetilde{\mathcal{O}}(1/\sqrt{k})$和$\mathcal{O}(1/k)$。

    

    本文提出了适用于解决非光滑凸性和非光滑非凸性（非光滑弱凸性）优化问题的“随机坐标半梯度法”（RCS）。RCS在每次迭代中随机选择一个坐标块进行更新，比更新所有坐标更实用。我们考虑了目标函数的线性有界次梯度假设，该假设比传统的Lipschitz连续性假设更为通用，以适应实际情况。此外，我们基于这种广义的Lipschitz类型假设对RCS在凸和非凸情况下进行了全面的收敛性分析。具体来说，当$f$为非光滑凸函数时，我们在期望上建立了$\widetilde{\mathcal{O}}(1/\sqrt{k})$收敛速率，以及在次优间隙方面的$\tilde o(1/\sqrt{k})$几乎肯定渐近收敛速率。如果$f$进一步满足全局二次增长条件，则显示了改进的$\mathcal{O}(1/k)$速率。

    In this work, we propose the {Randomized Coordinate Subgradient method} (RCS) for solving nonsmooth convex and nonsmooth nonconvex (nonsmooth weakly convex) optimization problems. RCS randomly selects one block coordinate to update at each iteration, making it more practical than updating all coordinates. We consider the linearly bounded subgradients assumption for the objective function, which is more general than the traditional Lipschitz continuity assumption, to account for practical scenarios. We then conduct thorough convergence analysis for RCS in both convex and nonconvex cases based on this generalized Lipschitz-type assumption. Specifically, we establish the $\widetilde{\mathcal{O}}(1/\sqrt{k})$ convergence rate in expectation and the $\tilde o(1/\sqrt{k})$ almost sure asymptotic convergence rate in terms of suboptimality gap when $f$ is nonsmooth convex. If $f$ further satisfies the global quadratic growth condition, the improved $\mathcal{O}(1/k)$ rate is shown in terms of 
    
[^153]: 将机器学习应用于自动化测试生成的融合：系统性映射研究

    The Integration of Machine Learning into Automated Test Generation: A Systematic Mapping Study. (arXiv:2206.10210v4 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2206.10210](http://arxiv.org/abs/2206.10210)

    该论文研究了将机器学习应用于自动化测试生成的方法，并总结了目前的研究进展、应用和挑战。其中监督学习和强化学习是主要的技术方法。

    

    背景：机器学习（ML）可能实现有效的自动化测试生成。目标：我们研究测试实践、研究者目标、应用的ML技术、评估和挑战等方面的兴起研究。方法：我们在102篇论文中进行了系统性映射。结果：ML生成系统、GUI、单元、性能和组合测试的输入或改进现有的生成方法。ML还用于生成测试裁决、基于属性的和期望输出oracle。监督学习，通常基于神经网络和强化学习，通常基于Q-learning，是常见的，有些出版物还采用了无监督或半监督学习。(半/无)监督方法使用传统测试指标和ML相关指标（例如准确性）进行评估，而强化学习通常使用与奖励函数相关的测试指标进行评估。结论：迄今为止的工作显示了巨大的潜力，同时还揭示了挑战并提出了新的研究方向。

    Context: Machine learning (ML) may enable effective automated test generation.  Objective: We characterize emerging research, examining testing practices, researcher goals, ML techniques applied, evaluation, and challenges.  Methods: We perform a systematic mapping on a sample of 102 publications.  Results: ML generates input for system, GUI, unit, performance, and combinatorial testing or improves the performance of existing generation methods. ML is also used to generate test verdicts, property-based, and expected output oracles. Supervised learning - often based on neural networks and reinforcement learning - often based on Q-learning - are common, and some publications also employ unsupervised or semi-supervised learning. (Semi-/Un-)Supervised approaches are evaluated using both traditional testing metrics and ML-related metrics (e.g., accuracy), while reinforcement learning is often evaluated using testing metrics tied to the reward function.  Conclusion: Work-to-date shows grea
    
[^154]: CNN中用于特征保留电路的修剪

    Pruning for Feature-Preserving Circuits in CNNs. (arXiv:2206.01627v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.01627](http://arxiv.org/abs/2206.01627)

    本论文提出了一种方法，可以从深层CNN中提取“特征保留电路”，这些是能够保留目标特征的子函数，可以用于解释卷积神经网络的图像过滤过程。同时提出了一种工具用于可视化电路图像过滤过程。

    

    深度卷积神经网络是计算机视觉问题的强力模型类，但是由于网络规模庞大，难以解释它们实现的图像过滤过程。在这项工作中，我们引入了一种从深层CNN中提取“特征保留电路”的方法，利用基于显著性的神经网络修剪方法。这些电路是网络中的模块化子函数，仅包含与目标特征相关的部分卷积核。我们比较了三种基于显著性标准提取这些稀疏电路时的有效性。此外，我们展示了如何提取"子特征"电路，它们能保留特定图像对某个特征的反应，将该特征分成更稀疏的过滤过程。我们还开发了一种可视化“电路图”工具，以可解析的格式呈现电路实现的整个图像过滤过程。

    Deep convolutional neural networks are a powerful model class for a range of computer vision problems, but it is difficult to interpret the image filtering process they implement, given their sheer size. In this work, we introduce a method for extracting 'feature-preserving circuits' from deep CNNs, leveraging methods from saliency-based neural network pruning. These circuits are modular sub-functions, embedded within the network, containing only a subset of convolutional kernels relevant to a target feature. We compare the efficacy of 3 saliency-criteria for extracting these sparse circuits. Further, we show how 'sub-feature' circuits can be extracted, that preserve a feature's responses to particular images, dividing the feature into even sparser filtering processes. We also develop a tool for visualizing 'circuit diagrams', which render the entire image filtering process implemented by circuits in a parsable format.
    
[^155]: 面对混淆因素的悲观情绪：部分可观察马尔可夫决策过程的证明有效离线强化学习

    Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13589](http://arxiv.org/abs/2205.13589)

    本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。

    

    本文研究了部分可观测马尔可夫决策过程中的离线强化学习。特别地，我们旨在从由行为策略收集的数据集中学习最优策略，该策略可能取决于潜在状态。这样的数据集在混淆意义上同时影响行动和观测值，这对于现有的离线强化学习算法来说是禁止的。为此，我们提出了通过近端因果推断构建的悲观置信区间耦合序列的代理变量悲观策略优化（P3O）算法，该算法在广义函数逼近的上下文中解决了混淆偏差和最优策略与行为策略之间的分布偏移问题。我们证明，在混淆数据集的部分覆盖假设下，P3O可以实现n^{-1/2}的收敛率。

    We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
    
[^156]: 面向混合动力车辆的电池能量消耗的不确定性预测研究

    Uncertainty-Aware Prediction of Battery Energy Consumption for Hybrid Electric Vehicles. (arXiv:2204.12825v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.12825](http://arxiv.org/abs/2204.12825)

    该论文针对驾驶员对于给定行程中能源可用性的不确定性问题，提出了一种机器学习方法来建模电池能量消耗，通过减少预测不确定性提高对车辆性能的信任并提升其可用性。

    

    车辆的可用性严重依赖于其能耗。尤其是，妨碍电动汽车（EV）、混合动力汽车（HEV）和插电混合动力汽车（PHEV）大规模采用的主要因素之一是驾驶员对于给定行程中能源可用性的不确定性。为解决此问题，我们提出了一种机器学习方法来建模电池能量消耗。通过减少预测不确定性，该方法可以提高对车辆性能的信任，从而提升其可用性。大多数相关工作侧重于影响能量消耗的电池的物理和/或化学模型。我们提出了一种基于真实世界数据集的数据驱动方法，包括电池相关属性。我们的方法显示出与传统方法相比在预测不确定性和准确性方面的改进。

    The usability of vehicles is highly dependent on their energy consumption. In particular, one of the main factors hindering the mass adoption of electric (EV), hybrid (HEV), and plug-in hybrid (PHEV) vehicles is range anxiety, which occurs when a driver is uncertain about the availability of energy for a given trip. To tackle this problem, we propose a machine learning approach for modeling the battery energy consumption. By reducing predictive uncertainty, this method can help increase trust in the vehicle's performance and thus boost its usability. Most related work focuses on physical and/or chemical models of the battery that affect the energy consumption. We propose a data-driven approach which relies on real-world datasets including battery related attributes. Our approach showed an improvement in terms of predictive uncertainty as well as in accuracy compared to traditional methods.
    
[^157]: 基于星形细胞对关键期的神经可塑性神经网络，通过现有和记忆性的大脑可塑性和突触形成实现突触竞争和强度平衡。（arXiv: 2203.11740v12 [cs.NE] UPDATED）

    Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2203.11740](http://arxiv.org/abs/2203.11740)

    该论文提出基于星形细胞作用的神经网络，通过突触的竞争和强度平衡实现现有和记忆性的大脑可塑性和突触形成，并探讨了与关键期相关的神经紊乱和负面和正面记忆的持久性对突触激活的影响。

    

    除了突触共享连接权重之外，PNN还包括突触有效范围的权重[14-25]。PNN考虑突触强度平衡在突触吞噬的动态和长度常数之和的静态中[14]，并包含了鱼群行为的先导行为。突触形成在实验和模拟中会抑制树突生成[15]。类似于Spring Boot中的强制韧性，反向回路的记忆持久度梯度也存在。相对较好和较差的梯度信息存储在类似于脑褶的记忆痕迹细胞中，在反向回路的突触形成中。争议认为人类海马神经元的再生能力是否持续到老年，并可能在后期迭代中形成新的更长的回路[17,18]。关闭关键期会导致神经紊乱在实验和模拟中[19]。考虑到负面和正面记忆的持久性，有助于更好地激活突触。

    In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
    
[^158]: 利用邻居效应：适用于异质性图的Conv-Agnostic GNNs框架。

    Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily. (arXiv:2203.11200v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.11200](http://arxiv.org/abs/2203.11200)

    该论文提出了一种基于von Neumann熵的新指标来重新审视GNNs的异质性问题，并从整个邻居可识别的角度研究跨类边的特征聚合。此外，还提出了一个Conv-Agnostic GNN框架，通过学习每个节点的邻居效应，在异质性数据集上增强了大多数GNN的性能。

    

    由于图卷积网络（GNNs）中同质性假设的存在，图节点分类任务中的一个共识是GNNs在同质性图上表现良好，但在具有许多跨类边的异质性图上可能会失败。然而，以前的跨类边观点和相关的同质比指标不能很好地解释GNNs在某些异质性数据集下的表现，这意味着并非所有跨类边对GNNs都是有害的。在本研究中，我们提出了一种基于von Neumann熵的新指标，重新审视了GNNs的异质性问题，并从整个邻居可识别的角度研究了跨类边的特征聚合。此外，我们提出了一个简单而有效的Conv-Agnostic GNN框架（CAGNNs），通过为每个节点学习邻居效应，在异质性数据集上增强了大多数GNN的性能。具体而言，我们首先将每个节点的特征分解为用于下游任务的判别特征和邻居特征，然后提出了一种邻居特征聚合模块，在CAGNNs框架中自适应地聚合邻居特征。

    Due to the homophily assumption in graph convolution networks (GNNs), a common consensus in the graph node classification task is that GNNs perform well on homophilic graphs but may fail on heterophilic graphs with many inter-class edges. However, the previous inter-class edges perspective and related homo-ratio metrics cannot well explain the GNNs performance under some heterophilic datasets, which implies that not all the inter-class edges are harmful to GNNs. In this work, we propose a new metric based on von Neumann entropy to re-examine the heterophily problem of GNNs and investigate the feature aggregation of inter-class edges from an entire neighbor identifiable perspective. Moreover, we propose a simple yet effective Conv-Agnostic GNN framework (CAGNNs) to enhance the performance of most GNNs on heterophily datasets by learning the neighbor effect for each node. Specifically, we first decouple the feature of each node into the discriminative feature for downstream tasks and the
    
[^159]: 降维与Wasserstein稳定性在核回归中的应用

    Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2203.09347](http://arxiv.org/abs/2203.09347)

    本文研究了在高维回归框架中的降维与Wasserstein稳定性应用，针对在扰动输入数据用于拟合回归函数时出现的误差推导了稳定性结果，并利用主成分分析和核回归文献中的估计，推导了两步法的收敛速度。

    

    在高维回归框架中，我们研究了一个朴素的两步法，首先降低输入变量的维数，再使用核回归来预测输出变量。为了分析由此产生的回归误差，我们推导了一个针对Wasserstein距离的新的核回归稳定性结果。这使我们能够限制当扰动输入数据用于拟合回归函数时出现的误差。我们将通用的稳定性结果应用于主成分分析(PCA)，利用已知的主成分分析和核回归文献中的估计，推导出了两步法的收敛速度。后者在半监督设置中特别有用。

    In a high-dimensional regression framework, we study consequences of the naive two-step procedure where first the dimension of the input variables is reduced and second, the reduced input variables are used to predict the output variable with kernel regression. In order to analyze the resulting regression errors, a novel stability result for kernel regression with respect to the Wasserstein distance is derived. This allows us to bound errors that occur when perturbed input data is used to fit the regression function. We apply the general stability result to principal component analysis (PCA). Exploiting known estimates from the literature on both principal component analysis and kernel regression, we deduce convergence rates for the two-step procedure. The latter turns out to be particularly useful in a semi-supervised setting.
    
[^160]: 如何利用超球嵌入实现嵌入空间的OOV检测？

    How to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?. (arXiv:2203.04450v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.04450](http://arxiv.org/abs/2203.04450)

    本论文提出了一种新型表示学习框架CIDER，可以利用超球嵌入实现外部分布（OOD）检测，该方法综合优化两个损失以促进强内部-外部类别可分性，并在基准数据集上取得了新的OOD检测性能记录。

    

    对于可靠的机器学习任务，外部分布（OOD）检测至关重要。最近在表示学习方面的进展引发了基于距离的OOD检测，其中如果测试样本与内部分布（ID）类的质心或原型相对较远，则检测到这些样本为OOD。然而，以往的方法直接采用现成的对比损失来分类ID样本，但在测试输入包含OOD样本时，这些方法不具有最优设计。在这项工作中，我们提出了CIDER，一种利用超球嵌入进行OOD检测的新型表示学习框架。CIDER同时优化两个损失以促进强ID-OOD可分性：一种分散损失，促进不同类别原型之间的大角距离，以及一种紧凑损失，鼓励样本靠近其类别原型。我们分析并建立了超球空间嵌入属性与OOD检测性能之间尚未开发的关系。在基准数据集上进行的大量实验表明，CIDER优于现有最先进方法，并实现了OOD检测性能的新记录。

    Out-of-distribution (OOD) detection is a critical task for reliable machine learning. Recent advances in representation learning give rise to distance-based OOD detection, where testing samples are detected as OOD if they are relatively far away from the centroids or prototypes of in-distribution (ID) classes. However, prior methods directly take off-the-shelf contrastive losses that suffice for classifying ID samples, but are not optimally designed when test inputs contain OOD samples. In this work, we propose CIDER, a novel representation learning framework that exploits hyperspherical embeddings for OOD detection. CIDER jointly optimizes two losses to promote strong ID-OOD separability: a dispersion loss that promotes large angular distances among different class prototypes, and a compactness loss that encourages samples to be close to their class prototypes. We analyze and establish the unexplored relationship between OOD detection performance and the embedding properties in the hy
    
[^161]: 序列实验的反事实推断

    Counterfactual inference for sequential experiments. (arXiv:2202.06891v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.06891](http://arxiv.org/abs/2202.06891)

    本文针对序列实验的反事实推断问题，提出了一个潜在因子模型，使用非参数方法对反事实均值进行估计，并建立了误差界限。

    

    我们考虑针对连续设计实验进行的事后统计推断，在此实验中，多个单位在多个时间点上分配治疗，并使用随时间而适应的治疗策略。我们的目标是在对适应性治疗策略做出最少的假设的情况下，为最小可能规模的反事实均值提供推断保证，即在每个单位和每个时间下，针对不同治疗的平均结果。在没有对反事实均值进行任何结构性假设的情况下，这项具有挑战性的任务是不可行的，因为未知变量比观察到的数据点还多。为了取得进展，我们引入了一个潜在因子模型用于反事实均值上，该模型作为非参数形式的非线性混合效应模型和以前工作中考虑的双线性潜在因子模型的推广。我们使用非参数方法进行估计，即最近邻的变体，并为每个单位和每个时间的反事实均值建立了非渐进高概率误差界限。

    We consider after-study statistical inference for sequentially designed experiments wherein multiple units are assigned treatments for multiple time points using treatment policies that adapt over time. Our goal is to provide inference guarantees for the counterfactual mean at the smallest possible scale -- mean outcome under different treatments for each unit and each time -- with minimal assumptions on the adaptive treatment policy. Without any structural assumptions on the counterfactual means, this challenging task is infeasible due to more unknowns than observed data points. To make progress, we introduce a latent factor model over the counterfactual means that serves as a non-parametric generalization of the non-linear mixed effects model and the bilinear latent factor model considered in prior works. For estimation, we use a non-parametric method, namely a variant of nearest neighbors, and establish a non-asymptotic high probability error bound for the counterfactual mean for ea
    
[^162]: 善意过拟合的隐性偏差

    The Implicit Bias of Benign Overfitting. (arXiv:2201.11489v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11489](http://arxiv.org/abs/2201.11489)

    本文针对善意过拟合现象，提供了非线性回归的最小范数插值预测器在一般情况下偏向于不一致解的证明，从而说明善意过拟合不会发生，同时展示了如何将其扩展到标准线性回归以外。

    

    过拟合现象中的善意过拟合，指的是分类器完美地拟合了带有噪声的训练数据，同时达到接近最优的期望损失。近年来，这一现象受到了广泛关注，但除了线性回归设置外，仍然没有得到充分理解。在本文中，我们针对回归和分类任务，提供了关于何时可以或不能期望善意过拟合发生的若干新结果。我们考虑了一个典型且相当通用的线性分类器善意过拟合数据模型，其中将某个固定维度 $k$ 的任意输入分布与高维分布连接在一起。对于非必须经过良好规定的线性回归，我们证明最小范数插值预测器（标准训练方法所收敛到的）在一般情况下是偏向于不一致的解的，因此通常不会发生善意过拟合。此外，我们展示了如何通过一种方法将其扩展到标准线性回归以外。

    The phenomenon of benign overfitting, where a predictor perfectly fits noisy training data while attaining near-optimal expected loss, has received much attention in recent years, but still remains not fully understood beyond well-specified linear regression setups. In this paper, we provide several new results on when one can or cannot expect benign overfitting to occur, for both regression and classification tasks. We consider a prototypical and rather generic data model for benign overfitting of linear predictors, where an arbitrary input distribution of some fixed dimension $k$ is concatenated with a high-dimensional distribution. For linear regression which is not necessarily well-specified, we show that the minimum-norm interpolating predictor (that standard training methods converge to) is biased towards an inconsistent solution in general, hence benign overfitting will generally not occur. Moreover, we show how this can be extended beyond standard linear regression, by an argum
    
[^163]: GNN-Geo: 一种基于图神经网络的细粒度IP地理定位框架

    GNN-Geo: A Graph Neural Network-based Fine-grained IP geolocation Framework. (arXiv:2112.10767v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.10767](http://arxiv.org/abs/2112.10767)

    本文提出了一种基于图神经网络的 IP 地理定位框架 GNN-Geo，它通过对连接进行建模来细化节点嵌入，提高了准确性。

    

    基于规则的细粒度IP地理定位方法在不遵循假设规则的计算机网络中很难概括。最近，深度学习方法，如多层感知器（MLP），被尝试用于增加概括能力。然而，MLP 不适合于处理类似于网络的图结构数据。MLP 把 IP 地址视为孤立的实例，忽略连接信息，限制了地理定位的准确性。本文研究如何使用一种新兴的图深度学习方法——图神经网络（GNN）来增加概括能力。首先，将 IP 地理定位重新构造为属性图节点回归问题。然后，提出了一种基于 GNN 的 IP 地理定位框架，称为 GNN-Geo。GNN-Geo 由预处理器、编码器、消息传递（MP）层和解码器组成。预处理器和编码器将测量数据转换为初始节点嵌入。MP 层通过对连接进行建模来细化初始节点嵌入，从而提高了准确性。

    Rule-based fine-grained IP geolocation methods are hard to generalize in computer networks which do not follow hypothetical rules. Recently, deep learning methods, like multi-layer perceptron (MLP), are tried to increase generalization capabilities. However, MLP is not so suitable for graph-structured data like networks. MLP treats IP addresses as isolated instances and ignores the connection information, which limits geolocation accuracy. In this work, we research how to increase the generalization capability with an emerging graph deep learning method -- Graph Neural Network (GNN). First, IP geolocation is re-formulated as an attributed graph node regression problem. Then, we propose a GNN-based IP geolocation framework named GNN-Geo. GNN-Geo consists of a preprocessor, an encoder, messaging passing (MP) layers and a decoder. The preprocessor and encoder transform measurement data into the initial node embeddings. MP layers refine the initial node embeddings by modeling the connectio
    
[^164]: 遥感半监督对比学习：鉴定南美南部安第斯古城化的方法

    Semi-Supervised Contrastive Learning for Remote Sensing: Identifying Ancient Urbanization in the South Central Andes. (arXiv:2112.06437v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.06437](http://arxiv.org/abs/2112.06437)

    本文提出了一种利用遥感数据，在半监督对比学习框架下，改善南美南部安第斯地区古城化鉴定的方法。通过结合标注和未标注样本，能够有效地学习高度不平衡的数据集，从而极大地缩短对偏远地区考古遗存鉴定的工时和费用。

    

    考古学在采样和比例表示上存在根本问题，建立定居模式的从地区到区域的视图通常需系统步行勘测。而卫星和航空影像的系统手动勘测，在跨地区尺度下可以呈现历史遗存现象的分布视图，但这种粗暴方法却往往耗时、耗力且对敏感度和特异度存在差异。自监督学习方法的发展提供了一种使用未标注卫星和历史空中影像定位考古遗存的可扩展学习方案。然而，考古遗存相对于景观整体而言极为微小，目前的对比监督学习方法在高度不平衡数据集上表现较差。因此，本文提出一种半监督对比学习框架，使用遥感数据改善对南美南部安第斯古城化的鉴定。该方法通过标注和未标注样本的结合，能够有效地学习高度不平衡的数据集。实验结果表明，该方法达到了最先进的性能水平，并可极大地缩短对偏远地区考古遗存鉴定的工时和费用。

    Archaeology has long faced fundamental issues of sampling and scalar representation. Traditionally, the local-to-regional-scale views of settlement patterns are produced through systematic pedestrian surveys. Recently, systematic manual survey of satellite and aerial imagery has enabled continuous distributional views of archaeological phenomena at interregional scales. However, such 'brute force' manual imagery survey methods are both time- and labor-intensive, as well as prone to inter-observer differences in sensitivity and specificity. The development of self-supervised learning methods offers a scalable learning scheme for locating archaeological features using unlabeled satellite and historical aerial images. However, archaeological features are generally only visible in a very small proportion relative to the landscape, while the modern contrastive-supervised learning approach typically yields an inferior performance on highly imbalanced datasets. In this work, we propose a fram
    
[^165]: TraVLR: 现在你看到它了，现在你没看到它了！一个用于评估视觉语言推理的双模数据集。

    TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguistic Reasoning. (arXiv:2111.10756v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.10756](http://arxiv.org/abs/2111.10756)

    提出了TraVLR数据集，可以用于评估V+L模型的表现，数据集合成，包括四个V+L推理任务，同时使用双模式冗余编码来评估其泛化能力。

    

    已经开发了许多视觉语言（V+L）表示学习方法，但现有的数据集不能充分评估它们在统一空间中表示视觉和语言概念的程度。我们针对V+L模型提出了几种新颖的评估设置，包括跨模态传递。此外，现有的V+L基准经常报告整个数据集的全局准确性得分，这使得难以确定模型失败和成功的具体推理任务。我们提出了TraVLR，这是一个合成数据集，包括四个V+L推理任务。TraVLR的合成性质使我们能够沿任务相关维度限制其训练和测试分布，从而评估超出分布的泛化。TraVLR中的每个示例都以两种模态冗余编码场景，使得在训练或测试期间可以删除或添加其中的任一模态而不会失去相关信息。我们比较了四个最先进的V+L模型的性能。

    Numerous visio-linguistic (V+L) representation learning methods have been developed, yet existing datasets do not adequately evaluate the extent to which they represent visual and linguistic concepts in a unified space. We propose several novel evaluation settings for V+L models, including cross-modal transfer. Furthermore, existing V+L benchmarks often report global accuracy scores on the entire dataset, making it difficult to pinpoint the specific reasoning tasks that models fail and succeed at. We present TraVLR, a synthetic dataset comprising four V+L reasoning tasks. TraVLR's synthetic nature allows us to constrain its training and testing distributions along task-relevant dimensions, enabling the evaluation of out-of-distribution generalisation. Each example in TraVLR redundantly encodes the scene in two modalities, allowing either to be dropped or added during training or testing without losing relevant information. We compare the performance of four state-of-the-art V+L models,
    
[^166]: 两支队伍零和博弈中纳什均衡的收敛性

    Towards convergence to Nash equilibria in two-team zero-sum games. (arXiv:2111.04178v4 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2111.04178](http://arxiv.org/abs/2111.04178)

    研究了两支团队博弈的纳什均衡（NE）的解，证明了计算这类博弈的NE是困难的，提出了一组简单但非平凡的游戏基准用于检验在线学习算法在具有全信息反馈的游戏中的能力。

    

    机器学习在两支团队电子竞技中的应用和多智能体生成对抗网络的出色表现提出了有关两支团队博弈优化的重要且被忽视的理论问题。我们重点研究纳什均衡（NE）的解释概念。首先我们证明，对于这一类博弈，计算NE在复杂度类 ${\mathrm{CLS}}$ 中是 $\textit{hard}$。为了进一步检验在线学习算法在具有全信息反馈的游戏中的能力，我们提出了一组简单但非平凡的这样的游戏基准。这些游戏不具备证明相关算法收敛性的性质。我们使用动力系统的视角来证明...

    Contemporary applications of machine learning in two-team e-sports and the superior expressivity of multi-agent generative adversarial networks raise important and overlooked theoretical questions regarding optimization in two-team games. Formally, two-team zero-sum games are defined as multi-player games where players are split into two competing sets of agents, each experiencing a utility identical to that of their teammates and opposite to that of the opposing team. We focus on the solution concept of Nash equilibria (NE). We first show that computing NE for this class of games is $\textit{hard}$ for the complexity class ${\mathrm{CLS}}$. To further examine the capabilities of online learning algorithms in games with full-information feedback, we propose a benchmark of a simple -- yet nontrivial -- family of such games. These games do not enjoy the properties used to prove convergence for relevant algorithms. In particular, we use a dynamical systems perspective to demonstrate that 
    
[^167]: RL4RS：一种基于强化学习的推荐系统的真实世界数据集

    RL4RS: A Real-World Dataset for Reinforcement Learning based Recommender System. (arXiv:2110.11073v5 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2110.11073](http://arxiv.org/abs/2110.11073)

    RL4RS是一个新的基于强化学习的推荐系统数据集，为此提供了一种替代使用人造数据集和半仿真推荐系统数据集的方法，并提出了新的系统评估框架。

    

    基于强化学习的推荐系统目标在于从一批收集的数据中学习到一个良好的策略，将推荐问题转化为多步决策任务。然而，现有的基于强化学习的推荐系统研究通常存在巨大的现实差距。本文首次介绍了一个开源的真实世界数据集——RL4RS，旨在取代之前RL-based RS领域由于资源限制而使用的人工和半仿真RS数据集。与学术研究不同的是，RL-based RS面临着部署前需要进行良好验证的困难。我们尝试提出一种新的系统评估框架，包括环境模拟评估、环境评估、反事实策略评估以及建立于测试集的环境评估。综上所述，本文介绍了一个新的资源RL4RS（用于推荐系统的强化学习），并对现实差距等特殊问题进行了思考，并提供了两个真实世界数据集。

    Reinforcement learning based recommender systems (RL-based RS) aim at learning a good policy from a batch of collected data, by casting recommendations to multi-step decision-making tasks. However, current RL-based RS research commonly has a large reality gap. In this paper, we introduce the first open-source real-world dataset, RL4RS, hoping to replace the artificial datasets and semi-simulated RS datasets previous studies used due to the resource limitation of the RL-based RS domain. Unlike academic RL research, RL-based RS suffers from the difficulties of being well-validated before deployment. We attempt to propose a new systematic evaluation framework, including evaluation of environment simulation, evaluation on environments, counterfactual policy evaluation, and evaluation on environments built from test set. In summary, the RL4RS (Reinforcement Learning for Recommender Systems), a new resource with special concerns on the reality gaps, contains two real-world datasets, data und
    
[^168]: ML4C: 通过潜在邻域观察因果关系

    ML4C: Seeing Causality Through Latent Vicinity. (arXiv:2110.00637v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.00637](http://arxiv.org/abs/2110.00637)

    本文提出了一种监督式因果学习方法ML4C，采用了新颖的学习目标，用于分类未屏蔽三元组是否是v-结构，并构建因果关系。

    

    监督式因果学习（SCL）旨在通过访问与地面真实因果关系相关的先前看到的数据集，从观察数据中学习因果关系。本文提出了首次尝试解决一个基本问题：监督的好处是什么，以及如何受益？我们提出了一个面向因果学习的双阶段范例，通过显式考虑结构可识别性来解决SCL问题。按照这个范例，我们针对离散数据的SCL问题提出了ML4C。ML4C的核心是一个二元分类器，其新颖的学习目标是分类未屏蔽三元组（UT）是否是v-结构。具体而言，从提供了相应骨架的输入数据集开始，ML4C在将UT分类为v-结构后对其进行取向。这些v-结构一起用于构建最终输出。为解决基本问题，我们提出了一种学习目标，称为潜在邻域识别，通过对UT进行分类，最终获得因果关系。

    Supervised Causal Learning (SCL) aims to learn causal relations from observational data by accessing previously seen datasets associated with ground truth causal relations. This paper presents a first attempt at addressing a fundamental question: What are the benefits from supervision and how does it benefit? Starting from seeing that SCL is not better than random guessing if the learning target is non-identifiable a priori, we propose a two-phase paradigm for SCL by explicitly considering structure identifiability. Following this paradigm, we tackle the problem of SCL on discrete data and propose ML4C. The core of ML4C is a binary classifier with a novel learning target: it classifies whether an Unshielded Triple (UT) is a v-structure or not. Specifically, starting from an input dataset with the corresponding skeleton provided, ML4C orients each UT once it is classified as a v-structure. These v-structures are together used to construct the final output. To address the fundamental que
    
[^169]: 基于真实Shamir密钥分享的安全PAC Bayesian回归

    Secure PAC Bayesian Regression via Real Shamir Secret Sharing. (arXiv:2109.11200v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.11200](http://arxiv.org/abs/2109.11200)

    该论文提出了一种基于真实Shamir密钥分享的安全PAC Bayesian回归协议，通过解决多方计算和数据共享问题，实现在不违反数据隐私的情况下安全地学习线性模型参数。

    

    系统识别和机器学习的常用方法是利用训练数据生成模型，以尽可能准确地预测测试数据实例。然而，对数据隐私的担忧日益增加，但并非总是得到解决。我们提出了一种安全协议，用于学习一个线性模型，依靠最近描述的技术称为实数秘密共享。我们从PAC Bayesian界开始，并推导出一个闭合形式的模型参数，该参数依赖于数据和PAC Bayesian界给出的先验。要获得模型参数，需要解决一个线性系统。然而，我们考虑到多个方持有不同的数据实例，并且不愿意放弃数据的隐私。因此，我们建议使用实数秘密共享和多方计算来共享数据并在不违反数据隐私的情况下安全地解决线性回归。我们提出了两种方法；一个安全

    A common approach of system identification and machine learning is to generate a model by using training data to predict the test data instances as accurate as possible. Nonetheless, concerns about data privacy are increasingly raised, but not always addressed. We present a secure protocol for learning a linear model relying on recently described technique called real number secret sharing. We take as our starting point the PAC Bayesian bounds and deduce a closed form for the model parameters which depends on the data and the prior from the PAC Bayesian bounds. To obtain the model parameters one needs to solve a linear system. However, we consider the situation where several parties hold different data instances and they are not willing to give up the privacy of the data. Hence, we suggest to use real number secret sharing and multiparty computation to share the data and solve the linear regression in a secure way without violating the privacy of data. We suggest two methods; a secure 
    
[^170]: FedChain：用于联邦学习中近似最优通信成本的链接算法

    FedChain: Chained Algorithms for Near-Optimal Communication Cost in Federated Learning. (arXiv:2108.06869v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.06869](http://arxiv.org/abs/2108.06869)

    FedChain是一种算法框架，结合了本地方法和全局方法的优点，实现了在通信回合数方面快速收敛，并利用客户之间的相似性。

    

    联邦学习旨在最小化在分布在许多客户端上的异构数据上训练模型的通信复杂度。一种常用的方法是本地方法，其中客户端在与服务器通信之前对本地数据进行多个优化步骤（例如，FedAvg）。本地方法可以利用客户端数据的相似性。然而，在现有的分析中，这是以依赖于通信回合数R的收敛速度缓慢为代价的。另一方面，全局方法，其中客户端仅在每个回合返回梯度向量（例如，SGD），在R方面的快速收敛性方面更快，但即使客户端是同构的，也无法利用客户端之间的相似性。我们提出FedChain，一种算法框架，结合了本地方法和全局方法的优点，实现了在R方面的快速收敛，并利用客户之间的相似性。使用FedChain，我们实例化算法，改善了几个标准FL基准测试的已知结果。具体而言，我们展示了FedChain在客户端异构的情况下实现了接近最优的通信复杂度，并且当客户端是同构的时仍然保持快速收敛率。

    Federated learning (FL) aims to minimize the communication complexity of training a model over heterogeneous data distributed across many clients. A common approach is local methods, where clients take multiple optimization steps over local data before communicating with the server (e.g., FedAvg). Local methods can exploit similarity between clients' data. However, in existing analyses, this comes at the cost of slow convergence in terms of the dependence on the number of communication rounds R. On the other hand, global methods, where clients simply return a gradient vector in each round (e.g., SGD), converge faster in terms of R but fail to exploit the similarity between clients even when clients are homogeneous. We propose FedChain, an algorithmic framework that combines the strengths of local methods and global methods to achieve fast convergence in terms of R while leveraging the similarity between clients. Using FedChain, we instantiate algorithms that improve upon previously kno
    
[^171]: 差分评论家GAN:通过偏好提示生成用户需求数据

    Differential-Critic GAN: Generating What You Want by a Cue of Preferences. (arXiv:2107.06700v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.06700](http://arxiv.org/abs/2107.06700)

    本文提出了一种新的生成对抗网络——差分评论家GAN，它可以在只有部分数据集包含所需特性的情况下，利用本地信息和成对偏好生成满足用户期望的所需数据分布。

    

    本文提出了差分评论家生成对抗网络（DiCGAN），用于学习用户所需数据的分布。当只有部分数据集具有所需特性时，DiCGAN可以生成满足用户期望的所需数据，并帮助设计具有所需属性的生物产品。现有方法首先选择所需样本，然后在选定的样本上训练常规GAN以获取用户所需数据分布。然而，所需数据的选择依赖于全局知识和对整个数据集的监督。DiCGAN引入了差分评论家，该评论家从成对偏好中学习，这是本地知识，并且可以定义在部分训练数据上。评论家通过在Wasserstein GAN的评论家上定义额外的排名损失来构建。它赋予每对样本间评论家值的差异以用户偏好，引导所需数据的生成，而不是简单的克隆全局统计信息。

    This paper proposes Differential-Critic Generative Adversarial Network (DiCGAN) to learn the distribution of user-desired data when only partial instead of the entire dataset possesses the desired property. DiCGAN generates desired data that meets the user's expectations and can assist in designing biological products with desired properties. Existing approaches select the desired samples first and train regular GANs on the selected samples to derive the user-desired data distribution. However, the selection of the desired data relies on global knowledge and supervision over the entire dataset. DiCGAN introduces a differential critic that learns from pairwise preferences, which are local knowledge and can be defined on a part of training data. The critic is built by defining an additional ranking loss over the Wasserstein GAN's critic. It endows the difference of critic values between each pair of samples with the user preference and guides the generation of the desired data instead of
    
[^172]: 来自自激和相互激发时间序列的因果图发现

    Causal Graph Discovery from Self and Mutually Exciting Time Series. (arXiv:2106.02600v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.02600](http://arxiv.org/abs/2106.02600)

    该论文提出了一个新的因果图发现方法，结合了广义线性结构因果模型和自适应正则化方法，通过解决凸优化问题来恢复因果DAGs，并建立了置信区间以量化不确定性，经过实验证明其在恢复高度可解释的因果DAGs上表现出竞争性能。

    

    我们提出了一个广义线性结构因果模型，并结合一种新颖的数据自适应线性正则化方法，从时间序列中恢复因果有向无环图(DAGs)。通过利用最近开发的随机单调变分不等式(VI)形式，我们将因果发现问题转化为一般的凸优化问题。此外，我们通过解决线性规划问题，建立了一种非渐进性的恢复保证和可量化的不确定性，以确定一系列非线性单调连接函数的置信区间。我们通过广泛的数值实验验证了理论结果的有效性和方法的竞争性能。最重要的是，我们展示了我们的方法在恢复高度可解释的因果DAGs上的有效性，尤其是在Sepsis相关紊乱(SADs)方面，同时实现了与强大的“黑匣子”模型（如XGBoost）相当的预测性能。因此，我们提出的方法在未来进行条件随机场建模和因果推断中的应用具有重要意义。

    We present a generalized linear structural causal model, coupled with a novel data-adaptive linear regularization, to recover causal directed acyclic graphs (DAGs) from time series. By leveraging a recently developed stochastic monotone Variational Inequality (VI) formulation, we cast the causal discovery problem as a general convex optimization. Furthermore, we develop a non-asymptotic recovery guarantee and quantifiable uncertainty by solving a linear program to establish confidence intervals for a wide range of non-linear monotone link functions. We validate our theoretical results and show the competitive performance of our method via extensive numerical experiments. Most importantly, we demonstrate the effectiveness of our approach in recovering highly interpretable causal DAGs over Sepsis Associated Derangements (SADs) while achieving comparable prediction performance to powerful ``black-box'' models such as XGBoost. Thus, the future adoption of our proposed method to conduct con
    
[^173]: 基于三维解剖脑部 MRI 的 CNN 的基准测试：结构、数据增强和深度集成学习

    Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning. (arXiv:2106.01132v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.01132](http://arxiv.org/abs/2106.01132)

    该研究提出并实现了一个基于三维解剖脑部 MRI 的CNN模型的全面基准测试，包括结构、数据增强和深度集成等方面，基于大型多站点的脑部解剖MRI数据集，该测试为三维脑部解剖MRI数据分析领域的进一步研究提供了参考。

    

    深度学习（DL）和特别是CNN模型已成为广泛应用于各种视觉任务的事实标准，优于传统的机器学习（ML）方法。因此，它们引起了神经成像领域特别是成型预测或计算机辅助诊断的广泛关注。然而，目前大多数研究往往涉及小型单一站点队列，以及特定的预处理流程和自定义CNN结构，这使得它们难以进行比较。我们提出了最近的最新技术（SOTA）3D CNN的全面基准测试，还评估了数据增强和深度集成学习的好处，以及在基于体素的形态学（VBM）预处理和准原始图像上的表现。实验是在包含N = 10k扫描的大型多站点3D脑部解剖MRI数据集上进行的，涉及3项挑战性任务：年龄预测，性别分类和精神分裂症的诊断。我们发现所有模型都可以在VBM预处理方面提供显着更好的预测，而不是在准原始图像上，这凸显了预处理的重要性。此外，数据增强可以提高所有模型的性能。我们提出的由同一结构的6个不同模型组成的深度集成在所有任务上都取得了最佳结果，优于所有个体模型和先前的SOTA方法。我们的基准旨在为未来的三维脑部解剖MRI数据分析研究提供参考，并促进该领域的进一步研究。

    Deep Learning (DL) and specifically CNN models have become a de facto method for a wide range of vision tasks, outperforming traditional machine learning (ML) methods. Consequently, they drew a lot of attention in the neuroimaging field in particular for phenotype prediction or computer-aided diagnosis. However, most of the current studies often deal with small single-site cohorts, along with a specific pre-processing pipeline and custom CNN architectures, which make them difficult to compare to. We propose an extensive benchmark of recent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data augmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM) pre-processing and quasi-raw images. Experiments were conducted on a large multi-site 3D brain anatomical MRI data-set comprising N=10k scans on 3 challenging tasks: age prediction, sex classification, and schizophrenia diagnosis. We found that all models provide significantly better predictions with VBM 
    
[^174]: 基于平衡熵学习准则的贝叶斯神经网络主动学习

    Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle. (arXiv:2105.14559v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.14559](http://arxiv.org/abs/2105.14559)

    该论文提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），通过捕捉潜在softmax概率和标签变量的信息平衡，实现了基于平衡熵学习准则的贝叶斯神经网络主动学习，并在多个基准数据集上证明了该方法的有效性和较高的计算效率。

    

    在许多具有有限预算的机器学习应用中，获取标记数据是具有挑战性的。主动学习提供了一种选择最具信息量的数据点并通过减少标记成本来提高数据效率的过程。信息最大化学习原则（例如 BALD）最大化相互信息已经在各种主动学习应用中成功地广泛采用。然而，这种特定于池的目标本质上引入了冗余选择，并进一步需要高计算成本进行批处理选择。在本文中，我们设计并提出了一种新的不确定性测量方法Balanced Entropy Acquisition（BalEntAcq），它捕捉了潜在softmax概率和标签变量的不确定性之间的信息平衡。为此，我们通过Beta分布逼近每个边缘分布。Beta逼近使我们能够将BalEntAcq制定为增强熵和边缘联合熵之间的比率。所得到的BalEntAcq的闭式表达式可以高效地计算并与其他最先进的主动学习方法进行比较。我们在包括图像分类，目标检测和语义分割任务在内的几个基准数据集上展示了我们方法的有效性。我们提出的方法在显著降低计算成本的同时，达到了与现有方法相当的性能。

    Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expr
    
[^175]: CogDL：图深度学习的综合库

    CogDL: A Comprehensive Library for Graph Deep Learning. (arXiv:2103.00959v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2103.00959](http://arxiv.org/abs/2103.00959)

    CogDL是一个图深度学习的综合库，针对图数据的稀疏性和复杂任务提供了统一的训练和评估设计和多种训练技术，包括高效和可扩展的实现和实用工具，是进行图深度学习的理想选择。

    

    近年来，图神经网络(GNNs)在图学习社区中引起了极大的关注，并在各个领域的实际应用中被广泛采用，比如社交网络和生物图。然而，图深度学习的研究和应用存在一些新的挑战，包括图数据稀疏性、GNN复杂的训练和图任务的非标准评估。为了解决这些问题，我们提出了CogDL，一个图深度学习的综合库，允许研究人员和实践者轻松高效地进行实验、比较方法和构建应用。在CogDL中，我们提出了对于各种图任务的GNN模型训练和评估的统一设计，使其在现有的图学习库中独树一帜。通过使用这个统一的训练器，CogDL可以优化GNN训练循环，采用混合精度训练等多种训练技术。此外，我们针对各种GNN模型开发了高效且可扩展的实现，包括经典模型和最新的模型。此外，CogDL提供了一系列的实用工具和工具，支持图深度学习的开发，如数据加载器和评估指标。我们还通过在流行图数据集上的广泛实验证明了CogDL的有效性，并为各种图任务提供了全面的基准。

    Graph neural networks (GNNs) have attracted tremendous attention from the graph learning community in recent years. It has been widely adopted in various real-world applications from diverse domains, such as social networks and biological graphs. The research and applications of graph deep learning present new challenges, including the sparse nature of graph data, complicated training of GNNs, and non-standard evaluation of graph tasks. To tackle the issues, we present CogDL, a comprehensive library for graph deep learning that allows researchers and practitioners to conduct experiments, compare methods, and build applications with ease and efficiency. In CogDL, we propose a unified design for the training and evaluation of GNN models for various graph tasks, making it unique among existing graph learning libraries. By utilizing this unified trainer, CogDL can optimize the GNN training loop with several training techniques, such as mixed precision training. Moreover, we develop efficie
    
[^176]: 灵活的模型聚合方法用于分位数回归

    Flexible Model Aggregation for Quantile Regression. (arXiv:2103.00083v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2103.00083](http://arxiv.org/abs/2103.00083)

    本文研究聚合条件分位数模型的方法，提高分位数回归的准确性和鲁棒性，并提出了能够应用于现代深度学习工具包的多种模型，对许多从业者具有广泛的适用性。

    

    分位数回归是一种用于统计学习的基本问题，旨在量化预测的不确定性，或在不过度简化的情况下对多样化人群建模。本文研究聚合任意数量的条件分位数模型的方法，以提高准确性和鲁棒性，并考虑权重集成，权重不仅可以变化于单个模型，还可以变化于分位数水平和特征值。本文所考虑的所有模型均可使用现代深度学习工具包拟合，因此对许多从业者具有广泛的适用性（从实现的角度来看）。

    Quantile regression is a fundamental problem in statistical learning motivated by a need to quantify uncertainty in predictions, or to model a diverse population without being overly reductive. For instance, epidemiological forecasts, cost estimates, and revenue predictions all benefit from being able to quantify the range of possible values accurately. As such, many models have been developed for this problem over many years of research in statistics, machine learning, and related fields. Rather than proposing yet another (new) algorithm for quantile regression we adopt a meta viewpoint: we investigate methods for aggregating any number of conditional quantile models, in order to improve accuracy and robustness. We consider weighted ensembles where weights may vary over not only individual models, but also over quantile levels, and feature values. All of the models we consider in this paper can be fit using modern deep learning toolkits, and hence are widely accessible (from an implem
    
[^177]: AdvSim: 生成自动驾驶车辆的安全关键场景

    AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2101.06549](http://arxiv.org/abs/2101.06549)

    提出了AdvSim框架，利用对抗性方法生成自动驾驶车辆的安全关键场景，具有可扩展性，适用于任何基于激光雷达的自主系统，可以识别各种具有语义意义的安全关键场景。

    

    随着自动驾驶系统的不断提升，模拟可能出现自主堆栈失败的情况变得越来越重要。传统上，这些场景只为规划模块生成了一些相对较少的场景，其输入为地面真实车辆状态。这不具有可扩展性，并且无法识别所有可能的自主失败，例如由于遮挡导致的感知故障。本文提出了AdvSim，一个对于任何基于激光雷达的自主系统生成安全关键场景的对抗性框架。给定一个初始交通场景，AdvSim以物理可行的方式修改参与者的轨迹并更新激光雷达传感器数据以匹配受扰动的世界。重要的是，通过直接从传感器数据进行模拟，我们获得安全关键场景，适用于完整的自主堆栈。我们的实验表明，我们的方法具有普适性，可以识别出大量具有语义意义的安全关键场景，适用于现代自动驾驶系统的各种情况。

    As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving sy
    
[^178]: 高斯混合模型中的局部极小结构

    Local Minima Structures in Gaussian Mixture Models. (arXiv:2009.13040v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2009.13040](http://arxiv.org/abs/2009.13040)

    研究了高斯混合模型中的负对数似然函数的局部极小值结构，发现它们都共享一种常见结构而部分确定了真正的位置混合物的簇中心。这些结果适用于真实混合组分满足某种分离条件的情况，也适用于成分数量过多或过少的情况。

    

    我们在人口极限的情况下调查了混合成分模型（GMM）的负对数似然函数的情况，并探讨了具有一般成分数量的GMM的负对数似然函数的局部极小值结构。由于目标函数是非凸的，即使对于分离良好的混合模型，也可能存在不是全局最优的多个局部极小值。我们的研究揭示了所有局部极小值都共享一种常见结构，该结构部分确定了真正的位置混合物（即高斯成分的均值）的簇中心。具体而言，每个局部极小值可以表示为两种类型子配置的非重叠组合：将单个均值估计与多个高斯分量拟合或将多个估计拟合到单个真实分量。这些结果适用于真实混合组分满足某种分离条件的情况，并且在成分数量过多或过少的情况下也是有效的。我们还针对一维高斯混合物的设置提供了更精细的分析，通过结构计数论证导出了这些非全局最小值的精确数量和它们对应的配置。

    We investigate the landscape of the negative log-likelihood function of Gaussian Mixture Models (GMMs) with a general number of components in the population limit. As the objective function is non-convex, there can be multiple local minima that are not globally optimal, even for well-separated mixture models. Our study reveals that all local minima share a common structure that partially identifies the cluster centers (i.e., means of the Gaussian components) of the true location mixture. Specifically, each local minimum can be represented as a non-overlapping combination of two types of sub-configurations: fitting a single mean estimate to multiple Gaussian components or fitting multiple estimates to a single true component. These results apply to settings where the true mixture components satisfy a certain separation condition, and are valid even when the number of components is overor under-specified. We also present a more fine-grained analysis for the setting of one-dimensional G
    
[^179]: 用生成模型突破模型驱动强化学习中的样本大小障碍

    Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.12900](http://arxiv.org/abs/2005.12900)

    本文提出了两个算法——扰动模型驱动算法和保守模型驱动算法，通过生成模型在较小的样本大小下证明了它们的极小化最大算法优化性能。

    

    本论文着眼于在有生成模型（或模拟器）的情况下，增强学习的样本效率。首先，考虑带有折扣的无限时间步长马尔科夫决策过程（MDP），其状态空间为$\mathcal{S}$，动作空间为$\mathcal{A}$。尽管有许多先前的研究在解决这个问题，但是在样本复杂度和统计精度之间权衡的完整图景尚未确定。特别是，所有的先前结果都受到严重的样本大小障碍，因为它们声称的统计保证仅在样本大小超过至少$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$时才成立。本文通过证明两个算法——扰动模型驱动算法和保守模型驱动算法——在样本大小超过$\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$的情况下就能证明它们的极小化最大算法优化性能（几乎符合一些对数因子）。除了无限时间步长M解决方案之外，我们还考虑了有限样本和近似价值迭代问题，以在实践中实现算法的应用。

    This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\mathcal{S}$ and action space $\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$ (modulo some log factor). Moving beyond infinite-
    
[^180]: 通过语言基础实现零样本组合策略学习

    Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2004.07200](http://arxiv.org/abs/2004.07200)

    本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。

    

    尽管强化学习（RL）和模仿学习（IL）在最近都有了突破，但现有算法无法在训练环境之外进行推广。实际上，人类能够通过利用先前关于世界（如语言描述）的知识来快速适应新任务。为了促进带有领域自适应的语言引导代理的研究，我们提出了一项新的零样本组合策略学习任务，其中环境被描述为不同属性的组合。由于没有公共环境支持这项研究，我们介绍了一个新的研究平台BabyAI++，其中环境的动力学与视觉外观解耦。在每个回合中，BabyAI++提供了各种视觉动力学组合以及相应的描述性文本。为了评估所学代理的自适应能力，一组视觉动力学配对被保留在BabyAI++上进行测试。不出所料，我们发现当前的语言引导RL/IL方法无法解决这个零样本组合策略学习任务。因此，我们提出了一种新的语言引导策略学习算法，通过将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上。为了实现这一目标，我们引入了一种新的语言基础模块，将符号属性表示和自然语言输入集成到策略网络中。我们的实验表明，我们提出的算法在零样本组合策略学习任务上显著优于现有的RL/IL算法。

    Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL 
    
[^181]: 利用未标记数据扩展类别的开放集学习（Open-LACU）

    Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2002.01368](http://arxiv.org/abs/2002.01368)

    Open-LACU是一种新的开放式学习策略，它可以将分类器推广到观察到的和未观察到的新颖类别之间，并通过定义不同的背景和未知类别来提高训练成本效益性，确保在存在未观察到的新颖类别时进行安全分类。

    

    对于半监督学习（SSL）和开放式识别（OSR），已经进行了许多尝试以合成单个训练策略。然而，每次尝试都违反了开放集定义，因为这些方法在未标记的训练集中包含新颖的类别。本研究提出了一种新的学习策略，其中分类器能够在观察到的和未观察到的新颖类别之间进行推广，从而定义了观察到新颖类别的背景类别和未观察到新颖类别的未知类别。通过分类这两种新颖类别的方式，Open-LACU能够提高训练的成本效益性，并确保在存在未观察到的新颖类别时进行安全分类。

    Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
    
[^182]: 使用非负核回归构建邻域和图

    Neighborhood and Graph Constructions using Non-Negative Kernel Regression. (arXiv:1910.09383v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1910.09383](http://arxiv.org/abs/1910.09383)

    本文提出了一种非负核回归的算法来构建更好的邻域和图，并且在各种应用中展示出其优越性和实用性。

    

    数据驱动的邻域定义和图构建在机器学习和信号处理应用中经常使用。k近邻（kNN）和 $\epsilon$-邻域方法是最常用的邻域选择方法之一，由于其计算简单性。然而，这些方法所涉及的参数选择，如 k 和 $\epsilon$，仍然是临时的。本文有两个主要贡献。首先，我们提出了一种邻域选择的替代方法，其中我们表明邻域构造等同于一个稀疏信号逼近问题。其次，我们提出了一种算法，非负核回归（NNK），用于获得更好的稀疏表示的邻域。NNK与信号表示的正交匹配追踪方法相似，并具有良好的几何和理论性质。实验证明了（i）NNK算法在邻域和图构建中的鲁棒性，（ii）NNK在各种应用中优于其他流行的邻域选择方法，以及（iii）NNK在其他机器学习和信号处理任务中的有用性。

    Data-driven neighborhood definitions and graph constructions are often used in machine learning and signal processing applications. k-nearest neighbor~(kNN) and $\epsilon$-neighborhood methods are among the most common methods used for neighborhood selection, due to their computational simplicity. However, the choice of parameters associated with these methods, such as k and $\epsilon$, is still ad hoc. We make two main contributions in this paper. First, we present an alternative view of neighborhood selection, where we show that neighborhood construction is equivalent to a sparse signal approximation problem. Second, we propose an algorithm, non-negative kernel regression~(NNK), for obtaining neighborhoods that lead to better sparse representation. NNK draws similarities to the orthogonal matching pursuit approach to signal representation and possesses desirable geometric and theoretical properties. Experiments demonstrate (i) the robustness of the NNK algorithm for neighborhood and 
    

