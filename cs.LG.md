# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities.](http://arxiv.org/abs/2308.02490) | MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。 |
| [^2] | [BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks.](http://arxiv.org/abs/2308.02465) | 本论文研究了针对节点级垂直联邦图神经网络的标签推断攻击，利用零背景知识策略来实现攻击，并揭示了该领域内的重要问题。 |
| [^3] | [Universal Approximation of Linear Time-Invariant (LTI) Systems through RNNs: Power of Randomness in Reservoir Computing.](http://arxiv.org/abs/2308.02464) | 通过随机性的储备计算，RNNs可以通用逼近线性时不变系统，这一观察到的性能在理论上得到了支持。 |
| [^4] | [Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning.](http://arxiv.org/abs/2308.02462) | 本研究利用运算学习方法，在MOOSE框架中开发了一个快速准确的减阶模型，用于增材制造中的控制和优化过程，通过改变过程变量来学习微分方程，使用Fourier神经运算器和深度运算器网络开发了时间相关响应的减阶模型。 |
| [^5] | [Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles.](http://arxiv.org/abs/2308.02460) | 利用卫星观测和气候模型，该论文提出了一个用机器学习预测海平面变化的框架，并生成了30年后海平面上升的预测，为理解气候变化信号的贡献和未来海平面变化的预测提供了帮助。 |
| [^6] | [Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration.](http://arxiv.org/abs/2308.02459) | 本研究提出了一种多模态分类探索方法，通过此方法能够训练出平滑且准确的非抓取平面操作控制器。此方法能够捕捉任务的混合动力学特性，解决了之前使用的单模态探索策略无法实现准确性和平滑轨迹的问题。 |
| [^7] | [SoK: Assessing the State of Applied Federated Machine Learning.](http://arxiv.org/abs/2308.02454) | 本研究评估了Federated Machine Learning（FedML）在实际应用中的现状，并发现了阻碍其实际应用的挑战。 |
| [^8] | [Generative Modelling of L\'{e}vy Area for High Order SDE Simulation.](http://arxiv.org/abs/2308.02452) | 本文提出了一种基于深度学习的模型LévyGAN，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩，解决了非高斯性质下的抽样困难问题。 |
| [^9] | [Pruning a neural network using Bayesian inference.](http://arxiv.org/abs/2308.02451) | 使用贝叶斯推断修剪神经网络的新方法可以实现理想的稀疏程度，同时保持竞争力的准确性。 |
| [^10] | [From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence.](http://arxiv.org/abs/2308.02448) | 这项研究探讨了从军事到医疗保健领域采纳和扩展伦理原则以应用生成式人工智能的可行性和重要性。 |
| [^11] | [Adaptive Preferential Attached kNN Graph With Distribution-Awareness.](http://arxiv.org/abs/2308.02442) | 本文提出了一种名为paNNG的算法，它结合了自适应kNN和基于分布的图构建。通过包含分布信息，paNNG能够有效提升模糊样本的性能，并实现更好的准确性和泛化能力。 |
| [^12] | [Noise removal methods on ambulatory EEG: A Survey.](http://arxiv.org/abs/2308.02437) | 本文综述了便携式脑电图中噪音的检测和去除方法，发现模式识别对于区分不同条件下的脑电图数据非常重要。 |
| [^13] | [Contrastive Self-Supervised Learning Based Approach for Patient Similarity: A Case Study on Atrial Fibrillation Detection from PPG Signal.](http://arxiv.org/abs/2308.02433) | 提出了一种基于对比学习的深度学习框架，用于通过生理信号检测心房颤动(AF)。该框架能够学习相似嵌入并确定最相似的患者。在超过170名个体的数据集上进行了实验，并与其他基线方法进行了比较。 |
| [^14] | [Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training.](http://arxiv.org/abs/2308.02427) | 本研究提出了一种基于相似性匹配的学习模式，通过使用PyTorch实现了扩展到大型数据集的卷积非负相似性匹配，引入了局部监督的SM目标，以及利用PyTorch实现预训练网络结构的特征评估对比。这将生物学合理性的算法与计算成本相结合，提供了一种在线、本地化且具有生物学合理性的学习方法。 |
| [^15] | [Hypertension Detection From High-Dimensional Representation of Photoplethysmogram Signals.](http://arxiv.org/abs/2308.02425) | 本论文提出了一种基于随机卷积核的高维表示技术，用于从脉搏波信号中检测高血压。实验结果表明，这一方法不仅局限于心率和血压，展示了高血压检测的普适性。 |
| [^16] | [Differentiable short-time Fourier transform with respect to the hop length.](http://arxiv.org/abs/2308.02421) | 本文提出了一种基于跳步长度可微分的短时傅里叶变换，通过使跳步长度连续，实现了梯度优化的时间定位控制，提供了更好的优化效果和更高的计算效率。该方法可以轻松集成到现有算法和神经网络中。 |
| [^17] | [P\=uioio: On-device Real-Time Smartphone-Based Automated Exercise Repetition Counting System.](http://arxiv.org/abs/2308.02420) | 本研究探索了基于智能手机的实时健身动作重复计数系统，在提供了最新研究成果概述后，引入了一个由五个组件构成的深度学习系统，并通过名为P=主ioio的移动应用实现。该系统利用智能手机摄像头实时跟踪标准健身动作的重复次数。英文要点为：This study explored a real-time smartphone-based exercise repetition counting system, introduced a deep learning system consisting of five components, and implemented it through a mobile application named P=主ioio that uses the smartphone camera to track repetitions in real time for standard exercises. |
| [^18] | [Multimodal Indoor Localisation in Parkinson's Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting.](http://arxiv.org/abs/2308.02419) | 该研究提出了一种基于变压器的方法，使用穿戴设备的RSSI和加速度计数据进行室内定位，以改善当前方法的有效性。研究还探讨了室内定位是否可以通过检测帕金森病患者的药物使用情况来评估运动波动。 |
| [^19] | [Differentiable adaptive short-time Fourier transform with respect to the window length.](http://arxiv.org/abs/2308.02418) | 本文提出了一种基于梯度的方法，用于实时优化短时傅里叶变换（STFT）的帧间和频率间窗长。生成的可微分自适应STFT具有出色的特性，可以适应瞬态和稳态成分，并且易于优化。 |
| [^20] | [Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification.](http://arxiv.org/abs/2308.02416) | 本文提出了一个本地-全局时间融合网络结合注意机制的框架，用于针对心律失常的检测和分类任务。该方法通过提取本地时间信息和全局模式，并使用注意力机制进行本地-全局信息融合，以处理长度变化的心律失常数据。实验结果表明，此方法在心律失常分类任务上的性能优于现有方法。 |
| [^21] | [Self-Supervised Learning for WiFi CSI-Based Human Activity Recognition: A Systematic Study.](http://arxiv.org/abs/2308.02412) | 本研究对基于WiFi CSI的人体活动识别进行了自监督学习，提出了一种解决深度学习中数据不足的方法。通过将深度学习技术与CSI数据相结合，实现了最先进的性能，无需专家知识。研究人员通过分析不同类型的自监督学习算法的潜力，对缺乏标记CSI数据的挑战进行了全面的整理和分析。 |
| [^22] | [RFID-Assisted Indoor Localization Using Hybrid Wireless Data Fusion.](http://arxiv.org/abs/2308.02410) | 本文提出了一种基于射频识别和多种物联网无线技术的混合室内定位方法，通过仅在各区块边界安装RFID标签来降低成本，并通过不同无线技术的线性位置估计实现了室内物体定位。 |
| [^23] | [Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models.](http://arxiv.org/abs/2308.02409) | 该论文通过融合多个空间维度的方法，使用脑电信号对心理负荷进行分类和估计连续级别。在时间域中使用了时态卷积网络，而在频率域中引入了新的架构——多维残差块。 |
| [^24] | [Evaluating the structure of cognitive tasks with transfer learning.](http://arxiv.org/abs/2308.02408) | 本研究通过迁移学习探索了在脑电图解码任务中，不同任务之间深度学习表征的可迁移性，并展示了即使是线性探测转移，也可以显著提高解码性能，相较于纯监督方法，改进幅度高达28%。 |
| [^25] | [Design Space Exploration on Efficient and Accurate Human Pose Estimation from Sparse IMU-Sensing.](http://arxiv.org/abs/2308.02397) | 本论文通过模拟情况下的设计空间探索，研究了人体姿势估计中精度和硬件资源之间的折衷，提出了利用IMU感测进行高效准确的人体姿势估计的方法。 |
| [^26] | [HOOD: Real-Time Robust Human Presence and Out-of-Distribution Detection with Low-Cost FMCW Radar.](http://arxiv.org/abs/2308.02396) | 本文提出了一种名为HOOD的实时稳健的人员存在和离群检测方法，通过利用低成本的60 GHz FMCW雷达实现。该方法可同时解决存在检测和离群检测问题，通过重构架构和雷达图像实现准确检测人类存在，同时在人类不存在时检测移动或静止干扰物。 |
| [^27] | [ECG classification using Deep CNN and Gramian Angular Field.](http://arxiv.org/abs/2308.02395) | 本文介绍了一种使用深度卷积神经网络和Gramm角度场的ECG分类方法，通过将时间频率1D向量转换为2D图像，并对转换后的ECG信号进行分类，达到了高准确率。该方法改善了分类性能，同时还有助于识别和可视化ECG信号中的时域模式，在心血管疾病诊断和治疗以及异常检测方面具有重要意义。 |
| [^28] | [Learning Optimal Admission Control in Partially Observable Queueing Networks.](http://arxiv.org/abs/2308.02391) | 本文提出了一种在部分可观察队列网络中学习最优入场控制策略的高效强化学习算法，通过利用闭合产品形式队列网络的Norton等效定理和结构化的出生死亡过程 MDP 的高效强化学习算法，实现了对最大作业数量的亚线性遗憾。 |
| [^29] | [Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics.](http://arxiv.org/abs/2308.02382) | 本研究针对医疗保健中生存数据的挑战，提出了FedSurF++算法，这是一种联合学习算法用于处理分布式的、具有隐私保密要求的生存分析。该算法可以大规模建模和处理生存数据，解决了数据稀缺和隐私保密的问题。 |
| [^30] | [A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data.](http://arxiv.org/abs/2308.02370) | 本文提出了使用机器学习方法从探测车数据预测交通信号灯定时的方法，利用XGBoost模型估计信号周期长度，利用神经网络模型确定红灯时间，并根据周期长度和红灯时间计算绿灯时间。结果显示，对信号周期长度的估计误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。 |
| [^31] | [Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings.](http://arxiv.org/abs/2308.02362) | 本文提出了一种灵活的差分隐私垂直联邦学习方法（VFL），通过应用范数剪裁实现了严格的隐私保证，并通过自适应调整特征嵌入的尺度和分布来优化任务效用，而不损害隐私保护。 |
| [^32] | [Intensity-free Integral-based Learning of Marked Temporal Point Processes.](http://arxiv.org/abs/2308.02360) | 该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。 |
| [^33] | [Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes.](http://arxiv.org/abs/2308.02353) | 这项研究介绍了一种新颖的半监督图形因果解释器 (DyGRACE)，它通过学习数据表示并利用已知数据分布的初始知识，在动态数据环境中搜索有效的因果解释。该方法独立于底层预测模型。 |
| [^34] | [RobustMQ: Benchmarking Robustness of Quantized Models.](http://arxiv.org/abs/2308.02350) | 该论文通过在ImageNet上全面评估了量化模型的鲁棒性，发现量化模型在对抗攻击方面更具鲁棒性，但对自然损坏和系统噪声更脆弱。 |
| [^35] | [Stability and Generalization of Hypergraph Collaborative Networks.](http://arxiv.org/abs/2308.02347) | 本文研究了超图协同网络的稳定性和泛化性，并在分析中揭示了协同网络中超图滤波器的设计要点。 |
| [^36] | [Learning Networks from Gaussian Graphical Models and Gaussian Free Fields.](http://arxiv.org/abs/2308.02344) | 本文研究了从重复测量的高斯自由场中估计加权网络结构的问题，并提出了一种基于高斯分布傅里叶分析特性的新型估计器。该方法利用了从观测数据中构造的复数值统计量，具有研究价值。 |
| [^37] | [RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification.](http://arxiv.org/abs/2308.02335) | 我们提出了一种检索增强型混合网络(RAHNet)用于长尾图分类任务，通过联合学习稳健的特征提取器和无偏的分类器，解决了图神经网络在长尾类别分布下的偏差和泛化能力有限的问题。 |
| [^38] | [A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation.](http://arxiv.org/abs/2308.02293) | 通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。 |
| [^39] | [Frustratingly Easy Model Generalization by Dummy Risk Minimization.](http://arxiv.org/abs/2308.02287) | 通过虚拟风险最小化，本文提出了一种令人沮丧地简单且通用的技术（DuRM），能够显著改善经验风险最小化（ERM）的泛化能力。通过理论和经验验证，我们展示了DuRM可以通过增加梯度的方差来促进模型的泛化效果，并在不同任务和数据集上进行的实验证明了DuRM的有效性。 |
| [^40] | [DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization.](http://arxiv.org/abs/2308.02282) | DIVERSIFY是一个通用框架，用于解决时间序列离群检测和推广的挑战，通过利用数据集中的子域来对抗时间序列的非平稳性，并通过迭代过程减小潜在分布之间的差距。 |
| [^41] | [Adaptive Proximal Gradient Method for Convex Optimization.](http://arxiv.org/abs/2308.02261) | 本文提出了自适应版本的梯度下降（GD）和近端梯度方法（ProxGD），通过利用局部曲率信息完全自适应。所提出的方法具有收敛性，且允许使用更大的步长。 |
| [^42] | [Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song.](http://arxiv.org/abs/2308.02249) | 本文介绍了使用自监督学习对韩国民歌进行计算机分析的方法，并以“托里”作为案例进行了研究。实验结果表明，该方法能够更好地捕捉到“托里”的特征，为研究韩国民歌提供了新的视角。 |
| [^43] | [Self-Normalizing Neural Network, Enabling One Shot Transfer Learning for Modeling EDFA Wavelength Dependent Gain.](http://arxiv.org/abs/2308.02233) | 本论文提出了一种基于自正规化神经网络的新型机器学习框架，能够实现一次迁移学习并对多个EDFA器件的波长相关增益进行建模。 |
| [^44] | [Likelihood-ratio-based confidence intervals for neural networks.](http://arxiv.org/abs/2308.02221) | 本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。该方法能够构建不对称区间，考虑了训练时间、网络架构和正则化技术等因素。尽管方法实现昂贵，但在特定领域中具有重要应用潜力。 |
| [^45] | [A Survey of Spanish Clinical Language Models.](http://arxiv.org/abs/2308.02199) | 这项调查研究了西班牙语临床语言模型的应用，回顾了17个专注于临床任务的语料库的贡献，并对最相关的西班牙语语言模型和西班牙临床语言模型进行了彻底比较，提供了3000多个进行微调的模型。为了便于未来的研究和挑战，所有测试过的语料库和最佳模型都被以可访问的方式公开。 |
| [^46] | [AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification.](http://arxiv.org/abs/2308.02182) | AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。 |
| [^47] | [Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology.](http://arxiv.org/abs/2308.02180) | 本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。 |
| [^48] | [Diffusion probabilistic models enhance variational autoencoder for crystal structure generative modeling.](http://arxiv.org/abs/2308.02165) | 扩散概率模型增强了变分自动编码器在晶体结构生成建模中的应用，通过去噪原子坐标并生成质量相当的晶体结构，并且能够生成与真实基态更接近的结构，能量准确性明显提高。 |
| [^49] | [Speaker Diarization of Scripted Audiovisual Content.](http://arxiv.org/abs/2308.02160) | 本文介绍了一种用于发言人日化任务的新方法，利用制作脚本提取伪标签数据，并相对于无监督基线模型实现了51.7%的改进。 |
| [^50] | [Improved Order Analysis and Design of Exponential Integrator for Diffusion Models Sampling.](http://arxiv.org/abs/2308.02157) | 通过重新评估高阶微分求解器的设计，我们提出了改进的指数积分器，在扩散模型的采样中获得了更好的采样质量和准确性。 |
| [^51] | [Optimization on Pareto sets: On a theory of multi-objective optimization.](http://arxiv.org/abs/2308.02145) | 该论文研究了在多目标优化中，如何解决Pareto集合上的约束优化问题，提出了局部算法，并给出了收敛速率。 |
| [^52] | [Learning the solution operator of two-dimensional incompressible Navier-Stokes equations using physics-aware convolutional neural networks.](http://arxiv.org/abs/2308.02137) | 本论文提出了一种使用物理感知的卷积神经网络学习不同几何形状中稳态Navier-Stokes方程解的近似解的技术，无需参数化，在结果上与基于数据的方法进行了比较。 |
| [^53] | [Eva: A General Vectorized Approximation Framework for Second-order Optimization.](http://arxiv.org/abs/2308.02123) | Eva是一个内存和时间高效的二阶优化算法，使用Kronecker分解和Sherman-Morrison公式来减少内存消耗和计算矩阵逆，同时将其扩展为通用的矢量化近似框架以提高计算和内存效率。 |
| [^54] | [Model Provenance via Model DNA.](http://arxiv.org/abs/2308.02121) | 本文介绍了模型来源证明的新概念模型DNA，通过编码模型的训练数据和输入输出信息作为紧凑全面的表示，来确定源模型是否作为目标模型的来源证明。 |
| [^55] | [VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs.](http://arxiv.org/abs/2308.02117) | VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。 |
| [^56] | [Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network.](http://arxiv.org/abs/2308.02101) | 该论文提出了一种使用混合多任务CNN-Transformer网络进行乳腺超声肿瘤分类的方法。与传统的卷积神经网络相比，该方法能更好地捕捉全局上下文信息，并在实验中取得了最高的准确性、灵敏度和F1得分。 |
| [^57] | [Efficient Model Adaptation for Continual Learning at the Edge.](http://arxiv.org/abs/2308.02084) | 这篇论文提出了一个名为Encoder-Adaptor-Reconfigurator（EAR）框架，用于在领域漂移下进行高效的持续学习。该框架使用了固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。通过结合DNN和超维计算（HDC），该框架能够检测新数据是否属于分布之外（OOD），并能够识别出... (摘要内容省略) |
| [^58] | [Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare.](http://arxiv.org/abs/2308.02081) | 目标规范偏差是影响机器学习预测工具临床效用的普遍偏见，它指的是目标变量的操作化与决策者定义的不一致，可能导致预测准确性的过高估计和次优决策，与数据限制和健康差异无关。 |
| [^59] | [Causality Guided Disentanglement for Cross-Platform Hate Speech Detection.](http://arxiv.org/abs/2308.02080) | 本研究提出了一种跨平台仇恨言论检测模型，通过解缠输入表示为不变特征和平台相关特征，实现了对多个未见平台的良好泛化能力。 |
| [^60] | [Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale.](http://arxiv.org/abs/2308.02068) | 本研究利用日常抓取的1,404个不可靠新闻网站以及大型语言模型和聚类算法，提出了一个自动分析网络生态系统中传播的叙述的系统。通过识别55,301个叙述，描述了2022年传播最广泛的叙述，并确定了最具影响力的起源和放大叙述的网站。该系统可用于检测来自不可靠新闻网站的新叙述，并帮助事实核查组织更快地应对错误信息。 |
| [^61] | [Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives.](http://arxiv.org/abs/2308.02066) | 本文提出了ETR-NLP模型来减轻多任务学习中的任务干扰，通过使用非可学习原语和显式任务路由的协同组合，在共享分支和任务特定分支中显式地分离可学习参数，以实现任务之间的最小化干扰。 |
| [^62] | [On the Biometric Capacity of Generative Face Models.](http://arxiv.org/abs/2308.02065) | 这篇论文提出了一种统计方法，用于估计在超球特征空间中生成的人脸图像的生物特征容量，并在多个生成模型上进行了实证研究。 |
| [^63] | [Accurate Neural Network Pruning Requires Rethinking Sparse Optimization.](http://arxiv.org/abs/2308.02060) | 这项工作研究了高稀疏对神经网络训练的影响，发现使用传统的密集训练策略进行稀疏训练效果不佳，提出了新的方法来解决这个问题，并在视觉和语言模型上都取得了最先进的结果。 |
| [^64] | [Incorporating Recklessness to Collaborative Filtering based Recommender Systems.](http://arxiv.org/abs/2308.02058) | 本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。 |
| [^65] | [Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries.](http://arxiv.org/abs/2308.02055) | 本文提出了一种基于神经网络的自然语言处理算法，用于将季节性作为信号来重新排序电子商务的自动完成功能，从而提高自动完成的相关性和业务指标。 |
| [^66] | [Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems.](http://arxiv.org/abs/2308.02054) | 本文介绍了一种针对同步随机线性系统的鲁棒独立性检验方法，可以提供非渐近性保证的显著水平。该方法结合了置信区间估计、排列检验以及一般的依赖度量，以检测系统之间的任何非线性依赖关系。 |
| [^67] | [A Graphical Approach to Document Layout Analysis.](http://arxiv.org/abs/2308.02051) | 这项研究提出了一种基于图的文档布局分析方法，通过利用PDF的元数据，将每个页面表示为一个结构化图，并将布局分析问题转化为图分割和分类问题。该方法比现有计算机视觉模型更小且性能更好。 |
| [^68] | [FuNToM: Functional Modeling of RF Circuits Using a Neural Network Assisted Two-Port Analysis Method.](http://arxiv.org/abs/2308.02050) | 本文介绍了一种名为FuNToM的RF电路功能建模方法，该方法利用了双端口分析方法，并结合神经网络技术，有效地解决了训练数据收集和后布局建模仿真的问题。 |
| [^69] | [Learning Regionalization within a Differentiable High-Resolution Hydrological Model using Accurate Spatial Cost Gradients.](http://arxiv.org/abs/2308.02040) | 本文介绍了一种使用准确的空间成本梯度在可微的高分辨率水文模型中学习划分区域化模型的方法，该方法利用可学习的区域化映射，结合数据同化和参数校正，能够在广泛的时空计算域中利用不同数据集进行水文参数估计。 |
| [^70] | [What Twitter Data Tell Us about the Future?.](http://arxiv.org/abs/2308.02035) | 本研究通过研究Twitter上未来主义者对未来的预期，探究语言提示对社交媒体用户的预测性思维的影响，并开发了一个可扩展的自然语言处理流程和数据集。 |
| [^71] | [The Growth of E-Bike Use: A Machine Learning Approach.](http://arxiv.org/abs/2308.02034) | 本研究使用机器学习方法，预测了美国电动自行车销量的增长，并评估了影响电动自行车使用的因素。根据预测结果，预计2025年电动自行车销售量为130万辆，2028年为211.3万辆。 |
| [^72] | [Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy.](http://arxiv.org/abs/2308.02031) | 知识增强的神经符号人工智能将深度神经网络和符号知识图相结合，提高了人工智能系统的可解释性和安全性，在网络安全和隐私保护领域具有潜在应用价值。 |
| [^73] | [Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection.](http://arxiv.org/abs/2308.02029) | 本文提出了基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习方法，应用于地中海贫血检测。该方法对输入数据进行归一化处理，并利用Deep Maxout网络的特征融合和过采样方法进行数据增强，最终通过转移学习进行地中海贫血检测。 |
| [^74] | [Federated Representation Learning for Automatic Speech Recognition.](http://arxiv.org/abs/2308.02013) | 使用联邦学习和自监督学习的结合方法，研究了面向自动语音识别的联邦表示学习，将边缘设备上的隐私数据用于学习健壮的音频表示，并取得了显著的性能改善。 |
| [^75] | [Memory capacity of two layer neural networks with smooth activations.](http://arxiv.org/abs/2308.02001) | 研究发现，具有平滑激活函数的两层神经网络的存储容量下界为md/2，并且准确性大致为2倍。分析存储容量的方法包括计算网络雅可比矩阵的秩，并扩展了有关Hadamard幂秩的经典线性代数事实。 |
| [^76] | [On the Transition from Neural Representation to Symbolic Knowledge.](http://arxiv.org/abs/2308.02000) | 该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。 |
| [^77] | [Explainable unsupervised multi-modal image registration using deep networks.](http://arxiv.org/abs/2308.01994) | 这个论文描述了一个使用深度网络进行可解释的无监督多模态图像配准的方法，结合了Grad-CAM-based的可解释性框架，能够处理仿射和非刚性配准，并在临床MRI设置中具有重要应用价值。 |
| [^78] | [CartiMorph: a framework for automated knee articular cartilage morphometrics.](http://arxiv.org/abs/2308.01981) | CartiMorph是一种自动化膝关节软骨形态学测量的框架，利用深度学习模型进行图像分析，通过定量指标评估了软骨的损失和厚度，并与手动分割的结果进行了比较，结果显示表面法线的厚度映射方法具有较小的误差。 |
| [^79] | [Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces.](http://arxiv.org/abs/2308.01976) | 本研究针对在线市场中拼写错误的问题，通过数据增强方法和递归神经网络实现了领域特定的拼写检查器，并将其应用在微软AppSource市场的实时推断API中。我们的数据有效解决方案表明，控制高质量的合成数据可能成为一个有力的工具，特别是考虑到当前大语言模型所依赖的巨大且难以控制的数据集。 |
| [^80] | [DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation.](http://arxiv.org/abs/2308.01966) | 这项研究引入了一种扩张卷积转换模型，用于在MULTIMEDIATE 2023竞赛中建模和估计多模态对话中的人类参与度。在测试集上该系统比基准模型表现出显著的7%改进，在验证集上表现为4%改进。此外，使用简单的串联方法与自注意力融合可以获得最佳性能。 |
| [^81] | [Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes.](http://arxiv.org/abs/2308.01954) | 本文旨在通过调整损失权重来改善人工神经网络在多元回归任务中学习燃烧查找表的准确性，能够有效地学习所有物种质量分数。 |
| [^82] | [Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model.](http://arxiv.org/abs/2308.01947) | 本论文提出了一种基于双学生-教师模型的判别性图级异常检测方法，通过定义异常图信息和采用节点级和图级信息差来识别异常图，并引入教师模型和两个竞争的学生模型来提高异常检测的效果。 |
| [^83] | [Experimental Results regarding multiple Machine Learning via Quaternions.](http://arxiv.org/abs/2308.01946) | 本论文通过实验研究了在多个机器学习算法中应用四元数的效果。研究结果表明，使用四元数来表示和分类旋转数据，并结合多个机器学习算法，可以获得更高的准确率和性能提升。 |
| [^84] | [Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods.](http://arxiv.org/abs/2308.01938) | 本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。 |
| [^85] | [Training Data Protection with Compositional Diffusion Models.](http://arxiv.org/abs/2308.01937) | 使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。 |
| [^86] | [Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors.](http://arxiv.org/abs/2308.01932) | 基于机器学习的方法被用来估计超导体的临界温度，填补了关于超导性和临界温度估计的知识缺口。 |
| [^87] | [Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features.](http://arxiv.org/abs/2308.01930) | 基于光电脉搏信号特征的机器学习方法用于糖尿病检测，通过非侵入性PPG信号和LR、XGBoost算法的分类，实现了免创伤且连续监测的糖尿病检测。 |
| [^88] | [A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil.](http://arxiv.org/abs/2308.01929) | 这项研究提出了一种基于Transformer的方法来预测丙泊酚和瑞芬太尼的麻醉深度。该方法通过利用长短时记忆和门控残差网络来提高特征融合的效率，并应用注意机制来发现药物之间的相互作用。实验证明，该方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。 |
| [^89] | [Are Easy Data Easy (for K-Means).](http://arxiv.org/abs/2308.01926) | 本文研究了各种品牌的K-Means算法对互相分离的聚类的能力，并提出一种性能更优的K-Means++变体算法。 |
| [^90] | [An Empirical Study on Fairness Improvement with Multiple Protected Attributes.](http://arxiv.org/abs/2308.01923) | 本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。 |
| [^91] | [Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats.](http://arxiv.org/abs/2308.01921) | 该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。 |
| [^92] | [Sequence-Based Nanobody-Antigen Binding Prediction.](http://arxiv.org/abs/2308.01920) | 本研究旨在解决纳米抗体生产中的关键挑战，即缺乏与大多数抗原相匹配的纳米抗体。研究针对此问题提出了一种基于序列的方法来预测纳米抗体-抗原的结合。此方法不依赖于3D结构，并且能够提高纳米抗体的生产效率。 |
| [^93] | [PePNet: A Periodicity-Perceived Workload Prediction Network Supporting Rare Occurrence of Heavy Workload.](http://arxiv.org/abs/2308.01917) | PePNet是一种支持罕见重负载的工作负载预测网络，通过周期性感知机制和融合多尺度序列学习的能力提高了整体特别是重负载的准确性。 |
| [^94] | [Semi Supervised Meta Learning for Spatiotemporal Learning.](http://arxiv.org/abs/2308.01916) | 本文探讨了半监督元学习在时空学习中的应用，通过将元学习应用于自监督遮蔽自编码器，并结合状态-of-the-art表示学习架构，提出了一种新的框架来解决视频重建和动作分类任务。 |
| [^95] | [LOB-Based Deep Learning Models for Stock Price Trend Prediction: A Benchmark Study.](http://arxiv.org/abs/2308.01915) | 本研究通过基准研究探讨了基于LOB数据的股票价格趋势预测的15种最新DL模型的鲁棒性和泛化能力。实验证明这些模型在面对新数据时性能明显下降，对其在实际市场中的应用性提出了问题。 |
| [^96] | [Deep Policy Gradient Methods in Commodity Markets.](http://arxiv.org/abs/2308.01910) | 本论文研究了深度强化学习方法在商品交易中的应用，并通过提供流动性和减少市场波动性来稳定市场。这对于解决能源市场的不稳定和全球能源危机具有重要意义。 |
| [^97] | [MRQ:Support Multiple Quantization Schemes through Model Re-Quantization.](http://arxiv.org/abs/2308.01867) | 该论文提出了一种名为MRQ的模型重新量化方法，通过将现有的量化模型快速转换以满足不同的量化要求，解决了在固定点硬件上部署深度学习模型的挑战。 |
| [^98] | [Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models.](http://arxiv.org/abs/2308.01404) | 通过引入一款名为"Hoodwinked"的文本游戏，研究了当前语言模型是否具有欺骗和识别谎言的能力。实验证据表明，杀手经常否认罪行并指责他人，导致投票结果受到影响。更先进的模型在杀手效果上表现出优势。实验证据表明，这种改进是通过在讨论中更强的欺骗能力实现的。 |
| [^99] | [Unlearning Spurious Correlations in Chest X-ray Classification.](http://arxiv.org/abs/2308.01119) | 本论文提出了一种深度学习方法（XBL），通过利用模型解释来交互式地消除胸部X射线分类中的错误相关性。该方法可以帮助解决多数据源引入的混淆因素，提高模型的准确性和透明度。 |
| [^100] | [AI Increases Global Access to Reliable Flood Forecasts.](http://arxiv.org/abs/2307.16104) | 本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。 |
| [^101] | [Initial State Interventions for Deconfounded Imitation Learning.](http://arxiv.org/abs/2307.15980) | 本文介绍了一种针对模仿学习中因果混淆问题的初始化状态干预算法，该算法能够遮蔽观测中的混淆因素并提高性能表现。 |
| [^102] | [Backdoor Defense with Non-Adversarial Backdoor.](http://arxiv.org/abs/2307.15539) | 提出了一种非对抗性后门防御框架，通过在被污染样本中注入非对抗性后门，当触发时可以抑制攻击者对污染数据的后门攻击，同时保持对干净数据的影响有限。 |
| [^103] | [Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting.](http://arxiv.org/abs/2307.15299) | 本研究使用差分进化算法选择Transformer神经网络模型的优化超参数，以提高负荷预测的准确性。 |
| [^104] | [Learning minimal representations of stochastic processes with variational autoencoders.](http://arxiv.org/abs/2307.11608) | 本文引入了一种无监督机器学习方法，使用变分自动编码器确定最小参数集，有效描述随机过程动力学，并生成能准确复制预期随机行为的新轨迹。 |
| [^105] | [On Interpolating Experts and Multi-Armed Bandits.](http://arxiv.org/abs/2307.07264) | 学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。 |
| [^106] | [LeCo: Lightweight Compression via Learning Serial Correlations.](http://arxiv.org/abs/2306.15374) | 使用机器学习来自动消除序列冗余以实现出色的压缩比和解压缩性能的LeCo是一种轻量级压缩框架，通过学习序列相关性，它能够在压缩比和随机访问速度上实现帕累托改进。 |
| [^107] | [Joint Channel Estimation and Feedback with Masked Token Transformers in Massive MIMO Systems.](http://arxiv.org/abs/2306.06125) | 本论文提出了一种基于深度学习和掩码Token Transformer的联合信道估计和反馈框架，有效提高了大规模MIMO系统中信道估计和反馈的性能。 |
| [^108] | [Estimation of Ridge Using Nonlinear Transformation on Density Function.](http://arxiv.org/abs/2306.05722) | 本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。 |
| [^109] | [Federated Deep Learning for Intrusion Detection in IoT Networks.](http://arxiv.org/abs/2306.02715) | 本研究提出了一种基于联邦深度学习的入侵检测框架，可在保护数据隐私和局部性的同时实现高效的模型收敛，该框架在物联网入侵检测应用中具有潜力。 |
| [^110] | [Competing for Shareable Arms in Multi-Player Multi-Armed Bandits.](http://arxiv.org/abs/2305.19158) | 本文研究了在多人多臂赌博机中竞争可分享的手臂的问题。我们提出了一种新的自私MPMAB与分配平均算法（SMAA）方法，理论上证明了在玩家遵循该算法的情况下可以实现良好的后悔保证。此外，我们还证明了没有单个自私的玩家能通过偏离显著增加他们的回报。 |
| [^111] | [Mitigating Label Biases for In-context Learning.](http://arxiv.org/abs/2305.19148) | 本文针对上下文学习（ICL）中的三种标签偏差提出分类法，并提出一种简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。 |
| [^112] | [Evaluating generation of chaotic time series by convolutional generative adversarial networks.](http://arxiv.org/abs/2305.16729) | 该研究通过使用卷积生成对抗网络生成混沌时间序列，并评估生成的时间序列，证明了卷积神经网络有能力很好地复制原始时间序列的混沌特性，但误差分析表明仍然存在大误差。 |
| [^113] | [Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise.](http://arxiv.org/abs/2305.13498) | 本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。 |
| [^114] | [Traffic Forecasting on New Roads Unseen in the Training Data Using Spatial Contrastive Pre-Training.](http://arxiv.org/abs/2305.05237) | 本文提出一种名为SCPT的框架，利用对比学习进行空间预训练，并引入一个空间编码器模块，用于从未见数据中提取特征。该方法可以用于进行新道路的交通预测，无需重新训练模型。 |
| [^115] | [Interpretable (not just posthoc-explainable) heterogeneous survivor bias-corrected treatment effects for assignment of postdischarge interventions to prevent readmissions.](http://arxiv.org/abs/2304.09981) | 该研究使用生存分析来评价出院后评估和管理（E/M）服务对防止再住院或死亡的影响，避免了机器学习中幸存者偏差的问题，并确定了个案管理服务在减少再住院方面最为有效，尤其对于出院后到长期护理机构的患者以及入院前有高资源利用率的患者。 |
| [^116] | [A Fast and Lightweight Network for Low-Light Image Enhancement.](http://arxiv.org/abs/2304.02978) | 本文提出了一种称为FLW-Net的快速、轻量级网络，用于解决低光照图像中存在的噪声、低亮度、低对比度和色彩偏差问题。该方法具有高效的全局特征信息提取组件以及基于相对信息设计的损失函数，实验结果显示其有效性。 |
| [^117] | [SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization.](http://arxiv.org/abs/2303.13035) | 研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型. |
| [^118] | [Exploiting 4D CT Perfusion for segmenting infarcted areas in patients with suspected acute ischemic stroke.](http://arxiv.org/abs/2303.08757) | 该研究提出了一种新颖的方法，通过利用四维CTP全面利用时空信息，以分割疑似急性缺血性卒中患者的梗死区。实验证明，该方法明显优于现有的最先进方法，有潜力为改善AIS患者的早期诊断和治疗规划的准确性和效率做出贡献。 |
| [^119] | [Exploiting Multiple Abstractions in Episodic RL via Reward Shaping.](http://arxiv.org/abs/2303.00516) | 在这项工作中，我们通过引入一种新颖的奖励塑形形式，利用多层次的抽象来改善强化学习的效率，并且对抽象模型的设计要求较少，具有容忍性。 |
| [^120] | [Explainable Contextual Anomaly Detection using Quantile Regression Forests.](http://arxiv.org/abs/2302.11239) | 该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。 |
| [^121] | [SE(3) symmetry lets graph neural networks learn arterial velocity estimation from small datasets.](http://arxiv.org/abs/2302.08780) | 用SE(3)等变的图神经网络模型可以从小数据集中学习动脉流速估计，速度快，减少了使用CFD模拟的需要 |
| [^122] | [GraphCast: Learning skillful medium-range global weather forecasting.](http://arxiv.org/abs/2212.12794) | GraphCast是一种基于机器学习的方法，可以直接从再分析数据中训练，能在短时间内预测全球数百个天气变量，支持更好的严重事件预测，是准确和高效的天气预报的关键进展。 |
| [^123] | [Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs.](http://arxiv.org/abs/2212.09034) | 本文通过将中间模型命名为 PMLP 并在测试时采用 GNNs 的架构，发现 GNNs 的表现出众不是其高级表现力的主要原因，而是其固有的泛化能力。 |
| [^124] | [Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice.](http://arxiv.org/abs/2211.07206) | 本研究使用PAC-Bayesian理论提供了元学习的泛化界限，并推导出了最佳性能保证的闭式优化超后验(PACOH)。通过理论分析和案例研究，我们展示了这些保证在元学习中相对于PAC-Bayesian每个任务学习界限的改进。 |
| [^125] | [Data-Driven Modeling of Landau Damping by Physics-Informed Neural Networks.](http://arxiv.org/abs/2211.01021) | 本研究提出了一种基于物理启发式神经网络的数据驱动方法，成功构建了一个包含隐式流体闭合项的多矩便流体模型，能够重现Landau阻尼的动力学特征，并且引入了一个表征流体-细结构相互作用的新变量，该方法有效地将流体模型的应用范围扩展到多尺度系统，为研究等离子体动力学提供了强大工具。 |
| [^126] | [Occam learning.](http://arxiv.org/abs/2210.13179) | 本文讨论了一种具有固定隐藏层分布的概率神经网络模型，该模型选择简单、易解释，不需要过度参数化，同时训练有效。模型的隐藏单元为二元变量时具有以特征为基础的自然解释。作者认为隐藏变量的分布应该遵循最大关联度原则，并介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。 |
| [^127] | [Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS).](http://arxiv.org/abs/2210.08549) | 该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。 |
| [^128] | [Exponential Concentration of Stochastic Approximation with Non-vanishing Gradient.](http://arxiv.org/abs/2208.07243) | 本研究分析了非零梯度的随机逼近算法的行为，并证明了指数级的集中性界限，这对于投影随机梯度下降算法的收敛速度有重要意义。 |
| [^129] | [ENCODE: Encoding NetFlows for Network Anomaly Detection.](http://arxiv.org/abs/2207.03890) | 本文提出了一种编码算法，通过考虑特征值的频率和上下文，对NetFlow数据进行预处理，以提高网络异常检测的效果。 |
| [^130] | [Inference-Based Quantum Sensing.](http://arxiv.org/abs/2206.09919) | 这项工作提出了一种基于推理的量子感知方案，可以通过测量系统响应来推断未知参数的值，并确定方案的敏感性。 |
| [^131] | [Improved Algorithms for Bandit with Graph Feedback via Regret Decomposition.](http://arxiv.org/abs/2205.15076) | 通过遗憾分解，我们提出了一种基于反馈图划分的新算法框架，该框架统一了多臂赌博机和学习与专家建议的最优算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。 |
| [^132] | [Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming.](http://arxiv.org/abs/2205.13687) | 本篇论文提出了一种用于等式约束的随机非线性优化问题的统计推断方法，通过基于草图的顺序二次规划（StoSQP）进行求解，并且允许自适应选择随机步长和使用高效随机迭代求解器来降低计算成本。 |
| [^133] | [Mondrian Forest for Data Stream Classification Under Memory Constraints.](http://arxiv.org/abs/2205.07871) | 本文将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下，并设计了内存不足策略和修剪机制。研究表明，在所有配置中，Extend Node策略是最佳的内存不足策略。 |
| [^134] | [Mitigating the Bias of Centered Objects in Common Datasets.](http://arxiv.org/abs/2112.09195) | 本文讨论了卷积网络对物体位置的响应变化以及常见数据集中物体偏差问题。研究发现，训练过程中图像中心的物体过度表示导致网络性能受限，特别是当物体靠近边界时。同时，作者提出了使用数据增强技术来减轻这种影响的方法。 |
| [^135] | [A New Basis for Sparse Principal Component Analysis.](http://arxiv.org/abs/2007.00596) | 我们提出了一种新的方法来进行稀疏主成分分析，该方法使用正交旋转来获得近似稀疏的特征值基。与以往方法不同的是，我们的方法使稀疏成分不需要是主特征向量，而可以是它们的混合。这一方法不需要进行“缩减”操作或使用多个调参参数。 |
| [^136] | [Fine-grained Species Recognition with Privileged Pooling: Better Sample Efficiency Through Supervised Attention.](http://arxiv.org/abs/2003.09168) | 该论文提出了一种使用关键点注释来监督学习模型的方案，通过特权汇集和视觉注意机制，实现了对具有长尾物种分布和数据集偏差的动物物种进行细粒度识别，提高了小样本训练的效率和泛化能力。 |

# 详细

[^1]: MM-Vet: 评估大型多模态模型的综合能力

    MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])

    [http://arxiv.org/abs/2308.02490](http://arxiv.org/abs/2308.02490)

    MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。

    

    我们提出了MM-Vet，一个评估标准，用于检查在复杂多模态任务上的大型多模态模型（LMM）的表现。最近的LMM展示了各种有趣的能力，例如解决书写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。快速的模型进步给评估标准的开发带来了挑战。问题包括：（1）如何系统地构建和评估复杂的多模态任务；（2）如何设计适用于不同类型问题和回答的评估指标；（3）如何给出超出简单性能排名的模型洞察。为此，我们提出了MM-Vet，基于这样一个洞察：解决复杂任务的有趣能力通常通过一种通才模型能够整合不同的核心视觉-语言（VL）能力来实现。MM-Vet定义了6个核心VL能力，并检查了从这些能力组合中得出的16种有趣的整合方式。

    We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combin
    
[^2]: BlindSage：针对节点级垂直联邦图神经网络的标签推断攻击

    BlindSage: Label Inference Attacks against Node-level Vertical Federated Graph Neural Networks. (arXiv:2308.02465v1 [cs.LG])

    [http://arxiv.org/abs/2308.02465](http://arxiv.org/abs/2308.02465)

    本论文研究了针对节点级垂直联邦图神经网络的标签推断攻击，利用零背景知识策略来实现攻击，并揭示了该领域内的重要问题。

    

    联邦学习通过保持涉及工作方的原始数据私密性，实现机器学习模型的协作训练。其主要目标之一是提高模型的隐私性、安全性和可扩展性。垂直联邦学习（VFL）提供了一种有效的跨域设置，其中少数参与方在不共享相同特征的情况下共同训练模型。在这种情况下，分类标签通常被视为仅由一个（主动）参与方独占持有的敏感信息，而其他（被动）参与方仅使用其本地信息。最近的研究揭示了VFL的重要缺陷，可能导致在攻击者具有某些，甚至有限的标签与数据关系的背景知识的假设下发生标签推断攻击。在本文中，我们是首次（据我们所知）使用零背景知识策略研究VFL上的标签推断攻击。为了具体阐述我们的提案，我们专注于Grap的问题。

    Federated learning enables collaborative training of machine learning models by keeping the raw data of the involved workers private. One of its main objectives is to improve the models' privacy, security, and scalability. Vertical Federated Learning (VFL) offers an efficient cross-silo setting where a few parties collaboratively train a model without sharing the same features. In such a scenario, classification labels are commonly considered sensitive information held exclusively by one (active) party, while other (passive) parties use only their local information. Recent works have uncovered important flaws of VFL, leading to possible label inference attacks under the assumption that the attacker has some, even limited, background knowledge on the relation between labels and data. In this work, we are the first (to the best of our knowledge) to investigate label inference attacks on VFL using a zero-background knowledge strategy. To concretely formulate our proposal, we focus on Grap
    
[^3]: 通过RNNs实现线性时不变系统的通用逼近：随机性在储备计算中的作用

    Universal Approximation of Linear Time-Invariant (LTI) Systems through RNNs: Power of Randomness in Reservoir Computing. (arXiv:2308.02464v1 [eess.SP])

    [http://arxiv.org/abs/2308.02464](http://arxiv.org/abs/2308.02464)

    通过随机性的储备计算，RNNs可以通用逼近线性时不变系统，这一观察到的性能在理论上得到了支持。

    

    循环神经网络(RNNs)以相对温和和普适的条件被认为是动态系统的通用近似器，使其成为处理时间信息的良好工具。然而，RNNs通常受到标准RNN训练中梯度消失和爆炸的问题的影响。储备计算(RC)是一种特殊的RNN，其中的循环权重是随机化并留在未经训练状态，它被引入用于克服这些问题，并在诸如自然语言处理和无线通信等领域展现出卓越的实证性能，特别是在训练样本极其有限的情况下。然而，支持这种观察到的性能的理论基础并未以相同的速度完全发展。在这项工作中，我们展示了RNNs可以提供线性时不变(LTI)系统的通用逼近。具体而言，我们展示了RC可以对一般LTI系统进行全面逼近。我们提出了一个明确的信号处理方法。

    Recurrent neural networks (RNNs) are known to be universal approximators of dynamic systems under fairly mild and general assumptions, making them good tools to process temporal information. However, RNNs usually suffer from the issues of vanishing and exploding gradients in the standard RNN training. Reservoir computing (RC), a special RNN where the recurrent weights are randomized and left untrained, has been introduced to overcome these issues and has demonstrated superior empirical performance in fields as diverse as natural language processing and wireless communications especially in scenarios where training samples are extremely limited. On the contrary, the theoretical grounding to support this observed performance has not been fully developed at the same pace. In this work, we show that RNNs can provide universal approximation of linear time-invariant (LTI) systems. Specifically, we show that RC can universally approximate a general LTI system. We present a clear signal proces
    
[^4]: 基于MOOSE框架的快速准确的减阶建模在增材制造中的运算学习

    Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning. (arXiv:2308.02462v1 [cs.LG])

    [http://arxiv.org/abs/2308.02462](http://arxiv.org/abs/2308.02462)

    本研究利用运算学习方法，在MOOSE框架中开发了一个快速准确的减阶模型，用于增材制造中的控制和优化过程，通过改变过程变量来学习微分方程，使用Fourier神经运算器和深度运算器网络开发了时间相关响应的减阶模型。

    

    增材制造中的一个主要挑战是在运行时通过调整制造过程参数来达到特定的材料属性。这种调整往往增加了用于增材制造中的现有模拟工具的计算负荷。本研究的目标是为在多物理面向对象模拟环境（MOOSE）框架中开发的增材制造模型构建一个快速准确的减阶模型（ROM），从而最终减少增材制造控制和优化过程的时间/成本。我们采用了运算学习（OL）方法，通过改变激光的高斯点热源中的过程变量，学习了一系列微分方程。具体而言，我们使用了Fourier神经运算器（FNO）和深度运算器网络（DeepONet）来开发时间相关响应的减阶模型。此外，我们将这些OL方法的性能与传统深度神经网络（DNN）进行了基准测试。

    One predominant challenge in additive manufacturing (AM) is to achieve specific material properties by manipulating manufacturing process parameters during the runtime. Such manipulation tends to increase the computational load imposed on existing simulation tools employed in AM. The goal of the present work is to construct a fast and accurate reduced-order model (ROM) for an AM model developed within the Multiphysics Object-Oriented Simulation Environment (MOOSE) framework, ultimately reducing the time/cost of AM control and optimization processes. Our adoption of the operator learning (OL) approach enabled us to learn a family of differential equations produced by altering process variables in the laser's Gaussian point heat source. More specifically, we used the Fourier neural operator (FNO) and deep operator network (DeepONet) to develop ROMs for time-dependent responses. Furthermore, we benchmarked the performance of these OL methods against a conventional deep neural network (DNN
    
[^5]: 利用测高仪和气候模型集合的机器学习预测海平面变化

    Sea level Projections with Machine Learning using Altimetry and Climate Model ensembles. (arXiv:2308.02460v1 [physics.ao-ph])

    [http://arxiv.org/abs/2308.02460](http://arxiv.org/abs/2308.02460)

    利用卫星观测和气候模型，该论文提出了一个用机器学习预测海平面变化的框架，并生成了30年后海平面上升的预测，为理解气候变化信号的贡献和未来海平面变化的预测提供了帮助。

    

    自1993年以来，卫星测高仪观测到的全球平均海平面上升速度达到了前所未有的3.4毫米/年。凭借近30年的观测数据，我们现在可以研究人为气候变化信号（如温室气体、气溶胶和生物质燃烧）对海平面上升的贡献。我们使用机器学习来研究未来海平面变化的模式。为了了解气候变化信号的贡献程度，并帮助预测未来的海平面变化，我们用气候模型模拟来进行研究。本研究提出了一个利用卫星观测和气候模型模拟生成2度分辨率空间网格30年海平面上升预测的机器学习框架。我们通过非线性融合气候模型的回溯数据（1993-2019年）训练全连接神经网络（FCNN）来预测测高仪的数值。所学得的FCNN是

    Satellite altimeter observations retrieved since 1993 show that the global mean sea level is rising at an unprecedented rate (3.4mm/year). With almost three decades of observations, we can now investigate the contributions of anthropogenic climate-change signals such as greenhouse gases, aerosols, and biomass burning in this rising sea level. We use machine learning (ML) to investigate future patterns of sea level change. To understand the extent of contributions from the climate-change signals, and to help in forecasting sea level change in the future, we turn to climate model simulations. This work presents a machine learning framework that exploits both satellite observations and climate model simulations to generate sea level rise projections at a 2-degree resolution spatial grid, 30 years into the future. We train fully connected neural networks (FCNNs) to predict altimeter values through a non-linear fusion of the climate model hindcasts (for 1993-2019). The learned FCNNs are the
    
[^6]: 通过多模态分类探索的强化学习实现非抓取平面操作

    Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration. (arXiv:2308.02459v1 [cs.RO])

    [http://arxiv.org/abs/2308.02459](http://arxiv.org/abs/2308.02459)

    本研究提出了一种多模态分类探索方法，通过此方法能够训练出平滑且准确的非抓取平面操作控制器。此方法能够捕捉任务的混合动力学特性，解决了之前使用的单模态探索策略无法实现准确性和平滑轨迹的问题。

    

    开发能够实现灵巧的非抓取平面操作的机器人控制器是具有挑战性的。问题的欠驱动和混合动力学特性，再加上摩擦力交互所产生的不确定性，需要复杂的控制行为。强化学习（RL）是开发此类机器人控制器的强大框架。然而，先前的RL文献解决非抓取推动任务时的准确性低、轨迹不平滑，并且仅实现简单的运动，即不旋转被操作的对象。我们推测之前使用的单模态探索策略无法捕捉任务的混合动力学特性，因为机器人和物体之间可能存在不同的接触交互模式，如粘着、滑动和分离。在这项工作中，我们提出了一种通过分类分布进行多模态探索的方法，使我们能够训练出平滑且准确的非抓取平面操作控制器。

    Developing robot controllers capable of achieving dexterous nonprehensile manipulation, such as pushing an object on a table, is challenging. The underactuated and hybrid-dynamics nature of the problem, further complicated by the uncertainty resulting from the frictional interactions, requires sophisticated control behaviors. Reinforcement Learning (RL) is a powerful framework for developing such robot controllers. However, previous RL literature addressing the nonprehensile pushing task achieves low accuracy, non-smooth trajectories, and only simple motions, i.e. without rotation of the manipulated object. We conjecture that previously used unimodal exploration strategies fail to capture the inherent hybrid-dynamics of the task, arising from the different possible contact interaction modes between the robot and the object, such as sticking, sliding, and separation. In this work, we propose a multimodal exploration approach through categorical distributions, which enables us to train p
    
[^7]: 研究Federated Machine Learning在实际领域中的应用现状

    SoK: Assessing the State of Applied Federated Machine Learning. (arXiv:2308.02454v1 [cs.LG])

    [http://arxiv.org/abs/2308.02454](http://arxiv.org/abs/2308.02454)

    本研究评估了Federated Machine Learning（FedML）在实际应用中的现状，并发现了阻碍其实际应用的挑战。

    

    机器学习在各种应用中展现了巨大的潜力；然而，由于对数据隐私的担忧，它在需要保护隐私的领域的应用受到了限制。Federated Machine Learning（FedML）是解决这个问题的一种有希望的解决方案，它是一种面向数据的模型方法，更加重视数据隐私。通过使机器学习算法直接应用于分布式数据源而不共享原始数据，FedML提供了增强隐私保护，适用于需要保护隐私的环境。尽管在理论上具有显著优势，FedML在实践中并没有得到广泛应用。本研究旨在探索应用FedML的当前状态，并确定阻碍其实际应用的挑战。通过全面系统的文献回顾，我们评估了74篇相关论文，分析了FedML在实际应用中的可行性。我们的分析关注FedML实现的特征和新兴趋势，以及驱动力和应用方面的动机。

    Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application
    
[^8]: 对高阶SDE模拟的Lévy区域进行生成建模

    Generative Modelling of L\'{e}vy Area for High Order SDE Simulation. (arXiv:2308.02452v1 [stat.ML])

    [http://arxiv.org/abs/2308.02452](http://arxiv.org/abs/2308.02452)

    本文提出了一种基于深度学习的模型LévyGAN，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩，解决了非高斯性质下的抽样困难问题。

    

    众所周知，当数值模拟SDE的解时，要实现强收敛速率超过O(\sqrt{h})（其中h为步长），需要使用某些布朗运动的迭代积分，通常称为其“Lévy区域”。然而，由于其非高斯性质，对于d维布朗运动（d>2），目前没有快速近似抽样算法。本文提出了LévyGAN，一种基于深度学习的模型，用于生成条件于布朗增量的Lévy区域的近似样本。通过“桥翻转”操作，输出的样本可以精确匹配所有奇数阶矩。我们的生成器采用经过量身定制的GNN-inspired架构，强制输出分布与条件变量之间的正确依赖结构。此外，我们还结合了基于特征函数的数学原理的判别性归一化操作。

    It is well known that, when numerically simulating solutions to SDEs, achieving a strong convergence rate better than O(\sqrt{h}) (where h is the step size) requires the use of certain iterated integrals of Brownian motion, commonly referred to as its "L\'{e}vy areas". However, these stochastic integrals are difficult to simulate due to their non-Gaussian nature and for a d-dimensional Brownian motion with d > 2, no fast almost-exact sampling algorithm is known.  In this paper, we propose L\'{e}vyGAN, a deep-learning-based model for generating approximate samples of L\'{e}vy area conditional on a Brownian increment. Due to our "Bridge-flipping" operation, the output samples match all joint and conditional odd moments exactly. Our generator employs a tailored GNN-inspired architecture, which enforces the correct dependency structure between the output distribution and the conditioning variable. Furthermore, we incorporate a mathematically principled characteristic-function based discrim
    
[^9]: 使用贝叶斯推断修剪神经网络

    Pruning a neural network using Bayesian inference. (arXiv:2308.02451v1 [stat.ML])

    [http://arxiv.org/abs/2308.02451](http://arxiv.org/abs/2308.02451)

    使用贝叶斯推断修剪神经网络的新方法可以实现理想的稀疏程度，同时保持竞争力的准确性。

    

    神经网络修剪是一种非常有效的技术，旨在减少大型神经网络的计算和内存需求。在这篇研究论文中，我们提出了一种利用贝叶斯推断修剪神经网络的新方法，它可以无缝地集成到训练过程中。我们提出的方法利用修剪前后的神经网络的后验概率，从而计算贝叶斯因子。计算的贝叶斯因子指导着迭代修剪过程。通过对多个基准进行全面评估，我们证明了我们的方法在保持竞争力的准确性的同时实现了理想的稀疏程度。

    Neural network pruning is a highly effective technique aimed at reducing the computational and memory demands of large neural networks. In this research paper, we present a novel approach to pruning neural networks utilizing Bayesian inference, which can seamlessly integrate into the training procedure. Our proposed method leverages the posterior probabilities of the neural network prior to and following pruning, enabling the calculation of Bayes factors. The calculated Bayes factors guide the iterative pruning. Through comprehensive evaluations conducted on multiple benchmarks, we demonstrate that our method achieves desired levels of sparsity while maintaining competitive accuracy.
    
[^10]: 从军事到医疗保健：采纳和扩展用于生成式人工智能的伦理原则

    From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence. (arXiv:2308.02448v1 [cs.CY])

    [http://arxiv.org/abs/2308.02448](http://arxiv.org/abs/2308.02448)

    这项研究探讨了从军事到医疗保健领域采纳和扩展伦理原则以应用生成式人工智能的可行性和重要性。

    

    在2020年，美国国防部正式公布了一套指导未来战场上人工智能技术使用的伦理原则。尽管存在明显差异，但军事和医疗服务之间存在核心的相似之处。战场上的战士经常面临需要快速决策的改变生活的情况。医疗服务提供者在快速变化的医疗环境中也面临类似的挑战，例如在急诊科或治疗危及生命的状况下进行手术。生成式人工智能是一种新兴技术，旨在高效生成有价值的信息，具有巨大潜力。随着计算能力的日益普及和大量的健康数据（如电子健康记录、心电图和医学图像）的增加，医疗保健领域必将被这项技术革命化。最近，生成式人工智能在研究界引起了广泛关注，引发了关于其伦理问题的讨论。

    In 2020, the U.S. Department of Defense officially disclosed a set of ethical principles to guide the use of Artificial Intelligence (AI) technologies on future battlefields. Despite stark differences, there are core similarities between the military and medical service. Warriors on battlefields often face life-altering circumstances that require quick decision-making. Medical providers experience similar challenges in a rapidly changing healthcare environment, such as in the emergency department or during surgery treating a life-threatening condition. Generative AI, an emerging technology designed to efficiently generate valuable information, holds great promise. As computing power becomes more accessible and the abundance of health data, such as electronic health records, electrocardiograms, and medical images, increases, it is inevitable that healthcare will be revolutionized by this technology. Recently, generative AI has captivated the research community, leading to debates about 
    
[^11]: 使用分布感知的自适应优先级附加kNN图

    Adaptive Preferential Attached kNN Graph With Distribution-Awareness. (arXiv:2308.02442v1 [cs.LG])

    [http://arxiv.org/abs/2308.02442](http://arxiv.org/abs/2308.02442)

    本文提出了一种名为paNNG的算法，它结合了自适应kNN和基于分布的图构建。通过包含分布信息，paNNG能够有效提升模糊样本的性能，并实现更好的准确性和泛化能力。

    

    基于图的kNN算法因其简单性和有效性在机器学习任务中广受欢迎。然而，传统的kNN图对于k值的固定依赖可能会影响其性能，特别是在涉及复杂数据分布的情况下。此外，与其他分类模型类似，决策边界上存在的模糊样本常常是一个挑战，因为它们更容易被错误分类。为了解决这些问题，我们提出了优先级附加k-最近邻图（paNNG），它将自适应的kNN与基于分布的图构建相结合。通过结合分布信息，paNNG可以显著提高模糊样本的性能，通过“拉”它们回到原始类别，从而实现改进的整体准确性和泛化能力。通过在多样化的基准数据集上进行严格评估，paNNG的性能超越了现有算法，展示了它的优越性。

    Graph-based kNN algorithms have garnered widespread popularity for machine learning tasks, due to their simplicity and effectiveness. However, the conventional kNN graph's reliance on a fixed value of k can hinder its performance, especially in scenarios involving complex data distributions. Moreover, like other classification models, the presence of ambiguous samples along decision boundaries often presents a challenge, as they are more prone to incorrect classification. To address these issues, we propose the Preferential Attached k-Nearest Neighbors Graph (paNNG), which combines adaptive kNN with distribution-based graph construction. By incorporating distribution information, paNNG can significantly improve performance for ambiguous samples by "pulling" them towards their original classes and hence enable enhanced overall accuracy and generalization capability. Through rigorous evaluations on diverse benchmark datasets, paNNG outperforms state-of-the-art algorithms, showcasing its 
    
[^12]: 便携式脑电图中的噪音去除方法：一项调查

    Noise removal methods on ambulatory EEG: A Survey. (arXiv:2308.02437v1 [eess.SP])

    [http://arxiv.org/abs/2308.02437](http://arxiv.org/abs/2308.02437)

    本文综述了便携式脑电图中噪音的检测和去除方法，发现模式识别对于区分不同条件下的脑电图数据非常重要。

    

    多年来，一直致力于便携式脑电图中噪音的去除研究。在这方面，已经发布了大量的研究论文来识别噪音去除方法，但是详细回顾所有这些文献是困难的。因此，在本文中，我们试图综述噪音的检测和去除。我们讨论了100多篇研究论文，以识别检测和去除便携式脑电图的技术。进一步的文献综述表明，用于检测便携式脑电图的模式识别方法，比如眼睛闭合和睁开状态，因脑电图的条件不同而异。这主要是由于不同条件下检测到的脑电图具有不同的特征。因此，必须确定一种模式识别技术，以有效地区分脑电图噪音数据和各种脑电图数据的条件。

    Over many decades, research is being attempted for the removal of noise in the ambulatory EEG. In this respect, an enormous number of research papers is published for identification of noise removal, It is difficult to present a detailed review of all these literature. Therefore, in this paper, an attempt has been made to review the detection and removal of an noise. More than 100 research papers have been discussed to discern the techniques for detecting and removal the ambulatory EEG. Further, the literature survey shows that the pattern recognition required to detect ambulatory method, eye open and close, varies with different conditions of EEG datasets. This is mainly due to the fact that EEG detected under different conditions has different characteristics. This is, in turn, necessitates the identification of pattern recognition technique to effectively distinguish EEG noise data from a various condition of EEG data.
    
[^13]: 基于对比自监督学习的患者相似性研究方法：以心房颤动的检测为例

    Contrastive Self-Supervised Learning Based Approach for Patient Similarity: A Case Study on Atrial Fibrillation Detection from PPG Signal. (arXiv:2308.02433v1 [eess.SP])

    [http://arxiv.org/abs/2308.02433](http://arxiv.org/abs/2308.02433)

    提出了一种基于对比学习的深度学习框架，用于通过生理信号检测心房颤动(AF)。该框架能够学习相似嵌入并确定最相似的患者。在超过170名个体的数据集上进行了实验，并与其他基线方法进行了比较。

    

    本文提出了一种基于对比学习的深度学习框架，用于使用生理信号进行患者相似性搜索。我们使用对比学习的方法来学习具有相似生理信号数据的患者的相似嵌入。我们还引入了一些邻居选择算法，以确定生成的嵌入中具有最高相似性的患者。为了验证我们的框架用于测量患者相似性的有效性，我们选择使用从智能手表设备获取的光电容抗图信号进行心房颤动(AF)的检测作为我们的案例研究。我们对超过170名个体的数据集上的我们的框架进行了广泛的实验，并将其与该数据集上的其他基线方法的性能进行了比较。

    In this paper, we propose a novel contrastive learning based deep learning framework for patient similarity search using physiological signals. We use a contrastive learning based approach to learn similar embeddings of patients with similar physiological signal data. We also introduce a number of neighbor selection algorithms to determine the patients with the highest similarity on the generated embeddings. To validate the effectiveness of our framework for measuring patient similarity, we select the detection of Atrial Fibrillation (AF) through photoplethysmography (PPG) signals obtained from smartwatch devices as our case study. We present extensive experimentation of our framework on a dataset of over 170 individuals and compare the performance of our framework with other baseline methods on this dataset.
    
[^14]: 解锁相似性匹配的潜力：可扩展性、监督和预训练

    Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training. (arXiv:2308.02427v1 [cs.NE])

    [http://arxiv.org/abs/2308.02427](http://arxiv.org/abs/2308.02427)

    本研究提出了一种基于相似性匹配的学习模式，通过使用PyTorch实现了扩展到大型数据集的卷积非负相似性匹配，引入了局部监督的SM目标，以及利用PyTorch实现预训练网络结构的特征评估对比。这将生物学合理性的算法与计算成本相结合，提供了一种在线、本地化且具有生物学合理性的学习方法。

    

    尽管有效，反向传播算法在生物合理性、计算成本和在线学习适应性方面存在局限性。因此，人们对于基于局部学习规则的可替代生物学合理性学习方法越来越感兴趣。本研究重点研究了主要是非监督的相似性匹配(SM)框架，该框架与生物系统中观察到的机制相一致，并提供了在线、本地化和生物学上合理的算法。i) 为了将相似性匹配(SM)扩展到大型数据集，我们提出了使用PyTorch的卷积非负SM的实现。ii) 我们引入了一种类似于典型相关性分析的局部监督SM目标，便于堆叠SM层。iii) 我们利用PyTorch实现预训练网络结构，如LeNet，并将其特征评估与反向传播训练的模型进行比较。本研究将具有生物合理性的算法与计算成本相结合

    While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computationa
    
[^15]: 从高维脉搏波信号中检测高血压

    Hypertension Detection From High-Dimensional Representation of Photoplethysmogram Signals. (arXiv:2308.02425v1 [eess.SP])

    [http://arxiv.org/abs/2308.02425](http://arxiv.org/abs/2308.02425)

    本论文提出了一种基于随机卷积核的高维表示技术，用于从脉搏波信号中检测高血压。实验结果表明，这一方法不仅局限于心率和血压，展示了高血压检测的普适性。

    

    高血压常被称为“沉默杀手”，因为它可能导致严重的健康并发症，却没有任何明显症状。早期发现高血压在预防重大健康问题方面至关重要。尽管一些研究表明血压与某些重要信号（如脉搏波）之间存在关联，但目前尚无可靠的提取血压估计方法进行普适性泛化。这种不确定性使得一些研究对这种关系的存在产生怀疑，或者认为它们仅限于心率和血压。本文提出了一种基于随机卷积核的高维表示技术，用于使用脉搏波信号进行高血压检测。结果表明，这种关系不仅限于心率和血压，证明了使用泛化性的高血压检测的可行性。另外，使用卷积核进行变换的方法也是可行的。

    Hypertension is commonly referred to as the "silent killer", since it can lead to severe health complications without any visible symptoms. Early detection of hypertension is crucial in preventing significant health issues. Although some studies suggest a relationship between blood pressure and certain vital signals, such as Photoplethysmogram (PPG), reliable generalization of the proposed blood pressure estimation methods is not yet guaranteed. This lack of certainty has resulted in some studies doubting the existence of such relationships, or considering them weak and limited to heart rate and blood pressure. In this paper, a high-dimensional representation technique based on random convolution kernels is proposed for hypertension detection using PPG signals. The results show that this relationship extends beyond heart rate and blood pressure, demonstrating the feasibility of hypertension detection with generalization. Additionally, the utilized transform using convolution kernels, a
    
[^16]: 基于跳步长度可微分的短时傅里叶变换

    Differentiable short-time Fourier transform with respect to the hop length. (arXiv:2308.02421v1 [eess.SP])

    [http://arxiv.org/abs/2308.02421](http://arxiv.org/abs/2308.02421)

    本文提出了一种基于跳步长度可微分的短时傅里叶变换，通过使跳步长度连续，实现了梯度优化的时间定位控制，提供了更好的优化效果和更高的计算效率。该方法可以轻松集成到现有算法和神经网络中。

    

    在本文中，我们提出了一种基于跳步长度可微分的短时傅里叶变换（STFT），通过使这些参数连续，使跳步长度或帧时间位置可以基于梯度进行优化。我们的方法提供了对帧的时间定位更好的控制，因为跳步长度的连续性允许进行更精细的优化。此外，我们的贡献还可以使用诸如梯度下降之类的优化方法，这些方法比传统的离散优化方法更加高效。我们的可微分STFT也可以轻松集成到现有的算法和神经网络中。我们展示了一个模拟实例，以展示我们方法的有效性，并引起研究界的兴趣。

    In this paper, we propose a differentiable version of the short-time Fourier transform (STFT) that allows for gradient-based optimization of the hop length or the frame temporal position by making these parameters continuous. Our approach provides improved control over the temporal positioning of frames, as the continuous nature of the hop length allows for a more finely-tuned optimization. Furthermore, our contribution enables the use of optimization methods such as gradient descent, which are more computationally efficient than conventional discrete optimization methods. Our differentiable STFT can also be easily integrated into existing algorithms and neural networks. We present a simulated illustration to demonstrate the efficacy of our approach and to garner interest from the research community.
    
[^17]: P=主ioio：基于设备的实时智能手机自动健身动作重复计数系统中文标题

    P\=uioio: On-device Real-Time Smartphone-Based Automated Exercise Repetition Counting System. (arXiv:2308.02420v1 [eess.SP])

    [http://arxiv.org/abs/2308.02420](http://arxiv.org/abs/2308.02420)

    本研究探索了基于智能手机的实时健身动作重复计数系统，在提供了最新研究成果概述后，引入了一个由五个组件构成的深度学习系统，并通过名为P=主ioio的移动应用实现。该系统利用智能手机摄像头实时跟踪标准健身动作的重复次数。英文要点为：This study explored a real-time smartphone-based exercise repetition counting system, introduced a deep learning system consisting of five components, and implemented it through a mobile application named P=主ioio that uses the smartphone camera to track repetitions in real time for standard exercises.

    

    自动健身动作重复计数在健康到康复等各个方面都有应用。鉴于手机的普及性和跟踪身体活动的好处，本研究探索了仅使用手机设备推断实时计数健身动作的可行性。在本工作中，我们首先广泛概述了自动健身动作重复计数方法的最新研究成果，然后介绍了一种基于深度学习的智能手机健身动作重复计数系统，包括五个组件：（1）姿势估计，（2）阈值分割，（3）光流，（4）状态机和（5）计数器。然后，该系统通过一款跨平台移动应用程序P=主ioio实现，在实时跟踪标准健身动作（深蹲、俯卧撑和引体向上）的过程中只使用智能手机摄像头。通过对预先录制的个体锻炼视频进行数据集评估。

    Automated exercise repetition counting has applications across the physical fitness realm, from personal health to rehabilitation. Motivated by the ubiquity of mobile phones and the benefits of tracking physical activity, this study explored the feasibility of counting exercise repetitions in real-time, using only on-device inference, on smartphones. In this work, after providing an extensive overview of the state-of-the-art automatic exercise repetition counting methods, we introduce a deep learning based exercise repetition counting system for smartphones consisting of five components: (1) Pose estimation, (2) Thresholding, (3) Optical flow, (4) State machine, and (5) Counter. The system is then implemented via a cross-platform mobile application named P\=uioio that uses only the smartphone camera to track repetitions in real time for three standard exercises: Squats, Push-ups, and Pull-ups. The proposed system was evaluated via a dataset of pre-recorded videos of individuals exercis
    
[^18]: 在帕金森病中用于检测药物使用的多模态室内定位：在自由生活环境中的观察性试验

    Multimodal Indoor Localisation in Parkinson's Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting. (arXiv:2308.02419v1 [eess.SP])

    [http://arxiv.org/abs/2308.02419](http://arxiv.org/abs/2308.02419)

    该研究提出了一种基于变压器的方法，使用穿戴设备的RSSI和加速度计数据进行室内定位，以改善当前方法的有效性。研究还探讨了室内定位是否可以通过检测帕金森病患者的药物使用情况来评估运动波动。

    

    帕金森病（PD）是一种缓慢进展的神经退行性疾病，导致包括步态障碍在内的运动症状。运动波动是指在左多巴疗法（“开”）和PD症状再度出现（“关”）之间的变化，因药物效果减退而引起。这些波动经常影响步态速度，并随着PD进展而增加其致残影响。为了提高当前室内定位方法的有效性，提出了一种基于变压器的方法，利用可穿戴设备的接收信号强度指示器（RSSI）和加速度计数据提供互补的运动视角。一个次目标旨在评估室内定位，包括其家庭步态速度特征（即在房间之间行走所需的时间），是否可以用于通过检测帕金森病患者是否正在使用左多巴药物或患者是否停用药物来评估运动波动。

    Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withhold
    
[^19]: 基于梯度的可微分自适应短时傅里叶变换

    Differentiable adaptive short-time Fourier transform with respect to the window length. (arXiv:2308.02418v1 [eess.SP])

    [http://arxiv.org/abs/2308.02418](http://arxiv.org/abs/2308.02418)

    本文提出了一种基于梯度的方法，用于实时优化短时傅里叶变换（STFT）的帧间和频率间窗长。生成的可微分自适应STFT具有出色的特性，可以适应瞬态和稳态成分，并且易于优化。

    

    本文提出了一种基于梯度的方法，用于实时优化短时傅里叶变换（STFT）的帧间和频率间窗长，与我们之前开发的将窗长变为连续参数的可微分版本的STFT相关。生成的可微分自适应STFT具有出色的特性，例如在同一时频表示中适应瞬态和稳态成分，同时可以通过梯度下降轻松进行优化。我们在振动分析中验证了该方法的性能。

    This paper presents a gradient-based method for on-the-fly optimization for both per-frame and per-frequency window length of the short-time Fourier transform (STFT), related to previous work in which we developed a differentiable version of STFT by making the window length a continuous parameter. The resulting differentiable adaptive STFT possesses commendable properties, such as the ability to adapt in the same time-frequency representation to both transient and stationary components, while being easily optimized by gradient descent. We validate the performance of our method in vibration analysis.
    
[^20]: 本地-全局时间融合网络结合注意机制用于多类和多种心律失常分类

    Local-Global Temporal Fusion Network with an Attention Mechanism for Multiple and Multiclass Arrhythmia Classification. (arXiv:2308.02416v1 [eess.SP])

    [http://arxiv.org/abs/2308.02416](http://arxiv.org/abs/2308.02416)

    本文提出了一个本地-全局时间融合网络结合注意机制的框架，用于针对心律失常的检测和分类任务。该方法通过提取本地时间信息和全局模式，并使用注意力机制进行本地-全局信息融合，以处理长度变化的心律失常数据。实验结果表明，此方法在心律失常分类任务上的性能优于现有方法。

    

    临床决策支持系统（CDSSs）已被广泛应用于支持心电图（ECGs）中心血管科医生检测和分类心律失常时所做的决策。然而，由于心律失常长度的变化，形成一个针对心律失常分类任务的CDSS是具有挑战性的。虽然心律失常的发作时间是变化的，但之前开发的方法没有考虑到这些条件。因此，我们提出了一个框架，包括（i）本地时间信息提取，（ii）全局模式提取，和（iii）带有注意力的本地-全局信息融合，以实现对有限输入长度的心律失常检测和分类。我们的方法通过检测心律失常起始和结束时间作为一个事件，以及基于MIT-BIH心律失常数据库（MITDB）和MIT-BIH房颤数据库（AFDB）的心律失常持续时间来评估10类和4类表现。结果在统计上优于现有方法。

    Clinical decision support systems (CDSSs) have been widely utilized to support the decisions made by cardiologists when detecting and classifying arrhythmia from electrocardiograms (ECGs). However, forming a CDSS for the arrhythmia classification task is challenging due to the varying lengths of arrhythmias. Although the onset time of arrhythmia varies, previously developed methods have not considered such conditions. Thus, we propose a framework that consists of (i) local temporal information extraction, (ii) global pattern extraction, and (iii) local-global information fusion with attention to perform arrhythmia detection and classification with a constrained input length. The 10-class and 4-class performances of our approach were assessed by detecting the onset and offset of arrhythmia as an episode and the duration of arrhythmia based on the MIT-BIH arrhythmia database (MITDB) and MIT-BIH atrial fibrillation database (AFDB), respectively. The results were statistically superior to 
    
[^21]: 基于WiFi CSI的自监督学习的人体活动识别：系统性研究

    Self-Supervised Learning for WiFi CSI-Based Human Activity Recognition: A Systematic Study. (arXiv:2308.02412v1 [eess.SP])

    [http://arxiv.org/abs/2308.02412](http://arxiv.org/abs/2308.02412)

    本研究对基于WiFi CSI的人体活动识别进行了自监督学习，提出了一种解决深度学习中数据不足的方法。通过将深度学习技术与CSI数据相结合，实现了最先进的性能，无需专家知识。研究人员通过分析不同类型的自监督学习算法的潜力，对缺乏标记CSI数据的挑战进行了全面的整理和分析。

    

    最近，随着物联网（IoT）的发展，基于WiFi CSI的人体活动识别(HAR)引起了学术界和工业界的越来越多的关注。通过将深度学习技术与基于CSI的HAR相结合，研究人员在不需要专家知识的情况下实现了最先进的性能。然而，在基于CSI的HAR的背景下，标记CSI数据的稀缺性仍然是应用深度学习模型时最突出的挑战，这是由于CSI数据的隐私性和不可理解性。另一方面，自监督学习（SSL）作为一种在不重视标记示例的情况下从数据中学习有意义表示的有前途的方法已经出现。因此，通过利用SSL算法来解决深度学习中数据不足的挑战已经做出了相当大的努力。在本文中，我们对不同类型的SSL算法的潜力进行了全面的整理和分析，包括以前研究过的算法和那些还没有得到广泛研究的算法。

    Recently, with the advancement of the Internet of Things (IoT), WiFi CSI-based HAR has gained increasing attention from academic and industry communities. By integrating the deep learning technology with CSI-based HAR, researchers achieve state-of-the-art performance without the need of expert knowledge. However, the scarcity of labeled CSI data remains the most prominent challenge when applying deep learning models in the context of CSI-based HAR due to the privacy and incomprehensibility of CSI-based HAR data. On the other hand, SSL has emerged as a promising approach for learning meaningful representations from data without heavy reliance on labeled examples. Therefore, considerable efforts have been made to address the challenge of insufficient data in deep learning by leveraging SSL algorithms. In this paper, we undertake a comprehensive inventory and analysis of the potential held by different categories of SSL algorithms, including those that have been previously studied and tho
    
[^22]: 采用混合无线数据融合的RFID辅助室内定位

    RFID-Assisted Indoor Localization Using Hybrid Wireless Data Fusion. (arXiv:2308.02410v1 [eess.SP])

    [http://arxiv.org/abs/2308.02410](http://arxiv.org/abs/2308.02410)

    本文提出了一种基于射频识别和多种物联网无线技术的混合室内定位方法，通过仅在各区块边界安装RFID标签来降低成本，并通过不同无线技术的线性位置估计实现了室内物体定位。

    

    无线定位在室内环境中跟踪物体是至关重要的。物联网通过其多样的无线通信协议实现定位。本文提出了一种使用自开发的射频识别（RFID）跟踪设备和多个物联网无线技术的混合基于区块的室内定位方法。为了降低RFID标签的成本，标签仅安装在每个区块的边界上。RFID跟踪设备识别区块，提出的混合方法找到区块内物体的位置。该混合方法通过不同物联网无线技术获得的线性位置估计进行分析。使用开发的RFID跟踪设备和基于RSSI的蓝牙、WiFi和ZigBee技术的定位的实验结果验证了分析结果。

    Wireless localization is essential for tracking objects in indoor environments. Internet of Things (IoT) enables localization through its diverse wireless communication protocols. In this paper, a hybrid section-based indoor localization method using a developed Radio Frequency Identification (RFID) tracking device and multiple IoT wireless technologies is proposed. In order to reduce the cost of the RFID tags, the tags are installed only on the borders of each section. The RFID tracking device identifies the section, and the proposed wireless hybrid method finds the location of the object inside the section. The proposed hybrid method is analytically driven by linear location estimates obtained from different IoT wireless technologies. The experimental results using developed RFID tracking device and RSSI-based localization for Bluetooth, WiFi and ZigBee technologies verifies the analytical results.
    
[^23]: 通过融合多空间深度模型的脑电信号来估计心理负荷

    Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models. (arXiv:2308.02409v1 [eess.SP])

    [http://arxiv.org/abs/2308.02409](http://arxiv.org/abs/2308.02409)

    该论文通过融合多个空间维度的方法，使用脑电信号对心理负荷进行分类和估计连续级别。在时间域中使用了时态卷积网络，而在频率域中引入了新的架构——多维残差块。

    

    人脑在工作和休息时都处于持续活动的状态。心理活动是日常过程中的一部分，当大脑过度劳累时，会对人体健康产生负面影响。近年来，人们对于早期检测心理健康问题的重视逐渐增加，因为这可以帮助预防严重的健康问题，并改善生活质量。多种信号被用于评估心理状态，但由于大量提供关于大脑信息的特点，脑电图（EEG）被研究人员广泛使用。本文旨在将心理负荷分为三种状态并估计连续级别。我们的方法通过融合多个空间维度来实现最佳的心理估计结果。在时间域方法中，我们使用了时态卷积网络，而在频率域上，我们提出了一种名为多维残差块的新架构，它结合了残差块。

    The human brain is in a continuous state of activity during both work and rest. Mental activity is a daily process, and when the brain is overworked, it can have negative effects on human health. In recent years, great attention has been paid to early detection of mental health problems because it can help prevent serious health problems and improve quality of life. Several signals are used to assess mental state, but the electroencephalogram (EEG) is widely used by researchers because of the large amount of information it provides about the brain. This paper aims to classify mental workload into three states and estimate continuum levels. Our method combines multiple dimensions of space to achieve the best results for mental estimation. In the time domain approach, we use Temporal Convolutional Networks, and in the frequency domain, we propose a new architecture called the Multi-Dimensional Residual Block, which combines residual blocks.
    
[^24]: 通过迁移学习评估认知任务的结构

    Evaluating the structure of cognitive tasks with transfer learning. (arXiv:2308.02408v1 [eess.SP])

    [http://arxiv.org/abs/2308.02408](http://arxiv.org/abs/2308.02408)

    本研究通过迁移学习探索了在脑电图解码任务中，不同任务之间深度学习表征的可迁移性，并展示了即使是线性探测转移，也可以显著提高解码性能，相较于纯监督方法，改进幅度高达28%。

    

    由于标记数据有限，脑电图（EEG）解码是一项具有挑战性的任务。虽然迁移学习是解决这一挑战的一种有前景的技术，但它假设可传递的数据领域和任务是已知的，而在这个设置中并非如此。本研究调查了不同EEG解码任务之间深度学习表示的可迁移性。我们使用最先进的解码模型对最近发布的ERP CORE和M$^3$CV两个EEG数据集进行了大量实验，这两个数据集包含超过140个受试者和11个不同的认知任务。我们通过在一个任务上对深度神经网络进行预训练，并评估它们解码后续任务的能力，来衡量学到的表示的可迁移性。我们的实验表明，即使是线性探测转移，也可以获得显著的解码性能改进，相较于纯监督方法，改进幅度高达28%。此外，我们发现了证据证明...

    Electroencephalography (EEG) decoding is a challenging task due to the limited availability of labelled data. While transfer learning is a promising technique to address this challenge, it assumes that transferable data domains and task are known, which is not the case in this setting. This study investigates the transferability of deep learning representations between different EEG decoding tasks. We conduct extensive experiments using state-of-the-art decoding models on two recently released EEG datasets, ERP CORE and M$^3$CV, containing over 140 subjects and 11 distinct cognitive tasks. We measure the transferability of learned representations by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks. Our experiments demonstrate that, even with linear probing transfer, significant improvements in decoding performance can be obtained, with gains of up to 28% compare with the pure supervised approach. Additionally, we discover evidence tha
    
[^25]: 从稀疏IMU感测中高效准确地进行人体姿势估计的设计空间探索

    Design Space Exploration on Efficient and Accurate Human Pose Estimation from Sparse IMU-Sensing. (arXiv:2308.02397v1 [eess.SP])

    [http://arxiv.org/abs/2308.02397](http://arxiv.org/abs/2308.02397)

    本论文通过模拟情况下的设计空间探索，研究了人体姿势估计中精度和硬件资源之间的折衷，提出了利用IMU感测进行高效准确的人体姿势估计的方法。

    

    鉴于敏感的个人数据，对于评估运动、康复或工作安全中的人体运动的人体姿势估计（HPE），需要准确的感测。因此，本地处理是必要的，并且在此类系统中，有限的能源预算可以通过使用惯性测量单元（IMU）而不是常见的相机感测来解决。研究中很少讨论精度和硬件资源的有效利用之间的核心折衷。我们通过模拟情况下的设计空间探索来解决这个折衷问题，它涉及不同的IMU传感器数量和摆放位置。首先，我们使用公开可用的人体模型数据集为不同的传感器配置生成IMU数据，并用这些数据训练深度学习模型。此外，我们提出了一个组合度量来评估精度和资源利用的折衷。我们将设计空间探索用作评估传感器配置并确定特定用例的有益配置的工具。例如，对于一个同等重要性的系统...

    Human Pose Estimation (HPE) to assess human motion in sports, rehabilitation or work safety requires accurate sensing without compromising the sensitive underlying personal data. Therefore, local processing is necessary and the limited energy budget in such systems can be addressed by Inertial Measurement Units (IMU) instead of common camera sensing. The central trade-off between accuracy and efficient use of hardware resources is rarely discussed in research. We address this trade-off by a simulative Design Space Exploration (DSE) of a varying quantity and positioning of IMU-sensors. First, we generate IMU-data from a publicly available body model dataset for different sensor configurations and train a deep learning model with this data. Additionally, we propose a combined metric to assess the accuracy-resource trade-off. We used the DSE as a tool to evaluate sensor configurations and identify beneficial ones for a specific use case. Exemplary, for a system with equal importance of ac
    
[^26]: HOOD: 实时稳健的低成本FMCW雷达人员存在和离群检测

    HOOD: Real-Time Robust Human Presence and Out-of-Distribution Detection with Low-Cost FMCW Radar. (arXiv:2308.02396v1 [eess.SP])

    [http://arxiv.org/abs/2308.02396](http://arxiv.org/abs/2308.02396)

    本文提出了一种名为HOOD的实时稳健的人员存在和离群检测方法，通过利用低成本的60 GHz FMCW雷达实现。该方法可同时解决存在检测和离群检测问题，通过重构架构和雷达图像实现准确检测人类存在，同时在人类不存在时检测移动或静止干扰物。

    

    在室内环境中使用毫米波频率调制连续波（FMCW）雷达进行人员存在检测是具有挑战性的，主要是因为室内空间中存在移动和静止的杂波。本文提出了一种名为“HOOD”的实时稳健的人员存在和离群检测方法，通过利用60 GHz短距离FMCW雷达。我们将存在检测应用视为离群检测问题，并使用单一流程同时解决这两个问题。我们的解决方案依赖于基于重构的架构，并使用雷达宏观和微观范围-Doppler图像（RDI）。HOOD旨在在存在或不存在移动和静止干扰物的情况下准确检测人类的“存在”。由于它也是一个离群检测器，它旨在将移动或静止杂波作为人类不存在的离群检测，并将当前场景的输出预测为“无人存在”。HOOD是一种无需任何活动的方法，适用于不同的人类场景。

    Human presence detection in indoor environments using millimeter-wave frequency-modulated continuous-wave (FMCW) radar is challenging due to the presence of moving and stationary clutters in indoor places. This work proposes "HOOD" as a real-time robust human presence and out-of-distribution (OOD) detection method by exploiting 60 GHz short-range FMCW radar. We approach the presence detection application as an OOD detection problem and solve the two problems simultaneously using a single pipeline. Our solution relies on a reconstruction-based architecture and works with radar macro and micro range-Doppler images (RDIs). HOOD aims to accurately detect the "presence" of humans in the presence or absence of moving and stationary disturbers. Since it is also an OOD detector, it aims to detect moving or stationary clutters as OOD in humans' absence and predicts the current scene's output as "no presence." HOOD is an activity-free approach that performs well in different human scenarios. On 
    
[^27]: 使用深度卷积神经网络和Gramm角度场的ECG分类研究

    ECG classification using Deep CNN and Gramian Angular Field. (arXiv:2308.02395v1 [eess.SP])

    [http://arxiv.org/abs/2308.02395](http://arxiv.org/abs/2308.02395)

    本文介绍了一种使用深度卷积神经网络和Gramm角度场的ECG分类方法，通过将时间频率1D向量转换为2D图像，并对转换后的ECG信号进行分类，达到了高准确率。该方法改善了分类性能，同时还有助于识别和可视化ECG信号中的时域模式，在心血管疾病诊断和治疗以及异常检测方面具有重要意义。

    

    本文通过引入一种新的特征表示方法，即Gramm角度场变换，为ECG信号分析的信号处理和深度学习领域提供了一项创新贡献。所提出的方法是将时间频率1D向量转换为2D图像，然后使用卷积神经网络(CNN)对转换后的ECG信号进行分类。实验结果显示，异常检测的分类准确率达到了97.47%和98.65%。与最先进的方法相比，该特征表示方法不仅改善了分类性能，还有助于识别和可视化ECG信号中的时域模式，例如心率、节律和形态的变化，这在心血管疾病的诊断和治疗以及异常检测中具有重要意义。

    This paper study provides a novel contribution to the field of signal processing and DL for ECG signal analysis by introducing a new feature representation method for ECG signals. The proposed method is based on transforming time frequency 1D vectors into 2D images using Gramian Angular Field transform. Moving on, the classification of the transformed ECG signals is performed using Convolutional Neural Networks (CNN). The obtained results show a classification accuracy of 97.47% and 98.65% for anomaly detection. Accordingly, in addition to improving the classification performance compared to the state-of-the-art, the feature representation helps identify and visualize temporal patterns in the ECG signal, such as changes in heart rate, rhythm, and morphology, which may not be apparent in the original signal. This has significant implications in the diagnosis and treatment of cardiovascular diseases and detection of anomalies.
    
[^28]: 在部分可观察队列网络中学习最优入场控制

    Learning Optimal Admission Control in Partially Observable Queueing Networks. (arXiv:2308.02391v1 [cs.LG])

    [http://arxiv.org/abs/2308.02391](http://arxiv.org/abs/2308.02391)

    本文提出了一种在部分可观察队列网络中学习最优入场控制策略的高效强化学习算法，通过利用闭合产品形式队列网络的Norton等效定理和结构化的出生死亡过程 MDP 的高效强化学习算法，实现了对最大作业数量的亚线性遗憾。

    

    我们提出了一种高效的强化学习算法，用于在部分可观察的队列网络中学习最优入场控制策略。具体而言，只能观察到网络的到达和离开时间，并且优化指的是无限时域内的平均持有/拒绝成本。虽然在部分可观察的马尔可夫决策过程（POMDP）中进行强化学习通常是非常昂贵的，但我们展示了我们的算法的遗憾仅仅依赖于网络中作业数量的最大值S的亚线性函数。特别地，与现有的遗憾分析相比，我们的遗憾上界不依赖于底层马尔可夫决策过程（MDP）的直径，而在大多数队列系统中，这个直径至少是指数级的。

    We present an efficient reinforcement learning algorithm that learns the optimal admission control policy in a partially observable queueing network. Specifically, only the arrival and departure times from the network are observable, and optimality refers to the average holding/rejection cost in infinite horizon.  While reinforcement learning in Partially Observable Markov Decision Processes (POMDP) is prohibitively expensive in general, we show that our algorithm has a regret that only depends sub-linearly on the maximal number of jobs in the network, $S$. In particular, in contrast with existing regret analyses, our regret bound does not depend on the diameter of the underlying Markov Decision Process (MDP), which in most queueing systems is at least exponential in $S$.  The novelty of our approach is to leverage Norton's equivalent theorem for closed product-form queueing networks and an efficient reinforcement learning algorithm for MDPs with the structure of birth-and-death proces
    
[^29]: 《使用联合生存森林在医疗保健中扩展生存分析: 心力衰竭和乳腺癌基因组的比较研究》

    Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics. (arXiv:2308.02382v1 [cs.LG])

    [http://arxiv.org/abs/2308.02382](http://arxiv.org/abs/2308.02382)

    本研究针对医疗保健中生存数据的挑战，提出了FedSurF++算法，这是一种联合学习算法用于处理分布式的、具有隐私保密要求的生存分析。该算法可以大规模建模和处理生存数据，解决了数据稀缺和隐私保密的问题。

    

    生存分析是医学中的一种基本工具，用于对人群中发生感兴趣事件的时间进行建模。然而，在现实世界的应用中，生存数据通常是不完整、被审查、分布式和保密的，特别是在隐私保密至关重要的医疗保健环境中。数据稀缺严重限制了生存模型在依赖大型数据池的分布式应用中的可扩展性。联合学习是一种有望通过在多个数据集上训练机器学习模型而不损害用户隐私的技术，因此特别适合解决生存数据和大规模生存应用的挑战。尽管联合学习在分类和回归领域取得了重大发展，但在生存分析领域仍有许多未探索的方向。在本研究中，我们提出了联合生存森林算法的扩展，称为FedSurF++。这种联合集成方法可以对大规模生存数据进行建模并处理分布式情况。

    Survival analysis is a fundamental tool in medicine, modeling the time until an event of interest occurs in a population. However, in real-world applications, survival data are often incomplete, censored, distributed, and confidential, especially in healthcare settings where privacy is critical. The scarcity of data can severely limit the scalability of survival models to distributed applications that rely on large data pools. Federated learning is a promising technique that enables machine learning models to be trained on multiple datasets without compromising user privacy, making it particularly well-suited for addressing the challenges of survival data and large-scale survival applications. Despite significant developments in federated learning for classification and regression, many directions remain unexplored in the context of survival analysis. In this work, we propose an extension of the Federated Survival Forest algorithm, called FedSurF++. This federated ensemble method const
    
[^30]: 使用机器学习方法从探测车数据预测交通信号灯定时

    A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data. (arXiv:2308.02370v1 [cs.LG])

    [http://arxiv.org/abs/2308.02370](http://arxiv.org/abs/2308.02370)

    本文提出了使用机器学习方法从探测车数据预测交通信号灯定时的方法，利用XGBoost模型估计信号周期长度，利用神经网络模型确定红灯时间，并根据周期长度和红灯时间计算绿灯时间。结果显示，对信号周期长度的估计误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。

    

    交通信号灯在交通运输中起着重要作用，它们能够管理交通流量并确保交叉路口的安全。此外，了解交通信号灯的相位和定时数据可以实现最佳车辆行驶路线，提高时间和能源效率，进行生态驾驶以及准确模拟有信号的道路网络。本文提出了一种利用机器学习方法从车辆探测数据估计交通信号灯定时信息的方法。据作者所知，很少有研究利用机器学习技术从车辆探测数据确定交通信号灯定时参数的工作。在本研究中，我们开发了一种极限梯度增强（XGBoost）模型来估计信号周期长度，并利用神经网络模型从探测数据中确定相应的红灯时间。然后根据周期长度和红灯时间计算绿灯时间。我们的结果显示，信号周期长度的误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。

    Traffic signals play an important role in transportation by enabling traffic flow management, and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then be derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on ave
    
[^31]: 灵活的差分隐私垂直联邦学习与自适应特征嵌入

    Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings. (arXiv:2308.02362v1 [cs.CR])

    [http://arxiv.org/abs/2308.02362](http://arxiv.org/abs/2308.02362)

    本文提出了一种灵活的差分隐私垂直联邦学习方法（VFL），通过应用范数剪裁实现了严格的隐私保证，并通过自适应调整特征嵌入的尺度和分布来优化任务效用，而不损害隐私保护。

    

    垂直联邦学习（VFL）的出现引发了对隐私保护不完善的担忧，因为共享的特征嵌入可能在隐私攻击下泄露敏感信息。本文研究了VFL在差分隐私（DP）下数据隐私和任务效用目标之间的微妙平衡。为了解决现有技术的通用性问题，本文提出了一种灵活且通用的方法，将这两个目标分解并逐步解决。具体而言，我们首先通过对共享特征嵌入应用范数剪裁，得到了严格的隐私保证，该方法适用于各种数据集和模型。随后，我们证明通过对特征嵌入的尺度和分布进行自适应调整，以一种注重准确性的方式，可以优化任务效用，而不损害已建立的DP机制。我们将这一观察结果具体化为提出的VFL-AFE框架，该框架对抗了先验攻击，并显示出了有效性。

    The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against pri
    
[^32]: 基于积分的无强度积分化学能的学习

    Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])

    [http://arxiv.org/abs/2308.02360](http://arxiv.org/abs/2308.02360)

    该论文提出了一种基于积分的无强度积分化学能的学习框架IFIB，用于建模离散事件中具有分类或数值属性的事件标记。

    

    在标记的时间点过程（MTPP）中，一个核心问题是为条件联合概率密度函数（PDF）$p^*（m，t）$参数化插值时间t和标记m在历史条件下。现有研究大多预先定义强度函数。它们的实用性受到指定强度函数正确形式的挑战，这对于平衡表达能力和处理效率至关重要。最近，有研究摆脱预定义强度函数，一个模型$p^*（t）$和$p^*（m）$分开，另一个侧重于不考虑标记的时间点过程（TPP）。本研究旨在开发高保真度的$p^*（m，t）$，适用于事件标记在多维连续空间中具有分类或数值属性的离散事件。我们提出了一个解决方案框架IFIB（无强度积分化学能过程），直接建模条件联合概率密度函数$p^*（m，t）$。

    In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
    
[^33]: 适应变化：在动态数据环境中的强韧因果解释

    Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes. (arXiv:2308.02353v1 [cs.LG])

    [http://arxiv.org/abs/2308.02353](http://arxiv.org/abs/2308.02353)

    这项研究介绍了一种新颖的半监督图形因果解释器 (DyGRACE)，它通过学习数据表示并利用已知数据分布的初始知识，在动态数据环境中搜索有效的因果解释。该方法独立于底层预测模型。

    

    我们引入了一种新颖的半监督图形因果解释器 (GCE) 方法，称为动态图形因果解释器 (DyGRACE)。它利用已知数据分布的初始知识，在搜索有效的因果解释时避免使用潜在过时的决策函数的信息。DyGRACE利用两个图形自编码器 (GAE) 来学习二元分类问题中每个类的表示。GAE通过在训练过程中最小化原始图形与其学习表示之间的重建误差。该方法包括 (i) 通过最大化事实自编码器的重建误差来优化参数化密度函数 (实现为逻辑回归函数) ，以识别因果解释，(ii) 最小化因果自编码器的误差，(iii) 最大化事实图形与因果图形之间的相似性。这种半监督方法独立于基础黑盒预测模型。

    We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE) methodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages initial knowledge about the data distribution to search for valid counterfactuals while avoiding using information from potentially outdated decision functions in subsequent time steps. Employing two graph autoencoders (GAEs), DyGRACE learns the representation of each class in a binary classification scenario. The GAEs minimise the reconstruction error between the original graph and its learned representation during training. The method involves (i) optimising a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximising the factual autoencoder's reconstruction error, (ii) minimising the counterfactual autoencoder's error, and (iii) maximising the similarity between the factual and counterfactual graphs. This semi-supervised approach is independent of an underlying black-box oracle
    
[^34]: RobustMQ:评估量化模型鲁棒性的基准研究

    RobustMQ: Benchmarking Robustness of Quantized Models. (arXiv:2308.02350v1 [cs.LG])

    [http://arxiv.org/abs/2308.02350](http://arxiv.org/abs/2308.02350)

    该论文通过在ImageNet上全面评估了量化模型的鲁棒性，发现量化模型在对抗攻击方面更具鲁棒性，但对自然损坏和系统噪声更脆弱。

    

    量化已经成为在资源有限的设备上部署深度神经网络（DNNs）的一种重要技术。然而，在真实世界的应用中，量化模型在面对各种噪声时会展现出脆弱性。尽管评估量化对鲁棒性的影响的重要性，现有的研究在这个领域中还很有限，并且经常忽视已经确立的鲁棒性评估原则，导致了不完整和不确定的结果。为了解决这个问题，我们对ImageNet上的量化模型在各种噪声（对抗攻击，自然损坏和系统噪声）下进行了全面的鲁棒性评估。全面的评估结果从经验上为量化模型在不同场景下的鲁棒性提供了有价值的见解，例如：（1）量化模型在对抗攻击方面表现出更高的鲁棒性，但对自然损坏和系统噪声更脆弱；（2）总的来说，不同程度的量化在不同场景下表现出不同的鲁棒性。

    Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example: (1) quantized models exhibit higher adversarial robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises; (2) in general, inc
    
[^35]: 超图协同网络的稳定性和泛化性

    Stability and Generalization of Hypergraph Collaborative Networks. (arXiv:2308.02347v1 [cs.LG])

    [http://arxiv.org/abs/2308.02347](http://arxiv.org/abs/2308.02347)

    本文研究了超图协同网络的稳定性和泛化性，并在分析中揭示了协同网络中超图滤波器的设计要点。

    

    图神经网络已经被证明在利用样本之间的成对关系方面非常有效。最近，已经有几个成功的方案将图神经网络推广到超图神经网络，以利用更复杂的关系。特别是，超图协同网络相对于其他超图神经网络在各种半监督学习任务中产生了优秀的结果。协同网络通过将顶点嵌入和超边嵌入表述为一个联合优化问题，并使用它们在重构给定超图时的一致性，可以提供高质量的嵌入表示。本文旨在建立协同网络核心层的算法稳定性并提供泛化保证。分析结果揭示了协同网络中超图滤波器的设计，例如，数据和超图滤波器应如何缩放以实现统一的稳定性。

    Graph neural networks have been shown to be very effective in utilizing pairwise relationships across samples. Recently, there have been several successful proposals to generalize graph neural networks to hypergraph neural networks to exploit more complex relationships. In particular, the hypergraph collaborative networks yield superior results compared to other hypergraph neural networks for various semi-supervised learning tasks. The collaborative network can provide high quality vertex embeddings and hyperedge embeddings together by formulating them as a joint optimization problem and by using their consistency in reconstructing the given hypergraph. In this paper, we aim to establish the algorithmic stability of the core layer of the collaborative network and provide generalization guarantees. The analysis sheds light on the design of hypergraph filters in collaborative networks, for instance, how the data and hypergraph filters should be scaled to achieve uniform stability of the 
    
[^36]: 从高斯图模型和高斯自由场学习网络

    Learning Networks from Gaussian Graphical Models and Gaussian Free Fields. (arXiv:2308.02344v1 [math.ST])

    [http://arxiv.org/abs/2308.02344](http://arxiv.org/abs/2308.02344)

    本文研究了从重复测量的高斯自由场中估计加权网络结构的问题，并提出了一种基于高斯分布傅里叶分析特性的新型估计器。该方法利用了从观测数据中构造的复数值统计量，具有研究价值。

    

    我们研究了从网络上的高斯图模型（Gaussian Graphical Model，简称GGM）的重复测量中估计加权网络结构的问题。在这个方面，我们考虑了与基于其上加权网络的几何结构相一致的GGM的协方差结构。这种GGM在统计物理学中一直受到关注，并被称为高斯自由场（Gaussian Free Field，简称GFF）。近年来，它们在机器学习和理论计算机科学领域引起了广泛的兴趣。在这项工作中，我们提出了一种基于高斯分布的傅里叶分析特性的重复测量的GFF来估计加权网络（等价地，其拉普拉斯矩阵）的新型估计量。在这个过程中，我们的方法利用了从观测数据中构造的复数值统计量，这些统计量本身就具有研究价值。我们通过具体的恢复保证和对所需采样的界限来证明我们的估计器的有效性。

    We investigate the problem of estimating the structure of a weighted network from repeated measurements of a Gaussian Graphical Model (GGM) on the network. In this vein, we consider GGMs whose covariance structures align with the geometry of the weighted network on which they are based. Such GGMs have been of longstanding interest in statistical physics, and are referred to as the Gaussian Free Field (GFF). In recent years, they have attracted considerable interest in the machine learning and theoretical computer science. In this work, we propose a novel estimator for the weighted network (equivalently, its Laplacian) from repeated measurements of a GFF on the network, based on the Fourier analytic properties of the Gaussian distribution. In this pursuit, our approach exploits complex-valued statistics constructed from observed data, that are of interest on their own right. We demonstrate the effectiveness of our estimator with concrete recovery guarantees and bounds on the required sa
    
[^37]: RAHNet: 检索增强型混合网络用于长尾图分类

    RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v1 [cs.LG])

    [http://arxiv.org/abs/2308.02335](http://arxiv.org/abs/2308.02335)

    我们提出了一种检索增强型混合网络(RAHNet)用于长尾图分类任务，通过联合学习稳健的特征提取器和无偏的分类器，解决了图神经网络在长尾类别分布下的偏差和泛化能力有限的问题。

    

    图分类是许多实际多媒体应用中的关键任务，图可以表示各种多媒体数据类型，如图像、视频和社交网络。以往的研究在平衡的情况下应用图神经网络(GNN)，其中类分布是平衡的。然而，实际数据通常呈现出长尾类别分布，导致在使用GNN时对头部类别存在偏差，且对尾部类别的泛化能力有限。最近的方法主要集中在模型训练过程中重新平衡不同的类别，但这种方法未能明确引入新知识，并牺牲了头部类别的性能。为了解决这些缺点，我们提出了一种新的框架，称为检索增强型混合网络(RAHNet)，以分离的方式联合学习稳健的特征提取器和无偏的分类器。在特征提取器训练阶段，我们开发了一个图检索模块来搜索相关图形。

    Graph classification is a crucial task in many real-world multimedia applications, where graphs can represent various multimedia data types such as images, videos, and social networks. Previous efforts have applied graph neural networks (GNNs) in balanced situations where the class distribution is balanced. However, real-world data typically exhibit long-tailed class distributions, resulting in a bias towards the head classes when using GNNs and limited generalization ability over the tail classes. Recent approaches mainly focus on re-balancing different classes during model training, which fails to explicitly introduce new knowledge and sacrifices the performance of the head classes. To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant grap
    
[^38]: 用正则化高阶总变差的随机优化方法训练非线性神经网络

    A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])

    [http://arxiv.org/abs/2308.02293](http://arxiv.org/abs/2308.02293)

    通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。

    

    尽管包括深度神经网络在内的高度表达的参数模型可以更好地建模复杂概念，但训练这种高度非线性模型已知会导致严重的过拟合风险。针对这个问题，本研究考虑了一种k阶总变差（k-TV）正则化，它被定义为要训练的参数模型的k阶导数的平方积分，通过惩罚k-TV来产生一个更平滑的函数，从而避免过拟合。尽管将k-TV项应用于一般的参数模型由于积分而导致计算复杂，本研究提供了一种随机优化算法，可以高效地训练带有k-TV正则化的一般模型，而无需进行显式的数值积分。这种方法可以应用于结构任意的深度神经网络的训练，因为它只需要进行简单的随机梯度优化即可实现。

    While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
    
[^39]: 通过虚拟风险最小化实现令人沮丧的模型泛化

    Frustratingly Easy Model Generalization by Dummy Risk Minimization. (arXiv:2308.02287v1 [cs.LG])

    [http://arxiv.org/abs/2308.02287](http://arxiv.org/abs/2308.02287)

    通过虚拟风险最小化，本文提出了一种令人沮丧地简单且通用的技术（DuRM），能够显著改善经验风险最小化（ERM）的泛化能力。通过理论和经验验证，我们展示了DuRM可以通过增加梯度的方差来促进模型的泛化效果，并在不同任务和数据集上进行的实验证明了DuRM的有效性。

    

    经验风险最小化（ERM）是机器学习中的一个基本范例。然而，在各种任务中，它的泛化能力有限。在本文中，我们设计了虚拟风险最小化（DuRM），一种令人沮丧地简单和通用的技术来提高ERM的泛化能力。DuRM非常简单实现：只需扩大输出logits的维度，然后使用标准梯度下降进行优化。此外，我们通过理论和经验验证DuRM的有效性。从理论上讲，我们展示了DuRM导致更大的梯度方差，通过观察更好的平坦局部最小值促进模型泛化。从经验上讲，我们针对不同的数据集，模态和网络架构，在不同的任务上进行了DuRM的评估，包括传统分类，语义分割，超出分布泛化，对抗训练和长尾识别。结果表明，DuRM能够持续改进模型的泛化能力。

    Empirical risk minimization (ERM) is a fundamental machine learning paradigm. However, its generalization ability is limited in various tasks. In this paper, we devise Dummy Risk Minimization (DuRM), a frustratingly easy and general technique to improve the generalization of ERM. DuRM is extremely simple to implement: just enlarging the dimension of the output logits and then optimizing using standard gradient descent. Moreover, we validate the efficacy of DuRM on both theoretical and empirical analysis. Theoretically, we show that DuRM derives greater variance of the gradient, which facilitates model generalization by observing better flat local minima. Empirically, we conduct evaluations of DuRM across different datasets, modalities, and network architectures on diverse tasks, including conventional classification, semantic segmentation, out-of-distribution generalization, adverserial training, and long-tailed recognition. Results demonstrate that DuRM could consistently improve the 
    
[^40]: DIVERSIFY: 一般化时间序列离群检测和推广的通用框架

    DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization. (arXiv:2308.02282v1 [cs.LG])

    [http://arxiv.org/abs/2308.02282](http://arxiv.org/abs/2308.02282)

    DIVERSIFY是一个通用框架，用于解决时间序列离群检测和推广的挑战，通过利用数据集中的子域来对抗时间序列的非平稳性，并通过迭代过程减小潜在分布之间的差距。

    

    时间序列仍然是机器学习研究中最具挑战性的模态之一。由于其非平稳性质，时间序列的离群检测和推广往往受到困扰，即分布随时间变化。时间序列中的动态分布给现有算法带来了很大的挑战，因为它们主要关注领域信息已知的情况。本文尝试利用数据集中的子域来对抗非平稳性引发的问题，实现广义表示学习。我们提出了DIVERSIFY，一个针对动态时间序列分布的离群检测和推广的通用框架。DIVERSIFY采用迭代过程：首先通过对抗训练获得“最坏情况”潜在分布情景，然后减小这些潜在分布之间的差距。我们通过结合现有的离群检测方法实现了DIVERSIFY。

    Time series remains one of the most challenging modalities in machine learning research. The out-of-distribution (OOD) detection and generalization on time series tend to suffer due to its non-stationary property, i.e., the distribution changes over time. The dynamic distributions inside time series pose great challenges to existing algorithms to identify invariant distributions since they mainly focus on the scenario where the domain information is given as prior knowledge. In this paper, we attempt to exploit subdomains within a whole dataset to counteract issues induced by non-stationary for generalized representation learning. We propose DIVERSIFY, a general framework, for OOD detection and generalization on dynamic distributions of time series. DIVERSIFY takes an iterative process: it first obtains the "worst-case" latent distribution scenario via adversarial training, then reduces the gap between these latent distributions. We implement DIVERSIFY via combining existing OOD detect
    
[^41]: 自适应近端梯度方法的凸优化

    Adaptive Proximal Gradient Method for Convex Optimization. (arXiv:2308.02261v1 [math.OC])

    [http://arxiv.org/abs/2308.02261](http://arxiv.org/abs/2308.02261)

    本文提出了自适应版本的梯度下降（GD）和近端梯度方法（ProxGD），通过利用局部曲率信息完全自适应。所提出的方法具有收敛性，且允许使用更大的步长。

    

    在本文中，我们探讨了凸优化中的两个基本一阶算法，即梯度下降（GD）和近端梯度方法（ProxGD）。我们的重点是通过利用平滑函数的局部曲率信息，使这些算法完全自适应。我们提出了基于观察到的梯度差异的自适应版本的GD和ProxGD，因此不会增加计算成本。此外，我们在仅假设梯度的局部Lipschitz性的情况下，证明了我们方法的收敛性。另外，所提出的版本允许使用比[MM20]最初建议的更大的步长。

    In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20].
    
[^42]: 寻找托里：自监督学习用于分析韩国民歌

    Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song. (arXiv:2308.02249v1 [cs.SD])

    [http://arxiv.org/abs/2308.02249](http://arxiv.org/abs/2308.02249)

    本文介绍了使用自监督学习对韩国民歌进行计算机分析的方法，并以“托里”作为案例进行了研究。实验结果表明，该方法能够更好地捕捉到“托里”的特征，为研究韩国民歌提供了新的视角。

    

    在本文中，我们介绍了对大约700小时的韩国民歌场录音数据集进行计算机分析，这些录音大多数在1980-90年代录制。由于大部分歌曲都是由非专业音乐家在没有伴奏的情况下演唱的，因此该数据集提供了一些挑战。为了解决这个问题，我们使用基于音调轮廓的卷积神经网络进行了自监督学习，并分析了模型如何捕捉到“托里”这一音乐概念，它是一个基于特定音阶、装饰音和成语化旋律轮廓的分类系统。实验结果表明，与传统的音高直方图相比，我们的方法能够更好地捕捉到“托里”的特征。利用我们的方法，我们研究了现有学术界提出的音乐讨论在韩国民歌实际录音中的表现。

    In this paper, we introduce a computational analysis of the field recording dataset of approximately 700 hours of Korean folk songs, which were recorded around 1980-90s. Because most of the songs were sung by non-expert musicians without accompaniment, the dataset provides several challenges. To address this challenge, we utilized self-supervised learning with convolutional neural network based on pitch contour, then analyzed how the musical concept of tori, a classification system defined by a specific scale, ornamental notes, and an idiomatic melodic contour, is captured by the model. The experimental result shows that our approach can better capture the characteristics of tori compared to traditional pitch histograms. Using our approaches, we have examined how musical discussions proposed in existing academia manifest in the actual field recordings of Korean folk songs.
    
[^43]: 自正规化神经网络，实现EDFA波长相关增益建模的一次迁移学习

    Self-Normalizing Neural Network, Enabling One Shot Transfer Learning for Modeling EDFA Wavelength Dependent Gain. (arXiv:2308.02233v1 [cs.NI])

    [http://arxiv.org/abs/2308.02233](http://arxiv.org/abs/2308.02233)

    本论文提出了一种基于自正规化神经网络的新型机器学习框架，能够实现一次迁移学习并对多个EDFA器件的波长相关增益进行建模。

    

    我们提出了一个基于半监督、自正规化神经网络的新型机器学习框架，用于多个EDFA器件的波长相关增益建模，并实现了一次迁移学习。我们在Open Ireland和COSMOS测试平台上对22个EDFA进行了实验，结果显示即使在不同的放大器类型下，也能实现高精度的迁移学习。

    We present a novel ML framework for modeling the wavelength-dependent gain of multiple EDFAs, based on semi-supervised, self-normalizing neural networks, enabling one-shot transfer learning. Our experiments on 22 EDFAs in Open Ireland and COSMOS testbeds show high-accuracy transfer-learning even when operated across different amplifier types.
    
[^44]: 基于似然比的置信区间在神经网络中的应用

    Likelihood-ratio-based confidence intervals for neural networks. (arXiv:2308.02221v1 [stat.ML])

    [http://arxiv.org/abs/2308.02221](http://arxiv.org/abs/2308.02221)

    本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。该方法能够构建不对称区间，考虑了训练时间、网络架构和正则化技术等因素。尽管方法实现昂贵，但在特定领域中具有重要应用潜力。

    

    本文介绍了一种新颖的基于似然比的方法，用于构建神经网络的置信区间。我们的方法名为DeepLR，具有许多优点，其中最重要的是能够构建在数据有限的区域中扩展的不对称区间，并固有地考虑了训练时间、网络架构和正则化技术等因素。尽管承认目前的方法实现对于许多深度学习应用来说过于昂贵，但在诸如医学预测或天体物理学等特定领域中，可靠的单个预测的不确定性估计可能已经合理。这项工作突出了基于似然比的不确定性估计的重要潜力，并为未来的研究开辟了有希望的途径。

    This paper introduces a first implementation of a novel likelihood-ratio-based approach for constructing confidence intervals for neural networks. Our method, called DeepLR, offers several qualitative advantages: most notably, the ability to construct asymmetric intervals that expand in regions with a limited amount of data, and the inherent incorporation of factors such as the amount of training time, network architecture, and regularization techniques. While acknowledging that the current implementation of the method is prohibitively expensive for many deep-learning applications, the high cost may already be justified in specific fields like medical predictions or astrophysics, where a reliable uncertainty estimate for a single prediction is essential. This work highlights the significant potential of a likelihood-ratio-based uncertainty estimate and establishes a promising avenue for future research.
    
[^45]: 西班牙临床语言模型调查

    A Survey of Spanish Clinical Language Models. (arXiv:2308.02199v1 [cs.CL])

    [http://arxiv.org/abs/2308.02199](http://arxiv.org/abs/2308.02199)

    这项调查研究了西班牙语临床语言模型的应用，回顾了17个专注于临床任务的语料库的贡献，并对最相关的西班牙语语言模型和西班牙临床语言模型进行了彻底比较，提供了3000多个进行微调的模型。为了便于未来的研究和挑战，所有测试过的语料库和最佳模型都被以可访问的方式公开。

    

    本调查聚焦于使用编码器语言模型来解决西班牙语临床领域任务的问题。我们回顾了17个主要专注于临床任务的语料库的贡献，然后列出了最相关的西班牙语语言模型和西班牙临床语言模型。我们通过对可用语料库的精选子集进行基准测试，对这些模型进行了彻底的比较，以找到表现最佳的模型；总共超过3000个模型被针对这项研究进行了微调。所有测试的语料库和最佳模型都以可访问的方式公开，以便独立团队可以重现结果或在未来创建新的西班牙临床语言模型时进行挑战。

    This survey focuses in encoder Language Models for solving tasks in the clinical domain in the Spanish language. We review the contributions of 17 corpora focused mainly in clinical tasks, then list the most relevant Spanish Language Models and Spanish Clinical Language models. We perform a thorough comparison of these models by benchmarking them over a curated subset of the available corpora, in order to find the best-performing ones; in total more than 3000 models were fine-tuned for this study. All the tested corpora and the best models are made publically available in an accessible way, so that the results can be reproduced by independent teams or challenged in the future when new Spanish Clinical Language models are created.
    
[^46]: AutoML4ETC: 自动化神经架构搜索实现现实世界加密流量分类

    AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v1 [cs.NI])

    [http://arxiv.org/abs/2308.02182](http://arxiv.org/abs/2308.02182)

    AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。

    

    在实验环境中，深度学习（DL）已成功应用于加密网络流量分类。然而，在实际应用中，DL分类器的性能随时间不可避免地下降。仅仅对新数据集进行模型重新训练只能部分提高其性能。手动调整模型架构以满足新数据集上的性能期望耗时且需要领域专业知识。本文提出了一种新颖的工具AutoML4ETC，用于自动设计高效且高性能的神经架构以进行加密流量分类。我们定义了一个新颖而强大的搜索空间，专门针对使用数据包头字节进行近实时加密流量分类。通过在搜索空间上使用不同的搜索策略，我们展示了AutoML4ETC生成的神经架构在多个数据集上均优于当前最先进的加密流量分类器，包括公共基准数据集。

    Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark dat
    
[^47]: 通过大型语言模型扩展临床试验匹配：以肿瘤学为案例研究

    Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v1 [cs.CL])

    [http://arxiv.org/abs/2308.02180](http://arxiv.org/abs/2308.02180)

    本文研究了使用大型语言模型（LLMs）扩展临床试验匹配的方法，并以肿瘤学为案例研究。研究结果显示，先进的LLMs能够处理临床试验的复杂条件和匹配逻辑，相较于之前的方法，性能显著提升，并可作为人工辅助筛选患者-试验候选人的初步解决方案。

    

    临床试验匹配是医疗传递和发现中的关键过程。实际上，由于庞大的非结构化数据和不可扩展的手动处理，该过程存在问题。本文通过以肿瘤学为重点领域，对使用大型语言模型（LLM）扩展临床试验匹配进行了系统研究。我们的研究基于一个正在美国一个大型医疗网络进行测试部署的临床试验匹配系统。初步结果令人鼓舞：先进的LLM（如GPT-4）可以立即连接临床试验的复杂的合格条件，并提取复杂的匹配逻辑（例如嵌套的AND/OR/NOT）。虽然仍不完美，LLM在性能上显著优于以前的强基准线，并可能作为在人与人之间进行候选患者-试验划分的初步解决方案。我们的研究还揭示了一些应用LLM进行端到端临床试验匹配的重要增长领域，例如上下文限制和准确性。

    Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially
    
[^48]: 扩散概率模型增强了变分自动编码器在晶体结构生成建模中的应用

    Diffusion probabilistic models enhance variational autoencoder for crystal structure generative modeling. (arXiv:2308.02165v1 [cs.LG])

    [http://arxiv.org/abs/2308.02165](http://arxiv.org/abs/2308.02165)

    扩散概率模型增强了变分自动编码器在晶体结构生成建模中的应用，通过去噪原子坐标并生成质量相当的晶体结构，并且能够生成与真实基态更接近的结构，能量准确性明显提高。

    

    晶体扩散变分自动编码器（CDVAE）是一种利用分数匹配生成保留晶体对称性的逼真晶体结构的机器学习模型。本研究中，我们采用了新颖的扩散概率（DP）模型来去噪原子坐标，而不是采用CDVAE中的标准分数匹配方法。我们提出的DP-CDVAE模型可以重建和生成在质量上与原始CDVAE相当的晶体结构。值得注意的是，当将DP-CDVAE模型生成的碳结构与从密度泛函理论计算得到的弛豫结构进行比较时，我们发现DP-CDVAE生成的结构与其相应基态更接近。这些结构与真实基态之间的能量差平均比原始CDVAE生成的能量差低了68.1 meV/原子。这种能量准确性的显著改进凸显了其创新性和贡献。

    The crystal diffusion variational autoencoder (CDVAE) is a machine learning model that leverages score matching to generate realistic crystal structures that preserve crystal symmetry. In this study, we leverage novel diffusion probabilistic (DP) models to denoise atomic coordinates rather than adopting the standard score matching approach in CDVAE. Our proposed DP-CDVAE model can reconstruct and generate crystal structures whose qualities are statistically comparable to those of the original CDVAE. Furthermore, notably, when comparing the carbon structures generated by the DP-CDVAE model with relaxed structures obtained from density functional theory calculations, we find that the DP-CDVAE generated structures are remarkably closer to their respective ground states. The energy differences between these structures and the true ground states are, on average, 68.1 meV/atom lower than those generated by the original CDVAE. This significant improvement in the energy accuracy highlights the
    
[^49]: 视听内容的发言人日化

    Speaker Diarization of Scripted Audiovisual Content. (arXiv:2308.02160v1 [cs.CL])

    [http://arxiv.org/abs/2308.02160](http://arxiv.org/abs/2308.02160)

    本文介绍了一种用于发言人日化任务的新方法，利用制作脚本提取伪标签数据，并相对于无监督基线模型实现了51.7%的改进。

    

    媒体本地化行业通常需要一个与最终电影或电视制作的原文脚本相符的脚本，以便在外语中创建字幕或配音脚本。特别是，即播出脚本必须被结构化为包含时间代码、发言人姓名和转录的对话行序列。目前的语音识别技术可以减轻转录步骤。然而，目前最先进的发言人日化模型在电视节目上仍存在两个主要问题：（一）无法追踪大量发言人，（二）在检测频繁的发言人更换时准确率较低。为了缓解这个问题，我们提出了一种新方法，利用在拍摄过程中使用的制作脚本来提取用于发言人日化任务的伪标签数据。我们提出了一种新的半监督方法，并在我们的度量结果上，在66个节目的测试集上相对于两个无监督基线模型实现了51.7%的改进。

    The media localization industry usually requires a verbatim script of the final film or TV production in order to create subtitles or dubbing scripts in a foreign language. In particular, the verbatim script (i.e. as-broadcast script) must be structured into a sequence of dialogue lines each including time codes, speaker name and transcript. Current speech recognition technology alleviates the transcription step. However, state-of-the-art speaker diarization models still fall short on TV shows for two main reasons: (i) their inability to track a large number of speakers, (ii) their low accuracy in detecting frequent speaker changes. To mitigate this problem, we present a novel approach to leverage production scripts used during the shooting process, to extract pseudo-labeled data for the speaker diarization task. We propose a novel semi-supervised approach and demonstrate improvements of 51.7% relative to two unsupervised baseline models on our metrics on a 66 show test set.
    
[^50]: 改进的指数积分器在扩散模型采样中的序分析与设计

    Improved Order Analysis and Design of Exponential Integrator for Diffusion Models Sampling. (arXiv:2308.02157v1 [cs.LG])

    [http://arxiv.org/abs/2308.02157](http://arxiv.org/abs/2308.02157)

    通过重新评估高阶微分求解器的设计，我们提出了改进的指数积分器，在扩散模型的采样中获得了更好的采样质量和准确性。

    

    高效的微分方程求解器显著减少了扩散模型（DM）的采样时间，同时保持了高质量的采样结果。在这些求解器中，指数积分器（EI）以其展示的最新性能而受到关注。然而，现有的基于高阶EI的采样算法依赖于退化的EI求解器，与理论上预期的结果相比，导致较差的误差界限和降低的准确性。这种情况使得采样质量极其容易受到表面上无害的设计选择的影响，例如，低效的时间步长调度器可能需要两倍的步数才能达到与经过精心优化的时间步长获得的质量相当。为了解决这个问题，我们重新评估了对DM的高阶微分求解器的设计。通过彻底的序分析，我们揭示了现有高阶EI求解器的退化可以被... (摘要太长，已省略部分内容)

    Efficient differential equation solvers have significantly reduced the sampling time of diffusion models (DMs) while retaining high sampling quality. Among these solvers, exponential integrators (EI) have gained prominence by demonstrating state-of-the-art performance. However, existing high-order EI-based sampling algorithms rely on degenerate EI solvers, resulting in inferior error bounds and reduced accuracy in contrast to the theoretically anticipated results under optimal settings. This situation makes the sampling quality extremely vulnerable to seemingly innocuous design choices such as timestep schedules. For example, an inefficient timestep scheduler might necessitate twice the number of steps to achieve a quality comparable to that obtained through carefully optimized timesteps. To address this issue, we reevaluate the design of high-order differential solvers for DMs. Through a thorough order analysis, we reveal that the degeneration of existing high-order EI solvers can be 
    
[^51]: Pareto集合上的优化：多目标优化理论研究

    Optimization on Pareto sets: On a theory of multi-objective optimization. (arXiv:2308.02145v1 [math.OC])

    [http://arxiv.org/abs/2308.02145](http://arxiv.org/abs/2308.02145)

    该论文研究了在多目标优化中，如何解决Pareto集合上的约束优化问题，提出了局部算法，并给出了收敛速率。

    

    在多目标优化中，一个决策向量必须在多个目标之间平衡权衡。实现最佳权衡的解决方案被称为Pareto最优：这些是决策向量，通过改善任何一个目标，必然会以牺牲另一个目标为代价。但由于Pareto最优向量的集合可能非常大，我们进一步考虑了一个更实际重要的Pareto约束优化问题：目标是将偏好函数优化到Pareto集合约束下。我们研究了解决这个约束优化问题的局部方法，这个问题存在重要挑战，因为约束集合(i)通过隐式定义，且(ii)一般情况下非凸非光滑，即使目标是凸光滑的。我们定义了最优性和稳定性的概念，并提供了一个算法，当目标是强凸的且Lipschitz光滑时，它具有末次迭代的收敛速率为$O(K^{-1/2})$。

    In multi-objective optimization, a single decision vector must balance the trade-offs between many objectives. Solutions achieving an optimal trade-off are said to be Pareto optimal: these are decision vectors for which improving any one objective must come at a cost to another. But as the set of Pareto optimal vectors can be very large, we further consider a more practically significant Pareto-constrained optimization problem, where the goal is to optimize a preference function constrained to the Pareto set.  We investigate local methods for solving this constrained optimization problem, which poses significant challenges because the constraint set is (i) implicitly defined, and (ii) generally non-convex and non-smooth, even when the objectives are. We define notions of optimality and stationarity, and provide an algorithm with a last-iterate convergence rate of $O(K^{-1/2})$ to stationarity when the objectives are strongly convex and Lipschitz smooth.
    
[^52]: 使用物理感知的卷积神经网络学习二维不可压缩Navier-Stokes方程的解算子

    Learning the solution operator of two-dimensional incompressible Navier-Stokes equations using physics-aware convolutional neural networks. (arXiv:2308.02137v1 [math.NA])

    [http://arxiv.org/abs/2308.02137](http://arxiv.org/abs/2308.02137)

    本论文提出了一种使用物理感知的卷积神经网络学习不同几何形状中稳态Navier-Stokes方程解的近似解的技术，无需参数化，在结果上与基于数据的方法进行了比较。

    

    近年来，将物理引入机器学习的概念变得广受欢迎。然而，大多数包含物理的机器学习技术仍然局限于单一几何形状或一组可参数化的几何形状。因此，即使仅略微修改，仍然需要针对新的几何形状训练新模型。我们的工作介绍了一种技术，可以在不需要参数化的情况下学习在不同几何形状中的稳态Navier-Stokes方程的近似解。这种技术基于U-Net-like CNN和来自有限差分方法领域的成熟离散化方法的组合。我们将物理感知的CNN的结果与最先进的基于数据的方法进行了比较。此外，还展示了我们的方法与基于数据的方法结合时的性能。

    In recent years, the concept of introducing physics to machine learning has become widely popular. Most physics-inclusive ML-techniques however are still limited to a single geometry or a set of parametrizable geometries. Thus, there remains the need to train a new model for a new geometry, even if it is only slightly modified. With this work we introduce a technique with which it is possible to learn approximate solutions to the steady-state Navier--Stokes equations in varying geometries without the need of parametrization. This technique is based on a combination of a U-Net-like CNN and well established discretization methods from the field of the finite difference method.The results of our physics-aware CNN are compared to a state-of-the-art data-based approach. Additionally, it is also shown how our approach performs when combined with the data-based approach.
    
[^53]: Eva：用于二阶优化的通用矢量化近似框架

    Eva: A General Vectorized Approximation Framework for Second-order Optimization. (arXiv:2308.02123v1 [cs.LG])

    [http://arxiv.org/abs/2308.02123](http://arxiv.org/abs/2308.02123)

    Eva是一个内存和时间高效的二阶优化算法，使用Kronecker分解和Sherman-Morrison公式来减少内存消耗和计算矩阵逆，同时将其扩展为通用的矢量化近似框架以提高计算和内存效率。

    

    二阶优化算法对于训练深度学习模型具有优秀的收敛性能，但往往会导致显著的计算和内存开销。这可能导致比随机梯度下降（SGD）等一阶算法更低的训练效率。在这项工作中，我们提出了一种名为Eva的内存和时间高效的二阶算法，采用了两种新颖的技术：1）我们使用小批量训练数据上的Kronecker分解构建二阶信息，以减少内存消耗；2）我们利用Sherman-Morrison公式导出一种高效的更新公式，而无需显式计算矩阵的逆。我们进一步将Eva扩展为一个通用的矢量化近似框架，以提高两种现有二阶算法（FOOF和Shampoo）的计算和内存效率，而不影响它们的收敛性能。在不同模型和数据集上进行了大量的实验结果验证了我们方法的有效性。

    Second-order optimization algorithms exhibit excellent convergence properties for training deep learning models, but often incur significant computation and memory overheads. This can result in lower training efficiency than the first-order counterparts such as stochastic gradient descent (SGD). In this work, we present a memory- and time-efficient second-order algorithm named Eva with two novel techniques: 1) we construct the second-order information with the Kronecker factorization of small stochastic vectors over a mini-batch of training data to reduce memory consumption, and 2) we derive an efficient update formula without explicitly computing the inverse of matrices using the Sherman-Morrison formula. We further extend Eva to a general vectorized approximation framework to improve the compute and memory efficiency of two existing second-order algorithms (FOOF and Shampoo) without affecting their convergence performance. Extensive experimental results on different models and datase
    
[^54]: 通过模型DNA的模型来源证明

    Model Provenance via Model DNA. (arXiv:2308.02121v1 [cs.LG])

    [http://arxiv.org/abs/2308.02121](http://arxiv.org/abs/2308.02121)

    本文介绍了模型来源证明的新概念模型DNA，通过编码模型的训练数据和输入输出信息作为紧凑全面的表示，来确定源模型是否作为目标模型的来源证明。

    

    了解机器学习（ML）模型的生命周期是一个有趣的研究领域（例如，了解模型的来源，训练方式以及使用方式）。本文聚焦于这一领域内的一个新问题，即模型来源证明（MP），该问题涉及目标模型与其预训练模型之间的关系，并旨在确定一个源模型是否作为目标模型的来源证明。这是一个重要的问题，对于确保机器学习模型的安全性和知识产权具有重要意义，但在文献中并没有得到很多关注。为了填补这一空白，我们引入了一个新概念，即模型DNA，它代表了机器学习模型的独特特征。我们利用数据驱动和模型驱动的表示学习方法，将模型的训练数据和输入输出信息编码为模型的紧凑且全面的表示（即DNA）。

    Understanding the life cycle of the machine learning (ML) model is an intriguing area of research (e.g., understanding where the model comes from, how it is trained, and how it is used). This paper focuses on a novel problem within this field, namely Model Provenance (MP), which concerns the relationship between a target model and its pre-training model and aims to determine whether a source model serves as the provenance for a target model. This is an important problem that has significant implications for ensuring the security and intellectual property of machine learning models but has not received much attention in the literature. To fill in this gap, we introduce a novel concept of Model DNA which represents the unique characteristics of a machine learning model. We utilize a data-driven and model-driven representation learning method to encode the model's training data and input-output information as a compact and comprehensive representation (i.e., DNA) of the model. Using this 
    
[^55]: VQGraph: 图形向量量化用于连接GNN和MLPs

    VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs. (arXiv:2308.02117v1 [cs.LG])

    [http://arxiv.org/abs/2308.02117](http://arxiv.org/abs/2308.02117)

    VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。

    

    图神经网络（GNNs）进行信息传递，聚合局部邻居以更新节点表示。这种信息传递导致在实际的延迟约束应用程序中存在可扩展性问题。为了解决这个问题，最近的方法采用知识蒸馏（KD）通过模仿GNN的输出来学习计算效率高的多层感知机（MLP）。然而，现有的GNN表示空间可能不足以表示底层图的多样化局部结构，这限制了从GNN到MLP的知识转移。在这里，我们提出了一个新颖的框架VQGraph，用于学习一个强大的图形表示空间，用于连接GNN和MLPs。我们采用一种变体的矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，它将多样化的局部结构节点明确表示为大量离散令牌，并构成一个有意义的代码书。配备了学习的代码书，我们提出

    Graph Neural Networks (GNNs) conduct message passing which aggregates local neighbors to update node representations. Such message passing leads to scalability issues in practical latency-constrained applications. To address this issue, recent methods adopt knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (MLP) by mimicking the output of GNN. However, the existing GNN representation space may not be expressive enough for representing diverse local structures of the underlying graph, which limits the knowledge transfer from GNN to MLP. Here we present a novel framework VQGraph to learn a powerful graph representation space for bridging GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which explicitly represents the nodes of diverse local structures as numerous discrete tokens and constitutes a meaningful codebook. Equipped with the learned codebook, we propos
    
[^56]: 使用混合多任务CNN-Transformer网络进行乳腺超声肿瘤分类

    Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network. (arXiv:2308.02101v1 [eess.IV])

    [http://arxiv.org/abs/2308.02101](http://arxiv.org/abs/2308.02101)

    该论文提出了一种使用混合多任务CNN-Transformer网络进行乳腺超声肿瘤分类的方法。与传统的卷积神经网络相比，该方法能更好地捕捉全局上下文信息，并在实验中取得了最高的准确性、灵敏度和F1得分。

    

    在乳腺超声（BUS）图像分类中，捕捉全局上下文信息起着至关重要的作用。尽管卷积神经网络（CNN）在肿瘤分类中表现出可靠的性能，但由于卷积操作的局部性质，它们在建模全局和长程依赖性方面存在固有的限制。视觉Transformer具有捕捉全局上下文信息的改进能力，但由于标记化操作可能会扭曲局部图像模式。在本研究中，我们提出了一种名为Hybrid-MT-ESTAN的混合多任务深度神经网络，用于使用由CNN和Swin Transformer组件组成的混合架构执行BUS肿瘤分类和分割。所提出的方法与九种BUS分类方法进行了比较，并使用3320个BUS图像的七个定量指标进行评估。结果表明，Hybrid-MT-ESTAN实现了最高的准确性，灵敏度和F1得分。

    Capturing global contextual information plays a critical role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations for modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort the local image patterns due to the tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 sco
    
[^57]: 在边缘端的高效模型适应用于持续学习

    Efficient Model Adaptation for Continual Learning at the Edge. (arXiv:2308.02084v1 [cs.LG])

    [http://arxiv.org/abs/2308.02084](http://arxiv.org/abs/2308.02084)

    这篇论文提出了一个名为Encoder-Adaptor-Reconfigurator（EAR）框架，用于在领域漂移下进行高效的持续学习。该框架使用了固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。通过结合DNN和超维计算（HDC），该框架能够检测新数据是否属于分布之外（OOD），并能够识别出... (摘要内容省略)

    

    大多数机器学习系统在训练和部署过程中假设数据分布是固定和匹配的，但这通常是错误的假设。当机器学习模型部署在真实设备上时，数据分布常常会随时间变化，原因是环境因素、传感器特性和感兴趣的任务发生了变化。本文提出了一种名为Encoder-Adaptor-Reconfigurator（EAR）框架的方法，用于处理领域漂移下的高效持续学习。EAR框架利用固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。EAR框架能够通过将DNN与超维计算（HDC）相结合，检测出新数据是否属于分布之外（OOD），并能够识别出

    Most machine learning (ML) systems assume stationary and matching data distributions during training and deployment. This is often a false assumption. When ML models are deployed on real devices, data distributions often shift over time due to changes in environmental factors, sensor characteristics, and task-of-interest. While it is possible to have a human-in-the-loop to monitor for distribution shifts and engineer new architectures in response to these shifts, such a setup is not cost-effective. Instead, non-stationary automated ML (AutoML) models are needed. This paper presents the Encoder-Adaptor-Reconfigurator (EAR) framework for efficient continual learning under domain shifts. The EAR framework uses a fixed deep neural network (DNN) feature encoder and trains shallow networks on top of the encoder to handle novel data. The EAR framework is capable of 1) detecting when new data is out-of-distribution (OOD) by combining DNNs with hyperdimensional computing (HDC), 2) identifying l
    
[^58]: 目标规范偏差、反事实预测和医疗算法公正性

    Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare. (arXiv:2308.02081v1 [cs.LG])

    [http://arxiv.org/abs/2308.02081](http://arxiv.org/abs/2308.02081)

    目标规范偏差是影响机器学习预测工具临床效用的普遍偏见，它指的是目标变量的操作化与决策者定义的不一致，可能导致预测准确性的过高估计和次优决策，与数据限制和健康差异无关。

    

    在将机器学习应用于医疗领域时，偏见通常归因于不具代表性或不完整的数据，或者潜在的健康差异。本文发现了一种更普遍的偏见来源，影响了机器学习预测工具的临床效用：目标规范偏差。当目标变量的实施与决策者的定义不一致时，就会发生目标规范偏差。这种不匹配通常是微妙的，源于决策者通常对反事实的医疗情景的结果进行预测，而不是实际情况。目标规范偏差与数据限制和健康差异无关。如果不进行纠正，它会导致对预测准确性的过高估计，对医疗资源的低效利用，以及可能对患者造成伤害的次优决策。最近在计量学——测量科学领域的工作提出了对抗目标规范偏差的方法。

    Bias in applications of machine learning (ML) to healthcare is usually attributed to unrepresentative or incomplete data, or to underlying health disparities. This article identifies a more pervasive source of bias that affects the clinical utility of ML-enabled prediction tools: target specification bias. Target specification bias arises when the operationalization of the target variable does not match its definition by decision makers. The mismatch is often subtle, and stems from the fact that decision makers are typically interested in predicting the outcomes of counterfactual, rather than actual, healthcare scenarios. Target specification bias persists independently of data limitations and health disparities. When left uncorrected, it gives rise to an overestimation of predictive accuracy, to inefficient utilization of medical resources, and to suboptimal decisions that can harm patients. Recent work in metrology - the science of measurement suggests ways of counteracting target 
    
[^59]: 跨平台仇恨言论检测中的因果引导解缠问题

    Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v1 [cs.CL])

    [http://arxiv.org/abs/2308.02080](http://arxiv.org/abs/2308.02080)

    本研究提出了一种跨平台仇恨言论检测模型，通过解缠输入表示为不变特征和平台相关特征，实现了对多个未见平台的良好泛化能力。

    

    尽管社交媒体平台在促进公开对话方面具有价值，但他们经常被利用来传播有害内容。目前用于检测这种有害内容的深度学习和自然语言处理模型过度依赖于领域特定术语，影响到了它们适应泛化仇恨言论检测的能力。这是因为它们倾向于过于狭隘地关注特定的语言信号或某些词语类别的使用。当平台缺乏高质量的标记数据用于训练时，另一个重要的挑战出现了，需要跨平台模型来适应不同的分布转化。我们的研究引入了一个跨平台仇恨言论检测模型，能够在一个平台的数据上训练并推广到多个未见平台。为了实现对不同平台的良好泛化性能，一种方法是将输入表示解缠为不变特征和平台相关特征。我们还认为学习因果关系是提供更好解缠和泛化性能的关键。

    Social media platforms, despite their value in promoting open discourse, are often exploited to spread harmful content. Current deep learning and natural language processing models used for detecting this harmful content overly rely on domain-specific terms affecting their capabilities to adapt to generalizable hate speech detection. This is because they tend to focus too narrowly on particular linguistic signals or the use of certain categories of words. Another significant challenge arises when platforms lack high-quality annotated data for training, leading to a need for cross-platform models that can adapt to different distribution shifts. Our research introduces a cross-platform hate speech detection model capable of being trained on one platform's data and generalizing to multiple unseen platforms. To achieve good generalizability across platforms, one way is to disentangle the input representations into invariant and platform-dependent features. We also argue that learning causa
    
[^60]: 虚假网站：在规模上追踪和影响虚假新闻故事的传播

    Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale. (arXiv:2308.02068v1 [cs.SI])

    [http://arxiv.org/abs/2308.02068](http://arxiv.org/abs/2308.02068)

    本研究利用日常抓取的1,404个不可靠新闻网站以及大型语言模型和聚类算法，提出了一个自动分析网络生态系统中传播的叙述的系统。通过识别55,301个叙述，描述了2022年传播最广泛的叙述，并确定了最具影响力的起源和放大叙述的网站。该系统可用于检测来自不可靠新闻网站的新叙述，并帮助事实核查组织更快地应对错误信息。

    

    虚假信息、宣传和彻头彻尾的谎言在网络上大量传播，其中一些叙述对公共健康、选举和个人安全产生危险的现实影响。然而，尽管虚假信息的影响，研究界在追踪在线平台上的新闻叙述方面主要缺乏自动化和程序化的方法。在这项研究中，利用对1,404个不可靠新闻网站的日常抓取、大型语言模型MPNet和DP-Means聚类，我们介绍了一个系统来自动分离和分析在线生态系统中传播的叙述。我们在这些1,404个网站上识别了55,301个叙述，描述了2022年传播最广泛的叙述，并确定了起源和放大叙述的最具影响力的网站。最后，我们展示了如何利用我们的系统来检测源自不可靠新闻网站的新叙述，并帮助Politifact、路透社和美联社等事实核查组织更快地应对错误信息。

    Misinformation, propaganda, and outright lies proliferate on the web, with some narratives having dangerous real-world consequences on public health, elections, and individual safety. However, despite the impact of misinformation, the research community largely lacks automated and programmatic approaches for tracking news narratives across online platforms. In this work, utilizing daily scrapes of 1,404 unreliable news websites, the large-language model MPNet, and DP-Means clustering, we introduce a system to automatically isolate and analyze the narratives spread within online ecosystems. Identifying 55,301 narratives on these 1,404 websites, we describe the most prevalent narratives spread in 2022 and identify the most influential websites that originate and magnify narratives. Finally, we show how our system can be utilized to detect new narratives originating from unreliable news websites and aid fact-checkers like Politifact, Reuters, and AP News in more quickly addressing misinfo
    
[^61]: 通过使用非可学习原语的显式任务路由来减轻多任务学习中的任务干扰

    Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives. (arXiv:2308.02066v1 [cs.CV])

    [http://arxiv.org/abs/2308.02066](http://arxiv.org/abs/2308.02066)

    本文提出了ETR-NLP模型来减轻多任务学习中的任务干扰，通过使用非可学习原语和显式任务路由的协同组合，在共享分支和任务特定分支中显式地分离可学习参数，以实现任务之间的最小化干扰。

    

    多任务学习（MTL）通过利用任务之间的共享信息来学习一个模型来完成多个任务。然而，现有的MTL模型已经被发现存在负面干扰问题。为了减轻任务干扰，已有的努力主要集中在损失/梯度平衡或隐式参数划分上。在本文中，我们提出了ETR-NLP来通过非可学习原语（NLP）和显式任务路由（ETR）的协同组合来减轻任务干扰。我们的关键思想是使用非可学习原语来提取一组多样化的与任务无关的特征，并将它们重新组合成一个共享于所有任务的分支和专门为每个任务保留的显式任务特定分支。非可学习原语和可学习参数的显式解耦为最小化任务干扰提供了所需的灵活性。我们评估了ETR-NLP网络的有效性。

    Multi-task learning (MTL) seeks to learn a single model to accomplish multiple tasks by leveraging shared information among the tasks. Existing MTL models, however, have been known to suffer from negative interference among tasks. Efforts to mitigate task interference have focused on either loss/gradient balancing or implicit parameter partitioning with partial overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task interference through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable primitives to extract a diverse set of task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones afford the flexibility needed for minimizing task interference. We evaluate the efficacy of ETR-NLP networ
    
[^62]: 关于生成人脸模型的生物特征容量

    On the Biometric Capacity of Generative Face Models. (arXiv:2308.02065v1 [cs.CV])

    [http://arxiv.org/abs/2308.02065](http://arxiv.org/abs/2308.02065)

    这篇论文提出了一种统计方法，用于估计在超球特征空间中生成的人脸图像的生物特征容量，并在多个生成模型上进行了实证研究。

    

    在过去几年中，生成逼真面孔的进展非常大。尽管有这些进展，一个关键的问题仍然没有答案：“给定一个生成的人脸模型，它能够生成多少个独特的身份？”换句话说，生成人脸模型的生物特征容量是多少？回答这个问题的科学依据将有助于评估和比较不同的生成人脸模型，并确定它们的可扩展性的上限。本文提出了一种统计方法来估计在一个超球特征空间中生成的人脸图像的生物特征容量。我们在多个生成模型上应用了我们的方法，包括无条件生成器如StyleGAN、潜在扩散模型和“生成的照片”，以及DCF面，一个类条件生成器。我们还估计了与性别和年龄等人口属性相关的容量。我们的容量估计表明，在虚假接受条件下，使用ArcFace表示：

    There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: "Given a generative face model, how many unique identities can it generate?" In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and "Generated Photos," as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false accep
    
[^63]: 准确的神经网络剪枝需要重新思考稀疏优化

    Accurate Neural Network Pruning Requires Rethinking Sparse Optimization. (arXiv:2308.02060v1 [cs.LG])

    [http://arxiv.org/abs/2308.02060](http://arxiv.org/abs/2308.02060)

    这项工作研究了高稀疏对神经网络训练的影响，发现使用传统的密集训练策略进行稀疏训练效果不佳，提出了新的方法来解决这个问题，并在视觉和语言模型上都取得了最先进的结果。

    

    在模型压缩领域，获得既高精确又高稀疏的深度神经网络版本是一个主要挑战，社区已经对几种高性能的剪枝技术进行了研究。然而，我们对稀疏性和用于训练稀疏网络的标准随机优化技术的交互了解较少，大多数现有工作使用标准的密集训练计划和超参数来训练稀疏网络。在这项工作中，我们通过使用标准的计算机视觉和自然语言处理稀疏基准来研究高稀疏对模型训练的影响。我们首先展示了使用标准的密集训练策略进行稀疏训练是次优的，导致欠训练。我们提供了新的方法来解决这个问题，既可以用于视觉模型（如ResNet50/ImageNet）的稀疏预训练，也可以用于语言模型（如BERT/GLUE）的稀疏微调，实现了最先进的结果。

    Obtaining versions of deep neural networks that are both highly-accurate and highly-sparse is one of the main challenges in the area of model compression, and several high-performance pruning techniques have been investigated by the community. Yet, much less is known about the interaction between sparsity and the standard stochastic optimization techniques used for training sparse networks, and most existing work uses standard dense schedules and hyperparameters for training sparse networks. In this work, we examine the impact of high sparsity on model training using the standard computer vision and natural language processing sparsity benchmarks. We begin by showing that using standard dense training recipes for sparse training is suboptimal, and results in under-training. We provide new approaches for mitigating this issue for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE), achieving state-of-the-art resul
    
[^64]: 整合鲁莽行为到基于协同过滤的推荐系统中

    Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])

    [http://arxiv.org/abs/2308.02058](http://arxiv.org/abs/2308.02058)

    本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。

    

    包含可靠性测量的推荐系统往往在预测中更加保守，因为它们需要保持可靠性。这导致了这些系统可以提供的覆盖范围和新颖性的显著下降。在本文中，我们提出了在矩阵分解型推荐系统的学习过程中加入一项新的项，称为鲁莽行为，它可以控制在做出关于预测可靠性的决策时所希望的风险水平。实验结果表明，鲁莽行为不仅允许进行风险调控，还提高了推荐系统提供的预测的数量和质量。

    Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
    
[^65]: 基于自然语言查询的电子商务自动完成的季节性重新排序

    Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries. (arXiv:2308.02055v1 [cs.IR])

    [http://arxiv.org/abs/2308.02055](http://arxiv.org/abs/2308.02055)

    本文提出了一种基于神经网络的自然语言处理算法，用于将季节性作为信号来重新排序电子商务的自动完成功能，从而提高自动完成的相关性和业务指标。

    

    查询自动完成（QAC）也被称为typeahead，它在用户在搜索框中输入前缀时建议完整查询列表。它是现代搜索引擎特别是在电子商务领域的关键功能之一。typeahead的目标之一是向用户建议与季节性相关的重要查询。在本文中，我们提出了一种基于神经网络的自然语言处理（NLP）算法，以将季节性作为一个信号并对QAC排序模型进行端到端评估。将季节性纳入自动完成排序模型中可以提高自动完成的相关性和业务指标。

    Query autocomplete (QAC) also known as typeahead, suggests list of complete queries as user types prefix in the search box. It is one of the key features of modern search engines specially in e-commerce. One of the goals of typeahead is to suggest relevant queries to users which are seasonally important. In this paper we propose a neural network based natural language processing (NLP) algorithm to incorporate seasonality as a signal and present end to end evaluation of the QAC ranking model. Incorporating seasonality into autocomplete ranking model can improve autocomplete relevance and business metric.
    
[^66]: 针对同步随机线性系统的鲁棒独立性检验及有限样本保证

    Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems. (arXiv:2308.02054v1 [stat.ML])

    [http://arxiv.org/abs/2308.02054](http://arxiv.org/abs/2308.02054)

    本文介绍了一种针对同步随机线性系统的鲁棒独立性检验方法，可以提供非渐近性保证的显著水平。该方法结合了置信区间估计、排列检验以及一般的依赖度量，以检测系统之间的任何非线性依赖关系。

    

    本文介绍了一种针对随机线性时不变系统的鲁棒独立性检验方法，其在观测到的输出是同步的情况下可以提供非渐近性保证的显著水平。该方法提供了分布无关的第一类错误概率的界限，即创新项可以具有任意分布。该算法结合了置信区间估计、排列检验以及一般的依赖度量，如希尔伯特-施密特独立性准则和距离协方差，以检测观察到的系统之间的任何非线性依赖关系。我们还证明了在温和的假设下，我们的假设检验的一致性，并通过自回归系统的示例演示了这些思想。

    The paper introduces robust independence tests with non-asymptotically guaranteed significance levels for stochastic linear time-invariant systems, assuming that the observed outputs are synchronous, which means that the systems are driven by jointly i.i.d. noises. Our method provides bounds for the type I error probabilities that are distribution-free, i.e., the innovations can have arbitrary distributions. The algorithm combines confidence region estimates with permutation tests and general dependence measures, such as the Hilbert-Schmidt independence criterion and the distance covariance, to detect any nonlinear dependence between the observed systems. We also prove the consistency of our hypothesis tests under mild assumptions and demonstrate the ideas through the example of autoregressive systems.
    
[^67]: 《一种图形化的文档布局分析方法》

    A Graphical Approach to Document Layout Analysis. (arXiv:2308.02051v1 [cs.LG])

    [http://arxiv.org/abs/2308.02051](http://arxiv.org/abs/2308.02051)

    这项研究提出了一种基于图的文档布局分析方法，通过利用PDF的元数据，将每个页面表示为一个结构化图，并将布局分析问题转化为图分割和分类问题。该方法比现有计算机视觉模型更小且性能更好。

    

    文档布局分析（DLA）是检测文档中不同语义内容并将其正确分类到适当类别（如文本、标题、图表）的任务。DLA流水线使用户能够将文档转换为结构化的机器可读格式，然后可用于许多有用的下游任务。大多数现有的最先进的DLA模型将文档表示为图像，丢弃了在电子生成的PDF中可用的丰富元数据。通过直接利用这些元数据，我们将每个PDF页面表示为一个结构化图，并将DLA问题视为图分割和分类问题。我们引入了基于图的布局分析模型（GLAM），这是一个轻量级的图神经网络，与SOTA模型在两个具有挑战性的DLA数据集上竞争 - 同时比现有模型小一个数量级。特别是，具有400万个参数的GLAM模型优于领先的1.4亿参数计算机视觉模型。

    Document layout analysis (DLA) is the task of detecting the distinct, semantic content within a document and correctly classifying these items into an appropriate category (e.g., text, title, figure). DLA pipelines enable users to convert documents into structured machine-readable formats that can then be used for many useful downstream tasks. Most existing state-of-the-art (SOTA) DLA models represent documents as images, discarding the rich metadata available in electronically generated PDFs. Directly leveraging this metadata, we represent each PDF page as a structured graph and frame the DLA problem as a graph segmentation and classification problem. We introduce the Graph-based Layout Analysis Model (GLAM), a lightweight graph neural network competitive with SOTA models on two challenging DLA datasets - while being an order of magnitude smaller than existing models. In particular, the 4-million parameter GLAM model outperforms the leading 140M+ parameter computer vision-based model 
    
[^68]: FuNToM: 使用神经网络辅助双端口分析方法进行RF电路的功能建模

    FuNToM: Functional Modeling of RF Circuits Using a Neural Network Assisted Two-Port Analysis Method. (arXiv:2308.02050v1 [cs.LG])

    [http://arxiv.org/abs/2308.02050](http://arxiv.org/abs/2308.02050)

    本文介绍了一种名为FuNToM的RF电路功能建模方法，该方法利用了双端口分析方法，并结合神经网络技术，有效地解决了训练数据收集和后布局建模仿真的问题。

    

    自动合成模拟和射频（RF）电路是一种流行的方法，需要一种高效的电路建模方法。这是因为在每个合成周期中运行大量仿真的成本昂贵。人工智能方法是电路建模的有希望的方法，因为它们速度快且相对准确。然而，现有方法需要大量训练数据，这些数据仍然使用模拟运行收集。此外，即使添加或删除一个单一元素，这些方法也需要为每个电路拓扑收集一个完整的单独数据集。这些问题在需要进行后布局建模仿真时尤为严重，而这需要更长的时间。为了解决这些问题，在本文中我们提出了FuNToM，一种用于RF电路的功能建模方法。FuNToM利用了双端口分析方法，使用一个主数据集和多个小数据集来建模多个拓扑。它还利用了神经网络。

    Automatic synthesis of analog and Radio Frequency (RF) circuits is a trending approach that requires an efficient circuit modeling method. This is due to the expensive cost of running a large number of simulations at each synthesis cycle. Artificial intelligence methods are promising approaches for circuit modeling due to their speed and relative accuracy. However, existing approaches require a large amount of training data, which is still collected using simulation runs. In addition, such approaches collect a whole separate dataset for each circuit topology even if a single element is added or removed. These matters are only exacerbated by the need for post-layout modeling simulations, which take even longer. To alleviate these drawbacks, in this paper, we present FuNToM, a functional modeling method for RF circuits. FuNToM leverages the two-port analysis method for modeling multiple topologies using a single main dataset and multiple small datasets. It also leverages neural networks 
    
[^69]: 使用准确的空间成本梯度在可微的高分辨率水文模型中学习划分区域化模型

    Learning Regionalization within a Differentiable High-Resolution Hydrological Model using Accurate Spatial Cost Gradients. (arXiv:2308.02040v1 [cs.LG])

    [http://arxiv.org/abs/2308.02040](http://arxiv.org/abs/2308.02040)

    本文介绍了一种使用准确的空间成本梯度在可微的高分辨率水文模型中学习划分区域化模型的方法，该方法利用可学习的区域化映射，结合数据同化和参数校正，能够在广泛的时空计算域中利用不同数据集进行水文参数估计。

    

    在没有流量数据的未监测流域中估计空间分布的水文参数是一个具有挑战性的区域化问题，需要考虑流量数据的稀疏性并施加空间约束。一种可能的方法是寻找一个定量将物理指标与概念模型参数联系起来的转移函数。本文提出了一种混合数据同化和参数区域化（HDA-PR）方法，将可学习的区域化映射（基于多元回归或神经网络）引入可微的水文模型中。它可以利用准确的伴随梯度在高维的区域化背景下在广泛的时空计算域中利用异质数据。逆问题通过多个观测站点的信息计算校正代价函数来解决。HDA-PR在高分辨率、小时级和公里级的区域模拟中进行了测试。

    Estimating spatially distributed hydrological parameters in ungauged catchments poses a challenging regionalization problem and requires imposing spatial constraints given the sparsity of discharge data. A possible approach is to search for a transfer function that quantitatively relates physical descriptors to conceptual model parameters. This paper introduces a Hybrid Data Assimilation and Parameter Regionalization (HDA-PR) approach incorporating learnable regionalization mappings, based on either multivariate regressions or neural networks, into a differentiable hydrological model. It enables the exploitation of heterogeneous datasets across extensive spatio-temporal computational domains within a high-dimensional regionalization context, using accurate adjoint-based gradients. The inverse problem is tackled with a multi-gauge calibration cost function accounting for information from multiple observation sites. HDA-PR was tested on high-resolution, hourly and kilometric regional mod
    
[^70]: Twitter数据告诉我们关于未来的什么？

    What Twitter Data Tell Us about the Future?. (arXiv:2308.02035v1 [cs.CY])

    [http://arxiv.org/abs/2308.02035](http://arxiv.org/abs/2308.02035)

    本研究通过研究Twitter上未来主义者对未来的预期，探究语言提示对社交媒体用户的预测性思维的影响，并开发了一个可扩展的自然语言处理流程和数据集。

    

    预测是一种基本的人类认知能力，涉及对未来的思考和生活。虽然语言标记反映了预测性思维，但从自然语言处理的角度来研究预测性思维的研究还有限。本研究旨在调查Twitter上未来主义者对未来的预期，并探索语言提示对社交媒体用户的预测性思维的影响。我们解决了Twitter未来主义者预测和分享哪些未来，以及如何从社交数据中建模这些预期未来的研究问题。为了调查这一点，我们回顾了关于预测的相关工作，讨论了语言标记和知名人士对预测性思维的影响，并提出了一个将未来分为“现在的未来”和“未来的现在” 的分类系统。本研究提供了一个由未来影响者公开分享的超过100万条推文的编译数据集，并使用SOTA模型开发了一个可扩展的自然语言处理流程。

    Anticipation is a fundamental human cognitive ability that involves thinking about and living towards the future. While language markers reflect anticipatory thinking, research on anticipation from the perspective of natural language processing is limited. This study aims to investigate the futures projected by futurists on Twitter and explore the impact of language cues on anticipatory thinking among social media users. We address the research questions of what futures Twitter's futurists anticipate and share, and how these anticipated futures can be modeled from social data. To investigate this, we review related works on anticipation, discuss the influence of language markers and prestigious individuals on anticipatory thinking, and present a taxonomy system categorizing futures into "present futures" and "future present". This research presents a compiled dataset of over 1 million publicly shared tweets by future influencers and develops a scalable NLP pipeline using SOTA models. T
    
[^71]: 电动自行车使用的增长：一种机器学习方法

    The Growth of E-Bike Use: A Machine Learning Approach. (arXiv:2308.02034v1 [cs.CY])

    [http://arxiv.org/abs/2308.02034](http://arxiv.org/abs/2308.02034)

    本研究使用机器学习方法，预测了美国电动自行车销量的增长，并评估了影响电动自行车使用的因素。根据预测结果，预计2025年电动自行车销售量为130万辆，2028年为211.3万辆。

    

    本文介绍了电动自行车（电单车）及其对美国政策制定者的影响。电动自行车作为一种快速和环保的交通选择，已经获得了显著的流行。在我们追求可持续能源计划的过程中，了解电动自行车的增长和影响对政策制定者至关重要。我们的数学模型为电动自行车的价值和其在未来的角色提供了洞察。我们使用ARIMA模型，一种监督式的机器学习算法，预测了美国电动自行车销量的增长。我们的模型基于从2006年1月到2022年12月的历史销售数据进行训练，预测2025年销售量为130万辆，2028年销售量为211.3万辆。为了评估影响电动自行车使用的因素，我们采用了随机森林回归模型。影响电动自行车销量增长最显著的因素是可支配个人收入和受欢迎程度。此外，我们还研究了电动自行车对环境和健康的影响。

    We present our work on electric bicycles (e-bikes) and their implications for policymakers in the United States. E-bikes have gained significant popularity as a fast and eco-friendly transportation option. As we strive for a sustainable energy plan, understanding the growth and impact of e-bikes is crucial for policymakers. Our mathematical modeling offers insights into the value of e-bikes and their role in the future. Using an ARIMA model, a supervised machine-learning algorithm, we predicted the growth of e-bike sales in the U.S. Our model, trained on historical sales data from January 2006 to December 2022, projected sales of 1.3 million units in 2025 and 2.113 million units in 2028. To assess the factors contributing to e-bike usage, we employed a Random Forest regression model. The most significant factors influencing e-bike sales growth were disposable personal income and popularity. Furthermore, we examined the environmental and health impacts of e-bikes. Through Monte Carlo si
    
[^72]: 基于知识增强的神经符号人工智能用于网络安全和隐私保护

    Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy. (arXiv:2308.02031v1 [cs.CY])

    [http://arxiv.org/abs/2308.02031](http://arxiv.org/abs/2308.02031)

    知识增强的神经符号人工智能将深度神经网络和符号知识图相结合，提高了人工智能系统的可解释性和安全性，在网络安全和隐私保护领域具有潜在应用价值。

    

    神经符号人工智能是一个新兴且快速发展的领域，它将（深度）神经网络的子符号优势与知识图中的显式符号知识相结合，以提高人工智能系统的可解释性和安全性。这种方法解决了当前一代系统的关键问题，即它们无法为其结果生成人类可理解的解释，并在存在“未知未知”（例如网络安全、隐私）情况下确保安全行为。神经网络（擅长探索复杂数据空间）和符号知识图的整合（代表领域知识）使得人工智能系统能够以专家可理解的方式进行推理、学习和泛化。本文描述了神经符号人工智能如何在网络安全和隐私保护领域中应用，并且这两个领域对于人工智能的可解释性和在复杂环境中的高准确性需求最大，可以从神经符号人工智能中获益。

    Neuro-Symbolic Artificial Intelligence (AI) is an emerging and quickly advancing field that combines the subsymbolic strengths of (deep) neural networks and explicit, symbolic knowledge contained in knowledge graphs to enhance explainability and safety in AI systems. This approach addresses a key criticism of current generation systems, namely their inability to generate human-understandable explanations for their outcomes and ensure safe behaviors, especially in scenarios with \textit{unknown unknowns} (e.g. cybersecurity, privacy). The integration of neural networks, which excel at exploring complex data spaces, and symbolic knowledge graphs, which represent domain knowledge, allows AI systems to reason, learn, and generalize in a manner understandable to experts. This article describes how applications in cybersecurity and privacy, two most demanding domains in terms of the need for AI to be explainable while being highly accurate in complex environments, can benefit from Neuro-Symb
    
[^73]: 基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习在地中海贫血检测中的应用

    Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection. (arXiv:2308.02029v1 [cs.LG])

    [http://arxiv.org/abs/2308.02029](http://arxiv.org/abs/2308.02029)

    本文提出了基于Deep Maxout网络特征融合和Political Tangent Search优化器的转移学习方法，应用于地中海贫血检测。该方法对输入数据进行归一化处理，并利用Deep Maxout网络的特征融合和过采样方法进行数据增强，最终通过转移学习进行地中海贫血检测。

    

    地中海贫血是一种遗传性血液病，由遗传缺陷导致血红蛋白多肽链的产生不足。然而，对这些地区的发病频率和共享程度的了解较少。了解地中海贫血发生的频率和可靠突变是预防、控制和治疗计划的重要一步。本文介绍了基于Political Tangent Search优化器的转移学习（PTSO_TL）在地中海贫血检测中的应用。首先，从特定数据集获取的输入数据在数据归一化阶段进行了规范化。数据归一化阶段利用分位数归一化方法，然后将数据传递给特征融合阶段，在该阶段利用Deep Maxout网络的加权欧氏距离进行特征融合。然后，使用过采样方法进行数据增强以增加数据维度。最后，通过转移学习进行地中海贫血检测。

    Thalassemia is a heritable blood disorder which is the outcome of a genetic defect causing lack of production of hemoglobin polypeptide chains. However, there is less understanding of the precise frequency as well as sharing in these areas. Knowing about the frequency of thalassemia occurrence and dependable mutations is thus a significant step in preventing, controlling, and treatment planning. Here, Political Tangent Search Optimizer based Transfer Learning (PTSO_TL) is introduced for thalassemia detection. Initially, input data obtained from a particular dataset is normalized in the data normalization stage. Quantile normalization is utilized in the data normalization stage, and the data are then passed to the feature fusion phase, in which Weighted Euclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data augmentation is performed using the oversampling method to increase data dimensionality. Lastly, thalassemia detection is carried out by TL, wherein a convol
    
[^74]: 面向自动语音识别的联邦表示学习

    Federated Representation Learning for Automatic Speech Recognition. (arXiv:2308.02013v1 [cs.SD])

    [http://arxiv.org/abs/2308.02013](http://arxiv.org/abs/2308.02013)

    使用联邦学习和自监督学习的结合方法，研究了面向自动语音识别的联邦表示学习，将边缘设备上的隐私数据用于学习健壮的音频表示，并取得了显著的性能改善。

    

    联邦学习（FL）是一种保护隐私的模式，允许边缘设备在不共享数据的情况下进行协作学习。像Alexa和Siri这样的边缘设备是潜在的非标记音频数据来源，可以用来学习健壮的音频表示。在这项工作中，我们将自监督学习（SSL）和FL结合起来，以遵守数据隐私约束条件，学习用于自动语音识别的表示。我们使用未标记的语音数据集Libri-Light中的说话者和章节信息，模拟非独立同分布的说话者隔离数据分布，并使用FedSGD在对比预测编码框架下进行LSTM编码器的预训练。我们展示了在FL中预训练的ASR编码器的性能与中心预训练模型相当，并且相比没有预训练，有12-15%（WER）的改善。我们进一步将联邦预训练模型适应到一种新的语言，法语，并且相比没有预训练，实现了20%（WER）的改善。

    Federated Learning (FL) is a privacy-preserving paradigm, allowing edge devices to learn collaboratively without sharing data. Edge devices like Alexa and Siri are prospective sources of unlabeled audio data that can be tapped to learn robust audio representations. In this work, we bring Self-supervised Learning (SSL) and FL together to learn representations for Automatic Speech Recognition respecting data privacy constraints. We use the speaker and chapter information in the unlabeled speech dataset, Libri-Light, to simulate non-IID speaker-siloed data distributions and pre-train an LSTM encoder with the Contrastive Predictive Coding framework with FedSGD. We show that the pre-trained ASR encoder in FL performs as well as a centrally pre-trained model and produces an improvement of 12-15% (WER) compared to no pre-training. We further adapt the federated pre-trained models to a new language, French, and show a 20% (WER) improvement over no pre-training.
    
[^75]: 具有平滑激活函数的两层神经网络的存储容量研究

    Memory capacity of two layer neural networks with smooth activations. (arXiv:2308.02001v1 [cs.LG])

    [http://arxiv.org/abs/2308.02001](http://arxiv.org/abs/2308.02001)

    研究发现，具有平滑激活函数的两层神经网络的存储容量下界为md/2，并且准确性大致为2倍。分析存储容量的方法包括计算网络雅可比矩阵的秩，并扩展了有关Hadamard幂秩的经典线性代数事实。

    

    确定具有m个隐藏神经元和输入维数d（即md+m个训练参数）的两层神经网络的存储容量，即网络能够记忆的一般数据的最大尺寸，是一个基本的机器学习问题。对于非多项式实解析激活函数，如sigmoid和平滑的修正线性单元（平滑ReLU），我们建立了md/2的下界，并且准确性大约为2倍。类似的先前结果仅限于阶跃函数和ReLU激活函数，对于平滑激活函数的结果受到对数因子和随机数据的限制。为了分析存储容量，我们通过计算涉及Hadamard幂和Khati-Rao积的矩阵的秩来考察网络雅可比矩阵的秩。我们的计算扩展了关于Hadamard幂秩的经典线性代数事实。总体而言，我们的方法与之前关于存储容量的研究不同，并有希望实现。

    Determining the memory capacity of two-layer neural networks with m hidden neurons and input dimension d (i.e., md+m total trainable parameters), which refers to the largest size of general data the network can memorize, is a fundamental machine-learning question. For non-polynomial real analytic activation functions, such as sigmoids and smoothed rectified linear units (smoothed ReLUs), we establish a lower bound of md/2 and optimality up to a factor of approximately 2. Analogous prior results were limited to Heaviside and ReLU activations, with results for smooth activations suffering from logarithmic factors and requiring random data. To analyze the memory capacity, we examine the rank of the network's Jacobian by computing the rank of matrices involving both Hadamard powers and the Khati-Rao product. Our computation extends classical linear algebraic facts about the rank of Hadamard powers. Overall, our approach differs from previous works on memory capacity and holds promise for e
    
[^76]: 从神经表示到符号知识的过渡

    On the Transition from Neural Representation to Symbolic Knowledge. (arXiv:2308.02000v1 [cs.AI])

    [http://arxiv.org/abs/2308.02000](http://arxiv.org/abs/2308.02000)

    该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。

    

    弥合神经表示与符号表示之间的巨大差距可能使符号思维从本质上融入神经网络。受人类如何逐渐从通过知觉和环境交互学习到的原型符号构建复杂的符号表示的启发，我们提出了一种神经-符号过渡字典学习（TDL）框架，该框架使用EM算法学习数据的过渡表示，将输入的高维视觉部分信息压缩到一组张量作为神经变量，并自监督地发现隐含的谓词结构。我们通过将输入分解视为合作博弈来实现框架，使用扩散模型学习谓词，并通过RL基于扩散模型的马尔可夫性质进一步调整学习到的原型，以融入主观因素。

    Bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. Motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. We propose a Neural-Symbolic Transitional Dictionary Learning (TDL) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. We implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. We additionally use RL enabled by the Markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. Extensive experiments 
    
[^77]: 使用深度网络的可解释无监督多模态图像配准

    Explainable unsupervised multi-modal image registration using deep networks. (arXiv:2308.01994v1 [eess.IV])

    [http://arxiv.org/abs/2308.01994](http://arxiv.org/abs/2308.01994)

    这个论文描述了一个使用深度网络进行可解释的无监督多模态图像配准的方法，结合了Grad-CAM-based的可解释性框架，能够处理仿射和非刚性配准，并在临床MRI设置中具有重要应用价值。

    

    磁共振成像(MRI)的临床决策结合了多个MRI序列(定义为"模态")中的互补信息。MRI图像配准旨在几何上"配对"来自不同模态、时间点和切片的诊断结果。在临床MRI设置中，既有内模态MRI配准，也有间模态MRI配准。此外，在能够处理仿射和非刚性配准的MRI图像处理流程中非常重要，因为在真实的MRI数据情况下可能发生这两种类型的变形。与图像分类不同，图像配准深度学习方法中很少涉及可解释性问题，因为很难对模型-数据行为与变换场进行解释。为了正确处理这个问题，我们在我们的无监督多模态和多器官图像配准深度学习方法的每个主要组件中都加入了基于Grad-CAM的可解释性框架。我们先前证明了我们能够达到-

    Clinical decision making from magnetic resonance imaging (MRI) combines complementary information from multiple MRI sequences (defined as 'modalities'). MRI image registration aims to geometrically 'pair' diagnoses from different modalities, time points and slices. Both intra- and inter-modality MRI registration are essential components in clinical MRI settings. Further, an MRI image processing pipeline that can address both afine and non-rigid registration is critical, as both types of deformations may be occuring in real MRI data scenarios. Unlike image classification, explainability is not commonly addressed in image registration deep learning (DL) methods, as it is challenging to interpet model-data behaviours against transformation fields. To properly address this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. We previously demonstrated that we were able to reach su
    
[^78]: CartiMorph:一种自动化膝关节软骨形态学测量的框架

    CartiMorph: a framework for automated knee articular cartilage morphometrics. (arXiv:2308.01981v1 [eess.IV])

    [http://arxiv.org/abs/2308.01981](http://arxiv.org/abs/2308.01981)

    CartiMorph是一种自动化膝关节软骨形态学测量的框架，利用深度学习模型进行图像分析，通过定量指标评估了软骨的损失和厚度，并与手动分割的结果进行了比较，结果显示表面法线的厚度映射方法具有较小的误差。

    

    我们介绍了CartiMorph，一种用于自动化膝关节软骨形态学测量的框架。它以图像作为输入，并生成软骨亚区域的定量指标，包括全厚度软骨丢失（FCL）的百分比、平均厚度、表面积和体积。CartiMorph利用深度学习模型进行分层图像特征表示。我们训练和验证了深度学习模型，用于组织分割、模板构建和模板到图像的注册。我们建立了基于表面法线的软骨厚度映射、FCL估计和基于规则的软骨分割方法。我们的软骨厚度图在薄和周边区域显示出较小的误差。我们通过比较通过模型分割和手动分割获得的定量指标，评估了所采用的分割模型的有效性。FCL测量的均方根偏差小于8%，并且与手动分割的指标存在强相关性。

    We introduce CartiMorph, a framework for automated knee articular cartilage morphometrics. It takes an image as input and generates quantitative metrics for cartilage subregions, including the percentage of full-thickness cartilage loss (FCL), mean thickness, surface area, and volume. CartiMorph leverages the power of deep learning models for hierarchical image feature representation. Deep learning models were trained and validated for tissue segmentation, template construction, and template-to-image registration. We established methods for surface-normal-based cartilage thickness mapping, FCL estimation, and rule-based cartilage parcellation. Our cartilage thickness map showed less error in thin and peripheral regions. We evaluated the effectiveness of the adopted segmentation model by comparing the quantitative metrics obtained from model segmentation and those from manual segmentation. The root-mean-squared deviation of the FCL measurements was less than 8%, and strong correlations 
    
[^79]: 拼写检查器在在线市场中的领域特异性和数据效率：以在线市场搜索为例

    Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])

    [http://arxiv.org/abs/2308.01976](http://arxiv.org/abs/2308.01976)

    本研究针对在线市场中拼写错误的问题，通过数据增强方法和递归神经网络实现了领域特定的拼写检查器，并将其应用在微软AppSource市场的实时推断API中。我们的数据有效解决方案表明，控制高质量的合成数据可能成为一个有力的工具，特别是考虑到当前大语言模型所依赖的巨大且难以控制的数据集。

    

    由于在线市场的领域特定性和用户短查询的特点，错字是在线市场访问者的主要困扰。传统的拼写检查解决方案在纠正拼写错误方面表现不佳。我们提出了一种数据增强方法来解决缺乏标注拼写错误数据的问题，并使用递归神经网络训练了上下文限制的领域特定嵌入。这些嵌入被部署在微软AppSource市场的实时推断API中，以在错误拼写的用户查询和可用产品名称之间找到最接近的匹配。我们的数据有效解决方案表明，受到当前大语言模型的影响，控制高质量的合成数据可能成为一个有力的工具，而这些模型依赖于巨大且难以控制的数据集。

    Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.
    
[^80]: DCTM：扩张卷积转换模型用于多模态对话中的参与度估计

    DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation. (arXiv:2308.01966v1 [cs.MM])

    [http://arxiv.org/abs/2308.01966](http://arxiv.org/abs/2308.01966)

    这项研究引入了一种扩张卷积转换模型，用于在MULTIMEDIATE 2023竞赛中建模和估计多模态对话中的人类参与度。在测试集上该系统比基准模型表现出显著的7%改进，在验证集上表现为4%改进。此外，使用简单的串联方法与自注意力融合可以获得最佳性能。

    

    对话参与度估计被提出作为一个回归问题，需要识别参与者在对话中的关注和参与程度。这一任务对于揭示人类交互动力学和行为模式在对话中的洞察具有重要意义。在本研究中，我们引入了一种扩张卷积转换模型，用于建模和估计MULTIMEDIATE 2023竞赛中的人类参与度。我们提出的系统超过了基准模型，在测试集上获得了显著的7%改进和验证集上的4%改进。此外，我们采用了不同的模态融合机制，并展示对于这种类型的数据，简单的串联方法与自注意力融合获得了最佳性能。

    Conversational engagement estimation is posed as a regression problem, entailing the identification of the favorable attention and involvement of the participants in the conversation. This task arises as a crucial pursuit to gain insights into human's interaction dynamics and behavior patterns within a conversation. In this research, we introduce a dilated convolutional Transformer for modeling and estimating human engagement in the MULTIMEDIATE 2023 competition. Our proposed system surpasses the baseline models, exhibiting a noteworthy $7$\% improvement on test set and $4$\% on validation set. Moreover, we employ different modality fusion mechanism and show that for this type of data, a simple concatenated method with self-attention fusion gains the best performance.
    
[^81]: 将化学引入规模：在深度学习热化学过程中对多元回归的损失权重调整

    Bringing Chemistry to Scale: Loss Weight Adjustment for Multivariate Regression in Deep Learning of Thermochemical Processes. (arXiv:2308.01954v1 [cs.LG])

    [http://arxiv.org/abs/2308.01954](http://arxiv.org/abs/2308.01954)

    本文旨在通过调整损失权重来改善人工神经网络在多元回归任务中学习燃烧查找表的准确性，能够有效地学习所有物种质量分数。

    

    火焰模型广泛应用于计算流体动力学中，用于模拟湍流燃烧中的热化学过程。这些模型通常使用内存密集型的查找表来表示要模拟的燃烧过程。人工神经网络（ANNs）提供了一种深度学习方法，可以使用少量的网络权重存储这些表格数据，从而可能将复杂模拟的内存需求减少数个数量级。然而，具有标准训练损失的ANN在多元回归任务中往往难以处理代表较小物种质量分数的目标值不足的情况，例如在查找表中学习少数物种质量分数。本文旨在提高ANN在学习氢（\ce{H2}）燃烧查找表的多种物种质量分数时的准确性。我们评估了一种简单而有效的损失权重调整方法，优于标准的均方误差优化，并实现了所有物种质量分数的准确学习。

    Flamelet models are widely used in computational fluid dynamics to simulate thermochemical processes in turbulent combustion. These models typically employ memory-expensive lookup tables that are predetermined and represent the combustion process to be simulated. Artificial neural networks (ANNs) offer a deep learning approach that can store this tabular data using a small number of network weights, potentially reducing the memory demands of complex simulations by orders of magnitude. However, ANNs with standard training losses often struggle with underrepresented targets in multivariate regression tasks, e.g., when learning minor species mass fractions as part of lookup tables. This paper seeks to improve the accuracy of an ANN when learning multiple species mass fractions of a hydrogen (\ce{H2}) combustion lookup table. We assess a simple, yet effective loss weight adjustment that outperforms the standard mean-squared error optimization and enables accurate learning of all species ma
    
[^82]: 基于双学生-教师模型的判别性图级异常检测

    Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model. (arXiv:2308.01947v1 [cs.LG])

    [http://arxiv.org/abs/2308.01947](http://arxiv.org/abs/2308.01947)

    本论文提出了一种基于双学生-教师模型的判别性图级异常检测方法，通过定义异常图信息和采用节点级和图级信息差来识别异常图，并引入教师模型和两个竞争的学生模型来提高异常检测的效果。

    

    不同于当前的节点级异常检测任务，图级异常检测的目标是寻找在图集中与其他图显著不同的异常图。由于对图级异常检测的研究较少，关于图级异常的详细描述不足。此外，现有工作集中于捕捉异常图信息以学习更好的图表示，但忽视了对评估异常图的有效异常得分函数的重要性。因此，在这项工作中，我们首先定义了在图集中包括节点和图属性异常的异常图信息，并分别采用节点级和图级信息差来识别它们。然后，我们引入了一个具有双学生-教师模型的判别性图级异常检测框架，其中教师模型通过一种启发式损失进行训练，使得图表示更为分散。然后，两个竞争的学生模型通过争夺任务来提高异常检测效果。

    Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing studen
    
[^83]: 通过四元数进行多机器学习的实验结果

    Experimental Results regarding multiple Machine Learning via Quaternions. (arXiv:2308.01946v1 [cs.LG])

    [http://arxiv.org/abs/2308.01946](http://arxiv.org/abs/2308.01946)

    本论文通过实验研究了在多个机器学习算法中应用四元数的效果。研究结果表明，使用四元数来表示和分类旋转数据，并结合多个机器学习算法，可以获得更高的准确率和性能提升。

    

    本论文介绍了关于在多个机器学习算法中应用四元数的实验研究。四元数是三维空间中旋转的数学表示，可以用于表示复杂的数据转换。在这项研究中，我们探讨了使用四元数来表示和分类旋转数据的方法，使用随机生成的四元数数据和相应的标签，将四元数转换为旋转矩阵，并将其作为输入特征。基于四元数和多个机器学习算法，实验结果显示在预测任务中准确率更高且性能显著提升。总体上，这项研究为利用四元数进行机器学习任务提供了实证基础。

    This paper presents an experimental study on the application of quaternions in several machine learning algorithms. Quaternion is a mathematical representation of rotation in three-dimensional space, which can be used to represent complex data transformations. In this study, we explore the use of quaternions to represent and classify rotation data, using randomly generated quaternion data and corresponding labels, converting quaternions to rotation matrices, and using them as input features. Based on quaternions and multiple machine learning algorithms, it has shown higher accuracy and significantly improved performance in prediction tasks. Overall, this study provides an empirical basis for exploiting quaternions for machine learning tasks.
    
[^84]: 在线多任务学习中基于递归最小二乘和递归核方法的应用

    Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods. (arXiv:2308.01938v1 [stat.ML])

    [http://arxiv.org/abs/2308.01938](http://arxiv.org/abs/2308.01938)

    本文提出了两种新的在线多任务学习方法，分别基于递归最小二乘和递归核方法。与基于梯度下降或不精确逼近的方法不同，我们的方法在每个实例的代价上具有二次复杂度。我们将这些方法应用于风力短期预测挑战，并与其他竞争者进行了比较。

    

    本文提出了两种新颖的在线多任务学习（MTL）回归问题的方法。我们采用高性能基于图的MTL公式，基于加权递归最小二乘（WRLS）和在线稀疏最小二乘支持向量回归（OSLSSVR）开发其递归版本。采用任务堆叠转换，我们展示了存在一个单矩阵，它融合了多任务之间的关系，并为MT-WRLS方法的初始化过程和MT-OSLSSVR的多任务核函数提供结构信息。与现有大部分基于在线梯度下降（OGD）或不精确立方逼近方法的文献相比，我们实现了精确和近似递归，其每个实例的代价在输入空间的维度（MT-WRLS）或实例字典的大小上是二次的。我们将我们的在线MTL方法与其他竞争者在实际风短期预测挑战上进行了比较。

    This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind sp
    
[^85]: 使用组合扩散模型实现训练数据保护

    Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])

    [http://arxiv.org/abs/2308.01937](http://arxiv.org/abs/2308.01937)

    使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。

    

    我们引入了分区扩散模型（CDM），一种在不同数据源上训练不同扩散模型（或提示）并在推断时任意组合它们的方法。这些单独的模型可以在孤立状态下、在不同时间、在不同分布和领域上进行训练，并可以后续组合以达到与同时训练所有数据的理想模型相当的性能。此外，每个模型只包含其在训练期间接触到的数据子集的信息，可以实现多种形式的训练数据保护。特别是，CDM是第一种可以实现大规模扩散模型的选择性遗忘和持续学习的方法，并且允许根据用户访问权限提供定制模型。CDM还可以确定生成特定样本的数据子集的重要性。

    We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
    
[^86]: 对基于机器学习的估计超导体临界温度方法的研究

    Investigation on Machine Learning Based Approaches for Estimating the Critical Temperature of Superconductors. (arXiv:2308.01932v1 [cond-mat.supr-con])

    [http://arxiv.org/abs/2308.01932](http://arxiv.org/abs/2308.01932)

    基于机器学习的方法被用来估计超导体的临界温度，填补了关于超导性和临界温度估计的知识缺口。

    

    超导体一直是最吸引人的物质之一，自其发现以来，超导性的基本概念及临界温度与超导材料的关系一直是广泛研究的重点。然而，如何识别常温下的超导体仍然是一个未解之谜。此外，关于这一独特现象的很多因素和理解上的差距仍然存在，特别是超导性与估计临界温度的基本准则之间的联系。为了填补这一差距，已经建立了许多机器学习技术来估计临界温度，因为确定它是极具挑战性的。此外，各种机器学习方法强调了需要一种复杂且可行的方法来确定超出标准经验公式范围的温度范围。本文使用堆叠机器学习方法来研究这个问题。

    Superconductors have been among the most fascinating substances, as the fundamental concept of superconductivity as well as the correlation of critical temperature and superconductive materials have been the focus of extensive investigation since their discovery. However, superconductors at normal temperatures have yet to be identified. Additionally, there are still many unknown factors and gaps of understanding regarding this unique phenomenon, particularly the connection between superconductivity and the fundamental criteria to estimate the critical temperature. To bridge the gap, numerous machine learning techniques have been established to estimate critical temperatures as it is extremely challenging to determine. Furthermore, the need for a sophisticated and feasible method for determining the temperature range that goes beyond the scope of the standard empirical formula appears to be strongly emphasized by various machine-learning approaches. This paper uses a stacking machine le
    
[^87]: 基于机器学习的光电脉搏信号特征的糖尿病检测

    Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features. (arXiv:2308.01930v1 [cs.LG])

    [http://arxiv.org/abs/2308.01930](http://arxiv.org/abs/2308.01930)

    基于光电脉搏信号特征的机器学习方法用于糖尿病检测，通过非侵入性PPG信号和LR、XGBoost算法的分类，实现了免创伤且连续监测的糖尿病检测。

    

    糖尿病是一种常见的慢性疾病，在全球范围内影响着数百万人的健康。需要无创方法来预防和控制糖尿病，但大多数用于测量血糖水平的设备是有创的，不适合连续监测。在这里，我们提出了一种基于非侵入性光学光电脉搏图（PPG）的方法来检测糖尿病，以克服这些缺点。我们使用PPG信号和元数据对非糖尿病和糖尿病患者进行分类，用于训练逻辑回归（LR）和极限梯度提升（XGBoost）算法。我们使用了一个公开可用的数据集中的PPG信号。为了防止过拟合，我们将数据分成五个部分进行交叉验证。通过确保训练集中的患者不在测试集中，可以在未见过的受试者的数据上评估模型的性能，提供更准确的评估其泛化能力。我们的模型在F1-Score和AUC上分别达到了$58.8\pm20.0\%$和$7

    Diabetes is a prevalent chronic condition that compromises the health of millions of people worldwide. Minimally invasive methods are needed to prevent and control diabetes but most devices for measuring glucose levels are invasive and not amenable for continuous monitoring. Here, we present an alternative method to overcome these shortcomings based on non-invasive optical photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and Diabetic patients using the PPG signal and metadata for training Logistic Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG signals from a publicly available dataset. To prevent overfitting, we divided the data into five folds for cross-validation. By ensuring that patients in the training set are not in the testing set, the model's performance can be evaluated on unseen subjects' data, providing a more accurate assessment of its generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and $7
    
[^88]: 一种基于Transformer的预测靶控输注丙泊酚和瑞芬太尼麻醉深度的方法

    A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil. (arXiv:2308.01929v1 [cs.LG])

    [http://arxiv.org/abs/2308.01929](http://arxiv.org/abs/2308.01929)

    这项研究提出了一种基于Transformer的方法来预测丙泊酚和瑞芬太尼的麻醉深度。该方法通过利用长短时记忆和门控残差网络来提高特征融合的效率，并应用注意机制来发现药物之间的相互作用。实验证明，该方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。

    

    准确预测麻醉效果对于靶控输注系统至关重要。传统的药物动力学-药效学模型需要手动选择模型参数，在临床环境中可能具有挑战性。最近提出的深度学习方法只能捕捉到一般趋势，可能无法预测BIS的突变。为了解决这些问题，我们提出了一种基于Transformer的方法，利用丙泊酚和瑞芬太尼的药物输注来预测麻醉深度。我们的方法采用了长短时记忆（LSTM）和门控残差网络（GRN）来提高特征融合的效率，并应用了注意机制来发现药物之间的相互作用。我们还使用标签分布平滑和重新加权损失来处理数据不平衡。实验结果表明，我们提出的方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。

    Accurately predicting anesthetic effects is essential for target-controlled infusion systems. The traditional (PK-PD) models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic dept
    
[^89]: 数据是否易于K-Means算法 (arXiv:2308.01926v1 [cs.LG])

    Are Easy Data Easy (for K-Means). (arXiv:2308.01926v1 [cs.LG])

    [http://arxiv.org/abs/2308.01926](http://arxiv.org/abs/2308.01926)

    本文研究了各种品牌的K-Means算法对互相分离的聚类的能力，并提出一种性能更优的K-Means++变体算法。

    

    本文研究了各种品牌的K-Means算法在正确恢复互相分离的聚类时的能力。在这里所使用的互相分离的概念直接源自对聚类常见定义的推导，这个定义强调了在簇内同质性和簇间差异性之间的平衡。推导出了一种特殊情况下，具有互相分离性的聚类表现成了K-Means代价函数的全局最小值。通过实验调查发现各种品牌的K-Means算法实际上不能正确地发现互相分离的聚类。我们提出了一种新算法，它是K-Means++的变体，通过重复子采样来选择种子。这个新算法在任务中胜过了K-Means家族中的其他四个算法。

    This paper investigates the capability of correctly recovering well-separated clusters by various brands of the $k$-means algorithm. The concept of well-separatedness used here is derived directly from the common definition of clusters, which imposes an interplay between the requirements of within-cluster-homogenicity and between-clusters-diversity. Conditions are derived for a special case of well-separated clusters such that the global minimum of $k$-means cost function coincides with the well-separatedness. An experimental investigation is performed to find out whether or no various brands of $k$-means are actually capable of discovering well separated clusters. It turns out that they are not. A new algorithm is proposed that is a variation of $k$-means++ via repeated {sub}sampling when choosing a seed. The new algorithm outperforms four other algorithms from $k$-means family on the task.
    
[^90]: 多重保护属性的公平性改善的实证研究

    An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])

    [http://arxiv.org/abs/2308.01923](http://arxiv.org/abs/2308.01923)

    本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。

    

    现有研究主要关注单个保护属性的机器学习（ML）软件的公平性改善，但考虑到许多用户具有多个保护属性，这是不现实的。本文对多个保护属性的公平性改善进行了广泛研究，涵盖了11种最先进的公平性改善方法。我们分析了在考虑多个保护属性时，这些方法在不同数据集、评估指标和ML模型上的有效性。结果显示，改善单个保护属性的公平性大大降低了未考虑的保护属性的公平性。在88.3％的情况下观察到这种降低（平均为57.5％）。更令人惊讶的是，在考虑单个和多个保护属性时，准确率损失方面几乎没有差异，这表明在多属性模式下可以保持准确性。然而，在处理多个保护属性时，精确度和召回率的影响较大。

    Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling
    
[^91]: 可转移的图神经指纹模型快速应对未来生物威胁

    Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.01921](http://arxiv.org/abs/2308.01921)

    该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。

    

    基于配体结合亲和力的药物分子快速筛选是药物发现管线中的重要步骤。图神经指纹是一种用于开发高通量和高准确性分子对接代理的有希望方法。在这项研究中，我们建立了一个包含约30万种药物候选物和23个冠状病毒蛋白靶的COVID-19药物对接数据集。利用这个数据集，我们训练了图神经指纹对接模型，用于高通量虚拟COVID-19药物筛选。图神经指纹模型在对接得分上具有很高的预测准确性，对大多数对接靶点的均方误差低于0.21 kcal/mol，相比传统圆形指纹方法有显著改进。为了使神经指纹适用于未知的靶点，我们还提出了一种在多个靶点上训练的可转移的图神经指纹方法。

    Fast screening of drug molecules based on the ligand binding affinity is an important step in the drug discovery pipeline. Graph neural fingerprint is a promising method for developing molecular docking surrogates with high throughput and great fidelity. In this study, we built a COVID-19 drug docking dataset of about 300,000 drug candidates on 23 coronavirus protein targets. With this dataset, we trained graph neural fingerprint docking models for high-throughput virtual COVID-19 drug screening. The graph neural fingerprint models yield high prediction accuracy on docking scores with the mean squared error lower than $0.21$ kcal/mol for most of the docking targets, showing significant improvement over conventional circular fingerprint methods. To make the neural fingerprints transferable for unknown targets, we also propose a transferable graph neural fingerprint method trained on multiple targets. With comparable accuracy to target-specific graph neural fingerprint models, the transf
    
[^92]: 序列基础的纳米抗体-抗原结合预测

    Sequence-Based Nanobody-Antigen Binding Prediction. (arXiv:2308.01920v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.01920](http://arxiv.org/abs/2308.01920)

    本研究旨在解决纳米抗体生产中的关键挑战，即缺乏与大多数抗原相匹配的纳米抗体。研究针对此问题提出了一种基于序列的方法来预测纳米抗体-抗原的结合。此方法不依赖于3D结构，并且能够提高纳米抗体的生产效率。

    

    纳米抗体(Nb)是来源于骆驼和鲨鱼等动物的单体重链抗体片段。它们的尺寸相对较小（约3-4 nm；13 kDa）且具有良好的生物物理性质，因此成为重组生产的吸引人的目标。此外，纳米抗体具有选择性地结合到特定的抗原，如毒素、化学物质、细菌和病毒，使其成为细胞生物学、结构生物学、医学诊断以及治疗癌症和其他严重疾病的有力工具。然而，纳米抗体在大多数抗原上是不可获得的，这是纳米抗体生产中的一个关键挑战。尽管已经提出一些计算方法来筛选与给定目标抗原相配的潜在纳米抗体，但是由于依赖于3D结构，它们的实际应用受到了严格限制。此外，预测纳米抗体-抗原相互作用（结合）是一项耗时且劳动密集的任务。本研究针对这些问题进行了研究。

    Nanobodies (Nb) are monomeric heavy-chain fragments derived from heavy-chain only antibodies naturally found in Camelids and Sharks. Their considerably small size (~3-4 nm; 13 kDa) and favorable biophysical properties make them attractive targets for recombinant production. Furthermore, their unique ability to bind selectively to specific antigens, such as toxins, chemicals, bacteria, and viruses, makes them powerful tools in cell biology, structural biology, medical diagnostics, and future therapeutic agents in treating cancer and other serious illnesses. However, a critical challenge in nanobodies production is the unavailability of nanobodies for a majority of antigens. Although some computational methods have been proposed to screen potential nanobodies for given target antigens, their practical application is highly restricted due to their reliance on 3D structures. Moreover, predicting nanobodyantigen interactions (binding) is a time-consuming and labor-intensive task. This study
    
[^93]: PePNet: 一种支持罕见重负载的周期性感知工作负载预测网络

    PePNet: A Periodicity-Perceived Workload Prediction Network Supporting Rare Occurrence of Heavy Workload. (arXiv:2308.01917v1 [cs.DC])

    [http://arxiv.org/abs/2308.01917](http://arxiv.org/abs/2308.01917)

    PePNet是一种支持罕见重负载的工作负载预测网络，通过周期性感知机制和融合多尺度序列学习的能力提高了整体特别是重负载的准确性。

    

    云提供商可以从准确的工作负载预测中获得巨大的好处。然而，云服务器的工作负载高度变化，有时会发生重负载突发事件，这使得工作负载预测具有挑战性。目前有两种主要的工作负载预测方法：统计方法和基于神经网络的方法。前者依赖于强大的数学假设，当预测高度变化的工作负载时，其准确性较低。而后者在整体准确性上更高，但容易受到重负载和常见负载之间数据不平衡的影响，这会影响神经网络模型对重负载的预测准确性。无论是统计方法的整体不准确性还是基于神经网络的模型对重负载的不准确性都会导致服务级别协议的违规。因此，我们提出了PePNet来提高整体特别是重负载预测的准确性。它具有两个独特的特点：周期性感知机制和融合多尺度序列学习的能力。

    Cloud providers can greatly benefit from accurate workload prediction. However, the workload of cloud servers is highly variable, with occasional heavy workload bursts. This makes workload prediction challenging.  There are mainly two categories of workload prediction methods: statistical methods and neural-network-based ones. The former ones rely on strong mathematical assumptions and have reported low accuracy when predicting highly variable workload. The latter ones offer higher overall accuracy, yet they are vulnerable to data imbalance between heavy workload and common one. This impairs the prediction accuracy of neural network-based models on heavy workload.  Either the overall inaccuracy of statistic methods or the heavy-workload inaccuracy of neural-network-based models can cause service level agreement violations.  Thus, we propose PePNet to improve overall especially heavy workload prediction accuracy. It has two distinctive characteristics:  (i) A Periodicity-Perceived Mecha
    
[^94]: 半监督元学习在时空学习中的应用

    Semi Supervised Meta Learning for Spatiotemporal Learning. (arXiv:2308.01916v1 [cs.CV])

    [http://arxiv.org/abs/2308.01916](http://arxiv.org/abs/2308.01916)

    本文探讨了半监督元学习在时空学习中的应用，通过将元学习应用于自监督遮蔽自编码器，并结合状态-of-the-art表示学习架构，提出了一种新的框架来解决视频重建和动作分类任务。

    

    我们通过三个步骤来将元学习应用于自监督遮蔽自编码器以进行时空学习。广义上说，我们旨在理解将元学习应用于现有的最先进的表示学习架构的影响。因此，我们通过以下方式测试时空学习：仅元学习架构、仅表示学习架构以及将表示学习与元学习架构相结合的架构。我们利用了增强记忆神经网络（MANN）架构将元学习应用于我们的框架。具体而言，我们首先尝试在小规模时空数据集上应用预训练的自监督遮蔽自编码器，并进行视频重建任务的微调。接下来，我们尝试训练自监督遮蔽自编码器的编码器，并应用分类头进行动作分类任务。最后，我们尝试在预训练的自监督遮蔽自编码器的基础上，用MANN骨干进行微调，用于动作分类任务。

    We approached the goal of applying meta-learning to self-supervised masked autoencoders for spatiotemporal learning in three steps. Broadly, we seek to understand the impact of applying meta-learning to existing state-of-the-art representation learning architectures. Thus, we test spatiotemporal learning through: a meta-learning architecture only, a representation learning architecture only, and an architecture applying representation learning alongside a meta learning architecture. We utilize the Memory Augmented Neural Network (MANN) architecture to apply meta-learning to our framework. Specifically, we first experiment with applying a pre-trained MAE and fine-tuning on our small-scale spatiotemporal dataset for video reconstruction tasks. Next, we experiment with training an MAE encoder and applying a classification head for action classification tasks. Finally, we experiment with applying a pre-trained MAE and fine-tune with MANN backbone for action classification tasks.
    
[^95]: 基于LOB的深度学习模型用于股票价格趋势预测：一项基准研究

    LOB-Based Deep Learning Models for Stock Price Trend Prediction: A Benchmark Study. (arXiv:2308.01915v1 [q-fin.TR])

    [http://arxiv.org/abs/2308.01915](http://arxiv.org/abs/2308.01915)

    本研究通过基准研究探讨了基于LOB数据的股票价格趋势预测的15种最新DL模型的鲁棒性和泛化能力。实验证明这些模型在面对新数据时性能明显下降，对其在实际市场中的应用性提出了问题。

    

    深度学习（DL）研究在金融行业中产生了显著影响。我们研究了基于限价订单簿（LOB）数据的股票价格趋势预测（SPTP）的十五种最新 DL模型的鲁棒性和泛化能力。为了进行这项研究，我们开发了LOBCAST，一个开源框架，包括数据预处理、DL 模型训练、评估和利润分析。我们的大量实验表明，所有模型在面对新数据时性能显著下降，从而对它们在实际市场中的适用性提出了疑问。我们的工作作为一个基准，揭示了当前方法的潜力和局限性，并为创新解决方案提供了见解。

    The recent advancements in Deep Learning (DL) research have notably influenced the finance sector. We examine the robustness and generalizability of fifteen state-of-the-art DL models focusing on Stock Price Trend Prediction (SPTP) based on Limit Order Book (LOB) data. To carry out this study, we developed LOBCAST, an open-source framework that incorporates data preprocessing, DL model training, evaluation and profit analysis. Our extensive experiments reveal that all models exhibit a significant performance drop when exposed to new data, thereby raising questions about their real-world market applicability. Our work serves as a benchmark, illuminating the potential and the limitations of current approaches and providing insight for innovative solutions.
    
[^96]: 商品市场中的深度策略梯度方法

    Deep Policy Gradient Methods in Commodity Markets. (arXiv:2308.01910v1 [q-fin.TR])

    [http://arxiv.org/abs/2308.01910](http://arxiv.org/abs/2308.01910)

    本论文研究了深度强化学习方法在商品交易中的应用，并通过提供流动性和减少市场波动性来稳定市场。这对于解决能源市场的不稳定和全球能源危机具有重要意义。

    

    能源转型增加了对间歇性能源的依赖，不稳定了能源市场并导致了前所未有的波动性，最终导致了2021年的全球能源危机。除了对生产者和消费者造成伤害外，波动的能源市场还可能危及关键的碳减排努力。交易商通过提供流动性和减少波动性在稳定市场中扮演着重要角色。已经提出了几种数学和统计模型用于预测未来收益。然而，由于金融市场的低信噪比和非平稳动态，开发这样的模型并不是易事。本论文研究了深度强化学习方法在商品交易中的有效性。将商品交易问题形式化为连续离散时间随机动力系统。该系统采用了新颖的时间离散化方案，对市场波动做出反应并自适应，提供更好的统计特性。

    The energy transition has increased the reliance on intermittent energy sources, destabilizing energy markets and causing unprecedented volatility, culminating in the global energy crisis of 2021. In addition to harming producers and consumers, volatile energy markets may jeopardize vital decarbonization efforts. Traders play an important role in stabilizing markets by providing liquidity and reducing volatility. Several mathematical and statistical models have been proposed for forecasting future returns. However, developing such models is non-trivial due to financial markets' low signal-to-noise ratios and nonstationary dynamics.  This thesis investigates the effectiveness of deep reinforcement learning methods in commodities trading. It formalizes the commodities trading problem as a continuing discrete-time stochastic dynamical system. This system employs a novel time-discretization scheme that is reactive and adaptive to market volatility, providing better statistical properties f
    
[^97]: MRQ:通过模型重新量化支持多种量化方案

    MRQ:Support Multiple Quantization Schemes through Model Re-Quantization. (arXiv:2308.01867v1 [cs.LG])

    [http://arxiv.org/abs/2308.01867](http://arxiv.org/abs/2308.01867)

    该论文提出了一种名为MRQ的模型重新量化方法，通过将现有的量化模型快速转换以满足不同的量化要求，解决了在固定点硬件上部署深度学习模型的挑战。

    

    尽管各种硬件加速器（如NPU，TPU，DPU）的普及，但在固定点硬件上部署深度学习模型仍然具有挑战性，原因是复杂的模型量化和转换。现有的模型量化框架（如Tensorflow QAT，TFLite PTQ和Qualcomm AIMET）只支持有限的量化方案（如仅在TF1.x QAT中的非对称每张量量化）。因此，由于稍微不同的量化要求，深度学习模型不能轻松地为各种固定点硬件进行量化。在本文中，我们设想了一种新型的模型量化方法，称为MRQ（模型重新量化），它可以采用现有的量化模型，并快速将模型转换为满足不同量化要求（如非对称->对称，非2的幂次->2的幂次）。重新量化比从头开始进行量化要简单得多，因为它避免了昂贵的重新训练。

    Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU, DPU), deploying deep learning models on edge devices with fixed-point hardware is still challenging due to complex model quantization and conversion. Existing model quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and Qualcomm AIMET [3] supports only a limited set of quantization schemes (e.g., only asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep learning models cannot be easily quantized for diverse fixed-point hardwares, mainly due to slightly different quantization requirements. In this paper, we envision a new type of model quantization approach called MRQ (model re-quantization), which takes existing quantized models and quickly transforms the models to meet different quantization requirements (e.g., asymmetric -> symmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much simpler than quantizing from scratch because it avoids costly re-training and
    
[^98]: 蒙骗：基于文本的游戏中的欺骗与合作研究

    Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v1 [cs.CL])

    [http://arxiv.org/abs/2308.01404](http://arxiv.org/abs/2308.01404)

    通过引入一款名为"Hoodwinked"的文本游戏，研究了当前语言模型是否具有欺骗和识别谎言的能力。实验证据表明，杀手经常否认罪行并指责他人，导致投票结果受到影响。更先进的模型在杀手效果上表现出优势。实验证据表明，这种改进是通过在讨论中更强的欺骗能力实现的。

    

    当前的语言模型是否具有欺骗和识别谎言的能力？我们通过引入一款名为“Hoodwinked”的基于文本的游戏，受到“黑帮”和“谁是卧底”游戏的启发，来研究这个问题。玩家们被锁在一个房子里，必须找到一把钥匙才能逃脱，但其中一个玩家被派任务杀死其他人。每次发生谋杀，幸存的玩家们会进行自然语言讨论，然后投票将一名玩家放逐出游戏。我们使用GPT-3、GPT-3.5和GPT-4操控代理进行实验，并发现了欺骗和识别谎言的能力证据。杀手经常否认自己的罪行并指责他人，导致投票结果受到可测量的影响。更先进的模型在24个两两比较中的18个中表现出更高的杀手效果，超越了更小的模型。次要指标提供了证据，表明这种改进并不是通过不同的行动实现的，而是通过在讨论中更强的欺骗能力实现的。总的来说，我们发现了实质性的创新。

    Are current language models capable of deception and lie detection? We study this question by introducing a text-based game called $\textit{Hoodwinked}$, inspired by $\textit{Mafia}$ and $\textit{Among Us}$. Players are locked in a house and must find a key to escape, but one player is tasked with killing the others. Each time a murder is committed, the surviving players have a natural language discussion then vote to banish one player from the game. We conduct experiments with agents controlled by GPT-3, GPT-3.5, and GPT-4 and find evidence of deception and lie detection capabilities. The killer often denies their crime and accuses others, leading to measurable effects on voting outcomes. More advanced models are more effective killers, outperforming smaller models in 18 of 24 pairwise comparisons. Secondary metrics provide evidence that this improvement is not mediated by different actions, but rather by stronger deception capabilities during discussions. Overall, we find substantial
    
[^99]: 在胸部X射线分类中消除错误相关性

    Unlearning Spurious Correlations in Chest X-ray Classification. (arXiv:2308.01119v1 [eess.IV])

    [http://arxiv.org/abs/2308.01119](http://arxiv.org/abs/2308.01119)

    本论文提出了一种深度学习方法（XBL），通过利用模型解释来交互式地消除胸部X射线分类中的错误相关性。该方法可以帮助解决多数据源引入的混淆因素，提高模型的准确性和透明度。

    

    医学图像分类模型通常使用来自多个数据源的训练数据集进行训练。虽然利用多个数据源对于实现模型的泛化至关重要，但必须承认，这些数据源的多样性本质上引入了意外的混淆因素和其他可能影响模型准确性和透明度的挑战。在医学图像分类中一个显著的混淆因素，特别是在肌骨图像分类中，是在青春期观察到的骨骼成熟引起的骨骼生长。我们使用COVID-19胸部X射线数据集训练了一个深度学习模型，并展示了该数据集由于意外混淆区域可能导致错误相关性。基于解释的学习（XBL）是一种深度学习方法，通过利用模型解释来交互式地消除错误相关性，使其超越了可解释性。这是通过整合交互式用户反馈、精确的region-of-interest逐渐消褪等方法来实现的。

    Medical image classification models are frequently trained using training datasets derived from multiple data sources. While leveraging multiple data sources is crucial for achieving model generalization, it is important to acknowledge that the diverse nature of these sources inherently introduces unintended confounders and other challenges that can impact both model accuracy and transparency. A notable confounding factor in medical image classification, particularly in musculoskeletal image classification, is skeletal maturation-induced bone growth observed during adolescence. We train a deep learning model using a Covid-19 chest X-ray dataset and we showcase how this dataset can lead to spurious correlations due to unintended confounding regions. eXplanation Based Learning (XBL) is a deep learning approach that goes beyond interpretability by utilizing model explanations to interactively unlearn spurious correlations. This is achieved by integrating interactive user feedback, specifi
    
[^100]: 人工智能提高了全球可靠洪水预警的覆盖范围

    AI Increases Global Access to Reliable Flood Forecasts. (arXiv:2307.16104v1 [cs.LG])

    [http://arxiv.org/abs/2307.16104](http://arxiv.org/abs/2307.16104)

    本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。

    

    洪水是最常见和影响最大的自然灾害之一，对发展中国家尤其具有不对称的影响，这些国家往往缺乏密集的水流监测网络。准确及时的预警对于减轻洪水风险至关重要，但准确的水文模拟模型通常需要根据每个应用的流域中的长时间数据记录进行校准。我们开发了一个人工智能（AI）模型，可以预测7天内的极端水文事件。该模型在所有大洲、前导时间和重现期中均明显优于当前最先进的全球水文模型（Copernicus应急管理服务全球洪水意识系统）。AI在未经测量的流域中的预测尤其有效，这很重要，因为全球只有百分之几的流域具有流量观测站，而发展中国家的未经测量的流域数量占比很高，对人类特别脆弱。

    Floods are one of the most common and impactful natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow monitoring networks. Accurate and timely warnings are critical for mitigating flood risks, but accurate hydrological simulation models typically must be calibrated to long data records in each watershed where they are applied. We developed an Artificial Intelligence (AI) model to predict extreme hydrological events at timescales up to 7 days in advance. This model significantly outperforms current state of the art global hydrology models (the Copernicus Emergency Management Service Global Flood Awareness System) across all continents, lead times, and return periods. AI is especially effective at forecasting in ungauged basins, which is important because only a few percent of the world's watersheds have stream gauges, with a disproportionate number of ungauged basins in developing countries that are especially vulnerable to the human 
    
[^101]: 初始化状态干预对解决去除混淆的模仿学习问题的影响

    Initial State Interventions for Deconfounded Imitation Learning. (arXiv:2307.15980v1 [cs.LG])

    [http://arxiv.org/abs/2307.15980](http://arxiv.org/abs/2307.15980)

    本文介绍了一种针对模仿学习中因果混淆问题的初始化状态干预算法，该算法能够遮蔽观测中的混淆因素并提高性能表现。

    

    模仿学习存在因果混淆问题，即学习策略关注的特征并不因果地影响专家的行为，而是表面上的相关性。因果混淆的智能体在训练中产生了低的开环监督损失，但在部署时表现出差的闭环性能。我们考虑在观测空间的分离表示中遮蔽已观测到的混淆因素的问题。我们提出了一种新的遮蔽算法，利用了对初始系统状态进行干预的能力，避免了对专家查询、专家奖励函数或因果图规范的任何要求。在一定的假设下，我们在理论上证明了该算法是保守的，即不会错误地遮蔽因果相关的观测；此外，对初始状态的干预能够严格减少过度保守性。该遮蔽算法被应用于两个示例控制系统的行为克隆中。

    Imitation learning suffers from causal confusion. This phenomenon occurs when learned policies attend to features that do not causally influence the expert actions but are instead spuriously correlated. Causally confused agents produce low open-loop supervised loss but poor closed-loop performance upon deployment. We consider the problem of masking observed confounders in a disentangled representation of the observation space. Our novel masking algorithm leverages the usual ability to intervene in the initial system state, avoiding any requirement involving expert querying, expert reward functions, or causal graph specification. Under certain assumptions, we theoretically prove that this algorithm is conservative in the sense that it does not incorrectly mask observations that causally influence the expert; furthermore, intervening on the initial state serves to strictly reduce excess conservatism. The masking algorithm is applied to behavior cloning for two illustrative control system
    
[^102]: 非对抗性后门防御

    Backdoor Defense with Non-Adversarial Backdoor. (arXiv:2307.15539v1 [cs.LG])

    [http://arxiv.org/abs/2307.15539](http://arxiv.org/abs/2307.15539)

    提出了一种非对抗性后门防御框架，通过在被污染样本中注入非对抗性后门，当触发时可以抑制攻击者对污染数据的后门攻击，同时保持对干净数据的影响有限。

    

    深度神经网络（DNNs）容易受到后门攻击的影响，这种攻击并不会影响网络对干净数据的性能，但一旦添加触发模式，就会操纵网络行为。现有的防御方法大大降低了攻击成功率，但它们在干净数据上的预测准确性仍然远远落后于干净模型。受后门攻击的隐蔽性和有效性的启发，我们提出了一个简单但非常有效的防御框架，该框架注入了针对被污染样本的非对抗性后门。按照后门攻击的一般步骤，我们检测一小组可疑样本，然后对它们应用毒化策略。一旦触发，非对抗性后门抑制了攻击者对污染数据的后门攻击，但对干净数据的影响有限。防御可以在数据预处理期间进行，而不需要对标准的端到端训练流程进行任何修改。

    Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on mul
    
[^103]: 基于差分进化算法的Transformer神经网络模型用于负荷预测的超参数选择

    Differential Evolution Algorithm based Hyper-Parameters Selection of Transformer Neural Network Model for Load Forecasting. (arXiv:2307.15299v1 [cs.NE])

    [http://arxiv.org/abs/2307.15299](http://arxiv.org/abs/2307.15299)

    本研究使用差分进化算法选择Transformer神经网络模型的优化超参数，以提高负荷预测的准确性。

    

    精确的负荷预测在众多领域都起着重要作用，但准确捕捉动力系统的复杂动态仍然是传统统计模型面临的挑战。因此，时间序列模型（ARIMA）和深度学习模型（ANN，LSTM，GRU等）经常被使用，并且通常能够取得更好的成功率。本文分析了最近开发的Transformer-based神经网络模型在负荷预测中的效果。Transformer模型有望改进负荷预测，因为它们能够通过其Attention机制学习到长期依赖关系。我们运用了几种元启发式算法，如差分进化，以寻找Transformer-based神经网络的最优超参数，以产生精确的预测。差分进化为非可微分、多目标或约束优化问题提供了可扩展、强健和全局的解决方案。我们的工作比较了所提出的基于Transformer的神经网络与其他模型在负荷预测上的性能。

    Accurate load forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of dynamic power systems remains a challenge for traditional statistical models. For these reasons, time-series models (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly deployed and often experience higher success. In this paper, we analyze the efficacy of the recently developed Transformer-based Neural Network model in Load forecasting. Transformer models have the potential to improve Load forecasting because of their ability to learn long-range dependencies derived from their Attention Mechanism. We apply several metaheuristics namely Differential Evolution to find the optimal hyperparameters of the Transformer-based Neural Network to produce accurate forecasts. Differential Evolution provides scalable, robust, global solutions to non-differentiable, multi-objective, or constrained optimization problems. Our work compares the proposed Transformer based Ne
    
[^104]: 使用变分自动编码器学习随机过程的最小表示

    Learning minimal representations of stochastic processes with variational autoencoders. (arXiv:2307.11608v1 [cond-mat.soft])

    [http://arxiv.org/abs/2307.11608](http://arxiv.org/abs/2307.11608)

    本文引入了一种无监督机器学习方法，使用变分自动编码器确定最小参数集，有效描述随机过程动力学，并生成能准确复制预期随机行为的新轨迹。

    

    随机过程在科学中有许多应用，因为它们广泛用于模拟各种自然现象。由于其固有的随机性和不确定性，它们很难进行表征。在这里，我们引入了一种无监督机器学习方法，用于确定有效描述随机过程动力学所需的最小参数集。我们的方法建立在扩展的β-变分自动编码器架构上。通过与典型扩散模型相对应的模拟数据集，我们展示了它在提取能准确描述这些动力学的最小相关参数方面的有效性。此外，该方法可以生成忠实复制预期随机行为的新轨迹。总体而言，我们的方法使得能够自动发现描述随机过程的未知参数，从而增进对各个领域中复杂现象的理解。

    Stochastic processes have found numerous applications in science, as they are broadly used to model a variety of natural phenomena. Due to their intrinsic randomness and uncertainty, they are however difficult to characterize. Here, we introduce an unsupervised machine learning approach to determine the minimal set of parameters required to effectively describe the dynamics of a stochastic process. Our method builds upon an extended $\beta$-variational autoencoder architecture. By means of simulated datasets corresponding to paradigmatic diffusion models, we showcase its effectiveness in extracting the minimal relevant parameters that accurately describe these dynamics. Furthermore, the method enables the generation of new trajectories that faithfully replicate the expected stochastic behavior. Overall, our approach enables for the autonomous discovery of unknown parameters describing stochastic processes, hence enhancing our comprehension of complex phenomena across various fields.
    
[^105]: 关于插值专家和多臂赌博机的研究

    On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])

    [http://arxiv.org/abs/2307.07264](http://arxiv.org/abs/2307.07264)

    学习专家建议和多臂赌博是两个经典的在线决策问题，我们研究了两者之间的插值问题。我们提出了$\mathbf{m}$-MAB的极小后悔界并设计了$\mathbf{m}$-BAI的最优PAC算法，该算法旨在以尽可能少的轮数确定损失最小的臂。

    

    学习专家建议和多臂赌博是两个经典的在线决策问题，它们在每一轮观察信息的方式上有所不同。我们研究了这两者之间的插值问题。对于向量$\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$，$\mathbf{m}$-MAB的一个实例表示将臂分成$K$组，第$i$组包含$m_i$个臂。一旦拉动一个臂，同一组中所有臂的损失都被观察到。我们证明了$\mathbf{m}$-MAB的紧致极小后悔界，并为其纯探索版本$\mathbf{m}$-BAI设计了一个最优的PAC算法，其中目标是用尽可能少的轮数来识别损失最小的臂。我们证明了$\mathbf{m}$-MAB的极小后悔是$\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$，对于一个$(\epsilon,0.05)$-PAC算法的$\mathbf{m}$-BAI，拉动臂的最小次数是$\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$。

    Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$, an instance of $\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\mathbf{m}$-MAB is $\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$ and the minimum number of pulls for an $(\epsilon,0.05)$-PAC algorithm of $\mathbf{m}$-BAI is $\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$. Bot
    
[^106]: LeCo：通过学习序列相关性实现轻量级压缩

    LeCo: Lightweight Compression via Learning Serial Correlations. (arXiv:2306.15374v1 [cs.DB])

    [http://arxiv.org/abs/2306.15374](http://arxiv.org/abs/2306.15374)

    使用机器学习来自动消除序列冗余以实现出色的压缩比和解压缩性能的LeCo是一种轻量级压缩框架，通过学习序列相关性，它能够在压缩比和随机访问速度上实现帕累托改进。

    

    轻量级数据压缩是一种关键技术，它使得列式存储在分析查询方面展示出卓越的性能。尽管之前有关基于字典编码来逼近Shannon熵的研究已经很全面，但鲜有之前的工作系统地利用列的序列相关性来进行压缩。在本文中，我们提出了LeCo（即学习压缩），这是一种使用机器学习自动消除序列冗余以实现出色的压缩比和解压缩性能的框架。LeCo提供了一种通用的方法来实现这一目标，在我们的框架下，现有的（临时的）算法，如参考帧（Frame-of-Reference），Delta编码和游程编码（Run-Length Encoding）都是特例。我们对三个合成数据集和六个真实数据集进行的微基准测试显示，LeCo原型在压缩比和随机访问速度上相比现有解决方案取得了帕累托改进。当将LeCo集成时

    Lightweight data compression is a key technique that allows column stores to exhibit superior performance for analytical queries. Despite a comprehensive study on dictionary-based encodings to approach Shannon's entropy, few prior works have systematically exploited the serial correlation in a column for compression. In this paper, we propose LeCo (i.e., Learned Compression), a framework that uses machine learning to remove the serial redundancy in a value sequence automatically to achieve an outstanding compression ratio and decompression performance simultaneously. LeCo presents a general approach to this end, making existing (ad-hoc) algorithms such as Frame-of-Reference (FOR), Delta Encoding, and Run-Length Encoding (RLE) special cases under our framework. Our microbenchmark with three synthetic and six real-world data sets shows that a prototype of LeCo achieves a Pareto improvement on both compression ratio and random access speed over the existing solutions. When integrating LeC
    
[^107]: 基于掩码Token Transformer的大规模MIMO系统联合信道估计和反馈

    Joint Channel Estimation and Feedback with Masked Token Transformers in Massive MIMO Systems. (arXiv:2306.06125v1 [cs.IT])

    [http://arxiv.org/abs/2306.06125](http://arxiv.org/abs/2306.06125)

    本论文提出了一种基于深度学习和掩码Token Transformer的联合信道估计和反馈框架，有效提高了大规模MIMO系统中信道估计和反馈的性能。

    

    当基站具有下行通道状态信息（CSI）时，可以充分利用大规模多输入多输出（MIMO）在频分双工（FDD）模式下的潜力。本文提出了基于深度学习的联合信道估计和反馈框架，以实现大规模MIMO系统中的信道估计和反馈。具体而言，我们采用传统通道设计而非端到端方法。我们的模型包含两个网络。第一个网络是信道估计网络，采用双重损失设计，可以准确地估计完整的信道信息并消除信道噪声。第二个网络是压缩和反馈网络。受掩码Token Transformer的启发，我们提出了一种可学习的掩码Token方法，以获得出色的估计和压缩性能。广泛的仿真结果和削弱研究表明，我们的方法优于最先进的信道估计和反馈方法。

    When the base station has downlink channel status information (CSI), the huge potential of large-scale multiple input multiple output (MIMO) in frequency division duplex (FDD) mode can be fully exploited. In this paper, we propose a deep-learning-based joint channel estimation and feedback framework to realize channel estimation and feedback in massive MIMO systems. Specifically, we use traditional channel design rather than end-to-end methods. Our model contains two networks. The first network is a channel estimation network, which adopts a double loss design, and can accurately estimate the full channel information while removing channel noises. The second network is a compression and feedback network. Inspired by the masked token transformer, we propose a learnable mask token method to obtain excellent estimation and compression performance. The extensive simulation results and ablation studies show that our method outperforms state-of-the-art channel estimation and feedback methods
    
[^108]: 利用密度函数的非线性变换估计岭

    Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])

    [http://arxiv.org/abs/2306.05722](http://arxiv.org/abs/2306.05722)

    本文探索了利用密度函数的非线性变换对岭的估计，并发现其可以改进对切空间的估计以及在近似底层真实流形方面优于其他流形拟合算法。

    

    岭在准确近似流形的基础结构方面发挥着重要作用。本文通过将凹非线性变换应用于密度函数以探索岭的变化。通过对Hessian矩阵的推导和分析，我们发现非线性变换产生了Hessian矩阵的秩一修改。利用特征值问题的变分性质，我们建立了相应岭之间的偏序包含关系。我们直观地发现，通过Hessian矩阵的秩一修改，变换可以导致对切空间的估计改进。为验证我们的理论，我们在合成和真实世界数据集上进行了大量数值实验，证明了与其他流形拟合算法相比，我们的变换方法得到的岭在近似底层真实流形方面更加优越。

    Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
    
[^109]: 基于联邦深度学习的物联网入侵检测

    Federated Deep Learning for Intrusion Detection in IoT Networks. (arXiv:2306.02715v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2306.02715](http://arxiv.org/abs/2306.02715)

    本研究提出了一种基于联邦深度学习的入侵检测框架，可在保护数据隐私和局部性的同时实现高效的模型收敛，该框架在物联网入侵检测应用中具有潜力。

    

    物联网技术的大幅增长和攻击向量和威胁行为的不断演化，显著增加了网络安全风险。新型攻击可能会危及物联网设备，以获取对敏感数据的访问或控制它们以部署进一步的恶意活动。检测新型攻击通常依赖于人工智能解决方案。在分布式物联网系统中实现基于AI的入侵检测的常见方法是以集中方式实现。然而，此方法可能会侵犯数据隐私和保密性。此外，集中式数据采集禁止IDS的扩展。因此，物联网生态系统中的入侵检测解决方案需要朝分散化方向发展。联邦学习由于能够在保留数据机密性和局部性的同时进行协作学习而受到了广泛的关注。尽管如此，大多数基于联邦学习的物联网系统IDS都是在不切实际的数据分布条件下设计的。为此，我们设计了一个代表物联网生态系统中实际数据分布的实验，并提出了一种基于联邦深度学习（FDL）框架的物联网入侵检测方法。我们的方法整合了CNN模型和门控机制，以实现有效的模型收敛，同时保护数据隐私和局部性。实验结果表明，我们的FDL框架显著优于其他最先进的方法，表明其在实际物联网入侵检测应用中具有潜力。

    The vast increase of IoT technologies and the ever-evolving attack vectors and threat actors have increased cyber-security risks dramatically. Novel attacks can compromise IoT devices to gain access to sensitive data or control them to deploy further malicious activities. The detection of novel attacks often relies upon AI solutions. A common approach to implementing AI-based IDS in distributed IoT systems is in a centralised manner. However, this approach may violate data privacy and secrecy. In addition, centralised data collection prohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT ecosystems need to move towards a decentralised direction. FL has attracted significant interest in recent years due to its ability to perform collaborative learning while preserving data confidentiality and locality. Nevertheless, most FL-based IDS for IoT systems are designed under unrealistic data distribution conditions. To that end, we design an experiment representative o
    
[^110]: 在多人多臂赌博机中竞争可分享的手臂

    Competing for Shareable Arms in Multi-Player Multi-Armed Bandits. (arXiv:2305.19158v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19158](http://arxiv.org/abs/2305.19158)

    本文研究了在多人多臂赌博机中竞争可分享的手臂的问题。我们提出了一种新的自私MPMAB与分配平均算法（SMAA）方法，理论上证明了在玩家遵循该算法的情况下可以实现良好的后悔保证。此外，我们还证明了没有单个自私的玩家能通过偏离显著增加他们的回报。

    

    长期以来，竞争可分享和有限资源的研究一直是战略性代理人的主题。在现实中，代理人经常需要同时学习和最大化资源的回报。为了设计个性化的竞争策略，我们在一种新颖的多人多臂赌博机（MPMAB）设置中建模了代理人之间的竞争，其中玩家自私并旨在最大化自己的回报。此外，当几个玩家拉动相同的手臂时，我们假设这些玩家通过期望平均分享手臂的回报。在这种设置下，我们首先分析了当手臂的回报已知时的纳什均衡。随后，我们提出了一种基于该均衡的新颖的自私MPMAB与分配平均算法（SMAA）方法。我们从理论上证明，当所有玩家都遵循该算法时，SMAA可以为每个玩家实现良好的后悔保证。此外，我们还证明了没有单个自私的玩家能通过偏离显著增加他们的回报，也不能...

    Competitions for shareable and limited resources have long been studied with strategic agents. In reality, agents often have to learn and maximize the rewards of the resources at the same time. To design an individualized competing policy, we model the competition between agents in a novel multi-player multi-armed bandit (MPMAB) setting where players are selfish and aim to maximize their own rewards. In addition, when several players pull the same arm, we assume that these players averagely share the arms' rewards by expectation. Under this setting, we first analyze the Nash equilibrium when arms' rewards are known. Subsequently, we propose a novel Selfish MPMAB with Averaging Allocation (SMAA) approach based on the equilibrium. We theoretically demonstrate that SMAA could achieve a good regret guarantee for each player when all players follow the algorithm. Additionally, we establish that no single selfish player can significantly increase their rewards through deviation, nor can they
    
[^111]: 缓解上下文学习的标签偏差

    Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19148](http://arxiv.org/abs/2305.19148)

    本文针对上下文学习（ICL）中的三种标签偏差提出分类法，并提出一种简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。

    

    上下文学习（ICL）的各种设计设置，如选择和顺序的上下文示例，可能使模型对某种特定预测偏见，而这种预测并不反映对任务的理解。虽然许多研究讨论了这些设计选择，但对它们进行分类和减缓其影响的系统调查很少。在本文中，我们为文本分类中上下文学习（ICL）中的三种标签偏差定义了一个分类法：香草标签偏差、上下文标签偏差和领域标签偏差（我们首次概念化和检测到）。我们的分析表明，先前的标签偏差校准方法不能解决所有三种偏差。特别是，领域标签偏差使LLM在许多任务上只能实现随机级别的性能，而不管上下文示例的选择如何。为了缓解这些偏差的影响，我们提出一个简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。

    Various design settings for in-context learning (ICL), such as the choice and order of the in-context examples, can bias a model toward a particular prediction without being reflective of an understanding of the task. While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact. In this work, we define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias (which we conceptualize and detect for the first time).  Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases. Specifically, domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples. To mitigate the effect of these biases, we propose a simple bias calibration method that estimates a language model's label bias using random in-domain words f
    
[^112]: 基于卷积生成对抗网络生成混沌时间序列的评价

    Evaluating generation of chaotic time series by convolutional generative adversarial networks. (arXiv:2305.16729v1 [cs.LG])

    [http://arxiv.org/abs/2305.16729](http://arxiv.org/abs/2305.16729)

    该研究通过使用卷积生成对抗网络生成混沌时间序列，并评估生成的时间序列，证明了卷积神经网络有能力很好地复制原始时间序列的混沌特性，但误差分析表明仍然存在大误差。

    

    为了了解卷积神经网络生成类似于复杂时间信号的时间序列的能力和局限性，我们训练了一个由深度卷积网络组成的生成对抗网络来生成混沌时间序列，并使用非线性时间序列分析来评估生成的时间序列。确定性的数字度量和李雅普诺夫指数，一个轨迹不稳定的度量，表明生成的时间序列很好地复制了原始时间序列的混沌特性。然而，误差分布分析表明，低但不可忽略的速率下会出现大误差。如果假定分布为指数分布，则不会出现这样的误差。

    To understand the ability and limitations of convolutional neural networks to generate time series that mimic complex temporal signals, we trained a generative adversarial network consisting of deep convolutional networks to generate chaotic time series and used nonlinear time series analysis to evaluate the generated time series. A numerical measure of determinism and the Lyapunov exponent, a measure of trajectory instability, showed that the generated time series well reproduce the chaotic properties of the original time series. However, error distribution analyses showed that large errors appeared at a low but non-negligible rate. Such errors would not be expected if the distribution were assumed to be exponential.
    
[^113]: 用于带测量噪声的Ornstein-Uhlenbeck过程参数估计

    Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise. (arXiv:2305.13498v1 [stat.ML])

    [http://arxiv.org/abs/2305.13498](http://arxiv.org/abs/2305.13498)

    本文研究了带有测量噪声的Ornstein-Uhlenbeck过程参数估计，提出了算法和方法能够分离热噪声和乘性噪声，并改善数据分析的参数估计精度。

    

    本文旨在研究噪声对Ornstein-Uhlenbeck过程参数拟合的影响，重点考察了乘性噪声和热噪声对信号分离精度的影响。为了解决这些问题，我们提出了有效区分热噪声和乘性噪声、改善参数估计精度的算法和方法，探讨了乘性和热噪声对实际信号混淆的影响，并提出了解决方法。首先，我们提出了一种可以有效分离热噪声的算法，其性能可与Hamilton Monte Carlo (HMC)相媲美，但速度显著提高。随后，我们分析了乘性噪声，并证明了HMC无法隔离热噪声和乘性噪声。然而，我们展示了，在额外了解热噪声和乘性噪声之间比率的情况下，我们可以精确地估计参数和分离信号。

    This article aims to investigate the impact of noise on parameter fitting for an Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and thermal noise on the accuracy of signal separation. To address these issues, we propose algorithms and methods that can effectively distinguish between thermal and multiplicative noise and improve the precision of parameter estimation for optimal data analysis. Specifically, we explore the impact of both multiplicative and thermal noise on the obfuscation of the actual signal and propose methods to resolve them. Firstly, we present an algorithm that can effectively separate thermal noise with comparable performance to Hamilton Monte Carlo (HMC) but with significantly improved speed. Subsequently, we analyze multiplicative noise and demonstrate that HMC is insufficient for isolating thermal and multiplicative noise. However, we show that, with additional knowledge of the ratio between thermal and multiplicative noise, we can accuratel
    
[^114]: 利用空间对比预训练进行未见训练数据的新道路交通预测

    Traffic Forecasting on New Roads Unseen in the Training Data Using Spatial Contrastive Pre-Training. (arXiv:2305.05237v1 [cs.LG])

    [http://arxiv.org/abs/2305.05237](http://arxiv.org/abs/2305.05237)

    本文提出一种名为SCPT的框架，利用对比学习进行空间预训练，并引入一个空间编码器模块，用于从未见数据中提取特征。该方法可以用于进行新道路的交通预测，无需重新训练模型。

    

    随着时间推移会不断建设新的道路，但是之前的深度预测模型对于新道路（未见数据）的泛化能力很少被探索。本文引入了一个被称为时空（ST）分割的新设置，以评估模型对未见数据的泛化能力。在这个设置中，模型训练时使用一部分的道路数据，但测试时使用未见数据的道路。我们还提出了一种新的框架，称之为空间对比预训练（SCPT），其中引入了一个空间编码器模块来提取推理时未见道路的潜在特征。这个空间编码器是使用对比学习预训练的。在推理时，空间编码器仅需要新道路的两天交通数据，而不需要任何重新训练。我们还展示了空间编码器的输出可以有效地用于推断未见道路上的潜在节点嵌入。

    New roads are being constructed all the time. However, the capabilities of previous deep forecasting models to generalize to new roads not seen in the training data (unseen roads) are rarely explored. In this paper, we introduce a novel setup called a spatio-temporal (ST) split to evaluate the models' capabilities to generalize to unseen roads. In this setup, the models are trained on data from a sample of roads, but tested on roads not seen in the training data. Moreover, we also present a novel framework called Spatial Contrastive Pre-Training (SCPT) where we introduce a spatial encoder module to extract latent features from unseen roads during inference time. This spatial encoder is pre-trained using contrastive learning. During inference, the spatial encoder only requires two days of traffic data on the new roads and does not require any re-training. We also show that the output from the spatial encoder can be used effectively to infer latent node embeddings on unseen roads during 
    
[^115]: 可解释的异质性幸存者偏差校正治疗效果研究，旨在指派出院后预防再住院的干预措施

    Interpretable (not just posthoc-explainable) heterogeneous survivor bias-corrected treatment effects for assignment of postdischarge interventions to prevent readmissions. (arXiv:2304.09981v1 [stat.ME])

    [http://arxiv.org/abs/2304.09981](http://arxiv.org/abs/2304.09981)

    该研究使用生存分析来评价出院后评估和管理（E/M）服务对防止再住院或死亡的影响，避免了机器学习中幸存者偏差的问题，并确定了个案管理服务在减少再住院方面最为有效，尤其对于出院后到长期护理机构的患者以及入院前有高资源利用率的患者。

    

    我们采用生存分析来量化出院后评估和管理服务在防止住院或死亡方面的影响。我们的方法避免了应用机器学习到这个问题上的一个特定陷阱，那就是因为幸存者偏差而导致的效果过高 -- 这种过高的估计可能与人群中的异质性混淆因素有关。这种偏差之所以产生，是因为为了在出院后接受干预，一个人必须在介入期内没有再次住院。在得出这种幻影效应的表达式后，我们在本质上可解释的贝叶斯生存框架中控制了这个和其他偏差。我们确定个案管理服务对于整体减少再住院具有最大的影响力，特别是对于出院后到长期护理机构的患者，在入院前一个季度有高资源利用率的患者。

    We used survival analysis to quantify the impact of postdischarge evaluation and management (E/M) services in preventing hospital readmission or death. Our approach avoids a specific pitfall of applying machine learning to this problem, which is an inflated estimate of the effect of interventions, due to survivors bias -- where the magnitude of inflation may be conditional on heterogeneous confounders in the population. This bias arises simply because in order to receive an intervention after discharge, a person must not have been readmitted in the intervening period. After deriving an expression for this phantom effect, we controlled for this and other biases within an inherently interpretable Bayesian survival framework. We identified case management services as being the most impactful for reducing readmissions overall, particularly for patients discharged to long term care facilities, with high resource utilization in the quarter preceding admission.
    
[^116]: 一种快速、轻量级的用于低光照图像增强的网络

    A Fast and Lightweight Network for Low-Light Image Enhancement. (arXiv:2304.02978v1 [cs.CV])

    [http://arxiv.org/abs/2304.02978](http://arxiv.org/abs/2304.02978)

    本文提出了一种称为FLW-Net的快速、轻量级网络，用于解决低光照图像中存在的噪声、低亮度、低对比度和色彩偏差问题。该方法具有高效的全局特征信息提取组件以及基于相对信息设计的损失函数，实验结果显示其有效性。

    

    低光照图像通常存在严重的噪声、低亮度、低对比度和色彩偏差问题。本文提出了一种名为FLW-Net的快速、轻量级网络来解决上述问题。我们设计了一个高效的全局特征信息提取组件，并基于相对信息设计了损失函数来解决绝对参考缺失和获得全局对比度方面的问题。实验结果证实了该方法的有效性。

    Low-light images often suffer from severe noise, low brightness, low contrast, and color deviation. While several low-light image enhancement methods have been proposed, there remains a lack of efficient methods that can simultaneously solve all of these problems. In this paper, we introduce FLW-Net, a Fast and LightWeight Network for low-light image enhancement that significantly improves processing speed and overall effect. To achieve efficient low-light image enhancement, we recognize the challenges of the lack of an absolute reference and the need for a large receptive field to obtain global contrast. Therefore, we propose an efficient global feature information extraction component and design loss functions based on relative information to overcome these challenges. Finally, we conduct comparative experiments to demonstrate the effectiveness of the proposed method, and the results confirm that FLW-Net can significantly reduce the complexity of supervised low-light image enhancemen
    
[^117]: SPeC：软提示校准在临床笔记摘要中降低性能变异的研究

    SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization. (arXiv:2303.13035v1 [cs.CL])

    [http://arxiv.org/abs/2303.13035](http://arxiv.org/abs/2303.13035)

    研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型.

    

    电子健康记录（EHR）存储着包括病历、诊断、治疗和检测结果在内的大量患者信息。这些记录对于医疗保健专业人员做出明智的患者护理决策非常关键。摘要临床笔记可以帮助医疗保健专业人员更好地发现潜在健康风险，以及做出更好的决策。这一过程通过确保医疗保健专业人员可以访问最相关和最新的患者数据，有助于减少错误并提高患者的护理效果。最近的研究表明，将提示与大语言模型（LLM）相结合可以显著提高摘要任务的效率。然而，我们发现这种方法也会导致输出方差增加，即使提示意义相似，输出也会有明显的差异。为了解决这一挑战，我们引入了一个模型无关的软提示校准（SPeC）流程，该流程采用软提示嵌入来减轻输入变量对输出多样性的影响。我们的实验表明，SPeC不仅可以降低LLM的性能变异，而且在临床笔记摘要任务上优于现有的最先进模型。

    Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better-informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased output variance, resulting in notably divergent outputs even when prompts share similar meanings. To tackle this challenge, we introduce a model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft prom
    
[^118]: 利用四维CT灌注成像对疑似急性缺血性卒中患者的梗死区进行分割

    Exploiting 4D CT Perfusion for segmenting infarcted areas in patients with suspected acute ischemic stroke. (arXiv:2303.08757v1 [eess.IV])

    [http://arxiv.org/abs/2303.08757](http://arxiv.org/abs/2303.08757)

    该研究提出了一种新颖的方法，通过利用四维CTP全面利用时空信息，以分割疑似急性缺血性卒中患者的梗死区。实验证明，该方法明显优于现有的最先进方法，有潜力为改善AIS患者的早期诊断和治疗规划的准确性和效率做出贡献。

    

    精确、快速的急性缺血性卒中（AIS）患者缺血区（核心和半影区）预测方法对于改进诊断和治疗规划具有重要的临床意义。计算机断层扫描（CT）是疑似AIS患者早期评估的主要模式之一。CT灌注成像（CTP）通常用作主要评估手段，以确定卒中位置、严重程度和缺血性病灶体积。目前，大多数CTP自动分割方法都使用已经处理过的三维彩色地图作为放射科医师常规视觉评估的输入。或者，基于切片的二维+时间输入使用原始CTP数据，其中忽略了在体积上的空间信息。在本文中，我们研究不同方法来利用整个四维CTP作为输入，以充分利用时空信息。这使我们提出了一种新颖的4D卷积层。我们在大型数据集上进行的全面实验表明，所提出的方法明显优于现有的最先进方法。该方法有潜力为改善AIS患者的早期诊断和治疗规划的准确性和效率做出贡献。

    Precise and fast prediction methods for ischemic areas (core and penumbra) in acute ischemic stroke (AIS) patients are of significant clinical interest: they play an essential role in improving diagnosis and treatment planning. Computed Tomography (CT) scan is one of the primary modalities for early assessment in patients with suspected AIS. CT Perfusion (CTP) is often used as a primary assessment to determine stroke location, severity, and volume of ischemic lesions. Current automatic segmentation methods for CTP mostly use already processed 3D color maps conventionally used for visual assessment by radiologists as input. Alternatively, the raw CTP data is used on a slice-by-slice basis as 2D+time input, where the spatial information over the volume is ignored. In this paper, we investigate different methods to utilize the entire 4D CTP as input to fully exploit the spatio-temporal information. This leads us to propose a novel 4D convolution layer. Our comprehensive experiments on a l
    
[^119]: 通过奖励塑形在基于情节的RL中利用多重抽象

    Exploiting Multiple Abstractions in Episodic RL via Reward Shaping. (arXiv:2303.00516v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00516](http://arxiv.org/abs/2303.00516)

    在这项工作中，我们通过引入一种新颖的奖励塑形形式，利用多层次的抽象来改善强化学习的效率，并且对抽象模型的设计要求较少，具有容忍性。

    

    强化学习（RL）在许多实际领域应用的一个主要限制是需要大量的样本来学习最优策略。为了解决这个问题并提高学习效率，我们考虑了基于目标领域的马尔可夫决策过程（MDP）的线性层次的抽象层次。每个层次都是一个表示比层次结构下方即刻模型更粗糙的模型的MDP。在这项工作中，我们提出了一种新颖的奖励塑形形式，其中在抽象层面获得的解决方案用于向更具体的MDP提供奖励，以使抽象解决方案指导更复杂领域中的学习。与层次RL中的其他工作相比，我们的技术在抽象模型的设计方面有很少的要求，并且也对建模错误具有容忍性，从而使所提出的方法变得实用。我们正式分析了抽象模型与引发探索启发式的关系

    One major limitation to the applicability of Reinforcement Learning (RL) to many practical domains is the large number of samples required to learn an optimal policy. To address this problem and improve learning efficiency, we consider a linear hierarchy of abstraction layers of the Markov Decision Process (MDP) underlying the target domain. Each layer is an MDP representing a coarser model of the one immediately below in the hierarchy. In this work, we propose a novel form of Reward Shaping where the solution obtained at the abstract level is used to offer rewards to the more concrete MDP, in such a way that the abstract solution guides the learning in the more complex domain. In contrast with other works in Hierarchical RL, our technique has few requirements in the design of the abstract models and it is also tolerant to modeling errors, thus making the proposed approach practical. We formally analyze the relationship between the abstract models and the exploration heuristic induced 
    
[^120]: 使用分位数回归森林的可解释上下文异常检测

    Explainable Contextual Anomaly Detection using Quantile Regression Forests. (arXiv:2302.11239v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11239](http://arxiv.org/abs/2302.11239)

    该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。

    

    传统的异常检测方法通过平等对待所有特征来识别偏离大多数其他对象的对象。相比之下，上下文异常检测方法通过将特征划分为上下文特征和行为特征，旨在检测偏离类似对象上下文的其他对象。在本文中，我们建立了依赖于传统的基于依赖的异常检测方法和上下文异常检测方法之间的联系。基于由此获得的见解，我们提出了一种新颖的方法，采用分位数回归森林来模拟特征之间的依赖关系，实现内在的可解释上下文异常检测。各种合成和真实世界数据集上的广泛实验表明，我们的方法在识别上下文异常方面的准确性和可解释性方面优于现有的状态-of-art异常检测方法。

    Traditional anomaly detection methods aim to identify objects that deviate from most other objects by treating all features equally. In contrast, contextual anomaly detection methods aim to detect objects that deviate from other objects within a context of similar objects by dividing the features into contextual features and behavioral features. In this paper, we develop connections between dependency-based traditional anomaly detection methods and contextual anomaly detection methods. Based on resulting insights, we propose a novel approach to inherently interpretable contextual anomaly detection that uses Quantile Regression Forests to model dependencies between features. Extensive experiments on various synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art anomaly detection methods in identifying contextual anomalies in terms of accuracy and interpretability.
    
[^121]: SE(3)对称性让图神经网络能够从小数据集中学习动脉血流速度估计

    SE(3) symmetry lets graph neural networks learn arterial velocity estimation from small datasets. (arXiv:2302.08780v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08780](http://arxiv.org/abs/2302.08780)

    用SE(3)等变的图神经网络模型可以从小数据集中学习动脉流速估计，速度快，减少了使用CFD模拟的需要

    

    冠状动脉中的血液速度场可能是诊断、预后和治疗规划心血管疾病的有价值生物标志物的基础。然而，血流动力学模拟需要专家的细致设置，耗时且难以在临床实践中被大规模接受。为了解决这个问题，我们提出了图神经网络(GNN)作为一种高效的黑盒子代理方法，用于估计动脉流体中顶点映射的3D速度场。我们使用合成动脉模型和基于CFD的地面真实速度场对这些GNN进行培训。一旦GNN训练完成，与CFD相比，可以36倍加速获得新的、未见过动脉的速度估计。我们展示了如何构建一个SE(3)等变的GNN，它独立于输入网格的空间方向，并展示了这如何减少必要的数据

    Hemodynamic velocity fields in coronary arteries could be the basis of valuable biomarkers for diagnosis, prognosis and treatment planning in cardiovascular disease. Velocity fields are typically obtained from patient-specific 3D artery models via computational fluid dynamics (CFD). However, CFD simulation requires meticulous setup by experts and is time-intensive, which hinders large-scale acceptance in clinical practice. To address this, we propose graph neural networks (GNN) as an efficient black-box surrogate method to estimate 3D velocity fields mapped to the vertices of tetrahedral meshes of the artery lumen. We train these GNNs on synthetic artery models and CFD-based ground truth velocity fields. Once the GNN is trained, velocity estimates in a new and unseen artery can be obtained with 36-fold speed-up compared to CFD. We demonstrate how to construct an SE(3)-equivariant GNN that is independent of the spatial orientation of the input mesh and show how this reduces the necessar
    
[^122]: GraphCast：学习娴熟的中程全球天气预报

    GraphCast: Learning skillful medium-range global weather forecasting. (arXiv:2212.12794v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12794](http://arxiv.org/abs/2212.12794)

    GraphCast是一种基于机器学习的方法，可以直接从再分析数据中训练，能在短时间内预测全球数百个天气变量，支持更好的严重事件预测，是准确和高效的天气预报的关键进展。

    

    全球中程天气预报对于很多社会和经济领域的决策至关重要。传统的数值天气预报利用增加的计算资源提高预报准确性，但无法直接利用历史天气数据改进底层模型。我们引入了一个名为"GraphCast"的基于机器学习的方法，它可以直接从再分析数据中进行训练。它在不到一分钟的时间内，预测全球0.25度分辨率下的数百个天气变量，持续10天。我们表明GraphCast在1380个验证目标的90％上明显优于最准确的操作确定性系统，并且其预报支持更好的严重事件预测，包括热带气旋、大气河流和极端温度。GraphCast是准确和高效的天气预报的关键进展，并有助于实现机器学习在建模复杂动力系统方面的优势。

    Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but cannot directly use historical weather data to improve the underlying model. We introduce a machine learning-based method called "GraphCast", which can be trained directly from reanalysis data. It predicts hundreds of weather variables, over 10 days at 0.25 degree resolution globally, in under one minute. We show that GraphCast significantly outperforms the most accurate operational deterministic systems on 90% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.
    
[^123]: GNN 和 MLP 相互联系揭示 GNN 在本质上是好的泛化器

    Graph Neural Networks are Inherently Good Generalizers: Insights by Bridging GNNs and MLPs. (arXiv:2212.09034v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.09034](http://arxiv.org/abs/2212.09034)

    本文通过将中间模型命名为 PMLP 并在测试时采用 GNNs 的架构，发现 GNNs 的表现出众不是其高级表现力的主要原因，而是其固有的泛化能力。

    

    图神经网络（GNNs）是图表示学习的事实上模型类别，它们建立在多层感知器（MLP）体系结构之上，并增加了额外的消息传递层以允许特征在节点之间流动。本文猜测 GNNs 的表现出众不是其高级表现力的主要原因，而是其固有的泛化能力。这项发现提供了一种新的方式来理解 GNNs 的学习行为，并可以用作更深层次的分析工具。

    Graph neural networks (GNNs), as the de-facto model class for representation learning on graphs, are built upon the multi-layer perceptrons (MLP) architecture with additional message passing layers to allow features to flow across nodes. While conventional wisdom commonly attributes the success of GNNs to their advanced expressivity, we conjecture that this is not the main cause of GNNs' superiority in node-level prediction tasks. This paper pinpoints the major source of GNNs' performance gain to their intrinsic generalization capability, by introducing an intermediate model class dubbed as P(ropagational)MLP, which is identical to standard MLP in training, but then adopts GNN's architecture in testing. Intriguingly, we observe that PMLPs consistently perform on par with (or even exceed) their GNN counterparts, while being much more efficient in training. This finding sheds new insights into understanding the learning behavior of GNNs, and can be used as an analytic tool for dissecting
    
[^124]: 可扩展的PAC-Bayesian元学习：从理论到实践的PAC-Optimal超后验

    Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice. (arXiv:2211.07206v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.07206](http://arxiv.org/abs/2211.07206)

    本研究使用PAC-Bayesian理论提供了元学习的泛化界限，并推导出了最佳性能保证的闭式优化超后验(PACOH)。通过理论分析和案例研究，我们展示了这些保证在元学习中相对于PAC-Bayesian每个任务学习界限的改进。

    

    元学习旨在通过从相关学习任务的数据集中获取有用的归纳偏好，加速对新任务的学习过程。然而，在实践中，可用的相关任务数量通常很小，大多数现有方法假设任务数量丰富，使它们不切实际且容易过拟合。元学习文献中的一个核心问题是如何进行正则化以确保对未见任务的泛化。在这项工作中，我们使用PAC-Bayesian理论提供了一种理论分析，并提出了元学习的泛化界限，这是由Rothfuss等人（2021）首次推导出来的。关键是，该界限使我们能够得到最佳性能保证的闭式优化超后验，称为PACOH。我们提供了一种理论分析和实证案例研究，在哪些条件下以及在多大程度上这些元学习的保证改进了PAC-Bayesian每个任务学习界限。

    Meta-Learning aims to speed up the learning process on new tasks by acquiring useful inductive biases from datasets of related learning tasks. While, in practice, the number of related tasks available is often small, most of the existing approaches assume an abundance of tasks; making them unrealistic and prone to overfitting. A central question in the meta-learning literature is how to regularize to ensure generalization to unseen tasks. In this work, we provide a theoretical analysis using the PAC-Bayesian theory and present a generalization bound for meta-learning, which was first derived by Rothfuss et al. (2021). Crucially, the bound allows us to derive the closed form of the optimal hyper-posterior, referred to as PACOH, which leads to the best performance guarantees. We provide a theoretical analysis and empirical case study under which conditions and to what extent these guarantees for meta-learning improve upon PAC-Bayesian per-task learning bounds. The closed-form PACOH inspi
    
[^125]: 基于物理启发式神经网络的Landau阻尼数据驱动建模

    Data-Driven Modeling of Landau Damping by Physics-Informed Neural Networks. (arXiv:2211.01021v2 [physics.plasm-ph] UPDATED)

    [http://arxiv.org/abs/2211.01021](http://arxiv.org/abs/2211.01021)

    本研究提出了一种基于物理启发式神经网络的数据驱动方法，成功构建了一个包含隐式流体闭合项的多矩便流体模型，能够重现Landau阻尼的动力学特征，并且引入了一个表征流体-细结构相互作用的新变量，该方法有效地将流体模型的应用范围扩展到多尺度系统，为研究等离子体动力学提供了强大工具。

    

    在微观等离子体物理问题中，动力学方法一般很准确，但对于大尺度或多尺度系统而言计算开销较大。等离子体物理学中长期存在的问题之一是如何将动力学物理学整合到流体模型中，通常通过复杂的解析闭合项实现。本研究成功构建了一个多矩便流体模型，其中神经网络包含隐式流体闭合项，采用机器学习的物理引导神经网络（PINN）和梯度增强的物理引导神经网络（gPINN）对少量稀疏采样的动力学仿真数据进行训练。使用PINN或gPINN构建的多矩便流体模型能够重现Landau阻尼的电场能量时变演化，包括其阻尼率，以及动力学仿真中的等离子体动力学。我们首次引入了一个新变量，即多矩便雷诺应力张量，该变量表征流体-细结构相互作用，是理解等离子体多尺度效应的关键。我们的方法提供了一种有效的数据驱动方法，将流体模型的有效性扩展到多尺度系统，为研究等离子体动力学提供了显著优势。

    Kinetic approaches are generally accurate in dealing with microscale plasma physics problems but are computationally expensive for large-scale or multiscale systems. One of the long-standing problems in plasma physics is the integration of kinetic physics into fluid models, which is often achieved through sophisticated analytical closure terms. In this study, we successfully construct a multi-moment fluid model with an implicit fluid closure included in the neural network using machine learning. The multi-moment fluid model is trained with a small fraction of sparsely sampled data from kinetic simulations of Landau damping, using the physics-informed neural network (PINN) and the gradient-enhanced physics-informed neural network (gPINN). The multi-moment fluid model constructed using either PINN or gPINN reproduces the time evolution of the electric field energy, including its damping rate, and the plasma dynamics from the kinetic simulations. For the first time, we introduce a new var
    
[^126]: Occam学习

    Occam learning. (arXiv:2210.13179v2 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2210.13179](http://arxiv.org/abs/2210.13179)

    本文讨论了一种具有固定隐藏层分布的概率神经网络模型，该模型选择简单、易解释，不需要过度参数化，同时训练有效。模型的隐藏单元为二元变量时具有以特征为基础的自然解释。作者认为隐藏变量的分布应该遵循最大关联度原则，并介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。

    

    我们讨论了一种无监督学习的概率神经网络模型，在这种模型中，隐藏层的分布是固定的。我们认为采用这种体系架构的机器学习具有许多令人满意的性质。例如，该模型可以选择为简单且易解释的模型，不需要过度参数化，而且在热力学意义下，训练更有效。当隐藏单元为二元变量时，这些模型具有以特征为基础的自然解释。我们表明，缺乏特征的状态对应于在特征方面最大程度的无知状态，并且，学习第一个特征取决于数据的非高斯统计属性。我们认为应该根据最大关联度原则选择隐藏变量的分布。我们介绍了分层特征模型（HFM）作为满足这一原则并对特征空间进行中性先验组织的模型。

    We discuss probabilistic neural network models for unsupervised learning where the distribution of the hidden layer is fixed. We argue that learning machines with this architecture enjoy a number of desirable properties. For example, the model can be chosen as a simple and interpretable one, it does not need to be over-parametrised and training is argued to be efficient in a thermodynamic sense. When hidden units are binary variables, these models have a natural interpretation in terms of features. We show that the featureless state corresponds to a state of maximal ignorance about the features and that learning the first feature depends on non-Gaussian statistical properties of the data. We suggest that the distribution of hidden variables should be chosen according to the principle of maximal relevance. We introduce the Hierarchical Feature Model (HFM) as an example of a model that satisfies this principle, and that encodes a neutral a priori organisation of the feature space. We pre
    
[^127]: 国际空间站自动紧急无尘解决方案: 带有Bi-GRU的(AED-ISS)

    Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.08549](http://arxiv.org/abs/2210.08549)

    该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。

    

    随着对PM2.5或PM0.3问题的关注不断增加，颗粒物不仅对环境和人类构成潜在威胁，而且对国际空间站上的仪器也会产生不利影响。本研究团队旨在将各种颗粒物浓度与磁场、湿度、加速度、温度、压力和CO2浓度关联起来。我们的目标是建立一个早期预警系统(EWS)，能够预测颗粒物水平，并为宇航员提供充足的反应时间，以保护他们在某些实验中的仪器，或者提高测量的准确性；此外，所构建的模型还可以进一步发展为与火灾相关的遥感烟雾报警装置的原型。本文中，我们将实现Bi-GRU(双向门控循环单元)算法，收集过去90分钟的数据，并预测超过2.5微米的颗粒物水平。

    With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
    
[^128]: 非零梯度的随机逼近的指数集中性分析

    Exponential Concentration of Stochastic Approximation with Non-vanishing Gradient. (arXiv:2208.07243v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.07243](http://arxiv.org/abs/2208.07243)

    本研究分析了非零梯度的随机逼近算法的行为，并证明了指数级的集中性界限，这对于投影随机梯度下降算法的收敛速度有重要意义。

    

    我们分析了随机逼近算法的行为，其中每一步迭代，期望中向目标取得进展。当进展与算法的步长成比例时，我们证明了指数级的集中性界限。这些尾部界限与更常见的随机逼近的渐近正态结果形成对比。我们开发的方法依赖于几何阻尼性证明。这扩展了Hajek（1982）对马尔可夫链的结果到随机逼近算法的领域。对于具有非零梯度的投影随机梯度下降算法，我们的结果可以用来证明$O(1/t)$和线性收敛速度。

    We analyze the behavior of stochastic approximation algorithms where iterates, in expectation, make progress towards an objective at each step. When progress is proportional to the step size of the algorithm, we prove exponential concentration bounds. These tail-bounds contrast asymptotic normality results which are more frequently associated with stochastic approximation. The methods that we develop rely on a geometric ergodicity proof. This extends a result on Markov chains due to Hajek (1982) to the area of stochastic approximation algorithms. For Projected Stochastic Gradient Descent with a non-vanishing gradient, our results can be used to prove $O(1/t)$ and linear convergence rates.
    
[^129]: ENCODE：用于网络异常检测的编码NetFlows

    ENCODE: Encoding NetFlows for Network Anomaly Detection. (arXiv:2207.03890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.03890](http://arxiv.org/abs/2207.03890)

    本文提出了一种编码算法，通过考虑特征值的频率和上下文，对NetFlow数据进行预处理，以提高网络异常检测的效果。

    

    NetFlow数据是许多网络分析师和研究人员使用的流行网络日志格式。与深度包检查相比，使用NetFlow的优势在于更易于收集和处理，对隐私性的侵入性更小。许多研究使用机器学习来使用NetFlow数据检测网络攻击。这些机器学习流水线的第一步是在将数据提供给机器学习算法之前对数据进行预处理。存在许多方法来预处理NetFlow数据；然而，这些方法只是简单地将现有方法应用于数据，而不考虑网络数据的特定属性。我们认为，对于源自软件系统（如NetFlow或软件日志）的数据，特征值的频率和上下文的相似性比值本身的相似性更重要。在这项工作中，我们提出了一种编码算法，在处理数据时直接考虑特征值的频率和上下文。

    NetFlow data is a popular network log format used by many network analysts and researchers. The advantages of using NetFlow over deep packet inspection are that it is easier to collect and process, and it is less privacy intrusive. Many works have used machine learning to detect network attacks using NetFlow data. The first step for these machine learning pipelines is to pre-process the data before it is given to the machine learning algorithm. Many approaches exist to pre-process NetFlow data; however, these simply apply existing methods to the data, not considering the specific properties of network data. We argue that for data originating from software systems, such as NetFlow or software logs, similarities in frequency and contexts of feature values are more important than similarities in the value itself. In this work, we propose an encoding algorithm that directly takes the frequency and the context of the feature values into account when the data is being processed. Different ty
    
[^130]: 推理为基础的量子感知

    Inference-Based Quantum Sensing. (arXiv:2206.09919v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2206.09919](http://arxiv.org/abs/2206.09919)

    这项工作提出了一种基于推理的量子感知方案，可以通过测量系统响应来推断未知参数的值，并确定方案的敏感性。

    

    在标准的量子感知任务中，通过对系统的测量，目标是估计一个未知的参数θ，将其编码到一个n比特的探针态中。这个任务的成功取决于将参数的变化与系统响应Ρ（θ）的变化（即测量结果的变化）相关联的能力。对于简单情况，Ρ（θ）的形式是已知的，但对于现实场景来说，一般不存在闭合形式的表达式。在这项工作中，我们提出了一种基于推理的量子感知方案。我们展示了对于一类常规的编码的酉族系列，只需在2n+1个参数处测量系统响应，就可以完全表征Ρ（θ）。这使得我们能够根据测量的响应推断未知参数的值，以及确定该方案的敏感性，从而表征其整体性能。我们证明了推理误差在高概率下小于...

    In a standard Quantum Sensing (QS) task one aims at estimating an unknown parameter $\theta$, encoded into an $n$-qubit probe state, via measurements of the system. The success of this task hinges on the ability to correlate changes in the parameter to changes in the system response $\mathcal{R}(\theta)$ (i.e., changes in the measurement outcomes). For simple cases the form of $\mathcal{R}(\theta)$ is known, but the same cannot be said for realistic scenarios, as no general closed-form expression exists. In this work we present an inference-based scheme for QS. We show that, for a general class of unitary families of encoding, $\mathcal{R}(\theta)$ can be fully characterized by only measuring the system response at $2n+1$ parameters. This allows us to infer the value of an unknown parameter given the measured response, as well as to determine the sensitivity of the scheme, which characterizes its overall performance. We show that inference error is, with high probability, smaller than 
    
[^131]: 通过遗憾分解改进了带有图反馈的赌博机算法

    Improved Algorithms for Bandit with Graph Feedback via Regret Decomposition. (arXiv:2205.15076v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15076](http://arxiv.org/abs/2205.15076)

    通过遗憾分解，我们提出了一种基于反馈图划分的新算法框架，该框架统一了多臂赌博机和学习与专家建议的最优算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。

    

    带有图反馈的赌博机问题通过在有向图中编码损失向量在每轮游戏中的观测方式，将多臂赌博机问题和学习与专家建议问题进行了推广。最小最大遗憾与反馈图的结构密切相关，但二者的关系尚未完全理解。我们提出了一种基于反馈图划分的新算法框架。通过将遗憾分解为由小部分和它们之间相互作用引起的遗憾之和，我们的分析揭示了图的各个部分之间的相互作用。因此，我们的算法可以被看作是多臂赌博机和学习与专家建议的最优算法的插值和推广。我们的框架统一了先前针对强观测图和弱观测图的算法，对包括许多图类族在内的范围更广的图家族得到了改进和最优遗憾界限。

    The problem of bandit with graph feedback generalizes both the multi-armed bandit (MAB) problem and the learning with expert advice problem by encoding in a directed graph how the loss vector can be observed in each round of the game. The mini-max regret is closely related to the structure of the feedback graph and their connection is far from being fully understood. We propose a new algorithmic framework for the problem based on a partition of the feedback graph. Our analysis reveals the interplay between various parts of the graph by decomposing the regret to the sum of the regret caused by small parts and the regret caused by their interaction. As a result, our algorithm can be viewed as an interpolation and generalization of the optimal algorithms for MAB and learning with expert advice. Our framework unifies previous algorithms for both strongly observable graphs and weakly observable graphs, resulting in improved and optimal regret bounds on a wide range of graph families includi
    
[^132]: 通过基于草图的顺序二次规划对约束的随机优化进行统计推断

    Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming. (arXiv:2205.13687v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2205.13687](http://arxiv.org/abs/2205.13687)

    本篇论文提出了一种用于等式约束的随机非线性优化问题的统计推断方法，通过基于草图的顺序二次规划（StoSQP）进行求解，并且允许自适应选择随机步长和使用高效随机迭代求解器来降低计算成本。

    

    我们考虑对等式约束的随机非线性优化问题进行统计推断。我们开发了一种全在线随机顺序二次规划（StoSQP）方法来解决这些问题，可以将其视为将牛顿法应用于一阶最优性条件（即KKT条件）。受最近数值二阶方法设计的启发，我们允许StoSQP自适应地选择任意随机步长$ \bar {\ alpha} _t $，只要$ \ beta _t \ leq \ bar {\ alpha} _t \ leq \ beta _t + \ chi _t $，其中 $ \ beta_t $ 和 $ \ chi_t = o(\beta_t) $ 是某些控制序列。为了降低二阶方法的主要计算成本，我们还允许StoSQP通过使用草图技术的高效随机迭代求解器来不精确地解决二次规划问题。值得注意的是，我们不要求逼近误差随着迭代的进行而减小。对于开发的方法，我们证明在温和的假设（i）下，它的计算复杂度最多为$ O(1 / \ ep）$。

    We consider statistical inference of equality-constrained stochastic nonlinear optimization problems. We develop a fully online stochastic sequential quadratic programming (StoSQP) method to solve the problems, which can be regarded as applying Newton's method to the first-order optimality conditions (i.e., the KKT conditions). Motivated by recent designs of numerical second-order methods, we allow StoSQP to adaptively select any random stepsize $\bar{\alpha}_t$, as long as $\beta_t\leq \bar{\alpha}_t \leq \beta_t+\chi_t$, for some control sequences $\beta_t$ and $\chi_t=o(\beta_t)$. To reduce the dominant computational cost of second-order methods, we additionally allow StoSQP to inexactly solve quadratic programs via efficient randomized iterative solvers that utilize sketching techniques. Notably, we do not require the approximation error to diminish as iteration proceeds. For the developed method, we show that under mild assumptions (i) computationally, it can take at most $O(1/\ep
    
[^133]: 在内存限制下用于数据流分类的Mondrian Forest论文

    Mondrian Forest for Data Stream Classification Under Memory Constraints. (arXiv:2205.07871v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07871](http://arxiv.org/abs/2205.07871)

    本文将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下，并设计了内存不足策略和修剪机制。研究表明，在所有配置中，Extend Node策略是最佳的内存不足策略。

    

    监督学习算法通常假设在训练和测试阶段有足够的内存来存储数据模型。然而，在物联网中，当数据以无限数据流的形式出现时，或者当学习算法部署在具有较少内存的设备上时，这个假设是不现实的。在本文中，我们将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下。具体而言，我们设计了五种内存不足策略，以在达到内存限制时更新Mondrian树的新数据点。此外，我们设计了修剪机制，在内存限制下使Mondrian树对概念漂移更加稳健。我们在各种真实和模拟数据集上评估了我们的算法，并最后给出了在不同情况下使用它们的建议：在所有配置中，Extend Node策略似乎是最佳的内存不足策略，而修剪机制则因具体情况而异。

    Supervised learning algorithms generally assume the availability of enough memory to store their data model during the training and test phases. However, in the Internet of Things, this assumption is unrealistic when data comes in the form of infinite data streams, or when learning algorithms are deployed on devices with reduced amounts of memory. In this paper, we adapt the online Mondrian forest classification algorithm to work with memory constraints on data streams. In particular, we design five out-of-memory strategies to update Mondrian trees with new data points when the memory limit is reached. Moreover, we design trimming mechanisms to make Mondrian trees more robust to concept drifts under memory constraints. We evaluate our algorithms on a variety of real and simulated datasets, and we conclude with recommendations on their use in different situations: the Extend Node strategy appears as the best out-of-memory strategy in all configurations, whereas different trimming mechan
    
[^134]: 减轻常见数据集中物体偏差的方法

    Mitigating the Bias of Centered Objects in Common Datasets. (arXiv:2112.09195v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.09195](http://arxiv.org/abs/2112.09195)

    本文讨论了卷积网络对物体位置的响应变化以及常见数据集中物体偏差问题。研究发现，训练过程中图像中心的物体过度表示导致网络性能受限，特别是当物体靠近边界时。同时，作者提出了使用数据增强技术来减轻这种影响的方法。

    

    卷积网络被认为具有平移不变性，但是已经证明它们的响应可能根据物体的确切位置而变化。在本文中，我们将证明大多数常见的研究数据集存在一种偏差，即训练过程中图像中心的物体被过度表示。这种偏差和网络的边界条件对这些架构的性能有显著影响，当物体靠近边界时，它们的准确性会明显下降。我们还将展示如何通过数据增强技术来减轻这种影响。

    Convolutional networks are considered shift invariant, but it was demonstrated that their response may vary according to the exact location of the objects. In this paper we will demonstrate that most commonly investigated datasets have a bias, where objects are over-represented at the center of the image during training. This bias and the boundary condition of these networks can have a significant effect on the performance of these architectures and their accuracy drops significantly as an object approaches the boundary. We will also demonstrate how this effect can be mitigated with data augmentation techniques.
    
[^135]: 稀疏主成分分析的新基础

    A New Basis for Sparse Principal Component Analysis. (arXiv:2007.00596v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2007.00596](http://arxiv.org/abs/2007.00596)

    我们提出了一种新的方法来进行稀疏主成分分析，该方法使用正交旋转来获得近似稀疏的特征值基。与以往方法不同的是，我们的方法使稀疏成分不需要是主特征向量，而可以是它们的混合。这一方法不需要进行“缩减”操作或使用多个调参参数。

    

    之前的稀疏主成分分析方法假设特征值基（一个大小为$p \times k$的矩阵）近似稀疏。我们提出了一种方法，假设在进行$k \times k$旋转后，特征值基的稀疏性变得近似。算法的简单版本是以前$k$个主成分为初始值，然后使用$k \times k$正交旋转使主成分近似稀疏，最后对旋转后的主成分进行软阈值处理。该方法与以往方法不同之处在于使用正交旋转来近似稀疏基。一个结果是，稀疏成分不需要是主特征向量，而可以是它们的混合。因此，我们提出了一种新的（旋转后的）稀疏主成分分析基。此外，我们的方法避免了“缩减”和多个调参参数的需求。我们的稀疏主成分分析框架非常灵活，并且可以推广至...

    Previous versions of sparse principal component analysis (PCA) have presumed that the eigen-basis (a $p \times k$ matrix) is approximately sparse. We propose a method that presumes the $p \times k$ matrix becomes approximately sparse after a $k \times k$ rotation. The simplest version of the algorithm initializes with the leading $k$ principal components. Then, the principal components are rotated with an $k \times k$ orthogonal rotation to make them approximately sparse. Finally, soft-thresholding is applied to the rotated principal components. This approach differs from prior approaches because it uses an orthogonal rotation to approximate a sparse basis. One consequence is that a sparse component need not to be a leading eigenvector, but rather a mixture of them. In this way, we propose a new (rotated) basis for sparse PCA. In addition, our approach avoids "deflation" and multiple tuning parameters required for that. Our sparse PCA framework is versatile; for example, it extends nat
    
[^136]: 使用特权汇集的细粒度物种识别：通过监督关注提高样本效率。

    Fine-grained Species Recognition with Privileged Pooling: Better Sample Efficiency Through Supervised Attention. (arXiv:2003.09168v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2003.09168](http://arxiv.org/abs/2003.09168)

    该论文提出了一种使用关键点注释来监督学习模型的方案，通过特权汇集和视觉注意机制，实现了对具有长尾物种分布和数据集偏差的动物物种进行细粒度识别，提高了小样本训练的效率和泛化能力。

    

    我们提出了一种监督图像分类方案，利用特权信息，以训练数据的关键点注释的形式，从小量和/或偏见的训练集中学习强大的模型。我们的主要动机是用于生态应用（如生物多样性建模）的动物物种识别，这是具有挑战性的，因为由于稀有物种和相机陷阱中重复的场景背景等原因，存在长尾物种分布和强烈的数据集偏差。为了应对这些挑战，我们提出了一种视觉注意机制，通过关键点注释进行监督，突出重要的物体部分。这种特权信息作为一种新颖的特权汇集操作，在训练过程中仅需要，并有助于模型专注于具有区分度的区域。在三个不同的动物物种数据集上的实验中，我们展示了带有特权汇集的深度网络可以更高效地使用小的训练集，并且具有更好的泛化性能。

    We propose a scheme for supervised image classification that uses privileged information, in the form of keypoint annotations for the training data, to learn strong models from small and/or biased training sets. Our main motivation is the recognition of animal species for ecological applications such as biodiversity modelling, which is challenging because of long-tailed species distributions due to rare species, and strong dataset biases such as repetitive scene background in camera traps. To counteract these challenges, we propose a visual attention mechanism that is supervised via keypoint annotations that highlight important object parts. This privileged information, implemented as a novel privileged pooling operation, is only required during training and helps the model to focus on regions that are discriminative. In experiments with three different animal species datasets, we show that deep networks with privileged pooling can use small training sets more efficiently and generaliz
    

