# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks.](http://arxiv.org/abs/2311.00983) | 本文提出了一种基于决策导向学习的方法来解决库存配送问题，通过直接集成库存预测和路径优化，可能确保一个强大的供应链策略。 |
| [^2] | [Conditional Density Estimations from Privacy-Protected Data.](http://arxiv.org/abs/2310.12781) | 本文提出了一种从隐私保护数据中进行条件密度估计的方法，使用神经条件密度估计器来近似模型参数的后验分布，从而解决了在统计分析过程中只能访问私有化数据导致的计算复杂度增加的问题。 |
| [^3] | [Provable Probabilistic Imaging using Score-Based Generative Priors.](http://arxiv.org/abs/2310.10835) | 本文提出了一种基于得分的生成先验的插入式蒙特卡洛算法，能够实现高质量图像重建和不确定性量化。 |
| [^4] | [COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL.](http://arxiv.org/abs/2310.07220) | COPlanner是一个基于规划的框架，用于解决模型预测误差带来的问题。通过保守的模型演算和乐观的环境探索，COPlanner利用不确定性感知模型预测控制来解决动力学模型不准确的问题，并提供更好的解决方案。 |
| [^5] | [Density Estimation via Measure Transport: Outlook for Applications in the Biological Sciences.](http://arxiv.org/abs/2309.15366) | 通过测度传递方法进行密度估计在生物科学中具有广阔的应用前景，尤其是在处理稀疏数据的情况下，使用稀疏传递映射可以揭示数据中隐藏的信息。 |
| [^6] | [Dictionary Attack on IMU-based Gait Authentication.](http://arxiv.org/abs/2309.11766) | 这项研究提出了一种对使用惯性测量单元记录的步态模式进行认证的敌对模型。研究调查了是否可能构建一本IMUGait模式的字典，用于发动攻击或找到能够匹配目标IMUGait模式的模仿者。通过对错误率的进一步分析，挑战了基于IMUGait模式的认证系统是否最困难的观点。 |
| [^7] | [Early warning via transitions in latent stochastic dynamical systems.](http://arxiv.org/abs/2309.03842) | 本研究提出了一种基于定向异性扩散图的方法，通过捕捉低维流形中的潜在演化动态，能够有效提取早期警报信号来检测复杂系统或高维观测数据中的动力学转变，并在真实的脑电图数据上得到了验证。 |
| [^8] | [Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments.](http://arxiv.org/abs/2309.03537) | 本研究提出了一种基于子图的紧框架构造方法，能够灵活地调整框架的消失矩和其他属性，实现对具有路径支持的图信号的高效表示，在非线性逼近任务中表现出优越性能。 |
| [^9] | [Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations.](http://arxiv.org/abs/2309.02332) | 神经群体在中枢神经系统中使用数学结构精确地表示和操作信息，实现了特化、泛化、新奇检测等多种功能。 |
| [^10] | [Federated Two Stage Decoupling With Adaptive Personalization Layers.](http://arxiv.org/abs/2308.15821) | 该论文提出了一种具有自适应个性化层的联邦化两阶段解耦方法，通过将同质客户端聚类到同一组的方式来提高联邦学习的性能，并解决了数据异质性和聚类时间选择的问题。 |
| [^11] | [ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy.](http://arxiv.org/abs/2308.12210) | ULDP-FL是一种新颖的联邦学习框架，设计用于跨边界的联邦学习中确保用户级差分隐私。算法通过每个用户的加权剪裁直接确保用户级差分隐私，并通过密码学构件增强了其效用。实证实验表明，该方法在隐私和效用的权衡方面取得了显著改进。 |
| [^12] | [Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation.](http://arxiv.org/abs/2308.07931) | 本论文通过精简特征场，将精确的3D几何与2D基础模型的丰富语义相结合，实现了对未见过的物体的少样本操作的泛化能力。 |
| [^13] | [Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion.](http://arxiv.org/abs/2308.06382) | 本论文提出了一种名为“音素幻觉器”的一次性语音转换模型，通过集合扩展的方法，只需短时间目标说话人语音即可生成多样和高保真度的目标说话人音素，并用于基于邻居的语音转换。 |
| [^14] | [Asynchronous Evolution of Deep Neural Network Architectures.](http://arxiv.org/abs/2308.04102) | 本文提出了一种通用的异步评估策略，用于增加进化神经网络架构搜索的吞吐量。该策略维护一个个体队列，并在适当数量的个体被评估后立即进入下一代，平衡多样性和效率。 |
| [^15] | [Do algorithms and barriers for sparse principal component analysis extend to other structured settings?.](http://arxiv.org/abs/2307.13535) | 该论文研究了在尖峰Wishart模型下，通过一类子空间并集模型捕捉信号结构的主成分分析问题。通过统计和计算的视角，我们建立了基本限制，并展示了自然的投影功率方法在解决方案的统计近似最优邻域中的局部收敛性。我们还通过具体案例的分析展示了计算难度。结果表明，对于基本稀疏PCA观察到的现象在其结构化对应物中也同样存在。 |
| [^16] | [Active Control of Flow over Rotating Cylinder by Multiple Jets using Deep Reinforcement Learning.](http://arxiv.org/abs/2307.12083) | 本研究使用深度强化学习算法结合旋转和多个可控喷口，通过优化喷口数量和位置，传感器位置以及每个动作可允许的最大流量和每个episode中允许的总喷口数的形式，实现对旋转圆柱体流动的主动控制，抑制涡流脱落和稳定卡门涡流。 |
| [^17] | [When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions.](http://arxiv.org/abs/2306.15546) | 基础模型与联邦学习的交叉提供了解锁新可能性的独特机会，扩展了数据可用性，促进了协作式模型发展，并提高了性能和隐私保护。 |
| [^18] | [Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits.](http://arxiv.org/abs/2306.14872) | 本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。 |
| [^19] | [Valid inference after prediction.](http://arxiv.org/abs/2306.13746) | 最近的研究聚焦于基于预测的推断，并提出了修正步骤以实现对未观测到响应和协变量之间关系的有效推断，Angelopoulos等人（2023）的方法成功控制了第一类错误率，并提供了正确命名覆盖的置信区间，但在某些情况下，其存在低功率问题。 |
| [^20] | [Can Large Language Models Infer Causation from Correlation?.](http://arxiv.org/abs/2306.05836) | 本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。 |
| [^21] | [Addressing Negative Transfer in Diffusion Models.](http://arxiv.org/abs/2306.00354) | 本文从多任务学习角度出发，研究了扩散训练中的负迁移现象，提出了利用正则化技术增强扩散训练的方法，以减轻负迁移并提高去噪任务的性能。 |
| [^22] | [Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II.](http://arxiv.org/abs/2305.17282) | 本文研究了k近邻学习规则中的普遍一致性，发现在可分度量空间中，该规则在Nagata维度下的sigma有限维度的空间中是普遍一致的，在非阿基米德度量空间中是强普遍一致的，此规则在具有de Groot有限维度意义下的度量空间和Heisenberg群中也是普遍一致的。 |
| [^23] | [Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer.](http://arxiv.org/abs/2305.09126) | 本文提出了一个名为$\ell_1$-TCL的通用框架，它使用知识迁移和Lasso回归来提高因果效应估计精度。 |
| [^24] | [Deep Stock: training and trading scheme using deep learning.](http://arxiv.org/abs/2304.14870) | 本文提出了一种使用深度学习进行训练和交易的方案，DeepStock通过查看股票价格的过去数据，并使用Resnet和logits来预测股票价格在未来D天内是否会升降一定百分比，并在韩国和美国市场上取得了超过市场回报的利润。 |
| [^25] | [Hopfield model with planted patterns: a teacher-student self-supervised learning model.](http://arxiv.org/abs/2304.13710) | 该论文提出了一种基于师生自我监督学习问题的Hopfield模型，能够帮助机器利用结构化的模式来学习，虽然一些条件对于学习非常重要，但这种学习模式在特定条件下可以实现泛化。 |
| [^26] | [Energy-Based Sliced Wasserstein Distance.](http://arxiv.org/abs/2304.13586) | 本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。 |
| [^27] | [UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite.](http://arxiv.org/abs/2304.08842) | 该论文介绍了一个开源的道路坑洞检测基准套件UDTIRI，包含了标记齐全的1000张道路坑洞图像，可以用于深度学习方法在城市道路检查中的目标检测、语义分割和实例分割任务。 |
| [^28] | [Robust Decision-Focused Learning for Reward Transfer.](http://arxiv.org/abs/2304.03365) | 本文介绍了一种稳健决策重点（RDF）算法，利用非识别性的DF解，学习同时最大化期望回报和抵御奖励函数变化的模型，可以显著提高DF对奖励函数变化的稳健性，而不会降低智能体的总回报。 |
| [^29] | [An EMO Joint Pruning with Multiple Sub-networks: Fast and Effect.](http://arxiv.org/abs/2303.16212) | 本文提出了一种基于多子网络的EMO联合剪枝算法，该算法可以减少空间和资源消耗。该算法采用分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。基于跨网络约束的子网络训练方法可以进一步提高性能。 |
| [^30] | [Completeness of Atomic Structure Representations.](http://arxiv.org/abs/2302.14770) | 本文解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，并提出了一种构造有限子集描述符的新方法。 |
| [^31] | [Machine Learning for Synthetic Data Generation: A Review.](http://arxiv.org/abs/2302.04062) | 机器学习用于合成数据生成的综述，探讨了合成数据生成的应用（计算机视觉、语音、自然语言、医疗保健和商业）、机器学习方法（神经网络架构和深度生成模型）以及隐私和公平问题，并提出了未来的研究方向。 |
| [^32] | [Relativistic Digital Twin: Bringing the IoT to the Future.](http://arxiv.org/abs/2301.07390) | 本文提出了相对论数字孪生（RDT）框架，通过不断观察物联网实体的真实对应物来自动生成通用型数字孪生，并调整其行为模型。框架利用物联网之物（WoT）提供标准化接口。 |
| [^33] | [Markovian Sliced Wasserstein Distances: Beyond Independent Projections.](http://arxiv.org/abs/2301.03749) | 马尔可夫切片Wasserstein（MSW）距离是一种新的SW距离家族，通过在投影方向上施加一阶马尔可夫结构，解决了切片Wasserstein（SW）距离中独立投影导致的冗余投影的问题，并且具有较低的计算复杂度。（found in translation） |
| [^34] | [Differentially Private Diffusion Models.](http://arxiv.org/abs/2210.09929) | 本研究提出了一种差分隐私扩散模型(DPDMs)，通过差分隐私训练生成模型，实现对隐私的保护，在图像生成基准测试中表现优越，能够在标准测试中与特定任务的DP-SGD训练的分类器相媲美。 |
| [^35] | [Lossy Image Compression with Conditional Diffusion Models.](http://arxiv.org/abs/2209.06950) | 本文提出了一种利用条件扩散模型进行有损图像压缩的优化框架。通过引入额外的内容潜变量以及合成纹理变量，该方法在图像质量评估指标上表现出更强的性能。 |
| [^36] | [Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning.](http://arxiv.org/abs/2208.09894) | 本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。 |
| [^37] | [Ensemble forecasts in reproducing kernel Hilbert space family: dynamical systems in Wonderland.](http://arxiv.org/abs/2207.14653) | 本文提出了一种在动力系统中的集合预测和模拟的方法，将系统嵌入再生核希尔伯特空间族，并在该空间中使用简单的集合数据同化方法进行轨迹重构。 |
| [^38] | [Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems.](http://arxiv.org/abs/2205.04151) | 本文提出了一种名为Auto-SDE的算法来学习慢-快随机动力学系统的有效降维动力学，通过自动编码器神经网络和离散化的随机微分方程，捕捉了系统的演化特性，并在数值实验证明了其准确性、稳定性和有效性。 |

# 详细

[^1]: 优化库存配送：一种基于神经网络的决策导向学习方法

    Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])

    [http://arxiv.org/abs/2311.00983](http://arxiv.org/abs/2311.00983)

    本文提出了一种基于决策导向学习的方法来解决库存配送问题，通过直接集成库存预测和路径优化，可能确保一个强大的供应链策略。

    

    库存配送问题（IRP）是供应链管理中的一个关键挑战，它涉及在考虑库存需求规划的不确定性的情况下优化有效的路径选择。为了解决IRP问题，通常采用两阶段的方法，首先使用机器学习技术预测需求，然后使用优化算法来最小化配送成本。我们的实验表明，机器学习模型在实现完美准确度方面存在不足，因为库存水平受动态业务环境的影响，进而影响到下一阶段的优化问题，导致次优决策。在本文中，我们提出了一种基于决策导向学习的方法来解决现实世界的IRP问题。这种方法在一个端到端的系统中直接集成了库存预测和路径优化，可能确保一个强大的供应链策略。

    Inventory Routing Problem (IRP) is a crucial challenge in supply chain management as it involves optimizing efficient route selection while considering the uncertainty of inventory demand planning. To solve IRPs, usually a two-stage approach is employed, where demand is predicted using machine learning techniques first, and then an optimization algorithm is used to minimize routing costs. Our experiment shows machine learning models fall short of achieving perfect accuracy because inventory levels are influenced by the dynamic business environment, which, in turn, affects the optimization problem in the next stage, resulting in sub-optimal decisions. In this paper, we formulate and propose a decision-focused learning-based approach to solving real-world IRPs. This approach directly integrates inventory prediction and routing optimization within an end-to-end system potentially ensuring a robust supply chain strategy.
    
[^2]: 从隐私保护数据中进行条件密度估计

    Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])

    [http://arxiv.org/abs/2310.12781](http://arxiv.org/abs/2310.12781)

    本文提出了一种从隐私保护数据中进行条件密度估计的方法，使用神经条件密度估计器来近似模型参数的后验分布，从而解决了在统计分析过程中只能访问私有化数据导致的计算复杂度增加的问题。

    

    许多现代统计分析和机器学习应用需要在敏感用户数据上进行模型训练。差分隐私提供了一种正式的保证，即个体用户信息不会泄露。在这个框架下，随机算法向保密数据注入校准的噪声，从而产生隐私保护的数据集或查询。然而，在统计分析过程中只能访问私有化数据会导致计算复杂度增加，难以对基础机密数据的参数进行有效的推理。在本工作中，我们提出了基于隐私保护数据集的基于模拟的推理方法。具体而言，我们使用神经条件密度估计器作为一组灵活的分布来近似给定观测到的私有查询结果的模型参数的后验分布。我们在传染病模型下的离散时间序列数据以及普通线性回归模型上说明了我们的方法。

    Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
    
[^3]: 用基于得分的生成先验的可证明的概率成像

    Provable Probabilistic Imaging using Score-Based Generative Priors. (arXiv:2310.10835v1 [eess.IV])

    [http://arxiv.org/abs/2310.10835](http://arxiv.org/abs/2310.10835)

    本文提出了一种基于得分的生成先验的插入式蒙特卡洛算法，能够实现高质量图像重建和不确定性量化。

    

    在解决反问题时，估计高质量图像并量化其不确定性是图像重建算法中的两个理想特点。本文提出了插入式蒙特卡洛（PMC）作为一种对一般反问题可能解空间进行建模的原则性框架。PMC能够通过后验采样来结合丰富的基于得分的生成先验进行高质量图像重建，并进行不确定性量化。具体而言，我们引入了两种PMC算法，可以视为传统插入式先验（PnP）和去噪正则化（RED）算法的采样模拟。我们还建立了对PMC算法收敛性的理论分析。我们的分析为两种算法提供了非渐近稳定性保证，即使在非对数凹似然和不完美得分网络的情况下也是如此。

    Estimating high-quality images while also quantifying their uncertainty are two desired features in an image reconstruction algorithm for solving ill-posed inverse problems. In this paper, we propose plug-and-play Monte Carlo (PMC) as a principled framework for characterizing the space of possible solutions to a general inverse problem. PMC is able to incorporate expressive score-based generative priors for high-quality image reconstruction while also performing uncertainty quantification via posterior sampling. In particular, we introduce two PMC algorithms which can be viewed as the sampling analogues of the traditional plug-and-play priors (PnP) and regularization by denoising (RED) algorithms. We also establish a theoretical analysis for characterizing the convergence of the PMC algorithms. Our analysis provides non-asymptotic stationarity guarantees for both algorithms, even in the presence of non-log-concave likelihoods and imperfect score networks. We demonstrate the performance
    
[^4]: COPlanner: 保守的模型规划和乐观的环境探索为基于模型的强化学习提供支持

    COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL. (arXiv:2310.07220v1 [cs.LG])

    [http://arxiv.org/abs/2310.07220](http://arxiv.org/abs/2310.07220)

    COPlanner是一个基于规划的框架，用于解决模型预测误差带来的问题。通过保守的模型演算和乐观的环境探索，COPlanner利用不确定性感知模型预测控制来解决动力学模型不准确的问题，并提供更好的解决方案。

    

    Dyna-style基于模型的强化学习包含两个阶段：使用模型生成样本进行策略学习的模型演算阶段和使用当前策略进行真实环境探索以学习动力学模型的阶段。然而，由于复杂的现实环境，难免会学习到一个具有模型预测误差的不完美动力学模型，进而可能误导策略学习并导致次优解。本文提出了一种名为COPlanner的基于规划的框架，用于解决不准确学习的动力学模型问题，其采用保守的模型演算和乐观的环境探索。COPlanner利用一种基于策略引导的不确定性感知模型预测控制（UP-MPC）组件进行多步不确定性评估的规划。这个估计的不确定性在模型演算期间作为惩罚因素，在真实环境探索期间作为奖励因素，以选择动作。因此，COPlanner可以同时保证保守的模型演算和乐观的环境探索，提供更好的解决方案。

    Dyna-style model-based reinforcement learning contains two phases: model rollouts to generate sample for policy learning and real environment exploration using current policy for dynamics model learning. However, due to the complex real-world environment, it is inevitable to learn an imperfect dynamics model with model prediction error, which can further mislead policy learning and result in sub-optimal solutions. In this paper, we propose $\texttt{COPlanner}$, a planning-driven framework for model-based methods to address the inaccurately learned dynamics model problem with conservative model rollouts and optimistic environment exploration. $\texttt{COPlanner}$ leverages an uncertainty-aware policy-guided model predictive control (UP-MPC) component to plan for multi-step uncertainty estimation. This estimated uncertainty then serves as a penalty during model rollouts and as a bonus during real environment exploration respectively, to choose actions. Consequently, $\texttt{COPlanner}$ 
    
[^5]: 通过测度传递进行密度估计：生物科学中的应用展望

    Density Estimation via Measure Transport: Outlook for Applications in the Biological Sciences. (arXiv:2309.15366v1 [q-bio.QM])

    [http://arxiv.org/abs/2309.15366](http://arxiv.org/abs/2309.15366)

    通过测度传递方法进行密度估计在生物科学中具有广阔的应用前景，尤其是在处理稀疏数据的情况下，使用稀疏传递映射可以揭示数据中隐藏的信息。

    

    测度传递方法的一个优势是其允许对根据广泛概率测度分布的数据进行统一的处理和分析。在这个框架下，我们通过计算研究的结果来评估测度传递技术的潜力，特别是三角传递映射的使用，作为支持生物科学研究的工作流的一部分。稀疏数据场景在辐射生物学等领域很常见。我们发现，在数据稀缺时，稀疏传递映射是有优势的。具体而言，通过计算一系列（稀疏的）自适应传递映射的统计信息，这些映射是在随机选择的一系列可用数据样本子集上进行训练的，可以揭示数据中隐藏的信息。因此，在本文考虑的辐射生物学应用中，此方法为生成假设提供了一个工具。

    One among several advantages of measure transport methods is that they allow for a unified framework for processing and analysis of data distributed according to a wide class of probability measures. Within this context, we present results from computational studies aimed at assessing the potential of measure transport techniques, specifically, the use of triangular transport maps, as part of a workflow intended to support research in the biological sciences. Scarce data scenarios, which are common in domains such as radiation biology, are of particular interest. We find that when data is scarce, sparse transport maps are advantageous. In particular, statistics gathered from computing series of (sparse) adaptive transport maps, trained on a series of randomly chosen subsets of the set of available data samples, leads to uncovering information hidden in the data. As a result, in the radiation biology application considered here, this approach provides a tool for generating hypotheses ab
    
[^6]: 基于惯性测量单元(IMU)的步态认证的字典攻击

    Dictionary Attack on IMU-based Gait Authentication. (arXiv:2309.11766v1 [cs.CR])

    [http://arxiv.org/abs/2309.11766](http://arxiv.org/abs/2309.11766)

    这项研究提出了一种对使用惯性测量单元记录的步态模式进行认证的敌对模型。研究调查了是否可能构建一本IMUGait模式的字典，用于发动攻击或找到能够匹配目标IMUGait模式的模仿者。通过对错误率的进一步分析，挑战了基于IMUGait模式的认证系统是否最困难的观点。

    

    我们提出了一种新的对使用智能手机内置的惯性测量单元(IMU)记录的步态模式进行认证的敌对模型。攻击思路受到字典攻击知识(PIN或密码)基础认证系统的概念启发，并以此命名。具体而言，本研究调查是否可能构建一本IMUGait模式的字典，然后使用它发动攻击，或找到一个能够主动复制与目标IMUGait模式匹配的模仿者。九个身体和人口统计学多样化的个体以不同水平的四个预定义可控和可调节的步态因素(速度、步长、步宽和大腿抬起)行走，产生了178种独特的IMUGait模式。每个模式都会攻击各种用户认证模型。对错误率的深入分析(攻击前后)挑战了基于IMUGait模式的认证系统是最困难的这种信仰。

    We present a novel adversarial model for authentication systems that use gait patterns recorded by the inertial measurement unit (IMU) built into smartphones. The attack idea is inspired by and named after the concept of a dictionary attack on knowledge (PIN or password) based authentication systems. In particular, this work investigates whether it is possible to build a dictionary of IMUGait patterns and use it to launch an attack or find an imitator who can actively reproduce IMUGait patterns that match the target's IMUGait pattern. Nine physically and demographically diverse individuals walked at various levels of four predefined controllable and adaptable gait factors (speed, step length, step width, and thigh-lift), producing 178 unique IMUGait patterns. Each pattern attacked a wide variety of user authentication models. The deeper analysis of error rates (before and after the attack) challenges the belief that authentication systems based on IMUGait patterns are the most difficul
    
[^7]: 隐性随机动力学系统中的转向预警

    Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])

    [http://arxiv.org/abs/2309.03842](http://arxiv.org/abs/2309.03842)

    本研究提出了一种基于定向异性扩散图的方法，通过捕捉低维流形中的潜在演化动态，能够有效提取早期警报信号来检测复杂系统或高维观测数据中的动力学转变，并在真实的脑电图数据上得到了验证。

    

    在许多实际应用中，如基因突变、脑疾病、自然灾害、金融危机和工程可靠性，对复杂系统或高维观测数据中的动力学转变进行早期警报是至关重要的。为了有效提取早期警报信号，我们开发了一种新方法：定向异性扩散图，它捕捉了低维流形中的潜在演化动态。将该方法应用于真实的脑电图（EEG）数据，我们成功找到了适当的有效坐标，并推导出能够检测状态转变中临界点的早期警报信号。我们的方法将潜在动态与原始数据集联系起来。通过数值实验证明了该框架在密度和转变概率等方面的准确性和有效性。结果表明，第二个坐标在各种评估指标中保持有意义的信息。

    Early warnings for dynamical transitions in complex systems or high-dimensional observation data are essential in many real world applications, such as gene mutation, brain diseases, natural disasters, financial crises, and engineering reliability. To effectively extract early warning signals, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in low-dimensional manifold. Applying the methodology to authentic electroencephalogram (EEG) data, we successfully find the appropriate effective coordinates, and derive early warning signals capable of detecting the tipping point during the state transition. Our method bridges the latent dynamics with the original dataset. The framework is validated to be accurate and effective through numerical experiments, in terms of density and transition probability. It is shown that the second coordinate holds meaningful information for critical transition in various evaluation metrics.
    
[^8]: 基于子图的紧框架在具有紧致支持和渐消磨的图上

    Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments. (arXiv:2309.03537v1 [eess.SP])

    [http://arxiv.org/abs/2309.03537](http://arxiv.org/abs/2309.03537)

    本研究提出了一种基于子图的紧框架构造方法，能够灵活地调整框架的消失矩和其他属性，实现对具有路径支持的图信号的高效表示，在非线性逼近任务中表现出优越性能。

    

    在这项工作中，我们提出了一种新颖且通用的方法，基于一系列分层分区构建具有紧致支持的图上的紧框架。从我们的抽象构造开始，我们能够灵活地将子图Laplacians纳入到我们的图框架设计中。因此，我们的通用方法允许调整框架的（子图）消失矩和其他属性，如方向性，以有效地表示具有路径支持的图信号。我们明确定义并测试了几个变体。实验结果表明，我们提出的图框架在非线性逼近任务中表现出优越性能。

    In this work, we proposed a novel and general method to construct tight frames on graphs with compact supports based on a series of hierarchical partitions. Starting from our abstract construction that generalizes previous methods based on partition trees, we are able to flexibly incorporate subgraph Laplacians into our design of graph frames. Consequently, our general methods permit adjusting the (subgraph) vanishing moments of the framelets and extra properties, such as directionality, for efficiently representing graph signals with path-like supports. Several variants are explicitly defined and tested. Experimental results show our proposed graph frames perform superiorly in non-linear approximation tasks.
    
[^9]: 神经群体在中枢神经系统中的信息处理：数据和操作的数学结构

    Information Processing by Neuron Populations in the Central Nervous System: Mathematical Structure of Data and Operations. (arXiv:2309.02332v1 [q-bio.NC] CROSS LISTED)

    [http://arxiv.org/abs/2309.02332](http://arxiv.org/abs/2309.02332)

    神经群体在中枢神经系统中使用数学结构精确地表示和操作信息，实现了特化、泛化、新奇检测等多种功能。

    

    在哺乳动物中枢神经系统的复杂结构中，神经元形成群体。轴索束通过脉冲列作为媒介在这些群集之间进行通信。然而，这些神经群体的精确编码和操作还有待发现。在我们的分析中，出发点是一个具有可塑性的通用神经元的先进的机械模型。从这个简单的框架中出现了一个深刻的数学构造：通过有限凸锥的代数可以准确地描述信息的表示和操作。此外，这些神经群体不仅仅是被动传输者。它们在这个代数结构中扮演着运算符的角色，反映了低级编程语言的功能。当这些群体互连时，它们具有简洁而强大的代数表达式。这些网络使它们能够实现许多操作，如特化、泛化、新奇检测、维度降低等。

    In the intricate architecture of the mammalian central nervous system, neurons form populations. Axonal bundles communicate between these clusters using spike trains as their medium. However, these neuron populations' precise encoding and operations have yet to be discovered. In our analysis, the starting point is a state-of-the-art mechanistic model of a generic neuron endowed with plasticity. From this simple framework emerges a profound mathematical construct: The representation and manipulation of information can be precisely characterized by an algebra of finite convex cones. Furthermore, these neuron populations are not merely passive transmitters. They act as operators within this algebraic structure, mirroring the functionality of a low-level programming language. When these populations interconnect, they embody succinct yet potent algebraic expressions. These networks allow them to implement many operations, such as specialization, generalization, novelty detection, dimensiona
    
[^10]: 具有自适应个性化层的联邦化两阶段解耦

    Federated Two Stage Decoupling With Adaptive Personalization Layers. (arXiv:2308.15821v1 [cs.LG])

    [http://arxiv.org/abs/2308.15821](http://arxiv.org/abs/2308.15821)

    该论文提出了一种具有自适应个性化层的联邦化两阶段解耦方法，通过将同质客户端聚类到同一组的方式来提高联邦学习的性能，并解决了数据异质性和聚类时间选择的问题。

    

    由于分布式设备间的数据异质性，联邦学习在保持隐私约束的同时实现分布式学习的突破性能力引起了广泛关注。然而，由于数据异质性导致了显著的学习降级和慢收敛速度。因此，自然地采用将同质客户端聚类到同一组的概念，只允许在每个组内聚合模型权重。尽管大多数现有的聚类联邦学习方法采用模型梯度或推理输出作为客户端分区的度量标准，目的是将相似设备组合在一起，但每个聚类内部仍可能存在异质性。此外，缺乏研究探索确定聚类的适当时间的根本原因，导致常见做法是将每个客户端分配到其自己的独立聚类中，特别是在高度非ind情况下。

    Federated learning has gained significant attention due to its groundbreaking ability to enable distributed learning while maintaining privacy constraints. However, as a consequence of data heterogeneity among decentralized devices, it inherently experiences significant learning degradation and slow convergence speed. Therefore, it is natural to employ the concept of clustering homogeneous clients into the same group, allowing only the model weights within each group to be aggregated. While most existing clustered federated learning methods employ either model gradients or inference outputs as metrics for client partitioning, with the goal of grouping similar devices together, may still have heterogeneity within each cluster. Moreover, there is a scarcity of research exploring the underlying reasons for determining the appropriate timing for clustering, resulting in the common practice of assigning each client to its own individual cluster, particularly in the context of highly non ind
    
[^11]: ULDP-FL:具有跨边界用户级差分隐私的联邦学习

    ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy. (arXiv:2308.12210v1 [cs.LG])

    [http://arxiv.org/abs/2308.12210](http://arxiv.org/abs/2308.12210)

    ULDP-FL是一种新颖的联邦学习框架，设计用于跨边界的联邦学习中确保用户级差分隐私。算法通过每个用户的加权剪裁直接确保用户级差分隐私，并通过密码学构件增强了其效用。实证实验表明，该方法在隐私和效用的权衡方面取得了显著改进。

    

    差分隐私联邦学习（DP-FL）作为一种确保形式隐私的协同机器学习方法，已经引起了人们的关注。大多数DP-FL方法确保在每个边界内以记录级别的DP进行跨边界FL。然而，单个用户的数据可能延伸到多个边界，对于这种情况下的期望用户级DP保证仍然未知。在本研究中，我们提出了ULDP-FL，这是一个新颖的FL框架，旨在在单个用户的数据可能属于多个边界的跨边界FL中保证用户级DP。我们的算法通过每个用户的加权剪裁直接确保用户级DP，而不是采用组隐私方法。我们对算法的隐私和效用进行了理论分析。另外，我们通过使用密码学构件来增强算法的效用并展示了其私密实现。在真实数据集上的实证实验表明，我们的方法在隐私和效用的权衡方面取得了显著的改进。

    Differentially Private Federated Learning (DP-FL) has garnered attention as a collaborative machine learning approach that ensures formal privacy. Most DP-FL approaches ensure DP at the record-level within each silo for cross-silo FL. However, a single user's data may extend across multiple silos, and the desired user-level DP guarantee for such a setting remains unknown. In this study, we present ULDP-FL, a novel FL framework designed to guarantee user-level DP in cross-silo FL where a single user's data may belong to multiple silos. Our proposed algorithm directly ensures user-level DP through per-user weighted clipping, departing from group-privacy approaches. We provide a theoretical analysis of the algorithm's privacy and utility. Additionally, we enhance the algorithm's utility and showcase its private implementation using cryptographic building blocks. Empirical experiments on real-world datasets show substantial improvements in our methods in privacy-utility trade-offs under us
    
[^12]: 精简特征场使得语言引导的少样本操作成为可能

    Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation. (arXiv:2308.07931v1 [cs.CV])

    [http://arxiv.org/abs/2308.07931](http://arxiv.org/abs/2308.07931)

    本论文通过精简特征场，将精确的3D几何与2D基础模型的丰富语义相结合，实现了对未见过的物体的少样本操作的泛化能力。

    

    自监督和语言监督的图像模型包含了世界的丰富知识，对于泛化很重要。然而，许多机器人任务需要对 3D 几何的详细理解，这在 2D 图像特征中往往缺乏。本研究通过利用精简特征场，将精确的 3D 几何与 2D 基础模型的丰富语义相结合，来弥合机器人操作中的 2D 到 3D 的差距。我们提出一种针对 6 自由度抓取和放置的少样本学习方法，利用这些强大的空间和语义先验，实现对未见过的物体的自然泛化。通过从视觉语言模型 CLIP 中精简的特征，我们展示了一种通过自由文本自然语言指定新颖对象进行操作的方式，并展示了它在未见过的表达和新颖类别的物体上的泛化能力。

    Self-supervised and language-supervised image models contain rich knowledge of the world that is important for generalization. Many robotic tasks, however, require a detailed understanding of 3D geometry, which is often lacking in 2D image features. This work bridges this 2D-to-3D gap for robotic manipulation by leveraging distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models. We present a few-shot learning method for 6-DOF grasping and placing that harnesses these strong spatial and semantic priors to achieve in-the-wild generalization to unseen objects. Using features distilled from a vision-language model, CLIP, we present a way to designate novel objects for manipulation via free-text natural language, and demonstrate its ability to generalize to unseen expressions and novel categories of objects.
    
[^13]: 通过集合扩展实现一次性语音转换的音素幻觉器

    Phoneme Hallucinator: One-shot Voice Conversion via Set Expansion. (arXiv:2308.06382v1 [cs.SD])

    [http://arxiv.org/abs/2308.06382](http://arxiv.org/abs/2308.06382)

    本论文提出了一种名为“音素幻觉器”的一次性语音转换模型，通过集合扩展的方法，只需短时间目标说话人语音即可生成多样和高保真度的目标说话人音素，并用于基于邻居的语音转换。

    

    语音转换旨在改变一个人的声音，使其听起来与另一个人的声音相似，同时保留语言内容。现有的方法在内容可理解性和说话人相似性之间存在困境；即具有更高可理解性的方法通常具有较低的说话人相似性，而具有更高说话人相似性的方法通常需要大量目标说话人的语音数据来实现高可理解性。在这项工作中，我们提出了一种新方法“音素幻觉器”，它兼具两者的优势。音素幻觉器是一种一次性语音转换模型；它采用一种新颖的模型，仅基于较短的目标说话人语音（例如3秒）生成多样化和高保真度的目标说话人音素。然后利用生成的音素进行基于邻居的语音转换。我们的模型是一种无需文本注释的任意到任意的语音转换模型，支持转换到任何未知说话人。

    Voice conversion (VC) aims at altering a person's voice to make it sound similar to the voice of another person while preserving linguistic content. Existing methods suffer from a dilemma between content intelligibility and speaker similarity; i.e., methods with higher intelligibility usually have a lower speaker similarity, while methods with higher speaker similarity usually require plenty of target speaker voice data to achieve high intelligibility. In this work, we propose a novel method \textit{Phoneme Hallucinator} that achieves the best of both worlds. Phoneme Hallucinator is a one-shot VC model; it adopts a novel model to hallucinate diversified and high-fidelity target speaker phonemes based just on a short target speaker voice (e.g. 3 seconds). The hallucinated phonemes are then exploited to perform neighbor-based voice conversion. Our model is a text-free, any-to-any VC model that requires no text annotations and supports conversion to any unseen speaker. Objective and subje
    
[^14]: 深度神经网络架构的异步进化

    Asynchronous Evolution of Deep Neural Network Architectures. (arXiv:2308.04102v1 [cs.NE])

    [http://arxiv.org/abs/2308.04102](http://arxiv.org/abs/2308.04102)

    本文提出了一种通用的异步评估策略，用于增加进化神经网络架构搜索的吞吐量。该策略维护一个个体队列，并在适当数量的个体被评估后立即进入下一代，平衡多样性和效率。

    

    许多进化算法(EAs)利用候选解的并行评估。然而，如果评估时间差异很大，许多工作节点(即计算客户端)大部分时间都处于闲置状态，等待下一代的创建。进化神经网络架构搜索(ENAS)是一类优化深度神经网络架构和超参数的EA，特别容易受到这个问题的影响。本文提出了一种通用的异步评估策略(AES)，然后将其适配到ENAS上。AES通过维护一个多达$K$个个体的队列，这些个体已准备好被发送到工作器进行评估，并在由工作器评估了$M<<K$个个体之后立即进入下一代。合适的$M$值是通过实验确定的，平衡多样性和效率。为了展示AES的普适性和能力，首先在11位多路复用器设计(一个单个种群可验证的发现任务)上进行了评估。

    Many evolutionary algorithms (EAs) take advantage of parallel evaluation of candidates. However, if evaluation times vary significantly, many worker nodes (i.e.,\ compute clients) are idle much of the time, waiting for the next generation to be created. Evolutionary neural architecture search (ENAS), a class of EAs that optimizes the architecture and hyperparameters of deep neural networks, is particularly vulnerable to this issue. This paper proposes a generic asynchronous evaluation strategy (AES) that is then adapted to work with ENAS. AES increases throughput by maintaining a queue of upto $K$ individuals ready to be sent to the workers for evaluation and proceeding to the next generation as soon as $M<<K$ individuals have been evaluated by the workers. A suitable value for $M$ is determined experimentally, balancing diversity and efficiency. To showcase the generality and power of AES, it was first evaluated in 11-bit multiplexer design (a single-population verifiable discovery ta
    
[^15]: 算法和稀疏主成分分析的障碍是否适用于其他结构设置？

    Do algorithms and barriers for sparse principal component analysis extend to other structured settings?. (arXiv:2307.13535v1 [stat.ML])

    [http://arxiv.org/abs/2307.13535](http://arxiv.org/abs/2307.13535)

    该论文研究了在尖峰Wishart模型下，通过一类子空间并集模型捕捉信号结构的主成分分析问题。通过统计和计算的视角，我们建立了基本限制，并展示了自然的投影功率方法在解决方案的统计近似最优邻域中的局部收敛性。我们还通过具体案例的分析展示了计算难度。结果表明，对于基本稀疏PCA观察到的现象在其结构化对应物中也同样存在。

    

    在尖峰Wishart模型下，我们研究了一种主成分分析问题，其中信号中的结构通过一类子空间并集模型来捕捉。这个通用类别包括基本稀疏PCA以及带有图稀疏性的变体。为了在统计和计算的统一视角下研究这些问题，我们建立了与问题实例的几何有关的基本限制，并展示了自然的投影功率方法在解决方案的统计近似最优邻域中的局部收敛性。我们通过对普适基础中路径稀疏性和树稀疏性的两种重要特殊情况进行端到端分析，补充了这些结果，展示了初始化方法和相匹配的计算难度证据。总的来说，我们的结果表明，对于基本稀疏PCA观察到的几个现象自然地扩展到其结构化对应物中。

    We study a principal component analysis problem under the spiked Wishart model in which the structure in the signal is captured by a class of union-of-subspace models. This general class includes vanilla sparse PCA as well as its variants with graph sparsity. With the goal of studying these problems under a unified statistical and computational lens, we establish fundamental limits that depend on the geometry of the problem instance, and show that a natural projected power method exhibits local convergence to the statistically near-optimal neighborhood of the solution. We complement these results with end-to-end analyses of two important special cases given by path and tree sparsity in a general basis, showing initialization methods and matching evidence of computational hardness. Overall, our results indicate that several of the phenomena observed for vanilla sparse PCA extend in a natural fashion to its structured counterparts.
    
[^16]: 使用深度强化学习的多喷口对旋转圆柱体流动进行主动控制

    Active Control of Flow over Rotating Cylinder by Multiple Jets using Deep Reinforcement Learning. (arXiv:2307.12083v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2307.12083](http://arxiv.org/abs/2307.12083)

    本研究使用深度强化学习算法结合旋转和多个可控喷口，通过优化喷口数量和位置，传感器位置以及每个动作可允许的最大流量和每个episode中允许的总喷口数的形式，实现对旋转圆柱体流动的主动控制，抑制涡流脱落和稳定卡门涡流。

    

    人工智能的真正威力体现在强化学习中，由于其动态性质，强化学习在计算和物理方面更为复杂。旋转和喷射已被证实是减少钝体所受阻力的一种有效的主动流动控制方式。本研究将使用深度强化学习算法(DRL)来添加旋转，并利用多个可控喷口以实现最大可能的阻力抑制。将介绍DRL代码的特点，包括控制参数、其限制以及用于旋转的DRL网络的优化。本研究将重点优化喷口的数量和位置、传感器位置以及每个动作可允许的最大流量和每个episode中允许的总喷口数的形式。研究结果表明，将旋转与DRL工具相结合是有希望的，因为它可以抑制涡流脱落，稳定卡门涡流。

    The real power of artificial intelligence appears in reinforcement learning, which is computationally and physically more sophisticated due to its dynamic nature. Rotation and injection have been a proven way of active flow control to reduce the drag force exerted on blunt bodies. Rotation will be added to the cylinder alongside the deep reinforcement learning (DRL) algorithm, which uses multiple controlled jets to reach maximum possible drag suppression. Characteristics of the DRL code, including controlling parameters, their limitations, and optimization of the DRL network for use with rotation will be presented. This work will focus on optimizing the number and positions of the jets, sensors location, and maximum allowed flow rate to jets in the form of maximum allowed flow rate of each actuation and the total number of them per episode. It is found that combining the rotation with the DRL tools is promising, since it suppresses the vortex shedding, stabilizes the Karman vortex stre
    
[^17]: 当基础模型遇到联邦学习：动机、挑战和未来方向

    When Foundation Model Meets Federated Learning: Motivations, Challenges, and Future Directions. (arXiv:2306.15546v1 [cs.LG])

    [http://arxiv.org/abs/2306.15546](http://arxiv.org/abs/2306.15546)

    基础模型与联邦学习的交叉提供了解锁新可能性的独特机会，扩展了数据可用性，促进了协作式模型发展，并提高了性能和隐私保护。

    

    基础模型（FM）与联邦学习（FL）的交叉提供了相互的好处，在AI研究中提供了解锁新可能性的独特机会，解决了AI和现实世界应用中的关键挑战。FL扩展了FM的数据可用性，并实现了计算共享，分散了训练过程，并减轻了FL参与者的负担。它促进了协作式FM发展，民主化了这一过程，促进了包容性和创新。另一方面，FM以其庞大的规模、预训练的知识和出色的性能，为FL提供了一个强大的起点，促进了在非独立同分布数据下更快的收敛和更好的性能。此外，利用FM生成合成数据可以丰富数据多样性，减少过拟合，保护隐私。通过研究FL和FM之间的相互作用，本文旨在加深对它们协同关系的理解，强调动机和挑战。

    The intersection of the Foundation Model (FM) and Federated Learning (FL) provides mutual benefits, presents a unique opportunity to unlock new possibilities in AI research, and address critical challenges in AI and real-world applications. FL expands the availability of data for FMs and enables computation sharing, distributing the training process and reducing the burden on FL participants. It promotes collaborative FM development, democratizing the process and fostering inclusivity and innovation. On the other hand, FM, with its enormous size, pre-trained knowledge, and exceptional performance, serves as a robust starting point for FL, facilitating faster convergence and better performance under non-iid data. Additionally, leveraging FM to generate synthetic data enriches data diversity, reduces overfitting, and preserves privacy. By examining the interplay between FL and FM, this paper aims to deepen the understanding of their synergistic relationship, highlighting the motivations,
    
[^18]: 线性赌博机中平衡性能与理论保证的几何感知方法

    Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])

    [http://arxiv.org/abs/2306.14872](http://arxiv.org/abs/2306.14872)

    本文提出了一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为线性赌博机算法建立实例相关的频率后悔界，并实现了平衡算法性能与理论保证的效果。

    

    本文受线性赌博机算法表现良好的实证性能与悲观理论后悔界之间的不一致性启发，提出一种新的数据驱动技术，跟踪不确定度椭球体的几何形状，为包括贪心、OFUL和汤普森抽样算法在内的广泛算法类建立实例相关的频率后悔界，在保留基本算法大部分优良特性的同时“校正”基本算法在某些实例中表现差的问题，实现了渐近最优后悔界。我们通过仿真实验验证了该方法的有效性。

    This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
    
[^19]: 在预测之后的有效推断

    Valid inference after prediction. (arXiv:2306.13746v1 [stat.ML])

    [http://arxiv.org/abs/2306.13746](http://arxiv.org/abs/2306.13746)

    最近的研究聚焦于基于预测的推断，并提出了修正步骤以实现对未观测到响应和协变量之间关系的有效推断，Angelopoulos等人（2023）的方法成功控制了第一类错误率，并提供了正确命名覆盖的置信区间，但在某些情况下，其存在低功率问题。

    

    近期的研究聚焦于基于预测的推断，即使用预先训练好的机器学习模型预测未观测到的响应变量，然后对该预测响应与某些协变量之间的关系进行推断。然而，将标准推断方法应用于该过程并不能准确量化未观测到（而非预测到）响应与协变量之间的关系。最近，Wang等人（2020）和Angelopoulos等人（2023）提出了修正（ii）步骤的方法，以实现对未观测到响应和协变量之间关系的有效推断。本文表明，Angelopoulos等人（2023）提出的方法成功地控制了第一类错误率，并提供了具有正确命名覆盖的置信区间，无论预先训练的机器学习模型用于预测未观测到的响应的质量如何。然而，我们也发现在某些情况下，所提出的方法具有低功率。

    Recent work has focused on the very common practice of prediction-based inference: that is, (i) using a pre-trained machine learning model to predict an unobserved response variable, and then (ii) conducting inference on the association between that predicted response and some covariates. As pointed out by Wang et al. [2020], applying a standard inferential approach in (ii) does not accurately quantify the association between the unobserved (as opposed to the predicted) response and the covariates. In recent work, Wang et al. [2020] and Angelopoulos et al. [2023] propose corrections to step (ii) in order to enable valid inference on the association between the unobserved response and the covariates. Here, we show that the method proposed by Angelopoulos et al. [2023] successfully controls the type 1 error rate and provides confidence intervals with correct nominal coverage, regardless of the quality of the pre-trained machine learning model used to predict the unobserved response. Howe
    
[^20]: 大型语言模型能否从相关性中推断出因果关系?

    Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v1 [cs.CL])

    [http://arxiv.org/abs/2306.05836](http://arxiv.org/abs/2306.05836)

    本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。

    

    因果推断是人类智慧的标志之一。虽然CausalNLP领域近年来引起了广泛关注，但NLP中现有的因果推断数据集主要依赖于从经验知识（例如常识知识）中发现因果关系。在本文中，我们提出了第一个基准数据集，用于测试大型语言模型（LLM）的纯因果推断能力。具体而言，我们制定了一个新的任务Corr2Cause，它采用一组相关语句并确定变量之间的因果关系。我们策划了一个大规模的数据集，其中包含超过400K个样本，我们在其中评估了17个现有的LLMs。通过我们的实验，我们确定了LLMs在因果推断技能方面的一个关键缺陷，并表明这些模型在该任务上的表现几乎接近随机。当我们尝试通过微调将LLMs重新用于这种技能时，这种缺陷在某种程度上得到了缓解，但我们发现这些模型仍然失败了。

    Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 400K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fa
    
[^21]: 解决扩散模型中的负迁移问题

    Addressing Negative Transfer in Diffusion Models. (arXiv:2306.00354v1 [cs.CV])

    [http://arxiv.org/abs/2306.00354](http://arxiv.org/abs/2306.00354)

    本文从多任务学习角度出发，研究了扩散训练中的负迁移现象，提出了利用正则化技术增强扩散训练的方法，以减轻负迁移并提高去噪任务的性能。

    

    基于扩散的生成模型在各个领域都取得了显著的成功。它在同时涵盖不同噪声水平的去噪任务上训练模型，代表了一种多任务学习（MTL）的形式。然而，从MTL的角度分析和改善扩散模型仍然未被充分探索。特别地，MTL有时会导致众所周知的$\textit{负迁移}$现象，这种现象是由于任务之间存在冲突而导致某些任务的性能降低。本文旨在从MTL的角度分析扩散训练，提出了两个关键观察：$\textbf{(O1)}$ 随着噪声水平之间的差距加大，去噪任务之间的任务亲和力减弱， $\textbf{(O2)}$ 在扩散训练的背景下，负迁移也可能会出现。基于这些观察结果，我们的目标是通过减轻负迁移来增强扩散训练。为了实现这一目标，我们提出了利用现有的MTL方法、具体是正则化技术，来鼓励任务特定的特征提取并减少任务干扰。实验结果表明，我们提出的方法有效地减轻了负迁移，提高了扩散模型在一系列去噪任务上的性能。

    Diffusion-based generative models have achieved remarkable success in various domains. It trains a model on denoising tasks that encompass different noise levels simultaneously, representing a form of multi-task learning (MTL). However, analyzing and improving diffusion models from an MTL perspective remains under-explored. In particular, MTL can sometimes lead to the well-known phenomenon of $\textit{negative transfer}$, which results in the performance degradation of certain tasks due to conflicts between tasks. In this paper, we aim to analyze diffusion training from an MTL standpoint, presenting two key observations: $\textbf{(O1)}$ the task affinity between denoising tasks diminishes as the gap between noise levels widens, and $\textbf{(O2)}$ negative transfer can arise even in the context of diffusion training. Building upon these observations, our objective is to enhance diffusion training by mitigating negative transfer. To achieve this, we propose leveraging existing MTL metho
    
[^22]: 度量空间和Nagata维度中k-NN规则的普遍一致性(II)

    Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II. (arXiv:2305.17282v1 [cs.LG])

    [http://arxiv.org/abs/2305.17282](http://arxiv.org/abs/2305.17282)

    本文研究了k近邻学习规则中的普遍一致性，发现在可分度量空间中，该规则在Nagata维度下的sigma有限维度的空间中是普遍一致的，在非阿基米德度量空间中是强普遍一致的，此规则在具有de Groot有限维度意义下的度量空间和Heisenberg群中也是普遍一致的。

    

    我们继续在可分度量空间中研究k近邻学习规则。由于C\'erou和Guyader(2006)以及Preiss(1983)的结果，已知该规则在每个Nagata意义下的sigma有限维度的度量空间X中是普遍一致的。在此，我们展示了在无平局情况下此规则在这样的空间中是强普遍一致的。在Devroye，Gy\"{o}rfi，Krzy\.{z}ak和Lugosi（1994）在欧几里得设置中应用的打破平局策略下，我们设法在非阿基米德度量空间（即Nagata维度为零的空间）中展示了强普遍一致性。结合C\'erou和Guyader的定理和Assouad和Quentin de Gromard (2006)的结果，可以推出$k$-NN规则在具有de Groot有限维度意义下的度量空间中是普遍一致的。特别地，$k$-NN规则在Heisenberg群中是普遍一致的，而该群并非sigma有限维度的。

    We continue to investigate the $k$ nearest neighbour learning rule in separable metric spaces. Thanks to the results of C\'erou and Guyader (2006) and Preiss (1983), this rule is known to be universally consistent in every metric space $X$ that is sigma-finite dimensional in the sense of Nagata. Here we show that the rule is strongly universally consistent in such spaces in the absence of ties. Under the tie-breaking strategy applied by Devroye, Gy\"{o}rfi, Krzy\.{z}ak, and Lugosi (1994) in the Euclidean setting, we manage to show the strong universal consistency in non-Archimedian metric spaces (that is, those of Nagata dimension zero). Combining the theorem of C\'erou and Guyader with results of Assouad and Quentin de Gromard (2006), one deduces that the $k$-NN rule is universally consistent in metric spaces having finite dimension in the sense of de Groot. In particular, the $k$-NN rule is universally consistent in the Heisenberg group which is not sigma-finite dimensional in the se
    
[^23]: 知识迁移下的因果效应估计: 转移因果学习

    Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer. (arXiv:2305.09126v1 [cs.LG])

    [http://arxiv.org/abs/2305.09126](http://arxiv.org/abs/2305.09126)

    本文提出了一个名为$\ell_1$-TCL的通用框架，它使用知识迁移和Lasso回归来提高因果效应估计精度。

    

    本文研究了一种新颖的问题，即在相同的协变量（或特征）空间设置下通过知识迁移来提高因果效应估计精度，即同类别迁移学习（TL），将其称为转移因果学习（TCL）问题。我们提出了一个通用的框架$\ell_1$-TCL，其中包含$\ell_1$正则化TL来进行苦事参数估计和下游插件ACE估计器，包括结果回归、逆概率加权和双重稳健估计器。最重要的是，借助于Lasso用于高维回归，我们建立了非渐近恢复保证。

    A novel problem of improving causal effect estimation accuracy with the help of knowledge transfer under the same covariate (or feature) space setting, i.e., homogeneous transfer learning (TL), is studied, referred to as the Transfer Causal Learning (TCL) problem. While most recent efforts in adapting TL techniques to estimate average causal effect (ACE) have been focused on the heterogeneous covariate space setting, those methods are inadequate for tackling the TCL problem since their algorithm designs are based on the decomposition into shared and domain-specific covariate spaces. To address this issue, we propose a generic framework called \texttt{$\ell_1$-TCL}, which incorporates $\ell_1$ regularized TL for nuisance parameter estimation and downstream plug-in ACE estimators, including outcome regression, inverse probability weighted, and doubly robust estimators. Most importantly, with the help of Lasso for high-dimensional regression, we establish non-asymptotic recovery guarantee
    
[^24]: Deep Stock: 使用深度学习进行训练和交易的方案

    Deep Stock: training and trading scheme using deep learning. (arXiv:2304.14870v1 [q-fin.ST])

    [http://arxiv.org/abs/2304.14870](http://arxiv.org/abs/2304.14870)

    本文提出了一种使用深度学习进行训练和交易的方案，DeepStock通过查看股票价格的过去数据，并使用Resnet和logits来预测股票价格在未来D天内是否会升降一定百分比，并在韩国和美国市场上取得了超过市场回报的利润。

    

    尽管有效市场假说存在，但许多研究表明股票市场存在失灵现象，导致出现了一些能够获得超过市场回报的技术，即alpha。近几十年来，系统性交易已经取得了重大进展，深度学习作为分析和预测市场行为的强大工具已经开始崭露头角。本文中，我们提出了一种受专业交易员启发的模型，该模型查看先前的600天的股票价格，并预测股票价格在接下来D天内是否会升降一定百分比。我们的模型称为DeepStock，使用Resnet的跳跃连接和logits来增加模型在交易方案中的概率。我们在韩国和美国股票市场上测试了我们的模型，并在韩国市场上获得了N％的利润，超过市场回报M％，并在美国市场上获得了A％的利润，超过市场回报B％。

    Despite the efficient market hypothesis, many studies suggest the existence of inefficiencies in the stock market, leading to the development of techniques to gain above-market returns, known as alpha. Systematic trading has undergone significant advances in recent decades, with deep learning emerging as a powerful tool for analyzing and predicting market behavior. In this paper, we propose a model inspired by professional traders that look at stock prices of the previous 600 days and predicts whether the stock price rises or falls by a certain percentage within the next D days. Our model, called DeepStock, uses Resnet's skip connections and logits to increase the probability of a model in a trading scheme. We test our model on both the Korean and US stock markets and achieve a profit of N\% on Korea market, which is M\% above the market return, and profit of A\% on US market, which is B\% above the market return.
    
[^25]: 带种植模式的Hopfield模型：一种师生自我监督学习模型

    Hopfield model with planted patterns: a teacher-student self-supervised learning model. (arXiv:2304.13710v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2304.13710](http://arxiv.org/abs/2304.13710)

    该论文提出了一种基于师生自我监督学习问题的Hopfield模型，能够帮助机器利用结构化的模式来学习，虽然一些条件对于学习非常重要，但这种学习模式在特定条件下可以实现泛化。

    

    尽管Hopfield网络被认为是记忆存储和检索的典型模型，但现代人工智能系统主要基于机器学习范式。我们展示了如何利用具有结构化模式的Hopfield模型的适当推广来构建Boltzmann机的师生自我监督学习问题，其中自旋变量是机器权重，模式对应于训练集的示例。我们通过研究相图来分析学习性能，这些相图是通过训练集大小、数据集噪声和推断温度（即权重正则化）来构建的。使用小而富信息的数据集，机器可以通过记忆来学习。使用嘈杂的数据集，则需要大量的示例数以超过临界阈值。在这个区域，系统的存储限制成为产生一种学习模式的机会，在这种模式下，系统可以进行泛化。

    While Hopfield networks are known as paradigmatic models for memory storage and retrieval, modern artificial intelligence systems mainly stand on the machine learning paradigm. We show that it is possible to formulate a teacher-student self-supervised learning problem with Boltzmann machines in terms of a suitable generalization of the Hopfield model with structured patterns, where the spin variables are the machine weights and patterns correspond to the training set's examples. We analyze the learning performance by studying the phase diagram in terms of the training set size, the dataset noise and the inference temperature (i.e. the weight regularization). With a small but informative dataset the machine can learn by memorization. With a noisy dataset, an extensive number of examples above a critical threshold is needed. In this regime the memory storage limits of the system becomes an opportunity for the occurrence of a learning regime in which the system can generalize.
    
[^26]: 能量为基础的切片Wasserstein距离

    Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])

    [http://arxiv.org/abs/2304.13586](http://arxiv.org/abs/2304.13586)

    本文提出了一种能量为基础的切片Wasserstein距离，并将其参数化，以克服传统方法中的固定先验分布缺乏信息和优化最佳分布昂贵不稳定的局限。

    

    切片Wasserstein（SW）距离被广泛认为是两个概率测度之间的一种统计有效且计算高效的度量。SW距离的一个关键部分是切片分布。目前有两种方法来选择这个分布。第一种方法是使用固定的先验分布。第二种是优化归属于参数分布族的最佳分布，并且可以最大化期望的距离。然而，这两种方法都有局限性。固定的先验分布在突出能够区分两个常规概率测度的投影方向方面缺乏信息。而优化最佳分布通常是昂贵和不稳定的。此外，设计候选分布的参数分布族可能会很容易被错误指定。为了解决这些问题，我们提出将切片分布设计为基于能量的分布，并将其参数化，从而使其更加通用而稳健。

    The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
    
[^27]: UDTIRI:一个开源的道路坑洞检测基准套件

    UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite. (arXiv:2304.08842v1 [cs.CV])

    [http://arxiv.org/abs/2304.08842](http://arxiv.org/abs/2304.08842)

    该论文介绍了一个开源的道路坑洞检测基准套件UDTIRI，包含了标记齐全的1000张道路坑洞图像，可以用于深度学习方法在城市道路检查中的目标检测、语义分割和实例分割任务。

    

    看到在城市数字孪生领域中利用强大的深度学习方法的巨大潜力。特别是在智能道路检查领域，目前研究和数据有限。为了促进这一领域的进展，我们开发了一个名为Urban Digital Twins Intelligent Road Inspection (UDTIRI)数据集的标记齐全的道路坑洞数据集。我们希望这个数据集能够让强大的深度学习方法在城市道路检查中发挥作用，让算法更全面地理解场景并最大化其潜力。我们的数据集包括1000张道路坑洞图像，拍摄于不同的情境中，具有不同的光照和湿度条件。我们的意图是将这个数据集应用于目标检测、语义分割和实例分割任务。我们的团队花费了大量精力进行了详细的统计分析，并对UDTIRI数据集的一些代表性深度学习模型进行了基准测试。

    It is seen that there is enormous potential to leverage powerful deep learning methods in the emerging field of urban digital twins. It is particularly in the area of intelligent road inspection where there is currently limited research and data available. To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset. We hope this dataset will enable the use of powerful deep learning methods in urban road inspection, providing algorithms with a more comprehensive understanding of the scene and maximizing their potential. Our dataset comprises 1000 images of potholes, captured in various scenarios with different lighting and humidity conditions. Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks. Our team has devoted significant effort to conducting a detailed statistical analysis, and benchmarking a selection of represent
    
[^28]: 奖励转移的稳健决策重点学习

    Robust Decision-Focused Learning for Reward Transfer. (arXiv:2304.03365v1 [cs.LG])

    [http://arxiv.org/abs/2304.03365](http://arxiv.org/abs/2304.03365)

    本文介绍了一种稳健决策重点（RDF）算法，利用非识别性的DF解，学习同时最大化期望回报和抵御奖励函数变化的模型，可以显著提高DF对奖励函数变化的稳健性，而不会降低智能体的总回报。

    

    最近，决策重点（Decision-focused，DF）的基于模型的强化学习被介绍为一种强有力的算法，它可以专注于学习最有利于获得高报酬的MDP动态。虽然这种方法通过专注于直接优化报酬来提高智能体的性能，但从MLE的角度来看，它学习的动力学不够准确，因此可能对奖励函数的变化很脆弱。在这项工作中，我们开发了稳健决策重点（RDF）算法，它利用DF解的非识别性，学习同时最大化期望回报和抵御奖励函数变化的模型。我们在各种玩具示例和医疗模拟器上展示了RDF显着增加了DF对奖励函数变化的稳健性，而不会降低智能体的总回报。

    Decision-focused (DF) model-based reinforcement learning has recently been introduced as a powerful algorithm which can focus on learning the MDP dynamics which are most relevant for obtaining high rewards. While this approach increases the performance of agents by focusing the learning towards optimizing for the reward directly, it does so by learning less accurate dynamics (from a MLE standpoint), and may thus be brittle to changes in the reward function. In this work, we develop the robust decision-focused (RDF) algorithm which leverages the non-identifiability of DF solutions to learn models which maximize expected returns while simultaneously learning models which are robust to changes in the reward function. We demonstrate on a variety of toy example and healthcare simulators that RDF significantly increases the robustness of DF to changes in the reward function, without decreasing the overall return the agent obtains.
    
[^29]: 基于多子网络的EMO联合剪枝：高效快速

    An EMO Joint Pruning with Multiple Sub-networks: Fast and Effect. (arXiv:2303.16212v1 [cs.LG])

    [http://arxiv.org/abs/2303.16212](http://arxiv.org/abs/2303.16212)

    本文提出了一种基于多子网络的EMO联合剪枝算法，该算法可以减少空间和资源消耗。该算法采用分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。基于跨网络约束的子网络训练方法可以进一步提高性能。

    

    基于进化多目标（EMO）的网络剪枝算法可以平衡网络的剪枝率和性能。然而，由于基于种群的特性，它经常受到复杂的剪枝优化空间和高度资源消耗的剪枝结构验证过程的限制，从而限制了它的应用。为此，本文提出了一种基于多子网络的EMO联合剪枝（EMO-PMS），以减少空间复杂度和资源消耗。首先，提出了一种分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。一方面，这种分解减少了剪枝优化空间并降低了优化难度；另一方面，较小的网络结构收敛更快，因此所提出的算法的计算资源消耗较低。其次，基于跨网络约束的子网络训练方法。

    The network pruning algorithm based on evolutionary multi-objective (EMO) can balance the pruning rate and performance of the network. However, its population-based nature often suffers from the complex pruning optimization space and the highly resource-consuming pruning structure verification process, which limits its application. To this end, this paper proposes an EMO joint pruning with multiple sub-networks (EMO-PMS) to reduce space complexity and resource consumption. First, a divide-and-conquer EMO network pruning framework is proposed, which decomposes the complex EMO pruning task on the whole network into easier sub-tasks on multiple sub-networks. On the one hand, this decomposition reduces the pruning optimization space and decreases the optimization difficulty; on the other hand, the smaller network structure converges faster, so the computational resource consumption of the proposed algorithm is lower. Secondly, a sub-network training method based on cross-network constraint
    
[^30]: 原子结构表征的完备性

    Completeness of Atomic Structure Representations. (arXiv:2302.14770v2 [physics.chem-ph] UPDATED)

    [http://arxiv.org/abs/2302.14770](http://arxiv.org/abs/2302.14770)

    本文解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，并提出了一种构造有限子集描述符的新方法。

    

    在本文中，我们解决了获取全面对称的点粒子群体（如分子中的原子）表示的挑战，这在物理学和理论化学中非常重要。随着机器学习技术在科学中的广泛应用，这个问题变得更加重要，因为它支撑了模型准确复现物理关系并与基本对称性和守恒定律一致的能力。然而，通常用于表示点云的描述符（尤其是用于描述原子尺度上物质的描述符）无法区分特殊的粒子排列。这使得无法用机器学习来学习它们的属性。存在可证明完备性的框架，但仅在同时描述所有原子之间的相互关系的极限情况下才是如此，这在实践中是不可行的。我们提出了一种构造有限子集描述符的新方法。

    In this paper, we address the challenge of obtaining a comprehensive and symmetric representation of point particle groups, such as atoms in a molecule, which is crucial in physics and theoretical chemistry. The problem has become even more important with the widespread adoption of machine-learning techniques in science, as it underpins the capacity of models to accurately reproduce physical relationships while being consistent with fundamental symmetries and conservation laws. However, the descriptors that are commonly used to represent point clouds -- most notably those adopted to describe matter at the atomic scale -- are unable to distinguish between special arrangements of particles. This makes it impossible to machine learn their properties. Frameworks that are provably complete exist but are only so in the limit in which they simultaneously describe the mutual relationship between all atoms, which is impractical. We present a novel approach to construct descriptors of finite cor
    
[^31]: 机器学习用于合成数据生成的综述

    Machine Learning for Synthetic Data Generation: A Review. (arXiv:2302.04062v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04062](http://arxiv.org/abs/2302.04062)

    机器学习用于合成数据生成的综述，探讨了合成数据生成的应用（计算机视觉、语音、自然语言、医疗保健和商业）、机器学习方法（神经网络架构和深度生成模型）以及隐私和公平问题，并提出了未来的研究方向。

    

    数据在机器学习中发挥着关键作用。然而，在实际应用中，数据存在多种问题，如数据质量低，有限的数据点导致机器学习模型欠拟合，由于隐私、安全和监管问题难以访问数据。合成数据生成提供了一种有前途的新途径，因为它可以以真实世界数据无法做到的方式进行共享和使用。本文系统地回顾了利用机器学习模型进行合成数据生成的现有工作。具体而言，我们从以下几个方面讨论合成数据生成的工作：（i）应用，包括计算机视觉、语音、自然语言、医疗保健和商业；（ii）机器学习方法，特别是神经网络架构和深度生成模型；（iii）隐私和公平问题。此外，我们还确定了这一新兴领域的挑战和机遇，并提出了未来的研究方向。

    Data plays a crucial role in machine learning. However, in real-world applications, there are several problems with data, e.g., data are of low quality; a limited number of data points lead to under-fitting of the machine learning model; it is hard to access the data due to privacy, safety and regulatory concerns. Synthetic data generation offers a promising new avenue, as it can be shared and used in ways that real-world data cannot. This paper systematically reviews the existing works that leverage machine learning models for synthetic data generation. Specifically, we discuss the synthetic data generation works from several perspectives: (i) applications, including computer vision, speech, natural language, healthcare, and business; (ii) machine learning methods, particularly neural network architectures and deep generative models; (iii) privacy and fairness issue. In addition, we identify the challenges and opportunities in this emerging field and suggest future research directions
    
[^32]: 相对论数字孪生：将物联网引入未来

    Relativistic Digital Twin: Bringing the IoT to the Future. (arXiv:2301.07390v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2301.07390](http://arxiv.org/abs/2301.07390)

    本文提出了相对论数字孪生（RDT）框架，通过不断观察物联网实体的真实对应物来自动生成通用型数字孪生，并调整其行为模型。框架利用物联网之物（WoT）提供标准化接口。

    

    复杂的物联网生态系统通常需要使用其物理资产的数字孪生（DT）来进行预测分析和模拟“假设”情景。数字孪生能够复制物联网设备，并随着时间的推移适应其行为变化。然而，物联网中的数字孪生通常针对特定的用例，无法无缝适应不同的情境。此外，物联网的碎片化使得在具有多种数据格式和物联网网络协议的异构情景中部署数字孪生更具挑战性。在本文中，我们提出了相对论数字孪生（RDT）框架，通过该框架我们可以自动生成物联网实体的通用型数字孪生，并通过不断观察其真实对应物来调整其行为模型。该框架依赖于通过物联网之物（WoT）来进行对象表示，为每个物联网设备及其数字孪生提供标准化接口。

    Complex IoT ecosystems often require the usage of Digital Twins (DTs) of their physical assets in order to perform predictive analytics and simulate what-if scenarios. DTs are able to replicate IoT devices and adapt over time to their behavioral changes. However, DTs in IoT are typically tailored to a specific use case, without the possibility to seamlessly adapt to different scenarios. Further, the fragmentation of IoT poses additional challenges on how to deploy DTs in heterogeneous scenarios characterized by the usage of multiple data formats and IoT network protocols. In this paper, we propose the Relativistic Digital Twin (RDT) framework, through which we automatically generate general-purpose DTs of IoT entities and tune their behavioral models over time by constantly observing their real counterparts. The framework relies on the object representation via the Web of Things (WoT), to offer a standardized interface to each of the IoT devices as well as to their DTs. To this purpose
    
[^33]: 马尔可夫切片Wasserstein距离：超越独立投影

    Markovian Sliced Wasserstein Distances: Beyond Independent Projections. (arXiv:2301.03749v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.03749](http://arxiv.org/abs/2301.03749)

    马尔可夫切片Wasserstein（MSW）距离是一种新的SW距离家族，通过在投影方向上施加一阶马尔可夫结构，解决了切片Wasserstein（SW）距离中独立投影导致的冗余投影的问题，并且具有较低的计算复杂度。（found in translation）

    

    切片Wasserstein（SW）距离由于独立的均匀随机投影方向而导致冗余投影。为了部分克服这个问题，最大K切片Wasserstein（Max-K-SW）距离（$K\geq1$）寻求最佳的区分正交投影方向。尽管能够减少投影数量，但Max-K-SW的度量性在实践中不能保证，原因是优化的非最优性。此外，正交约束也在计算上是昂贵的，可能不太有效。为了解决这个问题，我们引入了一种新的SW距离家族，称为马尔可夫切片Wasserstein（MSW）距离，它在投影方向上施加了一阶马尔可夫结构。我们通过指定马尔可夫结构，包括先验分布、转移分布以及燃烧和稀疏化技术，讨论了MSW的各种成员。此外，我们还研究了MSW的理论性质，包括拓扑性质（found in translation）

    Sliced Wasserstein (SW) distance suffers from redundant projections due to independent uniform random projecting directions. To partially overcome the issue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the best discriminative orthogonal projecting directions. Despite being able to reduce the number of projections, the metricity of Max-K-SW cannot be guaranteed in practice due to the non-optimality of the optimization. Moreover, the orthogonality constraint is also computationally expensive and might not be effective. To address the problem, we introduce a new family of SW distances, named Markovian sliced Wasserstein (MSW) distance, which imposes a first-order Markov structure on projecting directions. We discuss various members of MSW by specifying the Markov structure including the prior distribution, the transition distribution, and the burning and thinning technique. Moreover, we investigate the theoretical properties of MSW including topological properties (met
    
[^34]: 差分隐私扩散模型

    Differentially Private Diffusion Models. (arXiv:2210.09929v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2210.09929](http://arxiv.org/abs/2210.09929)

    本研究提出了一种差分隐私扩散模型(DPDMs)，通过差分隐私训练生成模型，实现对隐私的保护，在图像生成基准测试中表现优越，能够在标准测试中与特定任务的DP-SGD训练的分类器相媲美。

    

    现代机器学习模型依赖于越来越大的训练数据集，然而在涉及隐私的领域，数据通常是有限的。通过差分隐私训练的生成模型可以绕过这一挑战，提供对合成数据的访问。本文在扩散模型的最新成功基础上，引入了差分隐私扩散模型(DPDMs)，使用差分隐私随机梯度下降(DP-SGD)来实现隐私保护。我们研究了DPDM中的参数化和采样算法，并提出了噪声多样性，这是一个针对DM训练的强大改进。我们在图像生成基准测试中验证了我们的新颖DPDMs，并在所有实验证明了最先进的性能。此外，在标准基准测试中，使用DPDM生成的合成数据训练的分类器表现与特定任务的DP-SGD训练的分类器相当，这在以往的研究中没有被证明。

    While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. We build on the recent success of diffusion models (DMs) and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs, and propose noise multiplicity, a powerful modification of DP-SGD tailored to the training of DMs. We validate our novel DPDMs on image generation benchmarks and achieve state-of-the-art performance in all experiments. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been dem
    
[^35]: 基于条件扩散模型的有损图像压缩

    Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v5 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.06950](http://arxiv.org/abs/2209.06950)

    本文提出了一种利用条件扩散模型进行有损图像压缩的优化框架。通过引入额外的内容潜变量以及合成纹理变量，该方法在图像质量评估指标上表现出更强的性能。

    

    本文提出了一种利用扩散生成模型的端到端优化的有损图像压缩框架。该方法基于变换编码范式，将图像映射到潜在空间进行信息熵编码，然后再映射回数据空间进行重构。与基于变分自编码器(VAE)的神经压缩方法不同，我们的解码器是一个条件扩散模型。因此，我们的方法引入了一个额外的“内容”潜变量，反向扩散过程会对其进行条件化，并利用该变量存储图像信息。决定扩散过程的剩余“纹理”变量会在解码时合成。通过实验，我们展示了模型的性能可以根据感知度量进行调整。我们广泛的实验涉及了多个数据集和图像质量评估指标，结果表明我们的方法相较于基于生成对抗网络的方法能够得到更好的FID分数。

    This paper outlines an end-to-end optimized lossy image compression framework using diffusion generative models. The approach relies on the transform coding paradigm, where an image is mapped into a latent space for entropy coding and, from there, mapped back to the data space for reconstruction. In contrast to VAE-based neural compression, where the (mean) decoder is a deterministic neural network, our decoder is a conditional diffusion model. Our approach thus introduces an additional "content" latent variable on which the reverse diffusion process is conditioned and uses this variable to store information about the image. The remaining "texture" variables characterizing the diffusion process are synthesized at decoding time. We show that the model's performance can be tuned toward perceptual metrics of interest. Our extensive experiments involving multiple datasets and image quality assessment metrics show that our approach yields stronger reported FID scores than the GAN-based mode
    
[^36]: 拜占庭人也能从历史中学习：联邦学习中心化剪裁的衰落

    Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09894](http://arxiv.org/abs/2208.09894)

    本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    

    联邦学习 (FL) 框架由于在广泛的协作学习任务中的成功而越来越受欢迎，但也引起了某些安全问题。其中，拜占庭攻击的风险是特别关注的问题，这指的是恶意客户参与学习过程的可能性。因此，FL 中的一个关键目标是消除 Byzantine attacks 的潜在影响，确保最终模型是可信的。已经观察到，客户端的模型/更新之间的方差越大，隐藏 Byzantine attacks 的空间就越大。因此，通过使用动量，从而减少方差，可以削弱已知 Byzantine attacks 的力量。中心化剪裁 (CC) 框架进一步表明，上一次的动量项除了减少方差外，还可以作为一个参考点更好地消除 Byzantine attacks。在本文中，我们研究了在不同的恶意代理有不同目标时 CC 的脆弱性。我们提出了一种改进的剪裁算法称为多引用点剪裁 (MRPC)，以克服这种脆弱性。MRPC 框架有效地利用多个参考点来消除专门设计以绕过 CC 方法的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks, and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients' models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that, the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this wor
    
[^37]: 在再生核希尔伯特空间系列中的集成预测：仙境中的动力系统。

    Ensemble forecasts in reproducing kernel Hilbert space family: dynamical systems in Wonderland. (arXiv:2207.14653v2 [math-ph] UPDATED)

    [http://arxiv.org/abs/2207.14653](http://arxiv.org/abs/2207.14653)

    本文提出了一种在动力系统中的集合预测和模拟的方法，将系统嵌入再生核希尔伯特空间族，并在该空间中使用简单的集合数据同化方法进行轨迹重构。

    

    提出了一种针对海洋或大气流等高维动力系统的集合估计和模拟的方法框架。为此，将该动力系统嵌入由动力驱动的再生核希尔伯特空间族中。这个家族因其吸引人的特性而被命名为仙境。在仙境中，Koopman和Perron-Frobenius算子是酉的和一致连续的。这个属性保证它们可以用对角化有界无穷小生成器的指数级级数表示。此外，可以直接获得对Lyapunov指数和切线线性动态的精确集合式表达式。仙境使我们能够设计出极其简单的集合数据同化方法，用于以轨迹样本的恒定时间线性组合来进行轨迹重构。这种令人尴尬的简单策略得以实现，是通过Hilbert空间设置中切线线性动力的完全合理的叠加原理实现的。

    A methodological framework for ensemble-based estimation and simulation of high dimensional dynamical systems such as the oceanic or atmospheric flows is proposed. To that end, the dynamical system is embedded in a family of reproducing kernel Hilbert spaces with kernel functions driven by the dynamics. This family is nicknamed Wonderland for its appealing properties. In Wonderland the Koopman and Perron-Frobenius operators are unitary and uniformly continuous. This property warrants they can be expressed in exponential series of diagonalizable bounded infinitesimal generators. Access to Lyapunov exponents and to exact ensemble based expressions of the tangent linear dynamics are directly available as well. Wonderland enables us the devise of strikingly simple ensemble data assimilation methods for trajectory reconstructions in terms of constant-in-time linear combinations of trajectory samples. Such an embarrassingly simple strategy is made possible through a fully justified superposi
    
[^38]: Auto-SDE:从数据驱动的随机动力学系统中学习有效的降维动力学

    Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.04151](http://arxiv.org/abs/2205.04151)

    本文提出了一种名为Auto-SDE的算法来学习慢-快随机动力学系统的有效降维动力学，通过自动编码器神经网络和离散化的随机微分方程，捕捉了系统的演化特性，并在数值实验证明了其准确性、稳定性和有效性。

    

    由于能够描绘许多实际应用中的复杂现象，多尺度随机动力学系统被广泛应用于科学和工程问题。本文致力于研究慢-快随机动力学系统的有效降维动力学。给定满足某些未知慢-快随机系统的短期观测数据，我们提出了一种包括自动编码器神经网络Auto-SDE的新算法来学习不变的慢流形。我们的方法捕捉了一系列时间相关的自动编码器神经网络的演化特性，损失函数通过离散化的随机微分方程构造。通过在各种评估指标下的数值实验证明，我们的算法具有准确性、稳定性和有效性。

    Multiscale stochastic dynamical systems have been widely adopted to scientific and engineering problems due to their capability of depicting complex phenomena in many real world applications. This work is devoted to investigating the effective reduced dynamics for a slow-fast stochastic dynamical system. Given observation data on a short-term period satisfying some unknown slow-fast stochastic system, we propose a novel algorithm including a neural network called Auto-SDE to learn invariant slow manifold. Our approach captures the evolutionary nature of a series of time-dependent autoencoder neural networks with the loss constructed from a discretized stochastic differential equation. Our algorithm is also proved to be accurate, stable and effective through numerical experiments under various evaluation metrics.
    

