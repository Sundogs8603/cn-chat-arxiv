# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning with Explanation Constraints.](http://arxiv.org/abs/2303.14496) | 本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。 |
| [^2] | [Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban Computing: A Survey.](http://arxiv.org/abs/2303.14483) | 本综述介绍了面向城市计算的时空图神经网络预测学习领域的发展现状，包括其框架、实现方法和应用场景，以及当前的研究热点和挑战，提出了该领域未来的发展方向和应用前景。 |
| [^3] | [Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains.](http://arxiv.org/abs/2303.14475) | 本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。 |
| [^4] | [3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition.](http://arxiv.org/abs/2303.14474) | 3Mformer是一种多阶多模变形器，通过形成超图捕捉身体关节组的高阶运动模式，使得在骨骼动作识别方面表现优于现有最先进的模型 |
| [^5] | [Autoregressive Conditional Neural Processes.](http://arxiv.org/abs/2303.14468) | 本论文提出了自回归条件神经过程模型，能够建模高度相关的非高斯预测分布。 |
| [^6] | [Verifying Properties of Tsetlin Machines.](http://arxiv.org/abs/2303.14464) | 该论文介绍了一种对Tsetlin Machine进行正式验证性质的方法，并展示了对抗性鲁棒性、等价性和相似性方面的结果。此外，还将新的模型相似性概念应用于TsMs。 |
| [^7] | [CFA: Class-wise Calibrated Fair Adversarial Training.](http://arxiv.org/abs/2303.14460) | 本文提出了CFA框架，针对每个类别自动定制特定的对抗训练配置，提高了DNN对抗训练的公平性，同时不影响总体的对抗鲁棒性。 |
| [^8] | [Federated Learning without Full Labels: A Survey.](http://arxiv.org/abs/2303.14453) | 本文综述了如何在联邦学习过程中利用无标注数据解决无全标签问题，并介绍了半监督学习、自监督学习和迁移学习等方法。同时还总结了用于评估这些方法的数据集和它们各自的优缺点。 |
| [^9] | [No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning.](http://arxiv.org/abs/2303.14443) | 本文通过对抗性学习破解了自动论文审稿人分配系统，实现了对论文的不明显更改，进而可以成功选择和删除审稿人，攻击成功率达80％以上。 |
| [^10] | [Heat flux for semi-local machine-learning potentials.](http://arxiv.org/abs/2303.14434) | 本文中介绍了如何将Green-Kubo方法应用于半局域机器学习势，使用自动微分推导出适应的热通量公式，成功计算了二氧化锆的热导率。 |
| [^11] | [Deep Active Learning with Contrastive Learning Under Realistic Data Pool Assumptions.](http://arxiv.org/abs/2303.14433) | 该论文提出了一种适用于现实数据池的、基于对比学习的深度主动学习方法，并且引入了包括模糊的、与任务无关的分布外样本以及分布内样本的新的主动学习基准。 |
| [^12] | [Beta-VAE has 2 Behaviors: PCA or ICA?.](http://arxiv.org/abs/2303.14430) | Beta-VAE模型的表示学习效果受潜在变量总量影响：使用少量潜在变量时表现为PCA，使用大量潜在变量时表现为ICA。 |
| [^13] | [Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation.](http://arxiv.org/abs/2303.14423) | 本文提出一种基于变换器的连续学习架构，用于学习双模态的视觉语言任务，并采用动态增加参数和知识蒸馏的方法，实现在多任务学习中共享信息和解决灾难性遗忘的问题。该方法具有扩展性和高效性能。 |
| [^14] | [Spatially-Aware Car-Sharing Demand Prediction.](http://arxiv.org/abs/2303.14421) | 本文提出了一种基于空间感知学习算法的方法来分析共享汽车站点的平均月度需求，利用了丰富的特征作为输入，可以提高预测性能。 |
| [^15] | [Deep Linear Discriminant Analysis with Variation for Polycystic Ovary Syndrome Classification.](http://arxiv.org/abs/2303.14401) | 本文介绍了基于 Deep LDA 的多囊卵巢综合症预测方案，采用带变化的深度线性判别分析算法，绕过简单机器学习算法利用图形处理器的限制，提高了诊断性能。 |
| [^16] | [IFSeg: Image-free Semantic Segmentation via Vision-Language Model.](http://arxiv.org/abs/2303.14396) | IFSeg提出了一种全新的无图像分割任务，能够在没有特定图像和注释的情况下执行语义分割，实现了基于视觉语言模型的人工图像分割对更新，取得了在多个基准数据集上的最先进表现，对未知类别和噪声鲁棒性强。 |
| [^17] | [Multi-pooling 3D Convolutional Neural Network for fMRI Classification of Visual Brain States.](http://arxiv.org/abs/2303.14391) | 本文提出一种多池化3D卷积神经网络（MP3DCNN）来提高fMRI分类准确性，可以将分类准确率从1.684%提高到14.918%,适用于分类面部与对象以及面部和对象的子类别。 |
| [^18] | [Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm.](http://arxiv.org/abs/2303.14382) | 本文提出了一种新的“主动微调”任务，旨在在预训练-微调范式中利用注释预算。作者提出了一种名为ActiveFT的方法，通过优化参数模型来选择一组数据子集进行注释，以减小所选子集的分布与整个数据池之间的地球移动距离。 |
| [^19] | [A Registration- and Uncertainty-based Framework for White Matter Tract Segmentation With Only One Annotated Subject.](http://arxiv.org/abs/2303.14371) | 本文提出使用只有一份标注样本进行白质束 (WM) 分割的框架，该框架使用注册式峰值增强 (RPA) 和基于不确定性的精炼 (URe) 模块构建，可以获得高精度和高饱和的性能表现。 |
| [^20] | [FlexNeRF: Photorealistic Free-viewpoint Rendering of Moving Humans from Sparse Views.](http://arxiv.org/abs/2303.14368) | 本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。通过对时间和姿态配置的优化以及额外的损失，可在观察视角变得更稀疏时提供高质量的输出，这在公开基准数据集以及自行捕获的时尚数据集上都表现出优越性。 |
| [^21] | [Hybrid Fuzzy-Crisp Clustering Algorithm: Theory and Experiments.](http://arxiv.org/abs/2303.14366) | 本文提出了一种基于目标函数的混合模糊-清晰聚类算法，能够解决传统模糊C均值聚类算法在聚类大小差异巨大时的不平衡影响问题，同时在实验中表现出更好的聚类质量和鲁棒性。 |
| [^22] | [Dealing With Heterogeneous 3D MR Knee Images: A Federated Few-Shot Learning Method With Dual Knowledge Distillation.](http://arxiv.org/abs/2303.14357) | 本文提出了一种具有双重知识蒸馏的联邦少样本学习方法，利用公共数据库的知识来缓解私人标注图像的短缺，并通过有限的标注数据、无监督学习和双重知识蒸馏，达到优于现有最先进方法的结果。 |
| [^23] | [Intelligent Load Balancing and Resource Allocation in O-RAN: A Multi-Agent Multi-Armed Bandit Approach.](http://arxiv.org/abs/2303.14355) | 本论文提出了一种多智能体多臂赌博机(mmLBRA)方法，用于实现O-RAN中的负载均衡和资源分配，以解决网络拥塞和用户故障问题。 |
| [^24] | [DiracDiffusion: Denoising and Incremental Reconstruction with Assured Data-Consistency.](http://arxiv.org/abs/2303.14353) | DiracDiffusion是一种新的逆问题求解框架，可以应用于图像去噪和增量重建，并保证数据一致性。 |
| [^25] | [Hierarchical Multi-Agent Multi-Armed Bandit for Resource Allocation in Multi-LEO Satellite Constellation Networks.](http://arxiv.org/abs/2303.14351) | 本文提出了一种分层式多智能体多臂赌博机资源分配（mmRAL）框架，用于适当分配LEO卫星星座的可用无线电资源，以解决资源管理及无信道信息收集的问题。 |
| [^26] | [Causal Image Synthesis of Brain MR in 3D.](http://arxiv.org/abs/2303.14349) | 该论文提出了一种基于因果关系的图像合成方法，可以生成在不同人口统计变量、临床指数和阿尔茨海默病患者的脑MR图像之间的反事实脑MR图像。 |
| [^27] | [From G\"odel's Incompleteness Theorem to the completeness of bot religions (Extended abstract).](http://arxiv.org/abs/2303.14338) | 本文研究了从哥德尔不完备定理到机器人宗教的完备性的逻辑过程，提出了任何信仰系统可以被形式化为逻辑理论，并且不完备定理意味着存在真实但无法证明的陈述，可以用来定义出与现有信仰和传统一致的新宗教实践。 |
| [^28] | [Ensemble-based Blackbox Attacks on Dense Prediction.](http://arxiv.org/abs/2303.14304) | 本文提出了一种对密集预测模型进行黑盒攻击的方法，该方法基于一个经过精心设计的集成，并注意到单个模型的权重规范化和集成权重的调整可以进一步提高攻击性能。该方法已经在目标检测和分割任务上得到了验证。 |
| [^29] | [Unsupervised Feature Selection to Identify Important ICD-10 Codes for Machine Learning: A Case Study on a Coronary Artery Disease Patient Cohort.](http://arxiv.org/abs/2303.14303) | 本研究比较了几种无监督特征选择方法，通过选择性能最佳的Concrete Autoencoder方法，成功识别出49,075例冠状动脉疾病患者数据库中的最佳100个特征，并证实Concrete Autoencoder方法中的权重调整能够提高其准确性。 |
| [^30] | [repliclust: Synthetic Data for Cluster Analysis.](http://arxiv.org/abs/2303.14301) | repliclust 是一个 Python 包，用于生成具有聚类的合成数据集，基于数据集的原型，提供了放置集群中心、采样集群形状、选择每个集群的数据点数量以及为集群分配概率分布的算法。 |
| [^31] | [Efficient Lipschitzian Global Optimization of H\"older Continuous Multivariate Functions.](http://arxiv.org/abs/2303.14293) | 本研究提出了一种高效的全局优化技术，通过预定的查询创建规则实现了对Hölder连续多元函数的计算优势，可在给定时间段内获得 minimax 最优的结果。 |
| [^32] | [Applications of Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes.](http://arxiv.org/abs/2303.14291) | 高斯过程是一种适合拟合少量数据且充分考虑不确定性的模型，可用于从分子到黑洞等多个领域的数据预测和推断。 |
| [^33] | [Feature Space Sketching for Logistic Regression.](http://arxiv.org/abs/2303.14284) | 该论文提出了基于草图的逻辑回归coreset构建、特征选择和降维的新界限，并解决了之前工作中存在的问题，并提出了可扩展到广义线性模型的前向误差界限。 |
| [^34] | [Sequential Knockoffs for Variable Selection in Reinforcement Learning.](http://arxiv.org/abs/2303.14281) | 本论文介绍了一种新颖的序列 Knockoffs (SEEK)算法，用于在强化学习系统中实现变量选择，该算法估计了最小充分状态，确保学习进程良好而不会减缓。 |
| [^35] | [Learning to Operate in Open Worlds by Adapting Planning Models.](http://arxiv.org/abs/2303.14272) | 该论文提出了一种能够在开放环境中检测新奇性并快速适应其领域模型和行动选择的方法，具有解释性，表现良好。 |
| [^36] | [The Exact Sample Complexity Gain from Invariances for Kernel Regression on Manifolds.](http://arxiv.org/abs/2303.14269) | 本文提供了在任何流形上，对于一个在流形上任意群作用下不变的目标函数，核岭回归的最小化最优率，从而增加了有效样本数量或降低了流形的维数。 |
| [^37] | [A Self-supervised Framework for Improved Data-Driven Monitoring of Stress via Multi-modal Passive Sensing.](http://arxiv.org/abs/2303.14267) | 本文介绍了一种利用多模态数据和自监督框架来跟踪压力反应的生理前体的新方法。这种方法有助于提高精神健康监测的可靠性和效果。 |
| [^38] | [Safe and Sample-efficient Reinforcement Learning for Clustered Dynamic Environments.](http://arxiv.org/abs/2303.14265) | 本研究提出了一种安全、高效的强化学习框架，使用安全集算法监测和修改标准控制，并在聚类动态环境下实现，同时使用三项技术提高智能体的学习效率。 |
| [^39] | [Towards Diverse and Coherent Augmentation for Time-Series Forecasting.](http://arxiv.org/abs/2303.14254) | 本研究提出了一种组合频谱和时间增强的方法，用于解决时间序列预测数据增强缺乏多样性和连贯性的问题。 |
| [^40] | [Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing.](http://arxiv.org/abs/2303.14244) | 本论文研究了过参数化低秩矩阵感知问题，证明了通过因子化方法训练的过参数化模型可以收敛，并且隐式平衡和正则化可以促进泛化。 |
| [^41] | [IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients.](http://arxiv.org/abs/2303.14242) | IDGI 提出了一种新的方法来减少 integrated gradients 解释显著性图中的噪声，并在众多可解释性指标上显著提高了解释性能。 |
| [^42] | [Core-based Trend Detection in Blockchain Networks.](http://arxiv.org/abs/2303.14241) | 本研究介绍了一种可伸缩的方法InnerCore用于分析区块链网络，实现了基于区块链网络对关键参与者的识别并提供情感指标，以实现自动化的趋势监测。 |
| [^43] | [Causality Detection for Efficient Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.14227) | 本文研究了多智能体强化学习中一些代理无法理解他们在团队表现中的真实影响，导致学习次优策略，表现懒惰。通过因果关系检测惩罚懒惰代理并改善其行为，团队整体性能和每个代理的个体能力都得到了提升。 |
| [^44] | [Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions.](http://arxiv.org/abs/2303.14226) | 提出了一种在组合干预下进行因果推断的模型，通过施加潜在结构跨越单位和组合，在降低实验数量和处理混杂问题方面有着良好表现。 |
| [^45] | [Machine Guided Discovery of Novel Carbon Capture Solvents.](http://arxiv.org/abs/2303.14223) | 该研究展示了机器学习在加速新型碳捕集材料发现方面的潜力，通过结合实验室测试和分子指纹模型方法，成功识别出潜在的碳捕集溶剂。 |
| [^46] | [The Battle of Information Representations: Comparing Sentiment and Semantic Features for Forecasting Market Trends.](http://arxiv.org/abs/2303.14221) | 本文研究了股票价格预测所需的情感和语义特征表示的比较，结果表明基于情感的方法在预测市场趋势方面更优。 |
| [^47] | [Variational Inference for Longitudinal Data Using Normalizing Flows.](http://arxiv.org/abs/2303.14220) | 该文提出一种基于标准化流的高维纵向数据生成模型，能够进行好的缺失数据插补操作。 |
| [^48] | [Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems.](http://arxiv.org/abs/2303.14197) | 该论文提出了一种在DRL基础的AVs中探索最佳平滑分布以消除后门攻击的方法，通过将噪声添加到输入中来中和攻击并实现更好的检测和防御。 |
| [^49] | [DeepEpiSolver: Unravelling Inverse problems in Covid, HIV, Ebola and Disease Transmission.](http://arxiv.org/abs/2303.14194) | DeepEpiSolver使用深度神经网络(DNN)作为逆问题求解器估计SIR模型的参数，相对于Physics Informed Neural Networks (PINNs)方法，其训练速度更快，且可以很好地推广到新的SIDR轨迹上，并在 COVID-19、HIV、埃博拉和疾病传播方面取得验证性结果。 |
| [^50] | [Improved Adversarial Training Through Adaptive Instance-wise Loss Smoothing.](http://arxiv.org/abs/2303.14077) | 本文提出了一种新的对抗训练方法(Instance-adaptive Adversarial Training, IAAT)通过平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本，取得了在各种数据集下的最新、最佳结果，并在白盒和黑盒攻击下均优于以前的方法。 |
| [^51] | [Topological Reconstruction of Particle Physics Processes using Graph Neural Networks.](http://arxiv.org/abs/2303.13937) | Topograph是一种利用图神经网络和粒子衰变自然规律的拓扑结构重建方法，不仅解决了观测到的末态对象组合指派问题，还预测了中间粒子的性质及其后续衰变，比标准方法效果更好，与现代机器学习技术表现相当。 |
| [^52] | [Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs.](http://arxiv.org/abs/2303.13763) | 本文提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。 |
| [^53] | [Artificial Intelligence for Sustainability: Facilitating Sustainable Smart Product-Service Systems with Computer Vision.](http://arxiv.org/abs/2303.13540) | 本论文在可持续性方面的主要贡献是使用深度学习技术提高产品生产和使用的可持续性，通过计算机视觉技术检测产品的磨损状态并用于改进智能产品-服务系统的集成和结果取向。 |
| [^54] | [Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis.](http://arxiv.org/abs/2303.13391) | Xplainer是一个透明且可解释的零样本诊断新框架，通过对存在的描述性观察进行分类来提高自动诊断集成到临床工作流程中的效率，同时避免需要大量注释数据的问题。 |
| [^55] | [SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization.](http://arxiv.org/abs/2303.13035) | 研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型. |
| [^56] | [The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs.](http://arxiv.org/abs/2303.12961) | 本论文回顾了超过80个在非成像 EMR 数据上训练的基础模型，发现这些模型大多范围有限、训练集有限，且评估指标未对其对医疗系统贡献提供有意义见解。因此，本研究提出了一种更接近于医疗保健重要指标的医疗基础模型效益评估框架。 |
| [^57] | [Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization.](http://arxiv.org/abs/2303.12921) | 本文研究了可复制算法与标准算法稳定性的联系，为一类统计问题提供了可复制算法的样本有效算法约化，同时表明这种等价关系必须在计算上崩溃。 |
| [^58] | [Cube-Based 3D Denoising Diffusion Probabilistic Model for Cone Beam Computed Tomography Reconstruction with Incomplete Data.](http://arxiv.org/abs/2303.12861) | 本文提出了一种基于立方体的3D去噪扩散概率模型（DDPM）来重建CBCT并解决了存储整个正弦图的内存问题。通过将整个CBCT volume分成多个小立方体，该模型能够实现高效的计算并在视觉和定量评价方面优于现有方法。 |
| [^59] | [Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder.](http://arxiv.org/abs/2303.12848) | 该方法使用遮蔽自编码器进行对抗攻击检测和重构，不需要在测试时间更新模型权重，也不需要使用更多的对抗样本来增强训练集。 |
| [^60] | [DPPMask: Masked Image Modeling with Determinantal Point Processes.](http://arxiv.org/abs/2303.12736) | 本文提出了一种简单有效的遮盖图像建模方法DPPMask，用确定性点过程（DPPs）替换了随机过程以减少遮盖后图像的语义变化，从而在多个基准数据集上显著改善了代表性能。 |
| [^61] | [Democratising AI: Multiple Meanings, Goals, and Methods.](http://arxiv.org/abs/2303.12642) | 这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。 |
| [^62] | [Multiscale Attention via Wavelet Neural Operators for Vision Transformers.](http://arxiv.org/abs/2303.12398) | 本文介绍了一种基于小波神经算子的多尺度注意力机制，它通过使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内，取得了比ViT和AFNO更显著的性能提高。 |
| [^63] | [Stochastic Nonsmooth Convex Optimization with Heavy-Tailed Noises.](http://arxiv.org/abs/2303.12277) | 本文分析了具有重尾噪声的随机非光滑凸优化问题，并填补了在函数非光滑场景下的研究空白。 |
| [^64] | [Projections of Model Spaces for Latent Graph Inference.](http://arxiv.org/abs/2303.11754) | 本文将双曲和球形模型空间的立体投影以及Riemannian隐空间的乘积应用于潜在图推断，实现了与非投影空间相当的性能并提供理论保证。 |
| [^65] | [Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations.](http://arxiv.org/abs/2303.11577) | 提出了一种基于特征相邻的多保真体系结构，通过共享低保真度和高保真度解决方案的特征空间来减少或消除对高精度数据的依赖，这在解决复杂问题时具有重要意义。 |
| [^66] | [SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency.](http://arxiv.org/abs/2303.11525) | 本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。 |
| [^67] | [STDLens: Model Hijacking-resilient Federated Learning for Object Detection.](http://arxiv.org/abs/2303.11511) | STDLens 是一种可以防止FL受到模型挟持的攻击的安全方法。它基于三层的取证框架来识别和排除特殊的梯度，并恢复FL的性能。STDLens在物体检测方面实现了最先进的性能并且具有防止模型挟持的鲁棒性。 |
| [^68] | [Investigating Topological Order using Recurrent Neural Networks.](http://arxiv.org/abs/2303.11207) | 本研究通过循环神经网络有效地捕获了多体哈密顿量中的拓扑序，进一步证明了循环神经网络波函数是研究物态相的一个有力工具。 |
| [^69] | [Rotating without Seeing: Towards In-hand Dexterity through Touch.](http://arxiv.org/abs/2303.10880) | 本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。 |
| [^70] | [Stochastic Interpolants: A Unifying Framework for Flows and Diffusions.](http://arxiv.org/abs/2303.08797) | 本文提出了一种统一的生成模型，该模型基于随机插值框架，可以实现流和扩散方法的统一。作者构建了一类广泛的连续时间随机过程，用于将两个任意的密度在有限时间内精确地连接。这种方法可以用于基于概率微分方程的确定性和随机生成模型的构建。 |
| [^71] | [Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields.](http://arxiv.org/abs/2303.08435) | 本文提出了一种新的基于机器学习的光刻模型范式，通过优化复值神经场执行光学核回归并将光刻系统拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核，使用小规模训练数据集展示了卓越的推广能力。 |
| [^72] | [Artificial intelligence for artificial materials: moir\'e atom.](http://arxiv.org/abs/2303.08162) | 研究者使用二维费米神经网络解决了Moiré工程中Moiré原子中电子的相互作用问题，并发现强Coulomb相互作用与各向异性Moiré势能相结合可以产生“Wigner分子”电荷密度分布。 |
| [^73] | [Audio Visual Language Maps for Robot Navigation.](http://arxiv.org/abs/2303.07522) | 该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。 |
| [^74] | [Many learning agents interacting with an agent-based market model.](http://arxiv.org/abs/2303.07393) | 本论文介绍了多个强化学习最优执行交易智能体与反应式基于智能体的金融市场模型的交互。通过平衡执行差价和未能及时执行订单的惩罚，说明了奖励函数的作用。研究表明，学习智能体的数量、初始订单大小和状态空间的变化，会对最小智能市场模拟造成不同的影响。 |
| [^75] | [Zone-based Federated Learning for Mobile Sensing Data.](http://arxiv.org/abs/2303.06246) | 本文提出了一种基于区域的联邦学习方法，用于训练移动感知数据的深度学习模型。该方法将物理空间划分为地理区域，并映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，能够很好地适应该区域用户的数据和行为，并保护用户数据隐私。 |
| [^76] | [Complement Sparsification: Low-Overhead Model Pruning for Federated Learning.](http://arxiv.org/abs/2303.06237) | 本文提出了一种名为补充稀疏化的模型剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足联邦学习中低双向通信开销、客户端低计算开销和良好模型准确性的要求。 |
| [^77] | [Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance.](http://arxiv.org/abs/2303.02841) | 本文研究了金融领域自然语言理解任务中的模型无关元学习算法，取得了最先进的性能表现。 |
| [^78] | [Linear Spaces of Meanings: Compositional Structures in Vision-Language Models.](http://arxiv.org/abs/2302.14383) | 本文研究了视觉语言模型中的组合结构，并提出了一种使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式的方法，将这些向量视为“理想单词”，并在CLIP的嵌入中以实验方式探索了这些结构的可用性。 |
| [^79] | [VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion.](http://arxiv.org/abs/2302.12251) | VoxFormer是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。它采用两阶段设计，从可见的体素查询开始，并通过自我注意来传播信息，实现了有效的三维场景补全。 |
| [^80] | [A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions.](http://arxiv.org/abs/2302.08175) | 本论文提出了一种用于逼近多元正态分布Fisher-Rao距离的简单方法，通过离散化曲线连接正态分布并逼近相邻正态分布之间的Rao距离，评估了逼近技术的质量，同时介绍了一些信息几何性质。 |
| [^81] | [Do Deep Learning Methods Really Perform Better in Molecular Conformation Generation?.](http://arxiv.org/abs/2302.07061) | 分子构象生成是药物研发中的基本问题，传统方法在不同的分子结构上有局限性。最近，有很多基于深度学习的方法称它们比传统方法优越许多。然而，这项研究发现基于传统方法的无参聚类算法与深度学习算法相媲美或更优，希望这个发现能促进MCG中深度学习方法的修正。 |
| [^82] | [Chain of Hindsight Aligns Language Models with Feedback.](http://arxiv.org/abs/2302.02676) | 该研究提出了一种新颖的技术，即回顾链，可以轻松优化，并可以从任何形式的反馈中学习，而不受其极性的影响。 |
| [^83] | [ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation.](http://arxiv.org/abs/2301.13166) | 本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。 |
| [^84] | [Identifying Adversarially Attackable and Robust Samples.](http://arxiv.org/abs/2301.12896) | 本文提出了一种深度学习方法，用于检测哪些样本最容易受到对抗性攻击，从而确定哪些样本最不容易受到攻击。实验结果表明，这种检测器在不同的模型结构中具有较好的可移植性和检测性能。 |
| [^85] | [Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration.](http://arxiv.org/abs/2301.11517) | 为了评估图神经网络，提出了一种通过对抗自我监督的概念性新框架，并引入了竞争性Barlow Twins目标函数，使两个GNN可以一起更新。 |
| [^86] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^87] | [The Impossibility of Parallelizing Boosting.](http://arxiv.org/abs/2301.09627) | Boosting算法无法进行有效的并行化，需要指数级别的计算资源，否则并行化的效果并不显著。 |
| [^88] | [PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav.](http://arxiv.org/abs/2301.07302) | 本文提出了PIRLNav，通过人类演示的BC预训练和RL微调两个阶段的学习方案，成功率达到ObjectNav的65.0％，比以前的最新技术高5.0％。 |
| [^89] | [Efficient Robustness Assessment via Adversarial Spatial-Temporal Focus on Videos.](http://arxiv.org/abs/2301.00896) | 该论文提出了一种名为AstFocus的新型攻击方法，利用视频中的时间和空间冗余来实现有效和高效的梯度估计，从而降低了对抗攻击的查询次数，该方法在对多个最先进的视频识别模型进行实验后证明了其有效性和高效性。 |
| [^90] | [Machine Learning as an Accurate Predictor for Percolation Threshold of Diverse Networks.](http://arxiv.org/abs/2212.14694) | 本研究展示了五种机器学习回归技术在精准预测渗透阈值方面的有效性，并证明其优于现有的合成估计器，在预测位置和爆炸性渗透时也有潜力。 |
| [^91] | [Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models.](http://arxiv.org/abs/2212.12380) | 本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。 |
| [^92] | [On Calibrating Semantic Segmentation Models: Analyses and An Algorithm.](http://arxiv.org/abs/2212.12053) | 本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。 |
| [^93] | [Expanding Knowledge Graphs with Humans in the Loop.](http://arxiv.org/abs/2212.05189) | 本文提出了一种与人类互动的方法扩展知识图谱，通过预测新概念的“父母”，然后由人类专家进一步验证。该方法能够保证预测的父母距离概念的真实父母“近”，能够提高人算协作的速度和准确性，并在新闻和娱乐领域的真实数据集上得到了验证。 |
| [^94] | [Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding.](http://arxiv.org/abs/2212.02802) | 本文提出了一种基于扩散自编码器的面部视频编辑框架，可以从给定的视频中提取出分解的特征，实现简单的特征调整来确保时间上的一致性。与现有的基于GAN的方法不同，该模型同时满足重建和编辑能力，并且对受野外面部视频的角落情况具有鲁棒性。 |
| [^95] | [ObjectMatch: Robust Registration using Canonical Object Correspondences.](http://arxiv.org/abs/2212.01985) | ObjectMatch是一种利用语义对象识别来实现间接对应关系的鲁棒性注册方法，在处理很少或没有帧之间重叠的情况下表现出了显著的优势，并在 RGB-D 序列的三个公共数据集中实现了最先进的准确性。 |
| [^96] | [Optimizing Explanations by Network Canonization and Hyperparameter Search.](http://arxiv.org/abs/2211.17174) | 这篇论文介绍了新的解释人工智能方法，通过网络规范化和超参数搜索来提高解释效果。 |
| [^97] | [Confidence-Aware Graph Neural Networks for Learning Reliability Assessment Commitments.](http://arxiv.org/abs/2211.15755) | 本论文针对可靠性评估承诺的优化问题，利用基于 GNN 的结构预测发电机的承诺和约束，并通过对高置信度预测结果的可行性修复，提高了最先进算法的解决方案质量。 |
| [^98] | [Shifted Diffusion for Text-to-image Generation.](http://arxiv.org/abs/2211.15388) | 本文提出了一种新的文本到图像生成方法，使用Shifted Diffusion模型更好地生成来自输入文本的图像嵌入，并通过大量实验和评估证明了其在效率和有效性方面的优势，同时支持半监督和无语言训练。 |
| [^99] | [Multi-Modal Few-Shot Temporal Action Detection.](http://arxiv.org/abs/2211.14905) | 提出了一个新的多模态少样本时间动作检测问题，针对这个问题提出了一个新的 MUPPET 方法，通过在视觉-语言模型中构建多模态提示，并使用多模态聚类算法来组合时序连续的片段，解决了问题。在少样本和零样本场景下表现出了优越性，并验证了不同组件的有效性。 |
| [^100] | [On Designing Light-Weight Object Trackers through Network Pruning: Use CNNs or Transformers?.](http://arxiv.org/abs/2211.13769) | 本文介绍了如何通过神经网络结构剪枝技术设计压缩版的高度压缩轻量级物体跟踪器。通过对CNN和Transformers跟踪器的比较研究，揭示出在设计轻量级跟踪器时的最佳架构选择。最后，提供了极端剪枝率的跟踪结果，可能有助于更好地了解网络剪枝在物体跟踪中的限制。 |
| [^101] | [BiasBed -- Rigorous Texture Bias Evaluation.](http://arxiv.org/abs/2211.13190) | 本文介绍了 BiasBed，一个测试平台，用于严格评估降低纹理偏差的方法，包括多个数据集和现有算法，并配备了广泛的评估协议以揭示其显著性。 |
| [^102] | [Minimizing the Accumulated Trajectory Error to Improve Dataset Distillation.](http://arxiv.org/abs/2211.11004) | 通过新增损失项最小化累积轨迹误差，从而提高数据集精炼效果，并且在多种数据集和网络架构上的实验证明该方法优于当前最先进的方法。 |
| [^103] | [Magic3D: High-Resolution Text-to-3D Content Creation.](http://arxiv.org/abs/2211.10440) | 本论文提出的Magic3D方法，采用两步优化框架，可以比之前的DreamFusion方法快2倍创建高质量3D网格模型，解决了NeRF优化速度极慢和对低分辨率图像空间监督的限制。 |
| [^104] | [Latent User Intent Modeling for Sequential Recommenders.](http://arxiv.org/abs/2211.09832) | 该论文提出了一种基于概率建模和变分自编码器的方法，将用户意图作为潜在变量，从而更好地理解用户并优化长期用户体验，证明其在离线分析和实时实验中的有效性。 |
| [^105] | [Thermodynamics of bidirectional associative memories.](http://arxiv.org/abs/2211.09694) | 研究了双向联想记忆的平衡性质，表征了其随机扩展在热力学极限下的计算能力，提供了有限温度和无噪声情况下的相图，分析了临界负载。 |
| [^106] | [Interpretable Few-shot Learning with Online Attribute Selection.](http://arxiv.org/abs/2211.09107) | 本文提出了一种在线属性选择机制的天然可解释模型来处理小样本学习，通过减少每个episode中涉及的属性数量提高准确性和可解释性，同时自动检测并补偿人工智能属性池不足的episode。 |
| [^107] | [Artificial intelligence approaches for materials-by-design of energetic materials: state-of-the-art, challenges, and future directions.](http://arxiv.org/abs/2211.08179) | 本文回顾了人工智能在能量材料设计方面的最新进展及应用，通过数据驱动的方法，可以确定最佳材料设计以及指向具有优越性能和性能指标的设计。 |
| [^108] | [Deep Temporal Modelling of Clinical Depression through Social Media Text.](http://arxiv.org/abs/2211.07717) | 本文通过使用抑郁症状检测分类器，从社交媒体文本提取临床相关特征，建立了一个模型用于检测用户的临床抑郁症，通过提供不同时间粒度的准确度度量来评估该模型。 |
| [^109] | [Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression.](http://arxiv.org/abs/2211.07484) | 该论文研究了一种带有资源线性约束的上下文幸存者问题的变种，提出了一种新的算法，该算法简单、计算效率高，同时能够实现较低的后悔。此外，当某些约束被违反时，算法在统计上是最优的。 |
| [^110] | [Average-Case Complexity of Tensor Decomposition for Low-Degree Polynomials.](http://arxiv.org/abs/2211.05274) | 该论文研究了低次多项式张量分解问题的平均计算复杂度，发现在$r \ll n^{3/2}$时存在多项式时间算法，但当$r \lesssim n^2$时，该问题只能在原则上恢复秩-1分量，是一个计算困难问题。 |
| [^111] | [A Characterization of List Learnability.](http://arxiv.org/abs/2211.04956) | 本文通过引入$k$-DS维度，完全表征了$k$-列表学习性，并指出当且仅当该假设类的$k$-DS维度有限，该假设类才$k$-列表可学习。 |
| [^112] | [Consistent and Truthful Interpretation with Fourier Analysis.](http://arxiv.org/abs/2210.17426) | 该论文提出了一个称为真实解释的新概念，通过傅立叶分析获得严格保证，并在实验中证明了其在支持假设情景和降低解释误差方面的优势。 |
| [^113] | [Generalizability of Functional Forms for Interatomic Potential Models Discovered by Symbolic Regression.](http://arxiv.org/abs/2210.15124) | 使用符号回归发现的新型原子势模型功能形式成功地应用于于铜等化学属性类似的元素。 |
| [^114] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^115] | [Neural Network Approximations of PDEs Beyond Linearity: A Representational Perspective.](http://arxiv.org/abs/2210.12101) | 本文研究表征能力，使用神经网络逼近非线性偏微分方程解。研究发现，函数与偏导数组合产生的函数Barron范数不超过$B_Lb^p$，可以通过具有Barron范数 $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}}\right)}$ 的函数$\epsilon$-逼近PDE解。 |
| [^116] | [LOT: Layer-wise Orthogonal Training on Improving $\ell_2$ Certified Robustness.](http://arxiv.org/abs/2210.11620) | 本文提出了一种基于层内正交训练的方法(LOT)，通过使用一个无限制矩阵来参数化正交矩阵来有效训练1-Lipschitz卷积层，并证明了半监督训练可以进一步提高利普希茨约束模型的可证明鲁棒性。在确定性l2可证明鲁棒性方面，LOT显著优于基线，并能够扩展到更深的神经网络。 |
| [^117] | [Stability of Entropic Wasserstein Barycenters and application to random geometric graphs.](http://arxiv.org/abs/2210.10535) | 本文研究了在离散网格上的WB与底层流形的几何关系，证明了在离散形状上计算的WB的一致性。 |
| [^118] | [TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis.](http://arxiv.org/abs/2210.09693) | 本文提出了一种基于时频分析的时间序列异常检测模型 TFAD。在设计的时频架构中，同时加入了时间序列分解和数据增强机制，以提升性能和解释性能力。在广泛使用的基准数据集上，实证研究表明，该方法在单变量和多变量时间序列异常检测任务中性能最佳。 |
| [^119] | [How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders.](http://arxiv.org/abs/2210.08344) | 本论文探究了Masked Autoencoders (MAE)学习有意义特征的理论方法，建立了MAE与对比学习之间的紧密联系，提出了一种增强均匀性的MAE (U-MAE) 损失函数。这些理论和方法在真实世界数据集上带来了显着的改进。 |
| [^120] | [Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers.](http://arxiv.org/abs/2210.08198) | 该论文提出了一种能够容忍异常值干扰数据的分布式鲁棒优化(DRO)公式，将其应用于图像分类器中可以使其对随机和对抗性攻击具有鲁棒性。在MNIST和CIFAR-10数据集上，相较于基准方法，采用新颖的随机训练方法，测试错误率减少高达83.5％，损失减少高达91.3％。 |
| [^121] | [Using Graph Algorithms to Pretrain Graph Completion Transformers.](http://arxiv.org/abs/2210.07453) | 该论文研究了使用多种图算法构建的预训练任务，探索了图结构生成预训练任务，并提出了一种新的路径查找算法用于下游的知识图谱完成任务，该方法表现最佳。 |
| [^122] | [A New Family of Generalization Bounds Using Samplewise Evaluated CMI.](http://arxiv.org/abs/2210.06422) | 本文提出了一类新的信息论泛化界限，通过逐个样本评估的条件互信息，限制联合凸函数上界，与先前的界限相比在某些情况下更紧密地刻画了深度神经网络的总体损失。 |
| [^123] | [Machine learning and invariant theory.](http://arxiv.org/abs/2209.14991) | 本文介绍了等变机器学习，其中函数将与某个群作用相关，使用不可约表示或不变量理论来参数化这些函数的空间。 Malgrange的一般过程用来表达群$G$作用下所有多项式映射。 |
| [^124] | [On the Convergence of AdaGrad on $\R^{d}$: Beyond Convexity, Non-Asymptotic Rate and Acceleration.](http://arxiv.org/abs/2209.14827) | 本论文主要展示了AdaGrad在平滑凸函数和更一般的quasar凸函数的情况下的收敛性。具体地，我们提出了新的技术，明确限定了vanilla AdaGrad在无约束问题中的收敛速率，并提出了一种AdaGrad变种，可以实现更快的收敛。 |
| [^125] | [An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation.](http://arxiv.org/abs/2209.14627) | 本文提出了一种平衡约束的等大小硬EM算法，用于训练多解码器模型以实现多样的对话生成，可在小型模型中生成高质量的多样化响应。 |
| [^126] | [All are Worth Words: A ViT Backbone for Diffusion Models.](http://arxiv.org/abs/2209.12152) | 本文提出了一种适用于扩散模型的ViT骨干网络U-ViT，用于图像生成任务，相较于传统基于CNN的U-Net模型，U-ViT具有可比甚至更好的性能，甚至在某些任务中创造了新的FID分数记录。 |
| [^127] | [Accelerating Neural Network Inference with Processing-in-DRAM: From the Edge to the Cloud.](http://arxiv.org/abs/2209.08938) | 该论文讨论了基于DRAM的内存中处理（PIM）方法加速神经网络推理的可行性。通过分析三种最先进的PIM架构，得出PIM极大地有利于内存受限的NN的结论。 |
| [^128] | [Learning to Exploit Elastic Actuators for Quadruped Locomotion.](http://arxiv.org/abs/2209.07171) | 本文提出了一种直接在真实机器人上学习无模型控制器的方法，利用弹性执行器的动力学性质优化动态运动控制，学习到的控制器可实现高性能的四足运动控制。 |
| [^129] | [Risk-aware linear bandits with convex loss.](http://arxiv.org/abs/2209.07154) | 本论文研究了带上下文的风险感知线性赌博机问题，提出了一种用于估计风险度量的置信序列，并提出了一种乐观的UCB算法以学习最佳的风险感知行为。 |
| [^130] | [On Generalization of Decentralized Learning with Separable Data.](http://arxiv.org/abs/2209.07116) | 本文研究了梯度下降分布式学习在分离数据上的广义性质，并推导出新颖的有限时间广义性能界限，这对于当前仅限于集中式学习场景下的研究有所补充。 |
| [^131] | [An Improved Algorithm For Online Min-Sum Set Cover.](http://arxiv.org/abs/2209.04870) | 本论文提出了一种改进的在线最小和集覆盖算法，其算法能够在不知道未来集合的前提下重新排序元素，以至于列表前的至少一个元素能够匹配上流中的某个元素，同时算法的表现也优于以往的算法。 |
| [^132] | [Lossy Image Compression with Quantized Hierarchical VAEs.](http://arxiv.org/abs/2208.13056) | 该论文提出了一种量化分层VAE模型，通过重新设计潜在变量模型，让模型在测试时能够容易地进行量化和熵编码，该模型通过粗糙到精细的方式压缩图像，支持并行编解码，在自然图像有损压缩上表现优异。 |
| [^133] | [Measuring incompatibility and clustering quantum observables with a quantum switch.](http://arxiv.org/abs/2208.06210) | 本研究提出了一种量子不相容性测量指标“共同本征空间干扰”，并进一步通过量子开关实现量化，方便量子机器学习任务的处理。同时，算法可以对测量结果进行聚类，确定共享相似测量环境的观察者组。 |
| [^134] | [AI-driven Hypergraph Network of Organic Chemistry: Network Statistics and Applications in Reaction Classification.](http://arxiv.org/abs/2208.01647) | 本文通过将化学反应表示为超图，构建了基于AI的有机化学超图网络并进行了统计研究，为反应分类提供了新思路。 |
| [^135] | [Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning.](http://arxiv.org/abs/2206.15387) | 该论文研究了在联邦学习中从预训练模型开始的影响，证明这种方法可以减少训练时间并提高模型的准确性。 |
| [^136] | [On the Convergence of Distributed Stochastic Bilevel Optimization Algorithms over a Network.](http://arxiv.org/abs/2206.15025) | 本论文提出了两种新型分散式随机双层优化算法，在网络中解决了分布式数据的问题，并初步证明了其在非凸强凸问题方面的收敛速度。实验结果表明，算法是有效的。 |
| [^137] | [Data Augmentation techniques in time series domain: A survey and taxonomy.](http://arxiv.org/abs/2206.13508) | 本综述介绍了基于时间序列数据增强技术的最新进展，并提出了一个分类法，旨在提高训练深度神经网络的数据集的大小和一致性，从而提高模型的效率和性能。 |
| [^138] | [FEATHERS: Federated Architecture and Hyperparameter Search.](http://arxiv.org/abs/2206.12342) | 介绍了一种名为FEATHERS的方法，它使用差分隐私保护数据隐私，可以联合优化在分布式数据设置中的神经结构和超参数，具有高效率和良好的收敛性能。 |
| [^139] | [FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks.](http://arxiv.org/abs/2206.06561) | 本文提出了一种称为FreeKD的自由方向知识蒸馏框架，通过强化学习针对图神经网络构建两个较浅的GNN，使其在它们之间交换知识，无需提供深度优化的教师GNN，并且采用动态和自由方向的知识转移策略。 |
| [^140] | [Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation.](http://arxiv.org/abs/2206.05751) | 本文提出了一种Consistent Attack的方法用于生成视觉导航中的普适性对抗扰动，在考虑系统动态的同时优化对抗扰动，实验结果表明该方法优于基线UAP方法且表现最先进。 |
| [^141] | [Optimal Activation Functions for the Random Features Regression Model.](http://arxiv.org/abs/2206.01332) | 本文确定了随机特征回归模型的最佳激活函数。这些函数可能是线性的、饱和线性函数或基于Hermite多项式的函数。使用最佳激活函数会影响RFR模型的重要特性，如双峰曲线和最佳正则化参数与噪声水平的相关性。 |
| [^142] | [itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection.](http://arxiv.org/abs/2205.15531) | 提出了基于交换传递的知识蒸馏框架，用于3D物体检测，同时考虑准确性和计算效率，具有压缩表示损失和头部注意力损失等优化手段。 |
| [^143] | [Counterfactual Analysis in Dynamic Latent State Models.](http://arxiv.org/abs/2205.13832) | 该论文提供了一个框架来解决带有隐藏状态的动态模型的反事实分析问题，并在乳腺癌案例研究中成功应用。通过优化方法得到了反事实量的上限和下限，并且该论文是第一个在动态潜在状态模型中进行这种计算的研究。 |
| [^144] | [Consistent and fast inference in compartmental models of epidemics using Poisson Approximate Likelihoods.](http://arxiv.org/abs/2205.13602) | 引入泊松近似似然(PAL)方法，与ODE方法不同，PAL是从有限人口数量的随机分区模型的近似滤波方程导出的，并且大人口数量限制推动最大PAL估计量的一致性。 |
| [^145] | [Explanatory machine learning for sequential human teaching.](http://arxiv.org/abs/2205.10250) | 本文研究了顺序问题解决中，课程顺序和机器学习解释对人类理解力的影响。 |
| [^146] | [A Rule Search Framework for the Early Identification of Chronic Emergency Homeless Shelter Clients.](http://arxiv.org/abs/2205.09883) | 本研究使用规则搜索技术，早期识别有可能成为长期或慢性无家可归者收容所的高风险人群。在实时交付支持性住房计划的框架内，应用本文方法使得早期识别处于慢性无家可归者风险的客户的中位时间从297天降至162天。 |
| [^147] | [FedGiA: An Efficient Hybrid Algorithm for Federated Learning.](http://arxiv.org/abs/2205.01438) | FedGiA是一种高效的混合式联邦学习算法，能够更有效地节省通信和计算资源，并在温和条件下实现全局收敛。 |
| [^148] | [CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks.](http://arxiv.org/abs/2204.10965) | CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。 |
| [^149] | [CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval.](http://arxiv.org/abs/2204.10779) | 本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。 |
| [^150] | [CGC: Contrastive Graph Clustering for Community Detection and Tracking.](http://arxiv.org/abs/2204.08504) | 本文提出了一种全新的图聚类算法CGC，采用对比学习进行自监督表示学习，结合跟踪模块以应对动态图拓扑变化，在社区发现和跟踪方面表现出领先的状态。 |
| [^151] | [PARC: Physics-Aware Recurrent Convolutional Neural Networks to Assimilate Meso-scale Reactive Mechanics of Energetic Materials.](http://arxiv.org/abs/2204.07234) | 提出了一种物理感知循环卷积神经网络(PARC)，可从数值模拟中学习介观尺度下的热力学和力学响应，预测受冲击的能量材料的热力学反应，具有准确性高，计算时间短的特点。 |
| [^152] | [Physics-/Model-Based and Data-Driven Methods for Low-Dose Computed Tomography: A survey.](http://arxiv.org/abs/2203.15725) | 本文系统回顾了基于物理/模型的数据驱动方法在LDCT中的应用，提出了将物理/模型与深度学习结合起来的新兴趋势。 |
| [^153] | [A survey on GANs for computer vision: Recent research, analysis and taxonomy.](http://arxiv.org/abs/2203.11242) | 本文综述了GAN的最新架构、损失函数优化、验证指标和应用领域，并提出了一个分类法以更好地理解计算机视觉中GAN的现状。 |
| [^154] | [Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection.](http://arxiv.org/abs/2203.02194) | 本文重新考虑了基于重构自编码器方法的外样本检测，在最大压缩自编码器的潜空间和保证重构能力的基础上，通过引入语义重构、数据确定性分解和标准化L2距离等策略，本文提出的方法在各个基准测试中都取得了最先进的性能表现，且不需要额外的标记外样本数据。 |
| [^155] | [An Information-Theoretic Framework for Supervised Learning.](http://arxiv.org/abs/2203.00246) | 本文提出了一种信息论框架，分析机器学习的数据需求，研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度，提出了样本复杂度边界。 |
| [^156] | [Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits.](http://arxiv.org/abs/2202.13603) | 论文提出了一种具有随机噪声的在线广义线性回归问题的最优解，获得了接近最优的遗憾上限。同时，针对具有异方差噪声的广义线性Bandits问题，提出了一种基于FTRL的算法实现第一个方差感知的遗憾上限。 |
| [^157] | [PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX.](http://arxiv.org/abs/2202.04110) | PGMax是一个用于离散概率图模型的因子图工具，可以在JAX中自动运行高效且可扩展的循环置信传播，与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。 |
| [^158] | [Discrete-Event Controller Synthesis for Autonomous Systems with Deep-Learning Perception Components.](http://arxiv.org/abs/2202.03360) | 本文提出了一种名为DeepDECS的新方法，用于为使用深度神经网络分类器作为决策过程的感知步骤的自主系统合成构建正确的离散事件控制器。模型能够保证满足自主系统的安全性、可靠性和性能要求，并与一组优化目标的Pareto最优相对应。 |
| [^159] | [Anticorrelated Noise Injection for Improved Generalization.](http://arxiv.org/abs/2202.02831) | 本文发现，在一些目标函数中，抗相关噪声的梯度下降方法比传统的梯度下降和常规扰动梯度下降有更好的泛化性能。理论分析证明了这是因为 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。 |
| [^160] | [PROMPT: Learning Dynamic Resource Allocation Policies for Network Applications.](http://arxiv.org/abs/2201.07916) | PROMPT是一个使用强化学习控制器和主动QoS预测的资源分配框架，可以实现更精确的资源优化，在处理短暂波动方面更加稳定，并且在调度新的最佳努力工作负载时具有更强的鲁棒性。 |
| [^161] | [Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders.](http://arxiv.org/abs/2201.07513) | 本文针对未受监督编码器面临的盗窃攻击漏洞，提出了基于对比学习的新型攻击方法 Cont-Steal，以更好地利用编码器的丰富特征。 |
| [^162] | [FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps.](http://arxiv.org/abs/2111.09445) | 本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。 |
| [^163] | [Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers.](http://arxiv.org/abs/2109.12772) | 本研究提出了一种适用于多类逻辑回归的分布鲁棒优化方法，在深度图像分类器中得到了应用。这种方法可使图像分类器对随机和对抗攻击具有鲁棒性。在使用MNIST和CIFAR-10数据集时，相比于基准方法，通过采用新的随机训练方法，测试错误率的降低高达83.5%，损失降低高达91.3%。 |
| [^164] | [Measuring Fairness Under Unawareness of Sensitive Attributes: A Quantification-Based Approach.](http://arxiv.org/abs/2109.08549) | 本论文提出了一种基于量化的方法，用于在不知道模型的敏感属性的情况下，评估模型对不同群体的公平性。 |
| [^165] | [Variance Reduction for Matrix Computations with Applications to Gaussian Processes.](http://arxiv.org/abs/2106.14565) | 本文提出了一种通过矩阵分解来进行矩阵计算的方差缩减方法，并展示了在某些问题上可以实现任意更好的随机性能。此外，本文提出的矩阵乘积迹的分解估计器与对半正定矩阵行列式的对数估计器均有显著的效率提高，可以在实际的贝叶斯优化问题中得到应用。 |
| [^166] | [Scene Uncertainty and the Wellington Posterior of Deterministic Image Classifiers.](http://arxiv.org/abs/2106.13870) | 本文提出了一种方法来估计确定性图像分类器在给定输入数据上结果的不确定性，定义了惠灵顿后验作为分布以表明可能由生成给定图像的相同场景生成的数据的响应。 |
| [^167] | [FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users.](http://arxiv.org/abs/2106.08946) | FGLP是一个联邦学习框架和预测模型组成的系统，将智能手机上收集的GPS轨迹抽象为2D空间中的相对点，合并了BiLSTM和CNN以捕获时间和空间模式，实现了8米的预测精度，且数据发送开销降低了两个数量级。 |
| [^168] | [Kernel Two-Sample Tests for Manifold Data.](http://arxiv.org/abs/2105.03425) | 本文研究了与最大均值差异（MMD）相关的基于核的双样本检验统计量在测量流形数据时的应用。文章展示了检验水平和功率与核带宽、样本数量和流形内在维度之间的关系，并在特定条件下建立了测试功率下界。 |
| [^169] | [Causality-based Counterfactual Explanation for Classification Models.](http://arxiv.org/abs/2105.00703) | 本论文提出了一种基于因果关系的反事实解释方法，可同时处理连续和分类变量，生成的样本具有实用性指导意义，在实验中表现出更好的性能。 |
| [^170] | [A hybrid ensemble method with negative correlation learning for regression.](http://arxiv.org/abs/2104.02317) | 该论文提出了一种带有负相关学习的混合集成算法，通过自动选择和加权子模型来解决在回归任务中模型不确定性问题，并在实验中表现出较好的性能。 |
| [^171] | [A Practical Survey on Faster and Lighter Transformers.](http://arxiv.org/abs/2103.14636) | Transformer虽然在许多序列建模任务中取得了很好的效果，但其复杂度与序列长度相关。近期，研究人员设计了类似于Longformer的解决方案来直接解决Transformer的限制，从而提高了其效率。 |
| [^172] | [Exploiting Shared Representations for Personalized Federated Learning.](http://arxiv.org/abs/2102.07078) | 该论文提出了一种新的联邦学习框架和算法，用于在客户端之间共享数据表示和各自本地拟合，该方法能够线性收敛到真实值。 |
| [^173] | [A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit.](http://arxiv.org/abs/2011.14033) | 本文提供了一个新颖的、不需要调整指数参数的MNL-Contextual Bandit问题的简便在线学习算法。算法具有与该问题的最佳理论界限匹配的遗憾上界。 |
| [^174] | [DeepTopPush: Simple and Scalable Method for Accuracy at the Top.](http://arxiv.org/abs/2006.12293) | DeepTopPush是一种用于解决Accuracy at the Top问题的简单而可扩展的方法，能有效地选择少量重要的样本，并在不同领域取得了优异的性能表现 |
| [^175] | [Utilizing Network Properties to Detect Erroneous Inputs.](http://arxiv.org/abs/2002.12520) | 本研究利用预训练神经网络的特征向量，训练线性SVM分类器，通过检测隐藏特征向量和softmax特征向量的线性可分性，来识别四种类型的错误数据，包括对抗攻击、损坏的、超出分布范围和误分类的示例。 |

# 详细

[^1]: 解释约束下的学习

    Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])

    [http://arxiv.org/abs/2303.14496](http://arxiv.org/abs/2303.14496)

    本文研究了解释约束下的学习问题，提出了EPAC模型，探讨了使用这些解释时模型的益处，并提供了一种基于变分近似的算法解决方案。

    

    尽管监督学习假设存在标注数据，但我们可能有关于模型应如何运行的先验信息。本文将其形式化为从解释约束中学习，并提供了一个学习理论框架，分析了这些解释如何提高模型的学习能力。本文的第一项关键贡献是通过定义我们称之为EPAC模型（在新数据期望中满足这些约束的模型）来回答哪些模型会受益于解释这一问题。我们使用标准的学习理论工具分析了这类模型。第二个关键贡献是对于由线性模型和两层神经网络的梯度信息给出的规范解释的限制（以其Rademacher复杂度为衡量标准）进行了表征。最后，我们通过一种变分近似提供了我们的框架的算法解决方案，它能够实现更好的性能并满足这些约束。

    While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
    
[^2]: 面向城市计算的时空图神经网络预测学习综述

    Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban Computing: A Survey. (arXiv:2303.14483v1 [cs.LG])

    [http://arxiv.org/abs/2303.14483](http://arxiv.org/abs/2303.14483)

    本综述介绍了面向城市计算的时空图神经网络预测学习领域的发展现状，包括其框架、实现方法和应用场景，以及当前的研究热点和挑战，提出了该领域未来的发展方向和应用前景。

    

    随着先进传感器和大型数据库技术的发展，越来越多的城市系统时空数据被记录和存储。这些数据的演化模式的预测学习是城市计算中基本但重要的循环，可以更好地支持城市智能管理决策，特别是在交通、环境、安全、公共卫生等领域。由于传统的统计学习和深度学习方法很难捕捉城市时空数据的复杂相关性，近年来提出了时空图神经网络（STGNN）的框架。STGNN通过集成图神经网络（GNN）和各种时间学习方法实现了复杂时空依赖关系的提取。然而，对于不同的预测学习任务，有效设计空间依赖学习模块、时间依赖学习模块、以及它们之间相互作用的方法仍然具有挑战性。

    With the development of sophisticated sensors and large database technologies, more and more spatio-temporal data in urban systems are recorded and stored. Predictive learning for the evolution patterns of these spatio-temporal data is a basic but important loop in urban computing, which can better support urban intelligent management decisions, especially in the fields of transportation, environment, security, public health, etc. Since traditional statistical learning and deep learning methods can hardly capture the complex correlations in the urban spatio-temporal data, the framework of spatio-temporal graph neural network (STGNN) has been proposed in recent years. STGNNs enable the extraction of complex spatio-temporal dependencies by integrating graph neural networks (GNNs) and various temporal learning methods. However, for different predictive learning tasks, it is a challenging problem to effectively design the spatial dependencies learning modules, temporal dependencies learnin
    
[^3]: 信息学习、中心性、卷积神经网络、相关文献检测、土著人类遗骸归还

    Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains. (arXiv:2303.14475v1 [cs.CL])

    [http://arxiv.org/abs/2303.14475](http://arxiv.org/abs/2303.14475)

    本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。

    

    澳大利亚和其他原住民面临的紧迫问题之一是将他们祖先的尸体遗骸归还到西方科学机构。成功将这些遗骸返还到其社区以重新安葬，主要取决于在1790年至1970年期间发表的科学和其他文献中找到记录它们被盗窃、捐赠、出售或在机构之间交换的信息。本文报道了由数据科学家和社会科学研究人员在“研究、和解、更新”网络（RRR）中进行的协作研究，以开发和应用文本挖掘技术来确定这些关键信息。我们描述了我们迄今为止开发基于机器学习的解决方案以自动化查找和语义分析相关文本的工作。分类模型，特别是基于深度学习的模型，在使用少量标记数据进行训练时精度低。

    Among the pressing issues facing Australian and other First Nations peoples is the repatriation of the bodily remains of their ancestors, which are currently held in Western scientific institutions. The success of securing the return of these remains to their communities for reburial depends largely on locating information within scientific and other literature published between 1790 and 1970 documenting their theft, donation, sale, or exchange between institutions. This article reports on collaborative research by data scientists and social science researchers in the Research, Reconcile, Renew Network (RRR) to develop and apply text mining techniques to identify this vital information. We describe our work to date on developing a machine learning-based solution to automate the process of finding and semantically analysing relevant texts. Classification models, particularly deep learning-based models, are known to have low accuracy when trained with small amounts of labelled (i.e. rele
    
[^4]: 3Mformer: 多阶多模变形器用于骨骼动作识别

    3Mformer: Multi-order Multi-mode Transformer for Skeletal Action Recognition. (arXiv:2303.14474v1 [cs.CV])

    [http://arxiv.org/abs/2303.14474](http://arxiv.org/abs/2303.14474)

    3Mformer是一种多阶多模变形器，通过形成超图捕捉身体关节组的高阶运动模式，使得在骨骼动作识别方面表现优于现有最先进的模型

    

    许多骨骼动作识别模型使用GCN通过连接的3D人体关节代表人体。GCNs聚合一到少量跳跃图邻域，并忽略未连接身体关节之间的依赖关系。我们提出形成超图来模拟图节点之间的超边（例如，第三和第四阶超边捕获三个和四个节点），这有助于捕获身体关节组的高阶运动模式。我们将动作序列分成时间块，Higher-order Transformer (HoT)基于（i）身体关节，（ii）身体关节的成对链接和（iii）骨架身体关节的高阶超边，产生每个时间块的嵌入。我们通过新型Multi-order Multi-mode Transformer(3Mformer)结合这些超级边的HoT嵌入，其中两个模块的顺序可以交换，以实现基于'channel-temporal block'，'order-channel-body joint'，'channel-hyper-edge-order'的耦合模式令牌上的耦合模式注意力。实验结果表明，3Mformer在三个基准数据集上优于现有最先进的模型。

    Many skeletal action recognition models use GCNs to represent the human body by 3D body joints connected body parts. GCNs aggregate one- or few-hop graph neighbourhoods, and ignore the dependency between not linked body joints. We propose to form hypergraph to model hyper-edges between graph nodes (e.g., third- and fourth-order hyper-edges capture three and four nodes) which help capture higher-order motion patterns of groups of body joints. We split action sequences into temporal blocks, Higher-order Transformer (HoT) produces embeddings of each temporal block based on (i) the body joints, (ii) pairwise links of body joints and (iii) higher-order hyper-edges of skeleton body joints. We combine such HoT embeddings of hyper-edges of orders 1, ..., r by a novel Multi-order Multi-mode Transformer (3Mformer) with two modules whose order can be exchanged to achieve coupled-mode attention on coupled-mode tokens based on 'channel-temporal block', 'order-channel-body joint', 'channel-hyper-edg
    
[^5]: 自回归条件神经过程

    Autoregressive Conditional Neural Processes. (arXiv:2303.14468v1 [stat.ML])

    [http://arxiv.org/abs/2303.14468](http://arxiv.org/abs/2303.14468)

    本论文提出了自回归条件神经过程模型，能够建模高度相关的非高斯预测分布。

    

    有条件的神经过程是一种有吸引力元学习模型，能够产生良好校准的预测，并且可以通过简单的最大似然过程进行训练。本研究提出了一种改变有条件的神经过程在测试时部署方式的方法，从而能够建模高度相关的非高斯预测分布。

    Conditional neural processes (CNPs; Garnelo et al., 2018a) are attractive meta-learning models which produce well-calibrated predictions and are trainable via a simple maximum likelihood procedure. Although CNPs have many advantages, they are unable to model dependencies in their predictions. Various works propose solutions to this, but these come at the cost of either requiring approximate inference or being limited to Gaussian predictions. In this work, we instead propose to change how CNPs are deployed at test time, without any modifications to the model or training procedure. Instead of making predictions independently for every target point, we autoregressively define a joint predictive distribution using the chain rule of probability, taking inspiration from the neural autoregressive density estimator (NADE) literature. We show that this simple procedure allows factorised Gaussian CNPs to model highly dependent, non-Gaussian predictive distributions. Perhaps surprisingly, in an e
    
[^6]: Tsetlin机器的性质验证

    Verifying Properties of Tsetlin Machines. (arXiv:2303.14464v1 [cs.LG])

    [http://arxiv.org/abs/2303.14464](http://arxiv.org/abs/2303.14464)

    该论文介绍了一种对Tsetlin Machine进行正式验证性质的方法，并展示了对抗性鲁棒性、等价性和相似性方面的结果。此外，还将新的模型相似性概念应用于TsMs。

    

    Tsetlin机器（TsMs）是一种有前途且易于解释的机器学习方法，可应用于各种分类任务。我们将TsMs精确编码为命题逻辑并使用SAT求解器正式验证了TsMs的性质。特别地，在这项工作中，我们引入了一种机器学习模型相似性的概念，并将我们的概念应用于检查TsMs的相似性。我们还考虑了文献中的鲁棒性和等价性概念，并为TsMs重新调整了它们。然后，我们展示了我们编码的正确性，并为TsMs的性质——对抗鲁棒性，等价性和相似性提供结果。在我们的实验中，我们分别应用MNIST和IMDB数据集进行图像和情感分类。我们将使用TsMs检查对抗性鲁棒性的结果与文献中在MNIST上使用二进制神经网络获得的结果进行讨论。

    Tsetlin Machines (TsMs) are a promising and interpretable machine learning method which can be applied for various classification tasks. We present an exact encoding of TsMs into propositional logic and formally verify properties of TsMs using a SAT solver. In particular, we introduce in this work a notion of similarity of machine learning models and apply our notion to check for similarity of TsMs. We also consider notions of robustness and equivalence from the literature and adapt them for TsMs. Then, we show the correctness of our encoding and provide results for the properties: adversarial robustness, equivalence, and similarity of TsMs. In our experiments, we employ the MNIST and IMDB datasets for (respectively) image and sentiment classification. We discuss the results for verifying robustness obtained with TsMs with those in the literature obtained with Binarized Neural Networks on MNIST.
    
[^7]: CFA: 类别间校准的公平对抗训练

    CFA: Class-wise Calibrated Fair Adversarial Training. (arXiv:2303.14460v1 [cs.LG])

    [http://arxiv.org/abs/2303.14460](http://arxiv.org/abs/2303.14460)

    本文提出了CFA框架，针对每个类别自动定制特定的对抗训练配置，提高了DNN对抗训练的公平性，同时不影响总体的对抗鲁棒性。

    

    对抗训练已经被广泛认为是提高深度神经网络对抗性鲁棒性最有效的方法。迄今为止，大多数现有工作都集中在增强整个模型的鲁棒性上，在训练和测试阶段同等对待每个类别。虽然揭示了类别间鲁棒性的差异，但很少有工作在不牺牲总体鲁棒性的情况下，在类别级别上使对抗训练公平。本文是第一个在理论和经验上研究不同类别对对抗性配置喜好的，包括扰动幅度、正则化和权重平均值等。在此基础上，我们进一步提出了一个名为CFA的类别间校准的公平对抗训练框架，它可以自动定制每个类别的特定训练配置。对基准数据集上的实验表明，我们提出的CFA可以提高DNNs的对抗训练公平性，而不牺牲总体的对抗鲁棒性。

    Adversarial training has been widely acknowledged as the most effective method to improve the adversarial robustness against adversarial examples for Deep Neural Networks (DNNs). So far, most existing works focus on enhancing the overall model robustness, treating each class equally in both the training and testing phases. Although revealing the disparity in robustness among classes, few works try to make adversarial training fair at the class level without sacrificing overall robustness. In this paper, we are the first to theoretically and empirically investigate the preference of different classes for adversarial configurations, including perturbation margin, regularization, and weight averaging. Motivated by this, we further propose a \textbf{C}lass-wise calibrated \textbf{F}air \textbf{A}dversarial training framework, named CFA, which customizes specific training configurations for each class automatically. Experiments on benchmark datasets demonstrate that our proposed CFA can imp
    
[^8]: 无全标签的联邦学习综述

    Federated Learning without Full Labels: A Survey. (arXiv:2303.14453v1 [cs.LG])

    [http://arxiv.org/abs/2303.14453](http://arxiv.org/abs/2303.14453)

    本文综述了如何在联邦学习过程中利用无标注数据解决无全标签问题，并介绍了半监督学习、自监督学习和迁移学习等方法。同时还总结了用于评估这些方法的数据集和它们各自的优缺点。

    

    数据隐私已成为实际大数据应用中机器学习越来越重要的考虑因素。为解决这一问题，联邦学习成为了可行的解决方案，可以利用分散且隐私的数据构建有效的机器学习模型。现有的联邦学习算法主要解决监督学习问题，这要求数据必须是全标签的。但实际上，完全标记数据往往难以获得，因为参与者可能缺乏足够的领域专业知识，或者缺乏标记数据的动机和工具。因此，在现实世界的联邦学习应用中，无全标签联邦学习问题非常重要。本文讨论了如何利用无标注数据的机器学习技术来解决此问题。我们对将联邦学习与半监督学习、自监督学习和迁移学习方法相结合的方法进行了综述。我们还总结了用于评估这些方法的数据集，并分析了它们的优点和局限性。

    Data privacy has become an increasingly important concern in real-world big data applications such as machine learning. To address the problem, federated learning (FL) has been a promising solution to building effective machine learning models from decentralized and private data. Existing federated learning algorithms mainly tackle the supervised learning problem, where data are assumed to be fully labeled. However, in practice, fully labeled data is often hard to obtain, as the participants may not have sufficient domain expertise, or they lack the motivation and tools to label data. Therefore, the problem of federated learning without full labels is important in real-world FL applications. In this paper, we discuss how the problem can be solved with machine learning techniques that leverage unlabeled data. We present a survey of methods that combine FL with semi-supervised learning, self-supervised learning, and transfer learning methods. We also summarize the datasets used to evalua
    
[^9]: 通过对抗性学习破解自动论文审稿人分配

    No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning. (arXiv:2303.14443v1 [cs.CR])

    [http://arxiv.org/abs/2303.14443](http://arxiv.org/abs/2303.14443)

    本文通过对抗性学习破解了自动论文审稿人分配系统，实现了对论文的不明显更改，进而可以成功选择和删除审稿人，攻击成功率达80％以上。

    

    许多学科的学术会议所提交的论文数量逐渐增加，为了处理这种增长，在审查过程中越来越多地使用自动论文审稿人分配系统。这些系统使用统计主题模型来表征提交内容，并自动分配给审稿人。本文表明，这种自动化可以通过对抗性学习进行操作。我们提出了一种攻击，使特定论文可以误导评审并选择自己的评审人。我们的攻击基于一种新的优化策略，交替使用特征空间和问题空间来实现对论文的不明显更改。为了评估我们的攻击的可行性，我们模拟了一个真实的安全会议（IEEE S&P）的论文审稿人分配，其中有165名审稿人在项目委员会审核。我们的结果表明，我们可以成功选择并删除审稿人，而无需访问分配系统的参数，并且我们的攻击可以在保持不被发现的情况下实现超过80％的成功率。

    The number of papers submitted to academic conferences is steadily rising in many scientific disciplines. To handle this growth, systems for automatic paper-reviewer assignments are increasingly used during the reviewing process. These systems use statistical topic models to characterize the content of submissions and automate the assignment to reviewers. In this paper, we show that this automation can be manipulated using adversarial learning. We propose an attack that adapts a given paper so that it misleads the assignment and selects its own reviewers. Our attack is based on a novel optimization strategy that alternates between the feature space and problem space to realize unobtrusive changes to the paper. To evaluate the feasibility of our attack, we simulate the paper-reviewer assignment of an actual security conference (IEEE S&P) with 165 reviewers on the program committee. Our results show that we can successfully select and remove reviewers without access to the assignment sys
    
[^10]: 半局域机器学习势的热通量

    Heat flux for semi-local machine-learning potentials. (arXiv:2303.14434v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2303.14434](http://arxiv.org/abs/2303.14434)

    本文中介绍了如何将Green-Kubo方法应用于半局域机器学习势，使用自动微分推导出适应的热通量公式，成功计算了二氧化锆的热导率。

    

    Green-Kubo (GK)方法是材料热传输模拟的严格框架，但它需要准确描述势能表面且收敛统计量。机器学习势可以达到第一性原理模拟的准确性，同时可以在一小部分成本内超越其模拟时间和长度尺度。在本文中，我们解释了如何将GK方法应用于最近的消息传递机器学习势类，该方法迭代地考虑初始交互截断以外的半局域交互。我们推导出一个适应的热通量公式，可以使用自动微分实现，而不会影响计算效率。该方法通过计算二氧化锆的热导率验证和验证。

    The Green-Kubo (GK) method is a rigorous framework for heat transport simulations in materials. However, it requires an accurate description of the potential-energy surface and carefully converged statistics. Machine-learning potentials can achieve the accuracy of first-principles simulations while allowing to reach well beyond their simulation time and length scales at a fraction of the cost. In this paper, we explain how to apply the GK approach to the recent class of message-passing machine-learning potentials, which iteratively consider semi-local interactions beyond the initial interaction cutoff. We derive an adapted heat flux formulation that can be implemented using automatic differentiation without compromising computational efficiency. The approach is demonstrated and validated by calculating the thermal conductivity of zirconium dioxide across temperatures.
    
[^11]: 基于对比学习的现实数据池假设下的深度主动学习

    Deep Active Learning with Contrastive Learning Under Realistic Data Pool Assumptions. (arXiv:2303.14433v1 [cs.CV])

    [http://arxiv.org/abs/2303.14433](http://arxiv.org/abs/2303.14433)

    该论文提出了一种适用于现实数据池的、基于对比学习的深度主动学习方法，并且引入了包括模糊的、与任务无关的分布外样本以及分布内样本的新的主动学习基准。

    

    主动学习旨在从未标记的数据池中识别出最具信息量的数据，从而使模型快速达到所需的准确性。这对于通常需要大量标记样本才能达到高性能的深度神经网络尤为有益。大多数现有的主动学习方法在一个理想的设置中进行评估，在这个设置中，只有与目标任务相关的样本，即分布内样本，存在于未标记的数据池中。然而，从野外收集的数据池很可能包含完全与目标任务无关的样本和/或对于甚至对于神谕来说都无法分配单个类标签的过于模糊的样本。我们认为假设一个未标记的数据池包含来自各种分布的样本更加现实。在本文中，我们引入了包括模糊的、与任务无关的分布外样本以及分布内样本的新的主动学习基准。我们还提出了一种旨在获取权威信息的主动学习方法。

    Active learning aims to identify the most informative data from an unlabeled data pool that enables a model to reach the desired accuracy rapidly. This benefits especially deep neural networks which generally require a huge number of labeled samples to achieve high performance. Most existing active learning methods have been evaluated in an ideal setting where only samples relevant to the target task, i.e., in-distribution samples, exist in an unlabeled data pool. A data pool gathered from the wild, however, is likely to include samples that are irrelevant to the target task at all and/or too ambiguous to assign a single class label even for the oracle. We argue that assuming an unlabeled data pool consisting of samples from various distributions is more realistic. In this work, we introduce new active learning benchmarks that include ambiguous, task-irrelevant out-of-distribution as well as in-distribution samples. We also propose an active learning method designed to acquire informat
    
[^12]: Beta-VAE有两种表现形式：PCA或ICA？

    Beta-VAE has 2 Behaviors: PCA or ICA?. (arXiv:2303.14430v1 [cs.LG])

    [http://arxiv.org/abs/2303.14430](http://arxiv.org/abs/2303.14430)

    Beta-VAE模型的表示学习效果受潜在变量总量影响：使用少量潜在变量时表现为PCA，使用大量潜在变量时表现为ICA。

    

    Beta-VAE是一种非常经典的解缠表示学习模型，扩展瓶颈的使用可使信息逐渐进入解码器，这是表示解缠以及高质量重建的关键。在最近对这种迷人结构进行的实验中，我们发现潜在变量的总量可以影响网络学习到的表示：使用非常少的潜在变量时，网络倾向于学习最重要或主要的变量，表现得像一个PCA; 使用非常大量的潜在变量时，变量倾向于更加解缠，表现出类似ICA的特点。我们的假设是潜在变量之间为获取最大信息带宽而进行的竞争可能导致这一现象。

    Beta-VAE is a very classical model for disentangled representation learning, the use of an expanding bottleneck that allow information into the decoder gradually is key to representation disentanglement as well as high-quality reconstruction. During recent experiments on such fascinating structure, we discovered that the total amount of latent variables can affect the representation learnt by the network: with very few latent variables, the network tend to learn the most important or principal variables, acting like a PCA; with very large numbers of latent variables, the variables tend to be more disentangled, and act like an ICA. Our assumption is that the competition between latent variables while trying to gain the most information bandwidth can lead to this phenomenon.
    
[^13]: 基于任务关注变换器架构的知识蒸馏连续学习视觉语言任务

    Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation. (arXiv:2303.14423v1 [cs.LG])

    [http://arxiv.org/abs/2303.14423](http://arxiv.org/abs/2303.14423)

    本文提出一种基于变换器的连续学习架构，用于学习双模态的视觉语言任务，并采用动态增加参数和知识蒸馏的方法，实现在多任务学习中共享信息和解决灾难性遗忘的问题。该方法具有扩展性和高效性能。

    

    对于在许多应用中采用机器学习而言，预训练神经网络的规模和计算负载成为两个主要障碍。而连续学习 (CL) 可以作为一种补救措施，通过使顺序到达的任务之间进行知识转移，从而减轻了需要从头开始微调所有网络权重的需要。然而，现有的 CL 算法主要考虑学习单模态的仅视觉或仅语言任务。我们开发了一种基于变换器的 CL 架构，用于学习双模态的视觉语言任务，通过动态增加可学习参数的数量并使用知识蒸馏。新添加的参数用于为每个任务专门定制网络。我们的方法使任务之间可以共享信息，同时解决了灾难性遗忘的挑战。我们的方法可扩展到大量任务的学习，因为它需要很少的内存和时间开销。我们的模型达到了最先进的性能水平。

    The size and the computational load of fine-tuning large-scale pre-trained neural network are becoming two major obstacles in adopting machine learning in many applications. Continual learning (CL) can serve as a remedy through enabling knowledge-transfer across sequentially arriving tasks which relaxes the need to fine-tune all network weights from scratch. However, existing CL algorithms primarily consider learning unimodal vision-only or language-only tasks. We develop a transformer-based CL architecture for learning bimodal vision-and-language tasks based on increasing the number of the learnable parameters dynamically and using knowledge distillation. The new additional parameters are used to specialize the network for each task. Our approach enables sharing information between the tasks while addressing the challenge of catastrophic forgetting. Our approach is scalable learning to a large number of tasks because it requires little memory and time overhead. Our model reaches state
    
[^14]: 空间感知的共享汽车需求预测

    Spatially-Aware Car-Sharing Demand Prediction. (arXiv:2303.14421v1 [cs.LG])

    [http://arxiv.org/abs/2303.14421](http://arxiv.org/abs/2303.14421)

    本文提出了一种基于空间感知学习算法的方法来分析共享汽车站点的平均月度需求，利用了丰富的特征作为输入，可以提高预测性能。

    

    近年来，共享汽车服务作为私人个人出行的可行替代品出现，承诺更可持续、资源利用效率更高，但仍然等同于私人出行。关于短期预测和优化方法的研究已经改善了共享汽车服务的运营和车队控制;然而，在文献中长期预测和空间分析是缺乏的。我们建议使用具有空间感知学习算法的平均月度需求来分析基于站点的共享汽车服务，这种算法既具有高预测性能，又具有可解释性。具体而言，我们比较了全球随机森林模型与空间感知方法来预测平均每个站点的月度需求。该研究利用了丰富的社会-人口学、基于位置的(例如POI)和共享汽车特定特征作为输入，这些特征来自一个大型的专有共享汽车数据集和公开可用的数据集。我们展示了全球随机森林模型通常表现最好，但在某些情况下，空间感知方法可以提高预测性能。

    In recent years, car-sharing services have emerged as viable alternatives to private individual mobility, promising more sustainable and resource-efficient, but still comfortable transportation. Research on short-term prediction and optimization methods has improved operations and fleet control of car-sharing services; however, long-term projections and spatial analysis are sparse in the literature. We propose to analyze the average monthly demand in a station-based car-sharing service with spatially-aware learning algorithms that offer high predictive performance as well as interpretability. In particular, we compare the spatially-implicit Random Forest model with spatially-aware methods for predicting average monthly per-station demand. The study utilizes a rich set of socio-demographic, location-based (e.g., POIs), and car-sharing-specific features as input, extracted from a large proprietary car-sharing dataset and publicly available datasets. We show that the global Random Forest 
    
[^15]: 带变化的深度线性判别分析在多囊卵巢综合症分类中的应用

    Deep Linear Discriminant Analysis with Variation for Polycystic Ovary Syndrome Classification. (arXiv:2303.14401v1 [cs.LG])

    [http://arxiv.org/abs/2303.14401](http://arxiv.org/abs/2303.14401)

    本文介绍了基于 Deep LDA 的多囊卵巢综合症预测方案，采用带变化的深度线性判别分析算法，绕过简单机器学习算法利用图形处理器的限制，提高了诊断性能。

    

    多囊卵巢综合症诊断是一个可以利用预测学习程序来解决的问题。虽然机器学习的算法在多囊卵巢综合症的诊断方面被广泛使用，但是这些算法在利用图形处理器的处理能力方面存在一定的局限性。通过使用深度学习的先进框架，可以提高简单机器学习算法的性能。线性判别分析是一种用于分类的线性降维算法，可以通过使用深度学习的 Deep LDA 来提高其性能。本文介绍了基于 Deep LDA 的多囊卵巢综合症预测方案。

    The polycystic ovary syndrome diagnosis is a problem that can be leveraged using prognostication based learning procedures. Many implementations of PCOS can be seen with Machine Learning but the algorithms have certain limitations in utilizing the processing power graphical processing units. The simple machine learning algorithms can be improved with advanced frameworks using Deep Learning. The Linear Discriminant Analysis is a linear dimensionality reduction algorithm for classification that can be boosted in terms of performance using deep learning with Deep LDA, a transformed version of the traditional LDA. In this result oriented paper we present the Deep LDA implementation with a variation for prognostication of PCOS.
    
[^16]: IFSeg：基于视觉语言模型的无图像语义分割

    IFSeg: Image-free Semantic Segmentation via Vision-Language Model. (arXiv:2303.14396v1 [cs.CV])

    [http://arxiv.org/abs/2303.14396](http://arxiv.org/abs/2303.14396)

    IFSeg提出了一种全新的无图像分割任务，能够在没有特定图像和注释的情况下执行语义分割，实现了基于视觉语言模型的人工图像分割对更新，取得了在多个基准数据集上的最先进表现，对未知类别和噪声鲁棒性强。

    

    近年来，视觉语言（VL）预训练因其在不同视觉任务中的可转移性和灵活性（例如跨模态转移）而备受关注。然而，VL驱动的分割任务尚未得到充分探索，并且现有方法仍需要获取额外的训练图像甚至分割注释来适应下游分割任务。本文介绍了一种新颖的无图像分割任务，其目标是在只有一组目标语义类别的情况下执行语义分割，但不使用任何特定于任务的图像和注释。为了解决这一具有挑战性的任务，我们提出了一种新颖的方法IFSeg，通过生成基于VL的人工图像分割对来更新预训练的VL模型以适应分割任务。我们通过创建一个随机语义类别的2D地图以及另一个地图的相应单词标记来构造这些人造训练数据。由于预训练的VL模型可以将语义短语与其视觉表示相关联，因此我们可以使用它生成带有地面真实语义分割掩模的图像。我们的方法在多个基准数据集上实现了最先进的性能，并且证明了对未见过的类别和不同级别噪声的鲁棒性。

    Vision-language (VL) pre-training has recently gained much attention for its transferability and flexibility in novel concepts (e.g., cross-modality transfer) across various visual tasks. However, VL-driven segmentation has been under-explored, and the existing approaches still have the burden of acquiring additional training images or even segmentation annotations to adapt a VL model to downstream segmentation tasks. In this paper, we introduce a novel image-free segmentation task where the goal is to perform semantic segmentation given only a set of the target semantic categories, but without any task-specific images and annotations. To tackle this challenging task, our proposed method, coined IFSeg, generates VL-driven artificial image-segmentation pairs and updates a pre-trained VL model to a segmentation task. We construct this artificial training data by creating a 2D map of random semantic categories and another map of their corresponding word tokens. Given that a pre-trained VL
    
[^17]: 多池化3D卷积神经网络用于fMRI分类视觉脑状态

    Multi-pooling 3D Convolutional Neural Network for fMRI Classification of Visual Brain States. (arXiv:2303.14391v1 [eess.IV])

    [http://arxiv.org/abs/2303.14391](http://arxiv.org/abs/2303.14391)

    本文提出一种多池化3D卷积神经网络（MP3DCNN）来提高fMRI分类准确性，可以将分类准确率从1.684%提高到14.918%,适用于分类面部与对象以及面部和对象的子类别。

    

    通过功能性磁共振成像（fMRI）数据对视觉对象分类进行神经解码是具有挑战性的，并且对于理解潜在的脑机制至关重要。本文提出了一种多池化3D卷积神经网络（MP3DCNN）来提高fMRI分类准确性。MP3DCNN主要由三层3DCNN组成，其中第一层和第二层的3D卷积各具有一个池化连接分支。结果表明，与以往研究相比，该模型可以将分类准确率从1.684%提高到14.918% ，用于分类面部与对象以及面部和对象的子类别。

    Neural decoding of visual object classification via functional magnetic resonance imaging (fMRI) data is challenging and is vital to understand underlying brain mechanisms. This paper proposed a multi-pooling 3D convolutional neural network (MP3DCNN) to improve fMRI classification accuracy. MP3DCNN is mainly composed of a three-layer 3DCNN, where the first and second layers of 3D convolutions each have a branch of pooling connection. The results showed that this model can improve the classification accuracy for categorical (face vs. object), face sub-categorical (male face vs. female face), and object sub-categorical (natural object vs. artificial object) classifications from 1.684% to 14.918% over the previous study in decoding brain mechanisms.
    
[^18]: 主动微调：在预训练-微调范式中利用注释预算

    Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm. (arXiv:2303.14382v1 [cs.CV])

    [http://arxiv.org/abs/2303.14382](http://arxiv.org/abs/2303.14382)

    本文提出了一种新的“主动微调”任务，旨在在预训练-微调范式中利用注释预算。作者提出了一种名为ActiveFT的方法，通过优化参数模型来选择一组数据子集进行注释，以减小所选子集的分布与整个数据池之间的地球移动距离。

    

    针对大规模数据和高昂的注释成本，预训练-微调范式在多个计算机视觉任务中变得流行。以前的研究涵盖了无监督预训练和有监督微调，在这个范式中很少关注利用注释预算来微调。为了填补这个空白，本文正式定义了这个新的主动微调任务，重点是在预训练-微调范式中选择样本进行注释。我们提出了一种称为ActiveFT的新方法来进行主动微调任务，通过在连续空间中优化参数模型，选择与整个未标记数据池类似分布并保持足够多样性的数据子集。我们证明了，在此过程中，所选子集的分布和整个数据池之间的地球移动距离也被减小。广泛的实验表明，ActiveFT相对于基线具有卓越的性能和高效性。

    Given the large-scale data and the high annotation cost, pretraining-finetuning becomes a popular paradigm in multiple computer vision tasks. Previous research has covered both the unsupervised pretraining and supervised finetuning in this paradigm, while little attention is paid to exploiting the annotation budget for finetuning. To fill in this gap, we formally define this new active finetuning task focusing on the selection of samples for annotation in the pretraining-finetuning paradigm. We propose a novel method called ActiveFT for active finetuning task to select a subset of data distributing similarly with the entire unlabeled pool and maintaining enough diversity by optimizing a parametric model in the continuous space. We prove that the Earth Mover's distance between the distributions of the selected subset and the entire data pool is also reduced in this process. Extensive experiments show the leading performance and high efficiency of ActiveFT superior to baselines on both i
    
[^19]: 基于注册和不确定性的只使用一份标注样本的白质束分割框架

    A Registration- and Uncertainty-based Framework for White Matter Tract Segmentation With Only One Annotated Subject. (arXiv:2303.14371v1 [eess.IV])

    [http://arxiv.org/abs/2303.14371](http://arxiv.org/abs/2303.14371)

    本文提出使用只有一份标注样本进行白质束 (WM) 分割的框架，该框架使用注册式峰值增强 (RPA) 和基于不确定性的精炼 (URe) 模块构建，可以获得高精度和高饱和的性能表现。

    

    基于扩散磁共振成像 (dMRI) 的白质束 (WM) 分割在人类健康和大脑疾病分析中扮演着重要角色。然而，WM tracts 的注释需要耗费时间，并且需要经验丰富的神经解剖学家。本文旨在探讨在极少注释情况下的白质束分割问题，我们提出了一种新颖的框架，仅使用一份标注样本 (subject-level one-shot) 进行白质束分割。我们的方法由注册式峰值增强 (RPA) 和基于不确定性的精炼 (URe) 模块构建而成。其中，RPA模块综合伪主体及其相应标签以提高白质束分割性能，URe模块则缓解低置信度像素对伪主体的负面影响。实验结果表明，我们的方法在性能上优于其他最先进的方法，并且我们提出的模块非常有效。综上，我们的方法取得了高饱和的性能。

    White matter (WM) tract segmentation based on diffusion magnetic resonance imaging (dMRI) plays an important role in the analysis of human health and brain diseases. However, the annotation of WM tracts is time-consuming and needs experienced neuroanatomists. In this study, to explore tract segmentation in the challenging setting of minimal annotations, we propose a novel framework utilizing only one annotated subject (subject-level one-shot) for tract segmentation. Our method is constructed by proposed registration-based peak augmentation (RPA) and uncertainty-based refining (URe) modules. RPA module synthesizes pseudo subjects and their corresponding labels to improve the tract segmentation performance. The proposed URe module alleviates the negative influence of the low-confidence voxels on pseudo subjects. Experimental results show that our method outperforms other state-of-the-art methods by a large margin, and our proposed modules are effective. Overall, our method achieves accur
    
[^20]: FlexNeRF：从稀疏视角中实现运动人体的真实自由视角渲染

    FlexNeRF: Photorealistic Free-viewpoint Rendering of Moving Humans from Sparse Views. (arXiv:2303.14368v1 [cs.CV])

    [http://arxiv.org/abs/2303.14368](http://arxiv.org/abs/2303.14368)

    本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。通过对时间和姿态配置的优化以及额外的损失，可在观察视角变得更稀疏时提供高质量的输出，这在公开基准数据集以及自行捕获的时尚数据集上都表现出优越性。

    

    本文提出了FlexNeRF方法，用于从单目视频中实现运动人体的真实自由视角渲染。我们的方法适用于稀疏视角，尤其是当主题表现出快速/复杂运动时，需要克服的挑战。我们提出了一种新颖的方法，同时优化规范时间和姿态配置，使姿态相关的运动场和姿态无关的时间变形互补。通过我们的新颖的时间和循环一致性约束以及对中间表示的额外损失（如分割），我们的方法提供高质量的输出，甚至在观察到的视角变得更稀疏时也是如此。我们实证演示了我们的方法在公开基准数据集以及自行捕获的时尚数据集上显着优于最先进技术。项目页面网址为：https://flex-nerf.github.io/

    We present FlexNeRF, a method for photorealistic freeviewpoint rendering of humans in motion from monocular videos. Our approach works well with sparse views, which is a challenging scenario when the subject is exhibiting fast/complex motions. We propose a novel approach which jointly optimizes a canonical time and pose configuration, with a pose-dependent motion field and pose-independent temporal deformations complementing each other. Thanks to our novel temporal and cyclic consistency constraints along with additional losses on intermediate representation such as segmentation, our approach provides high quality outputs as the observed views become sparser. We empirically demonstrate that our method significantly outperforms the state-of-the-art on public benchmark datasets as well as a self-captured fashion dataset. The project page is available at: https://flex-nerf.github.io/
    
[^21]: 混合模糊-清晰聚类算法：理论与实验

    Hybrid Fuzzy-Crisp Clustering Algorithm: Theory and Experiments. (arXiv:2303.14366v1 [stat.ML])

    [http://arxiv.org/abs/2303.14366](http://arxiv.org/abs/2303.14366)

    本文提出了一种基于目标函数的混合模糊-清晰聚类算法，能够解决传统模糊C均值聚类算法在聚类大小差异巨大时的不平衡影响问题，同时在实验中表现出更好的聚类质量和鲁棒性。

    

    在传统模糊C均值聚类算法中，由于隶属函数始终为正，当聚类大小差异巨大时，会导致不平衡的影响。即，一个明显更大的聚类将所有其他聚类坐标点吸引到其中心，无论它们有多远。为了解决这个问题，本文提出了一种基于隶属度函数线性和二次项的目标函数的混合模糊-清晰聚类算法。在该算法中，如果数据点距离聚类中心“足够”远，则将其隶属度精确地设置为零。本文介绍了一种新的混合模糊-清晰聚类算法及其几何解释。该算法在二十个模拟的数据集和五个来自UCI数据仓库的真实数据集上进行了测试，并与传统的模糊和清晰聚类方法进行了比较。实验结果表明，所提出的算法在聚类质量和鲁棒性方面优于传统方法。

    With the membership function being strictly positive, the conventional fuzzy c-means clustering method sometimes causes imbalanced influence when clusters of vastly different sizes exist. That is, an outstandingly large cluster drags to its center all the other clusters, however far they are separated. To solve this problem, we propose a hybrid fuzzy-crisp clustering algorithm based on a target function combining linear and quadratic terms of the membership function. In this algorithm, the membership of a data point to a cluster is automatically set to exactly zero if the data point is ``sufficiently'' far from the cluster center. In this paper, we present a new algorithm for hybrid fuzzy-crisp clustering along with its geometric interpretation. The algorithm is tested on twenty simulated data generated and five real-world datasets from the UCI repository and compared with conventional fuzzy and crisp clustering methods. The proposed algorithm is demonstrated to outperform the conventi
    
[^22]: 处理异构3D MR膝关节图像：一种具有双重知识蒸馏的联邦少样本学习方法

    Dealing With Heterogeneous 3D MR Knee Images: A Federated Few-Shot Learning Method With Dual Knowledge Distillation. (arXiv:2303.14357v1 [eess.IV])

    [http://arxiv.org/abs/2303.14357](http://arxiv.org/abs/2303.14357)

    本文提出了一种具有双重知识蒸馏的联邦少样本学习方法，利用公共数据库的知识来缓解私人标注图像的短缺，并通过有限的标注数据、无监督学习和双重知识蒸馏，达到优于现有最先进方法的结果。

    

    联邦学习在医学机构中越来越受欢迎，因为它可以在不汇总数据的情况下实现客户(如医院)之间的协作培训。然而，由于为大型3D图像数据集创建注释的成本高昂，特别是对于医疗机构来说，他们没有足够的监督数据来进行本地培训。因此，有限监督下的合作模型表现不佳。另一方面，大型机构有资源来编制高分辨率图像和标签数据存储库。因此，个体客户可以利用从公共数据存储库中获得的知识来缓解私有标注图像的短缺。在本文中，我们提出了一种具有双重知识蒸馏的联邦少样本学习方法。该方法允许在客户之间进行有限标注的联合培训，而不会危害隐私。所提出方法的监督学习从每个客户的有限标注数据中提取特征，而无监督学习从公共数据存储库中学习。此外，实现了双重知识蒸馏以生成更多的不同特征。对膝关节MR图像的异构临床数据集进行的实验证明，我们提出的方法优于现有的最先进方法，实现了0.87的AUC得分。

    Federated Learning has gained popularity among medical institutions since it enables collaborative training between clients (e.g., hospitals) without aggregating data. However, due to the high cost associated with creating annotations, especially for large 3D image datasets, clinical institutions do not have enough supervised data for training locally. Thus, the performance of the collaborative model is subpar under limited supervision. On the other hand, large institutions have the resources to compile data repositories with high-resolution images and labels. Therefore, individual clients can utilize the knowledge acquired in the public data repositories to mitigate the shortage of private annotated images. In this paper, we propose a federated few-shot learning method with dual knowledge distillation. This method allows joint training with limited annotations across clients without jeopardizing privacy. The supervised learning of the proposed method extracts features from limited lab
    
[^23]: O-RAN中的智能负载均衡和资源分配：一种多智能体多臂赌博机方法

    Intelligent Load Balancing and Resource Allocation in O-RAN: A Multi-Agent Multi-Armed Bandit Approach. (arXiv:2303.14355v1 [cs.LG])

    [http://arxiv.org/abs/2303.14355](http://arxiv.org/abs/2303.14355)

    本论文提出了一种多智能体多臂赌博机(mmLBRA)方法，用于实现O-RAN中的负载均衡和资源分配，以解决网络拥塞和用户故障问题。

    

    开放式无线接入网络(O-RAN)架构利用机器学习算法提供了一种成本有效和可扩展的优化网络的解决方案。该架构的开放接口实现了网络功能虚拟化，使O-RAN成为主要的用户通信设备。然而，有限的频率资源和信息爆炸使得在没有有效的流量控制或资源分配的情况下实现最佳的网络体验变得困难。为了解决这个问题，我们考虑进行基于移动性的负载均衡来均匀地分布网络负载，避免由单个开放式分布式单元(O-DU)管辖的开放式无线单元(O-RU)上过度聚集的负载导致网络拥塞和用户故障。我们提出了一种多智能体多臂赌博机方法来实现负载均衡和资源分配(mmLBRA)方案，旨在实现负载均衡和提高O-RAN网络的有效总和速率性能。

    The open radio access network (O-RAN) architecture offers a cost-effective and scalable solution for internet service providers to optimize their networks using machine learning algorithms. The architecture's open interfaces enable network function virtualization, with the O-RAN serving as the primary communication device for users. However, the limited frequency resources and information explosion make it difficult to achieve an optimal network experience without effective traffic control or resource allocation. To address this, we consider mobility-aware load balancing to evenly distribute loads across the network, preventing network congestion and user outages caused by excessive load concentration on open radio unit (O-RU) governed by a single open distributed unit (O-DU). We have proposed a multi-agent multi-armed bandit for load balancing and resource allocation (mmLBRA) scheme, designed to both achieve load balancing and improve the effective sum-rate performance of the O-RAN ne
    
[^24]: DiracDiffusion: 确保数据一致性的去噪和增量重建

    DiracDiffusion: Denoising and Incremental Reconstruction with Assured Data-Consistency. (arXiv:2303.14353v1 [eess.IV])

    [http://arxiv.org/abs/2303.14353](http://arxiv.org/abs/2303.14353)

    DiracDiffusion是一种新的逆问题求解框架，可以应用于图像去噪和增量重建，并保证数据一致性。

    

    扩散模型在许多计算机视觉任务中（包括图像恢复）已经建立了新的技术水平。基于扩散的逆问题求解器从严重损坏的测量数据中生成出具有出色视觉质量的重建结果。然而，在所谓的感知-失真权衡中，感知效果优秀的重建结果通常是以退化的失真度量（如PSNR）为代价的。失真度量衡量对观察的忠实度，这在逆问题中是一个至关重要的要求。在这项工作中，我们提出了一种新的逆问题求解框架，即我们假设观察值来自一个随机劣化过程，逐渐降低和噪声化原始干净图像，然后学习逆转劣化过程以恢复干净图像。我们的技术在整个逆转过程中保持与原始测量的一致性，并允许在感知质量和数据一致性之间取得巨大的灵活性。我们的方法称为DiracDiffusion，因为它基于由Dirac能量函数引导的扩散过程。我们在包括去噪和增量重建在内的几个具有挑战性的图像恢复任务中展示了我们方法的有效性。

    Diffusion models have established new state of the art in a multitude of computer vision tasks, including image restoration. Diffusion-based inverse problem solvers generate reconstructions of exceptional visual quality from heavily corrupted measurements. However, in what is widely known as the perception-distortion trade-off, the price of perceptually appealing reconstructions is often paid in declined distortion metrics, such as PSNR. Distortion metrics measure faithfulness to the observation, a crucial requirement in inverse problems. In this work, we propose a novel framework for inverse problem solving, namely we assume that the observation comes from a stochastic degradation process that gradually degrades and noises the original clean image. We learn to reverse the degradation process in order to recover the clean image. Our technique maintains consistency with the original measurement throughout the reverse process, and allows for great flexibility in trading off perceptual qu
    
[^25]: 层次化多智能体多臂赌博机在多LEO卫星星座网络中用于资源分配

    Hierarchical Multi-Agent Multi-Armed Bandit for Resource Allocation in Multi-LEO Satellite Constellation Networks. (arXiv:2303.14351v1 [cs.LG])

    [http://arxiv.org/abs/2303.14351](http://arxiv.org/abs/2303.14351)

    本文提出了一种分层式多智能体多臂赌博机资源分配（mmRAL）框架，用于适当分配LEO卫星星座的可用无线电资源，以解决资源管理及无信道信息收集的问题。

    

    低轨卫星星座可以在下一代非地面网络（NTN）中提供全球范围内的高速服务区域。由于操作功率、波束和通道的有限板载资源，因此在复杂的干扰情况下，弹性和高效的资源管理变得非常必要。然而，与传统的地面基站不同，LEO在相当高的高度和高运动状态下部署，从而在传输过程中产生大量延迟和干扰。因此，在不知道信道信息且不收集长时延地面网关数据的情况下，我们构建了一个具有双向传输的框架。在本文中，我们提出了一种适当分配可用无线电资源的分层式多智能体多臂赌博机资源分配（mmRAL）用于LEO卫星星座。

    Low Earth orbit (LEO) satellite constellation is capable of providing global coverage area with high-rate services in the next sixth-generation (6G) non-terrestrial network (NTN). Due to limited onboard resources of operating power, beams, and channels, resilient and efficient resource management has become compellingly imperative under complex interference cases. However, different from conventional terrestrial base stations, LEO is deployed at considerable height and under high mobility, inducing substantially long delay and interference during transmission. As a result, acquiring the accurate channel state information between LEOs and ground users is challenging. Therefore, we construct a framework with a two-way transmission under unknown channel information and no data collected at long-delay ground gateway. In this paper, we propose hierarchical multi-agent multi-armed bandit resource allocation for LEO constellation (mmRAL) by appropriately assigning available radio resources. L
    
[^26]: 3D脑MR的因果图像合成

    Causal Image Synthesis of Brain MR in 3D. (arXiv:2303.14349v1 [eess.IV])

    [http://arxiv.org/abs/2303.14349](http://arxiv.org/abs/2303.14349)

    该论文提出了一种基于因果关系的图像合成方法，可以生成在不同人口统计变量、临床指数和阿尔茨海默病患者的脑MR图像之间的反事实脑MR图像。

    

    临床决策需基于真实医学影像进行反事实推理，因此需要进行因果图像合成。为此，我们提出了一种新的方法，用于建模人口统计变量、临床指数和阿尔茨海默病患者的脑MR影像之间的因果关系。具体来说，我们利用结构因果模型来描述因果关系，利用风格生成器来合成图像。此外，为了减少建模复杂性并使学习可行，我们提出使用低维潜在特征表示高维3D图像，结合外生噪声，以建立图像和非图像变量之间的因果关系。我们基于1586个受试者和3683个3D图像进行了实验，并合成了在某些属性干预下的反事实脑MR图像，如年龄、脑容积和认知测试得分等。定量指标和对反事实图像的定性评估证明了所提方法的有效性。

    Clinical decision making requires counterfactual reasoning based on a factual medical image and thus necessitates causal image synthesis. To this end, we present a novel method for modeling the causality between demographic variables, clinical indices and brain MR images for Alzheimer's Diseases. Specifically, we leverage a structural causal model to depict the causality and a styled generator to synthesize the image. Furthermore, as a crucial step to reduce modeling complexity and make learning tractable, we propose the use of low dimensional latent feature representation of a high-dimensional 3D image, together with exogenous noise, to build causal relationship between the image and non image variables. We experiment the proposed method based on 1586 subjects and 3683 3D images and synthesize counterfactual brain MR images intervened on certain attributes, such as age, brain volume and cognitive test score. Quantitative metrics and qualitative evaluation of counterfactual images demo
    
[^27]: 从哥德尔不完备定理到机器人宗教的完备性（扩展摘要）

    From G\"odel's Incompleteness Theorem to the completeness of bot religions (Extended abstract). (arXiv:2303.14338v1 [cs.AI])

    [http://arxiv.org/abs/2303.14338](http://arxiv.org/abs/2303.14338)

    本文研究了从哥德尔不完备定理到机器人宗教的完备性的逻辑过程，提出了任何信仰系统可以被形式化为逻辑理论，并且不完备定理意味着存在真实但无法证明的陈述，可以用来定义出与现有信仰和传统一致的新宗教实践。

    

    Hilbert 和 Ackermann 提出了一种将不完备理论一致地扩展到完备理论的方法。哥德尔基本上证明了任何能够对其自身陈述及其证明进行编码的理论都包含了真实但不能被证明的陈述。哥德尔的构造并没有回答希尔伯特的问题，希尔伯特认为理论可以通过逐步添加公理来证明越来越多的真实陈述，就像科学一样，完备性是消失点。我们研究了底层的逻辑过程，并描述了导致可测试但不可行的机器人宗教的轨迹，这些宗教扩展了传统宗教并提出了新的仪式和信仰。我们的方法是基于任何信仰系统都可以被形式化为一个逻辑理论的想法，并且不完备定理意味着存在真实但无法证明的陈述，可以并入这个理论。我们提供了这样的例子，并展示了如何使用它们来定义与现有信仰和传统一致的新宗教实践。

    Hilbert and Ackermann asked for a method to consistently extend incomplete theories to complete theories. G\"odel essentially proved that any theory capable of encoding its own statements and their proofs contains statements that are true but not provable. Hilbert did not accept that G\"odel's construction answered his question, and in his late writings and lectures, G\"odel agreed that it did not, since theories can be completed incrementally, by adding axioms to prove ever more true statements, as science normally does, with completeness as the vanishing point. This pragmatic view of validity is familiar not only to scientists who conjecture test hypotheses but also to real estate agents and other dealers, who conjure claims, albeit invalid, as necessary to close a deal, confident that they will be able to conjure other claims, albeit invalid, sufficient to make the first claims valid. We study the underlying logical process and describe the trajectories leading to testable but unfal
    
[^28]: 基于集成的黑盒攻击密集预测模型

    Ensemble-based Blackbox Attacks on Dense Prediction. (arXiv:2303.14304v1 [cs.CV])

    [http://arxiv.org/abs/2303.14304](http://arxiv.org/abs/2303.14304)

    本文提出了一种对密集预测模型进行黑盒攻击的方法，该方法基于一个经过精心设计的集成，并注意到单个模型的权重规范化和集成权重的调整可以进一步提高攻击性能。该方法已经在目标检测和分割任务上得到了验证。

    

    我们提出了一种针对密集预测模型的对抗攻击方法(例如目标检测和分割)。众所周知，单个替代模型产生的攻击不适用于任意(黑盒)受害者模型。此外，有针对性的攻击通常比无针对性的攻击更具挑战性。本文表明，经过精心设计的集成可以为多个受害者模型创建有效的攻击。特别地，我们表明，对于单个模型的权重的规范化对于攻击的成功至关重要。然后，我们展示了通过根据受害者模型调整集成权重可以进一步提高攻击的性能。我们进行了许多目标检测和分割实验，以突显我们提出的方法的重要性。我们提出的基于集成的方法优于现有的用于目标检测和分割的黑盒攻击方法。最后，我们展示了通过使用权重调整方法测得的性能优于调整前的集成。

    We propose an approach for adversarial attacks on dense prediction models (such as object detectors and segmentation). It is well known that the attacks generated by a single surrogate model do not transfer to arbitrary (blackbox) victim models. Furthermore, targeted attacks are often more challenging than the untargeted attacks. In this paper, we show that a carefully designed ensemble can create effective attacks for a number of victim models. In particular, we show that normalization of the weights for individual models plays a critical role in the success of the attacks. We then demonstrate that by adjusting the weights of the ensemble according to the victim model can further improve the performance of the attacks. We performed a number of experiments for object detectors and segmentation to highlight the significance of the our proposed methods. Our proposed ensemble-based method outperforms existing blackbox attack methods for object detection and segmentation. Finally we show t
    
[^29]: 无监督特征选择识别ICD-10编码，以用于机器学习：冠状动脉疾病患者队列的案例研究

    Unsupervised Feature Selection to Identify Important ICD-10 Codes for Machine Learning: A Case Study on a Coronary Artery Disease Patient Cohort. (arXiv:2303.14303v1 [cs.LG])

    [http://arxiv.org/abs/2303.14303](http://arxiv.org/abs/2303.14303)

    本研究比较了几种无监督特征选择方法，通过选择性能最佳的Concrete Autoencoder方法，成功识别出49,075例冠状动脉疾病患者数据库中的最佳100个特征，并证实Concrete Autoencoder方法中的权重调整能够提高其准确性。

    

    在医疗保健中使用的国际疾病分类（ICD）代码因代码数量过多而在选择用于机器学习模型的相关代码作为特征时面临挑战。本研究比较了49,075例加拿大阿尔伯塔省冠状动脉疾病患者的ICD编码数据库的几种无监督特征选择方法。我们采用了拉普拉斯分数、多集群数据无监督特征选择、自编码器启发的无监督特征选择、主要特征分析以及具有和不具有ICD树权重调整的Concrete Autoencoders来选择超过9,000个代码中的100个最佳特征。我们评估了选择的特征能力，基于其重建初始特征空间和预测出院后90天的死亡率。我们的研究结果表明，在两项任务中，Concrete Autoencoder方法优于所有其他方法。此外，Concrete Autoencoder方法中的权重调整经证实提高了其准确性。

    The use of International Classification of Diseases (ICD) codes in healthcare presents a challenge in selecting relevant codes as features for machine learning models due to this system's large number of codes. In this study, we compared several unsupervised feature selection methods for an ICD code database of 49,075 coronary artery disease patients in Alberta, Canada. Specifically, we employed Laplacian Score, Unsupervised Feature Selection for Multi-Cluster Data, Autoencoder Inspired Unsupervised Feature Selection, Principal Feature Analysis, and Concrete Autoencoders with and without ICD tree weight adjustment to select the 100 best features from over 9,000 codes. We assessed the selected features based on their ability to reconstruct the initial feature space and predict 90-day mortality following discharge. Our findings revealed that the Concrete Autoencoder methods outperformed all other methods in both tasks. Furthermore, the weight adjustment in the Concrete Autoencoder method
    
[^30]: repliclust：聚类分析的合成数据

    repliclust: Synthetic Data for Cluster Analysis. (arXiv:2303.14301v1 [cs.LG])

    [http://arxiv.org/abs/2303.14301](http://arxiv.org/abs/2303.14301)

    repliclust 是一个 Python 包，用于生成具有聚类的合成数据集，基于数据集的原型，提供了放置集群中心、采样集群形状、选择每个集群的数据点数量以及为集群分配概率分布的算法。

    

    我们介绍了 repliclust（来自于 repli-cate 和 clust-er），这是一个用于生成具有聚类的合成数据集的 Python 包。我们的方法基于数据集的原型，即高级几何描述，用户可以从中创建许多不同的数据集，并具有所需的几何特性。我们软件的架构是模块化和面向对象的，将数据生成分解成放置集群中心的算法、采样集群形状的算法、选择每个集群的数据点数量的算法以及为集群分配概率分布的算法。repliclust.org 项目网页提供了简明的用户指南和全面的文档。

    We present repliclust (from repli-cate and clust-er), a Python package for generating synthetic data sets with clusters. Our approach is based on data set archetypes, high-level geometric descriptions from which the user can create many different data sets, each possessing the desired geometric characteristics. The architecture of our software is modular and object-oriented, decomposing data generation into algorithms for placing cluster centers, sampling cluster shapes, selecting the number of data points for each cluster, and assigning probability distributions to clusters. The project webpage, repliclust.org, provides a concise user guide and thorough documentation.
    
[^31]: 针对Hölder连续多元函数的高效Lipschitzian全局优化方法

    Efficient Lipschitzian Global Optimization of H\"older Continuous Multivariate Functions. (arXiv:2303.14293v1 [cs.LG])

    [http://arxiv.org/abs/2303.14293](http://arxiv.org/abs/2303.14293)

    本研究提出了一种高效的全局优化技术，通过预定的查询创建规则实现了对Hölder连续多元函数的计算优势，可在给定时间段内获得 minimax 最优的结果。

    

    本研究提出了一种有效的全局优化技术，专门针对Hölder连续的多元函数。与构造下界代理函数的传统方法不同，这个算法采用了预定的查询创建规则，使其在计算上更具优势。算法的性能使用平均或累积遗憾进行评估，这也意味着简单遗憾的界限，反映了该方法的整体有效性。结果表明，使用适当的参数，算法在给定时间段$T$内针对Hölder连续的Hölder指数为$\alpha$的目标函数在$n$维空间中获得了$O(T^{-\frac{\alpha}{n}})$的平均遗憾界限。我们证明了这一界限是极小化最优的。

    This study presents an effective global optimization technique designed for multivariate functions that are H\"older continuous. Unlike traditional methods that construct lower bounding proxy functions, this algorithm employs a predetermined query creation rule that makes it computationally superior. The algorithm's performance is assessed using the average or cumulative regret, which also implies a bound for the simple regret and reflects the overall effectiveness of the approach. The results show that with appropriate parameters the algorithm attains an average regret bound of $O(T^{-\frac{\alpha}{n}})$ for optimizing a H\"older continuous target function with H\"older exponent $\alpha$ in an $n$-dimensional space within a given time horizon $T$. We demonstrate that this bound is minimax optimal.
    
[^32]: 高斯过程在极端长度尺度上的应用：从分子到黑洞。

    Applications of Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes. (arXiv:2303.14291v1 [stat.ML])

    [http://arxiv.org/abs/2303.14291](http://arxiv.org/abs/2303.14291)

    高斯过程是一种适合拟合少量数据且充分考虑不确定性的模型，可用于从分子到黑洞等多个领域的数据预测和推断。

    

    在许多观测和实验科学领域，数据非常稀缺。在高能天体物理学中，受到天体遮挡和有限的望远镜时间的影响，数据观测受到干扰。而在合成化学和材料科学的实验室实验中得出的数据，耗时和成本都非常高昂。然而，在科学领域中通常可以获得有关数据产生机制的知识，例如实验装置的测量误差等。这两个特征，即数据量小和对基本物理原理的了解，使得高斯过程（GPs）成为适合拟合此类数据集的理想候选。GPs 能够考虑到不确定性，例如在分子和材料的虚拟筛选中进行预测，并且还可以对不完整的数据进行推断，例如从黑洞吸积盘的潜在发射特征。此外，GPs目前是贝叶斯优化的工作模型，这是一种预计将成为引导学习的方法。

    In many areas of the observational and experimental sciences data is scarce. Data observation in high-energy astrophysics is disrupted by celestial occlusions and limited telescope time while data derived from laboratory experiments in synthetic chemistry and materials science is time and cost-intensive to collect. On the other hand, knowledge about the data-generation mechanism is often available in the sciences, such as the measurement error of a piece of laboratory apparatus. Both characteristics, small data and knowledge of the underlying physics, make Gaussian processes (GPs) ideal candidates for fitting such datasets. GPs can make predictions with consideration of uncertainty, for example in the virtual screening of molecules and materials, and can also make inferences about incomplete data such as the latent emission signature from a black hole accretion disc. Furthermore, GPs are currently the workhorse model for Bayesian optimisation, a methodology foreseen to be a guide for l
    
[^33]: 逻辑回归特征空间草图

    Feature Space Sketching for Logistic Regression. (arXiv:2303.14284v1 [cs.LG])

    [http://arxiv.org/abs/2303.14284](http://arxiv.org/abs/2303.14284)

    该论文提出了基于草图的逻辑回归coreset构建、特征选择和降维的新界限，并解决了之前工作中存在的问题，并提出了可扩展到广义线性模型的前向误差界限。

    

    我们提出了针对逻辑回归的coreset构建、特征选择和降维的新界限。这三种方法都可以视为逻辑回归输入的草图。在coreset构建方面，我们解决了之前工作中的问题，并提出了coreset构造方法的复杂度新界限。在特征选择和降维方面，我们开始研究逻辑回归的前向误差界限。我们的界限可以收紧，直到确定的因素为止，并且前向误差界限可以扩展到广义线性模型。

    We present novel bounds for coreset construction, feature selection, and dimensionality reduction for logistic regression. All three approaches can be thought of as sketching the logistic regression inputs. On the coreset construction front, we resolve open problems from prior work and present novel bounds for the complexity of coreset construction methods. On the feature selection and dimensionality reduction front, we initiate the study of forward error bounds for logistic regression. Our bounds are tight up to constant factors and our forward error bounds can be extended to Generalized Linear Models.
    
[^34]: 基于序列 Knockoffs 的强化学习变量选择

    Sequential Knockoffs for Variable Selection in Reinforcement Learning. (arXiv:2303.14281v1 [stat.ML])

    [http://arxiv.org/abs/2303.14281](http://arxiv.org/abs/2303.14281)

    本论文介绍了一种新颖的序列 Knockoffs (SEEK)算法，用于在强化学习系统中实现变量选择，该算法估计了最小充分状态，确保学习进程良好而不会减缓。

    

    在强化学习的实际应用中，通常很难获得一个既简洁又满足马尔可夫属性的状态表示，而不需要使用先验知识。因此，常规做法是构造一个比必要的要大的状态，例如将连续时间点上的测量串联起来。然而，增加状态的维数可能会减缓学习进程并使学习策略模糊不清。我们引入了一个在马尔可夫决策过程(MDP)中的最小充分状态的概念，作为原始状态下最小的子向量，使该过程仍然是MDP，并且与原始过程共享相同的最优策略。我们提出了一种新颖的序列 Knockoffs (SEEK)算法，用于估计高维复杂非线性动力学系统中的最小充分状态。在大样本中，所提出的方法控制了假发现率，并且选择所有充分的变量的概率趋近于1。

    In real-world applications of reinforcement learning, it is often challenging to obtain a state representation that is parsimonious and satisfies the Markov property without prior knowledge. Consequently, it is common practice to construct a state which is larger than necessary, e.g., by concatenating measurements over contiguous time points. However, needlessly increasing the dimension of the state can slow learning and obfuscate the learned policy. We introduce the notion of a minimal sufficient state in a Markov decision process (MDP) as the smallest subvector of the original state under which the process remains an MDP and shares the same optimal policy as the original process. We propose a novel sequential knockoffs (SEEK) algorithm that estimates the minimal sufficient state in a system with high-dimensional complex nonlinear dynamics. In large samples, the proposed method controls the false discovery rate, and selects all sufficient variables with probability approaching one. As
    
[^35]: 通过适应规划模型学习在开放环境中操作

    Learning to Operate in Open Worlds by Adapting Planning Models. (arXiv:2303.14272v1 [cs.AI])

    [http://arxiv.org/abs/2303.14272](http://arxiv.org/abs/2303.14272)

    该论文提出了一种能够在开放环境中检测新奇性并快速适应其领域模型和行动选择的方法，具有解释性，表现良好。

    

    规划代理在领域模型不能准确代表世界的新情况下无法很好地行动。我们引入了一种方法，使这种代理在开放环境中能够检测到新奇性并有效地适应其领域模型和相应的行动选择。它利用行动执行的观察和根据环境模型的预期测量它们的偏差来推断新奇性的存在。然后，它通过对模型变化的启发式搜索来修订模型。我们在标准强化学习基准测试问题CartPole上报告了实证评估结果。结果表明，我们的方法可以快速且可解释地处理一类新奇性。

    Planning agents are ill-equipped to act in novel situations in which their domain model no longer accurately represents the world. We introduce an approach for such agents operating in open worlds that detects the presence of novelties and effectively adapts their domain models and consequent action selection. It uses observations of action execution and measures their divergence from what is expected, according to the environment model, to infer existence of a novelty. Then, it revises the model through a heuristics-guided search over model changes. We report empirical evaluations on the CartPole problem, a standard Reinforcement Learning (RL) benchmark. The results show that our approach can deal with a class of novelties very quickly and in an interpretable fashion.
    
[^36]: 内容不变性对流形核回归的精确样本复杂度增益

    The Exact Sample Complexity Gain from Invariances for Kernel Regression on Manifolds. (arXiv:2303.14269v1 [cs.LG])

    [http://arxiv.org/abs/2303.14269](http://arxiv.org/abs/2303.14269)

    本文提供了在任何流形上，对于一个在流形上任意群作用下不变的目标函数，核岭回归的最小化最优率，从而增加了有效样本数量或降低了流形的维数。

    

    在实践中，将内容不变性编码进模型可以提高样本复杂度。本文对内容不变性如何改善样本复杂度的理论结果进行了细化和推广，特别地，在任何流形上，对于一个在流形上任意群作用下不变的目标函数，我们提供了核岭回归的最小化最优率。我们的结果适用于（几乎）任何群作用，甚至是正维度的群。对于有限群，增益通过将“有效”样本数量扩大到群的大小来实现。对于正维度的群，增益表现为降低流形的维数，同时还与商空间体积成比例。我们的证明从微分几何的角度来看，与使用不变多项式的更常见策略不同。因此，这个在具有不变性的学习中的新几何视角可能具有独立的兴趣。

    In practice, encoding invariances into models helps sample complexity. In this work, we tighten and generalize theoretical results on how invariances improve sample complexity. In particular, we provide minimax optimal rates for kernel ridge regression on any manifold, with a target function that is invariant to an arbitrary group action on the manifold. Our results hold for (almost) any group action, even groups of positive dimension. For a finite group, the gain increases the "effective" number of samples by the group size. For groups of positive dimension, the gain is observed by a reduction in the manifold's dimension, in addition to a factor proportional to the volume of the quotient space. Our proof takes the viewpoint of differential geometry, in contrast to the more common strategy of using invariant polynomials. Hence, this new geometric viewpoint on learning with invariances may be of independent interest.
    
[^37]: 一种自监督框架来通过多模态被动感知改进基于数据驱动的压力监测

    A Self-supervised Framework for Improved Data-Driven Monitoring of Stress via Multi-modal Passive Sensing. (arXiv:2303.14267v1 [cs.LG])

    [http://arxiv.org/abs/2303.14267](http://arxiv.org/abs/2303.14267)

    本文介绍了一种利用多模态数据和自监督框架来跟踪压力反应的生理前体的新方法。这种方法有助于提高精神健康监测的可靠性和效果。

    

    远程健康监测系统的最新进展大大惠及了患者，并在提高其生活质量方面起到了至关重要的作用。然而，尽管生理健康解决方案已经展示出越来越多的成功和成熟性，但精神健康集中的应用相对而言取得的成功还比较有限，尽管压力和焦虑障碍是人们日常生活中最常见的问题之一。为了通过开发更强大的分析框架来测量精神健康的指标，我们提出了一种多模态半监督框架，用于跟踪压力反应的生理前体。我们的方法使我们能够利用来自可穿戴设备的不同领域和分辨率的多模态数据，并利用它们将短期情节映射到给定任务的语义高效嵌入中。另外，我们利用一种跨模态对比方法来增强结果的可靠性。

    Recent advances in remote health monitoring systems have significantly benefited patients and played a crucial role in improving their quality of life. However, while physiological health-focused solutions have demonstrated increasing success and maturity, mental health-focused applications have seen comparatively limited success in spite of the fact that stress and anxiety disorders are among the most common issues people deal with in their daily lives. In the hopes of furthering progress in this domain through the development of a more robust analytic framework for the measurement of indicators of mental health, we propose a multi-modal semi-supervised framework for tracking physiological precursors of the stress response. Our methodology enables utilizing multi-modal data of differing domains and resolutions from wearable devices and leveraging them to map short-term episodes to semantically efficient embeddings for a given task. Additionally, we leverage an inter-modality contrasti
    
[^38]: 面向聚类动态环境的安全、高效强化学习

    Safe and Sample-efficient Reinforcement Learning for Clustered Dynamic Environments. (arXiv:2303.14265v1 [cs.LG])

    [http://arxiv.org/abs/2303.14265](http://arxiv.org/abs/2303.14265)

    本研究提出了一种安全、高效的强化学习框架，使用安全集算法监测和修改标准控制，并在聚类动态环境下实现，同时使用三项技术提高智能体的学习效率。

    

    本研究提出了一种安全、高效的强化学习框架，以解决应用强化学习算法的两个主要挑战：满足安全约束和在有限样本下有效学习。为了在复杂的真实世界环境中保证安全性，我们使用安全集算法（SSA）来监测和修改标准控制，并在聚类动态环境下评估SSA+RL框架，这在现有的RL算法中具有挑战性。然而，SSA+RL框架通常在奖励稀疏的环境中不够高效，这在以前的安全RL工作中没有得到解决。为了提高学习效率，我们提出了三个技术：（1）通过适应SSA来避免过度保守的行为；（2）使用具有安全约束的随机网络精炼来鼓励安全探索；（3）通过将SSA视为专家演示并直接从中学习来提高策略的收敛性。实验结果显示：

    This study proposes a safe and sample-efficient reinforcement learning (RL) framework to address two major challenges in developing applicable RL algorithms: satisfying safety constraints and efficiently learning with limited samples. To guarantee safety in real-world complex environments, we use the safe set algorithm (SSA) to monitor and modify the nominal controls, and evaluate SSA+RL in a clustered dynamic environment which is challenging to be solved by existing RL algorithms. However, the SSA+RL framework is usually not sample-efficient especially in reward-sparse environments, which has not been addressed in previous safe RL works. To improve the learning efficiency, we propose three techniques: (1) avoiding behaving overly conservative by adapting the SSA; (2) encouraging safe exploration using random network distillation with safety constraints; (3) improving policy convergence by treating SSA as expert demonstrations and directly learn from that. The experimental results show
    
[^39]: 面向时间序列预测的多样化和连贯化数据增强技术研究

    Towards Diverse and Coherent Augmentation for Time-Series Forecasting. (arXiv:2303.14254v1 [cs.LG])

    [http://arxiv.org/abs/2303.14254](http://arxiv.org/abs/2303.14254)

    本研究提出了一种组合频谱和时间增强的方法，用于解决时间序列预测数据增强缺乏多样性和连贯性的问题。

    

    时间序列数据的增强技术缓解了深度学习模型的训练数据不足问题。然而，现有的增强方法主要针对分类问题设计，即使增强改变了时间动态，类别标签也可以保持不变。我们注意到，针对预测设计的增强需要多样性和与原始时间动态的连贯性。由于实际物理过程产生的时间序列数据具有时域和频域的特征，因此我们提出了组合频谱和时间增强（STAug）来生成更多样化和连贯的样本。具体而言，在频域中，我们使用经验模态分解来分解时间序列，并使用随机权重重新组装子分量。这样，我们可以生成多样的样本，同时与原始时间序列的关系连贯一致，因为它们都包含相同的基础分量。在时间域中，我们采用混合策略来组合数据，这可以增强模型对样本之间的连贯性。

    Time-series data augmentation mitigates the issue of insufficient training data for deep learning models. Yet, existing augmentation methods are mainly designed for classification, where class labels can be preserved even if augmentation alters the temporal dynamics. We note that augmentation designed for forecasting requires diversity as well as coherence with the original temporal dynamics. As time-series data generated by real-life physical processes exhibit characteristics in both the time and frequency domains, we propose to combine Spectral and Time Augmentation (STAug) for generating more diverse and coherent samples. Specifically, in the frequency domain, we use the Empirical Mode Decomposition to decompose a time series and reassemble the subcomponents with random weights. This way, we generate diverse samples while being coherent with the original temporal relationships as they contain the same set of base components. In the time domain, we adapt a mix-up strategy that genera
    
[^40]: 隐式平衡和正则化：过参数化非对称矩阵感知中的泛化和收敛保证

    Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v1 [cs.LG])

    [http://arxiv.org/abs/2303.14244](http://arxiv.org/abs/2303.14244)

    本论文研究了过参数化低秩矩阵感知问题，证明了通过因子化方法训练的过参数化模型可以收敛，并且隐式平衡和正则化可以促进泛化。

    

    最近，对于训练过参数化学习模型的基于梯度的方法的收敛和泛化属性有了重要进展。然而，其中许多方面，包括小随机初始化的角色以及模型的各种参数在梯度更新中如何耦合以促进良好的泛化，仍然是很神秘的。最近一系列的论文已经开始研究非凸对称半正定（PSD）矩阵感知问题的形式，在这个问题中需要从几个线性测量中重建一个低秩PSD矩阵。这种底层的对称性/PSD性对于现有的这个问题的收敛和泛化保证是至关重要的。在本文中，我们研究了一个一般的过参数化的低秩矩阵感知问题，其中希望从少量的线性测量中重建一个非对称矩形低秩矩阵。我们证明了通过因子化来训练的过参数化模型在这个问题上可以收敛，而隐式平衡和正则化可以促进泛化。

    Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factori
    
[^41]: IDGI：一个消除 integrated gradients 解释噪声的框架

    IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients. (arXiv:2303.14242v1 [cs.CV])

    [http://arxiv.org/abs/2303.14242](http://arxiv.org/abs/2303.14242)

    IDGI 提出了一种新的方法来减少 integrated gradients 解释显著性图中的噪声，并在众多可解释性指标上显著提高了解释性能。

    

    Integrated Gradients（IG）及其变体是解释深度神经网络决策的众所周知的技术。虽然基于IG的方法具有最先进的性能，但它们经常将噪声集成到其解释显著性图中，从而降低其可解释性。为了最小化噪声，我们通过分析找出了噪声的来源，并提出了一种新的方法来减少解释噪声。我们提出了重要方向梯度集成（IDGI）框架，它可以很容易地集成到任何使用Reimann积分计算集成梯度的基于IG的方法中。三种基于IG的方法的大量实验证明，IDGI在众多可解释性指标上显著提高了它们的性能。

    Integrated Gradients (IG) as well as its variants are well-known techniques for interpreting the decisions of deep neural networks. While IG-based approaches attain state-of-the-art performance, they often integrate noise into their explanation saliency maps, which reduce their interpretability. To minimize the noise, we examine the source of the noise analytically and propose a new approach to reduce the explanation noise based on our analytical findings. We propose the Important Direction Gradient Integration (IDGI) framework, which can be easily incorporated into any IG-based method that uses the Reimann Integration for integrated gradient computation. Extensive experiments with three IG-based methods show that IDGI improves them drastically on numerous interpretability metrics.
    
[^42]: 基于核心的区块链网络趋势监测研究

    Core-based Trend Detection in Blockchain Networks. (arXiv:2303.14241v1 [cs.LG])

    [http://arxiv.org/abs/2303.14241](http://arxiv.org/abs/2303.14241)

    本研究介绍了一种可伸缩的方法InnerCore用于分析区块链网络，实现了基于区块链网络对关键参与者的识别并提供情感指标，以实现自动化的趋势监测。

    

    区块链在贸易金融中的应用越来越广泛，每天交易的资产价值达数十亿美元。然而，由于数据的规模和复杂性，对这些网络进行分析仍然具有挑战性。我们介绍了一种可伸缩的方法- InnerCore，用于识别基于区块链的网络中的关键参与者，并使用基于数据深度的内核分解和中心模式发现提供网络情感指标。 InnerCore是一种计算高效、非监督的方法，适用于分析大规模时间图。我们通过对LunaTerra的最近崩溃和以太坊的PoS切换进行案例研究，并使用一家领先的区块链分析公司收集的外部基本事实证明了它的有效性。我们的实验表明，InnerCore可以与合格的分析准确匹配，不需要人为干预，从而实现可伸缩的区块链分析和趋势检测。

    Blockchains are now significantly easing trade finance, with billions of dollars worth of assets being transacted daily. However, analyzing these networks remains challenging due to the large size and complexity of the data. We introduce a scalable approach called "InnerCore" for identifying key actors in blockchain-based networks and providing a sentiment indicator for the networks using data depth-based core decomposition and centered-motif discovery. InnerCore is a computationally efficient, unsupervised approach suitable for analyzing large temporal graphs. We demonstrate its effectiveness through case studies on the recent collapse of LunaTerra and the Proof-of-Stake (PoS) switch of Ethereum, using external ground truth collected by a leading blockchain analysis company. Our experiments show that InnerCore can match the qualified analysis accurately without human involvement, automating blockchain analysis and its trend detection in a scalable manner.
    
[^43]: 高效多智能体强化学习中的因果关系检测

    Causality Detection for Efficient Multi-Agent Reinforcement Learning. (arXiv:2303.14227v1 [cs.AI])

    [http://arxiv.org/abs/2303.14227](http://arxiv.org/abs/2303.14227)

    本文研究了多智能体强化学习中一些代理无法理解他们在团队表现中的真实影响，导致学习次优策略，表现懒惰。通过因果关系检测惩罚懒惰代理并改善其行为，团队整体性能和每个代理的个体能力都得到了提升。

    

    当作为团队学习任务时，多智能体强化学习（MARL）中的一些代理可能无法理解他们在团队表现中的真实影响。这些代理最终会学习次优策略，表现出不良的懒惰行为。本文通过正式表述时间因果关系在MARL问题中的应用来研究这个问题。我们展示了如何利用因果关系来惩罚这些懒惰代理并改善其行为。通过理解他们的本地观测如何因果相关于团队奖励，团队中的每个代理都可以根据他们是否有助于导致奖励来调整其个人信用贡献。我们实证表明，在MARL中使用因果估计不仅可以改善团队整体性能，还可以提升每个代理的个体能力。我们观察到，在一组不同的环境中，这种改进是一致的。

    When learning a task as a team, some agents in Multi-Agent Reinforcement Learning (MARL) may fail to understand their true impact in the performance of the team. Such agents end up learning sub-optimal policies, demonstrating undesired lazy behaviours. To investigate this problem, we start by formalising the use of temporal causality applied to MARL problems. We then show how causality can be used to penalise such lazy agents and improve their behaviours. By understanding how their local observations are causally related to the team reward, each agent in the team can adjust their individual credit based on whether they helped to cause the reward or not. We show empirically that using causality estimations in MARL improves not only the holistic performance of the team, but also the individual capabilities of each agent. We observe that the improvements are consistent in a set of different environments.
    
[^44]: 组合干预的因果推断框架:合成组合

    Synthetic Combinations: A Causal Inference Framework for Combinatorial Interventions. (arXiv:2303.14226v1 [stat.ME])

    [http://arxiv.org/abs/2303.14226](http://arxiv.org/abs/2303.14226)

    提出了一种在组合干预下进行因果推断的模型，通过施加潜在结构跨越单位和组合，在降低实验数量和处理混杂问题方面有着良好表现。

    

    我们考虑一个包含N个异质单位和p个干预的设置。 我们的目标是学习任意组合的单位特定潜在结果，即N×2 ^ p个因果参数。在许多应用程序中自然出现了选择干预组合的问题，例如因子设计试验，推荐引擎(例如，为用户显示最大程度的参与度的一组电影)，医学中的组合疗法，选择ML模型的重要特征等等。当N和p增长时，进行N×2 ^ p个实验来估计各种参数是不可行的。而且，观测数据很可能存在混杂，即单位是否在组合下出现与其在该组合下的潜在结果相关。为了解决这些问题，我们提出了一种新颖的模型，它在单位和组合之间都施加了潜在结构。我们假设单位之间存在潜在的相似性(即类似单位的潜在结果是相似的)，并且组合之间也存在潜在的相似性(即类似组合的效果是相似的)。我们使用层次贝叶斯非参数模型来形式化这一点，该模型联合聚类单元和组合，并且足够灵活，可以模拟连续或离散结果。我们在模拟和实际数据上演示了所提出的方法，并表明它可以显着减少学习因果参数所需的实验数量。

    We consider a setting with $N$ heterogeneous units and $p$ interventions. Our goal is to learn unit-specific potential outcomes for any combination of these $p$ interventions, i.e., $N \times 2^p$ causal parameters. Choosing combinations of interventions is a problem that naturally arises in many applications such as factorial design experiments, recommendation engines (e.g., showing a set of movies that maximizes engagement for users), combination therapies in medicine, selecting important features for ML models, etc. Running $N \times 2^p$ experiments to estimate the various parameters is infeasible as $N$ and $p$ grow. Further, with observational data there is likely confounding, i.e., whether or not a unit is seen under a combination is correlated with its potential outcome under that combination. To address these challenges, we propose a novel model that imposes latent structure across both units and combinations. We assume latent similarity across units (i.e., the potential outco
    
[^45]: 机器辅助发现新型碳捕集溶剂

    Machine Guided Discovery of Novel Carbon Capture Solvents. (arXiv:2303.14223v1 [cs.LG])

    [http://arxiv.org/abs/2303.14223](http://arxiv.org/abs/2303.14223)

    该研究展示了机器学习在加速新型碳捕集材料发现方面的潜力，通过结合实验室测试和分子指纹模型方法，成功识别出潜在的碳捕集溶剂。

    

    碳捕集技术在减少CO2排放方面的重要性日益增长，提高捕集材料的可扩展性和效率面临着材料开发的挑战，该过程可能需要耗费大量成本和时间。机器学习通过结构-性质关系的高效相关性，提供了一个降低材料开发时间和资源负担的有前途方法，从而实现有前途候选材料的筛选和关注。为了证明这个理念，我们已经开发了一个端对端的“发现生命周期”，以选择与商业化酸气洗涤碳捕集兼容的新型水胺。我们结合了对CO2吸收的简单、快速实验室测试和基于机器学习的分子指纹模型方法。预测过程在实验和材料参数方面的准确性均为60%，在外部测试集上单个参数的准确性达到了80%。发现生命周期系统成功地确定了以前未知的胺类候选人作为潜在的碳捕集溶剂，展示了机器学习用于加速材料发现的潜力。

    The increasing importance of carbon capture technologies for deployment in remediating CO2 emissions, and thus the necessity to improve capture materials to allow scalability and efficiency, faces the challenge of materials development, which can require substantial costs and time. Machine learning offers a promising method for reducing the time and resource burdens of materials development through efficient correlation of structure-property relationships to allow down-selection and focusing on promising candidates. Towards demonstrating this, we have developed an end-to-end "discovery cycle" to select new aqueous amines compatible with the commercially viable acid gas scrubbing carbon capture. We combine a simple, rapid laboratory assay for CO2 absorption with a machine learning based molecular fingerprinting model approach. The prediction process shows 60% accuracy against experiment for both material parameters and 80% for a single parameter on an external test set. The discovery cy
    
[^46]: 信息表示之争：比较情感与语义特征预测市场趋势

    The Battle of Information Representations: Comparing Sentiment and Semantic Features for Forecasting Market Trends. (arXiv:2303.14221v1 [cs.LG])

    [http://arxiv.org/abs/2303.14221](http://arxiv.org/abs/2303.14221)

    本文研究了股票价格预测所需的情感和语义特征表示的比较，结果表明基于情感的方法在预测市场趋势方面更优。

    

    用机器学习方法研究股市是揭示隐藏市场规律的主要方向。与传统分析方法相比，这种知识有助于深入了解金融市场动态并获得行为洞察。股票价格与世界事件和社会观念密切相关。因此，在构建股票价格预测模型时，关键阶段是加入这些从新闻和社交媒体帖子反映出来的外部信息。为了实现这一点，研究人员利用隐式或显式的知识表示：（1）从文本中提取的情感或（2）原始文本嵌入。然而，在影响金融模型预测能力方面，这些方法之间的直接比较研究太少。在本文中，我们旨在弥补这一差距，并弄清楚语义特征方法能否超越基于情感的方法。我们的结果证明了后者在预测市场趋势方面的优越性，并概述了两种表示方式的优点和挑战。

    The study of the stock market with the attraction of machine learning approaches is a major direction for revealing hidden market regularities. This knowledge contributes to a profound understanding of financial market dynamics and getting behavioural insights, which could hardly be discovered with traditional analytical methods. Stock prices are inherently interrelated with world events and social perception. Thus, in constructing the model for stock price prediction, the critical stage is to incorporate such information on the outside world, reflected through news and social media posts. To accommodate this, researchers leverage the implicit or explicit knowledge representations: (1) sentiments extracted from the texts or (2) raw text embeddings. However, there is too little research attention to the direct comparison of these approaches in terms of the influence on the predictive power of financial models. In this paper, we aim to close this gap and figure out whether the semantic f
    
[^47]: 使用标准化流的变分推理处理纵向数据

    Variational Inference for Longitudinal Data Using Normalizing Flows. (arXiv:2303.14220v1 [stat.ML])

    [http://arxiv.org/abs/2303.14220](http://arxiv.org/abs/2303.14220)

    该文提出一种基于标准化流的高维纵向数据生成模型，能够进行好的缺失数据插补操作。

    

    本文引入了一种新的潜变量生成模型，能够处理高维纵向数据，并依赖于变分推理。使用标准化流来对相关的潜变量的时间依赖关系进行建模。该方法可以用于生成完全合成的纵向序列，也可以用于生成在序列中与多个数据有关的轨迹，并且在缺失数据方面表现出良好的鲁棒性。我们在6个不同复杂度的数据集上测试了该模型，并显示出它可以实现更好的似然估计，以及更可靠的缺失数据插补。代码可在\url{https://github.com/clementchadebec/variational_inference_for_longitudinal_data}上获得。

    This paper introduces a new latent variable generative model able to handle high dimensional longitudinal data and relying on variational inference. The time dependency between the observations of an input sequence is modelled using normalizing flows over the associated latent variables. The proposed method can be used to generate either fully synthetic longitudinal sequences or trajectories that are conditioned on several data in a sequence and demonstrates good robustness properties to missing data. We test the model on 6 datasets of different complexity and show that it can achieve better likelihood estimates than some competitors as well as more reliable missing data imputation. A code is made available at \url{https://github.com/clementchadebec/variational_inference_for_longitudinal_data}.
    
[^48]: 基于深度学习的交通系统中后门消除的最佳平滑分布探索

    Optimal Smoothing Distribution Exploration for Backdoor Neutralization in Deep Learning-based Traffic Systems. (arXiv:2303.14197v1 [cs.LG])

    [http://arxiv.org/abs/2303.14197](http://arxiv.org/abs/2303.14197)

    该论文提出了一种在DRL基础的AVs中探索最佳平滑分布以消除后门攻击的方法，通过将噪声添加到输入中来中和攻击并实现更好的检测和防御。

    

    深度强化学习（DRL）提高了自动驾驶车辆（AV）的效率，但也使它们容易受到后门攻击，这可能导致交通拥堵或碰撞。后门功能通常是通过污染训练数据集以保持对真实输入的高准确性并诱导攻击者选择的特定输入的期望（恶意）输出来实现的。当前抵御后门攻击的防御主要集中在使用基于图像的特征进行图像分类上，这不能很好地转移到DRL基础的AV控制器的回归任务，因为输入是连续的传感器数据，即AV及其周围车辆的速度和距离的组合。我们提出的方法是将精心设计的噪声添加到输入中来中和后门攻击。该方法涉及学习一个最佳平滑（噪声）分布来保持真实输入的正常功能同时中和后门攻击。通过这样做，我们实现了在DRL基础的AVs中更好的后门攻击检测和防御。

    Deep Reinforcement Learning (DRL) enhances the efficiency of Autonomous Vehicles (AV), but also makes them susceptible to backdoor attacks that can result in traffic congestion or collisions. Backdoor functionality is typically incorporated by contaminating training datasets with covert malicious data to maintain high precision on genuine inputs while inducing the desired (malicious) outputs for specific inputs chosen by adversaries. Current defenses against backdoors mainly focus on image classification using image-based features, which cannot be readily transferred to the regression task of DRL-based AV controllers since the inputs are continuous sensor data, i.e., the combinations of velocity and distance of AV and its surrounding vehicles. Our proposed method adds well-designed noise to the input to neutralize backdoors. The approach involves learning an optimal smoothing (noise) distribution to preserve the normal functionality of genuine inputs while neutralizing backdoors. By do
    
[^49]: DeepEpiSolver：揭示Covid，HIV，Ebola和疾病传播的逆问题

    DeepEpiSolver: Unravelling Inverse problems in Covid, HIV, Ebola and Disease Transmission. (arXiv:2303.14194v1 [cs.LG])

    [http://arxiv.org/abs/2303.14194](http://arxiv.org/abs/2303.14194)

    DeepEpiSolver使用深度神经网络(DNN)作为逆问题求解器估计SIR模型的参数，相对于Physics Informed Neural Networks (PINNs)方法，其训练速度更快，且可以很好地推广到新的SIDR轨迹上，并在 COVID-19、HIV、埃博拉和疾病传播方面取得验证性结果。

    

    许多传染病的传播都是用SIR隔室模型的变体进行建模的，该模型是一组耦合的微分方程。 SIR模型的系数确定了疾病传播轨迹，基于此可以采取积极措施。因此，系数估计必须既快又准确。Shaier等人在论文“疾病信息神经网络”中使用物理信息神经网络（PINNs）估计了SIR模型的参数。该方法有两个缺点。首先，PINN的训练时间很长，某些疾病需要接近90小时的训练时间。其次，PINN对于新的SIDR轨迹不具有普适性，学习其对应的SIR参数需要从头重新训练PINN。在这项工作中，我们旨在消除这两个缺点。我们通过使用LSODA算法解决参数和传播轨迹之间的正向问题来生成数据集。然后，我们使用深度神经网络（DNN）作为反演求解器，根据传播轨迹估计SIR模型的正确参数。我们提出的方法，DeepEpiSolver，比PINN方法快几个数量级，并且可以很好地推广到新的SIDR轨迹上。我们在四种不同的疾病上验证了我们的方法：Covid，HIV，Ebola和疾病传播。

    The spread of many infectious diseases is modeled using variants of the SIR compartmental model, which is a coupled differential equation. The coefficients of the SIR model determine the spread trajectories of disease, on whose basis proactive measures can be taken. Hence, the coefficient estimates must be both fast and accurate. Shaier et al. in the paper "Disease Informed Neural Networks" used Physics Informed Neural Networks (PINNs) to estimate the parameters of the SIR model. There are two drawbacks to this approach. First, the training time for PINNs is high, with certain diseases taking close to 90 hrs to train. Second, PINNs don't generalize for a new SIDR trajectory, and learning its corresponding SIR parameters requires retraining the PINN from scratch. In this work, we aim to eliminate both of these drawbacks. We generate a dataset between the parameters of ODE and the spread trajectories by solving the forward problem for a large distribution of parameters using the LSODA al
    
[^50]: 自适应实例级损失平滑改进对抗训练

    Improved Adversarial Training Through Adaptive Instance-wise Loss Smoothing. (arXiv:2303.14077v1 [cs.CV])

    [http://arxiv.org/abs/2303.14077](http://arxiv.org/abs/2303.14077)

    本文提出了一种新的对抗训练方法(Instance-adaptive Adversarial Training, IAAT)通过平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本，取得了在各种数据集下的最新、最佳结果，并在白盒和黑盒攻击下均优于以前的方法。

    

    通过对输入进行对抗扰动：即人类难以察觉的人造噪声，可以轻易地迷惑深度神经网络从而做出不正确的预测。目前对抗训练已成为最成功的对抗攻击防御方法，本文致力于改进对抗训练以提升对抗鲁棒性。首先从实例级别的角度分析了对抗训练期间对抗性脆弱性的演变。发现在训练期间，通过牺牲相当比例的训练样本来提高对抗攻击的脆弱性，从而实现对抗性损失的整体降低，这导致了不同数据的对抗性脆弱性分布不均衡。这种“不均衡脆弱性”在几种流行的鲁棒性训练方法中普遍存在，并且与对抗训练中的过拟合相关。基于此观察，我们提出了一种新的对抗训练方法：Instance-adaptive Adversarial Training (IAAT)。该方法在训练过程中平滑实例级别的对抗性损失，鼓励模型关注“难”的样本，同时避免牺牲特定的样本而偏爱其他样本。本方法在各种数据集下都取得了最新的最佳结果，并在白盒和黑盒攻击下均优于以前的方法。

    Deep neural networks can be easily fooled into making incorrect predictions through corruption of the input by adversarial perturbations: human-imperceptible artificial noise. So far adversarial training has been the most successful defense against such adversarial attacks. This work focuses on improving adversarial training to boost adversarial robustness. We first analyze, from an instance-wise perspective, how adversarial vulnerability evolves during adversarial training. We find that during training an overall reduction of adversarial loss is achieved by sacrificing a considerable proportion of training samples to be more vulnerable to adversarial attack, which results in an uneven distribution of adversarial vulnerability among data. Such "uneven vulnerability", is prevalent across several popular robust training methods and, more importantly, relates to overfitting in adversarial training. Motivated by this observation, we propose a new adversarial training method: Instance-adapt
    
[^51]: 使用图神经网络重建粒子物理过程的拓扑结构

    Topological Reconstruction of Particle Physics Processes using Graph Neural Networks. (arXiv:2303.13937v1 [hep-ph])

    [http://arxiv.org/abs/2303.13937](http://arxiv.org/abs/2303.13937)

    Topograph是一种利用图神经网络和粒子衰变自然规律的拓扑结构重建方法，不仅解决了观测到的末态对象组合指派问题，还预测了中间粒子的性质及其后续衰变，比标准方法效果更好，与现代机器学习技术表现相当。

    

    我们提出了一种新的方法，称为Topograph，它利用粒子物理衰变的本质和信息传递图神经网络的灵活性，重建了包括中介粒子在内的底层物理过程。Topograph不仅解决了观测到的末态对象的组合指派问题，将它们与它们原来的母粒子关联起来，而且直接预测了硬散射过程中中间粒子的性质及其后续衰变。与标准的组合方法或现代图神经网络方法相比，它的复杂度与重构对象的数量成线性关系。我们应用Topograph于全强子衰变模式下的顶夸克对产生问题，相对标准方法，我们的方法表现更优，与最先进的机器学习技术相当。

    We present a new approach, the Topograph, which reconstructs underlying physics processes, including the intermediary particles, by leveraging underlying priors from the nature of particle physics decays and the flexibility of message passing graph neural networks. The Topograph not only solves the combinatoric assignment of observed final state objects, associating them to their original mother particles, but directly predicts the properties of intermediate particles in hard scatter processes and their subsequent decays. In comparison to standard combinatoric approaches or modern approaches using graph neural networks, which scale exponentially or quadratically, the complexity of Topographs scales linearly with the number of reconstructed objects.  We apply Topographs to top quark pair production in the all hadronic decay channel, where we outperform the standard approach and match the performance of the state-of-the-art machine learning technique.
    
[^52]: 无需边缘但具有结构感知性：从GNN到MLP的原型引导知识蒸馏。

    Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs. (arXiv:2303.13763v1 [cs.LG])

    [http://arxiv.org/abs/2303.13763](http://arxiv.org/abs/2303.13763)

    本文提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。

    

    将高精度的图神经网络（GNN）在图任务中压缩成低延迟的多层感知器（MLP）已成为热门研究课题。以前的方法会将图的边缘处理成额外的输入给MLP，但这样的图结构对于各种场景可能无法获得。因此，我们提出了一种原型引导知识蒸馏（PGKD）方法，它不需要图形边缘，但可以在不考虑边缘的情况下学习结构感知的MLP。具体而言，我们分析了GNN教师中的图形结构信息，并通过原型在无边缘设置中从GNN到MLP进行了知识蒸馏。在流行的图形基准实验中的实验结果表明了所提出的PGKD方法的有效性和鲁棒性。

    Distilling high-accuracy Graph Neural Networks~(GNNs) to low-latency multilayer perceptrons~(MLPs) on graph tasks has become a hot research topic. However, MLPs rely exclusively on the node features and fail to capture the graph structural information. Previous methods address this issue by processing graph edges into extra inputs for MLPs, but such graph structures may be unavailable for various scenarios. To this end, we propose a Prototype-Guided Knowledge Distillation~(PGKD) method, which does not require graph edges~(edge-free) yet learns structure-aware MLPs. Specifically, we analyze the graph structural information in GNN teachers, and distill such information from GNNs to MLPs via prototypes in an edge-free setting. Experimental results on popular graph benchmarks demonstrate the effectiveness and robustness of the proposed PGKD.
    
[^53]: 人工智能在可持续性方面的应用: 利用计算机视觉促进可持续智能产品-服务系统。

    Artificial Intelligence for Sustainability: Facilitating Sustainable Smart Product-Service Systems with Computer Vision. (arXiv:2303.13540v1 [cs.LG])

    [http://arxiv.org/abs/2303.13540](http://arxiv.org/abs/2303.13540)

    本论文在可持续性方面的主要贡献是使用深度学习技术提高产品生产和使用的可持续性，通过计算机视觉技术检测产品的磨损状态并用于改进智能产品-服务系统的集成和结果取向。

    

    目前使用深度学习来实现清洁生产和可持续性目的的研究还非常有限。本论文展示了如何利用深度学习技术提高产品生产和使用的可持续性，尤其是采用深度学习的计算机视觉技术来识别产品的磨损状态，并将这些结果用于改进智能产品-服务系统的集成和结果取向。此外，这些成果预计将促进产品使用的改进和研发创新。我们在两种产品上演示了我们的方法:加工工具和旋转X射线阳极。

    The usage and impact of deep learning for cleaner production and sustainability purposes remain little explored. This work shows how deep learning can be harnessed to increase sustainability in production and product usage. Specifically, we utilize deep learning-based computer vision to determine the wear states of products. The resulting insights serve as a basis for novel product-service systems with improved integration and result orientation. Moreover, these insights are expected to facilitate product usage improvements and R&D innovations. We demonstrate our approach on two products: machining tools and rotating X-ray anodes. From a technical standpoint, we show that it is possible to recognize the wear state of these products using deep-learning-based computer vision. In particular, we detect wear through microscopic images of the two products. We utilize a U-Net for semantic segmentation to detect wear based on pixel granularity. The resulting mean dice coefficients of 0.631 and
    
[^54]: Xplainer：从X射线观察到可解释的零样本诊断

    Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis. (arXiv:2303.13391v1 [cs.CV])

    [http://arxiv.org/abs/2303.13391](http://arxiv.org/abs/2303.13391)

    Xplainer是一个透明且可解释的零样本诊断新框架，通过对存在的描述性观察进行分类来提高自动诊断集成到临床工作流程中的效率，同时避免需要大量注释数据的问题。

    

    通过医学图像进行自动诊断预测，是支持临床决策的宝贵资源。然而，这样的系统通常需要在大量注释数据上进行训练，而医学领域的注释数据往往很少。零样本方法通过允许在不依赖标记数据的情况下灵活适应具有不同临床结果的新设置来解决这一挑战。此外，为了将自动诊断集成到临床工作流程中，方法应该是透明且可解释的，增加医疗专业人员的信任并促进正确性验证。在这项工作中，我们引入了Xplainer，这是一个在临床设置中进行可解释的零样本诊断的新框架。Xplainer将对比视觉语言模型的分类即描述方法适应于多标签医学诊断任务。具体而言，我们提示模型对存在的描述性观察进行分类，而不是直接预测诊断。

    Automated diagnosis prediction from medical images is a valuable resource to support clinical decision-making. However, such systems usually need to be trained on large amounts of annotated data, which often is scarce in the medical domain. Zero-shot methods address this challenge by allowing a flexible adaption to new settings with different clinical findings without relying on labeled data. Further, to integrate automated diagnosis in the clinical workflow, methods should be transparent and explainable, increasing medical professionals' trust and facilitating correctness verification. In this work, we introduce Xplainer, a novel framework for explainable zero-shot diagnosis in the clinical setting. Xplainer adapts the classification-by-description approach of contrastive vision-language models to the multi-label medical diagnosis task. Specifically, instead of directly predicting a diagnosis, we prompt the model to classify the existence of descriptive observations, which a radiologi
    
[^55]: SPeC：软提示校准在临床笔记摘要中降低性能变异的研究

    SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization. (arXiv:2303.13035v1 [cs.CL])

    [http://arxiv.org/abs/2303.13035](http://arxiv.org/abs/2303.13035)

    研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型.

    

    电子健康记录（EHR）存储着包括病历、诊断、治疗和检测结果在内的大量患者信息。这些记录对于医疗保健专业人员做出明智的患者护理决策非常关键。摘要临床笔记可以帮助医疗保健专业人员更好地发现潜在健康风险，以及做出更好的决策。这一过程通过确保医疗保健专业人员可以访问最相关和最新的患者数据，有助于减少错误并提高患者的护理效果。最近的研究表明，将提示与大语言模型（LLM）相结合可以显著提高摘要任务的效率。然而，我们发现这种方法也会导致输出方差增加，即使提示意义相似，输出也会有明显的差异。为了解决这一挑战，我们引入了一个模型无关的软提示校准（SPeC）流程，该流程采用软提示嵌入来减轻输入变量对输出多样性的影响。我们的实验表明，SPeC不仅可以降低LLM的性能变异，而且在临床笔记摘要任务上优于现有的最先进模型。

    Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better-informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased output variance, resulting in notably divergent outputs even when prompts share similar meanings. To tackle this challenge, we introduce a model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft prom
    
[^56]: 临床基础模型的不稳定基础：针对 EMR 的大语言模型和基础模型的调查

    The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs. (arXiv:2303.12961v1 [cs.LG])

    [http://arxiv.org/abs/2303.12961](http://arxiv.org/abs/2303.12961)

    本论文回顾了超过80个在非成像 EMR 数据上训练的基础模型，发现这些模型大多范围有限、训练集有限，且评估指标未对其对医疗系统贡献提供有意义见解。因此，本研究提出了一种更接近于医疗保健重要指标的医疗基础模型效益评估框架。

    

    类似 ChatGPT 和 AlphaFold 的基础模型的成功引发了人们对于构建类似模型以改善 EMR（电子病历）以提高患者护理和医院运营的极大兴趣。然而，最近的炒作掩盖了我们对这些模型能力的关键缺失。我们回顾了超过80个在非成像 EMR 数据（即临床文本和/或结构化数据）上训练的基础模型，并创建了一个分类法来说明它们的体系结构、训练数据和潜在用例。我们发现大多数模型是在小型、范围有限的临床数据集（例如MIMIC-III）或广泛的公共生物医学语料库（例如PubMed）上进行训练的，并且在不提供对其对医疗系统有用处的有意义见解的任务上进行评估。基于这些发现，我们提出了一种更接近于医疗保健重要指标的医疗基础模型效益的改进评估框架。

    The successes of foundation models such as ChatGPT and AlphaFold have spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models' capabilities. We review over 80 foundation models trained on non-imaging EMR data (i.e. clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g. MIMIC-III) or broad, public biomedical corpora (e.g. PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. In light of these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.
    
[^57]: 稳定性稳定：可复制性、隐私和自适应推广之间的联系

    Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization. (arXiv:2303.12921v1 [cs.LG])

    [http://arxiv.org/abs/2303.12921](http://arxiv.org/abs/2303.12921)

    本文研究了可复制算法与标准算法稳定性的联系，为一类统计问题提供了可复制算法的样本有效算法约化，同时表明这种等价关系必须在计算上崩溃。

    

    在Impagliazzo et al. [STOC '22]中引入了可复制算法的概念，用于描述在输入重新采样时稳定的随机算法。具体而言，当其随机性被固定且在从相同分布中绘制的新的i.i.d.样本上运行时，可复制算法会以很高的概率给出相同的输出。使用可复制算法进行数据分析可以通过确保分析结果在新数据集上进行分析时具有相同的结果来简化已发布结果的验证。在这项工作中，我们建立了可复制性与算法稳定性标准概念之间的新联系和分离。特别地，我们为一类广泛的统计问题给出了完美推广、近似差分隐私和可复制性之间的样本有效算法约化。相反，我们表明这种等价关系必须在计算上崩溃：存在具有可复制算法但不具有任何可用的差分隐私机制的问题。

    The notion of replicable algorithms was introduced in Impagliazzo et al. [STOC '22] to describe randomized algorithms that are stable under the resampling of their inputs. More precisely, a replicable algorithm gives the same output with high probability when its randomness is fixed and it is run on a new i.i.d. sample drawn from the same distribution. Using replicable algorithms for data analysis can facilitate the verification of published results by ensuring that the results of an analysis will be the same with high probability, even when that analysis is performed on a new data set.  In this work, we establish new connections and separations between replicability and standard notions of algorithmic stability. In particular, we give sample-efficient algorithmic reductions between perfect generalization, approximate differential privacy, and replicability for a broad class of statistical problems. Conversely, we show any such equivalence must break down computationally: there exist s
    
[^58]: 面向不完整数据的锥束CT重建的基于立方体的3D去噪扩散概率模型

    Cube-Based 3D Denoising Diffusion Probabilistic Model for Cone Beam Computed Tomography Reconstruction with Incomplete Data. (arXiv:2303.12861v1 [eess.IV])

    [http://arxiv.org/abs/2303.12861](http://arxiv.org/abs/2303.12861)

    本文提出了一种基于立方体的3D去噪扩散概率模型（DDPM）来重建CBCT并解决了存储整个正弦图的内存问题。通过将整个CBCT volume分成多个小立方体，该模型能够实现高效的计算并在视觉和定量评价方面优于现有方法。

    

    深度学习在计算机断层摄影（CT）重建中获得了广泛的研究，特别是在稀疏视图CT重建中。然而，将DL应用于稀疏视图锥束CT（CBCT）仍然具有挑战性。本文提出了一种基于立方体的3D去噪扩散概率模型（DDPM）来重建CBCT，并解决了存储整个正弦图的内存问题。我们的方法将整个CBCT volume分成多个小立方体，以实现高效的计算。实验结果表明，该方法在视觉和定量评价方面优于现有方法。

    Deep learning (DL) has been extensively researched in the field of computed tomography (CT) reconstruction with incomplete data, particularly in sparse-view CT reconstruction. However, applying DL to sparse-view cone beam CT (CBCT) remains challenging. Many models learn the mapping from sparse-view CT images to ground truth but struggle to achieve satisfactory performance in terms of global artifact removal. Incorporating sinogram data and utilizing dual-domain information can enhance anti-artifact performance, but this requires storing the entire sinogram in memory. This presents a memory issue for high-resolution CBCT sinograms, limiting further research and application. In this paper, we propose a cube-based 3D denoising diffusion probabilistic model (DDPM) for CBCT reconstruction using down-sampled data. A DDPM network, trained on cubes extracted from paired fully sampled sinograms and down-sampled sinograms, is employed to inpaint down-sampled sinograms. Our method divides the ent
    
[^59]: 对抗攻击的测试时间防御：基于遮蔽自编码器的对抗样本检测和重构

    Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder. (arXiv:2303.12848v1 [cs.CV])

    [http://arxiv.org/abs/2303.12848](http://arxiv.org/abs/2303.12848)

    该方法使用遮蔽自编码器进行对抗攻击检测和重构，不需要在测试时间更新模型权重，也不需要使用更多的对抗样本来增强训练集。

    

    现有的对抗攻击防御方法可以分为训练时间和测试时间防御。训练时间防御需要大量的额外训练时间，通常无法推广到未见过的攻击。而测试时间防御需要访问（部分）模型权重以执行梯度下降，这对于冻结权重的模型可能不可行。为了解决这些挑战，我们提出了一种新的防御方法DRAM，它使用遮蔽自编码器（MAE）检测并重构多种类型的对抗攻击。我们演示了如何使用MAE损失构建KS测试来检测对抗攻击。此外，MAE损失可以用于修复未见攻击类型的对抗样本。因此，DRAM既不需要在测试时间更新模型权重，也不需要使用更多的对抗样本来增强训练集。在大规模的ImageN数据集上评估DRAM，实验结果表明其具有很高的鲁棒性和有效性。

    Existing defense methods against adversarial attacks can be categorized into training time and test time defenses. Training time defense, i.e., adversarial training, requires a significant amount of extra time for training and is often not able to be generalized to unseen attacks. On the other hand, test time defense by test time weight adaptation requires access to perform gradient descent on (part of) the model weights, which could be infeasible for models with frozen weights. To address these challenges, we propose DRAM, a novel defense method to Detect and Reconstruct multiple types of Adversarial attacks via Masked autoencoder (MAE). We demonstrate how to use MAE losses to build a KS-test to detect adversarial attacks. Moreover, the MAE losses can be used to repair adversarial samples from unseen attack types. In this sense, DRAM neither requires model weight updates in test time nor augments the training set with more adversarial samples. Evaluating DRAM on the large-scale ImageN
    
[^60]: DPPMask：基于确定性点过程的遮盖图像建模方法

    DPPMask: Masked Image Modeling with Determinantal Point Processes. (arXiv:2303.12736v1 [cs.CV])

    [http://arxiv.org/abs/2303.12736](http://arxiv.org/abs/2303.12736)

    本文提出了一种简单有效的遮盖图像建模方法DPPMask，用确定性点过程（DPPs）替换了随机过程以减少遮盖后图像的语义变化，从而在多个基准数据集上显著改善了代表性能。

    

    遮盖图像建模（MIM）旨在重建随机遮盖的图像，并已取得了令人瞩目的代表性能。尽管具有实证效果，但大多数先前的工作忽略了一个重要事实，即强制模型重建超出恢复范围的物体（如那些被遮盖的物体）是不合理的。本文中，我们展示了先前工作中广泛使用的均匀随机遮盖不可避免地丢失一些关键物体并更改原始语义信息，从而导致了一种不对齐问题并最终伤害了代表性学习。为了解决这个问题，我们将确定性点过程（DPPs）替换为随机过程，提出了一个新的遮盖策略，即DPPMask，以减少遮盖后图像的语义变化。我们的方法简单而有效，实现时不需要额外的可学习参数。我们特别在两个代表性的MIM框架，MASK和GMS上对我们的方法进行了评估，结果在几个基准数据集上显著改善了代表性能。

    Masked Image Modeling (MIM) has achieved impressive representative performance with the aim of reconstructing randomly masked images. Despite the empirical success, most previous works have neglected the important fact that it is unreasonable to force the model to reconstruct something beyond recovery, such as those masked objects. In this work, we show that uniformly random masking widely used in previous works unavoidably loses some key objects and changes original semantic information, resulting in a misalignment problem and hurting the representative learning eventually. To address this issue, we augment MIM with a new masking strategy namely the DPPMask by substituting the random process with Determinantal Point Process (DPPs) to reduce the semantic change of the image after masking. Our method is simple yet effective and requires no extra learnable parameters when implemented within various frameworks. In particular, we evaluate our method on two representative MIM frameworks, MA
    
[^61]: 智能化的民主化：多种含义、目标和方法

    Democratising AI: Multiple Meanings, Goals, and Methods. (arXiv:2303.12642v1 [cs.AI])

    [http://arxiv.org/abs/2303.12642](http://arxiv.org/abs/2303.12642)

    这篇论文探讨了AI的民主化，包括四种类型的民主化：AI使用的民主化，AI开发的民主化，AI利润的民主化，和AI治理的民主化。要想实现有效的政策和权衡讨论，需要认识到AI治理的民主化在决策中扮演着重要的角色。

    

    许多人呼吁实现AI的民主化，但这个词语用来指代多种目标，有时会相互冲突。本文确定了通常讨论的四种AI民主化类型：(1) AI使用的民主化，(2) AI开发的民主化，(3) AI利润的民主化，和(4) AI治理的民主化。本文讨论了实现每种民主化形式的多个目标和方法。从本文中主要得出的结论是，AI的民主化是一个多元而有时会相互冲突的概念，不应混淆AI可访问性的改善。如果我们想要超越对智能化民主化的模糊承诺，进入具体政策和权衡的生产性讨论，我们需要认识到AI治理的民主化在跨越关于使用、开发和利润的决策中导航权衡和风险的主要作用。

    Numerous parties are calling for the democratisation of AI, but the phrase is used to refer to a variety of goals, the pursuit of which sometimes conflict. This paper identifies four kinds of AI democratisation that are commonly discussed: (1) the democratisation of AI use, (2) the democratisation of AI development, (3) the democratisation of AI profits, and (4) the democratisation of AI governance. Numerous goals and methods of achieving each form of democratisation are discussed. The main takeaway from this paper is that AI democratisation is a multifarious and sometimes conflicting concept that should not be conflated with improving AI accessibility. If we want to move beyond ambiguous commitments to democratising AI, to productive discussions of concrete policies and trade-offs, then we need to recognise the principal role of the democratisation of AI governance in navigating tradeoffs and risks across decisions around use, development, and profits.
    
[^62]: 通过小波神经算子实现Transformers的多尺度注意力机制

    Multiscale Attention via Wavelet Neural Operators for Vision Transformers. (arXiv:2303.12398v1 [cs.CV])

    [http://arxiv.org/abs/2303.12398](http://arxiv.org/abs/2303.12398)

    本文介绍了一种基于小波神经算子的多尺度注意力机制，它通过使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内，取得了比ViT和AFNO更显著的性能提高。

    

    Transformer在计算机视觉中取得了广泛的成功。其核心是自注意机制（SA），它是一种归纳偏见，通过加权基础将输入中的每个token与每个其他token相关联。标准的SA机制具有二次复杂度，难以处理高分辨率图像中出现的长序列。为此，我们引入了基于小波神经算子的Multiscale Wavelet Attention（MWA），使用小波神经算子将注意力机制从局部扩展到全域和多尺度范围内。我们用CIFAR和ImageNet进行了实验，结果表明，MWA比ViT和AFNO都表现出显著的性能提高。

    Transformers have achieved widespread success in computer vision. At their heart, there is a Self-Attention (SA) mechanism, an inductive bias that associates each token in the input with every other token through a weighted basis. The standard SA mechanism has quadratic complexity with the sequence length, which impedes its utility to long sequences appearing in high resolution vision. Recently, inspired by operator learning for PDEs, Adaptive Fourier Neural Operators (AFNO) were introduced for high resolution attention based on global convolution that is efficiently implemented via FFT. However, the AFNO global filtering cannot well represent small and moderate scale structures that commonly appear in natural images. To leverage the coarse-to-fine scale structures we introduce a Multiscale Wavelet Attention (MWA) by leveraging wavelet neural operators which incurs linear complexity in the sequence size. We replace the attention in ViT with MWA and our experiments with CIFAR and ImageN
    
[^63]: 带有重尾噪声的随机非光滑凸优化

    Stochastic Nonsmooth Convex Optimization with Heavy-Tailed Noises. (arXiv:2303.12277v1 [math.OC])

    [http://arxiv.org/abs/2303.12277](http://arxiv.org/abs/2303.12277)

    本文分析了具有重尾噪声的随机非光滑凸优化问题，并填补了在函数非光滑场景下的研究空白。

    

    最近，一些研究将随机优化问题考虑在重尾噪声范式下，即假设随机梯度和真实梯度之间的差异具有有限的 $p$ 阶矩（例如被某个 $\sigma \geq0$ 上界限制为 $\sigma^{p}$），其中 $p\in (1,2]$，这不仅泛化了传统的有限方差假设（$p=2$），而且在许多不同的任务中都被观察到。在这个具有挑战性的假设下，针对凸或非凸问题已经取得了很多新进展，然而，大多数只考虑光滑的目标函数。相反，在函数非光滑时，人们尚未充分探索并完全理解这个问题。本文旨在通过对带有重尾噪声的随机非光滑凸优化提供全面分析来填补这一关键空白。我们重新考虑了一个简单的基于裁剪的算法，然而，这个算法只被证明能以期望方式收敛，但在附加

    Recently, several studies consider the stochastic optimization problem but in a heavy-tailed noise regime, i.e., the difference between the stochastic gradient and the true gradient is assumed to have a finite $p$-th moment (say being upper bounded by $\sigma^{p}$ for some $\sigma\geq0$) where $p\in(1,2]$, which not only generalizes the traditional finite variance assumption ($p=2$) but also has been observed in practice for several different tasks. Under this challenging assumption, lots of new progress has been made for either convex or nonconvex problems, however, most of which only consider smooth objectives. In contrast, people have not fully explored and well understood this problem when functions are nonsmooth. This paper aims to fill this crucial gap by providing a comprehensive analysis of stochastic nonsmooth convex optimization with heavy-tailed noises. We revisit a simple clipping-based algorithm, whereas, which is only proved to converge in expectation but under the additi
    
[^64]: 潜在图推断中的模型空间投影。

    Projections of Model Spaces for Latent Graph Inference. (arXiv:2303.11754v1 [cs.LG])

    [http://arxiv.org/abs/2303.11754](http://arxiv.org/abs/2303.11754)

    本文将双曲和球形模型空间的立体投影以及Riemannian隐空间的乘积应用于潜在图推断，实现了与非投影空间相当的性能并提供理论保证。

    

    图神经网络利用图的连接结构作为归纳偏差。潜在图推断关注于学习一个合适的图结构来扩散信息并提高模型的下游性能。本文利用双曲和球形模型空间的立体投影，以及Riemannian隐空间的乘积，用于潜在图推断。在避免曲率趋于零时空间发散的理论保证下，立体投影模型空间能实现与非投影对应模型空间相当的性能。我们在同构和异构图上进行实验。

    Graph Neural Networks leverage the connectivity structure of graphs as an inductive bias. Latent graph inference focuses on learning an adequate graph structure to diffuse information on and improve the downstream performance of the model. In this work we employ stereographic projections of the hyperbolic and spherical model spaces, as well as products of Riemannian manifolds, for the purpose of latent graph inference. Stereographically projected model spaces achieve comparable performance to their non-projected counterparts, while providing theoretical guarantees that avoid divergence of the spaces when the curvature tends to zero. We perform experiments on both homophilic and heterophilic graphs.
    
[^65]: 特征相邻多保真物理学习用于偏微分方程

    Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations. (arXiv:2303.11577v1 [cs.LG])

    [http://arxiv.org/abs/2303.11577](http://arxiv.org/abs/2303.11577)

    提出了一种基于特征相邻的多保真体系结构，通过共享低保真度和高保真度解决方案的特征空间来减少或消除对高精度数据的依赖，这在解决复杂问题时具有重要意义。

    

    物理学习神经网络已成为求解偏微分方程的备选方法。然而，对于复杂问题，这种网络的训练仍然需要高精度的数据，而这些数据的生成成本可能很高。为了减少甚至消除对高保真数据的依赖，我们提出了一种基于特征空间的多保真体系结构，该空间由低保真度和高保真度解决方案共享。在特征空间中，低精度和高精度解决方案的投影相邻，并通过约束它们的相对距离来实现。特征空间由编码器表示，其映射到原始解空间通过解码器实现。所提出的多保真方法在由偏微分方程描述的定态和非定态问题的正问题和逆问题上进行了验证。

    Physics-informed neural networks have emerged as an alternative method for solving partial differential equations. However, for complex problems, the training of such networks can still require high-fidelity data which can be expensive to generate. To reduce or even eliminate the dependency on high-fidelity data, we propose a novel multi-fidelity architecture which is based on a feature space shared by the low- and high-fidelity solutions. In the feature space, the projections of the low-fidelity and high-fidelity solutions are adjacent by constraining their relative distance. The feature space is represented with an encoder and its mapping to the original solution space is effected through a decoder. The proposed multi-fidelity approach is validated on forward and inverse problems for steady and unsteady problems described by partial differential equations.
    
[^66]: SIFT: 稀疏等FLOP转换以最大限度提高训练效率

    SIFT: Sparse Iso-FLOP Transformations for Maximizing Training Efficiency. (arXiv:2303.11525v1 [cs.LG])

    [http://arxiv.org/abs/2303.11525](http://arxiv.org/abs/2303.11525)

    本研究提出了一种名为SIFT的方法，用于提高深度神经网络的训练效率、准确性和表示能力，通过稀疏等FLOP转换，缩短训练时间。

    

    最近的研究探索了使用权重稀疏性来改善深度神经网络（DNN）的训练效率（与训练FLOPS相关的测试准确性）。 这些工作旨在减少训练FLOP，但使用稀疏权重进行训练通常会导致准确性损失或需要更长的训练周期，使得结果的训练效率不够清晰。 相比之下，我们专注于使用稀疏性提高准确性，同时使用与密集模型相同的FLOPS，并通过更高的准确性展示训练效率提高。 在本文中，我们介绍了SIFT，一组用作密集层的即插即用替代品来提高其表示能力和FLOP效率的稀疏等FLOP转换。 每个转换都由一个单一参数（稀疏级别）参数化，并提供更大的搜索空间以找到最佳的稀疏掩膜。

    Recent works have explored the use of weight sparsity to improve the training efficiency (test accuracy w.r.t training FLOPs) of deep neural networks (DNNs). These works aim to reduce training FLOPs but training with sparse weights often leads to accuracy loss or requires longer train schedules, making the resulting training efficiency less clear. In contrast, we focus on using sparsity to increase accuracy while using the same FLOPS as the dense model and show training efficiency gains through higher accuracy. In this work, we introduce SIFT, a family of Sparse Iso-FLOP Transformations which are used as drop-in replacements for dense layers to improve their representational capacity and FLOP efficiency. Each transformation is parameterized by a single parameter (sparsity level) and provides a larger search space to find optimal sparse masks. Without changing any training hyperparameters, replacing dense layers with SIFT leads to significant improvements across computer vision (CV) and
    
[^67]: STDLens：基于模型挟持的物体检测联邦学习的安全防护方法

    STDLens: Model Hijacking-resilient Federated Learning for Object Detection. (arXiv:2303.11511v1 [cs.CR])

    [http://arxiv.org/abs/2303.11511](http://arxiv.org/abs/2303.11511)

    STDLens 是一种可以防止FL受到模型挟持的攻击的安全方法。它基于三层的取证框架来识别和排除特殊的梯度，并恢复FL的性能。STDLens在物体检测方面实现了最先进的性能并且具有防止模型挟持的鲁棒性。

    

    联邦学习（FL）作为协同学习框架在分布式客户端中训练基于深度学习的物体检测模型已经越来越受欢迎。尽管它具有诸多优点，FL容易受到模型挟持的攻击。攻击者可以仅仅利用一小部分可以被攻击的客户端控制物体检测系统的正确性，通过植入特殊梯度实现攻击。本文提出了一种名为STDLens的安全方法以保护FL免受此类攻击。我们首先调查现有的缓解机制并分析它们在空间聚类分析梯度时由于固有误差而产生的失败情况。基于这些洞见，我们提出了一个三层的取证框架来识别和排除这种特殊的梯度，并在FL过程中恢复性能。我们考虑了三种类型的自适应攻击，并展示了STDLens对高级对手具有的稳健性。大量实验表明，STDLens在物体检测方面实现了最先进的性能，并且具有防止模型挟持的鲁棒性。

    Federated Learning (FL) has been gaining popularity as a collaborative learning framework to train deep learning-based object detection models over a distributed population of clients. Despite its advantages, FL is vulnerable to model hijacking. The attacker can control how the object detection system should misbehave by implanting Trojaned gradients using only a small number of compromised clients in the collaborative learning process. This paper introduces STDLens, a principled approach to safeguarding FL against such attacks. We first investigate existing mitigation mechanisms and analyze their failures caused by the inherent errors in spatial clustering analysis on gradients. Based on the insights, we introduce a three-tier forensic framework to identify and expel Trojaned gradients and reclaim the performance over the course of FL. We consider three types of adaptive attacks and demonstrate the robustness of STDLens against advanced adversaries. Extensive experiments show that STD
    
[^68]: 利用循环神经网络研究拓扑序

    Investigating Topological Order using Recurrent Neural Networks. (arXiv:2303.11207v2 [cond-mat.str-el] UPDATED)

    [http://arxiv.org/abs/2303.11207](http://arxiv.org/abs/2303.11207)

    本研究通过循环神经网络有效地捕获了多体哈密顿量中的拓扑序，进一步证明了循环神经网络波函数是研究物态相的一个有力工具。

    

    循环神经网络被用于自然语言处理，但它在描述强关联量子多体系统方面也很有前途。本研究利用二维循环神经网络研究了两个典型展现拓扑序的多体哈密顿量。具体来说，我们证明了循环神经网络波函数可以通过估算其拓扑纠缠熵，有效地捕获扭曲编码和蜂巢格上 Bose-Hubbard 自旋液体的拓扑序。我们还发现，循环神经网络更倾向于利用很少纠缠状态的相干叠加。总的来说，我们的研究表明，循环神经网络波函数是研究不对称破缺之外物态相的强有力工具。

    Recurrent neural networks (RNNs), originally developed for natural language processing, hold great promise for accurately describing strongly correlated quantum many-body systems. Here, we employ 2D RNNs to investigate two prototypical quantum many-body Hamiltonians exhibiting topological order. Specifically, we demonstrate that RNN wave functions can effectively capture the topological order of the toric code and a Bose-Hubbard spin liquid on the kagome lattice by estimating their topological entanglement entropies. We also find that RNNs favor coherent superpositions of minimally-entangled states over minimally-entangled states themselves. Overall, our findings demonstrate that RNN wave functions constitute a powerful tool to study phases of matter beyond Landau's symmetry-breaking paradigm.
    
[^69]: 不看就能旋转: 通过触觉实现手部灵活性

    Rotating without Seeing: Towards In-hand Dexterity through Touch. (arXiv:2303.10880v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.10880](http://arxiv.org/abs/2303.10880)

    本研究提出了一种新系统Touch Dexterity，通过密集二进制力传感器实现了多指机器人手不看就能旋转物体，同时大大降低了成本和与实际应用的差距。

    

    触感信息在人类灵巧性中扮演着至关重要的角色，它可以提供有用的接触信息，直接从视觉中无法推断。这篇论文探讨了是否能够使多指机器人手具备与人类类似的不看就能旋转物体的能力。作者们提出了一个新的系统Touch Dexterity，通过使用覆盖整个机器人手的密集二进制力传感器（触摸或未触摸）代替仅仅在小区域内进行精准的触觉传感，使系统具有低成本、覆盖范围广等优点，并通过强化学习在多样的物体模拟中训练出了一种触感旋转策略，能够在真实的机器人手上直接实施不看就能旋转新型物体。

    Tactile information plays a critical role in human dexterity. It reveals useful contact information that may not be inferred directly from vision. In fact, humans can even perform in-hand dexterous manipulation without using vision. Can we enable the same ability for the multi-finger robot hand? In this paper, we present Touch Dexterity, a new system that can perform in-hand object rotation using only touching without seeing the object. Instead of relying on precise tactile sensing in a small region, we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time. We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects tha
    
[^70]: 随机插值：流和扩散的统一框架

    Stochastic Interpolants: A Unifying Framework for Flows and Diffusions. (arXiv:2303.08797v1 [cs.LG])

    [http://arxiv.org/abs/2303.08797](http://arxiv.org/abs/2303.08797)

    本文提出了一种统一的生成模型，该模型基于随机插值框架，可以实现流和扩散方法的统一。作者构建了一类广泛的连续时间随机过程，用于将两个任意的密度在有限时间内精确地连接。这种方法可以用于基于概率微分方程的确定性和随机生成模型的构建。

    

    我们介绍了一类建立在随机插值框架上的生成模型，该框架是基于Albergo＆Vanden-Eijnden（2023）提出的，在流和扩散方法上实现统一，我们首先展示了如何构建一类广泛的连续时间随机过程，其时间依赖的概率密度函数在有限时间内精确地连接两个任意的密度。这些“随机插值器”是通过将来自两个密度的数据与其他潜在变量相结合构建的，并且构造的具体细节可以灵活地塑造导致的时间依赖密度。然后我们展示了随机插值器的时间依赖密度满足一阶输运方程以及一系列具有可调扩散的正向和反向Fokker-Planck方程族; 在考虑单个样本的时间演化时，这个观点立即导致了基于概率微分方程的确定性和随机生成模型。

    We introduce a class of generative models based on the stochastic interpolant framework proposed in Albergo & Vanden-Eijnden (2023) that unifies flow-based and diffusion-based methods. We first show how to construct a broad class of continuous-time stochastic processes whose time-dependent probability density function bridges two arbitrary densities exactly in finite time. These `stochastic interpolants' are built by combining data from the two densities with an additional latent variable, and the specific details of the construction can be leveraged to shape the resulting time-dependent density in a flexible way. We then show that the time-dependent density of the stochastic interpolant satisfies a first-order transport equation as well as a family of forward and backward Fokker-Planck equations with tunable diffusion; upon consideration of the time evolution of an individual sample, this viewpoint immediately leads to both deterministic and stochastic generative models based on proba
    
[^71]: 使用复值神经场的物理信息光学核回归

    Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields. (arXiv:2303.08435v1 [cs.CV])

    [http://arxiv.org/abs/2303.08435](http://arxiv.org/abs/2303.08435)

    本文提出了一种新的基于机器学习的光刻模型范式，通过优化复值神经场执行光学核回归并将光刻系统拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核，使用小规模训练数据集展示了卓越的推广能力。

    

    光刻是集成电路制造的基础，需要大量计算。基于机器学习的光刻模型的发展缓解了制造过程开销和能力之间的平衡。然而，所有以前的方法都将光刻系统视为图像到图像的黑盒映射，利用网络参数通过死记硬背映射大量的掩模到空中或掩模到电阻图像对，导致推广能力不佳。本文提出了一种新的基于机器学习的范式，将严格的光刻模型拆解为非参数掩模操作和包含行列式源、瞳孔和光刻信息的学习光学核。通过优化复值神经场以执行光学核回归，我们的方法可以准确地恢复光刻系统，同时使用较少的参数进行小规模训练数据集，展示了卓越的推广能力。

    Lithography is fundamental to integrated circuit fabrication, necessitating large computation overhead. The advancement of machine learning (ML)-based lithography models alleviates the trade-offs between manufacturing process expense and capability. However, all previous methods regard the lithography system as an image-to-image black box mapping, utilizing network parameters to learn by rote mappings from massive mask-to-aerial or mask-to-resist image pairs, resulting in poor generalization capability. In this paper, we propose a new ML-based paradigm disassembling the rigorous lithographic model into non-parametric mask operations and learned optical kernels containing determinant source, pupil, and lithography information. By optimizing complex-valued neural fields to perform optical kernel regression from coordinates, our method can accurately restore lithography system using a small-scale training dataset with fewer parameters, demonstrating superior generalization capability as w
    
[^72]: 人工智能用于人造材料：Moiré原子

    Artificial intelligence for artificial materials: moir\'e atom. (arXiv:2303.08162v1 [cond-mat.str-el])

    [http://arxiv.org/abs/2303.08162](http://arxiv.org/abs/2303.08162)

    研究者使用二维费米神经网络解决了Moiré工程中Moiré原子中电子的相互作用问题，并发现强Coulomb相互作用与各向异性Moiré势能相结合可以产生“Wigner分子”电荷密度分布。

    

    原子薄层Van der Waals异质结构中的Moiré工程创建了具有设计师属性的人造量子材料。我们使用2D费米神经网络解决了相互作用电子受限于Moiré超晶格势能最小值（Moiré原子）的多体问题。我们证明强Coulomb相互作用与各向异性Moiré势能相结合，可以产生“Wigner分子”电荷密度分布，可通过扫描隧道显微镜观察到。

    Moir\'e engineering in atomically thin van der Waals heterostructures creates artificial quantum materials with designer properties. We solve the many-body problem of interacting electrons confined to a moir\'e superlattice potential minimum (the moir\'e atom) using a 2D fermionic neural network. We show that strong Coulomb interactions in combination with the anisotropic moir\'e potential lead to striking ``Wigner molecule" charge density distributions observable with scanning tunneling microscopy.
    
[^73]: 机器人导航的音视语言地图

    Audio Visual Language Maps for Robot Navigation. (arXiv:2303.07522v1 [cs.RO])

    [http://arxiv.org/abs/2303.07522](http://arxiv.org/abs/2303.07522)

    该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。

    

    与世界的互动是一种多感官的体验，但是许多机器人仍然主要依赖视觉感知来绘制和导航他们的环境。本文提出了音视语言地图(AVLMaps)，这是一个统一的3D空间地图表示，用于存储来自音频、视觉和语言线索的跨模态信息。在导航的情境下，我们展示了AVLMaps能够使机器人系统根据多模态查询(例如，文本描述、图像或地标的音频片段)在地图中索引目标。特别是，添加音频信息使机器人能够更可靠地消除目标位置的歧义性。在模拟实验中，我们展示了AVLMaps能够实现从多模态提示进行零次学习的多模态目标导航，并在模糊场景中提供50%更好的召回率。

    While interacting in the world is a multi-sensory experience, many robots continue to predominantly rely on visual perception to map and navigate in their environments. In this work, we propose Audio-Visual-Language Maps (AVLMaps), a unified 3D spatial map representation for storing cross-modal information from audio, visual, and language cues. AVLMaps integrate the open-vocabulary capabilities of multimodal foundation models pre-trained on Internet-scale data by fusing their features into a centralized 3D voxel grid. In the context of navigation, we show that AVLMaps enable robot systems to index goals in the map based on multimodal queries, e.g., textual descriptions, images, or audio snippets of landmarks. In particular, the addition of audio information enables robots to more reliably disambiguate goal locations. Extensive experiments in simulation show that AVLMaps enable zero-shot multimodal goal navigation from multimodal prompts and provide 50% better recall in ambiguous scenar
    
[^74]: 多个学习智能体与基于智能体的市场模型的交互

    Many learning agents interacting with an agent-based market model. (arXiv:2303.07393v1 [q-fin.TR])

    [http://arxiv.org/abs/2303.07393](http://arxiv.org/abs/2303.07393)

    本论文介绍了多个强化学习最优执行交易智能体与反应式基于智能体的金融市场模型的交互。通过平衡执行差价和未能及时执行订单的惩罚，说明了奖励函数的作用。研究表明，学习智能体的数量、初始订单大小和状态空间的变化，会对最小智能市场模拟造成不同的影响。

    

    本文考虑了多个强化学习最优执行交易智能体与在事件时间下的反应式基于智能体的金融市场模型的动态和相互作用。模型代表了一个市场生态系统，由三个营养级别代表：最优执行学习智能体，最小智能的流动性需要者和快速的电子流动性提供者。最优执行代理类别包括买入和卖出代理，可以使用限价单和市价单的组合，或者仅使用市价单进行交易。奖励函数明确平衡了交易执行差价与未能及时执行订单的惩罚之间的关系。本文展示了多个竞争学习智能体如何随着智能体数量、初始订单的大小和用于学习的状态空间的函数影响最小智能市场模拟。我们使用相空间图来研究ABM的动态，当特定规范被应用

    We consider the dynamics and the interactions of multiple reinforcement learning optimal execution trading agents interacting with a reactive Agent-Based Model (ABM) of a financial market in event time. The model represents a market ecology with 3-trophic levels represented by: optimal execution learning agents, minimally intelligent liquidity takers, and fast electronic liquidity providers. The optimal execution agent classes include buying and selling agents that can either use a combination of limit orders and market orders, or only trade using market orders. The reward function explicitly balances trade execution slippage against the penalty of not executing the order timeously. This work demonstrates how multiple competing learning agents impact a minimally intelligent market simulation as functions of the number of agents, the size of agents' initial orders, and the state spaces used for learning. We use phase space plots to examine the dynamics of the ABM, when various specifica
    
[^75]: 基于区域的联邦学习用于移动感知数据

    Zone-based Federated Learning for Mobile Sensing Data. (arXiv:2303.06246v1 [cs.LG])

    [http://arxiv.org/abs/2303.06246](http://arxiv.org/abs/2303.06246)

    本文提出了一种基于区域的联邦学习方法，用于训练移动感知数据的深度学习模型。该方法将物理空间划分为地理区域，并映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，能够很好地适应该区域用户的数据和行为，并保护用户数据隐私。

    This paper proposes a zone-based federated learning method for training deep learning models with mobile sensing data. The method divides the physical space into geographical zones and maps them to a mobile-edge-cloud system architecture for good model accuracy and scalability. Each zone has a federated training model that adapts well to the data and behaviors of users in that zone, while protecting user data privacy.

    移动应用程序，如mHealth和健康应用程序，可以从使用智能手机或可穿戴设备收集的移动感知数据训练的深度学习（DL）模型中受益。然而，目前没有移动感知DL系统能够同时实现良好的模型准确性，适应用户的移动行为，随着用户数量的增加而扩展，并保护用户数据隐私。我们提出了基于区域的联邦学习（ZoneFL）来解决这些要求。ZoneFL将物理空间划分为地理区域，映射到移动边缘云系统架构，以实现良好的模型准确性和可扩展性。每个区域都有一个联合训练模型，称为区域模型，它能够很好地适应该区域用户的数据和行为。受益于FL设计，ZoneFL培训期间保护用户数据隐私。我们提出了两种新颖的基于区域的联合训练算法来优化区域模型以适应用户的移动行为：区域合并和分裂（ZMS）和Zo

    Mobile apps, such as mHealth and wellness applications, can benefit from deep learning (DL) models trained with mobile sensing data collected by smart phones or wearable devices. However, currently there is no mobile sensing DL system that simultaneously achieves good model accuracy while adapting to user mobility behavior, scales well as the number of users increases, and protects user data privacy. We propose Zone-based Federated Learning (ZoneFL) to address these requirements. ZoneFL divides the physical space into geographical zones mapped to a mobile-edge-cloud system architecture for good model accuracy and scalability. Each zone has a federated training model, called a zone model, which adapts well to data and behaviors of users in that zone. Benefiting from the FL design, the user data privacy is protected during the ZoneFL training. We propose two novel zone-based federated training algorithms to optimize zone models to user mobility behavior: Zone Merge and Split (ZMS) and Zo
    
[^76]: 低开销模型剪枝：面向联邦学习的补充稀疏化

    Complement Sparsification: Low-Overhead Model Pruning for Federated Learning. (arXiv:2303.06237v1 [cs.LG])

    [http://arxiv.org/abs/2303.06237](http://arxiv.org/abs/2303.06237)

    本文提出了一种名为补充稀疏化的模型剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足联邦学习中低双向通信开销、客户端低计算开销和良好模型准确性的要求。

    This paper proposes a model pruning mechanism called Complement Sparsification (CS), which satisfies the requirements of low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy in federated learning through complementary and collaborative pruning done at the server and the clients.

    联邦学习（FL）是一种隐私保护的分布式深度学习范例，涉及大量通信和计算工作，这对于资源受限的移动和物联网设备是一个问题。模型剪枝/稀疏化开发了可以解决此问题的稀疏模型，但现有的稀疏化解决方案不能同时满足服务器和客户端之间低双向通信开销、客户端低计算开销和良好模型准确性的要求，在FL假设下，服务器无法访问原始数据以微调修剪的模型。我们提出了补充稀疏化（CS），这是一种剪枝机制，通过在服务器和客户端之间进行互补和协作的剪枝来满足所有这些要求。在每一轮中，CS创建一个全局稀疏模型，其中包含捕获所有客户端的一般数据分布的权重，而客户端则创建本地稀疏模型。

    Federated Learning (FL) is a privacy-preserving distributed deep learning paradigm that involves substantial communication and computation effort, which is a problem for resource-constrained mobile and IoT devices. Model pruning/sparsification develops sparse models that could solve this problem, but existing sparsification solutions cannot satisfy at the same time the requirements for low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy, under the FL assumption that the server does not have access to raw data to fine-tune the pruned models. We propose Complement Sparsification (CS), a pruning mechanism that satisfies all these requirements through a complementary and collaborative pruning done at the server and the clients. At each round, CS creates a global sparse model that contains the weights that capture the general data distribution of all clients, while the clients create local sparse model
    
[^77]: 金融自然语言理解任务中的模型无关元学习

    Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in Finance. (arXiv:2303.02841v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02841](http://arxiv.org/abs/2303.02841)

    本文研究了金融领域自然语言理解任务中的模型无关元学习算法，取得了最先进的性能表现。

    

    金融领域的自然语言理解因缺乏标注数据和特殊语言而具有挑战性。近年来，研究人员提出使用预训练语言模型和多任务学习来学习稳健的表示。然而，过度微调经常导致过拟合，多任务学习可能会偏袒大量数据的任务。为了解决这些问题，本文研究了低资源金融自然语言理解任务中的模型无关元学习算法。我们的贡献包括：1.我们探索了使用多种类型任务的MAML方法的性能：GLUE数据集，SNLI，Sci-Tail和Financial PhraseBank；2.我们研究了在一个真实场景的基于推特文本的股票价格预测问题中使用MAML方法的性能。根据实验结果，我们的模型实现了最先进的性能，证明了我们的方法可以快速适应。

    Natural language understanding(NLU) is challenging for finance due to the lack of annotated data and the specialized language in that domain. As a result, researchers have proposed to use pre-trained language model and multi-task learning to learn robust representations. However, aggressive fine-tuning often causes over-fitting and multi-task learning may favor tasks with significantly larger amounts data, etc. To address these problems, in this paper, we investigate model-agnostic meta-learning algorithm(MAML) in low-resource financial NLU tasks. Our contribution includes: 1. we explore the performance of MAML method with multiple types of tasks: GLUE datasets, SNLI, Sci-Tail and Financial PhraseBank; 2. we study the performance of MAML method with multiple single-type tasks: a real scenario stock price prediction problem with twitter text data. Our models achieve the state-of-the-art performance according to the experimental results, which demonstrate that our method can adapt fast a
    
[^78]: 意义的线性空间：视觉语言模型中的组合结构

    Linear Spaces of Meanings: Compositional Structures in Vision-Language Models. (arXiv:2302.14383v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14383](http://arxiv.org/abs/2302.14383)

    本文研究了视觉语言模型中的组合结构，并提出了一种使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式的方法，将这些向量视为“理想单词”，并在CLIP的嵌入中以实验方式探索了这些结构的可用性。

    

    本文研究了预训练视觉语言模型（VLM）中的数据嵌入的组合结构。传统上，组合性与预先存在的词汇表中的单词嵌入的代数运算有关。相反，我们试图使用嵌入空间中较小集合的向量组合来近似表示来自编码器的表示形式。这些向量可以被看作是在模型的嵌入空间中直接生成概念的“理想单词”。我们首先从几何学的角度提出了理解组合结构的框架。然后，我们解释了VLM嵌入在概率上的这些组合结构的含义，并提供了它们在实践中产生的直觉。最后，我们在CLIP的嵌入中以实验方式探索了这些结构，并评估了它们在解决分类、去偏和检索等不同视觉语言任务中的有用性。我们的结果表明，嵌入空间中简单的线性代数运算可以实现与更复杂的方法相媲美甚至更好的性能，证明了所提出的意义的线性空间的有效性和可解释性。

    We investigate compositional structures in data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on embeddings of words from a pre-existing vocabulary. In contrast, we seek to approximate representations from an encoder as combinations of a smaller set of vectors in the embedding space. These vectors can be seen as "ideal words" for generating concepts directly within the embedding space of the model. We first present a framework for understanding compositional structures from a geometric perspective. We then explain what these compositional structures entail probabilistically in the case of VLM embeddings, providing intuitions for why they arise in practice. Finally, we empirically explore these structures in CLIP's embeddings and we evaluate their usefulness for solving different vision-language tasks such as classification, debiasing, and retrieval. Our results show that simple linear algebraic o
    
[^79]: VoxFormer： 基于稀疏体素变换的基于相机的三维语义场景补全

    VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion. (arXiv:2302.12251v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12251](http://arxiv.org/abs/2302.12251)

    VoxFormer是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。它采用两阶段设计，从可见的体素查询开始，并通过自我注意来传播信息，实现了有效的三维场景补全。

    

    人类很容易想象被遮挡物体和场景的完整三维几何形状，在识别和理解方面至关重要。为了使AI系统具备这种能力，我们提出了VoxFormer，这是一个基于变换器的语义场景补全框架，可以仅从2D图像输出完整的三维体积语义。我们的框架采用两阶段设计，从深度估计的稀疏可见和占用体素查询开始，随后进行生成稠密3D体素的稠密化阶段。这个设计的一个关键思想是，2D图像上的视觉特征仅对应于可见场景结构而不是遮挡或空间。因此，从可见结构的特征化和预测开始更加可靠。一旦我们获得了一组稀疏查询，我们就应用掩码自编码器设计通过自我注意将信息传播到所有体素。在SemanticKITTI上的实验表明了我们的方法的有效性。

    Humans can easily imagine the complete 3D geometry of occluded objects and scenes. This appealing ability is vital for recognition and understanding. To enable such capability in AI systems, we propose VoxFormer, a Transformer-based semantic scene completion framework that can output complete 3D volumetric semantics from only 2D images. Our framework adopts a two-stage design where we start from a sparse set of visible and occupied voxel queries from depth estimation, followed by a densification stage that generates dense 3D voxels from the sparse ones. A key idea of this design is that the visual features on 2D images correspond only to the visible scene structures rather than the occluded or empty spaces. Therefore, starting with the featurization and prediction of the visible structures is more reliable. Once we obtain the set of sparse queries, we apply a masked autoencoder design to propagate the information to all the voxels by self-attention. Experiments on SemanticKITTI show th
    
[^80]: 一种用于多元正态分布Fisher-Rao距离的数值逼近方法

    A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions. (arXiv:2302.08175v5 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2302.08175](http://arxiv.org/abs/2302.08175)

    本论文提出了一种用于逼近多元正态分布Fisher-Rao距离的简单方法，通过离散化曲线连接正态分布并逼近相邻正态分布之间的Rao距离，评估了逼近技术的质量，同时介绍了一些信息几何性质。

    

    我们提出了一个简单的方法来逼近基于离散化曲线连接彼此的正态分布和逼近这些曲线上相邻正态分布之间的Rao距离，该方法基于Jeffreys离散度的平方根，即对称化的Kullback-Leibler离散度。我们实验考虑了普通、自然和期望参数化的正态分布的线性插值曲线，并将这些曲线与源自Calvo 和Oller将Fisher-Rao $d$-variate正常流形等距嵌入$(d+1)\times (d+1)$对称正定矩阵锥体的一条曲线进行比较。我们报告了我们的实验结果，并通过将数值逼近与上限和下限进行比较来评估我们逼近技术的质量。最后，我们介绍了Calvo和Oller的一些信息几何性质。

    We present a simple method to approximate Rao's distance between multivariate normal distributions based on discretizing curves joining normal distributions and approximating Rao's distances between successive nearby normal distributions on the curves by the square root of Jeffreys divergence, the symmetrized Kullback-Leibler divergence. We consider experimentally the linear interpolation curves in the ordinary, natural and expectation parameterizations of the normal distributions, and compare these curves with a curve derived from the Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal manifold into the cone of $(d+1)\times (d+1)$ symmetric positive-definite matrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on our experiments and assess the quality of our approximation technique by comparing the numerical approximations with both lower and upper bounds. Finally, we present several information-geometric properties of the Calvo and Oller'
    
[^81]: 深度学习在分子构象生成中真的表现更好吗？

    Do Deep Learning Methods Really Perform Better in Molecular Conformation Generation?. (arXiv:2302.07061v2 [cs.CE] UPDATED)

    [http://arxiv.org/abs/2302.07061](http://arxiv.org/abs/2302.07061)

    分子构象生成是药物研发中的基本问题，传统方法在不同的分子结构上有局限性。最近，有很多基于深度学习的方法称它们比传统方法优越许多。然而，这项研究发现基于传统方法的无参聚类算法与深度学习算法相媲美或更优，希望这个发现能促进MCG中深度学习方法的修正。

    

    分子构象生成是药物研发中的一个基本和重要的问题。许多传统方法已经被开发来解决MCG问题，例如系统搜索、模型构建、随机搜索、距离几何、分子动力学、蒙特卡罗方法等等。然而，它们在不同的分子结构上存在一些局限性。最近，有许多基于深度学习的MCG方法声称它们在很大程度上优于传统方法。然而，令人惊讶的是，我们设计了一个简单且廉价的算法（无需参数），基于传统方法，发现它与基于深度学习的MCG方法在广泛使用的GEOM-QM9和GEOM-Drugs基准测试中可相媲美甚至更好。特别是，我们的设计算法只是RDKIT生成构象的聚类。我们希望我们的发现能帮助社区修正MCG中的深度学习方法。所提出算法的代码可在https://gis找到。

    Molecular conformation generation (MCG) is a fundamental and important problem in drug discovery. Many traditional methods have been developed to solve the MCG problem, such as systematic searching, model-building, random searching, distance geometry, molecular dynamics, Monte Carlo methods, etc. However, they have some limitations depending on the molecular structures. Recently, there are plenty of deep learning based MCG methods, which claim they largely outperform the traditional methods. However, to our surprise, we design a simple and cheap algorithm (parameter-free) based on the traditional methods and find it is comparable to or even outperforms deep learning based MCG methods in the widely used GEOM-QM9 and GEOM-Drugs benchmarks. In particular, our design algorithm is simply the clustering of the RDKIT-generated conformations. We hope our findings can help the community to revise the deep learning methods for MCG. The code of the proposed algorithm could be found at https://gis
    
[^82]: 回顾链将语言模型与反馈对齐

    Chain of Hindsight Aligns Language Models with Feedback. (arXiv:2302.02676v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02676](http://arxiv.org/abs/2302.02676)

    该研究提出了一种新颖的技术，即回顾链，可以轻松优化，并可以从任何形式的反馈中学习，而不受其极性的影响。

    

    从人类偏好中学习对于语言模型具有重要意义，这样才能对人类有所帮助并符合人类和社会价值观。先前的研究通过从人类反馈中学习来理解和遵循指令取得了显著成功。然而，这些方法要么是基于被人类注释者喜欢的手动挑选的模型生成，使得它们在数据利用方面效果不佳且普遍应用具有挑战性，要么依赖于奖励函数和强化学习，这容易出现奖励函数不完美和极难优化的问题。在本文中，我们提出了一种新颖的技术，“回顾链”，它易于优化，并可以从任何形式的反馈中学习，而不受其极性的影响。我们的想法受到了人类如何从以语言形式呈现的广泛反馈中学习的启发。我们将所有类型的反馈转换成句子，然后用它们来微调模型，从而利用这种方法。

    Learning from human preferences is important for language models to be helpful and useful for humans, and to align with human and social values. Prior work have achieved remarkable successes by learning from human feedback to understand and follow instructions. Nonetheless, these methods are either founded on hand-picked model generations that are favored by human annotators, rendering them ineffective in terms of data utilization and challenging to apply in general, or they depend on reward functions and reinforcement learning, which are prone to imperfect reward function and extremely challenging to optimize. In this work, we propose a novel technique, Chain of Hindsight, that is easy to optimize and can learn from any form of feedback, regardless of its polarity. Our idea is inspired by how humans learn from extensive feedback presented in the form of languages. We convert all types of feedback into sentences, which are then used to fine-tune the model, allowing us to take advantage
    
[^83]: ESC：具备软件常识约束的零样本物体导航探索

    ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation. (arXiv:2301.13166v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.13166](http://arxiv.org/abs/2301.13166)

    本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。

    

    准确地定位和导航到特定物体的能力对于在现实世界中操作并与物体交互以完成任务的实体代理来说至关重要。这种物体导航任务通常需要在具有标记物体的视觉环境中进行大规模训练，这种训练效果在未知环境中的新颖物体上泛化效果较差。本文提出了一种新颖的零样本物体导航方法——具备软件常识约束的探索（ESC），它将预先训练的模型中的常识知识转移到在视觉环境上进行开放世界物体导航时不需要进行导航或其他视觉环境训练。首先，ESC利用预先训练的视觉和语言模型进行开放世界基于提示的接地，利用预先训练的常识语言模型进行房间和物体推理。然后，ESC通过将常识知识建模为软逻辑谓词来使其转化为导航动作，从而进行有效的探索。在MP3D上进行了大量实验，......

    The ability to accurately locate and navigate to a specific object is a crucial capability for embodied agents that operate in the real world and interact with objects to complete tasks. Such object navigation tasks usually require large-scale training in visual environments with labeled objects, which generalizes poorly to novel objects in unknown environments. In this work, we present a novel zero-shot object navigation method, Exploration with Soft Commonsense constraints (ESC), that transfers commonsense knowledge in pre-trained models to open-world object navigation without any navigation experience nor any other training on the visual environments. First, ESC leverages a pre-trained vision and language model for open-world prompt-based grounding and a pre-trained commonsense language model for room and object reasoning. Then ESC converts commonsense knowledge into navigation actions by modeling it as soft logic predicates for efficient exploration. Extensive experiments on MP3D, 
    
[^84]: 鉴定容易受到对抗性攻击的样本和强韧样本

    Identifying Adversarially Attackable and Robust Samples. (arXiv:2301.12896v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12896](http://arxiv.org/abs/2301.12896)

    本文提出了一种深度学习方法，用于检测哪些样本最容易受到对抗性攻击，从而确定哪些样本最不容易受到攻击。实验结果表明，这种检测器在不同的模型结构中具有较好的可移植性和检测性能。

    

    对抗性攻击将微小的，难以感知的扰动插入输入样本，导致深度学习模型的输出发生大量不期望的变化。虽然对抗性攻击的生成和防御已经得到广泛研究，但对从输入数据角度理解对抗性攻击的研究仍然很有限。本文引入了样本攻击性的概念，旨在确定最容易受到对抗性攻击的样本（攻击性样本），从而反过来确定最不容易受到攻击的样本（强韧样本）。我们提出了一种基于深度学习的方法，用于检测针对未知目标模型的未见数据集中，容易受到对抗性攻击和强韧性样本。标准图像分类数据集上的实验证实了深度攻击性检测器在不同体系结构中的可移植性。我们发现，与基于简单模型不确定性的措施相比，深度攻击性检测器表现更好。

    Adversarial attacks insert small, imperceptible perturbations to input samples that cause large, undesired changes to the output of deep learning models. Despite extensive research on generating adversarial attacks and building defense systems, there has been limited research on understanding adversarial attacks from an input-data perspective. This work introduces the notion of sample attackability, where we aim to identify samples that are most susceptible to adversarial attacks (attackable samples) and conversely also identify the least susceptible samples (robust samples). We propose a deep-learning-based method to detect the adversarially attackable and robust samples in an unseen dataset for an unseen target model. Experiments on standard image classification datasets enables us to assess the portability of the deep attackability detector across a range of architectures. We find that the deep attackability detector performs better than simple model uncertainty-based measures for i
    
[^85]: 通过对抗协作实现任务无关的图神经网络评估

    Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration. (arXiv:2301.11517v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11517](http://arxiv.org/abs/2301.11517)

    为了评估图神经网络，提出了一种通过对抗自我监督的概念性新框架，并引入了竞争性Barlow Twins目标函数，使两个GNN可以一起更新。

    

    针对分子表示学习中图神经网络（GNN）研究进展的评估需要可靠的方法的需求不断增加。现有的用于分子表示学习的GNN基准测试方法主要关注于比较GNN在某些节点/图分类/回归任务和特定数据集上的表现。然而，缺乏一种原则性、任务无关的直接比较两个GNN的方法。此外，大多数现有的自监督学习方法都会将数据手工扩增，但由于图的特殊性，这种方法存在严重的困难。为解决上述问题，我们提出了GraphAC（Graph Adversarial Collaboration），这是一种具有概念性、原则性、任务无关性和稳定性的新框架，用于通过对比自我监督来评估GNN。我们引入了竞争性 Barlow Twins 目标函数，允许两个 GNN 共同更新。

    It has been increasingly demanding to develop reliable methods to evaluate the progress of Graph Neural Network (GNN) research for molecular representation learning. Existing GNN benchmarking methods for molecular representation learning focus on comparing the GNNs' performances on some node/graph classification/regression tasks on certain datasets. However, there lacks a principled, task-agnostic method to directly compare two GNNs. Additionally, most of the existing self-supervised learning works incorporate handcrafted augmentations to the data, which has several severe difficulties to be applied on graphs due to their unique characteristics. To address the aforementioned issues, we propose GraphAC (Graph Adversarial Collaboration) -a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. We introduce a novel objective function: the Competitive Barlow Twins, that allow two GNNs to jointly update themselves from
    
[^86]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^87]: Boosting算法的并行化不可能性研究

    The Impossibility of Parallelizing Boosting. (arXiv:2301.09627v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09627](http://arxiv.org/abs/2301.09627)

    Boosting算法无法进行有效的并行化，需要指数级别的计算资源，否则并行化的效果并不显著。

    

    Boosting算法的目标是将一系列弱学习器集成成一个强学习器。然而，这些方法都是完全顺序的。本文研究了Boosting算法的并行化可能性，发现了一个强烈的负面结果，即显著的并行化需要指数级别的计算资源来完成训练。

    The aim of boosting is to convert a sequence of weak learners into a strong learner. At their heart, these methods are fully sequential. In this paper, we investigate the possibility of parallelizing boosting. Our main contribution is a strong negative result, implying that significant parallelization of boosting requires an exponential blow-up in the total computing resources needed for training.
    
[^88]: PIRLNav: 对于ObjectNav进行模仿学习和强化学习微调的预训练研究

    PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav. (arXiv:2301.07302v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07302](http://arxiv.org/abs/2301.07302)

    本文提出了PIRLNav，通过人类演示的BC预训练和RL微调两个阶段的学习方案，成功率达到ObjectNav的65.0％，比以前的最新技术高5.0％。

    

    本研究探讨了ObjectGoal Navigation——在新环境中要求虚拟机器人导航到一个物体。以前的研究表明，使用人类演示的数据集进行行为克隆（BC）的模仿学习（IL）取得了有希望的结果。然而，这种方法也存在局限性——1）由于训练只模仿动作而不是后果，因此BC策略对新状态的泛化能力较差，2）收集演示数据成本高昂。另一方面，强化学习（RL）容易扩展，但需要精心设计奖励来实现理想的行为。我们提出PIRLNav，一个两阶段的学习方案，用于对人类演示进行BC预训练，然后进行RL微调。这导致该策略在ObjectNav上实现了65.0％的成功率（绝对值比以前的最新技术高5.0％）。使用这种BC $ \rightarrow $ RL训练方法，我们对设计选择进行了严格的实证分析。首先，我们调查了使用人类演示是否可行。

    We study ObjectGoal Navigation -- where a virtual robot situated in a new environment is asked to navigate to an object. Prior work has shown that imitation learning (IL) using behavior cloning (BC) on a dataset of human demonstrations achieves promising results. However, this has limitations -- 1) BC policies generalize poorly to new states, since the training mimics actions not their consequences, and 2) collecting demonstrations is expensive. On the other hand, reinforcement learning (RL) is trivially scalable, but requires careful reward engineering to achieve desirable behavior. We present PIRLNav, a two-stage learning scheme for BC pretraining on human demonstrations followed by RL-finetuning. This leads to a policy that achieves a success rate of $65.0\%$ on ObjectNav ($+5.0\%$ absolute over previous state-of-the-art). Using this BC$\rightarrow$RL training recipe, we present a rigorous empirical analysis of design choices. First, we investigate whether human demonstrations can b
    
[^89]: 视频中的对抗空间-时间聚焦可以实现高效的强化评估

    Efficient Robustness Assessment via Adversarial Spatial-Temporal Focus on Videos. (arXiv:2301.00896v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.00896](http://arxiv.org/abs/2301.00896)

    该论文提出了一种名为AstFocus的新型攻击方法，利用视频中的时间和空间冗余来实现有效和高效的梯度估计，从而降低了对抗攻击的查询次数，该方法在对多个最先进的视频识别模型进行实验后证明了其有效性和高效性。

    

    视频识别模型的对抗鲁棒性评估引起了人们的关注，因为它们在安全关键任务中应用广泛。与图片相比，视频具有更高的维度，生成对抗视频时会带来巨大的计算成本。为了缓解这个问题，我们提出了利用视频中的时间和空间冗余来实现在缩小的搜索空间上进行有效和高效的梯度估计的方案。为了实现这个想法，我们设计了新颖的对抗空间-时间聚焦（AstFocus）攻击方法，该攻击方法从视频的帧间和帧内同时聚焦关键帧和关键区域进行攻击，基于合作的多任务学习（MTL）框架来模拟对目标模型的影响。大量实验证明了我们提出的方法的有效性和高效性，并且我们还将其应用于评估几种最先进的视频识别模型的鲁棒性。

    Adversarial robustness assessment for video recognition models has raised concerns owing to their wide applications on safety-critical tasks. Compared with images, videos have much high dimension, which brings huge computational costs when generating adversarial videos. This is especially serious for the query-based black-box attacks where gradient estimation for the threat models is usually utilized, and high dimensions will lead to a large number of queries. To mitigate this issue, we propose to simultaneously eliminate the temporal and spatial redundancy within the video to achieve an effective and efficient gradient estimation on the reduced searching space, and thus query number could decrease. To implement this idea, we design the novel Adversarial spatial-temporal Focus (AstFocus) attack on videos, which performs attacks on the simultaneously focused key frames and key regions from the inter-frames and intra-frames in the video. AstFocus attack is based on the cooperative Multi-
    
[^90]: 机器学习作为多种网络渗透阈值的精准预测器。

    Machine Learning as an Accurate Predictor for Percolation Threshold of Diverse Networks. (arXiv:2212.14694v2 [physics.soc-ph] UPDATED)

    [http://arxiv.org/abs/2212.14694](http://arxiv.org/abs/2212.14694)

    本研究展示了五种机器学习回归技术在精准预测渗透阈值方面的有效性，并证明其优于现有的合成估计器，在预测位置和爆炸性渗透时也有潜力。

    

    渗透阈值是确定大型网络内在刚度的重要度量。预测大型网络的渗透阈值是计算密集型的，因此有必要开发不依赖数值模拟的网络渗透阈值预测器。我们展示了五种基于机器学习的回归技术，用于准确预测渗透阈值。生成用于训练机器学习模型的数据集包含总共777个真实和合成网络。它包括网络的5种统计和结构性质作为特征，以及数值计算得出的渗透阈值作为输出属性。我们证明了机器学习模型优于三种现有的合成估计器的键合渗透阈值，还将此实验扩展到预测位置和爆炸性渗透。此外，我们比较了我们的模型在预测P时的表现。

    The percolation threshold is an important measure to determine the inherent rigidity of large networks. Predictors of the percolation threshold for large networks are computationally intense to run, hence it is a necessity to develop predictors of the percolation threshold of networks, that do not rely on numerical simulations. We demonstrate the efficacy of five machine learning-based regression techniques for the accurate prediction of the percolation threshold. The dataset generated to train the machine learning models contains a total of 777 real and synthetic networks. It consists of 5 statistical and structural properties of networks as features and the numerically computed percolation threshold as the output attribute. We establish that the machine learning models outperform three existing empirical estimators of bond percolation threshold, and extend this experiment to predict site and explosive percolation. Further, we compared the performance of our models in predicting the p
    
[^91]: 面向可扩展物理一致的神经网络：在数据驱动多区域热建筑模型中的应用研究

    Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models. (arXiv:2212.12380v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12380](http://arxiv.org/abs/2212.12380)

    本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。

    

    随着越来越多的数据被收集，数据驱动建模方法近年来越来越受欢迎。虽然经典灰盒模型在物理上是可靠的，但通常很难识别和扩展，并且受其有限的表现力影响可能会影响其准确性。另一方面，常常依赖神经网络 (NNs) 的经典黑盒方法通常能够从数据中推导出统计模式，即使在扩展方面也能取得令人印象深刻的性能。然而，它们对潜在的物理定律完全无视，如果基于它们做决策用于实际物理系统，可能会导致潜在的灾难性后果。最近开发了物理一致神经网络 (PCNNs) 来解决这些问题，确保物理一致性，同时利用 NNs 实现最先进的准确性。在这项工作中，我们将 PCNN 扩展到建筑温度动态建模，并提出与经典灰盒和黑盒方法的彻底比较。特别是，我们研究多区域建筑模型，其中每个区域的热行为由能量平衡方程式统治，其参数必须通过测量数据进行识别。所得结果表明，即使涉及许多相互作用的组件构成的复杂和动态系统，PCNNs 也可以在确保物理一致性的同时实现高精度。此外，我们证明 PCNN 在经典灰盒模型上提供了可扩展性优势，在有限的可用训练数据下表现出色。

    With more and more data being collected, data-driven modeling methods have been gaining in popularity in recent years. While physically sound, classical gray-box models are often cumbersome to identify and scale, and their accuracy might be hindered by their limited expressiveness. On the other hand, classical black-box methods, typically relying on Neural Networks (NNs) nowadays, often achieve impressive performance, even at scale, by deriving statistical patterns from data. However, they remain completely oblivious to the underlying physical laws, which may lead to potentially catastrophic failures if decisions for real-world physical systems are based on them. Physically Consistent Neural Networks (PCNNs) were recently developed to address these aforementioned issues, ensuring physical consistency while still leveraging NNs to attain state-of-the-art accuracy.  In this work, we scale PCNNs to model building temperature dynamics and propose a thorough comparison with classical gray-b
    
[^92]: 关于语义分割模型的校准：分析与算法

    On Calibrating Semantic Segmentation Models: Analyses and An Algorithm. (arXiv:2212.12053v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.12053](http://arxiv.org/abs/2212.12053)

    本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。

    

    我们研究了语义分割校准的问题。虽然已经提出了很多解决方案来处理图像分类置信度的模型误校准，但至今为止，对语义分割的置信度校准研究仍然很有限。我们对语义分割模型的校准进行了系统研究，并提出了一种简单而有效的方法。首先，我们发现模型容量、裁剪大小、多尺度测试和预测正确性对校准有影响。其中，预测正确性，特别是错误预测，对由于过度置信而导致的误校准更为重要。接下来，我们提出了一种简单、统一且有效的方法，即选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑。然后，我们研究了流行的现有校准方法，并将它们与选择性缩放在语义分割校准上进行比较。我们进行了大量实验，使用了多种数据集和语义分割模型，以验证我们提出的方法的有效性。

    We study the problem of semantic segmentation calibration. Lots of solutions have been proposed to approach model miscalibration of confidence in image classification. However, to date, confidence calibration research on semantic segmentation is still limited. We provide a systematic study on the calibration of semantic segmentation models and propose a simple yet effective approach. First, we find that model capacity, crop size, multi-scale testing, and prediction correctness have impact on calibration. Among them, prediction correctness, especially misprediction, is more important to miscalibration due to over-confidence. Next, we propose a simple, unifying, and effective approach, namely selective scaling, by separating correct/incorrect prediction for scaling and more focusing on misprediction logit smoothing. Then, we study popular existing calibration methods and compare them with selective scaling on semantic segmentation calibration. We conduct extensive experiments with a vari
    
[^93]: 人工参与的知识图谱拓展

    Expanding Knowledge Graphs with Humans in the Loop. (arXiv:2212.05189v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.05189](http://arxiv.org/abs/2212.05189)

    本文提出了一种与人类互动的方法扩展知识图谱，通过预测新概念的“父母”，然后由人类专家进一步验证。该方法能够保证预测的父母距离概念的真实父母“近”，能够提高人算协作的速度和准确性，并在新闻和娱乐领域的真实数据集上得到了验证。

    

    精心策划的知识图谱编码领域专业知识，提高推荐、分割、广告定向和其他机器学习系统在多个领域中的性能。随着领域中出现新概念，知识图谱必须扩展以保持机器学习性能。但是，在规模上手动扩展知识图谱是不可行的。在这项工作中，我们提出了一种与人类互动的知识图谱拓展方法。具体而言，给定一个知识图谱，我们的方法预测了需要添加到此图谱中的新概念的“父母”，以供人类专家进一步验证。我们证明了我们的方法既准确又可证明是“人性化”的。具体来说，我们证明了即使预测不正确，我们的方法也能预测距离概念的真实父母“近”的父母。然后，我们通过一项受控实验，证明了满足此属性可以增加人算协作的速度和准确性。我们进一步展示了我们的方法在新闻和娱乐领域的真实数据集上的有效性。

    Curated knowledge graphs encode domain expertise and improve the performance of recommendation, segmentation, ad targeting, and other machine learning systems in several domains. As new concepts emerge in a domain, knowledge graphs must be expanded to preserve machine learning performance. Manually expanding knowledge graphs, however, is infeasible at scale. In this work, we propose a method for knowledge graph expansion with humans-in-the-loop. Concretely, given a knowledge graph, our method predicts the "parents" of new concepts to be added to this graph for further verification by human experts. We show that our method is both accurate and provably "human-friendly". Specifically, we prove that our method predicts parents that are "near" concepts' true parents in the knowledge graph, even when the predictions are incorrect. We then show, with a controlled experiment, that satisfying this property increases both the speed and the accuracy of the human-algorithm collaboration. We furth
    
[^94]: 扩散视频自编码器：通过分解视频特征实现一致的人脸视频编辑

    Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding. (arXiv:2212.02802v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02802](http://arxiv.org/abs/2212.02802)

    本文提出了一种基于扩散自编码器的面部视频编辑框架，可以从给定的视频中提取出分解的特征，实现简单的特征调整来确保时间上的一致性。与现有的基于GAN的方法不同，该模型同时满足重建和编辑能力，并且对受野外面部视频的角落情况具有鲁棒性。

    

    受到最近面部图像编辑方法的惊人表现的启发，自然会有几项研究来扩展这些方法以应用于面部视频编辑任务。 这里的一个主要挑战是编辑帧之间的时间一致性，这仍然没有得到解决。 为此，我们提出了一种基于扩散自编码器的新型面部视频编辑框架，该框架可以成功地从给定的视频中提取出分解的特征-首次作为面部视频编辑模型-标识和运动。

    Inspired by the impressive performance of recent face image editing methods, several studies have been naturally proposed to extend these methods to the face video editing task. One of the main challenges here is temporal consistency among edited frames, which is still unresolved. To this end, we propose a novel face video editing framework based on diffusion autoencoders that can successfully extract the decomposed features - for the first time as a face video editing model - of identity and motion from a given video. This modeling allows us to edit the video by simply manipulating the temporally invariant feature to the desired direction for the consistency. Another unique strength of our model is that, since our model is based on diffusion models, it can satisfy both reconstruction and edit capabilities at the same time, and is robust to corner cases in wild face videos (e.g. occluded faces) unlike the existing GAN-based methods.
    
[^95]: ObjectMatch: 使用规范对象对应关系的鲁棒注册方法

    ObjectMatch: Robust Registration using Canonical Object Correspondences. (arXiv:2212.01985v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.01985](http://arxiv.org/abs/2212.01985)

    ObjectMatch是一种利用语义对象识别来实现间接对应关系的鲁棒性注册方法，在处理很少或没有帧之间重叠的情况下表现出了显著的优势，并在 RGB-D 序列的三个公共数据集中实现了最先进的准确性。

    

    本文提出了ObjectMatch，一种基于语义和物体中心的RGB-D SLAM相机姿态估计器。现代相机姿态估计器依赖于帧之间的直接对应关系，然而它们无法对齐具有很少或没有重叠的相机帧。本文提出了利用通过语义对象识别获得的间接对应关系。我们首先提出了一个神经网络来预测每个像素级别的对应关系，然后将其与最先进的关键点匹配相结合，并使用联合高斯牛顿优化来解决能量公式。在成对设置中，我们的方法提高了最先进的特征匹配的注册召回率，包括在帧之间重叠率低于10%的对中，从24%到45%。在注册RGB-D序列时，我们的方法在三个公共数据集中达到了最先进的准确性。

    We present ObjectMatch, a semantic and object-centric camera pose estimator for RGB-D SLAM pipelines. Modern camera pose estimators rely on direct correspondences of overlapping regions between frames; however, they cannot align camera frames with little or no overlap. In this work, we propose to leverage indirect correspondences obtained via semantic object identification. For instance, when an object is seen from the front in one frame and from the back in another frame, we can provide additional pose constraints through canonical object correspondences. We first propose a neural network to predict such correspondences on a per-pixel level, which we then combine in our energy formulation with state-of-the-art keypoint matching solved with a joint Gauss-Newton optimization. In a pairwise setting, our method improves registration recall of state-of-the-art feature matching, including from 24% to 45% in pairs with 10% or less inter-frame overlap. In registering RGB-D sequences, our meth
    
[^96]: 通过网络规范化和超参数搜索优化解释

    Optimizing Explanations by Network Canonization and Hyperparameter Search. (arXiv:2211.17174v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.17174](http://arxiv.org/abs/2211.17174)

    这篇论文介绍了新的解释人工智能方法，通过网络规范化和超参数搜索来提高解释效果。

    

    解释型人工智能（XAI）正在逐渐成为许多人工智能应用的关键组成部分。然而，基于规则和修改后的反向传播XAI方法往往在应用于现代模型架构时面临挑战，包括创新的层构建块，这是由两个原因造成的。首先，基于规则的XAI方法的高灵活性导致了许多潜在的参数化。其次，许多XAI方法破坏了实现不变性公理，因为他们无法处理某些模型组件，例如BatchNorm层。后者可以通过模型规范化来解决，模型规范化是重新组织模型以忽略有问题的组件而不改变基本函数的过程。虽然对于简单的架构（例如VGG、ResNet），模型规范化很简单，但对于更复杂和高度互联的模型（例如DenseNet），它可能具有挑战性。此外，只有很少的可量化证据表明模型规范化对XAI有益。

    Explainable AI (XAI) is slowly becoming a key component for many AI applications. Rule-based and modified backpropagation XAI approaches however often face challenges when being applied to modern model architectures including innovative layer building blocks, which is caused by two reasons. Firstly, the high flexibility of rule-based XAI methods leads to numerous potential parameterizations. Secondly, many XAI methods break the implementation-invariance axiom because they struggle with certain model components, e.g., BatchNorm layers. The latter can be addressed with model canonization, which is the process of re-structuring the model to disregard problematic components without changing the underlying function. While model canonization is straightforward for simple architectures (e.g., VGG, ResNet), it can be challenging for more complex and highly interconnected models (e.g., DenseNet). Moreover, there is only little quantifiable evidence that model canonization is beneficial for XAI.
    
[^97]: 基于置信度的图神经网络用于学习可靠性评估承诺

    Confidence-Aware Graph Neural Networks for Learning Reliability Assessment Commitments. (arXiv:2211.15755v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15755](http://arxiv.org/abs/2211.15755)

    本论文针对可靠性评估承诺的优化问题，利用基于 GNN 的结构预测发电机的承诺和约束，并通过对高置信度预测结果的可行性修复，提高了最先进算法的解决方案质量。

    

    由于可再生能源的比例增加和预测误差的提高，可靠性评估承诺(Reliability Assessment Commitment, RAC)优化在电网运行中变得越来越重要。本研究旨在解决RAC公式扩展所带来的计算挑战。它提出了RACLearn，利用基于Graph Neural Network (GNN)的架构来预测发电机的承诺和线路约束，为每个承诺预测关联一个置信度值，并选择一组高置信度预测，对其进行可行性修复，并利用可行的预测与约束状态引导最先进的优化算法。实验结果表明，RACLearn在Midcontinent Independent System Operator (MISO)使用的准确RAC公式上，比现有的最先进方法具有显着更好的解决方案质量。

    Reliability Assessment Commitment (RAC) Optimization is increasingly important in grid operations due to larger shares of renewable generations in the generation mix and increased prediction errors. Independent System Operators (ISOs) also aim at using finer time granularities, longer time horizons, and possibly stochastic formulations for additional economic and reliability benefits. The goal of this paper is to address the computational challenges arising in extending the scope of RAC formulations. It presents RACLearn that (1) uses a Graph Neural Network (GNN) based architecture to predict generator commitments and active line constraints, (2) associates a confidence value to each commitment prediction, (3) selects a subset of the high-confidence predictions, which are (4) repaired for feasibility, and (5) seeds a state-of-the-art optimization algorithm with feasible predictions and active constraints. Experimental results on exact RAC formulations used by the Midcontinent Independe
    
[^98]: Shifted Diffusion用于文本到图像生成

    Shifted Diffusion for Text-to-image Generation. (arXiv:2211.15388v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15388](http://arxiv.org/abs/2211.15388)

    本文提出了一种新的文本到图像生成方法，使用Shifted Diffusion模型更好地生成来自输入文本的图像嵌入，并通过大量实验和评估证明了其在效率和有效性方面的优势，同时支持半监督和无语言训练。

    

    我们提出了Corgi，一种新颖的文本到图像生成方法。Corgi基于我们提出的Shifted Diffusion模型，可以更好地生成来自输入文本的图像嵌入。与DALL-E 2中使用的基线扩散模型不同，我们的方法通过设计新的初始化分布和扩散的新过渡步骤，在其扩散过程中无缝地编码了预训练CLIP模型的先前知识。与强劲的DALL-E 2基准相比，我们的方法在从文本中生成图像嵌入方面表现更好，具有更高的效率和有效性，从而实现更好的文本到图像生成。进行了大量的大规模实验，并在定量指标和人类评估方面进行了评估，结果表明与现有方法相比，我们的方法具有更强的生成能力。此外，我们的模型实现了文本到图像生成的半监督和无语言训练，只需要部分或不需要训练数据集中的图像与输入文本对齐。

    We present Corgi, a novel method for text-to-image generation. Corgi is based on our proposed shifted diffusion model, which achieves better image embedding generation from input text. Unlike the baseline diffusion model used in DALL-E 2, our method seamlessly encodes prior knowledge of the pre-trained CLIP model in its diffusion process by designing a new initialization distribution and a new transition step of the diffusion. Compared to the strong DALL-E 2 baseline, our method performs better in generating image embedding from the text in terms of both efficiency and effectiveness, resulting in better text-to-image generation. Extensive large-scale experiments are conducted and evaluated in terms of both quantitative measures and human evaluation, indicating a stronger generation ability of our method compared to existing ones. Furthermore, our model enables semi-supervised and language-free training for text-to-image generation, where only part or none of the images in the training 
    
[^99]: 多模态少样本时间动作检测

    Multi-Modal Few-Shot Temporal Action Detection. (arXiv:2211.14905v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.14905](http://arxiv.org/abs/2211.14905)

    提出了一个新的多模态少样本时间动作检测问题，针对这个问题提出了一个新的 MUPPET 方法，通过在视觉-语言模型中构建多模态提示，并使用多模态聚类算法来组合时序连续的片段，解决了问题。在少样本和零样本场景下表现出了优越性，并验证了不同组件的有效性。

    

    少样本 (FS) 和零样本 (ZS) 学习是缩放时间动作检测 (TAD) 到新类的两种不同方法。前者将经过预训练的视觉模型适应于新任务，该任务由每类仅有一个视频表示，而后者通过利用新类的语义描述而不需要训练示例。在本文中，我们介绍了一种新的多模态少样本 (MMFS) TAD 问题，它可以被视为通过共同利用少数支持视频和新类名字来结合 FS-TAD 和 ZS-TAD 的方法。为了解决这个问题，我们进一步提出了一种新颖的 MUlti-modality PromPt mETa-learning (MUPPET) 方法。这是通过有效地连接预训练的视觉和语言模型，同时最大程度地重用已经学习的能力来实现的。具体来说，我们通过使用元学习适配器装备的视觉语义分词器，将支持视频映射到视觉-语言模型的文本标记空间中来构建多模态提示。为了解决大的类内变化，我们提出了一种新的多模态聚类算法来对时间上一致的提议片段进行分组。全面的实验展示了所提出的方法在少样本和零样本场景下的优势，以及不同组件的有效性。

    Few-shot (FS) and zero-shot (ZS) learning are two different approaches for scaling temporal action detection (TAD) to new classes. The former adapts a pretrained vision model to a new task represented by as few as a single video per class, whilst the latter requires no training examples by exploiting a semantic description of the new class. In this work, we introduce a new multi-modality few-shot (MMFS) TAD problem, which can be considered as a marriage of FS-TAD and ZS-TAD by leveraging few-shot support videos and new class names jointly. To tackle this problem, we further introduce a novel MUlti-modality PromPt mETa-learning (MUPPET) method. This is enabled by efficiently bridging pretrained vision and language models whilst maximally reusing already learned capacity. Concretely, we construct multi-modal prompts by mapping support videos into the textual token space of a vision-language model using a meta-learned adapter-equipped visual semantics tokenizer. To tackle large intra-clas
    
[^100]: 通过网络剪枝设计轻量级物体跟踪器：使用CNN还是Transformers?

    On Designing Light-Weight Object Trackers through Network Pruning: Use CNNs or Transformers?. (arXiv:2211.13769v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13769](http://arxiv.org/abs/2211.13769)

    本文介绍了如何通过神经网络结构剪枝技术设计压缩版的高度压缩轻量级物体跟踪器。通过对CNN和Transformers跟踪器的比较研究，揭示出在设计轻量级跟踪器时的最佳架构选择。最后，提供了极端剪枝率的跟踪结果，可能有助于更好地了解网络剪枝在物体跟踪中的限制。

    

    低功耗设备上部署的物体跟踪器需要轻量级设计，然而，大多数现有最先进的方法依赖于使用构建于CNN或transformers上的计算密集的主干网络。这些模型的巨大尺寸不允许在低功耗条件下部署它们，因此设计压缩版的大型跟踪模型具有重要意义。本文演示了如何通过神经结构剪枝设计高度压缩的轻量级物体跟踪器，同时提供了一个比较研究，以确定最适合设计轻量级跟踪器的架构选择。还提供了使用CNNs、transformers以及两者组合的最新跟踪器之间的比较，以研究它们在各种压缩比下的稳定性。最后，展示了极端剪枝场景下的结果，有些情况下剪枝比率低至1%，以研究网络剪枝在物体跟踪中的限制。本文提供了更深入的洞察力。

    Object trackers deployed on low-power devices need to be light-weight, however, most of the current state-of-the-art (SOTA) methods rely on using compute-heavy backbones built using CNNs or transformers. Large sizes of such models do not allow their deployment in low-power conditions and designing compressed variants of large tracking models is of great importance. This paper demonstrates how highly compressed light-weight object trackers can be designed using neural architectural pruning of large CNN and transformer based trackers. Further, a comparative study on architectural choices best suited to design light-weight trackers is provided. A comparison between SOTA trackers using CNNs, transformers as well as the combination of the two is presented to study their stability at various compression ratios. Finally results for extreme pruning scenarios going as low as 1% in some cases are shown to study the limits of network pruning in object tracking. This work provides deeper insights 
    
[^101]: BiasBed -- 严格的纹理偏差评估

    BiasBed -- Rigorous Texture Bias Evaluation. (arXiv:2211.13190v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13190](http://arxiv.org/abs/2211.13190)

    本文介绍了 BiasBed，一个测试平台，用于严格评估降低纹理偏差的方法，包括多个数据集和现有算法，并配备了广泛的评估协议以揭示其显著性。

    

    现代卷积神经网络存在纹理偏差的问题已有充分文献证明，这导致出现了大量算法，强调形状线索，以支持到新领域的概括。然而，普通数据集、基准和一般的模型选择策略都缺失，且没有共识的、严格的评估协议。在本文中，我们研究了使用降低了纹理偏差的网络进行训练时的困难和限制。特别地，我们还展示了适当的评估和方法之间有意义的比较并不是一件容易的事情。我们引入了 BiasBed，一个用于测试纹理和风格偏差训练的测试平台，包括多个数据集和一系列现有算法。它配备了广泛的评估协议，包括严格的假设检验，以衡量结果的显著性，尽管一些风格偏差方法的训练不稳定。我们的大量实验证明了需要仔细、基于统计的对纹理偏差降低方法进行评估，并展示了严格的评估协议的价值。

    The well-documented presence of texture bias in modern convolutional neural networks has led to a plethora of algorithms that promote an emphasis on shape cues, often to support generalization to new domains. Yet, common datasets, benchmarks and general model selection strategies are missing, and there is no agreed, rigorous evaluation protocol. In this paper, we investigate difficulties and limitations when training networks with reduced texture bias. In particular, we also show that proper evaluation and meaningful comparisons between methods are not trivial. We introduce BiasBed, a testbed for textureand style-biased training, including multiple datasets and a range of existing algorithms. It comes with an extensive evaluation protocol that includes rigorous hypothesis testing to gauge the significance of the results, despite the considerable training instability of some style bias methods. Our extensive experiments, shed new light on the need for careful, statistically founded ev
    
[^102]: 通过减少累积轨迹误差来提高数据集精炼效果的论文翻译

    Minimizing the Accumulated Trajectory Error to Improve Dataset Distillation. (arXiv:2211.11004v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11004](http://arxiv.org/abs/2211.11004)

    通过新增损失项最小化累积轨迹误差，从而提高数据集精炼效果，并且在多种数据集和网络架构上的实验证明该方法优于当前最先进的方法。

    

    由于大型真实世界数据集的可用性，基于模型的深度学习取得了惊人的成功。然而，处理如此大量的数据在计算、存储、训练和搜寻良好的神经结构等方面成本相当高昂，因此数据集精炼近期成为焦点。这种范式涉及获取真实世界数据集中的信息并将其提炼为微小紧凑的合成数据集，以便在理想情况下处理后者的表现类似于前者。当前最先进的方法主要依靠学习通过在真实数据和合成数据之间匹配训练期间获得的梯度的合成数据集。然而，这些梯度匹配方法受到所谓的累积轨迹误差的影响，此误差是由于精炼和后续评估之间不一致导致的。为了减轻这种累积轨迹误差的不利影响，我们提出了一种新方法，鼓励将累积轨迹误差从训练阶段转移到精炼阶段。具体而言，我们引入了一种损失项，在精炼过程中最小化累积轨迹误差。我们在不同数据集和网络架构上的实验表明，我们的方法优于当前最先进的方法并显著减少累积轨迹误差。

    Model-based deep learning has achieved astounding successes due in part to the availability of large-scale real-world data. However, processing such massive amounts of data comes at a considerable cost in terms of computations, storage, training and the search for good neural architectures. Dataset distillation has thus recently come to the fore. This paradigm involves distilling information from large real-world datasets into tiny and compact synthetic datasets such that processing the latter ideally yields similar performances as the former. State-of-the-art methods primarily rely on learning the synthetic dataset by matching the gradients obtained during training between the real and synthetic data. However, these gradient-matching methods suffer from the so-called accumulated trajectory error caused by the discrepancy between the distillation and subsequent evaluation. To mitigate the adverse impact of this accumulated trajectory error, we propose a novel approach that encourages t
    
[^103]: Magic3D：高分辨率文本到3D内容创作

    Magic3D: High-Resolution Text-to-3D Content Creation. (arXiv:2211.10440v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.10440](http://arxiv.org/abs/2211.10440)

    本论文提出的Magic3D方法，采用两步优化框架，可以比之前的DreamFusion方法快2倍创建高质量3D网格模型，解决了NeRF优化速度极慢和对低分辨率图像空间监督的限制。

    

    近期，DreamFusion展示了一个预训练的文本到图像扩散模型（text-to-image diffusion model）优化神经辐射场（Neural Radiance Fields，NeRF）的实用性，实现了惊人的文本到3D合成结果。然而该方法具有两个固有限制：（a）NeRF的优化速度极慢，（b）对NeRF的低分辨率图像空间监督，导致长时间处理的低质量3D模型。本文通过利用一个两步优化框架来解决这些限制。首先，我们使用低分辨率扩散先验获得一个粗糙模型，并加速通过使用稀疏的3D哈希网格结构。使用粗略表示作为初始化，我们采用高分辨率潜在扩散模型相互作用的高效可微渲染器进一步优化纹理3D网格模型。我们的方法名为Magic3D，可以在40分钟内创建高质量3D网格模型，这比DreamFusion（据报道平均需要1.5小时）快2倍。

    DreamFusion has recently demonstrated the utility of a pre-trained text-to-image diffusion model to optimize Neural Radiance Fields (NeRF), achieving remarkable text-to-3D synthesis results. However, the method has two inherent limitations: (a) extremely slow optimization of NeRF and (b) low-resolution image space supervision on NeRF, leading to low-quality 3D models with a long processing time. In this paper, we address these limitations by utilizing a two-stage optimization framework. First, we obtain a coarse model using a low-resolution diffusion prior and accelerate with a sparse 3D hash grid structure. Using the coarse representation as the initialization, we further optimize a textured 3D mesh model with an efficient differentiable renderer interacting with a high-resolution latent diffusion model. Our method, dubbed Magic3D, can create high quality 3D mesh models in 40 minutes, which is 2x faster than DreamFusion (reportedly taking 1.5 hours on average), while also achieving hi
    
[^104]: 用于序列推荐器的潜在用户意图建模

    Latent User Intent Modeling for Sequential Recommenders. (arXiv:2211.09832v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.09832](http://arxiv.org/abs/2211.09832)

    该论文提出了一种基于概率建模和变分自编码器的方法，将用户意图作为潜在变量，从而更好地理解用户并优化长期用户体验，证明其在离线分析和实时实验中的有效性。

    

    序列推荐模型是现代工业推荐系统的关键组成部分。这些模型通过学习用户在平台上的互动历史，预测用户可能会与哪些项目进行交互。然而，大多数序列推荐器缺乏对用户意图的高级理解，而用户意图通常驱动着在线用户行为。因此，意图建模对于理解用户并优化长期用户体验至关重要。我们提出了一种概率建模方法，将用户意图作为潜在变量，并使用变分自编码器（VAE）根据用户行为信号进行推断。然后，根据推断出的用户意图调整推荐策略。我们通过离线分析和大规模工业推荐平台上的实时实验证明了潜在用户意图建模的有效性。

    Sequential recommender models are essential components of modern industrial recommender systems. These models learn to predict the next items a user is likely to interact with based on his/her interaction history on the platform. Most sequential recommenders however lack a higher-level understanding of user intents, which often drive user behaviors online. Intent modeling is thus critical for understanding users and optimizing long-term user experience. We propose a probabilistic modeling approach and formulate user intent as latent variables, which are inferred based on user behavior signals using variational autoencoders (VAE). The recommendation policy is then adjusted accordingly given the inferred user intent. We demonstrate the effectiveness of the latent user intent modeling via offline analyses as well as live experiments on a large-scale industrial recommendation platform.
    
[^105]: 双向联想记忆的热力学

    Thermodynamics of bidirectional associative memories. (arXiv:2211.09694v2 [cond-mat.dis-nn] UPDATED)

    [http://arxiv.org/abs/2211.09694](http://arxiv.org/abs/2211.09694)

    研究了双向联想记忆的平衡性质，表征了其随机扩展在热力学极限下的计算能力，提供了有限温度和无噪声情况下的相图，分析了临界负载。

    

    本文研究了双向联想记忆（BAM）的平衡性质。最简单的结构是由两层神经元定义的，仅在不同层之间的单元之间存在突触连接：即使在每层内没有内部连接的情况下，通过神经活动在层与层之间传递，信息的存储和检索仍然是可能的。我们通过应用统计物理的严格技术，表征了此模型的随机扩展在热力学极限下的计算能力。我们提供了复制对称层面上相图的详细描绘，包括有限温度和无噪声的情况。对于后者，我们进一步研究了临界负载，直到一步复制对称性破缺。我们对转换曲线进行了分析和数值检查。

    In this paper we investigate the equilibrium properties of bidirectional associative memories (BAMs). Introduced by Kosko in 1988 as a generalization of the Hopfield model to a bipartite structure, the simplest architecture is defined by two layers of neurons, with synaptic connections only between units of different layers: even without internal connections within each layer, information storage and retrieval are still possible through the reverberation of neural activities passing from one layer to another. We characterize the computational capabilities of a stochastic extension of this model in the thermodynamic limit, by applying rigorous techniques from statistical physics. A detailed picture of the phase diagram at the replica symmetric level is provided, both at finite temperature and in the noiseless regimes. Also for the latter, the critical load is further investigated up to one step of replica symmetry breaking. An analytical and numerical inspection of the transition curves
    
[^106]: 在线属性选择的可解释的小样本学习

    Interpretable Few-shot Learning with Online Attribute Selection. (arXiv:2211.09107v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09107](http://arxiv.org/abs/2211.09107)

    本文提出了一种在线属性选择机制的天然可解释模型来处理小样本学习，通过减少每个episode中涉及的属性数量提高准确性和可解释性，同时自动检测并补偿人工智能属性池不足的episode。

    

    小样本学习(few-shot learning, FSL)是一种挑战性的学习问题，每个类别只有很少的样本可用。在FSL中决策的解释比传统分类更加重要，因为错误的几率更大。然而，大多数以前的FSL方法都是黑匣子模型。本文提出了一种基于易于理解的属性的天然可解释模型来处理FSL。此外，我们提出了一种在线属性选择机制，以有效过滤每个episode中不相关的属性。该属性选择机制通过减少每个episode中涉及的属性数量来提高准确性和可解释性。我们提出了一种机制，自动检测人工智能属性池不足的episode，并通过涉及学习的未知属性来补偿。我们证明了所提出的方法可以实现与黑匣子小样本学习模型相当的结果。

    Few-shot learning (FSL) is a challenging learning problem in which only a few samples are available for each class. Decision interpretation is more important in few-shot classification since there is a greater chance of error than in traditional classification. However, most of the previous FSL methods are black-box models. In this paper, we propose an inherently interpretable model for FSL based on human-friendly attributes. Moreover, we propose an online attribute selection mechanism that can effectively filter out irrelevant attributes in each episode. The attribute selection mechanism improves the accuracy and helps with interpretability by reducing the number of participated attributes in each episode. We propose a mechanism that automatically detects the episodes where the pool of human-friendly attributes are not adequate, and compensates by engaging learned unknown attributes. We demonstrate that the proposed method achieves results on par with black-box few-shot-learning model
    
[^107]: 能量材料设计中的人工智能方法：现状、挑战和未来方向

    Artificial intelligence approaches for materials-by-design of energetic materials: state-of-the-art, challenges, and future directions. (arXiv:2211.08179v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2211.08179](http://arxiv.org/abs/2211.08179)

    本文回顾了人工智能在能量材料设计方面的最新进展及应用，通过数据驱动的方法，可以确定最佳材料设计以及指向具有优越性能和性能指标的设计。

    

    人工智能作为解决各种复杂材料设计问题的工具正在快速发展。本文旨在回顾最近在人工智能驱动下的能量材料设计方面的进展及其应用。通过数据驱动的方法，人工智能模型可以识别材料设计参数空间中的趋势和模式，确定最佳材料设计以及指向具有优越/目标性能和性能指标的设计。我们将重点关注材料设计的三个主要阶段，即微结构形态的表示学习，结构-性能-性能 (S-P-P) 联系的估计以及优化/设计探索。我们将提供这些方法的潜力、实用性和功效的展望。

    Artificial intelligence (AI) is rapidly emerging as an enabling tool for solving various complex materials design problems. This paper aims to review recent advances in AI-driven materials-by-design and their applications to energetic materials (EM). Trained with data from numerical simulations and/or physical experiments, AI models can assimilate trends and patterns within the design parameter space, identify optimal material designs (micro-morphologies, combinations of materials in composites, etc.), and point to designs with superior/targeted property and performance metrics. We review approaches focusing on such capabilities with respect to the three main stages of materials-by-design, namely representation learning of microstructure morphology (i.e., shape descriptors), structure-property-performance (S-P-P) linkage estimation, and optimization/design exploration. We provide a perspective view of these methods in terms of their potential, practicality, and efficacy towards the rea
    
[^108]: 社交媒体文本深度时间建模在临床抑郁症中的应用

    Deep Temporal Modelling of Clinical Depression through Social Media Text. (arXiv:2211.07717v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.07717](http://arxiv.org/abs/2211.07717)

    本文通过使用抑郁症状检测分类器，从社交媒体文本提取临床相关特征，建立了一个模型用于检测用户的临床抑郁症，通过提供不同时间粒度的准确度度量来评估该模型。

    

    本文描述了一种基于用户时间轴社交媒体帖子的模型，用于检测用户的临床抑郁症。我们的模型使用了抑郁症状检测（DSD）分类器，该分类器基于最大数量的已经过临床医师注释的推文。我们随后使用我们的DSD模型来提取临床相关特征，例如抑郁症评分及其随后的时间模式，以及用户发布活动模式，例如量化他们的“无活动”或“沉默”。此外，为了评估这些提取特征的有效性，我们创建了三种数据集，包括来自两个现有的众所周知的用户级别抑郁症检测基准数据集的测试数据集。然后，我们提供了基于单个特征、基线特征和特征削减测试的准确度度量，在不同时间粒度的几个级别上。

    We describe the development of a model to detect user-level clinical depression based on a user's temporal social media posts. Our model uses a Depression Symptoms Detection (DSD) classifier, which is trained on the largest existing samples of clinician annotated tweets for clinical depression symptoms. We subsequently use our DSD model to extract clinically relevant features, e.g., depression scores and their consequent temporal patterns, as well as user posting activity patterns, e.g., quantifying their ``no activity'' or ``silence.'' Furthermore, to evaluate the efficacy of these extracted features, we create three kinds of datasets including a test dataset, from two existing well-known benchmark datasets for user-level depression detection. We then provide accuracy measures based on single features, baseline features and feature ablation tests, at several different levels of temporal granularity. The relevant data distributions and clinical depression detection related settings can
    
[^109]: 带装载和覆盖约束的上下文幸存者问题：基于回归的模块化Lagrangian方法

    Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.07484](http://arxiv.org/abs/2211.07484)

    该论文研究了一种带有资源线性约束的上下文幸存者问题的变种，提出了一种新的算法，该算法简单、计算效率高，同时能够实现较低的后悔。此外，当某些约束被违反时，算法在统计上是最优的。

    

    我们考虑一种上下文幸存者问题的变种，其中算法在总消费的线性约束下使用多个资源。这个问题推广了带背包的上下文幸存者问题(CBwK)，允许装载和覆盖约束，以及正负资源消耗。我们提出了一种新算法，简单、计算效率高，能够实现退化的后悔。当某些约束被违反时，对于CBwK，它在统计上是最优的。我们的算法基于LagrangianBwK(Immorlica等人，FOCS 2019)，这是一种面向CBwK的Lagrangian技术，以及SquareCB(Foster和Rakhlin，ICML 2020)，这是一种面向上下文幸存者的回归技术。我们的分析利用了两种技术本质上的模块化。

    We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
    
[^110]: 低次多项式张量分解的平均复杂度

    Average-Case Complexity of Tensor Decomposition for Low-Degree Polynomials. (arXiv:2211.05274v2 [cs.CC] UPDATED)

    [http://arxiv.org/abs/2211.05274](http://arxiv.org/abs/2211.05274)

    该论文研究了低次多项式张量分解问题的平均计算复杂度，发现在$r \ll n^{3/2}$时存在多项式时间算法，但当$r \lesssim n^2$时，该问题只能在原则上恢复秩-1分量，是一个计算困难问题。

    

    假设我们给定一个由$r$个随机秩-1项组成的$n$维三阶对称张量$T \in (\mathbb{R}^n)^{\otimes 3}$，则当$r \lesssim n^2$时，可以在原则上恢复秩-1分量，但是仅在$r \ll n^{3/2}$的情况下才知道存在多项式时间算法。许多高维推断任务中存在类似的“统计计算差距”，近年来，研究人员通过针对统计查询（SQ），平方和（SoS）和低次多项式（LDP）等受限（但强大）的计算模型证明下限，以解释这些问题的计算难度。然而，在张量分解中不存在类似“植入对空”的测试问题来解释其难度，这也是目前不存在任何此类工作的原因之一。我们考虑了一个随机三阶张量分解模型，其中一个分量的范数略大于其余分量（以破坏对称性）。

    Suppose we are given an $n$-dimensional order-3 symmetric tensor $T \in (\mathbb{R}^n)^{\otimes 3}$ that is the sum of $r$ random rank-1 terms. The problem of recovering the rank-1 components is possible in principle when $r \lesssim n^2$ but polynomial-time algorithms are only known in the regime $r \ll n^{3/2}$. Similar "statistical-computational gaps" occur in many high-dimensional inference tasks, and in recent years there has been a flurry of work on explaining the apparent computational hardness in these problems by proving lower bounds against restricted (yet powerful) models of computation such as statistical queries (SQ), sum-of-squares (SoS), and low-degree polynomials (LDP). However, no such prior work exists for tensor decomposition, largely because its hardness does not appear to be explained by a "planted versus null" testing problem.  We consider a model for random order-3 tensor decomposition where one component is slightly larger in norm than the rest (to break symmetr
    
[^111]: 列表可学习性的表征

    A Characterization of List Learnability. (arXiv:2211.04956v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2211.04956](http://arxiv.org/abs/2211.04956)

    本文通过引入$k$-DS维度，完全表征了$k$-列表学习性，并指出当且仅当该假设类的$k$-DS维度有限，该假设类才$k$-列表可学习。

    

    学习理论中的一个经典结果表明，二元假设类的PAC可学习性与VC维度的有限性等效。将其扩展到多类别设置是一个待解决的问题，近期通过早期由丹尼尔和沙列夫-施瓦茨引入的DS维度，解决了这个问题。本文考虑列表PAC学习，其目标是输出k个预测结果。在多种设置下已经开发了列表学习算法，事实上，在最近的多类学习的表征中，列表学习扮演了重要的角色。本文旨在探讨以下问题：何时可以用列表学习算法学习假设类？我们通过一个名为$k$-DS维度的DS维度泛化完全表征$k$-列表学习性。通过对多类学习的最近表征进行泛化，我们表明，假设类$k$-列表可学习，当且仅当...

    A classical result in learning theory shows the equivalence of PAC learnability of binary hypothesis classes and the finiteness of VC dimension. Extending this to the multiclass setting was an open problem, which was settled in a recent breakthrough result characterizing multiclass PAC learnability via the DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work we consider list PAC learning where the goal is to output a list of $k$ predictions. List learning algorithms have been developed in several settings before and indeed, list learning played an important role in the recent characterization of multiclass learnability. In this work we ask: when is it possible to $k$-list learn a hypothesis class? We completely characterize $k$-list learnability in terms of a generalization of DS dimension that we call the $k$-DS dimension. Generalizing the recent characterization of multiclass learnability, we show that a hypothesis class is $k$-list learnable if and only if the
    
[^112]: 傅立叶分析实现一致且真实的模型解释

    Consistent and Truthful Interpretation with Fourier Analysis. (arXiv:2210.17426v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2210.17426](http://arxiv.org/abs/2210.17426)

    该论文提出了一个称为真实解释的新概念，通过傅立叶分析获得严格保证，并在实验中证明了其在支持假设情景和降低解释误差方面的优势。

    

    对于许多跨学科领域，机器学习的解释需要与当前案例相关的假设情景一致，即如果一个因素改变，模型会如何反应？尽管归因方法由优雅的公理系统支持，但它们主要关注单个输入，并且通常不一致。为支持假设情景，我们引入了一个称为真实解释的新概念，并应用布尔函数的傅立叶分析来获得严格的保证。实验结果表明，对于各种半径的邻域，我们的方法与其他方法相比，可以实现2倍至50倍更低的解释误差。

    For many interdisciplinary fields, ML interpretations need to be consistent with what-if scenarios related to the current case, i.e., if one factor changes, how does the model react? Although the attribution methods are supported by the elegant axiomatic systems, they mainly focus on individual inputs, and are generally inconsistent. To support what-if scenarios, we introduce a new notion called truthful interpretation, and apply Fourier analysis of Boolean functions to get rigorous guarantees. Experimental results show that for neighborhoods with various radii, our method achieves 2x - 50x lower interpretation error compared with the other methods.
    
[^113]: 通过符号回归发现的原子势模型的功能形式的普适性

    Generalizability of Functional Forms for Interatomic Potential Models Discovered by Symbolic Regression. (arXiv:2210.15124v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2210.15124](http://arxiv.org/abs/2210.15124)

    使用符号回归发现的新型原子势模型功能形式成功地应用于于铜等化学属性类似的元素。

    

    近年来，利用机器学习算法开发原子势模型取得了很大的进展。机器学习的势模型通常比密度泛函理论快几个数量级，但比如嵌入原子方法等物理导出模型慢几个数量级。在之前的工作中，我们使用符号回归开发出了功能形式类似于嵌入原子方法的快速、准确和可迁移的铜原子势模型。为了确定这些形式的成功程度是否特定于铜，我们在此研究了这些模型在其他面心立方过渡金属中的普适性，并分析了它们在几种材料性质上的样外表现。我们发现，这些形式在化学上类似于铜的元素上工作得特别好。与经过优化的Sutton-Chen模型相比，这些功能形式的性能表现更好。

    In recent years there has been great progress in the use of machine learning algorithms to develop interatomic potential models. Machine-learned potential models are typically orders of magnitude faster than density functional theory but also orders of magnitude slower than physics-derived models such as the embedded atom method. In our previous work, we used symbolic regression to develop fast, accurate and transferrable interatomic potential models for copper with novel functional forms that resemble those of the embedded atom method. To determine the extent to which the success of these forms was specific to copper, here we explore the generalizability of these models to other face-centered cubic transition metals and analyze their out-of-sample performance on several material properties. We found that these forms work particularly well on elements that are chemically similar to copper. When compared to optimized Sutton-Chen models, which have similar complexity, the functional form
    
[^114]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^115]: 超越线性的偏微分方程神经网络逼近：一种表征视角

    Neural Network Approximations of PDEs Beyond Linearity: A Representational Perspective. (arXiv:2210.12101v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12101](http://arxiv.org/abs/2210.12101)

    本文研究表征能力，使用神经网络逼近非线性偏微分方程解。研究发现，函数与偏导数组合产生的函数Barron范数不超过$B_Lb^p$，可以通过具有Barron范数 $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}}\right)}$ 的函数$\epsilon$-逼近PDE解。

    

    近年来，一系列的研究借助深度神经网络逼近高维偏微分方程的解，从而开启了理论探究的大门，使人们开始探讨这些模型是如何避免维度灾难的。但是，大多数理论分析都局限于线性偏微分方程。本文致力于研究神经网络逼近非线性偏微分方程解的表征能力。我们集中研究了一类称为\emph{非线性椭圆变分偏微分方程}的偏微分方程，其解最小化一个\emph{欧拉-拉格朗日}能量泛函$\mathcal{E}(u) = \int_\Omega L(x, u(x), \nabla u(x)) - f(x) u(x)dx$。我们表明，如果用 Barron 范数为 $b$ 的函数与 $L$ 的偏导数组合可以产生 Barron 范数不超过 $B_Lb^p$ 的函数，则可以通过拥有 Barron 范数为 $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsilon)}}\right)}$ 的函数 $\epsilon$-逼近 $L^2$ 意义下的 PDE 解。

    A burgeoning line of research leverages deep neural networks to approximate the solutions to high dimensional PDEs, opening lines of theoretical inquiry focused on explaining how it is that these models appear to evade the curse of dimensionality. However, most prior theoretical analyses have been limited to linear PDEs. In this work, we take a step towards studying the representational power of neural networks for approximating solutions to nonlinear PDEs. We focus on a class of PDEs known as \emph{nonlinear elliptic variational PDEs}, whose solutions minimize an \emph{Euler-Lagrange} energy functional $\mathcal{E}(u) = \int_\Omega L(x, u(x), \nabla u(x)) - f(x) u(x)dx$. We show that if composing a function with Barron norm $b$ with partial derivatives of $L$ produces a function of Barron norm at most $B_L b^p$, the solution to the PDE can be $\epsilon$-approximated in the $L^2$ sense by a function with Barron norm $O\left(\left(dB_L\right)^{\max\{p \log(1/ \epsilon), p^{\log(1/\epsil
    
[^116]: LOT: 基于层内正交训练来提高$\ell_2$ 保护的鲁棒性。

    LOT: Layer-wise Orthogonal Training on Improving $\ell_2$ Certified Robustness. (arXiv:2210.11620v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.11620](http://arxiv.org/abs/2210.11620)

    本文提出了一种基于层内正交训练的方法(LOT)，通过使用一个无限制矩阵来参数化正交矩阵来有效训练1-Lipschitz卷积层，并证明了半监督训练可以进一步提高利普希茨约束模型的可证明鲁棒性。在确定性l2可证明鲁棒性方面，LOT显著优于基线，并能够扩展到更深的神经网络。

    

    最近的研究表明，使用利普希茨约束训练深度神经网络（DNN）能够增强对抗性鲁棒性和其他模型特性，例如稳定性。在本文中，我们提出了一种基于层内正交训练方法（LOT）来有效训练1-Lipschitz卷积层，通过使用一个无限制矩阵来参数化一个正交矩阵。然后，我们通过将输入域转换为傅里叶频域来高效计算卷积核的平方根的逆。另一方面，由于现有研究表明半监督训练有助于提高经验上的鲁棒性，我们旨在弥合差距，并证明半监督学习也会提高利普希茨约束模型的可证明鲁棒性。我们在不同设置下对LOT进行了全面评估，并展示了LOT在确定性l2可证明鲁棒性方面显著优于基线，并能够扩展到更深的神经网络。在监督情况下，我们发现与纯监督训练相比，半监督训练可以进一步提高保护的鲁棒性。

    Recent studies show that training deep neural networks (DNNs) with Lipschitz constraints are able to enhance adversarial robustness and other model properties such as stability. In this paper, we propose a layer-wise orthogonal training method (LOT) to effectively train 1-Lipschitz convolution layers via parametrizing an orthogonal matrix with an unconstrained matrix. We then efficiently compute the inverse square root of a convolution kernel by transforming the input domain to the Fourier frequency domain. On the other hand, as existing works show that semi-supervised training helps improve empirical robustness, we aim to bridge the gap and prove that semi-supervised learning also improves the certified robustness of Lipschitz-bounded models. We conduct comprehensive evaluations for LOT under different settings. We show that LOT significantly outperforms baselines regarding deterministic l2 certified robustness, and scales to deeper neural networks. Under the supervised scenario, we i
    
[^117]: 熵正则化Wasserstein重心的稳定性及其在随机几何图形中的应用

    Stability of Entropic Wasserstein Barycenters and application to random geometric graphs. (arXiv:2210.10535v2 [cs.CG] UPDATED)

    [http://arxiv.org/abs/2210.10535](http://arxiv.org/abs/2210.10535)

    本文研究了在离散网格上的WB与底层流形的几何关系，证明了在离散形状上计算的WB的一致性。

    

    近年来，由于对图形数据的关注不断增长，计算各种几何工具已变得至关重要。在某些领域，如网格处理，这些工具通常依赖于离散流形中的测地线和最短路径的计算。水印重心(WB)的计算是这种工具的一个最新例子。这是从最优输运理论中导出的一种非常通用的重心概念，以及它们的熵正则化变体。本文研究了在离散网格上的WB与底层流形的几何关系。我们首先提供了一个通用的稳定性结果，关于输入成本矩阵。然后，我们将此结果应用于用于流形的随机几何图形上，它们的最短路径收敛于测地线，从而证明了在离散形状上计算的WB的一致性。

    As interest in graph data has grown in recent years, the computation of various geometric tools has become essential. In some area such as mesh processing, they often rely on the computation of geodesics and shortest paths in discretized manifolds. A recent example of such a tool is the computation of Wasserstein barycenters (WB), a very general notion of barycenters derived from the theory of Optimal Transport, and their entropic-regularized variant. In this paper, we examine how WBs on discretized meshes relate to the geometry of the underlying manifold. We first provide a generic stability result with respect to the input cost matrices. We then apply this result to random geometric graphs on manifolds, whose shortest paths converge to geodesics, hence proving the consistency of WBs computed on discretized shapes.
    
[^118]: TFAD: 一种基于时频分析的时间序列异常检测架构

    TFAD: A Decomposition Time Series Anomaly Detection Architecture with Time-Frequency Analysis. (arXiv:2210.09693v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09693](http://arxiv.org/abs/2210.09693)

    本文提出了一种基于时频分析的时间序列异常检测模型 TFAD。在设计的时频架构中，同时加入了时间序列分解和数据增强机制，以提升性能和解释性能力。在广泛使用的基准数据集上，实证研究表明，该方法在单变量和多变量时间序列异常检测任务中性能最佳。

    

    时间序列异常检测是一个具有挑战性的问题，由于复杂的时间依赖性和有限的标签数据。虽然一些算法，包括传统和深度模型已经被提出，但大多数算法主要集中在时间域建模，没有充分利用时间序列数据中的频域信息。本文提出了一种基于时频分析的时间序列异常检测模型 TFAD，以利用时间和频域进行性能提升。此外，我们还在设计的时频架构中加入了时间序列分解和数据增强机制，进一步提升了性能和解释性能力。广泛使用的基准数据集上的实证研究表明，我们的方法在单变量和多变量时间序列异常检测任务中获得了最先进的性能。代码可在 https://github.com/DAMO-DI-ML/CIKM22-TFAD 获取。

    Time series anomaly detection is a challenging problem due to the complex temporal dependencies and the limited label data. Although some algorithms including both traditional and deep models have been proposed, most of them mainly focus on time-domain modeling, and do not fully utilize the information in the frequency domain of the time series data. In this paper, we propose a Time-Frequency analysis based time series Anomaly Detection model, or TFAD for short, to exploit both time and frequency domains for performance improvement. Besides, we incorporate time series decomposition and data augmentation mechanisms in the designed time-frequency architecture to further boost the abilities of performance and interpretability. Empirical studies on widely used benchmark datasets show that our approach obtains state-of-the-art performance in univariate and multivariate time series anomaly detection tasks. Code is provided at https://github.com/DAMO-DI-ML/CIKM22-TFAD.
    
[^119]: 探究掩码自编码器：Masked Autoencoders 的理论解释

    How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders. (arXiv:2210.08344v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.08344](http://arxiv.org/abs/2210.08344)

    本论文探究了Masked Autoencoders (MAE)学习有意义特征的理论方法，建立了MAE与对比学习之间的紧密联系，提出了一种增强均匀性的MAE (U-MAE) 损失函数。这些理论和方法在真实世界数据集上带来了显着的改进。

    

    基于重构任务的Masked Autoencoders (MAE)已成为自监督学习 (SSL) 的一种有前途的范式，并在不同的基准数据集上实现了最先进的性能。然而，尽管其令人印象深刻的实证成功，但对其仍存在有限的理论理解。本文提出了MAE如何通过掩码方式学习有意义的特征的理论理解。我们建立了MAE与对比学习之间的紧密联系，表明MAE隐式地对齐了由掩码引导的正对映样本。基于这一联系，我们开发了MAE方法的第一个下游保证，并分析了掩码比例的影响。此外，由于隐式对齐的结果，我们还指出了MAE的维度坍塌问题，并提出了一种增强均匀性的MAE (U-MAE) 损失函数，可以有效地解决这个问题，并在包括CIFAR-10、ImageNet-100和ImageNet-1K在内的真实世界数据集上带来显着的改进。

    Masked Autoencoders (MAE) based on a reconstruction task have risen to be a promising paradigm for self-supervised learning (SSL) and achieve state-of-the-art performance across different benchmark datasets. However, despite its impressive empirical success, there is still limited theoretical understanding of it. In this paper, we propose a theoretical understanding of how masking matters for MAE to learn meaningful features. We establish a close connection between MAE and contrastive learning, which shows that MAE implicit aligns the mask-induced positive pairs. Built upon this connection, we develop the first downstream guarantees for MAE methods, and analyze the effect of mask ratio. Besides, as a result of the implicit alignment, we also point out the dimensional collapse issue of MAE, and propose a Uniformity-enhanced MAE (U-MAE) loss that can effectively address this issue and bring significant improvements on real-world datasets, including CIFAR-10, ImageNet-100, and ImageNet-1K
    
[^120]: 分布式鲁棒多分类和在深度图像分类器中的应用

    Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2210.08198v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.08198](http://arxiv.org/abs/2210.08198)

    该论文提出了一种能够容忍异常值干扰数据的分布式鲁棒优化(DRO)公式，将其应用于图像分类器中可以使其对随机和对抗性攻击具有鲁棒性。在MNIST和CIFAR-10数据集上，相较于基准方法，采用新颖的随机训练方法，测试错误率减少高达83.5％，损失减少高达91.3％。

    

    我们提出了一种分布式鲁棒优化(DRO)的多分类逻辑回归(MLR)公式，可以容忍受到异常值干扰的数据。DRO框架使用一个概率模糊集合，该集合被定义为接近于Wasserstein度量意义下的训练集经验分布的分布球。 我们将DRO公式放松为一个规则化学习问题，其规则化器是系数矩阵的范数。 我们为我们模型的解决方案建立了样本外性能保证，为控制预测误差的规则化器的作用提供了洞察。我们将所提出的方法应用于深度视觉变换器(ViT)为基础的图像分类器中，使其对随机和对抗性攻击具有鲁棒性。具体地，在MNIST和CIFAR-10数据集上，我们通过采用一种新颖的随机训练方法，展示了测试错误率减少高达83.5％和损失减少高达91.3％的结果。

    We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.
    
[^121]: 使用图算法预训练图补全Transformer

    Using Graph Algorithms to Pretrain Graph Completion Transformers. (arXiv:2210.07453v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.07453](http://arxiv.org/abs/2210.07453)

    该论文研究了使用多种图算法构建的预训练任务，探索了图结构生成预训练任务，并提出了一种新的路径查找算法用于下游的知识图谱完成任务，该方法表现最佳。

    

    最近关于图神经网络的研究已经证明，自监督预训练可以进一步增强下游的图、链接和节点分类任务的性能。然而，预训练任务的有效性尚未完全调查，特别是在下游的大型知识图谱完成任务中。本研究使用一种上下文化的知识图嵌入方法，调查了构建于几种图算法和无外部数据的五个不同预训练信号及其组合。我们利用我们基于Transformer的模型的通用性，探索了通常不适用于大多数图嵌入方法的图结构生成预训练任务（即路径和k-hop邻域生成）。我们进一步提出了一种新的路径查找算法，该算法由信息增益引导，并发现它是在三个下游知识图谱完成数据集中表现最佳的预训练任务。使用我们的新路径查找算法作为预训练信号提供2

    Recent work on Graph Neural Networks has demonstrated that self-supervised pretraining can further enhance performance on downstream graph, link, and node classification tasks. However, the efficacy of pretraining tasks has not been fully investigated for downstream large knowledge graph completion tasks. Using a contextualized knowledge graph embedding approach, we investigate five different pretraining signals, constructed using several graph algorithms and no external data, as well as their combination. We leverage the versatility of our Transformer-based model to explore graph structure generation pretraining tasks (i.e. path and k-hop neighborhood generation), typically inapplicable to most graph embedding methods. We further propose a new path-finding algorithm guided by information gain and find that it is the best-performing pretraining task across three downstream knowledge graph completion datasets. While using our new path-finding algorithm as a pretraining signal provides 2
    
[^122]: 使用逐个样本评估的条件互信息提出一类新的泛化界限

    A New Family of Generalization Bounds Using Samplewise Evaluated CMI. (arXiv:2210.06422v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.06422](http://arxiv.org/abs/2210.06422)

    本文提出了一类新的信息论泛化界限，通过逐个样本评估的条件互信息，限制联合凸函数上界，与先前的界限相比在某些情况下更紧密地刻画了深度神经网络的总体损失。

    

    我们提出了一类新的信息论泛化界限，其中通过一个联合凸函数比较训练损失和总体损失。这个函数的上界通过分解、逐个样本评估的条件互信息（CMI）加以限制，这是一种与所选假设产生的损失有关而不是假设本身有关的信息度量，这在大多数近似正确性（PAC）- 贝叶斯结果中很常见。通过恢复和扩展之前已知的信息论界限，我们展示了这种框架的普适性。此外，使用评估的CMI，我们导出了Seeger的PAC-Bayesian界限的逐个样本的平均版本，其中凸函数是二元KL散度。在某些情况下，这种新的界限比先前的界限更紧密地刻画了深度神经网络的总体损失。最后，我们导出了一些这些平均界限的高概率版本。

    We present a new family of information-theoretic generalization bounds, in which the training loss and the population loss are compared through a jointly convex function. This function is upper-bounded in terms of the disintegrated, samplewise, evaluated conditional mutual information (CMI), an information measure that depends on the losses incurred by the selected hypothesis, rather than on the hypothesis itself, as is common in probably approximately correct (PAC)-Bayesian results. We demonstrate the generality of this framework by recovering and extending previously known information-theoretic bounds. Furthermore, using the evaluated CMI, we derive a samplewise, average version of Seeger's PAC-Bayesian bound, where the convex function is the binary KL divergence. In some scenarios, this novel bound results in a tighter characterization of the population loss of deep neural networks than previous bounds. Finally, we derive high-probability versions of some of these average bounds. We
    
[^123]: 机器学习与不变量理论

    Machine learning and invariant theory. (arXiv:2209.14991v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.14991](http://arxiv.org/abs/2209.14991)

    本文介绍了等变机器学习，其中函数将与某个群作用相关，使用不可约表示或不变量理论来参数化这些函数的空间。 Malgrange的一般过程用来表达群$G$作用下所有多项式映射。

    

    在物理定律的启发下，等变机器学习将学习限制在假设空间中，其中所有函数都关于某个群作用等变。通常使用不可约表示或不变量理论来参数化这些函数的空间。本文介绍了这一主题，并解释了一些用于明确参数化等变函数的方法，这些方法在机器学习应用中被使用。特别是，我们详细说明了Malgrange的一般过程，给定较大空间上不变多项式的表征，表达群$G$作用下所有多项式映射，该方法还在$G$是紧Lie群的情况下参数化了光顺等变映射。

    Inspired by constraints from physical law, equivariant machine learning restricts the learning to a hypothesis class where all the functions are equivariant with respect to some group action. Irreducible representations or invariant theory are typically used to parameterize the space of such functions. In this article, we introduce the topic and explain a couple of methods to explicitly parameterize equivariant functions that are being used in machine learning applications. In particular, we explicate a general procedure, attributed to Malgrange, to express all polynomial maps between linear spaces that are equivariant under the action of a group $G$, given a characterization of the invariant polynomials on a bigger space. The method also parametrizes smooth equivariant maps in the case that $G$ is a compact Lie group.
    
[^124]: 论AdaGrad在$\R^{d}$上的收敛性：超越凸性、非渐近速率和加速（arXiv：2209.14827v2 [cs.LG] UPDATED）

    On the Convergence of AdaGrad on $\R^{d}$: Beyond Convexity, Non-Asymptotic Rate and Acceleration. (arXiv:2209.14827v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14827](http://arxiv.org/abs/2209.14827)

    本论文主要展示了AdaGrad在平滑凸函数和更一般的quasar凸函数的情况下的收敛性。具体地，我们提出了新的技术，明确限定了vanilla AdaGrad在无约束问题中的收敛速率，并提出了一种AdaGrad变种，可以实现更快的收敛。

    

    现有的关于平滑凸优化的AdaGrad和其他自适应方法的分析通常是针对具有有界定义域直径的函数。在无约束问题中，以前的研究保证了渐近收敛速率，但没有明确的恒定因子，这适用于整个函数类。此外，在随机环境中，只分析了一个修改版本的AdaGrad，与通常实践中使用的版本不同，在这个回归中不使用最新的梯度来更新步幅。我们的论文旨在弥合这些差距，并在平滑凸函数的标准情况下以及更一般的quasar凸函数的情况下深入理解AdaGrad及其变种。首先，我们展示了新技术，明确地限定了vanilla AdaGrad在无约束问题中的收敛速率，无论是确定性的还是随机的情况下。其次，我们提出了一种AdaGrad变种，我们可以展示l的收敛

    Existing analysis of AdaGrad and other adaptive methods for smooth convex optimization is typically for functions with bounded domain diameter. In unconstrained problems, previous works guarantee an asymptotic convergence rate without an explicit constant factor that holds true for the entire function class. Furthermore, in the stochastic setting, only a modified version of AdaGrad, different from the one commonly used in practice, in which the latest gradient is not used to update the stepsize, has been analyzed. Our paper aims at bridging these gaps and developing a deeper understanding of AdaGrad and its variants in the standard setting of smooth convex functions as well as the more general setting of quasar convex functions. First, we demonstrate new techniques to explicitly bound the convergence rate of the vanilla AdaGrad for unconstrained problems in both deterministic and stochastic settings. Second, we propose a variant of AdaGrad for which we can show the convergence of the l
    
[^125]: 《一种针对多样对话生成的等大小硬EM算法》

    An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation. (arXiv:2209.14627v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.14627](http://arxiv.org/abs/2209.14627)

    本文提出了一种平衡约束的等大小硬EM算法，用于训练多解码器模型以实现多样的对话生成，可在小型模型中生成高质量的多样化响应。

    

    开放领域对话系统旨在以自然语言文本与人类互动。尽管像ChatGPT这样的超大型对话系统最近取得了成功，但使用中小型对话系统仍然是常见的做法，因为它们更加轻便易用。然而，在较小的模型中生成多样的对话响应是具有挑战性的。在本文中，我们提出了一种等大小硬EM（EqHard-EM）算法，用于训练多解码器模型以实现多样的对话生成。我们的算法以硬方式将样本分配给解码器，并额外施加平衡约束条件，以确保所有解码器都经过充分的训练。我们提供了详细的理论分析来证明我们的方法。此外，我们在两个大规模的开放领域对话数据集上进行实验，证明我们的EqHard-EM算法可以生成高质量的多样化响应。

    Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and accessible; however, generating diverse dialogue responses is challenging, especially with smaller models. In this work, we propose an Equal-size Hard Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model for diverse dialogue generation. Our algorithm assigns a sample to a decoder in a hard manner and additionally imposes an equal-assignment constraint to ensure that all decoders are well-trained. We provide detailed theoretical analysis to justify our approach. Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses.
    
[^126]: 全部值得一试：适用于扩散模型的ViT骨干网络

    All are Worth Words: A ViT Backbone for Diffusion Models. (arXiv:2209.12152v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.12152](http://arxiv.org/abs/2209.12152)

    本文提出了一种适用于扩散模型的ViT骨干网络U-ViT，用于图像生成任务，相较于传统基于CNN的U-Net模型，U-ViT具有可比甚至更好的性能，甚至在某些任务中创造了新的FID分数记录。

    

    在各种视觉任务中，视觉变换器（ViT）已经显示出了良好的性能，而基于卷积神经网络（CNN）的U-Net在扩散模型中仍然占主导地位。我们设计了一个简单通用的ViT骨干架构（称为U-ViT），用于生成扩散模型的图像。U-ViT的特点是将所有输入，包括时间、条件和噪声图像块都视为令牌，并在浅层和深层之间使用长跳跃连接。我们在无条件和类条件图像生成以及文本到图像生成任务中评估了U-ViT，在相似大小的基于“U-Net”的CNN模型中，U-ViT具有可比甚至更好的性能。特别是U-ViT的潜在扩散模型在ImageNet 256x256类条件图像生成中取得了2.29的最佳FID分数，在MS-COCO的文本到图像生成中取得了5.48的最佳FID分数，相比其他生成模型，不需要在训练期间访问大型外部数据集。我们的结果表明，在扩散型图像生成模型中，像U-ViT这样的ViT骨干架构可以实现与传统基于CNN的U-Net模型相当或更好的性能，甚至在某些任务中创造新的FID分数记录。

    Vision transformers (ViT) have shown promise in various vision tasks while the U-Net based on a convolutional neural network (CNN) remains dominant in diffusion models. We design a simple and general ViT-based architecture (named U-ViT) for image generation with diffusion models. U-ViT is characterized by treating all inputs including the time, condition and noisy image patches as tokens and employing long skip connections between shallow and deep layers. We evaluate U-ViT in unconditional and class-conditional image generation, as well as text-to-image generation tasks, where U-ViT is comparable if not superior to a CNN-based U-Net of a similar size. In particular, latent diffusion models with U-ViT achieve record-breaking FID scores of 2.29 in class-conditional image generation on ImageNet 256x256, and 5.48 in text-to-image generation on MS-COCO, among methods without accessing large external datasets during the training of generative models. Our results suggest that, for diffusion-b
    
[^127]: 基于DRAM的处理器加速神经网络推理：从边缘到云端

    Accelerating Neural Network Inference with Processing-in-DRAM: From the Edge to the Cloud. (arXiv:2209.08938v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2209.08938](http://arxiv.org/abs/2209.08938)

    该论文讨论了基于DRAM的内存中处理（PIM）方法加速神经网络推理的可行性。通过分析三种最先进的PIM架构，得出PIM极大地有利于内存受限的NN的结论。

    

    神经网络（NN）在重要性和复杂性上不断增长。神经网络的性能（及能效）可能会受到计算或内存资源的限制。在内存阵列附近或内部放置计算的内存中处理（PIM）范例是加速内存受限的NN的可行解决方案。然而，PIM架构因形式而异，不同的PIM方法导致不同的权衡。我们的目标是分析、讨论和对比基于DRAM的PIM架构对NN性能和能效的影响。为此，我们分析了三种最先进的PIM架构：（1）UPMEM，将处理器和DRAM阵列集成到单个二维芯片中；（2）Mensa，一种针对边缘设备量身定制的三维堆栈式PIM架构；和（3）SIMDRAM，它使用DRAM的模拟原理执行位串行操作。我们的分析表明，PIM极大地有利于内存受限的NN：（1）当GPU需要内存时，UPMEM提供了高端GPU的23倍性能。

    Neural networks (NNs) are growing in importance and complexity. A neural network's performance (and energy efficiency) can be bound either by computation or memory resources. The processing-in-memory (PIM) paradigm, where computation is placed near or within memory arrays, is a viable solution to accelerate memory-bound NNs. However, PIM architectures vary in form, where different PIM approaches lead to different trade-offs. Our goal is to analyze, discuss, and contrast DRAM-based PIM architectures for NN performance and energy efficiency. To do so, we analyze three state-of-the-art PIM architectures: (1) UPMEM, which integrates processors and DRAM arrays into a single 2D chip; (2) Mensa, a 3D-stack-based PIM architecture tailored for edge devices; and (3) SIMDRAM, which uses the analog principles of DRAM to execute bit-serial operations. Our analysis reveals that PIM greatly benefits memory-bound NNs: (1) UPMEM provides 23x the performance of a high-end GPU when the GPU requires memor
    
[^128]: 学习利用弹性执行器进行四足动物的运动控制

    Learning to Exploit Elastic Actuators for Quadruped Locomotion. (arXiv:2209.07171v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.07171](http://arxiv.org/abs/2209.07171)

    本文提出了一种直接在真实机器人上学习无模型控制器的方法，利用弹性执行器的动力学性质优化动态运动控制，学习到的控制器可实现高性能的四足运动控制。

    

    在四足运动中，基于弹簧的执行器可以提高能效和性能，但也增加了控制器设计的难度。以往的工作主要是通过建模与仿真来寻找最优的控制器，而本文提出直接在真实机器人上学习无模型控制器。我们的方法是首先由中央模式发生器（CPGs）合成步态，通过优化这些参数得到一种能够实现高效运动的开环控制器。然后，为了使控制器更加稳健并进一步提高性能，本文采用强化学习来闭环控制，学习在CPGs之上的矫正动作。我们在DLR弹性四足机器人上评估了所提出的方法。学习到的慢跑和跳跃步态表明，在优化动态运动时利用弹性执行器动力学是自然发生的，尽管无模型控制器，但仍可实现高性能的运动控制。

    Spring-based actuators in legged locomotion provide energy-efficiency and improved performance, but increase the difficulty of controller design. While previous work has focused on extensive modeling and simulation to find optimal controllers for such systems, we propose to learn model-free controllers directly on the real robot. In our approach, gaits are first synthesized by central pattern generators (CPGs), whose parameters are optimized to quickly obtain an open-loop controller that achieves efficient locomotion. Then, to make this controller more robust and further improve the performance, we use reinforcement learning to close the loop, to learn corrective actions on top of the CPGs. We evaluate the proposed approach on the DLR elastic quadruped bert. Our results in learning trotting and pronking gaits show that exploitation of the spring actuator dynamics emerges naturally from optimizing for dynamic motions, yielding high-performing locomotion despite being model-free. The who
    
[^129]: 带凸损失的风险感知线性赌博机

    Risk-aware linear bandits with convex loss. (arXiv:2209.07154v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2209.07154](http://arxiv.org/abs/2209.07154)

    本论文研究了带上下文的风险感知线性赌博机问题，提出了一种用于估计风险度量的置信序列，并提出了一种乐观的UCB算法以学习最佳的风险感知行为。

    

    在多臂赌博机等决策问题中，代理通过优化某种反馈进行顺序学习。虽然平均回报标准已被广泛研究，但反映对不良结果的厌恶的其他度量，例如方差、条件风险价值（CVaR），可能对关键应用（医疗保健、农业）有用。在没有上下文信息的赌博反馈下提出了用于此类风险感知度量的算法。在这项工作中，我们研究了具有上下文的赌徒，在这些赌博机反馈下，可以通过凸损失的最小化来提取这种风险度量作为上下文的线性函数。符合此框架的典型示例是expectile度量，它是通过不对称最小二乘问题的解得到的。使用卡曼超融合方法，我们导出了用于估计此类风险度量的置信序列。然后，我们提出了一种乐观的UCB算法，以学习最佳的风险感知行为。

    In decision-making problems such as the multi-armed bandit, an agent learns sequentially by optimizing a certain feedback. While the mean reward criterion has been extensively studied, other measures that reflect an aversion to adverse outcomes, such as mean-variance or conditional value-at-risk (CVaR), can be of interest for critical applications (healthcare, agriculture). Algorithms have been proposed for such risk-aware measures under bandit feedback without contextual information. In this work, we study contextual bandits where such risk measures can be elicited as linear functions of the contexts through the minimization of a convex loss. A typical example that fits within this framework is the expectile measure, which is obtained as the solution of an asymmetric least-square problem. Using the method of mixtures for supermartingales, we derive confidence sequences for the estimation of such risk measures. We then propose an optimistic UCB algorithm to learn optimal risk-aware act
    
[^130]: 论分离数据的分布式学习的泛化

    On Generalization of Decentralized Learning with Separable Data. (arXiv:2209.07116v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07116](http://arxiv.org/abs/2209.07116)

    本文研究了梯度下降分布式学习在分离数据上的广义性质，并推导出新颖的有限时间广义性能界限，这对于当前仅限于集中式学习场景下的研究有所补充。

    

    当数据自然地分布在基础图上传递的代理之间时，分布式学习提供了隐私和通信效率。 在过度参数化的学习设置中，模型被训练为零训练损失。 本文研究了梯度下降分布式学习在分离数据上的算法和广义性质。 具体来说，对于分布式梯度下降（DGD）和一系列在无限远处渐近为零的损失函数（包括指数和对数损失），我们推导出了新颖的有限时间广义性能界限。 这补充了最近一系列研究梯度下降在分离数据上的广义性能和隐式偏差，但目前仅限于集中式学习场景的工作。值得注意的是，我们的泛化界限与其集中式对应物的大小近乎相等。 独立于此，本文还建立了关于DGD的新边界。

    Decentralized learning offers privacy and communication efficiency when data are naturally distributed among agents communicating over an underlying graph. Motivated by overparameterized learning settings, in which models are trained to zero training loss, we study algorithmic and generalization properties of decentralized learning with gradient descent on separable data. Specifically, for decentralized gradient descent (DGD) and a variety of loss functions that asymptote to zero at infinity (including exponential and logistic losses), we derive novel finite-time generalization bounds. This complements a long line of recent work that studies the generalization performance and the implicit bias of gradient descent over separable data, but has thus far been limited to centralized learning scenarios. Notably, our generalization bounds approximately match in order their centralized counterparts. Critical behind this, and of independent interest, is establishing novel bounds on the training
    
[^131]: 一种改进的在线最小和集覆盖算法

    An Improved Algorithm For Online Min-Sum Set Cover. (arXiv:2209.04870v3 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2209.04870](http://arxiv.org/abs/2209.04870)

    本论文提出了一种改进的在线最小和集覆盖算法，其算法能够在不知道未来集合的前提下重新排序元素，以至于列表前的至少一个元素能够匹配上流中的某个元素，同时算法的表现也优于以往的算法。

    

    本文研究了一种基本的在线偏好聚合模型，其中算法维护了一个包含 n 个元素的有序列表。输入是一个首选集合 R1，R2，...，Rt，... 的流。在看到Rt时，算法不知道未来的任何集合，必须重新排序元素（更改列表排序），以便在列表前部至少找到一个Rt的元素。产生的成本是列表更新成本（相邻列表元素交换次数）和存取成本（Rt的第一个元素在列表上的位置）的总和。这种情况在应用程序中自然发生，在使用商店客户的聚合偏好订购项目时。这个问题的理论基础被称为最小和集覆盖。与之前的工作（Fotakis等人，ICALP 2020，NIPS 2020）大多研究了在线算法ALG与静态最优解（唯一最优列表排序）之间的性能不同，本文研究了一种论证方法，并提出了一种新的随机算法RR及其扩展RR+。我们表明，我们的算法RR+实现了一个$\tilde{O}(n^{2/3})$-competitive ratio相对于最优离线解，这是在线设置中已知的最佳绑定的改进。

    We study a fundamental model of online preference aggregation, where an algorithm maintains an ordered list of $n$ elements. An input is a stream of preferred sets $R_1, R_2, \dots, R_t, \dots$. Upon seeing $R_t$ and without knowledge of any future sets, an algorithm has to rerank elements (change the list ordering), so that at least one element of $R_t$ is found near the list front. The incurred cost is a sum of the list update costs (the number of swaps of neighboring list elements) and access costs (position of the first element of $R_t$ on the list). This scenario occurs naturally in applications such as ordering items in an online shop using aggregated preferences of shop customers. The theoretical underpinning of this problem is known as Min-Sum Set Cover.  Unlike previous work (Fotakis et al., ICALP 2020, NIPS 2020) that mostly studied the performance of an online algorithm ALG against the static optimal solution (a single optimal list ordering), in this paper, we study an argua
    
[^132]: 量化分层VAE的有损图像压缩

    Lossy Image Compression with Quantized Hierarchical VAEs. (arXiv:2208.13056v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2208.13056](http://arxiv.org/abs/2208.13056)

    该论文提出了一种量化分层VAE模型，通过重新设计潜在变量模型，让模型在测试时能够容易地进行量化和熵编码，该模型通过粗糙到精细的方式压缩图像，支持并行编解码，在自然图像有损压缩上表现优异。

    

    最近的研究表明了变分自编码器（VAE）与速率失真理论之间的强大理论联系。鉴于此，我们从生成建模的角度考虑了有损图像压缩问题。通过使用量化感知后验和先验重新设计ResNet VAE的潜在变量模型，使其能够在测试时轻松量化和熵编码。我们采用改进的神经网络架构，呈现了一个强大而高效的模型，其在自然图像有损压缩上优于以往方法。我们的模型以粗糙到精细的方式压缩图像，支持并行编解码，从而在GPU上快速执行。代码可在https://github.com/duanzhiihao/lossy-vae获得。

    Recent research has shown a strong theoretical connection between variational autoencoders (VAEs) and the rate-distortion theory. Motivated by this, we consider the problem of lossy image compression from the perspective of generative modeling. Starting with ResNet VAEs, which are originally designed for data (image) distribution modeling, we redesign their latent variable model using a quantization-aware posterior and prior, enabling easy quantization and entropy coding at test time. Along with improved neural network architecture, we present a powerful and efficient model that outperforms previous methods on natural image lossy compression. Our model compresses images in a coarse-to-fine fashion and supports parallel encoding and decoding, leading to fast execution on GPUs. Code is available at https://github.com/duanzhiihao/lossy-vae.
    
[^133]: 用量子开关测量不相容性并对量子观测结果进行聚类

    Measuring incompatibility and clustering quantum observables with a quantum switch. (arXiv:2208.06210v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2208.06210](http://arxiv.org/abs/2208.06210)

    本研究提出了一种量子不相容性测量指标“共同本征空间干扰”，并进一步通过量子开关实现量化，方便量子机器学习任务的处理。同时，算法可以对测量结果进行聚类，确定共享相似测量环境的观察者组。

    

    不相容观测结果是量子力学的基石，并且是量子技术中的宝贵资源。本文提出了一种不相容性测量指标，即“共同本征空间干扰”，可以量化一个精确观测量对另一个本征空间的干扰量。该指标提供了 von Neumann 测量空间的度量，并可以通过使用称为“量子开关”的设置，让测量过程以不确定的顺序进行，从而高效地进行估计。由于这些特性，MED可以在量子机器学习任务中使用。通过提供一个无监督算法，对未知的von Neumann 测量结果进行聚类。我们的算法对噪声具有鲁棒性，并可用于确定共享近似相同测量环境的观察者组。

    The existence of incompatible observables is a cornerstone of quantum mechanics and a valuable resource in quantum technologies. Here we introduce a measure of incompatibility, called the mutual eigenspace disturbance (MED), which quantifies the amount of disturbance induced by the measurement of a sharp observable on the eigenspaces of another. The MED provides a metric on the space of von Neumann measurements, and can be efficiently estimated by letting the measurement processes act in an indefinite order, using a setup known as the quantum switch, which also allows one to quantify the noncommutativity of arbitrary quantum processes. Thanks to these features, the MED can be used in quantum machine learning tasks. We demonstrate this application by providing an unsupervised algorithm that clusters unknown von Neumann measurements. Our algorithm is robust to noise can be used to identify groups of observers that share approximately the same measurement context.
    
[^134]: 基于AI的有机化学超图网络：网络统计和反应分类应用

    AI-driven Hypergraph Network of Organic Chemistry: Network Statistics and Applications in Reaction Classification. (arXiv:2208.01647v2 [q-bio.MN] UPDATED)

    [http://arxiv.org/abs/2208.01647](http://arxiv.org/abs/2208.01647)

    本文通过将化学反应表示为超图，构建了基于AI的有机化学超图网络并进行了统计研究，为反应分类提供了新思路。

    

    近年来，高通量筛选的进展、更复杂化学设计空间的可访问性以及精确的分子建模框架的发展，促进了新反应和分子的快速发现。因此，需要进行关注最近趋势并将其外推到可能的未来轨迹的综合性研究来理解不断增长的化学文献。为此，已经报告了几个基于网络理论的研究，这些研究使用化学反应的有向图表示。在这里，我们使用超图来表示化学反应，其中超边表示化学反应，节点表示参与的分子。我们使用标准的反应数据集构造了一个超网络，并报告其统计信息，例如度分布、平均路径长度、同配性或度相关性、PageRank 中心性和基于图的聚类（或社区）。

    Rapid discovery of new reactions and molecules in recent years has been facilitated by the advancements in high throughput screening, accessibility to a much more complex chemical design space, and the development of accurate molecular modeling frameworks. A holistic study of the growing chemistry literature is, therefore, required that focuses on understanding the recent trends and extrapolating them into possible future trajectories. To this end, several network theory-based studies have been reported that use a directed graph representation of chemical reactions. Here, we perform a study based on representing chemical reactions as hypergraphs where the hyperedges represent chemical reactions and nodes represent the participating molecules. We use a standard reactions dataset to construct a hypernetwork and report its statistics such as degree distributions, average path length, assortativity or degree correlations, PageRank centrality, and graph-based clusters (or communities). We a
    
[^135]: 从哪里开始？关于联邦学习中预训练和初始化的影响。

    Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning. (arXiv:2206.15387v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15387](http://arxiv.org/abs/2206.15387)

    该论文研究了在联邦学习中从预训练模型开始的影响，证明这种方法可以减少训练时间并提高模型的准确性。

    

    联邦学习中的一个常见挑战是异构性问题。数据异构性是指来自不同客户端的数据可能遵循非常不同的分布。系统异构性是指客户端设备具有不同的系统能力。许多联邦优化方法都解决了这个挑战。虽然文献中的实证评估通常从随机初始化开始联邦训练，但在许多实际的联邦学习应用中，服务器可以访问用于训练任务的代理数据，可以用这些数据在开始联邦训练之前预训练模型。使用四个标准联邦学习基准数据集，我们经验性地研究了在联邦学习中从经过预训练的模型开始的影响。不出所料，从经过预训练的模型开始可以减少达到目标误差率所需的训练时间，并使模型训练更准确（高达40％）。

    An oft-cited challenge of federated learning is the presence of heterogeneity. \emph{Data heterogeneity} refers to the fact that data from different clients may follow very different distributions. \emph{System heterogeneity} refers to client devices having different system capabilities. A considerable number of federated optimization methods address this challenge. In the literature, empirical evaluations usually start federated training from random initialization. However, in many practical applications of federated learning, the server has access to proxy data for the training task that can be used to pre-train a model before starting federated training. Using four standard federated learning benchmark datasets, we empirically study the impact of starting from a pre-trained model in federated learning. Unsurprisingly, starting from a pre-trained model reduces the training time required to reach a target error rate and enables the training of more accurate models (up to 40\%) than is
    
[^136]: 关于网络中分布式随机双层优化算法的收敛性研究

    On the Convergence of Distributed Stochastic Bilevel Optimization Algorithms over a Network. (arXiv:2206.15025v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15025](http://arxiv.org/abs/2206.15025)

    本论文提出了两种新型分散式随机双层优化算法，在网络中解决了分布式数据的问题，并初步证明了其在非凸强凸问题方面的收敛速度。实验结果表明，算法是有效的。

    

    双层优化算法已被应用于各种机器学习模型中，并且近年来已开发出许多随机双层优化算法。然而，大多数现有算法都将重点放在单机设置上，因此无法处理分布式数据。为了解决这个问题，在所有参与者组成网络并在该网络中进行点对点通信的情况下，我们开发了两种基于渐变跟踪通信机制和两种不同梯度估计器的新型分散式随机双层优化算法。此外，我们运用新型理论分析策略证明了这些算法在非凸强凸问题方面的收敛速度。据我们所知，这是第一个实现这些理论结果的研究。最后，我们将算法应用于实际机器学习模型中，实验结果证实了我们算法的有效性。

    Bilevel optimization has been applied to a wide variety of machine learning models, and numerous stochastic bilevel optimization algorithms have been developed in recent years. However, most existing algorithms restrict their focus on the single-machine setting so that they are incapable of handling the distributed data. To address this issue, under the setting where all participants compose a network and perform peer-to-peer communication in this network, we developed two novel decentralized stochastic bilevel optimization algorithms based on the gradient tracking communication mechanism and two different gradient estimators. Additionally, we established their convergence rates for nonconvex-strongly-convex problems with novel theoretical analysis strategies. To our knowledge, this is the first work achieving these theoretical results. Finally, we applied our algorithms to practical machine learning models, and the experimental results confirmed the efficacy of our algorithms.
    
[^137]: 基于时间序列的数据增强技术：一份综述和分类

    Data Augmentation techniques in time series domain: A survey and taxonomy. (arXiv:2206.13508v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.13508](http://arxiv.org/abs/2206.13508)

    本综述介绍了基于时间序列数据增强技术的最新进展，并提出了一个分类法，旨在提高训练深度神经网络的数据集的大小和一致性，从而提高模型的效率和性能。

    

    随着深度学习建模的最新进展，利用其在时间序列领域中出色性能的方式并不需要太长时间。深度神经网络在处理时间序列方面严重依赖于训练中使用的数据集的大小和一致性。这些特征通常在现实世界中并不丰富，通常受到限制和需要保证的约束。因此，提高数据量的有效方法是使用数据增强技术，无论是通过添加噪声或置换还是生成新的合成数据。本文系统地回顾了该领域中的最新技术现状，提供了所有可用算法的概述，并提出了最相关研究的分类法。不同变体的效率将作为该过程的中心部分进行评估，同时还将评估不同的性能指标以及每个模型的主要问题。

    With the latest advances in Deep Learning-based} generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using Data Augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state-of-the-art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will b
    
[^138]: FEATHERS：联邦体系结构和超参数搜索。

    FEATHERS: Federated Architecture and Hyperparameter Search. (arXiv:2206.12342v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.12342](http://arxiv.org/abs/2206.12342)

    介绍了一种名为FEATHERS的方法，它使用差分隐私保护数据隐私，可以联合优化在分布式数据设置中的神经结构和超参数，具有高效率和良好的收敛性能。

    

    深度神经结构对于当今许多人工智能任务的性能有着深远影响，然而其设计仍然严重依赖于人类的先前知识和经验。神经结构搜索（NAS）以及超参数优化（HO）有助于减少这种依赖。然而，随着分布式存储数据量的增加，最先进的NAS和HO往往变得不可行，通常违反数据隐私法规，如GDPR和CCPA。为此，我们引入了FEATHERS（联邦体系结构和超参数搜索），这种方法不仅可以在分布式数据设置中联合优化神经结构和优化相关的超参数，而且还通过使用差分隐私（DP）遵守数据隐私规定。我们证明，FEATHERS可以有效地优化体系结构和优化相关的超参数，同时展示收敛情况。

    Deep neural architectures have profound impact on achieved performance in many of today's AI tasks, yet, their design still heavily relies on human prior knowledge and experience. Neural architecture search (NAS) together with hyperparameter optimization (HO) helps to reduce this dependence. However, state of the art NAS and HO rapidly become infeasible with increasing amount of data being stored in a distributed fashion, typically violating data privacy regulations such as GDPR and CCPA. As a remedy, we introduce FEATHERS $\textbf{FE}$derated $\textbf{A}$rchi$\textbf{T}$ecture and $\textbf{H}$yp$\textbf{ER}$parameter $\textbf{S}$earch, a method that not only optimizes both neural architectures and optimization-related hyperparameters jointly in distributed data settings, but further adheres to data privacy through the use of differential privacy (DP). We show that FEATHERS efficiently optimizes architectural and optimization-related hyperparameters alike, while demonstrating converg
    
[^139]: FreeKD：用于图神经网络的自由方向知识蒸馏

    FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks. (arXiv:2206.06561v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.06561](http://arxiv.org/abs/2206.06561)

    本文提出了一种称为FreeKD的自由方向知识蒸馏框架，通过强化学习针对图神经网络构建两个较浅的GNN，使其在它们之间交换知识，无需提供深度优化的教师GNN，并且采用动态和自由方向的知识转移策略。

    

    知识蒸馏已经证明了一定的效果，可以提高图神经网络的性能，其目标是将来自深度教师GNN的知识浓缩到较浅的学生GNN中。然而，由于已知的过度参数化和过度平滑问题，构建一个令人满意的深层教师GNN实际上是困难的，这导致在实际应用中的无效知识传递。在本文中，我们提出了第一个自由方向知识蒸馏框架FreeKD，通过强化学习针对GNN，其不再需要提供深度优化的教师GNN。我们的核心思想是通过强化学习以分层方式协作地构建两个较浅的GNN，以在它们之间交换知识。我们观察到，一个典型的GNN模型通常在训练过程中在不同节点有较好和较差的表现，因此设计了一种动态和自由方向的知识转移策略，包括〇

    Knowledge distillation (KD) has demonstrated its effectiveness to boost the performance of graph neural networks (GNNs), where its goal is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is actually difficult to train a satisfactory teacher GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via Reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. The core idea of our work is to collaboratively build two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often has better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that consists o
    
[^140]: 一种基于连续决策的视觉导航普适性对抗扰动生成方法

    Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation. (arXiv:2206.05751v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05751](http://arxiv.org/abs/2206.05751)

    本文提出了一种Consistent Attack的方法用于生成视觉导航中的普适性对抗扰动，在考虑系统动态的同时优化对抗扰动，实验结果表明该方法优于基线UAP方法且表现最先进。

    

    针对使用深度神经网络的视觉导航嵌入式智能体普遍存在的对抗性攻击威胁，本文提出了一种名为"Consistent Attack"的普适性对抗扰动生成方法，其在扰动攻击时不仅考虑了系统动态，还优化了对抗扰动，最小化智能体的累积奖励。实验结果表明，该方法在两个流行基准测试上明显优于基线UAP方法，实现了最先进的性能。

    Embodied agents in vision navigation coupled with deep neural networks have attracted increasing attention. However, deep neural networks have been shown vulnerable to malicious adversarial noises, which may potentially cause catastrophic failures in Embodied Vision Navigation. Among different adversarial noises, universal adversarial perturbations (UAP), i.e., a constant image-agnostic perturbation applied on every input frame of the agent, play a critical role in Embodied Vision Navigation since they are computation-efficient and application-practical during the attack. However, existing UAP methods ignore the system dynamics of Embodied Vision Navigation and might be sub-optimal. In order to extend UAP to the sequential decision setting, we formulate the disturbed environment under the universal noise $\delta$, as a $\delta$-disturbed Markov Decision Process ($\delta$-MDP). Based on the formulation, we analyze the properties of $\delta$-MDP and propose two novel Consistent Attack me
    
[^141]: 随机特征回归模型的最佳激活函数

    Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2206.01332](http://arxiv.org/abs/2206.01332)

    本文确定了随机特征回归模型的最佳激活函数。这些函数可能是线性的、饱和线性函数或基于Hermite多项式的函数。使用最佳激活函数会影响RFR模型的重要特性，如双峰曲线和最佳正则化参数与噪声水平的相关性。

    

    近期已研究了随机特征回归模型(RFR)的渐近均方测试误差和灵敏度。我们在此基础上，通过不同的函数简洁概念，确定了在闭合形式下极小化RFR测试误差和灵敏度组合的激活函数(AF)族群。我们发现在某些场景下，最佳AF可以是线性的、饱和线性函数或基于Hermite多项式表示的函数。最后，我们展示了使用最佳AF如何影响RFR模型的重要特性，比如双峰曲线和其最佳正则化参数与观察噪声水平的相关性。

    The asymptotic mean squared test error and sensitivity of the Random Features Regression model (RFR) have been recently studied. We build on this work and identify in closed-form the family of Activation Functions (AFs) that minimize a combination of the test error and sensitivity of the RFR under different notions of functional parsimony. We find scenarios under which the optimal AFs are linear, saturated linear functions, or expressible in terms of Hermite polynomials. Finally, we show how using optimal AFs impacts well-established properties of the RFR model, such as its double descent curve, and the dependency of its optimal regularization parameter on the observation noise level.
    
[^142]: itKD: 基于交换传递的知识蒸馏用于3D物体检测

    itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection. (arXiv:2205.15531v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.15531](http://arxiv.org/abs/2205.15531)

    提出了基于交换传递的知识蒸馏框架，用于3D物体检测，同时考虑准确性和计算效率，具有压缩表示损失和头部注意力损失等优化手段。

    

    基于点云的3D物体检测最近取得了显著进展。然而，大多数研究仅关注提高准确性，而没有考虑计算效率。本文首先提出了一个自编码器风格的框架，通过基于交换传递的知识蒸馏进行通道压缩和解压缩。为了学习教师网络的地图视图特征，从教师和学生网络得到的特征被独立地通过共享的自编码器传递；这里，我们使用了一种压缩表示损失，将学生和教师网络的通道压缩知识作为一种正则化进行绑定。解压的特征反向传递以减小交换重构中的差距。最后，我们提出了一个头部注意力损失，以匹配多头自注意机制所提取的3D物体检测信息。

    Point-cloud based 3D object detectors recently have achieved remarkable progress. However, most studies are limited to the development of network architectures for improving only their accuracy without consideration of the computational efficiency. In this paper, we first propose an autoencoder-style framework comprising channel-wise compression and decompression via interchange transfer-based knowledge distillation. To learn the map-view feature of a teacher network, the features from teacher and student networks are independently passed through the shared autoencoder; here, we use a compressed representation loss that binds the channel-wised compression knowledge from both student and teacher networks as a kind of regularization. The decompressed features are transferred in opposite directions to reduce the gap in the interchange reconstructions. Lastly, we present an head attention loss to match the 3D object detection information drawn by the multi-head self-attention mechanism. Th
    
[^143]: 动态潜在状态模型中的反事实分析

    Counterfactual Analysis in Dynamic Latent State Models. (arXiv:2205.13832v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13832](http://arxiv.org/abs/2205.13832)

    该论文提供了一个框架来解决带有隐藏状态的动态模型的反事实分析问题，并在乳腺癌案例研究中成功应用。通过优化方法得到了反事实量的上限和下限，并且该论文是第一个在动态潜在状态模型中进行这种计算的研究。

    

    我们提供了一个基于优化的框架来执行具有隐藏状态的动态模型中的反事实分析。我们的框架以“猜测、行动和预测”方法为基础，以回答反事实查询，并解决了两个关键问题：(1)状态是隐藏的，(2)模型是动态的。考虑到对潜在因果机制的缺乏了解以及可能存在无限多个这样的机制，我们在该空间上进行优化，并计算所关心的反事实量的上限和下限。我们的工作汇集了因果关系、状态空间模型、模拟和优化的思想，并应用于乳腺癌案例研究中。据我们所知，我们是第一个在动态潜在状态模型中计算反事实查询的上限和下限的研究。

    We provide an optimization-based framework to perform counterfactual analysis in a dynamic model with hidden states. Our framework is grounded in the ``abduction, action, and prediction'' approach to answer counterfactual queries and handles two key challenges where (1) the states are hidden and (2) the model is dynamic. Recognizing the lack of knowledge on the underlying causal mechanism and the possibility of infinitely many such mechanisms, we optimize over this space and compute upper and lower bounds on the counterfactual quantity of interest. Our work brings together ideas from causality, state-space models, simulation, and optimization, and we apply it on a breast cancer case study. To the best of our knowledge, we are the first to compute lower and upper bounds on a counterfactual query in a dynamic latent-state model.
    
[^144]: 利用泊松近似似然进行流行病分区模型中的一致且快速推理

    Consistent and fast inference in compartmental models of epidemics using Poisson Approximate Likelihoods. (arXiv:2205.13602v3 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2205.13602](http://arxiv.org/abs/2205.13602)

    引入泊松近似似然(PAL)方法，与ODE方法不同，PAL是从有限人口数量的随机分区模型的近似滤波方程导出的，并且大人口数量限制推动最大PAL估计量的一致性。

    

    为了解决流行病学推理向复杂和异质性模型的扩展难题，我们引入了泊松近似似然(PAL)方法。与采用大人口数量限制来激励确定性模型的ODE方法不同，PAL是从有限人口数量的随机分区模型的近似滤波方程导出的，并且大人口数量限制推动最大PAL估计量的一致性。我们的理论结果似乎是第一个适用于广泛类别的部分观察随机分区模型和解决大人口数量局限性的基于似然的参数估计一致性结果。PALs实现简单，仅涉及基本算术操作和没有调整参数，且评估速度快，不需要从模型进行模拟，计算成本与人口规模无关。通过示例，我们演示了如何使用PALs

    Addressing the challenge of scaling-up epidemiological inference to complex and heterogeneous models, we introduce Poisson Approximate Likelihood (PAL) methods. In contrast to the popular ODE approach to compartmental modelling, in which a large population limit is used to motivate a deterministic model, PALs are derived from approximate filtering equations for finite-population, stochastic compartmental models, and the large population limit drives consistency of maximum PAL estimators. Our theoretical results appear to be the first likelihood-based parameter estimation consistency results which apply to a broad class of partially observed stochastic compartmental models and address the large population limit. PALs are simple to implement, involving only elementary arithmetic operations and no tuning parameters, and fast to evaluate, requiring no simulation from the model and having computational cost independent of population size. Through examples we demonstrate how PALs can be used
    
[^145]: 顺序人类教学的机器学习解释性研究

    Explanatory machine learning for sequential human teaching. (arXiv:2205.10250v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.10250](http://arxiv.org/abs/2205.10250)

    本文研究了顺序问题解决中，课程顺序和机器学习解释对人类理解力的影响。

    

    最近越来越多的人关注机器学习理论的可理解性。归纳逻辑编程（ILP）使用逻辑编程技术基于缩略推理和归纳推理，从少量的数据中得出逻辑理论。学得的理论以规则形式表示，是所获知识的声明性描述。在早期研究中，作者首次提出了基于机器学习逻辑规则的简单分类任务对人类理解能力有可衡量的提高的证据。在后续的研究中，发现向人类展示机器学习解释 在游戏学习环境中产生了有益和有害的影响。我们通过研究概念呈现的顺序对人类理解力的影响来继续探讨可理解性。在这项工作中，我们研究了课程顺序和机器学习解释对于顺序问题解决的解释效果。

    The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic rules for simple classification tasks. In a later study, it was found that the presentation of machine-learned explanations to humans can produce both beneficial and harmful effects in the context of game learning. We continue our investigation of comprehensibility by examining the effects of the ordering of concept presentations on human comprehension. In this work, we examine the explanatory effects of curriculum order and the presence of machine-learned explanations for sequential problem-solving. We show th
    
[^146]: 一个规则搜索框架用于早期识别慢性紧急无家可归者

    A Rule Search Framework for the Early Identification of Chronic Emergency Homeless Shelter Clients. (arXiv:2205.09883v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2205.09883](http://arxiv.org/abs/2205.09883)

    本研究使用规则搜索技术，早期识别有可能成为长期或慢性无家可归者收容所的高风险人群。在实时交付支持性住房计划的框架内，应用本文方法使得早期识别处于慢性无家可归者风险的客户的中位时间从297天降至162天。

    

    本文利用规则搜索技术，早期识别那些有可能成为长期或慢性住在无家可归者收容所的高风险人群。使用一家北美主要收容所服务与超过40,000人的12年交互数据集，采用优化修剪无序搜索(OPUS)算法，开发直观而有效的规则。在能够实现实时交付支持性住房计划的框架内，对这些规则进行了评估。结果表明，应用本文方法使得早期识别处于慢性无家可归者风险的客户的中位时间从297天降至162天。

    This paper uses rule search techniques for the early identification of emergency homeless shelter clients who are at risk of becoming long term or chronic shelter users. Using a data set from a major North American shelter containing 12 years of service interactions with over 40,000 individuals, the optimized pruning for unordered search (OPUS) algorithm is used to develop rules that are both intuitive and effective. The rules are evaluated within a framework compatible with the real-time delivery of a housing program meant to transition high risk clients to supportive housing. Results demonstrate that the median time to identification of clients at risk of chronic shelter use drops from 297 days to 162 days when the methods in this paper are applied.
    
[^147]: FedGiA: 一种高效的混合式联邦学习算法

    FedGiA: An Efficient Hybrid Algorithm for Federated Learning. (arXiv:2205.01438v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.01438](http://arxiv.org/abs/2205.01438)

    FedGiA是一种高效的混合式联邦学习算法，能够更有效地节省通信和计算资源，并在温和条件下实现全局收敛。

    

    联邦学习近来取得了进展，但仍面临许多挑战，如算法如何节省通信资源和降低计算成本，以及它们是否会收敛。为了解决这些关键问题，我们提出了一种混合联合学习算法（FedGiA），将梯度下降和不精确交替方向乘法方法相结合。所提出的算法在理论上和数值上比几种最先进的算法更具通信和计算效率。此外，在温和条件下，它还具有全局收敛性。

    Federated learning has shown its advances recently but is still facing many challenges, such as how algorithms save communication resources and reduce computational costs, and whether they converge. To address these critical issues, we propose a hybrid federated learning algorithm (FedGiA) that combines the gradient descent and the inexact alternating direction method of multipliers. The proposed algorithm is more communication- and computation-efficient than several state-of-the-art algorithms theoretically and numerically. Moreover, it also converges globally under mild conditions.
    
[^148]: CLIP-Dissect：深度视觉网络中神经元表示的自动描述

    CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks. (arXiv:2204.10965v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10965](http://arxiv.org/abs/2204.10965)

    CLIP-Dissect是一种用于自动描述视觉网络中神经元功能的新技术，它可以无需任何标记数据或人类示例即将内部神经元标记为无需任何标记数据或人类示例的开放概念，并比现有方法提供了更准确的描述。此外，它具有灵活性、高效性和可扩展性。

    

    本文提出了一种新技术CLIP-Dissect，可以自动描述视觉网络中单个隐藏神经元的功能。CLIP-Dissect利用了最近在多模态视觉/语言模型方面的进展，将内部神经元标记为无需任何标记数据或人类示例的开放概念。我们证明了CLIP-Dissect提供了比现有方法更准确的描述，其中包括具备“地面真相”（ground-truth）的最后一层神经元以及具备定性好的隐藏层神经元。此外，该方法非常灵活：它与模型无关，可以轻松处理新概念，可以扩展以利用未来更好的多模态模型。最后，CLIP-Dissect计算效率高，可以在短短4分钟内标记ResNet-50的五层所有神经元，比现有方法快10倍以上。我们的代码可在https://github.com/Trustworthy-ML-Lab/CLIP-dissect 上找到。

    In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10 times faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect.
    
[^149]: CgAT：基于中心引导的对抗性训练提升Hashing检索鲁棒性

    CgAT: Center-Guided Adversarial Training for Deep Hashing-Based Retrieval. (arXiv:2204.10779v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.10779](http://arxiv.org/abs/2204.10779)

    本文提出了CgAT方法，基于中心引导的对抗性训练方法，可提升深度Hashing网络检索的鲁棒性，取得了领先于现有方法的效果。

    

    深度Hashing在图像检索领域被广泛应用，但往往容易受到对抗样本的攻击。为此，本文提出了基于min-max的中心引导的对抗性训练方法（CgAT），通过最坏的对抗性样本来提高深度Hashing网络的鲁棒性。实验表明，该方法在多个基准数据集上优于目前深度Hashing检索领域中的最新对抗性防御算法。

    Deep hashing has been extensively utilized in massive image retrieval because of its efficiency and effectiveness. However, deep hashing models are vulnerable to adversarial examples, making it essential to develop adversarial defense methods for image retrieval. Existing solutions achieved limited defense performance because of using weak adversarial samples for training and lacking discriminative optimization objectives to learn robust features. In this paper, we present a min-max based Center-guided Adversarial Training, namely CgAT, to improve the robustness of deep hashing networks through worst adversarial examples. Specifically, we first formulate the center code as a semantically-discriminative representative of the input image content, which preserves the semantic similarity with positive samples and dissimilarity with negative examples. We prove that a mathematical formula can calculate the center code immediately. After obtaining the center codes in each optimization iterati
    
[^150]: CGC: 对比图聚类用于社区发现和跟踪

    CGC: Contrastive Graph Clustering for Community Detection and Tracking. (arXiv:2204.08504v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2204.08504](http://arxiv.org/abs/2204.08504)

    本文提出了一种全新的图聚类算法CGC，采用对比学习进行自监督表示学习，结合跟踪模块以应对动态图拓扑变化，在社区发现和跟踪方面表现出领先的状态。

    

    本文从图聚类的角度入手，探讨在网络数据中发现实体和实体之间的交互以及对它们进行社区跟踪的方法。我们提出了一种全新的端到端框架CGC，该方法利用对比学习范式进行自监督表示学习，并采用了跟踪模块以应对不断变化的图形拓扑。在各个真实场景和合成基准上，我们对CGC进行了评估，并在社区发现和跟踪方面展示出了卓越的性能，尤其在动态图上表现出了领先的状态。

    Given entities and their interactions in the web data, which may have occurred at different time, how can we find communities of entities and track their evolution? In this paper, we approach this important task from graph clustering perspective. Recently, state-of-the-art clustering performance in various domains has been achieved by deep clustering methods. Especially, deep graph clustering (DGC) methods have successfully extended deep clustering to graph-structured data by learning node representations and cluster assignments in a joint optimization framework. Despite some differences in modeling choices (e.g., encoder architectures), existing DGC methods are mainly based on autoencoders and use the same clustering objective with relatively minor adaptations. Also, while many real-world graphs are dynamic, previous DGC methods considered only static graphs. In this work, we develop CGC, a novel end-to-end framework for graph clustering, which fundamentally differs from existing meth
    
[^151]: PARC: 物理感知循环卷积神经网络用于同化中尺度反应性材料的介观力学

    PARC: Physics-Aware Recurrent Convolutional Neural Networks to Assimilate Meso-scale Reactive Mechanics of Energetic Materials. (arXiv:2204.07234v3 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2204.07234](http://arxiv.org/abs/2204.07234)

    提出了一种物理感知循环卷积神经网络(PARC)，可从数值模拟中学习介观尺度下的热力学和力学响应，预测受冲击的能量材料的热力学反应，具有准确性高，计算时间短的特点。

    

    冲击启动的能量材料（EM）的热力学反应受其微观结构的高度影响，提供了在“材料设计”框架中设计EM微观结构的机会。然而，当前的设计实践受限，需要大量模拟来构建复杂的EM结构 - 性能 - 性能关联。我们提出了物理感知循环卷积神经网络（PARC），这是一种深度学习算法，能够从少量高分辨率的直接数值模拟（DNS）中学习EM的介观热力学。验证结果表明，PARC可以预测受冲击的EM的热力学反应，其准确性与DNS相当，但计算时间明显更短。PARC的物理感知性增强了其建模能力和通用性，尤其是在未见预测方案时受到挑战时。我们还展示了在P

    The thermo-mechanical response of shock-initiated energetic materials (EM) is highly influenced by their microstructures, presenting an opportunity to engineer EM microstructure in a "materials-by-design" framework. However, the current design practice is limited, as a large ensemble of simulations is required to construct the complex EM structure-property-performance linkages. We present the Physics-Aware Recurrent Convolutional (PARC) Neural Network, a deep-learning algorithm capable of learning the mesoscale thermo-mechanics of EM from a modest number of high-resolution direct numerical simulations (DNS). Validation results demonstrated that PARC could predict the themo-mechanical response of shocked EM with a comparable accuracy to DNS but with notably less computation time. The physics awareness of PARC enhances its modeling capabilities and generalizability, especially when challenged in unseen prediction scenarios. We also demonstrate that visualizing the artificial neurons at P
    
[^152]: 基于物理/模型和数据驱动的低剂量计算机断层摄影：一项调查

    Physics-/Model-Based and Data-Driven Methods for Low-Dose Computed Tomography: A survey. (arXiv:2203.15725v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.15725](http://arxiv.org/abs/2203.15725)

    本文系统回顾了基于物理/模型的数据驱动方法在LDCT中的应用，提出了将物理/模型与深度学习结合起来的新兴趋势。

    

    自2016年以来，深度学习在低剂量计算机断层摄影（LDCT）成像方面取得了显著的成功。尽管受到大数据的推动，LDCT去噪和纯端到端重建网络常常遭受黑匣子的性质和稳定性等重大问题，这是将深度学习方法应用于低剂量CT应用的主要障碍。 一种新兴的趋势是将成像物理和模型与深度网络相结合，实现物理/模型驱动和数据驱动元素的混合。在本文中，我们系统地回顾了基于物理/模型的数据驱动方法在LDCT中的应用，总结了损失函数和训练策略，评估了不同方法的性能，并讨论了相关问题和未来方向。

    Since 2016, deep learning (DL) has advanced tomographic imaging with remarkable successes, especially in low-dose computed tomography (LDCT) imaging. Despite being driven by big data, the LDCT denoising and pure end-to-end reconstruction networks often suffer from the black box nature and major issues such as instabilities, which is a major barrier to apply deep learning methods in low-dose CT applications. An emerging trend is to integrate imaging physics and model into deep networks, enabling a hybridization of physics/model-based and data-driven elements. %This type of hybrid methods has become increasingly influential. In this paper, we systematically review the physics/model-based data-driven methods for LDCT, summarize the loss functions and training strategies, evaluate the performance of different methods, and discuss relevant issues and future directions.
    
[^153]: 计算机视觉GAN综述：最新研究、分析和分类（arXiv：2203.11242v2 [cs.LG] UPDATED）

    A survey on GANs for computer vision: Recent research, analysis and taxonomy. (arXiv:2203.11242v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.11242](http://arxiv.org/abs/2203.11242)

    本文综述了GAN的最新架构、损失函数优化、验证指标和应用领域，并提出了一个分类法以更好地理解计算机视觉中GAN的现状。

    

    在过去的几年中，深度学习领域已经进行了几次革命，其中最受关注的是生成对抗网络（GANs）的巨大影响。GAN不仅在定义其模型时提供了独特的架构，而且生成了引人注目的结果，对社会产生了直接影响。由于GAN带来的重大改进和新的研究领域，社区不断提出新的研究，使得跟上时代几乎是不可能的。我们的综述旨在提供GAN的概述，展示最新的架构、损失函数的优化、验证指标和最广泛认可的变体的应用领域。将评估不同变体的模型架构效率，展示最佳的应用领域；作为该过程的重要组成部分，将分析评估GAN性能的不同度量标准和经常使用的损失函数。最后，将提出一个分类法以更好地理解GAN在计算机视觉领域中的现状。

    In the last few years, there have been several revolutions in the field of deep learning, mainly headlined by the large impact of Generative Adversarial Networks (GANs). GANs not only provide an unique architecture when defining their models, but also generate incredible results which have had a direct impact on society. Due to the significant improvements and new areas of research that GANs have brought, the community is constantly coming up with new researches that make it almost impossible to keep up with the times. Our survey aims to provide a general overview of GANs, showing the latest architectures, optimizations of the loss functions, validation metrics and application areas of the most widely recognized variants. The efficiency of the different variants of the model architecture will be evaluated, as well as showing the best application area; as a vital part of the process, the different metrics for evaluating the performance of GANs and the frequently used loss functions will
    
[^154]: 重新思考基于重构自编码器的外样本检测

    Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection. (arXiv:2203.02194v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.02194](http://arxiv.org/abs/2203.02194)

    本文重新考虑了基于重构自编码器方法的外样本检测，在最大压缩自编码器的潜空间和保证重构能力的基础上，通过引入语义重构、数据确定性分解和标准化L2距离等策略，本文提出的方法在各个基准测试中都取得了最先进的性能表现，且不需要额外的标记外样本数据。

    

    在某些情况下，分类器需要检测远离其训练数据的外样本。重构自编码器方法利用输入重构误差作为新颖性与正常性的度量来解决这个问题。我们将这种方法的本质表述为具有对条件数据不确定性的代理查询的四元组域转换，其有内在偏见。因此，一种改进方向被形式化为最大压缩自编码器的潜空间，同时确保其重构能力，以充当所描述的域转换器。从中，引入了策略，包括语义重构、数据确定性分解和标准化L2距离，以实质性改善原始方法，这些方法共同在各种基准测试中建立了最先进的性能，例如，在Wide-ResNet上，CIFAR-100与TinyImagenet-crop的FPR@95%TPR为0.2%。重要的是，我们的方法不需要任何额外的标记外样本数据。

    In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any addit
    
[^155]: 监督学习的信息论框架

    An Information-Theoretic Framework for Supervised Learning. (arXiv:2203.00246v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.00246](http://arxiv.org/abs/2203.00246)

    本文提出了一种信息论框架，分析机器学习的数据需求，研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度，提出了样本复杂度边界。

    

    每年，深度学习展示出更加新颖和优秀的经验结果，其中采用更深和更广的神经网络。同时，利用现有的理论框架，分析超过两层的神经网络是困难的，除非诉诸于计数参数或遭遇深度指数样本复杂度边界。因此，在不同的角度下分析现代机器学习可能是有成果的。本文提出了一种新的信息论框架，具有自己的遗憾和样本复杂度概念，用于分析机器学习的数据需求。我们首先通过一些经典案例，例如标量估计和线性回归，使用我们的框架建立直觉和介绍一般技术。然后，我们利用该框架研究了由具有ReLU激活单元的深度神经网络生成的数据的学习样本复杂度。对于权重的特定先验分布，我们建立了学习的样本复杂度边界。

    Each year, deep learning demonstrates new and improved empirical results with deeper and wider neural networks. Meanwhile, with existing theoretical frameworks, it is difficult to analyze networks deeper than two layers without resorting to counting parameters or encountering sample complexity bounds that are exponential in depth. Perhaps it may be fruitful to try to analyze modern machine learning under a different lens. In this paper, we propose a novel information-theoretic framework with its own notions of regret and sample complexity for analyzing the data requirements of machine learning. With our framework, we first work through some classical examples such as scalar estimation and linear regression to build intuition and introduce general techniques. Then, we use the framework to study the sample complexity of learning from data generated by deep neural networks with ReLU activation units. For a particular prior distribution on weights, we establish sample complexity bounds tha
    
[^156]: 具有随机噪声的在线广义线性回归的最优解及其在异方差Bandits中的应用

    Optimal Online Generalized Linear Regression with Stochastic Noise and Its Application to Heteroscedastic Bandits. (arXiv:2202.13603v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13603](http://arxiv.org/abs/2202.13603)

    论文提出了一种具有随机噪声的在线广义线性回归问题的最优解，获得了接近最优的遗憾上限。同时，针对具有异方差噪声的广义线性Bandits问题，提出了一种基于FTRL的算法实现第一个方差感知的遗憾上限。

    

    我们研究了随机背景下在线广义线性回归问题，其中标签是由可能具有无界加性噪声的广义线性模型生成的。我们对经典的跟随正则化领袖（FTRL）算法进行了尖锐的分析，以应对标签噪声。具体而言，对于$\sigma$-子高斯标签噪声，我们的分析提供了一个遗憾的上限$O(\sigma^2 d \log T) + o(\log T)$，其中$d$是输入向量的维数, $T$ 是总回合数。我们还证明了随机在线线性回归的$\Omega(\sigma^2d\log(T/d))$下限，这表明我们的上限几乎是最优的。此外，我们将我们的分析扩展到了更精细的伯恩斯坦噪声条件。作为一个应用，我们研究了具有异方差噪声的广义线性Bandits，提出了一种基于FTRL的算法实现第一个方差感知的遗憾上限。

    We study the problem of online generalized linear regression in the stochastic setting, where the label is generated from a generalized linear model with possibly unbounded additive noise. We provide a sharp analysis of the classical follow-the-regularized-leader (FTRL) algorithm to cope with the label noise. More specifically, for $\sigma$-sub-Gaussian label noise, our analysis provides a regret upper bound of $O(\sigma^2 d \log T) + o(\log T)$, where $d$ is the dimension of the input vector, $T$ is the total number of rounds. We also prove a $\Omega(\sigma^2d\log(T/d))$ lower bound for stochastic online linear regression, which indicates that our upper bound is nearly optimal. In addition, we extend our analysis to a more refined Bernstein noise condition. As an application, we study generalized linear bandits with heteroscedastic noise and propose an algorithm based on FTRL to achieve the first variance-aware regret bound.
    
[^157]: PGMax: 用于离散概率图模型和JAX中的循环置信传播的因子图

    PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX. (arXiv:2202.04110v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.04110](http://arxiv.org/abs/2202.04110)

    PGMax是一个用于离散概率图模型的因子图工具，可以在JAX中自动运行高效且可扩展的循环置信传播，与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。

    PGMax is a factor graph tool for discrete probabilistic graphical models that automatically runs efficient and scalable loopy belief propagation in JAX. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups.

    PGMax是一个开源的Python包，用于轻松指定离散概率图模型（PGMs）作为因子图，并在JAX中自动运行高效且可扩展的循环置信传播（LBP）。PGMax支持具有可处理因子的一般因子图，并利用现代加速器（如GPU）进行推理。与现有替代方案相比，PGMax获得了更高质量的推理结果，推理时间加速高达三个数量级。PGMax还与快速增长的JAX生态系统无缝交互，开启了新的研究可能性。我们的源代码、示例和文档可在https://github.com/deepmind/PGMax上获得。

    PGMax is an open-source Python package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable loopy belief propagation (LBP) in JAX. PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax additionally interacts seamlessly with the rapidly growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/deepmind/PGMax.
    
[^158]: 带有深度学习感知组件的自主系统的离散事件控制器综合

    Discrete-Event Controller Synthesis for Autonomous Systems with Deep-Learning Perception Components. (arXiv:2202.03360v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03360](http://arxiv.org/abs/2202.03360)

    本文提出了一种名为DeepDECS的新方法，用于为使用深度神经网络分类器作为决策过程的感知步骤的自主系统合成构建正确的离散事件控制器。模型能够保证满足自主系统的安全性、可靠性和性能要求，并与一组优化目标的Pareto最优相对应。

    

    我们提出了一种名为DeepDECS的新方法，用于为使用深度神经网络(DNN)分类器作为决策过程的感知步骤的自主系统合成构建正确的离散事件控制器。尽管近年来深度学习取得了重大进展，但为这些系统提供安全保证仍然非常具有挑战性。我们的控制器综合方法通过将DNN验证与已验证马尔可夫模型的合成相结合来解决这一挑战。合成的模型对应于保证满足自主系统的安全性、可靠性和性能要求，并与一组优化目标的Pareto最优相对应的离散事件控制器。我们在仿真中使用该方法合成用于移动机器人碰撞缓解和维护共享控制自动驾驶中驾驶员注意力的控制器。

    We present DeepDECS, a new method for the synthesis of correct-by-construction discrete-event controllers for autonomous systems that use deep neural network (DNN) classifiers for the perception step of their decision-making processes. Despite major advances in deep learning in recent years, providing safety guarantees for these systems remains very challenging. Our controller synthesis method addresses this challenge by integrating DNN verification with the synthesis of verified Markov models. The synthesised models correspond to discrete-event controllers guaranteed to satisfy the safety, dependability and performance requirements of the autonomous system, and to be Pareto optimal with respect to a set of optimisation objectives. We use the method in simulation to synthesise controllers for mobile-robot collision mitigation and for maintaining driver attentiveness in shared-control autonomous driving.
    
[^159]: 抗相关噪声注入用于提高泛化性能

    Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.02831](http://arxiv.org/abs/2202.02831)

    本文发现，在一些目标函数中，抗相关噪声的梯度下降方法比传统的梯度下降和常规扰动梯度下降有更好的泛化性能。理论分析证明了这是因为 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。

    

    将人工噪声注入梯度下降常常被用于改善机器学习模型的性能。通常，这种扰动的梯度下降方法使用的是不相关的噪声。然而，目前尚不清楚是否使用不同类型的噪声能够提供更好的泛化性能。本文聚焦于相关的扰动。我们研究了各种目标函数，发现带有抗相关扰动的梯度下降（"Anti-PGD"）比传统的梯度下降和常规的（不相关的）扰动梯度下降有着更好的泛化性能。为了支持这些实验结果，我们还进行了理论分析，证明了 Anti-PGD 能够移动到更宽的最小值点，而 GD 和 PGD 会停滞在次优区域甚至发散。这一新颖的抗相关噪声与泛化性能的联系为训练机器学习模型提供了新的方法。

    Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations ("Anti-PGD") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.
    
[^160]: PROMPT：网络应用程序学习动态资源分配策略

    PROMPT: Learning Dynamic Resource Allocation Policies for Network Applications. (arXiv:2201.07916v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.07916](http://arxiv.org/abs/2201.07916)

    PROMPT是一个使用强化学习控制器和主动QoS预测的资源分配框架，可以实现更精确的资源优化，在处理短暂波动方面更加稳定，并且在调度新的最佳努力工作负载时具有更强的鲁棒性。

    

    越来越多的服务提供商正在探索通过将高优先级的延迟关键工作负载与最优努力工作负载进行协同调度来提高服务器利用率和降低功耗的方法。这种实践需要在工作负载之间进行严格的资源分配，以减少争用并保持服务质量（QoS）保证。

    A growing number of service providers are exploring methods to improve server utilization and reduce power consumption by co-scheduling high-priority latency-critical workloads with best-effort workloads. This practice requires strict resource allocation between workloads to reduce contention and maintain Quality-of-Service (QoS) guarantees. Prior work demonstrated promising opportunities to dynamically allocate resources based on workload demand, but may fail to meet QoS objectives in more stringent operating environments due to the presence of resource allocation cliffs, transient fluctuations in workload performance, and rapidly changing resource demand. We therefore propose PROMPT, a novel resource allocation framework using proactive QoS prediction to guide a reinforcement learning controller. PROMPT enables more precise resource optimization, more consistent handling of transient behaviors, and more robust generalization when co-scheduling new best-effort workloads not encountere
    
[^161]: 无法盗窃？尝试对抗窃听！针对图像编码器的对比窃听攻击

    Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders. (arXiv:2201.07513v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2201.07513](http://arxiv.org/abs/2201.07513)

    本文针对未受监督编码器面临的盗窃攻击漏洞，提出了基于对比学习的新型攻击方法 Cont-Steal，以更好地利用编码器的丰富特征。

    

    自我监督的表示学习技术正在快速发展，以充分利用未标记的图像。它们将图像编码为丰富的特征，这些特征对下游任务是不可知的。然而，为了实现其革命性的表示能力，需要专用的模型设计和大量的计算资源，这使图像编码器面临着潜在的模型盗窃攻击风险，这是一种廉价的方式，可以模仿经过充分训练的编码器性能而规避苛刻的要求。但是传统攻击仅针对于有标签和/或后验的受监督分类器，因此未受监督的编码器的漏洞尚未得到探索。

    Self-supervised representation learning techniques have been developing rapidly to make full use of unlabeled images. They encode images into rich features that are oblivious to downstream tasks. Behind their revolutionary representation power, the requirements for dedicated model designs and a massive amount of computation resources expose image encoders to the risks of potential model stealing attacks - a cheap way to mimic the well-trained encoder performance while circumventing the demanding requirements. Yet conventional attacks only target supervised classifiers given their predicted labels and/or posteriors, which leaves the vulnerability of unsupervised encoders unexplored.  In this paper, we first instantiate the conventional stealing attacks against encoders and demonstrate their severer vulnerability compared with downstream classifiers. To better leverage the rich representation of encoders, we further propose Cont-Steal, a contrastive-learning-based attack, and validate it
    
[^162]: FLSys：面向联邦学习移动应用的开放生态系统

    FLSys: Toward an Open Ecosystem for Federated Learning Mobile Apps. (arXiv:2111.09445v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09445](http://arxiv.org/abs/2111.09445)

    本文介绍了FLSys，一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。

    This article introduces FLSys, a mobile-cloud federated learning (FL) system that can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models.

    本文介绍了FLSys的设计、实现和评估，这是一个移动-云联邦学习（FL）系统，可以成为FL模型和应用程序开放生态系统的关键组成部分。FLSys旨在在智能手机上使用移动感测数据。它平衡了模型性能和资源消耗，容忍通信故障，并实现了可扩展性。在FLSys中，不同的DL模型和不同的FL聚合方法可以同时被不同的应用程序训练和访问。此外，FLSys提供了先进的隐私保护机制和一个通用的API，供第三方应用程序开发人员访问FL模型。FLSys采用模块化设计，实现在Android和AWS云中。我们与人类活动识别（HAR）模型共同设计了FLSys。在4个月的时间里，从100多名大学生中收集了HAR感测数据。我们实现了HAR-Wild，这是一个针对移动设备量身定制的CNN模型，具有数据增强机制以减轻p

    This article presents the design, implementation, and evaluation of FLSys, a mobile-cloud federated learning (FL) system, which can be a key component for an open ecosystem of FL models and apps. FLSys is designed to work on smart phones with mobile sensing data. It balances model performance with resource consumption, tolerates communication failures, and achieves scalability. In FLSys, different DL models with different FL aggregation methods can be trained and accessed concurrently by different apps. Furthermore, FLSys provides advanced privacy preserving mechanisms and a common API for third-party app developers to access FL models. FLSys adopts a modular design and is implemented in Android and AWS cloud. We co-designed FLSys with a human activity recognition (HAR) model. HAR sensing data was collected in the wild from 100+ college students during a 4-month period. We implemented HAR-Wild, a CNN model tailored to mobile devices, with a data augmentation mechanism to mitigate the p
    
[^163]: 分布鲁棒的多类分类及其在深度图像分类器中的应用

    Distributionally Robust Multiclass Classification and Applications in Deep Image Classifiers. (arXiv:2109.12772v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2109.12772](http://arxiv.org/abs/2109.12772)

    本研究提出了一种适用于多类逻辑回归的分布鲁棒优化方法，在深度图像分类器中得到了应用。这种方法可使图像分类器对随机和对抗攻击具有鲁棒性。在使用MNIST和CIFAR-10数据集时，相比于基准方法，通过采用新的随机训练方法，测试错误率的降低高达83.5%，损失降低高达91.3%。

    

    我们提出了一种适用于多类逻辑回归的分布鲁棒优化（DRO）方法，可以容忍数据受到离群值的干扰。该DRO框架使用具有接近Wasserstein距离意义下的经验分布的分布球的概率模糊集来定义。我们将DRO形式化简为一个正则化的学习问题，其中正则化项是系数矩阵的范数。我们为我们模型的解决方案建立了样外性能保证，为我们控制预测误差的正则化器的作用提供了见解。我们将提出的方法应用于使基于深度Vision Transformer（ViT）的图像分类器对随机和对抗攻击具有鲁棒性。具体而言，我们使用MNIST和CIFAR-10数据集，通过采用一种新颖的随机训练方法，证明了测试错误率降低了高达83.5%，损失降低了高达91.3%与基线方法相比。

    We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method.
    
[^164]: 在未知敏感属性情况下衡量公平性：一种基于量化的方法 (arXiv:2109.08549v5 [cs.CY] UPDATED)

    Measuring Fairness Under Unawareness of Sensitive Attributes: A Quantification-Based Approach. (arXiv:2109.08549v5 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2109.08549](http://arxiv.org/abs/2109.08549)

    本论文提出了一种基于量化的方法，用于在不知道模型的敏感属性的情况下，评估模型对不同群体的公平性。

    

    算法和模型越来越被用于影响人们的生活的决策中，因此影响不同人群的身份认同的敏感属性，如种族或性别等，并不会受到不公正的待遇，这个问题变得越来越重要。为了达到这个目标，对于那些开发这些模型的人来说，必须仔细评估这些模型对不同群体的影响并偏爱群体公平性。然而，收集和存储这些属性通常与数据最小化和隐私规定存在冲突。因此，即使是在开发公司内部，也很难衡量已训练模型的群体公平性。在本研究中，我们使用量化技术，解决了如何在未知敏感属性的情况下衡量群体公平性的问题。

    Algorithms and models are increasingly deployed to inform decisions about people, inevitably affecting their lives. As a consequence, those in charge of developing these models must carefully evaluate their impact on different groups of people and favour group fairness, that is, ensure that groups determined by sensitive demographic attributes, such as race or sex, are not treated unjustly. To achieve this goal, the availability (awareness) of these demographic attributes to those evaluating the impact of these models is fundamental. Unfortunately, collecting and storing these attributes is often in conflict with industry practices and legislation on data minimisation and privacy. For this reason, it can be hard to measure the group fairness of trained models, even from within the companies developing them. In this work, we tackle the problem of measuring group fairness under unawareness of sensitive attributes, by using techniques from quantification, a supervised learning task concer
    
[^165]: 矩阵计算的方差缩减及其在高斯过程中的应用

    Variance Reduction for Matrix Computations with Applications to Gaussian Processes. (arXiv:2106.14565v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2106.14565](http://arxiv.org/abs/2106.14565)

    本文提出了一种通过矩阵分解来进行矩阵计算的方差缩减方法，并展示了在某些问题上可以实现任意更好的随机性能。此外，本文提出的矩阵乘积迹的分解估计器与对半正定矩阵行列式的对数估计器均有显著的效率提高，可以在实际的贝叶斯优化问题中得到应用。

    

    随着计算速度和内存容量的不断提高，方法学上的进步也为随机模拟的性能带来了显著提高。本文聚焦于通过矩阵分解来进行矩阵计算的方差缩减。我们提供了现有方差缩减方法在估计大型矩阵元素时未能利用矩阵分解所带来的方差缩减，而如何通过计算矩阵的平方根分解，在某些情况下能够实现任意更好的随机性能。此外，我们提出了一种矩阵乘积迹的分解估计器，并在数值上证明，在某些高斯过程对数似然函数估计的问题上，该估计器的效率可以提高1000倍。此外，我们提供了一种对半正定矩阵行列式的对数估计器，其方差比文献中使用的标准估计器快速衰减。我们在实际的贝叶斯优化问题中说明了我们提出的方法的实用性。

    In addition to recent developments in computing speed and memory, methodological advances have contributed to significant gains in the performance of stochastic simulation. In this paper, we focus on variance reduction for matrix computations via matrix factorization. We provide insights into existing variance reduction methods for estimating the entries of large matrices. Popular methods do not exploit the reduction in variance that is possible when the matrix is factorized. We show how computing the square root factorization of the matrix can achieve in some important cases arbitrarily better stochastic performance. In addition, we propose a factorized estimator for the trace of a product of matrices and numerically demonstrate that the estimator can be up to 1,000 times more efficient on certain problems of estimating the log-likelihood of a Gaussian process. Additionally, we provide a new estimator of the log-determinant of a positive semi-definite matrix where the log-determinant 
    
[^166]: 场景不确定性与确定性图像分类器的惠灵顿后验

    Scene Uncertainty and the Wellington Posterior of Deterministic Image Classifiers. (arXiv:2106.13870v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.13870](http://arxiv.org/abs/2106.13870)

    本文提出了一种方法来估计确定性图像分类器在给定输入数据上结果的不确定性，定义了惠灵顿后验作为分布以表明可能由生成给定图像的相同场景生成的数据的响应。

    

    我们提出了一种方法来估计在给定输入数据上图像分类器结果的不确定性。用于图像分类的深度神经网络是从输入图像到输出类别的确定性映射。因此，它们在给定数据上的结果不涉及不确定性，因此必须在定义、测量和解释不确定性，并将“置信度”归因于结果时指定所引用的变化性。为此，我们介绍了惠灵顿后验，它是在可能由生成给定图像的相同场景生成的数据的响应中获得的结果分布。由于可以生成任何给定图像的无限多个场景，因此惠灵顿后验涉及来自除所描绘的场景之外的场景的归纳传递。我们探索了使用数据增强、丢弃、集成、单视图重建和模型线性化来计算惠灵顿后验。

    We propose a method to estimate the uncertainty of the outcome of an image classifier on a given input datum. Deep neural networks commonly used for image classification are deterministic maps from an input image to an output class. As such, their outcome on a given datum involves no uncertainty, so we must specify what variability we are referring to when defining, measuring and interpreting uncertainty, and attributing "confidence" to the outcome. To this end, we introduce the Wellington Posterior, which is the distribution of outcomes that would have been obtained in response to data that could have been generated by the same scene that produced the given image. Since there are infinitely many scenes that could have generated any given image, the Wellington Posterior involves inductive transfer from scenes other than the one portrayed. We explore the use of data augmentation, dropout, ensembling, single-view reconstruction, and model linearization to compute a Wellington Posterior. 
    
[^167]: FGLP：移动用户联邦细粒度位置预测系统

    FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users. (arXiv:2106.08946v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2106.08946](http://arxiv.org/abs/2106.08946)

    FGLP是一个联邦学习框架和预测模型组成的系统，将智能手机上收集的GPS轨迹抽象为2D空间中的相对点，合并了BiLSTM和CNN以捕获时间和空间模式，实现了8米的预测精度，且数据发送开销降低了两个数量级。

    

    智能手机上的细粒度位置预测可以用于改进应用程序/系统性能。 应用场景包括根据预测用户位置的5G网络质量自适应视频质量，以及基于预测用户位置加速内容渲染的增强现实应用程序。 这些用例要求预测误差与GPS误差相同，并且目前在位置预测方面没有任何现有工作可以实现这种精度水平。我们提出了一种基于手机上收集的GPS轨迹的移动用户的细粒度位置预测系统（FGLP）。 FGLP有两个组件：联邦学习框架和预测模型。 该框架在用户的手机上以及在协调系统中的所有用户的服务器上运行学习。 FGLP将用户位置数据表示为抽象2D空间中的相对点，这使得可以跨不同的物理空间进行学习。 该模型合并了双向长短期记忆（BiLSTM）和卷积神经网络（CNN）以捕获GPS轨迹中的时间和空间模式。 仿真结果表明，FGLP实现了8米的预测精度，这与GPS误差相当，同时将数据发送开销降低了两个数量级，相对于集中式系统。

    Fine-grained location prediction on smart phones can be used to improve app/system performance. Application scenarios include video quality adaptation as a function of the 5G network quality at predicted user locations, and augmented reality apps that speed up content rendering based on predicted user locations. Such use cases require prediction error in the same range as the GPS error, and no existing works on location prediction can achieve this level of accuracy. We present a system for fine-grained location prediction (FGLP) of mobile users, based on GPS traces collected on the phones. FGLP has two components: a federated learning framework and a prediction model. The framework runs on the phones of the users and also on a server that coordinates learning from all users in the system. FGLP represents the user location data as relative points in an abstract 2D space, which enables learning across different physical spaces. The model merges Bidirectional Long Short-Term Memory (BiLST
    
[^168]: 测量流形数据的核双样本检验

    Kernel Two-Sample Tests for Manifold Data. (arXiv:2105.03425v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2105.03425](http://arxiv.org/abs/2105.03425)

    本文研究了与最大均值差异（MMD）相关的基于核的双样本检验统计量在测量流形数据时的应用。文章展示了检验水平和功率与核带宽、样本数量和流形内在维度之间的关系，并在特定条件下建立了测试功率下界。

    

    我们在流形数据设置下研究了与最大均值差异（MMD）相关的基于核的双样本检验统计量，假设高维观测数据接近于低维流形。我们表征了测试水平和功率与核带宽、样本数量和流形的内在维度之间的关系。具体地，我们表明，当数据密度支持在一个嵌入到$m$维空间中的$d$维子流形$\mathcal{M}$上时，从服从于一对分布$p$和$q$抽取的数据进行核双样本检验，这对分布$ p $和$q$是具有H\"older阶$\beta$（最高2），样本数量$n$足够大，使得$\Delta_2\gtrsim n^{- {2\beta/(d+4\beta)}}$，其中$\Delta_2$是流形上$p$和$q$之间的平方$L^2$-差异。我们建立了一个足够大且有限$n$的测试功率下界，其中核带宽参数$\gamma$的比例尺度为$n^ {-1/(d+4\beta)}$。

    We present a study of a kernel-based two-sample test statistic related to the Maximum Mean Discrepancy (MMD) in the manifold data setting, assuming that high-dimensional observations are close to a low-dimensional manifold. We characterize the test level and power in relation to the kernel bandwidth, the number of samples, and the intrinsic dimensionality of the manifold. Specifically, we show that when data densities are supported on a $d$-dimensional sub-manifold $\mathcal{M}$ embedded in an $m$-dimensional space, the kernel two-sample test for data sampled from a pair of distributions $p$ and $q$ that are H\"older with order $\beta$ (up to 2) is powerful when the number of samples $n$ is large such that $\Delta_2 \gtrsim n^{- { 2 \beta/( d + 4 \beta ) }}$, where $\Delta_2$ is the squared $L^2$-divergence between $p$ and $q$ on manifold. We establish a lower bound on the test power for finite $n$ that is sufficiently large, where the kernel bandwidth parameter $\gamma$ scales as $n^{
    
[^169]: 基于因果关系的分类模型反事实解释方法

    Causality-based Counterfactual Explanation for Classification Models. (arXiv:2105.00703v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.00703](http://arxiv.org/abs/2105.00703)

    本论文提出了一种基于因果关系的反事实解释方法，可同时处理连续和分类变量，生成的样本具有实用性指导意义，在实验中表现出更好的性能。

    

    反事实解释是可解释机器学习的一个分支，它产生扰动样本以改变模型的原始决策。生成的样本可以作为建议，帮助最终用户实现他们所需的结果。大多数当前反事实解释方法是基于梯度的方法，只能优化连续变量的可微损失函数。据此，基于梯度的方法无法处理分类变量，因此提出了基于梯度的方法来解决这个问题。然而，这些方法存在几个主要限制：1）生成反事实时通常忽略特征之间的因果关系，可能导致对决策者的指导不切实际。2）反事实解释算法需要大量的参数调整，以确定每个损失函数的最优权重，这必须为不同的数据集和设置重复进行。本文提出了一种基于因果关系的反事实解释方法，以解决上述限制。该方法考虑特征之间的因果关系，处理连续和分类变量，无需任何用户指定的超参数。对不同数据集进行的实验结果表明，与其他最先进的方法相比，所提出的方法在模型准确性和生成的反事实样本质量方面表现出更好的性能。

    Counterfactual explanation is one branch of interpretable machine learning that produces a perturbation sample to change the model's original decision. The generated samples can act as a recommendation for end-users to achieve their desired outputs. Most of the current counterfactual explanation approaches are the gradient-based method, which can only optimize the differentiable loss functions with continuous variables. Accordingly, the gradient-free methods are proposed to handle the categorical variables, which however have several major limitations: 1) causal relationships among features are typically ignored when generating the counterfactuals, possibly resulting in impractical guidelines for decision-makers; 2) the counterfactual explanation algorithm requires a great deal of effort into parameter tuning for dertermining the optimal weight for each loss functions which must be conducted repeatedly for different datasets and settings. In this work, to address the above limitations,
    
[^170]: 一种带有负相关学习的混合集成算法进行回归分析

    A hybrid ensemble method with negative correlation learning for regression. (arXiv:2104.02317v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.02317](http://arxiv.org/abs/2104.02317)

    该论文提出了一种带有负相关学习的混合集成算法，通过自动选择和加权子模型来解决在回归任务中模型不确定性问题，并在实验中表现出较好的性能。

    

    混合集成是集成学习中的一个重要分支，在回归领域得到了迅速发展，并证实了多样性的重要性。然而，以往的集成方法主要是在子模型训练阶段考虑多样性，改善效果有限。相比之下，这项研究从异构模型池中自动选择和加权子模型，并使用内点过滤线性搜索算法解决优化问题。目标函数创新地将负相关学习作为一个惩罚项，并选择多样化子模型子集。选择每个模型类的最佳子模型来构建NCL集成，其性能优于简单平均和其他最先进的加权方法。在目标函数中加入正则化项，还可以进一步改善NCL集成的效果。

    Hybrid ensemble, an essential branch of ensembles, has flourished in the regression field, with studies confirming diversity's importance. However, previous ensembles consider diversity in the sub-model training stage, with limited improvement compared to single models. In contrast, this study automatically selects and weights sub-models from a heterogeneous model pool. It solves an optimization problem using an interior-point filtering linear-search algorithm. The objective function innovatively incorporates negative correlation learning as a penalty term, with which a diverse model subset can be selected. The best sub-models from each model class are selected to build the NCL ensemble, which performance is better than the simple average and other state-of-the-art weighting methods. It is also possible to improve the NCL ensemble with a regularization term in the objective function. In practice, it is difficult to conclude the optimal sub-model for a dataset prior due to the model unc
    
[^171]: 《更快更轻的Transformer的实用调查》的论文翻译

    A Practical Survey on Faster and Lighter Transformers. (arXiv:2103.14636v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.14636](http://arxiv.org/abs/2103.14636)

    Transformer虽然在许多序列建模任务中取得了很好的效果，但其复杂度与序列长度相关。近期，研究人员设计了类似于Longformer的解决方案来直接解决Transformer的限制，从而提高了其效率。

    

    循环神经网络是处理序列的有效模型。然而，由于它们固有的顺序性，它们无法学习长期依赖关系。作为解决方案，Vaswani等人提出了Transformer，一种仅基于注意力机制的模型，能够关联输入序列的任意两个位置，从而建模任意长的依赖关系。Transformer改善了众多序列建模任务的最新技术，但其有效性的代价是与序列长度相关的二次计算和内存复杂度，这阻碍了它的应用。幸运的是，深度学习社区一直致力于提高模型的效率，导致了一系列解决方案，如参数共享、剪枝、混合精度和知识蒸馏。最近，研究人员通过设计低复杂度的替代品，如Longformer等，直接解决了Transformer的局限性。

    Recurrent neural networks are effective models to process sequences. However, they are unable to learn long-term dependencies because of their inherent sequential nature. As a solution, Vaswani et al. introduced the Transformer, a model solely based on the attention mechanism that is able to relate any two positions of the input sequence, hence modelling arbitrary long dependencies. The Transformer has improved the state-of-the-art across numerous sequence modelling tasks. However, its effectiveness comes at the expense of a quadratic computational and memory complexity with respect to the sequence length, hindering its adoption. Fortunately, the deep learning community has always been interested in improving the models' efficiency, leading to a plethora of solutions such as parameter sharing, pruning, mixed-precision, and knowledge distillation. Recently, researchers have directly addressed the Transformer's limitation by designing lower-complexity alternatives such as the Longformer,
    
[^172]: 利用共享表示进行个性化联邦学习

    Exploiting Shared Representations for Personalized Federated Learning. (arXiv:2102.07078v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2102.07078](http://arxiv.org/abs/2102.07078)

    该论文提出了一种新的联邦学习框架和算法，用于在客户端之间共享数据表示和各自本地拟合，该方法能够线性收敛到真实值。

    

    深度神经网络已经展示出能够从图像和文本等数据中提取普适的特征表示，这对于各种学习任务都非常有用。然而，在联邦学习中尚未充分利用表示学习的成果。虽然联邦数据通常在客户端之间不是独立同分布的，但中心化深度学习的成功表明数据通常共享全局特征表示，而客户端或任务之间的统计异质性集中在标签上。基于这一直觉，我们提出了一种新的联邦学习框架和算法，用于学习跨客户端的共享数据表示和每个客户端的唯一本地拟合。我们的算法利用客户端之间的分布式计算能力，针对每个表示更新进行许多低维本地参数的本地更新。我们证明了该方法能够线性收敛到真实值。

    Deep neural networks have shown the ability to extract universal feature representations from data such as images and text that have been useful for a variety of learning tasks. However, the fruits of representation learning have yet to be fully-realized in federated settings. Although data in federated settings is often non-i.i.d. across clients, the success of centralized deep learning suggests that data often shares a global feature representation, while the statistical heterogeneity across clients or tasks is concentrated in the labels. Based on this intuition, we propose a novel federated learning framework and algorithm for learning a shared data representation across clients and unique local heads for each client. Our algorithm harnesses the distributed computational power across clients to perform many local-updates with respect to the low-dimensional local parameters for every update of the representation. We prove that this method obtains linear convergence to the ground-trut
    
[^173]: MNL上下文Bandit问题的简便在线学习算法

    A Tractable Online Learning Algorithm for the Multinomial Logit Contextual Bandit. (arXiv:2011.14033v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.14033](http://arxiv.org/abs/2011.14033)

    本文提供了一个新颖的、不需要调整指数参数的MNL-Contextual Bandit问题的简便在线学习算法。算法具有与该问题的最佳理论界限匹配的遗憾上界。

    

    本文考虑了MNL-Bandit问题的上下文变体。更具体地说，我们考虑了一个动态集合优化问题，其中决策者向消费者提供一组产品（购物清单），并在每个回合观察响应。消费者购买产品以最大化他们的效用。我们假设一组属性描述了产品，产品的平均效用与这些属性的值呈线性关系。我们使用广泛使用的Multinomial Logit（MNL）模型建模消费者选择行为，并考虑在优化销售周期$T$内累积收益的同时动态学习模型参数的决策者问题。尽管这个问题近来引起了相当大的关注，但许多现有方法通常涉及解决一个难以处理的非凸优化问题。他们的理论性能保证取决于一个可能非常大的问题相关参数。特别地，现有方法需要调整随着属性集规模指数增长的调整参数。本文提供了一种新颖的MNL-Contextual Bandit问题的简便在线学习算法，它不需要调整此类指数参数。我们展示我们的算法具有与该问题的最佳理论界限匹配的遗憾上界。我们还通过模拟和真实世界实验证明了我们算法的有效性。

    In this paper, we consider the contextual variant of the MNL-Bandit problem. More specifically, we consider a dynamic set optimization problem, where a decision-maker offers a subset (assortment) of products to a consumer and observes the response in every round. Consumers purchase products to maximize their utility. We assume that a set of attributes describe the products, and the mean utility of a product is linear in the values of these attributes. We model consumer choice behavior using the widely used Multinomial Logit (MNL) model and consider the decision maker problem of dynamically learning the model parameters while optimizing cumulative revenue over the selling horizon $T$. Though this problem has attracted considerable attention in recent times, many existing methods often involve solving an intractable non-convex optimization problem. Their theoretical performance guarantees depend on a problem-dependent parameter which could be prohibitively large. In particular, existing 
    
[^174]: DeepTopPush: 一种简单可扩展的Accuracy at the Top方法

    DeepTopPush: Simple and Scalable Method for Accuracy at the Top. (arXiv:2006.12293v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.12293](http://arxiv.org/abs/2006.12293)

    DeepTopPush是一种用于解决Accuracy at the Top问题的简单而可扩展的方法，能有效地选择少量重要的样本，并在不同领域取得了优异的性能表现

    

    Accuracy at the top是一类特殊的二分类问题，其性能仅在少数相关（顶部）样本上评估。应用包括信息检索系统或需要手动（昂贵）后处理的工艺。这导致最小化超过阈值的无关样本数量。我们考虑以任意（深度）网络的形式构建分类器，并提出了一种新的DeepTopPush方法来最小化顶部的损失函数。由于阈值取决于所有样本，因此问题是不可分解的。我们修改了随机梯度下降以处理非可分解性，并提出了一种从当前迷你批次值和一个延迟值估计阈值的方法。我们展示了DeepTopPush在视觉识别数据集和两个真实应用中的优异性能。第一个应用程序选择少量分子进行进一步的药物测试。第二个应用程序使用了

    Accuracy at the top is a special class of binary classification problems where the performance is evaluated only on a small number of relevant (top) samples. Applications include information retrieval systems or processes with manual (expensive) postprocessing. This leads to minimizing the number of irrelevant samples above a threshold. We consider classifiers in the form of an arbitrary (deep) network and propose a new method DeepTopPush for minimizing the loss function at the top. Since the threshold depends on all samples, the problem is non-decomposable. We modify the stochastic gradient descent to handle the non-decomposability in an end-to-end training manner and propose a way to estimate the threshold only from values on the current minibatch and one delayed value. We demonstrate the excellent performance of DeepTopPush on visual recognition datasets and two real-world applications. The first one selects a small number of molecules for further drug testing. The second one uses r
    
[^175]: 利用网络特性检测错误输入

    Utilizing Network Properties to Detect Erroneous Inputs. (arXiv:2002.12520v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2002.12520](http://arxiv.org/abs/2002.12520)

    本研究利用预训练神经网络的特征向量，训练线性SVM分类器，通过检测隐藏特征向量和softmax特征向量的线性可分性，来识别四种类型的错误数据，包括对抗攻击、损坏的、超出分布范围和误分类的示例。

    

    神经网络容易受到各种错误输入的影响，包括对抗性、损坏的、超出分布范围的和误分类的示例。本研究利用预训练神经网络的隐藏特征向量和softmax特征向量，训练一个线性SVM分类器来检测这四种类型的错误数据。结果表明，这些错误数据通常表现出与正确示例的线性可分激活属性，使我们能够拒绝坏的输入而无需额外的训练或开销。我们在各种数据集、领域、预训练模型和对抗攻击上实验证实了我们的发现。

    Neural networks are vulnerable to a wide range of erroneous inputs such as adversarial, corrupted, out-of-distribution, and misclassified examples. In this work, we train a linear SVM classifier to detect these four types of erroneous data using hidden and softmax feature vectors of pre-trained neural networks. Our results indicate that these faulty data types generally exhibit linearly separable activation properties from correct examples, giving us the ability to reject bad inputs with no extra training or overhead. We experimentally validate our findings across a diverse range of datasets, domains, pre-trained models, and adversarial attacks.
    

