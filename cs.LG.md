# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Dynamical Model of Neural Scaling Laws](https://rss.arxiv.org/abs/2402.01092) | 这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。 |
| [^2] | [Incremental Learning with Concept Drift Detection and Prototype-based Embeddings for Graph Stream Classification](https://arxiv.org/abs/2404.02572) | 这项工作提出了一种新颖的图流分类方法，通过增量学习实现持续模型适应，选择每个类别的代表性图，并创建图嵌入，以解决图流分类中的概念漂移问题。 |
| [^3] | [Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing](https://arxiv.org/abs/2404.00589) | 介绍了一种利用大型语言模型处理图数据中不确定性的方法，通过不确定性感知模块增强，提供置信度评分，实验结果表明该方法在知识图完成和图分类任务上超越了最先进算法。 |
| [^4] | [Transfer Learning with Reconstruction Loss](https://arxiv.org/abs/2404.00505) | 本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。 |
| [^5] | [Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems](https://arxiv.org/abs/2403.18998) | 提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。 |
| [^6] | [On the Fragility of Active Learners](https://arxiv.org/abs/2403.15744) | 本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。 |
| [^7] | [Leap: molecular synthesisability scoring with intermediates](https://arxiv.org/abs/2403.13005) | Leap是一个使用GPT-2模型训练的方法，根据预测的合成路线深度，动态地包含了关键中间体的可用性信息，在合成可达性评分上表现优异。 |
| [^8] | [Impacts of Color and Texture Distortions on Earth Observation Data in Deep Learning](https://arxiv.org/abs/2403.04385) | 本研究系统地研究了深度学习模型对地球观测数据中颜色和纹理失真的敏感性，发现模型对纹理失真比颜色失真更敏感 |
| [^9] | [Provably Robust DPO: Aligning Language Models with Noisy Feedback](https://arxiv.org/abs/2403.00409) | 通过引入面向随机偏好翻转的策略优化通用框架，本研究旨在理解存在嘈杂反馈时的DPO算法，从而解决语言模型对齐人类兴趣中的挑战。 |
| [^10] | [Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization](https://arxiv.org/abs/2402.16891) | 本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。 |
| [^11] | [Cut Facets and Cube Facets of Lifted Multicut Polytopes](https://arxiv.org/abs/2402.16814) | 本文回答了提升多段切割多面体的哪些下界立方不等式和哪些切割不等式定义面的基本问题，以及判定切割不等式定义性的NP难性。 |
| [^12] | [UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation](https://arxiv.org/abs/2402.12730) | 使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。 |
| [^13] | [Explaining the Machine Learning Solution of the Ising Model](https://arxiv.org/abs/2402.11701) | 展示了如何通过神经网络和模型哈密顿量的对称性，解释铁磁伊辛模型的机器学习解决方案策略。 |
| [^14] | [A Change Detection Reality Check](https://arxiv.org/abs/2402.06994) | 该论文通过实验证明，一个简单的U-Net分割基线仍然是进行变化检测任务的顶尖表现者。 |
| [^15] | [Increasing Trust in Language Models through the Reuse of Verified Circuits](https://arxiv.org/abs/2402.02619) | 本文介绍了一种通过重复使用经过验证的电路来增加语言模型的可信度的方法。研究者通过构建数学和逻辑规范的框架，并对一个n位整数加法模型进行完全验证。他们插入训练好的加法模型到一个未经训练的模型中，通过训练组合模型执行加法和减法。他们发现加法电路在这两个任务中得到了广泛的重复使用，从而简化了减法模型的验证。 |
| [^16] | [Unraveling the Impact of Initial Choices and In-Loop Interventions on Learning Dynamics in Autonomous Scanning Probe Microscopy](https://arxiv.org/abs/2402.00071) | 本文研究了自主扫描探针显微术中初始选择和循环干预对学习动力学的影响，并探讨了“种子效应”和种子点干预的概念，对深度内核学习的有效性进行了实证分析。 |
| [^17] | [Systematically Assessing the Security Risks of AI/ML-enabled Connected Healthcare Systems](https://arxiv.org/abs/2401.17136) | 研究评估了将机器学习应用于医疗系统的安全风险，特别是连接外围设备的连接系统。作者通过案例研究展示了通过利用蓝牙通信渠道漏洞对机器学习血糖监测系统进行攻击的可能性，并指出当前的风险评估技术不足以应对这些新的风险。 |
| [^18] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^19] | [Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced Local Value Functions](https://arxiv.org/abs/2202.13046) | 通过利用图结构，本文提出了一种通用计算高效的分布式框架，基于局部值函数的分布式RL方法在协作多智能体强化学习中取得了显著的样本复杂性降低。 |
| [^20] | [ProbMCL: Simple Probabilistic Contrastive Learning for Multi-label Visual Classification.](http://arxiv.org/abs/2401.01448) | ProbMCL是一个简单而有效的概率对比学习框架，用于解决多标签图像分类任务中的挑战。该方法通过采用监督对比学习和混合密度网络，在捕捉标签之间的依赖关系的同时，降低了复杂模块的计算需求和可解释性的不足。 |
| [^21] | [Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning.](http://arxiv.org/abs/2311.09852) | 这项研究介绍了一种将短期计划生成和选择与分布式优化以及深度强化学习相结合的渐进方法，用于无人机的协调和规划。实验结果表明，与最先进的方法相比，该方法在动态环境中具有出色的性能。 |
| [^22] | [ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital Biomarkers of Alzheimer's Disease.](http://arxiv.org/abs/2310.15301) | ADMarker是一个多模式联邦学习系统，用于在自然生活环境中监测阿尔茨海默病的数字生物标志物。它具有新颖的联邦学习架构，能够准确检测出数字生物标志物，并在临床试验中展示出高准确率和早期AD识别能力。 |
| [^23] | [Be Bayesian by Attachments to Catch More Uncertainty.](http://arxiv.org/abs/2310.13027) | 本文提出了一种附加结构贝叶斯神经网络(ABNN)，通过在主干网络中整合足够分布外数据的不确定性，来提高神经网络对不确定性的捕捉能力。 |
| [^24] | [Neural Likelihood Approximation for Integer Valued Time Series Data.](http://arxiv.org/abs/2310.12544) | 本文构建了整数值时间序列数据的神经似然近似方法，使用因果卷积并行评估整个时间序列的似然，实现了对生态学和流行病学模型进行准确推断并显著加快计算速度。 |
| [^25] | [On the Over-Memorization During Natural, Robust and Catastrophic Overfitting.](http://arxiv.org/abs/2310.08847) | 本论文研究了深度神经网络中的过度记忆问题，发现其会损害泛化能力，并提出了方法综合性地减轻不同类型的过拟合。 |
| [^26] | [The Expresssive Power of Transformers with Chain of Thought.](http://arxiv.org/abs/2310.07923) | 本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。 |
| [^27] | [Self-Supervised Dataset Distillation for Transfer Learning.](http://arxiv.org/abs/2310.06511) | 本文提出了一种自监督数据集蒸馏方法，用于将无标签数据集转化为小型合成样本，以支持高效的自监督学习。通过最小化模型对合成样本的表示和可学习目标特征表示之间的均方误差，解决了合成样本梯度偏差的问题。 |
| [^28] | [Generalization in diffusion models arises from geometry-adaptive harmonic representation.](http://arxiv.org/abs/2310.02557) | 通过分析基于分数的反向扩散算法生成的高质量样本的研究结果，我们发现尽管存在维度灾难，但为了降噪而训练的深度神经网络可以学习到高维密度。此外，我们展示了在训练集的非重叠子集上训练的网络可以学习到相同的密度，从而证明了DNN架构和训练算法中的归纳偏差与数据分布的一致性。 |
| [^29] | [Viewing the process of generating counterfactuals as a source of knowledge -- Application to the Naive Bayes classifier.](http://arxiv.org/abs/2309.04284) | 将生成对立假设的过程视为知识来源，并应用于朴素贝叶斯分类器，展示其有趣属性。 |
| [^30] | [On the Minimax Regret in Online Ranking with Top-k Feedback.](http://arxiv.org/abs/2309.02425) | 本文研究了在线排名中的最小极大后悔问题与Top-k反馈，并通过提供一个全面的极大后悔率刻画，解决了Chaudhuri和Tewari [2017]所提出的问题。 |
| [^31] | [Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes.](http://arxiv.org/abs/2308.14142) | 本论文提出了一种综合变分傅里叶特征的方法，可以对广泛的平稳协方差函数进行快速空间建模，相比其他方法具有更高的性能和加速效果。 |
| [^32] | [Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge.](http://arxiv.org/abs/2308.10918) | 本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。 |
| [^33] | [Contrastive Graph Pooling for Explainable Classification of Brain Networks.](http://arxiv.org/abs/2307.11133) | 本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。 |
| [^34] | [Properties of Discrete Sliced Wasserstein Losses.](http://arxiv.org/abs/2307.10352) | 本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。 |
| [^35] | [Kernel-Based Testing for Single-Cell Differential Analysis.](http://arxiv.org/abs/2307.08509) | 本论文提出了一种基于核方法的单细胞差异分析测试框架，可以非线性比较复杂的细胞间分子特征分布。通过利用核嵌入的变异性，我们的方法能够揭示细胞群体中隐蔽的异质性。我们展示了核测试如何克服单细胞差异分析方法的局限性，并应用于研究分化逆转的过程。 |
| [^36] | [Reinforcement Learning with Non-Cumulative Objective.](http://arxiv.org/abs/2307.04957) | 本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。 |
| [^37] | [CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution.](http://arxiv.org/abs/2307.03798) | 本文展示了对比式语言-图像预训练（CLIP）模型的脆弱性，通过挖掘生成模型的潜在空间可以找到欺骗主图像，这些图像在许多不同的提示下能欺骗CLIP模型，而对人类来说是无法认出的。欺骗主图像在少量图像标题上的训练上可能适用于更多数量的语义相关的标题。两种可能的缓解策略被评估，并发现脆弱性与对比式预训练中的模态差距密切相关。 |
| [^38] | [The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model.](http://arxiv.org/abs/2305.16589) | 本文研究了强化学习中的模型鲁棒性以缩小模拟与真实差距，提出了一个名为“分布鲁棒值迭代”的基于模型的方法，可以优化最坏情况下的表现。 |
| [^39] | [Topological Interpretability for Deep-Learning.](http://arxiv.org/abs/2305.08642) | 本文提出了一种在临床和非临床文本上训练的深度学习分类模型中使用拓扑和几何数据分析技术推断主要特征的方法。 |
| [^40] | [Calibration-Aware Bayesian Learning.](http://arxiv.org/abs/2305.07504) | 本文提出了一个综合框架，称为校准感知的贝叶斯神经网络 (CAB)，用于共同解决深度神经网络中的校准和贝叶斯学习，通过在训练过程中正则化模型的后验预测分布来提高模型的校准性。 |
| [^41] | [Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards.](http://arxiv.org/abs/2304.14989) | 本文提出了Kullback-Leibler Maillard Sampling (KL-MS)算法，能够在有界奖励的多臂赌博机中实现KL空间的扩展，具有较好的渐近性能。 |
| [^42] | [Fast Convergence Federated Learning with Aggregated Gradients.](http://arxiv.org/abs/2303.15799) | 该论文提出了一种带有聚合梯度的快速收敛联邦学习方法，通过引入均值场方法来完成参数和梯度的聚合步骤，该方法在收敛速度和通信成本方面优于传统方法。 |
| [^43] | [Adaptive Federated Learning via New Entropy Approach.](http://arxiv.org/abs/2303.14966) | 本文提出了一种新的自适应学习率方案，基于熵理论缓解异构客户端之间的偏差，实现全局模型的快速收敛。 |
| [^44] | [Efficient Graph Laplacian Estimation by Proximal Newton.](http://arxiv.org/abs/2302.06434) | 本文提出了一种基于Proximal Newton算法的高效图拉普拉斯估计方法，通过引入非凸minimax concave penalty，并利用二阶优化方法和几个算法技巧，实现了准确且高效的求解器。 |
| [^45] | [A Vision-free Baseline for Multimodal Grammar Induction.](http://arxiv.org/abs/2212.10564) | 本论文研究了在多模式设置下，只使用文本进行训练的大型语言模型（LLMs）是否能够提供强大的辅助来进行语法归纳。结果显示，基于LLM的纯文本方法在多种多模式数据集上优于先前的方法，并且在性能、参数数量和训练速度方面取得了最先进的结果。 |
| [^46] | [Rotation-equivariant Graph Neural Networks for Learning Glassy Liquids Representations.](http://arxiv.org/abs/2211.03226) | 本文提出了一种旋转等变图神经网络（GNN），通过约束保持旋转平移等变性的方式，学习玻璃液体静态结构的稳健表示。这种约束显著提高了预测能力和泛化能力，同时减少了参数数量，并且提高了解释性。通过迁移学习实验证明了网络的有效性。 |
| [^47] | [Efficient Representation of Natural Image Patches.](http://arxiv.org/abs/2210.13004) | 通过抽象模型，研究人员展示了如何通过非线性种群码实现自然图像块的高效表示，以实现早期视觉系统的信息传输和传感器概率分布建模的目标。 |

# 详细

[^1]: 神经缩放定律的动力学模型

    A Dynamical Model of Neural Scaling Laws

    [https://rss.arxiv.org/abs/2402.01092](https://rss.arxiv.org/abs/2402.01092)

    这篇论文提出了一个动力学模型来解释神经缩放定律。通过分析梯度下降训练的随机特征模型，研究发现训练时间和模型大小的缩放具有不同的幂律指数，而计算最优缩放规则要求增加训练步数快于增加模型参数，与实证观察相一致。

    

    在各种任务中，神经网络的性能随着训练时间、数据集大小和模型大小的增加而预测性地提高，跨多个数量级。这种现象被称为神经缩放定律。最重要的是计算最优缩放定律，它报告了在选择最佳模型大小时性能与计算数量的关系。我们分析了一个通过梯度下降进行训练和泛化的随机特征模型作为网络训练和泛化的可解模型。这个模型复现了关于神经缩放定律的许多观察结果。首先，我们的模型对于为什么训练时间和模型大小的缩放具有不同的幂律指数提出了一个预测。因此，理论预测了一种不对称的计算最优缩放规则，其中训练步数的增加速度快于模型参数的增加速度，与最近的实证观察一致。其次，观察到在训练的早期，网络会收敛到无限宽度情况下的结果。

    On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
    
[^2]: 具有概念漂移检测和基于原型的嵌入的图流分类的增量学习

    Incremental Learning with Concept Drift Detection and Prototype-based Embeddings for Graph Stream Classification

    [https://arxiv.org/abs/2404.02572](https://arxiv.org/abs/2404.02572)

    这项工作提出了一种新颖的图流分类方法，通过增量学习实现持续模型适应，选择每个类别的代表性图，并创建图嵌入，以解决图流分类中的概念漂移问题。

    

    数据流挖掘旨在从不断变化的数据流中提取有意义的知识，解决非静态环境带来的挑战，特别是指随时间改变的基础数据分布的概念漂移。图结构提供了一个强大的建模工具，用于表示复杂系统，比如关键基础设施系统和社交网络。从图流中学习变得必不可少，以了解图结构的动态并促进明智决策。本工作介绍了一种新颖的用于图流分类的方法，在数据生成过程产生随时间变化的节点和边的图的一般设置下运行。该方法使用增量学习进行持续模型适应，为每个类别选择代表性图（原型）并创建图嵌入。此外，它还包含基于损失的概念

    arXiv:2404.02572v1 Announce Type: new  Abstract: Data stream mining aims at extracting meaningful knowledge from continually evolving data streams, addressing the challenges posed by nonstationary environments, particularly, concept drift which refers to a change in the underlying data distribution over time. Graph structures offer a powerful modelling tool to represent complex systems, such as, critical infrastructure systems and social networks. Learning from graph streams becomes a necessity to understand the dynamics of graph structures and to facilitate informed decision-making. This work introduces a novel method for graph stream classification which operates under the general setting where a data generating process produces graphs with varying nodes and edges over time. The method uses incremental learning for continual model adaptation, selecting representative graphs (prototypes) for each class, and creating graph embeddings. Additionally, it incorporates a loss-based concept 
    
[^3]: 利用大型语言模型处理图数据中的不确定性

    Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing

    [https://arxiv.org/abs/2404.00589](https://arxiv.org/abs/2404.00589)

    介绍了一种利用大型语言模型处理图数据中不确定性的方法，通过不确定性感知模块增强，提供置信度评分，实验结果表明该方法在知识图完成和图分类任务上超越了最先进算法。

    

    处理图数据是一项非常困难的任务。传统技术，例如基于几何和矩阵分解的技术，依赖于对数据关系的假设，在处理大型和复杂的图数据时变得不足够。另一方面，深度学习方法展示了处理大型图数据的良好结果，但它们通常无法提供可解释的解释。为了使图处理具有高准确性和可解释性，我们引入了一种新颖的方法，利用了增强不确定性感知模块的大型语言模型(LLM)的力量，以提供生成答案的置信度分数。我们在两个图处理任务上对我们的方法进行了实验：少样本知识图完成和图分类。我们的结果表明，通过参数高效微调，LLM在各个方面超越了最先进的算法

    arXiv:2404.00589v1 Announce Type: cross  Abstract: Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across
    
[^4]: 具有重建损失的迁移学习

    Transfer Learning with Reconstruction Loss

    [https://arxiv.org/abs/2404.00505](https://arxiv.org/abs/2404.00505)

    本文通过引入额外的重建阶段和重建损失，提出了一种具有共享模型参数和特征表示的模型训练方法，建立了共同信息的概念，用于解决相关任务。

    

    在大多数利用神经网络进行数学优化的应用中，通常为每个特定优化目标训练一个专用模型。然而，在许多场景中，同一组问题输入上经常需要优化几个不同但相关的目标或任务。与为每个问题单独训练不同的神经网络相比，更有效的方法是利用这些目标之间的相关性，使用共享模型参数和特征表示训练多个神经网络模型。为实现这一目标，本文首先建立了共同信息的概念：解决相关任务所需的共享知识，然后提出了一种新颖的模型训练方法，通过在模型中添加一个额外的重建阶段以及相关的新重建损失。该损失用于从选择的隐藏状态开始重新构建共同信息。

    arXiv:2404.00505v1 Announce Type: cross  Abstract: In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidde
    
[^5]: 微服务系统的少样本跨系统异常跟踪分类

    Few-Shot Cross-System Anomaly Trace Classification for Microservice-based systems

    [https://arxiv.org/abs/2403.18998](https://arxiv.org/abs/2403.18998)

    提出了针对微服务系统的少样本异常跟踪分类的新框架，利用多头注意力自编码器构建系统特定的跟踪表示，并应用基于Transformer编码器的模型无关元学习进行高效分类。

    

    微服务系统（MSS）由于其复杂和动态的特性可能在各种故障类别中出现故障。为了有效处理故障，AIOps工具利用基于跟踪的异常检测和根本原因分析。本文提出了一个新颖的框架，用于微服务系统的少样本异常跟踪分类。我们的框架包括两个主要组成部分：（1）多头注意力自编码器用于构建系统特定的跟踪表示，从而实现（2）基于Transformer编码器的模型无关元学习，以进行有效和高效的少样本异常跟踪分类。该框架在两个代表性的MSS，Trainticket和OnlineBoutique上进行了评估，使用开放数据集。结果表明，我们的框架能够调整学到的知识，以对新的、未见的新颖故障类别的异常跟踪进行分类，无论是在最初训练的同一系统内，还是在其他系统中。

    arXiv:2403.18998v1 Announce Type: cross  Abstract: Microservice-based systems (MSS) may experience failures in various fault categories due to their complex and dynamic nature. To effectively handle failures, AIOps tools utilize trace-based anomaly detection and root cause analysis. In this paper, we propose a novel framework for few-shot abnormal trace classification for MSS. Our framework comprises two main components: (1) Multi-Head Attention Autoencoder for constructing system-specific trace representations, which enables (2) Transformer Encoder-based Model-Agnostic Meta-Learning to perform effective and efficient few-shot learning for abnormal trace classification. The proposed framework is evaluated on two representative MSS, Trainticket and OnlineBoutique, with open datasets. The results show that our framework can adapt the learned knowledge to classify new, unseen abnormal traces of novel fault categories both within the same system it was initially trained on and even in the 
    
[^6]: 论主动学习者的脆弱性

    On the Fragility of Active Learners

    [https://arxiv.org/abs/2403.15744](https://arxiv.org/abs/2403.15744)

    本研究发现主动学习技术只在特定情境下有效，对文本分类从业者的建议是选择适当的文本表示和分类器同样重要。

    

    主动学习（AL）技术旨在通过迭代选择最有可能提高预测准确性的实例，最大程度地利用标注预算。然而，与随机抽样相比，在不同设置下（例如不同数据集，分类器），它们的益处并不一致。在这项实证研究中，我们研究了不同因素的组合如何可能掩盖主动学习技术的任何收益。专注于文本分类，我们在大约1000个实验中严格评估了进行分类，我们在大约1000个实验中严格评估了AL技术，这些实验在数据集、批大小、文本表示和分类器方面变化。我们表明，AL只在一组有限的情境中有效。我们还解决了使用与现实世界期望更好对齐的度量的问题。这项研究的影响在于对从业者的洞察：(a) 文本表示和分类器的选择与AL技术的选择一样重要，(b) 选择的

    arXiv:2403.15744v1 Announce Type: cross  Abstract: Active learning (AL) techniques aim to maximally utilize a labeling budget by iteratively selecting instances that are most likely to improve prediction accuracy. However, their benefit compared to random sampling has not been consistent across various setups, e.g., different datasets, classifiers. In this empirical study, we examine how a combination of different factors might obscure any gains from an AL technique.   Focusing on text classification, we rigorously evaluate AL techniques over around 1000 experiments that vary wrt the dataset, batch size, text representation and the classifier. We show that AL is only effective in a narrow set of circumstances. We also address the problem of using metrics that are better aligned with real world expectations.   The impact of this study is in its insights for a practitioner: (a) the choice of text representation and classifier is as important as that of an AL technique, (b) choice of the 
    
[^7]: Leap: 中间体的分子合成评分

    Leap: molecular synthesisability scoring with intermediates

    [https://arxiv.org/abs/2403.13005](https://arxiv.org/abs/2403.13005)

    Leap是一个使用GPT-2模型训练的方法，根据预测的合成路线深度，动态地包含了关键中间体的可用性信息，在合成可达性评分上表现优异。

    

    评估分子是否可以合成是药物发现中的首要任务。它使计算化学家能够过滤可行化合物或偏向分子生成模型。合成性的概念是动态的，因为它会随着关键化合物的可用性而演变。药物发现中的一种常见方法涉及探索可合成中间体周围的化学空间。这一策略改善了由于关键中间体的可用性而导致的衍生分子的合成能力。现有的合成可达性评分方法，如SAScore、SCScore和RAScore，无法动态地根据中间体进行条件评分。我们的方法Leap是一个在预测的合成路线深度（或最长线性路径）上训练的GPT-2模型，允许在推断时包含关键中间体的可用性信息。我们展示了Leap在AUC sc上至少比所有其他评分方法高出5%。

    arXiv:2403.13005v1 Announce Type: cross  Abstract: Assessing whether a molecule can be synthesised is a primary task in drug discovery. It enables computational chemists to filter for viable compounds or bias molecular generative models. The notion of synthesisability is dynamic as it evolves depending on the availability of key compounds. A common approach in drug discovery involves exploring the chemical space surrounding synthetically-accessible intermediates. This strategy improves the synthesisability of the derived molecules due to the availability of key intermediates. Existing synthesisability scoring methods such as SAScore, SCScore and RAScore, cannot condition on intermediates dynamically. Our approach, Leap, is a GPT-2 model trained on the depth, or longest linear path, of predicted synthesis routes that allows information on the availability of key intermediates to be included at inference time. We show that Leap surpasses all other scoring methods by at least 5% on AUC sc
    
[^8]: 深度学习中颜色和纹理失真对地球观测数据的影响

    Impacts of Color and Texture Distortions on Earth Observation Data in Deep Learning

    [https://arxiv.org/abs/2403.04385](https://arxiv.org/abs/2403.04385)

    本研究系统地研究了深度学习模型对地球观测数据中颜色和纹理失真的敏感性，发现模型对纹理失真比颜色失真更敏感

    

    地物覆盖分类和变化检测是遥感和地球观测（EO）的两个重要应用领域，在深度学习的进展中得到了极大的益处。卷积和基于Transformer的U-net模型是这些任务的最先进架构，它们的性能得到了大规模标注EO数据集的增加的提升。然而，对输入EO数据的不同视觉特征对模型预测的影响尚不明确。在这项工作中，我们系统地研究了在推断期间对输入EO数据进行几种基于颜色和纹理的失真时模型的敏感性，考虑到这些模型是在没有这种失真的情况下进行训练的。我们对多个最先进的地物覆盖分类网络进行实验，结果表明它们通常对纹理失真比颜色失真更为敏感。

    arXiv:2403.04385v1 Announce Type: cross  Abstract: Land cover classification and change detection are two important applications of remote sensing and Earth observation (EO) that have benefited greatly from the advances of deep learning. Convolutional and transformer-based U-net models are the state-of-the-art architectures for these tasks, and their performances have been boosted by an increased availability of large-scale annotated EO datasets. However, the influence of different visual characteristics of the input EO data on a model's predictions is not well understood. In this work we systematically examine model sensitivities with respect to several color- and texture-based distortions on the input EO data during inference, given models that have been trained without such distortions. We conduct experiments with multiple state-of-the-art segmentation networks for land cover classification and show that they are in general more sensitive to texture than to color distortions. Beyond
    
[^9]: 可证明鲁棒的DPO: 用有噪反馈对齐语言模型

    Provably Robust DPO: Aligning Language Models with Noisy Feedback

    [https://arxiv.org/abs/2403.00409](https://arxiv.org/abs/2403.00409)

    通过引入面向随机偏好翻转的策略优化通用框架，本研究旨在理解存在嘈杂反馈时的DPO算法，从而解决语言模型对齐人类兴趣中的挑战。

    

    最近，从基于喜好反馈学习作为一种与人类兴趣对齐的有前景方法已经引起了广泛关注。虽然这些对齐的生成模型在各种任务中展示出令人印象深刻的能力，但它们对高质量人类喜好数据的依赖在实际应用中构成了瓶颈。具体来说，数据集中有噪（不正确和模糊）的偏好对可能会限制语言模型准确捕捉人类意图。虽然从业者最近提出了启发式方法来减轻噪声偏好的影响，但对它们的工作完整理论理解仍然难以捉摸。在这项工作中，我们旨在通过引入一个面向在随机偏好翻转存在的策略优化的通用框架来弥合这一差距。我们特别关注直接偏好优化（DPO）算法，因为它假设偏好遵循 Bradley-Te

    arXiv:2403.00409v1 Announce Type: cross  Abstract: Learning from preference-based feedback has recently gained traction as a promising approach to align language models with human interests. While these aligned generative models have demonstrated impressive capabilities across various tasks, their dependence on high-quality human preference data poses a bottleneck in practical applications. Specifically, noisy (incorrect and ambiguous) preference pairs in the dataset might restrict the language models from capturing human intent accurately. While practitioners have recently proposed heuristics to mitigate the effect of noisy preferences, a complete theoretical understanding of their workings remain elusive.   In this work, we aim to bridge this gap by by introducing a general framework for policy optimization in the presence of random preference flips. We focus on the direct preference optimization (DPO) algorithm in particular since it assumes that preferences adhere to the Bradley-Te
    
[^10]: 多任务学习用于具有跨问题零样本泛化的路径问题

    Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization

    [https://arxiv.org/abs/2402.16891](https://arxiv.org/abs/2402.16891)

    本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。

    

    车辆路径问题（VRPs）在许多实际应用中都能找到，已经成为几十年的重要研究课题。最近，利用基于学习的模型来解决VRPs的神经组合优化（NCO）方法引起了相当大的关注。然而，当前的NCO方法通常需要为每个路径问题构建一个模型，这显著阻碍了它们在具有不同属性的真实工业问题中的实际应用。在这项工作中，我们首次尝试解决跨问题泛化的关键挑战。具体而言，我们将VRPs定义为一组共享的基础属性的不同组合，并通过属性组合同时通过单一模型解决它们。通过这种方式，我们提出的模型能够成功解决具有未见属性组合的VRPs，实现零样本泛化。

    arXiv:2402.16891v1 Announce Type: cross  Abstract: Vehicle routing problems (VRPs), which can be found in numerous real-world applications, have been an important research topic for several decades. Recently, the neural combinatorial optimization (NCO) approach that leverages a learning-based model to solve VRPs without manual algorithm design has gained substantial attention. However, current NCO methods typically require building one model for each routing problem, which significantly hinders their practical application for real-world industry problems with diverse attributes. In this work, we make the first attempt to tackle the crucial challenge of cross-problem generalization. In particular, we formulate VRPs as different combinations of a set of shared underlying attributes and solve them simultaneously via a single model through attribute composition. In this way, our proposed model can successfully solve VRPs with unseen attribute combinations in a zero-shot generalization mann
    
[^11]: 切割面和立方面的提升多段切割多面体

    Cut Facets and Cube Facets of Lifted Multicut Polytopes

    [https://arxiv.org/abs/2402.16814](https://arxiv.org/abs/2402.16814)

    本文回答了提升多段切割多面体的哪些下界立方不等式和哪些切割不等式定义面的基本问题，以及判定切割不等式定义性的NP难性。

    

    提升多段切割问题在计算机视觉领域有着多样的应用。基于线性规划的精确算法需要对提升多段切割多面体有所了解。尽管最近取得了一些进展，但关于这些多面体的两个基本问题一直未能解决：哪些下界立方不等式定义了面，哪些切割不等式定义了面？在本文中，我们通过建立必要、充分且高效可判定的条件来回答第一个问题。至于第二个问题，我们表明判断切割不等式的面定义性是NP难的。这完成了对提升多段切割多面体的规范面的分析。

    arXiv:2402.16814v2 Announce Type: replace-cross  Abstract: The lifted multicut problem has diverse applications in the field of computer vision. Exact algorithms based on linear programming require an understanding of lifted multicut polytopes. Despite recent progress, two fundamental questions about these polytopes have remained open: Which lower cube inequalities define facets, and which cut inequalities define facets? In this article, we answer the first question by establishing conditions that are necessary, sufficient and efficiently decidable. Toward the second question, we show that deciding facet-definingness of cut inequalities is NP-hard. This completes the analysis of canonical facets of lifted multicut polytopes.
    
[^12]: UMBCLU在SemEval-2024任务1A和1C中的表现：带有和不带有机器翻译的语义文本相关性

    UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with and without machine translation

    [https://arxiv.org/abs/2402.12730](https://arxiv.org/abs/2402.12730)

    使用机器翻译和大型语言模型，本文开发了用于非洲和亚洲语言语义文本相关性任务的两种模型，取得了比部分官方基准更好的效果。

    

    这篇论文描述了我们为SemEval-2024任务1开发的系统，“非洲和亚洲语言的语义文本相关性”。 该任务的目标是构建一个能够识别目标语言中属于非洲和亚洲语言集合的两个句子之间的语义文本相关性（STR）的模型。 我们参与了子任务A和C，并探索了利用大型语言模型（LLMs）进行监督和跨语言训练。 预训练的大型语言模型已被广泛用于机器翻译和语义相似性。 使用机器翻译和句子嵌入LLMs的组合，我们为子任务A开发了一个统一的STR模型，TranSem，并对STR数据上的T5系列模型进行了微调，用于子任务C的FineSem。 我们在子任务A中7种语言的模型结果比3种语言的官方基准更好，而与其他4种语言的基准相当。

    arXiv:2402.12730v1 Announce Type: cross  Abstract: This paper describes the system we developed for SemEval-2024 Task 1, "Semantic Textual Relatedness for African and Asian Languages." The aim of the task is to build a model that can identify semantic textual relatedness (STR) between two sentences of a target language belonging to a collection of African and Asian languages. We participated in Subtasks A and C and explored supervised and cross-lingual training leveraging large language models (LLMs). Pre-trained large language models have been extensively used for machine translation and semantic similarity. Using a combination of machine translation and sentence embedding LLMs, we developed a unified STR model, TranSem, for subtask A and fine-tuned the T5 family of models on the STR data, FineSem, for use in subtask C. Our model results for 7 languages in subtask A were better than the official baseline for 3 languages and on par with the baseline for the remaining 4 languages. Our m
    
[^13]: 解释伊辛模型的机器学习解决方案

    Explaining the Machine Learning Solution of the Ising Model

    [https://arxiv.org/abs/2402.11701](https://arxiv.org/abs/2402.11701)

    展示了如何通过神经网络和模型哈密顿量的对称性，解释铁磁伊辛模型的机器学习解决方案策略。

    

    尽管机器学习（ML）技术在解决涉及大维数据的问题中非常强大，但解释从拟合参数得出的结果仍然是一项至关重要且具有挑战性的任务，特别是在物理应用中。本文展示了如何实现对铁磁伊辛模型的解释，这是近年来许多机器学习研究的重点对象。通过使用一个没有任何隐藏层的神经网络（NN）以及哈密顿量的对称性来找到模型连续相变的临界温度，找到了一种解释其策略的方法。这使得在对称性未知时可以预测解决问题所需的NN的最小扩展，这也是可以解释的。

    arXiv:2402.11701v1 Announce Type: cross  Abstract: As powerful as machine learning (ML) techniques are in solving problems involving data with large dimensionality, explaining the results from the fitted parameters remains a challenging task of utmost importance, especially in physics applications. Here it is shown how this can be accomplished for the ferromagnetic Ising model, the target of many ML studies in the last years. By using a neural network (NN) without any hidden layers and the symmetry of the Hamiltonian to find the critical temperature for the continuous phase transition of the model, an explanation of its strategy is found. This allows the prediction of the minimal extension of the NN to solve the problem when the symmetry is not known, which is also explainable.
    
[^14]: 一个变化检测的现实验证

    A Change Detection Reality Check

    [https://arxiv.org/abs/2402.06994](https://arxiv.org/abs/2402.06994)

    该论文通过实验证明，一个简单的U-Net分割基线仍然是进行变化检测任务的顶尖表现者。

    

    在近年来的遥感文献中，出现了大量提出的用于变化检测的深度学习架构。这些方法声称在不同的标准基准数据集上提供了最先进的性能。然而，该领域是否真正取得了重大进展？在本文中，我们进行了实验证明，一个简单的U-Net分割基线，没有训练技巧或复杂的架构改变，仍然是进行变化检测任务的顶尖表现者。

    In recent years, there has been an explosion of proposed change detection deep learning architectures in the remote sensing literature. These approaches claim to offer state-of the-art performance on different standard benchmark datasets. However, has the field truly made significant progress? In this paper we perform experiments which conclude a simple U-Net segmentation baseline without training tricks or complicated architectural changes is still a top performer for the task of change detection.
    
[^15]: 通过重复使用经过验证的电路增加语言模型的可信度

    Increasing Trust in Language Models through the Reuse of Verified Circuits

    [https://arxiv.org/abs/2402.02619](https://arxiv.org/abs/2402.02619)

    本文介绍了一种通过重复使用经过验证的电路来增加语言模型的可信度的方法。研究者通过构建数学和逻辑规范的框架，并对一个n位整数加法模型进行完全验证。他们插入训练好的加法模型到一个未经训练的模型中，通过训练组合模型执行加法和减法。他们发现加法电路在这两个任务中得到了广泛的重复使用，从而简化了减法模型的验证。

    

    语言模型（LMs）在各种预测任务中的应用越来越广泛，但它们的训练经常忽略罕见的边界情况，降低了它们的可靠性。在本文中，我们定义了一个严格的可信度标准，即任务算法和电路实现必须经过验证，考虑到边界情况，并且没有已知的故障模式。我们展示了通过使用数学和逻辑规范的框架来构建变压器模型，可以训练出满足这一标准的模型。在本文中，我们对一个n位整数加法模型进行了完全验证。为了展示经过验证的模块的重复使用性，我们将训练好的整数加法模型插入到一个未经训练的模型中，并训练组合模型同时执行加法和减法。我们发现加法电路在这两个任务中得到了广泛的重复使用，从而简化了更复杂的减法模型的验证。我们讨论了如何将经过验证的任务模块插入到语言模型中，以利用模型的重复使用来提高可验证性和可信度。

    Language Models (LMs) are increasingly used for a wide range of prediction tasks, but their training can often neglect rare edge cases, reducing their reliability. Here, we define a stringent standard of trustworthiness whereby the task algorithm and circuit implementation must be verified, accounting for edge cases, with no known failure modes. We show that a transformer model can be trained to meet this standard if built using mathematically and logically specified frameworks. In this paper, we fully verify a model for n-digit integer addition. To exhibit the reusability of verified modules, we insert the trained integer addition model into an untrained model and train the combined model to perform both addition and subtraction. We find extensive reuse of the addition circuits for both tasks, easing verification of the more complex subtractor model. We discuss how inserting verified task modules into LMs can leverage model reuse to improve verifiability and trustworthiness of languag
    
[^16]: 揭示自主扫描探针显微术中初始选择和循环干预对学习动力学的影响

    Unraveling the Impact of Initial Choices and In-Loop Interventions on Learning Dynamics in Autonomous Scanning Probe Microscopy

    [https://arxiv.org/abs/2402.00071](https://arxiv.org/abs/2402.00071)

    本文研究了自主扫描探针显微术中初始选择和循环干预对学习动力学的影响，并探讨了“种子效应”和种子点干预的概念，对深度内核学习的有效性进行了实证分析。

    

    自主实验（AE）目前的重点是开发有效进行AE的鲁棒工作流。这需要明确定义的方法来指导AE过程，包括超参数调整策略和工作流循环中的高级人员干预。本文通过分析自主扫描探针显微术中深度内核学习（DKL）的学习动力学，全面阐述了初始实验条件和循环干预对学习过程的影响。我们探讨了“种子效应”的概念，即初始实验设置对后续学习轨迹具有重要影响。此外，我们引入了AE中种子点干预的方法，使操作者能够影响探索过程。通过使用PbTiO3薄膜上的Piezoresponse力显微镜（PFM）数据集，我们展示了“种子效应”和循环种子干预对DKL的有效性的影响。

    The current focus in Autonomous Experimentation (AE) is on developing robust workflows to conduct the AE effectively. This entails the need for well-defined approaches to guide the AE process, including strategies for hyperparameter tuning and high-level human interventions within the workflow loop. This paper presents a comprehensive analysis of the influence of initial experimental conditions and in-loop interventions on the learning dynamics of Deep Kernel Learning (DKL) within the realm of AE in Scanning Probe Microscopy. We explore the concept of 'seed effect', where the initial experiment setup has a substantial impact on the subsequent learning trajectory. Additionally, we introduce an approach of the seed point interventions in AE allowing the operator to influence the exploration process. Using a dataset from Piezoresponse Force Microscopy (PFM) on PbTiO3 thin films, we illustrate the impact of the 'seed effect' and in-loop seed interventions on the effectiveness of DKL in pre
    
[^17]: 系统评估AI/ML支持的连接健康系统的安全风险

    Systematically Assessing the Security Risks of AI/ML-enabled Connected Healthcare Systems

    [https://arxiv.org/abs/2401.17136](https://arxiv.org/abs/2401.17136)

    研究评估了将机器学习应用于医疗系统的安全风险，特别是连接外围设备的连接系统。作者通过案例研究展示了通过利用蓝牙通信渠道漏洞对机器学习血糖监测系统进行攻击的可能性，并指出当前的风险评估技术不足以应对这些新的风险。

    

    在医疗领域中，机器学习支持的系统的采用数量不断增加。虽然在医疗保健中使用机器学习有很多好处，但它也扩大了医疗系统的威胁面。我们表明，在医疗系统中使用机器学习的过程中，特别是涉及将机器学习引擎与多个外围设备相连的连接系统中，存在安全风险，可能在敌对干预的情况下对患者的健康造成危害。这些新的风险来自外围设备和通信渠道的安全漏洞。我们展示了一个案例研究，演示了在推理过程中通过引入敌对数据点对机器学习血糖监测系统进行攻击的情况。我们展示了对手可以通过利用连接血糖仪与机器学习应用之间的蓝牙通信渠道中已知的漏洞来实现这一点。我们进一步表明，当前的风险评估技术不足以应对这些新的风险。

    The adoption of machine-learning-enabled systems in the healthcare domain is on the rise. While the use of ML in healthcare has several benefits, it also expands the threat surface of medical systems. We show that the use of ML in medical systems, particularly connected systems that involve interfacing the ML engine with multiple peripheral devices, has security risks that might cause life-threatening damage to a patient's health in case of adversarial interventions. These new risks arise due to security vulnerabilities in the peripheral devices and communication channels. We present a case study where we demonstrate an attack on an ML-enabled blood glucose monitoring system by introducing adversarial data points during inference. We show that an adversary can achieve this by exploiting a known vulnerability in the Bluetooth communication channel connecting the glucose meter with the ML-enabled app. We further show that state-of-the-art risk assessment techniques are not adequate for i
    
[^18]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^19]: 基于图诱导的局部值函数的分布式多智能体强化学习

    Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced Local Value Functions

    [https://arxiv.org/abs/2202.13046](https://arxiv.org/abs/2202.13046)

    通过利用图结构，本文提出了一种通用计算高效的分布式框架，基于局部值函数的分布式RL方法在协作多智能体强化学习中取得了显著的样本复杂性降低。

    

    实现大规模协作多智能体系统的分布式强化学习(RL)具有挑战性，因为：(i)每个智能体只能访问有限的信息；(ii)由于维度诅咒，会出现收敛或计算复杂性问题。本文提出了一种通用的计算高效的协作多智能体强化学习(MARL)分布式框架，通过利用该问题中涉及的图结构。我们引入了描述MARL中三种类型智能体耦合的三个耦合图，分别是状态图、观测图和奖励图。通过进一步考虑通信图，我们提出了两种基于耦合图中派生的局部值函数的分布式RL方法。第一种方法在前述四个图上的特定条件下可以显著降低样本复杂性。第二种

    arXiv:2202.13046v4 Announce Type: replace-cross  Abstract: Achieving distributed reinforcement learning (RL) for large-scale cooperative multi-agent systems (MASs) is challenging because: (i) each agent has access to only limited information; (ii) issues on convergence or computational complexity emerge due to the curse of dimensionality. In this paper, we propose a general computationally efficient distributed framework for cooperative multi-agent reinforcement learning (MARL) by utilizing the structures of graphs involved in this problem. We introduce three coupling graphs describing three types of inter-agent couplings in MARL, namely, the state graph, the observation graph and the reward graph. By further considering a communication graph, we propose two distributed RL approaches based on local value-functions derived from the coupling graphs. The first approach is able to reduce sample complexity significantly under specific conditions on the aforementioned four graphs. The second
    
[^20]: ProbMCL: 简单的概率对比学习用于多标签视觉分类

    ProbMCL: Simple Probabilistic Contrastive Learning for Multi-label Visual Classification. (arXiv:2401.01448v1 [cs.CV])

    [http://arxiv.org/abs/2401.01448](http://arxiv.org/abs/2401.01448)

    ProbMCL是一个简单而有效的概率对比学习框架，用于解决多标签图像分类任务中的挑战。该方法通过采用监督对比学习和混合密度网络，在捕捉标签之间的依赖关系的同时，降低了复杂模块的计算需求和可解释性的不足。

    

    在计算机视觉和医学影像等许多领域中，多标签图像分类是一项具有挑战性的任务。最近的进展引入了基于图和变压器的方法来提高性能并捕捉标签之间的依赖关系。然而，这些方法通常包含复杂的模块，需要大量计算，并且缺乏可解释性。在本文中，我们提出了概率多标签对比学习（ProbMCL），这是一个新颖的框架，用于解决多标签图像分类任务中的这些挑战。我们提出了一个简单而有效的方法，采用了监督对比学习，根据决策阈值将与锚图像具有足够标签的样本引入正样本集。这种结构通过将正样本对的嵌入拉近，并推离低于阈值的负样本来捕捉标签之间的依赖关系。我们通过将混合密度网络融入对比学习中来增强表示学习。

    Multi-label image classification presents a challenging task in many domains, including computer vision and medical imaging. Recent advancements have introduced graph-based and transformer-based methods to improve performance and capture label dependencies. However, these methods often include complex modules that entail heavy computation and lack interpretability. In this paper, we propose Probabilistic Multi-label Contrastive Learning (ProbMCL), a novel framework to address these challenges in multi-label image classification tasks. Our simple yet effective approach employs supervised contrastive learning, in which samples that share enough labels with an anchor image based on a decision threshold are introduced as a positive set. This structure captures label dependencies by pulling positive pair embeddings together and pushing away negative samples that fall below the threshold. We enhance representation learning by incorporating a mixture density network into contrastive learning 
    
[^21]: 短期与长期无人机协调：分布式优化与深度强化学习的交汇

    Short vs. Long-term Coordination of Drones: When Distributed Optimization Meets Deep Reinforcement Learning. (arXiv:2311.09852v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2311.09852](http://arxiv.org/abs/2311.09852)

    这项研究介绍了一种将短期计划生成和选择与分布式优化以及深度强化学习相结合的渐进方法，用于无人机的协调和规划。实验结果表明，与最先进的方法相比，该方法在动态环境中具有出色的性能。

    

    在智能城市中，支持充电技术的自主交互式无人机群可以提供引人注目的感知能力，例如交通监测和灾难响应。现有方法，包括分布式优化和深度强化学习(DRL)，旨在协调无人机以实现成本效益高、高质量的导航、感知和充电。然而，它们面临着重大挑战：短期优化在动态环境中的意外变化下并不有效，而长期学习缺乏可扩展性、韧性和灵活性。为了弥合这一差距，本文提出了一种新的渐进方法，将基于分布式优化的短期计划生成和选择与基于DRL的长期飞行方向的战略调度相结合。通过对从现实城市移动中生成的数据集进行广泛实验，表明所提出的解决方案与最先进的方法相比具有卓越的性能。

    Swarms of autonomous interactive drones, with the support of recharging technology, can provide compelling sensing capabilities in Smart Cities, such as traffic monitoring and disaster response. Existing approaches, including distributed optimization and deep reinforcement learning (DRL), aim to coordinate drones to achieve cost-effective, high-quality navigation, sensing, and charging. However, they face grand challenges: short-term optimization is not effective in dynamic environments with unanticipated changes, while long-term learning lacks scalability, resilience, and flexibility. To bridge this gap, this paper introduces a new progressive approach that combines short-term plan generation and selection based on distributed optimization with a DRL-based long-term strategic scheduling of flying direction. Extensive experimentation with datasets generated from realistic urban mobility underscores an outstanding performance of the proposed solution compared to state-of-the-art. We als
    
[^22]: ADMarker: 一种多模式联邦学习系统，用于监测阿尔茨海默病的数字生物标志物

    ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital Biomarkers of Alzheimer's Disease. (arXiv:2310.15301v1 [cs.LG])

    [http://arxiv.org/abs/2310.15301](http://arxiv.org/abs/2310.15301)

    ADMarker是一个多模式联邦学习系统，用于在自然生活环境中监测阿尔茨海默病的数字生物标志物。它具有新颖的联邦学习架构，能够准确检测出数字生物标志物，并在临床试验中展示出高准确率和早期AD识别能力。

    

    阿尔茨海默病（AD）及相关痴呆症由于人口老龄化而成为全球日益严重的健康挑战。本文介绍了ADMarker，这是第一个将多模式传感器和新的联邦学习算法整合起来，以在自然生活环境中检测多维AD数字生物标志物的端到端系统。ADMarker具有一种新颖的三阶段多模式联邦学习架构，能够以保护隐私的方式准确检测数字生物标志物。我们的方法共同解决了数据标签有限、数据异质性和有限的计算资源等几个主要的现实世界挑战。我们建立了一个紧凑的多模式硬件系统，并在一个为期四周的临床试验中将其部署在91名老年参与者身上。结果表明，ADMarker能够准确检测出全面的数字生物标志物，准确率高达93.8％，并以平均88.9％的准确率识别出早期AD。ADMarker提供了一个新的平台，可以在监测AD患者时提供准确和高效的数据分析。

    Alzheimer's Disease (AD) and related dementia are a growing global health challenge due to the aging population. In this paper, we present ADMarker, the first end-to-end system that integrates multi-modal sensors and new federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. ADMarker features a novel three-stage multi-modal federated learning architecture that can accurately detect digital biomarkers in a privacy-preserving manner. Our approach collectively addresses several major real-world challenges, such as limited data labels, data heterogeneity, and limited computing resources. We built a compact multi-modality hardware system and deployed it in a four-week clinical trial involving 91 elderly participants. The results indicate that ADMarker can accurately detect a comprehensive set of digital biomarkers with up to 93.8% accuracy and identify early AD with an average of 88.9% accuracy. ADMarker offers a new platform that 
    
[^23]: 通过附加件变得贝叶斯，捕捉更多不确定性

    Be Bayesian by Attachments to Catch More Uncertainty. (arXiv:2310.13027v1 [cs.LG])

    [http://arxiv.org/abs/2310.13027](http://arxiv.org/abs/2310.13027)

    本文提出了一种附加结构贝叶斯神经网络(ABNN)，通过在主干网络中整合足够分布外数据的不确定性，来提高神经网络对不确定性的捕捉能力。

    

    贝叶斯神经网络(BNNs)已成为不确定性评估的有希望方法之一，由于其坚实的理论基础。然而，BNNs的性能受到捕捉不确定性的能力的影响。本文提出了一种新的附加结构贝叶斯神经网络(ABNN)，通过附加结构从足够分布外的数据(OOD)中捕捉更多的不确定性。我们首先根据先验分布为OOD数据的不确定性构建了一个数学描述，然后开发了一个附加的贝叶斯结构将OOD数据的不确定性整合到主干网络中。ABNN由期望模块和若干分布模块组成。期望模块是一个专注于原始任务的主干深度网络，而分布模块则是作为主干的附加结构的小贝叶斯结构。特别地，这些分布模块的目的是检测和传播OOD数据的不确定性，从而提高整体网络的贝叶斯性质。

    Bayesian Neural Networks (BNNs) have become one of the promising approaches for uncertainty estimation due to the solid theorical foundations. However, the performance of BNNs is affected by the ability of catching uncertainty. Instead of only seeking the distribution of neural network weights by in-distribution (ID) data, in this paper, we propose a new Bayesian Neural Network with an Attached structure (ABNN) to catch more uncertainty from out-of-distribution (OOD) data. We first construct a mathematical description for the uncertainty of OOD data according to the prior distribution, and then develop an attached Bayesian structure to integrate the uncertainty of OOD data into the backbone network. ABNN is composed of an expectation module and several distribution modules. The expectation module is a backbone deep network which focuses on the original task, and the distribution modules are mini Bayesian structures which serve as attachments of the backbone. In particular, the distribu
    
[^24]: 整数值时间序列数据的神经似然近似

    Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])

    [http://arxiv.org/abs/2310.12544](http://arxiv.org/abs/2310.12544)

    本文构建了整数值时间序列数据的神经似然近似方法，使用因果卷积并行评估整个时间序列的似然，实现了对生态学和流行病学模型进行准确推断并显著加快计算速度。

    

    在物理和生物科学中，定义在整数值状态空间上的随机过程很常见。这些模型用于捕捉小系统的动力学，其中个体群体的个体属性不能被忽视，随机效应很重要。由于似然的复杂性，从时间序列数据中推断这些模型的参数是困难的；目前的方法基于基础模型的模拟，计算成本非常高昂，以至于难以实现。在本文中，我们使用因果卷积构建了用于整数值时间序列数据的神经似然近似方法，这使我们能够并行评估整个时间序列的似然。我们通过对一些生态学和流行病学模型进行推断来演示我们的方法，结果显示我们能够准确地近似真实的后验概率，同时在当前方法受限的情况下实现显著的计算加速。

    Stochastic processes defined on integer valued state spaces are popular within the physical and biological sciences. These models are necessary for capturing the dynamics of small systems where the individual nature of the populations cannot be ignored and stochastic effects are important. The inference of the parameters of such models, from time series data, is difficult due to intractability of the likelihood; current methods, based on simulations of the underlying model, can be so computationally expensive as to be prohibitive. In this paper we construct a neural likelihood approximation for integer valued time series data using causal convolutions, which allows us to evaluate the likelihood of the whole time series in parallel. We demonstrate our method by performing inference on a number of ecological and epidemiological models, showing that we can accurately approximate the true posterior while achieving significant computational speed ups in situations where current methods stru
    
[^25]: 关于自然、鲁棒和灾难性过拟合中的过度记忆问题

    On the Over-Memorization During Natural, Robust and Catastrophic Overfitting. (arXiv:2310.08847v1 [cs.LG])

    [http://arxiv.org/abs/2310.08847](http://arxiv.org/abs/2310.08847)

    本论文研究了深度神经网络中的过度记忆问题，发现其会损害泛化能力，并提出了方法综合性地减轻不同类型的过拟合。

    

    过拟合对深度神经网络（DNN）的泛化能力产生了负面影响，无论是在自然训练还是对抗性训练中。现有的方法难以一致地解决不同类型的过拟合，通常设计了针对自然模式或对抗模式的策略。在本工作中，我们采用统一的视角，仅关注自然模式，去探索不同类型的过拟合。具体而言，我们研究了DNN中的记忆效应，并揭示了一种称为过度记忆的共同行为，这会损害它们的泛化能力。这种行为表现为DNN突然对某些训练模式产生高置信度的预测，并对其保持持久记忆。此外，当DNN过度记忆一种对抗模式时，它们往往同时展现出对应自然模式的高置信度预测。这些发现激励我们综合性地减轻不同类型的过拟合，阻碍过度记忆行为的发生。

    Overfitting negatively impacts the generalization ability of deep neural networks (DNNs) in both natural and adversarial training. Existing methods struggle to consistently address different types of overfitting, typically designing strategies that focus separately on either natural or adversarial patterns. In this work, we adopt a unified perspective by solely focusing on natural patterns to explore different types of overfitting. Specifically, we examine the memorization effect in DNNs and reveal a shared behaviour termed over-memorization, which impairs their generalization capacity. This behaviour manifests as DNNs suddenly becoming high-confidence in predicting certain training patterns and retaining a persistent memory for them. Furthermore, when DNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit high-confidence prediction for the corresponding natural pattern. These findings motivate us to holistically mitigate different types of overfitting by hinder
    
[^26]: 基于思维链的Transformer的表达能力

    The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])

    [http://arxiv.org/abs/2310.07923](http://arxiv.org/abs/2310.07923)

    本论文研究基于思维链的Transformer的表达能力，通过允许使用中间生成的方式提高了Transformer的推理能力，并发现线性数量的解码步骤在标准计算复杂度下增加了明显的新能力。

    

    最近的理论研究发现了一些出人意料地简单的推理问题，例如检查图中是否存在连接的两个节点，或模拟有限状态机，这些问题被证明无法由立即读取输入后回答的标准Transformer解决。然而，在实践中，通过允许Transformer使用“思维链”或“草稿纸”，即在回答之前生成并依赖一系列中间token，可以改善其推理能力。基于此，我们问：这种中间生成是否从根本上扩展了仅有解码器的Transformer的计算能力？我们表明答案是肯定的，但增加的程度关键取决于中间生成的数量。例如，我们发现相对于输入长度来说，具有对数级解码步骤的Transformer解码器仅略微推动了标准Transformer的极限，而线性数量的解码步骤则增加了明显的新能力（在标准计算复杂度下）。

    Recent theoretical work has identified surprisingly simple reasoning problems, such as checking if two nodes in a graph are connected or simulating finite-state machines, that are provably unsolvable by standard transformers that answer immediately after reading their input. However, in practice, transformers' reasoning can be improved by allowing them to use a "chain of thought" or "scratchpad", i.e., generate and condition on a sequence of intermediate tokens before answering. Motivated by this, we ask: Does such intermediate generation fundamentally extend the computational power of a decoder-only transformer? We show that the answer is yes, but the amount of increase depends crucially on the amount of intermediate generation. For instance, we find that transformer decoders with a logarithmic number of decoding steps (w.r.t. the input length) push the limits of standard transformers only slightly, while a linear number of decoding steps adds a clear new ability (under standard compl
    
[^27]: 自监督数据集蒸馏用于迁移学习

    Self-Supervised Dataset Distillation for Transfer Learning. (arXiv:2310.06511v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.06511](http://arxiv.org/abs/2310.06511)

    本文提出了一种自监督数据集蒸馏方法，用于将无标签数据集转化为小型合成样本，以支持高效的自监督学习。通过最小化模型对合成样本的表示和可学习目标特征表示之间的均方误差，解决了合成样本梯度偏差的问题。

    

    数据集蒸馏方法在将大型数据集转化为少量具有代表性的样本方面取得了显著成功。然而，它们并不被设计用于产生一个适用于促进自监督预训练的蒸馏数据集。为此，我们提出了一种将无标签数据集蒸馏为一组小型合成样本以用于高效的自监督学习（SSL）的新问题。我们首先证明了在朴素双层优化中，合成样本相对于自监督目标的梯度是“有偏”的，这是由于数据增强或遮蔽引起的随机性。为了解决这个问题，我们提出了最小化模型对合成样本的表示和相应的可学习目标特征表示之间的均方误差（MSE）作为内部目标，这不引入任何随机性。我们的主要动机是通过提出的内部优化获得的模型可以模仿...

    Dataset distillation methods have achieved remarkable success in distilling a large dataset into a small set of representative samples. However, they are not designed to produce a distilled dataset that can be effectively used for facilitating self-supervised pre-training. To this end, we propose a novel problem of distilling an unlabeled dataset into a set of small synthetic samples for efficient self-supervised learning (SSL). We first prove that a gradient of synthetic samples with respect to a SSL objective in naive bilevel optimization is \textit{biased} due to the randomness originating from data augmentations or masking. To address this issue, we propose to minimize the mean squared error (MSE) between a model's representations of the synthetic examples and their corresponding learnable target feature representations for the inner objective, which does not introduce any randomness. Our primary motivation is that the model obtained by the proposed inner optimization can mimic the
    
[^28]: 扩散模型中的泛化性质源于几何自适应的谐波表示

    Generalization in diffusion models arises from geometry-adaptive harmonic representation. (arXiv:2310.02557v1 [cs.CV])

    [http://arxiv.org/abs/2310.02557](http://arxiv.org/abs/2310.02557)

    通过分析基于分数的反向扩散算法生成的高质量样本的研究结果，我们发现尽管存在维度灾难，但为了降噪而训练的深度神经网络可以学习到高维密度。此外，我们展示了在训练集的非重叠子集上训练的网络可以学习到相同的密度，从而证明了DNN架构和训练算法中的归纳偏差与数据分布的一致性。

    

    使用基于分数的反向扩散算法生成的高质量样本提供了证据，表明尽管存在维度灾难，为了降噪而训练的深度神经网络（DNN）可以学习高维密度。然而，关于训练集记忆化的最新报告引发了一个问题，即这些网络是否学习了数据的“真实”连续密度。我们在这里展示，训练在数据集的非重叠子集上的两个降噪DNN学习的几乎是相同的分数函数，从而学习了相同的密度，且仅需很少的训练图像。这种强大的泛化性证明了DNN架构和/或训练算法中的有力归纳偏差与数据分布的特性之间的一致性。我们分析了这些结果，展示了降噪器在适应于底层图像的基础上执行收缩操作。对这些基矢的检查揭示了沿轮廓和均匀图像区域的振荡谐波结构。

    High-quality samples generated with score-based reverse diffusion algorithms provide evidence that deep neural networks (DNN) trained for denoising can learn high-dimensional densities, despite the curse of dimensionality. However, recent reports of memorization of the training set raise the question of whether these networks are learning the "true" continuous density of the data. Here, we show that two denoising DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, with a surprisingly small number of training images. This strong generalization demonstrates an alignment of powerful inductive biases in the DNN architecture and/or training algorithm with properties of the data distribution. We analyze these, demonstrating that the denoiser performs a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous image region
    
[^29]: 将生成对立假设的过程视为知识来源 - 应用于朴素贝叶斯分类器

    Viewing the process of generating counterfactuals as a source of knowledge -- Application to the Naive Bayes classifier. (arXiv:2309.04284v1 [cs.LG])

    [http://arxiv.org/abs/2309.04284](http://arxiv.org/abs/2309.04284)

    将生成对立假设的过程视为知识来源，并应用于朴素贝叶斯分类器，展示其有趣属性。

    

    现在有许多理解算法可以理解机器学习算法的决策，其中包括基于生成对立假设示例的算法。本文提出将这个生成过程视为一种创造一定量知识的方法，这些知识可以存储并在以后以不同的方式使用。本文在加法模型中进行了说明，具体而言，是在朴素贝叶斯分类器的情况下，展示了其在此目的上的有趣属性。

    There are now many comprehension algorithms for understanding the decisions of a machine learning algorithm. Among these are those based on the generation of counterfactual examples. This article proposes to view this generation process as a source of creating a certain amount of knowledge that can be stored to be used, later, in different ways. This process is illustrated in the additive model and, more specifically, in the case of the naive Bayes classifier, whose interesting properties for this purpose are shown.
    
[^30]: 在在线排名中的最小极大后悔问题与Top-k反馈

    On the Minimax Regret in Online Ranking with Top-k Feedback. (arXiv:2309.02425v1 [cs.LG])

    [http://arxiv.org/abs/2309.02425](http://arxiv.org/abs/2309.02425)

    本文研究了在线排名中的最小极大后悔问题与Top-k反馈，并通过提供一个全面的极大后悔率刻画，解决了Chaudhuri和Tewari [2017]所提出的问题。

    

    在在线排名中，学习算法按顺序对一组项目进行排名，并以相关性得分的形式接收反馈。由于获得相关性得分通常涉及人工注释，因此考虑仅对排名中的前k个项目限制反馈的部分反馈设置具有极大的兴趣。Chaudhuri和Tewari [2017]开发了一个框架来分析带有Top $k$反馈的在线排名算法。他们工作的关键要素是使用了部分监控技术。在本文中，我们进一步研究了具有Top $k$反馈的在线排名，并解决了Chaudhuri和Tewari [2017]提出的一些开放性问题。我们对所有$k$和以下排名性能度量（Pairwise Loss，Discounted Cumulative Gain和Precision@n）的Top $k$反馈模型进行了最小极大后悔率的完全刻画。此外，我们提供了一种有效的算法，该算法实现了Precision@n的最小极大后悔率。

    In online ranking, a learning algorithm sequentially ranks a set of items and receives feedback on its ranking in the form of relevance scores. Since obtaining relevance scores typically involves human annotation, it is of great interest to consider a partial feedback setting where feedback is restricted to the top-$k$ items in the rankings. Chaudhuri and Tewari [2017] developed a framework to analyze online ranking algorithms with top $k$ feedback. A key element in their work was the use of techniques from partial monitoring. In this paper, we further investigate online ranking with top $k$ feedback and solve some open problems posed by Chaudhuri and Tewari [2017]. We provide a full characterization of minimax regret rates with the top $k$ feedback model for all $k$ and for the following ranking performance measures: Pairwise Loss, Discounted Cumulative Gain, and Precision@n. In addition, we give an efficient algorithm that achieves the minimax regret rate for Precision@n.
    
[^31]: 快速空间建模的综合变分傅里叶特征

    Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes. (arXiv:2308.14142v1 [stat.ML])

    [http://arxiv.org/abs/2308.14142](http://arxiv.org/abs/2308.14142)

    本论文提出了一种综合变分傅里叶特征的方法，可以对广泛的平稳协方差函数进行快速空间建模，相比其他方法具有更高的性能和加速效果。

    

    稀疏变分逼近是扩展高斯过程推理和学习至更大数据集的流行方法。对于$N$个训练点，精确推理的成本为$O(N^3)$；使用$M \ll N$特征的先进稀疏变分方法成本为$O(NM^2)$。最近，提出了使用更复杂特征的方法；这些方法在低维任务（如空间建模）中能够有很好的性能，但只使用了一类非常有限的核函数，排除了一些常用的核函数。在这项工作中，我们提出了综合傅里叶特征，将这些性能优势扩展到非常广泛的平稳协方差函数。我们从收敛分析和经验探索的角度来解释该方法和参数的选择，同时展示该方法在合成和实际空间回归任务中的实际加速效果。

    Sparse variational approximations are popular methods for scaling up inference and learning in Gaussian processes to larger datasets. For $N$ training points, exact inference has $O(N^3)$ cost; with $M \ll N$ features, state of the art sparse variational methods have $O(NM^2)$ cost. Recently, methods have been proposed using more sophisticated features; these promise $O(M^3)$ cost, with good performance in low dimensional tasks such as spatial modelling, but they only work with a very limited class of kernels, excluding some of the most commonly used. In this work, we propose integrated Fourier features, which extends these performance benefits to a very broad class of stationary covariance functions. We motivate the method and choice of parameters from a convergence analysis and empirical exploration, and show practical speedup in synthetic and real world spatial regression tasks.
    
[^32]: 基于Metapath的上下文知识的深度半监督异常检测

    Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge. (arXiv:2308.10918v1 [cs.LG])

    [http://arxiv.org/abs/2308.10918](http://arxiv.org/abs/2308.10918)

    本文介绍了一种利用基于Metapath的半监督学习的新颖方法，用于图异常检测。通过在编码器和解码器中使用GCN层来有效传播上下文信息，以及特别设计的异常社区，该方法在结构和属性差异的学习中表现出优越性能。通过实验证明了该方法的有效性，为未来的研究提供了重要的思路和方向。

    

    图异常检测近年来引起了广泛的关注。本文介绍了一种新颖的方法，利用基于Metapath的半监督学习，解决了之前方法的局限性。我们提出了一种新的框架，基于Metapath的半监督异常检测（MSAD），在编码器和解码器中都使用GCN层来有效地传播异常和正常节点之间的上下文信息。基于Metapath的上下文信息的设计和特别精心设计的异常社区增强了全局和局部结构和属性差异的学习过程。通过在七个真实网络上进行的一系列综合实验，本文证明了MSAD方法相对于最先进技术的优越性。本研究的有希望的结果为未来的研究铺平了道路，重点是优化和分析Metapath模式以进一步提高方法的效果。

    Graph anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of 
    
[^33]: 对脑网络的可解释分类进行对比图池化。

    Contrastive Graph Pooling for Explainable Classification of Brain Networks. (arXiv:2307.11133v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.11133](http://arxiv.org/abs/2307.11133)

    本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。

    

    功能性磁共振成像(fMRI)是一种常用的测量神经活动的技术。其应用在识别帕金森病、阿尔茨海默病和自闭症等神经退行性疾病方面尤为重要。最近的fMRI数据分析将大脑建模为图，并通过图神经网络(GNN)提取特征。然而，fMRI数据的独特特征要求对GNN进行特殊设计。定制GNN以生成有效且可解释的特征仍然具有挑战性。在本文中，我们提出了对比双注意块和可微分图池化方法ContrastPool，以更好地利用GNN分析脑网络，满足fMRI的特殊要求。我们将我们的方法应用于5个静息态fMRI脑网络数据集的3种疾病，并证明其优于最先进的基准线。我们的案例研究证实，我们的方法提取的模式与神经科学文献中的领域知识相匹配。

    Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literatu
    
[^34]: 离散切割Wasserstein损失的性质

    Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])

    [http://arxiv.org/abs/2307.10352](http://arxiv.org/abs/2307.10352)

    本文研究了离散切割Wasserstein损失的性质，并探讨了其正则性和优化性质以及通过蒙特卡洛近似的方法。

    

    切割Wasserstein（SW）距离已成为比较概率测度的Wasserstein距离的一种流行替代方法。广泛应用包括图像处理、领域自适应和生成建模，常常需要优化一些参数以最小化SW，该参数充当离散概率测度之间的损失函数（因为具有密度的测度在数值上是无法实现的）。所有这些优化问题都存在相同的子问题，即最小化切割Wasserstein能量。在本文中，我们研究了$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$的属性，即两个具有与一个测度的支撑相同数量的离散均匀测度之间的SW距离作为支撑$Y \in \mathbb{R}^{n \times d}$函数的能量。我们研究了这个能量的正则性和优化性质，以及其通过蒙特卡洛近似$\mathcal{E}_p$（使用SW中的期望估计）。

    The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
    
[^35]: 基于核方法的单细胞差异分析测试

    Kernel-Based Testing for Single-Cell Differential Analysis. (arXiv:2307.08509v1 [stat.ML])

    [http://arxiv.org/abs/2307.08509](http://arxiv.org/abs/2307.08509)

    本论文提出了一种基于核方法的单细胞差异分析测试框架，可以非线性比较复杂的细胞间分子特征分布。通过利用核嵌入的变异性，我们的方法能够揭示细胞群体中隐蔽的异质性。我们展示了核测试如何克服单细胞差异分析方法的局限性，并应用于研究分化逆转的过程。

    

    单细胞技术为我们提供了关于基因表达和表观遗传修饰等分子特征的宝贵信息。然而，以控制和强有力的方式比较这些复杂分布面临着方法论上的挑战。本文提出利用基于核嵌入的核测试框架来非线性比较细胞间复杂分子特征的分布。我们的框架不仅允许对特征进行分析，还能在考虑了它们之间复杂依赖关系的情况下进行转录组或表观组的全局比较。通过使用分类器基于核嵌入的变异性来区分细胞，我们的方法可以发现在细胞群体中原本无法察觉到的异质性。我们展示了核测试方法如何克服专门用于单细胞的差异分析方法的局限性。我们还将核测试应用于研究分化逆转的过程。

    Single-cell technologies have provided valuable insights into the distribution of molecular features, such as gene expression and epigenomic modifications. However, comparing these complex distributions in a controlled and powerful manner poses methodological challenges. Here we propose to benefit from the kernel-testing framework to compare the complex cell-wise distributions of molecular features in a non-linear manner based on their kernel embedding. Our framework not only allows for feature-wise analyses but also enables global comparisons of transcriptomes or epigenomes, considering their intricate dependencies. By using a classifier to discriminate cells based on the variability of their embedding, our method uncovers heterogeneities in cell populations that would otherwise go undetected. We show that kernel testing overcomes the limitations of differential analysis methods dedicated to single-cell. Kernel testing is applied to investigate the reversion process of differentiating
    
[^36]: 非累积目标的强化学习

    Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])

    [http://arxiv.org/abs/2307.04957](http://arxiv.org/abs/2307.04957)

    本文研究了最优控制和强化学习中非累积目标的挑战，并提出了修改现有算法的方法来优化这些目标。研究结果表明，在贝尔曼最优性方程中使用广义运算可以更好地处理非累积目标。

    

    在强化学习中，目标几乎总是定义为沿过程中奖励的\emph{累积}函数。然而，在许多最优控制和强化学习问题中，尤其是在通信和网络领域中，目标并不自然地表达为奖励的求和。本文中，我们认识到各种问题中非累积目标的普遍存在，并提出了修改现有算法以优化这些目标的方法。具体来说，我们深入研究了许多最优控制和强化学习算法的基本构建模块：贝尔曼最优性方程。为了优化非累积目标，我们用与目标相对应的广义运算替换了贝尔曼更新规则中的原始求和运算。此外，我们提供了广义运算形式的足够条件以及对马尔可夫决策的假设。

    In reinforcement learning, the objective is almost always defined as a \emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision 
    
[^37]: CLIPMasterPrints: 使用潜在变量演化欺骗对比式语言-图像预训练

    CLIPMasterPrints: Fooling Contrastive Language-Image Pre-training Using Latent Variable Evolution. (arXiv:2307.03798v1 [cs.CV])

    [http://arxiv.org/abs/2307.03798](http://arxiv.org/abs/2307.03798)

    本文展示了对比式语言-图像预训练（CLIP）模型的脆弱性，通过挖掘生成模型的潜在空间可以找到欺骗主图像，这些图像在许多不同的提示下能欺骗CLIP模型，而对人类来说是无法认出的。欺骗主图像在少量图像标题上的训练上可能适用于更多数量的语义相关的标题。两种可能的缓解策略被评估，并发现脆弱性与对比式预训练中的模态差距密切相关。

    

    以对比式语言-图像预训练（CLIP）为代表的同时利用视觉和文本数据的模型越来越重要。本文展示了尽管这些模型具有多功能性，但它们对于所谓的欺骗主图像是脆弱的。欺骗主图像能够最大化CLIP模型在许多不同的提示下的置信度评分，同时对于人类来说是无法认出的。我们展示了如何通过使用演化策略或随机梯度下降在生成模型的潜在空间中搜索欺骗主图像。我们研究了挖掘出的欺骗主图像的特性，并发现在少量图像标题上训练的图像可能适用于更多数量的语义相关的标题。此外，我们评估了两种可能的缓解策略，并发现对欺骗主例子的脆弱性与对比式预训练中的模态差距密切相关。

    Models leveraging both visual and textual data such as Contrastive Language-Image Pre-training (CLIP), are increasingly gaining importance. In this work, we show that despite their versatility, such models are vulnerable to what we refer to as fooling master images. Fooling master images are capable of maximizing the confidence score of a CLIP model for a significant number of widely varying prompts, while being unrecognizable for humans. We demonstrate how fooling master images can be mined by searching the latent space of generative models by means of an evolution strategy or stochastic gradient descent. We investigate the properties of the mined fooling master images, and find that images trained on a small number of image captions potentially generalize to a much larger number of semantically related captions. Further, we evaluate two possible mitigation strategies and find that vulnerability to fooling master examples is closely related to a modality gap in contrastive pre-trained
    
[^38]: 具有生成模型的强化学习中分布鲁棒性的可疑价格

    The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model. (arXiv:2305.16589v1 [cs.LG])

    [http://arxiv.org/abs/2305.16589](http://arxiv.org/abs/2305.16589)

    本文研究了强化学习中的模型鲁棒性以缩小模拟与真实差距，提出了一个名为“分布鲁棒值迭代”的基于模型的方法，可以优化最坏情况下的表现。

    

    本文研究了强化学习中的模型鲁棒性，以减少在实践中的模拟与真实差距。我们采用分布鲁棒马尔可夫决策过程（RMDPs）框架，旨在学习一个策略，在部署环境落在预定的不确定性集合内时，优化最坏情况下的表现。尽管最近有了一些努力，但RMDPs的样本复杂度仍然没有得到解决，无论使用的不确定性集合是什么。不清楚分布鲁棒性与标准强化学习相比是否具有统计学上的影响。假设有一个生成模型，根据名义MDP绘制样本，我们将描述RMDPs的样本复杂度，当由总变差（TV）距离或$\chi^2$分歧指定不确定性集合时。在这里研究的算法是一种基于模型的方法，称为分布鲁棒值迭代，证明了它在整个范围内都是近乎最优的。

    This paper investigates model robustness in reinforcement learning (RL) to reduce the sim-to-real gap in practice. We adopt the framework of distributionally robust Markov decision processes (RMDPs), aimed at learning a policy that optimizes the worst-case performance when the deployed environment falls within a prescribed uncertainty set around the nominal MDP. Despite recent efforts, the sample complexity of RMDPs remained mostly unsettled regardless of the uncertainty set in use. It was unclear if distributional robustness bears any statistical consequences when benchmarked against standard RL.  Assuming access to a generative model that draws samples based on the nominal MDP, we characterize the sample complexity of RMDPs when the uncertainty set is specified via either the total variation (TV) distance or $\chi^2$ divergence. The algorithm studied here is a model-based method called {\em distributionally robust value iteration}, which is shown to be near-optimal for the full range
    
[^39]: 深度学习的拓扑可解释性

    Topological Interpretability for Deep-Learning. (arXiv:2305.08642v1 [stat.ML])

    [http://arxiv.org/abs/2305.08642](http://arxiv.org/abs/2305.08642)

    本文提出了一种在临床和非临床文本上训练的深度学习分类模型中使用拓扑和几何数据分析技术推断主要特征的方法。

    

    随着基于人工智能的系统在日常生活中的应用越来越广泛，理解它们的决策机制的需求也相应加速。我们能够信任基于人工智能决策系统所做的统计推断的程度越来越成为一个越来越重要的问题，特别是在高风险的系统，例如刑事司法或医学诊断系统中，错误的推断可能会产生悲剧性的后果。尽管在解决涉及现实世界数据的问题方面取得了成功，但深度学习（DL）模型无法量化其预测的确定性。而且当其解决方案不正确时，通常仍然非常自信。本文介绍了一种方法，在临床和非临床文本上训练的两个DL分类模型中推断杰出特征，采用了拓扑和几何数据分析技术。我们创建了模型预测空间的图形，并通过特征和预测的相似性将输入聚类到图形的顶点中。

    With the increasing adoption of AI-based systems across everyday life, the need to understand their decision-making mechanisms is correspondingly accelerating. The level at which we can trust the statistical inferences made from AI-based decision systems is an increasing concern, especially in high-risk systems such as criminal justice or medical diagnosis, where incorrect inferences may have tragic consequences. Despite their successes in providing solutions to problems involving real-world data, deep learning (DL) models cannot quantify the certainty of their predictions. And are frequently quite confident, even when their solutions are incorrect.  This work presents a method to infer prominent features in two DL classification models trained on clinical and non-clinical text by employing techniques from topological and geometric data analysis. We create a graph of a model's prediction space and cluster the inputs into the graph's vertices by the similarity of features and prediction
    
[^40]: 校准感知的贝叶斯学习

    Calibration-Aware Bayesian Learning. (arXiv:2305.07504v1 [cs.LG])

    [http://arxiv.org/abs/2305.07504](http://arxiv.org/abs/2305.07504)

    本文提出了一个综合框架，称为校准感知的贝叶斯神经网络 (CAB)，用于共同解决深度神经网络中的校准和贝叶斯学习，通过在训练过程中正则化模型的后验预测分布来提高模型的校准性。

    

    深度学习模型，包括现代系统如大型语言模型，在提供其决策的不确定性方面往往无法提供可靠的估计。为了提高模型置信水平（也称为校准）的质量，常见的方法包括向训练损失添加基于数据的或基于数据无关的正则化项。在传统的频率派学习上最近引入了基于数据的正则化器，以惩罚置信度和准确度之间的偏差。相反，数据无关的正则化器在贝叶斯学习的核心，强制使模型参数空间中的变分分布服从先验密度。前一种方法无法量化认识不确定性，而后者则严重受到模型错误规范的影响。鉴于两种方法的局限性，本文提出了一个综合框架，称为校准感知的贝叶斯神经网络 (CAB)，用于共同解决深度神经网络中的校准和贝叶斯学习。所提出的框架涉及一种新颖的数据相关惩罚项，在训练过程中正则化模型的后验预测分布，从而提高模型的校准性。

    Deep learning models, including modern systems like large language models, are well known to offer unreliable estimates of the uncertainty of their decisions. In order to improve the quality of the confidence levels, also known as calibration, of a model, common approaches entail the addition of either data-dependent or data-independent regularization terms to the training loss. Data-dependent regularizers have been recently introduced in the context of conventional frequentist learning to penalize deviations between confidence and accuracy. In contrast, data-independent regularizers are at the core of Bayesian learning, enforcing adherence of the variational distribution in the model parameter space to a prior density. The former approach is unable to quantify epistemic uncertainty, while the latter is severely affected by model misspecification. In light of the limitations of both methods, this paper proposes an integrated framework, referred to as calibration-aware Bayesian neural n
    
[^41]: Kullback-Leibler Maillard采样在有界奖励的多臂赌博机问题中的应用

    Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])

    [http://arxiv.org/abs/2304.14989](http://arxiv.org/abs/2304.14989)

    本文提出了Kullback-Leibler Maillard Sampling (KL-MS)算法，能够在有界奖励的多臂赌博机中实现KL空间的扩展，具有较好的渐近性能。

    

    本文研究了奖励分布集中在区间$[0,1]$内的$K$臂数臂赌博机问题。本文提出了一种名为Kullback-Leibler Maillard Sampling (KL-MS)的新算法，它是Maillard采样在KL空间的自然扩展。实验表明，KL-MS在Bernoulli奖励时具有渐近最优性能，其最坏情况遗憾度上界为$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$，其中$\mu^*$是最优臂的期望奖励，$T$是时段长度。

    We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
    
[^42]: 带有聚合梯度的快速收敛联邦学习

    Fast Convergence Federated Learning with Aggregated Gradients. (arXiv:2303.15799v1 [cs.LG])

    [http://arxiv.org/abs/2303.15799](http://arxiv.org/abs/2303.15799)

    该论文提出了一种带有聚合梯度的快速收敛联邦学习方法，通过引入均值场方法来完成参数和梯度的聚合步骤，该方法在收敛速度和通信成本方面优于传统方法。

    

    联邦学习（FL）是一种新的机器学习框架，它使多个分布式设备在保护本地数据的同时，通过中央服务器协同训练共享模型。然而，非独立和同分布（Non-IID）的数据样本以及参与者之间频繁的通信将减缓收敛速率并增加通信成本。为了实现快速收敛，我们通过在常规本地更新规则中引入聚合梯度来改善本地梯度下降方法，并提出一种自适应学习率算法，在每次迭代中进一步考虑本地参数和全局参数的偏差。以上策略要求在每个本地迭代中收集所有客户端的本地参数和梯度，由于本地更新期间没有通信，这是具有挑战性的。因此，我们利用均值场方法，引入称为全局均值场和本地均值场的两个均值场术语来完成聚合步骤。实验结果表明，我们提出的方法在收敛速度和通信成本方面优于传统方法。

    Federated Learning (FL) is a novel machine learning framework, which enables multiple distributed devices cooperatively training a shared model scheduled by a central server while protecting private data locally. However, the non-independent-and-identically-distributed (Non-IID) data samples and frequent communication among participants will slow down the convergent rate and increase communication costs. To achieve fast convergence, we ameliorate the local gradient descend approach in conventional local update rule by introducing the aggregated gradients at each local update epoch, and propose an adaptive learning rate algorithm that further takes the deviation of local parameter and global parameter into consideration at each iteration. The above strategy requires all clients' local parameters and gradients at each local iteration, which is challenging as there is no communication during local update epochs. Accordingly, we utilize mean field approach by introducing two mean field ter
    
[^43]: 新熵方法的自适应联邦学习

    Adaptive Federated Learning via New Entropy Approach. (arXiv:2303.14966v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2303.14966](http://arxiv.org/abs/2303.14966)

    本文提出了一种新的自适应学习率方案，基于熵理论缓解异构客户端之间的偏差，实现全局模型的快速收敛。

    

    联邦学习 (FL) 是一种新兴的框架，它允许资源受限的离散客户端在中央服务器的协调下，通过在本地存储保护隐私数据的方式，共同学习全局模型。然而，由于异构客户端的设备和数据差异会导致本地模型参数的偏差，进而导致全局模型的收敛速度减慢和精度降低。当前的 FL 算法普遍采用静态客户端学习策略并不能适应不同客户端的动态训练参数。在本文中，我们根据熵理论考虑不同本地模型参数之间的偏差，为每个客户端提出了基于熵理论的自适应学习率方案，以缓解异构客户端之间的偏差，实现全局模型的快速收敛。但由于不同客户端的本地数据集和特征具有显著的差异，设计每个客户端的最优动态学习率是困难的。

    Federated Learning (FL) has recently emerged as a popular framework, which allows resource-constrained discrete clients to cooperatively learn the global model under the orchestration of a central server while storing privacy-sensitive data locally. However, due to the difference in equipment and data divergence of heterogeneous clients, there will be parameter deviation between local models, resulting in a slow convergence rate and a reduction of the accuracy of the global model. The current FL algorithms use the static client learning strategy pervasively and can not adapt to the dynamic training parameters of different clients. In this paper, by considering the deviation between different local model parameters, we propose an adaptive learning rate scheme for each client based on entropy theory to alleviate the deviation between heterogeneous clients and achieve fast convergence of the global model. It's difficult to design the optimal dynamic learning rate for each client as the lo
    
[^44]: Proximal Newton算法实现高效图拉普拉斯估计

    Efficient Graph Laplacian Estimation by Proximal Newton. (arXiv:2302.06434v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06434](http://arxiv.org/abs/2302.06434)

    本文提出了一种基于Proximal Newton算法的高效图拉普拉斯估计方法，通过引入非凸minimax concave penalty，并利用二阶优化方法和几个算法技巧，实现了准确且高效的求解器。

    

    Laplacian约束的高斯马尔科夫随机场（LGMRF）是一种常见的多元统计模型，用于从给定数据中学习权重稀疏的依赖图。这个图学习问题可以被形式化为最大似然估计（MLE）的精度矩阵，受到Laplacian结构约束的限制，并带有稀疏性诱导的惩罚项。本论文旨在准确且高效地解决这个学习问题。首先，由于在这个设置中通常使用的$\ell_1$-范数惩罚不适用并且可能导致完全图，所以我们采用了非凸的MCP（minimax concave penalty），它促进具有更低估计偏差的稀疏解。其次，与现有的该问题的一阶方法相反，我们开发了一种二阶proximal Newton方法来获得高效的求解器，利用了多种算法特性，如使用共轭梯度法、预条件化和分割到活动/自由集。数值实验证明了该算法的优点。

    The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common multivariate statistical model for learning a weighted sparse dependency graph from given data. This graph learning problem can be formulated as a maximum likelihood estimation (MLE) of the precision matrix, subject to Laplacian structural constraints, with a sparsity-inducing penalty term. This paper aims to solve this learning problem accurately and efficiently. First, since the commonly used $\ell_1$-norm penalty is inappropriate in this setting and may lead to a complete graph, we employ the nonconvex minimax concave penalty (MCP), which promotes sparse solutions with lower estimation bias. Second, as opposed to existing first-order methods for this problem, we develop a second-order proximal Newton approach to obtain an efficient solver, utilizing several algorithmic features, such as using Conjugate Gradients, preconditioning, and splitting to active/free sets. Numerical experiments demonstrate the advanta
    
[^45]: 无视觉基线的多模式语法归纳

    A Vision-free Baseline for Multimodal Grammar Induction. (arXiv:2212.10564v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10564](http://arxiv.org/abs/2212.10564)

    本论文研究了在多模式设置下，只使用文本进行训练的大型语言模型（LLMs）是否能够提供强大的辅助来进行语法归纳。结果显示，基于LLM的纯文本方法在多种多模式数据集上优于先前的方法，并且在性能、参数数量和训练速度方面取得了最先进的结果。

    

    过去的研究表明，配对的视觉与语言信号能够显著改善多模式数据集（如MSCOCO）中的语法归纳。我们研究了只使用文本进行训练的大型语言模型（LLMs）在多模式设置下是否能够提供强大的辅助来进行语法归纳。我们发现，我们的纯文本方法，即基于LLM的C-PCFG（LC-PCFG），在各种多模式数据集上优于先前的多模式方法，并且获得了最先进的语法归纳性能。与带图像的语法归纳相比，LC-PCFG在语料库F1得分上超过了先前的最先进方法7.9个点，参数数量减少了85％，训练速度加快了1.7倍。在三个辅助视频的语法归纳基准中，LC-PCFG在语料库F1上优于先前的最先进方法最多7.7个点，训练速度加快了8.8倍。

    Past work has shown that paired vision-language signals substantially improve grammar induction in multimodal datasets such as MSCOCO. We investigate whether advancements in large language models (LLMs) that are only trained with text could provide strong assistance for grammar induction in multimodal settings. We find that our text-only approach, an LLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods, and achieves state-of-the-art grammar induction performance for various multimodal datasets. Compared to image-aided grammar induction, LC-PCFG outperforms the prior state-of-the-art by 7.9 Corpus-F1 points, with an 85% reduction in parameter count and 1.7x faster training speed. Across three video-assisted grammar induction benchmarks, LC-PCFG outperforms prior state-of-the-art by up to 7.7 Corpus-F1, with 8.8x faster training. These results shed light on the notion that text-only language models might include visually grounded cues that aid in grammar induction in mult
    
[^46]: 学习玻璃液体表示的旋转等变图神经网络

    Rotation-equivariant Graph Neural Networks for Learning Glassy Liquids Representations. (arXiv:2211.03226v2 [cond-mat.soft] UPDATED)

    [http://arxiv.org/abs/2211.03226](http://arxiv.org/abs/2211.03226)

    本文提出了一种旋转等变图神经网络（GNN），通过约束保持旋转平移等变性的方式，学习玻璃液体静态结构的稳健表示。这种约束显著提高了预测能力和泛化能力，同时减少了参数数量，并且提高了解释性。通过迁移学习实验证明了网络的有效性。

    

    在玻璃液体研究领域，使用机器学习（ML）对粒子的静态结构进行建模是一个热门话题。最先进的方法是使用图神经网络（GNN），它具有强大的表达能力，但是模型参数多且缺乏可解释性。受机器学习群等变表示领域的最新进展的启发，我们构建了一个GNN，通过约束其保持旋转平移（SE（3））等变性，学习玻璃静态结构的稳健表示。我们发现，这种约束不仅显著提高了预测能力，还提高了对未见过温度的泛化能力，同时可以减少参数数量。此外，解释性也得到了改善，因为我们可以将基本卷积层的作用与众所周知的旋转不变专家特征联系起来。通过迁移学习实验，我们证明了我们的网络学习了一个稳健的表示。

    Within the glassy liquids community, the use of Machine Learning (ML) to model particles' static structure is currently a hot topic. The state of the art consists in Graph Neural Networks (GNNs), which have a great expressive power but are heavy models with numerous parameters and lack interpretability. Inspired by recent advances in the field of Machine Learning group-equivariant representations, we build a GNN that learns a robust representation of the glass' static structure by constraining it to preserve the roto-translation (SE(3)) equivariance. We show that this constraint not only significantly improves the predictive power but also improves the ability to generalize to unseen temperatures while allowing to reduce the number of parameters. Furthermore, interpretability is improved, as we can relate the action of our basic convolution layer to well-known rotation-invariant expert features. Through transfer-learning experiments we demonstrate that our network learns a robust repre
    
[^47]: 自然图像块的高效表示

    Efficient Representation of Natural Image Patches. (arXiv:2210.13004v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.13004](http://arxiv.org/abs/2210.13004)

    通过抽象模型，研究人员展示了如何通过非线性种群码实现自然图像块的高效表示，以实现早期视觉系统的信息传输和传感器概率分布建模的目标。

    

    在神经信息处理的复杂领域中，从次要细节中辨别出基本原理仍然是一个重大挑战。尽管我们已经对早期视觉系统的解剖学和生理学有了广泛的了解，但一个全面的计算理论仍然难以捉摸。我们能否通过抽象出系统的详细实现并专注于系统旨在解决的基本问题，来洞察生物系统的基本原理呢？利用基于最简化而又现实的假设的一个抽象模型，我们展示了如何实现早期视觉系统的两个最终目标：高效的信息传输和传感器概率分布建模。我们表明，为了优化信息传输，并不意味着获得了最优的概率分布建模。我们通过使用一个二维系统和图像块来说明，可以通过由两个类型驱动的非线性种群码实现一个高效的表示。

    In the complex domain of neural information processing, discerning fundamental principles from ancillary details remains a significant challenge. While there is extensive knowledge about the anatomy and physiology of the early visual system, a comprehensive computational theory remains elusive. Can we gain insights into the underlying principles of a biological system by abstracting away from its detailed implementation and focusing on the fundamental problems that the system is designed to solve? Utilizing an abstract model based on minimal yet realistic assumptions, we show how to achieve the early visual system's two ultimate objectives: efficient information transmission and sensor probability distribution modeling. We show that optimizing for information transmission does not yield optimal probability distribution modeling. We illustrate, using a two-pixel (2D) system and image patches, that an efficient representation can be realized via nonlinear population code driven by two ty
    

