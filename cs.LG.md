# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Neural Progressive Meshes.](http://arxiv.org/abs/2308.05741) | 本论文提出了一种神经渐进网格方法，通过共享的学习生成空间和逐渐传输额外的残余特征，实现了通过互联网传输大量的3D几何数据。 |
| [^2] | [Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics.](http://arxiv.org/abs/2308.05739) | 本论文提出了ZeroGrads框架，通过学习非可微图形的局部替代损失函数来解决无梯度问题，并通过主动平滑和局部性约束优化替代损失的拟合，同时设计了高效的采样方案，实现了可行的运行时间和竞争力。 |
| [^3] | [Follow Anything: Open-set detection, tracking, and following in real-time.](http://arxiv.org/abs/2308.05737) | 本文提出了一个名为“跟随任何物体”的机器人系统，可以实时检测、追踪和跟随任何物体，不受训练时概念限制，并且可以通过多模态查询进行应用。通过利用大规模预训练模型的视觉描述符，该系统能够检测、分割和跟踪物体，同时考虑遮挡和物体重新出现。 |
| [^4] | [PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers.](http://arxiv.org/abs/2308.05732) | PDE-Refiner 是一种利用多步细化过程准确建模所有频率分量的神经PDE求解器，能够在长时间范围内提供稳定、准确的预测。 |
| [^5] | [Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review.](http://arxiv.org/abs/2308.05731) | 这项综述重新思考了基于深度学习的自动驾驶系统中预测和规划的整合问题，提出了将其作为相互依赖的联合步骤来提高安全性、效率性和舒适性的必要性。 |
| [^6] | [EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis.](http://arxiv.org/abs/2308.05725) | 本研究通过引入Expresso数据集，对离散表达性语音再合成进行了基准测试和分析，提出了一种不依赖文本的高质量语音合成方法，能够捕捉到难以转录的语音表达方面。 |
| [^7] | [Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions.](http://arxiv.org/abs/2308.05724) | 该论文研究了使用动态激活函数优化前馈和卷积神经网络的性能。研究结果表明，在卷积神经网络和多层感知器中，复杂的分段线性激活函数比ReLU激活函数表现更好。 |
| [^8] | [A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control.](http://arxiv.org/abs/2308.05711) | 该论文比较了经典强化学习方法和深度强化学习方法在暖通空调控制中的应用，并探讨了模型参数和奖励设置的实际考虑因素。研究结果为能源高效和成本有效的操作提供了洞察力。 |
| [^9] | [Shadow Datasets, New challenging datasets for Causal Representation Learning.](http://arxiv.org/abs/2308.05707) | 该论文提出了两个新的挑战性数据集，用于因果表示学习，并对现有数据集进行了修改，以更好地评估CRL性能。 |
| [^10] | [Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient.](http://arxiv.org/abs/2308.05681) | 本文针对基于骨骼的人体动作识别方法的脆弱性进行了研究，提出了一种新的硬性无盒对抗攻击方法，通过学习运动流形和定义骨骼-动作知情梯度来攻击模型，揭示了这种脆弱性的存在。 |
| [^11] | [Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning.](http://arxiv.org/abs/2308.05680) | 本研究通过创建新的数据集、评估多语言预训练Transformer模型以及提出多阶段框架来解决了跨语言澄清检索问题。 |
| [^12] | [AST-MHSA : Code Summarization using Multi-Head Self-Attention.](http://arxiv.org/abs/2308.05646) | AST-MHSA模型通过多头自注意力从AST中提取重要的语义信息，并利用编码器-解码器架构生成源代码的简明自然语言描述。 |
| [^13] | [IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer.](http://arxiv.org/abs/2308.05633) | IIHT是一种用于医学报告生成的基于图像到指示器层次Transformer的框架，可以提取医学图像的特征并生成与疾病相关的指示器。 |
| [^14] | [ReLU and Addition-based Gated RNN.](http://arxiv.org/abs/2308.05629) | 这种新型的门控机制将循环神经网络中传统门的乘法和Sigmoid函数替换为加法和ReLU激活函数，以降低计算成本，并在受限硬件上实现更高效的执行或更大型的模型。通过实验证明，该机制能够捕捉到序列数据中的长期依赖关系。 |
| [^15] | [Normalized Gradients for All.](http://arxiv.org/abs/2308.05621) | 这篇论文提出了一种利用标准化梯度适应 H\"{o}lder 光滑性的方法，并引入了局部 H\"{o}lder 光滑性的新概念。 |
| [^16] | [Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance.](http://arxiv.org/abs/2308.05619) | 提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。 |
| [^17] | [Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction.](http://arxiv.org/abs/2308.05601) | 本文提出了一种基于多图空时图卷积网络的方法，用于预测高速公路每日交通流量。通过数据归一化策略处理数据不平衡问题，并利用图卷积网络捕捉空时特征。同时，还使用了气象和日历特征。 |
| [^18] | [NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search.](http://arxiv.org/abs/2308.05600) | NUPES提出一种改进的非均匀量化方法，用于解决深度学习模型量化中的局限性，并通过利用自同构来保持标量m。 |
| [^19] | [Symmetry Defense Against XGBoost Adversarial Perturbation Attacks.](http://arxiv.org/abs/2308.05575) | 本研究研究了对称性是否可以作为防御XGBoost对抗性攻击的一种方法，发现对称性可以使模型对对称对抗样本的分类恢复到正确的分类。 |
| [^20] | [AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting.](http://arxiv.org/abs/2308.05566) | AutoGluon-TimeSeries是一个开源的AutoML库，专注于概率时间序列预测。它提供了简单易用、准确的点预测和分位数预测，并在短时间内提供高准确性。通过结合传统的统计模型、机器学习预测方法和集成技术，AutoGluon-TimeSeries展现出了强大的实证性能，在多个基准数据集上表现优异。 |
| [^21] | [Efficient Variational Inference for Large Skew-t Copulas with Application to Intraday Equity Returns.](http://arxiv.org/abs/2308.05564) | 本研究提出一种快速而准确的贝叶斯变分推理方法，用于估计大规模偏t乌鸦因子勾结模型。该方法能够捕捉到金融数据中的不对称和极端尾部相关性，以及股票对之间的异质性非对称依赖。 |
| [^22] | [Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI.](http://arxiv.org/abs/2308.05525) | 本文研究了三维点云的临界点与非分布样本之间的相互作用，并将临界点的概念推广为重要性度量方法。通过仅基于非重要点进行分类网络训练，可以提高鲁棒性，同时在干净数据集上会有些性能损失。建议使用标准化熵选择非临界点集合的自适应阈值。这种重要性度量方法计算速度极快，可以应用于可解释AI、离群值去除、不确定性估计、鲁棒分类和对抗性防御等多种应用。 |
| [^23] | [Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning.](http://arxiv.org/abs/2308.05522) | 本研究通过将多个单步反合成模型应用于多步合成规划，发现单步性能较好并不一定能找到潜在的反应路径，强调了将单步模型与合成规划相结合的重要性。 |
| [^24] | [On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem.](http://arxiv.org/abs/2308.05509) | 本文研究了ReLU DNNs的最佳表达能力及其在逼近中的应用。我们证明了ReLU DNNs可以表示任何在$[0,1]$上由$O(N^2L)$个线性分段构成的连续函数，并且这种表示方式是最优的。此外，通过科尔莫哥洛夫叠加定理，我们实现了在高维空间中处理连续函数时ReLU DNNs的提升逼近速率。 |
| [^25] | [Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics.](http://arxiv.org/abs/2308.05483) | 这项研究针对机器人抓取任务中的奖励稀疏性、行为稀疏性和行为空间错位等挑战，探讨了优质多样性方法解决该问题的能力。通过在多个实验领域中进行实验，结果表明... |
| [^26] | [LLM As DBA.](http://arxiv.org/abs/2308.05481) | LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。 |
| [^27] | [Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis.](http://arxiv.org/abs/2308.05476) | 本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。 |
| [^28] | [Provably Efficient Algorithm for Nonstationary Low-Rank MDPs.](http://arxiv.org/abs/2308.05471) | 本文提出了针对非平稳低秩MDP的可证明高效算法，通过研究在非平稳环境下的强化学习，捕捉了深度RL中未知表示的特性，并给出了平均动态次最优间隙的上界。 |
| [^29] | [$\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns.](http://arxiv.org/abs/2308.05463) | $\mathcal{G}^2Pxy$是一种使用生成式方法的图节点开放集分类模型，通过在训练和验证过程中没有未知类别的信息，利用两种类型的代理未知节点进行分类。 |
| [^30] | [A Forecaster's Review of Judea Pearl's Causality: Models, Reasoning and Inference, Second Edition, 2009.](http://arxiv.org/abs/2308.05451) | 本文评述了朱迪亚·珀尔的《因果：模型、推理与推断》第二版，重点介绍了其中的更新内容以及一种易于跟随的预测场景下的因果推断策略，并讨论了在时间序列预测中应用因果推断所面临的潜在益处和挑战。 |
| [^31] | [Explainable AI applications in the Medical Domain: a systematic review.](http://arxiv.org/abs/2308.05411) | 该论文通过文献综述探讨了医学决策支持中可解释的人工智能解决方案的最新发展，结果发现通用模型的XAI技术被广泛采用，深度学习模型被更多使用，解释性被应用于提高信任，但医生的参与仍较少报道。 |
| [^32] | [A Comparative Assessment of Multi-view fusion learning for Crop Classification.](http://arxiv.org/abs/2308.05407) | 本研究比较评估了多视角融合学习在农作物分类中的效果，提出的融合方法优于单一视角和先前方法，根据测试区域选择最佳融合方法。 |
| [^33] | [Product Review Image Ranking for Fashion E-commerce.](http://arxiv.org/abs/2308.05390) | 本文针对时尚电子商务平台上的产品评论图片排序问题，提出了一个简单而有效的训练过程，能够将最相关的图片显示在前面，对用户的在线购物选择和行为产生影响。 |
| [^34] | [Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.](http://arxiv.org/abs/2308.05374) | 本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。 |
| [^35] | [Flexible Isosurface Extraction for Gradient-Based Mesh Optimization.](http://arxiv.org/abs/2308.05371) | 本文提出了一种名为FlexiCubes的灵活等值面表示方法，用于基于梯度的网格优化，允许对提取的网格几何和连通性进行灵活调整，从而高质量地保留特征。 |
| [^36] | [Machine Learning aided Computer Architecture Design for CNN Inferencing Systems.](http://arxiv.org/abs/2308.05364) | 本研究提出了一种机器学习辅助的计算机架构设计方法，用于加快卷积神经网络推理系统的设计过程。通过快速而准确地预测CNN在推理过程中的功耗和性能，帮助计算机架构师在早期阶段进行估计，从而减少开发周期。 |
| [^37] | [FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis.](http://arxiv.org/abs/2308.05362) | 本文提出了FINER，这是第一个能够生成高准确性和高可理解性解释的风险检测分类器框架。 |
| [^38] | [Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers.](http://arxiv.org/abs/2308.05353) | 本文介绍了一种名为PreAttacK的新算法，用于提前检测社交网络中的伪造账号。该算法利用了伪造账号在加入网络后的初始朋友请求行为，通过多类扩展偏好连接模型实现了近乎最优的解决方案。 |
| [^39] | [RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model.](http://arxiv.org/abs/2308.05345) | RTLLM是一个用自然语言指令生成设计RTL的开源基准测试，旨在解决现有工作中目标设计简单且规模小的问题，并提供对基于LLM的解决方案进行设计质量的定量评估。 |
| [^40] | [OpenProteinSet: Training data for structural biology at scale.](http://arxiv.org/abs/2308.05326) | OpenProteinSet是一个包含超过1600万个MSAs和蛋白质结构预测的开源数据集，解决了蛋白质机器学习中数据不足的问题。 |
| [^41] | [Homophily-enhanced Structure Learning for Graph Clustering.](http://arxiv.org/abs/2308.05309) | 提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。 |
| [^42] | [From CNN to Transformer: A Review of Medical Image Segmentation Models.](http://arxiv.org/abs/2308.05305) | 该论文综述了医疗图像分割模型的发展，重点介绍了U-Net及其变体以及基于Transformer的模型如TransUNet的应用。论文通过理论分析和定量评估，总结了这些模型的特点和性能，并讨论了医学图像分割领域的挑战和未来趋势。 |
| [^43] | [Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error.](http://arxiv.org/abs/2308.05292) | 本文研究了在分散网络中拜占庭鲁棒的随机优化问题，提出了两种方差减少方法来消除随机梯度噪声的负面效应，并取得了具有线性收敛速度和小的学习错误的结果。 |
| [^44] | [Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season.](http://arxiv.org/abs/2308.05281) | 该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。 |
| [^45] | [Cross-heterogeneity Graph Few-shot Learning.](http://arxiv.org/abs/2308.05275) | 这项研究提出了一种跨异质图少样本学习模型，通过提取元模式和使用多视图异质图神经网络来捕获异质信息并学习跨异质图的元模式。 |
| [^46] | [Data-driven Intra-Autonomous Systems Graph Generator.](http://arxiv.org/abs/2308.05254) | 本文介绍了一种基于深度学习的新型合成图生成器DGGI，用于准确地模拟互联网中自治系统内的图的属性，如中心性、聚类性、同质性以及节点度量。该生成器的性能优于现有的互联网拓扑生成器。 |
| [^47] | [AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS).](http://arxiv.org/abs/2308.05239) | 这篇论文提出了适应现代应用和组织要求的AI-enabled软件和系统架构框架，重点关注机器学习驱动的智能物联网系统(CPS)。作者提出了用于评估和基准化ML-enabled CPS的优点标准。 |
| [^48] | [Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models.](http://arxiv.org/abs/2308.05237) | 该研究通过比较研究四种量子机器学习模型，证明了量子支持向量分类器模型在金融欺诈检测方面具有最高性能，并为量子机器学习在欺诈检测领域的未来发展提供了重要见解。 |
| [^49] | [Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping.](http://arxiv.org/abs/2308.05235) | 本文提出了一种称为SGU-MLP的学习算法，它利用MLPs和空间门控单元（SGUs）来精确地进行土地利用和土地覆盖绘图。实验结果显示，SGU-MLP算法在多个基于CNN和CNN-ViT模型上具有明显的优势。 |
| [^50] | [Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving.](http://arxiv.org/abs/2308.05234) | 本论文研究利用边缘和云端技术实现自动驾驶中的实时物体检测。通过创建合成数据集，评估不同的外部化策略，并使用真实硬件和网络模拟进行比较，找到了权衡预测质量和端到端延迟的最佳方法。 |
| [^51] | [SegMatch: A semi-supervised learning method for surgical instrument segmentation.](http://arxiv.org/abs/2308.05232) | SegMatch是一种用于手术器械分割的半监督学习方法，通过结合一致性正则化和伪标签来减少昂贵的注释需求，并通过弱增强和生成伪标签来实现无监督损失的施加。 |
| [^52] | [Training neural networks with end-to-end optical backpropagation.](http://arxiv.org/abs/2308.05226) | 本研究首次提出了一种非常简单和通用的方案，使用饱和吸收体作为激活单元的光学元件来实现光学反向传播，以解决光学神经网络训练中的难题。 |
| [^53] | [Decoding Layer Saliency in Language Transformers.](http://arxiv.org/abs/2308.05219) | 本文提出了一种在语言转换器中识别文本显著性的策略，并适应了基于梯度的显著性方法，在多个基准分类数据集上取得了一致提升。 |
| [^54] | [Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio.](http://arxiv.org/abs/2308.05218) | 本论文提出了基于Conformer的单声道音频的目标说话者自动语音识别（TS-ASR）方法。该方法通过优化嵌入模块、掩模模块和ASR模块实现对目标说话者的识别，并且在多个数据集上取得了最先进的性能表现，建立了新的TS-ASR基准。 |
| [^55] | [Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving.](http://arxiv.org/abs/2308.05194) | 本论文评估了行人轨迹预测方法在自动驾驶应用中的可行性，并发现简单模型在生成单个轨迹时仍然具有竞争力，某些通常被认为有用的特征对整体性能影响较小。 |
| [^56] | [Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding.](http://arxiv.org/abs/2308.05189) | 本文研究了基于层次化表示的时空视觉注意力建模和理解，在视频序列中提出了上下文感知的生成概率模型以及用于建模时空视觉注意力和时间领域注意力的深度网络架构。 |
| [^57] | [Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models.](http://arxiv.org/abs/2308.05176) | 本研究对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面比较分析，通过应用多样的预处理技术和优化模型性能，为癫痫病人的有效管理和护理提供了准确且稳健的预测模型。 |
| [^58] | [Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels.](http://arxiv.org/abs/2308.05166) | 本研究提出了一种使用弱标签进行扩展射电星系形态识别的深度学习算法，降低了标注成本并取得了高准确性。 |
| [^59] | [Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators.](http://arxiv.org/abs/2308.05141) | 本文提出了使用深度神经操作器网络来模拟在真实的3D场景中带有移动源的声音传播。通过学习一个紧凑的代理模型，能够快速预测声音传播，避免了计算和存储脉冲响应的离线计算。 |
| [^60] | [Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders.](http://arxiv.org/abs/2308.05133) | 本研究旨在分析数据污染对精神障碍检测性能的影响，结果表明数据污染可能导致对目标精神障碍的分类器训练不佳。 |
| [^61] | [Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?.](http://arxiv.org/abs/2308.05129) | 本论文研究了机器学习基于胸部X射线诊断中性别偏见的原因，发现乳腺组织导致肺部曝光不足从而降低模型性能，并提出了一种新的采样方法来解决记录分布偏斜和标签错误问题。 |
| [^62] | [Data-Free Model Extraction Attacks in the Context of Object Detection.](http://arxiv.org/abs/2308.05127) | 该论文提出了一种在目标检测中进行无数据模型提取的攻击方法，通过使用生成器生成特殊查询，成功实现了对私有数据集上训练的目标模型的窃取。通过定义损失函数和使用新颖的生成器设置，实现了对边界框坐标的预测问题的黑盒攻击。 |
| [^63] | [Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network.](http://arxiv.org/abs/2308.05125) | 本研究采用两种新算法和四种经典算法，成功揭示了Omicron病毒变体中的社区结构，为进一步了解疾病发病机制和推进药物发现提供了重要线索。 |
| [^64] | [Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder.](http://arxiv.org/abs/2308.05122) | 本研究提出了一种基于自注意力的模型，在结合遗传、人口统计和神经影像数据的基础上预测自闭症谱系障碍。通过引入基因型数据来指导对神经影像数据的关注，实现了对重要特征的模型预测。 |
| [^65] | [Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems.](http://arxiv.org/abs/2308.05120) | 本文提出了一种实时的模型不可知方法，通过在训练数据集上结合超出分布检测来评估机器学习预测的可靠性，解决了机器学习集成系统可信度不足的问题。 |
| [^66] | [Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries.](http://arxiv.org/abs/2308.05118) | 本文提出了一种基于序列相似性和上下文的向量嵌入方法，用于改进cDNA文库的压缩、相似性搜索、聚类、组织和操作。通过将序列转换为向量嵌入的形式，可以更高效地聚类并提高压缩性能，同时可以基于氨基酸性质进行聚类。 |
| [^67] | [PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer.](http://arxiv.org/abs/2308.05115) | PTransIPs是一种新型深度学习模型，它将蛋白质序列中的氨基酸视为自然语言中的单词，并结合大型预训练蛋白质模型的嵌入。该模型通过结合卷积神经网络和Transformer模型进行训练，用于识别磷酸化位点。 |
| [^68] | [Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke.](http://arxiv.org/abs/2308.05110) | 本文提出了一种可解释的基于注意力机制的变压器模型，用于早期中风死亡率预测。该模型旨在提供解释性和忠实度，并通过使用Shapley值和基于注意力的评分来改进模型的可解释性和忠实度。 |
| [^69] | [Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures.](http://arxiv.org/abs/2308.05106) | 本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性，通过在联邦学习环境中训练最佳暴力检测模型，实现了比现有模型更好的准确性结果。 |
| [^70] | [Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories.](http://arxiv.org/abs/2308.05011) | 提出了一种专门用于处理具有不同内部类别的天文学异常检测方法，采用多类深度支持向量数据描述(MCDSVDD)方法，通过使用神经网络将数据映射到超球体中，每个超球体代表一个特定的内部类别，并计算样本与超球体中心的距离以确定异常分数。 |
| [^71] | [A Feature Set of Small Size for the PDF Malware Detection.](http://arxiv.org/abs/2308.04704) | 该研究提出了一种小型特征集，用于检测PDF恶意软件，无需太多领域知识。在六种机器学习模型中，使用Random Forest模型时可以达到99.75%的准确性。这个仅包含12个特征的特征集是最简洁的之一，尽管规模较小，但结果可与采用更大特征集的最先进方法相媲美。 |
| [^72] | [SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling.](http://arxiv.org/abs/2308.04365) | SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。 |
| [^73] | [Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience.](http://arxiv.org/abs/2308.03712) | 本文研究了通过同时缩放数据规模、模型规模和图像分辨率，利用自监督学习算法能够以非人类尺度的条件实现人类级别的物体识别能力。 |
| [^74] | [Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network.](http://arxiv.org/abs/2308.03382) | 提出了一个使用混合注意力和残差U块的双分支网络，用于增强细胞核分割。此方法能够有效处理细胞核的大小变化、模糊轮廓、染色不均匀、细胞团聚和重叠的细胞核等挑战。 |
| [^75] | [AI-GOMS: Large AI-Driven Global Ocean Modeling System.](http://arxiv.org/abs/2308.03152) | 提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。 |
| [^76] | [Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples.](http://arxiv.org/abs/2307.16361) | 本研究通过建立全面的点云对抗鲁棒性基准、收集已有的防御技巧，并进行实验，总结出了一种有效的点云对抗防御方法。 |
| [^77] | [Scaling Data Generation in Vision-and-Language Navigation.](http://arxiv.org/abs/2307.15644) | 这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。 |
| [^78] | [Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad.](http://arxiv.org/abs/2307.14527) | 该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。 |
| [^79] | [Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling.](http://arxiv.org/abs/2307.07944) | 本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。 |
| [^80] | [From NeurODEs to AutoencODEs: a mean-field control framework for width-varying Neural Networks.](http://arxiv.org/abs/2307.02279) | 该论文提出了一种均值场控制框架，从NeurODEs到AutoencODEs，用于模拟宽度可变的神经网络。通过修改驱动动态的控制场，扩展了原始NeurODEs的适用范围，并处理了低Tikhonov正则化情况下可能的非凸成本景观。 |
| [^81] | [Structure in Reinforcement Learning: A Survey and Open Problems.](http://arxiv.org/abs/2306.16021) | 这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。 |
| [^82] | [Incremental Profit per Conversion: a Response Transformation for Uplift Modeling in E-Commerce Promotions.](http://arxiv.org/abs/2306.13759) | 本文提出了一种新的促销活动单位经济效率的增值度量方法IPC，通过响应转化方法解决响应相关成本增值模型中训练多个模型或计算复杂的问题。该方法只需转换过的数据、其倾向性和一个估计模型，可以提供准确的促销活动获利估计，是提高电子商务平台促销效率的实用工具。 |
| [^83] | [FALL-E: A Foley Sound Synthesis Model and Strategies.](http://arxiv.org/abs/2306.09807) | 本文介绍了一种名为“FALL-E”的佛利音效合成系统及其策略。该模型通过条件训练使其能够根据文本输入了解声音质量和录音环境，并在DCASE 2023挑战赛中表现良好，尤其在多样性上得分最高。 |
| [^84] | [A Brief Review of Hypernetworks in Deep Learning.](http://arxiv.org/abs/2306.06955) | 超网络是一种生成另一个神经网络权重的深度学习技术，具有灵活性、适应性、动态性、更快的训练速度、信息共享和模型压缩等优点。它在各种深度学习问题中显示了良好的效果，并在持续学习、迁移学习、权重剪枝、不确定性量化、零样本学习、自然语言处理和强化学习等领域取得了成功。 |
| [^85] | [The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter.](http://arxiv.org/abs/2306.03805) | 本文在多个大型预训练模型中研究了关键稀疏性，发现在去除具有最小幅度权重的情况下，性能下降速度与稀疏程度的增加呈现出拐点，这对于大型语言模型仍然有效。 |
| [^86] | [Forward-Forward Training of an Optical Neural Network.](http://arxiv.org/abs/2305.19170) | 这篇论文介绍了一种光学神经网络的前向训练方法，使用前向-前向算法进行权重更新，解决了光学平台训练多个可训练层面临的挑战。 |
| [^87] | [Forecasting Irregularly Sampled Time Series using Graphs.](http://arxiv.org/abs/2305.12932) | 使用稀疏双分图结构图和图神经网络的新模型GraFITi，可以准确预测具有不规则采样和缺失值的时间序列。 |
| [^88] | [From Random Search to Bandit Learning in Metric Measure Spaces.](http://arxiv.org/abs/2305.11509) | 本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。 |
| [^89] | [Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission.](http://arxiv.org/abs/2305.11122) | 本研究设计并实现了一种自主溅射沉积薄膜的仪器，利用Python和贝叶斯优化算法控制薄膜组成，加速材料发现步伐。 |
| [^90] | [Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models.](http://arxiv.org/abs/2305.03829) | 本研究采用贝叶斯深度学习估计多种治疗的因果后验分布，提高了基于图像的精准医疗的不确定性估计方法，以预测噪声多的医疗环境下的个体治疗效果。 |
| [^91] | [{\Pi}-ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer.](http://arxiv.org/abs/2304.12177) | {\Pi}-ML是一种基于尺寸分析的机器学习方法，用于估计大气表层光学湍流的强度($C_n^2$)。 物理属性的特征分析表明，潜在温度的归一化方差是预测 $C_n^2$ 的关键特征。 通过训练模型集合，我们在样本外数据上取得了高性能。 |
| [^92] | [Conditional Generative Models for Learning Stochastic Processes.](http://arxiv.org/abs/2304.10382) | 提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。 |
| [^93] | [Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data.](http://arxiv.org/abs/2304.05874) | 本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。 |
| [^94] | [Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection.](http://arxiv.org/abs/2303.14961) | 本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。 |
| [^95] | [Learning ground states of gapped quantum Hamiltonians with Kernel Methods.](http://arxiv.org/abs/2303.08902) | 本文提出了一种利用 kernel 方法学习具有能隙的量子哈密顿量基态的统计学习方法，理论上需要多项式资源实现，通过数值模拟证明了该方法的有效性，并展示了方法的灵活性。 |
| [^96] | [Understanding Model Complexity for temporal tabular and multi-variate time series, case study with Numerai data science tournament.](http://arxiv.org/abs/2303.07925) | 本文采用 Numerai 数据科学竞赛的数据，探究了多变量时间序列建模中不同特征工程和降维方法的应用；提出了一种新的集成方法，用于高维时间序列建模，该方法在通用性、鲁棒性和效率上优于一些深度学习模型。 |
| [^97] | [Multi-metrics adaptively identifies backdoors in Federated learning.](http://arxiv.org/abs/2303.06601) | 本文提出了一种简单而有效的防御策略，采用多指标和动态加权的方法，能够适应性地识别联邦学习中的后门攻击。 |
| [^98] | [A hybrid deep-learning-metaheuristic framework for discrete road network design problems.](http://arxiv.org/abs/2303.06024) | 本研究提出了一种混合框架，结合了深度学习和元启发式算法，用于离散道路网络设计问题。该框架可以快速地得到高质量的解决方案，并且可以应用于其他以图为模型的双层问题决策中。 |
| [^99] | [Synthesizing Mixed-type Electronic Health Records using Diffusion Models.](http://arxiv.org/abs/2302.14679) | 本论文研究了使用扩散模型合成混合类型电子健康记录的潜力，与现有方法相比，在数据质量、实用性和增强方面表现出更好的性能，但在隐私方面存在权衡。 |
| [^100] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^101] | [Width and Depth Limits Commute in Residual Networks.](http://arxiv.org/abs/2302.00453) | 本文研究了深度残差网络中宽度和深度的极限情况，发现当枝干按比例缩放时，得到的协方差结构是相同的。这一发现解释了为什么即使深度和宽度处于相同阶数的网络，标准的宽度无限、然后深度趋向无穷的方法也能提供实际洞见。此外，本文还证明了在这种情况下预激活具有高斯分布，这对贝叶斯深度学习具有直接应用。通过大量模拟实验证明了理论发现的准确性。 |
| [^102] | [RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks.](http://arxiv.org/abs/2301.10822) | 本文提出了一种设计抗对抗攻击的鲁棒性预测维护系统的方法，通过分析不同类型的对抗性攻击的影响，为预测维护模型提出了一种新颖的对抗性防御技术。 |
| [^103] | [Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification.](http://arxiv.org/abs/2301.05869) | 功能性神经网络（FNNs）是一种新的神经网络类别，具有位移不变性和保持数据平滑性的特点。在脑电图分类任务中，FNNs的模型表现优于基准模型并能成功进行分类。 |
| [^104] | [Dynamic Feature Engineering and model selection methods for temporal tabular datasets with regime changes.](http://arxiv.org/abs/2301.00790) | 本文提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。使用梯度提升决策树（GBDT）并结合dropout技术的模型具有良好的性能和泛化能力，而动态特征中和则是一种高效而不需要重新训练模型就可以应用于任何机器学习模型中的后处理技术。 |
| [^105] | [A survey of some recent developments in measures of association.](http://arxiv.org/abs/2211.04702) | 本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展，并提出了一个对标准Borel空间的直接推广。 |
| [^106] | [Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design.](http://arxiv.org/abs/2211.03942) | 本文提出了一种新的插值MVU机制，通过数值机制设计实现面向隐私的联邦学习压缩，具有更好的隐私效用权衡和更高的可扩展性，并在各种数据集上提供了通信高效的私有FL的SOTA结果。 |
| [^107] | [Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano.](http://arxiv.org/abs/2210.13662) | 本论文通过多重假设检验的方法对机器学习中的隐私泄露进行了分析，揭示了差分隐私对抗数据重建攻击的理论有效性，为相对较大的隐私参数ε值下的实践应用提供了理论支持。 |
| [^108] | [Symmetry Defense Against CNN Adversarial Perturbation Attacks.](http://arxiv.org/abs/2210.04087) | 本文提出了一种对称防御方法，通过翻转或水平翻转对称对抗样本来提高对抗性鲁棒性，同时使用子群对称性进行分类。 |
| [^109] | [RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow.](http://arxiv.org/abs/2209.14408) | RALACs是一种针对自动驾驶车辆中动作识别的新颖系统，通过交互编码和光流技术将动作识别应用于道路场景，并弥合了其与人类动作识别之间的差距。 |
| [^110] | [MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning.](http://arxiv.org/abs/2209.07902) | MetaMask是一种通过元学习学习的维度遮罩，用于对抗自监督学习中的维度冗余和干扰问题。 |
| [^111] | [Overlooked Implications of the Reconstruction Loss for VAE Disentanglement.](http://arxiv.org/abs/2202.13341) | VAE解纷结果的成因有待重新审视，研究发现数据与重建损失之间的关系是解耦的主要贡献者，标准的基准数据集根据典型的VAE重建损失与感知轴之间存在意外的相关性。 |
| [^112] | [Distributed Out-of-Memory NMF on CPU/GPU Architectures.](http://arxiv.org/abs/2202.09518) | 提出了一种分布式超内存非负矩阵分解(NMF)算法，可以在CPU/GPU架构上实现高效计算。算法通过稀疏和稠密矩阵操作以及批处理/平铺策略，有效地处理超内存问题，并利用CUDA流进行数据传输和异步计算。 |
| [^113] | [InfoNCE is variational inference in a recognition parameterised model.](http://arxiv.org/abs/2107.02495) | InfoNCE目标在识别参数化模型中等同于ELBO，在学习最优先验时变为互信息，并与自监督学习方法建立了联系。然而，实际的InfoNCE目标是对互信息的松散下界，以避免高度纠缠的表示。 |

# 详细

[^1]: 神经渐进网格

    Neural Progressive Meshes. (arXiv:2308.05741v1 [cs.CV])

    [http://arxiv.org/abs/2308.05741](http://arxiv.org/abs/2308.05741)

    本论文提出了一种神经渐进网格方法，通过共享的学习生成空间和逐渐传输额外的残余特征，实现了通过互联网传输大量的3D几何数据。

    

    最近，可以在手持设备上消费的3D内容的激增需要有效的工具来通过互联网传输大量的几何数据，例如3D网格。详细的高分辨率资源对于存储和传输带宽都是一个挑战，通常使用层次细节技术在适当的带宽预算下传输资源。对于这些方法来说，以渐进的方式传输数据，随着更多数据的加入，改进几何的质量尤其可取。我们的关键观点是，3D网格的几何细节通常在不同的形状之间都呈现出相似的局部模式，因此可以用共享的学习生成空间来有效表示这些细节。我们使用基于细分的编码器-解码器架构提前训练大量表面，在此空间中学习这些细节。我们进一步观察到，在中间细分级别之间可以逐渐传输额外的残余特征，从而实现了渐进式传输和改善几何。

    The recent proliferation of 3D content that can be consumed on hand-held devices necessitates efficient tools for transmitting large geometric data, e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a challenge to storage as well as transmission bandwidth, and level-of-detail techniques are often used to transmit an asset using an appropriate bandwidth budget. It is especially desirable for these methods to transmit data progressively, improving the quality of the geometry with more data. Our key insight is that the geometric details of 3D meshes often exhibit similar local patterns even across different shapes, and thus can be effectively represented with a shared learned generative space. We learn this space using a subdivision-based encoder-decoder architecture trained in advance on a large collection of surfaces. We further observe that additional residual features can be transmitted progressively between intermediate levels of subdivision that enable the
    
[^2]: 永远不给任何零梯度：学习非可微图形的局部替代损失

    Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics. (arXiv:2308.05739v1 [cs.CV])

    [http://arxiv.org/abs/2308.05739](http://arxiv.org/abs/2308.05739)

    本论文提出了ZeroGrads框架，通过学习非可微图形的局部替代损失函数来解决无梯度问题，并通过主动平滑和局部性约束优化替代损失的拟合，同时设计了高效的采样方案，实现了可行的运行时间和竞争力。

    

    基于梯度的优化在图形领域变得普遍，但不幸的是无法应用于具有未定义或零梯度的问题。为了解决这个问题，可以通过手动替换损失函数来使用类似极小值但可微的“替代损失”。我们提出的ZeroGrads框架通过学习目标函数的神经逼近，即替代损失，来自动化这个过程，从而可以通过任意黑盒图形流程进行微分。我们训练替代损失在目标函数的主动平滑版本上，并鼓励局部性，使替代损失的容量集中在当前训练阶段的关键内容上。拟合是在线执行的，与参数优化同时进行，自监督进行，无需预先计算数据或预训练模型。由于目标的采样是昂贵的（需要完整的渲染或模拟运行），我们设计了一个高效的采样方案，以实现可行的运行时间和竞争力。

    Gradient-based optimization is now ubiquitous across graphics, but unfortunately can not be applied to problems with undefined or zero gradients. To circumvent this issue, the loss function can be manually replaced by a "surrogate" that has similar minima but is differentiable. Our proposed framework, ZeroGrads, automates this process by learning a neural approximation of the objective function, the surrogate, which in turn can be used to differentiate through arbitrary black-box graphics pipelines. We train the surrogate on an actively smoothed version of the objective and encourage locality, focusing the surrogate's capacity on what matters at the current training episode. The fitting is performed online, alongside the parameter optimization, and self-supervised, without pre-computed data or pre-trained models. As sampling the objective is expensive (it requires a full rendering or simulator run), we devise an efficient sampling scheme that allows for tractable run-times and competit
    
[^3]: Follow Anything: 实时开放集检测、追踪和跟随

    Follow Anything: Open-set detection, tracking, and following in real-time. (arXiv:2308.05737v1 [cs.RO])

    [http://arxiv.org/abs/2308.05737](http://arxiv.org/abs/2308.05737)

    本文提出了一个名为“跟随任何物体”的机器人系统，可以实时检测、追踪和跟随任何物体，不受训练时概念限制，并且可以通过多模态查询进行应用。通过利用大规模预训练模型的视觉描述符，该系统能够检测、分割和跟踪物体，同时考虑遮挡和物体重新出现。

    

    在工业自动化、物流和仓储、医疗保健和安全等多种机器人应用中，追踪和跟随感兴趣的物体至关重要。在本文中，我们提出了一个机器人系统，能够实时检测、追踪和跟随任何物体。我们的方法被称为“跟随任何物体”（FAn），它是一个开放词汇和多模态模型 - 不受训练时的概念限制，并且可以使用文本、图像或点击查询来应用于推断时的新类别。通过利用来自大规模预训练模型（基础模型）的丰富视觉描述符，FAn可以通过将多模态查询（文本、图像、点击）与输入图像序列进行匹配来检测和分割物体。这些检测和分割的物体在图像帧之间进行跟踪，同时考虑到遮挡和物体重新出现。我们在一个实际的机器人系统上（微型飞行器）演示了FAn，并报告了其无缝跟随感兴趣物体的能力。

    Tracking and following objects of interest is critical to several robotics use cases, ranging from industrial automation to logistics and warehousing, to healthcare and security. In this paper, we present a robotic system to detect, track, and follow any object in real-time. Our approach, dubbed ``follow anything'' (FAn), is an open-vocabulary and multimodal model -- it is not restricted to concepts seen at training time and can be applied to novel classes at inference time using text, images, or click queries. Leveraging rich visual descriptors from large-scale pre-trained models (foundation models), FAn can detect and segment objects by matching multimodal queries (text, images, clicks) against an input image sequence. These detected and segmented objects are tracked across image frames, all while accounting for occlusion and object re-emergence. We demonstrate FAn on a real-world robotic system (a micro aerial vehicle) and report its ability to seamlessly follow the objects of inter
    
[^4]: PDE-Refiner: 利用神经PDE求解器实现准确的长时间预测

    PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers. (arXiv:2308.05732v1 [cs.LG])

    [http://arxiv.org/abs/2308.05732](http://arxiv.org/abs/2308.05732)

    PDE-Refiner 是一种利用多步细化过程准确建模所有频率分量的神经PDE求解器，能够在长时间范围内提供稳定、准确的预测。

    

    时间相关的偏微分方程在科学和工程中非常普遍。最近，由于传统解法的高计算成本，基于深度神经网络的替代方法引起了极大关注。这些神经PDE求解器的实用价值依赖于它们能够在长时间范围内提供准确、稳定的预测，这是一个相当困难的问题。在本研究中，我们对常见的时间展开策略进行了大规模分析，发现忽略非主导空间频率信息（通常与PDE解中的高频率相关）是限制稳定、准确展开性能的主要陷阱。基于这些洞察，我们借鉴了扩散模型的最新进展，引入了PDE-Refiner；这是一种新颖的模型类别，通过多步细化过程实现对所有频率分量的更准确建模。我们在具有挑战性的基准测试中验证了PDE-Refiner的性能。

    Time-dependent partial differential equations (PDEs) are ubiquitous in science and engineering. Recently, mostly due to the high computational cost of traditional solution techniques, deep neural network based surrogates have gained increased interest. The practical utility of such neural PDE solvers relies on their ability to provide accurate, stable predictions over long time horizons, which is a notoriously hard problem. In this work, we present a large-scale analysis of common temporal rollout strategies, identifying the neglect of non-dominant spatial frequency information, often associated with high frequencies in PDE solutions, as the primary pitfall limiting stable, accurate rollout performance. Based on these insights, we draw inspiration from recent advances in diffusion models to introduce PDE-Refiner; a novel model class that enables more accurate modeling of all frequency components via a multistep refinement process. We validate PDE-Refiner on challenging benchmarks of co
    
[^5]: 重新思考基于深度学习的自动驾驶系统中的预测和规划的整合：一项综述

    Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review. (arXiv:2308.05731v1 [cs.RO])

    [http://arxiv.org/abs/2308.05731](http://arxiv.org/abs/2308.05731)

    这项综述重新思考了基于深度学习的自动驾驶系统中预测和规划的整合问题，提出了将其作为相互依赖的联合步骤来提高安全性、效率性和舒适性的必要性。

    

    自动驾驶有可能彻底改变个人、公共和货运交通的方式。除了感知环境的巨大挑战外，即准确地使用可用的传感器数据感知环境，自动驾驶还包括规划一个安全、舒适和高效的运动轨迹。为了促进安全和进步，许多工作依赖于模块化的交通未来运动的预测。模块化的自动驾驶系统通常将预测和规划作为顺序的独立任务处理。虽然这考虑了周围交通对自车的影响，但它未能预测交通参与者对自车行为的反应。最近的研究表明，将预测和规划整合为相互依赖的联合步骤是实现安全、高效和舒适驾驶所必需的。虽然有各种模型实现了这种集成系统，但对不同原理的全面概述和理论理解仍然缺乏。

    Automated driving has the potential to revolutionize personal, public, and freight mobility. Besides the enormous challenge of perception, i.e. accurately perceiving the environment using available sensor data, automated driving comprises planning a safe, comfortable, and efficient motion trajectory. To promote safety and progress, many works rely on modules that predict the future motion of surrounding traffic. Modular automated driving systems commonly handle prediction and planning as sequential separate tasks. While this accounts for the influence of surrounding traffic on the ego-vehicle, it fails to anticipate the reactions of traffic participants to the ego-vehicle's behavior. Recent works suggest that integrating prediction and planning in an interdependent joint step is necessary to achieve safe, efficient, and comfortable driving. While various models implement such integrated systems, a comprehensive overview and theoretical understanding of different principles are lacking.
    
[^6]: EXPRESSO: 一项对离散表达性语音再合成进行基准测试和分析的研究

    EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis. (arXiv:2308.05725v1 [cs.CL])

    [http://arxiv.org/abs/2308.05725](http://arxiv.org/abs/2308.05725)

    本研究通过引入Expresso数据集，对离散表达性语音再合成进行了基准测试和分析，提出了一种不依赖文本的高质量语音合成方法，能够捕捉到难以转录的语音表达方面。

    

    最近的研究表明，不依赖于文本，而是基于在无监督学习中学习到的低比特率离散单元，可以重新合成高质量的语音，并且能够捕捉到难以转录的语音表达方面（韵律、声音风格、非语言语音化）。然而，由于大多数语音合成数据集都是朗读的，因此对 spontaneity 和 expressivity 的要求限制了这些方法的应用。本文引入了 Expresso，这是一个高质量的无文本语音合成数据集，包括朗读语音和26种自发表达风格的即兴对话。我们通过一个表达性重新合成基准测试来展示这个数据集的挑战和潜力，在这个任务中，需要以低比特率单元对输入进行编码，并在目标音色中重新合成，同时保持内容和风格。我们使用自动度量标准对不同的自监督离散合成方法进行了质量评估。

    Recent work has shown that it is possible to resynthesize high-quality speech based, not on text, but on low bitrate discrete units that have been learned in a self-supervised fashion and can therefore capture expressive aspects of speech that are hard to transcribe (prosody, voice styles, non-verbal vocalization). The adoption of these methods is still limited by the fact that most speech synthesis datasets are read, severely limiting spontaneity and expressivity. Here, we introduce Expresso, a high-quality expressive speech dataset for textless speech synthesis that includes both read speech and improvised dialogues rendered in 26 spontaneous expressive styles. We illustrate the challenges and potentials of this dataset with an expressive resynthesis benchmark where the task is to encode the input in low-bitrate units and resynthesize it in a target voice while preserving content and style. We evaluate resynthesis quality with automatic metrics for different self-supervised discrete 
    
[^7]: 通过动态激活函数优化前馈和卷积神经网络的性能

    Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions. (arXiv:2308.05724v1 [cs.LG])

    [http://arxiv.org/abs/2308.05724](http://arxiv.org/abs/2308.05724)

    该论文研究了使用动态激活函数优化前馈和卷积神经网络的性能。研究结果表明，在卷积神经网络和多层感知器中，复杂的分段线性激活函数比ReLU激活函数表现更好。

    

    近年来，深度学习训练算法在语音、文本、图像和视频等许多领域取得了巨大成功。人们提出了越来越深的网络层次结构，如具有约152层的ResNet结构。浅层卷积神经网络（CNN）仍然是一个活跃的研究领域，其中一些现象仍然没有得到解释。网络中使用的激活函数非常重要，因为它们为网络提供了非线性。ReLU是最常用的激活函数。我们在隐藏层使用了复杂的分段线性（PWL）激活函数。我们证明了这些PWL激活函数在我们的卷积神经网络和多层感知器中比ReLU激活函数的性能更好。我们还提供了在PyTorch中比较浅层和深度CNN的结果，以进一步证实我们的观点。

    Deep learning training training algorithms are a huge success in recent years in many fields including speech, text,image video etc. Deeper and deeper layers are proposed with huge success with resnet structures having around 152 layers. Shallow convolution neural networks(CNN's) are still an active research, where some phenomena are still unexplained. Activation functions used in the network are of utmost importance, as they provide non linearity to the networks. Relu's are the most commonly used activation function.We show a complex piece-wise linear(PWL) activation in the hidden layer. We show that these PWL activations work much better than relu activations in our networks for convolution neural networks and multilayer perceptrons. Result comparison in PyTorch for shallow and deep CNNs are given to further strengthen our case.
    
[^8]: 经典强化学习方法与深度强化学习方法在暖通空调控制中的比较

    A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control. (arXiv:2308.05711v1 [cs.LG])

    [http://arxiv.org/abs/2308.05711](http://arxiv.org/abs/2308.05711)

    该论文比较了经典强化学习方法和深度强化学习方法在暖通空调控制中的应用，并探讨了模型参数和奖励设置的实际考虑因素。研究结果为能源高效和成本有效的操作提供了洞察力。

    

    强化学习（RL）是优化暖通空调控制的一种有前景的方法。RL提供了改进系统性能、减少能源消耗和提高成本效益的框架。我们对两种流行的经典强化学习方法（Q-Learning和Deep-Q-Networks）在多个暖通空调环境中进行了基准测试，并探讨了模型超参数选择和奖励调节的实际考虑因素。研究结果为配置HVAC系统中的RL代理提供了洞察力，促进了能源高效和成本有效的运行。

    Reinforcement learning (RL) is a promising approach for optimizing HVAC control. RL offers a framework for improving system performance, reducing energy consumption, and enhancing cost efficiency. We benchmark two popular classical and deep RL methods (Q-Learning and Deep-Q-Networks) across multiple HVAC environments and explore the practical consideration of model hyper-parameter selection and reward tuning. The findings provide insight for configuring RL agents in HVAC systems, promoting energy-efficient and cost-effective operation.
    
[^9]: 隐形数据集，用于因果表示学习的新挑战性数据集

    Shadow Datasets, New challenging datasets for Causal Representation Learning. (arXiv:2308.05707v1 [cs.LG])

    [http://arxiv.org/abs/2308.05707](http://arxiv.org/abs/2308.05707)

    该论文提出了两个新的挑战性数据集，用于因果表示学习，并对现有数据集进行了修改，以更好地评估CRL性能。

    

    在表示学习中，发现语义因素之间的因果关系是一个新兴的话题。大多数因果表示学习（CRL）方法都是完全监督的，由于标记成本高昂而不切实际。为了解决这个限制，引入了弱监督的CRL方法。为了评估CRL性能，使用了四个现有数据集：Pendulum、Flow、CelebA（BEARD）和CelebA（SMILE）。然而，现有的CRL数据集仅限于具有少量生成因素的简单图形。因此，我们提出了两个新的数据集，其中包含更多种类的生成因素和更复杂的因果图。此外，在当前的真实数据集CelebA（BEARD）和CelebA（SMILE）中，最初提出的因果图与数据集分布不一致。因此，我们提出了对它们的修改。

    Discovering causal relations among semantic factors is an emergent topic in representation learning. Most causal representation learning (CRL) methods are fully supervised, which is impractical due to costly labeling. To resolve this restriction, weakly supervised CRL methods were introduced. To evaluate CRL performance, four existing datasets, Pendulum, Flow, CelebA(BEARD) and CelebA(SMILE), are utilized. However, existing CRL datasets are limited to simple graphs with few generative factors. Thus we propose two new datasets with a larger number of diverse generative factors and more sophisticated causal graphs. In addition, current real datasets, CelebA(BEARD) and CelebA(SMILE), the originally proposed causal graphs are not aligned with the dataset distributions. Thus, we propose modifications to them.
    
[^10]: 基于骨骼的人体动作识别面临的硬性无盒对抗攻击和骨骼-动作知情梯度

    Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient. (arXiv:2308.05681v1 [cs.CV])

    [http://arxiv.org/abs/2308.05681](http://arxiv.org/abs/2308.05681)

    本文针对基于骨骼的人体动作识别方法的脆弱性进行了研究，提出了一种新的硬性无盒对抗攻击方法，通过学习运动流形和定义骨骼-动作知情梯度来攻击模型，揭示了这种脆弱性的存在。

    

    最近，基于骨骼的人体活动识别方法已被证明容易受到对抗攻击。然而，这些攻击方法要求要么完全了解受害者（即白盒攻击），要么有访问训练数据（即基于转移的攻击），或者频繁查询模型（即黑盒攻击）。所有这些要求都非常限制性，引发了对脆弱性的质疑。在本文中，我们证明了脆弱性确实存在。为此，我们考虑了一个新的攻击任务：攻击者无法访问受害者模型或训练数据或标签，我们将其称为硬性无盒攻击。具体来说，我们首先学习一个运动流形，然后定义一个用于计算攻击的对抗损失函数，称为骨骼-动作知情梯度（SMI梯度）。我们的梯度包含运动动力学的信息，这与现有的基于梯度的攻击方法不同，后者假设损失梯度是通过计算而来的。

    Recently, methods for skeleton-based human activity recognition have been shown to be vulnerable to adversarial attacks. However, these attack methods require either the full knowledge of the victim (i.e. white-box attacks), access to training data (i.e. transfer-based attacks) or frequent model queries (i.e. black-box attacks). All their requirements are highly restrictive, raising the question of how detrimental the vulnerability is. In this paper, we show that the vulnerability indeed exists. To this end, we consider a new attack task: the attacker has no access to the victim model or the training data or labels, where we coin the term hard no-box attack. Specifically, we first learn a motion manifold where we define an adversarial loss to compute a new gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our gradient contains information of the motion dynamics, which is different from existing gradient-based attack methods that compute the loss gradient assuming 
    
[^11]: 通过多阶段检索找到已经被澄清的叙述：实现跨语言、跨数据集和零样本学习

    Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning. (arXiv:2308.05680v1 [cs.CL])

    [http://arxiv.org/abs/2308.05680](http://arxiv.org/abs/2308.05680)

    本研究通过创建新的数据集、评估多语言预训练Transformer模型以及提出多阶段框架来解决了跨语言澄清检索问题。

    

    检索已经被澄清的叙述的任务旨在检测已经经过事实核查的故事。成功检测到已被澄清的声明不仅减少了专业事实核查人员的手动努力，还可以有助于减缓虚假信息的传播。由于缺乏可用数据，这是一个研究不足的问题，特别是在考虑跨语言任务时，即在检查的在线帖子的语言与事实核查文章的语言不同的情况下进行检索。本文通过以下方式填补了这一空白：（i）创建了一个新颖的数据集，以允许对已被澄清的叙述进行跨语言检索的研究，使用推文作为对事实核查文章数据库的查询；（ii）展示了一个全面的实验，以评估经过微调和现成的多语言预训练Transformer模型在这个任务上的性能；（iii）提出了一个新颖的多阶段框架，将这个跨语言澄清检索问题划分为不同的阶段。

    The task of retrieving already debunked narratives aims to detect stories that have already been fact-checked. The successful detection of claims that have already been debunked not only reduces the manual efforts of professional fact-checkers but can also contribute to slowing the spread of misinformation. Mainly due to the lack of readily available data, this is an understudied problem, particularly when considering the cross-lingual task, i.e. the retrieval of fact-checking articles in a language different from the language of the online post being checked. This paper fills this gap by (i) creating a novel dataset to enable research on cross-lingual retrieval of already debunked narratives, using tweets as queries to a database of fact-checking articles; (ii) presenting an extensive experiment to benchmark fine-tuned and off-the-shelf multilingual pre-trained Transformer models for this task; and (iii) proposing a novel multistage framework that divides this cross-lingual debunk ret
    
[^12]: AST-MHSA: 利用多头自注意力进行代码摘要

    AST-MHSA : Code Summarization using Multi-Head Self-Attention. (arXiv:2308.05646v1 [cs.CL])

    [http://arxiv.org/abs/2308.05646](http://arxiv.org/abs/2308.05646)

    AST-MHSA模型通过多头自注意力从AST中提取重要的语义信息，并利用编码器-解码器架构生成源代码的简明自然语言描述。

    

    代码摘要旨在为源代码生成简明的自然语言描述。现有的方法采用基于Transformer的编码器-解码器架构，其中利用源代码的抽象语法树（AST）来编码结构信息。然而，AST比对应的源代码要长得多，现有方法通过直接将整个线性化的AST输入到编码器中来忽略这个大小约束。这种简化的方法使得从过长的输入序列中提取真正有价值的依赖关系变得具有挑战性，并且由于对AST中的所有节点应用自注意力，导致了显著的计算开销。为了有效而高效地解决这个问题，我们提出了一个模型AST-MHSA，利用多头注意力从AST中提取重要的语义信息。该模型由两个主要组件组成：一个编码器和一个解码器。编码器以代码的抽象语法树（AST）作为输入，并

    Code summarization aims to generate concise natural language descriptions for source code. The prevailing approaches adopt transformer-based encoder-decoder architectures, where the Abstract Syntax Tree (AST) of the source code is utilized for encoding structural information. However, ASTs are much longer than the corresponding source code, and existing methods ignore this size constraint by directly feeding the entire linearized AST into the encoders. This simplistic approach makes it challenging to extract truly valuable dependency relations from the overlong input sequence and leads to significant computational overhead due to self-attention applied to all nodes in the AST.  To address this issue effectively and efficiently, we present a model, AST-MHSA that uses multi-head attention to extract the important semantic information from the AST. The model consists of two main components: an encoder and a decoder. The encoder takes as input the abstract syntax tree (AST) of the code and
    
[^13]: IIHT: 基于图像到指示器层次Transformer的医学报告生成

    IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer. (arXiv:2308.05633v1 [cs.CV])

    [http://arxiv.org/abs/2308.05633](http://arxiv.org/abs/2308.05633)

    IIHT是一种用于医学报告生成的基于图像到指示器层次Transformer的框架，可以提取医学图像的特征并生成与疾病相关的指示器。

    

    自动化医学报告生成在医疗分析中变得越来越重要。它可以产生计算机辅助诊断描述，从而极大地减轻医生的工作。受到神经机器翻译和图像描述的巨大成功的启发，已经提出了各种深度学习方法用于医学报告生成。然而，由于医学数据的固有特性，包括数据不平衡、报告序列的长度和相关性，现有方法生成的报告可能在语言流畅性上表现出色，但缺乏足够的临床准确性。在这项工作中，我们提出了一种基于图像到指示器层次Transformer的医学报告生成框架（IIHT）。它包括三个模块，即分类器模块、指示器扩展模块和生成器模块。分类器模块首先从输入的医学图像中提取图像特征，并生成与其对应状态的与疾病相关的指示器。

    Automated medical report generation has become increasingly important in medical analysis. It can produce computer-aided diagnosis descriptions and thus significantly alleviate the doctors' work. Inspired by the huge success of neural machine translation and image captioning, various deep learning methods have been proposed for medical report generation. However, due to the inherent properties of medical data, including data imbalance and the length and correlation between report sequences, the generated reports by existing methods may exhibit linguistic fluency but lack adequate clinical accuracy. In this work, we propose an image-to-indicator hierarchical transformer (IIHT) framework for medical report generation. It consists of three modules, i.e., a classifier module, an indicator expansion module and a generator module. The classifier module first extracts image features from the input medical images and produces disease-related indicators with their corresponding states. The dise
    
[^14]: ReLU和基于加法的门控循环神经网络

    ReLU and Addition-based Gated RNN. (arXiv:2308.05629v1 [cs.LG])

    [http://arxiv.org/abs/2308.05629](http://arxiv.org/abs/2308.05629)

    这种新型的门控机制将循环神经网络中传统门的乘法和Sigmoid函数替换为加法和ReLU激活函数，以降低计算成本，并在受限硬件上实现更高效的执行或更大型的模型。通过实验证明，该机制能够捕捉到序列数据中的长期依赖关系。

    

    我们将传统循环门的乘法和Sigmoid函数替换为加法和ReLU激活。该机制旨在以较低的计算成本来维护序列处理的长期记忆，从而在受限硬件上实现更高效的执行或更大型的模型。具有LSTM和GRU等门控机制的循环神经网络在学习序列数据方面取得了广泛成功，因为它们能够捕捉长期依赖关系。传统上，基于当前输入和先前状态历史的更新分别与动态权重相乘，并组合计算出下一个状态。然而，乘法在某些硬件架构或替代算术系统（如同态加密）中可能具有较高的计算开销。实验证明，这种新型门控机制可以对标准的合成序列学习任务捕捉到长期依赖关系。

    We replace the multiplication and sigmoid function of the conventional recurrent gate with addition and ReLU activation. This mechanism is designed to maintain long-term memory for sequence processing but at a reduced computational cost, thereby opening up for more efficient execution or larger models on restricted hardware. Recurrent Neural Networks (RNNs) with gating mechanisms such as LSTM and GRU have been widely successful in learning from sequential data due to their ability to capture long-term dependencies. Conventionally, the update based on current inputs and the previous state history is each multiplied with dynamic weights and combined to compute the next state. However, multiplication can be computationally expensive, especially for certain hardware architectures or alternative arithmetic systems such as homomorphic encryption. It is demonstrated that the novel gating mechanism can capture long-term dependencies for a standard synthetic sequence learning task while signifi
    
[^15]: 所有情况下的标准化梯度

    Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])

    [http://arxiv.org/abs/2308.05621](http://arxiv.org/abs/2308.05621)

    这篇论文提出了一种利用标准化梯度适应 H\"{o}lder 光滑性的方法，并引入了局部 H\"{o}lder 光滑性的新概念。

    

    在这篇简短的论文中，我展示了如何以黑盒的方式利用标准化梯度来适应 H\"{o}lder 光滑性。此外，这个界限将依赖于局部 H\"{o}lder 光滑性的一种新概念。主要思想直接来自于 Levy [2017]。

    In this short note, I show how to adapt to H\"{o}lder smoothness using normalized gradients in a black-box way. Moreover, the bound will depend on a novel notion of local H\"{o}lder smoothness. The main idea directly comes from Levy [2017].
    
[^16]: 使用基于排名的兼容性更新临床风险分层模型：评估和优化临床医生-模型团队性能的方法

    Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])

    [http://arxiv.org/abs/2308.05619](http://arxiv.org/abs/2308.05619)

    提出了一种基于排名的兼容性度量和一种新的损失函数来更新临床机器学习模型，以解决更新模型引入的兼容性问题。在使用MIMIC数据的病死率风险分层案例研究中，该方法相对于现有技术能产生更兼容的模型并保持判别性能。

    

    随着数据的变化或新数据的出现，更新临床机器学习模型可能是必要的，以保持或提高其性能。然而，更新模型可能会引入兼容性问题，当更新后的模型的行为与用户的期望不一致时，会导致用户-模型团队表现不佳。现有的兼容性度量依赖于模型的决策阈值，限制了它们在基于估计风险的排名生成模型的应用能力。为了解决这个限制，我们提出了一种新颖的基于排名的兼容性度量，$C^R$，以及一个旨在优化判别性能的新损失函数，同时鼓励良好的兼容性。在利用MIMIC数据的病死率风险分层的案例研究中，我们的方法相对于现有的模型选择技术，产生了更兼容的模型，同时保持了判别性能，$C^R$提高了0.019（$95\%$置信区间：...

    As data shift or new data become available, updating clinical machine learning models may be necessary to maintain or improve performance over time. However, updating a model can introduce compatibility issues when the behavior of the updated model does not align with user expectations, resulting in poor user-model team performance. Existing compatibility measures depend on model decision thresholds, limiting their applicability in settings where models are used to generate rankings based on estimated risk. To address this limitation, we propose a novel rank-based compatibility measure, $C^R$, and a new loss function that aims to optimize discriminative performance while encouraging good compatibility. Applied to a case study in mortality risk stratification leveraging data from MIMIC, our approach yields more compatible models while maintaining discriminative performance compared to existing model selection techniques, with an increase in $C^R$ of $0.019$ ($95\%$ confidence interval: 
    
[^17]: 多图空时图卷积网络用于交通流预测

    Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction. (arXiv:2308.05601v1 [cs.LG])

    [http://arxiv.org/abs/2308.05601](http://arxiv.org/abs/2308.05601)

    本文提出了一种基于多图空时图卷积网络的方法，用于预测高速公路每日交通流量。通过数据归一化策略处理数据不平衡问题，并利用图卷积网络捕捉空时特征。同时，还使用了气象和日历特征。

    

    城市之间的高速公路交通对于城市生活至关重要。作为智能交通系统中的关键功能之一，交通评估在现今起到了重要作用，而每日交通流量预测在整个网络范围的收费站仍面临挑战。一方面，实际中各个位置之间的数据不平衡状况加剧了预测的性能。另一方面，复杂的相关空时因素无法全面地应用于长期持续时间。本文提出了一种基于空时深度学习的高速公路每日交通流预测方法。在我们的方法中，采用数据归一化策略来处理数据不平衡，由于网络范围的收费站交通流的长尾分布。然后，基于图卷积网络，我们构建了具有不同语义的网络来捕捉空时特征。除此之外，我们的模型还使用了气象和日历特征。

    Inter-city highway transportation is significant for urban life. As one of the key functions in intelligent transportation system (ITS), traffic evaluation always plays significant role nowadays, and daily traffic flow prediction still faces challenges at network-wide toll stations. On the one hand, the data imbalance in practice among various locations deteriorates the performance of prediction. On the other hand, complex correlative spatio-temporal factors cannot be comprehensively employed in long-term duration. In this paper, a prediction method is proposed for daily traffic flow in highway domain through spatio-temporal deep learning. In our method, data normalization strategy is used to deal with data imbalance, due to long-tail distribution of traffic flow at network-wide toll stations. And then, based on graph convolutional network, we construct networks in distinct semantics to capture spatio-temporal features. Beside that, meteorology and calendar features are used by our mod
    
[^18]: NUPES：通过指数搜索进行非均匀后训练量化

    NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search. (arXiv:2308.05600v1 [cs.LG])

    [http://arxiv.org/abs/2308.05600](http://arxiv.org/abs/2308.05600)

    NUPES提出一种改进的非均匀量化方法，用于解决深度学习模型量化中的局限性，并通过利用自同构来保持标量m。

    

    深度神经网络（DNN）的部署由于其昂贵的计算需求而局限于较大的硬件设备。随着大型语言模型（LLM）的出现，这一挑战最近已经达到了另一个层面。为了减少内存占用和延迟，一种有希望的技术是量化。它通过将浮点表示转换为低位宽定点表示来实现，通常假设均匀映射到正则网格上。然而，这个过程，在文献中被称为均匀量化，可能不适合，因为大多数DNN的权重和激活遵循钟形分布。在LLM中更糟糕的是，其权重分布被认为具有大量、高影响力的异常值。在这项工作中，我们提出了对解决深度学习模型量化限制最常用方法的改进，即非均匀量化。NUPES利用自同构保持标量m

    Deep neural network (DNN) deployment has been confined to larger hardware devices due to their expensive computational requirements. This challenge has recently reached another scale with the emergence of large language models (LLMs). In order to reduce both their memory footprint and latency, a promising technique is quantization. It consists in converting floating point representations to low bit-width fixed point representations, usually by assuming a uniform mapping onto a regular grid. This process, referred to in the literature as uniform quantization, may however be ill-suited as most DNN weights and activations follow a bell-shaped distribution. This is even worse on LLMs whose weight distributions are known to exhibit large, high impact, outlier values. In this work, we propose an improvement over the most commonly adopted way to tackle this limitation in deep learning models quantization, namely, non-uniform quantization. NUPES leverages automorphisms to preserve the scalar m
    
[^19]: 对抗XGBoost攻击的对称防御

    Symmetry Defense Against XGBoost Adversarial Perturbation Attacks. (arXiv:2308.05575v1 [cs.LG])

    [http://arxiv.org/abs/2308.05575](http://arxiv.org/abs/2308.05575)

    本研究研究了对称性是否可以作为防御XGBoost对抗性攻击的一种方法，发现对称性可以使模型对对称对抗样本的分类恢复到正确的分类。

    

    我们研究了是否可以利用对称性来防御基于树的集成分类器，例如梯度提升决策树(GBDT)，抵御对抗性扰动攻击。这个想法基于最近对卷积神经网络分类器(CNNs)使用对称性缺失来进行对称防御的研究。CNNs之所以缺乏对称性是因为它们可以对待对称样本（比如水平翻转的图像）进行不同于原始样本的分类。CNNs缺乏对称性也意味着CNNs可以对对称的对抗样本进行与对抗样本不同的分类。利用CNNs的缺乏对称性，最近的CNN对称防御已经显示对称对抗样本的分类恢复到了正确的样本分类。为了将相同的对称防御应用到GBDTs上，我们研究了GBDT的不变性，并首次证明GBDTs在对称性方面也缺乏不变性。

    We examine whether symmetry can be used to defend tree-based ensemble classifiers such as gradient-boosting decision trees (GBDTs) against adversarial perturbation attacks. The idea is based on a recent symmetry defense for convolutional neural network classifiers (CNNs) that utilizes CNNs' lack of invariance with respect to symmetries. CNNs lack invariance because they can classify a symmetric sample, such as a horizontally flipped image, differently from the original sample. CNNs' lack of invariance also means that CNNs can classify symmetric adversarial samples differently from the incorrect classification of adversarial samples. Using CNNs' lack of invariance, the recent CNN symmetry defense has shown that the classification of symmetric adversarial samples reverts to the correct sample classification. In order to apply the same symmetry defense to GBDTs, we examine GBDT invariance and are the first to show that GBDTs also lack invariance with respect to symmetries. We apply and ev
    
[^20]: AutoGluon-TimeSeries: 自动机器学习用于概率时间序列预测的开源库

    AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting. (arXiv:2308.05566v1 [cs.LG])

    [http://arxiv.org/abs/2308.05566](http://arxiv.org/abs/2308.05566)

    AutoGluon-TimeSeries是一个开源的AutoML库，专注于概率时间序列预测。它提供了简单易用、准确的点预测和分位数预测，并在短时间内提供高准确性。通过结合传统的统计模型、机器学习预测方法和集成技术，AutoGluon-TimeSeries展现出了强大的实证性能，在多个基准数据集上表现优异。

    

    我们介绍了AutoGluon-TimeSeries，这是一个用于概率时间序列预测的开源AutoML库。AutoGluon-TimeSeries专注于易用性和稳健性，用户只需使用3行Python代码即可生成准确的点预测和分位数预测。基于AutoGluon的设计哲学，AutoGluon-TimeSeries利用多样化的预测模型集合，在短时间内提供高准确性。AutoGluon-TimeSeries结合了传统的统计模型、基于机器学习的预测方法和集成技术。在对29个基准数据集的评估中，AutoGluon-TimeSeries展现了强大的实证性能，在点预测和分位数预测准确性方面优于一系列预测方法，并且通常甚至超越先前方法的最佳组合。

    We introduce AutoGluon-TimeSeries - an open-source AutoML library for probabilistic time series forecasting. Focused on ease of use and robustness, AutoGluon-TimeSeries enables users to generate accurate point and quantile forecasts with just 3 lines of Python code. Built on the design philosophy of AutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecasting models to deliver high accuracy within a short training time. AutoGluon-TimeSeries combines both conventional statistical models, machine-learning based forecasting approaches, and ensembling techniques. In our evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstrates strong empirical performance, outperforming a range of forecasting methods in terms of both point and quantile forecast accuracy, and often even improving upon the best-in-hindsight combination of prior methods.
    
[^21]: 大规模偏t乌鸦勾结的高效变分推理及其在股票收益率中的应用

    Efficient Variational Inference for Large Skew-t Copulas with Application to Intraday Equity Returns. (arXiv:2308.05564v1 [econ.EM])

    [http://arxiv.org/abs/2308.05564](http://arxiv.org/abs/2308.05564)

    本研究提出一种快速而准确的贝叶斯变分推理方法，用于估计大规模偏t乌鸦因子勾结模型。该方法能够捕捉到金融数据中的不对称和极端尾部相关性，以及股票对之间的异质性非对称依赖。

    

    大规模偏t乌鸦因子勾结模型对金融数据建模具有吸引力，因为它们允许不对称和极端的尾部相关性。我们展示了Azzalini和Capitanio（2003）所隐含的乌鸦勾结在成对非对称依赖性方面比两种流行的乌鸦勾结更高。在高维情况下，对该乌鸦勾结的估计具有挑战性，我们提出了一种快速而准确的贝叶斯变分推理方法来解决这个问题。该方法使用条件高斯生成表示法定义了一个可以准确近似的附加后验。使用快速随机梯度上升算法来解决变分优化。这种新的方法被用来估计2017年至2021年间93个美国股票的股票收益率的勾结模型。除了成对相关性的变化外，该勾结还捕捉到了股票对之间的非对称依赖的大量异质性。

    Large skew-t factor copula models are attractive for the modeling of financial data because they allow for asymmetric and extreme tail dependence. We show that the copula implicit in the skew-t distribution of Azzalini and Capitanio (2003) allows for a higher level of pairwise asymmetric dependence than two popular alternative skew-t copulas. Estimation of this copula in high dimensions is challenging, and we propose a fast and accurate Bayesian variational inference (VI) approach to do so. The method uses a conditionally Gaussian generative representation of the skew-t distribution to define an augmented posterior that can be approximated accurately. A fast stochastic gradient ascent algorithm is used to solve the variational optimization. The new methodology is used to estimate copula models for intraday returns from 2017 to 2021 on 93 U.S. equities. The copula captures substantial heterogeneity in asymmetric dependence over equity pairs, in addition to the variability in pairwise co
    
[^22]: 临界点++：一种用于鲁棒分类、对抗性防御和可解释AI的敏捷点云重要性度量方法

    Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI. (arXiv:2308.05525v1 [cs.CV])

    [http://arxiv.org/abs/2308.05525](http://arxiv.org/abs/2308.05525)

    本文研究了三维点云的临界点与非分布样本之间的相互作用，并将临界点的概念推广为重要性度量方法。通过仅基于非重要点进行分类网络训练，可以提高鲁棒性，同时在干净数据集上会有些性能损失。建议使用标准化熵选择非临界点集合的自适应阈值。这种重要性度量方法计算速度极快，可以应用于可解释AI、离群值去除、不确定性估计、鲁棒分类和对抗性防御等多种应用。

    

    在真实世界的安全需求应用中，准确且快速地处理非分布样本是至关重要的。本文首先研究了三维点云的临界点与非分布样本之间的相互作用。我们的研究发现，常见的数据损坏和离群点往往会被解释为临界点。我们将临界点的概念推广为重要性度量。我们证明，仅基于非重要点的分类网络训练，可以大大提高鲁棒性，而在干净数据集上会稍微损失一些性能。我们观察到，标准化熵对于数据损坏分析非常有信息量。建议基于标准化熵选择非临界点集合的自适应阈值。我们提出的重要性度量计算极其快速。我们展示了它可以用于多种应用，例如可解释AI(XAI)，离群值去除，不确定性估计，鲁棒分类和对抗性防御。

    The ability to cope accurately and fast with Out-Of-Distribution (OOD) samples is crucial in real-world safety demanding applications. In this work we first study the interplay between critical points of 3D point clouds and OOD samples. Our findings are that common corruptions and outliers are often interpreted as critical points. We generalize the notion of critical points into importance measures. We show that training a classification network based only on less important points dramatically improves robustness, at a cost of minor performance loss on the clean set. We observe that normalized entropy is highly informative for corruption analysis. An adaptive threshold based on normalized entropy is suggested for selecting the set of uncritical points. Our proposed importance measure is extremely fast to compute. We show it can be used for a variety of applications, such as Explainable AI (XAI), Outlier Removal, Uncertainty Estimation, Robust Classification and Adversarial Defense. We 
    
[^23]: 模型很重要：单步反合成对合成规划的影响

    Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning. (arXiv:2308.05522v1 [cs.AI])

    [http://arxiv.org/abs/2308.05522](http://arxiv.org/abs/2308.05522)

    本研究通过将多个单步反合成模型应用于多步合成规划，发现单步性能较好并不一定能找到潜在的反应路径，强调了将单步模型与合成规划相结合的重要性。

    

    反合成是将化学化合物逐步递归地分解为分子前体，直到找到一组商业上可用的分子为止，以提供合成路线。它的两个主要研究方向，即单步反合成预测和多步合成规划，它们的目标是模拟化学反应逻辑和找到正确的反应顺序，二者密切相关。然而，这种联系在当前的研究中没有得到体现。在这项工作中，我们通过将多个单步反合成模型应用于多步合成规划并使用公开和专有的反应数据进行分析，将这两个主要研究方向结合起来。我们发现单步性能较好与找到潜在的反应路径成功之间存在断裂，这表明将来必须在合成规划中评估单步模型。此外，我们还展示了常用的单步反合成模型在合成规划中的应用效果。

    Retrosynthesis consists of breaking down a chemical compound recursively step-by-step into molecular precursors until a set of commercially available molecules is found with the goal to provide a synthesis route. Its two primary research directions, single-step retrosynthesis prediction, which models the chemical reaction logic, and multi-step synthesis planning, which tries to find the correct sequence of reactions, are inherently intertwined. Still, this connection is not reflected in contemporary research. In this work, we combine these two major research directions by applying multiple single-step retrosynthesis models within multi-step synthesis planning and analyzing their impact using public and proprietary reaction data. We find a disconnection between high single-step performance and potential route-finding success, suggesting that single-step models must be evaluated within synthesis planning in the future. Furthermore, we show that the commonly used single-step retrosynthesi
    
[^24]: 对ReLU深度神经网络的最佳表达能力及其在用科尔莫哥洛夫叠加定理进行逼近中的应用的研究

    On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem. (arXiv:2308.05509v1 [cs.LG])

    [http://arxiv.org/abs/2308.05509](http://arxiv.org/abs/2308.05509)

    本文研究了ReLU DNNs的最佳表达能力及其在逼近中的应用。我们证明了ReLU DNNs可以表示任何在$[0,1]$上由$O(N^2L)$个线性分段构成的连续函数，并且这种表示方式是最优的。此外，通过科尔莫哥洛夫叠加定理，我们实现了在高维空间中处理连续函数时ReLU DNNs的提升逼近速率。

    

    本文致力于研究ReLU深度神经网络（DNNs）的最佳表达能力及其在通过科尔莫哥洛夫叠加定理进行逼近的应用。我们首先构造性地证明了任何在$[0,1]$上由$O(N^2L)$个线性分段构成的连续函数都可以由具有$L$个隐藏层和每层$N$个神经元的ReLU DNNs表示。随后，我们通过研究ReLU DNNs的破碎容量，证明了这种构造在DNNs的参数计数方面是最优的。此外，通过引用科尔莫哥洛夫叠加定理，我们在处理高维空间中的连续函数时，实现了ReLU DNNs任意宽度和深度的提升逼近速率。

    This paper is devoted to studying the optimal expressive power of ReLU deep neural networks (DNNs) and its application in approximation via the Kolmogorov Superposition Theorem. We first constructively prove that any continuous piecewise linear functions on $[0,1]$, comprising $O(N^2L)$ segments, can be represented by ReLU DNNs with $L$ hidden layers and $N$ neurons per layer. Subsequently, we demonstrate that this construction is optimal regarding the parameter count of the DNNs, achieved through investigating the shattering capacity of ReLU DNNs. Moreover, by invoking the Kolmogorov Superposition Theorem, we achieve an enhanced approximation rate for ReLU DNNs of arbitrary width and depth when dealing with continuous functions in high-dimensional spaces.
    
[^25]: 机器人抓取中的稀疏奖励和稀疏交互下的优质多样性：应用于机器人学中的抓取任务

    Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics. (arXiv:2308.05483v1 [cs.RO])

    [http://arxiv.org/abs/2308.05483](http://arxiv.org/abs/2308.05483)

    这项研究针对机器人抓取任务中的奖励稀疏性、行为稀疏性和行为空间错位等挑战，探讨了优质多样性方法解决该问题的能力。通过在多个实验领域中进行实验，结果表明...

    

    优质多样性（Quality-Diversity，QD）方法旨在生成一组多样性和高性能的解决方案来解决给定问题。在进化机器人学中最初开发，大多数QD研究都是在有限的一组领域中进行的，主要应用于运动，其中适应度和行为信号是密集的。抓取是机器人操作中的关键任务。尽管许多研究社区的努力，但该任务尚未得到解决。抓取在QD文献中面临着前所未有的挑战：奖励稀疏性，行为稀疏性和行为空间错位。本研究探讨了QD如何解决抓取问题。在10个抓取领域上进行了15种不同方法的实验，对应于2种不同的机器人夹持器设置和5种标准物体。还提出了一个评估框架，以区分算法的评估与其内部组件的评估，以便进行公平比较。得到的结果表明：

    Quality-Diversity (QD) methods are algorithms that aim to generate a set of diverse and high-performing solutions to a given problem. Originally developed for evolutionary robotics, most QD studies are conducted on a limited set of domains - mainly applied to locomotion, where the fitness and the behavior signal are dense. Grasping is a crucial task for manipulation in robotics. Despite the efforts of many research communities, this task is yet to be solved. Grasping cumulates unprecedented challenges in QD literature: it suffers from reward sparsity, behavioral sparsity, and behavior space misalignment. The present work studies how QD can address grasping. Experiments have been conducted on 15 different methods on 10 grasping domains, corresponding to 2 different robot-gripper setups and 5 standard objects. An evaluation framework that distinguishes the evaluation of an algorithm from its internal components has also been proposed for a fair comparison. The obtained results show that 
    
[^26]: LLM变成DBA

    LLM As DBA. (arXiv:2308.05481v1 [cs.DB])

    [http://arxiv.org/abs/2308.05481](http://arxiv.org/abs/2308.05481)

    LLM变成DBA，提供数据库维护的诊断和优化建议，通过从文本来源中获取经验和多个LLMs的协作诊断。

    

    数据库管理员（DBA）在管理、维护和优化数据库系统以确保数据可用性、性能和可靠性方面起着至关重要的作用。然而，对于DBA来说，管理大量数据库实例（例如，云数据库上的数百万个实例）是困难和繁琐的。最近，大型语言模型（LLMs）已经显示出了理解有价值文件并生成合理答案的巨大潜力。因此，我们提出了D-Bot，一种基于LLM的数据库管理员，它可以持续从文本来源中获取数据库维护经验，并为目标数据库提供合理、有理、及时的诊断和优化建议。本文介绍了一个革命性的以LLM为中心的数据库维护框架，包括（i）从文档和工具中检测数据库维护知识，（ii）根本原因分析的思维树，和（iii）多个LLM之间的协作诊断。我们进行了初步实验。

    Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experiment
    
[^27]: 探索机器学习和基于Transformer的方法用于欺诈性文本分类：一项比较分析

    Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis. (arXiv:2308.05476v1 [cs.CL])

    [http://arxiv.org/abs/2308.05476](http://arxiv.org/abs/2308.05476)

    本研究通过比较分析机器学习和基于Transformer的方法在欺诈性文本分类中的效果，揭示了它们的优势和局限性。

    

    欺诈性文本分类是自然语言处理中的一项关键任务，旨在识别欺诈或欺骗性内容。本研究对机器学习和基于Transformer的方法进行了比较分析，用于欺诈性文本分类。我们研究了传统机器学习算法和最先进的Transformer模型（如BERT，XLNET，DistilBERT和RoBERTa）在检测欺诈性文本方面的有效性。我们使用一个带标签的数据集，其中包含欺诈性和非欺诈性文本，用于训练和评估目的。通过广泛的实验，我们比较了不同方法的性能指标，包括准确率，精确率，召回率和F1得分。本研究的结果揭示了机器学习和基于Transformer的方法在欺诈性文本分类中的优势和局限性，使研究人员和实践者能够在处理欺诈内容时做出明智的决策。

    Deceptive text classification is a critical task in natural language processing that aims to identify deceptive or fraudulent content. This study presents a comparative analysis of machine learning and transformer-based approaches for deceptive text classification. We investigate the effectiveness of traditional machine learning algorithms and state-of-the-art transformer models, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptive text. A labeled dataset consisting of deceptive and non-deceptive texts is used for training and evaluation purposes. Through extensive experimentation, we compare the performance metrics, including accuracy, precision, recall, and F1 score, of the different approaches. The results of this study shed light on the strengths and limitations of machine learning and transformer-based methods for deceptive text classification, enabling researchers and practitioners to make informed decisions when dealing with deceptive content
    
[^28]: 针对非平稳低秩MDP的可证明高效算法

    Provably Efficient Algorithm for Nonstationary Low-Rank MDPs. (arXiv:2308.05471v1 [cs.LG])

    [http://arxiv.org/abs/2308.05471](http://arxiv.org/abs/2308.05471)

    本文提出了针对非平稳低秩MDP的可证明高效算法，通过研究在非平稳环境下的强化学习，捕捉了深度RL中未知表示的特性，并给出了平均动态次最优间隙的上界。

    

    强化学习（RL）在改变环境模型下，通过非平稳的马尔可夫决策过程（MDPs）模拟了许多现实世界的应用，并因此引起了相当大的兴趣。然而，文献中关于非平稳MDPs的理论研究主要集中在表格和线性（混合）MDPs上，这些方法无法捕捉深度RL中未知表示的特性。在本文中，我们首次努力研究了在易耗型低秩MDPs下的非平稳RL，其中转移核和奖励都可能随时间变化，低秩模型除了线性状态嵌入函数外还包含未知表示。我们首先提出了一种参数相关的策略优化算法PORTAL，然后将PORTAL改进为自适应参数无关版本的Ada-PORTAL，该算法能够自适应地调整超参数，而不需要任何对非平稳性的先验知识。对于这两种算法，我们给出了平均动态次最优间隙的上界。

    Reinforcement learning (RL) under changing environment models many real-world applications via nonstationary Markov Decision Processes (MDPs), and hence gains considerable interest. However, theoretical studies on nonstationary MDPs in the literature have mainly focused on tabular and linear (mixture) MDPs, which do not capture the nature of unknown representation in deep RL. In this paper, we make the first effort to investigate nonstationary RL under episodic low-rank MDPs, where both transition kernels and rewards may vary over time, and the low-rank model contains unknown representation in addition to the linear state embedding function. We first propose a parameter-dependent policy optimization algorithm called PORTAL, and further improve PORTAL to its parameter-free version of Ada-PORTAL, which is able to tune its hyper-parameters adaptively without any prior knowledge of nonstationarity. For both algorithms, we provide upper bounds on the average dynamic suboptimality gap, which
    
[^29]: $\mathcal{G}^2Pxy$: 带有未知代理的图节点生成式开放集分类

    $\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns. (arXiv:2308.05463v1 [cs.LG])

    [http://arxiv.org/abs/2308.05463](http://arxiv.org/abs/2308.05463)

    $\mathcal{G}^2Pxy$是一种使用生成式方法的图节点开放集分类模型，通过在训练和验证过程中没有未知类别的信息，利用两种类型的代理未知节点进行分类。

    

    节点分类是在图中预测未标记节点的标签的任务。基于图神经网络的最先进方法在训练期间所有标签都可用时可以实现出色的性能。但在现实生活中，模型通常应用于具有新类别的数据，这可能导致大规模的误分类，从而显著降低性能。因此，开放集分类方法的开发对于确定给定样本是否属于已知类别至关重要。现有的开放集节点分类方法通常使用传导学习，利用真实未见类别节点的部分或全部特征来帮助开放集分类。在本文中，我们提出了一种新颖的生成式开放集节点分类方法，即$\mathcal{G}^2Pxy$，它遵循更严格的归纳学习设置，在训练和验证过程中没有未知类别的信息可用。两种类型的代理未知节点，即类间未知代理和外部未知代理，将被引入该方法中。

    Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e. $\mathcal{G}^2Pxy$, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and externa
    
[^30]: 《因果：模型、推理与推断》第二版的一位预测员的评述

    A Forecaster's Review of Judea Pearl's Causality: Models, Reasoning and Inference, Second Edition, 2009. (arXiv:2308.05451v1 [stat.ME])

    [http://arxiv.org/abs/2308.05451](http://arxiv.org/abs/2308.05451)

    本文评述了朱迪亚·珀尔的《因果：模型、推理与推断》第二版，重点介绍了其中的更新内容以及一种易于跟随的预测场景下的因果推断策略，并讨论了在时间序列预测中应用因果推断所面临的潜在益处和挑战。

    

    鉴于朱迪亚·珀尔原著《因果》的巨大普及和成功，本评述介绍了2009年第二版更新的主要内容，并展示了一种易于跟随的预测场景下的因果推断策略。此外，还讨论了在建模反事实、估计不确定性以及融入先前知识以在不同预测场景下估计因果效应时，使用时间序列预测进行因果推断可能带来的一些潜在益处和挑战。

    With the big popularity and success of Judea Pearl's original causality book, this review covers the main topics updated in the second edition in 2009 and illustrates an easy-to-follow causal inference strategy in a forecast scenario. It further discusses some potential benefits and challenges for causal inference with time series forecasting when modeling the counterfactuals, estimating the uncertainty and incorporating prior knowledge to estimate causal effects in different forecasting scenarios.
    
[^31]: 医学领域可解释的人工智能应用：一项系统综述

    Explainable AI applications in the Medical Domain: a systematic review. (arXiv:2308.05411v1 [cs.AI])

    [http://arxiv.org/abs/2308.05411](http://arxiv.org/abs/2308.05411)

    该论文通过文献综述探讨了医学决策支持中可解释的人工智能解决方案的最新发展，结果发现通用模型的XAI技术被广泛采用，深度学习模型被更多使用，解释性被应用于提高信任，但医生的参与仍较少报道。

    

    医学人工智能在医学影像、患者护理和其他领域取得了显著进展。虽然这些应用在回顾性研究中取得了成功，但实际上很少有应用。医学人工智能领域面临着建立用户信任、遵守法规、合理使用数据等各种挑战。可解释的人工智能（XAI）旨在使人类理解人工智能并信任其结果。本文基于最近几年发表的198篇文章，对医学决策支持的XAI解决方案的最新发展进行了文献综述。相关文章的系统综合产生了几个发现：（1）这些解决方案主要采用了通用模型的XAI技术，（2）相比其他类型的机器学习模型，深度学习模型被更多地使用，（3）解释性被应用于提高信任，但很少有工作报道了医生的参与。

    Artificial Intelligence in Medicine has made significant progress with emerging applications in medical imaging, patient care, and other areas. While these applications have proven successful in retrospective studies, very few of them were applied in practice.The field of Medical AI faces various challenges, in terms of building user trust, complying with regulations, using data ethically.Explainable AI (XAI) aims to enable humans understand AI and trust its results. This paper presents a literature review on the recent developments of XAI solutions for medical decision support, based on a representative sample of 198 articles published in recent years. The systematic synthesis of the relevant articles resulted in several findings. (1) model-agnostic XAI techniques were mostly employed in these solutions, (2) deep learning models are utilized more than other types of machine learning models, (3) explainability was applied to promote trust, but very few works reported the physicians par
    
[^32]: 多视角融合学习用于农作物分类的比较评估

    A Comparative Assessment of Multi-view fusion learning for Crop Classification. (arXiv:2308.05407v1 [cs.CV])

    [http://arxiv.org/abs/2308.05407](http://arxiv.org/abs/2308.05407)

    本研究比较评估了多视角融合学习在农作物分类中的效果，提出的融合方法优于单一视角和先前方法，根据测试区域选择最佳融合方法。

    

    随着遥感数据源数量和多样性的快速增加，多视角学习建模越来越重要。然而，由于遥感数据的分辨率、幅度和噪声差异，这是一个复杂的任务。通常的方法是在输入级别进行融合，但其他更高级的融合策略可能会超越传统方法。本研究评估了在CropHarvest数据集中用于农作物分类的不同融合策略。本文提出的融合方法优于基于单个视角和先前的融合方法的模型。我们没有找到一个单一的融合方法一直优于其他方法。相反，我们对三个不同数据集的多视角融合方法进行了比较，并表明，在测试区域不同的方法获得最佳性能。尽管如此，我们提出了一个初步的选择融合方法的标准。

    With a rapidly increasing amount and diversity of remote sensing (RS) data sources, there is a strong need for multi-view learning modeling. This is a complex task when considering the differences in resolution, magnitude, and noise of RS data. The typical approach for merging multiple RS sources has been input-level fusion, but other - more advanced - fusion strategies may outperform this traditional approach. This work assesses different fusion strategies for crop classification in the CropHarvest dataset. The fusion methods proposed in this work outperform models based on individual views and previous fusion methods. We do not find one single fusion method that consistently outperforms all other approaches. Instead, we present a comparison of multi-view fusion methods for three different datasets and show that, depending on the test region, different methods obtain the best performance. Despite this, we suggest a preliminary criterion for the selection of fusion methods.
    
[^33]: 时尚电子商务中的产品评论图片排序

    Product Review Image Ranking for Fashion E-commerce. (arXiv:2308.05390v1 [cs.CV])

    [http://arxiv.org/abs/2308.05390](http://arxiv.org/abs/2308.05390)

    本文针对时尚电子商务平台上的产品评论图片排序问题，提出了一个简单而有效的训练过程，能够将最相关的图片显示在前面，对用户的在线购物选择和行为产生影响。

    

    在一个时尚电子商务平台上，顾客无法亲自检查产品，因此能够看到其他顾客对产品的文字和图片评论在做购买决策时非常重要。随着用户生成内容的增加，客户图像的数量也相应增加，因此将最相关的图片显示在前面对于用户的在线购物选择和行为可能产生影响。本文提出了一个简单而有效的训练过程，用于排名顾客图像。我们创建了一个数据集，包括印度主要时尚电子商务公司Myntra的工作室帖子和高度参与（顶/踩）的用户生成内容图像，并对上述数据集的图像使用了选择的扭曲技术，使它们的质量达到与低质量的UGC图像相当。

    In a fashion e-commerce platform where customers can't physically examine the products on their own, being able to see other customers' text and image reviews of the product is critical while making purchase decisions. Given the high reliance on these reviews, over the years we have observed customers proactively sharing their reviews. With an increase in the coverage of User Generated Content (UGC), there has been a corresponding increase in the number of customer images. It is thus imperative to display the most relevant images on top as it may influence users' online shopping choices and behavior. In this paper, we propose a simple yet effective training procedure for ranking customer images. We created a dataset consisting of Myntra (A Major Indian Fashion e-commerce company) studio posts and highly engaged (upvotes/downvotes) UGC images as our starting point and used selected distortion techniques on the images of the above dataset to bring their quality at par with those of bad U
    
[^34]: 可信的LLMs：评估大型语言模型对齐的调查和指南

    Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. (arXiv:2308.05374v1 [cs.AI])

    [http://arxiv.org/abs/2308.05374](http://arxiv.org/abs/2308.05374)

    本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。

    

    在将大型语言模型（LLMs）应用于现实世界应用之前，确保对齐是一项关键任务。然而，从业者面临的主要挑战是缺乏明确的指导来评估LLMs的输出是否符合社会规范、价值观和法规。本文提出了一个全面的调查，涵盖了评估LLM可信度时必须考虑的关键维度。调查涵盖了LLM可信度的七个主要类别：可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性。每个主要类别进一步细分为若干子类别，共计29个子类别。

    Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset 
    
[^35]: 基于梯度的网格优化的灵活等值面提取

    Flexible Isosurface Extraction for Gradient-Based Mesh Optimization. (arXiv:2308.05371v1 [cs.GR])

    [http://arxiv.org/abs/2308.05371](http://arxiv.org/abs/2308.05371)

    本文提出了一种名为FlexiCubes的灵活等值面表示方法，用于基于梯度的网格优化，允许对提取的网格几何和连通性进行灵活调整，从而高质量地保留特征。

    

    本文考虑了基于梯度的网格优化，通过将其表示为标量场的等值面来迭代地优化三维表面网格，这在摄影测量、生成建模和反向物理等应用中越来越常见。现有的实现方式是将经典的等值面提取算法（如Marching Cubes或Dual Contouring）进行调整；然而，在优化环境中，这些技术缺乏表示高质量保留特征的网格的自由度，或者会遭受数值不稳定性的问题。我们介绍了FlexiCubes，一种专为优化未知网格而设计的等值面表示方法，以便于几何、视觉甚至物理目标。我们的主要创新是引入额外的精心选择的参数到表示方法中，从而允许对提取的网格几何和连通性进行本地灵活调整。

    This work considers gradient-based mesh optimization, where we iteratively optimize for a 3D surface mesh by representing it as the isosurface of a scalar field, an increasingly common paradigm in applications including photogrammetry, generative modeling, and inverse physics. Existing implementations adapt classic isosurface extraction algorithms like Marching Cubes or Dual Contouring; these techniques were designed to extract meshes from fixed, known fields, and in the optimization setting they lack the degrees of freedom to represent high-quality feature-preserving meshes, or suffer from numerical instabilities. We introduce FlexiCubes, an isosurface representation specifically designed for optimizing an unknown mesh with respect to geometric, visual, or even physical objectives. Our main insight is to introduce additional carefully-chosen parameters into the representation, which allow local flexible adjustments to the extracted mesh geometry and connectivity. These parameters are 
    
[^36]: 机器学习辅助的卷积神经网络推理系统的计算机架构设计

    Machine Learning aided Computer Architecture Design for CNN Inferencing Systems. (arXiv:2308.05364v1 [cs.AR])

    [http://arxiv.org/abs/2308.05364](http://arxiv.org/abs/2308.05364)

    本研究提出了一种机器学习辅助的计算机架构设计方法，用于加快卷积神经网络推理系统的设计过程。通过快速而准确地预测CNN在推理过程中的功耗和性能，帮助计算机架构师在早期阶段进行估计，从而减少开发周期。

    

    高效和及时计算机器学习（ML）算法对于自动驾驶、物联网（IoT）和边缘计算等新兴技术至关重要。这些系统中使用的主要ML算法之一是卷积神经网络（CNN），它需要高计算资源。为了满足设计约束，人们使用ML加速器如GPGPUs。然而，选择最合适的加速器通常涉及设计空间探索（DSE），这是一个耗时且需要大量手工努力的过程。我们的工作提出了一种加快DSE过程的方法，通过识别最适合CNN推理系统的GPGPU。我们开发了一种快速准确的技术，用于推理过程中的CNN功耗和性能预测，MAPE分别为5.03%和5.94%。我们的方法使计算机架构师能够在开发的早期估计功耗和性能，从而减少开发周期。

    Efficient and timely calculations of Machine Learning (ML) algorithms are essential for emerging technologies like autonomous driving, the Internet of Things (IoT), and edge computing. One of the primary ML algorithms used in such systems is Convolutional Neural Networks (CNNs), which demand high computational resources. This requirement has led to the use of ML accelerators like GPGPUs to meet design constraints. However, selecting the most suitable accelerator involves Design Space Exploration (DSE), a process that is usually time-consuming and requires significant manual effort. Our work presents approaches to expedite the DSE process by identifying the most appropriate GPGPU for CNN inferencing systems. We have developed a quick and precise technique for forecasting the power and performance of CNNs during inference, with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer architects to estimate power and performance in the early stages of development, reducing 
    
[^37]: FINER:利用特征归因增强先进的分类器以促进安全分析

    FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis. (arXiv:2308.05362v1 [cs.CR])

    [http://arxiv.org/abs/2308.05362](http://arxiv.org/abs/2308.05362)

    本文提出了FINER，这是第一个能够生成高准确性和高可理解性解释的风险检测分类器框架。

    

    深度学习分类器在各种风险检测应用中取得了最先进的性能。它们探索丰富的语义表示，并且应该自动发现风险行为。然而，由于缺乏透明度，行为语义无法传达给下游安全专家，以减少他们在安全分析中的繁重工作量。虽然特征归因方法可用于解释深度学习，但基础分类器仍然不知道哪些行为是可疑的，并且生成的解释不能适应下游任务，导致解释的准确性和可理解性较差。在本文中，我们提出了FINER，这是第一个为风险检测分类器生成高准确性和高可理解性解释的框架。高层次的思路是汇集模型开发者、特征归因设计师和安全专家的解释工作。为了提高准确性，我们使用解释引导的多任务学习来对分类器进行微调。

    Deep learning classifiers achieve state-of-the-art performance in various risk detection applications. They explore rich semantic representations and are supposed to automatically discover risk behaviors. However, due to the lack of transparency, the behavioral semantics cannot be conveyed to downstream security experts to reduce their heavy workload in security analysis. Although feature attribution (FA) methods can be used to explain deep learning, the underlying classifier is still blind to what behavior is suspicious, and the generated explanation cannot adapt to downstream tasks, incurring poor explanation fidelity and intelligibility. In this paper, we propose FINER, the first framework for risk detection classifiers to generate high-fidelity and high-intelligibility explanations. The high-level idea is to gather explanation efforts from model developer, FA designer, and security experts. To improve fidelity, we fine-tune the classifier with an explanation-guided multi-task learn
    
[^38]: 通过多类偏好连接分类器在社交网络上提前检测伪造账号

    Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers. (arXiv:2308.05353v1 [cs.SI])

    [http://arxiv.org/abs/2308.05353](http://arxiv.org/abs/2308.05353)

    本文介绍了一种名为PreAttacK的新算法，用于提前检测社交网络中的伪造账号。该算法利用了伪造账号在加入网络后的初始朋友请求行为，通过多类扩展偏好连接模型实现了近乎最优的解决方案。

    

    本文介绍了一种名为PreAttacK的新算法，用于检测社交网络中的伪造账号。最近，一些算法在这个问题上取得了很高的准确率。然而，它们所依赖的信息是关于伪造账号的友谊关系或其与他人分享的内容，而这正是我们想要防止的。PreAttacK与这些方法有着显著的不同。我们首次提供了关于新的伪造（和真实）账号在加入主要网络（Facebook）后尝试请求朋友的详细分布分析。我们表明，即使在新账号没有交朋友或分享内容之前，这些初始朋友请求行为会引发社交网络增长的经典偏好连接模型的自然多类扩展。我们利用这个模型推导出一个新的算法PreAttacK。我们证明，在相关问题实例中，PreAttacK能够近似最优地解决问题。

    In this paper, we describe a new algorithm called Preferential Attachment k-class Classifier (PreAttacK) for detecting fake accounts in a social network. Recently, several algorithms have obtained high accuracy on this problem. However, they have done so by relying on information about fake accounts' friendships or the content they share with others--the very things we seek to prevent.  PreAttacK represents a significant departure from these approaches. We provide some of the first detailed distributional analyses of how new fake (and real) accounts first attempt to request friends after joining a major network (Facebook). We show that even before a new account has made friends or shared content, these initial friend request behaviors evoke a natural multi-class extension of the canonical Preferential Attachment model of social network growth.  We use this model to derive a new algorithm, PreAttacK. We prove that in relevant problem instances, PreAttacK near-optimally approximates the 
    
[^39]: RTLLM：用于大规模语言模型设计RTL生成的开源基准测试

    RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model. (arXiv:2308.05345v1 [cs.LG])

    [http://arxiv.org/abs/2308.05345](http://arxiv.org/abs/2308.05345)

    RTLLM是一个用自然语言指令生成设计RTL的开源基准测试，旨在解决现有工作中目标设计简单且规模小的问题，并提供对基于LLM的解决方案进行设计质量的定量评估。

    

    受到像ChatGPT这样的大型语言模型（LLMs）的最新成功的启发，研究人员开始探索采用LLMs进行敏捷硬件设计，例如基于自然语言指令生成设计RTL。然而，在现有的工作中，目标设计都相对简单且规模较小，并由作者自己提出，这使得在不同的LLMs解决方案之间进行公平比较具有挑战性。此外，许多先前的工作只关注设计的正确性，而没有评估生成的设计RTL的设计质量。在这项工作中，我们提出了一个名为RTLLM的开源基准测试，用于使用自然语言指令生成设计RTL。为了系统评估自动生成的设计RTL，我们总结了三个渐进目标，即语法目标、功能目标和设计质量目标。该基准测试可以自动提供对任何给定基于LLM的解决方案的定量评估。

    Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisin
    
[^40]: OpenProteinSet：大规模结构生物学训练数据

    OpenProteinSet: Training data for structural biology at scale. (arXiv:2308.05326v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.05326](http://arxiv.org/abs/2308.05326)

    OpenProteinSet是一个包含超过1600万个MSAs和蛋白质结构预测的开源数据集，解决了蛋白质机器学习中数据不足的问题。

    

    蛋白质的多序列比对（MSAs）编码了丰富的生物信息，并且在蛋白质设计和蛋白质结构预测等生物信息学方法中已经成为核心工具多年。最近的突破，如AlphaFold2直接使用transformers对大量原始MSAs进行关注，再次肯定了它们的重要性。然而，MSAs的生成非常计算密集，并且尚未向研究界提供与AlphaFold2训练所用数据相当的数据集，制约了蛋白质机器学习的进展。为了解决这个问题，我们推出了OpenProteinSet，这是一个开源的包含超过1600万个MSAs、蛋白数据银行中的结构同源物和AlphaFold2蛋白质结构预测的语料库。我们先前已经成功地使用OpenProteinSet重新训练了AlphaFold2，并证明了其实用性。我们期望OpenProteinSet能够作为训练和验证数据广泛用于不同的任务。

    Multiple sequence alignments (MSAs) of proteins encode rich biological information and have been workhorses in bioinformatic methods for tasks like protein design and protein structure prediction for decades. Recent breakthroughs like AlphaFold2 that use transformers to attend directly over large quantities of raw MSAs have reaffirmed their importance. Generation of MSAs is highly computationally intensive, however, and no datasets comparable to those used to train AlphaFold2 have been made available to the research community, hindering progress in machine learning for proteins. To remedy this problem, we introduce OpenProteinSet, an open-source corpus of more than 16 million MSAs, associated structural homologs from the Protein Data Bank, and AlphaFold2 protein structure predictions. We have previously demonstrated the utility of OpenProteinSet by successfully retraining AlphaFold2 on it. We expect OpenProteinSet to be broadly useful as training and validation data for 1) diverse task
    
[^41]: 图聚类的同类性增强结构学习

    Homophily-enhanced Structure Learning for Graph Clustering. (arXiv:2308.05309v1 [cs.LG])

    [http://arxiv.org/abs/2308.05309](http://arxiv.org/abs/2308.05309)

    提出了一种名为HoLe的方法，通过在图结构中增强同类性可以显著改善图聚类任务的性能。

    

    图聚类是图分析中的一个基本任务，在利用图神经网络（GNNs）方面的最新进展已经取得了令人印象深刻的成果。尽管现有的基于GNN的图聚类方法取得了成功，但它们往往忽视了图结构的质量，这是由于现实世界图的稀疏性和多样性所固有的，从而导致了次优的性能。图结构学习可以通过添加缺失的连接和删除错误的连接来优化输入图。然而，以往的图结构学习工作主要集中在有监督的设置上，并且由于缺乏真实标签，不能直接应用于我们的特定聚类任务。为了弥补这个差距，我们提出了一种新颖的方法，称为同类性增强结构学习图聚类（HoLe）。我们的动机源于观察到，微妙地增强图结构中的同类性程度可以显著提升GNNs的性能。

    Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \textbf{ho}mophily-enhanced structure \textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve G
    
[^42]: 从CNN到Transformer: 医疗图像分割模型综述

    From CNN to Transformer: A Review of Medical Image Segmentation Models. (arXiv:2308.05305v1 [eess.IV])

    [http://arxiv.org/abs/2308.05305](http://arxiv.org/abs/2308.05305)

    该论文综述了医疗图像分割模型的发展，重点介绍了U-Net及其变体以及基于Transformer的模型如TransUNet的应用。论文通过理论分析和定量评估，总结了这些模型的特点和性能，并讨论了医学图像分割领域的挑战和未来趋势。

    

    医疗图像分割是医学图像分析的重要步骤，特别是作为高效疾病诊断和治疗的关键前提。使用深度学习进行图像分割已成为一种普遍趋势。目前广泛采用的方法是U-Net及其变体。此外，随着预训练模型在自然语言处理任务中取得显著成功，基于Transformer的模型，如TransUNet，在多个医学图像分割数据集上实现了令人满意的性能。在本文中，我们对近年来最具代表性的四种医学图像分割模型进行了调研。我们从理论上分析了这些模型的特点，并在两个基准数据集（结核病胸片和卵巢肿瘤）上定量评估了其性能。最后，我们讨论了医学图像分割面临的主要挑战和未来趋势。我们的工作可以帮助相关领域的研究人员快速建立医学图像分割模型。

    Medical image segmentation is an important step in medical image analysis, especially as a crucial prerequisite for efficient disease diagnosis and treatment. The use of deep learning for image segmentation has become a prevalent trend. The widely adopted approach currently is U-Net and its variants. Additionally, with the remarkable success of pre-trained models in natural language processing tasks, transformer-based models like TransUNet have achieved desirable performance on multiple medical image segmentation datasets. In this paper, we conduct a survey of the most representative four medical image segmentation models in recent years. We theoretically analyze the characteristics of these models and quantitatively evaluate their performance on two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors). Finally, we discuss the main challenges and future trends in medical image segmentation. Our work can assist researchers in the related field to quickly establish med
    
[^43]: 具有随机梯度噪声独立学习错误的拜占庭鲁棒分散随机优化

    Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error. (arXiv:2308.05292v1 [cs.LG])

    [http://arxiv.org/abs/2308.05292](http://arxiv.org/abs/2308.05292)

    本文研究了在分散网络中拜占庭鲁棒的随机优化问题，提出了两种方差减少方法来消除随机梯度噪声的负面效应，并取得了具有线性收敛速度和小的学习错误的结果。

    

    本文研究了在分散网络中拜占庭鲁棒的随机优化，其中每个代理定期与其邻居进行通信以交换本地模型，然后通过随机梯度下降（SGD）更新自己的本地模型。这种方法的性能受到在优化过程中进行敌对行为的未知数量的拜占庭代理的影响。据我们所知，目前尚没有现有的工作能够同时实现线性收敛速度和小的学习错误。我们观察到学习错误在很大程度上取决于内在的随机梯度噪声。受到这一观察的启发，我们引入了两种方差减少方法，随机平均梯度算法（SAGA）和无循环随机方差减少梯度（LSVRG），用于拜占庭鲁棒的分散随机优化，以消除随机梯度噪声的负面效应。最终得到的两种方法是BRAVO-SAGA和BRAVO-LS。

    This paper studies Byzantine-robust stochastic optimization over a decentralized network, where every agent periodically communicates with its neighbors to exchange local models, and then updates its own local model by stochastic gradient descent (SGD). The performance of such a method is affected by an unknown number of Byzantine agents, which conduct adversarially during the optimization process. To the best of our knowledge, there is no existing work that simultaneously achieves a linear convergence speed and a small learning error. We observe that the learning error is largely dependent on the intrinsic stochastic gradient noise. Motivated by this observation, we introduce two variance reduction methods, stochastic average gradient algorithm (SAGA) and loopless stochastic variance-reduced gradient (LSVRG), to Byzantine-robust decentralized stochastic optimization for eliminating the negative effect of the stochastic gradient noise. The two resulting methods, BRAVO-SAGA and BRAVO-LS
    
[^44]: 通过社交媒体数据和易感-感染-康复（SIR）模型研究灾害响应：以2020年西部美国火灾季为案例研究

    Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season. (arXiv:2308.05281v1 [cs.SI])

    [http://arxiv.org/abs/2308.05281](http://arxiv.org/abs/2308.05281)

    该研究通过社交媒体数据和SIR模型研究了2020年西部美国火灾季的灾害响应。研究发现Twitter用户主要关注健康影响、损失和撤离三个主题，并使用SIR理论探索了这些主题在Twitter上的传播规模和速度。

    

    有效的灾害响应对受影响的社区至关重要。应急人员和决策者在灾害期间在了解社区所面临问题的可靠和及时的指标上将受益于社交媒体提供的丰富数据来源。社交媒体可以反映公众关注和需求，为决策者提供有价值的洞见，以了解不断演变的情况并优化资源配置。我们使用双向编码器表示转换（BERT）主题建模对Twitter数据进行主题聚类。然后，我们进行了时间-空间分析，研究了这些主题在2020年美国西部火灾季期间在不同地区的分布情况。我们的结果显示，Twitter用户主要关注三个主题：“健康影响”，“损失”，“撤离”。我们使用易感-感染-康复（SIR）理论来探索主题在Twitter上的传播规模和速度。结果清晰地显示了主题传播的情况。

    Effective disaster response is critical for affected communities. Responders and decision-makers would benefit from reliable, timely measures of the issues impacting their communities during a disaster, and social media offers a potentially rich data source. Social media can reflect public concerns and demands during a disaster, offering valuable insights for decision-makers to understand evolving situations and optimize resource allocation. We used Bidirectional Encoder Representations from Transformers (BERT) topic modeling to cluster topics from Twitter data. Then, we conducted a temporal-spatial analysis to examine the distribution of these topics across different regions during the 2020 western U.S. wildfire season. Our results show that Twitter users mainly focused on three topics:"health impact," "damage," and "evacuation." We used the Susceptible-Infected-Recovered (SIR) theory to explore the magnitude and velocity of topic diffusion on Twitter. The results displayed a clear re
    
[^45]: 跨异质图少样本学习

    Cross-heterogeneity Graph Few-shot Learning. (arXiv:2308.05275v1 [cs.LG])

    [http://arxiv.org/abs/2308.05275](http://arxiv.org/abs/2308.05275)

    这项研究提出了一种跨异质图少样本学习模型，通过提取元模式和使用多视图异质图神经网络来捕获异质信息并学习跨异质图的元模式。

    

    近年来，异质图少样本学习被提出来解决异质图中标签稀疏问题，异质图包含多种类型的节点和边。现有的方法通过将从源异质图中丰富标记类提取的泛化知识转移到目标异质图中的少标记类来取得良好性能。然而，这些方法仅考虑源和目标异质图共享一组固定的节点/边类型的情况，忽略了更一般的跨异质图场景，即每个异质图可以有一个不同的、非固定的节点/边类型集合。为此，我们专注于未被探索的跨异质图场景，并提出了一种新的跨异质图少样本学习模型，即CGFL。在CGFL中，我们首先提取元模式来捕获异质信息，并提出了一种多视图异质图神经网络（MHGN）来学习跨异质图的元模式。然后，我们提出了一个范围子..

    In recent years, heterogeneous graph few-shot learning has been proposed to address the label sparsity issue in heterogeneous graphs (HGs), which contain various types of nodes and edges. The existing methods have achieved good performance by transferring generalized knowledge extracted from rich-labeled classes in source HG(s) to few-labeled classes in a target HG. However, these methods only consider the single-heterogeneity scenario where the source and target HGs share a fixed set of node/edge types, ignoring the more general scenario of cross-heterogeneity, where each HG can have a different and non-fixed set of node/edge types. To this end, we focus on the unexplored cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns to capture heterogeneous information and propose a multi-view heterogeneous graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose a sco
    
[^46]: 基于数据驱动的自治系统图生成器

    Data-driven Intra-Autonomous Systems Graph Generator. (arXiv:2308.05254v1 [cs.NI])

    [http://arxiv.org/abs/2308.05254](http://arxiv.org/abs/2308.05254)

    本文介绍了一种基于深度学习的新型合成图生成器DGGI，用于准确地模拟互联网中自治系统内的图的属性，如中心性、聚类性、同质性以及节点度量。该生成器的性能优于现有的互联网拓扑生成器。

    

    本文介绍了一种基于深度学习的新型合成图生成器DGGI，用于表示互联网中自治系统（AS）内的图。同时，还提出了一种来自Internet Topology Data Kit（ITDK）项目的真实自治系统图的大规模数据集，称为Internet Graphs（IGraphs）。创建IGraphs采用了Filtered Recurrent Multi-level（FRM）算法进行社区提取。实验证明，DGGI生成的合成图可以准确地再现中心性、聚类性、同质性和节点度量的特性。DGGI生成器优于现有的互联网拓扑生成器。平均而言，对于同质性、中介度、聚类性和节点度量，DGGI在最大均匀差异度（MMD）指标上分别提高了84.4%、95.1%、97.9%和94.7%。

    This paper introduces a novel deep-learning based generator of synthetic graphs that represent intra-Autonomous System (AS) in the Internet, named Deep-generative graphs for the Internet (DGGI). It also presents a novel massive dataset of real intra-AS graphs extracted from the project Internet Topology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs, the Filtered Recurrent Multi-level (FRM) algorithm for community extraction was developed. It is shown that DGGI creates synthetic graphs which accurately reproduce the properties of centrality, clustering, assortativity, and node degree. The DGGI generator overperforms existing Internet topology generators. On average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%, 95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and node degree, respectively.
    
[^47]: AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS).

    AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS). (arXiv:2308.05239v1 [cs.SE])

    [http://arxiv.org/abs/2308.05239](http://arxiv.org/abs/2308.05239)

    这篇论文提出了适应现代应用和组织要求的AI-enabled软件和系统架构框架，重点关注机器学习驱动的智能物联网系统(CPS)。作者提出了用于评估和基准化ML-enabled CPS的优点标准。

    

    在文献中提出了几种软件、系统和企业的架构框架。它们识别了各种利益相关者，并定义了架构的观点和视图，以框架和解决利益相关者的关注点。然而，在现有的架构框架中，尚未包括与数据科学和机器学习相关的利益相关者，如数据科学家和数据工程师。因此，它们未能解决响应数据科学社区关注的架构视点和视图。本文通过建立适用于现代应用和组织的架构框架来填补这一空白，其中机器学习工件普遍存在且至关重要。具体而言，我们专注于机器学习驱动的智能物联网系统（CPS），并提出了两组适应CPS高效开发和性能评估的优点标准，即用于评估和基准化机器学习驱动CPS的标准，

    Several architecture frameworks for software, systems, and enterprises have been proposed in the literature. They identified various stakeholders and defined architecture viewpoints and views to frame and address stakeholder concerns. However, the stakeholders with data science and Machine Learning (ML) related concerns, such as data scientists and data engineers, are yet to be included in existing architecture frameworks. Therefore, they failed to address the architecture viewpoints and views responsive to the concerns of the data science community. In this paper, we address this gap by establishing the architecture frameworks adapted to meet the requirements of modern applications and organizations where ML artifacts are both prevalent and crucial. In particular, we focus on ML-enabled Cyber-Physical Systems (CPSs) and propose two sets of merit criteria for their efficient development and performance assessment, namely the criteria for evaluating and benchmarking ML-enabled CPSs, and
    
[^48]: 金融欺诈检测：量子机器学习模型的比较研究

    Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models. (arXiv:2308.05237v1 [quant-ph])

    [http://arxiv.org/abs/2308.05237](http://arxiv.org/abs/2308.05237)

    该研究通过比较研究四种量子机器学习模型，证明了量子支持向量分类器模型在金融欺诈检测方面具有最高性能，并为量子机器学习在欺诈检测领域的未来发展提供了重要见解。

    

    在本研究中，针对金融欺诈检测进行了四种量子机器学习（QML）模型的比较研究。我们证明了量子支持向量分类器模型的性能最高，欺诈和非欺诈类别的F1分数均为0.98。其他模型如变分量子分类器、估计量子神经网络和采样器量子神经网络展示了有希望的结果，推动了QML在金融应用中的潜力。虽然它们存在一定的限制，但所得到的洞察为未来的增强和优化策略铺平了道路。然而，挑战存在，包括需要更高效的量子算法和更大更复杂的数据集。该文章提供了克服当前限制的解决方案，并为量子机器学习在欺诈检测领域提供了新的见解，对其未来发展有重要影响。

    In this research, a comparative study of four Quantum Machine Learning (QML) models was conducted for fraud detection in finance. We proved that the Quantum Support Vector Classifier model achieved the highest performance, with F1 scores of 0.98 for fraud and non-fraud classes. Other models like the Variational Quantum Classifier, Estimator Quantum Neural Network (QNN), and Sampler QNN demonstrate promising results, propelling the potential of QML classification for financial applications. While they exhibit certain limitations, the insights attained pave the way for future enhancements and optimisation strategies. However, challenges exist, including the need for more efficient Quantum algorithms and larger and more complex datasets. The article provides solutions to overcome current limitations and contributes new insights to the field of Quantum Machine Learning in fraud detection, with important implications for its future development.
    
[^49]: 空间门控多层感知机用于土地利用和土地覆盖绘图

    Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping. (arXiv:2308.05235v1 [cs.CV])

    [http://arxiv.org/abs/2308.05235](http://arxiv.org/abs/2308.05235)

    本文提出了一种称为SGU-MLP的学习算法，它利用MLPs和空间门控单元（SGUs）来精确地进行土地利用和土地覆盖绘图。实验结果显示，SGU-MLP算法在多个基于CNN和CNN-ViT模型上具有明显的优势。

    

    卷积神经网络（CNN）被广泛应用于特征的分层提取。通过使用自注意机制，视觉变压器（ViTs）最近在全局背景信息建模方面取得了优于CNN的成果。然而，要发挥它们在图像分类方面的优势，ViTs需要大量的训练数据。当可用的训练数据有限时，目前的先进多层感知机（MLPs）可以作为深度CNN和ViTs的可行替代方案。本文中，我们开发了SGU-MLP，这是一种有效利用MLPs和空间门控单元（SGUs）进行精确土地利用土地覆盖（LULC）绘图的学习算法。结果表明，所开发的SGU-MLP分类算法在多个基于CNN和CNN-ViT模型（包括HybridSN、ResNet、iFormer、EfficientFormer和CoAtNet）上优势明显。所提出的SGU-MLP算法通过在美国休斯顿进行的三个实验中进行了测试。

    Convolutional Neural Networks (CNNs) are models that are utilized extensively for the hierarchical extraction of features. Vision transformers (ViTs), through the use of a self-attention mechanism, have recently achieved superior modeling of global contextual information compared to CNNs. However, to realize their image classification strength, ViTs require substantial training datasets. Where the available training data are limited, current advanced multi-layer perceptrons (MLPs) can provide viable alternatives to both deep CNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithm that effectively uses both MLPs and spatial gating units (SGUs) for precise land use land cover (LULC) mapping. Results illustrated the superiority of the developed SGU-MLP classification algorithm over several CNN and CNN-ViT-based models, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. The proposed SGU-MLP algorithm was tested through three experiments in Houston, USA, 
    
[^50]: 利用边缘和云端技术实现自动驾驶中的实时物体检测

    Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving. (arXiv:2308.05234v1 [cs.CV])

    [http://arxiv.org/abs/2308.05234](http://arxiv.org/abs/2308.05234)

    本论文研究利用边缘和云端技术实现自动驾驶中的实时物体检测。通过创建合成数据集，评估不同的外部化策略，并使用真实硬件和网络模拟进行比较，找到了权衡预测质量和端到端延迟的最佳方法。

    

    环境感知是自动驾驶的关键因素，因为感知模块接收到的信息会影响核心驾驶决策。实时感知在自动驾驶中的一大挑战在于在检测质量和延迟之间找到最佳权衡。对于自动驾驶中的实时感知，必须考虑到计算和功耗方面的主要限制。较大的物体检测模型往往能产生最佳结果，但在运行时也更慢。由于最准确的检测器无法在本地实时运行，我们研究将计算外部化到边缘和云平台的可能性，这些平台资源受限较少。我们创建了一个合成数据集来训练物体检测模型，并评估不同的外部化策略。我们使用真实硬件和网络模拟来比较不同的预测质量和端到端延迟之间的权衡。由于通过网络传送原始帧的实现存在困难和挑战，我们引入了压缩技术来降低数据传输量。

    Environmental perception is a key element of autonomous driving because the information received from the perception module influences core driving decisions. An outstanding challenge in real-time perception for autonomous driving lies in finding the best trade-off between detection quality and latency. Major constraints on both computation and power have to be taken into account for real-time perception in autonomous vehicles. Larger object detection models tend to produce the best results, but are also slower at runtime. Since the most accurate detectors cannot run in real-time locally, we investigate the possibility of offloading computation to edge and cloud platforms, which are less resource-constrained. We create a synthetic dataset to train object detection models and evaluate different offloading strategies. Using real hardware and network simulations, we compare different trade-offs between prediction quality and end-to-end delay. Since sending raw frames over the network impl
    
[^51]: SegMatch: 一种用于手术器械分割的半监督学习方法

    SegMatch: A semi-supervised learning method for surgical instrument segmentation. (arXiv:2308.05232v1 [cs.CV])

    [http://arxiv.org/abs/2308.05232](http://arxiv.org/abs/2308.05232)

    SegMatch是一种用于手术器械分割的半监督学习方法，通过结合一致性正则化和伪标签来减少昂贵的注释需求，并通过弱增强和生成伪标签来实现无监督损失的施加。

    

    手术器械分割被认为是提供先进手术辅助和改善计算机辅助干预的关键手段。在这项工作中，我们提出了SegMatch，一种用于减少昂贵注释对腹腔镜和机器人手术图像的需求的半监督学习方法。SegMatch基于FixMatch，一种广泛采用一致性正则化和伪标签的半监督分类流程，并将其调整为分割任务。在我们提出的SegMatch中，未标记的图像进行弱增强，并通过分割模型生成伪标签，以对高置信度像素上的对抗增强图像的模型输出施加无监督损失。我们针对分割任务的调整还包括仔细考虑所依赖的增强函数的等变性和不变性属性，为增强的相关性增加。

    Surgical instrument segmentation is recognised as a key enabler to provide advanced surgical assistance and improve computer assisted interventions. In this work, we propose SegMatch, a semi supervised learning method to reduce the need for expensive annotation for laparoscopic and robotic surgical images. SegMatch builds on FixMatch, a widespread semi supervised classification pipeline combining consistency regularization and pseudo labelling, and adapts it for the purpose of segmentation. In our proposed SegMatch, the unlabelled images are weakly augmented and fed into the segmentation model to generate a pseudo-label to enforce the unsupervised loss against the output of the model for the adversarial augmented image on the pixels with a high confidence score. Our adaptation for segmentation tasks includes carefully considering the equivariance and invariance properties of the augmentation functions we rely on. To increase the relevance of our augmentations, we depart from using only
    
[^52]: 使用端到端光背向传播训练神经网络

    Training neural networks with end-to-end optical backpropagation. (arXiv:2308.05226v1 [physics.optics])

    [http://arxiv.org/abs/2308.05226](http://arxiv.org/abs/2308.05226)

    本研究首次提出了一种非常简单和通用的方案，使用饱和吸收体作为激活单元的光学元件来实现光学反向传播，以解决光学神经网络训练中的难题。

    

    光学是下一代机器学习计算硬件的令人兴奋的途径，承诺在计算速度和能量效率上提供几个数量级的增强。然而，为了充分发挥光学神经网络的能力，不仅推理，而且训练的计算也需要以光学方式实现。神经网络训练的主要算法是反向传播，其计算顺序与推理的信息流相反。尽管在数字计算机中很简单，但光学实现反向传播一直是困难的，特别是由于实现非线性激活函数的光学元件的冲突要求。在这项工作中，我们首次用一个非常简单和通用的方案解决了这个挑战。饱和吸收体被用于扮演激活单元的角色，并实现所需的性质。

    Optics is an exciting route for the next generation of computing hardware for machine learning, promising several orders of magnitude enhancement in both computational speed and energy efficiency. However, to reach the full capacity of an optical neural network it is necessary that the computing not only for the inference, but also for the training be implemented optically. The primary algorithm for training a neural network is backpropagation, in which the calculation is performed in the order opposite to the information flow for inference. While straightforward in a digital computer, optical implementation of backpropagation has so far remained elusive, particularly because of the conflicting requirements for the optical element that implements the nonlinear activation function. In this work, we address this challenge for the first time with a surprisingly simple and generic scheme. Saturable absorbers are employed for the role of the activation units, and the required properties are
    
[^53]: 语言转换器中的层显著性解码

    Decoding Layer Saliency in Language Transformers. (arXiv:2308.05219v1 [cs.CL])

    [http://arxiv.org/abs/2308.05219](http://arxiv.org/abs/2308.05219)

    本文提出了一种在语言转换器中识别文本显著性的策略，并适应了基于梯度的显著性方法，在多个基准分类数据集上取得了一致提升。

    

    本文介绍了一种在大规模语言模型应用于分类任务中识别文本显著性的策略。在视觉网络中，显著性往往通过卷积层自然地进行定位，然而，在用于处理自然语言的现代transformer-stack网络中，并非如此。我们为这些网络适应了基于梯度的显著性方法，提出了一种评估每层语义一致性程度的方法，并在多个基准分类数据集上展示了与其他多种文本显著性方法相比的一致提升。我们的方法不需要额外的训练或访问标记数据，而且计算效率相对较高。

    In this paper, we introduce a strategy for identifying textual saliency in large-scale language models applied to classification tasks. In visual networks where saliency is more well-studied, saliency is naturally localized through the convolutional layers of the network; however, the same is not true in modern transformer-stack networks used to process natural language. We adapt gradient-based saliency methods for these networks, propose a method for evaluating the degree of semantic coherence of each layer, and demonstrate consistent improvement over numerous other methods for textual saliency on multiple benchmark classification datasets. Our approach requires no additional training or access to labelled data, and is comparatively very computationally efficient.
    
[^54]: 基于Conformer的单声道音频的目标说话者自动语音识别

    Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio. (arXiv:2308.05218v1 [cs.SD])

    [http://arxiv.org/abs/2308.05218](http://arxiv.org/abs/2308.05218)

    本论文提出了基于Conformer的单声道音频的目标说话者自动语音识别（TS-ASR）方法。该方法通过优化嵌入模块、掩模模块和ASR模块实现对目标说话者的识别，并且在多个数据集上取得了最先进的性能表现，建立了新的TS-ASR基准。

    

    我们提出了CONF-TSASR，一种非自回归的端到端时间-频率域架构，用于单声道目标说话者自动语音识别（TS-ASR）。该模型包括基于TitaNet的说话者嵌入模块，基于Conformer的掩模以及ASR模块。这些模块在优化过程中同时进行，以转录目标说话者的语音，同时忽略其他说话者的语音。在训练中，我们使用连续时间分类（CTC）损失，并引入了一个尺度不变的谱图重构损失，以促使模型更好地将目标说话者的谱图与混合声音分离开来。在WSJ0-2mix-extr数据集上，我们获得了最先进的目标说话者词错误率（TS-WER）（4.2%）。此外，我们还首次报告了WSJ0-3mix-extr（12.4%）、LibriSpeech2Mix（4.2%）和LibriSpeech3Mix（7.6%）数据集上的TS-WER，建立了TS-ASR的新基准。我们将通过NVIDIA NeMo工具包开源提供该模型。

    We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domain architecture for single-channel target-speaker automatic speech recognition (TS-ASR). The model consists of a TitaNet based speaker embedding module, a Conformer based masking as well as ASR modules. These modules are jointly optimized to transcribe a target-speaker, while ignoring speech from other speakers. For training we use Connectionist Temporal Classification (CTC) loss and introduce a scale-invariant spectrogram reconstruction loss to encourage the model better separate the target-speaker's spectrogram from mixture. We obtain state-of-the-art target-speaker word error rate (TS-WER) on WSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER on WSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%) datasets, establishing new benchmarks for TS-ASR. The proposed model will be open-sourced through NVIDIA NeMo toolkit.
    
[^55]: 评估用于自动驾驶中的行人轨迹预测方法

    Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving. (arXiv:2308.05194v1 [cs.LG])

    [http://arxiv.org/abs/2308.05194](http://arxiv.org/abs/2308.05194)

    本论文评估了行人轨迹预测方法在自动驾驶应用中的可行性，并发现简单模型在生成单个轨迹时仍然具有竞争力，某些通常被认为有用的特征对整体性能影响较小。

    

    本文评估了行人轨迹预测领域的最新方法与常速模型在自动驾驶应用中的适用性。评估在广泛使用的ETH/UCY数据集上进行，报告了平均位移误差（ADE）和最终位移误差（FDE）。为了符合实际应用的要求，对初始模型的输入特征进行了修改。进行了消融研究，以研究观察到的运动历史对预测性能的影响，从而建立更好的理解。此外，还测量了每个模型的推理时间，以评估面对不同数量代理时每个模型的可扩展性。结果表明，在生成单个轨迹时，简单模型仍然具有竞争力，某些通常被认为有用的特征对整体性能影响很小。

    In this paper, the state of the art in the field of pedestrian trajectory prediction is evaluated alongside the constant velocity model (CVM) with respect to its applicability in autonomous vehicles. The evaluation is conducted on the widely-used ETH/UCY dataset where the Average Displacement Error (ADE) and the Final Displacement Error (FDE) are reported. To align with requirements in real-world applications, modifications are made to the input features of the initially proposed models. An ablation study is conducted to examine the influence of the observed motion history on the prediction performance, thereby establishing a better understanding of its impact. Additionally, the inference time of each model is measured to evaluate the scalability of each model when confronted with varying amounts of agents. The results demonstrate that simple models remain competitive when generating single trajectories, and certain features commonly thought of as useful have little impact on the overa
    
[^56]: 基于层次化表示的时空视觉注意力建模和理解

    Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding. (arXiv:2308.05189v1 [cs.CV])

    [http://arxiv.org/abs/2308.05189](http://arxiv.org/abs/2308.05189)

    本文研究了基于层次化表示的时空视觉注意力建模和理解，在视频序列中提出了上下文感知的生成概率模型以及用于建模时空视觉注意力和时间领域注意力的深度网络架构。

    

    本博士论文研究和开发了基于层次化表示的时空视觉注意力建模和理解方法，针对视频序列中的视觉注意力问题，提出了两种计算模型。首先，我们提出了一种上下文感知的生成概率模型用于视觉注意力建模和理解。其次，我们开发了一个深度网络架构，用于建模上行的时空视觉注意力，并最终用于建模时间领域中的注意力。

    This PhD. Thesis concerns the study and development of hierarchical representations for spatio-temporal visual attention modeling and understanding in video sequences. More specifically, we propose two computational models for visual attention. First, we present a generative probabilistic model for context-aware visual attention modeling and understanding. Secondly, we develop a deep network architecture for visual attention modeling, which first estimates top-down spatio-temporal visual attention, and ultimately serves for modeling attention in the temporal domain.
    
[^57]: 癫痫发作预测的比较分析：探索多样的预处理技术和机器学习模型

    Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models. (arXiv:2308.05176v1 [eess.SP])

    [http://arxiv.org/abs/2308.05176](http://arxiv.org/abs/2308.05176)

    本研究对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面比较分析，通过应用多样的预处理技术和优化模型性能，为癫痫病人的有效管理和护理提供了准确且稳健的预测模型。

    

    癫痫是一种常见的神经系统疾病，其特点是反复发作和不可预测的癫痫发作，需要准确的预测以实施有效的管理和患者护理。机器学习（ML）应用于脑电图（EEG）记录，以及其在癫痫发作期间提供有价值的脑活动洞察的能力，使准确且稳健的癫痫发作预测成为相关研究中不可或缺的组成部分。在这项研究中，我们对使用EEG数据进行癫痫发作预测的五种机器学习模型进行了全面的比较分析 - 随机森林（RF），决策树（DT），极端森林（ET），逻辑回归（LR）和梯度提升（GB）。数据集经过了细致的预处理， 包括清理、归一化、异常值处理和过采样，以确保数据质量和便于准确的模型训练。这些预处理技术对于提高模型性能至关重要。

    Epilepsy is a prevalent neurological disorder characterized by recurrent and unpredictable seizures, necessitating accurate prediction for effective management and patient care. Application of machine learning (ML) on electroencephalogram (EEG) recordings, along with its ability to provide valuable insights into brain activity during seizures, is able to make accurate and robust seizure prediction an indispensable component in relevant studies. In this research, we present a comprehensive comparative analysis of five machine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees (ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction of epileptic seizures using EEG data. The dataset underwent meticulous preprocessing, including cleaning, normalization, outlier handling, and oversampling, ensuring data quality and facilitating accurate model training. These preprocessing techniques played a crucial role in enhancing the models' performance. The res
    
[^58]: 使用弱标签进行扩展射电星系形态识别的深度学习

    Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels. (arXiv:2308.05166v1 [astro-ph.IM])

    [http://arxiv.org/abs/2308.05166](http://arxiv.org/abs/2308.05166)

    本研究提出了一种使用弱标签进行扩展射电星系形态识别的深度学习算法，降低了标注成本并取得了高准确性。

    

    本研究讨论了一种弱监督深度学习算法的使用，该算法降低了对具有多个组成部分的复杂射电星系进行像素级标签标注的成本。该算法通过使用射电星系的弱类别级别标签训练得到类激活图（CAMs）。然后使用像素间关系网络（IRNet）进一步优化这些CAMs，得到射电星系的实例分割掩膜以及它们的红外主机位置。我们使用了来自澳大利亚平方公里阵（ASKAP）望远镜的数据，特别是演化宇宙图（EMU）试验，该试验覆盖了270平方度的天区，RMS灵敏度为25-35微Jy/beam。我们证明了弱监督深度学习算法可以在预测像素级信息方面取得高准确性，包括扩展射电辐射的掩膜和红外主机星系的位置。

    The present work discusses the use of a weakly-supervised deep learning algorithm that reduces the cost of labelling pixel-level masks for complex radio galaxies with multiple components. The algorithm is trained on weak class-level labels of radio galaxies to get class activation maps (CAMs). The CAMs are further refined using an inter-pixel relations network (IRNet) to get instance segmentation masks over radio galaxies and the positions of their infrared hosts. We use data from the Australian Square Kilometre Array Pathfinder (ASKAP) telescope, specifically the Evolutionary Map of the Universe (EMU) Pilot Survey, which covered a sky area of 270 square degrees with an RMS sensitivity of 25-35 $\mu$Jy/beam. We demonstrate that weakly-supervised deep learning algorithms can achieve high accuracy in predicting pixel-level information, including masks for the extended radio emission encapsulating all galaxy components and the positions of the infrared host galaxies. We evaluate the perfo
    
[^59]: 在参数化源的情况下，使用深度神经操作器在真实的交互式3D场景中模拟声音传播

    Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators. (arXiv:2308.05141v1 [cs.SD])

    [http://arxiv.org/abs/2308.05141](http://arxiv.org/abs/2308.05141)

    本文提出了使用深度神经操作器网络来模拟在真实的3D场景中带有移动源的声音传播。通过学习一个紧凑的代理模型，能够快速预测声音传播，避免了计算和存储脉冲响应的离线计算。

    

    我们解决了在具有移动源的三维虚拟房间中进行声音传播模拟的挑战，这在虚拟/增强现实、游戏音频和空间计算方面具有应用。通过求解波动方程，可以描述衍射和干涉等波动现象。然而，使用传统的数值离散化方法模拟涉及数百个源和接收器位置的波动方程是不可行的，使得使用移动源刺激声场变得不切实际。为了解决这个限制，我们提出使用深度操作器网络来逼近线性波动方程操作器。这使得能够快速预测在具有移动源的真实三维声学场景中的声音传播，达到毫秒级的计算。通过学习紧凑的代理模型，我们避免了为所有相关的源/听者对计算和存储脉冲响应的离线计算。我们的实验证明，在包含各种复杂场景几何形状的情况下，与参考结果达成了良好的一致性。

    We address the challenge of sound propagation simulations in $3$D virtual rooms with moving sources, which have applications in virtual/augmented reality, game audio, and spatial computing. Solutions to the wave equation can describe wave phenomena such as diffraction and interference. However, simulating them using conventional numerical discretization methods with hundreds of source and receiver positions is intractable, making stimulating a sound field with moving sources impractical. To overcome this limitation, we propose using deep operator networks to approximate linear wave-equation operators. This enables the rapid prediction of sound propagation in realistic 3D acoustic scenes with moving sources, achieving millisecond-scale computations. By learning a compact surrogate model, we avoid the offline calculation and storage of impulse responses for all relevant source/listener pairs. Our experiments, including various complex scene geometries, show good agreement with reference 
    
[^60]: 分析数据污染对精神障碍检测性能的影响

    Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders. (arXiv:2308.05133v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.05133](http://arxiv.org/abs/2308.05133)

    本研究旨在分析数据污染对精神障碍检测性能的影响，结果表明数据污染可能导致对目标精神障碍的分类器训练不佳。

    

    自动识别精神障碍的主要方法通常涉及使用二分类器。这些分类器是使用从访谈设置中获得的行为数据进行训练的。在这个训练过程中，来自具体障碍的个体的数据被归类为阳性类，而所有其他参与者的数据则构成阴性类。实际上，人们普遍承认某些精神障碍具有相似的症状，导致收集到的行为数据包含与多种障碍相关的各种属性。因此，与目标精神障碍相关的属性也可能存在于阴性类中。这种数据污染可能导致对所关注的精神障碍的分类器训练不佳。在这项研究中，我们在重度抑郁症（MDD）和创伤后应激障碍（PTSD）的检测领域中调查了这个假设。

    The primary method for identifying mental disorders automatically has traditionally involved using binary classifiers. These classifiers are trained using behavioral data obtained from an interview setup. In this training process, data from individuals with the specific disorder under consideration are categorized as the positive class, while data from all other participants constitute the negative class. In practice, it is widely recognized that certain mental disorders share similar symptoms, causing the collected behavioral data to encompass a variety of attributes associated with multiple disorders. Consequently, attributes linked to the targeted mental disorder might also be present within the negative class. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that 
    
[^61]: 性别生理差异是导致胸部X射线诊断性别偏见的原因吗？

    Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?. (arXiv:2308.05129v1 [eess.IV])

    [http://arxiv.org/abs/2308.05129](http://arxiv.org/abs/2308.05129)

    本论文研究了机器学习基于胸部X射线诊断中性别偏见的原因，发现乳腺组织导致肺部曝光不足从而降低模型性能，并提出了一种新的采样方法来解决记录分布偏斜和标签错误问题。

    

    虽然许多研究评估了医学领域AI算法的公平性，但是预测性能差异的原因往往是未知的。对偏见原因缺乏了解妨碍了偏见缓解的有效性，简单的数据集平衡通常是减小性能差距的最好方法，但无法解决所有性能差异。在这项工作中，我们研究了机器学习基于胸部X射线诊断中性别偏见的原因。特别地，我们探讨了乳腺组织导致肺部曝光不足并导致模型性能降低的假设。在方法上，我们提出了一种新的采样方法，解决了两个广泛使用的公共数据集中记录每个患者强烈偏斜的分布，并同时减少了标签错误的影响。我们在疾病、数据集和训练集中性别表示方面对性别差异进行了全面分析，发现...

    While many studies have assessed the fairness of AI algorithms in the medical field, the causes of differences in prediction performance are often unknown. This lack of knowledge about the causes of bias hampers the efficacy of bias mitigation, as evidenced by the fact that simple dataset balancing still often performs best in reducing performance gaps but is unable to resolve all performance differences. In this work, we investigate the causes of gender bias in machine learning-based chest X-ray diagnosis. In particular, we explore the hypothesis that breast tissue leads to underexposure of the lungs and causes lower model performance. Methodologically, we propose a new sampling method which addresses the highly skewed distribution of recordings per patient in two widely used public datasets, while at the same time reducing the impact of label errors. Our comprehensive analysis of gender differences across diseases, datasets, and gender representations in the training set shows that d
    
[^62]: 在目标检测的背景下，无数据模型提取攻击

    Data-Free Model Extraction Attacks in the Context of Object Detection. (arXiv:2308.05127v1 [cs.CR])

    [http://arxiv.org/abs/2308.05127](http://arxiv.org/abs/2308.05127)

    该论文提出了一种在目标检测中进行无数据模型提取的攻击方法，通过使用生成器生成特殊查询，成功实现了对私有数据集上训练的目标模型的窃取。通过定义损失函数和使用新颖的生成器设置，实现了对边界框坐标的预测问题的黑盒攻击。

    

    很多机器学习模型都容易受到模型提取攻击的威胁，这些攻击是通过使用针对目标模型的特殊查询来窃取模型的。这项任务通常使用训练数据的一部分或代理数据集来在白盒环境中训练一个模仿目标模型的新模型来完成。然而，在实际情况下，目标模型是在对手无法访问的私有数据集上训练的。无数据模型提取技术解决了这个问题，它使用类似生成对抗网络中使用的生成器来人工生成查询。我们首次提出了一个对回归问题的黑盒攻击，用于预测物体检测中的边界框坐标。在我们的研究中，我们发现定义损失函数和使用新颖的生成器设置是提取目标模型的关键因素之一。

    A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. W
    
[^63]: 两种新颖方法检测社区：Omicron Lineage变体PPI网络的案例研究

    Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network. (arXiv:2308.05125v1 [q-bio.MN])

    [http://arxiv.org/abs/2308.05125](http://arxiv.org/abs/2308.05125)

    本研究采用两种新算法和四种经典算法，成功揭示了Omicron病毒变体中的社区结构，为进一步了解疾病发病机制和推进药物发现提供了重要线索。

    

    能够识别和分析蛋白质间的相互作用及其内部模块化组织的能力，在了解分子水平上生物过程的复杂机制方面起着关键作用。通过使用网络分析，我们可以了解这些相互作用的结构和动力学。通过识别网络社区，我们可以改进对疾病发病机制的生物学根源的理解。而这些知识则在推动药物发现的进步和促进个体化治疗方法方面具有重要潜力。在本研究中，我们旨在利用两种提出的新算法（ABCDE和ALCDE）以及四种广泛认可的算法（Girvan-Newman，Louvain，Leiden和标签传播算法）揭示变体B.1.1.529（Omicron病毒）中的社区。每个算法在该领域中都有显着的地位，并提供了对识别社区的独特视角。

    The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities wit
    
[^64]: 基于基因型和脑影像数据的自注意力联合模型用于预测自闭症谱系障碍

    Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder. (arXiv:2308.05122v1 [q-bio.QM])

    [http://arxiv.org/abs/2308.05122](http://arxiv.org/abs/2308.05122)

    本研究提出了一种基于自注意力的模型，在结合遗传、人口统计和神经影像数据的基础上预测自闭症谱系障碍。通过引入基因型数据来指导对神经影像数据的关注，实现了对重要特征的模型预测。

    

    自闭症谱系障碍 (ASD) 的多因素病因表明，从神经影像学，遗传学和临床表征等广泛的平台数据中结合多模态方法可以极大地受益于对其的研究。先前的神经影像学和遗传学分析方法通常在数据驱动的工作中应用简单的特征拼接方法，或者使用一种模态的发现来指导另一种的后续分析，错失了对配对的多模态数据进行真正统一的分析的机会。在这篇论文中，我们开发了一个更综合的模型，用于结合遗传、人口统计和神经影像数据。受到基因型对表型的影响的启发，我们提出使用一种基于自注意力的方法，其中遗传数据指导对模型预测可能重要的神经影像特征的关注。遗传数据来自复制数变异参数，而神经影像数据来自功能磁共振成像。我们评估了所提出的方法。

    The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approa
    
[^65]: 机器学习方法在仪器与控制系统中的动态模型不可知可靠性评估

    Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems. (arXiv:2308.05120v1 [cs.LG])

    [http://arxiv.org/abs/2308.05120](http://arxiv.org/abs/2308.05120)

    本文提出了一种实时的模型不可知方法，通过在训练数据集上结合超出分布检测来评估机器学习预测的可靠性，解决了机器学习集成系统可信度不足的问题。

    

    在最近几年中，数据驱动的基于神经网络的机器学习算法在仪器与控制系统中的适用性研究方面取得了显著进展。虽然它们在操作环境中具有潜力，但这些算法的可信度尚未得到充分评估。机器学习集成系统的故障情况尚不清楚；缺乏全面的风险建模可能会降低这些系统的可信度。最近国家标准与技术研究所的报告指出，机器学习的可信度是采用的关键障碍，并且将在智能系统的安全和可追溯运行中发挥关键作用。因此，在本研究中，我们演示了一种实时的模型不可知方法，通过在训练数据集上结合超出分布检测来评估ML预测的相对可靠性。已有文献证明，ML算法在插值（或接近插值）任务方面表现出色，但在超出训练数据分布的情况下会明显下降。

    In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at ex
    
[^66]: 基于序列相似性和上下文的向量嵌入，用于改进cDNA文库的压缩、相似性搜索、聚类、组织和操作

    Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries. (arXiv:2308.05118v1 [q-bio.GN])

    [http://arxiv.org/abs/2308.05118](http://arxiv.org/abs/2308.05118)

    本文提出了一种基于序列相似性和上下文的向量嵌入方法，用于改进cDNA文库的压缩、相似性搜索、聚类、组织和操作。通过将序列转换为向量嵌入的形式，可以更高效地聚类并提高压缩性能，同时可以基于氨基酸性质进行聚类。

    

    本文展示了基因的有组织的数值表征在研究中的实用性，其中涉及到扁平字符串基因格式（例如FASTA/FASTQ）。FASTA/FASTQ文件目前存在一些限制，如文件大小大、映射和比对的处理速度慢以及上下文依赖性。这些挑战严重妨碍了涉及查找相似序列的调查和任务。解决方案是将序列转换为一种替代表示法，便于将其聚类到与原始序列相比更相似的组中。通过给每个短序列分配一个唯一的向量嵌入，可以更高效地聚类，并改善cDNA文库字符串表示的压缩性能。此外，通过学习基于密码子三聚体上下文的替代坐标向量嵌入，可以基于氨基酸性质进行聚类。最后，使用这种序列嵌入可以提高相似性搜索的效果，用于改进cDNA文库的压缩、相似性搜索、聚类、组织和操作。

    This paper demonstrates the utility of organized numerical representations of genes in research involving flat string gene formats (i.e., FASTA/FASTQ5). FASTA/FASTQ files have several current limitations, such as their large file sizes, slow processing speeds for mapping and alignment, and contextual dependencies. These challenges significantly hinder investigations and tasks that involve finding similar sequences. The solution lies in transforming sequences into an alternative representation that facilitates easier clustering into similar groups compared to the raw sequences themselves. By assigning a unique vector embedding to each short sequence, it is possible to more efficiently cluster and improve upon compression performance for the string representations of cDNA libraries. Furthermore, through learning alternative coordinate vector embeddings based on the contexts of codon triplets, we can demonstrate clustering based on amino acid properties. Finally, using this sequence embed
    
[^67]: 基于蛋白质预训练语言模型和Transformer的磷酸化位点识别方法(PTransIPs)

    PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer. (arXiv:2308.05115v1 [q-bio.QM])

    [http://arxiv.org/abs/2308.05115](http://arxiv.org/abs/2308.05115)

    PTransIPs是一种新型深度学习模型，它将蛋白质序列中的氨基酸视为自然语言中的单词，并结合大型预训练蛋白质模型的嵌入。该模型通过结合卷积神经网络和Transformer模型进行训练，用于识别磷酸化位点。

    

    磷酸化是许多基础细胞过程的核心，影响着各种疾病的发生和进展。因此，磷酸化位点的识别是理解细胞和病毒感染的分子机制的重要一步，可能为新的治疗靶点提供基础。在本研究中，我们提出了一种名为PTransIPs的新型深度学习模型，用于识别磷酸化位点。PTransIPs将蛋白质序列中的氨基酸视为自然语言中的单词，并根据序列中氨基酸的类型和位置提取独特的编码。它还通过使用大型预训练蛋白质模型的嵌入作为额外的数据输入。PTransIPs进一步通过结合具有残差连接的卷积神经网络和Transformer模型，配备多头注意机制进行训练。最后，该模型通过全连接层输出分类结果。

    Phosphorylation is central to numerous fundamental cellular processes, influencing the onset and progression of a variety of diseases. Identification of phosphorylation sites is thus an important step for understanding the molecular mechanisms of cells and virus infection, which potentially leads to new therapeutic targets. In this study, we present PTransIPs, a novel deep learning model for the identification of phosphorylation sites. PTransIPs treats amino acids in protein sequences as words in natural language, extracting unique encodings based on the types along with position of amino acids in the sequence. It also incorporates embeddings from large pre-trained protein models as additional data inputs. PTransIPS is further trained on a combination model of convolutional neural network with residual connections and Transformer model equipped with multi-head attention mechanisms. At last, the model outputs classification results through a fully connected layer. The results of indepen
    
[^68]: 用注意力机制解释基于电子病历的死亡率预测任务：以出血性中风为例的案例研究

    Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke. (arXiv:2308.05110v1 [cs.LG])

    [http://arxiv.org/abs/2308.05110](http://arxiv.org/abs/2308.05110)

    本文提出了一种可解释的基于注意力机制的变压器模型，用于早期中风死亡率预测。该模型旨在提供解释性和忠实度，并通过使用Shapley值和基于注意力的评分来改进模型的可解释性和忠实度。

    

    中风是致死率和致残率显著的因素，需要早期预测策略来降低风险。传统评估患者的方法，如急性生理和慢性健康评估（APACHE II、IV）和简化急性生理评分III（SAPS III），具有有限的准确性和可解释性。本文提出了一种新颖的方法：一种可解释的基于注意力机制的变压器模型，用于早期中风死亡率预测。该模型旨在解决之前预测模型的局限性，提供解释性（清晰、易懂地解释模型）和忠实度（从输入到输出提供真实的模型动态解释）。此外，研究还探索和比较使用Shapley值和基于注意力的评分来改进模型的可解释性和忠实度分数。研究目标包括设计一种可解释的基于注意力机制的变压器模型，评估其性能。

    Stroke is a significant cause of mortality and morbidity, necessitating early predictive strategies to minimize risks. Traditional methods for evaluating patients, such as Acute Physiology and Chronic Health Evaluation (APACHE II, IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy and interpretability. This paper proposes a novel approach: an interpretable, attention-based transformer model for early stroke mortality prediction. This model seeks to address the limitations of previous predictive models, providing both interpretability (providing clear, understandable explanations of the model) and fidelity (giving a truthful explanation of the model's dynamics from input to output). Furthermore, the study explores and compares fidelity and interpretability scores using Shapley values and attention-based scores to improve model explainability. The research objectives include designing an interpretable attention-based transformer model, evaluating its performa
    
[^69]: 在联邦学习中平衡准确性和训练时间：暴力检测在监控视频中的神经网络架构研究

    Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures. (arXiv:2308.05106v1 [cs.CV])

    [http://arxiv.org/abs/2308.05106](http://arxiv.org/abs/2308.05106)

    本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性，通过在联邦学习环境中训练最佳暴力检测模型，实现了比现有模型更好的准确性结果。

    

    本文研究了联邦学习环境下视频暴力检测的机器学习技术以及它们的适应性。研究包括对基准视频数据集中提取的时空特征进行实验，比较不同方法，提出了一种修改版本的“Flow-Gated”架构，称为“Diff-Gated”。此外，探索了多种机器学习技术，包括超收敛和迁移学习，并开发了一种将集中式数据集适应到联邦学习环境的方法。通过在联邦学习环境中训练最佳暴力检测模型，研究实现了比现有模型更好的准确性结果。

    This paper presents an investigation into machine learning techniques for violence detection in videos and their adaptation to a federated learning context. The study includes experiments with spatio-temporal features extracted from benchmark video datasets, comparison of different methods, and proposal of a modified version of the "Flow-Gated" architecture called "Diff-Gated." Additionally, various machine learning techniques, including super-convergence and transfer learning, are explored, and a method for adapting centralized datasets to a federated learning context is developed. The research achieves better accuracy results compared to state-of-the-art models by training the best violence detection model in a federated learning context.
    
[^70]: 多类深度支持向量数据描述：一种用于天文学中具有不同内部类别的异常检测方法

    Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories. (arXiv:2308.05011v1 [cs.LG])

    [http://arxiv.org/abs/2308.05011](http://arxiv.org/abs/2308.05011)

    提出了一种专门用于处理具有不同内部类别的天文学异常检测方法，采用多类深度支持向量数据描述(MCDSVDD)方法，通过使用神经网络将数据映射到超球体中，每个超球体代表一个特定的内部类别，并计算样本与超球体中心的距离以确定异常分数。

    

    随着现代勘测望远镜产生的天文数据量不断增加，自动化流程和机器学习技术已成为对这些数据进行分析和提取知识的关键。异常检测，在数据中识别不规则或意外模式的任务，是天文学中的一个复杂挑战。本文中，我们提出了多类深度支持向量数据描述(MCDSVDD)方法，它是一种对现有异常检测算法One-Class Deep SVDD进行扩展的方法，专门用于处理具有不同数据分布的不同内部类别。MCDSVDD使用神经网络将数据映射到超球体中，其中每个超球体代表一个特定的内部类别。样本距离这些超球体中心的距离决定了异常分数。我们通过将MCDSVDD的性能与多个异常检测算法在大规模天文光变曲线数据集上进行比较，评估了MCDSVDD的有效性。

    With the increasing volume of astronomical data generated by modern survey telescopes, automated pipelines and machine learning techniques have become crucial for analyzing and extracting knowledge from these datasets. Anomaly detection, i.e. the task of identifying irregular or unexpected patterns in the data, is a complex challenge in astronomy. In this paper, we propose Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically designed to handle different inlier categories with distinct data distributions. MCDSVDD uses a neural network to map the data into hyperspheres, where each hypersphere represents a specific inlier category. The distance of each sample from the centers of these hyperspheres determines the anomaly score. We evaluate the effectiveness of MCDSVDD by comparing its performance with several anomaly detection algorithms on a large dataset of astronomical light-curves 
    
[^71]: 一种用于PDF恶意软件检测的小尺寸特征集

    A Feature Set of Small Size for the PDF Malware Detection. (arXiv:2308.04704v1 [cs.CR])

    [http://arxiv.org/abs/2308.04704](http://arxiv.org/abs/2308.04704)

    该研究提出了一种小型特征集，用于检测PDF恶意软件，无需太多领域知识。在六种机器学习模型中，使用Random Forest模型时可以达到99.75%的准确性。这个仅包含12个特征的特征集是最简洁的之一，尽管规模较小，但结果可与采用更大特征集的最先进方法相媲美。

    

    随着恶意软件威胁的增加和更加复杂化，基于机器学习（ML）的恶意软件检测系统变得越来越重要。PDF文件通常被用作钓鱼攻击的矢量，因为它们被广泛认为是可信的数据资源，并且在不同平台上都可以访问。因此，研究人员开发了许多不同的PDF恶意软件检测方法。特征选择对于检测PDF恶意软件的性能有很大影响。在这项研究中，我们提出了一个小型特征集，不需要太多关于PDF文件的领域知识。我们使用六种不同的机器学习模型评估了提出的特征。在使用Random Forest模型时，我们报告了最高99.75%的准确性。我们提出的仅包含12个特征的特征集是PDF恶意软件检测领域中最简洁的之一。尽管规模较小，但我们获得了与采用更大特征集的最先进方法相当的结果。

    Machine learning (ML)-based malware detection systems are becoming increasingly important as malware threats increase and get more sophisticated. PDF files are often used as vectors for phishing attacks because they are widely regarded as trustworthy data resources, and are accessible across different platforms. Therefore, researchers have developed many different PDF malware detection methods. Performance in detecting PDF malware is greatly influenced by feature selection. In this research, we propose a small features set that don't require too much domain knowledge of the PDF file. We evaluate proposed features with six different machine learning models. We report the best accuracy of 99.75% when using Random Forest model. Our proposed feature set, which consists of just 12 features, is one of the most conciseness in the field of PDF malware detection. Despite its modest size, we obtain comparable results to state-of-the-art that employ a much larger set of features.
    
[^72]: SLEM：机器学习用于路径建模和因果推断的超级学习者方程模型

    SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])

    [http://arxiv.org/abs/2308.04365](http://arxiv.org/abs/2308.04365)

    SLEM是一种路径建模技术，通过集成机器学习超级学习者，实现了一致且无偏的因果效应估计，并在处理非线性关系时超过了传统的结构方程模型。

    

    因果推断是科学的关键目标，使研究人员能够通过观察数据得出关于对假定干预的预测的有意义的结论。路径模型、结构方程模型(SEMs)以及更一般的有向无环图(DAGs)能够明确地指定关于现象背后的因果结构的假设。与DAGs不同，SEMs假设线性关系，这可能导致函数错误规范，从而阻碍研究人员进行可靠的效果大小估计。相反，我们提出了超级学习者方程模型（SLEM），一种集成了机器学习超级学习者集成的路径建模技术。我们通过实证研究，证明了SLEM能够提供一致且无偏的因果效应估计，在与SEMs进行线性模型比较时表现出竞争力，并且在处理非线性关系时优于SEMs。

    Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
    
[^73]: 通过缩放可能可以实现与人类相似的视觉经验和人类级别的物体识别能力

    Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience. (arXiv:2308.03712v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.03712](http://arxiv.org/abs/2308.03712)

    本文研究了通过同时缩放数据规模、模型规模和图像分辨率，利用自监督学习算法能够以非人类尺度的条件实现人类级别的物体识别能力。

    

    本文研究了当前自监督学习方法是否能够通过足够的缩放来达到与人类学习相同类型和数量的视觉经验的人类级别视觉物体识别能力。以往的研究只考虑了数据规模的缩放。在本研究中，我们考虑数据规模、模型规模和图像分辨率的同时缩放。我们进行了一次缩放实验，使用了最多633M参数规模（ViT-H/14）的视觉转换器，以长达5K小时的类人视频数据（长时间连续、主要为自我中心的视频）进行训练，图像分辨率高达476x476像素。作为一种自监督学习算法，掩蔽自编码器（MAEs）的高效性使得可以在普通的学术预算下进行这种缩放实验。我们发现，通过同时缩放这些因素，即使在亚人类尺度的模型规模、数据规模和图像尺寸下，实现人类级别的物体识别能力是可行的。

    This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. T
    
[^74]: 使用HARU-Net增强细胞核分割: 一个混合注意力和残差U块网络

    Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network. (arXiv:2308.03382v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2308.03382](http://arxiv.org/abs/2308.03382)

    提出了一个使用混合注意力和残差U块的双分支网络，用于增强细胞核分割。此方法能够有效处理细胞核的大小变化、模糊轮廓、染色不均匀、细胞团聚和重叠的细胞核等挑战。

    

    细胞核图像分割是分析、病理诊断和分类的关键步骤，它严重依赖于细胞核分割的质量。然而，细胞核尺寸的变化、模糊的细胞核轮廓、染色不均匀、细胞团聚和细胞重叠等问题的复杂性带来了重大挑战。当前的细胞核分割方法主要依赖于核形态学或基于轮廓的方法。基于核形态学的方法具有有限的泛化能力，对于预测不规则形状的细胞核效果有限，而基于轮廓提取的方法在准确分割重叠的细胞核方面面临困难。为了解决上述问题，我们提出了一个使用混合注意力和残差U块的双分支网络，用于细胞核实例分割。该网络同时预测目标信息和目标轮廓。此外，我们还引入了一种后处理方法，将目标信息与目标轮廓相结合。

    Nucleus image segmentation is a crucial step in the analysis, pathological diagnosis, and classification, which heavily relies on the quality of nucleus segmentation. However, the complexity of issues such as variations in nucleus size, blurred nucleus contours, uneven staining, cell clustering, and overlapping cells poses significant challenges. Current methods for nucleus segmentation primarily rely on nuclear morphology or contour-based approaches. Nuclear morphology-based methods exhibit limited generalization ability and struggle to effectively predict irregular-shaped nuclei, while contour-based extraction methods face challenges in accurately segmenting overlapping nuclei. To address the aforementioned issues, we propose a dual-branch network using hybrid attention based residual U-blocks for nucleus instance segmentation. The network simultaneously predicts target information and target contours. Additionally, we introduce a post-processing method that combines the target infor
    
[^75]: AI-GOMS: 大型AI驱动的全球海洋模拟系统

    AI-GOMS: Large AI-Driven Global Ocean Modeling System. (arXiv:2308.03152v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2308.03152](http://arxiv.org/abs/2308.03152)

    提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。

    

    海洋模拟是模拟海洋的物理、化学和生物过程的强大工具，是海洋科学研究和运营海洋学的基础。现代数值海洋模拟主要包括控制方程和数值算法。非线性不稳定性、计算开销、低可重用效率和高耦合成本逐渐成为数值海洋模拟进一步发展的主要瓶颈。近年来，基于人工智能的科学计算模型展示了数字孪生和科学模拟的革命潜力，但数值海洋模拟的瓶颈尚未得到进一步解决。在这里，我们提出了AI-GOMS，一个大型AI驱动的全球海洋模拟系统，用于准确高效的全球海洋每日预测。AI-GOMS包括一个基于傅里叶变换的掩码自编码器结构的骨干模型，用于基本海洋变量预测和轻量级微调。

    Ocean modeling is a powerful tool for simulating the physical, chemical, and biological processes of the ocean, which is the foundation for marine science research and operational oceanography. Modern numerical ocean modeling mainly consists of governing equations and numerical algorithms. Nonlinear instability, computational expense, low reusability efficiency and high coupling costs have gradually become the main bottlenecks for the further development of numerical ocean modeling. Recently, artificial intelligence-based modeling in scientific computing has shown revolutionary potential for digital twins and scientific simulations, but the bottlenecks of numerical ocean modeling have not been further solved. Here, we present AI-GOMS, a large AI-driven global ocean modeling system, for accurate and efficient global ocean daily prediction. AI-GOMS consists of a backbone model with the Fourier-based Masked Autoencoder structure for basic ocean variable prediction and lightweight fine-tun
    
[^76]: 对强健的点云识别进行基准测试和分析：抵御对抗样本的技巧

    Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples. (arXiv:2307.16361v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.16361](http://arxiv.org/abs/2307.16361)

    本研究通过建立全面的点云对抗鲁棒性基准、收集已有的防御技巧，并进行实验，总结出了一种有效的点云对抗防御方法。

    

    三维点云识别的深度神经网络(DNNs)对对抗样本具有弱点，威胁着它们的实际应用。尽管近年来进行了许多研究来解决这个问题，但在3D点云上的对抗样本的多样性使其比2D图像更具挑战性。例如，攻击者可以通过添加、移动或删除点来生成对抗样本。因此，现有的防御策略很难对付未知的点云对抗样本。本文首先建立了一个全面且严谨的点云对抗鲁棒性基准，评估对抗鲁棒性，可以详细了解防御和攻击方法的影响。我们然后收集点云对抗防御中已有的技巧，并进行广泛系统的实验，以确定这些技巧的有效组合。

    Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable to adversarial examples, threatening their practical deployment. Despite the many research endeavors have been made to tackle this issue in recent years, the diversity of adversarial examples on 3D point clouds makes them more challenging to defend against than those on 2D images. For examples, attackers can generate adversarial examples by adding, shifting, or removing points. Consequently, existing defense strategies are hard to counter unseen point cloud adversarial examples. In this paper, we first establish a comprehensive, and rigorous point cloud adversarial robustness benchmark to evaluate adversarial robustness, which can provide a detailed understanding of the effects of the defense and attack methods. We then collect existing defense tricks in point cloud adversarial defenses and then perform extensive and systematic experiments to identify an effective combination of these tricks. Furthermore, we prop
    
[^77]: 视觉语言导航中的数据生成规模化

    Scaling Data Generation in Vision-and-Language Navigation. (arXiv:2307.15644v1 [cs.CV])

    [http://arxiv.org/abs/2307.15644](http://arxiv.org/abs/2307.15644)

    这项研究提出了一种用于视觉语言导航中生成大规模数据的有效范式。通过利用逼真的环境和网络资源，合成了490万个指令轨迹对。通过使用这个大规模数据集，通过简单的模仿学习，已存在的代理的性能得到了显著提升至80%。

    

    最近在语言引导的视觉导航研究中，对于遍历环境的多样性和训练可泛化代理的监督数量有了明显需求。为了解决现有视觉语言导航数据集中普遍存在的数据稀缺问题，我们提出了一种有效的范式，用于生成用于学习的大规模数据。我们应用了HM3D和Gibson数据集中的1200多个逼真的环境，并利用网络上的资源合成了490万个指令轨迹对。重要的是，我们调查了范式中每个组成部分对代理性能的影响，并研究了如何恰当地应用扩增数据来预训练和微调代理。得益于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以大幅提升（相对于之前的最佳结果绝对值增加了11%），在R2R测试集中单次运行成功率显著提升至80%。

    Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11% absolute with regard to previous SoTA) to a significantly new best of 80% single-run success rate on the R2R test split by simple imitation learning. The
    
[^78]: 用于荒野SAR和寻找Patricia Wu-Murad的计算机视觉的开放问题

    Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v1 [cs.CV])

    [http://arxiv.org/abs/2307.14527](http://arxiv.org/abs/2307.14527)

    该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。

    

    本论文详细介绍了将两种计算机视觉系统，EfficientDET监督学习模型和无监督RX光谱分类器应用于来自日本Wu-Murad野外搜救（WSAR）努力的98.9 GB无人机图像的挑战，并确定了未来研究的3个方向。已经提出了至少19种方法和3个数据集，旨在在无人机图像中定位失踪人员，但只有3种方法（2种无监督和1种未知结构）在文献中被引用为实际WSAR操作中使用过。在这些提出的方法中，EfficientDET架构和无监督的RX光谱分类器被选择为最适合此情景的方法。EfficientDET模型应用于HERIDAL数据集，尽管在性能上达到了与最新技术相当的水平，但模型在假阳性方面无法在现实世界中有效识别（例如，识别树枝和岩石）

    This paper details the challenges in applying two computer vision systems, an EfficientDET supervised learning model and the unsupervised RX spectral classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and rescue (WSAR) effort in Japan and identifies 3 directions for future research. There have been at least 19 proposed approaches and 3 datasets aimed at locating missing persons in drone imagery, but only 3 approaches (2 unsupervised and 1 of an unknown structure) are referenced in the literature as having been used in an actual WSAR operation. Of these proposed approaches, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. The EfficientDET model was applied to the HERIDAL dataset and despite achieving performance that is statistically equivalent to the state-of-the-art, the model fails to translate to the real world in terms of false positives (e.g., identifying tree limbs and rocks 
    
[^79]: 通过可靠的、多样化的和类平衡的伪标签来重新审视领域自适应三维物体检测

    Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling. (arXiv:2307.07944v1 [cs.CV])

    [http://arxiv.org/abs/2307.07944](http://arxiv.org/abs/2307.07944)

    本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。

    

    无监督领域自适应与伪标签技术的辅助已经成为领域自适应三维物体检测的关键方法。然而，现有的领域自适应方法在应用于多类训练设置时性能大幅下降，原因是伪标签的质量低和类别不平衡问题共存。本文通过提出一种针对同时学习检测所有类别的新型ReDB框架来解决这一挑战。我们的方法产生可靠的、多样化的和类平衡的伪三维框，通过迭代地引导不同分布的目标领域的自训练。为了减轻环境差异（例如，光束数量）带来的干扰，我们提出了跨域检查（CDE），通过将目标实例复制粘贴到源环境中并测量预测的一致性来评估伪标签的正确性。为了减少计算开销和缓解物体的转移（例如，

    Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g.
    
[^80]: 从NeurODEs到AutoencODEs：一种适用于宽度变化神经网络的均值场控制框架

    From NeurODEs to AutoencODEs: a mean-field control framework for width-varying Neural Networks. (arXiv:2307.02279v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2307.02279](http://arxiv.org/abs/2307.02279)

    该论文提出了一种均值场控制框架，从NeurODEs到AutoencODEs，用于模拟宽度可变的神经网络。通过修改驱动动态的控制场，扩展了原始NeurODEs的适用范围，并处理了低Tikhonov正则化情况下可能的非凸成本景观。

    

    残差神经网络（ResNets）与连续时间控制系统（称为NeurODEs）之间的联系导致了神经网络的数学分析，为理论和实践中的重要结果提供了有趣的成果。然而，由于构造的关系，NeurODEs仅能描述宽度恒定的层，这使得它们无法用于模拟宽度可变的深度学习结构。在本文中，我们提出了一种连续时间自编码器，称为AutoencODE，它基于驱动动态的控制场的修改。这种改进使得原本设计用于常规NeurODEs的均值场控制框架得以扩展。在这个设置下，我们处理了Tikhonov正则化较低的情况，导致可能非凸的成本景观。虽然对于较高的Tikhonov正则化，全局得到的结果可能不适用于所有情况，但我们展示了很多结果在损失函数部分的区域可被恢复。

    The connection between Residual Neural Networks (ResNets) and continuous-time control systems (known as NeurODEs) has led to a mathematical analysis of neural networks which has provided interesting results of both theoretical and practical significance. However, by construction, NeurODEs have been limited to describing constant-width layers, making them unsuitable for modeling deep learning architectures with layers of variable width. In this paper, we propose a continuous-time Autoencoder, which we call AutoencODE, based on a modification of the controlled field that drives the dynamics. This adaptation enables the extension of the mean-field control framework originally devised for conventional NeurODEs. In this setting, we tackle the case of low Tikhonov regularization, resulting in potentially non-convex cost landscapes. While the global results obtained for high Tikhonov regularization may not hold globally, we show that many of them can be recovered in regions where the loss fun
    
[^81]: 强化学习中的结构：调查与开放问题

    Structure in Reinforcement Learning: A Survey and Open Problems. (arXiv:2306.16021v1 [cs.LG])

    [http://arxiv.org/abs/2306.16021](http://arxiv.org/abs/2306.16021)

    这项调查研究了强化学习中结构的角色和重要性，并介绍了各个子领域在提高强化学习的性能方面所做的工作。

    

    强化学习（RL）借助深度神经网络（DNN）在函数逼近方面的表达能力，已经在许多应用中取得了相当大的成功。然而，在应对多样且不可预测的动态、嘈杂信号以及庞大的状态和动作空间等各种真实场景时，其实用性仍然有限。这个限制源于诸如数据效率低、泛化能力有限、缺少安全保证和不可解释性等问题。为了克服这些挑战并在这些关键指标上提高性能，一个有前途的途径是将问题的附加结构信息纳入强化学习的学习过程中。强化学习的各个子领域已经提出了许多方法来纳入这样的归纳偏差。我们将这些多样化的方法统一到一个框架下，揭示结构在学习问题中的作用。

    Reinforcement Learning (RL), bolstered by the expressive capabilities of Deep Neural Networks (DNNs) for function approximation, has demonstrated considerable success in numerous applications. However, its practicality in addressing a wide range of real-world scenarios, characterized by diverse and unpredictable dynamics, noisy signals, and large state and action spaces, remains limited. This limitation stems from issues such as poor data efficiency, limited generalization capabilities, a lack of safety guarantees, and the absence of interpretability, among other factors. To overcome these challenges and improve performance across these crucial metrics, one promising avenue is to incorporate additional structural information about the problem into the RL learning process. Various sub-fields of RL have proposed methods for incorporating such inductive biases. We amalgamate these diverse methodologies under a unified framework, shedding light on the role of structure in the learning prob
    
[^82]: 增量转化收益：一种用于电子商务促销增值模型的响应转化方法

    Incremental Profit per Conversion: a Response Transformation for Uplift Modeling in E-Commerce Promotions. (arXiv:2306.13759v1 [cs.LG])

    [http://arxiv.org/abs/2306.13759](http://arxiv.org/abs/2306.13759)

    本文提出了一种新的促销活动单位经济效率的增值度量方法IPC，通过响应转化方法解决响应相关成本增值模型中训练多个模型或计算复杂的问题。该方法只需转换过的数据、其倾向性和一个估计模型，可以提供准确的促销活动获利估计，是提高电子商务平台促销效率的实用工具。

    

    促销在电子商务平台中发挥着关键作用，采用各种成本结构来推动用户参与。本文专注于具有响应相关成本的促销，只有当购买发生时才会产生费用。这些促销包括折扣和优惠券。虽然现有的增值模型方法旨在解决这一挑战，但这些方法通常需要训练多个模型，如元学习器，或者由于非转换个体的零成本和利润引起的零膨胀值而估算利润时遇到复杂情况。为了解决这些挑战，我们引入了增量转化收益（IPC），这是一种新的促销活动单位经济效率的增值度量。通过提出的响应转化方法，我们证明IPC仅需要转换后的数据、其倾向性和一个要估计的模型即可。结果，IPC解决了上述问题，同时减轻了通常与响应相关成本有关的噪声。对模拟数据和真实世界数据集的实证研究表明，IPC提供了对促销活动获利能力更准确、更稳定的估计，是提高电子商务平台促销定向的实用工具。

    Promotions play a crucial role in e-commerce platforms, and various cost structures are employed to drive user engagement. This paper focuses on promotions with response-dependent costs, where expenses are incurred only when a purchase is made. Such promotions include discounts and coupons. While existing uplift model approaches aim to address this challenge, these approaches often necessitate training multiple models, like meta-learners, or encounter complications when estimating profit due to zero-inflated values stemming from non-converted individuals with zero cost and profit.  To address these challenges, we introduce Incremental Profit per Conversion (IPC), a novel uplift measure of promotional campaigns' efficiency in unit economics. Through a proposed response transformation, we demonstrate that IPC requires only converted data, its propensity, and a single model to be estimated. As a result, IPC resolves the issues mentioned above while mitigating the noise typically associate
    
[^83]: FALL-E：一种佛利音效合成模型及其策略

    FALL-E: A Foley Sound Synthesis Model and Strategies. (arXiv:2306.09807v1 [eess.AS])

    [http://arxiv.org/abs/2306.09807](http://arxiv.org/abs/2306.09807)

    本文介绍了一种名为“FALL-E”的佛利音效合成系统及其策略。该模型通过条件训练使其能够根据文本输入了解声音质量和录音环境，并在DCASE 2023挑战赛中表现良好，尤其在多样性上得分最高。

    

    本文介绍了一种名为“FALL-E”的佛利音效合成系统及其训练/推断策略。FALL-E模型采用级联方法，包括低分辨率频谱图生成、频谱图超分辨率和声码器。我们从头开始使用大量数据集训练了每个与声音相关的模型，并使用预训练的语言模型。我们使用数据集特定的文本将模型进行条件训练，使其能够根据文本输入了解声音质量和录音环境。此外，我们利用外部语言模型改善了我们的数据集的文本描述，并进行了质量、连贯性和多样性的提示工程。FALL-E在DCASE 2023挑战赛任务7中进行了客观评估和听力测试。提交结果在平均得分上获得第二名，同时在多样性上得分最高，在音频质量上获得第二名，在类适应性上获得第三名。

    This paper introduces FALL-E, a foley synthesis system and its training/inference strategies. The FALL-E model employs a cascaded approach comprising low-resolution spectrogram generation, spectrogram super-resolution, and a vocoder. We trained every sound-related model from scratch using our extensive datasets, and utilized a pre-trained language model. We conditioned the model with dataset-specific texts, enabling it to learn sound quality and recording environment based on text input. Moreover, we leveraged external language models to improve text descriptions of our datasets and performed prompt engineering for quality, coherence, and diversity. FALL-E was evaluated by an objective measure as well as listening tests in the DCASE 2023 challenge Task 7. The submission achieved the second place on average, while achieving the best score for diversity, second place for audio quality, and third place for class fitness.
    
[^84]: 深度学习中的超网络简要回顾

    A Brief Review of Hypernetworks in Deep Learning. (arXiv:2306.06955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06955](http://arxiv.org/abs/2306.06955)

    超网络是一种生成另一个神经网络权重的深度学习技术，具有灵活性、适应性、动态性、更快的训练速度、信息共享和模型压缩等优点。它在各种深度学习问题中显示了良好的效果，并在持续学习、迁移学习、权重剪枝、不确定性量化、零样本学习、自然语言处理和强化学习等领域取得了成功。

    

    超网络（Hypernetworks）是生成另一个神经网络（目标网络）权重的神经网络。它们作为一种强大的深度学习技术出现，能够提供更大的灵活性、适应性、动态性、更快的训练速度、信息共享和模型压缩等。超网络在各种深度学习问题中显示出了良好的效果，包括持续学习、因果推断、迁移学习、权重剪枝、不确定性量化、零样本学习、自然语言处理和强化学习等。尽管超网络在不同的问题设置中取得了成功，但目前还没有可用的综述来告知研究人员有关其发展情况并帮助利用超网络。为了填补这一空白，我们回顾了超网络的进展。我们通过一个例子来说明如何使用超网络来训练深度神经网络，并提出了基于五个设计准则对超网络进行分类。

    Hypernetworks, or hypernets in short, are neural networks that generate weights for another neural network, known as the target network. They have emerged as a powerful deep learning technique that allows for greater flexibility, adaptability, dynamism, faster training, information sharing, and model compression etc. Hypernets have shown promising results in a variety of deep learning problems, including continual learning, causal inference, transfer learning, weight pruning, uncertainty quantification, zero-shot learning, natural language processing, and reinforcement learning etc. Despite their success across different problem settings, currently, there is no review available to inform the researchers about the developments and to help in utilizing hypernets. To fill this gap, we review the progress in hypernets. We present an illustrative example to train deep neural networks using hypernets and propose categorizing hypernets based on five design criteria as inputs, outputs, variabi
    
[^85]: 大型预训练模型中的关键稀疏性的出现：重要的权重。

    The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter. (arXiv:2306.03805v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.03805](http://arxiv.org/abs/2306.03805)

    本文在多个大型预训练模型中研究了关键稀疏性，发现在去除具有最小幅度权重的情况下，性能下降速度与稀疏程度的增加呈现出拐点，这对于大型语言模型仍然有效。

    

    大型预训练变压器在现代深度学习中表现出色，因此理解它们内部存在的简化模式变得至关重要。随着参数数量的增加，通过迭代量化剪枝（IMP）的“抽奖票据假设”（LTH）及其变体已经失去了稀疏化它们的实用性，因为重复的训练-剪枝-重新训练过程导致了计算和内存瓶颈问题，而这种问题在模型规模增大时变得更加严重。本文全面研究了在多个大型预训练视觉和语言变压器中引发的稀疏模式。我们提出了一种关键稀疏性的存在，即当我们一次性直接删除具有最小幅度的权重时，性能下降速度随着稀疏程度的增加而加快，存在一个拐点。我们还发现关键稀疏性在N:M稀疏模式以及现代大规模语言模型中仍然有效。

    Large pre-trained transformers are show-stealer in modern-day deep learning, and it becomes crucial to comprehend the parsimonious patterns that exist within them as they grow in scale. With exploding parameter counts, Lottery Ticket Hypothesis (LTH) and its variants, have lost their pragmatism in sparsifying them due to high computation and memory bottleneck of repetitive train-prune-retrain routine of iterative magnitude pruning (IMP) which worsens with increasing model size. This paper comprehensively studies induced sparse patterns across multiple large pre-trained vision and language transformers. We propose the existence of -- essential sparsity defined with a sharp dropping point beyond which the performance declines much faster w.r.t the rise of sparsity level, when we directly remove weights with the smallest magnitudes in one-shot without re-training. We also find essential sparsity to hold valid for N:M sparsity patterns as well as on modern-scale large language models (Vicu
    
[^86]: 光学神经网络的前向训练

    Forward-Forward Training of an Optical Neural Network. (arXiv:2305.19170v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19170](http://arxiv.org/abs/2305.19170)

    这篇论文介绍了一种光学神经网络的前向训练方法，使用前向-前向算法进行权重更新，解决了光学平台训练多个可训练层面临的挑战。

    

    神经网络在各种任务中展示出了卓越的能力，但它们密集的计算性质要求更快速和更节能的硬件实现。基于光学的平台，利用硅光子学和空间光调制器等技术，为实现这一目标提供了有希望的途径。然而，与这些物理系统同时训练多个可训练的层面临挑战，因为它们很难完全表征并用可微函数进行描述，从而阻碍了误差反向传播算法的使用。最近引入的前向-前向算法（FFA）消除了对学习系统完美表征的需求，并显示出在具有大量可编程参数的高效训练方面的潜力。FFA不需要通过反向传播误差信号来更新权重，而是仅通过单向传递信息来更新权重。对于每组可训练的参数，本地损失函数用于优化权重。

    Neural networks (NN) have demonstrated remarkable capabilities in various tasks, but their computation-intensive nature demands faster and more energy-efficient hardware implementations. Optics-based platforms, using technologies such as silicon photonics and spatial light modulators, offer promising avenues for achieving this goal. However, training multiple trainable layers in tandem with these physical systems poses challenges, as they are difficult to fully characterize and describe with differentiable functions, hindering the use of error backpropagation algorithm. The recently introduced Forward-Forward Algorithm (FFA) eliminates the need for perfect characterization of the learning system and shows promise for efficient training with large numbers of programmable parameters. The FFA does not require backpropagating an error signal to update the weights, rather the weights are updated by only sending information in one direction. The local loss function for each set of trainable 
    
[^87]: 使用图形预测不规则采样时间序列

    Forecasting Irregularly Sampled Time Series using Graphs. (arXiv:2305.12932v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.12932](http://arxiv.org/abs/2305.12932)

    使用稀疏双分图结构图和图神经网络的新模型GraFITi，可以准确预测具有不规则采样和缺失值的时间序列。

    

    针对健康、天文和气候科学等多种实际应用中的缺失值问题，准确预测具有不规则采样和缺失值的时间序列是一项关键任务。目前针对此问题的最新方法依赖于已知速度慢且通常需要额外特征来处理缺失值的普通微分方程（ODE）。为应对这个问题，我们提出了一种新型的模型，称为GraFITi，它使用图形来预测具有缺失值的不规则采样时间序列。GraFITi首先将时间序列转化为稀疏双分图结构图，然后将预测问题重新定义为图中边权预测任务。它利用图神经网络的力量来学习图并预测目标边权。GraFITi已经在3个真实世界和1个合成的具有缺失值的不规则采样时间序列数据集上进行了测试，并与各种最先进的模型进行了比较。实验结果演示了GraFITi的出色性能和能力。

    Forecasting irregularly sampled time series with missing values is a crucial task for numerous real-world applications such as healthcare, astronomy, and climate sciences. State-of-the-art approaches to this problem rely on Ordinary Differential Equations (ODEs) which are known to be slow and often require additional features to handle missing values. To address this issue, we propose a novel model using Graphs for Forecasting Irregularly Sampled Time Series with missing values which we call GraFITi. GraFITi first converts the time series to a Sparsity Structure Graph which is a sparse bipartite graph, and then reformulates the forecasting problem as the edge weight prediction task in the graph. It uses the power of Graph Neural Networks to learn the graph and predict the target edge weights. GraFITi has been tested on 3 real-world and 1 synthetic irregularly sampled time series dataset with missing values and compared with various state-of-the-art models. The experimental results demo
    
[^88]: 从随机搜索到度量测度空间中的赌博学习

    From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])

    [http://arxiv.org/abs/2305.11509](http://arxiv.org/abs/2305.11509)

    本文介绍了随机搜索及其性能，引入了“散射维度”的概念，描述了底层函数的状态，量化了随机搜索的性能，并证明了在无噪声和有界噪声情况下的输出分别以一定概率收敛到最优值。

    

    随机搜索是超参数优化中最常用的方法之一，对于深度学习模型的成功至关重要。尽管其性能令人惊叹，但很少有非启发式的理论用于描述其工作机制。本文给出了关于随机搜索的理论解释。我们引入了“散射维度”的概念，描述了底层函数的状态，并量化了随机搜索的性能。我们表明，当环境没有噪声时，随机搜索的输出以概率收敛到最优值，其速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $，其中$ d_s \ge 0 $是底层函数的散射维度。当观察到的函数值受到有界的独立同分布噪声影响时，随机搜索的输出以概率收敛到最优值，速率为$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $。

    Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
    
[^89]: 基于贝叶斯优化光学等离子体发射的自主溅射合成薄膜氮化物

    Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission. (arXiv:2305.11122v2 [physics.app-ph] UPDATED)

    [http://arxiv.org/abs/2305.11122](http://arxiv.org/abs/2305.11122)

    本研究设计并实现了一种自主溅射沉积薄膜的仪器，利用Python和贝叶斯优化算法控制薄膜组成，加速材料发现步伐。

    

    自主实验已成为加速材料发现步伐的有效方法。虽然自主合成的仪器在分子和聚合物科学中已经很流行，但是用于混合材料和纳米颗粒的溶液处理，物理气相沉积的自主工具却很少见，但对于半导体行业而言却很重要。本文报道了一种自主溅射沉积薄膜的仪器设计和实施，利用高度自动化的溅射反应器、Python、光电发射光谱和贝叶斯优化算法控制薄膜组成。我们将由元素锌和钛在氮气气氛下共溅射时监测到的发射线作为光谱数据，并将薄膜成分（由X荧光法测量）建模为发射线的线性函数。由OES提供信息的贝叶斯控制算法在溅射功率的空间中导航，以制造符合用户定义的组成的薄膜。

    Autonomous experimentation has emerged as an efficient approach to accelerate the pace of materials discovery. Although instruments for autonomous synthesis have become popular in molecular and polymer science, solution processing of hybrid materials and nanoparticles, examples of autonomous tools for physical vapour deposition are scarce yet important for the semiconductor industry. Here, we report the design and implementation of an autonomous instrument for sputter deposition of thin films with controlled composition, leveraging a highly automated sputtering reactor custom-controlled by Python, optical emission spectroscopy (OES), and Bayesian optimization algorithm. We modeled film composition, measured by x-ray fluorescence, as a linear function of emission lines monitored during the co-sputtering from elemental Zn and Ti targets in N$_2$ atmosphere. A Bayesian control algorithm, informed by OES, navigates the space of sputtering power to fabricate films with user-defined composit
    
[^90]: 利用不确定性感知因果模型提高基于图像的精准医疗

    Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models. (arXiv:2305.03829v1 [cs.LG])

    [http://arxiv.org/abs/2305.03829](http://arxiv.org/abs/2305.03829)

    本研究采用贝叶斯深度学习估计多种治疗的因果后验分布，提高了基于图像的精准医疗的不确定性估计方法，以预测噪声多的医疗环境下的个体治疗效果。

    

    基于图像的精准医疗旨在根据个体的独特成像特征个性化诊疗决策，以改善其临床结果。集成不确定性估计作为治疗建议的机器学习框架将更加安全可靠。然而，在精准医疗中，几乎没有研究适应不确定性估计技术和验证指标。本文采用贝叶斯深度学习估计多种治疗的因果后验分布，从而估计每种治疗选项的不确定性以及任意两种治疗之间的个体治疗效果。我们对患有多发性硬化症的患者进行训练和评估，以预测新的和扩大的T2病变数量，并评估模型的相关性。

    Image-based precision medicine aims to personalize treatment decisions based on an individual's unique imaging features so as to improve their clinical outcome. Machine learning frameworks that integrate uncertainty estimation as part of their treatment recommendations would be safer and more reliable. However, little work has been done in adapting uncertainty estimation techniques and validation metrics for precision medicine. In this paper, we use Bayesian deep learning for estimating the posterior distribution over factual and counterfactual outcomes on several treatments. This allows for estimating the uncertainty for each treatment option and for the individual treatment effects (ITE) between any two treatments. We train and evaluate this model to predict future new and enlarging T2 lesion counts on a large, multi-center dataset of MR brain images of patients with multiple sclerosis, exposed to several treatments during randomized controlled trials. We evaluate the correlation of 
    
[^91]: {\Pi}-ML：基于尺寸分析的大气表层光学湍流机器学习参数化

    {\Pi}-ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer. (arXiv:2304.12177v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2304.12177](http://arxiv.org/abs/2304.12177)

    {\Pi}-ML是一种基于尺寸分析的机器学习方法，用于估计大气表层光学湍流的强度($C_n^2$)。 物理属性的特征分析表明，潜在温度的归一化方差是预测 $C_n^2$ 的关键特征。 通过训练模型集合，我们在样本外数据上取得了高性能。

    

    大气折射率的湍流波动，即光学湍流，可以导致激光束的显著扭曲。因此，建立模型来估计这些波动的强度 ($C_n^2$) 对于成功开发和部署未来自由空间光通信链路非常重要。在本文中，我们提出了一种基于尺寸分析和梯度提升的物理信息机器学习 (ML) 方法 $\Pi$-ML 来估计 $C_n^2$。通过系统的特征重要性分析，我们确定了潜在温度归一化方差作为预测 $C_n^2$ 的主要特征。为了保证统计鲁棒性，我们训练了一个模型集合，该集合在 $R^2=0.958\pm0.001$ 的样本外数据上表现出高性能。

    Turbulent fluctuations of the atmospheric refraction index, so-called optical turbulence, can significantly distort propagating laser beams. Therefore, modeling the strength of these fluctuations ($C_n^2$) is highly relevant for the successful development and deployment of future free-space optical communication links. In this letter, we propose a physics-informed machine learning (ML) methodology, $\Pi$-ML, based on dimensional analysis and gradient boosting to estimate $C_n^2$. Through a systematic feature importance analysis, we identify the normalized variance of potential temperature as the dominating feature for predicting $C_n^2$. For statistical robustness, we train an ensemble of models which yields high performance on the out-of-sample data of $R^2=0.958\pm0.001$.
    
[^92]: 学习随机过程的有条件生成模型

    Conditional Generative Models for Learning Stochastic Processes. (arXiv:2304.10382v1 [quant-ph])

    [http://arxiv.org/abs/2304.10382](http://arxiv.org/abs/2304.10382)

    提出了一种称为 C-qGAN 的框架，利用量子电路结构实现了有效的状态准备过程，可以利用该方法加速蒙特卡罗分析等算法，并将其应用于亚式期权衍生品定价的任务中。

    

    提出了一种学习多模态分布的框架，称为条件量子生成对抗网络（C-qGAN）。神经网络结构严格采用量子电路，因此被证明能够比当前的方法更有效地表示状态准备过程。这种方法有潜力加速蒙特卡罗分析等算法。特别地，在展示了网络在学习任务中的有效性后，将该技术应用于定价亚式期权衍生品，为未来研究其他路径相关期权打下基础。

    A framework to learn a multi-modal distribution is proposed, denoted as the Conditional Quantum Generative Adversarial Network (C-qGAN). The neural network structure is strictly within a quantum circuit and, as a consequence, is shown to represents a more efficient state preparation procedure than current methods. This methodology has the potential to speed-up algorithms, such as Monte Carlo analysis. In particular, after demonstrating the effectiveness of the network in the learning task, the technique is applied to price Asian option derivatives, providing the foundation for further research on other path-dependent options.
    
[^93]: 自适应门控图卷积网络用于基于EEG数据的阿尔茨海默病可解释诊断

    Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data. (arXiv:2304.05874v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.05874](http://arxiv.org/abs/2304.05874)

    本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。

    

    近来，图神经网络(GNN)模型越来越多地被用于分类脑电图(EEG)数据，然而，基于GNN的神经系统疾病，如阿尔茨海默病(AD)的诊断仍然是相对未开发的领域。因此，本文提出了一种新颖的自适应门控图卷积网络(AGGCN)，该网络可以提供可解释的预测结果。AGGCN通过将基于卷积的节点特征增强与基于功能连接性的著名相关度量相结合来自适应学习图结构。此外，门控图卷积可以动态地加权考虑各种空间尺度的贡献。实验结果表明，该模型在闭眼和睁眼状态下均能取得较高的精度，表明学习到的表征结果的稳定性。最后，我们证明了所提出的AGGCN模型可以提供有关AD最受影响的脑区的重要见解。

    Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the propos
    
[^94]: 通过扩散去噪平滑进行认证和对抗性的鲁棒的样本外检测

    Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection. (arXiv:2303.14961v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.14961](http://arxiv.org/abs/2303.14961)

    本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。

    

    随着机器学习的应用不断扩展，确保其安全性变得尤为重要。其中一个主要关注点是识别给定样本是否来自训练分布，或者是一个“样本外”（OOD）样本。此外，对手可以以一种导致分类器做出自信预测的方式操纵OOD样本。本研究提出了一种新颖的方法，用于在输入的L2范围内证明在不考虑网络架构以及不需要特定组件或额外训练的情况下，对OOD检测的鲁棒性。此外，我们改进了检测OOD样本的对抗攻击的技术，同时提供了对于分布样本的高水平的认证和对抗的结果。在CIFAR10/100的所有OOD检测指标的平均值显示，与以前的方法相比提高了约13％/ 5％。

    As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an "Out-Of-Distribution" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\sim 13 \% / 5\%$ relative to previous approaches.
    
[^95]: 用 Kernel 方法学习具有能隙的量子哈密顿量的基态

    Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v1 [quant-ph])

    [http://arxiv.org/abs/2303.08902](http://arxiv.org/abs/2303.08902)

    本文提出了一种利用 kernel 方法学习具有能隙的量子哈密顿量基态的统计学习方法，理论上需要多项式资源实现，通过数值模拟证明了该方法的有效性，并展示了方法的灵活性。

    

    近年来，利用神经网络来近似量子哈密顿量基态的方法需要解决高度非线性的优化问题。本文提出了一种利用 kernel 方法来使优化变得简单的统计学习方法。我们的方案是功率法的一种近似实现，其中通过监督学习来学习功率迭代的下一步。我们证明，假设监督学习是有效的，那么可以使用多项式资源实现对任意具有能隙的量子哈密顿量的基态性质的计算。我们使用 kernel ridge 回归，通过对一维和二维的几个典型相互作用多体量子系统进行基态的寻找，提供了基于数值模拟的证据，证明了学习假设的有效性，展示了我们方法的灵活性。

    Neural network approaches to approximate the ground state of quantum hamiltonians require the numerical solution of a highly nonlinear optimization problem. We introduce a statistical learning approach that makes the optimization trivial by using kernel methods. Our scheme is an approximate realization of the power method, where supervised learning is used to learn the next step of the power iteration. We show that the ground state properties of arbitrary gapped quantum hamiltonians can be reached with polynomial resources under the assumption that the supervised learning is efficient. Using kernel ridge regression, we provide numerical evidence that the learning assumption is verified by applying our scheme to find the ground states of several prototypical interacting many-body quantum systems, both in one and two dimensions, showing the flexibility of our approach.
    
[^96]: 通过 Numerai 数据科学竞赛案例，理解时间表格和多变量时间序列的模型复杂度

    Understanding Model Complexity for temporal tabular and multi-variate time series, case study with Numerai data science tournament. (arXiv:2303.07925v1 [cs.LG])

    [http://arxiv.org/abs/2303.07925](http://arxiv.org/abs/2303.07925)

    本文采用 Numerai 数据科学竞赛的数据，探究了多变量时间序列建模中不同特征工程和降维方法的应用；提出了一种新的集成方法，用于高维时间序列建模，该方法在通用性、鲁棒性和效率上优于一些深度学习模型。

    

    本文探究了在多变量时间序列建模中使用不同特征工程和降维方法的应用。利用从 Numerai 数据竞赛创建的特征目标交叉相关时间序列数据集，我们证明在过度参数化的情况下，不同特征工程方法的性能与预测会收敛到可由再生核希尔伯特空间刻画的相同平衡态。我们提出了一种新的集成方法，该方法结合了不同的随机非线性变换，随后采用岭回归模型进行高维时间序列建模。与一些常用的用于序列建模的深度学习模型（如 LSTM 和 transformer）相比，我们的方法更加鲁棒（在不同的随机种子下具有较低的模型方差，且对架构的选择不太敏感），并且更有效率。我们方法的另一个优势在于模型的简单性，因为没有必要使用复杂的深度学习框架。

    In this paper, we explore the use of different feature engineering and dimensionality reduction methods in multi-variate time-series modelling. Using a feature-target cross correlation time series dataset created from Numerai tournament, we demonstrate under over-parameterised regime, both the performance and predictions from different feature engineering methods converge to the same equilibrium, which can be characterised by the reproducing kernel Hilbert space. We suggest a new Ensemble method, which combines different random non-linear transforms followed by ridge regression for modelling high dimensional time-series. Compared to some commonly used deep learning models for sequence modelling, such as LSTM and transformers, our method is more robust (lower model variance over different random seeds and less sensitive to the choice of architecture) and more efficient. An additional advantage of our method is model simplicity as there is no need to use sophisticated deep learning frame
    
[^97]: 多指标适应性地识别联邦学习中的后门攻击

    Multi-metrics adaptively identifies backdoors in Federated learning. (arXiv:2303.06601v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2303.06601](http://arxiv.org/abs/2303.06601)

    本文提出了一种简单而有效的防御策略，采用多指标和动态加权的方法，能够适应性地识别联邦学习中的后门攻击。

    

    联邦学习的去中心化和保护隐私的特性使其容易受到后门攻击，这些攻击旨在操纵模型对特定敌对选择的输入的行为。然而，大多数基于统计差异的现有防御方法只对特定攻击起效，特别是当恶意梯度与良性梯度相似或数据高度非独立和同分布（non-IID）时。在本文中，我们重新审视了基于距离的防御方法，并发现在高维度中欧几里得距离变得无意义，并且单个指标无法识别具有多种特征的恶意梯度。为此，我们提出了一种简单而有效的防御策略，使用多指标和动态加权来适应性地识别后门攻击。此外，我们的新型防御策略不依赖于攻击设置或数据分布的预定义假设，并对良性性能几乎没有影响。

    The decentralized and privacy-preserving nature of federated learning (FL) makes it vulnerable to backdoor attacks aiming to manipulate the behavior of the resulting model on specific adversary-chosen inputs. However, most existing defenses based on statistical differences take effect only against specific attacks, especially when the malicious gradients are similar to benign ones or the data are highly non-independent and identically distributed (non-IID). In this paper, we revisit the distance-based defense methods and discover that i) Euclidean distance becomes meaningless in high dimensions and ii) malicious gradients with diverse characteristics cannot be identified by a single metric. To this end, we present a simple yet effective defense strategy with multi-metrics and dynamic weighting to identify backdoors adaptively. Furthermore, our novel defense has no reliance on predefined assumptions over attack settings or data distributions and little impact on benign performance. To e
    
[^98]: 一种离散道路网络设计问题的混合深度学习-元启发式框架

    A hybrid deep-learning-metaheuristic framework for discrete road network design problems. (arXiv:2303.06024v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.06024](http://arxiv.org/abs/2303.06024)

    本研究提出了一种混合框架，结合了深度学习和元启发式算法，用于离散道路网络设计问题。该框架可以快速地得到高质量的解决方案，并且可以应用于其他以图为模型的双层问题决策中。

    

    本研究提出了一种具有双层架构的混合深度学习元启发式框架，用于解决道路网络设计问题（NDPs）。我们使用图神经网络（GNN）训练来近似用户均衡（UE）交通分配问题的解，并使用训练模型进行的推理来计算遗传算法（GA）的适应度函数评估，以近似解决NDPs。通过使用两个NDP变量和一个精确求解器作为基准，我们证明了我们提出的框架可以在少于1％的时间内给出全局最优结果的5％左右的间隙内提供解决方案。我们的框架可以在专家系统中使用，用于基础设施规划，以智能地确定最佳基础设施管理决策。由于该框架的灵活性，可以轻松地适应许多可以被建模为图上双层问题的其他决策问题。此外，我们还观察到许多有趣的未来方向。

    This study proposes a hybrid deep-learning-metaheuristic framework with a bi-level architecture for road network design problems (NDPs). We train a graph neural network (GNN) to approximate the solution of the user equilibrium (UE) traffic assignment problem, and use inferences made by the trained model to calculate fitness function evaluations of a genetic algorithm (GA) to approximate solutions for NDPs. Using two NDP variants and an exact solver as benchmark, we show that our proposed framework can provide solutions within 5% gap of the global optimum results given less than 1% of the time required for finding the optimal results. Our framework can be utilized within an expert system for infrastructure planning to intelligently determine the best infrastructure management decisions. Given the flexibility of the framework, it can easily be adapted to many other decision problems that can be modeled as bi-level problems on graphs. Moreover, we observe many interesting future direction
    
[^99]: 使用扩散模型合成混合类型的电子健康记录

    Synthesizing Mixed-type Electronic Health Records using Diffusion Models. (arXiv:2302.14679v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14679](http://arxiv.org/abs/2302.14679)

    本论文研究了使用扩散模型合成混合类型电子健康记录的潜力，与现有方法相比，在数据质量、实用性和增强方面表现出更好的性能，但在隐私方面存在权衡。

    

    电子健康记录（EHRs）包含敏感的患者信息，在共享此类数据时存在隐私问题。合成数据生成是缓解这些风险的一种有希望的解决方案，通常依赖于深度生成模型，如生成对抗网络（GANs）。然而，最近的研究表明，扩散模型在GANs之上具有几个优势，例如生成更真实的合成数据和稳定的训练以生成包括图像、文本和声音在内的数据模态。在这项工作中，我们研究了扩散模型在生成真实混合类型表格EHRs方面的潜力，将TabDDPM模型与现有方法在四个数据集上进行了数据质量、实用性、隐私和增强方面的比较。我们的实验证明，除隐私方面外，TabDDPM在所有评估指标上均优于现有模型，这证实了隐私和实用性之间的权衡。

    Electronic Health Records (EHRs) contain sensitive patient information, which presents privacy concerns when sharing such data. Synthetic data generation is a promising solution to mitigate these risks, often relying on deep generative models such as Generative Adversarial Networks (GANs). However, recent studies have shown that diffusion models offer several advantages over GANs, such as generation of more realistic synthetic data and stable training in generating data modalities, including image, text, and sound. In this work, we investigate the potential of diffusion models for generating realistic mixed-type tabular EHRs, comparing TabDDPM model with existing methods on four datasets in terms of data quality, utility, privacy, and augmentation. Our experiments demonstrate that TabDDPM outperforms the state-of-the-art models across all evaluation metrics, except for privacy, which confirms the trade-off between privacy and utility.
    
[^100]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^101]: 深度残差网络中宽度和深度极限的通行

    Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.00453](http://arxiv.org/abs/2302.00453)

    本文研究了深度残差网络中宽度和深度的极限情况，发现当枝干按比例缩放时，得到的协方差结构是相同的。这一发现解释了为什么即使深度和宽度处于相同阶数的网络，标准的宽度无限、然后深度趋向无穷的方法也能提供实际洞见。此外，本文还证明了在这种情况下预激活具有高斯分布，这对贝叶斯深度学习具有直接应用。通过大量模拟实验证明了理论发现的准确性。

    

    本文研究了带有跳跃连接的深度神经网络中，当枝干按比例$1/\sqrt{depth}$缩放时，将宽度和深度趋向无穷得到的协方差结构是相同的。这解释了为什么标准的宽度无限、然后深度趋向无穷的方法对于深度和宽度处于相同阶数的网络也能提供实际洞见。我们还证明了在这种情况下，预激活具有高斯分布，这在贝叶斯深度学习中具有直接应用。我们进行了大量模拟实验，结果与理论发现非常吻合。

    We show that taking the width and depth to infinity in a deep neural network with skip connections, when branches are scaled by $1/\sqrt{depth}$ (the only nontrivial scaling), result in the same covariance structure no matter how that limit is taken. This explains why the standard infinite-width-then-depth approach provides practical insights even for networks with depth of the same order as width. We also demonstrate that the pre-activations, in this case, have Gaussian distributions which has direct applications in Bayesian deep learning. We conduct extensive simulations that show an excellent match with our theoretical findings.
    
[^102]: RobustPdM：设计抗对抗攻击的鲁棒性预测维护

    RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks. (arXiv:2301.10822v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2301.10822](http://arxiv.org/abs/2301.10822)

    本文提出了一种设计抗对抗攻击的鲁棒性预测维护系统的方法，通过分析不同类型的对抗性攻击的影响，为预测维护模型提出了一种新颖的对抗性防御技术。

    

    最先进的预测维护技术在降低复杂机器的维护成本和停机时间，提高整体生产率方面已经取得了巨大成功，通过广泛利用物联网和深度学习。不幸的是，物联网传感器和深度学习算法都容易受到网络攻击的影响。例如，深度学习算法对对抗性示例的敏感性已经被公认。然而，在预测维护领域，对抗性攻击的研究相对较少。这是因为在计算机视觉领域用于分类任务的对抗性攻击不能直接应用于多变量时间序列回归任务的预测维护领域。本文提出了一种端到端的方法来设计对抗性鲁棒的预测维护系统，通过广泛分析不同类型的对抗性攻击的影响，并为基于深度学习的预测维护模型提出了一种新颖的对抗性防御技术。

    The state-of-the-art predictive maintenance (PdM) techniques have shown great success in reducing maintenance costs and downtime of complicated machines while increasing overall productivity through extensive utilization of Internet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors and DL algorithms are both prone to cyber-attacks. For instance, DL algorithms are known for their susceptibility to adversarial examples. Such adversarial attacks are vastly under-explored in the PdM domain. This is because the adversarial attacks in the computer vision domain for classification tasks cannot be directly applied to the PdM domain for multivariate time series (MTS) regression tasks. In this work, we propose an end-to-end methodology to design adversarially robust PdM systems by extensively analyzing the effect of different types of adversarial attacks and proposing a novel adversarial defense technique for DL-enabled PdM models. First, we propose novel MTS Projected Gradient 
    
[^103]: 功能性神经网络：用于功能数据的位移不变模型及其在脑电图分类中的应用

    Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05869](http://arxiv.org/abs/2301.05869)

    功能性神经网络（FNNs）是一种新的神经网络类别，具有位移不变性和保持数据平滑性的特点。在脑电图分类任务中，FNNs的模型表现优于基准模型并能成功进行分类。

    

    对于统计模型来说，独立于位置地检测感兴趣的信号是很理想的。如果数据由某个平滑过程生成，那么这种附加结构应该被考虑进去。我们引入了一种新的神经网络类别，它们具有位移不变性并保持数据的平滑性：功能性神经网络（FNNs）。为此，我们使用功能数据分析（FDA）的方法来扩展多层感知器和卷积神经网络以适应功能数据。我们提出了不同的模型架构，证明这些模型在准确性上优于FDA的基准模型，并成功地使用FNNs对脑电图数据进行分类。

    It is desirable for statistical models to detect signals of interest independently of their position. If the data is generated by some smooth process, this additional structure should be taken into account. We introduce a new class of neural networks that are shift invariant and preserve smoothness of the data: functional neural networks (FNNs). For this, we use methods from functional data analysis (FDA) to extend multi-layer perceptrons and convolutional neural networks to functional data. We propose different model architectures, show that the models outperform a benchmark model from FDA in terms of accuracy and successfully use FNNs to classify electroencephalography (EEG) data.
    
[^104]: 面向时序表格数据的动态特征工程和模型选择方法在制度变化下的应用

    Dynamic Feature Engineering and model selection methods for temporal tabular datasets with regime changes. (arXiv:2301.00790v2 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2301.00790](http://arxiv.org/abs/2301.00790)

    本文提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。使用梯度提升决策树（GBDT）并结合dropout技术的模型具有良好的性能和泛化能力，而动态特征中和则是一种高效而不需要重新训练模型就可以应用于任何机器学习模型中的后处理技术。

    

    由于严重的非平稳性，将深度学习算法应用于时序面板数据集是困难的，这可能导致过度拟合的模型在制度变化下性能不佳。在本文中，我们提出了一种新的机器学习管道，用于在数据制度变化下对时序面板数据集的预测进行排名。管道评估不同的机器学习模型，包括梯度提升决策树（GBDT）和具有和不具有简单特征工程的神经网络。我们发现，具有dropout的GBDT模型具有高性能、稳健性和泛化能力，而且相对复杂度较低、计算成本较低。然后，我们展示了在线学习技术可以在预测后处理中用于增强结果。特别地，我们提出了动态特征中和，这是一种无需重新训练模型就可以应用于任何机器学习模型的高效过程。

    The application of deep learning algorithms to temporal panel datasets is difficult due to heavy non-stationarities which can lead to over-fitted models that under-perform under regime changes. In this work we propose a new machine learning pipeline for ranking predictions on temporal panel datasets which is robust under regime changes of data. Different machine-learning models, including Gradient Boosting Decision Trees (GBDTs) and Neural Networks with and without simple feature engineering are evaluated in the pipeline with different settings. We find that GBDT models with dropout display high performance, robustness and generalisability with relatively low complexity and reduced computational cost. We then show that online learning techniques can be used in post-prediction processing to enhance the results. In particular, dynamic feature neutralisation, an efficient procedure that requires no retraining of models and can be applied post-prediction to any machine learning model, impr
    
[^105]: 关联度测量方法的一些最新发展综述

    A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2211.04702](http://arxiv.org/abs/2211.04702)

    本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展，并提出了一个对标准Borel空间的直接推广。

    

    本文综述了与作者引入的一种新的相关系数相关的关联度测量方法的一些最新发展。并在综述的最后提出了一个对标准Borel空间（包括所有波兰空间）的直接推广，这一推广在文献中迄今被忽视。

    This paper surveys some recent developments in measures of association related to a new coefficient of correlation introduced by the author. A straightforward extension of this coefficient to standard Borel spaces (which includes all Polish spaces), overlooked in the literature so far, is proposed at the end of the survey.
    
[^106]: 面向隐私的联邦学习压缩：通过数值机制设计

    Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design. (arXiv:2211.03942v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.03942](http://arxiv.org/abs/2211.03942)

    本文提出了一种新的插值MVU机制，通过数值机制设计实现面向隐私的联邦学习压缩，具有更好的隐私效用权衡和更高的可扩展性，并在各种数据集上提供了通信高效的私有FL的SOTA结果。

    This paper proposes a new Interpolated MVU mechanism for privacy-aware compression in federated learning, which achieves a better privacy-utility trade-off and scalability through numerical mechanism design, and provides SOTA results on communication-efficient private FL on a variety of datasets.

    在私有联邦学习（FL）中，服务器聚合来自大量客户端的差分隐私更新，以训练机器学习模型。这种情况下的主要挑战是在隐私和学习模型的分类准确性以及客户端和服务器之间通信的位数之间平衡隐私。先前的工作通过设计一种隐私感知压缩机制（称为最小方差无偏（MVU）机制）来实现良好的权衡，该机制通过数值求解优化问题来确定机制的参数。本文在此基础上引入了一种新的插值过程，用于数值设计过程，从而实现更高效的隐私分析。结果是新的插值MVU机制，它更具可扩展性，具有更好的隐私效用权衡，并在各种数据集上提供了通信高效的私有FL的SOTA结果。

    In private federated learning (FL), a server aggregates differentially private updates from a large number of clients in order to train a machine learning model. The main challenge in this setting is balancing privacy with both classification accuracy of the learnt model as well as the number of bits communicated between the clients and server. Prior work has achieved a good trade-off by designing a privacy-aware compression mechanism, called the minimum variance unbiased (MVU) mechanism, that numerically solves an optimization problem to determine the parameters of the mechanism. This paper builds upon it by introducing a new interpolation procedure in the numerical design process that allows for a far more efficient privacy analysis. The result is the new Interpolated MVU mechanism that is more scalable, has a better privacy-utility trade-off, and provides SOTA results on communication-efficient private FL on a variety of datasets.
    
[^107]: 通过多重假设检验分析机器学习中的隐私泄露: Fano的教训

    Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano. (arXiv:2210.13662v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13662](http://arxiv.org/abs/2210.13662)

    本论文通过多重假设检验的方法对机器学习中的隐私泄露进行了分析，揭示了差分隐私对抗数据重建攻击的理论有效性，为相对较大的隐私参数ε值下的实践应用提供了理论支持。

    

    差分隐私(DP)是目前最广泛接受的机器学习隐私风险缓解框架。然而，在实践中，为了保护特定隐私风险，隐私参数ε需要多小仍不为人知。在这项工作中，我们研究了离散数据的数据重建攻击，并在多重假设检验框架下进行了分析。我们利用著名的Fano不等式的不同变体，推导出模型在不同ially私有训练时数据重建对手推论能力的上限。重要的是，我们证明，如果底层私有数据取值来自大小为M的集合，那么在对手获得显著推论能力之前，目标隐私参数ε可以达到O(log M)。我们的分析为DP在相对较大的ε值下对抗数据重建攻击的经验有效性提供了理论证据。

    Differential privacy (DP) is by far the most widely accepted framework for mitigating privacy risks in machine learning. However, exactly how small the privacy parameter $\epsilon$ needs to be to protect against certain privacy risks in practice is still not well-understood. In this work, we study data reconstruction attacks for discrete data and analyze it under the framework of multiple hypothesis testing. We utilize different variants of the celebrated Fano's inequality to derive upper bounds on the inferential power of a data reconstruction adversary when the model is trained differentially privately. Importantly, we show that if the underlying private data takes values from a set of size $M$, then the target privacy parameter $\epsilon$ can be $O(\log M)$ before the adversary gains significant inferential power. Our analysis offers theoretical evidence for the empirical effectiveness of DP against data reconstruction attacks even at relatively large values of $\epsilon$.
    
[^108]: 对抗性CNN扰动攻击的对称防御

    Symmetry Defense Against CNN Adversarial Perturbation Attacks. (arXiv:2210.04087v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.04087](http://arxiv.org/abs/2210.04087)

    本文提出了一种对称防御方法，通过翻转或水平翻转对称对抗样本来提高对抗性鲁棒性，同时使用子群对称性进行分类。

    This paper proposes a symmetry defense method to improve adversarial robustness by flipping or horizontally flipping symmetric adversarial samples, and uses subgroup symmetries for classification.

    卷积神经网络分类器（CNN）容易受到对抗性攻击，这些攻击会扰动原始样本以欺骗分类器，例如自动驾驶汽车的道路标志图像分类器。CNN在对称样本的分类中也缺乏不变性，因为CNN可以以不同的方式对称样本进行分类。考虑到CNN缺乏对抗性鲁棒性和CNN缺乏不变性，对称对抗样本的分类可能与其错误分类不同。本文通过设计一种对称防御来回答这个问题，在对抗者不知道防御的情况下，将对称对抗样本翻转或水平翻转后再进行分类。对于知道防御的对手，防御设计了一个Klein四个对称子群，其中包括水平翻转和像素反转对称性。对称防御使用子群对称性进行分类，以提高对抗性鲁棒性。

    Convolutional neural network classifiers (CNNs) are susceptible to adversarial attacks that perturb original samples to fool classifiers such as an autonomous vehicle's road sign image classifier. CNNs also lack invariance in the classification of symmetric samples because CNNs can classify symmetric samples differently. Considered together, the CNN lack of adversarial robustness and the CNN lack of invariance mean that the classification of symmetric adversarial samples can differ from their incorrect classification. Could symmetric adversarial samples revert to their correct classification? This paper answers this question by designing a symmetry defense that inverts or horizontally flips adversarial samples before classification against adversaries unaware of the defense. Against adversaries aware of the defense, the defense devises a Klein four symmetry subgroup that includes the horizontal flip and pixel inversion symmetries. The symmetry defense uses the subgroup symmetries in ac
    
[^109]: RALACs: 使用交互编码和光流进行自动驾驶车辆中的动作识别

    RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow. (arXiv:2209.14408v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.14408](http://arxiv.org/abs/2209.14408)

    RALACs是一种针对自动驾驶车辆中动作识别的新颖系统，通过交互编码和光流技术将动作识别应用于道路场景，并弥合了其与人类动作识别之间的差距。

    

    将动作识别应用于自动驾驶车辆（AV）环境可以增强环境模型的情境感知能力。然而，传统的动作识别研究主要关注于人类，其对于嘈杂、未剪辑、原始的RGB数据的适应性有限，限制了其在其他领域的应用。为推动动作识别在AVs中的进展和应用，本研究提出了一种新颖的二阶段动作识别系统，命名为RALACs。RALACs将动作识别问题应用于道路场景，并弥合了其与人类动作识别领域之间的差距。本研究展示了注意力层如何有助于编码agent之间的关系，并强调这种方案如何与类别无关。此外，为解决道路上agent的动态性，RALACs提出了一种新颖的方法...

    When applied to autonomous vehicle (AV) settings, action recognition can enhance an environment model's situational awareness. This is especially prevalent in scenarios where traditional geometric descriptions and heuristics in AVs are insufficient. However, action recognition has traditionally been studied for humans, and its limited adaptability to noisy, un-clipped, un-pampered, raw RGB data has limited its application in other fields. To push for the advancement and adoption of action recognition into AVs, this work proposes a novel two-stage action recognition system, termed RALACs. RALACs formulates the problem of action recognition for road scenes, and bridges the gap between it and the established field of human action recognition. This work shows how attention layers can be useful for encoding the relations across agents, and stresses how such a scheme can be class-agnostic. Furthermore, to address the dynamic nature of agents on the road, RALACs constructs a novel approach to
    
[^110]: MetaMask：重新思考自监督学习中的维度干扰问题

    MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning. (arXiv:2209.07902v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.07902](http://arxiv.org/abs/2209.07902)

    MetaMask是一种通过元学习学习的维度遮罩，用于对抗自监督学习中的维度冗余和干扰问题。

    

    作为自监督学习的成功方法，对比学习旨在学习在输入样本的扭曲之间共享的不变信息。然而，对比学习仍然存在两个持久的缺陷：任务无关信息的干扰和样本效率低下，这与平凡常数解的反复存在相关。从维度分析的角度，我们发现维度冗余和维度干扰是这些现象背后的固有问题，并提供实验证据支持了我们的观点。我们进一步提出了一个简单而有效的方法MetaMask，即通过元学习学习的维度遮罩，以对抗维度冗余和干扰。MetaMask采用冗余减少技术来解决维度冗余问题，并创新地引入了一种维度干扰解决方法。

    As a successful approach to self-supervised learning, contrastive learning aims to learn invariant information shared among distortions of the input sample. While contrastive learning has yielded continuous advancements in sampling strategy and architecture design, it still remains two persistent defects: the interference of task-irrelevant information and sample inefficiency, which are related to the recurring existence of trivial constant solutions. From the perspective of dimensional analysis, we find out that the dimensional redundancy and dimensional confounder are the intrinsic issues behind the phenomena, and provide experimental evidence to support our viewpoint. We further propose a simple yet effective approach MetaMask, short for the dimensional Mask learned by Meta-learning, to learn representations against dimensional redundancy and confounder. MetaMask adopts the redundancy-reduction technique to tackle the dimensional redundancy issue and innovatively introduces a dimens
    
[^111]: VAE解纷效果的重建损失被忽视的影响

    Overlooked Implications of the Reconstruction Loss for VAE Disentanglement. (arXiv:2202.13341v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13341](http://arxiv.org/abs/2202.13341)

    VAE解纷结果的成因有待重新审视，研究发现数据与重建损失之间的关系是解耦的主要贡献者，标准的基准数据集根据典型的VAE重建损失与感知轴之间存在意外的相关性。

    

    学习具有变分自编码器（VAEs）的解耦表示通常归因于损失的正则化组件。在这项工作中，我们强调数据与损失的重建项之间的相互作用是VAEs中解耦的主要贡献者。我们发现，标准的基准数据集根据典型的VAE重建损失会导致它们的主观真实因素与数据中的感知轴之间存在意外的相关性。我们的工作利用这种关系为在给定重建损失下构建对抗数据集的理论提供了基础。我们通过构建一个示例数据集验证了这一点，该数据集阻碍了最先进框架中的解耦效果，同时保持了人类直观的真实因素。最后，我们通过设计一种示例重建损失，再次能够感知到真实因素来重新实现解耦效果。我们的发现证明了解耦的主观性质。

    Learning disentangled representations with variational autoencoders (VAEs) is often attributed to the regularisation component of the loss. In this work, we highlight the interaction between data and the reconstruction term of the loss as the main contributor to disentanglement in VAEs. We show that standard benchmark datasets have unintended correlations between their subjective ground-truth factors and perceived axes in the data according to typical VAE reconstruction losses. Our work exploits this relationship to provide a theory for what constitutes an adversarial dataset under a given reconstruction loss. We verify this by constructing an example dataset that prevents disentanglement in state-of-the-art frameworks while maintaining human-intuitive ground-truth factors. Finally, we re-enable disentanglement by designing an example reconstruction loss that is once again able to perceive the ground-truth factors. Our findings demonstrate the subjective nature of disentanglement and t
    
[^112]: 分布式CPU/GPU架构上的超内存非负矩阵分解(NMF)

    Distributed Out-of-Memory NMF on CPU/GPU Architectures. (arXiv:2202.09518v3 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2202.09518](http://arxiv.org/abs/2202.09518)

    提出了一种分布式超内存非负矩阵分解(NMF)算法，可以在CPU/GPU架构上实现高效计算。算法通过稀疏和稠密矩阵操作以及批处理/平铺策略，有效地处理超内存问题，并利用CUDA流进行数据传输和异步计算。

    

    我们提出了一种高效的分布式超内存实现的非负矩阵分解(NMF)算法，用于异构高性能计算(HPC)系统。该实现基于NMFk的先前工作，可以自动进行模型选择并从数据中提取潜在变量和模式。在本研究中，我们通过添加对多节点、多GPU系统的稠密和稀疏矩阵操作支持，扩展了NMFk。得到的算法针对超内存问题进行了优化，其中所需内存大于可用的GPU内存来进行矩阵分解。通过批处理/平铺策略降低内存复杂度，并使用GPU核心(或者可用的张量核心)显著加速稀疏和稠密矩阵操作。使用CUDA流隐藏了主机和设备之间的批处理复制的输入/输出(I/O)延迟，以实现数据传输和异步计算的重叠，以及与收集相关的延迟。

    We propose an efficient distributed out-of-memory implementation of the Non-negative Matrix Factorization (NMF) algorithm for heterogeneous high-performance-computing (HPC) systems. The proposed implementation is based on prior work on NMFk, which can perform automatic model selection and extract latent variables and patterns from data. In this work, we extend NMFk by adding support for dense and sparse matrix operation on multi-node, multi-GPU systems. The resulting algorithm is optimized for out-of-memory (OOM) problems where the memory required to factorize a given matrix is greater than the available GPU memory. Memory complexity is reduced by batching/tiling strategies, and sparse and dense matrix operations are significantly accelerated with GPU cores (or tensor cores when available). Input/Output (I/O) latency associated with batch copies between host and device is hidden using CUDA streams to overlap data transfers and compute asynchronously, and latency associated with collect
    
[^113]: InfoNCE是识别参数化模型中的变分推断

    InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2107.02495](http://arxiv.org/abs/2107.02495)

    InfoNCE目标在识别参数化模型中等同于ELBO，在学习最优先验时变为互信息，并与自监督学习方法建立了联系。然而，实际的InfoNCE目标是对互信息的松散下界，以避免高度纠缠的表示。

    

    在这里，我们展示InfoNCE目标等同于一种新型概率生成模型——识别参数化模型（RPM）中的ELBO。当我们学习最优先验时，RPM ELBO变成了互信息（MI；除了一个常数），从而与之前存在的自监督学习方法（如InfoNCE）建立了联系。然而，实际的InfoNCE方法并不使用MI作为目标；MI对于任意可逆变换是不变的，因此使用MI目标可能导致高度纠缠的表示（Tschannen et al.，2019）。相反，实际的InfoNCE目标是对MI的一个简化下界，即使在无限样本极限下也不紧密。因此，一个有效的目标（即实际的InfoNCE目标）似乎是对一个无效的目标（即给出任意纠缠表示的真实MI）的松散下界的动机。我们给出了实际的InfoNCE目标的另一种动机。在目录中

    Here, we show that the InfoNCE objective is equivalent to the ELBO in a new class of probabilistic generative model, the recognition parameterised model (RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the mutual information (MI; up to a constant), establishing a connection to pre-existing self-supervised learning methods such as InfoNCE. However, practical InfoNCE methods do not use the MI as an objective; the MI is invariant to arbitrary invertible transformations, so using an MI objective can lead to highly entangled representations (Tschannen et al., 2019). Instead, the actual InfoNCE objective is a simplified lower bound on the MI which is loose even in the infinite sample limit. Thus, an objective that works (i.e. the actual InfoNCE objective) appears to be motivated as a loose bound on an objective that does not work (i.e. the true MI which gives arbitrarily entangled representations). We give an alternative motivation for the actual InfoNCE objective. In pa
    

