# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Differentially Private Heavy Hitter Detection using Federated Analytics.](http://arxiv.org/abs/2307.11749) | 本研究通过使用联邦分析和差分隐私，提出了一种改进基于前缀树算法的热门检测方法。通过实验，在Reddit数据集上测试了这些改进的有效性。 |
| [^2] | [Advancing Ad Auction Realism: Practical Insights & Modeling Implications.](http://arxiv.org/abs/2307.11732) | 本文提出了一个学习模型来模拟现实的在线广告拍卖环境，并发现在这样的环境中，使用"软底价"可以提高关键绩效指标，即使投标者来自相同的人群。 |
| [^3] | [Mitigating Communications Threats in Decentralized Federated Learning through Moving Target Defense.](http://arxiv.org/abs/2307.11730) | 本文针对分散式联邦学习中的通信安全挑战，引入了一个安全模块，通过结合加密技术和移动目标防御技术来对抗通信攻击。 |
| [^4] | [Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses.](http://arxiv.org/abs/2307.11714) | 本论文研究了使用切片Wasserstein损失训练神经网络时，随机梯度下降算法的收敛性，并证明了在特定条件下，SGD轨迹逼近了梯度流方程的集合。 |
| [^5] | [JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning.](http://arxiv.org/abs/2307.11704) | 本文介绍了JoinGym，一种高效的强化学习查询优化环境。通过将加入顺序选择问题形式化为马尔可夫决策过程，我们提供了一种实现，该实现完全基于离线跟踪，并且无需设置系统即可进行测试。此外，研究还提供了3300个新SQL查询的所有可能加入追踪。 |
| [^6] | [Using simulation to calibrate real data acquisition in veterinary medicine.](http://arxiv.org/abs/2307.11695) | 使用仿真环境来增强兽医学中的数据采集和诊断，特别关注犬只的步态分析。通过生成反映多样条件的合成数据集，训练机器学习算法来识别正常和异常步态，并探索了摄像头视角对模型准确性的影响。初步结果显示，这种仿真方法有望提高兽医诊断的精确性和机器学习模型的效果。 |
| [^7] | [SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design.](http://arxiv.org/abs/2307.11694) | 本文提出了一种通过上下文学习个性化药物协同作用并进行药物设计的方法，该方法利用小型的个性化数据集，不依赖于文本语料库、分子指纹或蛋白质相互作用的领域特定知识，取得了竞争性的结果。 |
| [^8] | [Interpretable Graph Networks Formulate Universal Algebra Conjectures.](http://arxiv.org/abs/2307.11688) | 提出了首次使用人工智能来研究通用代数的猜想，并引入了可解释的图网络以增强可解释性。 |
| [^9] | [Towards Generalizable Reinforcement Learning for Trade Execution.](http://arxiv.org/abs/2307.11685) | 本论文提出了一种面向通用化的交易执行的强化学习方法。研究表明，现有的强化学习方法存在过拟合问题，阻碍了实际应用。作者通过使用离线强化学习和动态上下文建模来解决过拟合问题，并提出了学习上下文的紧凑表示方法。 |
| [^10] | [Minibatching Offers Improved Generalization Performance for Second Order Optimizers.](http://arxiv.org/abs/2307.11684) | 本研究通过实证研究发现，在训练过程中使用的批次大小对于二阶优化算法的性能具有显著影响，使用小批量化可以提供改善的泛化性能，并减少超参数调整的需求。 |
| [^11] | [Fast Adaptive Test-Time Defense with Robust Features.](http://arxiv.org/abs/2307.11672) | 本文提出了一种快速适应的测试防御策略，通过投影训练好的模型到最稳健的特征空间，降低了对抗攻击的脆弱性，无需额外的测试时间计算。 |
| [^12] | [An Efficient Interior-Point Method for Online Convex Optimization.](http://arxiv.org/abs/2307.11668) | 本文描述了一种用于在线凸优化的高效内点方法，该方法在遗憾最小化方面具有最小可能值$O(\sqrt{T \log T})$，并且是自适应的。 |
| [^13] | [Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts.](http://arxiv.org/abs/2307.11661) | 本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。 |
| [^14] | [Bandits with Deterministically Evolving States.](http://arxiv.org/abs/2307.11655) | 该论文提出了一种名为具有确定性演化状态的强盗模型，用于学习带有强盗反馈的推荐系统和在线广告。该模型考虑了状态演化的不同速率，能准确评估奖励与系统健康程度之间的关系。 |
| [^15] | [Scalable Multi-agent Skill Discovery based on Kronecker Graphs.](http://arxiv.org/abs/2307.11629) | 本文提出了一种基于Kronecker图的可扩展多智能体技能发现方法，通过连接状态转换图的Fiedler向量，直接计算具有协作探索行为的多智能体技能。 |
| [^16] | [Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization.](http://arxiv.org/abs/2307.11620) | 这项工作提出了一种名为OMIGA的离线多智能体强化学习算法，通过隐式的全局到局部价值正则化，解决了离线多智能体强化学习中的挑战，并优雅地桥接了多智能体价值分解和策略学习。 |
| [^17] | [Robust Fully-Asynchronous Methods for Distributed Training over General Architecture.](http://arxiv.org/abs/2307.11617) | 该论文提出了一种强健的全异步方法（R-FAST），在分布式机器学习中解决了完美同步的低效性和不可能性问题，通过采用鲁棒的梯度跟踪策略和灵活的通信架构，消除了数据异构性和数据包丢失的影响，并实现了期望的邻域收敛。 |
| [^18] | [Learning minimal representations of stochastic processes with variational autoencoders.](http://arxiv.org/abs/2307.11608) | 本文引入了一种无监督机器学习方法，使用变分自动编码器确定最小参数集，有效描述随机过程动力学，并生成能准确复制预期随机行为的新轨迹。 |
| [^19] | [Finding Optimal Diverse Feature Sets with Alternative Feature Selection.](http://arxiv.org/abs/2307.11607) | 本文引入了替代特征选择的概念，将其形式化为优化问题，并通过约束定义了替代特征集，使用户可以控制替代的数量和差异性。我们证明了该问题的NP-hard性，并讨论了如何将传统特征选择方法作为目标集成。实验证明替代特征集确实可以具有高预测质量，同时分析了几个影响因素。 |
| [^20] | [Transferability of Convolutional Neural Networks in Stationary Learning Tasks.](http://arxiv.org/abs/2307.11588) | 本文提出了一种用于大规模空间问题的卷积神经网络(CNNs)高效训练的新框架，通过研究CNNs在底层信号为固定的任务中的性质，发现在固定信号的小窗口上训练的CNN可以在更大的窗口上取得接近的性能，无需重新训练。 |
| [^21] | [A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion.](http://arxiv.org/abs/2307.11584) | 本研究通过语音到文本的模态转换方法，在MELD数据集上提高了语音情感识别的性能，超过了基于语音的最先进方法。这表明了模态转换在替代模态任务中的潜力。 |
| [^22] | [FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks.](http://arxiv.org/abs/2307.11565) | 这项工作中提出了一种名为FMT的防御策略，通过检测并移除训练用于从输入中提取后门信息的后门特征图，从而有效防止后门攻击。 |
| [^23] | [A multi-modal representation of El Ni\~no Southern Oscillation Diversity.](http://arxiv.org/abs/2307.11552) | 通过使用低维表示，在El Ni\~no Southern Oscillation（ENSO）中发现了新的极端El Ni\~no类别，并发现它们与典型EP El Ni\~no不同。EP El Ni\~nos，CP La Ni\~nas和Extreme El Ni\~nos对跨十年尺度的ENSO最具影响力。 |
| [^24] | [Towards practical reinforcement learning for tokamak magnetic control.](http://arxiv.org/abs/2307.11546) | 这项研究致力于解决强化学习方法在托卡马克磁控制中的关键缺点，通过改进算法和训练过程，实现了更高的控制精度、减小稳态误差和缩短学习新任务所需时间，并通过实验验证了模拟结果的有效性。 |
| [^25] | [Training Latency Minimization for Model-Splitting Allowed Federated Edge Learning.](http://arxiv.org/abs/2307.11532) | 本文提出了一个允许模型切分的联合学习框架，旨在最小化训练延迟，同时不损失测试准确性。 |
| [^26] | [Multi-modal Hate Speech Detection using Machine Learning.](http://arxiv.org/abs/2307.11519) | 本研究提出了一种使用多模态系统的方法，通过提取图像特征、音频特征值和文本，结合机器学习和自然语言处理技术，来检测视频内容中的仇恨言论。 |
| [^27] | [General regularization in covariate shift adaptation.](http://arxiv.org/abs/2307.11503) | 本文研究了协变量偏移自适应中的一般正则化方法，并通过组合已有结果得到了新的结果。在弱平滑条件下证明了实现与标准监督学习中相同精度所需的样本量要比现有分析证明的少。 |
| [^28] | [Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting.](http://arxiv.org/abs/2307.11494) | 本研究提出了一种面向概率时间序列预测的自引导扩散模型，称为TSDiff。该模型不需要辅助网络或训练过程的改变，在预测、改进和合成数据生成等时间序列任务上展现出了竞争力。 |
| [^29] | [A New Deep State-Space Analysis Framework for Patient Latent State Estimation and Classification from EHR Time Series Data.](http://arxiv.org/abs/2307.11487) | 该论文提出了一个基于深度状态空间分析的框架，用于从电子健康记录时间序列数据中估计和分类病人的潜在状态。通过该框架，可以学习、可视化和聚类与疾病进展相关的病人潜在状态的时间变化，并成功发现了与预后相关的潜在状态。 |
| [^30] | [A Deep Learning Approach for Overall Survival Analysis with Missing Values.](http://arxiv.org/abs/2307.11465) | 提出了一个深度学习模型，通过有效利用被审查和未被审查病人的信息，预测非小细胞肺癌（NSCLC）病人的整体生存。 |
| [^31] | [Improve Long-term Memory Learning Through Rescaling the Error Temporally.](http://arxiv.org/abs/2307.11462) | 本研究通过时间上重新缩放错误度量，改善了长期记忆学习的偏向于短期记忆的问题，并缓解了梯度消失的困扰。数值实验验证了适当的时间上重新缩放错误在有效的长期记忆学习中的重要性。 |
| [^32] | [Neural Operators for Delay-Compensating Control of Hyperbolic PIDEs.](http://arxiv.org/abs/2307.11436) | 该论文提出了延迟补偿超bolic PIDE控制的神经算子框架，扩展了基本PDE控制结果到一个涉及状态和系统延迟的高级超bolic类。使用DeepONet逼近算子，可以在无限维度上建立稳定的闭环反馈，并开发了逼近的观测者和输出反馈定律。 |
| [^33] | [Batching for Green AI -- An Exploratory Study on Inference.](http://arxiv.org/abs/2307.11434) | 这项研究探讨了在深度学习模型推理阶段引入批处理对能源消耗和响应时间的影响，并发现批处理对这两个指标都有显著影响。 |
| [^34] | [An Analysis of Multi-Agent Reinforcement Learning for Decentralized Inventory Control Systems.](http://arxiv.org/abs/2307.11432) | 本研究提出了一种多智能体强化学习的去中心化数据驱动库存管理问题的解决方案，通过将问题分解为子问题并控制每个实体的智能体，通过模拟不同供应链网络和不确定性水平，研究了三种多智能体变体的近端策略优化算法。 |
| [^35] | [Attention to Entropic Communication.](http://arxiv.org/abs/2307.11423) | 该论文研究了在通信理论中结合注意力和相对熵的概念。研究发现，在通信中使用注意力导向的加权相对熵是不适当的，而适当的注意力通信可通过发送者仅需要了解接收者的效用函数来实现最佳通知。 |
| [^36] | [Direct and inverse modeling of soft robots by learning a condensed FEM model.](http://arxiv.org/abs/2307.11408) | 本研究使用学习方法通过简化有限元方法模型，实现了对软体机器人的直接和逆向建模，并证明了这种紧凑模型在建模效果和效率上的优势。 |
| [^37] | [Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation.](http://arxiv.org/abs/2307.11397) | 本文提出了一种新颖的概率模型Pionono，用于医学图像分割中的观察者间和观察者内变异。该模型通过捕捉每个标记者的标记行为并将其与图像特征集成，产生概率分割预测。实验证明Pionono在准确性和效率上优于现有模型，并且可以预测多个一致的分割图，为诊断过程提供了宝贵的信息。 |
| [^38] | [Towards Better Fairness-Utility Trade-off: A Comprehensive Measurement-Based Reinforcement Learning Framework.](http://arxiv.org/abs/2307.11379) | 本论文提出了一种基于综合测量的强化学习框架CFU，旨在有效改善机器学习分类器中的公正性-效用权衡问题。 |
| [^39] | [LatentAugment: Data Augmentation via Guided Manipulation of GAN's Latent Space.](http://arxiv.org/abs/2307.11375) | LatentAugment是一种通过引导操纵GAN的潜在空间进行数据增强的策略，解决了标准数据增强的低多样性问题，提供了更多样化和真实性更高的合成图像样本。 |
| [^40] | [Diverse Offline Imitation via Fenchel Duality.](http://arxiv.org/abs/2307.11373) | 本文提出了一个离线技能发现算法，通过Fenchel对偶方法将强化学习和无监督技能发现结合起来，实现学习与专家相一致的多样的技能。 |
| [^41] | [Random Separating Hyperplane Theorem and Learning Polytopes.](http://arxiv.org/abs/2307.11371) | 通过随机选择的超平面，我们提出了随机分离超平面定理（RSH）来加强分离超平面定理，利用RSH我们得到了多面体学习中的算法应用。 |
| [^42] | [Bridging the Reality Gap of Reinforcement Learning based Traffic Signal Control using Domain Randomization and Meta Learning.](http://arxiv.org/abs/2307.11357) | 该论文研究了基于强化学习的交通信号控制中的现实差距问题，并提出了两种缩小现实差距的策略：域随机化和模型无关元学习。这些策略在一个交通仿真模型上进行了训练，并在不同的交通仿真模型上进行了性能评估。 |
| [^43] | [What can a Single Attention Layer Learn? A Study Through the Random Features Lens.](http://arxiv.org/abs/2307.11353) | 本研究通过随机特征分析，对单个注意层的学习和泛化进行了严格的理论研究。结果表明，在具有随机采样的关键矩阵和可训练值矩阵的情况下，随机特征注意层可以表示一类与关键向量置换无关的目标函数，并提供了学习这些目标函数的风险界限。 |
| [^44] | [Model-based Offline Reinforcement Learning with Count-based Conservatism.](http://arxiv.org/abs/2307.11352) | 本文提出了一种基于模型的离线强化学习方法$\texttt{Count-MORL}$，通过利用计数保守性来量化模型估计误差，证明了基于计数保守性在离线深度强化学习中的有效性，并展示了学习到的策略提供了接近最优性能的保证。 |
| [^45] | [Bounded P-values in Parametric Programming-based Selective Inference.](http://arxiv.org/abs/2307.11351) | 本研究提出了一种降低参数规划选择性推断计算成本的方法，通过计算p值的上界和下界来保证所需精度。 |
| [^46] | [Improving Transferability of Adversarial Examples via Bayesian Attacks.](http://arxiv.org/abs/2307.11334) | 通过将贝叶斯公式应用于模型参数和模型输入，本文提出了一种改进对抗性样本可迁移性的方法，实证研究表明具有显著提高效果，并超过了当前最新技术。 |
| [^47] | [Demystifying Local and Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition.](http://arxiv.org/abs/2307.11333) | 本文利用信息论的部分信息分解（PID）方法，研究了在联邦学习中关于敏感属性的群体公平性权衡问题。通过分解发现了三种不公平来源，分别是唯一不平等性、冗余不平等性和掩盖不平等性，揭示了全局和局部公平性之间的基本限制和权衡。 |
| [^48] | [Beyond Convergence: Identifiability of Machine Learning and Deep Learning Models.](http://arxiv.org/abs/2307.11332) | 本研究探讨了机器学习和深度学习模型中的参数可识别性。通过一个运动传感器数据的参数估计案例研究，发现虽然某些参数可以从观测数据中识别出来，但其他参数仍然不可识别。这表明不可识别性是实验设置的固有限制，需要改变数据收集方法。 |
| [^49] | [Systematic Adaptation of Communication-focused Machine Learning Models from Real to Virtual Environments for Human-Robot Collaboration.](http://arxiv.org/abs/2307.11327) | 该论文研究了如何将在真实环境中表现良好的深度学习模型适应到虚拟环境中，以实现人机合作中自然和直观的手势识别。 |
| [^50] | [Analysis of Elephant Movement in Sub-Saharan Africa: Ecological, Climatic, and Conservation Perspectives.](http://arxiv.org/abs/2307.11325) | 本研究分析了萨赫勒以南非洲象移动的模式，重点关注了季节变化和降雨模式等动态驱动因素。研究结果有助于预测生态因素对象迁徙的潜在影响，并为制定保护策略提供了综合的视角。 |
| [^51] | [XLDA: Linear Discriminant Analysis for Scaling Continual Learning to Extreme Classification at the Edge.](http://arxiv.org/abs/2307.11317) | 本文提出了一种名为 XLDA 的框架，可在边缘上进行极端分类，其中使用的线性判别分析（LDA）分类器等效于全连接（FC）层，通过优化实现了加速训练和推理的方法，并在极端数据集上进行了验证。 |
| [^52] | [Making Pre-trained Language Models both Task-solvers and Self-calibrators.](http://arxiv.org/abs/2307.11316) | 该论文研究了如何使预训练语言模型成为任务解决器和自校准器，在有限的训练样本、数据不平衡和其他实际挑战下进行了探索。 |
| [^53] | [Neuromorphic Online Learning for Spatiotemporal Patterns with a Forward-only Timeline.](http://arxiv.org/abs/2307.11314) | 本论文提出了一种基于神经形态学的在线学习算法，用于时空模式识别。该算法适用于在线学习脉冲神经网络，并且能够学习突触权重和调整时间滤波器，具有较低的计算和存储成本。 |
| [^54] | [PI-VEGAN: Physics Informed Variational Embedding Generative Adversarial Networks for Stochastic Differential Equations.](http://arxiv.org/abs/2307.11289) | PI-VEGAN是一种物理信息神经网络，通过将控制物理定律融入模型并引入变分编码器来解决随机微分方程的各种问题。 |
| [^55] | [Kernelized Offline Contextual Dueling Bandits.](http://arxiv.org/abs/2307.11288) | 本论文提出了基于内核的离线背景双向竞标者算法，用于解决基于偏好反馈的问题，并证明了算法的遗憾界。通过实验证明该方法优于使用均匀采样上下文的相似策略。 |
| [^56] | [MAS: Towards Resource-Efficient Federated Multiple-Task Learning.](http://arxiv.org/abs/2307.11285) | 本研究提出了第一个有效协调和训练多个同时进行的联邦学习任务的联邦学习系统MAS，通过合并和分割联邦学习任务来优化性能，实验证明其在减少训练时间的同时超过其他方法。 |
| [^57] | [Epsilon*: Privacy Metric for Machine Learning Models.](http://arxiv.org/abs/2307.11280) | Epsilon*是一种用于测量机器学习模型隐私风险的新度量方法，不需要访问训练数据或模型训练算法，能与成员推断攻击中的假设检验相结合，提供对经过训练的模型实例隐私损失的下界，避免数值和噪声放大不稳定性。 |
| [^58] | [Screening Mammography Breast Cancer Detection.](http://arxiv.org/abs/2307.11274) | 本研究提出了一种自动化乳腺癌检测解决方案，旨在提高筛查程序的效率和准确性，通过在RSNA数据集上测试不同的方法，得出了平均验证案例pF1得分为0.56。 |
| [^59] | [On the Fisher-Rao Gradient of the Evidence Lower Bound.](http://arxiv.org/abs/2307.11249) | 本文研究了证据下界的Fisher-Rao梯度，揭示了它与目标分布的Kullback-Leibler散度梯度的关系，进一步证明了最小化主要目标函数与最大化ELBO的等价性。 |
| [^60] | [On-Sensor Data Filtering using Neuromorphic Computing for High Energy Physics Experiments.](http://arxiv.org/abs/2307.11242) | 本文研究了在高能物理实验中利用神经形态计算的尖峰神经网络（SNN）模型对传感器数据进行滤波的方法。通过将传入的电荷波形转换为二值事件流，并优化SNN的系统设计和超参数，我们得到了信号有效率约为91%的SNN模型，参数数量几乎是深度神经网络的一半。 |
| [^61] | [Edgewise outliers of network indexed signals.](http://arxiv.org/abs/2307.11239) | 该论文研究了涉及依赖关系的网络索引多变量数据模型，并介绍了边缘离群值的概念。通过推导平方和的分布和提出鲁棒版本的边缘MCD算法，实现了离群值的检测。模拟数据和真实数据的应用结果验证了方法的实用性。 |
| [^62] | [QDC: Quantum Diffusion Convolution Kernels on Graphs.](http://arxiv.org/abs/2307.11234) | 本论文提出了一种新的卷积核，通过根据顶点占据相关性对图进行有效重连，以实现传播量子粒子的扩散范式。此外，还引入了一种多尺度变种，结合了传统的拉普拉斯算子和新的卷积核。通过研究我们发现同质化的谱依赖性和量子动力学在带通滤波器构造中的重要性。 |
| [^63] | [From Adaptive Query Release to Machine Unlearning.](http://arxiv.org/abs/2307.11228) | 该论文将机器取消学习问题形式化为设计高效的取消学习算法，给出了线性和前缀和查询类的高效取消学习算法，以及应用于随机凸优化问题的改进保证。 |
| [^64] | [Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models.](http://arxiv.org/abs/2307.11224) | Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。 |
| [^65] | [FairMobi-Net: A Fairness-aware Deep Learning Model for Urban Mobility Flow Generation.](http://arxiv.org/abs/2307.11214) | FairMobi-Net是一种注重公平性的深度学习模型，用于生成跨区域的真实人流。它在损失函数中唯一地引入了公平性损失，并采用二进制分类和数值回归技术的混合方法。模型经过四个美国城市的全面验证，并能够预测人类流动。 |
| [^66] | [The Effect of Epidemiological Cohort Creation on the Machine Learning Prediction of Homelessness and Police Interaction Outcomes Using Administrative Health Care Data.](http://arxiv.org/abs/2307.11211) | 这项研究使用行政卫生保健数据探索了流行病学队列创建对于预测无家可归和警察互动结果的机器学习模型的影响，并比较了不同观察窗口的模型性能。 |
| [^67] | [Clinical Trial Active Learning.](http://arxiv.org/abs/2307.11209) | 这项研究提出了一种考虑临床试验中非独立同分布结构的新型主动学习方法，并将其应用于光学相干断层扫描图像的疾病检测。研究表明，这种前瞻性主动学习方法能够克服传统方法的局限。 |
| [^68] | [Heuristic Hyperparameter Choice for Image Anomaly Detection.](http://arxiv.org/abs/2307.11197) | 本研究针对图像异常检测问题提出了一种启发式方法，通过选择适当的超参数，实现对深度特征的降维，以减少冗余特征并提高性能。 |
| [^69] | [Exploring reinforcement learning techniques for discrete and continuous control tasks in the MuJoCo environment.](http://arxiv.org/abs/2307.11166) | 该论文研究了在MuJoCo环境中离散和连续控制任务的强化学习方法，通过比较不同算法，发现DDPG在少量episode中表现优于其他方法。 |
| [^70] | [Contrastive Graph Pooling for Explainable Classification of Brain Networks.](http://arxiv.org/abs/2307.11133) | 本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。 |
| [^71] | [Synthetic Control Methods by Density Matching under Implicit Endogeneitiy.](http://arxiv.org/abs/2307.11127) | 本文提出了一种新型的合成对照方法，通过密度匹配来解决现有SCMs中的隐式内生性问题。该方法通过将经过处理单元的结果密度与未处理单元的密度进行加权平均来估计SC权重。 |
| [^72] | [A Markov Chain Model for Identifying Changes in Daily Activity Patterns of People Living with Dementia.](http://arxiv.org/abs/2307.11126) | 使用马尔可夫链模型，该研究分析了患有痴呆症的人在日常活动模式中的变化并发现了营养不良和脱水等极端行为变化的影响，并考察了COVID-19大流行对这些变化的影响。 |
| [^73] | [Diffusion Models for Probabilistic Deconvolution of Galaxy Images.](http://arxiv.org/abs/2307.11122) | 使用无条件扩散模型进行星系图像的PSF反褪色，捕捉到了更多的样本多样性。 |
| [^74] | [Comparison between transformers and convolutional models for fine-grained classification of insects.](http://arxiv.org/abs/2307.11112) | 本文对比了变压器和卷积模型在昆虫细粒度分类中的应用。这项研究对于解决物种鉴定中的困难非常有帮助，并为自动图像分类提供了新的洞见。 |
| [^75] | [Flatness-Aware Minimization for Domain Generalization.](http://arxiv.org/abs/2307.11108) | 本文提出了一种平坦度感知最小化算法（FAD），用于针对领域推广问题。通过同时优化零阶和一阶平坦度，FAD在各种领域推广数据集上表现出卓越的性能，并能发现更平坦的最优解。 |
| [^76] | [The importance of feature preprocessing for differentially private linear optimization.](http://arxiv.org/abs/2307.11106) | 本论文研究了差分隐私线性优化中特征预处理的重要性。在简单的线性分类情况下，与非隐私优化相比，特征预处理对于差分隐私优化是至关重要的，否则会产生与特征最大范数成比例的隐私错误。我们提出了一种结合特征预处理的算法DPSGD-F。 |
| [^77] | [Technical Challenges of Deploying Reinforcement Learning Agents for Game Testing in AAA Games.](http://arxiv.org/abs/2307.11105) | 本文介绍了在AAA游戏测试中部署强化学习代理所面临的技术挑战，并提出了一些帮助游戏行业采用这项技术的研究方向。 |
| [^78] | [Solving multiphysics-based inverse problems with learned surrogates and constraints.](http://arxiv.org/abs/2307.11099) | 本论文将学习代理和学习约束相结合用于解决基于多物理的反问题，通过该方法不仅改善了对流体流动性质的反演精度，而且为反演多模态数据提供了一个有效的解决方案。 |
| [^79] | [Towards the Better Ranking Consistency: A Multi-task Learning Framework for Early Stage Ads Ranking.](http://arxiv.org/abs/2307.11096) | 本论文提出了一种多任务学习框架，用于早期广告排序，以解决早期阶段和最终阶段排序之间的一致性问题。 |
| [^80] | [Modular DFR: Digital Delayed Feedback Reservoir Model for Enhancing Design Flexibility.](http://arxiv.org/abs/2307.11094) | 这项研究提出了一种适用于全数字实现的模块化DFR模型，通过减少超参数数量和选择非线性函数灵活性，提高精度和降低功耗。对比现有实现，该模型实现了10倍的功耗降低和5.3倍的吞吐量提升。 |
| [^81] | [Confidence intervals for performance estimates in 3D medical image segmentation.](http://arxiv.org/abs/2307.10926) | 本文研究了医学图像分割中性能估计的置信区间，通过实验发现参数置信区间的宽度与分割问题的特点有关。 |
| [^82] | [Detecting deceptive reviews using text classification.](http://arxiv.org/abs/2307.10617) | 这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。 |
| [^83] | [SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning.](http://arxiv.org/abs/2307.10579) | 提出了一种通过多目标联邦学习来调优SecureBoost超参数的方法，以找到在效用、效率和隐私之间最佳平衡的一组超参数解决方案。 |
| [^84] | [A Competitive Learning Approach for Specialized Models: A Solution for Complex Physical Systems with Distinct Functional Regimes.](http://arxiv.org/abs/2307.10496) | 本论文提出了一种用于复杂物理系统的竞争学习方法，通过同时训练多个模型，并使用动态损失函数识别不同的功能区域。实验证明该方法能够成功地解决模型发现和函数拟合问题。 |
| [^85] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^86] | [ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats.](http://arxiv.org/abs/2307.09782) | ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。 |
| [^87] | [MolFM: A Multimodal Molecular Foundation Model.](http://arxiv.org/abs/2307.09484) | MolFM是一种多模态分子基础模型，通过跨模态关注实现了分子结构、文本和知识图谱之间的联合表示学习。 |
| [^88] | [Computing the gradients with respect to all parameters of a quantum neural network using a single circuit.](http://arxiv.org/abs/2307.08167) | 该论文提出了一种使用单个电路计算量子神经网络所有参数梯度的方法，相比传统方法，它具有较低的电路深度和较少的编译时间，从而加速了总体运行时间。 |
| [^89] | [Provably Faster Gradient Descent via Long Steps.](http://arxiv.org/abs/2307.06324) | 本研究通过计算机辅助分析技术，证明了非常数步长策略下的梯度下降方法经过长距离步骤可以实现更快的收敛速度。 |
| [^90] | [Quantitative CLTs in Deep Neural Networks.](http://arxiv.org/abs/2307.06092) | 本文研究了具有随机高斯权重和偏置的全连接神经网络的分布，得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限，证明了随机全连接网络与相应的无限宽高斯过程之间的距离按照 $n^{-\gamma}$ 缩放，界限在网络宽度的依赖性方面优于以前的研究。 |
| [^91] | [Bayesian taut splines for estimating the number of modes.](http://arxiv.org/abs/2307.05825) | 本研究提出了一种贝叶斯紧系数样条方法，用于估计概率密度函数中模式的数量。该方法结合了核估计器和组合样条，实现了特征探索、模型选择和模式检验，并允许引入专家判断。通过在体育分析中的案例研究中的验证，证明了该方法的实用性。 |
| [^92] | [SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks.](http://arxiv.org/abs/2307.02953) | 这个论文提出了一种轻量级的医学图像分割网络SegNetr，通过引入SegNetr块和信息保留跳跃连接实现了动态的局部-全局交互和编码器-解码器特征的精确融合。 |
| [^93] | [Sound Demixing Challenge 2023 -- Music Demixing Track Technical Report.](http://arxiv.org/abs/2306.09382) | 本文介绍了2023年声音分离挑战赛音乐分离赛道的两个有效方法，分别是时效高的源分离网络和适用于噪声鲁棒性源分离的损失掩模方法。 |
| [^94] | [IsoEx: an explainable unsupervised approach to process event logs cyber investigation.](http://arxiv.org/abs/2306.09260) | IsoEx是一种可解释的无监督方法，用于处理事件日志的网络安全调查。它通过利用命令行的日志结构和父/子关系来检测异常和潜在问题命令行，准确性高于传统方法。 |
| [^95] | [Deep learning based Meta-modeling for Multi-objective Technology Optimization of Electrical Machines.](http://arxiv.org/abs/2306.09087) | 本文利用变分自编码器（VAE）在高维设计空间中同时优化了异步电机和永磁同步电机两种不同的电机技术，通过深度神经网络和解码器作为元模型，预测关键性能指标并生成新的设计。与经典的基于深度学习的直接方法相比，VAE方法表现出更好的性能。 |
| [^96] | [Self-Supervised Hyperspectral Inpainting with the Optimisation inspired Deep Neural Network Prior.](http://arxiv.org/abs/2306.07308) | 本文提出了一种自监督的高光谱图像修复算法LRS-PnP-DIP，该算法能够在高光谱图像中精确预测缺失像素和带，其在实验中表现优异，达到或超过了其他学习方法。 |
| [^97] | [High-dimensional and Permutation Invariant Anomaly Detection.](http://arxiv.org/abs/2306.03933) | 该研究引入了一种置换不变的高维密度估计方法，通过学习后将其用于高能物理数据中的异常检测，能够有效地识别出在仅具备背景假设下排除异常的喷注。 |
| [^98] | [Reduction of finite sampling noise in quantum neural networks.](http://arxiv.org/abs/2306.01639) | 介绍方差规范化技术方法，减小量子神经网络的有限采样噪声，在QNN的构造妥善的情况下，无需额外电路计算，测试发现可以显著地降低噪声水平及加快训练速度。 |
| [^99] | [Continual Learning for Abdominal Multi-Organ and Tumor Segmentation.](http://arxiv.org/abs/2306.00988) | 本文针对腹部多器官和肿瘤分割提出了一种持续学习方法，通过使用高质量伪标签缓解灾难性遗忘问题，并设计了一种创新架构，通过替换输出层为一组轻量级的、类别特定的头部来适应新出现的类别。 |
| [^100] | [Conditional Diffusion Models for Semantic 3D Medical Image Synthesis.](http://arxiv.org/abs/2305.18453) | 这篇论文提出了Med-DDPM，一种使用扩散模型进行语义化三维医学图像合成的创新解决方案，它通过控制像素级掩码标签的生成过程，能够生成高质量逼真的医学图像，并且在精度、稳定性和多样性等指标上优于GAN技术，也优于传统的增强技术和GAN合成图像。 |
| [^101] | [Shift-Robust Molecular Relational Learning with Causal Substructure.](http://arxiv.org/abs/2305.18451) | 本文提出了一种鲁棒性强的分子关系学习模型CMRL，通过检测与化学反应因果相关的核心亚结构来应对分子关系学习中的数据分布变化。 |
| [^102] | [Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II.](http://arxiv.org/abs/2305.17282) | 本文研究了k近邻学习规则中的普遍一致性，发现在可分度量空间中，该规则在Nagata维度下的sigma有限维度的空间中是普遍一致的，在非阿基米德度量空间中是强普遍一致的，此规则在具有de Groot有限维度意义下的度量空间和Heisenberg群中也是普遍一致的。 |
| [^103] | [Is Your Model "MADD"? A Novel Metric to Evaluate Algorithmic Fairness for Predictive Student Models.](http://arxiv.org/abs/2305.15342) | 本文提出一种新的度量标准，即MADD，可以独立于预测性能分析模型的歧视行为。研究者还提供了可视化分析的补充来帮助进行人类评估。 |
| [^104] | [Asynchronous Multi-Model Federated Learning over Wireless Networks: Theory, Modeling, and Optimization.](http://arxiv.org/abs/2305.13503) | 本文提出了MA-FL，应用异步模型传输体系结构来实现有多个下游任务需要训练的联邦学习。本文的收敛性分析揭示了资源分配、设备调度和个体模型状态对机器学习模型性能的影响。实验表明，MA-FL在收敛速度和模型精度方面优于现有的联邦学习方法。 |
| [^105] | [Editable User Profiles for Controllable Text Recommendation.](http://arxiv.org/abs/2304.04250) | 本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。 |
| [^106] | [Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness.](http://arxiv.org/abs/2303.17555) | 本文通过批判性回顾AI公平性文献中30篇交织性讨论，揭示研究人员普遍缺乏对交织性的整体理解，其一方面将其缩小为在群体子组上进行公平度量的优化，另一方面则在社会背景和权力结构的讨论方面存在欠缺。 |
| [^107] | [MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation.](http://arxiv.org/abs/2303.09975) | MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。 |
| [^108] | [StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces.](http://arxiv.org/abs/2303.06146) | 本文提出了StyleGANEX，一种基于StyleGAN的超出裁剪对齐人脸的操纵方法，通过使用扩张卷积来调整感受野，实现了对不对齐人脸的更好描述和各种操纵任务的有效性验证。 |
| [^109] | [Modeling Events and Interactions through Temporal Processes -- A Survey.](http://arxiv.org/abs/2303.06067) | 该调查研究通过时间过程建模事件序列的概率模型，并通过简单、标记和时空点过程分类，对基于深度学习的现有方法进行系统回顾，并分析了应用于预测和建模方面的场景。 |
| [^110] | [Tight Bounds for $\gamma$-Regret via the Decision-Estimation Coefficient.](http://arxiv.org/abs/2303.03327) | 本论文通过决策估计系数对任意结构化赌臂问题的$\gamma$-遗憾进行了紧密界定，该界定是对函数类的统计复杂度参数$\gamma$-DEC的修改版本。作者发现$\gamma$-DEC是任何模型类$\mathcal{F}$的基本限制，对于任何算法都存在某个$f \in \mathcal{F}$，该算法的$\gamma$-遗憾与$\mathcal{F}$的$\gamma$-DEC几乎成正比。 |
| [^111] | [On Provable Copyright Protection for Generative Models.](http://arxiv.org/abs/2302.10870) | 该论文研究了可证明版权保护生成模型的问题，提出了近无阻碍性（NAF）的定义，并给出了满足该定义的模型输出与受版权保护数据相似样本的概率上限。同时，还提供了生成模型学习算法，能够高效输出具有强大版权保护能力的生成模型。最后，进行了有前景的语言和图像生成模型实验。 |
| [^112] | [Simplifying Momentum-based Riemannian Submanifold Optimization.](http://arxiv.org/abs/2302.09738) | 本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。 |
| [^113] | [Multiresolution Graph Transformers and Wavelet Positional Encoding for Learning Hierarchical Structures.](http://arxiv.org/abs/2302.08647) | 该论文提出了多分辨率图形变换器（MGT）和小波位置编码（WavePE）方法，可以学习表示大分子的分层结构，并在众多数据集上获得了比其他先进方法更好的结果。 |
| [^114] | [Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames.](http://arxiv.org/abs/2302.04973) | 本文介绍了一种通过以槽为中心的参考框架来改进对象发现的方法，通过在Slot Attention中融入空间对称性，可以大幅提高数据效率和整体对象发现效果。 |
| [^115] | [Shortcut Detection with Variational Autoencoders.](http://arxiv.org/abs/2302.04246) | 本文提出了一个使用变分自动编码器来检测图像和音频数据集中快捷方式的新方法，并在几个实际数据集上展示了其有效性。 |
| [^116] | [Identifying the Hazard Boundary of ML-enabled Autonomous Systems Using Cooperative Co-Evolutionary Search.](http://arxiv.org/abs/2301.13807) | 本研究致力于通过合作协同进化搜索，确定机器学习自主系统中的ML组件的危险边界。这种边界可以用于构建安全监视器，并在达到危险边界时采取预定义的回退机制。 |
| [^117] | [SpArX: Sparse Argumentative Explanations for Neural Networks.](http://arxiv.org/abs/2301.09559) | 该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。 |
| [^118] | [A Convergence Rate for Manifold Neural Networks.](http://arxiv.org/abs/2212.12606) | 该论文研究了流形神经网络的收敛速率，通过建立一个与环境维度无关但与流形内在维度相关的收敛速率，对先前的工作进行了改进。 |
| [^119] | [A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle Scattering Problem.](http://arxiv.org/abs/2212.08736) | 本文提出了一种神经网络热启动方法，用于解决声学障碍物散射问题的逆问题。该方法通过在计算散射场和给定测量数据之间的$L^2$距离的区域边界中找到良好的初始猜测，以克服计算上的挑战。 |
| [^120] | [A Unified Algorithm Framework for Unsupervised Discovery of Skills based on Determinantal Point Process.](http://arxiv.org/abs/2212.00211) | 本文提出了一个使用确定性点过程（DPP）的统一算法框架，实现了对无监督技能发现的多样性和覆盖性的显式优化。 |
| [^121] | [Monotonic Risk Relationships under Distribution Shifts for Regularized Risk Minimization.](http://arxiv.org/abs/2210.11589) | 本文研究了在分布转移写下，期望模型在两个分布上性能存在单调关系的条件，利用岭正则化通用线性模型证明了平方误差的精确渐近线性关系和误分类误差的单调关系，以及线性逆问题的近似线性关系。 |
| [^122] | [Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems.](http://arxiv.org/abs/2210.03297) | 在目标机器学习系统中加入预处理器可以有效提高对基于查询的攻击的防御能力。预处理器引入输入空间的不变性，攻击者需要大量的查询才能重新发现或克服这种不变性。通过逆向工程预处理器并利用提取的信息攻击端到端系统可以绕过这些预处理器的防御。 |
| [^123] | [Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis.](http://arxiv.org/abs/2205.09702) | 这项研究深入分析了并行和分布式图神经网络，在设计了并行性分类方法后，研究了各种GNN模型、任务、软件框架和硬件加速器中的并行性，并重点关注相关张量的稀疏性/密度。 |
| [^124] | [Torchhd: An Open Source Python Library to Support Research on Hyperdimensional Computing and Vector Symbolic Architectures.](http://arxiv.org/abs/2205.09208) | Torchhd是一个高性能的开源Python库，旨在支持超维计算和向量符号体系研究。它提供了最先进的功能，易于使用的界面，并且能够使实验运行速度提高多达100倍。 |
| [^125] | [Multi-scale Attention Flow for Probabilistic Time Series Forecasting.](http://arxiv.org/abs/2205.07493) | 本论文提出了一种名为Multi-scale Attention Normalizing Flow(MANF)的非自回归深度学习模型，通过整合多尺度注意力和相对位置信息，实现多变量时间序列的精确分布建模，并且避免了累积误差的影响和增加时间复杂度的问题。 |
| [^126] | [The activity-weight duality in feed forward neural networks: The geometric determinants of generalization.](http://arxiv.org/abs/2203.10736) | 这项研究发现了在前馈神经网络中，神经元活动的变化与连接到下一层神经元的权重变化之间的准确对偶关系。通过这种对偶性，我们能够将输入数据的变化映射到对应的权重变化，并发现泛化损失可以通过解的损失函数的Hessian矩阵的特征方向的几何因子的乘积来表示。 |
| [^127] | [Learning Multi-agent Skills for Tabular Reinforcement Learning using Factor Graphs.](http://arxiv.org/abs/2201.08227) | 本论文提出了一个方法可以直接在多智能体场景中计算多智能体技能，通过智能体之间的合作性探索行为来改善联合状态空间的连通性。 |
| [^128] | [CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning.](http://arxiv.org/abs/2109.14778) | CALDA是一种新颖的框架，使用对比学习和对抗学习的原则来提高多源时间序列域自适应方法。它通过对齐特征表示和利用跨域标签信息来提高性能。 |
| [^129] | [Is Homophily a Necessity for Graph Neural Networks?.](http://arxiv.org/abs/2106.06134) | “同质性对于良好的图神经网络性能是否必要的”这一问题在研究中得到了重新评估。实验证明，标准的图卷积网络（GCNs）在一些常用的异质性图上可以实现比精心设计的方法更好的性能。 |

# 详细

[^1]: 使用联邦分析的差分隐私热门检测

    Differentially Private Heavy Hitter Detection using Federated Analytics. (arXiv:2307.11749v1 [cs.LG])

    [http://arxiv.org/abs/2307.11749](http://arxiv.org/abs/2307.11749)

    本研究通过使用联邦分析和差分隐私，提出了一种改进基于前缀树算法的热门检测方法。通过实验，在Reddit数据集上测试了这些改进的有效性。

    

    本研究研究了改进基于前缀树算法的差分隐私热门检测的实用启发式方法。我们的模型假设每个用户都有多个数据点，目标是学习跨所有用户数据的尽可能多的最常见数据点，并使用聚合和本地差分隐私。我们提出了一种自适应超参数调整算法，提高了算法的性能，同时满足计算、通信和隐私约束。我们探讨了不同的数据选择方案的影响，以及在多次运行算法时引入拒绝列表的影响。我们使用Reddit数据集进行广泛的实验来测试这些改进。

    In this work, we study practical heuristics to improve the performance of prefix-tree based algorithms for differentially private heavy hitter detection. Our model assumes each user has multiple data points and the goal is to learn as many of the most frequent data points as possible across all users' data with aggregate and local differential privacy. We propose an adaptive hyperparameter tuning algorithm that improves the performance of the algorithm while satisfying computational, communication and privacy constraints. We explore the impact of different data-selection schemes as well as the impact of introducing deny lists during multiple runs of the algorithm. We test these improvements using extensive experimentation on the Reddit dataset~\cite{caldas2018leaf} on the task of learning the most frequent words.
    
[^2]: 推进广告拍卖的现实性：实际见解与建模影响

    Advancing Ad Auction Realism: Practical Insights & Modeling Implications. (arXiv:2307.11732v1 [cs.LG])

    [http://arxiv.org/abs/2307.11732](http://arxiv.org/abs/2307.11732)

    本文提出了一个学习模型来模拟现实的在线广告拍卖环境，并发现在这样的环境中，使用"软底价"可以提高关键绩效指标，即使投标者来自相同的人群。

    

    本文提出了一个在线广告拍卖学习模型，允许考虑当代在线拍卖的四个关键现实特征：（1）广告槽可以根据用户的搜索查询具有不同的价值和点击率，（2）竞争广告商的数量和身份是不可观察的，并且在每次竞拍中会发生更改，（3）广告商仅接收到部分的汇总反馈，（4）付款规则只部分确定。我们将广告商建模为受对抗性赌博算法驱动的代理，独立于拍卖机制的复杂性。我们的目标是为了模拟广告商的行为，进行反事实分析、预测和推理。我们的研究结果表明，在这种更复杂的环境中，即使投标者来自相同的人群，"软底价"也可以提高关键绩效指标。我们进一步展示了如何从观察到的竞标中推断广告商价值分布，从而证实了该方法的实际功效。

    This paper proposes a learning model of online ad auctions that allows for the following four key realistic characteristics of contemporary online auctions: (1) ad slots can have different values and click-through rates depending on users' search queries, (2) the number and identity of competing advertisers are unobserved and change with each auction, (3) advertisers only receive partial, aggregated feedback, and (4) payment rules are only partially specified. We model advertisers as agents governed by an adversarial bandit algorithm, independent of auction mechanism intricacies. Our objective is to simulate the behavior of advertisers for counterfactual analysis, prediction, and inference purposes. Our findings reveal that, in such richer environments, "soft floors" can enhance key performance metrics even when bidders are drawn from the same population. We further demonstrate how to infer advertiser value distributions from observed bids, thereby affirming the practical efficacy of o
    
[^3]: 通过移动目标防御减轻分散式联邦学习中的通信威胁

    Mitigating Communications Threats in Decentralized Federated Learning through Moving Target Defense. (arXiv:2307.11730v1 [cs.CR])

    [http://arxiv.org/abs/2307.11730](http://arxiv.org/abs/2307.11730)

    本文针对分散式联邦学习中的通信安全挑战，引入了一个安全模块，通过结合加密技术和移动目标防御技术来对抗通信攻击。

    

    分散式联邦学习（DFL）的兴起使得机器学习模型可以在联邦参与方之间进行训练，促进了分散式模型聚合并减少对服务器的依赖。然而，这种方法引入了独特的通信安全挑战，尚未在文献中得到充分解决。这些挑战主要源于聚合过程的分散性质、参与者的多样化角色和责任以及缺乏监管和缓解威胁的中央机构。本文针对这些挑战，首先界定了一个全面的威胁模型，突出了DFL通信的潜在风险。针对这些确定的风险，本文引入了一个专为DFL平台设计的安全模块来对抗基于通信的攻击。该模块结合了对称和非对称加密等安全技术与移动目标防御（MTD）技术。

    The rise of Decentralized Federated Learning (DFL) has enabled the training of machine learning models across federated participants, fostering decentralized model aggregation and reducing dependence on a server. However, this approach introduces unique communication security challenges that have yet to be thoroughly addressed in the literature. These challenges primarily originate from the decentralized nature of the aggregation process, the varied roles and responsibilities of the participants, and the absence of a central authority to oversee and mitigate threats. Addressing these challenges, this paper first delineates a comprehensive threat model, highlighting the potential risks of DFL communications. In response to these identified risks, this work introduces a security module designed for DFL platforms to counter communication-based attacks. The module combines security techniques such as symmetric and asymmetric encryption with Moving Target Defense (MTD) techniques, including
    
[^4]: 使用切片Wasserstein损失来训练神经网络的SGD收敛性分析

    Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses. (arXiv:2307.11714v1 [cs.LG])

    [http://arxiv.org/abs/2307.11714](http://arxiv.org/abs/2307.11714)

    本论文研究了使用切片Wasserstein损失训练神经网络时，随机梯度下降算法的收敛性，并证明了在特定条件下，SGD轨迹逼近了梯度流方程的集合。

    

    最优输运近年来引发了广泛的兴趣，特别是由于Wasserstein距离，它提供了一种几何上合理和直观的比较概率测度的方法。出于计算原因，切片Wasserstein（SW）距离作为Wasserstein距离的一种替代方法被引入，并且已经被用于训练生成式神经网络（NNs）。虽然在这样的设置中实际观察到了随机梯度下降（SGD）的收敛性，但据我们所知，对于这一观察没有理论保证。借鉴Bianchi等人（2022）关于SGD在非光滑和非凸函数上收敛性的最新工作，我们旨在填补这一知识空白，并提供一个具有实际意义的上下文，使得SW损失对NN参数的固定步长SGD轨迹收敛到（次）梯度流方程的集合。更准确地说，我们证明了随着步长减小，这些轨迹逼近了梯度流方程的集合。

    Optimal Transport has sparked vivid interest in recent years, in particular thanks to the Wasserstein distance, which provides a geometrically sensible and intuitive way of comparing probability measures. For computational reasons, the Sliced Wasserstein (SW) distance was introduced as an alternative to the Wasserstein distance, and has seen uses for training generative Neural Networks (NNs). While convergence of Stochastic Gradient Descent (SGD) has been observed practically in such a setting, there is to our knowledge no theoretical guarantee for this observation. Leveraging recent works on convergence of SGD on non-smooth and non-convex functions by Bianchi et al. (2022), we aim to bridge that knowledge gap, and provide a realistic context under which fixed-step SGD trajectories for the SW loss on NN parameters converge. More precisely, we show that the trajectories approach the set of (sub)-gradient flow equations as the step decreases. Under stricter assumptions, we show a much st
    
[^5]: JoinGym: 一种高效的强化学习查询优化环境

    JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning. (arXiv:2307.11704v1 [cs.LG])

    [http://arxiv.org/abs/2307.11704](http://arxiv.org/abs/2307.11704)

    本文介绍了JoinGym，一种高效的强化学习查询优化环境。通过将加入顺序选择问题形式化为马尔可夫决策过程，我们提供了一种实现，该实现完全基于离线跟踪，并且无需设置系统即可进行测试。此外，研究还提供了3300个新SQL查询的所有可能加入追踪。

    

    本文介绍了JoinGym，一种高效且轻量级的强化学习查询优化环境。加入顺序选择（JOS）是一个经典的NP-hard组合优化问题，用于数据库查询优化，可作为RL算法泛化能力的实际测试平台。我们描述了如何将左深和繁茂的JOS问题的每个变种形式化为马尔可夫决策过程（MDP），并提供符合标准Gymnasium API的实现。我们强调我们的实现JoinGym完全基于所有可能连接的离线追踪，使RL从业者能够轻松快速地在一个真实的数据管理问题上测试他们的方法，而无需设置任何系统。此外，我们还提供了从IMDB数据集生成的3300个新SQL查询的所有可能连接追踪。在对流行的RL算法进行基准测试时，我们发现至少有一种方法可以获得。

    In this paper, we present \textsc{JoinGym}, an efficient and lightweight query optimization environment for reinforcement learning (RL). Join order selection (JOS) is a classic NP-hard combinatorial optimization problem from database query optimization and can serve as a practical testbed for the generalization capabilities of RL algorithms. We describe how to formulate each of the left-deep and bushy variants of the JOS problem as a Markov Decision Process (MDP), and we provide an implementation adhering to the standard Gymnasium API. We highlight that our implementation \textsc{JoinGym} is completely based on offline traces of all possible joins, which enables RL practitioners to easily and quickly test their methods on a realistic data management problem without needing to setup any systems. Moreover, we also provide all possible join traces on $3300$ novel SQL queries generated from the IMDB dataset. Upon benchmarking popular RL algorithms, we find that at least one method can obta
    
[^6]: 使用仿真技术在兽医学中校准真实数据采集

    Using simulation to calibrate real data acquisition in veterinary medicine. (arXiv:2307.11695v1 [cs.LG])

    [http://arxiv.org/abs/2307.11695](http://arxiv.org/abs/2307.11695)

    使用仿真环境来增强兽医学中的数据采集和诊断，特别关注犬只的步态分析。通过生成反映多样条件的合成数据集，训练机器学习算法来识别正常和异常步态，并探索了摄像头视角对模型准确性的影响。初步结果显示，这种仿真方法有望提高兽医诊断的精确性和机器学习模型的效果。

    

    本文探讨了在兽医学中创新的使用仿真环境来增强数据采集和诊断的方法，特别关注了犬只的步态分析。研究利用Blender和Blenderproc库生成反映多样解剖、环境和行为条件的合成数据集。生成的数据以图形形式表示，并进行标准化以实现最佳分析效果，然后用于训练机器学习算法以识别正常和异常步态。创建了两个具有不同程度的摄像头角度粒度的数据集，以进一步研究摄像头视角对模型准确性的影响。初步结果表明，这种基于仿真的方法有望通过实现更精确的数据采集和更有效的机器学习模型，推动兽医诊断的进展。通过整合合成和真实世界的患者数据，该研究为改善兽医学的发展奠定了坚实的基础。

    This paper explores the innovative use of simulation environments to enhance data acquisition and diagnostics in veterinary medicine, focusing specifically on gait analysis in dogs. The study harnesses the power of Blender and the Blenderproc library to generate synthetic datasets that reflect diverse anatomical, environmental, and behavioral conditions. The generated data, represented in graph form and standardized for optimal analysis, is utilized to train machine learning algorithms for identifying normal and abnormal gaits. Two distinct datasets with varying degrees of camera angle granularity are created to further investigate the influence of camera perspective on model accuracy. Preliminary results suggest that this simulation-based approach holds promise for advancing veterinary diagnostics by enabling more precise data acquisition and more effective machine learning models. By integrating synthetic and real-world patient data, the study lays a robust foundation for improving o
    
[^7]: SynerGPT:上下文学习用于个性化药物协同作用预测和药物设计

    SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design. (arXiv:2307.11694v1 [cs.AI])

    [http://arxiv.org/abs/2307.11694](http://arxiv.org/abs/2307.11694)

    本文提出了一种通过上下文学习个性化药物协同作用并进行药物设计的方法，该方法利用小型的个性化数据集，不依赖于文本语料库、分子指纹或蛋白质相互作用的领域特定知识，取得了竞争性的结果。

    

    预测药物的协同组合可以加速癌症治疗的发现，特别是通过活检细胞个性化的治疗。在本文中，我们提出了一种新的设置和模型用于上下文中的药物协同学习。我们给出了一个小的“个性化数据集”，其中包含特定癌症靶细胞上下文中的10-20个药物协同关系。我们的目标是预测该上下文中的额外药物协同关系。受最近工作的启发，该工作通过预训练GPT语言模型（LM）来“上下文学习”常见的功能类。我们设计了一种 新的预训练方案，使GPT模型能够上下文学习“药物协同功能”。我们的模型 - 不使用任何文本语料库，分子指纹，蛋白质相互作用或任何其他领域特定的知识 - 能够取得竞争性的结果。我们进一步将我们的上下文方法与遗传算法结合起来，以优化模型提示并选择协同候选项。

    Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient's specific tumor via biopsied cells. In this paper, we propose a novel setting and models for in-context drug synergy learning. We are given a small "personalized dataset" of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to "in-context learn" common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn "drug synergy functions". Our model -- which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge -- is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates
    
[^8]: 可解释的图网络用于形成通用代数猜想

    Interpretable Graph Networks Formulate Universal Algebra Conjectures. (arXiv:2307.11688v1 [cs.LG])

    [http://arxiv.org/abs/2307.11688](http://arxiv.org/abs/2307.11688)

    提出了首次使用人工智能来研究通用代数的猜想，并引入了可解释的图网络以增强可解释性。

    

    最近人工智能的崛起使得研究人员能够探究几十年来传统方法无法解决的困难数学问题。然而，人工智能在通用代数领域中的应用仍然完全未被探索。本研究提出了首次使用人工智能来研究通用代数的猜想，结合等式和拓扑特征进行建模。虽然拓扑表示法可以使用图神经网络来分析这些属性，但这些模型的透明性和可解释性有限，限制了它们直接用于验证现有猜想或提出新猜想的能力。为了弥补这些差距，我们提出了一个通用算法，基于通用代数的猜想生成可用于人工智能的数据集，并引入了一种新颖的神经层来构建完全可解释的图网络。我们的实验结果表明，可解释的图网络能够增强...

    The rise of Artificial Intelligence (AI) recently empowered researchers to investigate hard mathematical problems which eluded traditional approaches for decades. Yet, the use of AI in Universal Algebra (UA) -- one of the fields laying the foundations of modern mathematics -- is still completely unexplored. This work proposes the first use of AI to investigate UA's conjectures with an equivalent equational and topological characterization. While topological representations would enable the analysis of such properties using graph neural networks, the limited transparency and brittle explainability of these models hinder their straightforward use to empirically validate existing conjectures or to formulate new ones. To bridge these gaps, we propose a general algorithm generating AI-ready datasets based on UA's conjectures, and introduce a novel neural layer to build fully interpretable graph networks. The results of our experiments demonstrate that interpretable graph networks: (i) enhan
    
[^9]: 面向通用化的交易执行的强化学习方法

    Towards Generalizable Reinforcement Learning for Trade Execution. (arXiv:2307.11685v1 [q-fin.TR])

    [http://arxiv.org/abs/2307.11685](http://arxiv.org/abs/2307.11685)

    本论文提出了一种面向通用化的交易执行的强化学习方法。研究表明，现有的强化学习方法存在过拟合问题，阻碍了实际应用。作者通过使用离线强化学习和动态上下文建模来解决过拟合问题，并提出了学习上下文的紧凑表示方法。

    

    优化的交易执行是在给定时间内以最低的交易成本卖出（或买入）给定资产的过程。最近，强化学习方法被应用于优化的交易执行，以从市场数据中学习更智能的策略。然而，我们发现许多现有的强化学习方法存在显著的过拟合问题，从而阻碍了它们的实际应用。在本文中，我们对优化的交易执行中的过拟合问题进行了广泛研究。首先，我们将优化的交易执行建模为带有动态上下文（ORDC）的离线强化学习问题，其中上下文表示不能受到交易策略影响并以离线方式收集的市场变量。在这个框架下，我们推导了泛化界限，并发现过拟合问题是由于离线环境中上下文空间巨大且上下文样本有限所导致的。因此，我们提出了学习上下文的紧凑表示来解决过拟合问题，可以通过...

    Optimized trade execution is to sell (or buy) a given amount of assets in a given time with the lowest possible trading cost. Recently, reinforcement learning (RL) has been applied to optimized trade execution to learn smarter policies from market data. However, we find that many existing RL methods exhibit considerable overfitting which prevents them from real deployment. In this paper, we provide an extensive study on the overfitting problem in optimized trade execution. First, we model the optimized trade execution as offline RL with dynamic context (ORDC), where the context represents market variables that cannot be influenced by the trading policy and are collected in an offline manner. Under this framework, we derive the generalization bound and find that the overfitting issue is caused by large context space and limited context samples in the offline setting. Accordingly, we propose to learn compact representations for context to address the overfitting problem, either by levera
    
[^10]: 小批量化对于二阶优化算法提供了改善的泛化性能

    Minibatching Offers Improved Generalization Performance for Second Order Optimizers. (arXiv:2307.11684v1 [cs.LG])

    [http://arxiv.org/abs/2307.11684](http://arxiv.org/abs/2307.11684)

    本研究通过实证研究发现，在训练过程中使用的批次大小对于二阶优化算法的性能具有显著影响，使用小批量化可以提供改善的泛化性能，并减少超参数调整的需求。

    

    训练现代机器学习中使用的深度神经网络(DNN)非常耗费计算资源。因此，机器学习科学家通常依赖于随机一阶方法进行训练，并进行大量手工调整，以获得良好的性能。为了更好地理解不同随机算法（包括二阶方法）的性能变异性，我们进行了一项经验性研究，将性能视为同一模型的多个训练会话中的响应变量。使用二因素方差分析(ANOVA)与交互作用，我们表明训练过程中使用的批次大小对方法的峰值准确性有显著影响，并且完整批次通常表现最差。此外，我们发现二阶优化器(SOOs)在特定批次大小上通常表现出较低的方差，这表明它们可能需要较少的超参数调整，从而减少了模型训练的总体时间解决方案。

    Training deep neural networks (DNNs) used in modern machine learning is computationally expensive. Machine learning scientists, therefore, rely on stochastic first-order methods for training, coupled with significant hand-tuning, to obtain good performance. To better understand performance variability of different stochastic algorithms, including second-order methods, we conduct an empirical study that treats performance as a response variable across multiple training sessions of the same model. Using 2-factor Analysis of Variance (ANOVA) with interactions, we show that batch size used during training has a statistically significant effect on the peak accuracy of the methods, and that full batch largely performed the worst. In addition, we found that second-order optimizers (SOOs) generally exhibited significantly lower variance at specific batch sizes, suggesting they may require less hyperparameter tuning, leading to a reduced overall time to solution for model training.
    
[^11]: 快速自适应测试防御与稳健特征

    Fast Adaptive Test-Time Defense with Robust Features. (arXiv:2307.11672v1 [cs.LG])

    [http://arxiv.org/abs/2307.11672](http://arxiv.org/abs/2307.11672)

    本文提出了一种快速适应的测试防御策略，通过投影训练好的模型到最稳健的特征空间，降低了对抗攻击的脆弱性，无需额外的测试时间计算。

    

    自适应的测试防御被用来提高深度神经网络对抗性样本的鲁棒性。然而，现有方法由于对模型参数或输入进行额外的优化导致推理时间大幅增加。在本工作中，我们提出了一种新颖的自适应测试防御策略，它可以与任何现有（稳健的）训练过程轻松集成，并且无需额外的测试时间计算。基于我们提出的特征鲁棒性的概念，关键思想是将训练好的模型投影到最稳健的特征空间，从而降低对非稳健方向的对抗攻击的脆弱性。我们在广义可加性模型和使用神经切向核函数（NTK）等价法证明了特征矩阵的顶层特征空间更加稳健。我们在CIFAR-10和CIFAR-100数据集上进行了大量实验，用于几个稳健性基准测试。

    Adaptive test-time defenses are used to improve the robustness of deep neural networks to adversarial examples. However, existing methods significantly increase the inference time due to additional optimization on the model parameters or the input at test time. In this work, we propose a novel adaptive test-time defense strategy that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. We theoretically show that the top eigenspace of the feature matrix are more robust for a generalized additive model and support our argument for a large width neural network with the Neural Tangent Kernel (NTK) equivalence. We conduct extensive experiments on CIFAR-10 and CIFAR-100 datasets for several robustness benchmarks, 
    
[^12]: 一种用于在线凸优化的高效内点方法

    An Efficient Interior-Point Method for Online Convex Optimization. (arXiv:2307.11668v1 [cs.LG])

    [http://arxiv.org/abs/2307.11668](http://arxiv.org/abs/2307.11668)

    本文描述了一种用于在线凸优化的高效内点方法，该方法在遗憾最小化方面具有最小可能值$O(\sqrt{T \log T})$，并且是自适应的。

    

    本文描述了一种用于在线凸优化的新算法。该算法在$T$个时间段后的遗憾为$O(\sqrt{T \log T})$，这是除对数项外的最小可能值。此外，新算法是自适应的，遗憾界不仅适用于时间段$1,\ldots,T$，还适用于每个子区间$s,s+1,\ldots,t$。算法的运行时间与新引入的内点算法的遗憾最小化算法相匹配：在$n$维空间中，每次迭代中，新算法实质上解决了一个$n$阶线性方程组，而不仅仅是在$n$维空间中求解一些约束的凸优化问题。

    A new algorithm for regret minimization in online convex optimization is described. The regret of the algorithm after $T$ time periods is $O(\sqrt{T \log T})$ - which is the minimum possible up to a logarithmic term. In addition, the new algorithm is adaptive, in the sense that the regret bounds hold not only for the time periods $1,\ldots,T$ but also for every sub-interval $s,s+1,\ldots,t$. The running time of the algorithm matches that of newly introduced interior point algorithms for regret minimization: in $n$-dimensional space, during each iteration the new algorithm essentially solves a system of linear equations of order $n$, rather than solving some constrained convex optimization problem in $n$ dimensions and possibly many constraints.
    
[^13]: 用GPT-4增强CLIP：利用视觉描述作为提示

    Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts. (arXiv:2307.11661v1 [cs.CV])

    [http://arxiv.org/abs/2307.11661](http://arxiv.org/abs/2307.11661)

    本文展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，在专门细粒度数据集上显示了较大的0-shot迁移准确性改进。

    

    对比预训练的大型视觉-语言模型（VLMs）如CLIP在下游数据集上提供了良好性能，从而革新了视觉表示学习。VLMs通过设计与数据集相关的提示来0-shot适应下游数据集。这种提示工程利用了领域专业知识和验证数据集。同时，像GPT-4这样的生成预训练模型的最新发展意味着它们可以用作先进的互联网搜索工具。它们还可以被操作以提供任何结构化的视觉信息。在这项工作中，我们展示了如何利用GPT-4生成具有视觉描述性的文本，并将其用于适应CLIP到下游任务。与CLIP的默认提示相比，我们在专门细粒度数据集（如EuroSAT（~7％）、DTD（~7％）、SUN397（~4.6％）和CUB（~3.3％））上显示出了较大的0-shot迁移准确性改进。我们还设计了一个简单的少量样本适配器，它可以学习选择最佳的s

    Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have revolutionized visual representation learning by providing good performance on downstream datasets. VLMs are 0-shot adapted to a downstream dataset by designing prompts that are relevant to the dataset. Such prompt engineering makes use of domain expertise and a validation dataset. Meanwhile, recent developments in generative pretrained models like GPT-4 mean they can be used as advanced internet search tools. They can also be manipulated to provide visual information in any structure. In this work, we show that GPT-4 can be used to generate text that is visually descriptive and how this can be used to adapt CLIP to downstream tasks. We show considerable improvements in 0-shot transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD (~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt. We also design a simple few-shot adapter that learns to choose the best possible s
    
[^14]: 具有确定性演化状态的强盗模型

    Bandits with Deterministically Evolving States. (arXiv:2307.11655v1 [cs.LG])

    [http://arxiv.org/abs/2307.11655](http://arxiv.org/abs/2307.11655)

    该论文提出了一种名为具有确定性演化状态的强盗模型，用于学习带有强盗反馈的推荐系统和在线广告。该模型考虑了状态演化的不同速率，能准确评估奖励与系统健康程度之间的关系。

    

    我们提出了一种学习与强盗反馈结合的模型，同时考虑到确定性演化和不可观测的状态，我们称之为具有确定性演化状态的强盗模型。我们的模型主要应用于推荐系统和在线广告的学习。在这两种情况下，算法在每一轮获得的奖励是选择行动的短期奖励和系统的“健康”程度（即通过其状态测量）的函数。例如，在推荐系统中，平台从用户对特定类型内容的参与中获得的奖励不仅取决于具体内容的固有特征，还取决于用户与平台上其他类型内容互动后其偏好的演化。我们的通用模型考虑了状态演化的不同速率λ∈[0,1]（例如，用户的偏好因先前内容消费而快速变化）。

    We propose a model for learning with bandit feedback while accounting for deterministically evolving and unobservable states that we call Bandits with Deterministically Evolving States. The workhorse applications of our model are learning for recommendation systems and learning for online ads. In both cases, the reward that the algorithm obtains at each round is a function of the short-term reward of the action chosen and how ``healthy'' the system is (i.e., as measured by its state). For example, in recommendation systems, the reward that the platform obtains from a user's engagement with a particular type of content depends not only on the inherent features of the specific content, but also on how the user's preferences have evolved as a result of interacting with other types of content on the platform. Our general model accounts for the different rate $\lambda \in [0,1]$ at which the state evolves (e.g., how fast a user's preferences shift as a result of previous content consumption
    
[^15]: 基于Kronecker图的可扩展多智能体技能发现

    Scalable Multi-agent Skill Discovery based on Kronecker Graphs. (arXiv:2307.11629v1 [cs.LG])

    [http://arxiv.org/abs/2307.11629](http://arxiv.org/abs/2307.11629)

    本文提出了一种基于Kronecker图的可扩展多智能体技能发现方法，通过连接状态转换图的Fiedler向量，直接计算具有协作探索行为的多智能体技能。

    

    技能发现在强化学习中已经用于改善单智能体场景下稀疏奖励信号的探索，通过连接状态转换图的Fiedler向量所提供的嵌入空间中最远的状态。然而，在多智能体系统中，由于联合状态空间的指数增长，现有研究仍依赖于单智能体技能发现，要么变得难以实现，要么无法直接发现改善联合状态空间连通性的联合技能。本文展示了如何直接计算具有协作探索行为的多智能体技能，同时享受到分解的便利性。我们的关键思想是将联合状态空间近似为一个Kronecker图，基于此我们可以使用各个智能体的转换图的拉普拉斯谱直接估计其Fiedler向量。进一步地，考虑到直接计算拉普拉斯谱在计算上的复杂性，

    Covering skill (a.k.a., option) discovery has been developed to improve the exploration of RL in single-agent scenarios with sparse reward signals, through connecting the most distant states in the embedding space provided by the Fiedler vector of the state transition graph. Given that joint state space grows exponentially with the number of agents in multi-agent systems, existing researches still relying on single-agent option discovery either become prohibitive or fail to directly discover joint options that improve the connectivity of the joint state space. In this paper, we show how to directly compute multi-agent options with collaborative exploratory behaviors while still enjoying the ease of decomposition. Our key idea is to approximate the joint state space as a Kronecker graph, based on which we can directly estimate its Fiedler vector using the Laplacian spectrum of individual agents' transition graphs. Further, considering that directly computing the Laplacian spectrum is in
    
[^16]: 离线多智能体强化学习与隐式全局到局部价值正则化

    Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization. (arXiv:2307.11620v1 [cs.LG])

    [http://arxiv.org/abs/2307.11620](http://arxiv.org/abs/2307.11620)

    这项工作提出了一种名为OMIGA的离线多智能体强化学习算法，通过隐式的全局到局部价值正则化，解决了离线多智能体强化学习中的挑战，并优雅地桥接了多智能体价值分解和策略学习。

    

    近年来，离线强化学习（RL）由于其在无需环境交互的离线数据集上学习策略的能力而受到了广泛关注。尽管在单智能体环境中取得了一些成功，但离线多智能体强化学习（MARL）仍然是一个挑战。庞大的联合状态-动作空间和紧密耦合的多智能体行为为离线策略优化增加了额外的复杂性。大多数现有的离线MARL研究仅在单个智能体上应用与离线数据相关的正则化，而未完全考虑全局层面上的多智能体系统。在这项工作中，我们提出了OMIGA，一种新的离线多智能体强化学习算法，具有隐式全局到局部价值正则化。OMIGA提供了一个原则性的框架，将全局层面的价值正则化转化为等效的隐式局部价值正则化，并同时实现样本内学习，从而优雅地桥接了多智能体价值分解和策略学习。

    Offline reinforcement learning (RL) has received considerable attention in recent years due to its attractive capability of learning policies from offline datasets without environmental interactions. Despite some success in the single-agent setting, offline multi-agent RL (MARL) remains to be a challenge. The large joint state-action space and the coupled multi-agent behaviors pose extra complexities for offline policy optimization. Most existing offline MARL studies simply apply offline data-related regularizations on individual agents, without fully considering the multi-agent system at the global level. In this work, we present OMIGA, a new offline m ulti-agent RL algorithm with implicit global-to-local v alue regularization. OMIGA provides a principled framework to convert global-level value regularization into equivalent implicit local value regularizations and simultaneously enables in-sample learning, thus elegantly bridging multi-agent value decomposition and policy learning wi
    
[^17]: 强健的全异步方法用于通用架构上的分布式训练

    Robust Fully-Asynchronous Methods for Distributed Training over General Architecture. (arXiv:2307.11617v1 [cs.DC])

    [http://arxiv.org/abs/2307.11617](http://arxiv.org/abs/2307.11617)

    该论文提出了一种强健的全异步方法（R-FAST），在分布式机器学习中解决了完美同步的低效性和不可能性问题，通过采用鲁棒的梯度跟踪策略和灵活的通信架构，消除了数据异构性和数据包丢失的影响，并实现了期望的邻域收敛。

    

    分布式机器学习问题中完美的同步是低效甚至不可能的，由于延迟、数据丢失和延迟较大的设备。我们提出了一种强健的全异步随机梯度跟踪方法（R-FAST），其中每个设备以自己的速度进行本地计算和通信，而无需任何形式的同步。与现有的异步分布式算法不同，R-FAST可以通过采用基于设计良好的辅助变量来跟踪和缓冲整体梯度向量的鲁棒梯度跟踪策略，消除设备间数据异构性的影响，并允许数据包丢失。更重要的是，所提出的方法利用两个生成树图进行通信，只要两者共享至少一个共同的根节点，就能实现灵活的通信架构设计。我们证明了R-FAST对于平滑和强凸问题，收敛到最优解的期望邻域，并具有几何收敛率。

    Perfect synchronization in distributed machine learning problems is inefficient and even impossible due to the existence of latency, package losses and stragglers. We propose a Robust Fully-Asynchronous Stochastic Gradient Tracking method (R-FAST), where each device performs local computation and communication at its own pace without any form of synchronization. Different from existing asynchronous distributed algorithms, R-FAST can eliminate the impact of data heterogeneity across devices and allow for packet losses by employing a robust gradient tracking strategy that relies on properly designed auxiliary variables for tracking and buffering the overall gradient vector. More importantly, the proposed method utilizes two spanning-tree graphs for communication so long as both share at least one common root, enabling flexible designs in communication architectures. We show that R-FAST converges in expectation to a neighborhood of the optimum with a geometric rate for smooth and strongly
    
[^18]: 使用变分自动编码器学习随机过程的最小表示

    Learning minimal representations of stochastic processes with variational autoencoders. (arXiv:2307.11608v1 [cond-mat.soft])

    [http://arxiv.org/abs/2307.11608](http://arxiv.org/abs/2307.11608)

    本文引入了一种无监督机器学习方法，使用变分自动编码器确定最小参数集，有效描述随机过程动力学，并生成能准确复制预期随机行为的新轨迹。

    

    随机过程在科学中有许多应用，因为它们广泛用于模拟各种自然现象。由于其固有的随机性和不确定性，它们很难进行表征。在这里，我们引入了一种无监督机器学习方法，用于确定有效描述随机过程动力学所需的最小参数集。我们的方法建立在扩展的β-变分自动编码器架构上。通过与典型扩散模型相对应的模拟数据集，我们展示了它在提取能准确描述这些动力学的最小相关参数方面的有效性。此外，该方法可以生成忠实复制预期随机行为的新轨迹。总体而言，我们的方法使得能够自动发现描述随机过程的未知参数，从而增进对各个领域中复杂现象的理解。

    Stochastic processes have found numerous applications in science, as they are broadly used to model a variety of natural phenomena. Due to their intrinsic randomness and uncertainty, they are however difficult to characterize. Here, we introduce an unsupervised machine learning approach to determine the minimal set of parameters required to effectively describe the dynamics of a stochastic process. Our method builds upon an extended $\beta$-variational autoencoder architecture. By means of simulated datasets corresponding to paradigmatic diffusion models, we showcase its effectiveness in extracting the minimal relevant parameters that accurately describe these dynamics. Furthermore, the method enables the generation of new trajectories that faithfully replicate the expected stochastic behavior. Overall, our approach enables for the autonomous discovery of unknown parameters describing stochastic processes, hence enhancing our comprehension of complex phenomena across various fields.
    
[^19]: 利用替代特征选择找到最优的多样特征集

    Finding Optimal Diverse Feature Sets with Alternative Feature Selection. (arXiv:2307.11607v1 [cs.LG])

    [http://arxiv.org/abs/2307.11607](http://arxiv.org/abs/2307.11607)

    本文引入了替代特征选择的概念，将其形式化为优化问题，并通过约束定义了替代特征集，使用户可以控制替代的数量和差异性。我们证明了该问题的NP-hard性，并讨论了如何将传统特征选择方法作为目标集成。实验证明替代特征集确实可以具有高预测质量，同时分析了几个影响因素。

    

    特征选择是获取小型、可解释且高精度预测模型的一种常见方法。传统的特征选择方法通常只能得到一个特征集，这在某些场景下可能不足够。例如，用户可能对寻找具有相似预测质量但提供不同数据解释的替代特征集感兴趣。在本文中，我们引入了替代特征选择，并将其形式化为一个优化问题。特别地，我们通过约束定义了替代特征，并使用户可以控制替代的数量和差异性。接下来，我们分析了这个优化问题的复杂性并展示了其NP-hard性质。进一步地，我们讨论了如何将传统的特征选择方法作为目标集成。最后，我们使用30个分类数据集评估了替代特征选择的效果。我们观察到替代特征集确实可能具有较高的预测质量，并分析了几个影响这一结果的因素。

    Feature selection is popular for obtaining small, interpretable, yet highly accurate prediction models. Conventional feature-selection methods typically yield one feature set only, which might not suffice in some scenarios. For example, users might be interested in finding alternative feature sets with similar prediction quality, offering different explanations of the data. In this article, we introduce alternative feature selection and formalize it as an optimization problem. In particular, we define alternatives via constraints and enable users to control the number and dissimilarity of alternatives. Next, we analyze the complexity of this optimization problem and show NP-hardness. Further, we discuss how to integrate conventional feature-selection methods as objectives. Finally, we evaluate alternative feature selection with 30 classification datasets. We observe that alternative feature sets may indeed have high prediction quality, and we analyze several factors influencing this ou
    
[^20]: 卷积神经网络在固定学习任务中的可迁移性

    Transferability of Convolutional Neural Networks in Stationary Learning Tasks. (arXiv:2307.11588v1 [cs.LG])

    [http://arxiv.org/abs/2307.11588](http://arxiv.org/abs/2307.11588)

    本文提出了一种用于大规模空间问题的卷积神经网络(CNNs)高效训练的新框架，通过研究CNNs在底层信号为固定的任务中的性质，发现在固定信号的小窗口上训练的CNN可以在更大的窗口上取得接近的性能，无需重新训练。

    

    硬件和大规模数据采集的最新进展加速了深度学习技术的发展。在长时间的研究中，增加模型复杂性通常可以提升各种任务的性能。然而，这种趋势正在变得不可持续，需要寻找计算上更轻量的替代方法。本文介绍了一种用于大规模空间问题的卷积神经网络(CNNs)高效训练的新框架。为了实现这一目标，我们研究了CNNs在底层信号为固定的任务中的性质。我们表明，在固定信号的小窗口上训练的CNN可以在不重新训练的情况下，在更大的窗口上取得接近的性能。我们的理论分析支持了这一观点，并给出了性能降低的界限。此外，我们还对两个任务进行了彻底的实验分析：多目标跟踪和按需移动基础设施。我们的结果显示...

    Recent advances in hardware and big data acquisition have accelerated the development of deep learning techniques. For an extended period of time, increasing the model complexity has led to performance improvements for various tasks. However, this trend is becoming unsustainable and there is a need for alternative, computationally lighter methods. In this paper, we introduce a novel framework for efficient training of convolutional neural networks (CNNs) for large-scale spatial problems. To accomplish this we investigate the properties of CNNs for tasks where the underlying signals are stationary. We show that a CNN trained on small windows of such signals achieves a nearly performance on much larger windows without retraining. This claim is supported by our theoretical analysis, which provides a bound on the performance degradation. Additionally, we conduct thorough experimental analysis on two tasks: multi-target tracking and mobile infrastructure on demand. Our results show that the
    
[^21]: 心态转变：通过语音到文本的模态转换提高语音情感识别的性能

    A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion. (arXiv:2307.11584v1 [cs.SD])

    [http://arxiv.org/abs/2307.11584](http://arxiv.org/abs/2307.11584)

    本研究通过语音到文本的模态转换方法，在MELD数据集上提高了语音情感识别的性能，超过了基于语音的最先进方法。这表明了模态转换在替代模态任务中的潜力。

    

    语音情感识别（SER）是一项具有挑战性的任务。本文介绍了一种模态转换的概念，旨在提高在MELD数据集上的情感识别性能。我们通过两个实验评估了我们的方法：第一个实验使用自动语音识别（ASR）系统和文本分类器实现的称为模态转换的方法；第二个实验假设有完美的ASR输出，并研究了模态转换对SER的影响，此方法称为模态转换++。我们的研究结果表明，第一个方法取得了显著的成果，而第二个方法在MELD数据集上的SER加权-F1（WF1）得分方面超越了最先进的基于语音的方法。这项研究突出了模态转换在可以使用替代模态进行的任务中的潜力。

    Speech Emotion Recognition (SER) is a challenging task. In this paper, we introduce a modality conversion concept aimed at enhancing emotion recognition performance on the MELD dataset. We assess our approach through two experiments: first, a method named Modality-Conversion that employs automatic speech recognition (ASR) systems, followed by a text classifier; second, we assume perfect ASR output and investigate the impact of modality conversion on SER, this method is called Modality-Conversion++. Our findings indicate that the first method yields substantial results, while the second method outperforms state-of-the-art (SOTA) speech-based approaches in terms of SER weighted-F1 (WF1) score on the MELD dataset. This research highlights the potential of modality conversion for tasks that can be conducted in alternative modalities.
    
[^22]: FMT: 通过特征图测试在深度神经网络中移除后门特征图

    FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks. (arXiv:2307.11565v1 [cs.LG])

    [http://arxiv.org/abs/2307.11565](http://arxiv.org/abs/2307.11565)

    这项工作中提出了一种名为FMT的防御策略，通过检测并移除训练用于从输入中提取后门信息的后门特征图，从而有效防止后门攻击。

    

    深度神经网络广泛应用于许多关键应用，如自动驾驶车辆和医学诊断。然而，它们的安全性受到后门攻击的威胁，后门攻击是通过向特定训练数据中添加人工模式实现的。现有的防御策略主要集中在使用逆向工程来复现攻击者生成的后门触发器，并通过将触发器添加到输入中并使用真实标签微调模型来修复DNN模型。然而，一旦攻击者生成的触发器复杂而且不可见，防御者就无法成功复现触发器。因此，由于触发器没有被有效去除，DNN模型将无法被修复。在这项工作中，我们提出了特征图测试（FMT）方法。与现有的防御策略不同，它们专注于复现后门触发器，FMT试图检测训练用于从输入中提取后门信息的后门特征图。

    Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is threatened by backdoor attack, which is achieved by adding artificial patterns to specific training data. Existing defense strategies primarily focus on using reverse engineering to reproduce the backdoor trigger generated by attackers and subsequently repair the DNN model by adding the trigger into inputs and fine-tuning the model with ground-truth labels. However, once the trigger generated by the attackers is complex and invisible, the defender can not successfully reproduce the trigger. Consequently, the DNN model will not be repaired since the trigger is not effectively removed.  In this work, we propose Feature Map Testing~(FMT). Different from existing defense strategies, which focus on reproducing backdoor triggers, FMT tries to detect the backdoor feature maps, which are trained to extract backdoor information from the inputs. 
    
[^23]: El Ni\~no Southern Oscillation多模态表示的多样性

    A multi-modal representation of El Ni\~no Southern Oscillation Diversity. (arXiv:2307.11552v1 [physics.ao-ph])

    [http://arxiv.org/abs/2307.11552](http://arxiv.org/abs/2307.11552)

    通过使用低维表示，在El Ni\~no Southern Oscillation（ENSO）中发现了新的极端El Ni\~no类别，并发现它们与典型EP El Ni\~no不同。EP El Ni\~nos，CP La Ni\~nas和Extreme El Ni\~nos对跨十年尺度的ENSO最具影响力。

    

    El Ni\~no Southern Oscillation (ENSO)通过赤道太平洋温暖（El Ni\~no）和寒冷（La Ni\~na）海表温度异常（SSTA）的交替阶段来描述。尽管El Ni\~no和La Ni\~na是明确定义的气候模式，但没有两个事件是相同的。迄今为止，ENSO多样性主要以SSTA峰值的经度位置来描述，用于在东太平洋（EP）和中太平洋（CP）类型中定义双峰分类。在这里，我们使用太平洋SSTA的低维表示来证明二进制分类成员对描述ENSO事件不合适。通过模糊无监督聚类，我们恢复了四个已知的ENSO类别，以及第五个类别：极端El Ni\~no。我们表明，极端El Ni\~nos在其强度和时间演化方面与典型的EP El Ni\~nos有所不同。我们还发现，CP La Ni\~nas，EP El Ni\~nos和Extreme El Ni\~nos对跨十年尺度的ENSO最具贡献性。

    The El Ni\~no-Southern Oscillation (ENSO) is characterized by alternating periods of warm (El Ni\~no) and cold (La Ni\~na) sea surface temperature anomalies (SSTA) in the equatorial Pacific. Although El Ni\~no and La Ni\~na are well-defined climate patterns, no two events are alike. To date, ENSO diversity has been described primarily in terms of the longitudinal location of peak SSTA, used to define a bimodal classification of events in Eastern Pacific (EP) and Central Pacific (CP) types. Here, we use low-dimensional representations of Pacific SSTAs to argue that binary categorical memberships are unsuitable to describe ENSO events. Using fuzzy unsupervised clustering, we recover the four known ENSO categories, along with a fifth category: an Extreme El Ni\~no. We show that Extreme El Ni\~nos differ both in their intensity and temporal evolution from canonical EP El Ni\~nos. We also find that CP La Ni\~nas, EP El Ni\~nos, and Extreme El Ni\~nos contribute the most to interdecadal ENSO
    
[^24]: 实现可行的托卡马克磁控制强化学习

    Towards practical reinforcement learning for tokamak magnetic control. (arXiv:2307.11546v1 [physics.plasm-ph])

    [http://arxiv.org/abs/2307.11546](http://arxiv.org/abs/2307.11546)

    这项研究致力于解决强化学习方法在托卡马克磁控制中的关键缺点，通过改进算法和训练过程，实现了更高的控制精度、减小稳态误差和缩短学习新任务所需时间，并通过实验验证了模拟结果的有效性。

    

    强化学习（RL）在实时控制系统中展现出了很好的结果，包括等离子体磁控制领域。然而，与传统的反馈控制方法相比，仍存在显著的缺点。本研究致力于解决RL方法的关键缺点：实现更高的对等离子体属性的控制精度，减小稳态误差，并减少学习新任务所需的时间。我们在\cite{degrave2022magnetic}的基础上，提出了对代理结构和训练过程进行算法改进的方法。我们展示了模拟结果，显示了形状精度提高了65％，实现了等离子体电流在长期偏差上的大幅减少，并且将学习新任务所需的训练时间减少了3倍或更多。我们使用升级后的RL控制器在TCV托卡马克上进行了新的实验，验证了达到的模拟结果，并指出...

    Reinforcement learning (RL) has shown promising results for real-time control systems, including the domain of plasma magnetic control. However, there are still significant drawbacks compared to traditional feedback control approaches for magnetic confinement. In this work, we address key drawbacks of the RL method; achieving higher control accuracy for desired plasma properties, reducing the steady-state error, and decreasing the required time to learn new tasks. We build on top of \cite{degrave2022magnetic}, and present algorithmic improvements to the agent architecture and training procedure. We present simulation results that show up to 65\% improvement in shape accuracy, achieve substantial reduction in the long-term bias of the plasma current, and additionally reduce the training time required to learn new tasks by a factor of 3 or more. We present new experiments using the upgraded RL-based controllers on the TCV tokamak, which validate the simulation results achieved, and point
    
[^25]: 基于模型切分的允许边缘联合学习的训练延迟最小化

    Training Latency Minimization for Model-Splitting Allowed Federated Edge Learning. (arXiv:2307.11532v1 [cs.LG])

    [http://arxiv.org/abs/2307.11532](http://arxiv.org/abs/2307.11532)

    本文提出了一个允许模型切分的联合学习框架，旨在最小化训练延迟，同时不损失测试准确性。

    

    为了缓解客户在使用联合学习训练深度神经网络时所面临的计算能力不足问题，我们利用边缘计算和模型切分提出了一个允许模型切分的联合学习框架（SFL），旨在在不损失测试准确性的情况下最小化训练延迟。在同步全局更新设置下，完成一轮全局训练的延迟取决于客户端完成本地训练会话的最大延迟。因此，训练延迟最小化问题（TLMP）被建模为一个最小化最大值的问题。为了解决这个混合整数非线性规划问题，我们首先提出了一个回归方法来拟合AI模型的切割层和其他参数之间的量化关系，从而将TLMP转化为一个连续问题。考虑到TLMP中涉及的两个子问题，即客户端的切割层选择问题和计算资源问题。

    To alleviate the shortage of computing power faced by clients in training deep neural networks (DNNs) using federated learning (FL), we leverage the edge computing and split learning to propose a model-splitting allowed FL (SFL) framework, with the aim to minimize the training latency without loss of test accuracy. Under the synchronized global update setting, the latency to complete a round of global training is determined by the maximum latency for the clients to complete a local training session. Therefore, the training latency minimization problem (TLMP) is modelled as a minimizing-maximum problem. To solve this mixed integer nonlinear programming problem, we first propose a regression method to fit the quantitative-relationship between the cut-layer and other parameters of an AI-model, and thus, transform the TLMP into a continuous problem. Considering that the two subproblems involved in the TLMP, namely, the cut-layer selection problem for the clients and the computing resource 
    
[^26]: 使用机器学习进行多模态仇恨言论检测

    Multi-modal Hate Speech Detection using Machine Learning. (arXiv:2307.11519v1 [cs.AI])

    [http://arxiv.org/abs/2307.11519](http://arxiv.org/abs/2307.11519)

    本研究提出了一种使用多模态系统的方法，通过提取图像特征、音频特征值和文本，结合机器学习和自然语言处理技术，来检测视频内容中的仇恨言论。

    

    随着互联网用户和媒体内容的不断增长，追踪音频和视频中的仇恨言论变得非常困难。将视频或音频转换为文本并不能准确检测到仇恨言论，因为人们有时会将仇恨词汇作为幽默或愉快的意味使用，并在视频中使用不同的声调或展示不同的动作。当前最先进的仇恨言论检测模型大多是基于单一模态的。本研究提出了一种多模态系统的综合方法，通过提取图像特征、音频中的特征值、文本和使用机器学习和自然语言处理来检测视频内容中的仇恨言论。

    With the continuous growth of internet users and media content, it is very hard to track down hateful speech in audio and video. Converting video or audio into text does not detect hate speech accurately as human sometimes uses hateful words as humorous or pleasant in sense and also uses different voice tones or show different action in the video. The state-ofthe-art hate speech detection models were mostly developed on a single modality. In this research, a combined approach of multimodal system has been proposed to detect hate speech from video contents by extracting feature images, feature values extracted from the audio, text and used machine learning and Natural language processing.
    
[^27]: 在协变量偏移自适应中的一般正则化方法

    General regularization in covariate shift adaptation. (arXiv:2307.11503v1 [cs.LG])

    [http://arxiv.org/abs/2307.11503](http://arxiv.org/abs/2307.11503)

    本文研究了协变量偏移自适应中的一般正则化方法，并通过组合已有结果得到了新的结果。在弱平滑条件下证明了实现与标准监督学习中相同精度所需的样本量要比现有分析证明的少。

    

    样本重加权是纠正在再生核希尔伯特空间(RKHS)中由未来数据分布与训练数据分布不同引起的最小二乘学习算法错误的最常用方法之一。在实际情况中，样本权重是由未来数据分布对训练数据分布的估计Radon-Nikod\'ym导数的值确定的。本研究回顾了在RKHS中重新加权核回归的已知误差界限，并通过组合得到新的结果。我们在弱平滑条件下表明，为了实现与标准监督学习中数据分布差异相同精度的样本数目要比现有的分析证明的少。

    Sample reweighting is one of the most widely used methods for correcting the error of least squares learning algorithms in reproducing kernel Hilbert spaces (RKHS), that is caused by future data distributions that are different from the training data distribution. In practical situations, the sample weights are determined by values of the estimated Radon-Nikod\'ym derivative, of the future data distribution w.r.t.~the training data distribution. In this work, we review known error bounds for reweighted kernel regression in RKHS and obtain, by combination, novel results. We show under weak smoothness conditions, that the amount of samples, needed to achieve the same order of accuracy as in the standard supervised learning without differences in data distributions, is smaller than proven by state-of-the-art analyses.
    
[^28]: 预测、改进、合成：面向概率时间序列预测的自引导扩散模型

    Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting. (arXiv:2307.11494v1 [cs.LG])

    [http://arxiv.org/abs/2307.11494](http://arxiv.org/abs/2307.11494)

    本研究提出了一种面向概率时间序列预测的自引导扩散模型，称为TSDiff。该模型不需要辅助网络或训练过程的改变，在预测、改进和合成数据生成等时间序列任务上展现出了竞争力。

    

    扩散模型在各个领域的生成建模任务中取得了最先进的性能。之前关于时间序列扩散模型的研究主要集中在开发针对特定预测或填补任务的条件模型。在这项工作中，我们探索了面向多种时间序列应用的任务不可知条件下的扩散模型的潜力。我们提出了TSDiff，一种面向时间序列的无条件训练的扩散模型。我们的自引导机制在推理过程中使得TSDiff能够为下游任务进行条件设置，而无需辅助网络或改变训练过程。我们在三个不同的时间序列任务上展示了我们方法的有效性：预测、改进和合成数据生成。首先，我们表明TSDiff与几种任务特定的条件预测方法相竞争（预测）。其次，我们利用TSDiff学到的隐性概率密度来迭代地改进p

    Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the p
    
[^29]: 一个新的基于深度状态空间分析的框架用于从电子健康记录时间序列数据中估计和分类病人的潜在状态

    A New Deep State-Space Analysis Framework for Patient Latent State Estimation and Classification from EHR Time Series Data. (arXiv:2307.11487v1 [cs.LG])

    [http://arxiv.org/abs/2307.11487](http://arxiv.org/abs/2307.11487)

    该论文提出了一个基于深度状态空间分析的框架，用于从电子健康记录时间序列数据中估计和分类病人的潜在状态。通过该框架，可以学习、可视化和聚类与疾病进展相关的病人潜在状态的时间变化，并成功发现了与预后相关的潜在状态。

    

    许多疾病，包括癌症和慢性疾病，需要长期治疗和长期策略。机器学习和人工智能研究专注于电子健康记录（EHR）已经出现来解决这个需求。有效的治疗策略不仅仅涉及捕捉病人测试数值的顺序变化。它需要一个可解释和临床可解释的模型，通过捕捉病人随时间的内部状态。在这项研究中，我们提出了“深度状态空间分析框架”，使用深度状态空间模型对EHR的时间序列无监督学习。该框架能够学习、可视化和聚类与疾病进展相关的病人潜在状态的时间变化。我们使用来自12,695名癌症患者的时间序列实验室数据评估了我们的框架。通过估计潜在状态，我们成功发现了与预后相关的潜在状态。通过可视化和聚类分析，我们揭示了病人状态和治疗响应的时间动态。

    Many diseases, including cancer and chronic conditions, require extended treatment periods and long-term strategies. Machine learning and AI research focusing on electronic health records (EHRs) have emerged to address this need. Effective treatment strategies involve more than capturing sequential changes in patient test values. It requires an explainable and clinically interpretable model by capturing the patient's internal state over time.  In this study, we propose the "deep state-space analysis framework," using time-series unsupervised learning of EHRs with a deep state-space model. This framework enables learning, visualizing, and clustering of temporal changes in patient latent states related to disease progression.  We evaluated our framework using time-series laboratory data from 12,695 cancer patients. By estimating latent states, we successfully discover latent states related to prognosis. By visualization and cluster analysis, the temporal transition of patient status and 
    
[^30]: 一种用于具有缺失值的整体生存分析的深度学习方法

    A Deep Learning Approach for Overall Survival Analysis with Missing Values. (arXiv:2307.11465v1 [cs.LG])

    [http://arxiv.org/abs/2307.11465](http://arxiv.org/abs/2307.11465)

    提出了一个深度学习模型，通过有效利用被审查和未被审查病人的信息，预测非小细胞肺癌（NSCLC）病人的整体生存。

    

    人工智能可以应用于肺癌研究，尤其是非小细胞肺癌（NSCLC），这是一个具有挑战性的领域。对于病人状态的整体生存（OS）是一个重要指标，可以帮助识别生存概率不同的亚组，从而实现个体化治疗和改善整体生存率。在这个分析中，需要考虑两个挑战。首先，很少有研究能够有效利用每个病人的可用信息，利用未被审查的（即死亡）和被审查的（即幸存者）病人的信息，也要考虑到死亡时间。其次，不完整数据处理是医学领域常见的问题。这个问题通常通过使用插补方法来解决。我们的目标是提出一个能够克服这些限制的人工智能模型，能够从被审查和未被审查的病人及其可用特征中有效学习，预测NSCLC病人的OS。

    One of the most challenging fields where Artificial Intelligence (AI) can be applied is lung cancer research, specifically non-small cell lung cancer (NSCLC). In particular, overall survival (OS) is a vital indicator of patient status, helping to identify subgroups with diverse survival probabilities, enabling tailored treatment and improved OS rates. In this analysis, there are two challenges to take into account. First, few studies effectively exploit the information available from each patient, leveraging both uncensored (i.e., dead) and censored (i.e., survivors) patients, considering also the death times. Second, the handling of incomplete data is a common issue in the medical field. This problem is typically tackled through the use of imputation methods. Our objective is to present an AI model able to overcome these limits, effectively learning from both censored and uncensored patients and their available features, for the prediction of OS for NSCLC patients. We present a novel 
    
[^31]: 通过时间重新缩放错误以改善长期记忆学习

    Improve Long-term Memory Learning Through Rescaling the Error Temporally. (arXiv:2307.11462v1 [cs.LG])

    [http://arxiv.org/abs/2307.11462](http://arxiv.org/abs/2307.11462)

    本研究通过时间上重新缩放错误度量，改善了长期记忆学习的偏向于短期记忆的问题，并缓解了梯度消失的困扰。数值实验验证了适当的时间上重新缩放错误在有效的长期记忆学习中的重要性。

    

    本文研究了序列建模中长期记忆学习的错误度量选择。我们检查了常用错误度量（包括平均绝对/平方误差）对短期记忆的偏向。我们的发现表明，在学习线性函数时，所有时间上有正权重的错误都偏向于短期记忆。为了减少这种偏差并改善长期记忆学习，我们提出了使用时间上重新缩放的错误。除了减少对短期记忆的偏向外，这种方法还可以缓解梯度消失问题。我们在不同的长期记忆任务和序列模型上进行数值实验，以验证我们的假设。数值结果确认了适当的时间上重新缩放误差对于有效的长期记忆学习的重要性。据我们所知，这是第一篇定量分析序列建模中不同错误对短期记忆偏向的工作。

    This paper studies the error metric selection for long-term memory learning in sequence modelling. We examine the bias towards short-term memory in commonly used errors, including mean absolute/squared error. Our findings show that all temporally positive-weighted errors are biased towards short-term memory in learning linear functionals. To reduce this bias and improve long-term memory learning, we propose the use of a temporally rescaled error. In addition to reducing the bias towards short-term memory, this approach can also alleviate the vanishing gradient issue. We conduct numerical experiments on different long-memory tasks and sequence models to validate our claims. Numerical results confirm the importance of appropriate temporally rescaled error for effective long-term memory learning. To the best of our knowledge, this is the first work that quantitatively analyzes different errors' memory bias towards short-term memory in sequence modelling.
    
[^32]: 延迟补偿超bolic PIDE控制的神经算子

    Neural Operators for Delay-Compensating Control of Hyperbolic PIDEs. (arXiv:2307.11436v1 [math.OC])

    [http://arxiv.org/abs/2307.11436](http://arxiv.org/abs/2307.11436)

    该论文提出了延迟补偿超bolic PIDE控制的神经算子框架，扩展了基本PDE控制结果到一个涉及状态和系统延迟的高级超bolic类。使用DeepONet逼近算子，可以在无限维度上建立稳定的闭环反馈，并开发了逼近的观测者和输出反馈定律。

    

    最近引入的DeepONet算子学习框架从基本的超bolic和拟bolic PDE结果扩展到了一个高级超bolic类，其中包括状态和系统输出或输入的延迟。PDE反向设计产生的增益函数是非线性算子的输出，将空间域上的函数映射到空间域上的函数，其中该增益生成算子的输入是PDE的系数。使用DeepONet神经网络逼近该算子，可以证明其任意精度紧密。一旦在无限维度上产生了这个逼近理论结果，我们就可以在使用近似增益的反馈下建立封闭环的稳定性。除了提供全状态反馈下的这些结果外，我们还发展了DeepONet逼近的观测者和输出反馈定律，并证明了它们在神经算子逼近下的稳定性质。

    The recently introduced DeepONet operator-learning framework for PDE control is extended from the results for basic hyperbolic and parabolic PDEs to an advanced hyperbolic class that involves delays on both the state and the system output or input. The PDE backstepping design produces gain functions that are outputs of a nonlinear operator, mapping functions on a spatial domain into functions on a spatial domain, and where this gain-generating operator's inputs are the PDE's coefficients. The operator is approximated with a DeepONet neural network to a degree of accuracy that is provably arbitrarily tight. Once we produce this approximation-theoretic result in infinite dimension, with it we establish stability in closed loop under feedback that employs approximate gains. In addition to supplying such results under full-state feedback, we also develop DeepONet-approximated observers and output-feedback laws and prove their own stabilizing properties under neural operator approximations.
    
[^33]: 为环保人工智能而批处理 - 探索推理过程的研究

    Batching for Green AI -- An Exploratory Study on Inference. (arXiv:2307.11434v1 [cs.LG])

    [http://arxiv.org/abs/2307.11434](http://arxiv.org/abs/2307.11434)

    这项研究探讨了在深度学习模型推理阶段引入批处理对能源消耗和响应时间的影响，并发现批处理对这两个指标都有显著影响。

    

    在开发新的神经网络时，批大小是一个需要调整的重要参数。除了其他质量指标外，它对模型的准确性、泛化能力、训练时间和并行性具有很大的影响。这个事实是众所周知并被广泛研究的。然而，在深度学习模型应用阶段，当模型被最终用户用于推理时，我们发现对引入批大小的潜在好处存在忽视。在这项研究中，我们考察了输入批处理对于五个在计算机视觉领域被认为是最先进的完全训练的神经网络的能源消耗和响应时间的影响。结果表明，批处理对这两个指标都有显著影响。此外，我们还呈现了过去十年神经网络的能源效率和准确性的时间线。我们发现，总体上，能源消耗在这段时间内明显上升。

    The batch size is an essential parameter to tune during the development of new neural networks. Amongst other quality indicators, it has a large degree of influence on the model's accuracy, generalisability, training times and parallelisability. This fact is generally known and commonly studied. However, during the application phase of a deep learning model, when the model is utilised by an end-user for inference, we find that there is a disregard for the potential benefits of introducing a batch size. In this study, we examine the effect of input batching on the energy consumption and response times of five fully-trained neural networks for computer vision that were considered state-of-the-art at the time of their publication. The results suggest that batching has a significant effect on both of these metrics. Furthermore, we present a timeline of the energy efficiency and accuracy of neural networks over the past decade. We find that in general, energy consumption rises at a much ste
    
[^34]: 分析多智能体强化学习在去中心化库存控制系统中的应用

    An Analysis of Multi-Agent Reinforcement Learning for Decentralized Inventory Control Systems. (arXiv:2307.11432v1 [cs.LG])

    [http://arxiv.org/abs/2307.11432](http://arxiv.org/abs/2307.11432)

    本研究提出了一种多智能体强化学习的去中心化数据驱动库存管理问题的解决方案，通过将问题分解为子问题并控制每个实体的智能体，通过模拟不同供应链网络和不确定性水平，研究了三种多智能体变体的近端策略优化算法。

    

    大多数解决库存管理问题的方法假设信息的集中，与实际供应链网络的组织约束不兼容。库存管理问题是运筹学中一个众所周知的规划问题，涉及为供应链中的节点找到最优的重新订购策略。虽然存在许多关于该问题的集中式解决方案，但它们不能应用于由独立实体组成的真实世界供应链。然而，这个问题可以自然地分解成与独立实体相关的子问题，将其转化为一个多智能体系统。因此，提出了一种使用多智能体强化学习的去中心化数据驱动的库存管理问题的解决方案，每个实体由一个智能体控制。通过模拟不同供应链网络和不确定性水平，研究了三种多智能体变体的近端策略优化算法。

    Most solutions to the inventory management problem assume a centralization of information that is incompatible with organisational constraints in real supply chain networks. The inventory management problem is a well-known planning problem in operations research, concerned with finding the optimal re-order policy for nodes in a supply chain. While many centralized solutions to the problem exist, they are not applicable to real-world supply chains made up of independent entities. The problem can however be naturally decomposed into sub-problems, each associated with an independent entity, turning it into a multi-agent system. Therefore, a decentralized data-driven solution to inventory management problems using multi-agent reinforcement learning is proposed where each entity is controlled by an agent. Three multi-agent variations of the proximal policy optimization algorithm are investigated through simulations of different supply chain networks and levels of uncertainty. The centralize
    
[^35]: 注意力对熵通信的影响

    Attention to Entropic Communication. (arXiv:2307.11423v1 [cs.IT])

    [http://arxiv.org/abs/2307.11423](http://arxiv.org/abs/2307.11423)

    该论文研究了在通信理论中结合注意力和相对熵的概念。研究发现，在通信中使用注意力导向的加权相对熵是不适当的，而适当的注意力通信可通过发送者仅需要了解接收者的效用函数来实现最佳通知。

    

    注意力的概念是指在人工智能中强调特定数据重要性的数值权重，在通信理论中相对熵（RE，也称为库尔巴克-勒布勒散度）发挥着核心作用。在这里，我们结合了这些概念，即注意力和RE。RE引导带宽有限通信中的最佳编码以及通过最大熵原理（MEP）进行最佳消息解码。在编码场景中，RE可以从四个要求中推导出来，即分析性、局部性、适当性和校准性。而用于通信中注意力导向的加权RE实际上是不适当的。为了看到适当的注意力通信是如何出现的，我们分析了一个场景，即消息发送者希望确保接收者能够执行知情的操作。如果接收者使用MEP解码消息，则发送者只需要知道接收者的效用函数来进行最佳通知，不需要知道接收者的策略。

    The concept of attention, numerical weights that emphasize the importance of particular data, has proven to be very relevant in artificial intelligence. Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in communication theory. Here we combine these concepts, attention and RE. RE guides optimal encoding of messages in bandwidth-limited communication as well as optimal message decoding via the maximum entropy principle (MEP). In the coding scenario, RE can be derived from four requirements, namely being analytical, local, proper, and calibrated. Weighted RE, used for attention steering in communications, turns out to be improper. To see how proper attention communication can emerge, we analyze a scenario of a message sender who wants to ensure that the receiver of the message can perform well-informed actions. If the receiver decodes the message using the MEP, the sender only needs to know the receiver's utility function to inform optimally, but not the receive
    
[^36]: 通过学习简化的有限元方法模型，直接和反向建模软体机器人

    Direct and inverse modeling of soft robots by learning a condensed FEM model. (arXiv:2307.11408v1 [cs.RO])

    [http://arxiv.org/abs/2307.11408](http://arxiv.org/abs/2307.11408)

    本研究使用学习方法通过简化有限元方法模型，实现了对软体机器人的直接和逆向建模，并证明了这种紧凑模型在建模效果和效率上的优势。

    

    有限元方法(FEM)是一种用于预测软体机器人行为的强大建模工具。然而，对于非数值计算专家来说，它在控制方面的应用可能会很困难：它需要优化计算以使其实时化。在本文中，我们提出了一种基于学习的方法，以获得紧凑但足够丰富的机械表示。我们的选择基于FEM模型在致动器/效应器空间中提供的非线性顺从数据的精简。我们证明了这个紧凑模型可以通过合理量的数据进行学习，并且在建模方面非常有效，因为我们可以推导出机器人的直接和逆运动学。我们还展示了如何将一些单独学习的模型进行耦合，特别是在由两个软体手指组成的夹爪的例子上。通过比较从完整的FEM模型派生的逆模型和从紧凑学习版本派生的逆模型，还展示了其他结果。

    The Finite Element Method (FEM) is a powerful modeling tool for predicting the behavior of soft robots. However, its use for control can be difficult for non-specialists of numerical computation: it requires an optimization of the computation to make it real-time. In this paper, we propose a learning-based approach to obtain a compact but sufficiently rich mechanical representation. Our choice is based on nonlinear compliance data in the actuator/effector space provided by a condensation of the FEM model. We demonstrate that this compact model can be learned with a reasonable amount of data and, at the same time, be very efficient in terms of modeling, since we can deduce the direct and inverse kinematics of the robot. We also show how to couple some models learned individually in particular on an example of a gripper composed of two soft fingers. Other results are shown by comparing the inverse model derived from the full FEM model and the one from the compact learned version. This wo
    
[^37]: 医学图像分割中的观察者间和观察者内变异的概率建模

    Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation. (arXiv:2307.11397v1 [eess.IV])

    [http://arxiv.org/abs/2307.11397](http://arxiv.org/abs/2307.11397)

    本文提出了一种新颖的概率模型Pionono，用于医学图像分割中的观察者间和观察者内变异。该模型通过捕捉每个标记者的标记行为并将其与图像特征集成，产生概率分割预测。实验证明Pionono在准确性和效率上优于现有模型，并且可以预测多个一致的分割图，为诊断过程提供了宝贵的信息。

    

    医学图像分割是一项具有挑战性的任务，特别是由于观察者间和观察者内的变异性，即使是在医学专家之间也存在。在本文中，我们提出了一种新颖的模型，称为概率观察者间和观察者内变异网络（Pionono）。它通过多维概率分布捕捉每个标记者的标记行为，并将此信息与图像的特征图集成起来，产生概率分割预测。该模型通过变分推断进行优化，并可以端到端地进行训练。它在STAPLE、概率U-Net和基于混淆矩阵的模型等最先进的模型上表现出色。此外，Pionono预测多个一致的分割图，模拟了评分者的专业意见，为诊断过程提供了额外的有价值信息。在真实的癌症分割数据集上的实验证明了Pionono的高准确性和效率，使其成为一种强大的医学工具。

    Medical image segmentation is a challenging task, particularly due to interand intra-observer variability, even between medical experts. In this paper, we propose a novel model, called Probabilistic Inter-Observer and iNtra-Observer variation NetwOrk (Pionono). It captures the labeling behavior of each rater with a multidimensional probability distribution and integrates this information with the feature maps of the image to produce probabilistic segmentation predictions. The model is optimized by variational inference and can be trained end-to-end. It outperforms state-of-the-art models such as STAPLE, Probabilistic U-Net, and models based on confusion matrices. Additionally, Pionono predicts multiple coherent segmentation maps that mimic the rater's expert opinion, which provides additional valuable information for the diagnostic process. Experiments on real-world cancer segmentation datasets demonstrate the high accuracy and efficiency of Pionono, making it a powerful tool for med
    
[^38]: 朝着更好的公正性-效用权衡的方向：一种基于综合测量的强化学习框架

    Towards Better Fairness-Utility Trade-off: A Comprehensive Measurement-Based Reinforcement Learning Framework. (arXiv:2307.11379v1 [cs.LG])

    [http://arxiv.org/abs/2307.11379](http://arxiv.org/abs/2307.11379)

    本论文提出了一种基于综合测量的强化学习框架CFU，旨在有效改善机器学习分类器中的公正性-效用权衡问题。

    

    机器学习被广泛用于具有社会影响的决策，如银行贷款审核、刑事判决和简历筛选。如何在维持效用的同时确保公正性是一个具有挑战性但至关重要的问题。公正性是一个复杂且依赖于上下文的概念，有超过70种不同的测量指标。由于现有的规定通常对使用哪个指标模糊不清，并且不同的组织可能偏好不同的公正性指标，因此有必要通过综合手段来改善公正性。现有的缓解技术通常针对特定的公正性指标，并且在同时改进多个公正性概念方面存在局限性。在这项工作中，我们提出了CFU（Comprehensive Fairness-Utility），一种基于强化学习的框架，以有效改善机器学习分类器中的公正性-效用权衡。

    Machine learning is widely used to make decisions with societal impact such as bank loan approving, criminal sentencing, and resume filtering. How to ensure its fairness while maintaining utility is a challenging but crucial issue. Fairness is a complex and context-dependent concept with over 70 different measurement metrics. Since existing regulations are often vague in terms of which metric to use and different organizations may prefer different fairness metrics, it is important to have means of improving fairness comprehensively. Existing mitigation techniques often target at one specific fairness metric and have limitations in improving multiple notions of fairness simultaneously. In this work, we propose CFU (Comprehensive Fairness-Utility), a reinforcement learning-based framework, to efficiently improve the fairness-utility trade-off in machine learning classifiers. A comprehensive measurement that can simultaneously consider multiple fairness notions as well as utility is estab
    
[^39]: LatentAugment: 通过引导操纵GAN的潜在空间进行数据增强

    LatentAugment: Data Augmentation via Guided Manipulation of GAN's Latent Space. (arXiv:2307.11375v1 [cs.CV])

    [http://arxiv.org/abs/2307.11375](http://arxiv.org/abs/2307.11375)

    LatentAugment是一种通过引导操纵GAN的潜在空间进行数据增强的策略，解决了标准数据增强的低多样性问题，提供了更多样化和真实性更高的合成图像样本。

    

    数据增强（DA）是一种增加训练数据数量和多样性的技术，从而减少过拟合并改善泛化能力。然而，标准的数据增强只能产生具有有限多样性的合成数据。生成对抗网络（GANs）可以通过生成具有真实图像外观的合成样本来解锁数据集中的额外信息。然而，这些模型难以同时满足三个关键要求：保真度和高质量样本、多样性和模式覆盖、以及快速采样。实际上，GAN可以快速生成高质量的样本，但模式覆盖差，限制了它们在数据增强应用中的应用。我们提出了一种名为LatentAugment的数据增强策略，它克服了GAN的低多样性问题，从而使其在数据增强应用中得到应用。在没有外部监督的情况下，LatentAugment修改潜在向量并将其移动到潜在空间中的特定区域，以最大程度地增加合成图像的多样性和保真度。

    Data Augmentation (DA) is a technique to increase the quantity and diversity of the training data, and by that alleviate overfitting and improve generalisation. However, standard DA produces synthetic data for augmentation with limited diversity. Generative Adversarial Networks (GANs) may unlock additional information in a dataset by generating synthetic samples having the appearance of real images. However, these models struggle to simultaneously address three key requirements: fidelity and high-quality samples; diversity and mode coverage; and fast sampling. Indeed, GANs generate high-quality samples rapidly, but have poor mode coverage, limiting their adoption in DA applications. We propose LatentAugment, a DA strategy that overcomes the low diversity of GANs, opening up for use in DA applications. Without external supervision, LatentAugment modifies latent vectors and moves them into latent space regions to maximise the synthetic images' diversity and fidelity. It is also agnostic 
    
[^40]: 通过Fenchel对偶实现多样的离线模仿

    Diverse Offline Imitation via Fenchel Duality. (arXiv:2307.11373v1 [cs.LG])

    [http://arxiv.org/abs/2307.11373](http://arxiv.org/abs/2307.11373)

    本文提出了一个离线技能发现算法，通过Fenchel对偶方法将强化学习和无监督技能发现结合起来，实现学习与专家相一致的多样的技能。

    

    在无监督技能发现领域，最近取得了显著进展，各种工作提出了以互信息为基础的目标，作为内在驱动。先前的工作主要集中在设计需要在线环境访问的算法。相比之下，我们开发了一个\textit{离线}技能发现算法。我们的问题形式化考虑了在KL-散度约束下最大化互信息目标。更确切地说，约束确保每个技能的状态占用保持在一个具有良好状态操作覆盖率的离线数据集的支持范围内与专家的状态占用逼近。我们的主要贡献是连接Fenchel对偶、强化学习和无监督技能发现，并给出一个简单的离线算法，用于学习与专家相一致的多样的技能。

    There has been significant recent progress in the area of unsupervised skill discovery, with various works proposing mutual information based objectives, as a source of intrinsic motivation. Prior works predominantly focused on designing algorithms that require online access to the environment. In contrast, we develop an \textit{offline} skill discovery algorithm. Our problem formulation considers the maximization of a mutual information objective constrained by a KL-divergence. More precisely, the constraints ensure that the state occupancy of each skill remains close to the state occupancy of an expert, within the support of an offline dataset with good state-action coverage. Our main contribution is to connect Fenchel duality, reinforcement learning and unsupervised skill discovery, and to give a simple offline algorithm for learning diverse skills that are aligned with an expert.
    
[^41]: 随机分离超平面定理和学习多面体

    Random Separating Hyperplane Theorem and Learning Polytopes. (arXiv:2307.11371v1 [cs.LG])

    [http://arxiv.org/abs/2307.11371](http://arxiv.org/abs/2307.11371)

    通过随机选择的超平面，我们提出了随机分离超平面定理（RSH）来加强分离超平面定理，利用RSH我们得到了多面体学习中的算法应用。

    

    分离超平面定理是凸几何学中的一个基本结果，具有广泛的应用。我们的第一个结果是随机分离超平面定理（RSH），它是对多面体的一个加强。RSH断言，如果点a与具有k个顶点和单位直径的多面体K在$\Re^d$中的距离至少为$\delta$，其中$\delta$是$(0,1)$之间的一个固定常数，则随机选择的超平面以至少$1/poly(k)$的概率将a和K分离，并且边界至少为$\Omega \left( \delta/\sqrt{d} \right)$。我们结果的一个直接推论是，首次近乎最优的边界在从分离预言机到优化预言机的约简中错误增加。RSH在学习多面体中具有算法应用。我们考虑了一个基本问题，被称为“Hausdorff问题”，即在给定了关于K的优化预言机的情况下，学习一个单位直径多面体K，使其在Hausdorff距离$\delta$内。利用RSH，我们证明了在多项式时间内可以学习多面体K的解决方法。

    The Separating Hyperplane theorem is a fundamental result in Convex Geometry with myriad applications. Our first result, Random Separating Hyperplane Theorem (RSH), is a strengthening of this for polytopes. $\rsh$ asserts that if the distance between $a$ and a polytope $K$ with $k$ vertices and unit diameter in $\Re^d$ is at least $\delta$, where $\delta$ is a fixed constant in $(0,1)$, then a randomly chosen hyperplane separates $a$ and $K$ with probability at least $1/poly(k)$ and margin at least $\Omega \left(\delta/\sqrt{d} \right)$. An immediate consequence of our result is the first near optimal bound on the error increase in the reduction from a Separation oracle to an Optimization oracle over a polytope.  RSH has algorithmic applications in learning polytopes. We consider a fundamental problem, denoted the ``Hausdorff problem'', of learning a unit diameter polytope $K$ within Hausdorff distance $\delta$, given an optimization oracle for $K$. Using RSH, we show that with polynom
    
[^42]: 利用域随机化和元学习来缩小基于强化学习的交通信号控制中的现实差距

    Bridging the Reality Gap of Reinforcement Learning based Traffic Signal Control using Domain Randomization and Meta Learning. (arXiv:2307.11357v1 [cs.LG])

    [http://arxiv.org/abs/2307.11357](http://arxiv.org/abs/2307.11357)

    该论文研究了基于强化学习的交通信号控制中的现实差距问题，并提出了两种缩小现实差距的策略：域随机化和模型无关元学习。这些策略在一个交通仿真模型上进行了训练，并在不同的交通仿真模型上进行了性能评估。

    

    强化学习在交通信号控制应用中得到了广泛的探索，但是目前尚未有这样的系统在实践中得到部署。在这篇论文中，我们首先对可能导致现实差距的模拟参数进行了全面分析。然后，我们还研究了两种有望缩小这一差距的策略：域随机化和模型无关元学习。这两种策略都在一个交通仿真模型的基础上进行了训练。此外，该模型被嵌入到LemgoRL框架中，该框架将逼真的、安全关键的要求整合到控制系统中。随后，我们在一个不同的交通仿真模型上评估了这两种方法的性能。

    Reinforcement Learning (RL) has been widely explored in Traffic Signal Control (TSC) applications, however, still no such system has been deployed in practice. A key barrier to progress in this area is the reality gap, the discrepancy that results from differences between simulation models and their real-world equivalents. In this paper, we address this challenge by first presenting a comprehensive analysis of potential simulation parameters that contribute to this reality gap. We then also examine two promising strategies that can bridge this gap: Domain Randomization (DR) and Model-Agnostic Meta-Learning (MAML). Both strategies were trained with a traffic simulation model of an intersection. In addition, the model was embedded in LemgoRL, a framework that integrates realistic, safety-critical requirements into the control system. Subsequently, we evaluated the performance of the two methods on a separate model of the same intersection that was developed with a different traffic simul
    
[^43]: 一个单一的注意层能学到什么？通过随机特征视角的研究。

    What can a Single Attention Layer Learn? A Study Through the Random Features Lens. (arXiv:2307.11353v1 [cs.LG])

    [http://arxiv.org/abs/2307.11353](http://arxiv.org/abs/2307.11353)

    本研究通过随机特征分析，对单个注意层的学习和泛化进行了严格的理论研究。结果表明，在具有随机采样的关键矩阵和可训练值矩阵的情况下，随机特征注意层可以表示一类与关键向量置换无关的目标函数，并提供了学习这些目标函数的风险界限。

    

    注意层是Transformer架构的核心组成部分，通过将输入序列映射到输出序列，在现代人工智能领域取得了重要突破。本文对单个多头注意层进行了严格的理论研究，输入是一系列关键向量和一个独立的查询向量。我们考虑了一个随机特征设置，其中注意层具有大量头部，具有随机采样的冻结查询和关键矩阵以及可训练的值矩阵。我们展示了这样一个随机特征的注意层可以表示一类与关键向量置换无关的目标函数。我们进一步提供了有限样本情况下学习这些目标函数的定量过量风险界限的方法，使用有限数量的头部和随机特征注意层。我们的结果相比现有的随机线性功能模型有几个注意结构上的独特影响。

    Attention layers -- which map a sequence of inputs to a sequence of outputs -- are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads.  Our results feature several implications unique to the attention structure compared with existing ra
    
[^44]: 基于模型的离线强化学习与基于计数保守性的结合方法

    Model-based Offline Reinforcement Learning with Count-based Conservatism. (arXiv:2307.11352v1 [cs.LG])

    [http://arxiv.org/abs/2307.11352](http://arxiv.org/abs/2307.11352)

    本文提出了一种基于模型的离线强化学习方法$\texttt{Count-MORL}$，通过利用计数保守性来量化模型估计误差，证明了基于计数保守性在离线深度强化学习中的有效性，并展示了学习到的策略提供了接近最优性能的保证。

    

    本文提出了一种名为$\texttt{Count-MORL}$的基于模型的离线强化学习方法，它利用了状态动作对的计数估计来量化模型估计误差，据我们所知，这是首个证明了基于计数保守性在基于模型的离线深度强化学习中的有效性的算法。我们首先展示了估计误差与状态动作对的频率成反比的关系。其次，我们证明了在基于计数保守模型下学习的策略提供了接近最优性能的保证。通过大量的数值实验，我们验证了使用哈希编码实现的$\texttt{Count-MORL}$在D4RL基准数据集上显著优于现有离线强化学习算法。代码可在$\href{https://github.com/oh-lab/Count-MORL}{https://github.com/oh-lab/Count-MORL}$上进行访问。

    In this paper, we propose a model-based offline reinforcement learning method that integrates count-based conservatism, named $\texttt{Count-MORL}$. Our method utilizes the count estimates of state-action pairs to quantify model estimation error, marking the first algorithm of demonstrating the efficacy of count-based conservatism in model-based offline deep RL to the best of our knowledge. For our proposed method, we first show that the estimation error is inversely proportional to the frequency of state-action pairs. Secondly, we demonstrate that the learned policy under the count-based conservative model offers near-optimality performance guarantees. Through extensive numerical experiments, we validate that $\texttt{Count-MORL}$ with hash code implementation significantly outperforms existing offline RL algorithms on the D4RL benchmark datasets. The code is accessible at $\href{https://github.com/oh-lab/Count-MORL}{https://github.com/oh-lab/Count-MORL}$.
    
[^45]: 参数规划的选择性推断中的有界P值

    Bounded P-values in Parametric Programming-based Selective Inference. (arXiv:2307.11351v1 [stat.ML])

    [http://arxiv.org/abs/2307.11351](http://arxiv.org/abs/2307.11351)

    本研究提出了一种降低参数规划选择性推断计算成本的方法，通过计算p值的上界和下界来保证所需精度。

    

    选择性推断（SI）作为一种适用于数据驱动的假设检验的有前景的框架，一直受到研究关注。SI的基本思想是在一个假设被选中的事件的条件下进行推断。为了进行SI，必须以可追踪的形式对这个事件进行描述。当选择事件难以描述时，可以引入额外的条件以使其可处理。这些额外的条件往往会导致功效的损失，这一问题被称为过度条件化。基于参数规划的SI（PP-based SI）被提出作为解决过度条件化问题的一种方法。PP-based SI的主要问题是由于需要完全地探索数据空间而导致计算成本高。本研究引入了一种降低计算成本的过程，同时保证所需精度，通过提出计算p值的上界和下界的方法。我们还提出了三种类型的搜索策略。

    Selective inference (SI) has been actively studied as a promising framework for statistical hypothesis testing for data-driven hypotheses. The basic idea of SI is to make inferences conditional on an event that a hypothesis is selected. In order to perform SI, this event must be characterized in a traceable form. When selection event is too difficult to characterize, additional conditions are introduced for tractability. This additional conditions often causes the loss of power, and this issue is referred to as over-conditioning. Parametric programming-based SI (PP-based SI) has been proposed as one way to address the over-conditioning issue. The main problem of PP-based SI is its high computational cost due to the need to exhaustively explore the data space. In this study, we introduce a procedure to reduce the computational cost while guaranteeing the desired precision, by proposing a method to compute the upper and lower bounds of p-values. We also proposed three types of search str
    
[^46]: 通过贝叶斯攻击提高对抗性样本的可迁移性

    Improving Transferability of Adversarial Examples via Bayesian Attacks. (arXiv:2307.11334v1 [cs.LG])

    [http://arxiv.org/abs/2307.11334](http://arxiv.org/abs/2307.11334)

    通过将贝叶斯公式应用于模型参数和模型输入，本文提出了一种改进对抗性样本可迁移性的方法，实证研究表明具有显著提高效果，并超过了当前最新技术。

    

    本文是对我们在ICLR上发表工作的重要扩展。我们的ICLR工作提出了将贝叶斯公式应用于模型参数，以提高对抗性样本的可迁移性，从而有效模拟了无限多个深度神经网络的集合。而在这篇论文中，我们通过将贝叶斯公式应用于模型输入，引入了一种新颖的扩展，使得模型输入和模型参数都能够进行联合多样化。我们的实证研究证明：1）对模型输入和模型参数同时应用贝叶斯公式可以显著提高可迁移性；2）通过引入对模型输入后验分布的高级近似，攻击无需模型微调时，对抗性可迁移性得到进一步提升，超过了所有的最新技术。此外，我们还提出了一种有原则的方法来对模型参数进行微调。

    This paper presents a substantial extension of our work published at ICLR. Our ICLR work advocated for enhancing transferability in adversarial examples by incorporating a Bayesian formulation into model parameters, which effectively emulates the ensemble of infinitely many deep neural networks, while, in this paper, we introduce a novel extension by incorporating the Bayesian formulation into the model input as well, enabling the joint diversification of both the model input and model parameters. Our empirical findings demonstrate that: 1) the combination of Bayesian formulations for both the model input and model parameters yields significant improvements in transferability; 2) by introducing advanced approximations of the posterior distribution over the model input, adversarial transferability achieves further enhancement, surpassing all state-of-the-arts when attacking without model fine-tuning. Moreover, we propose a principled approach to fine-tune model parameters in such an ext
    
[^47]: 揭示联邦学习中局部和全局公平性权衡的信息分解方法

    Demystifying Local and Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition. (arXiv:2307.11333v1 [cs.LG])

    [http://arxiv.org/abs/2307.11333](http://arxiv.org/abs/2307.11333)

    本文利用信息论的部分信息分解（PID）方法，研究了在联邦学习中关于敏感属性的群体公平性权衡问题。通过分解发现了三种不公平来源，分别是唯一不平等性、冗余不平等性和掩盖不平等性，揭示了全局和局部公平性之间的基本限制和权衡。

    

    本文从信息论的角度，研究了在联邦学习中关于敏感属性（如性别、种族等）的群体公平性权衡问题。现有工作主要关注“全局公平性”（模型在所有客户端上的不平等程度）或“局部公平性”（模型在每个个体客户端上的不平等程度），而并不总是考虑它们之间的权衡。对于联邦学习中的全局公平性和局部公平性之间的相互作用，以及一个是否暗示另一个，我们缺乏理解。为了弥补这一空白，我们利用了信息论中的部分信息分解（PID）方法，首先确定了联邦学习中三种不公平来源，即“唯一不平等性”、“冗余不平等性”和“掩盖不平等性”。通过典型案例，我们演示了这三种不平等性如何影响全局和局部公平性。这种分解帮助我们推导出全局和局部公平性之间的基本限制和权衡。

    In this paper, we present an information-theoretic perspective to group fairness trade-offs in federated learning (FL) with respect to sensitive attributes, such as gender, race, etc. Existing works mostly focus on either \emph{global fairness} (overall disparity of the model across all clients) or \emph{local fairness} (disparity of the model at each individual client), without always considering their trade-offs. There is a lack of understanding of the interplay between global and local fairness in FL, and if and when one implies the other. To address this gap, we leverage a body of work in information theory called partial information decomposition (PID) which first identifies three sources of unfairness in FL, namely, \emph{Unique Disparity}, \emph{Redundant Disparity}, and \emph{Masked Disparity}. Using canonical examples, we demonstrate how these three disparities contribute to global and local fairness. This decomposition helps us derive fundamental limits and trade-offs between
    
[^48]: 超越收敛性：机器学习和深度学习模型的可识别性

    Beyond Convergence: Identifiability of Machine Learning and Deep Learning Models. (arXiv:2307.11332v1 [cs.LG])

    [http://arxiv.org/abs/2307.11332](http://arxiv.org/abs/2307.11332)

    本研究探讨了机器学习和深度学习模型中的参数可识别性。通过一个运动传感器数据的参数估计案例研究，发现虽然某些参数可以从观测数据中识别出来，但其他参数仍然不可识别。这表明不可识别性是实验设置的固有限制，需要改变数据收集方法。

    

    机器学习和深度学习模型被广泛应用于参数优化和回归问题。然而，并非所有机器学习的逆问题都是“可识别的”，这意味着模型参数可能无法从可用数据和数据模型的输入-输出关系中唯一确定。本研究通过一个以运动传感器数据的参数估计为重点的案例研究，探讨了模型参数可识别性的概念。利用双足弹簧质点人类行走动力学模型，我们生成了表示不同步态模式和条件的合成数据。通过使用深度神经网络，我们尝试估计个体参数，包括质量、刚度和平衡腿长。结果表明，虽然某些参数可以从观测数据中识别出来，但其他参数仍然不可识别，这凸显了不可识别性是实验设置的固有限制，需要改变数据收集方法。

    Machine learning (ML) and deep learning models are extensively used for parameter optimization and regression problems. However, not all inverse problems in ML are ``identifiable,'' indicating that model parameters may not be uniquely determined from the available data and the data model's input-output relationship. In this study, we investigate the notion of model parameter identifiability through a case study focused on parameter estimation from motion sensor data. Utilizing a bipedal-spring mass human walk dynamics model, we generate synthetic data representing diverse gait patterns and conditions. Employing a deep neural network, we attempt to estimate subject-wise parameters, including mass, stiffness, and equilibrium leg length. The results show that while certain parameters can be identified from the observation data, others remain unidentifiable, highlighting that unidentifiability is an intrinsic limitation of the experimental setup, necessitating a change in data collection a
    
[^49]: 从真实环境到虚拟环境的通信聚焦机器学习模型的系统适应：用于人机合作的研究

    Systematic Adaptation of Communication-focused Machine Learning Models from Real to Virtual Environments for Human-Robot Collaboration. (arXiv:2307.11327v1 [cs.HC])

    [http://arxiv.org/abs/2307.11327](http://arxiv.org/abs/2307.11327)

    该论文研究了如何将在真实环境中表现良好的深度学习模型适应到虚拟环境中，以实现人机合作中自然和直观的手势识别。

    

    虚拟现实在游戏、医学、培训以及人机合作界面的开发中表现出了其实用性。为了在虚拟环境中利用自然和直观的手势识别以实现协作机器人的体现式远程操作，需要创建大型的标注数据集。然而，根据不同的应用，这可能在计算或经济上具有限制性。因此，本研究旨在将在真实环境中表现良好的深度学习模型进行适应。

    Virtual reality has proved to be useful in applications in several fields ranging from gaming, medicine, and training to development of interfaces that enable human-robot collaboration. It empowers designers to explore applications outside of the constraints posed by the real world environment and develop innovative solutions and experiences. Hand gestures recognition which has been a topic of much research and subsequent commercialization in the real world has been possible because of the creation of large, labelled datasets. In order to utilize the power of natural and intuitive hand gestures in the virtual domain for enabling embodied teleoperation of collaborative robots, similarly large datasets must be created so as to keep the working interface easy to learn and flexible enough to add more gestures. Depending on the application, this may be computationally or economically prohibitive. Thus, the adaptation of trained deep learning models that perform well in the real environment 
    
[^50]: 萨赫勒以南非洲象移动的分析：生态学、气候和保护观点

    Analysis of Elephant Movement in Sub-Saharan Africa: Ecological, Climatic, and Conservation Perspectives. (arXiv:2307.11325v1 [q-bio.PE])

    [http://arxiv.org/abs/2307.11325](http://arxiv.org/abs/2307.11325)

    本研究分析了萨赫勒以南非洲象移动的模式，重点关注了季节变化和降雨模式等动态驱动因素。研究结果有助于预测生态因素对象迁徙的潜在影响，并为制定保护策略提供了综合的视角。

    

    象与环境的相互作用对生态学和保护策略都有深远的影响。本研究提出了一种分析方法来解读萨赫勒以南非洲象移动的复杂模式，重点关注季节变化和降雨模式等关键生态驱动因素。尽管围绕这些具有影响力的因素存在复杂性，我们的分析提供了对非洲动态景观背景下象迁徙行为的全面视角。我们综合的方法使我们能够预测这些生态决定因素对象迁徙的潜在影响，这是建立知情的保护策略的关键一步。考虑到全球气候变化对季节和降雨模式的影响，这种预测尤为重要，因为它未来可能会对象的行动产生显著影响。我们的工作成果旨在不仅推进对移动生态学的理解，同时也为保护实践提供参考。

    The interaction between elephants and their environment has profound implications for both ecology and conservation strategies. This study presents an analytical approach to decipher the intricate patterns of elephant movement in Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal variations and rainfall patterns. Despite the complexities surrounding these influential factors, our analysis provides a holistic view of elephant migratory behavior in the context of the dynamic African landscape. Our comprehensive approach enables us to predict the potential impact of these ecological determinants on elephant migration, a critical step in establishing informed conservation strategies. This projection is particularly crucial given the impacts of global climate change on seasonal and rainfall patterns, which could substantially influence elephant movements in the future. The findings of our work aim to not only advance the understanding of movement ecology but also f
    
[^51]: XLDA: 线性判别分析用于在边缘上进行极端分类的扩展

    XLDA: Linear Discriminant Analysis for Scaling Continual Learning to Extreme Classification at the Edge. (arXiv:2307.11317v1 [cs.LG])

    [http://arxiv.org/abs/2307.11317](http://arxiv.org/abs/2307.11317)

    本文提出了一种名为 XLDA 的框架，可在边缘上进行极端分类，其中使用的线性判别分析（LDA）分类器等效于全连接（FC）层，通过优化实现了加速训练和推理的方法，并在极端数据集上进行了验证。

    

    流式线性判别分析（LDA）在边缘上部署受限类别（最多1000个）的增量学习中已经被证明有效，但在极度分类场景中尚未得到证明。本文提出了：（a）XLDA，一种用于边缘部署中类增量学习的框架，其中LDA分类器被证明与FC层等效，包括在极度分类场景中；（b）优化以实现基于XLDA的训练和推理，其中存在可用计算资源的限制。我们展示了批处理训练方法下的42倍加速和最近邻搜索在AliProducts（50k类别）和Google Landmarks V2（81k类别）等极端数据集上的5倍推理加速。

    Streaming Linear Discriminant Analysis (LDA) while proven in Class-incremental Learning deployments at the edge with limited classes (upto 1000), has not been proven for deployment in extreme classification scenarios. In this paper, we present: (a) XLDA, a framework for Class-IL in edge deployment where LDA classifier is proven to be equivalent to FC layer including in extreme classification scenarios, and (b) optimizations to enable XLDA-based training and inference for edge deployment where there is a constraint on available compute resources. We show up to 42x speed up using a batched training approach and up to 5x inference speedup with nearest neighbor search on extreme datasets like AliProducts (50k classes) and Google Landmarks V2 (81k classes)
    
[^52]: 使预训练语言模型成为任务解决器和自校准器

    Making Pre-trained Language Models both Task-solvers and Self-calibrators. (arXiv:2307.11316v1 [cs.CL])

    [http://arxiv.org/abs/2307.11316](http://arxiv.org/abs/2307.11316)

    该论文研究了如何使预训练语言模型成为任务解决器和自校准器，在有限的训练样本、数据不平衡和其他实际挑战下进行了探索。

    

    预训练语言模型（PLMs）在各种实际系统中作为骨干。对于高风险应用，合理的置信度估计对于预测同样重要。虽然PLMs的常规置信度分数已经可以有效利用，但它们在错误预测中始终变得过于自信，这在实践中是不可取的。之前的工作表明，引入额外的校准任务可以缓解这个问题。基本思想是获得额外的数据来训练模型，以预测其初始预测的置信度。然而，它只是展示了这种方法的可行性，假设引入的校准任务有丰富的额外可用样本。在这项工作中，我们考虑到实际情况，我们需要有效利用训练样本，使PLMs成为任务解决器和自校准器。提出了三个挑战，包括有限的训练样本、数据不平衡和…

    Pre-trained language models (PLMs) serve as backbones for various real-world systems. For high-stake applications, it's equally essential to have reasonable confidence estimations in predictions. While the vanilla confidence scores of PLMs can already be effectively utilized, PLMs consistently become overconfident in their wrong predictions, which is not desirable in practice. Previous work shows that introducing an extra calibration task can mitigate this issue. The basic idea involves acquiring additional data to train models in predicting the confidence of their initial predictions. However, it only demonstrates the feasibility of this kind of method, assuming that there are abundant extra available samples for the introduced calibration task. In this work, we consider the practical scenario that we need to effectively utilize training samples to make PLMs both task-solvers and self-calibrators. Three challenges are presented, including limited training samples, data imbalance, and 
    
[^53]: 基于神经形态学的在线学习用于时空模式识别， 使用正向时间线。 (arXiv:2307.11314v1 [cs.NE])

    Neuromorphic Online Learning for Spatiotemporal Patterns with a Forward-only Timeline. (arXiv:2307.11314v1 [cs.NE])

    [http://arxiv.org/abs/2307.11314](http://arxiv.org/abs/2307.11314)

    本论文提出了一种基于神经形态学的在线学习算法，用于时空模式识别。该算法适用于在线学习脉冲神经网络，并且能够学习突触权重和调整时间滤波器，具有较低的计算和存储成本。

    

    脉冲神经网络(SNNs)是具有高能效的生物合理计算模型。神经元和突触的时间动态使其能够检测时间模式并生成序列。传统上使用时间反向传播(BPTT)来训练SNNs，但对于嵌入式应用的在线学习来说，BPTT不适合，因为它具有高计算和存储成本以及延迟时间较长。以前的研究提出了在线学习算法，但它们通常使用高度简化的脉冲神经元模型，没有突触动力学和重置反馈，导致性能不佳。在这项工作中，我们提出了适用于在线学习LIF神经元组成的SNNs的时空在线学习算法(SOLSA)，该算法具有指数衰减的突触和软重置。该算法不仅可以学习突触权重，还可以调整与突触相关的时间滤波器。与BPTT算法相比，SOLSA算法不仅在性能上更优秀，而且通过适应性学习实现较低的计算和存储成本。

    Spiking neural networks (SNNs) are bio-plausible computing models with high energy efficiency. The temporal dynamics of neurons and synapses enable them to detect temporal patterns and generate sequences. While Backpropagation Through Time (BPTT) is traditionally used to train SNNs, it is not suitable for online learning of embedded applications due to its high computation and memory cost as well as extended latency. Previous works have proposed online learning algorithms, but they often utilize highly simplified spiking neuron models without synaptic dynamics and reset feedback, resulting in subpar performance. In this work, we present Spatiotemporal Online Learning for Synaptic Adaptation (SOLSA), specifically designed for online learning of SNNs composed of Leaky Integrate and Fire (LIF) neurons with exponentially decayed synapses and soft reset. The algorithm not only learns the synaptic weight but also adapts the temporal filters associated to the synapses. Compared to the BPTT al
    
[^54]: PI-VEGAN: 物理信息变分嵌入生成对抗网络应用于随机微分方程

    PI-VEGAN: Physics Informed Variational Embedding Generative Adversarial Networks for Stochastic Differential Equations. (arXiv:2307.11289v1 [cs.LG])

    [http://arxiv.org/abs/2307.11289](http://arxiv.org/abs/2307.11289)

    PI-VEGAN是一种物理信息神经网络，通过将控制物理定律融入模型并引入变分编码器来解决随机微分方程的各种问题。

    

    我们提出了一种新的物理信息神经网络类型，称为物理信息变分嵌入生成对抗网络（PI-VEGAN），它有效地解决了随机微分方程的正向、反向和混合问题。在这些情况下，控制方程是已知的，但只有系统参数的少量传感器测量结果可用。我们使用自动微分将控制物理定律融入PI-VEGAN中，同时引入变分编码器来近似测量结果实际分布的潜在变量。这些潜在变量被融入生成器中，以便准确地学习随机偏微分方程的特征。我们的模型由三个组件组成，分别是编码器、生成器和判别器，每个组件都使用随机梯度下降算法交替进行更新。

    We present a new category of physics-informed neural networks called physics informed variational embedding generative adversarial network (PI-VEGAN), that effectively tackles the forward, inverse, and mixed problems of stochastic differential equations. In these scenarios, the governing equations are known, but only a limited number of sensor measurements of the system parameters are available. We integrate the governing physical laws into PI-VEGAN with automatic differentiation, while introducing a variational encoder for approximating the latent variables of the actual distribution of the measurements. These latent variables are integrated into the generator to facilitate accurate learning of the characteristics of the stochastic partial equations. Our model consists of three components, namely the encoder, generator, and discriminator, each of which is updated alternatively employing the stochastic gradient descent algorithm. We evaluate the effectiveness of PI-VEGAN in addressing 
    
[^55]: 基于内核的离线背景双向竞标者算法

    Kernelized Offline Contextual Dueling Bandits. (arXiv:2307.11288v1 [cs.LG])

    [http://arxiv.org/abs/2307.11288](http://arxiv.org/abs/2307.11288)

    本论文提出了基于内核的离线背景双向竞标者算法，用于解决基于偏好反馈的问题，并证明了算法的遗憾界。通过实验证明该方法优于使用均匀采样上下文的相似策略。

    

    基于偏好的反馈在许多应用中非常重要，这些应用中无法直接评估奖励函数。在人们对大型语言模型的强化学习中，这是一个显著的最新实例。对于许多这些应用，获取人类反馈的成本可能相当高甚至不可行。在这项工作中，我们利用一个事实，即代理通常可以选择获得人类反馈的上下文，以最高效地确定一个良好策略，并引入了离线背景双向竞标者设置。我们为这个设置提供了一个上界置信区间样式的算法，并证明了一个遗憾上界。我们还通过经验证实这种方法胜过使用均匀采样上下文的类似策略。

    Preference-based feedback is important for many applications where direct evaluation of a reward function is not feasible. A notable recent example arises in reinforcement learning from human feedback on large language models. For many of these applications, the cost of acquiring the human feedback can be substantial or even prohibitive. In this work, we take advantage of the fact that often the agent can choose contexts at which to obtain human feedback in order to most efficiently identify a good policy, and introduce the offline contextual dueling bandit setting. We give an upper-confidence-bound style algorithm for this setting and prove a regret bound. We also give empirical confirmation that this method outperforms a similar strategy that uses uniformly sampled contexts.
    
[^56]: MAS：面向资源高效的联邦多任务学习

    MAS: Towards Resource-Efficient Federated Multiple-Task Learning. (arXiv:2307.11285v1 [cs.LG])

    [http://arxiv.org/abs/2307.11285](http://arxiv.org/abs/2307.11285)

    本研究提出了第一个有效协调和训练多个同时进行的联邦学习任务的联邦学习系统MAS，通过合并和分割联邦学习任务来优化性能，实验证明其在减少训练时间的同时超过其他方法。

    

    联邦学习是一种新兴的分布式机器学习方法，可以使分布式边缘设备进行模型训练。然而，多个同时进行的联邦学习任务可能会过载资源受限的设备。在这项工作中，我们提出了第一个有效协调和训练多个同时进行的联邦学习任务的联邦学习系统。我们首先形式化了训练同时进行的联邦学习任务的问题。然后，我们提出了新的方法MAS（Merge and Split），以优化训练多个同时进行的联邦学习任务的性能。MAS首先将联邦学习任务合并为一个具有多任务体系结构的整体联邦学习任务。在训练几轮后，MAS通过使用整体训练期间测量的任务之间的亲和性将整体联邦学习任务分割为两个或更多个联邦学习任务。然后，基于整体训练的模型参数，继续训练每个分割的联邦学习任务。大量实验证明，MAS在减少训练时间的同时优于其他方法。

    Federated learning (FL) is an emerging distributed machine learning method that empowers in-situ model training on decentralized edge devices. However, multiple simultaneous FL tasks could overload resource-constrained devices. In this work, we propose the first FL system to effectively coordinate and train multiple simultaneous FL tasks. We first formalize the problem of training simultaneous FL tasks. Then, we present our new approach, MAS (Merge and Split), to optimize the performance of training multiple simultaneous FL tasks. MAS starts by merging FL tasks into an all-in-one FL task with a multi-task architecture. After training for a few rounds, MAS splits the all-in-one FL task into two or more FL tasks by using the affinities among tasks measured during the all-in-one training. It then continues training each split of FL tasks based on model parameters from the all-in-one training. Extensive experiments demonstrate that MAS outperforms other methods while reducing training time
    
[^57]: Epsilon*: 机器学习模型的隐私度量

    Epsilon*: Privacy Metric for Machine Learning Models. (arXiv:2307.11280v1 [cs.LG])

    [http://arxiv.org/abs/2307.11280](http://arxiv.org/abs/2307.11280)

    Epsilon*是一种用于测量机器学习模型隐私风险的新度量方法，不需要访问训练数据或模型训练算法，能与成员推断攻击中的假设检验相结合，提供对经过训练的模型实例隐私损失的下界，避免数值和噪声放大不稳定性。

    

    我们引入了Epsilon*，一种新的隐私度量方法，用于在隐私减轻策略部署之前、期间或之后，测量单个模型实例的隐私风险。该度量不需要访问训练数据采样或模型训练算法。Epsilon*是一个关于真阳性和假阳性率的函数，用于敌手在成员推断攻击中使用的假设检验中。我们区分了量化经过训练的模型实例的隐私损失和量化产生该模型实例的训练机制的隐私损失。现有的隐私审计文献中的方法为后者提供了下界，而我们的度量方法通过依赖于训练模型实例的隐私的（ε，δ）型量化，为前者提供了下界。我们建立了这些下界之间的关系，并展示了如何实现Epsilon*以避免数值和噪声放大不稳定性。

    We introduce Epsilon*, a new privacy metric for measuring the privacy risk of a single model instance prior to, during, or after deployment of privacy mitigation strategies. The metric does not require access to the training data sampling or model training algorithm. Epsilon* is a function of true positive and false positive rates in a hypothesis test used by an adversary in a membership inference attack. We distinguish between quantifying the privacy loss of a trained model instance and quantifying the privacy loss of the training mechanism which produces this model instance. Existing approaches in the privacy auditing literature provide lower bounds for the latter, while our metric provides a lower bound for the former by relying on an (${\epsilon}$,${\delta}$)-type of quantification of the privacy of the trained model instance. We establish a relationship between these lower bounds and show how to implement Epsilon* to avoid numerical and noise amplification instability. We further 
    
[^58]: 乳腺癌筛查乳腺摄影检测

    Screening Mammography Breast Cancer Detection. (arXiv:2307.11274v1 [eess.IV])

    [http://arxiv.org/abs/2307.11274](http://arxiv.org/abs/2307.11274)

    本研究提出了一种自动化乳腺癌检测解决方案，旨在提高筛查程序的效率和准确性，通过在RSNA数据集上测试不同的方法，得出了平均验证案例pF1得分为0.56。

    

    乳腺癌是导致癌症相关死亡的主要原因，但现有的程序成本高昂且容易出现假阳性，导致不必要的后续检查和患者焦虑。本文提出了一种自动化乳腺癌检测的解决方案，以提高筛查程序的效率和准确性。不同的方法在RSNA数据集的大约20,000名女性患者的传统乳房图像上进行了测试，并在各种方法之间获得了平均验证案例pF1得分为0.56。

    Breast cancer is a leading cause of cancer-related deaths, but current programs are expensive and prone to false positives, leading to unnecessary follow-up and patient anxiety. This paper proposes a solution to automated breast cancer detection, to improve the efficiency and accuracy of screening programs. Different methodologies were tested against the RSNA dataset of radiographic breast images of roughly 20,000 female patients and yielded an average validation case pF1 score of 0.56 across methods.
    
[^59]: 关于证据下界的Fisher-Rao梯度研究

    On the Fisher-Rao Gradient of the Evidence Lower Bound. (arXiv:2307.11249v1 [cs.LG])

    [http://arxiv.org/abs/2307.11249](http://arxiv.org/abs/2307.11249)

    本文研究了证据下界的Fisher-Rao梯度，揭示了它与目标分布的Kullback-Leibler散度梯度的关系，进一步证明了最小化主要目标函数与最大化ELBO的等价性。

    

    本文研究了证据下界（ELBO）的Fisher-Rao梯度，也称为自然梯度，它在变分自动编码器理论、Helmholtz机和自由能原理中起着关键作用。ELBO的自然梯度与目标分布的Kullback-Leibler散度的自然梯度相关，后者是学习的主要目标函数。基于信息几何中梯度的不变性特性，提供了关于底层模型的条件，确保最小化主要目标函数与最大化ELBO的等价性。

    This article studies the Fisher-Rao gradient, also referred to as the natural gradient, of the evidence lower bound, the ELBO, which plays a crucial role within the theory of the Variational Autonecoder, the Helmholtz Machine and the Free Energy Principle. The natural gradient of the ELBO is related to the natural gradient of the Kullback-Leibler divergence from a target distribution, the prime objective function of learning. Based on invariance properties of gradients within information geometry, conditions on the underlying model are provided that ensure the equivalence of minimising the prime objective function and the maximisation of the ELBO.
    
[^60]: 利用神经形态计算的传感器数据滤波在高能物理实验中的应用

    On-Sensor Data Filtering using Neuromorphic Computing for High Energy Physics Experiments. (arXiv:2307.11242v1 [cs.NE])

    [http://arxiv.org/abs/2307.11242](http://arxiv.org/abs/2307.11242)

    本文研究了在高能物理实验中利用神经形态计算的尖峰神经网络（SNN）模型对传感器数据进行滤波的方法。通过将传入的电荷波形转换为二值事件流，并优化SNN的系统设计和超参数，我们得到了信号有效率约为91%的SNN模型，参数数量几乎是深度神经网络的一半。

    

    本文描述了利用基于神经形态计算的尖峰神经网络（SNN）模型对在高亮度大型强子对撞机进行的高能物理实验中的传感器数据进行滤波的研究。我们提出了一种开发紧凑型神经形态模型的方法，该模型基于粒子的横向动量来滤除传感器数据，目标是减少传输到下游电子设备的数据量。传入的电荷波形被转换为二值事件流，然后由SNN进行处理。我们介绍了针对硬件部署进行优化的准确且紧凑的SNN的各种系统设计选择，从数据编码到训练算法的最佳超参数。我们的结果表明，利用进化算法和优化的超参数训练的SNN在信号有效率方面大约达到91%，参数数量几乎是深度神经网络的一半。

    This work describes the investigation of neuromorphic computing-based spiking neural network (SNN) models used to filter data from sensor electronics in high energy physics experiments conducted at the High Luminosity Large Hadron Collider. We present our approach for developing a compact neuromorphic model that filters out the sensor data based on the particle's transverse momentum with the goal of reducing the amount of data being sent to the downstream electronics. The incoming charge waveforms are converted to streams of binary-valued events, which are then processed by the SNN. We present our insights on the various system design choices - from data encoding to optimal hyperparameters of the training algorithm - for an accurate and compact SNN optimized for hardware deployment. Our results show that an SNN trained with an evolutionary algorithm and an optimized set of hyperparameters obtains a signal efficiency of about 91% with nearly half as many parameters as a deep neural netw
    
[^61]: 网络索引信号的边缘离群值

    Edgewise outliers of network indexed signals. (arXiv:2307.11239v1 [stat.ME])

    [http://arxiv.org/abs/2307.11239](http://arxiv.org/abs/2307.11239)

    该论文研究了涉及依赖关系的网络索引多变量数据模型，并介绍了边缘离群值的概念。通过推导平方和的分布和提出鲁棒版本的边缘MCD算法，实现了离群值的检测。模拟数据和真实数据的应用结果验证了方法的实用性。

    

    我们考虑涉及变量之间以及图节点之间依赖关系的网络索引多变量数据模型。在这些模型的框架下，我们着重于离群值检测，并引入了边缘离群值的概念。为此，我们首先推导一些平方和的分布，特别是可以用于离群值检测的平方马氏距离以确定检测规则和阈值。然后我们提出了一种鲁棒版本的确定性MCD算法，称为边缘MCD。对模拟数据进行的应用显示了考虑依赖结构的兴趣。我们还用真实数据集说明了所提方法的实用性。

    We consider models for network indexed multivariate data involving a dependence between variables as well as across graph nodes.  In the framework of these models, we focus on outliers detection and introduce the concept of edgewise outliers. For this purpose, we first derive the distribution of some sums of squares, in particular squared Mahalanobis distances that can be used to fix detection rules and thresholds for outlier detection. We then propose a robust version of the deterministic MCD algorithm that we call edgewise MCD. An application on simulated data shows the interest of taking the dependence structure into account. We also illustrate the utility of the proposed method with a real data set.
    
[^62]: QDC: 图上的量子扩散卷积核

    QDC: Quantum Diffusion Convolution Kernels on Graphs. (arXiv:2307.11234v1 [cs.LG])

    [http://arxiv.org/abs/2307.11234](http://arxiv.org/abs/2307.11234)

    本论文提出了一种新的卷积核，通过根据顶点占据相关性对图进行有效重连，以实现传播量子粒子的扩散范式。此外，还引入了一种多尺度变种，结合了传统的拉普拉斯算子和新的卷积核。通过研究我们发现同质化的谱依赖性和量子动力学在带通滤波器构造中的重要性。

    

    图卷积神经网络 (GCN) 通过在局部邻域上聚合消息来进行预测任务。许多 GCNs 可以被理解为在图上扩散输入特征的一种形式，并且通过改变消息传递的方式来提高预测准确性的工作已经有很多。在这项工作中，我们提出了一种根据顶点占据相关性来有效重新连接图的卷积核，以基于图上量子粒子的一般扩散范式进行传播。我们称此新的卷积核为量子扩散卷积 (QDC) 算子。此外，我们引入了一个多尺度变种，将 QDC 算子和传统的组合拉普拉斯算子的消息结合起来。为了理解我们的方法，我们探讨了同质化的谱依赖性以及量子动力学在带通滤波器构造中的重要性。通过这些研究，我们发现...

    Graph convolutional neural networks (GCNs) operate by aggregating messages over local neighborhoods given the prediction task under interest. Many GCNs can be understood as a form of generalized diffusion of input features on the graph, and significant work has been dedicated to improving predictive accuracy by altering the ways of message passing. In this work, we propose a new convolution kernel that effectively rewires the graph according to the occupation correlations of the vertices by trading on the generalized diffusion paradigm for the propagation of a quantum particle over the graph. We term this new convolution kernel the Quantum Diffusion Convolution (QDC) operator. In addition, we introduce a multiscale variant that combines messages from the QDC operator and the traditional combinatorial Laplacian. To understand our method, we explore the spectral dependence of homophily and the importance of quantum dynamics in the construction of a bandpass filter. Through these studies,
    
[^63]: 从自适应查询释放到机器取消学习

    From Adaptive Query Release to Machine Unlearning. (arXiv:2307.11228v1 [cs.LG])

    [http://arxiv.org/abs/2307.11228](http://arxiv.org/abs/2307.11228)

    该论文将机器取消学习问题形式化为设计高效的取消学习算法，给出了线性和前缀和查询类的高效取消学习算法，以及应用于随机凸优化问题的改进保证。

    

    我们将机器取消学习问题形式化为设计高效取消学习算法来对应从结构化查询类中选择自适应查询的学习算法。我们给出了线性和前缀和查询类的高效取消学习算法。作为应用，我们展示了在许多问题中，特别是随机凸优化（SCO）中的取消学习可以通过上述方法来减少，从而改善问题的保证。特别地，对于平滑的Lipschitz损失和任意的$\rho>0$，我们的结果给出了一个取消学习算法，其超出总体风险为$\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$，取消学习查询（梯度）复杂性为$\tilde O(\rho \cdot \text{重新训练复杂性})$，其中$d$是模型的维度，$n$是初始样本数。对于非平滑的Lipschitz损失，我们给出了一个取消学习算法，其超出总体风险为$\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}$

    We formalize the problem of machine unlearning as design of efficient unlearning algorithms corresponding to learning algorithms which perform a selection of adaptive queries from structured query classes. We give efficient unlearning algorithms for linear and prefix-sum query classes. As applications, we show that unlearning in many problems, in particular, stochastic convex optimization (SCO), can be reduced to the above, yielding improved guarantees for the problem. In particular, for smooth Lipschitz losses and any $\rho>0$, our results yield an unlearning algorithm with excess population risk of $\tilde O\big(\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\rho}\big)$ with unlearning query (gradient) complexity $\tilde O(\rho \cdot \text{Retraining Complexity})$, where $d$ is the model dimensionality and $n$ is the initial number of samples. For non-smooth Lipschitz losses, we give an unlearning algorithm with excess population risk $\tilde O\big(\frac{1}{\sqrt{n}}+\big(\frac{\sqrt{d}}{n\rho}
    
[^64]: Jina Embeddings:一种新颖的高性能句子嵌入模型

    Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v1 [cs.CL])

    [http://arxiv.org/abs/2307.11224](http://arxiv.org/abs/2307.11224)

    Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。

    

    Jina Embeddings由一组高性能的句子嵌入模型组成，能够将各种文本输入转化为数值表示，从而捕捉文本的语义本质。虽然这些模型并非专门设计用于文本生成，但在密集检索和语义文本相似性等应用中表现出色。本文详细介绍了Jina Embeddings的开发过程，从创建高质量的成对和三元数据集开始。它强调了数据清理在数据集准备中的关键作用，并对模型训练过程进行了深入探讨，最后利用Massive Textual Embedding Benchmark（MTEB）进行了全面的性能评估。

    Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB).
    
[^65]: FairMobi-Net:一个注重公平的深度学习模型用于城市流动生成

    FairMobi-Net: A Fairness-aware Deep Learning Model for Urban Mobility Flow Generation. (arXiv:2307.11214v1 [cs.LG])

    [http://arxiv.org/abs/2307.11214](http://arxiv.org/abs/2307.11214)

    FairMobi-Net是一种注重公平性的深度学习模型，用于生成跨区域的真实人流。它在损失函数中唯一地引入了公平性损失，并采用二进制分类和数值回归技术的混合方法。模型经过四个美国城市的全面验证，并能够预测人类流动。

    

    生成跨区域的真实人流对我们理解城市结构和人口活动模式至关重要，可以在城市规划和管理领域中应用。然而，现有大多数流动生成方法的一个明显缺点是忽视了预测公平性，这可能导致高危人群地区移动流量的低估，可能导致不公平的资源分配和基础设施发展。为了克服这个局限性，我们的研究提出了一种新颖的、注重公平性的深度学习模型FairMobi-Net，用于跨区域人流预测。FairMobi-Net模型将公平性损失独特地纳入损失函数，并采用二进制分类和数值回归技术的混合方法用于人流预测。我们使用四个美国城市的全面人流数据集验证了FairMobi-Net模型，并预测人类流动。

    Generating realistic human flows across regions is essential for our understanding of urban structures and population activity patterns, enabling important applications in the fields of urban planning and management. However, a notable shortcoming of most existing mobility generation methodologies is neglect of prediction fairness, which can result in underestimation of mobility flows across regions with vulnerable population groups, potentially resulting in inequitable resource distribution and infrastructure development. To overcome this limitation, our study presents a novel, fairness-aware deep learning model, FairMobi-Net, for inter-region human flow prediction. The FairMobi-Net model uniquely incorporates fairness loss into the loss function and employs a hybrid approach, merging binary classification and numerical regression techniques for human flow prediction. We validate the FairMobi-Net model using comprehensive human mobility datasets from four U.S. cities, predicting human
    
[^66]: 利用行政卫生保健数据，研究流行病学队列构建对无家可归和警察互动结果的机器学习预测的影响。

    The Effect of Epidemiological Cohort Creation on the Machine Learning Prediction of Homelessness and Police Interaction Outcomes Using Administrative Health Care Data. (arXiv:2307.11211v1 [cs.LG])

    [http://arxiv.org/abs/2307.11211](http://arxiv.org/abs/2307.11211)

    这项研究使用行政卫生保健数据探索了流行病学队列创建对于预测无家可归和警察互动结果的机器学习模型的影响，并比较了不同观察窗口的模型性能。

    

    背景：精神疾病可能导致无家可归和与警察的互动等不良结果，了解导致这些不良结果的事件是重要的。预测模型可以帮助识别处于风险中的个体。使用固定观察窗口的队列和逻辑回归（LR）或机器学习（ML）模型与自适应和分割窗口相比，性能较低。方法：使用了一个行政卫生保健数据集，包括2013年4月1日至2018年3月31日期间在加拿大阿尔伯塔省卡尔加里市被诊断为成瘾或精神疾病（AMH）的240,219个个体。对这个队列进行了2年的跟踪，以确定与无家可归和警察互动有关的因素。为了理解对预测模型的灵活窗口的好处，创建了一个替代队列。然后，对比了两个队列中的LR和ML模型，包括随机森林（RF）和极限梯度提升（XGBoost）。

    Background: Mental illness can lead to adverse outcomes such as homelessness and police interaction and understanding of the events leading up to these adverse outcomes is important. Predictive models may help identify individuals at risk of such adverse outcomes. Using a fixed observation window cohort with logistic regression (LR) or machine learning (ML) models can result in lower performance when compared with adaptive and parcellated windows. Method: An administrative healthcare dataset was used, comprising of 240,219 individuals in Calgary, Alberta, Canada who were diagnosed with addiction or mental health (AMH) between April 1, 2013, and March 31, 2018. The cohort was followed for 2 years to identify factors associated with homelessness and police interactions. To understand the benefit of flexible windows to predictive models, an alternative cohort was created. Then LR and ML models, including random forests (RF), and extreme gradient boosting (XGBoost) were compared in the two
    
[^67]: 临床试验主动学习

    Clinical Trial Active Learning. (arXiv:2307.11209v1 [cs.LG])

    [http://arxiv.org/abs/2307.11209](http://arxiv.org/abs/2307.11209)

    这项研究提出了一种考虑临床试验中非独立同分布结构的新型主动学习方法，并将其应用于光学相干断层扫描图像的疾病检测。研究表明，这种前瞻性主动学习方法能够克服传统方法的局限。

    

    本文提出了一种新颖的主动学习方法，考虑了临床试验环境中非独立同分布（non-i.i.d.）的结构。临床试验分为回顾性和前瞻性两种类型。回顾性临床试验在治疗后分析数据；前瞻性临床试验在治疗进行时收集数据。传统的主动学习方法通常假设数据集是独立同分布的（i.i.d.），选择训练样本时忽略了临床试验中数据间的依赖关系。因此，我们提出了前瞻性主动学习方法来克服传统主动学习方法的局限，并将其应用于光学相干断层扫描（OCT）图像中的疾病检测，通过对图像收集时间的条件约束来强制执行i.i.d.假设。我们将我们的方法与传统的主动学习范式进行了比较。

    This paper presents a novel approach to active learning that takes into account the non-independent and identically distributed (non-i.i.d.) structure of a clinical trial setting. There exists two types of clinical trials: retrospective and prospective. Retrospective clinical trials analyze data after treatment has been performed; prospective clinical trials collect data as treatment is ongoing. Typically, active learning approaches assume the dataset is i.i.d. when selecting training samples; however, in the case of clinical trials, treatment results in a dependency between the data collected at the current and past visits. Thus, we propose prospective active learning to overcome the limitations present in traditional active learning methods and apply it to disease detection in optical coherence tomography (OCT) images, where we condition on the time an image was collected to enforce the i.i.d. assumption. We compare our proposed method to the traditional active learning paradigm, whi
    
[^68]: 图像异常检测的启发式超参数选择

    Heuristic Hyperparameter Choice for Image Anomaly Detection. (arXiv:2307.11197v1 [cs.CV])

    [http://arxiv.org/abs/2307.11197](http://arxiv.org/abs/2307.11197)

    本研究针对图像异常检测问题提出了一种启发式方法，通过选择适当的超参数，实现对深度特征的降维，以减少冗余特征并提高性能。

    

    图像异常检测是一种基于深度学习神经网络的计算机视觉问题，用于识别与正常状态显著偏离的图像。通过对预训练模型提取的深度特征进行多元高斯分布分析，已经证明这些特征对于异常检测是至关重要的。然而，由于模型通常是在大型数据集（如ImageNet）上进行分类任务的预训练，因此它们可能会产生大量冗余的特征，增加了计算成本并降低了性能。我们旨在对这些特征进行负主成分分析（NPCA）的降维。因此，我们提出了一些启发式方法来选择NPCA算法的超参数，以尽可能获取较少的特征分量，同时确保良好的性能。

    Anomaly detection (AD) in images is a fundamental computer vision problem by deep learning neural network to identify images deviating significantly from normality. The deep features extracted from pretrained models have been proved to be essential for AD based on multivariate Gaussian distribution analysis. However, since models are usually pretrained on a large dataset for classification tasks such as ImageNet, they might produce lots of redundant features for AD, which increases computational cost and degrades the performance. We aim to do the dimension reduction of Negated Principal Component Analysis (NPCA) for these features. So we proposed some heuristic to choose hyperparameter of NPCA algorithm for getting as fewer components of features as possible while ensuring a good performance.
    
[^69]: 在MuJoCo环境中探索离散和连续控制任务的强化学习方法

    Exploring reinforcement learning techniques for discrete and continuous control tasks in the MuJoCo environment. (arXiv:2307.11166v1 [cs.LG])

    [http://arxiv.org/abs/2307.11166](http://arxiv.org/abs/2307.11166)

    该论文研究了在MuJoCo环境中离散和连续控制任务的强化学习方法，通过比较不同算法，发现DDPG在少量episode中表现优于其他方法。

    

    我们利用快速的物理模拟器MuJoCo在连续控制环境中运行任务，并揭示每个任务的观测空间、动作空间、奖励等详细信息。通过比较离散化方法中的Q学习和SARSA，将值基方法应用于连续控制任务，并使用它们作为基准，逐步向最先进的深度策略梯度方法DDPG过渡。在大量的episode中，Q学习的得分超过了SARSA，但DDPG在少量的episode中表现优于两者。最后，我们还通过调整模型超参数，期望在更少的时间和资源消耗下获得更好的性能。我们预期新设计的DDPG将大幅提高性能，然而在只有少数episode之后，我们已经能够达到不错的平均奖励。我们期望在足够的时间和计算资源下进一步提高性能。

    We leverage the fast physics simulator, MuJoCo to run tasks in a continuous control environment and reveal details like the observation space, action space, rewards, etc. for each task. We benchmark value-based methods for continuous control by comparing Q-learning and SARSA through a discretization approach, and using them as baselines, progressively moving into one of the state-of-the-art deep policy gradient method DDPG. Over a large number of episodes, Qlearning outscored SARSA, but DDPG outperformed both in a small number of episodes. Lastly, we also fine-tuned the model hyper-parameters expecting to squeeze more performance but using lesser time and resources. We anticipated that the new design for DDPG would vastly improve performance, yet after only a few episodes, we were able to achieve decent average rewards. We expect to improve the performance provided adequate time and computational resources.
    
[^70]: 对脑网络的可解释分类进行对比图池化。

    Contrastive Graph Pooling for Explainable Classification of Brain Networks. (arXiv:2307.11133v1 [q-bio.NC])

    [http://arxiv.org/abs/2307.11133](http://arxiv.org/abs/2307.11133)

    本论文提出了一种针对脑网络的对比图池化方法，以实现对脑网络的可解释分类。通过定制化的图神经网络和特殊设计的可解释特征提取方法，在5个静息态fMRI脑网络数据集上取得了优于最先进基准线的结果。

    

    功能性磁共振成像(fMRI)是一种常用的测量神经活动的技术。其应用在识别帕金森病、阿尔茨海默病和自闭症等神经退行性疾病方面尤为重要。最近的fMRI数据分析将大脑建模为图，并通过图神经网络(GNN)提取特征。然而，fMRI数据的独特特征要求对GNN进行特殊设计。定制GNN以生成有效且可解释的特征仍然具有挑战性。在本文中，我们提出了对比双注意块和可微分图池化方法ContrastPool，以更好地利用GNN分析脑网络，满足fMRI的特殊要求。我们将我们的方法应用于5个静息态fMRI脑网络数据集的3种疾病，并证明其优于最先进的基准线。我们的案例研究证实，我们的方法提取的模式与神经科学文献中的领域知识相匹配。

    Functional magnetic resonance imaging (fMRI) is a commonly used technique to measure neural activation. Its application has been particularly important in identifying underlying neurodegenerative conditions such as Parkinson's, Alzheimer's, and Autism. Recent analysis of fMRI data models the brain as a graph and extracts features by graph neural networks (GNNs). However, the unique characteristics of fMRI data require a special design of GNN. Tailoring GNN to generate effective and domain-explainable features remains challenging. In this paper, we propose a contrastive dual-attention block and a differentiable graph pooling method called ContrastPool to better utilize GNN for brain networks, meeting fMRI-specific requirements. We apply our method to 5 resting-state fMRI brain network datasets of 3 diseases and demonstrate its superiority over state-of-the-art baselines. Our case study confirms that the patterns extracted by our method match the domain knowledge in neuroscience literatu
    
[^71]: 通过密度匹配实现的合成对照方法下的隐式内生性问题

    Synthetic Control Methods by Density Matching under Implicit Endogeneitiy. (arXiv:2307.11127v1 [econ.EM])

    [http://arxiv.org/abs/2307.11127](http://arxiv.org/abs/2307.11127)

    本文提出了一种新型的合成对照方法，通过密度匹配来解决现有SCMs中的隐式内生性问题。该方法通过将经过处理单元的结果密度与未处理单元的密度进行加权平均来估计SC权重。

    

    合成对照方法（SCMs）已成为比较案例研究中因果推断的重要工具。SCMs的基本思想是通过使用来自未处理单元的观测结果的加权和来估计经过处理单元的反事实结果。合成对照（SC）的准确性对于估计因果效应至关重要，因此，SC权重的估计成为了研究的焦点。在本文中，我们首先指出现有的SCMs存在一个隐式内生性问题，即未处理单元的结果与反事实结果模型中的误差项之间的相关性。我们展示了这个问题会对因果效应估计器产生偏差。然后，我们提出了一种基于密度匹配的新型SCM，假设经过处理单元的结果密度可以用未处理单元的密度的加权平均来近似（即混合模型）。基于这一假设，我们通过匹配来估计SC权重。

    Synthetic control methods (SCMs) have become a crucial tool for causal inference in comparative case studies. The fundamental idea of SCMs is to estimate counterfactual outcomes for a treated unit by using a weighted sum of observed outcomes from untreated units. The accuracy of the synthetic control (SC) is critical for estimating the causal effect, and hence, the estimation of SC weights has been the focus of much research. In this paper, we first point out that existing SCMs suffer from an implicit endogeneity problem, which is the correlation between the outcomes of untreated units and the error term in the model of a counterfactual outcome. We show that this problem yields a bias in the causal effect estimator. We then propose a novel SCM based on density matching, assuming that the density of outcomes of the treated unit can be approximated by a weighted average of the densities of untreated units (i.e., a mixture model). Based on this assumption, we estimate SC weights by matchi
    
[^72]: 用于识别患有痴呆症的人日常活动模式变化的马尔可夫链模型

    A Markov Chain Model for Identifying Changes in Daily Activity Patterns of People Living with Dementia. (arXiv:2307.11126v1 [stat.AP])

    [http://arxiv.org/abs/2307.11126](http://arxiv.org/abs/2307.11126)

    使用马尔可夫链模型，该研究分析了患有痴呆症的人在日常活动模式中的变化并发现了营养不良和脱水等极端行为变化的影响，并考察了COVID-19大流行对这些变化的影响。

    

    营养不良和脱水与患有痴呆症的人认知和功能衰退增加以及住院率增加密切相关。饮食和饮水行为的极端变化经常导致营养不良和脱水，加速认知和功能衰退的进展，并导致生活质量显著降低。不幸的是，目前尚无确立的方法可以客观地检测这些变化。本文通过对73个患有痴呆症的家庭使用物联网技术收集的在家监测数据进行了广泛的定量分析。已经证明，2019冠状病毒病（COVID-19）大流行已经显著改变了患有痴呆症的行为习惯，尤其是饮食和饮水习惯。利用COVID-19大流行作为自然实验，我们进行了线性混合效应模型

    Malnutrition and dehydration are strongly associated with increased cognitive and functional decline in people living with dementia (PLWD), as well as an increased rate of hospitalisations in comparison to their healthy counterparts. Extreme changes in eating and drinking behaviours can often lead to malnutrition and dehydration, accelerating the progression of cognitive and functional decline and resulting in a marked reduction in quality of life. Unfortunately, there are currently no established methods by which to objectively detect such changes. Here, we present the findings of an extensive quantitative analysis conducted on in-home monitoring data collected from 73 households of PLWD using Internet of Things technologies. The Coronavirus 2019 (COVID-19) pandemic has previously been shown to have dramatically altered the behavioural habits, particularly the eating and drinking habits, of PLWD. Using the COVID-19 pandemic as a natural experiment, we conducted linear mixed-effects mo
    
[^73]: 星系图像的概率反褪色扩散模型

    Diffusion Models for Probabilistic Deconvolution of Galaxy Images. (arXiv:2307.11122v1 [astro-ph.IM])

    [http://arxiv.org/abs/2307.11122](http://arxiv.org/abs/2307.11122)

    使用无条件扩散模型进行星系图像的PSF反褪色，捕捉到了更多的样本多样性。

    

    望远镜捕捉到的图像具有特定的点扩散函数(PSF)。推断在具有更锐利PSF的情况下图像的样貌，即PSF反褪色问题，是不逆问题，因为PSF卷积不是可逆转换。深度生成模型在PSF反褪色中具有吸引力，因为它们可以推断出一个候选图像的后验分布，该分布在与PSF卷积后可能产生观测结果。然而，传统的深度生成模型(如VAE和GAN)通常不能提供足够的样本多样性。作为替代方案，我们提出了一种基于分类器的无条件扩散模型来进行星系图像的PSF反褪色。我们证明，与条件VAE相比，这种扩散模型捕捉到了更多可能的反褪色样本多样性。

    Telescopes capture images with a particular point spread function (PSF). Inferring what an image would have looked like with a much sharper PSF, a problem known as PSF deconvolution, is ill-posed because PSF convolution is not an invertible transformation. Deep generative models are appealing for PSF deconvolution because they can infer a posterior distribution over candidate images that, if convolved with the PSF, could have generated the observation. However, classical deep generative models such as VAEs and GANs often provide inadequate sample diversity. As an alternative, we propose a classifier-free conditional diffusion model for PSF deconvolution of galaxy images. We demonstrate that this diffusion model captures a greater diversity of possible deconvolutions compared to a conditional VAE.
    
[^74]: 变压器和卷积模型在昆虫细粒度分类中的比较

    Comparison between transformers and convolutional models for fine-grained classification of insects. (arXiv:2307.11112v1 [cs.CV])

    [http://arxiv.org/abs/2307.11112](http://arxiv.org/abs/2307.11112)

    本文对比了变压器和卷积模型在昆虫细粒度分类中的应用。这项研究对于解决物种鉴定中的困难非常有帮助，并为自动图像分类提供了新的洞见。

    

    由于找到具有鉴别能力的特征的困难，细粒度分类是具有挑战性的。当应用于同一分类类别中的物种识别时，这个问题会变得更加复杂。这是因为物种通常共享使它们难以区分的形态特征。我们考虑了昆虫纲。昆虫的鉴定对生物多样性监测至关重要，因为它们是许多生态系统中的基础生物之一。公众科学正在收集野外昆虫图像的杰出工作，为专家在所有国家制作改进的分布图提供了可能性。我们有数十亿需要自动分类的图像，深度神经网络算法是细粒度任务的主要技术之一。在最先进的技术中，深度学习算法领域非常丰富，那么如何确定要使用的算法？我们专注于蜻蜓目和甲虫目。

    Fine-grained classification is challenging due to the difficulty of finding discriminatory features. This problem is exacerbated when applied to identifying species within the same taxonomical class. This is because species are often sharing morphological characteristics that make them difficult to differentiate. We consider the taxonomical class of Insecta. The identification of insects is essential in biodiversity monitoring as they are one of the inhabitants at the base of many ecosystems. Citizen science is doing brilliant work of collecting images of insects in the wild giving the possibility to experts to create improved distribution maps in all countries. We have billions of images that need to be automatically classified and deep neural network algorithms are one of the main techniques explored for fine-grained tasks. At the SOTA, the field of deep learning algorithms is extremely fruitful, so how to identify the algorithm to use? We focus on Odonata and Coleoptera orders, and 
    
[^75]: 针对领域推广的平坦度感知最小化算法

    Flatness-Aware Minimization for Domain Generalization. (arXiv:2307.11108v1 [cs.CV])

    [http://arxiv.org/abs/2307.11108](http://arxiv.org/abs/2307.11108)

    本文提出了一种平坦度感知最小化算法（FAD），用于针对领域推广问题。通过同时优化零阶和一阶平坦度，FAD在各种领域推广数据集上表现出卓越的性能，并能发现更平坦的最优解。

    

    领域推广旨在学习在未知分布偏移下能够良好泛化的鲁棒模型。作为领域推广的关键方面之一，优化器的选择尚未深入研究。目前，大部分领域推广方法都遵循广泛使用的基准测试 DomainBed，并在所有数据集上使用Adam作为默认优化器。然而，我们揭示出Adam并不一定是当前大多数领域推广方法和数据集的最佳选择。基于损失函数平坦度的视角，我们提出了一种新颖的方法——针对领域推广的平坦度感知最小化算法（FAD），可以高效地同时优化零阶和一阶平坦度。我们对FAD的离分布泛化误差和收敛性进行了理论分析。实验结果表明，FAD在各种领域推广数据集上具有明显的优越性。此外，我们证实FAD能够发现更平坦的最优解，相对于其他零阶和一阶方法。

    Domain generalization (DG) seeks to learn robust models that generalize well under unknown distribution shifts. As a critical aspect of DG, optimizer selection has not been explored in depth. Currently, most DG methods follow the widely used benchmark, DomainBed, and utilize Adam as the default optimizer for all datasets. However, we reveal that Adam is not necessarily the optimal choice for the majority of current DG methods and datasets. Based on the perspective of loss landscape flatness, we propose a novel approach, Flatness-Aware Minimization for Domain Generalization (FAD), which can efficiently optimize both zeroth-order and first-order flatness simultaneously for DG. We provide theoretical analyses of the FAD's out-of-distribution (OOD) generalization error and convergence. Our experimental results demonstrate the superiority of FAD on various DG datasets. Additionally, we confirm that FAD is capable of discovering flatter optima in comparison to other zeroth-order and first-or
    
[^76]: 特征预处理对差分隐私线性优化的重要性

    The importance of feature preprocessing for differentially private linear optimization. (arXiv:2307.11106v1 [cs.LG])

    [http://arxiv.org/abs/2307.11106](http://arxiv.org/abs/2307.11106)

    本论文研究了差分隐私线性优化中特征预处理的重要性。在简单的线性分类情况下，与非隐私优化相比，特征预处理对于差分隐私优化是至关重要的，否则会产生与特征最大范数成比例的隐私错误。我们提出了一种结合特征预处理的算法DPSGD-F。

    

    在最近几年中，使用差分隐私（DP）训练机器学习模型引起了越来越多的关注。其中最流行的用于训练差分隐私模型的算法之一是差分隐私随机梯度下降（DPSGD）及其变种，在每个步骤中，梯度被剪裁并与一些噪音结合。鉴于DPSGD的广泛使用，我们提出一个问题：在隐私约束下，仅仅使用DPSGD是否足以找到每个数据集的良好极小值点？作为回答这个问题的第一步，我们展示了即使对于简单的线性分类情况，与非隐私优化相比，（私有）特征预处理对于差分隐私优化是至关重要的。具体而言，我们首先从理论上证明了存在一种例子，在没有特征预处理的情况下，DPSGD会产生与所有样本上的特征的最大范数成比例的隐私错误。然后，我们提出了一种名为DPSGD-F的算法，将DPSGD与特征预处理结合起来。

    Training machine learning models with differential privacy (DP) has received increasing interest in recent years. One of the most popular algorithms for training differentially private models is differentially private stochastic gradient descent (DPSGD) and its variants, where at each step gradients are clipped and combined with some noise. Given the increasing usage of DPSGD, we ask the question: is DPSGD alone sufficient to find a good minimizer for every dataset under privacy constraints? As a first step towards answering this question, we show that even for the simple case of linear classification, unlike non-private optimization, (private) feature preprocessing is vital for differentially private optimization. In detail, we first show theoretically that there exists an example where without feature preprocessing, DPSGD incurs a privacy error proportional to the maximum norm of features over all samples. We then propose an algorithm called DPSGD-F, which combines DPSGD with feature
    
[^77]: 部署强化学习代理进行AAA游戏测试的技术挑战

    Technical Challenges of Deploying Reinforcement Learning Agents for Game Testing in AAA Games. (arXiv:2307.11105v1 [cs.SE])

    [http://arxiv.org/abs/2307.11105](http://arxiv.org/abs/2307.11105)

    本文介绍了在AAA游戏测试中部署强化学习代理所面临的技术挑战，并提出了一些帮助游戏行业采用这项技术的研究方向。

    

    从研究到实际应用，特别是对于大型复杂软件系统来说，是一个困难的问题。在大规模游戏制作中，主要原因之一是开发环境可能与最终产品存在很大差异。本技术论文描述了一个在现有基于脚本机器人的自动化游戏测试解决方案中添加实验性强化学习系统的努力，以增加其能力。我们介绍了如何集成这个强化学习系统，旨在增加类似[1]的AAA游戏（包括Battlefield 2042和Dead Space（2023））的测试覆盖率。本技术论文旨在展示在游戏制作中利用强化学习的案例，并介绍了希望在游戏中进行相同探索的人可能会遇到的最大时间消耗。此外，为了帮助游戏行业更快地采用这项技术，我们提出了一些我们认为的研究方向。

    Going from research to production, especially for large and complex software systems, is fundamentally a hard problem. In large-scale game production, one of the main reasons is that the development environment can be very different from the final product. In this technical paper we describe an effort to add an experimental reinforcement learning system to an existing automated game testing solution based on scripted bots in order to increase its capacity. We report on how this reinforcement learning system was integrated with the aim to increase test coverage similar to [1] in a set of AAA games including Battlefield 2042 and Dead Space (2023). The aim of this technical paper is to show a use-case of leveraging reinforcement learning in game production and cover some of the largest time sinks anyone who wants to make the same journey for their game may encounter. Furthermore, to help the game industry to adopt this technology faster, we propose a few research directions that we believ
    
[^78]: 用学习的代理和约束解决基于多物理的反问题

    Solving multiphysics-based inverse problems with learned surrogates and constraints. (arXiv:2307.11099v1 [physics.geo-ph])

    [http://arxiv.org/abs/2307.11099](http://arxiv.org/abs/2307.11099)

    本论文将学习代理和学习约束相结合用于解决基于多物理的反问题，通过该方法不仅改善了对流体流动性质的反演精度，而且为反演多模态数据提供了一个有效的解决方案。

    

    在地质碳封存监测中，当多模态时变数据昂贵且数值模拟成本高昂时，解决基于多物理的反问题可能具有挑战性。我们通过将计算成本低廉的学习代理与学习约束相结合来克服这些挑战。这种组合不仅能够大大改善对重要流体流动性质（渗透率）的反演，还能为反演多模态数据（包括井测量和主动源时变地震数据）提供一个自然的平台。通过添加学习约束，我们得到了一个计算可行的反演方法，其精度仍然准确。这通过包含一个经过训练的深度神经网络（称为归一化流），使模型迭代保持在分布内，从而保证了作为代理的经过训练的傅里叶神经算子的准确性，这些算子用于代替涉及部分计算昂贵的多相流模拟。

    Solving multiphysics-based inverse problems for geological carbon storage monitoring can be challenging when multimodal time-lapse data are expensive to collect and costly to simulate numerically. We overcome these challenges by combining computationally cheap learned surrogates with learned constraints. Not only does this combination lead to vastly improved inversions for the important fluid-flow property, permeability, it also provides a natural platform for inverting multimodal data including well measurements and active-source time-lapse seismic data. By adding a learned constraint, we arrive at a computationally feasible inversion approach that remains accurate. This is accomplished by including a trained deep neural network, known as a normalizing flow, which forces the model iterates to remain in-distribution, thereby safeguarding the accuracy of trained Fourier neural operators that act as surrogates for the computationally expensive multiphase flow simulations involving partia
    
[^79]: 为了更好的排序一致性：一种面向早期广告排序的多任务学习框架

    Towards the Better Ranking Consistency: A Multi-task Learning Framework for Early Stage Ads Ranking. (arXiv:2307.11096v1 [cs.IR])

    [http://arxiv.org/abs/2307.11096](http://arxiv.org/abs/2307.11096)

    本论文提出了一种多任务学习框架，用于早期广告排序，以解决早期阶段和最终阶段排序之间的一致性问题。

    

    在大规模广告推荐中，将广告排序系统分为检索、早期和最终阶段是一种常见做法，以平衡效率和准确性。早期阶段的排序通常使用高效模型从一组检索到的广告中生成候选集。然后，将候选集馈送到计算密集且准确的最终阶段排序系统，生成最终的广告推荐。由于系统限制，早期和最终阶段的排序使用不同的特征和模型架构，导致了严重的排序一致性问题，即早期阶段的广告召回率较低，即最终阶段中排名靠前的广告在早期阶段排名较低。为了将更好的广告从早期阶段传递到最终阶段的排名，我们提出了一种面向早期阶段排序的多任务学习框架，以捕获多个最终阶段排序组件（即广告点击和广告质量事件）及其任务关系。

    Dividing ads ranking system into retrieval, early, and final stages is a common practice in large scale ads recommendation to balance the efficiency and accuracy. The early stage ranking often uses efficient models to generate candidates out of a set of retrieved ads. The candidates are then fed into a more computationally intensive but accurate final stage ranking system to produce the final ads recommendation. As the early and final stage ranking use different features and model architectures because of system constraints, a serious ranking consistency issue arises where the early stage has a low ads recall, i.e., top ads in the final stage are ranked low in the early stage. In order to pass better ads from the early to the final stage ranking, we propose a multi-task learning framework for early stage ranking to capture multiple final stage ranking components (i.e. ads clicks and ads quality events) and their task relations. With our multi-task learning framework, we can not only ac
    
[^80]: 模块化DFR：用于增强设计灵活性的数字延迟反馈储层模型

    Modular DFR: Digital Delayed Feedback Reservoir Model for Enhancing Design Flexibility. (arXiv:2307.11094v1 [cs.AR])

    [http://arxiv.org/abs/2307.11094](http://arxiv.org/abs/2307.11094)

    这项研究提出了一种适用于全数字实现的模块化DFR模型，通过减少超参数数量和选择非线性函数灵活性，提高精度和降低功耗。对比现有实现，该模型实现了10倍的功耗降低和5.3倍的吞吐量提升。

    

    延迟反馈储层(DFR)是一种适合硬件实现的储层计算系统，因其简单的结构而被广泛应用。现有的DFR实现大多使用模拟电路，需要数字模拟转换器和模拟数字转换器进行接口处理。然而，数字DFR在数字领域模拟模拟非线性元件，导致设计灵活性的缺失和更高的功耗。本文提出了一种适用于完全数字实现的新型模块化DFR模型。所提模型减少了超参数的数量，允许在选择非线性函数时具有灵活性，从而提高精度同时降低功耗。我们进一步提出了两个具有不同非线性函数的DFR实现，实现了10倍的功耗降低和5.3倍的吞吐量提升，同时保持相同或更好的精度。

    A delayed feedback reservoir (DFR) is a type of reservoir computing system well-suited for hardware implementations owing to its simple structure. Most existing DFR implementations use analog circuits that require both digital-to-analog and analog-to-digital converters for interfacing. However, digital DFRs emulate analog nonlinear components in the digital domain, resulting in a lack of design flexibility and higher power consumption. In this paper, we propose a novel modular DFR model that is suitable for fully digital implementations. The proposed model reduces the number of hyperparameters and allows flexibility in the selection of the nonlinear function, which improves the accuracy while reducing the power consumption. We further present two DFR realizations with different nonlinear functions, achieving 10x power reduction and 5.3x throughput improvement while maintaining equal or better accuracy.
    
[^81]: 对3D医学图像分割性能估计的置信区间研究

    Confidence intervals for performance estimates in 3D medical image segmentation. (arXiv:2307.10926v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2307.10926](http://arxiv.org/abs/2307.10926)

    本文研究了医学图像分割中性能估计的置信区间，通过实验发现参数置信区间的宽度与分割问题的特点有关。

    

    医学分割模型的评估是基于有限的例图像，因此评估结果存在噪声。除了报告平均性能指标外，报告置信区间也是非常重要的。然而，在医学图像分割中，很少有人这样做。置信区间的宽度取决于测试集大小和性能指标的散布程度（即测试集上的标准差）。对于分类问题，需要许多测试图像以避免宽泛的置信区间。然而，对于分割问题，这个情况尚未研究，因为给定的测试图像所提供的信息量不同。本文研究了医学图像分割中典型的置信区间。我们使用标准的nnU-net框架在两个来自Medical Decathlon挑战赛的数据集上进行了3D图像分割的实验，并使用Dice准确度和Hausdorff距离两个性能指标。我们发现参数置信区间的宽度与分割问题的特点有关，需要更多的研究才能得到更准确的结果。

    Medical segmentation models are evaluated empirically. As such an evaluation is based on a limited set of example images, it is unavoidably noisy. Beyond a mean performance measure, reporting confidence intervals is thus crucial. However, this is rarely done in medical image segmentation. The width of the confidence interval depends on the test set size and on the spread of the performance measure (its standard-deviation across of the test set). For classification, many test images are needed to avoid wide confidence intervals. Segmentation, however, has not been studied, and it differs by the amount of information brought by a given test image. In this paper, we study the typical confidence intervals in medical image segmentation. We carry experiments on 3D image segmentation using the standard nnU-net framework, two datasets from the Medical Decathlon challenge and two performance measures: the Dice accuracy and the Hausdorff distance. We show that the parametric confidence intervals
    
[^82]: 使用文本分类检测虚假评论

    Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])

    [http://arxiv.org/abs/2307.10617](http://arxiv.org/abs/2307.10617)

    这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。

    

    近年来，在线评论在推广任何产品或服务方面发挥着重要作用。企业可能会嵌入虚假评论以吸引客户购买他们的产品。他们甚至可能突出强调自己产品的优点或批评竞争对手的产品。市场营销人员、广告商和其他在线商业用户有动机为他们想要推广的产品编写虚假的正面评论，或者为他们真正不喜欢的产品提供虚假的负面评论。因此，识别虚假评论是一个紧迫且持续的研究领域。本研究论文提出了一种机器学习模型方法来识别虚假评论。论文调查了在一个餐馆评论的虚假意见垃圾语料库数据集上进行的多次实验的性能。我们采用了n-gram模型和最大特征来识别虚假评论。

    In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
    
[^83]: 通过多目标联邦学习对SecureBoost超参数进行调优的方法

    SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning. (arXiv:2307.10579v1 [cs.LG])

    [http://arxiv.org/abs/2307.10579](http://arxiv.org/abs/2307.10579)

    提出了一种通过多目标联邦学习来调优SecureBoost超参数的方法，以找到在效用、效率和隐私之间最佳平衡的一组超参数解决方案。

    

    SecureBoost是一种利用同态加密保护垂直联邦学习中数据隐私的树提升算法。由于其可解释性、效果和隐私保护能力，在金融和医疗保健等领域广泛应用。然而，SecureBoost存在计算复杂性高和标签泄漏风险的问题。为了充分发挥SecureBoost的潜力，需要仔细选择SecureBoost的超参数，以在效用、效率和隐私之间达到最佳平衡。现有方法要么经验性地设置超参数，要么启发式地设置超参数，远未达到最优。为了弥补这一差距，我们提出了一种约束多目标SecureBoost (CMOSB) 算法，以寻找每个解都是在效用损失、训练成本和隐私泄漏之间实现最佳权衡的一组超参数的Pareto最优解。我们设计了三个目标的度量方法。特别是，隐私泄漏是用... (此处省略)

    SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting. It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability. However, SecureBoost suffers from high computational complexity and risk of label leakage. To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy. Existing methods either set hyperparameters empirically or heuristically, which are far from optimal. To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage. We design measurements of the three objectives. In particular, the privacy leakage is measured using 
    
[^84]: 一种用于专门模型的竞争学习方法：解决具有不同功能区域的复杂物理系统的问题

    A Competitive Learning Approach for Specialized Models: A Solution for Complex Physical Systems with Distinct Functional Regimes. (arXiv:2307.10496v1 [cs.LG])

    [http://arxiv.org/abs/2307.10496](http://arxiv.org/abs/2307.10496)

    本论文提出了一种用于复杂物理系统的竞争学习方法，通过同时训练多个模型，并使用动态损失函数识别不同的功能区域。实验证明该方法能够成功地解决模型发现和函数拟合问题。

    

    在科学和工程中，复杂系统有时会展现出在不同区域之间变化的行为。传统的全局模型很难捕捉到这种复杂行为的全范围，从而限制了它们准确表示系统的能力。为了应对这个挑战，我们提出了一种新颖的竞争学习方法，用于获取基于数据的物理系统模型。所提出方法的主要思想是同时对一组模型进行训练，并采用动态损失函数。每个模型在训练过程中争夺每个观察值，从而允许在数据集中识别出不同的功能区域。为了展示学习方法的有效性，我们将其与使用梯度优化器进行训练的各种回归方法相结合。所提出的方法在涉及模型发现和函数拟合的各种问题上进行了测试，表明它能够成功地识别出功能区域。

    Complex systems in science and engineering sometimes exhibit behavior that changes across different regimes. Traditional global models struggle to capture the full range of this complex behavior, limiting their ability to accurately represent the system. In response to this challenge, we propose a novel competitive learning approach for obtaining data-driven models of physical systems. The primary idea behind the proposed approach is to employ dynamic loss functions for a set of models that are trained concurrently on the data. Each model competes for each observation during training, allowing for the identification of distinct functional regimes within the dataset. To demonstrate the effectiveness of the learning approach, we coupled it with various regression methods that employ gradient-based optimizers for training. The proposed approach was tested on various problems involving model discovery and function approximation, demonstrating its ability to successfully identify functional
    
[^85]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^86]: ZeroQuant-FP: 使用浮点格式进行LLMs训练后量化的一项飞跃

    ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])

    [http://arxiv.org/abs/2307.09782](http://arxiv.org/abs/2307.09782)

    ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。

    

    在大型语言模型（LLMs）的复杂领域中，平衡计算效率和保持模型质量是一个巨大的挑战。本研究通过探讨浮点（FP）量化的可行性，特别关注FP8和FP4，以应对均匀量化的固有限制，尤其是处理离群值，并受到NVIDIA H100硬件的启发。我们的全面调查发现，在LLMs中，FP8激活始终优于其整数（INT8）等效，性能优势在包含超过十亿参数的模型中更为明显。对于权重量化，我们的研究结果表明，FP4的性能与INT4相当，甚至更优，简化了在像H100这样支持FP的硬件上的部署。为了减少由权重和激活之间差异引起的精度对齐开销，我们提出了两个缩放约束。

    In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints
    
[^87]: MolFM:一种多模态分子基础模型

    MolFM: A Multimodal Molecular Foundation Model. (arXiv:2307.09484v1 [q-bio.BM])

    [http://arxiv.org/abs/2307.09484](http://arxiv.org/abs/2307.09484)

    MolFM是一种多模态分子基础模型，通过跨模态关注实现了分子结构、文本和知识图谱之间的联合表示学习。

    

    分子知识存在于三种不同的信息来源模式中：分子结构、生物医学文献和知识库。有效整合来自这些模态的分子知识对促进生物医学研究至关重要。然而，现有的多模态分子基础模型在捕捉分子结构和文本之间的复杂关联方面存在局限性，更重要的是，它们中的任何一个都没有尝试利用从知识图谱中获得的丰富分子专业知识。在本研究中，我们介绍了MolFM，一种多模态分子基础模型，旨在促进从分子结构、生物医学文本和知识图谱中进行联合表示学习。我们提出了分子结构中的原子、分子实体的邻居和语义相关文本之间的跨模态关注，以促进跨模态理解。我们提供了理论分析，表明我们的跨模态预训练捕捉到了分子结构、文本和知识图谱之间的复杂关系。

    Molecular knowledge resides within three different modalities of information sources: molecular structures, biomedical documents, and knowledge bases. Effective incorporation of molecular knowledge from these modalities holds paramount significance in facilitating biomedical research. However, existing multimodal molecular foundation models exhibit limitations in capturing intricate connections between molecular structures and texts, and more importantly, none of them attempt to leverage a wealth of molecular expertise derived from knowledge graphs. In this study, we introduce MolFM, a multimodal molecular foundation model designed to facilitate joint representation learning from molecular structures, biomedical texts, and knowledge graphs. We propose cross-modal attention between atoms of molecular structures, neighbors of molecule entities and semantically related texts to facilitate cross-modal comprehension. We provide theoretical analysis that our cross-modal pre-training captures
    
[^88]: 使用单个电路计算量子神经网络所有参数的梯度

    Computing the gradients with respect to all parameters of a quantum neural network using a single circuit. (arXiv:2307.08167v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2307.08167](http://arxiv.org/abs/2307.08167)

    该论文提出了一种使用单个电路计算量子神经网络所有参数梯度的方法，相比传统方法，它具有较低的电路深度和较少的编译时间，从而加速了总体运行时间。

    

    在使用参数平移规则计算量子神经网络的梯度时，需要对网络的单个可调参数计算两次代价函数。当参数总数较高时，需要调整和运行多次用于计算的量子电路。在这里，我们提出了一种仅使用一个电路计算所有梯度的方法，它具有较低的电路深度和较少的经典寄存器。我们还在真实量子硬件和模拟器上进行了实验证明，我们的方法具有电路编译时间明显缩短的优势，从而加速了总体运行时间。

    When computing the gradients of a quantum neural network using the parameter-shift rule, the cost function needs to be calculated twice for the gradient with respect to a single adjustable parameter of the network. When the total number of parameters is high, the quantum circuit for the computation has to be adjusted and run for many times. Here we propose an approach to compute all the gradients using a single circuit only, with a much reduced circuit depth and less classical registers. We also demonstrate experimentally, on both real quantum hardware and simulator, that our approach has the advantages that the circuit takes a significantly shorter time to compile than the conventional approach, resulting in a speedup on the total runtime.
    
[^89]: 经过长距离步骤的梯度下降的可证明更快收敛速度

    Provably Faster Gradient Descent via Long Steps. (arXiv:2307.06324v1 [math.OC])

    [http://arxiv.org/abs/2307.06324](http://arxiv.org/abs/2307.06324)

    本研究通过计算机辅助分析技术，证明了非常数步长策略下的梯度下降方法经过长距离步骤可以实现更快的收敛速度。

    

    本研究通过计算机辅助分析技术，建立了经过长距离步骤的梯度下降的可证明更快收敛速度。我们的理论允许非常数步长策略，通过分析多次迭代的整体效果而不是典型的一次迭代归纳使用的，从而有可能破坏下降。我们表明，长距离步骤，可能在短期内增加目标值，但在长期内带来更快的收敛速度。此外，我们还提出了一个关于梯度下降更快收敛速度的猜想，并进行了简单的数值验证。

    This work establishes provably faster convergence rates for gradient descent via a computer-assisted analysis technique. Our theory allows nonconstant stepsize policies with frequent long steps potentially violating descent by analyzing the overall effect of many iterations at once rather than the typical one-iteration inductions used in most first-order method analyses. We show that long steps, which may increase the objective value in the short term, lead to provably faster convergence in the long term. A conjecture towards proving a faster $O(1/T\log T)$ rate for gradient descent is also motivated along with simple numerical validation.
    
[^90]: 深度神经网络中的定量中心极限定理

    Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])

    [http://arxiv.org/abs/2307.06092](http://arxiv.org/abs/2307.06092)

    本文研究了具有随机高斯权重和偏置的全连接神经网络的分布，得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限，证明了随机全连接网络与相应的无限宽高斯过程之间的距离按照 $n^{-\gamma}$ 缩放，界限在网络宽度的依赖性方面优于以前的研究。

    

    我们研究了具有随机高斯权重和偏置的全连接神经网络的分布，其中隐藏层宽度与大常数 $n$ 成比例。在非线性的温和假设下，我们得到了在大但有限的 $n$ 和任意固定网络深度下成立的正态逼近的定量界限。我们的定理表明，无论是对于有限维分布还是整个过程，随机全连接网络（及其导数）与相应的无限宽高斯过程之间的距离都会按照 $n^{-\gamma}$ 缩放，其中 $\gamma>0$，指数取决于用于度量差异的度量方式。我们的界限在网络宽度的依赖性方面比文献中以前提供的任何界限都要强。

    We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma>0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
    
[^91]: 贝叶斯紧系数样条估计模式的数量

    Bayesian taut splines for estimating the number of modes. (arXiv:2307.05825v1 [stat.ME])

    [http://arxiv.org/abs/2307.05825](http://arxiv.org/abs/2307.05825)

    本研究提出了一种贝叶斯紧系数样条方法，用于估计概率密度函数中模式的数量。该方法结合了核估计器和组合样条，实现了特征探索、模型选择和模式检验，并允许引入专家判断。通过在体育分析中的案例研究中的验证，证明了该方法的实用性。

    

    概率密度函数中模式的数量代表模型的复杂性，也可以看作现有亚群体的数量。尽管其相关性，对其估计的研究非常有限。我们针对单变量情况提出一个新颖的方法，致力于预测准确性，受到了问题的一些被忽视的方面的启发。我们认为解决方案需要结构，模式的主观且不确定性，以及融合全局和局部密度特性的整体视图的便利性。我们的方法结合了灵活的核估计器和简洁的组合样条。特征探索、模型选择和模式检验都在贝叶斯推理范式中实现，为软解决方案提供了便利，并允许在过程中引入专家判断。我们的提议的实用性通过在体育分析中的案例研究中进行了验证，并展示了多个陪伴的可视化。

    The number of modes in a probability density function is representative of the model's complexity and can also be viewed as the number of existing subpopulations. Despite its relevance, little research has been devoted to its estimation. Focusing on the univariate setting, we propose a novel approach targeting prediction accuracy inspired by some overlooked aspects of the problem. We argue for the need for structure in the solutions, the subjective and uncertain nature of modes, and the convenience of a holistic view blending global and local density properties. Our method builds upon a combination of flexible kernel estimators and parsimonious compositional splines. Feature exploration, model selection and mode testing are implemented in the Bayesian inference paradigm, providing soft solutions and allowing to incorporate expert judgement in the process. The usefulness of our proposal is illustrated through a case study in sports analytics, showcasing multiple companion visualisation 
    
[^92]: SegNetr：重新思考U型网络中的局部-全局交互和跳跃连接

    SegNetr: Rethinking the local-global interactions and skip connections in U-shaped networks. (arXiv:2307.02953v1 [eess.IV])

    [http://arxiv.org/abs/2307.02953](http://arxiv.org/abs/2307.02953)

    这个论文提出了一种轻量级的医学图像分割网络SegNetr，通过引入SegNetr块和信息保留跳跃连接实现了动态的局部-全局交互和编码器-解码器特征的精确融合。

    

    最近，由于其简单且易于调整的结构，U型网络在医学图像分割领域占据主导地位。然而，现有的U型分割网络存在以下问题：1）主要关注设计复杂的自注意力模块，以弥补基于卷积操作的长期依赖性的缺失，从而增加了网络的总参数和计算复杂性；2）简单地融合编码器和解码器的特征，忽略了它们空间位置之间的连接。本文中，我们重新思考了上述问题，并构建了一种轻量级的医学图像分割网络，称为SegNetr。具体地，我们引入了一种新颖的SegNetr块，可以在任何阶段动态地进行局部-全局交互，并且具有线性复杂度。同时，我们设计了一个通用的信息保留跳跃连接（IRSC），以保留编码器特征的空间位置信息，并与解码器特征实现精确融合。

    Recently, U-shaped networks have dominated the field of medical image segmentation due to their simple and easily tuned structure. However, existing U-shaped segmentation networks: 1) mostly focus on designing complex self-attention modules to compensate for the lack of long-term dependence based on convolution operation, which increases the overall number of parameters and computational complexity of the network; 2) simply fuse the features of encoder and decoder, ignoring the connection between their spatial locations. In this paper, we rethink the above problem and build a lightweight medical image segmentation network, called SegNetr. Specifically, we introduce a novel SegNetr block that can perform local-global interactions dynamically at any stage and with only linear complexity. At the same time, we design a general information retention skip connection (IRSC) to preserve the spatial location information of encoder features and achieve accurate fusion with the decoder features. 
    
[^93]: 2023年声音分离挑战赛——音乐分离赛道技术报告

    Sound Demixing Challenge 2023 -- Music Demixing Track Technical Report. (arXiv:2306.09382v1 [cs.SD])

    [http://arxiv.org/abs/2306.09382](http://arxiv.org/abs/2306.09382)

    本文介绍了2023年声音分离挑战赛音乐分离赛道的两个有效方法，分别是时效高的源分离网络和适用于噪声鲁棒性源分离的损失掩模方法。

    

    本文介绍了我们在2023年声音分离挑战赛音乐分离赛道中获奖的解决方案。我们专注于两种在此挑战中设计的方法：一种时效高的源分离网络，在MUSDB基准测试上实现了最先进的结果；一种适用于噪声鲁棒性源分离的损失掩模方法。在github.com/kuielab/sdx23上提供了模型训练和最终提交的代码。

    In this report, we present our award-winning solutions for the Music Demixing Track of Sound Demixing Challenge 2023. We focus on two methods designed for this challenge: a time-efficient source separation network that achieves state-of-the-art results on the MUSDB benchmark and a loss masking method for noise-robust source separation. Code for reproducing model training and final submissions is available at github.com/kuielab/sdx23.
    
[^94]: IsoEx:一种可解释的无监督方法用于处理事件日志的网络安全调查

    IsoEx: an explainable unsupervised approach to process event logs cyber investigation. (arXiv:2306.09260v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2306.09260](http://arxiv.org/abs/2306.09260)

    IsoEx是一种可解释的无监督方法，用于处理事件日志的网络安全调查。它通过利用命令行的日志结构和父/子关系来检测异常和潜在问题命令行，准确性高于传统方法。

    

    39秒。这是自2023年以来连续两次网络攻击之间的时间间隔。这意味着在您阅读完此摘要之前，世界上可能已经发生了1到2次额外的网络攻击。在网络威胁频率大幅增加的背景下，安全运营中心(SOC)和计算机应急响应团队(CERT)可能会不堪重负。为了减轻网络安全团队在调查工作中的负担，并帮助他们将重点放在更增值的任务上，机器学习方法和技术开始出现。本文介绍了一种新颖的方法IsoEx，用于在污染设备调查期间检测异常和潜在问题命令行。IsoEx围绕一组特征构建，这些特征利用命令行的日志结构以及其父/子关系，以实现比传统方法更高的准确性。为了检测异常，IsoEx采用了无监督的异常检测技术。

    39 seconds. That is the timelapse between two consecutive cyber attacks as of 2023. Meaning that by the time you are done reading this abstract, about 1 or 2 additional cyber attacks would have occurred somewhere in the world. In this context of highly increased frequency of cyber threats, Security Operation Centers (SOC) and Computer Emergency Response Teams (CERT) can be overwhelmed. In order to relieve the cybersecurity teams in their investigative effort and help them focus on more added-value tasks, machine learning approaches and methods started to emerge. This paper introduces a novel method, IsoEx, for detecting anomalous and potentially problematic command lines during the investigation of contaminated devices. IsoEx is built around a set of features that leverages the log structure of the command line, as well as its parent/child relationship, to achieve a greater accuracy than traditional methods. To detect anomalies, IsoEx resorts to an unsupervised anomaly detection techni
    
[^95]: 基于深度学习的多目标电机技术优化的元模型建模

    Deep learning based Meta-modeling for Multi-objective Technology Optimization of Electrical Machines. (arXiv:2306.09087v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09087](http://arxiv.org/abs/2306.09087)

    本文利用变分自编码器（VAE）在高维设计空间中同时优化了异步电机和永磁同步电机两种不同的电机技术，通过深度神经网络和解码器作为元模型，预测关键性能指标并生成新的设计。与经典的基于深度学习的直接方法相比，VAE方法表现出更好的性能。

    

    旋转电机的优化既耗时又需要计算资源。由于参数化不同，设计优化通常对每种电机技术分别执行。本文介绍了利用变分自编码器（VAE）同时优化两种不同的电机技术，即异步电机和永磁同步电机。在训练之后，我们利用深度神经网络和解码器作为元模型，通过统一的潜在空间在优化循环中预测全局关键性能指标（KPI）并生成相关新设计。数值结果表明了在高维设计空间中的并行参数化多目标技术优化。VAE方法在KPI预测上与经典的基于深度学习的直接方法进行了定量比较。

    Optimization of rotating electrical machines is both time- and computationally expensive. Because of the different parametrization, design optimization is commonly executed separately for each machine technology. In this paper, we present the application of a variational auto-encoder (VAE) to optimize two different machine technologies simultaneously, namely an asynchronous machine and a permanent magnet synchronous machine. After training, we employ a deep neural network and a decoder as meta-models to predict global key performance indicators (KPIs) and generate associated new designs, respectively, through unified latent space in the optimization loop. Numerical results demonstrate concurrent parametric multi-objective technology optimization in the high-dimensional design space. The VAE-based approach is quantitatively compared to a classical deep learning-based direct approach for KPIs prediction.
    
[^96]: 基于优化启发式深度神经网络的自监督高光谱图像修复

    Self-Supervised Hyperspectral Inpainting with the Optimisation inspired Deep Neural Network Prior. (arXiv:2306.07308v1 [eess.IV])

    [http://arxiv.org/abs/2306.07308](http://arxiv.org/abs/2306.07308)

    本文提出了一种自监督的高光谱图像修复算法LRS-PnP-DIP，该算法能够在高光谱图像中精确预测缺失像素和带，其在实验中表现优异，达到或超过了其他学习方法。

    

    高光谱图像具有成百上千个窄带谱段，传递了大量的空间和谱信息。然而，由于仪器误差和大气变化，实践中得到的高光谱图像常常被噪声和坏点污染，导致缺失信息可能严重破坏后续应用。本文提出了一种新的高光谱图像取样点修复算法，称为低秩稀疏约束插入播放算法（LRS-PnP）。结果表明，即使图像的所有光谱带都丢失，LRS-PnP也能够预测缺失的像素和带。将LRS-PnP与Deep Image Prior（DIP）相结合，进一步扩展了一种自监督模型，称为LRS-PnP-DIP。在一系列真实数据实验中，结果表明，与其他基于学习的方法相比，LRS-PnP-DIP具有最先进的修复性能或胜过它们。

    Hyperspectral Image (HSI)s cover hundreds or thousands of narrow spectral bands, conveying a wealth of spatial and spectral information. However, due to the instrumental errors and the atmospheric changes, the HSI obtained in practice are often contaminated by noise and dead pixels(lines), resulting in missing information that may severely compromise the subsequent applications. We introduce here a novel HSI missing pixel prediction algorithm, called Low Rank and Sparsity Constraint Plug-and-Play (LRS-PnP). It is shown that LRS-PnP is able to predict missing pixels and bands even when all spectral bands of the image are missing. The proposed LRS-PnP algorithm is further extended to a self-supervised model by combining the LRS-PnP with the Deep Image Prior (DIP), called LRS-PnP-DIP. In a series of experiments with real data, It is shown that the LRS-PnP-DIP either achieves state-of-the-art inpainting performance compared to other learning-based methods, or outperforms them.
    
[^97]: 高维和置换不变异常检测。

    High-dimensional and Permutation Invariant Anomaly Detection. (arXiv:2306.03933v1 [hep-ph])

    [http://arxiv.org/abs/2306.03933](http://arxiv.org/abs/2306.03933)

    该研究引入了一种置换不变的高维密度估计方法，通过学习后将其用于高能物理数据中的异常检测，能够有效地识别出在仅具备背景假设下排除异常的喷注。

    

    由于学习高维概率密度的困难，新物理过程的异常检测方法通常局限于低维空间。特别是在成分级别上，将置换不变性和可变长度的输入等良好性质合并到流行的密度估计方法中变得更加困难。在本研究中，我们引入了一种基于扩散模型的粒子物理数据置换不变密度估计器，专门设计用于处理可变长度的输入。我们通过将学习到的密度用作置换不变的异常检测评分来展示我们方法的功效，有效地识别出在仅具备背景假设下的可能性较低的喷注。为了验证我们的密度估计方法，我们研究了学习到的密度比与被监督分类算法获得的密度之间的比较。

    Methods for anomaly detection of new physics processes are often limited to low-dimensional spaces due to the difficulty of learning high-dimensional probability densities. Particularly at the constituent level, incorporating desirable properties such as permutation invariance and variable-length inputs becomes difficult within popular density estimation methods. In this work, we introduce a permutation-invariant density estimator for particle physics data based on diffusion models, specifically designed to handle variable-length inputs. We demonstrate the efficacy of our methodology by utilizing the learned density as a permutation-invariant anomaly detection score, effectively identifying jets with low likelihood under the background-only hypothesis. To validate our density estimation method, we investigate the ratio of learned densities and compare to those obtained by a supervised classification algorithm.
    
[^98]: 量子神经网络中的有限采样噪声降低

    Reduction of finite sampling noise in quantum neural networks. (arXiv:2306.01639v1 [quant-ph])

    [http://arxiv.org/abs/2306.01639](http://arxiv.org/abs/2306.01639)

    介绍方差规范化技术方法，减小量子神经网络的有限采样噪声，在QNN的构造妥善的情况下，无需额外电路计算，测试发现可以显著地降低噪声水平及加快训练速度。

    

    量子神经网络(QNNs)使用参数化的量子电路与数据相关的输入来生成输出, 通过计算期望值带来了基本的有限采样噪声，即使在无误差的量子计算机上也会出现此现象。我们通过介绍方差规范化技术来减少这种噪声，该技术可以减小量子模型训练期间期望值的方差。如果QNN已经妥善构造，则此技术无需进行额外的电路计算。我们的实证研究表明，降低方差可以加快训练速度，降低输出噪声，减少梯度电路评估中的测量次数。我们对多项式函数回归进行了基准测试。在我们的示例中，我们展示了这种规范化方法平均可以降低一个数量级的方差，从而显着降低了噪声水平。

    Quantum neural networks (QNNs) use parameterized quantum circuits with data-dependent inputs and generate outputs through the evaluation of expectation values. Calculating these expectation values necessitates repeated circuit evaluations, thus introducing fundamental finite-sampling noise even on error-free quantum computers. We reduce this noise by introducing the variance regularization, a technique for reducing the variance of the expectation value during the quantum model training. This technique requires no additional circuit evaluations if the QNN is properly constructed. Our empirical findings demonstrate the reduced variance speeds up the training and lowers the output noise as well as decreases the number of measurements in the gradient circuit evaluation. This regularization method is benchmarked on the regression of multiple functions. We show that in our examples, it lowers the variance by an order of magnitude on average and leads to a significantly reduced noise level of
    
[^99]: 腹部多器官和肿瘤分割的持续学习

    Continual Learning for Abdominal Multi-Organ and Tumor Segmentation. (arXiv:2306.00988v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2306.00988](http://arxiv.org/abs/2306.00988)

    本文针对腹部多器官和肿瘤分割提出了一种持续学习方法，通过使用高质量伪标签缓解灾难性遗忘问题，并设计了一种创新架构，通过替换输出层为一组轻量级的、类别特定的头部来适应新出现的类别。

    

    对于多器官和肿瘤分割，动态扩展模型以适应新数据和类别的能力至关重要。然而，由于隐私规定，访问先前的数据和注释在医学领域可能存在问题。这对于在学习新类别时保持旧类别高分割精度的问题造成了重大障碍，因为会出现灾难性遗忘问题。本文首先经验证明，在器官分割设置中，仅使用高质量伪标签可以相对缓解该问题。此外，我们提出了一种专门设计用于连续器官和肿瘤分割的创新架构，该架构的计算负担最小。我们的设计方案是将传统输出层替换为一组轻量级的、类别特定的头部，因此具备适应新出现类别的灵活性。这些头部可以独立预测新引入的类别。

    The ability to dynamically extend a model to new data and classes is critical for multiple organ and tumor segmentation. However, due to privacy regulations, accessing previous data and annotations can be problematic in the medical domain. This poses a significant barrier to preserving the high segmentation accuracy of the old classes when learning from new classes because of the catastrophic forgetting problem. In this paper, we first empirically demonstrate that simply using high-quality pseudo labels can fairly mitigate this problem in the setting of organ segmentation. Furthermore, we put forward an innovative architecture designed specifically for continuous organ and tumor segmentation, which incurs minimal computational overhead. Our proposed design involves replacing the conventional output layer with a suite of lightweight, class-specific heads, thereby offering the flexibility to accommodate newly emerging classes. These heads enable independent predictions for newly introduc
    
[^100]: 基于条件扩散模型的语义化三维医学图像合成

    Conditional Diffusion Models for Semantic 3D Medical Image Synthesis. (arXiv:2305.18453v1 [eess.IV])

    [http://arxiv.org/abs/2305.18453](http://arxiv.org/abs/2305.18453)

    这篇论文提出了Med-DDPM，一种使用扩散模型进行语义化三维医学图像合成的创新解决方案，它通过控制像素级掩码标签的生成过程，能够生成高质量逼真的医学图像，并且在精度、稳定性和多样性等指标上优于GAN技术，也优于传统的增强技术和GAN合成图像。

    

    本文提出了Med-DDPM，它是一种创新的解决方案，使用扩散模型进行语义化的三维医学图像合成，解决了医学成像中数据稀缺、采集方法不一致和隐私问题等普遍存在的问题。实验结果表明，扩散模型在稳定性和性能方面都超过了生成对抗网络（GAN），能够生成高质量、逼真的三维医学图像。Med-DDPM的独特特点在于使用语义条件进行三维图像合成的扩散模型。通过控制像素级掩码标签的生成过程，它便于创建逼真的医学图像。经验证明，Med-DDPM在精度、稳定性和多样性等指标上优于GAN技术。此外，Med-DDPM在增强分割模型的准确性方面也优于传统的增强技术和GAN合成图像。它解决了医学图像合成中的难点。

    This paper introduces Med-DDPM, an innovative solution using diffusion models for semantic 3D medical image synthesis, addressing the prevalent issues in medical imaging such as data scarcity, inconsistent acquisition methods, and privacy concerns. Experimental evidence illustrates that diffusion models surpass Generative Adversarial Networks (GANs) in stability and performance, generating high-quality, realistic 3D medical images. The distinct feature of Med-DDPM is its use of semantic conditioning for the diffusion model in 3D image synthesis. By controlling the generation process through pixel-level mask labels, it facilitates the creation of realistic medical images. Empirical evaluations underscore the superior performance of Med-DDPM over GAN techniques in metrics such as accuracy, stability, and versatility. Furthermore, Med-DDPM outperforms traditional augmentation techniques and synthetic GAN images in enhancing the accuracy of segmentation models. It addresses challenges such
    
[^101]: 具有因果亚结构的分子关系学习模型在数据分布变化时的鲁棒性

    Shift-Robust Molecular Relational Learning with Causal Substructure. (arXiv:2305.18451v1 [cs.LG])

    [http://arxiv.org/abs/2305.18451](http://arxiv.org/abs/2305.18451)

    本文提出了一种鲁棒性强的分子关系学习模型CMRL，通过检测与化学反应因果相关的核心亚结构来应对分子关系学习中的数据分布变化。

    

    最近，分子关系学习引起了分子科学领域的广泛关注，其目标是预测分子对之间的相互作用行为。本文提出了一种鲁棒性强的分子关系学习模型CMRL，它通过检测与化学反应因果相关的核心亚结构来应对分子关系学习中的数据分布变化。为此，我们首先假定基于分子科学领域知识的因果关系，并构建结构因果模型（SCM）来揭示变量之间的关系。基于SCM，我们引入了一个新的条件干预框架，其干预是基于成对分子条件的。使用条件干预框架，我们的模型成功地从因果亚结构中学习，并减轻了与化学反应虚假相关的快捷亚结构的混淆效应。本文在各种任务和真实和合成数据集上进行了广泛实验。

    Recently, molecular relational learning, whose goal is to predict the interaction behavior between molecular pairs, got a surge of interest in molecular sciences due to its wide range of applications. In this work, we propose CMRL that is robust to the distributional shift in molecular relational learning by detecting the core substructure that is causally related to chemical reactions. To do so, we first assume a causal relationship based on the domain knowledge of molecular sciences and construct a structural causal model (SCM) that reveals the relationship between variables. Based on the SCM, we introduce a novel conditional intervention framework whose intervention is conditioned on the paired molecule. With the conditional intervention framework, our model successfully learns from the causal substructure and alleviates the confounding effect of shortcut substructures that are spuriously correlated to chemical reactions. Extensive experiments on various tasks with real-world and sy
    
[^102]: 度量空间和Nagata维度中k-NN规则的普遍一致性(II)

    Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II. (arXiv:2305.17282v1 [cs.LG])

    [http://arxiv.org/abs/2305.17282](http://arxiv.org/abs/2305.17282)

    本文研究了k近邻学习规则中的普遍一致性，发现在可分度量空间中，该规则在Nagata维度下的sigma有限维度的空间中是普遍一致的，在非阿基米德度量空间中是强普遍一致的，此规则在具有de Groot有限维度意义下的度量空间和Heisenberg群中也是普遍一致的。

    

    我们继续在可分度量空间中研究k近邻学习规则。由于C\'erou和Guyader(2006)以及Preiss(1983)的结果，已知该规则在每个Nagata意义下的sigma有限维度的度量空间X中是普遍一致的。在此，我们展示了在无平局情况下此规则在这样的空间中是强普遍一致的。在Devroye，Gy\"{o}rfi，Krzy\.{z}ak和Lugosi（1994）在欧几里得设置中应用的打破平局策略下，我们设法在非阿基米德度量空间（即Nagata维度为零的空间）中展示了强普遍一致性。结合C\'erou和Guyader的定理和Assouad和Quentin de Gromard (2006)的结果，可以推出$k$-NN规则在具有de Groot有限维度意义下的度量空间中是普遍一致的。特别地，$k$-NN规则在Heisenberg群中是普遍一致的，而该群并非sigma有限维度的。

    We continue to investigate the $k$ nearest neighbour learning rule in separable metric spaces. Thanks to the results of C\'erou and Guyader (2006) and Preiss (1983), this rule is known to be universally consistent in every metric space $X$ that is sigma-finite dimensional in the sense of Nagata. Here we show that the rule is strongly universally consistent in such spaces in the absence of ties. Under the tie-breaking strategy applied by Devroye, Gy\"{o}rfi, Krzy\.{z}ak, and Lugosi (1994) in the Euclidean setting, we manage to show the strong universal consistency in non-Archimedian metric spaces (that is, those of Nagata dimension zero). Combining the theorem of C\'erou and Guyader with results of Assouad and Quentin de Gromard (2006), one deduces that the $k$-NN rule is universally consistent in metric spaces having finite dimension in the sense of de Groot. In particular, the $k$-NN rule is universally consistent in the Heisenberg group which is not sigma-finite dimensional in the se
    
[^103]: 你的模型“MADD”了吗？一种用于评估预测性学生模型算法公平性的新指标。

    Is Your Model "MADD"? A Novel Metric to Evaluate Algorithmic Fairness for Predictive Student Models. (arXiv:2305.15342v1 [cs.LG])

    [http://arxiv.org/abs/2305.15342](http://arxiv.org/abs/2305.15342)

    本文提出一种新的度量标准，即MADD，可以独立于预测性能分析模型的歧视行为。研究者还提供了可视化分析的补充来帮助进行人类评估。

    

    由于其增强教育成果和支持利益相关者做出明智决策的能力，预测性学生模型在学习环境中越来越普遍。然而，预测模型可能存在偏见，导致对某些学生的潜在歧视和可能的有害长期影响。这促使了对公平性度量标准的研究，旨在捕捉和量化此类偏见。尽管如此，目前在教育领域使用的现有公平度量标准是面向预测性能的，重点是评估组间存在的有偏结果，而不考虑模型的行为以及结果中的偏见程度。因此，我们提出了一种新的度量标准，即“模型绝对密度距离”（MADD），以分析模型的歧视行为，独立于其预测性能。我们还提供了基于可视化分析的补充，以实现对模型行为的细粒度人类评估。

    Predictive student models are increasingly used in learning environments due to their ability to enhance educational outcomes and support stakeholders in making informed decisions. However, predictive models can be biased and produce unfair outcomes, leading to potential discrimination against some students and possible harmful long-term implications. This has prompted research on fairness metrics meant to capture and quantify such biases. Nonetheless, so far, existing fairness metrics used in education are predictive performance-oriented, focusing on assessing biased outcomes across groups of students, without considering the behaviors of the models nor the severity of the biases in the outcomes. Therefore, we propose a novel metric, the Model Absolute Density Distance (MADD), to analyze models' discriminatory behaviors independently from their predictive performance. We also provide a complementary visualization-based analysis to enable fine-grained human assessment of how the models
    
[^104]: 无线网络中的异步多模型联邦学习：理论、建模与优化(arXiv:2305.13503v1 [cs.LG])

    Asynchronous Multi-Model Federated Learning over Wireless Networks: Theory, Modeling, and Optimization. (arXiv:2305.13503v1 [cs.LG])

    [http://arxiv.org/abs/2305.13503](http://arxiv.org/abs/2305.13503)

    本文提出了MA-FL，应用异步模型传输体系结构来实现有多个下游任务需要训练的联邦学习。本文的收敛性分析揭示了资源分配、设备调度和个体模型状态对机器学习模型性能的影响。实验表明，MA-FL在收敛速度和模型精度方面优于现有的联邦学习方法。

    

    联邦学习是一种分布式机器学习的重要技术。目前，联邦学习的大部分文献都关注单一任务/模型的机器学习模型训练，并采用同步模型参数传输设置。为了解决这个问题，本文提出了MA-FL，它考虑利用异步模型传输体系结构，实现有多个下游任务需要训练的联邦学习。我们首先通过引入一族调度张量来捕捉设备的调度，并对MA-FL下的机器学习模型训练收敛性进行了表征。我们的收敛性分析揭示了资源分配（例如，小批量大小和梯度下降迭代次数）、设备调度和个体模型状态（即预热与冷启动初始化）对机器学习模型性能的影响。最后，我们为MA-FL制定了一个非凸混整数优化问题，用于共同配置资源分配和设备调度。对合成和真实数据集的数值实验表明，MA-FL在收敛速度和模型精度方面优于现有的联邦学习方法。

    Federated learning (FL) has emerged as a key technique for distributed machine learning (ML). Most literature on FL has focused on systems with (i) ML model training for a single task/model, (ii) a synchronous setting for uplink/downlink transfer of model parameters, which is often unrealistic. To address this, we develop MA-FL, which considers FL with multiple downstream tasks to be trained over an asynchronous model transmission architecture. We first characterize the convergence of ML model training under MA-FL via introducing a family of scheduling tensors to capture the scheduling of devices. Our convergence analysis sheds light on the impact of resource allocation (e.g., the mini-batch size and number of gradient descent iterations), device scheduling, and individual model states (i.e., warmed vs. cold initialization) on the performance of ML models. We then formulate a non-convex mixed integer optimization problem for jointly configuring the resource allocation and device schedu
    
[^105]: 可编辑用户档案的可控文本推荐方法

    Editable User Profiles for Controllable Text Recommendation. (arXiv:2304.04250v1 [cs.IR])

    [http://arxiv.org/abs/2304.04250](http://arxiv.org/abs/2304.04250)

    本文提出了一种新的概念值瓶颈模型LACE，用于可控文本推荐。该模型基于用户文档学习个性化的概念表示，并通过多种交互方式为用户提供了控制推荐的机制，验证了在离线和在线实验中该模型的推荐质量和有效性。

    

    实现高质量推荐的方法通常依赖于从交互数据中学习潜在表示。然而这些方法没有提供给用户控制所接收的推荐的机制。本文提出了LACE，一种新颖的概念值瓶颈模型，用于可控文本推荐。LACE基于用户交互的文档检索，将每个用户表示为简洁的可读的概念集，并基于用户文档学习概念的个性化表示。该基于概念的用户档案被利用来做出推荐。我们的模型设计通过透明的用户档案，提供了控制推荐的多种直观交互方式。我们首先在三个推荐任务（温启动、冷启动和零样本）的六个数据集上进行了离线评估，验证了从LACE获得的推荐质量。接下来，我们在在线实验中验证了LACE的有效性和用户控制能力。

    Methods for making high-quality recommendations often rely on learning latent representations from interaction data. These methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. Our work tackles this problem by proposing LACE, a novel concept value bottleneck model for controllable text recommendations. LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. This concept based user profile is then leveraged to make recommendations. The design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. We first establish the quality of recommendations obtained from LACE in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we validate the 
    
[^106]: 对压迫矩阵的分解:揭示交织性在AI公平性中的作用的批判性回顾与再想象

    Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness. (arXiv:2303.17555v1 [cs.CY])

    [http://arxiv.org/abs/2303.17555](http://arxiv.org/abs/2303.17555)

    本文通过批判性回顾AI公平性文献中30篇交织性讨论，揭示研究人员普遍缺乏对交织性的整体理解，其一方面将其缩小为在群体子组上进行公平度量的优化，另一方面则在社会背景和权力结构的讨论方面存在欠缺。

    

    交织性是一个关键框架，通过调查和实践，它使我们能够检查社会不平等如何通过结构和纪律领域持续存在。在AI公平的理念中，“公平性”是至关重要的，我们认为采用交织性作为分析框架对于有效地实现公平至关重要。通过对AI公平文献中30篇关于交织性的讨论进行批判性回顾，我们归纳和演绎出:1)交织性指导如何在AI公平范例中操作，2)揭示交织性的概念化和实现之间的差距。我们发现，研究人员普遍将交织性缩减为针对人口亚组的公平指标进行优化。他们也未能讨论它们的社会背景，当提到权力时，他们主要将其置于AI流程中。我们将进一步阐述并评估这些差距对于临床研究和实践的影响。

    Intersectionality is a critical framework that, through inquiry and praxis, allows us to examine how social inequalities persist through domains of structure and discipline. Given AI fairness' raison d'\^etre of ``fairness,'' we argue that adopting intersectionality as an analytical framework is pivotal to effectively operationalizing fairness. Through a critical review of how intersectionality is discussed in 30 papers from the AI fairness literature, we deductively and inductively: 1) map how intersectionality tenets operate within the AI fairness paradigm and 2) uncover gaps between the conceptualization and operationalization of intersectionality. We find that researchers overwhelmingly reduce intersectionality to optimizing for fairness metrics over demographic subgroups. They also fail to discuss their social context and when mentioning power, they mostly situate it only within the AI pipeline. We: 3) outline and assess the implications of these gaps for critical inquiry and prax
    
[^107]: MedNeXt：用于医学图像分割的变压器驱动卷积神经网络的可扩展性

    MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation. (arXiv:2303.09975v1 [eess.IV])

    [http://arxiv.org/abs/2303.09975](http://arxiv.org/abs/2303.09975)

    MedNeXt是一个定制化的现代化可扩展卷积神经网络，用于解决数据稀缺的医学环境挑战。该网络包含：完全ConvNeXt 3D编码器-解码器网络、残差ConvNeXt上下采样块和一种新的迭代增加核大小的技术。

    

    近年来，在医学图像分割中使用基于 Transformer 的架构越来越多，但是由于缺乏大规模标注的医学数据集，使得其性能远不如自然图像。相比之下，卷积神经网络具有更高的归纳偏差，因此更容易训练到高性能水平。最近，ConvNeXt 架构尝试通过镜像变压器块来现代化标准卷积神经网络。在这项工作中，我们改进了这一架构，设计了一种现代化且可扩展的卷积神经网络，以应对数据稀缺的医学环境的挑战。我们引入 MedNeXt，这是一个受变压器启发的大核分割网络，其中包括：1）用于医学图像分割的完全 ConvNeXt 3D 编码器 - 解码器网络，2）残差 ConvNeXt 上下采样块，以在各个尺度上保留语义信息，3）一种新的技术，通过上采样小核来迭代增加核大小。

    There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel 
    
[^108]: StyleGANEX: 基于StyleGAN的超出裁剪对齐人脸的操纵方法

    StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces. (arXiv:2303.06146v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.06146](http://arxiv.org/abs/2303.06146)

    本文提出了StyleGANEX，一种基于StyleGAN的超出裁剪对齐人脸的操纵方法，通过使用扩张卷积来调整感受野，实现了对不对齐人脸的更好描述和各种操纵任务的有效性验证。

    

    最近，使用StyleGAN进行人脸操纵取得了令人印象深刻的成果。然而，StyleGAN的局限性在于它仅适用于在预训练时固定图像分辨率下裁剪对齐的人脸。本文提出了一个简单且有效的解决方案，通过使用扩张卷积来重新调整StyleGAN浅层的感受野，而不改变任何模型参数。这使得浅层的固定尺寸小特征能够扩展成能适应不同分辨率的大特征，从而更好地描述不对齐的人脸。为了实现真实的人脸反演和操纵，我们引入了相应的编码器，除了潜在的风格编码外，还提供了扩展StyleGAN的第一层特征。我们使用各种分辨率的不对齐人脸输入验证了我们方法的有效性，包括面部属性编辑、超分辨率、素描/面具转换等各种人脸操纵任务。

    Recent advances in face manipulation using StyleGAN have produced impressive results. However, StyleGAN is inherently limited to cropped aligned faces at a fixed image resolution it is pre-trained on. In this paper, we propose a simple and effective solution to this limitation by using dilated convolutions to rescale the receptive fields of shallow layers in StyleGAN, without altering any model parameters. This allows fixed-size small features at shallow layers to be extended into larger ones that can accommodate variable resolutions, making them more robust in characterizing unaligned faces. To enable real face inversion and manipulation, we introduce a corresponding encoder that provides the first-layer feature of the extended StyleGAN in addition to the latent style code. We validate the effectiveness of our method using unaligned face inputs of various resolutions in a diverse set of face manipulation tasks, including facial attribute editing, super-resolution, sketch/mask-to-face 
    
[^109]: 通过时间过程建模事件和相互作用 - 一项调查

    Modeling Events and Interactions through Temporal Processes -- A Survey. (arXiv:2303.06067v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06067](http://arxiv.org/abs/2303.06067)

    该调查研究通过时间过程建模事件序列的概率模型，并通过简单、标记和时空点过程分类，对基于深度学习的现有方法进行系统回顾，并分析了应用于预测和建模方面的场景。

    

    在现实世界的场景中，许多现象以连续时间发生的一系列事件产生。点过程为建模这些事件序列提供了一种自然的数学框架。在本调查中，我们通过时间过程研究概率模型来建模事件序列。我们修订了事件建模的概念，并提供了表征相关文献的数学基础。我们定义了一个本体来以三个类别（简单、标记和时空点过程）对现有方法进行分类。对于每个类别，我们系统地回顾了基于深度学习的现有方法。最后，我们分析了提出的技术可以用于解决预测和建模方面的场景。

    In real-world scenario, many phenomena produce a collection of events that occur in continuous time. Point Processes provide a natural mathematical framework for modeling these sequences of events. In this survey, we investigate probabilistic models for modeling event sequences through temporal processes. We revise the notion of event modeling and provide the mathematical foundations that characterize the literature on the topic. We define an ontology to categorize the existing approaches in terms of three families: simple, marked, and spatio-temporal point processes. For each family, we systematically review the existing approaches based based on deep learning. Finally, we analyze the scenarios where the proposed techniques can be used for addressing prediction and modeling aspects.
    
[^110]: 通过决策估计系数，对$\gamma$-遗憾进行紧密界定

    Tight Bounds for $\gamma$-Regret via the Decision-Estimation Coefficient. (arXiv:2303.03327v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03327](http://arxiv.org/abs/2303.03327)

    本论文通过决策估计系数对任意结构化赌臂问题的$\gamma$-遗憾进行了紧密界定，该界定是对函数类的统计复杂度参数$\gamma$-DEC的修改版本。作者发现$\gamma$-DEC是任何模型类$\mathcal{F}$的基本限制，对于任何算法都存在某个$f \in \mathcal{F}$，该算法的$\gamma$-遗憾与$\mathcal{F}$的$\gamma$-DEC几乎成正比。

    

    在这项工作中，我们给出了对任意结构化赌臂问题的$\gamma$-遗憾的统计描述，该遗憾是与$\gamma$倍最优解相比较时产生的遗憾。在函数类$\mathcal{F}$上的结构化赌臂问题中，寻找$f \in \mathcal{F}$的精确最优解是难以处理的。我们的描述是基于$\gamma$-DEC的，它是函数类$\mathcal{F}$的统计复杂度参数，是Foster et al.，2023的约束决策估计系数(DEC)的修改版本（与Foster et al.，2021的原始偏移DEC密切相关）。我们的下界表明，对于任何模型类$\mathcal{F}$，$\gamma$-DEC是一个基本限制：对于任何算法，存在一些$f \in \mathcal{F}$，该算法的$\gamma$-遗憾与$\mathcal{F}$的$\gamma$-DEC的规模（几乎）成正比。我们还提供了一个上界，证明了存在一些......

    In this work, we give a statistical characterization of the $\gamma$-regret for arbitrary structured bandit problems, the regret which arises when comparing against a benchmark that is $\gamma$ times the optimal solution. The $\gamma$-regret emerges in structured bandit problems over a function class $\mathcal{F}$ where finding an exact optimum of $f \in \mathcal{F}$ is intractable. Our characterization is given in terms of the $\gamma$-DEC, a statistical complexity parameter for the class $\mathcal{F}$, which is a modification of the constrained Decision-Estimation Coefficient (DEC) of Foster et al., 2023 (and closely related to the original offset DEC of Foster et al., 2021). Our lower bound shows that the $\gamma$-DEC is a fundamental limit for any model class $\mathcal{F}$: for any algorithm, there exists some $f \in \mathcal{F}$ for which the $\gamma$-regret of that algorithm scales (nearly) with the $\gamma$-DEC of $\mathcal{F}$. We provide an upper bound showing that there exist
    
[^111]: 关于可证明版权保护生成模型的研究

    On Provable Copyright Protection for Generative Models. (arXiv:2302.10870v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10870](http://arxiv.org/abs/2302.10870)

    该论文研究了可证明版权保护生成模型的问题，提出了近无阻碍性（NAF）的定义，并给出了满足该定义的模型输出与受版权保护数据相似样本的概率上限。同时，还提供了生成模型学习算法，能够高效输出具有强大版权保护能力的生成模型。最后，进行了有前景的语言和图像生成模型实验。

    

    担心学习的条件生成模型可能输出与其训练集中的某些受版权保护的数据$C$极为相似的样本。我们给出了“近无阻碍性（NAF）”的正式定义，并证明了满足这个定义的模型输出与$C$相似样本的概率上限，即使$C$包含在其训练集中。粗略地说，生成模型$p$是“$k$-NAF”的，如果对于每一个潜在的受版权保护的数据$C$，$p$的输出与一个完全未访问$C$的模型$q$的输出之间的差别最大为$k$比特。我们还提供了生成模型学习算法，以黑盒方式高效修改原始生成模型学习算法，输出具有强大的保护内容采样概率上限的生成模型。此外，我们还针对语言（Transformer）和图像（Diffusion）生成模型进行了有前景的实验。

    There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data $C$ that was in their training set. We give a formal definition of $\textit{near access-freeness (NAF)}$ and prove bounds on the probability that a model satisfying this definition outputs a sample similar to $C$, even if $C$ is included in its training set. Roughly speaking, a generative model $p$ is $\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of $p$ diverges by at most $k$-bits from the output of a model $q$ that $\textit{did not access $C$ at all}$. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models
    
[^112]: 简化基于动量的黎曼子流形优化

    Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.09738](http://arxiv.org/abs/2302.09738)

    本文针对黎曼子流形优化算法进行了简化，提出了黎曼正常坐标的广义版本，可用于对称正定矩阵的子流形优化，并为深度学习开发了高效的二阶优化器，无需显式矩阵求逆。

    

    带有动量的黎曼子流形优化在计算上是具有挑战性的，因为确保迭代保持在子流形上通常需要解决困难的微分方程。本文针对具有仿射不变度量的对称正定矩阵的子流形优化算法进行了简化。我们提出了黎曼正常坐标的广义版本，可以将问题动态地简化为欧几里得无约束问题。我们使用我们的方法来解释和简化现有的结构化协方差方法，并为深度学习开发了高效的二阶优化器，而无需显式矩阵求逆。

    Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
    
[^113]: 多分辨率图形变换器与小波位置编码用于学习分层结构

    Multiresolution Graph Transformers and Wavelet Positional Encoding for Learning Hierarchical Structures. (arXiv:2302.08647v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08647](http://arxiv.org/abs/2302.08647)

    该论文提出了多分辨率图形变换器（MGT）和小波位置编码（WavePE）方法，可以学习表示大分子的分层结构，并在众多数据集上获得了比其他先进方法更好的结果。

    

    当前的图形学习算法并不能很好地处理大分子，因为它们没有考虑到原子之间的分层交互，而这对于确定大分子的属性至关重要。在这项工作中，我们提出了多分辨率图形变换器（MGT），这是第一个可以学习表示多种尺度下大分子的图形变换器架构。MGT可以学习产生原子的表示，并将它们分组成有意义的功能组或重复单元。我们还引入了小波位置编码（WavePE），一种新的位置编码方法，可以保证在频谱和空间域中的局部性。我们提出的模型在由聚合物和多肽组成的两个大分子数据集以及一个类似药物的分子数据集上取得了竞争性的结果。重要的是，我们的模型优于其他最先进的方法，在估算分子性质（例如GAP，HOMO和LUMO）时达到了化学精度。

    Contemporary graph learning algorithms are not well-defined for large molecules since they do not consider the hierarchical interactions among the atoms, which are essential to determine the molecular properties of macromolecules. In this work, we propose Multiresolution Graph Transformers (MGT), the first graph transformer architecture that can learn to represent large molecules at multiple scales. MGT can learn to produce representations for the atoms and group them into meaningful functional groups or repeating units. We also introduce Wavelet Positional Encoding (WavePE), a new positional encoding method that can guarantee localization in both spectral and spatial domains. Our proposed model achieves competitive results on two macromolecule datasets consisting of polymers and peptides, and one drug-like molecule dataset. Importantly, our model outperforms other state-of-the-art methods and achieves chemical accuracy in estimating molecular properties (e.g., GAP, HOMO and LUMO) calc
    
[^114]: 不变的槽注意力: 通过以槽为中心的参考框架进行对象发现

    Invariant Slot Attention: Object Discovery with Slot-Centric Reference Frames. (arXiv:2302.04973v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.04973](http://arxiv.org/abs/2302.04973)

    本文介绍了一种通过以槽为中心的参考框架来改进对象发现的方法，通过在Slot Attention中融入空间对称性，可以大幅提高数据效率和整体对象发现效果。

    

    从原始感知数据中自动发现可组合的抽象是机器学习中长期存在的挑战。最近，基于槽的神经网络以自我监督的方式学习对象在这个方向上取得了令人兴奋的进展。然而，它们通常在充分捕捉视觉世界中的空间对称性方面表现不佳，导致样本效率低下，比如在纠结对象外观和姿态时。在本文中，我们提出了一种简单但极其有效的方法，通过以槽为中心的参考框架来融入空间对称性。我们将等变性引入到Slot Attention的注意力和生成机制中，通过平移、缩放和旋转位置编码来实现对每个对象姿态变换的等变性。这些改变几乎没有额外的计算开销，易于实现，并可以在数据效率和整体对象发现方面取得巨大的改进。我们在广泛的语法范围内对我们的方法进行了评估。

    Automatically discovering composable abstractions from raw perceptual data is a long-standing challenge in machine learning. Recent slot-based neural networks that learn about objects in a self-supervised manner have made exciting progress in this direction. However, they typically fall short at adequately capturing spatial symmetries present in the visual world, which leads to sample inefficiency, such as when entangling object appearance and pose. In this paper, we present a simple yet highly effective method for incorporating spatial symmetries via slot-centric reference frames. We incorporate equivariance to per-object pose transformations into the attention and generation mechanism of Slot Attention by translating, scaling, and rotating position encodings. These changes result in little computational overhead, are easy to implement, and can result in large gains in terms of data efficiency and overall improvements to object discovery. We evaluate our method on a wide range of synt
    
[^115]: 使用变分自动编码器检测快捷方式

    Shortcut Detection with Variational Autoencoders. (arXiv:2302.04246v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04246](http://arxiv.org/abs/2302.04246)

    本文提出了一个使用变分自动编码器来检测图像和音频数据集中快捷方式的新方法，并在几个实际数据集上展示了其有效性。

    

    在机器学习的实际应用中，模型基于具有良好普适性的特征而不是数据中的偶然相关性进行预测是至关重要的。识别这种偶然相关性，也称为快捷方式，是一个具有挑战性的问题，迄今为止得到的研究很少。在本文中，我们提出了一个利用变分自动编码器（VAE）来检测图像和音频数据集中快捷方式的新方法。VAEs的潜在空间中的特征解缠使我们能够发现数据集中特征和目标的相关性，并对其进行半自动评估，以发现机器学习中的快捷方式。我们在几个实际数据集上演示了我们方法的适用性，发现了以前未发现的快捷方式。

    For real-world applications of machine learning (ML), it is essential that models make predictions based on well-generalizing features rather than spurious correlations in the data. The identification of such spurious correlations, also known as shortcuts, is a challenging problem and has so far been scarcely addressed. In this work, we present a novel approach to detect shortcuts in image and audio datasets by leveraging variational autoencoders (VAEs). The disentanglement of features in the latent space of VAEs allows us to discover feature-target correlations in datasets and semi-automatically evaluate them for ML shortcuts. We demonstrate the applicability of our method on several real-world datasets and identify shortcuts that have not been discovered before.
    
[^116]: 通过合作协同进化搜索确定基于机器学习自主系统的危险边界

    Identifying the Hazard Boundary of ML-enabled Autonomous Systems Using Cooperative Co-Evolutionary Search. (arXiv:2301.13807v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2301.13807](http://arxiv.org/abs/2301.13807)

    本研究致力于通过合作协同进化搜索，确定机器学习自主系统中的ML组件的危险边界。这种边界可以用于构建安全监视器，并在达到危险边界时采取预定义的回退机制。

    

    在机器学习（ML）驱动的自主系统（MLAS）中，确定ML组件（MLCs）的危险边界对于分析中的MLAS至关重要。鉴于这种边界可以捕捉到导致危险的MLC行为和系统背景条件，例如，在达到危险边界时，可以构建一个安全监视器，可以在运行时采取任何预定义的回退机制。然而，确定ML组件的这种危险边界是具有挑战性的。这是由于问题空间将系统环境（即场景）和MLC行为（即输入和输出）组合在一起，过于庞大，无法通过全面的探索甚至是传统的元启发式算法，如遗传算法来处理。此外，确定任何MLAS安全违规所需的模拟的高计算成本使问题更加具有挑战性。此外，以确定性地考虑问题空间中的一个区域是不切实际的。

    In Machine Learning (ML)-enabled autonomous systems (MLASs), it is essential to identify the hazard boundary of ML Components (MLCs) in the MLAS under analysis. Given that such boundary captures the conditions in terms of MLC behavior and system context that can lead to hazards, it can then be used to, for example, build a safety monitor that can take any predefined fallback mechanisms at runtime when reaching the hazard boundary. However, determining such hazard boundary for an ML component is challenging. This is due to the problem space combining system contexts (i.e., scenarios) and MLC behaviors (i.e., inputs and outputs) being far too large for exhaustive exploration and even to handle using conventional metaheuristics, such as genetic algorithms. Additionally, the high computational cost of simulations required to determine any MLAS safety violations makes the problem even more challenging. Furthermore, it is unrealistic to consider a region in the problem space deterministicall
    
[^117]: SpArX: 稀疏的神经网络论证解释

    SpArX: Sparse Argumentative Explanations for Neural Networks. (arXiv:2301.09559v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.09559](http://arxiv.org/abs/2301.09559)

    该论文提出了一种稀疏的神经网络论证解释方法SpArX，通过利用多层感知器和定量论证框架之间的关系，可以为神经网络的决策过程提供更忠实和深入的解释。

    

    神经网络在人工智能中有各种应用，但解释它们的决策仍然具有挑战性。现有方法通常关注解释改变单个输入如何影响神经网络的输出。然而，一个与神经网络的输入输出行为一致的解释未必忠实于其实际机制。在本文中，我们利用多层感知器和定量论证框架之间的关系，为多层感知器的机制创建了论证性解释。我们的SpArX方法首先将多层感知器稀疏化，同时保持尽可能多的原始结构。然后将稀疏的多层感知器转化为等效的定量论证框架，以揭示多层感知器的潜在决策过程，产生全局和/或局部解释。我们通过实验证明，SpArX比现有方法可以给出更忠实的解释，同时提供更深入的洞察实际推理过程。

    Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of M
    
[^118]: 流形神经网络的收敛速率

    A Convergence Rate for Manifold Neural Networks. (arXiv:2212.12606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12606](http://arxiv.org/abs/2212.12606)

    该论文研究了流形神经网络的收敛速率，通过建立一个与环境维度无关但与流形内在维度相关的收敛速率，对先前的工作进行了改进。

    

    高维数据在许多应用中产生，并且几何深度学习这一快速发展的领域致力于开发神经网络架构，以便在非欧几里德领域（如图和流形）中分析此类数据。弗丁·王、唐坤·卢以及亚历山大·里贝罗最近的工作引入了一种利用拉普拉斯-贝尔特拉米算子的谱分解构建流形神经网络的方法。此外，本文作者提供了一种数值方案，以在流形未知且仅有有限数量样本点可获得的情况下实施此类神经网络。作者证明了这种方案，依靠构建数据驱动的图，当样本点数量趋于无穷大时，收敛到连续极限。在这里，我们在此结果的基础上建立了一个收敛速率，该收敛速率取决于流形的内在维度，但与环境维度无关。我们还讨论了收敛速率如何依赖于...

    High-dimensional data arises in numerous applications, and the rapidly developing field of geometric deep learning seeks to develop neural network architectures to analyze such data in non-Euclidean domains, such as graphs and manifolds. Recent work by Z. Wang, L. Ruiz, and A. Ribeiro has introduced a method for constructing manifold neural networks using the spectral decomposition of the Laplace Beltrami operator. Moreover, in this work, the authors provide a numerical scheme for implementing such neural networks when the manifold is unknown and one only has access to finitely many sample points. The authors show that this scheme, which relies upon building a data-driven graph, converges to the continuum limit as the number of sample points tends to infinity. Here, we build upon this result by establishing a rate of convergence that depends on the intrinsic dimension of the manifold but is independent of the ambient dimension. We also discuss how the rate of convergence depends on the
    
[^119]: 神经网络热启动方法用于声学障碍物散射问题的逆问题

    A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle Scattering Problem. (arXiv:2212.08736v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2212.08736](http://arxiv.org/abs/2212.08736)

    本文提出了一种神经网络热启动方法，用于解决声学障碍物散射问题的逆问题。该方法通过在计算散射场和给定测量数据之间的$L^2$距离的区域边界中找到良好的初始猜测，以克服计算上的挑战。

    

    我们考虑在二维中的声学障碍物散射问题的逆问题，在这个问题中，通过对来自物体外部的一系列接收器接收到的散射场的测量来确定障碍物的边界。解决该问题的标准方法之一是将其重新表述为一个优化问题：找到最小化计算的散射场值与给定测量数据之间的$L^2$距离的区域边界。由于局部凸性随着频率增加而收缩，并在真解附近产生越来越多的局部最小值，这个优化问题在计算上具有挑战性。在许多实际实验设置中，由于实验装置或测量传感器的限制，低频测量是不可用的。因此，在这种环境中获得一个良好的优化问题初始猜测至关重要。

    We consider the inverse acoustic obstacle problem for sound-soft star-shaped obstacles in two dimensions wherein the boundary of the obstacle is determined from measurements of the scattered field at a collection of receivers outside the object. One of the standard approaches for solving this problem is to reformulate it as an optimization problem: finding the boundary of the domain that minimizes the $L^2$ distance between computed values of the scattered field and the given measurement data. The optimization problem is computationally challenging since the local set of convexity shrinks with increasing frequency and results in an increasing number of local minima in the vicinity of the true solution. In many practical experimental settings, low frequency measurements are unavailable due to limitations of the experimental setup or the sensors used for measurement. Thus, obtaining a good initial guess for the optimization problem plays a vital role in this environment.  We present a ne
    
[^120]: 基于确定性点过程的无监督技能发现的统一算法框架

    A Unified Algorithm Framework for Unsupervised Discovery of Skills based on Determinantal Point Process. (arXiv:2212.00211v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00211](http://arxiv.org/abs/2212.00211)

    本文提出了一个使用确定性点过程（DPP）的统一算法框架，实现了对无监督技能发现的多样性和覆盖性的显式优化。

    

    在强化学习研究中，通过时间抽象学习丰富的技能而无需外部奖励监督是一个前沿问题。现有的工作主要分为两个不同的类别：变分和拉普拉斯基于技能（又称为选项）发现。前者通过互信息损失最大化发现的选项的多样性，但忽视了状态空间的覆盖率，而后者侧重于通过增加探索过程中的连接性来提高选项的覆盖率，但不考虑多样性。本文提出了一个统一的框架，通过对确定性点过程（DPP）的新型使用来量化多样性和覆盖性，并显式优化无监督选项发现的两个目标。具体而言，我们使用状态转换图的拉普拉斯谱定义DPP核矩阵，并使用轨迹中的期望模数作为目标，来捕捉和增强多样性和覆盖率。

    Learning rich skills through temporal abstractions without supervision of external rewards is at the frontier of Reinforcement Learning research. Existing works mainly fall into two distinctive categories: variational and Laplacian-based skill (a.k.a., option) discovery. The former maximizes the diversity of the discovered options through a mutual information loss but overlooks coverage of the state space, while the latter focuses on improving the coverage of options by increasing connectivity during exploration, but does not consider diversity. In this paper, we propose a unified framework that quantifies diversity and coverage through a novel use of the Determinantal Point Process (DPP) and enables unsupervised option discovery explicitly optimizing both objectives. Specifically, we define the DPP kernel matrix with the Laplacian spectrum of the state transition graph and use the expected mode number in the trajectories as the objective to capture and enhance both diversity and cover
    
[^121]: 在分布偏移下正则化风险最小化的单调风险关系

    Monotonic Risk Relationships under Distribution Shifts for Regularized Risk Minimization. (arXiv:2210.11589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.11589](http://arxiv.org/abs/2210.11589)

    本文研究了在分布转移写下，期望模型在两个分布上性能存在单调关系的条件，利用岭正则化通用线性模型证明了平方误差的精确渐近线性关系和误分类误差的单调关系，以及线性逆问题的近似线性关系。

    

    机器学习系统通常应用于与训练分布不同的数据。最近的研究表明，在各种分类和信号重建问题中，超出分布的性能与内部分布的性能强烈线性相关。如果存在这种关系或更一般的单调关系，将产生重要的影响。例如，它允许将一个分布上的性能优化作为另一个分布上性能的代理。在本文中，我们研究了在两个分布上模型性能之间预期存在单调关系的条件。我们在协变量转移下，证明了岭正则化通用线性模型的平方误差的精确渐近线性关系和误分类误差的单调关系，以及线性逆问题的近似线性关系。

    Machine learning systems are often applied to data that is drawn from a different distribution than the training distribution. Recent work has shown that for a variety of classification and signal reconstruction problems, the out-of-distribution performance is strongly linearly correlated with the in-distribution performance. If this relationship or more generally a monotonic one holds, it has important consequences. For example, it allows to optimize performance on one distribution as a proxy for performance on the other. In this paper, we study conditions under which a monotonic relationship between the performances of a model on two distributions is expected. We prove an exact asymptotic linear relation for squared error and a monotonic relation for misclassification error for ridge-regularized general linear models under covariate shift, as well as an approximate linear relation for linear inverse problems.
    
[^122]: 预处理器很重要！对机器学习系统的现实决策攻击

    Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems. (arXiv:2210.03297v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.03297](http://arxiv.org/abs/2210.03297)

    在目标机器学习系统中加入预处理器可以有效提高对基于查询的攻击的防御能力。预处理器引入输入空间的不变性，攻击者需要大量的查询才能重新发现或克服这种不变性。通过逆向工程预处理器并利用提取的信息攻击端到端系统可以绕过这些预处理器的防御。

    

    基于决策的攻击通过只进行硬标签查询来构建针对机器学习(ML)模型的对抗样本。这些攻击主要直接应用于独立的神经网络。然而，在实践中，ML模型只是更大学习系统的一个组成部分。我们发现，通过在分类器前添加一个预处理器，最先进的基于查询的攻击对攻击预测流水线的效果要比对单独的模型攻击高效7倍。我们解释了这种差异的原因是大多数预处理器引入了输入空间的某种不变性。因此，不知道这种不变性的攻击必然会浪费大量的查询来重新发现或克服它。因此，我们开发了技术来(i)逆向工程预处理器，然后(ii)利用提取的信息攻击端到端系统。我们的预处理器提取方法只需要几百个查询，并且我们的预处理器感知攻击可以有效绕过这些预处理器的防御。

    Decision-based attacks construct adversarial examples against a machine learning (ML) model by making only hard-label queries. These attacks have mainly been applied directly to standalone neural networks. However, in practice, ML models are just one component of a larger learning system. We find that by adding a single preprocessor in front of a classifier, state-of-the-art query-based attacks are up to 7$\times$ less effective at attacking a prediction pipeline than at attacking the model alone. We explain this discrepancy by the fact that most preprocessors introduce some notion of invariance to the input space. Hence, attacks that are unaware of this invariance inevitably waste a large number of queries to re-discover or overcome it. We, therefore, develop techniques to (i) reverse-engineer the preprocessor and then (ii) use this extracted information to attack the end-to-end system. Our preprocessors extraction method requires only a few hundred queries, and our preprocessor-aware
    
[^123]: 并行和分布式图神经网络：深入并发性分析

    Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis. (arXiv:2205.09702v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09702](http://arxiv.org/abs/2205.09702)

    这项研究深入分析了并行和分布式图神经网络，在设计了并行性分类方法后，研究了各种GNN模型、任务、软件框架和硬件加速器中的并行性，并重点关注相关张量的稀疏性/密度。

    

    图神经网络（GNNs）是深度学习中最强大的工具之一。它们常常在无结构网络上解决复杂问题，如节点分类、图分类或链接预测，具有高准确性。然而，GNNs的推理和训练都非常复杂，它们独特地将不规则图处理的特性与密集和规则计算相结合。这种复杂性使得在现代大规模并行架构上高效执行GNNs非常具有挑战性。为了缓解这一问题，我们首先设计了GNNs中的并行性分类方法，考虑了数据并行性和模型并行性，以及不同形式的流水线。然后，我们使用这个分类方法来研究众多GNN模型、GNN驱动的机器学习任务、软件框架或硬件加速器中的并行性。我们使用工作深度模型，并评估通信量和同步。我们特别关注相关张量的稀疏性/密度。

    Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern massively parallel architectures. To alleviate this, we first design a taxonomy of parallelism in GNNs, considering data and model parallelism, and different forms of pipelining. Then, we use this taxonomy to investigate the amount of parallelism in numerous GNN models, GNN-driven machine learning tasks, software frameworks, or hardware accelerators. We use the work-depth model, and we also assess communication volume and synchronization. We specifically focus on the sparsity/density of the associated tensors, in o
    
[^124]: Torchhd:一种支持超维计算和向量符号体系研究的开源Python库

    Torchhd: An Open Source Python Library to Support Research on Hyperdimensional Computing and Vector Symbolic Architectures. (arXiv:2205.09208v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09208](http://arxiv.org/abs/2205.09208)

    Torchhd是一个高性能的开源Python库，旨在支持超维计算和向量符号体系研究。它提供了最先进的功能，易于使用的界面，并且能够使实验运行速度提高多达100倍。

    

    超维计算（HD），也被称为向量符号体系（VSA），是一种利用随机高维向量空间的性质进行分布式表示计算的框架。科学界对于聚集和传播这个特别多学科领域的研究的承诺对于其进步至关重要。为了加入这些努力，我们推出了Torchhd，一个高性能的超维/VSA的开源Python库。Torchhd旨在使超维/VSA更易于使用，并为进一步的研究和应用开发提供高效的基础。这个易于使用的库建立在PyTorch之上，具有最先进的超维/VSA功能，清晰的文档和来自知名出版物的实现示例。将公开可用的代码与其相应的Torchhd实现进行比较，实验可以运行速度提高多达100倍。Torchhd可在以下链接中获取：https://github.com/hyperdimensional-computing/tor

    Hyperdimensional computing (HD), also known as vector symbolic architectures (VSA), is a framework for computing with distributed representations by exploiting properties of random high-dimensional vector spaces. The commitment of the scientific community to aggregate and disseminate research in this particularly multidisciplinary area has been fundamental for its advancement. Joining these efforts, we present Torchhd, a high-performance open source Python library for HD/VSA. Torchhd seeks to make HD/VSA more accessible and serves as an efficient foundation for further research and application development. The easy-to-use library builds on top of PyTorch and features state-of-the-art HD/VSA functionality, clear documentation, and implementation examples from well-known publications. Comparing publicly available code with their corresponding Torchhd implementation shows that experiments can run up to 100x faster. Torchhd is available at: https://github.com/hyperdimensional-computing/tor
    
[^125]: 多尺度注意力流用于概率时间序列预测

    Multi-scale Attention Flow for Probabilistic Time Series Forecasting. (arXiv:2205.07493v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07493](http://arxiv.org/abs/2205.07493)

    本论文提出了一种名为Multi-scale Attention Normalizing Flow(MANF)的非自回归深度学习模型，通过整合多尺度注意力和相对位置信息，实现多变量时间序列的精确分布建模，并且避免了累积误差的影响和增加时间复杂度的问题。

    

    多变量时间序列的概率预测是一项具有挑战性但实用的任务。一方面，挑战在于如何有效地捕捉交互时间序列之间的跨序列相关性，以实现准确的分布建模。另一方面，我们应考虑如何更准确地捕捉时间序列内的上下文信息，以建模多变量时间序列的时间动态。在本工作中，我们提出了一种新颖的非自回归深度学习模型，称为多尺度注意力归一化流（MANF），其中我们整合了多尺度注意力和相对位置信息，而多变量数据分布由有条件的归一化流表示。此外，与自回归建模方法相比，我们的模型避免了累积误差的影响，且不增加时间复杂度。大量实验证明，我们的模型在许多流行的多变量时间序列上实现了最先进的性能。

    The probability prediction of multivariate time series is a notoriously challenging but practical task. On the one hand, the challenge is how to effectively capture the cross-series correlations between interacting time series, to achieve accurate distribution modeling. On the other hand, we should consider how to capture the contextual information within time series more accurately to model multivariate temporal dynamics of time series. In this work, we proposed a novel non-autoregressive deep learning model, called Multi-scale Attention Normalizing Flow(MANF), where we integrate multi-scale attention and relative position information and the multivariate data distribution is represented by the conditioned normalizing flow. Additionally, compared with autoregressive modeling methods, our model avoids the influence of cumulative error and does not increase the time complexity. Extensive experiments demonstrate that our model achieves state-of-the-art performance on many popular multiva
    
[^126]: 前馈神经网络中的活动-权重对偶性：泛化性的几何决定因素

    The activity-weight duality in feed forward neural networks: The geometric determinants of generalization. (arXiv:2203.10736v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.10736](http://arxiv.org/abs/2203.10736)

    这项研究发现了在前馈神经网络中，神经元活动的变化与连接到下一层神经元的权重变化之间的准确对偶关系。通过这种对偶性，我们能够将输入数据的变化映射到对应的权重变化，并发现泛化损失可以通过解的损失函数的Hessian矩阵的特征方向的几何因子的乘积来表示。

    

    机器学习中一个基本的问题是泛化性。在具有大量权重（参数）的神经网络模型中，可以找到很多解来很好地拟合训练数据。关键问题是哪个解能够描述不在训练集中的测试数据。在这里，我们报告了在任何前馈神经网络的密集连接层中，给定层神经元活动的变化与连接到下一层神经元的权重变化之间的确切对偶（等价）关系的发现。活动-权重（A-W）对偶性使我们能够将输入（数据）的变化映射到相应的对偶权重的变化。通过使用这种映射，我们表明泛化损失可以分解为在权重空间中的解的损失函数的Hessian矩阵的不同特征方向的贡献之和。给定特征方向的贡献是两个几何因子（行列式）的乘积：尖锐度

    One of the fundamental problems in machine learning is generalization. In neural network models with a large number of weights (parameters), many solutions can be found to fit the training data equally well. The key question is which solution can describe testing data not in the training set. Here, we report the discovery of an exact duality (equivalence) between changes in activities in a given layer of neurons and changes in weights that connect to the next layer of neurons in a densely connected layer in any feed forward neural network. The activity-weight (A-W) duality allows us to map variations in inputs (data) to variations of the corresponding dual weights. By using this mapping, we show that the generalization loss can be decomposed into a sum of contributions from different eigen-directions of the Hessian matrix of the loss function at the solution in weight space. The contribution from a given eigen-direction is the product of two geometric factors (determinants): the sharpn
    
[^127]: 使用因子图学习表格强化学习的多智能体技能

    Learning Multi-agent Skills for Tabular Reinforcement Learning using Factor Graphs. (arXiv:2201.08227v3 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2201.08227](http://arxiv.org/abs/2201.08227)

    本论文提出了一个方法可以直接在多智能体场景中计算多智能体技能，通过智能体之间的合作性探索行为来改善联合状态空间的连通性。

    

    技能发现被开发用于改善单智能体情景中稀疏奖励信号的强化学习探索能力，通过连接状态转移图的Fiedler向量提供的嵌入空间中最远的状态。然而，这些技能发现方法无法直接推广到多智能体场景，因为系统中的智能体数量增加，联合状态空间呈指数增长。因此，现有研究在多智能体场景中采用技能仍然依赖于单智能体技能发现，并未直接发现能够改善智能体联合状态空间连通性的联合技能。在本文中，我们展示了使用合作性探索行为在智能体之间直接计算多智能体技能的可行性，同时仍然享受分解的便利性。我们的关键思想是将联合状态空间逼近为Kronecker图——Kronecker

    Covering skill (a.k.a., option) discovery has been developed to improve the exploration of reinforcement learning in single-agent scenarios with sparse reward signals, through connecting the most distant states in the embedding space provided by the Fiedler vector of the state transition graph. However, these option discovery methods cannot be directly extended to multi-agent scenarios, since the joint state space grows exponentially with the number of agents in the system. Thus, existing researches on adopting options in multi-agent scenarios still rely on single-agent option discovery and fail to directly discover the joint options that can improve the connectivity of the joint state space of agents. In this paper, we show that it is indeed possible to directly compute multi-agent options with collaborative exploratory behaviors among the agents, while still enjoying the ease of decomposition. Our key idea is to approximate the joint state space as a Kronecker graph -- the Kronecker 
    
[^128]: CALDA:改进多源时间序列域自适应方法与对比对抗学习

    CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning. (arXiv:2109.14778v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.14778](http://arxiv.org/abs/2109.14778)

    CALDA是一种新颖的框架，使用对比学习和对抗学习的原则来提高多源时间序列域自适应方法。它通过对齐特征表示和利用跨域标签信息来提高性能。

    

    无监督域自适应（UDA）提供了一种策略，用于改进数据丰富（目标）领域中机器学习性能，在这些领域中无法获得地面真实标签，但可以在相关（源）领域中找到。在具有元领域信息（如标签分布）的情况下，弱监督可以进一步提升性能。我们提出了一个新颖的框架CALDA来解决这两个问题。CALDA通过对比学习和对抗学习的原则，为时间序列数据的多源域自适应（MS-UDA）提供了强大的支持。与以前的方法类似，CALDA利用对抗学习来对齐源和目标特征表示。与以前的方法不同，CALDA还利用了跨域的跨源标签信息。CALDA将具有相同标签的示例彼此靠近，而将具有不同标签的示例分开，通过对比学习来重新塑造空间。与以前的对比自适应方法不同

    Unsupervised domain adaptation (UDA) provides a strategy for improving machine learning performance in data-rich (target) domains where ground truth labels are inaccessible but can be found in related (source) domains. In cases where meta-domain information such as label distributions is available, weak supervision can further boost performance. We propose a novel framework, CALDA, to tackle these two problems. CALDA synergistically combines the principles of contrastive learning and adversarial learning to robustly support multi-source UDA (MS-UDA) for time series data. Similar to prior methods, CALDA utilizes adversarial learning to align source and target feature representations. Unlike prior approaches, CALDA additionally leverages cross-source label information across domains. CALDA pulls examples with the same label close to each other, while pushing apart examples with different labels, reshaping the space through contrastive learning. Unlike prior contrastive adaptation methods
    
[^129]: “同质性对于图神经网络是必要的吗？”

    Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.06134](http://arxiv.org/abs/2106.06134)

    “同质性对于良好的图神经网络性能是否必要的”这一问题在研究中得到了重新评估。实验证明，标准的图卷积网络（GCNs）在一些常用的异质性图上可以实现比精心设计的方法更好的性能。

    

    图神经网络（GNN）在学习适用于众多基于图的机器学习任务的表示方面显示出极强的能力。当应用于半监督节点分类时，由于同质性假设（“类似相互吸引”），人们普遍认为GNN可以很好地工作，但在异质性图中（连接不相似节点的图）无法泛化。最近的研究通过设计新的架构来克服这种与异质性相关的限制，引用了贫弱的基准性能以及在一些异质性图基准数据集上的新架构改进作为证据。在我们的实验证明，标准的图卷积网络（GCN）实际上在一些常用的异质性图上可以实现比这些精心设计的方法更好的性能。这激励我们重新思考同质性是否真正对于良好的GNN性能是必要的。我们发现这种说法并不完全正确，事实上，GCN可以在异质性图上实现强大的性能。

    Graph neural networks (GNNs) have shown great prowess in learning representations suitable for numerous graph-based machine learning tasks. When applied to semi-supervised node classification, GNNs are widely believed to work well due to the homophily assumption ("like attracts like"), and fail to generalize to heterophilous graphs where dissimilar nodes connect. Recent works design new architectures to overcome such heterophily-related limitations, citing poor baseline performance and new architecture improvements on a few heterophilous graph benchmark datasets as evidence for this notion. In our experiments, we empirically find that standard graph convolutional networks (GCNs) can actually achieve better performance than such carefully designed methods on some commonly used heterophilous graphs. This motivates us to reconsider whether homophily is truly necessary for good GNN performance. We find that this claim is not quite true, and in fact, GCNs can achieve strong performance on h
    

