# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification.](http://arxiv.org/abs/2311.01655) | 这项工作介绍了一种通用方法，可以高效地检测潜在的伪相关关系，并且相比之下需要更少的人工干预。 |
| [^2] | [Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis.](http://arxiv.org/abs/2311.01052) | 这项研究引入了韧性多选学习（rMCL）方法，通过使用基于Voronoi tessellations的数学框架和学习评分方案，在回归设置中实现了对于每个训练输入可能采样多个目标的条件分布估计。该方法在合成数据和声源定位问题上得到了实证验证和进一步评估，展示了其实际的有用性和解释的相关性。 |
| [^3] | [Loss Modeling for Multi-Annotator Datasets.](http://arxiv.org/abs/2311.00619) | 该论文提出了一种通过利用多任务学习和基于损失的标签修正来学习多注释者数据的准确表示的方法。通过这种方法，可以有效地分离赞同和不赞同的注释，并且在单一或多注释者设置下改善预测性能。该方法还显示出对主观数据的额外标签噪声具有鲁棒性。 |
| [^4] | [Infinite Width Graph Neural Networks for Node Regression/ Classification.](http://arxiv.org/abs/2310.08176) | 本研究分析了无限宽度图神经网络在图结构化数据上的应用。通过连接深度学习和高斯过程/核方法，研究推广了神经网络，并推导出了闭式形式的核函数和高斯过程。研究结果表明，高斯过程和核方法在不确定性估计方面更加用户友好，并且可以在多种架构和数据集上进行回归/分类任务。 |
| [^5] | [Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria.](http://arxiv.org/abs/2309.12620) | 本研究提出了一种新的基于偏好学习的方法，用于解决存在时间准则的多准则排序问题。首先，提出了一个凸二次规划模型，并引入正则化框架。其次，设计了一种集成学习算法，用于合并多个优化器的输出。为了提高可扩展性和适应可学习的时间折扣因子，引入了一种新颖的单调循环神经网络(mRNN)。这些方法有效地处理了时间序列数据，并保持了多准则排序问题的关键属性。 |
| [^6] | [Semi-automatic staging area for high-quality structured data extraction from scientific literature.](http://arxiv.org/abs/2309.10923) | 这篇论文介绍了一种半自动化分区平台，用于从科学文献中提取超导体实验数据。该平台通过自动和手动过程的结合，提高了数据更新效率，同时保持或提高了数据质量。评估实验表明该分区平台显著提高了数据的管理质量。 |
| [^7] | [Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning.](http://arxiv.org/abs/2309.07383) | 本文研究了在强化学习中出现的值函数近似在特定本地空间中的收敛速度，提出了运用算子方程进行离线近似的方法，并通过有限维近似空间中的功率函数得到了值函数近似误差的上界。这些结果改进和细化了值函数近似的收敛性。 |
| [^8] | [An Overview Of Temporal Commonsense Reasoning and Acquisition.](http://arxiv.org/abs/2308.00002) | 本文综述了时间常识推理领域的研究进展，重点关注通过增强语言模型的性能来提高推理能力，并对多个数据集进行评估。然而，这些增强模型仍然难以达到人类水平的推理能力。 |
| [^9] | [Shared Growth of Graph Neural Networks via Free-direction Knowledge Distillation.](http://arxiv.org/abs/2307.00534) | 本文提出了一种基于自由方向知识蒸馏的图神经网络共同增长的框架，通过强化学习同时训练两个较浅的GNN模型，实现了它们之间的知识交流和共享。 |
| [^10] | [Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD.](http://arxiv.org/abs/2307.00310) | 本文开发了一种新的DP-SGD分析方法，可以在训练过程中对许多数据点的隐私泄漏进行更准确的评估。 |
| [^11] | [Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition.](http://arxiv.org/abs/2306.14670) | 本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。 |
| [^12] | [Towards More Realistic Membership Inference Attacks on Large Diffusion Models.](http://arxiv.org/abs/2306.12983) | 本文研究了成员推断攻击问题，以确定图像是否在训练集中使用。研究集中于稳定扩散模型，提出了一种公平的评估框架，并进行了成员攻击，揭示了先前提出的评估设置不能很好地模拟真实世界中的成员攻击。 |
| [^13] | [GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection.](http://arxiv.org/abs/2306.12251) | GADBench是一个全面的基准系统，发现了树集成和简单邻域汇聚方法胜过所有23个模型，包括最新的针对GAD任务量身定制的GNN模型。 |
| [^14] | [Corrector Operator to Enhance Accuracy and Reliability of Neural Operator Surrogates of Nonlinear Variational Boundary-Value Problems.](http://arxiv.org/abs/2306.12047) | 本文提供了一种基于Corrector操作符的框架，以增强神经算子代理非线性变分边界值问题的准确度和可靠性。使用该方案对于PCANet型神经算子的二维非线性扩散模型的数值实验结果显示，逼近的准确度近乎提高了两个数量级，并且还在涉及非线性d之上的拓扑优化问题中得到了探讨。 |
| [^15] | [Open Problem: Learning with Variational Objectives on Measures.](http://arxiv.org/abs/2306.11928) | 本文探讨了在测度上编写变分目标的动机，提出通过此类目标推导实用算法，以解决超出分布的泛化和弱监督学习等问题的开放问题。 |
| [^16] | [Conditional Matrix Flows for Gaussian Graphical Models.](http://arxiv.org/abs/2306.07255) | 本文为解决高斯图模型中变量的条件独立结构问题，提出了一种针对精度矩阵的$l_p$正则化的方法，并将频率学派和贝叶斯学派的优点融合在变分推理中，并引入了矩阵变量标准化流程来逼近后验。 |
| [^17] | [Representational Strengths and Limitations of Transformers.](http://arxiv.org/abs/2306.02896) | 本文研究了transformer的表示能力，正面说明了transformer在稀疏平均任务中的效率比循环网络和前馈网络更高，并展示了大嵌入维度在transformer中的必要性和作用；负面说明了注意力层的复杂度随输入大小线性缩放，但这种情况在实践中很少发生，可以使用替代的变体。 |
| [^18] | [Data Representations' Study of Latent Image Manifolds.](http://arxiv.org/abs/2305.19730) | 本文研究了图像流形的曲率，其中最先进的卷积神经网络在层间具有特征曲率剖面，曲率差异与网络的泛化能力有强烈的相关性，且mixup等常见的规范化方法产生更平的表示。 |
| [^19] | [UMD: Unsupervised Model Detection for X2X Backdoor Attacks.](http://arxiv.org/abs/2305.18651) | UMD是一种无监督的模型检测方法，能够有效地检测X2X后门攻击，对抗（源，目标）类别对进行联合推断，该方法定义了新的可转移性统计量，并使用聚类方法来测量和选择潜在的后门类别对的子集。 |
| [^20] | [On Architectural Compression of Text-to-Image Diffusion Models.](http://arxiv.org/abs/2305.15798) | 本文研究了如何通过架构压缩方法实现文本到图像生成模型的高效化，提出了一种块删除知识提取SDMs（BK-SDMs）方法，在减少采样步骤数量和利用网络量化的同时，可以显著减少模型的参数数量、MAC和延迟，最终实现了与使用更多资源训练的模型相竞争的效果。 |
| [^21] | [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models.](http://arxiv.org/abs/2305.14456) | 这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。 |
| [^22] | [Energy-efficient memcapacitive physical reservoir computing system for temporal data processing.](http://arxiv.org/abs/2305.12025) | 本文研究了一种基于能效随态电容器的物理储层计算系统，解决了时间数据的分类任务和分析时间序列数据的问题。在实验中，系统能够实现较高的准确率和较小的均方误差。 |
| [^23] | [Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions.](http://arxiv.org/abs/2305.05400) | 本研究探讨了使用随机Lp范数失真对图像分类器的训练和测试数据进行增强，并评估模型对不可感知随机失真的稳健性，发现稳健性可能会提高模型在随机失真方面的性能，但也可能会损害L∞范数的稳健性。 |
| [^24] | [Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning.](http://arxiv.org/abs/2303.09986) | 本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。 |
| [^25] | [Learning to Reconstruct Signals From Binary Measurements.](http://arxiv.org/abs/2303.08691) | 该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。 |
| [^26] | [EvoPrompting: Language Models for Code-Level Neural Architecture Search.](http://arxiv.org/abs/2302.14838) | EvoPrompting利用语言模型作为自适应变异和交叉操作符来进行神经架构搜索，在MNIST-1D数据集和CLRS算法推理基准上都取得了比人类设计的架构更好的性能表现。 |
| [^27] | [ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning.](http://arxiv.org/abs/2301.12618) | ForkMerge是一种新方法，它帮助缓解了辅助任务学习中的负迁移问题，并在多任务学习中表现出良好的性能优于现有的ATL方法。 |
| [^28] | [Spectral2Spectral: Image-spectral Similarity Assisted Spectral CT Deep Reconstruction without Reference.](http://arxiv.org/abs/2210.01125) | 本文提出了一种名为Spectral2Spectral的深度重建网络，它利用图像-光谱领域内的相似性先验通过无参考方式来辅助光谱CT的深度重建。 |
| [^29] | [On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability.](http://arxiv.org/abs/2207.04876) | 本研究通过利用最小描述长度原则和结构稳定性为脉冲神经网络提供了一个明确的泛化界限，并指定了最大稳定分歧解数的下限和上限。 |
| [^30] | [Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-Start.](http://arxiv.org/abs/2202.03397) | 本文针对一类双层问题，提出了无需warm-start也可实现最优样本复杂度的方法。 |

# 详细

[^1]: 通过鲁棒视觉概念在真实图像和AI生成图像分类中检测伪相关关系

    Detecting Spurious Correlations via Robust Visual Concepts in Real and AI-Generated Image Classification. (arXiv:2311.01655v1 [cs.LG])

    [http://arxiv.org/abs/2311.01655](http://arxiv.org/abs/2311.01655)

    这项工作介绍了一种通用方法，可以高效地检测潜在的伪相关关系，并且相比之下需要更少的人工干预。

    

    通常机器学习模型倾向于自动学习训练数据中存在的关联，而不会质疑其有效性或适当性。这种不可取的特性是伪相关关系的体现，使得模型在分布变化的情况下不可靠且容易失败。研究表明，大多数试图纠正伪相关关系的方法仅对模型已知的伪关联有效。当前的伪相关关系检测算法要么依赖于大量的人工标注，要么在其制定中太过限制性。此外，它们依赖于对视觉工件的严格定义，这在由生成模型生成的数据中可能不适用，因为这些模型以产生不符合标准规范的内容而闻名。在这项工作中，我们介绍了一种通用方法，可以高效地检测潜在的伪相关关系，并且相比之下需要更少的人工干预。

    Often machine learning models tend to automatically learn associations present in the training data without questioning their validity or appropriateness. This undesirable property is the root cause of the manifestation of spurious correlations, which render models unreliable and prone to failure in the presence of distribution shifts. Research shows that most methods attempting to remedy spurious correlations are only effective for a model's known spurious associations. Current spurious correlation detection algorithms either rely on extensive human annotations or are too restrictive in their formulation. Moreover, they rely on strict definitions of visual artifacts that may not apply to data produced by generative models, as they are known to hallucinate contents that do not conform to standard specifications. In this work, we introduce a general-purpose method that efficiently detects potential spurious correlations, and requires significantly less human interference in comparison t
    
[^2]: 韧性多选学习：用于音频场景分析的学习评分方案的引入

    Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])

    [http://arxiv.org/abs/2311.01052](http://arxiv.org/abs/2311.01052)

    这项研究引入了韧性多选学习（rMCL）方法，通过使用基于Voronoi tessellations的数学框架和学习评分方案，在回归设置中实现了对于每个训练输入可能采样多个目标的条件分布估计。该方法在合成数据和声源定位问题上得到了实证验证和进一步评估，展示了其实际的有用性和解释的相关性。

    

    我们引入了韧性多选学习（rMCL），这是一种对于每个训练输入可能采样多个目标的回归设置下条件分布估计的MCL方法的扩展。多选学习是一个简单的框架，用于处理多模态密度估计，使用了一组假设的胜者全拿（WTA）损失。在回归设置中，现有的MCL变体主要集中在合并假设上，从而最终牺牲了预测的多样性。相反，我们的方法依赖于一个基于Voronoi tessellations的输出空间的数学框架支持的新颖的学习评分方案，我们可以从中得出概率解释。在对合成数据进行实证验证后，我们进一步评估了rMCL在声源定位问题上的优点，展示了其实际的有用性和解释的相关性。

    We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input. Multiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation. After empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation.
    
[^3]: 多注释者数据的损失建模

    Loss Modeling for Multi-Annotator Datasets. (arXiv:2311.00619v1 [cs.LG])

    [http://arxiv.org/abs/2311.00619](http://arxiv.org/abs/2311.00619)

    该论文提出了一种通过利用多任务学习和基于损失的标签修正来学习多注释者数据的准确表示的方法。通过这种方法，可以有效地分离赞同和不赞同的注释，并且在单一或多注释者设置下改善预测性能。该方法还显示出对主观数据的额外标签噪声具有鲁棒性。

    

    在公正性方面，考虑到数据集中所有注释者的意见至关重要。然而，在注释大型数据集时，个别注释者经常会提供数千个评分，这可能导致疲劳。此外，这些注释过程可能会持续多天，可能导致对注释者的意见随时间的不准确表示。为了解决这个问题，我们提出利用多任务学习和基于损失的标签修正来学习更准确的多样意见表示。我们展示了使用我们新颖的公式，我们可以清楚地分离赞同和不赞同的注释。此外，我们证明了这种修改可以改善单一或多注释者设置下的预测性能。最后，我们证明了该方法对应用于主观数据的额外标签噪声仍然具有稳健性。

    Accounting for the opinions of all annotators of a dataset is critical for fairness. However, when annotating large datasets, individual annotators will frequently provide thousands of ratings which can lead to fatigue. Additionally, these annotation processes can occur over multiple days which can lead to an inaccurate representation of an annotator's opinion over time. To combat this, we propose to learn a more accurate representation of diverse opinions by utilizing multitask learning in conjunction with loss-based label correction. We show that using our novel formulation, we can cleanly separate agreeing and disagreeing annotations. Furthermore, we demonstrate that this modification can improve prediction performance in a single or multi-annotator setting. Lastly, we show that this method remains robust to additional label noise that is applied to subjective data.
    
[^4]: 无限宽度图神经网络用于节点回归/分类

    Infinite Width Graph Neural Networks for Node Regression/ Classification. (arXiv:2310.08176v1 [cs.LG])

    [http://arxiv.org/abs/2310.08176](http://arxiv.org/abs/2310.08176)

    本研究分析了无限宽度图神经网络在图结构化数据上的应用。通过连接深度学习和高斯过程/核方法，研究推广了神经网络，并推导出了闭式形式的核函数和高斯过程。研究结果表明，高斯过程和核方法在不确定性估计方面更加用户友好，并且可以在多种架构和数据集上进行回归/分类任务。

    

    本研究分析了图神经网络，在每个全连接层的节点数量趋近无穷大时，它是对图结构化数据上全连接深度神经网的一种推广。无限宽度神经网络将深度学习与高斯过程和核方法相连接，后者都是具有悠久传统和丰富理论基础的机器学习框架。高斯过程和核方法的超参数较少，可用于不确定性估计，使其在应用中更加用户友好。本研究扩展了将高斯过程和核方法与神经网络相连接的研究数量不断增加的趋势。对于多种架构（包括标准图神经网络、具有跳跃连接的图神经网络和图注意力神经网络），推导出了核函数和高斯过程的闭式形式。对这些架构在各种数据集上进行了评估，并进行了回归/分类任务。

    This work analyzes Graph Neural Networks, a generalization of Fully-Connected Deep Neural Nets on Graph structured data, when their width, that is the number of nodes in each fullyconnected layer is increasing to infinity. Infinite Width Neural Networks are connecting Deep Learning to Gaussian Processes and Kernels, both Machine Learning Frameworks with long traditions and extensive theoretical foundations. Gaussian Processes and Kernels have much less hyperparameters then Neural Networks and can be used for uncertainty estimation, making them more user friendly for applications. This works extends the increasing amount of research connecting Gaussian Processes and Kernels to Neural Networks. The Kernel and Gaussian Process closed forms are derived for a variety of architectures, namely the standard Graph Neural Network, the Graph Neural Network with Skip-Concatenate Connections and the Graph Attention Neural Network. All architectures are evaluated on a variety of datasets on the task
    
[^5]: 基于数据驱动的多准则排序模型在时间准则下的应用研究

    Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria. (arXiv:2309.12620v1 [cs.LG])

    [http://arxiv.org/abs/2309.12620](http://arxiv.org/abs/2309.12620)

    本研究提出了一种新的基于偏好学习的方法，用于解决存在时间准则的多准则排序问题。首先，提出了一个凸二次规划模型，并引入正则化框架。其次，设计了一种集成学习算法，用于合并多个优化器的输出。为了提高可扩展性和适应可学习的时间折扣因子，引入了一种新颖的单调循环神经网络(mRNN)。这些方法有效地处理了时间序列数据，并保持了多准则排序问题的关键属性。

    

    预测方法的出现促进了数据驱动的决策支持方法在各个领域中的应用。然而，开发能够有效处理时间序列数据的模型仍然是一个长期的挑战。本研究提出了一种新颖的基于偏好学习的方法，用于解决存在时间准则的多准则排序问题。我们首先提出了一个凸二次规划模型，该模型具有固定时间折扣因子，并在正则化框架内运行。此外，我们提出了一种集成学习算法，旨在合并多个可能较弱的优化器的输出，通过并行计算高效执行此过程。为了提高可扩展性并适应可学习的时间折扣因子，我们引入了一种新颖的单调循环神经网络(mRNN)。它旨在捕捉随时间演化的偏好动态，同时保持多准则排序问题固有的关键属性，包括准则的顺序性。

    The advent of predictive methodologies has catalyzed the emergence of data-driven decision support across various domains. However, developing models capable of effectively handling input time series data presents an enduring challenge. This study presents novel preference learning approaches to multiple criteria sorting problems in the presence of temporal criteria. We first formulate a convex quadratic programming model characterized by fixed time discount factors, operating within a regularization framework. Additionally, we propose an ensemble learning algorithm designed to consolidate the outputs of multiple, potentially weaker, optimizers, a process executed efficiently through parallel computation. To enhance scalability and accommodate learnable time discount factors, we introduce a novel monotonic Recurrent Neural Network (mRNN). It is designed to capture the evolving dynamics of preferences over time while upholding critical properties inherent to MCS problems, including crit
    
[^6]: 半自动化分区: 用于从科学文献中提取高质量结构化数据的平台

    Semi-automatic staging area for high-quality structured data extraction from scientific literature. (arXiv:2309.10923v1 [cs.CL])

    [http://arxiv.org/abs/2309.10923](http://arxiv.org/abs/2309.10923)

    这篇论文介绍了一种半自动化分区平台，用于从科学文献中提取超导体实验数据。该平台通过自动和手动过程的结合，提高了数据更新效率，同时保持或提高了数据质量。评估实验表明该分区平台显著提高了数据的管理质量。

    

    在本研究中，我们提出了一个用于从科学文章中采集超导体实验数据的 SuperCon 数据库的分区平台。我们的目标是提高更新 SuperCon 的效率，同时保持或提高数据质量。我们介绍了一个由自动和手动过程组成的工作流驱动的半自动化分区平台，用于从提取的数据库中对数据进行校验和纠错。异常检测自动过程用于预先筛选采集到的数据。用户可以通过定制的用户界面在原始 PDF 文档上进行数据验证和纠错。此外，当记录被纠错时，其原始数据被收集并用于改进机器学习模型的训练数据。评估实验表明我们的分区平台显著提高了数据的管理质量。我们将界面与传统的手动阅读 PDF 文档并在 Excel 文档中记录信息的方法进行了比较。

    In this study, we propose a staging area for ingesting new superconductors' experimental data in SuperCon that is machine-collected from scientific articles. Our objective is to enhance the efficiency of updating SuperCon while maintaining or enhancing the data quality. We present a semi-automatic staging area driven by a workflow combining automatic and manual processes on the extracted database. An anomaly detection automatic process aims to pre-screen the collected data. Users can then manually correct any errors through a user interface tailored to simplify the data verification on the original PDF documents. Additionally, when a record is corrected, its raw data is collected and utilised to improve machine learning models as training data. Evaluation experiments demonstrate that our staging area significantly improves curation quality. We compare the interface with the traditional manual approach of reading PDF documents and recording information in an Excel document. Using the in
    
[^7]: 在强化学习中使用的近似的某些本地空间中的收敛速度

    Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning. (arXiv:2309.07383v1 [eess.SY])

    [http://arxiv.org/abs/2309.07383](http://arxiv.org/abs/2309.07383)

    本文研究了在强化学习中出现的值函数近似在特定本地空间中的收敛速度，提出了运用算子方程进行离线近似的方法，并通过有限维近似空间中的功率函数得到了值函数近似误差的上界。这些结果改进和细化了值函数近似的收敛性。

    

    本文研究了在一组再生核希尔伯特空间（RKHS）$H(\Omega)$中出现的一些值函数近似的收敛速度。通过在特定类的本地空间中构建一个最优控制问题，得到了离线近似的算子方程的强收敛速度，这个算子方程出现在策略迭代中。利用有限维近似空间$H_N$在本地空间$H(\Omega)$中的功率函数$\Pwr_{H,N}$，得到了值函数近似误差的显式上界。这些上界具有几何性质，并对值函数近似的收敛性有了一些改进和细化。

    This paper studies convergence rates for some value function approximations that arise in a collection of reproducing kernel Hilbert spaces (RKHS) $H(\Omega)$. By casting an optimal control problem in a specific class of native spaces, strong rates of convergence are derived for the operator equation that enables offline approximations that appear in policy iteration. Explicit upper bounds on error in value function approximations are derived in terms of power function $\Pwr_{H,N}$ for the space of finite dimensional approximants $H_N$ in the native space $H(\Omega)$. These bounds are geometric in nature and refine some well-known, now classical results concerning convergence of approximations of value functions.
    
[^8]: 时间常识推理与获取概述

    An Overview Of Temporal Commonsense Reasoning and Acquisition. (arXiv:2308.00002v1 [cs.AI])

    [http://arxiv.org/abs/2308.00002](http://arxiv.org/abs/2308.00002)

    本文综述了时间常识推理领域的研究进展，重点关注通过增强语言模型的性能来提高推理能力，并对多个数据集进行评估。然而，这些增强模型仍然难以达到人类水平的推理能力。

    

    时间常识推理是指理解短语、动作和事件的典型时间背景并将其应用于需要这种知识的问题推理的能力。这种能力在时间自然语言处理任务中至关重要，可能应用于时间线摘要、时间问答和时间自然语言推断等方面。最近的研究表明，大型语言模型虽然善于生成语法正确的句子和解决分类任务，但在推理过程中往往会采取捷径，并陷入简单的语言陷阱。本文章概述了在时间常识推理领域的研究，特别关注通过各种增强方式提高语言模型的性能以及对越来越多数据集的评估。然而，这些增强模型在推理任务上仍然难以达到人类的水平。

    Temporal commonsense reasoning refers to the ability to understand the typical temporal context of phrases, actions, and events, and use it to reason over problems requiring such knowledge. This trait is essential in temporal natural language processing tasks, with possible applications such as timeline summarization, temporal question answering, and temporal natural language inference. Recent research on the performance of large language models suggests that, although they are adept at generating syntactically correct sentences and solving classification tasks, they often take shortcuts in their reasoning and fall prey to simple linguistic traps. This article provides an overview of research in the domain of temporal commonsense reasoning, particularly focusing on enhancing language model performance through a variety of augmentations and their evaluation across a growing number of datasets. However, these augmented models still struggle to approach human performance on reasoning task
    
[^9]: 通过自由方向知识蒸馏在图神经网络中实现共同增长

    Shared Growth of Graph Neural Networks via Free-direction Knowledge Distillation. (arXiv:2307.00534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00534](http://arxiv.org/abs/2307.00534)

    本文提出了一种基于自由方向知识蒸馏的图神经网络共同增长的框架，通过强化学习同时训练两个较浅的GNN模型，实现了它们之间的知识交流和共享。

    

    知识蒸馏（KD）已被证明对提升图神经网络（GNNs）性能有效，其中典型目标是将深层教师GNN的知识蒸馏到更浅的学生GNN中。然而，由于众所周知的过参数化和过平滑问题，训练一个令人满意的深层GNN通常很具挑战性，导致在实际应用中无效的知识转移。在本文中，我们提出了一种基于强化学习的图神经网络自由方向知识蒸馏框架，称为FreeKD，它不再需要提供一个更深层次的优化良好的教师GNN。我们的核心思想是通过层次化的强化学习来协同学习两个较浅的GNN，以便在它们之间交换知识。由于我们观察到一个典型的GNN模型在训练过程中在不同节点表现出更好和更差的性能，我们设计了一种动态和自由方向的知识传递策略，它涉及

    Knowledge distillation (KD) has shown to be effective to boost the performance of graph neural networks (GNNs), where the typical objective is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is often quite challenging to train a satisfactory deeper GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. Our core idea is to collaboratively learn two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often exhibits better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that involves 
    
[^10]: 梯度相似：敏感度经常被过高估计在DP-SGD中

    Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])

    [http://arxiv.org/abs/2307.00310](http://arxiv.org/abs/2307.00310)

    本文开发了一种新的DP-SGD分析方法，可以在训练过程中对许多数据点的隐私泄漏进行更准确的评估。

    

    差分隐私随机梯度下降（DP-SGD）是私有深度学习的标准算法。虽然已知其隐私分析在最坏情况下是紧密的，但是一些实证结果表明，在常见的基准数据集上训练时，所得到的模型对许多数据点的隐私泄漏显著减少。在本文中，我们为DP-SGD开发了一种新的分析方法，捕捉到在数据集中具有相似邻居的点享受更好隐私性的直觉。形式上来说，这是通过修改从训练数据集计算得到的模型更新的每步隐私性分析来实现的。我们进一步开发了一个新的组合定理，以有效地利用这个新的每步分析来推理整个训练过程。总而言之，我们的评估结果表明，这种新颖的DP-SGD分析使我们能够正式地显示DP-SGD对许多数据点的隐私泄漏显著减少。

    Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we ob
    
[^11]: 竞争环境下贝叶斯风险的提高可能导致社会福利的降低

    Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])

    [http://arxiv.org/abs/2306.14670](http://arxiv.org/abs/2306.14670)

    本文研究了机器学习模型在竞争环境下的行为，发现提高数据表示质量可能会导致供应商整体预测准确性降低，从而降低社会福利。

    

    随着机器学习模型规模的增长，缩放定律等趋势预计会导致预测准确性的持续改进。然而，这些趋势只考虑了单个模型供应商的视角，而实际上供应商之间常常竞争用户。本文证明了竞争可以从根本上改变这些缩放趋势的行为，甚至可能造成整体预测准确性随着规模的增大而非单调或降低。我们定义了一个分类任务的竞争模型，并使用数据表示作为研究规模增加的影响的镜头。我们发现在一家市场上，改善数据表示质量（按贝叶斯风险计量）可能会降低竞争模型供应商的整体预测准确性（即社会福利）。我们的例子涵盖了简单设置中的封闭式公式到预训练的 CIFAR-10 模拟。

    As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
    
[^12]: 面向大型扩散模型的更真实成员推断攻击

    Towards More Realistic Membership Inference Attacks on Large Diffusion Models. (arXiv:2306.12983v1 [cs.LG])

    [http://arxiv.org/abs/2306.12983](http://arxiv.org/abs/2306.12983)

    本文研究了成员推断攻击问题，以确定图像是否在训练集中使用。研究集中于稳定扩散模型，提出了一种公平的评估框架，并进行了成员攻击，揭示了先前提出的评估设置不能很好地模拟真实世界中的成员攻击。

    

    生成扩散模型，包括稳定扩散和Midjourney，可以为各种应用程序生成具有视觉吸引力、多样性和高分辨率的图像。这些模型是在数十亿个互联网来源的图像上进行训练的，引发了关于潜在未经授权使用受版权保护的图像的重要担忧。本文研究了如何确定特定图像是否在训练集中使用了，这在网络安全社区中被称为成员推断攻击问题。我们的研究重点是稳定扩散，并解决了设计一个公平的评估框架来回答这个成员问题的挑战。我们提出了一种方法来建立一个公平的评估设置，并将其应用于稳定扩散，使潜在的扩展到其他生成模型成为可能。利用这个评估设置，我们执行成员攻击（包括已知和新引入的攻击）。我们的研究揭示了先前提出的评估设置不能很好地模拟真实世界中的成员攻击。

    Generative diffusion models, including Stable Diffusion and Midjourney, can generate visually appealing, diverse, and high-resolution images for various applications. These models are trained on billions of internet-sourced images, raising significant concerns about the potential unauthorized use of copyright-protected images. In this paper, we examine whether it is possible to determine if a specific image was used in the training set, a problem known in the cybersecurity community and referred to as a membership inference attack. Our focus is on Stable Diffusion, and we address the challenge of designing a fair evaluation framework to answer this membership question. We propose a methodology to establish a fair evaluation setup and apply it to Stable Diffusion, enabling potential extensions to other generative models. Utilizing this evaluation setup, we execute membership attacks (both known and newly introduced). Our research reveals that previously proposed evaluation setups do not
    
[^13]: GADBench：重新审视和对监督图形异常检测进行基准测试

    GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection. (arXiv:2306.12251v1 [cs.LG])

    [http://arxiv.org/abs/2306.12251](http://arxiv.org/abs/2306.12251)

    GADBench是一个全面的基准系统，发现了树集成和简单邻域汇聚方法胜过所有23个模型，包括最新的针对GAD任务量身定制的GNN模型。

    

    长期以来，传统图形异常检测（GAD）算法和最近流行的图形神经网络（GNN）一直存在。目前尚不清楚它们在标准综合设置下的性能如何，GNN是否优于传统算法（如树集成）以及它们在大规模图表上的效率如何。为了解决这些问题，我们提出了GADBench - 一个静态图形监督异常节点检测的全面基准。GADBench在从数千到数百万节点（约6M）的十个真实GAD数据集上提供了23种不同模型的彻底比较。我们的主要发现是，具有简单邻域汇聚的树集成胜过所有其他基线，包括最新的针对GAD任务量身定制的GNN。通过将GADBench作为开源工具提供，我们提供了有关GAD当前进展的关键见解，并为未来研究奠定了坚实的基础。

    With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting, (2) whether GNNs outperform traditional algorithms such as tree ensembles, and (3) their efficiency on large-scale graphs. In response, we present GADBench -- a comprehensive benchmark for supervised anomalous node detection on static graphs. GADBench provides a thorough comparison across 23 distinct models on ten real-world GAD datasets ranging from thousands to millions of nodes ($\sim$6M). Our main finding is that tree ensembles with simple neighborhood aggregation outperform all other baselines, including the latest GNNs tailored for the GAD task. By making GADBench available as an open-source tool, we offer pivotal insights into the current advancements of GAD and establish a solid foundation for future research. Our code is available at https://github.com/squareRoot3/GADBen
    
[^14]: 使用Corrector操作符增强神经算子代理非线性变分边界值问题的准确度和可靠性

    Corrector Operator to Enhance Accuracy and Reliability of Neural Operator Surrogates of Nonlinear Variational Boundary-Value Problems. (arXiv:2306.12047v1 [math.NA])

    [http://arxiv.org/abs/2306.12047](http://arxiv.org/abs/2306.12047)

    本文提供了一种基于Corrector操作符的框架，以增强神经算子代理非线性变分边界值问题的准确度和可靠性。使用该方案对于PCANet型神经算子的二维非线性扩散模型的数值实验结果显示，逼近的准确度近乎提高了两个数量级，并且还在涉及非线性d之上的拓扑优化问题中得到了探讨。

    

    本文旨在开发一类参数偏微分方程解算符的逼近方法，即通过神经算子的方式。神经算子有几个挑战，包括生成适当的训练数据、成本-准确度权衡和非平凡的超参数调整问题。神经算子准确度的不可预测性影响了它们在推理、优化和控制等后续问题中的应用。本文提出了一个基于线性变分问题的框架，给出了神经算子预测结果的校正值。与校正问题相关的算子称为校正算子。通过使用提出的方案对采用PCANet型神经算子的二维非线性扩散模型进行的数值实验结果显示，当使用校正方法对神经算子进行校正时，逼近的准确度近乎提高了两个数量级。此外，涉及非线性d之上的拓扑优化问题也得到了探讨。

    This work focuses on developing methods for approximating the solution operators of a class of parametric partial differential equations via neural operators. Neural operators have several challenges, including the issue of generating appropriate training data, cost-accuracy trade-offs, and nontrivial hyperparameter tuning. The unpredictability of the accuracy of neural operators impacts their applications in downstream problems of inference, optimization, and control. A framework is proposed based on the linear variational problem that gives the correction to the prediction furnished by neural operators. The operator associated with the corrector problem is referred to as the corrector operator. Numerical results involving a nonlinear diffusion model in two dimensions with PCANet-type neural operators show almost two orders of increase in the accuracy of approximations when neural operators are corrected using the proposed scheme. Further, topology optimization involving a nonlinear d
    
[^15]: 开放问题：基于变分目标的测度学习 (arXiv:2306.11928v1 [stat.ML])

    Open Problem: Learning with Variational Objectives on Measures. (arXiv:2306.11928v1 [stat.ML])

    [http://arxiv.org/abs/2306.11928](http://arxiv.org/abs/2306.11928)

    本文探讨了在测度上编写变分目标的动机，提出通过此类目标推导实用算法，以解决超出分布的泛化和弱监督学习等问题的开放问题。

    

    统计学习理论关注的是基于函数的变分目标。本文讨论了在测度上编写类似目标的动机，特别是讨论了超出分布的泛化和弱监督学习。这引发了一个自然的问题：能否将通常的统计学习结果转化为基于测量表达的目标？结果构建是否会导致新的实用算法？

    The theory of statistical learning has focused on variational objectives expressed on functions. In this note, we discuss motivations to write similar objectives on measures, in particular to discuss out-of-distribution generalization and weakly-supervised learning. It raises a natural question: can one cast usual statistical learning results to objectives expressed on measures? Does the resulting construction lead to new algorithms of practical interest?
    
[^16]: 针对高斯图模型的条件矩阵流

    Conditional Matrix Flows for Gaussian Graphical Models. (arXiv:2306.07255v1 [cs.LG])

    [http://arxiv.org/abs/2306.07255](http://arxiv.org/abs/2306.07255)

    本文为解决高斯图模型中变量的条件独立结构问题，提出了一种针对精度矩阵的$l_p$正则化的方法，并将频率学派和贝叶斯学派的优点融合在变分推理中，并引入了矩阵变量标准化流程来逼近后验。

    

    在少数观测变量中研究许多变量之间的条件独立结构是一项具有挑战性的任务。高斯图模型通过在$l_p$正则化中鼓励精度矩阵的稀疏性来解决此问题，其中$p \leq1$。然而，由于亚-$l_1$伪范数使目标高度非凸，因此大多数方法依赖于$l_1$范数。在这种情况下，频率学派方法允许优雅地计算作为收缩参数$\lambda$函数的解决方案路径。贝叶斯公式为精度矩阵引入了拉普拉斯先验，但是不同$\lambda$值的后验推断需要多次运行昂贵的吉布斯采样。我们提出了一个非常通用的框架，用于GGM的变分推理，它统一了频率学派和贝叶斯学派的优点。具体而言，我们建议用定义在s空间上的矩阵变量标准化流程来逼近后验。

    Studying conditional independence structure among many variables with few observations is a challenging task. Gaussian Graphical Models (GGMs) tackle this problem by encouraging sparsity in the precision matrix through an $l_p$ regularization with $p\leq1$. However, since the objective is highly non-convex for sub-$l_1$ pseudo-norms, most approaches rely on the $l_1$ norm. In this case frequentist approaches allow to elegantly compute the solution path as a function of the shrinkage parameter $\lambda$. Instead of optimizing the penalized likelihood, the Bayesian formulation introduces a Laplace prior on the precision matrix. However, posterior inference for different $\lambda$ values requires repeated runs of expensive Gibbs samplers. We propose a very general framework for variational inference in GGMs that unifies the benefits of frequentist and Bayesian frameworks. Specifically, we propose to approximate the posterior with a matrix-variate Normalizing Flow defined on the space of s
    
[^17]: Transformer的代表性优势和局限性

    Representational Strengths and Limitations of Transformers. (arXiv:2306.02896v1 [cs.LG])

    [http://arxiv.org/abs/2306.02896](http://arxiv.org/abs/2306.02896)

    本文研究了transformer的表示能力，正面说明了transformer在稀疏平均任务中的效率比循环网络和前馈网络更高，并展示了大嵌入维度在transformer中的必要性和作用；负面说明了注意力层的复杂度随输入大小线性缩放，但这种情况在实践中很少发生，可以使用替代的变体。

    

    注意力层常用于transformer中，是现代深度学习的支柱之一，但与其他网络结构相比，它们的好处和缺陷没有数学描述。在本研究中，我们对注意力层的表示能力进行了正面和负面的研究，并聚焦于内在复杂度参数，如宽度、深度和嵌入维度。在正面方面，我们提出了一项稀疏平均任务，其中循环网络和前馈网络的复杂度都随输入大小呈多项式缩放，而transformer仅呈对数缩放；此外，我们使用相同的构造来展示transformer中大嵌入维度的必要性和作用。在负面方面，我们提出了一个三元检测任务，其中注意力层的复杂度随输入大小呈线性缩放；由于这种情况在实践中似乎很少发生，因此我们还提出了可以替代的变体。

    Attention layers, as commonly used in transformers, form the backbone of modern deep learning, yet there is no mathematical description of their benefits and deficiencies as compared with other architectures. In this work we establish both positive and negative results on the representation power of attention layers, with a focus on intrinsic complexity parameters such as width, depth, and embedding dimension. On the positive side, we present a sparse averaging task, where recurrent networks and feedforward networks all have complexity scaling polynomially in the input size, whereas transformers scale merely logarithmically in the input size; furthermore, we use the same construction to show the necessity and role of a large embedding dimension in a transformer. On the negative side, we present a triple detection task, where attention layers in turn have complexity scaling linearly in the input size; as this scenario seems rare in practice, we also present natural variants that can be 
    
[^18]: 潜在图像流形的数据表示研究

    Data Representations' Study of Latent Image Manifolds. (arXiv:2305.19730v1 [cs.LG])

    [http://arxiv.org/abs/2305.19730](http://arxiv.org/abs/2305.19730)

    本文研究了图像流形的曲率，其中最先进的卷积神经网络在层间具有特征曲率剖面，曲率差异与网络的泛化能力有强烈的相关性，且mixup等常见的规范化方法产生更平的表示。

    

    深度神经网络在许多领域取得了惊人的成功，但其内在机制尚未得到很好的理解。本文研究了图像流形的曲率，即在其主方向上的流形偏离平坦的程度。我们发现，用于图像分类的最先进的卷积神经网络在层间具有特征曲率剖面：一个初始急剧增加，接着是长时间的平台期，然后是另一个增加。相反，在未经训练的网络中不出现这种行为，其中曲率变平。我们还表明，最后两层之间的曲率差异与网络的泛化能力有强烈的相关性。此外，我们发现，潜在编码的内在维度并非必然表征曲率。最后，我们观察到，mixup等常见的规范化方法在与其他方法相比时产生更平的表示。

    Deep neural networks have been demonstrated to achieve phenomenal success in many domains, and yet their inner mechanisms are not well understood. In this paper, we investigate the curvature of image manifolds, i.e., the manifold deviation from being flat in its principal directions. We find that state-of-the-art trained convolutional neural networks for image classification have a characteristic curvature profile along layers: an initial steep increase, followed by a long phase of a plateau, and followed by another increase. In contrast, this behavior does not appear in untrained networks in which the curvature flattens. We also show that the curvature gap between the last two layers has a strong correlation with the generalization capability of the network. Moreover, we find that the intrinsic dimension of latent codes is not necessarily indicative of curvature. Finally, we observe that common regularization methods such as mixup yield flatter representations when compared to other m
    
[^19]: UMD: 无监督模型检测X2X后门攻击

    UMD: Unsupervised Model Detection for X2X Backdoor Attacks. (arXiv:2305.18651v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18651](http://arxiv.org/abs/2305.18651)

    UMD是一种无监督的模型检测方法，能够有效地检测X2X后门攻击，对抗（源，目标）类别对进行联合推断，该方法定义了新的可转移性统计量，并使用聚类方法来测量和选择潜在的后门类别对的子集。

    

    后门（特洛伊）攻击是深度神经网络面临的常见威胁，其中嵌入后门触发器的一个或多个源类别的样本会被错误分类为对抗目标类别。现有的检测分类器是否遭受后门攻击的方法主要是针对单一对抗目标的攻击设计的（例如，全对一攻击）。据我们所知，没有现有的方法可以在没有监督的情况下有效地解决具有任意数量的源类别的更普遍的X2X攻击，每个源类别都与任意目标类别配对。在本文中，我们提出了UMD，第一个通过联合推断对抗（源，目标）类别对来有效检测X2X后门攻击的无监督模型检测方法。特别地，我们首先定义一种新颖的可转移性统计方法，通过提出的聚类方法来量度和选择一组潜在的后门类别对的子集。然后，这些选择的类别对是基于联合评估进行评估的。

    Backdoor (Trojan) attack is a common threat to deep neural networks, where samples from one or more source classes embedded with a backdoor trigger will be misclassified to adversarial target classes. Existing methods for detecting whether a classifier is backdoor attacked are mostly designed for attacks with a single adversarial target (e.g., all-to-one attack). To the best of our knowledge, without supervision, no existing methods can effectively address the more general X2X attack with an arbitrary number of source classes, each paired with an arbitrary target class. In this paper, we propose UMD, the first Unsupervised Model Detection method that effectively detects X2X backdoor attacks via a joint inference of the adversarial (source, target) class pairs. In particular, we first define a novel transferability statistic to measure and select a subset of putative backdoor class pairs based on a proposed clustering approach. Then, these selected class pairs are jointly assessed based
    
[^20]: 关于文本到图像扩散模型的架构压缩问题研究

    On Architectural Compression of Text-to-Image Diffusion Models. (arXiv:2305.15798v1 [cs.LG])

    [http://arxiv.org/abs/2305.15798](http://arxiv.org/abs/2305.15798)

    本文研究了如何通过架构压缩方法实现文本到图像生成模型的高效化，提出了一种块删除知识提取SDMs（BK-SDMs）方法，在减少采样步骤数量和利用网络量化的同时，可以显著减少模型的参数数量、MAC和延迟，最终实现了与使用更多资源训练的模型相竞争的效果。

    

    稳定扩散模型（SDMs）中出色的文本到图像（T2I）生成结果需要大量计算资源。为了解决这个问题，近期关于高效SDMs的研究将重点放在减少采样步骤的数量和利用网络量化上。与这些方向相反，本研究通过引入块删除知识提取SDMs（BK-SDMs），强调了经典架构压缩在通用T2I合成中的作用。我们从SDMs的U-Net中删除了几个残差和注意力块，使参数数量、每个采样步骤的MAC和延迟减少了超过30％。我们在单个A100 GPU上仅使用0.22M LAION对进行蒸馏预训练（少于全体训练对的0.1％）。尽管使用有限的资源进行训练，我们的紧凑型模型可以通过传递的知识模仿原始SDM，并在对抗较大的多十亿参数模型的情况下实现具有竞争力的结果。

    Exceptional text-to-image (T2I) generation results of Stable Diffusion models (SDMs) come with substantial computational demands. To resolve this issue, recent research on efficient SDMs has prioritized reducing the number of sampling steps and utilizing network quantization. Orthogonal to these directions, this study highlights the power of classical architectural compression for general-purpose T2I synthesis by introducing block-removed knowledge-distilled SDMs (BK-SDMs). We eliminate several residual and attention blocks from the U-Net of SDMs, obtaining over a 30% reduction in the number of parameters, MACs per sampling step, and latency. We conduct distillation-based pretraining with only 0.22M LAION pairs (fewer than 0.1% of the full training pairs) on a single A100 GPU. Despite being trained with limited resources, our compact models can imitate the original SDM by benefiting from transferred knowledge and achieve competitive results against larger multi-billion parameter models
    
[^21]: 在祈祷之后喝啤酒？测量大型语言模型中的文化偏见。

    Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. (arXiv:2305.14456v1 [cs.CL])

    [http://arxiv.org/abs/2305.14456](http://arxiv.org/abs/2305.14456)

    这篇论文研究了大型语言模型在处理和生成阿拉伯文本时出现的文化偏向西方文化的现象，表明语言模型在人名、食品、服装、地点、文学、饮料、宗教和体育等八个文化方面存在偏见。这些发现引发对于当前语言模型文化相关性的担忧。

    

    语言模型是否存在文化偏见？语言模型符合所服务社区的文化因素很重要。然而，本文表明在处理和生成阿拉伯文本时，语言模型存在显著的偏向西方文化的偏见，倾向于产生西方文化相关内容而非阿拉伯文化相关内容。我们通过使用从在线社交媒体上收集的自然出现的上下文和基于可能性评分的指标来量化这种偏见。我们的实验显示，阿拉伯语单语和多语模型在八个不同的文化方面存在西方文化偏见，包括人名、食品、服装、地点、文学、饮料、宗教和体育。当输入的阿拉伯语句子越接近英语时，模型也更容易表现出偏见。这些发现引发人们对当前语言模型文化相关性的担忧。我们的分析表明，在模型设计中应更多考虑文化因素和多样性。

    Are language models culturally biased? It is important that language models conform to the cultural aspects of the communities they serve. However, we show in this paper that language models suffer from a significant bias towards Western culture when handling and generating text in Arabic, often preferring, and producing Western-fitting content as opposed to the relevant Arab content. We quantify this bias through a likelihood scoring-based metric using naturally occurring contexts that we collect from online social media. Our experiments reveal that both Arabic monolingual and multilingual models exhibit bias towards Western culture in eight different cultural aspects: person names, food, clothing, location, literature, beverage, religion, and sports. Models also tend to exhibit more bias when prompted with Arabic sentences that are more linguistically aligned with English. These findings raise concerns about the cultural relevance of current language models. Our analyses show that pr
    
[^22]: 基于能效随态电容器的物理储层计算系统用于时间数据处理

    Energy-efficient memcapacitive physical reservoir computing system for temporal data processing. (arXiv:2305.12025v1 [cs.LG])

    [http://arxiv.org/abs/2305.12025](http://arxiv.org/abs/2305.12025)

    本文研究了一种基于能效随态电容器的物理储层计算系统，解决了时间数据的分类任务和分析时间序列数据的问题。在实验中，系统能够实现较高的准确率和较小的均方误差。

    

    储层计算是一种高效的机器学习框架，通过从输入信号中提取特征并将其映射到高维空间来处理时间数据。物理储层可使用磁旋电子、原子开关网络、硅光学模块、铁电晶体管和易失性存储器来实现。然而，这些设备由于其电阻性质本质上存在能量耗散问题，导致功耗增加。因此，采用电容存储器设备可提供更为能效的解决方案。在这里，我们利用模拟和实验中近似某些短期突触可塑性功能的易失生物膜基质量作为储层，解决分类任务和分析时间序列数据。我们的系统在口音数字分类中实现了98％的准确率，在二阶非线性回归任务中获得了0.0012的归一化均方误差。

    Reservoir computing is a highly efficient machine learning framework for processing temporal data by extracting features from the input signal and mapping them into higher dimensional spaces. Physical reservoir layers have been realized using spintronic oscillators, atomic switch networks, silicon photonic modules, ferroelectric transistors, and volatile memristors. However, these devices are intrinsically energy-dissipative due to their resistive nature, which leads to increased power consumption. Therefore, capacitive memory devices can provide a more energy-efficient approach. Here, we leverage volatile biomembrane-based memcapacitors that closely mimic certain short-term synaptic plasticity functions as reservoirs to solve classification tasks and analyze time-series data in simulation and experimentally. Our system achieves a 98% accuracy rate for spoken digit classification and a normalized mean square error of 0.0012 in a second-order non-linear regression task. Further, to demo
    
[^23]: 使用随机Lp范数失真探究图像分类器的腐败稳健性

    Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v1 [cs.LG])

    [http://arxiv.org/abs/2305.05400](http://arxiv.org/abs/2305.05400)

    本研究探讨了使用随机Lp范数失真对图像分类器的训练和测试数据进行增强，并评估模型对不可感知随机失真的稳健性，发现稳健性可能会提高模型在随机失真方面的性能，但也可能会损害L∞范数的稳健性。

    

    稳健性是机器学习分类器实现安全和可靠的基本属性。在对图像分类模型的对抗稳健性和形式稳健性验证领域中，稳健性通常被定义为在Lp范数距离内对所有输入变化的稳定性。然而，对随机失真的稳健性通常通过在现实世界中观察到的变化来改进和评估，而很少考虑数学定义的Lp范数失真。本研究探讨了使用随机Lp范数失真来增强图像分类器的训练和测试数据。我们借鉴了对抗稳健性领域的方法来评估模型对不可感知随机失真的稳健性。我们实证和理论上研究了在不同Lp范数之间稳健性是否可转移，并得出结论，哪些Lp范数的失真应该用来训练和评估模型。我们发现训练数据增强可能会提高模型在随机失真方面的性能，但也可能会损害L∞范数的稳健性。

    Robustness is a fundamental property of machine learning classifiers to achieve safety and reliability. In the fields of adversarial robustness and formal robustness verification of image classification models, robustness is commonly defined as the stability to all input variations within an Lp-norm distance. However, robustness to random corruptions is usually improved and evaluated using variations observed in the real-world, while mathematically defined Lp-norm corruptions are rarely considered. This study investigates the use of random Lp-norm corruptions to augment the training and test data of image classifiers. We adapt an approach from the field of adversarial robustness to assess the model robustness to imperceptible random corruptions. We empirically and theoretically investigate whether robustness is transferable across different Lp-norms and derive conclusions on which Lp-norm corruptions a model should be trained and evaluated on. We find that training data augmentation wi
    
[^24]: 实现AI控制的FES运动康复：利用强化学习学习循环刺激模式。

    Towards AI-controlled FES-restoration of movements: Learning cycling stimulation pattern with reinforcement learning. (arXiv:2303.09986v1 [cs.RO])

    [http://arxiv.org/abs/2303.09986](http://arxiv.org/abs/2303.09986)

    本文提出了一种基于人工智能的FES康复方法，通过强化学习和详细的肌肉骨骼模型寻找循环刺激模式，并使用真实的自行车数据进行微调，该方法可由非技术人员使用而无需额外硬件或传感器。

    

    功能性电刺激（FES）已经越来越多地与其他康复设备（包括机器人）集成在一起。 FES循环是康复治疗中常用的FES应用之一，它通过刺激腿部肌肉以特定模式进行。 适当的模式因人而异，需要手动调整，这可能需要耗费时间并对个体用户具有挑战性。 本文提出了一种基于人工智能的方法，可用于寻找循环刺激模式，而无需额外的硬件或传感器。我们的方法包括两个阶段，首先使用强化学习和详细的肌肉骨骼模型找到基于模型的模式，使用开源软件构建模型，可以通过我们的自动脚本进行定制，并且可以由非技术人员使用而不需要额外费用。接下来，我们的方法使用真实的自行车数据对模式进行微调。 我们在静止三轮车上对我们的方法进行了模拟测试和实验测试。在模拟测试中，我们的方法可以...

    Functional electrical stimulation (FES) has been increasingly integrated with other rehabilitation devices, including robots. FES cycling is one of the common FES applications in rehabilitation, which is performed by stimulating leg muscles in a certain pattern. The appropriate pattern varies across individuals and requires manual tuning which can be time-consuming and challenging for the individual user. Here, we present an AI-based method for finding the patterns, which requires no extra hardware or sensors. Our method has two phases, starting with finding model-based patterns using reinforcement learning and detailed musculoskeletal models. The models, built using open-source software, can be customised through our automated script and can be therefore used by non-technical individuals without extra cost. Next, our method fine-tunes the pattern using real cycling data. We test our both in simulation and experimentally on a stationary tricycle. In the simulation test, our method can 
    
[^25]: 从二进制测量中学习信号重构

    Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])

    [http://arxiv.org/abs/2303.08691](http://arxiv.org/abs/2303.08691)

    该论文提出了一种新的自监督学习方法SSBM，它只需要二进制数据进行训练，并探索了从不完整的二进制观察中学习的极端情况。这为从二进制测量中恢复信号提供了必要和充分条件，并在一系列真实数据集上展示了SSBM的卓越表现。

    

    无监督学习的最新进展突出了仅从噪声和不完整的线性测量中学习信号重构的可能性。这些方法在医学和科学成像以及传感中起到关键作用，其中地面真实数据经常稀缺或难以获得。然而，在实践中，测量不仅噪声和不完整，而且还被量化。在这里，我们探索从二进制观察中学习的极端情况，并提供了关于从不完整二进制数据中识别一组信号所需的测量数量的必要和充分条件。我们的结果是对从二进制测量中信号恢复现有界限的补充。此外，我们引入了一种新颖的自监督学习方法，我们将其命名为“SSBM”，它仅需要二进制数据进行训练。我们在一系列真实数据集上的实验证明SSBM与监督学习相当，并优于稀疏重构方法。

    Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
    
[^26]: EvoPrompting: 适用于代码级神经架构搜索的语言模型

    EvoPrompting: Language Models for Code-Level Neural Architecture Search. (arXiv:2302.14838v1 [cs.NE] CROSS LISTED)

    [http://arxiv.org/abs/2302.14838](http://arxiv.org/abs/2302.14838)

    EvoPrompting利用语言模型作为自适应变异和交叉操作符来进行神经架构搜索，在MNIST-1D数据集和CLRS算法推理基准上都取得了比人类设计的架构更好的性能表现。

    

    鉴于语言模型（LM）在代码生成方面的最新成就，我们探索将LM作为进化神经架构搜索（NAS）算法的自适应变异和交叉操作符的使用。尽管NAS仍然过于困难，以至于仅仅通过提示就难以成功，但我们发现进化提示工程与软提示调整的组合，一种我们称之为EvoPrompting的方法，始终可以发现多样化且性能高的模型。我们首先证明EvoPrompting在MNIST-1D数据集上是有效的，其中EvoPrompting产生的卷积架构变体在准确率和模型大小方面均优于人类专家设计的架构和天真的少数先导提示。然后，我们将我们的方法应用于在CLRS算法推理基准上搜索图神经网络，其中EvoPrompting能够设计出比当前最先进的模型更好的新颖结构。

    Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 ou
    
[^27]: ForkMerge: 缓解辅助任务学习中的负迁移

    ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning. (arXiv:2301.12618v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12618](http://arxiv.org/abs/2301.12618)

    ForkMerge是一种新方法，它帮助缓解了辅助任务学习中的负迁移问题，并在多任务学习中表现出良好的性能优于现有的ATL方法。

    

    辅助任务学习（ATL）旨在通过利用与目标任务相关的知识来提高目标任务的性能。然而，有时同时学习多个任务会导致比仅学习目标任务的准确率更低，这被称为负迁移。这个问题通常归因于任务之间的梯度冲突，并且在以前的工作中常常通过协调任务梯度来解决。然而，这些基于优化的方法在很大程度上忽略了辅助目标泛化能力。为了更好地理解负迁移的根本原因，我们从优化和泛化角度进行了实验研究。基于我们的研究发现，我们引入了ForkMerge，一种新方法，它会定期将模型分为多个分支，通过最小化目标验证错误自动搜索不同的任务权重，并动态地合并所有分支来过滤有害的任务参数更新。在一系列基准任务中，ForkMerge优于现有的ATL方法，并减轻了负迁移，证明其在提高多任务学习方面的有效性。

    Auxiliary-Task Learning (ATL) aims to improve the performance of the target task by leveraging the knowledge obtained from related tasks. Occasionally, learning multiple tasks simultaneously results in lower accuracy than learning only the target task, which is known as negative transfer. This problem is often attributed to the gradient conflicts among tasks, and is frequently tackled by coordinating the task gradients in previous works. However, these optimization-based methods largely overlook the auxiliary-target generalization capability. To better understand the root cause of negative transfer, we experimentally investigate it from both optimization and generalization perspectives. Based on our findings, we introduce ForkMerge, a novel approach that periodically forks the model into multiple branches, automatically searches the varying task weights by minimizing target validation errors, and dynamically merges all branches to filter out detrimental task-parameter updates. On a ser
    
[^28]: Spectral2Spectral: 无参考的图像光谱相似性辅助光谱CT深度重建

    Spectral2Spectral: Image-spectral Similarity Assisted Spectral CT Deep Reconstruction without Reference. (arXiv:2210.01125v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2210.01125](http://arxiv.org/abs/2210.01125)

    本文提出了一种名为Spectral2Spectral的深度重建网络，它利用图像-光谱领域内的相似性先验通过无参考方式来辅助光谱CT的深度重建。

    

    基于光子计数探测器（PCD）的光谱计算机断层扫描（CT）吸引了越来越多的关注，因为它能够为生物医学材料提供更准确的识别和定量分析。狭窄能量区间内有限的光子数量导致图像结果的信噪比较低。针对这些挑战，现有的CT重建的监督式深度重建网络很难解决，因为通常无法获取带有清晰结构的无噪声临床图像作为参考。本文提出了一种迭代深度重建网络，将无监督方法和数据先验相结合，命名为Spectral2Spectral。我们的Spectral2Spectral采用无监督的深度训练策略，在端到端的方式中从噪声数据中获得高质量图像。图像-光谱领域内的结构相似性先验被改进为正则化项，进一步约束网络。

    Spectral computed tomography based on a photon-counting detector (PCD) attracts more and more attentions since it has the capability to provide more accurate identification and quantitative analysis for biomedical materials. The limited number of photons within narrow energy bins leads to imaging results of low signal-noise ratio. The existing supervised deep reconstruction networks for CT reconstruction are difficult to address these challenges because it is usually impossible to acquire noise-free clinical images with clear structures as references. In this paper, we propose an iterative deep reconstruction network to synergize unsupervised method and data priors into a unified framework, named as Spectral2Spectral. Our Spectral2Spectral employs an unsupervised deep training strategy to obtain high-quality images from noisy data in an end-to-end fashion. The structural similarity prior within image-spectral domain is refined as a regularization term to further constrain the network t
    
[^29]: 基于最小描述长度和结构稳定性的脉冲神经网络的泛化研究

    On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability. (arXiv:2207.04876v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.04876](http://arxiv.org/abs/2207.04876)

    本研究通过利用最小描述长度原则和结构稳定性为脉冲神经网络提供了一个明确的泛化界限，并指定了最大稳定分歧解数的下限和上限。

    

    过去几十年中，由于其对于建模时间相关数据的潜力，脉冲神经网络引起了越来越多的关注。许多经验算法和技术已经被开发出来。然而，从理论上讲，训练后的脉冲神经网络在未见数据上的表现仍然是未知的。本研究通过利用最小描述长度原则，为脉冲神经网络提供一个明确的泛化界限。此外，我们通过结构稳定性实施了SNN的描述长度，并指定了最大稳定分歧解数的下限和上限，将在SNN中确定结构稳定性的挑战转化为一个具有定量特性的数学问题。

    The past decades have witnessed an increasing interest in spiking neural networks due to their great potential of modeling time-dependent data. Many empirical algorithms and techniques have been developed. However, theoretically, it remains unknown whether and to what extent a trained spiking neural network performs well on unseen data. This work takes one step in this direction by exploiting the minimum description length principle and thus, presents an explicit generalization bound for spiking neural networks. Further, we implement the description length of SNNs through structural stability and specify the lower and upper bounds of the maximum number of stable bifurcation solutions, which convert the challenge of qualifying structural stability in SNNs into a mathematical problem with quantitative properties.
    
[^30]: 有下层压缩的双层优化: 无warm-start情况下最优样本复杂度分析

    Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-Start. (arXiv:2202.03397v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2202.03397](http://arxiv.org/abs/2202.03397)

    本文针对一类双层问题，提出了无需warm-start也可实现最优样本复杂度的方法。

    

    本文分析了一类一般的双层问题，其中上层问题是将一光滑目标函数最小化，下层问题是寻找一光滑收缩映射的不动点。这类问题包括元学习、均衡模型、超参数优化和数据污染对抗攻击的实例。我们展示了，即使没有warm-start，在某些情况下，如元学习和均衡模型，仍然可以实现顺序最优的样本复杂度。

    We analyse a general class of bilevel problems, in which the upper-level problem consists in the minimization of a smooth objective function and the lower-level problem is to find the fixed point of a smooth contraction map. This type of problems include instances of meta-learning, equilibrium models, hyperparameter optimization and data poisoning adversarial attacks. Several recent works have proposed algorithms which warm-start the lower-level problem, i.e. they use the previous lower-level approximate solution as a staring point for the lower-level solver. This warm-start procedure allows one to improve the sample complexity in both the stochastic and deterministic settings, achieving in some cases the order-wise optimal sample complexity. However, there are situations, e.g., meta learning and equilibrium models, in which the warm-start procedure is not well-suited or ineffective. In this work we show that without warm-start, it is still possible to achieve order-wise (near) optimal
    

