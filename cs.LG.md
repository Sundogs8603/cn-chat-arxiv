# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Trust, but Verify: Robust Image Segmentation using Deep Learning.](http://arxiv.org/abs/2310.16999) | 本文描述了一种使用“信任，但要验证”方法进行深度学习图像分割的方法，通过辅助验证网络对分割进行预测，以此来验证深度神经网络的输出。这种方法对多种扰动具有鲁棒性，可以应对对抗性攻击，并且不依赖于黑盒神经网络来检测错误的分割。 |
| [^2] | [Online RL in Linearly $q^\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore.](http://arxiv.org/abs/2310.07811) | 该论文研究了在线强化学习中在线性$q^\pi$可实现的MDPs和线性MDPs的差异，并提出了一种新颖的学习算法，可以通过学习忽略某些状态将问题转化为线性MDP。 |
| [^3] | [Comparing the robustness of modern no-reference image- and video-quality metrics to adversarial attacks.](http://arxiv.org/abs/2310.06958) | 本文比较了现代图像和视频质量评估度量方法对抗攻击的鲁棒性，并发现部分度量方法对对抗攻击表现出较高的抵抗力，为基准测试提供了更安全的选择。 |
| [^4] | [A Framework for Interpretability in Machine Learning for Medical Imaging.](http://arxiv.org/abs/2310.01685) | 本文提出了一个机器学习在医学影像中的可解释性框架，明确了解释性的目标和要素，以指导方法设计并改进实际应用。 |
| [^5] | [MAPTree: Beating "Optimal" Decision Trees with Bayesian Decision Trees.](http://arxiv.org/abs/2309.15312) | MAPTree是一种通过贝叶斯方法对决策树进行归纳的算法，通过AND/OR搜索实现最大后验树的恢复。在实验中，MAPTree在多个数据集上表现出更好的性能，并且能够以更小的树来实现可比较的性能。在合成数据和实际场景中，MAPTree还展示出更强的抗噪声能力和更好的泛化能力。 |
| [^6] | [USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained Foundation Models.](http://arxiv.org/abs/2309.08023) | USM-SCD是一种基于大型预训练基础模型的多语种演讲者转换检测模型，通过微调模型参数，可以同时检测演讲者转换并为96种语言执行自动语音识别。在实验中表现出了优异的性能。 |
| [^7] | [Data-Juicer: A One-Stop Data Processing System for Large Language Models.](http://arxiv.org/abs/2309.02033) | Data-Juicer是一个为大型语言模型提供一站式数据处理系统，可以生成多样的数据配方，探索不同的数据混合方式，并评估它们对模型性能的影响。 |
| [^8] | [In-context learning for model-free system identification.](http://arxiv.org/abs/2308.13380) | 本文提出了一种基于上下文学习的无模型系统辨识方法，通过观察同一类别中其他系统的行为来理解动态系统的复杂性。 |
| [^9] | [PMET: Precise Model Editing in a Transformer.](http://arxiv.org/abs/2308.08742) | 该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。 |
| [^10] | [Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems.](http://arxiv.org/abs/2308.08511) | 提出了一种两个半顺序基于得分的模型（TOSM），用于解决CT和MRI中的三维体重建问题。通过在二维空间中学习数据分布来减少训练的复杂性，然后在三维空间中更新数据分布以实现准确的三维重建。 |
| [^11] | [DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting.](http://arxiv.org/abs/2308.08198) | DeSCo是一个通用且可扩展的深度子图计数方法，它解决了现有神经计数方法在计数准确性、图形区分和出现位置预测方面存在的问题。 |
| [^12] | [ADR-GNN: Advection-Diffusion-Reaction Graph Neural Networks.](http://arxiv.org/abs/2307.16092) | 本文提出了ADR-GNN，一种基于平流-扩散-反应系统的图神经网络架构。ADR-GNN在涉及平流的复杂现象建模方面具有优势，并在节点分类和时空数据集上显示出与最先进网络相比的改进或竞争性表现。 |
| [^13] | [Bootstrapping Vision-Language Learning with Decoupled Language Pre-training.](http://arxiv.org/abs/2307.07063) | 本文提出了一种新的方法，通过解耦语言预训练，集中在语言组件上，提供了优化应用大型语言模型的框架，有效改善了视觉语言学习的性能。 |
| [^14] | [Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning.](http://arxiv.org/abs/2307.05209) | 我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。 |
| [^15] | [GloptiNets: Scalable Non-Convex Optimization with Certificates.](http://arxiv.org/abs/2306.14932) | GloptiNets是一种新方法，可以处理具有证明的非凸优化问题，通过利用目标函数的正则性和并行计算的优势，取得了比现有方法更好的性能。 |
| [^16] | [Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes.](http://arxiv.org/abs/2306.12045) | 本研究提出 TeCoS-LVM 模型，使用脉冲神经元以模拟自然视觉刺激的神经响应。该模型能够自适应地探索和利用刺激序列中的时间依赖关系，避免丢失脉冲列中的信息。 |
| [^17] | [A Dynamical Graph Prior for Relational Inference.](http://arxiv.org/abs/2306.06041) | DYGR是一种用于关系推断的动态图先验方法，它利用高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度，并能够同时适用于具有共享图拓扑的“浅层”一步模型。 |
| [^18] | [Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity Prediction.](http://arxiv.org/abs/2306.04886) | 本文提出一种多任务生物测定预训练框架（MBP）用于基于结构的蛋白质-配体结合亲和力预测，通过构建一个预训练数据集ChEMBL-Dock，解决了高质量训练数据稀缺以及不同标签和实验条件导致的噪声问题。 |
| [^19] | [Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning.](http://arxiv.org/abs/2306.03625) | 本文提出了一种公平且健壮的异质治疗效果的估计框架，可以在公平约束下非参数地估计，并可用于权衡公平和最大福利之间的关系。 |
| [^20] | [Learning to Simulate Tree-Branch Dynamics for Manipulation.](http://arxiv.org/abs/2306.03410) | 本论文提出了一种仿真驱动的逆推理方法来学习树枝动态，并可以操纵可变形的植被，以解决密集植被中容易遮挡的任务，算法结合了生物学上的假设和传统参数推理方法的有限差分方案。 |
| [^21] | [Covariance Adaptive Best Arm Identification.](http://arxiv.org/abs/2306.02630) | 本文提出了一个协方差自适应的最佳臂识别问题，相较于独立臂分布假设下的解决方案，能更有效地识别出高平均奖励的臂，适用于临床试验等场景。 |
| [^22] | [Self Contrastive Learning for Session-based Recommendation.](http://arxiv.org/abs/2306.01266) | 本文提出了自对比学习方法，简化了会话推荐领域基于对比学习的模型的复杂性，并提高了推荐性能。 |
| [^23] | [MADiff: Offline Multi-agent Learning with Diffusion Models.](http://arxiv.org/abs/2305.17330) | 本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。 |
| [^24] | [PiML Toolbox for Interpretable Machine Learning Model Development and Validation.](http://arxiv.org/abs/2305.04214) | PiML工具箱是一个综合的Python工具箱，可用于开发和诊断可解释机器学习模型，包括日益增长的可解释模型、模型无关的可解释性工具和模型无关的诊断工具，还支持与MLOps平台的集成和质量保证。 |
| [^25] | [LAVA: Data Valuation without Pre-Specified Learning Algorithms.](http://arxiv.org/abs/2305.00054) | LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。 |
| [^26] | [Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information.](http://arxiv.org/abs/2304.13646) | 本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。 |
| [^27] | [Exponentially Improved Efficient Machine Learning for Quantum Many-body States with Provable Guarantees.](http://arxiv.org/abs/2304.04353) | 通过机器学习协议预测量子多体系统的基态及其性质，其精度为 $\varepsilon$，并具有可证明的保障；但对于普遍的能隙哈密顿量，样本个数 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，只适用于参数空间维度较大，且精度不是紧迫因素，无法进入更精确的学习和预测领域。 |
| [^28] | [RED-PSM: Regularization by Denoising of Partially Separable Models for Dynamic Imaging.](http://arxiv.org/abs/2304.03483) | 本文提出了一种称为RED-PSM的方法，将部分可分模型与去噪正则化相结合，用于解决动态成像问题，数值实验证明其优越性。 |
| [^29] | [Hard Regularization to Prevent Collapse in Online Deep Clustering without Data Augmentation.](http://arxiv.org/abs/2303.16521) | 该论文提出了一种不需要数据增强的在线深度聚类方法，通过加强正则化来避免崩溃，相比于其他方法，具有更高的稳定性。 |
| [^30] | [Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation.](http://arxiv.org/abs/2303.15413) | 本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。 |
| [^31] | [Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks.](http://arxiv.org/abs/2303.00196) | 这项研究首次通过推导泛化误差上界回答了转换的低秩参数化如何影响张量神经网络的学习行为，结果显示通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。 |
| [^32] | [Non-contact Respiratory Anomaly Detection using Infrared Light-wave Sensing.](http://arxiv.org/abs/2301.03713) | 本研究使用无接触红外光波传感技术，通过训练不同类型的呼吸模式来检测呼吸异常，并且通过验证数据的呼吸波形丢弃干扰数据，以实现安全、高效和无创的人体呼吸监测。 |
| [^33] | [Dual Accuracy-Quality-Driven Neural Network for Prediction Interval Generation.](http://arxiv.org/abs/2212.06370) | 本文提出了一种双重精度质量驱动的神经网络，可以自动地学习基于回归的神经网络的预测区间，而非只提供传统的目标估计。该方法通过设计一种新颖的损失函数，最小化平均预测区间宽度以及提高覆盖概率来提高PI的质量和精度，且比最先进的方法更加具有计算效率。 |
| [^34] | [Fake detection in imbalance dataset by Semi-supervised learning with GAN.](http://arxiv.org/abs/2212.01071) | 本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。 |
| [^35] | [Differentiable Uncalibrated Imaging.](http://arxiv.org/abs/2211.10525) | 本文提出了一种可微的成像框架，以解决测量坐标的不确定性，通过隐式神经网络和可微分样条插值器实现。该方法应用于2D和3D计算机断层扫描，产生了改进的重建结果。 |
| [^36] | [Multipoint-BAX: A New Approach for Efficiently Tuning Particle Accelerator Emittance via Virtual Objectives.](http://arxiv.org/abs/2209.04587) | 本论文提出了一种名为多点-BAX的新方法，通过虚拟目标来高效调整粒子加速器的发射度。该方法避免了使用传统的黑盒优化器进行缓慢而低效的多点查询，并通过快速学习模型计算发射度目标。该方法在Linac相干光源(LCLS)和Facility for Adv中最小化发射度。 |
| [^37] | [Analysis of Dual-Based PID Controllers through Convolutional Mirror Descent.](http://arxiv.org/abs/2202.06152) | 本文提供了基于双基础PID控制器性能的遗憾界限，并建立了双基础PID控制器与在线凸优化算法CMD之间的联系。 |

# 详细

[^1]: 信任，但要验证：使用深度学习进行鲁棒图像分割

    Trust, but Verify: Robust Image Segmentation using Deep Learning. (arXiv:2310.16999v1 [cs.CV])

    [http://arxiv.org/abs/2310.16999](http://arxiv.org/abs/2310.16999)

    本文描述了一种使用“信任，但要验证”方法进行深度学习图像分割的方法，通过辅助验证网络对分割进行预测，以此来验证深度神经网络的输出。这种方法对多种扰动具有鲁棒性，可以应对对抗性攻击，并且不依赖于黑盒神经网络来检测错误的分割。

    

    我们描述了一种用于验证深度神经网络在医学图像分割中的输出的方法，该方法对于多种类型的随机和最坏情况的扰动具有鲁棒性，即对抗性攻击。该方法基于作者最近提出的一种称为“信任，但要验证”的通用方法，其中辅助验证网络使用分割作为输入来对输入图像中的某些被遮蔽特征进行预测。设计良好的辅助网络将在输入分割准确时生成高质量的预测，但在分割不正确时生成低质量的预测。通过将这个网络的预测与原始图像进行检查，我们可以检测出错误的分割。然而，为了确保验证方法真正鲁棒，我们需要一种不依赖于黑盒神经网络的方法来检查预测的质量。事实上，我们展示了先前用于分割评估的方法无法应对鲁棒的情况。

    We describe a method for verifying the output of a deep neural network for medical image segmentation that is robust to several classes of random as well as worst-case perturbations i.e. adversarial attacks. This method is based on a general approach recently developed by the authors called ``Trust, but Verify" wherein an auxiliary verification network produces predictions about certain masked features in the input image using the segmentation as an input. A well-designed auxiliary network will produce high-quality predictions when the input segmentations are accurate, but will produce low-quality predictions when the segmentations are incorrect. Checking the predictions of such a network with the original image allows us to detect bad segmentations. However, to ensure the verification method is truly robust, we need a method for checking the quality of the predictions that does not itself rely on a black-box neural network. Indeed, we show that previous methods for segmentation evalua
    
[^2]: 在线RL在线性$q^\pi$可实现的MDPs中和线性MDPs一样容易，只要你学会忽略。 (arXiv:2310.07811v1 [cs.LG])

    Online RL in Linearly $q^\pi$-Realizable MDPs Is as Easy as in Linear MDPs If You Learn What to Ignore. (arXiv:2310.07811v1 [cs.LG])

    [http://arxiv.org/abs/2310.07811](http://arxiv.org/abs/2310.07811)

    该论文研究了在线强化学习中在线性$q^\pi$可实现的MDPs和线性MDPs的差异，并提出了一种新颖的学习算法，可以通过学习忽略某些状态将问题转化为线性MDP。

    

    我们考虑在线强化学习（RL）在离散的马尔可夫决策过程（MDPs）中，在线性$q^\pi$可实现的假设下，假设所有策略的动作值可以表示为状态-动作特征的线性函数。这个类别被认为比线性MDPs更一般化，其中转移内核和奖励函数被假设为特征向量的线性函数。我们的第一个贡献是展示了这两个类别之间的差异是在线性$q^\pi$可实现的MDPs中存在一些状态，在这些状态中，对于任何策略，所有的动作值都近似相等，通过跳过这些状态并按照任意固定策略在这些状态中进行转换，我们可以将问题转化为线性MDP。基于这个观察，我们推导了一种新颖（计算效率较低）的学习算法，用于在线性$q^\pi$可实现的MDPs中，该算法同时学习了应该跳过的状态，并运行另一个学习算法。

    We consider online reinforcement learning (RL) in episodic Markov decision processes (MDPs) under the linear $q^\pi$-realizability assumption, where it is assumed that the action-values of all policies can be expressed as linear functions of state-action features. This class is known to be more general than linear MDPs, where the transition kernel and the reward function are assumed to be linear functions of the feature vectors. As our first contribution, we show that the difference between the two classes is the presence of states in linearly $q^\pi$-realizable MDPs where for any policy, all the actions have approximately equal values, and skipping over these states by following an arbitrarily fixed policy in those states transforms the problem to a linear MDP. Based on this observation, we derive a novel (computationally inefficient) learning algorithm for linearly $q^\pi$-realizable MDPs that simultaneously learns what states should be skipped over and runs another learning algorith
    
[^3]: 比较现代无参考图像和视频质量评估度量方法对对抗攻击的鲁棒性

    Comparing the robustness of modern no-reference image- and video-quality metrics to adversarial attacks. (arXiv:2310.06958v1 [cs.CV])

    [http://arxiv.org/abs/2310.06958](http://arxiv.org/abs/2310.06958)

    本文比较了现代图像和视频质量评估度量方法对抗攻击的鲁棒性，并发现部分度量方法对对抗攻击表现出较高的抵抗力，为基准测试提供了更安全的选择。

    

    如今，基于神经网络的图像和视频质量评估度量方法相比传统方法表现更好。然而，它们也变得更容易受到对抗性攻击，这些攻击可以提高度量分数但不改善视觉质量。现有的质量度量基准将其性能与主观质量相关性和计算时间进行比较。然而，图像质量度量的对抗鲁棒性也是一个值得研究的领域。本文分析了现代度量方法对不同对抗攻击的鲁棒性。我们采用了计算机视觉任务中的对抗攻击，并比较了这些攻击对15个无参考图像/视频质量度量方法的效果。一些度量方法对对抗攻击表现出了较高的抵抗力，使它们在基准测试中的使用比容易受攻击的方法更安全。该基准测试接受研究人员提交新的度量方法，以使他们的方法对攻击更加鲁棒，或者为他们寻找符合需求的鲁棒度量方法。

    Nowadays neural-network-based image- and video-quality metrics show better performance compared to traditional methods. However, they also became more vulnerable to adversarial attacks that increase metrics' scores without improving visual quality. The existing benchmarks of quality metrics compare their performance in terms of correlation with subjective quality and calculation time. However, the adversarial robustness of image-quality metrics is also an area worth researching. In this paper, we analyse modern metrics' robustness to different adversarial attacks. We adopted adversarial attacks from computer vision tasks and compared attacks' efficiency against 15 no-reference image/video-quality metrics. Some metrics showed high resistance to adversarial attacks which makes their usage in benchmarks safer than vulnerable metrics. The benchmark accepts new metrics submissions for researchers who want to make their metrics more robust to attacks or to find such metrics for their needs. 
    
[^4]: 机器学习在医学影像中的可解释性框架

    A Framework for Interpretability in Machine Learning for Medical Imaging. (arXiv:2310.01685v1 [cs.LG])

    [http://arxiv.org/abs/2310.01685](http://arxiv.org/abs/2310.01685)

    本文提出了一个机器学习在医学影像中的可解释性框架，明确了解释性的目标和要素，以指导方法设计并改进实际应用。

    

    机器学习在医学影像中的可解释性是一个重要的研究方向。然而，对于可解释性的定义存在一种普遍的模糊感。为什么需要在医学影像中的机器学习中解释性？当需要解释性时，实际上追求的目标是什么？为了回答这些问题，我们确定了在医学影像中的机器学习可解释性的目标和要素需要形式化。通过对医学图像分析和机器学习的交叉点中常见的实际任务和目标进行推理，我们确定了四个核心要素：定位、视觉可识别性、物理归因和透明度。总的来说，本文在医学影像的背景下系统化了可解释性的需求，我们的实践观点澄清了具体的医学影像机器学习可解释性目标和考虑因素，以指导方法设计并改进实际应用。我们的目标是为模型设计提供实用和教学信息。

    Interpretability for machine learning models in medical imaging (MLMI) is an important direction of research. However, there is a general sense of murkiness in what interpretability means. Why does the need for interpretability in MLMI arise? What goals does one actually seek to address when interpretability is needed? To answer these questions, we identify a need to formalize the goals and elements of interpretability in MLMI. By reasoning about real-world tasks and goals common in both medical image analysis and its intersection with machine learning, we identify four core elements of interpretability: localization, visual recognizability, physical attribution, and transparency. Overall, this paper formalizes interpretability needs in the context of medical imaging, and our applied perspective clarifies concrete MLMI-specific goals and considerations in order to guide method design and improve real-world usage. Our goal is to provide practical and didactic information for model desig
    
[^5]: MAPTree: 用贝叶斯决策树击败“最优”决策树

    MAPTree: Beating "Optimal" Decision Trees with Bayesian Decision Trees. (arXiv:2309.15312v1 [cs.LG])

    [http://arxiv.org/abs/2309.15312](http://arxiv.org/abs/2309.15312)

    MAPTree是一种通过贝叶斯方法对决策树进行归纳的算法，通过AND/OR搜索实现最大后验树的恢复。在实验中，MAPTree在多个数据集上表现出更好的性能，并且能够以更小的树来实现可比较的性能。在合成数据和实际场景中，MAPTree还展示出更强的抗噪声能力和更好的泛化能力。

    

    决策树仍然是当今最流行的机器学习模型之一，主要是因为其开箱即用的性能和可解释性。在这项工作中，我们通过对树上的后验分布进行最大后验推理，提出了一种贝叶斯决策树归纳的方法。我们首先展示了决策树的最大后验推理与AND/OR搜索之间的关联。利用这一关联，我们提出了一种称为MAPTree的AND/OR搜索算法，能够恢复出最大后验树。最后，我们通过在合成数据和实际世界场景中展示最大后验树的经验性能。在16个实际数据集上，MAPTree要么优于基准线，要么在性能相当的情况下具有更小的树。在一个合成数据集上，MAPTree表现出比现有方法更强的抗噪声能力和更好的泛化能力。最后，MAPTree比其他方法更快地恢复出最大后验树。

    Decision trees remain one of the most popular machine learning models today, largely due to their out-of-the-box performance and interpretability. In this work, we present a Bayesian approach to decision tree induction via maximum a posteriori inference of a posterior distribution over trees. We first demonstrate a connection between maximum a posteriori inference of decision trees and AND/OR search. Using this connection, we propose an AND/OR search algorithm, dubbed MAPTree, which is able to recover the maximum a posteriori tree. Lastly, we demonstrate the empirical performance of the maximum a posteriori tree both on synthetic data and in real world settings. On 16 real world datasets, MAPTree either outperforms baselines or demonstrates comparable performance but with much smaller trees. On a synthetic dataset, MAPTree also demonstrates greater robustness to noise and better generalization than existing approaches. Finally, MAPTree recovers the maxiumum a posteriori tree faster tha
    
[^6]: 基于大型预训练基础模型的多语种演讲者转换检测模型（USM-SCD）

    USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained Foundation Models. (arXiv:2309.08023v1 [eess.AS])

    [http://arxiv.org/abs/2309.08023](http://arxiv.org/abs/2309.08023)

    USM-SCD是一种基于大型预训练基础模型的多语种演讲者转换检测模型，通过微调模型参数，可以同时检测演讲者转换并为96种语言执行自动语音识别。在实验中表现出了优异的性能。

    

    我们提出了一种多语种演讲者转换检测模型（USM-SCD），可以同时检测演讲者转换并为96种语言执行自动语音识别。该模型是从一个经过大量受监督和无监督数据训练的语音基础模型进行调整而来的，展示了从大型通用基础模型到下游任务的微调的实用性。通过一系列消融研究，我们分析了这个多语种演讲者转换检测模型的性能。我们展示了USM-SCD模型可以在由来自96种语言的数据构成的测试集上实现超过75%的平均演讲者转换检测F1得分。在美式英语上，USM-SCD模型可以在各种公共和内部测试集上实现85.8%的演讲者转换检测F1得分，相对于之前的单语言基准模型提高了21%。我们还展示了只需要微调可训练模型参数的四分之一就可以实现最佳模型性能。

    We introduce a multilingual speaker change detection model (USM-SCD) that can simultaneously detect speaker turns and perform ASR for 96 languages. This model is adapted from a speech foundation model trained on a large quantity of supervised and unsupervised data, demonstrating the utility of fine-tuning from a large generic foundation model for a downstream task. We analyze the performance of this multilingual speaker change detection model through a series of ablation studies. We show that the USM-SCD model can achieve more than 75% average speaker change detection F1 score across a test set that consists of data from 96 languages. On American English, the USM-SCD model can achieve an 85.8% speaker change detection F1 score across various public and internal test sets, beating the previous monolingual baseline model by 21% relative. We also show that we only need to fine-tune one-quarter of the trainable model parameters to achieve the best model performance. The USM-SCD model exhib
    
[^7]: Data-Juicer: 一个为大型语言模型提供一站式数据处理系统的论文

    Data-Juicer: A One-Stop Data Processing System for Large Language Models. (arXiv:2309.02033v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.02033](http://arxiv.org/abs/2309.02033)

    Data-Juicer是一个为大型语言模型提供一站式数据处理系统，可以生成多样的数据配方，探索不同的数据混合方式，并评估它们对模型性能的影响。

    

    大型语言模型的巨大发展凸显了大规模、异构和高质量数据的重要性。数据配方是用于训练大型语言模型的来自不同来源的数据混合物，对语言模型的性能起着至关重要的作用。现有的开源工具主要针对特定数据配方进行了定制。为了不断挖掘语言模型的潜力，引入来自新来源的数据，提高模型的性能，我们构建了一个名为Data-Juicer的新系统，这个系统可以高效地生成多样的数据配方，探索不同的数据混合方式，并评估它们对模型性能的影响。与传统的数据分析流程不同，Data-Juicer面临着一些独特的挑战。首先，用于生成数据配方的可能数据源是真正的异构和大规模的，具有不同的质量。其次，精确评估数据配方对语言模型性能的影响非常昂贵。

    The immense evolution in Large Language Models (LLMs) has underscored the importance of massive, heterogeneous, and high-quality data. A data recipe is a mixture of data from different sources for training LLMs, which plays a vital role in LLMs' performance. Existing open-source tools for LLM data processing are mostly tailored for specific data recipes. To continuously uncover the potential of LLMs, incorporate data from new sources, and improve LLMs' performance, we build a new system named Data-Juicer, with which we can efficiently generate diverse data recipes, explore different possibilities in forming data mixtures, and evaluate their effects on model performance. Different from traditional data-analytics pipelines, Data-Juicer faces some unique challenges. Firstly, the possible data sources for forming data recipes are truly heterogeneous and massive with various qualities. Secondly, it is extremely expensive to precisely evaluate data recipes' impact on LLMs' performance. Third
    
[^8]: 基于上下文学习的无模型系统辨识

    In-context learning for model-free system identification. (arXiv:2308.13380v1 [eess.SY])

    [http://arxiv.org/abs/2308.13380](http://arxiv.org/abs/2308.13380)

    本文提出了一种基于上下文学习的无模型系统辨识方法，通过观察同一类别中其他系统的行为来理解动态系统的复杂性。

    

    在传统的系统辨识中，我们通过给定的输入/输出序列和可用的物理知识来估计未知动态系统的模型。然而，是否还可以通过观察同一类别中其他系统的行为，而不仅仅是从它们的输入/输出模式中理解动态系统的复杂性呢？这个核心问题驱动着本文的研究。作为对这个问题的回应，我们引入了一种新的系统辨识范式，解决了两个主要任务：一步预测和多步模拟。与传统方法不同的是，我们不直接对特定系统进行模型估计，而是预先训练一个代表动态系统类别的元模型。该元模型是通过从某个分布中随机抽取的系统生成的潜在无限流的合成数据进行训练的。在其核心，元模型作为对主要特征的隐式表示，

    In traditional system identification, we estimate a model of an unknown dynamical system based on given input/output sequences and available physical knowledge. Yet, is it also possible to understand the intricacies of dynamical systems not solely from their input/output patterns, but by observing the behavior of other systems within the same class? This central question drives the study presented in this paper.  In response to this query, we introduce a novel paradigm for system identification, addressing two primary tasks: one-step-ahead prediction and multi-step simulation. Unlike conventional methods, we do not directly estimate a model for the specific system. Instead, we pretrain a meta model that represents a class of dynamical systems. This meta model is trained from a potentially infinite stream of synthetic data, generated by systems randomly extracted from a certain distribution. At its core, the meta model serves as an implicit representation of the main characteristics of 
    
[^9]: PMET: 在Transformer中的精确模型编辑

    PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])

    [http://arxiv.org/abs/2308.08742](http://arxiv.org/abs/2308.08742)

    该论文通过分析Transformer模型中的隐藏状态，发现多头自注意力编码了某些通用知识提取模式，因此在进行模型编辑时，不需要更新多头自注意力的权重。

    

    模型编辑技术可以以较低的成本修改大型语言模型中的少量知识，并且已经取得了显著的成功。现有方法假设Transformer层隐藏状态是前馈网络的键值内存的值。它们通常优化Transformer层隐藏状态来记忆目标知识，并将其用于更新大型语言模型中前馈网络的权重。然而，Transformer层隐藏状态的信息流来自三个部分：多头自注意力、前馈网络和残差连接。现有方法忽视了Transformer层隐藏状态包含了前馈网络特别需要的信息这一事实。因此，模型编辑的性能下降。为了实现更精确的模型编辑，我们分析了多头自注意力和前馈网络的隐藏状态，发现多头自注意力编码了某些通用知识提取模式。这意味着当引入新知识时，多头自注意力的权重不需要更新。

    Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
    
[^10]: 两个半顺序基于得分的模型用于解决三维不适定反问题

    Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems. (arXiv:2308.08511v1 [eess.IV])

    [http://arxiv.org/abs/2308.08511](http://arxiv.org/abs/2308.08511)

    提出了一种两个半顺序基于得分的模型（TOSM），用于解决CT和MRI中的三维体重建问题。通过在二维空间中学习数据分布来减少训练的复杂性，然后在三维空间中更新数据分布以实现准确的三维重建。

    

    计算机断层扫描（CT）和磁共振成像（MRI）是医学成像领域至关重要的技术。基于得分的模型已经被证明在解决CT和MRI中遇到的不同反问题（如稀疏视野CT和快速MRI重建）方面是有效的。然而，这些模型在实现精确的三维体重建方面面临挑战。现有的基于得分的模型主要关注重建二维数据分布，在重建的三维体积图像中导致相邻切片之间的不一致性。为了克服这一限制，我们提出了一种新颖的两个半顺序基于得分的模型（TOSM）。在训练阶段，我们的TOSM在二维空间中学习数据分布，相较于直接在三维体积上工作，减少了训练的复杂性。然而，在重建阶段，TOSM会在三维空间中更新数据分布，利用三个方向的互补得分（sag）

    Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial technologies in the field of medical imaging. Score-based models have proven to be effective in addressing different inverse problems encountered in CT and MRI, such as sparse-view CT and fast MRI reconstruction. However, these models face challenges in achieving accurate three dimensional (3D) volumetric reconstruction. The existing score-based models primarily focus on reconstructing two dimensional (2D) data distribution, leading to inconsistencies between adjacent slices in the reconstructed 3D volumetric images. To overcome this limitation, we propose a novel two-and-a-half order score-based model (TOSM). During the training phase, our TOSM learns data distributions in 2D space, which reduces the complexity of training compared to directly working on 3D volumes. However, in the reconstruction phase, the TOSM updates the data distribution in 3D space, utilizing complementary scores along three directions (sag
    
[^11]: DeSCo:面向通用且可扩展的深度子图计数方法

    DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting. (arXiv:2308.08198v1 [cs.LG])

    [http://arxiv.org/abs/2308.08198](http://arxiv.org/abs/2308.08198)

    DeSCo是一个通用且可扩展的深度子图计数方法，它解决了现有神经计数方法在计数准确性、图形区分和出现位置预测方面存在的问题。

    

    子图计数是在大型目标图中计算给定查询图的出现次数的问题。大规模的子图计数在各个领域中都很有用，比如社交网络分析中的图案计数和交易网络上的反洗钱检测中的循环计数。最近，为了解决可扩展子图计数的指数级运行时间复杂度，提出了神经方法。然而，现有的神经计数方法在三个方面存在不足。首先，相同查询的计数在不同目标图上可以从零到数百万，比大多数图回归任务都要困难得多。其次，目前的可扩展图神经网络具有有限的表达能力，无法高效地区分计数预测中的图形。此外，现有的神经方法无法预测查询在目标图中的出现位置。在这里，我们设计了DeSCo，这是一个可扩展的神经深度子图计数流水线，旨在准确地预测子图的计数和出现位置。

    Subgraph counting is the problem of counting the occurrences of a given query graph in a large target graph. Large-scale subgraph counting is useful in various domains, such as motif counting for social network analysis and loop counting for money laundering detection on transaction networks. Recently, to address the exponential runtime complexity of scalable subgraph counting, neural methods are proposed. However, existing neural counting approaches fall short in three aspects. Firstly, the counts of the same query can vary from zero to millions on different target graphs, posing a much larger challenge than most graph regression tasks. Secondly, current scalable graph neural networks have limited expressive power and fail to efficiently distinguish graphs in count prediction. Furthermore, existing neural approaches cannot predict the occurrence position of queries in the target graph.  Here we design DeSCo, a scalable neural deep subgraph counting pipeline, which aims to accurately p
    
[^12]: ADR-GNN：平流-扩散-反应图神经网络

    ADR-GNN: Advection-Diffusion-Reaction Graph Neural Networks. (arXiv:2307.16092v1 [cs.LG])

    [http://arxiv.org/abs/2307.16092](http://arxiv.org/abs/2307.16092)

    本文提出了ADR-GNN，一种基于平流-扩散-反应系统的图神经网络架构。ADR-GNN在涉及平流的复杂现象建模方面具有优势，并在节点分类和时空数据集上显示出与最先进网络相比的改进或竞争性表现。

    

    图神经网络在学习图结构数据表示方面取得了显著的成功。然而，GNN在建模涉及平流的复杂现象方面仍面临挑战。本文提出了一种基于平流-扩散-反应系统的新型GNN架构，称为ADR-GNN。平流模式化了信息的有向传输，扩散捕捉了信息的局部平滑，反应代表了通道中信息的非线性转换。我们对ADR-GNN的定性行为进行了分析，显示了将平流、扩散和反应结合的好处。为了证明其有效性，我们在真实世界的节点分类和时空数据集上评估了ADR-GNN，并展示了它相对于最先进网络的改进或竞争性表现。

    Graph neural networks (GNNs) have shown remarkable success in learning representations for graph-structured data. However, GNNs still face challenges in modeling complex phenomena that involve advection. In this paper, we propose a novel GNN architecture based on Advection-Diffusion-Reaction systems, called ADR-GNN. Advection models the directed transportation of information, diffusion captures the local smoothing of information, and reaction represents the non-linear transformation of information in channels. We provide an analysis of the qualitative behavior of ADR-GNN, that shows the benefit of combining advection, diffusion, and reaction. To demonstrate its efficacy, we evaluate ADR-GNN on real-world node classification and spatio-temporal datasets, and show that it improves or offers competitive performance compared to state-of-the-art networks.
    
[^13]: 使用解耦的语言预训练为视觉语言学习引入引导策略

    Bootstrapping Vision-Language Learning with Decoupled Language Pre-training. (arXiv:2307.07063v1 [cs.CV])

    [http://arxiv.org/abs/2307.07063](http://arxiv.org/abs/2307.07063)

    本文提出了一种新的方法，通过解耦语言预训练，集中在语言组件上，提供了优化应用大型语言模型的框架，有效改善了视觉语言学习的性能。

    

    本论文提出了一种新颖的方法，旨在优化冻结的大型语言模型（LLMs）在资源密集型视觉语言（VL）预训练中的应用。当前的范式使用视觉特征作为提示来引导语言模型，重点是确定与相应文本最相关的视觉特征。我们的方法不同，集中在语言组件上，具体是确定与视觉特征对齐的最佳提示。我们引入了Prompt-Transformer（P-Former），一种可以预测这些理想提示的模型，该模型仅在语言数据上进行训练，避免了图像-文本配对的需要。这种策略将端到端的VL训练过程巧妙地分为了额外的独立阶段。我们的实验证明，我们的框架显著提高了稳健的图像到文本基线（BLIP-2）的性能，并有效地缩小了使用4M或129M图像-文本对进行训练的模型之间的性能差距。

    We present a novel methodology aimed at optimizing the application of frozen large language models (LLMs) for resource-intensive vision-language (VL) pre-training. The current paradigm uses visual features as prompts to guide language models, with a focus on determining the most relevant visual features for corresponding text. Our approach diverges by concentrating on the language component, specifically identifying the optimal prompts to align with visual features. We introduce the Prompt-Transformer (P-Former), a model that predicts these ideal prompts, which is trained exclusively on linguistic data, bypassing the need for image-text pairings. This strategy subtly bifurcates the end-to-end VL training process into an additional, separate stage. Our experiments reveal that our framework significantly enhances the performance of a robust image-to-text baseline (BLIP-2), and effectively narrows the performance gap between models trained with either 4M or 129M image-text pairs. Importan
    
[^14]: 强化学习中基于奖励机器抽象的上下文预规划以增强迁移学习

    Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning. (arXiv:2307.05209v1 [cs.AI])

    [http://arxiv.org/abs/2307.05209](http://arxiv.org/abs/2307.05209)

    我们提出了一种使用奖励机器抽象来表示当前任务，并在迁移学习中提升DRL代理的性能的方法，实验表明该方法能够提高样本效率并在多个领域中进行少样本迁移。

    

    最近的研究表明，深度强化学习（DRL）代理倾向于过拟合训练任务，并且无法适应轻微的环境变化。为了在转移到未见任务时加快学习，我们提出了一种使用奖励机器（RM）来表示当前任务的新方法，奖励机器是基于当前任务的奖励和动态生成子任务的状态机抽象。我们的方法为代理提供了当前抽象状态的符号表示，并奖励它们达成这些转换。这些表示在任务之间共享，使代理能够利用先前遇到的符号和转换的知识，从而增强迁移能力。我们的实证评估表明，我们的表示在各种领域中提高了样本效率和少样本迁移。

    Recent studies show that deep reinforcement learning (DRL) agents tend to overfit to the task on which they were trained and fail to adapt to minor environment changes. To expedite learning when transferring to unseen tasks, we propose a novel approach to representing the current task using reward machines (RM), state machine abstractions that induce subtasks based on the current task's rewards and dynamics. Our method provides agents with symbolic representations of optimal transitions from their current abstract state and rewards them for achieving these transitions. These representations are shared across tasks, allowing agents to exploit knowledge of previously encountered symbols and transitions, thus enhancing transfer. Our empirical evaluation shows that our representations improve sample efficiency and few-shot transfer in a variety of domains.
    
[^15]: GloptiNets：具有证明的可扩展非凸优化

    GloptiNets: Scalable Non-Convex Optimization with Certificates. (arXiv:2306.14932v1 [math.OC])

    [http://arxiv.org/abs/2306.14932](http://arxiv.org/abs/2306.14932)

    GloptiNets是一种新方法，可以处理具有证明的非凸优化问题，通过利用目标函数的正则性和并行计算的优势，取得了比现有方法更好的性能。

    

    我们提出了一种处理超立方体或环面上的光滑函数的具有证明的非凸优化的新方法。与依赖代数性质的传统方法不同，我们的算法利用了目标函数的正则性，该正则性在其傅里叶谱的衰减中体现出来。通过定义一个易处理的模型族，我们既能够获得精确的证明，又能够利用用于优化神经网络的先进和强大的计算技术。通过与GPU的并行计算，我们自然地增强了我们方法的可扩展性。我们的方法在应用于具有数千个系数但维度适中的多项式的情况下，优于基于Lasserre层次的证明最先进的优化方法，解决了竞争者难以处理的问题。

    We present a novel approach to non-convex optimization with certificates, which handles smooth functions on the hypercube or on the torus. Unlike traditional methods that rely on algebraic properties, our algorithm exploits the regularity of the target function intrinsic in the decay of its Fourier spectrum. By defining a tractable family of models, we allow at the same time to obtain precise certificates and to leverage the advanced and powerful computational techniques developed to optimize neural networks. In this way the scalability of our approach is naturally enhanced by parallel computing with GPUs. Our approach, when applied to the case of polynomials of moderate dimensions but with thousands of coefficients, outperforms the state-of-the-art optimization methods with certificates, as the ones based on Lasserre's hierarchy, addressing problems intractable for the competitors.
    
[^16]: 处理自然视觉场景神经响应的时间条件脉冲潜变量模型

    Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes. (arXiv:2306.12045v1 [q-bio.NC])

    [http://arxiv.org/abs/2306.12045](http://arxiv.org/abs/2306.12045)

    本研究提出 TeCoS-LVM 模型，使用脉冲神经元以模拟自然视觉刺激的神经响应。该模型能够自适应地探索和利用刺激序列中的时间依赖关系，避免丢失脉冲列中的信息。

    

    发展神经响应的计算模型对于理解感知处理和神经计算至关重要。目前最先进的神经网络方法使用时间过滤器来处理时间依赖性，导致处理流程不现实且不灵活。同时，这些方法针对试验平均发放率，未能捕捉到脉冲列中的重要特征。本研究提出时间条件脉冲潜变量模型（TeCoS-LVM）来模拟自然视觉刺激的神经响应。我们使用脉冲神经元产生直接匹配记录脉冲列的脉冲输出。这种方法有助于避免丢失嵌入在原始脉冲列中的信息。我们从模型参数空间中排除时间维度，并引入时间条件操作，使模型能够在自然范式中自适应地探索和利用刺激序列中的时间依赖关系。我们展示了 TeCoS-LVM 模型能够产生...

    Developing computational models of neural response is crucial for understanding sensory processing and neural computations. Current state-of-the-art neural network methods use temporal filters to handle temporal dependencies, resulting in an unrealistic and inflexible processing flow. Meanwhile, these methods target trial-averaged firing rates and fail to capture important features in spike trains. This work presents the temporal conditioning spiking latent variable models (TeCoS-LVM) to simulate the neural response to natural visual stimuli. We use spiking neurons to produce spike outputs that directly match the recorded trains. This approach helps to avoid losing information embedded in the original spike trains. We exclude the temporal dimension from the model parameter space and introduce a temporal conditioning operation to allow the model to adaptively explore and exploit temporal dependencies in stimuli sequences in a natural paradigm. We show that TeCoS-LVM models can produce m
    
[^17]: 动态图邻先验用于关系推断

    A Dynamical Graph Prior for Relational Inference. (arXiv:2306.06041v1 [cs.LG])

    [http://arxiv.org/abs/2306.06041](http://arxiv.org/abs/2306.06041)

    DYGR是一种用于关系推断的动态图先验方法，它利用高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度，并能够同时适用于具有共享图拓扑的“浅层”一步模型。

    

    关系推断旨在从观察到的动态系统中识别部件之间的相互作用。目前的最先进方法是在可学习的图上拟合图神经网络 (GNN) 来进行关系推断。它们使用一步消息传递 GNN--直观上来说是正确的选择，因为多步或谱 GNN 的非局部性可能会混淆直接和间接相互作用。但是“有效”的交互图取决于采样速率，很少局限于直接邻居，导致一个步骤模型的局部最小值。在本文中，我们提出了一种“动态图先验”(DYGR)来进行关系推断。我们称之为先验的原因是，与已有的方法不同，它在高度非局部的多项式滤波器中构造性地利用误差放大来生成用于图形学习的良好梯度。为了处理非唯一性，DYGR 同时适用于具有共享图拓扑的“浅层”一步模型。实验证明 DYGR 能够重新构建交互结构，同时获得更好的性能。

    Relational inference aims to identify interactions between parts of a dynamical system from the observed dynamics. Current state-of-the-art methods fit a graph neural network (GNN) on a learnable graph to the dynamics. They use one-step message-passing GNNs -- intuitively the right choice since non-locality of multi-step or spectral GNNs may confuse direct and indirect interactions. But the \textit{effective} interaction graph depends on the sampling rate and it is rarely localized to direct neighbors, leading to local minima for the one-step model. In this work, we propose a \textit{dynamical graph prior} (DYGR) for relational inference. The reason we call it a prior is that, contrary to established practice, it constructively uses error amplification in high-degree non-local polynomial filters to generate good gradients for graph learning. To deal with non-uniqueness, DYGR simultaneously fits a ``shallow'' one-step model with shared graph topology. Experiments show that DYGR reconstr
    
[^18]: 多任务生物测定预训练用于蛋白质-配体结合亲和力预测

    Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity Prediction. (arXiv:2306.04886v1 [q-bio.BM])

    [http://arxiv.org/abs/2306.04886](http://arxiv.org/abs/2306.04886)

    本文提出一种多任务生物测定预训练框架（MBP）用于基于结构的蛋白质-配体结合亲和力预测，通过构建一个预训练数据集ChEMBL-Dock，解决了高质量训练数据稀缺以及不同标签和实验条件导致的噪声问题。

    

    蛋白质-配体结合亲和力（PLBA）预测是药物发现中的基本任务。最近，各种基于深度学习的模型通过将蛋白质-配体复合物的三维结构作为输入并取得了惊人的进展来预测结合亲和力。然而，由于高质量训练数据的稀缺性，当前模型的泛化能力仍然有限。此外，不同的生物测定使用不同的亲和力测量标签（即IC50，Ki，Kd），不同的实验条件不可避免地会引入系统噪声，这对构建高精度亲和力预测模型构成了重大挑战。为了解决这些问题，我们（1）提出了多任务生物测定预训练（MBP），一种用于基于结构的PLBA预测的预训练框架;（2）构建了一个包含超过300k个实验测定亲和力标签和约2.8M个对接三维结构的预训练数据集，称为ChEMBL-Dock。

    Protein-ligand binding affinity (PLBA) prediction is the fundamental task in drug discovery. Recently, various deep learning-based models predict binding affinity by incorporating the three-dimensional structure of protein-ligand complexes as input and achieving astounding progress. However, due to the scarcity of high-quality training data, the generalization ability of current models is still limited. In addition, different bioassays use varying affinity measurement labels (i.e., IC50, Ki, Kd), and different experimental conditions inevitably introduce systematic noise, which poses a significant challenge to constructing high-precision affinity prediction models. To address these issues, we (1) propose Multi-task Bioassay Pre-training (MBP), a pre-training framework for structure-based PLBA prediction; (2) construct a pre-training dataset called ChEMBL-Dock with more than 300k experimentally measured affinity labels and about 2.8M docked three-dimensional structures. By introducing m
    
[^19]: 公平且健壮的异质治疗效果政策学习估计

    Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning. (arXiv:2306.03625v1 [stat.ME])

    [http://arxiv.org/abs/2306.03625](http://arxiv.org/abs/2306.03625)

    本文提出了一种公平且健壮的异质治疗效果的估计框架，可以在公平约束下非参数地估计，并可用于权衡公平和最大福利之间的关系。

    

    我们提出了一种简单且通用的框架，用于在公平约束条件下非参数估计异质治疗效果。在标准正则条件下，我们证明了所得到的估计器具有双重健壮性。我们利用此框架来表征公平和最佳政策可实现的最大福利之间的权衡。我们在模拟研究中评估了该方法，并在一个真实世界的案例研究中进行了说明。

    We propose a simple and general framework for nonparametric estimation of heterogeneous treatment effects under fairness constraints. Under standard regularity conditions, we show that the resulting estimators possess the double robustness property. We use this framework to characterize the trade-off between fairness and the maximum welfare achievable by the optimal policy. We evaluate the methods in a simulation study and illustrate them in a real-world case study.
    
[^20]: 学习模拟树枝动力学以进行操纵

    Learning to Simulate Tree-Branch Dynamics for Manipulation. (arXiv:2306.03410v1 [cs.RO])

    [http://arxiv.org/abs/2306.03410](http://arxiv.org/abs/2306.03410)

    本论文提出了一种仿真驱动的逆推理方法来学习树枝动态，并可以操纵可变形的植被，以解决密集植被中容易遮挡的任务，算法结合了生物学上的假设和传统参数推理方法的有限差分方案。

    

    我们提出使用仿真驱动的逆推理方法来模拟操纵下的树枝关节动力学。学习枝干动态并获得操纵可变形植被的能力可帮助处理容易遮挡的任务，例如在密集树叶中采摘水果、移动悬垂的藤蔓和树枝，以便在密集植被中导航。植物的可变形几何形状通过在并行、不可微模拟器上执行的粗略弹簧抽象来实现。由模拟器定义的隐式统计模型、通过主动探测的地面真实情况获得的参考轨迹和贝叶斯形式主义一起指导弹簧参数后验密度估计。我们的无参数推理算法基于斯坦变分梯度下降，并将生物学上的假设作为神经网络驱动的学习联合先验合并到推理过程中。此外，它利用了有限差分方案来对函数梯度进行估计，从而克服了传统参数推理方法中的梯度计算困难和维度灾难问题。

    We propose to use a simulation driven inverse inference approach to model the joint dynamics of tree branches under manipulation. Learning branch dynamics and gaining the ability to manipulate deformable vegetation can help with occlusion-prone tasks, such as fruit picking in dense foliage, as well as moving overhanging vines and branches for navigation in dense vegetation. The underlying deformable tree geometry is encapsulated as coarse spring abstractions executed on parallel, non-differentiable simulators. The implicit statistical model defined by the simulator, reference trajectories obtained by actively probing the ground truth, and the Bayesian formalism, together guide the spring parameter posterior density estimation. Our non-parametric inference algorithm, based on Stein Variational Gradient Descent, incorporates biologically motivated assumptions into the inference process as neural network driven learnt joint priors; moreover, it leverages the finite difference scheme for g
    
[^21]: 协方差自适应最佳臂识别问题

    Covariance Adaptive Best Arm Identification. (arXiv:2306.02630v1 [stat.ML])

    [http://arxiv.org/abs/2306.02630](http://arxiv.org/abs/2306.02630)

    本文提出了一个协方差自适应的最佳臂识别问题，相较于独立臂分布假设下的解决方案，能更有效地识别出高平均奖励的臂，适用于临床试验等场景。

    

    本文研究了在多臂老虎机模型下，基于固定置信度的最佳臂识别问题。在给定置信度 $\delta$ 的情况下，旨在以至少 1 - $\delta$ 的概率识别出具有最高平均奖励的臂，同时最小化臂的拉动次数。虽然文献提供了针对独立臂分布假设下该问题的解决方案，但我们提出了一个更加灵活的情形，其中臂可以是相关的，并且收益可以同时进行采样。该框架允许学习者估计臂之间分布的协方差，从而更有效地识别最佳臂。我们提出了适应臂协方差的新算法，并通过理论保证证明其具有实质性改进。

    We consider the problem of best arm identification in the multi-armed bandit model, under fixed confidence. Given a confidence input $\delta$, the goal is to identify the arm with the highest mean reward with a probability of at least 1 -- $\delta$, while minimizing the number of arm pulls. While the literature provides solutions to this problem under the assumption of independent arms distributions, we propose a more flexible scenario where arms can be dependent and rewards can be sampled simultaneously. This framework allows the learner to estimate the covariance among the arms distributions, enabling a more efficient identification of the best arm. The relaxed setting we propose is relevant in various applications, such as clinical trials, where similarities between patients or drugs suggest underlying correlations in the outcomes. We introduce new algorithms that adapt to the unknown covariance of the arms and demonstrate through theoretical guarantees that substantial improvement 
    
[^22]: 自对比学习用于基于会话的推荐

    Self Contrastive Learning for Session-based Recommendation. (arXiv:2306.01266v1 [cs.IR])

    [http://arxiv.org/abs/2306.01266](http://arxiv.org/abs/2306.01266)

    本文提出了自对比学习方法，简化了会话推荐领域基于对比学习的模型的复杂性，并提高了推荐性能。

    

    基于会话的推荐旨在预测用户对现有项目交互序列的下一个感兴趣的项目，已经吸引了越来越多应用使用对比学习（CL）提高用户和项目的表示。然而，这些对比目标：（1）起到与交叉熵损失类似的作用，同时忽略了项目表示空间优化；（2）通常需要复杂的建模，包括复杂的正/负样本构建和额外的数据增强。在本文中，我们引入了自对比学习（SCL），简化了对比学习的应用，并增强了基于状态的推荐技术的性能。具体而言，SCL被制定为一个目标函数，直接促进项目表示之间的均匀分布，并有效地替换了所有现有的对比目标组件的状态-艺术模型。与以前的工作不同，SCL消除了任何正样本或负样本的需求和SCL消除了任何正样本或负样本的需求和数据增强的需求。

    Session-based recommendation, which aims to predict the next item of users' interest as per an existing sequence interaction of items, has attracted growing applications of Contrastive Learning (CL) with improved user and item representations. However, these contrastive objectives: (1) serve a similar role as the cross-entropy loss while ignoring the item representation space optimisation; and (2) commonly require complicated modelling, including complex positive/negative sample constructions and extra data augmentation. In this work, we introduce Self-Contrastive Learning (SCL), which simplifies the application of CL and enhances the performance of state-of-the-art CL-based recommendation techniques. Specifically, SCL is formulated as an objective function that directly promotes a uniform distribution among item representations and efficiently replaces all the existing contrastive objective components of state-of-the-art models. Unlike previous works, SCL eliminates the need for any p
    
[^23]: MADiff：离线多智能体学习与扩散模型

    MADiff: Offline Multi-agent Learning with Diffusion Models. (arXiv:2305.17330v1 [cs.AI])

    [http://arxiv.org/abs/2305.17330](http://arxiv.org/abs/2305.17330)

    本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。

    

    扩散模型（DM）是一种强大的生成模型，最近在包括离线强化学习在内的各种场景中取得了巨大成功，其中策略通过在在线评估中产生轨迹来进行规划学习。然而，尽管单智能体学习显示了其有效性，但仍不清楚DM如何在多智能体问题中操作，其中代理商很难在独立建模每个代理商轨迹的情况下完成团队合作。在本文中，我们提出MADiff，一种新的生成式多智能体学习框架，以解决这个问题。MADiff是通过基于注意力的扩散模型来实现对多个扩散智能体行为的复杂协调建模。据我们所知，MADiff是第一个基于扩散的多智能体离线RL框架，它既可以行为为分散的政策，又可以为集中控制器，其中包括对手建模，并可用于多智能体轨迹预测。

    Diffusion model (DM), as a powerful generative model, recently achieved huge success in various scenarios including offline reinforcement learning, where the policy learns to conduct planning by generating trajectory in the online evaluation. However, despite the effectiveness shown for single-agent learning, it remains unclear how DMs can operate in multi-agent problems, where agents can hardly complete teamwork without good coordination by independently modeling each agent's trajectories. In this paper, we propose MADiff, a novel generative multi-agent learning framework to tackle this problem. MADiff is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple diffusion agents. To the best of our knowledge, MADiff is the first diffusion-based multi-agent offline RL framework, which behaves as both a decentralized policy and a centralized controller, which includes opponent modeling and can be used for multi-agent trajectory predic
    
[^24]: PiML工具箱：可解释机器学习模型的开发和验证

    PiML Toolbox for Interpretable Machine Learning Model Development and Validation. (arXiv:2305.04214v1 [cs.LG])

    [http://arxiv.org/abs/2305.04214](http://arxiv.org/abs/2305.04214)

    PiML工具箱是一个综合的Python工具箱，可用于开发和诊断可解释机器学习模型，包括日益增长的可解释模型、模型无关的可解释性工具和模型无关的诊断工具，还支持与MLOps平台的集成和质量保证。

    

    PiML是一个综合且开放的Python工具箱，用于可解释机器学习模型的开发和模型诊断。它设计了低代码和高代码两种机器学习工作流，包括数据管道、模型训练、模型解释和说明以及模型诊断和比较。该工具箱支持日益增长的可解释模型（例如GAM、GAMI-Net、XGB2），具有本地和/或全局可解释性。它还支持模型无关的可解释性工具（例如PFI、PDP、LIME、SHAP）和一个强大的模型无关诊断套件（例如弱点、不确定性、鲁棒性、公平性）。通过灵活的高代码 API，将 PiML 模型和测试集成到现有的 MLOps 平台以实现质量保证。此外，PiML 工具箱还带有综合的用户指南和实践例子，包括银行业中的模型开发和验证应用。该项目可通过arXiv:2305.04214v1[cs.LG]获取。

    PiML (read $\pi$-ML, /`pai.`em.`el/) is an integrated and open-access Python toolbox for interpretable machine learning model development and model diagnostics. It is designed with machine learning workflows in both low-code and high-code modes, including data pipeline, model training, model interpretation and explanation, and model diagnostics and comparison. The toolbox supports a growing list of interpretable models (e.g. GAM, GAMI-Net, XGB2) with inherent local and/or global interpretability. It also supports model-agnostic explainability tools (e.g. PFI, PDP, LIME, SHAP) and a powerful suite of model-agnostic diagnostics (e.g. weakness, uncertainty, robustness, fairness). Integration of PiML models and tests to existing MLOps platforms for quality assurance are enabled by flexible high-code APIs. Furthermore, PiML toolbox comes with a comprehensive user guide and hands-on examples, including the applications for model development and validation in banking. The project is available
    
[^25]: LAVA: 无需预定学习算法的数据价值评估

    LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])

    [http://arxiv.org/abs/2305.00054](http://arxiv.org/abs/2305.00054)

    LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。

    

    传统的数据价值评估问题是如何公平地分配学习算法的验证性能，致使计算得到的数据价值依赖于底层学习算法的许多设计选择。本文提出了一种新的框架LAVA，该框架结合了学习算法的统计特性和训练数据的属性，迭代估计数据值，使其无视下游的学习算法。我们展示了LAVA比现有方法计算速度更快，精度更高，并且它可以为不同的应用提供有意义的数据排名。

    Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
    
[^26]: 基于数据驱动的分段仿射决策规则用于带协变信息的随机规划

    Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])

    [http://arxiv.org/abs/2304.13646](http://arxiv.org/abs/2304.13646)

    本研究提出一种嵌入非凸分段仿射决策规则的经验风险最小化方法，用于学习特征与最优决策之间的直接映射。所提出的方法可用于广泛的非凸型SP问题，并且在数值研究中表现出优越的性能。

    

    本文针对带协变信息的随机规划，提出了一种嵌入非凸分段仿射决策规则(PADR)的经验风险最小化(ERM)方法，旨在学习特征与最优决策之间的直接映射。我们建立了基于PADR的ERM模型的非渐近一致性结果，可用于无约束问题，以及约束问题的渐近一致性结果。为了解决非凸和非可微的ERM问题，我们开发了一个增强的随机主导下降算法，并建立了沿（复合强）方向稳定性的渐近收敛以及复杂性分析。我们表明，所提出的PADR-based ERM方法适用于广泛的非凸型SP问题，并具有理论一致性保证和计算可处理性。数值研究表明，在各种设置下，PADR-based ERM方法相对于最先进的方法具有优越的性能。

    Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
    
[^27]: 大规模量子多体态的机器学习显著提高效率并具有可证明保障

    Exponentially Improved Efficient Machine Learning for Quantum Many-body States with Provable Guarantees. (arXiv:2304.04353v1 [quant-ph])

    [http://arxiv.org/abs/2304.04353](http://arxiv.org/abs/2304.04353)

    通过机器学习协议预测量子多体系统的基态及其性质，其精度为 $\varepsilon$，并具有可证明的保障；但对于普遍的能隙哈密顿量，样本个数 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，只适用于参数空间维度较大，且精度不是紧迫因素，无法进入更精确的学习和预测领域。

    

    对于经典算法而言，解决量子多体系统的基态及其性质通常是一项艰巨的任务。对于定义在物理参数 $m$ 维空间上的哈密顿量族，只要可以高效地准备和测量一组 $N$ 个态，就可以通过机器学习协议预测其基态及其在任意参数配置下的性质，精度为 $\varepsilon$。最近的一项研究 [Huang 等人，Science 377，eabk3333（2022）] 对这种一般化提出了严格的保障。不幸的是，对于普遍的能隙哈密顿量，普适的指数缩放为 $N = m^{{\cal{O}} \left(\frac{1}{\varepsilon}\right)}$，这个结果仅适用于参数空间的维度较大，而精度的缩放则不是一个紧迫的因素，不能进入更精确的学习和预测领域。

    Solving the ground state and the ground-state properties of quantum many-body systems is generically a hard task for classical algorithms. For a family of Hamiltonians defined on an $m$-dimensional space of physical parameters, the ground state and its properties at an arbitrary parameter configuration can be predicted via a machine learning protocol up to a prescribed prediction error $\varepsilon$, provided that a sample set (of size $N$) of the states can be efficiently prepared and measured. In a recent work [Huang et al., Science 377, eabk3333 (2022)], a rigorous guarantee for such an generalization was proved. Unfortunately, an exponential scaling, $N = m^{ {\cal{O}} \left(\frac{1}{\varepsilon} \right) }$, was found to be universal for generic gapped Hamiltonians. This result applies to the situation where the dimension of the parameter space is large while the scaling with the accuracy is not an urgent factor, not entering the realm of more precise learning and prediction. In th
    
[^28]: RED-PSM: 带去噪正则化的部分可分模型用于动态成像

    RED-PSM: Regularization by Denoising of Partially Separable Models for Dynamic Imaging. (arXiv:2304.03483v1 [eess.IV])

    [http://arxiv.org/abs/2304.03483](http://arxiv.org/abs/2304.03483)

    本文提出了一种称为RED-PSM的方法，将部分可分模型与去噪正则化相结合，用于解决动态成像问题，数值实验证明其优越性。

    

    动态成像是指利用被欠采样的测量数据恢复每个时间点上的时变二维或三维物体。尤其是在动态断层扫描中，每个时间点上只有一个视角下的单个投影可用，使得问题严重算不可逆。本文提出了一种称为RED-PSM的方法，首次将两种强大的技术结合起来解决这个具有挑战性的成像问题。第一种技术是部分可分模型，已经用于高效地为时空目标引入低秩先验。第二种是最近提出的去噪正则化(RED)，它提供了一种灵活的框架，利用最先进的图像去噪算法处理各种反问题。我们提出了一个带正则化的部分可分目标，通过变量分裂和ADMM优化方案，并证明了我们的目标收敛于一个满足优化问题的稳定点。我们通过在具有挑战性的动态断层扫描问题上进行了大量的数值实验，证明了所提出的RED-PSM方法的优越性，相较于现有的动态成像技术。

    Dynamic imaging addresses the recovery of a time-varying 2D or 3D object at each time instant using its undersampled measurements. In particular, in the case of dynamic tomography, only a single projection at a single view angle may be available at a time, making the problem severely ill-posed. In this work, we propose an approach, RED-PSM, which combines for the first time two powerful techniques to address this challenging imaging problem. The first, are partially separable models, which have been used to efficiently introduce a low-rank prior for the spatio-temporal object. The second is the recent Regularization by Denoising (RED), which provides a flexible framework to exploit the impressive performance of state-of-the-art image denoising algorithms, for various inverse problems. We propose a partially separable objective with RED and an optimization scheme with variable splitting and ADMM, and prove convergence of our objective to a value corresponding to a stationary point satis
    
[^29]: 在不使用数据增强的情况下加强正则化来防止在线深度聚类中的崩溃

    Hard Regularization to Prevent Collapse in Online Deep Clustering without Data Augmentation. (arXiv:2303.16521v1 [cs.LG])

    [http://arxiv.org/abs/2303.16521](http://arxiv.org/abs/2303.16521)

    该论文提出了一种不需要数据增强的在线深度聚类方法，通过加强正则化来避免崩溃，相比于其他方法，具有更高的稳定性。

    

    在线深度聚类是指联合使用特征提取网络和聚类模型，以将每个新数据点或批处理分配到聚类标签中。尽管比离线方法更快速和更灵活，但在线聚类很容易达到崩溃解，其中编码器将所有输入映射到同一点，并将所有输入放入单个聚类中。现有成功模型采用了各种技术来避免这个问题，其中大多数需要数据增强或旨在使数据集中每个聚类的平均软分配相同。我们提出了一种不需要数据增强的方法，与现有方法不同，它对硬分配进行了规则化。我们使用贝叶斯框架，导出一个直观的优化目标，可以直接包含在编码器网络的训练中。在四个图像数据集上进行测试，我们证明它比其他方法更加稳定地避免了崩溃。

    Online deep clustering refers to the joint use of a feature extraction network and a clustering model to assign cluster labels to each new data point or batch as it is processed. While faster and more versatile than offline methods, online clustering can easily reach the collapsed solution where the encoder maps all inputs to the same point and all are put into a single cluster. Successful existing models have employed various techniques to avoid this problem, most of which require data augmentation or which aim to make the average soft assignment across the dataset the same for each cluster. We propose a method that does not require data augmentation, and that, differently from existing methods, regularizes the hard assignments. Using a Bayesian framework, we derive an intuitive optimization objective that can be straightforwardly included in the training of the encoder network. Tested on four image datasets, we show that it consistently avoids collapse more robustly than other method
    
[^30]: 2D扩散算法的去偏置方法用于文本到3D生成

    Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation. (arXiv:2303.15413v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15413](http://arxiv.org/abs/2303.15413)

    本文提出了两种去偏置的方法，一种通过增加2D扩散模型得出的分数的截断值，一种通过调整视角提示和物体空间摄像机姿态之间的差异。实验结果表明这些方法可以显著减少伪影，提高真实感。

    

    本文探讨了在文本到3D生成中出现的视角一致性问题，也称为Janus问题。这个问题来自于2D扩散模型的固有偏置，导致生成的3D对象不真实。通过对其进行研究，我们提出了两种方法来去除偏置以实现文本到3D生成的鲁棒性。第一种方法叫做score debiasing，通过逐渐增加2D扩散模型得出的分数的截断值，来达到去除偏置的效果。第二种方法叫做prompt debiasing，利用语言模型确定用户提示和视角提示之间的矛盾词语，并调整视角提示和物体空间摄像机姿态之间的差异。我们的实验结果表明，我们的方法通过显著减少伪影，提高了真实感，并在质量与速度方面取得了良好的平衡。

    The view inconsistency problem in score-distilling text-to-3D generation, also known as the Janus problem, arises from the intrinsic bias of 2D diffusion models, which leads to the unrealistic generation of 3D objects. In this work, we explore score-distilling text-to-3D generation and identify the main causes of the Janus problem. Based on these findings, we propose two approaches to debias the score-distillation frameworks for robust text-to-3D generation. Our first approach, called score debiasing, involves gradually increasing the truncation value for the score estimated by 2D diffusion models throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts utilizing a language model and adjusts the discrepancy between view prompts and object-space camera poses. Our experimental results show that our methods improve realism by significantly reducing artifacts and achieve a good trade-off between fa
    
[^31]: 转换的低秩参数化可以帮助张量神经网络实现稳健的泛化

    Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks. (arXiv:2303.00196v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00196](http://arxiv.org/abs/2303.00196)

    这项研究首次通过推导泛化误差上界回答了转换的低秩参数化如何影响张量神经网络的学习行为，结果显示通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。

    

    在数据科学中，实现高效且稳健的多通道数据学习是一项具有挑战性的任务。通过利用转换域中的低秩性，即转换的低秩性，张量奇异值分解（t-SVD）在多通道数据表示方面取得了广泛的成功，并最近扩展到了函数表示，如具有t-乘积层（t-NNs）的神经网络。然而，t-SVD理论上如何影响t-NNs的学习行为仍不清楚。本文第一次通过推导标准和对抗训练的t-NNs的泛化误差上界来回答这个问题。研究结果显示，通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。在实践中，尽管t-NNs很少具有完全转换的低秩权重，我们的分析进一步表明，通过使用梯度流（GF）进行对抗性训练，过参数化的t-NNs具有ReLU

    Achieving efficient and robust multi-channel data learning is a challenging task in data science. By exploiting low-rankness in the transformed domain, i.e., transformed low-rankness, tensor Singular Value Decomposition (t-SVD) has achieved extensive success in multi-channel data representation and has recently been extended to function representation such as Neural Networks with t-product layers (t-NNs). However, it still remains unclear how t-SVD theoretically affects the learning behavior of t-NNs. This paper is the first to answer this question by deriving the upper bounds of the generalization error of both standard and adversarially trained t-NNs. It reveals that the t-NNs compressed by exact transformed low-rank parameterization can achieve a sharper adversarial generalization bound. In practice, although t-NNs rarely have exactly transformed low-rank weights, our analysis further shows that by adversarial training with gradient flow (GF), the over-parameterized t-NNs with ReLU 
    
[^32]: 无接触红外光波传感的呼吸异常检测

    Non-contact Respiratory Anomaly Detection using Infrared Light-wave Sensing. (arXiv:2301.03713v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2301.03713](http://arxiv.org/abs/2301.03713)

    本研究使用无接触红外光波传感技术，通过训练不同类型的呼吸模式来检测呼吸异常，并且通过验证数据的呼吸波形丢弃干扰数据，以实现安全、高效和无创的人体呼吸监测。

    

    人体的呼吸频率和呼吸模式传达了关于主体的身体和心理状态的重要信息。异常呼吸可能表明严重的健康问题，需要进一步诊断和治疗。使用非相干红外光的无线光波传感（LWS）在不引起隐私问题的情况下，显示了安全、隐蔽、高效和无创的人体呼吸监测的潜力。呼吸监测系统需要在不同类型的呼吸模式上进行训练，以识别呼吸异常。该系统还必须验证所收集的数据是否为呼吸波形，丢弃由外部干扰、用户移动或系统故障引起的任何错误数据。为了解决这些需求，本研究使用模拟人类呼吸模式的机器人，模拟了正常和不同类型的异常呼吸。然后，使用红外光波传感技术收集了时间序列呼吸数据。在此基础上，用三种机器学习算法进行了呼吸异常检测。

    Human respiratory rate and its pattern convey essential information about the physical and psychological states of the subject. Abnormal breathing can indicate fatal health issues leading to further diagnosis and treatment. Wireless light-wave sensing (LWS) using incoherent infrared light shows promise in safe, discreet, efficient, and non-invasive human breathing monitoring without raising privacy concerns. The respiration monitoring system needs to be trained on different types of breathing patterns to identify breathing anomalies.The system must also validate the collected data as a breathing waveform, discarding any faulty data caused by external interruption, user movement, or system malfunction. To address these needs, this study simulated normal and different types of abnormal respiration using a robot that mimics human breathing patterns. Then, time-series respiration data were collected using infrared light-wave sensing technology. Three machine learning algorithms, decision t
    
[^33]: 双重精度质量驱动的神经网络用于生成预测区间

    Dual Accuracy-Quality-Driven Neural Network for Prediction Interval Generation. (arXiv:2212.06370v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06370](http://arxiv.org/abs/2212.06370)

    本文提出了一种双重精度质量驱动的神经网络，可以自动地学习基于回归的神经网络的预测区间，而非只提供传统的目标估计。该方法通过设计一种新颖的损失函数，最小化平均预测区间宽度以及提高覆盖概率来提高PI的质量和精度，且比最先进的方法更加具有计算效率。

    

    在深度学习模型在实际应用中，准确的不确定性量化对于提高其可靠性至关重要。对于回归任务，应该在深度学习模型的确定性预测之外提供预测区间(PIs)。只要Pis足够窄而且捕获了大部分的概率密度，这些Pis就是有用的或"高质量"的。本文提出了一种方法，可以自动地为回归神经网络学习预测区间，除了传统的目标预测之外。具体而言，我们训练两个伴侣神经网络：一个使用一个输出，目标估计，另一个使用两个输出，相应PI的上限和下限的值。我们的主要贡献是为生成PI的网络设计了一种新颖的损失函数，该函数考虑了目标估计网络的输出，并且具有两个优化目标：减小平均预测区间宽度和提高Pis的质量(通过其覆盖概率进行测量)。我们在几个回归数据集上评估了我们的方法，并证明了我们的方法可以产生比最先进的方法更准确且质量更高的预测区间，同时又具有计算效率。

    Accurate uncertainty quantification is necessary to enhance the reliability of deep learning models in real-world applications. In the case of regression tasks, prediction intervals (PIs) should be provided along with the deterministic predictions of deep learning models. Such PIs are useful or "high-quality" as long as they are sufficiently narrow and capture most of the probability density. In this paper, we present a method to learn prediction intervals for regression-based neural networks automatically in addition to the conventional target predictions. In particular, we train two companion neural networks: one that uses one output, the target estimate, and another that uses two outputs, the upper and lower bounds of the corresponding PI. Our main contribution is the design of a novel loss function for the PI-generation network that takes into account the output of the target-estimation network and has two optimization objectives: minimizing the mean prediction interval width and e
    
[^34]: 通过半监督学习和生成对抗网络在不平衡数据集中进行虚假检测

    Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01071](http://arxiv.org/abs/2212.01071)

    本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。

    

    随着社交媒体的快速发展，骚扰行为变得更加普遍，这导致了虚假检测成为研究人员中引人注目的领域。数据的图形特性以及大量节点导致了许多障碍，包括矩阵中大量无关特征的高离散度和不平衡类别。为了解决这些问题，本文采用了自编码器和半监督学习与生成对抗网络算法的组合，即SGAN。本文将少量标签应用于SGAN作为分类器。实验结果表明，仅使用100个标记样本，该方法在检测虚假账户方面的准确率达到了91\%。

    As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\% in detecting fake accounts using only 100 labeled samples.
    
[^35]: 可微非标定成像

    Differentiable Uncalibrated Imaging. (arXiv:2211.10525v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2211.10525](http://arxiv.org/abs/2211.10525)

    本文提出了一种可微的成像框架，以解决测量坐标的不确定性，通过隐式神经网络和可微分样条插值器实现。该方法应用于2D和3D计算机断层扫描，产生了改进的重建结果。

    This paper proposes a differentiable imaging framework to address uncertainty in measurement coordinates, using implicit neural networks and differentiable spline interpolators. The method is applied to 2D and 3D computed tomography and produces improved reconstructions.

    我们提出了一种可微成像框架，以解决测量坐标（如传感器位置和投影角度）的不确定性。我们将问题公式化为在未知节点处的测量插值，通过正向算子进行监督。为了解决这个问题，我们应用了隐式神经网络，也称为神经场，它们在输入坐标方面自然可微分。我们还开发了可微分样条插值器，其性能与神经网络一样好，需要更少的优化时间，并且具有良好的性质。可微性是关键，因为它允许我们共同拟合测量表示，优化不确定的测量坐标，并执行图像重建，从而确保一致的标定。我们将我们的方法应用于2D和3D计算机断层扫描，并展示了与不考虑缺乏标定的基线相比，它产生了改进的重建结果。所提出的框架的灵活性

    We propose a differentiable imaging framework to address uncertainty in measurement coordinates such as sensor locations and projection angles. We formulate the problem as measurement interpolation at unknown nodes supervised through the forward operator. To solve it we apply implicit neural networks, also known as neural fields, which are naturally differentiable with respect to the input coordinates. We also develop differentiable spline interpolators which perform as well as neural networks, require less time to optimize and have well-understood properties. Differentiability is key as it allows us to jointly fit a measurement representation, optimize over the uncertain measurement coordinates, and perform image reconstruction which in turn ensures consistent calibration. We apply our approach to 2D and 3D computed tomography and show that it produces improved reconstructions compared to baselines that do not account for the lack of calibration. The flexibility of the proposed framew
    
[^36]: 多点-BAX: 一种通过虚拟目标高效调整粒子加速器发射度的新方法

    Multipoint-BAX: A New Approach for Efficiently Tuning Particle Accelerator Emittance via Virtual Objectives. (arXiv:2209.04587v4 [physics.acc-ph] UPDATED)

    [http://arxiv.org/abs/2209.04587](http://arxiv.org/abs/2209.04587)

    本论文提出了一种名为多点-BAX的新方法，通过虚拟目标来高效调整粒子加速器的发射度。该方法避免了使用传统的黑盒优化器进行缓慢而低效的多点查询，并通过快速学习模型计算发射度目标。该方法在Linac相干光源(LCLS)和Facility for Adv中最小化发射度。

    

    尽管束发射度对于高亮度加速器的性能至关重要，但优化通常会受到时间限制，因为发射度计算通常是通过四极扫描完成的，而四极扫描通常较慢。这种计算是一种多点查询，即每个查询都需要多个辅助测量。传统的黑盒优化器，如贝叶斯优化，在处理这样的目标时速度慢且效率低下，因为它们必须获取完整的测量序列，但每个查询仅返回发射度。我们提出将贝叶斯算法执行(BAX)应用于查询和建模单个束流尺寸测量。BAX通过使用快速学习模型而不是直接从加速器中获取发射度指标来避免在加速器上进行缓慢的多点查询。在这里，我们使用BAX来最小化Linac相干光源(LCLS)和Facility for Adv的发射度。

    Although beam emittance is critical for the performance of high-brightness accelerators, optimization is often time limited as emittance calculations, commonly done via quadrupole scans, are typically slow. Such calculations are a type of $\textit{multi-point query}$, i.e. each query requires multiple secondary measurements. Traditional black-box optimizers such as Bayesian optimization are slow and inefficient when dealing with such objectives as they must acquire the full series of measurements, but return only the emittance, with each query. We propose applying Bayesian Algorithm Execution (BAX) to instead query and model individual beam-size measurements. BAX avoids the slow multi-point query on the accelerator by acquiring points through a $\textit{virtual objective}$, i.e. calculating the emittance objective from a fast learned model rather than directly from the accelerator. Here, we use BAX to minimize emittance at the Linac Coherent Light Source (LCLS) and the Facility for Adv
    
[^37]: 通过卷积反射下降分析基于双基础PID控制器

    Analysis of Dual-Based PID Controllers through Convolutional Mirror Descent. (arXiv:2202.06152v3 [math.OC] UPDATED)

    [http://arxiv.org/abs/2202.06152](http://arxiv.org/abs/2202.06152)

    本文提供了基于双基础PID控制器性能的遗憾界限，并建立了双基础PID控制器与在线凸优化算法CMD之间的联系。

    

    基于双基础PID控制器通常用于解决具有全局约束的在线分配问题，如在线广告中的预算节奏。然而，控制器在实践中以启发式方式使用，并且对其性能没有可证明的保证。本文针对在线分配问题首次提供了基于双基础PID控制器性能的遗憾界限。我们首先建立了双基础PID控制器与一种名为“卷积反射下降”（Convolutional Mirror Descent，CMD）的新型在线凸优化一阶算法之间的基本联系。CMD根据过去梯度的加权移动平均更新迭代。在特殊情况下，CMD恢复了在线镜像下降与动量和乐观镜像下降。我们建立了足够的条件，在这些条件下CMD可实现对带有对抗性输入的一般在线凸优化问题的低遗憾。我们利用这一新结果给出了关于网络广告中预算节奏问题的性能保证。

    Dual-based proportional-integral-derivative (PID) controllers are often employed in practice to solve online allocation problems with global constraints, such as budget pacing in online advertising. However, controllers are used in a heuristic fashion and come with no provable guarantees on their performance. This paper provides the first regret bounds on the performance of dual-based PID controllers for online allocation problems. We do so by first establishing a fundamental connection between dual-based PID controllers and a new first-order algorithm for online convex optimization called \emph{Convolutional Mirror Descent} (CMD), which updates iterates based on a weighted moving average of past gradients. CMD recovers, in a special case, online mirror descent with momentum and optimistic mirror descent. We establish sufficient conditions under which CMD attains low regret for general online convex optimization problems with adversarial inputs. We leverage this new result to give the 
    

