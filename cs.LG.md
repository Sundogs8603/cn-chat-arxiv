# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](https://arxiv.org/abs/2403.14624) | MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。 |
| [^2] | [Simplified Diffusion Schr\"odinger Bridge](https://arxiv.org/abs/2403.14623) | 介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。 |
| [^3] | [Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion](https://arxiv.org/abs/2403.14617) | Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。 |
| [^4] | [DreamReward: Text-to-3D Generation with Human Preference](https://arxiv.org/abs/2403.14613) | DreamReward提出了一个名为DreamFL的框架，通过学习和改进文本到3D模型，基于人类偏好反馈创建了第一个通用的文本到3D人类偏好奖励模型，并引入了Reward3D反馈学习算法，成功生成高保真度和一致的3D结果。 |
| [^5] | [Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey](https://arxiv.org/abs/2403.14608) | 大型模型参数高效微调（PEFT）是通过调整预训练模型的参数，以适应特定任务，并减少引入的附加参数或计算资源数量的实用解决方案。 |
| [^6] | [The Elements of Differentiable Programming](https://arxiv.org/abs/2403.14606) | 可微分编程是一个新的编程范式，使得复杂程序能够端对端地进行微分，实现基于梯度的参数优化。 |
| [^7] | [ReNoise: Real Image Inversion Through Iterative Noising](https://arxiv.org/abs/2403.14602) | 本研究提出了一种通过迭代添加噪声进行真实图像反转的方法，可以在不增加操作数量的情况下增强重建精度。 |
| [^8] | [Extended Reality for Enhanced Human-Robot Collaboration: a Human-in-the-Loop Approach](https://arxiv.org/abs/2403.14597) | 本文提出了一种自主的、基于机器学习的操作器框架，将人在回路原则和扩展现实结合起来，以促进人与机器人之间直观的沟通和编程。 |
| [^9] | [Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery](https://arxiv.org/abs/2403.14593) | 重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。 |
| [^10] | [ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589) | 提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。 |
| [^11] | [An Analysis of Linear Time Series Forecasting Models](https://arxiv.org/abs/2403.14587) | 分析了线性时间序列预测模型，证明了几种流行的线性模型变体等效于标准的线性回归，提供了实验证据支持这一结论。 |
| [^12] | [Co-Optimization of Environment and Policies for Decentralized Multi-Agent Navigation](https://arxiv.org/abs/2403.14583) | 将多智能体系统和周围环境视为共同演化的系统，提出智能体-环境协同优化问题并开发协调算法，以改进去中心化多智能体导航表现。 |
| [^13] | [RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain](https://arxiv.org/abs/2403.14578) | 该研究引入了RAmBLA框架，评估四个最先进的基础LLMs在生物医学领域是否可以作为可靠助手，在任务设计和性能评估中强调了提示的健壮性、高召回率和缺乏幻觉的重要性。 |
| [^14] | [A survey on Concept-based Approaches For Model Improvement](https://arxiv.org/abs/2403.14566) | 基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。 |
| [^15] | [Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling](https://arxiv.org/abs/2403.14551) | 这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。 |
| [^16] | [Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images](https://arxiv.org/abs/2403.14547) | 本文提出了一种用于估计通道数据增强技术对遥感图像物理信息一致性影响的方法，以解决这一领域中存在的争议。 |
| [^17] | [Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild](https://arxiv.org/abs/2403.14539) | 提出了ObjectDR，利用对象-centric的域随机化合成单视图3D形状重建中缺乏的配对数据，通过条件生成模型和解耦框架来生成和保留对象轮廓以及广泛变化的数据，从而为培训模型捕捉域不变性几何形状。 |
| [^18] | [Machine-learning invariant foliations in forced systems for reduced order modelling](https://arxiv.org/abs/2403.14514) | 使用机器学习不变叶轨道在强迫系统中识别降阶模型，结合全局和局部叶轨道，并强调解决数学方面的挑战。 |
| [^19] | [Constrained Reinforcement Learning with Smoothed Log Barrier Function](https://arxiv.org/abs/2403.14508) | 提出了一种新的约束强化学习方法CSAC-LB，通过应用线性平滑对数障碍函数，实现了竞争性能，无需任何预训练 |
| [^20] | [Soft Learning Probabilistic Circuits](https://arxiv.org/abs/2403.14504) | 该论文提出了一种新的学习过程 SoftLearn，通过软聚类过程诱导出一个 PC，相较于传统的 LearnSPN，在许多情况下表现更好，产生更好的似然值和样本。 |
| [^21] | [Physics-Based Causal Reasoning for Safe & Robust Next-Best Action Selection in Robot Manipulation Tasks](https://arxiv.org/abs/2403.14488) | 该论文提出了一个基于物理因果推理的框架，用于机器人在部分可观察的环境中进行概率推理，成功预测积木塔稳定性并选择下一最佳动作。 |
| [^22] | [HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges](https://arxiv.org/abs/2403.14484) | HyperGALE通过学习超边的超图门控注意力机制，在解释复杂的脑图数据方面取得显著改进，为ASD生物标志特征化提供更深入见解。 |
| [^23] | [Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research](https://arxiv.org/abs/2403.14483) | 该研究利用LightGBM算法对运营商用户信用评估模型进行研究，通过提取关键特征并进行数据预处理和特征工程，以改善用户信用评估策略。 |
| [^24] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^25] | [Universal Feature Selection for Simultaneous Interpretability of Multitask Datasets](https://arxiv.org/abs/2403.14466) | BoUTS的特征选择算法能够普适性地识别数据集中通用特征和预测特定子集的任务特定特征，在化学数据集上取得了最先进的特征稀疏性，同时保持着与专门方法相当的预测准确性。 |
| [^26] | [gTBLS: Generating Tables from Text by Conditional Question Answering](https://arxiv.org/abs/2403.14457) | gTBLS通过两阶段方法从文本中生成表格，第一阶段推断表格结构，第二阶段利用结构提出问题并通过微调语言模型来回答，能够在零短配置下利用预训练的大型语言模型，改进了先前方法的效果。 |
| [^27] | [Language Models Can Reduce Asymmetry in Information Markets](https://arxiv.org/abs/2403.14443) | 语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。 |
| [^28] | [Analysing Diffusion Segmentation for Medical Images](https://arxiv.org/abs/2403.14440) | 本研究批判性地分析和讨论了医学图像的扩散分割与扩散图像生成之间的差异，强调了针对扩散分割的架构改进带来的益处。 |
| [^29] | [A Multimodal Approach to Device-Directed Speech Detection with Large Language Models](https://arxiv.org/abs/2403.14438) | 探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。 |
| [^30] | [Biased Binary Attribute Classifiers Ignore the Majority Classes](https://arxiv.org/abs/2403.14435) | 本文将梯度基础的CAM技术扩展到二元分类器，并可视化二进制面部属性分类器的活动区域，证实在不平衡数据集上训练时偏向性分类器倾向于学习提取主要类别的特征 |
| [^31] | [Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2403.14429) | 提出了风格提取扩散模型，利用风格调节机制和内容调节机制，实现了在图像生成过程中注入未见图像风格信息，从而以零-shot方式生成具有未见风格的图像。 |
| [^32] | [Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization](https://arxiv.org/abs/2403.14425) | 提出了一种基于可微分模拟和优化的任务最优数据驱动替代模型方法，在eNMPC中表现出优越性能，为实现更具能力的控制器提供了有前途的途径。 |
| [^33] | [DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning](https://arxiv.org/abs/2403.14421) | 开发了第一个差分隐私检索增强生成算法，能够在生成高质量图像样本的同时提供可证明的隐私保证 |
| [^34] | [Model Uncertainty in Evolutionary Optimization and Bayesian Optimization: A Comparative Analysis](https://arxiv.org/abs/2403.14413) | 这项研究比较了进化优化和贝叶斯优化中的模型不确定性，引入了一种新的模型辅助策略以增强算法性能。 |
| [^35] | [GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning](https://arxiv.org/abs/2403.14410) | 该论文提出了GLC++方法，通过全局和局部聚类以及对比关联学习实现了无源通用域自适应，能够准确分类已知数据并将其从未知数据中分离。 |
| [^36] | [Physics-Informed Diffusion Models](https://arxiv.org/abs/2403.14404) | 提出了一个信息化去噪扩散模型框架，可在模型训练期间对生成样本施加约束，以改善样本与约束的对齐程度并提供自然的正则化，适用性广泛。 |
| [^37] | [Regularized Adaptive Momentum Dual Averaging with an Efficient Inexact Subproblem Solver for Training Structured Neural Network](https://arxiv.org/abs/2403.14398) | 提出了RAMDA算法用于训练结构化神经网络，引入了使用近似解的方法，并证明在收敛点附近RAMDA的迭代达到了最优结构。 |
| [^38] | [A Bag of Tricks for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2403.14392) | 提出了针对少样本类增量学习的一揽子技巧框架，将八种关键技术结合在一起，改进了稳定性、适应性和整体性能 |
| [^39] | [Estimating Causal Effects with Double Machine Learning -- A Method Evaluation](https://arxiv.org/abs/2403.14385) | 双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。 |
| [^40] | [Tensor network compressibility of convolutional models](https://arxiv.org/abs/2403.14379) | 张量化是将卷积神经网络中的卷积核替换为紧凑分解，并直接训练分解因子以偏向于低秩分解的方法，该研究探讨了张量化如何通过评估截断卷积核来保持准确性。 |
| [^41] | [Knowledge-Enhanced Recommendation with User-Centric Subgraph Network](https://arxiv.org/abs/2403.14377) | 提出了一种基于知识增强的用户中心子图网络推荐方法，通过将用户-物品交互信息和知识图中的附加信息结合到子图学习中，实现了有效的个性化推荐。 |
| [^42] | [Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server](https://arxiv.org/abs/2403.14371) | 循环改进（LI）是一种无需中央服务器或数据交换的新颖方法，可提高数据异质性下的特征提取效率，表现优越于先进算法FedALA，并可应用于个性化联邦学习和全局模型环境。 |
| [^43] | [Varroa destructor detection on honey bees using hyperspectral imagery](https://arxiv.org/abs/2403.14359) | 本研究提出了一种基于多元统计学的方法，可利用高光谱图像检测蜂蜜蜂上的寄生性变形螨，为蜜蜂巢穴的监测提供了新途径。 |
| [^44] | [Exploring the Potential of Large Language Models in Graph Generation](https://arxiv.org/abs/2403.14358) | 本文探索了大型语言模型在图生成中的潜力，通过任务设计和实验考察了其对不同图结构规则的理解、捕获结构类型分布的能力以及利用领域知识进行基于属性的图生成。 |
| [^45] | [DomainLab: A modular Python package for domain generalization in deep learning](https://arxiv.org/abs/2403.14356) | DomainLab是一个模块化Python包，允许用户训练指定的神经网络，并以组合的形式应用不同的正则化损失项，极大地方便了实验的可重现性。 |
| [^46] | [DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video Analytics](https://arxiv.org/abs/2403.14353) | 该论文提出了一种在自主系统中加速视频分析的持续学习方法，通过利用轻量级“学生”模型进行部署推理，利用更大的“教师”模型进行数据标记，实现对不断变化场景的持续自适应。 |
| [^47] | [Exploring Task Unification in Graph Representation Learning via Generative Approach](https://arxiv.org/abs/2403.14340) | 通过提出GA^2E，一个统一的框架，通过统一的生成式半监督学习，在单个训练阶段中实现了图生成、图判别和图预测任务。 |
| [^48] | [$\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning](https://arxiv.org/abs/2403.14339) | $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。 |
| [^49] | [A Differentially Private Clustering Algorithm for Well-Clustered Graphs](https://arxiv.org/abs/2403.14332) | 提出了一种面向良好聚类图的差分隐私聚类算法，适用于具有k个几乎平衡集群的图，误分类比率接近最佳非私有算法的水平 |
| [^50] | [Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression](https://arxiv.org/abs/2403.14328) | 通过梯度提升机和符号回归等技术，将神经网络的强化学习策略转化为更可解释的形式，提高了机器人运动策略的透明度和可理解性。 |
| [^51] | [Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes](https://arxiv.org/abs/2403.14327) | 本研究探讨了结构学习算法在识别影响糖尿病进展的风险因素方面的有效性，并强调算法选择对干预结果的重大影响。 |
| [^52] | [Neural Network-Based Processing and Reconstruction of Compromised Biophotonic Image Data](https://arxiv.org/abs/2403.14324) | 利用深度学习模型补偿生物光子图像数据受损，提升生物成像的时间分辨率和降低成本/尺寸。 |
| [^53] | [SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks](https://arxiv.org/abs/2403.14302) | 提出了一种新型脉冲自注意机制DSSA以及结合ResNet的多阶段架构的SpikingResformer架构，旨在改善性能和能效，并减少参数。 |
| [^54] | [Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications](https://arxiv.org/abs/2403.14297) | 本研究评估了在地球观测应用中缺失数据对训练模型的影响，发现集成策略可以实现高达100%的预测稳健性，同时揭示了缺失情景在回归任务中比分类任务更具挑战性，且光学视角是最关键的。 |
| [^55] | [Exploring Green AI for Audio Deepfake Detection](https://arxiv.org/abs/2403.14290) | 该研究提出了一个可以利用标准CPU资源训练的音频深度伪造检测新框架，以解决使用高性能计算和长训练时间带来的碳排放问题。 |
| [^56] | [Assessing the Robustness of Spectral Clustering for Deep Speaker Diarization](https://arxiv.org/abs/2403.14286) | 评估了在不同领域数据集下光谱聚类对说话人分离稳健性的影响，发现说话人分离性能差异源于光谱聚类的作用和参数不匹配。 |
| [^57] | [How to be fair? A study of label and selection bias](https://arxiv.org/abs/2403.14282) | 研究探讨数据偏见如何影响模型公平性，提出了建立偏见类型与缓解技术有效性之间关系的方法 |
| [^58] | [Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection](https://arxiv.org/abs/2403.14270) | 提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。 |
| [^59] | [Diffusion Models with Ensembled Structure-Based Anomaly Scoring for Unsupervised Anomaly Detection](https://arxiv.org/abs/2403.14262) | 本研究探讨了使用结构相似度(SSIM)作为异常检测中的评分函数，通过自适应集成策略为不同病理学提供更具病理学普适性的评分机制。 |
| [^60] | [ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification](https://arxiv.org/abs/2403.14255) | ERD提出了一个框架，通过提取与认知失调相关的部分和通过多个代理人进行推理步骤的辩论，改进了基于LLM的认知失调分类性能。 |
| [^61] | [LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding](https://arxiv.org/abs/2403.14252) | 提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。 |
| [^62] | [Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering](https://arxiv.org/abs/2403.14244) | 提出使用同性质高斯核替代各向异性核来提高计算性能，在不失去几何表示准确性的情况下实现约100倍的加速，适用于多种需要辐射场的应用领域。 |
| [^63] | [A Unified Framework for Model Editing](https://arxiv.org/abs/2403.14236) | 这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。 |
| [^64] | [RG-CAT: Detection Pipeline and Catalogue of Radio Galaxies in the EMU Pilot Survey](https://arxiv.org/abs/2403.14235) | 通过Gal-DINO计算机视觉网络，我们建立了EMU Pilot Survey中的射电星系目录，可高效预测无线电源形态、位置和红外主机信息。 |
| [^65] | [SoftPatch: Unsupervised Anomaly Detection with Noisy Data](https://arxiv.org/abs/2403.14233) | 首次考虑图像传感器异常检测中的标签级别噪声，并提出了一种能够有效去噪补丁级别数据的无监督异常检测方法SoftPatch。 |
| [^66] | [Contrastive Balancing Representation Learning for Heterogeneous Dose-Response Curves Estimation](https://arxiv.org/abs/2403.14232) | 通过理论证明了平衡和预后表示对于无偏估计的重要性，提出了一种对比平衡表示学习方法。 |
| [^67] | [Recovering Latent Confounders from High-dimensional Proxy Variables](https://arxiv.org/abs/2403.14228) | 提出了一种新颖的代理混淆因子分解 (PCF) 框架，用于处理高维混合代理变量来估计连续处理效应，实验证明在高样本大小情况下，该方法在因果效果估计中表现出较高的相关性和较低的误差。 |
| [^68] | [Posterior concentrations of fully-connected Bayesian neural networks with general priors on the weights](https://arxiv.org/abs/2403.14225) | 本文提出了一种新的近似理论，表明具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型。 |
| [^69] | [Debiasing surgeon: fantastic weights and how to find them](https://arxiv.org/abs/2403.14200) | 证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。 |
| [^70] | [OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.14183) | 通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。 |
| [^71] | [Policy Mirror Descent with Lookahead](https://arxiv.org/abs/2403.14156) | 提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。 |
| [^72] | [Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond](https://arxiv.org/abs/2403.14151) | 本文综述了深度学习在轨迹数据管理与挖掘中的发展和最新进展，探讨了其在预处理、存储、分析、预测、推荐、分类、估计和检测等方面的应用。 |
| [^73] | [Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition](https://arxiv.org/abs/2403.14148) | 提出了一种高效视频扩散模型CMD，通过预训练图像扩散模型和新的轻量级扩散模型生成内容帧和动态潜表示，以解决高内存和计算要求的问题。 |
| [^74] | [Learning Decomposable and Debiased Representations via Attribute-Centric Information Bottlenecks](https://arxiv.org/abs/2403.14140) | 提出了一种新颖的去偏见框架，引入基于注意力的信息瓶颈，用于学习属性的组合表示，而无需定义特定的偏见类型 |
| [^75] | [Genetic Programming for Explainable Manifold Learning](https://arxiv.org/abs/2403.14139) | 遗传规划方法提出了用于可解释流形学习的新方法，帮助解决当前流形学习中功能映射不明确的挑战。 |
| [^76] | [Improving Image Classification Accuracy through Complementary Intra-Class and Inter-Class Mixup](https://arxiv.org/abs/2403.14137) | 通过提出一种新的mixup方法，该方法针对类内混合进行了优化，提高了图像分类准确性。 |
| [^77] | [Learning causal graphs using variable grouping according to ancestral relationship](https://arxiv.org/abs/2403.14125) | 使用分治方法将变量分组，按照条件独立关系学习因果图，以提高在样本量较小的情况下的估算准确性。 |
| [^78] | [AI and Memory Wall](https://arxiv.org/abs/2403.14123) | 这项研究分析了AI应用中内存带宽成为主要瓶颈的问题，并提出了对模型架构、训练和部署策略进行重新设计的观点。 |
| [^79] | [Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning](https://arxiv.org/abs/2403.14120) | 联邦学习在工业物联网中的应用促进了机器学习和数据隐私，本文提出了一种用于提升PIUs性能的迭代幅值剪枝技术。 |
| [^80] | [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) | 本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。 |
| [^81] | [HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic Encryption](https://arxiv.org/abs/2403.14111) | HETAL提出了一种高效的基于同态加密的迁移学习算法，在训练中保护客户隐私，实现了加密训练的准确性，提供了高效的加密矩阵乘法算法。 |
| [^82] | [Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method](https://arxiv.org/abs/2403.14110) | HAAM-RL方法结合了启发式算法动作屏蔽和集成推断方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题，实验结果表明取得了16.25%的性能提升。 |
| [^83] | [DouRN: Improving DouZero by Residual Neural Networks](https://arxiv.org/abs/2403.14102) | 通过在DouZero模型中引入残差网络，并探索不同的架构设计，我们显著提高了斗地主游戏中获胜率。 |
| [^84] | [Text-Enhanced Data-free Approach for Federated Class-Incremental Learning](https://arxiv.org/abs/2403.14101) | 通过使用预训练语言模型产生的标签文本嵌入，本文提出了一种称为LANDER的方法，即面向联邦类增量学习的无数据方法，以解决DFKT在生成高质量数据时遇到的困难。 |
| [^85] | [Carbon Footprint Reduction for Sustainable Data Centers in Real-Time](https://arxiv.org/abs/2403.14092) | 我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。 |
| [^86] | [Protein Conformation Generation via Force-Guided SE(3) Diffusion Models](https://arxiv.org/abs/2403.14088) | 本文提出了一种力引导SE(3)扩散模型ConfDiff，用于蛋白质构象生成，通过结合力引导网络与基于数据的分数模型，实现了对蛋白质构象的准确生成。 |
| [^87] | [Learning-based Multi-continuum Model for Multiscale Flow Problems](https://arxiv.org/abs/2403.14084) | 提出了一种基于学习的多连续体模型，用于改进多尺度问题中单一连续体模型的准确性 |
| [^88] | [emoDARTS: Joint Optimisation of CNN & Sequential Neural Network Architectures for Superior Speech Emotion Recognition](https://arxiv.org/abs/2403.14083) | emoDARTS通过联合优化CNN和顺序神经网络架构，提升了语音情感识别性能。 |
| [^89] | [Improving $\Lambda$ Signal Extraction with Domain Adaptation via Normalizing Flows](https://arxiv.org/abs/2403.14076) | 通过归一化流进行领域自适应，成功改进了$\Lambda$信号提取，减少了对分类器输出切割线的依赖性 |
| [^90] | [M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain Multi-Hop Dense Sentence Retrieval](https://arxiv.org/abs/2403.14074) | M3是一个多任务混合目标学习框架，旨在解决仅依赖对比学习可能导致的次优检索性能问题，并取得了在FEVER数据集上的最先进性能。 |
| [^91] | [Sampling Audit Evidence Using a Naive Bayes Classifier](https://arxiv.org/abs/2403.14069) | 该研究通过将机器学习与抽样技术相结合，提出了使用朴素贝叶斯分类器对审计证据进行抽样的方法，以避免抽样偏差，保持随机性和变异性，并针对更有风险的样本。 |
| [^92] | [Automatic Outlier Rectification via Optimal Transport](https://arxiv.org/abs/2403.14067) | 提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务 |
| [^93] | [DiffSTOCK: Probabilistic relational Stock Market Predictions using Diffusion Models](https://arxiv.org/abs/2403.14063) | 提出了一种使用扩散模型进行概率关系型股市预测的方法，能更好地处理金融数据中的不确定性。 |
| [^94] | [Hypothesis-Driven Deep Learning for Out of Distribution Detection](https://arxiv.org/abs/2403.14058) | 本论文提出了一种基于假设的深度学习方法，用于量化新样本是否属于内部分布或外部分布，在高风险应用中如医疗保健领域具有重要意义。 |
| [^95] | [Towards a connection between the capacitated vehicle routing problem and the constrained centroid-based clustering](https://arxiv.org/abs/2403.14013) | 该论文探讨了容量车辆路径问题（CVRP）和约束中心基础聚类（CCBC）之间的联系，将CVRP简化为CCBC相当于使用常见的聚类算法将从指数复杂性转换为多项式复杂性。 |
| [^96] | [Multi-Modal Hallucination Control by Visual Information Grounding](https://arxiv.org/abs/2403.14003) | 引入了一种新的抽样方法M3ID来减少生成式视觉-语言模型中的幻觉，通过放大参考图像对语言先验的影响，从而更好地生成与视觉提示相关的标记。 |
| [^97] | [Uncertainty Driven Active Learning for Image Segmentation in Underwater Inspection](https://arxiv.org/abs/2403.14002) | 本研究探讨了在水下基础设施检测中应用主动学习进行图像分割的潜力，通过使用互信息和蒙特卡洛dropout计算来提高模型效果，在管道检测数据集上取得显著改进。 |
| [^98] | [Considerations in the use of ML interaction potentials for free energy calculations](https://arxiv.org/abs/2403.13952) | 该研究探讨了机器学习势在自由能计算中的应用，重点关注使用等变性图神经网络MLPs来准确预测自由能和过渡态，考虑到分子构型的能量和多样性。 |
| [^99] | [Evo* 2023 -- Late-Breaking Abstracts Volume](https://arxiv.org/abs/2403.13950) | Evo* 2023会议收录了关于将不同的生物启发方法（主要是进化计算）应用于解决不同问题（大多为现实世界问题）的研究和初步结果。 |
| [^100] | [Multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers](https://arxiv.org/abs/2403.13940) | 本文提出了一种多阶段集成方法，通过多标准分析选择单个反事实，避免了用户测试多种不同解释方法和分析冲突解决方案的困难，提供了一个在多个质量度量上得分很高的妥协方案。 |
| [^101] | [Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification](https://arxiv.org/abs/2403.13925) | 本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。 |
| [^102] | [Enhancing Fingerprint Image Synthesis with GANs, Diffusion Models, and Style Transfer Techniques](https://arxiv.org/abs/2403.13916) | 本研究提出了一种结合生成对抗网络、扩散模型和风格转移技术的方法，用于合成高质量的真实和伪造指纹图像，保留了指纹的独特性和多样性。 |
| [^103] | [Augmented Reality Demonstrations for Scalable Robot Imitation Learning](https://arxiv.org/abs/2403.13910) | 通过增强现实演示框架，本论文提出了一种创新方法，使非机器人专家用户能够为机器人模仿学习提供演示，实现了可扩展且多样化的演示收集。 |
| [^104] | [Sequential Modeling of Complex Marine Navigation: Case Study on a Passenger Vessel (Student Abstract)](https://arxiv.org/abs/2403.13909) | 该研究利用机器学习方法对船舶燃油消耗进行建模，创造了预测动态状态的时间序列模型，成为评估船舶运营熟练程度和未来优化算法的基础。 |
| [^105] | [Data Acquisition via Experimental Design for Decentralized Data Markets](https://arxiv.org/abs/2403.13893) | 我们提出了一个受线性实验设计启发的联邦方法，用于在数据市场中选择最有价值的数据点，并实现更低的预测误差，无需标记的验证数据，更适用于去中心化市场设置。 |
| [^106] | [Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models](https://arxiv.org/abs/2403.13890) | 提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。 |
| [^107] | [Spatial-Temporal Graph Representation Learning for Tactical Networks Future State Prediction](https://arxiv.org/abs/2403.13872) | 本文提出了一种空间-时间图编码器-解码器（STGED）框架，用于战术通信网络，通过有效利用网络状态的空间和时间特征，实现了对未来状态的准确预测。 |
| [^108] | [ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations](https://arxiv.org/abs/2403.13870) | ExMap 是一种无监督群体鲁棒性策略，利用可解释性热图推断模型的分类策略，通过聚类模块推断伪标签来增强传统分类器的鲁棒性。 |
| [^109] | [Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems](https://arxiv.org/abs/2403.13869) | 该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。 |
| [^110] | [Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations](https://arxiv.org/abs/2403.13868) | 本文通过随机递归方程的概率框架，研究了随机梯度下降的重尾特性，并通过i-p矩阵理论扩展了G\"{u}rb\"{u}zbalaban等人的结果。 |
| [^111] | [Capsule Neural Networks as Noise Stabilizer for Time Series Data](https://arxiv.org/abs/2403.13867) | Capsule神经网络在分析时间序列传感器数据时展现出良好的噪声鲁棒性，通过实证研究得出其作为噪声稳定器的有效性，击败了原始的卷积神经网络。 |
| [^112] | [The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training](https://arxiv.org/abs/2403.13866) | 本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。 |
| [^113] | [Graph Neural Network for Crawling Target Nodes in Social Networks](https://arxiv.org/abs/2403.13865) | 本文采用图神经网络应用于社交网络中的目标节点爬取，表明其在个别案例中优于传统分类器，并提出了训练样本增强技术以改进预测器质量。 |
| [^114] | [Optimal Transport for Fairness: Archival Data Repair using Small Research Data Sets](https://arxiv.org/abs/2403.13864) | 本文提出了使用小型研究数据集进行公平性的最优运输修复历史数据的方法，通过设计基于最优运输的修复方案来减小支持大小，实现成本节约和对离样本数据的修复。 |
| [^115] | [DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model](https://arxiv.org/abs/2403.13863) | 提出了DiffImpute，一种基于去噪扩散概率模型的表格数据插补方法，可以有效处理不同类型的缺失数据，并通过定制多个表格去噪网络来增强插补的一致性。 |
| [^116] | [Machine Learning-based Layer-wise Detection of Overheating Anomaly in LPBF using Photodiode Data](https://arxiv.org/abs/2403.13861) | 本研究提出了一种利用光电二极管数据进行逐层检测LPBF中过热异常的机器学习框架，并通过成本敏感学习处理类别不平衡问题。 |
| [^117] | [A conditional latent autoregressive recurrent model for generation and forecasting of beam dynamics in particle accelerators](https://arxiv.org/abs/2403.13858) | 提出了一个名为CLARM的两步无监督深度学习框架，用于学习加速器中带电粒子的时空动态，并能够生成不同加速器模块的投影和预测粒子的未来状态。 |
| [^118] | [Control of Medical Digital Twins with Artificial Neural Networks](https://arxiv.org/abs/2403.13851) | 介绍了一种使用神经网络方法来控制医学数字孪生体的方法 |
| [^119] | [Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance](https://arxiv.org/abs/2403.13850) | 该论文提出了ST-PAD框架，通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测，在多个基准数据集上的实验证明其优于当前主流模型 |
| [^120] | [Graphs Unveiled: Graph Neural Networks and Graph Generation](https://arxiv.org/abs/2403.13849) | 该论文综述了图神经网络（GNNs）在各个领域的应用，并介绍了GNNs中的先进领域：图生成。 |
| [^121] | [Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists](https://arxiv.org/abs/2403.13848) | 通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。 |
| [^122] | [Optimal Transport for Domain Adaptation through Gaussian Mixture Models](https://arxiv.org/abs/2403.13847) | 通过高斯混合模型进行域自适应的最优输运，可以实现源域和目标域混合成分之间的匹配，从而在失效诊断中取得最先进的性能。 |
| [^123] | [A Clustering Method with Graph Maximum Decoding Information](https://arxiv.org/abs/2403.13846) | CMDI聚类方法创新性地将二维结构信息理论融入聚类过程中，弥补了基于图的模型聚类方法中忽略的随机游走访问节点和数据中嵌入的结构信息的不确定性。 |
| [^124] | [Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis](https://arxiv.org/abs/2403.13845) | 提出了增量式ZSFD范式，开发了广深混合反遗忘框架（BDMAFF），旨在学习和适应新的故障类别和属性，解决了现有ZSFD范式在工业场景中无法从不断变化的训练数据流中学习的问题。 |
| [^125] | [Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces](https://arxiv.org/abs/2403.13844) | 低维度计算分类器基于向量符号体系结构（VSA），通过定时知识获取方法，提高小模型准确率，解决处理复杂脑信号的挑战。 |
| [^126] | [Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review](https://arxiv.org/abs/2403.13843) | 该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。 |
| [^127] | [Analyzing the Variations in Emergency Department Boarding and Testing the Transferability of Forecasting Models across COVID-19 Pandemic Waves in Hong Kong: Hybrid CNN-LSTM approach to quantifying building-level socioecological risk](https://arxiv.org/abs/2403.13842) | 对香港急诊室候诊时间变化进行分析，通过混合CNN-LSTM模型探讨预测模型的可传递性，在COVID-19大流行期间观察到波次四和五之间出现最多的ED候诊天数，并发现在波次四和五之间出现表现最佳的预测模型。 |
| [^128] | [Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting](https://arxiv.org/abs/2403.13841) | 本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。 |
| [^129] | [depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers](https://arxiv.org/abs/2403.13839) | depyf是一个非侵入性和用户友好的工具，旨在帮助机器学习研究者揭开PyTorch编译器的内部工作机制，并通过反编译将字节码转换为源代码，从而增进用户对底层过程的理解。 |
| [^130] | [Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate](https://arxiv.org/abs/2403.13838) | 本研究探索了通过预测下一个逻辑门来实现电路设计的可能性。 |
| [^131] | [Tree-based Learning for High-Fidelity Prediction of Chaos](https://arxiv.org/abs/2403.13836) | TreeDOX是一种基于树的方法，不需要超参数调整，使用时间延迟过度嵌入和额外树回归器进行特征降维和预测，并在深度预测混沌系统中表现出state-of-the-art的性能。 |
| [^132] | [SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees](https://arxiv.org/abs/2403.13835) | 提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。 |
| [^133] | [Few-shot Learning on Heterogeneous Graphs: Challenges, Progress, and Prospects](https://arxiv.org/abs/2403.13834) | 异质图上的少样本学习面临标签稀疏性问题，本文系统综述了FLHG方法，研究了单一、双重和多重异质性FLHG，并探讨了未来研究方向。 |
| [^134] | [Linearly Constrained Weights: Reducing Activation Shift for Faster Training of Neural Networks](https://arxiv.org/abs/2403.13833) | 神经网络中引入线性约束权重（LCW）来减少激活偏移，有效解决了梯度消失问题，提高了深度前向网络的训练效率。 |
| [^135] | [Bridging Text and Molecule: A Survey on Multimodal Frameworks for Molecule](https://arxiv.org/abs/2403.13830) | 本文首次系统调研了针对分子研究的多模态框架，重点讨论了文本与分子之间的关联、不同模型架构和预训练任务。同时还深入探讨了大型语言模型以及提示技术在分子领域中的应用。 |
| [^136] | [DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization](https://arxiv.org/abs/2403.13829) | 提出了一种基于可控分解扩散模型的结构化分子优化方法 |
| [^137] | [Self-Supervised Path Planning in UAV-aided Wireless Networks based on Active Inference](https://arxiv.org/abs/2403.13827) | 提出一种基于主动推理的自监督路径规划方法，使得无人机能够通过世界模型和主动推理进行实时自主决策和在线规划，有助于更快地适应新情况，并表现优于传统RL。 |
| [^138] | [Measuring Diversity in Co-creative Image Generation](https://arxiv.org/abs/2403.13826) | 提出了一种基于神经网络编码熵的方法，以比较图像集合之间的多样性，而无需真实标准知识且易于计算，并展示了不同预训练网络选择对我们要评估的多样性概念的影响。 |
| [^139] | [Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation](https://arxiv.org/abs/2403.13825) | 该论文提出了一种新的几何感知生成模型IEA-GAN，以及一种迎接下游物理分析挑战的YonedaVAE模型，为超高细粒度粒子物理探测器模拟提供了重要的解决方案。 |
| [^140] | [Offensive Lineup Analysis in Basketball with Clustering Players Based on Shooting Style and Offensive Role](https://arxiv.org/abs/2403.13821) | 本研究通过使用投篮风格聚类和基于注释的进攻角色聚类，更专门地分析了比赛风格兼容性对得分效率的影响，集中在进攻端。 |
| [^141] | [Identity information based on human magnetocardiography signals](https://arxiv.org/abs/2403.13820) | 该研究开发了一个基于人类磁心图信号的个人识别系统，利用空间信息和CNN分类技术，取得了97.04%的准确率。 |
| [^142] | [A machine learning approach to predict university enrolment choices through students' high school background in Italy](https://arxiv.org/abs/2403.13819) | 通过意大利高中学生的高中背景来预测大学录取选择，研究发现高中成就对录取选择有显著影响。 |
| [^143] | [Autonomous microARPES](https://arxiv.org/abs/2403.13815) | 使用高斯过程回归，实现了自主搜索$\mathbf{k}$和实空间，以在微型ARPES实验中找到感兴趣位置。 |
| [^144] | [Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool](https://arxiv.org/abs/2403.13812) | 论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。 |
| [^145] | [PyVRP: a high-performance VRP solver package](https://arxiv.org/abs/2403.13795) | PyVRP是一个实现混合遗传搜索作为最先进的车辆路径问题（VRP）求解器的Python包，在多个竞赛中取得了第一名，结合了Python的灵活性和C++的性能，代码质量高且在VRPTW和有容量限制的VRP问题上达到了最好的结果。 |
| [^146] | [Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark](https://arxiv.org/abs/2403.13502) | 该研究通过评估在自动控制系统中部署的深度学习模型对抗性攻击的脆弱性和不同防御策略的有效性，提出了结合多种防御方法的新颖保护方法，并为确保工业中的稳健故障诊断提供了见解。 |
| [^147] | [Arcee's MergeKit: A Toolkit for Merging Large Language Models](https://arxiv.org/abs/2403.13257) | 合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。 |
| [^148] | [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](https://arxiv.org/abs/2403.13213) | 本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。 |
| [^149] | [FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer](https://arxiv.org/abs/2403.12821) | FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。 |
| [^150] | [Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints](https://arxiv.org/abs/2403.06906) | 提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题 |
| [^151] | [A Geospatial Approach to Predicting Desert Locust Breeding Grounds in Africa](https://arxiv.org/abs/2403.06860) | 该研究开发了一个地理空间模型，用于预测沙漠蝗虫的繁殖地，有望提升早期预警系统和有针对性的控制措施。 |
| [^152] | [Unraveling the Mystery of Scaling Laws: Part I](https://arxiv.org/abs/2403.06563) | 确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战 |
| [^153] | [MedMamba: Vision Mamba for Medical Image Classification](https://arxiv.org/abs/2403.03849) | 提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。 |
| [^154] | [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](https://arxiv.org/abs/2403.02302) | 本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。 |
| [^155] | [OSCaR: Object State Captioning and State Change Representation](https://arxiv.org/abs/2402.17128) | 本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。 |
| [^156] | [Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data](https://arxiv.org/abs/2402.12190) | 提出了一种基于机器学习的框架，用于个性化反事实癌症治疗建议，集成了多种多组学技术的专家，可提供优越性能和决策解释。 |
| [^157] | [On the Privacy of Selection Mechanisms with Gaussian Noise](https://arxiv.org/abs/2402.06137) | 该论文研究了带有高斯噪声的选择机制的隐私问题，并证明了在底层查询是有界的情况下，可以提供纯粹的前期和后期差分隐私界限。 |
| [^158] | [EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models](https://arxiv.org/abs/2402.03049) | EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。 |
| [^159] | [DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging](https://arxiv.org/abs/2402.02622) | DenseFormer是对Transformer的简单修改，通过在每个transformer块之后进行深度加权平均，提高了模型的困惑度。学到的加权平均权重揭示了信息流的连贯模式，使得DenseFormer具有更高的数据效率，并且在相同困惑度下胜过传统的Transformer模型。 |
| [^160] | [SLIM: Skill Learning with Multiple Critics](https://arxiv.org/abs/2402.00823) | SLIM是一种多判别器学习方法，通过在机器人操作中组合多个判别器的奖励函数，显著改善了潜变量技能发现，克服了奖励之间的干扰。 |
| [^161] | [Graph Edits for Counterfactual Explanations: A comparative study](https://arxiv.org/abs/2401.11609) | 研究通过比较监督和无监督的图神经网络方法，扩展了图编辑作为反事实解释的先前努力，探讨了将输入数据表示为图形对于生成黑箱图像分类器最小且有意义的反事实解释的性能和时间效率最佳的方法。 |
| [^162] | [Synthetic Data Applications in Finance](https://arxiv.org/abs/2401.00081) | 合成数据在金融领域的广泛应用，涉及各种不同数据类型，有助于解决隐私、公平性和可解释性相关问题，对其质量和效果进行了评估，并探讨了未来发展方向。 |
| [^163] | [The LLM Surgeon](https://arxiv.org/abs/2312.17244) | 通过数据驱动压缩现有预训练模型，我们提供了一个改进权重更新的通用框架，以更有效地捕捉更多权重之间的相关性，同时保持计算效率。 |
| [^164] | [On the convergence of loss and uncertainty-based active learning algorithms](https://arxiv.org/abs/2312.13927) | 论文考虑了损失和不确定性基础的主动学习算法在线性分类器和线性可分数据集上的收敛速度，提出了一种新算法并展示了其效率。 |
| [^165] | [Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data](https://arxiv.org/abs/2312.10569) | 提出了一种适用于分布数据分析的可解释方法 ADD MALTS，有助于确保可靠和稳健的决策制定，能够优于其他方法估计处理效果 |
| [^166] | [Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs against Query-Based Attacks](https://arxiv.org/abs/2312.10132) | 本研究通过激活专门的防御措施，如随机噪声防御和随机图像变换，只针对低置信度的输入，在测试阶段实现了鲁棒性和准确性之间的有效权衡，从而改善了各种现有防御措施。 |
| [^167] | [Weighted Ensemble Models Are Strong Continual Learners](https://arxiv.org/abs/2312.08977) | 通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。 |
| [^168] | [Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training](https://arxiv.org/abs/2312.02914) | 该方法提出了UNITE框架，利用图像教师模型和视频学生模型进行遮蔽预训练和协作自训练，在多个视频领域自适应基准上取得显著改进的结果。 |
| [^169] | [Working Backwards: Learning to Place by Picking](https://arxiv.org/abs/2312.02352) | 通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。 |
| [^170] | [LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding](https://arxiv.org/abs/2311.15876) | RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。 |
| [^171] | [Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections](https://arxiv.org/abs/2311.10678) | 本研究提出了一种基于大型语言模型的系统，名为DROC，能够回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进机器人操作的性能。 |
| [^172] | [TD-MPC2: Scalable, Robust World Models for Continuous Control](https://arxiv.org/abs/2310.16828) | TD-MPC2是对TD-MPC算法的一系列改进，通过一组超参数在104个在线RL任务中取得了显著进展，成功训练单一的317M参数代理执行80个任务。 |
| [^173] | [Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient Method](https://arxiv.org/abs/2310.14525) | 图对比学习（GCL）作为一种代表性的图自监督方法，提出了一种旨在减轻假阴性影响的极其简单而有效的方法。 |
| [^174] | [Assessing the Causal Impact of Humanitarian Aid on Food Security](https://arxiv.org/abs/2310.11287) | 本研究通过因果推断框架评估人道主义援助对粮食危机的影响，结果表明在粮食安全系统内，人道主义干预对营养不良有显著影响。 |
| [^175] | [Modality-aware Transformer for Financial Time series Forecasting](https://arxiv.org/abs/2310.01232) | 提出了一种新颖的模态感知Transformer模型，能够有效地利用分类文本和数值时间序列的信息来预测金融时间序列，并通过神经注意力机制提供有价值的见解。 |
| [^176] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^177] | [Effective Structured Prompting by Meta-Learning and Representative Verbalizer](https://arxiv.org/abs/2306.00618) | 通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法 |
| [^178] | [A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective](https://arxiv.org/abs/2302.13425) | 本研究对深度学习的不确定性量化进行了调查，从不确定性来源的角度分析不同方法，以评估DNN预测的置信度。 |
| [^179] | [Toward a Theory of Causation for Interpreting Neural Code Models](https://arxiv.org/abs/2302.03788) | 该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。 |
| [^180] | [Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access](https://arxiv.org/abs/2302.01385) | 提出了Antigone框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器，通过生成伪敏感属性来实现。 |
| [^181] | [AI-KD: Adversarial learning and Implicit regularization for self-Knowledge Distillation](https://arxiv.org/abs/2211.10938) | 提出了一种名为AI-KD的对抗学习和隐式正则化自知识蒸馏的方法，通过对抗学习和隐式蒸馏规范训练过程，使得学生模型可以从预训练和先前时期的预测概率中蒸馏确定性和渐进式知识，同时通过对抗学习传输确定性预测分布的知识。 |
| [^182] | [Hub-aware Random Walk Graph Embedding Methods for Classification](https://arxiv.org/abs/2209.07603) | 提出了两种基于随机游走的新颖图嵌入算法，专门为节点分类问题而设计，并针对hub节点设计了特殊的采样策略。 |
| [^183] | [A Non-Parametric Bootstrap for Spectral Clustering](https://arxiv.org/abs/2209.05812) | 开发了两种新的算法，结合了数据矩阵的谱分解和非参数自举抽样方案，解决了谱聚类中收敛到次优解的问题，并展示出了其在估计有限混合模型时的优越性。 |
| [^184] | [Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction](https://arxiv.org/abs/2209.00568) | 提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能 |
| [^185] | [Differentially Private Linear Bandits with Partial Distributed Feedback](https://arxiv.org/abs/2207.05827) | 该论文研究了具有部分分布式反馈的差分私有线性Bandits，在隐私保护的前提下实现了全局奖励的最大化 |
| [^186] | [Don't Explain Noise: Robust Counterfactuals for Randomized Ensembles](https://arxiv.org/abs/2205.14116) | 本研究研究了随机集成的解释的稳健性，提出了一种生成稳健反事实解释的概率方法，展示了集成模型稳健性与基学习器稳健性之间的联系，并为凸基学习器的集成提供了实用方法和理论保证。 |
| [^187] | [On the consistency of supervised learning with missing values](https://arxiv.org/abs/1902.06931) | 两种方法在带缺失值的监督学习中表现出一致性，当缺失值不具信息性时，使用常数进行插补是一种简单且重要的实践方法。 |
| [^188] | [Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning.](http://arxiv.org/abs/2401.12648) | 本文提出了一种基于一致性增强的深度多视图聚类方法通过对比学习（CCEC）。该方法通过引入语义连接块并入特征表示中，以保持多个视图间的一致信息，并通过谱聚类改善聚类的表示过程。实验结果显示，该方法在多个数据集上的表现优于其他现有方法。 |
| [^189] | [Emergent Dominance Hierarchies in Reinforcement Learning Agents.](http://arxiv.org/abs/2401.12258) | 本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。 |
| [^190] | [Weighted least-squares approximation with determinantal point processes and generalized volume sampling.](http://arxiv.org/abs/2312.14057) | 该论文研究了使用行列式点过程和广义体积取样进行加权最小二乘逼近的问题，提出了广义版本的体积标准化取样算法，并证明了该算法在期望上的准最优性以及在某些规范向量空间中的逼近结果。 |
| [^191] | [Let's do the time-warp-attend: Learning topological invariants of dynamical systems.](http://arxiv.org/abs/2312.09234) | 该论文提出了一个数据驱动、基于物理信息的深度学习框架，用于分类和表征动力学变化的拓扑不变特征提取，特别关注超临界霍普分歧。这个方法可以帮助预测系统的质变和常发行为变化。 |
| [^192] | [$\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks.](http://arxiv.org/abs/2311.18744) | 本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。 |
| [^193] | [RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization.](http://arxiv.org/abs/2311.01753) | RiskQ是一种解决多智能体强化学习中风险敏感协调要求的方法，通过引入风险敏感的个体-全局最大（RIGM）原则和建模联合回报分布实现价值因子分解。 |
| [^194] | [VQPy: An Object-Oriented Approach to Modern Video Analytics.](http://arxiv.org/abs/2311.01623) | VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。 |
| [^195] | [Efficient Subgraph GNNs by Learning Effective Selection Policies.](http://arxiv.org/abs/2310.20082) | 本文通过学习有效的选择策略提高了子图图神经网络的效率，并且实验证明该方法优于现有的基准方法。 |
| [^196] | [TiC-CLIP: Continual Training of CLIP Models.](http://arxiv.org/abs/2310.16226) | 该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。 |
| [^197] | [Exact and efficient solutions of the LMC Multitask Gaussian Process model.](http://arxiv.org/abs/2310.12032) | LMC多任务高斯过程模型的精确解决方案表明，只需对噪声模型进行温和假设，即可实现高效计算。通过引入完整参数化的“投影LMC”模型和边缘似然函数表达式，展示了该方法相对于未经处理的方法的优异性能。 |
| [^198] | [Self-supervised Representation Learning From Random Data Projectors.](http://arxiv.org/abs/2310.07756) | 本文提出了一种无监督表示学习（SSRL）方法，通过重建随机数据投影来学习高质量的数据表示，不依赖于增强或掩蔽技术，可以应用于任何数据模态和网络架构。实验结果表明该方法在各种任务中优于其他SSRL算法。 |
| [^199] | [Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel.](http://arxiv.org/abs/2310.03054) | 本文提出了一种基于负距离核的最大平均距离(MMD)的条件流方法，用于后验抽样和条件生成建模。通过离散的Wasserstein梯度流近似联合分布，证明了粒子流是适当功能的Wasserstein梯度流。在条件图像生成和超分辨率等逆问题中展示了方法的有效性。 |
| [^200] | [QuATON: Quantization Aware Training of Optical Neurons.](http://arxiv.org/abs/2310.03049) | 提出一种光纤神经元的量化感知训练方法，通过考虑物理约束，实现了对光纤神经架构的鲁棒设计。 |
| [^201] | [ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF.](http://arxiv.org/abs/2310.02712) | ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。 |
| [^202] | [Learning to Make Adherence-Aware Advice.](http://arxiv.org/abs/2310.00817) | 本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。 |
| [^203] | [A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems.](http://arxiv.org/abs/2309.16584) | 我们开发了一个CDML设计工具箱，可以指导开发者设计满足用例要求的协作分布式机器学习系统。 |
| [^204] | [A Physics Enhanced Residual Learning (PERL) Framework for Traffic State Prediction.](http://arxiv.org/abs/2309.15284) | 这篇论文提出了一种名为物理增强残差学习（PERL）的框架，用于交通状态预测。PERL模型集成了物理模型和数据驱动模型的优势，通过将物理模型结果和预测残差作为修正相结合，具有可解释性，且比数据驱动方法要求更少的数据。 |
| [^205] | [Sequence-to-Sequence Spanish Pre-trained Language Models.](http://arxiv.org/abs/2309.11259) | 该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。 |
| [^206] | [Task Graph offloading via Deep Reinforcement Learning in Mobile Edge Computing.](http://arxiv.org/abs/2309.10569) | 本文研究了在移动边缘计算环境下通过深度强化学习实现任务图离载的问题。现有的工作往往无法适应环境变化，导致用户体验下降。我们提出了一种将任务图调度建模为马尔可夫决策过程的方法，以适应计算能力随时间变化的情况。 |
| [^207] | [Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation.](http://arxiv.org/abs/2309.06255) | 本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。 |
| [^208] | [Deep Reinforcement Learning from Hierarchical Weak Preference Feedback.](http://arxiv.org/abs/2309.02632) | 本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。 |
| [^209] | [TensorBank:Tensor Lakehouse for Foundation Model Training.](http://arxiv.org/abs/2309.02094) | TensorBank是一个基于Tensor的湖仓库，能够以高速从云对象存储流式传输张量到GPU内存，并通过使用分层统计指标进行查询加速。 |
| [^210] | [Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment.](http://arxiv.org/abs/2308.05374) | 本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。 |
| [^211] | [Generalized Early Stopping in Evolutionary Direct Policy Search.](http://arxiv.org/abs/2308.03574) | 本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。 |
| [^212] | [The Role of Transparency in Repeated First-Price Auctions with Unknown Valuations.](http://arxiv.org/abs/2307.09478) | 本文研究了一次性出价拍卖中透明度对遗憾最小化的影响，通过对拍卖透明度与环境特性的分析，揭示了在拍卖中学习最优出价的速度。 |
| [^213] | [QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules.](http://arxiv.org/abs/2306.09549) | 该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。 |
| [^214] | [TMI! Finetuned Models Leak Private Information from their Pretraining Data.](http://arxiv.org/abs/2306.01181) | 本文提出了一种新的会员推断威胁模型TMI，用于评估微调模型对预训练数据的泄露，突显了在使用预训练模型进行迁移学习中存在的隐私风险，并需要对机器学习中的隐私进行更严格的评估。 |
| [^215] | [From Tempered to Benign Overfitting in ReLU Neural Networks.](http://arxiv.org/abs/2305.15141) | 本论文通过对二层ReLU神经网络进行研究，证明了各种假设下过拟合的类型会从一维数据的极端情况下缓和到高维的良性，揭示了输入维度在神经网络过拟合中的关键作用。 |
| [^216] | [Identification of the Factors Affecting the Reduction of Energy Consumption and Cost in Buildings Using Data Mining Techniques.](http://arxiv.org/abs/2305.08886) | 本研究利用数据挖掘技术实现了对建筑物成本降低和能耗影响因素的识别，结果表明隔热、建筑物尺寸和制冷系统类型是影响能源消耗和成本降低的关键因素。 |
| [^217] | [Learning a Depth Covariance Function.](http://arxiv.org/abs/2303.12157) | 该论文提出了学习深度协方差函数，并利用该方法对深度补全、捆集调整和单目密集视觉里程计等几何视觉任务进行了处理。 |
| [^218] | [Mpox-AISM: AI-Mediated Super Monitoring for Forestalling Monkeypox Spread.](http://arxiv.org/abs/2303.09780) | 本文介绍了一种名为超级监测的远程实现猴痘早期诊断的策略。该策略以人工智能技术为基础，可实现高灵敏度和准确性的病症分类，同时成本低、易用性高，具有广泛的应用前景。 |
| [^219] | [Faster Predict-and-Optimize with Davis-Yin Splitting.](http://arxiv.org/abs/2301.13395) | 本文介绍了一种使用Davis-Yin分裂方法实现更快的预测与优化的方法，该方法借鉴了现代凸优化的思想，能够在具有数千个变量的问题上轻松扩展。 |
| [^220] | [Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with Riesz Kernels.](http://arxiv.org/abs/2301.11624) | 本文提出用神经网络逼近Jordan、Kinderlehrer和Otto的反向方案以及一种前向方案，用于计算非光滑Riesz核最大均值差异函数的Wasserstein梯度流。我们通过学习适当的损失函数来近似处理计划的分解，并在交互能上基准测量神经网络的质量。 |
| [^221] | [Time-Synchronized Full System State Estimation Considering Practical Implementation Challenges.](http://arxiv.org/abs/2212.01729) | 本研究提出了一种基于深度神经网络的状态估计器（DeNSE），利用贝叶斯框架综合利用慢速但广泛存在的SCADA数据和快速但局部的PMU数据，实现了对整个系统的亚秒级状态估计。通过考虑实际挑战，如拓扑变化、非高斯测量噪声和错误数据检测与校正，证明了DeNSE方法的优越性。 |
| [^222] | [Closing the gap between SVRG and TD-SVRG with Gradient Splitting.](http://arxiv.org/abs/2211.16237) | 本论文通过将TD学习视为适当选择函数的梯度分割，将TD和SVRG相结合，实现了具有几何收敛速度的策略评估方法，并在理论和实验上得到了支持。 |
| [^223] | [PGCN: Progressive Graph Convolutional Networks for Spatial-Temporal Traffic Forecasting.](http://arxiv.org/abs/2202.08982) | 这项研究提出了一种名为渐进图卷积网络（PGCN）的交通预测框架，通过在训练和测试阶段逐步适应输入数据来构建一组图，以解决交通预测中的复杂时空相关性和数据变化问题。 |

# 详细

[^1]: MathVerse：您的多模式LLM是否真正看到了视觉数学问题中的图表？

    MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?

    [https://arxiv.org/abs/2403.14624](https://arxiv.org/abs/2403.14624)

    MathVerse是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs在视觉数学问题解决中的能力。

    

    多模式大型语言模型（MLLMs）取得了显著进展，在视觉环境中表现出色，然而它们在视觉数学问题解决方面的能力仍未充分评估和理解。本研究调查了当前基准测试，将过多的视觉内容融入文本问题中，这有助于MLLM在不真正解释输入图表的情况下推导答案。为此，我们介绍了MathVerse，这是一个全方位的视觉数学基准测试，旨在公平而深入地评估MLLMs。我们精心收集了2,612个高质量的多学科数学问题，其中包含图表，来源于公开渠道。然后，每个问题由人工注释者转化为六个不同版本，每个版本在多模式中提供不同程度的信息内容，共贡献了15K个测试样本。这种方法使得MathVerse能够同时

    arXiv:2403.14624v1 Announce Type: cross  Abstract: The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to co
    
[^2]: 简化扩散薛定谔桥

    Simplified Diffusion Schr\"odinger Bridge

    [https://arxiv.org/abs/2403.14623](https://arxiv.org/abs/2403.14623)

    介绍了简化后的扩散薛定谔桥（DSB），通过与基于得分的生成模型（SGM）的统一解决了复杂数据生成中的限制，提高了性能并加快了收敛速度。

    

    这篇论文介绍了一种新的理论简化扩散薛定谔桥（DSB），便于将其与基于得分的生成模型（SGM）统一起来，解决了DSB在复杂数据生成方面的局限性，实现更快的收敛速度和增强的性能。通过将SGM作为DSB的初始解决方案，我们的方法利用了这两个框架的优势，确保了更高效的训练过程，并改进了SGM的性能。我们还提出了一种重新参数化技术，尽管存在理论近似，但实际上提高了网络的拟合能力。我们进行了大量的实验证实，证实了简化的DSB的有效性，展示了其显著的改进。我们相信这项工作的贡献为先进的生成建模铺平了道路。

    arXiv:2403.14623v1 Announce Type: new  Abstract: This paper introduces a novel theoretical simplification of the Diffusion Schr\"odinger Bridge (DSB) that facilitates its unification with Score-based Generative Models (SGMs), addressing the limitations of DSB in complex data generation and enabling faster convergence and enhanced performance. By employing SGMs as an initial solution for DSB, our approach capitalizes on the strengths of both frameworks, ensuring a more efficient training process and improving the performance of SGM. We also propose a reparameterization technique that, despite theoretical approximations, practically improves the network's fitting capabilities. Our extensive experimental evaluations confirm the effectiveness of the simplified DSB, demonstrating its significant improvements. We believe the contributions of this work pave the way for advanced generative modeling. The code is available at https://github.com/tzco/Simplified-Diffusion-Schrodinger-Bridge.
    
[^3]: Videoshop：具有噪声外推扩散反演的本地化语义视频编辑

    Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion

    [https://arxiv.org/abs/2403.14617](https://arxiv.org/abs/2403.14617)

    Videoshop是一个无需训练的视频编辑算法，通过图像为基础的方法实现了本地化语义编辑，从而允许用户对视频进行精细控制，取得了更高质量的编辑效果。

    

    我们介绍了Videoshop，这是一个无需训练的用于本地化语义编辑的视频编辑算法。Videoshop允许用户使用任何编辑软件，包括Photoshop和生成填充，修改第一帧；它会自动将这些更改传播到其余帧，保持语义、空间和时间上的一致运动。与现有方法只能通过不精确的文本指令进行编辑不同，Videoshop允许用户添加或删除对象，语义上更改对象，将素材照片插入视频等，并对位置和外观进行细粒度控制。我们通过对潜在值进行噪声外推反演的图像为基础的视频编辑来实现这一目标，从中我们生成根据编辑图像调整的视频。Videoshop在2个编辑基准测试中使用10个评估指标对6个基线取得了更高质量的编辑效果。

    arXiv:2403.14617v1 Announce Type: cross  Abstract: We introduce Videoshop, a training-free video editing algorithm for localized semantic edits. Videoshop allows users to use any editing software, including Photoshop and generative inpainting, to modify the first frame; it automatically propagates those changes, with semantic, spatial, and temporally consistent motion, to the remaining frames. Unlike existing methods that enable edits only through imprecise textual instructions, Videoshop allows users to add or remove objects, semantically change objects, insert stock photos into videos, etc. with fine-grained control over locations and appearance. We achieve this through image-based video editing by inverting latents with noise extrapolation, from which we generate videos conditioned on the edited image. Videoshop produces higher quality edits against 6 baselines on 2 editing benchmarks using 10 evaluation metrics.
    
[^4]: DreamReward: 文本到3D生成与人类偏好

    DreamReward: Text-to-3D Generation with Human Preference

    [https://arxiv.org/abs/2403.14613](https://arxiv.org/abs/2403.14613)

    DreamReward提出了一个名为DreamFL的框架，通过学习和改进文本到3D模型，基于人类偏好反馈创建了第一个通用的文本到3D人类偏好奖励模型，并引入了Reward3D反馈学习算法，成功生成高保真度和一致的3D结果。

    

    最近，从文本提示生成3D内容取得了显著成功。然而，当前的文本到3D方法通常生成的3D结果与人类偏好不一致。本文提出了一个全面的框架，称为DreamReward，从人类偏好反馈中学习和改进文本到3D模型。首先，我们收集了基于系统注释流水线，包括打分和排名的25k专家比较。然后，我们构建了Reward3D—第一个通用的文本到3D人类偏好奖励模型，以有效地编码人类偏好。基于3D奖励模型，最终进行理论分析并提出了Reward3D反馈学习（DreamFL），一个直接调优算法，用重新定义的评分者优化多视图扩散模型。通过理论证明和大量实验比较，我们的DreamReward成功地生成了高保真度和一致的3D结果。

    arXiv:2403.14613v1 Announce Type: cross  Abstract: 3D content creation from text prompts has shown remarkable success recently. However, current text-to-3D methods often generate 3D results that do not align well with human preferences. In this paper, we present a comprehensive framework, coined DreamReward, to learn and improve text-to-3D models from human preference feedback. To begin with, we collect 25k expert comparisons based on a systematic annotation pipeline including rating and ranking. Then, we build Reward3D -- the first general-purpose text-to-3D human preference reward model to effectively encode human preferences. Building upon the 3D reward model, we finally perform theoretical analysis and present the Reward3D Feedback Learning (DreamFL), a direct tuning algorithm to optimize the multi-view diffusion models with a redefined scorer. Grounded by theoretical proof and extensive experiment comparisons, our DreamReward successfully generates high-fidelity and 3D consistent 
    
[^5]: 大型模型的参数高效微调：一项全面调研

    Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey

    [https://arxiv.org/abs/2403.14608](https://arxiv.org/abs/2403.14608)

    大型模型参数高效微调（PEFT）是通过调整预训练模型的参数，以适应特定任务，并减少引入的附加参数或计算资源数量的实用解决方案。

    

    大型模型在多个应用领域代表了一项突破性的进展，使得在各种任务中取得了显著成就。然而，它们空前的规模带来了巨大的计算成本。这些模型通常由数十亿个参数组成，需要大量的计算资源来执行。特别是，在为特定下游任务定制大型模型时，尤其是在受到计算能力限制的硬件平台上，规模庞大和计算要求巨大构成了重大挑战。参数高效微调（PEFT）提供了一个实用解决方案，可以有效地调整大型模型以适应各种下游任务。具体而言，PEFT是指调整预训练大型模型的参数，使其适应特定任务的过程，同时尽量减少引入的附加参数或所需的计算资源数量。

    arXiv:2403.14608v1 Announce Type: new  Abstract: Large models represent a groundbreaking advancement in multiple application fields, enabling remarkable achievements across various tasks. However, their unprecedented scale comes with significant computational costs. These models, often consisting of billions of parameters, require vast amounts of computational resources for execution. Especially, the expansive scale and computational demands pose considerable challenges when customizing them for particular downstream tasks, particularly over the hardware platforms constrained by computational capabilities. Parameter Efficient Fine-Tuning (PEFT) provides a practical solution by efficiently adapt the large models over the various downstream tasks. In particular, PEFT refers to the process of adjusting the parameters of a pre-trained large models to adapt it to a specific task while minimizing the number of additional parameters introduced or computational resources required. This approac
    
[^6]: 可微分编程的要素

    The Elements of Differentiable Programming

    [https://arxiv.org/abs/2403.14606](https://arxiv.org/abs/2403.14606)

    可微分编程是一个新的编程范式，使得复杂程序能够端对端地进行微分，实现基于梯度的参数优化。

    

    人工智能最近取得了显著进展，这得益于大型模型、庞大数据集、加速硬件，以及可微分编程的变革性力量。这种新的编程范式使复杂计算机程序（包括具有控制流和数据结构的程序）能够进行端对端的微分，从而实现对程序参数的基于梯度的优化。不仅仅是程序的微分，可微分编程也包括了程序优化、概率等多个领域的概念。本书介绍了可微分编程所需的基本概念，并采用了优化和概率两个主要视角进行阐述。

    arXiv:2403.14606v1 Announce Type: new  Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the t
    
[^7]: ReNoise：通过迭代添加噪声进行真实图像反转

    ReNoise: Real Image Inversion Through Iterative Noising

    [https://arxiv.org/abs/2403.14602](https://arxiv.org/abs/2403.14602)

    本研究提出了一种通过迭代添加噪声进行真实图像反转的方法，可以在不增加操作数量的情况下增强重建精度。

    

    最近，文本引导扩散模型的进展释放出强大的图像操作能力。然而，将这些方法应用于真实图像需要将图像反转到预训练扩散模型的领域。实现忠实的反转仍然是一个挑战，特别是对于最近训练用于产生具有少量去噪步骤的图像的模型而言。在这项工作中，我们介绍了一种高质量和操作比的反转方法，增强重建精度而不增加操作数量。基于反转扩散采样过程，我们的方法在每个反转采样步骤中使用了迭代添加噪声的机制。这种机制通过在预测的点沿着前向扩散轨迹上迭代地应用预训练的扩散模型，并平均这些预测值来改进近似值。我们评估了我们的ReNoise技术的性能

    arXiv:2403.14602v1 Announce Type: cross  Abstract: Recent advancements in text-guided diffusion models have unlocked powerful image manipulation capabilities. However, applying these methods to real images necessitates the inversion of the images into the domain of the pretrained diffusion model. Achieving faithful inversion remains a challenge, particularly for more recent models trained to generate images with a small number of denoising steps. In this work, we introduce an inversion method with a high quality-to-operation ratio, enhancing reconstruction accuracy without increasing the number of operations. Building on reversing the diffusion sampling process, our method employs an iterative renoising mechanism at each inversion sampling step. This mechanism refines the approximation of a predicted point along the forward diffusion trajectory, by iteratively applying the pretrained diffusion model, and averaging these predictions. We evaluate the performance of our ReNoise technique 
    
[^8]: 扩展现实用于增强人机协作：一种人在回路中的方法

    Extended Reality for Enhanced Human-Robot Collaboration: a Human-in-the-Loop Approach

    [https://arxiv.org/abs/2403.14597](https://arxiv.org/abs/2403.14597)

    本文提出了一种自主的、基于机器学习的操作器框架，将人在回路原则和扩展现实结合起来，以促进人与机器人之间直观的沟通和编程。

    

    自动化的崛起为制造过程的高效率提供了机会，但往往牺牲了及时响应不断变化的市场需求和满足定制需求所需的灵活性。人机协作试图通过将机器的力量和精度与人类的机智和感知理解结合起来，以解决这些挑战。本文概念化并提出了一个实现框架，用于将人在回路原则与扩展现实（XR）相结合，以便于人与机器人之间进行直观沟通和编程。此外，这个概念框架预见到了人直接参与机器人学习过程，从而提高了适应性和任务泛化能力。本文重点介绍了支持所提出框架的关键技术，强调了实现这一框架的可行性。

    arXiv:2403.14597v1 Announce Type: cross  Abstract: The rise of automation has provided an opportunity to achieve higher efficiency in manufacturing processes, yet it often compromises the flexibility required to promptly respond to evolving market needs and meet the demand for customization. Human-robot collaboration attempts to tackle these challenges by combining the strength and precision of machines with human ingenuity and perceptual understanding. In this paper, we conceptualize and propose an implementation framework for an autonomous, machine learning-based manipulator that incorporates human-in-the-loop principles and leverages Extended Reality (XR) to facilitate intuitive communication and programming between humans and robots. Furthermore, the conceptual framework foresees human involvement directly in the robot learning process, resulting in higher adaptability and task generalization. The paper highlights key technologies enabling the proposed framework, emphasizing the im
    
[^9]: 重新思考对抗逆强化学习：从策略模仿和可转移奖励恢复的角度

    Rethinking Adversarial Inverse Reinforcement Learning: From the Angles of Policy Imitation and Transferable Reward Recovery

    [https://arxiv.org/abs/2403.14593](https://arxiv.org/abs/2403.14593)

    重新思考对抗逆强化学习中的策略模仿和可转移奖励恢复，提出了一个混合框架PPO-AIRL + SAC以解决SAC算法在AIRL训练中无法全面解开奖励函数的问题。

    

    对抗逆强化学习（AIRL）作为模仿学习中的基石方法。本文重新思考了AIRL的两个不同角度：策略模仿和可转移奖励恢复。我们从用Soft Actor-Critic（SAC）替换AIRL中的内置算法开始，以增强样本效率，这要归功于SAC的离策略形式和相对于AIRL而言可识别的马尔可夫决策过程（MDP）模型。这确实在策略模仿方面表现出显著的改进，但不慎给可转移奖励恢复带来了缺点。为了解决这个问题，我们阐述了SAC算法本身在AIRL训练过程中无法全面解开奖励函数，提出了一个混合框架，PPO-AIRL + SAC，以获得令人满意的转移效果。此外，我们分析了环境提取解开的奖励的能力。

    arXiv:2403.14593v1 Announce Type: new  Abstract: Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone approach in imitation learning. This paper rethinks the two different angles of AIRL: policy imitation and transferable reward recovery. We begin with substituting the built-in algorithm in AIRL with soft actor-critic (SAC) during the policy optimization process to enhance sample efficiency, thanks to the off-policy formulation of SAC and identifiable Markov decision process (MDP) models with respect to AIRL. It indeed exhibits a significant improvement in policy imitation but accidentally brings drawbacks to transferable reward recovery. To learn this issue, we illustrate that the SAC algorithm itself is not feasible to disentangle the reward function comprehensively during the AIRL training process, and propose a hybrid framework, PPO-AIRL + SAC, for satisfactory transfer effect. Additionally, we analyze the capability of environments to extract disentangled rewa
    
[^10]: ReAct遇上ActRe：对比性自训练中的代理轨迹自动标注

    ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training

    [https://arxiv.org/abs/2403.14589](https://arxiv.org/abs/2403.14589)

    提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。

    

    arXiv:2403.14589v1 公告类型：新 文摘：语言代理通过与基础模型推理展示了自主决策能力。最近，人们致力于通过多步推理和行动轨迹作为训练数据来训练语言代理以提高性能。然而，收集这样的轨迹仍需要相当大的人力，无论是通过人工标注还是实施多样化提示框架。在这项工作中，我们提出了A$^3$T，一个允许以ReAct风格自主注释代理轨迹的框架。其中心是一个ActRe提示代理，它解释任意动作的原因。当随机抽取外部动作时，ReAct风格代理可以查询ActRe代理以获取其文本理由。新颖的轨迹然后通过将ActRe的后验推理前置到抽样动作中进行综合合成。通过这种方式，ReAct风格代理可执行

    arXiv:2403.14589v1 Announce Type: new  Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent exe
    
[^11]: 线性时间序列预测模型分析

    An Analysis of Linear Time Series Forecasting Models

    [https://arxiv.org/abs/2403.14587](https://arxiv.org/abs/2403.14587)

    分析了线性时间序列预测模型，证明了几种流行的线性模型变体等效于标准的线性回归，提供了实验证据支持这一结论。

    

    尽管简单，线性模型在时间序列预测中表现良好，即使与更深层次和更昂贵的模型进行对比也是如此。已经提出了许多线性模型的变体，通常包括某种形式的特征规范化，可以改善模型的泛化能力。在本文中，我们分析了使用这些线性模型架构可以表达的函数集合。通过这样做，我们展示了几种流行的线性时间序列预测模型变体等效，并在功能上无法区分标准的非约束线性回归。我们为每种线性变体描述了模型类别。我们证明了每个模型都可以重新解释为在适当扩充的特征集上的非约束线性回归，因此在使用均方损失函数时可以得到封闭形式的解决方案。我们提供实验证据表明，待检查的模型学习到了几乎相同的解决方案。

    arXiv:2403.14587v1 Announce Type: new  Abstract: Despite their simplicity, linear models perform well at time series forecasting, even when pitted against deeper and more expensive models. A number of variations to the linear model have been proposed, often including some form of feature normalisation that improves model generalisation. In this paper we analyse the sets of functions expressible using these linear model architectures. In so doing we show that several popular variants of linear models for time series forecasting are equivalent and functionally indistinguishable from standard, unconstrained linear regression. We characterise the model classes for each linear variant. We demonstrate that each model can be reinterpreted as unconstrained linear regression over a suitably augmented feature set, and therefore admit closed-form solutions when using a mean-squared loss function. We provide experimental evidence that the models under inspection learn nearly identical solutions, a
    
[^12]: 为去中心化多智能体导航的环境和政策进行协同优化

    Co-Optimization of Environment and Policies for Decentralized Multi-Agent Navigation

    [https://arxiv.org/abs/2403.14583](https://arxiv.org/abs/2403.14583)

    将多智能体系统和周围环境视为共同演化的系统，提出智能体-环境协同优化问题并开发协调算法，以改进去中心化多智能体导航表现。

    

    这项工作将多智能体系统及其周围环境视为一个共同演化的系统，其中一个的行为会影响另一个。其目标是将智能体行为和环境配置都视为决策变量，并以协调的方式优化这两个组件，以改进某些感兴趣的度量。为此，我们考虑了在拥挤环境中的去中心化多智能体导航问题。通过引入多智能体导航和环境优化的两个子目标，提出了一个“智能体-环境协同优化”问题，并开发了一个“协调算法”，在这两个子目标之间交替以寻找智能体行为和障碍物环境配置的最佳综合；最终提高了导航性能。由于明确建模智能体、环境和性能之间关系的挑战，我们利用了

    arXiv:2403.14583v1 Announce Type: cross  Abstract: This work views the multi-agent system and its surrounding environment as a co-evolving system, where the behavior of one affects the other. The goal is to take both agent actions and environment configurations as decision variables, and optimize these two components in a coordinated manner to improve some measure of interest. Towards this end, we consider the problem of decentralized multi-agent navigation in cluttered environments. By introducing two sub-objectives of multi-agent navigation and environment optimization, we propose an $\textit{agent-environment co-optimization}$ problem and develop a $\textit{coordinated algorithm}$ that alternates between these sub-objectives to search for an optimal synthesis of agent actions and obstacle configurations in the environment; ultimately, improving the navigation performance. Due to the challenge of explicitly modeling the relation between agents, environment and performance, we leverag
    
[^13]: RAmBLA：评估LLMs在生物医学领域中作为助手的可靠性的框架

    RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain

    [https://arxiv.org/abs/2403.14578](https://arxiv.org/abs/2403.14578)

    该研究引入了RAmBLA框架，评估四个最先进的基础LLMs在生物医学领域是否可以作为可靠助手，在任务设计和性能评估中强调了提示的健壮性、高召回率和缺乏幻觉的重要性。

    

    大型语言模型(LLMs)越来越多地支持各种领域的应用，其中一些潜在影响社会的领域，如生物医学，然而它们在现实用例中的可靠性尚未得到充分研究。在这项工作中，我们引入了用于评估生物医学LLM助手可靠性的RAmBLA框架，并评估四个最先进的基础LLMs是否可以作为生物医学领域的可靠助手。我们确定提示的健壮性、高召回率和缺乏幻觉是这种用例的必要标准。我们设计了模拟真实用户交互的短表单任务和需要LLM自由形式回答的任务。我们使用一个评估者LLM通过与真实响应的语义相似性来评估LLM的性能。

    arXiv:2403.14578v1 Announce Type: new  Abstract: Large Language Models (LLMs) increasingly support applications in a wide range of domains, some with potential high societal impact such as biomedicine, yet their reliability in realistic use cases is under-researched. In this work we introduce the Reliability AssesMent for Biomedical LLM Assistants (RAmBLA) framework and evaluate whether four state-of-the-art foundation LLMs can serve as reliable assistants in the biomedical domain. We identify prompt robustness, high recall, and a lack of hallucinations as necessary criteria for this use case. We design shortform tasks and tasks requiring LLM freeform responses mimicking real-world user interactions. We evaluate LLM performance using semantic similarity with a ground truth response, through an evaluator LLM.
    
[^14]: 一项关于基于概念方法改进模型的调查

    A survey on Concept-based Approaches For Model Improvement

    [https://arxiv.org/abs/2403.14566](https://arxiv.org/abs/2403.14566)

    基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。

    

    最近研究的重点已经从仅仅提高深度神经网络（DNN）在各种任务中的性能转变为使DNN更易解释给人类。可解释人工智能（XAI）领域已经观察到各种技术，包括基于显著性和基于概念的方法。基于概念的方法用所谓的概念在简单的人类可理解术语中解释模型的决策。概念是数据的人类可解释单元，是人类思维的基石。用概念的解释能够检测到伪关联、固有偏见或聪明汉。随着基于概念的解释的出现，出现了各种概念表示方法和自动概念发现算法。一些最近的方法使用概念进行事后模型解缠评估，而其他人使用它们进行事前训练。基于概念的方法是新的，有许多表示方法。

    arXiv:2403.14566v1 Announce Type: new  Abstract: The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans. The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches. Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts. Concepts are human interpretable units of data and are the thinking ground of humans. Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans. With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms. Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training. The concept-based approaches are new, with many representatio
    
[^15]: 词汇级对比视觉基础改进语言建模

    Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling

    [https://arxiv.org/abs/2403.14551](https://arxiv.org/abs/2403.14551)

    这项研究介绍了LexiContrastive Grounding (LCG)，它结合了视觉监督和文本表示改进策略，在多个单词学习和句子理解基准测试中表现出比标准语言模型更高的学习效率和进步。

    

    今天最准确的语言模型是在比人类语言学习者接收到的语言数据量多得多的情况下训练的，但并没有来自在人类学习中起关键作用的其他感官模式的监督。本文描述了LexiContrastive Grounding (LCG)，一种利用视觉监督来改进文本表征的基于地面语言学习程序。LexiContrastive Grounding将下一个标记预测策略与对比视觉基础目标结合起来，重点放在编码词汇信息的早期层表示上。在多个单词学习和句子理解基准测试中，LexiContrastive Grounding不仅在学习效率上优于标准语言模型，而且在视觉与语言学习程序方面取得了进步。

    arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures inclu
    
[^16]: 估计通道数据增强对遥感图像物理信息一致性的影响

    Estimating Physical Information Consistency of Channel Data Augmentation for Remote Sensing Images

    [https://arxiv.org/abs/2403.14547](https://arxiv.org/abs/2403.14547)

    本文提出了一种用于估计通道数据增强技术对遥感图像物理信息一致性影响的方法，以解决这一领域中存在的争议。

    

    数据增强在深度学习方法中发挥着重要作用，特别是通道变换被整合到遥感图像分类任务的数据增强流程中。本文提出一种方法，用于估计通道增强技术是否会影响遥感图像的物理信息，以解决人们对其在遥感图像上的适用性存在争议的问题。

    arXiv:2403.14547v1 Announce Type: cross  Abstract: The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification. In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks. However, contradicting beliefs exist about their proper applications to RS images. A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures). To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images. To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject
    
[^17]: Object-Centric Domain Randomization用于野外3D形状重建

    Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild

    [https://arxiv.org/abs/2403.14539](https://arxiv.org/abs/2403.14539)

    提出了ObjectDR，利用对象-centric的域随机化合成单视图3D形状重建中缺乏的配对数据，通过条件生成模型和解耦框架来生成和保留对象轮廓以及广泛变化的数据，从而为培训模型捕捉域不变性几何形状。

    

    单视图3D形状在野外的重建面临的最大挑战之一是来自真实环境中的<3D形状，2D图像>-配对数据的稀缺性。受域随机化引人注目的成就的启发，我们提出了ObjectDR，通过对对象外观和背景的视觉变化进行随机仿真，合成这种配对数据。我们的数据合成框架利用条件生成模型（例如ControlNet）生成符合空间条件（例如2.5D草图）的图像，这些条件可以通过从对象集合（例如Objaverse-XL）的渲染过程获得3D形状。为了模拟多样化的变化同时保留嵌入空间条件中的对象轮廓，我们还引入了一个利用初始对象指导的解耦框架。

    arXiv:2403.14539v1 Announce Type: cross  Abstract: One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of <3D shape, 2D image>-paired data from real-world environments. Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds. Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL). To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance. After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry p
    
[^18]: 在强迫系统中使用机器学习不变叶轨道进行降阶建模

    Machine-learning invariant foliations in forced systems for reduced order modelling

    [https://arxiv.org/abs/2403.14514](https://arxiv.org/abs/2403.14514)

    使用机器学习不变叶轨道在强迫系统中识别降阶模型，结合全局和局部叶轨道，并强调解决数学方面的挑战。

    

    我们利用不变叶轨道从数据中识别强迫系统的降阶模型（ROM）。强迫可以是外部强迫、参数强迫、周期性强迫或准周期性强迫。该过程分为四步：1. 识别近似不变环面及其周围的线性动态；2. 识别围绕环面的全局定义的不变叶轨道；3. 识别关于一个补充全局叶轨道的不变流形的局部叶轨道；4. 提取作为通过环面的叶子的不变流形并解释结果。我们将第2步和第3步结合起来，这样我们可以跟踪不变环面的位置并适当调整不变性方程的比例。我们强调了将不变流形和叶轨道拟合到数据时所面临的一些基本限制，这需要进一步的数学来解决。

    arXiv:2403.14514v1 Announce Type: cross  Abstract: We identify reduced order models (ROM) of forced systems from data using invariant foliations. The forcing can be external, parametric, periodic or quasi-periodic. The process has four steps: 1. identify an approximate invariant torus and the linear dynamics about the torus; 2. identify a globally defined invariant foliation about the torus; 3. identify a local foliation about an invariant manifold that complements the global foliation 4. extract the invariant manifold as the leaf going through the torus and interpret the result. We combine steps 2 and 3, so that we can track the location of the invariant torus and scale the invariance equations appropriately. We highlight some fundamental limitations of invariant manifolds and foliations when fitting them to data, that require further mathematics to resolve.
    
[^19]: 带有平滑对数障碍函数的约束加强学习

    Constrained Reinforcement Learning with Smoothed Log Barrier Function

    [https://arxiv.org/abs/2403.14508](https://arxiv.org/abs/2403.14508)

    提出了一种新的约束强化学习方法CSAC-LB，通过应用线性平滑对数障碍函数，实现了竞争性能，无需任何预训练

    

    强化学习（RL）已广泛应用于许多控制任务，并在许多领域的性能上与传统控制方法相比有了显著提高，其中奖励函数是很好定义的。然而，对于许多现实世界的问题，以奖励和约束同时制定优化问题通常更为方便。通过奖励塑造来优化这些受限问题可能会很困难，因为需要对带有几个交互项的奖励函数进行繁琐的手动调整。最近包含约束的公式在多数情况下需要预训练阶段，这通常需要人类专业知识来收集数据或假定有一个待用的次优策略。我们提出了一种名为CSAC-LB（带有对数障碍函数的约束软演员-评论家）的新型约束RL方法，通过应用线性平滑对数障碍函数，该方法实现了竞争性能，而不需要任何预训练。

    arXiv:2403.14508v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier funct
    
[^20]: 软学习概率电路

    Soft Learning Probabilistic Circuits

    [https://arxiv.org/abs/2403.14504](https://arxiv.org/abs/2403.14504)

    该论文提出了一种新的学习过程 SoftLearn，通过软聚类过程诱导出一个 PC，相较于传统的 LearnSPN，在许多情况下表现更好，产生更好的似然值和样本。

    

    概率电路（PCs)是杰出的可计算概率模型，允许进行一系列准确推理。该论文专注于主要的 PC 训练算法 LearnSPN，由于其效率、性能和易用性而成为金标准，特别适用于表格数据。我们表明在温和假设下，LearnSPN 是一种贪心似然最大化器。虽然在 PC 中，推理可以利用整个电路结构来处理查询，但 LearnSPN 应用了一种硬方法来学习它们，通过在每个求和节点上通过一个而仅一个子/边的数据点进行传播，就像在一个硬聚类过程中一样。我们提出了一种名为 SoftLearn 的新学习程序，它通过软聚类过程诱导出一个 PC。我们调查了这种学习-推理兼容性在 PC 中的影响。我们的实验表明，SoftLearn 在许多情况下优于 LearnSPN，产生更好的似然值，可能还产生更好的样本。

    arXiv:2403.14504v1 Announce Type: cross  Abstract: Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analy
    
[^21]: 基于物理学因果推理的机器人操作任务中安全稳健的下一最佳动作选择

    Physics-Based Causal Reasoning for Safe & Robust Next-Best Action Selection in Robot Manipulation Tasks

    [https://arxiv.org/abs/2403.14488](https://arxiv.org/abs/2403.14488)

    该论文提出了一个基于物理因果推理的框架，用于机器人在部分可观察的环境中进行概率推理，成功预测积木塔稳定性并选择下一最佳动作。

    

    安全高效的物体操作是许多真实世界机器人应用的关键推手。然而，这种挑战在于机器人操作必须对一系列传感器和执行器的不确定性具有稳健性。本文提出了一个基于物理知识和因果推理的框架，用于让机器人在部分可观察的环境中对候选动作进行概率推理，以完成一个积木堆叠任务。我们将刚体系统动力学的基于物理学的仿真与因果贝叶斯网络（CBN）结合起来，定义了机器人决策过程的因果生成概率模型。通过基于仿真的蒙特卡洛实验，我们展示了我们的框架成功地能够：(1) 高准确度地预测积木塔的稳定性（预测准确率：88.6%）；和，(2) 为积木堆叠任务选择一个近似的下一最佳动作，供整合的机器人系统执行，实现94.2%的任务成功率。

    arXiv:2403.14488v1 Announce Type: cross  Abstract: Safe and efficient object manipulation is a key enabler of many real-world robot applications. However, this is challenging because robot operation must be robust to a range of sensor and actuator uncertainties. In this paper, we present a physics-informed causal-inference-based framework for a robot to probabilistically reason about candidate actions in a block stacking task in a partially observable setting. We integrate a physics-based simulation of the rigid-body system dynamics with a causal Bayesian network (CBN) formulation to define a causal generative probabilistic model of the robot decision-making process. Using simulation-based Monte Carlo experiments, we demonstrate our framework's ability to successfully: (1) predict block tower stability with high accuracy (Pred Acc: 88.6%); and, (2) select an approximate next-best action for the block stacking task, for execution by an integrated robot system, achieving 94.2% task succe
    
[^22]: HyperGALE: 通过学习超边的超图门控注意力进行ASD分类

    HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges

    [https://arxiv.org/abs/2403.14484](https://arxiv.org/abs/2403.14484)

    HyperGALE通过学习超边的超图门控注意力机制，在解释复杂的脑图数据方面取得显著改进，为ASD生物标志特征化提供更深入见解。

    

    自闭症谱系障碍（ASD）是一种神经发育障碍，其特征是各种社交认知挑战和重复行为模式。由于谱系的症状多样性，为ASD识别可靠的基于脑成像的生物标志一直是一个持久的挑战。该领域现有的基线已经在这个方向上取得了重要进展，但在性能和可解释性方面仍有改进空间。我们提出了\emph {HyperGALE}，它基于超图，结合了学习的超边和门控注意力机制。这种方法大大提高了模型解释复杂脑图数据的能力，为ASD生物标志特征化提供了更深入的见解。在广泛的ABIDE II数据集上进行评估，\emph {HyperGALE}不仅提高了可解释性，还在关键性能指标上表现出显著的增强

    arXiv:2403.14484v1 Announce Type: cross  Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by varied social cognitive challenges and repetitive behavioral patterns. Identifying reliable brain imaging-based biomarkers for ASD has been a persistent challenge due to the spectrum's diverse symptomatology. Existing baselines in the field have made significant strides in this direction, yet there remains room for improvement in both performance and interpretability. We propose \emph{HyperGALE}, which builds upon the hypergraph by incorporating learned hyperedges and gated attention mechanisms. This approach has led to substantial improvements in the model's ability to interpret complex brain graph data, offering deeper insights into ASD biomarker characterization. Evaluated on the extensive ABIDE II dataset, \emph{HyperGALE} not only improves interpretability but also demonstrates statistically significant enhancements in key performance metrics compare
    
[^23]: 使用LightGBM算法进行运营商用户信用评估研究

    Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research

    [https://arxiv.org/abs/2403.14483](https://arxiv.org/abs/2403.14483)

    该研究利用LightGBM算法对运营商用户信用评估模型进行研究，通过提取关键特征并进行数据预处理和特征工程，以改善用户信用评估策略。

    

    移动互联网用户信用评估是通信运营商制定决策和措施的重要方式，也是运营商获得预期收益的保障。本文利用通信运营商提供的海量数据，基于融合LightGBM算法进行运营商用户信用评估模型研究。

    arXiv:2403.14483v1 Announce Type: cross  Abstract: Mobile Internet user credit assessment is an important way for communication operators to establish decisions and formulate measures, and it is also a guarantee for operators to obtain expected benefits. However, credit evaluation methods have long been monopolized by financial industries such as banks and credit. As supporters and providers of platform network technology and network resources, communication operators are also builders and maintainers of communication networks. Internet data improves the user's credit evaluation strategy. This paper uses the massive data provided by communication operators to carry out research on the operator's user credit evaluation model based on the fusion LightGBM algorithm. First, for the massive data related to user evaluation provided by operators, key features are extracted by data preprocessing and feature engineering methods, and a multi-dimensional feature set with statistical significance 
    
[^24]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^25]: 适用于多任务数据集的普适特征选择

    Universal Feature Selection for Simultaneous Interpretability of Multitask Datasets

    [https://arxiv.org/abs/2403.14466](https://arxiv.org/abs/2403.14466)

    BoUTS的特征选择算法能够普适性地识别数据集中通用特征和预测特定子集的任务特定特征，在化学数据集上取得了最先进的特征稀疏性，同时保持着与专门方法相当的预测准确性。

    

    从复杂、高维数据集中提取有意义的特征在科学领域仍然具有挑战性。目前的方法通常在可扩展性方面存在问题，限制了它们对大型数据集的适用性，或者对特征属性关系做出了限制性假设，从而阻碍了捕获复杂交互作用的能力。BoUTS的通用且可扩展的特征选择算法突破了这些限制，既能识别对所有数据集相关的通用特征，又能识别预测特定子集的任务特定特征。在七个不同的化学回归数据集上进行评估，BoUTS实现了最先进的特征稀疏性，同时保持着与专门方法相当的预测准确性。值得注意的是，BoUTS的通用特征使得数据集之间可以进行领域特定的知识转移，并且暗示了看似不相关的化学数据集之间存在深层连接。我们期望这些结果会产生重要的影响。

    arXiv:2403.14466v1 Announce Type: new  Abstract: Extracting meaningful features from complex, high-dimensional datasets across scientific domains remains challenging. Current methods often struggle with scalability, limiting their applicability to large datasets, or make restrictive assumptions about feature-property relationships, hindering their ability to capture complex interactions. BoUTS's general and scalable feature selection algorithm surpasses these limitations to identify both universal features relevant to all datasets and task-specific features predictive for specific subsets. Evaluated on seven diverse chemical regression datasets, BoUTS achieves state-of-the-art feature sparsity while maintaining prediction accuracy comparable to specialized methods. Notably, BoUTS's universal features enable domain-specific knowledge transfer between datasets, and suggest deep connections in seemingly-disparate chemical datasets. We expect these results to have important repercussions i
    
[^26]: gTBLS：通过条件问答从文本中生成表格

    gTBLS: Generating Tables from Text by Conditional Question Answering

    [https://arxiv.org/abs/2403.14457](https://arxiv.org/abs/2403.14457)

    gTBLS通过两阶段方法从文本中生成表格，第一阶段推断表格结构，第二阶段利用结构提出问题并通过微调语言模型来回答，能够在零短配置下利用预训练的大型语言模型，改进了先前方法的效果。

    

    arXiv:2403.14457v1 公告类型：新的 摘要：将大段的非结构化文本提炼为结构化、简化的形式，如表格，是一个开放的研究问题。自动生成表格的主要挑战之一是确保其句法有效性。之前的方法通过在Transformer的注意力机制中包含额外的参数，以便注意特定的行和列标题来解决这一挑战。与这种单阶段方法相反，本文提出了一种名为生成式表格（gTBLS）的两阶段方法。第一阶段从文本中推断表格结构（行和列标题）。第二阶段利用这些标题提出问题，并微调因果语言模型来回答这些问题。此外，gTBLS方法易于在零短配置中利用预训练的大型语言模型，为在不能进行微调的情况下生成表格提供了解决方案。gTBLS提高了之前方法达到的效果

    arXiv:2403.14457v1 Announce Type: new  Abstract: Distilling large, unstructured text into a structured, condensed form such as tables is an open research problem. One of the primary challenges in automatically generating tables is ensuring their syntactic validity. Prior approaches address this challenge by including additional parameters in the Transformer's attention mechanism to attend to specific rows and column headers. In contrast to this single-stage method, this paper presents a two-stage approach called Generative Tables (gTBLS). The first stage infers table structure (row and column headers) from the text. The second stage formulates questions using these headers and fine-tunes a causal language model to answer them. Furthermore, the gTBLS approach is amenable to the utilization of pre-trained Large Language Models in a zero-shot configuration, presenting a solution for table generation in situations where fine-tuning is not feasible. gTBLS improves prior approaches by up to 
    
[^27]: 语言模型可以降低信息市场的不对称性

    Language Models Can Reduce Asymmetry in Information Markets

    [https://arxiv.org/abs/2403.14443](https://arxiv.org/abs/2403.14443)

    语言模型驱动的智能代理在模拟数字市场中完成买卖信息的任务，通过具备评估信息质量和遗忘能力的特点，成功降低了信息市场的买方检查悖论。

    

    这项工作解决了信息市场中买方检查悖论的问题。买方需要获取信息来确定其价值，而卖方需要限制访问以防止盗窃。为了研究这一问题，我们引入一个开源的模拟数字市场，其中由语言模型驱动的智能代理代表外部参与者买卖信息。这个市场的核心机制在于代理人的双重能力：他们不仅能够评估特权信息的质量，还具备遗忘的能力。这种诱导健忘的能力使供应商可以授予临时访问专有信息的权限，显著降低未经授权的保留风险，同时使代理人能够准确评估信息对特定查询或任务的相关性。为了表现优异，代理必须做出理性决策，战略性地探索市场。

    arXiv:2403.14443v1 Announce Type: new  Abstract: This work addresses the buyer's inspection paradox for information markets. The paradox is that buyers need to access information to determine its value, while sellers need to limit access to prevent theft. To study this, we introduce an open-source simulated digital marketplace where intelligent agents, powered by language models, buy and sell information on behalf of external participants. The central mechanism enabling this marketplace is the agents' dual capabilities: they not only have the capacity to assess the quality of privileged information but also come equipped with the ability to forget. This ability to induce amnesia allows vendors to grant temporary access to proprietary information, significantly reducing the risk of unauthorized retention while enabling agents to accurately gauge the information's relevance to specific queries or tasks. To perform well, agents must make rational decisions, strategically explore the marke
    
[^28]: 分析医学图像的扩散分割

    Analysing Diffusion Segmentation for Medical Images

    [https://arxiv.org/abs/2403.14440](https://arxiv.org/abs/2403.14440)

    本研究批判性地分析和讨论了医学图像的扩散分割与扩散图像生成之间的差异，强调了针对扩散分割的架构改进带来的益处。

    

    随着其能够提供概率建模和生成多样化输出的能力，去噪扩散概率模型变得越来越受欢迎。这种多功能性启发了它们被用于图像分割，模型的多次预测可以产生分割结果，不仅质量高，而且能够捕捉模型本质上的不确定性。本文提出了用于改进扩散分割性能的强大架构。然而，对扩散分割和图像生成之间的差异缺乏分析和讨论，并且缺乏对这些架构提供的改进在分割领域与在特定于扩散分割的益处之间进行区分的深入评估。

    arXiv:2403.14440v1 Announce Type: cross  Abstract: Denoising Diffusion Probabilistic models have become increasingly popular due to their ability to offer probabilistic modeling and generate diverse outputs. This versatility inspired their adaptation for image segmentation, where multiple predictions of the model can produce segmentation results that not only achieve high quality but also capture the uncertainty inherent in the model. Here, powerful architectures were proposed for improving diffusion segmentation performance. However, there is a notable lack of analysis and discussions on the differences between diffusion segmentation and image generation, and thorough evaluations are missing that distinguish the improvements these architectures provide for segmentation in general from their benefit for diffusion segmentation specifically. In this work, we critically analyse and discuss how diffusion segmentation for medical images differs from diffusion image generation, with a partic
    
[^29]: 一种利用大型语言模型进行设备定向语音检测的多模态方法

    A Multimodal Approach to Device-Directed Speech Detection with Large Language Models

    [https://arxiv.org/abs/2403.14438](https://arxiv.org/abs/2403.14438)

    探索了一种利用大型语言模型进行设备定向语音检测的多模态方法，相比于文本和音频模型，使用多模态信息能够显著提高相等错误率。

    

    虚拟助手的交互通常从预定义触发短语开始，然后是用户命令。为了使与助手的交互更直观，我们探讨了是否可以放弃用户必须用触发短语开始每个命令的要求。我们通过三种方式探索了这个任务：首先，我们仅使用从音频波形中获得的声学信息训练分类器。其次，我们将自动语音识别（ASR）系统的解码器输出，例如1-best假设，作为输入特征输入到大型语言模型（LLM）中。最后，我们探讨了一种多模态系统，将声学和词汇特征以及ASR解码器信号结合在LLM中。使用多模态信息相对于仅文本和仅音频模型提高了相等错误率高达39%和61%。增加LLM的大小并通过低秩调整进行训练进一步减少了相对EER值的减少

    arXiv:2403.14438v1 Announce Type: new  Abstract: Interactions with virtual assistants typically start with a predefined trigger phrase followed by the user command. To make interactions with the assistant more intuitive, we explore whether it is feasible to drop the requirement that users must begin each command with a trigger phrase. We explore this task in three ways: First, we train classifiers using only acoustic information obtained from the audio waveform. Second, we take the decoder outputs of an automatic speech recognition (ASR) system, such as 1-best hypotheses, as input features to a large language model (LLM). Finally, we explore a multimodal system that combines acoustic and lexical features, as well as ASR decoder signals in an LLM. Using multimodal information yields relative equal-error-rate improvements over text-only and audio-only models of up to 39% and 61%. Increasing the size of the LLM and training with low-rank adaption leads to further relative EER reductions o
    
[^30]: 偏向性的二进制属性分类器忽视了主要类别

    Biased Binary Attribute Classifiers Ignore the Majority Classes

    [https://arxiv.org/abs/2403.14435](https://arxiv.org/abs/2403.14435)

    本文将梯度基础的CAM技术扩展到二元分类器，并可视化二进制面部属性分类器的活动区域，证实在不平衡数据集上训练时偏向性分类器倾向于学习提取主要类别的特征

    

    为了可视化分类器基于其决策的兴趣区域，发展了不同的Class Activation Mapping (CAM)方法。然而，所有这些技术只针对分类分类器，而大多数实际任务是二元分类。本文将基于梯度的CAM技术扩展到与二进制分类器一起使用，并可视化二进制面部属性分类器的活动区域。当在不平衡的数据集上训练不平衡的二元分类器时，众所周知，即具有许多训练样本的主要类通常比具有少量训练实例的次要类预测得更好。在CelebA数据集上的实验中，我们验证了这些结果，当训练不平衡分类器同时提取40个面部属性。人们预期，偏向性分类器已经学会主要为多数类提取特征

    arXiv:2403.14435v1 Announce Type: cross  Abstract: To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed. However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification. In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary facial attribute classifiers. When training an unbalanced binary classifier on an imbalanced dataset, it is well-known that the majority class, i.e. the class with many training samples, is mostly predicted much better than minority class with few training instances. In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously. One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the 
    
[^31]: 风格提取扩散模型用于半监督组织学分割

    Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation

    [https://arxiv.org/abs/2403.14429](https://arxiv.org/abs/2403.14429)

    提出了风格提取扩散模型，利用风格调节机制和内容调节机制，实现了在图像生成过程中注入未见图像风格信息，从而以零-shot方式生成具有未见风格的图像。

    

    arXiv:2403.14429v1 公告类型:跨领域 摘要:基于深度学习的图像生成在扩散模型的显着进展下取得了重要进展，明显改善了生成图像的质量。尽管取得了这些进展，但生成具有对下游任务有益的未见特征的图像却受到了较少关注。为了弥补这一差距，我们提出了风格提取扩散模型，其中包含两种调节机制。具体来说，我们利用1)风格调制机制在图像生成过程中注入先前未见图像的风格信息，2)内容调制机制可以针对下游任务进行定位，例如布局用于分割。我们引入了可训练的风格编码器，从图像中提取风格信息，并引入了一个聚合块，用于合并来自多个风格输入的风格信息。这种架构使得通过利用来自未见图像的风格，在零-shot方式下生成具有未见风格的图像成为可能。

    arXiv:2403.14429v1 Announce Type: cross  Abstract: Deep learning-based image generation has seen significant advancements with diffusion models, notably improving the quality of generated images. Despite these developments, generating images with unseen characteristics beneficial for downstream tasks has received limited attention. To bridge this gap, we propose Style-Extracting Diffusion Models, featuring two conditioning mechanisms. Specifically, we utilize 1) a style conditioning mechanism which allows to inject style information of previously unseen images during image generation and 2) a content conditioning which can be targeted to a downstream task, e.g., layout for segmentation. We introduce a trainable style encoder to extract style information from images, and an aggregation block that merges style information from multiple style inputs. This architecture enables the generation of images with unseen styles in a zero-shot manner, by leveraging styles from unseen images, result
    
[^32]: 基于可微分模拟和优化的任务最优数据驱动替代模型用于eNMPC

    Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization

    [https://arxiv.org/abs/2403.14425](https://arxiv.org/abs/2403.14425)

    提出了一种基于可微分模拟和优化的任务最优数据驱动替代模型方法，在eNMPC中表现出优越性能，为实现更具能力的控制器提供了有前途的途径。

    

    我们提出了一种用于控制中优化性能的Koopman替代模型端到端学习方法。与之前采用标准强化学习（RL）算法的贡献相反，我们使用一种训练算法，利用基于机械模拟模型的环境的潜在可微性。通过将我们的方法与文献已知的eNMPC案例研究中其他控制器类型和训练算法组合的性能进行比较，我们评估了我们方法的性能。我们的方法在这个问题上表现出优越的性能，因此在使用动态替代模型的更有能力的控制器方面构成了一个有前途的途径。

    arXiv:2403.14425v1 Announce Type: new  Abstract: We present a method for end-to-end learning of Koopman surrogate models for optimal performance in control. In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the potential differentiability of environments based on mechanistic simulation models. We evaluate the performance of our method by comparing it to that of other controller type and training algorithm combinations on a literature known eNMPC case study. Our method exhibits superior performance on this problem, thereby constituting a promising avenue towards more capable controllers that employ dynamic surrogate models.
    
[^33]: 将扩散模型调整到私有领域而无需微调

    DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning

    [https://arxiv.org/abs/2403.14421](https://arxiv.org/abs/2403.14421)

    开发了第一个差分隐私检索增强生成算法，能够在生成高质量图像样本的同时提供可证明的隐私保证

    

    arXiv:2403.14421v1 公告类型：新的 文摘：文本到图像的扩散模型已经被证明存在样本级别的记忆化问题，可能会复制出与其训练图像几乎完全相同的副本，这可能是不希望看到的。为了解决这个问题，我们开发了第一个能够生成高质量图像样本并提供可证明的隐私保证的差分隐私检索增强生成算法。具体而言，我们假设可以访问一个在少量公共数据上训练的文本到图像扩散模型，并设计一个DP检索机制，以从私有检索数据集中检索的样本来增强文本提示。我们的\emph{差分隐私检索增强扩散模型}（DP-RDM）在适应另一个领域时无需对检索数据集进行微调，并且可以使用最先进的生成模型生成高质量的图像样本，同时满足严格的差分隐私保证。例如，在评估时

    arXiv:2403.14421v1 Announce Type: new  Abstract: Text-to-image diffusion models have been shown to suffer from sample-level memorization, possibly reproducing near-perfect replica of images that they are trained on, which may be undesirable. To remedy this issue, we develop the first differentially private (DP) retrieval-augmented generation algorithm that is capable of generating high-quality image samples while providing provable privacy guarantees. Specifically, we assume access to a text-to-image diffusion model trained on a small amount of public data, and design a DP retrieval mechanism to augment the text prompt with samples retrieved from a private retrieval dataset. Our \emph{differentially private retrieval-augmented diffusion model} (DP-RDM) requires no fine-tuning on the retrieval dataset to adapt to another domain, and can use state-of-the-art generative models to generate high-quality image samples while satisfying rigorous DP guarantees. For instance, when evaluated on M
    
[^34]: 进化优化和贝叶斯优化中的模型不确定性：一项比较分析

    Model Uncertainty in Evolutionary Optimization and Bayesian Optimization: A Comparative Analysis

    [https://arxiv.org/abs/2403.14413](https://arxiv.org/abs/2403.14413)

    这项研究比较了进化优化和贝叶斯优化中的模型不确定性，引入了一种新的模型辅助策略以增强算法性能。

    

    黑盒优化问题在许多实际应用中很常见，需要通过输入输出交互来进行优化，而没有访问内部工作原理。贝叶斯优化（BO）和辅助代理进化算法（SAEA）是两种广泛使用的无梯度优化技术，用于解决这些挑战。本文旨在阐明这两种方法在利用模型不确定性方面的相似性和差异，以及模型不准确性对算法性能的影响。引入了一种新颖的模型辅助策略，利用未评估的解决方案生成后代，利用进化算法的基于种群的搜索能力来增强。

    arXiv:2403.14413v1 Announce Type: cross  Abstract: Black-box optimization problems, which are common in many real-world applications, require optimization through input-output interactions without access to internal workings. This often leads to significant computational resources being consumed for simulations. Bayesian Optimization (BO) and Surrogate-Assisted Evolutionary Algorithm (SAEA) are two widely used gradient-free optimization techniques employed to address such challenges. Both approaches follow a similar iterative procedure that relies on surrogate models to guide the search process. This paper aims to elucidate the similarities and differences in the utilization of model uncertainty between these two methods, as well as the impact of model inaccuracies on algorithmic performance. A novel model-assisted strategy is introduced, which utilizes unevaluated solutions to generate offspring, leveraging the population-based search capabilities of evolutionary algorithm to enhance 
    
[^35]: GLC++: 全局局部聚类和对比关联学习的无源通用域自适应

    GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning

    [https://arxiv.org/abs/2403.14410](https://arxiv.org/abs/2403.14410)

    该论文提出了GLC++方法，通过全局和局部聚类以及对比关联学习实现了无源通用域自适应，能够准确分类已知数据并将其从未知数据中分离。

    

    深度神经网络经常在协变量和类别转移下表现出次优性能。无源域自适应（SFDA）为这一困境提供了一个有希望的解决方案，然而大多数SFDA方法局限于封闭集场景。在本文中，我们探讨了旨在准确分类属于常见类别的“已知”数据并将其与目标专有“未知”数据隔离开来的无源通用域自适应（SF-UniDA）。我们提出了一种新颖的全球和局部聚类（GLC）技术，其中包括自适应的一对全局聚类算法来区分目标类别，辅以本地k-NN聚类策略以减轻负面转移。尽管有效，但固有的封闭源架构导致对“未知”数据的统一处理，阻碍了对不同“未知”类别的识别。为了解决这个问题，我们将GLC发展到GLC++，整合了对比亲和性。

    arXiv:2403.14410v1 Announce Type: cross  Abstract: Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify "known" data belonging to common categories and segregate them from target-private "unknown" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of "unknown" data, impeding the identification of distinct "unknown" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affini
    
[^36]: 物理信息扩散模型

    Physics-Informed Diffusion Models

    [https://arxiv.org/abs/2403.14404](https://arxiv.org/abs/2403.14404)

    提出了一个信息化去噪扩散模型框架，可在模型训练期间对生成样本施加约束，以改善样本与约束的对齐程度并提供自然的正则化，适用性广泛。

    

    生成模型如去噪扩散模型正快速提升其逼近高度复杂数据分布的能力。它们也越来越多地被运用于科学机器学习中，预期从隐含数据分布中取样的样本将遵守特定的控制方程。我们提出了一个框架，用于在模型训练期间对生成样本的基础约束进行信息化。我们的方法改善了生成样本与施加约束的对齐程度，显著优于现有方法而不影响推理速度。此外，我们的研究结果表明，在训练过程中加入这些约束提供了自然的防止过拟合的正则化。我们的框架易于实现，适用性广泛，可用于施加等式和不等式约束以及辅助优化目标。

    arXiv:2403.14404v1 Announce Type: new  Abstract: Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions. They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations. We present a framework to inform denoising diffusion models on underlying constraints on such generated samples during model training. Our approach improves the alignment of the generated samples with the imposed constraints and significantly outperforms existing methods without affecting inference speed. Additionally, our findings suggest that incorporating such constraints during training provides a natural regularization against overfitting. Our framework is easy to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives.
    
[^37]: 用效率低下的近似子问题解算器训练结构化神经网络的正则化自适应动量双平均

    Regularized Adaptive Momentum Dual Averaging with an Efficient Inexact Subproblem Solver for Training Structured Neural Network

    [https://arxiv.org/abs/2403.14398](https://arxiv.org/abs/2403.14398)

    提出了RAMDA算法用于训练结构化神经网络，引入了使用近似解的方法，并证明在收敛点附近RAMDA的迭代达到了最优结构。

    

    我们提出了一种用于训练结构化神经网络的正则化自适应动量双平均（RAMDA）算法。与现有的正则化自适应方法类似，RAMDA的更新方向计算子问题涉及非光滑正则化项和对角预处理器，因此一般而言没有封闭形式的解。我们精心设计了一个可实现的近似条件，保留了类似于精确版本的收敛性保证，并提出了一个配套的高效求解器，用于使RAMDA和现有方法的子问题在实践中可行。我们利用变分分析中的流形识别理论表明，即使存在这种近似性，RAMDA的迭代在渐近收敛的稳定点处达到由正则化项诱导的理想结构。在收敛点附近，这种结构在局部上是最优的。

    arXiv:2403.14398v1 Announce Type: new  Abstract: We propose a Regularized Adaptive Momentum Dual Averaging (RAMDA) algorithm for training structured neural networks. Similar to existing regularized adaptive methods, the subproblem for computing the update direction of RAMDA involves a nonsmooth regularizer and a diagonal preconditioner, and therefore does not possess a closed-form solution in general. We thus also carefully devise an implementable inexactness condition that retains convergence guarantees similar to the exact versions, and propose a companion efficient solver for the subproblems of both RAMDA and existing methods to make them practically feasible. We leverage the theory of manifold identification in variational analysis to show that, even in the presence of such inexactness, the iterates of RAMDA attain the ideal structure induced by the regularizer at the stationary point of asymptotic convergence. This structure is locally optimal near the point of convergence, so RAM
    
[^38]: 用于少样本类增量学习的一揽子技巧

    A Bag of Tricks for Few-Shot Class-Incremental Learning

    [https://arxiv.org/abs/2403.14392](https://arxiv.org/abs/2403.14392)

    提出了针对少样本类增量学习的一揽子技巧框架，将八种关键技术结合在一起，改进了稳定性、适应性和整体性能

    

    我们提出了一个一揽子技巧框架，用于少样本类增量学习（FSCIL），这是一种具有挑战性的连续学习形式，涉及对新任务进行连续适应，并且样本有限。 FSCIL 需要保持稳定性和适应性，即在学习新任务时保持先前学习任务的熟练程度。我们提出的一揽子技巧将八种关键且具有高影响力的技术汇集在一起，针对 FSCIL 在一个统一框架下改进稳定性、适应性和整体性能。我们将这些技巧组织成三类：稳定性技巧、适应性技巧和训练技巧。稳定性技巧旨在通过增强已学习类别的嵌入之间的分离和在学习新类别时最小化干扰来减轻先前学习类别的遗忘。另一方面，适应性技巧侧重于有效学习新类别。

    arXiv:2403.14392v1 Announce Type: cross  Abstract: We present a bag of tricks framework for few-shot class-incremental learning (FSCIL), which is a challenging form of continual learning that involves continuous adaptation to new tasks with limited samples. FSCIL requires both stability and adaptability, i.e., preserving proficiency in previously learned tasks while learning new ones. Our proposed bag of tricks brings together eight key and highly influential techniques that improve stability, adaptability, and overall performance under a unified framework for FSCIL. We organize these tricks into three categories: stability tricks, adaptability tricks, and training tricks. Stability tricks aim to mitigate the forgetting of previously learned classes by enhancing the separation between the embeddings of learned classes and minimizing interference when learning new ones. On the other hand, adaptability tricks focus on the effective learning of new classes. Finally, training tricks improv
    
[^39]: 用双机器学习估计因果效应--一种方法评估

    Estimating Causal Effects with Double Machine Learning -- A Method Evaluation

    [https://arxiv.org/abs/2403.14385](https://arxiv.org/abs/2403.14385)

    双重/无偏机器学习（DML）方法改进了因果效应估计中对非线性混淆关系的调整，摆脱传统函数形式假设，但仍然依赖于标准因果假设。

    

    使用观测数据估计因果效应仍然是一个非常活跃的研究领域。近年来，研究人员开发了利用机器学习放宽传统假设以估计因果效应的新框架。在本文中，我们回顾了其中一个最重要的方法-"双/无偏机器学习"（DML），并通过比较它在模拟数据上相对于更传统的统计方法的表现，然后将其应用于真实世界数据进行了实证评估。我们的研究发现表明，在DML中应用一个适当灵活的机器学习算法可以改进对各种非线性混淆关系的调整。这种优势使得可以摆脱通常在因果效应估计中必需的传统函数形式假设。然而，我们表明该方法在关于因果关系的标准假设方面仍然至关重要。

    arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal 
    
[^40]: 卷积模型的张量网络可压缩性

    Tensor network compressibility of convolutional models

    [https://arxiv.org/abs/2403.14379](https://arxiv.org/abs/2403.14379)

    张量化是将卷积神经网络中的卷积核替换为紧凑分解，并直接训练分解因子以偏向于低秩分解的方法，该研究探讨了张量化如何通过评估截断卷积核来保持准确性。

    

    卷积神经网络（CNNs）代表了最广泛使用的神经网络架构之一，在计算机视觉任务中展示了最先进的性能。尽管一般情况下更大的CNNs通常表现出更高的准确性，但通过“张量化”可以有效地减小它们的大小，同时保持准确性。张量化包括将卷积核替换为如Tucker、Canonical Polyadic分解或受量子启发的分解（如矩阵乘积状态）等紧凑的分解，并直接训练分解中的因子，以偏向于低秩分解。但为什么张量化似乎对准确性没有不利影响？我们通过评估截断密集（非张量化）CNNs的卷积核对其准确性的影响来探讨这一点。

    arXiv:2403.14379v1 Announce Type: cross  Abstract: Convolutional neural networks (CNNs) represent one of the most widely used neural network architectures, showcasing state-of-the-art performance in computer vision tasks. Although larger CNNs generally exhibit higher accuracy, their size can be effectively reduced by "tensorization" while maintaining accuracy. Tensorization consists of replacing the convolution kernels with compact decompositions such as Tucker, Canonical Polyadic decompositions, or quantum-inspired decompositions such as matrix product states, and directly training the factors in the decompositions to bias the learning towards low-rank decompositions. But why doesn't tensorization seem to impact the accuracy adversely? We explore this by assessing how truncating the convolution kernels of dense (untensorized) CNNs impact their accuracy. Specifically, we truncated the kernels of (i) a vanilla four-layer CNN and (ii) ResNet-50 pre-trained for image classification on CIF
    
[^41]: 基于知识增强的用户中心子图网络推荐

    Knowledge-Enhanced Recommendation with User-Centric Subgraph Network

    [https://arxiv.org/abs/2403.14377](https://arxiv.org/abs/2403.14377)

    提出了一种基于知识增强的用户中心子图网络推荐方法，通过将用户-物品交互信息和知识图中的附加信息结合到子图学习中，实现了有效的个性化推荐。

    

    推荐系统在当今各种平台上得到广泛实施，根据用户的偏好向他们推荐相关的物品。依赖用户-物品交互矩阵的经典方法存在局限性，特别是在新物品缺乏交互数据的情况下。基于知识图（KG）的推荐系统已经成为一种有前途的解决方案。然而，大多数基于KG的方法采用节点嵌入，这种方法不能为不同用户提供个性化推荐，也无法很好地推广到新物品。为了解决这些局限性，我们提出了基于知识增强的用户中心子图网络（KUCNet），这是一种利用图神经网络（GNN）进行有效推荐的子图学习方法。KUCNet为每个用户-物品对构建一个U-I子图，该子图捕获了用户-物品交互的历史信息和KG中提供的附加信息。基于注意力机制的GNN进入...

    arXiv:2403.14377v1 Announce Type: cross  Abstract: Recommendation systems, as widely implemented nowadays on various platforms, recommend relevant items to users based on their preferences. The classical methods which rely on user-item interaction matrices has limitations, especially in scenarios where there is a lack of interaction data for new items. Knowledge graph (KG)-based recommendation systems have emerged as a promising solution. However, most KG-based methods adopt node embeddings, which do not provide personalized recommendations for different users and cannot generalize well to the new items. To address these limitations, we propose Knowledge-enhanced User-Centric subgraph Network (KUCNet), a subgraph learning approach with graph neural network (GNN) for effective recommendation. KUCNet constructs a U-I subgraph for each user-item pair that captures both the historical information of user-item interactions and the side information provided in KG. An attention-based GNN is d
    
[^42]: 循环改进：一种从异构数据中提取共享特征的高效方法，无需中央服务器

    Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server

    [https://arxiv.org/abs/2403.14371](https://arxiv.org/abs/2403.14371)

    循环改进（LI）是一种无需中央服务器或数据交换的新颖方法，可提高数据异质性下的特征提取效率，表现优越于先进算法FedALA，并可应用于个性化联邦学习和全局模型环境。

    

    在联邦学习中，数据的异质性显著影响性能。一种典型的解决方案是将这些参数分为共享和个性化组件，这个概念在多任务学习中也很重要。针对这一问题，我们提出了“循环改进”（LI），这是一种新颖的方法，增强了这种分离和特征提取，而不需要中央服务器或参与者之间的数据交换。我们的实验显示，在个性化联邦学习环境中，LI在准确性方面始终优于先进的FedALA算法，适用于各种情况。此外，LI的特征提取器与聚合所有客户端数据时实现的性能相匹配。在全局模型环境中，使用具有堆叠个性化层和额外网络的LI也产生了与合并客户端数据场景相当的结果。此外，LI的适应能力延展到...

    arXiv:2403.14371v1 Announce Type: cross  Abstract: In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose "Loop Improvement" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to m
    
[^43]: 使用高光谱图像检测蜂蜜蜂上的变形螨

    Varroa destructor detection on honey bees using hyperspectral imagery

    [https://arxiv.org/abs/2403.14359](https://arxiv.org/abs/2403.14359)

    本研究提出了一种基于多元统计学的方法，可利用高光谱图像检测蜂蜜蜂上的寄生性变形螨，为蜜蜂巢穴的监测提供了新途径。

    

    农业中的高光谱（HS）图像越来越常见。 这些图像具有更高的光谱分辨率优势。 需要先进的光谱处理技术来解锁这些HS图像中的信息潜力。 本文介绍了一种基于多元统计学的方法，旨在检测寄生性变形螨对西方蜜蜂 Apis mellifera 身体的影响，从而实现对蜜蜂巢穴的更轻松连续监测。 该方法探讨了用于寄生物鉴定的无监督（K均值++）和最近开发的监督（核流- 偏最小二乘法，KF-PLS） 方法。此外，鉴于定制波段多光谱相机的出现，本研究概述了一种用于识别有效的蜜蜂-螨分离所需特定波长的策略，适用于在定制波段相机中实施。通过一个真实案例数据集进行说明

    arXiv:2403.14359v1 Announce Type: cross  Abstract: Hyperspectral (HS) imagery in agriculture is becoming increasingly common. These images have the advantage of higher spectral resolution. Advanced spectral processing techniques are required to unlock the information potential in these HS images. The present paper introduces a method rooted in multivariate statistics designed to detect parasitic Varroa destructor mites on the body of western honey bee Apis mellifera, enabling easier and continuous monitoring of the bee hives. The methodology explores unsupervised (K-means++) and recently developed supervised (Kernel Flows - Partial Least-Squares, KF-PLS) methods for parasitic identification. Additionally, in light of the emergence of custom-band multispectral cameras, the present research outlines a strategy for identifying the specific wavelengths necessary for effective bee-mite separation, suitable for implementation in a custom-band camera. Illustrated with a real-case dataset, our
    
[^44]: 探索大型语言模型在图生成中的潜力

    Exploring the Potential of Large Language Models in Graph Generation

    [https://arxiv.org/abs/2403.14358](https://arxiv.org/abs/2403.14358)

    本文探索了大型语言模型在图生成中的潜力，通过任务设计和实验考察了其对不同图结构规则的理解、捕获结构类型分布的能力以及利用领域知识进行基于属性的图生成。

    

    大型语言模型（LLMs）在许多领域取得了巨大成功，最近的研究探讨了探索LLMs用于图判别任务，如节点分类。然而，LLMs在图生成方面的能力在文献中尚未被探索。图生成要求LLM生成具有特定属性的图，这在药物发现等有价值的实际应用中非常重要，但也更具挑战性。在本文中，我们提出了LLM4GraphGen来探索LLMs进行图生成的能力，通过系统性任务设计和大量实验。具体而言，我们提出了几个任务，并进行了全面实验，以解决有关LLMs对不同图结构规则的理解、捕获结构类型分布的能力以及利用域知识进行基于属性的图生成的关键问题。我们的评估表明，LLMs，特别是

    arXiv:2403.14358v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particular
    
[^45]: DomainLab: 一个用于深度学习领域泛化的模块化Python包

    DomainLab: A modular Python package for domain generalization in deep learning

    [https://arxiv.org/abs/2403.14356](https://arxiv.org/abs/2403.14356)

    DomainLab是一个模块化Python包，允许用户训练指定的神经网络，并以组合的形式应用不同的正则化损失项，极大地方便了实验的可重现性。

    

    由于看不见的领域中存在的分布转移导致的泛化性能不佳经常阻碍深度神经网络的可信部署。许多领域泛化技术通过在训练过程中添加领域不变的正则化损失项来解决这个问题。然而，缺乏模块化软件，允许用户以最小的努力将不同方法的优势结合在一起，以实现可重现性。DomainLab是一个模块化的Python包，用于训练用户指定的神经网络，并且可以组合不同的正则化损失项。它的解耦设计允许将神经网络与正则化损失构建分开。神经网络的层次组合、不同的领域泛化方法和相关超参数都可以与其他实验设置一起在单个配置文件中指定。

    arXiv:2403.14356v1 Announce Type: new  Abstract: Poor generalization performance caused by distribution shifts in unseen domains often hinders the trustworthy deployment of deep neural networks. Many domain generalization techniques address this problem by adding a domain invariant regularization loss terms during training. However, there is a lack of modular software that allows users to combine the advantages of different methods with minimal effort for reproducibility. DomainLab is a modular Python package for training user specified neural networks with composable regularization loss terms. Its decoupled design allows the separation of neural networks from regularization loss construction. Hierarchical combinations of neural networks, different domain generalization methods, and associated hyperparameters, can all be specified together with other experimental setup in a single configuration file. Hierarchical combinations of neural networks, different domain generalization methods,
    
[^46]: DaCapo：加快自主系统在视频分析中的持续学习

    DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video Analytics

    [https://arxiv.org/abs/2403.14353](https://arxiv.org/abs/2403.14353)

    该论文提出了一种在自主系统中加速视频分析的持续学习方法，通过利用轻量级“学生”模型进行部署推理，利用更大的“教师”模型进行数据标记，实现对不断变化场景的持续自适应。

    

    深度神经网络（DNN）视频分析对于自动驾驶车辆、无人机（UAV）和安防机器人等自主系统至关重要。然而，由于其有限的计算资源和电池功率，实际部署面临挑战。为了解决这些挑战，持续学习利用在部署（推理）中的轻量级“学生”模型，利用更大的“教师”模型对采样数据进行标记（标记），并不断重新训练学生模型以适应不断变化的场景。

    arXiv:2403.14353v1 Announce Type: cross  Abstract: Deep neural network (DNN) video analytics is crucial for autonomous systems such as self-driving vehicles, unmanned aerial vehicles (UAVs), and security robots. However, real-world deployment faces challenges due to their limited computational resources and battery power. To tackle these challenges, continuous learning exploits a lightweight "student" model at deployment (inference), leverages a larger "teacher" model for labeling sampled data (labeling), and continuously retrains the student model to adapt to changing scenarios (retraining). This paper highlights the limitations in state-of-the-art continuous learning systems: (1) they focus on computations for retraining, while overlooking the compute needs for inference and labeling, (2) they rely on power-hungry GPUs, unsuitable for battery-operated autonomous systems, and (3) they are located on a remote centralized server, intended for multi-tenant scenarios, again unsuitable for
    
[^47]: 通过生成方法探索图表示学习中的任务统一化

    Exploring Task Unification in Graph Representation Learning via Generative Approach

    [https://arxiv.org/abs/2403.14340](https://arxiv.org/abs/2403.14340)

    通过提出GA^2E，一个统一的框架，通过统一的生成式半监督学习，在单个训练阶段中实现了图生成、图判别和图预测任务。

    

    图在现实场景中无处不在，并涵盖了从节点级、边级和图级任务到迁移学习的各种任务。然而，为每种类型的图数据设计特定任务通常代价高昂且缺乏泛化能力。最近的研究致力于“预训练+微调”或“预训练+提示”范式，旨在设计一个能够泛化多种图任务的统一框架。在这些方法中，图自编码器（GAEs）、生成自监督模型已经证明了它们在有效解决各种图任务方面的潜力。然而，这些方法通常使用多阶段训练并需要自适应设计，这一方面使得将其无缝应用于不同的图任务变得困难，另一方面忽略了不同阶段任务目标之间的差异造成的负面影响。为了解决这些挑战，我们提出了GA^2E，一个统一的框架，通过统一的生成式半监督学习，可以在单个训练阶段中同时实现图生成、图判别和图预测任务。

    arXiv:2403.14340v1 Announce Type: cross  Abstract: Graphs are ubiquitous in real-world scenarios and encompass a diverse range of tasks, from node-, edge-, and graph-level tasks to transfer learning. However, designing specific tasks for each type of graph data is often costly and lacks generalizability. Recent endeavors under the "Pre-training + Fine-tuning" or "Pre-training + Prompt" paradigms aim to design a unified framework capable of generalizing across multiple graph tasks. Among these, graph autoencoders (GAEs), generative self-supervised models, have demonstrated their potential in effectively addressing various graph tasks. Nevertheless, these methods typically employ multi-stage training and require adaptive designs, which on one hand make it difficult to be seamlessly applied to diverse graph tasks and on the other hand overlook the negative impact caused by discrepancies in task objectives between the different stages. To address these challenges, we propose GA^2E, a unifi
    
[^48]: $\nabla \tau$: 基于梯度且任务无关的机器遗忘

    $\nabla \tau$: Gradient-based and Task-Agnostic machine Unlearning

    [https://arxiv.org/abs/2403.14339](https://arxiv.org/abs/2403.14339)

    $\nabla \tau$ 是一种旨在高效消除部分训练数据影响的机器遗忘优化框架。

    

    机器遗忘是一种有选择性地消除模型训练过程中某些数据示例影响的过程，作为从业者遵守最近的数据保护法规的手段，已经引起了显著关注。然而，现有的遗忘方法面临着关键缺点，包括其成本过高，通常与大量超参数相关，以及仅忘记相对较小数据部分的限制。这经常导致从头开始重新训练模型成为更快速和更有效的解决方案。在本研究中，我们介绍了基于梯度且任务无关的机器遗忘（$\nabla \tau$），这是一种旨在高效消除部分训练数据影响的优化框架。它对待遗忘的数据应用自适应梯度上升，同时对其余数据使用标准梯度下降。$\nabla \tau$相对于现有方法提供了多种优势。

    arXiv:2403.14339v1 Announce Type: cross  Abstract: Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations. However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions. This often makes retraining the model from scratch a quicker and more effective solution. In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\nabla \tau$), an optimization framework designed to remove the influence of a subset of training data efficiently. It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data. $\nabla \tau$ offers multiple benefits over existing approache
    
[^49]: 面向良好聚类图的差分隐私聚类算法

    A Differentially Private Clustering Algorithm for Well-Clustered Graphs

    [https://arxiv.org/abs/2403.14332](https://arxiv.org/abs/2403.14332)

    提出了一种面向良好聚类图的差分隐私聚类算法，适用于具有k个几乎平衡集群的图，误分类比率接近最佳非私有算法的水平

    

    我们研究了用于恢复良好聚类图中聚类的差分隐私（DP）算法，这些图的顶点集可以分为少量的集合，每个集合诱导出具有高内电导和小外电导的子图。这些图在谱聚类的理论分析中被广泛应用作为基准。我们提供了一个专门针对这种图设计的高效（ϵ，δ）-DP算法。我们的算法汲取了陈等人最近的研究成果，他们为图包含两个几乎平衡集群的情况开发了DP算法。我们的算法适用于具有k个几乎平衡集群的良好聚类图，并且误分类比率几乎与最佳已知的非私有算法相匹配。我们对已知地面真实聚类的数据集进行实验评估以证实

    arXiv:2403.14332v1 Announce Type: cross  Abstract: We study differentially private (DP) algorithms for recovering clusters in well-clustered graphs, which are graphs whose vertex set can be partitioned into a small number of sets, each inducing a subgraph of high inner conductance and small outer conductance. Such graphs have widespread application as a benchmark in the theoretical analysis of spectral clustering. We provide an efficient ($\epsilon$,$\delta$)-DP algorithm tailored specifically for such graphs. Our algorithm draws inspiration from the recent work of Chen et al., who developed DP algorithms for recovery of stochastic block models in cases where the graph comprises exactly two nearly-balanced clusters. Our algorithm works for well-clustered graphs with $k$ nearly-balanced clusters, and the misclassification ratio almost matches the one of the best-known non-private algorithms. We conduct experimental evaluations on datasets with known ground truth clusters to substantiate
    
[^50]: 将强化学习策略提炼为可解释的机器人运动：梯度提升机和符号回归

    Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression

    [https://arxiv.org/abs/2403.14328](https://arxiv.org/abs/2403.14328)

    通过梯度提升机和符号回归等技术，将神经网络的强化学习策略转化为更可解释的形式，提高了机器人运动策略的透明度和可理解性。

    

    最近强化学习（RL）的发展使机器人运动能力取得了显著进展。然而，基于神经网络的RL策略的复杂性和“黑匣子”特性阻碍了它们的可解释性和更广泛的接受度，特别是在要求高水平安全性和可靠性的应用中。本文引入了一种将神经RL策略提炼为更可解释形式的新方法，使用梯度提升机（GBMs）、可解释提升机（EBMs）和符号回归。通过利用广义加法模型、决策树和分析表达式的固有可解释性，我们将不透明的神经网络策略转化为更透明的“玻璃箱”模型。我们使用RL训练专家神经网络策略，然后将它们提炼为(i) GBMs、(ii) EBMs和(iii)符号策略。为了解决行为分布转移挑战

    arXiv:2403.14328v1 Announce Type: cross  Abstract: Recent advancements in reinforcement learning (RL) have led to remarkable achievements in robot locomotion capabilities. However, the complexity and ``black-box'' nature of neural network-based RL policies hinder their interpretability and broader acceptance, particularly in applications demanding high levels of safety and reliability. This paper introduces a novel approach to distill neural RL policies into more interpretable forms using Gradient Boosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic Regression. By leveraging the inherent interpretability of generalized additive models, decision trees, and analytical expressions, we transform opaque neural network policies into more transparent ``glass-box'' models. We train expert neural network policies using RL and subsequently distill them into (i) GBMs, (ii) EBMs, and (iii) symbolic policies. To address the inherent distribution shift challenge of behavioral 
    
[^51]: 研究结构学习算法在识别糖尿病患者干预风险因素方面的有效性

    Investigating the validity of structure learning algorithms in identifying risk factors for intervention in patients with diabetes

    [https://arxiv.org/abs/2403.14327](https://arxiv.org/abs/2403.14327)

    本研究探讨了结构学习算法在识别影响糖尿病进展的风险因素方面的有效性，并强调算法选择对干预结果的重大影响。

    

    糖尿病作为一种普遍而长期存在的健康挑战，对全球健康、金融医疗系统和社会福祉都产生重要影响。本研究全面探讨了各种结构学习算法，以辨认影响糖尿病进展的潜在风险因素之间因果路径。方法涉及将这些算法应用于相关糖尿病数据，然后将它们的输出图转换为因果贝叶斯网络（CBNs），实现预测分析并评估我们特定案例研究内假想干预效果的差异。本研究突显了算法选择对干预结果的重大影响。为了整合来自不同算法的见解，我们采用了一种模型平均技术，帮助我们从各种结构学习算法中获得针对糖尿病的独特因果模型。

    arXiv:2403.14327v1 Announce Type: new  Abstract: Diabetes, a pervasive and enduring health challenge, imposes significant global implications on health, financial healthcare systems, and societal well-being. This study undertakes a comprehensive exploration of various structural learning algorithms to discern causal pathways amongst potential risk factors influencing diabetes progression. The methodology involves the application of these algorithms to relevant diabetes data, followed by the conversion of their output graphs into Causal Bayesian Networks (CBNs), enabling predictive analysis and the evaluation of discrepancies in the effect of hypothetical interventions within our context-specific case study.   This study highlights the substantial impact of algorithm selection on intervention outcomes. To consolidate insights from diverse algorithms, we employ a model-averaging technique that helps us obtain a unique causal model for diabetes derived from a varied set of structural lear
    
[^52]: 基于神经网络的处理和重建受损生物光子图像数据

    Neural Network-Based Processing and Reconstruction of Compromised Biophotonic Image Data

    [https://arxiv.org/abs/2403.14324](https://arxiv.org/abs/2403.14324)

    利用深度学习模型补偿生物光子图像数据受损，提升生物成像的时间分辨率和降低成本/尺寸。

    

    利用深度学习技术与生物光子设置的整合在生物成像领域开辟了新的视野。该领域中的一个引人注目的趋势是有意地破坏某些测量指标，以设计更好的生物成像工具，从成本、速度和形态因素上进行补偿所产生的缺陷，随后通过利用在大量理想、优越或替代数据上训练的深度学习模型来补偿这些缺陷。这种战略性方法因其提升生物光子成像各个方面的潜力而日益受到青睐。采用这种策略的一个主要动机是追求更高的时间分辨率或增加成像速度，这对捕捉精细的动态生物过程至关重要。这种方法还提供了简化硬件要求/复杂性的可能性，从而以成本和/或尺寸上更易接受的方式使得先进的成像标准更具可及性。

    arXiv:2403.14324v1 Announce Type: cross  Abstract: The integration of deep learning techniques with biophotonic setups has opened new horizons in bioimaging. A compelling trend in this field involves deliberately compromising certain measurement metrics to engineer better bioimaging tools in terms of cost, speed, and form-factor, followed by compensating for the resulting defects through the utilization of deep learning models trained on a large amount of ideal, superior or alternative data. This strategic approach has found increasing popularity due to its potential to enhance various aspects of biophotonic imaging. One of the primary motivations for employing this strategy is the pursuit of higher temporal resolution or increased imaging speed, critical for capturing fine dynamic biological processes. This approach also offers the prospect of simplifying hardware requirements/complexities, thereby making advanced imaging standards more accessible in terms of cost and/or size. This ar
    
[^53]: SpikingResformer: 将ResNet和Vision Transformer在脉冲神经网络中进行桥接

    SpikingResformer: Bridging ResNet and Vision Transformer in Spiking Neural Networks

    [https://arxiv.org/abs/2403.14302](https://arxiv.org/abs/2403.14302)

    提出了一种新型脉冲自注意机制DSSA以及结合ResNet的多阶段架构的SpikingResformer架构，旨在改善性能和能效，并减少参数。

    

    Vision Transformer在人工神经网络中取得了显著成功，这导致了在脉冲神经网络(SNNs)中结合自注意机制和基于Transformer的结构引起越来越多的兴趣。为了解决这些挑战，我们提出了一种名为Dual Spike Self-Attention (DSSA)的新型脉冲自注意机制，带有合理的扩展方法。基于DSSA，我们提出了一种名为SpikingResformer的新型脉冲Vision Transformer架构，将基于ResNet的多阶段架构与我们提出的DSSA相结合，以提高性能和能效，同时减少参数。

    arXiv:2403.14302v1 Announce Type: cross  Abstract: The remarkable success of Vision Transformers in Artificial Neural Networks (ANNs) has led to a growing interest in incorporating the self-attention mechanism and transformer-based architecture into Spiking Neural Networks (SNNs). While existing methods propose spiking self-attention mechanisms that are compatible with SNNs, they lack reasonable scaling methods, and the overall architectures proposed by these methods suffer from a bottleneck in effectively extracting local features. To address these challenges, we propose a novel spiking self-attention mechanism named Dual Spike Self-Attention (DSSA) with a reasonable scaling method. Based on DSSA, we propose a novel spiking Vision Transformer architecture called SpikingResformer, which combines the ResNet-based multi-stage architecture with our proposed DSSA to improve both performance and energy efficiency while reducing parameters. Experimental results show that SpikingResformer ach
    
[^54]: 地球观测应用中缺失数据对模型预测的影响评估

    Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications

    [https://arxiv.org/abs/2403.14297](https://arxiv.org/abs/2403.14297)

    本研究评估了在地球观测应用中缺失数据对训练模型的影响，发现集成策略可以实现高达100%的预测稳健性，同时揭示了缺失情景在回归任务中比分类任务更具挑战性，且光学视角是最关键的。

    

    地球观测（EO）应用涉及复杂和异构数据源，通常采用机器学习模型进行处理。然而，人们普遍假设数据源将持续可用。不同情况可能影响EO数据源的可用性，如噪声、云层或卫星任务失败。本研究评估了在四个数据集上进行的分类和回归任务中缺失时间性和静态EO数据源对训练模型的影响。我们比较了不同方法的预测质量，并发现一些方法在面对缺失数据时自然更加稳健。特别是集成策略实现了高达100%的预测稳健性。我们发现缺失情景在回归任务中比分类任务更具挑战性。最后，我们发现光学视角在单独缺失时是最关键的视角。

    arXiv:2403.14297v1 Announce Type: cross  Abstract: Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models. However, there is a common assumption that data sources will be persistently available. Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures. In this work, we assess the impact of missing temporal and static EO sources in trained models across four datasets with classification and regression tasks. We compare the predictive quality of different methods and find that some are naturally more robust to missing data. The Ensemble strategy, in particular, achieves a prediction robustness up to 100%. We evidence that missing scenarios are significantly more challenging in regression than classification tasks. Finally, we find that the optical view is the most critical view when it is missing individually.
    
[^55]: 探索用于音频深度伪造检测的绿色人工智能

    Exploring Green AI for Audio Deepfake Detection

    [https://arxiv.org/abs/2403.14290](https://arxiv.org/abs/2403.14290)

    该研究提出了一个可以利用标准CPU资源训练的音频深度伪造检测新框架，以解决使用高性能计算和长训练时间带来的碳排放问题。

    

    深度神经网络基础的最先进音频深度伪造检测器展现出令人印象深刻的识别性能。然而，这一优势伴随着可观的碳足迹。这主要是由于使用带有加速器和长训练时间的高性能计算。研究表明，平均深度自然语言处理模型产生约626千磅的CO\textsubscript{2}，相当于其生命周期内平均美国汽车排放量的五倍。这显然是对环境的巨大威胁。为了解决这一挑战，本研究提出了一个可以利用标准CPU资源无缝训练的音频深度伪造检测新框架。我们提出的框架利用预先训练并在公共代码库中可用的现成自监督学习（SSL）模型。与现有方法相比，该框架不仅调整SSL模型，还采用额外的深度神经网络执行下游任务。

    arXiv:2403.14290v1 Announce Type: cross  Abstract: The state-of-the-art audio deepfake detectors leveraging deep neural networks exhibit impressive recognition performance. Nonetheless, this advantage is accompanied by a significant carbon footprint. This is mainly due to the use of high-performance computing with accelerators and high training time. Studies show that average deep NLP model produces around 626k lbs of CO\textsubscript{2} which is equivalent to five times of average US car emission at its lifetime. This is certainly a massive threat to the environment. To tackle this challenge, this study presents a novel framework for audio deepfake detection that can be seamlessly trained using standard CPU resources. Our proposed framework utilizes off-the-shelve self-supervised learning (SSL) based models which are pre-trained and available in public repositories. In contrast to existing methods that fine-tune SSL models and employ additional deep neural networks for downstream task
    
[^56]: 评估深度说话人分离的光谱聚类的稳健性

    Assessing the Robustness of Spectral Clustering for Deep Speaker Diarization

    [https://arxiv.org/abs/2403.14286](https://arxiv.org/abs/2403.14286)

    评估了在不同领域数据集下光谱聚类对说话人分离稳健性的影响，发现说话人分离性能差异源于光谱聚类的作用和参数不匹配。

    

    说话人嵌入的聚类对说话人分离至关重要，但与其他组件相比，尚未得到足够关注。此外，在开发和评估数据来自不同领域时，跨各种数据集评估说话人分离的稳健性也尚未被探讨。为填补这一空白，本研究彻底研究了光谱聚类在相同领域和跨领域说话人分离中的应用。我们在两个广泛使用的语料库AMI和DIHARD上进行了大量实验，揭示了领域不匹配情况下说话人分离性能趋势。我们观察到在两种不同领域条件下的性能差异可以归因于光谱聚类的作用。特别是在其他模块保持不变的情况下，我们展示了最优调参参数以及说话人计数估计的差异起源于不匹配。这项研究为说话人分离研究开辟了几个未来方向。

    arXiv:2403.14286v1 Announce Type: cross  Abstract: Clustering speaker embeddings is crucial in speaker diarization but hasn't received as much focus as other components. Moreover, the robustness of speaker diarization across various datasets hasn't been explored when the development and evaluation data are from different domains. To bridge this gap, this study thoroughly examines spectral clustering for both same-domain and cross-domain speaker diarization. Our extensive experiments on two widely used corpora, AMI and DIHARD, reveal the performance trend of speaker diarization in the presence of domain mismatch. We observe that the performance difference between two different domain conditions can be attributed to the role of spectral clustering. In particular, keeping other modules unchanged, we show that differences in optimal tuning parameters as well as speaker count estimation originates due to the mismatch. This study opens several future directions for speaker diarization resear
    
[^57]: 如何做到公平？标签和选择偏差研究

    How to be fair? A study of label and selection bias

    [https://arxiv.org/abs/2403.14282](https://arxiv.org/abs/2403.14282)

    研究探讨数据偏见如何影响模型公平性，提出了建立偏见类型与缓解技术有效性之间关系的方法

    

    众所周知，偏见数据会导致偏见、潜在不公平的模型。因此，已经提出了几种用于数据和模型预测偏见的措施，以及其目标是通过设计公平的偏见缓解技术来学习模型。近十年来已经发展了大量的缓解技术，然而，在什么情况下哪些方法起作用仍然知之甚少。最近，Wick等人在合成数据上的实验表明，存在一些情况，其中偏见缓解技术导致在无偏数据上测量时更精确的模型。然而，在缺乏彻底的数学分析的情况下，仍不清楚在何种情况下哪些技术是有效的。我们提出通过建立偏见类型与缓解技术有效性之间的关系来解决这个问题，我们将缓解技术按

    arXiv:2403.14282v1 Announce Type: cross  Abstract: It is widely accepted that biased data leads to biased and thus potentially unfair models. Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design. Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work. Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data. Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances. We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by 
    
[^58]: 场景图ViT：端到端的开放词汇视觉关系检测

    Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship Detection

    [https://arxiv.org/abs/2403.14270](https://arxiv.org/abs/2403.14270)

    提出了一种简单高效的无解码器架构，用于开放词汇的视觉关系检测，通过Transformer-based图像编码器隐式建模对象之间的关系，使用注意力机制提取关系信息，在混合数据上进行端到端训练，实现了最先进的关系检测性能。

    

    视觉关系检测旨在识别图像中的对象及其关系。以往的方法通过在现有目标检测架构中添加单独的关系模块或解码器来处理此任务。这种分离增加了复杂性，阻碍了端到端训练，限制了性能。我们提出了一种简单且高效的无解码器架构，用于开放词汇的视觉关系检测。我们的模型由基于Transformer的图像编码器组成，将对象表示为标记，并隐含地建模它们的关系。为了提取关系信息，我们引入了一个注意力机制，选择可能形成关系的对象对。我们提供了一个单阶段的训练方法，可以在混合对象和关系检测数据上训练此模型。我们的方法在Visual Genome和大词汇GQA基准测试上实现了最先进的关系检测性能，可实现实时性。

    arXiv:2403.14270v1 Announce Type: cross  Abstract: Visual relationship detection aims to identify objects and their relationships in images. Prior methods approach this task by adding separate relationship modules or decoders to existing object detection architectures. This separation increases complexity and hinders end-to-end training, which limits performance. We propose a simple and highly efficient decoder-free architecture for open-vocabulary visual relationship detection. Our model consists of a Transformer-based image encoder that represents objects as tokens and models their relationships implicitly. To extract relationship information, we introduce an attention mechanism that selects object pairs likely to form a relationship. We provide a single-stage recipe to train this model on a mixture of object and relationship detection data. Our approach achieves state-of-the-art relationship detection performance on Visual Genome and on the large-vocabulary GQA benchmark at real-tim
    
[^59]: 具有集成结构的扩散模型用于无监督异常检测

    Diffusion Models with Ensembled Structure-Based Anomaly Scoring for Unsupervised Anomaly Detection

    [https://arxiv.org/abs/2403.14262](https://arxiv.org/abs/2403.14262)

    本研究探讨了使用结构相似度(SSIM)作为异常检测中的评分函数，通过自适应集成策略为不同病理学提供更具病理学普适性的评分机制。

    

    监督深度学习技术在医学图像分析中显示出潜力，然而，它们需要全面的带注释数据集，这对于罕见疾病尤其具有挑战性。因此，无监督异常检测(UAD)作为病理分割的一种可行替代方案出现，因为只需要健康数据进行训练。然而，最近的UAD异常评分函数通常只关注强度，忽略结构差异，这影响了分割性能。本研究探讨了结构相似度(SSIM)作为弥合这一差距的潜力。SSIM捕捉了强度和结构差异，且可能优于传统的$l1$误差。然而，我们表明对于不同病理学，SSIM计算存在多个最佳核大小。因此，我们研究了用于不同核大小的自适应集成策略，以提供更具病理学普适性的评分机制。

    arXiv:2403.14262v1 Announce Type: cross  Abstract: Supervised deep learning techniques show promise in medical image analysis. However, they require comprehensive annotated data sets, which poses challenges, particularly for rare diseases. Consequently, unsupervised anomaly detection (UAD) emerges as a viable alternative for pathology segmentation, as only healthy data is required for training. However, recent UAD anomaly scoring functions often focus on intensity only and neglect structural differences, which impedes the segmentation performance. This work investigates the potential of Structural Similarity (SSIM) to bridge this gap. SSIM captures both intensity and structural disparities and can be advantageous over the classical $l1$ error. However, we show that there is more than one optimal kernel size for the SSIM calculation for different pathologies. Therefore, we investigate an adaptive ensembling strategy for various kernel sizes to offer a more pathology-agnostic scoring mec
    
[^60]: ERD：一个用于改善认知失调分类的LLM推理框架

    ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification

    [https://arxiv.org/abs/2403.14255](https://arxiv.org/abs/2403.14255)

    ERD提出了一个框架，通过提取与认知失调相关的部分和通过多个代理人进行推理步骤的辩论，改进了基于LLM的认知失调分类性能。

    

    使用大型语言模型（LLMs）改进心理治疗的可访问性近年来受到了重视。从受访者的话语中识别认知失调可以是心理治疗的重要组成部分，特别是对于认知行为疗法。在本文中，我们提出了ERD，通过额外模块的（1）提取与认知失调相关的部分和（2）通过多个代理人进行推理步骤的辩论，提高了基于LLM的认知失调分类性能。我们在一个公共数据集上的实验结果显示，ERD提高了多类F1分数以及二元特异性分数。关于后者的分数，我们的方法在向LLMs提供多代理人辩论摘要时有效地消除了基准方法的偏见，尤其是当该摘要被提供给LLMs时。

    arXiv:2403.14255v1 Announce Type: new  Abstract: Improving the accessibility of psychotherapy with the aid of Large Language Models (LLMs) is garnering a significant attention in recent years. Recognizing cognitive distortions from the interviewee's utterances can be an essential part of psychotherapy, especially for cognitive behavioral therapy. In this paper, we propose ERD, which improves LLM-based cognitive distortion classification performance with the aid of additional modules of (1) extracting the parts related to cognitive distortion, and (2) debating the reasoning steps by multiple agents. Our experimental results on a public dataset show that ERD improves the multi-class F1 score as well as binary specificity score. Regarding the latter score, it turns out that our method is effective in debiasing the baseline method which has high false positive rate, especially when the summary of multi-agent debate is provided to LLMs.
    
[^61]: LayoutLLM：大规模语言模型指令调整用于视觉丰富文档理解

    LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding

    [https://arxiv.org/abs/2403.14252](https://arxiv.org/abs/2403.14252)

    提出了一种新的LayoutLLM模型，通过结合大规模语言模型和文档图像理解的优势，实现了对文档图像的理解。

    

    这篇论文提出了LayoutLLM，一种更灵活的文档分析方法，用于理解图像文档。视觉丰富文档理解任务，如文档图像分类和信息提取，由于其重要性而受到重视。现有方法旨在通过整合对图像、文本和布局结构的预训练意识来提升文档理解能力。然而，这些方法需要针对每个任务和数据集进行微调，而且模型训练和操作成本高昂。为了克服这一限制，我们提出了一种新的LayoutLLM，将这些与大规模语言模型（LLMs）相集成。通过利用现有研究在文档图像理解和LLMs卓越的语言理解能力方面的优势，所提出的模型在多模态指令数据集的微调下，可以通过单个模型理解文档图像。

    arXiv:2403.14252v1 Announce Type: cross  Abstract: This paper proposes LayoutLLM, a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks, such as document image classification and information extraction, have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images, text, and layout structure. However, these methods require fine-tuning for each task and dataset, and the models are expensive to train and operate. To overcome this limitation, we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs' superior language understanding capabilities, the proposed model, fine-tuned with multimodal instruction datasets, performs an understanding of document images in a single model. Our experime
    
[^62]: 同性质高斯飘屑实现实时辐射场渲染

    Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering

    [https://arxiv.org/abs/2403.14244](https://arxiv.org/abs/2403.14244)

    提出使用同性质高斯核替代各向异性核来提高计算性能，在不失去几何表示准确性的情况下实现约100倍的加速，适用于多种需要辐射场的应用领域。

    

    3D高斯飘屑方法因其在训练中的高性能和渲染图像的高质量而备受关注。然而，它使用各向异性的高斯核来表示场景。虽然这种各向异性核在表示几何方面具有优势，但在计算方面会导致诸如分裂或合并两个核的困难。本文提出使用同性质高斯核来避免计算中的这些困难，从而导致一种性能更高的方法。实验证实，所提出的方法比原方法快约100倍，而不会丢失几何表示的准确性。所提出的方法可应用于需要辐射场的大范围应用，如3D重建、视图合成和动态对象建模。

    arXiv:2403.14244v1 Announce Type: cross  Abstract: The 3D Gaussian splatting method has drawn a lot of attention, thanks to its high performance in training and high quality of the rendered image. However, it uses anisotropic Gaussian kernels to represent the scene. Although such anisotropic kernels have advantages in representing the geometry, they lead to difficulties in terms of computation, such as splitting or merging two kernels. In this paper, we propose to use isotropic Gaussian kernels to avoid such difficulties in the computation, leading to a higher performance method. The experiments confirm that the proposed method is about {\bf 100X} faster without losing the geometry representation accuracy. The proposed method can be applied in a large range applications where the radiance field is needed, such as 3D reconstruction, view synthesis, and dynamic object modeling.
    
[^63]: 一个统一的模型编辑框架

    A Unified Framework for Model Editing

    [https://arxiv.org/abs/2403.14236](https://arxiv.org/abs/2403.14236)

    这个统一框架结合了“定位和编辑”模型编辑技术，最大化保留某些向量表示并记忆新事实信息。

    

    模型编辑是一个不断发展的领域，专注于更新模型中嵌入的知识。在各种方法中，ROME和MEMIT作为主要的“定位和编辑”模型编辑技术脱颖而出。而MEMIT可以批量编辑记忆，ROME则一次只能改变一个事实。本文引入了一个统一的框架，将ROME和MEMIT纳入一个单一的概念框架，优化同一目标，我们称之为“保存-记忆”目标。该目标旨在在记忆新事实信息的同时保留某些选定向量的表示。具体来说，ROME使用等式约束优化此目标，而MEMIT采用更灵活的最小二乘约束。除了批量编辑外，MEMIT还可以在多个层面编辑模型。我们将编辑的分布从多个层面分开，区别于优化目标。

    arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading "locate-and-edit" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the "preservation-memorization" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objectiv
    
[^64]: RG-CAT: EMU Pilot Survey中天体检测管线和无线电星系目录

    RG-CAT: Detection Pipeline and Catalogue of Radio Galaxies in the EMU Pilot Survey

    [https://arxiv.org/abs/2403.14235](https://arxiv.org/abs/2403.14235)

    通过Gal-DINO计算机视觉网络，我们建立了EMU Pilot Survey中的射电星系目录，可高效预测无线电源形态、位置和红外主机信息。

    

    我们提出了源检测和目录构建管线，以构建通过澳大利亚平方千米阵列探测器（ASKAP）望远镜进行的Evolutionary Map of the Universe（EMU-PS）270 $\rm deg^2$试验观测的第一个无线电星系目录。检测管线使用Gal-DINO计算机视觉网络（Gupta等人，2024年）来预测无线电源的类别和边界框，以及它们潜在的红外主机位置。Gal-DINO网络在大约5,000个经过视觉检验的无线电星系及其红外主机上进行训练和评估，包括紧凑和扩展的无线电形态。我们发现，对于99%的无线电源，预测和真值边界框的交集超过0.5，98%的预测主机位置与真值红外主机在评估中距离小于$3^{\prime \prime}$。

    arXiv:2403.14235v1 Announce Type: cross  Abstract: We present source detection and catalogue construction pipelines to build the first catalogue of radio galaxies from the 270 $\rm deg^2$ pilot survey of the Evolutionary Map of the Universe (EMU-PS) conducted with the Australian Square Kilometre Array Pathfinder (ASKAP) telescope. The detection pipeline uses Gal-DINO computer-vision networks (Gupta et al., 2024) to predict the categories of radio morphology and bounding boxes for radio sources, as well as their potential infrared host positions. The Gal-DINO network is trained and evaluated on approximately 5,000 visually inspected radio galaxies and their infrared hosts, encompassing both compact and extended radio morphologies. We find that the Intersection over Union (IoU) for the predicted and ground truth bounding boxes is larger than 0.5 for 99% of the radio sources, and 98% of predicted host positions are within $3^{\prime \prime}$ of the ground truth infrared host in the evalua
    
[^65]: SoftPatch：无监督噪声数据异常检测

    SoftPatch: Unsupervised Anomaly Detection with Noisy Data

    [https://arxiv.org/abs/2403.14233](https://arxiv.org/abs/2403.14233)

    首次考虑图像传感器异常检测中的标签级别噪声，并提出了一种能够有效去噪补丁级别数据的无监督异常检测方法SoftPatch。

    

    虽然主流的无监督异常检测算法在学术数据集中表现良好，但由于理想的干净训练数据的实验设置，它们在实际应用中的性能受到限制。 在真实世界的异常检测中，使用噪声数据进行训练是一个不可避免的问题，但很少有讨论。 本文首次考虑了图像传感器异常检测中的标签级别噪声。 为了解决这个问题，我们提出了一种基于内存的无监督AD方法SoftPatch，该方法能够有效地对补丁级别的数据进行去噪。 噪声判别器用于生成用于补丁级别噪声消除的异常点评分，然后将这些评分存储在内存存储器中，以软化异常检测边界。 与现有方法相比，SoftPatch保持了对正常数据的强建模能力，并减轻了coreset中的过度自信问题。在实验中进行了综合性实验证明。

    arXiv:2403.14233v1 Announce Type: cross  Abstract: Although mainstream unsupervised anomaly detection (AD) algorithms perform well in academic datasets, their performance is limited in practical application due to the ideal experimental setting of clean training data. Training with noisy data is an inevitable problem in real-world anomaly detection but is seldom discussed. This paper considers label-level noise in image sensory anomaly detection for the first time. To solve this problem, we proposed a memory-based unsupervised AD method, SoftPatch, which efficiently denoises the data at the patch level. Noise discriminators are utilized to generate outlier scores for patch-level noise elimination before coreset construction. The scores are then stored in the memory bank to soften the anomaly detection boundary. Compared with existing methods, SoftPatch maintains a strong modeling ability of normal data and alleviates the overconfidence problem in coreset. Comprehensive experiments in v
    
[^66]: 异质剂量-响应曲线估计的对比平衡表示学习

    Contrastive Balancing Representation Learning for Heterogeneous Dose-Response Curves Estimation

    [https://arxiv.org/abs/2403.14232](https://arxiv.org/abs/2403.14232)

    通过理论证明了平衡和预后表示对于无偏估计的重要性，提出了一种对比平衡表示学习方法。

    

    估计个体对不同治疗剂量的潜在响应对于决策制定至关重要，涉及精准医学和管理科学等领域。最近的研究大多通过学习与治疗变量无关的协变量表示来预测反事实结果。然而，这种独立性约束忽略了许多有用于反事实预测的协变量信息，特别是当治疗变量是连续的时。为了解决上述问题，本文首先从理论上证明了平衡和预后表示对于异质剂量-响应曲线的无偏估计的重要性，即学习到的表示受到限制，以满足协变量与治疗变量和潜在响应之间的条件独立关系。基于此，我们提出了一种新颖的对比平衡表示学习方法

    arXiv:2403.14232v1 Announce Type: new  Abstract: Estimating the individuals' potential response to varying treatment doses is crucial for decision-making in areas such as precision medicine and management science. Most recent studies predict counterfactual outcomes by learning a covariate representation that is independent of the treatment variable. However, such independence constraints neglect much of the covariate information that is useful for counterfactual prediction, especially when the treatment variables are continuous. To tackle the above issue, in this paper, we first theoretically demonstrate the importance of the balancing and prognostic representations for unbiased estimation of the heterogeneous dose-response curves, that is, the learned representations are constrained to satisfy the conditional independence between the covariates and both of the treatment variables and the potential responses. Based on this, we propose a novel Contrastive balancing Representation learni
    
[^67]: 从高维代理变量中恢复潜在潜在因素

    Recovering Latent Confounders from High-dimensional Proxy Variables

    [https://arxiv.org/abs/2403.14228](https://arxiv.org/abs/2403.14228)

    提出了一种新颖的代理混淆因子分解 (PCF) 框架，用于处理高维混合代理变量来估计连续处理效应，实验证明在高样本大小情况下，该方法在因果效果估计中表现出较高的相关性和较低的误差。

    

    检测潜在潜伏者，从代理变量是因果效应估计中的一个重要问题。以前的方法局限于低维代理，排序代理和二元治疗。我们消除了这些假设，并提出了一个新颖的代理混淆因子分解 (PCF) 框架，用于连续处理效应估计，当潜在混淆因子通过高维，混合代理变量而显现。对于特定样本大小，我们的两步 PCF 实施，使用独立成分分析 (ICA-PCF) 和端到端实施，使用梯度下降 (GD-PCF)，在高样本大小范围内，与潜在混淆因子的相关性较高，因果效应估计的绝对误差较低。，利用合成数据。即使面对气候数据，ICA-PCF 恢复了解释欧洲降雨模式的 North Atlantic Oscillation $75.9\%$ 方差的四个分量，一个已知的降水模式的混淆

    arXiv:2403.14228v1 Announce Type: cross  Abstract: Detecting latent confounders from proxy variables is an essential problem in causal effect estimation. Previous approaches are limited to low-dimensional proxies, sorted proxies, and binary treatments. We remove these assumptions and present a novel Proxy Confounder Factorization (PCF) framework for continuous treatment effect estimation when latent confounders manifest through high-dimensional, mixed proxy variables. For specific sample sizes, our two-step PCF implementation, using Independent Component Analysis (ICA-PCF), and the end-to-end implementation, using Gradient Descent (GD-PCF), achieve high correlation with the latent confounder and low absolute error in causal effect estimation with synthetic datasets in the high sample size regime. Even when faced with climate data, ICA-PCF recovers four components that explain $75.9\%$ of the variance in the North Atlantic Oscillation, a known confounder of precipitation patterns in Eur
    
[^68]: 具有权重通用先验的全连接贝叶斯神经网络的后验浓度

    Posterior concentrations of fully-connected Bayesian neural networks with general priors on the weights

    [https://arxiv.org/abs/2403.14225](https://arxiv.org/abs/2403.14225)

    本文提出了一种新的近似理论，表明具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型。

    

    训练深度神经网络（BNNs）的贝叶斯方法备受关注，并已在广泛的应用中得到有效利用。先前有关BNNs后验浓度性质的研究已有几项。然而，大多数这些研究仅在具有稀疏或重尾先验的BNN模型中展示结果。令人惊讶的是，目前尚无关于使用高斯先验的BNNs的理论结果，而高斯先验是最常用的先验之一。这种理论缺失源于缺乏近似非稀疏且具有有界参数的深度神经网络（DNNs）的结果。本文提出了用于具有有界参数的非稀疏DNNs的新近似理论。此外，基于这一近似理论，我们展示了具有非稀疏通用先验的BNNs可以实现接近最小化最优后验浓度速率至真实模型的结果。

    arXiv:2403.14225v1 Announce Type: cross  Abstract: Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. There have been several studies on the properties of posterior concentrations of BNNs. However, most of these studies only demonstrate results in BNN models with sparse or heavy-tailed priors. Surprisingly, no theoretical results currently exist for BNNs using Gaussian priors, which are the most commonly used one. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory, we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates to the true model.
    
[^69]: 手术员去偏见：神奇的权重及如何找到它们

    Debiasing surgeon: fantastic weights and how to find them

    [https://arxiv.org/abs/2403.14200](https://arxiv.org/abs/2403.14200)

    证明了在深度学习模型中存在一些无偏子网络，可以在不需要依赖算法偏见的情况下被提取出来，并且这种特定架构无法学习任何特定的偏见。

    

    现今一个日益关注的现象是算法偏见的出现，它可能导致不公平的模型。在深度学习领域，已经提出了几种去偏见的方法，采用更或多或少复杂的方法来阻止这些模型大规模地使用这些偏见。然而，一个问题出现了：这种额外的复杂性真的有必要吗？一个普通训练的模型是否已经包含了一些可以独立使用的“无偏子网络”，并且可以提出一个解决方案而不依赖于算法偏见？在这项工作中，我们展示了这样的子网络通常存在，并且可以从一个普通训练的模型中提取出来，而无需额外的训练。我们进一步验证了这种特定的架构无法学习特定的偏见，表明在深度神经网络中有可能通过架构上的对策来解决偏见问题。

    arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.
    
[^70]: OTSeg：多提示Sinkhorn注意力用于零样本语义分割

    OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.14183](https://arxiv.org/abs/2403.14183)

    通过引入OTSeg中的Multi-Prompts Sinkhorn Attention机制，能够更好地利用多个文本提示来匹配相关像素嵌入，从而提升零样本语义分割性能。

    

    CLIP的最新成功证明了通过将多模态知识转移到像素级分类来进行零样本语义分割的有希望的结果。然而，在现有方法中，利用预先训练的CLIP知识来紧密对齐文本嵌入和像素嵌入仍然存在局限性。为了解决这个问题，我们提出了OTSeg，这是一种新颖的多模态注意力机制，旨在增强多个文本提示匹配相关像素嵌入的潜力。我们首先提出了基于最优输运（OT）算法的多提示Sinkhorn（MPS），这使得多个文本提示可以有选择地关注图像像素内的各种语义特征。此外，受到Sinkformers在单模态设置中的成功启发，我们引入了MPS的扩展，称为多提示Sinkhorn注意力（MPSA），它有效地取代了Transformer框架中多模态设置中的交叉注意力机制。

    arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settin
    
[^71]: 具有前瞻特性的策略镜像下降算法

    Policy Mirror Descent with Lookahead

    [https://arxiv.org/abs/2403.14156](https://arxiv.org/abs/2403.14156)

    提出了一种新类别的策略镜像下降算法$h$-PMD，它通过在PMD更新规则中结合多步贪心策略改进和前瞻深度$h，以解决折扣无限时间视角下的马尔可夫决策过程。

    

    策略镜像下降（PMD）作为一种多功能算法框架，包括几种重要的策略梯度算法，如自然策略梯度，并与最先进的强化学习（RL）算法（如TRPO和PPO）相联系。PMD可以看作是实现正则化1步贪心策略改进的软策略迭代算法。然而，1步贪心策略可能不是最佳选择，最近在RL领域取得了显着的实证成功，如AlphaGo和AlphaZero已经证明，相对于多步骤，贪心方法可以超越它们的1步骤对应物。在这项工作中，我们提出了一种新类别的PMD算法，称为$h$-PMD，它将具有前瞻深度$h$的多步贪心策略改进结合到PMD更新规则中。为了解决折扣无限时间视角下的马尔可夫决策过程，其中折扣因子为$\gamma$，我们展示了$h$-PMD可以推广标准的PMD。

    arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\gamma$, we show that $h$-PMD which generalizes the standard PMD enj
    
[^72]: 轨迹数据管理与挖掘的深度学习：调查与展望

    Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond

    [https://arxiv.org/abs/2403.14151](https://arxiv.org/abs/2403.14151)

    本文综述了深度学习在轨迹数据管理与挖掘中的发展和最新进展，探讨了其在预处理、存储、分析、预测、推荐、分类、估计和检测等方面的应用。

    

    arXiv:2403.14151v1 公告类型：跨越 抽象：轨迹计算是一个重要的领域，涵盖轨迹数据管理和挖掘，因其在诸如位置服务、城市交通和公共安全等各种实际应用中的关键作用而受到广泛关注。传统方法侧重于简单的时空特征，面临复杂计算、有限的可扩展性和不足以适应现实复杂性的挑战。在本文中，我们对轨迹计算中深度学习的发展和最新进展进行了全面的回顾（DL4Traj）。我们首先定义轨迹数据，并简要介绍了广泛使用的深度学习模型。系统地探讨了深度学习在轨迹管理（预处理、存储、分析和可视化）和挖掘（与轨迹相关的预测、轨迹相关的推荐、轨迹分类、旅行时间估计、异常检测）

    arXiv:2403.14151v1 Announce Type: cross  Abstract: Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detecti
    
[^73]: 通过内容-帧动态潜分解实现高效视频扩散模型

    Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition

    [https://arxiv.org/abs/2403.14148](https://arxiv.org/abs/2403.14148)

    提出了一种高效视频扩散模型CMD，通过预训练图像扩散模型和新的轻量级扩散模型生成内容帧和动态潜表示，以解决高内存和计算要求的问题。

    

    视频扩散模型在生成质量方面取得了长足进展，但仍受制于高内存和计算要求。我们提出内容-动态潜扩散模型（CMD），作为预训练图像扩散模型在视频生成中的高效扩展。CMD通过自动编码器将视频简洁地编码为内容帧和低维动态潜表示的组合。我们通过对预训练图像扩散模型进行微调来生成内容帧，并通过训练新的轻量级扩散模型来生成动态潜表示。这里的关键创新在于设计了一种紧凑的潜

    arXiv:2403.14148v1 Announce Type: cross  Abstract: Video diffusion models have recently made great progress in generation quality, but are still limited by the high memory and computational requirements. This is because current video diffusion models often attempt to process high-dimensional videos directly. To tackle this issue, we propose content-motion latent diffusion model (CMD), a novel efficient extension of pretrained image diffusion models for video generation. Specifically, we propose an autoencoder that succinctly encodes a video as a combination of a content frame (like an image) and a low-dimensional motion latent representation. The former represents the common content, and the latter represents the underlying motion in the video, respectively. We generate the content frame by fine-tuning a pretrained image diffusion model, and we generate the motion latent representation by training a new lightweight diffusion model. A key innovation here is the design of a compact laten
    
[^74]: 通过属性中心信息瓶颈学习可分解且无偏见的表示形式

    Learning Decomposable and Debiased Representations via Attribute-Centric Information Bottlenecks

    [https://arxiv.org/abs/2403.14140](https://arxiv.org/abs/2403.14140)

    提出了一种新颖的去偏见框架，引入基于注意力的信息瓶颈，用于学习属性的组合表示，而无需定义特定的偏见类型

    

    有偏见的属性在数据集中与目标标签呈现虚假相关，可能导致神经网络学习不当的分类快捷方式，并且限制它们在超出分布的泛化方面的能力。本文提出了一个新颖的去偏见框架，引入基于注意力的信息瓶颈，用于学习属性的组合表示，而无需定义特定的偏见类型。

    arXiv:2403.14140v1 Announce Type: cross  Abstract: Biased attributes, spuriously correlated with target labels in a dataset, can problematically lead to neural networks that learn improper shortcuts for classifications and limit their capabilities for out-of-distribution (OOD) generalization. Although many debiasing approaches have been proposed to ensure correct predictions from biased datasets, few studies have considered learning latent embedding consisting of intrinsic and biased attributes that contribute to improved performance and explain how the model pays attention to attributes. In this paper, we propose a novel debiasing framework, Debiasing Global Workspace, introducing attention-based information bottlenecks for learning compositional representations of attributes without defining specific bias types. Based on our observation that learning shape-centric representation helps robust performance on OOD datasets, we adopt those abilities to learn robust and generalizable repre
    
[^75]: 用于可解释流形学习的遗传规划

    Genetic Programming for Explainable Manifold Learning

    [https://arxiv.org/abs/2403.14139](https://arxiv.org/abs/2403.14139)

    遗传规划方法提出了用于可解释流形学习的新方法，帮助解决当前流形学习中功能映射不明确的挑战。

    

    流形学习技术在机器学习中发挥着关键作用，通过揭示高维数据中的低维嵌入，从而将数据转换为更低维的表示形式，提高了数据分析的效率和可解释性。然而，当前流形学习方法的一个显著挑战是它们缺乏明确的功能映射，在许多现实世界应用中解释性至关重要。遗传规划以其可解释的基于功能树的模型而闻名，已成为解决这一挑战的一种有希望的方法。先前的研究利用多目标遗传规划来平衡流形质量与嵌入维度，产生了一系列嵌入大小下的功能映射。然而，这些映射树经常变得复杂，阻碍了解释性。作为回应，在本文中，我们提出了用于可解释流形学习的遗传规划（GP-EMaL）。

    arXiv:2403.14139v1 Announce Type: cross  Abstract: Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL),
    
[^76]: 通过互补的类内和类间Mixup提高图像分类准确性

    Improving Image Classification Accuracy through Complementary Intra-Class and Inter-Class Mixup

    [https://arxiv.org/abs/2403.14137](https://arxiv.org/abs/2403.14137)

    通过提出一种新的mixup方法，该方法针对类内混合进行了优化，提高了图像分类准确性。

    

    MixUp及其变体，在图像分类任务中存在两个关键限制。首先，它们通常忽略了同一类别内的混合（类内Mixup），导致同一类别样本之间的关系被低估。其次，尽管这些方法通过不同类别之间的混合（类间Mixup）有效增强了类间可分离性，但在通过其混合操作改进类内凝聚力方面表现不足，限制了它们的分类性能。为了解决这些问题，我们提出了一种新颖的mixup方法和一个全面的综合解决方案。我们的mixup方法专门针对常常被忽视的类内Mixup，以加强类内凝聚性-这是目前的mixup技术没有提供的特性。对于每个小批量，我们的方法利用小批量中每个类别的未增强原始图像的特征表示来生成a

    arXiv:2403.14137v1 Announce Type: cross  Abstract: MixUp and its variants, such as Manifold MixUp, have two key limitations in image classification tasks. First, they often neglect mixing within the same class (intra-class mixup), leading to an underutilization of the relationships among samples within the same class. Second, although these methods effectively enhance inter-class separability by mixing between different classes (inter-class mixup), they fall short in improving intra-class cohesion through their mixing operations, limiting their classification performance. To tackle these issues, we propose a novel mixup method and a comprehensive integrated solution.Our mixup approach specifically targets intra-class mixup, an aspect commonly overlooked, to strengthen intra-class cohesion-a feature not provided by current mixup techniques.For each mini-batch, our method utilizes feature representations of unaugmented original images from each class within the mini-batch to generate a s
    
[^77]: 使用根祖关系对变量进行分组学习因果图

    Learning causal graphs using variable grouping according to ancestral relationship

    [https://arxiv.org/abs/2403.14125](https://arxiv.org/abs/2403.14125)

    使用分治方法将变量分组，按照条件独立关系学习因果图，以提高在样本量较小的情况下的估算准确性。

    

    已经提出了几种因果发现算法。然而，当样本量相对于变量数量较小时，使用现有方法估算因果图的准确性会降低。有些方法在样本量小于变量数量时并不可行。为了规避这些问题，一些研究人员提出了采用分治方法的因果结构学习算法。为了学习整个因果图，这些方法首先根据变量之间的条件独立关系将变量分割成几个子集，然后将常规的因果发现算法应用于每个子集并合并估计结果。由于分治方法减少了因果结构学习算法应用的变量数量，因此预计可以改善因果图的估算准确性，尤其是在样本量相对较小时。

    arXiv:2403.14125v1 Announce Type: cross  Abstract: Several causal discovery algorithms have been proposed. However, when the sample size is small relative to the number of variables, the accuracy of estimating causal graphs using existing methods decreases. And some methods are not feasible when the sample size is smaller than the number of variables. To circumvent these problems, some researchers proposed causal structure learning algorithms using divide-and-conquer approaches. For learning the entire causal graph, the approaches first split variables into several subsets according to the conditional independence relationships among the variables, then apply a conventional causal discovery algorithm to each subset and merge the estimated results. Since the divide-and-conquer approach reduces the number of variables to which a causal structure learning algorithm is applied, it is expected to improve the estimation accuracy of causal graphs, especially when the sample size is small rela
    
[^78]: AI与内存墙

    AI and Memory Wall

    [https://arxiv.org/abs/2403.14123](https://arxiv.org/abs/2403.14123)

    这项研究分析了AI应用中内存带宽成为主要瓶颈的问题，并提出了对模型架构、训练和部署策略进行重新设计的观点。

    

    出现了前所未有的无监督训练数据可用性，加上神经缩放定律，导致用于服务/训练LLMs的模型大小和计算需求出现了前所未有的激增。然而，主要性能瓶颈日益转向内存带宽。在过去的20年中，服务器硬件FLOPS的峰值每2年增长3.0倍，超过了DRAM和互连带宽的增长，它们分别仅每2年增长1.6倍和1.4倍。这种不平衡使得内存，而非计算，成为AI应用中的主要瓶颈，特别是在服务方面。在这里，我们分析了编码器和解码器Transformer模型，并展示了内存带宽如何成为解码器模型的主要瓶颈。我们主张对模型架构、训练和部署策略进行重新设计，以克服这一内存限制。

    arXiv:2403.14123v1 Announce Type: new  Abstract: The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training LLMs. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware FLOPS has been scaling at 3.0x/2yrs, outpacing the growth of DRAM and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every 2 years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder Transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.
    
[^79]: 用迭代幅值剪枝推进工业物联网的联邦学习

    Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning

    [https://arxiv.org/abs/2403.14120](https://arxiv.org/abs/2403.14120)

    联邦学习在工业物联网中的应用促进了机器学习和数据隐私，本文提出了一种用于提升PIUs性能的迭代幅值剪枝技术。

    

    工业物联网（IIoT）在工业4.0的背景下迎来了一种互联的智能设备时代，数据驱动的见解和机器学习（ML）融合，彻底改变了制造业。 IIoT中一个值得关注的发展是联邦学习（FL）的整合，该技术解决了设备之间数据隐私和安全性的问题。 FL使边缘传感器（也称为外围智能单元（PIUs））能够使用本地数据进行学习和适应，无需显式共享机密数据，从而促进协作但机密的学习过程。然而，PIUs较低的内存占用和计算能力固有地需要具有非常紫紧凑尺寸的深度神经网络（DNN）模型。剪枝等模型压缩技术可用于通过移除对模型性能影响较小的不必要连接来减小DNN模型的大小，从而使模型更适合有限的环境。

    arXiv:2403.14120v1 Announce Type: cross  Abstract: The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited 
    
[^80]: C-TPT：通过文本特征离散性的校准测试时提示调整视觉-语言模型

    C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion

    [https://arxiv.org/abs/2403.14119](https://arxiv.org/abs/2403.14119)

    本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    

    在深度学习中，测试时适应已经引起了人们的关注，作为一种在不需要标记数据的情况下对模型进行微调的方法。一个主要的例证是最近提出的用于大规模视觉-语言模型（如CLIP）的测试时提示调整。然而，这些提示主要是为了提高准确性而开发的，忽视了校准的重要性——量化预测不确定性的关键方面。然而，传统的校准方法依赖大量标记数据，这使得它们在测试时场景下不切实际。为此，本文通过利用CLIP的固有属性，在测试时提示调整过程中探讨校准。通过一系列观察，我们发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion
    
[^81]: HETAL：使用同态加密进行高效的隐私保护迁移学习

    HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic Encryption

    [https://arxiv.org/abs/2403.14111](https://arxiv.org/abs/2403.14111)

    HETAL提出了一种高效的基于同态加密的迁移学习算法，在训练中保护客户隐私，实现了加密训练的准确性，提供了高效的加密矩阵乘法算法。

    

    转移学习是一种有效的方法，通过向在大型数据集上预先训练的模型添加和微调新的分类层，为数据稀缺问题高效地训练机器学习模型。虽然以往有许多研究提出在机器学习服务方面使用同态加密来解决转移学习中的数据隐私问题，但大多数研究仅关注加密推断。在本研究中，我们提出了HETAL，一种基于同态加密的高效迁移学习算法，通过使用CKKS同态加密方案对客户数据进行加密，从而保护客户在训练任务中的隐私。HETAL是第一个严格提供加密训练的实用方案，采用基于验证的早停技术，并实现了非加密训练的准确性。我们提出了一种高效的加密矩阵乘法算法，速度比现有方法快1.8到323倍。

    arXiv:2403.14111v1 Announce Type: cross  Abstract: Transfer learning is a de facto standard method for efficiently training machine learning models for data-scarce problems by adding and fine-tuning new classification layers to a model pre-trained on large datasets. Although numerous previous studies proposed to use homomorphic encryption to resolve the data privacy issue in transfer learning in the machine learning as a service setting, most of them only focused on encrypted inference. In this study, we present HETAL, an efficient Homomorphic Encryption based Transfer Learning algorithm, that protects the client's privacy in training tasks by encrypting the client data using the CKKS homomorphic encryption scheme. HETAL is the first practical scheme that strictly provides encrypted training, adopting validation-based early stopping and achieving the accuracy of nonencrypted training. We propose an efficient encrypted matrix multiplication algorithm, which is 1.8 to 323 times faster th
    
[^82]: 基于启发式算法动作屏蔽的强化学习（HAAM-RL）与集成推断方法

    Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method

    [https://arxiv.org/abs/2403.14110](https://arxiv.org/abs/2403.14110)

    HAAM-RL方法结合了启发式算法动作屏蔽和集成推断方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题，实验结果表明取得了16.25%的性能提升。

    

    本文介绍了一种名为HAAM-RL（基于启发式算法动作屏蔽的强化学习）的新型强化学习（RL）方法，用于优化汽车喷漆过程中的颜色批处理重新排序问题。我们的方法结合了多个关键技术，包括定制的马尔可夫决策过程（MDP）形式化，奖励设置包括基于潜力的奖励塑造，使用启发式算法进行动作屏蔽（HAAM-RL），以及一个结合多个RL模型的集成推断方法。实验结果表明，HAAM-RL与集成推断方法在30个场景中取得了16.25%的性能提升。

    arXiv:2403.14110v1 Announce Type: cross  Abstract: This paper presents a novel reinforcement learning (RL) approach called HAAM-RL (Heuristic Algorithm-based Action Masking Reinforcement Learning) for optimizing the color batching re-sequencing problem in automobile painting processes. The existing heuristic algorithms have limitations in adequately reflecting real-world constraints and accurately predicting logistics performance. Our methodology incorporates several key techniques including a tailored Markov Decision Process (MDP) formulation, reward setting including Potential-Based Reward Shaping, action masking using heuristic algorithms (HAAM-RL), and an ensemble inference method that combines multiple RL models. The RL agent is trained and evaluated using FlexSim, a commercial 3D simulation software, integrated with our RL MLOps platform BakingSoDA. Experimental results across 30 scenarios demonstrate that HAAM-RL with an ensemble inference method achieves a 16.25% performance im
    
[^83]: DouRN: 通过残差神经网络改进DouZero

    DouRN: Improving DouZero by Residual Neural Networks

    [https://arxiv.org/abs/2403.14102](https://arxiv.org/abs/2403.14102)

    通过在DouZero模型中引入残差网络，并探索不同的架构设计，我们显著提高了斗地主游戏中获胜率。

    

    深度强化学习在具有不完全信息的游戏中取得了显著进展，但在卡牌游戏斗地主方面的表现仍然令人不满意。斗地主不同于传统游戏，它涉及三名玩家，结合了合作和对抗的元素，导致状态空间和动作空间较大。2021年，一款名为DouZero的斗地主程序通过利用传统的蒙特卡洛方法和多层感知器，超越了以往没有先验知识的模型。在此基础上，我们的研究将残差网络纳入模型中，探索不同的架构设计，并进行多角色测试。我们的发现表明，该模型在相同的训练时间内显著提高了获胜率。此外，我们引入了一个呼叫得分系统，帮助代理决定是否成为地主。

    arXiv:2403.14102v1 Announce Type: new  Abstract: Deep reinforcement learning has made significant progress in games with imperfect information, but its performance in the card game Doudizhu (Chinese Poker/Fight the Landlord) remains unsatisfactory. Doudizhu is different from conventional games as it involves three players and combines elements of cooperation and confrontation, resulting in a large state and action space. In 2021, a Doudizhu program called DouZero\cite{zha2021douzero} surpassed previous models without prior knowledge by utilizing traditional Monte Carlo methods and multilayer perceptrons. Building on this work, our study incorporates residual networks into the model, explores different architectural designs, and conducts multi-role testing. Our findings demonstrate that this model significantly improves the winning rate within the same training time. Additionally, we introduce a call scoring system to assist the agent in deciding whether to become a landlord. With these
    
[^84]: 文本增强的面向联邦类增量学习的无数据方法

    Text-Enhanced Data-free Approach for Federated Class-Incremental Learning

    [https://arxiv.org/abs/2403.14101](https://arxiv.org/abs/2403.14101)

    通过使用预训练语言模型产生的标签文本嵌入，本文提出了一种称为LANDER的方法，即面向联邦类增量学习的无数据方法，以解决DFKT在生成高质量数据时遇到的困难。

    

    联邦类增量学习（FCIL）是一个尚未充分探讨但至关重要的问题，涉及在联邦学习环境中动态添加新类别。在这一领域，无数据知识迁移（DFKT）在解决灾难性遗忘和数据隐私问题方面发挥着关键作用。然而，以往的方法缺乏DFKT与模型训练阶段之间的关键协同作用，导致DFKT在生成旧任务模型的非锚定潜在空间中的高质量数据时遇到困难。在本文中，我们介绍了LANDER（标签文本中心化无数据知识迁移），通过利用预训练语言模型产生的标签文本嵌入（LTE）来解决这一问题。具体而言，在模型训练阶段，我们的方法将LTE视为锚点，并约束相应训练样本的特征嵌入围绕其周围，以更丰富的信息丰富周围区域

    arXiv:2403.14101v1 Announce Type: cross  Abstract: Federated Class-Incremental Learning (FCIL) is an underexplored yet pivotal issue, involving the dynamic addition of new classes in the context of federated learning. In this field, Data-Free Knowledge Transfer (DFKT) plays a crucial role in addressing catastrophic forgetting and data privacy problems. However, prior approaches lack the crucial synergy between DFKT and the model training phases, causing DFKT to encounter difficulties in generating high-quality data from a non-anchored latent space of the old task model. In this paper, we introduce LANDER (Label Text Centered Data-Free Knowledge Transfer) to address this issue by utilizing label text embeddings (LTE) produced by pretrained language models. Specifically, during the model training phase, our approach treats LTE as anchor points and constrains the feature embeddings of corresponding training samples around them, enriching the surrounding area with more meaningful informati
    
[^85]: 可持续数据中心实时减少碳足迹

    Carbon Footprint Reduction for Sustainable Data Centers in Real-Time

    [https://arxiv.org/abs/2403.14092](https://arxiv.org/abs/2403.14092)

    我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。

    

    随着机器学习工作负载显著增加能源消耗，碳排放低的可持续数据中心正成为全球政府和企业关注的重点。为了实现这一目标，需要在冷却和IT负载中进行功耗优化的范式转变，基于可再生能源在电网中的可用性来调整灵活负载，利用数据中心不间断电源中的电池存储，使用协作代理。这些优化策略之间的复杂关系以及它们对变化的外部因素（如天气和电网碳排放强度）的依赖使得这是一个困难的问题。目前缺乏一个能够在动态实际环境中同时优化所有这些目标的实时控制器。我们提出了一种数据中心碳足迹减少（DC-CFR）多代理强化学习（MARL）框架，能够优化多个角度的数据中心。

    arXiv:2403.14092v1 Announce Type: cross  Abstract: As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the mult
    
[^86]: 基于力引导SE(3)扩散模型的蛋白质构象生成

    Protein Conformation Generation via Force-Guided SE(3) Diffusion Models

    [https://arxiv.org/abs/2403.14088](https://arxiv.org/abs/2403.14088)

    本文提出了一种力引导SE(3)扩散模型ConfDiff，用于蛋白质构象生成，通过结合力引导网络与基于数据的分数模型，实现了对蛋白质构象的准确生成。

    

    蛋白质的构象景观对于理解复杂生物过程中的功能至关重要。传统基于物理的计算方法，如分子动力学（MD）模拟，存在稀有事件采样和长时间平衡问题，限制了它们在一般蛋白质系统中的应用。最近，深度生成建模技术，特别是扩散模型，已被应用于生成新颖的蛋白质构象。然而，现有的基于分数的扩散方法无法很好地结合重要的物理先验知识来指导生成过程，导致采样蛋白质构象与平衡分布之间存在较大偏差。本文提出了一种用于蛋白质构象生成的力引导SE(3)扩散模型ConfDiff，以克服这些限制。通过将力引导网络与一系列基于数据的分数模型相结合，ConfDiff能够实现对蛋白质构象的准确生成。

    arXiv:2403.14088v1 Announce Type: cross  Abstract: The conformational landscape of proteins is crucial to understanding their functionality in complex biological processes. Traditional physics-based computational methods, such as molecular dynamics (MD) simulations, suffer from rare event sampling and long equilibration time problems, hindering their applications in general protein systems. Recently, deep generative modeling techniques, especially diffusion models, have been employed to generate novel protein conformations. However, existing score-based diffusion methods cannot properly incorporate important physical prior knowledge to guide the generation process, causing large deviations in the sampled protein conformations from the equilibrium distribution. In this paper, to overcome these limitations, we propose a force-guided SE(3) diffusion model, ConfDiff, for protein conformation generation. By incorporating a force-guided network with a mixture of data-based score models, Conf
    
[^87]: 基于学习的多孔介质模型用于多尺度流动问题

    Learning-based Multi-continuum Model for Multiscale Flow Problems

    [https://arxiv.org/abs/2403.14084](https://arxiv.org/abs/2403.14084)

    提出了一种基于学习的多连续体模型，用于改进多尺度问题中单一连续体模型的准确性

    

    多尺度问题通常可以通过数值均质化来近似，通过具有某些有效参数的方程来捕获原始系统在粗网格上的宏观行为，以加快模拟速度。然而，这种方法通常假设尺度分离，并且解的异质性可以通过每个粗块中的解的平均值来近似。对于复杂的多尺度问题，计算的单一有效性特性/连续体可能不足够。在本文中，我们提出了一种新颖的基于学习的多连续体模型，用于丰富均质化方程并提高多尺度问题单一连续体模型的准确性，给定一些数据。不失一般性，我们考虑了一个双连续体的情况。第一个流动方程保留了原始均质化方程的信息，具有额外的交互项。第二个连续体是新引入的。

    arXiv:2403.14084v1 Announce Type: cross  Abstract: Multiscale problems can usually be approximated through numerical homogenization by an equation with some effective parameters that can capture the macroscopic behavior of the original system on the coarse grid to speed up the simulation. However, this approach usually assumes scale separation and that the heterogeneity of the solution can be approximated by the solution average in each coarse block. For complex multiscale problems, the computed single effective properties/continuum might be inadequate. In this paper, we propose a novel learning-based multi-continuum model to enrich the homogenized equation and improve the accuracy of the single continuum model for multiscale problems with some given data. Without loss of generalization, we consider a two-continuum case. The first flow equation keeps the information of the original homogenized equation with an additional interaction term. The second continuum is newly introduced, and t
    
[^88]: emoDARTS：联合优化CNN和顺序神经网络架构实现优越的语音情感识别

    emoDARTS: Joint Optimisation of CNN & Sequential Neural Network Architectures for Superior Speech Emotion Recognition

    [https://arxiv.org/abs/2403.14083](https://arxiv.org/abs/2403.14083)

    emoDARTS通过联合优化CNN和顺序神经网络架构，提升了语音情感识别性能。

    

    论文研究了emoDARTS，一种DARTS优化的联合CNN和顺序神经网络（SeqNN：LSTM、RNN）架构，以提升语音情感识别性能。研究表明选择CNN和LSTM耦合可以改善性能。虽然DARTS先前已用于独立选择CNN和LSTM操作，但我们的技术为选择最佳模型添加了一种新颖机制。

    arXiv:2403.14083v1 Announce Type: cross  Abstract: Speech Emotion Recognition (SER) is crucial for enabling computers to understand the emotions conveyed in human communication. With recent advancements in Deep Learning (DL), the performance of SER models has significantly improved. However, designing an optimal DL architecture requires specialised knowledge and experimental assessments. Fortunately, Neural Architecture Search (NAS) provides a potential solution for automatically determining the best DL model. The Differentiable Architecture Search (DARTS) is a particularly efficient method for discovering optimal models. This study presents emoDARTS, a DARTS-optimised joint CNN and Sequential Neural Network (SeqNN: LSTM, RNN) architecture that enhances SER performance. The literature supports the selection of CNN and LSTM coupling to improve performance.   While DARTS has previously been used to choose CNN and LSTM operations independently, our technique adds a novel mechanism for sel
    
[^89]: 通过归一化流实现领域自适应改进$\Lambda$信号提取

    Improving $\Lambda$ Signal Extraction with Domain Adaptation via Normalizing Flows

    [https://arxiv.org/abs/2403.14076](https://arxiv.org/abs/2403.14076)

    通过归一化流进行领域自适应，成功改进了$\Lambda$信号提取，减少了对分类器输出切割线的依赖性

    

    本研究提出了一种使用归一化流进行领域自适应的新应用。该研究调查了基于流的神经网络改进CLAS12中$\Lambda$超子信号提取的能力。归一化流可以帮助建模描述物理过程的复杂概率密度函数，实现事件生成等用途。虽然通过使用分类器网络改进了$\Lambda$信号提取，但模拟和数据领域的差异限制了分类器性能；该研究利用流进行蒙特卡罗模拟和数据之间的领域自适应。我们成功训练了一个流网络，将隐含的物理空间转换为正态分布。我们还发现应用流减少了merit图表对分类器输出切割线的依赖性，这意味着存在更广泛的范围，在该范围内切割会产生类似的merit图表。

    arXiv:2403.14076v1 Announce Type: cross  Abstract: The present study presents a novel application for normalizing flows for domain adaptation. The study investigates the ability of flow based neural networks to improve signal extraction of $\Lambda$ Hyperons at CLAS12. Normalizing Flows can help model complex probability density functions that describe physics processes, enabling uses such as event generation. $\Lambda$ signal extraction has been improved through the use of classifier networks, but differences in simulation and data domains limit classifier performance; this study utilizes the flows for domain adaptation between Monte Carlo simulation and data. We were successful in training a flow network to transform between the latent physics space and a normal distribution. We also found that applying the flows lessened the dependence of the figure of merit on the cut on the classifier output, meaning that there was a broader range where the cut results in a similar figure of merit
    
[^90]: M3: 用于开放领域多跳密集句子检索的多任务混合目标学习框架

    M3: A Multi-Task Mixed-Objective Learning Framework for Open-Domain Multi-Hop Dense Sentence Retrieval

    [https://arxiv.org/abs/2403.14074](https://arxiv.org/abs/2403.14074)

    M3是一个多任务混合目标学习框架，旨在解决仅依赖对比学习可能导致的次优检索性能问题，并取得了在FEVER数据集上的最先进性能。

    

    在最近的研究中，对比学习已被证明是一种非常有效的表示学习方法，广泛用于密集检索。然而，我们发现仅依赖对比学习可能会导致次优的检索性能。另一方面，尽管许多检索数据集支持各种超越对比学习的学习目标，但在多任务学习场景中高效地组合它们可能具有挑战性。在本文中，我们介绍了M3，这是一个先进的递归多跳密集句子检索系统，它建立在一种新颖的多任务混合目标方法之上，用于密集文本表示学习，解决了上述挑战。我们的方法在大规模开放领域事实验证基准数据集FEVER上取得了最先进的性能。代码和数据可在以下链接获取: https://github.com/TonyBY/M3

    arXiv:2403.14074v1 Announce Type: cross  Abstract: In recent research, contrastive learning has proven to be a highly effective method for representation learning and is widely used for dense retrieval. However, we identify that relying solely on contrastive learning can lead to suboptimal retrieval performance. On the other hand, despite many retrieval datasets supporting various learning objectives beyond contrastive learning, combining them efficiently in multi-task learning scenarios can be challenging. In this paper, we introduce M3, an advanced recursive Multi-hop dense sentence retrieval system built upon a novel Multi-task Mixed-objective approach for dense text representation learning, addressing the aforementioned challenges. Our approach yields state-of-the-art performance on a large-scale open-domain fact verification benchmark dataset, FEVER. Code and data are available at: https://github.com/TonyBY/M3
    
[^91]: 使用朴素贝叶斯分类器对审计证据进行抽样

    Sampling Audit Evidence Using a Naive Bayes Classifier

    [https://arxiv.org/abs/2403.14069](https://arxiv.org/abs/2403.14069)

    该研究通过将机器学习与抽样技术相结合，提出了使用朴素贝叶斯分类器对审计证据进行抽样的方法，以避免抽样偏差，保持随机性和变异性，并针对更有风险的样本。

    

    arXiv：2403.14069v1 公告类型：新的 摘要：台湾的审计师在处理过多的审计数据时遇到了困难，包括提取审计证据。本研究通过将机器学习与抽样技术相结合，推进了抽样技术。这种机器学习集成有助于避免抽样偏差，保持随机性和变异性，并针对更有风险的样本。我们首先使用朴素贝叶斯分类器将数据分类为几个类别。接下来，采用基于用户、基于项目或混合方法来提取审计证据。代表性指数是衡量其代表性的主要指标。基于用户的方法对称地围绕类别的中位数采样数据作为审计证据。它可能相当于货币和变量抽样的组合。基于项目的方法根据后验概率表示非对称抽样，以获得有风险的样本作为审计证据。它可能相当于非统计和货币抽样的组合。

    arXiv:2403.14069v1 Announce Type: new  Abstract: Taiwan's auditors have suffered from processing excessive audit data, including drawing audit evidence. This study advances sampling techniques by integrating machine learning with sampling. This machine learning integration helps avoid sampling bias, keep randomness and variability, and target risker samples. We first classify data using a Naive Bayes classifier into some classes. Next, a user-based, item-based, or hybrid approach is employed to draw audit evidence. The representativeness index is the primary metric for measuring its representativeness. The user-based approach samples data symmetric around the median of a class as audit evidence. It may be equivalent to a combination of monetary and variable samplings. The item-based approach represents asymmetric sampling based on posterior probabilities for obtaining risky samples as audit evidence. It may be identical to a combination of non-statistical and monetary samplings. Audito
    
[^92]: 通过最优输运的自动异常值矫正

    Automatic Outlier Rectification via Optimal Transport

    [https://arxiv.org/abs/2403.14067](https://arxiv.org/abs/2403.14067)

    提出了一种自动异常值矫正机制，通过将矫正和估计集成到联合优化框架中，利用最优输运和凹成本函数来检测和移除异常值，并选择最佳分布来执行估计任务

    

    在本文中，我们提出了一个新颖的概念框架，使用具有凹成本函数的最优输运来检测异常值。传统的异常值检测方法通常使用两阶段流程：首先检测并移除异常值，然后在清洁数据上执行估计。然而，这种方法并没有将异常值移除与估计任务联系起来，留下了改进的空间。为了解决这一局限性，我们提出了一种自动异常值矫正机制，将矫正和估计集成到一个联合优化框架中。我们首先利用具有凹成本函数的最优输运距离来构建概率分布空间中的矫正集合。然后，我们选择在矫正集合中的最佳分布来执行估计任务。值得注意的是，我们在本文中引入的凹成本函数是使我们的估计器具有关键性的因素。

    arXiv:2403.14067v1 Announce Type: cross  Abstract: In this paper, we propose a novel conceptual framework to detect outliers using optimal transport with a concave cost function. Conventional outlier detection approaches typically use a two-stage procedure: first, outliers are detected and removed, and then estimation is performed on the cleaned data. However, this approach does not inform outlier removal with the estimation task, leaving room for improvement. To address this limitation, we propose an automatic outlier rectification mechanism that integrates rectification and estimation within a joint optimization framework. We take the first step to utilize an optimal transport distance with a concave cost function to construct a rectification set in the space of probability distributions. Then, we select the best distribution within the rectification set to perform the estimation task. Notably, the concave cost function we introduced in this paper is the key to making our estimator e
    
[^93]: DiffSTOCK：使用扩散模型进行概率关系型股市预测

    DiffSTOCK: Probabilistic relational Stock Market Predictions using Diffusion Models

    [https://arxiv.org/abs/2403.14063](https://arxiv.org/abs/2403.14063)

    提出了一种使用扩散模型进行概率关系型股市预测的方法，能更好地处理金融数据中的不确定性。

    

    在这项工作中，我们提出了一种推广去噪扩散概率模型用于股市预测和投资组合管理的方法。现有的工作已经展示了建模股票间关系用于市场时间序列预测的功效，并利用基于图的学习模型进行价值预测和投资组合管理。尽管令人信服，这些确定性方法仍然无法处理不确定性，即由于金融数据的信噪比较低，学习有效的确定性模型相当具有挑战性。由于概率方法已被证明能有效模拟时间序列预测的更高不确定性。为此，我们展示了去噪扩散概率模型(DDPM)的有效利用，开发了一个基于历史财务指标和股票间关系提供更好市场预测的架构。

    arXiv:2403.14063v1 Announce Type: new  Abstract: In this work, we propose an approach to generalize denoising diffusion probabilistic models for stock market predictions and portfolio management. Present works have demonstrated the efficacy of modeling interstock relations for market time-series forecasting and utilized Graph-based learning models for value prediction and portfolio management. Though convincing, these deterministic approaches still fall short of handling uncertainties i.e., due to the low signal-to-noise ratio of the financial data, it is quite challenging to learn effective deterministic models. Since the probabilistic methods have shown to effectively emulate higher uncertainties for time-series predictions. To this end, we showcase effective utilisation of Denoising Diffusion Probabilistic Models (DDPM), to develop an architecture for providing better market predictions conditioned on the historical financial indicators and inter-stock relations. Additionally, we al
    
[^94]: 基于假设的深度学习用于外域检测

    Hypothesis-Driven Deep Learning for Out of Distribution Detection

    [https://arxiv.org/abs/2403.14058](https://arxiv.org/abs/2403.14058)

    本论文提出了一种基于假设的深度学习方法，用于量化新样本是否属于内部分布或外部分布，在高风险应用中如医疗保健领域具有重要意义。

    

    不透明黑盒系统的预测经常用于诸如医疗保健等高风险应用中。对于这类应用，评估模型处理超出训练数据域的样本的方式至关重要。虽然存在几种度量和测试来检测深度神经网络（DNN）中的超出分布（OoD）数据和分布内（InD）数据，但它们的性能在数据集、模型和任务之间存在显著差异，这限制了它们的实际应用。在本文中，我们提出了一种基于假设的方法来量化新样本是InD还是OoD。给定一个训练过的DNN和一些输入，我们首先通过DNN馈送输入并计算一组OoD度量，称为潜在响应。然后，我们将OoD检测问题表述为潜在响应之间的假设检验，并使用基于排列的重新采样来推断在零假设下观察到的潜在响应的显著性。

    arXiv:2403.14058v1 Announce Type: new  Abstract: Predictions of opaque black-box systems are frequently deployed in high-stakes applications such as healthcare. For such applications, it is crucial to assess how models handle samples beyond the domain of training data. While several metrics and tests exist to detect out-of-distribution (OoD) data from in-distribution (InD) data to a deep neural network (DNN), their performance varies significantly across datasets, models, and tasks, which limits their practical use. In this paper, we propose a hypothesis-driven approach to quantify whether a new sample is InD or OoD. Given a trained DNN and some input, we first feed the input through the DNN and compute an ensemble of OoD metrics, which we term latent responses. We then formulate the OoD detection problem as a hypothesis test between latent responses of different groups, and use permutation-based resampling to infer the significance of the observed latent responses under a null hypothe
    
[^95]: 朝向容量车辆路径问题和约束中心基础聚类之间的联系

    Towards a connection between the capacitated vehicle routing problem and the constrained centroid-based clustering

    [https://arxiv.org/abs/2403.14013](https://arxiv.org/abs/2403.14013)

    该论文探讨了容量车辆路径问题（CVRP）和约束中心基础聚类（CCBC）之间的联系，将CVRP简化为CCBC相当于使用常见的聚类算法将从指数复杂性转换为多项式复杂性。

    

    有效解决实际运行时间内的车辆路径问题（VRP）是交付管理公司面临的关键挑战。本文探讨了容量车辆路径问题（CVRP）和约束中心基础聚类（CCBC）之间的理论和实验联系。将CVRP简化为CCBC相当于使用常见的聚类算法（如K-means）将从指数复杂性转换为多项式复杂性。我们首先进行了一项探索性分析，通过说明性的小规模示例突出了这两个问题之间的关系，并同时推导了一些数学相关的公式和性质。在第二层次上，本文提出了一种基于CCBC的方法并加以一些增强。提出的框架由三个阶段组成。在第一步，约束中心基础聚类算法生成特征

    arXiv:2403.14013v1 Announce Type: cross  Abstract: Efficiently solving a vehicle routing problem (VRP) in a practical runtime is a critical challenge for delivery management companies. This paper explores both a theoretical and experimental connection between the Capacitated Vehicle Routing Problem (CVRP) and the Constrained Centroid-Based Clustering (CCBC). Reducing a CVRP to a CCBC is a synonym for a transition from an exponential to a polynomial complexity using commonly known algorithms for clustering, i.e K-means. At the beginning, we conduct an exploratory analysis to highlight the existence of such a relationship between the two problems through illustrative small-size examples and simultaneously deduce some mathematically-related formulations and properties. On a second level, the paper proposes a CCBC based approach endowed with some enhancements. The proposed framework consists of three stages. At the first step, a constrained centroid-based clustering algorithm generates fea
    
[^96]: 多模态视觉信息基础下的幻觉控制

    Multi-Modal Hallucination Control by Visual Information Grounding

    [https://arxiv.org/abs/2403.14003](https://arxiv.org/abs/2403.14003)

    引入了一种新的抽样方法M3ID来减少生成式视觉-语言模型中的幻觉，通过放大参考图像对语言先验的影响，从而更好地生成与视觉提示相关的标记。

    

    生成式视觉-语言模型（VLMs）往往会生成听起来合理的文本答案，但这些答案并不总是与输入图像相匹配。我们研究了这种现象，通常称为“幻觉”，并表明它源于对语言先验的过度依赖。特别是，我们发现随着生成的标记数量增加，对视觉提示的依赖性减少，这种行为与幻觉的出现强烈相关。为了减少幻觉，我们引入了一种新的抽样方法Multi-Modal Mutual-Information Decoding（M3ID）用于提示放大。M3ID增加了参考图像对语言先验的影响，从而有利于生成与视觉提示具有更高互信息的标记。M3ID可以应用于任何预训练的自回归VLM，在推断阶段而无需进行进一步的训练，并且计算开销最小。

    arXiv:2403.14003v1 Announce Type: cross  Abstract: Generative Vision-Language Models (VLMs) are prone to generate plausible-sounding textual answers that, however, are not always grounded in the input image. We investigate this phenomenon, usually referred to as "hallucination" and show that it stems from an excessive reliance on the language prior. In particular, we show that as more tokens are generated, the reliance on the visual prompt decreases, and this behavior strongly correlates with the emergence of hallucinations. To reduce hallucinations, we introduce Multi-Modal Mutual-Information Decoding (M3ID), a new sampling method for prompt amplification. M3ID amplifies the influence of the reference image over the language prior, hence favoring the generation of tokens with higher mutual information with the visual prompt. M3ID can be applied to any pre-trained autoregressive VLM at inference time without necessitating further training and with minimal computational overhead. If tra
    
[^97]: 不确定性驱动的主动学习在水下检测图像分割中的应用

    Uncertainty Driven Active Learning for Image Segmentation in Underwater Inspection

    [https://arxiv.org/abs/2403.14002](https://arxiv.org/abs/2403.14002)

    本研究探讨了在水下基础设施检测中应用主动学习进行图像分割的潜力，通过使用互信息和蒙特卡洛dropout计算来提高模型效果，在管道检测数据集上取得显著改进。

    

    主动学习旨在选择最小量的数据来训练一个与整个数据集训练的模型表现相似的模型。本文研究了主动学习在水下基础设施检验任务中图像分割中的潜力，这里通常需要收集大量的数据。管道检测图像通常在语义上是重复的，但质量却存在很大变化。我们使用互信息作为采集函数，通过蒙特卡洛dropout计算。为了评估该框架的有效性，我们使用CamVid数据集对DenseNet和HyperSeg进行了主动学习训练。此外，我们使用一个包含超过50,000张图像的管道检测数据集对HyperSeg进行训练。对于管道数据集，HyperSeg在使用12.5% 数据时实现了 67.5%的meanIoU，而在同样数量的随机选择图像的情况下仅为61.4%。这表明使用主动学习对分割模型进行训练是有效的。

    arXiv:2403.14002v1 Announce Type: cross  Abstract: Active learning aims to select the minimum amount of data to train a model that performs similarly to a model trained with the entire dataset. We study the potential of active learning for image segmentation in underwater infrastructure inspection tasks, where large amounts of data are typically collected. The pipeline inspection images are usually semantically repetitive but with great variations in quality. We use mutual information as the acquisition function, calculated using Monte Carlo dropout. To assess the effectiveness of the framework, DenseNet and HyperSeg are trained with the CamVid dataset using active learning. In addition, HyperSeg is trained with a pipeline inspection dataset of over 50,000 images. For the pipeline dataset, HyperSeg with active learning achieved 67.5% meanIoU using 12.5% of the data, and 61.4% with the same amount of randomly selected images. This shows that using active learning for segmentation models
    
[^98]: 机器学习相互作用势在自由能计算中的应用考虑

    Considerations in the use of ML interaction potentials for free energy calculations

    [https://arxiv.org/abs/2403.13952](https://arxiv.org/abs/2403.13952)

    该研究探讨了机器学习势在自由能计算中的应用，重点关注使用等变性图神经网络MLPs来准确预测自由能和过渡态，考虑到分子构型的能量和多样性。

    

    机器学习势（MLPs）具有准确建模分子能量和自由能景观的潜力，该准确性可媲美量子力学，并具有类似经典模拟的效率。本研究侧重于使用等变性图神经网络MLPs，因为它们在建模平衡分子轨迹中已被证明有效。一个关键问题是MLPs能否准确预测自由能和过渡态，要考虑分子构型的能量和多样性。我们检查了训练数据中集体变量（CVs）的分布如何影响MLP在确定系统自由能面（FES）时的准确性，使用Metadynamics模拟对丁烷和丙氨酸二肽（ADP）进行实验。该研究涉及对四十三个MLP进行训练，其中一半基于经典分子动力学数据，其余的基于从头计算的能量。这些MLPs进行了训练

    arXiv:2403.13952v1 Announce Type: cross  Abstract: Machine learning potentials (MLPs) offer the potential to accurately model the energy and free energy landscapes of molecules with the precision of quantum mechanics and an efficiency similar to classical simulations. This research focuses on using equivariant graph neural networks MLPs due to their proven effectiveness in modeling equilibrium molecular trajectories. A key issue addressed is the capability of MLPs to accurately predict free energies and transition states by considering both the energy and the diversity of molecular configurations. We examined how the distribution of collective variables (CVs) in the training data affects MLP accuracy in determining the free energy surface (FES) of systems, using Metadynamics simulations for butane and alanine dipeptide (ADP). The study involved training forty-three MLPs, half based on classical molecular dynamics data and the rest on ab initio computed energies. The MLPs were trained u
    
[^99]: Evo* 2023 -- 晚期摘要集

    Evo* 2023 -- Late-Breaking Abstracts Volume

    [https://arxiv.org/abs/2403.13950](https://arxiv.org/abs/2403.13950)

    Evo* 2023会议收录了关于将不同的生物启发方法（主要是进化计算）应用于解决不同问题（大多为现实世界问题）的研究和初步结果。

    

    arXiv:2403.13950v1 公告类型: 交叉摘要: 该卷收录了提交给在捷克布尔诺举办的Evo* 2023会议的晚期摘要，会议于4月12日至14日举行。这些论文展示了正在进行的研究以及初步结果，探讨了不同生物启发方法（主要是进化计算）在解决不同问题上的应用，其中大多数是现实世界中的问题。

    arXiv:2403.13950v1 Announce Type: cross  Abstract: Volume with the Late-Breaking Abstracts submitted to the Evo* 2023 Conference, held in Brno (Czech Republic), from 12 to 14 of April. These papers present ongoing research and preliminary results investigating on the application of different approaches of Bioinspired Methods (mainly Evolutionary Computation) to different problems, most of them real world ones.
    
[^100]: 从解释器集合中选择反事实解释的多标准方法

    Multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers

    [https://arxiv.org/abs/2403.13940](https://arxiv.org/abs/2403.13940)

    本文提出了一种多阶段集成方法，通过多标准分析选择单个反事实，避免了用户测试多种不同解释方法和分析冲突解决方案的困难，提供了一个在多个质量度量上得分很高的妥协方案。

    

    反事实被广泛用于解释机器学习模型的预测，提供获取更理想预测的替代场景。它们可以由多种方法生成，这些方法优化不同、有时是冲突的质量度量，并产生完全不同的解决方案。然而，选择最合适的解释方法和生成的反事实之一并不是一件容易的事情。本文提出使用多阶段集成方法，基于多标准分析来选择单个反事实，而不是强迫用户测试许多不同的解释方法并分析冲突的解决方案。它提供了一个妥协方案，在几个流行的质量度量上得分较高。这种方法利用支配关系和理想点决策辅助方法，从帕累托前沿中选择一个反事实。进行的实验证明了这种方法的有效性。

    arXiv:2403.13940v1 Announce Type: cross  Abstract: Counterfactuals are widely used to explain ML model predictions by providing alternative scenarios for obtaining the more desired predictions. They can be generated by a variety of methods that optimize different, sometimes conflicting, quality measures and produce quite different solutions. However, choosing the most appropriate explanation method and one of the generated counterfactuals is not an easy task. Instead of forcing the user to test many different explanation methods and analysing conflicting solutions, in this paper, we propose to use a multi-stage ensemble approach that will select single counterfactual based on the multiple-criteria analysis. It offers a compromise solution that scores well on several popular quality measures. This approach exploits the dominance relation and the ideal point decision aid method, which selects one counterfactual from the Pareto front. The conducted experiments demonstrated that the propos
    
[^101]: 减少大型语言模型偏见：重点关注“受限行业”的自动数据集增强和偏见量化

    Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification

    [https://arxiv.org/abs/2403.13925](https://arxiv.org/abs/2403.13925)

    本文提出了一种针对“受限行业”进行自动数据集增强以减少大型语言模型偏见的新机制，并创建了mb-index和db-index两个新的偏见量化指标。

    

    尽管大型语言模型的能力不断增强，但仍然存在对其产生偏见的担忧。本文提出了一种针对“受限行业”在有限数据情况下通过指定数据集增强来去偏见的新颖自动机制。我们还创建了两个新的衡量指标mb-index和db-index来量化偏见，考虑到偏见是由内在模型架构和数据集共同导致的这一观点。

    arXiv:2403.13925v1 Announce Type: cross  Abstract: Despite the growing capabilities of large language models, there exists concerns about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data. We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset.
    
[^102]: 使用GAN、扩散模型和风格转移技术增强指纹图像合成

    Enhancing Fingerprint Image Synthesis with GANs, Diffusion Models, and Style Transfer Techniques

    [https://arxiv.org/abs/2403.13916](https://arxiv.org/abs/2403.13916)

    本研究提出了一种结合生成对抗网络、扩散模型和风格转移技术的方法，用于合成高质量的真实和伪造指纹图像，保留了指纹的独特性和多样性。

    

    我们提出了新颖的方法，涉及生成对抗网络和扩散模型，以合成高质量的真实和伪造指纹图像，同时保留独特性和多样性等特征。我们使用各种方法从噪声中生成真实指纹，并利用图像转换技术将真实指纹图像转换成伪造指纹。为了基于有限训练数据生成不同类型的伪造图像，我们结合了风格转移技术，通过配备Wasserstein度量和梯度惩罚的循环自动编码器(CycleWGAN-GP)来避免模式崩溃和不稳定性。当伪造训练数据包含明显的伪造特征时，我们发现会导致改进的真实到伪造的转换。我们主要通过Fr\'echet Inception Distance (FID)和False Acceptance Rate (FAR)来评估生成的真实指纹图像的多样性和逼真程度。

    arXiv:2403.13916v1 Announce Type: cross  Abstract: We present novel approaches involving generative adversarial networks and diffusion models in order to synthesize high quality, live and spoof fingerprint images while preserving features such as uniqueness and diversity. We generate live fingerprints from noise with a variety of methods, and we use image translation techniques to translate live fingerprint images to spoof. To generate different types of spoof images based on limited training data we incorporate style transfer techniques through a cycle autoencoder equipped with a Wasserstein metric along with Gradient Penalty (CycleWGAN-GP) in order to avoid mode collapse and instability. We find that when the spoof training data includes distinct spoof characteristics, it leads to improved live-to-spoof translation. We assess the diversity and realism of the generated live fingerprint images mainly through the Fr\'echet Inception Distance (FID) and the False Acceptance Rate (FAR). Ou
    
[^103]: 扩展现实演示的可扩展机器人模仿学习

    Augmented Reality Demonstrations for Scalable Robot Imitation Learning

    [https://arxiv.org/abs/2403.13910](https://arxiv.org/abs/2403.13910)

    通过增强现实演示框架，本论文提出了一种创新方法，使非机器人专家用户能够为机器人模仿学习提供演示，实现了可扩展且多样化的演示收集。

    

    机器人模仿学习（IL）是一种广泛使用的方法，用于训练机器人执行涉及模仿人类演示以获取技能的操纵任务。然而，由于其要求用户接受操作真实机器人手臂的培训来提供演示，其实用性受到限制。本文提出了一种创新性解决方案：一种辅助增强现实（AR）框架用于演示收集，赋予非机器人专家用户使用HoloLens 2等设备为机器人IL制作演示的能力。我们的框架为现实世界的任务提供了可扩展和多样化的演示收集。我们通过对三个经典机器人任务（抓取、推动和拾取放置）的实验验证了我们的方法。真实机器人在回放通过AR收集的演示时成功执行每项任务。

    arXiv:2403.13910v1 Announce Type: cross  Abstract: Robot Imitation Learning (IL) is a widely used method for training robots to perform manipulation tasks that involve mimicking human demonstrations to acquire skills. However, its practicality has been limited due to its requirement that users be trained in operating real robot arms to provide demonstrations. This paper presents an innovative solution: an Augmented Reality (AR)-assisted framework for demonstration collection, empowering non-roboticist users to produce demonstrations for robot IL using devices like the HoloLens 2. Our framework facilitates scalable and diverse demonstration collection for real-world tasks. We validate our approach with experiments on three classical robotics tasks: reach, push, and pick-and-place. The real robot performs each task successfully while replaying demonstrations collected via AR.
    
[^104]: 复杂海洋航行的顺序建模：以一艘客运船为案例研究（学生摘要）

    Sequential Modeling of Complex Marine Navigation: Case Study on a Passenger Vessel (Student Abstract)

    [https://arxiv.org/abs/2403.13909](https://arxiv.org/abs/2403.13909)

    该研究利用机器学习方法对船舶燃油消耗进行建模，创造了预测动态状态的时间序列模型，成为评估船舶运营熟练程度和未来优化算法的基础。

    

    海事行业不断致力于可持续发展，致力于探索减少船舶燃油消耗的方法。本文通过机器学习方法来应对这一挑战，利用加拿大西海岸一艘渡轮两年的真实数据集。我们重点关注通过创造一个时间序列预测模型，基于动态和静态状态、行动和干扰，来预测动态状态。该模型旨在根据提供的行动预测动态状态，随后作为评估工具，评估船长指导下渡轮运营的熟练程度。另外，它为未来的优化算法奠定基础，为决策过程提供有价值的反馈。为了促进未来研究，我们的代码可在\url{https://github.com/pagand/model_optimze_vessel/tree/AAAI}找到。

    arXiv:2403.13909v1 Announce Type: new  Abstract: The maritime industry's continuous commitment to sustainability has led to a dedicated exploration of methods to reduce vessel fuel consumption. This paper undertakes this challenge through a machine learning approach, leveraging a real-world dataset spanning two years of a ferry in west coast Canada. Our focus centers on the creation of a time series forecasting model given the dynamic and static states, actions, and disturbances. This model is designed to predict dynamic states based on the actions provided, subsequently serving as an evaluative tool to assess the proficiency of the ferry's operation under the captain's guidance. Additionally, it lays the foundation for future optimization algorithms, providing valuable feedback on decision-making processes. To facilitate future studies, our code is available at \url{https://github.com/pagand/model_optimze_vessel/tree/AAAI}
    
[^105]: 通过实验设计实现去中心化数据市场的数据采集

    Data Acquisition via Experimental Design for Decentralized Data Markets

    [https://arxiv.org/abs/2403.13893](https://arxiv.org/abs/2403.13893)

    我们提出了一个受线性实验设计启发的联邦方法，用于在数据市场中选择最有价值的数据点，并实现更低的预测误差，无需标记的验证数据，更适用于去中心化市场设置。

    

    获取高质量的训练数据对于当前的机器学习模型至关重要。数据市场通过激励潜在的数据卖家加入市场的方式来增加数据供应，特别是在数据稀缺的领域，如医疗保健领域。我们提出了一个受线性实验设计启发的去中心化数据选择问题的联邦方法，该方法不需要标记的验证数据即可实现更低的预测误差，并且可以在快速和联邦的过程中进行优化。我们的工作的关键见解是，一种直接估计获取数据对于测试集预测的好处的方法特别适用于去中心化市场设置。

    arXiv:2403.13893v1 Announce Type: new  Abstract: Acquiring high-quality training data is essential for current machine learning models. Data markets provide a way to increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data sellers to join the market. A major challenge for a data buyer in such a market is selecting the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data selection problem that is inspired by linear experimental design. Our proposed data selection method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefit of acquiring data for test set prediction is particularly compatible with a decentralized market setting.
    
[^106]: 以多条件潜在扩散模型学习对比动力学

    Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models

    [https://arxiv.org/abs/2403.13890](https://arxiv.org/abs/2403.13890)

    提出了一个多条件潜在扩散模型来学习对比动力学，以减少对静脉内对比剂的依赖性。

    

    动态对比增强磁共振成像中的对比剂可以定位肿瘤并观察其对比动力学，这对于癌症表征和治疗决策至关重要。然而，对比剂的使用不仅与不良健康风险相关，而且对于怀孕患者、肾功能障碍患者或其他不良反应患者存在限制。由于对比剂摄取是病灶恶性、癌症复发风险和治疗反应的关键生物标志物，因此减少静脉内对比剂的依赖性变得至关重要。为此，我们提出了一个能够进行DCE-MRI时间序列的获取时间条件图像合成的多条件潜在扩散模型。为了评估医学图像合成，我们还提出并验证了基于生物标志物变异性的Fr\'echet放射组学距离作为图像质量度量。

    arXiv:2403.13890v1 Announce Type: cross  Abstract: Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow to localize tumors and observe their contrast kinetics, which is essential for cancer characterization and respective treatment decision-making. However, contrast agent administration is not only associated with adverse health risks, but also restricted for patients during pregnancy, and for those with kidney malfunction, or other adverse reactions. With contrast uptake as key biomarker for lesion malignancy, cancer recurrence risk, and treatment response, it becomes pivotal to reduce the dependency on intravenous contrast agent administration. To this end, we propose a multi-conditional latent diffusion model capable of acquisition time-conditioned image synthesis of DCE-MRI temporal sequences. To evaluate medical image synthesis, we additionally propose and validate the Fr\'echet radiomics distance as an image quality measure based on biomarker variability 
    
[^107]: 空间-时间图表示学习用于战术网络未来状态预测

    Spatial-Temporal Graph Representation Learning for Tactical Networks Future State Prediction

    [https://arxiv.org/abs/2403.13872](https://arxiv.org/abs/2403.13872)

    本文提出了一种空间-时间图编码器-解码器（STGED）框架，用于战术通信网络，通过有效利用网络状态的空间和时间特征，实现了对未来状态的准确预测。

    

    tbd:战术自组织网络中的资源分配存在独特挑战，因为其动态和多跳特性。在这种环境中，准确预测未来的网络连接对于有效的资源分配至关重要。本文提出了空间-时间图编码器-解码器（STGED）框架，用于战术通信网络，有效利用网络状态的空间和时间特征来学习潜在的战术行为。STGED层次地利用基于图的注意机制对一系列通信网络状态进行空间编码，利用循环神经网络对状态的演变进行时间编码，并利用全连接前馈网络来解码未来状态下的连接性。通过大量实验证明，STGED在不同时间步输入下一直比基线模型表现更出色，获得了较高的准确性。

    arXiv:2403.13872v1 Announce Type: new  Abstract: Resource allocation in tactical ad-hoc networks presents unique challenges due to their dynamic and multi-hop nature. Accurate prediction of future network connectivity is essential for effective resource allocation in such environments. In this paper, we introduce the Spatial-Temporal Graph Encoder-Decoder (STGED) framework for Tactical Communication Networks that leverages both spatial and temporal features of network states to learn latent tactical behaviors effectively. STGED hierarchically utilizes graph-based attention mechanism to spatially encode a series of communication network states, leverages a recurrent neural network to temporally encode the evolution of states, and a fully-connected feed-forward network to decode the connectivity in the future state. Through extensive experiments, we demonstrate that STGED consistently outperforms baseline models by large margins across different time-steps input, achieving an accuracy of
    
[^108]: ExMap：利用可解释性热图实现对虚假相关性的无监督群体鲁棒性

    ExMap: Leveraging Explainability Heatmaps for Unsupervised Group Robustness to Spurious Correlations

    [https://arxiv.org/abs/2403.13870](https://arxiv.org/abs/2403.13870)

    ExMap 是一种无监督群体鲁棒性策略，利用可解释性热图推断模型的分类策略，通过聚类模块推断伪标签来增强传统分类器的鲁棒性。

    

    arXiv:2403.13870v1 公告类型：交叉 组鲁棒性策略旨在减轻深度学习模型中由训练数据集中存在的虚假相关性产生的学习偏差。然而，大多数现有方法依赖于对群体标签分布的访问，这是耗时且昂贵的。因此，人们寻求无监督的群体鲁棒性策略。基于这样一种看法：可以根据可解释性热图准确推断训练模型的分类策略，我们引入了ExMap，这是一种设计用于增强传统分类器中群体鲁棒性的无监督两阶段机制。ExMap利用聚类模块根据模型的可解释性热图推断伪标签，然后在训练过程中使用这些伪标签代替实际标签。我们的实证研究验证了ExMap的有效性-我们展示它能够弥合与监督对应方法之间的性能差距，并优于现有的部分

    arXiv:2403.13870v1 Announce Type: cross  Abstract: Group robustness strategies aim to mitigate learned biases in deep learning models that arise from spurious correlations present in their training datasets. However, most existing methods rely on the access to the label distribution of the groups, which is time-consuming and expensive to obtain. As a result, unsupervised group robustness strategies are sought. Based on the insight that a trained model's classification strategies can be inferred accurately based on explainability heatmaps, we introduce ExMap, an unsupervised two stage mechanism designed to enhance group robustness in traditional classifiers. ExMap utilizes a clustering module to infer pseudo-labels based on a model's explainability heatmaps, which are then used during training in lieu of actual labels. Our empirical studies validate the efficacy of ExMap - We demonstrate that it bridges the performance gap with its supervised counterparts and outperforms existing partia
    
[^109]: 准确预测智能系统的安全关键稀有事件概率

    Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems

    [https://arxiv.org/abs/2403.13869](https://arxiv.org/abs/2403.13869)

    该研究致力于发展一个在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色的关键性预测模型。

    

    智能系统越来越成为我们日常生活中的重要组成部分，然而罕见的安全关键事件对它们的实际部署构成了重大潜在威胁。应对这一挑战的关键在于准确预测在给定时间步长内从当前状态发生安全关键事件的概率，一个我们定义为“重要性”的指标。预测重要性的复杂性源自于极端数据不平衡，这是由高维变量中与罕见事件相关联引起的一个挑战，我们称之为罕见性诅咒。现有方法往往要么过于保守，要么容易忽视安全关键事件，因此很难同时实现高精度和召回率，这严重限制了它们的适用性。本研究旨在开发一个重要性预测模型，在评估安全关键自主安全性的重要性方面，在精度和召回率方面都表现出色。

    arXiv:2403.13869v1 Announce Type: cross  Abstract: Intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. Addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. The complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. Existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. This study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical auton
    
[^110]: 通过随机递归方程分析随机梯度下降的重尾特性

    Analysing heavy-tail properties of Stochastic Gradient Descent by means of Stochastic Recurrence Equations

    [https://arxiv.org/abs/2403.13868](https://arxiv.org/abs/2403.13868)

    本文通过随机递归方程的概率框架，研究了随机梯度下降的重尾特性，并通过i-p矩阵理论扩展了G\"{u}rb\"{u}zbalaban等人的结果。

    

    在机器学习理论的最近研究中，观察到可以在随机递归的概率框架下研究随机梯度下降（SGD）的重尾特性。特别地，G\"{u}rb\"{u}zbalaban等人（arXiv:2006.04740）考虑了一个对应于线性回归的设置，其中SGD的迭代可以通过多变量仿射随机递归$X_k=A_k X_{k-1}+B_k$来建模，其中$(A_k, B_k)$是独立同分布对，$A_k$是一个随机对称矩阵，$B_k$是一个随机向量。本文将回答引用论文中的几个未解问题，并通过应用不可约-近端（i-p）矩阵理论扩展他们的结果。

    arXiv:2403.13868v1 Announce Type: cross  Abstract: In recent works on the theory of machine learning, it has been observed that heavy tail properties of Stochastic Gradient Descent (SGD) can be studied in the probabilistic framework of stochastic recursions. In particular, G\"{u}rb\"{u}zbalaban et al. (arXiv:2006.04740) considered a setup corresponding to linear regression for which iterations of SGD can be modelled by a multivariate affine stochastic recursion $X_k=A_k X_{k-1}+B_k$, for independent and identically distributed pairs $(A_k, B_k)$, where $A_k$ is a random symmetric matrix and $B_k$ is a random vector. In this work, we will answer several open questions of the quoted paper and extend their results by applying the theory of irreducible-proximal (i-p) matrices.
    
[^111]: 胶囊神经网络作为时间序列数据的噪声稳定器

    Capsule Neural Networks as Noise Stabilizer for Time Series Data

    [https://arxiv.org/abs/2403.13867](https://arxiv.org/abs/2403.13867)

    Capsule神经网络在分析时间序列传感器数据时展现出良好的噪声鲁棒性，通过实证研究得出其作为噪声稳定器的有效性，击败了原始的卷积神经网络。

    

    胶囊神经网络利用胶囊将神经元绑定成单个向量并学习位置等变特征，这使它们比原始的卷积神经网络更加稳健。CapsNets采用仿射变换矩阵和动态路由与耦合系数来学习稳健性。本文研究了CapsNets在分析高度敏感和嘈杂的时间序列传感器数据中的有效性。为了展示CapsNets的稳健性，我们将它们在复杂模式和噪声的医疗时间序列传感器数据——心电图数据上与原始CNN的性能进行了比较。我们的研究提供了实证证据，证明CapsNets作为噪声稳定器，在使用快速梯度符号方法和三种手动攻击（包括偏移移位、逐渐漂移和时间滞后）的手动和对抗性攻击实验中得到了验证。总而言之，CapsNets在手动和对抗性方面优于CNNs。

    arXiv:2403.13867v1 Announce Type: new  Abstract: Capsule Neural Networks utilize capsules, which bind neurons into a single vector and learn position equivariant features, which makes them more robust than original Convolutional Neural Networks. CapsNets employ an affine transformation matrix and dynamic routing with coupling coefficients to learn robustly. In this paper, we investigate the effectiveness of CapsNets in analyzing highly sensitive and noisy time series sensor data. To demonstrate CapsNets robustness, we compare their performance with original CNNs on electrocardiogram data, a medical time series sensor data with complex patterns and noise. Our study provides empirical evidence that CapsNets function as noise stabilizers, as investigated by manual and adversarial attack experiments using the fast gradient sign method and three manual attacks, including offset shifting, gradual drift, and temporal lagging. In summary, CapsNets outperform CNNs in both manual and adversarial
    
[^112]: 拍卖启发的多人生成对抗网络训练

    The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training

    [https://arxiv.org/abs/2403.13866](https://arxiv.org/abs/2403.13866)

    本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。

    

    本文提出了一种拍卖启发的多人生成对抗网络训练方法，可以缓解GAN的模式坍塌问题。模式坍塌指的是当一个过拟合的生成器生成一种有限范围的样本时，通常集中在数据分布的一小部分上。尽管生成的样本多样性受限，鉴别器仍然可以被欺骗，将这些样本误认为来自实际分布的真实样本。在没有外部标准的情况下，模型无法在训练阶段识别其失败。我们将生成对抗网络的双方游戏扩展到多方游戏。在训练过程中，每个模型的价值由其他玩家在类似拍卖的过程中提交的出价决定。

    arXiv:2403.13866v1 Announce Type: cross  Abstract: This article proposes auction-inspired multi-player generative adversarial networks training, which mitigates the mode collapse problem of GANs. Mode collapse occurs when an over-fitted generator generates a limited range of samples, often concentrating on a small subset of the data distribution. Despite the restricted diversity of generated samples, the discriminator can still be deceived into distinguishing these samples as real samples from the actual distribution. In the absence of external standards, a model cannot recognize its failure during the training phase. We extend the two-player game of generative adversarial networks to the multi-player game. During the training, the values of each model are determined by the bids submitted by other players in an auction-like process.
    
[^113]: 社交网络中用于爬取目标节点的图神经网络

    Graph Neural Network for Crawling Target Nodes in Social Networks

    [https://arxiv.org/abs/2403.13865](https://arxiv.org/abs/2403.13865)

    本文采用图神经网络应用于社交网络中的目标节点爬取，表明其在个别案例中优于传统分类器，并提出了训练样本增强技术以改进预测器质量。

    

    社交网络爬取是近年来积极研究的焦点。其中一个具有挑战性的任务是在给定爬取步数预算的情况下，在最初未知的图中收集目标节点。基于其部分已知邻域预测节点属性是成功爬虫的关键。本文采用图神经网络实现这一目的，并展示它们与传统分类器竞争，并为个别案例效果更好。此外，我们提出了一种训练样本增强技术，有助于在爬取的早期阶段使训练集多样化，从而提高预测器的质量。针对三种目标集拓扑的实验研究表明，基于GNN的方法在爬取任务中具有潜力，特别是在分布式目标节点的情况下。

    arXiv:2403.13865v1 Announce Type: cross  Abstract: Social networks crawling is in the focus of active research the last years. One of the challenging task is to collect target nodes in an initially unknown graph given a budget of crawling steps. Predicting a node property based on its partially known neighbourhood is at the heart of a successful crawler. In this paper we adopt graph neural networks for this purpose and show they are competitive to traditional classifiers and are better for individual cases. Additionally we suggest a training sample boosting technique, which helps to diversify the training set at early stages of crawling and thus improves the predictor quality. The experimental study on three types of target set topology indicates GNN based approach has a potential in crawling task, especially in the case of distributed target nodes.
    
[^114]: 使用小型研究数据集进行公平性的最优运输: 对历史数据进行修复

    Optimal Transport for Fairness: Archival Data Repair using Small Research Data Sets

    [https://arxiv.org/abs/2403.13864](https://arxiv.org/abs/2403.13864)

    本文提出了使用小型研究数据集进行公平性的最优运输修复历史数据的方法，通过设计基于最优运输的修复方案来减小支持大小，实现成本节约和对离样本数据的修复。

    

    随着AI法案和其他法规的出台，迫切需要修复训练数据中的不公平性的算法。本文将公平性定义为保护属性（$S$）和特征（$X$）在给定未受保护属性（$U$）条件下的条件独立性。我们研究了一个重要情景，即需要修复大量历史数据，但只能使用其中一小部分已标记$S|U$的研究数据。我们利用后者设计基于最优运输（OT）的修复方案来插值支持。这允许针对标记、历史数据的修复，同时受制于平稳性假设。这显著减小了OT方案的支持大小，相应地大幅节省了设计成本和顺序应用于离样本数据的成本。我们提供了使用模拟和基准数据进行的详细实验结果。

    arXiv:2403.13864v1 Announce Type: new  Abstract: With the advent of the AI Act and other regulations, there is now an urgent need for algorithms that repair unfairness in training data. In this paper, we define fairness in terms of conditional independence between protected attributes ($S$) and features ($X$), given unprotected attributes ($U$). We address the important setting in which torrents of archival data need to be repaired, using only a small proportion of these data, which are $S|U$-labelled (the research data). We use the latter to design optimal transport (OT)-based repair plans on interpolated supports. This allows {\em off-sample}, labelled, archival data to be repaired, subject to stationarity assumptions. It also significantly reduces the size of the supports of the OT plans, with correspondingly large savings in the cost of their design and of their {\em sequential\/} application to the off-sample data. We provide detailed experimental results with simulated and benchm
    
[^115]: 用去噪扩散概率模型进行表格数据插补的DiffImpute

    DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model

    [https://arxiv.org/abs/2403.13863](https://arxiv.org/abs/2403.13863)

    提出了DiffImpute，一种基于去噪扩散概率模型的表格数据插补方法，可以有效处理不同类型的缺失数据，并通过定制多个表格去噪网络来增强插补的一致性。

    

    表格数据在各个领域中起着至关重要的作用，但往往存在缺失值，从而限制了其潜在效用。传统的插值技术通常会产生次优结果，并给后续建模任务带来重大计算负担，导致出现不准确性。为了解决这些挑战，我们提出了DiffImpute，一种新颖的去噪扩散概率模型（DDPM）。具体来说，DiffImpute在完整的表格数据集上进行训练，确保可以为缺失条目生成可信的插补，而不会破坏现有数据的真实性。创新地，它可以应用于缺失完全随机（MCAR）和缺失随机（MAR）的各种情境。为了有效处理DDPM中的表格特征，我们定制了四个表格去噪网络，涵盖MLP、ResNet、Transformer和U-Net。我们还提出了Harmonization来增强观察到的数据和插补数据之间的一致性。

    arXiv:2403.13863v1 Announce Type: cross  Abstract: Tabular data plays a crucial role in various domains but often suffers from missing values, thereby curtailing its potential utility. Traditional imputation techniques frequently yield suboptimal results and impose substantial computational burdens, leading to inaccuracies in subsequent modeling tasks. To address these challenges, we propose DiffImpute, a novel Denoising Diffusion Probabilistic Model (DDPM). Specifically, DiffImpute is trained on complete tabular datasets, ensuring that it can produce credible imputations for missing entries without undermining the authenticity of the existing data. Innovatively, it can be applied to various settings of Missing Completely At Random (MCAR) and Missing At Random (MAR). To effectively handle the tabular features in DDPM, we tailor four tabular denoising networks, spanning MLP, ResNet, Transformer, and U-Net. We also propose Harmonization to enhance coherence between observed and imputed d
    
[^116]: 基于机器学习的利用光电二极管数据在LPBF中逐层检测过热异常

    Machine Learning-based Layer-wise Detection of Overheating Anomaly in LPBF using Photodiode Data

    [https://arxiv.org/abs/2403.13861](https://arxiv.org/abs/2403.13861)

    本研究提出了一种利用光电二极管数据进行逐层检测LPBF中过热异常的机器学习框架，并通过成本敏感学习处理类别不平衡问题。

    

    过热异常检测对于激光粉床熔化成形（LPBF）增材制造（AM）所生产零件的质量和可靠性至关重要。本研究侧重于利用光电二极管传感器数据检测过热异常。光电二极管传感器可以从熔池中收集高频数据，反映出过程动态和热历史。因此，所提出的方法提供了一个机器学习（ML）框架，利用光电二极管传感器数据进行逐层检测过热异常。为此，从原始光电二极管数据中提取了三组特征：MSMM（平均值、标准差、中位数、最大值）、MSQ（平均值、标准差、四分位数）和MSD（平均值、标准差、十分位数）。这三个数据集用于训练多个ML分类器。采用成本敏感学习来处理“异常”层（受过热影响）和“正常”层之间的类别不平衡问题。

    arXiv:2403.13861v1 Announce Type: new  Abstract: Overheating anomaly detection is essential for the quality and reliability of parts produced by laser powder bed fusion (LPBF) additive manufacturing (AM). In this research, we focus on the detection of overheating anomalies using photodiode sensor data. Photodiode sensors can collect high-frequency data from the melt pool, reflecting the process dynamics and thermal history. Hence, the proposed method offers a machine learning (ML) framework to utilize photodiode sensor data for layer-wise detection of overheating anomalies. In doing so, three sets of features are extracted from the raw photodiode data: MSMM (mean, standard deviation, median, maximum), MSQ (mean, standard deviation, quartiles), and MSD (mean, standard deviation, deciles). These three datasets are used to train several ML classifiers. Cost-sensitive learning is used to handle the class imbalance between the "anomalous" layers (affected by overheating) and "nominal" layer
    
[^117]: 用于粒子加速器束流动力学生成和预测的条件潜在自回归递归模型

    A conditional latent autoregressive recurrent model for generation and forecasting of beam dynamics in particle accelerators

    [https://arxiv.org/abs/2403.13858](https://arxiv.org/abs/2403.13858)

    提出了一个名为CLARM的两步无监督深度学习框架，用于学习加速器中带电粒子的时空动态，并能够生成不同加速器模块的投影和预测粒子的未来状态。

    

    粒子加速器是将强烈的带电粒子束流集中、引导和加速到高能的复杂系统。束流诊断面临挑战，因为受限的非破坏性测量、计算密集型模拟以及系统固有的不确定性。我们提出了一个名为条件潜在自回归递归模型（CLARM）的两步无监督深度学习框架，用于学习加速器中带电粒子的时空动态。CLARM包括一个条件变分自编码器（CVAE），将六维相空间转换为低维潜在分布，以及一个长短期记忆（LSTM）网络，以自回归方式捕获时间动态。CLARM能够通过对潜在空间表示进行采样和解码来生成各种加速器模块的投影。该模型还可以预测充电粒子的未来状态（下游位置）。

    arXiv:2403.13858v1 Announce Type: cross  Abstract: Particle accelerators are complex systems that focus, guide, and accelerate intense charged particle beams to high energy. Beam diagnostics present a challenging problem due to limited non-destructive measurements, computationally demanding simulations, and inherent uncertainties in the system. We propose a two-step unsupervised deep learning framework named as Conditional Latent Autoregressive Recurrent Model (CLARM) for learning the spatiotemporal dynamics of charged particles in accelerators. CLARM consists of a Conditional Variational Autoencoder (CVAE) transforming six-dimensional phase space into a lower-dimensional latent distribution and a Long Short-Term Memory (LSTM) network capturing temporal dynamics in an autoregressive manner. The CLARM can generate projections at various accelerator modules by sampling and decoding the latent space representation. The model also forecasts future states (downstream locations) of charged p
    
[^118]: 用人工神经网络控制医学数字孪生体

    Control of Medical Digital Twins with Artificial Neural Networks

    [https://arxiv.org/abs/2403.13851](https://arxiv.org/abs/2403.13851)

    介绍了一种使用神经网络方法来控制医学数字孪生体的方法

    

    个性化医学的目标是将干预措施调整到个体患者的独特特征。用于实现这一目的的关键技术涉及医学数字孪生体，这是人体生物学的计算模型，可以个性化并动态更新，以纳入随时间收集的特定患者数据。人体生物学的某些方面，如免疫系统，不容易用基于物理的模型（如微分方程）捕捉。相反，它们往往是多尺度的、随机的和混合的。对于现有的基于模型的控制和优化方法而言，这构成了一个挑战，这些方法无法轻松应用于这种模型。自动微分和神经网络控制方法的最新进展有望解决复杂的控制问题。然而，将这些方法应用于生物医学系统仍处于早期阶段。本文介绍了一种基于动力学的神经网络控制方

    arXiv:2403.13851v1 Announce Type: cross  Abstract: The objective of personalized medicine is to tailor interventions to an individual patient's unique characteristics. A key technology for this purpose involves medical digital twins, computational models of human biology that can be personalized and dynamically updated to incorporate patient-specific data collected over time. Certain aspects of human biology, such as the immune system, are not easily captured with physics-based models, such as differential equations. Instead, they are often multi-scale, stochastic, and hybrid. This poses a challenge to existing model-based control and optimization approaches that cannot be readily applied to such models. Recent advances in automatic differentiation and neural-network control methods hold promise in addressing complex control problems. However, the application of these approaches to biomedical systems is still in its early stages. This work introduces dynamics-informed neural-network co
    
[^119]: 经过物理意识和参数扩散指导的时空流体动力学建模

    Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance

    [https://arxiv.org/abs/2403.13850](https://arxiv.org/abs/2403.13850)

    该论文提出了ST-PAD框架，通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测，在多个基准数据集上的实验证明其优于当前主流模型

    

    本文提出了一种名为ST-PAD的两阶段框架，用于地球科学领域的时空流体动力学建模，旨在通过时空物理学意识和参数扩散引导实现流体动力学的高精度仿真和预测。在上游阶段，我们设计了一个具有时间演变特性的矢量量化重构模块，通过引入一般的物理约束，确保了平衡和有弹性的参数分布。在下游阶段，利用涉及参数的扩散概率网络来生成高质量的未来流体状态，同时通过感知不同物理设置中的参数，增强模型的泛化能力。对多个基准数据集进行的大量实验验证了ST-PAD框架的有效性和鲁棒性，显示ST-PAD在流体动力学方面优于当前主流模型。

    arXiv:2403.13850v1 Announce Type: cross  Abstract: This paper proposes a two-stage framework named ST-PAD for spatio-temporal fluid dynamics modeling in the field of earth sciences, aiming to achieve high-precision simulation and prediction of fluid dynamics through spatio-temporal physics awareness and parameter diffusion guidance. In the upstream stage, we design a vector quantization reconstruction module with temporal evolution characteristics, ensuring balanced and resilient parameter distribution by introducing general physical constraints. In the downstream stage, a diffusion probability network involving parameters is utilized to generate high-quality future states of fluids, while enhancing the model's generalization ability by perceiving parameters in various physical setups. Extensive experiments on multiple benchmark datasets have verified the effectiveness and robustness of the ST-PAD framework, which showcase that ST-PAD outperforms current mainstream models in fluid dyna
    
[^120]: 揭秘图：图神经网络与图生成

    Graphs Unveiled: Graph Neural Networks and Graph Generation

    [https://arxiv.org/abs/2403.13849](https://arxiv.org/abs/2403.13849)

    该论文综述了图神经网络（GNNs）在各个领域的应用，并介绍了GNNs中的先进领域：图生成。

    

    机器学习领域的热点话题之一是GNN领域。图数据的复杂性给现有的机器学习算法带来了重大挑战。最近，涌现了许多关于扩展深度学习方法应用于图数据的研究。本文提供了一项调研，全面概述了图神经网络（GNNs）。我们讨论了图神经网络在各个领域的应用。最后，我们介绍了GNNs中的一项先进领域：图生成。

    arXiv:2403.13849v1 Announce Type: cross  Abstract: One of the hot topics in machine learning is the field of GNN. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. This paper represents a survey, providing a comprehensive overview of Graph Neural Networks (GNNs). We discuss the applications of graph neural networks across various domains. Finally, we present an advanced field in GNNs: graph generation.
    
[^121]: 用于学习差异保护但准确规则列表的平滑敏感度

    Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists

    [https://arxiv.org/abs/2403.13848](https://arxiv.org/abs/2403.13848)

    通过建立Gini不纯度的平滑敏感度并将其应用于提出DP贪婪规则列表算法，本文改善了差异保护模型的准确性问题。

    

    差异保护（DP）机制可以嵌入到机器学习算法的设计中，以保护所得模型免受隐私泄露的影响，尽管这通常伴随着明显的准确性损失。本文旨在通过建立Gini不纯度的平滑敏感度并利用这一特性来提出一个DP贪婪规则列表算法，以改善这种权衡。我们的理论分析和实验结果表明，集成平滑敏感度的DP规则列表模型具有比使用全局敏感度的其他DP框架更高的准确性。

    arXiv:2403.13848v1 Announce Type: cross  Abstract: Differentially-private (DP) mechanisms can be embedded into the design of a machine learningalgorithm to protect the resulting model against privacy leakage, although this often comes with asignificant loss of accuracy. In this paper, we aim at improving this trade-off for rule lists modelsby establishing the smooth sensitivity of the Gini impurity and leveraging it to propose a DP greedyrule list algorithm. In particular, our theoretical analysis and experimental results demonstrate thatthe DP rule lists models integrating smooth sensitivity have higher accuracy that those using otherDP frameworks based on global sensitivity.
    
[^122]: 通过高斯混合模型进行域自适应的最优输运

    Optimal Transport for Domain Adaptation through Gaussian Mixture Models

    [https://arxiv.org/abs/2403.13847](https://arxiv.org/abs/2403.13847)

    通过高斯混合模型进行域自适应的最优输运，可以实现源域和目标域混合成分之间的匹配，从而在失效诊断中取得最先进的性能。

    

    在这篇论文中，我们探讨了通过最优输运进行域自适应的方法。我们提出了一种新颖的方法，即通过高斯混合模型对数据分布进行建模。这种策略使我们能够通过等价的离散问题解决连续最优输运。最优输运解决方案为我们提供了源域和目标域混合成分之间的匹配。通过这种匹配，我们可以在域之间映射数据点，或者将标签从源域组件转移到目标域。我们在失效诊断的两个域自适应基准测试中进行了实验，结果表明我们的方法具有最先进的性能。

    arXiv:2403.13847v1 Announce Type: cross  Abstract: In this paper we explore domain adaptation through optimal transport. We propose a novel approach, where we model the data distributions through Gaussian mixture models. This strategy allows us to solve continuous optimal transport through an equivalent discrete problem. The optimal transport solution gives us a matching between source and target domain mixture components. From this matching, we can map data points between domains, or transfer the labels from the source domain components towards the target domain. We experiment with 2 domain adaptation benchmarks in fault diagnosis, showing that our methods have state-of-the-art performance.
    
[^123]: 一种具有图最大解码信息的聚类方法

    A Clustering Method with Graph Maximum Decoding Information

    [https://arxiv.org/abs/2403.13846](https://arxiv.org/abs/2403.13846)

    CMDI聚类方法创新性地将二维结构信息理论融入聚类过程中，弥补了基于图的模型聚类方法中忽略的随机游走访问节点和数据中嵌入的结构信息的不确定性。

    

    基于图模型的聚类方法因其在各种知识领域中的广泛适用性而备受关注。其能够与其他相关应用无缝集成的适应性赋予了基于图模型的聚类分析能力，可以强大地从数据集中提取“自然关联”或“图结构”，有助于建模数据点之间的关系。尽管这种方法效果显著，但当前利用基于图的模型的聚类方法忽略了节点之间随机游走访问以及数据中嵌入的结构信息所带来的不确定性。为填补这一空白，我们提出了一种新颖的基于图的模型内最大化解码信息的聚类方法，命名为CMDI。CMDI创新地将二维结构信息理论纳入到聚类过程中，包括两个阶段：图结构提取和图顶点

    arXiv:2403.13846v1 Announce Type: cross  Abstract: The clustering method based on graph models has garnered increased attention for its widespread applicability across various knowledge domains. Its adaptability to integrate seamlessly with other relevant applications endows the graph model-based clustering analysis with the ability to robustly extract "natural associations" or "graph structures" within datasets, facilitating the modelling of relationships between data points. Despite its efficacy, the current clustering method utilizing the graph-based model overlooks the uncertainty associated with random walk access between nodes and the embedded structural information in the data. To address this gap, we present a novel Clustering method for Maximizing Decoding Information within graph-based models, named CMDI. CMDI innovatively incorporates two-dimensional structural information theory into the clustering process, consisting of two phases: graph structure extraction and graph vert
    
[^124]: 学会更好地看见看不见的东西：用于增量式零样本故障诊断的广深混合反遗忘框架

    Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis

    [https://arxiv.org/abs/2403.13845](https://arxiv.org/abs/2403.13845)

    提出了增量式ZSFD范式，开发了广深混合反遗忘框架（BDMAFF），旨在学习和适应新的故障类别和属性，解决了现有ZSFD范式在工业场景中无法从不断变化的训练数据流中学习的问题。

    

    零样本故障诊断（ZSFD）能够通过预测人类专家标注的故障属性来识别看不见的故障。为了解决工业过程中持续变化的需求，即模型适应新的故障类别和属性而避免忘记先前学到的诊断能力，我们首次提出了增量式ZSFD（IZSFD）范式，它结合了传统ZSFD和广义ZSFD范式的类别增量和属性增量。为了实现IZSFD，我们提出了一个旨在学习新的故障类别和属性的广深混合反遗忘框架（BDMAFF）。为了解决遗忘问题，BDMAFF有效地从两个角度积累先前获得的知识。

    arXiv:2403.13845v1 Announce Type: cross  Abstract: Zero-shot fault diagnosis (ZSFD) is capable of identifying unseen faults via predicting fault attributes labeled by human experts. We first recognize the demand of ZSFD to deal with continuous changes in industrial processes, i.e., the model's ability to adapt to new fault categories and attributes while avoiding forgetting the diagnosis ability learned previously. To overcome the issue that the existing ZSFD paradigm cannot learn from evolving streams of training data in industrial scenarios, the incremental ZSFD (IZSFD) paradigm is proposed for the first time, which incorporates category increment and attribute increment for both traditional ZSFD and generalized ZSFD paradigms. To achieve IZSFD, we present a broad-deep mixed anti-forgetting framework (BDMAFF) that aims to learn from new fault categories and attributes. To tackle the issue of forgetting, BDMAFF effectively accumulates previously acquired knowledge from two perspective
    
[^125]: 面向脑机接口的轻量级向量符号体系架构的定时知识获取

    Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces

    [https://arxiv.org/abs/2403.13844](https://arxiv.org/abs/2403.13844)

    低维度计算分类器基于向量符号体系结构（VSA），通过定时知识获取方法，提高小模型准确率，解决处理复杂脑信号的挑战。

    

    脑机接口（BCIs）通常设计为轻量级且实时响应，以为用户提供及时反馈。经典特征工程计算效率高但准确率低，而近期的神经网络（DNNs）提高准确率但计算代价高、延迟大。作为一种有前途的替代选择，基于向量符号体系结构（VSA）的低维度计算（LDC）分类器实现了小模型大小，但准确率高于经典特征工程方法。然而，它的准确率仍落后于现代DNNs，这使得处理复杂的脑信号具有挑战性。为了提高小模型的准确率，知识蒸馏是一种流行的方法。然而，在学生模型在其不断学习阶段时保持教师模型和学生模型之间的恒定蒸馏水平可能并非最佳选择。在这项研究中，我们提出了一种定时知识获取的方法，使学生模型能够在逐步学习阶段改善准确率。

    arXiv:2403.13844v1 Announce Type: cross  Abstract: Brain-Computer interfaces (BCIs) are typically designed to be lightweight and responsive in real-time to provide users timely feedback. Classical feature engineering is computationally efficient but has low accuracy, whereas the recent neural networks (DNNs) improve accuracy but are computationally expensive and incur high latency. As a promising alternative, the low-dimensional computing (LDC) classifier based on vector symbolic architecture (VSA), achieves small model size yet higher accuracy than classical feature engineering methods. However, its accuracy still lags behind that of modern DNNs, making it challenging to process complex brain signals. To improve the accuracy of a small model, knowledge distillation is a popular method. However, maintaining a constant level of distillation between the teacher and student models may not be the best way for a growing student during its progressive learning stages. In this work, we propos
    
[^126]: 机器学习和视觉Transformer在甲状腺癌诊断中的应用：综述

    Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review

    [https://arxiv.org/abs/2403.13843](https://arxiv.org/abs/2403.13843)

    该论文总结了使用机器学习和大数据分析结合transformer评估甲状腺癌预后的方法，介绍了新的分类系统，并强调了人工智能在辅助甲状腺癌诊断和治疗中的重要性。

    

    与发展智能诊断系统以帮助医学专家处理大量数据以治疗不可治愈疾病的兴趣不断增长。特别是，在识别甲状腺癌（TC）的挑战方面，使用机器学习（ML）和大数据分析取得了进展，结合transformer评估TC预后，并确定个体的恶性风险。本综述文章总结了各种关于以人工智能（AI）算法为基础的方法的研究，特别是那些采用transformer进行甲状腺癌诊断的方法。它引入了一个新的基于AI算法、框架目标和使用的计算环境对这些方法进行分类的系统。此外，它通过其特征审查和对比了可用的TC数据集。该论文强调了AI工具在通过监督、无监督或混合方式协助诊断和治疗TC方面的重要性。

    arXiv:2403.13843v1 Announce Type: cross  Abstract: The growing interest in developing smart diagnostic systems to help medical experts process extensive data for treating incurable diseases has been notable. In particular, the challenge of identifying thyroid cancer (TC) has seen progress with the use of machine learning (ML) and big data analysis, incorporating transformers to evaluate TC prognosis and determine the risk of malignancy in individuals. This review article presents a summary of various studies on AIbased approaches, especially those employing transformers, for diagnosing TC. It introduces a new categorization system for these methods based on artifcial intelligence (AI) algorithms, the goals of the framework, and the computing environments used. Additionally, it scrutinizes and contrasts the available TC datasets by their features. The paper highlights the importance of AI instruments in aiding the diagnosis and treatment of TC through supervised, unsupervised, or mixed 
    
[^127]: 分析香港急诊室候诊时间变化，并测试COVID-19大流行期间跨波次预测模型的可传递性：混合CNN-LSTM方法用于量化建筑级社会生态风险

    Analyzing the Variations in Emergency Department Boarding and Testing the Transferability of Forecasting Models across COVID-19 Pandemic Waves in Hong Kong: Hybrid CNN-LSTM approach to quantifying building-level socioecological risk

    [https://arxiv.org/abs/2403.13842](https://arxiv.org/abs/2403.13842)

    对香港急诊室候诊时间变化进行分析，通过混合CNN-LSTM模型探讨预测模型的可传递性，在COVID-19大流行期间观察到波次四和五之间出现最多的ED候诊天数，并发现在波次四和五之间出现表现最佳的预测模型。

    

    急诊科（ED）的候诊（定义为急诊室等待时间超过四小时）与病人不良结果及医疗系统表现不佳有关。然而，在COVID-19之前缺乏有效的预测模型，在COVID-19期间缺乏。在本研究中，我们应用了混合卷积神经网络（CNN）-长短期记忆（LSTM）模型对香港医院管理局、卫生署和房屋局的公共数据进行了分析。此外，我们试图使用深度迁移学习方法，识别在COVID-19大流行期间对我们复杂的自适应医疗系统产生明显干扰的阶段，从而揭示其组成部分之间的稳定相互关系模式。

    arXiv:2403.13842v1 Announce Type: new  Abstract: Emergency department's (ED) boarding (defined as ED waiting time greater than four hours) has been linked to poor patient outcomes and health system performance. Yet, effective forecasting models is rare before COVID-19, lacking during the peri-COVID era. Here, a hybrid convolutional neural network (CNN)-Long short-term memory (LSTM) model was applied to public-domain data sourced from Hong Kong's Hospital Authority, Department of Health, and Housing Authority. In addition, we sought to identify the phase of the COVID-19 pandemic that most significantly perturbed our complex adaptive healthcare system, thereby revealing a stable pattern of interconnectedness among its components, using deep transfer learning methodology.   Our result shows that 1) the greatest proportion of days with ED boarding was found between waves four and five; 2) the best-performing model for forecasting ED boarding was observed between waves four and five, which 
    
[^128]: 整合可穿戴传感器数据和自我报告日记用于个性化情感预测

    Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting

    [https://arxiv.org/abs/2403.13841](https://arxiv.org/abs/2403.13841)

    本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。

    

    情绪状态作为情感的指标对整体健康至关重要，因此在其发作前准确预测是至关重要的。目前的研究主要集中在使用来自可穿戴和移动设备的数据进行与短期情感检测。这些研究通常专注于客观的感官测量，往往忽略其他形式的自我报告信息，如日记和笔记。在本文中，我们提出了一种用于情感状态预测的多模态深度学习模型。该模型结合了一个transformer编码器和一个预训练语言模型，实现了客观指标和自我报告日记的综合分析。为了验证我们的模型，我们进行了一项纵向研究，招募了大学生并在一年内对其进行监测，收集了包括生理、环境、睡眠、代谢和身体活动参数在内的广泛数据集，同时参与者提供了开放式文本日记。

    arXiv:2403.13841v1 Announce Type: cross  Abstract: Emotional states, as indicators of affect, are pivotal to overall health, making their accurate prediction before onset crucial. Current studies are primarily centered on immediate short-term affect detection using data from wearable and mobile devices. These studies typically focus on objective sensory measures, often neglecting other forms of self-reported information like diaries and notes. In this paper, we propose a multimodal deep learning model for affect status forecasting. This model combines a transformer encoder with a pre-trained language model, facilitating the integrated analysis of objective metrics and self-reported diaries. To validate our model, we conduct a longitudinal study, enrolling college students and monitoring them over a year, to collect an extensive dataset including physiological, environmental, sleep, metabolic, and physical activity parameters, alongside open-ended textual diaries provided by the partici
    
[^129]: depyf：为机器学习研究者打开PyTorch编译器的神秘盒子

    depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers

    [https://arxiv.org/abs/2403.13839](https://arxiv.org/abs/2403.13839)

    depyf是一个非侵入性和用户友好的工具，旨在帮助机器学习研究者揭开PyTorch编译器的内部工作机制，并通过反编译将字节码转换为源代码，从而增进用户对底层过程的理解。

    

    PyTorch 2.x引入了一个旨在加速深度学习程序的编译器。然而，对于机器学习研究者来说，充分利用PyTorch编译器可能具有挑战性。编译器在Python字节码级别运行，使其看起来像一个神秘的盒子。为解决这一问题，我们引入了depyf，这是一个旨在揭开PyTorch编译器内部机制的工具。depyf可以将PyTorch生成的字节码反编译为等效的源代码，并建立内存中代码对象与磁盘上源代码对应的联系。这个特性使用户可以使用调试器逐行查看源代码，从而增进对底层过程的理解。值得注意的是，depyf是非侵入性且用户友好的，主要依赖于两个方便的上下文管理器来实现其核心功能。

    arXiv:2403.13839v1 Announce Type: cross  Abstract: PyTorch \texttt{2.x} introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, adapting to the PyTorch compiler to full potential can be challenging. The compiler operates at the Python bytecode level, making it appear as an opaque box. To address this, we introduce \texttt{depyf}, a tool designed to demystify the inner workings of the PyTorch compiler. \texttt{depyf} decompiles bytecode generated by PyTorch back into equivalent source code, and establishes connections between in-memory code objects and their on-disk source code counterparts. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, \texttt{depyf} is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is \href{https://github.com/thuml/depyf}
    
[^130]: 电路变压器：通过预测下一个门实现端到端电路设计

    Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate

    [https://arxiv.org/abs/2403.13838](https://arxiv.org/abs/2403.13838)

    本研究探索了通过预测下一个逻辑门来实现电路设计的可能性。

    

    语言是人类通过序列符号表达的突出能力，近年来大型语言模型（LLMs）已经在计算上掌握了这种能力。通过利用巨大的神经模型不断预测下一个单词，LLMs展现出了前所未有的理解和推理能力。电路作为电子设计的“语言”，通过逻辑门的级联连接来指定电子设备的功能。在这项工作中，我们首次探索了这种可能性，以通过简单地预测下一个逻辑门来征服电子设计任务。

    arXiv:2403.13838v1 Announce Type: new  Abstract: Language, a prominent human ability to express through sequential symbols, has been computationally mastered by recent advances of large language models (LLMs). By predicting the next word recurrently with huge neural models, LLMs have shown unprecedented capabilities in understanding and reasoning. Circuit, as the "language" of electronic design, specifies the functionality of an electronic device by cascade connections of logic gates. Then, can circuits also be mastered by a a sufficiently large "circuit model", which can conquer electronic design tasks by simply predicting the next logic gate? In this work, we take the first step to explore such possibilities. Two primary barriers impede the straightforward application of LLMs to circuits: their complex, non-sequential structure, and the intolerance of hallucination due to strict constraints (e.g., equivalence). For the first barrier, we encode a circuit as a memory-less, depth-first 
    
[^131]: 基于树的学习用于深度预测混沌现象

    Tree-based Learning for High-Fidelity Prediction of Chaos

    [https://arxiv.org/abs/2403.13836](https://arxiv.org/abs/2403.13836)

    TreeDOX是一种基于树的方法，不需要超参数调整，使用时间延迟过度嵌入和额外树回归器进行特征降维和预测，并在深度预测混沌系统中表现出state-of-the-art的性能。

    

    深度预测混沌系统的时间演变是至关重要但具有挑战性的。现有解决方案需要进行超参数调整，这严重阻碍了它们的广泛应用。在这项工作中，我们引入了一种无需超参数调整的基于树的方法：TreeDOX。它使用时间延迟过度嵌入作为显式短期记忆，以及额外树回归器来执行特征降维和预测。我们使用Henon映射，Lorenz和Kuramoto-Sivashinsky系统以及现实世界的Southern Oscillation Index展示了TreeDOX的最先进性能。

    arXiv:2403.13836v1 Announce Type: new  Abstract: Model-free forecasting of the temporal evolution of chaotic systems is crucial but challenging. Existing solutions require hyperparameter tuning, significantly hindering their wider adoption. In this work, we introduce a tree-based approach not requiring hyperparameter tuning: TreeDOX. It uses time delay overembedding as explicit short-term memory and Extra-Trees Regressors to perform feature reduction and forecasting. We demonstrate the state-of-the-art performance of TreeDOX using the Henon map, Lorenz and Kuramoto-Sivashinsky systems, and the real-world Southern Oscillation Index.
    
[^132]: 使用准确性保证自动缩减语言模型规模以降低处理费用的SMART

    SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees

    [https://arxiv.org/abs/2403.13835](https://arxiv.org/abs/2403.13835)

    提出了SMART框架，可通过准确性约束最小化自然语言处理任务的推理成本，同时确保结果质量。

    

    大型语言模型（LLMs）的进步显著提高了自然语言处理（NLP）任务的性能。然而，部署高性能LLMs会产生巨大的成本，主要是由于增加的参数数量旨在提升模型性能。这使得最先进的LLMs对终端用户而言变得更加昂贵。我们引入了SMART，即为降低标记费用而自适应缩放模型，这是一个新颖的LLM框架，旨在最大程度地降低NLP任务的推理成本，同时确保足够的结果质量。它使用户能够以输出的等效性指定准确性约束与最强大的LLM。

    arXiv:2403.13835v1 Announce Type: cross  Abstract: The advancement of Large Language Models (LLMs) has significantly boosted performance in natural language processing (NLP) tasks. However, the deployment of high-performance LLMs incurs substantial costs, primarily due to the increased number of parameters aimed at enhancing model performance. This has made the use of state-of-the-art LLMs more expensive for end-users. AI service providers, such as OpenAI and Anthropic, often offer multiple versions of LLMs with varying prices and performance. However, end-users still face challenges in choosing the appropriate LLM for their tasks that balance result quality with cost.   We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel LLM framework designed to minimize the inference costs of NLP tasks while ensuring sufficient result quality. It enables users to specify an accuracy constraint in terms of the equivalence of outputs to those of the most powerful LLM. SMART t
    
[^133]: 异质图上的少样本学习：挑战、进展和展望

    Few-shot Learning on Heterogeneous Graphs: Challenges, Progress, and Prospects

    [https://arxiv.org/abs/2403.13834](https://arxiv.org/abs/2403.13834)

    异质图上的少样本学习面临标签稀疏性问题，本文系统综述了FLHG方法，研究了单一、双重和多重异质性FLHG，并探讨了未来研究方向。

    

    异质图上的少样本学习(FLHG)越来越受到学术界和产业界的关注，因为现有的异质图研究往往受到标签稀疏性的困扰。 FLHG旨在解决面对有限标注数据时的性能下降问题，并已有许多最近的研究提出了各种方法和应用。 本文对现有的FLHG方法进行了全面评估，涵盖了挑战、研究进展和未来展望。 具体来说，我们首先对FLHG进行了形式化描述，并将其方法分为三种类型：单异质性FLHG、双异质性FLHG和多异质性FLHG。 然后，我们分析了每个类别内的研究进展，重点介绍了最新和代表性的发展。 最后，我们确定并讨论了FLHG未来研究的有前途的方向。 据我们所知，本文是第一篇系统而全面的FLHG综述。

    arXiv:2403.13834v1 Announce Type: new  Abstract: Few-shot learning on heterogeneous graphs (FLHG) is attracting more attention from both academia and industry because prevailing studies on heterogeneous graphs often suffer from label sparsity. FLHG aims to tackle the performance degradation in the face of limited annotated data and there have been numerous recent studies proposing various methods and applications. In this paper, we provide a comprehensive review of existing FLHG methods, covering challenges, research progress, and future prospects. Specifically, we first formalize FLHG and categorize its methods into three types: single-heterogeneity FLHG, dual-heterogeneity FLHG, and multi-heterogeneity FLHG. Then, we analyze the research progress within each category, highlighting the most recent and representative developments. Finally, we identify and discuss promising directions for future research in FLHG. To the best of our knowledge, this paper is the first systematic and compr
    
[^134]: 线性约束权重：减少神经网络训练中的激活偏移

    Linearly Constrained Weights: Reducing Activation Shift for Faster Training of Neural Networks

    [https://arxiv.org/abs/2403.13833](https://arxiv.org/abs/2403.13833)

    神经网络中引入线性约束权重（LCW）来减少激活偏移，有效解决了梯度消失问题，提高了深度前向网络的训练效率。

    

    在本文中，我们首次确定了激活偏移，这是神经网络中的一个简单但显著的现象，即神经元的预激活值具有非零均值，该均值取决于神经元的权重向量与前一层激活向量均值之间的夹角。然后，我们提出了线性约束权重（LCW），以减少全连接和卷积层中的激活偏移。从网络变量的方差如何通过前向和反向链中的层操作来改变的角度研究了减少神经网络中激活偏移的影响。我们还讨论了它与梯度消失问题的关系。实验结果表明，LCW使具有sigmoid激活函数的深度前向网络能够通过解决梯度消失问题而得以有效训练。此外，与批归一化结合使用，LCW改进了genera

    arXiv:2403.13833v1 Announce Type: cross  Abstract: In this paper, we first identify activation shift, a simple but remarkable phenomenon in a neural network in which the preactivation value of a neuron has non-zero mean that depends on the angle between the weight vector of the neuron and the mean of the activation vector in the previous layer. We then propose linearly constrained weights (LCW) to reduce the activation shift in both fully connected and convolutional layers. The impact of reducing the activation shift in a neural network is studied from the perspective of how the variance of variables in the network changes through layer operations in both forward and backward chains. We also discuss its relationship to the vanishing gradient problem. Experimental results show that LCW enables a deep feedforward network with sigmoid activation functions to be trained efficiently by resolving the vanishing gradient problem. Moreover, combined with batch normalization, LCW improves genera
    
[^135]: 文本与分子之间的桥梁：分子多模态框架综述

    Bridging Text and Molecule: A Survey on Multimodal Frameworks for Molecule

    [https://arxiv.org/abs/2403.13830](https://arxiv.org/abs/2403.13830)

    本文首次系统调研了针对分子研究的多模态框架，重点讨论了文本与分子之间的关联、不同模型架构和预训练任务。同时还深入探讨了大型语言模型以及提示技术在分子领域中的应用。

    

    人工智能在科学研究中展现出巨大潜力。在分子科学领域，它正在改变传统的计算机辅助范式，引领着深度学习的新时代。随着多模态学习和自然语言处理的最新进展，一种新兴趋势是构建多模态框架，以共同建模分子和文本领域知识。本文首次系统地调研了针对分子研究的多模态框架。具体来说，我们从分子深度学习的发展入手，指出涉及文本模态的必要性。接下来，我们关注了文本-分子对齐方法的最新进展，根据它们的架构将当前模型分为两组，并列出相关的预训练任务。此外，我们深入研究了大型语言模型和提示技术在分子任务和预训练中的应用。

    arXiv:2403.13830v1 Announce Type: cross  Abstract: Artificial intelligence has demonstrated immense potential in scientific research. Within molecular science, it is revolutionizing the traditional computer-aided paradigm, ushering in a new era of deep learning. With recent progress in multimodal learning and natural language processing, an emerging trend has targeted at building multimodal frameworks to jointly model molecules with textual domain knowledge. In this paper, we present the first systematic survey on multimodal frameworks for molecules research. Specifically,we begin with the development of molecular deep learning and point out the necessity to involve textual modality. Next, we focus on recent advances in text-molecule alignment methods, categorizing current models into two groups based on their architectures and listing relevant pre-training tasks. Furthermore, we delves into the utilization of large language models and prompting techniques for molecular tasks and prese
    
[^136]: DecompOpt：用于基于结构的分子优化的可控分解扩散模型

    DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization

    [https://arxiv.org/abs/2403.13829](https://arxiv.org/abs/2403.13829)

    提出了一种基于可控分解扩散模型的结构化分子优化方法

    

    最近，3D生成模型在基于结构的药物设计中表现出良好性能，通过学习在给定靶标结合位点的情况下生成配体。然而，仅建模靶-配体分布几乎无法实现药物发现的主要目标之一——设计具有所需属性（如高结合亲和力，易合成等）的新型配体。当用于训练的靶-配体对不符合这些期望属性时，这一挑战尤为明显。此外，大多数现有方法旨在解决\textit{从无到有}的设计任务，而许多需要灵活可控性的生成场景，如R基团优化和骨架跳跃等，却受到了很少关注。在这项工作中，我们提出了DecompOpt，这是一种基于结构的分子优化方法，基于一个可控且分解的扩散模型。DecompOpt提出了一种新的生成范式，结合了优化的

    arXiv:2403.13829v1 Announce Type: cross  Abstract: Recently, 3D generative models have shown promising performances in structure-based drug design by learning to generate ligands given target binding sites. However, only modeling the target-ligand distribution can hardly fulfill one of the main goals in drug discovery -- designing novel ligands with desired properties, e.g., high binding affinity, easily synthesizable, etc. This challenge becomes particularly pronounced when the target-ligand pairs used for training do not align with these desired properties. Moreover, most existing methods aim at solving \textit{de novo} design task, while many generative scenarios requiring flexible controllability, such as R-group optimization and scaffold hopping, have received little attention. In this work, we propose DecompOpt, a structure-based molecular optimization method based on a controllable and decomposed diffusion model. DecompOpt presents a new generation paradigm which combines optimi
    
[^137]: 基于主动推理的自监督路径规划在无人机辅助无线网络中的应用

    Self-Supervised Path Planning in UAV-aided Wireless Networks based on Active Inference

    [https://arxiv.org/abs/2403.13827](https://arxiv.org/abs/2403.13827)

    提出一种基于主动推理的自监督路径规划方法，使得无人机能够通过世界模型和主动推理进行实时自主决策和在线规划，有助于更快地适应新情况，并表现优于传统RL。

    

    本文提出了一种新颖的自监督路径规划方法，适用于无人机辅助网络。首先，我们利用优化器离线解决训练示例，然后使用得到的解决方案作为示范，让无人机可以学习世界模型以理解环境，并隐式地发现优化器的策略。配备世界模型的无人机可以做出实时自主决策，并利用主动推理进行在线规划。在规划过程中，无人机可以根据预期的惊喜为不同策略打分，从而选择最优的未来。此外，无人机可以利用世界模型预测其行为的结果，并以自监督的方式评估预期的惊喜。我们的方法使得无人机能够更快地适应新情况，并表现比传统RL更好，具有更广泛的泛化能力。

    arXiv:2403.13827v1 Announce Type: cross  Abstract: This paper presents a novel self-supervised path-planning method for UAV-aided networks. First, we employed an optimizer to solve training examples offline and then used the resulting solutions as demonstrations from which the UAV can learn the world model to understand the environment and implicitly discover the optimizer's policy. UAV equipped with the world model can make real-time autonomous decisions and engage in online planning using active inference. During planning, UAV can score different policies based on the expected surprise, allowing it to choose among alternative futures. Additionally, UAV can anticipate the outcomes of its actions using the world model and assess the expected surprise in a self-supervised manner. Our method enables quicker adaptation to new situations and better performance than traditional RL, leading to broader generalizability.
    
[^138]: 在共创图像生成中衡量多样性

    Measuring Diversity in Co-creative Image Generation

    [https://arxiv.org/abs/2403.13826](https://arxiv.org/abs/2403.13826)

    提出了一种基于神经网络编码熵的方法，以比较图像集合之间的多样性，而无需真实标准知识且易于计算，并展示了不同预训练网络选择对我们要评估的多样性概念的影响。

    

    质量和多样性已被提出作为评估共创系统生成内容的合理启发式方法，但迄今为止，人们对后者的构成以及如何衡量它尚无统一意见。目前用于评估生成模型多样性的方法存在局限性，在大型预训练生成模型时，这些方法将模型输出与一个可能不存在的真实标准进行比较，或者涉及到不切实际的计算量。我们提出了一种基于神经网络编码熵的替代方法，用于比较图像集合之间的多样性，而无需真实标准知识且易于计算。我们还比较了两个预训练网络，并展示了选择如何与我们想要评估的多样性概念相关联。最后我们讨论了这些测量方法在交互式系统的构思、模型评估以及其他应用领域中的潜在应用。

    arXiv:2403.13826v1 Announce Type: cross  Abstract: Quality and diversity have been proposed as reasonable heuristics for assessing content generated by co-creative systems, but to date there has been little agreement around what constitutes the latter or how to measure it. Proposed approaches for assessing generative models in terms of diversity have limitations in that they compare the model's outputs to a ground truth that in the era of large pre-trained generative models might not be available, or entail an impractical number of computations. We propose an alternative based on entropy of neural network encodings for comparing diversity between sets of images that does not require ground-truth knowledge and is easy to compute. We also compare two pre-trained networks and show how the choice relates to the notion of diversity that we want to evaluate. We conclude with a discussion of the potential applications of these measures for ideation in interactive systems, model evaluation, an
    
[^139]: 深层生成模型用于超高细粒度粒子物理探测器模拟：从仿真到外推的航程

    Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation

    [https://arxiv.org/abs/2403.13825](https://arxiv.org/abs/2403.13825)

    该论文提出了一种新的几何感知生成模型IEA-GAN，以及一种迎接下游物理分析挑战的YonedaVAE模型，为超高细粒度粒子物理探测器模拟提供了重要的解决方案。

    

    在粒子物理中模拟超高细粒度探测器响应是一项至关重要但计算量巨大的任务。本论文旨在为Belle II实验的Pixel Vertex Detector (PXD) 克服这一挑战，该实验具有超过750万像素通道-是有史以来使用生成模型分析的空间分辨率最高的探测器模拟数据集。论文首先对用于模拟探测器特征的生成模型进行了全面和分类学的回顾。然后，提出了具有几何感知的新型生成模型"Intra-Event Aware Generative Adversarial Network (IEA-GAN)"，引入关系式注意推理和自监督学习来近似探测器中的"事件"。该研究强调了对下游物理分析而言“事件内关联”的重要性。在此基础上，研究朝着更通用的方法迈进，并提出了YonedaVAE，这是受范畴论启发的一种模型

    arXiv:2403.13825v1 Announce Type: cross  Abstract: Simulating ultra-high-granularity detector responses in Particle Physics represents a critical yet computationally demanding task. This thesis aims to overcome this challenge for the Pixel Vertex Detector (PXD) at the Belle II experiment, which features over 7.5M pixel channels-the highest spatial resolution detector simulation dataset ever analysed with generative models. This thesis starts off by a comprehensive and taxonomic review on generative models for simulating detector signatures. Then, it presents the Intra-Event Aware Generative Adversarial Network (IEA-GAN), a new geometry-aware generative model that introduces a relational attentive reasoning and Self-Supervised Learning to approximate an "event" in the detector. This study underscores the importance of intra-event correlation for downstream physics analyses. Building upon this, the work drifts towards a more generic approach and presents YonedaVAE, a Category Theory-insp
    
[^140]: 用投篮风格和进攻角色对篮球球员进行聚类的进攻阵容分析

    Offensive Lineup Analysis in Basketball with Clustering Players Based on Shooting Style and Offensive Role

    [https://arxiv.org/abs/2403.13821](https://arxiv.org/abs/2403.13821)

    本研究通过使用投篮风格聚类和基于注释的进攻角色聚类，更专门地分析了比赛风格兼容性对得分效率的影响，集中在进攻端。

    

    在篮球比赛中，得分效率由于每场比赛中的大量进攻次数而显得非常重要。提高得分效率需要球员之间具有不同比赛风格的有效协作。以往的研究中，曾对篮球阵容进行分析，但它们的比赛风格兼容性尚未得到量化检验。本研究的目的是更具体地分析比赛风格兼容性对得分效率的影响，重点放在进攻端。本研究采用两种方法来捕捉球员在进攻端的比赛风格：利用跟踪数据进行投篮风格聚类，以及基于注释的比赛类型和高级统计数据进行进攻角色聚类。对于前者，利用可解释的手工制作的投篮特征和投篮风格分布之间的Wasserstein距离。对于后者，首次将软聚类应用于比赛类型数据。

    arXiv:2403.13821v1 Announce Type: new  Abstract: In a basketball game, scoring efficiency holds significant importance due to the numerous offensive possessions per game. Enhancing scoring efficiency necessitates effective collaboration among players with diverse playing styles. In previous studies, basketball lineups have been analyzed, but their playing style compatibility has not been quantitatively examined. The purpose of this study is to analyze more specifically the impact of playing style compatibility on scoring efficiency, focusing only on offense. This study employs two methods to capture the playing styles of players on offense: shooting style clustering using tracking data, and offensive role clustering based on annotated playtypes and advanced statistics. For the former, interpretable hand-crafted shot features and Wasserstein distances between shooting style distributions were utilized. For the latter, soft clustering was applied to playtype data for the first time. Subs
    
[^141]: 基于人类磁心图信号的身份信息

    Identity information based on human magnetocardiography signals

    [https://arxiv.org/abs/2403.13820](https://arxiv.org/abs/2403.13820)

    该研究开发了一个基于人类磁心图信号的个人识别系统，利用空间信息和CNN分类技术，取得了97.04%的准确率。

    

    我们开发了一个基于使用光抽运磁强计（OPMs）捕获的磁心图（MCG）信号的个人识别系统。我们的系统利用模式识别分析不同部位获取的信号，通过在由MCG信号组成的矩阵上使用2*2窗口进行扫描。为了利用MCG信号的空间信息，我们将邻近小区域的信号转换为数据集的四个通道。我们进一步使用小波变换将数据转换为时频矩阵，并采用卷积神经网络（CNN）进行分类。结果表明，我们的系统在辨认个人方面的准确率达到了97.04%。这一发现表明MCG信号具有潜力用于个人识别系统，为个性化健康管理提供了有价值的工具。

    arXiv:2403.13820v1 Announce Type: new  Abstract: We have developed an individual identification system based on magnetocardiography (MCG) signals captured using optically pumped magnetometers (OPMs). Our system utilizes pattern recognition to analyze the signals obtained at different positions on the body, by scanning the matrices composed of MCG signals with a 2*2 window. In order to make use of the spatial information of MCG signals, we transform the signals from adjacent small areas into four channels of a dataset. We further transform the data into time-frequency matrices using wavelet transforms and employ a convolutional neural network (CNN) for classification. As a result, our system achieves an accuracy rate of 97.04% in identifying individuals. This finding indicates that the MCG signal holds potential for use in individual identification systems, offering a valuable tool for personalized healthcare management.
    
[^142]: 一种利用机器学习方法通过意大利高中学生的高中背景预测大学录取选择

    A machine learning approach to predict university enrolment choices through students' high school background in Italy

    [https://arxiv.org/abs/2403.13819](https://arxiv.org/abs/2403.13819)

    通过意大利高中学生的高中背景来预测大学录取选择，研究发现高中成就对录取选择有显著影响。

    

    本文探讨了意大利高中学生在数学和意大利语方面的熟练程度对其大学录取选择的影响，特别关注STEM（科学、技术、工程和数学）课程。我们区分了高中科学和人文背景的学生，为他们的录取偏好提供了宝贵的见解。此外，我们研究了不同性别在对类似先前教育选择和成就的反应方面可能存在的差异。研究采用了梯度增强方法，以其高预测性能和捕捉数据中非线性关系的能力而闻名，并调整了与学生的社会人口特征和先前教育成就相关的变量。我们的分析揭示了基于先前高中成就的录取选择中存在着显著差异。这些发现揭示了

    arXiv:2403.13819v1 Announce Type: new  Abstract: This paper explores the influence of Italian high school students' proficiency in mathematics and the Italian language on their university enrolment choices, specifically focusing on STEM (Science, Technology, Engineering, and Mathematics) courses. We distinguish between students from scientific and humanistic backgrounds in high school, providing valuable insights into their enrolment preferences. Furthermore, we investigate potential gender differences in response to similar previous educational choices and achievements. The study employs gradient boosting methodology, known for its high predicting performance and ability to capture non-linear relationships within data, and adjusts for variables related to the socio-demographic characteristics of the students and their previous educational achievements. Our analysis reveals significant differences in the enrolment choices based on previous high school achievements. The findings shed li
    
[^143]: 自主微型ARPES

    Autonomous microARPES

    [https://arxiv.org/abs/2403.13815](https://arxiv.org/abs/2403.13815)

    使用高斯过程回归，实现了自主搜索$\mathbf{k}$和实空间，以在微型ARPES实验中找到感兴趣位置。

    

    角分辨光电发射光谱学（ARPES）是一种用于映射固体材料占据态电子结构的技术。X射线聚焦光学的最新进展导致ARPES发展为一种微观工具，允许空间映射样品表面上的电子结构。这是以耗时的扫描过程为代价的，不仅要覆盖三维能量-动量（$E, k_z, k_y$）空间，还要覆盖二维表面积。在这里，我们实现了一个协议，可以自主搜索$\mathbf{k}$和实空间，以找到特定位置，无论是因为其高光电发射强度还是因为尖锐的光谱特征。该搜索基于高斯过程回归，可以轻松扩展以包括额外的参数或优化标准。该自主实验控制已在SGM4微聚焦系统上实现。

    arXiv:2403.13815v1 Announce Type: cross  Abstract: Angle-resolved photoemission spectroscopy (ARPES) is a technique used to map the occupied electronic structure of solids. Recent progress in X-ray focusing optics has led to the development of ARPES into a microscopic tool, permitting the electronic structure to be spatially mapped across the surface of a sample. This comes at the expense of a time-consuming scanning process to cover not only a three-dimensional energy-momentum ($E, k_z, k_y$) space but also the two-dimensional surface area. Here, we implement a protocol to autonomously search both $\mathbf{k}$- and real space in order to find positions of particular interest, either because of their high photoemission intensity or because of sharp spectral features. The search is based on the use of Gaussian process regression and can easily be expanded to include additional parameters or optimisation criteria. This autonomous experimental control is implemented on the SGM4 micro-focu
    
[^144]: AI生成文本在学术研究中的定量分析：利用AI检测工具研究Arxiv投稿中的AI存在性

    Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool

    [https://arxiv.org/abs/2403.13812](https://arxiv.org/abs/2403.13812)

    论文研究了一种能够检测Arxiv投稿中AI成分的方法，使用物理、数学和计算机科学文章创建数据集，并通过Originality.ai进行分析，准确率达到98%。

    

    许多人对ChatGPT感兴趣，因为它已成为一个突出的AIGC模型，可以在各种情境下提供高质量的响应，如软件开发和维护。ChatGPT的误用可能引起重大问题，特别是在公共安全和教育领域，尽管其有巨大潜力。研究人员大多选择在Arxiv上发表他们的作品。未来工作的有效性和独创性取决于在这些贡献中检测到AI组件的能力。为了满足这一需求，本研究将分析一种方法，可以查看学术机构用于在Arxiv上发布的刻意制造的内容。为了进行这项研究，使用了物理、数学和计算机科学文章创建了一个数据集。利用新建立的数据集，接下来的步骤是将originality.ai投入使用。统计分析显示，Originality.ai非常精准，准确率达到98%。

    arXiv:2403.13812v1 Announce Type: cross  Abstract: Many people are interested in ChatGPT since it has become a prominent AIGC model that provides high-quality responses in various contexts, such as software development and maintenance. Misuse of ChatGPT might cause significant issues, particularly in public safety and education, despite its immense potential. The majority of researchers choose to publish their work on Arxiv. The effectiveness and originality of future work depend on the ability to detect AI components in such contributions. To address this need, this study will analyze a method that can see purposely manufactured content that academic organizations use to post on Arxiv. For this study, a dataset was created using physics, mathematics, and computer science articles. Using the newly built dataset, the following step is to put originality.ai through its paces. The statistical analysis shows that Originality.ai is very accurate, with a rate of 98%.
    
[^145]: PyVRP: 一个高性能的VRP求解器包

    PyVRP: a high-performance VRP solver package

    [https://arxiv.org/abs/2403.13795](https://arxiv.org/abs/2403.13795)

    PyVRP是一个实现混合遗传搜索作为最先进的车辆路径问题（VRP）求解器的Python包，在多个竞赛中取得了第一名，结合了Python的灵活性和C++的性能，代码质量高且在VRPTW和有容量限制的VRP问题上达到了最好的结果。

    

    我们介绍了PyVRP，一个实现混合遗传搜索作为最先进的车辆路径问题（VRP）求解器的Python包。该包旨在用于带有时间窗口（VRPTW）的VRP，但可以轻松扩展以支持其他VRP变体。PyVRP结合了Python的灵活性和C++的性能，通过在C++中实现算法的性能关键部分，同时在Python级别全面定制化。PyVRP是该算法的一个完善实现，在2021年DIMACS VRPTW挑战赛中名列第一，在改进后，在2022年EURO Meets NeurIPS车辆路径竞赛的静态变体上名列第一。该代码遵循良好的软件工程实践，并且有着良好的文档和单元测试。PyVRP在自由的MIT许可证下免费提供。通过数值实验，我们展示PyVRP在VRPTW和有容量限制的VRP上实现了最先进的结果。

    arXiv:2403.13795v1 Announce Type: cross  Abstract: We introduce PyVRP, a Python package that implements Hybrid Genetic Search as a state-of-the-art Vehicle Routing Problem (VRP) solver. The package is designed for the VRP with Time Windows (VRPTW), but can be easily extended to support other VRP variants. PyVRP combines the flexibility of Python with the performance of C++, by implementing (only) performance critical parts of the algorithm in C++, while being fully customisable at the Python level. PyVRP is a polished implementation of the algorithm that ranked 1st in the 2021 DIMACS VRPTW Challenge and, after improvements, ranked 1st on the static variant of the EURO Meets NeurIPS 2022 Vehicle Routing Competition. The code follows good software engineering practices, and is well-documented and unit tested. PyVRP is freely available under the liberal MIT license. Through numerical experiments we show that PyVRP achieves state-of-the-art results on the VRPTW and Capacitated VRP. We hope
    
[^146]: 在自动控制系统中的对抗性攻击与防御：一项综合基准研究

    Adversarial Attacks and Defenses in Automated Control Systems: A Comprehensive Benchmark

    [https://arxiv.org/abs/2403.13502](https://arxiv.org/abs/2403.13502)

    该研究通过评估在自动控制系统中部署的深度学习模型对抗性攻击的脆弱性和不同防御策略的有效性，提出了结合多种防御方法的新颖保护方法，并为确保工业中的稳健故障诊断提供了见解。

    

    将机器学习整合到自动控制系统（ACS）中增强了工业过程管理的决策能力。其中一项限制工业普遍采用这些技术的是神经网络对对抗性攻击的脆弱性。本研究探讨了使用Tennessee Eastman过程数据集在ACS中部署深度学习模型进行故障诊断时的威胁。通过评估三种不同架构的神经网络，我们对其进行了六种对抗性攻击，并探讨了五种不同的防御方法。我们的结果突出了模型对对抗性样本的强大脆弱性以及防御策略的不同有效性。我们还提出了一种新颖的保护方法，将多种防御方法结合起来，并展示了其有效性。这项研究对确保工业中机器学习的安全性提供了一些见解，确保了工业中稳健的故障诊断。

    arXiv:2403.13502v1 Announce Type: new  Abstract: Integrating machine learning into Automated Control Systems (ACS) enhances decision-making in industrial process management. One of the limitations to the widespread adoption of these technologies in industry is the vulnerability of neural networks to adversarial attacks. This study explores the threats in deploying deep learning models for fault diagnosis in ACS using the Tennessee Eastman Process dataset. By evaluating three neural networks with different architectures, we subject them to six types of adversarial attacks and explore five different defense methods. Our results highlight the strong vulnerability of models to adversarial samples and the varying effectiveness of defense strategies. We also propose a novel protection approach by combining multiple defense methods and demonstrate it's efficacy. This research contributes several insights into securing machine learning within ACS, ensuring robust fault diagnosis in industrial 
    
[^147]: Arcee的MergeKit：用于合并大型语言模型的工具包

    Arcee's MergeKit: A Toolkit for Merging Large Language Models

    [https://arxiv.org/abs/2403.13257](https://arxiv.org/abs/2403.13257)

    合并不同语言模型的参数，无需额外训练即可创建多任务模型，提升模型性能和多功能性，解决AI中的复杂挑战。

    

    开源语言模型领域的快速扩张为通过合并其参数来结合这些模型检查点的能力提供了机会。迁移学习的进步导致了大量针对特定任务进行微调的模型的开发，这些模型通常专门针对个别任务进行专门化，无法利用彼此的优势。模型合并促进了多任务模型的创建，无需额外的训练，为增强模型性能和多功能性提供了一个有前途的途径。通过保留原始模型的固有能力，模型合并解决了人工智能中的复杂挑战，包括灾难性遗忘和多任务学习的困难。为了支持这一不断扩大的研究领域，我们介绍了MergeKit，这是一个全面的、开源的库，旨在促进模型合并的应用。

    arXiv:2403.13257v1 Announce Type: new  Abstract: The rapid expansion of the open-source language model landscape presents an opportunity to merge the competencies of these model checkpoints by combining their parameters. Advances in transfer learning, the process of fine-tuning pre-trained models for specific tasks, has resulted in the development of vast amounts of task-specific models, typically specialized in individual tasks and unable to utilize each other's strengths. Model merging facilitates the creation of multitask models without the need for additional training, offering a promising avenue for enhancing model performance and versatility. By preserving the intrinsic capabilities of the original models, model merging addresses complex challenges in AI - including the difficulties of catastrophic forgetting and multi-task learning. To support this expanding area of research, we introduce MergeKit, a comprehensive, open-source library designed to facilitate the application of mo
    
[^148]: 从表现性伤害到服务质量伤害:羊驼2安全保障的案例研究

    From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards

    [https://arxiv.org/abs/2403.13213](https://arxiv.org/abs/2403.13213)

    本文探讨了针对表现性伤害和服务质量伤害的羊驼2安全保障措施的有效性，并指出了大型语言模型在实用性和安全性之间的权衡关系。

    

    近期大型语言模型（LLM）的进展导致它们在各个领域被广泛采用。然而，这些进步也引入了额外的安全风险，并引发了对其对已经边缘化人群的不利影响的担忧。尽管存在越来越多的减轻措施来开发安全保障措施，比如监督式的安全定向微调和利用来自人类反馈的安全强化学习，但关于这些模型的安全性和内在偏见仍存在多重关注。此外，先前的研究已经证明，为了安全而优化的模型通常会展示夸大的安全行为，比如出于预防措施而倾向于不回应某些请求。因此，文献中已经记录了这些模型在实用性和安全性之间的明显权衡。在本文中，我们进一步研究了安全措施的有效性，通过评估...

    arXiv:2403.13213v1 Announce Type: cross  Abstract: Recent progress in large language models (LLMs) has led to their widespread adoption in various domains. However, these advancements have also introduced additional safety risks and raised concerns regarding their detrimental impact on already marginalized populations. Despite growing mitigation efforts to develop safety safeguards, such as supervised safety-oriented fine-tuning and leveraging safe reinforcement learning from human feedback, multiple concerns regarding the safety and ingrained biases in these models remain. Furthermore, previous work has demonstrated that models optimized for safety often display exaggerated safety behaviors, such as a tendency to refrain from responding to certain requests as a precautionary measure. As such, a clear trade-off between the helpfulness and safety of these models has been documented in the literature. In this paper, we further investigate the effectiveness of safety measures by evaluatin
    
[^149]: FlowerFormer: 使用基于流感知的图变换器增强神经结构编码

    FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer

    [https://arxiv.org/abs/2403.12821](https://arxiv.org/abs/2403.12821)

    FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。

    

    特定神经网络架构的成功与其处理的数据集和任务密切相关；没有一种适合所有情况的解决方案。因此，人们付出了大量努力，以快速准确地估计神经结构在特定任务和数据集上的表现，而无需进行完整的训练或评估。神经结构编码在估计中起着至关重要的作用，而将架构视为图的基于图的方法表现出色。为了增强神经结构的表征学习，我们介绍了FlowerFormer，一种强大的图变换器，它融入了神经结构内的信息流。 FlowerFormer由两个关键组件组成：（a）受流程启发的双向异步消息传递；（b）建立在基于流程的掩码上的全局关注。我们广泛的实验表明，FlowerFormer优于现有神经结构。

    arXiv:2403.12821v1 Announce Type: cross  Abstract: The success of a specific neural network architecture is closely tied to the dataset and task it tackles; there is no one-size-fits-all solution. Thus, considerable efforts have been made to quickly and accurately estimate the performances of neural architectures, without full training or evaluation, for given tasks and datasets. Neural architecture encoding has played a crucial role in the estimation, and graphbased methods, which treat an architecture as a graph, have shown prominent performance. For enhanced representation learning of neural architectures, we introduce FlowerFormer, a powerful graph transformer that incorporates the information flows within a neural architecture. FlowerFormer consists of two key components: (a) bidirectional asynchronous message passing, inspired by the flows; (b) global attention built on flow-based masking. Our extensive experiments demonstrate the superiority of FlowerFormer over existing neural 
    
[^150]: 成本敏感学习在考虑工作量约束下推迟多位专家决策

    Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints

    [https://arxiv.org/abs/2403.06906](https://arxiv.org/abs/2403.06906)

    提出了成本和工作量约束下的推迟框架（DeCCaF），旨在解决成本敏感场景、并发预测和人类工作能力约束等问题

    

    学习推迟（L2D）旨在通过学习如何在人工智能协作系统中将决策推迟给人类，从而在人类更有可能正确时推迟决策。现有L2D研究忽视了阻碍其实际采用的真实系统的关键方面，即：忽视成本敏感场景，其中第1类和第2类错误的成本不同；要求每个训练数据集实例的并发人类预测；不处理人类工作能力约束。为了解决这些问题，我们提出了成本和工作量约束下的推迟框架（DeCCaF）。DeCCaF是一种新颖的L2D方法，采用监督学习来建模人类错误的概率，减少数据要求的限制，并使用约束编程来全局最小化错误成本，同时考虑工作量限制。我们在一个系列中测试了DeCCaF

    arXiv:2403.06906v1 Announce Type: cross  Abstract: Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key aspects of real-world systems that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type 1 and type 2 errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset and iii) not dealing with human work capacity constraints. To address these issues, we propose the deferral under cost and capacity constraints framework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost subject to workload limitations. We test DeCCaF in a series 
    
[^151]: 非洲沙漠蝗虫繁殖地预测的地理空间方法

    A Geospatial Approach to Predicting Desert Locust Breeding Grounds in Africa

    [https://arxiv.org/abs/2403.06860](https://arxiv.org/abs/2403.06860)

    该研究开发了一个地理空间模型，用于预测沙漠蝗虫的繁殖地，有望提升早期预警系统和有针对性的控制措施。

    

    沙漠蝗虫成群成队对农业和食品安全构成重大威胁。本研究针对这一挑战，开发了一个可操作的模型，用于预测蝗虫的繁殖地，有望增强早期预警系统和有针对性的控制措施。我们从联合国粮食和农业组织(UN-FAO)的蝗虫观测记录中整理了一个数据集，并使用两种类型的时空输入特征进行分析：遥感环境和气候数据，以及多光谱地球观测图像。我们的方法采用定制的深度学习模型(三维和基于LSTM的循环卷积网络)，以及Jakubik等人于2023年最新发布的地理空间基础模型Prithvi。这些模型显著优于现有基准线，基于Prithvi的模型，通过对来自NASA的谐调Landsat和哨兵-2(HLS)多光谱图像进行微调而表现出色。

    arXiv:2403.06860v1 Announce Type: new  Abstract: Desert locust swarms present a major threat to agriculture and food security. Addressing this challenge, our study develops an operationally-ready model for predicting locust breeding grounds, which has the potential to enhance early warning systems and targeted control measures. We curated a dataset from the United Nations Food and Agriculture Organization's (UN-FAO) locust observation records and analyzed it using two types of spatio-temporal input features: remotely-sensed environmental and climate data as well as multi-spectral earth observation images. Our approach employed custom deep learning models (three-dimensional and LSTM-based recurrent convolutional networks), along with the geospatial foundational model Prithvi recently released by Jakubik et al., 2023. These models notably outperformed existing baselines, with the Prithvi-based model, fine-tuned on multi-spectral images from NASA's Harmonized Landsat and Sentinel-2 (HLS) 
    
[^152]: 揭开缩放定律之谜：第一部分

    Unraveling the Mystery of Scaling Laws: Part I

    [https://arxiv.org/abs/2403.06563](https://arxiv.org/abs/2403.06563)

    确认缩放定律原则在模型预训练中的重要作用，揭示OpenAI原始缩放定律论文的不完整细节，并探究预测测试损失轨迹可靠公式的挑战

    

    缩放定律原则表明在模型大小、数据集大小和训练过程中使用的计算资源等变量之间存在幂定律相关性。这些原则在优化模型预训练的各个方面中起着至关重要的作用，最终有助于大型语言模型（如GPT-4、Llama和Gemini）的成功。然而，OpenAI的原始缩放定律论文并未披露推导精确缩放定律公式所必需的完整细节，他们的结论仅基于包含高达15亿参数的模型。尽管一些后续作品试图揭示这些细节并扩展到更大的模型，但它们经常忽略了重要因素的训练依赖性，如学习速率、上下文长度和批量大小，导致它们未能建立一个可靠的预测测试损失轨迹的公式。在本技术报告中，我们确认了缩放

    arXiv:2403.06563v1 Announce Type: cross  Abstract: Scaling law principles indicate a power-law correlation between loss and variables such as model size, dataset size, and computational resources utilized during training. These principles play a vital role in optimizing various aspects of model pre-training, ultimately contributing to the success of large language models such as GPT-4, Llama and Gemini. However, the original scaling law paper by OpenAI did not disclose the complete details necessary to derive the precise scaling law formulas, and their conclusions are only based on models containing up to 1.5 billion parameters. Though some subsequent works attempt to unveil these details and scale to larger models, they often neglect the training dependency of important factors such as the learning rate, context length and batch size, leading to their failure to establish a reliable formula for predicting the test loss trajectory. In this technical report, we confirm that the scaling 
    
[^153]: MedMamba: 用于医学图像分类的Vision Mamba

    MedMamba: Vision Mamba for Medical Image Classification

    [https://arxiv.org/abs/2403.03849](https://arxiv.org/abs/2403.03849)

    提出了Vision Mamba用于医学图像分类，结合了卷积层的局部特征提取能力和SSM捕捉长距离依赖性的能力。

    

    医学图像分类是计算机视觉领域中非常基础和关键的任务。近年来，基于CNN和Transformer的模型被广泛应用于分类各种医学图像。不幸的是，CNN在长距离建模能力方面存在局限，无法有效提取医学图像中的细粒度特征，而Transformers受到二次计算复杂度的阻碍。最近的研究表明，由Mamba表示的状态空间模型（SSM）可以高效地建模长距离交互作用同时保持线性计算复杂度。受此启发，我们提出了用于医学图像分类的Vision Mamba（MedMamba）。更具体地，我们引入了一个新颖的Conv-SSM模块，将卷积层的局部特征提取能力与SSM捕捉长距离依赖性的能力结合在一起。为了展示MedMamba的潜力，我们进行了

    arXiv:2403.03849v1 Announce Type: cross  Abstract: Medical image classification is a very fundamental and crucial task in the field of computer vision. These years, CNN-based and Transformer-based models are widely used in classifying various medical images. Unfortunately, The limitation of CNNs in long-range modeling capabilities prevent them from effectively extracting fine-grained features in medical images , while Transformers are hampered by their quadratic computational complexity. Recent research has shown that the state space model (SSM) represented by Mamba can efficiently model long-range interactions while maintaining linear computational complexity. Inspired by this, we propose Vision Mamba for medical image classification (MedMamba). More specifically, we introduce a novel Conv-SSM module, which combines the local feature extraction ability of convolutional layers with the ability of SSM to capture long-range dependency. To demonstrate the potential of MedMamba, we conduct
    
[^154]: 超越专业化：评估MLLMs在年龄和性别估计中的能力

    Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation

    [https://arxiv.org/abs/2403.02302](https://arxiv.org/abs/2403.02302)

    本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。

    

    最近，多模态大型语言模型（MLLMs）变得异常流行。像ChatGPT-4V和Gemini这样功能强大的商用模型，以及像LLaVA这样的开源模型，本质上都是通用模型，应用于解决各种各样的任务，包括计算机视觉中的任务。这些神经网络具有如此强大的通用知识和推理能力，以至于它们已被证明能够处理甚至未经专门训练的任务。我们将迄今为止最强大的MLLMs的能力进行了比较：ShareGPT4V、ChatGPT、LLaVA-Next 进行了专门任务的年龄和性别估计，与我们的最新专业化模型MiVOLO进行了比较。我们还更新了MiVOLO，并在本文中提供了详细信息和新的指标。这种比较产生了一些有趣的结果和关于参与模型的优点和缺点的见解。此外，我们尝试了各种微调方法

    arXiv:2403.02302v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune 
    
[^155]: OSCaR:对象状态字幕和状态变化表示

    OSCaR: Object State Captioning and State Change Representation

    [https://arxiv.org/abs/2402.17128](https://arxiv.org/abs/2402.17128)

    本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。

    

    arXiv:2402.17128v3 公告类型: 跨 面向人类在真实世界环境中的交互视角，智能模型推断和理解对象状态的变化能力是人工智能研究的一个重要且具有挑战性的方面。该任务涉及描述复杂的视觉环境，识别活跃对象，以及通过语言解释它们的变化。传统方法将对象字幕和状态变化检测进行隔离，提供了对动态环境的有限视图。此外，依赖于一小套符号化词汇来表示变化限制了语言的表达力。为了解决这些挑战，在本文中，我们介绍了对象状态字幕和状态变化表示（OSCaR）数据集和基准。OSCaR包括来自各种主观视角视频集合的14,084个带注释视频片段，涵盖近1,000个独特对象。它为评估多模态大型语言提供了一个新的实验平台。

    arXiv:2402.17128v3 Announce Type: cross  Abstract: The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of the language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large langua
    
[^156]: 基于AI的精准肿瘤学：基于多组学数据的个性化反事实治疗建议的机器学习框架

    Towards AI-Based Precision Oncology: A Machine Learning Framework for Personalized Counterfactual Treatment Suggestions based on Multi-Omics Data

    [https://arxiv.org/abs/2402.12190](https://arxiv.org/abs/2402.12190)

    提出了一种基于机器学习的框架，用于个性化反事实癌症治疗建议，集成了多种多组学技术的专家，可提供优越性能和决策解释。

    

    AI驱动的精准肿瘤学具有通过利用AI模型分析复杂患者特征与对应治疗结果之间互动的潜力，有望重塑癌症治疗。新技术平台促进了及时获取多模态肿瘤生物学数据，如单细胞多组学数据，使得这种数据的质量和数量可用于数据驱动的改进临床决策。本文提出了一个模块化的机器学习框架，旨在基于训练有关多种多组学技术的机器学习专家组成的集成来进行个性化反事实癌症治疗建议。这些专门的反事实专家根据技术不断聚合为性能更优越的专家，可提供决策的置信度和解释。

    arXiv:2402.12190v1 Announce Type: cross  Abstract: AI-driven precision oncology has the transformative potential to reshape cancer treatment by leveraging the power of AI models to analyze the interaction between complex patient characteristics and their corresponding treatment outcomes. New technological platforms have facilitated the timely acquisition of multimodal data on tumor biology at an unprecedented resolution, such as single-cell multi-omics data, making this quality and quantity of data available for data-driven improved clinical decision-making. In this work, we propose a modular machine learning framework designed for personalized counterfactual cancer treatment suggestions based on an ensemble of machine learning experts trained on diverse multi-omics technologies. These specialized counterfactual experts per technology are consistently aggregated into a more powerful expert with superior performance and can provide both confidence and an explanation of its decision. The
    
[^157]: 关于带有高斯噪声的选择机制的隐私问题

    On the Privacy of Selection Mechanisms with Gaussian Noise

    [https://arxiv.org/abs/2402.06137](https://arxiv.org/abs/2402.06137)

    该论文研究了带有高斯噪声的选择机制的隐私问题，并证明了在底层查询是有界的情况下，可以提供纯粹的前期和后期差分隐私界限。

    

    报告噪声最大值和阈值以上是两个经典的差分隐私(DP)选择机制。它们的输出是通过对一系列低灵敏度的查询添加噪声，并报告满足某个条件的查询(噪声的)答案的身份来获得的。当在查询上添加拉普拉斯噪声时，这些机制的纯DP保证很容易获得。另一方面，当使用高斯噪声实例化时，标准分析只能提供近似的DP保证，尽管这些机制的输出位于离散空间中。在这项工作中，我们重新审视了使用高斯噪声的报告噪声最大值和阈值以上的分析，并展示了在额外的假设下，即底层查询是有界的情况下，可以为报告噪声最大值提供纯粹的前期DP界限，以及为阈值以上提供纯粹的后期DP界限。得到的界限是紧密的，并且依赖于可以使用标准元方法数值评估的闭式表达式。

    Report Noisy Max and Above Threshold are two classical differentially private (DP) selection mechanisms. Their output is obtained by adding noise to a sequence of low-sensitivity queries and reporting the identity of the query whose (noisy) answer satisfies a certain condition. Pure DP guarantees for these mechanisms are easy to obtain when Laplace noise is added to the queries. On the other hand, when instantiated using Gaussian noise, standard analyses only yield approximate DP guarantees despite the fact that the outputs of these mechanisms lie in a discrete space. In this work, we revisit the analysis of Report Noisy Max and Above Threshold with Gaussian noise and show that, under the additional assumption that the underlying queries are bounded, it is possible to provide pure ex-ante DP bounds for Report Noisy Max and pure ex-post DP bounds for Above Threshold. The resulting bounds are tight and depend on closed-form expressions that can be numerically evaluated using standard met
    
[^158]: EasyInstruct：一个易于使用的用于大型语言模型的指令处理框架

    EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models

    [https://arxiv.org/abs/2402.03049](https://arxiv.org/abs/2402.03049)

    EasyInstruct是一个易于使用的用于大型语言模型的指令处理框架，通过模块化指令生成、选择和提示，并考虑它们的组合和交互，使指令处理更加方便和高效。

    

    近年来，指令调整已经引起了越来越多的关注，并成为增强大型语言模型（LLMs）能力的一种关键技术。为了构建高质量的指令数据集，已经提出了许多指令处理方法，旨在在数据数量和数据质量之间达到精巧的平衡。然而，由于各种指令处理方法之间仍然存在不一致，目前没有标准的开源指令处理实现框架可供社区使用，这使得从业者无法进一步开发和推进。为了促进指令处理的研究和开发，我们提出了EasyInstruct，一个易于使用的用于LLMs的指令处理框架，它将指令生成、选择和提示模块化，并考虑它们的组合和交互。EasyInstruct已经在https://github.com/zjunlp/EasyInstruct上公开发布，并得到了积极维护。

    In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along 
    
[^159]: DenseFormer: 通过深度加权平均增强Transformer中的信息流

    DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging

    [https://arxiv.org/abs/2402.02622](https://arxiv.org/abs/2402.02622)

    DenseFormer是对Transformer的简单修改，通过在每个transformer块之后进行深度加权平均，提高了模型的困惑度。学到的加权平均权重揭示了信息流的连贯模式，使得DenseFormer具有更高的数据效率，并且在相同困惑度下胜过传统的Transformer模型。

    

    从Vaswani等人（2017）的Transformer架构现已普遍应用于各个应用领域，从自然语言处理到语音处理和图像理解。我们提出了DenseFormer，这是对标准架构的简单修改，提高了模型的困惑度，而不增加其大小-对于拥有100B参数范围的大规模模型，只需添加几千个参数。我们的方法在每个transformer块之后依靠额外的平均步骤，计算当前和过去表示的加权平均-我们将这个操作称为深度加权平均（DWA）。学到的DWA权重展现了信息流的连贯模式，揭示了来自远层的激活的强大且结构化的重复使用。实验证明DenseFormer具有更高的数据效率，能够达到比更深的transformer模型相同的困惑度，并且在相同困惑度下，这些新模型在性能上超过了transformer基准模型。

    The transformer architecture from Vaswani et al. (2017) is now ubiquitous across application domains, from natural language processing to speech processing and image understanding. We propose DenseFormer, a simple modification to the standard architecture that improves the perplexity of the model without increasing its size -- adding a few thousand parameters for large-scale models in the 100B parameters range. Our approach relies on an additional averaging step after each transformer block, which computes a weighted average of current and past representations -- we refer to this operation as Depth-Weighted-Average (DWA). The learned DWA weights exhibit coherent patterns of information flow, revealing the strong and structured reuse of activations from distant layers. Experiments demonstrate that DenseFormer is more data efficient, reaching the same perplexity of much deeper transformer models, and that for the same perplexity, these new models outperform transformer baselines in terms
    
[^160]: SLIM: 多判别器在技能学习中的应用

    SLIM: Skill Learning with Multiple Critics

    [https://arxiv.org/abs/2402.00823](https://arxiv.org/abs/2402.00823)

    SLIM是一种多判别器学习方法，通过在机器人操作中组合多个判别器的奖励函数，显著改善了潜变量技能发现，克服了奖励之间的干扰。

    

    自我监督的技能学习旨在获取利用环境的底层动态的有用行为。基于互信息最大化的潜变量模型在此任务中取得了显著的成功，但在机器人操作领域仍存在困难。由于机器人操作可能涉及到环境中很多自由度，单纯的互信息最大化无法产生有用的操作行为。为了解决这个问题，我们引入了SLIM，一种针对机器人操作的多判别器学习方法。我们的主要观点是，在演员-评论者框架中利用多个判别器来优雅地组合多个奖励函数，能够显著改善机器人操作的潜变量技能发现，同时克服奖励之间可能发生的干扰，阻碍对有用技能的收敛。

    Self-supervised skill learning aims to acquire useful behaviors that leverage the underlying dynamics of the environment. Latent variable models, based on mutual information maximization, have been particularly successful in this task but still struggle in the context of robotic manipulation. As it requires impacting a possibly large set of degrees of freedom composing the environment, mutual information maximization fails alone in producing useful manipulation behaviors. To address this limitation, we introduce SLIM, a multi-critic learning approach for skill discovery with a particular focus on robotic manipulation. Our main insight is that utilizing multiple critics in an actor-critic framework to gracefully combine multiple reward functions leads to a significant improvement in latent-variable skill discovery for robotic manipulation while overcoming possible interference occurring among rewards which hinders convergence to useful skills. Furthermore, in the context of tabletop man
    
[^161]: 图编辑用于反事实解释：一项比较研究

    Graph Edits for Counterfactual Explanations: A comparative study

    [https://arxiv.org/abs/2401.11609](https://arxiv.org/abs/2401.11609)

    研究通过比较监督和无监督的图神经网络方法，扩展了图编辑作为反事实解释的先前努力，探讨了将输入数据表示为图形对于生成黑箱图像分类器最小且有意义的反事实解释的性能和时间效率最佳的方法。

    

    反事实已被确立为一种流行的可解释性技术，利用一组最小的编辑来改变分类器的预测。在考虑图像上的概念反事实时，请求的编辑应对应输入数据中存在的显著概念。同时，概念距离由知识图谱定义，确保概念编辑的最优性。在这项工作中，我们通过进行比较研究扩展了以图编辑为反事实解释的先前努力，在这项研究中涵盖了监督和无监督的图神经网络（GNN）方法。到此为止，我们提出了以下重要的研究问题：我们应该将输入数据表示为图形，这是生成黑箱图像分类器的最小和有意义的反事实解释在性能和时间效率方面最佳的GNN方法吗？

    arXiv:2401.11609v2 Announce Type: replace-cross  Abstract: Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?
    
[^162]: 金融领域中的合成数据应用

    Synthetic Data Applications in Finance

    [https://arxiv.org/abs/2401.00081](https://arxiv.org/abs/2401.00081)

    合成数据在金融领域的广泛应用，涉及各种不同数据类型，有助于解决隐私、公平性和可解释性相关问题，对其质量和效果进行了评估，并探讨了未来发展方向。

    

    合成数据在包括金融、医疗保健和虚拟现实在内的各种商业领域取得了巨大进展。本文概述了合成数据在金融领域的原型应用，并为其中的一些特定应用提供了更丰富的细节。这些应用涵盖了来自市场和零售金融应用的表格、时间序列、事件序列和非结构化数据模态的广泛数据类型。由于金融是一个受高度监管的行业，合成数据是处理与隐私、公平性和可解释性相关问题的一种潜在方法。在这些应用中，使用各种指标评估了我们方法的质量和有效性。最后，我们探讨了在金融领域合成数据的未来方向。

    arXiv:2401.00081v2 Announce Type: replace  Abstract: Synthetic data has made tremendous strides in various commercial settings including finance, healthcare, and virtual reality. We present a broad overview of prototypical applications of synthetic data in the financial sector and in particular provide richer details for a few select ones. These cover a wide variety of data modalities including tabular, time-series, event-series, and unstructured arising from both markets and retail financial applications. Since finance is a highly regulated industry, synthetic data is a potential approach for dealing with issues related to privacy, fairness, and explainability. Various metrics are utilized in evaluating the quality and effectiveness of our approaches in these applications. We conclude with open directions in synthetic data in the context of the financial domain.
    
[^163]: LLM外科医生

    The LLM Surgeon

    [https://arxiv.org/abs/2312.17244](https://arxiv.org/abs/2312.17244)

    通过数据驱动压缩现有预训练模型，我们提供了一个改进权重更新的通用框架，以更有效地捕捉更多权重之间的相关性，同时保持计算效率。

    

    最先进的语言模型越来越庞大，以期在大量可用的文本数据集上实现最佳性能。然而，Transformer架构的巨大规模使得在计算、环境或设备特定约束下部署模型变得困难。我们探讨了对现有预训练模型进行数据驱动压缩作为训练较小模型的替代方法。为此，我们将目标损失景观的Kronecker分解曲率近似扩展到大型语言模型中。通过这样做，我们既可以计算可删除结构的动态分配，也可以更新剩余权重以考虑删除。我们提供了一个通用框架，用于非结构化、半结构化和结构化修剪，并改进了权重更新以捕捉更多权重之间的相关性，同时保持计算效率。实验证明...

    arXiv:2312.17244v2 Announce Type: replace-cross  Abstract: State-of-the-art language models are becoming increasingly large in an effort to achieve the highest performance on large corpora of available textual data. However, the sheer size of the Transformer architectures makes it difficult to deploy models within computational, environmental or device-specific constraints. We explore data-driven compression of existing pretrained models as an alternative to training smaller models from scratch. To do so, we scale Kronecker-factored curvature approximations of the target loss landscape to large language models. In doing so, we can compute both the dynamic allocation of structures that can be removed as well as updates of remaining weights that account for the removal. We provide a general framework for unstructured, semi-structured and structured pruning and improve upon weight updates to capture more correlations between weights, while remaining computationally efficient. Experimental
    
[^164]: 关于损失和基于不确定性的主动学习算法的收敛性

    On the convergence of loss and uncertainty-based active learning algorithms

    [https://arxiv.org/abs/2312.13927](https://arxiv.org/abs/2312.13927)

    论文考虑了损失和不确定性基础的主动学习算法在线性分类器和线性可分数据集上的收敛速度，提出了一种新算法并展示了其效率。

    

    我们考虑了在不同假设下损失和基于不确定性的主动学习算法的收敛速度。首先，我们建立了一组条件，确保在应用于线性分类器和线性可分数据集时的收敛速度。这包括证明各种损失函数的基于损失的采样的收敛速度保证。其次，我们引入了一个框架，通过利用已知的随机梯度下降算法的收敛速率界限，使我们能够导出损失采样的收敛速率界限。最后，我们提出了一种新算法，将点采样和随机Polyak步长相结合。我们建立了一个关于采样过程的条件，确保该算法的收敛速度保证，特别是在光滑凸损失函数的情况下。我们的数值结果展示了所提出算法的效率。

    arXiv:2312.13927v2 Announce Type: replace-cross  Abstract: We consider the convergence rates of loss and uncertainty-based active learning algorithms under various assumptions. Firstly, we establish a set of conditions that ensure convergence rates when applied to linear classifiers and linearly separable datasets. This includes demonstrating convergence rate guarantees for loss-based sampling with various loss functions. Secondly, we introduce a framework that allows us to derive convergence rate bounds for loss-based sampling by leveraging known convergence rate bounds for stochastic gradient descent algorithms. Lastly, we propose a new algorithm that combines point sampling and stochastic Polyak's step size. We establish a condition on the sampling process, ensuring a convergence rate guarantee for this algorithm, particularly in the case of smooth convex loss functions. Our numerical results showcase the efficiency of the proposed algorithm.
    
[^165]: 适用于分析可穿戴设备、传感器和分布数据的可解释因果推断

    Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data

    [https://arxiv.org/abs/2312.10569](https://arxiv.org/abs/2312.10569)

    提出了一种适用于分布数据分析的可解释方法 ADD MALTS，有助于确保可靠和稳健的决策制定，能够优于其他方法估计处理效果

    

    许多现代因果问题都涉及到治疗如何影响通过可穿戴设备和传感器测量的复杂结果。当前的分析方法要求将这些数据汇总为标量统计数据（例如均值），但这些汇总可能具有误导性。研究人员可以通过将数据表示为分布来克服信息丢失问题。我们开发了一种适用于分布数据分析的可解释方法，确保了值得信赖和稳健的决策制定：通过学习拉伸后匹配的分布数据分析（ADD MALTS）。我们（i）提供了对我们估计策略正确性的分析保证，（ii）通过模拟表明ADD MALTS在估计处理效果方面优于其他分布数据分析方法，并（iii）展示了ADD MALTS验证是否存在比较

    arXiv:2312.10569v2 Announce Type: replace  Abstract: Many modern causal questions ask how treatments affect complex outcomes that are measured using wearable devices and sensors. Current analysis approaches require summarizing these data into scalar statistics (e.g., the mean), but these summaries can be misleading. For example, disparate distributions can have the same means, variances, and other statistics. Researchers can overcome the loss of information by instead representing the data as distributions. We develop an interpretable method for distributional data analysis that ensures trustworthy and robust decision-making: Analyzing Distributional Data via Matching After Learning to Stretch (ADD MALTS). We (i) provide analytical guarantees of the correctness of our estimation strategy, (ii) demonstrate via simulation that ADD MALTS outperforms other distributional data analysis methods at estimating treatment effects, and (iii) illustrate ADD MALTS' ability to verify whether there i
    
[^166]: 缩小差距：针对基于查询攻击实现更好的准确性-鲁棒性权衡

    Closing the Gap: Achieving Better Accuracy-Robustness Tradeoffs against Query-Based Attacks

    [https://arxiv.org/abs/2312.10132](https://arxiv.org/abs/2312.10132)

    本研究通过激活专门的防御措施，如随机噪声防御和随机图像变换，只针对低置信度的输入，在测试阶段实现了鲁棒性和准确性之间的有效权衡，从而改善了各种现有防御措施。

    

    尽管现有的防御措施对抗基于查询的攻击前景广阔，但它们存在一个共同的局限性：它们在提高对抗攻击鲁棒性的同时，会显著降低对干净样本的准确性。本文展示了如何在测试阶段有效建立鲁棒性和准确性之间的 solid tradeoff，以缓解基于查询攻击。考虑到这些攻击必然探索低置信区域，我们的观点是，仅针对低置信度的输入激活专门的防御措施，如随机噪声防御和随机图像变换，就足以阻止它们。我们的方法与训练无关，有理论支持。通过在CIFAR-10、CIFAR-100和ImageNet上进行大量实验，我们验证了我们的方法的有效性。我们的结果表明，我们的提议确实可以通过提供更好的鲁棒性和准确性之间的权衡，增强这些防御措施。

    arXiv:2312.10132v2 Announce Type: replace-cross  Abstract: Although promising, existing defenses against query-based attacks share a common limitation: they offer increased robustness against attacks at the price of a considerable accuracy drop on clean samples. In this work, we show how to efficiently establish, at test-time, a solid tradeoff between robustness and accuracy when mitigating query-based attacks. Given that these attacks necessarily explore low-confidence regions, our insight is that activating dedicated defenses, such as random noise defense and random image transformations, only for low-confidence inputs is sufficient to prevent them. Our approach is independent of training and supported by theory. We verify the effectiveness of our approach for various existing defenses by conducting extensive experiments on CIFAR-10, CIFAR-100, and ImageNet. Our results confirm that our proposal can indeed enhance these defenses by providing better tradeoffs between robustness and ac
    
[^167]: 加权集成模型是强大的持续学习者

    Weighted Ensemble Models Are Strong Continual Learners

    [https://arxiv.org/abs/2312.08977](https://arxiv.org/abs/2312.08977)

    通过加权集成模型实现了高准确性的持续学习，兼顾可塑性和稳定性。

    

    在本文中，我们研究持续学习（CL）的问题，其中目标是从一系列任务中学习模型，使得以前任务的数据在学习当前任务数据时不可用。CL本质上是在能够学习新任务（即可塑性）和保持先前学习概念的性能（即稳定性）之间取得平衡的过程。为了解决稳定性-可塑性的权衡问题，我们建议对先前和当前任务的模型参数进行加权集成。这种加权集成模型，我们称之为持续模型平均（或CoMA），通过利用可塑性在当前任务上获得高准确性，同时不会偏离太远的先前权重配置，从而确保稳定性。我们还提出了CoMA的改进型变体，名为持续费舍尔加权模型平均（或CoFiMA），该模型对每一个参数进行选择性加权。

    arXiv:2312.08977v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of continual learning (CL) where the goal is to learn a model on a sequence of tasks, such that the data from the previous tasks becomes unavailable while learning on the current task data. CL is essentially a balancing act between being able to learn on the new task (i.e., plasticity) and maintaining the performance on the previously learned concepts (i.e., stability). Intending to address the stability-plasticity trade-off, we propose to perform weight-ensembling of the model parameters of the previous and current tasks. This weighted-ensembled model, which we call Continual Model Averaging (or CoMA), attains high accuracy on the current task by leveraging plasticity, while not deviating too far from the previous weight configuration, ensuring stability. We also propose an improved variant of CoMA, named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively weighs each para
    
[^168]: 无监督视频域自适应：采用遮蔽预训练和协作自训练

    Unsupervised Video Domain Adaptation with Masked Pre-Training and Collaborative Self-Training

    [https://arxiv.org/abs/2312.02914](https://arxiv.org/abs/2312.02914)

    该方法提出了UNITE框架，利用图像教师模型和视频学生模型进行遮蔽预训练和协作自训练，在多个视频领域自适应基准上取得显著改进的结果。

    

    在这项工作中，我们解决了视频动作识别的无监督域自适应（UDA）问题。我们提出的方法称为UNITE，使用图像教师模型来调整视频学生模型到目标域。UNITE首先采用自监督预训练，通过教师引导的遮蔽蒸馏目标得到具有区分性的特征学习。然后我们对目标数据进行遮蔽自训练，利用视频学生模型和图像教师模型一起为未标记的目标视频生成改进的伪标签。我们的自训练过程成功利用了两个模型的优势，实现了跨域强大的转移性能。我们在多个视频域自适应基准上评估了我们的方法，并观察到相比先前报道的结果有显著改进。

    arXiv:2312.02914v3 Announce Type: replace-cross  Abstract: In this work, we tackle the problem of unsupervised domain adaptation (UDA) for video action recognition. Our approach, which we call UNITE, uses an image teacher model to adapt a video student model to the target domain. UNITE first employs self-supervised pre-training to promote discriminative feature learning on target domain videos using a teacher-guided masked distillation objective. We then perform self-training on masked target data, using the video student model and image teacher model together to generate improved pseudolabels for unlabeled target videos. Our self-training process successfully leverages the strengths of both models to achieve strong transfer performance across domains. We evaluate our approach on multiple video domain adaptation benchmarks and observe significant improvements upon previously reported results.
    
[^169]: 逆向学习：通过捡取学习放置

    Working Backwards: Learning to Place by Picking

    [https://arxiv.org/abs/2312.02352](https://arxiv.org/abs/2312.02352)

    通过逆向抓取过程并利用拾取和放置问题的对称性，提出了一种通过拾取的放置方法，并用自主收集的演示直接训练策略，实现在接触受限环境下物体放置任务的自主收集和泛化。

    

    我们提出了一种通过拾取（PvP）的放置方法，可以自主收集适用于一系列放置任务的现实世界演示，其中物体必须被操纵到特定的接触限制位置。通过PvP，我们通过颠倒抓取过程并利用拾取和放置问题固有的对称性，接近于机器人物体放置演示的收集。具体而言，我们从一组最初位于目标放置位置的物体的抓取序列中获得放置演示。我们的系统可以在接触受限环境中收集数百个演示，而无需人类干预，这是通过结合两个模块实现的：触觉重新抓取和用于抓取的顺从控制。我们通过行为克隆直接从视觉观察中通过自主收集的演示中训练策略。通过这样做，策略可以推广到超出训练环境范围的物体放置场景。

    arXiv:2312.02352v2 Announce Type: replace-cross  Abstract: We present placing via picking (PvP), a method to autonomously collect real-world demonstrations for a family of placing tasks in which objects must be manipulated to specific contact-constrained locations. With PvP, we approach the collection of robotic object placement demonstrations by reversing the grasping process and exploiting the inherent symmetry of the pick and place problems. Specifically, we obtain placing demonstrations from a set of grasp sequences of objects initially located at their target placement locations. Our system can collect hundreds of demonstrations in contact-constrained environments without human intervention by combining two modules: tactile regrasping and compliant control for grasps. We train a policy directly from visual observations through behavioral cloning, using the autonomously-collected demonstrations. By doing so, the policy can generalize to object placement scenarios outside of the tra
    
[^170]: LMM辅助的一致性嵌入下乳腺癌治疗目标分割

    LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding

    [https://arxiv.org/abs/2311.15876](https://arxiv.org/abs/2311.15876)

    RO-LMM是一个针对放射肿瘤学领域设计的多功能大型多模型，提出了一种Consistency Embedding Fine-Tuning（CEFTune）技术，使其能够在保持处理干净输入能力的同时提升对嘈杂输入的鲁棒性，用于放射治疗计划和目标体积分割。

    

    人工智能的最新进展深刻影响了医学领域，为降低临床工作量提供了工具。然而，大多数人工智能模型受限于执行单模式任务，与医学专业人员所使用的综合方法形成鲜明对比。为解决这一问题，本文介绍了RO-LMM，一个专为放射肿瘤学领域设计的多功能大型多模型（LMM）。该模型涵盖了临床工作流中的一系列任务，擅长临床报告摘要、放疗治疗计划建议和计划引导的目标体积分割。为了执行连续的临床任务，我们进一步提出了一种新颖的一致性嵌入微调（CEFTune）技术，提升了LMM对嘈杂输入的鲁棒性，同时保持了处理干净输入的能力，并将该概念转化为LMM驱动的分割框架，即一致性嵌入S。

    arXiv:2311.15876v2 Announce Type: replace-cross  Abstract: Recent advancements in Artificial Intelligence (AI) have profoundly influenced medical fields, by providing tools to reduce clinical workloads. However, most AI models are constrained to execute unimodal tasks, in stark contrast to the comprehensive approaches utilized by medical professionals. To address this, here we present RO-LMM, a multi-purpose large multimodal model (LMM) tailored for the field of radiation oncology. This model covers series of tasks within clinical workflow, adept at clinical report summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation. In particular, to perform consecutive clinical tasks, we further present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the capability of handling clean inputs, and transform this concept into LMM-driven segmentation framework as Consistency Embedding S
    
[^171]: 通过语言纠正提炼和检索机器人操作的通用知识

    Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections

    [https://arxiv.org/abs/2311.10678](https://arxiv.org/abs/2311.10678)

    本研究提出了一种基于大型语言模型的系统，名为DROC，能够回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进机器人操作的性能。

    

    今天的机器人政策在面对推广到新环境的挑战时表现不佳。人类的纠正反馈是一种至关重要的指导形式，可以实现这种泛化。然而，适应和从在线人类纠正中学习是一项不容易的任务：机器人不仅需要随时间记住人类的反馈以便在新环境中检索正确的信息并降低干涉率，而且还需要能够回应可能是关于高级人类偏好的任意纠正到技能参数的低级调整。在这项工作中，我们提出了基于大型语言模型(LLM)的在线纠正蒸馏和检索(DROC)系统，它可以回应任意形式的语言反馈，从纠正中提炼出通用知识，并根据文本和视觉相似性检索相关的过去经验，以改进性能。

    arXiv:2311.10678v2 Announce Type: replace-cross  Abstract: Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving p
    
[^172]: TD-MPC2：可扩展、稳健的连续控制世界模型

    TD-MPC2: Scalable, Robust World Models for Continuous Control

    [https://arxiv.org/abs/2310.16828](https://arxiv.org/abs/2310.16828)

    TD-MPC2是对TD-MPC算法的一系列改进，通过一组超参数在104个在线RL任务中取得了显著进展，成功训练单一的317M参数代理执行80个任务。

    

    TD-MPC是一种基于模型的强化学习（RL）算法，它在学习的隐式（无解码器）世界模型的潜在空间中执行局部轨迹优化。在这项工作中，我们展示了TD-MPC2：对TD-MPC算法的一系列改进。我们证明TD-MPC2在跨越4个不同任务领域的104个在线RL任务中显著改善了基线，通过一组超参数实现了持续强大的结果。我们进一步展示了随着模型和数据规模的增加，代理的能力也在增强，并成功训练了一个单一的317M参数代理，在多个任务领域、具象和动作空间中执行了80个任务。最后，我们总结了大型TD-MPC2代理所涉及的教训、机会和风险。在https://tdmpc2.com上探索视频、模型、数据、代码等。

    arXiv:2310.16828v2 Announce Type: replace-cross  Abstract: TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://tdmpc2.com
    
[^173]: 图排名对比学习：一种极其简单而高效的方法

    Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient Method

    [https://arxiv.org/abs/2310.14525](https://arxiv.org/abs/2310.14525)

    图对比学习（GCL）作为一种代表性的图自监督方法，提出了一种旨在减轻假阴性影响的极其简单而有效的方法。

    

    图对比学习（GCL）作为一种代表性的图自监督方法已经取得了显著的成功。目前普遍采用的GCL优化目标是InfoNCE。通常，它采用增强技术获得两个视图，其中一个视图中的节点充当锚点，另一个视图中的对应节点充当正样本，所有其他节点被视为负样本。其目标是最小化锚点与正样本之间的距离，并最大化到负样本的距离。然而，在训练期间由于缺乏标签信息，InfoNCE必然将来自相同类别的样本视为负样本，导致假负样本问题。这可能损害学到的节点表示，并随后阻碍下游任务的性能。尽管已经提出了许多方法来减轻假阴性的影响。

    arXiv:2310.14525v2 Announce Type: replace-cross  Abstract: Graph contrastive learning (GCL) has emerged as a representative graph self-supervised method, achieving significant success. The currently prevalent optimization objective for GCL is InfoNCE. Typically, it employs augmentation techniques to obtain two views, where a node in one view acts as the anchor, the corresponding node in the other view serves as the positive sample, and all other nodes are regarded as negative samples. The goal is to minimize the distance between the anchor node and positive samples and maximize the distance to negative samples. However, due to the lack of label information during training, InfoNCE inevitably treats samples from the same class as negative samples, leading to the issue of false negative samples. This can impair the learned node representations and subsequently hinder performance in downstream tasks. While numerous methods have been proposed to mitigate the impact of false negatives, they
    
[^174]: 评估人道主义援助对粮食安全的因果影响

    Assessing the Causal Impact of Humanitarian Aid on Food Security

    [https://arxiv.org/abs/2310.11287](https://arxiv.org/abs/2310.11287)

    本研究通过因果推断框架评估人道主义援助对粮食危机的影响，结果表明在粮食安全系统内，人道主义干预对营养不良有显著影响。

    

    在气候变化引发干旱的情况下，易受威胁的地区面临严重的粮食安全威胁，需要紧急的人道主义援助。本文介绍了一个针对非洲之角的因果推断框架，旨在评估基于现金的干预对粮食危机的影响。我们的贡献包括在粮食安全系统内识别因果关系，协调包括社会经济、天气和遥感数据在内的全面数据库，以及估计人道主义干预对营养不良的因果效应。就国家级别而言，我们的结果没有显著影响，可能是由于样本量有限、数据质量不佳，以及由于我们对粮食安全等跨学科系统的有限理解而导致的不完美因果图。相反，在区一级别上，结果显示出显著影响，进一步暗示了系统特定背景的本质。

    arXiv:2310.11287v2 Announce Type: replace  Abstract: In the face of climate change-induced droughts, vulnerable regions encounter severe threats to food security, demanding urgent humanitarian assistance. This paper introduces a causal inference framework for the Horn of Africa, aiming to assess the impact of cash-based interventions on food crises. Our contributions include identifying causal relationships within the food security system, harmonizing a comprehensive database including socio-economic, weather and remote sensing data, and estimating the causal effect of humanitarian interventions on malnutrition. On a country level, our results revealed no significant effects, likely due to limited sample size, suboptimal data quality, and an imperfect causal graph resulting from our limited understanding of multidisciplinary systems like food security. Instead, on a district level, results revealed significant effects, further implying the context-specific nature of the system. This un
    
[^175]: 面向金融时间序列预测的模态感知Transformer

    Modality-aware Transformer for Financial Time series Forecasting

    [https://arxiv.org/abs/2310.01232](https://arxiv.org/abs/2310.01232)

    提出了一种新颖的模态感知Transformer模型，能够有效地利用分类文本和数值时间序列的信息来预测金融时间序列，并通过神经注意力机制提供有价值的见解。

    

    时间序列预测是一个重大挑战，特别是当其准确性依赖于外部数据源而不仅仅基于历史数值时。金融领域普遍存在这一问题，时间序列的未来行为常常与从各种文本报告和大量经济指标中得出的信息密切相关。在实践中，关键挑战在于构建一个可靠的时间序列预测模型，能够利用不同来源的数据并提取有价值的见解，从而准确预测目标时间序列。在这项工作中，我们解决了这一挑战性问题，引入了一种新颖的多模态基于Transformer的模型，命名为\textit{模态感知Transformer}。我们的模型擅长于探索分类文本和数值时间序列的力量，有效预测目标时间序列，并通过其神经注意力机制提供见解。

    arXiv:2310.01232v2 Announce Type: replace  Abstract: Time series forecasting presents a significant challenge, particularly when its accuracy relies on external data sources rather than solely on historical values. This issue is prevalent in the financial sector, where the future behavior of time series is often intricately linked to information derived from various textual reports and a multitude of economic indicators. In practice, the key challenge lies in constructing a reliable time series forecasting model capable of harnessing data from diverse sources and extracting valuable insights to predict the target time series accurately. In this work, we tackle this challenging problem and introduce a novel multimodal transformer-based model named the \textit{Modality-aware Transformer}. Our model excels in exploring the power of both categorical text and numerical timeseries to forecast the target time series effectively while providing insights through its neural attention mechanism. 
    
[^176]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^177]: 通过元学习和代表性语言化器实现有效的结构化提示

    Effective Structured Prompting by Meta-Learning and Representative Verbalizer

    [https://arxiv.org/abs/2306.00618](https://arxiv.org/abs/2306.00618)

    通过使用提示池和构建基于实例的提示以及引入新颖的软语言化器，提出了一种通过元学习和代表性语言化器实现有效的结构化提示的方法

    

    预训练的遮蔽语言模型（MLM）的提示调整在自然语言处理任务中显示出有限标记示例的良好性能。它为下游任务调整提示，并使用语言化器来连接预测的标记和标签预测。由于训练数据有限，提示初始化对于提示调整至关重要。最近，MetaPrompting（Hou等，2022）使用元学习来学习所有特定任务提示的共享初始化。然而，当任务复杂时，单一初始化无法获得所有任务和样本的良好提示。此外，由于MLM通常很大，MetaPrompting需要调整整个MLM，导致计算和内存负担沉重。为了解决这些问题，我们使用提示池提取更多任务知识，并通过注意力构建基于实例的提示。我们进一步提出了一种新颖的软语言化器（RepVerb）...（剩余内容未提供）

    arXiv:2306.00618v2 Announce Type: replace-cross  Abstract: Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which con
    
[^178]: 对深度学习的不确定性量化进行调查：从不确定性来源的角度分析

    A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective

    [https://arxiv.org/abs/2302.13425](https://arxiv.org/abs/2302.13425)

    本研究对深度学习的不确定性量化进行了调查，从不确定性来源的角度分析不同方法，以评估DNN预测的置信度。

    

    深度神经网络(DNNs)在计算机视觉、自然语言处理以及科学与工程领域取得了巨大成功。然而，人们也认识到DNNs有时会做出意外、错误但过于自信的预测。这可能导致在自动驾驶、医学诊断和灾难响应等高风险应用中出现严重后果。不确定性量化（UQ）旨在估计DNN预测的置信度，超越预测准确性。近年来，已经开发了许多针对DNNs的UQ方法。系统地对这些UQ方法进行分类并比较它们的优势和劣势具有极大的实际价值。然而，现有调查大多集中在从神经网络架构角度或贝叶斯角度对UQ方法进行分类，忽略了每种方法可能引入的不确定性来源。

    arXiv:2302.13425v3 Announce Type: replace  Abstract: Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incor
    
[^179]: 面向解释神经代码模型的因果论理论

    Toward a Theory of Causation for Interpreting Neural Code Models

    [https://arxiv.org/abs/2302.03788](https://arxiv.org/abs/2302.03788)

    该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。

    

    Neural Language Models of Code，或者称为神经代码模型（NCMs），正在迅速从研究原型发展为商业开发者工具。因此，理解这些模型的能力和局限性变得至关重要。然而，这些模型的能力通常是使用自动化指标来衡量的，这些指标通常只能揭示它们真实性能的一部分。一般来说，NCMs的性能似乎很有前途，但目前关于这些模型如何做出决策仍有很多未知。因此，本文介绍了一种名为$do_{code}$的后验解释方法，该方法专门针对NCMs，能够解释模型的预测。$do_{code}$基于因果推断，以实现面向编程语言的解释。虽然$do_{code}$的理论基础可扩展到探索不同的模型属性，但我们提供了一个具体的实例，旨在减少影响...

    arXiv:2302.03788v2 Announce Type: replace-cross  Abstract: Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post hoc interpretability method specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact o
    
[^180]: 无需访问敏感属性的公平分类超参数调整

    Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access

    [https://arxiv.org/abs/2302.01385](https://arxiv.org/abs/2302.01385)

    提出了Antigone框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器，通过生成伪敏感属性来实现。

    

    公平的机器学习方法旨在训练能够在基于种族和性别等敏感属性定义的人口统计亚组之间平衡模型性能的模型。然而，在训练期间通常假定敏感属性已知，但由于隐私和其他后勤方面的考虑，实践中可能无法获取这些属性。最近的研究致力于在训练数据上没有敏感属性的情况下训练公平模型。然而，这些方法需要进行大量的超参数调整才能获得良好结果，因此假设在验证数据上已知敏感属性。然而，这种假设在实践中也可能不切实际。因此，在这里，我们提出了Antigone，这是一个框架，可以在训练数据或验证数据中都无需访问敏感属性即可训练公平的分类器。相反，我们通过训练有偏见的分类器并使用分类器错误（正确）标记的方式在验证数据上生成伪敏感属性。

    arXiv:2302.01385v2 Announce Type: replace-cross  Abstract: Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sought to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a biased classifier and using the classifier's incorrectly (correctly) labeled 
    
[^181]: AI-KD: 对抗学习和隐式正则化用于自知识蒸馏的方法

    AI-KD: Adversarial learning and Implicit regularization for self-Knowledge Distillation

    [https://arxiv.org/abs/2211.10938](https://arxiv.org/abs/2211.10938)

    提出了一种名为AI-KD的对抗学习和隐式正则化自知识蒸馏的方法，通过对抗学习和隐式蒸馏规范训练过程，使得学生模型可以从预训练和先前时期的预测概率中蒸馏确定性和渐进式知识，同时通过对抗学习传输确定性预测分布的知识。

    

    我们提出了一种新颖的对抗惩罚自知识蒸馏方法，名为对抗学习和隐式正则化自知识蒸馏（AI-KD），通过对抗学习和隐式蒸馏来规范训练过程。我们的模型不仅可以从预训练和先前时期的预测概率中蒸馏确定性和渐进式知识，还可以使用对抗学习传输确定性预测分布的知识。方法的动机在于自知识蒸馏方法通过软目标规范预测概率，但确切的分布可能难以预测。我们的方法部署了一个鉴别器来区分预训练模型和学生模型之间的分布，而学生模型在训练过程中被训练来愚弄鉴别器。因此，学生模型不仅可以学习到确定性预测分布，还可以从对抗学习中受益。

    arXiv:2211.10938v2 Announce Type: replace-cross  Abstract: We present a novel adversarial penalized self-knowledge distillation method, named adversarial learning and implicit regularization for self-knowledge distillation (AI-KD), which regularizes the training procedure by adversarial learning and implicit distillations. Our model not only distills the deterministic and progressive knowledge which are from the pre-trained and previous epoch predictive probabilities but also transfers the knowledge of the deterministic predictive distributions using adversarial learning. The motivation is that the self-knowledge distillation methods regularize the predictive probabilities with soft targets, but the exact distributions may be hard to predict. Our method deploys a discriminator to distinguish the distributions between the pre-trained and student models while the student model is trained to fool the discriminator in the trained procedure. Thus, the student model not only can learn the pr
    
[^182]: 面向节点分类的基于hub感知的随机游走图嵌入方法

    Hub-aware Random Walk Graph Embedding Methods for Classification

    [https://arxiv.org/abs/2209.07603](https://arxiv.org/abs/2209.07603)

    提出了两种基于随机游走的新颖图嵌入算法，专门为节点分类问题而设计，并针对hub节点设计了特殊的采样策略。

    

    在过去的二十年中，我们目睹了以图或网络形式结构化的宝贵大数据的巨大增长。将传统的机器学习和数据分析技术应用于这些数据，需要将图转换为保留图的最基本结构特性的基于向量的表示。为此，文献中提出了大量图嵌入方法。其中大多数产生通用嵌入，适用于各种应用，如节点聚类、节点分类、图可视化和链接预测。在本文中，我们提出了两种基于随机游走的新颖图嵌入算法，专门为节点分类问题而设计。所提出算法的随机游走采样策略被设计成特别关注hub -- 具有对总体具有关键作用的最高度节点。

    arXiv:2209.07603v3 Announce Type: replace  Abstract: In the last two decades we are witnessing a huge increase of valuable big data structured in the form of graphs or networks. To apply traditional machine learning and data analytic techniques to such data it is necessary to transform graphs into vector-based representations that preserve the most essential structural properties of graphs. For this purpose, a large number of graph embedding methods have been proposed in the literature. Most of them produce general-purpose embeddings suitable for a variety of applications such as node clustering, node classification, graph visualisation and link prediction. In this paper, we propose two novel graph embedding algorithms based on random walks that are specifically designed for the node classification problem. Random walk sampling strategies of the proposed algorithms have been designed to pay special attention to hubs -- high-degree nodes that have the most critical role for the overall 
    
[^183]: 一种用于谱聚类的非参数自举方法

    A Non-Parametric Bootstrap for Spectral Clustering

    [https://arxiv.org/abs/2209.05812](https://arxiv.org/abs/2209.05812)

    开发了两种新的算法，结合了数据矩阵的谱分解和非参数自举抽样方案，解决了谱聚类中收敛到次优解的问题，并展示出了其在估计有限混合模型时的优越性。

    

    有限混合模型是聚类领域中常用的方法，其软聚类成员概率很有益处。拟合有限混合模型的常见方法是使用谱聚类，该方法可以利用期望最大化（EM）算法。然而，EM算法存在一些问题，包括收敛到次优解。我们通过开发两种新算法来解决这个问题，这两种算法结合了数据矩阵的谱分解和非参数自举抽样方案。模拟显示了我们算法的有效性，并且展示出它们不仅具有灵活性，而且在估计有限混合模型时，与其他聚类算法相比，它们还具有计算效率和避免糟糕解的能力。相较于其他拟合有限混合模型的自举算法，我们的技术在收敛性方面更加一致。

    arXiv:2209.05812v2 Announce Type: replace-cross  Abstract: Finite mixture modelling is a popular method in the field of clustering and is beneficial largely due to its soft cluster membership probabilities. A common method for fitting finite mixture models is to employ spectral clustering, which can utilize the expectation-maximization (EM) algorithm. However, the EM algorithm falls victim to a number of issues, including convergence to sub-optimal solutions. We address this issue by developing two novel algorithms that incorporate the spectral decomposition of the data matrix and a non-parametric bootstrap sampling scheme. Simulations display the validity of our algorithms and demonstrate not only their flexibility, but also their computational efficiency and ability to avoid poor solutions when compared to other clustering algorithms for estimating finite mixture models. Our techniques are more consistent in their convergence when compared to other bootstrapped algorithms that fit fi
    
[^184]: 多尺度对比知识共同蒸馏用于事件时间关系抽取

    Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction

    [https://arxiv.org/abs/2209.00568](https://arxiv.org/abs/2209.00568)

    提出了MulCo：多尺度对比知识共同蒸馏用于全面提高所有类型时间数据集性能

    

    事件时间关系抽取（ETRE）是一个关键但具有挑战性的问题。事件对位于不同距离的话语中，我们称之为接近性带。关于位于更远（即“长”）或更近（即“短”）接近性带的事件对的时间顺序传达方式不同。目前ETRE模型往往在位于短或长接近性带的事件上表现良好，但不能同时表现良好。然而，现实世界中的自然文本包含所有类型的时间事件对。在本文中，我们提出了MulCo：多尺度对比知识共同蒸馏，这是一种融合方法，可以跨多个事件对接近性带共享知识，以提高对所有类型时间数据集的性能。我们的实验结果表明MulCo成功地整合了跨短和长接近性带的与时间推理相关的语言线索。

    arXiv:2209.00568v2 Announce Type: replace-cross  Abstract: Event Temporal Relation Extraction (ETRE) is a crucial yet challenging problem. Event pairs are situated within a discourse at different distances, which we refer to as proximity bands. The temporal ordering communicated about event pairs situated at more remote (i.e., ``long'') or less remote (i.e., ``short'') proximity bands is encoded differently. SOTA ETRE models have tended to perform well on events situated at either short or long proximity bands, but not both. Yet, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo: Multi-Scale Contrastive Knowledge Co-Distillation, a fusion approach that shares knowledge across multiple event pair proximity bands in order to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and 
    
[^185]: 具有部分分布式反馈的差分私有线性Bandits

    Differentially Private Linear Bandits with Partial Distributed Feedback

    [https://arxiv.org/abs/2207.05827](https://arxiv.org/abs/2207.05827)

    该论文研究了具有部分分布式反馈的差分私有线性Bandits，在隐私保护的前提下实现了全局奖励的最大化

    

    在本文中，我们研究了仅具有部分分布式反馈时的全局奖励最大化问题。 这个问题受到几个现实世界应用的启发（例如，蜂窝网络配置，动态定价和策略选择），在这些应用中，中央实体采取的一个行动影响了为全局奖励做出贡献的大量人口。 然而，从整个人口收集这样的奖励反馈不仅成本过高，而且通常会引起隐私问题。 为了解决这个问题，我们考虑具有差分私有分布式线性Bandits，其中仅选择人口的一个子集（称为客户端）参与学习过程，并且中央服务器通过在不同于差分的隐私方式中迭代聚合这些客户端的本地反馈来从这些部分反馈中学习全局模型。 然后，我们提出一个统一的算法学习框架，称为 differ

    arXiv:2207.05827v2 Announce Type: replace  Abstract: In this paper, we study the problem of global reward maximization with only partial distributed feedback. This problem is motivated by several real-world applications (e.g., cellular network configuration, dynamic pricing, and policy selection) where an action taken by a central entity influences a large population that contributes to the global reward. However, collecting such reward feedback from the entire population not only incurs a prohibitively high cost but often leads to privacy concerns. To tackle this problem, we consider differentially private distributed linear bandits, where only a subset of users from the population are selected (called clients) to participate in the learning process and the central server learns the global model from such partial feedback by iteratively aggregating these clients' local feedback in a differentially private fashion. We then propose a unified algorithmic learning framework, called differ
    
[^186]: 不解释噪音：面向随机集成的稳健反事实表达

    Don't Explain Noise: Robust Counterfactuals for Randomized Ensembles

    [https://arxiv.org/abs/2205.14116](https://arxiv.org/abs/2205.14116)

    本研究研究了随机集成的解释的稳健性，提出了一种生成稳健反事实解释的概率方法，展示了集成模型稳健性与基学习器稳健性之间的联系，并为凸基学习器的集成提供了实用方法和理论保证。

    

    反事实解释描述了如何修改特征向量以改变经过训练的分类器的结果。获得稳健的反事实解释对于提供有效的算法补救和有意义的解释至关重要。我们研究了随机集成的解释的稳健性，即使在训练数据固定的情况下，它们始终受到算法不确定性的影响。我们将稳健反事实解释的生成形式化为一个概率问题，并展示了集成模型的稳健性与基学习器的稳健性之间的联系。我们开发了一种在凸基学习器的集成上具有良好实证表现的实用方法，并用理论保证支持它。我们的结果表明，现有方法的稳健性令人惊讶地低：大多数数据集上天真反事实的有效性低于50％，在具有许多特征的问题上可能会降至20％。

    arXiv:2205.14116v3 Announce Type: replace  Abstract: Counterfactual explanations describe how to modify a feature vector in order to flip the outcome of a trained classifier. Obtaining robust counterfactual explanations is essential to provide valid algorithmic recourse and meaningful explanations. We study the robustness of explanations of randomized ensembles, which are always subject to algorithmic uncertainty even when the training data is fixed. We formalize the generation of robust counterfactual explanations as a probabilistic problem and show the link between the robustness of ensemble models and the robustness of base learners. We develop a practical method with good empirical performance and support it with theoretical guarantees for ensembles of convex base learners. Our results show that existing methods give surprisingly low robustness: the validity of naive counterfactuals is below $50\%$ on most data sets and can fall to $20\%$ on problems with many features. In contrast
    
[^187]: 关于带缺失值的监督学习的一致性

    On the consistency of supervised learning with missing values

    [https://arxiv.org/abs/1902.06931](https://arxiv.org/abs/1902.06931)

    两种方法在带缺失值的监督学习中表现出一致性，当缺失值不具信息性时，使用常数进行插补是一种简单且重要的实践方法。

    

    在许多应用设置中，数据存在缺失值，这使得分析变得具有挑战性。丰富的文献涉及缺失值在推断框架中的处理：从不完整的表中估计参数及其方差。在这里，我们考虑监督学习设置：在训练和测试数据中出现缺失值时预测目标。我们表明了两种方法在预测中的一致性。一个引人注目的结果是，当缺失值不具信息性时，使用常数进行插补，例如在学习之前使用均值，是一致的。这与推断设置形成鲜明对比，推断设置中常用的均值插补方法被指责扭曲数据的分布。这样一个简单的方法在实践中能够保持一致性是很重要的。我们还展示了适用于完整观测的预测器可以通过多重插补在不完整数据上进行最佳预测。最后，为了比较插补

    arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput
    
[^188]: 基于一致性增强的深度多视图聚类方法通过对比学习

    Consistency Enhancement-Based Deep Multiview Clustering via Contrastive Learning. (arXiv:2401.12648v1 [cs.LG])

    [http://arxiv.org/abs/2401.12648](http://arxiv.org/abs/2401.12648)

    本文提出了一种基于一致性增强的深度多视图聚类方法通过对比学习（CCEC）。该方法通过引入语义连接块并入特征表示中，以保持多个视图间的一致信息，并通过谱聚类改善聚类的表示过程。实验结果显示，该方法在多个数据集上的表现优于其他现有方法。

    

    多视图聚类（MVC）通过综合多个视图的信息，将数据样本分为有意义的聚类。而基于深度学习的方法在MVC场景中展现了强大的特征学习能力。然而，有效地泛化特征表示并保持一致性仍然是一个棘手的问题。此外，大多数基于对比学习的现有深度聚类方法在聚类过程中忽略了聚类表示的一致性。本文展示了如何解决上述问题，并提出了一种通过对比学习的一致增强型深度MVC方法（CCEC）。具体而言，将语义连接块并入特征表示中，以保持多个视图间的一致信息。此外，通过谱聚类改善聚类的表示过程，并提高了多个视图间的一致性。实验结果显示，我们的方法在多个数据集上的表现优于其他现有方法。

    Multiview clustering (MVC) segregates data samples into meaningful clusters by synthesizing information across multiple views. Moreover, deep learning-based methods have demonstrated their strong feature learning capabilities in MVC scenarios. However, effectively generalizing feature representations while maintaining consistency is still an intractable problem. In addition, most existing deep clustering methods based on contrastive learning overlook the consistency of the clustering representations during the clustering process. In this paper, we show how the above problems can be overcome and propose a consistent enhancement-based deep MVC method via contrastive learning (CCEC). Specifically, semantic connection blocks are incorporated into a feature representation to preserve the consistent information among multiple views. Furthermore, the representation process for clustering is enhanced through spectral clustering, and the consistency across multiple views is improved. Experiment
    
[^189]: 强化学习代理中的新兴支配等级

    Emergent Dominance Hierarchies in Reinforcement Learning Agents. (arXiv:2401.12258v1 [cs.MA])

    [http://arxiv.org/abs/2401.12258](http://arxiv.org/abs/2401.12258)

    本研究在强化学习中探讨了一种新的支配等级现象，并证明了在没有明确编程和内在奖励的情况下，强化学习代理能够自主发明、学习、实施和传递支配等级给新的群体。

    

    现代强化学习算法在各种任务中能够胜过人类。多智能体强化学习(MARL)设置提出了额外的挑战，成功的混合动机代理协作取决于个体和群体目标之间的微妙平衡。社会习惯和规范，往往受到人类机构的启发，被用作实现这种平衡的工具。在本文中，我们研究了一种基本且经过深入研究的社会习惯，即支配等级，它在动物和人类社会中都存在。我们将支配等级的行为理论应用于人工智能代理，并尽可能少地修改现有的术语和定义。我们证明，在没有明确编程或内在奖励的情况下，强化学习代理的群体能够发明、学习、实施和传递支配等级给新的群体。所产生的支配等级有一个

    Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance.  In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: Dominance hierarchies.  We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a 
    
[^190]: 基于行列式点过程和广义体积取样的加权最小二乘逼近

    Weighted least-squares approximation with determinantal point processes and generalized volume sampling. (arXiv:2312.14057v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2312.14057](http://arxiv.org/abs/2312.14057)

    该论文研究了使用行列式点过程和广义体积取样进行加权最小二乘逼近的问题，提出了广义版本的体积标准化取样算法，并证明了该算法在期望上的准最优性以及在某些规范向量空间中的逼近结果。

    

    我们考虑使用给定的m维空间V_m中的元素，借助于一些特征映射φ，通过对随机点x_1，...，x_n处的函数进行评估，来逼近函数从L^2到函数。在回顾一些关于使用独立同分布点的最优加权最小二乘的结果之后，我们考虑使用投影行列式点过程（DPP）或体积取样的加权最小二乘。这些分布在选定的特征φ(x_i)中引入了点之间的依赖性，以促进多样性。我们首先提供了广义版本的体积标准化取样，使用样本数n = O(mlog(m))得到了期望上的准最优结果，这意味着期望的L^2误差受到一个常数乘以在L^2中的最佳逼近误差的限制。此外，进一步假设函数在某个嵌入在L^2中的规范向量空间H中，我们进一步证明了逼近的结果。

    We consider the problem of approximating a function from $L^2$ by an element of a given $m$-dimensional space $V_m$, associated with some feature map $\varphi$, using evaluations of the function at random points $x_1,\dots,x_n$. After recalling some results on optimal weighted least-squares using independent and identically distributed points, we consider weighted least-squares using projection determinantal point processes (DPP) or volume sampling. These distributions introduce dependence between the points that promotes diversity in the selected features $\varphi(x_i)$. We first provide a generalized version of volume-rescaled sampling yielding quasi-optimality results in expectation with a number of samples $n = O(m\log(m))$, that means that the expected $L^2$ error is bounded by a constant times the best approximation error in $L^2$. Also, further assuming that the function is in some normed vector space $H$ continuously embedded in $L^2$, we further prove that the approximation is
    
[^191]: 做时间扭曲吧：学习动力系统的拓扑不变量

    Let's do the time-warp-attend: Learning topological invariants of dynamical systems. (arXiv:2312.09234v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.09234](http://arxiv.org/abs/2312.09234)

    该论文提出了一个数据驱动、基于物理信息的深度学习框架，用于分类和表征动力学变化的拓扑不变特征提取，特别关注超临界霍普分歧。这个方法可以帮助预测系统的质变和常发行为变化。

    

    科学领域中的动力系统，从电路到生态网络，当其基本参数跨越阈值时，会发生质变和常发性的行为变化，称为分歧。现有方法能够预测单个系统中即将发生的灾难，但主要基于时间序列，并且在分类不同系统的定性动力学变化和推广到真实数据方面存在困难。为了应对这一挑战，我们提出了一个数据驱动的、基于物理信息的深度学习框架，用于对动力学变化进行分类并表征分歧边界的拓扑不变特征提取。我们专注于超临界霍普分歧的典型案例，其用于模拟广泛应用的周期性动力学。我们的卷积关注方法经过了数据增强训练，鼓励学习可以用于检测分歧边界的拓扑不变量。

    Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boun
    
[^192]: 《$\mathbb{Z}_2\times \mathbb{Z}_2$》等变量量子神经网络：与经典神经网络的基准比较

    $\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks: Benchmarking against Classical Neural Networks. (arXiv:2311.18744v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.18744](http://arxiv.org/abs/2311.18744)

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与经典神经网络的性能进行了全面比较分析，结果表明《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上表现优越。

    

    本文对等变量量子神经网络（EQNN）和量子神经网络（QNN）与它们的经典对应物：等变量神经网络（ENN）和深度神经网络（DNN）的性能进行了全面比较分析。我们通过两个二元分类任务的玩具示例评估每个网络的性能，关注模型复杂度（由参数数量测量）和训练数据集的大小。我们的结果显示，《$\mathbb{Z}_2\times \mathbb{Z}_2$》EQNN和QNN在较小的参数集和适中的训练数据样本上提供了更优秀的性能。

    This paper presents a comprehensive comparative analysis of the performance of Equivariant Quantum Neural Networks (EQNN) and Quantum Neural Networks (QNN), juxtaposed against their classical counterparts: Equivariant Neural Networks (ENN) and Deep Neural Networks (DNN). We evaluate the performance of each network with two toy examples for a binary classification task, focusing on model complexity (measured by the number of parameters) and the size of the training data set. Our results show that the $\mathbb{Z}_2\times \mathbb{Z}_2$ EQNN and the QNN provide superior performance for smaller parameter sets and modest training data samples.
    
[^193]: RiskQ: 风险敏感的多智能体强化学习价值因子分解

    RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization. (arXiv:2311.01753v1 [cs.MA])

    [http://arxiv.org/abs/2311.01753](http://arxiv.org/abs/2311.01753)

    RiskQ是一种解决多智能体强化学习中风险敏感协调要求的方法，通过引入风险敏感的个体-全局最大（RIGM）原则和建模联合回报分布实现价值因子分解。

    

    多智能体系统特点是环境不确定性、智能体的策略多样性和部分可观测性，这导致了显著的风险。在多智能体强化学习（MARL）的背景下，学习对风险敏感的协调和分散策略是具有挑战性的。为了在风险敏感的MARL中制定协调要求，我们介绍了风险敏感的个体-全局最大（RIGM）原理，作为个体-全局最大（IGM）和分布式IGM（DIGM）原理的一种推广。该原理要求每个智能体的风险敏感动作选择集合应与中央策略的风险敏感动作选择等价。当前的MARL价值因子分解方法对于常见的风险度量（例如风险价值（VaR）度量或扭曲的风险度量）不满足RIGM原则。因此，我们提出了RiskQ来解决这个限制，通过建模联合回报分布来实现价值因子分解。

    Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeli
    
[^194]: VQPy：一种面向现代视频分析的面向对象方法。

    VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])

    [http://arxiv.org/abs/2311.01623](http://arxiv.org/abs/2311.01623)

    VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。

    

    视频分析广泛应用于当今系统和服务中。在视频分析的前沿是用户开发的视频查询，以找到特定感兴趣的对象。基于视频对象（例如人，动物，汽车等）与传统面向对象语言建模的对象相似的洞察力，我们提出了一种面向视频分析的面向对象方法。这种方法名为VQPy，包括一个前端（一种Python变体，其中包含用户可以表达视频对象及其交互的结构）和一个可扩展的后端，可以基于视频对象自动生成和优化管道。我们已经实施和开源了VQPy，它已经作为Cisco DeepVision框架的一部分产品化。

    Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.
    
[^195]: 通过学习有效的选择策略提高子图图神经网络的效率

    Efficient Subgraph GNNs by Learning Effective Selection Policies. (arXiv:2310.20082v1 [cs.LG])

    [http://arxiv.org/abs/2310.20082](http://arxiv.org/abs/2310.20082)

    本文通过学习有效的选择策略提高了子图图神经网络的效率，并且实验证明该方法优于现有的基准方法。

    

    子图图神经网络是一种可证明表达力的神经架构，可以从一组子图中学习图表示。然而，由于在许多子图上执行信息传递所带来的计算复杂性，它们的适用性受到了限制。本文考虑以数据驱动方式学习如何选择一个小的子图子集的问题。我们首先通过证明存在一些WL-难区分的图族，这些图族存在可以识别该族中所有图的有效子图选择策略，来解释这个问题。然后，我们提出了一种名为Policy-Learn的新方法，以迭代方式学习如何选择子图。我们证明，与常用的随机策略和解决相同问题的先前工作不同，我们的架构能够学习到上述高效策略。我们的实验结果表明，Policy-Learn的性能优于现有的基准方法。

    Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called Policy-Learn, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that Policy-Learn outperforms existing basel
    
[^196]: TiC-CLIP: CLIP模型的持续训练

    TiC-CLIP: Continual Training of CLIP Models. (arXiv:2310.16226v1 [cs.CV])

    [http://arxiv.org/abs/2310.16226](http://arxiv.org/abs/2310.16226)

    该论文提出了用于训练视觉-语言模型的大规模时间连续 (TiC) 基准，使用这些基准评估了现有模型的时间鲁棒性，并展示了一种简单有效的排练方法来持续训练模型。

    

    保持大型基础模型与最新数据保持同步本身就是昂贵的。为了避免不断重新训练的高成本，持续训练这些模型至关重要。这个问题被缺乏大规模连续学习基准或基线所加剧。我们引入了用于训练视觉-语言模型的第一批 Web 规模时间连续（TiC）基准：TiC-DataCompt、TiC-YFCC 和 TiC-RedCaps，其中包含超过 127 亿个时间戳图像-文本对，跨越了 9 年的时间（2014-2022）。我们首先使用这些基准来策划各种动态评估，以衡量现有模型的时间鲁棒性。我们展示了 OpenAI 的 CLIP 模型（使用 2020 年的数据进行训练）在我们策划的从 2021 年到 2022 年的检索任务中，失去了约 8% 的零-shot准确率，而与 OpenCLIP 存储库中最近训练的模型相比。然后，我们研究如何高效地对时间连续数据进行训练。我们证明了一种简单的排练方法，从上次的训练中继续训练，可以实现有效的训练。

    Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\approx 8\%$ zero-shot accuracy on our curated retrieval task from 2021--2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the l
    
[^197]: LMC多任务高斯过程模型的精确和高效解决方案

    Exact and efficient solutions of the LMC Multitask Gaussian Process model. (arXiv:2310.12032v1 [cs.LG])

    [http://arxiv.org/abs/2310.12032](http://arxiv.org/abs/2310.12032)

    LMC多任务高斯过程模型的精确解决方案表明，只需对噪声模型进行温和假设，即可实现高效计算。通过引入完整参数化的“投影LMC”模型和边缘似然函数表达式，展示了该方法相对于未经处理的方法的优异性能。

    

    线性共同关联模型（LMC）是一种非常通用的多任务高斯过程模型，用于回归或分类。虽然其表达能力和概念简单性很有吸引力，但朴素实现在数据点数量和任务数量方面具有立方复杂度，使得对大多数应用来说，必须进行近似处理。然而，最近的研究表明，在某些条件下，该模型的潜在过程可以解耦，导致仅与所述过程数量呈线性复杂度。我们在这里扩展了这些结果，从最一般的假设中展示了在LMC的高效精确计算所需的唯一条件是对噪声模型进行温和假设。我们引入了结果的完整参数化“投影LMC”模型，并给出了边缘似然函数的表达式，以实现高效的优化。我们对合成数据进行了参数研究，展示了我们方法相对于未经处理的方法的优异性能。

    The Linear Model of Co-regionalization (LMC) is a very general model of multitask gaussian process for regression or classification. While its expressivity and conceptual simplicity are appealing, naive implementations have cubic complexity in the number of datapoints and number of tasks, making approximations mandatory for most applications. However, recent work has shown that under some conditions the latent processes of the model can be decoupled, leading to a complexity that is only linear in the number of said processes. We here extend these results, showing from the most general assumptions that the only condition necessary to an efficient exact computation of the LMC is a mild hypothesis on the noise model. We introduce a full parametrization of the resulting \emph{projected LMC} model, and an expression of the marginal likelihood enabling efficient optimization. We perform a parametric study on synthetic data to show the excellent performance of our approach, compared to an unr
    
[^198]: 从随机数据投影器进行无监督表示学习

    Self-supervised Representation Learning From Random Data Projectors. (arXiv:2310.07756v1 [cs.LG])

    [http://arxiv.org/abs/2310.07756](http://arxiv.org/abs/2310.07756)

    本文提出了一种无监督表示学习（SSRL）方法，通过重建随机数据投影来学习高质量的数据表示，不依赖于增强或掩蔽技术，可以应用于任何数据模态和网络架构。实验结果表明该方法在各种任务中优于其他SSRL算法。

    

    通过利用人工设计的数据增强方法下的变换不变性假设，自监督表示学习（SSRL）已经取得了显著的进展。虽然基于增强的SSRL算法在计算机视觉和自然语言处理中推动了性能的提升，但它们通常不适用于其他数据模态，并且可能与应用特定的数据增强约束冲突。本文提出了一种SSRL方法，可以应用于任何数据模态和网络架构，因为它不依赖于增强或掩蔽。具体而言，我们通过重建随机数据投影来学习高质量的数据表示。我们对跨多种模态和实际应用的表示学习任务进行了评估，结果表明它优于多个最先进的SSRL基线模型。由于其广泛适用性和强大的实证结果，我们认为...

    Self-supervised representation learning~(SSRL) has advanced considerably by exploiting the transformation invariance assumption under artificially designed data augmentations. While augmentation-based SSRL algorithms push the boundaries of performance in computer vision and natural language processing, they are often not directly applicable to other data modalities, and can conflict with application-specific data augmentation constraints. This paper presents an SSRL approach that can be applied to any data modality and network architecture because it does not rely on augmentations or masking. Specifically, we show that high-quality data representations can be learned by reconstructing random data projections. We evaluate the proposed approach on a wide range of representation learning tasks that span diverse modalities and real-world applications. We show that it outperforms multiple state-of-the-art SSRL baselines. Due to its wide applicability and strong empirical results, we argue t
    
[^199]: 基于负距离核的最大平均距离(MMD)梯度流的后验抽样

    Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])

    [http://arxiv.org/abs/2310.03054](http://arxiv.org/abs/2310.03054)

    本文提出了一种基于负距离核的最大平均距离(MMD)的条件流方法，用于后验抽样和条件生成建模。通过离散的Wasserstein梯度流近似联合分布，证明了粒子流是适当功能的Wasserstein梯度流。在条件图像生成和超分辨率等逆问题中展示了方法的有效性。

    

    我们提出了基于负距离核的最大平均距离(MMD)的条件流用于后验抽样和条件生成建模。这个MMD，也被称为能量距离，具有像通过切片和排序进行高效计算的几个有益属性。我们使用离散的Wasserstein梯度流来近似真实情况和观察值的联合分布，并为后验分布建立了误差界限。此外，我们证明了我们的粒子流确实是适当功能的Wasserstein梯度流。我们方法的能力通过数字示例进行了演示，包括条件图像生成和诸如超分辨率、修复和低剂量和有限角度设置下的计算机断层扫描等逆问题。

    We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modeling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.
    
[^200]: QuATON: 光纤神经元的量化感知训练

    QuATON: Quantization Aware Training of Optical Neurons. (arXiv:2310.03049v1 [cs.LG])

    [http://arxiv.org/abs/2310.03049](http://arxiv.org/abs/2310.03049)

    提出一种光纤神经元的量化感知训练方法，通过考虑物理约束，实现了对光纤神经架构的鲁棒设计。

    

    光学神经架构（ONA）使用具有优化物理参数的编码元件进行智能测量。然而，制造具有设计性能的ONA是具有挑战性的。制造技术的限制通常限制了训练参数的可实现精度。物理约束也可能限制物理参数可以容纳的值范围。因此，ONA应在可实现的约束条件下进行训练。然而，这种基于物理的约束将训练目标转化为一个约束优化问题，使其更难以利用现有的梯度方法进行优化。为了缓解这些从模拟到实现的关键问题导致性能下降的问题，我们提出了一个基于物理信息的量化感知训练框架。我们的方法在文献中提出的一种ONA上进行了评估，该ONA被称为衍射深度神经网络。

    Optical neural architectures (ONAs) use coding elements with optimized physical parameters to perform intelligent measurements. However, fabricating ONAs while maintaining design performances is challenging. Limitations in fabrication techniques often limit the realizable precision of the trained parameters. Physical constraints may also limit the range of values the physical parameters can hold. Thus, ONAs should be trained within the implementable constraints. However, such physics-based constraints reduce the training objective to a constrained optimization problem, making it harder to optimize with existing gradient-based methods. To alleviate these critical issues that degrade performance from simulation to realization we propose a physics-informed quantization-aware training framework. Our approach accounts for the physical constraints during the training process, leading to robust designs. We evaluate our approach on an ONA proposed in the literature, named a diffractive deep ne
    
[^201]: ED-NeRF: 使用潜空间 NeRF 实现高效的文本引导的 3D 场景编辑

    ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF. (arXiv:2310.02712v1 [cs.CV])

    [http://arxiv.org/abs/2310.02712](http://arxiv.org/abs/2310.02712)

    ED-NeRF 提出了一种高效的 3D 场景编辑方法，通过将场景嵌入到潜空间中，得到更快速且更易于编辑的 NeRF 骨干。

    

    最近，文本到图像扩散模型取得了显著进展，在二维图像生成方面取得了突破性的性能。这些进展已经扩展到三维模型，实现了从文本描述中生成新的三维对象。这演变成了 NeRF 编辑方法，通过文本条件允许对现有的三维对象进行操作。然而，现有的 NeRF 编辑技术在性能上面临着一些限制，如训练速度慢和使用的损失函数不充分考虑编辑。为了解决这个问题，我们提出了一种新颖的 3D NeRF 编辑方法，称为 ED-NeRF，通过将真实世界场景成功嵌入到潜扩散模型 (LDM) 的潜空间中，通过独特的细化层。这种方法使我们能够获得一个不仅更快，而且更适合于编辑的 NeRF 骨干，与传统的图像空间 NeRF 编辑相比。此外，我们提出了一种改进的损失函数。

    Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss 
    
[^202]: 学习如何提供注重依从性的建议

    Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])

    [http://arxiv.org/abs/2310.00817](http://arxiv.org/abs/2310.00817)

    本文提出了一种顺序决策模型，考虑了人的依从程度和机器提供建议的时机，并提供了学习算法来学习最佳的建议策略。

    

    随着人工智能系统在人类决策中扮演越来越重要的角色，人工智能与人类之间的交互存在挑战。由于没有充分考虑到人类忽视人工智能建议和人工智能选择性提供建议的需求，一个挑战就来自于底层人工智能策略的不佳表现。本文提出了一个顺序决策模型，该模型考虑了人类的依从程度（即人类遵循/拒绝机器建议的概率），并引入了一个推迟选项，使得机器在最合适的时候可以暂时不提供建议。我们提供了学习算法，可以学习最佳的建议策略，并仅在关键时刻提供建议。与问题不可知的强化学习算法相比，我们的专门化学习算法不仅具有更好的理论收敛性能，而且在实证性能上表现出色。

    As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
    
[^203]: 用于开发协作分布式机器学习系统的设计工具箱

    A Design Toolbox for the Development of Collaborative Distributed Machine Learning Systems. (arXiv:2309.16584v1 [cs.MA])

    [http://arxiv.org/abs/2309.16584](http://arxiv.org/abs/2309.16584)

    我们开发了一个CDML设计工具箱，可以指导开发者设计满足用例要求的协作分布式机器学习系统。

    

    为了在保护机器学习模型的机密性的同时利用来自多方的训练数据对模型进行充分训练，研究人员开发了各种协作分布式机器学习（CDML）系统设计，例如辅助学习、联邦学习和分裂学习。CDML系统设计展示了不同的特征，例如高度的代理人自治性、机器学习模型的机密性和容错性。面对不同特征的各种CDML系统设计，开发者很难有针对性地设计满足用例要求的CDML系统。然而，不合适的CDML系统设计可能导致CDML系统无法实现其预期目的。我们开发了一个CDML设计工具箱，可以指导CDML系统的开发。基于CDML设计工具箱，我们提出了具有不同关键特征的CDML系统典型，可以支持设计满足用例要求的CDML系统。

    To leverage training data for the sufficient training of ML models from multiple parties in a confidentiality-preserving way, various collaborative distributed machine learning (CDML) system designs have been developed, for example, to perform assisted learning, federated learning, and split learning. CDML system designs show different traits, for example, high agent autonomy, machine learning (ML) model confidentiality, and fault tolerance. Facing a wide variety of CDML system designs with different traits, it is difficult for developers to design CDML systems with traits that match use case requirements in a targeted way. However, inappropriate CDML system designs may result in CDML systems failing their envisioned purposes. We developed a CDML design toolbox that can guide the development of CDML systems. Based on the CDML design toolbox, we present CDML system archetypes with distinct key traits that can support the design of CDML systems to meet use case requirements.
    
[^204]: 一种用于交通状态预测的物理增强残差学习（PERL）框架

    A Physics Enhanced Residual Learning (PERL) Framework for Traffic State Prediction. (arXiv:2309.15284v1 [cs.LG])

    [http://arxiv.org/abs/2309.15284](http://arxiv.org/abs/2309.15284)

    这篇论文提出了一种名为物理增强残差学习（PERL）的框架，用于交通状态预测。PERL模型集成了物理模型和数据驱动模型的优势，通过将物理模型结果和预测残差作为修正相结合，具有可解释性，且比数据驱动方法要求更少的数据。

    

    在车辆轨迹预测中，物理模型和数据驱动模型是两种主要方法。然而，每种方法都存在自己的挑战：物理模型在可预测性方面不足，而数据驱动模型则缺乏可解释性。针对这些已确定的缺点，本文提出了一种新颖的框架，即物理增强残差学习（PERL）模型。PERL将物理模型和数据驱动方法的优势融合在一起，用于交通状态预测。PERL包括一个物理模型和一个残差学习模型。它的预测结果是物理模型结果和预测残差的和作为对其的修正。PERL保留了物理模型天然的可解释性，并且相比数据驱动方法具有较小的数据需求。我们使用实际车辆轨迹数据集进行了实验。我们提出了一个PERL模型，其中以智能驾驶模型（IDM）作为其物理车跟模型，长短期记忆（LSTM）模型用于学习残差。

    In vehicle trajectory prediction, physics models and data-driven models are two predominant methodologies. However, each approach presents its own set of challenges: physics models fall short in predictability, while data-driven models lack interpretability. Addressing these identified shortcomings, this paper proposes a novel framework, the Physics-Enhanced Residual Learning (PERL) model. PERL integrates the strengths of physics-based and data-driven methods for traffic state prediction. PERL contains a physics model and a residual learning model. Its prediction is the sum of the physics model result and a predicted residual as a correction to it. It preserves the interpretability inherent to physics-based models and has reduced data requirements compared to data-driven methods. Experiments were conducted using a real-world vehicle trajectory dataset. We proposed a PERL model, with the Intelligent Driver Model (IDM) as its physics car-following model and Long Short-Term Memory (LSTM) 
    
[^205]: 序列到序列的西班牙预训练语言模型

    Sequence-to-Sequence Spanish Pre-trained Language Models. (arXiv:2309.11259v1 [cs.CL])

    [http://arxiv.org/abs/2309.11259](http://arxiv.org/abs/2309.11259)

    该论文介绍了一种新的序列到序列的西班牙预训练语言模型，该模型在各种序列到序列任务中表现出了竞争性能，并提供了BART、T5和BERT2BERT-style模型的西班牙版本。

    

    近年来，预训练语言模型的重大进展为许多非英语语言版本的开发铺平了道路，其中特别关注了仅编码器和仅解码器的架构。虽然西班牙语语言模型包括BERT、RoBERTa和GPT在自然语言理解和生成方面展现出了优势，但在涉及输入输出对的序列到序列任务中，缺乏编码器-解码器模型。本文通过引入实施和评估著名的仅在西班牙语语料库上进行预训练的编码器-解码器架构，开创了新的领域。具体而言，我们提出了BART、T5和BERT2BERT风格模型的西班牙语版本，并对它们在各种序列到序列任务上进行了全面评估，包括摘要、重述和生成式问答。我们的研究结果强调了所有模型的竞争性能，其中BART和T5表现出色。

    In recent years, substantial advancements in pre-trained language models have paved the way for the development of numerous non-English language versions, with a particular focus on encoder-only and decoder-only architectures. While Spanish language models encompassing BERT, RoBERTa, and GPT have exhibited prowess in natural language understanding and generation, there remains a scarcity of encoder-decoder models designed for sequence-to-sequence tasks involving input-output pairs. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures, exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across a diverse range of sequence-to-sequence tasks, spanning summarization, rephrasing, and generative question answering. Our findings underscore the competitive performance of all models, with BART and T5 emerging a
    
[^206]: 移动边缘计算中通过深度强化学习进行任务图离载

    Task Graph offloading via Deep Reinforcement Learning in Mobile Edge Computing. (arXiv:2309.10569v1 [cs.DC])

    [http://arxiv.org/abs/2309.10569](http://arxiv.org/abs/2309.10569)

    本文研究了在移动边缘计算环境下通过深度强化学习实现任务图离载的问题。现有的工作往往无法适应环境变化，导致用户体验下降。我们提出了一种将任务图调度建模为马尔可夫决策过程的方法，以适应计算能力随时间变化的情况。

    

    随着移动应用程序越来越复杂，其中包含的依赖任务越来越流行，这些应用程序通常具有低延迟要求，从而导致对计算资源的需求急剧增加。随着移动边缘计算（MEC）的出现，将应用程序任务卸载到部署在移动网络边缘的小型设备上以获得高质量用户体验成为最重要的问题。然而，由于MEC环境是动态的，大多数依赖专家知识或准确的分析模型的现有工作在任务图离载方面无法完全适应这种环境变化，导致用户体验降低。本文研究了MEC中的任务图离载，考虑到边缘计算设备的计算能力随时间变化。为了适应环境变化，我们将计算离载的任务图调度建模为一个Markov决策过程（Markov Decision Process）。

    Various mobile applications that comprise dependent tasks are gaining widespread popularity and are increasingly complex. These applications often have low-latency requirements, resulting in a significant surge in demand for computing resources. With the emergence of mobile edge computing (MEC), it becomes the most significant issue to offload the application tasks onto small-scale devices deployed at the edge of the mobile network for obtaining a high-quality user experience. However, since the environment of MEC is dynamic, most existing works focusing on task graph offloading, which rely heavily on expert knowledge or accurate analytical models, fail to fully adapt to such environmental changes, resulting in the reduction of user experience. This paper investigates the task graph offloading in MEC, considering the time-varying computation capabilities of edge computing devices. To adapt to environmental changes, we model the task graph scheduling for computation offloading as a Mark
    
[^207]: 通过精细的模态评估增强多模态协作

    Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation. (arXiv:2309.06255v1 [cs.CV])

    [http://arxiv.org/abs/2309.06255](http://arxiv.org/abs/2309.06255)

    本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。

    

    多模态学习的一个主要问题是如何将来自不同模态的异质信息共同结合起来。然而，大多数模型在多模态协作方面常常存在不尽人意的问题，不能很好地共同利用所有模态。一些方法被提出来识别和增强学习效果较差的模态，但往往难以在理论上提供对样本级别多模态协作的细粒度观察和支持。因此，合理观察和改进模态之间细粒度的协作尤为重要，尤其是在面对模态差异在不同样本之间可能变化的实际场景时。为了实现这一目标，我们引入了一种精细的模态评估指标，以评估每个模态在样本级别的贡献。通过模态评估，我们遗憾地发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。我们进一步分析了这个问题。

    One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this iss
    
[^208]: 从分层的弱偏好反馈中进行深度强化学习

    Deep Reinforcement Learning from Hierarchical Weak Preference Feedback. (arXiv:2309.02632v1 [cs.LG])

    [http://arxiv.org/abs/2309.02632](http://arxiv.org/abs/2309.02632)

    本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。

    

    奖励设计是实际强化学习中一个基本但具有挑战性的方面。对于简单任务，研究人员通常手工设计奖励函数，例如使用若干个奖励因子的线性组合。然而，这种奖励工程受到近似偏差的影响，需要大量的调优成本，并且通常无法提供复杂任务所需的细粒度。为了避免这些困难，研究人员开始转向从人类反馈中进行强化学习（RLHF），从轨迹序列对之间的人类偏好中学习奖励函数。通过利用基于偏好的奖励建模，RLHF学习到与人类偏好非常一致的复杂奖励，使得强化学习能够解决日益困难的问题。不幸的是，RLHF的适用性受到获得人类偏好数据的高成本和困难的限制。鉴于这个成本，我们研究了在复杂任务中使用更少人力投入的方式来学习奖励函数。

    Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; sim
    
[^209]: TensorBank: 基于Tensor的湖仓库用于基础模型训练

    TensorBank:Tensor Lakehouse for Foundation Model Training. (arXiv:2309.02094v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.02094](http://arxiv.org/abs/2309.02094)

    TensorBank是一个基于Tensor的湖仓库，能够以高速从云对象存储流式传输张量到GPU内存，并通过使用分层统计指标进行查询加速。

    

    随着基础模型在自然语言之外的领域的兴起，存储和流式处理高维数据成为基础模型训练的关键需求。在本文中，我们介绍了TensorBank，一个能够基于复杂关系查询从云对象存储（COS）流式传输张量到GPU内存的百亿级张量湖仓库。我们使用分层统计指标（HSI）来加速查询。我们的架构允许使用HTTP范围读取来直接访问块级别的张量。一旦在GPU内存中，数据可以使用PyTorch转换进行转换。我们提供了一个通用的PyTorch数据集类型，配有相应的数据集工厂，用于将关系查询和请求的转换作为一个实例进行翻译。通过使用HSI，可以跳过不相关的块，而无需读取它们，因为这些索引包含不同层次分辨率级别上内容的统计信息。这是一个基于开放标准的有主观观点的架构。

    Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank, a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making h
    
[^210]: 可信的LLMs：评估大型语言模型对齐的调查和指南

    Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. (arXiv:2308.05374v1 [cs.AI])

    [http://arxiv.org/abs/2308.05374](http://arxiv.org/abs/2308.05374)

    本文介绍了一份关于评估LLM可信度的综合调查，并提供了指导。调查涵盖了可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性等七个主要类别，共计29个子类别。

    

    在将大型语言模型（LLMs）应用于现实世界应用之前，确保对齐是一项关键任务。然而，从业者面临的主要挑战是缺乏明确的指导来评估LLMs的输出是否符合社会规范、价值观和法规。本文提出了一个全面的调查，涵盖了评估LLM可信度时必须考虑的关键维度。调查涵盖了LLM可信度的七个主要类别：可靠性、安全性、公平性、抵抗滥用、可解释性和推理能力、遵守社会规范以及鲁棒性。每个主要类别进一步细分为若干子类别，共计29个子类别。

    Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset 
    
[^211]: 演化直接策略搜索中的广义早停止方法

    Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])

    [http://arxiv.org/abs/2308.03574](http://arxiv.org/abs/2308.03574)

    本文提出了一种适用于直接策略搜索的早停止方法，通过观察每个时间步骤的目标值来决定是否停止评估，而无需问题特定的知识。在测试中，该方法在游戏、机器人和经典控制领域中表现出节省计算时间的优势。

    

    在许多优化问题中，尤其是涉及在物理世界中进行评估的直接策略搜索任务中，评估时间通常较长。当在固定时间段内评估解决方案时，往往会明确无法通过增加计算时间来提高目标值（例如，当两轮机器人持续在原地旋转时）。在这种情况下，及早停止评估以节省计算时间是有意义的。然而，大多数评估停止方法都是问题特定的，并且需要专门为当前任务设计。因此，我们提出了一种直接策略搜索的早停止方法。该方法只查看每个时间步骤的目标值，不需要任何问题特定的知识。我们在五个来自游戏、机器人和经典控制领域的直接策略搜索环境中测试了引入的停止准则，并展示了其节省了计算时间的优势。

    Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa
    
[^212]: 透明度在未知估值的重复一次性出价拍卖中的作用

    The Role of Transparency in Repeated First-Price Auctions with Unknown Valuations. (arXiv:2307.09478v1 [cs.GT])

    [http://arxiv.org/abs/2307.09478](http://arxiv.org/abs/2307.09478)

    本文研究了一次性出价拍卖中透明度对遗憾最小化的影响，通过对拍卖透明度与环境特性的分析，揭示了在拍卖中学习最优出价的速度。

    

    我们研究了在一系列一次性出价拍卖中，单个竞标人在只有在赢得拍卖时才知道物品价值的情况下，遗憾最小化的问题。我们的主要贡献是完整地刻画了拍卖的透明度对最小化感到遗憾的极小极大问题的影响，其中透明度调控了拍卖师在每次拍卖结束时公开竞争出价的信息量。我们的结果适用于不同假设（随机的、对抗性的和平滑变体）生成竞标人估值和竞争出价的环境。这些极小极大率揭示了透明度和环境性质之间的相互作用，以及影响一个人学习在一次性出价拍卖中如何最优出价的速度。

    We study the problem of regret minimization for a single bidder in a sequence of first-price auctions where the bidder knows the item's value only if the auction is won. Our main contribution is a complete characterization, up to logarithmic factors, of the minimax regret in terms of the auction's transparency, which regulates the amount of information on competing bids disclosed by the auctioneer at the end of each auction. Our results hold under different assumptions (stochastic, adversarial, and their smoothed variants) on the environment generating the bidder's valuations and competing bids. These minimax rates reveal how the interplay between transparency and the nature of the environment affects how fast one can learn to bid optimally in first-price auctions.
    
[^213]: QH9：QM9分子的量子哈密顿预测基准测试

    QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules. (arXiv:2306.09549v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.09549](http://arxiv.org/abs/2306.09549)

    该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。

    

    监督式机器学习方法越来越被用于加速电子结构预测，作为第一性原理计算方法（如密度泛函理论（DFT））的替代品。虽然许多量子化学数据集侧重于化学性质和原子力，但准确且高效地预测哈密顿矩阵的能力是非常重要和基本的物理量，它确定了物理系统和化学性质的量子状态。在这项工作中，我们生成了一个新的量子哈密顿数据集，命名为QH9，基于QM9数据集为2,399个分子动力学轨迹和130,831个稳定分子几何形态提供精确的哈密顿矩阵。通过设计各种分子的基准任务，我们展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。QH9数据集和基准模型都提供。

    Supervised machine learning approaches have been increasingly used in accelerating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chemistry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide precise Hamiltonian matrices for 2,399 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided
    
[^214]: 过拟合的模型会泄露预训练数据的隐私信息

    TMI! Finetuned Models Leak Private Information from their Pretraining Data. (arXiv:2306.01181v1 [cs.LG])

    [http://arxiv.org/abs/2306.01181](http://arxiv.org/abs/2306.01181)

    本文提出了一种新的会员推断威胁模型TMI，用于评估微调模型对预训练数据的泄露，突显了在使用预训练模型进行迁移学习中存在的隐私风险，并需要对机器学习中的隐私进行更严格的评估。

    

    迁移学习已成为机器学习中越来越流行的技术，用于利用为一个任务训练的预训练模型来协助构建相关任务的微调模型。该范例在隐私机器学习方面尤其受欢迎，其中预训练模型被认为是公开的，只有微调数据被视为敏感的。然而，有理由认为用于预训练的数据仍然是敏感的，因此必须了解微调模型泄露有关预训练数据的信息量。本文提出了一种新的会员推理威胁模型，其中对手只能访问已经微调好的模型，并想推断预训练数据的成员资格。为了实现这个威胁模型，我们实施了一种新型的基于元分类器的攻击TMI，它利用了在下游任务中记忆的预训练样本对预测的影响。我们在视觉和自然语言处理任务上评估了TMI，并表明它在仅使用微调模型的情况下实现了高精度的推断预训练数据的成员资格。我们的结果突显了在迁移学习中使用预训练模型可能存在的隐私风险，以及需要对机器学习中的隐私进行更严格的评估的需求。

    Transfer learning has become an increasingly popular technique in machine learning as a way to leverage a pretrained model trained for one task to assist with building a finetuned model for a related task. This paradigm has been especially popular for privacy in machine learning, where the pretrained model is considered public, and only the data for finetuning is considered sensitive. However, there are reasons to believe that the data used for pretraining is still sensitive, making it essential to understand how much information the finetuned model leaks about the pretraining data. In this work we propose a new membership-inference threat model where the adversary only has access to the finetuned model and would like to infer the membership of the pretraining data. To realize this threat model, we implement a novel metaclassifier-based attack, TMI, that leverages the influence of memorized pretraining samples on predictions in the downstream task. We evaluate TMI on both vision and na
    
[^215]: 从ReLU神经网络的缓和过拟合到良性过拟合

    From Tempered to Benign Overfitting in ReLU Neural Networks. (arXiv:2305.15141v1 [cs.LG])

    [http://arxiv.org/abs/2305.15141](http://arxiv.org/abs/2305.15141)

    本论文通过对二层ReLU神经网络进行研究，证明了各种假设下过拟合的类型会从一维数据的极端情况下缓和到高维的良性，揭示了输入维度在神经网络过拟合中的关键作用。

    

    过参数化神经网络被观察到即使训练模型来完美地适应嘈杂的数据也能很好地推广。这一现象引发了大量关于“良性过拟合”的工作，其中内插预测器实现接近最优性能。最近，有人猜测并经验性地观察到神经网络的行为通常更好地描述为“缓和过拟合”，其中性能既非最优，也非微不足道，并随噪声水平的变化而降低。然而，迄今为止，这一主张尚缺乏关于非线性神经网络理论的证明。在这项工作中，我们提供了几个结果，旨在弥合这些互补的观点。我们研究了一个简单的分类设置，使用二层ReLU神经网络，并证明在各种假设下，过拟合的类型从一维数据的极端情况下缓和到高维的良性。因此，我们证明输入维度在这种情况下有关键作用。

    Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on "benign overfitting", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as "tempered overfitting", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in thi
    
[^216]: 利用数据挖掘技术识别影响建筑物能耗和成本降低的因素

    Identification of the Factors Affecting the Reduction of Energy Consumption and Cost in Buildings Using Data Mining Techniques. (arXiv:2305.08886v1 [cs.LG])

    [http://arxiv.org/abs/2305.08886](http://arxiv.org/abs/2305.08886)

    本研究利用数据挖掘技术实现了对建筑物成本降低和能耗影响因素的识别，结果表明隔热、建筑物尺寸和制冷系统类型是影响能源消耗和成本降低的关键因素。

    

    优化能耗和协调公用事业系统一直是建筑行业关注的焦点。建筑是世界上最大的能源消耗者之一，其能效对于防止浪费和降低成本至关重要。此外，建筑物产生大量的原始数据，可以用于了解能源消耗模式并协助开发优化策略。本研究利用真实世界的数据集，旨在识别影响建筑物成本降低和能耗的因素。为实现这一目标，我们利用三种回归模型（Lasso回归、决策树和随机森林）来预测建筑物的主要燃料使用、电能消耗和成本节省。进行了一项影响能耗和成本降低因素的分析，并使用元启发式算法优化决策树算法。通过使用元启发技术，我们对决策树算法进行微调，以实现更好的模型精度和可解释性。结果表明，影响建筑物能耗和成本降低的关键因素是隔热、建筑物尺寸和使用的制冷系统类型。

    Optimizing energy consumption and coordination of utility systems have long been a concern of the building industry. Buildings are one of the largest energy consumers in the world, making their energy efficiency crucial for preventing waste and reducing costs. Additionally, buildings generate substantial amounts of raw data, which can be used to understand energy consumption patterns and assist in developing optimization strategies. Using a real-world dataset, this research aims to identify the factors that influence building cost reduction and energy consumption. To achieve this, we utilize three regression models (Lasso Regression, Decision Tree, and Random Forest) to predict primary fuel usage, electrical energy consumption, and cost savings in buildings. An analysis of the factors influencing energy consumption and cost reduction is conducted, and the decision tree algorithm is optimized using metaheuristics. By employing metaheuristic techniques, we fine-tune the decision tree alg
    
[^217]: 学习深度协方差函数

    Learning a Depth Covariance Function. (arXiv:2303.12157v1 [cs.CV])

    [http://arxiv.org/abs/2303.12157](http://arxiv.org/abs/2303.12157)

    该论文提出了学习深度协方差函数，并利用该方法对深度补全、捆集调整和单目密集视觉里程计等几何视觉任务进行了处理。

    

    我们提出了学习深度协方差函数，并将其应用于几何视觉任务。给定RGB图像作为输入，协方差函数可灵活地用于定义深度函数先验，给定观测的预测分布以及主动点选择方法。我们利用这些技术来解决一系列下游任务：深度补全、捆集调整和单目密集视觉里程计。

    We propose learning a depth covariance function with applications to geometric vision tasks. Given RGB images as input, the covariance function can be flexibly used to define priors over depth functions, predictive distributions given observations, and methods for active point selection. We leverage these techniques for a selection of downstream tasks: depth completion, bundle adjustment, and monocular dense visual odometry.
    
[^218]: Mpox-AISM：基于人工智能的超级监测以遏制猴痘传播

    Mpox-AISM: AI-Mediated Super Monitoring for Forestalling Monkeypox Spread. (arXiv:2303.09780v1 [eess.IV])

    [http://arxiv.org/abs/2303.09780](http://arxiv.org/abs/2303.09780)

    本文介绍了一种名为超级监测的远程实现猴痘早期诊断的策略。该策略以人工智能技术为基础，可实现高灵敏度和准确性的病症分类，同时成本低、易用性高，具有广泛的应用前景。

    

    针对及时、便捷和准确诊断早期患者是遏制猴痘传播的挑战。我们提出了一种远程、实时的在线可视化策略，称为“超级监测”，用于构建低成本、方便、及时和无专业知识的猴痘早期诊断。通过深度学习、数据增强和自监督学习组装的框架，我们提出了一种基于人工智能介导的“超级监测”（Mpox-AISM），根据数据集特征和猴痘演变趋势以及与高相似度的其他七种皮肤病的专业分类，因此这些功能与合理的程序界面和阈值设置确保了其灵敏度超过95.9％，特异度几乎达到100％。因此，在互联网和通讯终端的云服务的帮助下，这种策略可以潜在地用于实时检测猴痘的早期阶段。

    The challenge on forestalling monkeypox (Mpox) spread is the timely, convenient and accurate diagnosis for earlystage infected individuals. Here, we propose a remote and realtime online visualization strategy, called "Super Monitoring" to construct a low cost, convenient, timely and unspecialized diagnosis of early-stage Mpox. Such AI-mediated "Super Monitoring" (Mpox-AISM) invokes a framework assembled by deep learning, data augmentation and self-supervised learning, as well as professionally classifies four subtypes according to dataset characteristics and evolution trend of Mpox and seven other types of dermatopathya with high similarity, hence these features together with reasonable program interface and threshold setting ensure that its Recall (Sensitivity) was beyond 95.9% and the specificity was almost 100%. As a result, with the help of cloud service on Internet and communication terminal, this strategy can be potentially utilized for the real-time detection of earlystage Mpox 
    
[^219]: 使用Davis-Yin分裂实现更快的预测与优化

    Faster Predict-and-Optimize with Davis-Yin Splitting. (arXiv:2301.13395v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13395](http://arxiv.org/abs/2301.13395)

    本文介绍了一种使用Davis-Yin分裂方法实现更快的预测与优化的方法，该方法借鉴了现代凸优化的思想，能够在具有数千个变量的问题上轻松扩展。

    

    在许多应用中，需要反复解决具有相似但不同参数的组合问题。然而，参数$w$并非直接观察到的；只有与$w$相关的上下文数据$d$可用。我们很容易就会想到使用神经网络来根据$d$预测$w$，但是训练这样的模型需要将组合优化的离散性与用于训练神经网络的梯度优化框架相结合。当所讨论的问题是整数线性规划（ILP）时，克服这个问题的一种方法是考虑组合问题的连续放松。虽然现有方法使用这种方法在小型问题（10-100个变量）上显示出了高度的效果，但在大型问题上扩展能力不足。在本研究中，我们借鉴了现代凸优化的思想，设计了一个网络和训练方案，可以轻松地扩展到具有数千个变量的问题。

    In many applications, a combinatorial problem must be repeatedly solved with similar, but distinct parameters. Yet, the parameters $w$ are not directly observed; only contextual data $d$ that correlates with $w$ is available. It is tempting to use a neural network to predict $w$ given $d$, but training such a model requires reconciling the discrete nature of combinatorial optimization with the gradient-based frameworks used to train neural networks. When the problem in question is an Integer Linear Program (ILP), one approach to overcoming this issue is to consider a continuous relaxation of the combinatorial problem. While existing methods utilizing this approach have shown to be highly effective on small problems (10-100 variables), they do not scale well to large problems. In this work, we draw on ideas from modern convex optimization to design a network and training scheme which scales effortlessly to problems with thousands of variables.
    
[^220]: 用神经Wasserstein梯度流求解带有Riesz核的最大均值差异

    Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with Riesz Kernels. (arXiv:2301.11624v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11624](http://arxiv.org/abs/2301.11624)

    本文提出用神经网络逼近Jordan、Kinderlehrer和Otto的反向方案以及一种前向方案，用于计算非光滑Riesz核最大均值差异函数的Wasserstein梯度流。我们通过学习适当的损失函数来近似处理计划的分解，并在交互能上基准测量神经网络的质量。

    

    非光滑的Riesz核最大均值差异函数的Wasserstein梯度流显示出丰富的结构，奇异测度可以变成绝对连续的测度，反之亦然。本文旨在贡献于对这种流的理解。我们提出用神经网络（NN）逼近Jordan、Kinderlehrer和Otto的反向方案，以计算这种Wasserstein梯度流，同时提出了一种前向方案，用于所谓的Wasserstein最陡下降流。因为我们不能把自己限制在绝对连续的量度上，所以我们必须处理传输计划和速度计划，而不是通常的传输映射和速度场。的确，我们用生成的NN近似了两个计划的分解，这些计划是根据适当的损失函数学习的。为了评估两个神经系统的质量，我们将其基准化为相互作用能。在这里，我们提供了由Dirac测度开始的Wasserstein方案的解析公式。

    Wasserstein gradient flows of maximum mean discrepancy (MMD) functionals with non-smooth Riesz kernels show a rich structure as singular measures can become absolutely continuous ones and conversely. In this paper we contribute to the understanding of such flows. We propose to approximate the backward scheme of Jordan, Kinderlehrer and Otto for computing such Wasserstein gradient flows as well as a forward scheme for so-called Wasserstein steepest descent flows by neural networks (NNs). Since we cannot restrict ourselves to absolutely continuous measures, we have to deal with transport plans and velocity plans instead of usual transport maps and velocity fields. Indeed, we approximate the disintegration of both plans by generative NNs which are learned with respect to appropriate loss functions. In order to evaluate the quality of both neural schemes, we benchmark them on the interaction energy. Here we provide analytic formulas for Wasserstein schemes starting at a Dirac measure and s
    
[^221]: 考虑实际实施挑战的同步全系统状态估计

    Time-Synchronized Full System State Estimation Considering Practical Implementation Challenges. (arXiv:2212.01729v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2212.01729](http://arxiv.org/abs/2212.01729)

    本研究提出了一种基于深度神经网络的状态估计器（DeNSE），利用贝叶斯框架综合利用慢速但广泛存在的SCADA数据和快速但局部的PMU数据，实现了对整个系统的亚秒级状态估计。通过考虑实际挑战，如拓扑变化、非高斯测量噪声和错误数据检测与校正，证明了DeNSE方法的优越性。

    

    由于相量测量装置（PMUs）通常放置在最高电压的母线上，因此许多低电压级别的大规模电力系统无法被其观测到。这种观测缺失使得同步时间状态估计成为一个具有挑战性的问题。我们提出了一种基于深度神经网络的状态估计器（DeNSE），以解决这个问题。该DeNSE采用贝叶斯框架，通过间接结合来自慢时间尺度但普遍存在的监督控制与数据采集（SCADA）数据与快时间尺度但局部的PMU数据的推断，实现对整个系统的亚秒级情景感知。通过考虑拓扑变化、非高斯测量噪声和错误数据检测和校正，展示了所提方法的实际效用。使用IEEE 118-bus系统得到的结果表明了DeNSE在纯SCADA状态估计器、SCADA-PMU混合状态估计器和仅PMU线性状态估计器方面的优越性。

    As phasor measurement units (PMUs) are usually placed on the highest voltage buses, many lower voltage levels of the bulk power system are not observed by them. This lack of visibility makes time-synchronized state estimation of the full system a challenging problem. We propose a Deep Neural network-based State Estimator (DeNSE) to overcome this problem. The DeNSE employs a Bayesian framework to indirectly combine inferences drawn from slow timescale but widespread supervisory control and data acquisition (SCADA) data with fast timescale but local PMU data to attain sub-second situational awareness of the entire system. The practical utility of the proposed approach is demonstrated by considering topology changes, non-Gaussian measurement noise, and bad data detection and correction. The results obtained using the IEEE 118-bus system show the superiority of the DeNSE over a purely SCADA state estimator, a SCADA-PMU hybrid state estimator, and a PMU-only linear state estimator from a te
    
[^222]: 用梯度分割方法缩小SVRG与TD-SVRG之间的差距

    Closing the gap between SVRG and TD-SVRG with Gradient Splitting. (arXiv:2211.16237v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16237](http://arxiv.org/abs/2211.16237)

    本论文通过将TD学习视为适当选择函数的梯度分割，将TD和SVRG相结合，实现了具有几何收敛速度的策略评估方法，并在理论和实验上得到了支持。

    

    TD（时序差分）学习是一种增强学习中的策略评估方法，其性能可以通过方差缩减技术进行增强。最近，多个工作尝试将TD学习与SVRG相结合，以获得一种具有几何收敛速度的策略评估方法。然而，在凸优化设置下，所得到的收敛速度明显不及SVRG。本研究利用最近对TD学习的解释，将其视为一个适当选择函数的梯度的分割，从而简化了算法，并将TD与SVRG相结合。我们的主要结果是一个具有预定学习速率为1/8的几何收敛界限，与凸设置下SVRG的收敛界限相同。我们的理论发现得到了一系列实验证明。

    Temporal difference (TD) learning is a policy evaluation in reinforcement learning whose performance can be enhanced by variance reduction techniques. Recently, multiple works have sought to fuse TD learning with SVRG to obtain a policy evaluation method with a geometric rate of convergence. However, the resulting convergence rate is significantly weaker than what is achieved by SVRG in the setting of convex optimization. In this work we utilize a recent interpretation of TD-learning as the splitting of the gradient of an appropriately chosen function, thus simplifying the algorithm and fusing TD with SVRG. Our main result is a geometric convergence bound with predetermined learning rate of $1/8$, which is identical to the convergence bound available for SVRG in the convex setting. Our theoretical findings are supported by a set of experiments.
    
[^223]: PGCN：用于时空交通预测的渐进图卷积网络

    PGCN: Progressive Graph Convolutional Networks for Spatial-Temporal Traffic Forecasting. (arXiv:2202.08982v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.08982](http://arxiv.org/abs/2202.08982)

    这项研究提出了一种名为渐进图卷积网络（PGCN）的交通预测框架，通过在训练和测试阶段逐步适应输入数据来构建一组图，以解决交通预测中的复杂时空相关性和数据变化问题。

    

    交通网络中复杂的时空相关性使得交通预测问题具有挑战性。由于交通系统本质上具有图结构，因此已经进行了大量关于图神经网络的研究。最近，构建适应性图对数据进行预测在单一静态图结构上的模型上显示了有希望的结果。然而，图适应性仅在训练阶段应用，并不反映训练阶段使用的数据。这种缺点在交通预测中可能有问题，因为交通数据常常存在时间序列中的意外变化和不规则性。在本研究中，我们提出了一种新的交通预测框架，称为渐进图卷积网络（PGCN）。PGCN通过在训练和测试阶段逐步适应输入数据来构建一组图。具体而言，我们实现了该模型来构建渐进行的邻接矩阵。

    The complex spatial-temporal correlations in transportation networks make the traffic forecasting problem challenging. Since transportation system inherently possesses graph structures, much research efforts have been put with graph neural networks. Recently, constructing adaptive graphs to the data has shown promising results over the models relying on a single static graph structure. However, the graph adaptations are applied during the training phases, and do not reflect the data used during the testing phases. Such shortcomings can be problematic especially in traffic forecasting since the traffic data often suffers from the unexpected changes and irregularities in the time series. In this study, we propose a novel traffic forecasting framework called Progressive Graph Convolutional Network (PGCN). PGCN constructs a set of graphs by progressively adapting to input data during the training and the testing phases. Specifically, we implemented the model to construct progressive adjace
    

