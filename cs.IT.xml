<rss version="2.0"><channel><title>Chat Arxiv cs.IT</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.IT</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2303.06526</link><description>&lt;p&gt;
&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Data Dependent Regret Guarantees Against General Comparators for Full or Bandit Feedback. (arXiv:2303.06526v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06526
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a data-dependent online learning algorithm framework that has data-dependent regret guarantees in both full expert feedback and bandit feedback settings, applicable for a wide variety of problem scenarios.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#23436;&#20840;&#22312;&#32447;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20855;&#26377;&#22312;&#20840;&#19987;&#23478;&#21453;&#39304;&#21644;Bandit&#21453;&#39304;&#35774;&#32622;&#20013;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#19968;&#33324;&#27604;&#36739;&#22120;&#30340;&#39044;&#26399;&#24615;&#33021;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#22330;&#26223;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20174;&#36890;&#29992;&#39044;&#27979;&#35282;&#24230;&#24037;&#20316;&#65292;&#20351;&#29992;&#30340;&#24615;&#33021;&#24230;&#37327;&#26159;&#23545;&#20219;&#24847;&#27604;&#36739;&#22120;&#24207;&#21015;&#30340;&#39044;&#26399;&#36951;&#25022;&#65292;&#21363;&#25105;&#20204;&#30340;&#25439;&#22833;&#19982;&#31454;&#20105;&#25439;&#22833;&#24207;&#21015;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#31454;&#20105;&#31867;&#21487;&#20197;&#35774;&#35745;&#20026;&#21253;&#25324;&#22266;&#23450;&#33218;&#36873;&#25321;&#12289;&#20999;&#25442;Bandit&#12289;&#19978;&#19979;&#25991;Bandit&#12289;&#21608;&#26399;Bandit&#25110;&#20219;&#20309;&#20854;&#20182;&#24863;&#20852;&#36259;&#30340;&#31454;&#20105;&#12290;&#31454;&#20105;&#31867;&#20013;&#30340;&#24207;&#21015;&#36890;&#24120;&#30001;&#20855;&#20307;&#24212;&#29992;&#31243;&#24207;&#30830;&#23450;&#65292;&#24182;&#24212;&#30456;&#24212;&#22320;&#35774;&#35745;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26082;&#19981;&#20351;&#29992;&#20063;&#19981;&#38656;&#35201;&#20219;&#20309;&#26377;&#20851;&#25439;&#22833;&#24207;&#21015;&#30340;&#21021;&#27493;&#20449;&#24687;&#65292;&#23436;&#20840;&#22312;&#32447;&#12290;&#20854;
&lt;/p&gt;
&lt;p&gt;
We study the adversarial online learning problem and create a completely online algorithmic framework that has data dependent regret guarantees in both full expert feedback and bandit feedback settings. We study the expected performance of our algorithm against general comparators, which makes it applicable for a wide variety of problem scenarios. Our algorithm works from a universal prediction perspective and the performance measure used is the expected regret against arbitrary comparator sequences, which is the difference between our losses and a competing loss sequence. The competition class can be designed to include fixed arm selections, switching bandits, contextual bandits, periodic bandits or any other competition of interest. The sequences in the competition class are generally determined by the specific application at hand and should be designed accordingly. Our algorithm neither uses nor needs any preliminary information about the loss sequences and is completely online. Its
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;&#12290;</title><link>http://arxiv.org/abs/2303.06411</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;
&lt;/p&gt;
&lt;p&gt;
Deep Reinforcement Learning Based Power Allocation for Minimizing AoI and Energy Consumption in MIMO-NOMA IoT Systems. (arXiv:2303.06411v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06411
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;MIMO-NOMA IoT&#31995;&#32479;&#21151;&#29575;&#20998;&#37197;&#26041;&#27861;&#65292;&#20197;&#26368;&#23567;&#21270;AoI&#21644;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a deep reinforcement learning based power allocation method for MIMO-NOMA IoT systems to minimize AoI and energy consumption.
&lt;/p&gt;
&lt;p&gt;
&#22810;&#36755;&#20837;&#22810;&#36755;&#20986;&#21644;&#38750;&#27491;&#20132;&#22810;&#22336;&#65288;MIMO-NOMA&#65289;&#29289;&#32852;&#32593;&#65288;IoT&#65289;&#31995;&#32479;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20449;&#36947;&#23481;&#37327;&#21644;&#39057;&#35889;&#25928;&#29575;&#65292;&#20197;&#25903;&#25345;&#23454;&#26102;&#24212;&#29992;&#12290;&#26102;&#24310;&#65288;AoI&#65289;&#26159;&#23454;&#26102;&#24212;&#29992;&#30340;&#37325;&#35201;&#25351;&#26631;&#65292;&#20294;&#27809;&#26377;&#25991;&#29486;&#26368;&#23567;&#21270;MIMO-NOMA IoT&#31995;&#32479;&#30340;AoI&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#36827;&#34892;&#36825;&#39033;&#24037;&#20316;&#12290;&#22312;MIMO-NOMA IoT&#31995;&#32479;&#20013;&#65292;&#22522;&#31449;&#65288;BS&#65289;&#30830;&#23450;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#24182;&#20026;&#27599;&#20010;IoT&#35774;&#22791;&#20998;&#37197;&#20256;&#36755;&#21151;&#29575;&#12290;&#27599;&#20010;&#35774;&#22791;&#26681;&#25454;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#30830;&#23450;&#26159;&#21542;&#37319;&#26679;&#25968;&#25454;&#65292;&#24182;&#37319;&#29992;&#20998;&#37197;&#30340;&#21151;&#29575;&#23558;&#37319;&#26679;&#30340;&#25968;&#25454;&#36890;&#36807;MIMO-NOMA&#20449;&#36947;&#20256;&#36755;&#21040;BS&#12290;&#28982;&#21518;&#65292;BS&#37319;&#29992;&#36830;&#32493;&#24178;&#25200;&#28040;&#38500;&#65288;SIC&#65289;&#25216;&#26415;&#35299;&#30721;&#27599;&#20010;&#35774;&#22791;&#20256;&#36755;&#30340;&#25968;&#25454;&#20449;&#21495;&#12290;&#26679;&#26412;&#25910;&#38598;&#35201;&#27714;&#21644;&#21151;&#29575;&#20998;&#37197;&#23558;&#24433;&#21709;&#31995;&#32479;&#30340;AoI&#21644;&#33021;&#32791;&#12290;&#36825;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-input multi-out and non-orthogonal multiple access (MIMO-NOMA) internet-of-things (IoT) systems can improve channel capacity and spectrum efficiency distinctly to support the real-time applications. Age of information (AoI) is an important metric for real-time application, but there is no literature have minimized AoI of the MIMO-NOMA IoT system, which motivates us to conduct this work. In MIMO-NOMA IoT system, the base station (BS) determines the sample collection requirements and allocates the transmission power for each IoT device. Each device determines whether to sample data according to the sample collection requirements and adopts the allocated power to transmit the sampled data to the BS over MIMO-NOMA channel. Afterwards, the BS employs successive interference cancelation (SIC) technique to decode the signal of the data transmitted by each device. The sample collection requirements and power allocation would affect AoI and energy consumption of the system. It is critical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.06381</link><description>&lt;p&gt;
&#23398;&#20064;&#39044;&#32534;&#30721;&#29992;&#20110;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning to Precode for Integrated Sensing and Communications Systems. (arXiv:2303.06381v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#23398;&#20064;&#31070;&#32463;&#27169;&#22411;&#65292;&#29992;&#20110;&#35774;&#35745;&#38598;&#25104;&#24863;&#30693;&#21644;&#36890;&#20449;&#65288;ISAC&#65289;&#31995;&#32479;&#30340;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#65292;&#20197;&#26368;&#22823;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#30446;&#26631;&#29031;&#26126;&#21151;&#29575;&#65292;&#21516;&#26102;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#26368;&#23567;&#20449;&#24178;&#22122;&#27604;&#65288;SINR&#65289;&#12290;&#20174;&#19978;&#34892;&#23548;&#39057;&#21644;&#22238;&#27874;&#20013;&#23398;&#20064;&#20256;&#36755;&#39044;&#32534;&#30721;&#22120;&#30340;&#38382;&#39064;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#21442;&#25968;&#21270;&#20989;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#23398;&#20064;&#36825;&#20010;&#20989;&#25968;&#12290;&#20026;&#20102;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#38454;&#26368;&#20248;&#24615;&#26465;&#20214;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#32435;&#20837;SINR&#21644;&#21151;&#29575;&#32422;&#26463;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#20449;&#36947;&#20272;&#35745;&#35823;&#24046;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#20256;&#32479;&#30340;&#22522;&#20110;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20135;&#29983;&#36739;&#23567;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#30340;&#20449;&#36947;&#26465;&#20214;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#20123;&#26465;&#20214;&#22312;&#35757;&#32451;&#26399;&#38388;&#27809;&#26377;&#26174;&#31034;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present an unsupervised learning neural model to design transmit precoders for integrated sensing and communication (ISAC) systems to maximize the worst-case target illumination power while ensuring a minimum signal-to-interference-plus-noise ratio (SINR) for all the users. The problem of learning transmit precoders from uplink pilots and echoes can be viewed as a parameterized function estimation problem and we propose to learn this function using a neural network model. To learn the neural network parameters, we develop a novel loss function based on the first-order optimality conditions to incorporate the SINR and power constraints. Through numerical simulations, we demonstrate that the proposed method outperforms traditional optimization-based methods in presence of channel estimation errors while incurring lesser computational complexity and generalizing well across different channel conditions that were not shown during training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#26041;&#26696;&#65292;&#36890;&#36807;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2303.06361</link><description>&lt;p&gt;
&#38754;&#21521;&#38750;&#38745;&#24577;&#29615;&#22659;&#30340;&#38544;&#31169;&#20445;&#25252;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#65306;&#32852;&#37030;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Cooperative Visible Light Positioning for Nonstationary Environment: A Federated Learning Perspective. (arXiv:2303.06361v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#26041;&#26696;&#65292;&#36890;&#36807;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a cooperative visible light positioning scheme based on federated learning, which improves the positioning accuracy and generalization capability in nonstationary environments by jointly training a global model adaptive to environmental changes without sharing private data of users.
&lt;/p&gt;
&lt;p&gt;
&#21487;&#35265;&#20809;&#23450;&#20301;&#65288;VLP&#65289;&#20316;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#23460;&#20869;&#23450;&#20301;&#25216;&#26415;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#65292;&#30001;&#20110;&#39640;&#24230;&#26102;&#21464;&#30340;&#20449;&#36947;&#65292;VLP&#30340;&#24615;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#20026;&#20102;&#25552;&#39640;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#30340;&#23450;&#20301;&#31934;&#24230;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#21512;&#20316;VLP&#26041;&#26696;&#12290;&#21033;&#29992;FL&#26694;&#26550;&#65292;&#29992;&#25143;&#21487;&#20197;&#20849;&#21516;&#35757;&#32451;&#36866;&#24212;&#29615;&#22659;&#21464;&#21270;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#32780;&#19981;&#20849;&#20139;&#29992;&#25143;&#30340;&#31169;&#26377;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21512;&#20316;&#21487;&#35265;&#20809;&#23450;&#20301;&#32593;&#32476;&#65288;CVPosNet&#65289;&#65292;&#20197;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#21644;&#25552;&#39640;&#23450;&#20301;&#31934;&#24230;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#26696;&#22312;&#38750;&#38745;&#24577;&#29615;&#22659;&#19979;&#20248;&#20110;&#22522;&#20934;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Visible light positioning (VLP) has drawn plenty of attention as a promising indoor positioning technique. However, in nonstationary environments, the performance of VLP is limited because of the highly time-varying channels. To improve the positioning accuracy and generalization capability in nonstationary environments, a cooperative VLP scheme based on federated learning (FL) is proposed in this paper. Exploiting the FL framework, a global model adaptive to environmental changes can be jointly trained by users without sharing private data of users. Moreover, a Cooperative Visible-light Positioning Network (CVPosNet) is proposed to accelerate the convergence rate and improve the positioning accuracy. Simulation results show that the proposed scheme outperforms the benchmark schemes, especially in nonstationary environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2303.06198</link><description>&lt;p&gt;
&#20811;&#26381;&#24322;&#26041;&#24046;PCA&#20013;&#30149;&#24577;&#38382;&#39064;&#30340;&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deflated HeteroPCA: Overcoming the curse of ill-conditioning in heteroskedastic PCA. (arXiv:2303.06198v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;&#20811;&#26381;&#30149;&#24577;&#38382;&#39064;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel algorithm, called Deflated-HeteroPCA, that overcomes the curse of ill-conditioning in heteroskedastic PCA while achieving near-optimal and condition-number-free theoretical guarantees.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20174;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;X*&#30340;&#21015;&#23376;&#31354;&#38388;&#12290;&#24403;&#23384;&#22312;&#24322;&#26041;&#24046;&#22122;&#22768;&#21644;&#19981;&#24179;&#34913;&#30340;&#32500;&#24230;&#65288;&#21363;n2 &gt;&gt; n1&#65289;&#26102;&#65292;&#22914;&#20309;&#22312;&#23481;&#32435;&#26368;&#24191;&#27867;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#30340;&#21516;&#26102;&#33719;&#24471;&#26368;&#20339;&#30340;&#32479;&#35745;&#31934;&#24230;&#21464;&#24471;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;HeteroPCA&#25104;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24378;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#36973;&#21463;&#20102;&#8220;&#30149;&#24577;&#38382;&#39064;&#30340;&#35781;&#21650;&#8221;&#65292;&#21363;&#38543;&#30528;X*&#30340;&#26465;&#20214;&#25968;&#22686;&#38271;&#65292;&#20854;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#32780;&#19981;&#24433;&#21709;&#20801;&#35768;&#30340;&#20449;&#22122;&#27604;&#33539;&#22260;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32553;&#20943;&#24322;&#26041;&#24046;PCA&#65292;&#23427;&#22312;$\ell_2$&#21644;$\ell_{2,\infty}$&#32479;&#35745;&#31934;&#24230;&#26041;&#38754;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#21644;&#26080;&#26465;&#20214;&#25968;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23558;&#35889;&#20998;&#25104;&#20004;&#37096;&#20998;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with estimating the column subspace of a low-rank matrix $\boldsymbol{X}^\star \in \mathbb{R}^{n_1\times n_2}$ from contaminated data. How to obtain optimal statistical accuracy while accommodating the widest range of signal-to-noise ratios (SNRs) becomes particularly challenging in the presence of heteroskedastic noise and unbalanced dimensionality (i.e., $n_2\gg n_1$). While the state-of-the-art algorithm $\textsf{HeteroPCA}$ emerges as a powerful solution for solving this problem, it suffers from "the curse of ill-conditioning," namely, its performance degrades as the condition number of $\boldsymbol{X}^\star$ grows. In order to overcome this critical issue without compromising the range of allowable SNRs, we propose a novel algorithm, called $\textsf{Deflated-HeteroPCA}$, that achieves near-optimal and condition-number-free theoretical guarantees in terms of both $\ell_2$ and $\ell_{2,\infty}$ statistical accuracy. The proposed algorithm divides the spectrum
&lt;/p&gt;</description></item></channel></rss>