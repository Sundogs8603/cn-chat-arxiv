<rss version="2.0"><channel><title>Chat Arxiv q-fin</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for q-fin</description><item><title>&#35813;&#30740;&#31350;&#21033;&#29992;GPT-4&#21644;BERT&#27169;&#22411;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#65292;&#21457;&#29616;&#22522;&#20110;&#34920;&#24773;&#31526;&#21495;&#24773;&#32490;&#30340;&#31574;&#30053;&#21487;&#20197;&#24110;&#21161;&#36991;&#20813;&#24066;&#22330;&#19979;&#25387;&#24182;&#31283;&#23450;&#22238;&#25253;&#12290;</title><link>https://arxiv.org/abs/2402.10481</link><description>&lt;p&gt;
&#22522;&#20110;&#34920;&#24773;&#31526;&#21495;&#30340;&#21152;&#23494;&#36164;&#20135;&#24066;&#22330;&#21453;&#24212;
&lt;/p&gt;
&lt;p&gt;
Emoji Driven Crypto Assets Market Reactions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10481
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21033;&#29992;GPT-4&#21644;BERT&#27169;&#22411;&#36827;&#34892;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#65292;&#21457;&#29616;&#22522;&#20110;&#34920;&#24773;&#31526;&#21495;&#24773;&#32490;&#30340;&#31574;&#30053;&#21487;&#20197;&#24110;&#21161;&#36991;&#20813;&#24066;&#22330;&#19979;&#25387;&#24182;&#31283;&#23450;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21152;&#23494;&#36135;&#24065;&#39046;&#22495;&#65292;&#35832;&#22914;Twitter&#20043;&#31867;&#30340;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#24050;&#32463;&#25104;&#20026;&#24433;&#21709;&#24066;&#22330;&#36235;&#21183;&#21644;&#25237;&#36164;&#32773;&#24773;&#32490;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;GPT-4&#21644;&#32463;&#36807;&#24494;&#35843;&#30340;&#22522;&#20110;BERT&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#24773;&#24863;&#20998;&#26512;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#24773;&#31526;&#21495;&#24773;&#32490;&#23545;&#21152;&#23494;&#36135;&#24065;&#24066;&#22330;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23558;&#34920;&#24773;&#31526;&#21495;&#36716;&#21270;&#20026;&#21487;&#37327;&#21270;&#30340;&#24773;&#24863;&#25968;&#25454;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#35265;&#35299;&#19982;BTC&#20215;&#26684;&#21644;VCRIX&#25351;&#25968;&#31561;&#20851;&#38190;&#24066;&#22330;&#25351;&#26631;&#36827;&#34892;&#20102;&#30456;&#20851;&#32852;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#24320;&#21457;&#26088;&#22312;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#20803;&#32032;&#35782;&#21035;&#21644;&#39044;&#27979;&#24066;&#22330;&#36235;&#21183;&#30340;&#20132;&#26131;&#31574;&#30053;&#12290;&#20851;&#38190;&#26159;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#34920;&#24773;&#31526;&#21495;&#24773;&#32490;&#30340;&#31574;&#30053;&#21487;&#20197;&#26377;&#21161;&#20110;&#36991;&#20813;&#37325;&#22823;&#24066;&#22330;&#19979;&#25387;&#65292;&#24182;&#26377;&#21161;&#20110;&#22238;&#25253;&#30340;&#31283;&#23450;&#12290;&#36825;&#39033;&#30740;&#31350;&#24378;&#35843;&#20102;&#23558;&#20808;&#36827;&#30340;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#20998;&#26512;&#25972;&#21512;&#21040;&#37329;&#34701;&#31574;&#30053;&#20013;&#30340;&#23454;&#38469;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#26469;&#30475;&#24453;&#24066;&#22330;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10481v1 Announce Type: cross  Abstract: In the burgeoning realm of cryptocurrency, social media platforms like Twitter have become pivotal in influencing market trends and investor sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets. By translating emojis into quantifiable sentiment data, we correlate these insights with key market indicators like BTC Price and the VCRIX index. This approach may be fed into the development of trading strategies aimed at utilizing social media elements to identify and forecast market trends. Crucially, our findings suggest that strategies based on emoji sentiment can facilitate the avoidance of significant market downturns and contribute to the stabilization of returns. This research underscores the practical benefits of integrating advanced AI-driven analyses into financial strategies, offering a nuan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;FourNet&#65292;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#33021;&#22815;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#20855;&#26377;&#24050;&#30693;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#36807;&#28193;&#23494;&#24230;&#65292;&#24182;&#36890;&#36807;&#20005;&#23494;&#30340;&#35823;&#24046;&#20998;&#26512;&#32473;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#21644;&#38750;&#36127;&#24615;&#25439;&#22833;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2309.03966</link><description>&lt;p&gt;
&#37329;&#34701;&#20013;&#20613;&#37324;&#21494;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#36807;&#28193;&#23494;&#24230;
&lt;/p&gt;
&lt;p&gt;
Fourier Neural Network Approximation of Transition Densities in Finance. (arXiv:2309.03966v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;FourNet&#65292;&#19968;&#31181;&#20351;&#29992;&#39640;&#26031;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#33021;&#22815;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#20855;&#26377;&#24050;&#30693;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#36807;&#28193;&#23494;&#24230;&#65292;&#24182;&#36890;&#36807;&#20005;&#23494;&#30340;&#35823;&#24046;&#20998;&#26512;&#32473;&#20986;&#20102;&#20272;&#35745;&#35823;&#24046;&#21644;&#38750;&#36127;&#24615;&#25439;&#22833;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;FourNet&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#23618;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFNN&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#36924;&#36817;&#20855;&#26377;&#23553;&#38381;&#24418;&#24335;&#30340;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;&#21363;&#29305;&#24449;&#20989;&#25968;&#65289;&#21487;&#29992;&#30340;&#36807;&#28193;&#23494;&#24230;&#12290;FourNet&#30340;&#19968;&#20010;&#29420;&#29305;&#29305;&#28857;&#22312;&#20110;&#23427;&#20351;&#29992;&#20102;&#39640;&#26031;&#28608;&#27963;&#20989;&#25968;&#65292;&#20351;&#24471;&#31934;&#30830;&#30340;&#20613;&#37324;&#21494;&#21644;&#36870;&#20613;&#37324;&#21494;&#21464;&#25442;&#25104;&#20026;&#21487;&#33021;&#65292;&#24182;&#19982;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#31867;&#27604;&#12290;&#25105;&#20204;&#20174;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;FourNet&#33021;&#22815;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#36807;&#28193;&#23494;&#24230;&#65292;&#24182;&#20165;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#31070;&#32463;&#20803;&#12290;FourNet&#30340;&#21442;&#25968;&#36890;&#36807;&#26368;&#23567;&#21270;&#22522;&#20110;&#24050;&#30693;&#29305;&#24449;&#20989;&#25968;&#21644;FFNN&#30340;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#23398;&#20064;&#65292;&#21516;&#26102;&#37319;&#29992;&#20102;&#31574;&#30053;&#24615;&#37319;&#26679;&#26041;&#27861;&#26469;&#22686;&#24378;&#35757;&#32451;&#12290;&#36890;&#36807;&#20005;&#23494;&#32780;&#20840;&#38754;&#30340;&#35823;&#24046;&#20998;&#26512;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;$L_2$&#20272;&#35745;&#35823;&#24046;&#21644;&#20272;&#35745;&#23494;&#24230;&#20013;&#38750;&#36127;&#24615;&#30340;&#28508;&#22312;&#65288;&#36880;&#28857;&#65289;&#25439;&#22833;&#30340;&#20449;&#24687;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces FourNet, a novel single-layer feed-forward neural network (FFNN) method designed to approximate transition densities for which closed-form expressions of their Fourier transforms, i.e. characteristic functions, are available. A unique feature of FourNet lies in its use of a Gaussian activation function, enabling exact Fourier and inverse Fourier transformations and drawing analogies with the Gaussian mixture model. We mathematically establish FourNet's capacity to approximate transition densities in the $L_2$-sense arbitrarily well with finite number of neurons. The parameters of FourNet are learned by minimizing a loss function derived from the known characteristic function and the Fourier transform of the FFNN, complemented by a strategic sampling approach to enhance training. Through a rigorous and comprehensive error analysis, we derive informative bounds for the $L_2$ estimation error and the potential (pointwise) loss of nonnegativity in the estimated densit
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#22914;&#20309;&#36816;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#20013;&#25991;&#26032;&#38395;&#25991;&#26412;&#20449;&#24687;&#30340;&#24773;&#24863;&#22240;&#32032;&#65292;&#20197;&#26399;&#20419;&#36827;&#30693;&#24773;&#21644;&#39640;&#39057;&#30340;&#25237;&#36164;&#32452;&#21512;&#35843;&#25972;&#12290;&#36890;&#36807;&#24314;&#31435;&#20005;&#26684;&#21644;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#19982;&#26631;&#20934;&#21270;&#30340;&#22238;&#27979;&#26694;&#26550;&#65292;&#20316;&#32773;&#23545;&#19981;&#21516;&#31867;&#22411; LLMs &#22312;&#35813;&#39046;&#22495;&#20869;&#30340;&#25928;&#26524;&#36827;&#34892;&#20102;&#23458;&#35266;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.14222</link><description>&lt;p&gt;
&#25581;&#31034;&#24773;&#24863;&#30340;&#28508;&#21147;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#39044;&#27979;&#20013;&#22269;&#32929;&#31080;&#20215;&#26684;&#27874;&#21160;&#65311;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?. (arXiv:2306.14222v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14222
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#22914;&#20309;&#36816;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25552;&#21462;&#20013;&#25991;&#26032;&#38395;&#25991;&#26412;&#20449;&#24687;&#30340;&#24773;&#24863;&#22240;&#32032;&#65292;&#20197;&#26399;&#20419;&#36827;&#30693;&#24773;&#21644;&#39640;&#39057;&#30340;&#25237;&#36164;&#32452;&#21512;&#35843;&#25972;&#12290;&#36890;&#36807;&#24314;&#31435;&#20005;&#26684;&#21644;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#19982;&#26631;&#20934;&#21270;&#30340;&#22238;&#27979;&#26694;&#26550;&#65292;&#20316;&#32773;&#23545;&#19981;&#21516;&#31867;&#22411; LLMs &#22312;&#35813;&#39046;&#22495;&#20869;&#30340;&#25928;&#26524;&#36827;&#34892;&#20102;&#23458;&#35266;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLMs) &#30340;&#24555;&#36895;&#21457;&#23637;&#24050;&#24341;&#21457;&#20102;&#24191;&#27867;&#30340;&#35752;&#35770;&#65292;&#20854;&#20013;&#21253;&#25324;&#23427;&#20204;&#23558;&#22914;&#20309;&#25552;&#39640;&#37327;&#21270;&#32929;&#31080;&#20132;&#26131;&#31574;&#30053;&#30340;&#22238;&#25253;&#30340;&#28508;&#21147;&#12290;&#36825;&#20123;&#35752;&#35770;&#20027;&#35201;&#22260;&#32469;&#30528;&#21033;&#29992; LLMs &#30340;&#20986;&#33394;&#29702;&#35299;&#33021;&#21147;&#26469;&#25552;&#21462;&#24773;&#24863;&#22240;&#32032;&#65292;&#20174;&#32780;&#20419;&#36827;&#30693;&#24773;&#21644;&#39640;&#39057;&#30340;&#25237;&#36164;&#32452;&#21512;&#35843;&#25972;&#12290;&#20026;&#20102;&#30830;&#20445;&#36825;&#20123; LLMs &#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#20013;&#22269;&#37329;&#34701;&#25991;&#26412;&#20998;&#26512;&#21644;&#38543;&#21518;&#30340;&#20013;&#22269;&#32929;&#31080;&#24066;&#22330;&#20132;&#26131;&#31574;&#30053;&#24320;&#21457;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20005;&#26684;&#21644;&#20840;&#38754;&#30340;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#19968;&#20010;&#26631;&#20934;&#21270;&#30340;&#22238;&#27979;&#26694;&#26550;&#65292;&#26088;&#22312;&#23458;&#35266;&#35780;&#20272;&#19981;&#21516;&#31867;&#22411; LLMs &#22312;&#20013;&#25991;&#26032;&#38395;&#25991;&#26412;&#25968;&#25454;&#30340;&#24773;&#24863;&#22240;&#32032;&#25552;&#21462;&#20013;&#30340;&#25928;&#26524;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#22522;&#20934;&#27979;&#35797;&#30340;&#24037;&#20316;&#26041;&#24335;&#65292;&#25105;&#20204;&#24341;&#29992;&#20102;&#19977;&#20010;&#19981;&#21516;&#27169;&#22411;&#65306;1&#65289;&#29983;&#25104;&#24335; LLM (ChatGPT)&#65292;2&#65289;&#20013;&#25991;&#35821;&#35328;&#29305;&#23450;&#30340;&#39044;&#35757;&#32451; LLM (&#20108;&#37070;&#31070; RoBERTa)&#65292;&#20197;&#21450;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
The rapid advancement of Large Language Models (LLMs) has led to extensive discourse regarding their potential to boost the return of quantitative stock trading strategies. This discourse primarily revolves around harnessing the remarkable comprehension capabilities of LLMs to extract sentiment factors which facilitate informed and high-frequency investment portfolio adjustments. To ensure successful implementations of these LLMs into the analysis of Chinese financial texts and the subsequent trading strategy development within the Chinese stock market, we provide a rigorous and encompassing benchmark as well as a standardized back-testing framework aiming at objectively assessing the efficacy of various types of LLMs in the specialized domain of sentiment factor extraction from Chinese news text data. To illustrate how our benchmark works, we reference three distinctive models: 1) the generative LLM (ChatGPT), 2) the Chinese language-specific pre-trained LLM (Erlangshen-RoBERTa), and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#32463;&#20856;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#25193;&#23637;&#21040;&#22343;&#20540;-&#26041;&#24046;&#35774;&#32622;&#65292;&#24182;&#36890;&#36807;&#32771;&#34385;&#20122;&#39640;&#26031;&#33218;&#25918;&#26494;&#20102;&#20808;&#21069;&#20551;&#35774;&#65292;&#35299;&#20915;&#20102;&#39118;&#38505;-&#22238;&#25253;&#26435;&#34913;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2212.09192</link><description>&lt;p&gt;
&#22343;&#20540;-&#26041;&#24046;&#35774;&#32622;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multiarmed Bandits Problem Under the Mean-Variance Setting. (arXiv:2212.09192v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#32463;&#20856;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#25193;&#23637;&#21040;&#22343;&#20540;-&#26041;&#24046;&#35774;&#32622;&#65292;&#24182;&#36890;&#36807;&#32771;&#34385;&#20122;&#39640;&#26031;&#33218;&#25918;&#26494;&#20102;&#20808;&#21069;&#20551;&#35774;&#65292;&#35299;&#20915;&#20102;&#39118;&#38505;-&#22238;&#25253;&#26435;&#34913;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#38382;&#39064;&#28041;&#21450;&#19968;&#20010;&#23398;&#20064;&#32773;&#21644;&#19968;&#20010;&#21253;&#21547;K&#20010;&#29420;&#31435;&#33218;&#30340;&#38598;&#21512;&#65292;&#27599;&#20010;&#33218;&#37117;&#26377;&#33258;&#24049;&#30340;&#20107;&#21069;&#26410;&#30693;&#29420;&#31435;&#22870;&#21169;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#27425;&#36873;&#25321;&#20013;&#30340;&#27599;&#19968;&#27425;&#65292;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#33218;&#24182;&#25509;&#25910;&#26032;&#20449;&#24687;&#12290;&#23398;&#20064;&#32773;&#32463;&#24120;&#38754;&#20020;&#19968;&#20010;&#21208;&#25506;-&#24320;&#21457;&#22256;&#22659;&#65306;&#36890;&#36807;&#29609;&#20272;&#35745;&#22870;&#21169;&#26368;&#39640;&#30340;&#33218;&#26469;&#21033;&#29992;&#24403;&#21069;&#20449;&#24687;&#65292;&#36824;&#26159;&#25506;&#32034;&#25152;&#26377;&#33218;&#20197;&#25910;&#38598;&#26356;&#22810;&#22870;&#21169;&#20449;&#24687;&#12290;&#35774;&#35745;&#30446;&#26631;&#26088;&#22312;&#26368;&#22823;&#21270;&#25152;&#26377;&#22238;&#21512;&#20013;&#30340;&#26399;&#26395;&#32047;&#31215;&#22870;&#21169;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#30446;&#26631;&#24182;&#19981;&#32771;&#34385;&#39118;&#38505;-&#22238;&#25253;&#26435;&#34913;&#65292;&#32780;&#36825;&#22312;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#37329;&#34701;&#21644;&#32463;&#27982;&#39046;&#22495;&#65292;&#24120;&#24120;&#26159;&#19968;&#39033;&#22522;&#26412;&#21407;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;Sani&#31561;&#20154;&#65288;2012&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#23558;&#32463;&#20856;&#30340;MAB&#38382;&#39064;&#25193;&#23637;&#21040;&#22343;&#20540;-&#26041;&#24046;&#35774;&#32622;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#20122;&#39640;&#26031;&#33218;&#25918;&#26494;&#20102;Sani&#31561;&#20154;&#65288;2012&#65289;&#20570;&#20986;&#30340;&#29420;&#31435;&#33218;&#21644;&#26377;&#30028;&#22870;&#21169;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
The classical multi-armed bandit (MAB) problem involves a learner and a collection of K independent arms, each with its own ex ante unknown independent reward distribution. At each one of a finite number of rounds, the learner selects one arm and receives new information. The learner often faces an exploration-exploitation dilemma: exploiting the current information by playing the arm with the highest estimated reward versus exploring all arms to gather more reward information. The design objective aims to maximize the expected cumulative reward over all rounds. However, such an objective does not account for a risk-reward tradeoff, which is often a fundamental precept in many areas of applications, most notably in finance and economics. In this paper, we build upon Sani et al. (2012) and extend the classical MAB problem to a mean-variance setting. Specifically, we relax the assumptions of independent arms and bounded rewards made in Sani et al. (2012) by considering sub-Gaussian arms.
&lt;/p&gt;</description></item></channel></rss>