# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](https://arxiv.org/abs/2404.01012) | 提出了一种使用自动生成的相关性判断的查询性能预测框架，能够解决先前方法中对不同IR评估指标准确性和解释性的限制。 |
| [^2] | [RATSF: Empowering Customer Service Volume Management through Retrieval-Augmented Time-Series Forecasting](https://arxiv.org/abs/2403.04180) | 提出了一种检索增强时序序列预测框架(RATSF)，通过引入交叉注意力模块(RACA)及知识库设计，有效利用历史数据段进行客服量预测，在非平稳数据情况下显著提升了性能。 |
| [^3] | [InteraRec: Interactive Recommendations Using Multimodal Large Language Models](https://arxiv.org/abs/2403.00822) | InteraRec引入了一种复杂的交互式推荐框架，与传统方法不同，它不仅依赖Weblog生成推荐，还捕获用户导航时网页的高频截图。 |
| [^4] | [Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision](https://arxiv.org/abs/2402.16508) | 本研究提出了一种基于自监督方法的单个编码-解码模型来解决跨语言问答问题，通过利用维基百科内的跨语言链接结构合成监督信号，取得了优于其他方法的效果。 |
| [^5] | [Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding](https://arxiv.org/abs/2207.01262) | 在标准收集的初步实验中，我们发现长文档模型在MRR或NDCG方面性能不佳，表现低于FirstP，或平均最多超越5％。我们推测这不是因为模型无法处理长上下文，而是由于相关段落具有位置偏见，往往位于前512个文档标记之中。我们找到证据表明这种偏见至少存在于两个测试集中，这促使我们创建了一个新的收集MS MARCO FarRelevant，其中包含 |
| [^6] | [Denoising Diffusion Recommender Model.](http://arxiv.org/abs/2401.06982) | 该论文提出了一种去噪扩散推荐模型（DDRM），通过在推荐模型中注入噪声并利用扩散模型进行多步去噪过程，增强用户和项目嵌入的鲁棒性。 |
| [^7] | [Unlock Multi-Modal Capability of Dense Retrieval via Visual Module Plugin.](http://arxiv.org/abs/2310.14037) | 本文介绍了一种名为MARVEL的多模态检索模型，通过视觉模块插件为密集检索器添加图像理解能力，并且在多模态检索任务中取得了显著优于最先进方法的结果。 |
| [^8] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^9] | [The Family Tree Graph as a Predictor of the Family Members' Satisfaction with One Another.](http://arxiv.org/abs/2305.01552) | 该研究发现家庭成员满意度与家族树图，家庭规模，孩子是否为同父母，以及家庭收入有关。 |
| [^10] | [RLTP: Reinforcement Learning to Pace for Delayed Impression Modeling in Preloaded Ads.](http://arxiv.org/abs/2302.02592) | RLTP算法是一个强化学习算法，用于解决广告预加载过程中的延迟印象现象。 |

# 详细

[^1]: 使用大型语言模型生成的相关性判断来预测查询性能

    Query Performance Prediction using Relevance Judgments Generated by Large Language Models

    [https://arxiv.org/abs/2404.01012](https://arxiv.org/abs/2404.01012)

    提出了一种使用自动生成的相关性判断的查询性能预测框架，能够解决先前方法中对不同IR评估指标准确性和解释性的限制。

    

    查询性能预测（QPP）旨在估计搜索系统对查询的检索质量，而无需人工相关性判断。先前的QPP方法通常返回单个标量值，并不要求预测值接近特定的信息检索（IR）评估指标，从而导致以下某些缺点：（i）单个标量无法准确表示不同的IR评估指标，特别是当度量不高度相关时，（ii）单个标量限制了QPP方法的可解释性，因为仅使用标量无法解释QPP结果。为解决这些问题，我们提出了一个使用自动生成的相关性判断的QPP框架（QPP-GenRE），将QPP分解为独立的子任务，即对排名列表中每个项目对给定查询的相关性进行判断。这样我们可以使用生成的相关性判断来预测任何IR评估指标。

    arXiv:2404.01012v1 Announce Type: cross  Abstract: Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of judging the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgment
    
[^2]: RATSF：通过检索增强时间序列预测来赋能客服量管理

    RATSF: Empowering Customer Service Volume Management through Retrieval-Augmented Time-Series Forecasting

    [https://arxiv.org/abs/2403.04180](https://arxiv.org/abs/2403.04180)

    提出了一种检索增强时序序列预测框架(RATSF)，通过引入交叉注意力模块(RACA)及知识库设计，有效利用历史数据段进行客服量预测，在非平稳数据情况下显著提升了性能。

    

    一个高效的客服管理系统取决于对服务量的精确预测。在这种数据非平稳性明显的情况下，成功的预测严重依赖于识别和利用类似的历史数据，而不仅仅是总结周期性模式。现有基于RNN或Transformer架构的模型通常在灵活和有效利用方面存在挑战。为了解决这一挑战，我们提出了一种高效且可适应的交叉注意力模块，称为RACA，它在预测任务中有效利用了历史段，并设计了一个精确的历史序列查询表示方案，结合了知识库的设计。这些关键组件共同构成了我们的检索增强时序序列预测框架（RATSF）。RATSF不仅在菲鸡酒店服务量预测环境中显著增强了性能，而且...

    arXiv:2403.04180v1 Announce Type: new  Abstract: An efficient customer service management system hinges on precise forecasting of service volume. In this scenario, where data non-stationarity is pronounced, successful forecasting heavily relies on identifying and leveraging similar historical data rather than merely summarizing periodic patterns. Existing models based on RNN or Transformer architectures often struggle with this flexible and effective utilization. To address this challenge, we propose an efficient and adaptable cross-attention module termed RACA, which effectively leverages historical segments in forecasting task, and we devised a precise representation scheme for querying historical sequences, coupled with the design of a knowledge repository. These critical components collectively form our Retrieval-Augmented Temporal Sequence Forecasting framework (RATSF). RATSF not only significantly enhances performance in the context of Fliggy hotel service volume forecasting but,
    
[^3]: InteraRec：使用多模式大型语言模型进行交互式推荐

    InteraRec: Interactive Recommendations Using Multimodal Large Language Models

    [https://arxiv.org/abs/2403.00822](https://arxiv.org/abs/2403.00822)

    InteraRec引入了一种复杂的交互式推荐框架，与传统方法不同，它不仅依赖Weblog生成推荐，还捕获用户导航时网页的高频截图。

    

    Weblog由记录任何网站上用户活动的记录组成，可以为用户偏好、行为和兴趣提供宝贵的见解。许多推荐算法利用通过这些Weblog挖掘的数据，采用协同过滤、基于内容的过滤和混合方法等策略，为用户提供个性化推荐。本研究引入了一种称为InteraRec的复杂交互式推荐框架，它不同于传统方法，后者仅依赖Weblog生成推荐。该框架捕获用户导航时网页的高频截图。

    arXiv:2403.00822v1 Announce Type: cross  Abstract: Weblogs, comprised of records detailing user activities on any website, offer valuable insights into user preferences, behavior, and interests. Numerous recommendation algorithms, employing strategies such as collaborative filtering, content-based filtering, and hybrid methods, leverage the data mined through these weblogs to provide personalized recommendations to users. Despite the abundance of information available in these weblogs, identifying and extracting pertinent information and key features necessitates extensive engineering endeavors. The intricate nature of the data also poses a challenge for interpretation, especially for non-experts. In this study, we introduce a sophisticated and interactive recommendation framework denoted as InteraRec, which diverges from conventional approaches that exclusively depend on weblogs for recommendation generation. This framework captures high-frequency screenshots of web pages as users nav
    
[^4]: 使用大规模合成监督进行跨语言开放域问答的预训练

    Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision

    [https://arxiv.org/abs/2402.16508](https://arxiv.org/abs/2402.16508)

    本研究提出了一种基于自监督方法的单个编码-解码模型来解决跨语言问答问题，通过利用维基百科内的跨语言链接结构合成监督信号，取得了优于其他方法的效果。

    

    跨语言问答（CLQA）是一个复杂的问题，包括从多语言知识库进行跨语言检索，然后在英语或查询语言中生成答案。本文展示了可以使用单个编码-解码模型来解决CLQA。为了有效训练这个模型，我们提出了一种基于利用维基百科内跨语言链接结构的自监督方法。我们展示了如何利用链接的维基百科页面来合成跨语言检索的监督信号，通过一种填空查询形式生成更自然的查询以监督答案生成。最后，我们展示了我们的方法CLASS在监督学习和零-shot情况下均优于可比方法。

    arXiv:2402.16508v1 Announce Type: new  Abstract: Cross-lingual question answering (CLQA) is a complex problem, comprising cross-lingual retrieval from a multilingual knowledge base, followed by answer generation either in English or the query language. Both steps are usually tackled by separate models, requiring substantial annotated datasets, and typically auxiliary resources, like machine translation systems to bridge between languages. In this paper, we show that CLQA can be addressed using a single encoder-decoder model. To effectively train this model, we propose a self-supervised method based on exploiting the cross-lingual link structure within Wikipedia. We demonstrate how linked Wikipedia pages can be used to synthesise supervisory signals for cross-lingual retrieval, through a form of cloze query, and generate more natural queries to supervise answer generation. Together, we show our approach, \texttt{CLASS}, outperforms comparable methods on both supervised and zero-shot lan
    
[^5]: 通过全面评估和Leaderboarding理解长文档排名模型的性能

    Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding

    [https://arxiv.org/abs/2207.01262](https://arxiv.org/abs/2207.01262)

    在标准收集的初步实验中，我们发现长文档模型在MRR或NDCG方面性能不佳，表现低于FirstP，或平均最多超越5％。我们推测这不是因为模型无法处理长上下文，而是由于相关段落具有位置偏见，往往位于前512个文档标记之中。我们找到证据表明这种偏见至少存在于两个测试集中，这促使我们创建了一个新的收集MS MARCO FarRelevant，其中包含

    

    我们评估了20多个用于长文档排名的Transformer模型（包括最近使用FlashAttention训练的LongP模型），并将它们与简单的FirstP基线进行了比较（将相同模型应用于输入截断为前512个标记）。我们使用MS MARCO文档v1作为主要训练集，并在零-shot场景下评估了模型，以及在对其他收集进行微调后评估了模型。

    arXiv:2207.01262v2 Announce Type: replace-cross  Abstract: We evaluated 20+ Transformer models for ranking of long documents (including recent LongP models trained with FlashAttention) and compared them with simple FirstP baselines (applying the same model to input truncated to the first 512 tokens). We used MS MARCO Documents v1 as a primary training set and evaluated models in the zero-shot scenario as well as after fine-tuning on other collections.   In our initial experiments with standard collections we found that long-document models underperformed FirstP or outperformed it by at most 5% on average in terms of MRR or NDCG. We then conjectured that this was not due to models inability to process long context but rather due to a positional bias of relevant passages, which tended to be among the first 512 document tokens. We found evidence that this bias was, indeed, present in at least two test sets, which motivated us to create a new collection MS MARCO FarRelevant where the relev
    
[^6]: 去噪扩散推荐模型

    Denoising Diffusion Recommender Model. (arXiv:2401.06982v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2401.06982](http://arxiv.org/abs/2401.06982)

    该论文提出了一种去噪扩散推荐模型（DDRM），通过在推荐模型中注入噪声并利用扩散模型进行多步去噪过程，增强用户和项目嵌入的鲁棒性。

    

    推荐系统通常面临着具有噪声的隐式反馈问题。大多数研究从数据清洗的角度缓解噪声问题，如数据重新采样和重新加权，但它们受到启发式假设的限制。另一种去噪方法是从模型的角度，积极地向用户-项目交互中注入噪声，并增强模型的内在去噪能力。然而，这种去噪过程对推荐模型的表示能力来捕捉噪声模式提出了显著挑战。为了解决这个问题，我们提出了去噪扩散推荐模型（DDRM），它基于扩散模型使用多步去噪过程来增强来自任何推荐模型的用户和项目嵌入的鲁棒性。DDRM在前向过程中注入受控高斯噪声，并在反向去噪过程中迭代地去除噪声，从而提高对噪声反馈的嵌入鲁棒性。为了实现这一目标，关键在于提供一种能够捕捉噪声模式的扩散模型，并通过多步去噪过程来改善嵌入。

    Recommender systems often grapple with noisy implicit feedback. Most studies alleviate the noise issues from data cleaning perspective such as data resampling and reweighting, but they are constrained by heuristic assumptions. Another denoising avenue is from model perspective, which proactively injects noises into user-item interactions and enhance the intrinsic denoising ability of models. However, this kind of denoising process poses significant challenges to the recommender model's representation capacity to capture noise patterns. To address this issue, we propose Denoising Diffusion Recommender Model (DDRM), which leverages multi-step denoising process based on diffusion models to robustify user and item embeddings from any recommender models. DDRM injects controlled Gaussian noises in the forward process and iteratively removes noises in the reverse denoising process, thereby improving embedding robustness against noisy feedback. To achieve this target, the key lies in offering 
    
[^7]: 通过视觉模块插件解锁密集检索的多模态能力

    Unlock Multi-Modal Capability of Dense Retrieval via Visual Module Plugin. (arXiv:2310.14037v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.14037](http://arxiv.org/abs/2310.14037)

    本文介绍了一种名为MARVEL的多模态检索模型，通过视觉模块插件为密集检索器添加图像理解能力，并且在多模态检索任务中取得了显著优于最先进方法的结果。

    

    本文提出了通过视觉模块插件（MARVEL）学习查询和多模态文档的嵌入空间以进行检索的多模态检索模型。MARVEL使用统一的编码器模型对查询和多模态文档进行编码，有助于减小图像和文本之间的模态差距。具体而言，我们通过将视觉模块编码的图像特征作为其输入，使得经过训练的密集检索器T5-ANCE具有图像理解能力。为了促进多模态检索任务，我们基于ClueWeb22数据集构建了ClueWeb22-MM数据集，将锚文本作为查询，并从锚链接的网页中提取相关文本和图像文档。实验证明，MARVEL在多模态检索数据集WebQA和ClueWeb22-MM上明显优于最先进的方法。进一步的分析表明，视觉模块插件方法为实现图像理解能力量身定制。

    This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL) to learn an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of a well-trained dense retriever, T5-ANCE, by incorporating the image features encoded by the visual module as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and exact the related texts and image documents from anchor linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. Our further analyses show that the visual module plugin method is tailored to enable the image understanding ability for an 
    
[^8]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^9]: 家族树图与家庭成员满意度之间的关系研究

    The Family Tree Graph as a Predictor of the Family Members' Satisfaction with One Another. (arXiv:2305.01552v1 [physics.soc-ph])

    [http://arxiv.org/abs/2305.01552](http://arxiv.org/abs/2305.01552)

    该研究发现家庭成员满意度与家族树图，家庭规模，孩子是否为同父母，以及家庭收入有关。

    

    个人对核心家庭和扩展家庭的满意度在一个人的日常生活中扮演着至关重要的角色。因此，更好地了解决定一个人对家庭满意度的特征可以为更好的社会政策设计打开大门。为此，该研究考察了家族树图与家庭成员对核心家庭和扩展家庭的满意度之间的关系。我们收集了来自486个家庭的数据，其中包括家族树图和家庭成员之间的满意度。我们得到了一个能够解释75%家庭成员对彼此满意度的模型。我们发现了让家庭成员更加满意的三个指标。首先，平均而言，较大的家庭有更满意的成员。此外，没有继兄弟姐妹的同父母家庭-即成年子女已经成家的家庭，在兄弟姐妹和父母方面也更满意。最后，家庭成员的平均满意度和家庭的收入水平息息相关。

    Individuals' satisfaction with their nuclear and extended family plays a critical role in individuals everyday life. Thus, a better understanding of the features that determine one's satisfaction with her family can open the door to the design of better sociological policies. To this end, this study examines the relationship between the family tree graph and family members' satisfaction with their nuclear and extended family. We collected data from 486 families which included a family tree graph and family members' satisfaction with each other. We obtain a model that is able to explain 75\% of the family members' satisfaction with one another. We found three indicators for more satisfied families. First, larger families, on average, have more satisfied members. Moreover, families with kids from the same parents - i.e., without step-siblings also express more satisfaction from both their siblings and parents when the children are already adults. Lastly, the average satisfaction of the f
    
[^10]: RLTP算法：用于预加载广告中的延迟印象建模的强化学习算法

    RLTP: Reinforcement Learning to Pace for Delayed Impression Modeling in Preloaded Ads. (arXiv:2302.02592v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.02592](http://arxiv.org/abs/2302.02592)

    RLTP算法是一个强化学习算法，用于解决广告预加载过程中的延迟印象现象。

    

    为了增加品牌知名度，许多广告商与广告平台签订合同购买广告流量，然后将广告投放到目标受众中。在整个广告投放期间，广告商通常希望广告获得特定的印象数，并期望广告展示的效果越好越好（如高点击率）。广告平台通过实时调整流量请求的选择概率来满足需求。然而，发布者的策略也会影响广告投放过程，这是广告平台无法控制的。预加载是许多类型广告（如视频广告）的常用策略，以确保在流量请求后显示的响应时间是合理的，这将导致延迟印象现象。传统的配速算法无法很好地处理预加载的特性，因为它们依赖于即时反馈信号。

    To increase brand awareness, many advertisers conclude contracts with advertising platforms to purchase traffic and then deliver advertisements to target audiences. In a whole delivery period, advertisers usually desire a certain impression count for the ads, and they also expect that the delivery performance is as good as possible (e.g., obtaining high click-through rate). Advertising platforms employ pacing algorithms to satisfy the demands via adjusting the selection probabilities to traffic requests in real-time. However, the delivery procedure is also affected by the strategies from publishers, which cannot be controlled by advertising platforms. Preloading is a widely used strategy for many types of ads (e.g., video ads) to make sure that the response time for displaying after a traffic request is legitimate, which results in delayed impression phenomenon. Traditional pacing algorithms cannot handle the preloading nature well because they rely on immediate feedback signals, and m
    

