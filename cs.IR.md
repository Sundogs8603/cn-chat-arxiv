# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Analyzing Coherency in Facet-based Clarification Prompt Generation for Search.](http://arxiv.org/abs/2401.04524) | 本研究关注基于维度的搜索澄清提示生成中的维度质量和相关性的重要性，并提出了一个相关性分类器来评估澄清过程中存在的维度相关性问题。 |
| [^2] | [Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search.](http://arxiv.org/abs/2401.04514) | 本论文提出一种扩展的生成增强检索（GAR）框架，通过对代码进行重写来解决代码搜索中存在的风格不匹配问题，实验结果表明该方法显著提高了检索准确性。 |
| [^3] | [Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems.](http://arxiv.org/abs/2401.04474) | 本论文介绍了一种使用基于嵌入和基于语义的模型相结合的方法来生成推荐系统中的事后解释，并利用基于本体的知识图谱来提高可解释性。这样的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度。 |
| [^4] | [Privacy-Preserving Sequential Recommendation with Collaborative Confusion.](http://arxiv.org/abs/2401.04423) | 该论文提出了一种基于协同混淆的隐私保护顺序推荐方法，通过注入不可区分的项目来增加目标序列的困惑度，从而提高隐私保护性能。 |
| [^5] | [Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems.](http://arxiv.org/abs/2401.04408) | 本文提出了一种细粒度嵌入维度优化方法（FIITED），能够在推荐系统的训练过程中根据嵌入向量的重要性不断调整其维度，并设计了一种虚拟哈希索引哈希表的嵌入存储系统以有效节省内存。 |
| [^6] | [G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale Recommender Systems.](http://arxiv.org/abs/2401.04338) | 本文提出了一个用于大规模推荐系统中的GPU集群分布式元学习的高性能框架G-Meta，通过利用数据并行性和模型并行性以及设计高效的元-IO流水线，实现了高速分布式训练。 |
| [^7] | [Divergent Characteristics of Biomedical Research across Publication Types: A Quantitative Analysis on the Aging-related Research.](http://arxiv.org/abs/2401.04323) | 本研究分析了老龄相关基因研究中不同出版类型的特征差异，发现这些出版类型在对老龄化研究的关注度、研究基因的范围和主题偏好上存在显著差异。尽管存在差异，一些顶级基因如胰岛素普遍受到重视，而且出版类型在研究基因方面也呈现相似的不平衡水平。另外，出版类型还在作者数量、引用数量等方面存在差异。 |
| [^8] | [Prompt-based Multi-interest Learning Method for Sequential Recommendation.](http://arxiv.org/abs/2401.04312) | 提出了一种基于提示的多兴趣学习方法（PoMRec），用于顺序推荐。该方法通过利用具体的提示来指导兴趣提取和权重预测模块的学习，以克服现有方法中存在的限制。 |
| [^9] | [An AI-based solution for the cold start and data sparsity problems in the recommendation systems.](http://arxiv.org/abs/2312.01840) | 这项研究提出了一个基于人工智能的解决方案，用于解决推荐系统中的冷启动和数据稀疏问题，以应对信息超载带来的挑战。 |
| [^10] | [VKIE: The Application of Key Information Extraction on Video Text.](http://arxiv.org/abs/2310.11650) | 本文提出了一项重要任务，即从视频文本中提取层次化关键信息。研究者们通过拆分任务为四个子任务，并介绍了两种实现方案，即PipVKIE和UniVKIE。两种方案都利用了视觉、文本和坐标的多模态信息进行特征表示。实验证明，这些方案在性能和推理速度方面表现出色。 |
| [^11] | [FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning.](http://arxiv.org/abs/2309.08420) | 提出了一种名为FedDCSR的联邦跨领域顺序推荐框架，通过解缠表示学习来处理不同领域之间的序列特征异质性，并保护数据隐私。 |
| [^12] | [Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models.](http://arxiv.org/abs/2305.05973) | 提出使用差分隐私大语言模型合成查询的隐私保护推荐系统，可以安全有效地训练深度检索模型并提高检索质量。 |
| [^13] | [Two-Stage Constrained Actor-Critic for Short Video Recommendation.](http://arxiv.org/abs/2302.01680) | 本论文提出了一种两阶段有约束的演员-评论家算法，用于解决短视频推荐问题。通过将短视频推荐问题建模为约束马尔可夫决策过程，我们解决了在用户交互和多样的响应中优化累计观看时间的问题。进行了两阶段的策略学习，并且能够同时满足主要目标和辅助目标的约束。 |
| [^14] | [PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval.](http://arxiv.org/abs/2109.05206) | PHPQ是一种用于高效细粒度图像检索的金字塔混合池化量化方法。它通过金字塔混合池化模块捕获和保留多层次特征中的细粒度语义信息，并引入可学习的量化模块来提高哈希的表达能力。 |

# 详细

[^1]: 分析基于维度的搜索澄清提示生成中的相关性

    Analyzing Coherency in Facet-based Clarification Prompt Generation for Search. (arXiv:2401.04524v1 [cs.IR])

    [http://arxiv.org/abs/2401.04524](http://arxiv.org/abs/2401.04524)

    本研究关注基于维度的搜索澄清提示生成中的维度质量和相关性的重要性，并提出了一个相关性分类器来评估澄清过程中存在的维度相关性问题。

    

    澄清用户的信息需求是现代搜索系统中必不可少的组成部分。尽管大多数构建澄清提示的方法依赖于查询维度，但维度质量的影响相对未经探索。在这项工作中，我们通过维度相关性的概念来关注维度质量，并评估其对搜索中澄清的整体实用性的重要性。我们发现现有的评估程序未考虑维度相关性，这一点可以从相关性与自动度量标准的较差相关性看出。此外，我们提出了一个相关性分类器，并评估了一个关于澄清的已确立数据集中不一致维度的普遍性。我们的发现可以为未来在这个主题上的工作提供动力。

    Clarifying user's information needs is an essential component of modern search systems. While most of the approaches for constructing clarifying prompts rely on query facets, the impact of the quality of the facets is relatively unexplored. In this work, we concentrate on facet quality through the notion of facet coherency and assess its importance for overall usefulness for clarification in search. We find that existing evaluation procedures do not account for facet coherency, as evident by the poor correlation of coherency with automated metrics. Moreover, we propose a coherency classifier and assess the prevalence of incoherent facets in a well-established dataset on clarification. Our findings can serve as motivation for future work on the topic.
    
[^2]: 重写代码：一种用于大型语言模型增强代码搜索的简单方法

    Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search. (arXiv:2401.04514v1 [cs.SE])

    [http://arxiv.org/abs/2401.04514](http://arxiv.org/abs/2401.04514)

    本论文提出一种扩展的生成增强检索（GAR）框架，通过对代码进行重写来解决代码搜索中存在的风格不匹配问题，实验结果表明该方法显著提高了检索准确性。

    

    在代码搜索中，生成增强检索（GAR）框架是一种有前景的策略，通过生成示例代码片段来增强查询，以解决代码片段和自然语言查询之间的主要模态不匹配问题，尤其是在大型语言模型（LLM）展示了代码生成能力的情况下。然而，我们的初步调查发现，LLM增强框架所提供的改进有一定的限制。这种限制可能是因为生成的代码，尽管在功能上准确，但在代码库中与基准代码之间经常显示出明显的风格偏差。在本文中，我们扩展了基础GAR框架，并提出了一种简单而有效的方法，通过对代码库中的代码进行重写（ReCo）来进行风格规范化。实验结果表明，ReCo显著提高了检索准确性。

    In code search, the Generation-Augmented Retrieval (GAR) framework, which generates exemplar code snippets to augment queries, has emerged as a promising strategy to address the principal challenge of modality misalignment between code snippets and natural language queries, particularly with the demonstrated code generation capabilities of Large Language Models (LLMs). Nevertheless, our preliminary investigations indicate that the improvements conferred by such an LLM-augmented framework are somewhat constrained. This limitation could potentially be ascribed to the fact that the generated codes, albeit functionally accurate, frequently display a pronounced stylistic deviation from the ground truth code in the codebase. In this paper, we extend the foundational GAR framework and propose a simple yet effective method that additionally Rewrites the Code (ReCo) within the codebase for style normalization. Experimental results demonstrate that ReCo significantly boosts retrieval accuracy ac
    
[^3]: 结合基于嵌入和基于语义的模型用于推荐系统中的事后解释

    Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems. (arXiv:2401.04474v1 [cs.IR])

    [http://arxiv.org/abs/2401.04474](http://arxiv.org/abs/2401.04474)

    本论文介绍了一种使用基于嵌入和基于语义的模型相结合的方法来生成推荐系统中的事后解释，并利用基于本体的知识图谱来提高可解释性。这样的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度。

    

    在当今数据丰富的环境中，推荐系统在决策支持系统中扮演着至关重要的角色。它们为用户提供个性化推荐和对这些推荐的解释。嵌入式模型尽管被广泛使用，但往往缺乏可解释性，这可能损害信任和用户参与度。本论文提出了一种将嵌入式和基于语义的模型相结合的方法，用于在推荐系统中生成事后解释，利用基于本体的知识图谱来提高可解释性。通过在一个结构化框架内组织数据，本体允许对实体之间的复杂关系进行建模，这对于生成解释是必不可少的。通过结合基于嵌入和基于语义的模型用于推荐系统中的事后解释，我们定义的框架旨在产生有意义且易于理解的解释，增强用户的信任和满意度，并潜在地增加推荐的可靠性和效果。

    In today's data-rich environment, recommender systems play a crucial role in decision support systems. They provide to users personalized recommendations and explanations about these recommendations. Embedding-based models, despite their widespread use, often suffer from a lack of interpretability, which can undermine trust and user engagement. This paper presents an approach that combines embedding-based and semantic-based models to generate post-hoc explanations in recommender systems, leveraging ontology-based knowledge graphs to improve interpretability and explainability. By organizing data within a structured framework, ontologies enable the modeling of intricate relationships between entities, which is essential for generating explanations. By combining embedding-based and semantic based models for post-hoc explanations in recommender systems, the framework we defined aims at producing meaningful and easy-to-understand explanations, enhancing user trust and satisfaction, and pot
    
[^4]: 基于协同混淆的隐私保护顺序推荐

    Privacy-Preserving Sequential Recommendation with Collaborative Confusion. (arXiv:2401.04423v1 [cs.IR])

    [http://arxiv.org/abs/2401.04423](http://arxiv.org/abs/2401.04423)

    该论文提出了一种基于协同混淆的隐私保护顺序推荐方法，通过注入不可区分的项目来增加目标序列的困惑度，从而提高隐私保护性能。

    

    隐私保护的顺序推荐受到学术界和行业的广泛关注，然而对于收集和传输用户个人交互数据所带来的隐私风险往往被低估或忽视。现有的隐私保护研究主要应用于传统的协同过滤或矩阵分解，而非顺序推荐。此外，这些研究大多基于差分隐私或联邦学习，往往导致性能明显下降，或对通信有很高的要求。在这项工作中，我们从不同的角度解决隐私保护问题。与现有研究不同，我们捕捉邻居交互序列的协同信号，并在推荐过程开始前直接将不可区分的项目注入目标序列，从而增加目标序列的困惑度。即使攻击者获得目标交互序列，也很难区分真实数据和注入的数据。

    Sequential recommendation has attracted a lot of attention from both academia and industry, however the privacy risks associated to gathering and transferring users' personal interaction data are often underestimated or ignored. Existing privacy-preserving studies are mainly applied to traditional collaborative filtering or matrix factorization rather than sequential recommendation. Moreover, these studies are mostly based on differential privacy or federated learning, which often leads to significant performance degradation, or has high requirements for communication. In this work, we address privacy-preserving from a different perspective. Unlike existing research, we capture collaborative signals of neighbor interaction sequences and directly inject indistinguishable items into the target sequence before the recommendation process begins, thereby increasing the perplexity of the target sequence. Even if the target interaction sequence is obtained by attackers, it is difficult to dis
    
[^5]: 在推荐系统的训练过程中优化细粒度嵌入维度

    Fine-Grained Embedding Dimension Optimization During Training for Recommender Systems. (arXiv:2401.04408v1 [cs.IR])

    [http://arxiv.org/abs/2401.04408](http://arxiv.org/abs/2401.04408)

    本文提出了一种细粒度嵌入维度优化方法（FIITED），能够在推荐系统的训练过程中根据嵌入向量的重要性不断调整其维度，并设计了一种虚拟哈希索引哈希表的嵌入存储系统以有效节省内存。

    

    现代深度学习推荐模型中的大型嵌入表在训练和推断过程中需要过大的内存。为了减小训练时的内存占用，本文提出了一种细粒度嵌入维度优化方法 (FIITED)。根据嵌入向量的重要性不同，FIITED在训练过程中连续调整每个嵌入向量的维度，将更重要的嵌入向量分配更长的维度，并能够适应数据的动态变化。同时，本文设计了一种基于虚拟哈希的物理索引哈希表的嵌入存储系统，以实现嵌入维度的调整并有效地节省内存。对两个行业模型的实验表明，FIITED能够将嵌入的大小减小超过65%，同时保持训练模型的质量，比现有的一种在训练过程中进行嵌入修剪的方法节省更多内存。

    Huge embedding tables in modern Deep Learning Recommender Models (DLRM) require prohibitively large memory during training and inference. Aiming to reduce the memory footprint of training, this paper proposes FIne-grained In-Training Embedding Dimension optimization (FIITED). Given the observation that embedding vectors are not equally important, FIITED adjusts the dimension of each individual embedding vector continuously during training, assigning longer dimensions to more important embeddings while adapting to dynamic changes in data. A novel embedding storage system based on virtually-hashed physically-indexed hash tables is designed to efficiently implement the embedding dimension adjustment and effectively enable memory saving. Experiments on two industry models show that FIITED is able to reduce the size of embeddings by more than 65% while maintaining the trained model's quality, saving significantly more memory than a state-of-the-art in-training embedding pruning method. On p
    
[^6]: G-Meta: 大规模推荐系统中的GPU集群分布式元学习

    G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale Recommender Systems. (arXiv:2401.04338v1 [cs.LG])

    [http://arxiv.org/abs/2401.04338](http://arxiv.org/abs/2401.04338)

    本文提出了一个用于大规模推荐系统中的GPU集群分布式元学习的高性能框架G-Meta，通过利用数据并行性和模型并行性以及设计高效的元-IO流水线，实现了高速分布式训练。

    

    最近，一个名为元学习的新范式被广泛应用于深度学习推荐模型(DLRM)，并在统计性能方面取得了显著的改进，特别是在冷启动场景中。然而，现有的系统并没有为基于元学习的DLRM模型量身定制，并且在GPU集群的分布式训练中存在关于效率的重要问题。这是因为传统的深度学习流水线对于元学习中的两个任务特定数据集和两个更新循环并没有进行优化。本文提出了一个高性能框架，用于在GPU集群上进行基于优化的元DLRM模型的大规模训练，即G-Meta。首先，G-Meta利用数据并行性和模型并行性，并对计算和通信效率进行精心协调，实现高速分布式训练。其次，它提出了一个用于高效数据摄入的元-IO流水线，以缓解输入/输出瓶颈。进行了各种实验

    Recently, a new paradigm, meta learning, has been widely applied to Deep Learning Recommendation Models (DLRM) and significantly improves statistical performance, especially in cold-start scenarios. However, the existing systems are not tailored for meta learning based DLRM models and have critical problems regarding efficiency in distributed training in the GPU cluster. It is because the conventional deep learning pipeline is not optimized for two task-specific datasets and two update loops in meta learning. This paper provides a high-performance framework for large-scale training for Optimization-based Meta DLRM models over the \textbf{G}PU cluster, namely \textbf{G}-Meta. Firstly, G-Meta utilizes both data parallelism and model parallelism with careful orchestration regarding computation and communication efficiency, to enable high-speed distributed training. Secondly, it proposes a Meta-IO pipeline for efficient data ingestion to alleviate the I/O bottleneck. Various experimental r
    
[^7]: 出版类型对生物医学研究的差异特征：以老龄相关研究为例的定量分析

    Divergent Characteristics of Biomedical Research across Publication Types: A Quantitative Analysis on the Aging-related Research. (arXiv:2401.04323v1 [cs.DL])

    [http://arxiv.org/abs/2401.04323](http://arxiv.org/abs/2401.04323)

    本研究分析了老龄相关基因研究中不同出版类型的特征差异，发现这些出版类型在对老龄化研究的关注度、研究基因的范围和主题偏好上存在显著差异。尽管存在差异，一些顶级基因如胰岛素普遍受到重视，而且出版类型在研究基因方面也呈现相似的不平衡水平。另外，出版类型还在作者数量、引用数量等方面存在差异。

    

    本文研究了老龄相关基因研究中不同出版类型的特征差异。我们利用来自PubMed等权威数据库的五个模型物种的文献计量数据进行了分析。根据PubMed的分类，将文章分为不同的类型。结果表明，不同出版类型在对老龄相关研究的关注度、研究基因的范围和主题偏好上存在显著的差异。例如，比较研究和元分析比验证研究更注重老龄化问题。综述更关注细胞生物学，而临床研究则强调转化性主题。出版类型在高度研究的基因上也表现出差异，例如综述更关注APOE基因，而临床研究更关注GH1基因。尽管存在差异，一些顶级基因如胰岛素普遍受到重视。出版类型在研究基因方面也体现出相似的不平衡水平。在作者数量、引用数量等文献计量方面也存在差异。

    This paper investigates differences in characteristics across publication types for aging-related genetic research. We utilized bibliometric data for five model species retrieved from authoritative databases including PubMed. Publications are classified into types according to PubMed. Results indicate substantial divergence across publication types in attention paid to aging-related research, scopes of studied genes, and topical preferences. For instance, comparative studies and meta-analyses show a greater focus on aging than validation studies. Reviews concentrate more on cell biology while clinical studies emphasize translational topics. Publication types also manifest variations in highly studied genes, like APOE for reviews versus GH1 for clinical studies. Despite differences, top genes like insulin are universally emphasized. Publication types demonstrate similar levels of imbalance in research efforts to genes. Differences also exist in bibliometrics like authorship numbers, cit
    
[^8]: 基于提示的多兴趣学习方法用于顺序推荐

    Prompt-based Multi-interest Learning Method for Sequential Recommendation. (arXiv:2401.04312v1 [cs.IR])

    [http://arxiv.org/abs/2401.04312](http://arxiv.org/abs/2401.04312)

    提出了一种基于提示的多兴趣学习方法（PoMRec），用于顺序推荐。该方法通过利用具体的提示来指导兴趣提取和权重预测模块的学习，以克服现有方法中存在的限制。

    

    顺序推荐的多兴趣学习方法旨在根据用户的多方面兴趣预测下一个项目，给定用户的历史互动。现有方法主要由两个模块组成：多兴趣提取模块学习用户的多兴趣嵌入以捕捉用户多兴趣，多兴趣权重预测模块学习每个兴趣的权重，以聚合学习到的多兴趣嵌入以得到用户嵌入，用于预测用户对项目的评分。尽管这些方法很有效，但存在两个主要限制：1)它们直接将用户互动输入两个模块中，而忽略了它们不同的学习目标；2)它们仅考虑用户互动的中心性来学习用户的多兴趣，忽视了它们的离散性。为了解决这些限制，我们提出了一种基于提示的多兴趣学习方法（PoMRec），其中具体的提示被用来指导多兴趣嵌入模块和多兴趣权重预测模块的学习。

    Multi-interest learning method for sequential recommendation aims to predict the next item according to user multi-faceted interests given the user historical interactions. Existing methods mainly consist of two modules: the multi-interest extraction module that learns user multi-interest embeddings to capture the user multi-interests, and the multi-interest weight prediction module that learns the weight of each interest for aggregating the learned multi-interest embeddings to derive the user embedding, used for predicting the user rating to an item. Despite their effectiveness, existing methods have two key limitations: 1) they directly feed the user interactions into the two modules, while ignoring their different learning objectives, and 2) they merely consider the centrality of the user interactions to learn the user multi-interests, while overlooking their dispersion. To tackle these limitations, we propose a prompt-based multi-interest learning method (PoMRec), where specific pr
    
[^9]: 基于人工智能的解决推荐系统中冷启动和数据稀疏问题的方案

    An AI-based solution for the cold start and data sparsity problems in the recommendation systems. (arXiv:2312.01840v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.01840](http://arxiv.org/abs/2312.01840)

    这项研究提出了一个基于人工智能的解决方案，用于解决推荐系统中的冷启动和数据稀疏问题，以应对信息超载带来的挑战。

    

    近年来，互联网上可用的数据量以及利用互联网的用户数量以前所未有的速度增长。数字信息量和互联网用户数量的指数级增长，带来了信息超载的可能性，阻碍了对互联网上感兴趣内容的快速访问。像Google、DevilFinder和Altavista等信息检索系统在一定程度上克服了这一挑战，但缺乏信息的优先级和个性化（即系统将可获取的材料映射到用户的兴趣和偏好）处理。这导致了对推荐系统的需求空前增加。推荐系统是信息过滤系统，它通过根据用户的兴趣、喜好以及对所需项目的评级，从大量动态生成的数据中过滤出重要的信息片段，以解决信息超载问题。

    In recent years, the amount of data available on the internet and the number of users who utilize the Internet have increased at an unparalleled pace. The exponential development in the quantity of digital information accessible and the number of Internet users has created the possibility for information overload, impeding fast access to items of interest on the Internet. Information retrieval systems like as Google, DevilFinder, and Altavista have partly overcome this challenge, but prioritizing and customization of information (where a system maps accessible material to a user's interests and preferences) were lacking. This has resulted in a higher-than-ever need for recommender systems. Recommender systems are information filtering systems that address the issue of information overload by filtering important information fragments from a huge volume of dynamically produced data based on the user's interests, favorite things, preferences and ratings on the desired item. Recommender sy
    
[^10]: VKIE:应用关键信息提取于视频文本的研究

    VKIE: The Application of Key Information Extraction on Video Text. (arXiv:2310.11650v1 [cs.IR])

    [http://arxiv.org/abs/2310.11650](http://arxiv.org/abs/2310.11650)

    本文提出了一项重要任务，即从视频文本中提取层次化关键信息。研究者们通过拆分任务为四个子任务，并介绍了两种实现方案，即PipVKIE和UniVKIE。两种方案都利用了视觉、文本和坐标的多模态信息进行特征表示。实验证明，这些方案在性能和推理速度方面表现出色。

    

    从视频中提取结构化信息对于行业中许多下游应用至关重要。本文定义了从视频文本中提取层次化关键信息的重要任务。为了完成这个任务，我们将其拆分为四个子任务，并介绍了两种实现方案，分别称为PipVKIE和UniVKIE。PipVKIE按照连续阶段顺序完成四个子任务，而UniVKIE通过将所有子任务统一到一个主干中进行改进。PipVKIE和UniVKIE都利用了来自视觉、文本和坐标的多模态信息进行特征表示。在一个明确定义的数据集上进行了大量实验证明，我们的解决方案可以取得显著的性能和高效的推理速度。代码和数据集将公开提供。

    Extracting structured information from videos is critical for numerous downstream applications in the industry. In this paper, we define a significant task of extracting hierarchical key information from visual texts on videos. To fulfill this task, we decouples it into four subtasks and introduce two implementation solutions called PipVKIE and UniVKIE. PipVKIE sequentially completes the four subtasks in continuous stages, while UniVKIE is improved by unifying all the subtasks into one backbone. Both PipVKIE and UniVKIE leverage multimodal information from vision, text, and coordinates for feature representation. Extensive experiments on one well-defined dataset demonstrate that our solutions can achieve remarkable performance and efficient inference speed. The code and dataset will be publicly available.
    
[^11]: FedDCSR: 通过解缠表示学习实现联邦跨领域顺序推荐

    FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning. (arXiv:2309.08420v1 [cs.LG])

    [http://arxiv.org/abs/2309.08420](http://arxiv.org/abs/2309.08420)

    提出了一种名为FedDCSR的联邦跨领域顺序推荐框架，通过解缠表示学习来处理不同领域之间的序列特征异质性，并保护数据隐私。

    

    近年来，利用来自多个领域的用户序列数据的跨领域顺序推荐(CSR)受到了广泛关注。然而，现有的CSR方法需要在领域之间共享原始用户数据，这违反了《通用数据保护条例》(GDPR)。因此，有必要将联邦学习(FL)和CSR相结合，充分利用不同领域的知识，同时保护数据隐私。然而，不同领域之间的序列特征异质性对FL的整体性能有显著影响。在本文中，我们提出了FedDCSR，这是一种通过解缠表示学习的新型联邦跨领域顺序推荐框架。具体而言，为了解决不同领域之间的序列特征异质性，我们引入了一种称为领域内-领域间序列表示解缠(SRD)的方法，将用户序列特征解缠成领域共享和领域专属特征。

    Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design
    
[^12]: 使用差分隐私大语言模型合成查询的隐私保护推荐系统.

    Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models. (arXiv:2305.05973v1 [cs.CL])

    [http://arxiv.org/abs/2305.05973](http://arxiv.org/abs/2305.05973)

    提出使用差分隐私大语言模型合成查询的隐私保护推荐系统，可以安全有效地训练深度检索模型并提高检索质量。

    

    我们提出了一种新颖的方法，使用差分隐私大语言模型（LLMs）开发隐私保护的大规模推荐系统，克服了在训练这些复杂系统时的某些挑战和限制。我们的方法特别适用于基于LLM的推荐系统的新兴领域，但也可以轻松地用于处理自然语言输入表示的任何推荐系统。我们的方法涉及使用DP训练方法，对公开预训练的LLM在查询生成任务上进行微调。生成的模型可以生成私有合成查询，代表原始查询，可以在任何下游非私有推荐训练过程中自由共享，而不会产生任何额外的隐私成本。我们评估了我们的方法对安全训练有效的深度检索模型的能力，我们观察到它们的检索质量有显着的提高，而不会损害查询级别的隐私。

    We propose a novel approach for developing privacy-preserving large-scale recommender systems using differentially private (DP) large language models (LLMs) which overcomes certain challenges and limitations in DP training these complex systems. Our method is particularly well suited for the emerging area of LLM-based recommender systems, but can be readily employed for any recommender systems that process representations of natural language inputs. Our approach involves using DP training methods to fine-tune a publicly pre-trained LLM on a query generation task. The resulting model can generate private synthetic queries representative of the original queries which can be freely shared for any downstream non-private recommendation training procedures without incurring any additional privacy cost. We evaluate our method on its ability to securely train effective deep retrieval models, and we observe significant improvements in their retrieval quality without compromising query-level pri
    
[^13]: 两阶段有约束的演员-评论家算法用于短视频推荐

    Two-Stage Constrained Actor-Critic for Short Video Recommendation. (arXiv:2302.01680v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01680](http://arxiv.org/abs/2302.01680)

    本论文提出了一种两阶段有约束的演员-评论家算法，用于解决短视频推荐问题。通过将短视频推荐问题建模为约束马尔可夫决策过程，我们解决了在用户交互和多样的响应中优化累计观看时间的问题。进行了两阶段的策略学习，并且能够同时满足主要目标和辅助目标的约束。

    

    社交媒体上短视频的广泛流行为视频分享平台上的推荐系统优化提供了新的机遇和挑战。用户与系统依次交互，并提供包括观看时间和对多个视频的各种类型交互在内的复杂多面 responses。一方面，平台旨在长期优化用户的累计观看时间（主要目标），这可以通过强化学习有效优化。另一方面，平台还需要满足适应多个用户交互 responses（辅助目标）的约束，如 follow、share 等。在本文中，我们将短视频推荐问题作为约束马尔可夫决策过程（CMDP）进行了建模。我们发现传统的约束强化学习算法在这种情况下效果不好。我们提出了一种新颖的两阶段有约束的演员-评论家方法：第一阶段，我们学习个体的策略，以优化主要目标。第二阶段，我们进一步学习共享的策略，以满足辅助目标的约束。

    The wide popularity of short videos on social media poses new opportunities and challenges to optimize recommender systems on the video-sharing platforms. Users sequentially interact with the system and provide complex and multi-faceted responses, including watch time and various types of interactions with multiple videos. One the one hand, the platforms aims at optimizing the users' cumulative watch time (main goal) in long term, which can be effectively optimized by Reinforcement Learning. On the other hand, the platforms also needs to satisfy the constraint of accommodating the responses of multiple user interactions (auxiliary goals) such like, follow, share etc. In this paper, we formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP). We find that traditional constrained reinforcement learning algorithms can not work well in this setting. We propose a novel two-stage constrained actor-critic method: At stage one, we learn individual pol
    
[^14]: PHPQ: 金字塔混合池化量化用于高效的细粒度图像检索

    PHPQ: Pyramid Hybrid Pooling Quantization for Efficient Fine-Grained Image Retrieval. (arXiv:2109.05206v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.05206](http://arxiv.org/abs/2109.05206)

    PHPQ是一种用于高效细粒度图像检索的金字塔混合池化量化方法。它通过金字塔混合池化模块捕获和保留多层次特征中的细粒度语义信息，并引入可学习的量化模块来提高哈希的表达能力。

    

    鉴于其高计算和存储效率，深度哈希方法（包括深度量化和深度二进制哈希）已成为大规模图像检索的常见解决方案。然而，大多数现有的哈希方法对于细粒度检索无法产生令人满意的结果，因为它们通常采用最后一个CNN层的输出生成二进制码。由于更深的层倾向于将视觉线索（如纹理）总结为抽象的语义（如狗和猫），最后一个CNN层产生的特征在捕捉浅层中存在但具有辨别力的细微视觉细节方面效果较差。为了改善细粒度图像哈希，我们提出了金字塔混合池化量化（PHPQ）方法。具体地，我们提出了金字塔混合池化（PHP）模块，用于从多层次特征中捕获和保留细粒度的语义信息，强调不同子类别之间的细微区分。此外，我们还提出了一个可学习的量化模块来进一步提高哈希的表达能力。

    Deep hashing approaches, including deep quantization and deep binary hashing, have become a common solution to large-scale image retrieval due to their high computation and storage efficiency. Most existing hashing methods cannot produce satisfactory results for fine-grained retrieval, because they usually adopt the outputs of the last CNN layer to generate binary codes. Since deeper layers tend to summarize visual clues, e.g., texture, into abstract semantics, e.g., dogs and cats, the feature produced by the last CNN layer is less effective in capturing subtle but discriminative visual details that mostly exist in shallow layers. To improve fine-grained image hashing, we propose Pyramid Hybrid Pooling Quantization (PHPQ). Specifically, we propose a Pyramid Hybrid Pooling (PHP) module to capture and preserve fine-grained semantic information from multi-level features, which emphasizes the subtle discrimination of different sub-categories. Besides, we propose a learnable quantization mo
    

