# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Dual-Channel Multiplex Graph Neural Networks for Recommendation](https://arxiv.org/abs/2403.11624) | 该研究提出了一种名为双通道多重图神经网络（DCMGNN）的新型推荐框架，能够有效解决现有推荐方法中存在的多通路关系行为模式建模和对目标关系影响忽略的问题。 |
| [^2] | [ConvSDG: Session Data Generation for Conversational Search](https://arxiv.org/abs/2403.11335) | 基于大型语言模型的ConvSDG框架探索了生成更多带相关标签训练会话以提升会话搜索性能的方法。 |
| [^3] | [Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation](https://arxiv.org/abs/2403.11136) | 通过对数据增强的研究，论文探讨了在顺序推荐系统中，仅使用数据增强是否能取得优越的推荐结果。 |
| [^4] | [Entity Alignment with Unlabeled Dangling Cases](https://arxiv.org/abs/2403.10978) | 提出了一种基于GNN的框架，在实体对齐中解决了无标签悬挂案例的问题，通过设计注意机制和正样本-无标签损失来实现更好的对齐性能 |
| [^5] | [Improving the Robustness of Dense Retrievers Against Typos via Multi-Positive Contrastive Learning](https://arxiv.org/abs/2403.10939) | 本研究提出通过多正对比学习来提高密集检索器对错别字的鲁棒性，并表明所有可用的正样本可以同时使用。 |
| [^6] | [The Impact Of Bug Localization Based on Crash Report Mining: A Developers' Perspective](https://arxiv.org/abs/2403.10753) | 本文报告了一种基于崩溃报告挖掘的Bug定位方法，探讨了该方法在软件公司日常生活中的使用，解释了开发者对这一方法的看法。 |
| [^7] | [Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond](https://arxiv.org/abs/2403.10667) | 本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。 |
| [^8] | [LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial Keyword Queries](https://arxiv.org/abs/2403.07331) | 提出了一种名为LIST的新技术，通过学习为基于嵌入的空间关键词查询建立空间文本数据索引，以加速top-k搜索过程。 |
| [^9] | [MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation](https://arxiv.org/abs/2403.06747) | 提出了Meta-Split网络（MSN）来解决消费者之间电子商务平台中限量库存产品推荐中的独特挑战，通过分割用户历史序列来有效利用用户历史信息。 |
| [^10] | [Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation](https://arxiv.org/abs/2403.04503) | Ducho 2.0推出，提供更个性化的用户体验和支持多模态大型模型提取和处理特征，可用于多模式推荐，同时优化数据加载和存储。 |
| [^11] | [Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning](https://arxiv.org/abs/2403.03835) | Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。 |
| [^12] | [ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework](https://arxiv.org/abs/2403.00781) | 这项研究介绍了ChatDiet，一个借助LLM技术构建的框架，能够帮助个性化营养导向食品推荐聊天机器人提供个性化和可解释的推荐。 |
| [^13] | [Confidence-aware Fine-tuning of Sequential Recommendation Systems via Conformal Prediction](https://arxiv.org/abs/2402.08976) | 本研究提出了CPFT框架，通过在顺序推荐系统中精细调整过程中结合交叉熵损失函数和基于符合性预测的损失函数，增强了推荐系统的置信度。CPFT动态生成潜在真实值的项目集合，提升了训练过程中的性能，并提高了推荐的准确性和可信度。 |
| [^14] | [Attention Calibration for Transformer-based Sequential Recommendation](https://arxiv.org/abs/2308.09419) | 本文针对基于Transformer的顺序推荐中存在的注意力权重分配不准确问题，提出了一种解决方案。 |
| [^15] | [Multimodal Transformer Distillation for Audio-Visual Synchronization](https://arxiv.org/abs/2210.15563) | 该论文提出了一种通过多模态Transformer蒸馏技术来进行训练的MTDVocaLiST模型，能够深度模仿VocaLiST中Transformer的交叉注意力分布和值关系，从而在音频-视觉同步任务中取得了很好的效果。 |
| [^16] | [Causal Intervention for Fairness in Multi-behavior Recommendation](https://arxiv.org/abs/2209.04589) | 通过考虑多种用户行为来减轻流行度偏见，处理了多行为推荐中的公平问题。 |
| [^17] | [Towards 3D Molecule-Text Interpretation in Language Models.](http://arxiv.org/abs/2401.13923) | 提出了一个名为3D-MoLM的模型，通过给语言模型配备一个3D分子编码器，实现了对3D分子-文本的解释和分析，此模型在下游任务上显著优于现有基线。 |
| [^18] | [SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering.](http://arxiv.org/abs/2401.13463) | SpeechDPR是第一个用于开放领域口语问答的端到端框架，能够从口语存档中检索可能包含答案的段落。通过融合无监督ASR和文本密集检索器的知识，SpeechDPR能够获得较好的性能，并且在UASR性能较差时表现更加鲁棒。 |
| [^19] | [Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning.](http://arxiv.org/abs/2401.11021) | 提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。 |
| [^20] | [NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation.](http://arxiv.org/abs/2309.07705) | NineRec是一个用于评估可迁移推荐的数据集套件，包括一个大规模的源域推荐数据集和九个多样的目标域推荐数据集。每个物品由文本描述和高分辨率封面图像表示。 |
| [^21] | [Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms.](http://arxiv.org/abs/2309.05961) | 本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。 |
| [^22] | [Temporal Interest Network for Click-Through Rate Prediction.](http://arxiv.org/abs/2308.08487) | 本文提出了时间兴趣网络（TIN），用于捕捉行为与目标之间的四重语义和时间相关性，以预测点击率的效果和已有方法对这种相关性的学习程度尚不清楚。 |
| [^23] | [Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?.](http://arxiv.org/abs/2307.09985) | 该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。 |
| [^24] | [Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning.](http://arxiv.org/abs/2306.16001) | 本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。 |
| [^25] | [Sheaf Neural Networks for Graph-based Recommender Systems.](http://arxiv.org/abs/2304.09097) | 基于Sheaf神经网络的模型提出了一种新的向量空间表示方法，使得其在基准推荐任务上获得最先进的性能表现。 |
| [^26] | [Equivariant Contrastive Learning for Sequential Recommendation.](http://arxiv.org/abs/2211.05290) | 本论文提出了序列推荐的等变性对比学习（ECL-SR）方法，通过使用条件判别器来使得学习到的用户行为表示对于侵入性增强敏感并对轻微增强不敏感，从而提高了序列推荐模型的区分能力。 |

# 详细

[^1]: 双通道多重图神经网络用于推荐

    Dual-Channel Multiplex Graph Neural Networks for Recommendation

    [https://arxiv.org/abs/2403.11624](https://arxiv.org/abs/2403.11624)

    该研究提出了一种名为双通道多重图神经网络（DCMGNN）的新型推荐框架，能够有效解决现有推荐方法中存在的多通路关系行为模式建模和对目标关系影响忽略的问题。

    

    高效的推荐系统在准确捕捉反映个人偏好的用户和项目属性方面发挥着至关重要的作用。一些现有的推荐技术已经开始将重点转向在真实世界的推荐场景中对用户和项目之间的各种类型交互关系进行建模，例如在线购物平台上的点击、标记收藏和购买。然而，这些方法仍然面临两个重要的缺点：(1) 不足的建模和利用用户和项目之间多通路关系形成的各种行为模式对表示学习的影响，以及(2) 忽略了行为模式中不同关系对推荐系统场景中目标关系的影响。在本研究中，我们介绍了一种新颖的推荐框架，即双通道多重图神经网络（DCMGNN），该框架解决了上述挑战。

    arXiv:2403.11624v1 Announce Type: cross  Abstract: Efficient recommender systems play a crucial role in accurately capturing user and item attributes that mirror individual preferences. Some existing recommendation techniques have started to shift their focus towards modeling various types of interaction relations between users and items in real-world recommendation scenarios, such as clicks, marking favorites, and purchases on online shopping platforms. Nevertheless, these approaches still grapple with two significant shortcomings: (1) Insufficient modeling and exploitation of the impact of various behavior patterns formed by multiplex relations between users and items on representation learning, and (2) ignoring the effect of different relations in the behavior patterns on the target relation in recommender system scenarios. In this study, we introduce a novel recommendation framework, Dual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the aforementioned challenges
    
[^2]: ConvSDG：用于会话搜索的会话数据生成

    ConvSDG: Session Data Generation for Conversational Search

    [https://arxiv.org/abs/2403.11335](https://arxiv.org/abs/2403.11335)

    基于大型语言模型的ConvSDG框架探索了生成更多带相关标签训练会话以提升会话搜索性能的方法。

    

    会话搜索通过允许用户与搜索引擎进行多轮交互提供了更便捷的搜索界面。然而，会话密集检索方法的有效性受到训练数据的稀缺性限制，这些数据需要用于微调。因此，生成更多带有相关标签的训练会话可能会提高搜索性能。基于大型语言模型（LLMs）在文本生成上的有益能力，我们提出了ConvSDG，这是一个简单而有效的框架，旨在探索使用LLM进行会话数据生成来提升会话搜索的可行性。在这个框架内，我们根据相关判断的可用性设计了对话/会话级和查询级数据生成的无监督和半监督学习。生成的数据被用于微调会话密集检索器。

    arXiv:2403.11335v1 Announce Type: cross  Abstract: Conversational search provides a more convenient interface for users to search by allowing multi-turn interaction with the search engine. However, the effectiveness of the conversational dense retrieval methods is limited by the scarcity of training data required for their fine-tuning. Thus, generating more training conversational sessions with relevant labels could potentially improve search performance. Based on the promising capabilities of large language models (LLMs) on text generation, we propose ConvSDG, a simple yet effective framework to explore the feasibility of boosting conversational search by using LLM for session data generation. Within this framework, we design dialogue/session-level and query-level data generation with unsupervised and semi-supervised learning, according to the availability of relevance judgments. The generated data are used to fine-tune the conversational dense retriever. Extensive experiments on four
    
[^3]: 对比学习是否必要？数据增强与对比学习在顺序推荐中的研究

    Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation

    [https://arxiv.org/abs/2403.11136](https://arxiv.org/abs/2403.11136)

    通过对数据增强的研究，论文探讨了在顺序推荐系统中，仅使用数据增强是否能取得优越的推荐结果。

    

    顺序推荐系统（SRS）旨在基于用户的历史交互数据预测其未来行为。最近的研究越来越多地利用对比学习（CL）来利用无监督信号来缓解SRS中的数据稀疏问题。一般来说，基于CL的SRS首先通过使用数据增强策略增广原始的序列交互数据，并采用对比训练方案来强化来自相同原始交互数据的序列的表示为相似。尽管CL日益普及，作为CL的基本组成部分的数据增强并没有受到足够的关注。这引发了一个问题：是否可以仅通过数据增强实现卓越的推荐结果？为了回答这个问题，我们在四个真实世界数据集上评估了八种广泛使用的数据增强策略，以及最先进的基于CL的SRS方法。

    arXiv:2403.11136v1 Announce Type: new  Abstract: Sequential recommender systems (SRS) are designed to predict users' future behaviors based on their historical interaction data. Recent research has increasingly utilized contrastive learning (CL) to leverage unsupervised signals to alleviate the data sparsity issue in SRS. In general, CL-based SRS first augments the raw sequential interaction data by using data augmentation strategies and employs a contrastive training scheme to enforce the representations of those sequences from the same raw interaction data to be similar. Despite the growing popularity of CL, data augmentation, as a basic component of CL, has not received sufficient attention. This raises the question: Is it possible to achieve superior recommendation results solely through data augmentation? To answer this question, we benchmark eight widely used data augmentation strategies, as well as state-of-the-art CL-based SRS methods, on four real-world datasets under both war
    
[^4]: 具有无标签悬挂案例的实体对齐

    Entity Alignment with Unlabeled Dangling Cases

    [https://arxiv.org/abs/2403.10978](https://arxiv.org/abs/2403.10978)

    提出了一种基于GNN的框架，在实体对齐中解决了无标签悬挂案例的问题，通过设计注意机制和正样本-无标签损失来实现更好的对齐性能

    

    我们研究了具有无标签悬挂案例的实体对齐问题，这意味着源图或目标图中有一些实体在另一方中没有对应实体，并且这些实体保持未标记状态。该问题出现在源图和目标图的规模不同，并且标记可匹配实体的成本远低于悬挂实体的情况下。为了解决这个问题，我们提出了一种新颖的基于GNN的悬挂检测和实体对齐框架。虽然这两个任务共享相同的GNN，并且一起训练，但检测到的悬挂实体在对齐中被移除。我们的框架特点是具有用于选择性邻域聚合的设计实体和关系注意机制，以及用于对悬挂实体进行无偏估计的正样本-无标签学习损失。实验结果表明我们设计的每个组件都对整体对齐性能有贡献

    arXiv:2403.10978v1 Announce Type: new  Abstract: We investigate the entity alignment problem with unlabeled dangling cases, meaning that there are entities in the source or target graph having no counterparts in the other, and those entities remain unlabeled. The problem arises when the source and target graphs are of different scales, and it is much cheaper to label the matchable pairs than the dangling entities. To solve the issue, we propose a novel GNN-based dangling detection and entity alignment framework. While the two tasks share the same GNN and are trained together, the detected dangling entities are removed in the alignment. Our framework is featured by a designed entity and relation attention mechanism for selective neighborhood aggregation in representation learning, as well as a positive-unlabeled learning loss for an unbiased estimation of dangling entities. Experimental results have shown that each component of our design contributes to the overall alignment performance
    
[^5]: 通过多正对比学习提高密集检索器对错别字的鲁棒性

    Improving the Robustness of Dense Retrievers Against Typos via Multi-Positive Contrastive Learning

    [https://arxiv.org/abs/2403.10939](https://arxiv.org/abs/2403.10939)

    本研究提出通过多正对比学习来提高密集检索器对错别字的鲁棒性，并表明所有可用的正样本可以同时使用。

    

    密集检索已成为段落检索中的新范式。尽管在无错别字查询上效果显著，但在处理包含错别字的查询时却不够鲁棒。当前针对提高密集检索器对错别字鲁棒性的研究结合了(i) 在训练期间获得错别字查询的数据增强和(ii) 旨在对齐原始无错别字查询与错别字变体的附加鲁棒性子任务。尽管每个查询的多个错别字变体可用作正样本，但某些方法假设单一正样本和一组负样本以及使用对比学习处理改进鲁棒性的子任务；因此，未充分利用多个正样本（错别字查询）。与之相反，本研究认为所有可用的正样本可以同时使用，并采用支持多正对比学习的方法。实验结果表明...

    arXiv:2403.10939v1 Announce Type: new  Abstract: Dense retrieval has become the new paradigm in passage retrieval. Despite its effectiveness on typo-free queries, it is not robust when dealing with queries that contain typos. Current works on improving the typo-robustness of dense retrievers combine (i) data augmentation to obtain the typoed queries during training time with (ii) additional robustifying subtasks that aim to align the original, typo-free queries with their typoed variants. Even though multiple typoed variants are available as positive samples per query, some methods assume a single positive sample and a set of negative ones per anchor and tackle the robustifying subtask with contrastive learning; therefore, making insufficient use of the multiple positives (typoed queries). In contrast, in this work, we argue that all available positives can be used at the same time and employ contrastive learning that supports multiple positives (multi-positive). Experimental results o
    
[^6]: 基于崩溃报告挖掘的Bug定位影响：开发者视角

    The Impact Of Bug Localization Based on Crash Report Mining: A Developers' Perspective

    [https://arxiv.org/abs/2403.10753](https://arxiv.org/abs/2403.10753)

    本文报告了一种基于崩溃报告挖掘的Bug定位方法，探讨了该方法在软件公司日常生活中的使用，解释了开发者对这一方法的看法。

    

    开发人员通常使用崩溃报告来理解bug的根本原因。然而，从这些信息中定位有错误的源代码片段是一项具有挑战性的任务，特别是当日志数据库包含许多崩溃报告时。为了解决这个问题，最近的研究提出并评估了分组崩溃报告数据和使用堆栈跟踪信息来定位bug的方法。这种方法的有效性主要通过将候选buggy源代码片段与bug修复提交中实际更改的代码进行比较来评估，这是在回顾性仓库挖掘研究的背景下发生的。因此，现有文献仍缺乏讨论这些方法在软件公司日常生活中的使用，这可以解释开发者对这些方法的看法。在本文中，我们报告了我们在每周基基础上使用一种分组崩溃报告并找到错误代码的方法的经验。

    arXiv:2403.10753v1 Announce Type: cross  Abstract: Developers often use crash reports to understand the root cause of bugs. However, locating the buggy source code snippet from such information is a challenging task, mainly when the log database contains many crash reports. To mitigate this issue, recent research has proposed and evaluated approaches for grouping crash report data and using stack trace information to locate bugs. The effectiveness of such approaches has been evaluated by mainly comparing the candidate buggy code snippets with the actual changed code in bug-fix commits -- which happens in the context of retrospective repository mining studies. Therefore, the existing literature still lacks discussing the use of such approaches in the daily life of a software company, which could explain the developers' perceptions on the use of these approaches. In this paper, we report our experience of using an approach for grouping crash reports and finding buggy code on a weekly bas
    
[^7]: 通向统一多模式个性化：大型视觉语言模型用于生成推荐和更多领域

    Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond

    [https://arxiv.org/abs/2403.10667](https://arxiv.org/abs/2403.10667)

    本文旨在建立一个统一的多模态个性化系统(UniMP)，有效利用多模态数据同时消除与任务和模态特定定制相关的复杂性。

    

    开发一个能够有效利用异构资源并满足各种个性化需求的通用模型一直是社区渴望的目标。我们日常的选择，尤其是在时尚和零售等领域，很大程度上受多模态数据的影响，比如图片和文本描述。这些模态不仅提供直观的指导，还迎合个性化用户偏好。然而，当前主流的个性化方法主要聚焦于基于ID或文本的推荐问题，未能理解涵盖各种任务或模态的信息。本文的目标是建立一个统一的多模态个性化系统(UniMP)，能够有效利用多模态数据，同时消除与任务和模态特定定制相关的复杂性。我们认为基础生成建模的进展提供了

    arXiv:2403.10667v1 Announce Type: cross  Abstract: Developing a universal model that can effectively harness heterogeneous resources and respond to a wide range of personalized needs has been a longstanding community aspiration. Our daily choices, especially in domains like fashion and retail, are substantially shaped by multi-modal data, such as pictures and textual descriptions. These modalities not only offer intuitive guidance but also cater to personalized user preferences. However, the predominant personalization approaches mainly focus on the ID or text-based recommendation problem, failing to comprehend the information spanning various tasks or modalities. In this paper, our goal is to establish a Unified paradigm for Multi-modal Personalization systems (UniMP), which effectively leverages multi-modal data while eliminating the complexities associated with task- and modality-specific customization. We argue that the advancements in foundational generative modeling have provided
    
[^8]: LIST: 学习为基于嵌入的空间关键词查询建立空间文本数据索引

    LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial Keyword Queries

    [https://arxiv.org/abs/2403.07331](https://arxiv.org/abs/2403.07331)

    提出了一种名为LIST的新技术，通过学习为基于嵌入的空间关键词查询建立空间文本数据索引，以加速top-k搜索过程。

    

    随着空间文本数据的普及，“Top-k KNN空间关键词查询（TkQs）”已经在许多实际应用中发现，它基于一个评价空间和文本相关性的排名函数返回一个对象列表。现有的用于TkQs的geo-textual索引使用传统的检索模型（如BM25）来计算文本相关性，并通常利用简单的线性函数来计算空间相关性，但其效果有限。为了提高效果，最近提出了几种深度学习模型，但它们存在严重的效率问题。据我们所知，目前没有为加速这些深度学习模型的top-k搜索过程专门设计的有效索引。为了解决这些问题，我们提出了一种新技术，通过学习为回答基于嵌入的空间关键词查询（称为LIST）建立空间文本数据索引。LIST具有两个新颖组件。

    arXiv:2403.07331v1 Announce Type: new  Abstract: With the proliferation of spatio-textual data, Top-k KNN spatial keyword queries (TkQs), which return a list of objects based on a ranking function that evaluates both spatial and textual relevance, have found many real-life applications. Existing geo-textual indexes for TkQs use traditional retrieval models like BM25 to compute text relevance and usually exploit a simple linear function to compute spatial relevance, but its effectiveness is limited. To improve effectiveness, several deep learning models have recently been proposed, but they suffer severe efficiency issues. To the best of our knowledge, there are no efficient indexes specifically designed to accelerate the top-k search process for these deep learning models.   To tackle these issues, we propose a novel technique, which Learns to Index the Spatio-Textual data for answering embedding based spatial keyword queries (called LIST). LIST is featured with two novel components. F
    
[^9]: MetaSplit: 用于限量产品推荐的Meta-Split网络

    MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation

    [https://arxiv.org/abs/2403.06747](https://arxiv.org/abs/2403.06747)

    提出了Meta-Split网络（MSN）来解决消费者之间电子商务平台中限量库存产品推荐中的独特挑战，通过分割用户历史序列来有效利用用户历史信息。

    

    相对于面向消费者的电子商务系统，消费者之间的电子商务平台通常会遇到限量库存问题，即产品在C2C系统中只能销售一次。这为点击率（CTR）预测带来了几个独特的挑战。鉴于每个产品（即商品）的有限用户交互，CTR模型中对应的商品嵌入可能不容易收敛。这使得传统基于序列建模的方法无法有效利用用户历史信息，因为历史用户行为包含了不同库存量的商品混合。特别是，序列模型中的注意力机制倾向于将更多累积用户交互的产品分配更高的分数，导致限量产品被忽视且对最终输出的贡献较少。为此，我们提出了Meta-Split网络（MSN）来分割用户历史序列...

    arXiv:2403.06747v1 Announce Type: new  Abstract: Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSN) to split user history sequence regar
    
[^10]: Ducho 2.0：面向多模式推荐的更为时尚的特征提取和处理框架

    Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation

    [https://arxiv.org/abs/2403.04503](https://arxiv.org/abs/2403.04503)

    Ducho 2.0推出，提供更个性化的用户体验和支持多模态大型模型提取和处理特征，可用于多模式推荐，同时优化数据加载和存储。

    

    在这项工作中，我们介绍了Ducho 2.0，我们框架的最新稳定版本。与Ducho不同，Ducho 2.0提供了更个性化的用户体验，可以定义和导入在特定任务和数据集上进行了微调的自定义提取模型。此外，新版本能够通过多模态设计的大型模型提取和处理特征。值得注意的是，所有这些新功能都受到了对本地存储器进行了优化的数据加载和存储的支持。为了展示Ducho 2.0的功能，我们展示了一个完整的多模式推荐流水线，从提取/处理到最终推荐。我们的想法是为从业者和经验丰富的学者提供一个即用工具，可以在任何多模式推荐框架之上运行广泛的基准分析。所有材料都可以在以下网址获得：\url{https://github.com/sisinflab/Ducho}。

    arXiv:2403.04503v1 Announce Type: new  Abstract: In this work, we introduce Ducho 2.0, the latest stable version of our framework. Differently from Ducho, Ducho 2.0 offers a more personalized user experience with the definition and import of custom extraction models fine-tuned on specific tasks and datasets. Moreover, the new version is capable of extracting and processing features through multimodal-by-design large models. Notably, all these new features are supported by optimized data loading and storing to the local memory. To showcase the capabilities of Ducho 2.0, we demonstrate a complete multimodal recommendation pipeline, from the extraction/processing to the final recommendation. The idea is to provide practitioners and experienced scholars with a ready-to-use tool that, put on top of any multimodal recommendation framework, may permit them to run extensive benchmarking analyses. All materials are accessible at: \url{https://github.com/sisinflab/Ducho}.
    
[^11]: Cobweb：一种增量和分层式的人类类别学习模型

    Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning

    [https://arxiv.org/abs/2403.03835](https://arxiv.org/abs/2403.03835)

    Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。

    

    Cobweb是一种类似人类的类别学习系统，与其他增量分类模型不同的是，它利用类别效用度量构建分层组织的类似树状结构。先前的研究表明，Cobweb能够捕捉心理效应，如基本水平、典型性和扇形效应。然而，对Cobweb作为人类分类模型的更广泛评估仍然缺乏。本研究填补了这一空白。它确定了Cobweb与经典的人类类别学习效应的一致性。还探讨了Cobweb展现出在单一模型中既有实例又有原型学习的灵活性。这些发现为将来研究Cobweb作为人类类别学习的综合模型奠定了基础。

    arXiv:2403.03835v1 Announce Type: cross  Abstract: Cobweb, a human like category learning system, differs from other incremental categorization models in constructing hierarchically organized cognitive tree-like structures using the category utility measure. Prior studies have shown that Cobweb can capture psychological effects such as the basic level, typicality, and fan effects. However, a broader evaluation of Cobweb as a model of human categorization remains lacking. The current study addresses this gap. It establishes Cobweb's alignment with classical human category learning effects. It also explores Cobweb's flexibility to exhibit both exemplar and prototype like learning within a single model. These findings set the stage for future research on Cobweb as a comprehensive model of human category learning.
    
[^12]: ChatDiet：通过LLM增强框架赋能个性化营养导向食品推荐聊天机器人

    ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework

    [https://arxiv.org/abs/2403.00781](https://arxiv.org/abs/2403.00781)

    这项研究介绍了ChatDiet，一个借助LLM技术构建的框架，能够帮助个性化营养导向食品推荐聊天机器人提供个性化和可解释的推荐。

    

    食物对健康的深远影响使得先进的营养导向食品推荐服务成为必要。传统方法往往缺乏个性化、可解释性和互动性等关键元素。虽然大型语言模型（LLMs）带来了解释性和可解释性，但它们单独的使用未能实现真正的个性化。本文介绍了ChatDiet，一种新颖的LLM驱动框架，专门设计用于个性化营养导向食品推荐聊天机器人。ChatDiet集成了个人和人群模型，辅以一个协调器，无缝检索和处理相关信息。其结果是动态提供个性化和可解释的食品推荐，根据个人用户喜好定制。我们对ChatDiet进行了评估，包括一个引人入胜的案例研究，在案例研究中建立了一个因果个人模型来估计个人营养效果。

    arXiv:2403.00781v1 Announce Type: cross  Abstract: The profound impact of food on health necessitates advanced nutrition-oriented food recommendation services. Conventional methods often lack the crucial elements of personalization, explainability, and interactivity. While Large Language Models (LLMs) bring interpretability and explainability, their standalone use falls short of achieving true personalization. In this paper, we introduce ChatDiet, a novel LLM-powered framework designed specifically for personalized nutrition-oriented food recommendation chatbots. ChatDiet integrates personal and population models, complemented by an orchestrator, to seamlessly retrieve and process pertinent information. The result is a dynamic delivery of personalized and explainable food recommendations, tailored to individual user preferences. Our evaluation of ChatDiet includes a compelling case study, where we establish a causal personal model to estimate individual nutrition effects. Our assessmen
    
[^13]: 通过符合性预测实现置信度感知的顺序推荐系统的精细调整

    Confidence-aware Fine-tuning of Sequential Recommendation Systems via Conformal Prediction

    [https://arxiv.org/abs/2402.08976](https://arxiv.org/abs/2402.08976)

    本研究提出了CPFT框架，通过在顺序推荐系统中精细调整过程中结合交叉熵损失函数和基于符合性预测的损失函数，增强了推荐系统的置信度。CPFT动态生成潜在真实值的项目集合，提升了训练过程中的性能，并提高了推荐的准确性和可信度。

    

    在顺序推荐系统中，通常使用交叉熵损失函数，但在训练过程中未能利用项目置信度分数。为了认识到置信度在将训练目标与评估指标对齐中的关键作用，我们提出了CPFT，这是一个多功能的框架，通过在精细调整过程中将基于符合性预测的损失函数与交叉熵损失函数相结合，增强了推荐系统的置信度。CPFT动态生成一组具有高概率包含真实值的项目，通过将验证数据纳入训练过程而不损害其在模型选择中的作用，丰富了训练过程。这种创新的方法与基于符合性预测的损失函数相结合，更专注于改善推荐集合，从而提高潜在项目预测的置信度。通过通过基于符合性预测的损失函数对项目置信度进行精细调整，CPFT显著提高了模型性能，提供了更精确和可信的推荐。

    arXiv:2402.08976v1 Announce Type: new Abstract: In Sequential Recommendation Systems, Cross-Entropy (CE) loss is commonly used but fails to harness item confidence scores during training. Recognizing the critical role of confidence in aligning training objectives with evaluation metrics, we propose CPFT, a versatile framework that enhances recommendation confidence by integrating Conformal Prediction (CP)-based losses with CE loss during fine-tuning. CPFT dynamically generates a set of items with a high probability of containing the ground truth, enriching the training process by incorporating validation data without compromising its role in model selection. This innovative approach, coupled with CP-based losses, sharpens the focus on refining recommendation sets, thereby elevating the confidence in potential item predictions. By fine-tuning item confidence through CP-based losses, CPFT significantly enhances model performance, leading to more precise and trustworthy recommendations th
    
[^14]: 基于Transformer的顺序推荐中的注意力校准

    Attention Calibration for Transformer-based Sequential Recommendation

    [https://arxiv.org/abs/2308.09419](https://arxiv.org/abs/2308.09419)

    本文针对基于Transformer的顺序推荐中存在的注意力权重分配不准确问题，提出了一种解决方案。

    

    近年来，基于Transformer的顺序推荐（SR）蓬勃发展，其中自注意力机制是其关键组成部分。自注意力被普遍认为能够通过为这些项目学习更大的关注权重，有效地选择来自互动项目序列的信息丰富且相关项目，以用于下一个项目预测。然而，在现实中，这并不总是正确的。我们对一些代表性的基于Transformer的SR模型进行的经验分析显示，很常见的现象是将较大的注意力权重分配给不够相关的项目，这可能导致不准确的推荐。通过进一步深入分析，我们发现两个因素可能导致这种不准确的注意力权重分配：次优的位置编码和嘈杂的输入。因此，在本文中，我们旨在解决现有研究中存在的这一重要且具有挑战性的差距。明确地说，我们提出了一种简单的

    arXiv:2308.09419v2 Announce Type: replace  Abstract: Transformer-based sequential recommendation (SR) has been booming in recent years, with the self-attention mechanism as its key component. Self-attention has been widely believed to be able to effectively select those informative and relevant items from a sequence of interacted items for next-item prediction via learning larger attention weights for these items. However, this may not always be true in reality. Our empirical analysis of some representative Transformer-based SR models reveals that it is not uncommon for large attention weights to be assigned to less relevant items, which can result in inaccurate recommendations. Through further in-depth analysis, we find two factors that may contribute to such inaccurate assignment of attention weights: sub-optimal position encoding and noisy input. To this end, in this paper, we aim to address this significant yet challenging gap in existing works. To be specific, we propose a simple 
    
[^15]: 多模态Transformer蒸馏用于音频-视觉同步

    Multimodal Transformer Distillation for Audio-Visual Synchronization

    [https://arxiv.org/abs/2210.15563](https://arxiv.org/abs/2210.15563)

    该论文提出了一种通过多模态Transformer蒸馏技术来进行训练的MTDVocaLiST模型，能够深度模仿VocaLiST中Transformer的交叉注意力分布和值关系，从而在音频-视觉同步任务中取得了很好的效果。

    

    音频-视觉同步旨在确定视频中的口型运动和语音是否同步。VocaLiST通过融合多模态Transformer来模拟音频-视觉交互信息，达到了最先进的性能。然而，它需要高计算资源，使其在现实世界应用中不切实际。本文提出了一种MTDVocaLiST模型，该模型通过我们提出的多模态Transformer蒸馏（MTD）损失进行训练。MTD损失使MTDVocaLiST模型能够深度模仿VocaLiST中Transformer的交叉注意力分布和值关系。此外，我们利用不确定性加权来充分利用所有层中的交互信息。我们提出的方法在两方面非常有效：从蒸馏方法的角度来看，MTD损失优于其他强蒸馏基线。从经过蒸馏模型的性能角度看：1) MTDVocaLiST 胜过

    arXiv:2210.15563v3 Announce Type: replace-cross  Abstract: Audio-visual synchronization aims to determine whether the mouth movements and speech in the video are synchronized. VocaLiST reaches state-of-the-art performance by incorporating multimodal Transformers to model audio-visual interact information. However, it requires high computing resources, making it impractical for real-world applications. This paper proposed an MTDVocaLiST model, which is trained by our proposed multimodal Transformer distillation (MTD) loss. MTD loss enables MTDVocaLiST model to deeply mimic the cross-attention distribution and value-relation in the Transformer of VocaLiST. Additionally, we harness uncertainty weighting to fully exploit the interaction information across all layers. Our proposed method is effective in two aspects: From the distillation method perspective, MTD loss outperforms other strong distillation baselines. From the distilled model's performance perspective: 1) MTDVocaLiST outperform
    
[^16]: 多行为推荐中的公平因果干预

    Causal Intervention for Fairness in Multi-behavior Recommendation

    [https://arxiv.org/abs/2209.04589](https://arxiv.org/abs/2209.04589)

    通过考虑多种用户行为来减轻流行度偏见，处理了多行为推荐中的公平问题。

    

    推荐系统通常从各种用户行为中学习用户兴趣，包括点击和点击后的行为（例如，点赞和收藏）。然而，这些行为不可避免地表现出流行度偏差，导致一些不公平问题：1）对于相似质量的物品，更受欢迎的物品会获得更多曝光；2）更糟糕的是，流行度较低的受欢迎物品可能会获得更多曝光。现有工作在减轻流行度偏差方面盲目消除偏见，通常忽略物品质量的影响。我们认为，不同用户行为之间（例如转化率）的关系实际上反映了物品质量。因此，为了处理不公平问题，我们提出通过考虑多种用户行为来减轻流行度偏见。在这项工作中，我们研究了多行为推荐中交互生成过程背后的因果关系。

    arXiv:2209.04589v2 Announce Type: replace-cross  Abstract: Recommender systems usually learn user interests from various user behaviors, including clicks and post-click behaviors (e.g., like and favorite). However, these behaviors inevitably exhibit popularity bias, leading to some unfairness issues: 1) for items with similar quality, more popular ones get more exposure; and 2) even worse the popular items with lower popularity might receive more exposure. Existing work on mitigating popularity bias blindly eliminates the bias and usually ignores the effect of item quality. We argue that the relationships between different user behaviors (e.g., conversion rate) actually reflect the item quality. Therefore, to handle the unfairness issues, we propose to mitigate the popularity bias by considering multiple user behaviors.   In this work, we examine causal relationships behind the interaction generation procedure in multi-behavior recommendation. Specifically, we find that: 1) item popula
    
[^17]: 在语言模型中实现对3D分子-文本的解释

    Towards 3D Molecule-Text Interpretation in Language Models. (arXiv:2401.13923v1 [cs.LG])

    [http://arxiv.org/abs/2401.13923](http://arxiv.org/abs/2401.13923)

    提出了一个名为3D-MoLM的模型，通过给语言模型配备一个3D分子编码器，实现了对3D分子-文本的解释和分析，此模型在下游任务上显著优于现有基线。

    

    语言模型（LMs）在各个领域有着很大的影响。然而，它们对于理解3D分子结构的固有限制极大地限制了它们在生物分子领域的潜力。为了弥补这一差距，我们关注于3D分子-文本解释，并提出3D-MoLM：3D分子语言模型。具体而言，3D-MoLM通过为LM配备一个3D分子编码器，使得LM能够解释和分析3D分子。这种集成是通过一个3D分子-文本投影器实现的，它连接了3D分子编码器的表示空间和LM的输入空间。此外，为了增强3D-MoLM在跨模态分子理解和指令跟随方面的能力，我们精心策划了一个以3D分子为中心的指引调整数据集--3D-MoIT。通过3D分子-文本对齐和3D分子中心的指引调整，3D-MoLM建立了3D分子编码器和LM的集成。它在下游任务上显著超过了现有的基线。

    Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder's representation space and the LM's input space. Moreover, to enhance 3D-MoLM's ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset -- 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks,
    
[^18]: SpeechDPR: 开放领域口语问答的端到端口语段落检索

    SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering. (arXiv:2401.13463v1 [cs.CL])

    [http://arxiv.org/abs/2401.13463](http://arxiv.org/abs/2401.13463)

    SpeechDPR是第一个用于开放领域口语问答的端到端框架，能够从口语存档中检索可能包含答案的段落。通过融合无监督ASR和文本密集检索器的知识，SpeechDPR能够获得较好的性能，并且在UASR性能较差时表现更加鲁棒。

    

    口语问答(SQA)是机器通过在给定口语段落中找到答案范围来回答用户问题的关键。过去的SQA方法没有使用ASR，以避免识别错误和词汇外问题。然而，实际的开放领域SQA(openSQA)问题中，机器需要首先从口语存档中检索可能包含答案的段落。本文提出了第一个已知的用于openSQA问题检索组件的端到端框架SpeechDPR。SpeechDPR通过从无监督ASR(UASR)和文本密集检索器(TDR)的级联模型中提炼知识，学习句子级语义表示。不需要手动转录的语音数据。初步实验表明，与级联的UASR和TDR模型相比，性能相当，并且在UASR性能较差时显著提高，验证了这种方法更加鲁棒。

    Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage. SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems. However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered. This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem. SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR). No manually transcribed speech data is needed. Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robus
    
[^19]: 基于Transformer深度学习的多语言仇恨言论分析和检测

    Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning. (arXiv:2401.11021v1 [cs.CL])

    [http://arxiv.org/abs/2401.11021](http://arxiv.org/abs/2401.11021)

    提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。

    

    仇恨言论是直接攻击或宣传针对特定群体或个人的憎恨的有害内容，例如种族主义、宗教或性取向等。这会对社交媒体平台上的社会生活产生影响，因为通过社交媒体分享的仇恨内容可能会对个人和社区造成伤害。随着网络上仇恨言论的增加，自动化检测作为自然语言处理的一个任务的需求也在增加。在这项工作中，提出了一种使用基于Transformer模型在社交媒体上检测仇恨言论的方法，如Twitter、Facebook、WhatsApp、Instagram等。该模型独立于语言，并已在意大利语、英语、德语、孟加拉语上进行了测试。黄金标准数据集由知名研究者Zeerak Talat、Sara Tonelli、Melanie Siegel和Rezaul Karim收集。所提出模型在仇恨言论检测方面的成功率高于现有基准和最先进模型，准确率较高。

    Hate speech is harmful content that directly attacks or promotes hatred against members of groups or individuals based on actual or perceived aspects of identity, such as racism, religion, or sexual orientation. This can affect social life on social media platforms as hateful content shared through social media can harm both individuals and communities. As the prevalence of hate speech increases online, the demand for automated detection as an NLP task is increasing. In this work, the proposed method is using transformer-based model to detect hate speech in social media, like twitter, Facebook, WhatsApp, Instagram, etc. The proposed model is independent of languages and has been tested on Italian, English, German, Bengali. The Gold standard datasets were collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel, and Rezaul Karim. The success rate of the proposed model for hate speech detection is higher than the existing baseline and state-of-the-art models with acc
    
[^20]: NineRec: 用于评估可迁移推荐的基准数据集套件

    NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation. (arXiv:2309.07705v1 [cs.IR])

    [http://arxiv.org/abs/2309.07705](http://arxiv.org/abs/2309.07705)

    NineRec是一个用于评估可迁移推荐的数据集套件，包括一个大规模的源域推荐数据集和九个多样的目标域推荐数据集。每个物品由文本描述和高分辨率封面图像表示。

    

    近年来，从物品的原始特征（如图像、文本、音频等）学习推荐系统模型，称为MoRec，引起了越来越多的兴趣。 MoRec的一个关键优势是它可以轻松受益于其他领域的进展，如自然语言处理（NLP）和计算机视觉（CV）。此外，它通过特征自然支持不同系统之间的迁移学习，称为可迁移推荐系统或TransRec。然而，迄今为止，与NLP和CV领域的开创性基础模型相比，TransRec取得了很小的进展。缺乏大规模、高质量的推荐数据集是一个重大障碍。为此，我们介绍了NineRec，这是一个TransRec数据集套件，包括一个大规模的源域推荐数据集和九个多样的目标域推荐数据集。NineRec中的每个物品都由一个文本描述和一个高分辨率的封面图像表示。通过NineRec，我们可以实现Tran

    Learning a recommender system model from an item's raw modality features (such as image, text, audio, etc.), called MoRec, has attracted growing interest recently. One key advantage of MoRec is that it can easily benefit from advances in other fields, such as natural language processing (NLP) and computer vision (CV). Moreover, it naturally supports transfer learning across different systems through modality features, known as transferable recommender systems, or TransRec.  However, so far, TransRec has made little progress, compared to groundbreaking foundation models in the fields of NLP and CV. The lack of large-scale, high-quality recommendation datasets poses a major obstacle. To this end, we introduce NineRec, a TransRec dataset suite that includes a large-scale source domain recommendation dataset and nine diverse target domain recommendation datasets. Each item in NineRec is represented by a text description and a high-resolution cover image. With NineRec, we can implement Tran
    
[^21]: 评估潮起潮落：对不同平台间问答趋势的深入分析

    Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v1 [cs.SI])

    [http://arxiv.org/abs/2309.05961](http://arxiv.org/abs/2309.05961)

    本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。

    

    社区问答平台因其快速回答用户查询的能力而越来越受欢迎。这些回答速度的快慢取决于查询特定和用户相关的因素的综合。本文通过研究六个高度流行的社区问答平台，分析了这些因素在其中的作用。我们的调查揭示了问题的第一个回答所花费的时间与元数据、问题的构成方式和用户之间的互动水平之间的关联。此外，通过使用传统的机器学习模型分析这些元数据和用户互动模式，我们试图预测哪些查询将迅速获得初始回答。

    Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
    
[^22]: 点击率预测的时间兴趣网络

    Temporal Interest Network for Click-Through Rate Prediction. (arXiv:2308.08487v1 [cs.IR])

    [http://arxiv.org/abs/2308.08487](http://arxiv.org/abs/2308.08487)

    本文提出了时间兴趣网络（TIN），用于捕捉行为与目标之间的四重语义和时间相关性，以预测点击率的效果和已有方法对这种相关性的学习程度尚不清楚。

    

    用户行为的历史是预测点击率最重要的特征之一，因为它们与目标项目具有强烈的语义和时间相关性。虽然已有文献分别研究了这些相关性，但尚未分析它们的组合，即行为语义、目标语义、行为时间和目标时间的四重相关性。这种相关性对性能的影响以及现有方法学习这种相关性的程度尚不清楚。为了填补这一空白，我们在实践中测量了四重相关性，并观察到直观而强大的四重模式。我们测量了几种代表性的用户行为方法的学习相关性，但令人惊讶的是，它们都没有学习到这样的模式，特别是时间模式。在本文中，我们提出了时间兴趣网络（TIN）来捕捉行为与目标之间的四重语义和时间相关性。

    The history of user behaviors constitutes one of the most significant characteristics in predicting the click-through rate (CTR), owing to their strong semantic and temporal correlation with the target item. While the literature has individually examined each of these correlations, research has yet to analyze them in combination, that is, the quadruple correlation of (behavior semantics, target semantics, behavior temporal, and target temporal). The effect of this correlation on performance and the extent to which existing methods learn it remain unknown. To address this gap, we empirically measure the quadruple correlation and observe intuitive yet robust quadruple patterns. We measure the learned correlation of several representative user behavior methods, but to our surprise, none of them learn such a pattern, especially the temporal one.  In this paper, we propose the Temporal Interest Network (TIN) to capture the quadruple semantic and temporal correlation between behaviors and th
    
[^23]: 我们的模型在MovieLens上取得了出色的表现：这意味着什么？

    Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?. (arXiv:2307.09985v1 [cs.IR])

    [http://arxiv.org/abs/2307.09985](http://arxiv.org/abs/2307.09985)

    该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。

    

    推荐系统评估的典型基准数据集是在某一时间段内在平台上生成的用户-物品交互数据。交互生成机制部分解释了为什么用户与物品进行交互（如喜欢、购买、评分）以及特定交互发生的背景。在本研究中，我们对MovieLens数据集进行了细致的分析，并解释了使用该数据集进行评估推荐算法时可能的影响。我们从分析中得出了一些主要发现。首先，在用户与MovieLens平台交互的不同阶段存在显著差异。早期交互在很大程度上定义了用户画像，影响了后续的交互。其次，用户交互受到平台内部推荐算法推荐的候选电影的很大影响。删除靠近最后几次交互的交互会对结果产生较大影响。

    A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g.,like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis on the MovieLens dataset and explain the potential impact on using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Removal of interactions that happen nearer to the last few interactions 
    
[^24]: 用深度学习简化社交媒体信息检索以支持公共卫生研究

    Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])

    [http://arxiv.org/abs/2306.16001](http://arxiv.org/abs/2306.16001)

    本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。

    

    社交媒体在流行病监测中的利用已经得到了很好的证实。然而，当使用预定义的词汇表来检索相关语料库时，常常会引入偏见。本研究介绍了一个框架，旨在构建医学俗语和统一医学语言系统（UMLS）概念的广泛字典。该框架由三个模块组成：基于BERT的命名实体识别（NER）模型，用于从社交媒体内容中识别出医学实体；深度学习驱动的标准化模块，用于对提取出的实体进行规范化处理；半监督聚类模块，将最可能的UMLS概念分配给每个规范化实体。我们将该框架应用于从2020年2月1日到2022年4月30日期间与COVID-19相关的推文，生成了一个症状词典（可在https://github.com/ningkko/UMLS_colloquialism/上获取），其中包含9,249个标准化实体，映射到876个UMLS概念和38,175个俚语表达。该框架的演示

    The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
    
[^25]: 基于Sheaf神经网络的基于图的推荐系统

    Sheaf Neural Networks for Graph-based Recommender Systems. (arXiv:2304.09097v1 [cs.IR])

    [http://arxiv.org/abs/2304.09097](http://arxiv.org/abs/2304.09097)

    基于Sheaf神经网络的模型提出了一种新的向量空间表示方法，使得其在基准推荐任务上获得最先进的性能表现。

    

    近年来，Graph神经网络在许多应用中得到了广泛应用，包括推荐系统。Graph神经网络对其他方法的优越性在于，推荐系统中的许多问题可以自然地建模为图，其中节点可以是用户或项目，边代表偏好关系。 在当前的Graph神经网络方法中，节点用在训练时学习到的静态向量表示。这种静态向量可能只适用于捕捉定义它们的一些用户或项目的微妙差别。为了克服这个限制，我们建议使用最近提出的启发范畴论的模型：Sheaf神经网络。Sheaf神经网络及其连接的拉普拉斯可以通过将每个节点（以及边）与向量空间而不是单个向量相关联来解决上述问题。向量空间表示更丰富，并允许在推理时选择正确的表示。这种方法使我们的模型更具表现力和灵活性，在几个基准推荐任务上实现了最先进的性能。

    Recent progress in Graph Neural Networks has resulted in wide adoption by many applications, including recommendation systems. The reason for Graph Neural Networks' superiority over other approaches is that many problems in recommendation systems can be naturally modeled as graphs, where nodes can be either users or items and edges represent preference relationships. In current Graph Neural Network approaches, nodes are represented with a static vector learned at training time. This static vector might only be suitable to capture some of the nuances of users or items they define. To overcome this limitation, we propose using a recently proposed model inspired by category theory: Sheaf Neural Networks. Sheaf Neural Networks, and its connected Laplacian, can address the previous problem by associating every node (and edge) with a vector space instead than a single vector. The vector space representation is richer and allows picking the proper representation at inference time. This approa
    
[^26]: 序列推荐的等变性对比学习

    Equivariant Contrastive Learning for Sequential Recommendation. (arXiv:2211.05290v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.05290](http://arxiv.org/abs/2211.05290)

    本论文提出了序列推荐的等变性对比学习（ECL-SR）方法，通过使用条件判别器来使得学习到的用户行为表示对于侵入性增强敏感并对轻微增强不敏感，从而提高了序列推荐模型的区分能力。

    

    对比学习（CL）通过信息自监督信号有益于训练序列推荐模型。现有的解决方案采用通用的序列数据增强策略生成正样本，并鼓励它们的表示具有不变性。然而，由于用户行为序列的固有特性，一些增强策略（如物品替换）可能导致用户意图的改变。为了避免不选定适所有增强策略的不变表示，我们提出了序列推荐的等变性对比学习（ECL-SR），该方法赋予SR模型强大的区分能力，使学习到的用户行为表示对侵入性增强（如物品替换）敏感并对轻微增强（如特征级丢失遮蔽）不敏感。具体而言，我们使用条件判别器来捕捉由于物品替换而产生的行为差异。

    Contrastive learning (CL) benefits the training of sequential recommendation models with informative self-supervision signals. Existing solutions apply general sequential data augmentation strategies to generate positive pairs and encourage their representations to be invariant. However, due to the inherent properties of user behavior sequences, some augmentation strategies, such as item substitution, can lead to changes in user intent. Learning indiscriminately invariant representations for all augmentation strategies might be suboptimal. Therefore, we propose Equivariant Contrastive Learning for Sequential Recommendation (ECL-SR), which endows SR models with great discriminative power, making the learned user behavior representations sensitive to invasive augmentations (e.g., item substitution) and insensitive to mild augmentations (e.g., featurelevel dropout masking). In detail, we use the conditional discriminator to capture differences in behavior due to item substitution, which e
    

