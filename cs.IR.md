# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^2] | [The Family Tree Graph as a Predictor of the Family Members' Satisfaction with One Another.](http://arxiv.org/abs/2305.01552) | 该研究发现家庭成员满意度与家族树图，家庭规模，孩子是否为同父母，以及家庭收入有关。 |
| [^3] | [Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks.](http://arxiv.org/abs/2305.01548) | 本论文提出 EXPLAIGNN 方法，使用图神经网络构建异构图，从多个数据源中提取信息，达到更全面准确的问答效果，并提供了用户可理解的答案解释。 |
| [^4] | [Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization.](http://arxiv.org/abs/2305.01522) | 该论文提出了一种新的反事实学习排序方法，通过基于曝光的风险正则化对IPS估计进行调整，以确保学习排名模型与给定的安全模型接近，从而在部署过程中降低风险。 |
| [^5] | [MTrainS: Improving DLRM training efficiency using heterogeneous memories.](http://arxiv.org/abs/2305.01515) | 本文旨在研究现实中部署的深度学习推荐模型中嵌入表的带宽需求和局部性，并通过使用异构内存提出MTrainS来提高DLRM训练效率。 |
| [^6] | [Retrieving Comparative Arguments using Ensemble Methods and Neural Information Retrieval.](http://arxiv.org/abs/2305.01513) | 本文针对Touche实验室任务提出了一个方案，该方案使用决策树集成算法和大型上下文化语言模型，能够按照相关性和论证支持排序比较文档。该方法在竞赛中表现优异，可用于改进信息检索和对话系统中处理比较查询的性能。 |
| [^7] | [Report from Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education.](http://arxiv.org/abs/2305.01509) | 本篇文章是Dagstuhl研讨会23031“前沿信息获取实验研究和教育”的报告，主要讨论了通过更负责任的实验实践来提高信息获取技术的有效性和科学教育，会议召集了各领域专家，提出了进一步改善我们的研究方法和研究教育的方向。 |
| [^8] | [NewsPanda: Media Monitoring for Timely Conservation Action.](http://arxiv.org/abs/2305.01503) | NewsPanda是一个可以自动检测和分析与环保和基础建设相关的网上文章的工具。该工具使用主动学习方法和噪声校正算法对BERT模型进行微调以识别相关文章，并提取关键字和找到相关来源。已被世界自然基金会团队在英国、印度和尼泊尔成功部署。 |
| [^9] | [Multimodal Neural Databases.](http://arxiv.org/abs/2305.01447) | 本文提出了多模态神经数据库框架（MMNDBs），可以回答涉及文本和图像等不同输入模态的复杂查询，具有类似数据库的功能。 |
| [^10] | [An experimental framework for designing document structure for users' decision making - An empirical study of recipes.](http://arxiv.org/abs/2305.01359) | 本研究提出了实验框架，通过汇集非专业读者的见解来确定文档的有用内容，以提高非专业读者的决策能力。研究结果表明，在食谱中为每个烹饪步骤的末尾安排副标题的适当成分或注释可以显著增加食谱的可读性。 |
| [^11] | [Optimizing Guided Traversal for Fast Learned Sparse Retrieval.](http://arxiv.org/abs/2305.01203) | 本文通过优化BM25引导的索引遍历，提出了一个使用稀疏表示进行快速学习稀疏检索的解决方案。这种方案比原始MaxScore方法快得多，同时保留相关性的有效性。 |
| [^12] | [Exploration of Unranked Items in Safe Online Learning to Re-Rank.](http://arxiv.org/abs/2305.01202) | 本文提出了一种安全的在线学习排序算法，通过将当前排名中的一个项目与排名外的项目高效地交换来执行探索，并基于Kullback-Leibler上置信度界限（KL-UCB）对未排序项目进行乐观选择和安全的排序，以提高长期收益。 |
| [^13] | [Complex Logical Reasoning over Knowledge Graphs using Large Language Models.](http://arxiv.org/abs/2305.01157) | 本文提出了一种使用大型语言模型的解耦方法，将复杂的知识图谱推理形式化为上下文知识图搜索和抽象逻辑查询推理的组合，与现有方法相比，它在多个逻辑查询结构的标准基准数据集上都表现出更好的性能，并且在更高复杂性的查询中获得了显着的性能提升。 |
| [^14] | [Ripple Knowledge Graph Convolutional Networks For Recommendation Systems.](http://arxiv.org/abs/2305.01147) | 本文介绍了一种基于知识图谱的深度学习模型RKGCN，它能够动态分析用户的偏好并推荐出合适的物品。该模型在包括电影、书籍和音乐在内的三个真实世界的数据集上比5个基准模型表现更好。 |
| [^15] | [Multidimensional Fairness in Paper Recommendation.](http://arxiv.org/abs/2305.01141) | 本文提出了三种公平方法，考虑到作者多样性，以解决论文推荐中的潜在偏见，这些方法可以同时提供跨多个受保护变量的公正结果。 |
| [^16] | [CHIC: Corporate Document for Visual question Answering.](http://arxiv.org/abs/2305.01054) | CHIC提供了一个公共企业文档问答数据库，以满足不同类型企业文件的需求。 |
| [^17] | [LooPy: A Research-Friendly Mix Framework for Music Information Retrieval on Electronic Dance Music.](http://arxiv.org/abs/2305.01051) | LooPy是一种Python软件包，为MIR提供了一种面向电子舞曲的基础设施，可用于自动生成EDM音频，并提供了框架来构建专业级的模板，使用户可以从指定的旋律和和弦中呈现出制作精良的歌曲轨道或仅通过使用符号性的旋律生成器，提供具有多种风格的音轨。 |
| [^18] | [RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure.](http://arxiv.org/abs/2211.05239) | RecD 是一种为 DLRM 训练提供去重功能的端到端基础设施优化，解决了由于特征重复造成的海量存储、预处理和训练开销，引入了新的张量格式 InverseKeyedJaggedTensors (IKJTs) 来去除特征值的重复，使 DLRM 模型架构能够更好地利用数据的重复性提高训练吞吐量。 |
| [^19] | [Graph Neural Networks for Link Prediction with Subgraph Sketching.](http://arxiv.org/abs/2209.15486) | 本研究提出了一种名为ELPH的全图GNN模型，它使用子图草图作为消息传递，以缓解LP任务中子图之间的冗余问题，并在多个基准数据集上取得了最先进的结果。 |
| [^20] | [Boosted Off-Policy Learning.](http://arxiv.org/abs/2208.01148) | 我们提出了一种基于Boosting的离线策略学习算法，将基础学习器简化为监督学习，获得了广泛的实际效益；实验结果表明其应用能力优于深度神经网络的离线策略学习和简单回归方法。 |

# 详细

[^1]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^2]: 家族树图与家庭成员满意度之间的关系研究

    The Family Tree Graph as a Predictor of the Family Members' Satisfaction with One Another. (arXiv:2305.01552v1 [physics.soc-ph])

    [http://arxiv.org/abs/2305.01552](http://arxiv.org/abs/2305.01552)

    该研究发现家庭成员满意度与家族树图，家庭规模，孩子是否为同父母，以及家庭收入有关。

    

    个人对核心家庭和扩展家庭的满意度在一个人的日常生活中扮演着至关重要的角色。因此，更好地了解决定一个人对家庭满意度的特征可以为更好的社会政策设计打开大门。为此，该研究考察了家族树图与家庭成员对核心家庭和扩展家庭的满意度之间的关系。我们收集了来自486个家庭的数据，其中包括家族树图和家庭成员之间的满意度。我们得到了一个能够解释75%家庭成员对彼此满意度的模型。我们发现了让家庭成员更加满意的三个指标。首先，平均而言，较大的家庭有更满意的成员。此外，没有继兄弟姐妹的同父母家庭-即成年子女已经成家的家庭，在兄弟姐妹和父母方面也更满意。最后，家庭成员的平均满意度和家庭的收入水平息息相关。

    Individuals' satisfaction with their nuclear and extended family plays a critical role in individuals everyday life. Thus, a better understanding of the features that determine one's satisfaction with her family can open the door to the design of better sociological policies. To this end, this study examines the relationship between the family tree graph and family members' satisfaction with their nuclear and extended family. We collected data from 486 families which included a family tree graph and family members' satisfaction with each other. We obtain a model that is able to explain 75\% of the family members' satisfaction with one another. We found three indicators for more satisfied families. First, larger families, on average, have more satisfied members. Moreover, families with kids from the same parents - i.e., without step-siblings also express more satisfaction from both their siblings and parents when the children are already adults. Lastly, the average satisfaction of the f
    
[^3]: 迭代图神经网络实现异构数据可解释对话问答

    Explainable Conversational Question Answering over Heterogeneous Sources via Iterative Graph Neural Networks. (arXiv:2305.01548v1 [cs.IR])

    [http://arxiv.org/abs/2305.01548](http://arxiv.org/abs/2305.01548)

    本论文提出 EXPLAIGNN 方法，使用图神经网络构建异构图，从多个数据源中提取信息，达到更全面准确的问答效果，并提供了用户可理解的答案解释。

    

    在对话问答中，用户通过一系列上下文不完整的表达来表达他们的信息需求。典型的 ConvQA 方法依赖于单一数据源(知识库、文本语料库或一组表格)，因此无法从多个数据源的覆盖范围和冗余性中获益。我们的 EXPLAIGNN 方法通过混合数据源并提供用户可理解的答案解释来克服这些限制。它从知识库、文本语料库、网络表格和信息框中检索实体和证据片段，并构建一个异构图。然后通过图神经网络进行迭代缩减，直到最佳答案及其解释被提炼出来。实验证明，EXPLAIGNN 提高了现有基线方式的性能。用户研究表明，导出的答案被终端用户理解。

    In conversational question answering, users express their information needs through a series of utterances with incomplete context. Typical ConvQA methods rely on a single source (a knowledge base (KB), or a text corpus, or a set of tables), thus being unable to benefit from increased answer coverage and redundancy of multiple sources. Our method EXPLAIGNN overcomes these limitations by integrating information from a mixture of sources with user-comprehensible explanations for answers. It constructs a heterogeneous graph from entities and evidence snippets retrieved from a KB, a text corpus, web tables, and infoboxes. This large graph is then iteratively reduced via graph neural networks that incorporate question-level attention, until the best answers and their explanations are distilled. Experiments show that EXPLAIGNN improves performance over state-of-the-art baselines. A user study demonstrates that derived answers are understandable by end users.
    
[^4]: 带有基于曝光的风险最小化的反事实学习排序安全部署

    Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization. (arXiv:2305.01522v1 [cs.IR])

    [http://arxiv.org/abs/2305.01522](http://arxiv.org/abs/2305.01522)

    该论文提出了一种新的反事实学习排序方法，通过基于曝光的风险正则化对IPS估计进行调整，以确保学习排名模型与给定的安全模型接近，从而在部署过程中降低风险。

    

    反事实学习排序（CLTR）依赖于基于曝光的倒数概率评分（IPS），一种LTR特定的自适应IPS来纠正位置偏差。虽然IPS可以提供无偏和一致的估计，但通常会受到高方差的影响。尤其是当可用点击数据很少时，这种方差可能会导致CLTR学习次优的排名行为。因此，现有的CLTR方法带来了重大风险，因为简单地部署它们的模型可能会导致用户体验非常差。我们引入了一种新的风险感知CLTR方法，具有安全部署的理论保证。我们对LTR的IPS估计应用了一种新的基于曝光的风险正则化概念。我们的风险正则化惩罚学习模型的排名行为与给定安全模型的不匹配。因此，在IPS估计存在高度不确定性时，它确保学习排名模型与可信模型保持接近，从而大大降低了部署过程中的风险。

    Counterfactual learning to rank (CLTR) relies on exposure-based inverse propensity scoring (IPS), a LTR-specific adaptation of IPS to correct for position bias. While IPS can provide unbiased and consistent estimates, it often suffers from high variance. Especially when little click data is available, this variance can cause CLTR to learn sub-optimal ranking behavior. Consequently, existing CLTR methods bring significant risks with them, as naively deploying their models can result in very negative user experiences. We introduce a novel risk-aware CLTR method with theoretical guarantees for safe deployment. We apply a novel exposure-based concept of risk regularization to IPS estimation for LTR. Our risk regularization penalizes the mismatch between the ranking behavior of a learned model and a given safe model. Thereby, it ensures that learned ranking models stay close to a trusted model, when there is high uncertainty in IPS estimation, which greatly reduces the risks during deployme
    
[^5]: MTrainS: 使用异构内存提高DLRM训练效率

    MTrainS: Improving DLRM training efficiency using heterogeneous memories. (arXiv:2305.01515v1 [cs.IR])

    [http://arxiv.org/abs/2305.01515](http://arxiv.org/abs/2305.01515)

    本文旨在研究现实中部署的深度学习推荐模型中嵌入表的带宽需求和局部性，并通过使用异构内存提出MTrainS来提高DLRM训练效率。

    

    推荐模型非常庞大，在训练时需要使用几TB的内存。为了获得更好的质量，模型的大小和复杂度随着时间的推移而增长，这需要更多的训练数据以避免过拟合。这种模型增长要求数据中心大量资源。因此，训练效率变得越来越重要，以保持数据中心的功率需求可控。在深度学习推荐模型(DLRM)中，通过嵌入表捕捉分类输入的稀疏特征是模型大小的主要贡献者，并且需要高内存带宽。在本文中，我们研究了现实中部署模型中嵌入表的带宽需求和局部性。我们观察到，不同表的带宽要求不均匀，并且嵌入表显示出高时序局部性。然后，我们设计了MTrainS，利用异构内存，包括字节和块可寻址存储类内存，用于DLRM的分层训练。

    Recommendation models are very large, requiring terabytes (TB) of memory during training. In pursuit of better quality, the model size and complexity grow over time, which requires additional training data to avoid overfitting. This model growth demands a large number of resources in data centers. Hence, training efficiency is becoming considerably more important to keep the data center power demand manageable. In Deep Learning Recommendation Models (DLRM), sparse features capturing categorical inputs through embedding tables are the major contributors to model size and require high memory bandwidth. In this paper, we study the bandwidth requirement and locality of embedding tables in real-world deployed models. We observe that the bandwidth requirement is not uniform across different tables and that embedding tables show high temporal locality. We then design MTrainS, which leverages heterogeneous memory, including byte and block addressable Storage Class Memory for DLRM hierarchicall
    
[^6]: 利用集成方法和神经信息检索检索比较论点

    Retrieving Comparative Arguments using Ensemble Methods and Neural Information Retrieval. (arXiv:2305.01513v1 [cs.IR])

    [http://arxiv.org/abs/2305.01513](http://arxiv.org/abs/2305.01513)

    本文针对Touche实验室任务提出了一个方案，该方案使用决策树集成算法和大型上下文化语言模型，能够按照相关性和论证支持排序比较文档。该方法在竞赛中表现优异，可用于改进信息检索和对话系统中处理比较查询的性能。

    

    本文针对Touche实验室“比较问题下的论证检索”任务提出了一个方案。我们的团队Katana提供了基于决策树集成算法的多种方法来按照相关性和论证支持排序比较文档。我们使用PyTerrier库将集成模型应用于排序问题，并考虑基于统计文本特征和基于比较结构的特征。我们还采用了大型上下文化语言建模技术，例如BERT，来解决所提出的排名任务。为了将这种技术与排序建模相结合，我们利用了神经排名库OpenNIR。我们的系统明显优于提议的基准，并在竞赛的官方指标（对于NDCG@5得分）中在相关性上排名第一，质量上排名第二。提出的模型可以帮助改进信息检索和对话系统中处理比较查询的性能。

    In this paper, we present a submission to the Touche lab's Task 2 on Argument Retrieval for Comparative Questions. Our team Katana supplies several approaches based on decision tree ensembles algorithms to rank comparative documents in accordance with their relevance and argumentative support. We use PyTerrier library to apply ensembles models to a ranking problem, considering statistical text features and features based on comparative structures. We also employ large contextualized language modelling techniques, such as BERT, to solve the proposed ranking task. To merge this technique with ranking modelling, we leverage neural ranking library OpenNIR.  Our systems substantially outperforming the proposed baseline and scored first in relevance and second in quality according to the official metrics of the competition (for measure NDCG@5 score). Presented models could help to improve the performance of processing comparative queries in information retrieval and dialogue systems.
    
[^7]: Dagstuhl研讨会23031：“前沿信息获取实验研究和教育”。报告。

    Report from Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education. (arXiv:2305.01509v1 [cs.IR])

    [http://arxiv.org/abs/2305.01509](http://arxiv.org/abs/2305.01509)

    本篇文章是Dagstuhl研讨会23031“前沿信息获取实验研究和教育”的报告，主要讨论了通过更负责任的实验实践来提高信息获取技术的有效性和科学教育，会议召集了各领域专家，提出了进一步改善我们的研究方法和研究教育的方向。

    

    本文记录了Dagstuhl研讨会23031“前沿信息获取实验研究和教育”的计划和成果，会议汇聚了来自12个国家的37名参与者。研讨会涉及技术增强型信息访问（信息检索、推荐系统、自然语言处理）并特别聚焦于对其进行更负责任的实验实践以获得更有效的结果，既适用于研究，也适用于科学教育。会议召集了信息访问各子领域的专家，即信息检索、推荐系统、自然语言处理、信息科学和人机交互，以共同理解下一代信息访问系统面临的问题和挑战，并从研究和实验的角度讨论现有的解决方案和障碍，并提出未来需要追求的方向，以期改善我们的研究方法和研究教育。

    This report documents the program and the outcomes of Dagstuhl Seminar 23031 ``Frontiers of Information Access Experimentation for Research and Education'', which brought together 37 participants from 12 countries.  The seminar addressed technology-enhanced information access (information retrieval, recommender systems, natural language processing) and specifically focused on developing more responsible experimental practices leading to more valid results, both for research as well as for scientific education.  The seminar brought together experts from various sub-fields of information access, namely IR, RS, NLP, information science, and human-computer interaction to create a joint understanding of the problems and challenges presented by next generation information access systems, from both the research and the experimentation point of views, to discuss existing solutions and impediments, and to propose next steps to be pursued in the area in order to improve not also our research met
    
[^8]: NewsPanda: 用于及时保护行动的媒体监控工具

    NewsPanda: Media Monitoring for Timely Conservation Action. (arXiv:2305.01503v1 [cs.IR])

    [http://arxiv.org/abs/2305.01503](http://arxiv.org/abs/2305.01503)

    NewsPanda是一个可以自动检测和分析与环保和基础建设相关的网上文章的工具。该工具使用主动学习方法和噪声校正算法对BERT模型进行微调以识别相关文章，并提取关键字和找到相关来源。已被世界自然基金会团队在英国、印度和尼泊尔成功部署。

    

    环保非政府组织对监测相关媒体并及时了解基础建设项目的更新具有重要兴趣，因为这些项目可能会对重要的保护区域产生巨大影响。然而，这种监测很难且需要耗费时间。我们介绍了一个名为NewsPanda的工具包，它可以自动检测和分析与环保和基础建设相关的网上文章。我们使用主动学习方法和噪声校正算法对BERT模型进行微调，以识别与保护和基础建设相关的文章。对已识别出的文章，我们进行进一步的分析，提取关键字并找到可能相关的来源。NewsPanda自2022年2月以来已被世界自然基金会团队在英国、印度和尼泊尔成功部署。它目前监测了印度80,000个网站和1,074个保护地点。

    Non-governmental organizations for environmental conservation have a significant interest in monitoring conservation-related media and getting timely updates about infrastructure construction projects as they may cause massive impact to key conservation areas. Such monitoring, however, is difficult and time-consuming. We introduce NewsPanda, a toolkit which automatically detects and analyzes online articles related to environmental conservation and infrastructure construction. We fine-tune a BERT-based model using active learning methods and noise correction algorithms to identify articles that are relevant to conservation and infrastructure construction. For the identified articles, we perform further analysis, extracting keywords and finding potentially related sources. NewsPanda has been successfully deployed by the World Wide Fund for Nature teams in the UK, India, and Nepal since February 2022. It currently monitors over 80,000 websites and 1,074 conservation sites across India an
    
[^9]: 多模态神经数据库

    Multimodal Neural Databases. (arXiv:2305.01447v1 [cs.MM])

    [http://arxiv.org/abs/2305.01447](http://arxiv.org/abs/2305.01447)

    本文提出了多模态神经数据库框架（MMNDBs），可以回答涉及文本和图像等不同输入模态的复杂查询，具有类似数据库的功能。

    

    近年来，文本、图像和其他模态的松散结构数据的增加呼吁新的查询方法。多媒体信息检索填补了这个空白并在最近几年取得了令人兴奋的进展。检索大规模多媒体档案的任务已经经历了巨大的性能提升，这在很大程度上是由于多模态深度学习的最近发展所推动的。然而，这个领域的方法在它们所支持的查询类型上仍然受到限制，尤其是它们无法回答类似数据库的查询。因此，受神经数据库的最新工作启发，我们提出了一个新框架，命名为多模态神经数据库（MMNDBs）。MMNDBs可以回答涉及不同输入模态（例如文本和图像）的推理的复杂类似数据库的查询。在本文中，我们提出了第一个能够满足这一系列要求的架构，并通过几个基线测试了它的性能。

    The rise in loosely-structured data available through text, images, and other modalities has called for new ways of querying them. Multimedia Information Retrieval has filled this gap and has witnessed exciting progress in recent years. Tasks such as search and retrieval of extensive multimedia archives have undergone massive performance improvements, driven to a large extent by recent developments in multimodal deep learning. However, methods in this field remain limited in the kinds of queries they support and, in particular, their inability to answer database-like queries. For this reason, inspired by recent work on neural databases, we propose a new framework, which we name Multimodal Neural Databases (MMNDBs). MMNDBs can answer complex database-like queries that involve reasoning over different input modalities, such as text and images, at scale. In this paper, we present the first architecture able to fulfill this set of requirements and test it with several baselines, showing th
    
[^10]: 设计用户决策文档结构的实验框架 - 以食谱为例的实证研究

    An experimental framework for designing document structure for users' decision making - An empirical study of recipes. (arXiv:2305.01359v1 [cs.DL])

    [http://arxiv.org/abs/2305.01359](http://arxiv.org/abs/2305.01359)

    本研究提出了实验框架，通过汇集非专业读者的见解来确定文档的有用内容，以提高非专业读者的决策能力。研究结果表明，在食谱中为每个烹饪步骤的末尾安排副标题的适当成分或注释可以显著增加食谱的可读性。

    

    在远程区域进行有效的异步通信需要优质的文本文档，特别是在COVID-19大流行期间。然而，为了改善非专业读者的决策能力而定义首选的文档结构（内容和布局）具有挑战性。因为一方面，无法仅通过收集专业知识来确定各种读者有用的内容类型。而另一方面，还没有建立起从用户角度评估文档有用性的方法。本研究提出了实验性框架，通过汇集非专业读者的见解来确定文档的有用内容。本研究以200个在线食谱为研究对象，招募了1,340名业余厨师作为非专业读者。提出的框架确定了六个食谱的有用内容。多层次建模结果显示，在确认的六个内容中，每个烹饪步骤的末尾安排副标题的适当成分或注释可以显著增加食谱的可读性。

    Textual documents need to be of good quality to ensure effective asynchronous communication in remote areas, especially during the COVID-19 pandemic. However, defining a preferred document structure (content and arrangement) for improving lay readers' decision-making is challenging. First, the types of useful content for various readers cannot be determined simply by gathering expert knowledge. Second, methodologies to evaluate the document's usefulness from the user's perspective have not been established. This study proposed the experimental framework to identify useful contents of documents by aggregating lay readers' insights. This study used 200 online recipes as research subjects and recruited 1,340 amateur cooks as lay readers. The proposed framework identified six useful contents of recipes. Multi-level modeling then showed that among the six identified contents, suitable ingredients or notes arranged with a subheading at the end of each cooking step significantly increased rec
    
[^11]: 优化引导遍历以实现快速学习稀疏检索

    Optimizing Guided Traversal for Fast Learned Sparse Retrieval. (arXiv:2305.01203v1 [cs.IR])

    [http://arxiv.org/abs/2305.01203](http://arxiv.org/abs/2305.01203)

    本文通过优化BM25引导的索引遍历，提出了一个使用稀疏表示进行快速学习稀疏检索的解决方案。这种方案比原始MaxScore方法快得多，同时保留相关性的有效性。

    

    最近的研究表明，基于由DeepImpact生成的学习稀疏表示的MaxScore文档检索可以通过BM25驱动的动态索引跳过大大加快。本文研究了在使用其他模型（如SPLADE和uniCOIL）进行top k检索时使用这种遍历引导策略的有效性，并发现当BM25模型与学习权重模型不完全对齐或检索深度k很小时，无约束的BM25 driven跳过可能会导致显著的相关性降低。本文通过二级剪枝控制方案和模型对齐优化了BM25引导的索引遍历，以使用稀疏表示快速检索。虽然可能会增加延迟成本，但拟议的方案比没有BM25引导的原始MaxScore方法快得多，同时保留相关性的有效性。本文分析了这个两级剪枝方案的竞争力，并评估了其在几个现实数据集上的有效性。

    Recent studies show that BM25-driven dynamic index skipping can greatly accelerate MaxScore-based document retrieval based on the learned sparse representation derived by DeepImpact. This paper investigates the effectiveness of such a traversal guidance strategy during top k retrieval when using other models such as SPLADE and uniCOIL, and finds that unconstrained BM25-driven skipping could have a visible relevance degradation when the BM25 model is not well aligned with a learned weight model or when retrieval depth k is small. This paper generalizes the previous work and optimizes the BM25 guided index traversal with a two-level pruning control scheme and model alignment for fast retrieval using a sparse representation. Although there can be a cost of increased latency, the proposed scheme is much faster than the original MaxScore method without BM25 guidance while retaining the relevance effectiveness. This paper analyzes the competitiveness of this two-level pruning scheme, and eva
    
[^12]: 安全在线学习中未排序项目的探索与重新排序

    Exploration of Unranked Items in Safe Online Learning to Re-Rank. (arXiv:2305.01202v1 [cs.IR])

    [http://arxiv.org/abs/2305.01202](http://arxiv.org/abs/2305.01202)

    本文提出了一种安全的在线学习排序算法，通过将当前排名中的一个项目与排名外的项目高效地交换来执行探索，并基于Kullback-Leibler上置信度界限（KL-UCB）对未排序项目进行乐观选择和安全的排序，以提高长期收益。

    

    在线学习排序问题的贝叶斯算法经常试图利用用户反馈最大化长期收益。然而，从实际角度考虑，这种算法由于过于激进的探索而具有损害用户体验的高风险。因此，近年来，对安全探索的需求不断增加。本文提出了一种安全的在线学习排序算法，它通过将当前排名中的一个项目与排名外的项目（即未排序项目）高效地交换来执行探索并逐步提高原始排名的质量。我们基于Kullback-Leibler上置信度界限（KL-UCB）乐观地选择一个未排名项目进行探索，并安全地对包括所选项目在内的项目进行重新排序。通过实验，我们证明了所提出的算法可以在没有任何安全违规的情况下提高长期悔恨。

    Bandit algorithms for online learning to rank (OLTR) problems often aim to maximize long-term revenue by utilizing user feedback. From a practical point of view, however, such algorithms have a high risk of hurting user experience due to their aggressive exploration. Thus, there has been a rising demand for safe exploration in recent years. One approach to safe exploration is to gradually enhance the quality of an original ranking that is already guaranteed acceptable quality. In this paper, we propose a safe OLTR algorithm that efficiently exchanges one of the items in the current ranking with an item outside the ranking (i.e., an unranked item) to perform exploration. We select an unranked item optimistically to explore based on Kullback-Leibler upper confidence bounds (KL-UCB) and safely re-rank the items including the selected one. Through experiments, we demonstrate that the proposed algorithm improves long-term regret from baselines without any safety violation.
    
[^13]: 使用大型语言模型在知识图谱上进行复杂逻辑推理

    Complex Logical Reasoning over Knowledge Graphs using Large Language Models. (arXiv:2305.01157v1 [cs.LO])

    [http://arxiv.org/abs/2305.01157](http://arxiv.org/abs/2305.01157)

    本文提出了一种使用大型语言模型的解耦方法，将复杂的知识图谱推理形式化为上下文知识图搜索和抽象逻辑查询推理的组合，与现有方法相比，它在多个逻辑查询结构的标准基准数据集上都表现出更好的性能，并且在更高复杂性的查询中获得了显着的性能提升。

    

    在知识图谱上进行推理是一项具有挑战性的任务，它需要对实体之间的复杂关系以及它们之间的基础逻辑进行深入理解。当前的方法依赖于学习几何来嵌入实体的向量空间进行逻辑查询操作，但是它们在复杂查询和特定数据集表示方面表现不佳。本文提出了一种新颖的解耦方法，称为基于语言引导的知识图谱抽象推理（LARK），将复杂的知识图谱推理形式化为上下文知识图搜索和抽象逻辑查询推理的组合，以分别利用图形提取算法和大型语言模型的优势。我们的实验表明，所提出的方法在多个逻辑查询结构的标准基准数据集上优于现有的知识图谱推理方法，在更高复杂性的查询中获得了显着的性能提升。

    Reasoning over knowledge graphs (KGs) is a challenging task that requires a deep understanding of the complex relationships between entities and the underlying logic of their relations. Current approaches rely on learning geometries to embed entities in vector space for logical query operations, but they suffer from subpar performance on complex queries and dataset-specific representations. In this paper, we propose a novel decoupled approach, Language-guided Abstract Reasoning over Knowledge graphs (LARK), that formulates complex KG reasoning as a combination of contextual KG search and abstract logical query reasoning, to leverage the strengths of graph extraction algorithms and large language models (LLM), respectively. Our experiments demonstrate that the proposed approach outperforms state-of-the-art KG reasoning methods on standard benchmark datasets across several logical query constructs, with significant performance gain for queries of higher complexity. Furthermore, we show t
    
[^14]: 基于知识图谱的卷积神经网络在推荐系统中的应用

    Ripple Knowledge Graph Convolutional Networks For Recommendation Systems. (arXiv:2305.01147v1 [cs.IR])

    [http://arxiv.org/abs/2305.01147](http://arxiv.org/abs/2305.01147)

    本文介绍了一种基于知识图谱的深度学习模型RKGCN，它能够动态分析用户的偏好并推荐出合适的物品。该模型在包括电影、书籍和音乐在内的三个真实世界的数据集上比5个基准模型表现更好。

    

    最近已经证明，使用知识图谱来辅助深度学习模型进行推荐决策能有效提高模型的可解释性和准确性。本文介绍了一种端到端的深度学习模型，命名为RKGCN，它动态分析每个用户的偏好，并推荐出合适的物品。它在物品和用户双方面利用知识图谱来丰富它们的表示，最大化知识图谱中丰富的信息的利用。 RKGCN能够在三种不同的场景下提供更个性化和相关的推荐。实验结果表明，在包括电影、书籍和音乐在内的三个真实世界的数据集上，我们的模型比5个基准模型更有效。

    Using knowledge graphs to assist deep learning models in making recommendation decisions has recently been proven to effectively improve the model's interpretability and accuracy. This paper introduces an end-to-end deep learning model, named RKGCN, which dynamically analyses each user's preferences and makes a recommendation of suitable items. It combines knowledge graphs on both the item side and user side to enrich their representations to maximize the utilization of the abundant information in knowledge graphs. RKGCN is able to offer more personalized and relevant recommendations in three different scenarios. The experimental results show the superior effectiveness of our model over 5 baseline models on three real-world datasets including movies, books, and music.
    
[^15]: 论文推荐中的多维公正性

    Multidimensional Fairness in Paper Recommendation. (arXiv:2305.01141v1 [cs.IR])

    [http://arxiv.org/abs/2305.01141](http://arxiv.org/abs/2305.01141)

    本文提出了三种公平方法，考虑到作者多样性，以解决论文推荐中的潜在偏见，这些方法可以同时提供跨多个受保护变量的公正结果。

    

    为了防止会议和期刊的论文审核和选择过程中出现偏见，大多数会采用双盲审查。尽管如此，研究表明偏见仍然存在。论文审核的推荐算法也可能存在内在的偏差。我们提出了三种公平方法，特别考虑到作者多样性在论文推荐中的作用。与典型的公平算法只使用一个保护变量不同，我们的方法同时提供跨多个受保护变量的公正结果。五个人口统计特征-性别、种族、职业阶段、大学排名和地理位置-被包括在我们的多维作者资料中。总体多样性方法使用整体多样性得分来排名出版物，轮流多样性技术选择依次属于每个受保护团体的作者的论文，而多方面多样性方法选择最初填写族裔特征的论文。

    To prevent potential bias in the paper review and selection process for conferences and journals, most include double blind review. Despite this, studies show that bias still exists. Recommendation algorithms for paper review also may have implicit bias. We offer three fair methods that specifically take into account author diversity in paper recommendation to address this. Our methods provide fair outcomes across many protected variables concurrently, in contrast to typical fair algorithms that only use one protected variable. Five demographic characteristics-gender, ethnicity, career stage, university rank, and geolocation-are included in our multidimensional author profiles. The Overall Diversity approach uses a score for overall diversity to rank publications. The Round Robin Diversity technique chooses papers from authors who are members of each protected group in turn, whereas the Multifaceted Diversity method chooses papers that initially fill the demographic feature with the hi
    
[^16]: CHIC: 企业文档可视化问答

    CHIC: Corporate Document for Visual question Answering. (arXiv:2305.01054v1 [cs.DB])

    [http://arxiv.org/abs/2305.01054](http://arxiv.org/abs/2305.01054)

    CHIC提供了一个公共企业文档问答数据库，以满足不同类型企业文件的需求。

    

    数字化文件的广泛使用，由于无纸化倡议的显著趋势，迫使一些公司寻找自动处理每天数以千计文档的方法。为了实现这一点，它们使用自动信息检索（IR），使它们能够快速从庞大的数据集中提取有用信息。然而，在实现有效的IR方法之前，首先需要有一个足够的数据集。尽管公司有足够的数据以满足其需求，但还需要一个公共数据库来比较最先进的方法。文档的公共数据存在于DocVQA[2]和XFUND [10]中，但这些都不能完全满足公司的需求。与XFUND相比，DocVQA有几种类型的文件，但只有4.5％的文件是企业文件（即结构化文件，如表格、半结构化文件，如发票，以及非结构化文件，如电子邮件）。

    The massive use of digital documents due to the substantial trend of paperless initiatives confronted some companies to find ways to process thousands of documents per day automatically. To achieve this, they use automatic information retrieval (IR) allowing them to extract useful information from large datasets quickly. In order to have effective IR methods, it is first necessary to have an adequate dataset. Although companies have enough data to take into account their needs, there is also a need for a public database to compare contributions between state-of-the-art methods. Public data on the document exists as DocVQA[2] and XFUND [10], but these do not fully satisfy the needs of companies. XFUND contains only form documents while the company uses several types of documents (i.e. structured documents like forms but also semi-structured as invoices, and unstructured as emails). Compared to XFUND, DocVQA has several types of documents but only 4.5% of them are corporate documents (i.
    
[^17]: LooPy: 一种针对电子舞曲的研究友好型混合框架的音乐信息检索

    LooPy: A Research-Friendly Mix Framework for Music Information Retrieval on Electronic Dance Music. (arXiv:2305.01051v1 [cs.SD])

    [http://arxiv.org/abs/2305.01051](http://arxiv.org/abs/2305.01051)

    LooPy是一种Python软件包，为MIR提供了一种面向电子舞曲的基础设施，可用于自动生成EDM音频，并提供了框架来构建专业级的模板，使用户可以从指定的旋律和和弦中呈现出制作精良的歌曲轨道或仅通过使用符号性的旋律生成器，提供具有多种风格的音轨。

    

    近年来，随着深度学习技术的发展，音乐信息检索(MIR)得到了爆炸性的发展。然而，诸如电子舞曲等音乐类型相对于其他类型一直较少研究。考虑到其广泛的应用，我们提出了一种Python软件包，用于自动化EDM音频生成，并作为EDM歌曲MIR的基础设施，以缓解获取标注数据的难度。它是一个方便的工具，可以轻松连接到许多符号音乐生成管道的末端。在这个软件包中，我们提供了一个框架来构建专业水平的模板，可以从指定的旋律和和弦中呈现出一个制作精良的轨道，或者仅通过我们的概率符号旋律生成器，提供具有各种风格的音轨。实验证明，我们的混音在主观和客观评估方面与由世界著名艺术家制作的原始参考歌曲具有相同的质量。

    Music information retrieval (MIR) has gone through an explosive development with the advancement of deep learning in recent years. However, music genres like electronic dance music (EDM) has always been relatively less investigated compared to others. Considering its wide range of applications, we present a Python package for automated EDM audio generation as an infrastructure for MIR for EDM songs, to mitigate the difficulty of acquiring labelled data. It is a convenient tool that could be easily concatenated to the end of many symbolic music generation pipelines. Inside this package, we provide a framework to build professional-level templates that could render a well-produced track from specified melody and chords, or produce massive tracks given only a specific key by our probabilistic symbolic melody generator. Experiments show that our mixes could achieve the same quality of the original reference songs produced by world-famous artists, with respect to both subjective and objecti
    
[^18]: RecD：为端到端深度学习推荐模型训练基础设施提供去重功能

    RecD: Deduplication for End-to-End Deep Learning Recommendation Model Training Infrastructure. (arXiv:2211.05239v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.05239](http://arxiv.org/abs/2211.05239)

    RecD 是一种为 DLRM 训练提供去重功能的端到端基础设施优化，解决了由于特征重复造成的海量存储、预处理和训练开销，引入了新的张量格式 InverseKeyedJaggedTensors (IKJTs) 来去除特征值的重复，使 DLRM 模型架构能够更好地利用数据的重复性提高训练吞吐量。

    

    我们提出了 RecD（推荐去重），它是一组针对深度学习推荐模型 (DLRM) 训练流程的端到端基础设施优化。RecD解决了由于特征重复造成的海量存储、预处理和训练开销，这是大规模 DLRM 训练数据集内在的问题，因为 DLRM 数据集是从交互中生成的。我们展示了 RecD 如何利用此属性来优化生产数据的流程，减少数据集存储和预处理需求，并最大限度地在训练批次中重复。RecD 引入了一种新的张量格式 InverseKeyedJaggedTensors (IKJTs)，以在每个批次中去除特征值的重复。我们展示了 DLRM 模型架构如何利用 IKJTs 来显著提高训练吞吐量。

    We present RecD (Recommendation Deduplication), a suite of end-to-end infrastructure optimizations across the Deep Learning Recommendation Model (DLRM) training pipeline. RecD addresses immense storage, preprocessing, and training overheads caused by feature duplication inherent in industry-scale DLRM training datasets. Feature duplication arises because DLRM datasets are generated from interactions. While each user session can generate multiple training samples, many features' values do not change across these samples. We demonstrate how RecD exploits this property, end-to-end, across a deployed training pipeline. RecD optimizes data generation pipelines to decrease dataset storage and preprocessing resource demands and to maximize duplication within a training batch. RecD introduces a new tensor format, InverseKeyedJaggedTensors (IKJTs), to deduplicate feature values in each batch. We show how DLRM model architectures can leverage IKJTs to drastically increase training throughput. Re
    
[^19]: 基于子图草图的图神经网络用于链路预测

    Graph Neural Networks for Link Prediction with Subgraph Sketching. (arXiv:2209.15486v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.15486](http://arxiv.org/abs/2209.15486)

    本研究提出了一种名为ELPH的全图GNN模型，它使用子图草图作为消息传递，以缓解LP任务中子图之间的冗余问题，并在多个基准数据集上取得了最先进的结果。

    

    许多图神经网络在链路预测任务中表现不佳，这是由于表达能力的限制，例如无法计算三角形（大多数LP启发式算法的骨干），以及不能区分同构节点（具有相同结构角色的节点）。这两种表达问题可以通过学习链路（而不是节点）表示，并结合三角形计数等结构特征来缓解。由于显式链路表示通常代价高昂，因此最近的研究采用了基于子图的方法，这些方法在LP方面取得了最先进的性能，但由于子图之间存在高度冗余，效率较低。我们分析了子图GNN（SGNN）方法的组件，基于我们的分析，提出了一种名为ELPH（高效哈希链路预测）的新型全图GNN，将子图草图作为消息传递以近似全图上的转换。ELPH在多个基准数据集上实现了最先进的结果，同时需要比现有基于子图的方法更少的计算资源。

    Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate t
    
[^20]: 基于Boosting的离线策略学习算法

    Boosted Off-Policy Learning. (arXiv:2208.01148v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.01148](http://arxiv.org/abs/2208.01148)

    我们提出了一种基于Boosting的离线策略学习算法，将基础学习器简化为监督学习，获得了广泛的实际效益；实验结果表明其应用能力优于深度神经网络的离线策略学习和简单回归方法。

    

    我们提出了一种针对来自记录式赌博反馈的离线策略学习的Boosting算法。与现有的监督学习的Boosting方法不同，我们的算法直接优化了策略预期收益的估计。我们对该算法进行了分析，并证明如果基础学习器满足“弱”学习条件，那么每一轮Boosting都会减小过量经验风险（可能是指数级）。我们进一步展示了如何将基础学习器简化为监督学习，从而打开了广泛的基础学习器源，如决策树等，具有实际益处。实验结果表明，我们的算法继承了许多基于决策树的Boosting算法的优良性质（例如对特征缩放和超参数调整的鲁棒性），并且可以胜过基于深度神经网络的离线策略学习和只是回归观察到的奖励的方法。

    We propose the first boosting algorithm for off-policy learning from logged bandit feedback. Unlike existing boosting methods for supervised learning, our algorithm directly optimizes an estimate of the policy's expected reward. We analyze this algorithm and prove that the excess empirical risk decreases (possibly exponentially fast) with each round of boosting, provided a ''weak'' learning condition is satisfied by the base learner. We further show how to reduce the base learner to supervised learning, which opens up a broad range of readily available base learners with practical benefits, such as decision trees. Experiments indicate that our algorithm inherits many desirable properties of tree-based boosting algorithms (e.g., robustness to feature scaling and hyperparameter tuning), and that it can outperform off-policy learning with deep neural networks as well as methods that simply regress on the observed rewards.
    

