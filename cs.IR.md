# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Ducho: A Unified Framework for the Extraction of Multimodal Features in Recommendation.](http://arxiv.org/abs/2306.17125) | Ducho是一个用于推荐系统中多模态特征提取的统一框架，通过集成三个广泛采用的深度学习库作为后端，提供了一个共享界面来提取和处理特征。 |
| [^2] | [Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities.](http://arxiv.org/abs/2306.17082) | 本文提出了一种自适应查询扩展的文档检索方法，通过先重新排序再进行查询扩展，以及引入新的扩展模型和自适应组件来提高检索效果。使用该方法，我们在NDCG、MAP和R@1000等指标上取得了最好的结果。 |
| [^3] | [Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks.](http://arxiv.org/abs/2306.16891) | 该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。 |
| [^4] | [Computing all-vs-all MEMs in grammar-compressed text.](http://arxiv.org/abs/2306.16815) | 本论文提出了一种压缩感知方法，在语法压缩文本中计算全对全最大精确匹配（MEM）。通过构建一个完全平衡的语法，满足特定属性，并修改语法规则，我们能够以更高效的方式计算MEMs。我们的方法在时间和空间复杂度上都具有优势。 |
| [^5] | [Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall Classification.](http://arxiv.org/abs/2306.16760) | 该论文讨论了使用半监督数据集注释进行迁移学习的方法，通过利用现有的模型解决鸟鸣分类比赛中的挑战，并提出了一种获取带标注数据集的方法。实验证明这种方法在鸟类物种分类方面有效，并展示了迁移学习和半监督数据集注释在类似任务中的潜力。 |
| [^6] | [Multi-Scenario Ranking with Adaptive Feature Learning.](http://arxiv.org/abs/2306.16732) | 多情景学习在推荐和检索系统中被广泛应用于行业中。本文提出了一种自适应特征学习方法，通过优化特征表示来提高排序性能，减少了对网络结构的搜索和维护成本。 |
| [^7] | [Exploring the Representation Power of SPLADE Models.](http://arxiv.org/abs/2306.16680) | SPLADE模型是一种学习稀疏检索的方法，通过正则化保持倒排列表的稀疏性来提高词汇匹配和排名效果。研究发现，即使使用不常见的词汇，如停用词或随机词，SPLADE模型仍然可以有效地编码排名信号。 |
| [^8] | [Beyond CO2 Emissions: The Overlooked Impact of Water Consumption of Information Retrieval Models.](http://arxiv.org/abs/2306.16668) | 信息检索社区对于搜索模型的能量消耗产生了兴趣，并发现基于大型语言模型的新神经模型导致了信息检索模型的能源消耗增加，但与自然语言处理等领域相比较低。 |
| [^9] | [Multimodal Search on Iconclass using Vision-Language Pre-Trained Models.](http://arxiv.org/abs/2306.16529) | 本文介绍了一种使用预训练的视觉-语言模型CLIP的搜索引擎实现方案，用于Iconclass图像分类系统，可以通过图像或文本查询来检索和探索Iconclass概念。 |
| [^10] | [A Food Recommender System in Academic Environments Based on Machine Learning Models.](http://arxiv.org/abs/2306.16528) | 这个论文介绍了一个基于机器学习模型的食物推荐系统，通过使用协同过滤、基于内容和基于知识的模型，以提高人们的健康。研究探讨了决策树、k最近邻居(kNN)、AdaBoost和Bagging等机器学习模型在食物推荐系统上的应用。 |
| [^11] | [OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents.](http://arxiv.org/abs/2306.16527) | OBELISC是一个开放的网页规模筛选图像文本数据集，包含141亿个网页，3.53亿个图像和1150亿个文本标记。通过在此数据集上训练一个80亿参数的模型，取得了在多模态基准测试中有竞争力的性能。 |
| [^12] | [Shilling Black-box Review-based Recommender Systems through Fake Review Generation.](http://arxiv.org/abs/2306.16526) | 本文提出了一种基于生成的模型，通过虚假评论生成器对基于评论的推荐系统进行操纵攻击。实验证明该框架可以成功地攻击亚马逊上的三种不同类型的RBRS。 |
| [^13] | [Event Detection from Social Media Stream: Methods, Datasets and Opportunities.](http://arxiv.org/abs/2306.16495) | 本论文调查了Twitter数据流的事件检测方法，提供了公开可用的数据集，并探讨了未来的研究机会。 |
| [^14] | [Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering.](http://arxiv.org/abs/2306.16478) | 本文提出了一个为外部知识视觉问答任务预训练的段落检索模型的自动数据生成管道，相较于最先进的架构实现了更好的Precision@5。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。 |
| [^15] | [A Collaborative Transfer Learning Framework for Cross-domain Recommendation.](http://arxiv.org/abs/2306.16425) | 这篇论文提出了一种协作跨领域迁移学习框架（CCTL），用于解决推荐系统中不同领域CTR预测建模的挑战。 |
| [^16] | [Improving Identity-Robustness for Face Models.](http://arxiv.org/abs/2304.03838) | 该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。 |

# 详细

[^1]: Ducho: 一种用于推荐系统中多模态特征提取的统一框架

    Ducho: A Unified Framework for the Extraction of Multimodal Features in Recommendation. (arXiv:2306.17125v1 [cs.IR])

    [http://arxiv.org/abs/2306.17125](http://arxiv.org/abs/2306.17125)

    Ducho是一个用于推荐系统中多模态特征提取的统一框架，通过集成三个广泛采用的深度学习库作为后端，提供了一个共享界面来提取和处理特征。

    

    在多模态感知的推荐系统中，有意义的多模态特征的提取是实现高质量推荐的基础。通常，每个推荐框架都会使用特定的策略和工具来实现其多模态特征的提取过程。这种限制有两个原因：（一）不同的特征提取策略不利于多模态推荐框架之间的相互关联，因此无法进行有效和公平的比较；（二）由于不同的开源工具提供了大量经过预训练的深度学习模型，模型设计者无法访问共享界面来提取特征。在上述问题的基础上，我们提出了Ducho，一种用于推荐系统中多模态特征提取的统一框架。通过集成三个广泛采用的深度学习库作为后端，即TensorFlow、PyTorch和Transformers，我们提供了一个共享界面，用于提取和处理特征，每个后端都有自己的特定方法。

    In multimodal-aware recommendation, the extraction of meaningful multimodal features is at the basis of high-quality recommendations. Generally, each recommendation framework implements its multimodal extraction procedures with specific strategies and tools. This is limiting for two reasons: (i) different extraction strategies do not ease the interdependence among multimodal recommendation frameworks; thus, they cannot be efficiently and fairly compared; (ii) given the large plethora of pre-trained deep learning models made available by different open source tools, model designers do not have access to shared interfaces to extract features. Motivated by the outlined aspects, we propose Ducho, a unified framework for the extraction of multimodal features in recommendation. By integrating three widely-adopted deep learning libraries as backends, namely, TensorFlow, PyTorch, and Transformers, we provide a shared interface to extract and process features where each backend's specific metho
    
[^2]: 重新排序-扩展-重复：使用单词和实体的自适应查询扩展的文档检索

    Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document Retrieval Using Words and Entities. (arXiv:2306.17082v1 [cs.IR])

    [http://arxiv.org/abs/2306.17082](http://arxiv.org/abs/2306.17082)

    本文提出了一种自适应查询扩展的文档检索方法，通过先重新排序再进行查询扩展，以及引入新的扩展模型和自适应组件来提高检索效果。使用该方法，我们在NDCG、MAP和R@1000等指标上取得了最好的结果。

    

    稀疏和密集的伪相关反馈(PRf)方法在挑战性查询中表现不佳，原因是在第一次检索中的低准确率。然而，最近的神经语言模型(NLMs)的进展可以将相关文档重新排名到前几名，即使重新排名池中只有很少的文档。本文首先通过简单地在查询扩展之前应用重新排序并重新执行查询来解决伪相关反馈的问题。我们发现仅凭这个改变就可以将稀疏和密集PRF方法的检索效果提升5-8%。进一步地，我们提出了一种新的扩展模型，潜在实体扩展(LEE)，它是一种细粒度的基于词和实体的相关性建模，包括局部特征。最后，我们在检索过程中引入了一个“自适应”组件，它在评分过程中使用扩展模型迭代地调整重新排名池，即“重新排序-扩展-重复”。使用LEE，我们实现了(据我们所知)最好的NDCG、MAP和R@1000。

    Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on challenging queries due to low precision in first-pass retrieval. However, recent advances in neural language models (NLMs) can re-rank relevant documents to top ranks, even when few are in the re-ranking pool. This paper first addresses the problem of poor pseudo-relevance feedback by simply applying re-ranking prior to query expansion and re-executing this query. We find that this change alone can improve the retrieval effectiveness of sparse and dense PRF approaches by 5-8%. Going further, we propose a new expansion model, Latent Entity Expansion (LEE), a fine-grained word and entity-based relevance modelling incorporating localized features. Finally, we include an "adaptive" component to the retrieval process, which iteratively refines the re-ranking pool during scoring using the expansion model, i.e. we "re-rank - expand repeat". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000 re
    
[^3]: 利用Hugging Face Transformers预测社交网络中的精神健康障碍的力量

    Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks. (arXiv:2306.16891v1 [cs.IR])

    [http://arxiv.org/abs/2306.16891](http://arxiv.org/abs/2306.16891)

    该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。

    

    早期诊断精神障碍并进行干预可以促进预防严重伤害和改善治疗效果。本研究利用社交媒体和预训练的语言模型，探讨用户生成的数据如何用于预测精神障碍症状。我们的研究比较了Hugging Face的四种不同BERT模型和近期文献中用于自动抑郁症诊断的标准机器学习技术。结果显示，新模型的准确率高达97%，超过了以前的方法。通过补充先前的发现，对结果进行分析，我们发现即使是微小的数据量（如用户的个人简介描述）也有预测精神障碍的潜力。我们得出结论，社交媒体数据是进行精神健康筛查的一个极好的来源，并且预训练模型可以有效自动化这一关键任务。

    Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.
    
[^4]: 在语法压缩文本中计算全对全最大精确匹配（MEM）

    Computing all-vs-all MEMs in grammar-compressed text. (arXiv:2306.16815v1 [cs.IR])

    [http://arxiv.org/abs/2306.16815](http://arxiv.org/abs/2306.16815)

    本论文提出了一种压缩感知方法，在语法压缩文本中计算全对全最大精确匹配（MEM）。通过构建一个完全平衡的语法，满足特定属性，并修改语法规则，我们能够以更高效的方式计算MEMs。我们的方法在时间和空间复杂度上都具有优势。

    

    我们描述了一种压缩感知方法，用于计算重复集合$\mathcal{T}$中字符串之间的全对全最大精确匹配（MEM）。我们工作的关键概念是从$\mathcal{T}$构建一个完全平衡的语法$\mathcal{G}$，满足我们称之为“fix-free”的属性：解析树中具有相同高度的非终结符的扩展形成了一个fix-free集合（即前缀自由和后缀自由）。fix-free属性使我们能够使用标准的基于后缀树的MEM算法在$\mathcal{G}$上递增地计算$\mathcal{T}$的MEM，该算法一次在一组语法规则上运行，并且不解压缩非终结符。通过修改Christiansen等人2020年的局部一致性语法，我们展示了如何以线性时间和空间构建$\mathcal{G}$从$\mathcal{T}$。我们还证明了我们的MEM算法在$\mathcal{G}$上以$O(G+occ)$时间运行，并且使用$O(\log G(G+occ))$位，其中$G$是语法大小，而$occ$是MEM的数量。

    We describe a compression-aware method to compute all-vs-all maximal exact matches (MEM) among strings of a repetitive collection $\mathcal{T}$. The key concept in our work is the construction of a fully-balanced grammar $\mathcal{G}$ from $\mathcal{T}$ that meets a property that we call \emph{fix-free}: the expansions of the nonterminals that have the same height in the parse tree form a fix-free set (i.e., prefix-free and suffix-free). The fix-free property allows us to compute the MEMs of $\mathcal{T}$ incrementally over $\mathcal{G}$ using a standard suffix-tree-based MEM algorithm, which runs on a subset of grammar rules at a time and does not decompress nonterminals. By modifying the locally-consistent grammar of Christiansen et al 2020., we show how we can build $\mathcal{G}$ from $\mathcal{T}$ in linear time and space. We also demonstrate that our MEM algorithm runs on top of $\mathcal{G}$ in $O(G +occ)$ time and uses $O(\log G(G+occ))$ bits, where $G$ is the grammar size, and 
    
[^5]: 使用半监督数据集注释进行迁移学习的鸟鸣分类

    Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall Classification. (arXiv:2306.16760v1 [cs.SD])

    [http://arxiv.org/abs/2306.16760](http://arxiv.org/abs/2306.16760)

    该论文讨论了使用半监督数据集注释进行迁移学习的方法，通过利用现有的模型解决鸟鸣分类比赛中的挑战，并提出了一种获取带标注数据集的方法。实验证明这种方法在鸟类物种分类方面有效，并展示了迁移学习和半监督数据集注释在类似任务中的潜力。

    

    我们提出了关于使用半监督数据集注释进行鸟鸣分类的迁移学习的工作笔记，重点是在记录的声景中识别非洲鸟类物种。我们的方法利用现有的现成模型BirdNET和MixIT来解决比赛中的表示和标注挑战。我们探索了BirdNET学习到的嵌入空间，并提出了一种获取用于监督学习的带标注数据集的方法。我们的实验涉及各种模型和特征工程方法，以在比赛排行榜上达到最佳表现。结果表明我们的方法在鸟类物种分类方面的有效性，并突出了迁移学习和半监督数据集注释在类似任务中的潜力。

    We present working notes on transfer learning with semi-supervised dataset annotation for the BirdCLEF 2023 competition, focused on identifying African bird species in recorded soundscapes. Our approach utilizes existing off-the-shelf models, BirdNET and MixIT, to address representation and labeling challenges in the competition. We explore the embedding space learned by BirdNET and propose a process to derive an annotated dataset for supervised learning. Our experiments involve various models and feature engineering approaches to maximize performance on the competition leaderboard. The results demonstrate the effectiveness of our approach in classifying bird species and highlight the potential of transfer learning and semi-supervised dataset annotation in similar tasks.
    
[^6]: 多情景排序与自适应特征学习

    Multi-Scenario Ranking with Adaptive Feature Learning. (arXiv:2306.16732v1 [cs.IR])

    [http://arxiv.org/abs/2306.16732](http://arxiv.org/abs/2306.16732)

    多情景学习在推荐和检索系统中被广泛应用于行业中。本文提出了一种自适应特征学习方法，通过优化特征表示来提高排序性能，减少了对网络结构的搜索和维护成本。

    

    最近，多情景学习（MSL）在推荐和检索系统中被广泛应用于行业中，因为它有助于从不同情景中进行迁移学习，减轻了数据稀疏性并降低了维护成本。这些努力通过搜索更优网络结构（如辅助网络、专家网络和多塔网络）产生不同的MSL范式。不同的情景可以持有特定的特征，因此激活用户的意图会有所不同。换句话说，在不同的情景下，不同类型的辅助特征的重要性也会有所不同。通过以情景感知的方式优化更具有区分性的特征表示，可以轻松地获得更好的排序性能，而无需昂贵地搜索最优网络结构。不幸的是，这个简单的想法在实际系统中主要被忽视，但却是非常需要的。进一步的分析也验证了自适应特征学习的合理性。

    Recently, Multi-Scenario Learning (MSL) is widely used in recommendation and retrieval systems in the industry because it facilitates transfer learning from different scenarios, mitigating data sparsity and reducing maintenance cost. These efforts produce different MSL paradigms by searching more optimal network structure, such as Auxiliary Network, Expert Network, and Multi-Tower Network. It is intuitive that different scenarios could hold their specific characteristics, activating the user's intents quite differently. In other words, different kinds of auxiliary features would bear varying importance under different scenarios. With more discriminative feature representations refined in a scenario-aware manner, better ranking performance could be easily obtained without expensive search for the optimal network structure. Unfortunately, this simple idea is mainly overlooked but much desired in real-world systems.Further analysis also validates the rationality of adaptive feature learni
    
[^7]: 探索 SPLADE 模型的表示能力

    Exploring the Representation Power of SPLADE Models. (arXiv:2306.16680v1 [cs.IR])

    [http://arxiv.org/abs/2306.16680](http://arxiv.org/abs/2306.16680)

    SPLADE模型是一种学习稀疏检索的方法，通过正则化保持倒排列表的稀疏性来提高词汇匹配和排名效果。研究发现，即使使用不常见的词汇，如停用词或随机词，SPLADE模型仍然可以有效地编码排名信号。

    

    SPLADE (SParse Lexical AnD Expansion) 模型是一种高效的学习稀疏检索方法，其中文档由从大型语言模型中获取的词项影响分数表示。在训练过程中，SPLADE 应用正则化来确保倒排列表保持稀疏 -- 目的是模拟自然词项分布的特性 -- 从而实现高效和有效的词汇匹配和排名。然而，我们假设 SPLADE 可以通过常见的倒排列表进一步编码附加的信号以提高效果。为了探索这个想法，我们进行了一系列的实证分析，通过使用不同的控制词汇重新训练 SPLADE 并衡量其在排名段落方面的效果。我们的研究结果表明，即使词汇被限制在传统上用于排名的无用词项（如停用词或随机词），SPLADE 仍然可以有效地在文档中编码有效的排名信号。

    The SPLADE (SParse Lexical AnD Expansion) model is a highly effective approach to learned sparse retrieval, where documents are represented by term impact scores derived from large language models. During training, SPLADE applies regularization to ensure postings lists are kept sparse -- with the aim of mimicking the properties of natural term distributions -- allowing efficient and effective lexical matching and ranking. However, we hypothesize that SPLADE may encode additional signals into common postings lists to further improve effectiveness. To explore this idea, we perform a number of empirical analyses where we re-train SPLADE with different, controlled vocabularies and measure how effective it is at ranking passages. Our findings suggest that SPLADE can effectively encode useful ranking signals in documents even when the vocabulary is constrained to terms that are not traditionally useful for ranking, such as stopwords or even random words.
    
[^8]: 超越CO2排放：信息检索模型的水消耗的被忽视的影响

    Beyond CO2 Emissions: The Overlooked Impact of Water Consumption of Information Retrieval Models. (arXiv:2306.16668v1 [cs.IR])

    [http://arxiv.org/abs/2306.16668](http://arxiv.org/abs/2306.16668)

    信息检索社区对于搜索模型的能量消耗产生了兴趣，并发现基于大型语言模型的新神经模型导致了信息检索模型的能源消耗增加，但与自然语言处理等领域相比较低。

    

    与其他人工智能领域一样，信息检索社区对与神经模型相关的能量消耗产生了兴趣，特别是对搜索模型的研究。随着基于大型语言模型的新神经模型的出现，信息检索模型的能源消耗也随之增加，尽管相对于自然语言处理等领域而言仍然较低，但这种兴趣变得尤为重要。

    As in other fields of artificial intelligence, the information retrieval community has grown interested in investigating the power consumption associated with neural models, particularly models of search. This interest has become particularly relevant as the energy consumption of information retrieval models has risen with new neural models based on large language models, leading to an associated increase of CO2 emissions, albeit relatively low compared to fields such as natural language processing.
    
[^9]: 使用视觉-语言预训练模型在Iconclass上进行多模态搜索

    Multimodal Search on Iconclass using Vision-Language Pre-Trained Models. (arXiv:2306.16529v1 [cs.IR])

    [http://arxiv.org/abs/2306.16529](http://arxiv.org/abs/2306.16529)

    本文介绍了一种使用预训练的视觉-语言模型CLIP的搜索引擎实现方案，用于Iconclass图像分类系统，可以通过图像或文本查询来检索和探索Iconclass概念。

    

    术语来源，如受控词汇、词表和分类系统，在数字化文化遗产中起着关键作用。然而，允许查询和探索这些词汇资源的信息检索（IR）系统往往缺乏对用户搜索背后语义的适当表示，这可以通过多种表达方式传达（例如，图像、关键词或文本描述）。本文介绍了一种新的搜索引擎实现方案，用于其中一种最常用的图像分类系统Iconclass。该系统的创新之处在于使用预训练的视觉 - 语言模型CLIP来检索和探索Iconclass概念，无论是通过视觉查询还是文本查询。

    Terminology sources, such as controlled vocabularies, thesauri and classification systems, play a key role in digitizing cultural heritage. However, Information Retrieval (IR) systems that allow to query and explore these lexical resources often lack an adequate representation of the semantics behind the user's search, which can be conveyed through multiple expression modalities (e.g., images, keywords or textual descriptions). This paper presents the implementation of a new search engine for one of the most widely used iconography classification system, Iconclass. The novelty of this system is the use of a pre-trained vision-language model, namely CLIP, to retrieve and explore Iconclass concepts using visual or textual queries.
    
[^10]: 基于机器学习模型的学术环境中的食物推荐系统

    A Food Recommender System in Academic Environments Based on Machine Learning Models. (arXiv:2306.16528v1 [cs.IR])

    [http://arxiv.org/abs/2306.16528](http://arxiv.org/abs/2306.16528)

    这个论文介绍了一个基于机器学习模型的食物推荐系统，通过使用协同过滤、基于内容和基于知识的模型，以提高人们的健康。研究探讨了决策树、k最近邻居(kNN)、AdaBoost和Bagging等机器学习模型在食物推荐系统上的应用。

    

    背景：人们的健康取决于适当的饮食，是一个重要因素。如今，随着人们生活的机械化增加，适当的饮食习惯和行为被忽视了。另一方面，健康领域中的食物推荐也试图解决这个问题。但是随着西方饮食风格的引入和西方化学药物的进步，在疾病治疗和营养方面出现了许多问题。技术的最新进展和人工智能方法在信息系统中的应用，导致了推荐系统的创建，以改善人们的健康。方法：采用混合推荐系统，包括协同过滤、基于内容和基于知识的模型。在2519名学生的营养管理系统中，研究了决策树、k最近邻居(kNN)、AdaBoost和Bagging等机器学习模型在食物推荐系统领域的应用。

    Background: People's health depends on the use of proper diet as an important factor. Today, with the increasing mechanization of people's lives, proper eating habits and behaviors are neglected. On the other hand, food recommendations in the field of health have also tried to deal with this issue. But with the introduction of the Western nutrition style and the advancement of Western chemical medicine, many issues have emerged in the field of disease treatment and nutrition. Recent advances in technology and the use of artificial intelligence methods in information systems have led to the creation of recommender systems in order to improve people's health. Methods: A hybrid recommender system including, collaborative filtering, content-based, and knowledge-based models was used. Machine learning models such as Decision Tree, k-Nearest Neighbors (kNN), AdaBoost, and Bagging were investigated in the field of food recommender systems on 2519 students in the nutrition management system of
    
[^11]: OBELISC：一个开放的网页规模筛选图像文档数据集

    OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents. (arXiv:2306.16527v1 [cs.IR])

    [http://arxiv.org/abs/2306.16527](http://arxiv.org/abs/2306.16527)

    OBELISC是一个开放的网页规模筛选图像文本数据集，包含141亿个网页，3.53亿个图像和1150亿个文本标记。通过在此数据集上训练一个80亿参数的模型，取得了在多模态基准测试中有竞争力的性能。

    

    在要求对一个或多个图片进行推理生成文本的各种多模态基准测试中，基于自然文档的大规模多模态模型（图像与文本交错）的表现优于基于图像-文本对训练的模型。然而，用于训练这些模型的数据集尚未发布，并且收集过程尚未完全明确。我们介绍了OBELISC数据集，一个由141亿个从Common Crawl提取的网页，3.53亿个相关图像和1150亿个文本标记组成的开放式网页规模筛选的图像文本交错的数据集。我们描述了数据集的创建过程，提供了全面的过滤规则，并对数据集的内容进行了分析。为了展示OBELISC的可行性，我们在数据集上训练了一个80亿参数的视觉和语言模型，并在各种多模态基准测试中获得了有竞争力的性能。我们发布了用于重现数据集的代码以及数据集本身。

    Large multimodal models trained on natural documents, which interleave images and text, outperform models trained on image-text pairs on various multimodal benchmarks that require reasoning over one or multiple images to generate a text. However, the datasets used to train these models have not been released, and the collection process has not been fully specified. We introduce the OBELISC dataset, an open web-scale filtered dataset of interleaved image-text documents comprising 141 million web pages extracted from Common Crawl, 353 million associated images, and 115 billion text tokens. We describe the dataset creation process, present comprehensive filtering rules, and provide an analysis of the dataset's content. To show the viability of OBELISC, we train an 80 billion parameters vision and language model on the dataset and obtain competitive performance on various multimodal benchmarks. We release the code to reproduce the dataset along with the dataset itself.
    
[^12]: 通过生成虚假评论对基于评论的推荐系统进行操纵的黑盒检测

    Shilling Black-box Review-based Recommender Systems through Fake Review Generation. (arXiv:2306.16526v1 [cs.IR])

    [http://arxiv.org/abs/2306.16526](http://arxiv.org/abs/2306.16526)

    本文提出了一种基于生成的模型，通过虚假评论生成器对基于评论的推荐系统进行操纵攻击。实验证明该框架可以成功地攻击亚马逊上的三种不同类型的RBRS。

    

    基于评论的推荐系统（RBRS）由于能够缓解众所周知的冷启动问题而受到越来越多的研究关注。RBRS利用评论来构建用户和物品的表示。然而，在本文中，我们认为这种对评论的依赖可能会使系统面临被操纵的风险。为了探索这种可能性，在本文中，我们提出了一种用于对RBRS进行操纵攻击的基于生成的模型。具体而言，我们通过强化学习来学习一个虚假评论生成器，它通过向系统添加生成的评论导致预测偏移从而恶意推广物品。通过引入辅助奖励，借助预训练的语言模型和方面预测器来增加文本的流畅性和多样性，生成的评论可以有效地用于高保真度的操纵。实验结果表明，所提出的框架可以成功地攻击亚马逊上的三种不同类型的RBRS。

    Review-Based Recommender Systems (RBRS) have attracted increasing research interest due to their ability to alleviate well-known cold-start problems. RBRS utilizes reviews to construct the user and items representations. However, in this paper, we argue that such a reliance on reviews may instead expose systems to the risk of being shilled. To explore this possibility, in this paper, we propose the first generation-based model for shilling attacks against RBRSs. Specifically, we learn a fake review generator through reinforcement learning, which maliciously promotes items by forcing prediction shifts after adding generated reviews to the system. By introducing the auxiliary rewards to increase text fluency and diversity with the aid of pre-trained language models and aspect predictors, the generated reviews can be effective for shilling with high fidelity. Experimental results demonstrate that the proposed framework can successfully attack three different kinds of RBRSs on the Amazon c
    
[^13]: 社交媒体流中的事件检测：方法、数据集和机会

    Event Detection from Social Media Stream: Methods, Datasets and Opportunities. (arXiv:2306.16495v1 [cs.SI])

    [http://arxiv.org/abs/2306.16495](http://arxiv.org/abs/2306.16495)

    本论文调查了Twitter数据流的事件检测方法，提供了公开可用的数据集，并探讨了未来的研究机会。

    

    社交媒体流包含大量多样化的信息，从日常生活故事到最新的全球和当地事件和新闻。特别是Twitter，允许快速传播实时发生的事件，并使个人和组织能够及时了解当前事件。从社交媒体数据中检测事件与传统文本面临不同的挑战，是近年来受到关注的研究领域。在本文中，我们调查了Twitter数据流的广泛事件检测方法，帮助读者了解该领域的最新发展。我们还介绍了公开可用的数据集。此外，还有一些研究机会。

    Social media streams contain large and diverse amount of information, ranging from daily-life stories to the latest global and local events and news. Twitter, especially, allows a fast spread of events happening real time, and enables individuals and organizations to stay informed of the events happening now. Event detection from social media data poses different challenges from traditional text and is a research area that has attracted much attention in recent years. In this paper, we survey a wide range of event detection methods for Twitter data stream, helping readers understand the recent development in this area. We present the datasets available to the public. Furthermore, a few research opportunities
    
[^14]: 为外部知识视觉问答预训练多模态稠密检索器

    Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual Question Answering. (arXiv:2306.16478v1 [cs.IR])

    [http://arxiv.org/abs/2306.16478](http://arxiv.org/abs/2306.16478)

    本文提出了一个为外部知识视觉问答任务预训练的段落检索模型的自动数据生成管道，相较于最先进的架构实现了更好的Precision@5。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。

    

    本文研究了一类视觉问答任务，其中访问外部知识对于回答问题是必要的。这个类别被称为外部知识视觉问答（OK-VQA）。开发OK-VQA系统的一个重要步骤是为给定的多模态查询检索相关文档。目前此任务的最先进的非对称稠密检索模型使用了一个多模态查询编码器和一个单模态文档编码器的架构。这样的架构需要大量的训练数据才能实现有效的性能。我们提出了一个用于预训练OK-VQA任务的段落检索模型的自动数据生成管道。与当前最先进的非对称架构相比，所提出的方法使Precision@5提升了26.9%。此外，所提出的预训练方法在零样本检索场景中展示了良好的能力。

    This paper studies a category of visual question answering tasks, in which accessing external knowledge is necessary for answering the questions. This category is called outside-knowledge visual question answering (OK-VQA). A major step in developing OK-VQA systems is to retrieve relevant documents for the given multi-modal query. Current state-of-the-art asymmetric dense retrieval model for this task uses an architecture with a multi-modal query encoder and a uni-modal document encoder. Such an architecture requires a large amount of training data for effective performance. We propose an automatic data generation pipeline for pre-training passage retrieval models for OK-VQA tasks. The proposed approach leads to 26.9% Precision@5 improvements compared to the current state-of-the-art asymmetric architecture. Additionally, the proposed pre-training approach exhibits a good ability in zero-shot retrieval scenarios.
    
[^15]: 跨领域推荐的协作迁移学习框架

    A Collaborative Transfer Learning Framework for Cross-domain Recommendation. (arXiv:2306.16425v1 [cs.IR])

    [http://arxiv.org/abs/2306.16425](http://arxiv.org/abs/2306.16425)

    这篇论文提出了一种协作跨领域迁移学习框架（CCTL），用于解决推荐系统中不同领域CTR预测建模的挑战。

    

    在推荐系统中，有多个不同的业务领域来满足用户的多样化兴趣和需求，不同领域的点击率（CTR）可能会有很大差异，这就需要对不同业务领域进行CTR预测建模。行业解决方案是对每个领域使用特定的模型或迁移学习技术。前者的缺点是单一领域模型没有利用其他领域的数据，而后者则利用不同领域的所有数据，但迁移学习的微调模型可能使模型陷入源领域的局部最优，难以适应目标领域。同时，不同领域之间存在数据数量和特征模式的显著差异，即领域偏移，在迁移过程中可能导致负面迁移。为了克服这些挑战，我们提出了协作跨领域迁移学习框架（CCTL）。

    In the recommendation systems, there are multiple business domains to meet the diverse interests and needs of users, and the click-through rate(CTR) of each domain can be quite different, which leads to the demand for CTR prediction modeling for different business domains. The industry solution is to use domain-specific models or transfer learning techniques for each domain. The disadvantage of the former is that the data from other domains is not utilized by a single domain model, while the latter leverage all the data from different domains, but the fine-tuned model of transfer learning may trap the model in a local optimum of the source domain, making it difficult to fit the target domain. Meanwhile, significant differences in data quantity and feature schemas between different domains, known as domain shift, may lead to negative transfer in the process of transferring. To overcome these challenges, we propose the Collaborative Cross-Domain Transfer Learning Framework (CCTL). CCTL e
    
[^16]: 提高人脸模型的身份鲁棒性

    Improving Identity-Robustness for Face Models. (arXiv:2304.03838v1 [cs.CV])

    [http://arxiv.org/abs/2304.03838](http://arxiv.org/abs/2304.03838)

    该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。

    

    虽然深度学习模型在许多任务中取得了成功，但人们仍然担心这些模型可能学习到快捷方式，并且缺乏对无关混淆因素的鲁棒性。在直接训练于人脸上的模型中，一个敏感的混淆因素是人的身份。许多与人脸相关的任务理想情况下应该是与身份无关的，并在不同个体之间表现一致（即公平）。通过在训练期间强制执行这种鲁棒性和性能均匀性是度量和实施的一种方法，假设可以在规模上获取与身份相关的信息。但是，由于隐私问题以及收集此类信息的成本，这通常不是情况，大多数人脸数据集只包含输入图像及其相应的任务标签。因此，无需此类注释即可提高身份相关鲁棒性非常重要。在这里，我们探讨使用人脸识别嵌入向量作为身份标识的替代方法，以执行这种鲁棒性和公平性。

    Despite the success of deep-learning models in many tasks, there have been concerns about such models learning shortcuts, and their lack of robustness to irrelevant confounders. When it comes to models directly trained on human faces, a sensitive confounder is that of human identities. Many face-related tasks should ideally be identity-independent, and perform uniformly across different individuals (i.e. be fair). One way to measure and enforce such robustness and performance uniformity is through enforcing it during training, assuming identity-related information is available at scale. However, due to privacy concerns and also the cost of collecting such information, this is often not the case, and most face datasets simply contain input images and their corresponding task-related labels. Thus, improving identity-related robustness without the need for such annotations is of great importance. Here, we explore using face-recognition embedding vectors, as proxies for identities, to enfo
    

