# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](https://arxiv.org/abs/2403.10517) | 提出了一种新颖的基于代理的系统VideoAgent，利用大型语言模型作为中央代理，采用互动推理和计划来处理长视频理解问题，在挑战性基准测试中表现出卓越的效果和效率。 |
| [^2] | [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://arxiv.org/abs/2403.10516) | FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。 |
| [^3] | [SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores](https://arxiv.org/abs/2403.10408) | SocialGenPod提出了一种隐私友好的生成式AI社交网络应用部署方式，通过使用分布式的Solid规范来解耦用户数据与应用程序，实现用户在个人Pod中安全存储所有数据的控制。 |
| [^4] | [A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE](https://arxiv.org/abs/2403.10407) | 本文比较了跨编码器和LLMs在重新排序SPLADE中的表现，发现在MS MARCO上，两者难以区分，但在领域外情况下，模型类型和重新排序文档数量对效果有影响，同时GPT-4表现出色，但传统跨编码器仍然具有竞争力。 |
| [^5] | [Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification](https://arxiv.org/abs/2403.10254) | 提出了一种名为EDITOR的学习框架，用于为多模态物体再识别选择来自视觉Transformer的多样化令牌，通过Spatial-Frequency Token Selection（SFTS）模块自适应选择以对象为中心的令牌，同时通过Hierarchical Masked Aggregation（HMA）模块促进跨模态内部和之间的特征交互 |
| [^6] | [Multiscale Matching Driven by Cross-Modal Similarity Consistency for Audio-Text Retrieval](https://arxiv.org/abs/2403.10146) | 提出了一种能够从不同视角和细粒度多尺度匹配多模态信息的新型ATR框架 |
| [^7] | [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](https://arxiv.org/abs/2403.10135) | 探索在顺序推荐中使用上下文学习的方法，提出了一种聚合演示的新颖方法LLMSRec-Syn，在多个数据集上实验证明其优于现有基于LLM的方法。 |
| [^8] | [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](https://arxiv.org/abs/2403.10081) | 提出了一种新框架DRAGIN，旨在解决大型语言模型在文本生成过程中动态检索和生成中存在的问题。 |
| [^9] | [PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction](https://arxiv.org/abs/2403.10049) | PPM是用于点击率预测的预训练插件模型，克服了传统方法在冷启动问题和训练数据长度上的限制，并能够在工业推荐系统中实现端到端训练。 |
| [^10] | [Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction](https://arxiv.org/abs/2403.09963) | 本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。 |
| [^11] | [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://arxiv.org/abs/2403.09738) | 大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。 |
| [^12] | [Navigating the Peril of Generated Alternative Facts: A ChatGPT-4 Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation](https://arxiv.org/abs/2403.09674) | 本研究展示了AI（ChatGPT-4）如何轻松制造令人信服但完全虚构的科学数据，以制造出一个完全虚构的医学案例来警示医学误信息的危害。 |
| [^13] | [Benchmarking News Recommendation in the Era of Green AI](https://arxiv.org/abs/2403.04736) | 提出了用于新闻推荐的第一个绿色AI基准测试框架GreenRec，并引入评估推荐准确性和效率权衡的度量标准，实验证明其OLEO范式在可持续性方面取得竞争准确性且提供高达2992%的可持续性改进 |
| [^14] | [End-to-end Graph-Sequential Representation Learning for Accurate Recommendations](https://arxiv.org/abs/2403.00895) | 本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。 |
| [^15] | [Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain](https://arxiv.org/abs/2402.03388) | 在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。 |
| [^16] | [Within-basket Recommendation via Neural Pattern Associator.](http://arxiv.org/abs/2401.16433) | 本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。 |
| [^17] | [An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap.](http://arxiv.org/abs/2304.09572) | 本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。 |

# 详细

[^1]: 基于大型语言模型的视频代理：长视频理解

    VideoAgent: Long-form Video Understanding with Large Language Model as Agent

    [https://arxiv.org/abs/2403.10517](https://arxiv.org/abs/2403.10517)

    提出了一种新颖的基于代理的系统VideoAgent，利用大型语言模型作为中央代理，采用互动推理和计划来处理长视频理解问题，在挑战性基准测试中表现出卓越的效果和效率。

    

    长视频理解在计算机视觉中代表着一个重大挑战，需要一个能够推理长时间多模态序列的模型。受人类认知长视频过程的启发，我们强调互动推理和计划，而不是处理长篇视觉输入的能力。我们引入了一个新颖的基于代理的系统VideoAgent，它采用大型语言模型作为中央代理，迭代地识别和整理关键信息以回答问题，视觉语言基础模型作为工具来翻译和检索视觉信息。在具有挑战性的EgoSchema和NExT-QA基准测试中，VideoAgent在平均仅使用8.4和8.2帧的情况下分别实现了54.1%和71.3%的零-shot准确率。这些结果展示了我们方法相对于当前最先进方法的卓越效果和效率，突出了代理模型的潜力。

    arXiv:2403.10517v1 Announce Type: cross  Abstract: Long-form video understanding represents a significant challenge within computer vision, demanding a model capable of reasoning over long multi-modal sequences. Motivated by the human cognitive process for long-form video understanding, we emphasize interactive reasoning and planning over the ability to process lengthy visual inputs. We introduce a novel agent-based system, VideoAgent, that employs a large language model as a central agent to iteratively identify and compile crucial information to answer a question, with vision-language foundation models serving as tools to translate and retrieve visual information. Evaluated on the challenging EgoSchema and NExT-QA benchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only 8.4 and 8.2 frames used on average. These results demonstrate superior effectiveness and efficiency of our method over the current state-of-the-art methods, highlighting the potential of agent-base
    
[^2]: FeatUp: 一个与模型无关的特征任意分辨率框架

    FeatUp: A Model-Agnostic Framework for Features at Any Resolution

    [https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)

    FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。

    

    深度特征是计算机视觉研究的基石，捕捉图像语义并使社区能够解决下游任务，即使在零或少样本情况下也能做到。然而，这些特征通常缺乏空间分辨率，无法直接执行像分割和深度预测这样的稠密预测任务，因为模型会过于聚合大范围的信息。在这项工作中，我们介绍了FeatUp，一个任务和模型无关的框架，用于恢复深度特征中丢失的空间信息。我们介绍了FeatUp的两个变体：一个在单次前向传递中引导具有高分辨率信号的特征，另一个适应单个图像并以任何分辨率重构特征的隐式模型。这两种方法都使用了一个具有与 NeRF 类似的深度类比的多视图一致性损失。我们的特征保留其原始语义，并可以替换现有应用程序，即使不重新

    arXiv:2403.10516v1 Announce Type: cross  Abstract: Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-
    
[^3]: SocialGenPod: 隐私友好的分布式个人数据存储的生成式AI社交网络应用

    SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores

    [https://arxiv.org/abs/2403.10408](https://arxiv.org/abs/2403.10408)

    SocialGenPod提出了一种隐私友好的生成式AI社交网络应用部署方式，通过使用分布式的Solid规范来解耦用户数据与应用程序，实现用户在个人Pod中安全存储所有数据的控制。

    

    我们提出了SocialGenPod，这是一种分布式且隐私友好的方式用于部署生成式AI Web应用。我们展示了如何利用Solid规范来将用户数据与生成式AI应用程序解耦，与保持用户数据与应用程序和服务提供商绑定的集中式Web和数据架构不同。我们使用一个原型演示了SocialGenPod，允许用户与不同的大型语言模型对话，可选择利用检索增强生成技术生成以用户被允许直接或间接访问的任何Solid Pod中存储的私人文档为基础的答案。SocialGenPod利用Solid访问控制机制，让用户完全控制确定谁可以访问存储在他们Pod中的数据。SocialGenPod将所有用户数据（聊天记录，应用程序配置，个人文档等）安全地存储在用户的个人Pod中；与特定模型分开。

    arXiv:2403.10408v1 Announce Type: cross  Abstract: We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid -- a decentralised Web specification -- to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user's personal Pod; separate from specific model 
    
[^4]: 跨编码器和LLMs在重新排序SPLADE中的彻底比较

    A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE

    [https://arxiv.org/abs/2403.10407](https://arxiv.org/abs/2403.10407)

    本文比较了跨编码器和LLMs在重新排序SPLADE中的表现，发现在MS MARCO上，两者难以区分，但在领域外情况下，模型类型和重新排序文档数量对效果有影响，同时GPT-4表现出色，但传统跨编码器仍然具有竞争力。

    

    我们在重新排序有效的SPLADE检索器的背景下，介绍了跨编码器和LLMs重新排序器之间的比较性研究。我们对TREC深度学习数据集和BEIR、LoTTE等领域外数据集进行了大量评估。在第一组实验中，我们展示了在重新排序SPLADE在MS MARCO上时，跨编码器重新排序器是难以区分的。观察结果在领域外情况下发生了变化，模型类型和重新排序文档数量对效果产生影响。然后，我们专注于基于大型语言模型的列表式重新排序器，特别是GPT-4。虽然GPT-4展示了令人印象深刻的（零样本）性能，但我们表明传统的跨编码器仍然非常具有竞争力。总体而言，我们的研究结果旨在提供对围绕LLM-based重新排序器最近的兴奋情绪更细致的观点，将它们定位为在平衡效果时需要考虑的另一个因素。

    arXiv:2403.10407v1 Announce Type: new  Abstract: We present a comparative study between cross-encoder and LLMs rerankers in the context of re-ranking effective SPLADE retrievers. We conduct a large evaluation on TREC Deep Learning datasets and out-of-domain datasets such as BEIR and LoTTE. In the first set of experiments, we show how cross-encoder rerankers are hard to distinguish when it comes to re-rerank SPLADE on MS MARCO. Observations shift in the out-of-domain scenario, where both the type of model and the number of documents to re-rank have an impact on effectiveness. Then, we focus on listwise rerankers based on Large Language Models -- especially GPT-4. While GPT-4 demonstrates impressive (zero-shot) performance, we show that traditional cross-encoders remain very competitive. Overall, our findings aim to to provide a more nuanced perspective on the recent excitement surrounding LLM-based re-rankers -- by positioning them as another factor to consider in balancing effectivenes
    
[^5]: 魔法令牌：为多模态物体再识别选择多样化令牌

    Magic Tokens: Select Diverse Tokens for Multi-modal Object Re-Identification

    [https://arxiv.org/abs/2403.10254](https://arxiv.org/abs/2403.10254)

    提出了一种名为EDITOR的学习框架，用于为多模态物体再识别选择来自视觉Transformer的多样化令牌，通过Spatial-Frequency Token Selection（SFTS）模块自适应选择以对象为中心的令牌，同时通过Hierarchical Masked Aggregation（HMA）模块促进跨模态内部和之间的特征交互

    

    单模态物体再识别（ReID）在复杂视觉场景中保持稳健性面临巨大挑战。相比之下，多模态物体ReID利用来自多样化模态的互补信息，显示出在实际应用中具有巨大潜力。然而，先前的方法可能容易受到无关背景的影响，并通常忽视模态之间的差距。为了解决上述问题，我们提出了一个名为\textbf{EDITOR}的新型学习框架，用于为多模态物体ReID选择来自视觉Transformer的多样化令牌。我们从一个共享的视觉Transformer开始，从不同的输入模态中提取令牌化特征。然后，我们引入了一个名为空间频率令牌选择（SFTS）模块，自适应地选择具有空间和频率信息的以对象为中心的令牌。随后，我们采用了一个名为分层掩码聚合（HMA）模块，促进跨模态内部和之间的特征交互。

    arXiv:2403.10254v1 Announce Type: cross  Abstract: Single-modal object re-identification (ReID) faces great challenges in maintaining robustness within complex visual scenarios. In contrast, multi-modal object ReID utilizes complementary information from diverse modalities, showing great potentials for practical applications. However, previous methods may be easily affected by irrelevant backgrounds and usually ignore the modality gaps. To address above issues, we propose a novel learning framework named \textbf{EDITOR} to select diverse tokens from vision Transformers for multi-modal object ReID. We begin with a shared vision Transformer to extract tokenized features from different input modalities. Then, we introduce a Spatial-Frequency Token Selection (SFTS) module to adaptively select object-centric tokens with both spatial and frequency information. Afterwards, we employ a Hierarchical Masked Aggregation (HMA) module to facilitate feature interactions within and across modalities.
    
[^6]: 基于跨模态相似性一致性驱动的多尺度匹配用于音频-文本检索

    Multiscale Matching Driven by Cross-Modal Similarity Consistency for Audio-Text Retrieval

    [https://arxiv.org/abs/2403.10146](https://arxiv.org/abs/2403.10146)

    提出了一种能够从不同视角和细粒度多尺度匹配多模态信息的新型ATR框架

    

    音频-文本检索（ATR）近年来受到了广泛的研究关注，它可以在给定音频剪辑（A2T）时检索相关字幕，反之亦然（T2A）。现有方法通常将每种模态的信息聚合到单个向量中进行匹配，但这样做会牺牲局部细节，并且很难捕获模态内部和之间复杂的关系。此外，当前ATR数据集缺乏全面的对齐信息，并且简单的二元对比学习标签忽略了样本间细粒度语义差异的衡量。为了应对这些挑战，我们提出了一个新颖的ATR框架，该框架全面捕捉了不同视角和更细的粒度中多模态信息的匹配关系。具体而言，引入了一种细粒度对齐方法，通过从局部到全局层次的多尺度过程实现更详细的匹配，以捕获metic

    arXiv:2403.10146v1 Announce Type: cross  Abstract: Audio-text retrieval (ATR), which retrieves a relevant caption given an audio clip (A2T) and vice versa (T2A), has recently attracted much research attention. Existing methods typically aggregate information from each modality into a single vector for matching, but this sacrifices local details and can hardly capture intricate relationships within and between modalities. Furthermore, current ATR datasets lack comprehensive alignment information, and simple binary contrastive learning labels overlook the measurement of fine-grained semantic differences between samples. To counter these challenges, we present a novel ATR framework that comprehensively captures the matching relationships of multimodal information from different perspectives and finer granularities. Specifically, a fine-grained alignment method is introduced, achieving a more detail-oriented matching through a multiscale process from local to global levels to capture metic
    
[^7]: 整体优于总和：在上下文学习中使用聚合演示进行顺序推荐

    The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation

    [https://arxiv.org/abs/2403.10135](https://arxiv.org/abs/2403.10135)

    探索在顺序推荐中使用上下文学习的方法，提出了一种聚合演示的新颖方法LLMSRec-Syn，在多个数据集上实验证明其优于现有基于LLM的方法。

    

    大型语言模型（LLMs）在各种自然语言处理任务中展现出优秀性能。为了将LLMs作为强大的顺序推荐系统，我们探索了上下文学习方法用于顺序推荐。我们研究了指导格式、任务一致性、演示选择和演示数量对模型的影响。我们提出了一种新颖的方法LLMSRec-Syn，通过将多个演示用户整合成一个聚合演示来提高准确性。我们在三个推荐数据集上进行了实验证明，LLMSRec-Syn优于最先进的基于LLM的顺序推荐方法。在某些情况下，LLMSRec-Syn可以与甚至优于监督学习方法。我们的代码公开在https://github.com/demoleiwang/LLMSRec_Syn。

    arXiv:2403.10135v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown excellent performance on various NLP tasks. To use LLMs as strong sequential recommenders, we explore the in-context learning approach to sequential recommendation. We investigate the effects of instruction format, task consistency, demonstration selection, and number of demonstrations. As increasing the number of demonstrations in ICL does not improve accuracy despite using a long prompt, we propose a novel method called LLMSRec-Syn that incorporates multiple demonstration users into one aggregated demonstration. Our experiments on three recommendation datasets show that LLMSRec-Syn outperforms state-of-the-art LLM-based sequential recommendation methods. In some cases, LLMSRec-Syn can perform on par with or even better than supervised learning methods. Our code is publicly available at https://github.com/demoleiwang/LLMSRec_Syn.
    
[^8]: DRAGIN：基于大型语言模型实时信息需求的动态检索增强生成

    DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models

    [https://arxiv.org/abs/2403.10081](https://arxiv.org/abs/2403.10081)

    提出了一种新框架DRAGIN，旨在解决大型语言模型在文本生成过程中动态检索和生成中存在的问题。

    

    动态检索增强生成（RAG）范式在大型语言模型（LLMs）的文本生成过程中主动决定何时以及何时检索。该范式的两个关键元素是确定激活检索模块的最佳时机（决定何时检索）以及一旦触发检索，制定适当的查询（确定要检索什么）。然而，当前动态RAG方法在两个方面都存在不足。首先，决定何时进行检索的策略通常依赖于静态规则。此外，决定要检索什么的策略通常局限于LLM的最近一句或最后几个标记，而LLM的实时信息需求可能跨越整个上下文。为克服这些局限性，我们引入了一个新框架DRAGIN， 即基于LLMs实时信息需求的动态检索增强生成。

    arXiv:2403.10081v1 Announce Type: new  Abstract: Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs). There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to retrieve) and crafting the appropriate query once retrieval is triggered (determining what to retrieve). However, current dynamic RAG methods fall short in both aspects. Firstly, the strategies for deciding when to retrieve often rely on static rules. Moreover, the strategies for deciding what to retrieve typically limit themselves to the LLM's most recent sentence or the last few tokens, while the LLM's real-time information needs may span across the entire context. To overcome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic Retrieval Augmented Generation based on the real-time Information Needs of LLMs. Our framework is specif
    
[^9]: PPM：用于点击率预测的预训练插件模型

    PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction

    [https://arxiv.org/abs/2403.10049](https://arxiv.org/abs/2403.10049)

    PPM是用于点击率预测的预训练插件模型，克服了传统方法在冷启动问题和训练数据长度上的限制，并能够在工业推荐系统中实现端到端训练。

    

    arXiv:2403.10049v1 公告类型: 跨学科 摘要: 点击率（CTR）预测是推荐系统中的核心任务。现有方法（简称为IDRec）依赖于唯一身份来表示几十年来盛行的不同用户和物品。一方面，IDRec在冷启动问题上经常面临显著的性能下降；另一方面，由于迭代效率的约束，IDRec无法使用更长的训练数据。大多数先前的研究通过引入预训练知识（例如，预训练用户模型或多模态嵌入）来缓解上述问题。然而，在线延迟的爆炸性增长可以归因于预训练模型中的巨大参数。因此，大多数无法在工业推荐系统中使用与IDRec端到端训练的统一模型，从而限制了预训练模型的潜力。为此，我们提出了一种$\textbf{P}$re-trained $\textbf{P}$lug-in CTR $\textbf{M}$odel，即PPM。PPM em

    arXiv:2403.10049v1 Announce Type: cross  Abstract: Click-through rate (CTR) prediction is a core task in recommender systems. Existing methods (IDRec for short) rely on unique identities to represent distinct users and items that have prevailed for decades. On one hand, IDRec often faces significant performance degradation on cold-start problem; on the other hand, IDRec cannot use longer training data due to constraints imposed by iteration efficiency. Most prior studies alleviate the above problems by introducing pre-trained knowledge(e.g. pre-trained user model or multi-modal embeddings). However, the explosive growth of online latency can be attributed to the huge parameters in the pre-trained model. Therefore, most of them cannot employ the unified model of end-to-end training with IDRec in industrial recommender systems, thus limiting the potential of the pre-trained model. To this end, we propose a $\textbf{P}$re-trained $\textbf{P}$lug-in CTR $\textbf{M}$odel, namely PPM. PPM em
    
[^10]: 处理好您的提示偏见！调查和减轻事实知识提取中的提示偏见

    Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction

    [https://arxiv.org/abs/2403.09963](https://arxiv.org/abs/2403.09963)

    本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。

    

    最近的研究表明，预训练语言模型（PLMs）在事实知识提取中存在“提示偏见”，即提示往往会引入对特定标签的偏见。然而，模型内部提示偏见的程度和影响尚未得到充分探讨。为了回应这一点，本文量化了不同类型提示的偏见，并评估了它们对不同基准测试的影响。我们发现：1）实验中的所有提示都表现出不可忽视的偏见，基于梯度的提示如AutoPrompt和OptiPrompt显示出更高水平的偏见；2）提示偏见可以通过过度拟合测试数据集不合理地放大基准测试的准确性，特别是在类似LAMA这样的不平衡数据集上。基于这些发现，我们提出了一种基于表示的方法来减轻提示偏见，在推断时。具体而言，我们首先使用仅提示查询来估计有偏差的表示，然后从中删除。

    arXiv:2403.09963v1 Announce Type: cross  Abstract: Recent research shows that pre-trained language models (PLMs) suffer from "prompt bias" in factual knowledge extraction, i.e., prompts tend to introduce biases toward specific labels. However, the extent and impact of prompt bias within the model remain underexplored. In response, this paper quantifies the bias with various types of prompts and assesses their impact on different benchmarks. We show that: 1) all prompts in the experiments exhibit non-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt displaying significantly higher levels of bias; 2) prompt bias can amplify benchmark accuracy unreasonably by overfitting the test datasets, especially on imbalanced datasets like LAMA. Based on these findings, we propose a representation-based approach to mitigate the prompt bias during inference time. Specifically, we first estimate the biased representation using prompt-only querying, and then remove it from the 
    
[^11]: 评估大语言模型作为对话推荐中生成用户模拟器

    Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation

    [https://arxiv.org/abs/2403.09738](https://arxiv.org/abs/2403.09738)

    大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。

    

    合成用户是对话推荐系统评估中成本效益较高的真实用户代理。大型语言模型表现出在模拟类似人类行为方面的潜力，这引发了它们能否代表多样化用户群体的问题。我们引入了一个新的协议，用于衡量语言模型能够准确模拟对话推荐中人类行为的程度。该协议由五个任务组成，每个任务旨在评估合成用户应该表现出的关键特性：选择要谈论的物品，表达二进制偏好，表达开放式偏好，请求推荐以及提供反馈。通过对基准模拟器的评估，我们展示了这些任务有效地揭示了语言模型与人类行为的偏差，并提供了关于如何通过模型选择和提示策略减少这些偏差的见解。

    arXiv:2403.09738v1 Announce Type: cross  Abstract: Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.
    
[^12]: 避开生成的替代事实的危险：以ChatGPT-4制造的Ω变种案例作为医学误信息的警示故事

    Navigating the Peril of Generated Alternative Facts: A ChatGPT-4 Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation

    [https://arxiv.org/abs/2403.09674](https://arxiv.org/abs/2403.09674)

    本研究展示了AI（ChatGPT-4）如何轻松制造令人信服但完全虚构的科学数据，以制造出一个完全虚构的医学案例来警示医学误信息的危害。

    

    在人工智能与医学研究交织的时代，真相的披露变得日益复杂。本研究表面上审查了一种所谓的新型SARS-CoV-2变种，被称为Ω变种，展示在S基因区域中有31个独特突变。然而，这个故事的真正潜台词是展示了AI（具体来说是ChatGPT-4）可以如何轻松地制造令人信服但完全虚构的科学数据。所谓的Ω变种在一个完全接种疫苗、之前感染过的35岁男性中被鉴定出现严重COVID-19症状。通过详细的，尽管是虚拟的，基因组分析和接触者追踪，本研究模拟了真实病例报告的严谨方法，从而为一个引人入胜但完全构造的叙述奠定了基础。整个病例研究是由OpenAI的大型语言模型ChatGPT-4生成的Ω变种。

    arXiv:2403.09674v1 Announce Type: new  Abstract: In an era where artificial intelligence (AI) intertwines with medical research, the delineation of truth becomes increasingly complex. This study ostensibly examines a purported novel SARS-CoV-2 variant, dubbed the Omega variant, showcasing 31 unique mutations in the S gene region. However, the real undercurrent of this narrative is a demonstration of the ease with which AI, specifically ChatGPT-4, can fabricate convincing yet entirely fictional scientific data. The so-called Omega variant was identified in a fully vaccinated, previously infected 35-year-old male presenting with severe COVID-19 symptoms. Through a detailed, albeit artificial, genomic analysis and contact tracing, this study mirrors the rigorous methodology of genuine case reports, thereby setting the stage for a compelling but entirely constructed narrative. The entire case study was generated by ChatGPT-4, a large language model by OpenAI. The fabricated Omega variant f
    
[^13]: 在绿色AI时代对新闻推荐进行基准测试

    Benchmarking News Recommendation in the Era of Green AI

    [https://arxiv.org/abs/2403.04736](https://arxiv.org/abs/2403.04736)

    提出了用于新闻推荐的第一个绿色AI基准测试框架GreenRec，并引入评估推荐准确性和效率权衡的度量标准，实验证明其OLEO范式在可持续性方面取得竞争准确性且提供高达2992%的可持续性改进

    

    近年来，新闻推荐系统在学术界和工业界备受关注，强调了需要一个标准化基准来评估和比较这些系统的性能。同时，绿色人工智能倡导减少机器学习的能耗和环境影响。为了解决这些问题，我们引入了第一个用于新闻推荐的绿色AI基准测试框架，称为GreenRec，并提出了一个评估推荐准确性和效率之间权衡的度量标准。我们的基准测试涵盖30个基础模型及其变体，涵盖了传统的端到端训练范式以及我们提出的高效的仅编码一次（OLEO）范式。通过消耗2000个GPU小时的实验，我们观察到OLEO范式在可持续性方面相较于最先进的端到端范式实现了具竞争力的准确性，并提供高达2992%的可持续性改进。

    arXiv:2403.04736v1 Announce Type: new  Abstract: Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992\% improvement in sustainability
    
[^14]: 精确推荐的端到端图-序列表示学习

    End-to-end Graph-Sequential Representation Learning for Accurate Recommendations

    [https://arxiv.org/abs/2403.00895](https://arxiv.org/abs/2403.00895)

    本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。

    

    近年来推荐系统的许多新进展集中在开发基于序列和基于图的方法上。这两种方法在建模行为数据中的复杂关系方面都证明了其有效性，从而在个性化排名和下一个推荐任务中取得了有益的成果，同时保持了良好的可扩展性。然而，它们从数据中捕捉到的信号截然不同。前者直接通过与最近物品的有序交互来表示用户，而后者旨在捕捉交互图中的间接依赖关系。本文提出了一个新颖的多重表示学习框架，利用这两种范式之间的协同作用。我们在几个数据集上的实证评估表明，利用所提出的框架相互训练序列和图组件显著改善了推荐性能。

    arXiv:2403.00895v1 Announce Type: cross  Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.
    
[^15]: 在预算限制下行为用户分割中的优化传递发现

    Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain

    [https://arxiv.org/abs/2402.03388](https://arxiv.org/abs/2402.03388)

    在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。

    

    用户在线行为足迹可以使公司发现基于行为的用户细分，并向用户发送特定细分的信息。在发现细分之后，通过像Facebook和Google这样的首选媒体渠道向用户发送信息可能具有挑战性，因为只有部分行为细分中的用户在媒体上找到匹配，并且只有其中一小部分看到消息（曝光）。即使高质量的发现也会在传递失败时变得无用。许多复杂的算法用于发现行为细分，然而这些算法忽略了传递组件。问题变得复杂是因为（i）发现是在公司数据（例如用户点击）的行为数据空间中进行的，而传递则是基于媒体定义的静态数据空间（例如地理位置，年龄）进行的；（ii）公司在预算限制下运作。我们引入了一种基于随机优化的算法，用于在预算限制下优化传递发现行为用户细分。

    Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral u
    
[^16]: 通过神经模式关联器进行篮内推荐

    Within-basket Recommendation via Neural Pattern Associator. (arXiv:2401.16433v1 [cs.IR])

    [http://arxiv.org/abs/2401.16433](http://arxiv.org/abs/2401.16433)

    本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。

    

    篮内推荐（WBR）是指在购物过程中为了完成一个非空购物篮而推荐商品的任务。尽管这个领域的最新创新在基准数据集上表现出了显著的性能提升，但它们常常忽视了实际用户行为的复杂性，比如1）多个购物意图的共存，2）这些意图的多粒度和3）购物过程中的交织行为（切换意图）。本文提出了一种名为神经模式关联器（NPA）的深度商品关联挖掘模型，明确地建模了上述因素。具体来说，受到向量量化的启发，NPA模型学习将常见的用户意图（或商品组合模式）编码为量化表示（也称为码本），这允许在推理阶段通过注意力驱动的查找来识别用户的购物意图。这样产生的推荐结果连贯且自解释。

    Within-basket recommendation (WBR) refers to the task of recommending items to the end of completing a non-empty shopping basket during a shopping session. While the latest innovations in this space demonstrate remarkable performance improvement on benchmark datasets, they often overlook the complexity of user behaviors in practice, such as 1) co-existence of multiple shopping intentions, 2) multi-granularity of such intentions, and 3) interleaving behavior (switching intentions) in a shopping session. This paper presents Neural Pattern Associator (NPA), a deep item-association-mining model that explicitly models the aforementioned factors. Specifically, inspired by vector quantization, the NPA model learns to encode common user intentions (or item-combination patterns) as quantized representations (a.k.a. codebook), which permits identification of users's shopping intentions via attention-driven lookup during the reasoning phase. This yields coherent and self-interpretable recommendat
    
[^17]: 个人知识图谱生态系统：调查与研究路线图

    An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap. (arXiv:2304.09572v1 [cs.AI])

    [http://arxiv.org/abs/2304.09572](http://arxiv.org/abs/2304.09572)

    本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。

    

    本论文提出了一个个人知识图谱（PKG）的生态系统，通常定义为有关个人相关实体、其属性和它们之间关系的结构化信息资源。PKG是安全、精密的个人数据管理和个性化服务的关键支持。然而，在PKG能够广泛应用之前需要解决一些挑战。其中一个基本挑战是关于PKG的定义，因为术语有多种解释。我们提出了自己的PKG定义，强调了（1）单个个体拥有数据和（2）提供个性化服务作为主要目的的方面。我们进一步提出了一个综合的PKG视图，需要解锁它们的全部潜力，并提出了一个统一的框架，其中PKG是更大的生态系统的一部分，具有明确的与数据服务和数据源的接口。本文还展示了对当前PKG研究的全面调查和研究路线图。

    This paper presents an ecosystem for personal knowledge graphs (PKG), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and 
    

