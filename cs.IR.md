# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized Adaptive Testing.](http://arxiv.org/abs/2310.07477) | GMOCAT是一种用于计算机化自适应测试的图增强多目标方法，通过引入质量、多样性和新颖性三个目标，提高了预测准确性，并考虑了概念多样性和问题暴露控制的重要性。 |
| [^2] | [Preliminary Results of a Scientometric Analysis of the German Information Retrieval Community 2020-2023.](http://arxiv.org/abs/2310.07346) | 首次对德国信息检索社区进行科学计量分析，生成了401篇最近的信息检索相关论文数据集，并在机构和研究人员级别进行了分析。 |
| [^3] | [A Completely Locale-independent Session-based Recommender System by Leveraging Trained Model.](http://arxiv.org/abs/2310.07281) | 本文介绍了一种完全与本地环境无关的基于会话的推荐系统，通过利用训练模型并结合特征选取和重新排序的方法，能够在不同的本地环境下表现出一致的良好性能，甚至在训练中结合其他本地环境的数据时效果更好。 |
| [^4] | [Validating Synthetic Usage Data in Living Lab Environments.](http://arxiv.org/abs/2310.07142) | 本研究介绍了一种在数据稀缺的人在循环环境（如生活实验室）中验证由点击模型产生的合成使用数据的评估方法。 |
| [^5] | [AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction.](http://arxiv.org/abs/2310.07137) | 本论文提出了一种基于语义匹配和负标签采样的多标签分类模型 AE-smnsMLC，用于解决产品属性值提取的问题。该模型将属性值提取任务转化为多标签分类任务，可以应用于只有属性值注释的实际场景，而无需属性值的位置信息注释。 |
| [^6] | [Answer Candidate Type Selection: Text-to-Text Language Model for Closed Book Question Answering Meets Knowledge Graphs.](http://arxiv.org/abs/2310.07008) | 本文提出了一种新颖的方法，通过对预训练的文本到文本问答系统生成的候选答案基于其类型进行过滤和重新排序，以解决在知识图谱问答任务中，模型容量有限且对于含有不太流行实体的问题质量下降的问题。 |
| [^7] | [A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging.](http://arxiv.org/abs/2310.06913) | 本文研究了基于Transformer的神经文本表示技术在缺陷分配中的应用，相比之前的方法，这些新技术能更好地捕捉微妙的文本模式，提高自动化缺陷分配的性能。 |
| [^8] | [MuseChat: A Conversational Music Recommendation System for Videos.](http://arxiv.org/abs/2310.06282) | MuseChat是一种创新的对话式音乐推荐系统，通过模拟用户和推荐系统之间的对话交互，利用预训练的音乐标签和艺术家信息，为用户提供定制的音乐推荐，使用户可以个性化选择他们喜欢的音乐。 |
| [^9] | [DiscoverPath: A Knowledge Refinement and Retrieval System for Interdisciplinarity on Biomedical Research.](http://arxiv.org/abs/2309.01808) | DiscoverPath是一个基于知识图的生物医学研究论文搜索引擎，通过命名实体识别和词性标注从文章摘要中提取术语和关系，并展示给用户一个关注查询实体及其邻近节点的子图，以及查询推荐系统，使用户能够循序渐进地细化查询。 |
| [^10] | [Deep Neural Aggregation for Recommending Items to Group of Users.](http://arxiv.org/abs/2307.09447) | 本文针对群体用户推荐商品的问题，提出了两种新的深度学习模型，并通过实验证明了这些模型相比现有模型的改进效果。 |
| [^11] | [Editing Large Language Models: Problems, Methods, and Opportunities.](http://arxiv.org/abs/2305.13172) | 本文深入探讨了编辑大型语言模型的问题、方法和机会，提供了任务定义和挑战的概述、先进方法的实证分析，以及构建了新的基准数据集。这些结果有助于改进LLMs的编辑技术，提高其效果和可行性。 |
| [^12] | [Knowledge Rumination for Pre-trained Language Models.](http://arxiv.org/abs/2305.08732) | 本文提出了一种名为知识反思的新范式，旨在帮助预训练语言模型利用已经编码在其预训练参数中的相关潜在知识，而不需要从外部语料库中检索。这种方法通过在模型中添加提示，并将相关知识注入模型进行整合，取得了在常识推理任务和GLUE基准上的实验结果。 |
| [^13] | [Contrastive Self-supervised Learning in Recommender Systems: A Survey.](http://arxiv.org/abs/2303.09902) | 本综述论文对基于对比自监督学习的推荐方法进行了综合评估和分类，并提供了统一的框架来概述这些方法。对比自监督学习方法由于灵活性和性能优良而吸引了大量关注，并成为了自监督学习推荐方法的主导分支。 |
| [^14] | [Query2doc: Query Expansion with Large Language Models.](http://arxiv.org/abs/2303.07678) | 本论文提出了一种名为query2doc的查询扩展方法，使用大型语言模型生成伪文档来改善稀疏和密集检索系统，取得了在多个数据集上提高 BM25 性能的结果。 |
| [^15] | [Scene-centric vs. Object-centric Image-Text Cross-modal Retrieval: A Reproducibility Study.](http://arxiv.org/abs/2301.05174) | 这项研究关注基于场景和对象的图像-文本跨模态检索的可复现性，通过选择不同体系结构的最先进模型并在不同类型的数据集上进行评估，探讨了其在不同数据集类型上的泛化能力。 |
| [^16] | [Towards Reliable Item Sampling for Recommendation Evaluation.](http://arxiv.org/abs/2211.15743) | 本文研究面向推荐系统评估的可靠物品采样方法，提出了一种新的采样估计器，优化误差和理论精度。 |
| [^17] | [An Equity-Aware Recommender System for Curating Art Exhibits Based on Locally-Constrained Graph Matching.](http://arxiv.org/abs/2207.14367) | 这个论文介绍了一种注重公正性的艺术展推荐系统，通过局部约束图匹配和价值导向的资源分配，实现公共艺术展览的策划。该系统采用Schelling模型构建成本矩阵，并通过优化评分函数，软分配艺术作品到公共空间，以减少内部群体偏好、满足最低代表性和曝光标准。 |
| [^18] | [Efficiently Leveraging Multi-level User Intent for Session-based Recommendation via Atten-Mixer Network.](http://arxiv.org/abs/2206.12781) | 本文针对基于会话的推荐任务，通过剖析经典的基于图神经网络的推荐模型，发现一些复杂的图神经网络传播部分是多余的。基于此观察，我们提出了Multi-Level Attention Mixture Network (Atten-Mixer)，它通过移除多余的传播部分，实现了对读出模块的更高效利用。 |
| [^19] | [UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text.](http://arxiv.org/abs/2108.08614) | 本文提出了一个名为UNIQORN的问答系统，它能够无缝地处理RDF数据和文本，使用fine-tuned BERT模型为问题构建上下文图，并使用图算法确定与问题相关的子图来回答问题。 |

# 详细

[^1]: GMOCAT:一种用于计算机化自适应测试的图增强多目标方法

    GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized Adaptive Testing. (arXiv:2310.07477v1 [cs.IR])

    [http://arxiv.org/abs/2310.07477](http://arxiv.org/abs/2310.07477)

    GMOCAT是一种用于计算机化自适应测试的图增强多目标方法，通过引入质量、多样性和新颖性三个目标，提高了预测准确性，并考虑了概念多样性和问题暴露控制的重要性。

    

    计算机化自适应测试（CAT）是指根据学生的历史作答记录，根据他们的能力智能选择最合适的问题的在线系统。大多数CAT方法只关注准确预测学生能力的质量目标，而忽视了概念多样性或问题暴露控制，这在确保CAT的性能和有效性方面是重要考虑因素。此外，学生的作答记录包含问题和知识概念之间有价值的关系信息。之前的方法忽视了这种关系信息，导致选择次优的测试问题。为了解决这些挑战，我们提出了一种用于CAT的图增强多目标方法（GMOCAT）。首先，在CAT的标量化多目标强化学习框架中引入了三个目标，分别对应于提高预测准确性、增加多样性和新颖性。

    Computerized Adaptive Testing(CAT) refers to an online system that adaptively selects the best-suited question for students with various abilities based on their historical response records. Most CAT methods only focus on the quality objective of predicting the student ability accurately, but neglect concept diversity or question exposure control, which are important considerations in ensuring the performance and validity of CAT. Besides, the students' response records contain valuable relational information between questions and knowledge concepts. The previous methods ignore this relational information, resulting in the selection of sub-optimal test questions. To address these challenges, we propose a Graph-Enhanced Multi-Objective method for CAT (GMOCAT). Firstly, three objectives, namely quality, diversity and novelty, are introduced into the Scalarized Multi-Objective Reinforcement Learning framework of CAT, which respectively correspond to improving the prediction accuracy, incre
    
[^2]: 2020-2023年德国信息检索社区的科学计量分析初步结果

    Preliminary Results of a Scientometric Analysis of the German Information Retrieval Community 2020-2023. (arXiv:2310.07346v1 [cs.IR])

    [http://arxiv.org/abs/2310.07346](http://arxiv.org/abs/2310.07346)

    首次对德国信息检索社区进行科学计量分析，生成了401篇最近的信息检索相关论文数据集，并在机构和研究人员级别进行了分析。

    

    德国信息检索社区分布在信息科学和计算机科学两个子领域中。目前没有研究对这两个社区进行科学计量分析。现有研究只关注信息科学方面的社区。我们生成了一个数据集，其中包括了401篇最近的信息检索相关论文，从主要由计算机科学背景的六个核心信息检索会议中提取。我们在机构和研究人员级别对该数据集进行了分析。该数据集已公开发布，我们还展示了一个映射使用案例。

    The German Information Retrieval community is located in two different sub-fields: Information and computer science. There are no current studies that investigate these communities on a scientometric level. Available studies only focus on the information scientific part of the community. We generated a data set of 401 recent IR-related publications extracted from six core IR conferences from a mainly computer scientific background. We analyze this data set at the institutional and researcher level. The data set is publicly released, and we also demonstrate a mapping use case.
    
[^3]: 通过利用训练模型实现完全与本地环境无关的基于会话的推荐系统

    A Completely Locale-independent Session-based Recommender System by Leveraging Trained Model. (arXiv:2310.07281v1 [cs.IR])

    [http://arxiv.org/abs/2310.07281](http://arxiv.org/abs/2310.07281)

    本文介绍了一种完全与本地环境无关的基于会话的推荐系统，通过利用训练模型并结合特征选取和重新排序的方法，能够在不同的本地环境下表现出一致的良好性能，甚至在训练中结合其他本地环境的数据时效果更好。

    

    本文提出了一个解决方案，在KDD Cup 2023挑战任务2（针对语言/本地环境推荐下一款产品）中获得了第10名。我们的方法包括两个步骤：（i）基于共同访问识别候选项集，和（ii）使用包括基于会话的特征和产品相似性在内的与本地环境无关的特征，使用LightGBM对这些项进行重新排序。实验表明，与不同测试本地环境相比，与本地环境无关的模型表现出一致的良好性能，并且在训练中结合其他本地环境的数据时效果更好。

    In this paper, we propose a solution that won the 10th prize in the KDD Cup 2023 Challenge Task 2 (Next Product Recommendation for Underrepresented Languages/Locales). Our approach involves two steps: (i) Identify candidate item sets based on co-visitation, and (ii) Re-ranking the items using LightGBM with locale-independent features, including session-based features and product similarity. The experiment demonstrated that the locale-independent model performed consistently well across different test locales, and performed even better when incorporating data from other locales into the training.
    
[^4]: 在生活实验室环境中验证合成使用数据

    Validating Synthetic Usage Data in Living Lab Environments. (arXiv:2310.07142v1 [cs.IR])

    [http://arxiv.org/abs/2310.07142](http://arxiv.org/abs/2310.07142)

    本研究介绍了一种在数据稀缺的人在循环环境（如生活实验室）中验证由点击模型产生的合成使用数据的评估方法。

    

    在没有编辑相关性判断的情况下评估检索性能是具有挑战性的，但是可以使用用户交互作为相关信号。生活实验室为小规模平台提供了一种使用真实用户验证信息检索系统的方式。如果有足够多的用户交互数据，可以从历史会话中对点击模型进行参数化，以在将用户暴露于实验排名之前评估系统。然而，在生活实验室中，交互数据很稀疏，关于当点击数据数量较少时如何验证可靠的用户模拟方面的研究很少。本研究介绍了一种验证在数据稀疏的人在循环环境（如生活实验室）中由点击模型产生的合成使用数据的评估方法。我们的方法基于点击模型对系统排名与已知相对性能的参考排名之间的估计。我们的实验比较了不同的点击模型。

    Evaluating retrieval performance without editorial relevance judgments is challenging, but instead, user interactions can be used as relevance signals. Living labs offer a way for small-scale platforms to validate information retrieval systems with real users. If enough user interaction data are available, click models can be parameterized from historical sessions to evaluate systems before exposing users to experimental rankings. However, interaction data are sparse in living labs, and little is studied about how click models can be validated for reliable user simulations when click data are available in moderate amounts.  This work introduces an evaluation approach for validating synthetic usage data generated by click models in data-sparse human-in-the-loop environments like living labs. We ground our methodology on the click model's estimates about a system ranking compared to a reference ranking for which the relative performance is known. Our experiments compare different click m
    
[^5]: AE-smnsMLC：基于语义匹配和负标签采样的产品属性值提取的多标签分类

    AE-smnsMLC: Multi-Label Classification with Semantic Matching and Negative Label Sampling for Product Attribute Value Extraction. (arXiv:2310.07137v1 [cs.IR])

    [http://arxiv.org/abs/2310.07137](http://arxiv.org/abs/2310.07137)

    本论文提出了一种基于语义匹配和负标签采样的多标签分类模型 AE-smnsMLC，用于解决产品属性值提取的问题。该模型将属性值提取任务转化为多标签分类任务，可以应用于只有属性值注释的实际场景，而无需属性值的位置信息注释。

    

    产品属性值提取在电子商务等许多实际应用中起着重要作用，如产品搜索和推荐。之前的方法将其视为需要更多注释来标注产品文本中值的序列标记任务。这限制了它们在实际场景中的应用，其中每个产品只有属性值的弱标注，而没有它们的位置信息。此外，这些方法只使用产品文本（即产品标题和描述），而不考虑给定产品的多个属性值与其文本之间的语义连接，这可以帮助属性值提取。在本文中，我们将这个任务重新定义为一个多标签分类任务，可以在实际场景中应用，其中只有属性值的注释可用于训练模型（即没有属性值位置信息的注释）。我们提出了一个具有语义匹配和负标签采样的分类模型

    Product attribute value extraction plays an important role for many real-world applications in e-Commerce such as product search and recommendation. Previous methods treat it as a sequence labeling task that needs more annotation for position of values in the product text. This limits their application to real-world scenario in which only attribute values are weakly-annotated for each product without their position. Moreover, these methods only use product text (i.e., product title and description) and do not consider the semantic connection between the multiple attribute values of a given product and its text, which can help attribute value extraction. In this paper, we reformulate this task as a multi-label classification task that can be applied for real-world scenario in which only annotation of attribute values is available to train models (i.e., annotation of positional information of attribute values is not available). We propose a classification model with semantic matching and
    
[^6]: 答案候选类型选择：闭书问答中的文本到文本语言模型满足知识图谱

    Answer Candidate Type Selection: Text-to-Text Language Model for Closed Book Question Answering Meets Knowledge Graphs. (arXiv:2310.07008v1 [cs.CL])

    [http://arxiv.org/abs/2310.07008](http://arxiv.org/abs/2310.07008)

    本文提出了一种新颖的方法，通过对预训练的文本到文本问答系统生成的候选答案基于其类型进行过滤和重新排序，以解决在知识图谱问答任务中，模型容量有限且对于含有不太流行实体的问题质量下降的问题。

    

    预训练的文本到文本语言模型（如T5或BART）在知识图谱问答（KGQA）任务中取得了令人期待的结果。然而，模型的容量有限，对于包含不太流行实体的问题，质量下降。在本文中，我们提出了一种新颖的方法，该方法在预训练的文本到文本问答系统的基础上解决了这个问题。我们的简单而有效的方法根据候选答案的类型（来自Wikidata的"instance_of"属性）进行筛选和重新排序。

    Pre-trained Text-to-Text Language Models (LMs), such as T5 or BART yield promising results in the Knowledge Graph Question Answering (KGQA) task. However, the capacity of the models is limited and the quality decreases for questions with less popular entities. In this paper, we present a novel approach which works on top of the pre-trained Text-to-Text QA system to address this issue. Our simple yet effective method performs filtering and re-ranking of generated candidates based on their types derived from Wikidata "instance_of" property.
    
[^7]: 基于Transformer的神经文本表示技术在缺陷分配中的比较研究

    A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging. (arXiv:2310.06913v1 [cs.SE])

    [http://arxiv.org/abs/2310.06913](http://arxiv.org/abs/2310.06913)

    本文研究了基于Transformer的神经文本表示技术在缺陷分配中的应用，相比之前的方法，这些新技术能更好地捕捉微妙的文本模式，提高自动化缺陷分配的性能。

    

    在管理缺陷报告时，通常第一步是将缺陷分配给最适合理解、定位和修复目标缺陷的开发人员。此外，将给定的缺陷分配给软件项目的特定部分可以加快修复过程。然而，尽管这些活动的重要性，但在手动分配的过程中可能需要花费几天的时间。过去的研究尝试利用有限的文本数据训练文本分类模型来自动化这个过程，但得到的成功程度参差不齐。然而，先前工作中使用的文本表示和机器学习模型受到其表达能力的限制，往往无法捕捉到可以帮助缺陷分配过程的微妙文本模式。最近，基于Transformer的大型预训练神经文本表示技术（如BERT）在几个自然语言处理任务中取得了更好的性能。

    Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process -- to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-trained neural text representation techniques such as BERT have achieved greater performance in several natural language processing t
    
[^8]: MuseChat:一种视频对话音乐推荐系统

    MuseChat: A Conversational Music Recommendation System for Videos. (arXiv:2310.06282v1 [cs.LG])

    [http://arxiv.org/abs/2310.06282](http://arxiv.org/abs/2310.06282)

    MuseChat是一种创新的对话式音乐推荐系统，通过模拟用户和推荐系统之间的对话交互，利用预训练的音乐标签和艺术家信息，为用户提供定制的音乐推荐，使用户可以个性化选择他们喜欢的音乐。

    

    我们引入了MuseChat，一种创新的基于对话的音乐推荐系统。这个独特的平台不仅提供互动用户参与，还为输入的视频提供了定制的音乐推荐，使用户可以改进和个性化他们的音乐选择。与之相反，以前的系统主要强调内容的兼容性，往往忽视了用户个体偏好的细微差别。例如，所有的数据集都只提供基本的音乐-视频配对，或者带有音乐描述的配对。为了填补这一空白，我们的研究提供了三个贡献。首先，我们设计了一种对话合成方法，模拟了用户和推荐系统之间的两轮交互，利用预训练的音乐标签和艺术家信息。在这个交互中，用户提交一个视频给系统，系统会提供一个合适的音乐片段，并附带解释。之后，用户会表达他们对音乐的偏好，系统会呈现一个改进后的音乐推荐

    We introduce MuseChat, an innovative dialog-based music recommendation system. This unique platform not only offers interactive user engagement but also suggests music tailored for input videos, so that users can refine and personalize their music selections. In contrast, previous systems predominantly emphasized content compatibility, often overlooking the nuances of users' individual preferences. For example, all the datasets only provide basic music-video pairings or such pairings with textual music descriptions. To address this gap, our research offers three contributions. First, we devise a conversation-synthesis method that simulates a two-turn interaction between a user and a recommendation system, which leverages pre-trained music tags and artist information. In this interaction, users submit a video to the system, which then suggests a suitable music piece with a rationale. Afterwards, users communicate their musical preferences, and the system presents a refined music recomme
    
[^9]: DiscoverPath：用于生物医学研究的知识细化和检索系统

    DiscoverPath: A Knowledge Refinement and Retrieval System for Interdisciplinarity on Biomedical Research. (arXiv:2309.01808v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2309.01808](http://arxiv.org/abs/2309.01808)

    DiscoverPath是一个基于知识图的生物医学研究论文搜索引擎，通过命名实体识别和词性标注从文章摘要中提取术语和关系，并展示给用户一个关注查询实体及其邻近节点的子图，以及查询推荐系统，使用户能够循序渐进地细化查询。

    

    学术出版物的指数增长需要高级工具来实现高效的文章检索，尤其在跨学科领域中，不同的术语被用来描述相似的研究。传统的基于关键词的搜索引擎往往无法帮助那些对特定术语不熟悉的用户。为了解决这个问题，我们提出了一种基于知识图的生物医学研究论文搜索引擎，以增强用户在发现相关查询和文章方面的体验。该系统被称为DiscoverPath，采用命名实体识别（NER）和词性标注（POS）来从文章摘要中提取术语和关系，创建知识图谱。为了减少信息超载，DiscoverPath给用户展示了一个关注查询实体及其邻近节点的子图，并且还结合了查询推荐系统，使用户能够循序渐进地细化查询。该系统配备了一个易于访问的图形用户界面（GUI）。

    The exponential growth in scholarly publications necessitates advanced tools for efficient article retrieval, especially in interdisciplinary fields where diverse terminologies are used to describe similar research. Traditional keyword-based search engines often fall short in assisting users who may not be familiar with specific terminologies. To address this, we present a knowledge graph-based paper search engine for biomedical research to enhance the user experience in discovering relevant queries and articles. The system, dubbed DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS) tagging to extract terminologies and relationships from article abstracts to create a KG. To reduce information overload, DiscoverPath presents users with a focused subgraph containing the queried entity and its neighboring nodes and incorporates a query recommendation system, enabling users to iteratively refine their queries. The system is equipped with an accessible Graphical Us
    
[^10]: 为群体用户推荐商品的深度神经聚合

    Deep Neural Aggregation for Recommending Items to Group of Users. (arXiv:2307.09447v1 [cs.IR])

    [http://arxiv.org/abs/2307.09447](http://arxiv.org/abs/2307.09447)

    本文针对群体用户推荐商品的问题，提出了两种新的深度学习模型，并通过实验证明了这些模型相比现有模型的改进效果。

    

    现代社会花费了大量时间在数字交互上，我们的日常行为很多都通过数字手段完成。这导致了许多人工智能工具的出现，帮助我们在生活的各个方面进行辅助。对于数字社会来说，一个关键的工具是推荐系统，它是智能的系统，通过学习我们的过去行为，提出与我们兴趣相符的新行为建议。其中一些系统专门从用户群体的行为中学习，向希望共同完成某个任务的个体群体提出建议。在本文中，我们分析了群体推荐系统的现状，并提出了两种使用新兴的深度学习架构的模型。实验结果表明，与使用四个不同数据集的最新模型相比，采用我们提出的模型可以取得改进。该模型及所有实验的源代码都可供获取。

    Modern society devotes a significant amount of time to digital interaction. Many of our daily actions are carried out through digital means. This has led to the emergence of numerous Artificial Intelligence tools that assist us in various aspects of our lives. One key tool for the digital society is Recommender Systems, intelligent systems that learn from our past actions to propose new ones that align with our interests. Some of these systems have specialized in learning from the behavior of user groups to make recommendations to a group of individuals who want to perform a joint task. In this article, we analyze the current state of Group Recommender Systems and propose two new models that use emerging Deep Learning architectures. Experimental results demonstrate the improvement achieved by employing the proposed models compared to the state-of-the-art models using four different datasets. The source code of the models, as well as that of all the experiments conducted, is available i
    
[^11]: 编辑大型语言模型：问题、方法和机会

    Editing Large Language Models: Problems, Methods, and Opportunities. (arXiv:2305.13172v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13172](http://arxiv.org/abs/2305.13172)

    本文深入探讨了编辑大型语言模型的问题、方法和机会，提供了任务定义和挑战的概述、先进方法的实证分析，以及构建了新的基准数据集。这些结果有助于改进LLMs的编辑技术，提高其效果和可行性。

    

    尽管能够训练出表现优秀的大型语言模型（LLMs），但其保持相关性和纠正错误的方法仍然难以确定。为此，最近几年出现了许多编辑LLMs的技术，其目标是在特定领域内高效地改变LLMs的行为，同时不对其他输入的性能产生负面影响。本文深入探讨了与LLMs模型编辑相关的问题、方法和机会。特别是，我们提供了关于模型编辑任务定义和相关挑战的全面概述，以及对目前最先进的方法的深入实证分析。我们还构建了一个新的基准数据集，以促进更强大的评估，并指出现有技术固有的持久问题。我们的目标是为每种编辑技术的效果和可行性提供有价值的见解，从而帮助社区在LLMs的管理中取得更好的结果。

    Despite the ability to train capable LLMs, the methodology for maintaining their relevancy and rectifying errors remains elusive. To this end, the past few years have witnessed a surge in techniques for editing LLMs, the objective of which is to efficiently alter the behavior of LLMs within a specific domain without negatively impacting performance across other inputs. This paper embarks on a deep exploration of the problems, methods, and opportunities related to model editing for LLMs. In particular, we provide an exhaustive overview of the task definition and challenges associated with model editing, along with an in-depth empirical analysis of the most progressive methods currently at our disposal. We also build a new benchmark dataset to facilitate a more robust evaluation and pinpoint enduring issues intrinsic to existing techniques. Our objective is to provide valuable insights into the effectiveness and feasibility of each editing technique, thereby assisting the community in ma
    
[^12]: 预训练语言模型的知识反思

    Knowledge Rumination for Pre-trained Language Models. (arXiv:2305.08732v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08732](http://arxiv.org/abs/2305.08732)

    本文提出了一种名为知识反思的新范式，旨在帮助预训练语言模型利用已经编码在其预训练参数中的相关潜在知识，而不需要从外部语料库中检索。这种方法通过在模型中添加提示，并将相关知识注入模型进行整合，取得了在常识推理任务和GLUE基准上的实验结果。

    

    先前的研究揭示了普通的预训练语言模型（PLMs）单独处理知识密集型NLP任务的能力不足，因此，一些工作尝试将外部知识集成到PLMs中。然而，尽管有着有前途的结果，但我们经验性地观察到，PLM可能已经在其预训练参数中编码了丰富的知识，但在应用到知识密集型任务时未能充分利用它们。在本文中，我们提出了一种名为知识反思的新范式，以帮助预训练语言模型利用相关的潜在知识，而不需要从外部语料库中检索它们。通过简单地在PLMs中添加一个如“据我所知”的提示，我们试图回顾相关的潜在知识，并将其注入模型以进行知识整合。我们将提出的知识反思应用于各种语言模型，包括RoBERTa、DeBERTa和GPT-3。在六个常识推理任务和GLUE基准上的实验结果显示.....

    Previous studies have revealed that vanilla pre-trained language models (PLMs) lack the capacity to handle knowledge-intensive NLP tasks alone; thus, several works have attempted to integrate external knowledge into PLMs. However, despite the promising outcome, we empirically observe that PLMs may have already encoded rich knowledge in their pre-trained parameters but fail to fully utilize them when applying them to knowledge-intensive tasks. In this paper, we propose a new paradigm dubbed Knowledge Rumination to help the pre-trained language model utilize that related latent knowledge without retrieving it from the external corpus. By simply adding a prompt like "As far as I know" to the PLMs, we try to review related latent knowledge and inject them back into the model for knowledge consolidation. We apply the proposed knowledge rumination to various language models, including RoBERTa, DeBERTa, and GPT-3. Experimental results on six commonsense reasoning tasks and GLUE benchmarks dem
    
[^13]: 推荐系统中对比自监督学习综述

    Contrastive Self-supervised Learning in Recommender Systems: A Survey. (arXiv:2303.09902v1 [cs.IR])

    [http://arxiv.org/abs/2303.09902](http://arxiv.org/abs/2303.09902)

    本综述论文对基于对比自监督学习的推荐方法进行了综合评估和分类，并提供了统一的框架来概述这些方法。对比自监督学习方法由于灵活性和性能优良而吸引了大量关注，并成为了自监督学习推荐方法的主导分支。

    

    近年来，基于深度学习的推荐系统取得了显著的成功。但是，这些方法通常严重依赖于有标签的数据（即用户-物品交互），遭受着数据稀疏和冷启动等问题。自监督学习是一种新兴的范式，它从未标记的数据中提取信息，为解决这些问题提供了见解。具体来说，对比自监督学习由于其灵活性和良好的性能，已经吸引了相当多的关注，并最近成为基于自监督学习的推荐方法中的主导分支。在本调查中，我们提供了当前基于对比自监督学习的推荐方法的最新和全面的评估。首先，我们提出一个统一的框架来概述这些方法。然后，我们根据框架的关键组成部分，包括视图生成策略、对比任务和对比目标，提出了一个分类法。对于每个组成部分，

    Deep learning-based recommender systems have achieved remarkable success in recent years. However, these methods usually heavily rely on labeled data (i.e., user-item interactions), suffering from problems such as data sparsity and cold-start. Self-supervised learning, an emerging paradigm that extracts information from unlabeled data, provides insights into addressing these problems. Specifically, contrastive self-supervised learning, due to its flexibility and promising performance, has attracted considerable interest and recently become a dominant branch in self-supervised learning-based recommendation methods. In this survey, we provide an up-to-date and comprehensive review of current contrastive self-supervised learning-based recommendation methods. Firstly, we propose a unified framework for these methods. We then introduce a taxonomy based on the key components of the framework, including view generation strategy, contrastive task, and contrastive objective. For each component,
    
[^14]: Query2doc: 基于大型语言模型的查询扩展方法

    Query2doc: Query Expansion with Large Language Models. (arXiv:2303.07678v1 [cs.IR])

    [http://arxiv.org/abs/2303.07678](http://arxiv.org/abs/2303.07678)

    本论文提出了一种名为query2doc的查询扩展方法，使用大型语言模型生成伪文档来改善稀疏和密集检索系统，取得了在多个数据集上提高 BM25 性能的结果。

    

    本论文介绍了一种简单但有效的查询扩展方法，称为query2doc，可改善稀疏和密集检索系统。该方法首先利用小批量提示大型语言模型生成伪文档，然后使用生成的伪文档扩展查询。大型语言模型经过训练，能够记忆知识，从而生成的伪文档通常包含高度相关的信息，有助于查询消岐和指导检索器。实验结果表明，在不进行任何模型微调的情况下，query2doc 在 MS-MARCO 和 TREC DL 等 ad-hoc IR 数据集上将 BM25 的性能提高了 3% 到 15%。此外，我们的方法还在领域内和领域外的结果方面受益于最先进的密集检索器。

    This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.
    
[^15]: 基于场景和对象的图像-文本跨模态检索：一项可复现性研究

    Scene-centric vs. Object-centric Image-Text Cross-modal Retrieval: A Reproducibility Study. (arXiv:2301.05174v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2301.05174](http://arxiv.org/abs/2301.05174)

    这项研究关注基于场景和对象的图像-文本跨模态检索的可复现性，通过选择不同体系结构的最先进模型并在不同类型的数据集上进行评估，探讨了其在不同数据集类型上的泛化能力。

    

    大多数跨模态检索（CMR）方法要么聚焦于以对象为中心的数据集，即每个文档描绘或描述一个单一对象，要么聚焦于以场景为中心的数据集，即每个图像描绘或描述相互关联的多个对象和关系的复杂场景。我们认为一个强大的CMR模型应该在两种数据集类型上都具有良好的泛化能力。尽管CMR取得了一些进展，但结果的可复现性及其在不同数据集类型上的泛化性尚未被研究过。我们填补了这个空白，并关注当在以对象为中心和以场景为中心的数据集上评估时，最先进的CMR结果的可复现性。我们选择了两种具有不同体系结构的最先进CMR模型：（i）CLIP；以及（ii）X-VLM。此外，我们选择了两个以场景为中心的数据集和三个以对象为中心的数据集，并确定了所选模型在这些数据集上的相对性能。

    Most approaches to cross-modal retrieval (CMR) focus either on object-centric datasets, meaning that each document depicts or describes a single object, or on scene-centric datasets, meaning that each image depicts or describes a complex scene that involves multiple objects and relations between them. We posit that a robust CMR model should generalize well across both dataset types. Despite recent advances in CMR, the reproducibility of the results and their generalizability across different dataset types has not been studied before. We address this gap and focus on the reproducibility of the state-of-the-art CMR results when evaluated on object-centric and scene-centric datasets. We select two state-of-the-art CMR models with different architectures: (i) CLIP; and (ii) X-VLM. Additionally, we select two scene-centric datasets, and three object-centric datasets, and determine the relative performance of the selected models on these datasets. We focus on reproducibility, replicability, 
    
[^16]: 面向可靠的推荐评估的推荐物品采样研究

    Towards Reliable Item Sampling for Recommendation Evaluation. (arXiv:2211.15743v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.15743](http://arxiv.org/abs/2211.15743)

    本文研究面向推荐系统评估的可靠物品采样方法，提出了一种新的采样估计器，优化误差和理论精度。

    

    自从Rendle和Krichene认为常用的基于采样的评估方法与全局度量不一致后，已经有一些关于基于采样的推荐系统评估的研究。现有的方法要么将基于采样的度量映射到全局度量，要么更一般地学习经验排名分布来估计前K度量。但是，尽管存在许多努力，但仍然缺乏对所提出的度量估计器的严格理论理解，而基本的物品采样也面临“盲点”问题，即当K很小时，估计恢复前K度量的准确性仍然可以相当大。本文深入研究这些问题，并作出两项创新性贡献。首先，我们提出了一种新的物品采样估计器，显式地优化了与基础真实值的误差，并在理论上突显了其

    Since Rendle and Krichene argued that commonly used sampling-based evaluation metrics are "inconsistent" with respect to the global metrics (even in expectation), there have been a few studies on the sampling-based recommender system evaluation. Existing methods try either mapping the sampling-based metrics to their global counterparts or more generally, learning the empirical rank distribution to estimate the top-$K$ metrics. However, despite existing efforts, there is still a lack of rigorous theoretical understanding of the proposed metric estimators, and the basic item sampling also suffers from the "blind spot" issue, i.e., estimation accuracy to recover the top-$K$ metrics when $K$ is small can still be rather substantial. In this paper, we provide an in-depth investigation into these problems and make two innovative contributions. First, we propose a new item-sampling estimator that explicitly optimizes the error with respect to the ground truth, and theoretically highlight its 
    
[^17]: 一种基于局部约束图匹配的注重公正性的艺术展推荐系统

    An Equity-Aware Recommender System for Curating Art Exhibits Based on Locally-Constrained Graph Matching. (arXiv:2207.14367v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.14367](http://arxiv.org/abs/2207.14367)

    这个论文介绍了一种注重公正性的艺术展推荐系统，通过局部约束图匹配和价值导向的资源分配，实现公共艺术展览的策划。该系统采用Schelling模型构建成本矩阵，并通过优化评分函数，软分配艺术作品到公共空间，以减少内部群体偏好、满足最低代表性和曝光标准。

    

    公共艺术塑造了我们共享的空间。公共艺术应该与社区和背景相关，然而最近的研究表明，许多知名机构的艺术作品偏向于过时的文化规范和传统社群。鉴于此，我们开发了一种新颖的推荐系统，用于以内置公正目标和局部基于价值的有限资源分配来策划公共艺术展览。我们利用Schelling的种族分离模型构建了成本矩阵。使用成本矩阵作为输入，通过投影梯度下降优化得到了一个软分配矩阵的评分函数。我们的优化程序以一种方式将艺术作品分配给公共空间，以降低“内部群体”偏好，并满足最低代表性和曝光标准。我们借鉴现有的文献为算法输出开发了一个公正性指标，并评估了我们的方法的效果，并从策展和公正性的角度讨论其潜在问题。

    Public art shapes our shared spaces. Public art should speak to community and context, and yet, recent work has demonstrated numerous instances of art in prominent institutions favoring outdated cultural norms and legacy communities. Motivated by this, we develop a novel recommender system to curate public art exhibits with built-in equity objectives and a local value-based allocation of constrained resources. We develop a cost matrix by drawing on Schelling's model of segregation. Using the cost matrix as an input, the scoring function is optimized via a projected gradient descent to obtain a soft assignment matrix. Our optimization program allocates artwork to public spaces in a way that de-prioritizes "in-group" preferences, by satisfying minimum representation and exposure criteria. We draw on existing literature to develop a fairness metric for our algorithmic output, and we assess the effectiveness of our approach and discuss its potential pitfalls from both a curatorial and equi
    
[^18]: 通过Atten-Mixer网络高效利用多级用户意图进行基于会话的推荐

    Efficiently Leveraging Multi-level User Intent for Session-based Recommendation via Atten-Mixer Network. (arXiv:2206.12781v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2206.12781](http://arxiv.org/abs/2206.12781)

    本文针对基于会话的推荐任务，通过剖析经典的基于图神经网络的推荐模型，发现一些复杂的图神经网络传播部分是多余的。基于此观察，我们提出了Multi-Level Attention Mixture Network (Atten-Mixer)，它通过移除多余的传播部分，实现了对读出模块的更高效利用。

    

    基于会话的推荐旨在根据短暂且动态的会话预测用户的下一个动作。最近，在利用各种精心设计的图神经网络(GNN)捕捉物品之间的成对关系方面引起了越来越多的兴趣，似乎表明设计更复杂的模型是提高实证性能的万灵药。然而，这些模型在模型复杂度呈指数增长的同时，仅取得了相对较小的改进。在本文中，我们剖析了经典的基于GNN的SBR模型，并在经验上发现，一些复杂的GNN传播在给定读出模块在GNN模型中起到重要作用的情况下是多余的。基于这一观察，我们直观地提出了移除GNN传播部分的想法，而读出模块将在模型推理过程中承担更多责任。为此，我们提出了Multi-Level Attention Mixture Network (Atten-Mixer)，它同时利用概念-

    Session-based recommendation (SBR) aims to predict the user's next action based on short and dynamic sessions. Recently, there has been an increasing interest in utilizing various elaborately designed graph neural networks (GNNs) to capture the pair-wise relationships among items, seemingly suggesting the design of more complicated models is the panacea for improving the empirical performance. However, these models achieve relatively marginal improvements with exponential growth in model complexity. In this paper, we dissect the classical GNN-based SBR models and empirically find that some sophisticated GNN propagations are redundant, given the readout module plays a significant role in GNN-based models. Based on this observation, we intuitively propose to remove the GNN propagation part, while the readout module will take on more responsibility in the model reasoning process. To this end, we propose the Multi-Level Attention Mixture Network (Atten-Mixer), which leverages both concept-
    
[^19]: UNIQORN：统一的RDF知识图谱与自然语言文本问答系统

    UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v5 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2108.08614](http://arxiv.org/abs/2108.08614)

    本文提出了一个名为UNIQORN的问答系统，它能够无缝地处理RDF数据和文本，使用fine-tuned BERT模型为问题构建上下文图，并使用图算法确定与问题相关的子图来回答问题。

    

    问题回答在知识图谱和其他RDF数据上已经取得了巨大的进展，许多优秀的系统可以为自然语言问题或电报查询提供清晰的答案。其中一些系统将文本源作为附加证据纳入回答过程，但不能计算仅存在于文本中的答案。相反，IR和NLP社区的系统已经解决了有关文本的QA问题，但是这些系统几乎不利用语义数据和知识。本文提出了第一个可以无缝操作混合RDF数据集和文本语料库或单个来源的复杂问题的系统，在统一框架中进行操作。我们的方法称为UNIQORN，通过使用经过精细调整的BERT模型从RDF数据和/或文本语料库中检索与问题相关的证据来动态构建上下文图。结果图通常非常丰富但高度嘈杂。UNIQORN通过用于组Steiner树的图算法来处理这个输入，从而确定与问题相关的子图，进而回答问题。

    Question answering over knowledge graphs and other RDF data has been greatly advanced, with a number of good systems providing crisp answers for natural language questions or telegraphic queries. Some of these systems incorporate textual sources as additional evidence for the answering process, but cannot compute answers that are present in text alone. Conversely, systems from the IR and NLP communities have addressed QA over text, but such systems barely utilize semantic data and knowledge. This paper presents the first system for complex questions that can seamlessly operate over a mixture of RDF datasets and text corpora, or individual sources, in a unified framework. Our method, called UNIQORN, builds a context graph on-the-fly, by retrieving question-relevant evidences from the RDF data and/or a text corpus, using fine-tuned BERT models. The resulting graph is typically rich but highly noisy. UNIQORN copes with this input by a graph algorithm for Group Steiner Trees, that identifi
    

