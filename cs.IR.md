# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Video and Audio are Images: A Cross-Modal Mixer for Original Data on Video-Audio Retrieval.](http://arxiv.org/abs/2308.13820) | 本文提出了一个新的跨模态检索框架，通过跨模态混合器和掩模自编码器实现了原始数据的融合和分离，解决了跨模态检索中的语义关系建立和检索性能不佳的问题。 |
| [^2] | [Central Similarity Multi-View Hashing for Multimedia Retrieval.](http://arxiv.org/abs/2308.13774) | 本文提出一种新的中心相似性多视图哈希方法（CSMVH），针对多媒体检索中的局部相似性和多视图特征融合问题，利用中心相似性学习全局相似性并运用门控融合方法，取得了优越的性能。 |
| [^3] | [How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context.](http://arxiv.org/abs/2308.13760) | 本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。 |
| [^4] | [ZC3: Zero-Shot Cross-Language Code Clone Detection.](http://arxiv.org/abs/2308.13754) | 本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。 |
| [^5] | [LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring.](http://arxiv.org/abs/2308.13590) | 本研究提出了基于LSTM模型的情感分析和Net品牌声誉算法评估微服务的声誉分数的方法，并在一组与Amazon Web微服务相关的超过10,000条评论上进行了测试。 |
| [^6] | [Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4.](http://arxiv.org/abs/2308.13563) | 三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。 |
| [^7] | [Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset.](http://arxiv.org/abs/2308.13545) | 本研究提出了使用深度生成模型在孟加拉文本分类中进行特征提取的方法，并收集、注释了一个全面的数据集。评估结果表明，对抗自编码器模型产生了最佳的特征空间。 |
| [^8] | [Adversarial Collaborative Filtering for Free.](http://arxiv.org/abs/2308.13541) | 这篇论文介绍了一种面向免费的对抗性协同过滤方法，通过对抗性学习来规范用户/项目的表示，提高模型的泛化能力和鲁棒性，并提出了SharpCF方法来解决现有方法的缺点。 |
| [^9] | [A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System.](http://arxiv.org/abs/2308.13538) | 本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。 |
| [^10] | [STEM: Unleashing the Power of Embeddings for Multi-task Recommendation.](http://arxiv.org/abs/2308.13537) | 本文提出了一种称为STEM的新范例，用于解决多任务推荐中的负传递问题。与现有方法不同，STEM通过根据样本中正反馈数量的相对比例进行细分，深入研究样本的复杂性，以提高推荐系统的性能。 |
| [^11] | [Implicit ZCA Whitening Effects of Linear Autoencoders for Recommendation.](http://arxiv.org/abs/2308.13536) | 本文展示了线性自动编码器模型在推荐系统中隐式的ZCA白化作用，以及其对低维物品嵌入的有效性。 |
| [^12] | [MUSE: Music Recommender System with Shuffle Play Recommendation Enhancement.](http://arxiv.org/abs/2308.09649) | MUSE是一种音乐推荐系统，通过增强随机播放推荐实现了对音乐领域独特挑战的解决。它采用自监督学习框架和创新的会话增强方法，以提高推荐系统的整体训练效果。 |
| [^13] | [How Discriminative Are Your Qrels? How To Study the Statistical Significance of Document Adjudication Methods.](http://arxiv.org/abs/2308.09340) | 本论文提出了一种新方法，评估低成本裁决方法在保持完整集合中系统之间成对显著差异方面的能力。 |
| [^14] | [SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search.](http://arxiv.org/abs/2308.07711) | 本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。 |
| [^15] | [Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework.](http://arxiv.org/abs/2306.17426) | 该论文提出了一种因果标记框架，利用观看时间反馈进行短视频推荐。通过构建多个语义的标签，并使用分位数来提取观看时间的信息，使模型学习更加容易，同时减少偏见对推荐结果的影响。 |
| [^16] | [Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning.](http://arxiv.org/abs/2304.07920) | 本论文提出了一种基于因果决策Transformer和离线强化学习的推荐系统，通过探索用户行为的因果关系，指导代理捕捉动态兴趣，并解决了大规模情境下数据效率低的问题。 |
| [^17] | [Analyzing and visualizing polarization and balance with signed networks: the U.S. Congress case study.](http://arxiv.org/abs/2209.00676) | 该论文提出了一种在美国国会案例研究中分析和可视化符号网络极化和平衡的方法。该方法基于拉普拉斯矩阵的谱特性，具有计算成本低、对任意小的子图进行数量化和视觉评估等优点。 |

# 详细

[^1]: 视频和音频是图像：用于视频音频检索原始数据的跨模态混合器

    Video and Audio are Images: A Cross-Modal Mixer for Original Data on Video-Audio Retrieval. (arXiv:2308.13820v1 [cs.IR])

    [http://arxiv.org/abs/2308.13820](http://arxiv.org/abs/2308.13820)

    本文提出了一个新的跨模态检索框架，通过跨模态混合器和掩模自编码器实现了原始数据的融合和分离，解决了跨模态检索中的语义关系建立和检索性能不佳的问题。

    

    跨模态检索在近年来变得流行，尤其是随着多媒体的兴起。通常，每个模态的信息展现出不同的表示和语义信息，这使得特征往往处于编码为双塔结构的分离潜空间中，并且难以建立模态之间的语义关系，导致检索性能差。为了解决这个问题，我们提出了一个新的跨模态检索框架，包括一个跨模态混合器、一个用于预训练的掩模自编码器和一个用于下游任务的跨模态检索器。具体来说，我们首先采用跨模态混合器和掩模建模来融合原始模态并消除冗余。然后，在预训练阶段应用编码器-解码器架构来实现融合后分离的任务。我们将掩模融合表示馈送到编码器中，并用解码器进行重构，最终分离出两个模态的原始数据。

    Cross-modal retrieval has become popular in recent years, particularly with the rise of multimedia. Generally, the information from each modality exhibits distinct representations and semantic information, which makes feature tends to be in separate latent spaces encoded with dual-tower architecture and makes it difficult to establish semantic relationships between modalities, resulting in poor retrieval performance. To address this issue, we propose a novel framework for cross-modal retrieval which consists of a cross-modal mixer, a masked autoencoder for pre-training, and a cross-modal retriever for downstream tasks.In specific, we first adopt cross-modal mixer and mask modeling to fuse the original modality and eliminate redundancy. Then, an encoder-decoder architecture is applied to achieve a fuse-then-separate task in the pre-training phase.We feed masked fused representations into the encoder and reconstruct them with the decoder, ultimately separating the original data of two mo
    
[^2]: 多媒体检索的中心相似性多视图哈希方法

    Central Similarity Multi-View Hashing for Multimedia Retrieval. (arXiv:2308.13774v1 [cs.CV])

    [http://arxiv.org/abs/2308.13774](http://arxiv.org/abs/2308.13774)

    本文提出一种新的中心相似性多视图哈希方法（CSMVH），针对多媒体检索中的局部相似性和多视图特征融合问题，利用中心相似性学习全局相似性并运用门控融合方法，取得了优越的性能。

    

    多视图异构数据的哈希表示学习是提高多媒体检索准确性的关键。然而，现有方法仅利用局部相似性，未能深度融合多视图特征，导致检索准确性较低。现有方法只使用局部相似性来训练模型，忽视了全局相似性。此外，最近的工作大多通过加权和或串联来融合多视图特征。我们认为这些融合方法不足以捕捉各种视图之间的交互。我们提出了一种新颖的中心相似性多视图哈希方法（CSMVH）来解决上述问题。中心相似性学习用于解决局部相似性问题，可以利用哈希中心与样本之间的全局相似性。我们提供了丰富的实验证据，证明基于门控融合方法优于传统方法。在MS COCO和NUS-WIDE数据集上，我们的CSMVH方法取得了优越的性能。

    Hash representation learning of multi-view heterogeneous data is the key to improving the accuracy of multimedia retrieval. However, existing methods utilize local similarity and fall short of deeply fusing the multi-view features, resulting in poor retrieval accuracy. Current methods only use local similarity to train their model. These methods ignore global similarity. Furthermore, most recent works fuse the multi-view features via a weighted sum or concatenation. We contend that these fusion methods are insufficient for capturing the interaction between various views. We present a novel Central Similarity Multi-View Hashing (CSMVH) method to address the mentioned problems. Central similarity learning is used for solving the local similarity problem, which can utilize the global similarity between the hash center and samples. We present copious empirical data demonstrating the superiority of gate-based fusion over conventional approaches. On the MS COCO and NUS-WIDE, the proposed CSM
    
[^3]: 如何利用上下文帮助？探索段落和个性化上下文的联合检索

    How Can Context Help? Exploring Joint Retrieval of Passage and Personalized Context. (arXiv:2308.13760v1 [cs.AI])

    [http://arxiv.org/abs/2308.13760](http://arxiv.org/abs/2308.13760)

    本文探索了如何将个性化上下文信息与文档对话系统结合，提出了个性化上下文感知的段落检索任务，并引入了一种有效利用上下文信息的新颖方法PCAS。通过实验证明，PCAS不仅在检索最相关的段落方面优于基准系统，而且在确定相关上下文方面也表现出色。这将激发未来研究的兴趣。

    

    将外部个性化上下文信息整合到以文档为基础的对话系统中具有重要的商业价值，但这方面的研究还不够深入。受个性化上下文感知文档对话系统的概念启发，我们引入了上下文感知的段落检索任务，并构建了一个专门为此目的策划的数据集。我们描述了多个基准系统来解决这个任务，并提出了一种新颖的方法，即个性化上下文感知搜索(Personalized Context-Aware Search，PCAS)，它在段落检索过程中有效地利用上下文信息。在多个流行的稠密检索系统上进行的实验评估表明，我们的方法不仅在检索最相关的段落方面优于基准系统，而且在确定所有可用上下文中的相关上下文方面也表现出色。我们预计我们的贡献将成为激励未来研究的催化剂。

    The integration of external personalized context information into document-grounded conversational systems has significant potential business value, but has not been well-studied. Motivated by the concept of personalized context-aware document-grounded conversational systems, we introduce the task of context-aware passage retrieval. We also construct a dataset specifically curated for this purpose. We describe multiple baseline systems to address this task, and propose a novel approach, Personalized Context-Aware Search (PCAS), that effectively harnesses contextual information during passage retrieval. Experimental evaluations conducted on multiple popular dense retrieval systems demonstrate that our proposed approach not only outperforms the baselines in retrieving the most relevant passage but also excels at identifying the pertinent context among all the available contexts. We envision that our contributions will serve as a catalyst for inspiring future research endeavors in this pr
    
[^4]: ZC3: 跨语言零样本代码克隆检测

    ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v1 [cs.SE])

    [http://arxiv.org/abs/2308.13754](http://arxiv.org/abs/2308.13754)

    本文提出了一种名为ZC3的跨语言零样本代码克隆检测方法。该方法设计了对比代码片段预测，形成不同编程语言之间的同构表示空间，并利用领域感知学习和循环一致性学习来进一步约束模型。

    

    开发人员引入代码克隆以提高编程效率。许多现有研究在单语言代码克隆检测方面取得了令人瞩目的成果。然而，在软件开发过程中，越来越多的开发人员使用不同的语言编写语义上等价的程序，以支持不同的平台，并帮助开发人员从一种语言翻译项目到另一种语言。考虑到收集跨语言并行数据（尤其是低资源语言）的成本高昂且耗时，设计一种不依赖任何并行数据的有效跨语言模型是一个重要问题。本文提出了一种名为ZC3的新方法，用于零样本跨语言代码克隆检测。ZC3通过设计对比代码片段预测来形成不同编程语言之间的同构表示空间。基于此，ZC3利用领域感知学习和循环一致性学习进一步约束模型以生成表达。

    Developers introduce code clones to improve programming productivity. Many existing studies have achieved impressive performance in monolingual code clone detection. However, during software development, more and more developers write semantically equivalent programs with different languages to support different platforms and help developers translate projects from one language to another. Considering that collecting cross-language parallel data, especially for low-resource languages, is expensive and time-consuming, how designing an effective cross-language model that does not rely on any parallel data is a significant problem. In this paper, we propose a novel method named ZC3 for Zero-shot Cross-language Code Clone detection. ZC3 designs the contrastive snippet prediction to form an isomorphic representation space among different programming languages. Based on this, ZC3 exploits domain-aware learning and cycle consistency learning to further constrain the model to generate represen
    
[^5]: 基于LSTM的Web微服务口碑评分的QoE评估

    LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring. (arXiv:2308.13590v1 [cs.IR])

    [http://arxiv.org/abs/2308.13590](http://arxiv.org/abs/2308.13590)

    本研究提出了基于LSTM模型的情感分析和Net品牌声誉算法评估微服务的声誉分数的方法，并在一组与Amazon Web微服务相关的超过10,000条评论上进行了测试。

    

    情感分析是挖掘作者对特定实体的意见的任务。它允许组织实时监控不同的服务并采取相应的行动。声誉是人们或事物通常说到或相信的东西。非正式地说，声誉综合了从用户那里得到的反馈、评论和评级所反映的可靠度度量，这些反映了他们的体验质量(QoE)，可能会增加或损害所提供服务的声誉。在这项研究中，我们提出对Web微服务评价指标的情感分析，以利用提供的信息来评估和评分微服务的声誉。我们提出的方法使用了长短期记忆(LSTM)模型进行情感分析，并使用网络品牌声誉(NBR)算法评估微服务的声誉分数。该方法在与15个Amazon Web微服务相关的10000多条评论的数据集上进行了测试，实验结果表明

    Sentiment analysis is the task of mining the authors' opinions about specific entities. It allows organizations to monitor different services in real time and act accordingly. Reputation is what is generally said or believed about people or things. Informally, reputation combines the measure of reliability derived from feedback, reviews, and ratings gathered from users, which reflect their quality of experience (QoE) and can either increase or harm the reputation of the provided services. In this study, we propose to perform sentiment analysis on web microservices reviews to exploit the provided information to assess and score the microservices' reputation. Our proposed approach uses the Long Short-Term Memory (LSTM) model to perform sentiment analysis and the Net Brand Reputation (NBR) algorithm to assess reputation scores for microservices. This approach is tested on a set of more than 10,000 reviews related to 15 Amazon Web microservices, and the experimental results have shown that
    
[^6]: 大型语言模型在分析事故叙述中的应用——ChatGPT、BARD和GPT-4的比较研究

    Large Language Models in Analyzing Crash Narratives -- A Comparative Study of ChatGPT, BARD and GPT-4. (arXiv:2308.13563v1 [cs.CL])

    [http://arxiv.org/abs/2308.13563](http://arxiv.org/abs/2308.13563)

    三个大型语言模型接口(ChatGPT, BARD和GPT4)在分析事故叙述中的效果进行了比较研究。研究结果表明，它们在提取事故相关信息和回答相关问题方面都具有一定的有效性，但也存在一些限制。

    

    在交通安全研究中，使用文本分析从事故叙述中提取信息是一种常见的做法。随着大型语言模型（LLM）的最新进展，了解流行的LLM接口在分类或从事故叙述中提取信息方面的表现将非常有用。为了探索这一问题，我们的研究使用了目前最流行的三个公开可用的LLM接口——ChatGPT、BARD和GPT4。本研究调查了它们在提取信息和回答与事故有关的查询方面的有效性和限制。研究从爱荷华州和堪萨斯州的100个事故叙述中提取信息，并对它们的能力和限制进行了评估，比较了它们对查询的响应。五个与叙述相关的问题被提出：1）谁是责任方？2）碰撞方式是什么？3）事故发生在工作区吗？4）事故涉及行人吗？5）事故中有害事件的顺序是什么？对于第1到第4个问题，三个LLM接口的回答都经过了比较。

    In traffic safety research, extracting information from crash narratives using text analysis is a common practice. With recent advancements of large language models (LLM), it would be useful to know how the popular LLM interfaces perform in classifying or extracting information from crash narratives. To explore this, our study has used the three most popular publicly available LLM interfaces- ChatGPT, BARD and GPT4. This study investigated their usefulness and boundaries in extracting information and answering queries related to accidents from 100 crash narratives from Iowa and Kansas. During the investigation, their capabilities and limitations were assessed and their responses to the queries were compared. Five questions were asked related to the narratives: 1) Who is at-fault? 2) What is the manner of collision? 3) Has the crash occurred in a work-zone? 4) Did the crash involve pedestrians? and 5) What are the sequence of harmful events in the crash? For questions 1 through 4, the o
    
[^7]: 使用深度生成模型进行孟加拉文本分类的特征提取（arXiv:2308.13545v1 [cs.IR]）

    Feature Extraction Using Deep Generative Models for Bangla Text Classification on a New Comprehensive Dataset. (arXiv:2308.13545v1 [cs.IR])

    [http://arxiv.org/abs/2308.13545](http://arxiv.org/abs/2308.13545)

    本研究提出了使用深度生成模型在孟加拉文本分类中进行特征提取的方法，并收集、注释了一个全面的数据集。评估结果表明，对抗自编码器模型产生了最佳的特征空间。

    

    文本分类中的特征选择是文本挖掘和信息检索中的基础任务。尽管孟加拉语是世界上使用最广泛的第六大语言，但由于文本数据集的稀缺性，它一直受到较少关注。在本研究中，我们收集、注释和准备了一个包含212,184个孟加拉文档的全面数据集，涵盖了七个不同的类别，并将其公开。我们实现了三个深度学习生成模型：LSTM变分自编码器（LSTM VAE）、辅助分类器生成对抗网络（AC-GAN）和对抗自编码器（AAE）来提取文本特征，尽管它们的应用最初是在计算机视觉领域发现的。我们利用我们的数据集训练了这三个模型，并在文档分类任务中使用了得到的特征空间。我们评估了分类器的性能，并发现对抗自编码器模型产生了最佳的特征空间。

    The selection of features for text classification is a fundamental task in text mining and information retrieval. Despite being the sixth most widely spoken language in the world, Bangla has received little attention due to the scarcity of text datasets. In this research, we collected, annotated, and prepared a comprehensive dataset of 212,184 Bangla documents in seven different categories and made it publicly accessible. We implemented three deep learning generative models: LSTM variational autoencoder (LSTM VAE), auxiliary classifier generative adversarial network (AC-GAN), and adversarial autoencoder (AAE) to extract text features, although their applications are initially found in the field of computer vision. We utilized our dataset to train these three models and used the feature space obtained in the document classification task. We evaluated the performance of the classifiers and found that the adversarial autoencoder model produced the best feature space.
    
[^8]: 面向免费的对抗性协同过滤

    Adversarial Collaborative Filtering for Free. (arXiv:2308.13541v1 [cs.IR])

    [http://arxiv.org/abs/2308.13541](http://arxiv.org/abs/2308.13541)

    这篇论文介绍了一种面向免费的对抗性协同过滤方法，通过对抗性学习来规范用户/项目的表示，提高模型的泛化能力和鲁棒性，并提出了SharpCF方法来解决现有方法的缺点。

    

    协同过滤（CF）已成功用于帮助用户发现感兴趣的项目。然而，现有的CF方法存在噪声数据问题，这对推荐的质量产生负面影响。为了解决这个问题，许多先前的研究利用对抗性学习来规范用户/项目的表示，从而提高泛化能力和鲁棒性。这些方法通常在最小最大优化框架下学习对抗扰动和模型参数。然而，目前存在两个主要缺点：1）现有方法缺乏理论保证，无法解释为什么添加扰动可以提高模型的泛化能力和鲁棒性；2）解决最小最大优化问题需要耗时。除了更新模型参数，每次迭代还需要额外计算来更新扰动，使它们不适用于规模大的工业数据集。本文提出了一种新的Sharpness-aware Collaborative Filtering（SharpCF）方法，它简单而有效。

    Collaborative Filtering (CF) has been successfully used to help users discover the items of interest. Nevertheless, existing CF methods suffer from noisy data issue, which negatively impacts the quality of recommendation. To tackle this problem, many prior studies leverage adversarial learning to regularize the representations of users/items, which improves both generalizability and robustness. Those methods often learn adversarial perturbations and model parameters under min-max optimization framework. However, there still have two major drawbacks: 1) Existing methods lack theoretical guarantees of why adding perturbations improve the model generalizability and robustness; 2) Solving min-max optimization is time-consuming. In addition to updating the model parameters, each iteration requires additional computations to update the perturbations, making them not scalable for industry-scale datasets.  In this paper, we present Sharpness-aware Collaborative Filtering (SharpCF), a simple ye
    
[^9]: 一个概念游戏特征生成与推荐系统的初步研究

    A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. (arXiv:2308.13538v1 [cs.IR])

    [http://arxiv.org/abs/2308.13538](http://arxiv.org/abs/2308.13538)

    本研究介绍了一个用于生成游戏特征建议的系统，通过使用文本提示，提取主题相似的游戏特征并生成新特征。经过用户研究比较，该系统的生成模型在某些游戏中的表现超过了人工建议。该系统是一个与用户在概念层面上进行协作的游戏设计助手工具的一部分。

    

    本文介绍了一个基于文本提示生成游戏特征建议的系统。该系统通过使用一个小型的GLoVe模型的词嵌入来提取主题相似的游戏中的特征和实体，并将其通过一个生成模型传递，用于生成用户提示的新特征。我们进行了一项短期用户研究，比较了来自一个经过微调的GPT-2模型、使用ConceptNet的模型以及人工编写的游戏特征生成的特征。虽然人工建议获得了绝大多数的投票，但在某些游戏中，GPT-2模型的表现超过了人工建议。该系统是一个更大的游戏设计助手工具的一部分，能够在概念层面上与用户进行协作。

    This paper introduces a system used to generate game feature suggestions based on a text prompt. Trained on the game descriptions of almost 60k games, it uses the word embeddings of a small GLoVe model to extract features and entities found in thematically similar games which are then passed through a generator model to generate new features for a user's prompt. We perform a short user study comparing the features generated from a fine-tuned GPT-2 model, a model using the ConceptNet, and human-authored game features. Although human suggestions won the overall majority of votes, the GPT-2 model outperformed the human suggestions in certain games. This system is part of a larger game design assistant tool that is able to collaborate with users at a conceptual level.
    
[^10]: STEM:释放Embedding在多任务推荐中的力量

    STEM: Unleashing the Power of Embeddings for Multi-task Recommendation. (arXiv:2308.13537v1 [cs.IR])

    [http://arxiv.org/abs/2308.13537](http://arxiv.org/abs/2308.13537)

    本文提出了一种称为STEM的新范例，用于解决多任务推荐中的负传递问题。与现有方法不同，STEM通过根据样本中正反馈数量的相对比例进行细分，深入研究样本的复杂性，以提高推荐系统的性能。

    

    多任务学习（MTL）在推荐系统中变得越来越受欢迎，因为它能够同时优化多个目标。MTL的一个关键挑战是负传递的发生，即由于任务之间的冲突导致某些任务的性能下降。现有研究通过将所有样本视为一个整体来探索负传递，忽视了其中固有的复杂性。为此，我们根据任务之间正反馈的相对数量将样本进行细分，深入研究样本的复杂性。令人惊讶的是，现有MTL方法在收到各任务类似反馈的样本上仍然存在负传递。值得注意的是，现有方法通常采用共享嵌入的范例，并且我们假设它们的失败可以归因于使用这种通用嵌入来建模不同用户偏好的有限能力。

    Multi-task learning (MTL) has gained significant popularity in recommendation systems as it enables the simultaneous optimization of multiple objectives. A key challenge in MTL is the occurrence of negative transfer, where the performance of certain tasks deteriorates due to conflicts between tasks. Existing research has explored negative transfer by treating all samples as a whole, overlooking the inherent complexities within them. To this end, we delve into the intricacies of samples by splitting them based on the relative amount of positive feedback among tasks. Surprisingly, negative transfer still occurs in existing MTL methods on samples that receive comparable feedback across tasks. It is worth noting that existing methods commonly employ a shared-embedding paradigm, and we hypothesize that their failure can be attributed to the limited capacity of modeling diverse user preferences across tasks using such universal embeddings.  In this paper, we introduce a novel paradigm called
    
[^11]: 线性自动编码器对推荐系统中的隐式ZCA白化的影响

    Implicit ZCA Whitening Effects of Linear Autoencoders for Recommendation. (arXiv:2308.13536v1 [cs.IR])

    [http://arxiv.org/abs/2308.13536](http://arxiv.org/abs/2308.13536)

    本文展示了线性自动编码器模型在推荐系统中隐式的ZCA白化作用，以及其对低维物品嵌入的有效性。

    

    近年来，在推荐系统领域，线性回归（自动编码器）模型被研究作为学习物品相似性的一种方法。本文展示了线性自动编码器模型与推荐数据的ZCA白化之间的联系。特别地，我们展示了线性自动编码器模型的对偶形式解在物品的特征向量上实际上具有ZCA白化效果，而在自动编码器/回归模型的原始问题中，物品被视为输入特征。我们还展示了将线性自动编码器应用于使用Item2vec等嵌入方法获得的低维物品向量来估计物品之间相似性的正确性。我们的实验提供了初步结果，表明白化低维物品嵌入是有效的。

    Recently, in the field of recommendation systems, linear regression (autoencoder) models have been investigated as a way to learn item similarity. In this paper, we show a connection between a linear autoencoder model and ZCA whitening for recommendation data. In particular, we show that the dual form solution of a linear autoencoder model actually has ZCA whitening effects on feature vectors of items, while items are considered as input features in the primal problem of the autoencoder/regression model. We also show the correctness of applying a linear autoencoder to low-dimensional item vectors obtained using embedding methods such as Item2vec to estimate item-item similarities. Our experiments provide preliminary results indicating the effectiveness of whitening low-dimensional item embeddings.
    
[^12]: MUSE: 在随机播放推荐增强方面的音乐推荐系统

    MUSE: Music Recommender System with Shuffle Play Recommendation Enhancement. (arXiv:2308.09649v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.09649](http://arxiv.org/abs/2308.09649)

    MUSE是一种音乐推荐系统，通过增强随机播放推荐实现了对音乐领域独特挑战的解决。它采用自监督学习框架和创新的会话增强方法，以提高推荐系统的整体训练效果。

    

    推荐系统已成为音乐流媒体服务中不可或缺的部分，通过个性化播放列表和促进偶然发现新音乐来提升用户体验。然而，现有的推荐系统忽视了音乐领域固有的独特挑战，特别是随机播放会以随机序列提供连续的曲目。基于我们的观察，随机播放会话主要由于高独特转换率阻碍了音乐推荐系统的整体训练过程，我们提出了一种名为MUSE的音乐推荐系统，该系统增强了随机播放推荐。 MUSE采用自监督学习框架，通过增加曲目的转换来最大化原始播放会话与增强会话之间的一致性，这种增强通过我们的新颖会话增强方法（称为基于转换的增强）来实现。为了进一步促进两个视图之间的表示对齐，我们设计了两种细粒度机制。

    Recommender systems have become indispensable in music streaming services, enhancing user experiences by personalizing playlists and facilitating the serendipitous discovery of new music. However, the existing recommender systems overlook the unique challenges inherent in the music domain, specifically shuffle play, which provides subsequent tracks in a random sequence. Based on our observation that the shuffle play sessions hinder the overall training process of music recommender systems mainly due to the high unique transition rates of shuffle play sessions, we propose a Music Recommender System with Shuffle Play Recommendation Enhancement (MUSE). MUSE employs the self-supervised learning framework that maximizes the agreement between the original session and the augmented session, which is augmented by our novel session augmentation method, called transition-based augmentation. To further facilitate the alignment of the representations between the two views, we devise two fine-grain
    
[^13]: 你的Qrels有多具有区分性？如何研究文档裁决方法的统计学显著性

    How Discriminative Are Your Qrels? How To Study the Statistical Significance of Document Adjudication Methods. (arXiv:2308.09340v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.09340](http://arxiv.org/abs/2308.09340)

    本论文提出了一种新方法，评估低成本裁决方法在保持完整集合中系统之间成对显著差异方面的能力。

    

    创建离线检索评估的测试集需要人工判断文档的相关性。在减少评估成本方面，裁决方法积极决定专家审查文档的顺序，以更好地利用评估预算或降低其成本。研究人员通过测量完整集合下已知系统的金标排名与低成本集合下系统的观察排名之间的相关性来评估这些方法的质量。这种传统分析忽略了低成本裁决对于完整集合中系统之间的统计显著差异是否以及如何影响。我们通过提出一种新方法来评估低成本裁决方法在保持完整集合中系统之间成对显著差异方面的能力来填补这一空白。

    Creating test collections for offline retrieval evaluation requires human effort to judge documents' relevance. This expensive activity motivated much work in developing methods for constructing benchmarks with fewer assessment costs. In this respect, adjudication methods actively decide both which documents and the order in which experts review them, in order to better exploit the assessment budget or to lower it. Researchers evaluate the quality of those methods by measuring the correlation between the known gold ranking of systems under the full collection and the observed ranking of systems under the lower-cost one. This traditional analysis ignores whether and how the low-cost judgements impact on the statistically significant differences among systems with respect to the full collection. We fill this void by proposing a novel methodology to evaluate how the low-cost adjudication methods preserve the pairwise significant differences between systems as the full collection. In other
    
[^14]: SPM: Meituan搜索中用于相关性建模的结构化预训练和匹配架构

    SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])

    [http://arxiv.org/abs/2308.07711](http://arxiv.org/abs/2308.07711)

    本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。

    

    在电商搜索中，查询和文档之间的相关性是满足用户体验的基本要求。与传统的电商平台不同，用户在美团等生活服务平台上进行搜索主要是为了产品供应商，这些供应商通常拥有丰富的结构化信息，例如名称、地址、类别、成千上万的产品。使用这些丰富的结构化内容进行搜索相关性建模具有挑战性，主要存在以下问题：（1）不同字段的结构化文档存在语言分布差异，无法直接采用预训练的语言模型方法（如BERT）。（2）不同字段通常具有不同的重要性，且长度差异很大，很难提取对相关性匹配有帮助的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配架构，用于丰富结构的相关性匹配。

    In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
    
[^15]: 利用观看时间反馈进行短视频推荐：一种因果标记框架

    Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework. (arXiv:2306.17426v1 [cs.IR])

    [http://arxiv.org/abs/2306.17426](http://arxiv.org/abs/2306.17426)

    该论文提出了一种因果标记框架，利用观看时间反馈进行短视频推荐。通过构建多个语义的标签，并使用分位数来提取观看时间的信息，使模型学习更加容易，同时减少偏见对推荐结果的影响。

    

    随着短视频应用的普及，短视频推荐的重要性大大增加。与其他推荐场景不同，短视频推荐系统大量依赖于观看时间的反馈。现有方法简单地将观看时间视为直接标签，未能充分利用其广泛的语义并引入偏见，从而限制了基于观看时间建模用户兴趣的潜力。为了克服这一挑战，我们提出了一个名为去偏多语义提取标记（DML）的框架。DML利用观看时间分布得出的分位数构建包含各种语义的标签，优先考虑相对顺序而不是绝对标签值。这种方法便于模型学习，同时符合推荐的排序目标。此外，我们引入了受因果调整启发的方法来优化标签定义，从而减少偏见对推荐结果的影响。

    With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiasied Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby reducing the impact of bias on th
    
[^16]: 通过离线强化学习实现因果决策Transformer的推荐系统

    Causal Decision Transformer for Recommender Systems via Offline Reinforcement Learning. (arXiv:2304.07920v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2304.07920](http://arxiv.org/abs/2304.07920)

    本论文提出了一种基于因果决策Transformer和离线强化学习的推荐系统，通过探索用户行为的因果关系，指导代理捕捉动态兴趣，并解决了大规模情境下数据效率低的问题。

    

    最近，基于强化学习的推荐系统已经变得越来越流行。然而，优化推荐策略的奖励函数的设计往往并不简单。探索用户行为背后的因果关系可以替代奖励函数，指导代理捕捉用户的动态兴趣。此外，由于仿真环境的典型限制（如数据效率），大部分研究无法广泛应用于大规模情境。尽管一些研究尝试将离线数据集转化为仿真器，但数据效率使学习过程变得更加缓慢。由于强化学习的本质是通过相互作用进行学习，它无法在单次交互过程中收集足够的数据进行训练。此外，传统的强化学习算法不像监督学习方法那样具备直接从离线数据集进行学习的牢固能力。

    Reinforcement learning-based recommender systems have recently gained popularity. However, the design of the reward function, on which the agent relies to optimize its recommendation policy, is often not straightforward. Exploring the causality underlying users' behavior can take the place of the reward function in guiding the agent to capture the dynamic interests of users. Moreover, due to the typical limitations of simulation environments (e.g., data inefficiency), most of the work cannot be broadly applied in large-scale situations. Although some works attempt to convert the offline dataset into a simulator, data inefficiency makes the learning process even slower. Because of the nature of reinforcement learning (i.e., learning by interaction), it cannot collect enough data to train during a single interaction. Furthermore, traditional reinforcement learning algorithms do not have a solid capability like supervised learning methods to learn from offline datasets directly. In this p
    
[^17]: 分析和可视化具有符号网络的极化和平衡：美国国会案例研究

    Analyzing and visualizing polarization and balance with signed networks: the U.S. Congress case study. (arXiv:2209.00676v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2209.00676](http://arxiv.org/abs/2209.00676)

    该论文提出了一种在美国国会案例研究中分析和可视化符号网络极化和平衡的方法。该方法基于拉普拉斯矩阵的谱特性，具有计算成本低、对任意小的子图进行数量化和视觉评估等优点。

    

    符号网络和平衡理论为展示极化动态、正负关系和政治党派之间提供了一个自然的环境。例如，它们已被证明有效地研究了美国国会两个议院投票的日益极化，从二战以来。为了对这个特定案例研究提供更深入的洞察，我们提出了一个流水线的应用，用于分析和可视化符号图的配置，基于对应的拉普拉斯矩阵的谱特性的利用。整体方法与基于挫败指数的其他方法相当，但至少有两个主要优点：首先，它需要更低的计算成本；其次，它允许对任意小的子图（甚至单个节点）对网络的整体平衡（或不平衡）产生数量化和视觉评估。所提出的流水线允许对极化进行探索。

    Signed networks and balance theory provide a natural setting for real-world scenarios that show polarization dynamics, positive/negative relationships, and political partisanship. For example, they have been proven effective in studying the increasing polarization of the votes in the two chambers of the U.S. Congress from World War II on.  To provide further insights into this particular case study, we propose the application of a pipeline to analyze and visualize a signed graph's configuration based on the exploitation of the corresponding Laplacian matrix' spectral properties. The overall methodology is comparable with others based on the frustration index, but it has at least two main advantages: first, it requires a much lower computational cost; second, it allows for a quantitative and visual assessment of how arbitrarily small subgraphs (even single nodes) contribute to the overall balance (or unbalance) of the network.  The proposed pipeline allows the exploration of polarizatio
    

