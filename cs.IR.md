# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unlocking Insights: Semantic Search in Jupyter Notebooks](https://arxiv.org/abs/2402.13234) | 本文探讨了在Jupyter笔记本中应用大型语言模型增强语义搜索能力的方法，展示了一个全面理解整个笔记本内容语义的搜索框架。 |
| [^2] | [Mode Estimation with Partial Feedback](https://arxiv.org/abs/2402.13079) | 本文提出了一种在模态估计中利用部分反馈的方法，通过熵编码实现最优信息获取，开发了粗糙的充分统计用于模态识别，并将赌博算法调整为新设置，最终提出了一个高效的问题解决方案 |
| [^3] | [Enhancing Real-World Complex Network Representations with Hyperedge Augmentation](https://arxiv.org/abs/2402.13033) | 提出了一种新颖的图增强方法Hyperedge Augmentation (HyperAug)，通过构建直接从原始数据形成的虚拟超边，以解决现实世界复杂网络表示中高阶节点关系的问题 |
| [^4] | [Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism](https://arxiv.org/abs/2402.12997) | 提出了一种适用于现实约束的轻量级弃权机制，特别适用于再排序阶段，通过数据驱动的方法达到有效性，并提供了开源代码以促进其更广泛的应用。 |
| [^5] | [Distributionally Robust Graph-based Recommendation System](https://arxiv.org/abs/2402.12994) | 提出了一种基于分布鲁棒性的图神经推荐系统（DR-GNN），通过将分布鲁棒性优化（DRO）融入到基于GNN的推荐中，解决训练和测试数据分布不同造成的效果下降问题 |
| [^6] | [An Autonomous Large Language Model Agent for Chemical Literature Data Mining](https://arxiv.org/abs/2402.12993) | 介绍了一个端到端的人工智能代理框架，利用大型语言模型实现从化学文献中高保真提取信息，充当化学助手的角色，自动化数据收集和分析，从而提高工作效率。 |
| [^7] | [Understanding and Mitigating the Threat of Vec2Text to Dense Retrieval Systems](https://arxiv.org/abs/2402.12784) | 本文研究了Vec2Text对密集检索系统的威胁以及如何缓解，通过对距离度量、池化函数、瓶颈预训练等方面进行深入分析，以获得对密集检索系统中文本可恢复性和检索效果权衡关键元素的更深入理解。 |
| [^8] | [Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding](https://arxiv.org/abs/2402.12774) | 提出了CONVINV方法，通过增强的重写将不透明的对话式会话嵌入转换为明确可解释的文本，同时保持原始检索性能。 |
| [^9] | [BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation](https://arxiv.org/abs/2402.12733) | 提出了一种新颖的基于多层感知器的异构序列推荐方法BMLP，通过行为感知模块和购买意图感知模块捕捉用户的异构兴趣和购买意图。 |
| [^10] | [Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2402.12728) | 提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。 |
| [^11] | [SoftQE: Learned Representations of Queries Expanded by LLMs](https://arxiv.org/abs/2402.12663) | SoftQE通过将输入查询的嵌入映射到LLM扩展查询的嵌入，提高了密集检索性能，并在领域外任务上取得了显著的性能改善。 |
| [^12] | [Leveraging Opposite Gender Interaction Ratio as a Path towards Fairness in Online Dating Recommendations Based on User Sexual Orientation](https://arxiv.org/abs/2402.12541) | 提出了一种新的度量标准Opposite Gender Interaction Ratio (OGIR)，用于研究在线约会推荐中针对具有不同异性偏好的用户潜在不公平性；实证分析表明现有的推荐算法可能根据OGIR存在分组不公平。 |
| [^13] | [SECP: A Speech Enhancement-Based Curation Pipeline For Scalable Acquisition Of Clean Speech](https://arxiv.org/abs/2402.12482) | 提出了基于语音增强的策划管道（SECP），可以在规模上获取干净语音并训练语音增强模型，通过两轮迭代观察到增强输出作为基准不会降低模型性能，并通过主观测试证明优化数据在感知上优于原始数据。 |
| [^14] | [Microstructures and Accuracy of Graph Recall by Large Language Models](https://arxiv.org/abs/2402.11821) | 本研究首次系统研究了大型语言模型对图形召回的准确性和偏见微结构，探讨了它们与人类的异同以及对其他图形推理任务的影响。 |
| [^15] | [Unified Hallucination Detection for Multimodal Large Language Models](https://arxiv.org/abs/2402.03190) | 该论文提出了一个新颖的统一的多模态幻觉检测框架UNIHD，并设计了一个评估基准方法MHaluBench来评估幻觉检测方法的进展。这项工作扩展了幻觉检测的研究范围并提供了有效的解决方案。 |
| [^16] | [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://arxiv.org/abs/2401.07453) | 评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。 |
| [^17] | [Challenging Low Homophily in Social Recommendation.](http://arxiv.org/abs/2401.14606) | 本研究挑战了社交推荐中的低同质性问题，提出了Social Heterophily-alleviating Rewiring (SHaRe)框架，用于增强现有的基于图的社交推荐模型。通过捕捉高同质的社交关系并剪切低同质关系，该框架有效提取了偏好感知同质性信息，解决了社交推荐中的信息冗余问题。 |
| [^18] | [ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction.](http://arxiv.org/abs/2310.09234) | 这篇论文提出了一个新颖的模型，旨在同时模拟语义和协同知识，以实现准确的CTR估计，并解决推理效率问题。 |
| [^19] | [A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining.](http://arxiv.org/abs/2309.04761) | 本调研综合审查了在教育数据挖掘中深度学习技术的最新研究进展，包括对知识跟踪、学生不良行为检测、性能预测和个性化推荐等典型教育场景的应用。同时提供了公共数据集和处理工具的综合概述，并指出了未来的研究方向。 |

# 详细

[^1]: 在Jupyter笔记本中解锁洞见：语义搜索

    Unlocking Insights: Semantic Search in Jupyter Notebooks

    [https://arxiv.org/abs/2402.13234](https://arxiv.org/abs/2402.13234)

    本文探讨了在Jupyter笔记本中应用大型语言模型增强语义搜索能力的方法，展示了一个全面理解整个笔记本内容语义的搜索框架。

    

    语义搜索旨在通过理解搜索者的意图和可搜索数据空间中术语的上下文含义，提供高度相关的搜索结果，在信息检索中起着至关重要的作用。本文探讨了应用大型语言模型增强语义搜索能力的方法，特别针对Jupyter笔记本领域进行了定制。我们的目标是检索生成的输出，如图表、关联函数和方法以及其他相关信息。我们展示了一个语义搜索框架，可以全面理解整个笔记本内容的语义，从而有效处理各种类型的用户查询。该框架的关键组成部分包括：1）设计了一个数据预处理器，用于处理Jupyter笔记本中各种类型的单元格，包括Markdown和代码单元格。2）一种创新的方法

    arXiv:2402.13234v1 Announce Type: cross  Abstract: Semantic search, a process aimed at delivering highly relevant search results by comprehending the searcher's intent and the contextual meaning of terms within a searchable dataspace, plays a pivotal role in information retrieval. In this paper, we investigate the application of large language models to enhance semantic search capabilities, specifically tailored for the domain of Jupyter Notebooks. Our objective is to retrieve generated outputs, such as figures or tables, associated functions and methods, and other pertinent information.   We demonstrate a semantic search framework that achieves a comprehensive semantic understanding of the entire notebook's contents, enabling it to effectively handle various types of user queries. Key components of this framework include:   1). A data preprocessor is designed to handle diverse types of cells within Jupyter Notebooks, encompassing both markdown and code cells. 2). An innovative methodo
    
[^2]: 具有部分反馈的模态估计

    Mode Estimation with Partial Feedback

    [https://arxiv.org/abs/2402.13079](https://arxiv.org/abs/2402.13079)

    本文提出了一种在模态估计中利用部分反馈的方法，通过熵编码实现最优信息获取，开发了粗糙的充分统计用于模态识别，并将赌博算法调整为新设置，最终提出了一个高效的问题解决方案

    

    arXiv:2402.13079v1 通告类型: 交叉摘要: 最近人工智能发展中，轻度监督的预训练和在线微调的组合在起着关键作用。这些新的学习流程需要新的理论框架。本文通过一个简单问题，形式化弱监督和主动学习的核心方面：使用部分反馈估计分布的模态。我们展示了如何利用熵编码从部分反馈中实现最优信息获取，为模态识别开发了粗糙的充分统计，并将赌博算法调整为我们的新设置。最后，我们将这些贡献结合起来，提出了一个在统计上和计算上高效的问题解决方案。

    arXiv:2402.13079v1 Announce Type: cross  Abstract: The combination of lightly supervised pre-training and online fine-tuning has played a key role in recent AI developments. These new learning pipelines call for new theoretical frameworks. In this paper, we formalize core aspects of weakly supervised and active learning with a simple problem: the estimation of the mode of a distribution using partial feedback. We show how entropy coding allows for optimal information acquisition from partial feedback, develop coarse sufficient statistics for mode identification, and adapt bandit algorithms to our new setting. Finally, we combine those contributions into a statistically and computationally efficient solution to our problem.
    
[^3]: 用超边增强改进现实世界复杂网络表示

    Enhancing Real-World Complex Network Representations with Hyperedge Augmentation

    [https://arxiv.org/abs/2402.13033](https://arxiv.org/abs/2402.13033)

    提出了一种新颖的图增强方法Hyperedge Augmentation (HyperAug)，通过构建直接从原始数据形成的虚拟超边，以解决现实世界复杂网络表示中高阶节点关系的问题

    

    arXiv:2402.13033v1 公告类型: 新摘要: 图增强方法在改进图神经网络（GNNs）的性能和增强泛化能力中起着至关重要的作用。现有的图增强方法主要扰动图结构，通常限于成对节点关系。这些方法无法完全解决真实世界大规模网络的复杂性，这些网络通常涉及高阶节点关系，而不仅仅是成对关系。同时，由于缺乏可用于形成高阶边的数据，真实世界图数据集主要被建模为简单图。因此，将高阶边重新配置为图增强策略的一部分是一个有前途的研究路径，可解决前述问题。在本文中，我们提出了超边增强（HyperAug），一种新颖的图增强方法，直接从原始数据构建虚拟超边，并产生辅助节点。

    arXiv:2402.13033v1 Announce Type: new  Abstract: Graph augmentation methods play a crucial role in improving the performance and enhancing generalisation capabilities in Graph Neural Networks (GNNs). Existing graph augmentation methods mainly perturb the graph structures and are usually limited to pairwise node relations. These methods cannot fully address the complexities of real-world large-scale networks that often involve higher-order node relations beyond only being pairwise. Meanwhile, real-world graph datasets are predominantly modelled as simple graphs, due to the scarcity of data that can be used to form higher-order edges. Therefore, reconfiguring the higher-order edges as an integration into graph augmentation strategies lights up a promising research path to address the aforementioned issues. In this paper, we present Hyperedge Augmentation (HyperAug), a novel graph augmentation method that constructs virtual hyperedges directly form the raw data, and produces auxiliary nod
    
[^4]: 朝着可信的再排序：一种简单但有效的弃权机制

    Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism

    [https://arxiv.org/abs/2402.12997](https://arxiv.org/abs/2402.12997)

    提出了一种适用于现实约束的轻量级弃权机制，特别适用于再排序阶段，通过数据驱动的方法达到有效性，并提供了开源代码以促进其更广泛的应用。

    

    神经信息检索（NIR）已经显著改进了基于启发式的IR系统。然而，失败仍然频繁发生，通常所使用的模型无法检索与用户查询相关的文档。我们通过提出一种适用于现实约束的轻量级弃权机制来解决这一挑战，特别强调再排序阶段。我们介绍了一个协议，用于在黑匣子场景中评估弃权策略的效果，并提出了一种简单但有效的数据驱动机制。我们提供了实验复制和弃权实施的开源代码，促进其在不同环境中更广泛的采用和应用。

    arXiv:2402.12997v1 Announce Type: cross  Abstract: Neural Information Retrieval (NIR) has significantly improved upon heuristic-based IR systems. Yet, failures remain frequent, the models used often being unable to retrieve documents relevant to the user's query. We address this challenge by proposing a lightweight abstention mechanism tailored for real-world constraints, with particular emphasis placed on the reranking phase. We introduce a protocol for evaluating abstention strategies in a black-box scenario, demonstrating their efficacy, and propose a simple yet effective data-driven mechanism. We provide open-source code for experiment replication and abstention implementation, fostering wider adoption and application in diverse contexts.
    
[^5]: 基于分布鲁棒性的图神经推荐系统

    Distributionally Robust Graph-based Recommendation System

    [https://arxiv.org/abs/2402.12994](https://arxiv.org/abs/2402.12994)

    提出了一种基于分布鲁棒性的图神经推荐系统（DR-GNN），通过将分布鲁棒性优化（DRO）融入到基于GNN的推荐中，解决训练和测试数据分布不同造成的效果下降问题

    

    具有捕捉高阶协作信号能力的图神经网络（GNNs）已经成为推荐系统（RS）中强大的方法。然而，它们的有效性通常取决于训练和测试数据共享相同分布（即IID假设），并在分布转移下出现显著下降。分布转移在RS中常见，通常归因于用户喜好的动态性或RS中数据收集过程中的普遍偏见。尽管其重要性，针对基于GNN的推荐系统对抗分布转移的研究仍然很少。为了弥合这一差距，我们提出了将分布鲁棒性优化（DRO）引入基于GNN的推荐系统中的分布鲁棒性GNN（DR-GNN）。DR-GNN解决了两个核心挑战：1）使DRO能够适应与GNN交织的图数据，我们将GNN重新解释为图平滑正则化器，从而促进...

    arXiv:2402.12994v1 Announce Type: new  Abstract: With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (a.k.a. IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitatin
    
[^6]: 用于化学文献数据挖掘的自主大型语言模型代理

    An Autonomous Large Language Model Agent for Chemical Literature Data Mining

    [https://arxiv.org/abs/2402.12993](https://arxiv.org/abs/2402.12993)

    介绍了一个端到端的人工智能代理框架，利用大型语言模型实现从化学文献中高保真提取信息，充当化学助手的角色，自动化数据收集和分析，从而提高工作效率。

    

    化学合成对于推动材料合成和药物发现至关重要，影响着包括环境科学和医疗保健在内的各个领域。化学领域的技术上升使得产生了大量的化学数据，挑战研究人员去识别模式并细化合成过程。人工智能通过分析数据来优化合成并提高产量。然而，人工智能在处理文献数据方面面临着挑战，因为化学文献的结构不规整，写作风格多样。为了克服这些困难，我们引入了一个端到端的人工智能代理框架，能够从广泛的化学文献中高保真地提取信息。这个人工智能代理采用大型语言模型（LLMs）进行快速生成和迭代优化。它充当化学助手的角色，自动化数据收集和分析，从而节省人力并提高性能。

    arXiv:2402.12993v1 Announce Type: cross  Abstract: Chemical synthesis, which is crucial for advancing material synthesis and drug discovery, impacts various sectors including environmental science and healthcare. The rise of technology in chemistry has generated extensive chemical data, challenging researchers to discern patterns and refine synthesis processes. Artificial intelligence (AI) helps by analyzing data to optimize synthesis and increase yields. However, AI faces challenges in processing literature data due to the unstructured format and diverse writing style of chemical literature. To overcome these difficulties, we introduce an end-to-end AI agent framework capable of high-fidelity extraction from extensive chemical literature. This AI agent employs large language models (LLMs) for prompt generation and iterative optimization. It functions as a chemistry assistant, automating data collection and analysis, thereby saving manpower and enhancing performance. Our framework's ef
    
[^7]: 理解和缓解Vec2Text对密集检索系统的威胁

    Understanding and Mitigating the Threat of Vec2Text to Dense Retrieval Systems

    [https://arxiv.org/abs/2402.12784](https://arxiv.org/abs/2402.12784)

    本文研究了Vec2Text对密集检索系统的威胁以及如何缓解，通过对距离度量、池化函数、瓶颈预训练等方面进行深入分析，以获得对密集检索系统中文本可恢复性和检索效果权衡关键元素的更深入理解。

    

    引入Vec2Text技术，一种用于反转文本嵌入的技术，引发了人们对密集检索系统中存在严重隐私问题的担忧，包括那些使用OpenAI和Cohere提供的文本嵌入的系统。这种威胁来自于一个恶意攻击者通过访问文本嵌入来重构原始文本。本文研究了影响使用Vec2Text恢复文本的嵌入模型的各个方面。我们的探索涉及距离度量、池化函数、瓶颈预训练、加噪声训练、嵌入量化和嵌入维度等因素，这些因素在原始Vec2Text论文中尚未被讨论。通过对这些因素的深入分析，我们旨在更深入地了解影响密集检索系统中文本可恢复性和检索效果之间权衡的关键因素。

    arXiv:2402.12784v1 Announce Type: cross  Abstract: The introduction of Vec2Text, a technique for inverting text embeddings, has raised serious privacy concerns within dense retrieval systems utilizing text embeddings, including those provided by OpenAI and Cohere. This threat comes from the ability for a malicious attacker with access to text embeddings to reconstruct the original text.   In this paper, we investigate various aspects of embedding models that could influence the recoverability of text using Vec2Text. Our exploration involves factors such as distance metrics, pooling functions, bottleneck pre-training, training with noise addition, embedding quantization, and embedding dimensions -- aspects not previously addressed in the original Vec2Text paper. Through a thorough analysis of these factors, our aim is to gain a deeper understanding of the critical elements impacting the trade-offs between text recoverability and retrieval effectiveness in dense retrieval systems. This a
    
[^8]: 通过增强的重写来解释对话式密集检索的会话嵌入

    Interpreting Conversational Dense Retrieval by Rewriting-Enhanced Inversion of Session Embedding

    [https://arxiv.org/abs/2402.12774](https://arxiv.org/abs/2402.12774)

    提出了CONVINV方法，通过增强的重写将不透明的对话式会话嵌入转换为明确可解释的文本，同时保持原始检索性能。

    

    对话式密集检索已被证明在对话式搜索中非常有效。然而，对话式密集检索的一个主要局限性是它们缺乏可解释性，从而阻碍了对模型行为的直观理解以进行有针对性的改进。本文提出了CONVINV，一种简单而有效的方法，可以揭示可解释的对话式密集检索模型。CONVINV将不透明的对话式会话嵌入转换为明确可解释的文本，同时尽可能忠实地保持其原始检索性能。这种转换是通过训练一种基于专门查询编码器的最近提出的Vec2Text模型来实现的，利用了会话和查询嵌入在现有对话式密集检索中共享相同空间的事实。为了进一步增强可解释性，我们建议将外部可解释的查询重写纳入转换过程中。

    arXiv:2402.12774v1 Announce Type: new  Abstract: Conversational dense retrieval has shown to be effective in conversational search. However, a major limitation of conversational dense retrieval is their lack of interpretability, hindering intuitive understanding of model behaviors for targeted improvements. This paper presents CONVINV, a simple yet effective approach to shed light on interpretable conversational dense retrieval models. CONVINV transforms opaque conversational session embeddings into explicitly interpretable text while faithfully maintaining their original retrieval performance as much as possible. Such transformation is achieved by training a recently proposed Vec2Text model based on the ad-hoc query encoder, leveraging the fact that the session and query embeddings share the same space in existing conversational dense retrieval. To further enhance interpretability, we propose to incorporate external interpretable query rewrites into the transformation process. Extensi
    
[^9]: BMLP：用于异构序列推荐的行为感知MLP

    BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation

    [https://arxiv.org/abs/2402.12733](https://arxiv.org/abs/2402.12733)

    提出了一种新颖的基于多层感知器的异构序列推荐方法BMLP，通过行为感知模块和购买意图感知模块捕捉用户的异构兴趣和购买意图。

    

    在真实的推荐场景中，用户往往具有不同类型的行为，比如点击和购买。现有研究方法表明，通过不同类型的行为可以捕捉用户的异构兴趣。然而，大多数多行为方法在学习不同行为之间的关系方面存在局限性。本文提出了一种新颖的基于多层感知器（MLP）的异构序列推荐方法，即行为感知多层感知器（BMLP）。具体而言，它包括两个主要模块，即异构兴趣感知（HIP）模块，通过行为类型和转换关系在多个粒度上建模行为，并购买意图感知（PIP）模块，该模块自适应地融合辅助行为的子序列以捕捉用户的购买意图。与主流序列模型相比，MLP在准确性方面有竞争力。

    arXiv:2402.12733v1 Announce Type: cross  Abstract: In real recommendation scenarios, users often have different types of behaviors, such as clicking and buying. Existing research methods show that it is possible to capture the heterogeneous interests of users through different types of behaviors. However, most multi-behavior approaches have limitations in learning the relationship between different behaviors. In this paper, we propose a novel multilayer perceptron (MLP)-based heterogeneous sequential recommendation method, namely behavior-aware multilayer perceptron (BMLP). Specifically, it has two main modules, including a heterogeneous interest perception (HIP) module, which models behaviors at multiple granularities through behavior types and transition relationships, and a purchase intent perception (PIP) module, which adaptively fuses subsequences of auxiliary behaviors to capture users' purchase intent. Compared with mainstream sequence models, MLP is competitive in terms of accu
    
[^10]: 基于大型语言模型的模态感知集成用于基于知识的视觉问答

    Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering

    [https://arxiv.org/abs/2402.12728](https://arxiv.org/abs/2402.12728)

    提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。

    

    知识驱动的视觉问答（KVQA）已被广泛研究，以利用外部知识如知识图谱（KG）来回答视觉问题。尽管已提出几种尝试利用大型语言模型（LLMs）作为隐含知识源，但由于LLMs可能生成幻觉，因此仍然具有挑战性。此外，多种知识来源，例如图像、知识图谱和LLMs，不能轻易对齐以应对复杂场景。为了解决这些问题，我们提出了一种针对KVQA的新颖的具有模态感知的LLM集成方法（MAIL）。它精心利用多模态知识进行图像理解和知识推理。具体而言，（i）我们提出了一种使用LLMs的两阶段提示策略，将图像密集地融入带有详细视觉特征的场景图中；（ii）我们通过将提到的实体与外部事实联系起来构建一个耦合的概念图；（iii）设计了一个定制的伪孪生图中介融合。

    arXiv:2402.12728v1 Announce Type: cross  Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designe
    
[^11]: SoftQE: LLM扩展的查询学习表示

    SoftQE: Learned Representations of Queries Expanded by LLMs

    [https://arxiv.org/abs/2402.12663](https://arxiv.org/abs/2402.12663)

    SoftQE通过将输入查询的嵌入映射到LLM扩展查询的嵌入，提高了密集检索性能，并在领域外任务上取得了显著的性能改善。

    

    我们研究了将大型语言模型(LLMs)集成到查询编码器中，以改善密集检索，同时避免在推断时依赖LLMs增加延迟和成本。SoftQE通过将输入查询的嵌入映射到LLM扩展查询的嵌入来整合LLMs的知识。虽然对于领域内MS-MARCO指标，SoftQE相对于各种强基准模型的改善有限，但在五个领域外BEIR任务上，SoftQE在平均性能上提高了2.83个绝对百分点。

    arXiv:2402.12663v1 Announce Type: new  Abstract: We investigate the integration of Large Language Models (LLMs) into query encoders to improve dense retrieval without increasing latency and cost, by circumventing the dependency on LLMs at inference time. SoftQE incorporates knowledge from LLMs by mapping embeddings of input queries to those of the LLM-expanded queries. While improvements over various strong baselines on in-domain MS-MARCO metrics are marginal, SoftQE improves performance by 2.83 absolute percentage points on average on five out-of-domain BEIR tasks.
    
[^12]: 利用相反性别互动比作为基于用户性取向的在线约会推荐中公平性的途径

    Leveraging Opposite Gender Interaction Ratio as a Path towards Fairness in Online Dating Recommendations Based on User Sexual Orientation

    [https://arxiv.org/abs/2402.12541](https://arxiv.org/abs/2402.12541)

    提出了一种新的度量标准Opposite Gender Interaction Ratio (OGIR)，用于研究在线约会推荐中针对具有不同异性偏好的用户潜在不公平性；实证分析表明现有的推荐算法可能根据OGIR存在分组不公平。

    

    在线约会平台作为个人寻找潜在恋爱关系的手段已经广受欢迎。尽管推荐系统旨在通过提供个性化推荐来改善约会平台的用户体验，但关于公平性的增加关注促使从各种角度（例如性别和种族）开发考虑公平性的推荐系统。然而，对于找到令人满意的关系起着重要作用的性取向却受到了较少的研究。为了填补这一重要空白，我们提出了一种新颖的度量标准，即相反性别互动比（OGIR），作为研究具有不同对异性偏好的用户潜在不公平性的方式。我们在一个真实的在线约会数据集上进行了实证分析，并观察到现有的推荐算法根据OGIR可能会受到分组不公平的影响。我们进一步调查了造成这种不公平的潜在原因。

    arXiv:2402.12541v1 Announce Type: new  Abstract: Online dating platforms have gained widespread popularity as a means for individuals to seek potential romantic relationships. While recommender systems have been designed to improve the user experience in dating platforms by providing personalized recommendations, increasing concerns about fairness have encouraged the development of fairness-aware recommender systems from various perspectives (e.g., gender and race). However, sexual orientation, which plays a significant role in finding a satisfying relationship, is under-investigated. To fill this crucial gap, we propose a novel metric, Opposite Gender Interaction Ratio (OGIR), as a way to investigate potential unfairness for users with varying preferences towards the opposite gender. We empirically analyze a real online dating dataset and observe existing recommender algorithms could suffer from group unfairness according to OGIR. We further investigate the potential causes for such g
    
[^13]: SECP：基于语音增强的策划管道，用于可扩展获取干净语音

    SECP: A Speech Enhancement-Based Curation Pipeline For Scalable Acquisition Of Clean Speech

    [https://arxiv.org/abs/2402.12482](https://arxiv.org/abs/2402.12482)

    提出了基于语音增强的策划管道（SECP），可以在规模上获取干净语音并训练语音增强模型，通过两轮迭代观察到增强输出作为基准不会降低模型性能，并通过主观测试证明优化数据在感知上优于原始数据。

    

    随着越来越多的语音技术依赖于以干净语音为基准的监督式深度学习方法，需要一种方法来在规模上接入这些语音。然而，这种方法需要最大程度地减少对人类听觉和注释的依赖，只在需要时需要人类介入。本文通过概述基于语音增强的策划管道（SECP）来解决这个问题，作为一个框架用来接入干净语音。这些干净语音可以用来训练语音增强模型，进一步改进原始数据集，从而关闭迭代循环。我们通过两轮迭代的实验观察到，作为基准的增强输出不会使模型性能根据本文使用的 $\Delta_{PESQ}$ 指标下降。我们还通过基于比较均值意见评分（CMOS）的主观测试表明，优化数据的最高和最低边界在感知上优于原始数据。

    arXiv:2402.12482v1 Announce Type: cross  Abstract: As more speech technologies rely on a supervised deep learning approach with clean speech as the ground truth, a methodology to onboard said speech at scale is needed. However, this approach needs to minimize the dependency on human listening and annotation, only requiring a human-in-the-loop when needed. In this paper, we address this issue by outlining Speech Enhancement-based Curation Pipeline (SECP) which serves as a framework to onboard clean speech. This clean speech can then train a speech enhancement model, which can further refine the original dataset and thus close the iterative loop. By running two iterative rounds, we observe that enhanced output used as ground truth does not degrade model performance according to $\Delta_{PESQ}$, a metric used in this paper. We also show through comparative mean opinion score (CMOS) based subjective tests that the highest and lowest bound of refined data is perceptually better than the ori
    
[^14]: 大型语言模型对图形召回的微结构和准确性

    Microstructures and Accuracy of Graph Recall by Large Language Models

    [https://arxiv.org/abs/2402.11821](https://arxiv.org/abs/2402.11821)

    本研究首次系统研究了大型语言模型对图形召回的准确性和偏见微结构，探讨了它们与人类的异同以及对其他图形推理任务的影响。

    

    图形数据对许多应用至关重要，其中很多数据以文本格式描述关系。因此，准确地召回和编码先前文本中描述的图形是大型语言模型(LLMs)需要展示的基本但关键能力，以执行涉及图形结构信息的推理任务。人类在图形召回方面的表现已被认知科学家研究了几十年，发现其经常呈现与人类处理社会关系一致的某些结构性偏见模式。然而，迄今为止，我们很少了解LLMs在类似图形召回任务中的行为：它们召回的图形是否也呈现某些偏见模式，如果是，它们与人类的表现有何不同并如何影响其他图形推理任务？在这项研究中，我们进行了第一次对LLMs进行图形召回的系统研究，研究其准确性和偏见微结构（局部结构）。

    arXiv:2402.11821v1 Announce Type: cross  Abstract: Graphs data is crucial for many applications, and much of it exists in the relations described in textual format. As a result, being able to accurately recall and encode a graph described in earlier text is a basic yet pivotal ability that LLMs need to demonstrate if they are to perform reasoning tasks that involve graph-structured information. Human performance at graph recall by has been studied by cognitive scientists for decades, and has been found to often exhibit certain structural patterns of bias that align with human handling of social relationships. To date, however, we know little about how LLMs behave in analogous graph recall tasks: do their recalled graphs also exhibit certain biased patterns, and if so, how do they compare with humans and affect other graph reasoning tasks? In this work, we perform the first systematical study of graph recall by LLMs, investigating the accuracy and biased microstructures (local structura
    
[^15]: 统一的多模态大型语言模型的幻觉检测

    Unified Hallucination Detection for Multimodal Large Language Models

    [https://arxiv.org/abs/2402.03190](https://arxiv.org/abs/2402.03190)

    该论文提出了一个新颖的统一的多模态幻觉检测框架UNIHD，并设计了一个评估基准方法MHaluBench来评估幻觉检测方法的进展。这项工作扩展了幻觉检测的研究范围并提供了有效的解决方案。

    

    尽管在多模态任务方面取得了重大进展，多模态大型语言模型(MLLMs)仍然存在幻觉的严重问题。因此，可靠地检测MLLMs中的幻觉已成为模型评估和实际应用部署保障的重要方面。之前在这个领域的研究受到了狭窄的任务焦点、不足的幻觉类别涵盖范围以及缺乏详细的细粒度的限制。针对这些挑战，我们的工作扩展了幻觉检测的研究范围。我们提出了一个新颖的元评估基准方法，MHaluBench，精心设计以促进幻觉检测方法的进展评估。此外，我们揭示了一个新颖的统一多模态幻觉检测框架，UNIHD，它利用一套辅助工具来稳健地验证幻觉的发生。我们通过实验证明了UNIHD的有效性。

    Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD throug
    
[^16]: 规模化模型编辑会导致渐进性和突发性遗忘

    Model Editing at Scale leads to Gradual and Catastrophic Forgetting

    [https://arxiv.org/abs/2401.07453](https://arxiv.org/abs/2401.07453)

    评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。

    

    在大型语言模型中编辑知识是一种具有吸引力的能力，它使我们能够在预训练期间纠正错误学习的事实，同时使用不断增长的新事实列表更新模型。我们认为，为了使模型编辑具有实际效用，我们必须能够对同一模型进行多次编辑。因此，我们评估了当前规模下的模型编辑方法，重点关注两种最先进的方法：ROME 和 MEMIT。我们发现，随着模型被顺序编辑多个事实，它不断地遗忘先前编辑过的事实以及执行下游任务的能力。这种遗忘分为两个阶段--初始的渐进性遗忘阶段，随后是突然或灾难性的遗忘。

    arXiv:2401.07453v2 Announce Type: replace-cross  Abstract: Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgettin
    
[^17]: 挑战社交推荐中的低同质性

    Challenging Low Homophily in Social Recommendation. (arXiv:2401.14606v1 [cs.IR])

    [http://arxiv.org/abs/2401.14606](http://arxiv.org/abs/2401.14606)

    本研究挑战了社交推荐中的低同质性问题，提出了Social Heterophily-alleviating Rewiring (SHaRe)框架，用于增强现有的基于图的社交推荐模型。通过捕捉高同质的社交关系并剪切低同质关系，该框架有效提取了偏好感知同质性信息，解决了社交推荐中的信息冗余问题。

    

    在社交推荐中，利用社交关系来解决用户-物品交互数据稀疏性问题，基于社交同质性的假设。然而，社交推荐范式主要关注基于用户偏好的同质性。虽然社交信息可以增强推荐效果，但它与用户偏好的一致性并不保证，从而可能引入信息冗余。我们经验性地发现，真实的推荐数据中的社交图展现出低偏好感知的同质性，这限制了社交推荐模型的作用。为了全面提取社交图中潜在的偏好感知同质性信息，我们提出了Social Heterophily-alleviating Rewiring (SHaRe)，这是一个以数据为中心的框架，用于增强现有基于图的社交推荐模型。我们采用图重连技术来捕捉和添加高度同质的社交关系，并剪切低同质（或异质）关系。为了更好地优化从社交图中提取的推荐模式的刻画，我们还引入基于图的用户偏好分布修正方法。

    Social relations are leveraged to tackle the sparsity issue of user-item interaction data in recommendation under the assumption of social homophily. However, social recommendation paradigms predominantly focus on homophily based on user preferences. While social information can enhance recommendations, its alignment with user preferences is not guaranteed, thereby posing the risk of introducing informational redundancy. We empirically discover that social graphs in real recommendation data exhibit low preference-aware homophily, which limits the effect of social recommendation models. To comprehensively extract preference-aware homophily information latent in the social graph, we propose Social Heterophily-alleviating Rewiring (SHaRe), a data-centric framework for enhancing existing graph-based social recommendation models. We adopt Graph Rewiring technique to capture and add highly homophilic social relations, and cut low homophilic (or heterophilic) relations. To better refine the u
    
[^18]: ClickPrompt: CTR模型是将语言模型适应为CTR预测的强大提示生成器

    ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction. (arXiv:2310.09234v1 [cs.IR])

    [http://arxiv.org/abs/2310.09234](http://arxiv.org/abs/2310.09234)

    这篇论文提出了一个新颖的模型，旨在同时模拟语义和协同知识，以实现准确的CTR估计，并解决推理效率问题。

    

    点击率（CTR）预测已经成为各种互联网应用程序中越来越不可或缺的。传统的CTR模型通过独热编码将多字段分类数据转换为ID特征，并提取特征之间的协同信号。这种范式的问题在于语义信息的丢失。另一方面的研究通过将输入数据转换为文本句子来探索预训练语言模型（PLM）在CTR预测中的潜力。虽然语义信号得到了保留，但它们通常无法捕捉到协同信息（如特征交互、纯ID特征），更不用说由庞大的模型大小带来的无法接受的推理开销了。在本文中，我们旨在为准确的CTR估计建立语义知识和协同知识，并解决推理效率问题。为了从两个领域中受益并弥合它们之间的差距，我们提出了一种新颖的模型-。

    Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-
    
[^19]: 在教育数据挖掘中深度学习技术的综合调研

    A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining. (arXiv:2309.04761v1 [cs.LG])

    [http://arxiv.org/abs/2309.04761](http://arxiv.org/abs/2309.04761)

    本调研综合审查了在教育数据挖掘中深度学习技术的最新研究进展，包括对知识跟踪、学生不良行为检测、性能预测和个性化推荐等典型教育场景的应用。同时提供了公共数据集和处理工具的综合概述，并指出了未来的研究方向。

    

    教育数据挖掘(EDM)作为研究的重要领域，利用计算技术来分析教育数据。随着教育数据的复杂性和多样性增加，深度学习技术在解决分析和建模这些数据所面临的挑战方面表现出了显著的优势。本调研旨在系统地审查深度学习在EDM领域的最新研究进展。我们首先提供了关于EDM和深度学习的简要介绍，强调了它们在现代教育环境中的重要性。接下来，我们详细回顾了在四个典型教育场景中应用的深度学习技术，包括知识跟踪、学生不良行为检测、性能预测和个性化推荐。此外，我们还提供了EDM的公共数据集和处理工具的综合概述。最后，我们指出了该研究领域的新兴趋势和未来方向。

    Educational Data Mining (EDM) has emerged as a vital field of research, which harnesses the power of computational techniques to analyze educational data. With the increasing complexity and diversity of educational data, Deep Learning techniques have shown significant advantages in addressing the challenges associated with analyzing and modeling this data. This survey aims to systematically review the state-of-the-art in EDM with Deep Learning. We begin by providing a brief introduction to EDM and Deep Learning, highlighting their relevance in the context of modern education. Next, we present a detailed review of Deep Learning techniques applied in four typical educational scenarios, including knowledge tracing, undesirable student detecting, performance prediction, and personalized recommendation. Furthermore, a comprehensive overview of public datasets and processing tools for EDM is provided. Finally, we point out emerging trends and future directions in this research area.
    

