# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models.](http://arxiv.org/abs/2308.08500) | 本文提出了InTune，一个基于强化学习的数据流优化方法，应用于深度推荐模型。通过研究在Netflix计算集群中的DLRM数据处理流程，我们发现目前的流程优化器存在性能不佳、频繁崩溃或需要不切实际的集群重组等问题。 |
| [^2] | [Context-Aware Service Recommendation System for the Social Internet of Things.](http://arxiv.org/abs/2308.08499) | 该研究提出了一个面向社交物联网的上下文感知服务推荐系统，通过捕捉设备之间的潜在特征交互和建模设备-服务对的高阶特征交互，实现了准确的评级预测和个性化的服务推荐。 |
| [^3] | [HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User Preferences in Streaming Recommendation.](http://arxiv.org/abs/2308.08497) | HyperBandit是一种基于超网络的上下文强化学习方法，用于处理流媒体推荐系统中时间变化的用户偏好。它通过建立时间特征和用户偏好之间的关联，动态调整推荐模型以适应动态场景。 |
| [^4] | [Understanding User Intent Modeling for Conversational Recommender Systems: A Systematic Literature Review.](http://arxiv.org/abs/2308.08496) | 该论文进行了一项系统文献综述，研究了对话式推荐系统中用户意图建模的相关模型和特征。研究结果为研究人员提供了模型选择、质量问题和评估指标等方面的洞察。 |
| [^5] | [Conceptualizing Machine Learning for Dynamic Information Retrieval of Electronic Health Record Notes.](http://arxiv.org/abs/2308.08494) | 该论文提出了一种概念化的机器学习方法，通过使用电子健康记录的审计日志作为监督，实现在特定临床背景下、特定时间点的笔记相关性检索。实验证明该方法在预测个别笔记撰写会话中哪些笔记会被阅读方面具有很高的准确性，并且临床医生的用户研究结果显示该框架可以帮助临床医生更高效地检索相关信息。 |
| [^6] | [Temporal Interest Network for Click-Through Rate Prediction.](http://arxiv.org/abs/2308.08487) | 本文提出了时间兴趣网络（TIN），用于捕捉行为与目标之间的四重语义和时间相关性，以预测点击率的效果和已有方法对这种相关性的学习程度尚不清楚。 |
| [^7] | [TBIN: Modeling Long Textual Behavior Data for CTR Prediction.](http://arxiv.org/abs/2308.08483) | TBIN模型通过局部敏感哈希算法和基于块位移的自注意力方法解决了利用长文本用户行为数据进行CTR预测时的截断问题和模型表达能力问题。 |
| [^8] | [CDR: Conservative Doubly Robust Learning for Debiased Recommendation.](http://arxiv.org/abs/2308.08461) | 该论文提出了一种保守双重稳健策略（CDR），用于解决推荐系统中存在的有毒插补问题。CDR通过审查插补的均值和方差来过滤插补，结果显示CDR具有降低方差和改进尾部界限的优势，并且能够显著提升性能并减少有毒插补的频率。 |
| [^9] | [Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem.](http://arxiv.org/abs/2308.08460) | 提出了一种名为MOSR的算法，用于解决动态邮件重新排序问题。该算法使用自适应控制模型来平衡亲密度，及时性和简洁性等标准，并能够适应偏好的变化。在恩隆邮件数据集上的实验结果表明，MOSR在非稳态偏好下表现出更好的性能，并且在具有高方差的邮件特征的小型抽样数据集上也能保持稳定的排名。 |
| [^10] | [Knowledge Prompt-tuning for Sequential Recommendation.](http://arxiv.org/abs/2308.08459) | 该论文提出了知识提示调优的顺序推荐(KP4SR)方法，通过引入外部知识库和构建知识提示，解决了顺序推荐中的语义差距和信息损失问题，从而提高了推荐性能。 |
| [^11] | [CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction in On-Demand Food Delivery Services.](http://arxiv.org/abs/2308.08446) | 本研究提出了CSPM模型，通过对比学习和时空偏好提取来解决按需食品配送CTR预测中的时空信息建模问题。 |
| [^12] | [A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems.](http://arxiv.org/abs/2308.08434) | 本文提出了一个名为BIGRec的两步接地框架，通过将大型语言模型与推荐空间接地，生成有意义的标记，并识别相应的实际项目，来探究大型语言模型在推荐系统中的全面排序能力。 |
| [^13] | [Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction.](http://arxiv.org/abs/2308.08413) | 这篇论文提出了一种知识增强的多标签少样本产品属性值提取方法，通过利用生成的标签描述和类别信息来学习更具有区分性的原型，并整合混合注意力来减少噪声和捕捉更多信息丰富的语义。实验结果表明，该方法在提取未见过的属性值对方面表现优于其他方法。 |
| [^14] | [Content-based Recommendation Engine for Video Streaming Platform.](http://arxiv.org/abs/2308.08406) | 本文提出了一种基于内容的推荐引擎，通过计算文档中单词的相关性和使用余弦相似度方法来推荐视频给用户。同时，还通过计算精确率、召回率和F1得分来评估引擎的性能。 |
| [^15] | [Advancing continual lifelong learning in neural information retrieval: definition, dataset, framework, and empirical evaluation.](http://arxiv.org/abs/2308.08378) | 本文提出了一个系统的持续神经信息检索任务定义，并提供了一个模拟连续信息检索的多主题数据集。同时，还提出了一个全面的持续神经信息检索框架，能够防止灾难性遗忘并提高先前学习任务的性能。 |
| [^16] | [Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?.](http://arxiv.org/abs/2308.08354) | 本文研究表明，针对推荐系统中的冷启动问题，元学习技术在处理深度学习模型时已成为最受欢迎的方法。然而，当前的元学习方法在实际推荐系统中并不实用，因为这些系统拥有庞大的用户和物品数量，且有严格的延迟要求。 |
| [^17] | [Phase Retrieval with Background Information: Decreased References and Efficient Methods.](http://arxiv.org/abs/2308.08328) | 本文提出了具备背景信息的相位恢复方法，通过改进方法与理论结果，成功减少了对背景信息的需求。 |
| [^18] | [Pre-training with Large Language Model-based Document Expansion for Dense Passage Retrieval.](http://arxiv.org/abs/2308.08285) | 本文研究了基于大型语言模型的文档扩展预训练对稠密通道检索的潜力，通过利用该方法进行查询生成并传递扩展的知识给检索器，实验证明这种方法显著提高了大规模网络搜索任务的检索性能。 |
| [^19] | [Uncovering User Interest from Biased and Noised Watch Time in Video Recommendation.](http://arxiv.org/abs/2308.08120) | 本研究分析了视频推荐中观看时长的生成机制，提出了一种基于因果推断的视频推荐方法，减轻了持续时间偏差和噪声观看带来的问题，并改善了从观看时长中揭示用户兴趣的效果。 |
| [^20] | [Decentralized Graph Neural Network for Privacy-Preserving Recommendation.](http://arxiv.org/abs/2308.08072) | 本文提出了一种去中心化图神经网络（DGREC）框架，用于隐私保护推荐，其中用户可以选择公开他们的交互。该框架通过图构建、局部梯度计算和全局梯度传递三个阶段实现，同时引入了名为安全梯度共享的差分隐私机制，保护用户的私密数据。 |
| [^21] | [Transforming Sentiment Analysis in the Financial Domain with ChatGPT.](http://arxiv.org/abs/2308.07935) | 本研究使用ChatGPT 3.5来进行金融情绪分析，特别关注外汇市场，通过零-shot提示方法，在精心策划的数据集上评估了其性能，并发现与传统模型相比，ChatGPT在金融情绪分析中表现出约35％的性能提升。 |
| [^22] | [SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search.](http://arxiv.org/abs/2308.07711) | 本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。 |
| [^23] | [A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous Data.](http://arxiv.org/abs/2308.07426) | 本文针对旅游领域的兴趣点推荐问题进行了调查研究，探讨了利用异构数据解决旅途中兴趣点推荐问题的潜力与挑战。 |
| [^24] | [Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning.](http://arxiv.org/abs/2308.05379) | 这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。 |
| [^25] | [LLM-Rec: Personalized Recommendation via Prompting Large Language Models.](http://arxiv.org/abs/2307.15780) | 本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。 |
| [^26] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |

# 详细

[^1]: InTune:基于强化学习的数据流优化用于深度推荐模型

    InTune: Reinforcement Learning-based Data Pipeline Optimization for Deep Recommendation Models. (arXiv:2308.08500v1 [cs.IR])

    [http://arxiv.org/abs/2308.08500](http://arxiv.org/abs/2308.08500)

    本文提出了InTune，一个基于强化学习的数据流优化方法，应用于深度推荐模型。通过研究在Netflix计算集群中的DLRM数据处理流程，我们发现目前的流程优化器存在性能不佳、频繁崩溃或需要不切实际的集群重组等问题。

    

    基于深度学习的推荐模型(DLRM)已经成为许多现代推荐系统的重要组成部分。一些公司正在建设大型计算集群专门用于DLRM训练，进而推动了对成本和时间的节约优化的新兴兴趣。在这个场景中所面临的系统挑战是独特的；尽管典型的深度学习训练任务由模型执行主导，但DLRM训练性能中最重要的因素往往是线上数据摄入。在本文中，我们探讨了该数据摄入问题的独特特征，并深入研究了DLRM训练流程中的性能瓶颈和挑战。我们对Netflix计算集群中真实的DLRM数据处理流程进行了研究，观察了线上摄入的性能影响，并识别出现有流程优化器的不足之处。我们发现当前的工具要么产生次优性能，要么经常崩溃，要么需要不现实的集群重组。

    Deep learning-based recommender models (DLRMs) have become an essential component of many modern recommender systems. Several companies are now building large compute clusters reserved only for DLRM training, driving new interest in cost- and time- saving optimizations. The systems challenges faced in this setting are unique; while typical deep learning training jobs are dominated by model execution, the most important factor in DLRM training performance is often online data ingestion.  In this paper, we explore the unique characteristics of this data ingestion problem and provide insights into DLRM training pipeline bottlenecks and challenges. We study real-world DLRM data processing pipelines taken from our compute cluster at Netflix to observe the performance impacts of online ingestion and to identify shortfalls in existing pipeline optimizers. We find that current tooling either yields sub-optimal performance, frequent crashes, or else requires impractical cluster re-organization 
    
[^2]: 面向社交物联网的上下文感知服务推荐系统

    Context-Aware Service Recommendation System for the Social Internet of Things. (arXiv:2308.08499v1 [cs.IR])

    [http://arxiv.org/abs/2308.08499](http://arxiv.org/abs/2308.08499)

    该研究提出了一个面向社交物联网的上下文感知服务推荐系统，通过捕捉设备之间的潜在特征交互和建模设备-服务对的高阶特征交互，实现了准确的评级预测和个性化的服务推荐。

    

    社交物联网（SIoT）使智能设备相互连接并共享数据和服务，为个性化服务推荐提供了机会。然而，现有研究经常忽视了可以提高SIoT环境下推荐的准确性和相关性的关键因素。具体而言，现有技术往往只考虑了设备之间的社交关系的提取，而忽视了服务评论的上下文呈现。本研究旨在通过探索每个设备-服务对的上下文表示来填补这些缺口。首先，我们提出了一种潜在特征组合技术，可以通过聚合SIoT中的设备-设备关系来捕捉潜在特征交互。然后，我们利用因子分解机来建模每个SIoT设备-服务对特定的高阶特征交互，以实现准确的评级预测。最后，我们提出了一个基于评级预测的SIoT服务推荐框架。

    The Social Internet of Things (SIoT) enables interconnected smart devices to share data and services, opening up opportunities for personalized service recommendations. However, existing research often overlooks crucial aspects that can enhance the accuracy and relevance of recommendations in the SIoT context. Specifically, existing techniques tend to consider the extraction of social relationships between devices and neglect the contextual presentation of service reviews. This study aims to address these gaps by exploring the contextual representation of each device-service pair. Firstly, we propose a latent features combination technique that can capture latent feature interactions, by aggregating the device-device relationships within the SIoT. Then, we leverage Factorization Machines to model higher-order feature interactions specific to each SIoT device-service pair to accomplish accurate rating prediction. Finally, we propose a service recommendation framework for SIoT based on r
    
[^3]: HyperBandit: 基于超网络的时间变化用户偏好的上下文强化学习算法在流媒体推荐系统中的应用

    HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User Preferences in Streaming Recommendation. (arXiv:2308.08497v1 [cs.IR])

    [http://arxiv.org/abs/2308.08497](http://arxiv.org/abs/2308.08497)

    HyperBandit是一种基于超网络的上下文强化学习方法，用于处理流媒体推荐系统中时间变化的用户偏好。它通过建立时间特征和用户偏好之间的关联，动态调整推荐模型以适应动态场景。

    

    在现实世界的流媒体推荐系统中，用户偏好经常在时间上动态变化（例如，在工作日和周末用户可能有不同的偏好）。现有的基于强化学习的流媒体推荐模型只将时间视为时间戳，没有明确地建模时间变量与时间变化的用户偏好之间的关系。这导致推荐模型无法快速适应动态场景。为了解决这个问题，我们提出了一种使用超网络的上下文强化学习方法，称为HyperBandit，其将时间特征作为输入，并动态调整推荐模型以适应时间变化的用户偏好。具体而言，HyperBandit维护了一个能够生成用于估计时间变化奖励的参数的神经网络，考虑了时间特征和用户偏好之间的相关性。使用估计的时间变化奖励，我们采用强化学习策略来进行在线推荐。

    In real-world streaming recommender systems, user preferences often dynamically change over time (e.g., a user may have different preferences during weekdays and weekends). Existing bandit-based streaming recommendation models only consider time as a timestamp, without explicitly modeling the relationship between time variables and time-varying user preferences. This leads to recommendation models that cannot quickly adapt to dynamic scenarios. To address this issue, we propose a contextual bandit approach using hypernetwork, called HyperBandit, which takes time features as input and dynamically adjusts the recommendation model for time-varying user preferences. Specifically, HyperBandit maintains a neural network capable of generating the parameters for estimating time-varying rewards, taking into account the correlation between time features and user preferences. Using the estimated time-varying rewards, a bandit policy is employed to make online recommendations by learning the laten
    
[^4]: 理解对话式推荐系统中用户意图建模：一项系统文献综述

    Understanding User Intent Modeling for Conversational Recommender Systems: A Systematic Literature Review. (arXiv:2308.08496v1 [cs.IR])

    [http://arxiv.org/abs/2308.08496](http://arxiv.org/abs/2308.08496)

    该论文进行了一项系统文献综述，研究了对话式推荐系统中用户意图建模的相关模型和特征。研究结果为研究人员提供了模型选择、质量问题和评估指标等方面的洞察。

    

    背景：用户意图建模是自然语言处理中的一个关键过程，旨在识别用户请求背后的潜在目的，从而实现个性化的响应。在过去十年中，文献中引入了大量的方法（超过13,000篇论文），理解人工智能系统中相关概念和常用模型是至关重要的。方法：我们进行了一项系统文献综述，收集了设计对话式推荐系统中通常采用的模型的数据。从收集到的数据中，我们开发了一个决策模型，以帮助研究人员选择最适合其系统的模型。此外，我们进行了两个案例研究，评估我们提出的决策模型的有效性。结果：我们的研究分析了59个不同的模型，并确定了74个常用的特征。我们提供了关于潜在的模型组合、模型选择趋势、质量问题、评估指标以及经常使用的数据的见解。

    Context: User intent modeling is a crucial process in Natural Language Processing that aims to identify the underlying purpose behind a user's request, enabling personalized responses. With a vast array of approaches introduced in the literature (over 13,000 papers in the last decade), understanding the related concepts and commonly used models in AI-based systems is essential. Method: We conducted a systematic literature review to gather data on models typically employed in designing conversational recommender systems. From the collected data, we developed a decision model to assist researchers in selecting the most suitable models for their systems. Additionally, we performed two case studies to evaluate the effectiveness of our proposed decision model. Results: Our study analyzed 59 distinct models and identified 74 commonly used features. We provided insights into potential model combinations, trends in model selection, quality concerns, evaluation measures, and frequently used dat
    
[^5]: 用于动态电子健康记录信息检索的机器学习概念化

    Conceptualizing Machine Learning for Dynamic Information Retrieval of Electronic Health Record Notes. (arXiv:2308.08494v1 [cs.IR])

    [http://arxiv.org/abs/2308.08494](http://arxiv.org/abs/2308.08494)

    该论文提出了一种概念化的机器学习方法，通过使用电子健康记录的审计日志作为监督，实现在特定临床背景下、特定时间点的笔记相关性检索。实验证明该方法在预测个别笔记撰写会话中哪些笔记会被阅读方面具有很高的准确性，并且临床医生的用户研究结果显示该框架可以帮助临床医生更高效地检索相关信息。

    

    临床医生花费大量时间筛选病人笔记并在电子健康记录（EHR）中记录是临床医生倦怠的主要原因。通过在记录过程中主动和动态地检索相关笔记，我们可以减少查找相关病例历史所需的工作量。在这项工作中，我们概念化了使用EHR审计日志作为机器学习的来源，以监督特定临床背景下、特定时间点的笔记相关性。我们的评估重点放在紧急科室的动态检索上，这是一个具有独特信息检索和笔记编写模式的高重症设置。我们显示我们的方法在预测哪些笔记会在个别笔记撰写会话中被阅读方面可以实现0.963的AUC。此外，我们对多名临床医生进行了用户研究，发现我们的框架可以帮助临床医生更高效地检索相关信息。通过展示我们的框架和...

    The large amount of time clinicians spend sifting through patient notes and documenting in electronic health records (EHRs) is a leading cause of clinician burnout. By proactively and dynamically retrieving relevant notes during the documentation process, we can reduce the effort required to find relevant patient history. In this work, we conceptualize the use of EHR audit logs for machine learning as a source of supervision of note relevance in a specific clinical context, at a particular point in time. Our evaluation focuses on the dynamic retrieval in the emergency department, a high acuity setting with unique patterns of information retrieval and note writing. We show that our methods can achieve an AUC of 0.963 for predicting which notes will be read in an individual note writing session. We additionally conduct a user study with several clinicians and find that our framework can help clinicians retrieve relevant information more efficiently. Demonstrating that our framework and m
    
[^6]: 点击率预测的时间兴趣网络

    Temporal Interest Network for Click-Through Rate Prediction. (arXiv:2308.08487v1 [cs.IR])

    [http://arxiv.org/abs/2308.08487](http://arxiv.org/abs/2308.08487)

    本文提出了时间兴趣网络（TIN），用于捕捉行为与目标之间的四重语义和时间相关性，以预测点击率的效果和已有方法对这种相关性的学习程度尚不清楚。

    

    用户行为的历史是预测点击率最重要的特征之一，因为它们与目标项目具有强烈的语义和时间相关性。虽然已有文献分别研究了这些相关性，但尚未分析它们的组合，即行为语义、目标语义、行为时间和目标时间的四重相关性。这种相关性对性能的影响以及现有方法学习这种相关性的程度尚不清楚。为了填补这一空白，我们在实践中测量了四重相关性，并观察到直观而强大的四重模式。我们测量了几种代表性的用户行为方法的学习相关性，但令人惊讶的是，它们都没有学习到这样的模式，特别是时间模式。在本文中，我们提出了时间兴趣网络（TIN）来捕捉行为与目标之间的四重语义和时间相关性。

    The history of user behaviors constitutes one of the most significant characteristics in predicting the click-through rate (CTR), owing to their strong semantic and temporal correlation with the target item. While the literature has individually examined each of these correlations, research has yet to analyze them in combination, that is, the quadruple correlation of (behavior semantics, target semantics, behavior temporal, and target temporal). The effect of this correlation on performance and the extent to which existing methods learn it remain unknown. To address this gap, we empirically measure the quadruple correlation and observe intuitive yet robust quadruple patterns. We measure the learned correlation of several representative user behavior methods, but to our surprise, none of them learn such a pattern, especially the temporal one.  In this paper, we propose the Temporal Interest Network (TIN) to capture the quadruple semantic and temporal correlation between behaviors and th
    
[^7]: TBIN: 模型化长文本行为数据用于CTR预测

    TBIN: Modeling Long Textual Behavior Data for CTR Prediction. (arXiv:2308.08483v1 [cs.IR])

    [http://arxiv.org/abs/2308.08483](http://arxiv.org/abs/2308.08483)

    TBIN模型通过局部敏感哈希算法和基于块位移的自注意力方法解决了利用长文本用户行为数据进行CTR预测时的截断问题和模型表达能力问题。

    

    点击率（CTR）预测在推荐系统的成功中起着关键作用。受到最近语言模型（LMs）的繁荣影响，许多研究通过以文本格式组织用户行为数据，并利用LMs来在语义层面上理解用户兴趣来改进预测。虽然有前景，但这些研究不得不截断文本数据以减少LMs中自注意力的二次计算开销。然而，已经研究表明长时间的用户行为数据可以显著提高CTR预测。此外，这些工作通常将用户的多样化兴趣压缩成一个特征向量，这阻碍了模型的表达能力。本文提出了一种基于文本行为的兴趣切块网络（TBIN），通过结合高效的局部敏感哈希算法和基于块位移的自注意力方法来解决上述限制。得到的用户多样化兴趣是

    Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are
    
[^8]: CDR：用于去偏推荐的保守双重稳健学习

    CDR: Conservative Doubly Robust Learning for Debiased Recommendation. (arXiv:2308.08461v1 [cs.IR])

    [http://arxiv.org/abs/2308.08461](http://arxiv.org/abs/2308.08461)

    该论文提出了一种保守双重稳健策略（CDR），用于解决推荐系统中存在的有毒插补问题。CDR通过审查插补的均值和方差来过滤插补，结果显示CDR具有降低方差和改进尾部界限的优势，并且能够显著提升性能并减少有毒插补的频率。

    

    在推荐系统中，用户行为数据往往是观察性的而不是实验性的，导致数据中普遍存在偏差。因此，解决偏差问题已成为推荐系统领域的一个重要挑战。最近，双重稳健学习（DR）由于其卓越的性能和稳健的特性而受到了广泛关注。然而，我们的实验结果表明，现有的DR方法在存在所谓的有毒插补（Poisonous Imputation）时受到严重影响，插补明显偏离真实数据并适得其反。为了解决这个问题，本文提出了一种保守双重稳健策略（CDR），通过审查插补的均值和方差来过滤插补。理论分析表明，CDR可以降低方差并改进尾部界限。此外，我们的实验研究表明，CDR显著提升了性能，并且确实减少了有毒插补的频率。

    In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive.  To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.
    
[^9]: 动态邮件重新排序问题的固定算法平衡

    Stationary Algorithmic Balancing For Dynamic Email Re-Ranking Problem. (arXiv:2308.08460v1 [cs.IR])

    [http://arxiv.org/abs/2308.08460](http://arxiv.org/abs/2308.08460)

    提出了一种名为MOSR的算法，用于解决动态邮件重新排序问题。该算法使用自适应控制模型来平衡亲密度，及时性和简洁性等标准，并能够适应偏好的变化。在恩隆邮件数据集上的实验结果表明，MOSR在非稳态偏好下表现出更好的性能，并且在具有高方差的邮件特征的小型抽样数据集上也能保持稳定的排名。

    

    电子邮件平台需要生成满足用户偏好并随时间变化的个性化邮件排序。我们将其作为一个基于三个标准的推荐问题来处理：亲密度（发件人和主题与用户的相关度），及时性（邮件的最近程度）和简洁性（邮件的简短程度）。我们提出了MOSR（多目标稳态推荐器），一种新颖的在线算法，它使用自适应控制模型来动态平衡这些标准并适应偏好变化。我们在恩隆邮件数据集上评估了MOSR，这是一个包含大量实际邮件的集合，并将其与其他基准进行了比较。结果显示MOSR取得了更好的性能，尤其是在非稳态偏好下，用户随时间不同程度地评估不同的标准。我们还在一个小型抽样数据集上测试了MOSR的鲁棒性，该数据集的邮件特征变化很大，并展示了它在不同样本中保持稳定的排名。

    Email platforms need to generate personalized rankings of emails that satisfy user preferences, which may vary over time. We approach this as a recommendation problem based on three criteria: closeness (how relevant the sender and topic are to the user), timeliness (how recent the email is), and conciseness (how brief the email is). We propose MOSR (Multi-Objective Stationary Recommender), a novel online algorithm that uses an adaptive control model to dynamically balance these criteria and adapt to preference changes. We evaluate MOSR on the Enron Email Dataset, a large collection of real emails, and compare it with other baselines. The results show that MOSR achieves better performance, especially under non-stationary preferences, where users value different criteria more or less over time. We also test MOSR's robustness on a smaller down-sampled dataset that exhibits high variance in email characteristics, and show that it maintains stable rankings across different samples. Our work
    
[^10]: 知识提示调优的顺序推荐

    Knowledge Prompt-tuning for Sequential Recommendation. (arXiv:2308.08459v1 [cs.IR])

    [http://arxiv.org/abs/2308.08459](http://arxiv.org/abs/2308.08459)

    该论文提出了知识提示调优的顺序推荐(KP4SR)方法，通过引入外部知识库和构建知识提示，解决了顺序推荐中的语义差距和信息损失问题，从而提高了推荐性能。

    

    预训练语言模型(PLMs)在顺序推荐(SR)中展示出强大的性能，用于提取通用知识。然而，现有方法仍然缺乏领域知识，并且很难捕捉用户的细粒度偏好。同时，许多传统的SR方法通过整合辅助信息来改善这个问题，但却遭受信息损失的困扰。总而言之，我们认为一个好的推荐系统应该同时利用通用知识和领域知识。因此，我们引入了一个外部知识库，并提出了知识提示调优的顺序推荐(KP4SR)。具体来说，我们构建了一组关系模板，并将结构化知识图谱(KG)转化为知识提示，以解决语义差距的问题。然而，知识提示破坏了原始数据结构并引入了大量的噪音。我们进一步构建了一个知识树，并提出了一个知识树的方法来减少噪音并提高推荐性能。

    Pre-trained language models (PLMs) have demonstrated strong performance in sequential recommendation (SR), which are utilized to extract general knowledge. However, existing methods still lack domain knowledge and struggle to capture users' fine-grained preferences. Meanwhile, many traditional SR methods improve this issue by integrating side information while suffering from information loss. To summarize, we believe that a good recommendation system should utilize both general and domain knowledge simultaneously. Therefore, we introduce an external knowledge base and propose Knowledge Prompt-tuning for Sequential Recommendation (\textbf{KP4SR}). Specifically, we construct a set of relationship templates and transform a structured knowledge graph (KG) into knowledge prompts to solve the problem of the semantic gap. However, knowledge prompts disrupt the original data structure and introduce a significant amount of noise. We further construct a knowledge tree and propose a knowledge tre
    
[^11]: CSPM: 用于按需食品配送CTR预测的对比时空偏好模型

    CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction in On-Demand Food Delivery Services. (arXiv:2308.08446v1 [cs.IR])

    [http://arxiv.org/abs/2308.08446](http://arxiv.org/abs/2308.08446)

    本研究提出了CSPM模型，通过对比学习和时空偏好提取来解决按需食品配送CTR预测中的时空信息建模问题。

    

    点击率（CTR）预测是在线按需食品配送（OFD）平台中一项关键任务，用于准确估计用户点击食品项目的概率。与淘宝和亚马逊等通用电商平台不同，OFD平台上的用户行为和兴趣更加与地点和时间相关，这是因为存在有限的配送范围和区域商品供应。然而，现有的OFD场景下的CTR预测算法主要集中于捕捉来自历史行为序列的兴趣，未能有效地对特征中的复杂时空信息进行建模，导致性能较差。为解决这一挑战，本文提出了对比时空偏好模型（CSPM），通过对比时空表示学习（CSRL）、时空偏好提取器（StPE）和时空信息过滤器（StIF）三个模块，对不同搜索状态下的用户偏好进行建模。

    Click-through rate (CTR) prediction is a crucial task in the context of an online on-demand food delivery (OFD) platform for precisely estimating the probability of a user clicking on food items. Unlike universal e-commerce platforms such as Taobao and Amazon, user behaviors and interests on the OFD platform are more location and time-sensitive due to limited delivery ranges and regional commodity supplies. However, existing CTR prediction algorithms in OFD scenarios concentrate on capturing interest from historical behavior sequences, which fails to effectively model the complex spatiotemporal information within features, leading to poor performance. To address this challenge, this paper introduces the Contrastive Sres under different search states using three modules: contrastive spatiotemporal representation learning (CSRL), spatiotemporal preference extractor (StPE), and spatiotemporal information filter (StIF). CSRL utilizes a contrastive learning framework to generate a spatiotem
    
[^12]: 大型语言模型在推荐系统中的双步接地范式

    A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems. (arXiv:2308.08434v1 [cs.IR])

    [http://arxiv.org/abs/2308.08434](http://arxiv.org/abs/2308.08434)

    本文提出了一个名为BIGRec的两步接地框架，通过将大型语言模型与推荐空间接地，生成有意义的标记，并识别相应的实际项目，来探究大型语言模型在推荐系统中的全面排序能力。

    

    随着推荐领域对大型语言模型（LLMs）的关注加强，针对推荐目的（称为LLM4Rec）优化LLMs的重要性在提供推荐方面得到了增强。然而，现有的LLM4Rec方法通常使用有限的候选集来评估性能，这可能无法准确反映模型的整体排序能力。在本文中，我们的目标是调查LLMs的全面排序能力，并提出一个名为BIGRec（推荐的双步接地范式）的两步接地框架。它首先通过微调将LLMs与推荐空间接地，生成与项目相关的有意义的标记，然后识别与生成的标记相对应的适当实际项目。通过在两个数据集上进行广泛实验，我们证明了其卓越的性能、处理少样本场景的能力以及在多个数据集上的通用性。

    As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations. However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities. In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation). It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens. By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across mu
    
[^13]: 知识增强的多标签少样本产品属性值提取

    Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction. (arXiv:2308.08413v1 [cs.IR])

    [http://arxiv.org/abs/2308.08413](http://arxiv.org/abs/2308.08413)

    这篇论文提出了一种知识增强的多标签少样本产品属性值提取方法，通过利用生成的标签描述和类别信息来学习更具有区分性的原型，并整合混合注意力来减少噪声和捕捉更多信息丰富的语义。实验结果表明，该方法在提取未见过的属性值对方面表现优于其他方法。

    

    现有的属性值提取（AVE）模型需要大量的标记数据进行训练。然而，现实世界中的电子商务每天都会有带有新属性值对的新产品进入市场。因此，我们在多标签少样本学习（FSL）中制定AVE，旨在基于少量的训练示例提取未见过的属性值对。我们提出了一种基于原型网络的知识增强注意力框架（KEAF），利用生成的标签描述和类别信息来学习更具有区分性的原型。此外，KEAF通过计算与标签相关的权重和查询相关的权重，整合了混合注意力，以减少噪声并捕捉更多信息丰富的语义。为了实现多标签推理，KEAF进一步通过整合支持集和查询集的语义信息来学习动态阈值。在两个数据集上进行的大量实验和消融研究表明，KEAF的性能优于其他方法。

    Existing attribute-value extraction (AVE) models require large quantities of labeled data for training. However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce. Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples. We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes. Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights. To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set. Extensive experiments with ablation studies conducted on two datasets demonstrate that KEAF outpe
    
[^14]: 基于内容的视频流媒体平台推荐引擎

    Content-based Recommendation Engine for Video Streaming Platform. (arXiv:2308.08406v1 [cs.IR])

    [http://arxiv.org/abs/2308.08406](http://arxiv.org/abs/2308.08406)

    本文提出了一种基于内容的推荐引擎，通过计算文档中单词的相关性和使用余弦相似度方法来推荐视频给用户。同时，还通过计算精确率、召回率和F1得分来评估引擎的性能。

    

    推荐引擎使用机器学习算法向用户建议内容、产品或服务。本文提出了一种基于内容的推荐引擎，根据用户之前的兴趣和选择，向用户提供视频推荐。我们将使用TF-IDF文本向量化方法来确定文档中单词的相关性。然后通过计算它们之间的余弦相似度，找出每个内容之间的相似性。最后，根据得到的相似度分数值，引擎将向用户推荐视频。另外，我们将通过计算精确率、召回率和F1得分来衡量引擎的性能。

    Recommendation engine suggest content, product or services to the user by using machine learning algorithm. This paper proposed a content-based recommendation engine for providing video suggestion to the user based on their previous interests and choices. We will use TF-IDF text vectorization method to determine the relevance of words in a document. Then we will find out the similarity between each content by calculating cosine similarity between them. Finally, engine will recommend videos to the users based on the obtained similarity score value. In addition, we will measure the engine's performance by computing precision, recall, and F1 core of the proposed system.
    
[^15]: 推进神经信息检索中的持续终身学习：定义、数据集、框架和实证评估

    Advancing continual lifelong learning in neural information retrieval: definition, dataset, framework, and empirical evaluation. (arXiv:2308.08378v1 [cs.IR])

    [http://arxiv.org/abs/2308.08378](http://arxiv.org/abs/2308.08378)

    本文提出了一个系统的持续神经信息检索任务定义，并提供了一个模拟连续信息检索的多主题数据集。同时，还提出了一个全面的持续神经信息检索框架，能够防止灾难性遗忘并提高先前学习任务的性能。

    

    持续学习是指机器学习模型在学习和适应新信息的同时，不影响其在先前学习任务上的性能。尽管已有多项研究探讨了信息检索任务中的持续学习方法，但仍缺乏明确的任务定义，并且目前尚不清楚在这种背景下典型的学习策略的表现如何。为了应对这一挑战，本文提出了一种系统的持续神经信息检索任务定义，并提供了一个模拟连续信息检索的多主题数据集。随后，本文提出了一个全面的持续神经信息检索框架，包括典型检索模型和持续学习策略。实证评估结果表明，所提出的框架能够成功地防止神经信息检索中的灾难性遗忘，并提高先前学习任务的性能。结果表明，基于嵌入的检索方式较传统的基于索引的检索方式具有优势，并且持续学习策略能够有效地提升检索性能。

    Continual learning refers to the capability of a machine learning model to learn and adapt to new information, without compromising its performance on previously learned tasks. Although several studies have investigated continual learning methods for information retrieval tasks, a well-defined task formulation is still lacking, and it is unclear how typical learning strategies perform in this context. To address this challenge, a systematic task formulation of continual neural information retrieval is presented, along with a multiple-topic dataset that simulates continuous information retrieval. A comprehensive continual neural information retrieval framework consisting of typical retrieval models and continual learning strategies is then proposed. Empirical evaluations illustrate that the proposed framework can successfully prevent catastrophic forgetting in neural information retrieval and enhance performance on previously learned tasks. The results indicate that embedding-based retr
    
[^16]: 元学习是否是解决推荐系统中冷启动问题的正确方法？

    Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?. (arXiv:2308.08354v1 [cs.IR])

    [http://arxiv.org/abs/2308.08354](http://arxiv.org/abs/2308.08354)

    本文研究表明，针对推荐系统中的冷启动问题，元学习技术在处理深度学习模型时已成为最受欢迎的方法。然而，当前的元学习方法在实际推荐系统中并不实用，因为这些系统拥有庞大的用户和物品数量，且有严格的延迟要求。

    

    推荐系统已经成为现代在线产品和服务的基础构建模块，并对用户体验产生了重大影响。在过去的几年中，深度学习方法吸引了大量的研究，并在现代实际推荐系统中得到广泛应用。然而，处理冷启动设置下的推荐问题，例如当用户在系统中的互动有限时，仍然是一个远未解决的问题。元学习技术，尤其是基于优化的元学习，最近已成为学术研究文献中处理推荐系统中冷启动问题的最流行方法。然而，目前的元学习方法对于拥有数十亿用户和物品以及严格的延迟要求的现实推荐系统来说并不实用。在本文中，我们展示了在常用基准上获得类似或更高性能是可能的。

    Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience. In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems. Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved. Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems. However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements. In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchma
    
[^17]: 具备背景信息的相位恢复：减少参考和高效算法

    Phase Retrieval with Background Information: Decreased References and Efficient Methods. (arXiv:2308.08328v1 [cs.IR])

    [http://arxiv.org/abs/2308.08328](http://arxiv.org/abs/2308.08328)

    本文提出了具备背景信息的相位恢复方法，通过改进方法与理论结果，成功减少了对背景信息的需求。

    

    傅里叶相位恢复是一个严重病态的反问题，在各种应用中都会出现。为了保证唯一解并减少对初始化的依赖，可以利用背景信息作为结构先验。然而，在高分辨率成像时，对背景信息的需求可能是具有挑战性的。与此同时，之前提出的投影梯度下降（PGD）方法也需要大量的背景信息。本文提出了关于背景信息需求的改进理论结果，并提出了两种基于Douglas Rachford（DR）的方法。分析结果表明，在2-D信号相比于1-D信号中，为了确保唯一解所需的背景可以减少将近$1/2$。通过将结果推广到$d$-dimension，我们证明了超过信号长度$(2^{\frac{d+1}{d}}-1)$倍的背景信息足以确保唯一解。

    Fourier phase retrieval(PR) is a severely ill-posed inverse problem that arises in various applications. To guarantee a unique solution and relieve the dependence on the initialization, background information can be exploited as a structural priors. However, the requirement for the background information may be challenging when moving to the high-resolution imaging. At the same time, the previously proposed projected gradient descent(PGD) method also demands much background information.  In this paper, we present an improved theoretical result about the demand for the background information, along with two Douglas Rachford(DR) based methods. Analytically, we demonstrate that the background required to ensure a unique solution can be decreased by nearly $1/2$ for the 2-D signals compared to the 1-D signals. By generalizing the results into $d$-dimension, we show that the length of the background information more than $(2^{\frac{d+1}{d}}-1)$ folds of the signal is sufficient to ensure th
    
[^18]: 基于大型语言模型的文档扩展预训练用于稠密通道检索

    Pre-training with Large Language Model-based Document Expansion for Dense Passage Retrieval. (arXiv:2308.08285v1 [cs.IR])

    [http://arxiv.org/abs/2308.08285](http://arxiv.org/abs/2308.08285)

    本文研究了基于大型语言模型的文档扩展预训练对稠密通道检索的潜力，通过利用该方法进行查询生成并传递扩展的知识给检索器，实验证明这种方法显著提高了大规模网络搜索任务的检索性能。

    

    本文系统地研究了基于大型语言模型（LLM）的文档扩展预训练在稠密通道检索中的潜力。具体来说，我们利用LLMs的能力进行文档扩展，即查询生成，并通过针对通道检索的预训练策略有效地将扩展的知识传递给检索器。这些策略包括对比学习和瓶颈查询生成。此外，我们还采用了课程学习策略来减少对LLM推理的依赖。实验结果表明，基于LLM的文档扩展预训练显著提高了大规模网络搜索任务的检索性能。我们的工作展示了强大的零-shot和跨领域检索能力，在没有人工标注数据的情况下更具广泛的应用性。

    In this paper, we systematically study the potential of pre-training with Large Language Model(LLM)-based document expansion for dense passage retrieval. Concretely, we leverage the capabilities of LLMs for document expansion, i.e. query generation, and effectively transfer expanded knowledge to retrievers using pre-training strategies tailored for passage retrieval. These strategies include contrastive learning and bottlenecked query generation. Furthermore, we incorporate a curriculum learning strategy to reduce the reliance on LLM inferences. Experimental results demonstrate that pre-training with LLM-based document expansion significantly boosts the retrieval performance on large-scale web-search tasks. Our work shows strong zero-shot and out-of-domain retrieval abilities, making it more widely applicable for retrieval when initializing with no human-labeled data.
    
[^19]: 从偏差和噪声的观看时长中揭示用户兴趣的视频推荐方法

    Uncovering User Interest from Biased and Noised Watch Time in Video Recommendation. (arXiv:2308.08120v1 [cs.IR])

    [http://arxiv.org/abs/2308.08120](http://arxiv.org/abs/2308.08120)

    本研究分析了视频推荐中观看时长的生成机制，提出了一种基于因果推断的视频推荐方法，减轻了持续时间偏差和噪声观看带来的问题，并改善了从观看时长中揭示用户兴趣的效果。

    

    在视频推荐中，观看时长常被用作用户兴趣的指标。然而，观看时长不仅受到用户兴趣匹配的影响，还受到其他因素的影响，比如持续时间偏差和噪声观看。持续时间偏差指的是用户倾向于在视频持续时间较长时花费更多时间观看，而不考虑实际的兴趣水平。另一方面，噪声观看描述了用户花时间判断他们是否喜欢一个视频，这可能导致用户花时间观看他们不喜欢的视频。因此，持续时间偏差和噪声观看的存在使得观看时长成为一个不足以表示用户兴趣的标签。此外，当前的方法主要解决持续时间偏差而忽视了噪声观看的影响，这可能限制了它们在从观看时长中揭示用户兴趣方面的有效性。在本研究中，我们首先从统一的因果视角分析了用户观看时长的生成机制。具体来说，我们提出了一种基于因果推断的视频推荐方法，以减轻持续时间偏差和噪声观看带来的问题，并改善从观看时长中揭示用户兴趣的效果。

    In the video recommendation, watch time is commonly adopted as an indicator of user interest. However, watch time is not only influenced by the matching of users' interests but also by other factors, such as duration bias and noisy watching. Duration bias refers to the tendency for users to spend more time on videos with longer durations, regardless of their actual interest level. Noisy watching, on the other hand, describes users taking time to determine whether they like a video or not, which can result in users spending time watching videos they do not like. Consequently, the existence of duration bias and noisy watching make watch time an inadequate label for indicating user interest. Furthermore, current methods primarily address duration bias and ignore the impact of noisy watching, which may limit their effectiveness in uncovering user interest from watch time. In this study, we first analyze the generation mechanism of users' watch time from a unified causal viewpoint. Specific
    
[^20]: 基于去中心化图神经网络的隐私保护推荐系统

    Decentralized Graph Neural Network for Privacy-Preserving Recommendation. (arXiv:2308.08072v1 [cs.IR])

    [http://arxiv.org/abs/2308.08072](http://arxiv.org/abs/2308.08072)

    本文提出了一种去中心化图神经网络（DGREC）框架，用于隐私保护推荐，其中用户可以选择公开他们的交互。该框架通过图构建、局部梯度计算和全局梯度传递三个阶段实现，同时引入了名为安全梯度共享的差分隐私机制，保护用户的私密数据。

    

    在不违反用户隐私的情况下构建基于图神经网络（GNN）的推荐系统是具有挑战性的。现有方法可以分为联邦GNN和去中心化GNN两种。然而，这两种方法都存在问题，如通信效率低和隐私泄露。本文提出了一种新的去中心化GNN框架，名为DGREC，用于隐私保护推荐，用户可以选择公开他们的交互。该框架包括三个阶段，即图构建、局部梯度计算和全局梯度传递。第一阶段为每个用户构建了一个本地内部物品超图和一个全局用户间图。第二阶段对用户偏好进行建模，并在每个本地设备上计算梯度。第三阶段设计了一种名为安全梯度共享的本地差分隐私机制，以保护用户的私密数据。我们在三个公共数据集上进行了大量实验，验证了我们框架的一贯优越性。

    Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framewo
    
[^21]: 用ChatGPT变革金融领域的情绪分析

    Transforming Sentiment Analysis in the Financial Domain with ChatGPT. (arXiv:2308.07935v1 [cs.CL])

    [http://arxiv.org/abs/2308.07935](http://arxiv.org/abs/2308.07935)

    本研究使用ChatGPT 3.5来进行金融情绪分析，特别关注外汇市场，通过零-shot提示方法，在精心策划的数据集上评估了其性能，并发现与传统模型相比，ChatGPT在金融情绪分析中表现出约35％的性能提升。

    

    金融情绪分析在解读市场趋势和指导战略交易决策中起着关键作用。尽管已经使用了先进的深度学习技术和语言模型来改进金融情绪分析，但本研究通过探索大型语言模型（特别是ChatGPT 3.5）在金融情绪分析中的潜力，特别强调外汇市场（forex），开创了新的领域。采用零-shot提示方法，在一份经过精心策划的外汇相关新闻标题数据集上检验多个ChatGPT提示，并使用精确度、召回率、F1得分和情绪分类的平均绝对误差（MAE）等指标评估性能。此外，我们还探讨了预测情绪和市场回报之间的相关性作为一种额外的评估方法。与FinBERT相比，ChatGPT在情绪分析方面的性能提高了约35％。

    Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero-shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1-score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an additional evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35\% enhanced performance in sentiment 
    
[^22]: SPM: Meituan搜索中用于相关性建模的结构化预训练和匹配架构

    SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search. (arXiv:2308.07711v1 [cs.IR])

    [http://arxiv.org/abs/2308.07711](http://arxiv.org/abs/2308.07711)

    本论文提出了一种用于在Meituan搜索中进行相关性建模的新颖两阶段预训练和匹配架构。

    

    在电商搜索中，查询和文档之间的相关性是满足用户体验的基本要求。与传统的电商平台不同，用户在美团等生活服务平台上进行搜索主要是为了产品供应商，这些供应商通常拥有丰富的结构化信息，例如名称、地址、类别、成千上万的产品。使用这些丰富的结构化内容进行搜索相关性建模具有挑战性，主要存在以下问题：（1）不同字段的结构化文档存在语言分布差异，无法直接采用预训练的语言模型方法（如BERT）。（2）不同字段通常具有不同的重要性，且长度差异很大，很难提取对相关性匹配有帮助的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配架构，用于丰富结构的相关性匹配。

    In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching.  To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structure
    
[^23]: 利用异构数据进行兴趣点推荐的调查

    A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous Data. (arXiv:2308.07426v1 [cs.IR])

    [http://arxiv.org/abs/2308.07426](http://arxiv.org/abs/2308.07426)

    本文针对旅游领域的兴趣点推荐问题进行了调查研究，探讨了利用异构数据解决旅途中兴趣点推荐问题的潜力与挑战。

    

    旅游是推荐系统的一个重要应用领域。在这个领域中，推荐系统主要负责为交通、住宿、兴趣点或旅游服务提供个性化推荐。在这些任务中，尤其是对个体游客可能感兴趣的兴趣点进行推荐的问题近年来引起了越来越多的关注。然而，在游客“旅途中”提供兴趣点推荐可能会面临特殊挑战，因为用户的上下文变化多样。随着互联网的快速发展和当今各种在线服务的大量数据，各种异构数据源的数据已经变得可用，这些异构数据源为解决旅途中兴趣点推荐问题的挑战提供了巨大潜力。在这项工作中，我们从异构数据的角度提供了2017年至2022年间已发表的兴趣点推荐研究的综述。

    Tourism is an important application domain for recommender systems. In this domain, recommender systems are for example tasked with providing personalized recommendations for transportation, accommodation, points-of-interest (POIs), or tourism services. Among these tasks, in particular the problem of recommending POIs that are of likely interest to individual tourists has gained growing attention in recent years. Providing POI recommendations to tourists \emph{during their trip} can however be especially challenging due to the variability of the users' context. With the rapid development of the Web and today's multitude of online services, vast amounts of data from various sources have become available, and these heterogeneous data sources represent a huge potential to better address the challenges of in-trip POI recommendation problems. In this work, we provide a comprehensive survey of published research on POI recommendation between 2017 and 2022 from the perspective of heterogeneou
    
[^24]: 超越语义：利用自我监督学习的行为增强相关模型的学习

    Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])

    [http://arxiv.org/abs/2308.05379](http://arxiv.org/abs/2308.05379)

    这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。

    

    相关建模旨在定位与对应查询相关的理想项目，这对于搜索引擎确保用户体验非常重要。虽然大多数传统方法通过评估查询与项目之间的语义相似性来解决这个问题，但纯语义匹配并不是唯一的方法。实际上，从用户搜索记录的历史行为数据中提取的辅助查询-项目交互可以提供进一步揭示用户搜索意图的线索。得益于此，我们设计了一种新颖的基于行为增强相关学习模型的支付宝搜索模型（BARL-ASe），该模型利用目标项目的相邻查询和目标查询的相邻项目来补充目标查询-项目的语义匹配。具体而言，我们的模型建立了多层共同注意力，从相邻和目标视图中提取了粗粒度和细粒度的语义表示。模型随后采用邻居-目标的自我监督学习来提高精度和鲁棒性。

    Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
    
[^25]: LLM-Rec: 通过引导大型语言模型进行个性化推荐

    LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])

    [http://arxiv.org/abs/2307.15780](http://arxiv.org/abs/2307.15780)

    本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。

    

    本文通过输入增强技术，研究了多种不同的引导策略，以提高大型语言模型（LLM）在个性化内容推荐方面的性能。我们提出的方法名为LLM-Rec，包括四种不同的引导策略：（1）基础引导，（2）推荐驱动引导，（3）参与引导引导，和（4）推荐驱动+参与引导引导。实验证明，将原始内容描述与LLM生成的增强输入文本结合起来，采用这些引导策略可以提高推荐性能。这一发现强调了在个性化内容推荐中，通过引入多样的引导和输入增强技术来提升大型语言模型的推荐能力的重要性。

    We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
    
[^26]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    

