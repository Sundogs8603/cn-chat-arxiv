# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Categorization of Complexity Classes for Information Retrieval and Synthesis Using Natural Logic](https://arxiv.org/abs/2402.18566) | 提出了一个新的框架，使用自然演绎演算来分析问题答案的复杂度，划分了前向、查询和规划三个明确的片段，这是一个全新且独特的方法。 |
| [^2] | [Approaching Human-Level Forecasting with Language Models](https://arxiv.org/abs/2402.18563) | 该研究探讨了使用语言模型（LMs）进行预测未来事件的能力，开发了一种检索增强型LM系统，通过在竞争性预测平台收集数据集，并在知识截止日期后评估系统性能，发现该系统能够准确预测未来事件并在某些情况下超越人类预测者。 |
| [^3] | [Graph Regularized Encoder Training for Extreme Classification](https://arxiv.org/abs/2402.18434) | 本文提出了一种图正则化编码器训练方法用于极端分类，在实践中发现使用图数据来规范编码器训练比实施 GCN 效果更好。 |
| [^4] | [DynaWarp -- Efficient, large-scale log storage and retrieval](https://arxiv.org/abs/2402.18355) | DynaWarp提出了一种新的成员草图结构，可以高效地回答多集多成员查询，相比于倒排索引和成员草图，具有更高的存储效率和查询吞吐量。 |
| [^5] | [Detecting Anti-vaccine Content on Twitter using Multiple Message-Based Network Representations](https://arxiv.org/abs/2402.18335) | 分析了来自Twitter的多个社交网络表征，证明了通过全局和局部网络度量指标可以有效检测有争议和无争议的反疫苗标签和关键词 |
| [^6] | [Prospect Personalized Recommendation on Large Language Model-based Agent Platform](https://arxiv.org/abs/2402.18240) | 提出了一种基于大型语言模型代理平台的个性化推荐系统Rec4Agentverse，强调代理项和代理推荐器之间的合作，促进个性化信息服务，提升信息交换，并展望了其演进为支持互动和信息交换的三个阶段 |
| [^7] | [Sequence-level Semantic Representation Fusion for Recommender Systems](https://arxiv.org/abs/2402.18166) | 研究通过序列级语义融合的方法，在推荐系统中更好地整合文本和ID特征，提高推荐性能 |
| [^8] | [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](https://arxiv.org/abs/2402.18154) | 通过信息流的视角解释并干预语言模型中的知识冲突，提出了一种名为Pruning Head via PatH的方法来缓解冲突 |
| [^9] | [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](https://arxiv.org/abs/2402.18150) | 本文提出了一种名为InFO-RAG的无监督信息细化训练方法，将大型语言模型在检索增强生成中的角色定义为“信息细化者”，帮助模型更好地整合检索信息以生成更加简洁、准确和完整的文本。 |
| [^10] | [Corpus-Steered Query Expansion with Large Language Models](https://arxiv.org/abs/2402.18031) | 通过引入语料库引导的查询扩展（CSQE），结合大型语言模型的知识增强扩展，改善了查询与目标文档之间的相关性预测。 |
| [^11] | [[RE] Modeling Personalized Item Frequency Information for Next-basket Recommendation](https://arxiv.org/abs/2402.17925) | 复制并扩展了使用个性化商品频率信息进行下一个购物篮推荐的论文研究，利用多个数据集验证了TIFU-KNN模型的优越性，并引入了新的$\beta$-VAE架构来建模NBR。 |
| [^12] | [A Language Model based Framework for New Concept Placement in Ontologies](https://arxiv.org/abs/2402.17897) | 提出了一种基于语言模型的框架，用于将从文本中提取的新概念插入到本体中，在边搜索、边形成和增强、边选择三个步骤中分别利用神经方法，并在 SNOMED CT 本体和 MedMentions 实体链接基准上进行了评估 |
| [^13] | [JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability](https://arxiv.org/abs/2402.17887) | JMLR通过联合训练信息检索系统和大型语言模型，在医学领域提高问题回答系统性能，降低计算资源需求，增强模型利用医疗知识进行推理和回答问题的能力。 |
| [^14] | [UniRetriever: Multi-task Candidates Selection for Various Context-Adaptive Conversational Retrieval](https://arxiv.org/abs/2402.16261) | 提出了一种UniRetriever框架，利用双编码器架构和两个损失约束实现了多任务候选者选择，适用于不同情境下的对话检索任务。 |
| [^15] | [ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval](https://arxiv.org/abs/2402.15838) | ListT5通过Fusion-in-Decoder技术实现列表重排，在零-shot检索任务中表现出优越性能，效率高于之前的模型，并解决了以往列表重排器的中间段丢失问题。 |
| [^16] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^17] | [Towards Efficient Communication and Secure Federated Recommendation System via Low-rank Training](https://arxiv.org/abs/2401.03748) | 通过相关低秩结构（CoLR）框架，实现了联邦推荐系统中高效的通信和安全性，显著降低了通信开销同时保持与安全聚合协议的兼容性。 |
| [^18] | [Automatic ESG Assessment of Companies by Mining and Evaluating Media Coverage Data: NLP Approach and Tool](https://arxiv.org/abs/2212.06540) | 通过NLP方法和工具，本研究旨在从文本媒体反应中自动提取ESG相关信息，实现公司ESG的自动评估。 |
| [^19] | [Safe Collaborative Filtering.](http://arxiv.org/abs/2306.05292) | 本论文提出了一个安全的协同过滤算法，通过最小化条件风险价值，提高低满意度用户的推荐质量。在实际数据集中表现出色，同时也保持总体推荐质量。 |
| [^20] | [A Comprehensive Survey on Deep Graph Representation Learning.](http://arxiv.org/abs/2304.05055) | 本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。 |

# 详细

[^1]: 信息检索与综合的复杂度类别的分类使用自然逻辑

    A Categorization of Complexity Classes for Information Retrieval and Synthesis Using Natural Logic

    [https://arxiv.org/abs/2402.18566](https://arxiv.org/abs/2402.18566)

    提出了一个新的框架，使用自然演绎演算来分析问题答案的复杂度，划分了前向、查询和规划三个明确的片段，这是一个全新且独特的方法。

    

    鉴于大型语言模型不断增强的推理能力，信息检索变得更加复杂。现代信息检索系统不仅可以检索文档，还宣称可以根据多种不同文档、相互矛盾的数据源以及推理来综合得出答案。本文引入了一个新颖的框架，用自然演绎演算中的证明论作为分析问题答案复杂度的基础。我们的框架在于，据我们所知，没有人以此逻辑为复杂度类别基础，同时也没有任何已存在的复杂度类别用类似方法划分。我们特别识别了三个明确的片段，称为前向片段、查询片段和规划片段，我们...

    arXiv:2402.18566v1 Announce Type: new  Abstract: Given the emergent reasoning abilities of large language models, information retrieval is becoming more complex. Rather than just retrieve a document, modern information retrieval systems advertise that they can synthesize an answer based on potentially many different documents, conflicting data sources, and using reasoning. But, different kinds of questions have different answers, and different answers have different complexities. In this paper, we introduce a novel framework for analyzing the complexity of a question answer based on the natural deduction calculus as presented in Prawitz (1965). Our framework is novel both in that no one to our knowledge has used this logic as a basis for complexity classes, and also in that no other existing complexity classes to these have been delineated using any analogous methods either. We identify three decidable fragments in particular called the forward, query and planning fragments, and we com
    
[^2]: 用语言模型接近人类水平的预测能力

    Approaching Human-Level Forecasting with Language Models

    [https://arxiv.org/abs/2402.18563](https://arxiv.org/abs/2402.18563)

    该研究探讨了使用语言模型（LMs）进行预测未来事件的能力，开发了一种检索增强型LM系统，通过在竞争性预测平台收集数据集，并在知识截止日期后评估系统性能，发现该系统能够准确预测未来事件并在某些情况下超越人类预测者。

    

    预测未来事件对政策和决策制定至关重要。本研究探讨了语言模型(LMs)是否能够在竞争性人类预测者的水平上进行预测。为实现这一目标，我们开发了一种检索增强型LM系统，旨在自动搜索相关信息、生成预测和聚合预测。为了促进研究，我们收集了来自竞争性预测平台的大量问题数据集。在LM的知识截止日期之后发布的测试集下，我们评估了我们系统的端到端性能与人类预测的聚合之间的比较。平均而言，该系统接近于竞争预测者的聚合，并在某些情况下超越了它。我们的工作表明，利用LM来预测未来可能会提供准确的大规模预测，并有助于为机构决策提供信息。

    arXiv:2402.18563v1 Announce Type: cross  Abstract: Forecasting future events is important for policy and decision making. In this work, we study whether language models (LMs) can forecast at the level of competitive human forecasters. Towards this goal, we develop a retrieval-augmented LM system designed to automatically search for relevant information, generate forecasts, and aggregate predictions. To facilitate our study, we collect a large dataset of questions from competitive forecasting platforms. Under a test set published after the knowledge cut-offs of our LMs, we evaluate the end-to-end performance of our system against the aggregates of human forecasts. On average, the system nears the crowd aggregate of competitive forecasters, and in some settings surpasses it. Our work suggests that using LMs to forecast the future could provide accurate predictions at scale and help to inform institutional decision making.
    
[^3]: 图正则化编码器训练用于极端分类

    Graph Regularized Encoder Training for Extreme Classification

    [https://arxiv.org/abs/2402.18434](https://arxiv.org/abs/2402.18434)

    本文提出了一种图正则化编码器训练方法用于极端分类，在实践中发现使用图数据来规范编码器训练比实施 GCN 效果更好。

    

    arXiv:2402.18434v1 通告类型: 新的 摘要: 深度极端分类（XC）旨在训练编码器架构和配套的分类器架构，以从一个非常庞大的标签集合中为数据点打上最相关的子标签集合。在排名、推荐和标记中常见的XC应用中，通常会遇到训练数据极少的尾标签。图卷积网络（GCN）提供了一个方便但计算代价高昂的方法，可利用任务元数据并增强模型在这些设置中的准确性。本文正式确定了在若干用例中，通过用非GCN架构替换GCNs，完全可以避免GCNs的巨大计算成本。本文指出，在这些设置中，使用图数据来规范编码器训练比实施GCN更加有效。基于这些见解，提出了一种替代范式RAMEN，用于利用XC设置中的图元数据。

    arXiv:2402.18434v1 Announce Type: new  Abstract: Deep extreme classification (XC) aims to train an encoder architecture and an accompanying classifier architecture to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels for which the amount of training data is exceedingly small. Graph convolutional networks (GCN) present a convenient but computationally expensive way to leverage task metadata and enhance model accuracies in these settings. This paper formally establishes that in several use cases, the steep computational cost of GCNs is entirely avoidable by replacing GCNs with non-GCN architectures. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN is presented to utilize graph metadata in XC settings that offers 
    
[^4]: DynaWarp -- 高效的大规模日志存储和检索

    DynaWarp -- Efficient, large-scale log storage and retrieval

    [https://arxiv.org/abs/2402.18355](https://arxiv.org/abs/2402.18355)

    DynaWarp提出了一种新的成员草图结构，可以高效地回答多集多成员查询，相比于倒排索引和成员草图，具有更高的存储效率和查询吞吐量。

    

    现代大规模监控系统必须实时处理和存储大量日志数据。在查询时，系统必须基于日志消息的内容找到相关日志，使用能够扩展到这些数据量并且仍然高效的支持结构。我们提出了一种新颖的DynaWarp成员草图，能够回答多集多成员查询，可作为流式日志数据的现有索引结构的替代方案。在我们的实验中，DynaWarp所需的存储空间比测试的最先进的倒排索引少了高达93％，误报率比测试的最先进的成员草图少了高达四个数量级。此外，DynaWarp的查询吞吐量比测试的倒排索引高出高达250倍，并且比测试的成员草图高出高达240倍。

    arXiv:2402.18355v1 Announce Type: new  Abstract: Modern, large scale monitoring systems have to process and store vast amounts of log data in near real-time. At query time the systems have to find relevant logs based on the content of the log message using support structures that can scale to these amounts of data while still being efficient to use. We present our novel DynaWarp membership sketch, capable of answering Multi-Set Multi-Membership-Queries, that can be used as an alternative to existing indexing structures for streamed log data. In our experiments, DynaWarp required up to 93% less storage space than the tested state-of-the-art inverted index and had up to four orders of magnitude less false-positives than the tested state-of-the-art membership sketch. Additionally, DynaWarp achieved up to 250 times higher query throughput than the tested inverted index and up to 240 times higher query throughput than the tested membership sketch.
    
[^5]: 在Twitter上利用多个基于消息的网络表示检测反疫苗内容

    Detecting Anti-vaccine Content on Twitter using Multiple Message-Based Network Representations

    [https://arxiv.org/abs/2402.18335](https://arxiv.org/abs/2402.18335)

    分析了来自Twitter的多个社交网络表征，证明了通过全局和局部网络度量指标可以有效检测有争议和无争议的反疫苗标签和关键词

    

    社交媒体平台如Twitter在通过转推和回复的概念促进在线观点的传播和讨论方面起着基础作用。然而，这些功能也有助于在COVID-19大流行的疫苗推出期间传播误导信息。我们以COVID-19疫苗为案例研究，分析了来自Twitter上三种基于消息的互动的多个社交网络表征（引述转推、提及和回复），基于一组已知的反疫苗标签和关键词。每个网络代表了一个特定的标签或关键词，根据一小组参与者的标记，这些标签被标记为“有争议的”和“无争议的”。对于每个网络，我们提取了一组全局和局部基于网络的度量，将其用作二进制分类的特征向量。我们的结果表明，可能通过这些特征向量来检测有争议与无争议的术语。

    arXiv:2402.18335v1 Announce Type: cross  Abstract: Social media platforms such as Twitter have a fundamental role in facilitating the spread and discussion of ideas online through the concept of retweeting and replying. However, these features also contribute to the spread of mis/disinformation during the vaccine rollout of the COVID-19 pandemic. Using COVID-19 vaccines as a case study, we analyse multiple social network representation derived from three message-based interactions on Twitter (quote retweets, mentions and replies) based upon a set of known anti-vax hashtags and keywords. Each network represents a certain hashtag or keyword which were labelled as "controversial" and "non-controversial" according to a small group of participants. For each network, we extract a combination of global and local network-based metrics which are used as feature vectors for binary classification. Our results suggest that it is possible to detect controversial from non-controversial terms with hi
    
[^6]: 基于大型语言模型的代理平台上的前景个性化推荐

    Prospect Personalized Recommendation on Large Language Model-based Agent Platform

    [https://arxiv.org/abs/2402.18240](https://arxiv.org/abs/2402.18240)

    提出了一种基于大型语言模型代理平台的个性化推荐系统Rec4Agentverse，强调代理项和代理推荐器之间的合作，促进个性化信息服务，提升信息交换，并展望了其演进为支持互动和信息交换的三个阶段

    

    新型代理导向信息系统，以GPT为例，促使我们审视信息系统基础设施，以支持代理级信息处理并适应基于大型语言模型（LLM）的代理的特征，如互动性。本研究展望了基于LLM代理平台的推荐系统的前景，并介绍了一种称为Rec4Agentverse的新型推荐范式，包括代理项和代理推荐器。Rec4Agentverse强调代理项和代理推荐器之间的合作，从而促进个性化信息服务，并增强信息交换，超越传统的用户-推荐器反馈循环。此外，我们展望了Rec4Agentverse的演进，并将其概念化为基于代理项、代理推荐器和用户之间互动和信息交换增强的三个阶段。

    arXiv:2402.18240v1 Announce Type: cross  Abstract: The new kind of Agent-oriented information system, exemplified by GPTs, urges us to inspect the information system infrastructure to support Agent-level information processing and to adapt to the characteristics of Large Language Model (LLM)-based Agents, such as interactivity. In this work, we envisage the prospect of the recommender system on LLM-based Agent platforms and introduce a novel recommendation paradigm called Rec4Agentverse, comprised of Agent Items and Agent Recommender. Rec4Agentverse emphasizes the collaboration between Agent Items and Agent Recommender, thereby promoting personalized information services and enhancing the exchange of information beyond the traditional user-recommender feedback loop. Additionally, we prospect the evolution of Rec4Agentverse and conceptualize it into three stages based on the enhancement of the interaction and information exchange among Agent Items, Agent Recommender, and the user. A pre
    
[^7]: 序列级语义表示融合用于推荐系统

    Sequence-level Semantic Representation Fusion for Recommender Systems

    [https://arxiv.org/abs/2402.18166](https://arxiv.org/abs/2402.18166)

    研究通过序列级语义融合的方法，在推荐系统中更好地整合文本和ID特征，提高推荐性能

    

    随着推荐系统的快速发展，可以利用的辅助信息越来越多，以提高推荐性能。特别是，我们关注项目的关联\emph{文本数据}的利用（例如产品标题），并研究文本特征如何与ID特征在顺序推荐中有效融合。然而，这两种项目特征存在明显的数据特征，使得直接融合方法（例如将文本和ID嵌入作为项目表示进行相加）变得不太有效。为了解决这个问题，我们提出了一种新颖的面向顺序\ul \emph{推荐}的{\ul \emph{Rec}}的{\bf \我们}的{\bf \我们}的{\bf \我们}的{\bf \我们}的{\bf \我们}的{\bf \我们}的{\bf \我们}的{\bf 我们的}的含义。我们的方法的核心思想是通过更好地整合全局上下文来进行序列级语义融合方法。关键策略在于我们通过傅里叶变换对文本嵌入和ID嵌入进行转换

    arXiv:2402.18166v1 Announce Type: new  Abstract: With the rapid development of recommender systems, there is increasing side information that can be employed to improve the recommendation performance. Specially, we focus on the utilization of the associated \emph{textual data} of items (eg product title) and study how text features can be effectively fused with ID features in sequential recommendation. However, there exists distinct data characteristics for the two kinds of item features, making a direct fusion method (eg adding text and ID embeddings as item representation) become less effective. To address this issue, we propose a novel {\ul \emph{Te}}xt-I{\ul \emph{D}} semantic fusion approach for sequential {\ul \emph{Rec}}ommendation, namely \textbf{\our}. The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts. The key strategy lies in that we transform the text embeddings and ID embeddings by Fourier Transform f
    
[^8]: 切断头部终结冲突：解释和缓解语言模型中的知识冲突的机制

    Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models

    [https://arxiv.org/abs/2402.18154](https://arxiv.org/abs/2402.18154)

    通过信息流的视角解释并干预语言模型中的知识冲突，提出了一种名为Pruning Head via PatH的方法来缓解冲突

    

    最近，检索增强和工具增强展示了通过提供外部上下文来扩展语言模型（LMs）的内部记忆边界的显著能力。然而，内部记忆和外部上下文不可避免地发生冲突，导致LMs内部出现知识冲突。本文旨在通过信息流的视角解释知识冲突的机制，然后通过在关键点进行精确干预来缓解冲突。我们发现在后续层中有一些具有相反效果的注意力头，其中内存头可以从内部记忆中召回知识，而上下文头可以从外部上下文中检索知识。此外，我们揭示了LMs中知识冲突发生的关键点是内存头和上下文头整合不一致信息流的地方。受到这些见解的启发，我们提出了一种名为Pruning Head via PatH的新方法。

    arXiv:2402.18154v1 Announce Type: cross  Abstract: Recently, retrieval augmentation and tool augmentation have demonstrated a remarkable capability to expand the internal memory boundaries of language models (LMs) by providing external context. However, internal memory and external context inevitably clash, leading to knowledge conflicts within LMs. In this paper, we aim to interpret the mechanism of knowledge conflicts through the lens of information flow, and then mitigate conflicts by precise interventions at the pivotal point. We find there are some attention heads with opposite effects in the later layers, where memory heads can recall knowledge from internal memory, and context heads can retrieve knowledge from external context. Moreover, we reveal that the pivotal point at which knowledge conflicts emerge in LMs is the integration of inconsistent information flows by memory heads and context heads. Inspired by the insights, we propose a novel method called Pruning Head via PatH 
    
[^9]: 大型语言模型的无监督信息细化训练用于检索增强生成

    Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation

    [https://arxiv.org/abs/2402.18150](https://arxiv.org/abs/2402.18150)

    本文提出了一种名为InFO-RAG的无监督信息细化训练方法，将大型语言模型在检索增强生成中的角色定义为“信息细化者”，帮助模型更好地整合检索信息以生成更加简洁、准确和完整的文本。

    

    检索增强生成（RAG）通过将来自检索的额外信息整合到大型语言模型（LLMs）中，从而增强其性能。然而，研究表明，LLMs在有效利用检索信息方面仍然面临挑战，有时会忽视或被错误引导。其关键原因在于LLMs的训练没有清晰地让LLMs学会如何利用具有不同质量的检索文本输入。本文提出了一个新颖的视角，将LLMs在RAG中的角色视为“信息细化者”，这意味着无论检索文本的正确性、完整性或有用性如何，LLMs都能一致地整合检索文本中的知识和模型参数，生成比检索文本更简洁、准确和完整的文本。为此，我们提出了一种名为InFO-RAG的信息细化训练方法，以无监督的方式优化LLMs用于RAG。

    arXiv:2402.18150v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignoring it or being misled by it. The key reason is that the training of LLMs does not clearly make LLMs learn how to utilize input retrieved texts with varied quality. In this paper, we propose a novel perspective that considers the role of LLMs in RAG as ``Information Refiner'', which means that regardless of correctness, completeness, or usefulness of retrieved texts, LLMs can consistently integrate knowledge within the retrieved texts and model parameters to generate the texts that are more concise, accurate, and complete than the retrieved texts. To this end, we propose an information refinement training method named InFO-RAG that optimizes LLMs for RAG in an unsupervised manner. InFO-RAG i
    
[^10]: 由大型语言模型引导的语料库查询扩展

    Corpus-Steered Query Expansion with Large Language Models

    [https://arxiv.org/abs/2402.18031](https://arxiv.org/abs/2402.18031)

    通过引入语料库引导的查询扩展（CSQE），结合大型语言模型的知识增强扩展，改善了查询与目标文档之间的相关性预测。

    

    最近的研究表明，由大型语言模型（LLMs）生成的查询扩展可以通过生成能够回答查询的假设文档而显着增强信息检索系统。然而，由于LLMs的有限内在知识，扩展与检索语料库之间的不对齐导致问题，如幻觉和过时信息。受伪相关反馈（PRF）启发，我们引入了语料库引导的查询扩展（CSQE）来促进嵌入在语料库中的知识的整合。CSQE利用LLMs的相关性评估能力系统地识别最初检索到的文档中的关键句。这些由语料库产生的文本随后与LLM知识增强扩展一起用于扩展查询，改善查询与目标文档之间的相关性预测。广泛的实验证明CSQE明显提高了信息检索结果的质量。

    arXiv:2402.18031v1 Announce Type: cross  Abstract: Recent studies demonstrate that query expansions generated by large language models (LLMs) can considerably enhance information retrieval systems by generating hypothetical documents that answer the queries as expansions. However, challenges arise from misalignments between the expansions and the retrieval corpus, resulting in issues like hallucinations and outdated information due to the limited intrinsic knowledge of LLMs. Inspired by Pseudo Relevance Feedback (PRF), we introduce Corpus-Steered Query Expansion (CSQE) to promote the incorporation of knowledge embedded within the corpus. CSQE utilizes the relevance assessing capability of LLMs to systematically identify pivotal sentences in the initially-retrieved documents. These corpus-originated texts are subsequently used to expand the query together with LLM-knowledge empowered expansions, improving the relevance prediction between the query and the target documents. Extensive exp
    
[^11]: [RE] 对下一个购物篮推荐建模个性化商品频率信息

    [RE] Modeling Personalized Item Frequency Information for Next-basket Recommendation

    [https://arxiv.org/abs/2402.17925](https://arxiv.org/abs/2402.17925)

    复制并扩展了使用个性化商品频率信息进行下一个购物篮推荐的论文研究，利用多个数据集验证了TIFU-KNN模型的优越性，并引入了新的$\beta$-VAE架构来建模NBR。

    

    这篇论文旨在复制和扩展论文《对下一个购物篮推荐建模个性化商品频率信息》，该论文介绍了TIFU-KNN模型，并提出利用个性化商品频率 (PIF) 进行下一个购物篮推荐 (NBR)。我们利用了原始论文中使用的公开可用的食品杂货购物数据集，并结合其他数据集来评估研究结果的泛化能力。我们评估了各种模型的性能，包括 Recall@K、NDCG@K、个性化命中率 (PHR) 和平均倒数排名 (MRR) 等指标。此外，我们考虑了用户特征，如平均购物篮大小、商品受欢迎程度和新颖性，从而对公平性进行了彻底检查。最后，我们引入了新颖的 $\beta$-VAE 架构来建模 NBR。实验结果表明，复制出的模型 TIFU-KNN 胜过基线模型 Personal Top Frequency。

    arXiv:2402.17925v1 Announce Type: new  Abstract: This paper focuses on reproducing and extending the results of the paper: "Modeling Personalized Item Frequency Information for Next-basket Recommendation" which introduced the TIFU-KNN model and proposed to utilize Personalized Item Frequency (PIF) for Next Basket Recommendation (NBR). We utilized publicly available grocery shopping datasets used in the original paper and incorporated additional datasets to assess the generalizability of the findings. We evaluated the performance of the models using metrics such as Recall@K, NDCG@K, personalized-hit ratio (PHR), and Mean Reciprocal Rank (MRR). Furthermore, we conducted a thorough examination of fairness by considering user characteristics such as average basket size, item popularity, and novelty. Lastly, we introduced novel $\beta$-VAE architecture to model NBR. The experimental results confirmed that the reproduced model, TIFU-KNN, outperforms the baseline model, Personal Top Frequency
    
[^12]: 基于语言模型的本体论中新概念放置框架

    A Language Model based Framework for New Concept Placement in Ontologies

    [https://arxiv.org/abs/2402.17897](https://arxiv.org/abs/2402.17897)

    提出了一种基于语言模型的框架，用于将从文本中提取的新概念插入到本体中，在边搜索、边形成和增强、边选择三个步骤中分别利用神经方法，并在 SNOMED CT 本体和 MedMentions 实体链接基准上进行了评估

    

    我们研究了利用语言模型将从文本中提取的新概念插入本体的任务。我们探索了一个三步方法：边搜索，即找到要插入的候选位置集（即概念之间的包含关系），边形成和增强，利用本体结构生成和增强边候选，以及边选择，最终确定要放置的边。在所有步骤中，我们提出利用神经方法，其中应用基于嵌入的方法和对比学习，如BERT用于边搜索，采用基于BERT微调的多标签边交叉编码器，以及GPT系列、FLAN-T5 和 Llama 2 等大型语言模型（LLM）用于边选择。我们在使用 SNOMED CT 本体和 MedMentions 实体链接基准创建的最新数据集上评估了这些方法。

    arXiv:2402.17897v1 Announce Type: new  Abstract: We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our fram
    
[^13]: JMLR：联合医疗LLM和检索训练以增强推理和专业问题回答能力

    JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability

    [https://arxiv.org/abs/2402.17887](https://arxiv.org/abs/2402.17887)

    JMLR通过联合训练信息检索系统和大型语言模型，在医学领域提高问题回答系统性能，降低计算资源需求，增强模型利用医疗知识进行推理和回答问题的能力。

    

    随着医疗数据的爆炸性增长和人工智能技术的快速发展，精准医学已经成为增强医疗服务质量和效率的关键。在这种背景下，大型语言模型（LLMs）在医疗知识获取和问题回答系统中发挥越来越重要的作用。为了进一步提高这些系统在医学领域的性能，我们介绍了一种创新方法，在微调阶段同时训练信息检索（IR）系统和LLM。我们称之为联合医疗LLM和检索训练（JMLR）的方法旨在克服传统模型在处理医学问题回答任务时面临的挑战。通过采用同步训练机制，JMLR减少了对计算资源的需求，并增强了模型利用医疗知识进行推理和回答问题的能力。

    arXiv:2402.17887v1 Announce Type: new  Abstract: With the explosive growth of medical data and the rapid development of artificial intelligence technology, precision medicine has emerged as a key to enhancing the quality and efficiency of healthcare services. In this context, Large Language Models (LLMs) play an increasingly vital role in medical knowledge acquisition and question-answering systems. To further improve the performance of these systems in the medical domain, we introduce an innovative method that jointly trains an Information Retrieval (IR) system and an LLM during the fine-tuning phase. This approach, which we call Joint Medical LLM and Retrieval Training (JMLR), is designed to overcome the challenges faced by traditional models in handling medical question-answering tasks. By employing a synchronized training mechanism, JMLR reduces the demand for computational resources and enhances the model's ability to leverage medical knowledge for reasoning and answering question
    
[^14]: UniRetriever：各种情境自适应对话检索的多任务候选者选择

    UniRetriever: Multi-task Candidates Selection for Various Context-Adaptive Conversational Retrieval

    [https://arxiv.org/abs/2402.16261](https://arxiv.org/abs/2402.16261)

    提出了一种UniRetriever框架，利用双编码器架构和两个损失约束实现了多任务候选者选择，适用于不同情境下的对话检索任务。

    

    对话检索是指以迭代和交互方式运行的信息检索系统，需要检索各种外部资源（如人设、知识甚至回应）以有效与用户交互并成功完成对话。为了提高效率和性能，我们提出了一个多任务框架，作为三个主要检索任务的通用检索器：人设选择、知识选择和回应选择。为此，我们设计了一个双编码器架构，包括一个情境自适应对话编码器和一个候选者编码器，旨在通过简单的点积关注长对话中的相关上下文并检索合适的候选者。此外，我们引入了两个损失约束以捕捉...

    arXiv:2402.16261v1 Announce Type: new  Abstract: Conversational retrieval refers to an information retrieval system that operates in an iterative and interactive manner, requiring the retrieval of various external resources, such as persona, knowledge, and even response, to effectively engage with the user and successfully complete the dialogue. However, most previous work trained independent retrievers for each specific resource, resulting in sub-optimal performance and low efficiency. Thus, we propose a multi-task framework function as a universal retriever for three dominant retrieval tasks during the conversation: persona selection, knowledge selection, and response selection. To this end, we design a dual-encoder architecture consisting of a context-adaptive dialogue encoder and a candidate encoder, aiming to attention to the relevant context from the long dialogue and retrieve suitable candidates by simply a dot product. Furthermore, we introduce two loss constraints to capture t
    
[^15]: ListT5: 基于解码器内融合的列表重排方法改善零-shot检索

    ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval

    [https://arxiv.org/abs/2402.15838](https://arxiv.org/abs/2402.15838)

    ListT5通过Fusion-in-Decoder技术实现列表重排，在零-shot检索任务中表现出优越性能，效率高于之前的模型，并解决了以往列表重排器的中间段丢失问题。

    

    我们提出了ListT5，一种基于在训练和推断时处理多个候选段落的Fusion-in-Decoder（FiD）的新型重排方法。我们还介绍了一个基于m元锦标赛排序和输出缓存的列表排序的高效推断框架。我们在BEIR基准上评估和比较我们的模型，证明了ListT5（1）在平均NDCG@10得分上比最先进的RankT5基线表现出明显的+1.3增益，（2）具有与逐点排名模型可比拟的效率，并超越以前的列表排序模型的效率，（3）克服了以前列表重排器的中间段丢失问题。我们的代码、模型检查点和评估框架完全开源在 \url{https://github.com/soyoung97/ListT5}。

    arXiv:2402.15838v1 Announce Type: new  Abstract: We propose ListT5, a novel reranking approach based on Fusion-in-Decoder (FiD) that handles multiple candidate passages at both train and inference time. We also introduce an efficient inference framework for listwise ranking based on m-ary tournament sort with output caching. We evaluate and compare our model on the BEIR benchmark for zero-shot retrieval task, demonstrating that ListT5 (1) outperforms the state-of-the-art RankT5 baseline with a notable +1.3 gain in the average NDCG@10 score, (2) has an efficiency comparable to pointwise ranking models and surpasses the efficiency of previous listwise ranking models, and (3) overcomes the lost-in-the-middle problem of previous listwise rerankers. Our code, model checkpoints, and the evaluation framework are fully open-sourced at \url{https://github.com/soyoung97/ListT5}.
    
[^16]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^17]: 通过低秩训练实现高效通信和安全的联邦推荐系统

    Towards Efficient Communication and Secure Federated Recommendation System via Low-rank Training

    [https://arxiv.org/abs/2401.03748](https://arxiv.org/abs/2401.03748)

    通过相关低秩结构（CoLR）框架，实现了联邦推荐系统中高效的通信和安全性，显著降低了通信开销同时保持与安全聚合协议的兼容性。

    

    arXiv:2401.03748v2 公告类型: 替换 摘要: 针对不断增长的监管关注引发的需求，联邦推荐（FedRec）系统已经成为保护用户数据的一种解决方案。然而，这类系统面临的主要挑战之一在于传输神经网络模型所带来的通信成本，即在用户设备和中央服务器之间传输。先前针对这些挑战的方法通常会导致诸如计算开销、模型特性限制以及与安全聚合协议兼容性的问题。 作为响应，我们提出了一种新颖的框架，称为相关低秩结构（CoLR），它利用了调整轻量级可训练参数的概念，同时保持大部分参数冻结。我们的方法显著减少了通信开销而不引入额外的计算负担。至关重要的是，我们的框架与安全聚合协议完全兼容，包括鲁棒地使用同态

    arXiv:2401.03748v2 Announce Type: replace  Abstract: Federated Recommendation (FedRec) systems have emerged as a solution to safeguard users' data in response to growing regulatory concerns. However, one of the major challenges in these systems lies in the communication costs that arise from the need to transmit neural network models between user devices and a central server. Prior approaches to these challenges often lead to issues such as computational overheads, model specificity constraints, and compatibility issues with secure aggregation protocols. In response, we propose a novel framework, called Correlated Low-rank Structure (CoLR), which leverages the concept of adjusting lightweight trainable parameters while keeping most parameters frozen. Our approach substantially reduces communication overheads without introducing additional computational burdens. Critically, our framework remains fully compatible with secure aggregation protocols, including the robust use of Homomorphic 
    
[^18]: 通过挖掘和评估媒体报道数据实现公司的ESG自动评估：NLP方法与工具

    Automatic ESG Assessment of Companies by Mining and Evaluating Media Coverage Data: NLP Approach and Tool

    [https://arxiv.org/abs/2212.06540](https://arxiv.org/abs/2212.06540)

    通过NLP方法和工具，本研究旨在从文本媒体反应中自动提取ESG相关信息，实现公司ESG的自动评估。

    

    可持续性企业行为受到社会越来越重视，影响着企业声誉和客户信任。因此，公司定期发布可持续发展报告，以阐明其对环境、社会和治理（ESG）因素的影响。然而，分析有关ESG因素的媒体报道具有挑战性，因为（1）每天发布的新闻文章数量不断增加，（2）媒体报道数据不一定涉及ESG相关主题，必须经过仔细筛选，（3）大多数媒体报道数据是非结构化的。我们的研究目标是自动从文本媒体反应中提取ESG相关信息，以计算

    arXiv:2212.06540v2 Announce Type: replace  Abstract: Context: Sustainable corporate behavior is increasingly valued by society and impacts corporate reputation and customer trust. Hence, companies regularly publish sustainability reports to shed light on their impact on environmental, social, and governance (ESG) factors. Problem: Sustainability reports are written by companies themselves and are therefore considered a company-controlled source. Contrary, studies reveal that non-corporate channels (e.g., media coverage) represent the main driver for ESG transparency. However, analysing media coverage regarding ESG factors is challenging since (1) the amount of published news articles grows daily, (2) media coverage data does not necessarily deal with an ESG-relevant topic, meaning that it must be carefully filtered, and (3) the majority of media coverage data is unstructured. Research Goal: We aim to extract ESG-relevant information from textual media reactions automatically to calcula
    
[^19]: 安全的协同过滤

    Safe Collaborative Filtering. (arXiv:2306.05292v1 [cs.IR])

    [http://arxiv.org/abs/2306.05292](http://arxiv.org/abs/2306.05292)

    本论文提出了一个安全的协同过滤算法，通过最小化条件风险价值，提高低满意度用户的推荐质量。在实际数据集中表现出色，同时也保持总体推荐质量。

    

    对于现代机器学习任务，例如算法公平性、类别不平衡和风险敏感的决策制定，优秀的尾部性能非常重要，因为它确保了对数据集中具有挑战性的样本的有效处理。尾部性能也是个性化推荐系统成功的重要决定因素，以减少对低满意度用户的流失风险。本研究介绍了一种“安全”的协同过滤方法，该方法优先考虑低满意度用户的推荐质量，而不是关注平均表现。我们的方法最小化条件风险价值（CVaR），表示用户损失尾部的平均风险。为了克服网络规模的推荐系统的计算难题，我们开发了一个强大而实用的算法，扩展了最可扩展的方法隐式交替最小二乘法（iALS）。在实际数据集的经验证明，我们的方法具有出色的尾部性能，同时保持了总体推荐质量。

    Excellent tail performance is crucial for modern machine learning tasks, such as algorithmic fairness, class imbalance, and risk-sensitive decision making, as it ensures the effective handling of challenging samples within a dataset. Tail performance is also a vital determinant of success for personalised recommender systems to reduce the risk of losing users with low satisfaction. This study introduces a "safe" collaborative filtering method that prioritises recommendation quality for less-satisfied users rather than focusing on the average performance. Our approach minimises the conditional value at risk (CVaR), which represents the average risk over the tails of users' loss. To overcome computational challenges for web-scale recommender systems, we develop a robust yet practical algorithm that extends the most scalable method, implicit alternating least squares (iALS). Empirical evaluation on real-world datasets demonstrates the excellent tail performance of our approach while maint
    
[^20]: 深度图表示学习综述

    A Comprehensive Survey on Deep Graph Representation Learning. (arXiv:2304.05055v1 [cs.LG])

    [http://arxiv.org/abs/2304.05055](http://arxiv.org/abs/2304.05055)

    本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。

    

    图表示学习旨在将高维稀疏的图结构数据有效地编码成低维密集向量，这是一个基本任务，在包括机器学习和数据挖掘在内的一系列领域都得到了广泛的研究。传统图嵌入方法遵循这样一种基本思想，即图中相互连接的节点的嵌入矢量仍然能够保持相对接近的距离，从而保留了图中节点之间的结构信息。然而，这种方法存在以下问题：（i）传统方法的模型容量受限，限制了学习性能; （ii）现有技术通常依赖于无监督学习策略，无法与最新的学习范式相结合；（iii）表示学习和下游任务相互依存，应共同加强。随着深度学习的显着成功，深度图表示学习已经显示出巨大的潜力和优势。

    Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages 
    

