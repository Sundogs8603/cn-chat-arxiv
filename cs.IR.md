# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model](https://arxiv.org/abs/2402.06557) | 本文介绍了量化布尔贝叶斯网络（QBBN），它提供了逻辑和概率推理的统一视角，并解决了大型语言模型（LLM）的妄想问题。通过创建一阶演算法的键值版本，QBBN能够表示人类语言背后的逻辑推理。精确推理是不可解的，但可以使用循环信念传播（LBP）进行推理。 |
| [^2] | [Toward Building a Semantic Network Inventory for Model-Driven Telemetry](https://arxiv.org/abs/2402.06511) | 本研究提出了一个语义网络清单，用于集成和共享与模型驱动遥测相关的上下文信息，并自动化地将这些信息集成到网络清单中。通过实施和验证原型，证明了网络清单可以简化模型驱动遥测的操作。 |
| [^3] | [What's in People's Digital File Collections?](https://arxiv.org/abs/2402.06421) | 该研究通过分析348个文件收藏的结构和内容，发现人们的数字文件收藏中包含丰富多样的内容。不同的收藏类型在内容、重复率和使用目的上存在差异。通过这些研究结果，我们可以更好地设计和测试个人信息管理的服务和软件。 |
| [^4] | [CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models](https://arxiv.org/abs/2402.06360) | CoSearchAgent是一种基于大语言模型的轻量级协作搜索代理，可作为Slack插件在多方对话中支持协作搜索。 |
| [^5] | [ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs](https://arxiv.org/abs/2402.06334) | ExaRanker-Open 是一种使用开源LLMs进行IR的方法，通过适应和探索开源语言模型来生成解释。研究结果表明，纳入解释能够稳定提高神经排序器的性能，而LLM的大小越大，收益越大。 |
| [^6] | [Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems](https://arxiv.org/abs/2402.06233) | 该论文开发并实施了基于协同过滤、K最近邻和余弦相似度的家居装饰推荐系统，通过测试不同的评估技术来研究其性能，并提出了解决稀疏性和冷启动问题的建议。 |
| [^7] | [ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement](https://arxiv.org/abs/2402.06221) | ResumeFlow是一种利用LLM技术的工具，能够帮助求职者根据特定的职位要求生成个性化的简历，从而解决了手动定制简历的耗时和容易出错的问题。 |
| [^8] | [Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss](https://arxiv.org/abs/2402.06216) | 本文指出现有的基于大规模语言模型的推荐方法在公平性和评估上存在问题，需要重新审视交叉熵损失并替代传统的点对/点对损失函数。并且通过理论和实验结果表明，现有的基于LLM的方法对于预测下一个项目的效果并不像宣称的那样有效。 |
| [^9] | [Task Supportive and Personalized Human-Large Language Model Interaction: A User Study](https://arxiv.org/abs/2402.06170) | 本研究通过提示工程将任务上下文和用户感知融入人-ChatGPT交互中，设计了一个具有支持性功能的平台，能够帮助用户管理期望、减少认知负荷，并增加用户参与度。 |
| [^10] | [Assortment Planning with Sponsored Products](https://arxiv.org/abs/2402.06158) | 本研究主要关注零售中带有赞助产品的品类规划挑战并将其建模为组合优化任务，以实现在考虑赞助产品的情况下优化预期收入的目的。 |
| [^11] | [Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs](https://arxiv.org/abs/2402.05941) | 本文提出了一个新的基于人物的服装生成（COG）问题，旨在准确解释人物信息并根据用户的规范生成服装组合。我们提出了一个新颖的框架LVA-COG，利用大型语言模型（LLMs）从用户的兴趣中提取见解，并结合文本到图像模型，增强了对连贯服装的视觉理解和生成。 |
| [^12] | [Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey](https://arxiv.org/abs/2402.05391) | 知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。 |
| [^13] | [Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2402.04867) | 本论文介绍了一种基于多智能体强化学习和人类反馈的多模态查询建议系统。通过利用语言模型和强化学习算法，该系统能够根据用户的查询图像生成个性化的查询建议，从而提高搜索结果的意图性和多样性。 |
| [^14] | [Future Impact Decomposition in Request-level Recommendations](https://arxiv.org/abs/2401.16108) | 在请求级别的推荐系统中，我们通过比较标准方法和基于物品级别的演员-评论家框架在模拟和在线实验中的性能，证明了基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。 |
| [^15] | [Seller-Side Experiments under Interference Induced by Feedback Loops in Two-Sided Platforms](https://arxiv.org/abs/2401.15811) | 本文研究了两边平台中反馈循环引起的干扰对卖家实验的影响，提出了数学框架进行分析并实证评估了反事实交错设计，结果显示反馈循环可能导致误导性的结论。 |
| [^16] | [An In-depth Investigation of User Response Simulation for Conversational Search.](http://arxiv.org/abs/2304.07944) | 本文研究了对话式搜索中用户响应模拟的方法。当前的模拟系统要么只能对是非问题进行回答，要么无法产生高质量的响应。通过用更小但先进的系统替换当前最先进的用户模拟系统，能够显著改进性能。 |

# 详细

[^1]: 量化布尔贝叶斯网络：逻辑图模型的理论和实验

    The Quantified Boolean Bayesian Network: Theory and Experiments with a Logical Graphical Model

    [https://arxiv.org/abs/2402.06557](https://arxiv.org/abs/2402.06557)

    本文介绍了量化布尔贝叶斯网络（QBBN），它提供了逻辑和概率推理的统一视角，并解决了大型语言模型（LLM）的妄想问题。通过创建一阶演算法的键值版本，QBBN能够表示人类语言背后的逻辑推理。精确推理是不可解的，但可以使用循环信念传播（LBP）进行推理。

    

    本文介绍了量化布尔贝叶斯网络（QBBN），它提供了逻辑和概率推理的统一视角。QBBN旨在解决大型语言模型（LLM）的一个核心问题，即LLM会出现妄想现象。由于贝叶斯网络的构建方式，它无法产生妄想，因为它只能返回可以解释的答案。我们展示了如何配置一个含有无限数量布尔变量的贝叶斯网络来表示人类语言背后的逻辑推理。我们通过创建一种键-值版本的一阶演算法来实现这一点，我们可以证明其一致性和完备性。我们展示了该模型在完全观测数据上是易于训练的，但推理是非平凡的。贝叶斯网络的精确推理是不可解的（即$N$个变量的推理复杂度为$\Omega(2^N)$）。对于推理，我们研究了循环信念传播（LBP）的使用，它并不...

    This paper introduces the Quantified Boolean Bayesian Network (QBBN), which provides a unified view of logical and probabilistic reasoning. The QBBN is meant to address a central problem with the Large Language Model (LLM), which has become extremely popular in Information Retrieval, which is that the LLM hallucinates. A Bayesian Network, by construction, cannot hallucinate, because it can only return answers that it can explain. We show how a Bayesian Network over an unbounded number of boolean variables can be configured to represent the logical reasoning underlying human language. We do this by creating a key-value version of the First-Order Calculus, for which we can prove consistency and completeness. We show that the model is trivially trained over fully observed data, but that inference is non-trivial. Exact inference in a Bayesian Network is intractable (i.e. $\Omega(2^N)$ for $N$ variables). For inference, we investigate the use of Loopy Belief Propagation (LBP), which is not 
    
[^2]: 构建基于模型驱动遥测的语义网络清单的研究

    Toward Building a Semantic Network Inventory for Model-Driven Telemetry

    [https://arxiv.org/abs/2402.06511](https://arxiv.org/abs/2402.06511)

    本研究提出了一个语义网络清单，用于集成和共享与模型驱动遥测相关的上下文信息，并自动化地将这些信息集成到网络清单中。通过实施和验证原型，证明了网络清单可以简化模型驱动遥测的操作。

    

    基于数据模型的网络遥测被期望成为高效收集网络设备运行数据的标准机制。但是，标准和专有数据模型的广泛多样性，以及网络供应商提供的遥测协议的不同实现，使得监控异构网络基础设施变得困难。为了促进与模型驱动遥测相关的上下文信息的集成和共享，该研究提出了一个语义网络清单，该清单集成了特定开发的新信息模型，以一种供应商无关的方式捕获上下文信息，使用了当前上下文管理所定义的标准。为了自动化地将这些上下文信息集成到网络清单中，设计了一个参考架构。最后，通过一个案例研究实施并验证了该解决方案的原型，阐述了网络清单如何简化模型驱动遥测的操作。

    Network telemetry based on data models is expected to become the standard mechanism for collecting operational data from network devices efficiently. But the wide variety of standard and proprietary data models along with the different implementations of telemetry protocols offered by network vendors, become a barrier when monitoring heterogeneous network infrastructures. To facilitate the integration and sharing of context information related to model-driven telemetry, this work proposes a semantic network inventory that integrates new information models specifically developed to capture context information in a vendor-agnostic fashion using current standards defined for context management. To automate the integration of this context information within the network inventory, a reference architecture is designed. Finally, a prototype of the solution is implemented and validated through a case study that illustrates how the network inventory can ease the operation of model-driven teleme
    
[^3]: 人们的数字文件收藏中有什么？

    What's in People's Digital File Collections?

    [https://arxiv.org/abs/2402.06421](https://arxiv.org/abs/2402.06421)

    该研究通过分析348个文件收藏的结构和内容，发现人们的数字文件收藏中包含丰富多样的内容。不同的收藏类型在内容、重复率和使用目的上存在差异。通过这些研究结果，我们可以更好地设计和测试个人信息管理的服务和软件。

    

    深入了解人们数字文件收藏中的内容对于设计支持个人信息管理（PIM）的服务和进行软件测试至关重要，但关于人们的文件收藏，尤其是个人收藏的了解相对较少。在最近关于348个文件收藏结构的研究基础上，我们研究了这些收藏的内容，重复内容的数量以及个人收藏和学习工作用途收藏的差异。尽管所有收藏都包含很多图片，但一些直观上常见的文件类型却相当稀缺。个人收藏包含更多音频，知识型工作者的收藏包含更多文本文档但文件夹较少，IT收藏具有不寻常的特点。收藏的重复与其结构特征相关，但令人惊讶的是，与收藏的年龄无关。我们根据以前的研究讨论了我们的发现，并提供了对各种类型信息的启示。

    Thoughtfully designing services and rigorously testing software to support personal information management (PIM) requires understanding the relevant collections, but relatively little is known about what people keep in their file collections, especially personal collections. Complementing recent work on the structure of 348 file collections, we examine those collections' contents, how much content is duplicated, and how collections used for personal matters differ from those used for study and work. Though all collections contain many images, some intuitively common file types are surprisingly scarce. Personal collections contain more audio than others, knowledge workers' collections contain more text documents but far fewer folders, and IT collections exhibit unusual traits. Collection duplication is correlated to collections' structural traits, but surprisingly, not to collection age. We discuss our findings in light of prior works and provide implications for various kinds of inform
    
[^4]: CoSearchAgent:基于大语言模型的轻量级协作搜索代理

    CoSearchAgent: A Lightweight Collaborative Search Agent with Large Language Models

    [https://arxiv.org/abs/2402.06360](https://arxiv.org/abs/2402.06360)

    CoSearchAgent是一种基于大语言模型的轻量级协作搜索代理，可作为Slack插件在多方对话中支持协作搜索。

    

    协作搜索支持多个用户共同完成特定的搜索任务。研究发现，将轻量级协作搜索插件设计在即时通讯平台内更符合用户的协作习惯。然而，由于多用户交互场景的复杂性，实现一个完全功能的轻量级协作搜索系统是具有挑战性的。因此，之前的轻量级协作搜索研究不得不依赖于"吹牛大王"范例。近年来，大型语言模型(LLM)已被证明可以与用户自然交互，并通过基于LLM的代理实现复杂的信息搜索任务。因此，为了更好地支持协作搜索研究，本文提出了CoSearchAgent，一种由LLM驱动的轻量级协作搜索代理。CoSearchAgent被设计为Slack插件，可以在该平台上的多方对话中支持协作搜索。

    Collaborative search supports multiple users working together to accomplish a specific search task. Research has found that designing lightweight collaborative search plugins within instant messaging platforms aligns better with users' collaborative habits. However, due to the complexity of multi-user interaction scenarios, it is challenging to implement a fully functioning lightweight collaborative search system. Therefore, previous studies on lightweight collaborative search had to rely on the Wizard of Oz paradigm. In recent years, large language models (LLMs) have been demonstrated to interact naturally with users and achieve complex information-seeking tasks through LLM-based agents. Hence, to better support the research in collaborative search, in this demo, we propose CoSearchAgent, a lightweight collaborative search agent powered by LLMs. CoSearchAgent is designed as a Slack plugin that can support collaborative search during multi-party conversations on this platform. Equipped
    
[^5]: ExaRanker-Open: 使用开源LLMs进行IR的合成解释

    ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs

    [https://arxiv.org/abs/2402.06334](https://arxiv.org/abs/2402.06334)

    ExaRanker-Open 是一种使用开源LLMs进行IR的方法，通过适应和探索开源语言模型来生成解释。研究结果表明，纳入解释能够稳定提高神经排序器的性能，而LLM的大小越大，收益越大。

    

    ExaRanker最近提出了一种训练信息检索(IR)模型的方法，该方法将自然语言解释作为附加标签。该方法解决了有限标记示例的挑战，提高了IR模型的效果。然而，初始结果是基于专有的语言模型，如GPT-3.5，这导致了数据集大小的限制，因为其成本和数据隐私。在本文中，我们介绍了ExaRanker-Open，通过适应和探索开源语言模型来生成解释。该方法已经使用不同的LLMs和数据集大小进行了测试，以更好地理解数据增强的有效贡献。我们的研究结果表明，纳入解释能够稳定提高神经排序器的性能，而LLM的大小越大，收益越大。值得注意的是，即使在大数据集上，数据增强方法也是有优势的，ExaRanker的性能超过目标基线0

    ExaRanker recently introduced an approach to training information retrieval (IR) models, incorporating natural language explanations as additional labels. The method addresses the challenge of limited labeled examples, leading to improvements in the effectiveness of IR models. However, the initial results were based on proprietary language models such as GPT-3.5, which posed constraints on dataset size due to its cost and data privacy. In this paper, we introduce ExaRanker-Open, where we adapt and explore the use of open-source language models to generate explanations. The method has been tested using different LLMs and datasets sizes to better comprehend the effective contribution of data augmentation. Our findings reveal that incorporating explanations consistently enhances neural rankers, with benefits escalating as the LLM size increases. Notably, the data augmentation method proves advantageous even with large datasets, as evidenced by ExaRanker surpassing the target baseline by 0
    
[^6]: 在家居装饰推荐系统中的协同过滤、K最近邻和余弦相似度

    Collaborative filtering, K-nearest neighbor and cosine similarity in home decor recommender systems

    [https://arxiv.org/abs/2402.06233](https://arxiv.org/abs/2402.06233)

    该论文开发并实施了基于协同过滤、K最近邻和余弦相似度的家居装饰推荐系统，通过测试不同的评估技术来研究其性能，并提出了解决稀疏性和冷启动问题的建议。

    

    基于协同过滤使用K最近邻和余弦相似度的体系结构框架被开发和实施，以满足DecorRaid公司的需求。本文旨在测试环境中不同的评估技术，以研究推荐系统的性能。在特定环境中，发现了三个相关的评估视角，即数据集、系统和用户视角。通过这些视角，可以更全面地了解推荐系统的性能。进行了在线A/B分割测试，比较了对推荐系统进行小调整的性能，并测试了评估技术的相关性。关键因素是解决稀疏性和冷启动问题，建议通过研究将基于内容和基于协同过滤的技术进行混合。

    An architectural framework, based on collaborative filtering using K-nearest neighbor and cosine similarity, was developed and implemented to fit the requirements for the company DecorRaid. The aim of the paper is to test different evaluation techniques within the environment to research the recommender systems performance. Three perspectives were found relevant for evaluating a recommender system in the specific environment, namely dataset, system and user perspective. With these perspectives it was possible to gain a broader view of the recommender systems performance. Online A/B split testing was conducted to compare the performance of small adjustments to the RS and to test the relevance of the evaluation techniques. Key factors are solving the sparsity and cold start problem, where the suggestion is to research a hybrid RS combining Content-based and CF based techniques.
    
[^7]: ResumeFlow: 一种个性化简历生成和修订的LLM辅助流程

    ResumeFlow: An LLM-facilitated Pipeline for Personalized Resume Generation and Refinement

    [https://arxiv.org/abs/2402.06221](https://arxiv.org/abs/2402.06221)

    ResumeFlow是一种利用LLM技术的工具，能够帮助求职者根据特定的职位要求生成个性化的简历，从而解决了手动定制简历的耗时和容易出错的问题。

    

    对于许多求职者来说，制作符合特定职位要求的理想简历是一项具有挑战性的任务，尤其是对于初入职场的求职者来说。虽然强烈建议求职者根据他们申请的具体职位定制简历，但手动根据工作描述和职位要求来定制简历通常 (1) 非常耗时，且 (2) 容易出错。此外，在申请多个职位时进行这样的定制步骤可能导致编辑简历质量不高。为了解决这个问题，在本演示论文中，我们提出了ResumeFlow: 一种利用大型语言模型（LLM）的工具，使终端用户只需提供详细的简历和所需的职位发布信息，就能在几秒钟内获得一个针对该特定职位发布的个性化简历。我们提出的流程利用了最先进的LLM（如OpenAI的GPT-4和Google的......）

    Crafting the ideal, job-specific resume is a challenging task for many job applicants, especially for early-career applicants. While it is highly recommended that applicants tailor their resume to the specific role they are applying for, manually tailoring resumes to job descriptions and role-specific requirements is often (1) extremely time-consuming, and (2) prone to human errors. Furthermore, performing such a tailoring step at scale while applying to several roles may result in a lack of quality of the edited resumes. To tackle this problem, in this demo paper, we propose ResumeFlow: a Large Language Model (LLM) aided tool that enables an end user to simply provide their detailed resume and the desired job posting, and obtain a personalized resume specifically tailored to that specific job posting in the matter of a few seconds. Our proposed pipeline leverages the language understanding and information extraction capabilities of state-of-the-art LLMs such as OpenAI's GPT-4 and Goog
    
[^8]: 公平评估基于大规模语言模型的推荐方法需要重新审视交叉熵损失

    Fairly Evaluating Large Language Model-based Recommendation Needs Revisit the Cross-Entropy Loss

    [https://arxiv.org/abs/2402.06216](https://arxiv.org/abs/2402.06216)

    本文指出现有的基于大规模语言模型的推荐方法在公平性和评估上存在问题，需要重新审视交叉熵损失并替代传统的点对/点对损失函数。并且通过理论和实验结果表明，现有的基于LLM的方法对于预测下一个项目的效果并不像宣称的那样有效。

    

    大规模语言模型(LLM)在推荐领域引起了广泛关注；一些研究观察到，经过全softmax细调的LLM已经可以达到最先进的性能。然而，这些观点来自于主观和不公平的比较。鉴于现实中的大量物品，传统的推荐方法通常采用点对/点对损失函数进行训练。然而，这种替代方法会导致性能严重下降，低估传统方法的效果，并过高评估LLM的排序能力。本文从理论上证明了交叉熵的优越性，并展示了可以用一些基本近似方法进行适当替代的必要修改。在三个公共数据集上的显著结果证实，即使从实际意义上讲，现有的基于LLM的方法对于预测下一个项目的效果并不像宣称的那样有效。

    Large language models (LLMs) have gained much attention in the recommendation community; some studies have observed that LLMs, fine-tuned by the cross-entropy loss with a full softmax, could achieve state-of-the-art performance already. However, these claims are drawn from unobjective and unfair comparisons. In view of the substantial quantity of items in reality, conventional recommenders typically adopt a pointwise/pairwise loss function instead for training. This substitute however causes severe performance degradation, leading to under-estimation of conventional methods and over-confidence in the ranking capability of LLMs.   In this work, we theoretically justify the superiority of cross-entropy, and showcase that it can be adequately replaced by some elementary approximations with certain necessary modifications. The remarkable results across three public datasets corroborate that even in a practical sense, existing LLM-based methods are not as effective as claimed for next-item 
    
[^9]: 任务支持和个性化的人机大型语言模型交互: 一项用户研究

    Task Supportive and Personalized Human-Large Language Model Interaction: A User Study

    [https://arxiv.org/abs/2402.06170](https://arxiv.org/abs/2402.06170)

    本研究通过提示工程将任务上下文和用户感知融入人-ChatGPT交互中，设计了一个具有支持性功能的平台，能够帮助用户管理期望、减少认知负荷，并增加用户参与度。

    

    大型语言模型（LLM）应用，如ChatGPT，是在线信息获取（IS）和问题解决任务的强大工具。然而，用户仍然面临着初始化和优化提示的挑战，他们的认知障碍和偏见进一步阻碍了任务完成。这些问题反映了信息获取和交互式信息检索领域所面临的更广泛挑战。为了解决这些问题，我们的方法通过提示工程将任务上下文和用户感知融入到人-ChatGPT交互中。我们开发了一个类似于ChatGPT的平台，集成了支持性功能，包括感知表达、提示建议和对话解释。我们的用户研究结果表明，这些支持功能可以帮助用户管理期望，减少认知负荷，更好地优化提示，并增加用户参与度。这项研究提升了我们对于设计主动性和用户中心系统与LLMs的理解。

    Large language model (LLM) applications, such as ChatGPT, are a powerful tool for online information-seeking (IS) and problem-solving tasks. However, users still face challenges initializing and refining prompts, and their cognitive barriers and biased perceptions further impede task completion. These issues reflect broader challenges identified within the fields of IS and interactive information retrieval (IIR). To address these, our approach integrates task context and user perceptions into human-ChatGPT interactions through prompt engineering. We developed a ChatGPT-like platform integrated with supportive functions, including perception articulation, prompt suggestion, and conversation explanation. Our findings of a user study demonstrate that the supportive functions help users manage expectations, reduce cognitive loads, better refine prompts, and increase user engagement. This research enhances our comprehension of designing proactive and user-centric systems with LLMs. It offer
    
[^10]: 带有赞助产品的品类规划

    Assortment Planning with Sponsored Products

    [https://arxiv.org/abs/2402.06158](https://arxiv.org/abs/2402.06158)

    本研究主要关注零售中带有赞助产品的品类规划挑战并将其建模为组合优化任务，以实现在考虑赞助产品的情况下优化预期收入的目的。

    

    在零售行业快速发展的背景下，品类规划对于企业的成功起着至关重要的作用。随着赞助产品在在线市场的日益突出地位，零售商在有效管理产品品类方面面临新的挑战。值得注意的是，以前的品类规划研究大多忽视了赞助产品的存在及其对整体推荐效果可能产生的影响。相反，他们通常简化地假设所有产品都是有机产品或非赞助产品。这个研究空白突显了在赞助产品存在的情况下更深入探讨品类规划挑战的必要性。我们将在存在赞助产品的情况下将品类规划问题建模为组合优化任务。最终目标是计算出一种最优的品类规划方案，既能优化预期收入，又能考虑到赞助产品的存在。

    In the rapidly evolving landscape of retail, assortment planning plays a crucial role in determining the success of a business. With the rise of sponsored products and their increasing prominence in online marketplaces, retailers face new challenges in effectively managing their product assortment in the presence of sponsored products. Remarkably, previous research in assortment planning largely overlooks the existence of sponsored products and their potential impact on overall recommendation effectiveness. Instead, they commonly make the simplifying assumption that all products are either organic or non-sponsored. This research gap underscores the necessity for a more thorough investigation of the assortment planning challenge when sponsored products are in play. We formulate the assortment planning problem in the presence of sponsored products as a combinatorial optimization task. The ultimate objective is to compute an assortment plan that optimizes expected revenue while considerin
    
[^11]: 基于人物的服装生成与通过LLMs进行视觉增强的风格提取

    Character-based Outfit Generation with Vision-augmented Style Extraction via LLMs

    [https://arxiv.org/abs/2402.05941](https://arxiv.org/abs/2402.05941)

    本文提出了一个新的基于人物的服装生成（COG）问题，旨在准确解释人物信息并根据用户的规范生成服装组合。我们提出了一个新颖的框架LVA-COG，利用大型语言模型（LLMs）从用户的兴趣中提取见解，并结合文本到图像模型，增强了对连贯服装的视觉理解和生成。

    

    服装生成问题涉及根据用户的兴趣推荐一个完整的服装。现有方法主要基于锚定商品或指定查询风格来推荐物品，但不考虑用户对电影、社交媒体等中著名人物的兴趣。本文定义了一个新的基于人物的服装生成（COG）问题，旨在准确解释人物信息，并根据用户的规范（如年龄和性别）生成完整的服装组合。为了解决这个问题，我们提出了一个新颖的框架LVA-COG，利用大型语言模型（LLMs）从用户的兴趣（例如人物信息）中提取见解，并采用提示工程技术准确理解用户的喜好。此外，我们还结合了文本到图像模型，增强了对连贯服装的视觉理解和生成（事实或反事实）。我们的框架将LLMs与文本到图像模型整合起来。

    The outfit generation problem involves recommending a complete outfit to a user based on their interests. Existing approaches focus on recommending items based on anchor items or specific query styles but do not consider customer interests in famous characters from movie, social media, etc. In this paper, we define a new Character-based Outfit Generation (COG) problem, designed to accurately interpret character information and generate complete outfit sets according to customer specifications such as age and gender. To tackle this problem, we propose a novel framework LVA-COG that leverages Large Language Models (LLMs) to extract insights from customer interests (e.g., character information) and employ prompt engineering techniques for accurate understanding of customer preferences. Additionally, we incorporate text-to-image models to enhance the visual understanding and generation (factual or counterfactual) of cohesive outfits. Our framework integrates LLMs with text-to-image models 
    
[^12]: 知识图谱与多模态学习：综述

    Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2402.05391](https://arxiv.org/abs/2402.05391)

    知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。

    

    知识图谱在推动各种人工智能应用方面起着关键作用，语义网络社区对多模态维度的探索为创新打开了新的途径。在本综述中，我们仔细审查了300多篇文章，重点关注了两个主要方面的知识图谱感知研究：以知识图谱支持多模态任务的KG驱动多模态（KG4MM）学习，将知识图谱研究扩展到多模态知识图谱（MM4KG）领域。我们从定义知识图谱和多模态知识图谱开始，然后探索它们的构建进展。我们的综述包括两个主要任务类别：KG感知的多模态学习任务，如图像分类和视觉问答，以及内在的多模态知识图谱任务，如多模态知识图谱补全和实体对齐，突出了具体的研究轨迹。对于这些任务中的大部分，我们提供了定义、评估基准，并进一步指出进行相关研究的重要见解。最后，我们讨论了cu

    Knowledge Graphs (KGs) play a pivotal role in advancing various AI applications, with the semantic web community's exploration into multi-modal dimensions unlocking new avenues for innovation. In this survey, we carefully review over 300 articles, focusing on KG-aware research in two principal aspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal tasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into the MMKG realm. We begin by defining KGs and MMKGs, then explore their construction progress. Our review includes two primary task categories: KG-aware multi-modal learning tasks, such as Image Classification and Visual Question Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph Completion and Entity Alignment, highlighting specific research trajectories. For most of these tasks, we provide definitions, evaluation benchmarks, and additionally outline essential insights for conducting relevant research. Finally, we discuss cu
    
[^13]: 多模态查询建议中的多智能体强化学习与人类反馈

    Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback

    [https://arxiv.org/abs/2402.04867](https://arxiv.org/abs/2402.04867)

    本论文介绍了一种基于多智能体强化学习和人类反馈的多模态查询建议系统。通过利用语言模型和强化学习算法，该系统能够根据用户的查询图像生成个性化的查询建议，从而提高搜索结果的意图性和多样性。

    

    在信息检索的快速发展环境中，搜索引擎致力于为用户提供更个性化和相关性更强的结果。查询建议系统在实现这一目标方面起着重要作用，通过协助用户制定有效的查询。然而，现有的查询建议系统主要依赖于文本输入，可能限制用户对图像查询的体验。本文提出了一种新颖的多模态查询建议（MMQS）任务，旨在基于用户查询图像生成查询建议，以提高搜索结果的意图性和多样性。我们提出了RL4Sugg框架，利用大型语言模型（LLM）和多智能体强化学习与人类反馈的力量来优化生成过程。通过全面的实验，我们验证了RL4Sugg的有效性，与最佳现有方法相比，获得了18%的改进。此外，MMQS已经在实际环境中得到了应用。

    In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world s
    
[^14]: 请求级别推荐中的未来影响分解

    Future Impact Decomposition in Request-level Recommendations

    [https://arxiv.org/abs/2401.16108](https://arxiv.org/abs/2401.16108)

    在请求级别的推荐系统中，我们通过比较标准方法和基于物品级别的演员-评论家框架在模拟和在线实验中的性能，证明了基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。

    

    在推荐系统中，强化学习解决方案在优化用户和系统之间的交互序列以提高长期性能方面显示出有希望的结果。出于实际原因，策略的动作通常被设计为推荐一组物品以更高效地处理用户的频繁和连续的浏览请求。在这种列表式推荐场景中，用户状态在相应的MDP（马尔可夫决策过程）表述中的每个请求上都会更新。然而，这种请求级别的表述与用户的物品级别行为实质上是不一致的。在这项研究中，我们证明了在请求级别MDP下，基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。我们通过比较标准请求级别方法和提出的基于物品级别的演员-评论家框架在模拟和在线实验中的性能来支持这一观点。

    In recommender systems, reinforcement learning solutions have shown promising results in optimizing the interaction sequence between users and the system over the long-term performance. For practical reasons, the policy's actions are typically designed as recommending a list of items to handle users' frequent and continuous browsing requests more efficiently. In this list-wise recommendation scenario, the user state is updated upon every request in the corresponding MDP formulation. However, this request-level formulation is essentially inconsistent with the user's item-level behavior. In this study, we demonstrate that an item-level optimization approach can better utilize item characteristics and optimize the policy's performance even under the request-level MDP. We support this claim by comparing the performance of standard request-level methods with the proposed item-level actor-critic framework in both simulation and online experiments. Furthermore, we show that a reward-based fut
    
[^15]: 两边平台中反馈循环引起的干扰下的卖家实验

    Seller-Side Experiments under Interference Induced by Feedback Loops in Two-Sided Platforms

    [https://arxiv.org/abs/2401.15811](https://arxiv.org/abs/2401.15811)

    本文研究了两边平台中反馈循环引起的干扰对卖家实验的影响，提出了数学框架进行分析并实证评估了反事实交错设计，结果显示反馈循环可能导致误导性的结论。

    

    两边平台在现代商业和内容分享中起着重要作用，通常使用A/B测试来开发新功能。尽管用户端实验很常见，但对于特定干预和指标，卖家端实验变得至关重要。本文研究了反馈循环引起的干扰对两边平台卖家实验的影响，特别关注在\citet{ha2020counterfactual,nandy2021b}中提出的反事实交错设计。这些反馈循环通常由节奏算法产生，会导致早期会话的结果影响后续会话。本文通过创建数学框架来分析这种干扰，理论估计其影响，并在实际情境中进行反事实交错设计的实证评估。我们的研究表明，反馈循环可能导致对处理效果做出误导性的结论。

    Two-sided platforms are central to modern commerce and content sharing and often utilize A/B testing for developing new features. While user-side experiments are common, seller-side experiments become crucial for specific interventions and metrics. This paper investigates the effects of interference caused by feedback loops on seller-side experiments in two-sided platforms, with a particular focus on the counterfactual interleaving design, proposed in \citet{ha2020counterfactual,nandy2021b}. These feedback loops, often generated by pacing algorithms, cause outcomes from earlier sessions to influence subsequent ones. This paper contributes by creating a mathematical framework to analyze this interference, theoretically estimating its impact, and conducting empirical evaluations of the counterfactual interleaving design in real-world scenarios. Our research shows that feedback loops can result in misleading conclusions about the treatment effects.
    
[^16]: 论用户响应模拟在对话式搜索中的深入研究

    An In-depth Investigation of User Response Simulation for Conversational Search. (arXiv:2304.07944v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2304.07944](http://arxiv.org/abs/2304.07944)

    本文研究了对话式搜索中用户响应模拟的方法。当前的模拟系统要么只能对是非问题进行回答，要么无法产生高质量的响应。通过用更小但先进的系统替换当前最先进的用户模拟系统，能够显著改进性能。

    

    对话式搜索在信息检索和自然语言处理领域引起了广泛关注。它通过多次自然语言交互来澄清和解决用户的搜索需求。然而，大多数现有系统是通过记录或人工对话日志进行训练和演示的。最终，对话式搜索系统应该在未见过的对话轨迹的开放环境中进行训练、评估和部署。一个关键的挑战是训练和评估这样的系统都需要人工参与，这既昂贵又不可扩展。其中一种策略是模拟用户，以此来减少扩展成本。然而，当前的用户模拟器要么仅限于对对话搜索系统的是非问题进行回答，要么无法产生高质量的响应。本文表明，通过用一个更小但先进的系统来替换当前最先进的用户模拟系统，能够大幅改进其性能。

    Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve a user's search need through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy for this is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only respond to yes-no questions from the conversational search system, or unable to produce high quality responses in general.  In this paper, we show that current state-of-the-art user simulation system could be significantly improved by replacing it with a smaller but advanced
    

