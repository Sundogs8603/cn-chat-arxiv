# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [STUDY: Socially Aware Temporally Casual Decoder Recommender Systems.](http://arxiv.org/abs/2306.07946) | 该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。 |
| [^2] | [Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision.](http://arxiv.org/abs/2306.07908) | 本文介绍了一种新的评估方法，称为词典精度或lexiprecision，该方法通过提高对最满意用户的排名质量的评估来解决倒数排名的灵敏性缺乏问题。 |
| [^3] | [ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading.](http://arxiv.org/abs/2306.07875) | ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。 |
| [^4] | [KuaiSAR: A Unified Search And Recommendation Dataset.](http://arxiv.org/abs/2306.07705) | 这篇论文介绍了一份大规模、真实的数据集KuaiSAR，该数据集记录了快手短视频应用程序中真实的集成搜索和推荐行为。 |
| [^5] | [Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square Two-tower model, HNSW, Sign Cauchy Projections.](http://arxiv.org/abs/2306.07607) | 本文探索了在稀疏数据中使用基于图的ANN算法进行高效搜索，特别是HNSW算法在搜索稀疏嵌入方面特别有效。提出了适用于实际中常见的稀疏嵌入的SGN变体，实验结果表明我们提出的算法可以达到最先进的性能水平。 |
| [^6] | [Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective.](http://arxiv.org/abs/2306.07528) | 本文提出了点击模型不可知的统一非同策略学习排序（CUOLR）方法，通过离线强化学习（RL）直接学习最优排名，可以轻松地应用于各种点击模型。 |
| [^7] | [Topic-Centric Explanations for News Recommendation.](http://arxiv.org/abs/2306.07506) | 提出了一种基于主题的解释性新闻推荐模型，可以准确地识别相关文章并解释为什么推荐这些文章，同时提高了解释的可解释性度量。 |
| [^8] | [Incentivizing High-Quality Content in Online Recommender Systems.](http://arxiv.org/abs/2306.07479) | 本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。 |
| [^9] | [Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard.](http://arxiv.org/abs/2306.07471) | 提供了BEIR基准数据集的可重复参考实现和官方排行榜以跟踪模型性能和进展。 |
| [^10] | [Fair Learning to Rank with Distribution-free Risk Control.](http://arxiv.org/abs/2306.07188) | 本论文提出了一种新的后置模型无关方法，公平LTR-RC，它不需要昂贵的训练，在保证公平性的同时，还能在效用和公平之间实现有效的权衡。 |
| [^11] | [Controllable Multi-Objective Re-ranking with Policy Hypernetworks.](http://arxiv.org/abs/2306.05118) | 本文提出一种名为CMR的新框架，用于解决在推荐系统中的多目标再排序问题。该框架使用策略超网络，使得偏好权重可以在线优化，而不用重新训练模型。 |
| [^12] | [Gen-IR @ SIGIR 2023: The First Workshop on Generative Information Retrieval.](http://arxiv.org/abs/2306.02887) | 本研讨会旨在探讨生成式信息检索（IR）的新指标、理论基础、评估方法、任务定义、模型和用户界面等，以探究它是否是IR的范式转变。该研讨会关注先前探索过的技术，并提供一个地点用于探讨和探索如何将生成式IR应用于新领域。 |
| [^13] | [TEIMMA: The First Content Reuse Annotator for Text, Images, and Math.](http://arxiv.org/abs/2305.13193) | TEIMMA 是一款可以注释文本、图片和数学公式重用的工具，能够记录不同类型的重用并支持可视化查看内容重复，有助于开发检测抄袭算法。 |
| [^14] | [DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for CTR Prediction.](http://arxiv.org/abs/2305.04891) | 该论文提出了一种名为DELTA的CTR模型，使用截断意识注意力进行动态嵌入学习，有效地解决了上下文中无效和冗余特征的问题。 |
| [^15] | [Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure.](http://arxiv.org/abs/2211.10738) | 本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。 |
| [^16] | [Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach.](http://arxiv.org/abs/2110.04514) | 本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。 |
| [^17] | [A Trio Neural Model for Dynamic Entity Relatedness Ranking.](http://arxiv.org/abs/1808.08316) | 这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。 |
| [^18] | [Multiple Models for Recommending Temporal Aspects of Entities.](http://arxiv.org/abs/1803.07890) | 本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。 |

# 详细

[^1]: 研究：社交感知时间松散解码器推荐系统

    STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. (arXiv:2306.07946v1 [cs.SI])

    [http://arxiv.org/abs/2306.07946](http://arxiv.org/abs/2306.07946)

    该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。

    

    随着现在在线和离线可获取的数据数量过于庞大，推荐系统变得越来越必要，以帮助用户找到符合他们兴趣的物品。当社交网络信息存在时，有一些方法利用这些信息来做出更好的推荐，但这些方法通常有复杂的结构和训练过程。此外，许多现有的方法使用图神经网络，而这些网络训练起来非常困难。为了解决这个问题，我们提出了基于社交感知和时间因素的解码器推荐系统(STUDY)。STUDY采用一个经过修改的transformer解码器网络的单向前传，对社交网络图中相邻的用户组进行联合推断。我们在基于学校课堂结构定义社交网络的教育内容领域测试了我们的方法。我们的方法在保持单一均匀网络设计简单性的同时，优于社交和顺序方法。

    With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks. Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous netw
    
[^2]: 最佳情况检索评估：用词典精度提高倒数排名的灵敏度

    Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision. (arXiv:2306.07908v1 [cs.IR])

    [http://arxiv.org/abs/2306.07908](http://arxiv.org/abs/2306.07908)

    本文介绍了一种新的评估方法，称为词典精度或lexiprecision，该方法通过提高对最满意用户的排名质量的评估来解决倒数排名的灵敏性缺乏问题。

    

    在各种排名任务中，研究人员使用倒数排名来衡量对仅对一个相关项感兴趣的用户的效果。尽管广泛使用，但有证据表明，倒数排名在区分系统方面是脆弱的。这种脆弱性在现代评估环境中得到了强化，其中当前的高精度系统可能难以区分。我们通过引入并将其与最佳情况检索的概念相联系来解决倒数排名的灵敏性缺乏问题，后者是一种评估方法，专注于对可能的召回要求下最满意的用户的排名质量进行评估。这个观点使我们能够推广倒数排名并定义一种新的基于偏好的评估，我们称之为词典精度或lexiprecision。通过数学构造，我们确保lexiprecision保留了倒数排名检测到的区别，同时在广泛的基准排名上提高了灵敏度和鲁棒性。

    Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a br
    
[^3]: ReadProbe: 一种支持横向阅读的检索增强大语言模型演示

    ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading. (arXiv:2306.07875v1 [cs.IR])

    [http://arxiv.org/abs/2306.07875](http://arxiv.org/abs/2306.07875)

    ReadProbe 是一种利用大型语言模型和搜索引擎支持横向阅读的工具，它能够生成有用问题和答案以帮助用户评估在线信息。

    

    随着网络不实信息的快速增长和传播，人们需要工具来帮助他们评估在线信息的可信度和准确性。横向阅读是一种跨参考多个信息源的策略，可能是实现这一目标的有效方法。在本文中，我们提出了一个工具，名为 ReadProbe，它支持横向阅读，由 OpenAI 的生成式大语言模型和必应搜索引擎驱动。我们的工具能够为横向阅读生成有用的问题，搜寻网络上相关的文档，并产生良好归因的答案，帮助人们更好地评估在线信息。我们制作了一个基于 Web 的应用程序，演示了 ReadProbe 如何帮助减少被虚假信息误导的风险。我们的代码可在 https://github.com/DakeZhang1998/ReadProbe 上获得，我们的早期版本赢得了全国人工智能虚假信息黑客马拉松的一等奖。

    With the rapid growth and spread of online misinformation, people need tools to help them evaluate the credibility and accuracy of online information. Lateral reading, a strategy that involves cross-referencing information with multiple sources, may be an effective approach to achieving this goal. In this paper, we present ReadProbe, a tool to support lateral reading, powered by generative large language models from OpenAI and the Bing search engine. Our tool is able to generate useful questions for lateral reading, scour the web for relevant documents, and generate well-attributed answers to help people better evaluate online information. We made a web-based application to demonstrate how ReadProbe can help reduce the risk of being misled by false information. The code is available at https://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won the first prize in a national AI misinformation hackathon.
    
[^4]: KuaiSAR: 一份统一的搜索与推荐数据集

    KuaiSAR: A Unified Search And Recommendation Dataset. (arXiv:2306.07705v1 [cs.IR])

    [http://arxiv.org/abs/2306.07705](http://arxiv.org/abs/2306.07705)

    这篇论文介绍了一份大规模、真实的数据集KuaiSAR，该数据集记录了快手短视频应用程序中真实的集成搜索和推荐行为。

    

    搜索和推荐服务的融合是像快手和抖音这样的在线内容平台的重要方面。S&R建模的整合是业界实践者采用的高度直观的方法。然而，由于缺乏公开可用的数据集，学术界在这个领域中进行的研究明显不足。因此，在学术界和产业界之间在这个领域进行研究的实践之间出现了实质性的差距。为了弥合这个差距，我们介绍了快手的一个领先短视频应用程序收集的集成搜索与推荐行为的大规模真实世界数据集KuaiSAR。与以前的数据集不同，KuaiSAR记录了真实用户的行为，每个行为的发生时间都被精确记录了。

    The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each in
    
[^5]: 基于图的ANN算法在稀疏数据上的应用：卡方双塔模型、HNSW、符号柯西投影

    Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square Two-tower model, HNSW, Sign Cauchy Projections. (arXiv:2306.07607v1 [cs.IR])

    [http://arxiv.org/abs/2306.07607](http://arxiv.org/abs/2306.07607)

    本文探索了在稀疏数据中使用基于图的ANN算法进行高效搜索，特别是HNSW算法在搜索稀疏嵌入方面特别有效。提出了适用于实际中常见的稀疏嵌入的SGN变体，实验结果表明我们提出的算法可以达到最先进的性能水平。

    

    在实际应用中，稀疏数据很常见。传统的“手工制作”的特征通常是稀疏的。通过训练得到的嵌入向量也可能非常稀疏，例如使用“ReLu”激活函数训练的嵌入。本文探讨了使用基于图的ANN算法（例如，HNSW或其GPU版本SONG）进行稀疏数据中的高效搜索，这些算法在工业实践中非常流行，例如搜索和广告（广告投放）。我们进行了专利广告定向应用的实验，并测试了基准公共数据集。对于广告定向，我们使用标准的“余弦双塔”模型和开发的“卡方双塔”模型训练嵌入，这两种模型都能够产生（非常）稀疏的嵌入，当它们与“ReLu”激活函数集成时。在嵌入式检索（EBR）应用中，在训练完嵌入向量后，下一个至关重要的任务是用于服务的近似最近邻（ANN）搜索。虽然有许多ANN算法可用，但基于图的算法已知是高效且可扩展的。我们经验证明，基于图的算法，特别是HNSW在搜索稀疏嵌入（高达97％的稀疏度）方面特别有效。我们还提出了适用于实际中常见的稀疏嵌入的SGN变体（符号柯西投影）。我们将所提出的算法在公共数据集以及来自广告应用的实际数据上进行了测试。实验结果表明，我们提出的算法可以达到最先进的性能水平。

    Sparse data are common. The traditional ``handcrafted'' features are often sparse. Embedding vectors from trained models can also be very sparse, for example, embeddings trained via the ``ReLu'' activation function. In this paper, we report our exploration of efficient search in sparse data with graph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of HNSW), which are popular in industrial practice, e.g., search and ads (advertising).  We experiment with the proprietary ads targeting application, as well as benchmark public datasets. For ads targeting, we train embeddings with the standard ``cosine two-tower'' model and we also develop the ``chi-square two-tower'' model. Both models produce (highly) sparse embeddings when they are integrated with the ``ReLu'' activation function. In EBR (embedding-based retrieval) applications, after we the embeddings are trained, the next crucial task is the approximate near neighbor (ANN) search for serving. While there are many AN
    
[^6]: 统一的非同策略学习排序：强化学习视角

    Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective. (arXiv:2306.07528v1 [cs.LG])

    [http://arxiv.org/abs/2306.07528](http://arxiv.org/abs/2306.07528)

    本文提出了点击模型不可知的统一非同策略学习排序（CUOLR）方法，通过离线强化学习（RL）直接学习最优排名，可以轻松地应用于各种点击模型。

    

    非同策略学习排序（LTR）旨在通过已部署的记录策略收集的数据优化排名器。然而，现有的非同策略学习排序方法经常对用户如何生成点击数据即点击模型进行假设，因此需要根据不同的点击模型专门调整他们的方法。在本文中，我们将排名过程在一般随机点击模型下统一为马尔可夫决策过程（MDP），通过离线强化学习（RL），可以直接学习最优排名。在此基础上，我们利用离线RL技术进行非同策略LTR，并提出点击模型不可知的统一非同策略学习排序（CUOLR）方法，该方法可以轻松地应用于各种点击模型。通过对MDP的专门制定，我们证明了离线RL算法可以适应各种点击模型，而无需复杂的去偏倚技术和先验知识。在各种大规模数据集上的实验结果都证明了我们方法的有效性。

    Off-policy Learning to Rank (LTR) aims to optimize a ranker from data collected by a deployed logging policy. However, existing off-policy learning to rank methods often make strong assumptions about how users generate the click data, i.e., the click model, and hence need to tailor their methods specifically under different click models. In this paper, we unified the ranking process under general stochastic click models as a Markov Decision Process (MDP), and the optimal ranking could be learned with offline reinforcement learning (RL) directly. Building upon this, we leverage offline RL techniques for off-policy LTR and propose the Click Model-Agnostic Unified Off-policy Learning to Rank (CUOLR) method, which could be easily applied to a wide range of click models. Through a dedicated formulation of the MDP, we show that offline RL algorithms can adapt to various click models without complex debiasing techniques and prior knowledge of the model. Results on various large-scale datasets
    
[^7]: 基于主题的新闻推荐的解释性方法

    Topic-Centric Explanations for News Recommendation. (arXiv:2306.07506v1 [cs.IR])

    [http://arxiv.org/abs/2306.07506](http://arxiv.org/abs/2306.07506)

    提出了一种基于主题的解释性新闻推荐模型，可以准确地识别相关文章并解释为什么推荐这些文章，同时提高了解释的可解释性度量。

    

    新闻推荐系统被广泛应用于在线新闻网站，以帮助用户根据他们的兴趣找到相关文章。然而，推荐缺乏解释会导致用户的不信任和推荐的缺乏接受度。为了解决这个问题，我们提出了一种新的可解释的新闻模型，构建了一个基于主题的解释性推荐方法，可以准确地识别相关文章并解释为什么推荐这些文章，利用相关主题的信息。此外，我们的模型结合了两种用于评估主题质量的一致性度量，提供了这些解释的可解释性的度量。我们在MIND数据集上的实验结果表明，所提出的可解释性NRS优于其他几个基线系统，同时还能够产生可解释的主题。

    News recommender systems (NRS) have been widely applied for online news websites to help users find relevant articles based on their interests. Recent methods have demonstrated considerable success in terms of recommendation performance. However, the lack of explanation for these recommendations can lead to mistrust among users and lack of acceptance of recommendations. To address this issue, we propose a new explainable news model to construct a topic-aware explainable recommendation approach that can both accurately identify relevant articles and explain why they have been recommended, using information from associated topics. Additionally, our model incorporates two coherence metrics applied to assess topic quality, providing measure of the interpretability of these explanations. The results of our experiments on the MIND dataset indicate that the proposed explainable NRS outperforms several other baseline systems, while it is also capable of producing interpretable topics compared 
    
[^8]: 在在线推荐系统中激励高质量内容

    Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])

    [http://arxiv.org/abs/2306.07479](http://arxiv.org/abs/2306.07479)

    本文研究了在线推荐系统中激励高质量内容的算法问题，经典的在线学习算法会激励生产者创建低质量的内容，但本文提出的一种算法通过惩罚低质量内容的创建者，成功地激励了生产者创造高质量的内容。

    

    对于像TikTok和YouTube这样的内容推荐系统，平台的决策算法塑造了内容生产者的激励，包括生产者在内容质量上投入多少努力。许多平台采用在线学习，这会产生跨时间的激励，因为今天生产的内容会影响未来内容的推荐。在本文中，我们研究了在线学习产生的激励，分析了在纳什均衡下生产的内容质量。我们发现，像Hedge和EXP3这样的经典在线学习算法会激励生产者创建低质量的内容。特别地，内容质量在学习率方面有上限，并且随着典型学习率进展而趋近于零。在这一负面结果的基础上，我们设计了一种不同的学习算法——基于惩罚创建低质量内容的生产者——正确激励生产者创建高质量内容。我们的算法依赖于新颖的策略性赌博机问题，并克服了在组合设置中应用对抗性技术的挑战。在模拟和真实数据的实验中，我们的算法成功地激励生产者创建高质量内容。

    For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
    
[^9]: 《用于编制BEIR的资源：可重复参考模型和官方排行榜》

    Resources for Brewing BEIR: Reproducible Reference Models and an Official Leaderboard. (arXiv:2306.07471v1 [cs.IR])

    [http://arxiv.org/abs/2306.07471](http://arxiv.org/abs/2306.07471)

    提供了BEIR基准数据集的可重复参考实现和官方排行榜以跟踪模型性能和进展。

    

    BEIR是一个跨越18个不同领域/任务组合进行零样本评估的基准数据集，用于信息检索模型。我们目睹了利用预先训练的transformers在监督学习框架下建立检索模型的表示学习方法的日益普及。但这自然会引出一个问题：这些模型在遇到与训练数据不同的查询和文档时有多有效？我们的工作解决了BEIR在实现其全部潜力方面存在的两个缺陷。第一，现代神经方法的复杂性和当前的软件基础设施创建了对新手的进入门槛。为此，我们提供了覆盖两个主要检索模型类的可重复参考实现。第二，虽然BEIR提供了多样化的测试套件，但没有官方排名榜可跟踪模型性能和进展。为解决这个问题，我们为参与者提供了一个官方BEIR排行榜，可提交结果并与最先进的模型进行比较。

    BEIR is a benchmark dataset for zero-shot evaluation of information retrieval models across 18 different domain/task combinations. In recent years, we have witnessed the growing popularity of a representation learning approach to building retrieval models, typically using pretrained transformers in a supervised setting. This naturally begs the question: How effective are these models when presented with queries and documents that differ from the training data? Examples include searching in different domains (e.g., medical or legal text) and with different types of queries (e.g., keywords vs. well-formed questions). While BEIR was designed to answer these questions, our work addresses two shortcomings that prevent the benchmark from achieving its full potential: First, the sophistication of modern neural methods and the complexity of current software infrastructure create barriers to entry for newcomers. To this end, we provide reproducible reference implementations that cover the two m
    
[^10]: 无分布风险控制的公平学习排序

    Fair Learning to Rank with Distribution-free Risk Control. (arXiv:2306.07188v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.07188](http://arxiv.org/abs/2306.07188)

    本论文提出了一种新的后置模型无关方法，公平LTR-RC，它不需要昂贵的训练，在保证公平性的同时，还能在效用和公平之间实现有效的权衡。

    

    在线经济中，学习排序方法对用户和物品提供者至关重要。LTR模型的公平性对于按比例分配曝光至关重要。当具有相同相关性的项接收略有不同的分数时，确定性排名模型可能导致不公平的曝光分配。随机LTR模型，包括Plackett-Luce（PL）模型，解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了公平LTR-RC，一种新的后置模型无关方法。公平LTR-RC利用预先训练的评分函数创建随机LTR模型，消除了昂贵的训练需求。此外，公平LTR-RC使用无分布式风险控制框架对用户指定的效用提供有限的样本保证。通过另外结合Thresholded PL（TPL）模型，我们能够在效用和公平之间实现有效的权衡。实验结果显示，FairLTR-RC在公平性和效用性指标上优于现有方法。

    Learning to Rank (LTR) methods are vital in online economies, affecting users and item providers. Fairness in LTR models is crucial to allocate exposure proportionally to item relevance. The deterministic ranking model can lead to unfair exposure distribution when items with the same relevance receive slightly different scores. Stochastic LTR models, incorporating the Plackett-Luce (PL) model, address fairness issues but have limitations in computational cost and performance guarantees. To overcome these limitations, we propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC leverages a pretrained scoring function to create a stochastic LTR model, eliminating the need for expensive training. Furthermore, FairLTR-RC provides finite-sample guarantees on a user-specified utility using distribution-free risk control framework. By additionally incorporating the Thresholded PL (TPL) model, we are able to achieve an effective trade-off between utility and fairness. Experimental
    
[^11]: 用策略超网络的可控多目标再排序

    Controllable Multi-Objective Re-ranking with Policy Hypernetworks. (arXiv:2306.05118v1 [cs.IR])

    [http://arxiv.org/abs/2306.05118](http://arxiv.org/abs/2306.05118)

    本文提出一种名为CMR的新框架，用于解决在推荐系统中的多目标再排序问题。该框架使用策略超网络，使得偏好权重可以在线优化，而不用重新训练模型。

    

    多阶段排名管道已成为现代推荐系统中广泛使用的策略，其中最终阶段旨在返回一个排名列表，以平衡用户偏好、多样性、新颖性等多个要求。线性标量化是将多个要求合并为一个优化目标最广泛使用的技术，通过使用一定的偏好权重来总结这些要求。现有的最终阶段排名方法通常采用静态模型，其中偏好权重在离线训练期间确定，并在在线服务期间保持不变。每当需要修改偏好权重时，模型必须重新训练，这是时间和资源上的浪费。同时，不同用户群体或不同时间段（例如，在节日促销期间）的最合适权重可能会有很大的差异。本文提出了一种称为可控多目标再排序（CMR）的框架，该框架使用策略超网络，以使偏好权重在线优化，而不必重新训练模型。所提出的框架具有灵活性和可控性，为推荐系统中的多目标再排序问题提供了有效的解决方案。

    Multi-stage ranking pipelines have become widely used strategies in modern recommender systems, where the final stage aims to return a ranked list of items that balances a number of requirements such as user preference, diversity, novelty etc. Linear scalarization is arguably the most widely used technique to merge multiple requirements into one optimization objective, by summing up the requirements with certain preference weights. Existing final-stage ranking methods often adopt a static model where the preference weights are determined during offline training and kept unchanged during online serving. Whenever a modification of the preference weights is needed, the model has to be re-trained, which is time and resources inefficient. Meanwhile, the most appropriate weights may vary greatly for different groups of targeting users or at different time periods (e.g., during holiday promotions). In this paper, we propose a framework called controllable multi-objective re-ranking (CMR) whic
    
[^12]: 2023年SIGIR会议上的Gen-IR研讨会：生成式信息检索的首个研讨会

    Gen-IR @ SIGIR 2023: The First Workshop on Generative Information Retrieval. (arXiv:2306.02887v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.02887](http://arxiv.org/abs/2306.02887)

    本研讨会旨在探讨生成式信息检索（IR）的新指标、理论基础、评估方法、任务定义、模型和用户界面等，以探究它是否是IR的范式转变。该研讨会关注先前探索过的技术，并提供一个地点用于探讨和探索如何将生成式IR应用于新领域。

    

    生成式信息检索（IR）在多个研究社区（例如信息检索、计算机视觉、自然语言处理和机器学习）中得到了显著增长，并在流行媒体上备受关注。已发布了理论、实证和实际用户产品，这些产品可以通过生成文档（通过生成）或直接生成答案来检索文档或回答输入请求。我们想调查端到端生成模型是否只是另一种趋势，还是像某些人所声称的那样，是IR的范式转变。这需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。本次研讨会的目标是关注先前探索过的生成式IR技术，如文档检索和直接实现的基础答案生成，同时也提供一个地点用于探讨和探索生成式IR如何应用于推荐等新领域。

    Generative information retrieval (IR) has experienced substantial growth across multiple research communities (e.g., information retrieval, computer vision, natural language processing, and machine learning), and has been highly visible in the popular press. Theoretical, empirical, and actual user-facing products have been released that retrieve documents (via generation) or directly generate answers given an input request. We would like to investigate whether end-to-end generative models are just another trend or, as some claim, a paradigm change for IR. This necessitates new metrics, theoretical grounding, evaluation methods, task definitions, models, user interfaces, etc. The goal of this workshop (https://coda.io/@sigir/gen-ir) is to focus on previously explored Generative IR techniques like document retrieval and direct Grounded Answer Generation, while also offering a venue for the discussion and exploration of how Generative IR can be applied to new domains like recommendation s
    
[^13]: TEIMMA：第一个支持文本、图片和数学公式内容重用注释的工具

    TEIMMA: The First Content Reuse Annotator for Text, Images, and Math. (arXiv:2305.13193v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.13193](http://arxiv.org/abs/2305.13193)

    TEIMMA 是一款可以注释文本、图片和数学公式重用的工具，能够记录不同类型的重用并支持可视化查看内容重复，有助于开发检测抄袭算法。

    

    本篇论文介绍了 TEIMMA 工具，这是第一个对文本、图片和数学公式在文档对中重用进行注释的工具。注释内容重用对于开发检测抄袭算法非常有用。现实中的内容重用通常被混淆，这使得识别此类情况变得具有挑战性。TEIMMA 允许输入混淆类型，以便针对已确认的抄袭案例进行新的分类。它可以记录 HTML 中文本、图片和数学公式的不同重用类型，并使用文本和数学相似度检测方法支持用户可视化查看文档对中的内容重复。

    This demo paper presents the first tool to annotate the reuse of text, images, and mathematical formulae in a document pair -- TEIMMA. Annotating content reuse is particularly useful to develop plagiarism detection algorithms. Real-world content reuse is often obfuscated, which makes it challenging to identify such cases. TEIMMA allows entering the obfuscation type to enable novel classifications for confirmed cases of plagiarism. It enables recording different reuse types for text, images, and mathematical formulae in HTML and supports users by visualizing the content reuse in a document pair using similarity detection methods for text and math.
    
[^14]: 带有截断意识注意力的动态嵌入学习模型用于CTR预测

    DELTA: Dynamic Embedding Learning with Truncated Conscious Attention for CTR Prediction. (arXiv:2305.04891v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.04891](http://arxiv.org/abs/2305.04891)

    该论文提出了一种名为DELTA的CTR模型，使用截断意识注意力进行动态嵌入学习，有效地解决了上下文中无效和冗余特征的问题。

    

    点击率（CTR）预测是产品和内容推荐中关键的任务，学习有效的特征嵌入具有重要意义。传统方法通常学习固定的特征表示，而缺乏根据上下文信息动态调整特征表示的机制，导致性能不佳。一些近期的方法尝试通过学习位权重或增强嵌入来解决这个问题，但是受到上下文中无信息或冗余特征的影响。为了解决这个问题，我们借鉴了意识加工中全局工作区理论，该理论认为只有特定的产品特征与点击行为相关，其余特征可能会噪音干扰，甚至有害，因此提出了一种带有截断意识注意力的动态嵌入学习模型DELTA进行CTR预测。

    Click-Through Rate (CTR) prediction is a pivotal task in product and content recommendation, where learning effective feature embeddings is of great significance. However, traditional methods typically learn fixed feature representations without dynamically refining feature representations according to the context information, leading to suboptimal performance. Some recent approaches attempt to address this issue by learning bit-wise weights or augmented embeddings for feature representations, but suffer from uninformative or redundant features in the context. To tackle this problem, inspired by the Global Workspace Theory in conscious processing, which posits that only a specific subset of the product features are pertinent while the rest can be noisy and even detrimental to human-click behaviors, we propose a CTR model that enables Dynamic Embedding Learning with Truncated Conscious Attention for CTR prediction, termed DELTA. DELTA contains two key components: (I) conscious truncatio
    
[^15]: 基于关系对称结构的知识图谱对比学习

    Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure. (arXiv:2211.10738v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.10738](http://arxiv.org/abs/2211.10738)

    本论文提出了一种基于关系对称结构的知识图谱对比学习框架 KGE-SymCL，它能有效地提高知识图谱中实体的可区分度。

    

    知识图谱嵌入 (KGE) 旨在学习强大的表示以受益于各种人工智能应用。与此同时，对比学习已被广泛利用于图学习，作为增强所学表示的可区分能力的有效机制。然而，KG的复杂结构使得构建适当的对比对变得困难。为数不多的几个尝试将对比学习策略与KGE集成。但是，它们大多依赖于语言模型（例如Bert）进行对比对构建，而不是完全挖掘潜在的图结构信息，从而阻碍了表达能力。令人惊讶的是，我们发现关系对称结构内的实体通常相似且相关。因此，我们提出了一种基于关系对称结构的知识图谱对比学习框架，KGE-SymCL，它在KG中挖掘对称结构信息以增强所学表示的区分能力。

    Knowledge graph embedding (KGE) aims at learning powerful representations to benefit various artificial intelligence applications. Meanwhile, contrastive learning has been widely leveraged in graph learning as an effective mechanism to enhance the discriminative capacity of the learned representations. However, the complex structures of KG make it hard to construct appropriate contrastive pairs. Only a few attempts have integrated contrastive learning strategies with KGE. But, most of them rely on language models ( e.g., Bert) for contrastive pair construction instead of fully mining information underlying the graph structure, hindering expressive ability. Surprisingly, we find that the entities within a relational symmetrical structure are usually similar and correlated. To this end, we propose a knowledge graph contrastive learning framework based on relation-symmetrical structure, KGE-SymCL, which mines symmetrical structure information in KGs to enhance the discriminative ability o
    
[^16]: 开放世界特征外推问题的归纳图学习方法

    Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach. (arXiv:2110.04514v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.04514](http://arxiv.org/abs/2110.04514)

    本文提出了一种采用图表示和学习的方法，解决了处理开放世界特征外推问题的挑战，同时使用两种训练策略来实现对新特征的外推，并缓解特征层面的过拟合问题。

    

    本文解决了开放世界特征外推问题，其中输入数据的特征空间经过扩展，在部分观察到的特征上训练的模型需要处理测试数据中的新特征而无需重新训练。我们提出了一种新的采用图表示和学习的学习范式。我们的框架包含两个模块：1）骨干网络作为较低的模型，将特征作为输入并输出预测的标签；2）图神经网络作为较高的模型，通过在从观察到的数据构建的特征-数据图上进行消息传递，学习外推新特征的嵌入。基于我们的框架，我们设计了两种训练策略，一种是自监督方法，另一种是归纳学习方法，用于赋予模型外推能力并缓解特征层面的过拟合。我们还提供了理论分析。

    We target open-world feature extrapolation problem where the feature space of input data goes through expansion and a model trained on partially observed features needs to handle new features in test data without further retraining. The problem is of much significance for dealing with features incrementally collected from different fields. To this end, we propose a new learning paradigm with graph representation and learning. Our framework contains two modules: 1) a backbone network (e.g., feedforward neural nets) as a lower model takes features as input and outputs predicted labels; 2) a graph neural network as an upper model learns to extrapolate embeddings for new features via message passing over a feature-data graph built from observed data. Based on our framework, we design two training strategies, a self-supervised approach and an inductive learning approach, to endow the model with extrapolation ability and alleviate feature-level over-fitting. We also provide theoretical analy
    
[^17]: 一种三元神经模型用于动态实体相关性排名

    A Trio Neural Model for Dynamic Entity Relatedness Ranking. (arXiv:1808.08316v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1808.08316](http://arxiv.org/abs/1808.08316)

    这篇论文提出了一种基于神经网络的方法，通过动态评估实体相关性，利用集体注意作为监督，能学习到丰富而不同的实体表示，能在大规模数据集上比竞争基线获得更好的结果。

    

    测量实体相关性是许多自然语言处理和信息检索应用的基本任务。之前的研究通常在静态设置和非监督方式下研究实体相关性。然而，现实世界中的实体往往涉及许多不同的关系，因此实体关系随时间变得非常动态。在这项工作中，我们提出了一种基于神经网络的方法来动态评估实体相关性，利用集体注意力作为监督。我们的模型能够在联合框架中学习丰富而不同的实体表示。通过对大规模数据集的广泛实验，我们证明了我们的方法比竞争基线获得了更好的结果。

    Measuring entity relatedness is a fundamental task for many natural language processing and information retrieval applications. Prior work often studies entity relatedness in static settings and an unsupervised manner. However, entities in real-world are often involved in many different relationships, consequently entity-relations are very dynamic over time. In this work, we propose a neural networkbased approach for dynamic entity relatedness, leveraging the collective attention as supervision. Our model is capable of learning rich and different entity representations in a joint framework. Through extensive experiments on large-scale datasets, we demonstrate that our method achieves better results than competitive baselines.
    
[^18]: 推荐实体的时间因素的多模型方法

    Multiple Models for Recommending Temporal Aspects of Entities. (arXiv:1803.07890v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1803.07890](http://arxiv.org/abs/1803.07890)

    本研究提出了一种新颖的基于事件中心的集合排名方法，该方法考虑到时间动态性，能够推荐最相关的实体方面，提高搜索体验。

    

    实体方面的推荐是语义搜索中的新兴任务，可以帮助用户发现与实体相关的巧合和突出信息，其中显着性（例如流行度）是以前工作中最重要的因素。但是，实体方面是具有时间动态性的，经常受到随时间发生的事件的影响。在这种情况下，仅基于显着性特征的方面建议可能会给出令人不满意的结果，原因有两个。首先，显着性通常在长时间段内累积，并且不考虑最近情况。其次，与事件实体相关的许多方面强烈依赖于时间。在本文中，我们研究了针对给定实体的时间方面推荐任务，旨在推荐最相关的方面，并考虑时间以提高搜索体验。我们提出了一种新颖的基于事件中心的集合排名方法，该方法从多个时间和类型依赖的模型中学习，并动态权衡显着性和最近情况。

    Entity aspect recommendation is an emerging task in semantic search that helps users discover serendipitous and prominent information with respect to an entity, of which salience (e.g., popularity) is the most important factor in previous work. However, entity aspects are temporally dynamic and often driven by events happening over time. For such cases, aspect suggestion based solely on salience features can give unsatisfactory results, for two reasons. First, salience is often accumulated over a long time period and does not account for recency. Second, many aspects related to an event entity are strongly time-dependent. In this paper, we study the task of temporal aspect recommendation for a given entity, which aims at recommending the most relevant aspects and takes into account time in order to improve search experience. We propose a novel event-centric ensemble ranking method that learns from multiple time and type-dependent models and dynamically trades off salience and recency c
    

