# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning.](http://arxiv.org/abs/2307.13632) | 通过成本敏感学习减轻推荐中的主流偏见，通过使用推荐效用作为衡量主流性的代理，并提出了简单的用户加权方法来纳入训练过程中，这样能够更好地识别非主流用户并提供更好的服务效果。 |
| [^2] | [Cloud Render Farm Services Discovery Using NLP And Ontology Based Knowledge Graph.](http://arxiv.org/abs/2307.13604) | 利用自然语言处理和基于本体的知识图谱，这项研究提出了一种名为RenderSelect的服务发现引擎，用于发现成本效益高且符合功能要求的云渲染农场服务。 |
| [^3] | [Gaussian Graph with Prototypical Contrastive Learning in E-Commerce Bundle Recommendation.](http://arxiv.org/abs/2307.13468) | 本文提出了一种新颖的具有高斯图和典型对比学习（GPCL）框架，用于解决电子商务套餐推荐中的不确定性和采样偏差问题。 |
| [^4] | [Comprehensive Review on Semantic Information Retrieval and Ontology Engineering.](http://arxiv.org/abs/2307.13427) | 本论文综述了语义信息检索和本体工程的现状和未来研究方向。通过本体推理，可以克服传统系统的局限性，并提供一个形式化、灵活和可扩展的知识表示、推理和推断框架。 |
| [^5] | [An End-to-End Workflow using Topic Segmentation and Text Summarisation Methods for Improved Podcast Comprehension.](http://arxiv.org/abs/2307.13394) | 本研究使用主题分割和文本摘要方法相结合，探讨了如何通过为播客节目提供逐个主题的细分和每个主题的简短摘要来提高播客节目的理解能力。研究采样了Spotify的英语播客数据集中的10个节目，并使用TextSplit算法进行了分割。调查结果表明，TextSplit算法在评估指标上达到了最低平均值。 |
| [^6] | [Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements.](http://arxiv.org/abs/2307.13377) | 本论文评估了在科学论文致谢文本中自动提取和分类被致谢实体的不同嵌入模型的性能。在使用Flair NLP框架进行命名实体识别任务的训练中，Flair Embeddings模型在中等规模语料库上达到了最佳准确度（0.79）。同时，扩大训练语料库的规模可以显著提高所有训练算法的准确性。 |
| [^7] | [An Intent Taxonomy of Legal Case Retrieval.](http://arxiv.org/abs/2307.13298) | 本论文提出了一种新颖的法律案件检索的意图分类法，在明确了法律检索用户的潜在搜索意图更加复杂的情况下，通过五种意图类型进行分类。该分类法经过广泛的评估，揭示了用户行为和满意度方面的显著差异。 |
| [^8] | [Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study.](http://arxiv.org/abs/2307.13165) | 本研究通过对多个数据集进行评估发现，顺序推荐系统中删除序列末尾的项目显著降低了性能，而删除序列开头或中间的项目则没有明显影响。这一发现强调了考虑训练数据中扰动项目位置的重要性，并能指导更具鲁棒性的顺序推荐系统的设计。 |
| [^9] | [Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning.](http://arxiv.org/abs/2307.12996) | 该论文研究了如何使用多模态对比学习方法从自然语言中提取分子属性信息，通过改进文本检索和引入分子图扩增策略等方法提高了属性预测性能。实验结果显示相对于仅在图模态上预训练的模型，我们取得了+4.26%的AUROC增益和+1.54%的增益。 |
| [^10] | [RRAML: Reinforced Retrieval Augmented Machine Learning.](http://arxiv.org/abs/2307.12798) | RRAML是一种新的机器学习框架，将大型语言模型（LLMs）的推理能力与用户提供的庞大数据库中的支持信息相结合。利用强化学习的进展，该方法成功解决了几个关键挑战。 |
| [^11] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^12] | [Similarity search in the blink of an eye with compressed indices.](http://arxiv.org/abs/2304.04759) | 本文提出一种新的向量压缩方法局部自适应量化(LVQ)，并在基于图的索引的关键优化下实现减少有效带宽同时启用随机访问友好的快速相似性计算，从而在性能和内存占用方面创造了新的最佳表现。 |
| [^13] | [A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion Mining.](http://arxiv.org/abs/2111.02259) | 本研究提出了一种简单、现代和有效的方法，能够同时处理多种语言，构建一个单一主题模型，并基于深度神经网络进行情感分析。通过将该模型应用于有机食品的报纸文章和用户评论，我们发现主题在不同语言中匹配，并获得了高比例的稳定且与领域相关的主题。 |
| [^14] | [Classification of Consumer Belief Statements From Social Media.](http://arxiv.org/abs/2106.15498) | 本研究探讨了使用复杂的专家注解在社交媒体中进行消费者信念陈述分类的准确性，比较了细粒度和抽象类别的标签，并说明复杂专家注解在高度特定的意见挖掘中的潜在优势。 |
| [^15] | [Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior Implicit Recommendation.](http://arxiv.org/abs/2105.11876) | 提出了一种基于准则的非采样学习框架，命名为CHCF，用于多行为隐式推荐的异构协同过滤。该方法通过引入上限和下限阈值来指示选择标准，并指导用户偏好学习。 |

# 详细

[^1]: 通过成本敏感学习减轻推荐中的主流偏见

    Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning. (arXiv:2307.13632v1 [cs.IR])

    [http://arxiv.org/abs/2307.13632](http://arxiv.org/abs/2307.13632)

    通过成本敏感学习减轻推荐中的主流偏见，通过使用推荐效用作为衡量主流性的代理，并提出了简单的用户加权方法来纳入训练过程中，这样能够更好地识别非主流用户并提供更好的服务效果。

    

    主流偏见是指一些用户由于其偏好不常见或者活跃度较低而收到较差的推荐，这在推荐系统中对公平性至关重要。现有方法未显式地对这些非主流用户的重要性建模，或者在建模时与数据和推荐模型不兼容。相反，我们使用推荐效用作为更通用和隐含的衡量主流性的代理，并提出了一种简单的用户加权方法，将其纳入训练过程中，并考虑潜在推荐错误的成本。我们通过大量实验结果表明，通过效用来量化主流性更能准确地识别非主流用户，并且当使用成本敏感方式训练模型时，这些用户的服务效果确实更好。这一成果几乎没有或没有损失。

    Mainstream bias, where some users receive poor recommendations because their preferences are uncommon or simply because they are less active, is an important aspect to consider regarding fairness in recommender systems. Existing methods to mitigate mainstream bias do not explicitly model the importance of these non-mainstream users or, when they do, it is in a way that is not necessarily compatible with the data and recommendation model at hand. In contrast, we use the recommendation utility as a more generic and implicit proxy to quantify mainstreamness, and propose a simple user-weighting approach to incorporate it into the training process while taking the cost of potential recommendation errors into account. We provide extensive experimental results showing that quantifying mainstreamness via utility is better able at identifying non-mainstream users, and that they are indeed better served when training the model in a cost-sensitive way. This is achieved with negligible or no loss 
    
[^2]: 利用自然语言处理和基于本体的知识图谱发现云渲染农场服务

    Cloud Render Farm Services Discovery Using NLP And Ontology Based Knowledge Graph. (arXiv:2307.13604v1 [cs.DC])

    [http://arxiv.org/abs/2307.13604](http://arxiv.org/abs/2307.13604)

    利用自然语言处理和基于本体的知识图谱，这项研究提出了一种名为RenderSelect的服务发现引擎，用于发现成本效益高且符合功能要求的云渲染农场服务。

    

    云渲染农场服务是针对动画领域的特定云服务平台（PaaS）类型的云服务，提供完整的平台来渲染动画文件。然而，识别成本效益且符合功能要求（如动画软件、所需插件等）的渲染农场服务是一项挑战。本研究提出了一种基于本体的服务发现引擎RenderSelect，用于云渲染农场服务。云渲染农场本体语义上定义了云渲染农场服务之间的关系。采用基于知识的推理算法，包括概念相似性推理、等价推理和数值相似性推理，来确定云服务之间的相似性。该服务发现引擎在三种不同的情景下进行了评估，即a）利用本体帮助，b）

    Cloud render farm services are the animation domain specific cloud services Platform-as-a-Service (PaaS) type of cloud services that provides a complete platform to render the animation files. However, identifying the render farm services that is cost effective and also matches the functional requirements that changes for almost every project like the animation software, plug-ins required etc., is a challenge. This research work proposes an ontology-based service discovery engine named RenderSelect for the cloud render farm services. The cloud render farm ontology semantically defines the relationship among the cloud render farm services. The knowledge-based reasoning algorithms namely, the Concept similarity reasoning, Equivalent reasoning and the Numerical similarity reasoning have been applied to determine the similarity among the cloud services. The service discovery engine was evaluated for finding the services under three different scenarios namely a) with help of the ontology, b
    
[^3]: 电子商务套餐推荐中的高斯图与典型对比学习

    Gaussian Graph with Prototypical Contrastive Learning in E-Commerce Bundle Recommendation. (arXiv:2307.13468v1 [cs.IR])

    [http://arxiv.org/abs/2307.13468](http://arxiv.org/abs/2307.13468)

    本文提出了一种新颖的具有高斯图和典型对比学习（GPCL）框架，用于解决电子商务套餐推荐中的不确定性和采样偏差问题。

    

    套餐推荐旨在满足用户在电子商务平台上的偏好。既有的成功解决方案基于对比图学习范式，其中使用图神经网络（GNN）从用户级别和套餐级别的图视图中学习表示，并使用对比学习模块增强不同视图之间的合作关联。然而，由于高度稀疏性或多样性导致的缺乏有区别性信息，不确定性问题在实际套餐推荐场景中具有重要影响，这些解决方案忽视了这一问题。我们进一步指出，它们的逐实例对比学习无法区分语义上相似的负样本（即采样偏差问题），导致性能下降。在本文中，我们提出了一种新颖的具有高斯图和典型对比学习（GPCL）框架来克服这些挑战。

    Bundle recommendation aims to provide a bundle of items to satisfy the user preference on e-commerce platform. Existing successful solutions are based on the contrastive graph learning paradigm where graph neural networks (GNNs) are employed to learn representations from user-level and bundle-level graph views with a contrastive learning module to enhance the cooperative association between different views. Nevertheless, they ignore the uncertainty issue which has a significant impact in real bundle recommendation scenarios due to the lack of discriminative information caused by highly sparsity or diversity. We further suggest that their instancewise contrastive learning fails to distinguish the semantically similar negatives (i.e., sampling bias issue), resulting in performance degradation. In this paper, we propose a novel Gaussian Graph with Prototypical Contrastive Learning (GPCL) framework to overcome these challenges. In particular, GPCL embeds each user/bundle/item as a Gaussian
    
[^4]: 语义信息检索和本体工程的综合评述

    Comprehensive Review on Semantic Information Retrieval and Ontology Engineering. (arXiv:2307.13427v1 [cs.IR])

    [http://arxiv.org/abs/2307.13427](http://arxiv.org/abs/2307.13427)

    本论文综述了语义信息检索和本体工程的现状和未来研究方向。通过本体推理，可以克服传统系统的局限性，并提供一个形式化、灵活和可扩展的知识表示、推理和推断框架。

    

    情景意识是一种重要的认知能力，使个体能够准确地感知、理解和预测环境的当前状态。它涉及意识到相关信息，理解其含义，并利用这种理解做出明智的决策。意识系统通常需要整合新的知识并适应不断变化的环境。本体推理促进了知识的整合和演化，实现了本体的无缝更新和扩展。考虑到上述因素，我们提供了关于语义信息检索和本体工程的快速评述，以了解新兴挑战和未来研究。在评述中，我们发现本体推理通过提供一个形式化、灵活和可扩展的知识表示、推理和推断框架，克服了传统系统的局限性。

    Situation awareness is a crucial cognitive skill that enables individuals to perceive, comprehend, and project the current state of their environment accurately. It involves being conscious of relevant information, understanding its meaning, and using that understanding to make well-informed decisions. Awareness systems often need to integrate new knowledge and adapt to changing environments. Ontology reasoning facilitates knowledge integration and evolution, allowing for seamless updates and expansions of the ontology. With the consideration of above, we are providing a quick review on semantic information retrieval and ontology engineering to understand the emerging challenges and future research. In the review we have found that the ontology reasoning addresses the limitations of traditional systems by providing a formal, flexible, and scalable framework for knowledge representation, reasoning, and inference.
    
[^5]: 使用主题分割和文本摘要方法的端到端工作流程，以提高播客理解能力

    An End-to-End Workflow using Topic Segmentation and Text Summarisation Methods for Improved Podcast Comprehension. (arXiv:2307.13394v1 [cs.IR])

    [http://arxiv.org/abs/2307.13394](http://arxiv.org/abs/2307.13394)

    本研究使用主题分割和文本摘要方法相结合，探讨了如何通过为播客节目提供逐个主题的细分和每个主题的简短摘要来提高播客节目的理解能力。研究采样了Spotify的英语播客数据集中的10个节目，并使用TextSplit算法进行了分割。调查结果表明，TextSplit算法在评估指标上达到了最低平均值。

    

    播客媒体的消费量正在迅速增加。由于播客节目的冗长性质，用户常常会仔细选择要听的节目。虽然节目描述通过提供整个播客的摘要来帮助用户，但它们并没有提供逐个主题的细分。本研究探讨了利用主题分割和文本摘要方法相结合的应用，以研究如何提高播客节目的理解能力。我们从Spotify的英语播客数据集中选择了10个节目，并使用TextTiling和TextSplit进行了分割。此外，我们应用了三种文本摘要模型，分别是T5、BART和Pegasus，为每个片段提供一个非常简短的标题。我们使用我们的标注样本使用了$P_k$和WindowDiff ($WD$)两个度量来评估分割部分。我们还进行了一项调查（$N=25$），以评估生成的摘要的质量。TextSplit算法在两个评估指标的平均值上都达到了最低水平。

    The consumption of podcast media has been increasing rapidly. Due to the lengthy nature of podcast episodes, users often carefully select which ones to listen to. Although episode descriptions aid users by providing a summary of the entire podcast, they do not provide a topic-by-topic breakdown. This study explores the combined application of topic segmentation and text summarisation methods to investigate how podcast episode comprehension can be improved. We have sampled 10 episodes from Spotify's English-Language Podcast Dataset and employed TextTiling and TextSplit to segment them. Moreover, three text summarisation models, namely T5, BART, and Pegasus, were applied to provide a very short title for each segment. The segmentation part was evaluated using our annotated sample with the $P_k$ and WindowDiff ($WD$) metrics. A survey was also rolled out ($N=25$) to assess the quality of the generated summaries. The TextSplit algorithm achieved the lowest mean for both evaluation metrics 
    
[^6]: 使用嵌入模型进行科学致谢中命名实体的自动提取和分类

    Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements. (arXiv:2307.13377v1 [cs.DL])

    [http://arxiv.org/abs/2307.13377](http://arxiv.org/abs/2307.13377)

    本论文评估了在科学论文致谢文本中自动提取和分类被致谢实体的不同嵌入模型的性能。在使用Flair NLP框架进行命名实体识别任务的训练中，Flair Embeddings模型在中等规模语料库上达到了最佳准确度（0.79）。同时，扩大训练语料库的规模可以显著提高所有训练算法的准确性。

    

    科学论文中的致谢部分可能揭示科学社区的某些方面，比如奖励体系、合作模式和隐藏的研究趋势。该论文旨在评估不同嵌入模型在科学论文致谢文本中自动提取和分类被致谢实体的性能。我们使用Flair NLP框架进行命名实体识别（NER）任务的训练和实现。训练使用了三个默认的Flair NER模型，使用四个不同大小的语料库和不同版本的Flair NLP框架进行。在最新的FLAIR版本上，使用中等规模的语料库训练的Flair嵌入模型显示出了最好的准确性，为0.79。将训练语料库的规模从非常小的扩展到中等规模大大提高了所有训练算法的准确性，但进一步扩大训练语料库并没有带来进一步的改善。此外，嵌入模型的性能在其他Embeddings选项上没有显著差异。

    Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP framework. The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework. The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79. Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement. Moreover, the performance of the
    
[^7]: 法律案件检索的意图分类法

    An Intent Taxonomy of Legal Case Retrieval. (arXiv:2307.13298v1 [cs.IR])

    [http://arxiv.org/abs/2307.13298](http://arxiv.org/abs/2307.13298)

    本论文提出了一种新颖的法律案件检索的意图分类法，在明确了法律检索用户的潜在搜索意图更加复杂的情况下，通过五种意图类型进行分类。该分类法经过广泛的评估，揭示了用户行为和满意度方面的显著差异。

    

    法律案件检索是一项特殊的信息检索任务，关注的是法律案件文件。根据检索到的案件文件的下游任务和用户的信息需求，法律案件检索中的信息需求与网络搜索和传统的自适应检索任务可能会有显著的区别。虽然有几项研究根据文本相似性来检索法律案件，但作为本文所示，法律检索用户的潜在搜索意图更加复杂，但大部分尚未探索。为此，我们提出了一种新颖的法律案件检索的意图分类法。它由五种意图类型组成，根据三个标准进行分类，即搜索特定案例，特征描述，处罚，程序和利益。该分类法通过透明的构建和广泛的评估，包括访谈、编辑用户研究和查询日志分析。通过实验室用户研究，我们揭示了用户行为和满意度方面的显著差异。

    Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and sati
    
[^8]: 研究顺序推荐系统对训练数据扰动的鲁棒性：一项经验研究

    Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study. (arXiv:2307.13165v1 [cs.IR])

    [http://arxiv.org/abs/2307.13165](http://arxiv.org/abs/2307.13165)

    本研究通过对多个数据集进行评估发现，顺序推荐系统中删除序列末尾的项目显著降低了性能，而删除序列开头或中间的项目则没有明显影响。这一发现强调了考虑训练数据中扰动项目位置的重要性，并能指导更具鲁棒性的顺序推荐系统的设计。

    

    顺序推荐系统被广泛用于建模用户随时间变化的行为，然而其在面对训练数据扰动时的鲁棒性是一个关键问题。本文进行了一项经验研究，探究了在时间顺序序列中不同位置上删除项目的效果。我们评估了两种不同的顺序推荐系统模型在多个数据集上的表现，使用归一化折现累积增益（NDCG）指标和排名敏感度列表（Rank Sensitivity List）指标来衡量其性能。我们的结果显示，删除序列末尾的项目显著影响性能，NDCG下降高达60％，而删除序列开头或中间的项目没有显著影响。这些发现凸显了考虑训练数据中扰动项目位置的重要性，并可指导更具鲁棒性的顺序推荐系统的设计。

    Sequential Recommender Systems (SRSs) have been widely used to model user behavior over time, but their robustness in the face of perturbations to training data is a critical issue. In this paper, we conduct an empirical study to investigate the effects of removing items at different positions within a temporally ordered sequence. We evaluate two different SRS models on multiple datasets, measuring their performance using Normalized Discounted Cumulative Gain (NDCG) and Rank Sensitivity List metrics. Our results demonstrate that removing items at the end of the sequence significantly impacts performance, with NDCG decreasing up to 60\%, while removing items from the beginning or middle has no significant effect. These findings highlight the importance of considering the position of the perturbed items in the training data and shall inform the design of more robust SRSs.
    
[^9]: 使用多模态对比学习从自然语言中提取分子属性

    Extracting Molecular Properties from Natural Language with Multimodal Contrastive Learning. (arXiv:2307.12996v1 [cs.LG])

    [http://arxiv.org/abs/2307.12996](http://arxiv.org/abs/2307.12996)

    该论文研究了如何使用多模态对比学习方法从自然语言中提取分子属性信息，通过改进文本检索和引入分子图扩增策略等方法提高了属性预测性能。实验结果显示相对于仅在图模态上预训练的模型，我们取得了+4.26%的AUROC增益和+1.54%的增益。

    

    在计算生物化学中，深度学习传统上专注于分子图神经表征；然而，最近语言模型的进展突显了文本中所编码的科学知识量。为了弥合这两种模态，我们研究了如何将分子属性信息从自然语言转化为图表征。我们研究了在使用对比学习将神经图表征与其特征的文本描述表征对齐后，属性预测性能的提升。我们实现了神经相关性评分策略以改进文本检索，引入了一种受有机反应启发的新颖合法分子图扩增策略，并在下游的MoleculeNet属性分类任务上展示了性能的改善。与仅在图模态上预训练的模型相比，我们取得了+4.26%的AUROC增益，并与最近提出的分子图/文本对比模型相比，取得了+1.54%的增益。

    Deep learning in computational biochemistry has traditionally focused on molecular graphs neural representations; however, recent advances in language models highlight how much scientific knowledge is encoded in text. To bridge these two modalities, we investigate how molecular property information can be transferred from natural language to graph representations. We study property prediction performance gains after using contrastive learning to align neural graph representations with representations of textual descriptions of their characteristics. We implement neural relevance scoring strategies to improve text retrieval, introduce a novel chemically-valid molecular graph augmentation strategy inspired by organic reactions, and demonstrate improved performance on downstream MoleculeNet property classification tasks. We achieve a +4.26% AUROC gain versus models pre-trained on the graph modality alone, and a +1.54% gain compared to recently proposed molecular graph/text contrastively t
    
[^10]: RRAML: 强化检索增强的机器学习

    RRAML: Reinforced Retrieval Augmented Machine Learning. (arXiv:2307.12798v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12798](http://arxiv.org/abs/2307.12798)

    RRAML是一种新的机器学习框架，将大型语言模型（LLMs）的推理能力与用户提供的庞大数据库中的支持信息相结合。利用强化学习的进展，该方法成功解决了几个关键挑战。

    

    大型语言模型（LLMs）的出现彻底改变了机器学习和相关领域，在理解、生成和操作人类语言方面展示了显著的能力。然而，通过基于API的文本提示提交来使用它们会存在一定的限制，包括上下文约束和外部资源的可用性。为了解决这些挑战，我们提出了一种新的框架，称为强化检索增强的机器学习（RRAML）。RRAML将LLMs的推理能力与由专用检索器从用户提供的庞大数据库中检索到的支持信息相结合。通过利用强化学习的最新进展，我们的方法有效地解决了几个关键挑战。首先，它绕过了访问LLM梯度的需求。其次，我们的方法减轻了针对特定任务重新训练LLMs的负担，因为由于对模型和合作的访问受限，这往往是不可行或不可能的。

    The emergence of large language models (LLMs) has revolutionized machine learning and related fields, showcasing remarkable abilities in comprehending, generating, and manipulating human language. However, their conventional usage through API-based text prompt submissions imposes certain limitations in terms of context constraints and external source availability. To address these challenges, we propose a novel framework called Reinforced Retrieval Augmented Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs with supporting information retrieved by a purpose-built retriever from a vast user-provided database. By leveraging recent advancements in reinforcement learning, our method effectively addresses several critical challenges. Firstly, it circumvents the need for accessing LLM gradients. Secondly, our method alleviates the burden of retraining LLMs for specific tasks, as it is often impractical or impossible due to restricted access to the model and the co
    
[^11]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^12]: 压缩索引实现瞬间相似性搜索

    Similarity search in the blink of an eye with compressed indices. (arXiv:2304.04759v1 [cs.LG])

    [http://arxiv.org/abs/2304.04759](http://arxiv.org/abs/2304.04759)

    本文提出一种新的向量压缩方法局部自适应量化(LVQ)，并在基于图的索引的关键优化下实现减少有效带宽同时启用随机访问友好的快速相似性计算，从而在性能和内存占用方面创造了新的最佳表现。

    

    如今，数据以向量表示。在海量数据中寻找与给定查询相似的向量是一项广泛应用的问题。本文提出了创建更快、更小的索引以运行这些搜索的新技术。为此，我们介绍了一种新的向量压缩方法，局部自适应量化(LVQ)，它同时减少内存占用和改善搜索性能，对搜索准确性的影响最小。LVQ被设计为与基于图的索引一起工作以实现减少有效带宽同时启用随机访问友好的快速相似性计算。我们的实验结果表明，在现代数据中心系统中针对基于图的索引进行关键优化后，LVQ的性能和内存占用方面创造了新的最佳表现。在处理数十亿个向量时，LVQ超过第二佳方案：

    Nowadays, data is represented by vectors. Retrieving those vectors, among millions and billions, that are similar to a given query is a ubiquitous problem of relevance for a wide range of applications. In this work, we present new techniques for creating faster and smaller indices to run these searches. To this end, we introduce a novel vector compression method, Locally-adaptive Vector Quantization (LVQ), that simultaneously reduces memory footprint and improves search performance, with minimal impact on search accuracy. LVQ is designed to work optimally in conjunction with graph-based indices, reducing their effective bandwidth while enabling random-access-friendly fast similarity computations. Our experimental results show that LVQ, combined with key optimizations for graph-based indices in modern datacenter systems, establishes the new state of the art in terms of performance and memory footprint. For billions of vectors, LVQ outcompetes the second-best alternatives: (1) in the low
    
[^13]: 一个简单的跨语言观点挖掘的案例研究和质性分析

    A Case Study and Qualitative Analysis of Simple Cross-Lingual Opinion Mining. (arXiv:2111.02259v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2111.02259](http://arxiv.org/abs/2111.02259)

    本研究提出了一种简单、现代和有效的方法，能够同时处理多种语言，构建一个单一主题模型，并基于深度神经网络进行情感分析。通过将该模型应用于有机食品的报纸文章和用户评论，我们发现主题在不同语言中匹配，并获得了高比例的稳定且与领域相关的主题。

    

    社交媒体上的用户生成内容涉及多种语言，这在技术上使得跨不同文化和地区比较讨论主题变得具有挑战性。对于全球化世界中的领域，如市场研究，人们可能对产品有不同的需求。我们提出了一种简单、现代和有效的方法来构建能够同时覆盖多种语言的单一主题模型，并基于一个预训练的最先进的深度神经网络进行自然语言理解的情感分析。为了证明其可行性，我们将该模型应用于特定领域的报纸文章和用户评论，即有机食品产品和相关消费行为。主题在不同语言中匹配。此外，我们获得了高比例的稳定且相关领域的主题，主题与其相应文本内容之间存在有意义的关系，以及一些新颖的

    User-generated content from social media is produced in many languages, making it technically challenging to compare the discussed themes from one domain across different cultures and regions. It is relevant for domains in a globalized world, such as market research, where people from two nations and markets might have different requirements for a product. We propose a simple, modern, and effective method for building a single topic model with sentiment analysis capable of covering multiple languages simultanteously, based on a pre-trained state-of-the-art deep neural network for natural language understanding. To demonstrate its feasibility, we apply the model to newspaper articles and user comments of a specific domain, i.e., organic food products and related consumption behavior. The themes match across languages. Additionally, we obtain an high proportion of stable and domain-relevant topics, a meaningful relation between topics and their respective textual contents, and an interpr
    
[^14]: 社交媒体中消费者信念陈述的分类

    Classification of Consumer Belief Statements From Social Media. (arXiv:2106.15498v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.15498](http://arxiv.org/abs/2106.15498)

    本研究探讨了使用复杂的专家注解在社交媒体中进行消费者信念陈述分类的准确性，比较了细粒度和抽象类别的标签，并说明复杂专家注解在高度特定的意见挖掘中的潜在优势。

    

    社交媒体提供了大量信息，可以进行市场调研，以满足客户的需求。研究人员通常通过收集和分类用户生成的内容，构建复杂细粒度的类别结构来进行市场调研。然而，在许多情况下，数据量较少且注解复杂。如何成功利用这些数据进行分类仍不完全清楚。本研究考察了当专家注解被应用于a) 许多细粒度类别和b) 少数抽象类别时的分类准确性。对于场景b)，我们比较了领域专家给出的抽象类别标签（基准）和自动分层聚类给出的抽象类别标签。我们将其与另一基准进行比较，该基准使用完全无监督的聚类方法给出整个类别结构。通过这样做，该研究可以作为复杂专家注解如何在高度特定的意见挖掘中发挥潜在优势，并以最优化的方式利用的示例。

    Social media offer plenty of information to perform market research in order to meet the requirements of customers. One way how this research is conducted is that a domain expert gathers and categorizes user-generated content into a complex and fine-grained class structure. In many of such cases, little data meets complex annotations. It is not yet fully understood how this can be leveraged successfully for classification. We examine the classification accuracy of expert labels when used with a) many fine-grained classes and b) few abstract classes. For scenario b) we compare abstract class labels given by the domain expert as baseline and by automatic hierarchical clustering. We compare this to another baseline where the entire class structure is given by a completely unsupervised clustering approach. By doing so, this work can serve as an example of how complex expert annotations are potentially beneficial and can be utilized in the most optimal way for opinion mining in highly speci
    
[^15]: 基于准则的多行为隐式推荐的异构协同过滤

    Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior Implicit Recommendation. (arXiv:2105.11876v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2105.11876](http://arxiv.org/abs/2105.11876)

    提出了一种基于准则的非采样学习框架，命名为CHCF，用于多行为隐式推荐的异构协同过滤。该方法通过引入上限和下限阈值来指示选择标准，并指导用户偏好学习。

    

    近年来，多媒体信息系统中的互动行为呈爆炸式增长，利用来自各种辅助行为（如提示和收藏）的数据，多行为推荐系统受到越来越多的关注。在各种多行为推荐方法中，非采样方法表现优于负采样方法。然而，现有的基于二进制回归的非采样方法通常忽略了两点观察：（1）用户对不同项目具有不同的偏好强度，因此不能简单通过二进制隐式数据来衡量；（2）多个行为之间的依赖关系对不同的用户和项目是不同的。为了解决上述问题，我们提出了一种新的非采样学习框架，命名为基于准则的异构协同过滤（CHCF）。CHCF引入了上限和下限阈值来指示选择标准，并指导用户偏好学习。

    Recent years have witnessed the explosive growth of interaction behaviors in multimedia information systems, where multi-behavior recommender systems have received increasing attention by leveraging data from various auxiliary behaviors such as tip and collect. Among various multi-behavior recommendation methods, non-sampling methods have shown superiority over negative sampling methods. However, two observations are usually ignored in existing state-of-the-art non-sampling methods based on binary regression: (1) users have different preference strengths for different items, so they cannot be measured simply by binary implicit data; (2) the dependency across multiple behaviors varies for different users and items. To tackle the above issue, we propose a novel non-sampling learning framework named Criterion-guided Heterogeneous Collaborative Filtering (CHCF). CHCF introduces both upper and lower thresholds to indicate selection criteria, which will guide user preference learning. Beside
    

