# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Roadmap to Pluralistic Alignment](https://arxiv.org/abs/2402.05070) | 这篇论文提出了一条通向多元对齐的路线图，以解决设计AI系统能够服务于人们具有不同价值观和观点的需求。论文介绍了对齐定义和实现多元主义的三种方式，并提出了三种多元基准类别来评估和测试多元对齐的效果。 |
| [^2] | [Detecting Generated Native Ads in Conversational Search](https://arxiv.org/abs/2402.04889) | 本论文研究了LLM是否可以用作对抗生成式原生广告的对策，并通过构建广告倾向查询数据集和带自动整合广告的生成答案数据集进行实验证明。 |
| [^3] | [Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2402.04867) | 本论文介绍了一种基于多智能体强化学习和人类反馈的多模态查询建议系统。通过利用语言模型和强化学习算法，该系统能够根据用户的查询图像生成个性化的查询建议，从而提高搜索结果的意图性和多样性。 |
| [^4] | [Leveraging LLMs for Unsupervised Dense Retriever Ranking](https://arxiv.org/abs/2402.04853) | 本文介绍了一种利用大型语言模型（LLMs）进行无监督选择最佳预训练的密集检索器的新技术。选择合适的检索器对于应用于新的目标语料库并且存在领域转移的情况非常重要。 |
| [^5] | [Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search](https://arxiv.org/abs/2402.04713) | 本论文对图形基准最近邻搜索的自适应入口点选择进行了理论和实证分析，并提出了新的概念$b\textit{-单调路径}$和$B\textit{-MSNET}$。理论证明了自适应入口点选择在更一般的条件下比固定中心入口点具有更好的性能上界。实验验证了该方法在各种数据集上的准确性、速度和内存使用方面的有效性，尤其是在分布之外的数据和难例的挑战场景中。这项全面研究提供了优化图形基准最近邻搜索入口点的深入洞察，适用于实际的高维数据应用。 |
| [^6] | [SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph](https://arxiv.org/abs/2402.04627) | 在本研究中，我们针对生命科学知识图谱上的问题回答对OpenLlama LLM进行了微调，并提出了一种数据增强方法，以扩展现有查询集合，从而能够进行微调，即使训练数据稀缺。我们还研究了查询中语义线索的作用。 |
| [^7] | [NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering](https://arxiv.org/abs/2402.04548) | NORMY是一种用于开放式检索对话式问答的非均匀历史建模流程，通过为每个模块生成最佳对话历史，提高了系统性能。 |
| [^8] | [RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation](https://arxiv.org/abs/2402.04527) | 这篇论文提出了一种基于LLM的推荐系统的高效ID表示对齐框架RA-Rec，通过将预训练的ID嵌入到LLMs中，并设计创新的对齐模块和高效调整方法，实现了在推荐系统中的显著性能优化。 |
| [^9] | [Reliability quality measures for recommender systems](https://arxiv.org/abs/2402.04457) | 本文提出了一种基于可靠性的推荐系统质量度量方法，改进了准确性结果，填补了可靠性/置信度质量度量的研究空白。 |
| [^10] | [The Potential of AutoML for Recommender Systems](https://arxiv.org/abs/2402.04453) | 这项研究探讨了在推荐系统领域中，自动机器学习（AutoML）的巨大潜力以及目前相对少有的关注和开发。 |
| [^11] | [Building Retrieval Systems for the ClueWeb22-B Corpus](https://arxiv.org/abs/2402.04357) | 这个项目的目标是为ClueWeb22-B数据集的英文部分构建检索基线，可以供研究界比较其系统并训练/评估新的检索和排序算法。构建的系统包括稀疏和密集的第一阶段检索以及神经重新排序器。 |
| [^12] | [Future Impact Decomposition in Request-level Recommendations](https://arxiv.org/abs/2401.16108) | 在请求级别的推荐系统中，我们通过比较标准方法和基于物品级别的演员-评论家框架在模拟和在线实验中的性能，证明了基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。 |
| [^13] | [Recent Advances in Text Analysis](https://arxiv.org/abs/2401.00775) | 文本分析是一个有趣的研究领域，在数据科学中有广泛的应用。本文回顾了文本分析的常见方法，介绍了一种新的统计方法Topic-SCORE，并在统计出版物数据集MADStat上进行了应用。通过对MADStat的分析，我们发现了11个代表统计领域的主题，并提出了一种新的统计模型来评估主题的引用影响。同时，我们还构建了一个跨主题的引用图来分析研究结果在不同领域之间的传播。 |
| [^14] | [Labeled Interactive Topic Models](https://arxiv.org/abs/2311.09438) | 这篇论文介绍了一种用户友好的交互式神经主题模型，通过用户分配单词标签来更新主题模型，使得主题更加相关和准确。这种方法包括可训练和后训练集成两种不同类型的神经主题模型。 |
| [^15] | [Recency Ranking by Diversification of Result Set.](http://arxiv.org/abs/2401.14595) | 本文提出了一种通过多样化结果集来增加普通文档排名新鲜度的网络搜索检索方法，通过实验验证了该方法可以显著提高用户的满意度。 |
| [^16] | [Towards Populating Generalizable Engineering Design Knowledge.](http://arxiv.org/abs/2307.06985) | 这项研究提出了一种从专利文件中提取工程设计知识的方法，通过构建知识图来填充通用设计知识，并与现有方法进行了比较。 |

# 详细

[^1]: 通往多元对齐的路线图

    A Roadmap to Pluralistic Alignment

    [https://arxiv.org/abs/2402.05070](https://arxiv.org/abs/2402.05070)

    这篇论文提出了一条通向多元对齐的路线图，以解决设计AI系统能够服务于人们具有不同价值观和观点的需求。论文介绍了对齐定义和实现多元主义的三种方式，并提出了三种多元基准类别来评估和测试多元对齐的效果。

    

    随着人工智能系统的权力和普及程度的增加，设计能够为不同价值观和观点的人服务的人工智能系统变得愈发重要。然而，将模型对齐以服务多元人类价值观仍然是一个待解决的研究问题。在本文中，我们提出了一条通向多元对齐的路线图，具体使用语言模型作为测试平台。我们确定和形式化了三种可能的方式来定义和实现人工智能系统中的多元主义：1）Overton多元模型，展示合理反应的光谱；2）可操控的多元模型，可以调整以反映特定的观点；3）分布多元模型，在分布中很好地校准给定人群的模型。我们还提出和形式化了三种可能的多元基准类别：1）多目标基准；2）权衡可操控基准，鼓励模型对任意权衡进行调整；3）陪审团多元基准，明确地模拟了不同陪审团的意见。

    With increased power and prevalence of AI systems, it is ever more critical that AI systems are designed to serve all, i.e., people with diverse values and perspectives. However, aligning models to serve pluralistic human values remains an open research question. In this piece, we propose a roadmap to pluralistic alignment, specifically using language models as a test bed. We identify and formalize three possible ways to define and operationalize pluralism in AI systems: 1) Overton pluralistic models that present a spectrum of reasonable responses; 2) Steerably pluralistic models that can steer to reflect certain perspectives; and 3) Distributionally pluralistic models that are well-calibrated to a given population in distribution. We also propose and formalize three possible classes of pluralistic benchmarks: 1) Multi-objective benchmarks, 2) Trade-off steerable benchmarks, which incentivize models to steer to arbitrary trade-offs, and 3) Jury-pluralistic benchmarks which explicitly m
    
[^2]: 发现对话式搜索中的生成式原生广告

    Detecting Generated Native Ads in Conversational Search

    [https://arxiv.org/abs/2402.04889](https://arxiv.org/abs/2402.04889)

    本论文研究了LLM是否可以用作对抗生成式原生广告的对策，并通过构建广告倾向查询数据集和带自动整合广告的生成答案数据集进行实验证明。

    

    对话式搜索引擎如YouChat和Microsoft Copilot使用大型语言模型（LLM）为查询生成答案。将此技术用于生成并整合广告，而不是将广告与有机搜索结果分开放置，只是一小步。这种类型的广告类似于原生广告和产品放置，两者都是非常有效的微妙和操纵性广告形式。在考虑到与LLM相关的高计算成本时，信息搜索者将很可能在不久的将来面临这种LLM技术的使用，因此供应商需要开发可持续的商业模式。本文研究了LLM是否也可以用作对抗生成式原生广告的对策，即阻止它们。为此，我们编制了一个大型的广告倾向查询数据集和带自动整合广告的生成答案数据集进行实验。

    Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate answers to queries. It is only a small step to also use this technology to generate and integrate advertising within these answers - instead of placing ads separately from the organic search results. This type of advertising is reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. It is likely that information seekers will be confronted with such use of LLM technology in the near future, especially when considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models. This paper investigates whether LLMs can also be used as a countermeasure against generated native ads, i.e., to block them. For this purpose we compile a large dataset of ad-prone queries and of generated answers with automatically integrated ads to experiment with fin
    
[^3]: 多模态查询建议中的多智能体强化学习与人类反馈

    Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback

    [https://arxiv.org/abs/2402.04867](https://arxiv.org/abs/2402.04867)

    本论文介绍了一种基于多智能体强化学习和人类反馈的多模态查询建议系统。通过利用语言模型和强化学习算法，该系统能够根据用户的查询图像生成个性化的查询建议，从而提高搜索结果的意图性和多样性。

    

    在信息检索的快速发展环境中，搜索引擎致力于为用户提供更个性化和相关性更强的结果。查询建议系统在实现这一目标方面起着重要作用，通过协助用户制定有效的查询。然而，现有的查询建议系统主要依赖于文本输入，可能限制用户对图像查询的体验。本文提出了一种新颖的多模态查询建议（MMQS）任务，旨在基于用户查询图像生成查询建议，以提高搜索结果的意图性和多样性。我们提出了RL4Sugg框架，利用大型语言模型（LLM）和多智能体强化学习与人类反馈的力量来优化生成过程。通过全面的实验，我们验证了RL4Sugg的有效性，与最佳现有方法相比，获得了18%的改进。此外，MMQS已经在实际环境中得到了应用。

    In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18% improvement compared to the best existing approach. Moreover, the MMQS has been transferred into real-world s
    
[^4]: 利用LLMs进行无监督的密集检索排名

    Leveraging LLMs for Unsupervised Dense Retriever Ranking

    [https://arxiv.org/abs/2402.04853](https://arxiv.org/abs/2402.04853)

    本文介绍了一种利用大型语言模型（LLMs）进行无监督选择最佳预训练的密集检索器的新技术。选择合适的检索器对于应用于新的目标语料库并且存在领域转移的情况非常重要。

    

    本文介绍了一种利用大型语言模型（LLMs）确定特定测试（目标）语料库最合适的密集检索器的新颖无监督技术。选择合适的密集检索器对于许多采用这些在公开数据集上训练的检索器进行编码或在新的私有目标语料库中进行搜索的信息检索应用程序至关重要。当密集检索器应用于与原始训练集在领域或任务上有差异的目标语料库时，其有效性可能会大大降低。在目标语料库没有标注的情况下，例如在零样本场景中，无法直接评估模型在目标语料库上的效果。因此，无监督选择最佳预训练的密集检索器，特别是在领域迁移条件下，成为一个关键挑战。现有的密集检索器排序方法在解决这些领域迁移问题方面存在不足。

    This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain 
    
[^5]: 图形基准最近邻搜索的自适应入口点选择的理论与实证分析

    Theoretical and Empirical Analysis of Adaptive Entry Point Selection for Graph-based Approximate Nearest Neighbor Search

    [https://arxiv.org/abs/2402.04713](https://arxiv.org/abs/2402.04713)

    本论文对图形基准最近邻搜索的自适应入口点选择进行了理论和实证分析，并提出了新的概念$b\textit{-单调路径}$和$B\textit{-MSNET}$。理论证明了自适应入口点选择在更一般的条件下比固定中心入口点具有更好的性能上界。实验验证了该方法在各种数据集上的准确性、速度和内存使用方面的有效性，尤其是在分布之外的数据和难例的挑战场景中。这项全面研究提供了优化图形基准最近邻搜索入口点的深入洞察，适用于实际的高维数据应用。

    

    我们对图形基准最近邻搜索的自适应入口点选择进行了理论和实证分析。我们引入了新的概念：$b\textit{-单调路径}$和$B\textit{-MSNET}$，比现有的概念如MSNET更好地捕捉了实际算法中的图形特征。我们证明了在比以前的工作更一般的条件下，自适应入口点选择提供了比固定中心入口点更好的性能上界。在实证方面，我们验证了该方法在准确性、速度和内存使用方面在各种数据集上的有效性，尤其是在分布之外的数据和难例的挑战性场景中。我们的综合研究深入洞察了用于实际高维数据应用中的图形基准最近邻搜索的入口点优化。

    We present a theoretical and empirical analysis of the adaptive entry point selection for graph-based approximate nearest neighbor search (ANNS). We introduce novel concepts: $b\textit{-monotonic path}$ and $B\textit{-MSNET}$, which better capture an actual graph in practical algorithms than existing concepts like MSNET. We prove that adaptive entry point selection offers better performance upper bound than the fixed central entry point under more general conditions than previous work. Empirically, we validate the method's effectiveness in accuracy, speed, and memory usage across various datasets, especially in challenging scenarios with out-of-distribution data and hard instances. Our comprehensive study provides deeper insights into optimizing entry points for graph-based ANNS for real-world high-dimensional data applications.
    
[^6]: SPARQL生成：对OpenLLaMA用于生命科学知识图谱问答的微调进行分析

    SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph

    [https://arxiv.org/abs/2402.04627](https://arxiv.org/abs/2402.04627)

    在本研究中，我们针对生命科学知识图谱上的问题回答对OpenLlama LLM进行了微调，并提出了一种数据增强方法，以扩展现有查询集合，从而能够进行微调，即使训练数据稀缺。我们还研究了查询中语义线索的作用。

    

    大型语言模型（LLM）在各种自然语言处理应用中的成功为基于LLM的知识图谱问答系统开辟了新的路径。然而，其实施的主要障碍之一是在将问题转化为相应的SPARQL查询的任务中，尤其是在特定领域的知识图谱中，训练数据的稀缺性。为了克服这一挑战，在本研究中，我们评估了针对生命科学知识图谱上的问题回答对OpenLlama LLM进行微调的几种策略。具体而言，我们提出了一种端到端的数据增强方法，用于扩展已有查询集合，从而获得一组更大的语义丰富的问题-SPARQL查询对的数据集，即使在这些对稀缺的数据集中也能进行微调。在这个背景下，我们还研究了查询中语义“线索”的作用，例如有意义的变量名和...

    The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic "clues" in the queries, such as meaningful variable names and
    
[^7]: NORMY：非均匀历史建模用于开放式检索对话式问答

    NORMY: Non-Uniform History Modeling for Open Retrieval Conversational Question Answering

    [https://arxiv.org/abs/2402.04548](https://arxiv.org/abs/2402.04548)

    NORMY是一种用于开放式检索对话式问答的非均匀历史建模流程，通过为每个模块生成最佳对话历史，提高了系统性能。

    

    开放式检索对话式问答（OrConvQA）在给定对话和文档集合的情况下回答问题。典型的OrConvQA流程包括三个模块：一个检索器用于从集合中检索相关文档，一个重新排序器根据问题和上下文对它们重新排序，并且一个阅读器用于提取答案范围。对话的转向可以为回答最终问题提供有价值的上下文。目前最先进的OrConvQA系统在流程的三个模块中使用相同的历史建模。我们假设这是次优的。具体而言，我们认为第一个模块中需要更广泛的上下文以防止错过相关文档，而最后一个模块中需要更狭窄的上下文来确定精确的答案范围。我们提出NORMY，第一个无监督的非均匀历史建模流程，为每个模块生成最佳对话历史。我们进一步提出了一种新颖的NORMY检索器，它使用k

    Open Retrieval Conversational Question Answering (OrConvQA) answers a question given a conversation as context and a document collection. A typical OrConvQA pipeline consists of three modules: a Retriever to retrieve relevant documents from the collection, a Reranker to rerank them given the question and the context, and a Reader to extract an answer span. The conversational turns can provide valuable context to answer the final query. State-of-the-art OrConvQA systems use the same history modeling for all three modules of the pipeline. We hypothesize this as suboptimal. Specifically, we argue that a broader context is needed in the first modules of the pipeline to not miss relevant documents, while a narrower context is needed in the last modules to identify the exact answer span. We propose NORMY, the first unsupervised non-uniform history modeling pipeline which generates the best conversational history for each module. We further propose a novel Retriever for NORMY, which employs k
    
[^8]: RA-Rec:基于LLM的推荐系统的高效ID表示对齐框架

    RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation

    [https://arxiv.org/abs/2402.04527](https://arxiv.org/abs/2402.04527)

    这篇论文提出了一种基于LLM的推荐系统的高效ID表示对齐框架RA-Rec，通过将预训练的ID嵌入到LLMs中，并设计创新的对齐模块和高效调整方法，实现了在推荐系统中的显著性能优化。

    

    大语言模型(LLM)最近已经成为各种自然语言处理任务的强大工具，为LLM和推荐系统的结合带来了新的潮流，称为LLM-based RS。目前的方法通常分为两种主要范例，即ID直接使用范例和ID翻译范例，指出它们的核心弱点在于缺乏推荐知识和独特性。为了解决这个限制，我们提出了一种新的范例，即ID表示，它以一种互补的方式将预训练的ID嵌入到LLMs中。在这项工作中，我们提出了RA-Rec，一种基于LLM的推荐系统的高效ID表示对齐框架，与多种基于ID的方法和LLM架构兼容。具体而言，我们将ID嵌入视为软提示，并设计了一种创新的对齐模块和一种用于对齐的高效调整方法，以及为对齐定制的数据构建。大量实验证明，RA-Rec在性能上显著优于其他方法。

    Large language models (LLM) have recently emerged as a powerful tool for a variety of natural language processing tasks, bringing a new surge of combining LLM with recommendation systems, termed as LLM-based RS. Current approaches generally fall into two main paradigms, the ID direct usage paradigm and the ID translation paradigm, noting their core weakness stems from lacking recommendation knowledge and uniqueness. To address this limitation, we propose a new paradigm, ID representation, which incorporates pre-trained ID embeddings into LLMs in a complementary manner. In this work, we present RA-Rec, an efficient ID representation alignment framework for LLM-based recommendation, which is compatible with multiple ID-based methods and LLM architectures. Specifically, we treat ID embeddings as soft prompts and design an innovative alignment module and an efficient tuning method with tailored data construction for alignment. Extensive experiments demonstrate RA-Rec substantially outperfo
    
[^9]: 推荐系统的可靠性质量度量

    Reliability quality measures for recommender systems

    [https://arxiv.org/abs/2402.04457](https://arxiv.org/abs/2402.04457)

    本文提出了一种基于可靠性的推荐系统质量度量方法，改进了准确性结果，填补了可靠性/置信度质量度量的研究空白。

    

    用户希望了解推荐的可靠性，如果没有可靠性证据，他们不会接受高预测值。推荐系统应提供与预测相关的可靠性值。对可靠性度量的研究要求存在简单、合理和通用的可靠性质量度量。对推荐系统质量度量的研究主要集中在准确性上。此外，还研究了新颖性、意外性和多样性，但是对可靠性/置信度质量度量的研究缺乏重要内容。本文提出了可靠性质量预测度量（RPI）和可靠性质量推荐度量（RRI）。这两个质量度量是基于一个假设，即越适合的可靠性度量，在应用时将提供更好的准确性结果。当适当的可靠性值与推荐结果相关联时，这些可靠性质量度量显示了准确性的提升。

    Users want to know the reliability of the recommendations; they do not accept high predictions if there is no reliability evidence. Recommender systems should provide reliability values associated with the predictions. Research into reliability measures requires the existence of simple, plausible and universal reliability quality measures. Research into recommender system quality measures has focused on accuracy. Moreover, novelty, serendipity and diversity have been studied; nevertheless there is an important lack of research into reliability/confidence quality measures.   This paper proposes a reliability quality prediction measure (RPI) and a reliability quality recommendation measure (RRI). Both quality measures are based on the hypothesis that the more suitable a reliability measure is, the better accuracy results it will provide when applied. These reliability quality measures show accuracy improvements when appropriated reliability values are associated with their predictions (i
    
[^10]: 自动机器学习在推荐系统中的潜力

    The Potential of AutoML for Recommender Systems

    [https://arxiv.org/abs/2402.04453](https://arxiv.org/abs/2402.04453)

    这项研究探讨了在推荐系统领域中，自动机器学习（AutoML）的巨大潜力以及目前相对少有的关注和开发。

    

    自动化机器学习（AutoML）已经在包括模型压缩、机器翻译和计算机视觉等领域大大推进了机器学习（ML）的应用。推荐系统（RecSys）可以被看作是ML的一个应用。然而，AutoML在RecSys社区中并没有得到太多关注，RecSys也没有在AutoML社区中引起显著的关注。目前只有少数几个相对简单的自动化推荐系统（AutoRecSys）库采用了AutoML技术。然而，这些库都是基于学生项目开发的，并且没有提供AutoML库的功能和完善的开发。我们的目标是确定在一个没有经验的用户想要实现一个推荐系统的场景中，AutoML库的表现如何。我们比较了来自15个库的60个AutoML、AutoRecSys、ML和RecSys算法以及一个均值预测基准模型在14个显式反馈的RecSys数据集上的预测性能。

    Automated Machine Learning (AutoML) has greatly advanced applications of Machine Learning (ML) including model compression, machine translation, and computer vision. Recommender Systems (RecSys) can be seen as an application of ML. Yet, AutoML has found little attention in the RecSys community; nor has RecSys found notable attention in the AutoML community. Only few and relatively simple Automated Recommender Systems (AutoRecSys) libraries exist that adopt AutoML techniques. However, these libraries are based on student projects and do not offer the features and thorough development of AutoML libraries. We set out to determine how AutoML libraries perform in the scenario of an inexperienced user who wants to implement a recommender system. We compared the predictive performance of 60 AutoML, AutoRecSys, ML, and RecSys algorithms from 15 libraries, including a mean predictor baseline, on 14 explicit feedback RecSys datasets. To simulate the perspective of an inexperienced user, the algo
    
[^11]: 为ClueWeb22-B语料库构建检索系统

    Building Retrieval Systems for the ClueWeb22-B Corpus

    [https://arxiv.org/abs/2402.04357](https://arxiv.org/abs/2402.04357)

    这个项目的目标是为ClueWeb22-B数据集的英文部分构建检索基线，可以供研究界比较其系统并训练/评估新的检索和排序算法。构建的系统包括稀疏和密集的第一阶段检索以及神经重新排序器。

    

    ClueWeb22数据集包含近100亿个文档，于2022年发布用于支持学术和行业研究。本项目的目标是为该数据集的英文部分（超头部分类B）构建检索基线。这些基线可以供研究界使用，用于比较其系统，并生成数据以训练/评估新的检索和排序算法。报告涵盖了针对该数据集实施的稀疏和密集的第一阶段检索，以及神经重新排序器。这些系统可在卡内基梅隆大学集群上作为服务提供。

    The ClueWeb22 dataset containing nearly 10 billion documents was released in 2022 to support academic and industry research. The goal of this project was to build retrieval baselines for the English section of the "super head" part (category B) of this dataset. These baselines can then be used by the research community to compare their systems and also to generate data to train/evaluate new retrieval and ranking algorithms. The report covers sparse and dense first stage retrievals as well as neural rerankers that were implemented for this dataset. These systems are available as a service on a Carnegie Mellon University cluster.
    
[^12]: 请求级别推荐中的未来影响分解

    Future Impact Decomposition in Request-level Recommendations

    [https://arxiv.org/abs/2401.16108](https://arxiv.org/abs/2401.16108)

    在请求级别的推荐系统中，我们通过比较标准方法和基于物品级别的演员-评论家框架在模拟和在线实验中的性能，证明了基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。

    

    在推荐系统中，强化学习解决方案在优化用户和系统之间的交互序列以提高长期性能方面显示出有希望的结果。出于实际原因，策略的动作通常被设计为推荐一组物品以更高效地处理用户的频繁和连续的浏览请求。在这种列表式推荐场景中，用户状态在相应的MDP（马尔可夫决策过程）表述中的每个请求上都会更新。然而，这种请求级别的表述与用户的物品级别行为实质上是不一致的。在这项研究中，我们证明了在请求级别MDP下，基于物品级别的优化方法可以更好地利用物品特性并优化策略的性能。我们通过比较标准请求级别方法和提出的基于物品级别的演员-评论家框架在模拟和在线实验中的性能来支持这一观点。

    In recommender systems, reinforcement learning solutions have shown promising results in optimizing the interaction sequence between users and the system over the long-term performance. For practical reasons, the policy's actions are typically designed as recommending a list of items to handle users' frequent and continuous browsing requests more efficiently. In this list-wise recommendation scenario, the user state is updated upon every request in the corresponding MDP formulation. However, this request-level formulation is essentially inconsistent with the user's item-level behavior. In this study, we demonstrate that an item-level optimization approach can better utilize item characteristics and optimize the policy's performance even under the request-level MDP. We support this claim by comparing the performance of standard request-level methods with the proposed item-level actor-critic framework in both simulation and online experiments. Furthermore, we show that a reward-based fut
    
[^13]: 文本分析的最新进展

    Recent Advances in Text Analysis

    [https://arxiv.org/abs/2401.00775](https://arxiv.org/abs/2401.00775)

    文本分析是一个有趣的研究领域，在数据科学中有广泛的应用。本文回顾了文本分析的常见方法，介绍了一种新的统计方法Topic-SCORE，并在统计出版物数据集MADStat上进行了应用。通过对MADStat的分析，我们发现了11个代表统计领域的主题，并提出了一种新的统计模型来评估主题的引用影响。同时，我们还构建了一个跨主题的引用图来分析研究结果在不同领域之间的传播。

    

    文本分析是数据科学中一个有趣的研究领域，具有人工智能、生物医学研究和工程等多种应用。我们回顾了文本分析的流行方法，从主题建模到最新的神经语言模型。特别是，我们回顾了Topic-SCORE，一种用于主题建模的统计方法，并讨论了如何使用它来分析我们收集和清理的统计出版物数据集MADStat。在MADStat上应用Topic-SCORE和其他方法得到了有趣的发现。例如，我们鉴定出了统计领域中11个代表性的主题。对于每个期刊，可以可视化主题权重随时间的变化，并利用这些结果分析统计研究的趋势。特别是，我们提出了一种用于排名11个主题引用影响的新的统计模型，还构建了一个跨主题的引用图，以说明不同主题的研究成果是如何传播到其他领域的。

    Text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. We review popular methods for text analysis, ranging from topic modeling to the recent neural language models. In particular, we review Topic-SCORE, a statistical approach to topic modeling, and discuss how to use it to analyze MADStat - a dataset on statistical publications that we collected and cleaned.   The application of Topic-SCORE and other methods on MADStat leads to interesting findings. For example, $11$ representative topics in statistics are identified. For each journal, the evolution of topic weights over time can be visualized, and these results are used to analyze the trends in statistical research. In particular, we propose a new statistical model for ranking the citation impacts of $11$ topics, and we also build a cross-topic citation graph to illustrate how research results on different topics spread to o
    
[^14]: 标记交互式主题模型

    Labeled Interactive Topic Models

    [https://arxiv.org/abs/2311.09438](https://arxiv.org/abs/2311.09438)

    这篇论文介绍了一种用户友好的交互式神经主题模型，通过用户分配单词标签来更新主题模型，使得主题更加相关和准确。这种方法包括可训练和后训练集成两种不同类型的神经主题模型。

    

    主题模型对于理解大量文档集合非常有价值，但是它们并不总是能够识别出最相关的主题。传统的概率和基于锚点的主题模型提供了允许用户引导模型指向更相关主题的交互版本。然而，神经主题模型缺乏这种交互功能。为了弥补这一不足，我们引入了一种用户友好的神经主题模型交互方法。这种交互允许用户为一个主题分配一个单词标签，从而更新主题模型，使主题中的单词与给定的标签密切对应。我们的方法包括两种不同类型的神经主题模型。第一种包括主题嵌入可训练且在训练过程中演变的模型。第二种涉及主题嵌入后训练集成的模型，提供了一种不同的主题细化方法。为了方便用户与这些神经主题模型的交互，我们还提出了一个交互式图形用户界面工具。

    Topic models are valuable for understanding extensive document collections, but they don't always identify the most relevant topics. Classical probabilistic and anchor-based topic models offer interactive versions that allow users to guide the models towards more pertinent topics. However, such interactive features have been lacking in neural topic models. To correct this lacuna, we introduce a user-friendly interaction for neural topic models. This interaction permits users to assign a word label to a topic, leading to an update in the topic model where the words in the topic become closely aligned with the given label. Our approach encompasses two distinct kinds of neural topic models. The first includes models where topic embeddings are trainable and evolve during the training process. The second kind involves models where topic embeddings are integrated post-training, offering a different approach to topic refinement. To facilitate user interaction with these neural topic models, w
    
[^15]: 通过多样性结果集实现最新性排名

    Recency Ranking by Diversification of Result Set. (arXiv:2401.14595v1 [cs.IR])

    [http://arxiv.org/abs/2401.14595](http://arxiv.org/abs/2401.14595)

    本文提出了一种通过多样化结果集来增加普通文档排名新鲜度的网络搜索检索方法，通过实验验证了该方法可以显著提高用户的满意度。

    

    本文提出了一种网络搜索检索方法，它可以自动识别对最新内容敏感的查询，并通过与最近内容需求的概率成比例地增加普通文档排名的新鲜度。我们提出使用结果多样性原则来解决最新性排名问题，并处理查询的非主题歧义，这种歧义只能以不确定性的方式检测到最近内容的需求。我们的离线和在线实验使用了来自真实搜索引擎用户的数百万个查询，结果表明通过我们的方法生成的搜索结果可以显著提高用户的满意度。

    In this paper, we propose a web search retrieval approach which automatically detects recency sensitive queries and increases the freshness of the ordinary document ranking by a degree proportional to the probability of the need in recent content. We propose to solve the recency ranking problem by using result diversification principles and deal with the query's non-topical ambiguity appearing when the need in recent content can be detected only with uncertainty. Our offline and online experiments with millions of queries from real search engine users demonstrate the significant increase in satisfaction of users presented with a search result generated by our approach.
    
[^16]: 迈向填充通用工程设计知识的方法

    Towards Populating Generalizable Engineering Design Knowledge. (arXiv:2307.06985v1 [cs.CL])

    [http://arxiv.org/abs/2307.06985](http://arxiv.org/abs/2307.06985)

    这项研究提出了一种从专利文件中提取工程设计知识的方法，通过构建知识图来填充通用设计知识，并与现有方法进行了比较。

    

    为了填充通用工程设计知识，我们提出了一种从专利文件中提取head entity :: relationship :: tail entity形式事实的方法。这些事实可以在专利文件内部和跨文件之间组合形成知识图，用作表示和存储设计知识的方案。现有的工程设计文献中的方法通常利用一组预定义的关系来填充统计近似而非事实的三元组。在我们的方法中，我们训练一个标记器来识别句子中的实体和关系。在确定了一对实体后，我们训练另一个标记器来识别特定表示这对实体之间关系的关系标记。为了训练这些标记器，我们手动构建了一个包含44,227个句子和相应事实的数据集。我们还将该方法的性能与通常推荐的方法进行了比较，其中我们预.

    Aiming to populate generalizable engineering design knowledge, we propose a method to extract facts of the form head entity :: relationship :: tail entity from sentences found in patent documents. These facts could be combined within and across patent documents to form knowledge graphs that serve as schemes for representing as well as storing design knowledge. Existing methods in engineering design literature often utilise a set of predefined relationships to populate triples that are statistical approximations rather than facts. In our method, we train a tagger to identify both entities and relationships from a sentence. Given a pair of entities thus identified, we train another tagger to identify the relationship tokens that specifically denote the relationship between the pair. For training these taggers, we manually construct a dataset of 44,227 sentences and corresponding facts. We also compare the performance of the method against typically recommended approaches, wherein, we pre
    

