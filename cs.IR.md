# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means](https://arxiv.org/abs/2403.18766) | 该论文介绍了一种新型K-means聚类算法，通过竞争性随机样本大小优化，有效提高了Big-means中的并行大数据聚类效率。 |
| [^2] | [Scaling Laws For Dense Retrieval](https://arxiv.org/abs/2403.18684) | 该研究探究了密集检索模型的性能是否遵循其他神经模型的缩放规律，并提出使用对比对数似然作为评估指标进行了广泛实验。 |
| [^3] | [Improving Content Recommendation: Knowledge Graph-Based Semantic Contrastive Learning for Diversity and Cold-Start Users](https://arxiv.org/abs/2403.18667) | 提出了一种基于知识图的语义对比学习方法，通过混合多任务学习在用户-项目和项目-项目交互上进行训练，从而提供个性化和多样化的推荐。 |
| [^4] | [To Recommend or Not: Recommendability Identification in Conversations with Pre-trained Language Models](https://arxiv.org/abs/2403.18628) | 这项研究提出并定义了可推荐性识别问题，专注于在当前对话环境中探讨是否需要推荐，以减少用户干扰。 |
| [^5] | [Antitrust, Amazon, and Algorithmic Auditing](https://arxiv.org/abs/2403.18623) | 本研究调查了亚马逊是否存在自我偏好的做法，讨论了如何利用计算机科学工具进行基于算法审计的监管，以规范数字市场。 |
| [^6] | [Modeling Sustainable City Trips: Integrating CO2 Emissions, Popularity, and Seasonality into Tourism Recommender Systems](https://arxiv.org/abs/2403.18604) | 该论文提出了一种新颖的方法，为用户出发地可到达的城市旅行分配可持续性指标（SF指数）。 |
| [^7] | [A Novel Behavior-Based Recommendation System for E-commerce](https://arxiv.org/abs/2403.18536) | 提出了一种基于顾客行为的推荐方法，通过利用顾客在电子商务平台上的自然行为来生成准确的推荐结果 |
| [^8] | [Enhanced Generative Recommendation via Content and Collaboration Integration](https://arxiv.org/abs/2403.18480) | 本文引入了一种基于内容的协作生成式推荐系统ColaRec，旨在解决生成式推荐中的协作信号集成和信息对齐的挑战。 |
| [^9] | [Lightweight Embeddings for Graph Collaborative Filtering](https://arxiv.org/abs/2403.18479) | 提出了一种轻量级嵌入方法，通过自动学习用户/项目的索引到元嵌入之间的映射，提高了基于GNN的推荐系统的性能。 |
| [^10] | [Decoy Effect In Search Interaction: Understanding User Behavior and Measuring System Vulnerability](https://arxiv.org/abs/2403.18462) | 该研究探讨了诱饵效应对用户搜索交互的影响，提出了新的衡量IR系统脆弱性的方法，并介绍了DEJA-VU指标来评估系统对诱饵效应的易感性。 |
| [^11] | [DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via Structural Word Alignment](https://arxiv.org/abs/2403.18435) | 引入DELTA，利用结构化词对齐预训练判别式编码器进行法律案例检索，通过强调关键事实来提高表示的判别能力。 |
| [^12] | [Sequential Recommendation with Latent Relations based on Large Language Model](https://arxiv.org/abs/2403.18348) | 本文提出了一种基于大型语言模型的关系感知顺序推荐框架，通过潜在关系发现（LRD）提升了推荐系统在各种场景中的泛化能力。 |
| [^13] | [Common Sense Enhanced Knowledge-based Recommendation with Large Language Model](https://arxiv.org/abs/2403.18325) | 这项研究提出了一种利用大语言模型中的世界知识来增强基于常识的知识推荐框架，以解决先前工作中知识图的局限性和冷启动问题。 |
| [^14] | [A Situation-aware Enhancer for Personalized Recommendation](https://arxiv.org/abs/2403.18317) | 本文提出了一种将情境作为用户交互的前提条件的新视角，并基于此设计了一种面向情境的推荐系统增强器。 |
| [^15] | [A Recommender System for NFT Collectibles with Item Feature](https://arxiv.org/abs/2403.18305) | 该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。 |
| [^16] | [Improving Out-of-Vocabulary Handling in Recommendation Systems](https://arxiv.org/abs/2403.18280) | 本研究提出了改进推荐系统中非词汇处理的方法，针对训练时未见过的新用户和物品，通过更好地利用可用的用户/物品特征来改善嵌入表中的非词汇处理。 |
| [^17] | [RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers](https://arxiv.org/abs/2403.18276) | Mamba模型基于状态空间模型，在多个序列建模任务中取得了与Transformer相当的性能，并在经典信息检索任务--文档排名中展现了其有效性。 |
| [^18] | [One Backpropagation in Two Tower Recommendation Models](https://arxiv.org/abs/2403.18227) | 该论文提出了一种在两塔推荐模型中使用单次反向传播更新策略的方法，挑战了现有算法中平等对待用户和物品的假设。 |
| [^19] | [Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence](https://arxiv.org/abs/2403.18183) | 本研究探讨了AI模型在文档理解任务中对于布局和图像数据有益的影响，以及AI是否能有效捕捉文件美学的微妙之处。 |
| [^20] | [LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices](https://arxiv.org/abs/2403.18173) | 这项研究介绍了在HCI文献中使用LLMs和结构化文本分析技术提取实验数据的新系统，评估了GPT-3.5和Llama-2模型在准确性方面的表现，并分析了使用LLMs在研究中面临的挑战和风险。 |
| [^21] | [Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER](https://arxiv.org/abs/2403.18025) | 提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。 |
| [^22] | [MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification](https://arxiv.org/abs/2403.17421) | 引入了基于多智能体强化学习的MA4DIV方法，将搜索结果多样化建模为多个智能体之间的合作任务，直接优化多样性指标，如$\alpha$-NDCG，以实现高训练效率。 |
| [^23] | [Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models](https://arxiv.org/abs/2403.16915) | 本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。 |
| [^24] | [MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation](https://arxiv.org/abs/2403.06747) | 提出了Meta-Split网络（MSN）来解决消费者之间电子商务平台中限量库存产品推荐中的独特挑战，通过分割用户历史序列来有效利用用户历史信息。 |
| [^25] | [DynaWarp -- Efficient, large-scale log storage and retrieval](https://arxiv.org/abs/2402.18355) | DynaWarp提出了一种新的成员草图结构，可以高效地回答多集多成员查询，相比于倒排索引和成员草图，具有更高的存储效率和查询吞吐量。 |
| [^26] | [Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism](https://arxiv.org/abs/2402.12997) | 提出了一种适用于现实约束的轻量级弃权机制，特别适用于再排序阶段，通过数据驱动的方法达到有效性，并提供了开源代码以促进其更广泛的应用。 |
| [^27] | [LLatrieval: LLM-Verified Retrieval for Verifiable Generation](https://arxiv.org/abs/2311.07838) | 可验证生成中检索的文件不仅帮助LLM生成正确答案，还作为用户验证LLM输出的证据，但目前广泛使用的检索器已成为性能瓶颈，需要解决。 |

# 详细

[^1]: 通过竞争性随机样本大小优化在Big-means中实现优越的并行大数据聚类

    Superior Parallel Big Data Clustering through Competitive Stochastic Sample Size Optimization in Big-means

    [https://arxiv.org/abs/2403.18766](https://arxiv.org/abs/2403.18766)

    该论文介绍了一种新型K-means聚类算法，通过竞争性随机样本大小优化，有效提高了Big-means中的并行大数据聚类效率。

    

    这篇论文介绍了一种新颖的K-means聚类算法，是对传统Big-means方法的进步。所提出的方法有效地整合了并行处理、随机抽样和竞争性优化，创建了一个专为大数据应用设计的可扩展变体。它解决了传统技术通常面临的可伸缩性和计算时间挑战。该算法在执行过程中动态调整每个工作人员的样本大小，优化性能。这些样本大小的数据不断被分析，促进了找到最有效配置的识别。通过在使用不同样本大小的工作人员之间引入竞争因素，进一步刺激了Big-means算法内的效率。本质上，该算法通过在并行计算环境中采用随机、竞争性抽样策略，平衡了计算时间和聚类质量。

    arXiv:2403.18766v1 Announce Type: cross  Abstract: This paper introduces a novel K-means clustering algorithm, an advancement on the conventional Big-means methodology. The proposed method efficiently integrates parallel processing, stochastic sampling, and competitive optimization to create a scalable variant designed for big data applications. It addresses scalability and computation time challenges typically faced with traditional techniques. The algorithm adjusts sample sizes dynamically for each worker during execution, optimizing performance. Data from these sample sizes are continually analyzed, facilitating the identification of the most efficient configuration. By incorporating a competitive element among workers using different sample sizes, efficiency within the Big-means algorithm is further stimulated. In essence, the algorithm balances computational time and clustering quality by employing a stochastic, competitive sampling strategy in a parallel computing setting.
    
[^2]: 密集检索的扩展规律

    Scaling Laws For Dense Retrieval

    [https://arxiv.org/abs/2403.18684](https://arxiv.org/abs/2403.18684)

    该研究探究了密集检索模型的性能是否遵循其他神经模型的缩放规律，并提出使用对比对数似然作为评估指标进行了广泛实验。

    

    将神经模型扩展到更大规模已经在多项任务中取得了显著进展，特别是在语言生成方面。先前的研究发现，神经模型的性能常遵循可预测的扩展规律，与训练集大小和模型大小等因素相关。这一洞察力非常宝贵，尤其是随着大规模实验变得越来越耗费资源。然而，由于检索指标的离散性以及检索任务中训练数据和模型大小之间的复杂关系，密集检索中的这种扩展规律尚未得到充分探讨。在本研究中，我们调查了密集检索模型的性能是否遵循其他神经模型的缩放规律。我们建议使用对比对数似然作为评估指标，并对实现了不同参数数量并使用不同数量的数据训练的密集检索模型进行了广泛实验。

    arXiv:2403.18684v1 Announce Type: cross  Abstract: Scaling up neural models has yielded significant advancements in a wide array of tasks, particularly in language generation. Previous studies have found that the performance of neural models frequently adheres to predictable scaling laws, correlated with factors such as training set size and model size. This insight is invaluable, especially as large-scale experiments grow increasingly resource-intensive. Yet, such scaling law has not been fully explored in dense retrieval due to the discrete nature of retrieval metrics and complex relationships between training data and model sizes in retrieval tasks. In this study, we investigate whether the performance of dense retrieval models follows the scaling law as other neural models. We propose to use contrastive log-likelihood as the evaluation metric and conduct extensive experiments with dense retrieval models implemented with different numbers of parameters and trained with different amo
    
[^3]: 改进内容推荐：基于知识图的语义对比学习用于多样性和冷启动用户

    Improving Content Recommendation: Knowledge Graph-Based Semantic Contrastive Learning for Diversity and Cold-Start Users

    [https://arxiv.org/abs/2403.18667](https://arxiv.org/abs/2403.18667)

    提出了一种基于知识图的语义对比学习方法，通过混合多任务学习在用户-项目和项目-项目交互上进行训练，从而提供个性化和多样化的推荐。

    

    处理与数据稀疏性、冷启动问题和推荐系统多样性相关的挑战既至关重要又具有挑战性。许多当前的解决方案利用知识图来解决这些问题，结合基于项目和用户-项目协作信号。这些方法的一个普遍趋势是专注于提高排名性能，但会增加模型复杂性、降低多样性并使任务变得更复杂。提供既个性化又多样化的推荐是至关重要的，而不仅仅依赖于实现高排名性能，比如点击率、召回率等。本文提出了一种混合多任务学习方法，通过在用户-项目和项目-项目交互上进行训练。我们在描述性文本上应用基于项目的对比学习，根据项目元数据对正负样本进行抽样。我们的方法使模型能更好地理解关系

    arXiv:2403.18667v1 Announce Type: cross  Abstract: Addressing the challenges related to data sparsity, cold-start problems, and diversity in recommendation systems is both crucial and demanding. Many current solutions leverage knowledge graphs to tackle these issues by combining both item-based and user-item collaborative signals. A common trend in these approaches focuses on improving ranking performance at the cost of escalating model complexity, reducing diversity, and complicating the task. It is essential to provide recommendations that are both personalized and diverse, rather than solely relying on achieving high rank-based performance, such as Click-through Rate, Recall, etc. In this paper, we propose a hybrid multi-task learning approach, training on user-item and item-item interactions. We apply item-based contrastive learning on descriptive text, sampling positive and negative pairs based on item metadata. Our approach allows the model to better understand the relationships 
    
[^4]: 是否推荐：在与预训练语言模型的对话中识别可推荐性

    To Recommend or Not: Recommendability Identification in Conversations with Pre-trained Language Models

    [https://arxiv.org/abs/2403.18628](https://arxiv.org/abs/2403.18628)

    这项研究提出并定义了可推荐性识别问题，专注于在当前对话环境中探讨是否需要推荐，以减少用户干扰。

    

    大多数当前的推荐系统主要关注于推荐什么，假设用户总是需要个性化推荐。然而，随着ChatGPT和其他聊天机器人的广泛传播，在对话系统的背景下更关键的问题是在为用户提供推荐服务时如何最小化用户的干扰。我们正式定义了可推荐性识别问题，旨在确定在特定场景中是否需要推荐。

    arXiv:2403.18628v1 Announce Type: new  Abstract: Most current recommender systems primarily focus on what to recommend, assuming users always require personalized recommendations. However, with the widely spread of ChatGPT and other chatbots, a more crucial problem in the context of conversational systems is how to minimize user disruption when we provide recommendation services for users. While previous research has extensively explored different user intents in dialogue systems, fewer efforts are made to investigate whether recommendations should be provided. In this paper, we formally define the recommendability identification problem, which aims to determine whether recommendations are necessary in a specific scenario. First, we propose and define the recommendability identification task, which investigates the need for recommendations in the current conversational context. A new dataset is constructed. Subsequently, we discuss and evaluate the feasibility of leveraging pre-trained
    
[^5]: 反垄断、亚马逊和算法审计

    Antitrust, Amazon, and Algorithmic Auditing

    [https://arxiv.org/abs/2403.18623](https://arxiv.org/abs/2403.18623)

    本研究调查了亚马逊是否存在自我偏好的做法，讨论了如何利用计算机科学工具进行基于算法审计的监管，以规范数字市场。

    

    在数字市场中，反垄断法和特殊法规旨在确保市场保持竞争，尽管数字平台在每个人生活中扮演着主导角色。与传统市场不同，这些市场中的市场参与者行为很容易被观察到。我们展示了一系列实证调查，探讨亚马逊在多大程度上参与了通常被描述为自我偏好的做法。我们讨论了本文中使用的计算机科学工具如何在基于算法审计的监管环境中使用，并要求在规模上监管数字市场。

    arXiv:2403.18623v1 Announce Type: cross  Abstract: In digital markets, antitrust law and special regulations aim to ensure that markets remain competitive despite the dominating role that digital platforms play today in everyone's life. Unlike traditional markets, market participant behavior is easily observable in these markets. We present a series of empirical investigations into the extent to which Amazon engages in practices that are typically described as self-preferencing. We discuss how the computer science tools used in this paper can be used in a regulatory environment that is based on algorithmic auditing and requires regulating digital markets at scale.
    
[^6]: 建模可持续城市旅行：将CO2排放、热度和季节性整合到旅游推荐系统中

    Modeling Sustainable City Trips: Integrating CO2 Emissions, Popularity, and Seasonality into Tourism Recommender Systems

    [https://arxiv.org/abs/2403.18604](https://arxiv.org/abs/2403.18604)

    该论文提出了一种新颖的方法，为用户出发地可到达的城市旅行分配可持续性指标（SF指数）。

    

    在信息过载和复杂决策过程的时代，推荐系统（RS）已成为各个领域不可或缺的工具，尤其是旅行和旅游领域。本文介绍了一种新颖的方法，为用户出发地可到达的城市旅行分配可持续性指标（SF指数）。

    arXiv:2403.18604v1 Announce Type: new  Abstract: In an era of information overload and complex decision-making processes, Recommender Systems (RS) have emerged as indispensable tools across diverse domains, particularly travel and tourism. These systems simplify trip planning by offering personalized recommendations that consider individual preferences and address broader challenges like seasonality, travel regulations, and capacity constraints. The intricacies of the tourism domain, characterized by multiple stakeholders, including consumers, item providers, platforms, and society, underscore the complexity of achieving balance among diverse interests. Although previous research has focused on fairness in Tourism Recommender Systems (TRS) from a multistakeholder perspective, limited work has focused on generating sustainable recommendations.   Our paper introduces a novel approach for assigning a sustainability indicator (SF index) for city trips accessible from the users' starting po
    
[^7]: 一种新颖的基于行为的电子商务推荐系统

    A Novel Behavior-Based Recommendation System for E-commerce

    [https://arxiv.org/abs/2403.18536](https://arxiv.org/abs/2403.18536)

    提出了一种基于顾客行为的推荐方法，通过利用顾客在电子商务平台上的自然行为来生成准确的推荐结果

    

    大多数现有的推荐系统依赖于用户评分，这受到用户协作欠缺和稀疏问题的限制。为了解决这些问题，本研究提出了一种基于行为的推荐系统，利用顾客在电子商务平台上的自然行为，如浏览和点击。提出的推荐系统涉及对活跃顾客进行聚类、确定邻域、收集相似用户、基于相似用户计算产品声誉以及推荐高声誉产品。为了克服顾客行为和传统聚类方法的复杂性，开发了一种基于产品类别的无监督聚类方法，以增强推荐方法。该研究在几个方面做出了显著贡献。

    arXiv:2403.18536v1 Announce Type: cross  Abstract: The majority of existing recommender systems rely on user ratings, which are limited by the lack of user collaboration and the sparsity problem. To address these issues, this study proposes a behavior-based recommender system that leverages customers' natural behaviors, such as browsing and clicking, on e-commerce platforms. The proposed recommendation system involves clustering active customers, determining neighborhoods, collecting similar users, calculating product reputation based on similar users, and recommending high-reputation products. To overcome the complexity of customer behaviors and traditional clustering methods, an unsupervised clustering approach based on product categories is developed to enhance the recommendation methodology. This study makes notable contributions in several aspects. Firstly, a groundbreaking behavior-based recommendation methodology is developed, incorporating customer behavior to generate accurate
    
[^8]: 通过内容和协作集成增强生成式推荐

    Enhanced Generative Recommendation via Content and Collaboration Integration

    [https://arxiv.org/abs/2403.18480](https://arxiv.org/abs/2403.18480)

    本文引入了一种基于内容的协作生成式推荐系统ColaRec，旨在解决生成式推荐中的协作信号集成和信息对齐的挑战。

    

    生成式推荐已经出现作为一种有前途的范式，旨在通过生成式人工智能的最新进展来增强推荐系统。本任务被制定为一个序列到序列的生成过程，其中输入序列包含与用户先前交互的项目相关的数据，输出序列表示建议项目的生成标识符。然而，现有的生成式推荐方法仍然面临着以下挑战：有效地在统一生成框架内集成用户-项目协作信号和项目内容信息，以及在内容信息和协作信号之间执行高效的对齐。

    arXiv:2403.18480v1 Announce Type: new  Abstract: Generative recommendation has emerged as a promising paradigm aimed at augmenting recommender systems with recent advancements in generative artificial intelligence. This task has been formulated as a sequence-to-sequence generation process, wherein the input sequence encompasses data pertaining to the user's previously interacted items, and the output sequence denotes the generative identifier for the suggested item. However, existing generative recommendation approaches still encounter challenges in (i) effectively integrating user-item collaborative signals and item content information within a unified generative framework, and (ii) executing an efficient alignment between content information and collaborative signals.   In this paper, we introduce content-based collaborative generation for recommender systems, denoted as ColaRec. To capture collaborative signals, the generative item identifiers are derived from a pretrained collabora
    
[^9]: 轻量级嵌入用于图协同过滤

    Lightweight Embeddings for Graph Collaborative Filtering

    [https://arxiv.org/abs/2403.18479](https://arxiv.org/abs/2403.18479)

    提出了一种轻量级嵌入方法，通过自动学习用户/项目的索引到元嵌入之间的映射，提高了基于GNN的推荐系统的性能。

    

    图神经网络（GNNs）目前是最有效的协同过滤方法之一。然而，由于使用嵌入表来表示每个用户/项目为不同的向量，基于GNN的推荐系统继承了参数效率低下的长期缺陷。为了解决这个问题，我们提出了一种轻量级嵌入方法，即在学习过程中自动学习用户/项目的索引到对应的元嵌入之间的映射。

    arXiv:2403.18479v1 Announce Type: new  Abstract: Graph neural networks (GNNs) are currently one of the most performant collaborative filtering methods. Meanwhile, owing to the use of an embedding table to represent each user/item as a distinct vector, GNN-based recommenders have inherited the long-standing defect of parameter inefficiency. As a common practice for scalable embeddings, parameter sharing enables the use of fewer embedding vectors (i.e., meta-embeddings). When assigning meta-embeddings, most existing methods are a heuristically designed, predefined mapping from each user's/item's ID to the corresponding meta-embedding indexes, thus simplifying the optimization problem into learning only the meta-embeddings. However, in the context of GNN-based collaborative filtering, such a fixed mapping omits the semantic correlations between entities that are evident in the user-item interaction graph, leading to suboptimal recommendation performance. To this end, we propose Lightweigh
    
[^10]: 搜索交互中的诱饵效应：理解用户行为和测量系统脆弱性

    Decoy Effect In Search Interaction: Understanding User Behavior and Measuring System Vulnerability

    [https://arxiv.org/abs/2403.18462](https://arxiv.org/abs/2403.18462)

    该研究探讨了诱饵效应对用户搜索交互的影响，提出了新的衡量IR系统脆弱性的方法，并介绍了DEJA-VU指标来评估系统对诱饵效应的易感性。

    

    本研究考察了诱饵效应对用户搜索交互的影响，以及衡量信息检索（IR）系统对这种影响的脆弱性的方法。它探讨了诱饵结果如何改变用户在搜索引擎结果页面上的交互，关注点击概率、浏览时间和感知文档有用性等指标。通过分析来自多个数据集的用户交互日志，研究表明诱饵结果显著影响用户行为和感知。此外，研究还调查了不同任务难度和用户知识水平如何修改诱饵效应的影响，发现更容易的任务和较低的知识水平会导致更高的目标文档参与度。在IR系统评估方面，研究引入了DEJA-VU指标来评估系统对诱饵效应的易感性，并在特定检索任务上进行测试。结果显示在系统上存在差异

    arXiv:2403.18462v1 Announce Type: new  Abstract: This study examines the decoy effect's underexplored influence on user search interactions and methods for measuring information retrieval (IR) systems' vulnerability to this effect. It explores how decoy results alter users' interactions on search engine result pages, focusing on metrics like click-through likelihood, browsing time, and perceived document usefulness. By analyzing user interaction logs from multiple datasets, the study demonstrates that decoy results significantly affect users' behavior and perceptions. Furthermore, it investigates how different levels of task difficulty and user knowledge modify the decoy effect's impact, finding that easier tasks and lower knowledge levels lead to higher engagement with target documents. In terms of IR system evaluation, the study introduces the DEJA-VU metric to assess systems' susceptibility to the decoy effect, testing it on specific retrieval tasks. The results show differences in 
    
[^11]: 利用结构化词对齐预训练判别式编码器进行法律案例检索

    DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via Structural Word Alignment

    [https://arxiv.org/abs/2403.18435](https://arxiv.org/abs/2403.18435)

    引入DELTA，利用结构化词对齐预训练判别式编码器进行法律案例检索，通过强调关键事实来提高表示的判别能力。

    

    最近的研究表明，使用预训练语言模型进行法律案例检索是有效的。现有的大部分研究侧重于提高[CLS]标记的上下文嵌入的表征能力，并使用文本语义相似性计算相关性。然而，在法律领域，文本语义相似性并不总是意味着案例之间足够相关。相反，在法律案例中，相关性主要取决于影响最终判决的关键事实的相似性。为此，我们引入了DELTA，这是一个为法律案例检索设计的判别式模型。基本思想是在法律案例中找到关键事实，并将[CLS]标记的上下文嵌入逼近这些关键事实，同时远离非关键事实。

    arXiv:2403.18435v1 Announce Type: cross  Abstract: Recent research demonstrates the effectiveness of using pre-trained language models for legal case retrieval. Most of the existing works focus on improving the representation ability for the contextualized embedding of the [CLS] token and calculate relevance using textual semantic similarity. However, in the legal domain, textual semantic similarity does not always imply that the cases are relevant enough. Instead, relevance in legal cases primarily depends on the similarity of key facts that impact the final judgment. Without proper treatments, the discriminative ability of learned representations could be limited since legal cases are lengthy and contain numerous non-key facts. To this end, we introduce DELTA, a discriminative model designed for legal case retrieval. The basic idea involves pinpointing key facts in legal cases and pulling the contextualized embedding of the [CLS] token closer to the key facts while pushing away from 
    
[^12]: 基于大型语言模型的关系感知顺序推荐

    Sequential Recommendation with Latent Relations based on Large Language Model

    [https://arxiv.org/abs/2403.18348](https://arxiv.org/abs/2403.18348)

    本文提出了一种基于大型语言模型的关系感知顺序推荐框架，通过潜在关系发现（LRD）提升了推荐系统在各种场景中的泛化能力。

    

    arXiv:2403.18348v1 声明类型: 新的摘要: 顺序推荐系统通过建模用户基于历史互动的偏好来预测可能吸引用户的项目。传统的顺序推荐方法依赖于捕获项目之间的隐性协作过滤信号。最近的基于关系感知的顺序推荐模型通过将项目关系明确纳入用户历史序列的建模中取得了令人期待的性能，其中大多数关系来自知识图。然而，现有方法依赖于手动预定义的关系，并受到稀疏问题的困扰，限制了在具有不同项目关系的各种场景中的泛化能力。在本文中，我们提出了一种基于潜在关系发现（LRD）的新颖关系感知顺序推荐框架。与以往依赖预定义规则的关系感知模型不同，我们提议利用大型语言模型（LLM）提供新类型的关系

    arXiv:2403.18348v1 Announce Type: new  Abstract: Sequential recommender systems predict items that may interest users by modeling their preferences based on historical interactions. Traditional sequential recommendation methods rely on capturing implicit collaborative filtering signals among items. Recent relation-aware sequential recommendation models have achieved promising performance by explicitly incorporating item relations into the modeling of user historical sequences, where most relations are extracted from knowledge graphs. However, existing methods rely on manually predefined relations and suffer the sparsity issue, limiting the generalization ability in diverse scenarios with varied item relations. In this paper, we propose a novel relation-aware sequential recommendation framework with Latent Relation Discovery (LRD). Different from previous relation-aware models that rely on predefined rules, we propose to leverage the Large Language Model (LLM) to provide new types of re
    
[^13]: 利用大语言模型增强基于常识的知识推荐

    Common Sense Enhanced Knowledge-based Recommendation with Large Language Model

    [https://arxiv.org/abs/2403.18325](https://arxiv.org/abs/2403.18325)

    这项研究提出了一种利用大语言模型中的世界知识来增强基于常识的知识推荐框架，以解决先前工作中知识图的局限性和冷启动问题。

    

    知识推荐模型有效地缓解了数据稀疏问题，利用知识图中的侧面信息，并取得了相当可观的性能。然而，在先前的工作中使用的知识图，即基于元数据的知识图，通常是基于物品的属性和共现关系（例如，也购买）构建的，前者提供有限信息，后者依赖充分的交互数据，仍然受冷启动问题困扰。作为一种具有概括性和普适性的知识形式，常识可以作为元数据知识图的补充，并为建模用户偏好提供新视角。最近，受益于大型语言模型的新兴世界知识，高效获取常识变得可能。在本文中，我们提出了一个新颖的基于知识的推荐框架 incor

    arXiv:2403.18325v1 Announce Type: new  Abstract: Knowledge-based recommendation models effectively alleviate the data sparsity issue leveraging the side information in the knowledge graph, and have achieved considerable performance. Nevertheless, the knowledge graphs used in previous work, namely metadata-based knowledge graphs, are usually constructed based on the attributes of items and co-occurring relations (e.g., also buy), in which the former provides limited information and the latter relies on sufficient interaction data and still suffers from cold start issue. Common sense, as a form of knowledge with generality and universality, can be used as a supplement to the metadata-based knowledge graph and provides a new perspective for modeling users' preferences. Recently, benefiting from the emergent world knowledge of the large language model, efficient acquisition of common sense has become possible. In this paper, we propose a novel knowledge-based recommendation framework incor
    
[^14]: 一种面向情境的个性化推荐增强器

    A Situation-aware Enhancer for Personalized Recommendation

    [https://arxiv.org/abs/2403.18317](https://arxiv.org/abs/2403.18317)

    本文提出了一种将情境作为用户交互的前提条件的新视角，并基于此设计了一种面向情境的推荐系统增强器。

    

    当用户与推荐系统（RecSys）交互时，当前的情境，比如时间、地点和环境，显著影响他们的偏好。情境作为交互的背景，用户和物品之间的关系随着情境变化而发展。然而，现有的RecSys将情境、用户和物品视为同一级别。它们只能分别建模情境与用户/物品之间的关系，而无法建模情境动态对用户-物品关联（即用户偏好）的影响。本文提出了一种将情境视为用户交互的前提条件的新视角。这个视角使我们能够将情境与用户/物品表示分开，并捕捉情境对用户-物品关系的影响，从而更全面地理解情境。基于此，我们提出了一种新型的面向情境的推荐增强器（SARE），

    arXiv:2403.18317v1 Announce Type: new  Abstract: When users interact with Recommender Systems (RecSys), current situations, such as time, location, and environment, significantly influence their preferences. Situations serve as the background for interactions, where relationships between users and items evolve with situation changes. However, existing RecSys treat situations, users, and items on the same level. They can only model the relations between situations and users/items respectively, rather than the dynamic impact of situations on user-item associations (i.e., user preferences). In this paper, we provide a new perspective that takes situations as the preconditions for users' interactions. This perspective allows us to separate situations from user/item representations, and capture situations' influences over the user-item relationship, offering a more comprehensive understanding of situations. Based on it, we propose a novel Situation-Aware Recommender Enhancer (SARE), a plugg
    
[^15]: 一种具有项目特征的NFT可收藏品推荐系统

    A Recommender System for NFT Collectibles with Item Feature

    [https://arxiv.org/abs/2403.18305](https://arxiv.org/abs/2403.18305)

    该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。

    

    推荐系统已被积极研究并应用于各个领域以解决信息过载问题。尽管有许多关于电影、音乐和电子商务的推荐系统的研究，但相比之下，尽管NFT市场持续增长，对于NFT的推荐系统却受到了相对较少的关注。本文提出了一种针对NFT的推荐系统，利用各种数据源，从NFT交易记录到外部项目特征，生成符合个人偏好的精确推荐。我们开发了一种数据高效的基于图的推荐系统，以有效捕捉每个项目与用户之间的复杂关系，并生成包含节点特征信息和图结构的节点（项目）嵌入。此外，我们利用超出用户-项目互动的输入，如图像特征、文本特征和价格特征。数值实验证实了该模型的性能。

    arXiv:2403.18305v1 Announce Type: cross  Abstract: Recommender systems have been actively studied and applied in various domains to deal with information overload. Although there are numerous studies on recommender systems for movies, music, and e-commerce, comparatively less attention has been paid to the recommender system for NFTs despite the continuous growth of the NFT market. This paper presents a recommender system for NFTs that utilizes a variety of data sources, from NFT transaction records to external item features, to generate precise recommendations that cater to individual preferences. We develop a data-efficient graph-based recommender system to efficiently capture the complex relationship between each item and users and generate node(item) embeddings which incorporate both node feature information and graph structure. Furthermore, we exploit inputs beyond user-item interactions, such as image feature, text feature, and price feature. Numerical experiments verify the perf
    
[^16]: 改进推荐系统中的非词汇处理

    Improving Out-of-Vocabulary Handling in Recommendation Systems

    [https://arxiv.org/abs/2403.18280](https://arxiv.org/abs/2403.18280)

    本研究提出了改进推荐系统中非词汇处理的方法，针对训练时未见过的新用户和物品，通过更好地利用可用的用户/物品特征来改善嵌入表中的非词汇处理。

    

    推荐系统在学术界和工业界都是一个越来越重要的领域，因为它们对数十亿用户的日常在线体验有着广泛影响。一个常见的问题是冷启动问题，在实际推荐系统中，用户和物品可能没有足够的信息来产生高质量的推荐。本研究侧重于另一个问题：在训练时推荐未见过的新用户和物品（非词汇，或OOV）。这种情况被称为归纳设置，对于基于因子分解的模型特别有问题，因为这些模型仅依赖于在训练时看到的用户/物品来编码固定的参数向量。许多现有的解决方案在实践中往往很天真，比如将OOV用户/物品分配到随机桶中。在这项工作中，我们解决了这个问题，并提出了利用可用用户/物品特征来改进嵌入表中OOV处理的方法。

    arXiv:2403.18280v1 Announce Type: new  Abstract: Recommendation systems (RS) are an increasingly relevant area for both academic and industry researchers, given their widespread impact on the daily online experiences of billions of users. One common issue in real RS is the cold-start problem, where users and items may not contain enough information to produce high-quality recommendations. This work focuses on a complementary problem: recommending new users and items unseen (out-of-vocabulary, or OOV) at training time. This setting is known as the inductive setting and is especially problematic for factorization-based models, which rely on encoding only those users/items seen at training time with fixed parameter vectors. Many existing solutions applied in practice are often naive, such as assigning OOV users/items to random buckets. In this work, we tackle this problem and propose approaches that better leverage available user/item features to improve OOV handling at the embedding tabl
    
[^17]: RankMamba，在Transformer时代对Mamba文档排名性能的基准测试

    RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era of Transformers

    [https://arxiv.org/abs/2403.18276](https://arxiv.org/abs/2403.18276)

    Mamba模型基于状态空间模型，在多个序列建模任务中取得了与Transformer相当的性能，并在经典信息检索任务--文档排名中展现了其有效性。

    

    Transformer结构在自然语言处理（NLP）、计算机视觉（CV）和信息检索(IR)等多个应用的机器学习领域取得了巨大成功。Transformer架构的核心机制--注意力，在训练中需要$O(n^2)$的时间复杂度，在推断中需要$O(n)$的时间复杂度。许多工作已经提出改进注意力机制的可扩展性，比如Flash Attention和Multi-query Attention。另一方面的工作旨在设计新的机制来取代注意力。最近，基于状态空间模型的一个显著模型结构--Mamba，在多个序列建模任务中取得了与Transformer相当的性能。

    arXiv:2403.18276v1 Announce Type: cross  Abstract: Transformer structure has achieved great success in multiple applied machine learning communities, such as natural language processing (NLP), computer vision (CV) and information retrieval (IR). Transformer architecture's core mechanism -- attention requires $O(n^2)$ time complexity in training and $O(n)$ time complexity in inference. Many works have been proposed to improve the attention mechanism's scalability, such as Flash Attention and Multi-query Attention. A different line of work aims to design new mechanisms to replace attention. Recently, a notable model structure -- Mamba, which is based on state space models, has achieved transformer-equivalent performance in multiple sequence modeling tasks.   In this work, we examine \mamba's efficacy through the lens of a classical IR task -- document ranking. A reranker model takes a query and a document as input, and predicts a scalar relevance score. This task demands the language mod
    
[^18]: 两塔推荐模型中的单次反向传播

    One Backpropagation in Two Tower Recommendation Models

    [https://arxiv.org/abs/2403.18227](https://arxiv.org/abs/2403.18227)

    该论文提出了一种在两塔推荐模型中使用单次反向传播更新策略的方法，挑战了现有算法中平等对待用户和物品的假设。

    

    最近几年，已经看到为了减轻信息过载而开发两塔推荐模型的广泛研究。这种模型中可以识别出四个构建模块，分别是用户-物品编码、负采样、损失计算和反向传播更新。据我们所知，现有算法仅研究了前三个模块，却忽略了反向传播模块。他们都采用某种形式的双反向传播策略，基于一个隐含的假设，即在训练阶段平等对待用户和物品。在本文中，我们挑战了这种平等训练假设，并提出了一种新颖的单次反向传播更新策略，这种策略保留了物品编码塔的正常梯度反向传播，但削减了用户编码塔的反向传播。相反，我们提出了一种移动聚合更新策略来更新每个训练周期中的用户编码。

    arXiv:2403.18227v1 Announce Type: new  Abstract: Recent years have witnessed extensive researches on developing two tower recommendation models for relieving information overload. Four building modules can be identified in such models, namely, user-item encoding, negative sampling, loss computing and back-propagation updating. To the best of our knowledge, existing algorithms have researched only on the first three modules, yet neglecting the backpropagation module. They all adopt a kind of two backpropagation strategy, which are based on an implicit assumption of equally treating users and items in the training phase. In this paper, we challenge such an equal training assumption and propose a novel one backpropagation updating strategy, which keeps the normal gradient backpropagation for the item encoding tower, but cuts off the backpropagation for the user encoding tower. Instead, we propose a moving-aggregation updating strategy to update a user encoding in each training epoch. Exce
    
[^19]: AI模型能否欣赏文档美学？探究可读性与版面质量与预测置信度的关系

    Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence

    [https://arxiv.org/abs/2403.18183](https://arxiv.org/abs/2403.18183)

    本研究探讨了AI模型在文档理解任务中对于布局和图像数据有益的影响，以及AI是否能有效捕捉文件美学的微妙之处。

    

    一份精心设计的文件不仅通过文字传达信息，还通过视觉优雅传达信息。作者利用颜色、字体、图形和布局等美学元素来塑造信息的感知。经过心理洞察力启发的周到文件设计既增强了视觉吸引力，也增进了内容的理解。尽管最先进的文件AI模型展示了将布局和图像数据融入的好处，但文件美学的微妙之处是否被有效捕捉仍不清楚。为了弥合人类认知与AI对美学元素解释之间的差距，我们提出了假设，涉及AI在文件理解任务中的行为，特别是植根于文件设计原则。在关注可读性和版面质量的基础上，我们测试了美学效果的四个方面：噪音、字体大小对比、对齐和复杂性，以模型置信度为基准。

    arXiv:2403.18183v1 Announce Type: new  Abstract: A well-designed document communicates not only through its words but also through its visual eloquence. Authors utilize aesthetic elements such as colors, fonts, graphics, and layouts to shape the perception of information. Thoughtful document design, informed by psychological insights, enhances both the visual appeal and the comprehension of the content. While state-of-the-art document AI models demonstrate the benefits of incorporating layout and image data, it remains unclear whether the nuances of document aesthetics are effectively captured. To bridge the gap between human cognition and AI interpretation of aesthetic elements, we formulated hypotheses concerning AI behavior in document understanding tasks, specifically anchored in document design principles. With a focus on legibility and layout quality, we tested four aspects of aesthetic effects: noise, font-size contrast, alignment, and complexity, on model confidence using corre
    
[^20]: HCI数据工作中的LLMs：弥合信息检索与负责任研究实践之间的差距

    LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices

    [https://arxiv.org/abs/2403.18173](https://arxiv.org/abs/2403.18173)

    这项研究介绍了在HCI文献中使用LLMs和结构化文本分析技术提取实验数据的新系统，评估了GPT-3.5和Llama-2模型在准确性方面的表现，并分析了使用LLMs在研究中面临的挑战和风险。

    

    从科学论文中高效准确地提取信息在迅速发展的人机交互研究中的文献综述过程中具有重要意义。我们的论文介绍并分析了一种新的信息检索系统，使用最先进的大型语言模型（LLMs）结合结构化文本分析技术从HCI文献中提取实验数据，强调关键要素。然后，我们分析了在研究领域中使用LLMs面临的挑战和风险。我们对包含300篇CHI 2020-2022论文指定信息的数据集进行了全面分析，以评估两个大型语言模型GPT-3.5（text-davinci-003）和Llama-2-70b与结构化文本分析技术合作的性能。GPT-3.5模型获得了58%的精确度和7.00的平均绝对误差。相比之下，Llama-2模型显示出56%的准确度。

    arXiv:2403.18173v1 Announce Type: cross  Abstract: Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process. Our paper introduces and analyses a new information retrieval system using state-of-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements. Then We analyze the challenges and risks of using LLMs in the world of research. We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model gains an accuracy of 58\% and a mean absolute error of 7.00. In contrast, the Llama2 model indicates an accuracy of 56\% with a
    
[^21]: 通过特定掩码损失改善预训练语言模型的敏感性：以生物医学实体识别为例

    Improving Pre-trained Language Model Sensitivity via Mask Specific losses: A case study on Biomedical NER

    [https://arxiv.org/abs/2403.18025](https://arxiv.org/abs/2403.18025)

    提出了Mask Specific Language Modeling（MSLM）方法来改善LM在微调过程中对目标领域知识的敏感性，通过加权领域特定术语的重要性进行学习。

    

    将语言模型（LMs）调整到新领域通常通过在特定领域数据上微调预训练LM（PLM）来实现。微调将新知识引入LM，使它能够理解和有效执行目标域任务。然而，微调可能会无意中变得不够敏感，如果它忽视了源域和目标域之间的广泛差异（例如在词义上）。为了解决微调不敏感的问题，我们提出了Mask Specific Language Modeling（MSLM），一种通过在微调过程中适当加权领域特定术语（DS-terms）的重要性来有效获取目标领域知识的方法。MSLM同时屏蔽DS术语和通用词，然后通过确保LM受到更大惩罚来学习特定于掩码的损失。

    arXiv:2403.18025v1 Announce Type: cross  Abstract: Adapting language models (LMs) to novel domains is often achieved through fine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning introduces new knowledge into an LM, enabling it to comprehend and efficiently perform a target domain task. Fine-tuning can however be inadvertently insensitive if it ignores the wide array of disparities (e.g in word meaning) between source and target domains. For instance, words such as chronic and pressure may be treated lightly in social conversations, however, clinically, these words are usually an expression of concern. To address insensitive fine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach that efficiently acquires target domain knowledge by appropriately weighting the importance of domain-specific terms (DS-terms) during fine-tuning. MSLM jointly masks DS-terms and generic words, then learns mask-specific losses by ensuring LMs incur larger penalties for in
    
[^22]: MA4DIV：用于搜索结果多样化的多智能体强化学习

    MA4DIV: Multi-Agent Reinforcement Learning for Search Result Diversification

    [https://arxiv.org/abs/2403.17421](https://arxiv.org/abs/2403.17421)

    引入了基于多智能体强化学习的MA4DIV方法，将搜索结果多样化建模为多个智能体之间的合作任务，直接优化多样性指标，如$\alpha$-NDCG，以实现高训练效率。

    

    搜索结果多样化（SRD）的目标是确保所选文档涵盖尽可能多的不同子主题。现有方法主要利用“贪婪选择”范式，即一次选择一个具有最高多样性分数的文档。这些方法往往效率低下，容易陷入次优状态。此外，一些其他方法旨在近似优化多样性指标，如$\alpha$-NDCG，但结果仍然不尽如人意。为了解决这些挑战，我们引入了用于搜索结果多样性的多智能体强化学习（MARL）方法，称为MA4DIV。在这种方法中，每个文档都是一个智能体，搜索结果多样化被建模为多个智能体之间的合作任务。该方法允许直接优化多样性指标，如$\alpha$-NDCG，同时实现高训练效率。我们进行了初步实验。

    arXiv:2403.17421v1 Announce Type: cross  Abstract: The objective of search result diversification (SRD) is to ensure that selected documents cover as many different subtopics as possible. Existing methods primarily utilize a paradigm of "greedy selection", i.e., selecting one document with the highest diversity score at a time. These approaches tend to be inefficient and are easily trapped in a suboptimal state. In addition, some other methods aim to approximately optimize the diversity metric, such as $\alpha$-NDCG, but the results still remain suboptimal. To address these challenges, we introduce Multi-Agent reinforcement learning (MARL) for search result DIVersity, which called MA4DIV. In this approach, each document is an agent and the search result diversification is modeled as a cooperative task among multiple agents. This approach allows for directly optimizing the diversity metrics, such as $\alpha$-NDCG, while achieving high training efficiency. We conducted preliminary experi
    
[^23]: 利用预训练语言模型进行粗调优的专题文档检索

    Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models

    [https://arxiv.org/abs/2403.16915](https://arxiv.org/abs/2403.16915)

    本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。

    

    在信息检索系统中，利用预训练语言模型（PLM-based IR）进行微调需要学习查询表示和查询-文档关系，除了下游任务特定的学习。本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调。通过在粗调优学习查询表示和查询-文档关系，我们旨在减少微调的负担，提高下游IR任务的学习效果。我们提出了用于粗调优的查询-文档对预测（QDPP），其预测查询-文档对的适当性。评估实验显示，所提出的方法显著改善了四个专题文档检索数据集中的MRR和/或nDCG@5。此外，查询预测任务的结果表明，粗调优促进了查询表示和查询-文档关系的学习。

    arXiv:2403.16915v1 Announce Type: cross  Abstract: Fine-tuning in information retrieval systems using pre-trained language models (PLM-based IR) requires learning query representations and query-document relations, in addition to downstream task-specific learning. This study introduces coarse-tuning as an intermediate learning stage that bridges pre-training and fine-tuning. By learning query representations and query-document relations in coarse-tuning, we aim to reduce the load of fine-tuning and improve the learning effect of downstream IR tasks. We propose Query-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the appropriateness of query-document pairs. Evaluation experiments show that the proposed method significantly improves MRR and/or nDCG@5 in four ad-hoc document retrieval datasets. Furthermore, the results of the query prediction task suggested that coarse-tuning facilitated learning of query representation and query-document relations.
    
[^24]: MetaSplit: 用于限量产品推荐的Meta-Split网络

    MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation

    [https://arxiv.org/abs/2403.06747](https://arxiv.org/abs/2403.06747)

    提出了Meta-Split网络（MSN）来解决消费者之间电子商务平台中限量库存产品推荐中的独特挑战，通过分割用户历史序列来有效利用用户历史信息。

    

    相对于面向消费者的电子商务系统，消费者之间的电子商务平台通常会遇到限量库存问题，即产品在C2C系统中只能销售一次。这为点击率（CTR）预测带来了几个独特的挑战。鉴于每个产品（即商品）的有限用户交互，CTR模型中对应的商品嵌入可能不容易收敛。这使得传统基于序列建模的方法无法有效利用用户历史信息，因为历史用户行为包含了不同库存量的商品混合。特别是，序列模型中的注意力机制倾向于将更多累积用户交互的产品分配更高的分数，导致限量产品被忽视且对最终输出的贡献较少。为此，我们提出了Meta-Split网络（MSN）来分割用户历史序列...

    arXiv:2403.06747v1 Announce Type: new  Abstract: Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSN) to split user history sequence regar
    
[^25]: DynaWarp -- 高效的大规模日志存储和检索

    DynaWarp -- Efficient, large-scale log storage and retrieval

    [https://arxiv.org/abs/2402.18355](https://arxiv.org/abs/2402.18355)

    DynaWarp提出了一种新的成员草图结构，可以高效地回答多集多成员查询，相比于倒排索引和成员草图，具有更高的存储效率和查询吞吐量。

    

    现代大规模监控系统必须实时处理和存储大量日志数据。在查询时，系统必须基于日志消息的内容找到相关日志，使用能够扩展到这些数据量并且仍然高效的支持结构。我们提出了一种新颖的DynaWarp成员草图，能够回答多集多成员查询，可作为流式日志数据的现有索引结构的替代方案。在我们的实验中，DynaWarp所需的存储空间比测试的最先进的倒排索引少了高达93％，误报率比测试的最先进的成员草图少了高达四个数量级。此外，DynaWarp的查询吞吐量比测试的倒排索引高出高达250倍，并且比测试的成员草图高出高达240倍。

    arXiv:2402.18355v1 Announce Type: new  Abstract: Modern, large scale monitoring systems have to process and store vast amounts of log data in near real-time. At query time the systems have to find relevant logs based on the content of the log message using support structures that can scale to these amounts of data while still being efficient to use. We present our novel DynaWarp membership sketch, capable of answering Multi-Set Multi-Membership-Queries, that can be used as an alternative to existing indexing structures for streamed log data. In our experiments, DynaWarp required up to 93% less storage space than the tested state-of-the-art inverted index and had up to four orders of magnitude less false-positives than the tested state-of-the-art membership sketch. Additionally, DynaWarp achieved up to 250 times higher query throughput than the tested inverted index and up to 240 times higher query throughput than the tested membership sketch.
    
[^26]: 朝着可信的再排序：一种简单但有效的弃权机制

    Towards Trustworthy Reranking: A Simple yet Effective Abstention Mechanism

    [https://arxiv.org/abs/2402.12997](https://arxiv.org/abs/2402.12997)

    提出了一种适用于现实约束的轻量级弃权机制，特别适用于再排序阶段，通过数据驱动的方法达到有效性，并提供了开源代码以促进其更广泛的应用。

    

    神经信息检索（NIR）已经显著改进了基于启发式的IR系统。然而，失败仍然频繁发生，通常所使用的模型无法检索与用户查询相关的文档。我们通过提出一种适用于现实约束的轻量级弃权机制来解决这一挑战，特别强调再排序阶段。我们介绍了一个协议，用于在黑匣子场景中评估弃权策略的效果，并提出了一种简单但有效的数据驱动机制。我们提供了实验复制和弃权实施的开源代码，促进其在不同环境中更广泛的采用和应用。

    arXiv:2402.12997v1 Announce Type: cross  Abstract: Neural Information Retrieval (NIR) has significantly improved upon heuristic-based IR systems. Yet, failures remain frequent, the models used often being unable to retrieve documents relevant to the user's query. We address this challenge by proposing a lightweight abstention mechanism tailored for real-world constraints, with particular emphasis placed on the reranking phase. We introduce a protocol for evaluating abstention strategies in a black-box scenario, demonstrating their efficacy, and propose a simple yet effective data-driven mechanism. We provide open-source code for experiment replication and abstention implementation, fostering wider adoption and application in diverse contexts.
    
[^27]: LLatrieval：LLM-验证检索用于可验证生成

    LLatrieval: LLM-Verified Retrieval for Verifiable Generation

    [https://arxiv.org/abs/2311.07838](https://arxiv.org/abs/2311.07838)

    可验证生成中检索的文件不仅帮助LLM生成正确答案，还作为用户验证LLM输出的证据，但目前广泛使用的检索器已成为性能瓶颈，需要解决。

    

    可验证生成旨在使大型语言模型（LLM）生成具有支撑文件的文本，这使用户能够灵活验证答案，并使LLM的输出更可靠。检索在可验证生成中起着至关重要的作用。具体而言，检索到的文件不仅补充知识以帮助LLM生成正确答案，还作为支持用户验证LLM输出的证据。然而，广泛使用的检索器成为整个流程的瓶颈，并限制了整体性能。由于通常具有的参数比大型语言模型少得多，并且尚未证明能够良好地扩展到LLM的规模，因此它们的能力通常比LLMs差。如果检索器未能正确找到支持文件，则LLM将无法生成正确和可验证的答案，这会掩盖LLM的显著能力。为解决这些问

    arXiv:2311.07838v2 Announce Type: replace  Abstract: Verifiable generation aims to let the large language model (LLM) generate text with supporting documents, which enables the user to flexibly verify the answer and makes the LLM's output more reliable. Retrieval plays a crucial role in verifiable generation. Specifically, the retrieved documents not only supplement knowledge to help the LLM generate correct answers, but also serve as supporting evidence for the user to verify the LLM's output. However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. Their capabilities are usually inferior to LLMs since they often have much fewer parameters than the large language model and have not been demonstrated to scale well to the size of LLMs. If the retriever does not correctly find the supporting documents, the LLM can not generate the correct and verifiable answer, which overshadows the LLM's remarkable abilities. To address these li
    

