# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Fast Interactive Search with a Scale-Free Comparison Oracle.](http://arxiv.org/abs/2306.01814) | 该论文提出了一种基于比较的快速交互式搜索算法，其中使用了称为 $\gamma$-CKL 的刻度自由概率预言模型，并开发了一种具有指数收敛速度的搜索算法。 |
| [^2] | [Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes.](http://arxiv.org/abs/2306.01805) | 本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。 |
| [^3] | [Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in Ad Auctions.](http://arxiv.org/abs/2306.01799) | 本文提出了一种新的加权排名损失函数来训练CTR模型，以实现广告拍卖中的福利最大化，并且没有假设eCPM的先验分布，同时避免了朴素地应用现有学习排名方法的问题。 |
| [^4] | [Task Relation-aware Continual User Representation Learning.](http://arxiv.org/abs/2306.01792) | 本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。 |
| [^5] | [Beyond Rankings: Exploring the Impact of SERP Features on Organic Click-through Rates.](http://arxiv.org/abs/2306.01785) | 本研究探讨了SERP特征对点击率的影响，揭示SERP特征不仅是美学成分，而且强烈影响点击率和互联网用户的相关行为，能够显着调节网络流量。 |
| [^6] | [The Effect of News Article Quality on Ad Consumption.](http://arxiv.org/abs/2306.01781) | 本文研究了新闻文章对广告消费的影响，并展示了高质量文章与广告消费之间的相关性。 |
| [^7] | [Class Anchor Margin Loss for Content-Based Image Retrieval.](http://arxiv.org/abs/2306.00630) | 本论文提出一种新颖的斥力-吸引力损失函数，该函数位于度量学习范式中，可以直接优化L2度量，无需生成成对，在多个数据集上的实验表明，在检索准确性和效率方面，该方法优于现有技术。 |
| [^8] | [Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation.](http://arxiv.org/abs/2305.18885) | 本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。 |
| [^9] | [Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder.](http://arxiv.org/abs/2305.16304) | 本论文提出了一种使用两阶段模式结合预先计算图像嵌入和参考文本-候选项三元组交互选择的方式进行组合图像检索候选集重排序的方法。 |
| [^10] | [Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding.](http://arxiv.org/abs/2305.14449) | 一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。 |
| [^11] | [A First Look at LLM-Powered Generative News Recommendation.](http://arxiv.org/abs/2305.06566) | 本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。 |
| [^12] | [AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in Recommendations.](http://arxiv.org/abs/2304.04959) | AdaTT是一种适用于推荐系统的自适应任务融合深度网络模型，通过利用残差机制和门控机制实现任务之间的融合，自适应地学习共享知识和任务特定知识，在多个任务上可以显著优于现有的最先进基线模型。 |
| [^13] | [Continuous Input Embedding Size Search For Recommender Systems.](http://arxiv.org/abs/2304.03501) | 提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。 |
| [^14] | [ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics.](http://arxiv.org/abs/2302.01501) | ANTM是一种对齐的神经主题模型，它利用重叠滑动窗口算法来维护演变主题的时间连续性，并通过对语义相似的文档进行对齐来捕捉出现和消退的趋势。实验证明ANTM在主题连贯性和多样性方面优于传统动态主题模型。 |
| [^15] | [ExaRanker: Explanation-Augmented Neural Ranker.](http://arxiv.org/abs/2301.10521) | 本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。 |
| [^16] | [Towards Disentangling Relevance and Bias in Unbiased Learning to Rank.](http://arxiv.org/abs/2212.13937) | 该论文描述了在无偏学习排序中解离关联性和偏差性的重要性，并提出了对解决这个问题的三种方法。 |
| [^17] | [Multi-hop Evidence Retrieval for Cross-document Relation Extraction.](http://arxiv.org/abs/2212.10786) | 本文介绍了一个名为MR.COD的多跳证据检索方法，用于支持跨文档关系抽取。实验表明该方法有效地获取了跨文档证据，并提升了封闭和开放设置中的性能。 |
| [^18] | [Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender Systems.](http://arxiv.org/abs/2210.10629) | “Tenrec”是一个大规模多用途推荐系统基准数据集，包含约500万用户和1.4亿次交互，不仅具有积极的用户反馈，还有真正的负反馈，包含了各种类型的用户积极反馈，是一个综合性的基准数据集，可用于评估推荐系统模型的多个方面。 |
| [^19] | [Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search.](http://arxiv.org/abs/2209.05861) | 本文介绍了两种在线查询重写的范式：生成式（NLG）和密集检索（DR）方法。通过比较这两种方法并结合优势，提出了CLOVER-Unity模型，其NLG和DR组件始终优于单独训练的组件以及其他基线模型。 |
| [^20] | [LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval.](http://arxiv.org/abs/2208.14754) | LexMAE是一个新的预训练框架，用于学习重要性感知的词汇表示，在大规模信息检索中表现出了卓越的性能。 |
| [^21] | [UnifieR: A Unified Retriever for Large-Scale Retrieval.](http://arxiv.org/abs/2205.11194) | UnifieR是一个将PLM的密集向量和基于词汇表的检索统一到一个模型中的学习框架，在段落检索基准测试中证明了其有效性。 |
| [^22] | [Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems.](http://arxiv.org/abs/2204.01815) | 本文介绍了一种新的一致性方法来解决矩阵和张量补全问题，在推荐系统应用中，我们证明了通过保留单位比例和一致性两个约束条件可以实现解的存在性与唯一性。 |
| [^23] | [Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors.](http://arxiv.org/abs/2202.02830) | 我们使用概念激活向量来把用户描述商品的属性的语义表达出来，以改进推荐系统的效果。 |
| [^24] | [The hypergeometric test performs comparably to a common TF-IDF variant on standard information retrieval tasks.](http://arxiv.org/abs/2002.11844) | 本文实证研究表明，超几何检验在选定的真实数据文档检索和摘要任务中表现与常用的TF-IDF变体相当，这提供了TF-IDF长期有效性的统计显著性解释的第一步。 |

# 详细

[^1]: 基于比较的快速交互式搜索算法及其应用

    Fast Interactive Search with a Scale-Free Comparison Oracle. (arXiv:2306.01814v1 [cs.IR])

    [http://arxiv.org/abs/2306.01814](http://arxiv.org/abs/2306.01814)

    该论文提出了一种基于比较的快速交互式搜索算法，其中使用了称为 $\gamma$-CKL 的刻度自由概率预言模型，并开发了一种具有指数收敛速度的搜索算法。

    

    基于比较的搜索算法可以让用户通过回答“项 $i$ 和 $j$ 哪一个更接近 $t$？”的查询来在数据库中找到目标项 $t$ 。我们提出了一种称为 $\gamma$-CKL 的刻度自由概率预言模型，用于表示这种相似性三元组 $(i,j;t)$。这种模型在控制预言的区分能力和包含项的特征空间维度方面具有独立的优势。我们开发了一种搜索算法，证明了在 $\gamma$-CKL 模型下具有指数收敛速度。我们还评估了算法在几个真实三元组数据库上的性能。

    A comparison-based search algorithm lets a user find a target item $t$ in a database by answering queries of the form, ``Which of items $i$ and $j$ is closer to $t$?'' Instead of formulating an explicit query (such as one or several keywords), the user navigates towards the target via a sequence of such (typically noisy) queries.  We propose a scale-free probabilistic oracle model called $\gamma$-CKL for such similarity triplets $(i,j;t)$, which generalizes the CKL triplet model proposed in the literature. The generalization affords independent control over the discriminating power of the oracle and the dimension of the feature space containing the items.  We develop a search algorithm with provably exponential rate of convergence under the $\gamma$-CKL oracle, thanks to a backtracking strategy that deals with the unavoidable errors in updating the belief region around the target.  We evaluate the performance of the algorithm both over the posited oracle and over several real-world tri
    
[^2]: Cook-Gen：从食谱中生成健康烹饪动作的鲁棒性建模

    Cook-Gen: Robust Generative Modeling of Cooking Actions from Recipes. (arXiv:2306.01805v1 [cs.CL])

    [http://arxiv.org/abs/2306.01805](http://arxiv.org/abs/2306.01805)

    本文研究了使用生成AI方法来扩展当前的食品计算模型，将烹饪行为纳入考虑，以实现更全面的健康食谱推荐。

    

    随着人们越来越关注自己的饮食选择，食品计算模型在帮助人们保持健康饮食习惯方面变得越来越流行。例如，食品推荐系统分析食谱指令以评估营养成分并提供食谱推荐。而生成AI方法（如自回归大语言模型）的成功应用可以让我们更全面地理解食谱，从而实现更为健康全面的食谱推荐。本研究探讨使用生成AI方法来扩展当前的食品计算模型，从而将烹饪行为（例如加盐、煎肉、煮蔬菜等）纳入考虑。烹饪行为由于其不规则的数据模式而难以使用统计学习方法进行建模。

    As people become more aware of their food choices, food computation models have become increasingly popular in assisting people in maintaining healthy eating habits. For example, food recommendation systems analyze recipe instructions to assess nutritional contents and provide recipe recommendations. The recent and remarkable successes of generative AI methods, such as auto-regressive large language models, can lead to robust methods for a more comprehensive understanding of recipes for healthy food recommendations beyond surface-level nutrition content assessments. In this study, we explore the use of generative AI methods to extend current food computation models, primarily involving the analysis of nutrition and ingredients, to also incorporate cooking actions (e.g., add salt, fry the meat, boil the vegetables, etc.). Cooking actions are notoriously hard to model using statistical learning methods due to irregular data patterns - significantly varying natural language descriptions f
    
[^3]: 在广告拍卖中通过点击率预测来实现福利最大化的成对排名损失函数

    Pairwise Ranking Losses of Click-Through Rates Prediction for Welfare Maximization in Ad Auctions. (arXiv:2306.01799v1 [cs.GT])

    [http://arxiv.org/abs/2306.01799](http://arxiv.org/abs/2306.01799)

    本文提出了一种新的加权排名损失函数来训练CTR模型，以实现广告拍卖中的福利最大化，并且没有假设eCPM的先验分布，同时避免了朴素地应用现有学习排名方法的问题。

    

    本文研究了设计点击率（CTR）损失函数以在广告拍卖中优化（社会）福利。现有的研究要么只关注于CTR预测，而没有考虑广告拍卖中的业务目标（例如福利），要么假设参与者期望每次展示费用（eCPM）的分布是先验已知的，然后使用各种附加假设来推导用于预测CTR的损失函数。在这项工作中，我们将广告拍卖的福利目标带回CTR预测中，并提出了一种新型的加权排名损失函数来训练CTR模型。与现有文献相比，我们的方法在不假设eCPM分布的情况下提供了对福利的可证明保证，同时避免了朴素地应用现有学习排名方法时的棘手问题。此外，我们提出了一种在“老师网络”生成标签的情况下使用校准损失的理论可证明技术。

    We study the design of loss functions for click-through rates (CTR) to optimize (social) welfare in advertising auctions. Existing works either only focus on CTR predictions without consideration of business objectives (e.g., welfare) in auctions or assume that the distribution over the participants' expected cost-per-impression (eCPM) is known a priori, then use various additional assumptions on the parametric form of the distribution to derive loss functions for predicting CTRs. In this work, we bring back the welfare objectives of ad auctions into CTR predictions and propose a novel weighted rankloss to train the CTR model. Compared to existing literature, our approach provides a provable guarantee on welfare but without assumptions on the eCPMs' distribution while also avoiding the intractability of naively applying existing learning-to-rank methods. Further, we propose a theoretically justifiable technique for calibrating the losses using labels generated from a teacher network, o
    
[^4]: 任务关系感知的持续用户表示学习

    Task Relation-aware Continual User Representation Learning. (arXiv:2306.01792v1 [cs.IR])

    [http://arxiv.org/abs/2306.01792](http://arxiv.org/abs/2306.01792)

    本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。

    

    用户建模是基于其过去行为学习将用户表示为低维表示空间的方法，它受到了工业界提供个性化服务的兴趣激增。以往的用户建模工作主要集中在学习为单一任务而设计的任务特定用户表示上。然而，由于为每个任务学习任务特定用户表示是不可行的，因此最近的研究引入了通用用户表示的概念，即与多种任务相关的更广义用户表示。尽管这些方法非常有效，但由于数据需求、灾难性遗忘以及为持续添加的任务提供有限的学习能力，现有的学习通用用户表示的方法在实际应用中是不切实际的。本文提出了一种新颖的持续用户表示学习方法TERACON，其学习能力不受任务数量限制。

    User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number 
    
[^5]: 超越排名：探索SERP特征对有机点击率的影响。

    Beyond Rankings: Exploring the Impact of SERP Features on Organic Click-through Rates. (arXiv:2306.01785v1 [cs.IR])

    [http://arxiv.org/abs/2306.01785](http://arxiv.org/abs/2306.01785)

    本研究探讨了SERP特征对点击率的影响，揭示SERP特征不仅是美学成分，而且强烈影响点击率和互联网用户的相关行为，能够显着调节网络流量。

    

    搜索引擎结果页面（SERP）作为通往广阔互联网世界的数字门户。过去几十年以网站排名为中心的研究主要集中在这些页面上，以确定点击率（CTR）。然而，在这段时间内，SERP的景观发生了戏剧性的演变：SERP特征，包括知识面板、媒体画廊、常见问题解答等元素，已经成为这些结果页面中越来越突出的方面。我们的研究研究了这些特征的关键作用，揭示它们不仅是美学成分，而且强烈影响点击率和互联网用户的相关行为。我们展示了这些特征如何显着调节网络流量，无论是放大还是减弱它。我们使用涵盖40个不同美国电子商务领域的67,000个关键字及其相应的Google SERPs的独特数据集，分析了这些复杂的交互作用效应。

    Search Engine Result Pages (SERPs) serve as the digital gateways to the vast expanse of the internet. Past decades have witnessed a surge in research primarily centered on the influence of website ranking on these pages, to determine the click-through rate (CTR). However, during this period, the landscape of SERPs has undergone a dramatic evolution: SERP features, encompassing elements such as knowledge panels, media galleries, FAQs, and more, have emerged as an increasingly prominent facet of these result pages. Our study examines the crucial role of these features, revealing them to be not merely aesthetic components, but strongly influence CTR and the associated behavior of internet users. We demonstrate how these features can significantly modulate web traffic, either amplifying or attenuating it. We dissect these intricate interaction effects leveraging a unique dataset of 67,000 keywords and their respective Google SERPs, spanning over 40 distinct US-based e-commerce domains, gen
    
[^6]: 新闻文章质量对广告消费的影响

    The Effect of News Article Quality on Ad Consumption. (arXiv:2306.01781v1 [cs.IR])

    [http://arxiv.org/abs/2306.01781](http://arxiv.org/abs/2306.01781)

    本文研究了新闻文章对广告消费的影响，并展示了高质量文章与广告消费之间的相关性。

    

    实用的新闻平台会生成一系列新闻文章和广告内容，但往往独立地优化文章和广告的位置。然而，如我们所示，在考虑彼此影响的情况下进行排版非常重要，因为新闻文章会极大地影响用户对广告的行为。本文研究了新闻文章对用户广告消费的影响，并展示了新闻与广告效果之间的相关性。我们进行了服务日志分析，并展示了与高质量新闻文章接触的会话比低质量新闻文章接触的会话拥有更多的广告消费。基于此结果，我们假设接触高质量文章将导致更高的广告消费率。因此，我们进行了千万级别的A/B测试，以研究高质量文章对广告消费的影响，其中我们优先考虑高质量文章。

    Practical news feed platforms generate a hybrid list of news articles and advertising items (e.g., products, services, or information) and many platforms optimize the position of news articles and advertisements independently. However, they should be arranged with careful consideration of each other, as we show in this study, since user behaviors toward advertisements are significantly affected by the news articles. This paper investigates the effect of news articles on users' ad consumption and shows the dependency between news and ad effectiveness. We conducted a service log analysis and showed that sessions with high-quality news article exposure had more ad consumption than those with low-quality news article exposure. Based on this result, we hypothesized that exposure to high-quality articles will lead to a high ad consumption rate. Thus, we conducted million-scale A/B testing to investigate the effect of high-quality articles on ad consumption, in which we prioritized high-quali
    
[^7]: 基于内容的图像检索的类锚点边距损失

    Class Anchor Margin Loss for Content-Based Image Retrieval. (arXiv:2306.00630v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.00630](http://arxiv.org/abs/2306.00630)

    本论文提出一种新颖的斥力-吸引力损失函数，该函数位于度量学习范式中，可以直接优化L2度量，无需生成成对，在多个数据集上的实验表明，在检索准确性和效率方面，该方法优于现有技术。

    

    神经网络在内容为基础的图像检索（CBIR）中的性能受所选的损失（目标）函数的影响很大。神经模型的大多数目标函数可以分为度量学习和统计学习两类。度量学习方法需要成对挖掘策略，这往往缺乏效率，而统计学习方法由于其间接特征优化而无法生成高度压缩的特征。为此，我们提出了一种新颖的斥力-吸引力损失函数，位于度量学习范式中，却可以直接优化L2度量，无需生成成对。我们的损失由三个组成部分组成。一个主要目标确保学习到的特征被吸引到各自指定的可学习类锚点。第二个损失组分对锚点进行调节，强制它们相互之间有一定间隔，而第三个目标确保锚点不会崩溃为零。此外，我们开发了一种更高效的变体，它不需要计算完整的成对距离矩阵。我们在多个数据集上的实验表明，我们提出的损失在检索准确性和效率方面优于现有技术。

    The performance of neural networks in content-based image retrieval (CBIR) is highly influenced by the chosen loss (objective) function. The majority of objective functions for neural models can be divided into metric learning and statistical learning. Metric learning approaches require a pair mining strategy that often lacks efficiency, while statistical learning approaches are not generating highly compact features due to their indirect feature optimization. To this end, we propose a novel repeller-attractor loss that falls in the metric learning paradigm, yet directly optimizes for the L2 metric without the need of generating pairs. Our loss is formed of three components. One leading objective ensures that the learned features are attracted to each designated learnable class anchor. The second loss component regulates the anchors and forces them to be separable by a margin, while the third objective ensures that the anchors do not collapse to zero. Furthermore, we develop a more eff
    
[^8]: 标准比评分更重要：面向多准则推荐的标准偏好感知轻量图卷积网络

    Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation. (arXiv:2305.18885v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2305.18885](http://arxiv.org/abs/2305.18885)

    本文提出了一种面向多准则推荐的标准偏好感知轻量图卷积网络，该方法结合了MC扩展图，可以准确地捕捉用户的标准偏好，并进一步将用户对各个标准的偏好合并到最终的推荐列表中。

    

    多准则推荐系统现在在广泛的电子商务领域中利用多准则 (MC) 评分信息，而深度学习中的图神经网络 (GNN) 已经被广泛应用于各种推荐系统的开发中。在这种情况下，本文首次尝试使用GNN辅助设计MC推荐系统。具体而言，我们提出了一种新颖的标准偏好感知轻量图卷积方法(CPA-LGC),可以准确捕捉用户的标准偏好以及复杂高阶连接中的协作信号。本文在MC扩展图上构建了一个能够将用户-物品MC评分转换为扩展二分图的MC扩展图，再进一步将标准重要性编码到图卷积过程中，并引入了一种新的标准偏好感知聚合方法来将用户对不同标准的偏好合并到最终的推荐列表中。

    The multi-criteria (MC) recommender system, which leverages MC rating information in a wide range of e-commerce areas, is ubiquitous nowadays. Surprisingly, although graph neural networks (GNNs) have been widely applied to develop various recommender systems due to GNN's high expressive capability in learning graph representations, it has been still unexplored how to design MC recommender systems with GNNs. In light of this, we make the first attempt towards designing a GNN-aided MC recommender system. Specifically, rather than straightforwardly adopting existing GNN-based recommendation methods, we devise a novel criteria preference-aware light graph convolution CPA-LGC method, which is capable of precisely capturing the criteria preference of users as well as the collaborative signal in complex high-order connectivities. To this end, we first construct an MC expansion graph that transforms user--item MC ratings into an expanded bipartite graph to potentially learn from the collaborat
    
[^9]: 具有双多模态编码器的组合图像检索候选集重排序

    Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder. (arXiv:2305.16304v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16304](http://arxiv.org/abs/2305.16304)

    本论文提出了一种使用两阶段模式结合预先计算图像嵌入和参考文本-候选项三元组交互选择的方式进行组合图像检索候选集重排序的方法。

    

    组合图像检索旨在找到最匹配给定多模态用户查询(包括参考图像和文本对)的图像。现有方法通常预先计算整个语料库的图像嵌入，并在测试时将这些嵌入与经过查询文本修改的参考图像嵌入进行比较。然而，仅通过短文本描述引导修改参考图像嵌入可能很困难，特别是独立于潜在的候选项。一种替代方法是允许查询和每个可能的候选项之间的交互，即参考文本-候选项三元组，并从整个集合中选择最佳匹配。虽然这种方法更具有判别性，但对于大规模数据集，由于不能预先计算候选嵌入，因此计算成本是禁止性的。我们提出使用两阶段模式结合这两个方案的优点

    Composed image retrieval aims to find an image that best matches a given multi-modal user query consisting of a reference image and text pair. Existing methods commonly pre-compute image embeddings over the entire corpus and compare these to a reference image embedding modified by the query text at test time. Such a pipeline is very efficient at test time since fast vector distances can be used to evaluate candidates, but modifying the reference image embedding guided only by a short textual description can be difficult, especially independent of potential candidates. An alternative approach is to allow interactions between the query and every possible candidate, i.e., reference-text-candidate triplets, and pick the best from the entire set. Though this approach is more discriminative, for large-scale datasets the computational cost is prohibitive since pre-computation of candidate embeddings is no longer possible. We propose to combine the merits of both schemes using a two-stage mode
    
[^10]: 图谱遇见LLM：一种用于稳健对话理解的协同过滤新方法

    Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding. (arXiv:2305.14449v1 [cs.AI])

    [http://arxiv.org/abs/2305.14449](http://arxiv.org/abs/2305.14449)

    一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。

    

    会话式人工智能系统（例如Alexa，Siri，Google Assistant等）需要理解存在缺陷的查询以确保稳健的会话理解并减少用户摩擦。这些有缺陷的查询通常是由用户的歧义和错误，自动语音识别（ASR）和自然语言理解（NLU）中的错误引起的。个性化查询重写（个性化QR）旨在减少身体和尾部用户查询流量中的缺陷，通常依赖于与对话式人工智能的过去成功的用户交互的索引。本文提出我们的“协同查询重写”方法，专注于重写用户历史中没有出现过的新型用户交互。该方法构建了一个“用户反馈交互图”（FIG），由历史用户-实体交互组成，并利用多跳客户亲和力来丰富每个用户的索引（即协同用户索引），从而帮助覆盖未来未曾见过的存在缺陷的查询。为了防止这些新的丰富索引被噪声反馈交互所支配，我们采用了有限内存BFGS（LLM）算法和回退方案来调整每个索引的权重。实验结果表明，我们的方法明显优于最先进的个性化QR方法，并在未看到的用户交互上取得了近乎完美的性能。

    Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU).  Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a "user Feedback Interaction Graph" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract th
    
[^11]: LLM驱动的生成式新闻推荐初探

    A First Look at LLM-Powered Generative News Recommendation. (arXiv:2305.06566v1 [cs.IR])

    [http://arxiv.org/abs/2305.06566](http://arxiv.org/abs/2305.06566)

    本文介绍了一种LLM驱动的生成式新闻推荐框架GENRE，它利用预训练语义知识丰富新闻数据，通过从模型设计转移到提示设计提供灵活而统一的解决方案，实现了个性化新闻生成、用户画像和新闻摘要。

    

    个性化的新闻推荐系统已成为用户浏览海量在线新闻内容所必需的工具，然而现有的新闻推荐系统面临着冷启动问题、用户画像建模和新闻内容理解等重大挑战。先前的研究通常通过模型设计遵循一种不灵活的例行程序来解决特定的挑战，但在理解新闻内容和捕捉用户兴趣方面存在局限性。在本文中，我们介绍了GENRE，一种LLM驱动的生成式新闻推荐框架，它利用来自大型语言模型的预训练语义知识来丰富新闻数据。我们的目标是通过从模型设计转移到提示设计来提供一种灵活而统一的新闻推荐解决方案。我们展示了GENRE在个性化新闻生成、用户画像和新闻摘要中的应用。使用各种流行的推荐模型进行的大量实验证明了GENRE的有效性。

    Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding. Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests. In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data. Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design. We showcase the use of GENRE for personalized news generation, user profiling, and news summarization. Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE. 
    
[^12]: AdaTT: 自适应任务融合网络用于多任务学习推荐系统

    AdaTT: Adaptive Task-to-Task Fusion Network for Multitask Learning in Recommendations. (arXiv:2304.04959v1 [cs.IR])

    [http://arxiv.org/abs/2304.04959](http://arxiv.org/abs/2304.04959)

    AdaTT是一种适用于推荐系统的自适应任务融合深度网络模型，通过利用残差机制和门控机制实现任务之间的融合，自适应地学习共享知识和任务特定知识，在多个任务上可以显著优于现有的最先进基线模型。

    

    多任务学习旨在通过同时在多个任务上训练机器学习模型来提高性能和效率。然而，多任务学习面临两个挑战：1）对任务之间的关系进行建模，以有效地共享知识；2）联合学习任务特定和共享知识。本文介绍了一种新型的自适应任务融合网络（AdaTT）来解决这两个挑战。AdaTT是一个深度融合网络，在多个级别上使用任务特定和可选共享融合单元构建。通过利用残差机制和门控机制实现任务之间的融合，这些单元自适应地学习共享知识和任务特定知识。为了评估AdaTT的性能，我们在公共基准测试集和工业级推荐数据集上使用不同的任务组进行实验。结果表明，AdaTT可以显著优于现有的最先进基线模型。

    Multi-task learning (MTL) aims at enhancing the performance and efficiency of machine learning models by training them on multiple tasks simultaneously. However, MTL research faces two challenges: 1) modeling the relationships between tasks to effectively share knowledge between them, and 2) jointly learning task-specific and shared knowledge. In this paper, we present a novel model Adaptive Task-to-Task Fusion Network (AdaTT) to address both challenges. AdaTT is a deep fusion network built with task specific and optional shared fusion units at multiple levels. By leveraging a residual mechanism and gating mechanism for task-to-task fusion, these units adaptively learn shared knowledge and task specific knowledge. To evaluate the performance of AdaTT, we conduct experiments on a public benchmark and an industrial recommendation dataset using various task groups. Results demonstrate AdaTT can significantly outperform existing state-of-the-art baselines.
    
[^13]: 推荐系统的连续输入嵌入大小搜索

    Continuous Input Embedding Size Search For Recommender Systems. (arXiv:2304.03501v1 [cs.IR])

    [http://arxiv.org/abs/2304.03501](http://arxiv.org/abs/2304.03501)

    提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。

    

    潜在因子模型是现今推荐系统最流行的基础，其性能卓越。潜在因子模型通过对用户和项目进行表示，用于对成对相似度的计算。所有嵌入向量传统上都被限制在一个相对较大的统一大小（例如256维）。随着当代电子商务中用户和项目目录指数级增长，这种设计显然变得效率低下。为了促进轻量级推荐，强化学习（RL）最近开辟了一些机会，用于识别不同用户/项目的不同嵌入大小。然而，受到搜索效率和学习最优RL策略的限制，现有的基于RL的方法被限制为高度离散的预定义嵌入大小选项。这导致了一个被广泛忽视的潜力，可以在给定计算预算下引入更细的粒度来获得更好的推荐效果。在本文中，我们提出了一种新方法，称为CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索。CONTINUOUS通过将嵌入大小选择建模为连续变量和制定可微优化问题的形式来解决之前工作的挑战。在三个基准数据集上的实验证实了CONTINUOUS优于基线的优越性，验证了动态优化嵌入大小的有效性和高效性。

    Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a giv
    
[^14]: ANTM: 一种对齐的神经主题模型，用于探索演变的主题

    ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics. (arXiv:2302.01501v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.01501](http://arxiv.org/abs/2302.01501)

    ANTM是一种对齐的神经主题模型，它利用重叠滑动窗口算法来维护演变主题的时间连续性，并通过对语义相似的文档进行对齐来捕捉出现和消退的趋势。实验证明ANTM在主题连贯性和多样性方面优于传统动态主题模型。

    

    本文提出了一种称为对齐神经主题模型（ANTM）的动态主题模型算法家族，它结合了新颖的数据挖掘算法，提供了一个模块化框架，用于发现演变的主题。ANTM利用先进的预训练大型语言模型从文档中提取时间感知特征，并使用重叠滑动窗口算法进行顺序文档聚类，从而维护了演变主题的时间连续性。这种重叠滑动窗口算法在每个时间框架内标识不同数量的主题，并在时间段内对语义相似的文档聚类进行对齐。这个过程捕捉了不同时期出现和消退的趋势，并允许更具可解释性的演变主题表示。针对四个不同数据集的实验表明，ANTM在主题连贯性和多样性指标方面优于概率动态主题模型。此外，它改善了动态主题建模的可扩展性和灵活性。

    This paper presents an algorithmic family of dynamic topic models called Aligned Neural Topic Models (ANTM), which combine novel data mining algorithms to provide a modular framework for discovering evolving topics. ANTM maintains the temporal continuity of evolving topics by extracting time-aware features from documents using advanced pre-trained Large Language Models (LLMs) and employing an overlapping sliding window algorithm for sequential document clustering. This overlapping sliding window algorithm identifies a different number of topics within each time frame and aligns semantically similar document clusters across time periods. This process captures emerging and fading trends across different periods and allows for a more interpretable representation of evolving topics. Experiments on four distinct datasets show that ANTM outperforms probabilistic dynamic topic models in terms of topic coherence and diversity metrics. Moreover, it improves the scalability and flexibility of dy
    
[^15]: ExaRanker: 解释增强型神经排序模型

    ExaRanker: Explanation-Augmented Neural Ranker. (arXiv:2301.10521v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10521](http://arxiv.org/abs/2301.10521)

    本文提出了一个名为ExaRanker的解释增强型神经排序模型，使用大型语言模型增强检索数据集，可在输出相关度标签与解释时提高性能。

    

    最近的研究表明，让大型语言模型在输出答案前生成解释是提高各种推理任务性能的有效策略。本文提出神经排序模型也受益于解释。我们使用GPT-3.5等语言模型来增强具有解释的检索数据集，并训练一个序列到序列的排序模型，以输出给定查询-文档对的相关度标签和解释。我们的模型被称为ExaRanker，在使用合成解释的几千个样本进行微调后，性能与无解释的3倍样本微调的模型相当。此外，ExaRanker模型在排序过程中没有额外的计算成本，并允许根据需要请求解释。

    Recent work has shown that inducing a large language model (LLM) to generate explanations prior to outputting an answer is an effective strategy to improve performance on a wide range of reasoning tasks. In this work, we show that neural rankers also benefit from explanations. We use LLMs such as GPT-3.5 to augment retrieval datasets with explanations and train a sequence-to-sequence ranking model to output a relevance label and an explanation for a given query-document pair. Our model, dubbed ExaRanker, finetuned on a few thousand examples with synthetic explanations performs on par with models finetuned on 3x more examples without explanations. Furthermore, the ExaRanker model incurs no additional computational cost during ranking and allows explanations to be requested on demand.
    
[^16]: 在无偏学习排序中解离关联性和偏差性的追求

    Towards Disentangling Relevance and Bias in Unbiased Learning to Rank. (arXiv:2212.13937v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.13937](http://arxiv.org/abs/2212.13937)

    该论文描述了在无偏学习排序中解离关联性和偏差性的重要性，并提出了对解决这个问题的三种方法。

    

    无偏学习排序(ULTR)研究的问题在于从隐含的用户反馈数据（如点击）中减轻各种偏差性的影响，并且最近受到了相当大的关注。一种用于实际应用的流行ULTR方法是使用双塔结构，其中将点击建模分解为一个具有常规输入特征的关联塔和一个具有偏差相关输入（如文件位置）的偏差塔。成功的分解将允许关联塔免受偏差的影响。在这项工作中，我们发现了现有ULTR方法忽略的一个关键问题——通过底层真实关联性，偏差塔可能会与关联塔混淆。特别是，位置是由记录策略（即以前的生产模型）确定的，它将具有关联信息。我们给出了理论分析和实证结果，以展示由于这种相关性对于关联塔的负面影响。然后，我们提出了三种方法来解决这个问题。

    Unbiased learning to rank (ULTR) studies the problem of mitigating various biases from implicit user feedback data such as clicks, and has been receiving considerable attention recently. A popular ULTR approach for real-world applications uses a two-tower architecture, where click modeling is factorized into a relevance tower with regular input features, and a bias tower with bias-relevant inputs such as the position of a document. A successful factorization will allow the relevance tower to be exempt from biases. In this work, we identify a critical issue that existing ULTR methods ignored - the bias tower can be confounded with the relevance tower via the underlying true relevance. In particular, the positions were determined by the logging policy, i.e., the previous production model, which would possess relevance information. We give both theoretical analysis and empirical results to show the negative effects on relevance tower due to such a correlation. We then propose three method
    
[^17]: 跨文档关系抽取的多跳证据检索

    Multi-hop Evidence Retrieval for Cross-document Relation Extraction. (arXiv:2212.10786v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10786](http://arxiv.org/abs/2212.10786)

    本文介绍了一个名为MR.COD的多跳证据检索方法，用于支持跨文档关系抽取。实验表明该方法有效地获取了跨文档证据，并提升了封闭和开放设置中的性能。

    

    关系抽取(RE)已经扩展到跨文档场景中，因为许多关系不仅仅在一个文档中描述。这不可避免地带来了有效的开放空间证据检索的挑战，以支持跨文档关系的推断，同时也带来了多跳推理的挑战，以处理散布在开放式文档集中的实体和证据。为了应对这些挑战，我们提出了MR.COD(跨文档关系抽取的多跳证据检索)，这是一种基于证据路径挖掘和排序的多跳证据检索方法。我们探索了多个检索器的变体，以显示证据检索在跨文档RE中的重要性。我们还为此设置提出了一种上下文密集的检索器。在CodRED上的实验表明，MR.COD的证据检索有效地获取了跨文档证据，并提升了封闭和开放设置中的端到端RE性能。

    Relation Extraction (RE) has been extended to cross-document scenarios because many relations are not simply described in a single document. This inevitably brings the challenge of efficient open-space evidence retrieval to support the inference of cross-document relations, along with the challenge of multi-hop reasoning on top of entities and evidence scattered in an open set of documents. To combat these challenges, we propose MR.COD (Multi-hop evidence retrieval for Cross-document relation extraction), which is a multi-hop evidence retrieval method based on evidence path mining and ranking. We explore multiple variants of retrievers to show evidence retrieval is essential in cross-document RE. We also propose a contextual dense retriever for this setting. Experiments on CodRED show that evidence retrieval with MR.COD effectively acquires crossdocument evidence and boosts end-to-end RE performance in both closed and open settings.
    
[^18]: Tenrec: 一种大规模多用途推荐系统基准数据集

    Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender Systems. (arXiv:2210.10629v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.10629](http://arxiv.org/abs/2210.10629)

    “Tenrec”是一个大规模多用途推荐系统基准数据集，包含约500万用户和1.4亿次交互，不仅具有积极的用户反馈，还有真正的负反馈，包含了各种类型的用户积极反馈，是一个综合性的基准数据集，可用于评估推荐系统模型的多个方面。

    

    现有的推荐系统基准数据集要么规模较小，要么只涉及非常有限形式的用户反馈。在这篇论文中，我们介绍了一个全新的、公开可用的推荐系统数据集“Tenrec”，记录了来自四种不同推荐场景的各种用户反馈。具体而言，Tenrec 具有以下五个特点：(1)它是大规模的，包含约 500 万用户和 1.4 亿次交互;(2)它不仅具有积极的用户反馈，还有真正的负反馈;(3)它包含了四个不同场景中的重叠用户和项目;(4)它包含了各种类型的用户积极反馈，以点击、喜欢、分享和关注等形式展现;(5)它还包含了用户 ID 和项目 ID 以外的其他特征。我们运行了多种最先进的推荐系统模型来验证 Tenrec，结果展示了 Tenrec 对推荐系统模型的挑战，以及其实际潜力。Tenrec 可以作为一个综合性的基准数据集，评估推荐系统模型的各个方面，如推荐质量、反馈预测、数据稀疏性、迁移学习和多样性促进等。

    Existing benchmark datasets for recommender systems (RS) either are created at a small scale or involve very limited forms of user feedback. RS models evaluated on such datasets often lack practical values for large-scale real-world applications. In this paper, we describe Tenrec, a novel and publicly available data collection for RS that records various user feedback from four different recommendation scenarios. To be specific, Tenrec has the following five characteristics: (1) it is large-scale, containing around 5 million users and 140 million interactions; (2) it has not only positive user feedback, but also true negative feedback (vs. one-class recommendation); (3) it contains overlapped users and items across four different scenarios; (4) it contains various types of user positive feedback, in forms of clicks, likes, shares, and follows, etc; (5) it contains additional features beyond the user IDs and item IDs. We verify Tenrec on ten diverse recommendation tasks by running sever
    
[^19]: 联合生成与密集检索用于赞助搜索的查询重写

    Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search. (arXiv:2209.05861v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2209.05861](http://arxiv.org/abs/2209.05861)

    本文介绍了两种在线查询重写的范式：生成式（NLG）和密集检索（DR）方法。通过比较这两种方法并结合优势，提出了CLOVER-Unity模型，其NLG和DR组件始终优于单独训练的组件以及其他基线模型。

    

    赞助搜索是搜索引擎的一个关键收入来源，广告主通过竞价方式针对用户或感兴趣的搜索查询竞标关键字。然而，由于关键字空间庞大且动态变化、模糊的用户/广告主意图以及各种可能的主题和语言，找到与给定查询相关的关键字非常具有挑战性。本文介绍了在线查询重写的两种范式：生成式（NLG）和密集检索（DR）方法之间的全面比较。我们观察到两种方法都提供了互补的且可相加的优势。因此，我们展示了由这两种方法检索到的高质量关键字中有约40%是独特的，而另一种方法没有找到。为了发挥两种方法的优势，我们提出了CLOVER-Unity，这是一种将生成式与密集检索方法结合在一个模型中的新方法。通过离线实验，我们展示了CLOVER-Unity的NLG和DR组件始终优于单独训练的NLG和DR组件以及其他强基线模型，具有检索到关键字的相关性和多样性。

    Sponsored search is a key revenue source for search engines, where advertisers bid on keywords to target users or search queries of interest. However, finding relevant keywords for a given query is challenging due to the large and dynamic keyword space, ambiguous user/advertiser intents, and diverse possible topics and languages. In this work, we present a comprehensive comparison between two paradigms for online query rewriting: Generative (NLG) and Dense Retrieval (DR) methods. We observe that both methods offer complementary benefits that are additive. As a result, we show that around 40% of the high-quality keywords retrieved by the two approaches are unique and not retrieved by the other. To leverage the strengths of both methods, we propose CLOVER-Unity, a novel approach that unifies generative and dense retrieval methods in one single model. Through offline experiments, we show that the NLG and DR components of CLOVER-Unity consistently outperform individually trained NLG and DR
    
[^20]: LexMAE：用于大规模检索的词汇限制预训练

    LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval. (arXiv:2208.14754v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2208.14754](http://arxiv.org/abs/2208.14754)

    LexMAE是一个新的预训练框架，用于学习重要性感知的词汇表示，在大规模信息检索中表现出了卓越的性能。

    

    在大规模检索中，利用词汇权重范例，学习在词汇空间中的加权稀疏表示，显示出了高质量和低延迟的有前途的结果。为了填补语言建模和词汇加权检索之间的巨大差距，我们提出了一种全新的预训练框架，LexMAE，用于学习重要性感知的词汇表示。这一框架通过加入一个词汇瓶颈模块，将普通的语言模型编码器和弱化的解码器之间加入了一个连续词袋瓶颈，以实现无监督学习词汇重要性分布。预训练后的LexMAE已经表现出了在大规模信息检索中的卓越性能。

    In large-scale retrieval, the lexicon-weighting paradigm, learning weighted sparse representations in vocabulary space, has shown promising results with high quality and low latency. Despite it deeply exploiting the lexicon-representing capability of pre-trained language models, a crucial gap remains between language modeling and lexicon-weighting retrieval -- the former preferring certain or low-entropy words whereas the latter favoring pivot or high-entropy words -- becoming the main barrier to lexicon-weighting performance for large-scale retrieval. To bridge this gap, we propose a brand-new pre-training framework, lexicon-bottlenecked masked autoencoder (LexMAE), to learn importance-aware lexicon representations. Essentially, we present a lexicon-bottlenecked module between a normal language modeling encoder and a weakened decoder, where a continuous bag-of-words bottleneck is constructed to learn a lexicon-importance distribution in an unsupervised fashion. The pre-trained LexMAE 
    
[^21]: 统一检索器：大规模检索的统一检索器

    UnifieR: A Unified Retriever for Large-Scale Retrieval. (arXiv:2205.11194v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.11194](http://arxiv.org/abs/2205.11194)

    UnifieR是一个将PLM的密集向量和基于词汇表的检索统一到一个模型中的学习框架，在段落检索基准测试中证明了其有效性。

    

    大规模检索是指在给定查询的情况下从大量文档中召回相关文档。它依赖于表征学习，将文档和查询嵌入到一个共同的语义编码空间中。根据编码空间，基于预训练语言模型（PLM）的最近检索方法可以粗略地分为密集向量或基于词汇表的范例。这两种范例在不同粒度的全局序列级压缩和局部单词级上下文中展现了PLMs的表征能力。受到它们互补的全局局部上下文化和不同的代表视角的启发，我们提出了一个新的学习框架，统一检索器，它将密集向量和基于词汇表的检索统一到一个模型中，具有双重表示能力。对段落检索基准的实验验证了它在两个范例中的有效性。进一步提出了更好的检索质量的uni-retrieval方案。最后，我们评估了该模型。

    Large-scale retrieval is to recall relevant documents from a huge collection given a query. It relies on representation learning to embed documents and queries into a common semantic encoding space. According to the encoding space, recent retrieval methods based on pre-trained language models (PLM) can be coarsely categorized into either dense-vector or lexicon-based paradigms. These two paradigms unveil the PLMs' representation capability in different granularities, i.e., global sequence-level compression and local word-level contexts, respectively. Inspired by their complementary global-local contextualization and distinct representing views, we propose a new learning framework, UnifieR which unifies dense-vector and lexicon-based retrieval in one model with a dual-representing capability. Experiments on passage retrieval benchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme is further presented with even better retrieval quality. We lastly evaluate the model 
    
[^22]: 具有可证明的一致性和公平保证的推荐系统张量补全

    Tensor Completion with Provable Consistency and Fairness Guarantees for Recommender Systems. (arXiv:2204.01815v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2204.01815](http://arxiv.org/abs/2204.01815)

    本文介绍了一种新的一致性方法来解决矩阵和张量补全问题，在推荐系统应用中，我们证明了通过保留单位比例和一致性两个约束条件可以实现解的存在性与唯一性。

    

    我们引入了一种新的基于一致性的方法来定义和解决非负/正矩阵和张量补全问题。该框架的新颖之处在于，我们不是人为地将问题形式化为任意优化问题，例如，最小化一个结构量，如秩或范数，而是展示了一个单一的属性/约束：保留单位比例一致性，保证了解的存在，并在相对较弱的支持假设下保证了解的唯一性。该框架和解算法也直接推广到任意维度的张量中，同时保持了固定维度 d 的问题规模的线性计算复杂性。在推荐系统应用中，我们证明了两个合理的性质，这些性质应该适用于任何 RS 问题的解，足以允许在我们的框架内建立唯一性保证。关键理论贡献是展示了这些约束下解的存在性与唯一性。

    We introduce a new consistency-based approach for defining and solving nonnegative/positive matrix and tensor completion problems. The novelty of the framework is that instead of artificially making the problem well-posed in the form of an application-arbitrary optimization problem, e.g., minimizing a bulk structural measure such as rank or norm, we show that a single property/constraint: preserving unit-scale consistency, guarantees the existence of both a solution and, under relatively weak support assumptions, uniqueness. The framework and solution algorithms also generalize directly to tensors of arbitrary dimensions while maintaining computational complexity that is linear in problem size for fixed dimension d. In the context of recommender system (RS) applications, we prove that two reasonable properties that should be expected to hold for any solution to the RS problem are sufficient to permit uniqueness guarantees to be established within our framework. Key theoretical contribu
    
[^23]: 使用概念激活向量在推荐系统中发现软属性的个性化语义

    Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors. (arXiv:2202.02830v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2202.02830](http://arxiv.org/abs/2202.02830)

    我们使用概念激活向量来把用户描述商品的属性的语义表达出来，以改进推荐系统的效果。

    

    交互式推荐系统已经成为一种有前途的范例，以克服传统推荐系统所使用的原始用户反馈的局限性（例如点击、项目消费、评分）。它们允许用户以更丰富的方式表达意图、偏好、约束和上下文，通常使用自然语言（包括分类搜索和对话）。然而，需要更多的研究来找到使用这些反馈的最有效方法。一个挑战是从经常用于描述所需项目的开放式术语或属性中推断用户的语义意图，并使用它来改进推荐结果。利用最近在机器学习中开发的模型可解释性方法——概念激活向量（CAVs），我们开发了一个框架，在推荐系统中学习一种表示，捕捉这些属性的语义，并将它们连接到用户的偏好和行为中。我们方法的一个新功能是它能够区分

    Interactive recommender systems have emerged as a promising paradigm to overcome the limitations of the primitive user feedback used by traditional recommender systems (e.g., clicks, item consumption, ratings). They allow users to express intent, preferences, constraints, and contexts in a richer fashion, often using natural language (including faceted search and dialogue). Yet more research is needed to find the most effective ways to use this feedback. One challenge is inferring a user's semantic intent from the open-ended terms or attributes often used to describe a desired item, and using it to refine recommendation results. Leveraging concept activation vectors (CAVs) [26], a recently developed approach for model interpretability in machine learning, we develop a framework to learn a representation that captures the semantics of such attributes and connects them to user preferences and behaviors in recommender systems. One novel feature of our approach is its ability to distinguis
    
[^24]: 超几何检验在标准信息检索任务中表现与TF-IDF变体相当

    The hypergeometric test performs comparably to a common TF-IDF variant on standard information retrieval tasks. (arXiv:2002.11844v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2002.11844](http://arxiv.org/abs/2002.11844)

    本文实证研究表明，超几何检验在选定的真实数据文档检索和摘要任务中表现与常用的TF-IDF变体相当，这提供了TF-IDF长期有效性的统计显著性解释的第一步。

    

    词频-逆文档频率（TF-IDF）及其许多变体形成了一类常用的术语加权函数，在信息检索应用中被广泛使用。虽然TF-IDF最初是一种启发式方法，但已经提出了基于信息理论、概率和与随机性背离的范式的理论证明。在本文中，我们展示了一项实证研究，表明在选定的真实数据文档检索和摘要任务中，超几何检验的统计显著性与常用的TF-IDF变体非常接近。这些发现表明TF-IDF变体与超几何检验P值的负对数（即超几何分布尾概率）之间存在根本的数学连结有待阐明。我们在此提供实证案例研究，作为从统计显著性角度解释TF-IDF长期有效性的第一步。

    Term frequency-inverse document frequency, or tf-idf for short, and its many variants form a class of term weighting functions the members of which are widely used in information retrieval applications. While tf-idf was originally proposed as a heuristic, theoretical justifications grounded in information theory, probability, and the divergence from randomness paradigm have been advanced. In this work, we present an empirical study showing that the hypergeometric test of statistical significance corresponds very nearly with a common tf-idf variant on selected real-data document retrieval and summarization tasks. These findings suggest that a fundamental mathematical connection between the tf-idf variant and the negative logarithm of the hypergeometric test P-value (i.e., a hypergeometric distribution tail probability) remains to be elucidated. We offer the empirical case study herein as a first step toward explaining the long-standing effectiveness of tf-idf from a statistical signific
    

