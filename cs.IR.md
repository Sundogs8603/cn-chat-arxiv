# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks.](http://arxiv.org/abs/2308.10028) | 提出了一种基于图神经网络的提示式微调框架VPGNN，用于促销券滥用检测。通过设计新颖的图提示函数，将下游任务重构为与预训练中的预文本任务类似的模板，从而缩小了目标差距。在实验中展示了VPGNN在少样本和半监督情况下的强大性能，并在生产环境中实现了23.4%的性能改进。 |
| [^2] | [Explicit Time Embedding Based Cascade Attention Network for Information Popularity Prediction.](http://arxiv.org/abs/2308.09976) | 这篇论文提出了一种显式时间嵌入的级联注意力网络，用于预测信息流行度。该网络通过时间嵌入方法将时间属性融入节点特征中，然后采用级联图注意力编码器和级联序列注意力编码器来充分学习级联图和级联序列的表示。 |
| [^3] | [Time-aligned Exposure-enhanced Model for Click-Through Rate Prediction.](http://arxiv.org/abs/2308.09966) | 这项研究提出了一种用于点击率预测的新框架TEM4CTR，通过时间对齐和信息传递机制来提高预测准确性。 |
| [^4] | [printf: Preference Modeling Based on User Reviews with Item Images and Textual Information via Graph Learning.](http://arxiv.org/abs/2308.09943) | 本文提出了printf方法，通过图学习基于用户评论、物品图像和文本信息来建模偏好，以解决现代推荐系统中文本和图像特征捕捉不足的问题。 |
| [^5] | [RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models.](http://arxiv.org/abs/2308.09904) | 提出了一个人类中心的推荐框架RAH，利用大型语言模型（LLMs）作为助手，实现用户满意度和个性化反馈，并成功应用于学习用户个性和调整推荐系统。 |
| [^6] | [Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method.](http://arxiv.org/abs/2308.09861) | 本文针对密集检索模型提出了一种黑盒对抗攻击方法，旨在欺骗模型检索到初始候选文档集范围之外的目标文档。 |
| [^7] | [Taken by Surprise: Contrast effect for Similarity Scores.](http://arxiv.org/abs/2308.09765) | 提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。 |
| [^8] | [Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification.](http://arxiv.org/abs/2308.09308) | 本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。 |
| [^9] | [Natural Language is All a Graph Needs.](http://arxiv.org/abs/2308.07134) | 本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。 |
| [^10] | [Adaptive Preferential Attached kNN Graph With Distribution-Awareness.](http://arxiv.org/abs/2308.02442) | 本文提出了一种名为paNNG的算法，它结合了自适应kNN和基于分布的图构建。通过包含分布信息，paNNG能够有效提升模糊样本的性能，并实现更好的准确性和泛化能力。 |
| [^11] | [Optimal Bandwidth Selection for DENCLUE.](http://arxiv.org/abs/2307.03206) | 本文提出了一种计算DENCLUE算法最优参数的新方法，并在实验部分讨论了其性能。 |
| [^12] | [OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents.](http://arxiv.org/abs/2306.16527) | OBELISC是一个开放的网页规模筛选图像文本数据集，包含141亿个网页，3.53亿个图像和1150亿个文本标记。通过在此数据集上训练一个80亿参数的模型，取得了在多模态基准测试中有竞争力的性能。 |
| [^13] | [Scalable Neural Contextual Bandit for Recommender Systems.](http://arxiv.org/abs/2306.14834) | 本研究提出了一种可扩展的神经上下文Bandit算法，通过设计Epistemic Neural Recommendation (ENR)网络结构，实现了大规模的Thompson抽样，显著提高了推荐系统的点击率和用户评分。 |
| [^14] | [CompMix: A Benchmark for Heterogeneous Question Answering.](http://arxiv.org/abs/2306.12235) | CompMix是一个异构问答系统的基准测试，有多个信息源和复杂意图，旨在提供公平的评估QA系统的能力。 |
| [^15] | [Task Relation-aware Continual User Representation Learning.](http://arxiv.org/abs/2306.01792) | 本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。 |
| [^16] | [FARA: Future-aware Ranking Algorithm for Fairness Optimization.](http://arxiv.org/abs/2305.16637) | FARA是一种未来感知的公平优化排名算法，可以通过联合优化多个排名列表并将其保存到未来的会话中，同时最小化公平性和相关性差异。实验证明，FARA在排名相关性和公平性方面优于现有算法。 |
| [^17] | [Zero-Shot Composed Image Retrieval with Textual Inversion.](http://arxiv.org/abs/2303.15247) | 提出了零样本组合图像检索任务(ZS-CIR)，通过将视觉特征映射到CLIP令牌嵌入空间中的伪词标记并与相对标题集成，解决了不需要标记训练数据集的组合图像检索问题。引入了名为CIRCO的开放域基准数据集，该数据集是第一个包含每个查询的多个真实答案的CIR数据集。实验结果表明，SEARLE具有更好的性能。 |
| [^18] | [Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation.](http://arxiv.org/abs/2302.14640) | 该论文提出了一种用于解决不平衡冷启动推荐问题的元学习算法，通过自适应加权损失来适应用户的个性化需求。 |
| [^19] | [RECOMED: A Comprehensive Pharmaceutical Recommendation System.](http://arxiv.org/abs/2301.00280) | RECOMED是基于患者和药物特征设计的一种综合性药物推荐系统，采用人工智能模型和自然语言处理方法进行实现，首次考虑了患者条件和历史来选择合适药物，以及药物相互作用。 |
| [^20] | [A Profit-Maximizing Strategy for Advertising on the e-Commerce Platforms.](http://arxiv.org/abs/2211.01160) | 本文提出了一种针对在线广告定向选项的最大化利润策略，通过将优化问题重新定义为多选背包问题，找到最佳特征组合以增加将定向受众转化为实际购买者的概率。 |
| [^21] | [FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for CTR Prediction.](http://arxiv.org/abs/2209.05016) | FiBiNet++通过引入低秩特征交互层，成功减小了FiBiNet模型大小，并在三个公共数据集上实现了12倍至16倍的参数减小，同时显著提高了性能。 |

# 详细

[^1]: 基于图神经网络的促销券滥用检测中的提示式微调研究

    Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks. (arXiv:2308.10028v1 [cs.IR])

    [http://arxiv.org/abs/2308.10028](http://arxiv.org/abs/2308.10028)

    提出了一种基于图神经网络的提示式微调框架VPGNN，用于促销券滥用检测。通过设计新颖的图提示函数，将下游任务重构为与预训练中的预文本任务类似的模板，从而缩小了目标差距。在实验中展示了VPGNN在少样本和半监督情况下的强大性能，并在生产环境中实现了23.4%的性能改进。

    

    促销券滥用检测是电子商务中重要的异常检测问题。虽然出现了许多基于图神经网络的解决方案，但监督式范式取决于大量标记数据。一个常见的替代方案是采用自监督预训练使用无标签数据，并在有限标签的下游任务上进一步微调。然而，“预训练，微调”范式常常受到预训练和下游任务之间目标差距的困扰。因此，我们提出了VPGNN，一种基于GNN的提示式微调框架用于促销券滥用检测。我们设计了一个新颖的图提示函数，将下游任务重构成与预训练中的预文本任务类似的模板，从而缩小了目标差距。在专有和公共数据集上进行的大量实验证明了VPGNN在少样本和半监督情况下的优势。此外，在生产环境中在线部署VPGNN显示出23.4%的性能改进。

    Voucher abuse detection is an important anomaly detection problem in E-commerce. While many GNN-based solutions have emerged, the supervised paradigm depends on a large quantity of labeled data. A popular alternative is to adopt self-supervised pre-training using label-free data, and further fine-tune on a downstream task with limited labels. Nevertheless, the "pre-train, fine-tune" paradigm is often plagued by the objective gap between pre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based fine-tuning framework on GNNs for voucher abuse detection. We design a novel graph prompting function to reformulate the downstream task into a similar template as the pretext task in pre-training, thereby narrowing the objective gap. Extensive experiments on both proprietary and public datasets demonstrate the strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover, an online deployment of VPGNN in a production environment shows a 23.4% improvement over two ex
    
[^2]: 显式时间嵌入的级联注意力网络用于信息流行度预测

    Explicit Time Embedding Based Cascade Attention Network for Information Popularity Prediction. (arXiv:2308.09976v1 [cs.SI])

    [http://arxiv.org/abs/2308.09976](http://arxiv.org/abs/2308.09976)

    这篇论文提出了一种显式时间嵌入的级联注意力网络，用于预测信息流行度。该网络通过时间嵌入方法将时间属性融入节点特征中，然后采用级联图注意力编码器和级联序列注意力编码器来充分学习级联图和级联序列的表示。

    

    在社交网络中，预测信息级联的流行度是一个基本问题。捕捉时间属性和级联角色信息（如级联图和级联序列）对于理解信息级联是必要的。当前的方法很少关注将这些信息统一起来进行流行度预测，这使得它们无法有效地对级联的全部属性进行建模，以实现令人满意的预测性能。在本文中，我们提出了一种显式的基于时间嵌入的级联注意力网络(TCAN)作为一种针对大规模信息网络的新型流行度预测架构。TCAN通过一种通用的时间嵌入方法(TC)将时间属性（周期性、线性和非线性缩放）融入节点特征中，然后采用级联图注意力编码器(CGAT)和级联序列注意力编码器(CSAT)来充分学习级联图和级联序列的表示。

    Predicting information cascade popularity is a fundamental problem in social networks. Capturing temporal attributes and cascade role information (e.g., cascade graphs and cascade sequences) is necessary for understanding the information cascade. Current methods rarely focus on unifying this information for popularity predictions, which prevents them from effectively modeling the full properties of cascades to achieve satisfactory prediction performances. In this paper, we propose an explicit Time embedding based Cascade Attention Network (TCAN) as a novel popularity prediction architecture for large-scale information networks. TCAN integrates temporal attributes (i.e., periodicity, linearity, and non-linear scaling) into node features via a general time embedding approach (TE), and then employs a cascade graph attention encoder (CGAT) and a cascade sequence attention encoder (CSAT) to fully learn the representation of cascade graphs and cascade sequences. We use two real-world dataset
    
[^3]: 时间对齐增强模型用于点击率预测

    Time-aligned Exposure-enhanced Model for Click-Through Rate Prediction. (arXiv:2308.09966v1 [cs.IR])

    [http://arxiv.org/abs/2308.09966](http://arxiv.org/abs/2308.09966)

    这项研究提出了一种用于点击率预测的新框架TEM4CTR，通过时间对齐和信息传递机制来提高预测准确性。

    

    点击率预测在推荐系统和在线广告等应用中至关重要，它基于用户点击的可能性对项目进行排序。用户行为序列建模在点击率预测中取得了进展，它从用户的历史行为序列中提取潜在兴趣，以实现准确的点击率预测。最近的研究探索使用隐式反馈序列（例如未点击的记录）来提取多样化的用户兴趣。然而，这些方法面临两个关键挑战：1）由于序列时间范围不同而导致的时间错位，以及2）缺乏对反馈序列之间的细粒度交互的建模。为了解决这些挑战，我们提出了一种新颖的框架TEM4CTR，该框架确保序列之间的时间对齐，同时利用辅助反馈信息通过表示投影机制增强项目级的点击行为。此外，该基于投影的信息传递模块可以更**/

    Click-Through Rate (CTR) prediction, crucial in applications like recommender systems and online advertising, involves ranking items based on the likelihood of user clicks. User behavior sequence modeling has marked progress in CTR prediction, which extracts users' latent interests from their historical behavior sequences to facilitate accurate CTR prediction. Recent research explores using implicit feedback sequences, like unclicked records, to extract diverse user interests. However, these methods encounter key challenges: 1) temporal misalignment due to disparate sequence time ranges and 2) the lack of fine-grained interaction among feedback sequences. To address these challenges, we propose a novel framework called TEM4CTR, which ensures temporal alignment among sequences while leveraging auxiliary feedback information to enhance click behavior at the item level through a representation projection mechanism. Moreover, this projection-based information transfer module can effectivel
    
[^4]: printf:基于用户评论和物品图像与文本信息的偏好建模的图学习方法

    printf: Preference Modeling Based on User Reviews with Item Images and Textual Information via Graph Learning. (arXiv:2308.09943v1 [cs.IR])

    [http://arxiv.org/abs/2308.09943](http://arxiv.org/abs/2308.09943)

    本文提出了printf方法，通过图学习基于用户评论、物品图像和文本信息来建模偏好，以解决现代推荐系统中文本和图像特征捕捉不足的问题。

    

    现代推荐系统通常利用文本和视觉内容作为辅助信息来预测用户偏好。对于文本信息来说，评论文本是建模用户行为的最受欢迎内容之一。然而，在仅使用文本评论作为特征的前N个推荐系统中，评论通常失去了它们的亮点，因为它们很难充分捕捉用户和物品之间的交互关系。对于视觉信息，通常会使用简单的卷积网络来建模，但很难捕捉用户和物品之间的高阶关系。此外，以前的工作没有合理地共同使用文本和图像。本文提出了基于图学习的printf，即基于用户评论与物品图像和文本信息的偏好建模，以解决上述挑战。具体而言，基于维度的注意力机制指导用户评论和交互项之间的关系，所有部分共同学习以更好地建模用户偏好。

    Nowadays, modern recommender systems usually leverage textual and visual contents as auxiliary information to predict user preference. For textual information, review texts are one of the most popular contents to model user behaviors. Nevertheless, reviews usually lose their shine when it comes to top-N recommender systems because those that solely utilize textual reviews as features struggle to adequately capture the interaction relationships between users and items. For visual one, it is usually modeled with naive convolutional networks and also hard to capture high-order relationships between users and items. Moreover, previous works did not collaboratively use both texts and images in a proper way. In this paper, we propose printf, preference modeling based on user reviews with item images and textual information via graph learning, to address the above challenges. Specifically, the dimension-based attention mechanism directs relations between user reviews and interacted items, all
    
[^5]: RAH！RecSys-Assistant-Human：一个具有大型语言模型的人类中心推荐框架

    RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models. (arXiv:2308.09904v1 [cs.IR])

    [http://arxiv.org/abs/2308.09904](http://arxiv.org/abs/2308.09904)

    提出了一个人类中心的推荐框架RAH，利用大型语言模型（LLMs）作为助手，实现用户满意度和个性化反馈，并成功应用于学习用户个性和调整推荐系统。

    

    推荐生态系统涉及到推荐系统（计算机）和用户（人类）之间的交互。与推荐系统的角度不同，我们尝试从用户的角度利用大型语言模型（LLMs），并提出一个更加人类中心的推荐框架，命名为RAH。该框架包括推荐系统、助手和人类。助手是一个基于LLMs的个人代理，用于实现用户满意度。助手扮演非侵入性的角色，RAH框架可以适应不同的推荐系统和用户群体。随后，我们实现并评估了RAH框架，用于学习用户个性和代理人类反馈。实验表明：（1）使用学习-行动-评论家和反思机制可以导致更加一致的个性，（2）我们的助手可以有效地代理人类反馈并帮助调整推荐系统。最后，我们讨论了在RAH框架中进一步解决人类中心问题的策略，包括用户``夺权''等问题。

    The recommendation ecosystem involves interactions between recommender systems(Computer) and users(Human). Orthogonal to the perspective of recommender systems, we attempt to utilize LLMs from the perspective of users and propose a more human-central recommendation framework named RAH, which consists of Recommender system, Assistant and Human. The assistant is a LLM-based and personal proxy for a human to achieve user satisfaction. The assistant plays a non-invasion role and the RAH framework can adapt to different recommender systems and user groups. Subsequently, we implement and evaluate the RAH framework for learning user personalities and proxy human feedback. The experiment shows that (1) using learn-action-critic and reflection mechanisms can lead more aligned personality and (2) our assistant can effectively proxy human feedback and help adjust recommender systems. Finally, we discuss further strategies in the RAH framework to address human-central concerns including user contr
    
[^6]: 黑盒对抗攻击针对密集检索模型：一种多视角对比学习方法

    Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method. (arXiv:2308.09861v1 [cs.IR])

    [http://arxiv.org/abs/2308.09861](http://arxiv.org/abs/2308.09861)

    本文针对密集检索模型提出了一种黑盒对抗攻击方法，旨在欺骗模型检索到初始候选文档集范围之外的目标文档。

    

    神经排名模型（NRMs）和密集检索（DR）模型在整体检索性能方面取得了重大改进。除了它们的有效性之外，由于深度学习方法在其他领域的鲁棒性已被证明不足，对于核心检索问题的深度学习方法的鲁棒性越来越引起人们的兴趣。到目前为止，所开发的对抗攻击方法主要集中在攻击NRMs上，对DR模型的抗性鲜有关注。本文介绍了对抗检索攻击（AREA）任务。AREA任务旨在欺骗DR模型，使其在响应查询时从最初检索候选文档集之外检索到目标文档。我们考虑了基于决策的黑盒对抗设置，这在实际搜索引擎中是现实的。为了解决AREA任务，我们首先采用现有的为NRMs设计的对抗攻击方法。

    Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for N
    
[^7]: 受冷落: 相似度分数的反差效应

    Taken by Surprise: Contrast effect for Similarity Scores. (arXiv:2308.09765v1 [cs.CL])

    [http://arxiv.org/abs/2308.09765](http://arxiv.org/abs/2308.09765)

    提出了一种新的相似度度量方法，称为“惊喜分数”，该方法能够考虑对象的上下文信息并显著提高零样本和少样本文档分类任务的性能。

    

    准确评估物体向量嵌入的相似度对于自然语言处理、信息检索和分类任务至关重要。流行的相似度分数（如余弦相似度）基于嵌入向量对，并忽略了从中提取对象的分布。人类对物体相似度的感知显著取决于对象出现的上下文。在这项工作中，我们提出了“惊喜分数”，这是一个对整体进行归一化的相似度度量，包括了人类感知的反差效应，并显著提高了零样本和少样本文档分类任务的性能。此分数量化了在两个元素之间找到给定相似度的惊喜，相对于成对的整体相似度。我们在零样本/少样本分类和聚类任务上评估了这个度量，通常发现与原始余弦相似度相比，性能提高了10-15\%。我们的代码...

    Accurately evaluating the similarity of object vector embeddings is of critical importance for natural language processing, information retrieval and classification tasks. Popular similarity scores (e.g cosine similarity) are based on pairs of embedding vectors and disregard the distribution of the ensemble from which objects are drawn. Human perception of object similarity significantly depends on the context in which the objects appear. In this work we propose the \emph{surprise score}, an ensemble-normalized similarity metric that encapsulates the contrast effect of human perception and significantly improves the classification performance on zero- and few-shot document classification tasks. This score quantifies the surprise to find a given similarity between two elements relative to the pairwise ensemble similarities. We evaluate this metric on zero/few shot classification and clustering tasks and typically find 10-15\% better performance compared to raw cosine similarity. Our cod
    
[^8]: 可微检索增强通过生成式语言建模的电子商务查询意图分类

    Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification. (arXiv:2308.09308v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2308.09308](http://arxiv.org/abs/2308.09308)

    本研究提出了一种可微的检索增强方法，通过生成式语言建模，在电子商务查询意图分类任务中显著提升了性能，解决了检索器和下游模型之间的不可微性问题。

    

    检索增强通过使用知识检索器和外部语料库来增强下游模型，而不仅仅是增加模型参数的数量，在许多自然语言处理（NLP）任务中，如文本分类、问题回答等方面已经取得了成功。然而，由于两个部分之间的不可微性，现有方法通常通过分别或异步训练检索器和下游模型来导致性能下降，与端到端联合训练相比。在本文中，我们提出了Differentiable Retrieval Augmentation via Generative lANguage modeling（Dragan），通过一种新颖的可微重构来解决这个问题。我们在电子商务搜索中的一个有挑战性的NLP任务上展示了我们提出的方法的有效性，即查询意图分类。实验结果和消融研究均表明，所提出的方法显著且合理地改进了最先进的基准模型。

    Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training. In this paper, we propose Differentiable Retrieval Augmentation via Generative lANguage modeling(Dragan), to address this problem by a novel differentiable reformulation. We demonstrate the effectiveness of our proposed method on a challenging NLP task in e-commerce search, namely query intent classification. Both the experimental results and ablation study show that the proposed method significantly and reasonably improves the state-of-the-art basel
    
[^9]: 自然语言是图表所需要的全部内容

    Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07134](http://arxiv.org/abs/2308.07134)

    本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。

    

    大规模预训练语言模型的出现，如ChatGPT，已经在人工智能的各个研究领域中引起了革命。基于Transformer的大型语言模型（LLMs）逐渐取代了CNN和RNN，将计算机视觉和自然语言处理领域统一起来。与相对独立存在的数据（如图像、视频或文本）相比，图表是一种包含丰富结构和关系信息的数据类型。同时，作为最具表现力的媒介之一，自然语言在描述复杂结构方面表现出色。然而，将图表学习问题纳入生成式语言建模框架的现有工作仍然非常有限。随着大型语言模型的重要性不断增长，探索LLMs是否也可以替代GNNs成为图表的基础模型变得至关重要。在本文中，我们提出了InstructGLM（结构化语言模型）算法，系统地设计高度可扩展的模型来处理图表学习问题。

    The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
    
[^10]: 使用分布感知的自适应优先级附加kNN图

    Adaptive Preferential Attached kNN Graph With Distribution-Awareness. (arXiv:2308.02442v1 [cs.LG])

    [http://arxiv.org/abs/2308.02442](http://arxiv.org/abs/2308.02442)

    本文提出了一种名为paNNG的算法，它结合了自适应kNN和基于分布的图构建。通过包含分布信息，paNNG能够有效提升模糊样本的性能，并实现更好的准确性和泛化能力。

    

    基于图的kNN算法因其简单性和有效性在机器学习任务中广受欢迎。然而，传统的kNN图对于k值的固定依赖可能会影响其性能，特别是在涉及复杂数据分布的情况下。此外，与其他分类模型类似，决策边界上存在的模糊样本常常是一个挑战，因为它们更容易被错误分类。为了解决这些问题，我们提出了优先级附加k-最近邻图（paNNG），它将自适应的kNN与基于分布的图构建相结合。通过结合分布信息，paNNG可以显著提高模糊样本的性能，通过“拉”它们回到原始类别，从而实现改进的整体准确性和泛化能力。通过在多样化的基准数据集上进行严格评估，paNNG的性能超越了现有算法，展示了它的优越性。

    Graph-based kNN algorithms have garnered widespread popularity for machine learning tasks, due to their simplicity and effectiveness. However, the conventional kNN graph's reliance on a fixed value of k can hinder its performance, especially in scenarios involving complex data distributions. Moreover, like other classification models, the presence of ambiguous samples along decision boundaries often presents a challenge, as they are more prone to incorrect classification. To address these issues, we propose the Preferential Attached k-Nearest Neighbors Graph (paNNG), which combines adaptive kNN with distribution-based graph construction. By incorporating distribution information, paNNG can significantly improve performance for ambiguous samples by "pulling" them towards their original classes and hence enable enhanced overall accuracy and generalization capability. Through rigorous evaluations on diverse benchmark datasets, paNNG outperforms state-of-the-art algorithms, showcasing its 
    
[^11]: DENCLUE的最优带宽选择

    Optimal Bandwidth Selection for DENCLUE. (arXiv:2307.03206v1 [cs.LG])

    [http://arxiv.org/abs/2307.03206](http://arxiv.org/abs/2307.03206)

    本文提出了一种计算DENCLUE算法最优参数的新方法，并在实验部分讨论了其性能。

    

    在现代工业中，聚类算法是算法工程师的日常工作。尽管在2010年之前，聚类算法经历了快速增长，但在深度学习成为机器学习应用的实际工业标准之后，与该研究主题相关的创新停滞不前。2007年，提出了一种名为DENCLUE的基于密度的聚类算法，用于解决非线性数据结构的聚类问题。然而，直到2011年，该算法的参数选择问题仍然被大部分忽视。本文提出了一种计算DENCLUE算法最优参数的新方法，并在实验部分讨论了其性能。

    In modern day industry, clustering algorithms are daily routines of algorithm engineers. Although clustering algorithms experienced rapid growth before 2010. Innovation related to the research topic has stagnated after deep learning became the de facto industrial standard for machine learning applications. In 2007, a density-based clustering algorithm named DENCLUE was invented to solve clustering problem for nonlinear data structures. However, its parameter selection problem was largely neglected until 2011. In this paper, we propose a new approach to compute the optimal parameters for the DENCLUE algorithm, and discuss its performance in the experiment section.
    
[^12]: OBELISC：一个开放的网页规模筛选图像文档数据集

    OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents. (arXiv:2306.16527v1 [cs.IR])

    [http://arxiv.org/abs/2306.16527](http://arxiv.org/abs/2306.16527)

    OBELISC是一个开放的网页规模筛选图像文本数据集，包含141亿个网页，3.53亿个图像和1150亿个文本标记。通过在此数据集上训练一个80亿参数的模型，取得了在多模态基准测试中有竞争力的性能。

    

    在要求对一个或多个图片进行推理生成文本的各种多模态基准测试中，基于自然文档的大规模多模态模型（图像与文本交错）的表现优于基于图像-文本对训练的模型。然而，用于训练这些模型的数据集尚未发布，并且收集过程尚未完全明确。我们介绍了OBELISC数据集，一个由141亿个从Common Crawl提取的网页，3.53亿个相关图像和1150亿个文本标记组成的开放式网页规模筛选的图像文本交错的数据集。我们描述了数据集的创建过程，提供了全面的过滤规则，并对数据集的内容进行了分析。为了展示OBELISC的可行性，我们在数据集上训练了一个80亿参数的视觉和语言模型，并在各种多模态基准测试中获得了有竞争力的性能。我们发布了用于重现数据集的代码以及数据集本身。

    Large multimodal models trained on natural documents, which interleave images and text, outperform models trained on image-text pairs on various multimodal benchmarks that require reasoning over one or multiple images to generate a text. However, the datasets used to train these models have not been released, and the collection process has not been fully specified. We introduce the OBELISC dataset, an open web-scale filtered dataset of interleaved image-text documents comprising 141 million web pages extracted from Common Crawl, 353 million associated images, and 115 billion text tokens. We describe the dataset creation process, present comprehensive filtering rules, and provide an analysis of the dataset's content. To show the viability of OBELISC, we train an 80 billion parameters vision and language model on the dataset and obtain competitive performance on various multimodal benchmarks. We release the code to reproduce the dataset along with the dataset itself.
    
[^13]: 可扩展的神经上下文推荐系统中的Bandit算法

    Scalable Neural Contextual Bandit for Recommender Systems. (arXiv:2306.14834v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.14834](http://arxiv.org/abs/2306.14834)

    本研究提出了一种可扩展的神经上下文Bandit算法，通过设计Epistemic Neural Recommendation (ENR)网络结构，实现了大规模的Thompson抽样，显著提高了推荐系统的点击率和用户评分。

    

    高质量的推荐系统应通过与用户的有效和探索性互动提供创新和相关内容。然而，许多现有推荐系统中基于监督学习的神经网络仅利用已识别的用户兴趣，对于有效发现未知用户偏好存在不足。尽管神经上下文Bandit算法在通过神经网络实现在线探索方面取得了一些进展，但他们对计算的要求较高，限制了它在实际推荐系统中的广泛应用。在本研究中，我们提出了一种可扩展的样本效率高的神经上下文Bandit算法用于推荐系统。为此，我们设计了一种认知神经网络架构，Epistemic Neural Recommendation (ENR)，它能够在大规模上实现Thompson抽样。通过两个不同的真实任务的大规模实验，ENR显著提高了点击率和用户评分。

    High-quality recommender systems ought to deliver both innovative and relevant content through effective and exploratory interactions with users. Yet, supervised learning-based neural networks, which form the backbone of many existing recommender systems, only leverage recognized user interests, falling short when it comes to efficiently uncovering unknown user preferences. While there has been some progress with neural contextual bandit algorithms towards enabling online exploration through neural networks, their onerous computational demands hinder widespread adoption in real-world recommender systems. In this work, we propose a scalable sample-efficient neural contextual bandit algorithm for recommender systems. To do this, we design an epistemic neural network architecture, Epistemic Neural Recommendation (ENR), that enables Thompson sampling at a large scale. In two distinct large-scale experiments with real-world tasks, ENR significantly boosts click-through rates and user rating
    
[^14]: CompMix: 一种异构问答系统的基准测试

    CompMix: A Benchmark for Heterogeneous Question Answering. (arXiv:2306.12235v1 [cs.IR])

    [http://arxiv.org/abs/2306.12235](http://arxiv.org/abs/2306.12235)

    CompMix是一个异构问答系统的基准测试，有多个信息源和复杂意图，旨在提供公平的评估QA系统的能力。

    

    事实为中心的问答系统经常需要访问多种异构信息源。通过共同考虑多个信息源，如知识库、文本收集和来自网络的表格，问答系统可以增强其答案覆盖范围和可信度。然而，现有的 QA 基准测试大多是为了构建单一的知识资源而设计的。这限制了这些基准测试的能力，无法公平地评估可以利用多个信息库的 QA 系统。为了弥补这一差距，我们发布了 CompMix，这是一种由众包问答构建的基准测试，自然地要求集成多种输入源。CompMix 共有 9,410 个问题，并具有多个复杂意图，如连接和时间条件。在 CompMix 上评估一系列 QA 系统强调了进一步研究利用异构信息源的必要性。

    Fact-centric question answering (QA) often requires access to multiple, heterogeneous, information sources. By jointly considering several sources like a knowledge base (KB), a text collection, and tables from the web, QA systems can enhance their answer coverage and confidence. However, existing QA benchmarks are mostly constructed with a single source of knowledge in mind. This limits capabilities of these benchmarks to fairly evaluate QA systems that can tap into more than one information repository. To bridge this gap, we release CompMix, a crowdsourced QA benchmark which naturally demands the integration of a mixture of input sources. CompMix has a total of 9,410 questions, and features several complex intents like joins and temporal conditions. Evaluation of a range of QA systems on CompMix highlights the need for further research on leveraging information from heterogeneous sources.
    
[^15]: 任务关系感知的持续用户表示学习

    Task Relation-aware Continual User Representation Learning. (arXiv:2306.01792v1 [cs.IR])

    [http://arxiv.org/abs/2306.01792](http://arxiv.org/abs/2306.01792)

    本文提出了一种新的持续用户表示学习方法TERACON，它能够学习通用的用户表示，而不是为每个任务学习任务特定的用户表示，具有很强的实用性和学习能力。

    

    用户建模是基于其过去行为学习将用户表示为低维表示空间的方法，它受到了工业界提供个性化服务的兴趣激增。以往的用户建模工作主要集中在学习为单一任务而设计的任务特定用户表示上。然而，由于为每个任务学习任务特定用户表示是不可行的，因此最近的研究引入了通用用户表示的概念，即与多种任务相关的更广义用户表示。尽管这些方法非常有效，但由于数据需求、灾难性遗忘以及为持续添加的任务提供有限的学习能力，现有的学习通用用户表示的方法在实际应用中是不切实际的。本文提出了一种新颖的持续用户表示学习方法TERACON，其学习能力不受任务数量限制。

    User modeling, which learns to represent users into a low-dimensional representation space based on their past behaviors, got a surge of interest from the industry for providing personalized services to users. Previous efforts in user modeling mainly focus on learning a task-specific user representation that is designed for a single task. However, since learning task-specific user representations for every task is infeasible, recent studies introduce the concept of universal user representation, which is a more generalized representation of a user that is relevant to a variety of tasks. Despite their effectiveness, existing approaches for learning universal user representations are impractical in real-world applications due to the data requirement, catastrophic forgetting and the limited learning capability for continually added tasks. In this paper, we propose a novel continual user representation learning method, called TERACON, whose learning capability is not limited as the number 
    
[^16]: FARA: 未来感知的公平优化排名算法

    FARA: Future-aware Ranking Algorithm for Fairness Optimization. (arXiv:2305.16637v1 [cs.IR])

    [http://arxiv.org/abs/2305.16637](http://arxiv.org/abs/2305.16637)

    FARA是一种未来感知的公平优化排名算法，可以通过联合优化多个排名列表并将其保存到未来的会话中，同时最小化公平性和相关性差异。实验证明，FARA在排名相关性和公平性方面优于现有算法。

    

    排名系统是现代信息检索应用（例如搜索引擎和推荐系统）的关键组件。除了与用户相关的排名相关性外，向项目提供者公平的曝光度也被认为是排名优化的重要因素。许多公平排名算法已被提出以联合优化排名相关性和公平性。然而，我们发现大多数现有的公平排名方法采用贪心算法，仅针对下一个即时会话或请求优化排名。正如本文所示，这种短视的范式可能限制排名优化的上限，并导致长期的次优性能。为此，我们提出了FARA，一种新颖的未来感知排名算法，用于排名相关性和公平优化。FARA不是贪婪地优化下一个会话的排名，而是通过联合优化多个排名列表并将它们保存到未来会话中，来提前规划。特别地，FARA旨在最小化排名列表的公平性和相关性差异，并考虑未来会话对当前排名的影响。我们在真实世界数据集上的实验证明，FARA在排名相关性和公平性方面优于现有的公平排名算法。

    Ranking systems are the key components of modern Information Retrieval (IR) applications, such as search engines and recommender systems. Besides the ranking relevance to users, the exposure fairness to item providers has also been considered an important factor in ranking optimization. Many fair ranking algorithms have been proposed to jointly optimize both ranking relevance and fairness. However, we find that most existing fair ranking methods adopt greedy algorithms that only optimize rankings for the next immediate session or request. As shown in this paper, such a myopic paradigm could limit the upper bound of ranking optimization and lead to suboptimal performance in the long term. To this end, we propose FARA, a novel Future-Aware Ranking Algorithm for ranking relevance and fairness optimization. Instead of greedily optimizing rankings for the next immediate session, FARA plans ahead by jointly optimizing multiple ranklists together and saving them for future sessions. Particula
    
[^17]: 零样本组合图像检索与文本反转

    Zero-Shot Composed Image Retrieval with Textual Inversion. (arXiv:2303.15247v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15247](http://arxiv.org/abs/2303.15247)

    提出了零样本组合图像检索任务(ZS-CIR)，通过将视觉特征映射到CLIP令牌嵌入空间中的伪词标记并与相对标题集成，解决了不需要标记训练数据集的组合图像检索问题。引入了名为CIRCO的开放域基准数据集，该数据集是第一个包含每个查询的多个真实答案的CIR数据集。实验结果表明，SEARLE具有更好的性能。

    

    组合图像检索(CIR)旨在根据由参考图像和描述两个图像之间差异的相对标题组成的查询来检索目标图像。标记CIR数据集所需的高工作量和成本阻碍了现有方法的广泛使用，因为它们依赖于监督学习。在这项工作中，我们提出了一个新的任务，零样本CIR (ZS-CIR)，旨在解决在不需要标记训练数据集的情况下进行CIR。我们的方法名为零样本组合图像检索与文本反转(SEARLE)，它将参考图像的视觉特征映射到CLIP令牌嵌入空间中的伪词标记，并将其与相对标题集成。为了支持ZS-CIR的研究，我们引入了一个名为“共同对象环境中的组合图像检索”(CIRCO)的开放域基准数据集，这是第一个包含每个查询的多个真实答案的CIR数据集。实验表明，SEARLE具有更好的性能。

    Composed Image Retrieval (CIR) aims to retrieve a target image based on a query composed of a reference image and a relative caption that describes the difference between the two images. The high effort and cost required for labeling datasets for CIR hamper the widespread usage of existing methods, as they rely on supervised learning. In this work, we propose a new task, Zero-Shot CIR (ZS-CIR), that aims to address CIR without requiring a labeled training dataset. Our approach, named zero-Shot composEd imAge Retrieval with textuaL invErsion (SEARLE), maps the visual features of the reference image into a pseudo-word token in CLIP token embedding space and integrates it with the relative caption. To support research on ZS-CIR, we introduce an open-domain benchmarking dataset named Composed Image Retrieval on Common Objects in context (CIRCO), which is the first dataset for CIR containing multiple ground truths for each query. The experiments show that SEARLE exhibits better performance 
    
[^18]: 用自适应加权损失进行元学习，解决不平衡的冷启动推荐问题

    Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation. (arXiv:2302.14640v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.14640](http://arxiv.org/abs/2302.14640)

    该论文提出了一种用于解决不平衡冷启动推荐问题的元学习算法，通过自适应加权损失来适应用户的个性化需求。

    

    顺序推荐系统在捕捉用户喜好方面取得了重大突破。然而，冷启动推荐仍然是一个基本挑战，因为它们通常涉及有限的用户-物品交互进行个性化。最近，基于梯度的元学习方法在顺序推荐领域中出现，因为它们具有快速适应和易于集成的能力。元学习算法将冷启动推荐描述为一个少样本学习问题，其中每个用户都被表示为需要适应的任务。然而，元学习算法通常假设任务样本在类别或值上均匀分布，而实际应用中的用户-物品交互并不符合这样的分布（例如，多次观看喜欢的视频，只留下正面评分而没有负面评分）。因此，占据任务训练数据大部分的不平衡用户反馈可能主导着用户的适应过程。

    Sequential recommenders have made great strides in capturing a user's preferences. Nevertheless, the cold-start recommendation remains a fundamental challenge as they typically involve limited user-item interactions for personalization. Recently, gradient-based meta-learning approaches have emerged in the sequential recommendation field due to their fast adaptation and easy-to-integrate abilities. The meta-learning algorithms formulate the cold-start recommendation as a few-shot learning problem, where each user is represented as a task to be adapted. While meta-learning algorithms generally assume that task-wise samples are evenly distributed over classes or values, user-item interactions in real-world applications do not conform to such a distribution (e.g., watching favorite videos multiple times, leaving only positive ratings without any negative ones). Consequently, imbalanced user feedback, which accounts for the majority of task training data, may dominate the user adaptation pr
    
[^19]: RECOMED: 一种综合性药物推荐系统

    RECOMED: A Comprehensive Pharmaceutical Recommendation System. (arXiv:2301.00280v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2301.00280](http://arxiv.org/abs/2301.00280)

    RECOMED是基于患者和药物特征设计的一种综合性药物推荐系统，采用人工智能模型和自然语言处理方法进行实现，首次考虑了患者条件和历史来选择合适药物，以及药物相互作用。

    

    基于从Drugs.com和Druglib.com提取的患者和药物特征，设计了一种综合性药物推荐系统。首先，将这些数据库的数据进行合并，建立了一个包含患者和药物信息的数据集。其次，对患者和药物进行了聚类，然后根据患者提供的不同评级以及从患者和药物规格中获取的知识，并考虑药物相互作用进行推荐。据我们所知，我们是第一组在所提出的方法中考虑患者的状况和历史来选择特定合适药物的。我们的方法使用人工智能（AI）模型来实现。在预处理中，采用自然语言处理方法进行情感分析，并使用基于神经网络的方法和推荐系统算法对系统建模。

    A comprehensive pharmaceutical recommendation system was designed based on the patients and drugs features extracted from Drugs.com and Druglib.com. First, data from these databases were combined, and a dataset of patients and drug information was built. Secondly, the patients and drugs were clustered, and then the recommendation was performed using different ratings provided by patients, and importantly by the knowledge obtained from patients and drug specifications, and considering drug interactions. To the best of our knowledge, we are the first group to consider patients conditions and history in the proposed approach for selecting a specific medicine appropriate for that particular user. Our approach applies artificial intelligence (AI) models for the implementation. Sentiment analysis using natural language processing approaches is employed in pre-processing along with neural network-based methods and recommender system algorithms for modeling the system. In our work, patients co
    
[^20]: 电子商务平台上的广告最大化利润策略

    A Profit-Maximizing Strategy for Advertising on the e-Commerce Platforms. (arXiv:2211.01160v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.01160](http://arxiv.org/abs/2211.01160)

    本文提出了一种针对在线广告定向选项的最大化利润策略，通过将优化问题重新定义为多选背包问题，找到最佳特征组合以增加将定向受众转化为实际购买者的概率。

    

    在线广告管理平台已经越来越受到电子商务卖家/广告商的欢迎，提供了一个简化的方法来吸引目标客户。尽管有其优势，但对于资源有限的在线卖家来说，正确配置广告策略仍然是一个挑战。无效的策略往往会导致大量的无效点击，从而导致广告费用与销售增长不成比例。在本文中，我们提出了一种针对在线广告定向选项的新颖的最大化利润策略。所提出的模型旨在找到最佳的特征组合，以最大化将定向受众转化为实际购买者的概率。我们通过将优化挑战重新定义为多选背包问题（MCKP）来解决优化问题。我们进行了一项实证研究，使用来自天猫的真实数据，证明了我们提出的方法可以有效地优化广告策略。

    The online advertising management platform has become increasingly popular among e-commerce vendors/advertisers, offering a streamlined approach to reach target customers. Despite its advantages, configuring advertising strategies correctly remains a challenge for online vendors, particularly those with limited resources. Ineffective strategies often result in a surge of unproductive ``just looking'' clicks, leading to disproportionately high advertising expenses comparing to the growth of sales. In this paper, we present a novel profit-maximing strategy for targeting options of online advertising. The proposed model aims to find the optimal set of features to maximize the probability of converting targeted audiences into actual buyers. We address the optimization challenge by reformulating it as a multiple-choice knapsack problem (MCKP). We conduct an empirical study featuring real-world data from Tmall to show that our proposed method can effectively optimize the advertising strategy
    
[^21]: FiBiNet++：通过低秩特征交互层减小CTR预测模型的大小

    FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for CTR Prediction. (arXiv:2209.05016v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2209.05016](http://arxiv.org/abs/2209.05016)

    FiBiNet++通过引入低秩特征交互层，成功减小了FiBiNet模型大小，并在三个公共数据集上实现了12倍至16倍的参数减小，同时显著提高了性能。

    

    点击率（CTR）估计已经成为许多现实世界应用中最基本的任务之一，并且已经提出了各种深度模型。一些研究证明FiBiNet是表现最佳的模型之一，并且在Avazu数据集上胜过了所有其他模型。然而，FiBiNet的大型模型大小限制了它的广泛应用。在本文中，我们提出了一种新的FiBiNet++模型来重新设计FiBiNet的模型结构，从而大大减小了模型大小，并进一步提高了性能。其中一个主要技术是我们提出的“低秩层”，专注于特征交互，它作为实现模型优越压缩比的关键驱动器。在三个公共数据集上进行的广泛实验证明，FiBiNet++有效地将FiBiNet的非嵌入式模型参数在三个数据集上减小了12倍至16倍。另一方面，与最先进的CTR方法（包括FiBiNet）相比，FiBiNet++能显著提高性能。

    Click-Through Rate (CTR) estimation has become one of the most fundamental tasks in many real-world applications and various deep models have been proposed. Some research has proved that FiBiNet is one of the best performance models and outperforms all other models on Avazu dataset. However, the large model size of FiBiNet hinders its wider application. In this paper, we propose a novel FiBiNet++ model to redesign FiBiNet's model structure, which greatly reduces model size while further improves its performance. One of the primary techniques involves our proposed "Low Rank Layer" focused on feature interaction, which serves as a crucial driver of achieving a superior compression ratio for models. Extensive experiments on three public datasets show that FiBiNet++ effectively reduces non-embedding model parameters of FiBiNet by 12x to 16x on three datasets. On the other hand, FiBiNet++ leads to significant performance improvements compared to state-of-the-art CTR methods, including FiBiN
    

