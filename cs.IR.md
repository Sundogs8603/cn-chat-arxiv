# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding.](http://arxiv.org/abs/2401.12798) | 这篇论文介绍了一种能够解决实体对齐解码问题的新方法，该方法通过最小化能量来优化解码过程，以实现图同质性，并且仅依赖于实体嵌入，具有较高的通用性和效率。 |
| [^2] | [CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process.](http://arxiv.org/abs/2401.12732) | CDRNP是一种通过神经网络将用户表示从源领域转移到目标领域，解决用户冷启动问题的跨领域推荐方法。 |
| [^3] | [MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels.](http://arxiv.org/abs/2401.12593) | MOReGIn是一种多目标推荐系统，可以同时在全局和个体层面上满足多个目标。通过调节推荐列表，MORS可以保证推荐的流派校准和供应商公平性。验证实验表明了该方法的有效性。 |
| [^4] | [PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering.](http://arxiv.org/abs/2401.12590) | PolyCF是一个灵活的图信号滤波器，通过多项式图过滤器处理交互信号，能够捕捉多个特征空间中的谱特征，并近似恢复丢失的交互，旨在实现最优的协同过滤。 |
| [^5] | [InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization.](http://arxiv.org/abs/2401.12553) | InfoRank是一种无偏的学习-排序范式，通过最小化以输入特征为条件的观测估计和相关估计之间的互信息来实现偏差-free 的相关估计。 |
| [^6] | [DREditor: An Time-efficient Approach for Building a Domain-specific Dense Retrieval Model.](http://arxiv.org/abs/2401.12540) | DREditor是一种时间高效的方法，通过直接校准现有的密集检索模型的输出嵌入，使用线性映射和编辑操作符来编辑匹配规则，以提高特定领域的检索效率。 |
| [^7] | [Key Information Retrieval to Classify the Unstructured Data Content of Preferential Trade Agreements.](http://arxiv.org/abs/2401.12520) | 本论文介绍了一种用于长文本分类和预测的新方法，通过嵌入技术对长文本进行压缩，然后采用双向编码器表示来自Transformers的嵌入方法进行文本分类训练，实验结果显示在优惠贸易协定的长文本分类方面取得了显著的性能提升。 |
| [^8] | [Persona-centric Metamorphic Relation guided Robustness Evaluation for Multi-turn Dialogue Modelling.](http://arxiv.org/abs/2401.12483) | 本研究介绍了一种基于角色的变态关系构建方法，用于对多轮对话建模进行鲁棒性评估。这种方法通过变态测试来评估对话系统的个性一致性和对话长时间维持性之间的关系。 |
| [^9] | [Session-level Normalization and Click-through Data Enhancement for Session-based Evaluation.](http://arxiv.org/abs/2401.12445) | 本研究针对会话级别的搜索系统评估，提出了会话级归一化和点击数据增强的方法。传统方法中会话级指标的假设可能不符合实际情况，本文考虑了用户满意度和隐式反馈的影响。 |
| [^10] | [Topics evolution through multilayer networks; Analysing 2M tweets from 2022 Qatar FIFA World Cup.](http://arxiv.org/abs/2401.12228) | 本研究通过多层网络方法对2022年卡塔尔世界杯的200万条推文进行了全面分析，可视化了主要主题的演变，考虑了上下文和意义关系。 |
| [^11] | [In-context Learning with Retrieved Demonstrations for Language Models: A Survey.](http://arxiv.org/abs/2401.11624) | 本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。 |
| [^12] | [D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems.](http://arxiv.org/abs/2401.11478) | D2K提出了一个以数据为中心的框架，将大量用户行为数据转化为可检索的知识，用于推荐系统。与传统的将知识存储在模型参数中的方法不同，D2K存储的是由用户、物品和背景构成的完整的推荐因素，从而具有更好的可扩展性和灵活性。 |
| [^13] | [ChatQA: Building GPT-4 Level Conversational QA Models.](http://arxiv.org/abs/2401.10225) | ChatQA是一系列对话问答模型，可以达到GPT-4级别的准确性。通过两阶段的指令调整方法，可以显著提高大型语言模型在零-shot对话问答中的结果。使用密集检索器进行问答数据集的微调可以实现与最先进的查询重写模型相当的结果，同时降低部署成本。ChatQA-70B在10个对话问答数据集上的平均得分超过了GPT-4，且不依赖于任何来自OpenAI GPT模型的合成数据。 |
| [^14] | [Preference and Concurrence Aware Bayesian Graph Neural Networks for Recommender Systems.](http://arxiv.org/abs/2312.11486) | 本文提出了一个偏好和并发感知的贝叶斯图神经网络框架用于解决推荐系统中的问题，通过生成模型和关注图结构信息来捕捉用户与物品的高阶信息，实验证明了其有效性。 |
| [^15] | [GraphPro: Graph Pre-training and Prompt Learning for Recommendation.](http://arxiv.org/abs/2311.16716) | GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。 |
| [^16] | [Unlock Multi-Modal Capability of Dense Retrieval via Visual Module Plugin.](http://arxiv.org/abs/2310.14037) | 本文介绍了一种名为MARVEL的多模态检索模型，通过视觉模块插件为密集检索器添加图像理解能力，并且在多模态检索任务中取得了显著优于最先进方法的结果。 |
| [^17] | [Retrieval meets Long Context Large Language Models.](http://arxiv.org/abs/2310.03025) | "本论文研究了将检索增强和长上下文窗口的大语言模型相结合的解决方案，发现在长上下文任务中，通过检索增强的LLM使用4K上下文窗口可以取得与通过长上下文窗口微调的LLM使用16K上下文窗口相当的性能，同时计算量要少得多。此外，无论上下文窗口大小如何，检索都可以显著提高LLM的性能。" |
| [^18] | [How Much Freedom Does An Effectiveness Metric Really Have?.](http://arxiv.org/abs/2309.09477) | 本文研究了评估指标对搜索引擎结果页面（SERP）的自由度，并发现了固有的 SERP 对排序关系约束。该研究认为这种关系约束应该应用于信息检索实验中，并提出了一种新的测量范式。 |
| [^19] | [SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription.](http://arxiv.org/abs/2309.09085) | SynthTab是一个利用合成数据的大规模吉他谱转录数据集，解决了现有数据集规模有限的问题，并通过合成音频保持了原始指法、风格和技巧的相符性。 |
| [^20] | [Refined Edge Usage of Graph Neural Networks for Edge Prediction.](http://arxiv.org/abs/2212.12970) | 这项研究提出了一种新的边缘预测范式（EMPIRE），通过细化边缘使用方法解决了节点分类任务和边缘预测任务之间的区别。该方法引入了边缘拆分技术和新的消息传递机制，以更好地利用边缘的拓扑结构和监督信号。 |

# 详细

[^1]: 能量的梯度流：实体对齐解码的通用高效方法

    Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding. (arXiv:2401.12798v1 [cs.IR])

    [http://arxiv.org/abs/2401.12798](http://arxiv.org/abs/2401.12798)

    这篇论文介绍了一种能够解决实体对齐解码问题的新方法，该方法通过最小化能量来优化解码过程，以实现图同质性，并且仅依赖于实体嵌入，具有较高的通用性和效率。

    

    实体对齐（EA）是在集成多源知识图谱（KGs）中的关键过程，旨在识别这些图谱中的等价实体对。大多数现有方法将EA视为图表示学习任务，专注于增强图编码器。然而，在EA中解码过程-对于有效的操作和对齐准确性至关重要-得到了有限的关注，并且仍然针对特定数据集和模型架构进行定制，需要实体和额外的显式关系嵌入。这种特殊性限制了它的适用性，尤其是在基于GNN的模型中。为了填补这一空白，我们引入了一种新颖、通用和高效的EA解码方法，仅依赖于实体嵌入。我们的方法通过最小化狄利克雷能量来优化解码过程，在图内引导梯度流，以促进图同质性。梯度流的离散化产生了一种快速可扩展的方法，称为三元特征。

    Entity alignment (EA), a pivotal process in integrating multi-source Knowledge Graphs (KGs), seeks to identify equivalent entity pairs across these graphs. Most existing approaches regard EA as a graph representation learning task, concentrating on enhancing graph encoders. However, the decoding process in EA - essential for effective operation and alignment accuracy - has received limited attention and remains tailored to specific datasets and model architectures, necessitating both entity and additional explicit relation embeddings. This specificity limits its applicability, particularly in GNN-based models. To address this gap, we introduce a novel, generalized, and efficient decoding approach for EA, relying solely on entity embeddings. Our method optimizes the decoding process by minimizing Dirichlet energy, leading to the gradient flow within the graph, to promote graph homophily. The discretization of the gradient flow produces a fast and scalable approach, termed Triple Feature
    
[^2]: CDRNP: 通过神经过程实现跨领域推荐以解决冷启动用户问题

    CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process. (arXiv:2401.12732v1 [cs.IR])

    [http://arxiv.org/abs/2401.12732](http://arxiv.org/abs/2401.12732)

    CDRNP是一种通过神经网络将用户表示从源领域转移到目标领域，解决用户冷启动问题的跨领域推荐方法。

    

    跨领域推荐（CDR）已被证明是解决用户冷启动问题的一种有效方法，旨在通过从源领域转移用户偏好来为目标领域的用户进行推荐。传统的CDR研究遵循嵌入和映射（EMCDR）范 paradigm，通过学习一个用户共享映射函数将用户表示从源领域转移到目标领域，忽视了用户特定偏好。最近的CDR研究尝试在元学习范 paradigm 下学习用户特定映射函数，将每个用户的CDR视为独立任务，但忽视了用户之间的偏好相关性，限制了用于表示用户的有益信息。此外，这两个范 paradigm 都忽略了映射过程中来自两个领域的用户-项目显式交互。为了解决上述问题，本文提出了一种新的CDR框架，使用神经过程（NP），称为CDRNP。

    Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops th
    
[^3]: MOReGIn: 多目标推荐在全局和个体层面上的应用

    MOReGIn: Multi-Objective Recommendation at the Global and Individual Levels. (arXiv:2401.12593v1 [cs.IR])

    [http://arxiv.org/abs/2401.12593](http://arxiv.org/abs/2401.12593)

    MOReGIn是一种多目标推荐系统，可以同时在全局和个体层面上满足多个目标。通过调节推荐列表，MORS可以保证推荐的流派校准和供应商公平性。验证实验表明了该方法的有效性。

    

    多目标推荐系统（MORS）作为一种保证多个目标的范式出现。除了准确性外，MORS可以在全局层面上工作，为整个系统实现除准确性之外的其他目标，也可以在个体层面上工作，这意味着推荐是根据每个用户的需求定制的。现有的MORS要么在全局层面上工作，要么在个体层面上工作，而不假设这两种观点的共存。在本研究中，我们表明当全局和个体目标共存时，MORS无法同时满足这两种目标。为了解决这个问题，我们提出了一种方法，通过调节推荐列表来保证全局和个体的观点，同时保持其有效性。具体而言，作为个体角度，我们解决了流派校准问题，作为全局角度，我们解决了供应商公平性问题。我们在两个实际数据集上验证了我们的方法，这些数据集与本文一同公开发布。

    Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to guarantee multiple (often conflicting) goals. Besides accuracy, a MORS can operate at the global level, where additional beyond-accuracy goals are met for the system as a whole, or at the individual level, meaning that the recommendations are tailored to the needs of each user. The state-of-the-art MORSs either operate at the global or individual level, without assuming the co-existence of the two perspectives. In this study, we show that when global and individual objectives co-exist, MORSs are not able to meet both types of goals. To overcome this issue, we present an approach that regulates the recommendation lists so as to guarantee both global and individual perspectives, while preserving its effectiveness. Specifically, as individual perspective, we tackle genre calibration and, as global perspective, provider fairness. We validate our approach on two real-world datasets, publicly released with this paper.
    
[^4]: PolyCF: 面向协同过滤的最优谱图过滤器

    PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering. (arXiv:2401.12590v1 [cs.IR])

    [http://arxiv.org/abs/2401.12590](http://arxiv.org/abs/2401.12590)

    PolyCF是一个灵活的图信号滤波器，通过多项式图过滤器处理交互信号，能够捕捉多个特征空间中的谱特征，并近似恢复丢失的交互，旨在实现最优的协同过滤。

    

    协同过滤（CF）是推荐系统中的一个关键研究领域，利用用户与项目之间的协同相似性提供个性化推荐。在基于节点嵌入的图神经网络（GNNs）取得显著成就的基础上，我们探索了基于嵌入方法的表达能力的上限，并通过将CF任务重新定义为图信号处理问题来应对挑战。为此，我们提出了PolyCF，一个灵活的图信号滤波器，利用多项式图过滤器处理交互信号。PolyCF通过一系列广义格拉姆滤波器捕捉多个特征空间中的谱特征，并能够近似于恢复丢失的交互的最优多项式响应函数。图优化目标和成对排名目标共同用于优化卷积核的参数。在三个广泛采用的数据集上进行实验

    Collaborative Filtering (CF) is a pivotal research area in recommender systems that capitalizes on collaborative similarities between users and items to provide personalized recommendations. With the remarkable achievements of node embedding-based Graph Neural Networks (GNNs), we explore the upper bounds of expressiveness inherent to embedding-based methodologies and tackle the challenges by reframing the CF task as a graph signal processing problem. To this end, we propose PolyCF, a flexible graph signal filter that leverages polynomial graph filters to process interaction signals. PolyCF exhibits the capability to capture spectral features across multiple eigenspaces through a series of Generalized Gram filters and is able to approximate the optimal polynomial response function for recovering missing interactions. A graph optimization objective and a pair-wise ranking objective are jointly used to optimize the parameters of the convolution kernel. Experiments on three widely adopted 
    
[^5]: InfoRank：通过条件互信息最小化实现无偏的学习-排序

    InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization. (arXiv:2401.12553v1 [cs.IR])

    [http://arxiv.org/abs/2401.12553](http://arxiv.org/abs/2401.12553)

    InfoRank是一种无偏的学习-排序范式，通过最小化以输入特征为条件的观测估计和相关估计之间的互信息来实现偏差-free 的相关估计。

    

    对个别用户兴趣进行排序是多种下游任务（如推荐系统）的核心技术。学习这样的个性化排序器通常依赖于用户过去的点击行为的隐式反馈。然而，收集到的反馈对先前排名较高的项目存在偏见，直接从中学习会导致“富者愈富”的现象。在本文中，我们提出了一个简单但足够的无偏学习-排序范式，名为InfoRank，旨在同时解决位置和流行度偏见。我们首先将这些偏差的影响整合到一个单一的观察因子中，从而为解决与偏见相关的问题提供了统一的方法。随后，我们通过最小化以输入特征为条件的观测估计和相关估计之间的互信息来实现偏差-free 的相关估计。为了实现InfoRank，我们首先融入一个

    Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in a "rich-get-richer" phenomenon. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation can be proved to be free of bias. To implement InfoRank, we first incorporate a
    
[^6]: DREditor:一种用于构建特定领域密集检索模型的时间高效方法

    DREditor: An Time-efficient Approach for Building a Domain-specific Dense Retrieval Model. (arXiv:2401.12540v1 [cs.IR])

    [http://arxiv.org/abs/2401.12540](http://arxiv.org/abs/2401.12540)

    DREditor是一种时间高效的方法，通过直接校准现有的密集检索模型的输出嵌入，使用线性映射和编辑操作符来编辑匹配规则，以提高特定领域的检索效率。

    

    在不同行业中，有效部署密集检索模型变得越来越重要。这在企业搜索服务中尤为如此，因为需求不同领域的不同企业的时间需求不同。出于这个原因，我们开发了一种名为DREditor的时间高效方法，用于编辑现成的密集检索模型的匹配规则，以适应特定领域。通过直接校准模型的输出嵌入，使用一种高效而有效的线性映射来实现这一点。这种映射是由解决一个特殊构建的最小二乘问题获得的编辑操作符驱动的。与通过长时间微调进行隐式规则修改相比，我们的实验结果表明，DREditor在不同的特定领域数据集、数据集来源、检索模型和计算设备上都提供了显著优势。它始终可以提高时间效率100-300倍，同时保持不变。

    Deploying dense retrieval models efficiently is becoming increasingly important across various industries. This is especially true for enterprise search services, where customizing search engines to meet the time demands of different enterprises in different domains is crucial. Motivated by this, we develop a time-efficient approach called DREditor to edit the matching rule of an off-the-shelf dense retrieval model to suit a specific domain. This is achieved by directly calibrating the output embeddings of the model using an efficient and effective linear mapping. This mapping is powered by an edit operator that is obtained by solving a specially constructed least squares problem. Compared to implicit rule modification via long-time finetuning, our experimental results show that DREditor provides significant advantages on different domain-specific datasets, dataset sources, retrieval models, and computing devices. It consistently enhances time efficiency by 100-300 times while maintain
    
[^7]: 对优惠贸易协定的非结构化数据内容进行关键信息检索的研究

    Key Information Retrieval to Classify the Unstructured Data Content of Preferential Trade Agreements. (arXiv:2401.12520v1 [cs.CL])

    [http://arxiv.org/abs/2401.12520](http://arxiv.org/abs/2401.12520)

    本论文介绍了一种用于长文本分类和预测的新方法，通过嵌入技术对长文本进行压缩，然后采用双向编码器表示来自Transformers的嵌入方法进行文本分类训练，实验结果显示在优惠贸易协定的长文本分类方面取得了显著的性能提升。

    

    随着文本数据的迅速增长，预测长文本已经成为自然语言处理领域的重要挑战。传统的文本预测方法在处理长文本时遇到困难，主要是由于冗余和无关信息的存在，这影响了模型从文本中捕捉重要见解的能力。为了解决这个问题，我们提出了一种新的长文本分类和预测方法。首先，我们采用嵌入技术来对长文本进行压缩，以减少其中的冗余信息。随后，我们使用双向编码器表示来自Transformers（BERT）的嵌入方法进行文本分类训练。实验结果表明，我们的方法在优惠贸易协定的长文本分类方面实现了显著的性能提升。此外，通过嵌入方法对文本进行压缩不仅增强了预测表现，而且有助于提取关键信息。

    With the rapid proliferation of textual data, predicting long texts has emerged as a significant challenge in the domain of natural language processing. Traditional text prediction methods encounter substantial difficulties when grappling with long texts, primarily due to the presence of redundant and irrelevant information, which impedes the model's capacity to capture pivotal insights from the text. To address this issue, we introduce a novel approach to long-text classification and prediction. Initially, we employ embedding techniques to condense the long texts, aiming to diminish the redundancy therein. Subsequently,the Bidirectional Encoder Representations from Transformers (BERT) embedding method is utilized for text classification training. Experimental outcomes indicate that our method realizes considerable performance enhancements in classifying long texts of Preferential Trade Agreements. Furthermore, the condensation of text through embedding methods not only augments predic
    
[^8]: 基于角色的变态关系引导多轮对话建模的鲁棒性评估

    Persona-centric Metamorphic Relation guided Robustness Evaluation for Multi-turn Dialogue Modelling. (arXiv:2401.12483v1 [cs.IR])

    [http://arxiv.org/abs/2401.12483](http://arxiv.org/abs/2401.12483)

    本研究介绍了一种基于角色的变态关系构建方法，用于对多轮对话建模进行鲁棒性评估。这种方法通过变态测试来评估对话系统的个性一致性和对话长时间维持性之间的关系。

    

    最近，在对话系统领域中引入了微调和提示学习等训练范式的推动下，取得了显著进展。角色可以作为先验知识，用于保持对话系统的个性一致性，从而在准确性方面表现出色。然而，传统的基于参考的评估方法在捕捉模型真实文本理解能力方面存在不足，过度依赖数据注释的质量。相比之下，变态测试的应用提供了对模型独特能力更深入的洞察，而无需额外的注释标签。这种方法更全面地揭示了模型的复杂性，并暴露了基于参考验证技术所隐藏的复杂性。因此，我们引入了基于角色的变态关系构建方法，用于变态测试，旨在评估角色一致性和对话长时间维持性之间的关系。

    Recently there has been significant progress in the field of dialogue system thanks to the introduction of training paradigms such as fine-tune and prompt learning. Persona can function as the prior knowledge for maintaining the personality consistency of dialogue systems, which makes it perform well on accuracy. Nonetheless, the conventional reference-based evaluation method falls short in capturing the genuine text comprehension prowess of the model, significantly relying on the quality of data annotation. In contrast, the application of metamorphic testing offers a more profound insight into the model's distinct capabilities without necessitating supplementary annotation labels. This approach furnishes a more comprehensive portrayal of the model's intricacies and exposes intricacies concealed within reference-based validation techniques. Consequently, we introduce a persona-centric metamorphic relation construction for metamorphic testing, aimed at evaluating both the persona consis
    
[^9]: 会话级归一化和点击数据增强对于会话评估的应用

    Session-level Normalization and Click-through Data Enhancement for Session-based Evaluation. (arXiv:2401.12445v1 [cs.IR])

    [http://arxiv.org/abs/2401.12445](http://arxiv.org/abs/2401.12445)

    本研究针对会话级别的搜索系统评估，提出了会话级归一化和点击数据增强的方法。传统方法中会话级指标的假设可能不符合实际情况，本文考虑了用户满意度和隐式反馈的影响。

    

    鉴于用户通常需要发出一系列查询并检查多个文档以解决复杂的信息需求，研究人员更关注于会话级别而非单一查询级别上对搜索系统进行评估。现有的大多数会话级指标都是分别评估每个查询，然后使用会话级加权函数对查询级得分进行聚合。这些指标的假设是会话中的所有查询都应该参与其中，并且它们的顺序是固定的。然而，如果一个搜索系统可以通过用户的前几个查询使用户满意，那么她可能不需要任何后续查询了。此外，在大多数实际搜索场景中，由于缺乏真实用户的明确反馈，我们只能利用一些隐式反馈，如用户的点击，作为离线评估的相关性标签。这样的隐式反馈与搜索会话中的真实相关性可能有所不同，因为有些文档可能被忽略了。

    Since a user usually has to issue a sequence of queries and examine multiple documents to resolve a complex information need in a search session, researchers have paid much attention to evaluating search systems at the session level rather than the single-query level. Most existing session-level metrics evaluate each query separately and then aggregate the query-level scores using a session-level weighting function. The assumptions behind these metrics are that all queries in the session should be involved, and their orders are fixed. However, if a search system could make the user satisfied with her first few queries, she may not need any subsequent queries. Besides, in most real-world search scenarios, due to a lack of explicit feedback from real users, we can only leverage some implicit feedback, such as users' clicks, as relevance labels for offline evaluation. Such implicit feedback might be different from the real relevance in a search session as some documents may be omitted in 
    
[^10]: 通过多层网络分析演变的主题；分析2022年卡塔尔世界杯的200万条推文

    Topics evolution through multilayer networks; Analysing 2M tweets from 2022 Qatar FIFA World Cup. (arXiv:2401.12228v1 [cs.SI])

    [http://arxiv.org/abs/2401.12228](http://arxiv.org/abs/2401.12228)

    本研究通过多层网络方法对2022年卡塔尔世界杯的200万条推文进行了全面分析，可视化了主要主题的演变，考虑了上下文和意义关系。

    

    本研究对2022年卡塔尔世界杯事件进行了全面的数据收集，并使用多层网络方法可视化了主要主题，同时考虑了它们的上下文和意义关系。我们将数据按照比赛阶段划分为不同的层次，并利用Gephi软件生成了多层网络。我们的可视化展示了主题和词汇之间的关系，展示了词汇-上下文关系以及各层次上最常讨论主题的动态和变化。

    In this study, we conducted a comprehensive data collection on the 2022 Qatar FIFA World Cup event and used a multilayer network approach to visualize the main topics, while considering their context and meaning relationships. We structured the data into layers that corresponded with the stages of the tournament and utilized Gephi software to generate the multilayer networks. Our visualizations displayed both the relationships between topics and words, showing the word-context relationship, as well as the dynamics and changes over time by layer of the most frequently discussed topics.
    
[^11]: 通过检索示范进行上下文学习的语言模型：一项综述

    In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11624](http://arxiv.org/abs/2401.11624)

    本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。

    

    语言模型，特别是预训练的大型语言模型，已展示出卓越的能力，可以在输入上下文中进行少量样本的情境学习（ICL），并在新任务上具有适应能力。然而，模型的ICL能力对于少样本示范的选择是敏感的。最近的一项研究进展是检索针对每个输入查询定制的示范。示范检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且已经证明可以减少手动示例选择中的偏见。鉴于令人鼓舞的结果和在检索示范的ICL方面不断增长的研究，我们进行了广泛的研究综述。在这项综述中，我们讨论和比较了检索模型的不同设计选择，检索训练

    Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
    
[^12]: D2K: 将历史数据转化为可检索的知识，用于推荐系统

    D2K: Turning Historical Data into Retrievable Knowledge for Recommender Systems. (arXiv:2401.11478v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2401.11478](http://arxiv.org/abs/2401.11478)

    D2K提出了一个以数据为中心的框架，将大量用户行为数据转化为可检索的知识，用于推荐系统。与传统的将知识存储在模型参数中的方法不同，D2K存储的是由用户、物品和背景构成的完整的推荐因素，从而具有更好的可扩展性和灵活性。

    

    如今，在大型推荐平台上不断积累的大量用户行为数据记录了用户的各种兴趣和品味。但是，如何在新数据不断到来时保留旧数据中的知识成为推荐系统中的一个重要问题。现有的方法通常试图将知识隐含在模型参数中。然而，这种以参数为中心的方法缺乏可扩展性和灵活性——容量难以扩展，知识难以利用。因此，本文提出了一个将大量用户行为数据转化为可检索知识的框架（D2K）。这是一种以数据为中心的方法，不依赖于特定模型并且易于扩展。不同于仅存储用户或物品的一元知识，D2K提出存储用于推荐的三元知识，该知识由完整的推荐因素——用户、物品和背景构成。目标样本可以直接检索到这些知识。

    A vast amount of user behavior data is constantly accumulating on today's large recommendation platforms, recording users' various interests and tastes. Preserving knowledge from the old data while new data continually arrives is a vital problem for recommender systems. Existing approaches generally seek to save the knowledge implicitly in the model parameters. However, such a parameter-centric approach lacks scalability and flexibility -- the capacity is hard to scale, and the knowledge is inflexible to utilize. Hence, in this work, we propose a framework that turns massive user behavior data to retrievable knowledge (D2K). It is a data-centric approach that is model-agnostic and easy to scale up. Different from only storing unary knowledge such as the user-side or item-side information, D2K propose to store ternary knowledge for recommendation, which is determined by the complete recommendation factors -user, item, and context. The knowledge retrieved by target samples can be direc
    
[^13]: ChatQA: 构建GPT-4级对话问答模型

    ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v1 [cs.CL])

    [http://arxiv.org/abs/2401.10225](http://arxiv.org/abs/2401.10225)

    ChatQA是一系列对话问答模型，可以达到GPT-4级别的准确性。通过两阶段的指令调整方法，可以显著提高大型语言模型在零-shot对话问答中的结果。使用密集检索器进行问答数据集的微调可以实现与最先进的查询重写模型相当的结果，同时降低部署成本。ChatQA-70B在10个对话问答数据集上的平均得分超过了GPT-4，且不依赖于任何来自OpenAI GPT模型的合成数据。

    

    在这项工作中，我们介绍了ChatQA，一系列具有GPT-4级别准确性的对话问答模型。具体地，我们提出了一个两阶段的指令调整方法，可以显著提高大型语言模型（LLM）在零-shot对话问答中的结果。为了处理对话问答中的检索问题，我们在多轮问答数据集上进行了密集检索器的微调，这样可以提供与使用最先进的查询重写模型相当的结果，同时大大降低部署成本。值得注意的是，我们的ChatQA-70B可以在10个对话问答数据集的平均分上超过GPT-4（54.14 vs. 53.90），而不依赖于OpenAI GPT模型的任何合成数据。

    In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.
    
[^14]: 偏好和并发感知的贝叶斯图神经网络用于推荐系统

    Preference and Concurrence Aware Bayesian Graph Neural Networks for Recommender Systems. (arXiv:2312.11486v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.11486](http://arxiv.org/abs/2312.11486)

    本文提出了一个偏好和并发感知的贝叶斯图神经网络框架用于解决推荐系统中的问题，通过生成模型和关注图结构信息来捕捉用户与物品的高阶信息，实验证明了其有效性。

    

    基于图的协同过滤方法对于推荐系统具有突出的性能，因为它们可以捕捉用户和物品之间的高阶信息，其中图是由观察到的用户-物品交互构建的，这些交互可能会丢失链接或包含虚假的正交互。贝叶斯图神经网络框架通过生成模型解决了这个问题。关键问题是设计一族适合推荐系统的图生成模型。我们提出了一种高效的生成模型，它同时考虑了用户的偏好、物品的并发以及一些重要的图结构信息。在四个流行的基准数据集上的实验证明了我们提出的图生成方法在推荐系统中的有效性。

    Graph-based collaborative filtering methods have prevailing performance for recommender systems since they can capture high-order information between users and items, in which the graphs are constructed from the observed user-item interactions that might miss links or contain spurious positive interactions in industrial scenarios. The Bayesian Graph Neural Network framework approaches this issue with generative models for the interaction graphs. The critical problem is to devise a proper family of graph generative models tailored to recommender systems. We propose an efficient generative model that jointly considers the preferences of users, the concurrence of items and some important graph structure information. Experiments on four popular benchmark datasets demonstrate the effectiveness of our proposed graph generative methods for recommender systems.
    
[^15]: GraphPro: 面向推荐系统的图预训练和提示学习

    GraphPro: Graph Pre-training and Prompt Learning for Recommendation. (arXiv:2311.16716v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.16716](http://arxiv.org/abs/2311.16716)

    GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。

    

    基于GNN的推荐系统通过多次消息传递在建模复杂的用户-物品交互方面表现出色。然而，现有方法往往忽视了不断变化的用户-物品交互的动态性，这限制了其在适应用户偏好变化和新到达数据分布变化方面的可扩展性和性能。因此，它们在真实世界的动态环境中的可扩展性和性能受到了限制。在这项研究中，我们提出了GraphPro，这是一个将参数高效和动态图预训练与提示学习相结合的框架。这种新颖的组合能够有效捕捉长期用户偏好和短期行为动态，从而实现准确和及时的推荐。我们的GraphPro框架通过无缝集成临时提示机制和图结构提示学习机制到预训练的GNN模型中来解决用户偏好不断变化的挑战。

    GNN-based recommenders have excelled in modeling intricate user-item interactions through multi-hop message passing. However, existing methods often overlook the dynamic nature of evolving user-item interactions, which impedes the adaption to changing user preferences and distribution shifts in newly arriving data. Thus, their scalability and performances in real-world dynamic environments are limited. In this study, we propose GraphPro, a framework that incorporates parameter-efficient and dynamic graph pre-training with prompt learning. This novel combination empowers GNNs to effectively capture both long-term user preferences and short-term behavior dynamics, enabling the delivery of accurate and timely recommendations. Our GraphPro framework addresses the challenge of evolving user preferences by seamlessly integrating a temporal prompt mechanism and a graph-structural prompt learning mechanism into the pre-trained GNN model. The temporal prompt mechanism encodes time information o
    
[^16]: 通过视觉模块插件解锁密集检索的多模态能力

    Unlock Multi-Modal Capability of Dense Retrieval via Visual Module Plugin. (arXiv:2310.14037v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.14037](http://arxiv.org/abs/2310.14037)

    本文介绍了一种名为MARVEL的多模态检索模型，通过视觉模块插件为密集检索器添加图像理解能力，并且在多模态检索任务中取得了显著优于最先进方法的结果。

    

    本文提出了通过视觉模块插件（MARVEL）学习查询和多模态文档的嵌入空间以进行检索的多模态检索模型。MARVEL使用统一的编码器模型对查询和多模态文档进行编码，有助于减小图像和文本之间的模态差距。具体而言，我们通过将视觉模块编码的图像特征作为其输入，使得经过训练的密集检索器T5-ANCE具有图像理解能力。为了促进多模态检索任务，我们基于ClueWeb22数据集构建了ClueWeb22-MM数据集，将锚文本作为查询，并从锚链接的网页中提取相关文本和图像文档。实验证明，MARVEL在多模态检索数据集WebQA和ClueWeb22-MM上明显优于最先进的方法。进一步的分析表明，视觉模块插件方法为实现图像理解能力量身定制。

    This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin (MARVEL) to learn an embedding space for queries and multi-modal documents to conduct retrieval. MARVEL encodes queries and multi-modal documents with a unified encoder model, which helps to alleviate the modality gap between images and texts. Specifically, we enable the image understanding ability of a well-trained dense retriever, T5-ANCE, by incorporating the image features encoded by the visual module as its inputs. To facilitate the multi-modal retrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22 dataset, which regards anchor texts as queries, and exact the related texts and image documents from anchor linked web pages. Our experiments show that MARVEL significantly outperforms the state-of-the-art methods on the multi-modal retrieval dataset WebQA and ClueWeb22-MM. Our further analyses show that the visual module plugin method is tailored to enable the image understanding ability for an 
    
[^17]: "检索遇上长篇大语言模型"

    Retrieval meets Long Context Large Language Models. (arXiv:2310.03025v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.03025](http://arxiv.org/abs/2310.03025)

    "本论文研究了将检索增强和长上下文窗口的大语言模型相结合的解决方案，发现在长上下文任务中，通过检索增强的LLM使用4K上下文窗口可以取得与通过长上下文窗口微调的LLM使用16K上下文窗口相当的性能，同时计算量要少得多。此外，无论上下文窗口大小如何，检索都可以显著提高LLM的性能。"

    

    "最近，扩展大语言模型（LLM）的上下文窗口越来越流行，而将检索与LLM相结合的解决方案已存在多年。自然而然的问题是：检索增强与长上下文窗口，哪个对下游任务更好？这两种方法可以结合起来以兼顾利弊吗？在这项工作中，我们使用两个最先进的预训练LLM（即一个私有的43B GPT和Llama2-70B）来研究这两种解决方案。也许令人惊讶的是，我们发现在长上下文任务中，LLM使用4K上下文窗口并通过简单的检索增强在生成时可以达到与通过长上下文窗口进行位置插值的微调LLM使用16K上下文窗口相当的性能，同时计算量要少得多。更重要的是，我们证明了不论其扩展的上下文窗口大小如何，检索都可以显著提高LLM的性能。我们最好的模型是具有32K上下文窗口的检索增强Llama2-70B。"

    Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented Llama2-70B with 32K context wi
    
[^18]: 评估指标到底有多少自由度？

    How Much Freedom Does An Effectiveness Metric Really Have?. (arXiv:2309.09477v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2309.09477](http://arxiv.org/abs/2309.09477)

    本文研究了评估指标对搜索引擎结果页面（SERP）的自由度，并发现了固有的 SERP 对排序关系约束。该研究认为这种关系约束应该应用于信息检索实验中，并提出了一种新的测量范式。

    

    人们常常误以为，由于评估指标对搜索引擎结果页面（SERP）可以自由选择分数，因此对于 SERP 对的相对顺序也有类似的自由度。事实上，在很大程度上，这种第二类自由度是虚幻的。这是因为如果对于一对 SERP 中的一个已经被评估指标给予了特定的分数，许多情况下基本的排序约束则决定了对于第二个 SERP 的分数要么不小于，要么不大于给予第一个 SERP 的分数。我们将这种固定的关系称之为固有的 SERP 对排序。本文的第一个目标是描述和辩护这些 SERP 对关系约束，并通过详尽和经验性的实验来统计它们的相对发生情况。然后，我们考虑如何在信息检索实验中应用这些固有的 SERP 对关系，从而提出了一种新的测量范式。

    It is tempting to assume that because effectiveness metrics have free choice to assign scores to search engine result pages (SERPs) there must thus be a similar degree of freedom as to the relative order that SERP pairs can be put into. In fact that second freedom is, to a considerable degree, illusory. That's because if one SERP in a pair has been given a certain score by a metric, fundamental ordering constraints in many cases then dictate that the score for the second SERP must be either not less than, or not greater than, the score assigned to the first SERP. We refer to these fixed relationships as innate pairwise SERP orderings. Our first goal in this work is to describe and defend those pairwise SERP relationship constraints, and tabulate their relative occurrence via both exhaustive and empirical experimentation.  We then consider how to employ such innate pairwise relationships in IR experiments, leading to a proposal for a new measurement paradigm. Specifically, we argue that
    
[^19]: SynthTab: 利用合成数据进行吉他谱转录

    SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription. (arXiv:2309.09085v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2309.09085](http://arxiv.org/abs/2309.09085)

    SynthTab是一个利用合成数据的大规模吉他谱转录数据集，解决了现有数据集规模有限的问题，并通过合成音频保持了原始指法、风格和技巧的相符性。

    

    吉他谱是吉他手广泛使用的一种音乐符号。它不仅捕捉了一首乐曲的音乐内容，还包括了在乐器上的实施和装饰。吉他谱转录（GTT）是一项重要的任务，在音乐教育和娱乐领域有广泛应用。现有的数据集在规模和范围上都有限，导致基于这些数据集训练的最先进的GTT模型容易过拟合，并且在跨数据集的泛化中失败。为解决这个问题，我们开发了一种方法来合成SynthTab，这是一个利用多个商用吉他插件合成的大规模吉他谱转录数据集。该数据集基于DadaGP的吉他谱构建，DadaGP提供了我们希望转录的吉他谱的庞大收藏和特定程度。所提出的合成流程可产生与原始指法、风格和技巧在音色上相符的音频。

    Guitar tablature is a form of music notation widely used among guitarists. It captures not only the musical content of a piece, but also its implementation and ornamentation on the instrument. Guitar Tablature Transcription (GTT) is an important task with broad applications in music education and entertainment. Existing datasets are limited in size and scope, causing state-of-the-art GTT models trained on such datasets to suffer from overfitting and to fail in generalization across datasets. To address this issue, we developed a methodology for synthesizing SynthTab, a large-scale guitar tablature transcription dataset using multiple commercial acoustic and electric guitar plugins. This dataset is built on tablatures from DadaGP, which offers a vast collection and the degree of specificity we wish to transcribe. The proposed synthesis pipeline produces audio which faithfully adheres to the original fingerings, styles, and techniques specified in the tablature with diverse timbre. Exper
    
[^20]: 基于图神经网络的边缘预测中细化边缘使用方法

    Refined Edge Usage of Graph Neural Networks for Edge Prediction. (arXiv:2212.12970v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12970](http://arxiv.org/abs/2212.12970)

    这项研究提出了一种新的边缘预测范式（EMPIRE），通过细化边缘使用方法解决了节点分类任务和边缘预测任务之间的区别。该方法引入了边缘拆分技术和新的消息传递机制，以更好地利用边缘的拓扑结构和监督信号。

    

    图神经网络（GNNs）最初用于节点分类，也激发了许多关于边缘预测（即链路预测）的最新研究。然而，现有方法在关于这两个任务的区别方面缺乏精细的设计，这一点常常被忽视：（i）对于节点分类任务而言，边仅构成拓扑结构，但在边缘预测任务中既可以作为拓扑结构，也可以作为监督信号（即标签）；（ii）节点分类是对每个节点进行预测，而边缘预测则由每对节点决定。为此，我们提出了一种称为边缘感知消息传递神经网络（EMPIRE）的新型边缘预测范式。具体而言，我们首先引入一种边缘拆分技术来指定每个边的使用方式，其中每个边仅用作拓扑结构或监督信号（分别称为拓扑边或监督边）。然后，我们开发了一种新的消息传递机制，生成消息的传递的过程。

    Graph Neural Networks (GNNs), originally proposed for node classification, have also motivated many recent works on edge prediction (a.k.a., link prediction). However, existing methods lack elaborate design regarding the distinctions between two tasks that have been frequently overlooked: (i) edges only constitute the topology in the node classification task but can be used as both the topology and the supervisions (i.e., labels) in the edge prediction task; (ii) the node classification makes prediction over each individual node, while the edge prediction is determinated by each pair of nodes. To this end, we propose a novel edge prediction paradigm named Edge-aware Message PassIng neuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting technique to specify use of each edge where each edge is solely used as either the topology or the supervision (named as topology edge or supervision edge). We then develop a new message passing mechanism that generates the messages t
    

