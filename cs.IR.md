# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generate to Understand for Representation.](http://arxiv.org/abs/2306.10056) | GUR是一种预训练框架，将语言建模和对比学习目标结合在单个训练步骤中，通过从原始无标签文档中选择相似的文本对来训练模型，无需任何标记训练数据即可作为检索器超过其他预训练基线模型。 |
| [^2] | [NFTs to MARS: Multi-Attention Recommender System for NFTs.](http://arxiv.org/abs/2306.10053) | 本文提出了首个具有三大关键特征——图形注意力、多模态注意力和多任务学习的面向NFT的多注意力推荐系统(NFT-MARS)，以解决NFT市场挑战。 |
| [^3] | [TOBY: A Tool for Exploring Data in Academic Survey Papers.](http://arxiv.org/abs/2306.10051) | TOBY是一种可视化工具，能帮助用户探索学术调查论文的内容，包括分类层次结构视图、文档相似性视图、引用网络视图和论文推荐工具。 |
| [^4] | [Interpolating Item and User Fairness in Recommendation Systems.](http://arxiv.org/abs/2306.10050) | 本文研究在推荐系统中平衡项目和用户公平性的框架，并通过低后悔的在线优化算法实现了维持收益同时实现公平推荐的目标。 |
| [^5] | [Neighborhood-based Hard Negative Mining for Sequential Recommendation.](http://arxiv.org/abs/2306.10047) | 本文提出了一种基于邻域重叠的基于图形的负采样方法（GNNO），利用隐藏在用户行为中的结构信息进行负采样，用于增进序列推荐模型的训练和性能。 |
| [^6] | [Document Layout Annotation: Database and Benchmark in the Domain of Public Affairs.](http://arxiv.org/abs/2306.10046) | 该研究介绍了一个基于4个基本布局块和4个文本类别的布局标签的数字文档的半自动注释过程，生成了一个用于公共事务领域的DLA新数据库，以帮助自动处理数字文档。 |
| [^7] | [A Practical Entity Linking System for Tables in Scientific Literature.](http://arxiv.org/abs/2306.10044) | 本文介绍了一个用于将实体链接到知识库中的通用系统，并将其适应于链接特定领域的实体，特别是 COVID-19 相关科学文献中的嵌入式实体。通过利用表格的结构和语义特征，以提高整体实体链接性能。 |
| [^8] | [A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction.](http://arxiv.org/abs/2306.10042) | 本文提出了一种配对增强方法，通过对比学习将方面-意见配对知识注入到Aspect Sentiment Triplet Extraction（ASTE）模型中，提高了三元组提取的准确性和性能。 |
| [^9] | [Unlocking Insights into Business Trajectories with Transformer-based Spatio-temporal Data Analysis.](http://arxiv.org/abs/2306.10034) | 本研究利用新闻文章数据，采用Transformer模型模拟商业轨迹，揭示商业趋势和行业表现。 |
| [^10] | [Pseudo session-based recommendation with hierarchical embedding and session attributes.](http://arxiv.org/abs/2306.10029) | 本文提出了一种新方法CoHHGN+，用于解决缺乏用户ID的电商网站数据的推荐问题。该方法使用了定义的伪会话以及包括价格、类别、性别和地区等用户信息，得到了较好的推荐结果。 |
| [^11] | [Graph Based Long-Term And Short-Term Interest Model for Click-Through Rate Prediction.](http://arxiv.org/abs/2306.10028) | 本论文提出了一种名为GLSM的基于图的长期和短期兴趣模型，可以很好地处理长期和短期用户兴趣数据的问题。 |
| [^12] | [Decomposition and Interleaving for Variance Reduction of Post-click Metrics.](http://arxiv.org/abs/2306.10024) | 本研究提出了一种有效的方法，通过分解和交错多个排名的后点击度量以减少样本方差。该方法专注于测量多个排名中每个项目的后点击度量，并优化排名以暴露具有高群体方差的项目。 |
| [^13] | [Theoretical Analysis on the Efficiency of Interleaved Comparisons.](http://arxiv.org/abs/2306.10023) | 本研究对交错比较方法的效率进行了理论分析，发现当用户根据相关性离开排名时，交错比较比A/B测试更为有效。 |
| [^14] | [The News Delivery Channel Recommendation Based on Granular Neural Network.](http://arxiv.org/abs/2306.10022) | 本文提出了一种基于粒神经网络的新闻推荐模型，通过分析新闻的特性来推荐适当的渠道。 |
| [^15] | [RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation.](http://arxiv.org/abs/2306.08947) | 本文提出了 RecFusion，一种特定针对1D和/或二进制设置的推荐模型方法，其利用了二项式扩散过程对二元用户-项目交互进行显式建模，并在核心推荐设置和最常见的数据集上接近复杂的VAE基线的表现。 |
| [^16] | [Learning to Rank when Grades Matter.](http://arxiv.org/abs/2306.08650) | 本论文提出了一种学习排序和成绩预测的多目标函数，可以在真实应用中更好地平衡排序和成绩，优于现有方法。 |
| [^17] | [KuaiSAR: A Unified Search And Recommendation Dataset.](http://arxiv.org/abs/2306.07705) | 这篇论文介绍了一份大规模、真实的数据集KuaiSAR，该数据集记录了快手短视频应用程序中真实的集成搜索和推荐行为。 |
| [^18] | [Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding.](http://arxiv.org/abs/2305.14449) | 一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。 |
| [^19] | [Exploring the Viability of Synthetic Query Generation for Relevance Prediction.](http://arxiv.org/abs/2305.11944) | 本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。 |
| [^20] | [Revisiting k-NN for Pre-trained Language Models.](http://arxiv.org/abs/2304.09058) | 本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。 |
| [^21] | [Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices.](http://arxiv.org/abs/2303.06016) | 本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。 |
| [^22] | [Pacos: Modeling Users' Interpretable and Context-Dependent Choices in Preference Reversals.](http://arxiv.org/abs/2303.05648) | Pacos是一个上下文依赖的偏好模型，可以处理偏好逆转问题，并提供用户的自适应权重、比较和显示位置等可解释因素，有助于提供个性化服务。 |
| [^23] | [Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation.](http://arxiv.org/abs/2301.12197) | 本文提出了一种基于互Wasserstein距离最小化的新型自监督学习框架用于提高推荐系统的性能，该方法使用Wasserstein距离测量来增强互信息最大化，优于现有的几种顺序推荐方法。 |
| [^24] | [MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers.](http://arxiv.org/abs/2212.07841) | 本文提出了一个名为MASTER的多任务预训练模型，利用瓶颈掩蔽自编码器统一各种预训练任务，并将其集成到一个模型中。该模型在两个广泛使用的数据集上的实验表明，相比同等模型大小和预训练资源的最先进密集检索模型，MASTER表现更好。 |
| [^25] | [XSimGCL: Towards Extremely Simple Graph Contrastive Learning for Recommendation.](http://arxiv.org/abs/2209.02544) | 本文提出一种极简的推荐图形对比学习方法(XSimGCL)，发现有效减轻流行度偏见与促进长尾物品发现并不需要过多的图形增强。 |
| [^26] | [VFed-SSD: Towards Practical Vertical Federated Advertising.](http://arxiv.org/abs/2205.15987) | 本文提出了一种半监督分裂知识蒸馏框架VFed-SSD，用于改善广告模型的学习效果。该框架利用未标记的相互重叠的数据，并通过分解联邦模型来在模型性能和推理效率之间保持平衡。实验结果在真实数据集上表明，VFed-SSD相对于其他最先进的垂直联合学习方法具有更高的预测准确性和推理效率。 |

# 详细

[^1]: 为了表示而生成——一种结合对比学习的语言预训练框架

    Generate to Understand for Representation. (arXiv:2306.10056v1 [cs.CL])

    [http://arxiv.org/abs/2306.10056](http://arxiv.org/abs/2306.10056)

    GUR是一种预训练框架，将语言建模和对比学习目标结合在单个训练步骤中，通过从原始无标签文档中选择相似的文本对来训练模型，无需任何标记训练数据即可作为检索器超过其他预训练基线模型。

    

    近年来涌现了大量高质量的预训练模型，极大地影响了自然语言理解、自然语言生成和文本表示等任务。然而，传统上这些模型是在特定领域的语料库上进行预训练，并进行特定任务的微调，这导致了高昂的GPU使用和劳动力成本。文章提出了GUR：一种将语言建模和对比学习目标结合在单个训练步骤中的预训练框架。我们从原始的无标签文档中基于最长公共子字符串（LCS）选择相似的文本对，并使用掩码语言建模和无监督对比学习来训练模型。结果表明，GUR模型在没有任何标记训练数据的情况下取得了令人印象深刻的结果，作为检索器超过了所有其他预训练基线模型。

    In recent years, a significant number of high-quality pretrained models have emerged, greatly impacting Natural Language Understanding (NLU), Natural Language Generation (NLG), and Text Representation tasks. Traditionally, these models are pretrained on custom domain corpora and finetuned for specific tasks, resulting in high costs related to GPU usage and labor. Unfortunately, recent trends in language modeling have shifted towards enhancing performance through scaling, further exacerbating the associated costs.  Introducing GUR: a pretraining framework that combines language modeling and contrastive learning objectives in a single training step. We select similar text pairs based on their Longest Common Substring (LCS) from raw unlabeled documents and train the model using masked language modeling and unsupervised contrastive learning. The resulting model, GUR, achieves impressive results without any labeled training data, outperforming all other pretrained baselines as a retriever a
    
[^2]: NFT到MARS：面向NFT的多注意力推荐系统

    NFTs to MARS: Multi-Attention Recommender System for NFTs. (arXiv:2306.10053v1 [cs.IR])

    [http://arxiv.org/abs/2306.10053](http://arxiv.org/abs/2306.10053)

    本文提出了首个具有三大关键特征——图形注意力、多模态注意力和多任务学习的面向NFT的多注意力推荐系统(NFT-MARS)，以解决NFT市场挑战。

    

    推荐系统已成为增强各个领域用户体验的必备工具。尽管针对电影、音乐和电子商务的推荐系统已进行了广泛研究，但日益增长和经济意义重大的非同质化代币（NFT）市场仍未被充分探索。NFT市场的独特特性和日益突出的地位凸显了开发专门针对其需求的定制推荐系统的重要性，并揭示其充分潜力。本文分析了NFT的独特特性，并提出了首个专门设计以应对NFT市场挑战的推荐系统。具体而言，我们开发了一种面向NFT的多注意力推荐系统(NFT-MARS)，具有三个关键特征：(1)图形注意力以处理稀疏的用户-项目交互;(2)多模态注意力以融入用户的特征偏好;(3)多任务学习来考虑NFT作为艺术作品和数字资产的双重性质。

    Recommender systems have become essential tools for enhancing user experiences across various domains. While extensive research has been conducted on recommender systems for movies, music, and e-commerce, the rapidly growing and economically significant Non-Fungible Token (NFT) market remains underexplored. The unique characteristics and increasing prominence of the NFT market highlight the importance of developing tailored recommender systems to cater to its specific needs and unlock its full potential. In this paper, we examine the distinctive characteristics of NFTs and propose the first recommender system specifically designed to address NFT market challenges. In specific, we develop a Multi-Attention Recommender System for NFTs (NFT-MARS) with three key characteristics: (1) graph attention to handle sparse user-item interactions, (2) multi-modal attention to incorporate feature preference of users, and (3) multi-task learning to consider the dual nature of NFTs as both artwork and
    
[^3]: TOBY:一种用于探索学术调查论文数据的工具

    TOBY: A Tool for Exploring Data in Academic Survey Papers. (arXiv:2306.10051v1 [cs.DL])

    [http://arxiv.org/abs/2306.10051](http://arxiv.org/abs/2306.10051)

    TOBY是一种可视化工具，能帮助用户探索学术调查论文的内容，包括分类层次结构视图、文档相似性视图、引用网络视图和论文推荐工具。

    

    本文介绍了TOBY，一种可视化工具，帮助用户探索学术调查论文的内容。可视化包括四个部分：调查数据的分类层次结构视图，分类类别空间中的文档相似性视图，引用网络视图以及一种新的论文推荐工具。本文将讨论这些功能在三种不同的工具部署情景下的应用。

    This paper describes TOBY, a visualization tool that helps a user explore the contents of an academic survey paper. The visualization consists of four components: a hierarchical view of taxonomic data in the survey, a document similarity view in the space of taxonomic classes, a network view of citations, and a new paper recommendation tool. In this paper, we will discuss these features in the context of three separate deployments of the tool.
    
[^4]: 在推荐系统中插值项目和用户公平性

    Interpolating Item and User Fairness in Recommendation Systems. (arXiv:2306.10050v1 [cs.IR])

    [http://arxiv.org/abs/2306.10050](http://arxiv.org/abs/2306.10050)

    本文研究在推荐系统中平衡项目和用户公平性的框架，并通过低后悔的在线优化算法实现了维持收益同时实现公平推荐的目标。

    

    在多边平台中，平台与卖家（项目）和客户（用户）等各种各样的利益相关者互动，每个相关者都有自己的期望结果，寻找合适的平衡点变得非常复杂。在这项工作中，我们研究了“公平成本”，它捕捉了平台在平衡不同利益相关者利益时可能做出的妥协。出于这个目的，我们提出了一个公平推荐框架，其中平台在插值项目和用户公平性约束时最大化其收益。我们在一个更现实但具有挑战性的在线设置中进一步研究了公平推荐问题，在这种情况下，平台缺乏了解用户偏好的知识，只能观察二进制购买决策。为了解决这个问题，我们设计了一种低后悔的在线优化算法，它在维护平台收益的同时管理项目和用户公平性之间的权衡。我们的实验证明了我们提出的框架在实现公平推荐同时保持高收益方面的有效性。

    Online platforms employ recommendation systems to enhance customer engagement and drive revenue. However, in a multi-sided platform where the platform interacts with diverse stakeholders such as sellers (items) and customers (users), each with their own desired outcomes, finding an appropriate middle ground becomes a complex operational challenge. In this work, we investigate the ``price of fairness'', which captures the platform's potential compromises when balancing the interests of different stakeholders. Motivated by this, we propose a fair recommendation framework where the platform maximizes its revenue while interpolating between item and user fairness constraints. We further examine the fair recommendation problem in a more realistic yet challenging online setting, where the platform lacks knowledge of user preferences and can only observe binary purchase decisions. To address this, we design a low-regret online optimization algorithm that preserves the platform's revenue while
    
[^5]: 基于邻域的难例挖掘用于序列推荐

    Neighborhood-based Hard Negative Mining for Sequential Recommendation. (arXiv:2306.10047v1 [cs.IR])

    [http://arxiv.org/abs/2306.10047](http://arxiv.org/abs/2306.10047)

    本文提出了一种基于邻域重叠的基于图形的负采样方法（GNNO），利用隐藏在用户行为中的结构信息进行负采样，用于增进序列推荐模型的训练和性能。

    

    在训练序列推荐模型时，负采样在其中起着关键作用。目前已经提出了许多策略来挖掘信息丰富的负样本，以强化训练和性能。但是，很少有这些方法利用结构信息。本文观察到在训练过程中，不同程度邻域重叠的不同组节点对相似度的分布发生显着变化，这表明不同组中的项目对可能具有不同的负关系。受此观察的启发，我们提出了一种基于邻域重叠的基于图的负采样方法（GNNO）来利用隐藏在用户行为中的结构信息进行负采样。GNNO首先使用训练序列构建全局加权项目转换图。随后，它根据与目标项的重叠程度来挖掘难例负样本。

    Negative sampling plays a crucial role in training successful sequential recommendation models. Instead of merely employing random negative sample selection, numerous strategies have been proposed to mine informative negative samples to enhance training and performance. However, few of these approaches utilize structural information. In this work, we observe that as training progresses, the distributions of node-pair similarities in different groups with varying degrees of neighborhood overlap change significantly, suggesting that item pairs in distinct groups may possess different negative relationships. Motivated by this observation, we propose a Graph-based Negative sampling approach based on Neighborhood Overlap (GNNO) to exploit structural information hidden in user behaviors for negative mining. GNNO first constructs a global weighted item transition graph using training sequences. Subsequently, it mines hard negative samples based on the degree of overlap with the target item on
    
[^6]: 公共事务领域中文档布局注释：数据库与基准

    Document Layout Annotation: Database and Benchmark in the Domain of Public Affairs. (arXiv:2306.10046v1 [cs.IR])

    [http://arxiv.org/abs/2306.10046](http://arxiv.org/abs/2306.10046)

    该研究介绍了一个基于4个基本布局块和4个文本类别的布局标签的数字文档的半自动注释过程，生成了一个用于公共事务领域的DLA新数据库，以帮助自动处理数字文档。

    

    每天都会生成成千上万个数字文档，其中包含对公司、公共组织和公民有用的信息。鉴于手动处理这些文档的不可能性，在某些行业中自动处理这些文档变得越来越必要。然而，这项任务仍然具有挑战性，因为在大多数情况下，仅基于文本的解析是不足以完全理解通过不同重要性的不同组件呈现的信息的。在这方面，文档布局分析（DLA）多年来一直是一个有趣的研究领域，旨在检测和分类文档的基本组件。在这项工作中，我们使用一种程序对数字文档进行半自动注释，包括4个基本布局块和4个文本类别的不同布局标签。我们应用此程序在20四个来自西班牙政府的数据源上收集了一个公共事务领域的DLA新数据库。该数据库包含......

    Every day, thousands of digital documents are generated with useful information for companies, public organizations, and citizens. Given the impossibility of processing them manually, the automatic processing of these documents is becoming increasingly necessary in certain sectors. However, this task remains challenging, since in most cases a text-only based parsing is not enough to fully understand the information presented through different components of varying significance. In this regard, Document Layout Analysis (DLA) has been an interesting research field for many years, which aims to detect and classify the basic components of a document. In this work, we used a procedure to semi-automatically annotate digital documents with different layout labels, including 4 basic layout blocks and 4 text categories. We apply this procedure to collect a novel database for DLA in the public affairs domain, using a set of 24 data sources from the Spanish Administration. The database comprises 
    
[^7]: 一种用于科学文献中表格实体链接的实用系统。

    A Practical Entity Linking System for Tables in Scientific Literature. (arXiv:2306.10044v1 [cs.IR])

    [http://arxiv.org/abs/2306.10044](http://arxiv.org/abs/2306.10044)

    本文介绍了一个用于将实体链接到知识库中的通用系统，并将其适应于链接特定领域的实体，特别是 COVID-19 相关科学文献中的嵌入式实体。通过利用表格的结构和语义特征，以提高整体实体链接性能。

    

    实体链接是构建知识图谱的重要步骤，可以方便地回答包括从这些文档中检索相关信息在内的高级问题。本文介绍了一种通用的系统，用于将实体链接到维基数据知识库中的项。它描述了如何适应该系统以链接领域特定的实体，特别是那些来自COVID-19相关科学文献中的嵌入式实体。我们描述了系统的离线实例的设置，使我们的实体链接方法在实践中更加可行。作为推断科学表格的语义含义的更广泛方法的一部分，我们利用表格的结构和语义特征来提高整体实体链接性能。

    Entity linking is an important step towards constructing knowledge graphs that facilitate advanced question answering over scientific documents, including the retrieval of relevant information included in tables within these documents. This paper introduces a general-purpose system for linking entities to items in the Wikidata knowledge base. It describes how we adapt this system for linking domain-specific entities, especially for those entities embedded within tables drawn from COVID-19-related scientific literature. We describe the setup of an efficient offline instance of the system that enables our entity-linking approach to be more feasible in practice. As part of a broader approach to infer the semantic meaning of scientific tables, we leverage the structural and semantic characteristics of the tables to improve overall entity linking performance.
    
[^8]: 一种用于Aspect Sentiment Triplet Extraction的配对增强方法

    A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction. (arXiv:2306.10042v1 [cs.IR])

    [http://arxiv.org/abs/2306.10042](http://arxiv.org/abs/2306.10042)

    本文提出了一种配对增强方法，通过对比学习将方面-意见配对知识注入到Aspect Sentiment Triplet Extraction（ASTE）模型中，提高了三元组提取的准确性和性能。

    

    Aspect Sentiment Triplet Extraction（ASTE）旨在从评论文本中提取一个方面术语、一个意见术语和它们相应的情感极性的三元组。由于语言的复杂性和单个句子中存在多个方面术语和意见术语，当前的模型经常会混淆描述它的方面术语和意见术语之间的联系。为了解决这个问题，我们提出了一种配对增强方法，它在训练阶段采用对比学习，将方面-意见配对知识注入到三元组提取模型中。实验结果表明，与几种相关经典和最先进的三元组提取方法相比，我们的方法在四个ASTE数据集（即14lap，14res，15res和16res）上表现良好。此外，消融研究进行分析并验证了对比学习相比其他配对增强方法的优势。

    Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplet of an aspect term, an opinion term, and their corresponding sentiment polarity from the review texts. Due to the complexity of language and the existence of multiple aspect terms and opinion terms in a single sentence, current models often confuse the connections between an aspect term and the opinion term describing it. To address this issue, we propose a pairing enhancement approach for ASTE, which incorporates contrastive learning during the training stage to inject aspect-opinion pairing knowledge into the triplet extraction model. Experimental results demonstrate that our approach performs well on four ASTE datasets (i.e., 14lap, 14res, 15res and 16res) compared to several related classical and state-of-the-art triplet extraction methods. Moreover, ablation studies conduct an analysis and verify the advantage of contrastive learning over other pairing enhancement approaches.
    
[^9]: 基于Transformer的时空数据分析在揭示商业轨迹方面的应用研究

    Unlocking Insights into Business Trajectories with Transformer-based Spatio-temporal Data Analysis. (arXiv:2306.10034v1 [cs.IR])

    [http://arxiv.org/abs/2306.10034](http://arxiv.org/abs/2306.10034)

    本研究利用新闻文章数据，采用Transformer模型模拟商业轨迹，揭示商业趋势和行业表现。

    

    商业世界持续发展，保持领先需要深入理解市场趋势和业绩。本文通过模拟商业轨迹，利用新闻文章数据来满足这一需求。

    The world of business is constantly evolving and staying ahead of the curve requires a deep understanding of market trends and performance. This article addresses this requirement by modeling business trajectories using news articles data.
    
[^10]: 采用分层嵌入和会话属性的伪会话推荐

    Pseudo session-based recommendation with hierarchical embedding and session attributes. (arXiv:2306.10029v1 [cs.IR])

    [http://arxiv.org/abs/2306.10029](http://arxiv.org/abs/2306.10029)

    本文提出了一种新方法CoHHGN+，用于解决缺乏用户ID的电商网站数据的推荐问题。该方法使用了定义的伪会话以及包括价格、类别、性别和地区等用户信息，得到了较好的推荐结果。

    

    最近，由于隐私问题，电子商务网站无法为每个交易数据条目提供标识号（用户ID）。因为大多数推荐方法假定所有数据都被分配了用户ID，所以它们不能应用于没有用户ID的数据。最近研究了基于会话信息的会话推荐（SBR），该方法基于用户的短期行为信息。常规的SBR只使用与感兴趣的项目相关的信息来进行推荐（例如，在EC站点上使用项目ID）。特别是在EC网站的情况下，记录的数据包括被购买的物品名称、物品价格、类别层次结构以及用户的性别和地区。在本研究中，我们为没有用户ID和会话ID的EC网站的购买历史数据定义了伪会话。最后，我们提出了一种CoHHGN+会话推荐方法，它使用协同导向的异构超图和全局图网络。

    Recently, electronic commerce (EC) websites have been unable to provide an identification number (user ID) for each transaction data entry because of privacy issues. Because most recommendation methods assume that all data are assigned a user ID, they cannot be applied to the data without user IDs. Recently, session-based recommendation (SBR) based on session information, which is short-term behavioral information of users, has been studied. A general SBR uses only information about the item of interest to make a recommendation (e.g., item ID for an EC site). Particularly in the case of EC sites, the data recorded include the name of the item being purchased, the price of the item, the category hierarchy, and the gender and region of the user. In this study, we define a pseudo--session for the purchase history data of an EC site without user IDs and session IDs. Finally, we propose an SBR with a co-guided heterogeneous hypergraph and globalgraph network plus, called CoHHGN+. The result
    
[^11]: 基于图的长短期兴趣模型用于点击率预测

    Graph Based Long-Term And Short-Term Interest Model for Click-Through Rate Prediction. (arXiv:2306.10028v1 [cs.IR])

    [http://arxiv.org/abs/2306.10028](http://arxiv.org/abs/2306.10028)

    本论文提出了一种名为GLSM的基于图的长期和短期兴趣模型，可以很好地处理长期和短期用户兴趣数据的问题。

    

    点击率预测旨在预测用户点击项的概率，是在线推荐和广告系统中的关键任务之一。在这样的系统中，丰富的用户行为（即长期和短期）已被证明对捕捉用户兴趣非常有价值。工业界和学术界都对这个主题非常关注，并提出了不同的方法来建模长期和短期用户行为数据。但仍存在一些未解决的问题。更具体地说，（1）基于规则和截断的方法从长期行为中提取信息易导致信息丢失，（2）从短期行为中提取信息时单一反馈行为无论场景都会导致信息混淆和噪声。为了填补这一空白，我们提出了一种基于图的长期和短期兴趣模型，称为GLSM。它由一个多兴趣图结构组成，用于捕捉长期用户行为，一个多场景兴趣子图用于捕捉短期用户行为。

    Click-through rate (CTR) prediction aims to predict the probability that the user will click an item, which has been one of the key tasks in online recommender and advertising systems. In such systems, rich user behavior (viz. long- and short-term) has been proved to be of great value in capturing user interests. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long-term and short-term user behavior data. But there are still some unresolved issues. More specially, (1) rule and truncation based methods to extract information from long-term behavior are easy to cause information loss, and (2) single feedback behavior regardless of scenario to extract information from short-term behavior lead to information confusion and noise. To fill this gap, we propose a Graph based Long-term and Short-term interest Model, termed GLSM. It consists of a multi-interest graph structure for capturing long-term user behavior, a multi-scenari
    
[^12]: 分解和交错用于减少后点击度量的方差

    Decomposition and Interleaving for Variance Reduction of Post-click Metrics. (arXiv:2306.10024v1 [cs.IR])

    [http://arxiv.org/abs/2306.10024](http://arxiv.org/abs/2306.10024)

    本研究提出了一种有效的方法，通过分解和交错多个排名的后点击度量以减少样本方差。该方法专注于测量多个排名中每个项目的后点击度量，并优化排名以暴露具有高群体方差的项目。

    

    本研究提出了一种比较多个排名后点击度量（例如停留时间和转化率）的有效方法。所提出的方法涉及（1）将排名的后点击度量测量分解为点击模型估计和排名中每个项的后点击度量测量，以及（2）交错多个排名以生成一个偏好暴露具有高群体方差的项目的单个排名。后点击度量测量的分解使得可以在排名中自由布局项目，并专注于多个排名中每个项目的后点击度量的测量。多个排名的交错通过优化展示给用户的排名，以便那些项目接收更多的后点击度量样本，从而减少具有高群体方差的项目的样本方差。此外，我们还提供了一个证明，证明所提出的方法可以显著地降低后点击度量的样本方差。

    In this study, we propose an efficient method for comparing the post-click metric (e.g., dwell time and conversion rate) of multiple rankings in online experiments. The proposed method involves (1) the decomposition of the post-click metric measurement of a ranking into a click model estimation and a post-click metric measurement of each item in the ranking, and (2) interleaving of multiple rankings to produce a single ranking that preferentially exposes items possessing a high population variance. The decomposition of the post-click metric measurement enables the free layout of items in a ranking and focuses on the measurement of the post-click metric of each item in the multiple rankings. The interleaving of multiple rankings reduces the sample variance of the items possessing a high population variance by optimizing a ranking to be presented to the users so that those items received more samples of the post-click metric. In addition, we provide a proof that the proposed method leads
    
[^13]: 对交错比较效率的理论分析

    Theoretical Analysis on the Efficiency of Interleaved Comparisons. (arXiv:2306.10023v1 [cs.IR])

    [http://arxiv.org/abs/2306.10023](http://arxiv.org/abs/2306.10023)

    本研究对交错比较方法的效率进行了理论分析，发现当用户根据相关性离开排名时，交错比较比A/B测试更为有效。

    

    本研究针对一种用于排名的高效在线评估方法——交错比较，进行了效率的理论分析。虽然交错比较已经应用于实际系统中，但其高效率的源头在文献中尚未得到明确的阐述。因此，本研究设计了一个类似于普通交错比较方法的简单交错比较方法，并探索了一种条件，该条件下交错比较方法比A/B测试更有效。其中的条件是，当用户根据物品的相关性来离开排名时（这是点击模型中的一个典型假设），这种情况就会出现。最后，我们还基于数值分析和用户模拟进行实验，证明了理论结果与实证结果是一致的。

    This study presents a theoretical analysis on the efficiency of interleaving, an efficient online evaluation method for rankings. Although interleaving has already been applied to production systems, the source of its high efficiency has not been clarified in the literature. Therefore, this study presents a theoretical analysis on the efficiency of interleaving methods. We begin by designing a simple interleaving method similar to ordinary interleaving methods. Then, we explore a condition under which the interleaving method is more efficient than A/B testing and find that this is the case when users leave the ranking depending on the item's relevance, a typical assumption made in click models. Finally, we perform experiments based on numerical analysis and user simulation, demonstrating that the theoretical results are consistent with the empirical results.
    
[^14]: 基于粒神经网络的新闻推荐渠道研究

    The News Delivery Channel Recommendation Based on Granular Neural Network. (arXiv:2306.10022v1 [cs.IR])

    [http://arxiv.org/abs/2306.10022](http://arxiv.org/abs/2306.10022)

    本文提出了一种基于粒神经网络的新闻推荐模型，通过分析新闻的特性来推荐适当的渠道。

    

    随着神经网络技术的不断成熟和扩展，深度神经网络已经被广泛应用于各种应用程序中，包括语音识别、机器翻译、图像处理以及推荐系统的创建。因此，许多复杂的实际问题都可以通过深度学习技术得到解决。本文提出了一种使用粒神经网络模型推荐新闻到适当的渠道的推荐模型，通过分析新闻的特性。具体来说，一种特定的神经网络被认为是粒神经网络建模的基础。

    With the continuous maturation and expansion of neural network technology, deep neural networks have been widely utilized as the fundamental building blocks of deep learning in a variety of applications, including speech recognition, machine translation, image processing, and the creation of recommendation systems. Therefore, many real-world complex problems can be solved by the deep learning techniques. As is known, traditional news recommendation systems mostly employ techniques based on collaborative filtering and deep learning, but the performance of these algorithms is constrained by the sparsity of the data and the scalability of the approaches. In this paper, we propose a recommendation model using granular neural network model to recommend news to appropriate channels by analyzing the properties of news. Specifically, a specified neural network serves as the foundation for the granular neural network that the model is considered to be build. Different information granularities 
    
[^15]: RecFusion：基于二项式扩散过程的1D数据推荐模型

    RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation. (arXiv:2306.08947v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.08947](http://arxiv.org/abs/2306.08947)

    本文提出了 RecFusion，一种特定针对1D和/或二进制设置的推荐模型方法，其利用了二项式扩散过程对二元用户-项目交互进行显式建模，并在核心推荐设置和最常见的数据集上接近复杂的VAE基线的表现。

    

    本文提出了RecFusion，这是一组用于推荐的扩散模型。不同于包含空间相关性的图像数据，常用于推荐的用户-项目交互矩阵缺乏用户和项目之间的空间关系。我们在一个一维向量上制定了扩散方法，并提出了二项式扩散，这个方法利用了伯努利过程显式地对二元用户-项目交互进行建模。我们展示了RecFusion在核心推荐设置（针对二进制非顺序反馈的前n项推荐）和最常见的数据集（MovieLens和Netflix）上接近于复杂的VAE基线的表现。我们提出的专门针对1D和/或二进制设置的扩散模型的意义超出了推荐系统，例如在医学领域中使用MRI和CT扫描。

    In this paper we propose RecFusion, which comprise a set of diffusion models for recommendation. Unlike image data which contain spatial correlations, a user-item interaction matrix, commonly utilized in recommendation, lacks spatial relationships between users and items. We formulate diffusion on a 1D vector and propose binomial diffusion, which explicitly models binary user-item interactions with a Bernoulli process. We show that RecFusion approaches the performance of complex VAE baselines on the core recommendation setting (top-n recommendation for binary non-sequential feedback) and the most common datasets (MovieLens and Netflix). Our proposed diffusion models that are specialized for 1D and/or binary setups have implications beyond recommendation systems, such as in the medical domain with MRI and CT scans.
    
[^16]: 当评分很重要时的学习排序

    Learning to Rank when Grades Matter. (arXiv:2306.08650v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.08650](http://arxiv.org/abs/2306.08650)

    本论文提出了一种学习排序和成绩预测的多目标函数，可以在真实应用中更好地平衡排序和成绩，优于现有方法。

    

    在真实世界中的学习排序应用中，分级标签广泛存在，特别是在人工标注的相关性数据中。传统的学习排序技术旨在优化文件的排序顺序。然而，它们通常忽略了实际分数的预测。这使它们无法在需要考虑分数的应用程序中被采用，例如筛选“劣质”文件。在良好的排序性能和良好的等级预测性能之间取得平衡仍然是一个未经探索的问题。现有的研究要么只关注排序性能而不校准模型输出，要么将成绩视为数值，假设标签在线性范围内，并未利用序数级别信息。本文对学习排序与成绩进行了深入研究，同时重视排序性能和等级预测性能。我们提供了关于如何使用非标量分级进行排名的形式化讨论，并提出了一个多目标函数，用于联合优化排序和成绩预测性能。基于两个真实数据集的实验表明，我们的方法在排序和等级预测性能方面均显著优于现有方法。

    Graded labels are ubiquitous in real-world learning-to-rank applications, especially in human rated relevance data. Traditional learning-to-rank techniques aim to optimize the ranked order of documents. They typically, however, ignore predicting actual grades. This prevents them from being adopted in applications where grades matter, such as filtering out ``poor'' documents. Achieving both good ranking performance and good grade prediction performance is still an under-explored problem. Existing research either focuses only on ranking performance by not calibrating model outputs, or treats grades as numerical values, assuming labels are on a linear scale and failing to leverage the ordinal grade information. In this paper, we conduct a rigorous study of learning to rank with grades, where both ranking performance and grade prediction performance are important. We provide a formal discussion on how to perform ranking with non-scalar predictions for grades, and propose a multiobjective f
    
[^17]: KuaiSAR: 一份统一的搜索与推荐数据集

    KuaiSAR: A Unified Search And Recommendation Dataset. (arXiv:2306.07705v1 [cs.IR])

    [http://arxiv.org/abs/2306.07705](http://arxiv.org/abs/2306.07705)

    这篇论文介绍了一份大规模、真实的数据集KuaiSAR，该数据集记录了快手短视频应用程序中真实的集成搜索和推荐行为。

    

    搜索和推荐服务的融合是像快手和抖音这样的在线内容平台的重要方面。S&R建模的整合是业界实践者采用的高度直观的方法。然而，由于缺乏公开可用的数据集，学术界在这个领域中进行的研究明显不足。因此，在学术界和产业界之间在这个领域进行研究的实践之间出现了实质性的差距。为了弥合这个差距，我们介绍了快手的一个领先短视频应用程序收集的集成搜索与推荐行为的大规模真实世界数据集KuaiSAR。与以前的数据集不同，KuaiSAR记录了真实用户的行为，每个行为的发生时间都被精确记录了。

    The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each in
    
[^18]: 图谱遇见LLM：一种用于稳健对话理解的协同过滤新方法

    Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding. (arXiv:2305.14449v1 [cs.AI])

    [http://arxiv.org/abs/2305.14449](http://arxiv.org/abs/2305.14449)

    一种协同过滤新方法用于稳健对话理解，在历史用户-实体交互的基础上，利用多跳客户亲和力丰富每个用户的索引，并使用有限内存BFGS算法调整每个索引的权重，实验结果显示其明显优于最先进的个性化查询重写方法。

    

    会话式人工智能系统（例如Alexa，Siri，Google Assistant等）需要理解存在缺陷的查询以确保稳健的会话理解并减少用户摩擦。这些有缺陷的查询通常是由用户的歧义和错误，自动语音识别（ASR）和自然语言理解（NLU）中的错误引起的。个性化查询重写（个性化QR）旨在减少身体和尾部用户查询流量中的缺陷，通常依赖于与对话式人工智能的过去成功的用户交互的索引。本文提出我们的“协同查询重写”方法，专注于重写用户历史中没有出现过的新型用户交互。该方法构建了一个“用户反馈交互图”（FIG），由历史用户-实体交互组成，并利用多跳客户亲和力来丰富每个用户的索引（即协同用户索引），从而帮助覆盖未来未曾见过的存在缺陷的查询。为了防止这些新的丰富索引被噪声反馈交互所支配，我们采用了有限内存BFGS（LLM）算法和回退方案来调整每个索引的权重。实验结果表明，我们的方法明显优于最先进的个性化QR方法，并在未看到的用户交互上取得了近乎完美的性能。

    Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU).  Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our "Collaborative Query Rewriting" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a "user Feedback Interaction Graph" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract th
    
[^19]: 探索用于相关性预测的合成查询生成的可行性

    Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])

    [http://arxiv.org/abs/2305.11944](http://arxiv.org/abs/2305.11944)

    本文研究在电子商务和医疗保健等专业领域中，利用强大的模型生成高质量特定任务和领域的合成数据，探索用于预测对文档的查询分级相关性的方法，并尝试使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    

    查询-文档相关性预测是信息检索系统中的一个关键问题。这个问题越来越多地使用（预先训练的）基于转换器的模型来解决，这些模型使用大量标记数据进行微调。然而，在电子商务和医疗保健等专业领域，这种方法的可行性受到领域内大规模数据的匮乏限制。为了解决这个问题，最近的方法利用这些强大的模型生成高质量的特定任务和领域的合成数据。先前的工作主要探索了合成数据生成或用于问答和二元（是/否）相关性预测的查询生成（QGen）, 其中例如，QGen模型给出一个文档，并训练生成一个与该文档相关的查询。然而，在许多问题中，我们对相关性有一个更细粒度的概念，而不是一个简单的是/否标签。因此，在这项工作中，我们进行了详细的研究，探讨了如何利用QGen方法实现细微的相关性预测。具体而言，我们研究了使用合成查询来预测对文档的查询分级相关性的有效性，并探索使用无监督聚类技术进一步改进对数据中相关性模式的理解。

    Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced
    
[^20]: 重访基于预训练语言模型的k-NN

    Revisiting k-NN for Pre-trained Language Models. (arXiv:2304.09058v1 [cs.CL])

    [http://arxiv.org/abs/2304.09058](http://arxiv.org/abs/2304.09058)

    本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。

    

    预训练语言模型（PLMs）作为参数化的急切学习器，已成为自然语言处理（NLP）当前范式的实际选择。与此形成对比的是，k-最近邻（k-NN）分类器作为延迟学习模型，倾向于减轻过拟合和孤立噪声。本文中我们重访了k-NN分类器，以增强基于PLMs的分类器。从方法层面上，我们提出采用文本表示的PLMs在两个步骤中采用k-NN：（1）利用k-NN作为先验知识来校准训练过程（2）线性插值k-NN预测的概率分布和PLMs分类器的概率分布。我们的方法核心是实现了k-NN校准训练，将预测结果作为训练过程中易于和难以学习的示例的指标。从应用场景多样性的角度出发，我们在各种基准数据集上进行了广泛的微调、提示微调范式和零样本任务设置的实验。我们的结果表明，结合k-NN可以在所有受到检查的设置中持续提高PLMs的性能，并且在所有受到考虑的设置中跑赢了基于普通PLMs的方法。

    Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-sh
    
[^21]: Probe：学习用户在时间跨度的捆绑选择中的个性化投影偏差

    Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices. (arXiv:2303.06016v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06016](http://arxiv.org/abs/2303.06016)

    本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。

    

    时间跨度的选择需要权衡现在的成本和未来的收益。其中一种具体的选择是决定购买单个物品还是选择包含该物品的捆绑销售方式。以往的研究假设个人对这些选择中涉及的因素有准确的期望。然而，在现实中，用户对这些因素的感知往往存在偏差，导致了非理性和次优的决策。本文重点关注两种常见的偏差：投影偏差和参照点效应，并为此提出了一种新颖的偏差嵌入式偏好模型——Probe。该模型利用加权函数来捕捉用户的投影偏差，利用价值函数来考虑参照点效应，并引入行为经济学中的前景理论来组合加权和价值函数。这使得我们能够确定用户购买捆绑销售的概率，从而提高决策的有效性和个性化。

    Intertemporal choices involve making decisions that require weighing the costs in the present against the benefits in the future. One specific type of intertemporal choice is the decision between purchasing an individual item or opting for a bundle that includes that item. Previous research assumes that individuals have accurate expectations of the factors involved in these choices. However, in reality, users' perceptions of these factors are often biased, leading to irrational and suboptimal decision-making. In this work, we specifically focus on two commonly observed biases: projection bias and the reference-point effect. To address these biases, we propose a novel bias-embedded preference model called Probe. The Probe incorporates a weight function to capture users' projection bias and a value function to account for the reference-point effect, and introduce prospect theory from behavioral economics to combine the weight and value functions. This allows us to determine the probabili
    
[^22]: Pacos: 建模用户的可解释和上下文依赖选择以处理偏好逆转问题

    Pacos: Modeling Users' Interpretable and Context-Dependent Choices in Preference Reversals. (arXiv:2303.05648v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.05648](http://arxiv.org/abs/2303.05648)

    Pacos是一个上下文依赖的偏好模型，可以处理偏好逆转问题，并提供用户的自适应权重、比较和显示位置等可解释因素，有助于提供个性化服务。

    

    选择问题是指从多个项目中选择最佳选择，学习用户在选择问题中的偏好对于理解决策机制和提供个性化服务具有重要意义。现有的研究通常假设人们独立地评估项目。在实践中，但是用户的偏好取决于项目所处的市场，这被称为上下文效应；而用户对两个项目的偏好顺序甚至可能被颠倒，这被称为偏好逆转。本文识别了导致上下文效应的三个因素：用户的自适应权重、项目之间的比较和显示位置。我们提出了一个名为Pacos的上下文依赖偏好模型作为统一框架来同时解决这三个因素，并考虑了两种设计方法，包括具有高可解释性的加性方法和具有高准确性的基于ANN的方法。我们研究了基于各种市场情景和模型参数的偏好逆转条件，并展示了Pacos可以有效地捕捉偏好逆转。此外，Pacos可以提供上下文效应和用户自适应行为的可解释指示，有助于提供个性化服务。

    Choice problems refer to selecting the best choices from several items, and learning users' preferences in choice problems is of great significance in understanding the decision making mechanisms and providing personalized services. Existing works typically assume that people evaluate items independently. In practice, however, users' preferences depend on the market in which items are placed, which is known as context effects; and the order of users' preferences for two items may even be reversed, which is referred to preference reversals. In this work, we identify three factors contributing to context effects: users' adaptive weights, the inter-item comparison, and display positions. We propose a context-dependent preference model named Pacos as a unified framework for addressing three factors simultaneously, and consider two design methods including an additive method with high interpretability and an ANN-based method with high accuracy. We study the conditions for preference reversa
    
[^23]: 序列推荐的互Wasserstein距离最小化算法

    Mutual Wasserstein Discrepancy Minimization for Sequential Recommendation. (arXiv:2301.12197v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12197](http://arxiv.org/abs/2301.12197)

    本文提出了一种基于互Wasserstein距离最小化的新型自监督学习框架用于提高推荐系统的性能，该方法使用Wasserstein距离测量来增强互信息最大化，优于现有的几种顺序推荐方法。

    

    自监督的顺序推荐通过最大化互信息和设计良好的数据增广显著提高了推荐系统的性能。然而, 目前的互信息估计基于计算Kullback Leibler差异，并且存在许多局限性，包括非对称估计、指数样本大小需求和训练不稳定。而使用的现有数据增广大多是随机的，可能会因为随机修改而破坏顺序相关性。因此，我们提出了一种基于互Wasserstein距离最小化的新型自监督学习框架来解决这些问题，提出了Wasserstein距离测量来评估增广序列之间的互信息，通过减少原始和增广序列的概率分布之间的距离，增强互信息最大化。在实际数据集上进行的实验结果表明，我们的方法优于现有的几种顺序推荐方法。

    Self-supervised sequential recommendation significantly improves recommendation performance by maximizing mutual information with well-designed data augmentations. However, the mutual information estimation is based on the calculation of Kullback Leibler divergence with several limitations, including asymmetrical estimation, the exponential need of the sample size, and training instability. Also, existing data augmentations are mostly stochastic and can potentially break sequential correlations with random modifications. These two issues motivate us to investigate an alternative robust mutual information measurement capable of modeling uncertainty and alleviating KL divergence limitations. To this end, we propose a novel self-supervised learning framework based on Mutual WasserStein discrepancy minimization MStein for the sequential recommendation. We propose the Wasserstein Discrepancy Measurement to measure the mutual information between augmented sequences. Wasserstein Discrepancy M
    
[^24]: MASTER:多任务预训练的瓶颈掩蔽自编码器比密集型检索器更好

    MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers. (arXiv:2212.07841v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07841](http://arxiv.org/abs/2212.07841)

    本文提出了一个名为MASTER的多任务预训练模型，利用瓶颈掩蔽自编码器统一各种预训练任务，并将其集成到一个模型中。该模型在两个广泛使用的数据集上的实验表明，相比同等模型大小和预训练资源的最先进密集检索模型，MASTER表现更好。

    

    现有的密集检索方法中，预训练的Transformer（如BERT）通常用于参数初始化，最近的研究正在探索更有效的预训练任务，以进一步提高密集向量的质量。虽然已经提出了各种新颖而有效的任务，但它们不同的输入格式和学习目标使它们难以被整合起来共同提高模型性能。本文旨在将各种预训练任务统一成瓶颈掩蔽自编码器，将它们整合到一个多任务预训练模型中，名为MASTER。具体来说，MASTER利用共享编码器多解码器架构，可以构造表示瓶颈，将跨各种任务的丰富语义信息压缩成密集向量。基于此，我们整合了三种代表性的预训练任务：破损段落恢复、相关段落恢复和PLMs输出恢复，以同时进行转录、索引和QA。我们在两个广泛使用的数据集上的实验表明，MASTER在相同的模型大小和预训练资源下优于最先进的密集检索模型，表明了将各种预训练任务以统一的格式集成的有效性。

    Pre-trained Transformers (\eg BERT) have been commonly used in existing dense retrieval methods for parameter initialization, and recent studies are exploring more effective pre-training tasks for further improving the quality of dense vectors. Although various novel and effective tasks have been proposed, their different input formats and learning objectives make them hard to be integrated for jointly improving the model performance. In this work, we aim to unify a variety of pre-training tasks into the bottlenecked masked autoencoder manner, and integrate them into a multi-task pre-trained model, namely MASTER. Concretely, MASTER utilizes a shared-encoder multi-decoder architecture that can construct a representation bottleneck to compress the abundant semantic information across tasks into dense vectors. Based on it, we integrate three types of representative pre-training tasks: corrupted passages recovering, related passages recovering and PLMs outputs recovering, to characterize t
    
[^25]: XSimGCL：面向极简推荐图形对比学习的探索

    XSimGCL: Towards Extremely Simple Graph Contrastive Learning for Recommendation. (arXiv:2209.02544v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2209.02544](http://arxiv.org/abs/2209.02544)

    本文提出一种极简的推荐图形对比学习方法(XSimGCL)，发现有效减轻流行度偏见与促进长尾物品发现并不需要过多的图形增强。

    

    最近，对比学习(Contrastive learning, CL)在提高推荐系统性能方面扮演着重要角色。基于CL的推荐模型的原理是: 确保从用户-物品二分图的不同图形增强中派生的表示一致性。这种自监督方法可以从原始数据中提取通用特征，减轻数据稀疏性的问题。尽管这种方法很有效，但是其性能提升的因素尚未被完全理解。本文提出了对CL对推荐的影响的新见解。我们的发现表明，CL使模型学习到更均匀分布的用户和物品表示，从而减轻了盛行的流行度偏见，促进了长尾物品的发现。我们的分析还表明，之前认为必不可少的图形增强在基于CL的推荐中相对不可靠且影响有限。

    Contrastive learning (CL) has recently been demonstrated critical in improving recommendation performance. The underlying principle of CL-based recommendation models is to ensure the consistency between representations derived from different graph augmentations of the user-item bipartite graph. This self-supervised approach allows for the extraction of general features from raw data, thereby mitigating the issue of data sparsity. Despite the effectiveness of this paradigm, the factors contributing to its performance gains have yet to be fully understood. This paper provides novel insights into the impact of CL on recommendation. Our findings indicate that CL enables the model to learn more evenly distributed user and item representations, which alleviates the prevalent popularity bias and promoting long-tail items. Our analysis also suggests that the graph augmentations, previously considered essential, are relatively unreliable and of limited significance in CL-based recommendation. B
    
[^26]: VFed-SSD：面向实用的垂直联邦广告

    VFed-SSD: Towards Practical Vertical Federated Advertising. (arXiv:2205.15987v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15987](http://arxiv.org/abs/2205.15987)

    本文提出了一种半监督分裂知识蒸馏框架VFed-SSD，用于改善广告模型的学习效果。该框架利用未标记的相互重叠的数据，并通过分解联邦模型来在模型性能和推理效率之间保持平衡。实验结果在真实数据集上表明，VFed-SSD相对于其他最先进的垂直联合学习方法具有更高的预测准确性和推理效率。

    

    垂直联邦学习是一种新兴的安全学习范式，利用跨机构私有数据，旨在通过启用广告主和发布者私有拥有的互补用户属性的联合学习来改进广告模型。然而，将它应用到广告系统时存在两个关键挑战：a）标记重叠样本的有限规模，以及b）实时跨机构服务的高成本。为了缓解这两个限制，本文提出了一种半监督分裂知识蒸馏框架VFed-SSD。我们认为：i）在广告系统中有大量未标记的重叠数据可用，ii）通过分解联邦模型，我们可以在模型性能和推理成本之间保持平衡。

    As an emerging secure learning paradigm in lever-aging cross-agency private data, vertical federatedlearning (VFL) is expected to improve advertising models by enabling the joint learning of complementary user attributes privately owned by the advertiser and the publisher. However, there are two key challenges in applying it to advertising systems: a) the limited scale of labeled overlapping samples, and b) the high cost of real-time cross-agency serving. In this paper, we propose a semi-supervised split distillation framework VFed-SSD to alleviate the two limitations. We identify that: i)there are massive unlabeled overlapped data available in advertising systems, and ii) we can keep a balance between model performance and inference cost by decomposing the federated model. Specifically, we develop a self-supervised task MatchedPair Detection (MPD) to exploit the vertically partitioned unlabeled data and propose the Split Knowledge Distillation (SplitKD) schema to avoid cross-agency se
    

