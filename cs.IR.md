# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Indexing Portuguese NLP Resources with PT-Pump-Up.](http://arxiv.org/abs/2401.15400) | 本文介绍了PT-Pump-Up，一套旨在提高葡萄牙语自然语言处理资源可访问性的工具，并包括了一个Web平台、一个客户端Python软件包、一个管理平台的管理Python软件包和一个公共GitHub存储库。 |
| [^2] | [Privacy-Preserving Cross-Domain Sequential Recommendation.](http://arxiv.org/abs/2401.15369) | 本论文提出了一种隐私保护的跨领域顺序推荐系统（PriCDSR），可以在提供推荐服务的同时保护用户的隐私。 |
| [^3] | [A Survey on Neural Topic Models: Methods, Applications, and Challenges.](http://arxiv.org/abs/2401.15351) | 这篇综述调研了神经主题模型的方法、应用和挑战，对于短文本和跨语言文档等各种场景提供了系统性的组织和介绍，并讨论了广泛应用的一系列热门应用。 |
| [^4] | [Music Auto-Tagging with Robust Music Representation Learned via Domain Adversarial Training.](http://arxiv.org/abs/2401.15323) | 该研究通过领域对抗训练(DAT)方法提出了一种改善嘈杂环境中音乐自动标记性能的方法。该方法通过额外的预训练阶段和添加合成的嘈杂音乐数据，获得了鲁棒的音乐表示，并在音乐自动标记方面展现了增强的性能。 |
| [^5] | [Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models.](http://arxiv.org/abs/2401.15269) | 本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。 |
| [^6] | [Training Differentially Private Ad Prediction Models with Semi-Sensitive Features.](http://arxiv.org/abs/2401.15246) | 我们介绍了一种新的算法，用于训练具有半敏感特征的差分隐私广告预测模型，并在真实广告数据集上证明了其优于传统方法的效果。 |
| [^7] | [The Power of Noise: Redefining Retrieval for RAG Systems.](http://arxiv.org/abs/2401.14887) | 本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。 |
| [^8] | [PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering.](http://arxiv.org/abs/2401.12590) | PolyCF是一个灵活的图信号滤波器，通过多项式图过滤器处理交互信号，能够捕捉多个特征空间中的谱特征，并近似恢复丢失的交互，旨在实现最优的协同过滤。 |
| [^9] | [Knowledge Navigation: Inferring the Interlocking Map of Knowledge from Research Trajectories.](http://arxiv.org/abs/2401.11742) | 本研究利用自然语言处理技术引入了一种创新的嵌入方案，推断出了知识交错地图，揭示了知识之间错综复杂的联系，并展示了多个应用场景。 |
| [^10] | [Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation.](http://arxiv.org/abs/2401.11648) | 通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。 |
| [^11] | [Location Sensitive Embedding for Knowledge Graph Embedding.](http://arxiv.org/abs/2401.10893) | 这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。 |
| [^12] | [Knowledge graph driven recommendation model of graph neural network.](http://arxiv.org/abs/2401.10244) | 提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。 |
| [^13] | [Denoising Diffusion Recommender Model.](http://arxiv.org/abs/2401.06982) | 该论文提出了一种去噪扩散推荐模型（DDRM），通过在推荐模型中注入噪声并利用扩散模型进行多步去噪过程，增强用户和项目嵌入的鲁棒性。 |
| [^14] | [Uncertain research country rankings. Should we continue producing uncertain rankings?.](http://arxiv.org/abs/2312.17560) | 这项研究对基于引用的国家排名进行了分析，发现这些排名可能对日本的科研地位进行错误的分类。研究还发现了引用分布的偏离情况，并评估了其对评估的影响。 |
| [^15] | [A Survey on Query-based API Recommendation.](http://arxiv.org/abs/2312.10623) | 这项调研研究了过去10年发表的API推荐研究，通过对API推荐工具的结构、数据来源和收集方法以及常见数据表示等方面的分析，提出了四个关键研究问题。 |
| [^16] | [Knowledge Graph Reasoning Based on Attention GCN.](http://arxiv.org/abs/2312.10049) | 本论文通过将图卷积神经网络（GCN）与注意力机制相结合，提出了一种新颖的技术来增强知识图谱推理，通过检查实体之间及其邻居节点之间的关系以及整合实体的属性和相互作用，生成丰富的隐式特征向量，以提高实体分类和链接预测等任务的性能。 |
| [^17] | [Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank.](http://arxiv.org/abs/2309.15560) | 研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。 |
| [^18] | [Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder.](http://arxiv.org/abs/2305.16304) | 本论文提出了一种使用两阶段模式结合预先计算图像嵌入和参考文本-候选项三元组交互选择的方式进行组合图像检索候选集重排序的方法。 |
| [^19] | [ConvGQR: Generative Query Reformulation for Conversational Search.](http://arxiv.org/abs/2305.15645) | 本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。 |
| [^20] | [Fast and exact fixed-radius neighbor search based on sorting.](http://arxiv.org/abs/2212.07679) | SNN是一种新的固定半径近邻搜索方法，通过排序和使用高级BLAS实现，能够显著提高查询和索引时间，返回精确结果，并且无需参数调整。 |
| [^21] | [DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles.](http://arxiv.org/abs/2207.01079) | 本文提出了一个新型挑战任务，即通过远程监督方式从科学文章中的表格中提取有关材料组成的信息。为此，研究者创建了一个包含4408个远程监督表格和1475个手动注释的开发和测试表格的训练数据集，并提出了一个强基线——DiSCoMaT。 |

# 详细

[^1]: 使用PT-Pump-Up索引葡萄牙自然语言处理资源

    Indexing Portuguese NLP Resources with PT-Pump-Up. (arXiv:2401.15400v1 [cs.CL])

    [http://arxiv.org/abs/2401.15400](http://arxiv.org/abs/2401.15400)

    本文介绍了PT-Pump-Up，一套旨在提高葡萄牙语自然语言处理资源可访问性的工具，并包括了一个Web平台、一个客户端Python软件包、一个管理平台的管理Python软件包和一个公共GitHub存储库。

    

    自然语言处理(NLP)的最新进展与需要大量语料库的训练过程相关。由于资源分散和需要维护这些基础设施的在线和更新，访问这些数据通常不是一个简单的过程。由于缺乏数据和适当的资源管理基础设施，低资源和中资源语言（如葡萄牙语）在NLP方面的新发展往往受到限制。在这项工作中，我们提出了PT-Pump-Up，一套旨在减少资源分散并提高葡萄牙语自然语言处理资源可访问性的工具。我们的提议分为四个软件组件：a）一个列出可用资源的Web平台；b）一个客户端Python软件包，简化葡萄牙语NLP资源的加载；c）一个管理平台的管理Python软件包；d）一个公共GitHub存储库

    The recent advances in natural language processing (NLP) are linked to training processes that require vast amounts of corpora. Access to this data is commonly not a trivial process due to resource dispersion and the need to maintain these infrastructures online and up-to-date. New developments in NLP are often compromised due to the scarcity of data or lack of a shared repository that works as an entry point to the community. This is especially true in low and mid-resource languages, such as Portuguese, which lack data and proper resource management infrastructures. In this work, we propose PT-Pump-Up, a set of tools that aim to reduce resource dispersion and improve the accessibility to Portuguese NLP resources. Our proposal is divided into four software components: a) a web platform to list the available resources; b) a client-side Python package to simplify the loading of Portuguese NLP resources; c) an administrative Python package to manage the platform and d) a public GitHub rep
    
[^2]: 隐私保护的跨领域顺序推荐

    Privacy-Preserving Cross-Domain Sequential Recommendation. (arXiv:2401.15369v1 [cs.IR])

    [http://arxiv.org/abs/2401.15369](http://arxiv.org/abs/2401.15369)

    本论文提出了一种隐私保护的跨领域顺序推荐系统（PriCDSR），可以在提供推荐服务的同时保护用户的隐私。

    

    跨领域顺序推荐是推荐系统的重要发展方向。它结合了顺序推荐系统和跨领域推荐系统的特点，可以捕捉用户的动态偏好并缓解冷启动用户的问题。然而，近年来，人们越来越关注自己的隐私。他们不希望别人知道他们刚刚购买了什么、观看了哪些视频以及他们来自哪里。如何保护用户的隐私已经成为一个迫切需要解决的问题。在本文中，我们提出了一种新颖的隐私保护的跨领域顺序推荐系统（PriCDSR），它可以同时为用户提供推荐服务并保护他们的隐私。具体而言，我们在数据上定义了一种新的差分隐私，考虑了ID信息和顺序信息。然后，我们设计了一个满足这种差分隐私的随机机制...

    Cross-domain sequential recommendation is an important development direction of recommender systems. It combines the characteristics of sequential recommender systems and cross-domain recommender systems, which can capture the dynamic preferences of users and alleviate the problem of cold-start users. However, in recent years, people pay more and more attention to their privacy. They do not want other people to know what they just bought, what videos they just watched, and where they just came from. How to protect the users' privacy has become an urgent problem to be solved. In this paper, we propose a novel privacy-preserving cross-domain sequential recommender system (PriCDSR), which can provide users with recommendation services while preserving their privacy at the same time. Specifically, we define a new differential privacy on the data, taking into account both the ID information and the order information. Then, we design a random mechanism that satisfies this differential privac
    
[^3]: 关于神经主题模型的综述：方法、应用和挑战

    A Survey on Neural Topic Models: Methods, Applications, and Challenges. (arXiv:2401.15351v1 [cs.CL])

    [http://arxiv.org/abs/2401.15351](http://arxiv.org/abs/2401.15351)

    这篇综述调研了神经主题模型的方法、应用和挑战，对于短文本和跨语言文档等各种场景提供了系统性的组织和介绍，并讨论了广泛应用的一系列热门应用。

    

    主题模型几十年来一直被广泛应用于无监督方式下发现潜在主题和推断文档的主题比例。它们在文本分析和上下文推荐等各种应用中得到广泛应用。近年来，神经网络的崛起促成了一个新的研究领域——神经主题模型(NTMs)的出现。与传统的主题模型不同，NTMs直接优化参数，而不需要模型特定的推导。这使得NTMs具有更好的可扩展性和灵活性，吸引了大量的研究关注并产生了丰富的新方法和应用。在本文中，我们对神经主题模型的方法、应用和挑战进行了全面的调研。具体而言，根据网络结构系统地组织了当前NTM方法，并介绍了针对短文本和跨语言文档等各种场景的NTMs。我们还讨论了广泛应用的一系列热门应用。

    Topic models have been prevalent for decades to discover latent topics and infer topic proportions of documents in an unsupervised fashion. They have been widely used in various applications like text analysis and context recommendation. Recently, the rise of neural networks has facilitated the emergence of a new research field -- Neural Topic Models (NTMs). Different from conventional topic models, NTMs directly optimize parameters without requiring model-specific derivations. This endows NTMs with better scalability and flexibility, resulting in significant research attention and plentiful new methods and applications. In this paper, we present a comprehensive survey on neural topic models concerning methods, applications, and challenges. Specifically, we systematically organize current NTM methods according to their network structures and introduce the NTMs for various scenarios like short texts and cross-lingual documents. We also discuss a wide range of popular applications built 
    
[^4]: 音乐自动标记：通过领域对抗训练学习鲁棒的音乐表示

    Music Auto-Tagging with Robust Music Representation Learned via Domain Adversarial Training. (arXiv:2401.15323v1 [cs.SD])

    [http://arxiv.org/abs/2401.15323](http://arxiv.org/abs/2401.15323)

    该研究通过领域对抗训练(DAT)方法提出了一种改善嘈杂环境中音乐自动标记性能的方法。该方法通过额外的预训练阶段和添加合成的嘈杂音乐数据，获得了鲁棒的音乐表示，并在音乐自动标记方面展现了增强的性能。

    

    音乐自动标记对于增强音乐发现和推荐至关重要。现有的音乐信息检索(MIR)模型在多媒体内容中存在的环境噪声和语音声音等现实世界噪声方面面临困难。本研究提出了一种受语音相关任务启发的方法，以增强嘈杂环境中的音乐自动标记性能。该方法将领域对抗训练(DAT)集成到音乐领域中，使得鲁棒的音乐表示能够抵抗噪声。与以前的研究不同，该方法还涉及领域分类器的额外预训练阶段，以避免后续阶段性能的下降。添加各种合成的嘈杂音乐数据改善了该模型在不同噪声水平下的泛化能力。所提出的架构通过有效利用无标签的嘈杂音乐数据，在音乐自动标记方面展现了增强的性能。在补充无标签数据的额外实验进一步提高了模型的性能。

    Music auto-tagging is crucial for enhancing music discovery and recommendation. Existing models in Music Information Retrieval (MIR) struggle with real-world noise such as environmental and speech sounds in multimedia content. This study proposes a method inspired by speech-related tasks to enhance music auto-tagging performance in noisy settings. The approach integrates Domain Adversarial Training (DAT) into the music domain, enabling robust music representations that withstand noise. Unlike previous research, this approach involves an additional pretraining phase for the domain classifier, to avoid performance degradation in the subsequent phase. Adding various synthesized noisy music data improves the model's generalization across different noise levels. The proposed architecture demonstrates enhanced performance in music auto-tagging by effectively utilizing unlabeled noisy music data. Additional experiments with supplementary unlabeled data further improves the model's performance
    
[^5]: 通过检索和自我反思改善医疗推理能力的检索增强型大型语言模型

    Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])

    [http://arxiv.org/abs/2401.15269](http://arxiv.org/abs/2401.15269)

    本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。

    

    最近的专有大型语言模型（LLMs），例如GPT-4，在生物医学领域中解决了从多项选择题到长篇生成等多样化挑战的里程碑。为了解决LLMs编码知识无法处理的挑战，已经开发了各种检索增强生成（RAG）方法，通过从知识语料库中搜索文档并无条件或有选择地将其附加到LLMs的输入来进行生成。然而，将现有方法应用于不同领域特定问题时，出现了泛化能力差的问题，导致获取不正确的文档或做出不准确的判断。在本文中，我们介绍了一种可靠的医学文本框架Self-BioRAG，专门用于生成解释、检索领域特定文档和自我反思生成的响应。我们使用了84k个经过过滤的生物医学指令集来训练Self-BioRAG，它具备评估自己的基因

    Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene
    
[^6]: 使用半敏感特征训练差分隐私广告预测模型

    Training Differentially Private Ad Prediction Models with Semi-Sensitive Features. (arXiv:2401.15246v1 [cs.LG])

    [http://arxiv.org/abs/2401.15246](http://arxiv.org/abs/2401.15246)

    我们介绍了一种新的算法，用于训练具有半敏感特征的差分隐私广告预测模型，并在真实广告数据集上证明了其优于传统方法的效果。

    

    我们以数字广告中出现的问题为出发点，介绍了使用半敏感特征训练差分隐私机器学习模型的任务。在这种情况下，攻击者已知一部分特征（因此无需保护），而剩余的特征以及标签对于攻击者来说是未知的，需要通过差分隐私保护。这个任务插值了使用全差分隐私（需要保护标签和所有特征）或标签差分隐私（所有特征被认为是已知的，只需保护标签）来训练模型。我们提出了一种新的算法来训练具有半敏感特征的差分隐私模型。通过对真实广告数据集的实证评估，我们证明了我们的算法在效用方面超过了（i）在所有特征上运行的差分隐私随机梯度下降（DP-SGD）基线和（ii）仅在已知特征上运行的标签差分隐私算法（而丢弃了未知的特征）。

    Motivated by problems arising in digital advertising, we introduce the task of training differentially private (DP) machine learning models with semi-sensitive features. In this setting, a subset of the features is known to the attacker (and thus need not be protected) while the remaining features as well as the label are unknown to the attacker and should be protected by the DP guarantee. This task interpolates between training the model with full DP (where the label and all features should be protected) or with label DP (where all the features are considered known, and only the label should be protected). We present a new algorithm for training DP models with semi-sensitive features. Through an empirical evaluation on real ads datasets, we demonstrate that our algorithm surpasses in utility the baselines of (i) DP stochastic gradient descent (DP-SGD) run on all features (known and unknown), and (ii) a label DP algorithm run only on the known features (while discarding the unknown one
    
[^7]: 噪声的力量：重新定义RAG系统的检索

    The Power of Noise: Redefining Retrieval for RAG Systems. (arXiv:2401.14887v1 [cs.IR])

    [http://arxiv.org/abs/2401.14887](http://arxiv.org/abs/2401.14887)

    本研究通过分析和评估检索增强生成（RAG）系统中的信息检索（IR）组件，填补了目前研究中忽视的领域，在有效的RAG的提示表述中，不相关文档的包含可能会对系统性能产生负面影响。

    

    检索增强生成（RAG）系统相对于传统的大型语言模型（LLMs）代表了一个重大进步。RAG系统通过整合通过信息检索（IR）阶段检索的外部数据来增强其生成能力，克服了标准LLMs的限制，后者仅限于其预先训练的知识和有限的上下文窗口。这个领域的大部分研究主要集中在RAG系统内LLMs的生成方面。我们的研究填补了这一空白，通过全面而批判性地分析IR组件对RAG系统的影响。本文分析了一个检索器在有效的RAG的提示表述中应该具备的特征，重点关注应该检索哪种类型的文档。我们评估了各种因素，如文档与提示的相关性，它们的位置以及上下文中包含的数量。我们的发现揭示出，包含不相关的文档可能会…

    Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can
    
[^8]: PolyCF: 面向协同过滤的最优谱图过滤器

    PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative Filtering. (arXiv:2401.12590v1 [cs.IR])

    [http://arxiv.org/abs/2401.12590](http://arxiv.org/abs/2401.12590)

    PolyCF是一个灵活的图信号滤波器，通过多项式图过滤器处理交互信号，能够捕捉多个特征空间中的谱特征，并近似恢复丢失的交互，旨在实现最优的协同过滤。

    

    协同过滤（CF）是推荐系统中的一个关键研究领域，利用用户与项目之间的协同相似性提供个性化推荐。在基于节点嵌入的图神经网络（GNNs）取得显著成就的基础上，我们探索了基于嵌入方法的表达能力的上限，并通过将CF任务重新定义为图信号处理问题来应对挑战。为此，我们提出了PolyCF，一个灵活的图信号滤波器，利用多项式图过滤器处理交互信号。PolyCF通过一系列广义格拉姆滤波器捕捉多个特征空间中的谱特征，并能够近似于恢复丢失的交互的最优多项式响应函数。图优化目标和成对排名目标共同用于优化卷积核的参数。在三个广泛采用的数据集上进行实验

    Collaborative Filtering (CF) is a pivotal research area in recommender systems that capitalizes on collaborative similarities between users and items to provide personalized recommendations. With the remarkable achievements of node embedding-based Graph Neural Networks (GNNs), we explore the upper bounds of expressiveness inherent to embedding-based methodologies and tackle the challenges by reframing the CF task as a graph signal processing problem. To this end, we propose PolyCF, a flexible graph signal filter that leverages polynomial graph filters to process interaction signals. PolyCF exhibits the capability to capture spectral features across multiple eigenspaces through a series of Generalized Gram filters and is able to approximate the optimal polynomial response function for recovering missing interactions. A graph optimization objective and a pair-wise ranking objective are jointly used to optimize the parameters of the convolution kernel. Experiments on three widely adopted 
    
[^9]: 知识导航：从研究轨迹中推断知识的交错地图

    Knowledge Navigation: Inferring the Interlocking Map of Knowledge from Research Trajectories. (arXiv:2401.11742v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2401.11742](http://arxiv.org/abs/2401.11742)

    本研究利用自然语言处理技术引入了一种创新的嵌入方案，推断出了知识交错地图，揭示了知识之间错综复杂的联系，并展示了多个应用场景。

    

    "如果我看得更远，那是因为我站在巨人的肩膀上。"艾萨克·牛顿的著名声明暗示了新知识建立在现有基础之上的事实，这意味着知识之间存在着相互依赖的关系，而这种关系在科学体系的历史发展中一直未被揭示。通过利用自然语言处理技术，本研究引入了一种创新的嵌入方案，旨在推断“知识交错地图”。这个地图是从数百万学者的研究轨迹中推导出来的，揭示了知识之间错综复杂的联系。我们验证了推断出的地图有效地勾画了学科边界，并捕捉到了不同概念之间复杂的关系。交错地图的实用性通过多个应用展示出来。首先，我们展示了在知识空间中的多步类比推理和概念之间的功能连接。

    "If I have seen further, it is by standing on the shoulders of giants," Isaac Newton's renowned statement hints that new knowledge builds upon existing foundations, which means there exists an interdependent relationship between knowledge, which, yet uncovered, is implied in the historical development of scientific systems for hundreds of years. By leveraging natural language processing techniques, this study introduces an innovative embedding scheme designed to infer the "knowledge interlocking map." This map, derived from the research trajectories of millions of scholars, reveals the intricate connections among knowledge. We validate that the inferred map effectively delineates disciplinary boundaries and captures the intricate relationships between diverse concepts. The utility of the interlocking map is showcased through multiple applications. Firstly, we demonstrated the multi-step analogy inferences within the knowledge space and the functional connectivity between concepts in di
    
[^10]: 通过具有分层正则化的医学代码中心的多模态对比EHR建模预测下次就诊诊断

    Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation. (arXiv:2401.11648v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11648](http://arxiv.org/abs/2401.11648)

    通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。

    

    在医疗保健中，利用电子健康记录（EHR）预测下次就诊的诊断是一项必要的任务，对于制定医疗保健提供者和患者的主动未来计划至关重要。然而，之前的许多研究并没有充分解决EHR数据固有的异构和分层特征，必然导致次优的性能。为此，我们提出了NECHO，一种新颖的医学代码中心的多模态对比EHR学习框架，其中包括分层正则化。首先，我们使用定制的网络设计和一对双模态对比损失融合涵盖医学代码、人口统计数据和临床笔记的多方面信息，所有这些都围绕着医学代码表现。我们还使用医学本体中的父级信息来规范特定模态的编码器，以学习EHR数据的层次结构。对MIMIC-III数据进行的一系列实验证明了我们方法的有效性。

    Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical code representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.
    
[^11]: 知识图谱嵌入的位置敏感嵌入

    Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])

    [http://arxiv.org/abs/2401.10893](http://arxiv.org/abs/2401.10893)

    这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。

    

    知识图谱嵌入将知识图谱转化为连续的、低维度的空间，有助于推理和补全任务。该领域主要分为传统的距离模型和语义匹配模型。传统的距离模型面临的关键挑战是无法有效区分图谱中的“头实体”和“尾实体”。为了解决这个问题，提出了新颖的位置敏感嵌入（LSE）方法。LSE通过关系特定的映射修改头实体，将关系概念化为线性变换而不仅仅是平移。LSE的理论基础，包括其表示能力和与现有模型的联系，都进行了详细研究。一种更简化的变体LSEd利用对角矩阵进行变换以提高实用性能。在对四个大规模数据集进行链接预测的测试中，LSEd要么表现更好，要么具有竞争力。

    Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
    
[^12]: 基于知识图谱驱动的图神经网络推荐模型

    Knowledge graph driven recommendation model of graph neural network. (arXiv:2401.10244v1 [cs.IR])

    [http://arxiv.org/abs/2401.10244](http://arxiv.org/abs/2401.10244)

    提出了一种基于知识图谱的图神经网络推荐模型KGLN，通过合并节点特征、调整聚合权重和迭代演化，提高了个性化推荐的准确性和效果。在实验中相对于已有基准方法，KGLN在不同数据集上的AUC提高了0.3%至5.9%和1.1%至8.2%。

    

    提出了一种新的基于图神经网络的推荐模型KGLN，该模型利用知识图谱（KG）信息，提高了个性化推荐的准确性和效果。该模型首先利用单层神经网络将图中的个体节点特征合并，然后通过结合影响因素调整相邻实体的聚合权重。通过迭代，模型从单层逐渐演变为多层，使实体能够获取丰富的多阶关联实体信息。最后，将实体和用户的特征结合起来产生推荐分数。通过比较不同聚合方法和影响因素的效果，评估了模型的性能。在使用MovieLen-1M和Book-Crossing数据集进行测试时，KGLN相对于LibFM和D等已有基准方法，AUC（ROC曲线下的面积）提高了0.3%至5.9%和1.1%至8.2%。

    A new graph neural network-based recommendation model called KGLN, which leverages Knowledge Graph (KG) information, was developed to enhance the accuracy and effectiveness of personalized recommendations. This model begins by using a single-layer neural network to merge individual node features in the graph. It then adjusts the aggregation weights of neighboring entities by incorporating influence factors. The model evolves from a single layer to multiple layers through iteration, enabling entities to access extensive multi-order associated entity information. The final step involves integrating features of entities and users to produce a recommendation score. The model's performance was evaluated by comparing its effects on various aggregation methods and influence factors. In tests using the MovieLen-1M and Book-Crossing datasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to 5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like LibFM, D
    
[^13]: 去噪扩散推荐模型

    Denoising Diffusion Recommender Model. (arXiv:2401.06982v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2401.06982](http://arxiv.org/abs/2401.06982)

    该论文提出了一种去噪扩散推荐模型（DDRM），通过在推荐模型中注入噪声并利用扩散模型进行多步去噪过程，增强用户和项目嵌入的鲁棒性。

    

    推荐系统通常面临着具有噪声的隐式反馈问题。大多数研究从数据清洗的角度缓解噪声问题，如数据重新采样和重新加权，但它们受到启发式假设的限制。另一种去噪方法是从模型的角度，积极地向用户-项目交互中注入噪声，并增强模型的内在去噪能力。然而，这种去噪过程对推荐模型的表示能力来捕捉噪声模式提出了显著挑战。为了解决这个问题，我们提出了去噪扩散推荐模型（DDRM），它基于扩散模型使用多步去噪过程来增强来自任何推荐模型的用户和项目嵌入的鲁棒性。DDRM在前向过程中注入受控高斯噪声，并在反向去噪过程中迭代地去除噪声，从而提高对噪声反馈的嵌入鲁棒性。为了实现这一目标，关键在于提供一种能够捕捉噪声模式的扩散模型，并通过多步去噪过程来改善嵌入。

    Recommender systems often grapple with noisy implicit feedback. Most studies alleviate the noise issues from data cleaning perspective such as data resampling and reweighting, but they are constrained by heuristic assumptions. Another denoising avenue is from model perspective, which proactively injects noises into user-item interactions and enhance the intrinsic denoising ability of models. However, this kind of denoising process poses significant challenges to the recommender model's representation capacity to capture noise patterns. To address this issue, we propose Denoising Diffusion Recommender Model (DDRM), which leverages multi-step denoising process based on diffusion models to robustify user and item embeddings from any recommender models. DDRM injects controlled Gaussian noises in the forward process and iteratively removes noises in the reverse denoising process, thereby improving embedding robustness against noisy feedback. To achieve this target, the key lies in offering 
    
[^14]: 不确定性的研究国家排名：我们应该继续制作不确定性排名吗？

    Uncertain research country rankings. Should we continue producing uncertain rankings?. (arXiv:2312.17560v2 [cs.DL] UPDATED)

    [http://arxiv.org/abs/2312.17560](http://arxiv.org/abs/2312.17560)

    这项研究对基于引用的国家排名进行了分析，发现这些排名可能对日本的科研地位进行错误的分类。研究还发现了引用分布的偏离情况，并评估了其对评估的影响。

    

    基于引用的国家排名通常将日本划为发展中国家，甚至是在最有声望的机构中也是如此。考虑到日本的科研地位提升，这种分类挑战了这些排名的可信度。在大多数情况下，这些排名使用百分位指标，如果国家的引用符合理想的分布模型，那么这些排名是准确的，但在偏离的情况下，它们可能具有误导性。理想模型意味着对数正态分布的引用分布和基于幂律的引用分布的双重排名：全球和国家排名。本研究对偏离理想模型的情况进行了系统性的检查，以及其对评估的影响。研究评估了三个具有科学相关性的主题的六个选定国家，并利用莱顿排名评估了300多所大学。研究结果显示了对数正态分布的三种偏离类型：i 极端上尾部的偏离；ii 膨胀的下尾部；

    Citation based country rankings consistently categorize Japan as a developing country, even in those from the most reputed institutions. This categorization challenges the credibility of such rankings, considering Japan elevated scientific standing. In most cases, these rankings use percentile indicators and are accurate if country citations fit an ideal model of distribution, but they can be misleading in cases of deviations. The ideal model implies a lognormal citation distribution and a power law citation based double rank: in the global and country lists. This report conducts a systematic examination of deviations from the ideal model and their consequential impact on evaluations. The study evaluates six selected countries across three scientifically relevant topics and utilizes Leiden Ranking assessments of over 300 universities. The findings reveal three types of deviations from the lognormal citation distribution: i deviations in the extreme upper tail; ii inflated lower tails; 
    
[^15]: 一份关于基于查询的API推荐的调研

    A Survey on Query-based API Recommendation. (arXiv:2312.10623v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.10623](http://arxiv.org/abs/2312.10623)

    这项调研研究了过去10年发表的API推荐研究，通过对API推荐工具的结构、数据来源和收集方法以及常见数据表示等方面的分析，提出了四个关键研究问题。

    

    应用程序接口(APIs)旨在帮助开发人员更有效地构建软件。近年来，为特定任务推荐合适的APIs已经引起了研究人员和开发者的越来越多关注。为了全面了解这个研究领域，我们对过去10年发表的API推荐研究进行了调查分析。我们的研究从API推荐工具的结构概述开始。随后，我们系统地分析了先前的研究并提出了四个关键的研究问题。在RQ1中，我们检查了API推荐领域内发表的论文数量和发表的会议。在RQ2中，我们对API推荐研究中常用的数据来源和收集方法进行分类和总结。在RQ3中，我们探索了API推荐方法使用的数据类型和常见的数据表示。我们还调查了典型的数据提取过程和收集方法。

    Application Programming Interfaces (APIs) are designed to help developers build software more effectively. Recommending the right APIs for specific tasks has gained increasing attention among researchers and developers in recent years. To comprehensively understand this research domain, we have surveyed to analyze API recommendation studies published in the last 10 years. Our study begins with an overview of the structure of API recommendation tools. Subsequently, we systematically analyze prior research and pose four key research questions. For RQ1, we examine the volume of published papers and the venues in which these papers appear within the API recommendation field. In RQ2, we categorize and summarize the prevalent data sources and collection methods employed in API recommendation research. In RQ3, we explore the types of data and common data representations utilized by API recommendation approaches. We also investigate the typical data extraction procedures and collection approac
    
[^16]: 基于注意力GCN的知识图谱推理

    Knowledge Graph Reasoning Based on Attention GCN. (arXiv:2312.10049v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.10049](http://arxiv.org/abs/2312.10049)

    本论文通过将图卷积神经网络（GCN）与注意力机制相结合，提出了一种新颖的技术来增强知识图谱推理，通过检查实体之间及其邻居节点之间的关系以及整合实体的属性和相互作用，生成丰富的隐式特征向量，以提高实体分类和链接预测等任务的性能。

    

    我们提出了一种新颖的技术，通过将图卷积神经网络（GCN）与注意力机制相结合来增强知识图谱推理。该方法利用注意力机制来检查实体之间及其邻居节点之间的关系，从而为每个实体开发详细的特征向量。GCN使用共享参数有效地表示相邻实体的特征。我们首先学习实体之间的相似度，以进行节点表示学习。通过整合实体的属性和它们的相互作用，该方法为每个实体生成了丰富的隐式特征向量，提高了实体分类和链接预测等任务的性能，优于传统的神经网络模型。总之，这项工作为搜索引擎、问答系统、推荐系统和数据整合任务等多个应用领域提供了重要的方法支持。

    We propose a novel technique to enhance Knowledge Graph Reasoning by combining Graph Convolution Neural Network (GCN) with the Attention Mechanism. This approach utilizes the Attention Mechanism to examine the relationships between entities and their neighboring nodes, which helps to develop detailed feature vectors for each entity. The GCN uses shared parameters to effectively represent the characteristics of adjacent entities. We first learn the similarity of entities for node representation learning. By integrating the attributes of the entities and their interactions, this method generates extensive implicit feature vectors for each entity, improving performance in tasks including entity classification and link prediction, outperforming traditional neural network models. To conclude, this work provides crucial methodological support for a range of applications, such as search engines, question-answering systems, recommendation systems, and data integration tasks.
    
[^17]: 识别性很重要：揭示无偏学习排名中隐藏的可恢复条件

    Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank. (arXiv:2309.15560v1 [cs.IR])

    [http://arxiv.org/abs/2309.15560](http://arxiv.org/abs/2309.15560)

    研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。

    

    无偏学习排名(Unbiased Learning to Rank, ULTR)在从有偏点击日志训练无偏排名模型的现代系统中被广泛应用。关键在于明确地建模用户行为的生成过程，并基于检验假设对点击数据进行拟合。先前的研究经验性地发现只要点击完全拟合，大多数情况下可以恢复出真实潜在相关性。然而，我们证明并非总是能够实现这一点，从而导致排名性能显著降低。在本工作中，我们旨在回答真实相关性是否能够从点击数据恢复出来的问题，这是ULTR领域的一个基本问题。我们首先将一个排名模型定义为可识别的，如果它可以恢复出真实相关性，最多只有一个缩放变换，这对于成对排名目标来说已足够。然后，我们探讨了一个等价的可识别条件，可以新颖地表达为一个图连通性测试问题：当且仅当一个图（即可识别性图）连通时，该排名模型是可识别的。

    The application of Unbiased Learning to Rank (ULTR) is widespread in modern systems for training unbiased ranking models from biased click logs. The key is to explicitly model a generation process for user behavior and fit click data based on examination hypothesis. Previous research found empirically that the true latent relevance can be recovered in most cases as long as the clicks are perfectly fitted. However, we demonstrate that this is not always achievable, resulting in a significant reduction in ranking performance. In this work, we aim to answer if or when the true relevance can be recovered from click data, which is a foundation issue for ULTR field. We first define a ranking model as identifiable if it can recover the true relevance up to a scaling transformation, which is enough for pairwise ranking objective. Then we explore an equivalent condition for identifiability that can be novely expressed as a graph connectivity test problem: if and only if a graph (namely identifi
    
[^18]: 具有双多模态编码器的组合图像检索候选集重排序

    Candidate Set Re-ranking for Composed Image Retrieval with Dual Multi-modal Encoder. (arXiv:2305.16304v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.16304](http://arxiv.org/abs/2305.16304)

    本论文提出了一种使用两阶段模式结合预先计算图像嵌入和参考文本-候选项三元组交互选择的方式进行组合图像检索候选集重排序的方法。

    

    组合图像检索旨在找到最匹配给定多模态用户查询(包括参考图像和文本对)的图像。现有方法通常预先计算整个语料库的图像嵌入，并在测试时将这些嵌入与经过查询文本修改的参考图像嵌入进行比较。然而，仅通过短文本描述引导修改参考图像嵌入可能很困难，特别是独立于潜在的候选项。一种替代方法是允许查询和每个可能的候选项之间的交互，即参考文本-候选项三元组，并从整个集合中选择最佳匹配。虽然这种方法更具有判别性，但对于大规模数据集，由于不能预先计算候选嵌入，因此计算成本是禁止性的。我们提出使用两阶段模式结合这两个方案的优点

    Composed image retrieval aims to find an image that best matches a given multi-modal user query consisting of a reference image and text pair. Existing methods commonly pre-compute image embeddings over the entire corpus and compare these to a reference image embedding modified by the query text at test time. Such a pipeline is very efficient at test time since fast vector distances can be used to evaluate candidates, but modifying the reference image embedding guided only by a short textual description can be difficult, especially independent of potential candidates. An alternative approach is to allow interactions between the query and every possible candidate, i.e., reference-text-candidate triplets, and pick the best from the entire set. Though this approach is more discriminative, for large-scale datasets the computational cost is prohibitive since pre-computation of candidate embeddings is no longer possible. We propose to combine the merits of both schemes using a two-stage mode
    
[^19]: ConvGQR：面向会话搜索的生成式查询重构

    ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])

    [http://arxiv.org/abs/2305.15645](http://arxiv.org/abs/2305.15645)

    本文提出了一种新的面向会话搜索的ConvGQR框架，通过结合预训练语言模型来重新构造查询，从而提供更好的搜索查询。

    

    在会话搜索中，用户当前搜索意图依赖于先前的对话历史。从整个对话上下文中确定一个良好的搜索查询是具有挑战性的。为避免查询编码器的昂贵重新训练，大部分现有方法尝试学习一个重写模型，通过模仿手动查询重写来去除当前查询的上下文。然而，手动重写的查询并不总是最好的搜索查询。训练重写模型会限制模型产生良好搜索查询的能力。本文提出一种新的框架ConvGQR，基于预训练语言模型（PLM），一个用于查询重写，另一个用于生成潜在答案，以重新构造会话查询。通过结合两者，ConvGQR可以提供更好的搜索查询。此外，为了将查询重构与检索性能联系起来，我们提出了一种基于特征选择的相似度分数模型，用于验证ConvGQR的有效性。

    In conversational search, the user's real search intent for the current turn is dependent on the previous conversation history. It is challenging to determine a good search query from the whole conversation context. To avoid the expensive re-training of the query encoder, most existing methods try to learn a rewriting model to de-contextualize the current query by mimicking the manual query rewriting. However, manually rewritten queries are not always the best search queries. Training a rewriting model on them would limit the model's ability to produce good search queries. Another useful hint is the potential answer to the question. In this paper, we propose ConvGQR, a new framework to reformulate conversational queries based on generative pre-trained language models (PLMs), one for query rewriting and another for generating potential answers. By combining both, ConvGQR can produce better search queries. In addition, to relate query reformulation to retrieval performance, we propose a 
    
[^20]: 基于排序的快速准确的固定半径近邻搜索

    Fast and exact fixed-radius neighbor search based on sorting. (arXiv:2212.07679v6 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.07679](http://arxiv.org/abs/2212.07679)

    SNN是一种新的固定半径近邻搜索方法，通过排序和使用高级BLAS实现，能够显著提高查询和索引时间，返回精确结果，并且无需参数调整。

    

    固定半径近邻搜索是一种基本的数据操作，用于检索到查询点在用户指定距离内的所有数据点。目前存在一些高效的算法可以提供快速的近似查询响应，但它们通常具有计算密集型的索引阶段，并且需要仔细的参数调整。因此，精确的暴力搜索和基于树的搜索方法仍然被广泛使用。本文提出了一种新的固定半径近邻搜索方法SNN，在索引和查询时间方面显著改进了暴力搜索和基于树的方法，能够准确返回结果，并且无需参数调整。SNN利用数据点根据其第一主成分进行排序，从而修剪查询搜索空间。通过使用高级的基础线性代数子程序（BLAS）的高效实现，进一步提速。我们提供了该方法的理论分析，并展示了它在独立使用和与其他方法结合使用时的实际性能。

    Fixed-radius near neighbor search is a fundamental data operation that retrieves all data points within a user-specified distance to a query point. There are efficient algorithms that can provide fast approximate query responses, but they often have a very compute-intensive indexing phase and require careful parameter tuning. Therefore, exact brute force and tree-based search methods are still widely used. Here we propose a new fixed-radius near neighbor search method, called SNN, that significantly improves over brute force and tree-based methods in terms of index and query time, provably returns exact results, and requires no parameter tuning. SNN exploits a sorting of the data points by their first principal component to prune the query search space. Further speedup is gained from an efficient implementation using high-level Basic Linear Algebra Subprograms (BLAS). We provide theoretical analysis of our method and demonstrate its practical performance when used stand-alone and when 
    
[^21]: DiSCoMaT：材料科学文章中基于远程监督的表格组成提取

    DiSCoMaT: Distantly Supervised Composition Extraction from Tables in Materials Science Articles. (arXiv:2207.01079v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.01079](http://arxiv.org/abs/2207.01079)

    本文提出了一个新型挑战任务，即通过远程监督方式从科学文章中的表格中提取有关材料组成的信息。为此，研究者创建了一个包含4408个远程监督表格和1475个手动注释的开发和测试表格的训练数据集，并提出了一个强基线——DiSCoMaT。

    

    从科学领域文章中的表格中提取有关材料组成的信息是知识库策划的重要组成部分。然而，现有的表格提取器假定您已经了解表格结构和格式，而科学表格中可能没有这些先前的知识。本文研究了一种特定且具有挑战性的表格提取问题：提取材料（例如玻璃，合金）的组成。我们首先观察到材料科学研究人员使用各种表格样式组织类似的组成，这需要一个智能模型来理解表格和提取组成。因此，我们将其定义为机器学习领域的新型挑战，并创建了一个由4408个远程监督表格和1475个手动注释的开发和测试表格组成的训练数据集。我们还提出了DiSCoMaT，它是一个针对该问题的强基线。

    A crucial component in the curation of KB for a scientific domain is information extraction from tables in the domain's published articles -- tables carry important information (often numeric), which must be adequately extracted for a comprehensive machine understanding of an article. Existing table extractors assume prior knowledge of table structure and format, which may not be known in scientific tables. We study a specific and challenging table extraction problem: extracting compositions of materials (e.g., glasses, alloys). We first observe that materials science researchers organize similar compositions in a wide variety of table styles, necessitating an intelligent model for table understanding and composition extraction. Consequently, we define this novel task as a challenge for the ML community and create a training dataset comprising 4,408 distantly supervised tables, along with 1,475 manually annotated dev and test tables. We also present DiSCoMaT, a strong baseline geared t
    

