# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The tale of two MS MARCO -- and their unfair comparisons.](http://arxiv.org/abs/2304.12904) | 论文介绍了MS MARCO-passage数据集中包含公正性和可重复性的重要性，并指出了文献中使用了两个不同版本的数据集以及版本之间的差异，这可能导致不公平的比较和领域不可靠的进展。 |
| [^2] | [A New Information Theory of Certainty for Machine Learning.](http://arxiv.org/abs/2304.12833) | 该论文提出了一种新的信息理论概念 troenpy 来量化底层分布的确定性，用于机器学习中文档分类和序列数据权重方案，并定义了量子 troenpy 量化量子系统确定性。 |
| [^3] | [A Novel Dual of Shannon Information and Weighting Scheme.](http://arxiv.org/abs/2304.12814) | 本文通过发掘信息熵自然对偶，提出了一种新的量troenpy，并应用于提出了基于troenpy的文档加权方案，即正类别频率（PCF），以及一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。 |
| [^4] | [A Static Pruning Study on Sparse Neural Retrievers.](http://arxiv.org/abs/2304.12702) | 本论文研究了稀疏神经信息检索器的静态修剪方法，结果表明在不同数据集上，采用面向文档、面向术语和不可知三种策略的静态修剪仍然适用于稀疏神经信息检索器，能够实现2倍速度提升，且效果损失极小（≤ 2%）。 |
| [^5] | [THUIR at WSDM Cup 2023 Task 1: Unbiased Learning to Rank.](http://arxiv.org/abs/2304.12650) | THUIR在WSDM Cup 2023“无偏学习排序”任务中获得第二名，使用了传统IR模型和Transformer-based cross-encoder architecture的组合，以及一系列特征来提高排序性能。 |
| [^6] | [MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce.](http://arxiv.org/abs/2304.12636) | MG-ShopDial是一个用于电子商务的多目标对话数据集，包含超过17k个涉及搜索、推荐及商品相关问题的对话，具有很高的复杂性和多样性。 |
| [^7] | [PUNR: Pre-training with User Behavior Modeling for News Recommendation.](http://arxiv.org/abs/2304.12633) | 本论文提出了一种无监督的预训练方法，它可以通过两个任务实现有效的用户行为建模，以提高新闻推荐系统的准确性和性能表现。 |
| [^8] | [Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation.](http://arxiv.org/abs/2304.12631) | 本论文提出了一种解释NRM的新方法——基于等价查询的局部解释方法。通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。该方法与现有方法进行比较，并对检索效果和每种方法生成的词项进行了对比。 |
| [^9] | [OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification.](http://arxiv.org/abs/2304.12608) | OFAR是一种用于非法直播识别的证据检索框架，能够帮助直播平台立即识别直播中的非法行为。 |
| [^10] | [Learnable Pillar-based Re-ranking for Image-Text Retrieval.](http://arxiv.org/abs/2304.12570) | 本文提出了一种新颖的可学习的基于支柱的图文检索重排方法，通过选择等级最高的内部和跨模态邻居作为支柱，并使用它们之间的邻居关系重构数据样本，将每个样本映射到多模态支柱空间中。 |
| [^11] | [COUPA: An Industrial Recommender System for Online to Offline Service Platforms.](http://arxiv.org/abs/2304.12549) | COUPA是一个面向O2O服务平台的工业级推荐系统，通过时间感知偏好和位置感知偏好来提高推荐效果。 |
| [^12] | [GARCIA: Powering Representations of Long-tail Query with Multi-granularity Contrastive Learning.](http://arxiv.org/abs/2304.12537) | GARCIA利用多粒度对比学习，基于图的知识转移和基于意图的表示，提高了长尾查询表示能力。 |
| [^13] | [Rank Flow Embedding for Unsupervised and Semi-Supervised Manifold Learning.](http://arxiv.org/abs/2304.12448) | 本文提出了Rank Flow Embedding算法用于无监督和半监督场景的流形学习。 |
| [^14] | [Extreme Classification for Answer Type Prediction in Question Answering.](http://arxiv.org/abs/2304.12395) | 本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。 |
| [^15] | [Overview of the TREC 2022 NeuCLIR Track.](http://arxiv.org/abs/2304.12367) | TREC NeuCLIR轨道的第一年，研究神经方法对跨语言信息检索的影响，通过英语查询来ad hoc排名检索中文、波斯语或俄语新闻文档，共有12个团队提交了172次运行。 |
| [^16] | [USTEP: Structuration des logs en flux gr{\^a}ce {\`a} un arbre de recherche {\'e}volutif.](http://arxiv.org/abs/2304.12331) | 本论文提出了一种基于演化树结构的在线日志解析方法USTEP，该方法在有效性和鲁棒性方面优越。 |
| [^17] | [Continuous Input Embedding Size Search For Recommender Systems.](http://arxiv.org/abs/2304.03501) | 提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。 |
| [^18] | [Code Recommendation for Open Source Software Developers.](http://arxiv.org/abs/2210.08332) | CODER 是一个基于图的代码推荐框架，通过建模微观用户-代码交互和宏观用户-项目交互，预测开发者未来的贡献行为，以缩短开发时间并提高开发效率。 |

# 详细

[^1]: 两个MS MARCO的故事--他们不公平的比较

    The tale of two MS MARCO -- and their unfair comparisons. (arXiv:2304.12904v1 [cs.IR])

    [http://arxiv.org/abs/2304.12904](http://arxiv.org/abs/2304.12904)

    论文介绍了MS MARCO-passage数据集中包含公正性和可重复性的重要性，并指出了文献中使用了两个不同版本的数据集以及版本之间的差异，这可能导致不公平的比较和领域不可靠的进展。

    

    MS MARCO-passage 数据集是IR社区主要的大规模数据集，多年来它成功地推动了新型神经检索模型的发展。但是，事实证明文献中使用了两个不同的MS MARCO语料库，一个是官方版本，一个是加入了标题的第二个版本，主要是由于引入了Tevatron代码库。然而，添加标题实际上泄漏了相关信息，而且违反了MS MARCO-passage数据集的原始指南。在这项工作中，我们研究了两个版本之间的差异，并且通过实验证明，当评估新方法时，它们会产生显著的差异。换句话说，我们展示了如果一个论文没有恰当地报告所使用的版本，那么就基本上不可能公平地复现其结果。此外，鉴于当前审查的状态，监测最新进展是非常重要的，拥有两个不同版本的MS MARCO数据集可能会导致不公平的比较和信息检索领域不可靠的进展。

    The MS MARCO-passage dataset has been the main large-scale dataset open to the IR community and it has fostered successfully the development of novel neural retrieval models over the years. But, it turns out that two different corpora of MS MARCO are used in the literature, the official one and a second one where passages were augmented with titles, mostly due to the introduction of the Tevatron code base. However, the addition of titles actually leaks relevance information, while breaking the original guidelines of the MS MARCO-passage dataset. In this work, we investigate the differences between the two corpora and demonstrate empirically that they make a significant difference when evaluating a new method. In other words, we show that if a paper does not properly report which version is used, reproducing fairly its results is basically impossible. Furthermore, given the current status of reviewing, where monitoring state-of-the-art results is of great importance, having two differen
    
[^2]: 一种新的用于机器学习的确定性信息理论

    A New Information Theory of Certainty for Machine Learning. (arXiv:2304.12833v1 [cs.IT])

    [http://arxiv.org/abs/2304.12833](http://arxiv.org/abs/2304.12833)

    该论文提出了一种新的信息理论概念 troenpy 来量化底层分布的确定性，用于机器学习中文档分类和序列数据权重方案，并定义了量子 troenpy 量化量子系统确定性。

    

    克劳德·香农提出了熵的概念来量化通信编码理论中随机分布的不确定性。我们观察到熵的这种不确定性特性也限制了其在数学建模中的直接使用。因此，我们提出了一个新概念 troenpy，作为熵的规范对偶，来量化底层分布的确定性。我们展示了在机器学习中的两个应用。第一个是用于传统的文档分类，我们开发了一个基于 troenpy 权重方案来利用文档分类标签。第二个是针对序列数据的自我 troenpy 权重方案，并表明它可以轻松地包含在基于神经网络的语言模型中，并实现显著的困惑度降低。我们还定义了量子 troenpy 作为 Von Neumann 熵的对偶，以量化量子系统的确定性。

    Claude Shannon coined entropy to quantify the uncertainty of a random distribution for communication coding theory. We observe that the uncertainty nature of entropy also limits its direct usage in mathematical modeling. Therefore we propose a new concept troenpy,as the canonical dual of entropy, to quantify the certainty of the underlying distribution. We demonstrate two applications in machine learning. The first is for the classical document classification, we develop a troenpy based weighting scheme to leverage the document class label. The second is a self-troenpy weighting scheme for sequential data and show that it can be easily included in neural network based language models and achieve dramatic perplexity reduction. We also define quantum troenpy as the dual of the Von Neumann entropy to quantify the certainty of quantum systems.
    
[^3]: 一种新型的Shannon信息及加权方案的对偶

    A Novel Dual of Shannon Information and Weighting Scheme. (arXiv:2304.12814v1 [cs.CL])

    [http://arxiv.org/abs/2304.12814](http://arxiv.org/abs/2304.12814)

    本文通过发掘信息熵自然对偶，提出了一种新的量troenpy，并应用于提出了基于troenpy的文档加权方案，即正类别频率（PCF），以及一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。

    

    Shannon信息理论不仅在通信技术领域，其应用还拓展至机器学习和人工智能领域。本文发掘信息熵存在自然对偶，并引入了一种新的量troenpy，用于衡量底层分布的确定性、普遍性和相似性。我们提出了基于troenpy的文档加权方案，即正类别频率（PCF），并证明其在公共数据集上的优越性。此外，我们还开发了一种新的类别信息偏差特征ECIB，在监督学习中具有互信息的泛化性质。

    Shannon Information theory has achieved great success in not only communication technology where it was originally developed for but also many other science and engineering fields such as machine learning and artificial intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered that information entropy has a natural dual. We complement the classical Shannon information theory by proposing a novel quantity, namely troenpy. Troenpy measures the certainty, commonness and similarity of the underlying distribution. To demonstrate its usefulness, we propose a troenpy based weighting scheme for document with class labels, namely positive class frequency (PCF). On a collection of public datasets we show the PCF based weighting scheme outperforms the classical TF-IDF and a popular Optimal Transportation based word moving distance algorithm in a kNN setting. We further developed a new odds-ratio type feature, namely Expected Class Information Bias(ECIB), which can be regarded as
    
[^4]: 稀疏神经信息检索器的静态修剪研究

    A Static Pruning Study on Sparse Neural Retrievers. (arXiv:2304.12702v1 [cs.IR])

    [http://arxiv.org/abs/2304.12702](http://arxiv.org/abs/2304.12702)

    本论文研究了稀疏神经信息检索器的静态修剪方法，结果表明在不同数据集上，采用面向文档、面向术语和不可知三种策略的静态修剪仍然适用于稀疏神经信息检索器，能够实现2倍速度提升，且效果损失极小（≤ 2%）。

    

    近期提出了一种称为DeepImpact、uniCOIL和SPLADE的稀疏神经信息检索器，它们是一种有效且高效的通过倒排索引进行信息检索的方法，旨在通过学习术语重要性和文档扩展来提供比传统的基于词袋的信息检索模型（例如BM25）更为有效的文档排名。然而，与传统的信息检索器相比，这些稀疏神经信息检索器已被证明会增加计算成本和查询处理的延迟。为了缓解这一问题，我们应用了一种旨在提高倒排索引查询处理效率的著名技术家族：静态修剪。我们尝试了三种静态修剪策略，即面向文档、面向术语和不可知修剪，并在不同数据集上进行了评估，结果表明这些技术仍然适用于稀疏神经信息检索器。特别地，静态修剪实现了2倍的速度提升，且效果损失极小（≤ 2%）。

    Sparse neural retrievers, such as DeepImpact, uniCOIL and SPLADE, have been introduced recently as an efficient and effective way to perform retrieval with inverted indexes. They aim to learn term importance and, in some cases, document expansions, to provide a more effective document ranking compared to traditional bag-of-words retrieval models such as BM25. However, these sparse neural retrievers have been shown to increase the computational costs and latency of query processing compared to their classical counterparts. To mitigate this, we apply a well-known family of techniques for boosting the efficiency of query processing over inverted indexes: static pruning. We experiment with three static pruning strategies, namely document-centric, term-centric and agnostic pruning, and we assess, over diverse datasets, that these techniques still work with sparse neural retrievers. In particular, static pruning achieves $2\times$ speedup with negligible effectiveness loss ($\leq 2\%$ drop) 
    
[^5]: THUIR在WSDM Cup 2023任务1中的表现：无偏学习排序的尝试

    THUIR at WSDM Cup 2023 Task 1: Unbiased Learning to Rank. (arXiv:2304.12650v1 [cs.IR])

    [http://arxiv.org/abs/2304.12650](http://arxiv.org/abs/2304.12650)

    THUIR在WSDM Cup 2023“无偏学习排序”任务中获得第二名，使用了传统IR模型和Transformer-based cross-encoder architecture的组合，以及一系列特征来提高排序性能。

    

    本文介绍了我们在WSDM Cup 2023任务1：“无偏学习排序”中所用的方法。我们尝试使用传统信息检索模型和基于Transformer的交叉编码器架构相结合的方法。为了进一步提高排序性能，我们还考虑了一系列的排序学习特征。结果表明，我们在最终排行榜上获得第二名。

    This paper introduces the approaches we have used to participate in the WSDM Cup 2023 Task 1: Unbiased Learning to Rank. In brief, we have attempted a combination of both traditional IR models and transformer-based cross-encoder architectures. To further enhance the ranking performance, we also considered a series of features for learning to rank. As a result, we won 2nd place on the final leaderboard.
    
[^6]: MG-ShopDial：一种用于电子商务的多目标对话数据集

    MG-ShopDial: A Multi-Goal Conversational Dataset for e-Commerce. (arXiv:2304.12636v1 [cs.IR])

    [http://arxiv.org/abs/2304.12636](http://arxiv.org/abs/2304.12636)

    MG-ShopDial是一个用于电子商务的多目标对话数据集，包含超过17k个涉及搜索、推荐及商品相关问题的对话，具有很高的复杂性和多样性。

    

    在电子商务平台上寻找合适的产品需要一个能够提供搜索功能、理解用户偏好、提供推荐及回答与商品有关的各种问题的交互式对话系统。然而，已有的对话数据集并没有充分支持混合不同的对话目标（例如搜索、推荐和问答），而是聚焦于单一目标。因此，我们推出了MG-ShopDial：一种电子商务领域混合不同目标对话的数据集。

    Conversational systems can be particularly effective in supporting complex information seeking scenarios with evolving information needs. Finding the right products on an e-commerce platform is one such scenario, where a conversational agent would need to be able to provide search capabilities over the item catalog, understand and make recommendations based on the user's preferences, and answer a range of questions related to items and their usage. Yet, existing conversational datasets do not fully support the idea of mixing different conversational goals (i.e., search, recommendation, and question answering) and instead focus on a single goal. To address this, we introduce MG-ShopDial: a dataset of conversations mixing different goals in the domain of e-commerce. Specifically, we make the following contributions. First, we develop a coached human-human data collection protocol where each dialogue participant is given a set of instructions, instead of a specific script or answers to ch
    
[^7]: PUNR: 用户行为建模的新闻推荐预训练

    PUNR: Pre-training with User Behavior Modeling for News Recommendation. (arXiv:2304.12633v1 [cs.IR])

    [http://arxiv.org/abs/2304.12633](http://arxiv.org/abs/2304.12633)

    本论文提出了一种无监督的预训练方法，它可以通过两个任务实现有效的用户行为建模，以提高新闻推荐系统的准确性和性能表现。

    

    新闻推荐旨在基于用户行为预测点击行为。如何有效地建模用户表示是推荐首选新闻的关键。现有方法大多集中在监督微调阶段的改进上。然而，还缺乏针对用户表示优化的基于PLM的无监督预训练方法。在本文中，我们提出了一种具有两个任务的无监督预训练范例，即用户行为掩蔽和用户行为生成，均致力于有效的用户行为建模。首先，我们引入了用户行为掩蔽预训练任务，以恢复基于上下文行为的掩蔽用户行为。通过这种方式，模型可以捕捉到更强大、更全面的用户新闻阅读模式。此外，我们还结合了一种新颖的辅助用户行为生成预训练任务，以增强从用户编码器派生出的用户表示向量。我们使用上述预训练的用户建模来进行新闻推荐，实验结果表明，我们的模型在多个数据集上取得了显著的性能提升。

    News recommendation aims to predict click behaviors based on user behaviors. How to effectively model the user representations is the key to recommending preferred news. Existing works are mostly focused on improvements in the supervised fine-tuning stage. However, there is still a lack of PLM-based unsupervised pre-training methods optimized for user representations. In this work, we propose an unsupervised pre-training paradigm with two tasks, i.e. user behavior masking and user behavior generation, both towards effective user behavior modeling. Firstly, we introduce the user behavior masking pre-training task to recover the masked user behaviors based on their contextual behaviors. In this way, the model could capture a much stronger and more comprehensive user news reading pattern. Besides, we incorporate a novel auxiliary user behavior generation pre-training task to enhance the user representation vector derived from the user encoder. We use the above pre-trained user modeling en
    
[^8]: BM25简单易懂：用稀疏逼近解释密集模型的排名列表

    Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a Sparse Approximation. (arXiv:2304.12631v1 [cs.IR])

    [http://arxiv.org/abs/2304.12631](http://arxiv.org/abs/2304.12631)

    本论文提出了一种解释NRM的新方法——基于等价查询的局部解释方法。通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。该方法与现有方法进行比较，并对检索效果和每种方法生成的词项进行了对比。

    

    相比于传统统计模型，神经检索模型(NRMs)因为可以通过稠密文档表示来捕捉语义意义而显示出更好的检索性能。然而，由于其不依赖于明确的词项匹配，这些模型往往可读性差。为了生成一种基于局部查询解释的新方法，我们引入了“等价查询”的概念，通过最大化NRM结果与具有等价查询的稀疏检索系统的结果集之间的相似性来生成等价查询。我们将这种方法与现有方法(如基于RM3的查询扩展)进行了比较，并对检索效果和每种方法生成的词项进行了对比。

    Neural retrieval models (NRMs) have been shown to outperform their statistical counterparts owing to their ability to capture semantic meaning via dense document representations. These models, however, suffer from poor interpretability as they do not rely on explicit term matching. As a form of local per-query explanations, we introduce the notion of equivalent queries that are generated by maximizing the similarity between the NRM's results and the result set of a sparse retrieval system with the equivalent query. We then compare this approach with existing methods such as RM3-based query expansion and contrast differences in retrieval effectiveness and in the terms generated by each approach.
    
[^9]: OFAR: 一种用于非法直播识别的多模式证据检索框架

    OFAR: A Multimodal Evidence Retrieval Framework for Illegal Live-streaming Identification. (arXiv:2304.12608v1 [cs.IR])

    [http://arxiv.org/abs/2304.12608](http://arxiv.org/abs/2304.12608)

    OFAR是一种用于非法直播识别的证据检索框架，能够帮助直播平台立即识别直播中的非法行为。

    

    非法直播识别是为了帮助直播平台立即识别直播中的非法行为，例如售卖珍贵和濒危动物，对净化网络环境起着至关重要的作用。本文提出了一种名为OFAR的多模式证据检索框架，以利于非法直播识别。OFAR包括三个模块：查询编码器、文档编码器和基于MaxSim的对比晚交集。查询编码器和文档编码器都采用了先进的OFA。

    Illegal live-streaming identification, which aims to help live-streaming platforms immediately recognize the illegal behaviors in the live-streaming, such as selling precious and endangered animals, plays a crucial role in purifying the network environment. Traditionally, the live-streaming platform needs to employ some professionals to manually identify the potential illegal live-streaming. Specifically, the professional needs to search for related evidence from a large-scale knowledge database for evaluating whether a given live-streaming clip contains illegal behavior, which is time-consuming and laborious. To address this issue, in this work, we propose a multimodal evidence retrieval system, named OFAR, to facilitate the illegal live-streaming identification. OFAR consists of three modules: \textit{Query Encoder}, \textit{Document Encoder}, and \textit{MaxSim-based Contrastive Late Intersection}. Both query encoder and document encoder are implemented with the advanced \mbox{OFA} 
    
[^10]: 可学习的基于支柱的图文检索重排

    Learnable Pillar-based Re-ranking for Image-Text Retrieval. (arXiv:2304.12570v1 [cs.CV])

    [http://arxiv.org/abs/2304.12570](http://arxiv.org/abs/2304.12570)

    本文提出了一种新颖的可学习的基于支柱的图文检索重排方法，通过选择等级最高的内部和跨模态邻居作为支柱，并使用它们之间的邻居关系重构数据样本，将每个样本映射到多模态支柱空间中。

    

    图文检索旨在通过语义相似性跨模态检索内容。先前的工作通常关注二元关系（即数据样本是否匹配），而忽略了高阶邻居关系（即多个数据样本之间的匹配结构）。重排是一种流行的后处理实践，已经证明在单模态检索任务中捕捉邻居关系的优越性。然而，将现有的重排算法直接扩展到图文检索是无效的。在此论文中，我们从一般化、灵活性、稀疏性和不对称性四个方面分析了原因，并提出了一种新颖的可学习的基于支柱的图文检索重排。具体而言，我们首先选择等级最高的内部和跨模态邻居作为支柱，然后使用它们之间和支柱之间的邻居关系重构数据样本。通过这种方式，每个样本可以映射到多模态支柱空间中。

    Image-text retrieval aims to bridge the modality gap and retrieve cross-modal content based on semantic similarities. Prior work usually focuses on the pairwise relations (i.e., whether a data sample matches another) but ignores the higher-order neighbor relations (i.e., a matching structure among multiple data samples). Re-ranking, a popular post-processing practice, has revealed the superiority of capturing neighbor relations in single-modality retrieval tasks. However, it is ineffective to directly extend existing re-ranking algorithms to image-text retrieval. In this paper, we analyze the reason from four perspectives, i.e., generalization, flexibility, sparsity, and asymmetry, and propose a novel learnable pillar-based re-ranking paradigm. Concretely, we first select top-ranked intra- and inter-modal neighbors as pillars, and then reconstruct data samples with the neighbor relations between them and the pillars. In this way, each sample can be mapped into a multimodal pillar space
    
[^11]: COUPA: 一种面向在线到线下服务平台的工业级推荐系统

    COUPA: An Industrial Recommender System for Online to Offline Service Platforms. (arXiv:2304.12549v1 [cs.IR])

    [http://arxiv.org/abs/2304.12549](http://arxiv.org/abs/2304.12549)

    COUPA是一个面向O2O服务平台的工业级推荐系统，通过时间感知偏好和位置感知偏好来提高推荐效果。

    

    在线到线下（O2O）服务平台旨在帮助用户在本地发现零售服务（例如娱乐和餐饮），近年来变得越来越流行，这极大地挑战了现有的推荐系统。本文基于支付宝平台的真实数据，针对O2O服务的特殊情景发现了递归基础上的时间模式和位置偏置普遍存在，严重影响了推荐效果。基于此，我们提出了COUPA，这是一个工业级系统，旨在通过考虑以下两个方面来表征用户偏好：(1)时间感知偏好：我们采用了具有注意机制的连续时间感知点过程，以完全捕捉推荐的时间模式。(2)位置感知偏好：一个配备了位置个性化模块的位置选择器组件被精心设计，以以个性化的方式减轻位置偏差。最后，我们仔细实现并部署COUPA在支付宝平台上。

    Aiming at helping users locally discovery retail services (e.g., entertainment and dinning), Online to Offline (O2O) service platforms have become popular in recent years, which greatly challenge current recommender systems. With the real data in Alipay, a feeds-like scenario for O2O services, we find that recurrence based temporal patterns and position biases commonly exist in our scenarios, which seriously threaten the recommendation effectiveness. To this end, we propose COUPA, an industrial system targeting for characterizing user preference with following two considerations: (1) Time aware preference: we employ the continuous time aware point process equipped with an attention mechanism to fully capture temporal patterns for recommendation. (2) Position aware preference: a position selector component equipped with a position personalization module is elaborately designed to mitigate position bias in a personalized manner. Finally, we carefully implement and deploy COUPA on Alipay 
    
[^12]: GARCIA：利用多粒度对比学习提高长尾查询表示能力

    GARCIA: Powering Representations of Long-tail Query with Multi-granularity Contrastive Learning. (arXiv:2304.12537v1 [cs.LG])

    [http://arxiv.org/abs/2304.12537](http://arxiv.org/abs/2304.12537)

    GARCIA利用多粒度对比学习，基于图的知识转移和基于意图的表示，提高了长尾查询表示能力。

    

    最近，服务平台的发展为用户和商家带来了巨大的便利，服务搜索引擎通过文本查询在改善用户体验方面发挥着重要作用。然而，用户的不可控制的搜索习惯通常带来大量的长尾查询，这严重威胁到搜索模型的能力。针对这个问题，我们开发了一个新的框架GARCIA，利用基于图的知识转移和基于意图的表示来提高长尾查询表示能力。

    Recently, the growth of service platforms brings great convenience to both users and merchants, where the service search engine plays a vital role in improving the user experience by quickly obtaining desirable results via textual queries. Unfortunately, users' uncontrollable search customs usually bring vast amounts of long-tail queries, which severely threaten the capability of search models. Inspired by recently emerging graph neural networks (GNNs) and contrastive learning (CL), several efforts have been made in alleviating the long-tail issue and achieve considerable performance. Nevertheless, they still face a few major weaknesses. Most importantly, they do not explicitly utilize the contextual structure between heads and tails for effective knowledge transfer, and intention-level information is commonly ignored for more generalized representations.  To this end, we develop a novel framework GARCIA, which exploits the graph based knowledge transfer and intention based representat
    
[^13]: 无监督和半监督流形学习的Rank Flow Embedding

    Rank Flow Embedding for Unsupervised and Semi-Supervised Manifold Learning. (arXiv:2304.12448v1 [cs.CV])

    [http://arxiv.org/abs/2304.12448](http://arxiv.org/abs/2304.12448)

    本文提出了Rank Flow Embedding算法用于无监督和半监督场景的流形学习。

    

    先进的获取和共享技术使得多媒体集合及其应用的增长几乎无限，然而，由于标注数据往往昂贵而费时，因此有监督的训练所需的标注数据可用性相反。我们提出了一种名为Rank Flow Embedding（RFE）的新型流形学习算法用于无监督和半监督场景。该算法基于最近流形学习方法利用的想法，包括超图、笛卡尔积和连通成分。

    Impressive advances in acquisition and sharing technologies have made the growth of multimedia collections and their applications almost unlimited. However, the opposite is true for the availability of labeled data, which is needed for supervised training, since such data is often expensive and time-consuming to obtain. While there is a pressing need for the development of effective retrieval and classification methods, the difficulties faced by supervised approaches highlight the relevance of methods capable of operating with few or no labeled data. In this work, we propose a novel manifold learning algorithm named Rank Flow Embedding (RFE) for unsupervised and semi-supervised scenarios. The proposed method is based on ideas recently exploited by manifold learning approaches, which include hypergraphs, Cartesian products, and connected components. The algorithm computes context-sensitive embeddings, which are refined following a rank-based processing flow, while complementary contextu
    
[^14]: 问题回答中的答案类型预测的极限分类

    Extreme Classification for Answer Type Prediction in Question Answering. (arXiv:2304.12395v1 [cs.CL])

    [http://arxiv.org/abs/2304.12395](http://arxiv.org/abs/2304.12395)

    本文提出了使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类，以提高问题回答（QA）系统中语义答案类型预测（SMART）任务的性能，并获得最先进的结果。

    

    语义答案类型预测（SMART）已被证明是有效的问题回答（QA）系统的有用步骤。 SMART任务涉及预测给定自然语言问题的前k个知识图（KG）类型。由于KG中存在大量类型，这是具有挑战性的。在本文中，我们提出使用Transformer模型（XBERT）进行极端多标签分类，通过将KG类型基于问题文本使用结构和语义特征进行聚类。我们具体地改善了XBERT流程的聚类阶段，利用从KG中派生的文本和结构特征。我们表明，这些特征可以提高SMART任务的端到端性能，并产生最先进的结果。

    Semantic answer type prediction (SMART) is known to be a useful step towards effective question answering (QA) systems. The SMART task involves predicting the top-$k$ knowledge graph (KG) types for a given natural language question. This is challenging due to the large number of types in KGs. In this paper, we propose use of extreme multi-label classification using Transformer models (XBERT) by clustering KG types using structural and semantic features based on question text. We specifically improve the clustering stage of the XBERT pipeline using textual and structural features derived from KGs. We show that these features can improve end-to-end performance for the SMART task, and yield state-of-the-art results.
    
[^15]: TREC 2022 NeuCLIR轨道综述

    Overview of the TREC 2022 NeuCLIR Track. (arXiv:2304.12367v1 [cs.IR])

    [http://arxiv.org/abs/2304.12367](http://arxiv.org/abs/2304.12367)

    TREC NeuCLIR轨道的第一年，研究神经方法对跨语言信息检索的影响，通过英语查询来ad hoc排名检索中文、波斯语或俄语新闻文档，共有12个团队提交了172次运行。

    

    这是TREC神经CLIR（NeuCLIR）轨道的第一年，旨在研究神经方法对跨语言信息检索的影响。今年轨道的主要任务是使用用英语表达的查询，对中文、波斯语或俄语新闻文档进行ad hoc排名检索。话题是使用标准的TREC流程开发的，除了在评估该话题的不同语言上评估一个注释器开发的话题时，由另一个注释器开发的话题。共有12个团队提交了172次运行。

    This is the first year of the TREC Neural CLIR (NeuCLIR) track, which aims to study the impact of neural approaches to cross-language information retrieval. The main task in this year's track was ad hoc ranked retrieval of Chinese, Persian, or Russian newswire documents using queries expressed in English. Topics were developed using standard TREC processes, except that topics developed by an annotator for one language were assessed by a different annotator when evaluating that topic on a different language. There were 172 total runs submitted by twelve teams.
    
[^16]: USTEP: 基于演化树结构的在线日志解析方法

    USTEP: Structuration des logs en flux gr{\^a}ce {\`a} un arbre de recherche {\'e}volutif. (arXiv:2304.12331v1 [cs.CL])

    [http://arxiv.org/abs/2304.12331](http://arxiv.org/abs/2304.12331)

    本论文提出了一种基于演化树结构的在线日志解析方法USTEP，该方法在有效性和鲁棒性方面优越。

    

    运行时日志记录了有价值的系统信息。它们被广泛用于数据驱动的开发和监控目的。解析日志消息以结构化其格式是日志挖掘任务的经典预备步骤。由于它们出现在上游，解析操作可能成为下游应用程序的处理时间瓶颈。解析质量也直接影响其效率。本文提出了一种基于演化树结构的在线日志解析方法USTEP。对来自不同实际系统的广泛数据集的评估结果表明，与其他在线方法相比，USTEP在有效性和鲁棒性方面优越。

    Logs record valuable system information at runtime. They are widely used by data-driven approaches for development and monitoring purposes. Parsing log messages to structure their format is a classic preliminary step for log-mining tasks. As they appear upstream, parsing operations can become a processing time bottleneck for downstream applications. The quality of parsing also has a direct influence on their efficiency. Here, we propose USTEP, an online log parsing method based on an evolving tree structure. Evaluation results on a wide panel of datasets coming from different real-world systems demonstrate USTEP superiority in terms of both effectiveness and robustness when compared to other online methods.
    
[^17]: 推荐系统的连续输入嵌入大小搜索

    Continuous Input Embedding Size Search For Recommender Systems. (arXiv:2304.03501v1 [cs.IR])

    [http://arxiv.org/abs/2304.03501](http://arxiv.org/abs/2304.03501)

    提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。

    

    潜在因子模型是现今推荐系统最流行的基础，其性能卓越。潜在因子模型通过对用户和项目进行表示，用于对成对相似度的计算。所有嵌入向量传统上都被限制在一个相对较大的统一大小（例如256维）。随着当代电子商务中用户和项目目录指数级增长，这种设计显然变得效率低下。为了促进轻量级推荐，强化学习（RL）最近开辟了一些机会，用于识别不同用户/项目的不同嵌入大小。然而，受到搜索效率和学习最优RL策略的限制，现有的基于RL的方法被限制为高度离散的预定义嵌入大小选项。这导致了一个被广泛忽视的潜力，可以在给定计算预算下引入更细的粒度来获得更好的推荐效果。在本文中，我们提出了一种新方法，称为CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索。CONTINUOUS通过将嵌入大小选择建模为连续变量和制定可微优化问题的形式来解决之前工作的挑战。在三个基准数据集上的实验证实了CONTINUOUS优于基线的优越性，验证了动态优化嵌入大小的有效性和高效性。

    Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a giv
    
[^18]: 开源软件开发者的代码推荐

    Code Recommendation for Open Source Software Developers. (arXiv:2210.08332v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2210.08332](http://arxiv.org/abs/2210.08332)

    CODER 是一个基于图的代码推荐框架，通过建模微观用户-代码交互和宏观用户-项目交互，预测开发者未来的贡献行为，以缩短开发时间并提高开发效率。

    

    开源软件是技术基础设施的支柱，吸引数百万人才做出贡献。考虑到开发人员的兴趣和项目代码的语义特征，向开源软件开发者推荐适当的开发任务具有挑战性和重要性。在本文中，我们提出了一个新颖的代码推荐问题，其目的是根据开发者的交互历史、源代码的语义特征和项目的分层文件结构来预测开发者未来的贡献行为。考虑到系统中多方之间的复杂交互，我们提出了CODER，这是一个新颖的基于图的开源软件开发者代码推荐框架。CODER通过异构图共同建模微观用户-代码交互和宏观用户-项目交互，并通过在反映文件结构的文件结构图上的聚合进一步连接两个级别的信息。

    Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. Considering the complex interactions among multiple parties within the system, we propose CODER, a novel graph-based code recommendation framework for open source software developers. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect 
    

