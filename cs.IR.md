# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Benchmarking News Recommendation in the Era of Green AI](https://arxiv.org/abs/2403.04736) | 提出了用于新闻推荐的第一个绿色AI基准测试框架GreenRec，并引入评估推荐准确性和效率权衡的度量标准，实验证明其OLEO范式在可持续性方面取得竞争准确性且提供高达2992%的可持续性改进 |
| [^2] | [Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation](https://arxiv.org/abs/2403.04503) | Ducho 2.0推出，提供更个性化的用户体验和支持多模态大型模型提取和处理特征，可用于多模式推荐，同时优化数据加载和存储。 |
| [^3] | [A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges](https://arxiv.org/abs/2403.04468) | 本文调查了图神经网络在现实世界中面临的不平衡、噪声、隐私和OOD挑战，并致力于提高模型性能、可靠性和鲁棒性。 |
| [^4] | [The 2nd Workshop on Recommendation with Generative Models](https://arxiv.org/abs/2403.04399) | 生成模型的兴起推动了推荐系统的重大进步，为增强用户个性化推荐提供了独特机会，该研讨会主要关注生成模型在推荐系统中的创新应用，涵盖算法改进、个性化内容生成、用户交互演变、可信度检查加强和评估方法完善等五个关键视角。 |
| [^5] | [ALTO: An Efficient Network Orchestrator for Compound AI Systems](https://arxiv.org/abs/2403.04311) | ALTO是一个网络编排器，针对生成语言模型的优化机会，实现了高吞吐量和低延迟，同时解决了流式中间输出的两个新挑战：正确性和负载平衡。 |
| [^6] | [DGR: A General Graph Desmoothing Framework for Recommendation via Global and Local Perspectives](https://arxiv.org/abs/2403.04287) | 该论文介绍了DGR框架，通过考虑全局和局部视角有效解决了常规GCN-based推荐模型中的过度平滑问题。 |
| [^7] | [SSDRec: Self-Augmented Sequence Denoising for Sequential Recommendation](https://arxiv.org/abs/2403.04278) | 提出了一种SSDRec方法，通过在去噪之前插入项来增强序列，以减少噪声对顺序推荐的影响。 |
| [^8] | [Can Small Language Models be Good Reasoners for Sequential Recommendation?](https://arxiv.org/abs/2403.04260) | 提出了逐步知识提取框架（SLIM），为顺序推荐系统解决了大型语言模型（LLMs）高资源需求的难题，使其能以资源高效的方式享受LLMs的出色推理能力。 |
| [^9] | [Towards Robustness Analysis of E-Commerce Ranking System](https://arxiv.org/abs/2403.04257) | 本文提出了关于电子商务排名系统稳健性的首个系统性测量研究，定义了稳健性为语义相同查询排名结果的一致性，并提出了一种新颖的度量标准来定量分析稳健性。 |
| [^10] | [Federated Recommendation via Hybrid Retrieval Augmented Generation](https://arxiv.org/abs/2403.04256) | 提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制，解决了传统FR系统在数据稀疏性和异构性方面的性能下降问题，弥补了基于LLM的推荐器在实际场景中推理效率低和潜在幻觉等挑战，实现了隐私保护推荐的目标 |
| [^11] | [RATSF: Empowering Customer Service Volume Management through Retrieval-Augmented Time-Series Forecasting](https://arxiv.org/abs/2403.04180) | 提出了一种检索增强时序序列预测框架(RATSF)，通过引入交叉注意力模块(RACA)及知识库设计，有效利用历史数据段进行客服量预测，在非平稳数据情况下显著提升了性能。 |
| [^12] | [Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](https://arxiv.org/abs/2403.04160) | 提出了一种利用语料库主题分类改进主题特定应用中检索的框架，通过确定查询和文档的中心主题以及利用主题相关性来补充缺失的上下文。 |
| [^13] | [Personalized Negative Reservoir for Incremental Learning in Recommender Systems](https://arxiv.org/abs/2403.03993) | 推荐系统中的个性化负采样技术在增量学习中的应用，解决了更新推荐系统模型时遇到的遗忘灾难问题。 |
| [^14] | [Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation](https://arxiv.org/abs/2403.00877) | Disaggregated Multi-Tower提出了一种面向拓扑感知的建模技术，通过SPTT、TM和TP三个组件实现了高效的大规模推荐，加速性能提升了1.9倍。 |
| [^15] | [Modeling User Viewing Flow Using Large Language Models for Article Recommendation](https://arxiv.org/abs/2311.07619) | 本文提出了SINGLE方法，使用大型语言模型对用户浏览流进行建模，以更好地进行文章推荐。 |
| [^16] | [Budgeted Embedding Table For Recommender Systems](https://arxiv.org/abs/2310.14884) | 提出了一种预算嵌入表的方法，解决了传统推荐系统中固定嵌入大小难以扩展的问题，能够有效应对不同用户和项目的多样性嵌入大小。 |
| [^17] | [Interactive Question Answering Systems: Literature Review](https://arxiv.org/abs/2209.01621) | 交互式问答系统是问答和对话系统的结合，用户可以用自然语言提问并与系统动态交互，获得更精确的结果。 |
| [^18] | [Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval.](http://arxiv.org/abs/2310.20091) | 本研究引入了一种基于密度的用户表示(DURs)，利用高斯过程回归实现了有效的多兴趣推荐和检索。该方法不仅能够捕捉用户的兴趣变化，还具备不确定性感知能力，并且适用于大量用户的规模。 |
| [^19] | [Continuous Input Embedding Size Search For Recommender Systems.](http://arxiv.org/abs/2304.03501) | 提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。 |

# 详细

[^1]: 在绿色AI时代对新闻推荐进行基准测试

    Benchmarking News Recommendation in the Era of Green AI

    [https://arxiv.org/abs/2403.04736](https://arxiv.org/abs/2403.04736)

    提出了用于新闻推荐的第一个绿色AI基准测试框架GreenRec，并引入评估推荐准确性和效率权衡的度量标准，实验证明其OLEO范式在可持续性方面取得竞争准确性且提供高达2992%的可持续性改进

    

    近年来，新闻推荐系统在学术界和工业界备受关注，强调了需要一个标准化基准来评估和比较这些系统的性能。同时，绿色人工智能倡导减少机器学习的能耗和环境影响。为了解决这些问题，我们引入了第一个用于新闻推荐的绿色AI基准测试框架，称为GreenRec，并提出了一个评估推荐准确性和效率之间权衡的度量标准。我们的基准测试涵盖30个基础模型及其变体，涵盖了传统的端到端训练范式以及我们提出的高效的仅编码一次（OLEO）范式。通过消耗2000个GPU小时的实验，我们观察到OLEO范式在可持续性方面相较于最先进的端到端范式实现了具竞争力的准确性，并提供高达2992%的可持续性改进。

    arXiv:2403.04736v1 Announce Type: new  Abstract: Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992\% improvement in sustainability
    
[^2]: Ducho 2.0：面向多模式推荐的更为时尚的特征提取和处理框架

    Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation

    [https://arxiv.org/abs/2403.04503](https://arxiv.org/abs/2403.04503)

    Ducho 2.0推出，提供更个性化的用户体验和支持多模态大型模型提取和处理特征，可用于多模式推荐，同时优化数据加载和存储。

    

    在这项工作中，我们介绍了Ducho 2.0，我们框架的最新稳定版本。与Ducho不同，Ducho 2.0提供了更个性化的用户体验，可以定义和导入在特定任务和数据集上进行了微调的自定义提取模型。此外，新版本能够通过多模态设计的大型模型提取和处理特征。值得注意的是，所有这些新功能都受到了对本地存储器进行了优化的数据加载和存储的支持。为了展示Ducho 2.0的功能，我们展示了一个完整的多模式推荐流水线，从提取/处理到最终推荐。我们的想法是为从业者和经验丰富的学者提供一个即用工具，可以在任何多模式推荐框架之上运行广泛的基准分析。所有材料都可以在以下网址获得：\url{https://github.com/sisinflab/Ducho}。

    arXiv:2403.04503v1 Announce Type: new  Abstract: In this work, we introduce Ducho 2.0, the latest stable version of our framework. Differently from Ducho, Ducho 2.0 offers a more personalized user experience with the definition and import of custom extraction models fine-tuned on specific tasks and datasets. Moreover, the new version is capable of extracting and processing features through multimodal-by-design large models. Notably, all these new features are supported by optimized data loading and storing to the local memory. To showcase the capabilities of Ducho 2.0, we demonstrate a complete multimodal recommendation pipeline, from the extraction/processing to the final recommendation. The idea is to provide practitioners and experienced scholars with a ready-to-use tool that, put on top of any multimodal recommendation framework, may permit them to run extensive benchmarking analyses. All materials are accessible at: \url{https://github.com/sisinflab/Ducho}.
    
[^3]: 关于图神经网络在现实世界中的调查：不平衡、噪声、隐私和OOD挑战

    A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges

    [https://arxiv.org/abs/2403.04468](https://arxiv.org/abs/2403.04468)

    本文调查了图神经网络在现实世界中面临的不平衡、噪声、隐私和OOD挑战，并致力于提高模型性能、可靠性和鲁棒性。

    

    arXiv:2403.04468v1 发布类型: 跨域 摘要: 图结构化数据表现出普适性和广泛适用性，涵盖社交网络分析、生物化学、金融欺诈检测和网络安全等多个领域。在利用图神经网络（GNNs）取得显著成功方面已经取得了重要进展。然而，在实际应用场景中，模型的训练环境往往远非理想，由于各种不利因素，包括数据分布不平衡、错误数据中存在噪声、敏感信息的隐私保护以及对于OOD场景的泛化能力，导致GNN模型的性能大幅下降。为解决这些问题，人们致力于改善GNN模型在实际应用场景中的性能，提高其可靠性和鲁棒性。本文全面调查了...

    arXiv:2403.04468v1 Announce Type: cross  Abstract: Graph-structured data exhibits universality and widespread applicability across diverse domains, such as social network analysis, biochemistry, financial fraud detection, and network security. Significant strides have been made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success in these areas. However, in real-world scenarios, the training environment for models is often far from ideal, leading to substantial performance degradation of GNN models due to various unfavorable factors, including imbalance in data distribution, the presence of noise in erroneous data, privacy protection of sensitive information, and generalization capability for out-of-distribution (OOD) scenarios. To tackle these issues, substantial efforts have been devoted to improving the performance of GNN models in practical real-world scenarios, as well as enhancing their reliability and robustness. In this paper, we present a comprehensive surv
    
[^4]: 《基于生成模型的推荐系统第二次研讨会》

    The 2nd Workshop on Recommendation with Generative Models

    [https://arxiv.org/abs/2403.04399](https://arxiv.org/abs/2403.04399)

    生成模型的兴起推动了推荐系统的重大进步，为增强用户个性化推荐提供了独特机会，该研讨会主要关注生成模型在推荐系统中的创新应用，涵盖算法改进、个性化内容生成、用户交互演变、可信度检查加强和评估方法完善等五个关键视角。

    

    生成模型的兴起推动了推荐系统的重大进步，为增强用户个性化推荐提供了独特机会。该研讨会旨在为研究人员提供一个平台，探讨和交流与将生成模型整合到推荐系统中相关的创新概念。主要关注五个关键视角：（i）改进推荐算法，（ii）生成个性化内容，（iii）演变用户-系统交互范式，（iv）增强可信度检查，和（v）完善生成推荐的评估方法。随着生成模型的快速发展，这些领域出现了越来越多的研究，强调了此研讨会的及时性和重要性。相关研究将向推荐系统引入创新技术，并在学术界和工业界为新挑战做出贡献。

    arXiv:2403.04399v1 Announce Type: new  Abstract: The rise of generative models has driven significant advancements in recommender systems, leaving unique opportunities for enhancing users' personalized recommendations. This workshop serves as a platform for researchers to explore and exchange innovative concepts related to the integration of generative models into recommender systems. It primarily focuses on five key perspectives: (i) improving recommender algorithms, (ii) generating personalized content, (iii) evolving the user-system interaction paradigm, (iv) enhancing trustworthiness checks, and (v) refining evaluation methodologies for generative recommendations. With generative models advancing rapidly, an increasing body of research is emerging in these domains, underscoring the timeliness and critical importance of this workshop. The related research will introduce innovative technologies to recommender systems and contribute to fresh challenges in both academia and industry. I
    
[^5]: ALTO：一种用于复合AI系统的高效网络编排器

    ALTO: An Efficient Network Orchestrator for Compound AI Systems

    [https://arxiv.org/abs/2403.04311](https://arxiv.org/abs/2403.04311)

    ALTO是一个网络编排器，针对生成语言模型的优化机会，实现了高吞吐量和低延迟，同时解决了流式中间输出的两个新挑战：正确性和负载平衡。

    

    我们提出了ALTO，一种用于有效为诸如语言模型管道之类的复合AI系统提供服务的网络编排器。ALTO通过利用生成语言模型特有的优化机会：流式中间输出，实现了高吞吐量和低延迟。由于语言模型逐个生成token的输出，ALTO在可能时暴露了在阶段之间流式传输中间输出的机会。我们强调了在跨分布式管道阶段实例之间流式传输中间数据时出现的两个新挑战：正确性和负载平衡。我们还提出了聚合感知路由接口和分布式提示感知调度以应对这些挑战的需求。我们在一个复杂的聊天机器人验证管道上展示了ALTO部分输出流式传输的影响，将吞吐量提高了最多3倍，同时将固定延迟目标设置为4秒/请求，还减少了尾延迟。

    arXiv:2403.04311v1 Announce Type: new  Abstract: We present ALTO, a network orchestrator for efficiently serving compound AI systems such as pipelines of language models. ALTO achieves high throughput and low latency by taking advantage of an optimization opportunity specific to generative language models: streaming intermediate outputs. As language models produce outputs token by token, ALTO exposes opportunities to stream intermediate outputs between stages when possible. We highlight two new challenges of correctness and load balancing which emerge when streaming intermediate data across distributed pipeline stage instances. We also motivate the need for an aggregation-aware routing interface and distributed prompt-aware scheduling to address these challenges. We demonstrate the impact of ALTO's partial output streaming on a complex chatbot verification pipeline, increasing throughput by up to 3x for a fixed latency target of 4 seconds / request while also reducing tail latency by 1
    
[^6]: DGR：一种通过全局和局部视角进行推荐的通用图去平滑框架

    DGR: A General Graph Desmoothing Framework for Recommendation via Global and Local Perspectives

    [https://arxiv.org/abs/2403.04287](https://arxiv.org/abs/2403.04287)

    该论文介绍了DGR框架，通过考虑全局和局部视角有效解决了常规GCN-based推荐模型中的过度平滑问题。

    

    Graph Convolutional Networks (GCNs)已经成为推荐系统中的重要组成部分，通过利用用户-物品交互图的节点信息和拓扑结构来学习用户和物品的嵌入。然而，这些模型经常面临着过度平滑的问题，导致模糊的用户和物品嵌入以及降低的个性化。传统的去平滑方法在基于GCN的系统中是特定于模型的，缺乏通用解决方案。本文提出了一种新颖的、与模型无关的方法，命名为DGR：去平滑框架用于GCN-based推荐系统，通过考虑全局和局部视角有效地解决了常规GCN-based推荐模型中的过度平滑问题。

    arXiv:2403.04287v1 Announce Type: new  Abstract: Graph Convolutional Networks (GCNs) have become pivotal in recommendation systems for learning user and item embeddings by leveraging the user-item interaction graph's node information and topology. However, these models often face the famous over-smoothing issue, leading to indistinct user and item embeddings and reduced personalization. Traditional desmoothing methods in GCN-based systems are model-specific, lacking a universal solution. This paper introduces a novel, model-agnostic approach named \textbf{D}esmoothing Framework for \textbf{G}CN-based \textbf{R}ecommendation Systems (\textbf{DGR}). It effectively addresses over-smoothing on general GCN-based recommendation models by considering both global and local perspectives. Specifically, we first introduce vector perturbations during each message passing layer to penalize the tendency of node embeddings approximating overly to be similar with the guidance of the global topological
    
[^7]: SSDRec：自我增强序列去噪用于顺序推荐

    SSDRec: Self-Augmented Sequence Denoising for Sequential Recommendation

    [https://arxiv.org/abs/2403.04278](https://arxiv.org/abs/2403.04278)

    提出了一种SSDRec方法，通过在去噪之前插入项来增强序列，以减少噪声对顺序推荐的影响。

    

    arXiv：2403.04278v1 发表类型：新摘要：传统的顺序推荐方法假设用户的序列数据足够干净，可以学习准确的序列表示以反映用户偏好。然而，在实践中，用户的序列不可避免地包含噪声（例如，偶然的交互），导致对用户偏好的不正确反映。因此，一些先驱性研究探讨了建模序列性和序列之间关联性以隐式或显式地减少噪声的影响。然而，仅依赖于序列内信息（即，序列内的顺序性和关联性）是不足的，可能会导致过度去噪和欠去噪问题（OUPs），尤其是对于短序列。为了提高可靠性，我们建议在去噪之前通过插入项来增强序列。然而，由于数据稀疏问题和计算成本，选择整个项目世界中的适当项目插入适当位置是具有挑战性的。

    arXiv:2403.04278v1 Announce Type: new  Abstract: Traditional sequential recommendation methods assume that users' sequence data is clean enough to learn accurate sequence representations to reflect user preferences. In practice, users' sequences inevitably contain noise (e.g., accidental interactions), leading to incorrect reflections of user preferences. Consequently, some pioneer studies have explored modeling sequentiality and correlations in sequences to implicitly or explicitly reduce noise's influence. However, relying on only available intra-sequence information (i.e., sequentiality and correlations in a sequence) is insufficient and may result in over-denoising and under-denoising problems (OUPs), especially for short sequences. To improve reliability, we propose to augment sequences by inserting items before denoising. However, due to the data sparsity issue and computational costs, it is challenging to select proper items from the entire item universe to insert into proper po
    
[^8]: 小型语言模型能成为顺序推荐系统的良好推理者吗？

    Can Small Language Models be Good Reasoners for Sequential Recommendation?

    [https://arxiv.org/abs/2403.04260](https://arxiv.org/abs/2403.04260)

    提出了逐步知识提取框架（SLIM），为顺序推荐系统解决了大型语言模型（LLMs）高资源需求的难题，使其能以资源高效的方式享受LLMs的出色推理能力。

    

    大型语言模型（LLMs）由于其出色的语言理解和生成能力，为顺序推荐开拓了新的领域。然而，要成功实现由LLMs赋能的顺序推荐还有许多挑战需要解决。首先，用户行为模式通常复杂，仅仅依靠LLMs的一步推理可能会导致错误或与任务无关的响应。其次，LLMs（例如ChatGPT-175B）极高的资源需求是难以承受且在实际顺序推荐系统中不切实际的。本文提出了一个新颖的逐步知识提取框架用于推荐（SLIM），为顺序推荐器以“瘦”（即资源高效）的方式享受LLMs出色的推理能力铺平了一条有前途的道路。我们引入基于用户行为序列的CoT提示来实现更好的推荐。

    arXiv:2403.04260v1 Announce Type: cross  Abstract: Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larg
    
[^9]: 面向电子商务排名系统的稳健分析

    Towards Robustness Analysis of E-Commerce Ranking System

    [https://arxiv.org/abs/2403.04257](https://arxiv.org/abs/2403.04257)

    本文提出了关于电子商务排名系统稳健性的首个系统性测量研究，定义了稳健性为语义相同查询排名结果的一致性，并提出了一种新颖的度量标准来定量分析稳健性。

    

    arXiv:2403.04257v1 公告类型：新的 摘要：信息检索（IR）是各种应用中的关键组成部分。最近机器学习（ML）的进展使得ML算法能够整合到IR中，特别是在排名系统中。虽然有大量关于基于ML的排名系统的稳健性的研究，但这些研究在很大程度上忽视了商业电子商务系统，并未建立实际世界和操作查询相关性之间的联系。在本文中，我们提出了关于电子商务排名系统稳健性的第一个系统性测量研究。我们将稳健性定义为语义相同查询的排名结果的一致性。为了定量分析稳健性，我们提出了一种新颖的度量标准，考虑了排名位置和现有度量中缺失的特定项目信息。我们使用来自电子商务零售商的真实数据进行大规模的测量研究，揭示了一个衡量和改进稳健性的开放机会。

    arXiv:2403.04257v1 Announce Type: new  Abstract: Information retrieval (IR) is a pivotal component in various applications. Recent advances in machine learning (ML) have enabled the integration of ML algorithms into IR, particularly in ranking systems. While there is a plethora of research on the robustness of ML-based ranking systems, these studies largely neglect commercial e-commerce systems and fail to establish a connection between real-world and manipulated query relevance. In this paper, we present the first systematic measurement study on the robustness of e-commerce ranking systems. We define robustness as the consistency of ranking outcomes for semantically identical queries. To quantitatively analyze robustness, we propose a novel metric that considers both ranking position and item-specific information that are absent in existing metrics. Our large-scale measurement study with real-world data from e-commerce retailers reveals an open opportunity to measure and improve robus
    
[^10]: 基于混合检索增强生成的联邦推荐

    Federated Recommendation via Hybrid Retrieval Augmented Generation

    [https://arxiv.org/abs/2403.04256](https://arxiv.org/abs/2403.04256)

    提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制，解决了传统FR系统在数据稀疏性和异构性方面的性能下降问题，弥补了基于LLM的推荐器在实际场景中推理效率低和潜在幻觉等挑战，实现了隐私保护推荐的目标

    

    联邦推荐（FR）是一种新兴范式，能够实现隐私保护推荐。然而，传统的FR系统通常使用离散的身份（ID）表示用户/物品，在FR中由于数据稀疏性和异构性而导致性能下降。另一方面，大型语言模型（LLMs）作为推荐器已经在各种推荐场景中被证明有效。然而，基于LLM的推荐器面临诸如推理效率低和潜在幻觉等挑战，从而影响它们在实际场景中的表现。为此，我们提出了一个名为GPT-FedRec的联邦推荐框架，利用ChatGPT和一种新颖的混合检索增强生成（RAG）机制。GPT-FedRec是一个两阶段的解决方案。第一阶段是一个混合检索过程，挖掘基于ID的用户模式和基于文本的商品特征。接下来，所检索到的结果被转换为文本提示

    arXiv:2403.04256v1 Announce Type: cross  Abstract: Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to the data sparsity and heterogeneity in FR. On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. Yet, LLM-based recommenders encounter challenges such as low inference efficiency and potential hallucination, compromising their performance in real-world scenarios. To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features. Next, the retrieved results are converted into text prompts and
    
[^11]: RATSF：通过检索增强时间序列预测来赋能客服量管理

    RATSF: Empowering Customer Service Volume Management through Retrieval-Augmented Time-Series Forecasting

    [https://arxiv.org/abs/2403.04180](https://arxiv.org/abs/2403.04180)

    提出了一种检索增强时序序列预测框架(RATSF)，通过引入交叉注意力模块(RACA)及知识库设计，有效利用历史数据段进行客服量预测，在非平稳数据情况下显著提升了性能。

    

    一个高效的客服管理系统取决于对服务量的精确预测。在这种数据非平稳性明显的情况下，成功的预测严重依赖于识别和利用类似的历史数据，而不仅仅是总结周期性模式。现有基于RNN或Transformer架构的模型通常在灵活和有效利用方面存在挑战。为了解决这一挑战，我们提出了一种高效且可适应的交叉注意力模块，称为RACA，它在预测任务中有效利用了历史段，并设计了一个精确的历史序列查询表示方案，结合了知识库的设计。这些关键组件共同构成了我们的检索增强时序序列预测框架（RATSF）。RATSF不仅在菲鸡酒店服务量预测环境中显著增强了性能，而且...

    arXiv:2403.04180v1 Announce Type: new  Abstract: An efficient customer service management system hinges on precise forecasting of service volume. In this scenario, where data non-stationarity is pronounced, successful forecasting heavily relies on identifying and leveraging similar historical data rather than merely summarizing periodic patterns. Existing models based on RNN or Transformer architectures often struggle with this flexible and effective utilization. To address this challenge, we propose an efficient and adaptable cross-attention module termed RACA, which effectively leverages historical segments in forecasting task, and we devised a precise representation scheme for querying historical sequences, coupled with the design of a knowledge repository. These critical components collectively form our Retrieval-Augmented Temporal Sequence Forecasting framework (RATSF). RATSF not only significantly enhances performance in the context of Fliggy hotel service volume forecasting but,
    
[^12]: 利用语料库主题分类改进主题特定应用中的检索

    Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy

    [https://arxiv.org/abs/2403.04160](https://arxiv.org/abs/2403.04160)

    提出了一种利用语料库主题分类改进主题特定应用中检索的框架，通过确定查询和文档的中心主题以及利用主题相关性来补充缺失的上下文。

    

    文献检索已经从大规模预训练语言模型（PLM）的进步中受益良多。然而，它们的有效性在专门领域或行业的主题特定应用中通常受到限制，这是由于独特术语、用户查询的不完整上下文和专门搜索意图导致的。为了捕捉主题特定信息并改进检索，我们提出使用语料库主题分类，该分类概述了语料库的潜在主题结构，同时反映了用户感兴趣的方面。我们介绍了ToTER（增强型主题分类检索）框架，该框架借助分类的指导确定查询和文档的中心主题，并利用它们的主题相关性补充缺失的上下文。作为一种即插即用的框架，ToTER可灵活应用于增强各种基于PLM的检索器。通过对两个案例进行广泛的定量、缺失和探索性实验，我们评估了ToTER框架的性能。

    arXiv:2403.04160v1 Announce Type: cross  Abstract: Document retrieval has greatly benefited from the advancements of large-scale pre-trained language models (PLMs). However, their effectiveness is often limited in theme-specific applications for specialized areas or industries, due to unique terminologies, incomplete contexts of user queries, and specialized search intents. To capture the theme-specific information and improve retrieval, we propose to use a corpus topical taxonomy, which outlines the latent topic structure of the corpus while reflecting user-interested aspects. We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which identifies the central topics of queries and documents with the guidance of the taxonomy, and exploits their topical relatedness to supplement missing contexts. As a plug-and-play framework, ToTER can be flexibly employed to enhance various PLM-based retrievers. Through extensive quantitative, ablative, and exploratory experiments on two r
    
[^13]: 个性化负采样在推荐系统增量学习中的应用

    Personalized Negative Reservoir for Incremental Learning in Recommender Systems

    [https://arxiv.org/abs/2403.03993](https://arxiv.org/abs/2403.03993)

    推荐系统中的个性化负采样技术在增量学习中的应用，解决了更新推荐系统模型时遇到的遗忘灾难问题。

    

    推荐系统已成为在线平台的重要组成部分。每天训练数据量不断扩大，用户互动次数不断增加。探索更大更具表现力的模型已成为改善用户体验的必要追求。然而，这种进展带来了更大的计算负担。在商业环境中，一旦推荐系统模型被训练和部署，通常需要频繁更新以适应新的客户数据。累积起来，数据量的增加必将使得从头开始进行全量重训练变得计算上不可行。仅仅在新数据上进行简单微调会遇到已被广泛记录的遗忘灾难问题。尽管负采样在使用隐式反馈进行训练中是至关重要的一部分，但目前并不存在专门针对增量学习的技术。

    arXiv:2403.03993v1 Announce Type: cross  Abstract: Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the increme
    
[^14]: Disaggregated Multi-Tower: 面向拓扑感知的高效大规模推荐建模技术

    Disaggregated Multi-Tower: Topology-aware Modeling Technique for Efficient Large-Scale Recommendation

    [https://arxiv.org/abs/2403.00877](https://arxiv.org/abs/2403.00877)

    Disaggregated Multi-Tower提出了一种面向拓扑感知的建模技术，通过SPTT、TM和TP三个组件实现了高效的大规模推荐，加速性能提升了1.9倍。

    

    我们研究了深度学习推荐模型的扁平架构、常见的分布式训练模式和分层数据中心拓扑之间的不匹配。为了解决相关的低效性，我们提出了Disaggregated Multi-Tower（DMT），这是一种建模技术，包括（1）语义保留的Tower Transform（SPTT），一个将单片全局嵌入查找过程分解为不相交塔以利用数据中心位置关系的新型训练模式；（2）Tower Module（TM），一个附加到每个塔的协同稠密组件，通过分层特征交互降低模型复杂性和通信量；和（3）Tower Partitioner（TP），一个特征分区器，系统地创建具有有意义特征交互和负载平衡分配的塔，通过学习的嵌入来保持模型质量和训练吞吐量。我们展示了DMT相比于最新的方法可以实现高达1.9倍的加速。

    arXiv:2403.00877v1 Announce Type: new  Abstract: We study a mismatch between the deep learning recommendation models' flat architecture, common distributed training paradigm and hierarchical data center topology. To address the associated inefficiencies, we propose Disaggregated Multi-Tower (DMT), a modeling technique that consists of (1) Semantic-preserving Tower Transform (SPTT), a novel training paradigm that decomposes the monolithic global embedding lookup process into disjoint towers to exploit data center locality; (2) Tower Module (TM), a synergistic dense component attached to each tower to reduce model complexity and communication volume through hierarchical feature interaction; and (3) Tower Partitioner (TP), a feature partitioner to systematically create towers with meaningful feature interactions and load balanced assignments to preserve model quality and training throughput via learned embeddings. We show that DMT can achieve up to 1.9x speedup compared to the state-of-th
    
[^15]: 使用大型语言模型对用户浏览流进行建模以进行文章推荐

    Modeling User Viewing Flow Using Large Language Models for Article Recommendation

    [https://arxiv.org/abs/2311.07619](https://arxiv.org/abs/2311.07619)

    本文提出了SINGLE方法，使用大型语言模型对用户浏览流进行建模，以更好地进行文章推荐。

    

    本文提出了用户浏览流建模（SINGLE）方法用于文章推荐任务，该方法从用户点击的文章中模拟用户的持续偏好和即时兴趣。具体而言，我们首先采用用户持续浏览流建模方法总结用户的一般兴趣以推荐文章。在这种情况下，我们利用大型语言模型（LLMs）从先前点击的文章中捕捉用户的持续偏好，如技能和职位。然后我们设计用户即时浏览流建模方法来构建用户点击的文章历史与候选文章之间的交互。它专注于阅读用户点击文章的表示，并旨在学习用户不同的兴趣观点以匹配候选文章。我们在阿里巴巴技术协会（ATA）网站上的实验结果显示SINGLE的优势，相较于先前的基线实现了2.4%的改进。

    arXiv:2311.07619v2 Announce Type: replace-cross  Abstract: This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we first employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. In this case, we utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, achieving a 2.4% improvement over previous baseli
    
[^16]: 面向推荐系统的预算嵌入表

    Budgeted Embedding Table For Recommender Systems

    [https://arxiv.org/abs/2310.14884](https://arxiv.org/abs/2310.14884)

    提出了一种预算嵌入表的方法，解决了传统推荐系统中固定嵌入大小难以扩展的问题，能够有效应对不同用户和项目的多样性嵌入大小。

    

    当今推荐系统的核心是提供给用户优质推荐体验的潜在因素模型。这些模型使用嵌入向量来表示用户和项目。最近的轻量级嵌入方法使不同用户和项目能够具有不同的嵌入大小，但通常存在两个主要缺点。首先，它们将嵌入大小搜索限制在优化启发式平衡推荐质量和内存复杂性的范围内，其中折衷系数需要为每个内存预算手动调整。隐式强制的内存复杂性项甚至可能无法限制参数使用量，使得得到的嵌入表无法严格满足内存预算。其次，大多数解决方案，特别是……

    arXiv:2310.14884v4 Announce Type: replace  Abstract: At the heart of contemporary recommender systems (RSs) are latent factor models that provide quality recommendation experience to users. These models use embedding vectors, which are typically of a uniform and fixed size, to represent users and items. As the number of users and items continues to grow, this design becomes inefficient and hard to scale. Recent lightweight embedding methods have enabled different users and items to have diverse embedding sizes, but are commonly subject to two major drawbacks. Firstly, they limit the embedding size search to optimizing a heuristic balancing the recommendation quality and the memory complexity, where the trade-off coefficient needs to be manually tuned for every memory budget requested. The implicitly enforced memory complexity term can even fail to cap the parameter usage, making the resultant embedding table fail to meet the memory budget strictly. Secondly, most solutions, especially 
    
[^17]: 交互式问答系统：文献综述

    Interactive Question Answering Systems: Literature Review

    [https://arxiv.org/abs/2209.01621](https://arxiv.org/abs/2209.01621)

    交互式问答系统是问答和对话系统的结合，用户可以用自然语言提问并与系统动态交互，获得更精确的结果。

    

    arXiv:2209.01621v2 公告类型: 替换-跨  摘要: 问答系统被公认为在网络上寻求信息的流行且有效的手段。在这种系统中，信息寻找者可以通过用自然语言提出问题来获得简洁的回答。交互式问答是最近提出的并越来越流行的解决方案，位于问答和对话系统的交集处。一方面，用户可以用普通语言提问并找到她问题的实际回答；另一方面，如果初始请求中存在多个可能的回复、很少或模棱两可，系统可以将问答会话延长为对话。通过允许用户提出更多问题，交互式问答使用户能够动态地与系统交互并获得更精确的结果。本综述提供了交互式问答系统的详细概述。

    arXiv:2209.01621v2 Announce Type: replace-cross  Abstract: Question answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their query by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to dynamically interact with the system and receive more precise results. This survey offers a detailed overview of the interactive question-ans
    
[^18]: 基于高斯过程回归的密度用户表示方法用于多兴趣个性化检索

    Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])

    [http://arxiv.org/abs/2310.20091](http://arxiv.org/abs/2310.20091)

    本研究引入了一种基于密度的用户表示(DURs)，利用高斯过程回归实现了有效的多兴趣推荐和检索。该方法不仅能够捕捉用户的兴趣变化，还具备不确定性感知能力，并且适用于大量用户的规模。

    

    在设计个性化推荐系统中，准确建模用户的各种多样化和动态的兴趣仍然是一个重大挑战。现有的用户建模方法，如单点和多点表示，存在准确性、多样性、计算成本和适应性方面的局限性。为了克服这些不足，我们引入了一种新颖的模型——基于密度的用户表示(DURs)，它利用高斯过程回归实现有效的多兴趣推荐和检索。我们的方法GPR4DUR利用DURs来捕捉用户的兴趣变化，无需手动调整，同时具备不确定性感知能力，并且适用于大量用户的规模。使用真实世界的离线数据集进行的实验证实了GPR4DUR的适应性和效率，而使用模拟用户的在线实验则证明了它通过有效利用模型的不确定性，能够解决探索-开发的平衡问题。

    Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
    
[^19]: 推荐系统的连续输入嵌入大小搜索

    Continuous Input Embedding Size Search For Recommender Systems. (arXiv:2304.03501v1 [cs.IR])

    [http://arxiv.org/abs/2304.03501](http://arxiv.org/abs/2304.03501)

    提出了一种新的方法CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索，它通过将嵌入大小选择建模为连续变量解决了先前工作中的挑战，并在三个基准数据集上的实验中证实了它的有效性和高效性。

    

    潜在因子模型是现今推荐系统最流行的基础，其性能卓越。潜在因子模型通过对用户和项目进行表示，用于对成对相似度的计算。所有嵌入向量传统上都被限制在一个相对较大的统一大小（例如256维）。随着当代电子商务中用户和项目目录指数级增长，这种设计显然变得效率低下。为了促进轻量级推荐，强化学习（RL）最近开辟了一些机会，用于识别不同用户/项目的不同嵌入大小。然而，受到搜索效率和学习最优RL策略的限制，现有的基于RL的方法被限制为高度离散的预定义嵌入大小选项。这导致了一个被广泛忽视的潜力，可以在给定计算预算下引入更细的粒度来获得更好的推荐效果。在本文中，我们提出了一种新方法，称为CONTINUOUS，可以对潜在因子模型进行连续嵌入大小搜索。CONTINUOUS通过将嵌入大小选择建模为连续变量和制定可微优化问题的形式来解决之前工作的挑战。在三个基准数据集上的实验证实了CONTINUOUS优于基线的优越性，验证了动态优化嵌入大小的有效性和高效性。

    Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a giv
    

