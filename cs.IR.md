# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Covidia: COVID-19 Interdisciplinary Academic Knowledge Graph.](http://arxiv.org/abs/2304.07242) | Covidia是一种COVID-19跨学科学术知识图谱，通过有效的论文分类和高效的跨领域知识提取和整合，弥合了不同领域对COVID-19知识的差距。 |
| [^2] | [EvalRS 2023. Well-Rounded Recommender Systems For Real-World Deployments.](http://arxiv.org/abs/2304.07145) | EvalRS 2023旨在探讨推荐系统的全面评估，关注其在现实场景下的实际影响。过去只有准确度的测量方法可能无法全面评估其性能，公平性、偏见、有用性和信息量等方面也应该被关注。本次研讨会是去年CIKM研讨会的继承和发展，带有实际操作性和互动性。 |
| [^3] | [Keeping the Questions Conversational: Using Structured Representations to Resolve Dependency in Conversational Question Answering.](http://arxiv.org/abs/2304.07125) | 该论文提出了一个名为CONVSR的框架，可以在不影响对话性质的同时，使用结构化表示解决对话式问答中的依赖关系问题。 |
| [^4] | [SEA: A Scalable Entity Alignment System.](http://arxiv.org/abs/2304.07065) | 提出了一个可扩展的实体对齐系统SEA，它包括了六个最先进的EA模型并能够使用户轻松建立、评估自己的模型，提高了基于GNN的EA模型在实际应用中的可用性和效率。 |
| [^5] | [Learning Graph ODE for Continuous-Time Sequential Recommendation.](http://arxiv.org/abs/2304.07042) | 提出了一个基于图ODE的连续时间序列推荐框架GDERec，它通过连续时间图卷积网络解决协作信号演化和不规则采样问题，并在四个真实数据集上取得显著优于现有方法的效果。 |
| [^6] | [A Diffusion model for POI recommendation.](http://arxiv.org/abs/2304.07041) | 本文提出了一种基于扩散算法采样用户空间偏好的POI推荐模型，解决了现有方法只基于用户先前访问位置聚合的缺点，适用于推荐新颖区域的POI。 |
| [^7] | [WYTIWYR: A User Intent-Aware Framework with Multi-modal Inputs for Visualization Retrieval.](http://arxiv.org/abs/2304.06991) | WYTIWYR框架是一个基于多模态输入和用户意图感知的可视化检索工具，通过分为两阶段——解耦视觉属性和嵌入用户意图——来实现图表的个性化检索。 |
| [^8] | [PIE: Personalized Interest Exploration for Large-Scale Recommender Systems.](http://arxiv.org/abs/2304.06844) | 本文提出了一个用于大规模推荐系统的探索框架，包括用户-创建者探索、在线探索框架和反馈组成机制，以解决推荐系统中流行内容的限制和无法系统探索用户兴趣的挑战，从而提高推荐的整体质量和训练数据的有效性。 |
| [^9] | [Unbiased Pairwise Learning from Implicit Feedback for Recommender Systems without Biased Variance Control.](http://arxiv.org/abs/2304.05066) | 本文提出了一种名为“无偏成对学习（NPLwVC）”的新框架，解决了推荐系统中隐式反馈数据的偏估问题，实验结果表明其在两个公共数据集上表现优于现有最先进方法。 |
| [^10] | [Where to Go Next for Recommender Systems? ID- vs. Modality-based recommender models revisited.](http://arxiv.org/abs/2303.13835) | 推荐系统中，使用唯一标识的IDRec模型相比使用模态的MoRec模型在推荐准确性和效率上表现更好，然而，需要根据具体情况选择适合的推荐模型。 |
| [^11] | [TwERC: High Performance Ensembled Candidate Generation for Ads Recommendation at Twitter.](http://arxiv.org/abs/2302.13915) | 本文介绍了TwERC方法，用于解决Twitter广告推荐的候选生成问题。该方法结合了实时轻型排名器和数据来源策略，成功提高了推荐系统的性能和收入。其中，基于相互作用图和排名分数缓存的两种策略互补应用，分别实现了4.08%和1.38%的增益。 |
| [^12] | [Alloprof: a new French question-answer education dataset and its use in an information retrieval case study.](http://arxiv.org/abs/2302.07738) | 这个论文介绍了一个新的阿洛普夫法语问答数据集，收集了来自10,368名学生的29,349个问题和解释，并展示了在信息检索任务中使用该数据集的案例研究。 |
| [^13] | [Exploring usability of Reddit in data science and knowledge processing.](http://arxiv.org/abs/2110.02158) | 本文认为Reddit是一个庞大、分类、开放获取的数据集，几乎可以涵盖“任何主题”，适用于数据科学和知识探索。作者提出了一个开源工具，可提供Reddit资源的易于访问性和对Reddit如何涵盖选定主题进行探索性数据分析。 |

# 详细

[^1]: Covidia: COVID-19 跨学科学术知识图谱

    Covidia: COVID-19 Interdisciplinary Academic Knowledge Graph. (arXiv:2304.07242v1 [cs.IR])

    [http://arxiv.org/abs/2304.07242](http://arxiv.org/abs/2304.07242)

    Covidia是一种COVID-19跨学科学术知识图谱，通过有效的论文分类和高效的跨领域知识提取和整合，弥合了不同领域对COVID-19知识的差距。

    

    COVID-19 疫情激发了不同领域广泛的研究工作。现有的COVID-19文献和知识平台只关注生物学和医学领域的论文收集，忽略了跨学科的努力，这妨碍了领域间的知识共享和研究合作以解决问题。研究跨学科研究需要有效的论文分类和高效的跨领域知识提取和整合。在这项工作中，我们提出Covidia，COVID-19跨学科学术知识图谱，以弥合不同领域对COVID-19知识的差距。我们基于对比学习设计框架进行学科分类，并提出了一种新的学术知识图谱方案，用于交叉领域的实体提取、关系分类和本体论管理。基于Covidia，我们还建立了发现COVID-19研究的知识发现基准。

    The pandemic of COVID-19 has inspired extensive works across different research fields. Existing literature and knowledge platforms on COVID-19 only focus on collecting papers on biology and medicine, neglecting the interdisciplinary efforts, which hurdles knowledge sharing and research collaborations between fields to address the problem. Studying interdisciplinary researches requires effective paper category classification and efficient cross-domain knowledge extraction and integration. In this work, we propose Covidia, COVID-19 interdisciplinary academic knowledge graph to bridge the gap between knowledge of COVID-19 on different domains. We design frameworks based on contrastive learning for disciplinary classification, and propose a new academic knowledge graph scheme for entity extraction, relation classification and ontology management in accordance with interdisciplinary researches. Based on Covidia, we also establish knowledge discovery benchmarks for finding COVID-19 research
    
[^2]: EvalRS 2023. 面向实际应用的全面推荐系统评估

    EvalRS 2023. Well-Rounded Recommender Systems For Real-World Deployments. (arXiv:2304.07145v1 [cs.IR])

    [http://arxiv.org/abs/2304.07145](http://arxiv.org/abs/2304.07145)

    EvalRS 2023旨在探讨推荐系统的全面评估，关注其在现实场景下的实际影响。过去只有准确度的测量方法可能无法全面评估其性能，公平性、偏见、有用性和信息量等方面也应该被关注。本次研讨会是去年CIKM研讨会的继承和发展，带有实际操作性和互动性。

    

    EvalRS旨在汇聚产业和学术界的从业者，促进对推荐系统的全面评估的讨论，并重点关注在各种部署场景下的实际影响。推荐系统通常只通过准确性指标进行评估，这些指标无法完全描述其泛化能力并忽视了重要的方面，如公平性、偏见、有用性、信息量等。本次研讨会在CIKM去年研讨会的成功基础上进一步扩大范围，并采取互动形式。

    EvalRS aims to bring together practitioners from industry and academia to foster a debate on rounded evaluation of recommender systems, with a focus on real-world impact across a multitude of deployment scenarios. Recommender systems are often evaluated only through accuracy metrics, which fall short of fully characterizing their generalization capabilities and miss important aspects, such as fairness, bias, usefulness, informativeness. This workshop builds on the success of last year's workshop at CIKM, but with a broader scope and an interactive format.
    
[^3]: 让问题更具对话性：使用结构化表示解决问答中的依赖关系

    Keeping the Questions Conversational: Using Structured Representations to Resolve Dependency in Conversational Question Answering. (arXiv:2304.07125v1 [cs.CL])

    [http://arxiv.org/abs/2304.07125](http://arxiv.org/abs/2304.07125)

    该论文提出了一个名为CONVSR的框架，可以在不影响对话性质的同时，使用结构化表示解决对话式问答中的依赖关系问题。

    

    拥有一个能够参与对话式问答（ConvQA）的智能对话代理现在已不仅仅局限于科幻电影，并且已经成为现实。这些智能代理需要理解和正确解释作为给定问题背景的顺序转换。然而，这些顺序的问题有时会被留下隐含的，因此需要解决一些自然语言现象，例如指代和省略。对问题重写的任务有潜力通过将它们转换成明确意图的问题来解决解决上下文转换之间依赖关系的挑战。然而，重写隐式问题的解决方案存在一些潜在的挑战，例如生成冗长的问题并通过生成自包含问题的方式使对话中的情境削弱了。在本文中，我们提出了一个新的框架CONVSR（使用结构化表示的CONVQA）。

    Having an intelligent dialogue agent that can engage in conversational question answering (ConvQA) is now no longer limited to Sci-Fi movies only and has, in fact, turned into a reality. These intelligent agents are required to understand and correctly interpret the sequential turns provided as the context of the given question. However, these sequential questions are sometimes left implicit and thus require the resolution of some natural language phenomena such as anaphora and ellipsis. The task of question rewriting has the potential to address the challenges of resolving dependencies amongst the contextual turns by transforming them into intent-explicit questions. Nonetheless, the solution of rewriting the implicit questions comes with some potential challenges such as resulting in verbose questions and taking conversational aspect out of the scenario by generating self-contained questions. In this paper, we propose a novel framework, CONVSR (CONVQA using Structured Representations)
    
[^4]: SEA: 一个可扩展实体对齐系统

    SEA: A Scalable Entity Alignment System. (arXiv:2304.07065v1 [cs.CL])

    [http://arxiv.org/abs/2304.07065](http://arxiv.org/abs/2304.07065)

    提出了一个可扩展的实体对齐系统SEA，它包括了六个最先进的EA模型并能够使用户轻松建立、评估自己的模型，提高了基于GNN的EA模型在实际应用中的可用性和效率。

    

    实体对齐旨在在不同知识图谱中找到相应的实体。现有的实体对齐方法通常使用图神经网络来编码实体。然而，大多数方法都是在全批量模式下训练模型和评估结果，这使得实体对齐在大规模数据集上无法扩展。为了增强基于图神经网络的实体对齐模型在实际应用中的可用性，我们提出了一个可扩展的实体对齐系统SEA。它能够(i)训练大规模的图神经网络用于实体对齐，(ii)加速归一化和评估过程，(iii)为用户提供清晰的结果以估计不同的模型和参数设置。SEA只需要一个图形卡就可以运行。此外，SEA包括六个最先进的实体对齐模型，并为用户提供快速建立和评估自己模型的方法。因此，SEA允许用户在不涉及复杂实现的情况下执行实体对齐，如负抽样和GPU加速。

    Entity alignment (EA) aims to find equivalent entities in different knowledge graphs (KGs). State-of-the-art EA approaches generally use Graph Neural Networks (GNNs) to encode entities. However, most of them train the models and evaluate the results in a fullbatch fashion, which prohibits EA from being scalable on largescale datasets. To enhance the usability of GNN-based EA models in real-world applications, we present SEA, a scalable entity alignment system that enables to (i) train large-scale GNNs for EA, (ii) speed up the normalization and the evaluation process, and (iii) report clear results for users to estimate different models and parameter settings. SEA can be run on a computer with merely one graphic card. Moreover, SEA encompasses six state-of-the-art EA models and provides access for users to quickly establish and evaluate their own models. Thus, SEA allows users to perform EA without being involved in tedious implementations, such as negative sampling and GPU-accelerated
    
[^5]: 连续时间序列推荐中的图ODE学习

    Learning Graph ODE for Continuous-Time Sequential Recommendation. (arXiv:2304.07042v1 [cs.IR])

    [http://arxiv.org/abs/2304.07042](http://arxiv.org/abs/2304.07042)

    提出了一个基于图ODE的连续时间序列推荐框架GDERec，它通过连续时间图卷积网络解决协作信号演化和不规则采样问题，并在四个真实数据集上取得显著优于现有方法的效果。

    

    连续时间序列推荐旨在通过捕获用户过去交互中的项购买序列，理解用户的偏好。现有方法通常通过建模顺序模式来预测下一个项目。尽管有效，然而存在两个天然不足：（i）用户偏好具有动态性，并且经常忽略协作信号的演化；（ii）观察到的交互通常是不规则采样的，而现有方法则假设均匀间隔来进行项目转换建模。因此，如何有效地对用户偏好的基础动态建模和预测成为一个关键的研究问题。为了解决上述挑战，本文关注于连续时间序列推荐，提出了一种基于图正则微分方程（graph ordinary differential equation, GDERec）的连续时间序列推荐框架。技术上，GDERec由一个自回归图正则微分方程组成，通过连续时间图卷积网络来建模项转移动态。在四个真实数据集上的实证结果表明，GDERec显著优于现有方法，并提供了连续时间用户偏好动态的可解释见解。

    Sequential recommendation aims at understanding user preference by capturing successive behavior correlations, which are usually represented as the item purchasing sequences based on their past interactions. Existing efforts generally predict the next item via modeling the sequential patterns. Despite effectiveness, there exist two natural deficiencies: (i) user preference is dynamic in nature, and the evolution of collaborative signals is often ignored; and (ii) the observed interactions are often irregularly-sampled, while existing methods model item transitions assuming uniform intervals. Thus, how to effectively model and predict the underlying dynamics for user preference becomes a critical research problem. To tackle the above challenges, in this paper, we focus on continuous-time sequential recommendation and propose a principled graph ordinary differential equation framework named GDERec. Technically, GDERec is characterized by an autoregressive graph ordinary differential equa
    
[^6]: 一种POI推荐的扩散模型

    A Diffusion model for POI recommendation. (arXiv:2304.07041v1 [cs.IR])

    [http://arxiv.org/abs/2304.07041](http://arxiv.org/abs/2304.07041)

    本文提出了一种基于扩散算法采样用户空间偏好的POI推荐模型，解决了现有方法只基于用户先前访问位置聚合的缺点，适用于推荐新颖区域的POI。

    

    下一个兴趣点（POI）的推荐是定位服务中的关键任务，旨在为用户的下一个目的地提供个性化建议。先前关于POI推荐的工作侧重于对用户空间偏好的建模。然而，现有的利用空间信息的方法仅基于用户先前访问位置的聚合，这会使模型不会推荐新颖区域的POI，从而损害其在许多情况下的性能。此外，将时间顺序信息融入用户的空间偏好仍是一个挑战。在本文中，我们提出了Diff-POI：一种基于扩散的模型，用于采样用户的空间偏好，以进行下一步POI推荐。在扩散算法在从分布中进行采样方面的广泛应用的启发下，Diff-POI使用两个量身定制的图编码模块对用户的访问序列和空间特性进行编码。

    Next Point-of-Interest (POI) recommendation is a critical task in location-based services that aim to provide personalized suggestions for the user's next destination. Previous works on POI recommendation have laid focused on modeling the user's spatial preference. However, existing works that leverage spatial information are only based on the aggregation of users' previous visited positions, which discourages the model from recommending POIs in novel areas. This trait of position-based methods will harm the model's performance in many situations. Additionally, incorporating sequential information into the user's spatial preference remains a challenge. In this paper, we propose Diff-POI: a Diffusion-based model that samples the user's spatial preference for the next POI recommendation. Inspired by the wide application of diffusion algorithm in sampling from distributions, Diff-POI encodes the user's visiting sequence and spatial character with two tailor-designed graph encoding modules
    
[^7]: WYTIWYR:一种基于多模态输入和用户意图感知的可视化检索框架

    WYTIWYR: A User Intent-Aware Framework with Multi-modal Inputs for Visualization Retrieval. (arXiv:2304.06991v1 [cs.IR])

    [http://arxiv.org/abs/2304.06991](http://arxiv.org/abs/2304.06991)

    WYTIWYR框架是一个基于多模态输入和用户意图感知的可视化检索工具，通过分为两阶段——解耦视觉属性和嵌入用户意图——来实现图表的个性化检索。

    

    在大量语料库中检索图表是一项基本任务，可以惠及众多应用，如可视化推荐。检索结果应符合显式的视觉属性（例如图表类型、色图）和隐含的用户意图（例如设计风格、上下文信息），这些意图根据应用场景而异。然而，现有的基于示例的图表检索方法是建立在难以解释的非解耦合和低级别视觉特征上的，而基于定义的方法受到预定义属性的限制，难以扩展。在本文中，我们提出了一种新的框架，即WYTIWYR（What-You-Think-Is-What-You-Retrieve），将用户意图整合到图表检索过程中。该框架分为两个阶段：首先，注释阶段将位图查询图表中的视觉属性进行解耦；其次，检索阶段通过定制的文本提示和查询图表嵌入用户的意图，以提取图表。

    Retrieving charts from a large corpus is a fundamental task that can benefit numerous applications such as visualization recommendations.The retrieved results are expected to conform to both explicit visual attributes (e.g., chart type, colormap) and implicit user intents (e.g., design style, context information) that vary upon application scenarios. However, existing example-based chart retrieval methods are built upon non-decoupled and low-level visual features that are hard to interpret, while definition-based ones are constrained to pre-defined attributes that are hard to extend. In this work, we propose a new framework, namely WYTIWYR (What-You-Think-Is-What-You-Retrieve), that integrates user intents into the chart retrieval process. The framework consists of two stages: first, the Annotation stage disentangles the visual attributes within the bitmap query chart; and second, the Retrieval stage embeds the user's intent with customized text prompt as well as query chart, to recall
    
[^8]: PIE: 针对大规模推荐系统的个性化兴趣探索

    PIE: Personalized Interest Exploration for Large-Scale Recommender Systems. (arXiv:2304.06844v1 [cs.IR])

    [http://arxiv.org/abs/2304.06844](http://arxiv.org/abs/2304.06844)

    本文提出了一个用于大规模推荐系统的探索框架，包括用户-创建者探索、在线探索框架和反馈组成机制，以解决推荐系统中流行内容的限制和无法系统探索用户兴趣的挑战，从而提高推荐的整体质量和训练数据的有效性。

    

    推荐系统越来越成功地向用户推荐个性化内容。然而，这些系统常常利用热门内容，且用户兴趣的持续演进需要被捕捉，但没有直接的方式来系统性地探索用户的兴趣。这也经常影响到推荐系统的整体质量，因为训练数据是从推荐给用户的候选项中生成的。本文提出了一种用于大规模推荐系统中的探索框架来解决这些挑战。它由三个部分组成：第一部分是用户创建者探索，专注于识别用户感兴趣的最佳创建者，第二部分是在线探索框架，第三部分是一个平衡探索与利用的反馈组成机制，以确保探索性视频的最佳普及率。我们的方法可以很容易地被集成到现有的大规模推荐系统中，只需进行最小限度的修改。

    Recommender systems are increasingly successful in recommending personalized content to users. However, these systems often capitalize on popular content. There is also a continuous evolution of user interests that need to be captured, but there is no direct way to systematically explore users' interests. This also tends to affect the overall quality of the recommendation pipeline as training data is generated from the candidates presented to the user. In this paper, we present a framework for exploration in large-scale recommender systems to address these challenges. It consists of three parts, first the user-creator exploration which focuses on identifying the best creators that users are interested in, second the online exploration framework and third a feed composition mechanism that balances explore and exploit to ensure optimal prevalence of exploratory videos. Our methodology can be easily integrated into an existing large-scale recommender system with minimal modifications. We 
    
[^9]: 面向推荐系统的无偏成对学习算法

    Unbiased Pairwise Learning from Implicit Feedback for Recommender Systems without Biased Variance Control. (arXiv:2304.05066v1 [cs.IR])

    [http://arxiv.org/abs/2304.05066](http://arxiv.org/abs/2304.05066)

    本文提出了一种名为“无偏成对学习（NPLwVC）”的新框架，解决了推荐系统中隐式反馈数据的偏估问题，实验结果表明其在两个公共数据集上表现优于现有最先进方法。

    

    推荐系统的模型训练一般基于显式反馈和隐式反馈两种数据。隐式反馈数据中仅包含正反馈，因此很难判断未互动项到底是负反馈还是未曝光。同时，稀有物品的相关性往往被低估。为了解决这些问题，先前提出了无偏成对学习算法，但存在偏差方差控制问题。本文提出一种名为“无偏成对学习（NPLwVC）”的新框架，不需要偏差方差控制项，从而简化算法。两个公共数据集的实验结果表明，NPLwVC在保持无偏性的同时显著优于现有最先进方法。

    Generally speaking, the model training for recommender systems can be based on two types of data, namely explicit feedback and implicit feedback. Moreover, because of its general availability, we see wide adoption of implicit feedback data, such as click signal. There are mainly two challenges for the application of implicit feedback. First, implicit data just includes positive feedback. Therefore, we are not sure whether the non-interacted items are really negative or positive but not displayed to the corresponding user. Moreover, the relevance of rare items is usually underestimated since much fewer positive feedback of rare items is collected compared with popular ones. To tackle such difficulties, both pointwise and pairwise solutions are proposed before for unbiased relevance learning. As pairwise learning suits well for the ranking tasks, the previously proposed unbiased pairwise learning algorithm already achieves state-of-the-art performance. Nonetheless, the existing unbiased 
    
[^10]: 推荐系统何去何从？ID- vs. 基于模态的推荐模型再探讨

    Where to Go Next for Recommender Systems? ID- vs. Modality-based recommender models revisited. (arXiv:2303.13835v1 [cs.IR])

    [http://arxiv.org/abs/2303.13835](http://arxiv.org/abs/2303.13835)

    推荐系统中，使用唯一标识的IDRec模型相比使用模态的MoRec模型在推荐准确性和效率上表现更好，然而，需要根据具体情况选择适合的推荐模型。

    

    过去十年，利用唯一标识（ID）来表示不同用户和物品的推荐模型一直是最先进的，并且在推荐系统文献中占主导地位。与此同时，预训练模态编码器（如BERT和ViT）在对物品的原始模态特征（如文本和图像）进行建模方面变得越来越强大。因此，自然而然的问题是：通过用最先进的模态编码器替换物品ID嵌入向量，一个纯粹的基于模态的推荐模型（MoRec）能否胜过或与纯ID基础模型（IDRec）相匹配？实际上，早在十年前，这个问题就被回答了，IDRec在推荐准确性和效率方面都远远胜过MoRec。我们旨在重新审视这个“老问题”，从多个方面对MoRec进行系统研究。具体而言，我们研究了几个子问题：（i）在实际场景中，MoRec或IDRec哪个推荐模式表现更好，特别是在一般情况和......

    Recommendation models that utilize unique identities (IDs) to represent distinct users and items have been state-of-the-art (SOTA) and dominated the recommender systems (RS) literature for over a decade. Meanwhile, the pre-trained modality encoders, such as BERT and ViT, have become increasingly powerful in modeling the raw modality features of an item, such as text and images. Given this, a natural question arises: can a purely modality-based recommendation model (MoRec) outperforms or matches a pure ID-based model (IDRec) by replacing the itemID embedding with a SOTA modality encoder? In fact, this question was answered ten years ago when IDRec beats MoRec by a strong margin in both recommendation accuracy and efficiency. We aim to revisit this `old' question and systematically study MoRec from several aspects. Specifically, we study several sub-questions: (i) which recommendation paradigm, MoRec or IDRec, performs better in practical scenarios, especially in the general setting and 
    
[^11]: TwERC: Twitter广告推荐高性能集成式候选生成

    TwERC: High Performance Ensembled Candidate Generation for Ads Recommendation at Twitter. (arXiv:2302.13915v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.13915](http://arxiv.org/abs/2302.13915)

    本文介绍了TwERC方法，用于解决Twitter广告推荐的候选生成问题。该方法结合了实时轻型排名器和数据来源策略，成功提高了推荐系统的性能和收入。其中，基于相互作用图和排名分数缓存的两种策略互补应用，分别实现了4.08%和1.38%的增益。

    

    推荐系统是社交媒体公司的核心功能，包括有机和推广内容推荐。现代推荐系统通常分为多个阶段，即候选生成和重排序，以平衡计算成本和推荐质量。本文聚焦于大规模广告推荐问题中的候选生成阶段，并提出了一种机器学习为先的异构重构方法，称为TwERC。我们展示了一个将实时轻型排名器与能够捕获额外信息的数据来源策略相结合的系统，可以提供验证增益。我们提出了两种策略。第一个策略使用相互作用图中的相似性概念，而第二个策略缓存排名阶段的先前得分。基于图形的策略实现了4.08%的收入增益，而基于排名分数的策略实现了1.38%的增益。这两种策略具有互补偏差。

    Recommendation systems are a core feature of social media companies with their uses including recommending organic and promoted contents. Many modern recommendation systems are split into multiple stages - candidate generation and heavy ranking - to balance computational cost against recommendation quality. We focus on the candidate generation phase of a large-scale ads recommendation problem in this paper, and present a machine learning first heterogeneous re-architecture of this stage which we term TwERC. We show that a system that combines a real-time light ranker with sourcing strategies capable of capturing additional information provides validated gains. We present two strategies. The first strategy uses a notion of similarity in the interaction graph, while the second strategy caches previous scores from the ranking stage. The graph based strategy achieves a 4.08% revenue gain and the rankscore based strategy achieves a 1.38% gain. These two strategies have biases that complemen
    
[^12]: Alloprof：一个新的法语问答教育数据集及其在信息检索案例研究中的应用

    Alloprof: a new French question-answer education dataset and its use in an information retrieval case study. (arXiv:2302.07738v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07738](http://arxiv.org/abs/2302.07738)

    这个论文介绍了一个新的阿洛普夫法语问答数据集，收集了来自10,368名学生的29,349个问题和解释，并展示了在信息检索任务中使用该数据集的案例研究。

    

    教师和学生越来越依赖在线学习资源来补充学校提供的资源。可用资源的广度和深度的增加对学生来说是一件好事，但前提是他们能够找到答案。问答和信息检索系统已受益于公共数据集，以训练和评估其算法，但大多数这些数据集都是英文文本，由成年人编写和阅读。我们介绍了一个新的公共法语问答数据集，从总部位于魁北克的小学和中学帮助网站Alloprof收集，包含29,349个问题及其解释，涵盖各种学科的10,368名学生，超过一半的解释包含链接到其他问题或网站上的2,596个参考页面之一。我们还向您展示了在信息检索任务中使用本数据集的案例研究。

    Teachers and students are increasingly relying on online learning resources to supplement the ones provided in school. This increase in the breadth and depth of available resources is a great thing for students, but only provided they are able to find answers to their queries. Question-answering and information retrieval systems have benefited from public datasets to train and evaluate their algorithms, but most of these datasets have been in English text written by and for adults. We introduce a new public French question-answering dataset collected from Alloprof, a Quebec-based primary and high-school help website, containing 29 349 questions and their explanations in a variety of school subjects from 10 368 students, with more than half of the explanations containing links to other questions or some of the 2 596 reference pages on the website. We also present a case study of this dataset in an information retrieval task. This dataset was collected on the Alloprof public forum, with 
    
[^13]: 探索 Reddit 在数据科学和知识处理中的可用性

    Exploring usability of Reddit in data science and knowledge processing. (arXiv:2110.02158v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2110.02158](http://arxiv.org/abs/2110.02158)

    本文认为Reddit是一个庞大、分类、开放获取的数据集，几乎可以涵盖“任何主题”，适用于数据科学和知识探索。作者提出了一个开源工具，可提供Reddit资源的易于访问性和对Reddit如何涵盖选定主题进行探索性数据分析。

    

    本文认为作为一个庞大、分类、开放获取的数据集，Reddit是一个有用的数据来源，几乎可以涵盖“任何主题”。因此，Reddit可以用于数据科学，比如用于知识探索。这个观点是基于180篇手动注释的Reddit相关论文和从科学论文的流行数据库中获得的数据进行分析得出的。最后，介绍了一个开源工具，提供了对Reddit资源的易于访问性，并对Reddit如何涵盖选定主题进行了探索性数据分析。这些功能可以作为更广泛探索Reddit适用性的前奏分析。

    This contribution argues that Reddit, as a massive, categorized, open-access dataset, is a useful data source, for "almost any topic". Hence, it can be used in data science, e.g. for knowledge exploration. This statement is backed-up with presented analysis, based on 180 manually annotated papers, related to Reddit itself, and data acquired from popular databases of scientific papers. Finally, an open source tool is introduced, which provides an easy access to Reddit resources, and an exploratory data analysis of how Reddit covers selected topics. These functions can be used as a prelude analysis to a broader exploration of Reddit's applicability.
    

