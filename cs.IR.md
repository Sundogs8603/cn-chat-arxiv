# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Estimating Propensity for Causality-based Recommendation without Exposure Data.](http://arxiv.org/abs/2310.20388) | 本文提出了一个新的框架，可以在没有暴露数据的情况下估计基于因果关系的推荐的倾向和暴露，弥补了现有方法的不足。 |
| [^2] | [Overview of LiLAS 2020 -- Living Labs for Academic Search.](http://arxiv.org/abs/2310.20387) | LiLAS 2020是一个开放的学术搜索实验室，提供了两个平台LIVIVO和GESIS Search，在真实环境中评估学术搜索系统的性能。 |
| [^3] | [Large Multi-modal Encoders for Recommendation.](http://arxiv.org/abs/2310.20343) | 本文研究了在推荐系统中使用大规模多模态编码器的方法，以提高推荐性能。现有的多模态推荐系统主要依赖于单独提取的特征，并且不同模态之间只有浅层次的对齐，而大规模多模态编码器能够更好地捕捉模态之间的潜在关系。 |
| [^4] | [FA Team at the NTCIR-17 UFO Task.](http://arxiv.org/abs/2310.20322) | FA团队参加了NTCIR-17 UFO任务，通过利用ELECTRA语言模型的增强技术，成功实现了对表格中有价值数据的提取，达到了93.43%的准确率，并在排行榜上获得第二名。在TTRE任务中，他们还提出了基于规则的方法来提取文本和表格之间的关系。 |
| [^5] | [Extracting Entities of Interest from Comparative Product Reviews.](http://arxiv.org/abs/2310.20274) | 本文提出了一种基于深度学习的方法，用于从比较性产品评论中提取产品比较信息，并通过实验证明其在这个任务中优于现有的语义角色标注框架。 |
| [^6] | [FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated Recommendation Systems.](http://arxiv.org/abs/2310.20193) | FedRec+是一个集成框架，旨在增强隐私性和解决联邦推荐系统中的异质性问题。它利用特征相似性来生成伪项目的虚拟评分，减少噪声，并通过使用Wasserstein距离来估计异质性问题。 |
| [^7] | [LFG: A Generative Network for Real-Time Recommendation.](http://arxiv.org/abs/2310.20189) | 本文提出了一种名为LFG的生成网络，用于实现实时的推荐系统。该网络通过深度神经网络动态生成用户的潜在因子，无需重新分解或重新训练。实验结果表明，该网络在提高推荐准确性的同时实现了实时推荐的目标。 |
| [^8] | [Multi-Objective Intrinsic Reward Learning for Conversational Recommender Systems.](http://arxiv.org/abs/2310.20109) | 本论文提出了一种多目标内在奖励学习的方法，用于处理对话推荐系统中手工制作奖励函数无法满足用户意图的问题。通过学习与用户的交互来获得内在奖励，进而优化CRS策略，同时最大化成功率并最小化对话轮次，以达到更好的推荐效果。 |
| [^9] | [Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval.](http://arxiv.org/abs/2310.20091) | 本研究引入了一种基于密度的用户表示(DURs)，利用高斯过程回归实现了有效的多兴趣推荐和检索。该方法不仅能够捕捉用户的兴趣变化，还具备不确定性感知能力，并且适用于大量用户的规模。 |
| [^10] | [Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models.](http://arxiv.org/abs/2310.20081) | 个性化是NLP系统中用户体验的关键，本文通过大型语言模型将总结和检索整合，提出了一种利用任务感知的总结增强个性化方法。 |
| [^11] | [Evaluation Framework for Understanding Sensitive Attribute Association Bias in Latent Factor Recommendation Algorithms.](http://arxiv.org/abs/2310.20061) | 我们提出了一个评估框架，用于理解潜在因素推荐算法中的敏感属性关联偏见。这个框架允许从业人员探索推荐系统如何引入或放大利益相关者的表达伤害，并为他们提供了解决这个问题的方法。 |
| [^12] | [Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications.](http://arxiv.org/abs/2310.19942) | 本研究提出了一种名为Split-NER的系统，通过将命名实体识别问题分成提取实体提及跨度和跨度分类两个子任务，然后利用问答模型解决这两个子任务，实现了高效和准确的命名实体识别。 |
| [^13] | [BTRec: BERT-Based Trajectory Recommendation for Personalized Tours.](http://arxiv.org/abs/2310.19886) | BTRec是一种基于BERT的轨迹推荐算法，它利用用户的人口统计信息和过去的POI访问信息，通过修改后的BERT语言模型生成个性化的POI行程预测，从而为旅游者提供有针对性的推荐行程。 |
| [^14] | [AMIR: Automated MisInformation Rebuttal -- A COVID-19 Vaccination Datasets based Recommendation System.](http://arxiv.org/abs/2310.19834) | 本研究提出了基于COVID-19疫苗数据集的自动化虚假信息驳斥推荐系统，利用社交媒体信息和经过策划的事实核查数据，实现了大规模自动驳斥虚假信息。这为对抗虚假信息提供了一种成本效益高、可扩展的解决方案。 |
| [^15] | [Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation.](http://arxiv.org/abs/2310.14318) | 本论文提出了一种名为ICSRec的方法，用于建模用户的潜在意图，以提高顺序推荐的性能。该方法通过对比学习和交叉子序列来准确捕捉用户的意图。 |
| [^16] | [Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms.](http://arxiv.org/abs/2309.05961) | 本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。 |
| [^17] | [Towards Personalized Cold-Start Recommendation with Prompts.](http://arxiv.org/abs/2306.17256) | 本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。 |
| [^18] | [Enabling Large Language Models to Generate Text with Citations.](http://arxiv.org/abs/2305.14627) | 本文提出ALCE，是首个自动LLMs引文评估基准，实现大型语言模型生成带引文的文本，提高其事实正确性和可验证性；提示LLMs特定的关键词或利用外部知识源可以显著提高其引文准确性。 |
| [^19] | [From Retrieval to Generation: Efficient and Effective Entity Set Expansion.](http://arxiv.org/abs/2304.03531) | 本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。 |
| [^20] | [Learning List-Level Domain-Invariant Representations for Ranking.](http://arxiv.org/abs/2212.10764) | 本文提出了一种针对排名问题的列表级别对齐的学习方法，该方法利用列表的结构特性，在领域适应中实现从源领域到目标领域的知识转移。 |

# 详细

[^1]: 不使用暴露数据的基于因果关系的推荐倾向估计

    Estimating Propensity for Causality-based Recommendation without Exposure Data. (arXiv:2310.20388v1 [cs.IR])

    [http://arxiv.org/abs/2310.20388](http://arxiv.org/abs/2310.20388)

    本文提出了一个新的框架，可以在没有暴露数据的情况下估计基于因果关系的推荐的倾向和暴露，弥补了现有方法的不足。

    

    基于因果关系的推荐系统关注用户与物品交互的因果效应，即物品的推荐或暴露给用户的情况，而不是传统的基于相关性的推荐。由于对用户、卖家和平台都有多方面的好处，这类推荐系统越来越受欢迎。然而，现有的基于因果关系的推荐方法需要额外的输入，即暴露数据和/或倾向得分（即暴露的概率）进行训练。由于技术或隐私限制，现实世界中往往无法获得这些对于建模推荐因果关系至关重要的数据。在本文中，我们提出了一个新的框架，名为基于因果关系的倾向估计（PropCare）。它可以从一种更实际的设置中估计倾向和暴露，即只有交互数据可用，没有关于暴露或倾向的任何真实数据。

    Causality-based recommendation systems focus on the causal effects of user-item interactions resulting from item exposure (i.e., which items are recommended or exposed to the user), as opposed to conventional correlation-based recommendation. They are gaining popularity due to their multi-sided benefits to users, sellers and platforms alike. However, existing causality-based recommendation methods require additional input in the form of exposure data and/or propensity scores (i.e., the probability of exposure) for training. Such data, crucial for modeling causality in recommendation, are often not available in real-world situations due to technical or privacy constraints. In this paper, we bridge the gap by proposing a new framework, called Propensity Estimation for Causality-based Recommendation (PropCare). It can estimate the propensity and exposure from a more practical setup, where only interaction data are available without any ground truth on exposure or propensity in training an
    
[^2]: LiLAS 2020综述 -- 用于学术搜索的生活实验室

    Overview of LiLAS 2020 -- Living Labs for Academic Search. (arXiv:2310.20387v1 [cs.IR])

    [http://arxiv.org/abs/2310.20387](http://arxiv.org/abs/2310.20387)

    LiLAS 2020是一个开放的学术搜索实验室，提供了两个平台LIVIVO和GESIS Search，在真实环境中评估学术搜索系统的性能。

    

    学术搜索是信息检索领域多年来一直面临的挑战。即使在今天，寻找学术资料仍然是一个广泛的研究领域，最近开始致力于解决像COVID-19大流行这样的问题。然而，测试集和专门的数据集如CORD-19只能进行系统导向的实验，而在真实环境中评估算法的机会只对来自工业界的研究人员开放。在LiLAS中，我们开放了两个学术搜索平台，以便参与研究者能够在基于Docker的研究环境中评估他们的系统。这篇综述论文描述了动机、基础设施和两个系统LIVIVO和GESIS Search，它们是CLEF实验室的一部分。

    Academic Search is a timeless challenge that the field of Information Retrieval has been dealing with for many years. Even today, the search for academic material is a broad field of research that recently started working on problems like the COVID-19 pandemic. However, test collections and specialized data sets like CORD-19 only allow for system-oriented experiments, while the evaluation of algorithms in real-world environments is only available to researchers from industry. In LiLAS, we open up two academic search platforms to allow participating research to evaluate their systems in a Docker-based research environment. This overview paper describes the motivation, infrastructure, and two systems LIVIVO and GESIS Search that are part of this CLEF lab.
    
[^3]: 大规模多模态编码器用于推荐

    Large Multi-modal Encoders for Recommendation. (arXiv:2310.20343v1 [cs.IR])

    [http://arxiv.org/abs/2310.20343](http://arxiv.org/abs/2310.20343)

    本文研究了在推荐系统中使用大规模多模态编码器的方法，以提高推荐性能。现有的多模态推荐系统主要依赖于单独提取的特征，并且不同模态之间只有浅层次的对齐，而大规模多模态编码器能够更好地捕捉模态之间的潜在关系。

    

    近年来，快速增长的在线多媒体服务（如电子商务平台）使得需要开发个性化推荐方法来对每个项目的多样内容进行编码。现代的多模态推荐系统利用从原始图像和物品描述中获取的多种特征来提高推荐性能。然而，现有的多模态推荐系统主要依赖于通过预训练的媒体特定编码器单独提取的特征，并且不同模态之间只有浅层次的对齐，限制了这些系统捕捉模态之间潜在关系的能力。本文中，我们研究在推荐系统特定背景下使用大规模多模态编码器的用法，因为在各个领域中评估物品排名时，这些编码器以前已经展示出最先进的效果。

    In recent years, the rapid growth of online multimedia services, such as e-commerce platforms, has necessitated the development of personalised recommendation approaches that can encode diverse content about each item. Indeed, modern multi-modal recommender systems exploit diverse features obtained from raw images and item descriptions to enhance the recommendation performance. However, the existing multi-modal recommenders primarily depend on the features extracted individually from different media through pre-trained modality-specific encoders, and exhibit only shallow alignments between different modalities - limiting these systems' ability to capture the underlying relationships between the modalities. In this paper, we investigate the usage of large multi-modal encoders within the specific context of recommender systems, as these have previously demonstrated state-of-the-art effectiveness when ranking items across various domains. Specifically, we tailor two state-of-the-art multi
    
[^4]: NTCIR-17 UFO任务中的FA团队（arXiv:2310.20322v1 [cs.CL]）

    FA Team at the NTCIR-17 UFO Task. (arXiv:2310.20322v1 [cs.CL])

    [http://arxiv.org/abs/2310.20322](http://arxiv.org/abs/2310.20322)

    FA团队参加了NTCIR-17 UFO任务，通过利用ELECTRA语言模型的增强技术，成功实现了对表格中有价值数据的提取，达到了93.43%的准确率，并在排行榜上获得第二名。在TTRE任务中，他们还提出了基于规则的方法来提取文本和表格之间的关系。

    

    FA团队参加了NTCIR-17 UFO的表格数据提取（TDE）和文本到表格关系提取（TTRE）任务。本文报告了我们解决这些问题的方法，并讨论了官方结果。我们成功地利用基于ELECTRA语言模型的各种增强技术从表格中提取有价值的数据。我们的努力导致了93.43%的令人印象深刻的TDE准确率，并使我们在排行榜上排名第二。这一卓越成就证明了我们提出的方法的有效性。在TTRE任务中，我们提出了基于规则的方法来提取文本和表格之间的有意义的关系，并验证了性能。

    The FA team participated in the Table Data Extraction (TDE) and Text-to-Table Relationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of Non-Financial Objects in Financial Reports (UFO). This paper reports our approach to solving the problems and discusses the official results. We successfully utilized various enhancement techniques based on the ELECTRA language model to extract valuable data from tables. Our efforts resulted in an impressive TDE accuracy rate of 93.43 %, positioning us in second place on the Leaderboard rankings. This outstanding achievement is a testament to our proposed approach's effectiveness. In the TTRE task, we proposed the rule-based method to extract meaningful relationships between the text and tables task and confirmed the performance.
    
[^5]: 从比较性产品评论中提取感兴趣的实体

    Extracting Entities of Interest from Comparative Product Reviews. (arXiv:2310.20274v1 [cs.IR])

    [http://arxiv.org/abs/2310.20274](http://arxiv.org/abs/2310.20274)

    本文提出了一种基于深度学习的方法，用于从比较性产品评论中提取产品比较信息，并通过实验证明其在这个任务中优于现有的语义角色标注框架。

    

    本文提出了一种基于深度学习的方法，用于从各种电子商务网站的用户评论中提取产品比较信息。任何一个比较性产品评论都有三个重要的信息实体：被比较产品的名称，用户观点（谓词）以及被比较的特征或方面。所有这些信息实体彼此依赖并受到评论语言规则的约束。我们观察到，这些相互依赖关系可以很好地通过LSTM进行捕捉。我们在现有的手动标记数据集上评估了我们的系统，并观察到其在这个任务中表现优于现有的语义角色标注（SRL）框架。

    This paper presents a deep learning based approach to extract product comparison information out of user reviews on various e-commerce websites. Any comparative product review has three major entities of information: the names of the products being compared, the user opinion (predicate) and the feature or aspect under comparison. All these informing entities are dependent on each other and bound by the rules of the language, in the review. We observe that their inter-dependencies can be captured well using LSTMs. We evaluate our system on existing manually labeled datasets and observe out-performance over the existing Semantic Role Labeling (SRL) framework popular for this task.
    
[^6]: FedRec+:增强隐私性和解决异质性问题的联邦推荐系统

    FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated Recommendation Systems. (arXiv:2310.20193v1 [cs.LG])

    [http://arxiv.org/abs/2310.20193](http://arxiv.org/abs/2310.20193)

    FedRec+是一个集成框架，旨在增强隐私性和解决联邦推荐系统中的异质性问题。它利用特征相似性来生成伪项目的虚拟评分，减少噪声，并通过使用Wasserstein距离来估计异质性问题。

    

    在推荐系统中，保护隐私和降低边缘用户的通信成本是一个重要的挑战。尽管联邦学习在避免客户端和服务器之间的数据交换方面被证明是有效的，但研究表明，服务器可以根据两轮用户上传的梯度的非零梯度变化来推断用户的评分。此外，联邦推荐系统面临异质性问题，导致推荐性能下降。在本文中，我们提出了一种名为FedRec+的联邦推荐系统的集成框架，旨在增强隐私性并解决异质性问题。FedRec+利用基于特征相似性的最优子集选择来生成伪项目的近似最佳虚拟评分，仅利用用户的本地信息。这种方法可以减少噪声而不增加额外的通信成本。此外，我们利用Wasserstein距离来估计异质性问题。

    Preserving privacy and reducing communication costs for edge users pose significant challenges in recommendation systems. Although federated learning has proven effective in protecting privacy by avoiding data exchange between clients and servers, it has been shown that the server can infer user ratings based on updated non-zero gradients obtained from two consecutive rounds of user-uploaded gradients. Moreover, federated recommendation systems (FRS) face the challenge of heterogeneity, leading to decreased recommendation performance. In this paper, we propose FedRec+, an ensemble framework for FRS that enhances privacy while addressing the heterogeneity challenge. FedRec+ employs optimal subset selection based on feature similarity to generate near-optimal virtual ratings for pseudo items, utilizing only the user's local information. This approach reduces noise without incurring additional communication costs. Furthermore, we utilize the Wasserstein distance to estimate the heterogene
    
[^7]: LFG：一种用于实时推荐的生成网络

    LFG: A Generative Network for Real-Time Recommendation. (arXiv:2310.20189v1 [cs.IR])

    [http://arxiv.org/abs/2310.20189](http://arxiv.org/abs/2310.20189)

    本文提出了一种名为LFG的生成网络，用于实现实时的推荐系统。该网络通过深度神经网络动态生成用户的潜在因子，无需重新分解或重新训练。实验结果表明，该网络在提高推荐准确性的同时实现了实时推荐的目标。

    

    推荐系统是当今重要的信息技术，结合深度学习的推荐算法已成为该领域的研究热点。通过矩阵分解和梯度下降捕捉潜在特征以适应用户偏好的潜在因子模型（LFM）推动了各种改进推荐准确性的推荐算法的出现。然而，基于LFM的协同过滤推荐模型缺乏灵活性，并且在实时推荐方面存在一些缺点，因为当有新用户到达时需要重新进行矩阵分解和重新训练。针对这一问题，本文创新性地提出了一种Latent Factor Generator (LFG)网络，并将电影推荐作为研究主题。LFG通过深度神经网络动态生成用户的潜在因子，无需重新分解或重新训练。实验结果表明，该模型在提高推荐准确性的同时实现了实时推荐的目标。

    Recommender systems are essential information technologies today, and recommendation algorithms combined with deep learning have become a research hotspot in this field. The recommendation model known as LFM (Latent Factor Model), which captures latent features through matrix factorization and gradient descent to fit user preferences, has given rise to various recommendation algorithms that bring new improvements in recommendation accuracy. However, collaborative filtering recommendation models based on LFM lack flexibility and has shortcomings for real-time recommendations, as they need to redo the matrix factorization and retrain using gradient descent when new users arrive. In response to this, this paper innovatively proposes a Latent Factor Generator (LFG) network, and set the movie recommendation as research theme. The LFG dynamically generates user latent factors through deep neural networks without the need for re-factorization or retrain. Experimental results indicate that the
    
[^8]: 多目标内在奖励学习用于对话推荐系统

    Multi-Objective Intrinsic Reward Learning for Conversational Recommender Systems. (arXiv:2310.20109v1 [cs.IR])

    [http://arxiv.org/abs/2310.20109](http://arxiv.org/abs/2310.20109)

    本论文提出了一种多目标内在奖励学习的方法，用于处理对话推荐系统中手工制作奖励函数无法满足用户意图的问题。通过学习与用户的交互来获得内在奖励，进而优化CRS策略，同时最大化成功率并最小化对话轮次，以达到更好的推荐效果。

    

    对话推荐系统（CRS）积极获取用户偏好以生成适应性推荐。主流的基于强化学习的CRS解决方案严重依赖手工制作的奖励函数，这可能与CRS任务中的用户意图不一致。因此，设计任务特定的奖励对于促进CRS策略学习至关重要，但在文献中尚未得到广泛探讨。在本文中，我们提出了一种新的方法来解决这个挑战，即通过与用户的互动学习内在奖励。具体而言，我们将内在奖励学习形式化为一个多目标双层优化问题。内层优化CRS策略，通过学习到的内在奖励进行增强，而外层驱动内在奖励优化两个CRS特定目标：最大化成功率和最小化对话中达到成功推荐所需的轮次数。为了评估我们方法的有效性，我们进行了实验。

    Conversational Recommender Systems (CRS) actively elicit user preferences to generate adaptive recommendations. Mainstream reinforcement learning-based CRS solutions heavily rely on handcrafted reward functions, which may not be aligned with user intent in CRS tasks. Therefore, the design of task-specific rewards is critical to facilitate CRS policy learning, which remains largely under-explored in the literature. In this work, we propose a novel approach to address this challenge by learning intrinsic rewards from interactions with users. Specifically, we formulate intrinsic reward learning as a multi-objective bi-level optimization problem. The inner level optimizes the CRS policy augmented by the learned intrinsic rewards, while the outer level drives the intrinsic rewards to optimize two CRS-specific objectives: maximizing the success rate and minimizing the number of turns to reach a successful recommendation in conversations. To evaluate the effectiveness of our approach, we cond
    
[^9]: 基于高斯过程回归的密度用户表示方法用于多兴趣个性化检索

    Density-based User Representation through Gaussian Process Regression for Multi-interest Personalized Retrieval. (arXiv:2310.20091v1 [cs.IR])

    [http://arxiv.org/abs/2310.20091](http://arxiv.org/abs/2310.20091)

    本研究引入了一种基于密度的用户表示(DURs)，利用高斯过程回归实现了有效的多兴趣推荐和检索。该方法不仅能够捕捉用户的兴趣变化，还具备不确定性感知能力，并且适用于大量用户的规模。

    

    在设计个性化推荐系统中，准确建模用户的各种多样化和动态的兴趣仍然是一个重大挑战。现有的用户建模方法，如单点和多点表示，存在准确性、多样性、计算成本和适应性方面的局限性。为了克服这些不足，我们引入了一种新颖的模型——基于密度的用户表示(DURs)，它利用高斯过程回归实现有效的多兴趣推荐和检索。我们的方法GPR4DUR利用DURs来捕捉用户的兴趣变化，无需手动调整，同时具备不确定性感知能力，并且适用于大量用户的规模。使用真实世界的离线数据集进行的实验证实了GPR4DUR的适应性和效率，而使用模拟用户的在线实验则证明了它通过有效利用模型的不确定性，能够解决探索-开发的平衡问题。

    Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.
    
[^10]: 通过大型语言模型将总结和检索整合，增强个性化能力

    Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. (arXiv:2310.20081v1 [cs.CL])

    [http://arxiv.org/abs/2310.20081](http://arxiv.org/abs/2310.20081)

    个性化是NLP系统中用户体验的关键，本文通过大型语言模型将总结和检索整合，提出了一种利用任务感知的总结增强个性化方法。

    

    个性化是自然语言处理(NLP)系统中用户体验的一个关键因素。我们提出了一种利用大型语言模型(LLM)来更好地个性化用户体验的方法。为了个性化语言模型的输出，一个直接的方法是将过去的用户数据并入语言模型的提示中，但这种方法会导致输入过长，超出输入长度限制，并且引起延迟和成本问题。现有方法通过选择性地提取相关的用户数据（即选择性检索）来解决这些挑战，以构建下游任务的提示。然而，基于检索的方法受限于潜在的信息丢失、缺乏更深入的用户理解和冷启动挑战。为了克服这些限制，我们提出了一种新颖的总结增强方法，通过扩展检索增强个性化与任务感知相结合。

    Personalization, the ability to tailor a system to individual users, is an essential factor in user experience with natural language processing (NLP) systems. With the emergence of Large Language Models (LLMs), a key question is how to leverage these models to better personalize user experiences. To personalize a language model's output, a straightforward approach is to incorporate past user data into the language model prompt, but this approach can result in lengthy inputs exceeding limitations on input length and incurring latency and cost issues. Existing approaches tackle such challenges by selectively extracting relevant user data (i.e. selective retrieval) to construct a prompt for downstream tasks. However, retrieval-based methods are limited by potential information loss, lack of more profound user understanding, and cold-start challenges. To overcome these limitations, we propose a novel summary-augmented approach by extending retrieval-augmented personalization with task-awar
    
[^11]: 理解潜在因素推荐算法中敏感属性关联偏见的评估框架

    Evaluation Framework for Understanding Sensitive Attribute Association Bias in Latent Factor Recommendation Algorithms. (arXiv:2310.20061v1 [cs.IR])

    [http://arxiv.org/abs/2310.20061](http://arxiv.org/abs/2310.20061)

    我们提出了一个评估框架，用于理解潜在因素推荐算法中的敏感属性关联偏见。这个框架允许从业人员探索推荐系统如何引入或放大利益相关者的表达伤害，并为他们提供了解决这个问题的方法。

    

    我们提出了一个新颖的评估框架，用于评估潜在因素推荐算法中的表示偏见。我们的框架引入了属性关联偏见的概念，让从业人员可以探索推荐系统如何引入或放大利益相关者表达上的伤害。当敏感属性在训练的推荐潜在空间中被语义捕捉或纠缠时，就会出现属性关联偏见（AAB）。这种偏见可能导致推荐者强化有害的刻板印象，从而可能对系统的使用者和供应者利益相关者造成进一步的表达伤害。潜在因素推荐模型由于能够将显式和隐式属性纠缠在训练的潜在空间中，因此容易遭受AAB的影响。由于在混合工业推荐系统中，实体向量作为属性在下游组件中的使用越来越常见，因此理解这种现象是非常重要的。我们为从业人员提供了一个框架，可以帮助他们评估和解决AAB问题。

    We present a novel evaluation framework for representation bias in latent factor recommendation (LFR) algorithms. Our framework introduces the concept of attribute association bias in recommendations allowing practitioners to explore how recommendation systems can introduce or amplify stakeholder representation harm. Attribute association bias (AAB) occurs when sensitive attributes become semantically captured or entangled in the trained recommendation latent space. This bias can result in the recommender reinforcing harmful stereotypes, which may result in downstream representation harms to system consumer and provider stakeholders. LFR models are at risk of experiencing AAB due to their ability to entangle explicit and implicit attributes into the trained latent space. Understanding this phenomenon is essential due to the increasingly common use of entity vectors as attributes in downstream components in hybrid industry recommendation systems. We provide practitioners with a framewor
    
[^12]: Split-NER: 通过两个基于问答的分类解决命名实体识别问题

    Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications. (arXiv:2310.19942v1 [cs.CL])

    [http://arxiv.org/abs/2310.19942](http://arxiv.org/abs/2310.19942)

    本研究提出了一种名为Split-NER的系统，通过将命名实体识别问题分成提取实体提及跨度和跨度分类两个子任务，然后利用问答模型解决这两个子任务，实现了高效和准确的命名实体识别。

    

    本研究将命名实体识别问题分成两个逻辑子任务：（1）提取实体提及跨度，无论实体类型如何；（2）将跨度分类为实体类型。进一步，我们将这两个子任务都形式化为问答问题，并产生两个可以分别为每个子任务进行优化的更轻的模型。在四个跨领域数据集上的实验表明，这个两步法既有效又节省时间。我们的系统SplitNER在OntoNotes5.0、WNUT17和一个网络安全数据集上的性能超过了基线，并在BioNLP13CG上表现相当。在所有情况下，与QA基线对照相比，它在训练时减少了显著的时间。我们系统的有效性源于分别对跨度检测和分类进行BERT模型的微调。源代码可在https://github.com/c3sr/split-ner找到。

    In this work, we address the NER problem by splitting it into two logical sub-tasks: (1) Span Detection which simply extracts entity mention spans irrespective of entity type; (2) Span Classification which classifies the spans into their entity types. Further, we formulate both sub-tasks as question-answering (QA) problems and produce two leaner models which can be optimized separately for each sub-task. Experiments with four cross-domain datasets demonstrate that this two-step approach is both effective and time efficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17 and a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all cases, it achieves a significant reduction in training time compared to its QA baseline counterpart. The effectiveness of our system stems from fine-tuning the BERT model twice, separately for span detection and classification. The source code can be found at https://github.com/c3sr/split-ner.
    
[^13]: BTRec: 基于BERT的个性化旅游轨迹推荐

    BTRec: BERT-Based Trajectory Recommendation for Personalized Tours. (arXiv:2310.19886v1 [cs.LG])

    [http://arxiv.org/abs/2310.19886](http://arxiv.org/abs/2310.19886)

    BTRec是一种基于BERT的轨迹推荐算法，它利用用户的人口统计信息和过去的POI访问信息，通过修改后的BERT语言模型生成个性化的POI行程预测，从而为旅游者提供有针对性的推荐行程。

    

    对于旅游者来说，拥有一个精心规划的行程和相关推荐是度过愉快假期的关键，尤其是当他们访问陌生城市时。许多旅游推荐工具只考虑了有限的因素，如热门景点和路径限制。因此，它们提供的解决方案可能不总是与系统的个体用户保持一致。本文提出了一种名为BTREC（基于BERT的轨迹推荐）的迭代算法，它从POIBERT嵌入算法扩展到使用BERT框架推荐个性化POI行程。我们的BTREC算法将用户的人口统计信息和过去的POI访问信息合并到修改后的BERT语言模型中，以给出一对出发地和目的地POI的个性化POI行程预测。我们的推荐系统可以创建一个最大化访问POI的旅行行程，同时考虑用户的偏好。

    An essential task for tourists having a pleasant holiday is to have a well-planned itinerary with relevant recommendations, especially when visiting unfamiliar cities. Many tour recommendation tools only take into account a limited number of factors, such as popular Points of Interest (POIs) and routing constraints. Consequently, the solutions they provide may not always align with the individual users of the system. We propose an iterative algorithm in this paper, namely: BTREC (BERT-based Trajectory Recommendation), that extends from the POIBERT embedding algorithm to recommend personalized itineraries on POIs using the BERT framework. Our BTREC algorithm incorporates users' demographic information alongside past POI visits into a modified BERT language model to recommend a personalized POI itinerary prediction given a pair of source and destination POIs. Our recommendation system can create a travel itinerary that maximizes POIs visited, while also taking into account user preferenc
    
[^14]: AMIR：基于COVID-19疫苗数据集的自动化虚假信息驳斥推荐系统

    AMIR: Automated MisInformation Rebuttal -- A COVID-19 Vaccination Datasets based Recommendation System. (arXiv:2310.19834v1 [cs.AI])

    [http://arxiv.org/abs/2310.19834](http://arxiv.org/abs/2310.19834)

    本研究提出了基于COVID-19疫苗数据集的自动化虚假信息驳斥推荐系统，利用社交媒体信息和经过策划的事实核查数据，实现了大规模自动驳斥虚假信息。这为对抗虚假信息提供了一种成本效益高、可扩展的解决方案。

    

    虚假信息近年来已成为一个重要的社会威胁，特别是在COVID-19大流行的背景下，它加剧了疫苗犹豫不决。对抗虚假信息的成本效益高、可扩展的解决方案是当务之急。本研究探讨如何利用社交媒体获取的现有信息，并与更多经过策划的事实核查数据库相结合，以促进大规模自动驳斥虚假信息。虽然这里的想法可以推广并重新应用于使用多种信息来源和满足社交媒体平台光谱的较大范围的虚假信息缓解，但本工作作为一个概念验证受限于其范围，仅限于对推文的反驳，且仅限于COVID-19相关的虚假信息。它利用了两个公开可用的数据集，即FaCov（经事实核查的文章）和misleading（社交媒体推文）。

    Misinformation has emerged as a major societal threat in recent years in general; specifically in the context of the COVID-19 pandemic, it has wrecked havoc, for instance, by fuelling vaccine hesitancy. Cost-effective, scalable solutions for combating misinformation are the need of the hour. This work explored how existing information obtained from social media and augmented with more curated fact checked data repositories can be harnessed to facilitate automated rebuttal of misinformation at scale. While the ideas herein can be generalized and reapplied in the broader context of misinformation mitigation using a multitude of information sources and catering to the spectrum of social media platforms, this work serves as a proof of concept, and as such, it is confined in its scope to only rebuttal of tweets, and in the specific context of misinformation regarding COVID-19. It leverages two publicly available datasets, viz. FaCov (fact-checked articles) and misleading (social media Twitt
    
[^15]: 用交叉子序列进行意图对比学习的顺序推荐

    Intent Contrastive Learning with Cross Subsequences for Sequential Recommendation. (arXiv:2310.14318v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.14318](http://arxiv.org/abs/2310.14318)

    本论文提出了一种名为ICSRec的方法，用于建模用户的潜在意图，以提高顺序推荐的性能。该方法通过对比学习和交叉子序列来准确捕捉用户的意图。

    

    用户的购买行为主要受到他们的意图影响（例如，购买装饰用的衣服，购买画画用的画笔等）。建模用户的潜在意图可以显著提高推荐的性能。先前的工作通过考虑辅助信息中的预定义标签或引入随机数据增强来建模用户的意图。然而，辅助信息是稀疏的，并且对于推荐系统并不总是可用的，引入随机数据增强可能会引入噪声，从而改变序列中隐藏的意图。因此，利用用户的意图进行顺序推荐可能具有挑战性，因为它们经常变化且不可观察。本文提出了用于顺序推荐的意图对比学习与交叉子序列（ICSRec），用于建模用户的潜在意图。

    The user purchase behaviors are mainly influenced by their intentions (e.g., buying clothes for decoration, buying brushes for painting, etc.). Modeling a user's latent intention can significantly improve the performance of recommendations. Previous works model users' intentions by considering the predefined label in auxiliary information or introducing stochastic data augmentation to learn purposes in the latent space. However, the auxiliary information is sparse and not always available for recommender systems, and introducing stochastic data augmentation may introduce noise and thus change the intentions hidden in the sequence. Therefore, leveraging user intentions for sequential recommendation (SR) can be challenging because they are frequently varied and unobserved. In this paper, Intent contrastive learning with Cross Subsequences for sequential Recommendation (ICSRec) is proposed to model users' latent intentions. Specifically, ICSRec first segments a user's sequential behaviors
    
[^16]: 评估潮起潮落：对不同平台间问答趋势的深入分析

    Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v1 [cs.SI])

    [http://arxiv.org/abs/2309.05961](http://arxiv.org/abs/2309.05961)

    本文通过对六个社区问答平台的研究，发现了查询的元数据、问题构成方式和用户互动水平与第一个回答时间之间的关联，并利用机器学习模型预测查询是否能够迅速获得回答。

    

    社区问答平台因其快速回答用户查询的能力而越来越受欢迎。这些回答速度的快慢取决于查询特定和用户相关的因素的综合。本文通过研究六个高度流行的社区问答平台，分析了这些因素在其中的作用。我们的调查揭示了问题的第一个回答所花费的时间与元数据、问题的构成方式和用户之间的互动水平之间的关联。此外，通过使用传统的机器学习模型分析这些元数据和用户互动模式，我们试图预测哪些查询将迅速获得初始回答。

    Community Question Answering (CQA) platforms steadily gain popularity as they provide users with fast responses to their queries. The swiftness of these responses is contingent on a mixture of query-specific and user-related elements. This paper scrutinizes these contributing factors within the context of six highly popular CQA platforms, identified through their standout answering speed. Our investigation reveals a correlation between the time taken to yield the first response to a question and several variables: the metadata, the formulation of the questions, and the level of interaction among users. Additionally, by employing conventional machine learning models to analyze these metadata and patterns of user interaction, we endeavor to predict which queries will receive their initial responses promptly.
    
[^17]: 以提示为基础的个性化冷启动推荐的研究

    Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])

    [http://arxiv.org/abs/2306.17256](http://arxiv.org/abs/2306.17256)

    本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。

    

    推荐系统在根据用户过去的行为帮助用户发现与其兴趣相符的信息方面发挥着关键作用。然而，当用户和物品之间的历史交互记录不可用时，开发个性化推荐系统变得具有挑战性，这就是所谓的系统冷启动推荐问题。此问题在创业企业或用户参与历史不足的平台中尤为突出。以往的研究集中在用户或物品的冷启动场景，其中系统仍然通过在同一领域中的历史用户和物品交互进行训练来为新用户或物品提供推荐，而无法解决我们的问题。为了弥合这一鸿沟，我们的研究引入了一种创新且有效的方法，利用预训练语言模型的能力。我们将推荐过程转化为自然语言情感分析，其中包含用户资料和物品属性的信息。

    Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
    
[^18]: 实现大型语言模型生成带引文的文本

    Enabling Large Language Models to Generate Text with Citations. (arXiv:2305.14627v1 [cs.CL])

    [http://arxiv.org/abs/2305.14627](http://arxiv.org/abs/2305.14627)

    本文提出ALCE，是首个自动LLMs引文评估基准，实现大型语言模型生成带引文的文本，提高其事实正确性和可验证性；提示LLMs特定的关键词或利用外部知识源可以显著提高其引文准确性。

    

    大型语言模型（LLMs）已成为广泛使用的信息寻找工具，但生成的输出容易出现幻觉。本文旨在实现LLMs生成带引文的文本，提高其事实正确性和可验证性。我们提出了ALCE，这是首个自动LLMs引文评估基准。ALCE收集了各种问题和检索语料库，并要求建立端到端系统以检索支持证据并生成带有引文的答案。我们沿着流畅性、正确性和引文质量三个维度构建自动指标，并展示了它们与人类判断的强相关性。我们使用最先进的LLMs和新的提示策略进行实验，结果表明当前系统仍有相当大的提升空间--例如，提示LLMs特定的关键词或利用外部知识源可以显著提高其引文准确性。我们的工作为未来研究发展能够生成可验证和可信赖输出的LLMs提供了坚实基础。

    Large language models (LLMs) have emerged as a widely-used tool for information seeking, but their generated outputs are prone to hallucination. In this work, we aim to enable LLMs to generate text with citations, improving their factual correctness and verifiability. Existing work mainly relies on commercial search engines and human evaluation, making it challenging to reproduce and compare with different modeling approaches. We propose ALCE, the first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set of questions and retrieval corpora and requires building end-to-end systems to retrieve supporting evidence and generate answers with citations. We build automatic metrics along three dimensions -- fluency, correctness, and citation quality -- and demonstrate their strong correlation with human judgements. Our experiments with state-of-the-art LLMs and novel prompting strategies show that current systems have considerable room for improvements -for example,
    
[^19]: 从检索到生成：高效且有效的实体集扩展方法

    From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v1 [cs.CL])

    [http://arxiv.org/abs/2304.03531](http://arxiv.org/abs/2304.03531)

    本文提出了GenExpan，一种基于生成式预训练语言模型的实体集扩展框架，利用前缀树保证实体生成的有效性，采用自动生成的类名来引导模型生成同一类实体，从而提高了效率和可扩展性。

    

    实体集扩展（ESE）是一项至关重要的任务，旨在扩展由小的种子实体集描述的目标语义类的实体。大多数现有的ESE方法是基于检索的框架，需要提取实体的上下文特征，并计算种子实体和候选实体之间的相似性。为了实现这两个目的，它们必须迭代地遍历语料库和数据集中提供的实体词汇，导致效率和可扩展性较差。实验结果表明，基于检索的ESE方法消耗的时间与实体词汇和语料库的大小成线性增长。本文首先提出了一种生成式ESE框架，Generative Entity Set Expansion (GenExpan)，它利用生成式预训练语言模型来完成ESE任务。具体而言，采用前缀树来保证实体生成的有效性，并采用自动生成的类名来引导模型生成同一类实体。

    Entity Set Expansion (ESE) is a critical task aiming to expand entities of the target semantic class described by a small seed entity set. Most existing ESE methods are retrieval-based frameworks that need to extract the contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they should iteratively traverse the corpus and the entity vocabulary provided in the datasets, resulting in poor efficiency and scalability. The experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose a generative ESE framework, Generative Entity Set Expansion (GenExpan), which utilizes a generative pre-trained language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to gen
    
[^20]: 学习用于排名的列表级别领域不变表示

    Learning List-Level Domain-Invariant Representations for Ranking. (arXiv:2212.10764v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.10764](http://arxiv.org/abs/2212.10764)

    本文提出了一种针对排名问题的列表级别对齐的学习方法，该方法利用列表的结构特性，在领域适应中实现从源领域到目标领域的知识转移。

    

    领域适应旨在将在（数据丰富）源领域学到的知识转移到（资源有限）目标领域，一种常用的方法是不变表示学习，它匹配并对齐特征空间上的数据分布。尽管这种方法在分类和回归问题上得到了广泛研究和应用，但在排名问题上的应用却是零散的，并且现有的几种实现缺乏理论上的证明。本文重新审视了用于排名的不变表示学习。在审查之前的工作时，我们发现他们实施了我们称之为项目级别对齐的方法，该方法在聚合的所有列表中对进行排名的项目分布进行对齐，但忽略了列表的结构。然而，列表的结构应该被利用，因为它是排名问题的固有特性，其中数据和度量是在列表上定义和计算的，而不是在项目本身上。为了解决这一不一致，我们提出了列表级别对齐的学习

    Domain adaptation aims to transfer the knowledge learned on (data-rich) source domains to (low-resource) target domains, and a popular method is invariant representation learning, which matches and aligns the data distributions on the feature space. Although this method is studied extensively and applied on classification and regression problems, its adoption on ranking problems is sporadic, and the few existing implementations lack theoretical justifications. This paper revisits invariant representation learning for ranking. Upon reviewing prior work, we found that they implement what we call item-level alignment, which aligns the distributions of the items being ranked from all lists in aggregate but ignores their list structure. However, the list structure should be leveraged, because it is intrinsic to ranking problems where the data and the metrics are defined and computed on lists, not the items by themselves. To close this discrepancy, we propose list-level alignment -learning
    

