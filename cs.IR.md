# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language.](http://arxiv.org/abs/2310.13540) | 本研究提出了一种新颖的统一预训练语言模型增强顺序推荐方法（UPSR），旨在构建一个统一的预训练推荐模型用于多领域推荐任务。研究者设计了五个关键指标来指导预训练和微调过程中的文本->物品适应和行为序列->文本序列适应。 |
| [^2] | [Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation.](http://arxiv.org/abs/2310.13505) | 这项研究提出了一种新的框架REIGN，通过生成训练问题的改写，并使用深度强化学习来指导对话问答模型，增加模型对表面形式变化的鲁棒性，同时在不同的基准上进行零-shot应用。 |
| [^3] | [Two-Stage Triplet Loss Training with Curriculum Augmentation for Audio-Visual Retrieval.](http://arxiv.org/abs/2310.13451) | 本研究提出了一种基于课程学习的两阶段训练方法，通过在训练过程中区分半硬和硬三元组，提高了跨模态检索模型的性能。 |
| [^4] | [Music Augmentation and Denoising For Peak-Based Audio Fingerprinting.](http://arxiv.org/abs/2310.13388) | 本研究通过引入音频增强流水线和深度学习模型，为嘈杂环境下的音频指纹识别提出了解决方案，提高了识别性能。 |
| [^5] | [Towards Multi-Subsession Conversational Recommendation.](http://arxiv.org/abs/2310.13365) | 这篇论文提出了一种名为多子会话多轮会话推荐的新颖场景，通过多轮交互对话获取用户对所需物品的动态偏好。为了解决这一场景的问题，提出了一种新的框架，使用上下文感知的推荐模块综合建模用户兴趣。 |
| [^6] | [Motif-Based Prompt Learning for Universal Cross-Domain Recommendation.](http://arxiv.org/abs/2310.13303) | 我们提出了一种基于模式的提示学习框架MOP，该框架引入了基于模式的共享嵌入，解决了现有CDR模型在跨领域推荐中面临的适应性和负面转移问题。 |
| [^7] | [VR PreM+: An Immersive Pre-learning Branching Visualization System for Museum Tours.](http://arxiv.org/abs/2310.13294) | VR PreM+是一个沉浸式的博物馆导览预学习分支可视化系统，通过关键字信息检索在动态的3D空间中管理和连接各种内容来源，提高了沟通和数据比较的能力，有望应用于研究和教育等领域。 |
| [^8] | [Unified Pretraining for Recommendation via Task Hypergraphs.](http://arxiv.org/abs/2310.13286) | 本文提出了一种名为"通过任务超图的统一预训练推荐"的多任务预训练框架，使用任务超图将先前任务推广为超边预测，并通过过渡性注意力层学习每个先前任务与推荐之间的相关性。实验表明，这种方法在准确性和效率方面优于其他基准方法。 |
| [^9] | [An Exploratory Study on Simulated Annealing for Feature Selection in Learning-to-Rank.](http://arxiv.org/abs/2310.13269) | 该研究探讨了在学习排序中使用模拟退火进行特征选择的方法，并引入了进展参数来有效遍历搜索空间。实验证明了该方法的有效性。 |
| [^10] | [A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems.](http://arxiv.org/abs/2310.13260) | 这个论文介绍了一个以数据为中心的多目标学习框架，用于构建负责任的推荐系统。该框架能够解决当前方法在处理多个目标时遇到的困难，并且提供了对目标优先级的可控性。 |
| [^11] | [Knowledge Graph Context-Enhanced Diversified Recommendation.](http://arxiv.org/abs/2310.13253) | 该研究在知识图谱背景下探索多样化推荐系统，通过引入创新的度量标准和评分函数，有效提高了知识图谱推荐算法的多样性。 |
| [^12] | [TempGNN: Temporal Graph Neural Networks for Dynamic Session-Based Recommendations.](http://arxiv.org/abs/2310.13249) | TempGNN是一种用于动态会话推荐的时间图神经网络，可以捕捉复杂物品转换的结构和时间动态，通过对动态会话图中的节点和边进行时间嵌入操作，有效地预测下一步动作。 |
| [^13] | [Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking.](http://arxiv.org/abs/2310.13243) | 最新的开源大规模语言模型展现出了强大的零-shot查询似然模型的排名能力，研究显示，这些模型在没有监督指导微调的情况下依然能够进行有效的排序，而且我们还提出了一种新的最先进的排序系统，该系统将基于语言模型的查询似然模型与零-shot检索器集成，不仅在零-shot情况下表现出色，而且在少-shot场景中也展现了卓越的效果。 |
| [^14] | [Software Metadata Classification based on Generative Artificial Intelligence.](http://arxiv.org/abs/2310.13006) | 本文提出了一种利用生成式人工智能在二进制代码评论质量分类模型中提升性能的新方法，通过引入生成数据集，模型的准确性得到了显著改善，支持向量机模型的精确度提高了6%，人工神经网络模型的召回率提高了1.5%。 |
| [^15] | [Conversational Financial Information Retrieval Model (ConFIRM).](http://arxiv.org/abs/2310.13001) | ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。 |
| [^16] | [Document-Level Relation Extraction with Relation Correlation Enhancement.](http://arxiv.org/abs/2310.13000) | 该论文提出了一种关系图方法，用于解决文档级关系抽取中忽视关系相关性的问题。通过构建关系图、加权处理和利用图注意力网络，可以有效地捕捉文档中关系之间的相关性。该方法可以作为现有模型的模块集成，并在实验中取得了良好的效果。 |
| [^17] | [From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification.](http://arxiv.org/abs/2310.11675) | 本论文提出了一种基于反馈的证据检索器(FER)，通过整合声明验证者的反馈来优化事实验证中的证据检索过程。实证研究表明FER优于现有的基准方法。 |
| [^18] | [Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports.](http://arxiv.org/abs/2309.12273) | 通过自适应的NLP模型选择和临床专家规则的分类器，该研究提出一种改进VTE识别的新方法，在放射学报告中准确识别VTE事件的准确性得到提高。 |
| [^19] | [FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning.](http://arxiv.org/abs/2309.08420) | 提出了一种名为FedDCSR的联邦跨领域顺序推荐框架，通过解缠表示学习来处理不同领域之间的序列特征异质性，并保护数据隐私。 |
| [^20] | [Multi-Relational Contrastive Learning for Recommendation.](http://arxiv.org/abs/2309.01103) | 本论文介绍了一种多关系对比学习框架（RCL），用于解决个性化推荐系统中单一行为学习的限制。RCL模型通过多关系图编码器捕捉短期偏好的异质性，并使用动态跨关系记忆网络来捕捉用户的长期多行为模式。 |
| [^21] | [Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models.](http://arxiv.org/abs/2307.11224) | Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。 |
| [^22] | [GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study.](http://arxiv.org/abs/2305.13062) | 本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。 |
| [^23] | [Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search.](http://arxiv.org/abs/2303.06573) | 本论文提出了一个提示框架，利用大型语言模型作为文本搜索意图解释器来帮助会话搜索。通过探索三种提示方法，从而生成多个查询重写和假设性回复，并将它们聚合成一个集成表示以表示用户的真实上下文搜索意图。 |
| [^24] | [A challenge-based survey of e-recruitment recommendation systems.](http://arxiv.org/abs/2209.05112) | 这篇论文提供了一个基于挑战的电子招聘推荐系统调查，该调查以实用性为导向，适用于面临具体招聘设计任务和挑战的开发人员。 |

# 详细

[^1]: 全面将多领域预训练推荐建模为语言

    Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language. (arXiv:2310.13540v1 [cs.IR])

    [http://arxiv.org/abs/2310.13540](http://arxiv.org/abs/2310.13540)

    本研究提出了一种新颖的统一预训练语言模型增强顺序推荐方法（UPSR），旨在构建一个统一的预训练推荐模型用于多领域推荐任务。研究者设计了五个关键指标来指导预训练和微调过程中的文本->物品适应和行为序列->文本序列适应。

    

    随着预训练语言模型（PLM）在各种自然语言处理任务中的广泛应用，先驱性工作试图探索将PLM中的通用文本信息与用户历史行为序列中的个性化行为信息相结合，以增强顺序推荐（SR）。然而，尽管输入格式和任务目标存在共性，行为和文本信息之间存在巨大差距，这阻碍了将SR作为语言建模完全建模。为了填补这一差距，我们提出了一种新颖的统一预训练语言模型增强顺序推荐（UPSR）方法，旨在构建一个统一的预训练推荐模型用于多领域推荐任务。我们正式设计了自然性、领域一致性、信息性、噪声和模糊性以及文本长度等五个关键指标，分别用于指导预训练和微调过程中的文本->物品适应和行为序列->文本序列适应。

    With the thriving of pre-trained language model (PLM) widely verified in various of NLP tasks, pioneer efforts attempt to explore the possible cooperation of the general textual information in PLM with the personalized behavioral information in user historical behavior sequences to enhance sequential recommendation (SR). However, despite the commonalities of input format and task goal, there are huge gaps between the behavioral and textual information, which obstruct thoroughly modeling SR as language modeling via PLM. To bridge the gap, we propose a novel Unified pre-trained language model enhanced sequential recommendation (UPSR), aiming to build a unified pre-trained recommendation model for multi-domain recommendation tasks. We formally design five key indicators, namely naturalness, domain consistency, informativeness, noise & ambiguity, and text length, to guide the text->item adaptation and behavior sequence->text sequence adaptation differently for pre-training and fine-tuning 
    
[^2]: 具有强化改写生成的对话问答模型的鲁棒训练

    Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation. (arXiv:2310.13505v1 [cs.CL])

    [http://arxiv.org/abs/2310.13505](http://arxiv.org/abs/2310.13505)

    这项研究提出了一种新的框架REIGN，通过生成训练问题的改写，并使用深度强化学习来指导对话问答模型，增加模型对表面形式变化的鲁棒性，同时在不同的基准上进行零-shot应用。

    

    知识图谱（KG）上的对话问答（ConvQA）模型通常在黄金QA对的基准上进行训练和测试。这意味着训练仅限于在相应数据集中见到的表面形式，评估仅针对一小部分问题。通过我们的提出的框架REIGN，我们采取了几个步骤来解决这个受限的学习设置。首先，我们系统地生成训练问题的改写，以提高模型对表面形式变化的鲁棒性。这是一个特别具有挑战性的问题，因为这些问题的不完整性。其次，我们使用深度强化学习将ConvQA模型引导到更高的性能，只提供那些有助于提高回答质量的改写。第三，我们展示了在一个基准上训练主要模型组件并将其零-shot应用于另一个的可行性。最后，为了对训练模型的鲁棒性进行严格评估，我们使用和重新配置初始的改写、测试语料。

    Models for conversational question answering (ConvQA) over knowledge graphs (KGs) are usually trained and tested on benchmarks of gold QA pairs. This implies that training is limited to surface forms seen in the respective datasets, and evaluation is on a small set of held-out questions. Through our proposed framework REIGN, we take several steps to remedy this restricted learning setup. First, we systematically generate reformulations of training questions to increase robustness of models to surface form variations. This is a particularly challenging problem, given the incomplete nature of such questions. Second, we guide ConvQA models towards higher performance by feeding it only those reformulations that help improve their answering quality, using deep reinforcement learning. Third, we demonstrate the viability of training major model components on one benchmark and applying them zero-shot to another. Finally, for a rigorous evaluation of robustness for trained models, we use and re
    
[^3]: 两阶段三元组损失训练与课程增强在音视频检索中的应用

    Two-Stage Triplet Loss Training with Curriculum Augmentation for Audio-Visual Retrieval. (arXiv:2310.13451v1 [cs.SD])

    [http://arxiv.org/abs/2310.13451](http://arxiv.org/abs/2310.13451)

    本研究提出了一种基于课程学习的两阶段训练方法，通过在训练过程中区分半硬和硬三元组，提高了跨模态检索模型的性能。

    

    跨模态检索模型利用三元组损失优化来学习鲁棒的嵌入空间。然而，现有方法通常在单次训练中对这些模型进行训练，忽视了优化过程中半硬和硬三元组之间的区别。没有区分半硬和硬三元组的疏忽导致了模型性能的次优。本文引入了一种基于课程学习的新方法来解决这个问题。我们提出了一个两阶段的训练范式，引导模型的学习过程从半硬三元组到硬三元组。在第一阶段，模型从低损失基础开始，使用一组半硬三元组进行训练。随后，在第二阶段，我们使用插值技术对嵌入进行增强。这个过程可以识别潜在的困难负样本，缓解由于困难三元组稀缺导致的高损失函数的问题。我们的方法还在增强后的嵌入中应用了硬三元组挖掘。

    The cross-modal retrieval model leverages the potential of triple loss optimization to learn robust embedding spaces. However, existing methods often train these models in a singular pass, overlooking the distinction between semi-hard and hard triples in the optimization process. The oversight of not distinguishing between semi-hard and hard triples leads to suboptimal model performance. In this paper, we introduce a novel approach rooted in curriculum learning to address this problem. We propose a two-stage training paradigm that guides the model's learning process from semi-hard to hard triplets. In the first stage, the model is trained with a set of semi-hard triplets, starting from a low-loss base. Subsequently, in the second stage, we augment the embeddings using an interpolation technique. This process identifies potential hard negatives, alleviating issues arising from high-loss functions due to a scarcity of hard triples. Our approach then applies hard triplet mining in the aug
    
[^4]: 音频指纹识别中的音乐增强和降噪

    Music Augmentation and Denoising For Peak-Based Audio Fingerprinting. (arXiv:2310.13388v1 [cs.SD])

    [http://arxiv.org/abs/2310.13388](http://arxiv.org/abs/2310.13388)

    本研究通过引入音频增强流水线和深度学习模型，为嘈杂环境下的音频指纹识别提出了解决方案，提高了识别性能。

    

    音频指纹识别是一种从简短录音片段中识别歌曲的成熟解决方案。流行的方法依赖于抽取稀疏表示，通常是频谱峰值，并且已经证明准确、快速，并可扩展到大型集合。然而，在现实世界中，音频识别的应用往往发生在嘈杂的环境中，这可能导致这些系统失效。在这项工作中，我们通过引入和发布一个新的音频增强流水线来解决这个问题，该流水线以一种逼真的方式向音乐片段添加噪声，通过随机模拟现实世界的场景。然后，我们提出并发布了一个深度学习模型，该模型从谱图中去除噪声成分，以提高基于峰值的指纹识别系统的准确性。我们证明了我们的模型的添加改进了常用音频指纹识别系统的识别性能，即使在嘈杂的条件下也是如此。

    Audio fingerprinting is a well-established solution for song identification from short recording excerpts. Popular methods rely on the extraction of sparse representations, generally spectral peaks, and have proven to be accurate, fast, and scalable to large collections. However, real-world applications of audio identification often happen in noisy environments, which can cause these systems to fail. In this work, we tackle this problem by introducing and releasing a new audio augmentation pipeline that adds noise to music snippets in a realistic way, by stochastically mimicking real-world scenarios. We then propose and release a deep learning model that removes noisy components from spectrograms in order to improve peak-based fingerprinting systems' accuracy. We show that the addition of our model improves the identification performance of commonly used audio fingerprinting systems, even under noisy conditions.
    
[^5]: 迈向多子会话会话推荐

    Towards Multi-Subsession Conversational Recommendation. (arXiv:2310.13365v1 [cs.IR])

    [http://arxiv.org/abs/2310.13365](http://arxiv.org/abs/2310.13365)

    这篇论文提出了一种名为多子会话多轮会话推荐的新颖场景，通过多轮交互对话获取用户对所需物品的动态偏好。为了解决这一场景的问题，提出了一种新的框架，使用上下文感知的推荐模块综合建模用户兴趣。

    

    会话推荐系统(CRS)可以通过多轮交互对话获取用户对所需物品的动态偏好。以往的CRS主要关注用户在成功推荐后退出的单次对话(子会话)，忽视了用户在短时间内进行多次对话(多子会话)的常见场景。因此，我们提出了一种新颖的会话推荐场景，名为多子会话多轮会话推荐(MSMCR)，用户在多个子会话之后仍然会使用CRS，并可能保持模糊的兴趣，系统会主动询问属性以激活当前子会话中的用户兴趣。为了填补这一新的CRS场景中的空白，我们设计了一种称为带有激活属性的多子会话会话推荐器的新框架(MSCAA)。具体而言，我们首先开发了一个上下文感知的推荐模块，全面地对用户兴趣进行建模，

    Conversational recommendation systems (CRS) could acquire dynamic user preferences towards desired items through multi-round interactive dialogue. Previous CRS mainly focuses on the single conversation (subsession) that user quits after a successful recommendation, neglecting the common scenario where user has multiple conversations (multi-subsession) over a short period. Therefore, we propose a novel conversational recommendation scenario named Multi-Subsession Multi-round Conversational Recommendation (MSMCR), where user would still resort to CRS after several subsessions and might preserve vague interests, and system would proactively ask attributes to activate user interests in the current subsession. To fill the gap in this new CRS scenario, we devise a novel framework called Multi-Subsession Conversational Recommender with Activation Attributes (MSCAA). Specifically, we first develop a context-aware recommendation module, comprehensively modeling user interests from historical in
    
[^6]: 基于模式的提示学习用于通用跨领域推荐

    Motif-Based Prompt Learning for Universal Cross-Domain Recommendation. (arXiv:2310.13303v1 [cs.IR])

    [http://arxiv.org/abs/2310.13303](http://arxiv.org/abs/2310.13303)

    我们提出了一种基于模式的提示学习框架MOP，该框架引入了基于模式的共享嵌入，解决了现有CDR模型在跨领域推荐中面临的适应性和负面转移问题。

    

    跨领域推荐（CDR）是一项关键技术，通过将源领域的通用知识转移至目标领域，解决数据稀疏和冷启动问题。然而，现有的CDR模型由于固有的复杂性，其在不同场景中的适应性受到限制。为了解决这个挑战，最近的研究引入了基于共享嵌入的通用CDR模型，通过"多任务学习"或"预训练，微调"范式来捕捉跨领域通用知识。然而，这些模型通常忽视跨领域之间的广泛结构拓扑，并且在训练目标上不能完全对齐，可能导致负面的转移效果。为了解决这些问题，我们提出了基于模式的提示学习框架MOP，引入了基于模式的共享嵌入，以包含泛化的领域知识，同时适应领域内和领域间的CDR任务。具体地，我们设计了三种典型的模式：蝴蝶...

    Cross-Domain Recommendation (CDR) stands as a pivotal technology addressing issues of data sparsity and cold start by transferring general knowledge from the source to the target domain. However, existing CDR models suffer limitations in adaptability across various scenarios due to their inherent complexity. To tackle this challenge, recent advancements introduce universal CDR models that leverage shared embeddings to capture general knowledge across domains and transfer it through "Multi-task Learning" or "Pre-train, Fine-tune" paradigms. However, these models often overlook the broader structural topology that spans domains and fail to align training objectives, potentially leading to negative transfer. To address these issues, we propose a motif-based prompt learning framework, MOP, which introduces motif-based shared embeddings to encapsulate generalized domain knowledge, catering to both intra-domain and inter-domain CDR tasks. Specifically, we devise three typical motifs: butterf
    
[^7]: VR PreM+：一个沉浸式的博物馆导览预学习分支可视化系统

    VR PreM+: An Immersive Pre-learning Branching Visualization System for Museum Tours. (arXiv:2310.13294v1 [cs.HC])

    [http://arxiv.org/abs/2310.13294](http://arxiv.org/abs/2310.13294)

    VR PreM+是一个沉浸式的博物馆导览预学习分支可视化系统，通过关键字信息检索在动态的3D空间中管理和连接各种内容来源，提高了沟通和数据比较的能力，有望应用于研究和教育等领域。

    

    我们提出了VR PreM+，一个创新的VR系统，旨在增强传统电脑屏幕以外的网络探索。与静态的2D显示不同，VR PreM+利用3D环境创建了沉浸式的预学习体验。通过关键字信息检索，用户可以在动态的3D空间中管理和连接各种内容来源，提高沟通和数据比较的能力。我们进行了初步和用户研究，证明了高效的信息检索、增加了用户参与度和更强的存在感。这些发现为未来的VR信息系统提供了三个设计指导原则：显示、交互和以用户为中心的设计。VR PreM+弥补了传统的网络浏览和沉浸式VR之间的差距，提供了一种交互式和全面的信息获取方法。它在研究、教育等领域具有潜力。

    We present VR PreM+, an innovative VR system designed to enhance web exploration beyond traditional computer screens. Unlike static 2D displays, VR PreM+ leverages 3D environments to create an immersive pre-learning experience. Using keyword-based information retrieval allows users to manage and connect various content sources in a dynamic 3D space, improving communication and data comparison. We conducted preliminary and user studies that demonstrated efficient information retrieval, increased user engagement, and a greater sense of presence. These findings yielded three design guidelines for future VR information systems: display, interaction, and user-centric design. VR PreM+ bridges the gap between traditional web browsing and immersive VR, offering an interactive and comprehensive approach to information acquisition. It holds promise for research, education, and beyond.
    
[^8]: 通过任务超图实现推荐的统一预训练

    Unified Pretraining for Recommendation via Task Hypergraphs. (arXiv:2310.13286v1 [cs.IR])

    [http://arxiv.org/abs/2310.13286](http://arxiv.org/abs/2310.13286)

    本文提出了一种名为"通过任务超图的统一预训练推荐"的多任务预训练框架，使用任务超图将先前任务推广为超边预测，并通过过渡性注意力层学习每个先前任务与推荐之间的相关性。实验表明，这种方法在准确性和效率方面优于其他基准方法。

    

    尽管预训练在最近几年引起了广泛关注和流行，但它在基于图的推荐系统中的应用相对有限。在广泛使用的ID依赖数据集中利用预训练的先前知识是具有挑战性的。一方面，一个数据集中的用户-物品交互历史很难通过预训练转移到其他数据集中，因为ID不同。另一方面，在同一个数据集上进行预训练和微调会导致过拟合的高风险。在本文中，我们提出了一种名为通过任务超图的统一推荐预训练的新型多任务预训练框架。为了处理各种先前任务的不同要求和细微差别，我们设计了任务超图将先前任务推广为超边预测。我们设计了一种新的过渡性注意力层来有差异地学习每个先前任务与推荐之间的相关性。在三个基准数据集上进行的实验结果表明，在准确性和效率方面，我们的方法优于其他基准方法。

    Although pretraining has garnered significant attention and popularity in recent years, its application in graph-based recommender systems is relatively limited. It is challenging to exploit prior knowledge by pretraining in widely used ID-dependent datasets. On one hand, user-item interaction history in one dataset can hardly be transferred to other datasets through pretraining, where IDs are different. On the other hand, pretraining and finetuning on the same dataset leads to a high risk of overfitting. In this paper, we propose a novel multitask pretraining framework named Unified Pretraining for Recommendation via Task Hypergraphs. For a unified learning pattern to handle diverse requirements and nuances of various pretext tasks, we design task hypergraphs to generalize pretext tasks to hyperedge prediction. A novel transitional attention layer is devised to discriminatively learn the relevance between each pretext task and recommendation. Experimental results on three benchmark da
    
[^9]: 用于学习排序中特征选择的模拟退火探索性研究

    An Exploratory Study on Simulated Annealing for Feature Selection in Learning-to-Rank. (arXiv:2310.13269v1 [cs.LG])

    [http://arxiv.org/abs/2310.13269](http://arxiv.org/abs/2310.13269)

    该研究探讨了在学习排序中使用模拟退火进行特征选择的方法，并引入了进展参数来有效遍历搜索空间。实验证明了该方法的有效性。

    

    学习排序是一种应用于监督式机器学习的领域。由于特征选择已被发现可以有效提高学习模型的准确性，因此研究将该过程应用于学习排序领域是非常有趣的。在本研究中，我们调查了一种称为模拟退火的流行元启发式方法在该任务中的应用。在模拟退火的一般框架下，我们探索了各种邻域选择策略和温度冷却方案。我们进一步引入了一个新的超参数，称为进展参数，可以有效地用于遍历搜索空间。我们的算法在五个公开基准数据集上进行了评估。为了更好地验证，我们还将基于模拟退火的特征选择算法与另一种有效的元启发式算法，即局部波束搜索进行了比较。广泛的实验结果表明了我们提出的模型的有效性。

    Learning-to-rank is an applied domain of supervised machine learning. As feature selection has been found to be effective for improving the accuracy of learning models in general, it is intriguing to investigate this process for learning-to-rank domain. In this study, we investigate the use of a popular meta-heuristic approach called simulated annealing for this task. Under the general framework of simulated annealing, we explore various neighborhood selection strategies and temperature cooling schemes. We further introduce a new hyper-parameter called the progress parameter that can effectively be used to traverse the search space. Our algorithms are evaluated on five publicly benchmark datasets of learning-to-rank. For a better validation, we also compare the simulated annealing-based feature selection algorithm with another effective meta-heuristic algorithm, namely local beam search. Extensive experimental results shows the efficacy of our proposed models.
    
[^10]: 一个以数据为中心的多目标学习框架用于负责任的推荐系统

    A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems. (arXiv:2310.13260v1 [cs.IR])

    [http://arxiv.org/abs/2310.13260](http://arxiv.org/abs/2310.13260)

    这个论文介绍了一个以数据为中心的多目标学习框架，用于构建负责任的推荐系统。该框架能够解决当前方法在处理多个目标时遇到的困难，并且提供了对目标优先级的可控性。

    

    推荐系统能够有效地引导用户在广泛的内容库中找到他们需要的信息。一般来说，推荐模型的优化是从用户效用的角度出发，比如点击率或匹配相关性。然而，一个负责任的工业推荐系统不仅需要考虑用户效用（对用户的责任），还需要考虑其他目标，包括增加平台收入（对平台的责任），确保公平性（对内容创作者的责任）和保持无偏性（对长期健康发展的责任）。多目标学习是实现负责任推荐系统的一种有力方法。然而，目前的方法面临两个挑战：在统一框架内扩展到异构目标的困难，以及优化过程中对目标优先级的不充分可控性，导致无法控制的解决方案。

    Recommendation systems effectively guide users in locating their desired information within extensive content repositories. Generally, a recommendation model is optimized to enhance accuracy metrics from a user utility standpoint, such as click-through rate or matching relevance. However, a responsible industrial recommendation system must address not only user utility (responsibility to users) but also other objectives, including increasing platform revenue (responsibility to platforms), ensuring fairness (responsibility to content creators), and maintaining unbiasedness (responsibility to long-term healthy development). Multi-objective learning is a potent approach for achieving responsible recommendation systems. Nevertheless, current methods encounter two challenges: difficulty in scaling to heterogeneous objectives within a unified framework, and inadequate controllability over objective priority during optimization, leading to uncontrollable solutions.  In this paper, we present 
    
[^11]: 知识图谱增强的多样化推荐

    Knowledge Graph Context-Enhanced Diversified Recommendation. (arXiv:2310.13253v1 [cs.IR])

    [http://arxiv.org/abs/2310.13253](http://arxiv.org/abs/2310.13253)

    该研究在知识图谱背景下探索多样化推荐系统，通过引入创新的度量标准和评分函数，有效提高了知识图谱推荐算法的多样性。

    

    推荐系统领域一直致力于通过利用用户的历史交互来提高准确性。然而，这种追求准确性的同时往往导致了多样性的降低，从而产生了众所周知的“回声室”现象。多样化推荐系统作为一种对策应运而生，将多样性与准确性同等看待，并在学术界和行业实践者中获得了显著的关注。本研究探索了多样化推荐系统在复杂的知识图谱（KG）背景下的应用。这些知识图谱是连接实体和项目的信息库，通过加入深入的上下文信息，提供了增加推荐多样性的有利途径。我们的贡献包括引入了一种创新的度量标准，实体覆盖和关系覆盖，有效地量化了知识图谱领域的多样性。此外，我们还引入了多样化评分函数，该函数通过综合利用实体覆盖和关系覆盖来提高推荐算法的多样性。

    The field of Recommender Systems (RecSys) has been extensively studied to enhance accuracy by leveraging users' historical interactions. Nonetheless, this persistent pursuit of accuracy frequently engenders diminished diversity, culminating in the well-recognized "echo chamber" phenomenon. Diversified RecSys has emerged as a countermeasure, placing diversity on par with accuracy and garnering noteworthy attention from academic circles and industry practitioners. This research explores the realm of diversified RecSys within the intricate context of knowledge graphs (KG). These KGs act as repositories of interconnected information concerning entities and items, offering a propitious avenue to amplify recommendation diversity through the incorporation of insightful contextual information. Our contributions include introducing an innovative metric, Entity Coverage, and Relation Coverage, which effectively quantifies diversity within the KG domain. Additionally, we introduce the Diversified
    
[^12]: TempGNN: 用于动态会话推荐的时间图神经网络

    TempGNN: Temporal Graph Neural Networks for Dynamic Session-Based Recommendations. (arXiv:2310.13249v1 [cs.IR])

    [http://arxiv.org/abs/2310.13249](http://arxiv.org/abs/2310.13249)

    TempGNN是一种用于动态会话推荐的时间图神经网络，可以捕捉复杂物品转换的结构和时间动态，通过对动态会话图中的节点和边进行时间嵌入操作，有效地预测下一步动作。

    

    最近，基于会话的推荐系统通过理解用户在短期会话中与物品的交互行为来预测下一步动作的方法受到了广泛关注。以前的研究主要集中在通过循环神经网络、自注意模型和最近的大多数图神经网络来捕捉会话中复杂物品转换的顺序依赖性。尽管有很多根据会话中物品顺序的不同模型，但很少有方法来更好地处理交互之间的时间意义。我们提出了一种名为Temporal Graph Neural Networks (TempGNN)的通用框架，利用节点和边上的时间嵌入操作来捕捉复杂物品转换的结构和时间动态，将其表示为定时事件序列的动态会话图。广泛的实验结果显示了所提方法的有效性和适应性。

    Session-based recommendations which predict the next action by understanding a user's interaction behavior with items within a relatively short ongoing session have recently gained increasing popularity. Previous research has focused on capturing the dynamics of sequential dependencies from complicated item transitions in a session by means of recurrent neural networks, self-attention models, and recently, mostly graph neural networks. Despite the plethora of different models relying on the order of items in a session, few approaches have been proposed for dealing better with the temporal implications between interactions. We present Temporal Graph Neural Networks (TempGNN), a generic framework for capturing the structural and temporal dynamics in complex item transitions utilizing temporal embedding operators on nodes and edges on dynamic session graphs, represented as sequences of timed events. Extensive experimental results show the effectiveness and adaptability of the proposed met
    
[^13]: 开源大规模语言模型是用于文档排序的零-shot查询似然模型

    Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking. (arXiv:2310.13243v1 [cs.IR])

    [http://arxiv.org/abs/2310.13243](http://arxiv.org/abs/2310.13243)

    最新的开源大规模语言模型展现出了强大的零-shot查询似然模型的排名能力，研究显示，这些模型在没有监督指导微调的情况下依然能够进行有效的排序，而且我们还提出了一种新的最先进的排序系统，该系统将基于语言模型的查询似然模型与零-shot检索器集成，不仅在零-shot情况下表现出色，而且在少-shot场景中也展现了卓越的效果。

    

    在信息检索领域中，查询似然模型（QLMs）根据生成查询的概率来对文档进行排序。最近，先进的大规模语言模型（LLMs）已经成为有效的QLMs，展示了有前途的排序能力。本文重点研究了最近LLMs的真实零-shot排序效果，这些模型仅在无结构文本数据上进行了预训练，没有进行监督指导微调。我们的发现揭示了这些LLMs的强大零-shot排序能力，同时强调除非微调数据集中存在问答生成任务，否则额外的指导微调可能会降低效果。此外，我们还介绍了一种新颖的最先进排序系统，该系统将基于LLM的QLMs与混合零-shot检索器集成，展示了在零-shot和少-shot场景中的出色效果。我们将我们的代码库公开在https://github.com/ielab/llm-qlm上。

    In the field of information retrieval, Query Likelihood Models (QLMs) rank documents based on the probability of generating the query given the content of a document. Recently, advanced large language models (LLMs) have emerged as effective QLMs, showcasing promising ranking capabilities. This paper focuses on investigating the genuine zero-shot ranking effectiveness of recent LLMs, which are solely pre-trained on unstructured text data without supervised instruction fine-tuning. Our findings reveal the robust zero-shot ranking ability of such LLMs, highlighting that additional instruction fine-tuning may hinder effectiveness unless a question generation task is present in the fine-tuning dataset. Furthermore, we introduce a novel state-of-the-art ranking system that integrates LLM-based QLMs with a hybrid zero-shot retriever, demonstrating exceptional effectiveness in both zero-shot and few-shot scenarios. We make our codebase publicly available at https://github.com/ielab/llm-qlm.
    
[^14]: 基于生成式人工智能的软件元数据分类

    Software Metadata Classification based on Generative Artificial Intelligence. (arXiv:2310.13006v1 [cs.SE])

    [http://arxiv.org/abs/2310.13006](http://arxiv.org/abs/2310.13006)

    本文提出了一种利用生成式人工智能在二进制代码评论质量分类模型中提升性能的新方法，通过引入生成数据集，模型的准确性得到了显著改善，支持向量机模型的精确度提高了6%，人工神经网络模型的召回率提高了1.5%。

    

    本文提出了一种新颖的方法，通过应用生成式人工智能(AI)来提高二进制代码评论质量分类模型的性能。通过利用OpenAI API，将从各种GitHub仓库和开源项目中提取的1239个新生成的代码-评论对数据集标记为“有用”或“无用”，并与现有的9048个C编程语言对数据集集成。利用先进的大型语言模型架构，生成的数据集在模型准确性方面表现出明显的改善。具体来说，当集成到支持向量机(SVM)模型中时，精确度提高了6%，从0.79增加到0.85。此外，人工神经网络(ANN)模型的召回率提高了1.5%，从0.731增加到0.746。本文揭示了生成式人工智能在增强代码评论质量分类模型中的潜力。

    This paper presents a novel approach to enhance the performance of binary code comment quality classification models through the application of Generative Artificial Intelligence (AI). By leveraging the OpenAI API, a dataset comprising 1239 newly generated code-comment pairs, extracted from various GitHub repositories and open-source projects, has been labelled as "Useful" or "Not Useful", and integrated into the existing corpus of 9048 pairs in the C programming language. Employing a cutting-edge Large Language Model Architecture, the generated dataset demonstrates notable improvements in model accuracy. Specifically, when incorporated into the Support Vector Machine (SVM) model, a 6% increase in precision is observed, rising from 0.79 to 0.85. Additionally, the Artificial Neural Network (ANN) model exhibits a 1.5% increase in recall, climbing from 0.731 to 0.746. This paper sheds light on the potential of Generative AI in augmenting code comment quality classification models. The res
    
[^15]: 会话式金融信息检索模型（ConFIRM）

    Conversational Financial Information Retrieval Model (ConFIRM). (arXiv:2310.13001v1 [cs.IR])

    [http://arxiv.org/abs/2310.13001](http://arxiv.org/abs/2310.13001)

    ConFIRM是一种会话式金融信息检索模型，通过合成金融领域特定问答对和评估参数微调方法，实现了超过90%的准确性，为金融对话系统提供了数据高效的解决方案。

    

    随着大型语言模型（LLM）的指数级增长，利用它们在金融等专门领域的新兴特性具有探索的价值。然而，金融等受监管领域具有独特的约束条件，需要具备针对该领域的优化框架。我们提出了ConFIRM，一种基于LLM的会话式金融信息检索模型，用于查询意图分类和知识库标记。ConFIRM包括两个模块：1）一种合成金融领域特定问答对的方法，以及2）评估参数高效的微调方法来进行查询分类任务。我们生成了一个包含4000多个样本的数据集，并在单独的测试集上评估了准确性。ConFIRM实现了超过90%的准确性，这对于符合监管要求至关重要。ConFIRM提供了一种数据高效的解决方案，用于提取金融对话系统的精确查询意图。

    With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling.  ConFIRM comprises two modules:  1) a method to synthesize finance domain-specific question-answer pairs, and  2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set.  ConFIRM achieved over 90% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.
    
[^16]: 关系相关性增强的文档级关系抽取

    Document-Level Relation Extraction with Relation Correlation Enhancement. (arXiv:2310.13000v1 [cs.IR])

    [http://arxiv.org/abs/2310.13000](http://arxiv.org/abs/2310.13000)

    该论文提出了一种关系图方法，用于解决文档级关系抽取中忽视关系相关性的问题。通过构建关系图、加权处理和利用图注意力网络，可以有效地捕捉文档中关系之间的相关性。该方法可以作为现有模型的模块集成，并在实验中取得了良好的效果。

    

    文档级关系抽取是一项致力于识别文档内实体间关系的任务。然而，现有的文档级关系抽取模型往往忽视了关系之间的相关性，并缺乏对关系相关性的定量分析。为了解决这一问题并有效捕捉文档级关系抽取中的关系相关性，我们提出了一种关系图方法，旨在明确利用关系之间的相互依赖关系。首先，我们构建一个关系图，利用先前的关系知识导出的统计共现信息来建模关系之间的相关性。其次，我们采用重新加权的方法创建一个有效的关系相关性矩阵，以引导关系信息的传播。此外，我们利用图注意力网络来聚合关系嵌入。重要的是，我们的方法可以无缝地作为一个即插即用的模块集成到现有的模型中。实验结果表明，我们的方法可以增强关系抽取的效果。

    Document-level relation extraction (DocRE) is a task that focuses on identifying relations between entities within a document. However, existing DocRE models often overlook the correlation between relations and lack a quantitative analysis of relation correlations. To address this limitation and effectively capture relation correlations in DocRE, we propose a relation graph method, which aims to explicitly exploit the interdependency among relations. Firstly, we construct a relation graph that models relation correlations using statistical co-occurrence information derived from prior relation knowledge. Secondly, we employ a re-weighting scheme to create an effective relation correlation matrix to guide the propagation of relation information. Furthermore, we leverage graph attention networks to aggregate relation embeddings. Importantly, our method can be seamlessly integrated as a plug-and-play module into existing models. Experimental results demonstrate that our approach can enhanc
    
[^17]: 从相关性到实用性: 基于反馈的证据检索在事实验证中的应用

    From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification. (arXiv:2310.11675v1 [cs.IR])

    [http://arxiv.org/abs/2310.11675](http://arxiv.org/abs/2310.11675)

    本论文提出了一种基于反馈的证据检索器(FER)，通过整合声明验证者的反馈来优化事实验证中的证据检索过程。实证研究表明FER优于现有的基准方法。

    

    在事实验证中，检索增强方法已成为主要的方法之一；它需要对多个检索到的证据进行推理，以验证声明的真实性。为了检索证据，现有的方法通常使用基于概率排序原则设计的现成检索模型。我们认为，在事实验证中，我们需要关注的是声明验证者从检索到的证据中获得的实用性，而不是相关性。我们引入了基于反馈的证据检索器（FER），通过整合声明验证者的反馈来优化证据检索过程。作为反馈信号，我们使用验证者有效利用检索到的证据和基准证据之间实用性的差异来产生最终的声明标签。实证研究证明FER优于现有的基准方法。

    Retrieval-enhanced methods have become a primary approach in fact verification (FV); it requires reasoning over multiple retrieved pieces of evidence to verify the integrity of a claim. To retrieve evidence, existing work often employs off-the-shelf retrieval models whose design is based on the probability ranking principle. We argue that, rather than relevance, for FV we need to focus on the utility that a claim verifier derives from the retrieved evidence. We introduce the feedback-based evidence retriever(FER) that optimizes the evidence retrieval process by incorporating feedback from the claim verifier. As a feedback signal we use the divergence in utility between how effectively the verifier utilizes the retrieved evidence and the ground-truth evidence to produce the final claim label. Empirical studies demonstrate the superiority of FER over prevailing baselines.
    
[^18]: 通过自适应的NLP模型选择和基于临床专家规则的分类器改进VTE的识别

    Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports. (arXiv:2309.12273v1 [cs.CL])

    [http://arxiv.org/abs/2309.12273](http://arxiv.org/abs/2309.12273)

    通过自适应的NLP模型选择和临床专家规则的分类器，该研究提出一种改进VTE识别的新方法，在放射学报告中准确识别VTE事件的准确性得到提高。

    

    快速准确地识别静脉血栓栓塞（VTE），包括深静脉血栓（DVT）和肺栓塞（PE），对于有效治疗非常重要。利用自然语言处理（NLP）在放射学报告中，自动化方法已经在从回顾性数据集中识别VTE事件或帮助临床专家识别放射学报告中的VTE事件方面展示了有希望的进展。然而，由于标记有限的医学文本数据、放射学报告的复杂性和异质性以及数据不平衡，有效训练深度学习（DL）和NLP模型存在挑战。本研究提出了DL方法的新的组合方法，结合数据增强、自适应预训练的NLP模型选择和临床专家NLP基于规则的分类器，以提高非结构化（自由文本）放射学报告中VTE识别的准确性。我们的实验结果证明了该模型的有效性。

    Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achievi
    
[^19]: FedDCSR: 通过解缠表示学习实现联邦跨领域顺序推荐

    FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning. (arXiv:2309.08420v1 [cs.LG])

    [http://arxiv.org/abs/2309.08420](http://arxiv.org/abs/2309.08420)

    提出了一种名为FedDCSR的联邦跨领域顺序推荐框架，通过解缠表示学习来处理不同领域之间的序列特征异质性，并保护数据隐私。

    

    近年来，利用来自多个领域的用户序列数据的跨领域顺序推荐(CSR)受到了广泛关注。然而，现有的CSR方法需要在领域之间共享原始用户数据，这违反了《通用数据保护条例》(GDPR)。因此，有必要将联邦学习(FL)和CSR相结合，充分利用不同领域的知识，同时保护数据隐私。然而，不同领域之间的序列特征异质性对FL的整体性能有显著影响。在本文中，我们提出了FedDCSR，这是一种通过解缠表示学习的新型联邦跨领域顺序推荐框架。具体而言，为了解决不同领域之间的序列特征异质性，我们引入了一种称为领域内-领域间序列表示解缠(SRD)的方法，将用户序列特征解缠成领域共享和领域专属特征。

    Cross-domain Sequential Recommendation (CSR) which leverages user sequence data from multiple domains has received extensive attention in recent years. However, the existing CSR methods require sharing origin user data across domains, which violates the General Data Protection Regulation (GDPR). Thus, it is necessary to combine federated learning (FL) and CSR to fully utilize knowledge from different domains while preserving data privacy. Nonetheless, the sequence feature heterogeneity across different domains significantly impacts the overall performance of FL. In this paper, we propose FedDCSR, a novel federated cross-domain sequential recommendation framework via disentangled representation learning. Specifically, to address the sequence feature heterogeneity across domains, we introduce an approach called inter-intra domain sequence representation disentanglement (SRD) to disentangle the user sequence features into domain-shared and domain-exclusive features. In addition, we design
    
[^20]: 多关系对比学习用于推荐系统

    Multi-Relational Contrastive Learning for Recommendation. (arXiv:2309.01103v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2309.01103](http://arxiv.org/abs/2309.01103)

    本论文介绍了一种多关系对比学习框架（RCL），用于解决个性化推荐系统中单一行为学习的限制。RCL模型通过多关系图编码器捕捉短期偏好的异质性，并使用动态跨关系记忆网络来捕捉用户的长期多行为模式。

    

    个性化推荐系统在捕捉用户随时间变化的偏好、提供准确有效的推荐方面起着至关重要的作用。然而，许多推荐模型只依赖于一种行为学习，这限制了它们在真实场景中表示用户和物品之间复杂关系的能力。在这种情况下，用户以多种方式与物品互动，包括点击、标记为喜爱、评论和购买。为了解决这个问题，我们提出了关系感知对比学习（RCL）框架，它有效地建模动态交互异质性。RCL模型包括一个多关系图编码器，捕捉短期偏好的异质性，同时保留不同类型用户-物品交互的专用关系语义。此外，我们设计了一个动态跨关系记忆网络，使RCL模型能够捕捉用户的长期多行为模式。

    Personalized recommender systems play a crucial role in capturing users' evolving preferences over time to provide accurate and effective recommendations on various online platforms. However, many recommendation models rely on a single type of behavior learning, which limits their ability to represent the complex relationships between users and items in real-life scenarios. In such situations, users interact with items in multiple ways, including clicking, tagging as favorite, reviewing, and purchasing. To address this issue, we propose the Relation-aware Contrastive Learning (RCL) framework, which effectively models dynamic interaction heterogeneity. The RCL model incorporates a multi-relational graph encoder that captures short-term preference heterogeneity while preserving the dedicated relation semantics for different types of user-item interactions. Moreover, we design a dynamic cross-relational memory network that enables the RCL model to capture users' long-term multi-behavior p
    
[^21]: Jina Embeddings:一种新颖的高性能句子嵌入模型

    Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v1 [cs.CL])

    [http://arxiv.org/abs/2307.11224](http://arxiv.org/abs/2307.11224)

    Jina Embeddings是一组高性能的句子嵌入模型，能够捕捉文本的语义本质。该论文详细介绍了Jina Embeddings的开发过程，并通过性能评估验证了其优越性能。

    

    Jina Embeddings由一组高性能的句子嵌入模型组成，能够将各种文本输入转化为数值表示，从而捕捉文本的语义本质。虽然这些模型并非专门设计用于文本生成，但在密集检索和语义文本相似性等应用中表现出色。本文详细介绍了Jina Embeddings的开发过程，从创建高质量的成对和三元数据集开始。它强调了数据清理在数据集准备中的关键作用，并对模型训练过程进行了深入探讨，最后利用Massive Textual Embedding Benchmark（MTEB）进行了全面的性能评估。

    Jina Embeddings constitutes a set of high-performance sentence embedding models adept at translating various textual inputs into numerical representations, thereby capturing the semantic essence of the text. While these models are not exclusively designed for text generation, they excel in applications such as dense retrieval and semantic textual similarity. This paper details the development of Jina Embeddings, starting with the creation of a high-quality pairwise and triplet dataset. It underlines the crucial role of data cleaning in dataset preparation, gives in-depth insights into the model training process, and concludes with a comprehensive performance evaluation using the Massive Textual Embedding Benchmark (MTEB).
    
[^22]: GPT4Table：大型语言模型能理解结构化表格数据吗？一项基准测试和实证研究

    GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13062](http://arxiv.org/abs/2305.13062)

    本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。

    

    大型语言模型（LLMs）作为少样本推理器来解决与自然语言相关的任务越来越具吸引力。然而，关于LLMs对结构化数据（例如表格）的理解程度还有很多需要学习的地方。尽管可以使用表格序列化作为LLMs的输入，但目前还缺乏对LLMs是否真正能够理解这类数据的全面研究。本文通过设计一个基准测试来评估LLMs的结构理解能力（SUC）来解决这个问题。我们创建的基准测试包括七个任务，每个任务都有其独特的挑战，例如单元格查找、行检索和大小检测。我们对GPT-3.5和GPT-4进行了一系列评估。我们发现性能因多种输入选择而异，包括表格输入格式、内容顺序、角色提示和分区标记等。根据基准测试评估所得的见解，我们提出了“自我增强”技术以改善性能。

    Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. While it is true that tables can be used as inputs to LLMs with serialization, there lack of comprehensive studies examining whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, \eg, cell lookup, row retrieval, and size detection. We run a series of evaluations on GPT-3.5 and GPT-4. We discover that the performance varied depending on a number of input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we then propose \textit{self-augmentation} for effect
    
[^23]: 大型语言模型了解您的上下文搜索意图：用于会话搜索的提示框架

    Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search. (arXiv:2303.06573v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06573](http://arxiv.org/abs/2303.06573)

    本论文提出了一个提示框架，利用大型语言模型作为文本搜索意图解释器来帮助会话搜索。通过探索三种提示方法，从而生成多个查询重写和假设性回复，并将它们聚合成一个集成表示以表示用户的真实上下文搜索意图。

    

    准确理解用户的上下文搜索意图对于会话搜索而言是一个重要的挑战。由于对话搜索会话的多样性和长尾性，现有的基于有限数据训练的方法在处理真实的会话搜索场景时仍然显示出不令人满意的效果和鲁棒性。最近，大型语言模型（LLM）展示了令人惊叹的文本生成和对话理解能力。在这项工作中，我们提出了一个简单但有效的提示框架，名为LLM4CS，利用LLM作为基于文本的搜索意图解释器来帮助会话搜索。在该框架下，我们探索了三种提示方法来生成多个查询重写和假设性回复，并提议将它们聚合到一个集成表示中，这可以稳健地表示用户的真实上下文搜索意图。在三个广泛使用的会话搜索基准测试上进行了广泛的自动评估和人工评估。

    Precisely understanding users' contextual search intent has been an important challenge for conversational search. As conversational search sessions are much more diverse and long-tailed, existing methods trained on limited data still show unsatisfactory effectiveness and robustness to handle real conversational search scenarios. Recently, large language models (LLMs) have demonstrated amazing capabilities for text generation and conversation understanding. In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search. Under this framework, we explore three prompting methods to generate multiple query rewrites and hypothetical responses, and propose to aggregate them into an integrated representation that can robustly represent the user's real contextual search intent. Extensive automatic evaluations and human evaluations on three widely used conversational search benchmarks, 
    
[^24]: 一个基于挑战的电子招聘推荐系统调查

    A challenge-based survey of e-recruitment recommendation systems. (arXiv:2209.05112v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2209.05112](http://arxiv.org/abs/2209.05112)

    这篇论文提供了一个基于挑战的电子招聘推荐系统调查，该调查以实用性为导向，适用于面临具体招聘设计任务和挑战的开发人员。

    

    电子招聘推荐系统会为求职者推荐工作，也会为招聘者推荐求职者。推荐是根据求职者适合职位以及求职者和招聘者的偏好生成的。因此，电子招聘推荐系统对求职者的职业发展有着重要影响。此外，通过影响公司的招聘流程，电子招聘推荐系统在塑造公司在市场的竞争优势方面扮演着重要角色。因此，电子招聘推荐领域值得特别关注。现有的调查往往从算法的角度讨论过去的研究，例如将它们分为协同过滤、基于内容和混合方法。而这项调查则采取了一个互补的、基于挑战的方法，我们认为这对于面临具体招聘设计任务和一系列具体挑战的开发人员更加实用。

    E-recruitment recommendation systems recommend jobs to job seekers and job seekers to recruiters. The recommendations are generated based on the suitability of the job seekers for the positions as well as the job seekers' and the recruiters' preferences. Therefore, e-recruitment recommendation systems could greatly impact job seekers' careers. Moreover, by affecting the hiring processes of the companies, e-recruitment recommendation systems play an important role in shaping the companies' competitive edge in the market. Hence, the domain of e-recruitment recommendation deserves specific attention. Existing surveys on this topic tend to discuss past studies from the algorithmic perspective, e.g., by categorizing them into collaborative filtering, content based, and hybrid methods. This survey, instead, takes a complementary, challenge-based approach, which we believe might be more practical to developers facing a concrete e-recruitment design task with a specific set of challenges, as w
    

