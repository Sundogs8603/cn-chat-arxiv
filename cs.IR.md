# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DeepSRGM -- Sequence Classification and Ranking in Indian Classical Music with Deep Learning](https://arxiv.org/abs/2402.10168) | DeepSRGM是一种基于深度学习的Raga识别方法，通过使用LSTM-RNN学习音乐数据中的时间序列，达到了88.1%和97%的准确率，在Raga识别任务中取得了最新技术的地位。 |
| [^2] | [PICS: Pipeline for Image Captioning and Search](https://arxiv.org/abs/2402.10090) | PICS是一种用于图像描述和搜索的流水线，它利用了大型语言模型的进展来自动化图像描述的过程，并通过集成情感分析来增强元数据，从而提高了大规模图像库的搜索效率和访问性。 |
| [^3] | [Self-Augmented In-Context Learning for Unsupervised Word Translation](https://arxiv.org/abs/2402.10024) | 通过自学习上下文增强方法，本论文提出一种无监督词汇翻译的方法，在零样本提示的大型语言模型上取得了显著的改进，超过了传统基于映射的方法。 |
| [^4] | [LLM-based Federated Recommendation](https://arxiv.org/abs/2402.09959) | 这项研究介绍了一种基于LLM的联邦推荐系统，用于提高推荐系统的性能和隐私保护。面临的挑战是客户端性能不平衡和对计算资源的高需求。 |
| [^5] | [Generative AI in the Construction Industry: A State-of-the-art Analysis](https://arxiv.org/abs/2402.09939) | 本研究通过分析提供了建筑行业中生成式AI的最新状态、机遇和挑战。同时，提出了一个帮助建筑公司构建定制化生成式AI解决方案的框架。 |
| [^6] | [Sequential Recommendation on Temporal Proximities with Contrastive Learning and Self-Attention](https://arxiv.org/abs/2402.09784) | 该论文基于对比学习和自注意力机制，提出了一种考虑垂直和水平时间接近度的顺序推荐方法，以更好地捕捉用户-项目交互中的时间上下文。 |
| [^7] | [From Variability to Stability: Advancing RecSys Benchmarking Practices](https://arxiv.org/abs/2402.09766) | 本论文提出了一种新的基准测试方法，通过使用多样化的开放数据集，并在多个度量指标上评估多种协同过滤算法，来研究数据集特征对算法性能的影响。这一方法填补了推荐系统算法比较中的不足之处，推进了评估实践。 |
| [^8] | [Grounding Language Model with Chunking-Free In-Context Retrieval](https://arxiv.org/abs/2402.09760) | 这是一种针对检索增强生成系统（RAG）的无块语境检索方法，通过绕过文本切分的过程，利用编码隐藏状态进行准确地语境检索，解决了传统方法中存在的文本语义连贯性破坏和证据检索中的噪声和不准确性问题。 |
| [^9] | [POBEVM: Real-time Video Matting via Progressively Optimize the Target Body and Edge](https://arxiv.org/abs/2402.09731) | POBEVM 是一种实时视频抠像方法，通过逐步优化目标主体和边缘，解决了当前方法中处理目标边缘的模糊和不正确问题，并提出了一种无需修剪图的视频抠像方法，取得了显著的预测目标边缘改进。 |
| [^10] | [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727) | ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。 |
| [^11] | [User Modeling and User Profiling: A Comprehensive Survey](https://arxiv.org/abs/2402.09660) | 这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。 |
| [^12] | [LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations](https://arxiv.org/abs/2402.09617) | 这项研究旨在提高LLM在图数据中的关系挖掘效率和能力，通过整合图神经网络和大型语言模型，以利用边缘信息来理解复杂节点关系，并从图结构中提取有意义洞见。 |
| [^13] | [Rethinking Large Language Model Architectures for Sequential Recommendations](https://arxiv.org/abs/2402.09543) | 本文提出了一种名为Lite-LLM4Rec的简化的基于LLM的推荐模型，旨在实现顺序推荐任务的高效推理。Lite-LLM4Rec通过使用直接项目投影头来生成排名分数，避免了波束搜索解码，同时引入了自适应截断机制以提高推理效率。 |
| [^14] | [Intersectional Two-sided Fairness in Recommendation](https://arxiv.org/abs/2402.02816) | 本文针对推荐系统中的交叉双边公平性问题，提出了一种名为交叉双边公平推荐（ITFR）的新方法，通过利用锐度感知损失感知劣势群体，使用协作损失平衡开发不同交叉群体的一致区分能力，并利用预测得分归一化来公平对待不同交叉群体中的正例。实验证明该方法在提高交叉双边公平性方面取得了显著效果。 |
| [^15] | [On-Device Recommender Systems: A Comprehensive Survey](https://arxiv.org/abs/2401.11441) | 该论文综述了传统的云推荐系统（CloudRSs）与基于设备的推荐系统（DeviceRSs）之间的区别和优势，并提出了利用边缘设备的存储、通信和计算能力来解决资源消耗、响应延迟以及隐私和安全风险的方法。 |
| [^16] | [When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm.](http://arxiv.org/abs/2306.02552) | 从事用户行为分析的学术界一直面临着收集足够高质量用户行为数据的难题，一种解决方案是自动模拟用户行为，近期研究表明，利用大语言模型进行可靠的用户模拟有了重要的突破，将这种模型应用到用户行为分析研究中有着巨大潜力，可能对传统研究范式产生革命性影响。 |
| [^17] | [DAPR: A Benchmark on Document-Aware Passage Retrieval.](http://arxiv.org/abs/2305.13915) | DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。 |
| [^18] | [Utilizing Human Memory Processes to Model Genre Preferences for Personalized Music Recommendations.](http://arxiv.org/abs/2003.10699) | 本文基于心理学模型，利用人类记忆过程来模拟和预测不同用户群体的音乐类型偏好。通过分析超过十亿条音乐收听记录数据集，发现该方法对于不同用户群体的预测准确性显著优于其他基准算法，并且具有透明和可解释性的特点。 |

# 详细

[^1]: DeepSRGM -- 基于深度学习的印度古典音乐中的序列分类和排序

    DeepSRGM -- Sequence Classification and Ranking in Indian Classical Music with Deep Learning

    [https://arxiv.org/abs/2402.10168](https://arxiv.org/abs/2402.10168)

    DeepSRGM是一种基于深度学习的Raga识别方法，通过使用LSTM-RNN学习音乐数据中的时间序列，达到了88.1%和97%的准确率，在Raga识别任务中取得了最新技术的地位。

    

    《arXiv:2402.10168v1 公告类型: 交叉》 摘要：印度古典音乐(ICM)的一个重要方面是Raga，它作为作曲和即兴演奏的旋律框架。Raga的识别是ICM中一项重要的音乐信息检索任务，它可以帮助从音乐推荐到组织大型音乐收藏等多种下游应用。在这项工作中，我们提出了一种基于深度学习的Raga识别方法。我们的方法采用有效的预处理，使用基于长短期记忆(LSTM)的递归神经网络(RNN)学习音乐数据中的时间序列。我们在采样自原始音频的较小序列上进行网络的训练和测试，而最终的推理则是在整个音频上进行的。我们的方法在Comp Music Carnatic数据集和其10个Raga子集上的推理过程中分别达到了88.1%和97%的准确率，使其成为Raga识别任务的最新技术。我们的方法还使序列排序成为可能。

    arXiv:2402.10168v1 Announce Type: cross  Abstract: A vital aspect of Indian Classical Music (ICM) is Raga, which serves as a melodic framework for compositions and improvisations alike. Raga Recognition is an important music information retrieval task in ICM as it can aid numerous downstream applications ranging from music recommendations to organizing huge music collections. In this work, we propose a deep learning based approach to Raga recognition. Our approach employs efficient pre possessing and learns temporal sequences in music data using Long Short Term Memory based Recurrent Neural Networks (LSTM-RNN). We train and test the network on smaller sequences sampled from the original audio while the final inference is performed on the audio as a whole. Our method achieves an accuracy of 88.1% and 97 % during inference on the Comp Music Carnatic dataset and its 10 Raga subset respectively making it the state-of-the-art for the Raga recognition task. Our approach also enables sequence
    
[^2]: PICS: 图像描述和搜索的流水线

    PICS: Pipeline for Image Captioning and Search

    [https://arxiv.org/abs/2402.10090](https://arxiv.org/abs/2402.10090)

    PICS是一种用于图像描述和搜索的流水线，它利用了大型语言模型的进展来自动化图像描述的过程，并通过集成情感分析来增强元数据，从而提高了大规模图像库的搜索效率和访问性。

    

    数字图像的增长使得高效分类和检索的先进系统成为必需，这在数据库管理和信息检索中提出了重大挑战。本文介绍了PICS（图像描述和搜索的流水线），这是一种旨在解决组织大规模图像库中固有复杂性的新方法。PICS利用了大型语言模型（LLM）的进展，自动化图像描述的过程，提供一个超越传统手动注释方法的解决方案。该方法基于这样的认识，即有意义的，人工智能生成的描述能够显著改善大型数据库中图像的可搜索性和可访问性。通过将情感分析整合到流水线中，PICS进一步丰富了元数据，实现了超越基本描述符的细致搜索。这种方法不仅简化了管理大规模数据库的任务，同时提高了图像的检索效率。

    arXiv:2402.10090v1 Announce Type: cross  Abstract: The growing volume of digital images necessitates advanced systems for efficient categorization and retrieval, presenting a significant challenge in database management and information retrieval. This paper introduces PICS (Pipeline for Image Captioning and Search), a novel approach designed to address the complexities inherent in organizing large-scale image repositories. PICS leverages the advancements in Large Language Models (LLMs) to automate the process of image captioning, offering a solution that transcends traditional manual annotation methods. The approach is rooted in the understanding that meaningful, AI-generated captions can significantly enhance the searchability and accessibility of images in large databases. By integrating sentiment analysis into the pipeline, PICS further enriches the metadata, enabling nuanced searches that extend beyond basic descriptors. This methodology not only simplifies the task of managing vas
    
[^3]: 自学习上下文增强对于无监督词汇翻译的研究

    Self-Augmented In-Context Learning for Unsupervised Word Translation

    [https://arxiv.org/abs/2402.10024](https://arxiv.org/abs/2402.10024)

    通过自学习上下文增强方法，本论文提出一种无监督词汇翻译的方法，在零样本提示的大型语言模型上取得了显著的改进，超过了传统基于映射的方法。

    

    近期的研究表明，尽管大型语言模型在一些小规模的设置中展示出了较强的词汇翻译和双语词典诱导(BLI)的能力，但在无监督的情况下，即没有种子翻译对可用的情况下，尤其是对于资源较少的语言，它们仍然无法达到“传统”的基于映射的方法的性能。为了解决这个挑战，我们提出了一种自学习上下文增强方法 (SAIL) 来进行无监督的BLI：从零样本提示开始，SAIL通过迭代地从LLM中引出一组高置信度的词汇翻译对，然后在ICL的方式下再次应用于同一个LLM中。我们的方法在两个广泛的BLI基准测试中，跨越多种语言对，在零样本提示的LLM上取得了显著的改进，也在各个方面优于基于映射的基线。除了达到最先进的无监督

    arXiv:2402.10024v1 Announce Type: cross  Abstract: Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of 'traditional' mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages. To address this challenge with LLMs, we propose self-augmented in-context learning (SAIL) for unsupervised BLI: starting from a zero-shot prompt, SAIL iteratively induces a set of high-confidence word translation pairs for in-context learning (ICL) from an LLM, which it then reapplies to the same LLM in the ICL fashion. Our method shows substantial gains over zero-shot prompting of LLMs on two established BLI benchmarks spanning a wide range of language pairs, also outperforming mapping-based baselines across the board. In addition to achieving state-of-the-art unsupervised 
    
[^4]: 基于LLM的联邦推荐系统

    LLM-based Federated Recommendation

    [https://arxiv.org/abs/2402.09959](https://arxiv.org/abs/2402.09959)

    这项研究介绍了一种基于LLM的联邦推荐系统，用于提高推荐系统的性能和隐私保护。面临的挑战是客户端性能不平衡和对计算资源的高需求。

    

    大规模语言模型（LLM）通过微调方法展示了改进推荐系统的巨大潜力，具备先进的上下文理解能力。然而，微调需要用户行为数据，这会带来隐私风险，因为包含了敏感用户信息。这些数据的意外泄露可能侵犯数据保护法，并引发伦理问题。为了减轻这些隐私问题，联邦学习推荐系统（Fed4Rec）被提出作为一种有前景的方法。然而，将Fed4Rec应用于基于LLM的推荐系统面临两个主要挑战：首先，客户端性能不平衡加剧，影响系统的效率；其次，对于本地训练和推理LLM，对客户端的计算和存储资源需求很高。

    arXiv:2402.09959v1 Announce Type: new  Abstract: Large Language Models (LLMs), with their advanced contextual understanding abilities, have demonstrated considerable potential in enhancing recommendation systems via fine-tuning methods. However, fine-tuning requires users' behavior data, which poses considerable privacy risks due to the incorporation of sensitive user information. The unintended disclosure of such data could infringe upon data protection laws and give rise to ethical issues. To mitigate these privacy issues, Federated Learning for Recommendation (Fed4Rec) has emerged as a promising approach. Nevertheless, applying Fed4Rec to LLM-based recommendation presents two main challenges: first, an increase in the imbalance of performance across clients, affecting the system's efficiency over time, and second, a high demand on clients' computational and storage resources for local training and inference of LLMs.   To address these challenges, we introduce a Privacy-Preserving LL
    
[^5]: 建筑行业中的生成式人工智能：一项最新分析

    Generative AI in the Construction Industry: A State-of-the-art Analysis

    [https://arxiv.org/abs/2402.09939](https://arxiv.org/abs/2402.09939)

    本研究通过分析提供了建筑行业中生成式AI的最新状态、机遇和挑战。同时，提出了一个帮助建筑公司构建定制化生成式AI解决方案的框架。

    

    建筑行业是全球经济中至关重要的一个部门，但在设计、规划、采购、检查和维护等各个环节中面临着许多生产力挑战。生成式人工智能（AI）可以基于某些输入或先前的知识创造新颖且逼真的数据或内容，如文本、图像、视频或代码，为解决这些挑战提供了创新和颠覆性的解决方案。然而，在关于建筑行业中生成式AI的当前状态、机遇和挑战的文献中存在着空白。本研究旨在通过提供建筑领域生成式AI的最新分析来填补这一空缺，研究目标包括：（1）对建筑行业现有和新兴的生成式AI机遇和挑战进行回顾和分类；（2）提出一个框架，帮助建筑公司利用自己的数据和需求构建定制化的生成式AI解决方案。

    arXiv:2402.09939v1 Announce Type: new  Abstract: The construction industry is a vital sector of the global economy, but it faces many productivity challenges in various processes, such as design, planning, procurement, inspection, and maintenance. Generative artificial intelligence (AI), which can create novel and realistic data or content, such as text, image, video, or code, based on some input or prior knowledge, offers innovative and disruptive solutions to address these challenges. However, there is a gap in the literature on the current state, opportunities, and challenges of generative AI in the construction industry. This study aims to fill this gap by providing a state-of-the-art analysis of generative AI in construction, with three objectives: (1) to review and categorize the existing and emerging generative AI opportunities and challenges in the construction industry; (2) to propose a framework for construction firms to build customized generative AI solutions using their ow
    
[^6]: 基于对比学习和自注意力的时间接近度上的顺序推荐

    Sequential Recommendation on Temporal Proximities with Contrastive Learning and Self-Attention

    [https://arxiv.org/abs/2402.09784](https://arxiv.org/abs/2402.09784)

    该论文基于对比学习和自注意力机制，提出了一种考虑垂直和水平时间接近度的顺序推荐方法，以更好地捕捉用户-项目交互中的时间上下文。

    

    传统的基于深度学习和最新的基于Transformer的模型在先前的研究中捕捉了用户-项目交互中的单向和双向模式，但对于时间上下文的重要性，如个体行为和社会趋势模式，仍未得到很好的探索。最近的模型通常忽略了在类似的时间段内隐含在用户之间发生的用户行为的相似性，我们将其称为垂直时间接近度。这些模型主要通过适应Transformer的自注意机制来考虑用户行为中的时间上下文。同时，这种适应在考虑项目交互中的水平时间接近度方面仍然有限，例如区分在一周内与一个月内购买的连续项目。

    arXiv:2402.09784v1 Announce Type: cross  Abstract: Sequential recommender systems identify user preferences from their past interactions to predict subsequent items optimally. Although traditional deep-learning-based models and modern transformer-based models in previous studies capture unidirectional and bidirectional patterns within user-item interactions, the importance of temporal contexts, such as individual behavioral and societal trend patterns, remains underexplored. Notably, recent models often neglect similarities in users' actions that occur implicitly among users during analogous timeframes-a concept we term vertical temporal proximity. These models primarily adapt the self-attention mechanisms of the transformer to consider the temporal context in individual user actions. Meanwhile, this adaptation still remains limited in considering the horizontal temporal proximity within item interactions, like distinguishing between subsequent item purchases within a week versus a mon
    
[^7]: 从变动性到稳定性：推荐系统基准化实践的进展

    From Variability to Stability: Advancing RecSys Benchmarking Practices

    [https://arxiv.org/abs/2402.09766](https://arxiv.org/abs/2402.09766)

    本论文提出了一种新的基准测试方法，通过使用多样化的开放数据集，并在多个度量指标上评估多种协同过滤算法，来研究数据集特征对算法性能的影响。这一方法填补了推荐系统算法比较中的不足之处，推进了评估实践。

    

    在快速发展的推荐系统领域中，新的算法经常通过对一组有限的任意选择的数据集进行评估来声称自己具有最先进的性能。然而，由于数据集特征对算法性能有重大影响，这种方法可能无法全面反映它们的有效性。为了解决这个问题，本文引入了一种新的基准测试方法，以促进公平和稳健的推荐系统算法比较，从而推进评估实践。通过利用包括本文介绍的两个数据集在内的30个开放数据集，并在9个度量指标上评估11种协同过滤算法，我们对数据集特征对算法性能的影响进行了重要的研究。我们进一步研究了将多个数据集的结果聚合成一个统一排名的可行性。通过严格的实验分析，我们发现......

    arXiv:2402.09766v1 Announce Type: cross  Abstract: In the rapidly evolving domain of Recommender Systems (RecSys), new algorithms frequently claim state-of-the-art performance based on evaluations over a limited set of arbitrarily selected datasets. However, this approach may fail to holistically reflect their effectiveness due to the significant impact of dataset characteristics on algorithm performance. Addressing this deficiency, this paper introduces a novel benchmarking methodology to facilitate a fair and robust comparison of RecSys algorithms, thereby advancing evaluation practices. By utilizing a diverse set of $30$ open datasets, including two introduced in this work, and evaluating $11$ collaborative filtering algorithms across $9$ metrics, we critically examine the influence of dataset characteristics on algorithm performance. We further investigate the feasibility of aggregating outcomes from multiple datasets into a unified ranking. Through rigorous experimental analysis, 
    
[^8]: 无块语境检索的语言模型 grounding

    Grounding Language Model with Chunking-Free In-Context Retrieval

    [https://arxiv.org/abs/2402.09760](https://arxiv.org/abs/2402.09760)

    这是一种针对检索增强生成系统（RAG）的无块语境检索方法，通过绕过文本切分的过程，利用编码隐藏状态进行准确地语境检索，解决了传统方法中存在的文本语义连贯性破坏和证据检索中的噪声和不准确性问题。

    

    本论文介绍了一种针对检索增强生成（RAG）系统的无块语境（CFIC）检索方法。传统的RAG系统在使用精确证据文本进行 grounding 时往往面临处理冗长文档和过滤无关内容的挑战。常用的解决方案，如文档切分和调整语言模型以处理更长的上下文，都存在局限性。这些方法要么破坏了文本的语义连贯性，要么未能有效解决证据检索中的噪声和不准确性问题。CFIC通过绕过传统的切分过程来应对这些挑战。它利用文档的编码隐藏状态进行语境检索，在对用户查询进行自回归解码时准确地识别出所需的具体证据文本，消除了切分的需求。CFIC 进一步。。。

    arXiv:2402.09760v1 Announce Type: cross  Abstract: This paper presents a novel Chunking-Free In-Context (CFIC) retrieval approach, specifically tailored for Retrieval-Augmented Generation (RAG) systems. Traditional RAG systems often struggle with grounding responses using precise evidence text due to the challenges of processing lengthy documents and filtering out irrelevant content. Commonly employed solutions, such as document chunking and adapting language models to handle longer contexts, have their limitations. These methods either disrupt the semantic coherence of the text or fail to effectively address the issues of noise and inaccuracy in evidence retrieval.   CFIC addresses these challenges by circumventing the conventional chunking process. It utilizes the encoded hidden states of documents for in-context retrieval, employing auto-aggressive decoding to accurately identify the specific evidence text required for user queries, eliminating the need for chunking. CFIC is further
    
[^9]: POBEVM: 实时视频抠像通过逐步优化目标主体和边缘

    POBEVM: Real-time Video Matting via Progressively Optimize the Target Body and Edge

    [https://arxiv.org/abs/2402.09731](https://arxiv.org/abs/2402.09731)

    POBEVM 是一种实时视频抠像方法，通过逐步优化目标主体和边缘，解决了当前方法中处理目标边缘的模糊和不正确问题，并提出了一种无需修剪图的视频抠像方法，取得了显著的预测目标边缘改进。

    

    基于深度卷积神经网络（CNN）的方法在视频抠像方面取得了很好的性能。许多这些方法可以为目标主体产生准确的 alpha 估计，但通常会生成模糊或不正确的目标边缘。这通常是由以下原因引起的：1）当前的方法总是不加区分地处理目标主体和边缘；2）目标主体在整个目标中占据了主导地位，只有很小的比例是目标边缘。针对第一个问题，我们提出了一个基于CNN的模块，分别优化抠像的目标主体和边缘（SOBE）。基于此，我们引入了一种实时、无需修剪图的视频抠像方法——POBEVM，相比之前的方法它更轻量级，并在预测的目标边缘方面取得了显著改进。针对第二个问题，我们提出了一个边缘L1损失（ELL）函数，强制将我们的网络应用于抠像的目标主体.

    arXiv:2402.09731v1 Announce Type: cross  Abstract: Deep convolutional neural networks (CNNs) based approaches have achieved great performance in video matting. Many of these methods can produce accurate alpha estimation for the target body but typically yield fuzzy or incorrect target edges. This is usually caused by the following reasons: 1) The current methods always treat the target body and edge indiscriminately; 2) Target body dominates the whole target with only a tiny proportion target edge. For the first problem, we propose a CNN-based module that separately optimizes the matting target body and edge (SOBE). And on this basis, we introduce a real-time, trimap-free video matting method via progressively optimizing the matting target body and edge (POBEVM) that is much lighter than previous approaches and achieves significant improvements in the predicted target edge. For the second problem, we propose an Edge-L1-Loss (ELL) function that enforces our network on the matting target
    
[^10]: 一种具有长期上下文概要记忆的人工智能阅读代理

    A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts

    [https://arxiv.org/abs/2402.09727](https://arxiv.org/abs/2402.09727)

    ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。

    

    当前的大型语言模型不仅限制在某个最大上下文长度内，而且无法稳定地处理长输入。为了解决这些限制，我们提出了ReadAgent，一个增加了有效上下文长度的语言模型代理系统，在我们的实验中可以达到20倍。受到人类交互式阅读长文档的启发，我们将ReadAgent实现为一个简单的提示系统，利用LLM的高级语言能力来：（1）决定将哪些内容存储在一个记忆片段中，（2）将这些记忆片段压缩成为称为概要记忆的短时记忆，（3）在需要时通过原始文本查找段落来提醒自己相关细节以完成任务。我们使用检索方法、使用原始长上下文以及使用概要记忆来评估ReadAgent与基线的性能。这些评估是在三个长文档阅读理解任务上进行的。

    arXiv:2402.09727v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension task
    
[^11]: 用户建模与用户画像：综述

    User Modeling and User Profiling: A Comprehensive Survey

    [https://arxiv.org/abs/2402.09660](https://arxiv.org/abs/2402.09660)

    这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。

    

    人工智能（AI）融入日常生活，特别是通过信息检索和推荐系统，已经促使先进的用户建模和用户画像技术，以提供个性化体验。这些技术旨在基于与这些系统的互动中生成的大量数据构建准确的用户表示。本文对用户建模和用户画像研究的现状、发展和未来方向进行了全面综述。我们提供了一个历史概述，追溯了从早期的刻板模型到最新的深度学习技术，并提出了一个新的分类体系，涵盖了这一研究领域中的所有活动主题，包括最近的趋势。我们的综述突出了向更复杂的用户画像方法的范式转变，强调了隐式数据收集、多行为建模以及图数据的整合。

    arXiv:2402.09660v1 Announce Type: new  Abstract: The integration of artificial intelligence (AI) into daily life, particularly through information retrieval and recommender systems, has necessitated advanced user modeling and profiling techniques to deliver personalized experiences. These techniques aim to construct accurate user representations based on the rich amounts of data generated through interactions with these systems. This paper presents a comprehensive survey of the current state, evolution, and future directions of user modeling and profiling research. We provide a historical overview, tracing the development from early stereotype models to the latest deep learning techniques, and propose a novel taxonomy that encompasses all active topics in this research area, including recent trends. Our survey highlights the paradigm shifts towards more sophisticated user profiling methods, emphasizing implicit data collection, multi-behavior modeling, and the integration of graph data
    
[^12]: 增强LLM用户-物品交互：利用边缘信息进行优化推荐的研究

    LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations

    [https://arxiv.org/abs/2402.09617](https://arxiv.org/abs/2402.09617)

    这项研究旨在提高LLM在图数据中的关系挖掘效率和能力，通过整合图神经网络和大型语言模型，以利用边缘信息来理解复杂节点关系，并从图结构中提取有意义洞见。

    

    大型语言模型的出色性能不仅改变了自然语言处理领域的研究格局，还展示了它在各个领域的卓越应用潜力。然而，这些模型在挖掘图数据中的关系方面的潜力仍未得到充分探索。图神经网络作为近年来热门的研究领域，在关系挖掘方面有大量研究。然而，当前图神经网络的尖端研究尚未有效整合大型语言模型，导致在图关系挖掘任务中的效率和能力受限。一个主要的挑战是LLM无法深入利用图中的边缘信息，而这对于理解复杂节点关系至关重要。这种差距限制了LLM从图结构中提取有意义洞见的潜力，限制了它在更复杂的基于图的分析中的适用性。

    arXiv:2402.09617v1 Announce Type: new  Abstract: The extraordinary performance of large language models has not only reshaped the research landscape in the field of NLP but has also demonstrated its exceptional applicative potential in various domains. However, the potential of these models in mining relationships from graph data remains under-explored. Graph neural networks, as a popular research area in recent years, have numerous studies on relationship mining. Yet, current cutting-edge research in graph neural networks has not been effectively integrated with large language models, leading to limited efficiency and capability in graph relationship mining tasks. A primary challenge is the inability of LLMs to deeply exploit the edge information in graphs, which is critical for understanding complex node relationships. This gap limits the potential of LLMs to extract meaningful insights from graph structures, limiting their applicability in more complex graph-based analysis. We focus
    
[^13]: 重新思考用于顺序推荐的大型语言模型架构

    Rethinking Large Language Model Architectures for Sequential Recommendations

    [https://arxiv.org/abs/2402.09543](https://arxiv.org/abs/2402.09543)

    本文提出了一种名为Lite-LLM4Rec的简化的基于LLM的推荐模型，旨在实现顺序推荐任务的高效推理。Lite-LLM4Rec通过使用直接项目投影头来生成排名分数，避免了波束搜索解码，同时引入了自适应截断机制以提高推理效率。

    

    最近，顺序推荐已经被适应到了LLM范式中，以享受LLM的强大能力。基于LLM的方法通常将推荐信息转化为自然语言，模型被训练成以自回归方式预测下一个项目。尽管它们取得了显著的成功，但是推理的巨大计算开销对于其在实际应用中的可行性构成了重大障碍。在这项工作中，我们努力简化现有的基于LLM的推荐模型，并提出了一种简单而高效的模型Lite-LLM4Rec。Lite-LLM4Rec的主要目标是实现顺序推荐任务的高效推理。Lite-LLM4Rec通过使用直接项目投影头来生成排名分数，避免了波束搜索解码。这个设计源于我们的经验观察，即波束搜索解码对于顺序推荐实际上是不必要的。此外，Lite-LLM4Rec还引入了解码时长的自适应截断机制，以进一步提高推理效率。

    arXiv:2402.09543v1 Announce Type: new  Abstract: Recently, sequential recommendation has been adapted to the LLM paradigm to enjoy the power of LLMs. LLM-based methods usually formulate recommendation information into natural language and the model is trained to predict the next item in an auto-regressive manner. Despite their notable success, the substantial computational overhead of inference poses a significant obstacle to their real-world applicability. In this work, we endeavor to streamline existing LLM-based recommendation models and propose a simple yet highly effective model Lite-LLM4Rec. The primary goal of Lite-LLM4Rec is to achieve efficient inference for the sequential recommendation task. Lite-LLM4Rec circumvents the beam search decoding by using a straight item projection head for ranking scores generation. This design stems from our empirical observation that beam search decoding is ultimately unnecessary for sequential recommendations. Additionally, Lite-LLM4Rec introd
    
[^14]: 推荐系统中的交叉双边公平性

    Intersectional Two-sided Fairness in Recommendation

    [https://arxiv.org/abs/2402.02816](https://arxiv.org/abs/2402.02816)

    本文针对推荐系统中的交叉双边公平性问题，提出了一种名为交叉双边公平推荐（ITFR）的新方法，通过利用锐度感知损失感知劣势群体，使用协作损失平衡开发不同交叉群体的一致区分能力，并利用预测得分归一化来公平对待不同交叉群体中的正例。实验证明该方法在提高交叉双边公平性方面取得了显著效果。

    

    近年来，推荐系统的公平性引起了越来越多的关注。根据涉及的利益相关者，推荐系统的公平性可分为用户公平性、物品公平性和同时考虑用户和物品公平性的双边公平性。然而，我们认为即使推荐系统是双边公平的，交叉双边不公平仍然可能存在，这在本文使用真实世界数据的实证研究中得到了观察和展示，并且以前尚未得到很好的研究。为了缓解这个问题，我们提出了一种新方法，称为交叉双边公平推荐（ITFR）。我们的方法利用一个锐度感知损失来感知劣势群体，然后使用协作损失平衡来开发不同交叉群体的一致区分能力。此外，我们利用预测得分归一化来调整正面预测得分，以公平地对待不同交叉群体中的正例。广泛的实验结果表明，我们的方法在提高交叉双边公平性方面取得了显著的效果。

    Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experime
    
[^15]: 设备上的推荐系统：综述

    On-Device Recommender Systems: A Comprehensive Survey

    [https://arxiv.org/abs/2401.11441](https://arxiv.org/abs/2401.11441)

    该论文综述了传统的云推荐系统（CloudRSs）与基于设备的推荐系统（DeviceRSs）之间的区别和优势，并提出了利用边缘设备的存储、通信和计算能力来解决资源消耗、响应延迟以及隐私和安全风险的方法。

    

    推荐系统已经在各种实际应用中广泛部署，以帮助用户从海量信息中找到感兴趣的内容。传统的推荐系统通过在云数据中心收集用户-物品交互数据，并训练一个集中式模型来进行推荐服务。然而，这种基于云的推荐系统（CloudRSs）不可避免地面临着过多的资源消耗、响应延迟以及涉及数据和模型的隐私和安全风险。最近，受到边缘设备存储、通信和计算能力的进步推动，人们逐渐从CloudRSs转向了设备上的推荐系统（DeviceRSs），这些系统利用边缘设备的能力来最小化集中式数据存储的要求，减少通信开销带来的响应延迟，并通过本地化的方式增强用户的隐私和安全性。

    arXiv:2401.11441v2 Announce Type: replace  Abstract: Recommender systems have been widely deployed in various real-world applications to help users identify content of interest from massive amounts of information. Traditional recommender systems work by collecting user-item interaction data in a cloud-based data center and training a centralized model to perform the recommendation service. However, such cloud-based recommender systems (CloudRSs) inevitably suffer from excessive resource consumption, response latency, as well as privacy and security risks concerning both data and models. Recently, driven by the advances in storage, communication, and computation capabilities of edge devices, there has been a shift of focus from CloudRSs to on-device recommender systems (DeviceRSs), which leverage the capabilities of edge devices to minimize centralized data storage requirements, reduce the response latency caused by communication overheads, and enhance user privacy and security by local
    
[^16]: 当基于大语言模型的智能体遇到用户行为分析：一种新颖的用户模拟范式

    When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm. (arXiv:2306.02552v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.02552](http://arxiv.org/abs/2306.02552)

    从事用户行为分析的学术界一直面临着收集足够高质量用户行为数据的难题，一种解决方案是自动模拟用户行为，近期研究表明，利用大语言模型进行可靠的用户模拟有了重要的突破，将这种模型应用到用户行为分析研究中有着巨大潜力，可能对传统研究范式产生革命性影响。

    

    用户行为分析在以人为中心的AI应用中至关重要。然而，收集足够和高质量的用户行为数据一直是一个基本但具有挑战性的问题。为了解决这个问题，自动模拟用户行为是一个直观的想法。然而，由于人类认知过程的主观和复杂性质，可靠地模拟用户行为是困难的。最近，大语言模型（LLM）取得了显著的成功，展示了实现类似人类智能的巨大潜力。我们认为这些模型为可靠的用户模拟提供了重要机会，并有可能改变传统的用户行为分析研究范式。在本文中，我们以推荐系统为例，探索使用LLM进行用户模拟的潜力。具体而言，我们将每个用户视为基于LLM的自治智能体，并让不同智能体在虚拟环境中自由交流、行为和发展。

    User behavior analysis is crucial in human-centered AI applications. In this field, the collection of sufficient and high-quality user behavior data has always been a fundamental yet challenging problem. An intuitive idea to address this problem is automatically simulating the user behaviors. However, due to the subjective and complex nature of human cognitive processes, reliably simulating the user behavior is difficult. Recently, large language models (LLM) have obtained remarkable successes, showing great potential to achieve human-like intelligence. We argue that these models present significant opportunities for reliable user simulation, and have the potential to revolutionize traditional study paradigms in user behavior analysis. In this paper, we take recommender system as an example to explore the potential of using LLM for user simulation. Specifically, we regard each user as an LLM-based autonomous agent, and let different agents freely communicate, behave and evolve in a vir
    
[^17]: DAPR：文档感知段落检索的基准测试

    DAPR: A Benchmark on Document-Aware Passage Retrieval. (arXiv:2305.13915v1 [cs.IR])

    [http://arxiv.org/abs/2305.13915](http://arxiv.org/abs/2305.13915)

    DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。

    

    最近的神经检索主要关注短文本的排名，并且在处理长文档方面存在挑战。现有的工作主要评估排名段落或整个文档。然而，许多情况下，用户希望从庞大的语料库中找到长文档中的相关段落，例如法律案例，研究论文等，此时段落往往提供很少的文档上下文，这就挑战了当前的方法找到正确的文档并返回准确的结果。为了填补这个空白，我们提出并命名了Document-Aware Passage Retrieval（DAPR）任务，并构建了一个包括来自不同领域的多个数据集的基准测试，涵盖了DAPR和整个文档检索。在实验中，我们通过不同的方法，包括在文档摘要中添加文档级别的内容，汇总段落表示和使用BM25进行混合检索，扩展了最先进的神经段落检索器。这个混合检索系统，总体基准测试显示，我们提出的DAPR任务是一个具有挑战性和重要性的问题，需要进一步研究。

    Recent neural retrieval mainly focuses on ranking short texts and is challenged with long documents. Existing work mainly evaluates either ranking passages or whole documents. However, there are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. legal cases, research papers, etc. In this scenario, the passage often provides little document context and thus challenges the current approaches to finding the correct document and returning accurate results. To fill this gap, we propose and name this task Document-Aware Passage Retrieval (DAPR) and build a benchmark including multiple datasets from various domains, covering both DAPR and whole-document retrieval. In experiments, we extend the state-of-the-art neural passage retrievers with document-level context via different approaches including prepending document summary, pooling over passage representations, and hybrid retrieval with BM25. The hybrid-retrieval systems, the overall b
    
[^18]: 利用人类记忆过程模拟音乐类型偏好以实现个性化音乐推荐

    Utilizing Human Memory Processes to Model Genre Preferences for Personalized Music Recommendations. (arXiv:2003.10699v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2003.10699](http://arxiv.org/abs/2003.10699)

    本文基于心理学模型，利用人类记忆过程来模拟和预测不同用户群体的音乐类型偏好。通过分析超过十亿条音乐收听记录数据集，发现该方法对于不同用户群体的预测准确性显著优于其他基准算法，并且具有透明和可解释性的特点。

    

    本文介绍了一种受心理学启发的方法，通过利用人类记忆过程来模拟和预测不同用户群体的音乐类型偏好。这些过程描述了人类如何通过考虑过去使用频率、过去使用时效以及当前上下文来访问其记忆中的信息单元。使用公开可用的超过十亿条在音乐流媒体平台Last.fm上分享的音乐收听记录数据集，我们发现我们的方法对于所有评估的用户群体，即低主流音乐听众、中等主流音乐听众和高主流音乐听众，提供了显著更好的预测准确性结果。此外，我们的方法基于一个简单的心理模型，有助于透明和可解释性的计算预测。

    In this paper, we introduce a psychology-inspired approach to model and predict the music genre preferences of different groups of users by utilizing human memory processes. These processes describe how humans access information units in their memory by considering the factors of (i) past usage frequency, (ii) past usage recency, and (iii) the current context. Using a publicly available dataset of more than a billion music listening records shared on the music streaming platform Last.fm, we find that our approach provides significantly better prediction accuracy results than various baseline algorithms for all evaluated user groups, i.e., (i) low-mainstream music listeners, (ii) medium-mainstream music listeners, and (iii) high-mainstream music listeners. Furthermore, our approach is based on a simple psychological model, which contributes to the transparency and explainability of the calculated predictions.
    

