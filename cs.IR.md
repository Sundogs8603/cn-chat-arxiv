# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery.](http://arxiv.org/abs/2305.07637) | Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。 |
| [^2] | [Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training.](http://arxiv.org/abs/2305.07633) | 本论文提出了一种使用产品知识图谱预训练模型从预训练的语言模型提取项目特征，以解决零样本项目推荐任务。该方法通过提出四个预训练任务和任务导向的适应层来解决预训练过程中的挑战，并将模型微调到新的推荐任务中。 |
| [^3] | [PALR: Personalization Aware LLMs for Recommendation.](http://arxiv.org/abs/2305.07622) | 本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。 |
| [^4] | [NevIR: Negation in Neural Information Retrieval.](http://arxiv.org/abs/2305.07614) | 本研究探讨了否定在神经信息检索中的影响，构建了基准模型，结果表明当前信息检索模型大多数都没有考虑否定，而交叉编码器是目前表现最好的架构。 |
| [^5] | [Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation.](http://arxiv.org/abs/2305.07609) | 这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。 |
| [^6] | [Eye Tracking as a Source of Implicit Feedback in Recommender Systems: A Preliminary Analysis.](http://arxiv.org/abs/2305.07516) | 本研究表明，眼动追踪可以为推荐系统提供一个额外的隐含反馈来源，并且AOI持续时间与已知的点击数据和先前看过的电影相关，为推荐模型提供了更好的改进。 |
| [^7] | [Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval.](http://arxiv.org/abs/2305.07477) | 本文研究将生成式和伪相关反馈在稀疏、稠密和学习稀疏检索中的应用。实验表明，相比类似的伪相关反馈技术，生成式相关反馈可以提高约10%的精确度和召回率。同时，我们提出将两种反馈信号结合起来以实现它们的优势。 |
| [^8] | [BactInt: A domain driven transfer learning approach and a corpus for extracting inter-bacterial interactions from biomedical text.](http://arxiv.org/abs/2305.07468) | BactInt是一种面向领域的自动化方法，使用迁移学习从生物医学文本中提取细菌间相互作用并挖掘特定细菌群之间的关系。公开可用的BactInt语料库标注了1200篇PubMed摘要。 |
| [^9] | [Knowledge Soft Integration for Multimodal Recommendation.](http://arxiv.org/abs/2305.07419) | 本文提出了一个知识软融合框架用于多模态推荐，该框架在特征提取和推荐过程中集成了领域特定的知识，解决了模型拟合偏差和性能下降的问题。 |
| [^10] | [Knowledge Refinement via Interaction Between Search Engines and Large Language Models.](http://arxiv.org/abs/2305.07402) | 本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。 |
| [^11] | [Music Rearrangement Using Hierarchical Segmentation.](http://arxiv.org/abs/2305.07347) | 本文提出了一种自动化音乐重排的方法，利用深度音频表示对音乐进行分层分割，考虑段落边界和音乐功能，实验结果表明其具有一致音乐发展和听觉无感知的特点。 |
| [^12] | [Methods and Tools to Advance the Retrieval of Mathematical Knowledge from Digital Libraries for Search-, Recommendation-, and Assistance-Systems.](http://arxiv.org/abs/2305.07335) | 该项目研究了提高数字图书馆中数学内容及语义信息的检索、推荐和辅助系统的新方法与技术，并公布了相应工具，以便研究人员更好地利用。 |
| [^13] | [Local Life: Stay Informed Around You, A Scalable Geoparsing and Geotagging Approach to Serve Local News Worldwide.](http://arxiv.org/abs/2305.07168) | 本文提出了一个可扩展的地理解析和地理标记方法，以确定本地新闻文章的位置和影响范围，以便为全球用户提供精准的本地新闻推荐服务。 |
| [^14] | [Automated Data Denoising for Recommendation.](http://arxiv.org/abs/2305.07070) | 本文提出了一个自动数据去噪的推荐框架——AutoDenoise，利用显式数据作为验证集动态 guiding 推荐算法的训练，对隐式数据进行去噪处理，提高推荐系统的准确性。 |
| [^15] | [Deep Reinforcement Learning for Interference Management in UAV-based 3D Networks: Potentials and Challenges.](http://arxiv.org/abs/2305.07069) | 本文提出了利用深度强化学习进行干扰管理的方法来解决UAV通信中的干扰问题，而无需先知干扰信号的信道信息。 |
| [^16] | [Searching Mobile App Screens via Text + Doodle.](http://arxiv.org/abs/2305.06165) | TpD为迭代搜索移动应用屏幕提供了交互式草图和关键字搜索技术的结合方法，使用户能够更快地查找所需屏幕。 |
| [^17] | [Inference at Scale Significance Testing for Large Search and Recommendation Experiments.](http://arxiv.org/abs/2305.02461) | 本文研究了大规模搜索和推荐实验的显著性检验行为，结果发现在大样本下Wilcoxon和Sign测试的1型错误率显著更高，建议在这种情况下使用bootstrap、随机化和t测试。 |
| [^18] | [SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval.](http://arxiv.org/abs/2207.02578) | 本文提出了一种名为SimLM的密集文本检索预训练方法，采用瓶颈架构和替代语言建模目标。在无标记的情况下，它也是适用的。相比于强基线模型，SimLM在多个大规模排序任务数据集上显示出了更好的性能，甚至超过了需要更多存储成本的多向量方法ColBERTv2。 |

# 详细

[^1]: Text2Cohort: 自然语言队列发现对癌症影像数据共享平台的民主化

    Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery. (arXiv:2305.07637v1 [cs.LG])

    [http://arxiv.org/abs/2305.07637](http://arxiv.org/abs/2305.07637)

    Text2Cohort是一个基于大语言模型的工具箱，可以将用户输入转化为IDC数据库查询，促进自然语言队列发现，减少研究人员查询IDC数据库的学习曲线，实现了癌症成像数据的民主化。

    

    影像数据共享平台(IDC)是一个基于云的数据库，为研究人员提供开放获取的癌症成像数据和分析工具，旨在促进医学成像研究中的协作。然而，由于其复杂和技术性质，查询IDC数据库以进行队列发现和访问成像数据对研究人员来说具有显著的学习曲线。我们开发了基于大语言模型（LLM）的Text2Cohort工具箱，通过提示工程将用户输入转化为IDC数据库查询，并将查询的响应返回给用户，以促进自然语言队列发现。此外，实现了自动校正以解决查询中的语法和语义错误，通过将错误传回模型进行解释和校正。我们对50个自然语言用户输入进行了Text2Cohort评估，范围从信息提取到队列发现。结果查询和输出由两位计算机科学家进行了确认。

    The Imaging Data Commons (IDC) is a cloud-based database that provides researchers with open access to cancer imaging data and tools for analysis, with the goal of facilitating collaboration in medical imaging research. However, querying the IDC database for cohort discovery and access to imaging data has a significant learning curve for researchers due to its complex and technical nature. We developed Text2Cohort, a large language model (LLM) based toolkit to facilitate natural language cohort discovery by translating user input into IDC database queries through prompt engineering and returning the query's response to the user. Furthermore, autocorrection is implemented to resolve syntax and semantic errors in queries by passing the errors back to the model for interpretation and correction. We evaluate Text2Cohort on 50 natural language user inputs ranging from information extraction to cohort discovery. The resulting queries and outputs were verified by two computer scientists to me
    
[^2]: 基于多任务产品知识图谱预训练的零样本基于项目推荐

    Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training. (arXiv:2305.07633v1 [cs.IR])

    [http://arxiv.org/abs/2305.07633](http://arxiv.org/abs/2305.07633)

    本论文提出了一种使用产品知识图谱预训练模型从预训练的语言模型提取项目特征，以解决零样本项目推荐任务。该方法通过提出四个预训练任务和任务导向的适应层来解决预训练过程中的挑战，并将模型微调到新的推荐任务中。

    

    现有的推荐系统在处理零样本项目（即在训练阶段没有与用户进行过历史互动的项目）时面临困难。虽然最近的工作通过预训练语言模型（PLM）提取通用项目表示，但它们忽略了关键的项目关系。本文提出了一种新的方法，使用产品知识图谱（PKG）对模型进行预训练，以从PLMs中提炼出项目特征来解决零样本项目推荐（ZSIR）任务。我们确定了预训练PKG的三个挑战，即PKG中的多类型关系，项目通用信息和关系之间的语义差异以及从PKG到下游ZSIR任务的域差异。我们通过提出四个预训练任务和新颖的面向任务的适应（ToA）层来解决这些挑战。此外，本文还讨论了如何对新的推荐任务进行微调，使得ToA层适应于ZSIR任务。在18个市场数据集上进行了全面实验。

    Existing recommender systems face difficulties with zero-shot items, i.e. items that have no historical interactions with users during the training stage. Though recent works extract universal item representation via pre-trained language models (PLMs), they ignore the crucial item relationships. This paper presents a novel paradigm for the Zero-Shot Item-based Recommendation (ZSIR) task, which pre-trains a model on product knowledge graph (PKG) to refine the item features from PLMs. We identify three challenges for pre-training PKG, which are multi-type relations in PKG, semantic divergence between item generic information and relations and domain discrepancy from PKG to downstream ZSIR task. We address the challenges by proposing four pre-training tasks and novel task-oriented adaptation (ToA) layers. Moreover, this paper discusses how to fine-tune the model on new recommendation task such that the ToA layers are adapted to ZSIR task. Comprehensive experiments on 18 markets dataset ar
    
[^3]: 个性化感知的推荐系统中的LMMs模型

    PALR: Personalization Aware LLMs for Recommendation. (arXiv:2305.07622v1 [cs.IR])

    [http://arxiv.org/abs/2305.07622](http://arxiv.org/abs/2305.07622)

    本文提出了一个称为PALR的框架，将用户的历史行为与LLMs相结合，生成用户喜欢的物品的推荐。与现有的推荐方法相比，我们的PALR框架实现了最先进的性能。

    

    大型语言模型(LLMs)由于其出色的性能而受到越来越多的关注。本文提出了一种新的框架PALR，将用户的历史行为与LLMs相结合，以生成用户喜欢的物品的推荐。我们首先使用用户/物品互动作为候选检索的指导，然后采用基于LLMs的排序模型生成推荐物品。实验结果表明，与现有的推荐方法相比，我们提出的PALR框架实现了最先进的性能。

    Large language models (LLMs) have recently received significant attention for their exceptional capabilities. Despite extensive efforts in developing general-purpose LLMs that can be utilized in various natural language processing (NLP) tasks, there has been less research exploring their potential in recommender systems. In this paper, we propose a novel framework, named PALR, which aiming to combine user history behaviors (such as clicks, purchases, ratings, etc.) with LLMs to generate user preferred items. Specifically, we first use user/item interactions as guidance for candidate retrieval. Then we adopt a LLM-based ranking model to generate recommended items. Unlike existing approaches that typically adopt general-purpose LLMs for zero/few-shot recommendation testing or training on small-sized language models (with less than 1 billion parameters), which cannot fully elicit LLMs' reasoning abilities and leverage rich item side parametric knowledge, we fine-tune a 7 billion parameter
    
[^4]: NevIR: 神经信息检索中的否定

    NevIR: Negation in Neural Information Retrieval. (arXiv:2305.07614v1 [cs.IR])

    [http://arxiv.org/abs/2305.07614](http://arxiv.org/abs/2305.07614)

    本研究探讨了否定在神经信息检索中的影响，构建了基准模型，结果表明当前信息检索模型大多数都没有考虑否定，而交叉编码器是目前表现最好的架构。

    

    否定是一种常见而日常化的现象，也一直是语言模型的一个弱点。虽然信息检索领域采用了语言模型作为现代化架构的主干，但几乎没有研究深入了解否定对神经信息检索的影响。因此，我们构建了一个简单的基准来研究这个主题：要求信息检索模型对仅仅因为是否定而不同的两个文档进行排名。我们发现，结果根据不同的信息检索架构而有很大差异：交叉编码器表现最好，后期交互模型次之，而双编码器和稀疏神经架构排名最后。我们发现，大多数当前的信息检索模型都没有考虑否定，表现与随机排名相似或更差。我们证明，尽管在一个包含否定对照文档的数据集上继续微调明显的方法可以提高性能（模型大小也是如此），但是机器和人之间仍存在很大的差距。

    Negation is a common everyday phenomena and has been a consistent area of weakness for language models (LMs). Although the Information Retrieval (IR) community has adopted LMs as the backbone of modern IR architectures, there has been little to no research in understanding how negation impacts neural IR. We therefore construct a straightforward benchmark on this theme: asking IR models to rank two documents that differ only by negation. We show that the results vary widely according to the type of IR architecture: cross-encoders perform best, followed by late-interaction models, and in last place are bi-encoder and sparse neural architectures. We find that most current information retrieval models do not consider negation, performing similarly or worse than randomly ranking. We show that although the obvious approach of continued fine-tuning on a dataset of contrastive documents containing negations increases performance (as does model size), there is still a large gap between machine 
    
[^5]: ChatGPT是否公平可靠？评估大型语言模型推荐中的公平性

    Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])

    [http://arxiv.org/abs/2305.07609](http://arxiv.org/abs/2305.07609)

    这篇论文介绍了一种新的推荐范式——通过LLM进行推荐，但由于LLMs可能存在社会偏见，需要进一步调查RecLLM所做推荐的公正性。为此，作者提出了一个新的公平性基准——FaiRLLM，并针对音乐和电影推荐场景中的八个敏感属性进行了评估。

    

    大型语言模型（LLM）的显着成就导致一种新的推荐范式——通过LLM进行推荐（RecLLM）。然而，需要注意LLMs可能包含社会偏见，因此需要进一步调查RecLLM所做推荐的公正性。为了避免RecLLM的潜在风险，有必要从用户的各种敏感属性角度评估RecLLM的公平性。由于RecLLM范式与传统推荐范式之间存在差异，因此直接使用传统推荐的公平性基准是有问题的。为了解决这个困境，我们提出了一个新的基准，称为“通过LLM的推荐的公平性”（FaiRLLM）。该基准包括精心设计的指标和数据集，涵盖两个推荐场景中的八个敏感属性：音乐和电影。通过利用我们的FaiRLLM基准，我们进行了一项评估。

    The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm -- Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation 
    
[^6]: 眼动追踪作为推荐系统中隐含反馈的来源：初步分析

    Eye Tracking as a Source of Implicit Feedback in Recommender Systems: A Preliminary Analysis. (arXiv:2305.07516v1 [cs.IR])

    [http://arxiv.org/abs/2305.07516](http://arxiv.org/abs/2305.07516)

    本研究表明，眼动追踪可以为推荐系统提供一个额外的隐含反馈来源，并且AOI持续时间与已知的点击数据和先前看过的电影相关，为推荐模型提供了更好的改进。

    

    在推荐系统中使用眼动追踪可以提供额外的隐含反馈来源，同时帮助评估其他反馈来源。本研究使用眼动追踪数据来指导电影推荐的协同过滤模型，相对于基于点击的实现提供了改进，并且还分析了感兴趣区域（AOI）持续时间与已知的点击数据和先前看过的电影相关性，表明AOI信息始终与这些感兴趣的事项一致。

    Eye tracking in recommender systems can provide an additional source of implicit feedback, while helping to evaluate other sources of feedback. In this study, we use eye tracking data to inform a collaborative filtering model for movie recommendation providing an improvement over the click-based implementations and additionally analyze the area of interest (AOI) duration as related to the known information of click data and movies seen previously, showing AOI information consistently coincides with these items of interest.
    
[^7]: 生成式和伪相关反馈在稀疏、稠密和学习稀疏检索中的应用

    Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval. (arXiv:2305.07477v1 [cs.IR])

    [http://arxiv.org/abs/2305.07477](http://arxiv.org/abs/2305.07477)

    本文研究将生成式和伪相关反馈在稀疏、稠密和学习稀疏检索中的应用。实验表明，相比类似的伪相关反馈技术，生成式相关反馈可以提高约10%的精确度和召回率。同时，我们提出将两种反馈信号结合起来以实现它们的优势。

    

    伪相关反馈（PRF）是一种经典的方法，通过使用第一次检索来丰富查询来解决词汇不匹配的问题。此外，最近的生成式相关反馈（GRF）工作表明，使用大型语言模型生成的文本进行查询扩展模型可以改善稀疏检索，而无需依赖于第一次检索的效果。本文将GRF扩展到稠密和学习稀疏检索范例，并在六个标准文档排序基准测试中进行实验。我们发现，GRF在精确度和召回率方面的表现均比类似的PRF技术提高了约10%。然而，查询分析显示，GRF和PRF具有相反的优点，GRF提供了外部上下文，而PRF则将查询基于目标语料库中包含的信息。因此，我们建议将生成式和伪相关反馈排名信号结合起来，以实现两个反馈类别的好处。

    Pseudo-relevance feedback (PRF) is a classical approach to address lexical mismatch by enriching the query using first-pass retrieval. Moreover, recent work on generative-relevance feedback (GRF) shows that query expansion models using text generated from large language models can improve sparse retrieval without depending on first-pass retrieval effectiveness. This work extends GRF to dense and learned sparse retrieval paradigms with experiments over six standard document ranking benchmarks. We find that GRF improves over comparable PRF techniques by around 10% on both precision and recall-oriented measures. Nonetheless, query analysis shows that GRF and PRF have contrasting benefits, with GRF providing external context not present in first-pass retrieval, whereas PRF grounds the query to the information contained within the target corpus. Thus, we propose combining generative and pseudo-relevance feedback ranking signals to achieve the benefits of both feedback classes, which signifi
    
[^8]: BactInt:一种面向领域的迁移学习方法和一个语料库，用于从生物医学文本中提取细菌间相互作用

    BactInt: A domain driven transfer learning approach and a corpus for extracting inter-bacterial interactions from biomedical text. (arXiv:2305.07468v1 [cs.IR])

    [http://arxiv.org/abs/2305.07468](http://arxiv.org/abs/2305.07468)

    BactInt是一种面向领域的自动化方法，使用迁移学习从生物医学文本中提取细菌间相互作用并挖掘特定细菌群之间的关系。公开可用的BactInt语料库标注了1200篇PubMed摘要。

    

    生物学领域中不同类型微生物在生物学空间中发挥着重要作用，这些微生物之间的相互作用是微生物群落结构的基本构建单元。生物医学文本中的证据可作为预测这种相互作用的可靠来源。然而，阅读海量且不断增长的生物医学文献是一项耗时并令人望而生畏的工作。这就必然需要开发自动化方法来准确提取生物医学文献中所报道的细菌关系。本文介绍了一种从生物医学文献中自动提取微生物相互作用（特别是细菌之间）的方法以及使用迁移学习来提高其准确性的方法。我们还描述了一个管道，用于挖掘特定细菌群之间的关系。此外，我们还介绍了第一个公开可用的Bacterial Interaction (BactInt)语料库，其中包括1200篇PubMed摘要，注释有细菌间关系。

    The community of different types of microbes present in a biological niche plays a very important role in functioning of the system. The crosstalk or interactions among the different microbes contributes to the building blocks of such microbial community structures. Evidence reported in biomedical text serves as a reliable source for predicting such interactions. However, going through the vast and ever-increasing volume of biomedical literature is an intimidating and time consuming process. This necessitates development of automated methods capable of accurately extracting bacterial relations reported in biomedical literature. In this paper, we introduce a method for automated extraction of microbial interactions (specifically between bacteria) from biomedical literature along with ways of using transfer learning to improve its accuracy. We also describe a pipeline using which relations among specific bacteria groups can be mined. Additionally, we introduce the first publicly availabl
    
[^9]: 多模态推荐中的知识软融合

    Knowledge Soft Integration for Multimodal Recommendation. (arXiv:2305.07419v1 [cs.IR])

    [http://arxiv.org/abs/2305.07419](http://arxiv.org/abs/2305.07419)

    本文提出了一个知识软融合框架用于多模态推荐，该框架在特征提取和推荐过程中集成了领域特定的知识，解决了模型拟合偏差和性能下降的问题。

    

    现代推荐系统中的主要挑战之一是如何有效地利用多模态内容实现更个性化的推荐。尽管有各种各样的解决方案，但大多数解决方案都忽略了独立特征提取过程所获得知识与下游推荐任务之间的不匹配。具体而言，多模态特征提取过程未纳入与推荐任务相关的先前知识，而推荐任务经常直接将这些多模态特征用作辅助信息。这种不匹配可能导致模型拟合偏差和性能下降，本文将其称为“知识诅咒”问题。为了解决这个问题，我们提出使用知识软融合平衡多模态特征利用和知识诅咒问题带来的负面影响。为此，我们提出了一个适用于多模态推荐的知识软融合框架，简称KSI，它将领域特定的知识集成到特征提取和推荐过程中。在三个真实数据集上的实验表明，KSI在推荐准确性和多样性方面超越了几种最先进的方法。

    One of the main challenges in modern recommendation systems is how to effectively utilize multimodal content to achieve more personalized recommendations. Despite various proposed solutions, most of them overlook the mismatch between the knowledge gained from independent feature extraction processes and downstream recommendation tasks. Specifically, multimodal feature extraction processes do not incorporate prior knowledge relevant to recommendation tasks, while recommendation tasks often directly use these multimodal features as side information. This mismatch can lead to model fitting biases and performance degradation, which this paper refers to as the \textit{curse of knowledge} problem. To address this issue, we propose using knowledge soft integration to balance the utilization of multimodal features and the curse of knowledge problem it brings about. To achieve this, we put forward a Knowledge Soft Integration framework for the multimodal recommendation, abbreviated as KSI, whic
    
[^10]: 搜索引擎与大型语言模型间的交互优化知识精炼

    Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v1 [cs.CL])

    [http://arxiv.org/abs/2305.07402](http://arxiv.org/abs/2305.07402)

    本文介绍了一种新的框架InteR，通过搜索引擎和大型语言模型之间的交互促进知识精炼，从而提高检索准确性。

    

    信息检索在从大量数据中定位相关资源方面具有重要作用，其应用已从传统知识库发展至现代搜索引擎（SEs）。大型语言模型（LLMs）的出现进一步通过使用自然语言与搜索系统交互革命性地改变了该领域。本文探索了LLMs和SEs的优缺点，强调它们在理解用户查询和检索最新信息方面的各自优势。为了利用两种范例的优势并避免其限制，我们提出了InteR，这是一个通过SEs和LLMs之间的交互促进知识精炼的新框架。 InteR使SEs能够使用LLM生成的摘要来调整查询，同时使LLMs能够使用SE检索到的文档来增强提示。这种迭代的精炼过程增强了SEs和LLMs的输入，从而导致更准确的检索结果。

    Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to refine knowledge in query using LLM-generated summaries and enables LLMs to enhance prompts using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Ex
    
[^11]: 使用分层分割的方法进行音乐重排

    Music Rearrangement Using Hierarchical Segmentation. (arXiv:2305.07347v1 [cs.SD])

    [http://arxiv.org/abs/2305.07347](http://arxiv.org/abs/2305.07347)

    本文提出了一种自动化音乐重排的方法，利用深度音频表示对音乐进行分层分割，考虑段落边界和音乐功能，实验结果表明其具有一致音乐发展和听觉无感知的特点。

    

    音乐重排涉及到音乐曲目的重新组合、删除和重复，目的是产生一个不同时间长度的独立版本。这通常由专业音乐工程师进行创造性而耗时的任务。本文提出了一种自动重新排列音乐录音的方法，考虑了录音的分层结构。以往的方法仅关注音频中可能导致平滑转换的切割点的识别。我们利用深度音频表示来对作品进行分层分割，并定义对段落边界和音乐功能进行切割点搜索。我们根据相似性和它们所属的段落来评分适当的进入点和退出点对，并定义一个最优路径搜索。实验结果表明，所选择的切割点通常对听众最不可察觉，并导致更一致音乐发展。

    Music rearrangement involves reshuffling, deleting, and repeating sections of a music piece with the goal of producing a standalone version that has a different duration. It is a creative and time-consuming task commonly performed by an expert music engineer. In this paper, we propose a method for automatically rearranging music recordings that takes into account the hierarchical structure of the recording. Previous approaches focus solely on identifying cut-points in the audio that could result in smooth transitions. We instead utilize deep audio representations to hierarchically segment the piece and define a cut-point search subject to the boundaries and musical functions of the segments. We score suitable entry- and exit-point pairs based on their similarity and the segments they belong to, and define an optimal path search. Experimental results demonstrate the selected cut-points are most commonly imperceptible by listeners and result in more consistent musical development with le
    
[^12]: 数字图书馆中数学知识检索、推荐和辅助系统的发展方法和工具

    Methods and Tools to Advance the Retrieval of Mathematical Knowledge from Digital Libraries for Search-, Recommendation-, and Assistance-Systems. (arXiv:2305.07335v1 [cs.IR])

    [http://arxiv.org/abs/2305.07335](http://arxiv.org/abs/2305.07335)

    该项目研究了提高数字图书馆中数学内容及语义信息的检索、推荐和辅助系统的新方法与技术，并公布了相应工具，以便研究人员更好地利用。

    

    本项目研究了提高数学内容及其语义信息在各种信息检索应用中可访问性的新方法和技术。为实现这一目标，该项目解决了三个主要研究挑战：（1）数学表达式的句法分析，（2）数学表达式的语义增强，（3）使用质量度量和演示程序进行评估。为了使我们的研究对研究社区有所用处，我们公布了能够使研究人员更有效、更高效地处理数学表达式的工具。

    This project investigated new approaches and technologies to enhance the accessibility of mathematical content and its semantic information for a broad range of information retrieval applications. To achieve this goal, the project addressed three main research challenges: (1) syntactic analysis of mathematical expressions, (2) semantic enrichment of mathematical expressions, and (3) evaluation using quality metrics and demonstrators. To make our research useful for the research community, we published tools that enable researchers to process mathematical expressions more effectively and efficiently.
    
[^13]: 本地生活：一个可扩展的地理解析和地理标记方法，以为全球提供本地新闻。

    Local Life: Stay Informed Around You, A Scalable Geoparsing and Geotagging Approach to Serve Local News Worldwide. (arXiv:2305.07168v1 [cs.IR])

    [http://arxiv.org/abs/2305.07168](http://arxiv.org/abs/2305.07168)

    本文提出了一个可扩展的地理解析和地理标记方法，以确定本地新闻文章的位置和影响范围，以便为全球用户提供精准的本地新闻推荐服务。

    

    由于其各种好处，本地新闻在新闻行业中变得越来越重要。 它为当地观众提供信息，帮助他们参与社区和兴趣。 它还作为可靠的事实报道来源，可以防止错误信息。 此外，它可以影响国家观众，因为一些本地故事可能对政治，环境或犯罪产生更广泛的影响。 因此，检测本地新闻的确切地理位置和影响范围对于新闻推荐系统至关重要。 在这篇论文中，我们专注于第二步，并提出（1）一个有效的方法来确定本地新闻文章的位置和半径，（2）一种将用户位置与文章位置协调的方法，以及（3）一个度量标准来评估该方法的性能。

    Local news has become increasingly important in the news industry due to its various benefits. It offers local audiences information that helps them participate in their communities and interests. It also serves as a reliable source of factual reporting that can prevent misinformation. Moreover, it can influence national audiences as some local stories may have wider implications for politics, environment or crime. Hence, detecting the exact geolocation and impact scope of local news is crucial for news recommendation systems. There are two fundamental things required in this process, (1) classify whether an article belongs to local news, and (2) identify the geolocation of the article and its scope of influence to recommend it to appropriate users. In this paper, we focus on the second step and propose (1) an efficient approach to determine the location and radius of local news articles, (2) a method to reconcile the user's location with the article's location, and (3) a metric to eva
    
[^14]: 自动数据去噪技术用于推荐系统的应用

    Automated Data Denoising for Recommendation. (arXiv:2305.07070v1 [cs.IR])

    [http://arxiv.org/abs/2305.07070](http://arxiv.org/abs/2305.07070)

    本文提出了一个自动数据去噪的推荐框架——AutoDenoise，利用显式数据作为验证集动态 guiding 推荐算法的训练，对隐式数据进行去噪处理，提高推荐系统的准确性。

    

    在现实世界中，大多数平台收集的反馈数据既有大规模、自然嘈杂的隐式反馈，也有小规模但高度相关的显式反馈。由于数据稀缺的问题，隐式反馈通常是训练推荐系统的默认选择，但这种数据可能非常嘈杂，因为用户行为的随机性和多样性。幸运的是，通过利用两种反馈的优势来弥补另一种的弱点，我们可以几乎不花费什么代价来缓解以上问题。本文提出了一个自动数据去噪的框架——AutoDenoise用于推荐系统，它使用少量显式数据作为验证集来指导推荐算法的训练。AutoDenoise受到课程学习（CL）的广义定义的启发，学会自动动态地进行课程学习，进而对数据进行去噪处理。

    In real-world scenarios, most platforms collect both large-scale, naturally noisy implicit feedback and small-scale yet highly relevant explicit feedback. Due to the issue of data sparsity, implicit feedback is often the default choice for training recommender systems (RS), however, such data could be very noisy due to the randomness and diversity of user behaviors. For instance, a large portion of clicks may not reflect true user preferences and many purchases may result in negative reviews or returns. Fortunately, by utilizing the strengths of both types of feedback to compensate for the weaknesses of the other, we can mitigate the above issue at almost no cost. In this work, we propose an Automated Data Denoising framework, \textbf{\textit{AutoDenoise}}, for recommendation, which uses a small number of explicit data as validation set to guide the recommender training. Inspired by the generalized definition of curriculum learning (CL), AutoDenoise learns to automatically and dynamica
    
[^15]: 无人机三维网络中的干扰管理的深度强化学习：潜力与挑战

    Deep Reinforcement Learning for Interference Management in UAV-based 3D Networks: Potentials and Challenges. (arXiv:2305.07069v1 [cs.IT])

    [http://arxiv.org/abs/2305.07069](http://arxiv.org/abs/2305.07069)

    本文提出了利用深度强化学习进行干扰管理的方法来解决UAV通信中的干扰问题，而无需先知干扰信号的信道信息。

    

    现代蜂窝网络是多小区的，采用通用频率重用来最大化频谱效率。这导致高干扰。随着无人机(UAV)的采用，这个问题正在变得越来越严重，因为UAV通信中的直射频道会迅速增加干扰链路的强度和数量。现有的干扰管理解决方案需要每个发射器知道干扰信号的信道信息，从而导致过多的信令开销。在本文中，我们提出利用深度强化学习进行干扰管理来解决这个缺陷。特别地，我们表明即使不知道干扰信号的信道信息，也仍然可以有效地减轻干扰。然后，我们讨论了使用线性/亚线性复杂度扩展算法和使用多智能体强化学习对其进行分散的新方法。

    Modern cellular networks are multi-cell and use universal frequency reuse to maximize spectral efficiency. This results in high inter-cell interference. This problem is growing as cellular networks become three-dimensional with the adoption of unmanned aerial vehicles (UAVs). This is because the strength and number of interference links rapidly increase due to the line-of-sight channels in UAV communications. Existing interference management solutions need each transmitter to know the channel information of interfering signals, rendering them impractical due to excessive signaling overhead. In this paper, we propose leveraging deep reinforcement learning for interference management to tackle this shortcoming. In particular, we show that interference can still be effectively mitigated even without knowing its channel information. We then discuss novel approaches to scale the algorithms with linear/sublinear complexity and decentralize them using multi-agent reinforcement learning. By ha
    
[^16]: 通过文本和涂鸦搜索移动应用屏幕

    Searching Mobile App Screens via Text + Doodle. (arXiv:2305.06165v1 [cs.IR])

    [http://arxiv.org/abs/2305.06165](http://arxiv.org/abs/2305.06165)

    TpD为迭代搜索移动应用屏幕提供了交互式草图和关键字搜索技术的结合方法，使用户能够更快地查找所需屏幕。

    

    现有资源中要找到特定的移动应用程序屏幕局限于基本的关键词搜索，如Google图像搜索，或需要完整的查询屏幕图像，如Swire的情况。然而，类似PSDoodle的交互式部分基于草图的解决方案存在精度不准确和无法考虑屏幕上出现文本等局限性。一种潜在有效的解决方案涉及实施一个系统，为有效构建用户界面元素提供交互式部分草图功能。此外，该系统应结合文本查询以进一步增强其能力。我们的方法TpD代表了通过结合交互式草图和关键字搜索技术进行屏幕迭代搜索的开创性工作。TpD建立在大约58k个Android应用程序屏幕的Rico存储库和PSDoodle的组合基础上。我们与第三方软件开发人员的评估表明，PSDoodle提供了高精度、高召回的结果，并且TpD使用户能够更快地查找所需屏幕。

    Locating a specific mobile application screen from existing repositories is restricted to basic keyword searches, such as Google Image Search, or necessitates a complete query screen image, as in the case of Swire. However, interactive partial sketch-based solutions like PSDoodle have limitations, including inaccuracy and an inability to consider text appearing on the screen. A potentially effective solution involves implementing a system that provides interactive partial sketching functionality for efficiently structuring user interface elements. Additionally, the system should incorporate text queries to enhance its capabilities further. Our approach, TpD, represents the pioneering effort to enable an iterative search of screens by combining interactive sketching and keyword search techniques. TpD is built on a combination of the Rico repository of approximately 58k Android app screens and the PSDoodle. Our evaluation with third-party software developers showed that PSDoodle provided
    
[^17]: 大规模搜索和推荐实验的显著性检验

    Inference at Scale Significance Testing for Large Search and Recommendation Experiments. (arXiv:2305.02461v1 [cs.IR])

    [http://arxiv.org/abs/2305.02461](http://arxiv.org/abs/2305.02461)

    本文研究了大规模搜索和推荐实验的显著性检验行为，结果发现在大样本下Wilcoxon和Sign测试的1型错误率显著更高，建议在这种情况下使用bootstrap、随机化和t测试。

    

    许多信息检索研究已经进行了评估，以确定哪种统计技术适用于比较系统。然而，这些研究集中于TREC样式的实验，通常少于100个主题。没有类似的研究适用于大规模搜索和推荐实验；这些研究通常涉及数千个主题或用户以及更稀疏的相关性判断，因此不清楚分析传统TREC实验的建议是否适用于这些情况。在本文中，我们实证研究了大规模搜索和推荐评估数据的显著性检验行为。我们的结果显示，Wilcoxon和Sign测试显示出显著更高的1型错误率，而不是更一致符合预期错误率的bootstrap、随机化和t测试。虽然统计测试在样本较小时显示出功率差异，但在功率相同时显示出没有区别。

    A number of information retrieval studies have been done to assess which statistical techniques are appropriate for comparing systems. However, these studies are focused on TREC-style experiments, which typically have fewer than 100 topics. There is no similar line of work for large search and recommendation experiments; such studies typically have thousands of topics or users and much sparser relevance judgements, so it is not clear if recommendations for analyzing traditional TREC experiments apply to these settings. In this paper, we empirically study the behavior of significance tests with large search and recommendation evaluation data. Our results show that the Wilcoxon and Sign tests show significantly higher Type-1 error rates for large sample sizes than the bootstrap, randomization and t-tests, which were more consistent with the expected error rate. While the statistical tests displayed differences in their power for smaller sample sizes, they showed no difference in their po
    
[^18]: SimLM：表示瓶颈预训练用于密集文本检索

    SimLM: Pre-training with Representation Bottleneck for Dense Passage Retrieval. (arXiv:2207.02578v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.02578](http://arxiv.org/abs/2207.02578)

    本文提出了一种名为SimLM的密集文本检索预训练方法，采用瓶颈架构和替代语言建模目标。在无标记的情况下，它也是适用的。相比于强基线模型，SimLM在多个大规模排序任务数据集上显示出了更好的性能，甚至超过了需要更多存储成本的多向量方法ColBERTv2。

    

    本文中，我们提出了一种名为SimLM（预训练模型中的相似性匹配）的简单而有效的密集文本检索预训练方法。它采用了一个简单的瓶颈架构，通过自监督预训练将文本信息压缩为一个密集向量。我们使用了一种替代语言建模目标，灵感来自ELECTRA，以改善样本效率并减少预训练和微调之间输入分布的偏差。SimLM只需要对未标记的语料库进行访问，并且在没有标记数据或查询的情况下更为广泛适用。我们在几个大规模排序任务数据集上进行了实验，并在各种设置下显示了比强基线更大的改进。值得注意的是，SimLM甚至在需要更多存储成本的多向量方法（如ColBERTv2）的情况下也能取得更好的性能。我们的代码和模型检查点可在https://github.com/microsoft/unilm/tree/mast中找到。

    In this paper, we propose SimLM (Similarity matching with Language Model pre-training), a simple yet effective pre-training method for dense passage retrieval. It employs a simple bottleneck architecture that learns to compress the passage information into a dense vector through self-supervised pre-training. We use a replaced language modeling objective, which is inspired by ELECTRA, to improve the sample efficiency and reduce the mismatch of the input distribution between pre-training and fine-tuning. SimLM only requires access to unlabeled corpus, and is more broadly applicable when there are no labeled data or queries. We conduct experiments on several large-scale passage retrieval datasets, and show substantial improvements over strong baselines under various settings. Remarkably, SimLM even outperforms multi-vector approaches such as ColBERTv2 which incurs significantly more storage cost. Our code and model check points are available at https://github.com/microsoft/unilm/tree/mast
    

