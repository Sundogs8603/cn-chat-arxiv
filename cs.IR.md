# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Retrieval-Augmented Thought Process as Sequential Decision Making](https://arxiv.org/abs/2402.07812) | 检索增强思维过程（RATP）通过多步决策和蒙特卡洛树搜索，以及Q值估计器，解决了大型语言模型在隐私、产生幻觉和处理长文本方面的挑战，并在处理私人数据的问答任务中实现了50%的性能提升。 |
| [^2] | [Quantitative knowledge retrieval from large language models](https://arxiv.org/abs/2402.07770) | 本文探讨了大型语言模型（LLMs）作为定量知识检索的可行性，以辅助数据分析任务。提出了一个提示工程框架，将LLMs作为科学文献潜在空间的接口。讨论了使用LLMs作为“专家”的影响和挑战。 |
| [^3] | [Multimodal Learned Sparse Retrieval for Image Suggestion](https://arxiv.org/abs/2402.07736) | 该论文探索了在多模态领域中应用学习稀疏检索（LSR）的方法，通过丰富图像内容与其标题信息相结合，极大地提高了模型性能，提供了实际而有效的训练LSR检索模型的解决方案。 |
| [^4] | [Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks](https://arxiv.org/abs/2402.07659) | 这项研究提出了一种新的方法，使用部分顺序图卷积网络来解决单一图形中多个行为的协同过滤问题。该方法通过定义多个行为之间的部分顺序关系，并利用加权边合并行为图，实现了在主要任务和辅助任务上都表现良好的联合嵌入。 |
| [^5] | [GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants](https://arxiv.org/abs/2402.07647) | 本论文介绍了GRILLBot在实践中的应用，该系统是用于复杂实际任务的多模态助手，并处理了开发和部署中的实际问题和挑战。作者提出了一种混合架构，利用大型语言模型和专门模型来保证任务导向的问题回答和实时任务调整的性能和低延迟，以及通过代码生成方法实现的对话状态管理。该论文对于构建适应性会话任务助手具有重要的创新和贡献。 |
| [^6] | [VCR: Video representation for Contextual Retrieval](https://arxiv.org/abs/2402.07466) | 该论文提出了一种基于文本的方法，通过融合视觉、音频和文本特征来高效地索引和分类视频内容，并使用语义嵌入提供相关的信息和推荐，从而实现了一种直观而有吸引力的探索体验。 |
| [^7] | [AraSpider: Democratizing Arabic-to-SQL](https://arxiv.org/abs/2402.07448) | AraSpider是首个阿拉伯语版本的Spider数据集，研究表明使用回译策略可以显著提高ChatGPT 3.5和SQLCoder模型在阿拉伯语NLP任务中的性能。 |
| [^8] | [Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT](https://arxiv.org/abs/2402.07440) | 该论文介绍了LoCoV1，一个用于评估长上下文检索性能的新型基准测试，并提出了M2-BERT检索编码器，用于处理长上下文检索，解决了如何评估性能、预训练语言模型以及如何进行微调的挑战。 |
| [^9] | [Debiasing Recommendation with Personal Popularity](https://arxiv.org/abs/2402.07425) | 该论文提出了使用个人流行度来消除推荐系统中的偏见问题。传统方法没有注意到全局流行度的根本问题，而个人流行度能够更好地捕捉到个体用户的兴趣，并生成个性化的推荐。研究者设计了一个称为个人流行度感知反事实的框架，将个人流行度融入到推荐系统中。 |
| [^10] | [Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models](https://arxiv.org/abs/2402.07179) | 本文研究了基于检索增强生成的大型语言模型（LLM）中提示扰动的影响，并引入了一种新的优化技术GGPP。通过GGPP，我们可以将LLMs的输出引导到特定的错误答案，并应对提示中的无关上下文。 |
| [^11] | [Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation](https://arxiv.org/abs/2402.07092) | 本文提出了一种通过LLM-认知数据增强的方法来广义对话密集检索。该方法首先生成多级增强对话，捕捉多样的对话环境。其次，通过认知感知过程减少错误生成情况，并通过难度自适应样本筛选器选择具有挑战性的样本。 |
| [^12] | [Enhancing Multi-field B2B Cloud Solution Matching via Contrastive Pre-training](https://arxiv.org/abs/2402.07076) | 通过对比预训练和多领域匹配结构，我们提出了CAMA框架来改善B2B云解决方案的匹配问题，克服了复杂特征和有限数据的挑战。 |
| [^13] | [Non-autoregressive Generative Models for Reranking Recommendation](https://arxiv.org/abs/2402.06871) | 本研究提出了一个非自回归的生成模型用于排序推荐，在多阶段推荐系统中扮演关键角色。该模型旨在提高效率和效果，并解决稀疏训练样本和动态候选项对模型收敛性的挑战。 |
| [^14] | [LiRank: Industrial Large Scale Ranking Models at LinkedIn](https://arxiv.org/abs/2402.06859) | LiRank是领英的一个大规模排名框架，它应用了最先进的建模架构和优化方法，并提出了新的建模改进和技术，通过A/B测试取得了有效的结果。 |
| [^15] | [MDGNN: Multi-Relational Dynamic Graph Neural Network for Comprehensive and Dynamic Stock Investment Prediction](https://arxiv.org/abs/2402.06633) | 提出了多关系动态图神经网络（MDGNN）框架，通过利用离散动态图全面捕捉股票之间的多方面关系及其随时间的演变，并利用Transformer结构的能力对多重关系的时间演变进行编码，从而提供了股票及其关联实体之间相互关系的完整视角。 |
| [^16] | [PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models](https://arxiv.org/abs/2402.05868) | PromptCrypt是一种使用表情符号对用户输入进行加密的机制，保护了大型语言模型（LLM）中用户的隐私，防止数据泄露和解密。 |
| [^17] | [Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and Google Bard Content in Relation to BioMedical Literature](https://arxiv.org/abs/2402.05116) | 本研究旨在通过文本挖掘方法评估ChatGPT和Google Bard生成的内容与生物医学文献之间的相似性。实验结果显示，在余弦文档相似性方面，ChatGPT表现优于Google Bard。 |
| [^18] | [Hide Your Model: A Parameter Transmission-free Federated Recommender System](https://arxiv.org/abs/2311.14968) | 提出了一种无需参数传输的联邦推荐系统，解决了全局共享模型和高维参数传输的问题。 |
| [^19] | [Utilizing Contextual Clues and Role Correlations for Enhancing Document-level Event Argument Extraction](https://arxiv.org/abs/2310.05116) | 本文提出了CARLG模型，通过利用上下文线索和角色相关性，提升了文档级事件论证提取的性能。 |
| [^20] | [Making Language Models Better Tool Learners with Execution Feedback](https://arxiv.org/abs/2305.13068) | 这篇论文提出了一个名为TRICE的框架，通过执行反馈实现语言模型的工具学习，使其能够学会何时以及如何有效地使用工具。 |
| [^21] | [Scalable Neural Network Training over Distributed Graphs](https://arxiv.org/abs/2302.13053) | RETEXO是第一个消除分布式图神经网络训练中通信瓶颈的框架，通过新的训练过程懒消息传递来改善网络通信效率。 |
| [^22] | [A Purely Regular Approach to Non-Regular Core Spanners](https://arxiv.org/abs/2010.13442) | 本文提出了一种纯粹规则的非规则核心跨度生成方法，通过将字符串相等选择直接纳入底层规则语言中，可以得到具有略微较弱表达能力的核心跨度生成器的片段。 |
| [^23] | [Challenging Low Homophily in Social Recommendation.](http://arxiv.org/abs/2401.14606) | 本研究挑战了社交推荐中的低同质性问题，提出了Social Heterophily-alleviating Rewiring (SHaRe)框架，用于增强现有的基于图的社交推荐模型。通过捕捉高同质的社交关系并剪切低同质关系，该框架有效提取了偏好感知同质性信息，解决了社交推荐中的信息冗余问题。 |
| [^24] | [CIDER: Category-Guided Intent Disentanglement for Accurate Personalized News Recommendation.](http://arxiv.org/abs/2310.09401) | CIDER是一种基于类别引导的个性化新闻推荐框架，通过意图分离和一致性的新闻表示来准确理解新闻文章的多个意图，并区分用户不同的后阅读偏好。 |
| [^25] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^26] | [DAPR: A Benchmark on Document-Aware Passage Retrieval.](http://arxiv.org/abs/2305.13915) | DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。 |

# 详细

[^1]: 检索增强的思维过程作为序列决策制定

    Retrieval-Augmented Thought Process as Sequential Decision Making

    [https://arxiv.org/abs/2402.07812](https://arxiv.org/abs/2402.07812)

    检索增强思维过程（RATP）通过多步决策和蒙特卡洛树搜索，以及Q值估计器，解决了大型语言模型在隐私、产生幻觉和处理长文本方面的挑战，并在处理私人数据的问答任务中实现了50%的性能提升。

    

    大型语言模型(LLM)展示了其强大的辅助人类并展现出"智能的火花"的能力。然而，几个开放挑战阻碍了它们的广泛应用：如对隐私的关注、倾向于产生幻觉、难以处理长文本。在本研究中，我们通过引入检索增强思维过程(RATP)来解决这些挑战。通过获取外部知识，RATP将LLM的思考生成过程定式为多步决策过程。为了优化这种思考过程，RATP利用蒙特卡洛树搜索，并学习了一个Q值估计器，实现了高效的推理。在处理具有私人数据的问答任务时，LLM训练方法受到伦理和安全问题的限制。RATP在上下文检索增强语言模型的基础上实现了50%的性能提升。

    Large Language Models (LLMs) have demonstrated their strong ability to assist people and show "sparks of intelligence". However, several open challenges hinder their wider application: such as concerns over privacy, tendencies to produce hallucinations, and difficulties in handling long contexts. In this work, we address those challenges by introducing the Retrieval-Augmented Thought Process (RATP). Given access to external knowledge, RATP formulates the thought generation of LLMs as a multiple-step decision process. To optimize such a thought process, RATP leverages Monte-Carlo Tree Search, and learns a Q-value estimator that permits cost-efficient inference. In addressing the task of question-answering with private data, where ethical and security concerns limit LLM training methods, RATP achieves a 50% improvement over existing in-context retrieval-augmented language models.
    
[^2]: 大型语言模型中的定量知识检索

    Quantitative knowledge retrieval from large language models

    [https://arxiv.org/abs/2402.07770](https://arxiv.org/abs/2402.07770)

    本文探讨了大型语言模型（LLMs）作为定量知识检索的可行性，以辅助数据分析任务。提出了一个提示工程框架，将LLMs作为科学文献潜在空间的接口。讨论了使用LLMs作为“专家”的影响和挑战。

    

    大型语言模型（LLM）因其生成具有说服力的自然语言序列的能力而被广泛研究，但其作为定量信息检索的实用性尚不明确。本文探讨了将LLMs作为定量知识检索机制的可行性，以帮助数据分析任务，如贝叶斯模型的先验分布引导和缺失数据的填补。我们提出了一个提示工程框架，将LLMs视为科学文献潜在空间的接口，在不同上下文和领域中比较响应与更成熟的方法。讨论了使用LLMs作为“专家”的影响和挑战。

    Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood. In this paper we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data. We present a prompt engineering framework, treating an LLM as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches. Implications and challenges of using LLMs as 'experts' are discussed.
    
[^3]: 图像建议的多模态学习稀疏检索

    Multimodal Learned Sparse Retrieval for Image Suggestion

    [https://arxiv.org/abs/2402.07736](https://arxiv.org/abs/2402.07736)

    该论文探索了在多模态领域中应用学习稀疏检索（LSR）的方法，通过丰富图像内容与其标题信息相结合，极大地提高了模型性能，提供了实际而有效的训练LSR检索模型的解决方案。

    

    学习稀疏检索（LSR）是一组设计用于将查询和文档编码成稀疏词汇向量的神经方法。这些向量可以通过倒排索引进行高效地索引和检索。虽然LSR在文本检索中表现出了潜力，但其在多模态检索中的潜力仍然未被充分探索。基于此，本文研究了LSR在多模态领域中的应用，即我们专注于多模态学习稀疏检索（MLSR）。我们使用多种MLSR模型配置进行实验，并评估图像建议任务的性能。我们发现仅基于图像内容解决该任务具有挑战性。通过丰富图像内容与其标题信息相结合，可以显著提高模型性能，这表明图像标题提供了图像的精细概念和上下文信息的重要性。我们的方法为多模态设置中训练LSR检索模型提供了实际而有效的解决方案。

    Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors. These vectors can be efficiently indexed and retrieved using an inverted index. While LSR has shown promise in text retrieval, its potential in multi-modal retrieval remains largely unexplored. Motivated by this, in this work, we explore the application of LSR in the multi-modal domain, i.e., we focus on Multi-Modal Learned Sparse Retrieval (MLSR). We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task. We find that solving the task solely based on the image content is challenging. Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images. Our approach presents a practical and effective solution for training LSR retrieval models in multi-modal settings.
    
[^4]: 具有部分顺序图卷积网络的多行为协同过滤

    Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks

    [https://arxiv.org/abs/2402.07659](https://arxiv.org/abs/2402.07659)

    这项研究提出了一种新的方法，使用部分顺序图卷积网络来解决单一图形中多个行为的协同过滤问题。该方法通过定义多个行为之间的部分顺序关系，并利用加权边合并行为图，实现了在主要任务和辅助任务上都表现良好的联合嵌入。

    

    在单一图形协作过滤（CF）向量中表示多个行为的信息一直是一个长期存在的挑战。这是因为不同的行为自然形成单独的行为图，并学习单独的CF嵌入。现有模型通过指定某些行为的CF嵌入作为主要嵌入，并利用其他辅助工具来增强主要嵌入来合并这些单独的嵌入。然而，这种方法通常在主要任务上联合嵌入表现良好，但在辅助任务上表现不佳。为了解决由单独的行为图引起的问题，我们提出了部分顺序图（POG）的概念。POG定义了多个行为的部分顺序关系，并将行为组合建模为带有权重的边，以将单独的行为图合并成一个联合的POG。理论证明了POG可以推广到任何给定的多个行为集。基于POG，我们提出了定制的部分顺序模型。

    Representing the information of multiple behaviors in the single graph collaborative filtering (CF) vector has been a long-standing challenge. This is because different behaviors naturally form separate behavior graphs and learn separate CF embeddings. Existing models merge the separate embeddings by appointing the CF embeddings for some behaviors as the primary embedding and utilizing other auxiliaries to enhance the primary embedding. However, this approach often results in the joint embedding performing well on the main tasks but poorly on the auxiliary ones. To address the problem arising from the separate behavior graphs, we propose the concept of Partial Order Graphs (POG). POG defines the partial order relation of multiple behaviors and models behavior combinations as weighted edges to merge separate behavior graphs into a joint POG. Theoretical proof verifies that POG can be generalized to any given set of multiple behaviors. Based on POG, we propose the tailored Partial Order 
    
[^5]: GRILLBot在实践中的应用：部署大型语言模型以建立适应性会话任务助手的经验与权衡

    GRILLBot In Practice: Lessons and Tradeoffs Deploying Large Language Models for Adaptable Conversational Task Assistants

    [https://arxiv.org/abs/2402.07647](https://arxiv.org/abs/2402.07647)

    本论文介绍了GRILLBot在实践中的应用，该系统是用于复杂实际任务的多模态助手，并处理了开发和部署中的实际问题和挑战。作者提出了一种混合架构，利用大型语言模型和专门模型来保证任务导向的问题回答和实时任务调整的性能和低延迟，以及通过代码生成方法实现的对话状态管理。该论文对于构建适应性会话任务助手具有重要的创新和贡献。

    

    我们致力于解决构建复杂实际任务的实际多模态助手的难题。我们描述了开发和部署GRILLBot的实践性和挑战性，该系统是Alexa Prize TaskBot挑战赛中获得第一和第二名的系统（分别在2022年和2023年）。在我们的开放助手工具包（OAT）框架的基础上，我们提出了一种混合架构，利用大型语言模型（LLMs）和为需要非常低延迟的特定子任务调优的专门模型。OAT使我们能够以结构化且可部署的方式定义何时、如何以及使用哪些LLMs。对于知识驱动的问题回答和实时任务调整，我们展示了LLM在任务背景和世界知识上的推理能力超过延迟问题。对于对话状态管理，我们实现了一种代码生成方法，并展示了专门的较小模型具有84％的有效性和100倍的低延迟。总体而言，我们提供了洞见，并讨论了权衡选择。

    We tackle the challenge of building real-world multimodal assistants for complex real-world tasks. We describe the practicalities and challenges of developing and deploying GRILLBot, a leading (first and second prize winning in 2022 and 2023) system deployed in the Alexa Prize TaskBot Challenge. Building on our Open Assistant Toolkit (OAT) framework, we propose a hybrid architecture that leverages Large Language Models (LLMs) and specialised models tuned for specific subtasks requiring very low latency. OAT allows us to define when, how and which LLMs should be used in a structured and deployable manner. For knowledge-grounded question answering and live task adaptations, we show that LLM reasoning abilities over task context and world knowledge outweigh latency concerns. For dialogue state management, we implement a code generation approach and show that specialised smaller models have 84% effectiveness with 100x lower latency. Overall, we provide insights and discuss tradeoffs for de
    
[^6]: VCR: 文本检索下的视频表示方法

    VCR: Video representation for Contextual Retrieval

    [https://arxiv.org/abs/2402.07466](https://arxiv.org/abs/2402.07466)

    该论文提出了一种基于文本的方法，通过融合视觉、音频和文本特征来高效地索引和分类视频内容，并使用语义嵌入提供相关的信息和推荐，从而实现了一种直观而有吸引力的探索体验。

    

    在媒体档案中简化内容发现需要整合先进的数据表示和有效的可视化技术，以清晰地向用户传达视频主题。该系统通过利用视觉、音频和文本特征的融合来有效地导航大型视频集合，并通过基于文本的方法准确地索引和分类视频内容。此外，还使用语义嵌入来为用户提供相关的信息和推荐，从而在使用OpenAI GPT-4的主题本体图上获得直观而有吸引力的探索体验。

    Streamlining content discovery within media archives requires integrating advanced data representations and effective visualization techniques for clear communication of video topics to users. The proposed system addresses the challenge of efficiently navigating large video collections by exploiting a fusion of visual, audio, and textual features to accurately index and categorize video content through a text-based method. Additionally, semantic embeddings are employed to provide contextually relevant information and recommendations to users, resulting in an intuitive and engaging exploratory experience over our topics ontology map using OpenAI GPT-4.
    
[^7]: AraSpider：实现阿拉伯语到SQL的民主化

    AraSpider: Democratizing Arabic-to-SQL

    [https://arxiv.org/abs/2402.07448](https://arxiv.org/abs/2402.07448)

    AraSpider是首个阿拉伯语版本的Spider数据集，研究表明使用回译策略可以显著提高ChatGPT 3.5和SQLCoder模型在阿拉伯语NLP任务中的性能。

    

    本研究介绍了AraSpider，这是首个阿拉伯语版本的Spider数据集，旨在提升阿拉伯语社区中的自然语言处理（NLP）。该研究测试了四个多语言翻译模型在将英文翻译成阿拉伯语方面的有效性。另外，还评估了两个模型在从阿拉伯文本生成SQL查询方面的能力。结果表明，使用回译显著提高了ChatGPT 3.5和SQLCoder模型的表现，这两个模型在Spider数据集上被认为是最佳表现者。值得注意的是，ChatGPT 3.5展示了高质量的翻译，而SQLCoder在文本到SQL任务中表现出色。该研究强调了将上下文模式和采用回译策略纳入阿拉伯语NLP任务中以提高模型性能的重要性。此外，提供了详细的方法论以实现结果复现并将数据集翻译成其他语言，突显了研究促进的承诺。

    This study presents AraSpider, the first Arabic version of the Spider dataset, aimed at improving natural language processing (NLP) in the Arabic-speaking community. Four multilingual translation models were tested for their effectiveness in translating English to Arabic. Additionally, two models were assessed for their ability to generate SQL queries from Arabic text. The results showed that using back translation significantly improved the performance of both ChatGPT 3.5 and SQLCoder models, which are considered top performers on the Spider dataset. Notably, ChatGPT 3.5 demonstrated high-quality translation, while SQLCoder excelled in text-to-SQL tasks. The study underscores the importance of incorporating contextual schema and employing back translation strategies to enhance model performance in Arabic NLP tasks. Moreover, the provision of detailed methodologies for reproducibility and translation of the dataset into other languages highlights the research's commitment to promoting 
    
[^8]: 使用LoCo和M2-BERT进行基准测试和构建长上下文检索模型

    Benchmarking and Building Long-Context Retrieval Models with LoCo and M2-BERT

    [https://arxiv.org/abs/2402.07440](https://arxiv.org/abs/2402.07440)

    该论文介绍了LoCoV1，一个用于评估长上下文检索性能的新型基准测试，并提出了M2-BERT检索编码器，用于处理长上下文检索，解决了如何评估性能、预训练语言模型以及如何进行微调的挑战。

    

    检索管道是许多机器学习系统中的重要组成部分，在文档很长（例如10K个标记或更多）且需要在整个文本中合成信息来确定相关文档的领域中表现不佳。开发适用于这些领域的长上下文检索编码器面临三个挑战：（1）如何评估长上下文检索性能，（2）如何预训练基本语言模型以表示短上下文（对应查询）和长上下文（对应文档），以及（3）如何根据GPU内存限制下的批量大小限制对该模型进行微调。为了解决这些挑战，我们首先介绍了LoCoV1，这是一个新颖的12个任务基准测试，用于测量在不可分块或不有效的情况下的长上下文检索。接下来，我们提出了M2-BERT检索编码器，这是一个80M参数状态空间编码器模型，采用Monarch Mixer架构构建，能够进行可扩展的检索。

    Retrieval pipelines-an integral component of many machine learning systems-perform poorly in domains where documents are long (e.g., 10K tokens or more) and where identifying the relevant document requires synthesizing information across the entire text. Developing long-context retrieval encoders suitable for these domains raises three challenges: (1) how to evaluate long-context retrieval performance, (2) how to pretrain a base language model to represent both short contexts (corresponding to queries) and long contexts (corresponding to documents), and (3) how to fine-tune this model for retrieval under the batch size limitations imposed by GPU memory constraints. To address these challenges, we first introduce LoCoV1, a novel 12 task benchmark constructed to measure long-context retrieval where chunking is not possible or not effective. We next present the M2-BERT retrieval encoder, an 80M parameter state-space encoder model built from the Monarch Mixer architecture, capable of scali
    
[^9]: 用个人流行度消除推荐偏见

    Debiasing Recommendation with Personal Popularity

    [https://arxiv.org/abs/2402.07425](https://arxiv.org/abs/2402.07425)

    该论文提出了使用个人流行度来消除推荐系统中的偏见问题。传统方法没有注意到全局流行度的根本问题，而个人流行度能够更好地捕捉到个体用户的兴趣，并生成个性化的推荐。研究者设计了一个称为个人流行度感知反事实的框架，将个人流行度融入到推荐系统中。

    

    全球流行度（GP）偏见是指推荐系统在推荐物品时普遍偏向热门物品，这违背了提供个性化推荐的目标，对用户体验和推荐准确性造成了不利影响。许多方法已经被提出来减少GP偏见，但它们没有注意到GP的根本问题，即它从全局的角度考虑热门度，使用一组热门物品，因此无法捕捉到个别用户的兴趣。因此，我们提出了一种以用户为基础的物品流行度称为个人流行度（PP），通过考虑分享相似兴趣的用户来为每个用户识别不同的热门物品。由于PP模型化了个体用户的偏好，它自然可以帮助生成个性化的推荐并减少GP偏见。为了将PP融入推荐中，我们设计了一个通用的个人流行度感知反事实（PPAC）框架。

    Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a \textit{global} perspective of \textit{all users} and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named \textit{personal popularity} (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general \textit{personal popularity aware counterfactual} (PPAC) frame
    
[^10]: 在基于检索增强生成的大型语言模型中进行提示扰动

    Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models

    [https://arxiv.org/abs/2402.07179](https://arxiv.org/abs/2402.07179)

    本文研究了基于检索增强生成的大型语言模型（LLM）中提示扰动的影响，并引入了一种新的优化技术GGPP。通过GGPP，我们可以将LLMs的输出引导到特定的错误答案，并应对提示中的无关上下文。

    

    大型语言模型（LLM）的鲁棒性在其在各个领域的使用迅速增长中变得越来越重要。检索增强生成（RAG）被视为提高从LLM生成文本的可信度的方法。然而，目前对RAG-based LLMs的输出如何受到稍有不同的输入影响的研究还不够充分。在本文中，我们发现即使在提示中插入一个很短的前缀也会导致生成的输出与事实正确答案相去甚远。我们系统地评估了这类前缀对RAG的影响，并引入了一种称为Gradient Guided Prompt Perturbation（GGPP）的新型优化技术。GGPP在将RAG-based LLMs的输出引导到特定错误答案方面取得了很高的成功率。它还可以应对提示中请求忽略无关上下文的指令。我们还利用LLMs在带有和不带有GGPP扰动的提示之间的神经元激活差异来提供一种改进方法。

    The robustness of large language models (LLMs) becomes increasingly important as their use rapidly grows in a wide range of domains. Retrieval-Augmented Generation (RAG) is considered as a means to improve the trustworthiness of text generation from LLMs. However, how the outputs from RAG-based LLMs are affected by slightly different inputs is not well studied. In this work, we find that the insertion of even a short prefix to the prompt leads to the generation of outputs far away from factually correct answers. We systematically evaluate the effect of such prefixes on RAG by introducing a novel optimization technique called Gradient Guided Prompt Perturbation (GGPP). GGPP achieves a high success rate in steering outputs of RAG-based LLMs to targeted wrong answers. It can also cope with instructions in the prompts requesting to ignore irrelevant context. We also exploit LLMs' neuron activation difference between prompts with and without GGPP perturbations to give a method that improves
    
[^11]: 通过LLM-认知数据增强广义对话密集检索

    Generalizing Conversational Dense Retrieval via LLM-Cognition Data Augmentation

    [https://arxiv.org/abs/2402.07092](https://arxiv.org/abs/2402.07092)

    本文提出了一种通过LLM-认知数据增强的方法来广义对话密集检索。该方法首先生成多级增强对话，捕捉多样的对话环境。其次，通过认知感知过程减少错误生成情况，并通过难度自适应样本筛选器选择具有挑战性的样本。

    

    对话式搜索利用多轮自然语言环境来检索相关段落。现有的对话密集检索模型大多将对话视为一系列固定的问题和回答，忽视了严重的数据稀疏性问题 - 也就是说，用户可以以不同的方式进行对话，而这些备选对话是未记录的。因此，它们经常难以推广到真实场景中的多样对话。在这项工作中，我们提出了一种通过LLM-认知数据增强广义对话密集检索的框架(ConvAug)。ConvAug首先生成多级增强对话，以捕捉对话环境的多样性。受人类认知方式的启发，我们设计了一种认知感知过程，以减少错误的正例、负例和幻觉的生成。此外，我们还开发了一种难度自适应样本筛选器，用于选择复杂对话的具有挑战性的样本。

    Conversational search utilizes muli-turn natural language contexts to retrieve relevant passages. Existing conversational dense retrieval models mostly view a conversation as a fixed sequence of questions and responses, overlooking the severe data sparsity problem -- that is, users can perform a conversation in various ways, and these alternate conversations are unrecorded. Consequently, they often struggle to generalize to diverse conversations in real-world scenarios. In this work, we propose a framework for generalizing Conversational dense retrieval via LLM-cognition data Augmentation (ConvAug). ConvAug first generates multi-level augmented conversations to capture the diverse nature of conversational contexts. Inspired by human cognition, we devise a cognition-aware process to mitigate the generation of false positives, false negatives, and hallucinations. Moreover, we develop a difficulty-adaptive sample filter that selects challenging samples for complex conversations, thereby g
    
[^12]: 通过对比预训练，改善多领域B2B云解决方案匹配

    Enhancing Multi-field B2B Cloud Solution Matching via Contrastive Pre-training

    [https://arxiv.org/abs/2402.07076](https://arxiv.org/abs/2402.07076)

    通过对比预训练和多领域匹配结构，我们提出了CAMA框架来改善B2B云解决方案的匹配问题，克服了复杂特征和有限数据的挑战。

    

    云解决方案在技术行业中非常受欢迎，因为它们提供了一系列服务和工具来解决特定问题。然而，尽管它们被广泛使用，但解决方案提供商的销售团队仍然面临一个复杂的业务问题，即找到适合特定目标解决方案的合适的公司客户，现有的匹配系统尚未能够充分解决这个问题。在这项工作中，我们研究了B2B解决方案匹配问题，并确定了该场景的两个主要挑战：(1) 复杂多领域特征的建模和(2) 有限、不完整和稀疏的交易数据。为了解决这些挑战，我们提出了一个框架CAMA，它以分层多领域匹配结构为主干，并通过三种数据增强策略和对比预训练目标来弥补可用数据的不完善之处。通过对一个真实数据集进行大量实验，我们证明了...

    Cloud solutions have gained significant popularity in the technology industry as they offer a combination of services and tools to tackle specific problems. However, despite their widespread use, the task of identifying appropriate company customers for a specific target solution to the sales team of a solution provider remains a complex business problem that existing matching systems have yet to adequately address. In this work, we study the B2B solution matching problem and identify two main challenges of this scenario: (1) the modeling of complex multi-field features and (2) the limited, incomplete, and sparse transaction data. To tackle these challenges, we propose a framework CAMA, which is built with a hierarchical multi-field matching structure as its backbone and supplemented by three data augmentation strategies and a contrastive pre-training objective to compensate for the imperfections in the available data. Through extensive experiments on a real-world dataset, we demonstra
    
[^13]: 非自回归的生成模型用于排序推荐

    Non-autoregressive Generative Models for Reranking Recommendation

    [https://arxiv.org/abs/2402.06871](https://arxiv.org/abs/2402.06871)

    本研究提出了一个非自回归的生成模型用于排序推荐，在多阶段推荐系统中扮演关键角色。该模型旨在提高效率和效果，并解决稀疏训练样本和动态候选项对模型收敛性的挑战。

    

    在多阶段推荐系统中，重新排序通过建模项目之间的内部相关性起到了至关重要的作用。重新排序的关键挑战在于在排列的组合空间中探索最佳序列。最近的研究提出了生成器-评估器学习范式，生成器生成多个可行序列，评估器基于估计的列表得分选择最佳序列。生成器至关重要，而生成模型非常适合生成器函数。当前的生成模型采用自回归策略进行序列生成。然而，在实时工业系统中部署自回归模型是具有挑战性的。因此，我们提出了一个非自回归生成模型用于排序推荐（NAR4Rec），以提高效率和效果。为了解决与稀疏训练样本和动态候选项对模型收敛性的挑战，我们引入了一个m

    In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items.The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. Generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Hence, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To address challenges related to sparse training samples and dynamic candidates impacting model convergence, we introduce a m
    
[^14]: LiRank: 领英的工业规模排名模型

    LiRank: Industrial Large Scale Ranking Models at LinkedIn

    [https://arxiv.org/abs/2402.06859](https://arxiv.org/abs/2402.06859)

    LiRank是领英的一个大规模排名框架，它应用了最先进的建模架构和优化方法，并提出了新的建模改进和技术，通过A/B测试取得了有效的结果。

    

    我们介绍了LiRank，这是领英的一个大规模排名框架，它将最先进的建模架构和优化方法应用于生产。我们揭示了几个建模改进，包括Residual DCN，它在著名的DCNv2架构中添加了注意力和残差连接。我们分享了将SOTA架构组合和调优以创建统一模型的见解，包括Dense Gating、Transformers和Residual DCN。我们还提出了用于校准的新技术，并描述了如何将基于深度学习的探索/利用方法应用于生产环境。为了实现大规模排名模型的有效、生产级服务，我们详细介绍了使用量化和词汇压缩训练和压缩模型的方法。我们提供了Feed排名、职位推荐和广告点击率（CTR）预测等大规模使用案例的部署设置细节。通过阐明最有效的技术方法，我们总结了各种A/B测试的经验教训。

    We present LiRank, a large-scale ranking framework at LinkedIn that brings to production state-of-the-art modeling architectures and optimization methods. We unveil several modeling improvements, including Residual DCN, which adds attention and residual connections to the famous DCNv2 architecture. We share insights into combining and tuning SOTA architectures to create a unified model, including Dense Gating, Transformers and Residual DCN. We also propose novel techniques for calibration and describe how we productionalized deep learning based explore/exploit methods. To enable effective, production-grade serving of large ranking models, we detail how to train and compress models using quantization and vocabulary compression. We provide details about the deployment setup for large-scale use cases of Feed ranking, Jobs Recommendations, and Ads click-through rate (CTR) prediction. We summarize our learnings from various A/B tests by elucidating the most effective technical approaches. T
    
[^15]: MDGNN：多关系动态图神经网络用于全面和动态的股票投资预测

    MDGNN: Multi-Relational Dynamic Graph Neural Network for Comprehensive and Dynamic Stock Investment Prediction

    [https://arxiv.org/abs/2402.06633](https://arxiv.org/abs/2402.06633)

    提出了多关系动态图神经网络（MDGNN）框架，通过利用离散动态图全面捕捉股票之间的多方面关系及其随时间的演变，并利用Transformer结构的能力对多重关系的时间演变进行编码，从而提供了股票及其关联实体之间相互关系的完整视角。

    

    股票市场是金融系统的一个关键组成部分，但由于经济指标、财务报告、全球新闻和投资者情绪等多方面的动态和复杂关系，预测股价的变动是困难的。传统的序列方法和基于图的模型已经应用于股票价格预测，但它们在捕捉股价变动中的多方面和时间影响方面存在局限性。为了解决这些挑战，提出了多关系动态图神经网络（MDGNN）框架，它利用离散动态图全面捕捉股票之间的多方面关系及其随时间的演变。由图生成的表示提供了股票及其关联实体之间相互关系的完整视角。此外，还利用Transformer结构的能力对多重关系的时间演变进行编码。

    The stock market is a crucial component of the financial system, but predicting the movement of stock prices is challenging due to the dynamic and intricate relations arising from various aspects such as economic indicators, financial reports, global news, and investor sentiment. Traditional sequential methods and graph-based models have been applied in stock movement prediction, but they have limitations in capturing the multifaceted and temporal influences in stock price movements. To address these challenges, the Multi-relational Dynamic Graph Neural Network (MDGNN) framework is proposed, which utilizes a discrete dynamic graph to comprehensively capture multifaceted relations among stocks and their evolution over time. The representation generated from the graph offers a complete perspective on the interrelationships among stocks and associated entities. Additionally, the power of the Transformer structure is leveraged to encode the temporal evolution of multiplex relations, provid
    
[^16]: PromptCrypt: 使用表情符号对大型语言模型进行安全通信的提示加密

    PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models

    [https://arxiv.org/abs/2402.05868](https://arxiv.org/abs/2402.05868)

    PromptCrypt是一种使用表情符号对用户输入进行加密的机制，保护了大型语言模型（LLM）中用户的隐私，防止数据泄露和解密。

    

    基于云的大型语言模型（LLM）如ChatGPT在日常操作中变得越来越重要，成为各种应用程序中的重要工具。虽然这些模型在可访问性和功能性方面带来了重大好处，但它们也引入了重要的隐私问题：在云基础架构中传输和存储用户数据会产生重大的数据泄露和未经授权访问敏感信息的风险；即使数据的传输和存储被加密，LLM服务提供商仍然知道数据的真实内容，从而阻止个人或实体放心使用此类LLM服务。为了解决这些问题，本文提出了一种简单但有效的机制PromptCrypt来保护用户隐私。它使用表情符号对用户输入进行加密，然后将其发送到LLM，有效地使其对人类或LLM的检查无法理解，同时保留原始提示的意图，从而确保用户隐私。

    Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the 
    
[^17]: 量化相似性：使用文本挖掘方法评估ChatGPT和Google Bard生成内容与生物医学文献的关联性

    Quantifying Similarity: Text-Mining Approaches to Evaluate ChatGPT and Google Bard Content in Relation to BioMedical Literature

    [https://arxiv.org/abs/2402.05116](https://arxiv.org/abs/2402.05116)

    本研究旨在通过文本挖掘方法评估ChatGPT和Google Bard生成的内容与生物医学文献之间的相似性。实验结果显示，在余弦文档相似性方面，ChatGPT表现优于Google Bard。

    

    背景：在大语言模型（LLMs）的支持下，生成式人工智能工具的出现展示了强大的生成内容能力。到目前为止，评估通过所谓的提示工程生成的内容的有用性已经成为一个有趣的研究问题。目标：通过提示工程的平均值，我们评估这些内容与科学家产生的真实文献的相似性和接近程度。方法：在这个探索性分析中，（1）我们通过提示工程来生成ChatGPT和Google Bard的临床内容，以便与文献对应内容进行比较，（2）我们通过比较所生成内容与生物医学文献对应内容的相似性来评估它们之间的相似性。我们的方法是使用文本挖掘方法比较文档和相关的二元组，并使用网络分析来评估术语的中心性。结果：实验表明，ChatGPT在余弦文档相似性方面表现优于Google Bard（38%对34%），

    Background: The emergence of generative AI tools, empowered by Large Language Models (LLMs), has shown powerful capabilities in generating content. To date, the assessment of the usefulness of such content, generated by what is known as prompt engineering, has become an interesting research question. Objectives Using the mean of prompt engineering, we assess the similarity and closeness of such contents to real literature produced by scientists. Methods In this exploratory analysis, (1) we prompt-engineer ChatGPT and Google Bard to generate clinical content to be compared with literature counterparts, (2) we assess the similarities of the contents generated by comparing them with counterparts from biomedical literature. Our approach is to use text-mining approaches to compare documents and associated bigrams and to use network analysis to assess the terms' centrality. Results The experiments demonstrated that ChatGPT outperformed Google Bard in cosine document similarity (38% to 34%), 
    
[^18]: 隐藏您的模型：一种无需参数传输的联邦推荐系统

    Hide Your Model: A Parameter Transmission-free Federated Recommender System

    [https://arxiv.org/abs/2311.14968](https://arxiv.org/abs/2311.14968)

    提出了一种无需参数传输的联邦推荐系统，解决了全局共享模型和高维参数传输的问题。

    

    随着对用户数据隐私的担忧日益增长，联邦推荐系统（FedRec）由于其保护隐私的能力而近来受到重视。现有的FedRec通常遵循一种学习协议，即中央服务器与客户端共享全局推荐模型，并通过频繁通信模型的公共参数来实现协作学习。然而，这种学习框架有两个缺点，限制了其实际可用性：（1）它需要一个全局共享的推荐模型；然而，在现实场景中，与推荐模型相关的信息，包括其算法和参数，构成了平台的知识产权。因此，服务提供商不太可能主动发布此类信息。（2）模型参数传输的通信成本昂贵，因为模型参数通常是高维矩阵。随着模型大小的增加，通信成本也随之增加。

    With the growing concerns regarding user data privacy, Federated Recommender System (FedRec) has garnered significant attention recently due to its privacy-preserving capabilities. Existing FedRecs generally adhere to a learning protocol in which a central server shares a global recommendation model with clients, and participants achieve collaborative learning by frequently communicating the model's public parameters. Nevertheless, this learning framework has two drawbacks that limit its practical usability: (1) It necessitates a global-sharing recommendation model; however, in real-world scenarios, information related to the recommender model, including its algorithm and parameters, constitutes the platforms' intellectual property. Hence, service providers are unlikely to release such information actively. (2) The communication costs of model parameter transmission are expensive since the model parameters are usually high-dimensional matrices. With the model size increasing, the commu
    
[^19]: 利用上下文线索和角色相关性提升文档级事件论证提取

    Utilizing Contextual Clues and Role Correlations for Enhancing Document-level Event Argument Extraction

    [https://arxiv.org/abs/2310.05116](https://arxiv.org/abs/2310.05116)

    本文提出了CARLG模型，通过利用上下文线索和角色相关性，提升了文档级事件论证提取的性能。

    

    文档级事件论证提取（EAE）是信息提取中至关重要但具有挑战性的子任务之一。现有方法大多关注论证和事件触发器之间的交互，忽视了两个关键点：上下文线索的信息和论证角色之间的语义相关性。本文提出了CARLG模型，包括两个模块：上下文线索聚合（CCA）和基于角色的潜在信息引导（RLIG），通过有效利用上下文线索和角色相关性来提高文档级EAE。CCA模块通过利用来自预训练编码器的上下文注意权重，自适应地捕捉和整合上下文线索。RLIG模块通过角色交互编码捕捉语义相关性，并通过潜在角色表示提供宝贵的信息引导。值得注意的是，我们的CCA和RLIG模块紧凑、可移植且高效，引入的新参数不超过1%，且易于实现。

    Document-level event argument extraction (EAE) is a vital but challenging subtask in information extraction. Most existing approaches focus on the interaction between arguments and event triggers, ignoring two critical points: the information of contextual clues and the semantic correlations among argument roles. In this paper, we propose the CARLG model, which consists of two modules: Contextual Clues Aggregation (CCA) and Role-based Latent Information Guidance (RLIG), effectively leveraging contextual clues and role correlations for improving document-level EAE. The CCA module adaptively captures and integrates contextual clues by utilizing context attention weights from a pre-trained encoder. The RLIG module captures semantic correlations through role-interactive encoding and provides valuable information guidance with latent role representation. Notably, our CCA and RLIG modules are compact, transplantable and efficient, which introduce no more than 1% new parameters and can be eas
    
[^20]: 通过执行反馈使语言模型成为更好的工具学习者

    Making Language Models Better Tool Learners with Execution Feedback

    [https://arxiv.org/abs/2305.13068](https://arxiv.org/abs/2305.13068)

    这篇论文提出了一个名为TRICE的框架，通过执行反馈实现语言模型的工具学习，使其能够学会何时以及如何有效地使用工具。

    

    工具作为关键的界面，使人类能够理解和改变环境。随着基础模型的出现，AI系统可以利用工具扩展其能力并与真实世界互动。现有的工具学习方法包括监督微调和提示工程方法，通常使大型语言模型不加选择地利用工具，因为复杂任务往往超出了它们自身的能力。然而，为简单任务引入工具（模型本身可以轻松解决的任务），可能会无意间传播错误而不是提高性能。因此，研究问题是：我们能否教会语言模型何时以及如何使用工具？为满足这个需求，我们提出了Tool leaRning wIth exeCution fEedback (TRICE)，这是一个两阶段的端到端框架，使模型能够通过从工具执行中得到的反馈不断学习，从而学会何时以及如何有效地使用工具。

    Tools serve as pivotal interfaces that enable humans to understand and reshape the environment. With the advent of foundation models, AI systems can utilize tools to expand their capabilities and interact with the real world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex tasks often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance. This leads to the research question: can we teach language models when and how to use tools? To meet this need, we propose Tool leaRning wIth exeCution fEedback (TRICE), a two-stage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively. Experimental results, backed b
    
[^21]: 可扩展的分布式图上神经网络训练

    Scalable Neural Network Training over Distributed Graphs

    [https://arxiv.org/abs/2302.13053](https://arxiv.org/abs/2302.13053)

    RETEXO是第一个消除分布式图神经网络训练中通信瓶颈的框架，通过新的训练过程懒消息传递来改善网络通信效率。

    

    图神经网络（GNN）在涉及图结构数据的各种机器学习任务中发挥着重要作用，包括预测蛋白质结构和提供个性化推荐等。实际世界中的图数据往往需要分布式存储在许多计算机上，原因不仅是因为容量限制，还有数据所在地或隐私法律的要求。在这种设置中，网络通信成本很高，成为训练GNN的主要瓶颈。迄今为止，分布式GNN训练的优化主要针对数据级别的改进，例如缓存、网络感知划分和子采样等，这些方法适用于数据中心类似的设置，其中图数据对单个实体可访问且数据传输成本被忽略。我们提出了RETEXO，这是一种可以消除分布式GNN训练中严重通信瓶颈的首个框架，同时尊重任何给定的数据分区配置。关键是通过一种新的训练过程，即懒消息传递，重新排序了消息传递的顺序。

    Graph neural networks (GNNs) fuel diverse machine learning tasks involving graph-structured data, ranging from predicting protein structures to serving personalized recommendations. Real-world graph data must often be stored distributed across many machines not just because of capacity constraints, but because of compliance with data residency or privacy laws. In such setups, network communication is costly and becomes the main bottleneck to train GNNs. Optimizations for distributed GNN training have targeted data-level improvements so far -- via caching, network-aware partitioning, and sub-sampling -- that work for data center-like setups where graph data is accessible to a single entity and data transfer costs are ignored.   We present RETEXO, the first framework which eliminates the severe communication bottleneck in distributed GNN training while respecting any given data partitioning configuration. The key is a new training procedure, lazy message passing, that reorders the sequen
    
[^22]: 一种纯粹规则的非规则核心跨度生成方法

    A Purely Regular Approach to Non-Regular Core Spanners

    [https://arxiv.org/abs/2010.13442](https://arxiv.org/abs/2010.13442)

    本文提出了一种纯粹规则的非规则核心跨度生成方法，通过将字符串相等选择直接纳入底层规则语言中，可以得到具有略微较弱表达能力的核心跨度生成器的片段。

    

    规则跨度生成器是通过vset-自动机特征化的，它们对并集、连接和投影等代数操作封闭，并具有理想的算法属性。核心跨度生成器作为IBM SystemT中查询语言AQL的核心功能的形式化引入，除了需要字符串相等选择外，还被证明会导致静态分析和查询评估中典型问题的高复杂性甚至不可判定性。我们提出了一种替代性的核心跨度生成方法：将字符串相等选择直接纳入表示底层规则跨度生成器的规则语言中（而不是将其视为在规则跨度生成器提取的表上的代数操作），我们得到了一个具有略微较弱表达能力的核心跨度生成器的片段。

    The regular spanners (characterised by vset-automata) are closed under the algebraic operations of union, join and projection, and have desirable algorithmic properties. The core spanners (introduced by Fagin, Kimelfeld, Reiss, and Vansummeren (PODS 2013, JACM 2015) as a formalisation of the core functionality of the query language AQL used in IBM's SystemT) additionally need string-equality selections and it has been shown by Freydenberger and Holldack (ICDT 2016, Theory of Computing Systems 2018) that this leads to high complexity and even undecidability of the typical problems in static analysis and query evaluation. We propose an alternative approach to core spanners: by incorporating the string-equality selections directly into the regular language that represents the underlying regular spanner (instead of treating it as an algebraic operation on the table extracted by the regular spanner), we obtain a fragment of core spanners that, while having slightly weaker expressive power t
    
[^23]: 挑战社交推荐中的低同质性

    Challenging Low Homophily in Social Recommendation. (arXiv:2401.14606v1 [cs.IR])

    [http://arxiv.org/abs/2401.14606](http://arxiv.org/abs/2401.14606)

    本研究挑战了社交推荐中的低同质性问题，提出了Social Heterophily-alleviating Rewiring (SHaRe)框架，用于增强现有的基于图的社交推荐模型。通过捕捉高同质的社交关系并剪切低同质关系，该框架有效提取了偏好感知同质性信息，解决了社交推荐中的信息冗余问题。

    

    在社交推荐中，利用社交关系来解决用户-物品交互数据稀疏性问题，基于社交同质性的假设。然而，社交推荐范式主要关注基于用户偏好的同质性。虽然社交信息可以增强推荐效果，但它与用户偏好的一致性并不保证，从而可能引入信息冗余。我们经验性地发现，真实的推荐数据中的社交图展现出低偏好感知的同质性，这限制了社交推荐模型的作用。为了全面提取社交图中潜在的偏好感知同质性信息，我们提出了Social Heterophily-alleviating Rewiring (SHaRe)，这是一个以数据为中心的框架，用于增强现有基于图的社交推荐模型。我们采用图重连技术来捕捉和添加高度同质的社交关系，并剪切低同质（或异质）关系。为了更好地优化从社交图中提取的推荐模式的刻画，我们还引入基于图的用户偏好分布修正方法。

    Social relations are leveraged to tackle the sparsity issue of user-item interaction data in recommendation under the assumption of social homophily. However, social recommendation paradigms predominantly focus on homophily based on user preferences. While social information can enhance recommendations, its alignment with user preferences is not guaranteed, thereby posing the risk of introducing informational redundancy. We empirically discover that social graphs in real recommendation data exhibit low preference-aware homophily, which limits the effect of social recommendation models. To comprehensively extract preference-aware homophily information latent in the social graph, we propose Social Heterophily-alleviating Rewiring (SHaRe), a data-centric framework for enhancing existing graph-based social recommendation models. We adopt Graph Rewiring technique to capture and add highly homophilic social relations, and cut low homophilic (or heterophilic) relations. To better refine the u
    
[^24]: CIDER: 基于类别引导的意图分离方法用于准确的个性化新闻推荐

    CIDER: Category-Guided Intent Disentanglement for Accurate Personalized News Recommendation. (arXiv:2310.09401v1 [cs.IR])

    [http://arxiv.org/abs/2310.09401](http://arxiv.org/abs/2310.09401)

    CIDER是一种基于类别引导的个性化新闻推荐框架，通过意图分离和一致性的新闻表示来准确理解新闻文章的多个意图，并区分用户不同的后阅读偏好。

    

    个性化新闻推荐旨在帮助用户找到与其兴趣相符的新闻文章，这在缓解用户信息过载问题方面起到至关重要的作用。尽管许多最近的研究致力于改进用户和新闻的表示方法，但以下挑战很少被研究：（C1）如何准确理解一篇新闻文章中包含的多个意图？以及（C2）如何区分用户点击历史中对新闻文章有不同后阅读偏好的情况？为了同时解决这两个挑战，在本文中，我们提出了一种新的个性化新闻推荐框架（CIDER），它利用（1）基于类别引导的意图分离来解决（C1）和（2）基于一致性的新闻表示来解决（C2）。此外，我们将类别预测纳入CIDER的训练过程作为辅助任务，这提供了额外的监督信号，以增强意图分离。在两个真实数据集上进行了广泛的实验。

    Personalized news recommendation aims to assist users in finding news articles that align with their interests, which plays a pivotal role in mitigating users' information overload problem. Although many recent works have been studied for better user and news representations, the following challenges have been rarely studied: (C1) How to precisely comprehend a range of intents coupled within a news article? and (C2) How to differentiate news articles with varying post-read preferences in users' click history? To tackle both challenges together, in this paper, we propose a novel personalized news recommendation framework (CIDER) that employs (1) category-guided intent disentanglement for (C1) and (2) consistency-based news representation for (C2). Furthermore, we incorporate a category prediction into the training process of CIDER as an auxiliary task, which provides supplementary supervisory signals to enhance intent disentanglement. Extensive experiments on two real-world datasets rev
    
[^25]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^26]: DAPR：文档感知段落检索的基准测试

    DAPR: A Benchmark on Document-Aware Passage Retrieval. (arXiv:2305.13915v1 [cs.IR])

    [http://arxiv.org/abs/2305.13915](http://arxiv.org/abs/2305.13915)

    DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。

    

    最近的神经检索主要关注短文本的排名，并且在处理长文档方面存在挑战。现有的工作主要评估排名段落或整个文档。然而，许多情况下，用户希望从庞大的语料库中找到长文档中的相关段落，例如法律案例，研究论文等，此时段落往往提供很少的文档上下文，这就挑战了当前的方法找到正确的文档并返回准确的结果。为了填补这个空白，我们提出并命名了Document-Aware Passage Retrieval（DAPR）任务，并构建了一个包括来自不同领域的多个数据集的基准测试，涵盖了DAPR和整个文档检索。在实验中，我们通过不同的方法，包括在文档摘要中添加文档级别的内容，汇总段落表示和使用BM25进行混合检索，扩展了最先进的神经段落检索器。这个混合检索系统，总体基准测试显示，我们提出的DAPR任务是一个具有挑战性和重要性的问题，需要进一步研究。

    Recent neural retrieval mainly focuses on ranking short texts and is challenged with long documents. Existing work mainly evaluates either ranking passages or whole documents. However, there are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. legal cases, research papers, etc. In this scenario, the passage often provides little document context and thus challenges the current approaches to finding the correct document and returning accurate results. To fill this gap, we propose and name this task Document-Aware Passage Retrieval (DAPR) and build a benchmark including multiple datasets from various domains, covering both DAPR and whole-document retrieval. In experiments, we extend the state-of-the-art neural passage retrievers with document-level context via different approaches including prepending document summary, pooling over passage representations, and hybrid retrieval with BM25. The hybrid-retrieval systems, the overall b
    

