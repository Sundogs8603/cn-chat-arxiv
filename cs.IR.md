# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Robust Calibrate Proxy Loss for Deep Metric Learning.](http://arxiv.org/abs/2304.09162) | 本研究提出了一种新的 Calibrate Proxy 结构，通过利用实际样本信息改善了基于代理的损失相似性计算，引入一个校准损失来约束代理优化方向类别特征中心。实验证明了该方法在多个数据集上都取得了较好表现。 |
| [^2] | [Perspectives on Large Language Models for Relevance Judgment.](http://arxiv.org/abs/2304.09161) | 本文讨论了LLMs协助人类专家进行相关性判断的可能方法和问题，制定了人机协作谱系，提供了一个基于LLM的相关性判断与经过训练的人类评估者判断相关性的初步实验，以及支持和反对使用LLMs进行自动相关性判断的两个对立观点以及妥协的观点。 |
| [^3] | [Practical Lessons on Optimizing Sponsored Products in eCommerce.](http://arxiv.org/abs/2304.09107) | 本文提出了一个实用的机器学习框架，可以解决电商广告系统中赞助产品优化的多个问题，而不需要改变现有机器学习模型结构。使用该框架可以处理广告系统中的长期问题，并为多个评估指标带来增量。 |
| [^4] | [Exploring 360-Degree View of Customers for Lookalike Modeling.](http://arxiv.org/abs/2304.09105) | 该论文提出了一个能将客户360度视角的不同行为或特征，在此基础上构建出类似模型以改善客户定位的框架。实验结果表明，该模型在电商和旅游领域中能够有效发挥作用。 |
| [^5] | [MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices.](http://arxiv.org/abs/2304.09099) | 该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。 |
| [^6] | [Sheaf Neural Networks for Graph-based Recommender Systems.](http://arxiv.org/abs/2304.09097) | 基于Sheaf神经网络的模型提出了一种新的向量空间表示方法，使得其在基准推荐任务上获得最先进的性能表现。 |
| [^7] | [Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism.](http://arxiv.org/abs/2304.09096) | 本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，采用输出扰动的高斯机制实现差分隐私，通过Rényi差分隐私对整体隐私损失进行特征化，在保护用户隐私的同时实现了推荐系统功能。 |
| [^8] | [Improving Items and Contexts Understanding with Descriptive Graph for Conversational Recommendation.](http://arxiv.org/abs/2304.09093) | KLEVER是一个新的CRS框架，可以将物品和它们相关的上下文单词联合建模在同一语义空间中，解决了以前工作中的物品和单词语义空间不对齐的问题。 |
| [^9] | [A Field Test of Bandit Algorithms for Recommendations: Understanding the Validity of Assumptions on Human Preferences in Multi-armed Bandits.](http://arxiv.org/abs/2304.09088) | 本研究采用漫画推荐MAB设置，与众包工作者对关键MAB假设的有效性进行研究，结果挑战了这些假设，强调了需要进行更多关于MAB推荐中这些假设的实证工作。 |
| [^10] | [MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed.](http://arxiv.org/abs/2304.09087) | 本研究提出了一种名为MDDL的多通道深度确定性策略梯度学习框架，旨在整合多种策略，以增强位置分配的强化学习模型训练。该框架在在线和离线性能方面表现优于一些最先进的方法。 |
| [^11] | [Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations.](http://arxiv.org/abs/2304.09085) | 本文提出了利用无偏评分平衡已有的去偏方法来对抗未观测混淆和模型规范误差的方法。 |
| [^12] | [DRIFT: A Federated Recommender System with Implicit Feedback on the Items.](http://arxiv.org/abs/2304.09084) | DRIFT是一个联邦推荐系统架构，使用隐式反馈，以保护用户隐私，并使用SAROS算法实现精准推荐。 |
| [^13] | [Unsupervised clustering of file dialects according to monotonic decompositions of mixtures.](http://arxiv.org/abs/2304.09082) | 本文提出了一种无监督分类方法，即将一组文件分成不同的方言，其中方言由其行为模式组成。提出了一种贪心算法从文件-消息数据矩阵的数据集中推断出候选方言，并证明了该算法是最优时的条件。 |
| [^14] | [Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction.](http://arxiv.org/abs/2304.09062) | 本文提出了一种面向CTR预测的漂移感知增量学习框架。该框架基于集成学习，通过显式的基于误差的漂移检测来解决CTR预测中的灾难性遗忘问题。 |
| [^15] | [A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services.](http://arxiv.org/abs/2304.09061) | 本论文提出了一个通用框架，它基于表示-聚合策略构建可扩展但有效的APC模型，用于大规模应用，可以包括各种表示学习和序列建模技术。 |
| [^16] | [Revisiting k-NN for Pre-trained Language Models.](http://arxiv.org/abs/2304.09058) | 本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。 |
| [^17] | [CodeKGC: Code Language Model for Generative Knowledge Graph Construction.](http://arxiv.org/abs/2304.09048) | 本文提出了一种使用代码语言模型处理生成式知识图谱构建任务的方法，能够有效利用知识图谱内的语义结构，提高模型的可解释性。 |
| [^18] | [Generalized Weak Supervision for Neural Information Retrieval.](http://arxiv.org/abs/2304.08912) | 本文提出了一种名为广义弱监督学习(GWS)的解决方案，它能够迭代地使用现有的排序模型(弱标注器)产生大量的训练数据，无需手动标注就能显著提高排序性能。 |
| [^19] | [Dual-Ganularity Contrastive Learning for Session-based Recommendation.](http://arxiv.org/abs/2304.08873) | 本文提出一种基于双粒度对比学习的会话推荐系统，通过引入多粒度CL框架和新的CL策略，能够有效地捕捉会话之间微小的差异，并优于现有最先进的方法。 |
| [^20] | [eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems.](http://arxiv.org/abs/2304.08597) | eTOP框架可以在任何AutoML系统之上工作，并决定是否将执行管道到最后或在中间步骤终止以更快地训练模型。 |
| [^21] | [CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems.](http://arxiv.org/abs/2304.08562) | CAM2是一个面向大规模推荐系统的一致性感知多任务排名模型，通过利用因果建模系统地解开用户对流行物品的一致性与他们真正兴趣的联系，来消除历史用户交互数据带来的一致性偏见，并在实践中得到有效的应用。 |
| [^22] | [Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders.](http://arxiv.org/abs/2304.01016) | 本文提出了一种通过结构压缩和模型尺寸不对称的双编码器模型 KALE，有效提高密集信息检索的推理效率，同时允许查询编码器的有效压缩，而无需进行全部的再训练或索引生成，此方法能够生成超过DistilBERT性能的模型。 |
| [^23] | [Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models.](http://arxiv.org/abs/2209.06506) | 本研究提出了一种模拟黑盒神经排名模型的对抗攻击，可被黑帽SEO用来打败更好防护的搜索引擎。 |
| [^24] | [PMC-Patients: A Large-scale Dataset of Patient Summaries and Relations for Benchmarking Retrieval-based Clinical Decision Support Systems.](http://arxiv.org/abs/2202.13876) | 本文提出了一个名为“PMC-Patients”的新数据集，用于定义和测试病患到文章的检索（ReCDS-PAR）和病患到病患的检索（ReCDS-PPR），以评估基于召回的临床决策支持系统（ReCDS）的性能。PMC-Patients数据集涵盖逾10,000名病患信息和27,000篇PubMed Central文章，并展示了多种ReCDS系统的效果分析和20个案例的实用性分析。 |
| [^25] | [Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective.](http://arxiv.org/abs/2202.08063) | 低资源情境下，如何让知识抽取更好地从非结构化文本中提取信息？本文调研了三种解决范式：高资源数据、更强的模型和数据与模型的结合，提出了未来的研究方向。 |
| [^26] | [An Optimal Algorithm for Finding Champions in Tournament Graphs.](http://arxiv.org/abs/2111.13621) | 本文提出了一种在完成最少比赛的前提下寻找锦标赛图中冠军（Copeland获胜者）的最优算法，该算法可以加速信息检索和推荐系统应用，这对于进行循环赛的机器学习模型具有重要的意义，能减少模型推理的数量。 |
| [^27] | [Sparse Bayesian Learning Approach for Discrete Signal Reconstruction.](http://arxiv.org/abs/1906.00309) | 本研究提出了一种新的离散化先验，将其与稀疏贝叶斯学习框架和变分贝叶斯推理方法相结合，设计了一种交替优化算法，可以有效解决离散信号重建问题，并且具有显著的性能提高。 |

# 详细

[^1]: 深度度量学习的鲁棒性校准代理损失

    Robust Calibrate Proxy Loss for Deep Metric Learning. (arXiv:2304.09162v1 [cs.IR])

    [http://arxiv.org/abs/2304.09162](http://arxiv.org/abs/2304.09162)

    本研究提出了一种新的 Calibrate Proxy 结构，通过利用实际样本信息改善了基于代理的损失相似性计算，引入一个校准损失来约束代理优化方向类别特征中心。实验证明了该方法在多个数据集上都取得了较好表现。

    

    深度度量学习中，主流研究可分为两种：基于代理的方法和基于成对的方法。基于代理的方法由于训练复杂度低、网络收敛快速而受到广泛关注。然而，这些方法的局限在于代理优化由网络完成，使得难以准确地表示数据实际类别的特征分布情况。本文提出了一种 Calibrate Proxy（CP）结构，利用实际样本信息改善了基于代理的损失的相似度计算，并引入了校准损失来约束代理优化朝向类别特征中心。同时，我们为每个类别设置了少量代理以减轻类内差异对检索性能的影响。通过在三个公共数据集和多个合成标签噪声数据集上进行了广泛的实验评估了我们方法的有效性。

    The mainstream researche in deep metric learning can be divided into two genres: proxy-based and pair-based methods. Proxy-based methods have attracted extensive attention due to the lower training complexity and fast network convergence. However, these methods have limitations as the poxy optimization is done by network, which makes it challenging for the proxy to accurately represent the feature distrubtion of the real class of data. In this paper, we propose a Calibrate Proxy (CP) structure, which uses the real sample information to improve the similarity calculation in proxy-based loss and introduces a calibration loss to constraint the proxy optimization towards the center of the class features. At the same time, we set a small number of proxies for each class to alleviate the impact of intra-class differences on retrieval performance. The effectiveness of our method is evaluated by extensive experiments on three public datasets and multiple synthetic label-noise datasets. The res
    
[^2]: 大型语言模型在相关性评价中的应用

    Perspectives on Large Language Models for Relevance Judgment. (arXiv:2304.09161v1 [cs.IR])

    [http://arxiv.org/abs/2304.09161](http://arxiv.org/abs/2304.09161)

    本文讨论了LLMs协助人类专家进行相关性判断的可能方法和问题，制定了人机协作谱系，提供了一个基于LLM的相关性判断与经过训练的人类评估者判断相关性的初步实验，以及支持和反对使用LLMs进行自动相关性判断的两个对立观点以及妥协的观点。

    

    当被问及时，像ChatGPT这样的当前大型语言模型（LLMs）声称它们可以协助我们进行相关性判断。许多研究人员认为这不会导致可信的信息检索研究。在本文中，我们讨论了LLMs协助人类专家进行相关性判断的可能方法以及可能出现的问题和关注点。我们制定了一个人机协作谱系，可以将不同的相关性判断策略进行分类，基于人类对机器的依赖程度。针对“完全自动化评估”的极端点，我们进一步进行了基于LLM的相关性判断与经过训练的人类评估者判断的相关性的初步实验。我们通过分析文献、我们的初步实验证据以及我们作为信息检索研究人员的经验，提出了支持和反对使用LLMs进行自动相关性判断的两个对立观点以及妥协的观点。我们希望开始进行建设性的讨论。

    When asked, current large language models (LLMs) like ChatGPT claim that they can assist us with relevance judgments. Many researchers think this would not lead to credible IR research. In this perspective paper, we discuss possible ways for LLMs to assist human experts along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows categorizing different relevance judgment strategies, based on how much the human relies on the machine. For the extreme point of "fully automated assessment", we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing two opposing perspectives - for and against the use of LLMs for automatic relevance judgments - and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.  We hope to start a constructive discussion withi
    
[^3]: 电商中优化赞助产品的实践经验

    Practical Lessons on Optimizing Sponsored Products in eCommerce. (arXiv:2304.09107v1 [cs.IR])

    [http://arxiv.org/abs/2304.09107](http://arxiv.org/abs/2304.09107)

    本文提出了一个实用的机器学习框架，可以解决电商广告系统中赞助产品优化的多个问题，而不需要改变现有机器学习模型结构。使用该框架可以处理广告系统中的长期问题，并为多个评估指标带来增量。

    

    本文研究了赞助产品优化中的多个问题，包括基于位置的去偏差、点击-转化多任务学习以及预测点击率的校准。我们提出了一个实用的机器学习框架，可以解决这些问题，而不需要改变现有机器学习模型的结构，因此可以与大多数机器学习模型结合使用（包括浅层模型，如梯度提升决策树、支持向量机）。在本文中，我们首先提出了数据和特征工程技术，以处理广告系统中的上述问题; 然后，我们评估了我们的实用框架在来自在线购物网站流量日志的实际数据集上的效益。我们表明，我们的提议的实用框架与数据和特征工程也可以处理广告系统中的长期问题，并为多个评估指标带来增量。

    In this paper, we study multiple problems from sponsored product optimization in ad system, including position-based de-biasing, click-conversion multi-task learning, and calibration on predicted click-through-rate (pCTR). We propose a practical machine learning framework that provides the solutions to such problems without structural change to existing machine learning models, thus can be combined with most machine learning models including shallow models (e.g. gradient boosting decision trees, support vector machines). In this paper, we first propose data and feature engineering techniques to handle the aforementioned problems in ad system; after that, we evaluate the benefit of our practical framework on real-world data sets from our traffic logs from online shopping site. We show that our proposed practical framework with data and feature engineering can also handle the perennial problems in ad systems and bring increments to multiple evaluation metrics.
    
[^4]: 探究客户360度视角实现类似建模

    Exploring 360-Degree View of Customers for Lookalike Modeling. (arXiv:2304.09105v1 [cs.IR])

    [http://arxiv.org/abs/2304.09105](http://arxiv.org/abs/2304.09105)

    该论文提出了一个能将客户360度视角的不同行为或特征，在此基础上构建出类似模型以改善客户定位的框架。实验结果表明，该模型在电商和旅游领域中能够有效发挥作用。

    

    类似建模是基于用户相似性对产品销售和扩展广告活动起到重要作用的假设。这项工作的挑战在于用户群体的异质性和其稀疏性。我们提出了一个新的框架，将客户的不同行为或特征（如人口统计信息、在不同平台上的购买行为、客户忠诚行为）统一起来，构建了一个类似模型，以改善乐天集团的客户定位。真实的电子商务和旅游数据集上的广泛实验表明，我们提出的类似模型对于用户定位任务非常有效。

    Lookalike models are based on the assumption that user similarity plays an important role towards product selling and enhancing the existing advertising campaigns from a very large user base. Challenges associated to these models reside on the heterogeneity of the user base and its sparsity. In this work, we propose a novel framework that unifies the customers different behaviors or features such as demographics, buying behaviors on different platforms, customer loyalty behaviors and build a lookalike model to improve customer targeting for Rakuten Group, Inc. Extensive experiments on real e-commerce and travel datasets demonstrate the effectiveness of our proposed lookalike model for user targeting task.
    
[^5]: MATURE-HEALTH: MAndatory FeaTURE选择的健康推荐系统

    MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices. (arXiv:2304.09099v1 [cs.IR])

    [http://arxiv.org/abs/2304.09099](http://arxiv.org/abs/2304.09099)

    该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。

    

    平衡电解质对于人体器官的适当功能至关重要和必不可少，因为电解质失衡可能是潜在病理生理学发展的指示。高效监测电解质失衡不仅可以增加疾病早期检测的机会，而且可以通过严格遵循营养控制饮食以平衡电解质从而防止健康进一步恶化。本研究提出并实施了一个推荐系统MATURE Health，该系统预测血液中必需电解质和其他物质的不平衡，然后推荐含有平衡营养的食物，以避免电解质不平衡的发生。该模型考虑到用户最近的实验室结果和每日食物摄入量来预测电解质不平衡。MATURE Health依赖于MATURE Food算法推荐食物，后者仅推荐那些

    Balancing electrolytes is utmost important and essential for appropriate functioning of organs in human body as electrolytes imbalance can be an indication of the development of underlying pathophysiology. Efficient monitoring of electrolytes imbalance not only can increase the chances of early detection of disease, but also prevents the further deterioration of the health by strictly following nutrient controlled diet for balancing the electrolytes post disease detection. In this research, a recommender system MATURE Health is proposed and implemented, which predicts the imbalance of mandatory electrolytes and other substances presented in blood and recommends the food items with the balanced nutrients to avoid occurrence of the electrolytes imbalance. The proposed model takes user most recent laboratory results and daily food intake into account to predict the electrolytes imbalance. MATURE Health relies on MATURE Food algorithm to recommend food items as latter recommends only those
    
[^6]: 基于Sheaf神经网络的基于图的推荐系统

    Sheaf Neural Networks for Graph-based Recommender Systems. (arXiv:2304.09097v1 [cs.IR])

    [http://arxiv.org/abs/2304.09097](http://arxiv.org/abs/2304.09097)

    基于Sheaf神经网络的模型提出了一种新的向量空间表示方法，使得其在基准推荐任务上获得最先进的性能表现。

    

    近年来，Graph神经网络在许多应用中得到了广泛应用，包括推荐系统。Graph神经网络对其他方法的优越性在于，推荐系统中的许多问题可以自然地建模为图，其中节点可以是用户或项目，边代表偏好关系。 在当前的Graph神经网络方法中，节点用在训练时学习到的静态向量表示。这种静态向量可能只适用于捕捉定义它们的一些用户或项目的微妙差别。为了克服这个限制，我们建议使用最近提出的启发范畴论的模型：Sheaf神经网络。Sheaf神经网络及其连接的拉普拉斯可以通过将每个节点（以及边）与向量空间而不是单个向量相关联来解决上述问题。向量空间表示更丰富，并允许在推理时选择正确的表示。这种方法使我们的模型更具表现力和灵活性，在几个基准推荐任务上实现了最先进的性能。

    Recent progress in Graph Neural Networks has resulted in wide adoption by many applications, including recommendation systems. The reason for Graph Neural Networks' superiority over other approaches is that many problems in recommendation systems can be naturally modeled as graphs, where nodes can be either users or items and edges represent preference relationships. In current Graph Neural Network approaches, nodes are represented with a static vector learned at training time. This static vector might only be suitable to capture some of the nuances of users or items they define. To overcome this limitation, we propose using a recently proposed model inspired by category theory: Sheaf Neural Networks. Sheaf Neural Networks, and its connected Laplacian, can address the previous problem by associating every node (and edge) with a vector space instead than a single vector. The vector space representation is richer and allows picking the proper representation at inference time. This approa
    
[^7]: 基于高斯机制的保护隐私矩阵分解推荐系统

    Privacy-Preserving Matrix Factorization for Recommendation Systems using Gaussian Mechanism. (arXiv:2304.09096v1 [cs.IR])

    [http://arxiv.org/abs/2304.09096](http://arxiv.org/abs/2304.09096)

    本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，采用输出扰动的高斯机制实现差分隐私，通过Rényi差分隐私对整体隐私损失进行特征化，在保护用户隐私的同时实现了推荐系统功能。

    

    建立推荐系统需要分析用户数据，这可能会泄露用户的个人信息。匿名化用户数据通常不足以保护用户隐私。鉴于此，本文提出了一种基于差分隐私框架和矩阵分解的保护隐私推荐系统，矩阵分解是最流行的推荐系统算法之一。通过差分隐私，即使对手拥有用户的公开信息，也可以防止对手提取敏感用户信息。我们采用输出扰动的高斯机制实现差分隐私并发布满足隐私定义的用户档案。我们使用Rényi差分隐私对整体隐私损失进行了紧密的特征化。我们在实验中进行了广泛的测试。

    Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. Anonymizing user data is often not sufficient for preserving user privacy. Motivated by this, we propose a privacy-preserving recommendation system based on the differential privacy framework and matrix factorization, which is one of the most popular algorithms for recommendation systems. As differential privacy is a powerful and robust mathematical framework for designing privacy-preserving machine learning algorithms, it is possible to prevent adversaries from extracting sensitive user information even if the adversary possesses their publicly available (auxiliary) information. We implement differential privacy via the Gaussian mechanism in the form of output perturbation and release user profiles that satisfy privacy definitions. We employ R\'enyi Differential Privacy for a tight characterization of the overall privacy loss. We perform extensive experiments on
    
[^8]: 基于描述性图的对话式推荐系统中的物品和上下文理解改进

    Improving Items and Contexts Understanding with Descriptive Graph for Conversational Recommendation. (arXiv:2304.09093v1 [cs.IR])

    [http://arxiv.org/abs/2304.09093](http://arxiv.org/abs/2304.09093)

    KLEVER是一个新的CRS框架，可以将物品和它们相关的上下文单词联合建模在同一语义空间中，解决了以前工作中的物品和单词语义空间不对齐的问题。

    

    对话式推荐系统（CRS）在利用外部知识提高物品和上下文单词表示方面处于最前沿水平，以实现高质量的推荐和响应生成。然而，物品和单词的表示通常在两个独立的语义空间中建模，这会导致它们之间的不对齐问题。因此，当用户输入信息不足时，这将导致CRS仅实现次优排名表现。为了解决以前工作的局限性，我们提出了一个新的CRS框架KLEVER，它可以联合建模在相同语义空间中的物品和它们相关的上下文单词。特别是，我们从丰富的物品文本特征（如物品描述和类别）中构建一个物品描述性图。基于构建的描述性图，KLEVER共同学习单词和物品的嵌入，以增强推荐和对话生成的互动。

    State-of-the-art methods on conversational recommender systems (CRS) leverage external knowledge to enhance both items' and contextual words' representations to achieve high quality recommendations and responses generation. However, the representations of the items and words are usually modeled in two separated semantic spaces, which leads to misalignment issue between them. Consequently, this will cause the CRS to only achieve a sub-optimal ranking performance, especially when there is a lack of sufficient information from the user's input. To address limitations of previous works, we propose a new CRS framework KLEVER, which jointly models items and their associated contextual words in the same semantic space. Particularly, we construct an item descriptive graph from the rich items' textual features, such as item description and categories. Based on the constructed descriptive graph, KLEVER jointly learns the embeddings of the words and items, towards enhancing both recommender and d
    
[^9]: 推荐中的Bandit算法的现场测试：了解MAB中关于人类偏好假设的有效性

    A Field Test of Bandit Algorithms for Recommendations: Understanding the Validity of Assumptions on Human Preferences in Multi-armed Bandits. (arXiv:2304.09088v1 [cs.IR])

    [http://arxiv.org/abs/2304.09088](http://arxiv.org/abs/2304.09088)

    本研究采用漫画推荐MAB设置，与众包工作者对关键MAB假设的有效性进行研究，结果挑战了这些假设，强调了需要进行更多关于MAB推荐中这些假设的实证工作。

    

    个性化推荐系统渗透到现代生活中，塑造了我们读什么媒体和消费什么产品。驱动此类系统的算法往往包括基于监督学习的启发式算法，例如具有多种启发式选择的潜在因素模型。同时，有关推荐的理论处理通常涉及问题的决策理论性质，包括通过多臂赌博机（MAB）框架平衡探索和开发的需要。然而，基于MAB的方法严重依赖于人类偏好的假设。这些偏好假设很少使用人员研究进行测试，部分原因是缺乏公开可用的工具包来进行这些研究。在这项工作中，我们在漫画推荐MAB设置中与众包工作者进行研究。每个机器臂表示一个漫画类别，用户在每次推荐后提供反馈。我们检查了关键MAB假设的有效性，即人类偏好是时空具有静态性，并且可以建模为潜在收益分布的嘈杂实现。我们的研究结果挑战了这些假设，强调了需要进行更多关于MAB推荐中这些假设的实证工作。

    Personalized recommender systems suffuse modern life, shaping what media we read and what products we consume. Algorithms powering such systems tend to consist of supervised learning-based heuristics, such as latent factor models with a variety of heuristically chosen prediction targets. Meanwhile, theoretical treatments of recommendation frequently address the decision-theoretic nature of the problem, including the need to balance exploration and exploitation, via the multi-armed bandits (MABs) framework. However, MAB-based approaches rely heavily on assumptions about human preferences. These preference assumptions are seldom tested using human subject studies, partly due to the lack of publicly available toolkits to conduct such studies. In this work, we conduct a study with crowdworkers in a comics recommendation MABs setting. Each arm represents a comic category, and users provide feedback after each recommendation. We check the validity of core MABs assumptions-that human preferen
    
[^10]: MDDL: 基于强化学习的多通道Feed位置分配框架

    MDDL: A Framework for Reinforcement Learning-based Position Allocation in Multi-Channel Feed. (arXiv:2304.09087v1 [cs.IR])

    [http://arxiv.org/abs/2304.09087](http://arxiv.org/abs/2304.09087)

    本研究提出了一种名为MDDL的多通道深度确定性策略梯度学习框架，旨在整合多种策略，以增强位置分配的强化学习模型训练。该框架在在线和离线性能方面表现优于一些最先进的方法。

    

    目前，位置分配系统的主流方法是利用强化学习模型为各通道的物品分配合适的位置，然后混合到Feed中。强化学习模型的训练使用两种数据：策略数据和随机数据。策略数据来自当前在线模型，它受到状态-动作对分布不均衡的困扰，导致训练过程中存在严重的高估问题。另一方面，随机数据提供了更均匀的状态-动作对分布，但在工业场景中很难获取，因为随机探索可能会对平台收入和用户体验产生负面影响。由于这两种数据具有不同的分布，因此设计一种有效的策略来利用两种数据以增强强化学习模型的训练效果已成为一个极具挑战性的问题。本研究提出了一种名为MDDL（多通道深度确定性策略梯度学习）的框架来解决上述问题。我们的框架旨在整合多种策略，以增强位置分配的RL模型训练。实验证明，在线和离线性能方面，MDDL表现优于一些最先进的方法。

    Nowadays, the mainstream approach in position allocation system is to utilize a reinforcement learning model to allocate appropriate locations for items in various channels and then mix them into the feed. There are two types of data employed to train reinforcement learning (RL) model for position allocation, named strategy data and random data. Strategy data is collected from the current online model, it suffers from an imbalanced distribution of state-action pairs, resulting in severe overestimation problems during training. On the other hand, random data offers a more uniform distribution of state-action pairs, but is challenging to obtain in industrial scenarios as it could negatively impact platform revenue and user experience due to random exploration. As the two types of data have different distributions, designing an effective strategy to leverage both types of data to enhance the efficacy of the RL model training has become a highly challenging problem. In this study, we propo
    
[^11]: 利用少量无偏评分平衡未观测混淆的去偏推荐

    Balancing Unobserved Confounding with a Few Unbiased Ratings in Debiased Recommendations. (arXiv:2304.09085v1 [cs.IR])

    [http://arxiv.org/abs/2304.09085](http://arxiv.org/abs/2304.09085)

    本文提出了利用无偏评分平衡已有的去偏方法来对抗未观测混淆和模型规范误差的方法。

    

    推荐系统被视为解决信息过载的有效工具，但众所周知，存在各种偏差使得在大规模观测数据上进行直接训练会导致次优的预测性能。与之相反，从随机控制试验或A/B测试中获得的无偏评分被认为是黄金标准，但在现实中成本高且规模较小。为了利用这两种类型的数据，最近的研究提出利用无偏评分来修正在有偏数据集上训练的倾向性或插补模型的参数。然而，现有方法在存在未观测混淆或模型规范误差时无法获得准确的预测。本文提出了一种理论上保证的模型不可知平衡方法，可应用于任何现有的去偏方法，旨在对抗未观测混淆和模型规范误差。所提出的方法充分利用了无偏数据。

    Recommender systems are seen as an effective tool to address information overload, but it is widely known that the presence of various biases makes direct training on large-scale observational data result in sub-optimal prediction performance. In contrast, unbiased ratings obtained from randomized controlled trials or A/B tests are considered to be the golden standard, but are costly and small in scale in reality. To exploit both types of data, recent works proposed to use unbiased ratings to correct the parameters of the propensity or imputation models trained on the biased dataset. However, the existing methods fail to obtain accurate predictions in the presence of unobserved confounding or model misspecification. In this paper, we propose a theoretically guaranteed model-agnostic balancing approach that can be applied to any existing debiasing method with the aim of combating unobserved confounding and model misspecification. The proposed approach makes full use of unbiased data by 
    
[^12]: DRIFT: 一种基于隐式反馈的联邦推荐系统

    DRIFT: A Federated Recommender System with Implicit Feedback on the Items. (arXiv:2304.09084v1 [cs.IR])

    [http://arxiv.org/abs/2304.09084](http://arxiv.org/abs/2304.09084)

    DRIFT是一个联邦推荐系统架构，使用隐式反馈，以保护用户隐私，并使用SAROS算法实现精准推荐。

    

    现在网络上可用的物品越来越多，这使得用户很难找到他们喜欢的物品。推荐系统旨在使用用户的历史交互来找到最适合用户的物品。然而，这些交互可能更或更少敏感，并收集它们涉及到用户隐私的问题。联邦系统已经显示出即使在不存储用户个人信息的情况下也可以进行准确和有效的推荐。然而，这些系统使用用户的即时反馈。在本报告中，我们提出了DRIFT，一种使用隐式反馈的联合推荐系统架构。我们的学习模型基于最近用于隐式反馈推荐的算法SAROS。我们的目标是使推荐与SAROS一样精确，同时不损害用户的隐私。通过实验和收敛性的理论分析，我们展示了DRIFT的性能。

    Nowadays there are more and more items available online, this makes it hard for users to find items that they like. Recommender systems aim to find the item who best suits the user, using his historical interactions. Depending on the context, these interactions may be more or less sensitive and collecting them brings an important problem concerning the users' privacy. Federated systems have shown that it is possible to make accurate and efficient recommendations without storing users' personal information. However, these systems use instantaneous feedback from the user. In this report, we propose DRIFT, a federated architecture for recommender systems, using implicit feedback. Our learning model is based on a recent algorithm for recommendation with implicit feedbacks SAROS. We aim to make recommendations as precise as SAROS, without compromising the users' privacy. In this report we show that thanks to our experiments, but also thanks to a theoretical analysis on the convergence. We h
    
[^13]: 按照混合的单调分解无监督聚类文件方言

    Unsupervised clustering of file dialects according to monotonic decompositions of mixtures. (arXiv:2304.09082v1 [cs.PL])

    [http://arxiv.org/abs/2304.09082](http://arxiv.org/abs/2304.09082)

    本文提出了一种无监督分类方法，即将一组文件分成不同的方言，其中方言由其行为模式组成。提出了一种贪心算法从文件-消息数据矩阵的数据集中推断出候选方言，并证明了该算法是最优时的条件。

    

    本文提出了一种无监督分类方法，根据一组程序消耗的消息，将一组文件分割为不重叠的方言。消息的模式可以被用作特定行为的标志，有些消息可能会同时出现，而其他消息不会。消息模式可以用来将文件分类为不同方言。一个方言由子集消息作为必需消息来定义。一旦将文件置于方言及其必需的消息之下，剩下的消息则是统计独立的。有了这个方言定义，我们提出了一种贪心算法，从文件-消息数据矩阵的数据集中推断出候选方言。文章证明了该算法在多种文件格式上的效果，并证明了该算法是最优时的条件。文章表明，分析员需要考虑的方言比不同文件所需的组数少。

    This paper proposes an unsupervised classification method that partitions a set of files into non-overlapping dialects based upon their behaviors, determined by messages produced by a collection of programs that consume them. The pattern of messages can be used as the signature of a particular kind of behavior, with the understanding that some messages are likely to co-occur, while others are not. Patterns of messages can be used to classify files into dialects. A dialect is defined by a subset of messages, called the required messages. Once files are conditioned upon dialect and its required messages, the remaining messages are statistically independent.  With this definition of dialect in hand, we present a greedy algorithm that deduces candidate dialects from a dataset consisting of a matrix of file-message data, demonstrate its performance on several file formats, and prove conditions under which it is optimal. We show that an analyst needs to consider fewer dialects than distinct 
    
[^14]: 总是增强你的优势: 一种面向CTR预测的漂移感知增量学习框架

    Always Strengthen Your Strengths: A Drift-Aware Incremental Learning Framework for CTR Prediction. (arXiv:2304.09062v1 [cs.IR])

    [http://arxiv.org/abs/2304.09062](http://arxiv.org/abs/2304.09062)

    本文提出了一种面向CTR预测的漂移感知增量学习框架。该框架基于集成学习，通过显式的基于误差的漂移检测来解决CTR预测中的灾难性遗忘问题。

    

    点击率 (CTR) 预测在推荐系统和在线广告平台中非常重要。在工业场景中使用时，CTR 模型观察到的用户生成数据通常以流的形式到达。流式数据具有随着时间而漂移并可能重现的特性。如果模型仅适应于新数据分布，这可能会导致灾难性遗忘。此外，重复学习已经出现的分布是低效的。由于内存限制和大规模工业应用中数据分布的多样性，传统的灾难性遗忘策略（如重放、参数隔离和知识蒸馏）难以部署。在本研究中，我们基于集成学习设计了一种新的漂移感知增量学习框架，用于解决CTR预测中的灾难性遗忘。通过对流数据进行显式基于误差的漂移检测，该框架可以发现分布漂移并有针对性地学习数据分布漂移。

    Click-through rate (CTR) prediction is of great importance in recommendation systems and online advertising platforms. When served in industrial scenarios, the user-generated data observed by the CTR model typically arrives as a stream. Streaming data has the characteristic that the underlying distribution drifts over time and may recur. This can lead to catastrophic forgetting if the model simply adapts to new data distribution all the time. Also, it's inefficient to relearn distribution that has been occurred. Due to memory constraints and diversity of data distributions in large-scale industrial applications, conventional strategies for catastrophic forgetting such as replay, parameter isolation, and knowledge distillation are difficult to be deployed. In this work, we design a novel drift-aware incremental learning framework based on ensemble learning to address catastrophic forgetting in CTR prediction. With explicit error-based drift detection on streaming data, the framework fur
    
[^15]: 音乐流媒体服务中自动生成播放列表的可扩展框架

    A Scalable Framework for Automatic Playlist Continuation on Music Streaming Services. (arXiv:2304.09061v1 [cs.IR])

    [http://arxiv.org/abs/2304.09061](http://arxiv.org/abs/2304.09061)

    本论文提出了一个通用框架，它基于表示-聚合策略构建可扩展但有效的APC模型，用于大规模应用，可以包括各种表示学习和序列建模技术。

    

    音乐流媒体服务通常旨在推荐歌曲以扩展用户在该服务上创建的播放列表。然而，在保留其音乐特征和符合用户倾向的情况下扩展播放列表仍然是一项具有挑战性的任务，通常被称为自动播放列表延续（APC）。此外，尽管这些服务经常需要在大型目录中实时选择最佳歌曲进行推荐，但最近关于APC的研究主要集中在具有少量可扩展性保证并在相对较小的数据集上进行评估的模型上。在本文中，我们介绍了一个通用框架，用于构建适用于大规模应用的可扩展但有效的APC模型。基于表示-聚合策略，它通过设计确保可扩展性，同时足够灵活，可以包含各种表示学习和序列建模技术，例如基于Transformer。我们通过在不同数据集和情况下的实验证明了该框架的相关性。

    Music streaming services often aim to recommend songs for users to extend the playlists they have created on these services. However, extending playlists while preserving their musical characteristics and matching user preferences remains a challenging task, commonly referred to as Automatic Playlist Continuation (APC). Besides, while these services often need to select the best songs to recommend in real-time and among large catalogs with millions of candidates, recent research on APC mainly focused on models with few scalability guarantees and evaluated on relatively small datasets. In this paper, we introduce a general framework to build scalable yet effective APC models for large-scale applications. Based on a represent-then-aggregate strategy, it ensures scalability by design while remaining flexible enough to incorporate a wide range of representation learning and sequence modeling techniques, e.g., based on Transformers. We demonstrate the relevance of this framework through in-
    
[^16]: 重访基于预训练语言模型的k-NN

    Revisiting k-NN for Pre-trained Language Models. (arXiv:2304.09058v1 [cs.CL])

    [http://arxiv.org/abs/2304.09058](http://arxiv.org/abs/2304.09058)

    本研究提出一种新方法，结合k-NN和预训练语言模型（PLMs）能够提高自然语言处理（NLP）的性能，并在多个基准数据集上得到验证。

    

    预训练语言模型（PLMs）作为参数化的急切学习器，已成为自然语言处理（NLP）当前范式的实际选择。与此形成对比的是，k-最近邻（k-NN）分类器作为延迟学习模型，倾向于减轻过拟合和孤立噪声。本文中我们重访了k-NN分类器，以增强基于PLMs的分类器。从方法层面上，我们提出采用文本表示的PLMs在两个步骤中采用k-NN：（1）利用k-NN作为先验知识来校准训练过程（2）线性插值k-NN预测的概率分布和PLMs分类器的概率分布。我们的方法核心是实现了k-NN校准训练，将预测结果作为训练过程中易于和难以学习的示例的指标。从应用场景多样性的角度出发，我们在各种基准数据集上进行了广泛的微调、提示微调范式和零样本任务设置的实验。我们的结果表明，结合k-NN可以在所有受到检查的设置中持续提高PLMs的性能，并且在所有受到考虑的设置中跑赢了基于普通PLMs的方法。

    Pre-trained Language Models (PLMs), as parametric-based eager learners, have become the de-facto choice for current paradigms of Natural Language Processing (NLP). In contrast, k-Nearest-Neighbor (k-NN) classifiers, as the lazy learning paradigm, tend to mitigate over-fitting and isolated noise. In this paper, we revisit k-NN classifiers for augmenting the PLMs-based classifiers. From the methodological level, we propose to adopt k-NN with textual representations of PLMs in two steps: (1) Utilize k-NN as prior knowledge to calibrate the training process. (2) Linearly interpolate the probability distribution predicted by k-NN with that of the PLMs' classifier. At the heart of our approach is the implementation of k-NN-calibrated training, which treats predicted results as indicators for easy versus hard examples during the training process. From the perspective of the diversity of application scenarios, we conduct extensive experiments on fine-tuning, prompt-tuning paradigms and zero-sh
    
[^17]: CodeKGC：用于生成知识图谱构建的代码语言模型

    CodeKGC: Code Language Model for Generative Knowledge Graph Construction. (arXiv:2304.09048v1 [cs.CL])

    [http://arxiv.org/abs/2304.09048](http://arxiv.org/abs/2304.09048)

    本文提出了一种使用代码语言模型处理生成式知识图谱构建任务的方法，能够有效利用知识图谱内的语义结构，提高模型的可解释性。

    

    目前的生成式知识图谱构建方法通常无法捕捉结构性知识，而只是将自然语言转化为序列化文本或规范语言。然而，对于像代码这样的结构化数据进行训练的大型生成式语言模型已经展现了在理解自然语言以进行结构性预测和推理任务方面的卓越能力。本文提出了一种使用代码语言模型处理生成式知识图谱构建任务的方法。具体而言，在给定代码格式的自然语言输入的情况下，目标是生成可以表示为代码补全任务的三元组。我们开发了具有模式感知型提示的方法，可以有效利用知识图谱内的语义结构。由于代码本质上具有结构，如类和函数定义，因此它作为先验的语义结构知识模型非常有用。此外，我们采用了基于原理的生成方法来提高性能。原理提供了模型生成结果的可解释性。

    Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provi
    
[^18]: 神经信息检索的广义弱监督学习方法

    Generalized Weak Supervision for Neural Information Retrieval. (arXiv:2304.08912v1 [cs.IR])

    [http://arxiv.org/abs/2304.08912](http://arxiv.org/abs/2304.08912)

    本文提出了一种名为广义弱监督学习(GWS)的解决方案，它能够迭代地使用现有的排序模型(弱标注器)产生大量的训练数据，无需手动标注就能显著提高排序性能。

    

    神经排序模型(NRM)在多个信息检索(IR)任务中表现出有效的性能。然而，训练NRM通常需要大规模的训练数据，这很难且昂贵。为了解决这个问题，可以通过弱监督学习的方式来训练NRM，其中使用现有的排序模型(称为弱标注器)自动产生了一个大规模的训练数据集来训练NRM。弱监督的NRM可以从观察到的数据中推广，并显著优于弱标注器。本文通过迭代的重新标注过程对这个想法进行了推广，证明了弱监督模型可以迭代地扮演弱标注器的角色，并且不需要使用已手动标注的数据就可以显著提高排序性能。所提出的广义弱监督学习(GWS)解决方案是通用的，并且与排序模型体系结构相互独立。本文提供了四个GWS的实现：自我标注、跨标注、联合跨标注和自我标注、自举法。在几个基准数据集上的实验表明，GWS优于现有的最先进的方法，并与全监督方法相当。

    Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and
    
[^19]: 基于双粒度对比学习的会话推荐系统

    Dual-Ganularity Contrastive Learning for Session-based Recommendation. (arXiv:2304.08873v1 [cs.IR])

    [http://arxiv.org/abs/2304.08873](http://arxiv.org/abs/2304.08873)

    本文提出一种基于双粒度对比学习的会话推荐系统，通过引入多粒度CL框架和新的CL策略，能够有效地捕捉会话之间微小的差异，并优于现有最先进的方法。

    

    会话推荐系统（SBRS）在当前电子商务和流媒体推荐场景中更适用，因此成为了热门话题。SBRS遇到的数据通常非常稀疏，也是限制推荐准确度的瓶颈之一。因此，对比学习（CL）在SBRS中应用，因为它能够在稀疏数据条件下改善嵌入学习。然而，现有的CL策略在强制执行更细粒度（例如，因素级）比较方面能力有限，因此无法捕捉实例之间的微小差异。除此之外，这些策略通常使用项目或片段随机删除作为数据增强的手段，可能导致数据更稀疏，从而无效地自我监督信号。通过解决上述两个限制，我们引入了一种新的多粒度CL框架。具体而言，我们将具有双重粒度的两个额外的嵌入卷积通道合并到网络中，使网络能够学习会话的本地项目和全局因素信息的共享和判别表示。我们还提出了一种新的CL策略，使用自我监督的重要性加权来强制执行细粒度比较。在两个真实世界数据集上进行的大量实验表明，我们提出的方法优于现有最先进的方法，并且能够有效地捕捉会话之间的微小差异。

    Session-based recommendation systems(SBRS) are more suitable for the current e-commerce and streaming media recommendation scenarios and thus have become a hot topic. The data encountered by SBRS is typically highly sparse, which also serves as one of the bottlenecks limiting the accuracy of recommendations. So Contrastive Learning(CL) is applied in SBRS owing to its capability of improving embedding learning under the condition of sparse data. However, existing CL strategies are limited in their ability to enforce finer-grained (e.g., factor-level) comparisons and, as a result, are unable to capture subtle differences between instances. More than that, these strategies usually use item or segment dropout as a means of data augmentation which may result in sparser data and thus ineffective self-supervised signals. By addressing the two aforementioned limitations, we introduce a novel multi-granularity CL framework. Specifically, two extra augmented embedding convolution channels with d
    
[^20]: eTOP：用于更快地训练AutoML系统的管道提前终止

    eTOP: Early Termination of Pipelines for Faster Training of AutoML Systems. (arXiv:2304.08597v1 [cs.LG])

    [http://arxiv.org/abs/2304.08597](http://arxiv.org/abs/2304.08597)

    eTOP框架可以在任何AutoML系统之上工作，并决定是否将执行管道到最后或在中间步骤终止以更快地训练模型。

    

    软件和硬件技术的最新进展使得AI/ML模型可以应用到日常应用中，极大地提高了所提供服务的质量。但是对于给定的应用程序，找到合适的AI/ML模型是一个复杂而昂贵的过程，涉及多个相互关联的步骤（称为管道），如数据预处理、特征工程、选择和模型调整的生成、训练和评估等。这些管道在结构上是复杂的，在计算资源和时间上都很昂贵，并与每个步骤相关联。AutoML系统自动搜索这些超参数，但速度很慢，因为它们依赖于管道的最终输出进行优化。我们提出了eTOP框架，它可以在任何AutoML系统之上工作，并决定是否将管道执行到最后或在中间步骤终止。在26个基准数据集上的实验评估以及eTOP与

    Recent advancements in software and hardware technologies have enabled the use of AI/ML models in everyday applications has significantly improved the quality of service rendered. However, for a given application, finding the right AI/ML model is a complex and costly process, that involves the generation, training, and evaluation of multiple interlinked steps (called pipelines), such as data pre-processing, feature engineering, selection, and model tuning. These pipelines are complex (in structure) and costly (both in compute resource and time) to execute end-to-end, with a hyper-parameter associated with each step. AutoML systems automate the search of these hyper-parameters but are slow, as they rely on optimizing the pipeline's end output. We propose the eTOP Framework which works on top of any AutoML system and decides whether or not to execute the pipeline to the end or terminate at an intermediate step. Experimental evaluation on 26 benchmark datasets and integration of eTOPwith 
    
[^21]: CAM2: 面向大规模推荐系统的一致性感知多任务排名模型

    CAM2: Conformity-Aware Multi-Task Ranking Model for Large-Scale Recommender Systems. (arXiv:2304.08562v1 [cs.IR])

    [http://arxiv.org/abs/2304.08562](http://arxiv.org/abs/2304.08562)

    CAM2是一个面向大规模推荐系统的一致性感知多任务排名模型，通过利用因果建模系统地解开用户对流行物品的一致性与他们真正兴趣的联系，来消除历史用户交互数据带来的一致性偏见，并在实践中得到有效的应用。

    

    将历史用户交互数据拟合到大规模工业推荐系统模型中，可能会导致一致性偏见，因为用户兴趣可能很难确定，而许多项目通常基于生态系统因素而不是与个体用户相关性交互。在本研究中，我们引入了CAM2，这是一个一致性感知的多任务排名模型，旨在为其中一个最大的工业推荐平台向用户提供相关物品。CAM2通过利用因果建模系统地解开用户对流行物品的一致性与他们真正兴趣的联系。这个框架是可推广的，并且可以扩展以支持在任何大规模推荐系统中的多个一致性和用户相关性的表示。我们提供更深入的实践见解，并通过离线评估的改进来演示所提出模型的有效性。

    Learning large-scale industrial recommender system models by fitting them to historical user interaction data makes them vulnerable to conformity bias. This may be due to a number of factors, including the fact that user interests may be difficult to determine and that many items are often interacted with based on ecosystem factors other than their relevance to the individual user. In this work, we introduce CAM2, a conformity-aware multi-task ranking model to serve relevant items to users on one of the largest industrial recommendation platforms. CAM2 addresses these challenges systematically by leveraging causal modeling to disentangle users' conformity to popular items from their true interests. This framework is generalizable and can be scaled to support multiple representations of conformity and user relevance in any large-scale recommender system. We provide deeper practical insights and demonstrate the effectiveness of the proposed model through improvements in offline evaluatio
    
[^22]: 快速密集信息检索器利用KALE进行后置KL对齐的异形双编码器模型训练 (arXiv:2304.01016v2 [cs.CL] UPDATED)

    Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders. (arXiv:2304.01016v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.01016](http://arxiv.org/abs/2304.01016)

    本文提出了一种通过结构压缩和模型尺寸不对称的双编码器模型 KALE，有效提高密集信息检索的推理效率，同时允许查询编码器的有效压缩，而无需进行全部的再训练或索引生成，此方法能够生成超过DistilBERT性能的模型。

    

    本文提出了一种有结构压缩和模型尺寸不对称的双编码器模型，旨在提高基于语言模型的密集信息检索系统的推理速度。通过对MSMARCO、自然问答、问答游戏等多个数据集进行前后训练压缩实验，研究了压缩对系统推理效率的影响，结果表明密集信息检索器的双编码器结构异形化有助于提高其推理效率。基于此，我们引入了一种名为Kullback Leibler Alignment of Embeddings (KALE)的方法，通过裁剪和对齐查询编码器，提高了密集信息检索的推理效率。KALE扩展了传统的知识蒸馏方法，使得在双编码器训练后可以有效地对查询编码器进行压缩而无需进行完整的再训练或索引生成。使用KALE和不对称训练，我们可以生成超过DistilBERT性能的模型，同时模型尺寸更小。

    In this paper, we consider the problem of improving the inference latency of language model-based dense retrieval systems by introducing structural compression and model size asymmetry between the context and query encoders. First, we investigate the impact of pre and post-training compression on the MSMARCO, Natural Questions, TriviaQA, SQUAD, and SCIFACT, finding that asymmetry in the dual encoders in dense retrieval can lead to improved inference efficiency. Knowing this, we introduce Kullback Leibler Alignment of Embeddings (KALE), an efficient and accurate method for increasing the inference efficiency of dense retrieval methods by pruning and aligning the query encoder after training. Specifically, KALE extends traditional Knowledge Distillation after bi-encoder training, allowing for effective query encoder compression without full retraining or index generation. Using KALE and asymmetric training, we can generate models which exceed the performance of DistilBERT despite having 
    
[^23]: 阶-无序：黑盒神经排名模型的模拟对抗攻击

    Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models. (arXiv:2209.06506v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2209.06506](http://arxiv.org/abs/2209.06506)

    本研究提出了一种模拟黑盒神经排名模型的对抗攻击，可被黑帽SEO用来打败更好防护的搜索引擎。

    

    神经文本排名模型取得了显着进展，并越来越多地被应用于实践中。然而，它们也继承了一般神经模型的对抗性弱点，虽然已被发现，但仍未被先前的研究充分探讨。此外，这种对抗性弱点可能被黑帽SEO用来打败更好防护的搜索引擎。本研究提出了一种模拟黑盒神经段落排名模型的对抗攻击。我们首先展示了目标排名模型可以通过枚举关键查询/候选项透明化并模仿，然后训练一个排名模仿模型。利用排名模仿模型，我们可以精心操纵排名结果并将操纵攻击转移到目标排名模型上。为此，我们提出了一种创新的基于梯度的攻击方法，使用配对目标函数强化，以生成对抗触发器，从而导致PremE.

    Neural text ranking models have witnessed significant advancement and are increasingly being deployed in practice. Unfortunately, they also inherit adversarial vulnerabilities of general neural models, which have been detected but remain underexplored by prior studies. Moreover, the inherit adversarial vulnerabilities might be leveraged by blackhat SEO to defeat better-protected search engines. In this study, we propose an imitation adversarial attack on black-box neural passage ranking models. We first show that the target passage ranking model can be transparentized and imitated by enumerating critical queries/candidates and then train a ranking imitation model. Leveraging the ranking imitation model, we can elaborately manipulate the ranking results and transfer the manipulation attack to the target ranking model. For this purpose, we propose an innovative gradient-based attack method, empowered by the pairwise objective function, to generate adversarial triggers, which causes preme
    
[^24]: PMC-Patients: 用于评估基于召回的临床决策支持系统的大规模病患数据集

    PMC-Patients: A Large-scale Dataset of Patient Summaries and Relations for Benchmarking Retrieval-based Clinical Decision Support Systems. (arXiv:2202.13876v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.13876](http://arxiv.org/abs/2202.13876)

    本文提出了一个名为“PMC-Patients”的新数据集，用于定义和测试病患到文章的检索（ReCDS-PAR）和病患到病患的检索（ReCDS-PPR），以评估基于召回的临床决策支持系统（ReCDS）的性能。PMC-Patients数据集涵盖逾10,000名病患信息和27,000篇PubMed Central文章，并展示了多种ReCDS系统的效果分析和20个案例的实用性分析。

    

    目标：基于召回的临床决策支持系统（ReCDS）可以通过提供相关文献和类似病患的信息来帮助临床工作流程。然而，由于缺乏多样的病患收集和公开的大规模病患层面注释数据集，ReCDS系统的发展受到了严重阻碍。在本文中，我们旨在使用名为PMC-Patients的新数据集定义和测试两个ReCDS任务：病患到文章的检索（ReCDS-PAR）和病患到病患的检索（ReCDS-PPR）。方法：我们使用简单的启发式方法从PubMed Central文章中提取病患总结，并利用PubMed引文关系图来定义病患-文章相关性和病患-病患相似性。我们还在PMC-Patients基准测试上实施和评估了几种ReCDS系统，包括稀疏检索器、密集检索器和最近邻检索器。我们进行了几个案例研究，以展示PMC-Patients的临床效用。结果：PMC-Patients数据集包含了10,186名病患的信息，涵盖了逾27,000篇PubMed Central文章。我们提供了两个ReCDS任务的基准评估结果和多种系统的效果分析。此外，我们对两个任务的20个案例进行了分析，证明了PMC-Patients的实用性。

    Objective: Retrieval-based Clinical Decision Support (ReCDS) can aid clinical workflow by providing relevant literature and similar patients for a given patient. However, the development of ReCDS systems has been severely obstructed by the lack of diverse patient collections and publicly available large-scale patient-level annotation datasets. In this paper, we aim to define and benchmark two ReCDS tasks: Patient-to-Article Retrieval (ReCDS-PAR) and Patient-to-Patient Retrieval (ReCDS-PPR) using a novel dataset called PMC-Patients.  Methods: We extract patient summaries from PubMed Central articles using simple heuristics and utilize the PubMed citation graph to define patient-article relevance and patient-patient similarity. We also implement and evaluate several ReCDS systems on the PMC-Patients benchmarks, including sparse retrievers, dense retrievers, and nearest neighbor retrievers. We conduct several case studies to show the clinical utility of PMC-Patients.  Results: PMC-Patient
    
[^25]: 低资源情境下的知识抽取：调研与展望

    Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective. (arXiv:2202.08063v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.08063](http://arxiv.org/abs/2202.08063)

    低资源情境下，如何让知识抽取更好地从非结构化文本中提取信息？本文调研了三种解决范式：高资源数据、更强的模型和数据与模型的结合，提出了未来的研究方向。

    

    知识抽取（KE）旨在从非结构化文本中提取结构信息，通常遭受数据匮乏和出现未见类型（低资源情境）的困扰。许多神经网络方法已广泛研究并取得了令人瞩目的表现。本文对低资源情境下KE进行文献综述，并将现有的工作系统性地分为三种范式：（1）利用高资源数据，（2）利用更强的模型，（3）同时利用数据和模型。此外，本文提出有前途的应用，并概述了未来研究的一些潜在方向。我们希望我们的调研可以帮助学术和工业界更好地理解这一领域，激发更多的创意，提升更广泛的应用。

    Knowledge Extraction (KE), aiming to extract structural information from unstructured texts, often suffers from data scarcity and emerging unseen types, i.e., low-resource scenarios. Many neural approaches to low-resource KE have been widely investigated and achieved impressive performance. In this paper, we present a literature review towards KE in low-resource scenarios, and systematically categorize existing works into three paradigms: (1) exploiting higher-resource data, (2) exploiting stronger models, and (3) exploiting data and models together. In addition, we highlight promising applications and outline some potential directions for future research. We hope that our survey can help both the academic and industrial communities to better understand this field, inspire more ideas, and boost broader applications.
    
[^26]: 寻找锦标赛图中冠军的最优算法

    An Optimal Algorithm for Finding Champions in Tournament Graphs. (arXiv:2111.13621v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2111.13621](http://arxiv.org/abs/2111.13621)

    本文提出了一种在完成最少比赛的前提下寻找锦标赛图中冠军（Copeland获胜者）的最优算法，该算法可以加速信息检索和推荐系统应用，这对于进行循环赛的机器学习模型具有重要的意义，能减少模型推理的数量。

    

    锦标赛图是一个完全有向图，可用于模拟$n$名选手之间的循环赛。本文讨论了寻找锦标赛的冠军（亦称Copeland获胜者）的问题，即赢得最多比赛的选手。我们的目标是探究通过进行较少比赛来寻找冠军的算法。解决这个问题可以加速多种信息检索和推荐系统应用，包括问答、对话搜索等。这些应用经常通过使用机器学习模型估计谁会赢得每个成对比赛，从而诱导选手之间的循环赛来寻找冠军。因此，我们的贡献允许通过执行较少的模型推理来寻找冠军。我们证明了任何具有常数成功概率的确定性或随机算法找到冠军都需要$\Omega(\ell n)$次比较。

    A tournament graph is a complete directed graph, which can be used to model a round-robin tournament between $n$ players. In this paper, we address the problem of finding a champion of the tournament, also known as Copeland winner, which is a player that wins the highest number of matches. In detail, we aim to investigate algorithms that find the champion by playing a low number of matches. Solving this problem allows us to speed up several Information Retrieval and Recommender System applications, including question answering, conversational search, etc. Indeed, these applications often search for the champion inducing a round-robin tournament among the players by employing a machine learning model to estimate who wins each pairwise comparison. Our contribution, thus, allows finding the champion by performing a low number of model inferences. We prove that any deterministic or randomized algorithm finding a champion with constant success probability requires $\Omega(\ell n)$ compariso
    
[^27]: 稀疏贝叶斯学习在离散信号重建中的应用

    Sparse Bayesian Learning Approach for Discrete Signal Reconstruction. (arXiv:1906.00309v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/1906.00309](http://arxiv.org/abs/1906.00309)

    本研究提出了一种新的离散化先验，将其与稀疏贝叶斯学习框架和变分贝叶斯推理方法相结合，设计了一种交替优化算法，可以有效解决离散信号重建问题，并且具有显著的性能提高。

    

    本研究从稀疏贝叶斯学习（SBL）的角度解决了离散信号重建的问题。通常，在SBL框架下使用理想的离散化先验进行贝叶斯推理是不可行的。为了克服这个挑战，我们引入了一种新的离散化先验，以利用感兴趣信号的离散特性的知识。通过将离散化先验集成到SBL框架中，并应用变分贝叶斯推理（VBI）方法，我们设计了一种交替优化算法来共同表征有限字母特征并重建未知信号。当测量矩阵是每个分量的i.i.d.高斯分布时，我们进一步将广义近似信息传递（GAMP）嵌入到基于VBI的方法中，以直接采用理想先验并显著降低计算负担。模拟结果表明，该方法具有显著的性能提高。

    This study addresses the problem of discrete signal reconstruction from the perspective of sparse Bayesian learning (SBL). Generally, it is intractable to perform the Bayesian inference with the ideal discretization prior under the SBL framework. To overcome this challenge, we introduce a novel discretization enforcing prior to exploit the knowledge of the discrete nature of the signal-of-interest. By integrating the discretization enforcing prior into the SBL framework and applying the variational Bayesian inference (VBI) methodology, we devise an alternating optimization algorithm to jointly characterize the finite-alphabet feature and reconstruct the unknown signal. When the measurement matrix is i.i.d. Gaussian per component, we further embed the generalized approximate message passing (GAMP) into the VBI-based method, so as to directly adopt the ideal prior and significantly reduce the computational burden. Simulation results demonstrate substantial performance improvement of the 
    

