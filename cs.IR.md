# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Instant Representation Learning for Recommendation over Large Dynamic Graphs.](http://arxiv.org/abs/2305.18622) | 提出了一种名为SUPA的新型图神经网络模型，用于在大型动态图中即时学习表示，以提高推荐系统的效率和效果。 |
| [^2] | [Improving Generalization for Multimodal Fake News Detection.](http://arxiv.org/abs/2305.18599) | 本研究提出了三种模型，采用和微调最先进的多模态Transformer进行多模态假新闻检测，并提出了训练数据增强来提高模型泛化能力。 |
| [^3] | [Adapting Learned Sparse Retrieval for Long Documents.](http://arxiv.org/abs/2305.18494) | 本文提出了两种方法，即 ExactSDM 和 SoftSDM，将顺序依赖模型 (SDM) 适应到学习稀疏检索 (LSR) 中，以解决长篇文档检索的问题。在 MSMARCO 文档和 TREC Robust04 数据集上的实验证明，ExactSDM 和 SoftSDM 都优于现有的 LSR 聚合方法。 |
| [^4] | [Optimizing Airbnb Search Journey with Multi-task Learning.](http://arxiv.org/abs/2305.18431) | 本文提出了一种新的多任务深度学习模型架构Journey Ranker，来解决Airbnb搜索过程中的唯一挑战，即客户和主机的偏好，该模型可应用于多个用例。 |
| [^5] | [Fast and Accurate Dual-Way Streaming PARAFAC2 for Irregular Tensors -- Algorithm and Application.](http://arxiv.org/abs/2305.18376) | 本文提出了一种名为Dash的有效而准确的PARAFAC2分解方法，其采用两阶段ALS算法，在双向流处理非规则张量时高效地处理新行，同时提供了在该应用场景下的异常检测度量方法，实验结果显示Dash方法优于现有的方法。 |
| [^6] | [Pure Spectral Graph Embeddings: Reinterpreting Graph Convolution for Top-N Recommendation.](http://arxiv.org/abs/2305.18374) | 本文提出了一种新的纯谱图嵌入方法，在Top-N推荐任务中比现有基于图卷积的模型具有更优的性能。 |
| [^7] | [Towards Explainable Conversational Recommender Systems.](http://arxiv.org/abs/2305.18363) | 本文提出了衡量对话式推荐系统的可解释性的十种评估视角，并通过构建新数据集来提高解释质量。 |
| [^8] | [DataChat: Prototyping a Conversational Agent for Dataset Search and Visualization.](http://arxiv.org/abs/2305.18358) | DataChat是一个用于数据集搜索和可视化的聊天机器人，通过图数据库和语言模型为用户提供更加智能化的数据搜索体验。 |
| [^9] | [Towards Open-World Product Attribute Mining: A Lightly-Supervised Approach.](http://arxiv.org/abs/2305.18350) | 该研究提出了一种用于电子商务产品属性挖掘的新任务设置，可以利用高质量的种子属性集合轻度监督并自动发现新的属性类型。通过自我监督启发式和无监督潜在属性，该方法能够以额外的隐含语义信号作为辅助监督，将现有类型的属性扩展最多12倍，并成功发掘了39％的新属性值。 |
| [^10] | [Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics.](http://arxiv.org/abs/2305.18333) | 研究了物品流行度、质量和位置偏差对用户福利的影响，提出了通过探索减轻流行度偏见负面影响的算法。 |
| [^11] | [#REVAL: a semantic evaluation framework for hashtag recommendation.](http://arxiv.org/abs/2305.18330) | #REVAL是一种新颖的语义评估框架，用于解决传统评估方法无法考虑推荐和实际hashtag之间语义相关性问题。实验证明#REVAL在捕捉语义相关性方面是有效的。 |
| [^12] | [Application of Text Analytics in Public Service Co-Creation: Literature Review and Research Framework.](http://arxiv.org/abs/2305.18316) | 本文系统综述了在公共服务领域中应用文本分析技能以支持公共服务协同创作的研究，发掘了TA技术和公共服务的对公共价值的影响，以及在公共服务领域中TA技术的应用前景。 |
| [^13] | [CDJUR-BR -- A Golden Collection of Legal Document from Brazilian Justice with Fine-Grained Named Entities.](http://arxiv.org/abs/2305.18315) | CDJUR-BR是一份稳健的黄金收藏，包含巴西司法文件中的精细命名实体，该收藏涵盖各种法律程序文件，并有助于解决目前命名实体识别（NER）无法轻而易举地识别法律实践文本中实体的问题。 |
| [^14] | [Selective Query Processing: a Risk-Sensitive Selection of System Configurations.](http://arxiv.org/abs/2305.18311) | 提出了一个针对信息检索系统的风险敏感查询选择框架，可以在一组可能的系统配置中选择最佳配置，从而提高搜索效率和利用系统资源的效率。 |
| [^15] | [Multi-View Interactive Collaborative Filtering.](http://arxiv.org/abs/2305.18306) | 提出了基于多视角交互主题回归算法（MV-ICTR）的推荐系统，在不同视角下同时纳入评分和上下文信息来建模物品特定功能的相关性和用户的个人偏好，采用多臂老虎机策略进行持续的在线个性化，显著提高了数据集上性能。 |
| [^16] | [High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits.](http://arxiv.org/abs/2305.18305) | 使用潜在Bandits算法解决用户冷启动问题，同时实现更高的准确率和更低的遗憾。 |
| [^17] | [Semantic-aware Digital Twin for Metaverse: A Comprehensive Review.](http://arxiv.org/abs/2305.18304) | 本文综述了数字孪生体在元宇宙中的部署，并介绍了通过语义通信实现数字孪生体与元宇宙结合的框架，以及其在智能工业应用中的基本原理和性能优化的实现。 |
| [^18] | [Consistent Text Categorization using Data Augmentation in e-Commerce.](http://arxiv.org/abs/2305.05402) | 本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。 |
| [^19] | [FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction.](http://arxiv.org/abs/2304.00902) | 本研究提出了一个用于CTR预测的增强双流MLP模型，经实证研究表明，该模型仅是简单地结合两个MLP就可以实现令人惊讶的良好性能。 |
| [^20] | [CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding.](http://arxiv.org/abs/2209.10918) | 本文提出了CONE，一个高效的粗-细对齐框架，可用于长视频时间定位。CONE通过基于查询的窗口选择策略和对比学习机制提升了多模态对齐，并在两个大规模长视频时间定位基准测试中取得最先进结果。 |
| [^21] | [A Data-driven Latent Semantic Analysis for Automatic Text Summarization using LDA Topic Modelling.](http://arxiv.org/abs/2207.14687) | 本研究使用LDA主题建模方法进行文本摘要，针对与基因和疾病相关的医学科学期刊文章进行研究，提供了一个能够保留关键信息并保持原始意义的压缩版本，并使用PyLDAvis进行交互式可视化。 |
| [^22] | [C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System.](http://arxiv.org/abs/2201.02732) | 本文提出了一种新的粗到细对比学习框架，用于对话式推荐系统中多类型外部数据的数据语义融合，在此基础上提高了数据的处理效率。 |
| [^23] | [Efficient-FedRec: Efficient Federated Learning Framework for Privacy-Preserving News Recommendation.](http://arxiv.org/abs/2109.05446) | 本文提出了一种新的联邦学习框架，用于隐私保护的新闻推荐。该框架将新闻推荐模型分解为大型新闻模型和轻量级用户模型，通过将新闻表示和用户模型在服务器和客户端之间进行通信，从而实现了高效率和有效性的训练。 |

# 详细

[^1]: 应用于大型动态图的即时表示学习推荐模型

    Instant Representation Learning for Recommendation over Large Dynamic Graphs. (arXiv:2305.18622v1 [cs.IR])

    [http://arxiv.org/abs/2305.18622](http://arxiv.org/abs/2305.18622)

    提出了一种名为SUPA的新型图神经网络模型，用于在大型动态图中即时学习表示，以提高推荐系统的效率和效果。

    

    推荐系统通过用户和物品的表示学习来了解用户偏好，而现代推荐模型开始利用用户表现出的各种行为类型的信息，以提高表示学习效果。在真实世界的情况下，用户行为图不仅是多重的，而且是动态的，即图随时间快速演变，添加或删除各种类型的节点和边缘，这导致邻域扰动。然而，大多数现有方法忽略了这种流动动力学，因此一旦图形发生显着演变，它们需要重新训练，使它们不适用于在线学习环境。此外，动态图中存在的邻域扰动会恶化基于邻居聚合的图模型的性能。为此，我们提出了SUPA，这是一个新颖的动态多重异构图的图神经网络。与邻居聚合体系结构相比，SUPA开发了一个时间感知的消息传递方案，以自适应地聚合来自各种邻居的节点信息。此外，我们还整合了一个动态图编码器来捕捉图级动态。因此，我们可以以在线方式高效地生成与其历史行为相关的用户和物品表示。三个公共基准测试的实验结果验证了SUPA与最先进方法相比的有效性和效率。

    Recommender systems are able to learn user preferences based on user and item representations via their historical behaviors. To improve representation learning, recent recommendation models start leveraging information from various behavior types exhibited by users. In real-world scenarios, the user behavioral graph is not only multiplex but also dynamic, i.e., the graph evolves rapidly over time, with various types of nodes and edges added or deleted, which causes the Neighborhood Disturbance. Nevertheless, most existing methods neglect such streaming dynamics and thus need to be retrained once the graph has significantly evolved, making them unsuitable in the online learning environment. Furthermore, the Neighborhood Disturbance existing in dynamic graphs deteriorates the performance of neighbor-aggregation based graph models. To this end, we propose SUPA, a novel graph neural network for dynamic multiplex heterogeneous graphs. Compared to neighbor-aggregation architecture, SUPA dev
    
[^2]: 提高多模态假新闻检测的泛化能力

    Improving Generalization for Multimodal Fake News Detection. (arXiv:2305.18599v1 [cs.CL])

    [http://arxiv.org/abs/2305.18599](http://arxiv.org/abs/2305.18599)

    本研究提出了三种模型，采用和微调最先进的多模态Transformer进行多模态假新闻检测，并提出了训练数据增强来提高模型泛化能力。

    

    现在，虚假信息的不断传播及其惊人的影响已经促使行业和学术界开发出假新闻检测方法。然而，最先进的方法通常使用规模较小或特定主题的有限数据集进行训练。因此，这些模型缺乏泛化能力，不能应用于现实世界的数据。本文提出了三种采用并微调最先进的多模态Transformer进行多模态假新闻检测的模型。我们通过操作输入数据进行深入分析，旨在探索这些模型在社交媒体上的实际使用情况下的性能。我们跨多个模型进行的研究表明，这些系统在受到操作数据的情况下会出现显着的性能下降。为了减少偏差并提高模型的泛化能力，我们建议进行训练数据增强，以在社交媒体上进行更有意义的假新闻检测实验。

    The increasing proliferation of misinformation and its alarming impact have motivated both industry and academia to develop approaches for fake news detection. However, state-of-the-art approaches are usually trained on datasets of smaller size or with a limited set of specific topics. As a consequence, these models lack generalization capabilities and are not applicable to real-world data. In this paper, we propose three models that adopt and fine-tune state-of-the-art multimodal transformers for multimodal fake news detection. We conduct an in-depth analysis by manipulating the input data aimed to explore models performance in realistic use cases on social media. Our study across multiple models demonstrates that these systems suffer significant performance drops against manipulated data. To reduce the bias and improve model generalization, we suggest training data augmentation to conduct more meaningful experiments for fake news detection on social media. The proposed data augmentat
    
[^3]: 学习稀疏检索在长文档中的应用

    Adapting Learned Sparse Retrieval for Long Documents. (arXiv:2305.18494v1 [cs.IR])

    [http://arxiv.org/abs/2305.18494](http://arxiv.org/abs/2305.18494)

    本文提出了两种方法，即 ExactSDM 和 SoftSDM，将顺序依赖模型 (SDM) 适应到学习稀疏检索 (LSR) 中，以解决长篇文档检索的问题。在 MSMARCO 文档和 TREC Robust04 数据集上的实验证明，ExactSDM 和 SoftSDM 都优于现有的 LSR 聚合方法。

    

    学习稀疏检索 (LSR) 是一种将查询和文档转换成与词汇表对齐的稀疏权重向量的神经检索方法。虽然像 Splade 这样的 LSR 方法在短文段上表现良好，但它们如何处理更长的文档还不清楚。本文研究了用于适应 LSR 到长文档的现有聚合方法，并发现接近打分对于 LSR 处理长文档是至关重要的。为了利用这个特性，我们提出了两种将顺序依赖模型 (SDM) 适应到 LSR 的方法：ExactSDM 和 SoftSDM。ExactSDM 假定只有精确的查询项依赖性，而 SoftSDM 使用潜在函数对查询项及其扩展项 (即使用转换器的掩码语言建模头识别的项) 的依赖关系进行建模。在 MSMARCO 文档和 TREC Robust04 数据集上的实验证明，ExactSDM 和 SoftSDM 都优于现有的 LSR 聚合方法，针对不同的文档长度约束表现出最佳的性能。

    Learned sparse retrieval (LSR) is a family of neural retrieval methods that transform queries and documents into sparse weight vectors aligned with a vocabulary. While LSR approaches like Splade work well for short passages, it is unclear how well they handle longer documents. We investigate existing aggregation approaches for adapting LSR to longer documents and find that proximal scoring is crucial for LSR to handle long documents. To leverage this property, we proposed two adaptations of the Sequential Dependence Model (SDM) to LSR: ExactSDM and SoftSDM. ExactSDM assumes only exact query term dependence, while SoftSDM uses potential functions that model the dependence of query terms and their expansion terms (i.e., terms identified using a transformer's masked language modeling head).  Experiments on the MSMARCO Document and TREC Robust04 datasets demonstrate that both ExactSDM and SoftSDM outperform existing LSR aggregation approaches for different document length constraints. Surp
    
[^4]: 多任务学习优化Airbnb搜索之旅

    Optimizing Airbnb Search Journey with Multi-task Learning. (arXiv:2305.18431v1 [cs.IR])

    [http://arxiv.org/abs/2305.18431](http://arxiv.org/abs/2305.18431)

    本文提出了一种新的多任务深度学习模型架构Journey Ranker，来解决Airbnb搜索过程中的唯一挑战，即客户和主机的偏好，该模型可应用于多个用例。

    

    Airbnb是一个在线住宿和体验市场，客人通常需要花费数周来探索和比较多个物品，并在做出最后的预订请求之前平衡客人和主机的偏好。搜索过程的长期性质以及需要平衡客人和主机的偏好，这些都为Airbnb的搜索排名提供了独特的挑战。本文提出了一种新的多任务深度学习模型架构Journey Ranker，以解决这些挑战。Journey Ranker利用中间的客户操作作为里程碑（无论是积极的还是消极的）来更好地将客户推向成功的预订。它还使用上下文信息（如客户状态和搜索查询）来平衡客人和主机的偏好。其模块化和可扩展的设计包括四个模块，分离明确，可以方便地应用于Airbnb搜索排名以外的用例。

    At Airbnb, an online marketplace for stays and experiences, guests often spend weeks exploring and comparing multiple items before making a final reservation request. Each reservation request may then potentially be rejected or cancelled by the host prior to check-in. The long and exploratory nature of the search journey, as well as the need to balance both guest and host preferences, present unique challenges for Airbnb search ranking. In this paper, we present Journey Ranker, a new multi-task deep learning model architecture that addresses these challenges. Journey Ranker leverages intermediate guest actions as milestones, both positive and negative, to better progress the guest towards a successful booking. It also uses contextual information such as guest state and search query to balance guest and host preferences. Its modular and extensible design, consisting of four modules with clear separation of concerns, allows for easy application to use cases beyond the Airbnb search ranki
    
[^5]: 快速而准确的PARAFAC2双向流算法及其在非规则张量中的应用

    Fast and Accurate Dual-Way Streaming PARAFAC2 for Irregular Tensors -- Algorithm and Application. (arXiv:2305.18376v1 [cs.LG])

    [http://arxiv.org/abs/2305.18376](http://arxiv.org/abs/2305.18376)

    本文提出了一种名为Dash的有效而准确的PARAFAC2分解方法，其采用两阶段ALS算法，在双向流处理非规则张量时高效地处理新行，同时提供了在该应用场景下的异常检测度量方法，实验结果显示Dash方法优于现有的方法。

    

    本文针对一种非规则张量的双向流处理，其中张量的两个维度在时间上增加，提出了一种有效而准确的PARAFAC2分解方法Dash。该方法采用两阶段ALS算法，在处理新行时效率高。同时，本文还提出了在双向流上检测异常情况的度量方法。实验结果表明，Dash方法在性能和检测效果上均优于现有的静态和流式PARAFAC2分解方法以及异常检测方法。

    How can we efficiently and accurately analyze an irregular tensor in a dual-way streaming setting where the sizes of two dimensions of the tensor increase over time? What types of anomalies are there in the dual-way streaming setting? An irregular tensor is a collection of matrices whose column lengths are the same while their row lengths are different. In a dual-way streaming setting, both new rows of existing matrices and new matrices arrive over time. PARAFAC2 decomposition is a crucial tool for analyzing irregular tensors. Although real-time analysis is necessary in the dual-way streaming, static PARAFAC2 decomposition methods fail to efficiently work in this setting since they perform PARAFAC2 decomposition for accumulated tensors whenever new data arrive. Existing streaming PARAFAC2 decomposition methods work in a limited setting and fail to handle new rows of matrices efficiently. In this paper, we propose Dash, an efficient and accurate PARAFAC2 decomposition method working in 
    
[^6]: 纯谱图嵌入：将图卷积重新解释为Top-N推荐中的方法

    Pure Spectral Graph Embeddings: Reinterpreting Graph Convolution for Top-N Recommendation. (arXiv:2305.18374v1 [cs.IR])

    [http://arxiv.org/abs/2305.18374](http://arxiv.org/abs/2305.18374)

    本文提出了一种新的纯谱图嵌入方法，在Top-N推荐任务中比现有基于图卷积的模型具有更优的性能。

    

    最近在协同过滤任务（CF）的推荐系统算法的开发中，使用图卷积已经取得了最先进的结果。虽然已经证明，图卷积操作与图谱域上的过滤操作有关，但为什么这会导致协同过滤问题的更高性能的理论基础仍不为人知。本文提出了两个贡献。首先，我们研究了在用户和项目表示学习过程中使用图卷积的效果，并展示了学习到的潜在特征如何从过滤操作推进到由归一化邻接矩阵的最高特征值对应的特征向量张成的子空间中，并且该子空间上的向量是与训练数据上的预测函数的求和相关的目标函数的最优解。然后，我们提出了一种方法，将图卷积操作重新解释为纯谱嵌入，将其与谱方法文献对齐，并突出其与Laplacian Eigenmaps和Common Neighbour Ranking Mechanism的联系。通过利用图Laplacian的谱特性，该方法能够在Top-N推荐任务中取得优于现有基于图卷积的模型的性能。

    The use of graph convolution in the development of recommender system algorithms has recently achieved state-of-the-art results in the collaborative filtering task (CF). While it has been demonstrated that the graph convolution operation is connected to a filtering operation on the graph spectral domain, the theoretical rationale for why this leads to higher performance on the collaborative filtering problem remains unknown. The presented work makes two contributions. First, we investigate the effect of using graph convolution throughout the user and item representation learning processes, demonstrating how the latent features learned are pushed from the filtering operation into the subspace spanned by the eigenvectors associated with the highest eigenvalues of the normalised adjacency matrix, and how vectors lying on this subspace are the optimal solutions for an objective function related to the sum of the prediction function over the training data. Then, we present an approach that 
    
[^7]: 迈向可解释的对话式推荐系统

    Towards Explainable Conversational Recommender Systems. (arXiv:2305.18363v1 [cs.IR])

    [http://arxiv.org/abs/2305.18363](http://arxiv.org/abs/2305.18363)

    本文提出了衡量对话式推荐系统的可解释性的十种评估视角，并通过构建新数据集来提高解释质量。

    

    传统推荐系统中的解释已经证明在帮助用户理解推荐合理性以及提高系统效率、透明度和可信度方面具有益处。在对话环境中，需要生成多个上下文化解释，这进一步增加了解释的挑战。为了更好地衡量对话式推荐系统的可解释性，我们提出了十种评估视角，结合传统推荐系统的概念和对话式推荐系统的特点。我们使用这些指标评估了五个已有的对话式推荐系统基准数据集，并观察到需要提高对话式推荐系统的解释质量的必要性。为了实现这一目标，我们采用手动和自动方法扩展了这些对话，并构建了一个新的对话式推荐系统数据集，名为“可解释推荐对话”（E-ReDial）。该数据集包括756个对话，超过2000条高质量的重写解释。我们比较了两种基线方法，并进行了实验验证。

    Explanations in conventional recommender systems have demonstrated benefits in helping the user understand the rationality of the recommendations and improving the system's efficiency, transparency, and trustworthiness. In the conversational environment, multiple contextualized explanations need to be generated, which poses further challenges for explanations. To better measure explainability in conversational recommender systems (CRS), we propose ten evaluation perspectives based on concepts from conventional recommender systems together with the characteristics of CRS. We assess five existing CRS benchmark datasets using these metrics and observe the necessity of improving the explanation quality of CRS. To achieve this, we conduct manual and automatic approaches to extend these dialogues and construct a new CRS dataset, namely Explainable Recommendation Dialogues (E-ReDial). It includes 756 dialogues with over 2,000 high-quality rewritten explanations. We compare two baseline approa
    
[^8]: DataChat：一个用于数据集搜索和可视化的会话代理的原型设计。

    DataChat: Prototyping a Conversational Agent for Dataset Search and Visualization. (arXiv:2305.18358v1 [cs.IR])

    [http://arxiv.org/abs/2305.18358](http://arxiv.org/abs/2305.18358)

    DataChat是一个用于数据集搜索和可视化的聊天机器人，通过图数据库和语言模型为用户提供更加智能化的数据搜索体验。

    

    数据用户需要相关的上下文和研究专业知识以有效地搜索和识别相关数据集。众所周知，元数据和搜索工具是支持数据搜索的两个关键因素。在本文中，我们提出了一种新颖的基于聊天机器人的搜索系统 DataChat，它利用图数据库和大型语言模型为用户提供与研究数据交互和搜索的新颖方式。

    Data users need relevant context and research expertise to effectively search for and identify relevant datasets. Leading data providers, such as the Inter-university Consortium for Political and Social Research (ICPSR), offer standardized metadata and search tools to support data search. Metadata standards emphasize the machine-readability of data and its documentation. There are opportunities to enhance dataset search by improving users' ability to learn about, and make sense of, information about data. Prior research has shown that context and expertise are two main barriers users face in effectively searching for, evaluating, and deciding whether to reuse data. In this paper, we propose a novel chatbot-based search system, DataChat, that leverages a graph database and a large language model to provide novel ways for users to interact with and search for research data. DataChat complements data archives' and institutional repositories' ongoing efforts to curate, preserve, and share 
    
[^9]: 实现开放世界产品属性挖掘：基于轻度监督方法的研究

    Towards Open-World Product Attribute Mining: A Lightly-Supervised Approach. (arXiv:2305.18350v1 [cs.LG])

    [http://arxiv.org/abs/2305.18350](http://arxiv.org/abs/2305.18350)

    该研究提出了一种用于电子商务产品属性挖掘的新任务设置，可以利用高质量的种子属性集合轻度监督并自动发现新的属性类型。通过自我监督启发式和无监督潜在属性，该方法能够以额外的隐含语义信号作为辅助监督，将现有类型的属性扩展最多12倍，并成功发掘了39％的新属性值。

    

    我们提出了一种新的电子商务产品属性挖掘任务设置，用于提取开放世界属性，同时减少人工干预。我们的监督来自于现有资源中引导的高质量种子属性集合，旨在扩展现有种子类型的属性词汇，并通过自动方式发现任何新的属性类型。我们创建了一个新数据集以支持我们的设置，并提出了特定于受限监督的Amacer方法。尤其是，由于那些未见过的新属性没有直接监督，我们的新颖公式利用了自我监督启发式和无监督潜在属性，利用产品上下文获得额外的隐含语义信号作为辅助监督。实验表明，我们的方法在F1值上超过了各种基线方法12个百分点，使现有类型的属性大大扩展了最多12倍，并且发现新属性值的能力达到了39％。

    We present a new task setting for attribute mining on e-commerce products, serving as a practical solution to extract open-world attributes without extensive human intervention. Our supervision comes from a high-quality seed attribute set bootstrapped from existing resources, and we aim to expand the attribute vocabulary of existing seed types, and also to discover any new attribute types automatically. A new dataset is created to support our setting, and our approach Amacer is proposed specifically to tackle the limited supervision. Especially, given that no direct supervision is available for those unseen new attributes, our novel formulation exploits self-supervised heuristic and unsupervised latent attributes, which attains implicit semantic signals as additional supervision by leveraging product context. Experiments suggest that our approach surpasses various baselines by 12 F1, expanding attributes of existing types significantly by up to 12 times, and discovering values from 39%
    
[^10]: 具有流行度偏见的排名：自增强动态下的用户福利

    Ranking with Popularity Bias: User Welfare under Self-Amplification Dynamics. (arXiv:2305.18333v1 [cs.IR])

    [http://arxiv.org/abs/2305.18333](http://arxiv.org/abs/2305.18333)

    研究了物品流行度、质量和位置偏差对用户福利的影响，提出了通过探索减轻流行度偏见负面影响的算法。

    

    虽然已经确认流行度偏见在推荐（和其他基于排名的）系统中发挥作用，但其对用户福利的影响的详细分析仍然缺乏。我们提出了一种通用机制，通过它，物品的流行度、质量和位置偏差可以影响用户选择，并且可以负面影响各种推荐策略的集体用户效用。我们将问题表述为非平稳上下文脱靶机，强调不是为了消除流行度偏见而是为了减轻其负面影响而进行探索的重要性。首先，普通的有流行度偏差的推荐系统会通过混淆物品质量和流行度而引发线性遗憾。更一般地，我们展示了即使在线性设置下，由于流行度偏见的混淆效应，物品质量的可识别性也可能无法实现。然而，在足够变异的假设下，我们开发了一种高效的类UCB算法，并证明了有效的遗憾保证。我们通过实验验证了我们提出的算法的有效性，并证实了流行度偏见的负面影响。

    While popularity bias is recognized to play a role in recommmender (and other ranking-based) systems, detailed analyses of its impact on user welfare have largely been lacking. We propose a general mechanism by which item popularity, item quality, and position bias can impact user choice, and how it can negatively impact the collective user utility of various recommender policies. Formulating the problem as a non-stationary contextual bandit, we highlight the importance of exploration, not to eliminate popularity bias, but to mitigate its negative effects. First, naive popularity-biased recommenders are shown to induce linear regret by conflating item quality and popularity. More generally, we show that, even in linear settings, identifiability of item quality may not be possible due to the confounding effects of popularity bias. However, under sufficient variability assumptions, we develop an efficient UCB-style algorithm and prove efficient regret guarantees. We complement our analys
    
[^11]: #REVAL：一种用于hashtag推荐的语义评估框架

    #REVAL: a semantic evaluation framework for hashtag recommendation. (arXiv:2305.18330v1 [cs.IR])

    [http://arxiv.org/abs/2305.18330](http://arxiv.org/abs/2305.18330)

    #REVAL是一种新颖的语义评估框架，用于解决传统评估方法无法考虑推荐和实际hashtag之间语义相关性问题。实验证明#REVAL在捕捉语义相关性方面是有效的。

    

    在许多在线社交网络系统中，自动评估hashtag推荐模型是一项基本任务。传统的评估方法是首先比较算法推荐的hashtag与实际的hashtag的精确对应关系，然后使用精确匹配的数量计算命中率、命中比率、精确度、召回率或F1分数。然而，这种评估方式忽略了推荐和实际hashtag之间的语义相关性。为了解决这个问题，我们提出了一种新颖的语义评估框架#REval，它包括一个称为BERTag的内部模块，可自动学习hashtag嵌入。我们使用提出的#REval-hit-ratio度量标准，研究了#REval框架在不同的词嵌入方法和推荐中的同义词和hashtag数量下的性能。在两个基准数据集上的实验表明，我们提出的框架在捕捉推荐和实际hashtag之间的语义相关性方面是有效的。

    Automatic evaluation of hashtag recommendation models is a fundamental task in many online social network systems. In the traditional evaluation method, the recommended hashtags from an algorithm are firstly compared with the ground truth hashtags for exact correspondences. The number of exact matches is then used to calculate the hit rate, hit ratio, precision, recall, or F1-score. This way of evaluating hashtag similarities is inadequate as it ignores the semantic correlation between the recommended and ground truth hashtags. To tackle this problem, we propose a novel semantic evaluation framework for hashtag recommendation, called #REval. This framework includes an internal module referred to as BERTag, which automatically learns the hashtag embeddings. We investigate on how the #REval framework performs under different word embedding methods and different numbers of synonyms and hashtags in the recommendation using our proposed #REval-hit-ratio measure. Our experiments of the propo
    
[^12]: 文本分析在公共服务协同创作中的应用：文献综述和研究框架

    Application of Text Analytics in Public Service Co-Creation: Literature Review and Research Framework. (arXiv:2305.18316v1 [cs.CY])

    [http://arxiv.org/abs/2305.18316](http://arxiv.org/abs/2305.18316)

    本文系统综述了在公共服务领域中应用文本分析技能以支持公共服务协同创作的研究，发掘了TA技术和公共服务的对公共价值的影响，以及在公共服务领域中TA技术的应用前景。

    

    公共部门面临着多个挑战，例如来自内部外部的需求变化，公民对公共部门组织的不满和挫败感，这些问题需要得到解决。公共服务协同创作是传统自上而下的公共服务开发的一种替代方案，它促进了利益相关者之间的合作，旨在创建更好的公共服务并实现公共价值。同时，文本数据的可用性推动了数据分析的发展。尽管协同创作和TA在私营部门中都得到了应用，但本文研究了现有的关于应用文本分析技术支持公共服务协同创作的研究，并对975篇文章进行了系统综述，分析了TA技术和公共服务对公共价值的影响。

    The public sector faces several challenges, such as a number of external and internal demands for change, citizens' dissatisfaction and frustration with public sector organizations, that need to be addressed. An alternative to the traditional top-down development of public services is co-creation of public services. Co-creation promotes collaboration between stakeholders with the aim to create better public services and achieve public values. At the same time, data analytics has been fuelled by the availability of immense amounts of textual data. Whilst both co-creation and TA have been used in the private sector, we study existing works on the application of Text Analytics (TA) techniques on text data to support public service co-creation. We systematically review 75 of the 979 papers that focus directly or indirectly on the application of TA in the context of public service development. In our review, we analyze the TA techniques, the public service they support, public value outcome
    
[^13]: CDJUR-BR -- 带有精细命名实体的巴西司法文件黄金收藏

    CDJUR-BR -- A Golden Collection of Legal Document from Brazilian Justice with Fine-Grained Named Entities. (arXiv:2305.18315v1 [cs.CL])

    [http://arxiv.org/abs/2305.18315](http://arxiv.org/abs/2305.18315)

    CDJUR-BR是一份稳健的黄金收藏，包含巴西司法文件中的精细命名实体，该收藏涵盖各种法律程序文件，并有助于解决目前命名实体识别（NER）无法轻而易举地识别法律实践文本中实体的问题。

    

    对于大多数法律人工智能（Legal AI）应用程序而言，命名实体识别（NER）是一项基本任务。然而，法律实践中产生的文本涉及到的实体并非当前可用的NER轻而易举地识别。缺乏法规、判例、证据、惩罚、法律程序中人们的角色（法官、律师、受害者、被告、证人）、位置类型（犯罪地点、被告地址）等的分类。因此，仍需要一个用法律领域的精细实体进行注释的稳健的黄金收藏，涵盖法律程序的各种文件，例如请愿书、调查、投诉、决定和判决。在本文中，我们描述了巴西司法黄金收藏（CDJUR-BR）的开发，该收藏包含一组由法律文献专家注释的精细命名实体。创建CDJUR-BR遵循了自己的

    A basic task for most Legal Artificial Intelligence (Legal AI) applications is Named Entity Recognition (NER). However, texts produced in the context of legal practice make references to entities that are not trivially recognized by the currently available NERs. There is a lack of categorization of legislation, jurisprudence, evidence, penalties, the roles of people in a legal process (judge, lawyer, victim, defendant, witness), types of locations (crime location, defendant's address), etc. In this sense, there is still a need for a robust golden collection, annotated with fine-grained entities of the legal domain, and which covers various documents of a legal process, such as petitions, inquiries, complaints, decisions and sentences. In this article, we describe the development of the Golden Collection of the Brazilian Judiciary (CDJUR-BR) contemplating a set of fine-grained named entities that have been annotated by experts in legal documents. The creation of CDJUR-BR followed its ow
    
[^14]: 针对系统配置的风险敏感选择的选择性查询处理

    Selective Query Processing: a Risk-Sensitive Selection of System Configurations. (arXiv:2305.18311v1 [cs.IR])

    [http://arxiv.org/abs/2305.18311](http://arxiv.org/abs/2305.18311)

    提出了一个针对信息检索系统的风险敏感查询选择框架，可以在一组可能的系统配置中选择最佳配置，从而提高搜索效率和利用系统资源的效率。

    

    在信息检索系统中，搜索参数会根据一组过去的搜索进行优化以确保高有效性，然后将这些优化参数用作所有后续查询的系统配置。然而，更好的方法是根据实际查询来适应参数。 选择性查询扩展是这种方法之一，其中系统自动决定是否扩展查询，形成两种可能的系统配置。最近，这种方法扩展到包括许多其他参数，从而导致许多可能的系统配置，其中系统在每个查询的基础上自动选择最佳配置。为了确定在实际系统中在每个查询基础上使用的理想配置，我们开发了一种方法，其中预先选择了有限数量的可能配置，然后在元搜索引擎中使用这些配置来确定每个查询的最佳搜索配置。我们为信息检索系统定义了一个风险敏感的查询选择框架，该框架基于预定义的可能配置集确定给定查询的最优系统配置。这种方法可以更有效地利用系统资源并改善搜索性能。

    In information retrieval systems, search parameters are optimized to ensure high effectiveness based on a set of past searches and these optimized parameters are then used as the system configuration for all subsequent queries. A better approach, however, would be to adapt the parameters to fit the query at hand. Selective query expansion is one such an approach, in which the system decides automatically whether or not to expand the query, resulting in two possible system configurations. This approach was extended recently to include many other parameters, leading to many possible system configurations where the system automatically selects the best configuration on a per-query basis. To determine the ideal configurations to use on a per-query basis in real-world systems we developed a method in which a restricted number of possible configurations is pre-selected and then used in a meta-search engine that decides the best search configuration on a per query basis. We define a risk-sens
    
[^15]: 多视角交互式协同过滤

    Multi-View Interactive Collaborative Filtering. (arXiv:2305.18306v1 [cs.IR])

    [http://arxiv.org/abs/2305.18306](http://arxiv.org/abs/2305.18306)

    提出了基于多视角交互主题回归算法（MV-ICTR）的推荐系统，在不同视角下同时纳入评分和上下文信息来建模物品特定功能的相关性和用户的个人偏好，采用多臂老虎机策略进行持续的在线个性化，显著提高了数据集上性能。

    

    在许多场景下，推荐系统中的用户交互数据（如点击或评分）往往很少，物品的换手率（例如新文章、招聘信息）很高。因此，除了用户-物品评分外，集成上下文“边”信息是非常可取的。虽然存在可以同时处理评分和上下文数据的算法，但这些算法通常仅能进行样本内推荐，受到维度诅咒的限制，并不采用多臂老虎机（MAB）策略进行长期累积收益优化。我们提出了多视角交互主题回归（MV-ICTR）算法，这是一种新颖的部分在线潜在因子推荐算法，同时纳入评分和上下文信息来建模物品特定功能的相关性和用户的个人偏好，采用多臂老虎机策略进行持续在线个性化。该算法在数据集上的性能显著提高。

    In many scenarios, recommender system user interaction data such as clicks or ratings is sparse, and item turnover rates (e.g., new articles, job postings) high. Given this, the integration of contextual "side" information in addition to user-item ratings is highly desirable. Whilst there are algorithms that can handle both rating and contextual data simultaneously, these algorithms are typically limited to making only in-sample recommendations, suffer from the curse of dimensionality, and do not incorporate multi-armed bandit (MAB) policies for long-term cumulative reward optimization. We propose multi-view interactive topic regression (MV-ICTR) a novel partially online latent factor recommender algorithm that incorporates both rating and contextual information to model item-specific feature dependencies and users' personal preferences simultaneously, with multi-armed bandit policies for continued online personalization. The result is significantly increased performance on datasets wi
    
[^16]: 使用潜在Bandits的高准确度和低遗憾用户冷启动方法

    High Accuracy and Low Regret for User-Cold-Start Using Latent Bandits. (arXiv:2305.18305v1 [cs.IR])

    [http://arxiv.org/abs/2305.18305](http://arxiv.org/abs/2305.18305)

    使用潜在Bandits算法解决用户冷启动问题，同时实现更高的准确率和更低的遗憾。

    

    我们开发了一种新型的潜在Bandits算法，用于解决新用户加入推荐系统时面临的冷启动问题。这种新算法在同时实现更高的准确率和更低的遗憾方面明显优于现有技术。

    We develop a novel latent-bandit algorithm for tackling the cold-start problem for new users joining a recommender system. This new algorithm significantly outperforms the state of the art, simultaneously achieving both higher accuracy and lower regret.
    
[^17]: 语义感知数字孪生体在元宇宙中的综述

    Semantic-aware Digital Twin for Metaverse: A Comprehensive Review. (arXiv:2305.18304v1 [cs.CY])

    [http://arxiv.org/abs/2305.18304](http://arxiv.org/abs/2305.18304)

    本文综述了数字孪生体在元宇宙中的部署，并介绍了通过语义通信实现数字孪生体与元宇宙结合的框架，以及其在智能工业应用中的基本原理和性能优化的实现。

    

    为了在元宇宙中实现数字孪生体的部署，提出了具有语义感知能力的范式，以实现准确的、面向任务的信息提取和内在的智能化。然而，这种框架需要将元宇宙环境中的所有设备直接连接到语义模型中，以实现信息的忠实解释。相反，本文介绍了数字孪生体框架，考虑了智能工业应用，通过与元宇宙使能技术结合使用，实现了语义通信。本文介绍了语义通信、元宇宙和数字孪生体的基础知识，并在工业车间管理应用用例中展示了该框架的基本原理，以通过语义通信改善其性能。介绍了这些技术与基本架构的集成以及对未来工业应用的影响。

    To facilitate the deployment of digital twins in Metaverse, the paradigm with semantic awareness has been proposed as a means for enabling accurate and task-oriented information extraction with inherent intelligence. However, this framework requires all devices in the Metaverse environment to be directly linked with the semantic model to enable faithful interpretation of messages. In contrast, this article introduces the digital twin framework, considering a smart industrial application, which enables semantic communication in conjugation with the Metaverse enabling technologies. The fundamentals of this framework are demonstrated on an industrial shopfloor management use case with a digital twin so as to improve its performance through semantic communication. An overview of semantic communication, Metaverse, and digital twins is presented. Integration of these technologies with the basic architecture as well as the impact on future industrial applications is presented. In a nutshell, 
    
[^18]: 在电子商务中使用数据增强实现一致的文本分类

    Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])

    [http://arxiv.org/abs/2305.05402](http://arxiv.org/abs/2305.05402)

    本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。

    

    大规模电子商务数据分类是一项关键的、广泛应用于工业领域的任务。本文旨在改进一家主要网络公司已经在使用的产品分类模型，该模型用于多种应用。在该模型核心中，产品分类模型是一个文本分类模型，接受产品标题作为输入，并从数千个可用候选项中输出最合适的类别。经过进一步观察，我们发现了类似物品标签上的不一致性。例如，标题中关于颜色或尺寸的小变化，会对模型产生较大影响。这种现象可能会对下游的推荐或搜索应用造成负面影响，导致用户体验下降。为了解决这个问题，我们提出了一个新的框架，实现一致的文本分类。我们的目标是提高模型的一致性，并保持其生产水平的性能。

    The categorization of massive e-Commerce data is a crucial, well-studied task, which is prevalent in industrial settings. In this work, we aim to improve an existing product categorization model that is already in use by a major web company, serving multiple applications. At its core, the product categorization model is a text classification model that takes a product title as an input and outputs the most suitable category out of thousands of available candidates. Upon a closer inspection, we found inconsistencies in the labeling of similar items. For example, minor modifications of the product title pertaining to colors or measurements majorly impacted the model's output. This phenomenon can negatively affect downstream recommendation or search applications, leading to a sub-optimal user experience.  To address this issue, we propose a new framework for consistent text categorization. Our goal is to improve the model's consistency while maintaining its production-level performance. W
    
[^19]: FinalMLP: 用于CTR预测的增强双流MLP模型

    FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction. (arXiv:2304.00902v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2304.00902](http://arxiv.org/abs/2304.00902)

    本研究提出了一个用于CTR预测的增强双流MLP模型，经实证研究表明，该模型仅是简单地结合两个MLP就可以实现令人惊讶的良好性能。

    

    点击率预测是在线广告和推荐中的基本任务之一。虽然多层感知器（MLP）在许多深度CTR预测模型中作为核心组件，但广为人知的是，仅应用一个基本MLP网络在学习乘法特征相互作用方面并不高效。因此，许多两个流交互模型（例如，DeepFM和DCN）通过将MLP网络与另一个专用网络集成以增强CTR预测。由于MLP流隐式地学习特征交互作用，因此现有研究主要关注于增强补充流中的显式特征交互作用。相反，我们的实证研究表明，一个经过良好调整的双流MLP模型，它只是简单地结合了两个MLP，甚至可以实现令人惊讶的良好性能，这在现有的工作中从未被报道过。基于这个观察结果，我们进一步提出了特征选择和交互聚合层。

    Click-through rate (CTR) prediction is one of the fundamental tasks for online advertising and recommendation. While multi-layer perceptron (MLP) serves as a core component in many deep CTR prediction models, it has been widely recognized that applying a vanilla MLP network alone is inefficient in learning multiplicative feature interactions. As such, many two-stream interaction models (e.g., DeepFM and DCN) have been proposed by integrating an MLP network with another dedicated network for enhanced CTR prediction. As the MLP stream learns feature interactions implicitly, existing research focuses mainly on enhancing explicit feature interactions in the complementary stream. In contrast, our empirical study shows that a well-tuned two-stream MLP model that simply combines two MLPs can even achieve surprisingly good performance, which has never been reported before by existing work. Based on this observation, we further propose feature selection and interaction aggregation layers that c
    
[^20]: CONE：用于长视频时间定位的高效粗-细对齐框架

    CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding. (arXiv:2209.10918v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.10918](http://arxiv.org/abs/2209.10918)

    本文提出了CONE，一个高效的粗-细对齐框架，可用于长视频时间定位。CONE通过基于查询的窗口选择策略和对比学习机制提升了多模态对齐，并在两个大规模长视频时间定位基准测试中取得最先进结果。

    

    本文解决了一个新兴且具有挑战性的问题——长视频时间定位（VTG），即定位与自然语言查询相关的视频片段。相比于短视频，长视频同样非常受欢迎，但是探索较少，这带来了多个挑战，例如更高的推理计算成本和弱的多模态对齐。为了解决这些挑战，我们提出了CONE，一个高效的粗-细对齐框架。CONE是一个插拔式的框架，可在现有的VTG模型上处理长视频，通过滑动窗口机制。具体来说，CONE（1）引入了基于查询的窗口选择策略以加快推理速度，（2）提议了通过新增对比学习来增强长视频的多模态对齐的粗细机制。对两个大规模长VTG基准测试进行的大量实验均表明，CONE在性能上都有很大提升（例如在MAD上从3.13％到6.87％），并且具有最先进的结果。分析也证明了CONE模型的有效性和可解释性。

    This paper tackles an emerging and challenging problem of long video temporal grounding~(VTG) that localizes video moments related to a natural language (NL) query. Compared with short videos, long videos are also highly demanded but less explored, which brings new challenges in higher inference computation cost and weaker multi-modal alignment. To address these challenges, we propose CONE, an efficient COarse-to-fiNE alignment framework. CONE is a plug-and-play framework on top of existing VTG models to handle long videos through a sliding window mechanism. Specifically, CONE (1) introduces a query-guided window selection strategy to speed up inference, and (2) proposes a coarse-to-fine mechanism via a novel incorporation of contrastive learning to enhance multi-modal alignment for long videos. Extensive experiments on two large-scale long VTG benchmarks consistently show both substantial performance gains (e.g., from 3.13% to 6.87% on MAD) and state-of-the-art results. Analyses also 
    
[^21]: 基于LDA主题建模的自动文本摘要的数据驱动潜在语意分析

    A Data-driven Latent Semantic Analysis for Automatic Text Summarization using LDA Topic Modelling. (arXiv:2207.14687v7 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.14687](http://arxiv.org/abs/2207.14687)

    本研究使用LDA主题建模方法进行文本摘要，针对与基因和疾病相关的医学科学期刊文章进行研究，提供了一个能够保留关键信息并保持原始意义的压缩版本，并使用PyLDAvis进行交互式可视化。

    

    随着现代时代大数据挖掘和大文本分析的到来和普及，自动文本摘要成为从文档中提取和检索重要信息的重要手段。本研究从单个和多个文档的角度探讨了自动文本摘要的各个方面。摘要是将庞大的文本文章压缩为短小汇总版本的任务。目的是缩小文本的大小，但要保留关键重要信息并保持原始文档的意义。“潜在狄利克雷分配”（LDA）方法被用于从与基因和疾病相关的医学科学期刊文章中进行主题建模。在本研究中，使用PyLDAvis的基于网页的交互式可视化工具来可视化所选主题。这种可视化提供了主要主题的总体视图，同时允许深入理解个体的普遍性。

    With the advent and popularity of big data mining and huge text analysis in modern times, automated text summarization became prominent for extracting and retrieving important information from documents. This research investigates aspects of automatic text summarization from the perspectives of single and multiple documents. Summarization is a task of condensing huge text articles into short, summarized versions. The text is reduced in size for summarization purpose but preserving key vital information and retaining the meaning of the original document. This study presents the Latent Dirichlet Allocation (LDA) approach used to perform topic modelling from summarised medical science journal articles with topics related to genes and diseases. In this study, PyLDAvis web-based interactive visualization tool was used to visualise the selected topics. The visualisation provides an overarching view of the main topics while allowing and attributing deep meaning to the prevalence individual to
    
[^22]: C2-CRS：面向对话推荐系统的粗到细对比学习

    C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational Recommender System. (arXiv:2201.02732v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.02732](http://arxiv.org/abs/2201.02732)

    本文提出了一种新的粗到细对比学习框架，用于对话式推荐系统中多类型外部数据的数据语义融合，在此基础上提高了数据的处理效率。

    

    对话式推荐系统旨在通过自然语言交互向用户推荐适合的物品。为了开发有效的对话式推荐系统，一个主要的技术问题是如何从非常有限的对话上下文中准确地推断用户偏好。为了解决这个问题，一种有前途的解决方案是结合外部数据来丰富上下文信息。然而，以往的研究主要集中在为一些特定类型的外部数据设计融合模型，这不适用于模型和利用多类型的外部数据。为了有效利用多类型的外部数据，我们提出了一种新的粗到细对比学习框架来改善对话式推荐系统的数据语义融合。在我们的方法中，我们首先从不同的数据信号中提取和表示多种粒度的语义单元，然后以粗到细的方式对齐相关的多种语义单元。为了实现这个框架，我们设计了粗粒度和细粒度的过程来对用户建模。

    Conversational recommender systems (CRS) aim to recommend suitable items to users through natural language conversations. For developing effective CRSs, a major technical issue is how to accurately infer user preference from very limited conversation context. To address issue, a promising solution is to incorporate external data for enriching the context information. However, prior studies mainly focus on designing fusion models tailored for some specific type of external data, which is not general to model and utilize multi-type external data.  To effectively leverage multi-type external data, we propose a novel coarse-to-fine contrastive learning framework to improve data semantic fusion for CRS. In our approach, we first extract and represent multi-grained semantic units from different data signals, and then align the associated multi-type semantic units in a coarse-to-fine way. To implement this framework, we design both coarse-grained and fine-grained procedures for modeling user 
    
[^23]: 面向隐私保护新闻推荐的高效联邦学习框架

    Efficient-FedRec: Efficient Federated Learning Framework for Privacy-Preserving News Recommendation. (arXiv:2109.05446v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2109.05446](http://arxiv.org/abs/2109.05446)

    本文提出了一种新的联邦学习框架，用于隐私保护的新闻推荐。该框架将新闻推荐模型分解为大型新闻模型和轻量级用户模型，通过将新闻表示和用户模型在服务器和客户端之间进行通信，从而实现了高效率和有效性的训练。

    

    新闻推荐对于个性化新闻访问至关重要。大多数现有的新闻推荐方法依赖于中心化存储用户历史新闻点击行为数据，这可能会引发隐私问题和危害。联邦学习是一种隐私保护框架，可用于多个客户端共同训练模型而无需共享其私有数据。然而，以联邦方式直接学习许多现有的新闻推荐模型的计算和通信成本对于用户客户端是不可接受的。因此，本文提出了一种高效的联邦学习框架，可用于面向隐私保护的新闻推荐。具体来说，我们将新闻推荐模型分解为服务器维护的大型新闻模型和在服务器和客户端之间共享的轻量级用户模型，其中新闻表示和用户模型在服务器和客户端之间进行通信。然后，客户端请求服务器提供用户模型和新闻表示，并在本地使用自己的私有数据进行训练。接着，他们将更新后的用户模型上传到服务器，服务器对它们进行聚合以更新集中式的新闻模型。在两个真实数据集上的实验结果表明了我们提出的框架的有效性和效率，既保持了用户隐私，同时与现有的中心化和联邦学习方法相比表现出竞争性的性能。

    News recommendation is critical for personalized news access. Most existing news recommendation methods rely on centralized storage of users' historical news click behavior data, which may lead to privacy concerns and hazards. Federated Learning is a privacy-preserving framework for multiple clients to collaboratively train models without sharing their private data. However, the computation and communication cost of directly learning many existing news recommendation models in a federated way are unacceptable for user clients. In this paper, we propose an efficient federated learning framework for privacy-preserving news recommendation. Instead of training and communicating the whole model, we decompose the news recommendation model into a large news model maintained in the server and a light-weight user model shared on both server and clients, where news representations and user model are communicated between server and clients. More specifically, the clients request the user model an
    

