# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Enhancing Job Recommendation through LLM-based Generative Adversarial Networks.](http://arxiv.org/abs/2307.10747) | 本论文提出一种基于LLM的生成对抗网络来增强工作推荐。通过利用LLMs丰富的外部知识和文本处理能力，可以提高推荐的准确性。然而，需要解决LLMs虚构生成和少样本问题。 |
| [^2] | [A Constraint-based Recommender System via RDF Knowledge Graphs.](http://arxiv.org/abs/2307.10702) | 本文研究并提出了一种基于RDF知识图的约束推荐系统，应用于车辆购买/销售领域，通过显式利用约束和知识图的结合，能够高效地根据用户的偏好识别推荐。 |
| [^3] | [A Personalized Recommender System Based-on Knowledge Graph Embeddings.](http://arxiv.org/abs/2307.10680) | 本研究通过知识图谱嵌入构建了一个个性化推荐系统，在车辆购买/销售领域中展现了其良好的推荐效果。 |
| [^4] | [Language-Enhanced Session-Based Recommendation with Decoupled Contrastive Learning.](http://arxiv.org/abs/2307.10650) | 本文提出了一种基于会话的推荐系统，利用解耦对比学习和多模态方法来解决流行偏见和冷启动问题。通过使用文本内容和物品ID，利用预训练语言模型提取特征，同时学习通用物品表示，从而提高语言表示的效果。 |
| [^5] | [Improving Semantic Similarity Measure Within a Recommender System Based-on RDF Graphs.](http://arxiv.org/abs/2307.10639) | 本文提出了一种改进推荐系统中语义相似度计算的方法，以提高推荐系统在处理文本数据时的效果。 |
| [^6] | [Detecting deceptive reviews using text classification.](http://arxiv.org/abs/2307.10617) | 这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。 |
| [^7] | [SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval.](http://arxiv.org/abs/2307.10488) | SPRINT是一个统一的Python工具包，基于Pyserini和Lucene，支持评估和解析零样本神经稀疏检索。它解决了缺乏统一环境和实现在未见过领域上的检索能力的问题。 |
| [^8] | [Fast Approximate Nearest Neighbor Search with a Dynamic Exploration Graph using Continuous Refinement.](http://arxiv.org/abs/2307.10479) | 本论文提出了一种名为动态探索图（DEG）的算法，通过结合连续细化和图构建过程，达到了在近似最近邻搜索中提高搜索效率、预测索引大小、保持连通性和动态图结构的目的。 |
| [^9] | [Classification of Visualization Types and Perspectives in Patents.](http://arxiv.org/abs/2307.10471) | 本文主要研究了专利图像中可视化类型和视角的分类问题，扩展了CLEF-IP数据集并采用最先进的深度学习方法进行了分类。这项研究对于促进专利探索和检索具有重要意义。 |
| [^10] | [IncDSI: Incrementally Updatable Document Retrieval.](http://arxiv.org/abs/2307.10323) | IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。 |
| [^11] | [Mood Classification of Bangla Songs Based on Lyrics.](http://arxiv.org/abs/2307.10314) | 本研究通过分析孟加拉歌曲的歌词，成功实现了对这些歌曲的情绪进行多类分类，包括快乐、悲伤、浪漫和放松，为使音乐更贴近人们的情感做出了重要贡献。 |
| [^12] | [Automated Action Model Acquisition from Narrative Texts.](http://arxiv.org/abs/2307.10247) | NaRuto是一个系统，可以从叙事文本中自动提取结构化事件，并生成高质量的行动模型，优于现有的完全自动化方法和与半自动化方法相媲美。 |
| [^13] | [Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors.](http://arxiv.org/abs/2307.10244) | 本研究对深度推荐系统在面对硬件错误时的健壮性进行了系统研究，开发了一个错误注入框架Terrorch，发现激活剪裁是一种有希望的错误缓解方法，可以恢复高达30%的被降低的AUC-ROC得分。 |
| [^14] | [Prompt Tuning on Graph-augmented Low-resource Text Classification.](http://arxiv.org/abs/2307.10230) | 本论文提出了一种基于图增强的低资源文本分类模型G2P2，通过预训练和提示的方式，利用图结构的语义关系来提升低资源文本分类的性能。 |
| [^15] | [An IPW-based Unbiased Ranking Metric in Two-sided Markets.](http://arxiv.org/abs/2307.10204) | 这项研究提出了一种基于IPW的无偏排序度量方法，针对双边市场中用户之间的偏见相互作用，解决了位置偏见和两个用户群体的位置偏差问题。 |
| [^16] | [Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning.](http://arxiv.org/abs/2307.10189) | 本文介绍了一种名为CrowdOpinion的无监督学习方法，可以通过汇集标签分布中相似的项目，揭示在群体中存在的有意义的观点分歧，特别是在标注者人群中可能已经代表性不足的群体中。 |
| [^17] | [Improving Text Matching in E-Commerce Search with A Rationalizable, Intervenable and Fast Entity-Based Relevance Model.](http://arxiv.org/abs/2307.00370) | 本研究提出了一种称为基于实体的关联模型（EBRM）的新模型，将查询-商品关联问题分解为多个查询-实体关联问题，并使用软逻辑聚合结果，以提高准确性和推理速度。 |
| [^18] | [ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis.](http://arxiv.org/abs/2306.11296) | 该论文使用提示工程的方法指导ChatGPT对科学文献进行自动化文本挖掘，以获得金属-有机框架（MOF）合成条件。通过该系统，可以高精确地提取大量合成参数，为MOF合成提供支持。 |
| [^19] | [Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval.](http://arxiv.org/abs/2205.11498) | 通过学习哈希技术提高零样本密集检索的准确性和效率，克服了存储密集索引的高内存使用问题，并在跨领域环境中进行了评估。 |
| [^20] | [Deep Exploration for Recommendation Systems.](http://arxiv.org/abs/2109.12509) | 本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。 |
| [^21] | [Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior Implicit Recommendation.](http://arxiv.org/abs/2105.11876) | 提出了一种基于准则的非采样学习框架，命名为CHCF，用于多行为隐式推荐的异构协同过滤。该方法通过引入上限和下限阈值来指示选择标准，并指导用户偏好学习。 |
| [^22] | [ABNIRML: Analyzing the Behavior of Neural IR Models.](http://arxiv.org/abs/2011.00696) | ABNIRML提供了一个全面的框架，分析了神经信息检索模型的行为，包括写作风格、事实性、对改写和词序的敏感性等特征。通过进行广泛的实证研究，我们探究了神经模型增益的因素，并发现了潜在的偏见。 |

# 详细

[^1]: 通过基于LLM的生成对抗网络增强工作推荐

    Enhancing Job Recommendation through LLM-based Generative Adversarial Networks. (arXiv:2307.10747v1 [cs.IR])

    [http://arxiv.org/abs/2307.10747](http://arxiv.org/abs/2307.10747)

    本论文提出一种基于LLM的生成对抗网络来增强工作推荐。通过利用LLMs丰富的外部知识和文本处理能力，可以提高推荐的准确性。然而，需要解决LLMs虚构生成和少样本问题。

    

    在线招聘平台上向用户推荐合适的工作是一个关键任务，可以提高用户满意度和平台的盈利能力。现有的工作推荐方法面临的挑战包括用户简历的低质量，影响了其准确性和实际效果。随着大型语言模型（LLMs）的快速发展，利用其中包含的丰富外部知识以及它们强大的文本处理和推理能力，是实现更准确的推荐的有希望的方法。然而，直接利用LLMs来增强推荐结果并非适用于所有情况，因为LLMs可能存在虚构生成和少样本问题，降低了简历完成的质量。本文提出了一种新的基于LLM的工作推荐方法。为了缓解LLMs虚构生成的限制，我们提取准确和有价值信息。

    Recommending suitable jobs to users is a critical task in online recruitment platforms, as it can enhance users' satisfaction and the platforms' profitability. While existing job recommendation methods encounter challenges such as the low quality of users' resumes, which hampers their accuracy and practical effectiveness. With the rapid development of large language models (LLMs), utilizing the rich external knowledge encapsulated within them, as well as their powerful capabilities of text processing and reasoning, is a promising way to complete users' resumes for more accurate recommendations. However, directly leveraging LLMs to enhance recommendation results is not a one-size-fits-all solution, as LLMs may suffer from fabricated generation and few-shot problems, which degrade the quality of resume completion. In this paper, we propose a novel LLM-based approach for job recommendation. To alleviate the limitation of fabricated generation for LLMs, we extract accurate and valuable inf
    
[^2]: 基于RDF知识图的约束推荐系统

    A Constraint-based Recommender System via RDF Knowledge Graphs. (arXiv:2307.10702v1 [cs.IR])

    [http://arxiv.org/abs/2307.10702](http://arxiv.org/abs/2307.10702)

    本文研究并提出了一种基于RDF知识图的约束推荐系统，应用于车辆购买/销售领域，通过显式利用约束和知识图的结合，能够高效地根据用户的偏好识别推荐。

    

    知识图以RDF形式表示，能够通过本体模型来建模实体及其关系。近年来，知识图在信息建模方面受到了广泛关注。在推荐系统中，物品和用户可以被映射和集成到知识图中，从而可以表示用户和物品之间更多的链接和关系。基于约束的推荐系统基于显式利用约束来深入挖掘推荐知识，并识别相关的推荐。当结合知识图时，基于约束的推荐系统在约束集方面获得了多个优势。本文研究并提出了一种基于RDF知识图应用于车辆购买/销售领域的约束推荐系统的构建方法。我们的实验结果表明，所提出的方法能够高效地根据用户的偏好识别推荐。

    Knowledge graphs, represented in RDF, are able to model entities and their relations by means of ontologies. The use of knowledge graphs for information modeling has attracted interest in recent years. In recommender systems, items and users can be mapped and integrated into the knowledge graph, which can represent more links and relationships between users and items. Constraint-based recommender systems are based on the idea of explicitly exploiting deep recommendation knowledge through constraints to identify relevant recommendations. When combined with knowledge graphs, a constraint-based recommender system gains several benefits in terms of constraint sets. In this paper, we investigate and propose the construction of a constraint-based recommender system via RDF knowledge graphs applied to the vehicle purchase/sale domain. The results of our experiments show that the proposed approach is able to efficiently identify recommendations in accordance with user preferences.
    
[^3]: 基于知识图谱嵌入的个性化推荐系统

    A Personalized Recommender System Based-on Knowledge Graph Embeddings. (arXiv:2307.10680v1 [cs.AI])

    [http://arxiv.org/abs/2307.10680](http://arxiv.org/abs/2307.10680)

    本研究通过知识图谱嵌入构建了一个个性化推荐系统，在车辆购买/销售领域中展现了其良好的推荐效果。

    

    知识图谱通过本体论对实体及其关系进行建模，已被证明在信息建模中非常有效。最近，人们对将知识图谱用作信息建模的兴趣不断增长，因此在推荐系统中的应用也越来越广泛。通过将用户和物品纳入知识图谱，这些系统可以更好地捕捉它们之间的隐含关联并提供更准确的推荐。本文通过应用于车辆购买/销售领域的知识图谱嵌入，研究并提出了一种个性化推荐系统的构建方法。实验结果表明，所提出的方法能够提供与个体用户一致的相关推荐。

    Knowledge graphs have proven to be effective for modeling entities and their relationships through the use of ontologies. The recent emergence in interest for using knowledge graphs as a form of information modeling has led to their increased adoption in recommender systems. By incorporating users and items into the knowledge graph, these systems can better capture the implicit connections between them and provide more accurate recommendations. In this paper, we investigate and propose the construction of a personalized recommender system via knowledge graphs embedding applied to the vehicle purchase/sale domain. The results of our experimentation demonstrate the efficacy of the proposed method in providing relevant recommendations that are consistent with individual users.
    
[^4]: 通过解耦对比学习来增强语言增强的基于会话的推荐系统

    Language-Enhanced Session-Based Recommendation with Decoupled Contrastive Learning. (arXiv:2307.10650v1 [cs.IR])

    [http://arxiv.org/abs/2307.10650](http://arxiv.org/abs/2307.10650)

    本文提出了一种基于会话的推荐系统，利用解耦对比学习和多模态方法来解决流行偏见和冷启动问题。通过使用文本内容和物品ID，利用预训练语言模型提取特征，同时学习通用物品表示，从而提高语言表示的效果。

    

    基于会话的推荐技术旨在通过分析过去的交互来捕捉动态用户行为。然而，现有方法严重依赖于历史物品ID序列以提取用户偏好，导致了流行偏见和冷启动问题等挑战。在本文中，我们提出了一种混合多模态方法来解决基于会话的推荐中的这些挑战。我们的方法结合了不同的模态，包括文本内容和物品ID，利用CatBoost利用这些模态的互补性。为了学习通用物品表示，我们设计了一种基于语言表示的物品检索架构，利用预训练语言模型从文本内容中提取特征。此外，我们引入了一种新的解耦对比学习方法来增强语言表示的有效性。这种技术解耦了序列表示和物品表示空间，促进双向对齐

    Session-based recommendation techniques aim to capture dynamic user behavior by analyzing past interactions. However, existing methods heavily rely on historical item ID sequences to extract user preferences, leading to challenges such as popular bias and cold-start problems. In this paper, we propose a hybrid multimodal approach for session-based recommendation to address these challenges. Our approach combines different modalities, including textual content and item IDs, leveraging the complementary nature of these modalities using CatBoost. To learn universal item representations, we design a language representation-based item retrieval architecture that extracts features from the textual content utilizing pre-trained language models. Furthermore, we introduce a novel Decoupled Contrastive Learning method to enhance the effectiveness of the language representation. This technique decouples the sequence representation and item representation space, facilitating bidirectional alignmen
    
[^5]: 在基于RDF图的推荐系统中改进语义相似度测量

    Improving Semantic Similarity Measure Within a Recommender System Based-on RDF Graphs. (arXiv:2307.10639v1 [cs.IR])

    [http://arxiv.org/abs/2307.10639](http://arxiv.org/abs/2307.10639)

    本文提出了一种改进推荐系统中语义相似度计算的方法，以提高推荐系统在处理文本数据时的效果。

    

    在当今信息爆炸的时代，越来越多的用户依赖推荐系统来获得更好的建议、推荐或灵感。语义相关性或相似性的测量在处理文本数据的不同应用中扮演着重要角色，就像在推荐系统中一样。在过去几年中，许多本体论已被开发并用作信息系统中知识库的结构化表示形式。本文提出并实施了一种在基于RDF图的推荐系统中改进语义相似度计算的方法。

    In today's era of information explosion, more users are becoming more reliant upon recommender systems to have better advice, suggestions, or inspire them. The measure of the semantic relatedness or likeness between terms, words, or text data plays an important role in different applications dealing with textual data, as in a recommender system. Over the past few years, many ontologies have been developed and used as a form of structured representation of knowledge bases for information systems. The measure of semantic similarity from ontology has developed by several methods. In this paper, we propose and carry on an approach for the improvement of semantic similarity calculations within a recommender system based-on RDF graphs.
    
[^6]: 使用文本分类检测虚假评论

    Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])

    [http://arxiv.org/abs/2307.10617](http://arxiv.org/abs/2307.10617)

    这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。

    

    近年来，在线评论在推广任何产品或服务方面发挥着重要作用。企业可能会嵌入虚假评论以吸引客户购买他们的产品。他们甚至可能突出强调自己产品的优点或批评竞争对手的产品。市场营销人员、广告商和其他在线商业用户有动机为他们想要推广的产品编写虚假的正面评论，或者为他们真正不喜欢的产品提供虚假的负面评论。因此，识别虚假评论是一个紧迫且持续的研究领域。本研究论文提出了一种机器学习模型方法来识别虚假评论。论文调查了在一个餐馆评论的虚假意见垃圾语料库数据集上进行的多次实验的性能。我们采用了n-gram模型和最大特征来识别虚假评论。

    In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
    
[^7]: SPRINT: 一种用于评估和解析零样本神经稀疏检索的统一工具包

    SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval. (arXiv:2307.10488v1 [cs.IR])

    [http://arxiv.org/abs/2307.10488](http://arxiv.org/abs/2307.10488)

    SPRINT是一个统一的Python工具包，基于Pyserini和Lucene，支持评估和解析零样本神经稀疏检索。它解决了缺乏统一环境和实现在未见过领域上的检索能力的问题。

    

    传统上，稀疏检索系统依赖于词汇表示来检索文档，如BM25，在信息检索任务中占主导地位。随着诸如BERT这样的预训练transformer模型的出现，神经稀疏检索引领了检索中的新范式。尽管取得了成功，但目前缺乏支持不同稀疏检索器在统一的环境中运行的软件。这妨碍了实践者公正地比较不同的稀疏模型，并获得真实的评估结果。还有一个缺失的部分是，大多数先前的工作是对稀疏检索模型进行域内检索评估，即仅在一个数据集上进行评估：MS MARCO。然而，在实际检索系统中，一个重要的要求是模型能够在未见过的域外，即零样本检索任务中具有良好的泛化能力。在这项工作中，我们提供了SPRINT，这是一个基于Pyserini和Lucene的统一Python工具包，支持神经稀疏检索的通用接口。

    Traditionally, sparse retrieval systems relied on lexical representations to retrieve documents, such as BM25, dominated information retrieval tasks. With the onset of pre-trained transformer models such as BERT, neural sparse retrieval has led to a new paradigm within retrieval. Despite the success, there has been limited software supporting different sparse retrievers running in a unified, common environment. This hinders practitioners from fairly comparing different sparse models and obtaining realistic evaluation results. Another missing piece is, that a majority of prior work evaluates sparse retrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO. However, a key requirement in practical retrieval systems requires models that can generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In this work, we provide SPRINT, a unified Python toolkit based on Pyserini and Lucene, supporting a common interface for evaluating neural sparse retrieval. The 
    
[^8]: 使用连续细化的动态探索图进行快速近似最近邻搜索

    Fast Approximate Nearest Neighbor Search with a Dynamic Exploration Graph using Continuous Refinement. (arXiv:2307.10479v1 [cs.IR])

    [http://arxiv.org/abs/2307.10479](http://arxiv.org/abs/2307.10479)

    本论文提出了一种名为动态探索图（DEG）的算法，通过结合连续细化和图构建过程，达到了在近似最近邻搜索中提高搜索效率、预测索引大小、保持连通性和动态图结构的目的。

    

    对于近似最近邻搜索，基于图的算法在精度和搜索时间之间提供了最佳的折衷方案。我们提出了动态探索图（DEG），通过结合两个新思想，在搜索和探索效率方面显著优于现有算法：首先，通过部分替换现有边来增量构建一个单个的无向偶正则图，以同时整合新顶点和更新旧邻域。其次，使用边优化算法连续改善图的质量。将这种持续细化与图构建过程相结合，始终保持良好组织的图结构，从而实现：（1）提高搜索效率，（2）预测索引大小，（3）保证所有顶点的连通性和可达性，以及（4）动态图结构。此外，我们还研究了现有基于图的搜索系统在处理索引查询方面的能力。

    For approximate nearest neighbor search, graph-based algorithms have shown to offer the best trade-off between accuracy and search time. We propose the Dynamic Exploration Graph (DEG) which significantly outperforms existing algorithms in terms of search and exploration efficiency by combining two new ideas: First, a single undirected even regular graph is incrementally built by partially replacing existing edges to integrate new vertices and to update old neighborhoods at the same time. Secondly, an edge optimization algorithm is used to continuously improve the quality of the graph. Combining this ongoing refinement with the graph construction process leads to a well-organized graph structure at all times, resulting in: (1) increased search efficiency, (2) predictable index size, (3) guaranteed connectivity and therefore reachability of all vertices, and (4) a dynamic graph structure. In addition we investigate how well existing graph-based search systems can handle indexed queries w
    
[^9]: 专利中可视化类型和视角的分类

    Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])

    [http://arxiv.org/abs/2307.10471](http://arxiv.org/abs/2307.10471)

    本文主要研究了专利图像中可视化类型和视角的分类问题，扩展了CLEF-IP数据集并采用最先进的深度学习方法进行了分类。这项研究对于促进专利探索和检索具有重要意义。

    

    鉴于每年专利申请数量的迅速增长，促进专利探索和检索的信息和多媒体检索方法至关重要。不同类型的可视化（例如，图形、技术图纸）和视角（例如，侧视、透视）被用来可视化专利创新的细节。对这些图像的分类可以实现更高效的搜索并进行进一步分析。到目前为止，用于图像类型分类的数据集缺少一些重要的专利可视化类型。此外，相关研究没有使用包括transformers在内的最新深度学习方法。在本文中，我们采用最先进的深度学习方法来分类专利图像中的可视化类型和视角。我们对专利中图像类型分类的CLEF-IP数据集进行了扩展，增加到了十个类别，并提供了手动标注的真实标签。此外，我们从一个数据集中推导出一组层级类别。

    Due to the swift growth of patent applications each year, information and multimedia retrieval approaches that facilitate patent exploration and retrieval are of utmost importance. Different types of visualizations (e.g., graphs, technical drawings) and perspectives (e.g., side view, perspective) are used to visualize details of innovations in patents. The classification of these images enables a more efficient search and allows for further analysis. So far, datasets for image type classification miss some important visualization types for patents. Furthermore, related work does not make use of recent deep learning approaches including transformers. In this paper, we adopt state-of-the-art deep learning methods for the classification of visualization types and perspectives in patent images. We extend the CLEF-IP dataset for image type classification in patents to ten classes and provide manual ground truth annotations. In addition, we derive a set of hierarchical classes from a dataset
    
[^10]: IncDSI：递增可更新的文档检索

    IncDSI: Incrementally Updatable Document Retrieval. (arXiv:2307.10323v1 [cs.IR])

    [http://arxiv.org/abs/2307.10323](http://arxiv.org/abs/2307.10323)

    IncDSI是一种递增可更新的文档检索方法，它通过最小改变网络参数的约束优化问题，实现实时添加文档而无需重新训练整个模型，具有与重新训练模型相竞争的速度，能够实时更新的文档检索系统的开发。

    

    不同iable搜索索引是最近提出的一种文档检索范例，它将文档语料库的信息编码在神经网络的参数中，并直接将查询映射到相应的文档。这些模型在许多基准测试中取得了最先进的性能。这些模型具有一个重要限制：在训练模型之后添加新文档并不容易。我们提出了IncDSI，一种实时添加文档的方法（每个文档约20-50毫秒），而无需对整个数据集（甚至部分数据集）重新训练模型。相反，我们将添加文档的过程形式化为一个在网络参数上进行最小改变的约束优化问题。虽然速度更快几个数量级，但我们的方法与在整个数据集上重新训练模型相竞争，并且可以实时更新的文档检索系统的开发。我们的IncDSI代码

    Differentiable Search Index is a recently proposed paradigm for document retrieval, that encodes information about a corpus of documents within the parameters of a neural network and directly maps queries to corresponding documents. These models have achieved state-of-the-art performances for document retrieval across many benchmarks. These kinds of models have a significant limitation: it is not easy to add new documents after a model is trained. We propose IncDSI, a method to add documents in real time (about 20-50ms per document), without retraining the model on the entire dataset (or even parts thereof). Instead we formulate the addition of documents as a constrained optimization problem that makes minimal changes to the network parameters. Although orders of magnitude faster, our approach is competitive with re-training the model on the whole dataset and enables the development of document retrieval systems that can be updated with new information in real-time. Our code for IncDSI
    
[^11]: 基于歌词的孟加拉歌曲情绪分类

    Mood Classification of Bangla Songs Based on Lyrics. (arXiv:2307.10314v1 [cs.IR])

    [http://arxiv.org/abs/2307.10314](http://arxiv.org/abs/2307.10314)

    本研究通过分析孟加拉歌曲的歌词，成功实现了对这些歌曲的情绪进行多类分类，包括快乐、悲伤、浪漫和放松，为使音乐更贴近人们的情感做出了重要贡献。

    

    音乐能唤起各种情绪，随着技术的进步，人们对音乐的接触也越来越多。然而对于展现不同人类情感的孟加拉音乐，相关的研究尚不足够。本文的作者旨在通过分析孟加拉歌曲的歌词来分类其情绪。为实现这一目标，研究人员收集了4000首孟加拉歌曲的歌词和流派，并运用自然语言处理和BERT算法来分析数据。在这4000首歌曲中，1513首代表悲伤情绪，1362首代表浪漫情绪，886首代表快乐，其余的239首被归类为放松。通过嵌入歌词，作者将这些歌曲分为四种情绪：快乐、悲伤、浪漫和放松。该研究对于实现音乐的多类情绪分类至关重要，使音乐更能与人们的情感产生共鸣。该文章详细描述了通过歌词准确推导出的四种情绪的自动化结果。

    Music can evoke various emotions, and with the advancement of technology, it has become more accessible to people. Bangla music, which portrays different human emotions, lacks sufficient research. The authors of this article aim to analyze Bangla songs and classify their moods based on the lyrics. To achieve this, this research has compiled a dataset of 4000 Bangla song lyrics, genres, and used Natural Language Processing and the Bert Algorithm to analyze the data. Among the 4000 songs, 1513 songs are represented for the sad mood, 1362 for the romantic mood, 886 for happiness, and the rest 239 are classified as relaxation. By embedding the lyrics of the songs, the authors have classified the songs into four moods: Happy, Sad, Romantic, and Relaxed. This research is crucial as it enables a multi-class classification of songs' moods, making the music more relatable to people's emotions. The article presents the automated result of the four moods accurately derived from the song lyrics.
    
[^12]: 从叙事文本中自动获取行动模型

    Automated Action Model Acquisition from Narrative Texts. (arXiv:2307.10247v1 [cs.CL])

    [http://arxiv.org/abs/2307.10247](http://arxiv.org/abs/2307.10247)

    NaRuto是一个系统，可以从叙事文本中自动提取结构化事件，并生成高质量的行动模型，优于现有的完全自动化方法和与半自动化方法相媲美。

    

    行动模型以前提/效果公理的形式存在，为人工智能代理提供行动之间的因果关联和动机连接。行动模型获取被认为是计划技术应用中的瓶颈，特别是在叙事计划中。从叙事文本中以自动化的方式获取行动模型是必要的，但由于这样的文本本质上复杂，因此具有挑战性。我们提出了NaRuto，一个系统，它可以从叙事文本中提取结构化事件，并基于常识事件关系的预测以及文本上的矛盾和相似性无监督地生成计划语言风格的行动模型。经典的叙事计划领域的实验结果显示，NaRuto可以生成质量显著优于现有完全自动化方法的行动模型，甚至与半自动化方法的行动模型相媲美。

    Action models, which take the form of precondition/effect axioms, facilitate causal and motivational connections between actions for AI agents. Action model acquisition has been identified as a bottleneck in the application of planning technology, especially within narrative planning. Acquiring action models from narrative texts in an automated way is essential, but challenging because of the inherent complexities of such texts. We present NaRuto, a system that extracts structured events from narrative text and subsequently generates planning-language-style action models based on predictions of commonsense event relations, as well as textual contradictions and similarities, in an unsupervised manner. Experimental results in classical narrative planning domains show that NaRuto can generate action models of significantly better quality than existing fully automated methods, and even on par with those of semi-automated methods.
    
[^13]: 对深度推荐系统抗硬件错误能力的评估和增强

    Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors. (arXiv:2307.10244v1 [cs.IR])

    [http://arxiv.org/abs/2307.10244](http://arxiv.org/abs/2307.10244)

    本研究对深度推荐系统在面对硬件错误时的健壮性进行了系统研究，开发了一个错误注入框架Terrorch，发现激活剪裁是一种有希望的错误缓解方法，可以恢复高达30%的被降低的AUC-ROC得分。

    

    深度推荐系统（DRS）严重依赖于专用的高性能计算硬件和加速器，以优化能源、效率和推荐质量。尽管目前在部署DRS的大规模系统中观察到硬件错误的增加，但DRS的健壮性一直未受到重视。本文首次系统地研究了DRS在面对硬件错误时的健壮性。我们开发了一个名为Terrorch的用户友好、高效灵活的错误注入框架，基于广泛使用的PyTorch。我们评估了广泛的模型和数据集，观察到DRS的健壮性受到多种因素的影响，包括模型参数和输入特征。我们还探索了3种错误缓解方法，包括基于算法的容错（ABFT）、激活剪裁和选择性位保护（SBP）。我们发现应用激活剪裁可以恢复被降低的AUC-ROC得分高达30%，这使其成为一种有希望的缓解方法。

    Deep recommendation systems (DRS) heavily depend on specialized HPC hardware and accelerators to optimize energy, efficiency, and recommendation quality. Despite the growing number of hardware errors observed in large-scale fleet systems where DRS are deployed, the robustness of DRS has been largely overlooked. This paper presents the first systematic study of DRS robustness against hardware errors. We develop Terrorch, a user-friendly, efficient and flexible error injection framework on top of the widely-used PyTorch. We evaluate a wide range of models and datasets and observe that the DRS robustness against hardware errors is influenced by various factors from model parameters to input characteristics. We also explore 3 error mitigation methods including algorithm based fault tolerance (ABFT), activation clipping and selective bit protection (SBP). We find that applying activation clipping can recover up to 30% of the degraded AUC-ROC score, making it a promising mitigation method.
    
[^14]: 基于图增强的低资源文本分类的Prompt调优

    Prompt Tuning on Graph-augmented Low-resource Text Classification. (arXiv:2307.10230v1 [cs.IR])

    [http://arxiv.org/abs/2307.10230](http://arxiv.org/abs/2307.10230)

    本论文提出了一种基于图增强的低资源文本分类模型G2P2，通过预训练和提示的方式，利用图结构的语义关系来提升低资源文本分类的性能。

    

    文本分类是信息检索中的一个基础问题，有许多实际应用，例如预测在线文章的主题和电子商务产品描述的类别。然而，低资源文本分类，即没有或只有很少标注样本的情况，对监督学习构成了严重问题。与此同时，许多文本数据本质上都建立在网络结构上，例如在线文章的超链接/引用网络和电子商务产品的用户-物品购买网络。这些图结构捕捉了丰富的语义关系，有助于增强低资源文本分类。在本文中，我们提出了一种名为Graph-Grounded Pre-training and Prompting (G2P2)的新模型，以两方面方法解决低资源文本分类问题。在预训练阶段，我们提出了三种基于图交互的对比策略，共同预训练图文模型；在下游分类阶段，我们探索了手工设计的提示信息对模型的影响。

    Text classification is a fundamental problem in information retrieval with many real-world applications, such as predicting the topics of online articles and the categories of e-commerce product descriptions. However, low-resource text classification, with no or few labeled samples, presents a serious concern for supervised learning. Meanwhile, many text data are inherently grounded on a network structure, such as a hyperlink/citation network for online articles, and a user-item purchase network for e-commerce products. These graph structures capture rich semantic relationships, which can potentially augment low-resource text classification. In this paper, we propose a novel model called Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource text classification in a two-pronged approach. During pre-training, we propose three graph interaction-based contrastive strategies to jointly pre-train a graph-text model; during downstream classification, we explore handcrafted 
    
[^15]: 基于IPW的双边市场中的无偏排序度量

    An IPW-based Unbiased Ranking Metric in Two-sided Markets. (arXiv:2307.10204v1 [cs.IR])

    [http://arxiv.org/abs/2307.10204](http://arxiv.org/abs/2307.10204)

    这项研究提出了一种基于IPW的无偏排序度量方法，针对双边市场中用户之间的偏见相互作用，解决了位置偏见和两个用户群体的位置偏差问题。

    

    在现代推荐系统中，无偏学习排序（LTR）对于优先考虑来自有偏的隐式用户反馈（如点击数据）的项目是至关重要的。已经提出了一些技术，例如倒数倾向性加权（IPW），用于单边市场。然而，在双边市场（如工作平台或约会服务）中，成功转化需要匹配两个用户的偏好，但对于这种情况关注较少。本文解决了双边市场中用户之间的偏见相互作用，并提出了一种特定的LTR方法。我们首先提出了双边匹配平台中反馈机制的形式化，并指出它们的隐式反馈可能包含来自两个用户群体的位置偏差。基于这一观察，我们扩展了IPW估计器并提出了一种新的估计器，称为双边IPW，以解决双边市场中的位置偏见。我们证明了该估计器满足真实排名的无偏性。

    In modern recommendation systems, unbiased learning-to-rank (LTR) is crucial for prioritizing items from biased implicit user feedback, such as click data. Several techniques, such as Inverse Propensity Weighting (IPW), have been proposed for single-sided markets. However, less attention has been paid to two-sided markets, such as job platforms or dating services, where successful conversions require matching preferences from both users. This paper addresses the complex interaction of biases between users in two-sided markets and proposes a tailored LTR approach. We first present a formulation of feedback mechanisms in two-sided matching platforms and point out that their implicit feedback may include position bias from both user groups. On the basis of this observation, we extend the IPW estimator and propose a new estimator, named two-sided IPW, to address the position bases in two-sided markets. We prove that the proposed estimator satisfies the unbiasedness for the ground-truth ran
    
[^16]: 主观数据的主观人群分歧：通过群体级学习揭示有意义的群体意见

    Subjective Crowd Disagreements for Subjective Data: Uncovering Meaningful CrowdOpinion with Population-level Learning. (arXiv:2307.10189v1 [cs.IR])

    [http://arxiv.org/abs/2307.10189](http://arxiv.org/abs/2307.10189)

    本文介绍了一种名为CrowdOpinion的无监督学习方法，可以通过汇集标签分布中相似的项目，揭示在群体中存在的有意义的观点分歧，特别是在标注者人群中可能已经代表性不足的群体中。

    

    人类标注数据在AI系统的公平性中起着至关重要的作用，包括处理改变人们生活的决策或管理人类创建的网络/社交媒体内容的系统。传统上，在进行任何学习之前，会解决标注者之间的分歧。然而，研究人员越来越多地认识到标注者之间的分歧是普遍存在且有意义的。他们还质疑系统在标注者分歧时的性能。尤其是在忽视少数观点时，尤其是在标注者人群中可能已经代表性不足的群体中。在本文中，我们介绍了一种基于无监督学习的方法\emph{CrowdOpinion}，它使用语言特征和标签分布将相似的项目汇集成较大的标签分布样本。我们尝试了四种生成方法和一种基于密度的聚类方法，应用于五个标签分布和特征的线性组合。我们使用五个p

    Human-annotated data plays a critical role in the fairness of AI systems, including those that deal with life-altering decisions or moderating human-created web/social media content. Conventionally, annotator disagreements are resolved before any learning takes place. However, researchers are increasingly identifying annotator disagreement as pervasive and meaningful. They also question the performance of a system when annotators disagree. Particularly when minority views are disregarded, especially among groups that may already be underrepresented in the annotator population. In this paper, we introduce \emph{CrowdOpinion}\footnote{Accepted for publication at ACL 2023}, an unsupervised learning based approach that uses language features and label distributions to pool similar items into larger samples of label distributions. We experiment with four generative and one density-based clustering method, applied to five linear combinations of label distributions and features. We use five p
    
[^17]: 提升电子商务搜索中的文本匹配能力：基于可理解、可干预和快速实体关联模型

    Improving Text Matching in E-Commerce Search with A Rationalizable, Intervenable and Fast Entity-Based Relevance Model. (arXiv:2307.00370v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2307.00370](http://arxiv.org/abs/2307.00370)

    本研究提出了一种称为基于实体的关联模型（EBRM）的新模型，将查询-商品关联问题分解为多个查询-实体关联问题，并使用软逻辑聚合结果，以提高准确性和推理速度。

    

    在电子商务搜索系统中，从大量商品中发现用户查询的目标商品是主要目标之一。关联预测对于搜索系统至关重要，因为它有助于提高性能。目前，广泛使用的模型如Bi-encoder和Cross-encoder分别在准确性或推理速度上存在局限性。在这项工作中，我们提出了一种新的模型，称为基于实体的关联模型（EBRM）。我们识别商品中包含的实体，并将QI（查询-商品）关联问题分解为多个QE（查询-实体）关联问题；然后使用软逻辑形式聚合其结果以形成QI的预测。分解允许我们使用Cross-encoder QE关联模块以获得高准确性，并为快速在线推理缓存QE预测。利用软逻辑使预测过程可解释性高并具有干预能力。

    Discovering the intended items of user queries from a massive repository of items is one of the main goals of an e-commerce search system. Relevance prediction is essential to the search system since it helps improve performance. When online serving a relevance model, the model is required to perform fast and accurate inference. Currently, the widely used models such as Bi-encoder and Cross-encoder have their limitations in accuracy or inference speed respectively. In this work, we propose a novel model called the Entity-Based Relevance Model (EBRM). We identify the entities contained in an item and decompose the QI (query-item) relevance problem into multiple QE (query-entity) relevance problems; we then aggregate their results to form the QI prediction using a soft logic formulation. The decomposition allows us to use a Cross-encoder QE relevance module for high accuracy as well as cache QE predictions for fast online inference. Utilizing soft logic makes the prediction procedure int
    
[^18]: ChatGPT化学助手用于文本挖掘和MOF合成预测

    ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis. (arXiv:2306.11296v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2306.11296](http://arxiv.org/abs/2306.11296)

    该论文使用提示工程的方法指导ChatGPT对科学文献进行自动化文本挖掘，以获得金属-有机框架（MOF）合成条件。通过该系统，可以高精确地提取大量合成参数，为MOF合成提供支持。

    

    我们使用提示工程来指导ChatGPT自动化地从科学文献中挖掘多样的金属-有机框架（MOF）合成条件。这有效地减少了ChatGPT在科学领域中使用大型语言模型（LLMs）时出现信息产生误差的问题。我们的方法包括通过ChatGPT本身编程来开发实施文本挖掘的三个不同过程。所有这些过程都可以解析、搜索、过滤、分类、摘要和数据统一，但在劳动力、速度和准确性之间有不同的权衡。我们部署了该系统，从同行评审的研究文章中提取了26257个不同的合成参数，涉及大约800个MOF。这个过程包含了我们的ChemPrompt工程策略，以指导ChatGPT进行文本挖掘，结果显示出了90-99%的令人印象深刻的精确度、召回率和F1得分。

    We use prompt engineering to guide ChatGPT in the automation of text mining of metal-organic frameworks (MOFs) synthesis conditions from diverse formats and styles of the scientific literature. This effectively mitigates ChatGPT's tendency to hallucinate information -- an issue that previously made the use of Large Language Models (LLMs) in scientific fields challenging. Our approach involves the development of a workflow implementing three different processes for text mining, programmed by ChatGPT itself. All of them enable parsing, searching, filtering, classification, summarization, and data unification with different tradeoffs between labor, speed, and accuracy. We deploy this system to extract 26,257 distinct synthesis parameters pertaining to approximately 800 MOFs sourced from peer-reviewed research articles. This process incorporates our ChemPrompt Engineering strategy to instruct ChatGPT in text mining, resulting in impressive precision, recall, and F1 scores of 90-99%. Furthe
    
[^19]: 为有效和高效的零样本密集检索注入领域适应的学习哈希

    Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.11498](http://arxiv.org/abs/2205.11498)

    通过学习哈希技术提高零样本密集检索的准确性和效率，克服了存储密集索引的高内存使用问题，并在跨领域环境中进行了评估。

    

    密集检索在无查询词检索中克服了词汇隔阂，并在自动信息检索中取得了巨大成功。尽管成功，但密集检索器在实际应用中的服务成本较高。对于需要从数百万份文档中搜索的用例，密集索引变得庞大，并且在存储索引时需要高内存使用量。最近的学习哈希（LTH）技术，如BPR和JPQ，生成二进制文档向量，从而降低了存储密集索引的内存需求。LTH技术是有监督的，并使用排名损失对检索器进行微调。它们优于传统的向量压缩技术，如PCA或PQ。之前的研究中缺少的一个环节是现有技术仅在领域内进行评估，即仅在单一数据集（如MS MARCO）上进行评估。在我们的工作中，我们评估了LTH和向量压缩技术，以提高TAS-B d的零样本检索准确性。

    Dense retrieval overcome the lexical gap and has shown great success in ad-hoc information retrieval (IR). Despite their success, dense retrievers are expensive to serve across practical use cases. For use cases requiring to search from millions of documents, the dense index becomes bulky and requires high memory usage for storing the index. More recently, learning-to-hash (LTH) techniques, for e.g., BPR and JPQ, produce binary document vectors, thereby reducing the memory requirement to efficiently store the dense index. LTH techniques are supervised and finetune the retriever using a ranking loss. They outperform their counterparts, i.e., traditional out-of-the-box vector compression techniques such as PCA or PQ. A missing piece from prior work is that existing techniques have been evaluated only in-domain, i.e., on a single dataset such as MS MARCO. In our work, we evaluate LTH and vector compression techniques for improving the downstream zero-shot retrieval accuracy of the TAS-B d
    
[^20]: 推荐系统的深度探索

    Deep Exploration for Recommendation Systems. (arXiv:2109.12509v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2109.12509](http://arxiv.org/abs/2109.12509)

    本文提出了一种深度探索方法以解决推荐系统中奖励稀少时的问题，并在高保真度的工业级模拟器下进行了实验，证明了该算法相比现有算法有很大的提升。

    

    现代推荐系统应从延迟反馈中探索和学习。过去的研究往往侧重于从用户对单个推荐的响应中学习。这些工作利用了监督学习和强化学习的方法，但放弃了学习用户之后的行为。在过去的工作中，虽然致力于从随后的行为中学习，但缺乏有效的方法来引导并获取有意义的延迟反馈。当奖励较少时，通过引导探索有意义的延迟反馈变得特别具有挑战性。为了解决这个问题，我们为推荐系统开发了深度探索方法。具体而言，我们将推荐系统形式化为一个序列决策问题，并证明了深度探索方法在单步探索方面的优势。我们的实验是在高保真度的工业级模拟器下进行的，并且证明了该算法相比现有算法有很大的提升。

    Modern recommendation systems ought to benefit by probing for and learning from delayed feedback. Research has tended to focus on learning from a user's response to a single recommendation. Such work, which leverages methods of supervised and bandit learning, forgoes learning from the user's subsequent behavior. Where past work has aimed to learn from subsequent behavior, there has been a lack of effective methods for probing to elicit informative delayed feedback. Effective exploration through probing for delayed feedback becomes particularly challenging when rewards are sparse. To address this, we develop deep exploration methods for recommendation systems. In particular, we formulate recommendation as a sequential decision problem and demonstrate benefits of deep exploration over single-step exploration. Our experiments are carried out with high-fidelity industrial-grade simulators and establish large improvements over existing algorithms.
    
[^21]: 基于准则的多行为隐式推荐的异构协同过滤

    Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior Implicit Recommendation. (arXiv:2105.11876v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2105.11876](http://arxiv.org/abs/2105.11876)

    提出了一种基于准则的非采样学习框架，命名为CHCF，用于多行为隐式推荐的异构协同过滤。该方法通过引入上限和下限阈值来指示选择标准，并指导用户偏好学习。

    

    近年来，多媒体信息系统中的互动行为呈爆炸式增长，利用来自各种辅助行为（如提示和收藏）的数据，多行为推荐系统受到越来越多的关注。在各种多行为推荐方法中，非采样方法表现优于负采样方法。然而，现有的基于二进制回归的非采样方法通常忽略了两点观察：（1）用户对不同项目具有不同的偏好强度，因此不能简单通过二进制隐式数据来衡量；（2）多个行为之间的依赖关系对不同的用户和项目是不同的。为了解决上述问题，我们提出了一种新的非采样学习框架，命名为基于准则的异构协同过滤（CHCF）。CHCF引入了上限和下限阈值来指示选择标准，并指导用户偏好学习。

    Recent years have witnessed the explosive growth of interaction behaviors in multimedia information systems, where multi-behavior recommender systems have received increasing attention by leveraging data from various auxiliary behaviors such as tip and collect. Among various multi-behavior recommendation methods, non-sampling methods have shown superiority over negative sampling methods. However, two observations are usually ignored in existing state-of-the-art non-sampling methods based on binary regression: (1) users have different preference strengths for different items, so they cannot be measured simply by binary implicit data; (2) the dependency across multiple behaviors varies for different users and items. To tackle the above issue, we propose a novel non-sampling learning framework named Criterion-guided Heterogeneous Collaborative Filtering (CHCF). CHCF introduces both upper and lower thresholds to indicate selection criteria, which will guide user preference learning. Beside
    
[^22]: ABNIRML: 分析神经信息检索模型的行为

    ABNIRML: Analyzing the Behavior of Neural IR Models. (arXiv:2011.00696v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2011.00696](http://arxiv.org/abs/2011.00696)

    ABNIRML提供了一个全面的框架，分析了神经信息检索模型的行为，包括写作风格、事实性、对改写和词序的敏感性等特征。通过进行广泛的实证研究，我们探究了神经模型增益的因素，并发现了潜在的偏见。

    

    预训练上下文化语言模型（如BERT和T5）已经建立了信息检索领域的新的最先进技术。然而，我们还不完全理解为什么这些方法如此有效，是什么使一些变种比其他变种更有效，以及它们可能存在哪些问题。我们提出了一个全面的框架来分析神经信息检索模型行为（ABNIRML），包括新的诊断探针类型，允许我们测试先前技术未解决的几个特征，例如写作风格，事实性，对改写和词序的敏感性等。为了展示这个框架的价值，我们进行了广泛的实证研究，得出了对神经模型增益因素的见解，并确定了模型可能存在的潜在偏见。我们的一些结果证实了传统的观点，例如最近的神经排序模型对查询的确切术语匹配的依赖程度较低，而是利用更丰富的语言特征。

    Pretrained contextualized language models such as BERT and T5 have established a new state-of-the-art for ad-hoc search. However, it is not yet well-understood why these methods are so effective, what makes some variants more effective than others, and what pitfalls they may have. We present a new comprehensive framework for Analyzing the Behavior of Neural IR ModeLs (ABNIRML), which includes new types of diagnostic probes that allow us to test several characteristics -- such as writing styles, factuality, sensitivity to paraphrasing and word order -- that are not addressed by previous techniques. To demonstrate the value of the framework, we conduct an extensive empirical study that yields insights into the factors that contribute to the neural model's gains, and identify potential unintended biases the models exhibit. Some of our results confirm conventional wisdom, like that recent neural ranking models rely less on exact term overlap with the query, and instead leverage richer ling
    

