# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives.](http://arxiv.org/abs/2304.00413) | 存档查询日志是互联网档案馆在过去25年中收集的全面查询日志，包含较大规模、广泛范围和多样性，其提供了支持新的检索模型和搜索引擎分析的机会。 |
| [^2] | [Reviewer Assignment Problem: A Systematic Review of the Literature.](http://arxiv.org/abs/2304.00353) | 本文综述了自1992年以来，103篇关于评审人自动分配的研究成果，并介绍了该领域的研究热点和未来发展方向。 |
| [^3] | [On the Feasibility and Robustness of Pointwise Evaluation of Query Performance Prediction.](http://arxiv.org/abs/2304.00310) | 提出了一种点对点的QPP框架，通过测量每个预测与相应真实值之间的偏差来评估QPP系统的单个查询质量，得到的方法能够在各种目标指标和检索模型上导致更小的QPP评估方差。 |
| [^4] | [Bipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space.](http://arxiv.org/abs/2304.00241) | 本文提出了一种称为BGCH的端到端双分图图卷积哈希方法，在汉明空间中实现了有效的Top-N搜索，并具有三个新颖而有效的模块：自适应图卷积哈希，潜在特征分散和傅里叶序列化梯度估计。 |
| [^5] | [Enhancing Large Language Models with Climate Resources.](http://arxiv.org/abs/2304.00116) | 本研究利用最新的想法，将大型语言模型视为可以访问包含关于组织、机构和公司的最新和准确信息的代理，结合气候变化数据库和常规 Google 搜索，以提供更可靠和准确的信息。 |
| [^6] | [Dense Sparse Retrieval: Using Sparse Language Models for Inference Efficient Dense Retrieval.](http://arxiv.org/abs/2304.00114) | 本文研究了如何使用稀疏语言模型实现高效稠密检索，使用Tevatron 和MSMARCO、NQ和TriviaQA数据集，发现稀疏语言模型可以直接替换为原有模型，几乎不降低准确性，并且推理速度提高了最多4.3倍。 |
| [^7] | [Bi-directional personalization reinforcement learning-based architecture with active learning using a multi-model data service for the travel nursing industry.](http://arxiv.org/abs/2304.00006) | 本文提出了一个面向旅行护理行业的招聘方案，采用多模型数据服务加速数据采集，并使用双向强化学习和主动学习提供个性化推荐，解决了这一行业标注数据短缺的问题。 |
| [^8] | [Learning Job Titles Similarity from Noisy Skill Labels.](http://arxiv.org/abs/2207.00494) | 本文介绍了一种使用含噪技能标签的无监督表示学习方法，能够训练出有效的职称相似性模型，对于文本排序和职位标准化等任务非常有效。 |
| [^9] | [Questions Are All You Need to Train a Dense Passage Retriever.](http://arxiv.org/abs/2206.10658) | ART是一种能够不使用标记数据进行训练的密集检索模型，并且只需要访问未配对的输入和输出。它使用一个新的文档检索自编码方案，通过问题重构进行检索训练，可以有效地进行无监督学习，并且可以将其合并到完整的Open QA系统中。 |
| [^10] | [Subscriptions and external links help drive resentful users to alternative and extremist YouTube videos.](http://arxiv.org/abs/2204.10921) | 频繁订阅和关注外链是导致具有反感情绪的用户观看YouTube上的极端视频的主要因素。 |
| [^11] | [Improving Passage Retrieval with Zero-Shot Question Generation.](http://arxiv.org/abs/2204.07496) | 本论文提出了一种基于零样本问题生成模型的重新排序方法，适用于开放式问题回答中的段落检索，可以适用于任何检索方法，无需特定训练，可在多个数据集中提高检索准确性，可以帮助提高开放域问答的性能。 |

# 详细

[^1]: 存档查询日志：25年网络档案中数百个搜索引擎的数百万搜索结果页面的挖掘

    The Archive Query Log: Mining Millions of Search Result Pages of Hundreds of Search Engines from 25 Years of Web Archives. (arXiv:2304.00413v1 [cs.IR])

    [http://arxiv.org/abs/2304.00413](http://arxiv.org/abs/2304.00413)

    存档查询日志是互联网档案馆在过去25年中收集的全面查询日志，包含较大规模、广泛范围和多样性，其提供了支持新的检索模型和搜索引擎分析的机会。

    

    存档查询日志（AQL）是互联网档案馆在过去25年收集的以前未使用的全面查询日志。其第一个版本包括3.56亿次查询、1.66亿个搜索结果页面和550个搜索提供商的17亿个搜索结果。虽然文献中有许多查询日志的研究，但拥有这些日志的搜索提供商通常不会公开发布以保护用户隐私和重要业务数据。在少数公开可用的查询日志中，没有一种结合了规模、范围和多样性。AQL是第一个这样做的，为新的检索模型和（历时的）搜索引擎分析提供支持。以保护隐私的方式提供，它促进了开放研究，并增加了搜索行业的透明度和问责制。

    The Archive Query Log (AQL) is a previously unused, comprehensive query log collected at the Internet Archive over the last 25 years. Its first version includes 356 million queries, 166 million search result pages, and 1.7 billion search results across 550 search providers. Although many query logs have been studied in the literature, the search providers that own them generally do not publish their logs to protect user privacy and vital business data. Of the few query logs publicly available, none combines size, scope, and diversity. The AQL is the first to do so, enabling research on new retrieval models and (diachronic) search engine analyses. Provided in a privacy-preserving manner, it promotes open research as well as more transparency and accountability in the search industry.
    
[^2]: 评审人分配问题：文献综述

    Reviewer Assignment Problem: A Systematic Review of the Literature. (arXiv:2304.00353v1 [cs.DL])

    [http://arxiv.org/abs/2304.00353](http://arxiv.org/abs/2304.00353)

    本文综述了自1992年以来，103篇关于评审人自动分配的研究成果，并介绍了该领域的研究热点和未来发展方向。

    

    适当的评审人分配显著影响评估的质量，因为准确和公正的审查取决于将其分配给相关的评审人。将评审人分配给提交的提案是审查过程的起点，也称为评审人分配问题（RAP）。由于手动分配的明显限制，期刊编辑、会议组织者和拨款经理要求自动评审人分配方法。自1992年以来，许多研究提出了分配解决方案以响应自动化程序的需求。本次调查报告的主要目标是为学者和实践者提供关于RAP领域中可用研究的全面概述。为实现这一目标，本文对过去三十年内发表在Web of Science、Scopus、ScienceDirect和Google Scholar等数据库中的103篇评审人分配领域的出版物进行了深入的系统综述。

    Appropriate reviewer assignment significantly impacts the quality of proposal evaluation, as accurate and fair reviews are contingent on their assignment to relevant reviewers. The crucial task of assigning reviewers to submitted proposals is the starting point of the review process and is also known as the reviewer assignment problem (RAP). Due to the obvious restrictions of manual assignment, journal editors, conference organizers, and grant managers demand automatic reviewer assignment approaches. Many studies have proposed assignment solutions in response to the demand for automated procedures since 1992. The primary objective of this survey paper is to provide scholars and practitioners with a comprehensive overview of available research on the RAP. To achieve this goal, this article presents an in-depth systematic review of 103 publications in the field of reviewer assignment published in the past three decades and available in the Web of Science, Scopus, ScienceDirect, Google Sc
    
[^3]: 论点级别评价系统的可行性和鲁棒性

    On the Feasibility and Robustness of Pointwise Evaluation of Query Performance Prediction. (arXiv:2304.00310v1 [cs.IR])

    [http://arxiv.org/abs/2304.00310](http://arxiv.org/abs/2304.00310)

    提出了一种点对点的QPP框架，通过测量每个预测与相应真实值之间的偏差来评估QPP系统的单个查询质量，得到的方法能够在各种目标指标和检索模型上导致更小的QPP评估方差。

    

    虽然查询的检索有效性彼此独立，但是查询性能预测(QPP)系统的评估一直是通过测量整个查询集合上的等级相关性来完成的。这种列表方法有许多缺点，尤其是它不支持评估单个查询的QPP的常见要求。在本文中，我们提出了一个点对点的QPP框架，通过测量每个预测与相应真实值之间的偏差，然后在一组查询上聚合结果，可以评估QPP系统对各个查询的质量。我们的实验表明，这种新方法在各种目标指标和检索模型上均导致QPP评估方差更小。

    Despite the retrieval effectiveness of queries being mutually independent of one another, the evaluation of query performance prediction (QPP) systems has been carried out by measuring rank correlation over an entire set of queries. Such a listwise approach has a number of disadvantages, notably that it does not support the common requirement of assessing QPP for individual queries. In this paper, we propose a pointwise QPP framework that allows us to evaluate the quality of a QPP system for individual queries by measuring the deviations between each prediction versus the corresponding true value, and then aggregating the results over a set of queries. Our experiments demonstrate that this new approach leads to smaller variances in QPP evaluations across a range of different target metrics and retrieval models.
    
[^4]: 双分图图卷积哈希在汉明空间中有效、高效地进行Top-N搜索

    Bipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space. (arXiv:2304.00241v1 [cs.IR])

    [http://arxiv.org/abs/2304.00241](http://arxiv.org/abs/2304.00241)

    本文提出了一种称为BGCH的端到端双分图图卷积哈希方法，在汉明空间中实现了有效的Top-N搜索，并具有三个新颖而有效的模块：自适应图卷积哈希，潜在特征分散和傅里叶序列化梯度估计。

    

    在许多实际的网络应用中，例如在线推荐、数据库检索和查询文档搜索，双分图图搜索是基础且多用途的。传统方法依赖于连续欧几里得空间中矢量化节点嵌入的相似性匹配。为了有效地处理大规模的相似度计算，最近发展了一些图结构数据的哈希技术。尽管在汉明空间中的检索效率很高，但先前的工作仍面临灾难性的性能衰减。在本文中，我们研究了使用双分图图卷积网络进行哈希的问题，以实现有效的Top-N搜索。我们提出了一种端到端的双分图图卷积哈希方法（BGCH），它由三个新颖而有效的模块组成：（1）自适应图卷积哈希，（2）潜在特征分散，以及（3）傅里叶序列化梯度估计。

    Searching on bipartite graphs is basal and versatile to many real-world Web applications, e.g., online recommendation, database retrieval, and query-document searching. Given a query node, the conventional approaches rely on the similarity matching with the vectorized node embeddings in the continuous Euclidean space. To efficiently manage intensive similarity computation, developing hashing techniques for graph structured data has recently become an emerging research direction. Despite the retrieval efficiency in Hamming space, prior work is however confronted with catastrophic performance decay. In this work, we investigate the problem of hashing with Graph Convolutional Network on bipartite graphs for effective Top-N search. We propose an end-to-end Bipartite Graph Convolutional Hashing approach, namely BGCH, which consists of three novel and effective modules: (1) adaptive graph convolutional hashing, (2) latent feature dispersion, and (3) Fourier serialized gradient estimation. Sp
    
[^5]: 利用气候资源增强大型语言模型

    Enhancing Large Language Models with Climate Resources. (arXiv:2304.00116v1 [cs.CL])

    [http://arxiv.org/abs/2304.00116](http://arxiv.org/abs/2304.00116)

    本研究利用最新的想法，将大型语言模型视为可以访问包含关于组织、机构和公司的最新和准确信息的代理，结合气候变化数据库和常规 Google 搜索，以提供更可靠和准确的信息。

    

    大型语言模型 (LLM) 在生成各种主题的类人文本方面展示了其能力，显著地改变了人工智能的格局。然而，尽管它们具有令人印象深刻的能力，但 LLM 缺乏最近的信息，并且常常使用不够准确的语言，这在需要准确性的领域比如气候变化中可能会有害。在本研究中，我们利用最新的想法来利用 LLM 的潜力，将它们视为可以访问包含关于组织、机构和公司的最新和准确信息的数据库的代理。我们通过一个原型代理演示了我们的方法的有效性，该代理从 ClimateWatch (https://www.climatewatchdata.org/) 检索排放数据并利用常规 Google 搜索。通过将这些资源与 LLM 集成，我们的方法克服了与不精确语言相关的限制，在气候变化等领域提供了更可靠和准确的信息。

    Large language models (LLMs) have significantly transformed the landscape of artificial intelligence by demonstrating their ability in generating human-like text across diverse topics. However, despite their impressive capabilities, LLMs lack recent information and often employ imprecise language, which can be detrimental in domains where accuracy is crucial, such as climate change. In this study, we make use of recent ideas to harness the potential of LLMs by viewing them as agents that access multiple sources, including databases containing recent and precise information about organizations, institutions, and companies. We demonstrate the effectiveness of our method through a prototype agent that retrieves emission data from ClimateWatch (https://www.climatewatchdata.org/) and leverages general Google search. By integrating these resources with LLMs, our approach overcomes the limitations associated with imprecise language and delivers more reliable and accurate information in the cr
    
[^6]: 稠密稀疏检索：使用稀疏语言模型实现高效稠密检索

    Dense Sparse Retrieval: Using Sparse Language Models for Inference Efficient Dense Retrieval. (arXiv:2304.00114v1 [cs.IR])

    [http://arxiv.org/abs/2304.00114](http://arxiv.org/abs/2304.00114)

    本文研究了如何使用稀疏语言模型实现高效稠密检索，使用Tevatron 和MSMARCO、NQ和TriviaQA数据集，发现稀疏语言模型可以直接替换为原有模型，几乎不降低准确性，并且推理速度提高了最多4.3倍。

    

    基于向量的检索系统已成为学术和工业搜索应用的常见工具，因为它们提供了一种简单而可扩展的方式来利用文档和查询的上下文表示进行搜索。由于这些向量系统依赖于上下文语言模型，因此它们通常需要GPU的使用，这可能会很昂贵且难以管理。鉴于近年来引入稀疏性以提高推理效率的语言模型的最新进展，本文研究了如何使用稀疏语言模型进行稠密检索以提高推理效率。使用流行的检索库Tevatron和MSMARCO、NQ和TriviaQA数据集，我们发现稀疏语言模型可以直接替换为原有模型，几乎不降低准确性，并且推理速度提高了最多4.3倍。

    Vector-based retrieval systems have become a common staple for academic and industrial search applications because they provide a simple and scalable way of extending the search to leverage contextual representations for documents and queries. As these vector-based systems rely on contextual language models, their usage commonly requires GPUs, which can be expensive and difficult to manage. Given recent advances in introducing sparsity into language models for improved inference efficiency, in this paper, we study how sparse language models can be used for dense retrieval to improve inference efficiency. Using the popular retrieval library Tevatron and the MSMARCO, NQ, and TriviaQA datasets, we find that sparse language models can be used as direct replacements with little to no drop in accuracy and up to 4.3x improved inference speeds
    
[^7]: 面向旅行护理行业的使用多模型数据服务的双向个性化强化学习架构中的主动学习

    Bi-directional personalization reinforcement learning-based architecture with active learning using a multi-model data service for the travel nursing industry. (arXiv:2304.00006v1 [cs.IR])

    [http://arxiv.org/abs/2304.00006](http://arxiv.org/abs/2304.00006)

    本文提出了一个面向旅行护理行业的招聘方案，采用多模型数据服务加速数据采集，并使用双向强化学习和主动学习提供个性化推荐，解决了这一行业标注数据短缺的问题。

    

    本文讨论了机器学习技术如何通过使用多模型数据服务加速数据采集并使用双向强化学习和主动学习提供个性化推荐，从而增强旅行护理行业的招聘流程。该方案可帮助招聘人员推荐合格申请人，并使申请人接收到个性化工作推荐。本文还讨论了使用主动学习来解决这一行业标注数据短缺的问题。

    The challenges of using inadequate online recruitment systems can be addressed with machine learning and software engineering techniques. Bi-directional personalization reinforcement learning-based architecture with active learning can get recruiters to recommend qualified applicants and also enable applicants to receive personalized job recommendations. This paper focuses on how machine learning techniques can enhance the recruitment process in the travel nursing industry by helping speed up data acquisition using a multi-model data service and then providing personalized recommendations using bi-directional reinforcement learning with active learning. This need was especially evident when trying to respond to the overwhelming needs of healthcare facilities during the COVID-19 pandemic. The need for traveling nurses and other healthcare professionals was more evident during the lockdown period. A data service was architected for job feed processing using an orchestration of natural la
    
[^8]: 从含噪技能标签中学习职称相似度

    Learning Job Titles Similarity from Noisy Skill Labels. (arXiv:2207.00494v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.00494](http://arxiv.org/abs/2207.00494)

    本文介绍了一种使用含噪技能标签的无监督表示学习方法，能够训练出有效的职称相似性模型，对于文本排序和职位标准化等任务非常有效。

    

    测量职称之间的语义相似度是自动职位推荐的重要功能。这个任务通常使用监督学习技术来实现，需要以等效职称对的形式进行训练数据。本文提出了一种无监督表示学习方法，使用含噪技能标签训练职称相似性模型。我们证明，这种方法在文本排序和职位标准化等任务中非常有效。

    Measuring semantic similarity between job titles is an essential functionality for automatic job recommendations. This task is usually approached using supervised learning techniques, which requires training data in the form of equivalent job title pairs. In this paper, we instead propose an unsupervised representation learning method for training a job title similarity model using noisy skill labels. We show that it is highly effective for tasks such as text ranking and job normalization.
    
[^9]: 答案有解：无需标记数据来训练密集检索模型

    Questions Are All You Need to Train a Dense Passage Retriever. (arXiv:2206.10658v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.10658](http://arxiv.org/abs/2206.10658)

    ART是一种能够不使用标记数据进行训练的密集检索模型，并且只需要访问未配对的输入和输出。它使用一个新的文档检索自编码方案，通过问题重构进行检索训练，可以有效地进行无监督学习，并且可以将其合并到完整的Open QA系统中。

    

    我们引入了ART，一种新的语料库级自编码方法，用于训练密集检索模型，不需要任何标记的训练数据。在开放域任务中，如开放式问答（Open QA）中，密集检索是一个中心挑战，其中最先进的方法通常需要大量的监督数据集，具有自定义的硬负面挖掘和正面示例去噪声。与此相反，ART只需要访问未配对的输入和输出（例如，问题和潜在答案文件）。它使用一种新的文档检索自编码方案，其中（1）输入问题用于检索一组证据文档，（2）然后使用文档计算重构原始问题的概率。基于问题重构的检索训练可以有效地进行无监督学习，包括文档和问题编码器，可以稍后将其合并到完整的Open QA系统中，而不需要进一步进行微调。广泛的实验表明，ART获得了良好的性能。

    We introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g. questions and potential answer documents). It uses a new document-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence documents, and (2) the documents are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both document and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtain
    
[^10]: 订阅和外部链接促使具有反感情绪的用户观看YouTube上的极端视频

    Subscriptions and external links help drive resentful users to alternative and extremist YouTube videos. (arXiv:2204.10921v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2204.10921](http://arxiv.org/abs/2204.10921)

    频繁订阅和关注外链是导致具有反感情绪的用户观看YouTube上的极端视频的主要因素。

    

    网络平台是否促进了有害内容的消费？本研究利用2020年代表性样本（n=1,181）的行为和调查数据，揭示了在YouTube上观看替代和极端渠道视频的人群主要集中在高先前性别和种族反感水平的少数人之间。这些观众经常订阅这些频道（促使向他们的视频推荐），并关注外部链接。相反，非订阅用户很少看到或关注这些频道的视频。这些发现表明，我们观察的2020年期间，YouTube算法没有把人们带入“兔子洞”，可能是由于该公司在2019年对其推荐系统进行的更改。然而，该平台在促进专注观众接触替代和极端渠道的内容方面继续发挥着关键作用。

    Do online platforms facilitate the consumption of potentially harmful content? Using paired behavioral and survey data provided by participants recruited from a representative sample in 2020 (n=1,181), we show that exposure to alternative and extremist channel videos on YouTube is heavily concentrated among a small group of people with high prior levels of gender and racial resentment. These viewers often subscribe to these channels (prompting recommendations to their videos) and follow external links to them. In contrast, non-subscribers rarely see or follow recommendations to videos from these channels. Our findings suggest YouTube's algorithms were not sending people down "rabbit holes" during our observation window in 2020, possibly due to changes that the company made to its recommender system in 2019. However, the platform continues to play a key role in facilitating exposure to content from alternative and extremist channels among dedicated audiences.
    
[^11]: 用零样本问题生成提高段落检索

    Improving Passage Retrieval with Zero-Shot Question Generation. (arXiv:2204.07496v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.07496](http://arxiv.org/abs/2204.07496)

    本论文提出了一种基于零样本问题生成模型的重新排序方法，适用于开放式问题回答中的段落检索，可以适用于任何检索方法，无需特定训练，可在多个数据集中提高检索准确性，可以帮助提高开放域问答的性能。

    

    我们提出了一种简单而有效的重新排序方法，以提高开放式问题回答中的段落检索。重新排序器使用零样本问题生成模型重新评分，该模型使用预训练的语言模型计算基于所检索到的段落的输入问题的概率。该方法可以应用于任何检索方法（如神经或基于关键字的检索），不需要任何域或任务特定的训练（因此，预计更好地推广到数据分布转移），并提供了查询和段落之间的丰富交叉注意（即必须解释问题中的每个令牌）。在多个开放域检索数据集的评估中，我们的重新排序器将强大的无监督检索模型中提高了6％-18％，并将强大的监督模型中的前20个段落检索的准确性提高高达12％。我们还通过简单地添加新的重新排序器来获得了新的开放域问答的最新结果。

    We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot question generation model, which uses a pre-trained language model to compute the probability of the input question conditioned on a retrieved passage. This approach can be applied on top of any retrieval method (e.g. neural or keyword-based), does not require any domain- or task-specific training (and therefore is expected to generalize better to data distribution shifts), and provides rich cross-attention between query and passage (i.e. it must explain every token in the question). When evaluated on a number of open-domain retrieval datasets, our re-ranker improves strong unsupervised retrieval models by 6%-18% absolute and strong supervised models by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new state-of-the-art results on full open-domain question answering by simply adding the new r
    

