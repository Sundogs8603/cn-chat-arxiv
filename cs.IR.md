# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Robust Long-Tailed Learning via Label-Aware Bounded CVaR.](http://arxiv.org/abs/2308.15405) | 本文提出了两种基于CVaR的方法来改进长尾学习的性能，并具备坚实的理论基础。第一种方法是引入了一种标签感知有界CVaR（LAB-CVaR）损失函数，解决了原始CVaR的悲观结果，通过设计最优权重上下界进行改进；第二种方法是提出了一种带有logit调整的LAB-CVaR（LAB-CVaR-logit）损失函数，以稳定优化过程。 |
| [^2] | [A Multi-Perspective Learning to Rank Approach to Support Children's Information Seeking in the Classroom.](http://arxiv.org/abs/2308.15265) | 这项研究提出了一种多角度学习排序方法，能够通过分析URL、片段和页面标题，优先考虑高教育一致性、适当性和可读性的Web资源，从而改进儿童信息搜索能力。 |
| [^3] | [Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation.](http://arxiv.org/abs/2308.15244) | 该论文提出了一种基于知识的多重自适应空间融合推荐方法，通过统一的空间来融合双曲、欧几里得和球面空间，并利用注意力机制提高了知识传播的嵌入质量。 |
| [^4] | [Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification.](http://arxiv.org/abs/2308.15232) | 本文提出了一种结合可解释性分析的分类感知神经主题模型，用于冲突分类和主题发现。该模型提供了可靠的分类结果和发现的主题的解释，并通过优化模型的复杂度来提高分类性能。 |
| [^5] | [Providing Previously Unseen Users Fair Recommendations Using Variational Autoencoders.](http://arxiv.org/abs/2308.15230) | 本论文提出了一种使用变分自动编码器的新方法，通过限制人口统计信息的编码来减少推荐系统中的歧视，从而为以前未出现的用户提供公平推荐。 |
| [^6] | [CAGRA: Highly Parallel Graph Construction and Approximate Nearest Neighbor Search for GPUs.](http://arxiv.org/abs/2308.15136) | CAGRA是一种面向GPU的高度并行图构建和近似最近邻搜索方法，在近似最近邻搜索领域取得了显著的效率提升。 |
| [^7] | [Killing two birds with one stone: Can an audio captioning system also be used for audio-text retrieval?.](http://arxiv.org/abs/2308.15090) | 这篇论文研究了音频字幕系统和音频文本检索系统之间的关系，通过探索未经修改的音频字幕系统对音频文本检索任务的性能。研究发现，即使未进行微调，音频字幕系统在音频文本检索任务上表现出了一定的能力。 |
| [^8] | [STEC: See-Through Transformer-based Encoder for CTR Prediction.](http://arxiv.org/abs/2308.15033) | STEC是一种基于透明Transformer编码器的CTR预测模型，通过引入多种交互学习方法和残差连接，提升了模型性能。 |
| [^9] | [Improving Neural Ranking Models with Traditional IR Methods.](http://arxiv.org/abs/2308.15027) | 本文研究了一种低成本的替代方法，通过将传统的TF-IDF和浅层嵌入模型结合使用，可以与基于大型Transformer模型的神经排名模型竞争，并可以提高这些模型在大规模任务上的性能。 |
| [^10] | [CAPS: A Practical Partition Index for Filtered Similarity Search.](http://arxiv.org/abs/2308.15014) | CAPS是一种通过空间分区实现的用于带有过滤的相似性搜索的索引，它在召回-延迟权衡方面优于基于图的约束搜索技术，并且只需要较小的索引大小。 |
| [^11] | [Continual Learning for Generative Retrieval over Dynamic Corpora.](http://arxiv.org/abs/2308.14968) | 这项研究解决了生成性检索在动态语料库中的持续学习问题，通过引入CLEVER模型，并提出了增量产品量化的方法来实现低计算成本的新文档编码。 |
| [^12] | [Vector Search with OpenAI Embeddings: Lucene Is All You Need.](http://arxiv.org/abs/2308.14963) | 本论文提供了一个使用Lucene进行向量搜索的可复现演示，挑战了需要专用向量存储的观点，并展示了Lucene中的HNSW索引足以提供向量搜索功能。这表明在现代"AI堆栈"中进行搜索并不需要引入专用向量存储。 |
| [^13] | [RecRec: Algorithmic Recourse for Recommender Systems.](http://arxiv.org/abs/2308.14916) | 本文提出了一个算法性补救框架，用于帮助理解推荐系统的模型并修改推荐结果。 |
| [^14] | [Ad-Rec: Advanced Feature Interactions to Address Covariate-Shifts in Recommendation Networks.](http://arxiv.org/abs/2308.14902) | Ad-Rec是一个利用高级特征交互技术解决推荐网络中协变量漂移问题的模型，通过利用掩码转换器实现高阶交叉特征的学习，提高了模型质量、加速了收敛速度并减少了训练时间。 |
| [^15] | [Extending Cross-Modal Retrieval with Interactive Learning to Improve Image Retrieval Performance in Forensics.](http://arxiv.org/abs/2308.14786) | 本研究通过提出名为Excalibur的零样本跨模态图像检索系统，探索了交互式学习在提高执法学中图像检索性能方面的有效性，并通过模拟和用户研究证明了其显著的改进效果。 |
| [^16] | [Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model.](http://arxiv.org/abs/2307.07740) | 本论文使用CNN-LSTM模型对波斯推特的政治情感进行分析，使用ParsBERT进行词汇表示，并比较了机器学习和深度学习模型的效果。实验结果表明，深度学习模型表现更好，其中CNN-LSTM模型在两个数据集上分别达到了89%和71%的分类准确率。 |
| [^17] | [Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models.](http://arxiv.org/abs/2306.08018) | Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。 |

# 详细

[^1]: 通过标签感知有界CVaR实现鲁棒的长尾学习

    Robust Long-Tailed Learning via Label-Aware Bounded CVaR. (arXiv:2308.15405v1 [cs.LG])

    [http://arxiv.org/abs/2308.15405](http://arxiv.org/abs/2308.15405)

    本文提出了两种基于CVaR的方法来改进长尾学习的性能，并具备坚实的理论基础。第一种方法是引入了一种标签感知有界CVaR（LAB-CVaR）损失函数，解决了原始CVaR的悲观结果，通过设计最优权重上下界进行改进；第二种方法是提出了一种带有logit调整的LAB-CVaR（LAB-CVaR-logit）损失函数，以稳定优化过程。

    

    在真实世界的分类问题中，数据往往是不平衡或长尾分布的，其中大多数类别拥有大部分样本，并主导模型训练。在这种情况下，普通模型往往在少数类上表现较差。之前，已经提出了各种损失函数修正方法来解决长尾学习问题，然而这些方法要么对同一类别的样本漠不关心，要么缺乏理论保证。本文提出了两种基于CVaR（条件价值-at-Risk）的新方法来提高长尾学习的性能并具备坚实的理论基础。具体而言，我们首先引入了一种标签感知有界CVaR（LAB-CVaR）损失函数来克服原始CVaR悲观的结果，并在理论上设计了LAB-CVaR的最优权重上下界。基于LAB-CVaR，我们进一步提出了一种带有logit调整的LAB-CVaR（LAB-CVaR-logit）损失函数，以稳定优化过程。

    Data in the real-world classification problems are always imbalanced or long-tailed, wherein the majority classes have the most of the samples that dominate the model training. In such setting, the naive model tends to have poor performance on the minority classes. Previously, a variety of loss modifications have been proposed to address the long-tailed leaning problem, while these methods either treat the samples in the same class indiscriminatingly or lack a theoretical guarantee. In this paper, we propose two novel approaches based on CVaR (Conditional Value at Risk) to improve the performance of long-tailed learning with a solid theoretical ground. Specifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss to overcome the pessimistic result of the original CVaR, and further design the optimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we additionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to stabilize the optimization pro
    
[^2]: 一种多角度学习排序方法，支持教室中儿童的信息搜索

    A Multi-Perspective Learning to Rank Approach to Support Children's Information Seeking in the Classroom. (arXiv:2308.15265v1 [cs.IR])

    [http://arxiv.org/abs/2308.15265](http://arxiv.org/abs/2308.15265)

    这项研究提出了一种多角度学习排序方法，能够通过分析URL、片段和页面标题，优先考虑高教育一致性、适当性和可读性的Web资源，从而改进儿童信息搜索能力。

    

    我们介绍了一种新颖的重新排序模型，旨在增强标准搜索引擎的功能，以支持6至11岁儿童的课堂搜索活动。该模型通过平衡风险和回报扩展了已知的整体排序学习框架。通过分析给定主流搜索引擎检索到的Web资源的URL、片段和页面标题，该模型能够优先考虑高教育一致性、适当性和可读性的Web资源。实验结果包括消融研究和与现有基线的比较，展示了所提出模型的正确性。这项工作的结果证明了在设计能够更好地支持儿童信息发现的算法时，考虑到教室环境中的多个视角的价值，例如教育一致性、可读性和反对性。

    We introduce a novel re-ranking model that aims to augment the functionality of standard search engines to support classroom search activities for children (ages 6 to 11). This model extends the known listwise learning-to-rank framework by balancing risk and reward. Doing so enables the model to prioritize Web resources of high educational alignment, appropriateness, and adequate readability by analyzing the URLs, snippets, and page titles of Web resources retrieved by a given mainstream search engine. Experimental results, including an ablation study and comparisons with existing baselines, showcase the correctness of the proposed model. The outcomes of this work demonstrate the value of considering multiple perspectives inherent to the classroom setting, e.g., educational alignment, readability, and objectionability, when applied to the design of algorithms that can better support children's information discovery.
    
[^3]: 基于知识的多重自适应空间融合推荐方法

    Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation. (arXiv:2308.15244v1 [cs.IR])

    [http://arxiv.org/abs/2308.15244](http://arxiv.org/abs/2308.15244)

    该论文提出了一种基于知识的多重自适应空间融合推荐方法，通过统一的空间来融合双曲、欧几里得和球面空间，并利用注意力机制提高了知识传播的嵌入质量。

    

    鉴于知识图谱包含丰富的语义信息，近年来一些KG-enhanced推荐方法层出不穷。现有方法大多是基于欧几里得空间设计的，没有考虑曲率。然而，最近的研究表明，巨大的图结构数据表现出高度非欧几里得的特性。在这项工作中，我们受到这些观察的启发，提出了一种基于知识的多重自适应空间融合推荐方法，称为MCKG。与现有方法仅采用特定流形的方法不同，我们引入了与双曲、欧几里得和球面空间兼容的统一空间。此外，在注意力方式下，我们融合了多个统一空间，以获取更好的知识传播的高质量嵌入。此外，我们提出了一种几何感知优化策略，使得拉和推过程可以充分利用双曲和球面空间的优势。具体而言，在双曲空间中，

    Since Knowledge Graphs (KGs) contain rich semantic information, recently there has been an influx of KG-enhanced recommendation methods. Most of existing methods are entirely designed based on euclidean space without considering curvature. However, recent studies have revealed that a tremendous graph-structured data exhibits highly non-euclidean properties. Motivated by these observations, in this work, we propose a knowledge-based multiple adaptive spaces fusion method for recommendation, namely MCKG. Unlike existing methods that solely adopt a specific manifold, we introduce the unified space that is compatible with hyperbolic, euclidean and spherical spaces. Furthermore, we fuse the multiple unified spaces in an attention manner to obtain the high-quality embeddings for better knowledge propagation. In addition, we propose a geometry-aware optimization strategy which enables the pull and push processes benefited from both hyperbolic and spherical spaces. Specifically, in hyperbolic 
    
[^4]: 结合可解释性分析的分类感知神经主题模型——用于冲突分类

    Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification. (arXiv:2308.15232v1 [cs.LG])

    [http://arxiv.org/abs/2308.15232](http://arxiv.org/abs/2308.15232)

    本文提出了一种结合可解释性分析的分类感知神经主题模型，用于冲突分类和主题发现。该模型提供了可靠的分类结果和发现的主题的解释，并通过优化模型的复杂度来提高分类性能。

    

    世界上有大量的冲突事件一直在影响着我们。为了有效分析这些冲突事件，本文提出了一种用于冲突信息分类和主题发现的分类感知神经主题模型（CANTM-IA）。该模型通过引入可解释性分析来提供可靠的分类结果和发现的主题的解释。同时，将解释性引入模型架构中，以提高模型的分类性能，并使解释进一步关注数据的细节。最后，对模型架构进行优化，以降低模型的复杂度。

    A large number of conflict events are affecting the world all the time. In order to analyse such conflict events effectively, this paper presents a Classification-Aware Neural Topic Model (CANTM-IA) for Conflict Information Classification and Topic Discovery. The model provides a reliable interpretation of classification results and discovered topics by introducing interpretability analysis. At the same time, interpretation is introduced into the model architecture to improve the classification performance of the model and to allow interpretation to focus further on the details of the data. Finally, the model architecture is optimised to reduce the complexity of the model.
    
[^5]: 使用变分自动编码器为以前未出现的用户提供公平推荐

    Providing Previously Unseen Users Fair Recommendations Using Variational Autoencoders. (arXiv:2308.15230v1 [cs.IR])

    [http://arxiv.org/abs/2308.15230](http://arxiv.org/abs/2308.15230)

    本论文提出了一种使用变分自动编码器的新方法，通过限制人口统计信息的编码来减少推荐系统中的歧视，从而为以前未出现的用户提供公平推荐。

    

    机器学习中关于公平性的新定义要求模型对用户的人口统计信息不可见，例如，用户的性别或年龄不应影响模型。个性化推荐系统特别容易通过其显式的用户关注和用户建模来违反这个定义。显式的用户建模也是许多推荐系统无法为以前未出现的用户提供推荐的原因。我们提出了一种限制人口统计信息编码的新方法来减少基于变分自动编码器的推荐系统中的歧视。这些方法能够在评估中为未在训练数据中出现的用户提供公平推荐。

    An emerging definition of fairness in machine learning requires that models are oblivious to demographic user information, e.g., a user's gender or age should not influence the model. Personalized recommender systems are particularly prone to violating this definition through their explicit user focus and user modelling. Explicit user modelling is also an aspect that makes many recommender systems incapable of providing hitherto unseen users with recommendations. We propose novel approaches for mitigating discrimination in Variational Autoencoder-based recommender systems by limiting the encoding of demographic information. The approaches are capable of, and evaluated on, providing users that are not represented in the training data with fair recommendations.
    
[^6]: CAGRA：面向GPU的高度并行图构建和近似最近邻搜索

    CAGRA: Highly Parallel Graph Construction and Approximate Nearest Neighbor Search for GPUs. (arXiv:2308.15136v1 [cs.DS])

    [http://arxiv.org/abs/2308.15136](http://arxiv.org/abs/2308.15136)

    CAGRA是一种面向GPU的高度并行图构建和近似最近邻搜索方法，在近似最近邻搜索领域取得了显著的效率提升。

    

    近似最近邻搜索（ANNS）在数据挖掘和人工智能领域中起着关键作用，涵盖了信息检索、计算机视觉、自然语言处理和推荐系统等各个学科。近年来，数据量急剧增加，穷举精确最近邻搜索的计算成本往往是禁止性的，必须采用近似技术。尽管图形化方法的平衡性能和召回率在ANNS算法中最近引起了广泛关注，但只有少数研究探索了利用GPU和多核处理器的强大计算能力，尽管广泛使用了大规模并行和通用计算能力。为了弥补这一差距，我们引入了一种基于并行计算硬件的新颖接近图和搜索算法。通过利用现代硬件的高性能能力，我们的方法实现了显著的效率提升。具体而言，我们的方法实现了高效的图构建和近似最近邻搜索。

    Approximate Nearest Neighbor Search (ANNS) plays a critical role in various disciplines spanning data mining and artificial intelligence, from information retrieval and computer vision to natural language processing and recommender systems. Data volumes have soared in recent years and the computational cost of an exhaustive exact nearest neighbor search is often prohibitive, necessitating the adoption of approximate techniques. The balanced performance and recall of graph-based approaches have more recently garnered significant attention in ANNS algorithms, however, only a few studies have explored harnessing the power of GPUs and multi-core processors despite the widespread use of massively parallel and general-purpose computing. To bridge this gap, we introduce a novel parallel computing hardware-based proximity graph and search algorithm. By leveraging the high-performance capabilities of modern hardware, our approach achieves remarkable efficiency gains. In particular, our method s
    
[^7]: 一石二鸟：音频字幕系统是否能用于音频文本检索？

    Killing two birds with one stone: Can an audio captioning system also be used for audio-text retrieval?. (arXiv:2308.15090v1 [cs.CL])

    [http://arxiv.org/abs/2308.15090](http://arxiv.org/abs/2308.15090)

    这篇论文研究了音频字幕系统和音频文本检索系统之间的关系，通过探索未经修改的音频字幕系统对音频文本检索任务的性能。研究发现，即使未进行微调，音频字幕系统在音频文本检索任务上表现出了一定的能力。

    

    自动音频字幕系统旨在开发能够用文本句子描述音频录音的系统。与此相反，音频文本检索系统旨在为给定的文本查询（文本到音频）或反之（音频到文本）找到最佳匹配的音频录音。这些任务需要不同类型的系统：音频字幕系统采用序列到序列模型，而音频文本检索系统利用在共享投射子空间内比较音频和文本表示的排序模型。然而，本研究通过探索未经修改的音频字幕系统（无需针对新任务进行微调）的音频文本检索能力，研究了音频字幕系统与音频文本检索系统之间的关系。我们的音频字幕系统包括一个在音频标记上通过AudioSet进行训练的音频编码器（ConvNeXt-Tiny），以及一个负责生成句子的变压器解码器。对于音频字幕系统，它在Clotho上的SPIDEr-FL得分平均为0.298，在AudioCaps上的得分平均为0.472。对于音频文本检索系统，我们提出使用标准的交叉熵损失值。

    Automated Audio Captioning (AAC) aims to develop systems capable of describing an audio recording using a textual sentence. In contrast, Audio-Text Retrieval (ATR) systems seek to find the best matching audio recording(s) for a given textual query (Text-to-Audio) or vice versa (Audio-to-Text). These tasks require different types of systems: AAC employs a sequence-to-sequence model, while ATR utilizes a ranking model that compares audio and text representations within a shared projection subspace. However, this work investigates the relationship between AAC and ATR by exploring the ATR capabilities of an unmodified AAC system, without fine-tuning for the new task. Our AAC system consists of an audio encoder (ConvNeXt-Tiny) trained on AudioSet for audio tagging, and a transformer decoder responsible for generating sentences. For AAC, it achieves a high SPIDEr-FL score of 0.298 on Clotho and 0.472 on AudioCaps on average. For ATR, we propose using the standard Cross-Entropy loss values ob
    
[^8]: STEC: 基于透明Transformer编码器的CTR预测模型

    STEC: See-Through Transformer-based Encoder for CTR Prediction. (arXiv:2308.15033v1 [cs.IR])

    [http://arxiv.org/abs/2308.15033](http://arxiv.org/abs/2308.15033)

    STEC是一种基于透明Transformer编码器的CTR预测模型，通过引入多种交互学习方法和残差连接，提升了模型性能。

    

    点击率（CTR）预测在在线广告和推荐系统中扮演着关键角色，因为CTR预测性能直接影响用户的整体满意度和公司的收入。然而，CTR预测仍然是一个活跃的研究领域，因为它涉及基于稀疏和高维特征准确建模用户的偏好，多个特征的高阶交互可能导致不同的结果。大多数CTR预测模型依赖于单一的融合和交互学习策略。少数CTR预测模型利用多个交互建模策略，但将每个交互视为独立的。在本文中，我们提出了一种名为STEC的新模型，它在单一统一的结构中充分利用了多种交互学习方法的优势。此外，我们的模型引入了来自不同交互阶的残差连接，从而提升了模型的性能。

    Click-Through Rate (CTR) prediction holds a pivotal place in online advertising and recommender systems since CTR prediction performance directly influences the overall satisfaction of the users and the revenue generated by companies. Even so, CTR prediction is still an active area of research since it involves accurately modelling the preferences of users based on sparse and high-dimensional features where the higher-order interactions of multiple features can lead to different outcomes. Most CTR prediction models have relied on a single fusion and interaction learning strategy. The few CTR prediction models that have utilized multiple interaction modelling strategies have treated each interaction to be self-contained. In this paper, we propose a novel model named STEC that reaps the benefits of multiple interaction learning approaches in a single unified architecture. Additionally, our model introduces residual connections from different orders of interactions which boosts the perfor
    
[^9]: 用传统IR方法提高神经排名模型

    Improving Neural Ranking Models with Traditional IR Methods. (arXiv:2308.15027v1 [cs.IR])

    [http://arxiv.org/abs/2308.15027](http://arxiv.org/abs/2308.15027)

    本文研究了一种低成本的替代方法，通过将传统的TF-IDF和浅层嵌入模型结合使用，可以与基于大型Transformer模型的神经排名模型竞争，并可以提高这些模型在大规模任务上的性能。

    

    基于大型Transformer模型的神经排名方法近年来在信息检索领域引起了极大关注，并被主要商业解决方案采用。然而，它们在创建过程中计算成本高昂，并需要大量标记数据来适应特定的语料库。在本文中，我们探索了低资源替代方案，即基于嵌入模型的文档检索方法，并发现它在信息检索任务上与细调的大型Transformer模型相竞争。我们的结果表明，将传统关键字匹配方法TF-IDF与浅层嵌入模型简单结合可以以低成本追赶到复杂神经排名模型在三个数据集上的性能。此外，在这些任务上添加TF-IDF度量可以提高大规模细调模型的性能。

    Neural ranking methods based on large transformer models have recently gained significant attention in the information retrieval community, and have been adopted by major commercial solutions. Nevertheless, they are computationally expensive to create, and require a great deal of labeled data for specialized corpora. In this paper, we explore a low resource alternative which is a bag-of-embedding model for document retrieval and find that it is competitive with large transformer models fine tuned on information retrieval tasks. Our results show that a simple combination of TF-IDF, a traditional keyword matching method, with a shallow embedding model provides a low cost path to compete well with the performance of complex neural ranking models on 3 datasets. Furthermore, adding TF-IDF measures improves the performance of large-scale fine tuned models on these tasks.
    
[^10]: CAPS：用于带有过滤的相似性搜索的实用分区索引

    CAPS: A Practical Partition Index for Filtered Similarity Search. (arXiv:2308.15014v1 [cs.IR])

    [http://arxiv.org/abs/2308.15014](http://arxiv.org/abs/2308.15014)

    CAPS是一种通过空间分区实现的用于带有过滤的相似性搜索的索引，它在召回-延迟权衡方面优于基于图的约束搜索技术，并且只需要较小的索引大小。

    

    随着神经表示学习的进步，近似近邻搜索（ANNS）的流行度越来越高，同时也加强了对能够在查询中附带一组约束的能力的关注。尽管社区最近提出了几种用于约束ANNS的算法，但几乎所有这些方法都集中在与基于图的索引的集成上，这是一种能够在延迟-召回权衡中实现最先进性能的主要算法类别。在这项工作中，我们采用了不同的方法，专注于通过空间分区而不是图来开发约束ANNS算法。为此，我们引入了约束近似分区搜索（CAPS），这是一种通过空间分区进行带有过滤的ANNS索引，不仅保留了基于分区的算法的优势，而且在召回-延迟权衡方面胜过最先进的基于图的约束搜索技术，而且只需要10%的索引大小。

    With the surging popularity of approximate near-neighbor search (ANNS), driven by advances in neural representation learning, the ability to serve queries accompanied by a set of constraints has become an area of intense interest. While the community has recently proposed several algorithms for constrained ANNS, almost all of these methods focus on integration with graph-based indexes, the predominant class of algorithms achieving state-of-the-art performance in latency-recall tradeoffs. In this work, we take a different approach and focus on developing a constrained ANNS algorithm via space partitioning as opposed to graphs. To that end, we introduce Constrained Approximate Partitioned Search (CAPS), an index for ANNS with filters via space partitions that not only retains the benefits of a partition-based algorithm but also outperforms state-of-the-art graph-based constrained search techniques in recall-latency tradeoffs, with only 10% of the index size.
    
[^11]: 动态语料库上的生成性检索的持续学习

    Continual Learning for Generative Retrieval over Dynamic Corpora. (arXiv:2308.14968v1 [cs.IR])

    [http://arxiv.org/abs/2308.14968](http://arxiv.org/abs/2308.14968)

    这项研究解决了生成性检索在动态语料库中的持续学习问题，通过引入CLEVER模型，并提出了增量产品量化的方法来实现低计算成本的新文档编码。

    

    生成性检索（GR）基于参数模型直接预测相关文档的标识符（即docids），在许多应用检索任务上取得了良好的性能。然而，迄今为止，这些任务都假设了静态文档集合。然而，在许多实际场景中，文档集合是动态的，即持续不断地添加新文档。能够增量索引新文档同时保留以前和新索引的相关文档回答查询的能力，对应用GR模型非常重要。在本文中，我们解决了GR的实际持续学习问题。我们提出了一种新颖的持续学习模型CLEVER（Continual-LEarner for generatiVE Retrieval），在GR的持续学习方面做出了两个重大贡献：（i）为了以低计算成本将新文档编码为docids，我们提出了增量产品量化（Incremental Product Quantization），根据两个自适应阈值更新部分量化码本；和（ii）为了

    Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To
    
[^12]: 使用OpenAI嵌入和Lucene的向量搜索：Lucene即为所需

    Vector Search with OpenAI Embeddings: Lucene Is All You Need. (arXiv:2308.14963v1 [cs.IR])

    [http://arxiv.org/abs/2308.14963](http://arxiv.org/abs/2308.14963)

    本论文提供了一个使用Lucene进行向量搜索的可复现演示，挑战了需要专用向量存储的观点，并展示了Lucene中的HNSW索引足以提供向量搜索功能。这表明在现代"AI堆栈"中进行搜索并不需要引入专用向量存储。

    

    我们提供了一个可复现的、端到端的向量搜索演示，使用Lucene在流行的MS MARCO段落排名测试集上进行。我们的工作的主要目标是挑战一种普遍的观点，即利用最近在深度神经网络在搜索中的应用中取得的进展需要一个专用的向量存储。恰恰相反，我们展示了Lucene中的层次可导航小世界网络（HNSW）索引足以在标准的双编码器架构中提供向量搜索功能。这表明，从简单的成本效益分析来看，将一个专门的向量存储引入现代的“AI堆栈”中进行搜索似乎没有强有力的理由，因为这些应用已经在现有的广泛部署的基础设施中得到了大量的投资。

    We provide a reproducible, end-to-end demonstration of vector search with OpenAI embeddings using Lucene on the popular MS MARCO passage ranking test collection. The main goal of our work is to challenge the prevailing narrative that a dedicated vector store is necessary to take advantage of recent advances in deep neural networks as applied to search. Quite the contrary, we show that hierarchical navigable small-world network (HNSW) indexes in Lucene are adequate to provide vector search capabilities in a standard bi-encoder architecture. This suggests that, from a simple cost-benefit analysis, there does not appear to be a compelling reason to introduce a dedicated vector store into a modern "AI stack" for search, since such applications have already received substantial investments in existing, widely deployed infrastructure.
    
[^13]: RecRec: 推荐系统的算法性补救措施

    RecRec: Algorithmic Recourse for Recommender Systems. (arXiv:2308.14916v1 [cs.IR])

    [http://arxiv.org/abs/2308.14916](http://arxiv.org/abs/2308.14916)

    本文提出了一个算法性补救框架，用于帮助理解推荐系统的模型并修改推荐结果。

    

    推荐系统在娱乐、购物、食物、新闻、就业和教育等领域的决策中起着至关重要的作用。这些推荐系统背后的机器学习模型对于用户、内容提供者和系统开发者来说通常都是巨大且不透明的。对于所有利益相关者来说，理解模型在进行某些预测和推荐时的原理至关重要。对于那些生计依赖于推荐系统的内容提供者来说尤其如此。在本研究中，我们从从实际需求出发，提出了一个面向内容提供者的推荐系统补救框架。推荐设置中的算法性补救是一组操作，如果执行，将以期望的方式修改项目的推荐（或排序）。补救措施提供的操作形式为：“如果一个特征从X变为Y，那么该项目的排名也会相应变化。”

    Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model's rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners' need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: "if a feature changes X to Y, then the ranking of that item for a s
    
[^14]: Ad-Rec: 高级特征交互来解决推荐网络中的协变量漂移问题

    Ad-Rec: Advanced Feature Interactions to Address Covariate-Shifts in Recommendation Networks. (arXiv:2308.14902v1 [cs.IR])

    [http://arxiv.org/abs/2308.14902](http://arxiv.org/abs/2308.14902)

    Ad-Rec是一个利用高级特征交互技术解决推荐网络中协变量漂移问题的模型，通过利用掩码转换器实现高阶交叉特征的学习，提高了模型质量、加速了收敛速度并减少了训练时间。

    

    推荐模型通过利用多个输入特征之间的相关性，在提供个性化用户体验方面起到重要作用。然而，基于深度学习的推荐模型经常面临用户行为和物品特征不断变化导致的协变量漂移问题。在处理数据分布漂移和适应用户行为变化方面，有效的特征交互学习至关重要。传统的特征交互技术在这种情况下存在一些局限性。本文介绍了Ad-Rec，一个利用特征交互技术来解决协变量漂移问题的高级网络。这有助于消除推荐任务中的无关交互。Ad-Rec利用掩码转换器来实现高阶交叉特征的学习，同时减轻数据分布漂移的影响。我们的方法通过Area Under Curve（AUC）指标衡量，提高了模型质量，加快了收敛速度，减少了训练时间。

    Recommendation models are vital in delivering personalized user experiences by leveraging the correlation between multiple input features. However, deep learning-based recommendation models often face challenges due to evolving user behaviour and item features, leading to covariate shifts. Effective cross-feature learning is crucial to handle data distribution drift and adapting to changing user behaviour. Traditional feature interaction techniques have limitations in achieving optimal performance in this context.  This work introduces Ad-Rec, an advanced network that leverages feature interaction techniques to address covariate shifts. This helps eliminate irrelevant interactions in recommendation tasks. Ad-Rec leverages masked transformers to enable the learning of higher-order cross-features while mitigating the impact of data distribution drift. Our approach improves model quality, accelerates convergence, and reduces training time, as measured by the Area Under Curve (AUC) metric.
    
[^15]: 在执法学中通过交互式学习扩展跨模态检索以提高图像检索性能

    Extending Cross-Modal Retrieval with Interactive Learning to Improve Image Retrieval Performance in Forensics. (arXiv:2308.14786v1 [cs.IR])

    [http://arxiv.org/abs/2308.14786](http://arxiv.org/abs/2308.14786)

    本研究通过提出名为Excalibur的零样本跨模态图像检索系统，探索了交互式学习在提高执法学中图像检索性能方面的有效性，并通过模拟和用户研究证明了其显著的改进效果。

    

    如今，在执法学中面临的关键挑战之一是分析大量的非结构化数字证据，例如图像。往往，非结构化数字证据包含了执法调查中宝贵的信息。因此，一个能够有效识别与执法相关图像的检索系统至关重要。在这项工作中，我们通过提出名为Excalibur的零样本跨模态图像检索系统，探索了交互式学习在提高执法学中图像检索性能方面的有效性。Excalibur通过模拟和用户研究进行了评估。模拟结果表明，交互式学习在执法学中提高检索性能方面非常有效。此外，用户研究参与者能够有效地利用交互式学习的力量。最后，他们认为Excalibur易于使用且有效，并对将其应用于日常实践表达了兴趣。

    Nowadays, one of the critical challenges in forensics is analyzing the enormous amounts of unstructured digital evidence, such as images. Often, unstructured digital evidence contains precious information for forensic investigations. Therefore, a retrieval system that can effectively identify forensically relevant images is paramount. In this work, we explored the effectiveness of interactive learning in improving image retrieval performance in the forensic domain by proposing Excalibur - a zero-shot cross-modal image retrieval system extended with interactive learning. Excalibur was evaluated using both simulations and a user study. The simulations reveal that interactive learning is highly effective in improving retrieval performance in the forensic domain. Furthermore, user study participants could effectively leverage the power of interactive learning. Finally, they considered Excalibur effective and straightforward to use and expressed interest in using it in their daily practice.
    
[^16]: 使用CNN-LSTM模型对波斯推特的政治情感进行分析

    Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model. (arXiv:2307.07740v1 [cs.CL])

    [http://arxiv.org/abs/2307.07740](http://arxiv.org/abs/2307.07740)

    本论文使用CNN-LSTM模型对波斯推特的政治情感进行分析，使用ParsBERT进行词汇表示，并比较了机器学习和深度学习模型的效果。实验结果表明，深度学习模型表现更好，其中CNN-LSTM模型在两个数据集上分别达到了89%和71%的分类准确率。

    

    情感分析是识别和分类人们对各种话题的情感或观点的过程。近年来，对Twitter情感的分析成为一个越来越受欢迎的话题。在本文中，我们提出了几种机器学习和深度学习模型，用于分析波斯政治推特的情感。我们使用词袋模型和ParsBERT进行词汇表示的分析。我们应用了高斯朴素贝叶斯、梯度提升、逻辑回归、决策树、随机森林以及CNN和LSTM的组合来分类推特的极性。本研究的结果表明，使用ParsBERT嵌入的深度学习模型比机器学习表现更好。CNN-LSTM模型在第一个有三种类别的数据集上的分类准确率为89％，在第二个有七种类别的数据集上的分类准确率为71％。由于波斯语的复杂性，达到这一效率水平是一项困难的任务。

    Sentiment analysis is the process of identifying and categorizing people's emotions or opinions regarding various topics. The analysis of Twitter sentiment has become an increasingly popular topic in recent years. In this paper, we present several machine learning and a deep learning model to analysis sentiment of Persian political tweets. Our analysis was conducted using Bag of Words and ParsBERT for word representation. We applied Gaussian Naive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random Forests, as well as a combination of CNN and LSTM to classify the polarities of tweets. The results of this study indicate that deep learning with ParsBERT embedding performs better than machine learning. The CNN-LSTM model had the highest classification accuracy with 89 percent on the first dataset with three classes and 71 percent on the second dataset with seven classes. Due to the complexity of Persian, it was a difficult task to achieve this level of efficiency.
    
[^17]: Mol-Instructions: 一个大规模生物分子指令数据集，为大语言模型提供支持

    Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.08018](http://arxiv.org/abs/2306.08018)

    Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。

    

    大语言模型（LLM）以其卓越的任务处理能力和创新的输出，在许多领域推动了重大进展。然而，它们在生物分子研究等专业领域的熟练应用还受到限制。为了解决这个挑战，我们介绍了Mol-Instructions，这是一个经过精心策划、专门针对生物分子领域设计的综合指令数据集。Mol-Instructions由三个关键组成部分组成：分子导向指令、蛋白质导向指令和生物分子文本指令，每个部分都被策划用于增强LLM对生物分子特性和行为的理解和预测能力。通过对代表性LLM的广泛指令调整实验，我们强调了Mol-Instructions在增强大模型在生物分子研究复杂领域内的适应能力和认知敏锐度方面的潜力，从而促进生物分子领域的进一步发展。

    Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
    

