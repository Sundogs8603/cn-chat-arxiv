# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems.](http://arxiv.org/abs/2308.08434) | 本文提出了一个名为BIGRec的两步接地框架，通过将大型语言模型与推荐空间接地，生成有意义的标记，并识别相应的实际项目，来探究大型语言模型在推荐系统中的全面排序能力。 |

# 详细

[^1]: 大型语言模型在推荐系统中的双步接地范式

    A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems. (arXiv:2308.08434v1 [cs.IR])

    [http://arxiv.org/abs/2308.08434](http://arxiv.org/abs/2308.08434)

    本文提出了一个名为BIGRec的两步接地框架，通过将大型语言模型与推荐空间接地，生成有意义的标记，并识别相应的实际项目，来探究大型语言模型在推荐系统中的全面排序能力。

    

    随着推荐领域对大型语言模型（LLMs）的关注加强，针对推荐目的（称为LLM4Rec）优化LLMs的重要性在提供推荐方面得到了增强。然而，现有的LLM4Rec方法通常使用有限的候选集来评估性能，这可能无法准确反映模型的整体排序能力。在本文中，我们的目标是调查LLMs的全面排序能力，并提出一个名为BIGRec（推荐的双步接地范式）的两步接地框架。它首先通过微调将LLMs与推荐空间接地，生成与项目相关的有意义的标记，然后识别与生成的标记相对应的适当实际项目。通过在两个数据集上进行广泛实验，我们证明了其卓越的性能、处理少样本场景的能力以及在多个数据集上的通用性。

    As the focus on Large Language Models (LLMs) in the field of recommendation intensifies, the optimization of LLMs for recommendation purposes (referred to as LLM4Rec) assumes a crucial role in augmenting their effectiveness in providing recommendations. However, existing approaches for LLM4Rec often assess performance using restricted sets of candidates, which may not accurately reflect the models' overall ranking capabilities. In this paper, our objective is to investigate the comprehensive ranking capacity of LLMs and propose a two-step grounding framework known as BIGRec (Bi-step Grounding Paradigm for Recommendation). It initially grounds LLMs to the recommendation space by fine-tuning them to generate meaningful tokens for items and subsequently identifies appropriate actual items that correspond to the generated tokens. By conducting extensive experiments on two datasets, we substantiate the superior performance, capacity for handling few-shot scenarios, and versatility across mu
    

