# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Improving position bias estimation against sparse and skewed dataset with item embedding.](http://arxiv.org/abs/2305.13931) | 该研究提出了一种利用物品嵌入来缓解广告营销领域中位置偏差稀疏性问题的回归EM算法变体。 |
| [^2] | [DAPR: A Benchmark on Document-Aware Passage Retrieval.](http://arxiv.org/abs/2305.13915) | DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。 |
| [^3] | [Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines.](http://arxiv.org/abs/2305.13859) | 本论文提出了一种新的自回归搜索引擎框架AutoTSG，其特点是基于无序术语集的文档标识符和基于集合的生成管道，大大放松了对标识符精确生成的要求。 |
| [^4] | [Advances and Challenges of Multi-task Learning Method in Recommender System: A Survey.](http://arxiv.org/abs/2305.13843) | 本文综述了多任务学习在推荐系统中的应用，提出了基于多任务学习技术的推荐方法分类，同时探讨了未来发展方向。 |
| [^5] | [Continual Learning on Dynamic Graphs via Parameter Isolation.](http://arxiv.org/abs/2305.13825) | 提出了Parameter Isolation GNN (PI-GNN)模型，用于处理动态图上的持续学习任务。该模型通过参数隔离和扩展来避免学习新模式和保留旧模式之间的权衡。 |
| [^6] | [GenSpectrum Chat: Data Exploration in Public Health Using Large Language Models.](http://arxiv.org/abs/2305.13821) | GenSpectrum聊天机器人使用GPT-4作为LLM，允许用户通过简单的自然语言输入探索和可视化复杂的基因组数据，为公共卫生机构，研究人员和一般大众提供了一种更直观和可访问的方式来理解和分析与COVID-19相关的基因组数据。 |
| [^7] | [A Critical Reexamination of Intra-List Distance and Dispersion.](http://arxiv.org/abs/2305.13801) | 本研究从理论和实验角度对流行的多样性推荐目标——列表内距离和离散度进行关键的重新审视，揭示它们的潜在缺陷。 |
| [^8] | [Text Is All You Need: Learning Language Representations for Sequential Recommendation.](http://arxiv.org/abs/2305.13731) | 本研究提出了一种名为Recformer的框架，它将用户喜好和项目特征建模为可以推广到新项目和数据集的语言表示，并利用双向Transformer来捕捉长期依赖关系，用于序列推荐，比目前最先进的方法表现更好。 |
| [^9] | [Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker.](http://arxiv.org/abs/2305.13729) | 本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。 |
| [^10] | [Conversational Recommendation as Retrieval: A Simple, Strong Baseline.](http://arxiv.org/abs/2305.13725) | 本论文提出一种以检索方式进行的对话式推荐方法，将对话表示为查询，将物品表示为待检索的文档，并使用基于BM25的检索器进行推荐。相比于使用复杂的外部知识的基准线，该方法简单且更具优越性能。 |
| [^11] | [Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues.](http://arxiv.org/abs/2305.13690) | 本文提出了一个名为MAS2S的多注意力Seq2Seq网络，它能够提问以澄清任务导向信息获取中用户的信息需求和个人资料。实验证明该模型在任务导向信息查询方面的准确性和覆盖范围优于现有模型。 |
| [^12] | [Rethinking the Role of Pre-ranking in Large-scale E-Commerce Searching System.](http://arxiv.org/abs/2305.13647) | 本研究重新审视了电子商务搜索系统中预排名的作用，提出其主要目标是返回最优的无序选择集，以使得后续的排名更加高效且适应性更强。 |
| [^13] | [EDIS: Entity-Driven Image Search over Multimodal Web Content.](http://arxiv.org/abs/2305.13631) | 这篇论文介绍了EDIS数据集，该数据集包括100万个多模态图像和文本配对，旨在鼓励开发实现跨模态信息融合和匹配的检索模型。 |
| [^14] | [Curse of "Low" Dimensionality in Recommender Systems.](http://arxiv.org/abs/2305.13597) | 许多推荐系统问题的产生部分原因是使用了低维度的用户和物品嵌入引起，点积模型对于表现能力有限，需要足够高的维度来实现多样化、公平和稳健的推荐；低维度导致流行度偏差带来的贡献扩大了流行和长尾物品在排名位置上的差距。 |
| [^15] | [Understanding Differential Search Index for Text Retrieval.](http://arxiv.org/abs/2305.02073) | DSI是一种可微分搜索指数信息检索框架，虽然其能够生成文件标识符的排序列表，但在区分相关文档和随机文档方面表现不佳，研究人员提出了一种多任务蒸馏方法以提高其检索质量。 |
| [^16] | [AdaMS: Deep Metric Learning with Adaptive Margin and Adaptive Scale for Acoustic Word Discrimination.](http://arxiv.org/abs/2210.14564) | 本研究提出了一种自适应边界和自适应尺度的深度度量学习方法AdaMS，通过使用可学习参数替换超参数来有效地提高声学单词辨别的性能。 |
| [^17] | [A Study on the Efficiency and Generalization of Light Hybrid Retrievers.](http://arxiv.org/abs/2210.01371) | 本文研究了光轻混合召回器的效率和泛化性能，提出了一种采用索引高效的密集召回器和LITE召回器相结合的方法，相对于传统方法可以节省内存。实验证明，该方法可以在不牺牲性能的情况下显著提高模型的泛化性能。 |
| [^18] | [Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems.](http://arxiv.org/abs/2208.06746) | 本文提出了一种因果感知的推荐系统方法，使用对比反事实学习来学习鲁棒且可解释的推荐系统，利用反事实推理来估计推荐的因果效应，并确定有助于用户行为的关键因素。 |

# 详细

[^1]: 利用物品嵌入改进在稀疏和倾斜数据集中对位置偏差的估计

    Improving position bias estimation against sparse and skewed dataset with item embedding. (arXiv:2305.13931v1 [cs.IR])

    [http://arxiv.org/abs/2305.13931](http://arxiv.org/abs/2305.13931)

    该研究提出了一种利用物品嵌入来缓解广告营销领域中位置偏差稀疏性问题的回归EM算法变体。

    

    在学习排名中，估计位置偏差是一个众所周知的挑战。电子商务应用程序中的点击数据（例如广告定位和搜索引擎）提供了隐含但丰富的反馈，以改进个性化排名。然而，点击数据本质上包括各种偏差，例如位置偏差。点击建模旨在去噪有偏的点击数据并提取可靠的信号。已经提出了随机化结果和回归期望最大化算法来解决位置偏差。但是，这两种方法都需要各种观察值对（项目、位置）。然而，在广告营销的实际情况下，营销人员经常按固定的预定顺序显示广告，估计因此而受到影响。我们将位置偏差估计中的（项目、位置）稀疏性问题作为新问题，并提出了一种利用物品嵌入来缓解稀疏问题的回归EM算法变体。我们首先使用合成数据集评估我们的方法。

    Estimating position bias is a well-known challenge in Learning to rank (L2R). Click data in e-commerce applications, such as advertisement targeting and search engines, provides implicit but abundant feedback to improve personalized rankings. However, click data inherently include various biases like position bias. Click modeling is aimed at denoising biases in click data and extracting reliable signals. Result Randomization and Regression Expectation-maximization algorithm have been proposed to solve position bias. Both methods require various pairs of observations (item, position). However, in real cases of advertising, marketers frequently display advertisements in a fixed pre-determined order, and estimation suffers from it. We propose this sparsity of (item, position) in position bias estimation as a novel problem, and we propose a variant of the Regression EM algorithm which utilizes item embeddings to alleviate the issue of the sparsity. With a synthetic dataset, we first evalua
    
[^2]: DAPR：文档感知段落检索的基准测试

    DAPR: A Benchmark on Document-Aware Passage Retrieval. (arXiv:2305.13915v1 [cs.IR])

    [http://arxiv.org/abs/2305.13915](http://arxiv.org/abs/2305.13915)

    DAPR是一个文档感知段落检索的基准测试，挑战在于如何从长文档中找到正确的段落并返回准确结果。

    

    最近的神经检索主要关注短文本的排名，并且在处理长文档方面存在挑战。现有的工作主要评估排名段落或整个文档。然而，许多情况下，用户希望从庞大的语料库中找到长文档中的相关段落，例如法律案例，研究论文等，此时段落往往提供很少的文档上下文，这就挑战了当前的方法找到正确的文档并返回准确的结果。为了填补这个空白，我们提出并命名了Document-Aware Passage Retrieval（DAPR）任务，并构建了一个包括来自不同领域的多个数据集的基准测试，涵盖了DAPR和整个文档检索。在实验中，我们通过不同的方法，包括在文档摘要中添加文档级别的内容，汇总段落表示和使用BM25进行混合检索，扩展了最先进的神经段落检索器。这个混合检索系统，总体基准测试显示，我们提出的DAPR任务是一个具有挑战性和重要性的问题，需要进一步研究。

    Recent neural retrieval mainly focuses on ranking short texts and is challenged with long documents. Existing work mainly evaluates either ranking passages or whole documents. However, there are many cases where the users want to find a relevant passage within a long document from a huge corpus, e.g. legal cases, research papers, etc. In this scenario, the passage often provides little document context and thus challenges the current approaches to finding the correct document and returning accurate results. To fill this gap, we propose and name this task Document-Aware Passage Retrieval (DAPR) and build a benchmark including multiple datasets from various domains, covering both DAPR and whole-document retrieval. In experiments, we extend the state-of-the-art neural passage retrievers with document-level context via different approaches including prepending document summary, pooling over passage representations, and hybrid retrieval with BM25. The hybrid-retrieval systems, the overall b
    
[^3]: 术语集可以成为自回归搜索引擎的强文档标识符

    Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines. (arXiv:2305.13859v1 [cs.IR])

    [http://arxiv.org/abs/2305.13859](http://arxiv.org/abs/2305.13859)

    本论文提出了一种新的自回归搜索引擎框架AutoTSG，其特点是基于无序术语集的文档标识符和基于集合的生成管道，大大放松了对标识符精确生成的要求。

    

    自回归搜索引擎是下一代信息检索系统的有前途的范例。这些方法利用Seq2Seq模型，其中每个查询可以直接映射到其相关文档的标识符。因此，它们因具有端到端可微分性等优点而受到赞扬。然而，自回归搜索引擎在检索质量上也面临着挑战，因为其需要对文档标识符进行精确生成。也就是说，如果在生成过程的任何一步中对其标识符做出了错误的预测，则目标文档将从检索结果中漏失。在这项工作中，我们提出了一种新的框架，即AutoTSG(自回归搜索引擎与术语集生成)，其特点是1)无序基于术语的文档标识符和2)基于集合的生成管道。利用AutoTSG，术语集标识符的任何排列都将导致相应文档的检索，从而大大放松了对标识符精确生成的要求。

    Auto-regressive search engines emerge as a promising paradigm for next-gen information retrieval systems. These methods work with Seq2Seq models, where each query can be directly mapped to the identifier of its relevant document. As such, they are praised for merits like being end-to-end differentiable. However, auto-regressive search engines also confront challenges in retrieval quality, given the requirement for the exact generation of the document identifier. That's to say, the targeted document will be missed from the retrieval result if a false prediction about its identifier is made in any step of the generation process. In this work, we propose a novel framework, namely AutoTSG (Auto-regressive Search Engine with Term-Set Generation), which is featured by 1) the unordered term-based document identifier and 2) the set-oriented generation pipeline. With AutoTSG, any permutation of the term-set identifier will lead to the retrieval of the corresponding document, thus largely relaxi
    
[^4]: 推荐系统中的多任务学习方法的进展与挑战：综述

    Advances and Challenges of Multi-task Learning Method in Recommender System: A Survey. (arXiv:2305.13843v1 [cs.IR])

    [http://arxiv.org/abs/2305.13843](http://arxiv.org/abs/2305.13843)

    本文综述了多任务学习在推荐系统中的应用，提出了基于多任务学习技术的推荐方法分类，同时探讨了未来发展方向。

    

    多任务学习已在计算机视觉、自然语言处理等领域广泛应用，并取得了良好的性能。近年来，关于多任务学习推荐系统的研究已经涌现，但目前还没有文献总结这些成果。为了弥补这一空白，我们提供了一篇系统文献综述，旨在帮助研究人员和从业者快速了解这个方向的当前进展。在本综述中，我们首先介绍了多任务学习推荐系统的背景和动机。然后，我们根据多任务学习技术的不同阶段，包括任务关系发现、模型架构和优化策略，提供了多任务学习推荐方法的分类。最后，我们就这一领域的应用和未来方向展开讨论。

    Multi-task learning has been widely applied in computational vision, natural language processing and other fields, which has achieved well performance. In recent years, a lot of work about multi-task learning recommender system has been yielded, but there is no previous literature to summarize these works. To bridge this gap, we provide a systematic literature survey about multi-task recommender systems, aiming to help researchers and practitioners quickly understand the current progress in this direction. In this survey, we first introduce the background and the motivation of the multi-task learning-based recommender systems. Then we provide a taxonomy of multi-task learning-based recommendation methods according to the different stages of multi-task learning techniques, which including task relationship discovery, model architecture and optimization strategy. Finally, we raise discussions on the application and promising future directions in this area.
    
[^5]: 基于参数隔离的动态图上的持续学习

    Continual Learning on Dynamic Graphs via Parameter Isolation. (arXiv:2305.13825v1 [cs.LG])

    [http://arxiv.org/abs/2305.13825](http://arxiv.org/abs/2305.13825)

    提出了Parameter Isolation GNN (PI-GNN)模型，用于处理动态图上的持续学习任务。该模型通过参数隔离和扩展来避免学习新模式和保留旧模式之间的权衡。

    

    许多实际的图学习任务需要处理新节点和边出现的动态图。动态图学习方法通常遭遇灾难性遗忘问题，即为以前的图所学的知识会被新图的更新覆盖。为了缓解这个问题，提出了持续图学习方法。然而，现有的持续图学习方法旨在学习新的模式并维护旧的模式，但使用相同固定大小的参数集，因此面临两种目标之间的根本权衡。在本文中，我们提出了Parameter Isolation GNN (PI-GNN)，用于动态图上的持续学习，通过参数隔离和扩展来避免这种权衡。我们的动机在于不同的参数对于学习不同的图模式有贡献。基于这个想法，我们扩展模型参数以持续学习出现的图模式。与此同时，为了有效地保存未受影响模式的知识，我们找到参数。

    Many real-world graph learning tasks require handling dynamic graphs where new nodes and edges emerge. Dynamic graph learning methods commonly suffer from the catastrophic forgetting problem, where knowledge learned for previous graphs is overwritten by updates for new graphs. To alleviate the problem, continual graph learning methods are proposed. However, existing continual graph learning methods aim to learn new patterns and maintain old ones with the same set of parameters of fixed size, and thus face a fundamental tradeoff between both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN) for continual learning on dynamic graphs that circumvents the tradeoff via parameter isolation and expansion. Our motivation lies in that different parameters contribute to learning different graph patterns. Based on the idea, we expand model parameters to continually learn emerging graph patterns. Meanwhile, to effectively preserve knowledge for unaffected patterns, we find parameter
    
[^6]: GenSpectrum聊天机器人：利用大型语言模型进行公共卫生数据探索

    GenSpectrum Chat: Data Exploration in Public Health Using Large Language Models. (arXiv:2305.13821v1 [q-bio.GN])

    [http://arxiv.org/abs/2305.13821](http://arxiv.org/abs/2305.13821)

    GenSpectrum聊天机器人使用GPT-4作为LLM，允许用户通过简单的自然语言输入探索和可视化复杂的基因组数据，为公共卫生机构，研究人员和一般大众提供了一种更直观和可访问的方式来理解和分析与COVID-19相关的基因组数据。

    

    引言：COVID-19大流行凸显了使流行病学数据和科学见解易于公共卫生机构，一般大众和研究人员访问和探索的重要性。分享数据和见解的先进方法包括定期更新报告和Web仪表板。但它们面临数据探索简单性和灵活性之间的权衡。利用最近的大型语言模型（LLM）如GPT-4，可以克服这种权衡。结果：我们开发了聊天机器人“GenSpectrum Chat”（https://cov-spectrum.org/chat），它使用GPT-4作为基础LLM来探索SARS-CoV-2基因组测序数据。在来自真实用户的500个输入中，聊天机器人为453个提示提供了正确答案； 13个提示提供了错误答案，尽管34个提示的问题在范围内，但它没有提供答案。我们还测试了来自10种不同语言的输入，尽管GPT-4没有进行多语言处理，但它仍为某些查询提供了正确答案。聊天机器人允许用户通过简单的自然语言输入探索和可视化复杂的基因组数据，为公共卫生机构，研究人员和一般大众提供了一种更直观和可访问的方式来理解和分析与COVID-19相关的基因组数据。

    Introduction: The COVID-19 pandemic highlighted the importance of making epidemiological data and scientific insights easily accessible and explorable for public health agencies, the general public, and researchers. State-of-the-art approaches for sharing data and insights included regularly updated reports and web dashboards. However, they face a trade-off between the simplicity and flexibility of data exploration. With the capabilities of recent large language models (LLMs) such as GPT-4, this trade-off can be overcome.  Results: We developed the chatbot "GenSpectrum Chat" (https://cov-spectrum.org/chat) which uses GPT-4 as the underlying large language model (LLM) to explore SARS-CoV-2 genomic sequencing data. Out of 500 inputs from real-world users, the chatbot provided a correct answer for 453 prompts; an incorrect answer for 13 prompts, and no answer although the question was within scope for 34 prompts. We also tested the chatbot with inputs from 10 different languages, and desp
    
[^7]: 对列表内距离和离散度的关键重新审视

    A Critical Reexamination of Intra-List Distance and Dispersion. (arXiv:2305.13801v1 [cs.IR])

    [http://arxiv.org/abs/2305.13801](http://arxiv.org/abs/2305.13801)

    本研究从理论和实验角度对流行的多样性推荐目标——列表内距离和离散度进行关键的重新审视，揭示它们的潜在缺陷。

    

    推荐结果的多样化是应对用户信息需求不确定性的一种有前途的方法。在多样化推荐中，尤其重要的是定义和优化适当的多样性目标。本研究重新审视了最流行的多样性目标之一——列表内距离（ILD），定义为所选项目之间的平均成对距离，以及一种类似但较不为人知的目标——离散度，它是最小成对距离。由于它们的简单和灵活性，ILD和离散度已在众多多样化推荐研究中使用。然而，我们实际上不知道它们偏好哪些类型的项目。我们从理论和实验角度对ILD和离散度进行了关键的重新审视。我们的理论结果揭示了这些目标潜在的缺点：ILD可能选择非常接近的重复项目，而离散度可能导致重复推荐。

    Diversification of recommendation results is a promising approach for coping with the uncertainty associated with users' information needs. Of particular importance in diversified recommendation is to define and optimize an appropriate diversity objective. In this study, we revisit the most popular diversity objective called intra-list distance (ILD), defined as the average pairwise distance between selected items, and a similar but lesser known objective called dispersion, which is the minimum pairwise distance. Owing to their simplicity and flexibility, ILD and dispersion have been used in a plethora of diversified recommendation research. Nevertheless, we do not actually know what kind of items are preferred by them.  We present a critical reexamination of ILD and dispersion from theoretical and experimental perspectives. Our theoretical results reveal that these objectives have potential drawbacks: ILD may select duplicate items that are very close to each other, whereas dispersion
    
[^8]: 文本是唯一需要的：用于序列推荐的语言表示学习

    Text Is All You Need: Learning Language Representations for Sequential Recommendation. (arXiv:2305.13731v1 [cs.IR])

    [http://arxiv.org/abs/2305.13731](http://arxiv.org/abs/2305.13731)

    本研究提出了一种名为Recformer的框架，它将用户喜好和项目特征建模为可以推广到新项目和数据集的语言表示，并利用双向Transformer来捕捉长期依赖关系，用于序列推荐，比目前最先进的方法表现更好。

    

    序列推荐旨在从历史交互中建模动态用户行为。现有方法依靠明确的项目ID或一般文本特征进行序列建模，以理解用户喜好。尽管很有前途，但这些方法仍然难以建模冷启动项目或将知识转移至新数据集。在本文中，我们建议将用户喜好和项目特征建模为可以推广到新项目和数据集的语言表示。为此，我们提出了一个名为Recformer的新框架，它有效地学习序列推荐的语言表示。具体而言，我们建议通过展平由文本描述的项目键值属性，将项目作为“句子”（单词序列）来编写，以便用户的项目序列成为句子序列。为推荐，Recformer被训练以理解“句子”序列并检索下一个“句子”。为了编码项目序列，我们设计了一个双向Transformer，利用自我注意机制来捕捉长期依赖关系。我们在三个具有不同特征的公共数据集上进行了广泛的实验，并展示了Recformer始终优于现有最先进的方法。

    Sequential recommendation aims to model dynamic user behavior from historical interactions. Existing methods rely on either explicit item IDs or general textual features for sequence modeling to understand user preferences. While promising, these approaches still struggle to model cold-start items or transfer knowledge to new datasets. In this paper, we propose to model user preferences and item features as language representations that can be generalized to new items and datasets. To this end, we present a novel framework, named Recformer, which effectively learns language representations for sequential recommendation. Specifically, we propose to formulate an item as a "sentence" (word sequence) by flattening item key-value attributes described by text so that an item sequence for a user becomes a sequence of sentences. For recommendation, Recformer is trained to understand the "sentence" sequence and retrieve the next "sentence". To encode item sequences, we design a bi-directional T
    
[^9]: 基于约束生成的离散提示优化在零样本重排器中的应用

    Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker. (arXiv:2305.13729v1 [cs.IR])

    [http://arxiv.org/abs/2305.13729](http://arxiv.org/abs/2305.13729)

    本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。

    

    重排器是在给定查询的相关性评分下对检索的文档进行排序的方法，在信息检索（IR）任务中得到了关注。与微调预训练语言模型（PLM）不同，利用大规模语言模型（LLM）作为具有优异结果的零样本重排器。虽然 LLM 在很大程度上依赖于提示语，但零样本重排器提示语的影响和优化尚未得到探究。除了强调优化对零样本重排器的影响外，我们还提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。此外，Co-Prompt 生成的提示更易于人类理解。

    Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans aga
    
[^10]: 以检索方式进行的对话式推荐：一个简单、强大的基准线

    Conversational Recommendation as Retrieval: A Simple, Strong Baseline. (arXiv:2305.13725v1 [cs.CL])

    [http://arxiv.org/abs/2305.13725](http://arxiv.org/abs/2305.13725)

    本论文提出一种以检索方式进行的对话式推荐方法，将对话表示为查询，将物品表示为待检索的文档，并使用基于BM25的检索器进行推荐。相比于使用复杂的外部知识的基准线，该方法简单且更具优越性能。

    

    对话式推荐系统旨在通过自然语言对话向用户推荐合适的物品。然而，大多数现有的方法并没有有效利用这些对话提供的信号。它们严重依赖于显式的外部知识库（例如知识图谱）来增强模型对物品和属性的理解，这很难扩展。为了缓解这个问题，我们提出了一种替代信息检索（IR）风格的方法，将对话表示为查询，将物品表示为待检索的文档。我们扩展了用于检索的文档表示，使用训练集中的对话信息。通过简单的基于BM25的检索器，我们证明了我们的任务设置在流行的CRS基准测试中与复杂的、使用复杂外部知识的基准线相比具有优越性。我们使用以用户为中心的建模和数据增强来对抗冷启动问题，并进一步提高了推荐效果。

    Conversational recommendation systems (CRS) aim to recommend suitable items to users through natural language conversation. However, most CRS approaches do not effectively utilize the signal provided by these conversations. They rely heavily on explicit external knowledge e.g., knowledge graphs to augment the models' understanding of the items and attributes, which is quite hard to scale. To alleviate this, we propose an alternative information retrieval (IR)-styled approach to the CRS item recommendation task, where we represent conversations as queries and items as documents to be retrieved. We expand the document representation used for retrieval with conversations from the training set. With a simple BM25-based retriever, we show that our task formulation compares favorably with much more complex baselines using complex external knowledge on a popular CRS benchmark. We demonstrate further improvements using user-centric modeling and data augmentation to counter the cold start probl
    
[^11]: 面向任务导向对话的信息请求中的澄清问题提问方法

    Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues. (arXiv:2305.13690v1 [cs.CL])

    [http://arxiv.org/abs/2305.13690](http://arxiv.org/abs/2305.13690)

    本文提出了一个名为MAS2S的多注意力Seq2Seq网络，它能够提问以澄清任务导向信息获取中用户的信息需求和个人资料。实验证明该模型在任务导向信息查询方面的准确性和覆盖范围优于现有模型。

    

    任务导向的对话系统旨在为用户提供特定任务的服务。这种系统的用户通常不知道他们正在完成的任务的所有信息，需要寻求关于任务的信息。为了提供准确和个性化的任务导向信息查询结果，任务导向对话系统需要解决两个潜在问题：1) 用户无法在请求中描述他们复杂的信息需求；2) 系统对用户的信息存在模糊/缺失。在本文中，我们提出了一个新的多注意力Seq2Seq网络，命名为MAS2S，它可以提问以澄清用户在任务导向信息查询中的信息需求和用户个人资料。我们还扩展了现有的任务导向信息查询数据集，导致我们的数据集包含约100k个任务导向信息查询对话，这些对话是公开的\footnote{ 数据集和代码可在\href{http://link/to/dataset}{http://link/to/dataset}找到}。在扩展的数据集上进行的实验表明，所提出的模型在任务导向信息查询的准确性和覆盖范围方面优于现有模型。

    Task-oriented dialogue systems aim at providing users with task-specific services. Users of such systems often do not know all the information about the task they are trying to accomplish, requiring them to seek information about the task. To provide accurate and personalized task-oriented information seeking results, task-oriented dialogue systems need to address two potential issues: 1) users' inability to describe their complex information needs in their requests; and 2) ambiguous/missing information the system has about the users. In this paper, we propose a new Multi-Attention Seq2Seq Network, named MAS2S, which can ask questions to clarify the user's information needs and the user's profile in task-oriented information seeking. We also extend an existing dataset for task-oriented information seeking, leading to the \ourdataset which contains about 100k task-oriented information seeking dialogues that are made publicly available\footnote{Dataset and code is available at \href{http
    
[^12]: 重新审视大规模电子商务搜索系统中的预排名的作用

    Rethinking the Role of Pre-ranking in Large-scale E-Commerce Searching System. (arXiv:2305.13647v1 [cs.IR])

    [http://arxiv.org/abs/2305.13647](http://arxiv.org/abs/2305.13647)

    本研究重新审视了电子商务搜索系统中预排名的作用，提出其主要目标是返回最优的无序选择集，以使得后续的排名更加高效且适应性更强。

    

    电子商务搜索系统旨在为用户提供最偏爱的物品（例如产品）。由于海量数据和有限的响应时间，典型的工业排名系统由三个或更多的模块组成，包括匹配、预排名和排名。预排名被广泛认为是一个迷你排名模块，因为它需要对比排名模型更多的物品。现有研究着重于构建一个轻量级模型来模仿排名模型。预排名模型的指标使用离线评估的 ROC 曲线下面积(AUC) 来跟踪排名模型。然而，这样的指标与在线A / B测试在实践中不一致，因此工程师必须进行昂贵的在线测试才能得出令人信服的结论。在我们的工作中，我们重新考虑了预排名的作用。我们认为预排名的主要目标是返回最优的无序选择集，这使得后续的排名更加高效且适应性更强。

    E-commerce search systems such as Taobao Search, the largest e-commerce searching system in China, aim at providing users with the most preferred items (e.g., products). Due to the massive data and limited time for response, a typical industrial ranking system consists of three or more modules, including matching, pre-ranking, and ranking. The pre-ranking is widely considered a mini-ranking module, as it needs to rank hundreds of times more items than the ranking under limited latency. Existing researches focus on building a lighter model that imitates the ranking model. As such, the metric of a pre-ranking model follows the ranking model using Area Under ROC (AUC) for offline evaluation. However, such a metric is inconsistent with online A/B tests in practice, so engineers have to perform costly online tests to reach a convincing conclusion. In our work, we rethink the role of the pre-ranking. We argue that the primary goal of the pre-ranking stage is to return an optimal unordered se
    
[^13]: 基于实体的多模态网络内容图像搜索

    EDIS: Entity-Driven Image Search over Multimodal Web Content. (arXiv:2305.13631v1 [cs.CL])

    [http://arxiv.org/abs/2305.13631](http://arxiv.org/abs/2305.13631)

    这篇论文介绍了EDIS数据集，该数据集包括100万个多模态图像和文本配对，旨在鼓励开发实现跨模态信息融合和匹配的检索模型。

    

    为了在实际搜索应用中实现图像检索方法的实用性，需要在数据集规模、实体理解和多模态信息融合方面取得重大进展。

    Making image retrieval methods practical for real-world search applications requires significant progress in dataset scales, entity comprehension, and multimodal information fusion. In this work, we introduce \textbf{E}ntity-\textbf{D}riven \textbf{I}mage \textbf{S}earch (EDIS), a challenging dataset for cross-modal image search in the news domain. EDIS consists of 1 million web images from actual search engine results and curated datasets, with each image paired with a textual description. Unlike datasets that assume a small set of single-modality candidates, EDIS reflects real-world web image search scenarios by including a million multimodal image-text pairs as candidates. EDIS encourages the development of retrieval models that simultaneously address cross-modal information fusion and matching. To achieve accurate ranking results, a model must: 1) understand named entities and events from text queries, 2) ground entities onto images or text descriptions, and 3) effectively fuse tex
    
[^14]: 推荐系统中 “低” 维度所带来的问题

    Curse of "Low" Dimensionality in Recommender Systems. (arXiv:2305.13597v1 [cs.IR])

    [http://arxiv.org/abs/2305.13597](http://arxiv.org/abs/2305.13597)

    许多推荐系统问题的产生部分原因是使用了低维度的用户和物品嵌入引起，点积模型对于表现能力有限，需要足够高的维度来实现多样化、公平和稳健的推荐；低维度导致流行度偏差带来的贡献扩大了流行和长尾物品在排名位置上的差距。

    

    推荐系统的质量不仅仅与准确度有关，还包括多样性、公平性和鲁棒性等方面。本文认为推荐系统中许多问题的产生部分原因是用户和物品嵌入的低维度，特别是在使用矩阵分解等点积模型时。我们呈现了证据表明，对于嵌入向量，维度需要足够高才能达到多样化、公平和稳健的推荐。我们还对点积模型的表现能力进行了理论分析，结果表明在物品因子的维度上，点积模型能够表达的可能排名数是指数级绑定的。我们在实验中发现，低维度对于流行度偏差带来的贡献扩大了流行和长尾物品在排名位置上的差距，我们还给出了这一现象的理论解释。

    Beyond accuracy, there are a variety of aspects to the quality of recommender systems, such as diversity, fairness, and robustness. We argue that many of the prevalent problems in recommender systems are partly due to low-dimensionality of user and item embeddings, particularly when dot-product models, such as matrix factorization, are used.  In this study, we showcase empirical evidence suggesting the necessity of sufficient dimensionality for user/item embeddings to achieve diverse, fair, and robust recommendation. We then present theoretical analyses of the expressive power of dot-product models. Our theoretical results demonstrate that the number of possible rankings expressible under dot-product models is exponentially bounded by the dimension of item factors. We empirically found that the low-dimensionality contributes to a popularity bias, widening the gap between the rank positions of popular and long-tail items; we also give a theoretical justification for this phenomenon.
    
[^15]: 了解文本检索的可微分搜索指数

    Understanding Differential Search Index for Text Retrieval. (arXiv:2305.02073v1 [cs.IR])

    [http://arxiv.org/abs/2305.02073](http://arxiv.org/abs/2305.02073)

    DSI是一种可微分搜索指数信息检索框架，虽然其能够生成文件标识符的排序列表，但在区分相关文档和随机文档方面表现不佳，研究人员提出了一种多任务蒸馏方法以提高其检索质量。

    

    可微分搜索指数（DSI）是一种新颖的信息检索框架，利用可微分函数对给定查询生成一个文件标识符的排序列表。然而，由于端到端神经架构的黑盒特性，仍需了解DSI具备基本索引和检索能力的程度。为了弥补这一差距，在本研究中，我们定义并检验了一个有效的IR框架应具备的三个重要能力，即排他性、完整性和相关性排序。我们的分析实验证明，虽然DSI在记忆从伪查询到文档标识符的单向映射方面表现出熟练程度，但在区分相关文档和随机文档方面效果不佳，从而对其检索效果产生负面影响。为了解决这个问题，我们提出了一种多任务蒸馏方法，以提高检索质量而不改变结构。

    The Differentiable Search Index (DSI) is a novel information retrieval (IR) framework that utilizes a differentiable function to generate a sorted list of document identifiers in response to a given query. However, due to the black-box nature of the end-to-end neural architecture, it remains to be understood to what extent DSI possesses the basic indexing and retrieval abilities. To mitigate this gap, in this study, we define and examine three important abilities that a functioning IR framework should possess, namely, exclusivity, completeness, and relevance ordering. Our analytical experimentation shows that while DSI demonstrates proficiency in memorizing the unidirectional mapping from pseudo queries to document identifiers, it falls short in distinguishing relevant documents from random ones, thereby negatively impacting its retrieval effectiveness. To address this issue, we propose a multi-task distillation approach to enhance the retrieval quality without altering the structure o
    
[^16]: AdaMS: 自适应边界和自适应尺度的深度度量学习在声学单词辨别上的应用

    AdaMS: Deep Metric Learning with Adaptive Margin and Adaptive Scale for Acoustic Word Discrimination. (arXiv:2210.14564v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.14564](http://arxiv.org/abs/2210.14564)

    本研究提出了一种自适应边界和自适应尺度的深度度量学习方法AdaMS，通过使用可学习参数替换超参数来有效地提高声学单词辨别的性能。

    

    近年来，深度度量学习中的许多损失函数采用对数和指数形式，需要使用边界和尺度等超参数。由于每个数据类都具有固有特征，因此先前的一些工作尝试通过引入自适应边界来学习接近真实分布的嵌入空间。然而，先前没有关于自适应尺度的研究。本文认为在训练过程中应该自适应地调整边界和尺度。我们提出了一种称为AdaMS的方法，其中边界和尺度的超参数被替换为每个类的自适应边界和自适应尺度的可学习参数。我们在华尔街日报数据集上评估了我们的方法，并在单词识别任务上取得了表现更好的结果。

    Many recent loss functions in deep metric learning are expressed with logarithmic and exponential forms, and they involve margin and scale as essential hyper-parameters. Since each data class has an intrinsic characteristic, several previous works have tried to learn embedding space close to the real distribution by introducing adaptive margins. However, there was no work on adaptive scales at all. We argue that both margin and scale should be adaptively adjustable during the training. In this paper, we propose a method called Adaptive Margin and Scale (AdaMS), where hyper-parameters of margin and scale are replaced with learnable parameters of adaptive margins and adaptive scales for each class. Our method is evaluated on Wall Street Journal dataset, and we achieve outperforming results for word discrimination tasks.
    
[^17]: 光轻混合召回器的效率和泛化性能研究

    A Study on the Efficiency and Generalization of Light Hybrid Retrievers. (arXiv:2210.01371v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.01371](http://arxiv.org/abs/2210.01371)

    本文研究了光轻混合召回器的效率和泛化性能，提出了一种采用索引高效的密集召回器和LITE召回器相结合的方法，相对于传统方法可以节省内存。实验证明，该方法可以在不牺牲性能的情况下显著提高模型的泛化性能。

    

    混合召回器可以充分利用稀疏和密集召回器的优点。以前的混合召回器利用索引密集的密集召回器。在本研究中，我们研究“是否可以在不牺牲性能的情况下减少混合召回器的索引内存”？受此问题驱动，我们利用一种索引高效的密集召回器（即DrBoost），并引入LITE召回器进一步减少DrBoost的内存。LITE同时通过对比学习和知识蒸馏来进行联合训练，并将BM25稀疏召回器与LITE或DrBoost相结合形成轻混合召回器。我们的Hybrid-LITE召回器在保持BM25和DPR混合召回器98.0％的性能的同时节省了13倍的内存。此外，我们研究了我们的轻混合召回器在域外数据集和一组对抗性攻击数据集上的泛化容量。实验表明，轻混合召回器的泛化性能优于单个召回器。

    Hybrid retrievers can take advantage of both sparse and dense retrievers. Previous hybrid retrievers leverage indexing-heavy dense retrievers. In this work, we study "Is it possible to reduce the indexing memory of hybrid retrievers without sacrificing performance"? Driven by this question, we leverage an indexing-efficient dense retriever (i.e. DrBoost) and introduce a LITE retriever that further reduces the memory of DrBoost. LITE is jointly trained on contrastive learning and knowledge distillation from DrBoost. Then, we integrate BM25, a sparse retriever, with either LITE or DrBoost to form light hybrid retrievers. Our Hybrid-LITE retriever saves 13X memory while maintaining 98.0% performance of the hybrid retriever of BM25 and DPR. In addition, we study the generalization capacity of our light hybrid retrievers on out-of-domain dataset and a set of adversarial attacks datasets. Experiments showcase that light hybrid retrievers achieve better generalization performance than individ
    
[^18]: 因果感知的可解释推荐系统的对比反事实学习

    Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems. (arXiv:2208.06746v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2208.06746](http://arxiv.org/abs/2208.06746)

    本文提出了一种因果感知的推荐系统方法，使用对比反事实学习来学习鲁棒且可解释的推荐系统，利用反事实推理来估计推荐的因果效应，并确定有助于用户行为的关键因素。

    

    最近在因果推断框架下生成推荐的研究有所增加，推荐被视为一种处理，旨在加强我们对推荐如何影响用户行为的理解，并允许确定有助于该影响的因素。许多因果推断领域的研究人员专注于使用倾向分数，这可以减少偏差，但可能会引入额外的差异。其他研究则提出使用随机对照试验中的无偏数据，不过这种方法需要满足一定的假设，这在实践中可能难以满足。本文首先探讨了推荐的因果感知解释，并表明底层的暴露机制可以偏向于最大似然估计（MLE）的观测反馈。鉴于混淆因素可能无法测量，我们提出使用对比S对反事实学习（CCL）来学习鲁棒且可解释的推荐系统。我们的方法使用反事实推理来估计推荐的因果效应，并确定有助于用户行为的关键因素。我们在几个真实数据集上进行实验，证明了我们的方法在准确性和可解释性方面优于现有方法。

    There has been a recent surge in the study of generating recommendations within the framework of causal inference, with the recommendation being treated as a treatment. This approach enhances our understanding of how recommendations influence user behaviour and allows for identification of the factors that contribute to this impact. Many researchers in the field of causal inference for recommender systems have focused on using propensity scores, which can reduce bias but may also introduce additional variance. Other studies have proposed the use of unbiased data from randomized controlled trials, though this approach requires certain assumptions that may be difficult to satisfy in practice. In this paper, we first explore the causality-aware interpretation of recommendations and show that the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Given that confounders may be inaccessible for measurement, we propose using contrastive S
    

