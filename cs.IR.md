# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Data-efficient Fine-tuning for LLM-based Recommendation](https://arxiv.org/abs/2401.17197) | 本论文中介绍了基于LLM的推荐中的数据高效微调的方法，通过剪枝数据来减少LLM的微调成本，并提出了两种目标来实现高准确性的数据剪枝。 |
| [^2] | [Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning](https://arxiv.org/abs/2401.17186) | 本论文提出了一种通过持续语言学习来扩展视觉-语言预训练模型（VL-PTMs）的语言能力的方法。该方法通过增量更新语言知识，避免灾难性遗忘，并在跨模态和跨语言目标下进行优化。 |
| [^3] | [The Influence of Presentation and Performance on User Satisfaction.](http://arxiv.org/abs/2401.17100) | 这项研究探讨了用户满意度、信息检索性能指标和演示之间的关系，通过对无线新闻搜索界面的不同结果卡布局的有效性进行实证分析，结果表明演示和表现对于用户满意度的影响密切相关。 |
| [^4] | [Re3val: Reinforced and Reranked Generative Retrieval.](http://arxiv.org/abs/2401.16979) | Re3val是一个使用强化学习和重新排名技术进行训练的生成检索模型，它通过利用上下文信息来重新排名检索得到的页面标题，以最大化通过受限解码生成的奖励。同时，该模型通过生成问题来减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。 |
| [^5] | [Taxonomy of Mathematical Plagiarism.](http://arxiv.org/abs/2401.16969) | 本论文建立了数学内容重用的分类法，并分析了剽窃检测和数学内容相似性的最佳方法。研究发现，目前最佳方法在剽窃和数学内容相似性方面的表现依然不理想。这些发现将为剽窃检测系统、推荐系统和问答系统等领域的研究提供帮助。 |
| [^6] | [Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?.](http://arxiv.org/abs/2401.16807) | 这项研究评估了四种先进的文本检测器对LLM辅助写作的表现，发现它们的性能不如一个简单的检测器。研究认为需要开发专门用于LLM辅助写作的特定检测器，以解决当前承认实践中的挑战。 |
| [^7] | [AutoIE: An Automated Framework for Information Extraction from Scientific Literature.](http://arxiv.org/abs/2401.16672) | AutoIE是一个自动提取科学文献信息的创新框架，集成了多个关键组件，包括PDF文档布局分析、科学文本功能块识别、分子筛合成信息提取和在线学习等，具有高效提取关键数据的能力。应用于石化领域的实践证明了其有效性。 |
| [^8] | [History-Aware Conversational Dense Retrieval.](http://arxiv.org/abs/2401.16659) | 该论文提出了一种历史感知的对话式稠密检索系统，通过上下文去噪的查询重构以及根据历史轮次的实际影响自动挖掘监督信号改进了现有的对话式稠密检索方法。 |
| [^9] | [FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War.](http://arxiv.org/abs/2401.16625) | FakeClaim数据集是首个公开可用的用于自动识别2023年以色列哈马斯战争中假新闻的数据集，包含了来自不同平台的事实性主张和假YouTube视频。通过使用预训练的语言模型，该研究展示了使用用户评论可以帮助辟谣假视频的潜力。 |
| [^10] | [Dissecting users' needs for search result explanations.](http://arxiv.org/abs/2401.16509) | 该论文研究了用户对搜索结果解释的需求，发现用户不总是寻求解释，但对于复杂和关键的任务，解释是有益处的。该研究还总结了有益的解释的关键特征，并提出了对搜索引擎和解释的设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。 |
| [^11] | [Towards Regret Free Slot Allocation in Billboard Advertisement.](http://arxiv.org/abs/2401.16464) | 本文提出了一种无遗憾的广告牌广告时段分配方法，旨在最大化广告商与顾客之间的影响力，并通过四种高效的解决方案来减少遗憾的发生。 |
| [^12] | [KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants.](http://arxiv.org/abs/2401.16454) | KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。 |
| [^13] | [Within-basket Recommendation via Neural Pattern Associator.](http://arxiv.org/abs/2401.16433) | 本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。 |
| [^14] | [Improving conversion rate prediction via self-supervised pre-training in online advertising.](http://arxiv.org/abs/2401.16432) | 这项研究通过自监督预训练方法，改进了在线广告系统中的转化率预测。由于数据稀疏性的挑战，添加非点击归因的转化会损坏模型的校准，而自监督预训练能够解决这个问题。 |
| [^15] | [An Information Retrieval and Extraction Tool for Covid-19 Related Papers.](http://arxiv.org/abs/2401.16430) | 该论文开发了一个集信息检索和提取于一体的工具，应用于COVID-19 Open Research Dataset (CORD-19)。主要目的是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。 |
| [^16] | [Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life.](http://arxiv.org/abs/2401.16429) | 本文研究了结合主题建模和引用网络分析的方法，用来研究欧洲人权法院关于尊重私密和家庭生活的案例法。通过这种方法，可以找到和组织具有相似主题和引用模式的案例法，并且通过结合这两种技术能够得到更好的结果。 |
| [^17] | [Mitigating Position Bias with Regularization for Recommender Systems.](http://arxiv.org/abs/2401.16427) | 本研究提出了通过正则化技术减轻推荐系统中的位置偏差问题，实验证明该方法优于其他现代算法。 |
| [^18] | [Location Sensitive Embedding for Knowledge Graph Embedding.](http://arxiv.org/abs/2401.10893) | 这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。 |
| [^19] | [Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency.](http://arxiv.org/abs/2401.10545) | 该研究揭示了基于ChatGPT的推荐系统的偏见问题，并研究了提示设计策略对推荐质量的影响。实验结果显示，在RecLLMs中引入特定的系统角色和提示策略可以增强推荐的公平性和多样性，同时GPT-based模型倾向于推荐最新和更多样化的电影流派。 |
| [^20] | [Towards Differential Privacy in Sequential Recommendation: A Noisy Graph Neural Network Approach.](http://arxiv.org/abs/2309.11515) | 这项工作提出了一种新颖的差分隐私顺序推荐框架，采用了噪声图神经网络方法，解决了现有差分隐私推荐系统在动态和依赖关系方面的局限性，同时也关注了敏感用户特征的隐私风险。 |
| [^21] | [Ambiguity-Aware In-Context Learning with Large Language Models.](http://arxiv.org/abs/2309.07900) | 在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。 |
| [^22] | [Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations.](http://arxiv.org/abs/2308.16505) | 本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。 |
| [^23] | [TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems.](http://arxiv.org/abs/2308.14355) | TransGNN是一种将Transformer和GNN层交替结合以相互增强其能力的新型模型，用于解决当前基于GNN的推荐系统面临的感受域有限和存在噪音连接的挑战。 |
| [^24] | [SSLRec: A Self-Supervised Learning Library for Recommendation.](http://arxiv.org/abs/2308.05697) | SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。 |
| [^25] | [FedPDD: A Privacy-preserving Double Distillation Framework for Cross-silo Federated Recommendation.](http://arxiv.org/abs/2305.06272) | 本文提出了一个名为FedPDD的隐私保护双重蒸馏框架，用于跨平台联邦推荐。该框架包括教师蒸馏和学生蒸馏两个阶段，在不传输模型信息的情况下，通过有效地转移知识和使用一种新的蒸馏损失函数来构建全局模型，实现了最先进的性能。 |

# 详细

[^1]: 基于LLM的推荐的数据高效微调

    Data-efficient Fine-tuning for LLM-based Recommendation

    [https://arxiv.org/abs/2401.17197](https://arxiv.org/abs/2401.17197)

    本论文中介绍了基于LLM的推荐中的数据高效微调的方法，通过剪枝数据来减少LLM的微调成本，并提出了两种目标来实现高准确性的数据剪枝。

    

    近年来，利用大型语言模型（LLM）进行推荐引起了广泛关注，其中微调在LLM的适应中起着关键作用。然而，快速扩展的推荐数据上微调LLM的成本限制了它们的实际应用。为了解决这一挑战，少样本微调提供了一种快速适应LLM到新的推荐数据的方法。我们提出了为高效的LLM推荐任务剪枝数据的任务，旨在找到适合LLM的少样本微调的代表样本。虽然核心集选择与所提出的任务密切相关，但现有的核心集选择方法往往依赖于次优启发式指标或需要在大规模推荐数据上进行昂贵的优化。

    Leveraging Large Language Models (LLMs) for recommendation has recently garnered considerable attention, where fine-tuning plays a key role in LLMs' adaptation. However, the cost of fine-tuning LLMs on rapidly expanding recommendation data limits their practical application. To address this challenge, few-shot fine-tuning offers a promising approach to quickly adapt LLMs to new recommendation data. We propose the task of data pruning for efficient LLM-based recommendation, aimed at identifying representative samples tailored for LLMs' few-shot fine-tuning. While coreset selection is closely related to the proposed task, existing coreset selection methods often rely on suboptimal heuristic metrics or entail costly optimization on large-scale recommendation data.   To tackle these issues, we introduce two objectives for the data pruning task in the context of LLM-based recommendation: 1) high accuracy aims to identify the influential samples that can lead to high overall performance; and
    
[^2]: 在CLIP中拥抱语言包容性和多样性：通过持续语言学习

    Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning

    [https://arxiv.org/abs/2401.17186](https://arxiv.org/abs/2401.17186)

    本论文提出了一种通过持续语言学习来扩展视觉-语言预训练模型（VL-PTMs）的语言能力的方法。该方法通过增量更新语言知识，避免灾难性遗忘，并在跨模态和跨语言目标下进行优化。

    

    近年来，视觉-语言预训练模型(VL-PTMs)在多模态研究方面取得了进展，但由于只掌握了少数几种语言（比如英语），限制了其在更广泛的社区中的适用性。为了解决这个问题，人们越来越关注通过联合学习来开发多语言VL模型，然而，由于昂贵的成本和数据可用性，这种方法可能不切实际。在这项工作中，我们提出通过持续语言学习（CLL）来扩展VL-PTMs的语言能力，即模型需要增量地更新其语言知识，同时避免灾难性遗忘（CF）。我们首先介绍了一个名为CLL-CLIP的模型，它是在CLIP的基础上构建的，而CLIP是一种已经具备了图像-英语文本对齐能力的流行VL-PTM。具体而言，CLL-CLIP包含了一个可扩展的词嵌入层，用于处理语言差异。它仅训练词嵌入以提高内存稳定性，并在跨模态和跨语言目标下进行优化。

    While vision-language pre-trained models (VL-PTMs) have advanced multimodal research in recent years, their mastery in a few languages like English restricts their applicability in broader communities. To this end, there is an increasing interest in developing multilingual VL models via a joint-learning setup, which, however, could be unrealistic due to expensive costs and data availability. In this work, we propose to extend VL-PTMs' language capacity by continual language learning (CLL), where a model needs to update its linguistic knowledge incrementally without suffering from catastrophic forgetting (CF). We begin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP, a prevailing VL-PTM that has acquired image-English text alignment. Specifically, CLL-CLIP contains an expandable token embedding layer to handle linguistic differences. It solely trains token embeddings to improve memory stability and is optimized under cross-modal and cross-lingual objectives to l
    
[^3]: 演示和表现对用户满意度的影响

    The Influence of Presentation and Performance on User Satisfaction. (arXiv:2401.17100v1 [cs.HC])

    [http://arxiv.org/abs/2401.17100](http://arxiv.org/abs/2401.17100)

    这项研究探讨了用户满意度、信息检索性能指标和演示之间的关系，通过对无线新闻搜索界面的不同结果卡布局的有效性进行实证分析，结果表明演示和表现对于用户满意度的影响密切相关。

    

    评估信息检索系统的有效性不仅仅取决于其检索相关结果的能力，还取决于它如何向用户呈现这些结果；引人入胜的演示通常与增加用户满意度相关。尽管现有研究已经探讨了用户满意度、信息检索性能指标和演示之间的关联，但这些方面通常是孤立地进行研究的。我们的研究旨在探讨查询性能、演示和用户满意度之间的关系。为了进行分析，我们进行了一项介于受试组之间的实验，比较了无线内新闻搜索界面的各种结果卡布局的有效性。我们从TREC WaPo 2018收集了数据，在四个特定主题上进行了研究。在这些主题的每一个中，我们评估了具有不同nDCG值的六个不同查询。我们的研究涉及164名参与者，他们接触到了五种不同的包含结果卡的布局，例如“标题”

    The effectiveness of an IR system is gauged not just by its ability to retrieve relevant results but also by how it presents these results to users; an engaging presentation often correlates with increased user satisfaction. While existing research has delved into the link between user satisfaction, IR performance metrics, and presentation, these aspects have typically been investigated in isolation. Our research aims to bridge this gap by examining the relationship between query performance, presentation and user satisfaction. For our analysis, we conducted a between-subjects experiment comparing the effectiveness of various result card layouts for an ad-hoc news search interface. Drawing data from the TREC WaPo 2018 collection, we centered our study on four specific topics. Within each of these topics, we assessed six distinct queries with varying nDCG values. Our study involved 164 participants who were exposed to one of five distinct layouts containing result cards, such as "title'
    
[^4]: Re3val: 强化和重新排名的生成检索

    Re3val: Reinforced and Reranked Generative Retrieval. (arXiv:2401.16979v1 [cs.IR])

    [http://arxiv.org/abs/2401.16979](http://arxiv.org/abs/2401.16979)

    Re3val是一个使用强化学习和重新排名技术进行训练的生成检索模型，它通过利用上下文信息来重新排名检索得到的页面标题，以最大化通过受限解码生成的奖励。同时，该模型通过生成问题来减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。

    

    生成检索模型将文档中的信息指针编码为模型参数中的索引。这些模型作为更大的流程的一部分，通过检索的信息来为知识密集型自然语言处理任务生成条件。然而，我们发现有两个限制：生成检索没有考虑上下文信息。其次，检索无法为下游读者进行调整，因为解码页面标题是一个非可微分的操作。本文介绍了经过有限数据训练的生成重新排名和强化学习的 Re3val。Re3val利用通过密集通道检索获得的上下文对已检索页面标题进行重新排名，并利用REINFORCE算法最大化受限解码生成的奖励。此外，我们从预训练数据集中生成问题，以减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。随后，我们从中提取和重新排名上下文信息。

    Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from th
    
[^5]: 数学剽窃分类法

    Taxonomy of Mathematical Plagiarism. (arXiv:2401.16969v1 [cs.IR])

    [http://arxiv.org/abs/2401.16969](http://arxiv.org/abs/2401.16969)

    本论文建立了数学内容重用的分类法，并分析了剽窃检测和数学内容相似性的最佳方法。研究发现，目前最佳方法在剽窃和数学内容相似性方面的表现依然不理想。这些发现将为剽窃检测系统、推荐系统和问答系统等领域的研究提供帮助。

    

    剽窃问题是一个紧迫的关注点，尤其是在大型语言模型的可用性下更为突出。现有的剽窃检测系统可以可靠地找到复制和适度改写的文本，但在数学科学中的思想剽窃方面表现不佳，因为数学科学中使用了严格的数学符号。我们做出了两个贡献。首先，我们通过对可能存在剽窃的122个科学文档进行注释，建立了数学内容重用的分类法。其次，我们对刚刚建立的分类法上最佳表现的剽窃检测方法和数学内容相似性进行了分析。我们发现，对于剽窃和数学内容相似性，表现最佳的方法分别达到了0.06和0.16的整体检测分数（PlagDet）。这些最佳方法未能检测出七种新建立的数学相似性类型中的大部分案例。我们的贡献将有助于剽窃检测系统、推荐系统、问答系统和其他相关研究的发展。

    Plagiarism is a pressing concern, even more so with the availability of large language models. Existing plagiarism detection systems reliably find copied and moderately reworded text but fail for idea plagiarism, especially in mathematical science, which heavily uses formal mathematical notation. We make two contributions. First, we establish a taxonomy of mathematical content reuse by annotating potentially plagiarised 122 scientific document pairs. Second, we analyze the best-performing approaches to detect plagiarism and mathematical content similarity on the newly established taxonomy. We found that the best-performing methods for plagiarism and math content similarity achieve an overall detection score (PlagDet) of 0.06 and 0.16, respectively. The best-performing methods failed to detect most cases from all seven newly established math similarity types. Outlined contributions will benefit research in plagiarism detection systems, recommender systems, question-answering systems, an
    
[^6]: 在科学交流中检测LLM辅助写作：我们已经到达了吗？

    Detecting LLM-Assisted Writing in Scientific Communication: Are We There Yet?. (arXiv:2401.16807v1 [cs.IR])

    [http://arxiv.org/abs/2401.16807](http://arxiv.org/abs/2401.16807)

    这项研究评估了四种先进的文本检测器对LLM辅助写作的表现，发现它们的性能不如一个简单的检测器。研究认为需要开发专门用于LLM辅助写作的特定检测器，以解决当前承认实践中的挑战。

    

    大型语言模型（LLMs），如ChatGPT，在文本生成方面产生了重大影响，尤其是在写作辅助领域。尽管伦理考虑强调了在科学交流中透明地承认LLM的使用的重要性，但真实的承认仍然很少见。鼓励准确承认LLM辅助写作的一个潜在途径涉及使用自动检测器。我们对四个前沿的LLM生成文本检测器进行了评估，发现它们的性能不如一个简单的临时检测器，该检测器设计用于识别在LLM大量出现时的突然写作风格变化。我们认为，开发专门用于LLM辅助写作检测的专用检测器是必要的。这样的检测器可以在促进对LLM参与科学交流的更真实认可、解决当前承认实践中的挑战方面发挥关键作用。

    Large Language Models (LLMs), exemplified by ChatGPT, have significantly reshaped text generation, particularly in the realm of writing assistance. While ethical considerations underscore the importance of transparently acknowledging LLM use, especially in scientific communication, genuine acknowledgment remains infrequent. A potential avenue to encourage accurate acknowledging of LLM-assisted writing involves employing automated detectors. Our evaluation of four cutting-edge LLM-generated text detectors reveals their suboptimal performance compared to a simple ad-hoc detector designed to identify abrupt writing style changes around the time of LLM proliferation. We contend that the development of specialized detectors exclusively dedicated to LLM-assisted writing detection is necessary. Such detectors could play a crucial role in fostering more authentic recognition of LLM involvement in scientific communication, addressing the current challenges in acknowledgment practices.
    
[^7]: AutoIE：一种从科学文献中自动提取信息的框架

    AutoIE: An Automated Framework for Information Extraction from Scientific Literature. (arXiv:2401.16672v1 [cs.IR])

    [http://arxiv.org/abs/2401.16672](http://arxiv.org/abs/2401.16672)

    AutoIE是一个自动提取科学文献信息的创新框架，集成了多个关键组件，包括PDF文档布局分析、科学文本功能块识别、分子筛合成信息提取和在线学习等，具有高效提取关键数据的能力。应用于石化领域的实践证明了其有效性。

    

    在快速发展的科学研究领域中，高效地从大量科学论文中提取关键信息仍然是一个巨大的挑战。本文介绍了一个创新框架，旨在自动提取科学PDF文档中的重要数据，使研究人员更容易辨别未来的研究方向。AutoIE独特地集成了四个创新组件：（1）基于多语义特征融合的PDF文档布局分析方法；（2）科学文本中的高级功能块识别；（3）一种针对分子筛合成的信息提取和相关性的协同技术；（4）针对分子筛文献量身定制的在线学习范式。我们的SBERT模型在CoNLL04和ADE数据集上实现了高达87.19和89.65的Marco F1分数。此外，将AutoIE应用于石化领域的分子筛合成实践证明了其有效性，通过惊人的78%的...

    In the rapidly evolving field of scientific research, efficiently extracting key information from the burgeoning volume of scientific papers remains a formidable challenge. This paper introduces an innovative framework designed to automate the extraction of vital data from scientific PDF documents, enabling researchers to discern future research trajectories more readily. AutoIE uniquely integrates four novel components: (1) A multi-semantic feature fusion-based approach for PDF document layout analysis; (2) Advanced functional block recognition in scientific texts; (3) A synergistic technique for extracting and correlating information on molecular sieve synthesis; (4) An online learning paradigm tailored for molecular sieve literature. Our SBERT model achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE datasets. In addition, a practical application of AutoIE in the petrochemical molecular sieve synthesis domain demonstrates its efficacy, evidenced by an impressive 78\%
    
[^8]: 历史感知的对话式稠密检索

    History-Aware Conversational Dense Retrieval. (arXiv:2401.16659v1 [cs.IR])

    [http://arxiv.org/abs/2401.16659](http://arxiv.org/abs/2401.16659)

    该论文提出了一种历史感知的对话式稠密检索系统，通过上下文去噪的查询重构以及根据历史轮次的实际影响自动挖掘监督信号改进了现有的对话式稠密检索方法。

    

    对话搜索通过实现用户和系统之间的多轮交互，实现了复杂信息检索的便利。支持这种交互需要对对话输入有全面的理解，以便根据历史信息制定良好的搜索查询。特别是，搜索查询应包括来自先前对话回合的相关信息。然而，目前的对话式稠密检索方法主要依赖于对经过精调的预训练专门检索器进行整个对话式搜索会话的优化，这可能会变得冗长和嘈杂。此外，现有方法受现有数据集中手动监督信号数量的限制。为了解决上述问题，我们提出了一种历史感知的对话式稠密检索(HAConvDR)系统，它结合了两个思想：上下文去噪的查询重构和根据历史轮次的实际影响进行自动挖掘监督信号。

    Conversational search facilitates complex information retrieval by enabling multi-turn interactions between users and the system. Supporting such interactions requires a comprehensive understanding of the conversational inputs to formulate a good search query based on historical information. In particular, the search query should include the relevant information from the previous conversation turns. However, current approaches for conversational dense retrieval primarily rely on fine-tuning a pre-trained ad-hoc retriever using the whole conversational search session, which can be lengthy and noisy. Moreover, existing approaches are limited by the amount of manual supervision signals in the existing datasets. To address the aforementioned issues, we propose a History-Aware Conversational Dense Retrieval (HAConvDR) system, which incorporates two ideas: context-denoised query reformulation and automatic mining of supervision signals based on the actual impact of historical turns. Experime
    
[^9]: FakeClaim: 2023年以色列哈马斯战争中的假新闻识别的多平台驱动数据集

    FakeClaim: A Multiple Platform-driven Dataset for Identification of Fake News on 2023 Israel-Hamas War. (arXiv:2401.16625v1 [cs.IR])

    [http://arxiv.org/abs/2401.16625](http://arxiv.org/abs/2401.16625)

    FakeClaim数据集是首个公开可用的用于自动识别2023年以色列哈马斯战争中假新闻的数据集，包含了来自不同平台的事实性主张和假YouTube视频。通过使用预训练的语言模型，该研究展示了使用用户评论可以帮助辟谣假视频的潜力。

    

    我们提供了首个公开可用的来自不同平台的事实性主张和2023年以色列哈马斯战争的假YouTube视频数据集，用于自动识别假YouTube视频。FakeClaim数据集是从60个事实核查机构、30种语言中收集的，并通过训练有素的事实核查专业记者维护的事实核查机构元数据进行丰富。此外，我们使用文本信息和用户评论对YouTube视频子集中的假视频进行分类。我们使用了预训练模型来使用不同的特征组合对每个视频进行分类。我们表现最佳的微调语言模型，即Universal Sentence Encoder (USE)，达到了87\%的宏F1，这表明训练模型可以通过用户讨论中的评论帮助揭穿假视频。该数据集可在Github上找到。

    We contribute the first publicly available dataset of factual claims from different platforms and fake YouTube videos on the 2023 Israel-Hamas war for automatic fake YouTube video classification. The FakeClaim data is collected from 60 fact-checking organizations in 30 languages and enriched with metadata from the fact-checking organizations curated by trained journalists specialized in fact-checking. Further, we classify fake videos within the subset of YouTube videos using textual information and user comments. We used a pre-trained model to classify each video with different feature combinations. Our best-performing fine-tuned language model, Universal Sentence Encoder (USE), achieves a Macro F1 of 87\%, which shows that the trained model can be helpful for debunking fake videos using the comments from the user discussion. The dataset is available on Github\footnote{https://github.com/Gautamshahi/FakeClaim}
    
[^10]: 揭示用户对搜索结果解释的需求

    Dissecting users' needs for search result explanations. (arXiv:2401.16509v1 [cs.HC])

    [http://arxiv.org/abs/2401.16509](http://arxiv.org/abs/2401.16509)

    该论文研究了用户对搜索结果解释的需求，发现用户不总是寻求解释，但对于复杂和关键的任务，解释是有益处的。该研究还总结了有益的解释的关键特征，并提出了对搜索引擎和解释的设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。

    

    对于搜索引擎如何解释搜索结果的问题，已有研究假设解释会有益处，并引入了搜索结果解释。然而，我们的研究从根本上考虑了搜索解释是否需要以及何时会有益处。此外，我们总结了有益的解释的关键特征，并分享了用户对Google和Bing提供的解释功能的看法。对非技术人员的访谈显示，用户并不总是寻求或理解搜索解释，但对于复杂和关键的任务，他们觉得解释有帮助。他们认为Google的搜索解释太明显，但赞赏能够质疑搜索结果的能力。根据我们的研究结果，我们提供了设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。

    There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on how to explain, assuming explanations are beneficial. Our study takes a step back to examine if search explanations are needed and when they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.
    
[^11]: 实现无遗憾的广告牌广告时段分配

    Towards Regret Free Slot Allocation in Billboard Advertisement. (arXiv:2401.16464v1 [cs.IR])

    [http://arxiv.org/abs/2401.16464](http://arxiv.org/abs/2401.16464)

    本文提出了一种无遗憾的广告牌广告时段分配方法，旨在最大化广告商与顾客之间的影响力，并通过四种高效的解决方案来减少遗憾的发生。

    

    在广告牌广告中，为了创造和最大化对顾客的影响力，广告商需要找到具有一定影响力的人提供一定数量的广告播放，并基于观看数量收费。本文针对广告播放者，提出了一种解决该问题的离散优化方法，并通过四种高效的解决方案分析了它们的时间和空间复杂性。最终目标是最小化决策带来的损失（遗憾）。

    Creating and maximizing influence among the customers is one of the central goals of an advertiser, and hence, remains an active area of research in recent times. In this advertisement technique, the advertisers approach an influence provider for a specific number of views of their content on a payment basis. Now, if the influence provider can provide the required number of views or more, he will receive the full, else a partial payment. In the context of an influence provider, it is a loss for him if he offers more or less views. This is formalized as 'Regret', and naturally, in the context of the influence provider, the goal will be to minimize this quantity. In this paper, we solve this problem in the context of billboard advertisement and pose it as a discrete optimization problem. We propose four efficient solution approaches for this problem and analyze them to understand their time and space complexity. We implement all the solution methodologies with real-life datasets and comp
    
[^12]: KAUCUS: 知识增强用户模拟器用于训练语言模型助手

    KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants. (arXiv:2401.16454v1 [cs.HC])

    [http://arxiv.org/abs/2401.16454](http://arxiv.org/abs/2401.16454)

    KAUCUS引入了知识增强用户模拟器框架，可以生成多样化的模拟器助手交互，并能够快速引入外部知识，从而提高语言模型助手的训练效果。

    

    通过创建一个能够生成有用交互数据的模拟器，可以开发出一个有效的多轮指令跟随助手。理想的用户模拟器除了依靠其内在权重外，还应能够快速引入外部知识来模拟互联网上多样化的文本。以往的用户模拟器通常缺乏多样性，主要是封闭领域的，并且需要严格的模式，使得它们无法快速扩展以融入外部知识。在这方面，我们介绍了一个名为Kaucus的知识增强用户模拟器框架，以概述创建多样化用户模拟器的过程，并能够无缝地利用外部知识，同时受益于下游助手模型的训练。通过两个基于GPT-J的模拟器，即检索增强模拟器和摘要控制模拟器，我们生成多样化的模拟器助手交互。

    An effective multi-turn instruction-following assistant can be developed by creating a simulator that can generate useful interaction data. Apart from relying on its intrinsic weights, an ideal user simulator should also be able to bootstrap external knowledge rapidly in its raw form to simulate the multifarious diversity of text available over the internet. Previous user simulators generally lacked diversity, were mostly closed domain, and necessitated rigid schema making them inefficient to rapidly scale to incorporate external knowledge. In this regard, we introduce, Kaucus, a Knowledge-Augmented User Simulator framework, to outline a process of creating diverse user simulators, that can seamlessly exploit external knowledge as well as benefit downstream assistant model training. Through two GPT-J based simulators viz., a Retrieval Augmented Simulator and a Summary Controlled Simulator we generate diverse simulator-assistant interactions. Through reward and preference model-based ev
    
[^13]: 通过神经模式关联器进行篮内推荐

    Within-basket Recommendation via Neural Pattern Associator. (arXiv:2401.16433v1 [cs.IR])

    [http://arxiv.org/abs/2401.16433](http://arxiv.org/abs/2401.16433)

    本文介绍了一种称为神经模式关联器（NPA）的深度商品关联挖掘模型，该模型能够明确地建模购物过程中的复杂用户行为，并通过注意力驱动的查找来识别用户的购物意图。

    

    篮内推荐（WBR）是指在购物过程中为了完成一个非空购物篮而推荐商品的任务。尽管这个领域的最新创新在基准数据集上表现出了显著的性能提升，但它们常常忽视了实际用户行为的复杂性，比如1）多个购物意图的共存，2）这些意图的多粒度和3）购物过程中的交织行为（切换意图）。本文提出了一种名为神经模式关联器（NPA）的深度商品关联挖掘模型，明确地建模了上述因素。具体来说，受到向量量化的启发，NPA模型学习将常见的用户意图（或商品组合模式）编码为量化表示（也称为码本），这允许在推理阶段通过注意力驱动的查找来识别用户的购物意图。这样产生的推荐结果连贯且自解释。

    Within-basket recommendation (WBR) refers to the task of recommending items to the end of completing a non-empty shopping basket during a shopping session. While the latest innovations in this space demonstrate remarkable performance improvement on benchmark datasets, they often overlook the complexity of user behaviors in practice, such as 1) co-existence of multiple shopping intentions, 2) multi-granularity of such intentions, and 3) interleaving behavior (switching intentions) in a shopping session. This paper presents Neural Pattern Associator (NPA), a deep item-association-mining model that explicitly models the aforementioned factors. Specifically, inspired by vector quantization, the NPA model learns to encode common user intentions (or item-combination patterns) as quantized representations (a.k.a. codebook), which permits identification of users's shopping intentions via attention-driven lookup during the reasoning phase. This yields coherent and self-interpretable recommendat
    
[^14]: 在在线广告中通过自监督预训练改进转化率预测

    Improving conversion rate prediction via self-supervised pre-training in online advertising. (arXiv:2401.16432v1 [cs.IR])

    [http://arxiv.org/abs/2401.16432](http://arxiv.org/abs/2401.16432)

    这项研究通过自监督预训练方法，改进了在线广告系统中的转化率预测。由于数据稀疏性的挑战，添加非点击归因的转化会损坏模型的校准，而自监督预训练能够解决这个问题。

    

    预测转化率是在线广告系统中优化投标以满足广告主性能要求的关键任务。尽管深度神经网络的崛起，但这些预测通常由分解机（FM）进行，特别是在推理延迟至关重要的商业环境中。这些模型使用逻辑回归框架训练，利用与任务相关的过去用户活动形成的标记表格数据。许多广告主只关心被点击属性的转化。预测给定点击的转化模型训练的主要挑战来自数据稀疏性 - 点击很少，点击归因的转化更少。然而，在训练集中添加非点击归因的转化来减轻稀疏性会损坏模型的校准。由于校准对实现广告主目标至关重要，这是不可行的。在这项工作中，我们使用了自监督预训练的众所周知的思想来解决这个问题。

    The task of predicting conversion rates (CVR) lies at the heart of online advertising systems aiming to optimize bids to meet advertiser performance requirements. Even with the recent rise of deep neural networks, these predictions are often made by factorization machines (FM), especially in commercial settings where inference latency is key. These models are trained using the logistic regression framework on labeled tabular data formed from past user activity that is relevant to the task at hand.  Many advertisers only care about click-attributed conversions. A major challenge in training models that predict conversions-given-clicks comes from data sparsity - clicks are rare, conversions attributed to clicks are even rarer. However, mitigating sparsity by adding conversions that are not click-attributed to the training set impairs model calibration. Since calibration is critical to achieving advertiser goals, this is infeasible.  In this work we use the well-known idea of self-supervi
    
[^15]: 一个针对Covid-19相关论文的信息检索和提取工具

    An Information Retrieval and Extraction Tool for Covid-19 Related Papers. (arXiv:2401.16430v1 [cs.IR])

    [http://arxiv.org/abs/2401.16430](http://arxiv.org/abs/2401.16430)

    该论文开发了一个集信息检索和提取于一体的工具，应用于COVID-19 Open Research Dataset (CORD-19)。主要目的是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。

    

    背景：COVID-19大流行对全球的卫生系统造成了严重影响。其严重性以及个人和组织开展对策研究的兴趣增加，导致科学期刊中出现了大量新的研究。目标：我们旨在开发一种将信息检索（IR）和提取（IE）的方面应用于COVID-19 Open Research Dataset（CORD-19）的新颖工具。本文的主要重点是为研究人员提供一个更好的COVID-19相关论文的搜索工具，帮助他们找到参考论文并突出显示文本中的相关实体。方法：我们应用隐含狄利克雷分配（LDA）来根据研究方面对CORD-19中所有英文摘要的主题进行建模。提取每个摘要的相关命名实体，并将其链接到相应的UMLS概念。使用正则表达式和K最近邻算法来对相关论文进行排名。结果：我们的工具已经实现了...

    Background: The COVID-19 pandemic has caused severe impacts on health systems worldwide. Its critical nature and the increased interest of individuals and organizations to develop countermeasures to the problem has led to a surge of new studies in scientific journals. Objetive: We sought to develop a tool that incorporates, in a novel way, aspects of Information Retrieval (IR) and Extraction (IE) applied to the COVID-19 Open Research Dataset (CORD-19). The main focus of this paper is to provide researchers with a better search tool for COVID-19 related papers, helping them find reference papers and hightlight relevant entities in text. Method: We applied Latent Dirichlet Allocation (LDA) to model, based on research aspects, the topics of all English abstracts in CORD-19. Relevant named entities of each abstract were extracted and linked to the corresponding UMLS concept. Regular expressions and the K-Nearest Neighbors algorithm were used to rank relevant papers. Results: Our tool has s
    
[^16]: 结合主题建模和引用网络分析研究欧洲人权法院关于尊重私人和家庭生活权利的案例法

    Combining topic modelling and citation network analysis to study case law from the European Court on Human Rights on the right to respect for private and family life. (arXiv:2401.16429v1 [cs.IR])

    [http://arxiv.org/abs/2401.16429](http://arxiv.org/abs/2401.16429)

    本文研究了结合主题建模和引用网络分析的方法，用来研究欧洲人权法院关于尊重私密和家庭生活的案例法。通过这种方法，可以找到和组织具有相似主题和引用模式的案例法，并且通过结合这两种技术能够得到更好的结果。

    

    随着HUDOC等法律案例法数据库的快速增长，为了处理如此大规模的数据集，法律研究人员找到高效的方法变得至关重要。这种案例法数据库通常包含案件的文本内容以及它们之间的引用。本文重点研究了来自欧洲人权法院关于欧洲人权公约第8条关于尊重私人和家庭生活、家庭和通信权利的案例法。在本研究中，我们演示并比较了主题建模和引用网络在根据一般主题和引用模式找到和组织第8条案例法方面的潜力。另外，我们还探索了结合这两种技术是否比仅应用其中一种方法效果更好。我们在一组手工收集和注释的关于驱逐的第8条案例法独特数据集上评估了组合方法的有效性。我们的结果表明，结合使用这两种方法能够取得更好的效果。

    As legal case law databases such as HUDOC continue to grow rapidly, it has become essential for legal researchers to find efficient methods to handle such large-scale data sets. Such case law databases usually consist of the textual content of cases together with the citations between them. This paper focuses on case law from the European Court of Human Rights on Article 8 of the European Convention of Human Rights, the right to respect private and family life, home and correspondence. In this study, we demonstrate and compare the potential of topic modelling and citation network to find and organize case law on Article 8 based on their general themes and citation patterns, respectively. Additionally, we explore whether combining these two techniques leads to better results compared to the application of only one of the methods. We evaluate the effectiveness of the combined method on a unique manually collected and annotated dataset of Aricle 8 case law on evictions. The results of our
    
[^17]: 通过正则化减轻推荐系统中的位置偏差

    Mitigating Position Bias with Regularization for Recommender Systems. (arXiv:2401.16427v1 [cs.IR])

    [http://arxiv.org/abs/2401.16427](http://arxiv.org/abs/2401.16427)

    本研究提出了通过正则化技术减轻推荐系统中的位置偏差问题，实验证明该方法优于其他现代算法。

    

    公正性是近年来的研究热点。与公正性密切相关的研究课题是偏差和去偏差。在不同类型的偏差问题中，位置偏差是最常遇到的一种情况。位置偏差意味着推荐列表顶部的推荐项比相同列表底部的项更可能被点击。为了减轻这个问题，我们提出使用正则化技术减少偏差效应。在实验部分，我们证明我们的方法优于其他现代算法。

    Fairness is a popular research topic in recent years. A research topic closely related to fairness is bias and debiasing. Among different types of bias problems, position bias is one of the most widely encountered symptoms. Position bias means that recommended items on top of the recommendation list has a higher likelihood to be clicked than items on bottom of the same list. To mitigate this problem, we propose to use regularization technique to reduce the bias effect. In the experiment section, we prove that our method is superior to other modern algorithms.
    
[^18]: 知识图谱嵌入的位置敏感嵌入

    Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])

    [http://arxiv.org/abs/2401.10893](http://arxiv.org/abs/2401.10893)

    这篇论文介绍了一种新颖的位置敏感嵌入（LSE）方法，该方法通过关系特定的映射来修改头实体，将关系概念化为线性变换。LSE在知识图谱嵌入领域具有理论基础，同时提出了更高效的变体LSEd。实验证明LSEd在链接预测任务上具有竞争力。

    

    知识图谱嵌入将知识图谱转化为连续的、低维度的空间，有助于推理和补全任务。该领域主要分为传统的距离模型和语义匹配模型。传统的距离模型面临的关键挑战是无法有效区分图谱中的“头实体”和“尾实体”。为了解决这个问题，提出了新颖的位置敏感嵌入（LSE）方法。LSE通过关系特定的映射修改头实体，将关系概念化为线性变换而不仅仅是平移。LSE的理论基础，包括其表示能力和与现有模型的联系，都进行了详细研究。一种更简化的变体LSEd利用对角矩阵进行变换以提高实用性能。在对四个大规模数据集进行链接预测的测试中，LSEd要么表现更好，要么具有竞争力。

    Knowledge graph embedding transforms knowledge graphs into a continuous, low-dimensional space, facilitating inference and completion tasks. This field is mainly divided into translational distance models and semantic matching models. A key challenge in translational distance models is their inability to effectively differentiate between 'head' and 'tail' entities in graphs. To address this, the novel location-sensitive embedding (LSE) method has been developed. LSE innovatively modifies the head entity using relation-specific mappings, conceptualizing relations as linear transformations rather than mere translations. The theoretical foundations of LSE, including its representational capabilities and its connections to existing models, have been thoroughly examined. A more streamlined variant, LSEd, employs a diagonal matrix for transformations to enhance practical efficiency. In tests conducted on four large-scale datasets for link prediction, LSEd either outperforms or is competitive
    
[^19]: 理解ChatGPT基推荐系统中的偏见：供应商公平性、时间稳定性和最新性研究

    Understanding Biases in ChatGPT-based Recommender Systems: Provider Fairness, Temporal Stability, and Recency. (arXiv:2401.10545v1 [cs.IR])

    [http://arxiv.org/abs/2401.10545](http://arxiv.org/abs/2401.10545)

    该研究揭示了基于ChatGPT的推荐系统的偏见问题，并研究了提示设计策略对推荐质量的影响。实验结果显示，在RecLLMs中引入特定的系统角色和提示策略可以增强推荐的公平性和多样性，同时GPT-based模型倾向于推荐最新和更多样化的电影流派。

    

    该研究探讨了使用大型语言模型（RecLLMs）的推荐系统的细微能力和固有偏见，重点研究了基于ChatGPT的系统。研究了生成模型和传统协同过滤模型在电影推荐中的差异行为。本研究主要调查了提示设计策略及其对推荐质量的各个方面（包括准确性、供应商公平性、多样性、稳定性、流行类型和时效性）的影响。我们的实验分析表明，在RecLLMs中引入特定的“系统角色”和“提示策略”显著影响其性能。例如，基于角色的提示可以增强推荐的公平性和多样性，减轻流行偏见。我们发现，虽然基于GPT的模型并不总是能与传统协同过滤基线模型的性能匹配，但它们倾向于推荐更新、更多样化的电影流派。值得注意的是，GPT-base

    This study explores the nuanced capabilities and inherent biases of Recommender Systems using Large Language Models (RecLLMs), with a focus on ChatGPT-based systems. It studies into the contrasting behaviors of generative models and traditional collaborative filtering models in movie recommendations. The research primarily investigates prompt design strategies and their impact on various aspects of recommendation quality, including accuracy, provider fairness, diversity, stability, genre dominance, and temporal freshness (recency).  Our experimental analysis reveals that the introduction of specific 'system roles' and 'prompt strategies' in RecLLMs significantly influences their performance. For instance, role-based prompts enhance fairness and diversity in recommendations, mitigating popularity bias. We find that while GPT-based models do not always match the performance of CF baselines, they exhibit a unique tendency to recommend newer and more diverse movie genres. Notably, GPT-base
    
[^20]: 运用噪声图神经网络方法实现差分隐私的顺序推荐研究

    Towards Differential Privacy in Sequential Recommendation: A Noisy Graph Neural Network Approach. (arXiv:2309.11515v1 [cs.CR])

    [http://arxiv.org/abs/2309.11515](http://arxiv.org/abs/2309.11515)

    这项工作提出了一种新颖的差分隐私顺序推荐框架，采用了噪声图神经网络方法，解决了现有差分隐私推荐系统在动态和依赖关系方面的局限性，同时也关注了敏感用户特征的隐私风险。

    

    随着各种在线平台中高调的隐私泄露事件频繁发生，用户对隐私越来越关注。推荐系统作为在线平台提供个性化服务的核心组件，其隐私保护引起了极大的关注。作为隐私保护的黄金标准，差分隐私已被广泛应用于推荐系统中的隐私保护。然而，现有的差分隐私推荐系统只考虑静态和独立的用户交互，因此无法应用于具有动态和依赖关系的顺序推荐。同时，对于敏感用户特征的隐私风险关注较少，大多数只保护用户的反馈数据。在这项工作中，我们提出了一个新颖的差分隐私顺序推荐框架，采用了噪声图神经网络方法（称为DIPSGNN）来解决这些局限性。

    With increasing frequency of high-profile privacy breaches in various online platforms, users are becoming more concerned about their privacy. And recommender system is the core component of online platforms for providing personalized service, consequently, its privacy preservation has attracted great attention. As the gold standard of privacy protection, differential privacy has been widely adopted to preserve privacy in recommender systems. However, existing differentially private recommender systems only consider static and independent interactions, so they cannot apply to sequential recommendation where behaviors are dynamic and dependent. Meanwhile, little attention has been paid on the privacy risk of sensitive user features, most of them only protect user feedbacks. In this work, we propose a novel DIfferentially Private Sequential recommendation framework with a noisy Graph Neural Network approach (denoted as DIPSGNN) to address these limitations. To the best of our knowledge, 
    
[^21]: 具有大型语言模型的上下文学习中的歧义感知

    Ambiguity-Aware In-Context Learning with Large Language Models. (arXiv:2309.07900v1 [cs.CL])

    [http://arxiv.org/abs/2309.07900](http://arxiv.org/abs/2309.07900)

    在上下文学习中，选择与测试输入语义相似的演示有助于提高下游性能，但是考虑到语言模型关于任务的现有知识能够更好地指导演示选择。

    

    在上下文学习（In-context learning, ICL）中，仅向LLMs展示少量任务特定演示已经导致了下游增益，无需进行任务特定的微调。然而，LLMs对于提示选择非常敏感，因此一个关键的研究问题是如何为ICL选择好的演示。一种有效的策略是利用ICL演示和测试输入之间的语义相似性，并使用文本检索器，然而这种方法并不考虑LLM关于该任务的现有知识，因此并不最优。根据之前的工作（Min等，2022），我们已经知道与演示配对的标签会对模型预测造成偏见。这引导我们提出了一个假设：考虑到LLM关于任务的现有知识，特别是与输出标签空间相关的知识，是否有助于更好的演示选择策略。通过在三个文本分类任务上进行广泛的实验，我们发现不仅选择语义相似的ICL演示是有益的，同时也要考虑LLM关于任务的现有知识以获得更好的演示选择策略。

    In-context learning (ICL) i.e. showing LLMs only a few task-specific demonstrations has led to downstream gains with no task-specific fine-tuning required. However, LLMs are sensitive to the choice of prompts, and therefore a crucial research question is how to select good demonstrations for ICL. One effective strategy is leveraging semantic similarity between the ICL demonstrations and test inputs by using a text retriever, which however is sub-optimal as that does not consider the LLM's existing knowledge about that task. From prior work (Min et al., 2022), we already know that labels paired with the demonstrations bias the model predictions. This leads us to our hypothesis whether considering LLM's existing knowledge about the task, especially with respect to the output label space can help in a better demonstration selection strategy. Through extensive experimentation on three text classification tasks, we find that it is beneficial to not only choose semantically similar ICL demon
    
[^22]: 推荐AI代理：将大型语言模型整合到交互式推荐中

    Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (arXiv:2308.16505v1 [cs.IR])

    [http://arxiv.org/abs/2308.16505](http://arxiv.org/abs/2308.16505)

    本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。

    

    推荐模型通过利用广泛的用户行为数据来提供领域特定的物品推荐，展现出轻量级领域专家的能力。然而，它们在提供解释和参与对话等多样化任务方面存在困难。另一方面，大型语言模型（LLMs）代表了人工通用智能的重要进展，在指令理解、常识推理和人类交互方面表现出了显著能力。然而，LLMs缺乏领域特定物品目录和行为模式的知识，特别是在与一般世界知识不同的领域，如在线电子商务。为每个领域微调LLMs既不经济又不高效。在本文中，我们将推荐模型和LLMs之间的差距，结合各自的优势，创建了一个多功能交互式推荐系统。我们引入了一个高效的框架称为RecAgent，该框架使用LLMs

    Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called RecAgent, which employs LLMs a
    
[^23]: TransGNN: 利用Transformer和图神经网络的协同能力来做推荐系统

    TransGNN: Harnessing the Collaborative Power of Transformers and Graph Neural Networks for Recommender Systems. (arXiv:2308.14355v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.14355](http://arxiv.org/abs/2308.14355)

    TransGNN是一种将Transformer和GNN层交替结合以相互增强其能力的新型模型，用于解决当前基于GNN的推荐系统面临的感受域有限和存在噪音连接的挑战。

    

    图神经网络(GNNs)已经被证明是推荐系统中有前途的解决方案，通过对用户-物品交互图进行建模来进行协同过滤(CF)。现有基于GNN的推荐系统的核心是通过在用户-物品交互边上进行递归消息传递来改进编码嵌入。尽管它们已经证明是有效的，但是当前基于GNN的方法面临着有限的感受域和存在噪音 "兴趣无关" 连接的挑战。相比之下，基于Transformer的方法在自适应和全局信息聚合方面表现出色。然而，它们在捕捉复杂、纠缠的结构信息方面在大规模交互图中的应用受到困扰。在本文中，我们提出了TransGNN，这是一种新颖的模型，通过交替地结合Transformer和GNN层来相互增强它们的能力。

    Graph Neural Networks (GNNs) have emerged as promising solutions for collaborative filtering (CF) through the modeling of user-item interaction graphs. The nucleus of existing GNN-based recommender systems involves recursive message passing along user-item interaction edges to refine encoded embeddings. Despite their demonstrated effectiveness, current GNN-based methods encounter challenges of limited receptive fields and the presence of noisy ``interest-irrelevant'' connections. In contrast, Transformer-based methods excel in aggregating information adaptively and globally. Nevertheless, their application to large-scale interaction graphs is hindered by inherent complexities and challenges in capturing intricate, entangled structural information. In this paper, we propose TransGNN, a novel model that integrates Transformer and GNN layers in an alternating fashion to mutually enhance their capabilities. Specifically, TransGNN leverages Transformer layers to broaden the receptive field 
    
[^24]: SSLRec: 一个自监督学习的推荐系统库

    SSLRec: A Self-Supervised Learning Library for Recommendation. (arXiv:2308.05697v1 [cs.IR])

    [http://arxiv.org/abs/2308.05697](http://arxiv.org/abs/2308.05697)

    SSLRec是一个自监督学习的推荐系统库，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。

    

    自监督学习（SSL）作为解决推荐系统中稀疏和噪声数据挑战的解决方案，在最近几年引起了广泛关注。尽管设计了越来越多的SSL算法来在不同领域中提供最先进的推荐性能（例如图协同过滤、顺序推荐、社交推荐、知识图增强推荐），但目前仍缺乏一个统一框架来整合不同领域的推荐算法。这样的框架可以作为自监督推荐算法的基石，统一现有方法的验证，并推动新方法的设计。为了解决这个问题，我们介绍了SSLRec，一个新颖的基准平台，为评估各种SSL增强推荐系统提供了标准化、灵活和综合的框架。SSLRec库具有模块化架构，可以方便用户评估最先进的推荐器。

    Self-supervised learning (SSL) has gained significant interest in recent years as a solution to address the challenges posed by sparse and noisy data in recommender systems. Despite the growing number of SSL algorithms designed to provide state-of-the-art performance in various recommendation scenarios (e.g., graph collaborative filtering, sequential recommendation, social recommendation, KG-enhanced recommendation), there is still a lack of unified frameworks that integrate recommendation algorithms across different domains. Such a framework could serve as the cornerstone for self-supervised recommendation algorithms, unifying the validation of existing methods and driving the design of new ones. To address this gap, we introduce SSLRec, a novel benchmark platform that provides a standardized, flexible, and comprehensive framework for evaluating various SSL-enhanced recommenders. The SSLRec library features a modular architecture that allows users to easily evaluate state-of-the-art m
    
[^25]: FedPDD：用于跨平台联邦推荐的隐私保护双重蒸馏框架

    FedPDD: A Privacy-preserving Double Distillation Framework for Cross-silo Federated Recommendation. (arXiv:2305.06272v1 [cs.IR])

    [http://arxiv.org/abs/2305.06272](http://arxiv.org/abs/2305.06272)

    本文提出了一个名为FedPDD的隐私保护双重蒸馏框架，用于跨平台联邦推荐。该框架包括教师蒸馏和学生蒸馏两个阶段，在不传输模型信息的情况下，通过有效地转移知识和使用一种新的蒸馏损失函数来构建全局模型，实现了最先进的性能。

    

    跨平台推荐旨在通过从不同平台收集异构特征来提高推荐准确性。然而，越来越严格的隐私保护法规限制了这种平台间的跨界协作，因此不能聚合数据用于训练。联邦学习（FL）是推荐场景中处理数据孤岛问题的实用解决方案。现有的跨平台FL方法通过利用重叠用户的数据协同构建全局模型，传输模型信息。然而，在现实中，重叠用户的数量往往非常小，从而大大限制了此类方法的性能。此外，训练期间传输模型信息需要高通信成本，可能会造成严重的隐私泄露。本文提出了一种新的隐私保护双重蒸馏框架 FedPDD 用于跨平台联邦推荐，该框架通过有效地转移知识来保护隐私。FedPDD 包括两个阶段：教师蒸馏和学生蒸馏。在教师蒸馏阶段，每个平台在自己的数据上训练本地模型，并将来自这些模型的知识蒸馏到一个小的、带有噪声的教师模型中。然后，在学生蒸馏阶段，每个平台通过一种新的蒸馏损失函数，同时从教师模型和本地数据中学习，训练自己的学生模型。FedPDD 在两个真实世界的跨平台联邦推荐数据集上实现了最先进的性能，同时保护隐私。

    Cross-platform recommendation aims to improve recommendation accuracy by gathering heterogeneous features from different platforms. However, such cross-silo collaborations between platforms are restricted by increasingly stringent privacy protection regulations, thus data cannot be aggregated for training. Federated learning (FL) is a practical solution to deal with the data silo problem in recommendation scenarios. Existing cross-silo FL methods transmit model information to collaboratively build a global model by leveraging the data of overlapped users. However, in reality, the number of overlapped users is often very small, thus largely limiting the performance of such approaches. Moreover, transmitting model information during training requires high communication costs and may cause serious privacy leakage. In this paper, we propose a novel privacy-preserving double distillation framework named FedPDD for cross-silo federated recommendation, which efficiently transfers knowledge wh
    

