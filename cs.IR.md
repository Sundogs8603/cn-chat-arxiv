# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Linear-Time Graph Neural Networks for Scalable Recommendations](https://arxiv.org/abs/2402.13973) | 本文提出了一种线性时间图神经网络（LTGNN），用于扩展图神经网络在推荐系统中的可扩展性。 |
| [^2] | [Retention Induced Biases in a Recommendation System with Heterogeneous Users](https://arxiv.org/abs/2402.13959) | 通过研究留存引发的偏见，发现改变推荐算法会导致推荐系统的行为在过渡期间与其新稳态不同，从而破坏了A/B实验作为评估RS改进的可靠性。 |
| [^3] | [Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning](https://arxiv.org/abs/2402.13897) | 提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互 |
| [^4] | [Diversity-Aware $k$-Maximum Inner Product Search Revisited](https://arxiv.org/abs/2402.13858) | 将多样性目标融入原始相关性目标的多样性感知$k$-最大内积搜索问题，提供了用户在相关性和多样性之间可控的权衡。 |
| [^5] | [LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation](https://arxiv.org/abs/2402.13840) | 该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。 |
| [^6] | [Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks](https://arxiv.org/abs/2402.13787) | 本文研究了链接分析算法在阻止少数群体在网络中达到高排名位置的条件，发现PageRank能够平衡排名中少数群体的代表性，而HITS则在同构网络中通过新颖的理论分析放大了现有的偏见。 |
| [^7] | [General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout](https://arxiv.org/abs/2402.13769) | 提出了一种名为Adversarial Graph Dropout (AdvDrop) 的新框架，用于解决图神经网络在协同过滤中放大偏见的问题。 |
| [^8] | [Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://arxiv.org/abs/2402.13750) | 提出了一种基于大型语言模型的互补知识增强推荐系统（LLM-KERec），通过引入实体提取器和构建互补知识图，解决了推荐系统难以捕捉用户意图转变和适应新商品的挑战。 |
| [^9] | [Improving Video Corpus Moment Retrieval with Partial Relevance Enhancement](https://arxiv.org/abs/2402.13576) | 通过部分相关性增强，该研究提出了改进视频语料库时刻检索的方法，以捕捉关键内容和处理不同模态之间的相关性差异。 |
| [^10] | [Event-aware Video Corpus Moment Retrieval](https://arxiv.org/abs/2402.13566) | 提出了EventFormer模型，利用事件作为视频检索的基本单元，并通过事件推理和分层事件编码来提取事件表示。 |
| [^11] | [ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](https://arxiv.org/abs/2402.13542) | ARL2提出了一种检索器学习技术，利用LLMs作为标注者，并采用自适应自训练策略，能够有效减少注释成本，并在NQ和MMLU上取得了5.4%和4.6%的准确度提升。 |
| [^12] | [Leveraging Translation For Optimal Recall: Tailoring LLM Personalization With User Profiles](https://arxiv.org/abs/2402.13500) | 本研究提出了一种通过多级翻译、语义嵌入扩展和用户配置文件中心扩展相结合的方法，旨在在跨语言信息检索系统中改善召回率，通过个性化匹配用户查询和相关文档，展示了比基线方法更优异的性能。 |
| [^13] | [Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness](https://arxiv.org/abs/2402.13495) | 探索了用户兴趣多样性对推荐系统公平性的影响，揭示了兴趣更广泛的用户通常接收到质量较低推荐的不均现象，并提出了一个多兴趣框架来解决这一问题。 |
| [^14] | [The Effectiveness of Graph Contrastive Learning on Mathematical Information Retrieval](https://arxiv.org/abs/2402.13444) | 图对比学习在数学信息检索中的应用表现优于当前主流模型TangentCFT。 |
| [^15] | [Learning to Retrieve for Job Matching](https://arxiv.org/abs/2402.13435) | 将学习检索技术应用于提升领英的工作搜索和推荐系统，通过构建评估求职者资格的图表并利用学习到的链接进行检索，以提高申请者质量和优化求职者参与度。 |
| [^16] | [Unlocking the `Why' of Buying: Introducing a New Dataset and Benchmark for Purchase Reason and Post-Purchase Experience](https://arxiv.org/abs/2402.13417) | 引入了一个新的数据集和基准，旨在揭示用户购买决策背后的原因，提出了一个有效的基于LLM的方法来生成高质量、个性化的购买原因解释。 |
| [^17] | [A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction](https://arxiv.org/abs/2402.13364) | 该论文提出了一种名为G&O的方法，通过将内容生成与结构化过程分离，有效提升了大型语言模型在生成特定结构化文本上的性能。 |
| [^18] | [Distributionally Robust Graph-based Recommendation System](https://arxiv.org/abs/2402.12994) | 提出了一种基于分布鲁棒性的图神经推荐系统（DR-GNN），通过将分布鲁棒性优化（DRO）融入到基于GNN的推荐中，解决训练和测试数据分布不同造成的效果下降问题 |
| [^19] | [Discovering and exploring cases of educational source code plagiarism with Dolos](https://arxiv.org/abs/2402.10853) | Dolos 是一个用于检测和预防教育源代码抄袭的工具生态系统，在最新版本中加强了用户体验，教育工作者可以通过新的 Web 应用程序在浏览器中运行整个抄袭检测流程，无需安装或配置。 |
| [^20] | [User Modeling and User Profiling: A Comprehensive Survey](https://arxiv.org/abs/2402.09660) | 这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。 |
| [^21] | [Debiasing Recommendation with Personal Popularity](https://arxiv.org/abs/2402.07425) | 该论文提出了使用个人流行度来消除推荐系统中的偏见问题。传统方法没有注意到全局流行度的根本问题，而个人流行度能够更好地捕捉到个体用户的兴趣，并生成个性化的推荐。研究者设计了一个称为个人流行度感知反事实的框架，将个人流行度融入到推荐系统中。 |
| [^22] | [Hierarchical Matrix Factorization for Interpretable Collaborative Filtering](https://arxiv.org/abs/2311.13277) | HMF通过将潜在矩阵分解为概率连接矩阵和根聚类潜在矩阵，结合了聚类概念来捕捉层次结构，从而实现了更稳定和可解释的推荐系统。 |
| [^23] | [Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions](https://arxiv.org/abs/2311.04590) | 提出了一个适用于跨领域序列推荐的自适应多兴趣去偏见框架（AMID），在开放世界假设下设计，旨在解决现有方法在在线真实平台上由于数据分布转移导致性能下降的问题。 |
| [^24] | [Fair Ranking under Disparate Uncertainty](https://arxiv.org/abs/2309.01610) | 提出了一种新的公平排名标准Equal-Opportunity Ranking（EOR），将底层相关性模型的不确定性差异考虑在内，通过组内公平抽奖实现公平排名。 |
| [^25] | [InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers](https://arxiv.org/abs/2301.02998) | InPars-Light是一个简单而有效的修改，通过使用小得多的排名模型和免费语言模型BLOOM，在多个英文检索集合上显著改进了排名性能。 |
| [^26] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |

# 详细

[^1]: 可扩展推荐系统的线性时间图神经网络

    Linear-Time Graph Neural Networks for Scalable Recommendations

    [https://arxiv.org/abs/2402.13973](https://arxiv.org/abs/2402.13973)

    本文提出了一种线性时间图神经网络（LTGNN），用于扩展图神经网络在推荐系统中的可扩展性。

    

    在信息爆炸的时代，推荐系统是为用户提供个性化推荐的重要工具。推荐系统的关键在于根据先前的用户-物品互动来预测用户的未来行为。近年来，由于其强大的高阶连接性捕捉能力，人们对利用图神经网络（GNNs）来提升推荐系统预测性能的兴趣日益增加。然而，经典的矩阵分解（MF）和深度神经网络（DNN）方法由于其可扩展性优势，仍在实际的大规模推荐系统中扮演着重要角色。尽管存在GNN加速解决方案，但GNN-based推荐系统能否像经典的MF和DNN方法一样高效扩展仍是一个开放问题。本文提出了一种线性时间图神经网络（LTGNN）来扩展GN

    arXiv:2402.13973v1 Announce Type: cross  Abstract: In an era of information explosion, recommender systems are vital tools to deliver personalized recommendations for users. The key of recommender systems is to forecast users' future behaviors based on previous user-item interactions. Due to their strong expressive power of capturing high-order connectivities in user-item interaction data, recent years have witnessed a rising interest in leveraging Graph Neural Networks (GNNs) to boost the prediction performance of recommender systems. Nonetheless, classic Matrix Factorization (MF) and Deep Neural Network (DNN) approaches still play an important role in real-world large-scale recommender systems due to their scalability advantages. Despite the existence of GNN-acceleration solutions, it remains an open question whether GNN-based recommender systems can scale as efficiently as classic MF and DNN methods. In this paper, we propose a Linear-Time Graph Neural Network (LTGNN) to scale up GN
    
[^2]: 具有异构用户的推荐系统中的留存引发偏见

    Retention Induced Biases in a Recommendation System with Heterogeneous Users

    [https://arxiv.org/abs/2402.13959](https://arxiv.org/abs/2402.13959)

    通过研究留存引发的偏见，发现改变推荐算法会导致推荐系统的行为在过渡期间与其新稳态不同，从而破坏了A/B实验作为评估RS改进的可靠性。

    

    我研究了一个具有用户流入和流失动态的推荐系统（RS）的概念模型。当流入和流失达到平衡时，用户分布达到稳定状态。改变推荐算法会改变稳定状态并产生过渡期。在这个期间，RS的行为与其新稳态不同。特别是，在过渡期内获得的A/B实验指标是RS长期性能的偏见指标。然而，学者和实践者经常在引入新算法后不久进行A/B测试以验证其有效性。然而，这种被广泛认为是评估RS改进的黄金标准的A/B实验范式可能产生错误结论。我还简要讨论了用户保留动态造成的数据偏见。

    arXiv:2402.13959v1 Announce Type: new  Abstract: I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly discuss the data bias caused by the user retention dynamics.
    
[^3]: 科学检查者再度升级：透明度和逻辑推理的双向范式

    Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning

    [https://arxiv.org/abs/2402.13897](https://arxiv.org/abs/2402.13897)

    提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互

    

    信息检索是一个快速发展的领域。然而，它仍然面临着在科学和工业的海量信息中的诸多限制，比如语义分歧和检索中的词汇差距、语义搜索中的低精度和缺乏可解释性，或者生成模型中的幻觉和过时信息。在本文中，我们提出了一个两块式的方法来解决长文档的这些障碍。第一个模块通过查询扩展增强了在稀疏检索中的语言理解，以检索相关文档。第二个模块通过只使用长文档中传播的信息，为复杂问题提供全面和信息丰富的答案来加深结果，实现双向交互。在管道的各个阶段，向用户呈现中间结果以促进对系统推理的理解。我们相信这种双向方法带来了

    arXiv:2402.13897v1 Announce Type: cross  Abstract: Information retrieval is a rapidly evolving field. However it still faces significant limitations in the scientific and industrial vast amounts of information, such as semantic divergence and vocabulary gaps in sparse retrieval, low precision and lack of interpretability in semantic search, or hallucination and outdated information in generative models. In this paper, we introduce a two-block approach to tackle these hurdles for long documents. The first block enhances language understanding in sparse retrieval by query expansion to retrieve relevant documents. The second block deepens the result by providing comprehensive and informative answers to the complex question using only the information spread in the long document, enabling bidirectional engagement. At various stages of the pipeline, intermediate results are presented to users to facilitate understanding of the system's reasoning. We believe this bidirectional approach brings
    
[^4]: 多样性感知$k$-最大内积搜索再探讨

    Diversity-Aware $k$-Maximum Inner Product Search Revisited

    [https://arxiv.org/abs/2402.13858](https://arxiv.org/abs/2402.13858)

    将多样性目标融入原始相关性目标的多样性感知$k$-最大内积搜索问题，提供了用户在相关性和多样性之间可控的权衡。

    

    $k$-最大内积搜索($k$MIPS)作为推荐系统和各种数据挖掘任务中的基础组件。然而，尽管大多数现有的$k$MIPS方法优先考虑为用户高度相关的项目进行高效检索，但它们经常忽略了搜索结果同样关键的一个方面：\emph{多样性}。为了弥补这一差距，我们重新审视和完善了多样性感知$k$MIPS（D$k$MIPS）问题，通过将两个众所周知的多样性目标--在结果中最小化平均和最大成对项目相似性--融入原始相关性目标。这种增强受到了极大边际相关性（MMR）的启发，为用户提供了关于相关性和多样性之间可控的权衡。我们引入了\textsc{Greedy}和\textsc{DualGreedy}，这两种基于线性扫描的算法专门用于D$k$MIPS。它们都实现了数据依赖的近似，并在旨在最小化平均成对相似性。

    arXiv:2402.13858v1 Announce Type: new  Abstract: The $k$-Maximum Inner Product Search ($k$MIPS) serves as a foundational component in recommender systems and various data mining tasks. However, while most existing $k$MIPS approaches prioritize the efficient retrieval of highly relevant items for users, they often neglect an equally pivotal facet of search results: \emph{diversity}. To bridge this gap, we revisit and refine the diversity-aware $k$MIPS (D$k$MIPS) problem by incorporating two well-known diversity objectives -- minimizing the average and maximum pairwise item similarities within the results -- into the original relevance objective. This enhancement, inspired by Maximal Marginal Relevance (MMR), offers users a controllable trade-off between relevance and diversity. We introduce \textsc{Greedy} and \textsc{DualGreedy}, two linear scan-based algorithms tailored for D$k$MIPS. They both achieve data-dependent approximations and, when aiming to minimize the average pairwise simi
    
[^5]: LLM4SBR: 一个轻量且有效的框架，用于在基于会话的推荐中集成大型语言模型

    LLM4SBR: A Lightweight and Effective Framework for Integrating Large Language Models in Session-based Recommendation

    [https://arxiv.org/abs/2402.13840](https://arxiv.org/abs/2402.13840)

    该研究提出了LLM4SBR框架，是第一个适合在基于会话的推荐中集成大型语言模型的轻量且有效框架。

    

    传统的基于会话的推荐(SBR)利用来自匿名用户的会话行为序列进行推荐。虽然这种策略非常高效，但牺牲了商品的固有语义信息，使模型难以理解会话的真正意图，导致推荐结果缺乏可解释性。近年来，大型语言模型(LLMs)在各个领域蓬勃发展，为解决上述挑战带来了一线希望。受LLMs影响，探讨LLMs与推荐系统(RS)集成的研究如雨后春笋般涌现。然而，受限于高时间和空间成本，以及会话数据短暂且匿名的特性，第一个适合工业部署的LLM推荐框架在SBR领域尚未出现。为了解决上述挑战，我们...

    arXiv:2402.13840v1 Announce Type: cross  Abstract: Traditional session-based recommendation (SBR) utilizes session behavior sequences from anonymous users for recommendation. Although this strategy is highly efficient, it sacrifices the inherent semantic information of the items, making it difficult for the model to understand the true intent of the session and resulting in a lack of interpretability in the recommended results. Recently, large language models (LLMs) have flourished across various domains, offering a glimpse of hope in addressing the aforementioned challenges. Inspired by the impact of LLMs, research exploring the integration of LLMs with the Recommender system (RS) has surged like mushrooms after rain. However, constrained by high time and space costs, as well as the brief and anonymous nature of session data, the first LLM recommendation framework suitable for industrial deployment has yet to emerge in the field of SBR. To address the aforementioned challenges, we hav
    
[^6]: 从排名中崛起的公平性：HITS和PageRank在同质网络上的应用

    Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks

    [https://arxiv.org/abs/2402.13787](https://arxiv.org/abs/2402.13787)

    本文研究了链接分析算法在阻止少数群体在网络中达到高排名位置的条件，发现PageRank能够平衡排名中少数群体的代表性，而HITS则在同构网络中通过新颖的理论分析放大了现有的偏见。

    

    在本文中，我们研究了链接分析算法在阻止少数群体达到高排名位置的条件。我们发现，使用中心性度量标准的最常见链接算法，如PageRank和HITS，在网络中可能再现甚至放大对少数群体的偏见。然而，它们的行为有所不同：一方面，我们凭经验证明，PageRank在大部分排名位置上反映了度分布，并且可以平衡少数群体在排名靠前的节点中的代表性；另一方面，我们发现HITS通过新颖的理论分析在同构网络中放大了现有的偏见，支撑证据为实证结果。我们发现HITS中偏见放大的根本原因是网络中存在的同质性水平，通过一个具有两个社区的不断发展的网络模型进行建模。我们以合成和真实数据集阐明了我们的理论分析。

    arXiv:2402.13787v1 Announce Type: cross  Abstract: In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we pr
    
[^7]: 基于对抗图节点删除的图协同过滤通用去偏方法

    General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout

    [https://arxiv.org/abs/2402.13769](https://arxiv.org/abs/2402.13769)

    提出了一种名为Adversarial Graph Dropout (AdvDrop) 的新框架，用于解决图神经网络在协同过滤中放大偏见的问题。

    

    图神经网络（GNNs）在推荐系统中展现出令人印象深刻的性能，特别是在协同过滤（CF）中。关键在于聚合用户-物品交互图上的邻域信息，以增强用户/物品表示。然而，我们发现这种聚合机制存在一个缺点，即放大了交互图中存在的偏见。当前的聚合方法结合了所有信息，包括偏见和无偏见，导致偏见表征学习。因此，基于图的推荐系统可能学习到用户/物品的扭曲视图，阻碍了对其真实偏好和泛化建模的过程。为了解决这一问题，我们引入了一种称为对抗图节点删除（AdvDrop）的新框架。

    arXiv:2402.13769v1 Announce Type: new  Abstract: Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback, which amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations. To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiat
    
[^8]: 打破障碍：通过推理知识图利用大型语言模型进行工业推荐系统

    Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph

    [https://arxiv.org/abs/2402.13750](https://arxiv.org/abs/2402.13750)

    提出了一种基于大型语言模型的互补知识增强推荐系统（LLM-KERec），通过引入实体提取器和构建互补知识图，解决了推荐系统难以捕捉用户意图转变和适应新商品的挑战。

    

    推荐系统在电子商务网站和在线平台中被广泛使用，以应对信息过载。然而，现有系统主要依赖历史数据和用户反馈，难以捕捉用户意图转变。最近，提出了基于知识库（KB）的模型来整合专家知识，但它们难以适应新商品和不断发展的电子商务环境。为了解决这些挑战，我们提出了一种新颖的基于大型语言模型的互补知识增强推荐系统（LLM-KERec）。它引入了一个实体提取器，从商品和用户信息中提取统一概念术语。为了提供具有成本效益且可靠的先验知识，根据实体的流行度和特定策略生成实体对。大型语言模型确定每个实体对中的互补关系，构建一个互补知识图。此外，一个新的...

    arXiv:2402.13750v1 Announce Type: cross  Abstract: Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new 
    
[^9]: 通过部分相关性增强改进视频语料库时刻检索

    Improving Video Corpus Moment Retrieval with Partial Relevance Enhancement

    [https://arxiv.org/abs/2402.13576](https://arxiv.org/abs/2402.13576)

    通过部分相关性增强，该研究提出了改进视频语料库时刻检索的方法，以捕捉关键内容和处理不同模态之间的相关性差异。

    

    视频语料库时刻检索（VCMR）是一个新的视频检索任务，旨在使用自然语言文本作为查询，从大量未经修剪的视频语料库中检索相关时刻。视频与查询之间的相关性是部分的，主要体现在两个方面：（1）范围：未经修剪的视频包含信息丰富的帧，而并非所有帧都与查询相关。强相关性通常仅在相关时刻内观察到，强调捕捉关键内容的重要性。（2）模态：查询与不同模态的相关性不同；动作描述更倚赖于视觉元素，而角色对话与文本信息更相关。识别和解决这些模态特定的细微差别对于在VCMR中进行有效检索至关重要。然而，现有方法通常将所有视频内容平等对待，导致子优时刻检索。我们认为，有效捕捉p

    arXiv:2402.13576v1 Announce Type: cross  Abstract: Video corpus moment retrieval~(VCMR) is a new video retrieval task aimed at retrieving a relevant moment from a large corpus of untrimmed videos using a natural language text as query. The relevance between the video and query is partial, mainly evident in two aspects: (1) Scope: The untrimmed video contains information-rich frames, and not all are relevant to the query. Strong correlation is typically observed only within the relevant moment, emphasizing the importance of capturing key content. (2) Modality: The relevance of query to different modalities varies; action descriptions align more with the visual elements, while character conversations are more related to textual information. Recognizing and addressing these modality-specific nuances is crucial for effective retrieval in VCMR. However, existing methods often treat all video contents equally, leading to sub-optimal moment retrieval. We argue that effectively capturing the p
    
[^10]: 基于事件感知的视频语料库时刻检索

    Event-aware Video Corpus Moment Retrieval

    [https://arxiv.org/abs/2402.13566](https://arxiv.org/abs/2402.13566)

    提出了EventFormer模型，利用事件作为视频检索的基本单元，并通过事件推理和分层事件编码来提取事件表示。

    

    视频语料库时刻检索（VCMR）是一项实用的视频检索任务，重点是使用自然语言查询在庞大的未修剪视频语料库中识别特定时刻。现有的VCMR方法通常依赖于基于帧的视频检索，通过计算查询和视频帧之间的相似性来根据最大帧相似性对视频进行排序。然而，这种方法忽视了嵌入在帧间信息中的语义结构，即事件，这是人类理解视频的关键元素。受此启发，我们提出了EventFormer模型，该模型明确利用视频中的事件作为视频检索的基本单元。该模型通过事件推理和分层事件编码提取事件表示。事件推理模块将连续且视觉相似的帧表示分组成事件，而分层事件编码则在不同层次上编码信息。

    arXiv:2402.13566v1 Announce Type: cross  Abstract: Video Corpus Moment Retrieval (VCMR) is a practical video retrieval task focused on identifying a specific moment within a vast corpus of untrimmed videos using the natural language query. Existing methods for VCMR typically rely on frame-aware video retrieval, calculating similarities between the query and video frames to rank videos based on maximum frame similarity.However, this approach overlooks the semantic structure embedded within the information between frames, namely, the event, a crucial element for human comprehension of videos. Motivated by this, we propose EventFormer, a model that explicitly utilizes events within videos as fundamental units for video retrieval. The model extracts event representations through event reasoning and hierarchical event encoding. The event reasoning module groups consecutive and visually similar frame representations into events, while the hierarchical event encoding encodes information at bo
    
[^11]: ARL2: 通过自导自适应相关性标记将检索器与黑盒大型语言模型对齐

    ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling

    [https://arxiv.org/abs/2402.13542](https://arxiv.org/abs/2402.13542)

    ARL2提出了一种检索器学习技术，利用LLMs作为标注者，并采用自适应自训练策略，能够有效减少注释成本，并在NQ和MMLU上取得了5.4%和4.6%的准确度提升。

    

    arXiv:2402.13542v1 公告类型: 交叉 摘要: 检索增强生成通过整合外部知识源的相关信息改进大型语言模型（LLMs），使LLMs能够适应特定领域，并减轻知识密集任务中的幻觉。然而，由于其分开的训练过程和LLMs的黑盒特性，现有的检索器通常与LLMs不匹配。为解决这一挑战，我们提出了ARL2，一种利用LLMs作为标注者的检索器学习技术。ARL2利用LLMs注释和评分相关证据，从而能够从强大的LLM监督中学习检索器。此外，ARL2使用自适应自训练策略来策划高质量和多样性相关性数据，可以有效降低标注成本。大量实验表明ARL2的有效性，与最先进方法相比，在NQ上提高了5.4%的准确率，在MMLU上提高了4.6%。

    arXiv:2402.13542v1 Announce Type: cross  Abstract: Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevant evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses an adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-of-the-art methods. Additionall
    
[^12]: 利用翻译实现最佳召回率：通过用户配置文件定制LLM个性化

    Leveraging Translation For Optimal Recall: Tailoring LLM Personalization With User Profiles

    [https://arxiv.org/abs/2402.13500](https://arxiv.org/abs/2402.13500)

    本研究提出了一种通过多级翻译、语义嵌入扩展和用户配置文件中心扩展相结合的方法，旨在在跨语言信息检索系统中改善召回率，通过个性化匹配用户查询和相关文档，展示了比基线方法更优异的性能。

    

    本文探讨了一种新颖技术，通过基于用户的词汇-语义空间的迭代查询优化来提高跨语言信息检索(CLIR)系统中的召回率。提出的方法结合了多级翻译、基于语义嵌入的扩展，以及以用户配置文件为中心的扩展，以解决用户查询和相关文档之间的匹配差异挑战。通过初始的BM25检索、转换为中间语言、查找相似术语的嵌入，以及迭代重新排名，该技术旨在扩大可能与个体用户相关的潜在结果范围。对新闻和Twitter数据集的比较实验证明，所提方法在ROUGE指标方面优于基线BM25排名。翻译方法还通过多步骤过程展示出了保持的语义准确性。

    arXiv:2402.13500v1 Announce Type: cross  Abstract: This paper explores a novel technique for improving recall in cross-language information retrieval (CLIR) systems using iterative query refinement grounded in the user's lexical-semantic space. The proposed methodology combines multi-level translation, semantic embedding-based expansion, and user profile-centered augmentation to address the challenge of matching variance between user queries and relevant documents. Through an initial BM25 retrieval, translation into intermediate languages, embedding lookup of similar terms, and iterative re-ranking, the technique aims to expand the scope of potentially relevant results personalized to the individual user. Comparative experiments on news and Twitter datasets demonstrate superior performance over baseline BM25 ranking for the proposed approach across ROUGE metrics. The translation methodology also showed maintained semantic accuracy through the multi-step process. This personalized CLIR 
    
[^13]: 一个嵌入是否适用于所有？一种多兴趣学习范式，旨在提高用户兴趣多样性公平性

    Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness

    [https://arxiv.org/abs/2402.13495](https://arxiv.org/abs/2402.13495)

    探索了用户兴趣多样性对推荐系统公平性的影响，揭示了兴趣更广泛的用户通常接收到质量较低推荐的不均现象，并提出了一个多兴趣框架来解决这一问题。

    

    推荐系统因其捕捉用户兴趣的优越能力而在各个领域广泛应用。然而，用户兴趣的复杂性和微妙性涵盖了广泛多样的范围，这在提供公平推荐方面构成了重要挑战。本研究探讨了具有不同兴趣多样性水平的用户是否受到公平对待。实证实验揭示了一个固有的不均：兴趣更广泛的用户通常会收到质量较低的推荐。为了缓解这一问题，我们提出了一个多兴趣框架。

    arXiv:2402.13495v1 Announce Type: new  Abstract: Recommender systems (RSs) have gained widespread applications across various domains owing to the superior ability to capture users' interests. However, the complexity and nuanced nature of users' interests, which span a wide range of diversity, pose a significant challenge in delivering fair recommendations. In practice, user preferences vary significantly; some users show a clear preference toward certain item categories, while others have a broad interest in diverse ones. Even though it is expected that all users should receive high-quality recommendations, the effectiveness of RSs in catering to this disparate interest diversity remains under-explored.   In this work, we investigate whether users with varied levels of interest diversity are treated fairly. Our empirical experiments reveal an inherent disparity: users with broader interests often receive lower-quality recommendations. To mitigate this, we propose a multi-interest fram
    
[^14]: 图对比学习在数学信息检索中的有效性研究

    The Effectiveness of Graph Contrastive Learning on Mathematical Information Retrieval

    [https://arxiv.org/abs/2402.13444](https://arxiv.org/abs/2402.13444)

    图对比学习在数学信息检索中的应用表现优于当前主流模型TangentCFT。

    

    本文详细介绍了使用图对比学习（Graph Contrastive Learning，GCL）生成数学方程表示的实证调查，这是数学信息检索（MIR）的关键方面。我们的研究结果显示，这种简单方法始终优于当前领先的公式检索模型TangentCFT的性能。为支持这一领域的持续研究与发展，我们已将源代码公开在https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/。

    arXiv:2402.13444v1 Announce Type: new  Abstract: This paper details an empirical investigation into using Graph Contrastive Learning (GCL) to generate mathematical equation representations, a critical aspect of Mathematical Information Retrieval (MIR). Our findings reveal that this simple approach consistently exceeds the performance of the current leading formula retrieval model, TangentCFT. To support ongoing research and development in this field, we have made our source code accessible to the public at https://github.com/WangPeiSyuan/GCL-Formula-Retrieval/.
    
[^15]: 学习检索用于工作匹配

    Learning to Retrieve for Job Matching

    [https://arxiv.org/abs/2402.13435](https://arxiv.org/abs/2402.13435)

    将学习检索技术应用于提升领英的工作搜索和推荐系统，通过构建评估求职者资格的图表并利用学习到的链接进行检索，以提高申请者质量和优化求职者参与度。

    

    Web规模搜索系统通常通过两步骤范式来解决可伸缩性挑战：检索和排名。检索步骤，也称为候选选择，通常涉及提取标准化实体，创建反向索引，并执行检索的术语匹配。这种传统方法需要手动和耗时的查询模型开发。本文讨论了将学习检索技术应用于提升领英的工作搜索和推荐系统。在推广工作领域，关键目标是提高申请者的质量，从而为招聘客户提供价值。为了实现这一目标，我们利用确认的雇佣数据构建一个评估求职者对工作资格的图表，并利用学习到的链接进行检索。我们的学习模型易于解释，调试和调整。另一方面，有机工作的重点是优化求职者参与度。

    arXiv:2402.13435v1 Announce Type: cross  Abstract: Web-scale search systems typically tackle the scalability challenge with a two-step paradigm: retrieval and ranking. The retrieval step, also known as candidate selection, often involves extracting standardized entities, creating an inverted index, and performing term matching for retrieval. Such traditional methods require manual and time-consuming development of query models. In this paper, we discuss applying learning-to-retrieve technology to enhance LinkedIns job search and recommendation systems. In the realm of promoted jobs, the key objective is to improve the quality of applicants, thereby delivering value to recruiter customers. To achieve this, we leverage confirmed hire data to construct a graph that evaluates a seeker's qualification for a job, and utilize learned links for retrieval. Our learned model is easy to explain, debug, and adjust. On the other hand, the focus for organic jobs is to optimize seeker engagement. We 
    
[^16]: 解锁购买的“为何”：引入一个新的数据集和购买原因与后购买体验的基准

    Unlocking the `Why' of Buying: Introducing a New Dataset and Benchmark for Purchase Reason and Post-Purchase Experience

    [https://arxiv.org/abs/2402.13417](https://arxiv.org/abs/2402.13417)

    引入了一个新的数据集和基准，旨在揭示用户购买决策背后的原因，提出了一个有效的基于LLM的方法来生成高质量、个性化的购买原因解释。

    

    解释对于提高现代推荐系统中用户信任和理解至关重要。为了构建真正可解释的系统，我们需要能阐明用户为何做出选择的高质量数据集。我们提出了一个新颖的购买原因解释任务。为此，我们引入了一种基于LLM的方法来生成一个由真实用户解释为何做出某些购买决策的文本解释的数据集。我们诱导LLM明确区分用户评论中购买产品背后的原因和购买后的体验。自动化的LLM驱动评估以及小规模人工评估证实了我们方法获取高质量、个性化解释的有效性。我们在两个个性化数据集上对该数据集进行基准测试。

    arXiv:2402.13417v1 Announce Type: new  Abstract: Explanations are crucial for enhancing user trust and understanding within modern recommendation systems. To build truly explainable systems, we need high-quality datasets that elucidate why users make choices. While previous efforts have focused on extracting users' post-purchase sentiment in reviews, they ignore the reasons behind the decision to buy.   In our work, we propose a novel purchase reason explanation task. To this end, we introduce an LLM-based approach to generate a dataset that consists of textual explanations of why real users make certain purchase decisions. We induce LLMs to explicitly distinguish between the reasons behind purchasing a product and the experience after the purchase in a user review. An automated, LLM-driven evaluation, as well as a small scale human evaluation, confirms the effectiveness of our approach to obtaining high-quality, personalized explanations. We benchmark this dataset on two personalized 
    
[^17]: 一种简单而有效的方法，改善结构化语言模型在信息抽取中的输出

    A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction

    [https://arxiv.org/abs/2402.13364](https://arxiv.org/abs/2402.13364)

    该论文提出了一种名为G&O的方法，通过将内容生成与结构化过程分离，有效提升了大型语言模型在生成特定结构化文本上的性能。

    

    大型语言模型（LLMs）已经展示出在根据指令生成非结构化自然语言方面具有令人印象深刻的能力。然而，当要求它们生成符合特定结构化格式的文本时，它们的表现可能不一致，在命名实体识别（NER）或关系抽取（RE）等应用中这一点至关重要。为了解决这个问题，本文引入了一种高效的方法，G&O，以增强它们的结构化文本生成能力。它将生成分解为一个两步流程：首先，LLMs生成自然语言中的答案作为中间响应。随后，要求LLMs将输出组织成所需的结构，使用中间响应作为上下文。G&O有效地将内容生成与构建过程分离，减少了同时完成两个正交任务的压力。在零-shot NER和RE上进行测试，结果表明

    arXiv:2402.13364v1 Announce Type: new  Abstract: Large language models (LLMs) have demonstrated impressive abilities in generating unstructured natural language according to instructions. However, their performance can be inconsistent when tasked with producing text that adheres to specific structured formats, which is crucial in applications like named entity recognition (NER) or relation extraction (RE). To address this issue, this paper introduces an efficient method, G&O, to enhance their structured text generation capabilities. It breaks the generation into a two-step pipeline: initially, LLMs generate answers in natural language as intermediate responses. Subsequently, LLMs are asked to organize the output into the desired structure, using the intermediate responses as context. G&O effectively separates the generation of content from the structuring process, reducing the pressure of completing two orthogonal tasks simultaneously. Tested on zero-shot NER and RE, the results indica
    
[^18]: 基于分布鲁棒性的图神经推荐系统

    Distributionally Robust Graph-based Recommendation System

    [https://arxiv.org/abs/2402.12994](https://arxiv.org/abs/2402.12994)

    提出了一种基于分布鲁棒性的图神经推荐系统（DR-GNN），通过将分布鲁棒性优化（DRO）融入到基于GNN的推荐中，解决训练和测试数据分布不同造成的效果下降问题

    

    具有捕捉高阶协作信号能力的图神经网络（GNNs）已经成为推荐系统（RS）中强大的方法。然而，它们的有效性通常取决于训练和测试数据共享相同分布（即IID假设），并在分布转移下出现显著下降。分布转移在RS中常见，通常归因于用户喜好的动态性或RS中数据收集过程中的普遍偏见。尽管其重要性，针对基于GNN的推荐系统对抗分布转移的研究仍然很少。为了弥合这一差距，我们提出了将分布鲁棒性优化（DRO）引入基于GNN的推荐系统中的分布鲁棒性GNN（DR-GNN）。DR-GNN解决了两个核心挑战：1）使DRO能够适应与GNN交织的图数据，我们将GNN重新解释为图平滑正则化器，从而促进...

    arXiv:2402.12994v1 Announce Type: new  Abstract: With the capacity to capture high-order collaborative signals, Graph Neural Networks (GNNs) have emerged as powerful methods in Recommender Systems (RS). However, their efficacy often hinges on the assumption that training and testing data share the same distribution (a.k.a. IID assumption), and exhibits significant declines under distribution shifts. Distribution shifts commonly arises in RS, often attributed to the dynamic nature of user preferences or ubiquitous biases during data collection in RS. Despite its significance, researches on GNN-based recommendation against distribution shift are still sparse. To bridge this gap, we propose Distributionally Robust GNN (DR-GNN) that incorporates Distributional Robust Optimization (DRO) into the GNN-based recommendation. DR-GNN addresses two core challenges: 1) To enable DRO to cater to graph data intertwined with GNN, we reinterpret GNN as a graph smoothing regularizer, thereby facilitatin
    
[^19]: 使用Dolos发现和探索教育源代码抄袭案例

    Discovering and exploring cases of educational source code plagiarism with Dolos

    [https://arxiv.org/abs/2402.10853](https://arxiv.org/abs/2402.10853)

    Dolos 是一个用于检测和预防教育源代码抄袭的工具生态系统，在最新版本中加强了用户体验，教育工作者可以通过新的 Web 应用程序在浏览器中运行整个抄袭检测流程，无需安装或配置。

    

    源代码抄袭在教育实践中是一个重要问题，教育工作者需要易于使用的工具来应对这种学术不端行为。本文介绍了 Dolos 的最新版本，一个用于检测和预防教育源代码抄袭的工具生态系统。在这个新版本中，主要侧重于提升用户体验。教育工作者现在可以在他们的浏览器中通过一个新的 Web 应用程序运行整个抄袭检测流程，无需安装或配置。完全重新设计的分析仪表板可以即时评估一组源文件是否包含疑似抄袭案例以及集合中抄袭有多普遍。仪表板支持分层结构化导航，以便轻松缩放到疑似案例。集群是仪表板设计中一个重要的新组件，反映了

    arXiv:2402.10853v1 Announce Type: cross  Abstract: Source code plagiarism is a significant issue in educational practice, and educators need user-friendly tools to cope with such academic dishonesty. This article introduces the latest version of Dolos, a state-of-the-art ecosystem of tools for detecting and preventing plagiarism in educational source code. In this new version, the primary focus has been on enhancing the user experience. Educators can now run the entire plagiarism detection pipeline from a new web app in their browser, eliminating the need for any installation or configuration. Completely redesigned analytics dashboards provide an instant assessment of whether a collection of source files contains suspected cases of plagiarism and how widespread plagiarism is within the collection. The dashboards support hierarchically structured navigation to facilitate zooming in and out of suspect cases. Clusters are an essential new component of the dashboard design, reflecting the 
    
[^20]: 用户建模与用户画像：综述

    User Modeling and User Profiling: A Comprehensive Survey

    [https://arxiv.org/abs/2402.09660](https://arxiv.org/abs/2402.09660)

    这篇综述论文介绍了用户建模与用户画像研究的现状、发展和未来方向。该研究主要关注在人工智能应用中构建准确的用户表示，包括利用大量数据进行建模以及采用深度学习和图数据技术等先进方法。

    

    人工智能（AI）融入日常生活，特别是通过信息检索和推荐系统，已经促使先进的用户建模和用户画像技术，以提供个性化体验。这些技术旨在基于与这些系统的互动中生成的大量数据构建准确的用户表示。本文对用户建模和用户画像研究的现状、发展和未来方向进行了全面综述。我们提供了一个历史概述，追溯了从早期的刻板模型到最新的深度学习技术，并提出了一个新的分类体系，涵盖了这一研究领域中的所有活动主题，包括最近的趋势。我们的综述突出了向更复杂的用户画像方法的范式转变，强调了隐式数据收集、多行为建模以及图数据的整合。

    arXiv:2402.09660v1 Announce Type: new  Abstract: The integration of artificial intelligence (AI) into daily life, particularly through information retrieval and recommender systems, has necessitated advanced user modeling and profiling techniques to deliver personalized experiences. These techniques aim to construct accurate user representations based on the rich amounts of data generated through interactions with these systems. This paper presents a comprehensive survey of the current state, evolution, and future directions of user modeling and profiling research. We provide a historical overview, tracing the development from early stereotype models to the latest deep learning techniques, and propose a novel taxonomy that encompasses all active topics in this research area, including recent trends. Our survey highlights the paradigm shifts towards more sophisticated user profiling methods, emphasizing implicit data collection, multi-behavior modeling, and the integration of graph data
    
[^21]: 用个人流行度消除推荐偏见

    Debiasing Recommendation with Personal Popularity

    [https://arxiv.org/abs/2402.07425](https://arxiv.org/abs/2402.07425)

    该论文提出了使用个人流行度来消除推荐系统中的偏见问题。传统方法没有注意到全局流行度的根本问题，而个人流行度能够更好地捕捉到个体用户的兴趣，并生成个性化的推荐。研究者设计了一个称为个人流行度感知反事实的框架，将个人流行度融入到推荐系统中。

    

    全球流行度（GP）偏见是指推荐系统在推荐物品时普遍偏向热门物品，这违背了提供个性化推荐的目标，对用户体验和推荐准确性造成了不利影响。许多方法已经被提出来减少GP偏见，但它们没有注意到GP的根本问题，即它从全局的角度考虑热门度，使用一组热门物品，因此无法捕捉到个别用户的兴趣。因此，我们提出了一种以用户为基础的物品流行度称为个人流行度（PP），通过考虑分享相似兴趣的用户来为每个用户识别不同的热门物品。由于PP模型化了个体用户的偏好，它自然可以帮助生成个性化的推荐并减少GP偏见。为了将PP融入推荐中，我们设计了一个通用的个人流行度感知反事实（PPAC）框架。

    Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a \textit{global} perspective of \textit{all users} and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named \textit{personal popularity} (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general \textit{personal popularity aware counterfactual} (PPAC) frame
    
[^22]: 可解释的协同过滤的分层矩阵分解

    Hierarchical Matrix Factorization for Interpretable Collaborative Filtering

    [https://arxiv.org/abs/2311.13277](https://arxiv.org/abs/2311.13277)

    HMF通过将潜在矩阵分解为概率连接矩阵和根聚类潜在矩阵，结合了聚类概念来捕捉层次结构，从而实现了更稳定和可解释的推荐系统。

    

    矩阵分解（MF）是一种简单的协同过滤技术，通过将用户-项目交互矩阵分解为用户和项目潜在矩阵，实现了更高的推荐准确性。然而，由于模型通常独立学习每个交互，可能忽视用户和项目之间的共享依赖关系，导致推荐不够稳定和解释性不强。基于这些观察，我们提出了"分层矩阵分解"（HMF），该方法结合聚类概念来捕捉层次结构，其中叶节点和其他节点分别对应用户/项目和聚类。我们方法的核心是层次嵌入（hierarchical embeddings），它将潜在矩阵（嵌入）进一步分解为概率连接矩阵，将层次结构与根聚类潜在矩阵联系起来。这些嵌入具有可微性，允许同时学习交互和...

    arXiv:2311.13277v2 Announce Type: replace  Abstract: Matrix factorization (MF) is a simple collaborative filtering technique that achieves superior recommendation accuracy by decomposing the user-item interaction matrix into user and item latent matrices. Because the model typically learns each interaction independently, it may overlook the underlying shared dependencies between users and items, resulting in less stable and interpretable recommendations. Based on these insights, we propose "Hierarchical Matrix Factorization" (HMF), which incorporates clustering concepts to capture the hierarchy, where leaf nodes and other nodes correspond to users/items and clusters, respectively. Central to our approach, called hierarchical embeddings, is the additional decomposition of the latent matrices (embeddings) into probabilistic connection matrices, which link the hierarchy, and a root cluster latent matrix. The embeddings are differentiable, allowing simultaneous learning of interactions and
    
[^23]: 在开放世界假设下重新思考跨领域序列推荐

    Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions

    [https://arxiv.org/abs/2311.04590](https://arxiv.org/abs/2311.04590)

    提出了一个适用于跨领域序列推荐的自适应多兴趣去偏见框架（AMID），在开放世界假设下设计，旨在解决现有方法在在线真实平台上由于数据分布转移导致性能下降的问题。

    

    跨领域顺序推荐（CDSR）方法旨在解决单一领域顺序推荐（SDSR）中存在的数据稀疏和冷启动问题。现有的CDSR作品设计其精心的结构，依赖于重叠用户来传播跨领域信息。然而，当前的CDSR方法采用封闭世界假设，假设在多个领域之间完全重叠的用户，并且数据分布从训练环境到测试环境保持不变。因此，这些方法通常因数据分布转移而在在线真实平台上表现较差。为了在开放世界假设下解决这些挑战，我们设计了一个自适应多兴趣去偏见框架，用于跨领域序列推荐（AMID），其中包括一个多兴趣信息模块（MIM）和一个双重鲁

    arXiv:2311.04590v3 Announce Type: replace  Abstract: Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data sparsity and cold-start problems present in Single-Domain Sequential Recommendation (SDSR). Existing CDSR works design their elaborate structures relying on overlapping users to propagate the cross-domain information. However, current CDSR methods make closed-world assumptions, assuming fully overlapping users across multiple domains and that the data distribution remains unchanged from the training environment to the test environment. As a result, these methods typically result in lower performance on online real-world platforms due to the data distribution shifts. To address these challenges under open-world assumptions, we design an \textbf{A}daptive \textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing framework for cross-domain sequential recommendation (\textbf{AMID}), which consists of a multi-interest information module (\textbf{MIM}) and a doubly robu
    
[^24]: 不同不确定性下的公平排名

    Fair Ranking under Disparate Uncertainty

    [https://arxiv.org/abs/2309.01610](https://arxiv.org/abs/2309.01610)

    提出了一种新的公平排名标准Equal-Opportunity Ranking（EOR），将底层相关性模型的不确定性差异考虑在内，通过组内公平抽奖实现公平排名。

    

    排名是一种广泛使用的方法，用于将人类评估者的注意力集中在可管理的选项子集上。它作为人类决策过程的一部分的使用范围从在电子商务网站上展示潜在相关产品到为人工审查优先处理大学申请。虽然排名可以通过将关注集中在最有前途的选项上使人类评估更加高效，但我们认为，如果底层相关性模型的不确定性在不同组别的选项之间存在差异，排名可能会引入不公平。不幸的是，这种不确定性差异似乎普遍存在，常常对少数群体造成损害，因为这些群体的相关性估计可能由于缺乏数据或合适的特征而具有更高的不确定性。为了解决这个公平问题，我们提出了Equal-Opportunity Ranking（EOR）作为排名的新公平标准，并展示它对应于在相关选项之间进行组内公平抽奖

    arXiv:2309.01610v2 Announce Type: replace  Abstract: Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use as part of human decision-making processes ranges from surfacing potentially relevant products on an e-commerce site to prioritizing college applications for human review. While ranking can make human evaluation more effective by focusing attention on the most promising options, we argue that it can introduce unfairness if the uncertainty of the underlying relevance model differs between groups of options. Unfortunately, such disparity in uncertainty appears widespread, often to the detriment of minority groups for which relevance estimates can have higher uncertainty due to a lack of data or appropriate features. To address this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking and show that it corresponds to a group-wise fair lottery among the relevant options even
    
[^25]: InPars-Light:成本效益高的无监督训练高效排名器

    InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers

    [https://arxiv.org/abs/2301.02998](https://arxiv.org/abs/2301.02998)

    InPars-Light是一个简单而有效的修改，通过使用小得多的排名模型和免费语言模型BLOOM，在多个英文检索集合上显著改进了排名性能。

    

    我们开展了对InPars的可重现性研究，这是一种用于无监督训练神经排名器的方法。作为副产品，我们开发出了InPars-Light，这是对InPars的简单而有效的修改。与InPars不同，InPars-Light使用7-100倍更小的排名模型，并且只需要一个免费提供的语言模型BLOOM，我们发现，与专有的GPT-3模型相比，BLOOM能够产生更准确的排名器。在所有五个英文检索集合上，我们仅使用一个30M参数六层MiniLM-30M排名器和一个三选俩的提示，在nDCG和MRR方面，相比BM25，我们都获得了显著的（7%-30%）且具有统计学意义的改进。相反，在InPars的研究中，只有一个大100倍的monoT5-3B模型能够始终胜过BM25，而小得多的monoT5-220M模型（仍然比我们的MiniLM排名器大7倍）只是在MS MAR上胜过BM25。

    arXiv:2301.02998v2 Announce Type: replace-cross  Abstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MAR
    
[^26]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    

