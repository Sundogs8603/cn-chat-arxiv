# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports.](http://arxiv.org/abs/2401.01883) | 本文的目标是通过分析网络威胁情报报告，从过去的网络攻击行为中挖掘出时间攻击模式，以帮助安全从业人员优先处理和主动防御网络攻击。 |
| [^2] | [Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR).](http://arxiv.org/abs/2401.01835) | 本论文介绍了一种迭代的检索增强生成系统，通过并发的头脑风暴和假设满足相结合的策略，加快了高度相关文档的检索，并简化了查询的生成过程，提高了处理效率和准确性。 |
| [^3] | [Physio: An LLM-Based Physiotherapy Advisor.](http://arxiv.org/abs/2401.01825) | Physio是一种基于LLM的物理治疗顾问应用程序，它结合了生成模型的语言处理能力，并在回答中引用可靠的健康来源，能够进行诊断、推荐康复运动和非处方药物以缓解症状。 |
| [^4] | [Evaluating Trustworthiness of Online News Publishers via Article Classification.](http://arxiv.org/abs/2401.01781) | 本研究通过文章分类来评估在线新闻发布者的可信度，结果表明分类模型在分类新闻文章的可信度方面非常有效。可应用于提醒读者不可信的新闻来源、协助新闻组织评估媒体机构和选择可信的文章。 |
| [^5] | [Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering.](http://arxiv.org/abs/2401.01780) | 本文提出了一种新的大型语言模型，通过让模型自我评估是否需要查询外部资源，来优化封闭式问答中的幻觉问题。研究者通过引入幻觉屏蔽机制以及参数高效微调的方法，实现了该模型。 |
| [^6] | [Text mining arXiv: a look through quantitative finance papers.](http://arxiv.org/abs/2401.01751) | 本文通过文本挖掘技术和自然语言处理方法，研究了arXiv上的量化金融论文，发现了关于该领域的时间趋势、最常被引用的研究人员和期刊，以及不同算法进行主题建模的比较。 |
| [^7] | [Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2401.01711) | 本论文评估了尚未在知识图谱对话问答任务上进行预训练的大型语言模型的性能，并通过实验证明了这些模型在生成图查询方面的能力以及通过少量提示和微调技术可以显著改善其性能。 |
| [^8] | [GPT-4V(ision) is a Generalist Web Agent, if Grounded.](http://arxiv.org/abs/2401.01614) | GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。 |
| [^9] | [Team IELAB at TREC Clinical Trial Track 2023: Enhancing Clinical Trial Retrieval with Neural Rankers and Large Language Models.](http://arxiv.org/abs/2401.01566) | Team IELAB在2023年TREC临床试验跟踪中采用神经排序器和大型语言模型的方法提升了临床试验检索的效果，通过使用ChatGPT生成合成数据集和整合交叉编码器重新排序器，实现了PubmedBERT的强大排序器的集成，为临床试验检索带来了新的方法。 |
| [^10] | [Poisoning Attacks against Recommender Systems: A Survey.](http://arxiv.org/abs/2401.01527) | 本调查论文系统地、最新地回顾了针对推荐系统的毒化攻击研究领域，提出了一个新颖而全面的分类法，展示了潜在的未来研究方向，并引入了一个开源库ARLib用于比较毒化攻击方法。 |
| [^11] | [Expected Transaction Value Optimization for Precise Marketing in FinTech Platforms.](http://arxiv.org/abs/2401.01525) | 金融科技平台需要解决的问题是如何在推广互联网基金时预测投资金额的变动，以最大化每个客户的交易金额。 |
| [^12] | [Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments: A RAG Model Implementation for Multicultural Enterprise.](http://arxiv.org/abs/2401.01511) | 本文实现了在多元文化企业中使用RAG模型进行信息检索的关键挑战，包括数据供给策略、幻觉缓解和错误响应预防等方面。 |
| [^13] | [A Pre-trained Sequential Recommendation Framework: Popularity Dynamics for Zero-shot Transfer.](http://arxiv.org/abs/2401.01497) | 本文提出了一个预训练的顺序推荐框架PrepRec，通过建模物品流行度动态学习通用物品表示。在大量实验证明，PrepRec可以零-shot迁移到新领域，并且在模型大小上只有很小一部分，并且实现了竞争性的性能。 |
| [^14] | [A First Look at Information Highlighting in Stack Overflow Answers.](http://arxiv.org/abs/2401.01472) | 本论文进行了首次大规模的探索性研究，研究了Stack Overflow回答中的信息高亮。通过使用神经网络架构，开发了自动推荐突出内容的方法。 |
| [^15] | [RL-MPCA: A Reinforcement Learning Based Multi-Phase Computation Allocation Approach for Recommender Systems.](http://arxiv.org/abs/2401.01369) | RL-MPCA是一种基于强化学习的多阶段计算分配方法，用于解决推荐系统中在计算资源有限情况下的计算成本和业务收益之间的权衡问题。 |
| [^16] | [Efficient Indexing of Meta-Data (Extracted from Educational Videos).](http://arxiv.org/abs/2401.01356) | 这项研究旨在通过元数据索引教育视频，帮助全球各地的学生高效利用这些视频资源。 |
| [^17] | [Unlocking the Potential of Large Language Models for Explainable Recommendations.](http://arxiv.org/abs/2312.15661) | 本研究提出了LLMXRec框架，一种简单而有效的两阶段解释推荐方法，利用大型语言模型进一步提升解释质量，通过与先前的推荐模型密切协作，在推荐效果和解释质量方面取得了显著提升。 |
| [^18] | [Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset.](http://arxiv.org/abs/2311.07878) | 本文在基于文档的问答任务中评估了LLM的性能，包括精确答案选择和数字提取。研究发现LLM在单选题和是非题上的效果较好，展示了其在信息检索任务中的有效性。 |
| [^19] | [GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval.](http://arxiv.org/abs/2310.05195) | GMMFormer是一种基于高斯混合模型的Transformer，用于高效的部分相关视频检索。它通过隐式建模剪辑表示，采用多尺度剪辑信息，并引入了一个多样性损失函数来解决语义差异导致的稀疏嵌入空间问题。 |

# 详细

[^1]: 从网络威胁情报报告中挖掘时间攻击模式

    Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports. (arXiv:2401.01883v1 [cs.CR])

    [http://arxiv.org/abs/2401.01883](http://arxiv.org/abs/2401.01883)

    本文的目标是通过分析网络威胁情报报告，从过去的网络攻击行为中挖掘出时间攻击模式，以帮助安全从业人员优先处理和主动防御网络攻击。

    

    防御网络攻击要求从高级对手行为入手。过去的网络攻击事件的网络威胁情报(CTI)报告描述了恶意行动的时间链。为了避免重复发生网络攻击事件，从过去的网络攻击行为中主动识别和防御重复链式行动 - 我们将其称为时间攻击模式。自动挖掘行动之间的模式提供了关于过去网络攻击的对手行为的结构化和可操作的信息。本文旨在通过从网络威胁情报报告中挖掘时间攻击模式，帮助安全从业人员优先处理和主动防御网络攻击。为此，我们提出了ChronoCTI，一个自动化的管道，用于从过去的网络威胁情报(CTI)报告中挖掘时间攻击模式。为构建ChronoCTI，我们构建了时间攻击模式的基准数据集，并应用了最先进的技术。

    Defending from cyberattacks requires practitioners to operate on high-level adversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattack incidents describe the chain of malicious actions with respect to time. To avoid repeating cyberattack incidents, practitioners must proactively identify and defend against recurring chain of actions - which we refer to as temporal attack patterns. Automatically mining the patterns among actions provides structured and actionable information on the adversary behavior of past cyberattacks. The goal of this paper is to aid security practitioners in prioritizing and proactive defense against cyberattacks by mining temporal attack patterns from cyberthreat intelligence reports. To this end, we propose ChronoCTI, an automated pipeline for mining temporal attack patterns from cyberthreat intelligence (CTI) reports of past cyberattacks. To construct ChronoCTI, we build the ground truth dataset of temporal attack patterns and apply state-of-
    
[^2]: 并发头脑风暴和假设满足：一种增强检索增强生成的迭代框架

    Concurrent Brainstorming & Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR). (arXiv:2401.01835v1 [cs.IT])

    [http://arxiv.org/abs/2401.01835](http://arxiv.org/abs/2401.01835)

    本论文介绍了一种迭代的检索增强生成系统，通过并发的头脑风暴和假设满足相结合的策略，加快了高度相关文档的检索，并简化了查询的生成过程，提高了处理效率和准确性。

    

    为了解决全面信息检索的复杂性，本研究引入了一种创新的迭代检索增强生成系统。我们的方法独特地将向量空间驱动的重新排名机制与并发的头脑风暴相结合，加快高度相关文档的检索，从而简化潜在查询的生成。这为我们的新颖混合过程铺平了道路，该过程以假设形成和满足决策策略相结合，利用基于思维链的提示技术确定内容的充分性。这个统一的假设满意阶段智能地提炼信息，确定用户的查询是否得到满意的解答。达到这个标准后，系统将其输出精炼为简洁的表示形式，最大限度地提高概念密度，同时减少冗长。迭代的工作流增强了处理效率和准确性。

    Addressing the complexity of comprehensive information retrieval, this study introduces an innovative, iterative retrieval-augmented generation system. Our approach uniquely integrates a vector-space driven re-ranking mechanism with concurrent brainstorming to expedite the retrieval of highly relevant documents, thereby streamlining the generation of potential queries. This sets the stage for our novel hybrid process, which synergistically combines hypothesis formulation with satisfying decision-making strategy to determine content adequacy, leveraging a chain of thought-based prompting technique. This unified hypothesize-satisfied phase intelligently distills information to ascertain whether user queries have been satisfactorily addressed. Upon reaching this criterion, the system refines its output into a concise representation, maximizing conceptual density with minimal verbosity. The iterative nature of the workflow enhances process efficiency and accuracy. Crucially, the concurrenc
    
[^3]: Physio:一种基于LLM的物理治疗顾问

    Physio: An LLM-Based Physiotherapy Advisor. (arXiv:2401.01825v1 [cs.CL])

    [http://arxiv.org/abs/2401.01825](http://arxiv.org/abs/2401.01825)

    Physio是一种基于LLM的物理治疗顾问应用程序，它结合了生成模型的语言处理能力，并在回答中引用可靠的健康来源，能够进行诊断、推荐康复运动和非处方药物以缓解症状。

    

    最新语言模型的能力增加了将它们整合到实际应用中的兴趣。然而，这些模型生成的合理但不正确的文本事实在考虑在几个领域使用它们时会造成限制。医疗保健是一个要求文本生成可信度的领域的典型例子，以保障患者的健康。在本文中，我们介绍了Physio，一种用于物理康复的基于聊天的应用程序。Physio能够进行初步诊断，并引用可靠的健康来源来支持提供的信息。此外，Physio还可以借助外部知识数据库推荐康复运动和非处方药物以缓解症状。通过结合这些功能，Physio可以利用生成模型进行语言处理，同时将其回复条件化为可靠和可验证的来源。Physio的在线演示可在https://phys访问。

    The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://phys
    
[^4]: 通过文章分类评估在线新闻发布者的可信度

    Evaluating Trustworthiness of Online News Publishers via Article Classification. (arXiv:2401.01781v1 [cs.IR])

    [http://arxiv.org/abs/2401.01781](http://arxiv.org/abs/2401.01781)

    本研究通过文章分类来评估在线新闻发布者的可信度，结果表明分类模型在分类新闻文章的可信度方面非常有效。可应用于提醒读者不可信的新闻来源、协助新闻组织评估媒体机构和选择可信的文章。

    

    当今信息时代低质量的在线信息泛滥，强调了需要强大而自动的机制来评估在线新闻发布者的可信度。本文通过利用来自40个不同来源的4033条新闻故事的数据集，分析在线新闻媒体机构的可信度。我们的目标是根据个别文章的内容分类来推断来源的可信度水平。可信度标签来自NewsGuard，一个通过识别新闻来源使用良好的编辑和出版标准的新闻组织。结果表明，分类模型在分类新闻文章的可信度水平方面非常有效。这项研究在提醒读者可能不可信的新闻来源、协助新闻组织评估新的或不熟悉的媒体机构以及支持选择具有可信度的文章方面具有实际应用价值。

    The proliferation of low-quality online information in today's era has underscored the need for robust and automatic mechanisms to evaluate the trustworthiness of online news publishers. In this paper, we analyse the trustworthiness of online news media outlets by leveraging a dataset of 4033 news stories from 40 different sources. We aim to infer the trustworthiness level of the source based on the classification of individual articles' content. The trust labels are obtained from NewsGuard, a journalistic organization that evaluates news sources using well-established editorial and publishing criteria. The results indicate that the classification model is highly effective in classifying the trustworthiness levels of the news articles. This research has practical applications in alerting readers to potentially untrustworthy news sources, assisting journalistic organizations in evaluating new or unfamiliar media outlets and supporting the selection of articles for their trustworthiness 
    
[^5]: 在封闭式问答中优化API依赖以减少幻觉的不确定性导航

    Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering. (arXiv:2401.01780v1 [cs.CL])

    [http://arxiv.org/abs/2401.01780](http://arxiv.org/abs/2401.01780)

    本文提出了一种新的大型语言模型，通过让模型自我评估是否需要查询外部资源，来优化封闭式问答中的幻觉问题。研究者通过引入幻觉屏蔽机制以及参数高效微调的方法，实现了该模型。

    

    尽管大型语言模型(LLM)能够积累和恢复知识，但它们仍然容易产生幻觉。特别是在面对事实性问题时，LLM不能仅仅依靠参数中存储的知识来保证真实和正确的答案。将这些模型与搜索外部信息源(如网络)的能力相结合，是一种将知识基于检索信息的有希望的方法。然而，在大量文档中进行搜索会带来额外的计算/时间成本。最佳策略是只有在LLM对答案不确定时才查询外部资源。在本文中，我们提出了一种新的LLM，能够自我评估是否能够直接回答问题或者需要请求外部工具。我们通过在闭书问答任务中引入幻觉屏蔽机制来进行监督学习。此外，我们还提出利用参数高效微调的方法。

    While Large Language Models (LLM) are able to accumulate and restore knowledge, they are still prone to hallucination. Especially when faced with factual questions, LLM cannot only rely on knowledge stored in parameters to guarantee truthful and correct answers. Augmenting these models with the ability to search on external information sources, such as the web, is a promising approach to ground knowledge to retrieve information. However, searching in a large collection of documents introduces additional computational/time costs. An optimal behavior would be to query external resources only when the LLM is not confident about answers. In this paper, we propose a new LLM able to self-estimate if it is able to answer directly or needs to request an external tool. We investigate a supervised approach by introducing a hallucination masking mechanism in which labels are generated using a close book question-answering task. In addition, we propose to leverage parameter-efficient fine-tuning t
    
[^6]: 文本挖掘arXiv：对量化金融论文的观察

    Text mining arXiv: a look through quantitative finance papers. (arXiv:2401.01751v1 [cs.DL])

    [http://arxiv.org/abs/2401.01751](http://arxiv.org/abs/2401.01751)

    本文通过文本挖掘技术和自然语言处理方法，研究了arXiv上的量化金融论文，发现了关于该领域的时间趋势、最常被引用的研究人员和期刊，以及不同算法进行主题建模的比较。

    

    本文利用文本挖掘技术和自然语言处理方法，探索了arXiv预印本服务器上的论文，旨在发现这个庞大的研究集合中隐藏的有价值的见解。我们研究了从1997年到2022年在arXiv上发布的量化金融论文的内容。我们从整个文档中提取和分析关键信息，包括引用，以了解随时间变化的主题趋势，并找出这个领域中最常被引用的研究人员和期刊。此外，我们还比较了多种算法来进行主题建模，包括最先进的方法。

    This paper explores articles hosted on the arXiv preprint server with the aim to uncover valuable insights hidden in this vast collection of research. Employing text mining techniques and through the application of natural language processing methods, we examine the contents of quantitative finance papers posted in arXiv from 1997 to 2022. We extract and analyze crucial information from the entire documents, including the references, to understand the topics trends over time and to find out the most cited researchers and journals on this domain. Additionally, we compare numerous algorithms to perform topic modeling, including state-of-the-art approaches.
    
[^7]: 在语义解析中评估大型语言模型在基于知识图谱的对话问答中的应用

    Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2401.01711v1 [cs.CL])

    [http://arxiv.org/abs/2401.01711](http://arxiv.org/abs/2401.01711)

    本论文评估了尚未在知识图谱对话问答任务上进行预训练的大型语言模型的性能，并通过实验证明了这些模型在生成图查询方面的能力以及通过少量提示和微调技术可以显著改善其性能。

    

    会话式问答系统通常依赖语义解析来实现交互式信息检索，该过程涉及将自然语言输入转化为结构化数据库查询。对于知识图谱中存储的事实的信息检索对话，对话表达被转化为图查询的过程被称为基于知识的对话问答。本文评估了尚未明确在此任务上进行预训练的大型语言模型的性能。通过在广泛的基准数据集上进行一系列实验，我们比较了不同大小和提示技术的模型，并识别出生成输出中常见的问题类型。我们的结果表明，大型语言模型能够从对话中生成图查询，通过少量提示和微调技术可以显著提高性能，特别是对于展示较低零样本性能的较小模型。

    Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-sho
    
[^8]: GPT-4V(ision)是一个通用的网络代理，如果有基础的话。

    GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])

    [http://arxiv.org/abs/2401.01614](http://arxiv.org/abs/2401.01614)

    GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。

    

    最近对大型多模型（LMM）的研究，特别是GPT-4V(ision)和Gemini，快速推动了多模型的能力边界超越传统任务，如图像字幕和视觉问答。在这项工作中，我们探索了像GPT-4V这样的LMM作为通用网络代理的潜力，可以根据自然语言指令在任何给定的网站上完成任务。我们提出了SEEACT，一种利用LMM的力量进行综合视觉理解和网页操作的通用网络代理。我们在最新的MIND2WEB基准上进行评估。除了对缓存网站的标准离线评估外，我们还通过开发一个允许在实时网站上运行网络代理的工具，实现了一种新的在线评估设置。我们展示了GPT-4V在网页代理方面表现出巨大的潜力-如果我们将其文本计划手动地实施为网站上的行动，它可以成功地完成50%的任务。此结果明显超过了传统方法。

    The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms
    
[^9]: Team IELAB在TREC临床试验跟踪2023中的研究：利用神经排序器和大型语言模型提升临床试验检索能力。

    Team IELAB at TREC Clinical Trial Track 2023: Enhancing Clinical Trial Retrieval with Neural Rankers and Large Language Models. (arXiv:2401.01566v1 [cs.IR])

    [http://arxiv.org/abs/2401.01566](http://arxiv.org/abs/2401.01566)

    Team IELAB在2023年TREC临床试验跟踪中采用神经排序器和大型语言模型的方法提升了临床试验检索的效果，通过使用ChatGPT生成合成数据集和整合交叉编码器重新排序器，实现了PubmedBERT的强大排序器的集成，为临床试验检索带来了新的方法。

    

    我们介绍了澳大利亚联邦科学与工业研究组织（CSIRO）和昆士兰大学团队ielab在2023年TREC临床试验跟踪中的方法。我们的方法是使用神经排序器，但利用大型语言模型来解决这类排序器缺乏训练数据的问题。具体而言，我们采用ChatGPT从语料库中生成与随机选择的临床试验相关的患者描述。这个合成数据集与之前几年的人工注释训练数据结合，用于基于PubmedBERT的稠密和稀疏检索器的训练。此外，还将一个交叉编码器重新排序器集成到系统中。为了进一步提升我们的方法的有效性，我们使用GPT-4作为TREC注释器提供对我们的运行文件的判断。这些判断结果随后被用来重新排序结果。这种架构将强大的基于PubmedBERT的排序器与最先进的大型语言模型紧密集成在一起，展示了一个新的临床试验检索方法。

    We describe team ielab from CSIRO and The University of Queensland's approach to the 2023 TREC Clinical Trials Track. Our approach was to use neural rankers but to utilise Large Language Models to overcome the issue of lack of training data for such rankers. Specifically, we employ ChatGPT to generate relevant patient descriptions for randomly selected clinical trials from the corpus. This synthetic dataset, combined with human-annotated training data from previous years, is used to train both dense and sparse retrievers based on PubmedBERT. Additionally, a cross-encoder re-ranker is integrated into the system. To further enhance the effectiveness of our approach, we prompting GPT-4 as a TREC annotator to provide judgments on our run files. These judgments are subsequently employed to re-rank the results. This architecture tightly integrates strong PubmedBERT-based rankers with the aid of SOTA Large Language Models, demonstrating a new approach to clinical trial retrieval.
    
[^10]: 推荐系统中的恶意攻击：一项调查

    Poisoning Attacks against Recommender Systems: A Survey. (arXiv:2401.01527v1 [cs.IR])

    [http://arxiv.org/abs/2401.01527](http://arxiv.org/abs/2401.01527)

    本调查论文系统地、最新地回顾了针对推荐系统的毒化攻击研究领域，提出了一个新颖而全面的分类法，展示了潜在的未来研究方向，并引入了一个开源库ARLib用于比较毒化攻击方法。

    

    现代推荐系统取得了显著的成功，但它们仍然容易受到恶意活动的攻击，特别是毒化攻击。这些攻击涉及将恶意数据注入到推荐系统的训练数据集中，从而损害其完整性，并通过操纵推荐结果来获取非法利润。本调查论文系统地、最新地回顾了针对推荐系统的毒化攻击研究领域。我们提出了一个新颖而全面的分类法，将现有的毒化攻击方法分为三个不同的类别：组件特定、目标驱动和能力探测。对于每个类别，我们详细讨论了其机制以及相关方法。此外，本文还突出了该领域的潜在未来研究方向。另外，为了促进和基准测试毒化攻击的实证比较，我们引入了一个开源库ARLib，该库包含了一整套毒化攻击模型和常用的测试数据集。

    Modern recommender systems have seen substantial success, yet they remain vulnerable to malicious activities, notably poisoning attacks. These attacks involve injecting malicious data into the training datasets of RS, thereby compromising their integrity and manipulating recommendation outcomes for gaining illicit profits. This survey paper provides a systematic and up-to-date review of the research landscape on Poisoning Attacks against Recommendation (PAR). A novel and comprehensive taxonomy is proposed, categorizing existing PAR methodologies into three distinct categories: Component-Specific, Goal-Driven, and Capability Probing. For each category, we discuss its mechanism in detail, along with associated methods. Furthermore, this paper highlights potential future research avenues in this domain. Additionally, to facilitate and benchmark the empirical comparison of PAR, we introduce an open-source library, ARLib, which encompasses a comprehensive collection of PAR models and common
    
[^11]: 面向精细化营销的金融科技平台预期交易价值优化

    Expected Transaction Value Optimization for Precise Marketing in FinTech Platforms. (arXiv:2401.01525v1 [cs.IR])

    [http://arxiv.org/abs/2401.01525](http://arxiv.org/abs/2401.01525)

    金融科技平台需要解决的问题是如何在推广互联网基金时预测投资金额的变动，以最大化每个客户的交易金额。

    

    金融科技平台通过数字支付实现的互联网金融服务正迅速增长，通过移动应用向个人投资者提供个性化的互联网基金分销。作为金融产品投资的重要中介，这些平台在基金公司的要求下，以保证交付（GD）策略分发数千只互联网基金。平台通过推广互联网基金给有兴趣的投资者来推动用户的基金购买，从而最大化每个客户的交易金额。与传统广告或电子商务推荐中的转化不同，每次购买中的投资金额甚至对于相同的金融产品来说也差异很大，这给互联网基金的推广推荐提供了重大挑战。在传统推荐中，除了预测点击率（CTR）或转化率（CVR）外，对于金融科技平台来说，预测每次购买的投资金额同样很重要。

    FinTech platforms facilitated by digital payments are watching growth rapidly, which enable the distribution of mutual funds personalized to individual investors via mobile Apps. As the important intermediation of financial products investment, these platforms distribute thousands of mutual funds obtaining impressions under guaranteed delivery (GD) strategy required by fund companies. Driven by the profit from fund purchases of users, the platform aims to maximize each transaction amount of customers by promoting mutual funds to these investors who will be interested in. Different from the conversions in traditional advertising or e-commerce recommendations, the investment amount in each purchase varies greatly even for the same financial product, which provides a significant challenge for the promotion recommendation of mutual funds. In addition to predicting the click-through rate (CTR) or the conversion rate (CVR) as in traditional recommendations, it is essential for FinTech platfo
    
[^12]: 在多元化人力资源环境中提升多语言信息检索：多元文化企业中RAG模型的实现

    Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments: A RAG Model Implementation for Multicultural Enterprise. (arXiv:2401.01511v1 [cs.IR])

    [http://arxiv.org/abs/2401.01511](http://arxiv.org/abs/2401.01511)

    本文实现了在多元文化企业中使用RAG模型进行信息检索的关键挑战，包括数据供给策略、幻觉缓解和错误响应预防等方面。

    

    大型语言模型的出现彻底改变了信息检索，带来了广泛的知识获取能力的新时代。虽然这些模型在提供开放世界知识方面表现出色，但在具有不同读写能力的多语言环境中有效提取答案仍然是一个严峻的挑战。检索增强生成（RAG）成为一种有希望的解决方案，弥合了信息可获取性和多语言理解之间的差距。然而，将RAG模型部署到现实世界的情景中需要仔细考虑各种因素。本文解决了在多元文化环境中实施RAG模型所面临的关键挑战。我们深入探讨了包括数据供给策略、及时更新、幻觉缓解、错误响应预防和交付速度优化在内的关键考虑因素。我们的工作涉及将各种工具整合在一起，细致地组合以便促进无缝运作。

    The advent of Large Language Models has revolutionized information retrieval, ushering in a new era of expansive knowledge accessibility. While these models excel in providing open-world knowledge, effectively extracting answers in diverse linguistic environments with varying levels of literacy remains a formidable challenge. Retrieval Augmented Generation (RAG) emerges as a promising solution, bridging the gap between information availability and multilingual comprehension. However, deploying RAG models in real-world scenarios demands careful consideration of various factors. This paper addresses the critical challenges associated with implementing RAG models in multicultural environments. We delve into essential considerations, including data feeding strategies, timely updates, mitigation of hallucinations, prevention of erroneous responses, and optimization of delivery speed. Our work involves the integration of a diverse array of tools, meticulously combined to facilitate the seaml
    
[^13]: 一个预训练的顺序推荐框架：基于流行度动态的零-shot迁移

    A Pre-trained Sequential Recommendation Framework: Popularity Dynamics for Zero-shot Transfer. (arXiv:2401.01497v1 [cs.IR])

    [http://arxiv.org/abs/2401.01497](http://arxiv.org/abs/2401.01497)

    本文提出了一个预训练的顺序推荐框架PrepRec，通过建模物品流行度动态学习通用物品表示。在大量实验证明，PrepRec可以零-shot迁移到新领域，并且在模型大小上只有很小一部分，并且实现了竞争性的性能。

    

    顺序推荐对于在线应用如电子商务、视频流媒体和社交媒体的成功至关重要。尽管模型架构不断改进，但对于每个新的应用领域，我们仍然需要从头训练一个新模型以获得高质量的推荐。另一方面，预训练的语言和视觉模型已经在零-shot或少-shot适应新应用领域方面取得了巨大成功。受到同行AI领域预训练模型成功的启发，我们提出了一种新颖的预训练顺序推荐框架：PrepRec。我们通过建模物品流行度动态来学习通用物品表示。通过在五个真实世界数据集上的大量实验证明，PrepRec在没有任何辅助信息的情况下不仅能够零-shot迁移到新领域，并且与同类最先进的顺序推荐模型相比，模型大小仅相当一小部分的情况下，可以实现竞争性的性能。

    Sequential recommenders are crucial to the success of online applications, \eg e-commerce, video streaming, and social media. While model architectures continue to improve, for every new application domain, we still have to train a new model from scratch for high quality recommendations. On the other hand, pre-trained language and vision models have shown great success in zero-shot or few-shot adaptation to new application domains. Inspired by the success of pre-trained models in peer AI fields, we propose a novel pre-trained sequential recommendation framework: PrepRec. We learn universal item representations by modeling item popularity dynamics. Through extensive experiments on five real-world datasets, we show that PrepRec, without any auxiliary information, can not only zero-shot transfer to a new domain, but achieve competitive performance compared to state-of-the-art sequential recommender models with only a fraction of the model size. In addition, with a simple post-hoc interpol
    
[^14]: Stack Overflow回答中信息高亮的初探

    A First Look at Information Highlighting in Stack Overflow Answers. (arXiv:2401.01472v1 [cs.CL])

    [http://arxiv.org/abs/2401.01472](http://arxiv.org/abs/2401.01472)

    本论文进行了首次大规模的探索性研究，研究了Stack Overflow回答中的信息高亮。通过使用神经网络架构，开发了自动推荐突出内容的方法。

    

    背景：浏览Stack Overflow（SO）的知识仍然具有挑战性。为了使帖子对用户更生动，SO允许用户使用Markdown或HTML编写和编辑帖子，以便用户可以利用各种格式化样式（例如粗体、斜体和代码）来突出重要信息。然而，关于突出信息的研究仍然有限。目标：我们在最近的研究中进行了首次大规模的探索性研究，研究了SO回答中的信息高亮。为了扩展我们之前的研究，我们利用最初设计用于命名实体识别任务的神经网络架构，开发了自动推荐带有格式化样式的突出内容的方法。方法：本文研究了Stack Overflow的31,169,429个回答。为了训练推荐模型，我们选择了CNN和BERT模型，针对每种格式化类型（即粗体、斜体、代码和标题）使用我们从SO回答收集的突出信息数据集。

    Context: Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or HTML so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information. Objective: We carried out the first large-scale exploratory study on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using neural network architectures initially designed for the Named Entity Recognition task. Method: In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN and BERT models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.
    
[^15]: RL-MPCA: 基于强化学习的多阶段计算分配方法用于推荐系统

    RL-MPCA: A Reinforcement Learning Based Multi-Phase Computation Allocation Approach for Recommender Systems. (arXiv:2401.01369v1 [cs.IR])

    [http://arxiv.org/abs/2401.01369](http://arxiv.org/abs/2401.01369)

    RL-MPCA是一种基于强化学习的多阶段计算分配方法，用于解决推荐系统中在计算资源有限情况下的计算成本和业务收益之间的权衡问题。

    

    推荐系统旨在从大量候选项中向用户推荐最合适的物品。随着用户请求的增加和服务（或模型）的复杂性增加，其计算成本也在增加。在计算资源有限的情况下，如何在计算成本和业务收益之间做出权衡成为一个重要问题。现有的研究集中于在队列截断场景中动态分配计算资源（即分配候选项的大小），并将计算资源分配问题建模为带约束条件的优化问题。其中一些研究集中于单阶段的计算资源分配，而其他研究则集中于多阶段的计算资源分配，但引入了一些关于队列截断场景的假设。然而，这些假设在其他情景下（如检索通道选择和预测模型选择）是不成立的。此外，现有的研究忽略了请求在不同阶段之间的状态转移过程，限制了其有效性。

    Recommender systems aim to recommend the most suitable items to users from a large number of candidates. Their computation cost grows as the number of user requests and the complexity of services (or models) increases. Under the limitation of computation resources (CRs), how to make a trade-off between computation cost and business revenue becomes an essential question. The existing studies focus on dynamically allocating CRs in queue truncation scenarios (i.e., allocating the size of candidates), and formulate the CR allocation problem as an optimization problem with constraints. Some of them focus on single-phase CR allocation, and others focus on multi-phase CR allocation but introduce some assumptions about queue truncation scenarios. However, these assumptions do not hold in other scenarios, such as retrieval channel selection and prediction model selection. Moreover, existing studies ignore the state transition process of requests between different phases, limiting the effectiven
    
[^16]: 教育视频元数据的高效索引

    Efficient Indexing of Meta-Data (Extracted from Educational Videos). (arXiv:2401.01356v1 [cs.IR])

    [http://arxiv.org/abs/2401.01356](http://arxiv.org/abs/2401.01356)

    这项研究旨在通过元数据索引教育视频，帮助全球各地的学生高效利用这些视频资源。

    

    随着在线教育教室教学的普及，视频讲座越来越受欢迎和需求增加。如NPTEL等大规模在线开放课程（MOOCs）已经创建了高质量的教育内容，学生可以免费在线访问。全国许多大学现在都在课堂上使用NPTEL视频。因此，越来越多的视频讲座正在被记录、维护和上传。这些视频通常在讲座开始前包含有关该视频的信息。我们通常观察到，这些教育视频具有包含五到六个属性的元数据：学院名称、出版商名称、系别名称、教授名称、学科名称和主题名称。如果我们能按照它们的类别组织这些视频，将更容易维护这些视频。根据这些信息对这些视频进行索引对世界各地的学生高效利用这些视频非常有益。在这个项目中，我们尝试获取元数据信息来构建一个高效的视频索引。

    Video lectures are becoming more popular and in demand as online classroom teaching is becoming more prevalent. Massive Open Online Courses (MOOCs), such as NPTEL, have been creating high-quality educational content that is freely accessible to students online. A large number of colleges across the country are now using NPTEL videos in their classrooms. So more video lectures are being recorded, maintained, and uploaded. These videos generally contain information about that video before the lecture begins. We generally observe that these educational videos have metadata containing five to six attributes: Institute Name, Publisher Name, Department Name, Professor Name, Subject Name, and Topic Name. It would be easy to maintain these videos if we could organize them according to their categories. The indexing of these videos based on this information is beneficial for students all around the world to efficiently utilise these videos. In this project, we are trying to get the metadata inf
    
[^17]: 大型语言模型在可解释推荐中的潜力解锁

    Unlocking the Potential of Large Language Models for Explainable Recommendations. (arXiv:2312.15661v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2312.15661](http://arxiv.org/abs/2312.15661)

    本研究提出了LLMXRec框架，一种简单而有效的两阶段解释推荐方法，利用大型语言模型进一步提升解释质量，通过与先前的推荐模型密切协作，在推荐效果和解释质量方面取得了显著提升。

    

    生成关于为何推荐某个项目的用户友好解释已经变得越来越常见，这主要归功于语言生成技术的进步，这可以增强用户的信任并在使用在线服务时促进更明智的决策。然而，现有的可解释推荐系统主要使用小型语言模型。目前尚不清楚将解释生成器替换为最近出现的大型语言模型（LLMs）会产生何种影响。我们能否期望前所未有的结果？在这项研究中，我们提出了LLMXRec，一个简单而有效的两阶段可解释推荐框架，旨在通过使用LLMs进一步提高解释质量。与大多数现有的基于LLM的推荐工作不同，LLMXRec的一个重要特点是它强调先前的推荐模型与基于LLM的解释生成器之间的密切协作。具体而言，通过采用几种关键的微调技术，包括参数调优技术，我们的方法在推荐效果和解释质量方面实现了显著提升。

    Generating user-friendly explanations regarding why an item is recommended has become increasingly common, largely due to advances in language generation technology, which can enhance user trust and facilitate more informed decision-making when using online services. However, existing explainable recommendation systems focus on using small-size language models. It remains uncertain what impact replacing the explanation generator with the recently emerging large language models (LLMs) would have. Can we expect unprecedented results?  In this study, we propose LLMXRec, a simple yet effective two-stage explainable recommendation framework aimed at further boosting the explanation quality by employing LLMs. Unlike most existing LLM-based recommendation works, a key characteristic of LLMXRec is its emphasis on the close collaboration between previous recommender models and LLM-based explanation generators. Specifically, by adopting several key fine-tuning techniques, including parameter-eff
    
[^18]: 在基于文档的问答任务中评估LLM：使用Cogtale数据集进行精确答案选择和数字提取

    Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset. (arXiv:2311.07878v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.07878](http://arxiv.org/abs/2311.07878)

    本文在基于文档的问答任务中评估了LLM的性能，包括精确答案选择和数字提取。研究发现LLM在单选题和是非题上的效果较好，展示了其在信息检索任务中的有效性。

    

    基于文档的问答任务对于精确的信息检索至关重要。虽然一些已有的工作关注评估大型语言模型在从文档中检索和回答问题的性能，但对于需要从预定义选项中选择精确答案和进行数字提取的QA类型，LLM的性能尚未得到充分评估。本文特别关注这个未深入研究的背景，并对LLM（GPT-4和GPT-3.5）在单选题、是非题、多选题和数字提取问题等问答类型上进行实证分析，使用CogTale数据集进行评估。该数据集提供了人工专家标注的答案，为精确性和事实依据提供了强有力的基准。我们发现LLM，尤其是GPT-4，在相关背景下可以准确回答许多单选题和是非题，展示了它们在信息检索任务中的有效性。

    Document-based Question-Answering (QA) tasks are crucial for precise information retrieval. While some existing work focus on evaluating large language models performance on retrieving and answering questions from documents, assessing the LLMs performance on QA types that require exact answer selection from predefined options and numerical extraction is yet to be fully assessed. In this paper, we specifically focus on this underexplored context and conduct empirical analysis of LLMs (GPT-4 and GPT-3.5) on question types, including single-choice, yes-no, multiple-choice, and number extraction questions from documents in zero-shot setting. We use the CogTale dataset for evaluation, which provide human expert-tagged responses, offering a robust benchmark for precision and factual grounding. We found that LLMs, particularly GPT-4, can precisely answer many single-choice and yes-no questions given relevant context, demonstrating their efficacy in information retrieval tasks. However, their 
    
[^19]: GMMFormer: 基于高斯混合模型的Transformer用于高效的部分相关视频检索

    GMMFormer: Gaussian-Mixture-Model Based Transformer for Efficient Partially Relevant Video Retrieval. (arXiv:2310.05195v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05195](http://arxiv.org/abs/2310.05195)

    GMMFormer是一种基于高斯混合模型的Transformer，用于高效的部分相关视频检索。它通过隐式建模剪辑表示，采用多尺度剪辑信息，并引入了一个多样性损失函数来解决语义差异导致的稀疏嵌入空间问题。

    

    在给定一个文本查询的情况下，部分相关视频检索（PRVR）旨在在数据库中找到包含相关片段的未剪辑视频。对于PRVR，剪辑建模对于捕捉文本和视频之间的部分关系至关重要。当前的PRVR方法采用基于扫描的剪辑构建来实现显式剪辑建模，这种方法的信息冗余且需要大量的存储开销。为了解决PRVR方法的效率问题，本文提出了GMMFormer，一种基于高斯混合模型的Transformer，它隐式地建模了剪辑表示。在帧交互过程中，我们采用高斯混合模型约束，使每个帧专注于其相邻帧而不是整个视频。然后生成的表示将包含多尺度的剪辑信息，实现隐式剪辑建模。此外，PRVR方法忽视了与同一视频相关的文本查询之间的语义差异，导致稀疏的嵌入空间。我们提出了一个多样性损失函数来解决这个问题。

    Given a text query, partially relevant video retrieval (PRVR) seeks to find untrimmed videos containing pertinent moments in a database. For PRVR, clip modeling is essential to capture the partial relationship between texts and videos. Current PRVR methods adopt scanning-based clip construction to achieve explicit clip modeling, which is information-redundant and requires a large storage overhead. To solve the efficiency problem of PRVR methods, this paper proposes GMMFormer, a Gaussian-Mixture-Model based Transformer which models clip representations implicitly. During frame interactions, we incorporate Gaussian-Mixture-Model constraints to focus each frame on its adjacent frames instead of the whole video. Then generated representations will contain multi-scale clip information, achieving implicit clip modeling. In addition, PRVR methods ignore semantic differences between text queries relevant to the same video, leading to a sparse embedding space. We propose a query diverse loss to
    

