# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generative-Contrastive Heterogeneous Graph Neural Network](https://arxiv.org/abs/2404.02810) | 本研究提出了一种生成-对比异构图神经网络，通过对比视图增强策略、位置感知和语义感知正样本采样策略以及分层对比学习策略来克服图数据增强的限制。 |
| [^2] | [Efficient Multi-Vector Dense Retrieval Using Bit Vectors](https://arxiv.org/abs/2404.02805) | 提出了一种新颖的框架EMVB，利用位向量实现高效的多向量密集检索，通过引入质心交互机制来减少非相关文档，降低排名阶段成本。 |
| [^3] | [Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation](https://arxiv.org/abs/2404.02616) | 通过混合结构化摘要和基于LLM的数据增强方法，改进了主题相关性模型，使其能够更好地学习查询与文档之间的相关度。 |
| [^4] | [The Surprising Effectiveness of Rankers Trained on Expanded Queries](https://arxiv.org/abs/2404.02587) | 通过训练数据集中的扩展和困难查询，本研究提出了一种方法来提高困难查询的排序性能，而不降低其他查询的性能。 |
| [^5] | [Multi-Granularity Guided Fusion-in-Decoder](https://arxiv.org/abs/2404.02581) | 提出了多粒度引导的解码器融合（MGFiD），通过跨多个粒度辨别证据，并结合段落重新排序和句子分类，提高开放域问答中解码效率。 |
| [^6] | [Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset](https://arxiv.org/abs/2404.02543) | 本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。 |
| [^7] | [DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation](https://arxiv.org/abs/2404.02489) | 提出了一种名为DUQGen的方法，利用自动生成的有效和多样化的合成训练数据来进行现代神经排序器的新领域微调 |
| [^8] | [uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?](https://arxiv.org/abs/2404.02474) | 通过研究提示工程方法如何增强LLMs在横向思考任务上的表现，揭示了其固有的超越思维能力，并发现压缩的信息性提示和动态的情境学习显著提升了模型性能。 |
| [^9] | [Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM](https://arxiv.org/abs/2404.02402) | Token Trails是一种利用token-type嵌入导航对话中复杂上下文细微差别的新方法，通过提高对话理解和回复生成效果，在促进上下文意识聊天机器人交互方面具有前沿性能。 |
| [^10] | [A Survey of Web Content Control for Generative AI](https://arxiv.org/abs/2404.02309) | 该研究调查了生成AI领域网站内容控制的现状，提出了解决内容创作者和发布者知识产权保护问题的技术方案和挑战。 |
| [^11] | [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](https://arxiv.org/abs/2404.02261) | 在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。 |
| [^12] | [RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction](https://arxiv.org/abs/2404.02249) | RAT模型是为了解决当前CTR预测模型仅关注样本内特征交互而忽略跨样本关系的问题，通过检索相似样本构建增强输入，实现了对样本内和跨样本的全面特征交互推理，提高了CTR预测的效果。 |
| [^13] | [A Recommender System for NFT Collectibles with Item Feature](https://arxiv.org/abs/2403.18305) | 该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。 |
| [^14] | [An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations](https://arxiv.org/abs/2403.16424) | 该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。 |
| [^15] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^16] | [Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens](https://arxiv.org/abs/2401.17377) | 这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。 |
| [^17] | [SCTc-TE: A Comprehensive Formulation and Benchmark for Temporal Event Forecasting](https://arxiv.org/abs/2312.01052) | SCTc-TE提出了一种全面的时间事件预测形式化方法，并通过构建MidEast-TE数据集和区分各种上下文信息提升了预测方法。 |
| [^18] | [Agent-OM: Leveraging LLM Agents for Ontology Matching](https://arxiv.org/abs/2312.00326) | 本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。 |
| [^19] | [Utilizing Contextual Clues and Role Correlations for Enhancing Document-level Event Argument Extraction](https://arxiv.org/abs/2310.05116) | 本文提出了CARLG模型，通过利用上下文线索和角色相关性，提升了文档级事件论证提取的性能。 |
| [^20] | [Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models.](http://arxiv.org/abs/2401.15269) | 本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。 |
| [^21] | [Navigating Complex Search Tasks with AI Copilots.](http://arxiv.org/abs/2311.01235) | 该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。 |
| [^22] | [Chain-of-Choice Hierarchical Policy Learning for Conversational Recommendation.](http://arxiv.org/abs/2310.17922) | 提出了一种称为MTAMCR的对话推荐问题设定，通过每轮询问涵盖多个属性类型的多选题，提高了互动效率。同时，通过Chain-of-Choice层次化策略学习框架，提高了对话推荐系统的询问效率和推荐效果。 |

# 详细

[^1]: 生成-对比异构图神经网络

    Generative-Contrastive Heterogeneous Graph Neural Network

    [https://arxiv.org/abs/2404.02810](https://arxiv.org/abs/2404.02810)

    本研究提出了一种生成-对比异构图神经网络，通过对比视图增强策略、位置感知和语义感知正样本采样策略以及分层对比学习策略来克服图数据增强的限制。

    

    异构图表达了现实世界中复杂关系，包括多种类型的节点和边。受自监督学习启发，对比异构图神经网络(HGNNs)利用数据增强和辨别器展现了巨大潜力用于下游任务。然而，由于图的离散和抽象特性，数据增强仍然存在限制。为了解决上述限制，我们提出了一种新颖的\textit{生成-对比异构图神经网络(GC-HGNN)}。

    arXiv:2404.02810v1 Announce Type: new  Abstract: Heterogeneous Graphs (HGs) can effectively model complex relationships in the real world by multi-type nodes and edges. In recent years, inspired by self-supervised learning, contrastive Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential by utilizing data augmentation and discriminators for downstream tasks. However, data augmentation is still limited due to the discrete and abstract nature of graphs. To tackle the above limitations, we propose a novel \textit{Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN)}. Specifically, we first propose a heterogeneous graph generative learning enhanced contrastive paradigm. This paradigm includes: 1) A contrastive view augmentation strategy by using masked autoencoder. 2) Position-aware and semantics-aware positive sample sampling strategy for generate hard negative samples. 3) A hierarchical contrastive learning strategy for capturing local and global informa
    
[^2]: 使用位向量进行高效的多向量密集检索

    Efficient Multi-Vector Dense Retrieval Using Bit Vectors

    [https://arxiv.org/abs/2404.02805](https://arxiv.org/abs/2404.02805)

    提出了一种新颖的框架EMVB，利用位向量实现高效的多向量密集检索，通过引入质心交互机制来减少非相关文档，降低排名阶段成本。

    

    密集检索技术利用预训练的大型语言模型构建查询和段落的高维表示，使用高效的相似度措施计算段落相对于查询的相关性。最近，PLAID通过引入基于质心的术语表示来减少多向量体系的内存影响，通过利用质心交互机制，PLAID过滤出非相关文档，从而减少后续排名阶段的成本。本文提出了一种新颖的框架，名为“使用位向量进行高效的多向量密集检索”（EMVB），用于多向量密集检索中的高效查询处理。

    arXiv:2404.02805v1 Announce Type: new  Abstract: Dense retrieval techniques employ pre-trained large language models to build a high-dimensional representation of queries and passages. These representations compute the relevance of a passage w.r.t. to a query using efficient similarity measures. In this line, multi-vector representations show improved effectiveness at the expense of a one-order-of-magnitude increase in memory footprint and query latency by encoding queries and documents on a per-token level. Recently, PLAID has tackled these problems by introducing a centroid-based term representation to reduce the memory impact of multi-vector systems. By exploiting a centroid interaction mechanism, PLAID filters out non-relevant documents, thus reducing the cost of the successive ranking stages. This paper proposes ``Efficient Multi-Vector dense retrieval with Bit vectors'' (EMVB), a novel framework for efficient query processing in multi-vector dense retrieval. First, EMVB employs a
    
[^3]: 通过混合结构化摘要和基于LLM的数据增强来改进主题相关性模型

    Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation

    [https://arxiv.org/abs/2404.02616](https://arxiv.org/abs/2404.02616)

    通过混合结构化摘要和基于LLM的数据增强方法，改进了主题相关性模型，使其能够更好地学习查询与文档之间的相关度。

    

    查询和文档之间的主题相关性是社交搜索的一个非常重要的部分，可以评估文档与用户需求之间的匹配程度。在大多数社交搜索场景中，如大众点评，建模搜索相关性总是面临两个挑战。一个是许多社交搜索中的文档非常长且包含大量冗余信息。另一个问题是搜索相关性模型的训练数据很难获得，尤其是对于多分类相关性模型。为了解决以上两个问题，我们首先将查询与基于查询的摘要以及不带查询的文档摘要合并，作为主题相关性模型的输入，这有助于模型学习查询和文档核心主题之间的相关度。然后，我们利用大型语言模型（LLM）的语言理解和生成能力，从现有训练数据中重新编写和生成查询。

    arXiv:2404.02616v1 Announce Type: cross  Abstract: Topic relevance between query and document is a very important part of social search, which can evaluate the degree of matching between document and user's requirement. In most social search scenarios such as Dianping, modeling search relevance always faces two challenges. One is that many documents in social search are very long and have much redundant information. The other is that the training data for search relevance model is difficult to get, especially for multi-classification relevance model. To tackle above two problems, we first take query concatenated with the query-based summary and the document summary without query as the input of topic relevance model, which can help model learn the relevance degree between query and the core topic of document. Then, we utilize the language understanding and generation abilities of large language model (LLM) to rewrite and generate query from queries and documents in existing training da
    
[^4]: 训练扩展查询的排序器的出乎意料的有效性

    The Surprising Effectiveness of Rankers Trained on Expanded Queries

    [https://arxiv.org/abs/2404.02587](https://arxiv.org/abs/2404.02587)

    通过训练数据集中的扩展和困难查询，本研究提出了一种方法来提高困难查询的排序性能，而不降低其他查询的性能。

    

    文本排序系统中一个重要问题是处理查询分布尾部的困难查询。这种困难可能源于存在不常见、未明确或不完整的查询。在这项工作中，我们通过使用相关文档对训练查询进行了基于LLM的查询扩展来提高困难查询的排序性能，而不损害其他查询的性能。首先，我们基于LLM进行查询丰富化，使用相关文档进行训练。接下来，专门的排序器仅在丰富的困难查询上进行微调，而不是在原始查询上进行微调。我们将来自专门排序器和基本排序器的相关性得分以及为每个查询估计的查询性能得分进行组合。我们的方法不同于通常对所有查询使用单个排序器的现有方法，这些方法对易查询有偏见，易查询构成查询分布的大多数。

    arXiv:2404.02587v1 Announce Type: cross  Abstract: An important problem in text-ranking systems is handling the hard queries that form the tail end of the query distribution. The difficulty may arise due to the presence of uncommon, underspecified, or incomplete queries. In this work, we improve the ranking performance of hard or difficult queries without compromising the performance of other queries. Firstly, we do LLM based query enrichment for training queries using relevant documents. Next, a specialized ranker is fine-tuned only on the enriched hard queries instead of the original queries. We combine the relevance scores from the specialized ranker and the base ranker, along with a query performance score estimated for each query. Our approach departs from existing methods that usually employ a single ranker for all queries, which is biased towards easy queries, which form the majority of the query distribution. In our extensive experiments on the DL-Hard dataset, we find that a p
    
[^5]: 多粒度引导的解码器融合

    Multi-Granularity Guided Fusion-in-Decoder

    [https://arxiv.org/abs/2404.02581](https://arxiv.org/abs/2404.02581)

    提出了多粒度引导的解码器融合（MGFiD），通过跨多个粒度辨别证据，并结合段落重新排序和句子分类，提高开放域问答中解码效率。

    

    在开放域问答中，识别相关上下文作为证据并避免在检索结果中出现虚假上下文至关重要。在解码阶段使用多个上下文进行串联的模型架构（即Fusion-in-Decoder）表现出有希望的性能，但会从看似合理的上下文中生成不正确的输出。为了解决这个问题，我们提出了多粒度引导的解码器融合（MGFiD），跨多个粒度辨别证据。基于多任务学习，MGFiD将段落重新排序与句子分类进行协调。它将明显的句子聚合到一个锚定向量中，指导解码器。此外，它通过重用段落重新排序的结果来提高解码效率进行段落修剪。通过实验证明，MGFiD在自然问答（NQ）和TriviaQA（TQA）数据集上优于现有模型，突显了其优点。

    arXiv:2404.02581v1 Announce Type: new  Abstract: In Open-domain Question Answering (ODQA), it is essential to discern relevant contexts as evidence and avoid spurious ones among retrieved results. The model architecture that uses concatenated multiple contexts in the decoding phase, i.e., Fusion-in-Decoder, demonstrates promising performance but generates incorrect outputs from seemingly plausible contexts. To address this problem, we propose the Multi-Granularity guided Fusion-in-Decoder (MGFiD), discerning evidence across multiple levels of granularity. Based on multi-task learning, MGFiD harmonizes passage re-ranking with sentence classification. It aggregates evident sentences into an anchor vector that instructs the decoder. Additionally, it improves decoding efficiency by reusing the results of passage re-ranking for passage pruning. Through our experiments, MGFiD outperforms existing models on the Natural Questions (NQ) and TriviaQA (TQA) datasets, highlighting the benefits of i
    
[^6]: 无偏向学习排序遇到现实：百度大规模搜索数据集的经验教训

    Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset

    [https://arxiv.org/abs/2404.02543](https://arxiv.org/abs/2404.02543)

    本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。

    

    无偏向学习排序（ULTR）是一个用于学习用户点击数据的成熟框架，而这些数据往往受收集数据的排名者的偏见影响。虽然在理论上得到证明并在模拟中进行了广泛测试，但ULTR技术缺乏经验验证，尤其是在现代搜索引擎中。百度搜索引擎发布的WSDM Cup 2023数据集为评估主要ULTR技术在真实世界中的表现提供了难得的机会。尽管在WSDM Cup 2023期间有多次提交，以及随后的NTCIR ULTRE-2任务，但目前还不清楚观察到的改进是否源自应用ULTR或其他学习技术。我们重新审视并扩展了现有实验。我们发现，无偏向学习排序技术并不能明显提升性能，尤其是与排名损失和查询-文档特征选择带来的明显差异相比。

    arXiv:2404.02543v1 Announce Type: cross  Abstract: Unbiased learning-to-rank (ULTR) is a well-established framework for learning from user clicks, which are often biased by the ranker collecting the data. While theoretically justified and extensively tested in simulation, ULTR techniques lack empirical validation, especially on modern search engines. The dataset released for the WSDM Cup 2023, collected from Baidu's search engine, offers a rare opportunity to assess the real-world performance of prominent ULTR techniques. Despite multiple submissions during the WSDM Cup 2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the observed improvements stem from applying ULTR or other learning techniques. We revisit and extend the available experiments. We find that unbiased learning-to-rank techniques do not bring clear performance improvements, especially compared to the stark differences brought by the choice of ranking loss and query-document features. Our experiments 
    
[^7]: DUQGen: 通过多样化合成查询生成实现神经排序器的有效无监督领域自适应

    DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by Diversifying Synthetic Query Generation

    [https://arxiv.org/abs/2404.02489](https://arxiv.org/abs/2404.02489)

    提出了一种名为DUQGen的方法，利用自动生成的有效和多样化的合成训练数据来进行现代神经排序器的新领域微调

    

    最先进的在大型任务特定训练数据集(如MS-MARCO)上预训练的神经排序器在各种排名任务上表现出色，甚至无需领域自适应即可实现零-shot效果。然而，零-shot神经排序可能不够优化，因为它未利用目标领域信息。为了解决这个问题，我们提出了一种新的用于排名的无监督领域自适应方法DUQGen，填补了先前文献中的一个关键空白，即如何自动生成既有效又多样化的合成训练数据，以微调现代神经排序器适应新领域。具体而言，DUQGen通过识别相似文档的聚类产生了更有效的目标领域表示；并生成了更多元化的trai

    arXiv:2404.02489v1 Announce Type: cross  Abstract: State-of-the-art neural rankers pre-trained on large task-specific training data such as MS-MARCO, have been shown to exhibit strong performance on various ranking tasks without domain adaptation, also called zero-shot. However, zero-shot neural ranking may be sub-optimal, as it does not take advantage of the target domain information. Unfortunately, acquiring sufficiently large and high quality target training data to improve a modern neural ranker can be costly and time-consuming. To address this problem, we propose a new approach to unsupervised domain adaptation for ranking, DUQGen, which addresses a critical gap in prior literature, namely how to automatically generate both effective and diverse synthetic training data to fine tune a modern neural ranker for a new domain. Specifically, DUQGen produces a more effective representation of the target domain by identifying clusters of similar documents; and generates a more diverse tra
    
[^8]: uTeBC-NLP在SemEval-2024任务9中：LLMs能成为横向思考者吗？

    uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?

    [https://arxiv.org/abs/2404.02474](https://arxiv.org/abs/2404.02474)

    通过研究提示工程方法如何增强LLMs在横向思考任务上的表现，揭示了其固有的超越思维能力，并发现压缩的信息性提示和动态的情境学习显著提升了模型性能。

    

    受人类认知启发，Jiang等人（2023c）创建了一个用于评估LLMs横向思维（超越思维定势）的基准。在这一基准的基础上，我们研究了不同的提示方法如何增强LLMs在这一任务上的表现，以揭示其固有的超越思维能力。通过参加SemEval-2024的第9项任务，即句子拼图子任务，我们探讨了提示工程方法：思维链（CoT）和直接提示，使用信息性描述进行增强，并利用检索增强生成（RAG）管道进行情境化提示。我们的实验涉及三种LLMs，包括GPT-3.5、GPT-4和Zephyr-7B-beta。我们使用GPT-4生成了谜题和选项之间的思维路径数据集，并通过人类进行了质量验证。研究结果表明，压缩的信息性提示能够提升模型性能。动态的情境学习显著提升了模型性能。

    arXiv:2404.02474v1 Announce Type: cross  Abstract: Inspired by human cognition, Jiang et al.(2023c) create a benchmark for assessing LLMs' lateral thinking-thinking outside the box. Building upon this benchmark, we investigate how different prompting methods enhance LLMs' performance on this task to reveal their inherent power for outside-the-box thinking ability. Through participating in SemEval-2024, task 9, Sentence Puzzle sub-task, we explore prompt engineering methods: chain of thoughts (CoT) and direct prompting, enhancing with informative descriptions, and employing contextualizing prompts using a retrieval augmented generation (RAG) pipeline. Our experiments involve three LLMs including GPT-3.5, GPT-4, and Zephyr-7B-beta. We generate a dataset of thinking paths between riddles and options using GPT-4, validated by humans for quality. Findings indicate that compressed informative prompts enhance performance. Dynamic in-context learning enhances model performance significantly. F
    
[^9]: 使用ChatLLM在对话AI中导航语境深度的Token Trails

    Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM

    [https://arxiv.org/abs/2404.02402](https://arxiv.org/abs/2404.02402)

    Token Trails是一种利用token-type嵌入导航对话中复杂上下文细微差别的新方法，通过提高对话理解和回复生成效果，在促进上下文意识聊天机器人交互方面具有前沿性能。

    

    使用大型语言模型(LLMs)进行对话建模需要对上下文进行细致理解，以生成连贯且与上下文相关的回复。本文提出了Token Trails，这是一种利用token-type嵌入来导航对话中复杂上下文细微差别的新方法。我们的框架利用token-type嵌入来区分用户话语和机器人回复，从而促进生成具有上下文意识的回复。通过全面的实验和评估，我们展示了Token Trails在提高对话理解和回复生成方面的有效性，实现了最先进的性能。我们的结果突显了对话AI中上下文建模的重要性，并强调了Token Trails在推动该领域发展方面的潜力，为更复杂和具有上下文意识的聊天机器人交互铺平了道路。

    arXiv:2404.02402v1 Announce Type: cross  Abstract: Conversational modeling using Large Language Models (LLMs) requires a nuanced understanding of context to generate coherent and contextually relevant responses. In this paper, we present Token Trails, a novel approach that leverages token-type embeddings to navigate the intricate contextual nuances within conversations. Our framework utilizes token-type embeddings to distinguish between user utterances and bot responses, facilitating the generation of context-aware replies. Through comprehensive experimentation and evaluation, we demonstrate the effectiveness of Token Trails in improving conversational understanding and response generation, achieving state-of-the-art performance. Our results highlight the significance of contextual modeling in conversational AI and underscore the promising potential of Token Trails to advance the field, paving the way for more sophisticated and contextually aware chatbot interactions.
    
[^10]: 一个关于生成AI的网络内容控制调查

    A Survey of Web Content Control for Generative AI

    [https://arxiv.org/abs/2404.02309](https://arxiv.org/abs/2404.02309)

    该研究调查了生成AI领域网站内容控制的现状，提出了解决内容创作者和发布者知识产权保护问题的技术方案和挑战。

    

    最近，围绕生成AI的突破性进展引起了一波关注，导致了一系列诉讼，包括对Stability AI和OpenAI的重大行动。法律不确定性的这种情况引发了对内容创作者和发布者保护其在网络上知识产权的权利的广泛讨论。欧洲和美国的法律已经提供了大致的指导方针，为调节网络数据使用的技术解决方案指明了方向。在这个过程中，研究人员和实践者已经致力于众多网络标准和选择退出格式，使出版商有能力将他们的数据排除在生成AI模型的发展之外。新兴的AI/ML选择退出协议在数据主权方面具有价值，但同时，对于被最近诸多临时标准所淹没的网站所有者来说，这又创造了一种不利的局面。在我们的工作中，我们希望调查不同的网站

    arXiv:2404.02309v1 Announce Type: new  Abstract: The groundbreaking advancements around generative AI have recently caused a wave of concern culminating in a row of lawsuits, including high-profile actions against Stability AI and OpenAI. This situation of legal uncertainty has sparked a broad discussion on the rights of content creators and publishers to protect their intellectual property on the web. European as well as US law already provides rough guidelines, setting a direction for technical solutions to regulate web data use. In this course, researchers and practitioners have worked on numerous web standards and opt-out formats that empower publishers to keep their data out of the development of generative AI models. The emerging AI/ML opt-out protocols are valuable in regards to data sovereignty, but again, it creates an adverse situation for a site owners who are overwhelmed by the multitude of recent ad hoc standards to consider. In our work, we want to survey the different pr
    
[^11]: 在LLMs中循环：利用大型语言模型注释进行低资源语言的主动学习

    LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages

    [https://arxiv.org/abs/2404.02261](https://arxiv.org/abs/2404.02261)

    在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。

    

    由于语言资源和数据标注专业知识有限，低资源语言在人工智能开发中面临着重大障碍，使它们变得罕见且成本高昂。为了解决这一不足，我们提出利用LLMs的潜力在主动学习环节中进行数据注释。我们首先进行评估以评估注释者之间的一致性，从而选择适当的LLM注释者。然后，选择的注释者被集成到一个分类器的训练循环中，使用主动学习范式，最小化所需的查询数据量。实证评估，特别是使用GPT-4-Turbo，展示了几乎达到最先进性能的结果，同时大大减少了数据需求，由估算的潜在性能指示。

    arXiv:2404.02261v1 Announce Type: cross  Abstract: Low-resource languages face significant barriers in AI development due to limited linguistic resources and expertise for data labeling, rendering them rare and costly. The scarcity of data and the absence of preexisting tools exacerbate these challenges, especially since these languages may not be adequately represented in various NLP datasets. To address this gap, we propose leveraging the potential of LLMs in the active learning loop for data annotation. Initially, we conduct evaluations to assess inter-annotator agreement and consistency, facilitating the selection of a suitable LLM annotator. The chosen annotator is then integrated into a training loop for a classifier using an active learning paradigm, minimizing the amount of queried data required. Empirical evaluations, notably employing GPT-4-Turbo, demonstrate near-state-of-the-art performance with significantly reduced data requirements, as indicated by estimated potential co
    
[^12]: RAT: 检索增强变换器用于点击率预测

    RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction

    [https://arxiv.org/abs/2404.02249](https://arxiv.org/abs/2404.02249)

    RAT模型是为了解决当前CTR预测模型仅关注样本内特征交互而忽略跨样本关系的问题，通过检索相似样本构建增强输入，实现了对样本内和跨样本的全面特征交互推理，提高了CTR预测的效果。

    

    预测点击率（CTR）是Web应用程序的基本任务，其中一个关键问题是设计有效的特征交互模型。目前的方法主要集中于对单个样本内的特征交互进行建模，而忽略了可以作为参考背景来增强预测的潜在跨样本关系。为弥补这种不足，本文开发了一种检索增强变换器（RAT），旨在获取样本内和跨样本之间的细粒度特征交互。通过检索相似样本，我们为每个目标样本构建增强输入。然后利用级联注意力构建Transformer层，以捕获样本内和跨样本特征交互，促进全面推理以改善CTR预测的同时保持效率。对真实世界数据集的大量实验证实了RAT的有效性，并提出了

    arXiv:2404.02249v1 Announce Type: cross  Abstract: Predicting click-through rates (CTR) is a fundamental task for Web applications, where a key issue is to devise effective models for feature interactions. Current methodologies predominantly concentrate on modeling feature interactions within an individual sample, while overlooking the potential cross-sample relationships that can serve as a reference context to enhance the prediction. To make up for such deficiency, this paper develops a Retrieval-Augmented Transformer (RAT), aiming to acquire fine-grained feature interactions within and across samples. By retrieving similar samples, we construct augmented input for each target sample. We then build Transformer layers with cascaded attention to capture both intra- and cross-sample feature interactions, facilitating comprehensive reasoning for improved CTR prediction while retaining efficiency. Extensive experiments on real-world datasets substantiate the effectiveness of RAT and sugge
    
[^13]: 一种具有项目特征的NFT可收藏品推荐系统

    A Recommender System for NFT Collectibles with Item Feature

    [https://arxiv.org/abs/2403.18305](https://arxiv.org/abs/2403.18305)

    该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。

    

    推荐系统已被积极研究并应用于各个领域以解决信息过载问题。尽管有许多关于电影、音乐和电子商务的推荐系统的研究，但相比之下，尽管NFT市场持续增长，对于NFT的推荐系统却受到了相对较少的关注。本文提出了一种针对NFT的推荐系统，利用各种数据源，从NFT交易记录到外部项目特征，生成符合个人偏好的精确推荐。我们开发了一种数据高效的基于图的推荐系统，以有效捕捉每个项目与用户之间的复杂关系，并生成包含节点特征信息和图结构的节点（项目）嵌入。此外，我们利用超出用户-项目互动的输入，如图像特征、文本特征和价格特征。数值实验证实了该模型的性能。

    arXiv:2403.18305v1 Announce Type: cross  Abstract: Recommender systems have been actively studied and applied in various domains to deal with information overload. Although there are numerous studies on recommender systems for movies, music, and e-commerce, comparatively less attention has been paid to the recommender system for NFTs despite the continuous growth of the NFT market. This paper presents a recommender system for NFTs that utilizes a variety of data sources, from NFT transaction records to external item features, to generate precise recommendations that cater to individual preferences. We develop a data-efficient graph-based recommender system to efficiently capture the complex relationship between each item and users and generate node(item) embeddings which incorporate both node feature information and graph structure. Furthermore, we exploit inputs beyond user-item interactions, such as image feature, text feature, and price feature. Numerical experiments verify the perf
    
[^14]: 使用ChatGPT为电子学位论文指定LCSH主题的实验

    An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations

    [https://arxiv.org/abs/2403.16424](https://arxiv.org/abs/2403.16424)

    该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。

    

    该研究探讨了利用大型语言模型（LLMs）生成美国国会图书馆主题标头（LCSH）的潜力。作者使用ChatGPT根据电子学位论文的标题和摘要生成主题标头。结果显示，尽管一些生成的主题标头是有效的，但存在特定性和详尽性方面的问题。该研究展示了LLMs可以作为学术图书馆待编目项目的战略性应对措施，同时也提供了一种成本效益高且快速生成LCSH的方法。然而，人类编目员仍然是验证和增强LLMs生成的LCSH的有效性、详尽性和特定性的必要条件。

    arXiv:2403.16424v1 Announce Type: new  Abstract: This study delves into the potential use of Large Language Models (LLMs) for generating Library of Congress Subject Headings (LCSH). The authors employed ChatGPT to generate subject headings for electronic theses and dissertations (ETDs) based on their titles and summaries. The results revealed that although some generated subject headings were valid, there were issues regarding specificity and exhaustiveness. The study showcases that LLMs can serve as a strategic response to the backlog of items awaiting cataloging in academic libraries, while also offering a cost-effective approach for promptly generating LCSH. Nonetheless, human catalogers remain essential for verifying and enhancing the validity, exhaustiveness, and specificity of LCSH generated by LLMs.
    
[^15]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^16]: 无限-gram：将无限n-gram语言模型扩展到万亿标记

    Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens

    [https://arxiv.org/abs/2401.17377](https://arxiv.org/abs/2401.17377)

    这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。

    

    在神经大型语言模型（LLM）时代，n-gram语言模型还具有相关性吗？我们的答案是肯定的，并且我们展示了它们在文本分析和改进神经LLM方面的价值。然而，这需要在两个方面对n-gram模型进行现代化。首先，我们将它们与神经LLM相同的数据规模训练- 1.4万亿个标记。这是迄今为止构建的最大的n-gram模型。其次，现有的n-gram模型使用的n很小，这妨碍了它们的性能；相反，我们允许n可以是任意大的，通过引入一个新的无限-gram LM与回退。我们开发了一个名为infini-gram的引擎，它可以通过后缀数组计算无限-gram（以及任意n的n-gram）概率，并且具有毫秒级的延迟，而无需预先计算n-gram计数表（这将非常昂贵）。无限-gram框架和infini-gram引擎使我们能够对人类写作和机器生成的文本进行许多新颖和有意思的分析：我们发现无限-gram LM...

    Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM 
    
[^17]: SCTc-TE：一种全面的形式化和基准测试用于时间事件预测

    SCTc-TE: A Comprehensive Formulation and Benchmark for Temporal Event Forecasting

    [https://arxiv.org/abs/2312.01052](https://arxiv.org/abs/2312.01052)

    SCTc-TE提出了一种全面的时间事件预测形式化方法，并通过构建MidEast-TE数据集和区分各种上下文信息提升了预测方法。

    

    时间复杂事件预测旨在根据历史上观察到的事件来预测未来事件。大多数时间复杂事件的形式化是非结构化的或缺乏广泛的时间信息，导致表征不足和预测能力有限。为了填补这些差距，我们创新地引入了结构化、复杂和时间完整的时间事件（SCTc-TE）的形式化。在这个全面的形式化之后，我们开发了一个完全自动化的流程，并从约60万篇新闻文章中构建了一个名为MidEast-TE的大规模数据集。该数据集侧重于2015年至2022年间主要涉及中东地区各国之间的合作和冲突事件。除了数据集构建之外，更重要的是，我们通过区分各种上下文信息（即，本地和全球上下文）来推进预测方法。因此，我们提出了一种新颖的

    arXiv:2312.01052v2 Announce Type: replace-cross  Abstract: Temporal complex event forecasting aims to predict the future events given the observed events from history. Most formulations of temporal complex event are unstructured or without extensive temporal information, resulting in inferior representations and limited forecasting capabilities. To bridge these gaps, we innovatively introduce the formulation of Structured, Complex, and Time-complete temporal event (SCTc-TE). Following this comprehensive formulation, we develop a fully automated pipeline and construct a large-scale dataset named MidEast-TE from about 0.6 million news articles. This dataset focuses on the cooperation and conflict events among countries mainly in the MidEast region from 2015 to 2022. Not limited to the dataset construction, more importantly, we advance the forecasting methods by discriminating the crucial roles of various contextual information, i.e., local and global contexts. Thereby, we propose a novel
    
[^18]: Agent-OM：利用LLM代理进行本体匹配

    Agent-OM: Leveraging LLM Agents for Ontology Matching

    [https://arxiv.org/abs/2312.00326](https://arxiv.org/abs/2312.00326)

    本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。

    

    本体匹配（OM）能够实现不同本体之间的语义互操作性，通过对齐相关实体来解决其概念异构性。本研究引入了一种新颖的基于代理的LLM设计范式，命名为Agent-OM，包括两个用于检索和匹配的同体代理以及一组基于提示的简单OM工具。

    arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
    
[^19]: 利用上下文线索和角色相关性提升文档级事件论证提取

    Utilizing Contextual Clues and Role Correlations for Enhancing Document-level Event Argument Extraction

    [https://arxiv.org/abs/2310.05116](https://arxiv.org/abs/2310.05116)

    本文提出了CARLG模型，通过利用上下文线索和角色相关性，提升了文档级事件论证提取的性能。

    

    文档级事件论证提取（EAE）是信息提取中至关重要但具有挑战性的子任务之一。现有方法大多关注论证和事件触发器之间的交互，忽视了两个关键点：上下文线索的信息和论证角色之间的语义相关性。本文提出了CARLG模型，包括两个模块：上下文线索聚合（CCA）和基于角色的潜在信息引导（RLIG），通过有效利用上下文线索和角色相关性来提高文档级EAE。CCA模块通过利用来自预训练编码器的上下文注意权重，自适应地捕捉和整合上下文线索。RLIG模块通过角色交互编码捕捉语义相关性，并通过潜在角色表示提供宝贵的信息引导。值得注意的是，我们的CCA和RLIG模块紧凑、可移植且高效，引入的新参数不超过1%，且易于实现。

    Document-level event argument extraction (EAE) is a vital but challenging subtask in information extraction. Most existing approaches focus on the interaction between arguments and event triggers, ignoring two critical points: the information of contextual clues and the semantic correlations among argument roles. In this paper, we propose the CARLG model, which consists of two modules: Contextual Clues Aggregation (CCA) and Role-based Latent Information Guidance (RLIG), effectively leveraging contextual clues and role correlations for improving document-level EAE. The CCA module adaptively captures and integrates contextual clues by utilizing context attention weights from a pre-trained encoder. The RLIG module captures semantic correlations through role-interactive encoding and provides valuable information guidance with latent role representation. Notably, our CCA and RLIG modules are compact, transplantable and efficient, which introduce no more than 1% new parameters and can be eas
    
[^20]: 通过检索和自我反思改善医疗推理能力的检索增强型大型语言模型

    Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])

    [http://arxiv.org/abs/2401.15269](http://arxiv.org/abs/2401.15269)

    本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。

    

    最近的专有大型语言模型（LLMs），例如GPT-4，在生物医学领域中解决了从多项选择题到长篇生成等多样化挑战的里程碑。为了解决LLMs编码知识无法处理的挑战，已经开发了各种检索增强生成（RAG）方法，通过从知识语料库中搜索文档并无条件或有选择地将其附加到LLMs的输入来进行生成。然而，将现有方法应用于不同领域特定问题时，出现了泛化能力差的问题，导致获取不正确的文档或做出不准确的判断。在本文中，我们介绍了一种可靠的医学文本框架Self-BioRAG，专门用于生成解释、检索领域特定文档和自我反思生成的响应。我们使用了84k个经过过滤的生物医学指令集来训练Self-BioRAG，它具备评估自己的基因

    Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene
    
[^21]: 使用AI副驾驶员导航复杂搜索任务

    Navigating Complex Search Tasks with AI Copilots. (arXiv:2311.01235v1 [cs.IR])

    [http://arxiv.org/abs/2311.01235](http://arxiv.org/abs/2311.01235)

    该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。

    

    正如信息检索(IR)研究界的许多人所知和欣赏的那样，搜索远未解决。每天都有数百万人在搜索引擎上面对任务的困难。他们的困难通常与任务的内在复杂性以及搜索系统无法完全理解任务和提供相关结果有关。任务激发了搜索，创建了搜索者尝试连接/解决的差距/问题情况，并在他们处理不同任务方面时驱动搜索行为。复杂搜索任务需要的不仅是基本事实查找或搜索的支持。支持复杂任务的方法研究包括生成查询和网站建议，个性化和上下文化搜索，以及开发新的搜索体验，包括跨时间和空间。最近兴起的生成人工智能(AI)和基于该技术的辅助代理，或者说副驾驶员，的出现。

    As many of us in the information retrieval (IR) research community know and appreciate, search is far from being a solved problem. Millions of people struggle with tasks on search engines every day. Often, their struggles relate to the intrinsic complexity of their task and the failure of search systems to fully understand the task and serve relevant results. The task motivates the search, creating the gap/problematic situation that searchers attempt to bridge/resolve and drives search behavior as they work through different task facets. Complex search tasks require more than support for rudimentary fact finding or re-finding. Research on methods to support complex tasks includes work on generating query and website suggestions, personalizing and contextualizing search, and developing new search experiences, including those that span time and space. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology
    
[^22]: Chain-of-Choice层次化策略学习用于对话推荐

    Chain-of-Choice Hierarchical Policy Learning for Conversational Recommendation. (arXiv:2310.17922v1 [cs.IR])

    [http://arxiv.org/abs/2310.17922](http://arxiv.org/abs/2310.17922)

    提出了一种称为MTAMCR的对话推荐问题设定，通过每轮询问涵盖多个属性类型的多选题，提高了互动效率。同时，通过Chain-of-Choice层次化策略学习框架，提高了对话推荐系统的询问效率和推荐效果。

    

    对话推荐系统通过多轮互动对话来揭示用户偏好，最终导向精确和满意的推荐。然而，现有的对话推荐系统仅限于根据每轮单个属性类型（如颜色）询问二进制或多选题，导致互动轮数过多，降低了用户体验。为解决这个问题，我们提出了一种更现实和高效的对话推荐问题设定，称为多类型属性多轮对话推荐（MTAMCR），该问题设定使得对话推荐系统能够在每轮中询问涵盖多个属性类型的多选题，从而提高互动效率。此外，通过将MTAMCR定义为一项层次化强化学习任务，我们提出了一种Chain-of-Choice层次化策略学习（CoCHPL）框架来提高MTAMCR中的询问效率和推荐效果。

    Conversational Recommender Systems (CRS) illuminate user preferences via multi-round interactive dialogues, ultimately navigating towards precise and satisfactory recommendations. However, contemporary CRS are limited to inquiring binary or multi-choice questions based on a single attribute type (e.g., color) per round, which causes excessive rounds of interaction and diminishes the user's experience. To address this, we propose a more realistic and efficient conversational recommendation problem setting, called Multi-Type-Attribute Multi-round Conversational Recommendation (MTAMCR), which enables CRS to inquire about multi-choice questions covering multiple types of attributes in each round, thereby improving interactive efficiency. Moreover, by formulating MTAMCR as a hierarchical reinforcement learning task, we propose a Chain-of-Choice Hierarchical Policy Learning (CoCHPL) framework to enhance both the questioning efficiency and recommendation effectiveness in MTAMCR. Specifically,
    

