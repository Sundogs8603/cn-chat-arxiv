# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation.](http://arxiv.org/abs/2309.05238) | 本论文研究了为了更有效地筛选系统性审查生成自然语言查询的方法。通过探索使用不同的查询来源，如用于检索文档和基于指令的大规模语言模型生成的查询，我们提出了一种新的方法，可以在筛选过程中更准确地排名重要文档，并取得了很好的效果。 |

# 详细

[^1]: 为更有效的系统性审查筛选生成自然语言查询

    Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation. (arXiv:2309.05238v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2309.05238](http://arxiv.org/abs/2309.05238)

    本论文研究了为了更有效地筛选系统性审查生成自然语言查询的方法。通过探索使用不同的查询来源，如用于检索文档和基于指令的大规模语言模型生成的查询，我们提出了一种新的方法，可以在筛选过程中更准确地排名重要文档，并取得了很好的效果。

    

    医学系统性审查中的筛选优先级目标是通过复杂的布尔查询对检索到的文档集进行排名。优先处理最重要的文档可以确保后续审查步骤能够更高效、更有效地进行。目前的最新技术使用审查的最终标题作为查询，利用基于BERT的神经排序器对文档进行排名。然而，最终标题只在审查过程结束时形成，这使得该方法不切实际，因为它依赖于ex post facto的信息。在筛选的时候，只有一个粗略的工作标题可用，使用BERT-based排序器时效果明显不如最终标题。在本文中，我们探索了用于筛选优先级的查询的替代来源，例如用于检索待筛选文档的布尔查询，以及由基于指令的大规模语言模型（如ChatGPT和Alpaca）生成的查询。我们的最佳方法不仅仅是

    Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only
    

