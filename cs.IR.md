# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Role of Relevance in Fair Ranking.](http://arxiv.org/abs/2305.05608) | 本文结合社会学、信息检索和机器学习公平性的角度和工具，着眼于相关性在公平排序中的应用和作用，并推导出相关性评分应满足的一组期望标准以实现有意义地指导公平干预措施。 |
| [^2] | [Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment.](http://arxiv.org/abs/2305.05585) | 提出了一种基于多种用户行为数据学习的推荐框架，名为MBA，解决了学习通用且准确用户偏好和克服观察到的隐式用户反馈中的噪声和偏差的问题。 |
| [^3] | [Consistent Text Categorization using Data Augmentation in e-Commerce.](http://arxiv.org/abs/2305.05402) | 本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。 |
| [^4] | [CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding.](http://arxiv.org/abs/2305.05393) | 本文提出了一种融合法律知识的预训练模型CaseEncoder，针对法律案例的特殊领域需求，CaseEncoder在数据采样和预训练阶段中都使用了法律知识，其中包括利用细粒度的法律条款信息引导正负样本的选择，以及设计了与相关法律案例的评判标准相一致的法律特定预训练任务，该模型在法律案例检索和法律问答任务上优于最先进的PLMs。 |
| [^5] | [Explainable Recommender with Geometric Information Bottleneck.](http://arxiv.org/abs/2305.05331) | 该论文提出了一种新的可解释推荐系统模型，将从用户-商品交互中学得的几何先验知识与变分网络相结合，可以为用户提供既具备推荐性能又具有解释性能的解释推荐服务。 |
| [^6] | [Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data.](http://arxiv.org/abs/2305.05295) | 研究者提出训练排名模型的方法来提高跨语言检索的效率，该模型使用了人工代码切换的数据，并且实验表明在跨语言检索和多语言检索中会带来显著改进，在不影响单语检索的基础上，特别是对于远程语言之间的检索。 |
| [^7] | [Learning to Personalize Recommendation based on Customers' Shopping Intents.](http://arxiv.org/abs/2305.05279) | 本文介绍了亚马逊的新系统，利用深度学习模型将顾客的在线行为映射成为高级别购物意图，以便个性化推荐，提供更相关、可解释和多样化的购物体验。 |
| [^8] | [Learning Personalized Page Content Ranking Using Customer Representation.](http://arxiv.org/abs/2305.05267) | 本论文提出了一种基于深度学习的蒙特卡罗策略，该算法主要利用聚合的顾客行为特征，忽略单个购物者级别的过去活动。该模型通过整合历史购物行为、顾客潜在购物目标以及顾客和内容分类之间的相关性，产生更个性化的内容排名，测量值为12.08%的nDCG提升。 |
| [^9] | [Popularity Debiasing from Exposure to Interaction in Collaborative Filtering.](http://arxiv.org/abs/2305.05204) | 本文提出了一种新的流行度鉴别准则，即在公平的推荐系统中，受欢迎和不受欢迎的物品应该得到与喜欢它的用户数量成比例的交互，针对这个准则提出了一种新的去流行度偏差框架，并在多个真实数据集上的实验中展示了其在去偏差和推荐准确性方面的显着改进。 |
| [^10] | [Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed.](http://arxiv.org/abs/2305.05074) | Autumn是一个可扩展的、面向读操作优化的LSM-tree键值存储引擎，其创新之处在于通过动态调整相邻两层之间的容量比来不断提高读性能，使得点读和区间读成本从之前最优的$O(logN)$复杂度优化到了$O(\sqrt{logN})$。 |
| [^11] | [Recommender Systems with Generative Retrieval.](http://arxiv.org/abs/2305.05065) | 本文提出了一种新型的生成式检索模型，将检索和生成组合在一起以产生推荐。 |
| [^12] | [Web Content Filtering through knowledge distillation of Large Language Models.](http://arxiv.org/abs/2305.05027) | 本文提出了一种基于大语言模型知识蒸馏的 URL 分类方法，可用于网络内容过滤，其学生模型在参数数量减少 175 倍的情况下，精度提升了 9%，超过了当前最先进方法。 |
| [^13] | [Autoencoder-based prediction of ICU clinical codes.](http://arxiv.org/abs/2305.04992) | 本文研究了基于自编码器的 ICU 临床代码预测，针对不完整的临床代码清单，使用了各种自编码器方法以及两个强基准。结果表明，基于共现的方法表现略微更好，对抗自编码器实现了最佳性能。 |
| [^14] | [Graph Masked Autoencoder for Sequential Recommendation.](http://arxiv.org/abs/2305.04619) | 提出了一种简单而有效的基于图遮盖自编码器的序列推荐系统，它使用基于图的注意力机制暴露出带有遮盖的项目序列，自适应动态提取全局项目转换信息进行自监督增强，在具有较少标记样本的情况下始终比最先进的序列推荐方法表现出更好的性能，而且对数据损坏和缺失情况具有鲁棒性。 |
| [^15] | [Cross-domain Augmentation Networks for Click-Through Rate Prediction.](http://arxiv.org/abs/2305.03953) | 本文中提出了一个跨领域增强网络（CDAnet），能够进行异构输入下的知识转移和生成增强样本减轻数据稀疏问题，实验证明其优于现有的基线方法。 |
| [^16] | [SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes.](http://arxiv.org/abs/2302.06587) | SLIM是一种带倒排索引的多向量检索方法，通过对上下文化令牌嵌入进行稀疏化处理和晚期交互实现有效检索，且可与现成词库搜索库完全兼容。 |
| [^17] | [Language Agnostic Multilingual Information Retrieval with Contrastive Learning.](http://arxiv.org/abs/2210.06633) | 该论文提出一种使用对比学习的技术，利用平行和非平行语料库来提高多语种信息检索的效果，仅使用英语IR训练数据和一些平行语料库即可在非英语数据上实现显著的检索性能改进。 |
| [^18] | [Fairness in Recommender Systems: Research Landscape and Future Directions.](http://arxiv.org/abs/2205.11127) | 本文讨论了推荐系统的公平性问题，通过对160多篇学术出版物的综述总结了该领域目前的研究现状，强调了一些有前途的未来方向，例如需要超越统计平衡的新公平性衡量方法。 |
| [^19] | [Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks.](http://arxiv.org/abs/2203.11011) | 本文提出了一种强化学习框架下基于异构信息网络的概念推荐方法，可以更好地向不同专业水平的用户精细推荐知识。 |

# 详细

[^1]: 相关性在公平排序中的作用

    The Role of Relevance in Fair Ranking. (arXiv:2305.05608v1 [cs.IR])

    [http://arxiv.org/abs/2305.05608](http://arxiv.org/abs/2305.05608)

    本文结合社会学、信息检索和机器学习公平性的角度和工具，着眼于相关性在公平排序中的应用和作用，并推导出相关性评分应满足的一组期望标准以实现有意义地指导公平干预措施。

    

    在线平台在机会获取中起着重要作用：基于相关性的排名通过在招聘平台的工作职位、求职者或在线市场的卖家中分配曝光机会来创建和限制选项。为了负责任地这样做，这些社会相关系统采用各种公平措施和干预措施，其中许多措施试图根据价值分配曝光机会。但是，因为这些构造通常不是直接可观察的，所以平台必须使用代理评分，如相关性，并从搜索者的行为信号中推断出它们。然而，关键问题仍然存在，即相关性在高风险的公平排序中是否履行其作为价值评分这样的作用。本文结合社会学、信息检索和机器学习公平性的角度和工具，推导出相关性评分应满足的一组期望标准，以便有意义地指导公平干预措施。

    Online platforms mediate access to opportunity: relevance-based rankings create and constrain options by allocating exposure to job openings and job candidates in hiring platforms, or sellers in a marketplace. In order to do so responsibly, these socially consequential systems employ various fairness measures and interventions, many of which seek to allocate exposure based on worthiness. Because these constructs are typically not directly observable, platforms must instead resort to using proxy scores such as relevance and infer them from behavioral signals such as searcher clicks. Yet, it remains an open question whether relevance fulfills its role as such a worthiness score in high-stakes fair rankings.  In this paper, we combine perspectives and tools from the social sciences, information retrieval, and fairness in machine learning to derive a set of desired criteria that relevance scores should satisfy in order to meaningfully guide fairness interventions. We then empirically show 
    
[^2]: 通过多行为匹配方式提高基于隐式反馈的推荐系统

    Improving Implicit Feedback-Based Recommendation through Multi-Behavior Alignment. (arXiv:2305.05585v1 [cs.IR])

    [http://arxiv.org/abs/2305.05585](http://arxiv.org/abs/2305.05585)

    提出了一种基于多种用户行为数据学习的推荐框架，名为MBA，解决了学习通用且准确用户偏好和克服观察到的隐式用户反馈中的噪声和偏差的问题。

    

    学习隐性反馈的推荐系统往往使用大量单一类型的隐式用户反馈，例如点击，以增强对稀有目标行为，如购买的预测。针对此类目标行为预测，使用多种类型的隐式用户反馈仍然是一个开放性问题。现有的学习多种用户行为的研究往往未能解决以下问题：（i）从不同的行为数据分布中学习通用和准确的用户偏好；（ii）克服观察到的隐式用户反馈中的噪声和偏差。为解决这些问题，我们提出了多行为匹配（MBA），这是一种新的基于多种行为数据学习的推荐框架。我们假设来自同一用户的多种行为（例如点击和购买）应反映该用户类似的偏好。为此，我们将潜在的通用用户偏好视为潜在的变量。

    Recommender systems that learn from implicit feedback often use large volumes of a single type of implicit user feedback, such as clicks, to enhance the prediction of sparse target behavior such as purchases. Using multiple types of implicit user feedback for such target behavior prediction purposes is still an open question. Existing studies that attempted to learn from multiple types of user behavior often fail to: (i) learn universal and accurate user preferences from different behavioral data distributions, and (ii) overcome the noise and bias in observed implicit user feedback. To address the above problems, we propose multi-behavior alignment (MBA), a novel recommendation framework that learns from implicit feedback by using multiple types of behavioral data. We conjecture that multiple types of behavior from the same user (e.g., clicks and purchases) should reflect similar preferences of that user. To this end, we regard the underlying universal user preferences as a latent vari
    
[^3]: 在电子商务中使用数据增强实现一致的文本分类

    Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])

    [http://arxiv.org/abs/2305.05402](http://arxiv.org/abs/2305.05402)

    本文提出了一种在电子商务中使用数据增强实现一致的文本分类的新框架，该框架旨在改进产品分类模型的一致性，同时保持其生产水平的性能。

    

    大规模电子商务数据分类是一项关键的、广泛应用于工业领域的任务。本文旨在改进一家主要网络公司已经在使用的产品分类模型，该模型用于多种应用。在该模型核心中，产品分类模型是一个文本分类模型，接受产品标题作为输入，并从数千个可用候选项中输出最合适的类别。经过进一步观察，我们发现了类似物品标签上的不一致性。例如，标题中关于颜色或尺寸的小变化，会对模型产生较大影响。这种现象可能会对下游的推荐或搜索应用造成负面影响，导致用户体验下降。为了解决这个问题，我们提出了一个新的框架，实现一致的文本分类。我们的目标是提高模型的一致性，并保持其生产水平的性能。

    The categorization of massive e-Commerce data is a crucial, well-studied task, which is prevalent in industrial settings. In this work, we aim to improve an existing product categorization model that is already in use by a major web company, serving multiple applications. At its core, the product categorization model is a text classification model that takes a product title as an input and outputs the most suitable category out of thousands of available candidates. Upon a closer inspection, we found inconsistencies in the labeling of similar items. For example, minor modifications of the product title pertaining to colors or measurements majorly impacted the model's output. This phenomenon can negatively affect downstream recommendation or search applications, leading to a sub-optimal user experience.  To address this issue, we propose a new framework for consistent text categorization. Our goal is to improve the model's consistency while maintaining its production-level performance. W
    
[^4]: CaseEncoder：一种融合法律知识的预训练模型用于法律案例编码

    CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding. (arXiv:2305.05393v1 [cs.IR])

    [http://arxiv.org/abs/2305.05393](http://arxiv.org/abs/2305.05393)

    本文提出了一种融合法律知识的预训练模型CaseEncoder，针对法律案例的特殊领域需求，CaseEncoder在数据采样和预训练阶段中都使用了法律知识，其中包括利用细粒度的法律条款信息引导正负样本的选择，以及设计了与相关法律案例的评判标准相一致的法律特定预训练任务，该模型在法律案例检索和法律问答任务上优于最先进的PLMs。

    

    现代法律信息系统中，法律案例检索是关键的流程。尽管近期的研究利用了基于通用领域自监督预训练范式的预训练语言模型(PLMs)构建了用于法律案例检索的模型，但是使用通用领域的PLMs作为骨干模型有其局限性。具体来说，这些模型可能无法完全捕捉法律案例文档中的潜在法律特征。为了解决这个问题，我们提出了CaseEncoder，一种法律文档编码器，它在数据采样和预训练阶段利用细粒度的法律知识。在数据采样阶段，我们利用细粒度的法律条款信息引导正负样本的选择，从而提高了训练数据的质量。在预训练阶段，我们设计了与相关法律案例的评判标准相一致的法律特定预训练任务。根据这些任务，我们引入了一种创新的损失函数——偏置圆形损失(Biased Circle Loss)来处理法律案例数据集中正负样本之间的不平衡。实验结果表明，我们的CaseEncoder在法律案例检索和法律问答任务上优于最先进的PLMs。

    Legal case retrieval is a critical process for modern legal information systems. While recent studies have utilized pre-trained language models (PLMs) based on the general domain self-supervised pre-training paradigm to build models for legal case retrieval, there are limitations in using general domain PLMs as backbones. Specifically, these models may not fully capture the underlying legal features in legal case documents. To address this issue, we propose CaseEncoder, a legal document encoder that leverages fine-grained legal knowledge in both the data sampling and pre-training phases. In the data sampling phase, we enhance the quality of the training data by utilizing fine-grained law article information to guide the selection of positive and negative examples. In the pre-training phase, we design legal-specific pre-training tasks that align with the judging criteria of relevant legal cases. Based on these tasks, we introduce an innovative loss function called Biased Circle Loss to 
    
[^5]: 具有几何信息瓶颈的可解释推荐系统

    Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v1 [cs.IR])

    [http://arxiv.org/abs/2305.05331](http://arxiv.org/abs/2305.05331)

    该论文提出了一种新的可解释推荐系统模型，将从用户-商品交互中学得的几何先验知识与变分网络相结合，可以为用户提供既具备推荐性能又具有解释性能的解释推荐服务。

    

    可解释的推荐系统能够解释其推荐决策，增强用户对系统的信任。大多数可解释的推荐系统要么依赖于人工标注的原理来训练模型以生成解释，要么利用注意机制从评论中提取重要的文本段落作为解释。提取的原理往往局限于单个评论，可能无法识别评论文本之外的隐含特征。为了避免昂贵的人工注释过程并生成超出单个评论的解释，我们建议将从用户-商品交互中学得的几何先验知识与变分网络相结合，该网络从用户-商品评论中推断潜在因子。单个用户-商品对的潜在因子可用于推荐和解释生成，自然地继承了编码在先验知识中的全局特征。三个电子商务数据集上的实验结果表明，我们的模型在推荐性能和可解释性方面都具有竞争力。

    Explainable recommender systems can explain their recommendation decisions, enhancing user trust in the systems. Most explainable recommender systems either rely on human-annotated rationales to train models for explanation generation or leverage the attention mechanism to extract important text spans from reviews as explanations. The extracted rationales are often confined to an individual review and may fail to identify the implicit features beyond the review text. To avoid the expensive human annotation process and to generate explanations beyond individual reviews, we propose to incorporate a geometric prior learnt from user-item interactions into a variational network which infers latent factors from user-item reviews. The latent factors from an individual user-item pair can be used for both recommendation and explanation generation, which naturally inherit the global characteristics encoded in the prior knowledge. Experimental results on three e-commerce datasets show that our mo
    
[^6]: 通过训练人工代码切换数据来提升零样本跨语言检索

    Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])

    [http://arxiv.org/abs/2305.05295](http://arxiv.org/abs/2305.05295)

    研究者提出训练排名模型的方法来提高跨语言检索的效率，该模型使用了人工代码切换的数据，并且实验表明在跨语言检索和多语言检索中会带来显著改进，在不影响单语检索的基础上，特别是对于远程语言之间的检索。

    

    将以英语为代表的高资源语言的信息检索（IR）模型以零样本方式迁移到其他语言已成为被广泛采用的方法。在本研究中，我们表明当查询和文档以不同语言存在时，零样本排名器的有效性会降低。出于这个原因，我们建议使用人工代码切换数据来训练排名模型，而我们生成这些数据是通过利用双语词表。为此，我们尝试了从（1）跨语言词嵌入和（2）平行维基百科页面标题得出的词表。我们使用mMARCO数据集对涵盖单语IR（MoIR）、跨语言IR（CLIR）和多语言IR（MLIR）的36种语言对的重排模型进行了广泛评估。我们的结果表明，代码切换可以在保持MoIR性能稳定的同时，在CLIR中产生5.1 MRR@10的一致和显著增益，以及在MLIR中产生3.9 MRR@10的增益。令人鼓舞的是，远程语言之间的增益特别显著。

    Transferring information retrieval (IR) models from a high-resource language (typically English) to other languages in a zero-shot fashion has become a widely adopted approach. In this work, we show that the effectiveness of zero-shot rankers diminishes when queries and documents are present in different languages. Motivated by this, we propose to train ranking models on artificially code-switched data instead, which we generate by utilizing bilingual lexicons. To this end, we experiment with lexicons induced from (1) cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use the mMARCO dataset to extensively evaluate reranking models on 36 language pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual IR (MLIR). Our results show that code-switching can yield consistent and substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while maintaining stable performance in MoIR. Encouragingly, the gains are especially pronounced for distan
    
[^7]: 学习个性化推荐以基于客户购物意图

    Learning to Personalize Recommendation based on Customers' Shopping Intents. (arXiv:2305.05279v1 [cs.IR])

    [http://arxiv.org/abs/2305.05279](http://arxiv.org/abs/2305.05279)

    本文介绍了亚马逊的新系统，利用深度学习模型将顾客的在线行为映射成为高级别购物意图，以便个性化推荐，提供更相关、可解释和多样化的购物体验。

    

    理解顾客的高级别购物意图，如他们去露营或举办生日派对的愿望，对于电商平台非常重要；它可以通过提供更相关、可解释和多样化的推荐来提高购物体验的质量。然而，由于实际挑战，这种高级别的购物意图在行业中被忽视。在这项工作中，我们介绍了亚马逊的新系统，明确地识别和利用每个客户的高级别购物意图来个性化推荐。我们开发了一种新技术，自动识别亚马逊客户正在追求的各种高级别目标，如“去露营”和“准备海滩派对”。我们的解决方案进行了扩展（跨越21个国家的14种语言）。然后，一个深度学习模型将每个客户的在线行为，如产品搜索和个体项目参与，映射成一组高级别的购物意图。

    Understanding the customers' high level shopping intent, such as their desire to go camping or hold a birthday party, is critically important for an E-commerce platform; it can help boost the quality of shopping experience by enabling provision of more relevant, explainable, and diversified recommendations. However, such high level shopping intent has been overlooked in the industry due to practical challenges. In this work, we introduce Amazon's new system that explicitly identifies and utilizes each customer's high level shopping intents for personalizing recommendations. We develop a novel technique that automatically identifies various high level goals being pursued by the Amazon customers, such as "go camping", and "preparing for a beach party". Our solution is in a scalable fashion (in 14 languages across 21 countries). Then a deep learning model maps each customer's online behavior, e.g. product search and individual item engagements, into a subset of high level shopping intents
    
[^8]: 使用顾客表示学习个性化页面内容排名

    Learning Personalized Page Content Ranking Using Customer Representation. (arXiv:2305.05267v1 [cs.IR])

    [http://arxiv.org/abs/2305.05267](http://arxiv.org/abs/2305.05267)

    本论文提出了一种基于深度学习的蒙特卡罗策略，该算法主要利用聚合的顾客行为特征，忽略单个购物者级别的过去活动。该模型通过整合历史购物行为、顾客潜在购物目标以及顾客和内容分类之间的相关性，产生更个性化的内容排名，测量值为12.08%的nDCG提升。

    

    在电子商务网站上（例如亚马逊、eBay等），有丰富的推荐内容，可以帮助购物者更有效地购物。然而，鉴于产品众多，选择最相关的内容以减少信息过载的负担至关重要。我们引入了一种由线性因果赌博算法驱动的内容排名服务，以在每个上下文下为每个购物者排名和选择内容。该算法主要利用聚合的顾客行为特征，忽略单个购物者级别的过去活动。我们研究了从历史活动中推断购物者兴趣的问题。我们提出了一种基于深度学习的赌博算法，该算法整合了历史购物行为、顾客潜在购物目标以及顾客和内容分类之间的相关性。该模型产生了更个性化的内容排名，测量值为12.08%的nDCG提升。在在线A/B测试环境中，该模型提高了0.02%的商业度量年化影响，验证了其有效性。

    On E-commerce stores (Amazon, eBay etc.) there are rich recommendation content to help shoppers shopping more efficiently. However given numerous products, it's crucial to select most relevant content to reduce the burden of information overload. We introduced a content ranking service powered by a linear causal bandit algorithm to rank and select content for each shopper under each context. The algorithm mainly leverages aggregated customer behavior features, and ignores single shopper level past activities. We study the problem of inferring shoppers interest from historical activities. We propose a deep learning based bandit algorithm that incorporates historical shopping behavior, customer latent shopping goals, and the correlation between customers and content categories. This model produces more personalized content ranking measured by 12.08% nDCG lift. In the online A/B test setting, the model improved 0.02% annualized commercial impact measured by our business metric, validating
    
[^9]: 从交互行为中消除协同过滤推荐的流行度偏差

    Popularity Debiasing from Exposure to Interaction in Collaborative Filtering. (arXiv:2305.05204v1 [cs.IR])

    [http://arxiv.org/abs/2305.05204](http://arxiv.org/abs/2305.05204)

    本文提出了一种新的流行度鉴别准则，即在公平的推荐系统中，受欢迎和不受欢迎的物品应该得到与喜欢它的用户数量成比例的交互，针对这个准则提出了一种新的去流行度偏差框架，并在多个真实数据集上的实验中展示了其在去偏差和推荐准确性方面的显着改进。

    

    推荐系统往往受到流行度偏见的影响，过度推荐热门物品，而牺牲不受欢迎的物品。现有的研究通常关注如何确保每个物品的推荐次数暴露在相等或成比例的情况下,使用反向偏差加权、因果干预或对抗训练等方法。然而，增加不受欢迎物品的曝光率可能不会带来更多的点击或交互，导致利益分配不平衡，无法真正实现合理的流行度鉴别。在本文中，我们提出了一种新的流行度鉴别准则，即在一个公平的推荐系统中，受欢迎和不受欢迎的物品应该得到与喜欢它的用户数量成比例的交互。在该准则的指导下，我们提出了一种带有IPL正则化项的去偏差框架，该框架在理论上可以实现流行度去偏差和推荐性能的双赢局面。在几个真实世界数据集上的实验表明，我们的方法优于几个最先进的基线模型，并在去偏差性能和推荐准确性方面取得了显着的改进。

    Recommender systems often suffer from popularity bias, where popular items are overly recommended while sacrificing unpopular items. Existing researches generally focus on ensuring the number of recommendations exposure of each item is equal or proportional, using inverse propensity weighting, causal intervention, or adversarial training. However, increasing the exposure of unpopular items may not bring more clicks or interactions, resulting in skewed benefits and failing in achieving real reasonable popularity debiasing. In this paper, we propose a new criterion for popularity debiasing, i.e., in an unbiased recommender system, both popular and unpopular items should receive Interactions Proportional to the number of users who Like it, namely IPL criterion. Under the guidance of the criterion, we then propose a debiasing framework with IPL regularization term which is theoretically shown to achieve a win-win situation of both popularity debiasing and recommendation performance. Experi
    
[^10]: Autumn：基于LSM-tree的可扩展的面向读操作优化的键值存储引擎

    Autumn: A Scalable Read Optimized LSM-tree based Key-Value Stores with Fast Point and Range Read Speed. (arXiv:2305.05074v1 [cs.DB])

    [http://arxiv.org/abs/2305.05074](http://arxiv.org/abs/2305.05074)

    Autumn是一个可扩展的、面向读操作优化的LSM-tree键值存储引擎，其创新之处在于通过动态调整相邻两层之间的容量比来不断提高读性能，使得点读和区间读成本从之前最优的$O(logN)$复杂度优化到了$O(\sqrt{logN})$。

    

    基于Log Structured Merge Trees (LSM-tree)的键值存储引擎被广泛应用于许多存储系统中，以支持更新、点读和区间读等各种操作。本文中，我们提出了一个名为Autumn的可扩展的、面向读操作优化的基于LSM-tree的键值存储引擎，它具有最少的点读和区间读成本。通过动态调整相邻两层之间的容量比来不断提高读性能，点读和区间读成本从之前最优的$O(logN)$复杂度优化到了$O(\sqrt{logN})$，并应用了新的Garnering合并策略。Autumn是一个可扩展的、面向读操作优化的LSM-tree键值存储引擎。

    The Log Structured Merge Trees (LSM-tree) based key-value stores are widely used in many storage systems to support a variety of operations such as updates, point reads, and range reads. Traditionally, LSM-tree's merge policy organizes data into multiple levels of exponentially increasing capacity to support high-speed writes. However, we contend that the traditional merge policies are not optimized for reads. In this work, we present Autumn, a scalable and read optimized LSM-tree based key-value stores with minimal point and range read cost. The key idea in improving the read performance is to dynamically adjust the capacity ratio between two adjacent levels as more data are stored. As a result, smaller levels gradually increase their capacities and merge more often. In particular, the point and range read cost improves from the previous best known $O(logN)$ complexity to $O(\sqrt{logN})$ in Autumn by applying the new novel Garnering merge policy. While Garnering merge policy optimize
    
[^11]: 生成式检索推荐系统

    Recommender Systems with Generative Retrieval. (arXiv:2305.05065v1 [cs.IR])

    [http://arxiv.org/abs/2305.05065](http://arxiv.org/abs/2305.05065)

    本文提出了一种新型的生成式检索模型，将检索和生成组合在一起以产生推荐。

    

    现代推荐系统使用大规模检索模型进行推荐，包括两个阶段：训练双编码模型将查询和候选项嵌入到相同的空间中，然后使用近似最近邻搜索来选择给定查询嵌入的顶部候选项。本文提出了一种新的单阶段范例：生成式检索模型，该模型通过自回归方式在一个阶段中解码目标候选项的标识符。为此，我们不是为每个项目分配随机生成的原子ID，而是生成语义ID：每个项目的语义有意义的元组编码词，它作为其唯一标识符。我们使用称为RQ-VAE的分层方法生成这些编码词。一旦我们对所有项目都有了语义ID，就会训练基于Transformer的序列到序列模型来预测下一个项目的语义ID。由于这个模型以自回归的方式直接预测标识下一个项的编码词元组，因此它可以将检索和生成组合在一起以产生推荐。

    Modern recommender systems leverage large-scale retrieval models consisting of two stages: training a dual-encoder model to embed queries and candidates in the same space, followed by an Approximate Nearest Neighbor (ANN) search to select top candidates given a query's embedding. In this paper, we propose a new single-stage paradigm: a generative retrieval model which autoregressively decodes the identifiers for the target candidates in one phase. To do this, instead of assigning randomly generated atomic IDs to each item, we generate Semantic IDs: a semantically meaningful tuple of codewords for each item that serves as its unique identifier. We use a hierarchical method called RQ-VAE to generate these codewords. Once we have the Semantic IDs for all the items, a Transformer based sequence-to-sequence model is trained to predict the Semantic ID of the next item. Since this model predicts the tuple of codewords identifying the next item directly in an autoregressive manner, it can be c
    
[^12]: 基于大语言模型知识蒸馏的网络内容过滤方法

    Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])

    [http://arxiv.org/abs/2305.05027](http://arxiv.org/abs/2305.05027)

    本文提出了一种基于大语言模型知识蒸馏的 URL 分类方法，可用于网络内容过滤，其学生模型在参数数量减少 175 倍的情况下，精度提升了 9%，超过了当前最先进方法。

    

    本文提出了一种基于大语言模型的 URL 分类方法，旨在实现网络内容过滤的主要目标：保障组织免受法律和伦理风险，限制访问高风险或可疑网站，以及促进安全的专业工作环境。我们的方法利用大语言模型生成准确的分类，并利用已有的知识蒸馏技术创建更小、更专业的学生模型，以用于网络内容过滤。在将通过大型安全供应商收集的客户遥测数据的 30 个不同内容类别的网站进行分类的任务中，我们的学生模型通过蒸馏结果实现了 9% 的分类精度提升，超过了当前最先进方法。我们的学生模型在参数数量上与原始的大语言模型相比减少了 175 倍，从而达到了与老师模型相匹配的性能，可以用于大规模的在线扫描。

    We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9\% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large vo
    
[^13]: 基于自编码器的 ICU 临床代码预测

    Autoencoder-based prediction of ICU clinical codes. (arXiv:2305.04992v1 [cs.LG])

    [http://arxiv.org/abs/2305.04992](http://arxiv.org/abs/2305.04992)

    本文研究了基于自编码器的 ICU 临床代码预测，针对不完整的临床代码清单，使用了各种自编码器方法以及两个强基准。结果表明，基于共现的方法表现略微更好，对抗自编码器实现了最佳性能。

    

    电子病历中诊断代码的可用性对于患者护理以及报销目的至关重要。然而，将其输入到电子病历中非常繁琐，而且一些临床代码可能会被忽略。针对不完整的临床代码清单，我们研究了机器学习方法在预测完整临床代码方面的性能，并评估了在这项任务中包含其他临床患者数据的增加预测价值。我们使用了 MIMIC-III 数据集，并将完整临床代码的任务框架定为推荐问题。我们考虑了各种自编码器方法以及两个强基准；项共现和奇异值分解（SVD）。输入包括 1）记录的已知临床代码，2）代码加变量。基于共现的方法略微表现更好（F1 分数=0.26，均值平均准确度[MAP]=0.19），而 SVD（F1=0.24，MAP=0.18）表现较差。然而，当代码加变量时，对抗自编码器实现了最佳性能。

    Availability of diagnostic codes in Electronic Health Records (EHRs) is crucial for patient care as well as reimbursement purposes. However, entering them in the EHR is tedious, and some clinical codes may be overlooked. Given an in-complete list of clinical codes, we investigate the performance of ML methods on predicting the complete ones, and assess the added predictive value of including other clinical patient data in this task. We used the MIMIC-III dataset and frame the task of completing the clinical codes as a recommendation problem. We con-sider various autoencoder approaches plus two strong baselines; item co-occurrence and Singular Value Decomposition (SVD). Inputs are 1) a record's known clinical codes, 2) the codes plus variables. The co-occurrence-based ap-proach performed slightly better (F1 score=0.26, Mean Average Precision [MAP]=0.19) than the SVD (F1=0.24, MAP=0.18). However, the adversarial autoencoder achieved the best performance when using the codes plus variable
    
[^14]: 基于图形遮盖自编码器的序列推荐系统

    Graph Masked Autoencoder for Sequential Recommendation. (arXiv:2305.04619v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.04619](http://arxiv.org/abs/2305.04619)

    提出了一种简单而有效的基于图遮盖自编码器的序列推荐系统，它使用基于图的注意力机制暴露出带有遮盖的项目序列，自适应动态提取全局项目转换信息进行自监督增强，在具有较少标记样本的情况下始终比最先进的序列推荐方法表现出更好的性能，而且对数据损坏和缺失情况具有鲁棒性。

    

    虽然一些强大的神经网络架构（例如Transformer、图神经网络）通过高阶项依赖建模在序列推荐中实现了改进的性能，但它们可能在标签稀缺情况下表现出较差的表征能力。为了解决标签不足的问题，对比学习（CL）已经引起了近期的关注，通过嵌入对比来进行自我监督的数据增强。然而，由于其对比视图生成策略的手工制定特性，现有的CL增强模型不仅难以在不同的序列推荐任务中产生一致的性能，还可能对用户行为数据噪声不具有鲁棒性。鉴于这一点，我们提出了一种简单而有效的自适应全局信息提取的图遮盖自编码器增强的序列推荐系统（MAERec）来解决这个问题。它自然地避免了上述问题，得益于其独特的数据重构机制。具体而言，我们的模型使用基于图的注意力机制，暴露出带有遮盖的项目序列，使表示不仅利用本地顺序信息，还利用项目之间的全局相关性。我们在四个基准数据集上对我们的方法进行了广泛评估。实验结果表明，我们的模型在具有较少标记样本的情况下始终比最先进的序列推荐方法表现出更好的性能，而且对数据损坏和缺失情况具有鲁棒性。

    While some powerful neural network architectures (e.g., Transformer, Graph Neural Networks) have achieved improved performance in sequential recommendation with high-order item dependency modeling, they may suffer from poor representation capability in label scarcity scenarios. To address the issue of insufficient labels, Contrastive Learning (CL) has attracted much attention in recent methods to perform data augmentation through embedding contrasting for self-supervision. However, due to the hand-crafted property of their contrastive view generation strategies, existing CL-enhanced models i) can hardly yield consistent performance on diverse sequential recommendation tasks; ii) may not be immune to user behavior data noise. In light of this, we propose a simple yet effective Graph Masked AutoEncoder-enhanced sequential Recommender system (MAERec) that adaptively and dynamically distills global item transitional information for self-supervised augmentation. It naturally avoids the abov
    
[^15]: 跨领域增强网络用于点击率预测

    Cross-domain Augmentation Networks for Click-Through Rate Prediction. (arXiv:2305.03953v1 [cs.IR])

    [http://arxiv.org/abs/2305.03953](http://arxiv.org/abs/2305.03953)

    本文中提出了一个跨领域增强网络（CDAnet），能够进行异构输入下的知识转移和生成增强样本减轻数据稀疏问题，实验证明其优于现有的基线方法。

    

    数据稀疏性是点击率预测的一个重要问题，特别是当用户-物品交互太稀疏以至于无法学习可靠的模型时。最近，为了利用相关领域的有意义数据，许多跨领域点击率（CDCTR）预测工作已经被开发出来。然而，大多数现有的CDCTR工作具有不切实际的限制，需要跨领域之间具有完全相同的特征输入，而跨领域与不同的特征输入的CDCTR尚未被广泛探索，但这是一个紧急和重要的研究问题。本文中，我们提出了一个跨领域增强网络（CDAnet），能够在具有异构输入的两个领域之间执行知识转移。具体而言，CDAnet包含一个设计良好的翻译网络和一个增强网络，这两个网络训练过程是依次进行的。翻译网络能够计算出具有异构输入的两个领域的特征，增强网络能够生成增强样本以缓解数据稀疏问题。在两个公共数据集上的大量实验证明了我们提出的方法优于现有的基线方法。

    Data sparsity is an important issue for click-through rate (CTR) prediction, particularly when user-item interactions is too sparse to learn a reliable model. Recently, many works on cross-domain CTR (CDCTR) prediction have been developed in an effort to leverage meaningful data from a related domain. However, most existing CDCTR works have an impractical limitation that requires homogeneous inputs (\textit{i.e.} shared feature fields) across domains, and CDCTR with heterogeneous inputs (\textit{i.e.} varying feature fields) across domains has not been widely explored but is an urgent and important research problem. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform knowledge transfer between two domains with \textit{heterogeneous inputs}. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network is able to compute features from two domains with heterogeneous 
    
[^16]: SLIM: 带倒排索引的多向量检索中的稀疏化晚互动

    SLIM: Sparsified Late Interaction for Multi-Vector Retrieval with Inverted Indexes. (arXiv:2302.06587v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.06587](http://arxiv.org/abs/2302.06587)

    SLIM是一种带倒排索引的多向量检索方法，通过对上下文化令牌嵌入进行稀疏化处理和晚期交互实现有效检索，且可与现成词库搜索库完全兼容。

    

    本文提出了一种带倒排索引的多向量( SLIM ) 检索方法。在多向量检索方法中，ColBERT是基于预训练语言模型的上下文化令牌嵌入的后期交互最成熟的方法。然而，有效实现ColBERT需要复杂的工程，不利于实际应用。为解决这个问题，SLIM首先将每个上下文化的令牌向量映射到一个稀疏的高维词汇空间，然后在这些稀疏的令牌嵌入之间执行晚期交互。然后，我们介绍了一种高效的两阶段检索体系结构，包括倒排索引检索和分数细化模块，以近似稀疏化的晚期交互，并与诸如Lucene这样的现成词库搜索库完全兼容。SLIM在各种检索数据集上实现了与ColBERT相当的性能，但具有更高的实用性和可扩展性。

    This paper introduces Sparsified Late Interaction for Multi-vector (SLIM) retrieval with inverted indexes. Multi-vector retrieval methods have demonstrated their effectiveness on various retrieval datasets, and among them, ColBERT is the most established method based on the late interaction of contextualized token embeddings of pre-trained language models. However, efficient ColBERT implementations require complex engineering and cannot take advantage of off-the-shelf search libraries, impeding their practical use. To address this issue, SLIM first maps each contextualized token vector to a sparse, high-dimensional lexical space before performing late interaction between these sparse token embeddings. We then introduce an efficient two-stage retrieval architecture that includes inverted index retrieval followed by a score refinement module to approximate the sparsified late interaction, which is fully compatible with off-the-shelf lexical search libraries such as Lucene. SLIM achieves 
    
[^17]: 无关语言的多语种信息检索与对比学习

    Language Agnostic Multilingual Information Retrieval with Contrastive Learning. (arXiv:2210.06633v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2210.06633](http://arxiv.org/abs/2210.06633)

    该论文提出一种使用对比学习的技术，利用平行和非平行语料库来提高多语种信息检索的效果，仅使用英语IR训练数据和一些平行语料库即可在非英语数据上实现显著的检索性能改进。

    

    多语种信息检索具有挑战性，因为在许多语言中获取经过注释的训练数据成本很高。我们提出了一种有效的方法，在只有英语IR训练数据和英语与其他语言之间的一些平行语料库可用时训练多语种IR系统。我们利用平行和非平行语料库来提高预训练多语种语言模型的跨语言传递能力，并设计了一个语义对比损失，以对齐在不同语言中具有相同语义的平行句子的表示，以及一种新的语言对比损失，利用平行句子对从非平行语料库中的句子表示中删除语言特定信息。在使用这些损失对英语IR数据进行训练并在非英语数据上进行零-shot评估时，我们的模型表现出明显的改进，同时需要较少的计算资源。我们还证明了该方法的实用价值。

    Multilingual information retrieval (IR) is challenging since annotated training data is costly to obtain in many languages. We present an effective method to train multilingual IR systems when only English IR training data and some parallel corpora between English and other languages are available. We leverage parallel and non-parallel corpora to improve the pretrained multilingual language models' cross-lingual transfer ability. We design a semantic contrastive loss to align representations of parallel sentences that share the same semantics in different languages, and a new language contrastive loss to leverage parallel sentence pairs to remove language-specific information in sentence representations from non-parallel corpora. When trained on English IR data with these losses and evaluated zero-shot on non-English data, our model demonstrates significant improvement to prior work on retrieval performance, while it requires much less computational effort. We also demonstrate the valu
    
[^18]: 推荐系统中的公平性：研究现状与未来方向

    Fairness in Recommender Systems: Research Landscape and Future Directions. (arXiv:2205.11127v4 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.11127](http://arxiv.org/abs/2205.11127)

    本文讨论了推荐系统的公平性问题，通过对160多篇学术出版物的综述总结了该领域目前的研究现状，强调了一些有前途的未来方向，例如需要超越统计平衡的新公平性衡量方法。

    

    推荐系统可以极大地影响我们在线上看到的信息，例如在社交媒体上，从而影响我们的信仰、决策和行动。同时，这些系统可以为不同的利益相关者创造巨大的商业价值。鉴于这种基于人工智能的系统对个人、组织和社会的潜在影响越来越大，公平性问题在近年来得到了越来越多的关注。然而，推荐系统公平性的研究仍然是一个正在发展的领域。在本次调查中，我们首先回顾了近年来在该领域提出的公平性基本概念和观念。随后，通过对160多篇学术出版物的综述，我们总结了这一领域目前的研究现状，例如一般研究方法、公平性措施和算法方法。总的来说，我们对最近研究的分析指出了某些研究空白。特别是，我们发现在许多研究中，对提出的模型的公平性提升属性缺乏实质性的评估。此外，该调查还强调了一些有前途的未来方向，例如需要超越统计平衡的新公平性衡量方法。

    Recommender systems can strongly influence which information we see online, e.g., on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterward, through a review of more than 160 scholarly publications, we present an overview of how research in this field is currently operationalized, e.g., in terms of general research methodology, fairness measures, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many resea
    
[^19]: 强化型异构信息网络下MOOC概念推荐研究

    Reinforced MOOCs Concept Recommendation in Heterogeneous Information Networks. (arXiv:2203.11011v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2203.11011](http://arxiv.org/abs/2203.11011)

    本文提出了一种强化学习框架下基于异构信息网络的概念推荐方法，可以更好地向不同专业水平的用户精细推荐知识。

    

    大规模在线开放课程（MOOCs）通过互联网提供开放访问和广泛的互动参与，正在迅速成为在线和远程学习的首选方式。许多MOOC平台为用户提供课程推荐服务，以提高用户的学习体验。尽管这项服务很有用，但如果直接向用户推荐课程可能会忽视他们不同的专业水平，因此本文考虑了概念推荐这个问题，可以精细地向用户推荐知识。我们提出了一种新颖的方法——HinCRec-RL来解决MOOC中的概念推荐问题，该方法基于异构信息网络和强化学习。具体而言，我们提出将概念推荐问题塑造在强化学习框架内，以表征用户和知识概念之间的动态交互。

    Massive open online courses (MOOCs), which offer open access and widespread interactive participation through the internet, are quickly becoming the preferred method for online and remote learning. Several MOOC platforms offer the service of course recommendation to users, to improve the learning experience of users. Despite the usefulness of this service, we consider that recommending courses to users directly may neglect their varying degrees of expertise. To mitigate this gap, we examine an interesting problem of concept recommendation in this paper, which can be viewed as recommending knowledge to users in a fine-grained way. We put forward a novel approach, termed HinCRec-RL, for Concept Recommendation in MOOCs, which is based on Heterogeneous Information Networks and Reinforcement Learning. In particular, we propose to shape the problem of concept recommendation within a reinforcement learning framework to characterize the dynamic interaction between users and knowledge concepts 
    

