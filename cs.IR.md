# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Faithful Temporal Question Answering over Heterogeneous Sources](https://arxiv.org/abs/2402.15400) | 提出了一个能跨异构来源进行操作的时态问答系统，通过强制执行时间约束以确保忠实回答，正确处理隐含问题，并以统一方式覆盖知识库、文本和网络表格。 |
| [^2] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^3] | [Countries pushing the boundaries of knowledge: the US dominance, China rise, and the EU stagnation](https://arxiv.org/abs/2402.15263) | 通过使用 Rk 指标研究了25个国家和欧盟在10个关键研究主题上的贡献，发现在技术领域，美国、中国和欧盟处于领先地位，而欧盟明显落后于中国。 |
| [^4] | [Multi-Agent Collaboration Framework for Recommender Systems](https://arxiv.org/abs/2402.15235) | MACRec是一个新颖的框架，旨在通过多智能体协作来增强推荐系统，提供了多种专业智能体的协作努力解决推荐任务，并提供了应用示例。 |
| [^5] | [Item-side Fairness of Large Language Model-based Recommendation System](https://arxiv.org/abs/2402.15215) | 该研究从物品侧公平性的角度探讨了基于大型语言模型的推荐系统，揭示了历史用户交互和模型固有语义偏见对其公平性的影响因素，提出了扩展传统公平性方法以适用于该推荐系统的需求。 |
| [^6] | [EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems](https://arxiv.org/abs/2402.15164) | EasyRL4Rec是一个面向基于强化学习的推荐系统的用户友好和高效库，提供了多样化的RL环境、全面的核心模块、一致的评估标准和定制解决方案，旨在帮助简化模型开发并改善长期用户参与度。 |
| [^7] | [Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding](https://arxiv.org/abs/2402.15102) | 自动广告竞标中使用了一种新的迭代离线强化学习框架，有效缓解了传统RL算法在在线环境下性能下降的问题。 |
| [^8] | [ColBERT-XM: A Modular Multi-Vector Representation Model for Zero-Shot Multilingual Information Retrieval](https://arxiv.org/abs/2402.15059) | ColBERT-XM模型通过从单一高资源语言的数据中学习，实现了零-shot转移到广泛的语言，从而消除了对特定语言标记数据的需求。 |
| [^9] | [Filter Bubble or Homogenization? Disentangling the Long-Term Effects of Recommendations on User Consumption Patterns](https://arxiv.org/abs/2402.15013) | 本文解析了推荐算法对用户行为的长期影响，探讨了同质化和滤泡效应之间的关系，发现个性化推荐能够缓解滤泡效应。 |
| [^10] | [Stealthy Attack on Large Language Model based Recommendation](https://arxiv.org/abs/2402.14836) | 大型语言模型推荐系统容易受到隐秘攻击，攻击者可以通过微调文本内容在不干预模型训练的情况下显著提高物品的曝光度，而这种攻击对整体推荐性能无影响且难以被检测到。 |
| [^11] | [MSynFD: Multi-hop Syntax aware Fake News Detection](https://arxiv.org/abs/2402.14834) | 提出一种新的多跳语法感知假新闻检测方法，通过引入补充的语法信息来处理假新闻中的微妙转折 |
| [^12] | [Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks](https://arxiv.org/abs/2402.13787) | 本文研究了链接分析算法在阻止少数群体在网络中达到高排名位置的条件，发现PageRank能够平衡排名中少数群体的代表性，而HITS则在同构网络中通过新颖的理论分析放大了现有的偏见。 |
| [^13] | [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727) | ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。 |
| [^14] | [A Unified Framework for Multi-Domain CTR Prediction via Large Language Models](https://arxiv.org/abs/2312.10743) | 通过大型语言模型实现了统一框架，可以在多个领域进行点击率预测，避免了传统模型中忽略语义信息导致的泛化困难，并解决了部分领域主导性导致性能下降的问题。 |
| [^15] | [Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions](https://arxiv.org/abs/2311.04590) | 提出了一个适用于跨领域序列推荐的自适应多兴趣去偏见框架（AMID），在开放世界假设下设计，旨在解决现有方法在在线真实平台上由于数据分布转移导致性能下降的问题。 |
| [^16] | [Re3val: Reinforced and Reranked Generative Retrieval.](http://arxiv.org/abs/2401.16979) | Re3val是一个使用强化学习和重新排名技术进行训练的生成检索模型，它通过利用上下文信息来重新排名检索得到的页面标题，以最大化通过受限解码生成的奖励。同时，该模型通过生成问题来减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。 |
| [^17] | [Dissecting users' needs for search result explanations.](http://arxiv.org/abs/2401.16509) | 该论文研究了用户对搜索结果解释的需求，发现用户不总是寻求解释，但对于复杂和关键的任务，解释是有益处的。该研究还总结了有益的解释的关键特征，并提出了对搜索引擎和解释的设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。 |

# 详细

[^1]: 跨异构来源的忠实时态问答

    Faithful Temporal Question Answering over Heterogeneous Sources

    [https://arxiv.org/abs/2402.15400](https://arxiv.org/abs/2402.15400)

    提出了一个能跨异构来源进行操作的时态问答系统，通过强制执行时间约束以确保忠实回答，正确处理隐含问题，并以统一方式覆盖知识库、文本和网络表格。

    

    时态问答涉及时间约束，例如“...在2019年”或“...在COVID之前”。在前者中，时间是一个明确的条件，在后者中，它是隐含的。现有技术方法在三个方面存在局限性。首先，使用神经推理时，时间约束仅被软匹配，容易导致无效或无法解释的答案。其次，对于涉及隐含时间的问题支持不足。第三，答案只来自单一来源：知识库（KB）或文本语料库。我们提出了一个时态问答系统来解决这些缺陷。首先，它通过具体证据强制执行时间约束以确保忠实回答。其次，它正确处理隐含问题。第三，它以统一方式覆盖知识库、文本和网络表格，跨异构来源进行操作。该方法分为三个阶段：（i）理解问题及其时间条件，（ii）从中检索证据

    arXiv:2402.15400v1 Announce Type: cross  Abstract: Temporal question answering (QA) involves time constraints, with phrases such as "... in 2019" or "... before COVID". In the former, time is an explicit condition, in the latter it is implicit. State-of-the-art methods have limitations along three dimensions. First, with neural inference, time constraints are merely soft-matched, giving room to invalid or inexplicable answers. Second, questions with implicit time are poorly supported. Third, answers come from a single source: either a knowledge base (KB) or a text corpus. We propose a temporal QA system that addresses these shortcomings. First, it enforces temporal constraints for faithful answering with tangible evidence. Second, it properly handles implicit questions. Third, it operates over heterogeneous sources, covering KB, text and web tables in a unified manner. The method has three stages: (i) understanding the question and its temporal conditions, (ii) retrieving evidence from
    
[^2]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^3]: 各国在知识边界上的努力：美国主导地位、中国崛起和欧盟停滞

    Countries pushing the boundaries of knowledge: the US dominance, China rise, and the EU stagnation

    [https://arxiv.org/abs/2402.15263](https://arxiv.org/abs/2402.15263)

    通过使用 Rk 指标研究了25个国家和欧盟在10个关键研究主题上的贡献，发现在技术领域，美国、中国和欧盟处于领先地位，而欧盟明显落后于中国。

    

    知道哪些国家对推动科学技术知识边界的拓展贡献最大具有社会和政治重要性。然而，常见的引用度量不足以衡量这种贡献。这种度量需要更严格的指标，适用于推动知识边界的极具影响力的突破性论文，这些论文引用量很高但非常罕见。本文使用最近描述的 Rk 指标，专门设计用于解决这个问题。作者将这一指标应用于 25 个国家和欧盟在 10 个关键研究主题上，其中五个是技术主题，五个是生物医学主题，独立地研究了国内和国际合作论文。在技术主题上，国内论文的 Rk 指数显示，总体而言，美国、中国和欧盟处于领先地位；其他国家明显落后。美国明显领先于中国，而欧盟远远落后于中国。生物医学主题采用相同的方法...

    arXiv:2402.15263v1 Announce Type: cross  Abstract: Knowing which countries contribute the most to pushing the boundaries of knowledge in science and technology has social and political importance. However, common citation metrics do not adequately measure this contribution. This measure requires more stringent metrics appropriate for the highly influential breakthrough papers that push the boundaries of knowledge, which are very highly cited but very rare. Here I used the recently described Rk index, specifically designed to address this issue. I applied this index to 25 countries and the EU across 10 key research topics, five technological and five biomedical, studying domestic and international collaborative papers independently. In technological topics, the Rk indices of domestic papers show that overall, the USA, China, and the EU are leaders; other countries are clearly behind. The USA is notably ahead of China, and the EU is far behind China. The same approach to biomedical topic
    
[^4]: 用于推荐系统的多智能体协作框架

    Multi-Agent Collaboration Framework for Recommender Systems

    [https://arxiv.org/abs/2402.15235](https://arxiv.org/abs/2402.15235)

    MACRec是一个新颖的框架，旨在通过多智能体协作来增强推荐系统，提供了多种专业智能体的协作努力解决推荐任务，并提供了应用示例。

    

    基于LLM的智能体因其决策技能和处理复杂任务的能力而受到广泛关注。鉴于当前在利用智能体协作能力增强推荐系统方面存在的空白，我们介绍了MACRec，这是一个旨在通过多智能体协作增强推荐系统的新颖框架。与现有关于使用智能体进行用户/商品模拟的工作不同，我们旨在部署多智能体直接处理推荐任务。在我们的框架中，通过各种专业智能体的协作努力来解决推荐任务，包括经理、用户/商品分析师、反射器、搜索器和任务解释器，它们具有不同的工作流。此外，我们提供应用示例，说明开发人员如何轻松在各种推荐任务上使用MACRec，包括评分预测、序列推荐、对话推荐和解释生成。

    arXiv:2402.15235v1 Announce Type: new  Abstract: LLM-based agents have gained considerable attention for their decision-making skills and ability to handle complex tasks. Recognizing the current gap in leveraging agent capabilities for multi-agent collaboration in recommendation systems, we introduce MACRec, a novel framework designed to enhance recommendation systems through multi-agent collaboration. Unlike existing work on using agents for user/item simulation, we aim to deploy multi-agents to tackle recommendation tasks directly. In our framework, recommendation tasks are addressed through the collaborative efforts of various specialized agents, including Manager, User/Item Analyst, Reflector, Searcher, and Task Interpreter, with different working flows. Furthermore, we provide application examples of how developers can easily use MACRec on various recommendation tasks, including rating prediction, sequential recommendation, conversational recommendation, and explanation generation
    
[^5]: 基于大型语言模型的推荐系统的物品侧公平性

    Item-side Fairness of Large Language Model-based Recommendation System

    [https://arxiv.org/abs/2402.15215](https://arxiv.org/abs/2402.15215)

    该研究从物品侧公平性的角度探讨了基于大型语言模型的推荐系统，揭示了历史用户交互和模型固有语义偏见对其公平性的影响因素，提出了扩展传统公平性方法以适用于该推荐系统的需求。

    

    arXiv:2402.15215v1 公告类型: 新 推荐系统对Web内容分发密切关联着弱势群体的信息获取和暴露机会。基于大型语言模型(LRS)的推荐系统的出现可能由于大型语言模型(LLMs)内在偏见而向推荐系统引入额外的社会挑战。从物品侧公平性的视角看，鉴于LRS与传统推荐系统相比的独特特性，关于LRS的物品侧公平性仍缺乏全面的调查。为弥补这一差距，本研究审视了LRS的属性与物品侧公平性，并揭示了历史用户交互和LLMs固有语义偏见的影响因素，揭示了需要扩展传统物品侧公平性方法以适用于LRS的需求。为实现这一目标，我们开发了一个简洁有效的框架称为IFairLRS。

    arXiv:2402.15215v1 Announce Type: new  Abstract: Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS 
    
[^6]: EasyRL4Rec：面向基于强化学习的推荐系统的用户友好代码库

    EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender Systems

    [https://arxiv.org/abs/2402.15164](https://arxiv.org/abs/2402.15164)

    EasyRL4Rec是一个面向基于强化学习的推荐系统的用户友好和高效库，提供了多样化的RL环境、全面的核心模块、一致的评估标准和定制解决方案，旨在帮助简化模型开发并改善长期用户参与度。

    

    强化学习（RL）-基础的推荐系统（RSs）越来越被认可其提高长期用户参与度的能力。然而，这个领域面临挑战，如缺乏易用的框架、评估标准不一致以及复制以前的工作的复杂性。为解决这些障碍，我们提出了EasyRL4Rec，一个专为基于RL的RSs量身定制的用户友好和高效的库。EasyRL4Rec具有基于五个广泛使用的公共数据集构建的轻量级、多样化的RL环境，并配备了全面的核心模块，提供丰富的选项来简化模型的开发。它建立了一致的评估标准，重点关注长期影响，并引入了针对推荐系统定制的状态建模和行为表示的定制解决方案。此外，我们分享了通过与当前方法进行的大量实验获得的宝贵见解。EasyRL4Rec旨在促进

    arXiv:2402.15164v1 Announce Type: cross  Abstract: Reinforcement Learning (RL)-Based Recommender Systems (RSs) are increasingly recognized for their ability to improve long-term user engagement. Yet, the field grapples with challenges such as the absence of accessible frameworks, inconsistent evaluation standards, and the complexity of replicating prior work. Addressing these obstacles, we present EasyRL4Rec, a user-friendly and efficient library tailored for RL-based RSs. EasyRL4Rec features lightweight, diverse RL environments built on five widely-used public datasets, and is equipped with comprehensive core modules that offer rich options to ease the development of models. It establishes consistent evaluation criteria with a focus on long-term impacts and introduces customized solutions for state modeling and action representation tailored to recommender systems. Additionally, we share valuable insights gained from extensive experiments with current methods. EasyRL4Rec aims to facil
    
[^7]: 轨迹式迭代强化学习框架用于自动竞标

    Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding

    [https://arxiv.org/abs/2402.15102](https://arxiv.org/abs/2402.15102)

    自动广告竞标中使用了一种新的迭代离线强化学习框架，有效缓解了传统RL算法在在线环境下性能下降的问题。

    

    在在线广告中，广告主参与广告竞拍以获取广告机会，通常是通过需求方平台(DSPs)提供的自动竞标工具。目前的自动竞标算法通常采用强化学习（RL）。然而，由于安全性问题，大多数基于RL的自动竞标策略是在模拟环境中进行训练的，在在线环境中部署会导致性能下降。为了缩小这一差距，我们可以并行部署多个自动竞标代理以收集大量交互数据集。然后，可以利用离线RL算法训练新策略。训练后的策略随后可以部署以进行进一步的数据收集，从而形成一个迭代训练框架，我们将其称为迭代离线RL。在这项工作中，我们确定了这种迭代离线RL框架的性能瓶颈，其根源在于由于内在原因而导致的探索和利用的低效问题。

    arXiv:2402.15102v1 Announce Type: cross  Abstract: In online advertising, advertisers participate in ad auctions to acquire ad opportunities, often by utilizing auto-bidding tools provided by demand-side platforms (DSPs). The current auto-bidding algorithms typically employ reinforcement learning (RL). However, due to safety concerns, most RL-based auto-bidding policies are trained in simulation, leading to a performance degradation when deployed in online environments. To narrow this gap, we can deploy multiple auto-bidding agents in parallel to collect a large interaction dataset. Offline RL algorithms can then be utilized to train a new policy. The trained policy can subsequently be deployed for further data collection, resulting in an iterative training framework, which we refer to as iterative offline RL. In this work, we identify the performance bottleneck of this iterative offline RL framework, which originates from the ineffective exploration and exploitation caused by the inhe
    
[^8]: ColBERT-XM：一种用于零-shot 多语信息检索的模块化多向量表示模型

    ColBERT-XM: A Modular Multi-Vector Representation Model for Zero-Shot Multilingual Information Retrieval

    [https://arxiv.org/abs/2402.15059](https://arxiv.org/abs/2402.15059)

    ColBERT-XM模型通过从单一高资源语言的数据中学习，实现了零-shot转移到广泛的语言，从而消除了对特定语言标记数据的需求。

    

    最先进的神经检索器主要集中在英语等高资源语言上，这阻碍了它们在涉及其他语言的检索场景中的应用。当前方法通过利用能够进行跨语言转移的多语言预训练语言模型来规避非英语语言中缺乏高质量标记数据的问题。然而，这些模型需要在多种语言上进行大量特定任务的微调，在预训练语料库中表示极少的语言中通常表现不佳，并且在预训练阶段之后难以融合新语言。在这项工作中，我们提出了一种新颖的模块化稠密检索模型，它从单一高资源语言的丰富数据中学习，并有效地零-shot 转移到广泛的语言，从而消除了对特定语言标记数据的需求。我们的模型 ColBERT-XM 在现有模型上展现出有竞争力的性能。

    arXiv:2402.15059v1 Announce Type: new  Abstract: State-of-the-art neural retrievers predominantly focus on high-resource languages like English, which impedes their adoption in retrieval scenarios involving other languages. Current approaches circumvent the lack of high-quality labeled data in non-English languages by leveraging multilingual pretrained language models capable of cross-lingual transfer. However, these models require substantial task-specific fine-tuning across multiple languages, often perform poorly in languages with minimal representation in the pretraining corpus, and struggle to incorporate new languages after the pretraining phase. In this work, we present a novel modular dense retrieval model that learns from the rich data of a single high-resource language and effectively zero-shot transfers to a wide array of languages, thereby eliminating the need for language-specific labeled data. Our model, ColBERT-XM, demonstrates competitive performance against existing st
    
[^9]: 推荐算法对用户消费模式长期影响的解析: 滤泡还是同质化？

    Filter Bubble or Homogenization? Disentangling the Long-Term Effects of Recommendations on User Consumption Patterns

    [https://arxiv.org/abs/2402.15013](https://arxiv.org/abs/2402.15013)

    本文解析了推荐算法对用户行为的长期影响，探讨了同质化和滤泡效应之间的关系，发现个性化推荐能够缓解滤泡效应。

    

    推荐算法在塑造我们的媒体选择方面起着至关重要的作用，因此了解它们对用户行为的长期影响至关重要。这些算法通常与两个关键结果相关联：同质化，即使用户具有不同的基本偏好，也会消费相似的内容，以及滤泡效应，即具有不同偏好的个人仅消费与其偏好一致的内容（与其他用户几乎没有重叠）。先前的研究假设同质化和滤泡效应之间存在权衡，并展示个性化推荐通过促进同质化来缓解滤泡效应。然而，由于这一对这两种效应之间的权衡的假设，先前的工作无法发展出一种更为细致的看法，即推荐系统可能如何独立影响同质化和滤泡效应。我们对同质化和滤泡效应进行了更精细的定义

    arXiv:2402.15013v1 Announce Type: cross  Abstract: Recommendation algorithms play a pivotal role in shaping our media choices, which makes it crucial to comprehend their long-term impact on user behavior. These algorithms are often linked to two critical outcomes: homogenization, wherein users consume similar content despite disparate underlying preferences, and the filter bubble effect, wherein individuals with differing preferences only consume content aligned with their preferences (without much overlap with other users). Prior research assumes a trade-off between homogenization and filter bubble effects and then shows that personalized recommendations mitigate filter bubbles by fostering homogenization. However, because of this assumption of a tradeoff between these two effects, prior work cannot develop a more nuanced view of how recommendation systems may independently impact homogenization and filter bubble effects. We develop a more refined definition of homogenization and the 
    
[^10]: 大型语言模型推荐中的隐秘攻击

    Stealthy Attack on Large Language Model based Recommendation

    [https://arxiv.org/abs/2402.14836](https://arxiv.org/abs/2402.14836)

    大型语言模型推荐系统容易受到隐秘攻击，攻击者可以通过微调文本内容在不干预模型训练的情况下显著提高物品的曝光度，而这种攻击对整体推荐性能无影响且难以被检测到。

    

    最近，强大的大型语言模型(LLMs)在推动推荐系统(RS)的进展方面发挥了重要作用。然而，尽管这些系统蓬勃发展，但它们对安全威胁的敏感性却被大多忽视了。在这项工作中，我们揭示了LLMs引入推荐模型中产生新安全漏洞的情况，这是由于它们注重物品的文本内容。我们证明了攻击者可以在测试阶段仅通过改变物品的文本内容显著增加其曝光度，而无需直接干预模型的训练过程。此外，该攻击具有显著的隐秘性，因为它不会影响整体推荐性能，对文本的修改微妙，使用户和平台难以检测到。我们在四个主流的LLM-based推荐模型上进行了全面的实验。

    arXiv:2402.14836v1 Announce Type: cross  Abstract: Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item's exposure by merely altering its textual content during the testing phase, without requiring direct interference with the model's training process. Additionally, the attack is notably stealthy, as it does not affect the overall recommendation performance and the modifications to the text are subtle, making it difficult for users and platforms to detect. Our comprehensive experiments across four mainstream LLM-based recommendation models demonstrate the superior
    
[^11]: MSynFD: 多跳语法感知假新闻检测

    MSynFD: Multi-hop Syntax aware Fake News Detection

    [https://arxiv.org/abs/2402.14834](https://arxiv.org/abs/2402.14834)

    提出一种新的多跳语法感知假新闻检测方法，通过引入补充的语法信息来处理假新闻中的微妙转折

    

    社交媒体平台的广泛传播助长了假新闻的快速传播，对我们的现实社会构成威胁。现有方法使用多模态数据或上下文信息来增强对假新闻的检测，通过分析新闻内容和/或其社会背景。然而，这些方法常常忽视了基本的文本新闻内容（文章），并且过分依赖序列建模和全局注意力来提取语义信息。这些现有方法无法处理新闻文章中的复杂、微妙的转折，比如句法-语义不匹配和先验偏差，导致性能较低，并在缺失模态或社会背景时可能失败。为了弥合这些重要差距，我们提出了一种新颖的多跳语法感知假新闻检测（MSynFD）方法，该方法融合了补充的语法信息，以处理假新闻中的微妙转折。

    arXiv:2402.14834v1 Announce Type: cross  Abstract: The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical depen
    
[^12]: 从排名中崛起的公平性：HITS和PageRank在同质网络上的应用

    Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks

    [https://arxiv.org/abs/2402.13787](https://arxiv.org/abs/2402.13787)

    本文研究了链接分析算法在阻止少数群体在网络中达到高排名位置的条件，发现PageRank能够平衡排名中少数群体的代表性，而HITS则在同构网络中通过新颖的理论分析放大了现有的偏见。

    

    在本文中，我们研究了链接分析算法在阻止少数群体达到高排名位置的条件。我们发现，使用中心性度量标准的最常见链接算法，如PageRank和HITS，在网络中可能再现甚至放大对少数群体的偏见。然而，它们的行为有所不同：一方面，我们凭经验证明，PageRank在大部分排名位置上反映了度分布，并且可以平衡少数群体在排名靠前的节点中的代表性；另一方面，我们发现HITS通过新颖的理论分析在同构网络中放大了现有的偏见，支撑证据为实证结果。我们发现HITS中偏见放大的根本原因是网络中存在的同质性水平，通过一个具有两个社区的不断发展的网络模型进行建模。我们以合成和真实数据集阐明了我们的理论分析。

    arXiv:2402.13787v1 Announce Type: cross  Abstract: In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we pr
    
[^13]: 一种具有长期上下文概要记忆的人工智能阅读代理

    A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts

    [https://arxiv.org/abs/2402.09727](https://arxiv.org/abs/2402.09727)

    ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。

    

    当前的大型语言模型不仅限制在某个最大上下文长度内，而且无法稳定地处理长输入。为了解决这些限制，我们提出了ReadAgent，一个增加了有效上下文长度的语言模型代理系统，在我们的实验中可以达到20倍。受到人类交互式阅读长文档的启发，我们将ReadAgent实现为一个简单的提示系统，利用LLM的高级语言能力来：（1）决定将哪些内容存储在一个记忆片段中，（2）将这些记忆片段压缩成为称为概要记忆的短时记忆，（3）在需要时通过原始文本查找段落来提醒自己相关细节以完成任务。我们使用检索方法、使用原始长上下文以及使用概要记忆来评估ReadAgent与基线的性能。这些评估是在三个长文档阅读理解任务上进行的。

    arXiv:2402.09727v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension task
    
[^14]: 通过大型语言模型实现多领域点击率预测的统一框架

    A Unified Framework for Multi-Domain CTR Prediction via Large Language Models

    [https://arxiv.org/abs/2312.10743](https://arxiv.org/abs/2312.10743)

    通过大型语言模型实现了统一框架，可以在多个领域进行点击率预测，避免了传统模型中忽略语义信息导致的泛化困难，并解决了部分领域主导性导致性能下降的问题。

    

    点击率（CTR）预测是在线推荐平台中的重要任务，涉及估计用户通过点击广告或物品而参与的概率。给定各类服务如在线购物、打车、外卖和专业服务在商业平台上的可用性，这些平台的推荐系统需要跨多个领域进行CTR预测，而不仅仅是单一领域。然而，由于领域之间的复杂相互影响，多领域点击率（MDCTR）预测仍然是在线推荐中一个具有挑战性的任务。传统的MDCTR模型通常将领域编码为离散标识符，忽略了潜在的丰富语义信息。因此，它们很难推广到新的领域。此外，现有模型很容易被某些特定领域所主导，导致性能显著下降。

    arXiv:2312.10743v3 Announce Type: replace  Abstract: Click-Through Rate (CTR) prediction is a crucial task in online recommendation platforms as it involves estimating the probability of user engagement with advertisements or items by clicking on them. Given the availability of various services like online shopping, ride-sharing, food delivery, and professional services on commercial platforms, recommendation systems in these platforms are required to make CTR predictions across multiple domains rather than just a single domain. However, multi-domain click-through rate (MDCTR) prediction remains a challenging task in online recommendation due to the complex mutual influence between domains. Traditional MDCTR models typically encode domains as discrete identifiers, ignoring rich semantic information underlying. Consequently, they can hardly generalize to new domains. Besides, existing models can be easily dominated by some specific domains, which results in significant performance drops
    
[^15]: 在开放世界假设下重新思考跨领域序列推荐

    Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions

    [https://arxiv.org/abs/2311.04590](https://arxiv.org/abs/2311.04590)

    提出了一个适用于跨领域序列推荐的自适应多兴趣去偏见框架（AMID），在开放世界假设下设计，旨在解决现有方法在在线真实平台上由于数据分布转移导致性能下降的问题。

    

    跨领域顺序推荐（CDSR）方法旨在解决单一领域顺序推荐（SDSR）中存在的数据稀疏和冷启动问题。现有的CDSR作品设计其精心的结构，依赖于重叠用户来传播跨领域信息。然而，当前的CDSR方法采用封闭世界假设，假设在多个领域之间完全重叠的用户，并且数据分布从训练环境到测试环境保持不变。因此，这些方法通常因数据分布转移而在在线真实平台上表现较差。为了在开放世界假设下解决这些挑战，我们设计了一个自适应多兴趣去偏见框架，用于跨领域序列推荐（AMID），其中包括一个多兴趣信息模块（MIM）和一个双重鲁

    arXiv:2311.04590v3 Announce Type: replace  Abstract: Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data sparsity and cold-start problems present in Single-Domain Sequential Recommendation (SDSR). Existing CDSR works design their elaborate structures relying on overlapping users to propagate the cross-domain information. However, current CDSR methods make closed-world assumptions, assuming fully overlapping users across multiple domains and that the data distribution remains unchanged from the training environment to the test environment. As a result, these methods typically result in lower performance on online real-world platforms due to the data distribution shifts. To address these challenges under open-world assumptions, we design an \textbf{A}daptive \textbf{M}ulti-\textbf{I}nterest \textbf{D}ebiasing framework for cross-domain sequential recommendation (\textbf{AMID}), which consists of a multi-interest information module (\textbf{MIM}) and a doubly robu
    
[^16]: Re3val: 强化和重新排名的生成检索

    Re3val: Reinforced and Reranked Generative Retrieval. (arXiv:2401.16979v1 [cs.IR])

    [http://arxiv.org/abs/2401.16979](http://arxiv.org/abs/2401.16979)

    Re3val是一个使用强化学习和重新排名技术进行训练的生成检索模型，它通过利用上下文信息来重新排名检索得到的页面标题，以最大化通过受限解码生成的奖励。同时，该模型通过生成问题来减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。

    

    生成检索模型将文档中的信息指针编码为模型参数中的索引。这些模型作为更大的流程的一部分，通过检索的信息来为知识密集型自然语言处理任务生成条件。然而，我们发现有两个限制：生成检索没有考虑上下文信息。其次，检索无法为下游读者进行调整，因为解码页面标题是一个非可微分的操作。本文介绍了经过有限数据训练的生成重新排名和强化学习的 Re3val。Re3val利用通过密集通道检索获得的上下文对已检索页面标题进行重新排名，并利用REINFORCE算法最大化受限解码生成的奖励。此外，我们从预训练数据集中生成问题，以减小认识不确定性，并弥合预训练和微调数据集之间的领域差距。随后，我们从中提取和重新排名上下文信息。

    Generative retrieval models encode pointers to information in a corpus as an index within the model's parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can't be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from th
    
[^17]: 揭示用户对搜索结果解释的需求

    Dissecting users' needs for search result explanations. (arXiv:2401.16509v1 [cs.HC])

    [http://arxiv.org/abs/2401.16509](http://arxiv.org/abs/2401.16509)

    该论文研究了用户对搜索结果解释的需求，发现用户不总是寻求解释，但对于复杂和关键的任务，解释是有益处的。该研究还总结了有益的解释的关键特征，并提出了对搜索引擎和解释的设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。

    

    对于搜索引擎如何解释搜索结果的问题，已有研究假设解释会有益处，并引入了搜索结果解释。然而，我们的研究从根本上考虑了搜索解释是否需要以及何时会有益处。此外，我们总结了有益的解释的关键特征，并分享了用户对Google和Bing提供的解释功能的看法。对非技术人员的访谈显示，用户并不总是寻求或理解搜索解释，但对于复杂和关键的任务，他们觉得解释有帮助。他们认为Google的搜索解释太明显，但赞赏能够质疑搜索结果的能力。根据我们的研究结果，我们提供了设计建议，以帮助用户更好地评估搜索结果并提升他们的搜索体验。

    There is a growing demand for transparency in search engines to understand how search results are curated and to enhance users' trust. Prior research has introduced search result explanations with a focus on how to explain, assuming explanations are beneficial. Our study takes a step back to examine if search explanations are needed and when they are likely to provide benefits. Additionally, we summarize key characteristics of helpful explanations and share users' perspectives on explanation features provided by Google and Bing. Interviews with non-technical individuals reveal that users do not always seek or understand search explanations and mostly desire them for complex and critical tasks. They find Google's search explanations too obvious but appreciate the ability to contest search results. Based on our findings, we offer design recommendations for search engines and explanations to help users better evaluate search results and enhance their search experience.
    

