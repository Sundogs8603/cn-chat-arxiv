# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains.](http://arxiv.org/abs/2303.14475) | 本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。 |
| [^2] | [Evolution of the Online Rating Platform Data Structures and its Implications for Recommender Systems.](http://arxiv.org/abs/2303.14419) | 本文通过泊松过程分析在线评分平台的数据演化机制，发现均匀泊松过程无法捕捉用户在该平台上的评价行为机制，而非均匀泊松过程是兼容的。 |
| [^3] | [Analysis and Visualization of the Parameter Space of Matrix Factorization-based Recommender Systems.](http://arxiv.org/abs/2303.14417) | 本文通过可视化矩阵分解技术的参数空间内部结构，证明了其参数的分布不是多元正态分布。 |
| [^4] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^5] | [Towards Reliable Item Sampling for Recommendation Evaluation.](http://arxiv.org/abs/2211.15743) | 本文研究面向推荐系统评估的可靠物品采样方法，提出了一种新的采样估计器，优化误差和理论精度。 |
| [^6] | [Latent User Intent Modeling for Sequential Recommenders.](http://arxiv.org/abs/2211.09832) | 该论文提出了一种基于概率建模和变分自编码器的方法，将用户意图作为潜在变量，从而更好地理解用户并优化长期用户体验，证明其在离线分析和实时实验中的有效性。 |

# 详细

[^1]: 信息学习、中心性、卷积神经网络、相关文献检测、土著人类遗骸归还

    Informed Machine Learning, Centrality, CNN, Relevant Document Detection, Repatriation of Indigenous Human Remains. (arXiv:2303.14475v1 [cs.CL])

    [http://arxiv.org/abs/2303.14475](http://arxiv.org/abs/2303.14475)

    本篇研究介绍了研发出一个机器学习系统的进展, 该系统可以自动查找并语义分析相关文献,以协助土著人类寻找其被盗窃、捐赠、出售或在机构之间交换的遗骸信息。

    

    澳大利亚和其他原住民面临的紧迫问题之一是将他们祖先的尸体遗骸归还到西方科学机构。成功将这些遗骸返还到其社区以重新安葬，主要取决于在1790年至1970年期间发表的科学和其他文献中找到记录它们被盗窃、捐赠、出售或在机构之间交换的信息。本文报道了由数据科学家和社会科学研究人员在“研究、和解、更新”网络（RRR）中进行的协作研究，以开发和应用文本挖掘技术来确定这些关键信息。我们描述了我们迄今为止开发基于机器学习的解决方案以自动化查找和语义分析相关文本的工作。分类模型，特别是基于深度学习的模型，在使用少量标记数据进行训练时精度低。

    Among the pressing issues facing Australian and other First Nations peoples is the repatriation of the bodily remains of their ancestors, which are currently held in Western scientific institutions. The success of securing the return of these remains to their communities for reburial depends largely on locating information within scientific and other literature published between 1790 and 1970 documenting their theft, donation, sale, or exchange between institutions. This article reports on collaborative research by data scientists and social science researchers in the Research, Reconcile, Renew Network (RRR) to develop and apply text mining techniques to identify this vital information. We describe our work to date on developing a machine learning-based solution to automate the process of finding and semantically analysing relevant texts. Classification models, particularly deep learning-based models, are known to have low accuracy when trained with small amounts of labelled (i.e. rele
    
[^2]: 在线评分平台数据结构的演化及其对推荐系统的影响

    Evolution of the Online Rating Platform Data Structures and its Implications for Recommender Systems. (arXiv:2303.14419v1 [cs.IR])

    [http://arxiv.org/abs/2303.14419](http://arxiv.org/abs/2303.14419)

    本文通过泊松过程分析在线评分平台的数据演化机制，发现均匀泊松过程无法捕捉用户在该平台上的评价行为机制，而非均匀泊松过程是兼容的。

    

    在线评分平台代表了在线文化和商业商品消费的新趋势。此类平台上的用户评分数据是推荐算法的重要依据。了解数据演化模式及其潜在机制是理解推荐系统输入数据结构的关键。以往推荐系统输入数据分析的研究相当有限，唯一的例外是2018年的一项研究。本文利用泊松过程分析输入数据结构的演化机制。我们发现均匀泊松过程无法捕捉用户在在线评分平台上的评价行为机制，而非均匀泊松过程与形成过程是兼容的。

    Online rating platform represents the new trend of online cultural and commercial goods consumption. The user rating data on such platforms are foods for recommender system algorithms. Understanding the evolution pattern and its underlying mechanism is the key to understand the structures of input data for recommender systems. Prior research on input data analysis for recommender systems is quite limited, with a notable exception in 2018 [6]. In this paper, we take advantage of Poisson Process to analyze the evolution mechanism of the input data structures. We discover that homogeneous Poisson Process could not capture the mechanism of user rating behavior on online rating platforms, and inhomogeneous Poisson Process is compatible with the formation process.
    
[^3]: 基于矩阵分解推荐系统参数空间的分析与可视化

    Analysis and Visualization of the Parameter Space of Matrix Factorization-based Recommender Systems. (arXiv:2303.14417v1 [cs.IR])

    [http://arxiv.org/abs/2303.14417](http://arxiv.org/abs/2303.14417)

    本文通过可视化矩阵分解技术的参数空间内部结构，证明了其参数的分布不是多元正态分布。

    

    推荐系统是过去十年中最成功的商业技术。像Temu、TikTok和亚马逊这样的技术巨头利用这项技术每年创造巨额收入。虽然有足够的研究文献来提高技术的准确性，但可解释的AI仍然是该领域的新思路。2022年，本文作者提供了矩阵分解方法的几何解释，并使用几何逼近来解决推荐问题。我们在本文中继续沿着这个方向进行研究，并可视化矩阵分解技术的参数空间的内部结构。我们展示了矩阵分解方法的参数分布在一个超球体内。经过进一步分析，我们证明参数的分布不是多元正态分布。

    Recommender system is the most successful commercial technology in the past decade. Technical mammoth such as Temu, TikTok and Amazon utilize the technology to generate enormous revenues each year. Although there have been enough research literature on accuracy enhancement of the technology, explainable AI is still a new idea to the field. In 2022, the author of this paper provides a geometric interpretation of the matrix factorization-based methods and uses geometric approximation to solve the recommendation problem. We continue the research in this direction in this paper, and visualize the inner structure of the parameter space of matrix factorization technologies. We show that the parameters of matrix factorization methods are distributed within a hyper-ball. After further analysis, we prove that the distribution of the parameters is not multivariate normal.
    
[^4]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^5]: 面向可靠的推荐评估的推荐物品采样研究

    Towards Reliable Item Sampling for Recommendation Evaluation. (arXiv:2211.15743v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.15743](http://arxiv.org/abs/2211.15743)

    本文研究面向推荐系统评估的可靠物品采样方法，提出了一种新的采样估计器，优化误差和理论精度。

    

    自从Rendle和Krichene认为常用的基于采样的评估方法与全局度量不一致后，已经有一些关于基于采样的推荐系统评估的研究。现有的方法要么将基于采样的度量映射到全局度量，要么更一般地学习经验排名分布来估计前K度量。但是，尽管存在许多努力，但仍然缺乏对所提出的度量估计器的严格理论理解，而基本的物品采样也面临“盲点”问题，即当K很小时，估计恢复前K度量的准确性仍然可以相当大。本文深入研究这些问题，并作出两项创新性贡献。首先，我们提出了一种新的物品采样估计器，显式地优化了与基础真实值的误差，并在理论上突显了其

    Since Rendle and Krichene argued that commonly used sampling-based evaluation metrics are "inconsistent" with respect to the global metrics (even in expectation), there have been a few studies on the sampling-based recommender system evaluation. Existing methods try either mapping the sampling-based metrics to their global counterparts or more generally, learning the empirical rank distribution to estimate the top-$K$ metrics. However, despite existing efforts, there is still a lack of rigorous theoretical understanding of the proposed metric estimators, and the basic item sampling also suffers from the "blind spot" issue, i.e., estimation accuracy to recover the top-$K$ metrics when $K$ is small can still be rather substantial. In this paper, we provide an in-depth investigation into these problems and make two innovative contributions. First, we propose a new item-sampling estimator that explicitly optimizes the error with respect to the ground truth, and theoretically highlight its 
    
[^6]: 用于序列推荐器的潜在用户意图建模

    Latent User Intent Modeling for Sequential Recommenders. (arXiv:2211.09832v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.09832](http://arxiv.org/abs/2211.09832)

    该论文提出了一种基于概率建模和变分自编码器的方法，将用户意图作为潜在变量，从而更好地理解用户并优化长期用户体验，证明其在离线分析和实时实验中的有效性。

    

    序列推荐模型是现代工业推荐系统的关键组成部分。这些模型通过学习用户在平台上的互动历史，预测用户可能会与哪些项目进行交互。然而，大多数序列推荐器缺乏对用户意图的高级理解，而用户意图通常驱动着在线用户行为。因此，意图建模对于理解用户并优化长期用户体验至关重要。我们提出了一种概率建模方法，将用户意图作为潜在变量，并使用变分自编码器（VAE）根据用户行为信号进行推断。然后，根据推断出的用户意图调整推荐策略。我们通过离线分析和大规模工业推荐平台上的实时实验证明了潜在用户意图建模的有效性。

    Sequential recommender models are essential components of modern industrial recommender systems. These models learn to predict the next items a user is likely to interact with based on his/her interaction history on the platform. Most sequential recommenders however lack a higher-level understanding of user intents, which often drive user behaviors online. Intent modeling is thus critical for understanding users and optimizing long-term user experience. We propose a probabilistic modeling approach and formulate user intent as latent variables, which are inferred based on user behavior signals using variational autoencoders (VAE). The recommendation policy is then adjusted accordingly given the inferred user intent. We demonstrate the effectiveness of the latent user intent modeling via offline analyses as well as live experiments on a large-scale industrial recommendation platform.
    

