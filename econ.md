# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Coalitional Manipulations and Immunity of the Shapley Value.](http://arxiv.org/abs/2310.20415) | 本文研究了在群体博弈中的操纵现象，并提出了一种新的Shapley值基础，它是唯一的有效和对称的分配规则，对集体操纵具有免疫性。 |
| [^2] | [Robust Estimation of Realized Correlation: New Insight about Intraday Fluctuations in Market Betas.](http://arxiv.org/abs/2310.19992) | 本研究提出了一种新颖的子抽样象限估计方法，用于分析高频金融数据中的日内波动。通过该方法，我们发现日内β值的波动主要受日内相关性的波动驱动。 |
| [^3] | [Causal Q-Aggregation for CATE Model Selection.](http://arxiv.org/abs/2310.16945) | 该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率 |
| [^4] | [Improving Robust Decisions with Data.](http://arxiv.org/abs/2310.16281) | 该论文研究了如何通过数据改善鲁棒决策，并开发了简单易实现的推理方法以保证改善。 |
| [^5] | [Global Factors in Non-core Bank Funding and Exchange Rate Flexibility.](http://arxiv.org/abs/2310.11552) | 全球因素对发达经济体银行体系中非核心与核心资金比率的波动起主导作用，汇率灵活性能够在2008-2009年以外的时期减小这种影响。 |
| [^6] | [SGMM: Stochastic Approximation to Generalized Method of Moments.](http://arxiv.org/abs/2308.13564) | 我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。 |
| [^7] | [Robust Stackelberg Equilibria.](http://arxiv.org/abs/2304.14990) | 本论文系统研究了鲁棒斯塔克伯格均衡的概念，提出了一种新的解决方案RSE，旨在提高领袖策略的稳健性。我们证明了RSE的存在性，并研究了它的效用保证、算法和可学性。 |
| [^8] | [Measuring the strengths of the teams in the UEFA Champions League.](http://arxiv.org/abs/2304.09078) | 本文研究了UEFA俱乐部系数在保证欧洲冠军联赛对手实力相同方面的局限性，并提出通过考虑国内联赛的比赛成绩来改进系数的建议。 |
| [^9] | [Coherence without Rationality at the Zero Lower Bound.](http://arxiv.org/abs/2208.02073) | 该论文研究了在零下限条件下，非理性预期如何解决理性预期模型的一致性和完备性问题，提出了自我确认均衡和E稳定性准则作为解决方法。 |
| [^10] | [Detecting Grouped Local Average Treatment Effects and Selecting True Instruments.](http://arxiv.org/abs/2207.04481) | 我们提出了一个两步骤的过程来识别具有相同局部平均处理效应的响应组，并且即使有一些工具违反了识别假设，也可以选择真正满足假设的工具。 |
| [^11] | [The comparative statics of persuasion.](http://arxiv.org/abs/2204.07474) | 本论文主要研究了辩说模型中的比较静态问题，通过界定发信方中期回报变化的条件，确定了发信方在选择信号时会更倾向于选择具有更多信息量的信号。此外，论文还研究了发信方和接收方兴趣一致程度增加对比较静态的影响，并探讨了相关应用。 |
| [^12] | [Synthetic Interventions.](http://arxiv.org/abs/2006.07691) | 提出了一个称为合成干预的因果框架，能够在观察到每个单元最多两个干预措施的情况下推断每个单元对每个干预措施的预期潜在结果，具有有限样本一致性和渐近正态性。 |

# 详细

[^1]: 群体操纵与Shapley值的免疫性

    Coalitional Manipulations and Immunity of the Shapley Value. (arXiv:2310.20415v1 [econ.TH])

    [http://arxiv.org/abs/2310.20415](http://arxiv.org/abs/2310.20415)

    本文研究了在群体博弈中的操纵现象，并提出了一种新的Shapley值基础，它是唯一的有效和对称的分配规则，对集体操纵具有免疫性。

    

    我们考虑在群体博弈的背景下的操纵，其中一个联盟旨在增加其成员的总支付。如果一种分配规则对集体操纵免疫，那么没有任何联盟可以通过在其子联盟的层级上重新分配价值来获益（具有重新分配证明性），而且如果在其他条件不变的情况下，没有任何联盟可以从较低的价值中受益（具有弱集体单调性）。将Shapley在原始特征的可加性替换为这些要求可以得到Shapley值的新基础，即它是唯一的有效和对称的分配规则，对空玩家不予任何奖励，并且对集体操纵免疫。我们进一步发现，对于有效的分配规则，重新分配证明性等效于有约束的边际性，这是Young的边际性公理的一个较弱变体。我们的第二个特征改进了Young的特征，弱化了边际性内在的独立性要求。

    We consider manipulations in the context of coalitional games, where a coalition aims to increase the total payoff of its members. An allocation rule is immune to coalitional manipulation if no coalition can benefit from internal reallocation of worth on the level of its subcoalitions (reallocation-proofness), and if no coalition benefits from a lower worth while all else remains the same (weak coalitional monotonicity). Replacing additivity in Shapley's original characterization by these requirements yields a new foundation of the Shapley value, i.e., it is the unique efficient and symmetric allocation rule that awards nothing to a null player and is immune to coalitional manipulations. We further find that for efficient allocation rules, reallocation-proofness is equivalent to constrained marginality, a weaker variant of Young's marginality axiom. Our second characterization improves upon Young's characterization by weakening the independence requirement intrinsic to marginality.
    
[^2]: 鲁棒实现相关性估计：关于市场β值的日内波动的新见解

    Robust Estimation of Realized Correlation: New Insight about Intraday Fluctuations in Market Betas. (arXiv:2310.19992v1 [econ.EM])

    [http://arxiv.org/abs/2310.19992](http://arxiv.org/abs/2310.19992)

    本研究提出了一种新颖的子抽样象限估计方法，用于分析高频金融数据中的日内波动。通过该方法，我们发现日内β值的波动主要受日内相关性的波动驱动。

    

    时间变化的波动性是大多数经济时间序列的固有特征，这导致标准相关性估计不一致。象限相关性估计是一致但效率非常低的方法。我们提出了一种新颖的子抽样象限估计方法，可以在保持一致性和鲁棒性的同时提高效率。这种估计方法特别适用于高频金融数据，我们将其应用于大量的美国股票。我们的实证分析通过将市场β值分解为时间变化的相关性和相对波动性变化，为日内波动中的市场β值提供了新的见解。我们的结果表明，日内β值的波动主要受日内相关性的波动驱动。

    Time-varying volatility is an inherent feature of most economic time-series, which causes standard correlation estimators to be inconsistent. The quadrant correlation estimator is consistent but very inefficient. We propose a novel subsampled quadrant estimator that improves efficiency while preserving consistency and robustness. This estimator is particularly well-suited for high-frequency financial data and we apply it to a large panel of US stocks. Our empirical analysis sheds new light on intra-day fluctuations in market betas by decomposing them into time-varying correlations and relative volatility changes. Our results show that intraday variation in betas is primarily driven by intraday variation in correlations.
    
[^3]: Causal Q-Aggregation for CATE Model Selection（CATE模型选择中的因果Q集成）

    Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])

    [http://arxiv.org/abs/2310.16945](http://arxiv.org/abs/2310.16945)

    该论文提出了一种基于Q集成的CATE模型选择方法，其通过使用双重鲁棒损失实现了统计上的最佳预测模型选择遗憾率

    

    准确估计条件平均处理效应（CATE）是个性化决策的核心。尽管有大量用于CATE估计的模型，但由于因果推断的基本问题，模型选择是一项非常棘手的任务。最近的实证工作提供了有利于具有双重鲁棒性质的代理损失度量和模型集成的证据。然而，对于这些模型的理论理解还不够。直接应用先前的理论工作会由于模型选择问题的非凸性而导致次优的预测模型选择率。我们提供了现有主要CATE集成方法的遗憾率，并提出了一种基于双重鲁棒损失的Q集成的新的CATE模型集成方法。我们的主要结果表明，因果Q集成在预测模型选择的遗憾率上达到了统计上的最优值为$\frac{\log(M)}{n}$（其中$M$为模型数，$n$为样本数），加上高阶估计误差项

    Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
    
[^4]: 通过数据改善鲁棒决策

    Improving Robust Decisions with Data. (arXiv:2310.16281v1 [econ.TH])

    [http://arxiv.org/abs/2310.16281](http://arxiv.org/abs/2310.16281)

    该论文研究了如何通过数据改善鲁棒决策，并开发了简单易实现的推理方法以保证改善。

    

    决策者面临由数据生成过程(DGP)控制的不确定性，这些过程可能只属于一组独立但可能非相同分布的序列。鲁棒决策在这个集合中最大化决策者对最坏情况DGP的预期收益。本文研究了如何通过数据改善这些鲁棒决策，其中改善通过真实DGP下的预期收益来衡量。本文完全描述了在所有可能的DGP下保证这种改善的时间和方式，并开发了推理方法来实现它。这些推理方法是必需的，因为本文表明，常见的推理方法（如最大似然或贝叶斯）通常无法实现这种改善。重要的是，开发的推理方法是通过对标准推理程序进行简单扩展获得的，因此在实践中很容易实现。

    A decision-maker (DM) faces uncertainty governed by a data-generating process (DGP), which is only known to belong to a set of sequences of independent but possibly non-identical distributions. A robust decision maximizes the DM's expected payoff against the worst possible DGP in this set. This paper studies how such robust decisions can be improved with data, where improvement is measured by expected payoff under the true DGP. In this paper, I fully characterize when and how such an improvement can be guaranteed under all possible DGPs and develop inference methods to achieve it. These inference methods are needed because, as this paper shows, common inference methods (e.g., maximum likelihood or Bayesian) often fail to deliver such an improvement. Importantly, the developed inference methods are given by simple augmentations to standard inference procedures, and are thus easy to implement in practice.
    
[^5]: 非核心银行资金和汇率灵活性中的全球因素

    Global Factors in Non-core Bank Funding and Exchange Rate Flexibility. (arXiv:2310.11552v1 [econ.GN])

    [http://arxiv.org/abs/2310.11552](http://arxiv.org/abs/2310.11552)

    全球因素对发达经济体银行体系中非核心与核心资金比率的波动起主导作用，汇率灵活性能够在2008-2009年以外的时期减小这种影响。

    

    我们展示了发达经济体银行体系中非核心与核心资金比率的波动由少数几个既有实物性又有金融性质的全球因素驱动，国家特定因素没有发挥重要作用。汇率灵活性有助于减小非核心与核心比率受到全球因素的影响，但仅在重大全球金融震荡期间（如2008-2009年）明显起作用。

    We show that fluctuations in the ratio of non-core to core funding in the banking systems of advanced economies are driven by a handful of global factors of both real and financial natures, with country-specific factors playing no significant roles. Exchange rate flexibility helps insulate the non-core to core ratio from such global factors but only significantly so outside periods of major global financial disruptions, as in 2008-2009.
    
[^6]: SGMM: 广义矩方法的随机近似

    SGMM: Stochastic Approximation to Generalized Method of Moments. (arXiv:2308.13564v1 [econ.EM])

    [http://arxiv.org/abs/2308.13564](http://arxiv.org/abs/2308.13564)

    我们提出了一种新的随机广义矩方法（SGMM），用于估计和推断矩限制模型。该方法具有快速和可扩展的实时处理能力，并且能够处理大规模和在线数据集。

    

    我们引入了一种新的算法类，随机广义矩方法（SGMM），用于估计和推断（超识别）矩限制模型。我们的SGMM是一种新颖的随机逼近方法，替代了流行的Hansen（1982年）的（离线）GMM，并提供了快速和可扩展的实时流数据处理能力。我们证明了SGMM对于效率不高的在线2SLS和高效的SGMM具有几乎确定的收敛性和（函数）中心极限定理。此外，我们提出了Durbin-Wu-Hausman和Sargan-Hansen测试的在线版本，可以无缝集成到SGMM框架中。广泛的蒙特卡洛模拟结果表明，随着样本量的增加，SGMM在估计准确性和计算效率方面与标准（离线）GMM相匹配，并显示出在大规模和在线数据集上的实际价值。我们通过使用两个示例证明了我们方法的有效性。

    We introduce a new class of algorithms, Stochastic Generalized Method of Moments (SGMM), for estimation and inference on (overidentified) moment restriction models. Our SGMM is a novel stochastic approximation alternative to the popular Hansen (1982) (offline) GMM, and offers fast and scalable implementation with the ability to handle streaming datasets in real time. We establish the almost sure convergence, and the (functional) central limit theorem for the inefficient online 2SLS and the efficient SGMM. Moreover, we propose online versions of the Durbin-Wu-Hausman and Sargan-Hansen tests that can be seamlessly integrated within the SGMM framework. Extensive Monte Carlo simulations show that as the sample size increases, the SGMM matches the standard (offline) GMM in terms of estimation accuracy and gains over computational efficiency, indicating its practical value for both large-scale and online datasets. We demonstrate the efficacy of our approach by a proof of concept using two we
    
[^7]: 鲁棒斯塔克伯格均衡的系统研究

    Robust Stackelberg Equilibria. (arXiv:2304.14990v1 [cs.GT])

    [http://arxiv.org/abs/2304.14990](http://arxiv.org/abs/2304.14990)

    本论文系统研究了鲁棒斯塔克伯格均衡的概念，提出了一种新的解决方案RSE，旨在提高领袖策略的稳健性。我们证明了RSE的存在性，并研究了它的效用保证、算法和可学性。

    

    本文系统研究了鲁棒斯塔克伯格均衡(RSE)的概念，该概念自然地推广了广泛采用的强斯塔克伯格均衡(SSE)的解决方案。RSE考虑了在斯塔克伯格博弈中可能出现的高达-$\delta$ 子优跟随者反应，并被采用来提高领袖策略的稳健性。虽然先前的文献中已经考虑了一些鲁棒斯塔克伯格均衡的变体，但本文考虑的RSE解决方案概念重要的不同之处在于，某种意义上它放松了先前研究的鲁棒斯塔克伯格策略，并且适用于更广泛的不确定性来源。我们对几个RSE的基本属性进行了彻底的调查，包括它的效用保证、算法和可学性。我们首先证明了我们定义的RSE总是存在的，从而是严格定义的。然后我们阐明了在考虑的鲁棒性水平下领袖效用的变化情况。在算法方面，我们表明计算RSE是计算上困难的，并提出了适用于某些游戏类的有效算法来近似计算它。最后，我们研究了RSE的可学性，并表明它可以从样本中近似估计。

    This paper provides a systematic study of the robust Stackelberg equilibrium (RSE), which naturally generalizes the widely adopted solution concept of the strong Stackelberg equilibrium (SSE). The RSE accounts for any possible up-to-$\delta$ suboptimal follower responses in Stackelberg games and is adopted to improve the robustness of the leader's strategy. While a few variants of robust Stackelberg equilibrium have been considered in previous literature, the RSE solution concept we consider is importantly different -- in some sense, it relaxes previously studied robust Stackelberg strategies and is applicable to much broader sources of uncertainties.  We provide a thorough investigation of several fundamental properties of RSE, including its utility guarantees, algorithmics, and learnability. We first show that the RSE we defined always exists and thus is well-defined. Then we characterize how the leader's utility in RSE changes with the robustness level considered. On the algorithmic
    
[^8]: 测量欧洲冠军联赛球队实力的方法

    Measuring the strengths of the teams in the UEFA Champions League. (arXiv:2304.09078v1 [stat.AP])

    [http://arxiv.org/abs/2304.09078](http://arxiv.org/abs/2304.09078)

    本文研究了UEFA俱乐部系数在保证欧洲冠军联赛对手实力相同方面的局限性，并提出通过考虑国内联赛的比赛成绩来改进系数的建议。

    

    从2024/25赛季开始，《欧洲冠军联赛》将进行一个重大改革：传统的小组赛阶段将被一个联赛阶段所取代，其中的36个球队中每个队将参加8场比赛。由于排名仍然基于这些比赛的结果，公平需要确保每个俱乐部的对手实力相同。本文研究了当前使用的球队排名方法——UEFA俱乐部系数能否通过考虑国内联赛的比赛结果进行改进。根据我们的逻辑回归模型，Elo方法的一种变体在预测欧洲冠军联赛比赛方面具有更高的准确性。因此，我们建议欧洲足球协会（UEFA）仿效国际足球联合会世界排名的做法，改革系数的计算方式，以避免欧洲冠军联赛的新赛制中出现不平衡的赛程安排。

    One of the most popular club football tournaments, the UEFA Champions League, will see a fundamental reform from the 2024/25 season: the traditional group stage will be replaced by one league where each of the 36 teams plays eight matches. Since the ranking is still based on the results of these matches, fairness requires guaranteeing that the opponents of the clubs are of the same strength. This paper investigates whether the currently used rating of the teams, the UEFA club coefficient, can be improved by taking the games played in the national leagues into account. According to our logistic regression models, a variant of the Elo method provides a higher accuracy in forecasting Champions League matches. Therefore, the Union of European Football Associations (UEFA) is encouraged to follow the example of the FIFA World Ranking and reform the calculation of the coefficients in order to avoid unbalanced schedules in the novel tournament format of the Champions League.
    
[^9]: 在零下限条件下的非理性一致性

    Coherence without Rationality at the Zero Lower Bound. (arXiv:2208.02073v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2208.02073](http://arxiv.org/abs/2208.02073)

    该论文研究了在零下限条件下，非理性预期如何解决理性预期模型的一致性和完备性问题，提出了自我确认均衡和E稳定性准则作为解决方法。

    

    标准有时受限的零下限约束的理性预期模型要么没有解（不一致），要么有多个解（不完备）。本文显示，与全信息理性预期的偏离可以减轻不一致和不完备的担忧。没有理性预期均衡的模型可以包括使用简单的错误规范的预测模型的自我确认均衡。如果预期是自适应的，或者由于某些信息或行为摩擦，代理人更少地展望未来，完备性和一致性会得到恢复。在不完备的情况下，E稳定性准则选择一个均衡。

    Standard rational expectations models with an occasionally binding zero lower bound constraint either admit no solutions (incoherence) or multiple solutions (incompleteness). This paper shows that deviations from full-information rational expectations mitigate concerns about incoherence and incompleteness. Models with no rational expectations equilibria admit self-confirming equilibria involving the use of simple mis-specified forecasting models. Completeness and coherence is restored if expectations are adaptive or if agents are less forward-looking due to some information or behavioral friction. In the case of incompleteness, the E-stability criterion selects an equilibrium.
    
[^10]: 检测分组的局部平均处理效应并选择真正的工具

    Detecting Grouped Local Average Treatment Effects and Selecting True Instruments. (arXiv:2207.04481v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2207.04481](http://arxiv.org/abs/2207.04481)

    我们提出了一个两步骤的过程来识别具有相同局部平均处理效应的响应组，并且即使有一些工具违反了识别假设，也可以选择真正满足假设的工具。

    

    在具有异质效应和多个工具的内生二元处理中，我们提出了一个两步骤的过程，用于识别具有相同局部平均处理效应（LATE）的响应组，尽管依赖于不同的工具，即使有几个工具违反了识别假设。我们利用了LATE对于满足LATE假设（工具有效性和处理在工具上单调性）和在给定相应工具的情况下生成相同响应组的工具来说是均匀的这一事实。我们提出了一个两步骤的过程，第一步我们首先聚类倾向得分，在第二步中找到具有相同减少形式参数的IV组。在众数假设下，对于具有相同处理倾向的工具集合，真正满足LATE假设的工具是最大的组，我们的方法可以识别出这些真正的工具。

    Under an endogenous binary treatment with heterogeneous effects and multiple instruments, we propose a two-step procedure for identifying complier groups with identical local average treatment effects (LATE) despite relying on distinct instruments, even if several instruments violate the identifying assumptions. We use the fact that the LATE is homogeneous for instruments which (i) satisfy the LATE assumptions (instrument validity and treatment monotonicity in the instrument) and (ii) generate identical complier groups in terms of treatment propensities given the respective instruments. We propose a two-step procedure, where we first cluster the propensity scores in the first step and find groups of IVs with the same reduced form parameters in the second step. Under the plurality assumption that within each set of instruments with identical treatment propensities, instruments truly satisfying the LATE assumptions are the largest group, our procedure permits identifying these true instr
    
[^11]: 辩说的比较静态

    The comparative statics of persuasion. (arXiv:2204.07474v2 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2204.07474](http://arxiv.org/abs/2204.07474)

    本论文主要研究了辩说模型中的比较静态问题，通过界定发信方中期回报变化的条件，确定了发信方在选择信号时会更倾向于选择具有更多信息量的信号。此外，论文还研究了发信方和接收方兴趣一致程度增加对比较静态的影响，并探讨了相关应用。

    

    在经典的辩说模型中，比较静态一直是一个未解决的问题。我们回答了这个问题，界定了哪些条件下发信方的中期回报变化会使其最优选择更具信息量的信号。我们的第一个定理确定了一个粗略概念的“增加凸性”，我们证明这个定理刻画了发信方中期回报变化使其最优选择更加信息量不减的情况。为了加强这个结论为“更具信息量”需要进一步的假设：我们的第二个定理明确了发信方中期回报的必要和充分条件，这个条件严格推广了文献中常见的“S”形状。我们确定了发信方和接收方兴趣一致程度增加会导致比较静态的条件，并研究了应用场景。

    In the canonical persuasion model, comparative statics has been an open question. We answer it, delineating which shifts of the sender's interim payoff lead her optimally to choose a more informative signal. Our first theorem identifies a coarse notion of 'increased convexity' that we show characterises those shifts of the sender's interim payoff that lead her optimally to choose no less informative signals. To strengthen this conclusion to 'more informative' requires further assumptions: our second theorem identifies the necessary and sufficient condition on the sender's interim payoff, which strictly generalises the 'S' shape commonly imposed in the literature. We identify conditions under which increased alignment of interests between sender and receiver lead to comparative statics, and study applications.
    
[^12]: 合成干预

    Synthetic Interventions. (arXiv:2006.07691v6 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2006.07691](http://arxiv.org/abs/2006.07691)

    提出了一个称为合成干预的因果框架，能够在观察到每个单元最多两个干预措施的情况下推断每个单元对每个干预措施的预期潜在结果，具有有限样本一致性和渐近正态性。

    

    考虑一个拥有$N$个异质单元（例如个体或子群体）和$D$个干预措施（例如社会经济政策）的情景。我们的目标是学习每个单元对每个干预措施的预期潜在结果，总共有$N \times D$个因果参数。为此，我们提出了一个因果框架——合成干预（SI），以推断这$N \times D$个因果参数，同时仅观察每个单元在最多两个干预措施下的情况，与$D$无关。当个性化水平增加时，这将具有重要意义。在一个新的张量因子模型下，跨单元、结果和干预措施，我们证明了这$N \times D$个因果参数的识别结果，并在附加条件下证明了我们估计值的有限样本一致性和渐近正态性。重要的是，我们的估计器还允许存在决定干预分配方式的潜在混淆因素。

    Consider a setting with $N$ heterogeneous units (e.g., individuals, sub-populations) and $D$ interventions (e.g., socio-economic policies). Our goal is to learn the expected potential outcome associated with every intervention on every unit, totaling $N \times D$ causal parameters. Towards this, we present a causal framework, synthetic interventions (SI), to infer these $N \times D$ causal parameters while only observing each of the $N$ units under at most two interventions, independent of $D$. This can be significant as the number of interventions, i.e., level of personalization, grows. Under a novel tensor factor model across units, outcomes, and interventions, we prove an identification result for each of these $N \times D$ causal parameters, establish finite-sample consistency of our estimator along with asymptotic normality under additional conditions. Importantly, our estimator also allows for latent confounders that determine how interventions are assigned. The estimator is furt
    

