# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Optimal Conditional Inference in Adaptive Experiments.](http://arxiv.org/abs/2309.12162) | 我们研究了在自适应实验中进行条件推断的问题，证明了在没有进一步限制的情况下，仅使用最后一批结果进行推断是最优的；当实验的自适应方面是位置不变的时，我们还发现了额外的信息；在停止时间、分配概率和目标参数仅依赖于数据的多面体事件集合的情况下，我们推导出了计算可行且最优的条件推断程序。 |
| [^2] | [Buyer-Optimal Algorithmic Consumption.](http://arxiv.org/abs/2309.12122) | 该文分析了一个双边交易模型，提出了一种买方最优的算法消费模型，该模型实现了高价位下少推荐和低价位下多推荐产品的策略，同时提高算法精确性可以提高最大均衡价格，而知悉买方价值则会导致价格分布的扩散和买方收益的收缩。 |
| [^3] | [Techno-Economic Analysis of Synthetic Fuel Production from Existing Nuclear Power Plants across the United States.](http://arxiv.org/abs/2309.12085) | 该论文研究了利用现有核电站生产合成燃料的技术经济潜力，结果显示将合成燃料生产与核电站耦合可以提高核电站的盈利能力，为投资者带来可观的回报。 |
| [^4] | [A detection analysis for temporal memory patterns at different time-scales.](http://arxiv.org/abs/2309.12034) | 本论文介绍了一种新颖的方法，通过分析事件序列的事件间隔分布，以揭示时间序列的依赖模式。该方法可以发现跨多个时间尺度的记忆模式，并提供了有价值的应用于经济学中的时间序列分析。 |
| [^5] | [Explosive growth from AI automation: A review of the arguments.](http://arxiv.org/abs/2309.11690) | AI自动化的爆炸性增长是可能的，可能会加速全球经济增长，但目前对此的高度自信是不合适的。 |
| [^6] | [Common Agency with Non-Delegation or Imperfect Commitment.](http://arxiv.org/abs/2309.11595) | 在共同代理模型中，非委派契约或不完全承诺扩展了均衡结果的集合，并重新确立了广义菜单定理。 |
| [^7] | [Generalised Covariances and Correlations.](http://arxiv.org/abs/2307.03594) | 该论文广义化了协方差的概念，并用其他统计函数替代了均值，构造了广义相关性来衡量随机变量之间的依赖关系。这些新的依赖度量具有有利的特性，可以用于显示整个依赖结构，并且可以取代传统的尾部依赖系数。 |
| [^8] | [Foundations of self-progressive choice theories.](http://arxiv.org/abs/2212.13449) | 该论文讨论了自我渐进选择理论及其与代数结构和超模函数的等价性，并将分析扩展到普遍自我渐进的选择理论。 |
| [^9] | [Bayesian analysis of mixtures of lognormal distribution with an unknown number of components from grouped data.](http://arxiv.org/abs/2210.05115) | 本研究提出了一种用于估计收入的对数正态分布混合模型参数的贝叶斯分析方法，并通过模拟和实证数据的验证表明了其准确性和适用性。 |
| [^10] | [Bias-Aware Inference in Fuzzy Regression Discontinuity Designs.](http://arxiv.org/abs/1906.04631) | 本文提出了一种新的置信区间方法，针对模糊设计中的回归不连续参数，该方法基于局部线性回归，并且明确考虑了可能的偏差。与常用的模糊回归不连续分析推断方法不同，该方法避免了"delta method"逼近问题，并在多种实际相关条件下都是有效的。 |

# 详细

[^1]: 自适应实验中的最优条件推断

    Optimal Conditional Inference in Adaptive Experiments. (arXiv:2309.12162v1 [stat.ME])

    [http://arxiv.org/abs/2309.12162](http://arxiv.org/abs/2309.12162)

    我们研究了在自适应实验中进行条件推断的问题，证明了在没有进一步限制的情况下，仅使用最后一批结果进行推断是最优的；当实验的自适应方面是位置不变的时，我们还发现了额外的信息；在停止时间、分配概率和目标参数仅依赖于数据的多面体事件集合的情况下，我们推导出了计算可行且最优的条件推断程序。

    

    我们研究了批量赌徒实验，并考虑了在实现停止时间、分配概率和目标参数的条件下进行推断的问题，其中所有这些可能都是根据实验的最后一批信息进行自适应选择的。在没有对实验进行进一步限制的情况下，我们证明仅使用最后一批结果进行推断是最优的。当实验的自适应方面被认为是位置不变的，即当我们将所有批次-臂的平均值都向一个常数移动时，我们证明数据中还存在额外的信息，可以通过一个额外的批次-臂均值的线性函数来捕捉。在更严格的情况下，停止时间、分配概率和目标参数被认为仅依赖于数据通过一个多面体事件的集合，我们推导出了计算可行且最优的条件推断程序。

    We study batched bandit experiments and consider the problem of inference conditional on the realized stopping time, assignment probabilities, and target parameter, where all of these may be chosen adaptively using information up to the last batch of the experiment. Absent further restrictions on the experiment, we show that inference using only the results of the last batch is optimal. When the adaptive aspects of the experiment are known to be location-invariant, in the sense that they are unchanged when we shift all batch-arm means by a constant, we show that there is additional information in the data, captured by one additional linear function of the batch-arm means. In the more restrictive case where the stopping time, assignment probabilities, and target parameter are known to depend on the data only through a collection of polyhedral events, we derive computationally tractable and optimal conditional inference procedures.
    
[^2]: 买方最优的算法消费模型分析

    Buyer-Optimal Algorithmic Consumption. (arXiv:2309.12122v1 [econ.TH])

    [http://arxiv.org/abs/2309.12122](http://arxiv.org/abs/2309.12122)

    该文分析了一个双边交易模型，提出了一种买方最优的算法消费模型，该模型实现了高价位下少推荐和低价位下多推荐产品的策略，同时提高算法精确性可以提高最大均衡价格，而知悉买方价值则会导致价格分布的扩散和买方收益的收缩。

    

    我们分析了一个双边交易模型，其中买方对产品的价值和卖方的成本是不确定的，卖方选择产品价格，并且基于其价值和价格通过算法推荐产品。我们描述了一个最大化买方预期收益的算法，并且表明在高价位下的最优算法过少推荐产品，在低价位下过多推荐。算法的精确性提高了最大均衡价格，可能提高卖方成本的所有价格，而告知卖方买方的价值则会导致均衡价格的均值保持扩散和买方收益的均值保持收缩。

    We analyze a bilateral trade model in which the buyer's value for the product and the seller's costs are uncertain, the seller chooses the product price, and the product is recommended by an algorithm based on its value and price. We characterize an algorithm that maximizes the buyer's expected payoff and show that the optimal algorithm underrecommends the product at high prices and overrecommends at low prices. Higher algorithm precision increases the maximal equilibrium price and may increase prices across all of the seller's costs, whereas informing the seller about the buyer's value results in a mean-preserving spread of equilibrium prices and a mean-preserving contraction of the buyer's payoff.
    
[^3]: 美国现有核电站合成燃料生产的技术经济分析

    Techno-Economic Analysis of Synthetic Fuel Production from Existing Nuclear Power Plants across the United States. (arXiv:2309.12085v1 [econ.GN])

    [http://arxiv.org/abs/2309.12085](http://arxiv.org/abs/2309.12085)

    该论文研究了利用现有核电站生产合成燃料的技术经济潜力，结果显示将合成燃料生产与核电站耦合可以提高核电站的盈利能力，为投资者带来可观的回报。

    

    低碳合成燃料可以取代柴油和喷气燃料等传统燃料，有助于全球范围内实现交通领域的脱碳，但需要大规模的成本效益高的生产设施。与此同时，由于经济困难，核电站正在关闭：电力价格过低且不稳定，无法覆盖运营成本。利用现有核电站生产合成燃料可能阻止这些低碳资产的损失，同时大规模生产合成燃料，但目前尚无关于这种整合能源系统的技术经济分析。我们量化了在美国五个示例核电站与合成燃料生产过程耦合的技术经济潜力，以探究不同电力市场、二氧化碳资源的获取以及燃料市场的影响。将合成燃料生产与核电站耦合可以使核电站的盈利能力增加多达7.92亿美元（2020年），同时获得10％的投资回报率。

    Low carbon synfuel can displace transport fossil fuels such as diesel and jet fuel and help achieve the decarbonization of the transportation sector at a global scale, but large-scale cost-effective production facilities are needed. Meanwhile, nuclear power plants are closing due to economic difficulties: electricity prices are too low and variable to cover their operational costs. Using existing nuclear power plants to produce synfuels might prevent loss of these low-carbon assets while producing synfuels at scale, but no technoeconomic analysis of this Integrated Energy System exist. We quantify the technoeconomic potential of coupling a synthetic fuel production process with five example nuclear power plants across the U.S. to explore the influence of different electricity markets, access to carbon dioxide sources, and fuel markets. Coupling synfuel production increases nuclear plant profitability by up to 792 million USD(2020) in addition to a 10 percent rate of return on investmen
    
[^4]: 在不同时间尺度上检测时间记忆模式的检测分析

    A detection analysis for temporal memory patterns at different time-scales. (arXiv:2309.12034v1 [econ.EM])

    [http://arxiv.org/abs/2309.12034](http://arxiv.org/abs/2309.12034)

    本论文介绍了一种新颖的方法，通过分析事件序列的事件间隔分布，以揭示时间序列的依赖模式。该方法可以发现跨多个时间尺度的记忆模式，并提供了有价值的应用于经济学中的时间序列分析。

    

    本论文介绍了一种新颖的方法，利用延迟来揭示时间序列的依赖模式。通过分析事件序列的事件间隔分布，定制的统计检验可以检测到事件序列之间的记忆依赖关系。基于更新-老化性质的合成实验评估了观察者延迟对更新性质的影响。我们的检测方法可以发现跨多个时间尺度的记忆模式，强调了事件序列的概率结构超出了相关性。时间序列分析生成了统计检验和图形绘制，有助于检测不同时间尺度上事件之间的依赖模式。此外，该检验通过老化实验评估了更新假设，为经济学中的时间序列分析提供了有价值的应用。

    This paper introduces a novel methodology that utilizes latency to unveil time-series dependence patterns. A customized statistical test detects memory dependence in event sequences by analyzing their inter-event time distributions. Synthetic experiments based on the renewal-aging property assess the impact of observer latency on the renewal property. Our test uncovers memory patterns across diverse time scales, emphasizing the event sequence's probability structure beyond correlations. The time series analysis produces a statistical test and graphical plots which helps to detect dependence patterns among events at different time-scales if any. Furthermore, the test evaluates the renewal assumption through aging experiments, offering valuable applications in time-series analysis within economics.
    
[^5]: AI自动化的爆炸性增长: 论证综述

    Explosive growth from AI automation: A review of the arguments. (arXiv:2309.11690v1 [econ.GN])

    [http://arxiv.org/abs/2309.11690](http://arxiv.org/abs/2309.11690)

    AI自动化的爆炸性增长是可能的，可能会加速全球经济增长，但目前对此的高度自信是不合适的。

    

    我们研究了大规模AI自动化是否能够使全球经济增长加速达到约一个数量级，类似于工业革命所带来的经济增长效应。我们确定了这种增长的三个主要驱动因素：1）AI“劳动力”的可扩展性使得规模递增再现，2）AI劳动力的快速扩张，以及3）在短时间内进行的快速自动化带来的产出大幅增加。在这个背景下，我们评估了九个反对论点，包括监管障碍、产能瓶颈、匹配问题和自动化的速度。我们暂时评估了这些论点，发现大多数都不太可能成为决定因素。我们得出结论认为，如果AI能够广泛替代人力劳动，爆炸性增长似乎是有可能的，但目前对这一说法的高度自信似乎是不合理的。关于AI监管响应的强度、生产中的物理瓶颈和AI的经济价值，仍然存在关键问题。

    We examine whether substantial AI automation could accelerate global economic growth by about an order of magnitude, akin to the economic growth effects of the Industrial Revolution. We identify three primary drivers for such growth: 1) the scalability of an AI ``labor force" restoring a regime of increasing returns to scale, 2) the rapid expansion of an AI labor force, and 3) a massive increase in output from rapid automation occurring over a brief period of time. Against this backdrop, we evaluate nine counterarguments, including regulatory hurdles, production bottlenecks, alignment issues, and the pace of automation. We tentatively assess these arguments, finding most are unlikely deciders. We conclude that explosive growth seems plausible with AI capable of broadly substituting for human labor, but high confidence in this claim seems currently unwarranted. Key questions remain about the intensity of regulatory responses to AI, physical bottlenecks in production, the economic value 
    
[^6]: 具有非委派或不完全承诺的共同代理

    Common Agency with Non-Delegation or Imperfect Commitment. (arXiv:2309.11595v1 [econ.TH])

    [http://arxiv.org/abs/2309.11595](http://arxiv.org/abs/2309.11595)

    在共同代理模型中，非委派契约或不完全承诺扩展了均衡结果的集合，并重新确立了广义菜单定理。

    

    在传统契约理论中，我们通常假设两个条件：委派契约和完全承诺。虽然第二个假设要求较高，但第一个假设并不会减少广义性。遵循这一传统，当前的共同代理模型强加了委派契约和完全承诺。首先，我们证明非委派契约扩大了共同代理下的均衡结果。此外，共同代理的强大菜单定理（Peters（2001）和Martimort和Stole（2002））对于非委派契约或不完全承诺是不适用的。我们在这样的环境中确定了典型契约，并重新确立了广义菜单定理。在不完全承诺的情况下，我们对共同代理模型的结果与经典契约理论中Bester和Strausz（2001）以及Doval和Skreta（2012）的结果类似，重新确立了启示原理。

    In classical contract theory, we usually impose two assumptions: delegated contracts and perfect commitment. While the second assumption is demanding, the first one suffers no loss of generality. Following this tradition, current common-agency models impose delegated contracts and perfect commitment. We first show that non-delegated contracts expand the set of equilibrium outcomes under common agency. Furthermore, the powerful menu theorem for common agency (Peters (2001) and Martimort and Stole (2002)}) fails for either non-delegated contracts or imperfect commitment. We identify canonical contracts in such environments, and re-establish generalized menu theorems. Given imperfect commitment, our results for common-agency models are analogous to those in Bester and Strausz (2001) and Doval and Skreta (2012) for the classical contract theory, which re-establish the revelation principle.
    
[^7]: 广义协方差和相关性

    Generalised Covariances and Correlations. (arXiv:2307.03594v1 [stat.ME] CROSS LISTED)

    [http://arxiv.org/abs/2307.03594](http://arxiv.org/abs/2307.03594)

    该论文广义化了协方差的概念，并用其他统计函数替代了均值，构造了广义相关性来衡量随机变量之间的依赖关系。这些新的依赖度量具有有利的特性，可以用于显示整个依赖结构，并且可以取代传统的尾部依赖系数。

    

    两个随机变量的协方差衡量它们相对于各自均值的联合偏差的平均值。我们通过用其他统计函数（如分位数、期望量、或阈值）替代均值来推广这个众所周知的度量。这些函数的偏差通过广义误差定义，通常由识别或矩函数引发。作为一种归一化的依赖度量，我们构造了广义相关性。通过用一种新颖的Fr\'echet-Hoeffding归一化替代常见的Cauchy-Schwarz归一化，我们获得了对于任何给定边缘分布，整个区间$[-1, 1]$的可达性。我们发现了这些新的依赖度量的有利特性。分位数和阈值相关性的家族产生了函数值分布相关性，显示了整个依赖结构。它们导致了尾部相关性，这可能应该取代尾部依赖系数。最后，我们构造了摘要协方差（corre）

    The covariance of two random variables measures the average joint deviations from their respective means. We generalise this well-known measure by replacing the means with other statistical functionals such as quantiles, expectiles, or thresholds. Deviations from these functionals are defined via generalised errors, often induced by identification or moment functions. As a normalised measure of dependence, a generalised correlation is constructed. Replacing the common Cauchy-Schwarz normalisation by a novel Fr\'echet-Hoeffding normalisation, we obtain attainability of the entire interval $[-1, 1]$ for any given marginals. We uncover favourable properties of these new dependence measures. The families of quantile and threshold correlations give rise to function-valued distributional correlations, exhibiting the entire dependence structure. They lead to tail correlations, which should arguably supersede the coefficients of tail dependence. Finally, we construct summary covariances (corre
    
[^8]: 自我渐进选择理论的基础

    Foundations of self-progressive choice theories. (arXiv:2212.13449v4 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2212.13449](http://arxiv.org/abs/2212.13449)

    该论文讨论了自我渐进选择理论及其与代数结构和超模函数的等价性，并将分析扩展到普遍自我渐进的选择理论。

    

    考虑一个由许多代理人组成的群体，他们的选择行为可以根据给定的原始排序部分进行比较。在该群体中可接受的选择函数集合确定了一个选择理论。如果与理论一致的任何集体选择行为都可以表示为可比较的可接受选择函数上的概率分布，则该选择理论是自我渐进的。 我们证明了自我渐进选择理论和（i）称为格的众所周知的代数结构；（ii）特定领域内的超模函数的最大化者之间的等价性。我们将分析扩展到普遍自我渐进的选择理论，这些选择理论独立于原始排序给出了唯一的有序代表。

    Consider a population of agents whose choice behaviors are partially comparable according to given primitive orderings. The set of choice functions admissible in the population specifies a choice theory. A choice theory is self-progressive if any aggregate choice behavior consistent with the theory is uniquely representable as a probability distribution over admissible choice functions that are comparable. We establish an equivalence between self-progressive choice theories and (i) well-known algebraic structures called lattices; (ii) the maximizers of supermodular functions over a specific domain of choice functions. We extend our analysis to universally self-progressive choice theories which render unique orderly representations independent of primitive orderings.
    
[^9]: 未知组件数的对数正态分布混合模型的贝叶斯分析和组合数据的马尔可夫链蒙特卡洛方法

    Bayesian analysis of mixtures of lognormal distribution with an unknown number of components from grouped data. (arXiv:2210.05115v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2210.05115](http://arxiv.org/abs/2210.05115)

    本研究提出了一种用于估计收入的对数正态分布混合模型参数的贝叶斯分析方法，并通过模拟和实证数据的验证表明了其准确性和适用性。

    

    本研究提出了一种可逆跳跃马尔可夫链蒙特卡洛方法，用于估计收入的对数正态分布混合模型的参数。通过使用模拟数据示例，我们检验了所提算法的性能以及基尼系数的后验分布的准确性。结果表明参数估计准确，即使考虑了不同的数据生成过程，后验分布仍接近真实分布。此外，基于更具吸引力的基尼系数的结果，我们还将该方法应用于来自日本的实际数据。实证案例表明日本在2020年存在两个子群，并且基尼系数的完整性得到了验证。

    This study proposes a reversible jump Markov chain Monte Carlo method for estimating parameters of lognormal distribution mixtures for income. Using simulated data examples, we examined the proposed algorithm's performance and the accuracy of posterior distributions of the Gini coefficients. Results suggest that the parameters were estimated accurately. Therefore, the posterior distributions are close to the true distributions even when the different data generating process is accounted for. Moreover, promising results for Gini coefficients encouraged us to apply our method to real data from Japan. The empirical examples indicate two subgroups in Japan (2020) and the Gini coefficients' integrity.
    
[^10]: 在模糊回归不连续设计中的偏差感知推断

    Bias-Aware Inference in Fuzzy Regression Discontinuity Designs. (arXiv:1906.04631v4 [econ.EM] UPDATED)

    [http://arxiv.org/abs/1906.04631](http://arxiv.org/abs/1906.04631)

    本文提出了一种新的置信区间方法，针对模糊设计中的回归不连续参数，该方法基于局部线性回归，并且明确考虑了可能的偏差。与常用的模糊回归不连续分析推断方法不同，该方法避免了"delta method"逼近问题，并在多种实际相关条件下都是有效的。

    

    我们针对模糊设计中的回归不连续参数提出了新的置信区间（CS），这些CS基于局部线性回归，并且在可能的偏差方面是感知的，即它们明确地考虑了可能的偏差。它们的构造与完全确定的工具变量模型中的Anderson-Rubin CS相似，从而避免了大多数常用的模糊回归不连续分析现有推断方法中依赖于"delta method"逼近的问题。我们的CS在具有强识别和连续运行变量的经典设置中与现有程序渐进等价。然而，由于其特殊构造，它们在许多实际相关条件下也是有效的，而现有方法可能会失败，例如离散运行变量、环形设计和弱识别设置。

    We propose new confidence sets (CSs) for the regression discontinuity parameter in fuzzy designs. Our CSs are based on local linear regression, and are bias-aware, in the sense that they take possible bias explicitly into account. Their construction shares similarities with that of Anderson-Rubin CSs in exactly identified instrumental variable models, and thereby avoids issues with "delta method" approximations that underlie most commonly used existing inference methods for fuzzy regression discontinuity analysis. Our CSs are asymptotically equivalent to existing procedures in canonical settings with strong identification and a continuous running variable. However, due to their particular construction they are also valid under a wide range of empirically relevant conditions in which existing methods can fail, such as setups with discrete running variables, donut designs, and weak identification.
    

