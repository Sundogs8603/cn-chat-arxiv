# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Are there Dragon Kings in the Stock Market?.](http://arxiv.org/abs/2307.03693) | 研究发现，股市中存在一种被称为“龙王”的异常事件，它们与经济动荡相关并在统计意义上显著偏离分布尾部。 |
| [^2] | [Climate Models Underestimate the Sensitivity of Arctic Sea Ice to Carbon Emissions.](http://arxiv.org/abs/2307.03552) | 气候模型低估了北极海冰对碳排放的敏感性，未来北极无冰期可能比模型预计的要早得多。 |
| [^3] | [Firm-quasi-stability and re-equilibration in matching markets with contracts.](http://arxiv.org/abs/2305.17948) | 本研究探讨了带合约的匹配市场中的稳定性问题，发现稳定性破坏后，公司准稳定的分配方式可以自然出现，而我们提出的算法可以使市场从准稳定性中重新获得稳定性。 |
| [^4] | [Best-of-Both-Worlds Fairness in Committee Voting.](http://arxiv.org/abs/2303.03642) | 本文提出了在委员会投票中实现前后双赢公平性的方法，并形式化了一系列属性的层次结构。我们提出了一个多项式时间算法，能同时满足后期合理代表性、前期群体公平份额和前期强个体公平份额。同时，我们也提出了一个不在多项式时间内运行的算法，输出满足后期全权代表性和前期强群体公平份额的彩票。 |
| [^5] | [Individualized Treatment Allocation in Sequential Network Games.](http://arxiv.org/abs/2302.05747) | 本文针对顺序决策博弈中的互动主体，提出了一种个体化治疗分配方法，通过评估结果的固定分布并采用变分近似和贪婪优化算法，最大化了社会福利准则。 |
| [^6] | [Binary Mechanisms under Privacy-Preserving Noise.](http://arxiv.org/abs/2301.06967) | 这项研究探讨了在个体代理人的报告偏好经过隐私保护的噪声转换后进行公共物品供应的机制设计，并研究了保留公共决策、追求效率以及减轻噪声对收入影响之间的权衡。 |
| [^7] | [On Recoding Ordered Treatments as Binary Indicators.](http://arxiv.org/abs/2111.12258) | 本研究探讨了在使用工具变量研究有序治疗时，将治疗重新编码为二进制指示变量的方法。研究发现，当只存在广泛边际从者时，该方法可以捕捉到治疗效应的加权平均值，并可以进一步解析出每个从者群体的潜在结果均值。并且，研究还建立了广泛边际从者和二因素选择模型之间的等价性， 并应用于研究俄勒冈州健康保险实验中的治疗异质性。 |
| [^8] | [Valid Heteroskedasticity Robust Testing.](http://arxiv.org/abs/2104.12597) | 本文提出了一种有效的异方差鲁棒性检验方法，通过使用最小的控制大小的临界值，避免了异方差产生的问题，并给出了易于检查的条件。这些临界值是规范的选择，并能避免不必要的功率损失和虚假发现。 |

# 详细

[^1]: 股市中存在“龙王”吗？

    Are there Dragon Kings in the Stock Market?. (arXiv:2307.03693v1 [q-fin.ST])

    [http://arxiv.org/abs/2307.03693](http://arxiv.org/abs/2307.03693)

    研究发现，股市中存在一种被称为“龙王”的异常事件，它们与经济动荡相关并在统计意义上显著偏离分布尾部。

    

    我们对历史市场波动性进行了系统性研究，涵盖了大约过去五十年的时间。我们特别关注标普500指数实现波动率（RV）的时间序列及其分布函数。如预期的，RV的最大值与该时期的最大经济动荡相一致：储蓄和贷款危机、科技泡沫、金融危机和COVID-19大流行。我们探讨了这些值是否属于以下三类之一：黑天鹅（BS），即它们位于分布的无标度、幂律尾部；龙王（DK），即与BS显著上升偏离的统计意义上的异常；或者负龙王（nDK），即与BS显著下降偏离的统计意义上的异常。通过分析RV > 40的尾部，我们观察到“潜在”的龙王的出现，最终突然转变为负龙王。随着统计窗口天数的增加，这种现象变得更加明显。

    We undertake a systematic study of historic market volatility spanning roughly five preceding decades. We focus specifically on the time series of realized volatility (RV) of the S&P500 index and its distribution function. As expected, the largest values of RV coincide with the largest economic upheavals of the period: Savings and Loan Crisis, Tech Bubble, Financial Crisis and Covid Pandemic. We address the question of whether these values belong to one of the three categories: Black Swans (BS), that is they lie on scale-free, power-law tails of the distribution; Dragon Kings (DK), defined as statistically significant upward deviations from BS; or Negative Dragons Kings (nDK), defined as statistically significant downward deviations from BS. In analyzing the tails of the distribution with RV > 40, we observe the appearance of "potential" DK which eventually terminate in an abrupt plunge to nDK. This phenomenon becomes more pronounced with the increase of the number of days over which t
    
[^2]: 气候模型低估了北极海冰对碳排放的敏感性

    Climate Models Underestimate the Sensitivity of Arctic Sea Ice to Carbon Emissions. (arXiv:2307.03552v1 [econ.EM])

    [http://arxiv.org/abs/2307.03552](http://arxiv.org/abs/2307.03552)

    气候模型低估了北极海冰对碳排放的敏感性，未来北极无冰期可能比模型预计的要早得多。

    

    随着大气温室气体浓度的增加，北极海冰不断减少。利用1979年至2019年的观测数据，我们估计北极海冰面积与累积二氧化碳排放之间存在紧密的线性关系。为了比较，我们提供了使用全球气候模型（从CMIP5和CMIP6模型比较实验中提取的模拟数据）进行类似回归估计的结果。从观测数据来看，北极海冰面积对碳排放的敏感性比气候模型要强得多。因此，对于给定的未来排放路径，北极无冰期可能比气候模型预测的要早得多。此外，从CMIP5到CMIP6的最近全球气候模拟中，很少取得更准确地匹配北极海冰碳气候响应的进展。

    Arctic sea ice has steadily diminished as atmospheric greenhouse gas concentrations have increased. Using observed data from 1979 to 2019, we estimate a close contemporaneous linear relationship between Arctic sea ice area and cumulative carbon dioxide emissions. For comparison, we provide analogous regression estimates using simulated data from global climate models (drawn from the CMIP5 and CMIP6 model comparison exercises). The carbon sensitivity of Arctic sea ice area is considerably stronger in the observed data than in the climate models. Thus, for a given future emissions path, an ice-free Arctic is likely to occur much earlier than the climate models project. Furthermore, little progress has been made in recent global climate modeling (from CMIP5 to CMIP6) to more accurately match the observed carbon-climate response of Arctic sea ice.
    
[^3]: 带合约的匹配市场中的公司准稳定性和重新平衡

    Firm-quasi-stability and re-equilibration in matching markets with contracts. (arXiv:2305.17948v1 [econ.TH])

    [http://arxiv.org/abs/2305.17948](http://arxiv.org/abs/2305.17948)

    本研究探讨了带合约的匹配市场中的稳定性问题，发现稳定性破坏后，公司准稳定的分配方式可以自然出现，而我们提出的算法可以使市场从准稳定性中重新获得稳定性。

    

    本文研究了可替代偏好条件下，带有合约的多对多匹配中的公司准稳定性。我们建立了公司准稳定性和稳定性之间的各种关系，并对稳定配置的存在性和格子性质提供了新的见解。此外，我们证明了当市场的稳定性由于新公司的加入或一些工人的退休而受到破坏时，公司准稳定的分配自然出现，并介绍了一种广义的延迟接受算法，以表明市场可以通过分散的报价和接受过程从公司准稳定的分配中恢复稳定性。

    We study firm-quasi-stability in the framework of many-to-many matching with contracts under substitutable preferences. We establish various links between firm-quasi-stability and stability and give new insights into the existence and lattice property of stable allocations. Moreover, we show that firm-quasi-stable allocations appears naturally when the stability of the market is disrupted by the entry of new firms or the retirement of some workers, and introduce a generalized deferred acceptance algorithm to show that the market can regain stability from firm-quasi-stable allocations by a decentralized process of offers and acceptances.
    
[^4]: 委员会投票中的双赢公平性

    Best-of-Both-Worlds Fairness in Committee Voting. (arXiv:2303.03642v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2303.03642](http://arxiv.org/abs/2303.03642)

    本文提出了在委员会投票中实现前后双赢公平性的方法，并形式化了一系列属性的层次结构。我们提出了一个多项式时间算法，能同时满足后期合理代表性、前期群体公平份额和前期强个体公平份额。同时，我们也提出了一个不在多项式时间内运行的算法，输出满足后期全权代表性和前期强群体公平份额的彩票。

    

    双赢公平性范式倡导一种同时满足前后两种可取性质的方法。我们在重要的社会选择场景中引入了一个双赢公平性的观点，即基于批准的委员会投票。为此，我们在该领域中提出了前期比例代表性属性，并形式化了一系列属性的层次结构，其中包括个体公平份额 (IFS)、一致公平份额 (UFS)、群体公平份额 (GFS) 及其更强的变体。我们证明了它们与后期概念的兼容性，如扩展合理代表性 (EJR) 和全权代表性 (FJR)。我们的主要结果之一是一个多项式时间算法，能同时满足后期 EJR、前期 GFS 和前期强UFS。随后，我们进一步加强了后期的保证，提出了一个输出彩票的算法，该彩票满足后期 FJR 和前期强 UFS，但不在多项式时间内运行。

    The best-of-both-worlds paradigm advocates an approach that achieves desirable properties both ex-ante and ex-post. We launch a best-of-both-worlds fairness perspective for the important social choice setting of approval-based committee voting. To this end, we initiate work on ex-ante proportional representation properties in this domain and formalize a hierarchy of properties including Individual Fair Share (IFS), Unanimous Fair Share (UFS), Group Fair Share (GFS), and their stronger variants. We establish their compatibility with well-studied ex-post concepts such as extended justified representation (EJR) and fully justified representation (FJR). Our first main result is a polynomial-time algorithm that simultaneously satisfies ex-post EJR, ex-ante GFS and ex-ante Strong UFS. Subsequently, we strengthen our ex-post guarantee to FJR and present an algorithm that outputs a lottery which is ex-post FJR and ex-ante Strong UFS, but does not run in polynomial time.
    
[^5]: 顺序网络博弈中的个体化治疗分配

    Individualized Treatment Allocation in Sequential Network Games. (arXiv:2302.05747v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2302.05747](http://arxiv.org/abs/2302.05747)

    本文针对顺序决策博弈中的互动主体，提出了一种个体化治疗分配方法，通过评估结果的固定分布并采用变分近似和贪婪优化算法，最大化了社会福利准则。

    

    设计个体化的治疗分配，以最大化互动主体的均衡福利，在政策相关的应用中有很大的意义。本文针对互动主体的顺序决策博弈，开发了一种方法来获得最优的治疗分配规则，通过评估结果的固定分布来最大化社会福利准则。在顺序决策博弈中，固定分布由Gibbs分布给出，由于解析和计算复杂性，很难对治疗分配进行优化。我们采用变分近似来优化固定分布，并使用贪婪优化算法来优化近似平衡福利的治疗分配。我们通过福利遗憾界限推导了变分近似的性能，对贪婪优化算法的性能进行了表征。我们在模拟实验中实现了我们提出的方法。

    Designing individualized allocation of treatments so as to maximize the equilibrium welfare of interacting agents has many policy-relevant applications. Focusing on sequential decision games of interacting agents, this paper develops a method to obtain optimal treatment assignment rules that maximize a social welfare criterion by evaluating stationary distributions of outcomes. Stationary distributions in sequential decision games are given by Gibbs distributions, which are difficult to optimize with respect to a treatment allocation due to analytical and computational complexity. We apply a variational approximation to the stationary distribution and optimize the approximated equilibrium welfare with respect to treatment allocation using a greedy optimization algorithm. We characterize the performance of the variational approximation, deriving a performance guarantee for the greedy optimization algorithm via a welfare regret bound. We implement our proposed method in simulation exerci
    
[^6]: 二进制机制下的隐私保护噪声机构设计

    Binary Mechanisms under Privacy-Preserving Noise. (arXiv:2301.06967v2 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2301.06967](http://arxiv.org/abs/2301.06967)

    这项研究探讨了在个体代理人的报告偏好经过隐私保护的噪声转换后进行公共物品供应的机制设计，并研究了保留公共决策、追求效率以及减轻噪声对收入影响之间的权衡。

    

    我们研究了在个体代理人报告的偏好经过噪声保护的情况下进行公共物品供应的机制设计。该模型是一个具有转移和拟线性效用的标准二进制模型。代理人报告他们对公共物品的偏好，这些偏好会被随机“翻转”，以便任何个体报告都可以被解释为噪声的结果。我们研究了在存在噪声的情况下保留公共决策（噪声敏感性），追求效率以及减轻噪声对收入的影响之间的平衡。

    We study mechanism design for public-good provision under a noisy privacy-preserving transformation of individual agents' reported preferences. The setting is a standard binary model with transfers and quasi-linear utility. Agents report their preferences for the public good, which are randomly ``flipped,'' so that any individual report may be explained away as the outcome of noise. We study the tradeoffs between preserving the public decisions made in the presence of noise (noise sensitivity), pursuing efficiency, and mitigating the effect of noise on revenue.
    
[^7]: 关于将有序治疗重新编码为二进制指示变量的研究

    On Recoding Ordered Treatments as Binary Indicators. (arXiv:2111.12258v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2111.12258](http://arxiv.org/abs/2111.12258)

    本研究探讨了在使用工具变量研究有序治疗时，将治疗重新编码为二进制指示变量的方法。研究发现，当只存在广泛边际从者时，该方法可以捕捉到治疗效应的加权平均值，并可以进一步解析出每个从者群体的潜在结果均值。并且，研究还建立了广泛边际从者和二因素选择模型之间的等价性， 并应用于研究俄勒冈州健康保险实验中的治疗异质性。

    

    在使用工具变量研究有序治疗的研究中，常常将治疗重新编码为任何暴露的指示变量。我们在假设仪器将从无治疗转移到一些治疗中的从者，但不会从一些治疗转移到更多治疗的情况下，研究了该估计量。我们发现，当只存在广泛边际的从者时，该估计量捕捉了治疗效应的加权平均值，并且可以从各个从者群体的潜在结果均值中部分解开。我们还建立了广泛边际从者和二因素选择模型之间的等价性，并将我们的结果应用于研究俄勒冈州健康保险实验中的治疗异质性。

    Researchers using instrumental variables to investigate ordered treatments often recode treatment into an indicator for any exposure. We investigate this estimand under the assumption that the instruments shift compliers from no treatment to some but not from some treatment to more. We show that when there are extensive margin compliers only (EMCO) this estimand captures a weighted average of treatment effects that can be partially unbundled into each complier group's potential outcome means. We also establish an equivalence between EMCO and a two-factor selection model and apply our results to study treatment heterogeneity in the Oregon Health Insurance Experiment.
    
[^8]: 有效的异方差鲁棒性检验

    Valid Heteroskedasticity Robust Testing. (arXiv:2104.12597v3 [math.ST] UPDATED)

    [http://arxiv.org/abs/2104.12597](http://arxiv.org/abs/2104.12597)

    本文提出了一种有效的异方差鲁棒性检验方法，通过使用最小的控制大小的临界值，避免了异方差产生的问题，并给出了易于检查的条件。这些临界值是规范的选择，并能避免不必要的功率损失和虚假发现。

    

    异方差鲁棒性标准误差的检验是计量经济学实践中的重要技术。然而，选择正确的临界值并不简单：基于渐近理论的常规临界值往往会导致严重的大小失真；现有的调整方法，包括自助法，也存在相同问题。为了避免这些问题，本文建议使用最小的控制大小的临界值，我们在本文中证明了这些临界值在常用的检验统计量中的存在性。此外，我们给出了易于检查的足够条件和通常也是必要条件。如果这些临界值存在，它们是规范的选择：更大的临界值会导致不必要的功率损失，而更小的临界值会在零假设下过度拒绝，增加虚假发现的可能性，因此是无效的。我们建议使用算法来数值确定所提出的临界值，并提供了相应的实现。

    Tests based on heteroskedasticity robust standard errors are an important technique in econometric practice. Choosing the right critical value, however, is not simple at all: conventional critical values based on asymptotics often lead to severe size distortions; and so do existing adjustments including the bootstrap. To avoid these issues, we suggest to use smallest size-controlling critical values, the generic existence of which we prove in this article for the commonly used test statistics. Furthermore, sufficient and often also necessary conditions for their existence are given that are easy to check. Granted their existence, these critical values are the canonical choice: larger critical values result in unnecessary power loss, whereas smaller critical values lead to over-rejections under the null hypothesis, make spurious discoveries more likely, and thus are invalid. We suggest algorithms to numerically determine the proposed critical values and provide implementations in accomp
    

