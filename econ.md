# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Impact of Transportation Network Companies on Labor Supply and Wages for Taxi Drivers.](http://arxiv.org/abs/2307.13620) | 本研究通过分析纽约市2013年至2018年的出租车和TNC旅行记录数据，发现交通网络公司对出租车司机的工资和劳动供应产生负面影响，降低了他们的收入水平，并削弱了他们的工作意愿。 |
| [^2] | [Large sample properties of GMM estimators under second-order identification.](http://arxiv.org/abs/2307.13475) | 本文提出了GMM估计器在二阶识别条件下的大样本性质，证明了估计器的收敛速率并给出了极限分布，但需要满足过识别条件。 |
| [^3] | [Tuning-free testing of factor regression against factor-augmented sparse alternatives.](http://arxiv.org/abs/2307.13364) | 该研究提出了一种不需要调参、不需要估计协方差矩阵的自助法测试方法，用于评估因子回归模型在高维因子增强稀疏回归模型中的适用性。通过模拟实验证明了该方法的良好性能，并在应用于实际数据集时拒绝了经典因子回归模型的拟合性。 |
| [^4] | [Multilevel Large Language Models for Everyone.](http://arxiv.org/abs/2307.13221) | 本文提出了一个多层大型语言模型的设计，将通用的和特定的模型结合在一起，可以根据用户的个人输入和互联网信息相互改进。这种模型受到人类大脑功能的启发，具有全局、领域和用户级模型，可以在本地机器上运行以保护用户隐私。 |
| [^5] | [Inference in Experiments with Matched Pairs and Imperfect Compliance.](http://arxiv.org/abs/2307.13094) | 本文研究了在不完全遵守的随机对照试验中，根据"匹配对"确定治疗状态的局部平均治疗效应的推断，并提出了一种对极限方差的一致估计器。 |
| [^6] | [Synthetic Control Methods by Density Matching under Implicit Endogeneitiy.](http://arxiv.org/abs/2307.11127) | 本文提出了一种新型的合成对照方法，通过密度匹配来解决现有SCMs中的隐式内生性问题。该方法通过将经过处理单元的结果密度与未处理单元的密度进行加权平均来估计SC权重。 |
| [^7] | [Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?.](http://arxiv.org/abs/2306.10590) | 本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。 |
| [^8] | [Pricing cyber-insurance for systems via maturity models.](http://arxiv.org/abs/2302.04734) | 本篇论文提出了一种使用安全成熟度模型的方法，以评估组织的安全水平并确定网络保险的适当保费。 |
| [^9] | [An identification and testing strategy for proxy-SVARs with weak proxies.](http://arxiv.org/abs/2210.04523) | 本研究提出了一种针对具有弱代理的代理-SVARs的识别和测试策略。通过使用强工具对非目标冲击进行代理-SVAR的识别，可以通过最小距离估计和标准渐近方法进行频率学派渐近推断。该策略通过基于自助重采样的零仪器相关性预检验，解决了传统方法中的预检验问题。 |
| [^10] | [Constrained Classification and Policy Learning.](http://arxiv.org/abs/2106.12886) | 研究了受限分类和策略学习中替代损失程序的一致性和适用性。 |

# 详细

[^1]: 交通网络公司对出租车司机的劳动供应和工资影响的研究

    Impact of Transportation Network Companies on Labor Supply and Wages for Taxi Drivers. (arXiv:2307.13620v1 [stat.AP])

    [http://arxiv.org/abs/2307.13620](http://arxiv.org/abs/2307.13620)

    本研究通过分析纽约市2013年至2018年的出租车和TNC旅行记录数据，发现交通网络公司对出租车司机的工资和劳动供应产生负面影响，降低了他们的收入水平，并削弱了他们的工作意愿。

    

    尽管交通网络公司（TNCs）的增长大幅减少了传统出租车行业的客流和资产价值，但现有的出租车市场政策法规和规划模型仍需要重新审视，这需要对出租车行业劳动供应和收入水平的敏感性进行可靠估计。本研究旨在调查交通网络公司对出租车行业劳动供应的影响，估计工资弹性，并了解出租车司机工作偏好的变化。我们引入工资分解方法，根据纽约市2013年至2018年的出租车和TNC旅行记录数据，量化TNC旅行对出租车司机工作时间的影响。通过统计分析对数据进行分析，以评估整体市场表现和出租车司机工作行为的变化，我们的研究结果表明，TNC旅行的增加不仅降低了出租车司机的收入水平，还削弱了他们工作的意愿。

    While the growth of TNCs took a substantial part of ridership and asset value away from the traditional taxi industry, existing taxi market policy regulations and planning models remain to be reexamined, which requires reliable estimates of the sensitivity of labor supply and income levels in the taxi industry. This study aims to investigate the impact of TNCs on the labor supply of the taxi industry, estimate wage elasticity, and understand the changes in taxi drivers' work preferences. We introduce the wage decomposition method to quantify the effects of TNC trips on taxi drivers' work hours over time, based on taxi and TNC trip record data from 2013 to 2018 in New York City. The data are analyzed to evaluate the changes in overall market performances and taxi drivers' work behavior through statistical analyses, and our results show that the increase in TNC trips not only decreases the income level of taxi drivers but also discourages their willingness to work. We find that 1% increa
    
[^2]: GMM估计器在二阶识别下的大样本性质

    Large sample properties of GMM estimators under second-order identification. (arXiv:2307.13475v1 [econ.EM])

    [http://arxiv.org/abs/2307.13475](http://arxiv.org/abs/2307.13475)

    本文提出了GMM估计器在二阶识别条件下的大样本性质，证明了估计器的收敛速率并给出了极限分布，但需要满足过识别条件。

    

    本文翻译了Dovonon和Hall（2018）在全局识别参数向量{\phi}的p维情形中，当一阶识别条件失败但二阶识别条件成立时提出了GMM估计器的极限分布理论。他们假设一阶不识别是由于在真实值{\phi}_{0}处预期的Jacobian矩阵的秩为p-1，即存在秩缺失的情况。通过对模型重新参数化，使得Jacobian矩阵的最后一列为零，他们证明了前p-1个参数的GMM估计收敛速率为T^{-1/2}，剩下的参数{\phi}_{p}的GMM估计收敛速率为T^{-1/4}。他们还给出了T^{1/4}({\phi}_{p}-{\phi}_{0,p})的极限分布，但需要满足一个（不透明）条件，他们声称这个条件通常并不具限制性。然而，正如我们在本文中所展示的，他们的条件实际上只有在{\phi}过识别的情况下才满足。

    Dovonon and Hall (Journal of Econometrics, 2018) proposed a limiting distribution theory for GMM estimators for a p - dimensional globally identified parameter vector {\phi} when local identification conditions fail at first-order but hold at second-order. They assumed that the first-order underidentification is due to the expected Jacobian having rank p-1 at the true value {\phi}_{0}, i.e., having a rank deficiency of one. After reparametrizing the model such that the last column of the Jacobian vanishes, they showed that the GMM estimator of the first p-1 parameters converges at rate T^{-1/2} and the GMM estimator of the remaining parameter, {\phi}_{p}, converges at rate T^{-1/4}. They also provided a limiting distribution of T^{1/4}({\phi}_{p}-{\phi}_{0,p}) subject to a (non-transparent) condition which they claimed to be not restrictive in general. However, as we show in this paper, their condition is in fact only satisfied when {\phi} is overidentified and the limiting distributio
    
[^3]: 不需要调参的因子回归测试与因子增强稀疏的对立. (arXiv:2307.13364v1 [econ.EM])

    Tuning-free testing of factor regression against factor-augmented sparse alternatives. (arXiv:2307.13364v1 [econ.EM])

    [http://arxiv.org/abs/2307.13364](http://arxiv.org/abs/2307.13364)

    该研究提出了一种不需要调参、不需要估计协方差矩阵的自助法测试方法，用于评估因子回归模型在高维因子增强稀疏回归模型中的适用性。通过模拟实验证明了该方法的良好性能，并在应用于实际数据集时拒绝了经典因子回归模型的拟合性。

    

    该研究引入了一种基于自助法的因子回归有效性测试方法，该方法在集成了因子回归和稀疏回归技术的高维因子增强稀疏回归模型中使用。该测试方法提供了一种评估经典（密集）因子回归模型与替代（稀疏加密集）因子增强稀疏回归模型的适用性的方式。我们提出的测试不需要调参，消除了估计协方差矩阵的需求，并且在实现上简单。该测试的有效性在时间序列相关性下在理论上得到了证明。通过模拟实验，我们展示了我们的方法在有限样本下的良好性能。此外，我们使用FRED-MD数据集应用了该测试，并在因变量为通胀时拒绝了经典因子回归模型的拟合性，但在因变量为工业生产时未拒绝。这些发现为选择适当模型提供了参考。

    This study introduces a bootstrap test of the validity of factor regression within a high-dimensional factor-augmented sparse regression model that integrates factor and sparse regression techniques. The test provides a means to assess the suitability of the classical (dense) factor regression model compared to alternative (sparse plus dense) factor-augmented sparse regression models. Our proposed test does not require tuning parameters, eliminates the need to estimate covariance matrices, and offers simplicity in implementation. The validity of the test is theoretically established under time-series dependence. Through simulation experiments, we demonstrate the favorable finite sample performance of our procedure. Moreover, using the FRED-MD dataset, we apply the test and reject the adequacy of the classical factor regression model when the dependent variable is inflation but not when it is industrial production. These findings offer insights into selecting appropriate models for high
    
[^4]: 为所有人设计的多层大型语言模型

    Multilevel Large Language Models for Everyone. (arXiv:2307.13221v1 [cs.CV])

    [http://arxiv.org/abs/2307.13221](http://arxiv.org/abs/2307.13221)

    本文提出了一个多层大型语言模型的设计，将通用的和特定的模型结合在一起，可以根据用户的个人输入和互联网信息相互改进。这种模型受到人类大脑功能的启发，具有全局、领域和用户级模型，可以在本地机器上运行以保护用户隐私。

    

    在过去几年中，大型语言模型取得了显著的进展。然而，它们要么是通用的，要么是领域特定的，将社区划分为不同的群体。在本文中，我们将这些大型语言模型统一到一个更大的地图中，将通用的和特定的模型连接在一起，并根据用户的个人输入和来自互联网的信息相互改进。将多个大型语言模型链接在一起的思想受到了人类大脑功能的启发。大脑皮层上的特定区域对于某些低层次功能是特定的。而这些区域可以共同工作，实现更复杂的高层功能。人类大脑皮层上的这种行为为设计包含全局、领域和用户级模型的多层大型语言模型提供了新思路。用户级模型在本地机器上运行，以实现高效的响应并保护用户的隐私。这样的多层模型可以减少计算资源的消耗。

    Large language models have made significant progress in the past few years. However, they are either generic {\it or} field specific, splitting the community into different groups. In this paper, we unify these large language models into a larger map, where the generic {\it and} specific models are linked together and can improve each other, based on the user personal input and information from the internet. The idea of linking several large language models together is inspired by the functionality of human brain. The specific regions on the brain cortex are specific for certain low level functionality. And these regions can jointly work together to achieve more complex high level functionality. Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models. The user level models run on local machines to achieve efficient response and protect the user's privacy. Such multilevel models reduc
    
[^5]: 匹配对和不完全遵守下的实验推断

    Inference in Experiments with Matched Pairs and Imperfect Compliance. (arXiv:2307.13094v1 [econ.EM])

    [http://arxiv.org/abs/2307.13094](http://arxiv.org/abs/2307.13094)

    本文研究了在不完全遵守的随机对照试验中，根据"匹配对"确定治疗状态的局部平均治疗效应的推断，并提出了一种对极限方差的一致估计器。

    

    本文研究了在不完全遵守的随机对照试验中，根据“匹配对”确定治疗状态的局部平均治疗效应的推断。通过“匹配对”，我们指的是从感兴趣的总体中独立和随机抽取单位，根据观察到的基线协变量进行配对，然后在每个对中，随机选择一个单位进行治疗。在对匹配质量进行的弱假设下，我们首先推导了传统的Wald（即二阶最小二乘）估计器的局部平均治疗效应的极限行为。我们进一步显示，传统的异方差性稳健估计器的极限方差通常是保守的，即其可能性极限比极限方差（通常严格地）大。因此，我们提供了一种对所需数量一致的极限方差的替代估计器。最后，我们考虑了额外观察到的基线协变量的使用。

    This paper studies inference for the local average treatment effect in randomized controlled trials with imperfect compliance where treatment status is determined according to "matched pairs." By "matched pairs," we mean that units are sampled i.i.d. from the population of interest, paired according to observed, baseline covariates and finally, within each pair, one unit is selected at random for treatment. Under weak assumptions governing the quality of the pairings, we first derive the limiting behavior of the usual Wald (i.e., two-stage least squares) estimator of the local average treatment effect. We show further that the conventional heteroskedasticity-robust estimator of its limiting variance is generally conservative in that its limit in probability is (typically strictly) larger than the limiting variance. We therefore provide an alternative estimator of the limiting variance that is consistent for the desired quantity. Finally, we consider the use of additional observed, base
    
[^6]: 通过密度匹配实现的合成对照方法下的隐式内生性问题

    Synthetic Control Methods by Density Matching under Implicit Endogeneitiy. (arXiv:2307.11127v1 [econ.EM])

    [http://arxiv.org/abs/2307.11127](http://arxiv.org/abs/2307.11127)

    本文提出了一种新型的合成对照方法，通过密度匹配来解决现有SCMs中的隐式内生性问题。该方法通过将经过处理单元的结果密度与未处理单元的密度进行加权平均来估计SC权重。

    

    合成对照方法（SCMs）已成为比较案例研究中因果推断的重要工具。SCMs的基本思想是通过使用来自未处理单元的观测结果的加权和来估计经过处理单元的反事实结果。合成对照（SC）的准确性对于估计因果效应至关重要，因此，SC权重的估计成为了研究的焦点。在本文中，我们首先指出现有的SCMs存在一个隐式内生性问题，即未处理单元的结果与反事实结果模型中的误差项之间的相关性。我们展示了这个问题会对因果效应估计器产生偏差。然后，我们提出了一种基于密度匹配的新型SCM，假设经过处理单元的结果密度可以用未处理单元的密度的加权平均来近似（即混合模型）。基于这一假设，我们通过匹配来估计SC权重。

    Synthetic control methods (SCMs) have become a crucial tool for causal inference in comparative case studies. The fundamental idea of SCMs is to estimate counterfactual outcomes for a treated unit by using a weighted sum of observed outcomes from untreated units. The accuracy of the synthetic control (SC) is critical for estimating the causal effect, and hence, the estimation of SC weights has been the focus of much research. In this paper, we first point out that existing SCMs suffer from an implicit endogeneity problem, which is the correlation between the outcomes of untreated units and the error term in the model of a counterfactual outcome. We show that this problem yields a bias in the causal effect estimator. We then propose a novel SCM based on density matching, assuming that the density of outcomes of the treated unit can be approximated by a weighted average of the densities of untreated units (i.e., a mixture model). Based on this assumption, we estimate SC weights by matchi
    
[^7]: 我们能否在不做任何假设的情况下，证伪Wald置信区间在双重稳健函数下的有效性？

    Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])

    [http://arxiv.org/abs/2306.10590](http://arxiv.org/abs/2306.10590)

    本文提出无假设检验方法，可否定分析师对基于双重机器学习估计的Wald置信区间在广泛的双重稳健函数类中的有效性的证明。

    

    本文提出了一种可行的版本的无假设检验方法，可否定分析师对报道的以双重机器学习(DML)估计量为中心的名义$(1-\alpha)$Wald置信区间的有效性的证明，对Rotnitzky等人所研究的双重稳健(DR)函数类的任何成员进行检验。DR函数类在经济学和生物统计学中具有广泛和核心的重要性。它严格包括两个类别，即(i)可以被写成条件期望的仿射函数期望的均方连续函数的类别，这是由Chernozhukov等人研究的，以及Robins等人所研究的类别。目前DR函数的最先进的估计值是DML估计值。$\hat{\psi}_{1}$的偏差取决于两个辅助函数$b$和$p$的估计率的乘积。最常见的是，分析师证明了

    In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
    
[^8]: 基于成熟度模型的信息系统网络保险定价

    Pricing cyber-insurance for systems via maturity models. (arXiv:2302.04734v2 [econ.GN] UPDATED)

    [http://arxiv.org/abs/2302.04734](http://arxiv.org/abs/2302.04734)

    本篇论文提出了一种使用安全成熟度模型的方法，以评估组织的安全水平并确定网络保险的适当保费。

    

    对于与信息技术系统相关的风险进行保险定价提出了一个综合的建议，结合运营管理、安全和经济学，提出了一个社会经济模型。该模型包括实体关系图、安全成熟度模型和经济模型，解决了一个长期以来的研究难题，即如何在设计和定价网络保险政策时捕捉组织结构。文中提出了一个新的挑战，即网络保险的数据历史有限，不能直接应用于其它险种，因此提出一个安全成熟度模型，以评估组织的安全水平并确定相应的保险费用。

    Pricing insurance for risks associated with information technology systems presents a complex modelling challenge, combining the disciplines of operations management, security, and economics. This work proposes a socioeconomic model for cyber-insurance decisions compromised of entity relationship diagrams, security maturity models, and economic models, addressing a long-standing research challenge of capturing organizational structure in the design and pricing of cyber-insurance policies. Insurance pricing is usually informed by the long experience insurance companies have of the magnitude and frequency of losses that arise in organizations based on their size, industry sector, and location. Consequently, their calculations of premia will start from a baseline determined by these considerations. A unique challenge of cyber-insurance is that data history is limited and not necessarily informative of future loss risk meaning that established actuarial methodology for other lines of insur
    
[^9]: 一种针对具有弱代理的代理-SVARs的识别和测试策略

    An identification and testing strategy for proxy-SVARs with weak proxies. (arXiv:2210.04523v3 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2210.04523](http://arxiv.org/abs/2210.04523)

    本研究提出了一种针对具有弱代理的代理-SVARs的识别和测试策略。通过使用强工具对非目标冲击进行代理-SVAR的识别，可以通过最小距离估计和标准渐近方法进行频率学派渐近推断。该策略通过基于自助重采样的零仪器相关性预检验，解决了传统方法中的预检验问题。

    

    当用于识别目标结构冲击的代理（外部工具）较弱时，代理-SVARs（SVAR-IVs）中的推断是非标准的，并且为了构建感兴趣冲击响应的渐近有效置信区间，需要使用弱工具鲁棒方法。在存在多个目标冲击的情况下，测试反演技术需要对代理-SVAR参数施加额外的限制，这些限制可能难以解释和测试。我们展示了在这些情况下可以通过最小距离估计和标准渐近方法进行频率学派渐近推断，前提是可以使用“强”工具对非目标冲击（即分析中不感兴趣的冲击）进行代理-SVAR的识别。建议的识别策略依赖于一种基于自助重采样的零仪器相关性预检验，该预检验不受预检验问题的影响，从而保证了其有效性。

    When proxies (external instruments) used to identify target structural shocks are weak, inference in proxy-SVARs (SVAR-IVs) is nonstandard and the construction of asymptotically valid confidence sets for the impulse responses of interest requires weak-instrument robust methods. In the presence of multiple target shocks, test inversion techniques require extra restrictions on the proxy-SVAR parameters other those implied by the proxies that may be difficult to interpret and test. We show that frequentist asymptotic inference in these situations can be conducted through Minimum Distance estimation and standard asymptotic methods if the proxy-SVAR can be identified by using `strong' instruments for the non-target shocks; i.e. the shocks which are not of primary interest in the analysis. The suggested identification strategy hinges on a novel pre-test for the null of instrument relevance based on bootstrap resampling which is not subject to pre-testing issues, in the sense that the validit
    
[^10]: 受限分类和策略学习

    Constrained Classification and Policy Learning. (arXiv:2106.12886v2 [econ.EM] UPDATED)

    [http://arxiv.org/abs/2106.12886](http://arxiv.org/abs/2106.12886)

    研究了受限分类和策略学习中替代损失程序的一致性和适用性。

    

    现代机器学习方法对于分类问题使用了一些替代损失技术，如AdaBoost、支持向量机和深度神经网络，以绕过最小化经验分类风险的计算复杂性。这些技术在因果策略学习问题中也很有用，因为个性化治疗规则的估计可以被视为一种加权（成本敏感）分类问题。Zhang（2004年）和Bartlett等人（2006年）研究的替代损失方法的一致性关键依赖于正确规范的假设，即指定的分类器集合足够丰富，包含一个最佳分类器。然而，当分类器集合受到可解释性或公平性的限制时，这个假设较不可靠，这导致在这种次佳情景下替代损失方法的适用性未知。本文研究了在受限类集合条件下的替代损失程序的一致性。

    Modern machine learning approaches to classification, including AdaBoost, support vector machines, and deep neural networks, utilize surrogate loss techniques to circumvent the computational complexity of minimizing empirical classification risk. These techniques are also useful for causal policy learning problems, since estimation of individualized treatment rules can be cast as a weighted (cost-sensitive) classification problem. Consistency of the surrogate loss approaches studied in Zhang (2004) and Bartlett et al. (2006) crucially relies on the assumption of correct specification, meaning that the specified set of classifiers is rich enough to contain a first-best classifier. This assumption is, however, less credible when the set of classifiers is constrained by interpretability or fairness, leaving the applicability of surrogate loss based algorithms unknown in such second-best scenarios. This paper studies consistency of surrogate loss procedures under a constrained set of class
    

