<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#33041;&#32534;&#30721;&#30340;&#20219;&#21153;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;10&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38598;&#25104;&#65292;&#30456;&#36739;&#20110;&#24403;&#21069;&#22522;&#20934;&#32447;&#65292;&#24179;&#22343;&#25552;&#39640;&#20102;10%&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.15720</link><description>&lt;p&gt;
&#29992;&#20110;&#22823;&#33041;&#32534;&#30721;&#30340;&#20219;&#21153;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Ensemble of Task-Specific Language Models for Brain Encoding. (arXiv:2310.15720v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15720
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22823;&#33041;&#32534;&#30721;&#30340;&#20219;&#21153;&#29305;&#23450;&#35821;&#35328;&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;10&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38598;&#25104;&#65292;&#30456;&#36739;&#20110;&#24403;&#21069;&#22522;&#20934;&#32447;&#65292;&#24179;&#22343;&#25552;&#39640;&#20102;10%&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#35821;&#35328;&#27169;&#22411;&#36275;&#22815;&#20016;&#23500;&#65292;&#21487;&#20197;&#32534;&#30721;&#25105;&#20204;&#22823;&#33041;&#20013;&#29305;&#23450;&#20852;&#36259;&#21306;&#22495;&#30340;fMRI&#28608;&#27963;&#24773;&#20917;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#25506;&#32034;&#20102;&#20174;&#20026;&#27969;&#34892;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#23398;&#20064;&#30340;&#34920;&#31034;&#21521;&#39044;&#27979;&#22823;&#33041;&#21709;&#24212;&#30340;&#36716;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#30001;10&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;2&#20010;&#21477;&#27861;&#21644;8&#20010;&#35821;&#20041;&#65289;&#32452;&#25104;&#30340;&#38598;&#25104;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#36825;&#26679;&#30340;&#32534;&#30721;&#22120;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#22312;&#25152;&#26377;&#20852;&#36259;&#21306;&#22495;&#20013;&#65292;&#25105;&#20204;&#23558;&#24403;&#21069;&#30340;&#22522;&#20934;&#32447;&#25552;&#39640;&#20102;&#24179;&#22343;10%&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models have been shown to be rich enough to encode fMRI activations of certain Regions of Interest in our Brains. Previous works have explored transfer learning from representations learned for popular natural language processing tasks for predicting brain responses. In our work, we improve the performance of such encoders by creating an ensemble model out of 10 popular Language Models (2 syntactic and 8 semantic). We beat the current baselines by 10% on average across all ROIs through our ensembling methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#20960;&#20309;&#21644;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#20998;&#26512;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20013;&#30340;&#21387;&#32553;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20004;&#20010;&#35270;&#35282;&#39640;&#24230;&#30456;&#20851;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#35821;&#35328;&#25968;&#25454;&#30340;&#39640;&#21387;&#32553;&#39044;&#27979;&#20102;&#23545;&#35813;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#36866;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.13620</link><description>&lt;p&gt;
&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#36830;&#25509;&#20449;&#24687;&#35770;&#21644;&#20960;&#20309;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Bridging Information-Theoretic and Geometric Compression in Language Models. (arXiv:2310.13620v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13620
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20174;&#20960;&#20309;&#21644;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#20998;&#26512;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#20013;&#30340;&#21387;&#32553;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20004;&#20010;&#35270;&#35282;&#39640;&#24230;&#30456;&#20851;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#35821;&#35328;&#25968;&#25454;&#30340;&#39640;&#21387;&#32553;&#39044;&#27979;&#20102;&#23545;&#35813;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30495;&#23454;&#22320;&#27169;&#25311;&#20154;&#31867;&#35821;&#35328;&#65292;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#24517;&#39035;&#23558;&#22823;&#37327;&#30340;&#12289;&#28508;&#22312;&#26080;&#38480;&#30340;&#20449;&#24687;&#21387;&#32553;&#21040;&#30456;&#23545;&#36739;&#23569;&#30340;&#32500;&#24230;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20174;&#20960;&#20309;&#21644;&#20449;&#24687;&#35770;&#30340;&#20004;&#20010;&#35282;&#24230;&#20998;&#26512;&#65288;&#39044;&#35757;&#32451;&#30340;&#65289;LM&#30340;&#21387;&#32553;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#35270;&#35282;&#39640;&#24230;&#30456;&#20851;&#65292;&#35821;&#35328;&#25968;&#25454;&#30340;&#20869;&#22312;&#20960;&#20309;&#32500;&#24230;&#21487;&#20197;&#39044;&#27979;&#23427;&#20204;&#22312;LM&#19979;&#30340;&#32534;&#30721;&#38271;&#24230;&#12290;&#28982;&#21518;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#36827;&#19968;&#27493;&#65292;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#39640;&#21387;&#32553;&#39044;&#27979;&#20102;&#23545;&#35813;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#36866;&#24212;&#65292;&#30830;&#35748;&#20102;&#33021;&#22815;&#21387;&#32553;&#35821;&#35328;&#20449;&#24687;&#26159;&#25104;&#21151;LM&#24615;&#33021;&#30340;&#37325;&#35201;&#37096;&#20998;&#12290;&#20316;&#20026;&#25105;&#20204;&#20998;&#26512;&#30340;&#23454;&#38469;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#39318;&#27425;&#35780;&#20272;&#20102;&#19968;&#31995;&#21015;&#22312;&#35821;&#35328;&#25968;&#25454;&#19978;&#30340;&#20869;&#22312;&#32500;&#24230;&#20272;&#35745;&#22120;&#65292;&#34920;&#26126;&#21482;&#26377;&#19968;&#37096;&#20998;&#23553;&#35013;&#20102;&#20449;&#24687;&#35770;&#21387;&#32553;&#12289;&#20960;&#20309;&#21387;&#32553;&#21644;&#36866;&#24212;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
For a language model (LM) to faithfully model human language, it must compress vast, potentially infinite information into relatively few dimensions. We propose analyzing compression in (pre-trained) LMs from two points of view: geometric and information-theoretic. We demonstrate that the two views are highly correlated, such that the intrinsic geometric dimension of linguistic data predicts their coding length under the LM. We then show that, in turn, high compression of a linguistic dataset predicts rapid adaptation to that dataset, confirming that being able to compress linguistic information is an important part of successful LM performance. As a practical byproduct of our analysis, we evaluate a battery of intrinsic dimension estimators for the first time on linguistic data, showing that only some encapsulate the relationship between information-theoretic compression, geometric compression, and ease-of-adaptation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#27169;&#22411;&#22823;&#23567;&#12289;&#35821;&#35328;&#37197;&#23545;&#31561;&#22240;&#32032;&#21457;&#29616;&#20102;&#24433;&#21709;&#19968;&#33268;&#24615;&#30340;&#22240;&#32032;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22686;&#21152;&#27169;&#22411;&#22823;&#23567;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#19981;&#20250;&#25913;&#21892;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10378</link><description>&lt;p&gt;
&#36328;&#35821;&#35328;&#22810;&#35821;&#35328;&#27169;&#22411;&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models. (arXiv:2310.10378v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#27169;&#22411;&#22823;&#23567;&#12289;&#35821;&#35328;&#37197;&#23545;&#31561;&#22240;&#32032;&#21457;&#29616;&#20102;&#24433;&#21709;&#19968;&#33268;&#24615;&#30340;&#22240;&#32032;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22686;&#21152;&#27169;&#22411;&#22823;&#23567;&#21487;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#19981;&#20250;&#25913;&#21892;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#35328;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#26174;&#31034;&#23384;&#20648;&#20102;&#22823;&#37327;&#30340;&#20107;&#23454;&#30693;&#35782;&#65292;&#20294;&#22312;&#19981;&#21516;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#30340;&#21464;&#21270;&#12290;&#20026;&#20102;&#30830;&#20445;&#19981;&#21516;&#35821;&#35328;&#32972;&#26223;&#30340;&#29992;&#25143;&#20174;&#21516;&#19968;&#20010;&#27169;&#22411;&#20013;&#33719;&#24471;&#19968;&#33268;&#30340;&#21453;&#39304;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#22810;&#35821;&#35328;PLM&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#65288;CLC&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25490;&#24207;&#30340;&#19968;&#33268;&#24615;&#65288;RankC&#65289;&#24230;&#37327;&#65292;&#29992;&#20110;&#29420;&#31435;&#20110;&#20934;&#30830;&#24615;&#35780;&#20272;&#36328;&#35821;&#35328;&#38388;&#30340;&#30693;&#35782;&#19968;&#33268;&#24615;&#12290;&#21033;&#29992;&#36825;&#20010;&#24230;&#37327;&#26041;&#27861;&#65292;&#25105;&#20204;&#23545;&#20915;&#23450;CLC&#30340;&#22240;&#32032;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#21253;&#25324;&#27169;&#22411;&#23618;&#38754;&#21644;&#35821;&#35328;&#23545;&#23618;&#38754;&#12290;&#22312;&#20854;&#20182;&#32467;&#26524;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22686;&#21152;&#27169;&#22411;&#22823;&#23567;&#21487;&#20197;&#25552;&#39640;&#22823;&#22810;&#25968;&#35821;&#35328;&#20013;&#30340;&#20107;&#23454;&#25506;&#27979;&#20934;&#30830;&#24615;&#65292;&#20294;&#19981;&#33021;&#25913;&#21892;&#36328;&#35821;&#35328;&#19968;&#33268;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#22411;&#32534;&#36753;&#22312;PLMs&#20013;&#25554;&#20837;&#26032;&#30340;&#20107;&#23454;&#20851;&#32852;&#36827;&#34892;&#20102;&#19968;&#20010;CLC&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;&#23545;&#19968;&#23567;&#37096;&#20998;&#20107;&#23454;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#30340;&#19978;&#19979;&#38480;&#65292;&#21457;&#29616;&#23427;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#21516;&#26102;&#65292;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;Strahler&#25968;&#30340;&#22686;&#38271;&#27169;&#24335;&#65292;&#25581;&#31034;&#20102;&#23427;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2307.02697</link><description>&lt;p&gt;
Strahler&#25968;&#30340;&#32479;&#35745;&#21147;&#23398;&#65306;&#22522;&#20110;&#38543;&#26426;&#21644;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Statistical Mechanics of Strahler Number via Random and Natural Language Sentences. (arXiv:2307.02697v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#30340;&#19978;&#19979;&#38480;&#65292;&#21457;&#29616;&#23427;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#21516;&#26102;&#65292;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;Strahler&#25968;&#30340;&#22686;&#38271;&#27169;&#24335;&#65292;&#25581;&#31034;&#20102;&#23427;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Strahler&#25968;&#26368;&#21021;&#34987;&#25552;&#20986;&#29992;&#20110;&#25551;&#36848;&#27827;&#27969;&#20998;&#25903;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25214;&#21040;&#20102;&#21508;&#31181;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#35745;&#31639;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#19978;&#19979;&#38480;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#32467;&#26500;&#21487;&#20197;&#22312;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#23545;&#35821;&#27861;&#27880;&#37322;&#25968;&#25454;&#30340;&#32463;&#39564;&#24615;&#27979;&#37327;&#65292;&#26174;&#31034;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#30340;Strahler&#25968;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#19982;Strahler&#65288;1957&#24180;&#65289;&#21644;Horton&#65288;1945&#24180;&#65289;&#25253;&#36947;&#30340;&#27827;&#27969;&#20998;&#27969;&#24773;&#20917;&#31867;&#20284;&#12290;&#20174;&#35813;&#25968;&#20540;&#30340;&#29702;&#35770;&#35266;&#28857;&#20986;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#23427;&#26159;&#22312;&#29305;&#23450;&#27169;&#22411;&#19979;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#25968;&#23398;&#20998;&#26512;&#36827;&#19968;&#27493;&#20551;&#35774;&#20102;Strahler&#25968;&#30340;&#24615;&#36136;&#65292;&#25581;&#31034;&#20986;&#23427;&#24182;&#38750;&#24120;&#25968;&#32780;&#26159;&#20197;&#23545;&#25968;&#24418;&#24335;&#22686;&#38271;&#12290;&#36825;&#19968;&#21457;&#29616;&#25581;&#31034;&#20102;Strahler&#25968;&#20316;&#20026;&#25551;&#36848;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications. This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures, which are available in a large dataset allowing for statistical mechanics analysis.  Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost always 3 or 4, similar to the case of river bifurcation as reported by Strahler (1957) and Horton (1945).  From the theory behind the number, we show that it is the lower limit of the amount of memory required to process sentences under a particular model. A mathematical analysis of random trees provides a further conjecture on the nature of the Strahler number, revealing that it is not a constant but grows logarithmically. This finding uncovers the statistical basics behind the Strahler number as a character
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#35745;&#31639;&#38656;&#27714;&#37327;&#22823;&#30340;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#19981;&#24179;&#31561;&#21644;&#25285;&#24551;&#65292;&#36890;&#36807;&#23545;NLP&#31038;&#21306;&#30340;312&#20301;&#21442;&#19982;&#32773;&#36827;&#34892;&#35843;&#26597;&#65292;&#21457;&#29616;&#20102;&#22312;&#36164;&#21382;&#12289;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#31561;&#26041;&#38754;&#23384;&#22312;&#30340;&#65288;&#19981;&#65289;&#24179;&#31561;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32531;&#35299;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.16900</link><description>&lt;p&gt;
&#35843;&#26597;&#35745;&#31639;&#38656;&#27714;&#37327;&#22823;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30740;&#31350;&#20013;&#30340;&#19981;&#24179;&#31561;&#21644;&#25285;&#24551;
&lt;/p&gt;
&lt;p&gt;
Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research. (arXiv:2306.16900v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16900
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#35745;&#31639;&#38656;&#27714;&#37327;&#22823;&#30340;&#30740;&#31350;&#20013;&#23384;&#22312;&#30340;&#19981;&#24179;&#31561;&#21644;&#25285;&#24551;&#65292;&#36890;&#36807;&#23545;NLP&#31038;&#21306;&#30340;312&#20301;&#21442;&#19982;&#32773;&#36827;&#34892;&#35843;&#26597;&#65292;&#21457;&#29616;&#20102;&#22312;&#36164;&#21382;&#12289;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#31561;&#26041;&#38754;&#23384;&#22312;&#30340;&#65288;&#19981;&#65289;&#24179;&#31561;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32531;&#35299;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#35768;&#22810;&#26368;&#26032;&#36827;&#23637;&#28304;&#20110;&#24320;&#21457;&#21644;&#20351;&#29992;&#20855;&#26377;&#25968;&#21313;&#20159;&#21442;&#25968;&#30340;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLM&#65289;&#12290;&#22823;&#27169;&#22411;&#30340;&#35268;&#27169;&#20351;&#24471;&#35745;&#31639;&#25104;&#26412;&#25104;&#20026;&#35757;&#32451;&#21644;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#30340;&#20027;&#35201;&#38480;&#21046;&#22240;&#32032;&#20043;&#19968;&#65307;&#24182;&#19988;&#23545;&#20110;&#30740;&#31350;PLMs&#30340;&#21487;&#25345;&#32493;&#24615;&#12289;&#21487;&#37325;&#22797;&#24615;&#21644;&#21253;&#23481;&#24615;&#24341;&#21457;&#20102;&#20005;&#37325;&#30340;&#25285;&#24551;&#12290;&#36825;&#20123;&#25285;&#24551;&#24448;&#24448;&#22522;&#20110;&#20010;&#20154;&#32463;&#39564;&#21644;&#35266;&#23519;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#36827;&#34892;&#22823;&#35268;&#27169;&#35843;&#26597;&#26469;&#35843;&#26597;&#36825;&#20123;&#25285;&#24551;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#37327;&#21270;&#19982;&#29615;&#22659;&#24433;&#21709;&#12289;&#20844;&#24179;&#24615;&#21644;&#21516;&#34892;&#35780;&#23457;&#24433;&#21709;&#30456;&#20851;&#30340;&#36825;&#20123;&#25285;&#24551;&#12290;&#36890;&#36807;&#23545;NLP&#31038;&#21306;&#30340;312&#20301;&#21442;&#19982;&#32773;&#36827;&#34892;&#35843;&#26597;&#65292;&#25105;&#20204;&#25429;&#25417;&#21040;&#19981;&#21516;&#32676;&#20307;&#20869;&#37096;&#21644;&#20043;&#38388;&#30340;&#29616;&#26377;&#65288;&#19981;&#65289;&#24179;&#31561;&#29616;&#35937;&#65292;&#21253;&#25324;&#36164;&#21382;&#12289;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#65292;&#20197;&#21450;&#23427;&#20204;&#23545;&#21516;&#34892;&#35780;&#23457;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;&#23545;&#20110;&#27599;&#20010;&#20027;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#26512;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32531;&#35299;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;Helper-Head&#8221;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#25945;&#25480;&#27880;&#24847;&#22836;&#24573;&#30053;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#26576;&#20123;&#37096;&#20998;&#26469;&#28040;&#38500;&#31163;&#32676;&#20540;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;transformer&#30340;&#21487;&#37327;&#21270;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#12289;&#39640;&#27604;&#29305;&#23485;&#24230;&#35774;&#32622;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#24314;&#27169;&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.12929</link><description>&lt;p&gt;
&#21487;&#37327;&#21270;Transformer&#65306;&#36890;&#36807;&#24110;&#21161;&#27880;&#24847;&#21147;&#22836;&#8220;&#20160;&#20040;&#20063;&#19981;&#20570;&#8221;&#21435;&#38500;&#31163;&#32676;&#20540;
&lt;/p&gt;
&lt;p&gt;
Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing. (arXiv:2306.12929v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;Helper-Head&#8221;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#25945;&#25480;&#27880;&#24847;&#22836;&#24573;&#30053;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#26576;&#20123;&#37096;&#20998;&#26469;&#28040;&#38500;&#31163;&#32676;&#20540;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;transformer&#30340;&#21487;&#37327;&#21270;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#12289;&#39640;&#27604;&#29305;&#23485;&#24230;&#35774;&#32622;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#24314;&#27169;&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#37324;&#65292;Transformer&#27169;&#22411;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#26174;&#33879;&#25512;&#36827;&#20102;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#30001;&#20110;&#20854;&#35268;&#27169;&#65292;&#36825;&#20123;&#32593;&#32476;&#30340;&#33021;&#21147;&#24050;&#32463;&#22823;&#22823;&#22686;&#24378;&#65292;&#20294;&#36825;&#26159;&#20197;&#26497;&#22823;&#30340;&#35745;&#31639;&#25104;&#26412;&#20026;&#20195;&#20215;&#30340;&#12290;&#37327;&#21270;&#26159;&#20943;&#23569;&#31070;&#32463;&#32593;&#32476;&#35745;&#31639;&#26102;&#38388;&#21644;&#23384;&#20648;&#22120;&#28040;&#32791;&#30340;&#26368;&#26377;&#25928;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#20195;transformer&#27169;&#22411;&#24448;&#24448;&#23398;&#20064;&#21040;&#20854;&#28608;&#27963;&#20013;&#30340;&#24378;&#31163;&#32676;&#20540;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#38590;&#20197;&#37327;&#21270;&#12290;&#20026;&#20445;&#25345;&#21487;&#25509;&#21463;&#30340;&#24615;&#33021;&#65292;&#36825;&#20123;&#31163;&#32676;&#20540;&#30340;&#23384;&#22312;&#38656;&#35201;&#23558;&#28608;&#27963;&#32622;&#20110;&#26356;&#39640;&#30340;&#27604;&#29305;&#23485;&#24230;&#25110;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#23383;&#26684;&#24335;&#65292;&#36827;&#34892;&#39069;&#22806;&#30340;&#24494;&#35843;&#25110;&#20854;&#20182;&#21464;&#36890;&#26041;&#27861;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#24378;&#31163;&#32676;&#20540;&#19982;&#29305;&#23450;&#27880;&#24847;&#22836;&#34892;&#20026;&#30340;&#30456;&#20851;&#24615;&#65292;&#36825;&#20123;&#22836;&#35797;&#22270;&#23398;&#20064;&#8220;&#26080;&#25805;&#20316;&#8221;&#25110;&#20165;&#20165;&#26159;&#37096;&#20998;&#27531;&#24046;&#26356;&#26032;&#12290;&#20026;&#20102;&#23454;&#29616;&#27880;&#24847;&#21147;&#22836;&#20013;&#38656;&#35201;&#30340;&#31934;&#30830;&#38646;&#20301;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31216;&#20026;&#8220;Helper-Head&#8221;&#30340;&#26041;&#27861;&#65292;&#25945;&#25480;&#27880;&#24847;&#21147;&#22836;&#24573;&#30053;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#26576;&#20123;&#37096;&#20998;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#21033;&#29992;&#36825;&#20123;&#39069;&#22806;&#20449;&#24687;&#30340;&#37327;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#20351;&#29992;&#20302;&#31934;&#24230;&#37327;&#21270;&#29978;&#33267;&#26159;&#24378;&#31163;&#32676;&#25968;&#25454;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#12289;&#39640;&#27604;&#29305;&#23485;&#24230;&#35774;&#32622;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#20004;&#20010;&#27969;&#34892;&#30340;&#35821;&#35328;&#24314;&#27169;&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer models have been widely adopted in various domains over the last years, and especially large language models have advanced the field of AI significantly. Due to their size, the capability of these networks has increased tremendously, but this has come at the cost of a significant increase in necessary compute. Quantization is one of the most effective ways to reduce the computational time and memory consumption of neural networks. Many studies have shown, however, that modern transformer models tend to learn strong outliers in their activations, making them difficult to quantize. To retain acceptable performance, the existence of these outliers requires activations to be in higher bitwidth or the use of different numeric formats, extra fine-tuning, or other workarounds. We show that strong outliers are related to very specific behavior of attention heads that try to learn a "no-op" or just a partial update of the residual. To achieve the exact zeros needed in the attention 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23481;&#26131;&#34987;&#35823;&#23548;&#65292;&#20986;&#29616;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.11167</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34987;&#35823;&#23548;&#65306;&#20351;&#29992;Only Connect Wall&#25968;&#25454;&#38598;&#25506;&#32034;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#21644;Einstellung&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11167
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23545;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23481;&#26131;&#34987;&#35823;&#23548;&#65292;&#20986;&#29616;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#20154;&#24037;&#26234;&#33021;&#35806;&#29983;&#20197;&#26469;&#65292;&#23545;&#20154;&#31867;&#20223;&#30495;&#26234;&#33021;&#30340;&#36861;&#27714;&#19968;&#30452;&#26159;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30340;&#25345;&#20037;&#35805;&#39064;&#12290;&#26368;&#26032;&#19968;&#20195;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#25216;&#26415;&#28436;&#36827;&#21644;&#26032;&#20852;&#33021;&#21147;&#23558;&#36825;&#20010;&#20027;&#39064;&#20174;&#23398;&#26415;&#30028;&#24102;&#21040;&#20102;&#25991;&#21270;&#26102;&#20195;&#12290;&#23613;&#31649;&#26368;&#36817;&#30340;NLP&#35780;&#20272;&#22522;&#20934;&#20219;&#21153;&#27979;&#35797;&#20102;&#20154;&#31867;&#20223;&#30495;&#34892;&#20026;&#30340;&#19968;&#20123;&#26041;&#38754;&#65288;&#20363;&#22914;BIG-bench&#30340;&#8220;&#31867;&#20154;&#34892;&#20026;&#8221;&#20219;&#21153;&#65289;&#65292;&#20294;&#20960;&#20046;&#27809;&#26377;&#19968;&#20010;&#20219;&#21153;&#32771;&#23519;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;&#20154;&#31867;&#30340;&#21019;&#36896;&#24615;&#38382;&#39064;&#35299;&#20915;&#26159;&#35748;&#30693;&#31070;&#32463;&#31185;&#23398;&#20013;&#30740;&#31350;&#36739;&#20026;&#28145;&#20837;&#30340;&#20027;&#39064;&#65292;&#26631;&#20934;&#21270;&#27979;&#35797;&#20027;&#35201;&#20351;&#29992;&#23558;&#32447;&#32034;&#35789;&#20043;&#38388;&#30340;&#65288;&#24322;&#26500;&#65289;&#36830;&#25509;&#33021;&#21147;&#20316;&#20026;&#21019;&#36896;&#24615;&#30340;&#24230;&#37327;&#12290;&#22312;&#36825;&#26679;&#30340;&#20219;&#21153;&#20013;&#65292;&#26263;&#31034;&#24615;&#30340;&#35823;&#23548;&#24615;&#21050;&#28608;-&#34987;&#31216;&#20026;&#8220;&#35825;&#23548;&#35823;&#35299;&#8221;&#30340;&#24178;&#25200;&#22240;&#32032;-&#36890;&#36807;&#22266;&#23450;&#25928;&#24212;&#21644;Einstellung&#33539;&#24335;&#38459;&#30861;&#20102;&#20154;&#31867;&#30340;&#34920;&#29616;&#12290;&#22312;&#35748;&#30693;&#31070;&#32463;&#31185;&#23398;&#30340;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#20107;&#20808;&#35753;&#21442;&#19982;&#32773;&#25509;&#35302;&#21040;&#26377;&#30456;&#20284;&#25340;&#20889;&#30340;&#38169;&#35823;&#22240;&#32032;&#26469;&#23454;&#39564;&#24615;&#22320;&#35825;&#23548;&#36825;&#26679;&#30340;&#22266;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some aspects of human-imitative behaviour (e.g., BIG-bench's 'human-like behavior' tasks), few, if not none, examine creative problem solving abilities. Creative problem solving in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli - distractors dubbed red herrings - impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographically similar incor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#20102;&#20004;&#20010;&#39044;&#35757;&#32451;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#22312;&#38463;&#25289;&#20271;&#35821;GEC&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#19979;&#25991;&#31532;&#19968;&#38463;&#25289;&#20271;&#35821;&#22810;&#31867;&#35821;&#27861;&#38169;&#35823;&#26816;&#27979;&#32467;&#26524;&#12290;&#25991;&#31456;&#34920;&#26126;&#65292;&#20351;&#29992;GED&#20316;&#20026;GEC&#27169;&#22411;&#30340;&#36741;&#21161;&#36755;&#20837;&#26377;&#21161;&#20110;&#25552;&#39640;&#24615;&#33021;&#65292;&#32780;&#19978;&#19979;&#25991;&#24418;&#24577;&#39044;&#22788;&#29702;&#26377;&#21161;&#20110;&#25509;&#30528;GEC&#31995;&#32479;&#65292;&#25991;&#31456;&#22312;&#20004;&#20010;&#20849;&#20139;&#20219;&#21153;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;GEC&#32467;&#26524;&#20197;&#21450;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#22522;&#20934;&#12290;</title><link>http://arxiv.org/abs/2305.14734</link><description>&lt;p&gt;
&#38463;&#25289;&#20271;&#35821;&#35821;&#27861;&#38169;&#35823;&#26816;&#27979;&#21644;&#20462;&#27491;&#30340;&#36827;&#23637;&#65306;&#19968;&#39033;&#23454;&#35777;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation. (arXiv:2305.14734v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14734
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20102;&#20004;&#20010;&#39044;&#35757;&#32451;&#30340;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#22312;&#38463;&#25289;&#20271;&#35821;GEC&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#19979;&#25991;&#31532;&#19968;&#38463;&#25289;&#20271;&#35821;&#22810;&#31867;&#35821;&#27861;&#38169;&#35823;&#26816;&#27979;&#32467;&#26524;&#12290;&#25991;&#31456;&#34920;&#26126;&#65292;&#20351;&#29992;GED&#20316;&#20026;GEC&#27169;&#22411;&#30340;&#36741;&#21161;&#36755;&#20837;&#26377;&#21161;&#20110;&#25552;&#39640;&#24615;&#33021;&#65292;&#32780;&#19978;&#19979;&#25991;&#24418;&#24577;&#39044;&#22788;&#29702;&#26377;&#21161;&#20110;&#25509;&#30528;GEC&#31995;&#32479;&#65292;&#25991;&#31456;&#22312;&#20004;&#20010;&#20849;&#20139;&#20219;&#21153;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;GEC&#32467;&#26524;&#20197;&#21450;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#27861;&#38169;&#35823;&#32416;&#27491;(GEC)&#26159;&#19968;&#20010;&#32463;&#36807;&#28145;&#20837;&#30740;&#31350;&#30340;&#33521;&#35821;&#38382;&#39064;&#65292;&#22312;&#35768;&#22810;&#24050;&#26377;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#31232;&#32570;&#21644;&#35821;&#35328;&#22797;&#26434;&#24615;&#31561;&#25361;&#25112;&#65292;&#23545;&#24418;&#24577;&#20016;&#23500;&#30340;&#35821;&#35328;&#36827;&#34892;GEC&#30740;&#31350;&#30340;&#38480;&#21046;&#36739;&#22810;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#26032;&#24320;&#21457;&#30340;&#22522;&#20110;Transformer&#39044;&#35757;&#32451;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#65292;&#39318;&#27425;&#22312;&#38463;&#25289;&#20271;&#35821;GEC&#20013;&#33719;&#24471;&#20102;&#32467;&#26524;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#22810;&#31867;&#38463;&#25289;&#20271;&#35821;&#35821;&#27861;&#38169;&#35823;&#26816;&#27979;(GED)&#20219;&#21153;&#65292;&#24182;&#39318;&#27425;&#22312;&#22810;&#31867;&#38463;&#25289;&#20271;&#35821;GED&#19978;&#33719;&#24471;&#20102;&#32467;&#26524;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36328;&#36234;&#19981;&#21516;&#31867;&#22411;&#30340;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;GED&#20449;&#24687;&#20316;&#20026;&#36741;&#21161;&#36755;&#20837;&#30340;GEC&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;GEC&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#24418;&#24577;&#39044;&#22788;&#29702;&#22312;&#24110;&#21161;GEC&#31995;&#32479;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#20004;&#20010;&#38463;&#25289;&#20271;&#35821;GEC&#20849;&#20139;&#20219;&#21153;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#26032;&#32467;&#26524;&#65292;&#24182;&#22312;&#26032;&#21019;&#24314;&#30340;&#25968;&#25454;&#38598;&#19978;&#24314;&#31435;&#20102;&#19968;&#20010;&#24378;&#26377;&#21147;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Grammatical error correction (GEC) is a well-explored problem in English with many existing models and datasets. However, research on GEC in morphologically rich languages has been limited due to challenges such as data scarcity and language complexity. In this paper, we present the first results on Arabic GEC by using two newly developed Transformer-based pretrained sequence-to-sequence models. We address the task of multi-class Arabic grammatical error detection (GED) and present the first results on multi-class Arabic GED. We show that using GED information as auxiliary input in GEC models improves GEC performance across three datasets spanning different genres. Moreover, we also investigate the use of contextual morphological preprocessing in aiding GEC systems. Our models achieve state-of-the-art results on two Arabic GEC shared tasks datasets and establish a strong benchmark on a newly created dataset.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521; VideoCOT&#65292;&#21033;&#29992;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#33021;&#21147;&#65292;&#20197;&#22686;&#24378;&#35270;&#39057;&#25512;&#29702;&#65292;&#21516;&#26102;&#20943;&#23569;&#22788;&#29702;&#25968;&#30334;&#25110;&#25968;&#21315;&#24103;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#22312;VIP&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#22522;&#20110;&#21508;&#31181;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20351;&#29992;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;VideoCOT&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.13903</link><description>&lt;p&gt;
&#35753;&#25105;&#20204;&#36880;&#24103;&#24605;&#32771;&#65306;&#20351;&#29992;&#35270;&#39057;&#25554;&#24103;&#21644;&#39044;&#27979;&#35780;&#20272;&#35270;&#39057;&#24605;&#32500;&#38142;
&lt;/p&gt;
&lt;p&gt;
Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction. (arXiv:2305.13903v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13903
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521; VideoCOT&#65292;&#21033;&#29992;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#33021;&#21147;&#65292;&#20197;&#22686;&#24378;&#35270;&#39057;&#25512;&#29702;&#65292;&#21516;&#26102;&#20943;&#23569;&#22788;&#29702;&#25968;&#30334;&#25110;&#25968;&#21315;&#24103;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#22312;VIP&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#22522;&#20110;&#21508;&#31181;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20351;&#29992;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;VideoCOT&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;2023&#24180;&#26500;&#25104;&#20102;&#25152;&#26377;&#20114;&#32852;&#32593;&#27969;&#37327;&#30340;65&#65285;&#65292;&#20294;&#35270;&#39057;&#20869;&#23481;&#22312;&#29983;&#25104;AI&#30740;&#31350;&#20013;&#21364;&#34987;&#20302;&#20272;&#20102;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26368;&#36817;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#24050;&#36234;&#26469;&#36234;&#22810;&#22320;&#19982;&#35270;&#35273;&#27169;&#24577;&#34701;&#21512;&#12290;&#23558;&#35270;&#39057;&#19982;LLM&#25972;&#21512;&#26159;&#19979;&#19968;&#27493;&#33258;&#28982;&#30340;&#21457;&#23637;&#26041;&#21521;&#65292;&#37027;&#20040;&#36825;&#20010;&#40511;&#27807;&#22914;&#20309;&#34987;&#22635;&#34917;&#65311;&#20026;&#20102;&#25512;&#36827;&#35270;&#39057;&#25512;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#21363;&#22522;&#20110;&#35270;&#39057;&#20851;&#38190;&#24103;&#30340;VideoCOT&#65292;&#23427;&#21033;&#29992;&#20102;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;&#33021;&#21147;&#65292;&#20197;&#22686;&#24378;&#35270;&#39057;&#25512;&#29702;&#65292;&#21516;&#26102;&#20943;&#23569;&#22788;&#29702;&#25968;&#30334;&#25110;&#25968;&#21315;&#24103;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;VIP&#65292;&#19968;&#31181;&#21487;&#20197;&#29992;&#26469;&#35780;&#20272;VideoCOT&#30340;&#25512;&#26029;&#26102;&#38388;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;1&#65289;&#21508;&#31181;&#24102;&#26377;&#20851;&#38190;&#24103;&#30340;&#30495;&#23454;&#29983;&#27963;&#35270;&#39057;&#20197;&#21450;&#30456;&#24212;&#30340;&#38750;&#32467;&#26500;&#21270;&#21644;&#32467;&#26500;&#21270;&#22330;&#26223;&#25551;&#36848;&#65292;2&#65289;&#20004;&#20010;&#26032;&#30340;&#35270;&#39057;&#25512;&#29702;&#20219;&#21153;&#65306;&#35270;&#39057;&#25554;&#24103;&#21644;&#22330;&#26223;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;VIP&#19978;&#23545;&#21508;&#31181;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20351;&#29992;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;VideoCOT&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite constituting 65% of all internet traffic in 2023, video content is underrepresented in generative AI research. Meanwhile, recent large language models (LLMs) have become increasingly integrated with capabilities in the visual modality. Integrating video with LLMs is a natural next step, so how can this gap be bridged? To advance video reasoning, we propose a new research direction of VideoCOT on video keyframes, which leverages the multimodal generative abilities of vision-language models to enhance video reasoning while reducing the computational complexity of processing hundreds or thousands of frames. We introduce VIP, an inference-time dataset that can be used to evaluate VideoCOT, containing 1) a variety of real-life videos with keyframes and corresponding unstructured and structured scene descriptions, and 2) two new video reasoning tasks: video infilling and scene prediction. We benchmark various vision-language models on VIP, demonstrating the potential to use vision-la
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#33889;&#33796;&#29273;&#35821;&#36827;&#34892;&#21333;&#35821;&#35328;&#39044;&#35757;&#32451;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35268;&#27169;&#21512;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#24182;&#33021;&#22815;&#22312;&#19968;&#31995;&#21015;&#33889;&#33796;&#29273;&#35821;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20197;&#33521;&#35821;&#20026;&#20013;&#24515;&#21644;&#22810;&#35821;&#35328;&#30340;&#23545;&#25163;&#65292;&#26368;&#22909;&#30340;&#27169;&#22411;&#30340;&#34920;&#29616;&#19982;GPT-3.5-turbo&#25345;&#24179;&#12290;</title><link>http://arxiv.org/abs/2304.07880</link><description>&lt;p&gt;
Sabi&#225;: &#33889;&#33796;&#29273;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Sabi\'a: Portuguese Large Language Models. (arXiv:2304.07880v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07880
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#33889;&#33796;&#29273;&#35821;&#36827;&#34892;&#21333;&#35821;&#35328;&#39044;&#35757;&#32451;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35268;&#27169;&#21512;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#24182;&#33021;&#22815;&#22312;&#19968;&#31995;&#21015;&#33889;&#33796;&#29273;&#35821;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20197;&#33521;&#35821;&#20026;&#20013;&#24515;&#21644;&#22810;&#35821;&#35328;&#30340;&#23545;&#25163;&#65292;&#26368;&#22909;&#30340;&#27169;&#22411;&#30340;&#34920;&#29616;&#19982;GPT-3.5-turbo&#25345;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#33021;&#21147;&#30340;&#19981;&#26029;&#25552;&#39640;&#65292;&#8221;&#19968;&#20992;&#20999;&#8220;&#30340;&#27169;&#22411;&#20173;&#28982;&#26159;&#20027;&#27969;&#12290;&#23588;&#20854;&#26159;&#32771;&#34385;&#21040;&#20840;&#29699;&#20351;&#29992;&#30340;&#35821;&#35328;&#25968;&#37327;&#38750;&#24120;&#24222;&#22823;&#65292;&#24182;&#19988;&#20854;&#20013;&#24456;&#22810;&#35821;&#35328;&#37117;&#26159;&#20302;&#36164;&#28304;&#35821;&#35328;&#65292;&#20027;&#35201;&#30340;&#20570;&#27861;&#26159;&#23545;&#22810;&#31181;&#35821;&#35328;&#36827;&#34892;&#39044;&#35757;&#32451;&#12290;&#26412;&#25991;&#23545;&#36825;&#31181;&#20570;&#27861;&#25552;&#20986;&#20102;&#36136;&#30097;&#65292;&#35777;&#26126;&#20102;&#38024;&#23545;&#30446;&#26631;&#35821;&#35328;&#36827;&#34892;&#21333;&#35821;&#35328;&#39044;&#35757;&#32451;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#22823;&#35268;&#27169;&#21512;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;&#29992;3%&#25110;&#26356;&#23569;&#30340;&#21407;&#22987;&#39044;&#35757;&#32451;&#39044;&#31639;&#22312;&#33889;&#33796;&#29273;&#35821;&#25991;&#26412;&#19978;&#36827;&#19968;&#27493;&#39044;&#35757;&#32451;GPT-J&#21644;LLaMA&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;Poeta&#65288;&#19968;&#22871;&#30001;14&#20010;&#33889;&#33796;&#29273;&#35821;&#25968;&#25454;&#38598;&#32452;&#25104;&#30340;&#22871;&#20214;&#65289;&#19978;&#36827;&#34892;&#20102;&#23569;&#26679;&#26412;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#34920;&#29616;&#19978;&#36828;&#20248;&#20110;&#20197;&#33521;&#35821;&#20026;&#20013;&#24515;&#30340;&#21644;&#22810;&#35821;&#35328;&#30340;&#23545;&#25163;&#12290;&#25105;&#20204;&#30340;&#26368;&#20339;&#27169;&#22411;Sabi&#225;-65B&#30340;&#34920;&#29616;&#19982;GPT-3.5-turbo&#25345;&#24179;&#12290;&#25105;&#20204;&#22312;&#30446;&#26631;&#35821;&#35328;&#20013;&#24050;&#32463;&#35774;&#24819;&#20102;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#32463;&#36807;&#32763;&#35793;&#30340;&#25968;&#25454;&#38598;&#19978;&#37117;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the capabilities of language models continue to advance, it is conceivable that "one-size-fits-all" model will remain as the main paradigm. For instance, given the vast number of languages worldwide, many of which are low-resource, the prevalent practice is to pretrain a single model on multiple languages. In this paper, we add to the growing body of evidence that challenges this practice, demonstrating that monolingual pretraining on the target language significantly improves models already extensively trained on diverse corpora. More specifically, we further pretrain GPT-J and LLaMA models on Portuguese texts using 3% or less of their original pretraining budget. Few-shot evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models outperform English-centric and multilingual counterparts by a significant margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By evaluating on datasets originally conceived in the target language as well as transl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MLRegTest&#30340;&#26032;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#21253;&#21547;&#20102;&#26469;&#33258;1,800&#20010;&#27491;&#21017;&#35821;&#35328;&#30340;&#25968;&#25454;&#38598;&#12290;&#35813;&#27979;&#35797;&#26681;&#25454;&#36923;&#36753;&#22797;&#26434;&#24230;&#21644;&#36923;&#36753;&#25991;&#23383;&#31181;&#31867;&#32452;&#32455;&#35821;&#35328;&#65292;&#24182;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#20102;&#35299;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22312;&#23398;&#20064;&#19981;&#21516;&#31181;&#31867;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.07687</link><description>&lt;p&gt;
MLRegTest&#65306;&#26426;&#22120;&#23398;&#20064;&#27491;&#21017;&#35821;&#35328;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
MLRegTest: A Benchmark for the Machine Learning of Regular Languages. (arXiv:2304.07687v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MLRegTest&#30340;&#26032;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#21253;&#21547;&#20102;&#26469;&#33258;1,800&#20010;&#27491;&#21017;&#35821;&#35328;&#30340;&#25968;&#25454;&#38598;&#12290;&#35813;&#27979;&#35797;&#26681;&#25454;&#36923;&#36753;&#22797;&#26434;&#24230;&#21644;&#36923;&#36753;&#25991;&#23383;&#31181;&#31867;&#32452;&#32455;&#35821;&#35328;&#65292;&#24182;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#20102;&#35299;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22312;&#23398;&#20064;&#19981;&#21516;&#31181;&#31867;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23545;&#24050;&#30693;&#20998;&#31867;&#22120;&#30340;&#23398;&#20064;&#33021;&#21147;&#20801;&#35768;&#32454;&#33268;&#22320;&#26816;&#26597;&#23427;&#20204;&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#27169;&#24335;&#65292;&#24182;&#22312;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#26410;&#30693;&#20998;&#31867;&#22120;&#30340;&#23398;&#20064;&#26102;&#24314;&#31435;&#20449;&#24515;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;MLRegTest&#30340;&#26032;&#30340;&#24207;&#21015;&#20998;&#31867;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#21547;&#26469;&#33258;1,800&#20010;&#27491;&#21017;&#35821;&#35328;&#30340;&#35757;&#32451;&#12289;&#24320;&#21457;&#21644;&#27979;&#35797;&#38598;&#12290;&#19981;&#21516;&#31867;&#22411;&#30340;&#24418;&#24335;&#35821;&#35328;&#20195;&#34920;&#30528;&#19981;&#21516;&#31181;&#31867;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#65292;&#24182;&#27491;&#30830;&#22320;&#35782;&#21035;&#24207;&#21015;&#20013;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#26159;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#25104;&#21151;&#27867;&#21270;&#30340;&#24050;&#30693;&#25361;&#25112;&#12290;MLRegTest&#26681;&#25454;&#23427;&#20204;&#30340;&#36923;&#36753;&#22797;&#26434;&#24230;&#65288;&#21333;&#35843;&#20108;&#38454;&#65292;&#19968;&#38454;&#65292;&#21629;&#39064;&#25110;&#21333;&#39033;&#24335;&#34920;&#36798;&#24335;&#65289;&#21644;&#36923;&#36753;&#25991;&#23383;&#30340;&#31181;&#31867;&#65288;&#23383;&#31526;&#20018;&#65292;&#23450;&#32423;&#23383;&#31526;&#20018;&#65292;&#23376;&#24207;&#21015;&#25110;&#20004;&#32773;&#30340;&#32452;&#21512;&#65289;&#32452;&#32455;&#20854;&#35821;&#35328;&#12290;&#36923;&#36753;&#22797;&#26434;&#24230;&#21644;&#25991;&#23383;&#30340;&#36873;&#25321;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#26041;&#27861;&#26469;&#29702;&#35299;&#19981;&#21516;&#31181;&#31867;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#21644;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#22312;&#22788;&#29702;&#23427;&#20204;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating machine learning (ML) systems on their ability to learn known classifiers allows fine-grained examination of the patterns they can learn, which builds confidence when they are applied to the learning of unknown classifiers. This article presents a new benchmark for ML systems on sequence classification called MLRegTest, which contains training, development, and test sets from 1,800 regular languages.  Different kinds of formal languages represent different kinds of long-distance dependencies, and correctly identifying long-distance dependencies in sequences is a known challenge for ML systems to generalize successfully. MLRegTest organizes its languages according to their logical complexity (monadic second order, first order, propositional, or monomial expressions) and the kind of logical literals (string, tier-string, subsequence, or combinations thereof). The logical complexity and choice of literal provides a systematic way to understand different kinds of long-distance d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20154;&#24037;&#21644;&#26426;&#22120;&#23457;&#26680;&#21592;&#30340;&#20849;&#24773;&#20882;&#29359;&#21644;&#22122;&#22768;&#23457;&#35745;&#30740;&#31350;&#20102;&#20882;&#29359;&#24615;&#35328;&#35770;&#26816;&#27979;&#20013;&#30340;&#24046;&#24322;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23457;&#26680;&#21592;&#20043;&#38388;&#23384;&#22312;&#24191;&#27867;&#30340;&#20998;&#27495;&#65292;&#24182;&#19988;&#20154;&#24037;&#23457;&#26680;&#21592;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20998;&#31867;&#22120;&#26080;&#27861;&#39044;&#27979;&#20854;&#20182;&#23457;&#26680;&#21592;&#30340;&#22238;&#24212;&#12290;&#36825;&#23545;&#20110;&#20869;&#23481;&#23457;&#26680;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2301.12534</link><description>&lt;p&gt;
&#20154;&#24037;&#21644;&#26426;&#22120;&#20851;&#20110;&#20160;&#20040;&#26159;&#20882;&#29359;&#23384;&#22312;&#36739;&#22823;&#20998;&#27495;&#30340;&#20849;&#24773;&#20882;&#29359;&#21644;&#22122;&#22768;&#23457;&#35745;&#65306;&#32479;&#19968;&#20027;&#35266;&#20882;&#29359;&#30340;&#20154;&#31867;&#21644;&#26426;&#22120;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive. (arXiv:2301.12534v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20154;&#24037;&#21644;&#26426;&#22120;&#23457;&#26680;&#21592;&#30340;&#20849;&#24773;&#20882;&#29359;&#21644;&#22122;&#22768;&#23457;&#35745;&#30740;&#31350;&#20102;&#20882;&#29359;&#24615;&#35328;&#35770;&#26816;&#27979;&#20013;&#30340;&#24046;&#24322;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23457;&#26680;&#21592;&#20043;&#38388;&#23384;&#22312;&#24191;&#27867;&#30340;&#20998;&#27495;&#65292;&#24182;&#19988;&#20154;&#24037;&#23457;&#26680;&#21592;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20998;&#31867;&#22120;&#26080;&#27861;&#39044;&#27979;&#20854;&#20182;&#23457;&#26680;&#21592;&#30340;&#22238;&#24212;&#12290;&#36825;&#23545;&#20110;&#20869;&#23481;&#23457;&#26680;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20882;&#29359;&#24615;&#35328;&#35770;&#26816;&#27979;&#26159;&#20869;&#23481;&#23457;&#26680;&#30340;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#20160;&#20040;&#26159;&#20882;&#29359;&#24615;&#30340;&#21487;&#20197;&#26159;&#39640;&#24230;&#20027;&#35266;&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#28041;&#21450;&#21040;&#29616;&#23454;&#19990;&#30028;&#31038;&#20132;&#32593;&#31449;&#25919;&#27835;&#35328;&#35770;&#26102;&#65292;&#20154;&#24037;&#21644;&#26426;&#22120;&#23457;&#26680;&#21592;&#23545;&#20110;&#20160;&#20040;&#26159;&#20882;&#29359;&#24615;&#30340;&#23384;&#22312;&#20998;&#27495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65288;1&#65289;&#23457;&#26680;&#21592;&#20043;&#38388;&#65288;&#21253;&#25324;&#20154;&#24037;&#21644;&#26426;&#22120;&#65289;&#23384;&#22312;&#24191;&#27867;&#20998;&#27495;&#65307;&#21644;&#65288;2&#65289;&#20154;&#24037;&#23457;&#26680;&#21592;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20998;&#31867;&#22120;&#26080;&#27861;&#39044;&#27979;&#20854;&#20182;&#23457;&#26680;&#21592;&#22522;&#20110;&#20182;&#20204;&#30340;&#25919;&#27835;&#20542;&#21521;&#22914;&#20309;&#22238;&#24212;&#12290;&#23545;&#20110;&#65288;1&#65289;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#21069;&#25152;&#26410;&#26377;&#35268;&#27169;&#30340;&#22122;&#22768;&#23457;&#35745;&#65292;&#32467;&#21512;&#20102;&#26426;&#22120;&#21644;&#20154;&#24037;&#22238;&#31572;&#12290;&#23545;&#20110;&#65288;2&#65289;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#39318;&#21019;&#30340;&#20849;&#24773;&#20882;&#29359;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#22122;&#22768;&#23457;&#35745;&#25581;&#31034;&#20102;&#19981;&#21516;&#26426;&#22120;&#23457;&#26680;&#21592;&#20043;&#38388;&#30340;&#23457;&#26680;&#32467;&#26524;&#24046;&#24322;&#24456;&#22823;&#12290;&#25105;&#20204;&#19982;&#20154;&#24037;&#23457;&#26680;&#21592;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25919;&#27835;&#20542;&#21521;&#32467;&#21512;&#25935;&#24863;&#38382;&#39064;&#20250;&#24433;&#21709;&#21040;&#19968;&#23545;&#19968;&#30340;&#20882;&#29359;&#65292;&#20197;&#21450;&#20849;&#24773;&#20882;&#29359;&#12290;&#25968;&#25454;&#38598;&#21487;&#36890;&#36807;https://github.com/Homan-Lab/voic&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offensive speech detection is a key component of content moderation. However, what is offensive can be highly subjective. This paper investigates how machine and human moderators disagree on what is offensive when it comes to real-world social web political discourse. We show that (1) there is extensive disagreement among the moderators (humans and machines); and (2) human and large-language-model classifiers are unable to predict how other human raters will respond, based on their political leanings. For (1), we conduct a noise audit at an unprecedented scale that combines both machine and human responses. For (2), we introduce a first-of-its-kind dataset of vicarious offense. Our noise audit reveals that moderation outcomes vary wildly across different machine moderators. Our experiments with human moderators suggest that political leanings combined with sensitive issues affect both first-person and vicarious offense. The dataset is available through https://github.com/Homan-Lab/voic
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20154;&#31867;&#30699;&#27491;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26631;&#27880;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#65292;&#24182;&#23558;&#20854;&#27880;&#20837;&#33267;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#25104;&#21151;&#23558;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#20102;1.7&#20010;&#30334;&#20998;&#28857;&#12290;</title><link>http://arxiv.org/abs/2102.00225</link><description>&lt;p&gt;
&#20174;&#20154;&#31867;&#30340;&#32416;&#38169;&#20013;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning From How Humans Correct. (arXiv:2102.00225v14 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.00225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20154;&#31867;&#30699;&#27491;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#26631;&#27880;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#65292;&#24182;&#23558;&#20854;&#27880;&#20837;&#33267;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#65292;&#25104;&#21151;&#23558;&#25991;&#26412;&#20998;&#31867;&#20934;&#30830;&#24230;&#25552;&#21319;&#20102;1.7&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#25163;&#21160;&#26631;&#27880;&#30340;&#25968;&#25454;&#20013;&#23384;&#22312;&#19968;&#23450;&#25968;&#37327;&#30340;&#22122;&#22768;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#22122;&#22768;&#25968;&#25454;&#24182;&#25163;&#21160;&#37325;&#26032;&#26631;&#27880;&#23427;&#20204;&#65292;&#21516;&#26102;&#25910;&#38598;&#32416;&#38169;&#20449;&#24687;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#20154;&#31867;&#32416;&#38169;&#20449;&#24687;&#34701;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#20154;&#31867;&#30693;&#36947;&#22914;&#20309;&#32416;&#27491;&#22122;&#22768;&#25968;&#25454;&#65292;&#22240;&#27492;&#32416;&#38169;&#20449;&#24687;&#21487;&#20197;&#27880;&#20837;&#21040;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#22312;&#33258;&#24049;&#30340;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#25163;&#21160;&#26631;&#27880;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#37325;&#26032;&#26631;&#27880;&#20102;&#25105;&#20204;&#25968;&#25454;&#38598;&#20013;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#20197;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#24037;&#19994;&#24212;&#29992;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20998;&#31867;&#20934;&#30830;&#24230;&#20174;91.7%&#25552;&#21319;&#21040;92.5%&#12290;91.7%&#30340;&#20934;&#30830;&#24230;&#26159;&#22312;&#20462;&#27491;&#21518;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#65292;&#23427;&#23558;&#22522;&#32447;&#20934;&#30830;&#24230;&#20174;83.3%&#25552;&#21319;&#21040;91.7%&#12290;
&lt;/p&gt;
&lt;p&gt;
In industry NLP application, our manually labeled data has a certain number of noisy data. We present a simple method to find the noisy data and re-label them manually, meanwhile we collect the correction information. Then we present novel method to incorporate the human correction information into deep learning model. Human know how to correct noisy data. So the correction information can be inject into deep learning model. We do the experiment on our own text classification dataset, which is manually labeled, because we re-label the noisy data in our dataset for our industry application. The experiment result shows that our method improve the classification accuracy from 91.7% to 92.5%. The 91.7% accuracy is trained on the corrected dataset, which improve the baseline from 83.3% to 91.7%.
&lt;/p&gt;</description></item></channel></rss>