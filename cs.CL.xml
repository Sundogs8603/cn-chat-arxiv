<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#29616;&#26377;&#30340;&#25512;&#29305;&#24773;&#24863;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#22810;&#27169;&#24577;&#26684;&#24335;&#65292;&#24182;&#36827;&#34892;&#22522;&#20934;&#23454;&#39564;&#65292;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#20351;&#29992;&#24773;&#24863;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25991;&#26412;&#32534;&#30721;&#22120;&#26102;&#65292;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>https://arxiv.org/abs/2404.01753</link><description>&lt;p&gt;
M2SA: &#22810;&#27169;&#24577;&#21644;&#22810;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#25512;&#25991;&#24773;&#24863;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#29616;&#26377;&#30340;&#25512;&#29305;&#24773;&#24863;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#22810;&#27169;&#24577;&#26684;&#24335;&#65292;&#24182;&#36827;&#34892;&#22522;&#20934;&#23454;&#39564;&#65292;&#21457;&#29616;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#20351;&#29992;&#24773;&#24863;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25991;&#26412;&#32534;&#30721;&#22120;&#26102;&#65292;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38754;&#21521;&#23398;&#20064;&#21508;&#31181;&#25968;&#25454;&#31867;&#22411;&#30340;&#22810;&#27169;&#24577;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21463;&#21040;&#20102;&#37325;&#35270;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#20998;&#26512;&#22810;&#27169;&#24577;&#20219;&#21153;&#26102;&#38656;&#35201;&#26356;&#28165;&#26224;&#30340;&#29702;&#35299;&#12290;&#23613;&#31649;&#20808;&#21069;&#20851;&#20110;&#25512;&#25991;&#24773;&#24863;&#20998;&#26512;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#19978;&#65292;&#20294;&#26412;&#25991;&#36890;&#36807;&#31616;&#21333;&#30340;&#25972;&#29702;&#36807;&#31243;&#23558;&#29616;&#26377;&#30340;&#25991;&#26412;&#25512;&#29305;&#24773;&#24863;&#25968;&#25454;&#38598;&#36716;&#25442;&#20026;&#22810;&#27169;&#24577;&#26684;&#24335;&#65292;&#20174;&#32780;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#30740;&#31350;&#31038;&#21306;&#20869;&#19982;&#24773;&#24863;&#30456;&#20851;&#30340;&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#22686;&#24378;&#25968;&#25454;&#38598;&#36827;&#34892;&#22522;&#20934;&#23454;&#39564;&#24182;&#25253;&#21578;&#20102;&#30740;&#31350;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#27604;&#36739;&#21333;&#27169;&#24577;&#21644;&#22810;&#27169;&#24577;&#37197;&#32622;&#26102;&#65292;&#20351;&#29992;&#24773;&#24863;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25991;&#26412;&#32534;&#30721;&#22120;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01753v1 Announce Type: new  Abstract: In recent years, multimodal natural language processing, aimed at learning from diverse data types, has garnered significant attention. However, there needs to be more clarity when it comes to analysing multimodal tasks in multi-lingual contexts. While prior studies on sentiment analysis of tweets have predominantly focused on the English language, this paper addresses this gap by transforming an existing textual Twitter sentiment dataset into a multimodal format through a straightforward curation process. Our work opens up new avenues for sentiment-related research within the research community. Additionally, we conduct baseline experiments utilising this augmented dataset and report the findings. Notably, our evaluations reveal that when comparing unimodal and multimodal configurations, using a sentiment-tuned large language model as a text encoder performs exceptionally well.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21463;&#31070;&#32463;&#31995;&#32479;&#21551;&#21457;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#30340;&#31232;&#30095;&#26041;&#27861;&#65292;&#25506;&#32034;&#31867;&#20284;&#20110;&#29983;&#29289;&#32593;&#32476;&#30340;&#26426;&#21046;&#65292;&#23637;&#31034;&#20102;&#23545;&#21508;&#31181; NLP &#20219;&#21153;&#37117;&#34920;&#29616;&#20986;&#33394;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;-&#19981;&#21487;&#30693;&#31232;&#30095;&#24615;&#26041;&#27861;</title><link>https://arxiv.org/abs/2404.01306</link><description>&lt;p&gt;
NeuroPrune&#65306;&#19968;&#31181;&#21463;&#31070;&#32463;&#31995;&#32479;&#21551;&#21457;&#30340;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25299;&#25169;&#31232;&#30095;&#35757;&#32451;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21463;&#31070;&#32463;&#31995;&#32479;&#21551;&#21457;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#30340;&#31232;&#30095;&#26041;&#27861;&#65292;&#25506;&#32034;&#31867;&#20284;&#20110;&#29983;&#29289;&#32593;&#32476;&#30340;&#26426;&#21046;&#65292;&#23637;&#31034;&#20102;&#23545;&#21508;&#31181; NLP &#20219;&#21153;&#37117;&#34920;&#29616;&#20986;&#33394;&#21644;&#39640;&#25928;&#30340;&#27169;&#22411;-&#19981;&#21487;&#30693;&#31232;&#30095;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110; Transformer &#30340;&#35821;&#35328;&#27169;&#22411;&#30001;&#20110;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#20986;&#33394;&#24615;&#33021;&#32780;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#21464;&#24471;&#26222;&#36941;&#12290;&#28982;&#32780;&#65292;&#26114;&#36149;&#30340;&#35757;&#32451;&#20197;&#21450;&#25512;&#29702;&#20173;&#28982;&#26159;&#23427;&#20204;&#24191;&#27867;&#36866;&#29992;&#24615;&#30340;&#19968;&#20010;&#37325;&#35201;&#38556;&#30861;&#12290;&#22312;&#27169;&#22411;&#26550;&#26500;&#30340;&#21508;&#20010;&#23618;&#27425;&#24378;&#21046;&#24341;&#20837;&#31232;&#30095;&#24615;&#24050;&#34987;&#35777;&#26126;&#26377;&#21161;&#20110;&#35299;&#20915;&#25193;&#23637;&#24615;&#21644;&#25928;&#29575;&#38382;&#39064;&#65292;&#20294;&#31232;&#30095;&#24615;&#23545;&#32593;&#32476;&#25299;&#25169;&#30340;&#24433;&#21709;&#20173;&#23384;&#22312;&#26029;&#35010;&#12290;&#21463;&#22823;&#33041;&#31070;&#32463;&#32593;&#32476;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#32593;&#32476;&#25299;&#25169;&#30340;&#35270;&#35282;&#25506;&#32034;&#31232;&#30095;&#24615;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#22312;&#29983;&#29289;&#32593;&#32476;&#20013;&#35266;&#23519;&#21040;&#30340;&#26426;&#21046;&#65292;&#22914;&#20248;&#20808;&#38468;&#30528;&#21644;&#20887;&#20313;&#31361;&#35302;&#20462;&#21098;&#65292;&#24182;&#23637;&#31034;&#20102;&#22522;&#20110;&#21407;&#21017;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#31232;&#30095;&#24615;&#26041;&#27861;&#22312;&#36328;&#36234;&#20998;&#31867;&#65288;&#22914;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#65289;&#21644;&#29983;&#25104;&#65288;&#25688;&#35201;&#12289;&#26426;&#22120;&#32763;&#35793;&#65289;&#30340;&#21508;&#31181; NLP &#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#19988;&#39640;&#25928;&#65292;&#23613;&#31649; o
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01306v1 Announce Type: cross  Abstract: Transformer-based Language Models have become ubiquitous in Natural Language Processing (NLP) due to their impressive performance on various tasks. However, expensive training as well as inference remains a significant impediment to their widespread applicability. While enforcing sparsity at various levels of the model architecture has found promise in addressing scaling and efficiency issues, there remains a disconnect between how sparsity affects network topology. Inspired by brain neuronal networks, we explore sparsity approaches through the lens of network topology. Specifically, we exploit mechanisms seen in biological networks, such as preferential attachment and redundant synapse pruning, and show that principled, model-agnostic sparsity approaches are performant and efficient across diverse NLP tasks, spanning both classification (such as natural language inference) and generation (summarization, machine translation), despite o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#26469;&#23454;&#29616;&#35821;&#35328;&#26657;&#20934;&#65292;&#21487;&#20197;&#20351;&#29992;&#25143;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.00474</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#30340;&#35821;&#35328;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Linguistic Calibration of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00474
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#29983;&#25104;&#26469;&#23454;&#29616;&#35821;&#35328;&#26657;&#20934;&#65292;&#21487;&#20197;&#20351;&#29992;&#25143;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#21487;&#33021;&#20250;&#22312;&#33258;&#20449;&#24187;&#35273;&#26102;&#23548;&#33268;&#29992;&#25143;&#20570;&#20986;&#27425;&#20248;&#21270;&#30340;&#19979;&#28216;&#20915;&#31574;&#12290;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#21475;&#22836;&#20256;&#36798;&#20854;&#20027;&#24352;&#27491;&#30830;&#27010;&#29575;&#21487;&#20197;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#27169;&#22411;&#26080;&#27861;&#29983;&#25104;&#20855;&#26377;&#26657;&#20934;&#32622;&#20449;&#24230;&#22768;&#26126;&#30340;&#25991;&#26412;&#12290;&#25105;&#20204;&#36890;&#36807;&#20915;&#31574;&#35282;&#24230;&#65292;&#20026;&#38271;&#31687;&#29983;&#25104;&#24418;&#24335;&#30340;&#35821;&#35328;&#26657;&#20934;&#24418;&#24335;&#21270;&#23450;&#20041;&#65306;&#22914;&#26524;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#20351;&#20854;&#29992;&#25143;&#33021;&#22815;&#20570;&#20986;&#26657;&#20934;&#27010;&#29575;&#39044;&#27979;&#65292;&#21017;&#35813;&#27169;&#22411;&#26159;&#35821;&#35328;&#19978;&#26657;&#20934;&#30340;&#12290;&#36825;&#20010;&#23450;&#20041;&#20351;&#24471;&#19968;&#20010;&#35757;&#32451;&#26694;&#26550;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;&#19968;&#20010;&#30417;&#30563;&#24494;&#35843;&#27493;&#39588;&#24341;&#23548;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#21457;&#20986;&#24102;&#26377;&#32622;&#20449;&#24230;&#22768;&#26126;&#30340;&#38271;&#31687;&#29983;&#25104;&#65292;&#35832;&#22914;&#8220;&#25105;&#20272;&#35745;&#26377;30%&#30340;&#26426;&#20250;&#8230;&#8221;&#25110;&#8220;&#25105;&#30830;&#20449;&#8230;&#8221;&#65292;&#28982;&#21518;&#26159;&#19968;&#20010;&#24378;&#21270;&#23398;&#20064;&#27493;&#39588;&#65292;&#22870;&#21169;&#20351;&#29992;&#25143;&#33021;&#22815;&#23545;&#30456;&#20851;&#38382;&#39064;&#25552;&#20379;&#26657;&#20934;&#31572;&#26696;&#30340;&#29983;&#25104;&#12290;&#25105;&#20204;&#23545;Llama 2 7B &#36827;&#34892;&#35821;&#35328;&#26657;&#20934;&#65292;&#24182;&#21457;&#29616;&#22312;&#33258;&#21160;&#21270;&#21644;&#20154;&#31867;&#27979;&#35797;&#20013;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00474v1 Announce Type: cross  Abstract: Language models (LMs) may lead their users to make suboptimal downstream decisions when they confidently hallucinate. This issue can be mitigated by having the LM verbally convey the probability that its claims are correct, but existing models cannot produce text with calibrated confidence statements. Through the lens of decision-making, we formalize linguistic calibration for long-form generations: an LM is linguistically calibrated if its generations enable its users to make calibrated probabilistic predictions. This definition enables a training framework where a supervised finetuning step bootstraps an LM to emit long-form generations with confidence statements such as "I estimate a 30% chance of..." or "I am certain that...", followed by a reinforcement learning step which rewards generations that enable a user to provide calibrated answers to related questions. We linguistically calibrate Llama 2 7B and find in automated and huma
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#20195;&#30721;&#27604;&#36739;&#35843;&#20248;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#20195;&#30721;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;bug-fixing&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.19121</link><description>&lt;p&gt;
&#20195;&#30721;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20195;&#30721;&#27604;&#36739;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Code Comparison Tuning for Code Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19121
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#20195;&#30721;&#27604;&#36739;&#35843;&#20248;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#20195;&#30721;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;bug-fixing&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#20195;&#30721;&#27604;&#36739;&#35843;&#20248;&#65288;CCT&#65289;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35843;&#20248;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#20195;&#30721;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;Code LLMs&#65289;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#24494;&#22937;&#30340;&#20195;&#30721;&#38169;&#35823;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#25351;&#20196;&#35843;&#20248;&#20013;&#38598;&#25104;&#20102;&#27604;&#36739;&#30340;&#27010;&#24565;&#65292;&#21253;&#25324;&#22312;&#26631;&#35760;&#21644;&#24207;&#21015;&#32423;&#21035;&#19978;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#20998;&#36776;&#20195;&#30721;&#20013;&#29978;&#33267;&#26368;&#32454;&#24494;&#30340;&#20559;&#24046;&#12290;&#20026;&#20102;&#27604;&#36739;&#21407;&#22987;&#20195;&#30721;&#19982;&#21253;&#21547;&#25163;&#21160;&#28155;&#21152;&#30340;&#20195;&#30721;&#38169;&#35823;&#30340;&#38169;&#35823;&#29256;&#26412;&#65292;&#25105;&#20204;&#20351;&#29992;&#26631;&#35760;&#32423;&#21035;&#30340;&#20248;&#20808;&#25439;&#22833;&#36827;&#34892;&#35814;&#32454;&#30340;&#26631;&#35760;&#32423;&#21035;&#27604;&#36739;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32467;&#21512;&#20195;&#30721;&#27573;&#21019;&#24314;&#26032;&#30340;&#25351;&#20196;&#35843;&#20248;&#26679;&#26412;&#65292;&#29992;&#20110;&#24207;&#21015;&#32423;&#21035;&#27604;&#36739;&#65292;&#22686;&#24378;&#27169;&#22411;&#30340;&#38169;&#35823;&#20462;&#22797;&#33021;&#21147;&#12290;&#22312;HumanEvalFix&#22522;&#20934;&#27979;&#35797;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;CCT&#22312;&#21508;&#31181;&#20195;&#30721;LLMs&#19978;&#30340;pass@1&#20998;&#25968;&#27604;&#25351;&#20196;&#35843;&#20248;&#39640;&#20986;&#26368;&#22810;4&#20998;&#65292;&#24182;&#19988;&#24191;&#27867;&#30340;&#20998;&#26512;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19121v1 Announce Type: new  Abstract: We present Code Comparison Tuning (CCT), a simple and effective tuning method for code large language models (Code LLMs) to better handle subtle code errors. Specifically, we integrate the concept of comparison into instruction tuning, both at the token and sequence levels, enabling the model to discern even the slightest deviations in code. To compare the original code with an erroneous version containing manually added code errors, we use token-level preference loss for detailed token-level comparisons. Additionally, we combine code segments to create a new instruction tuning sample for sequence-level comparisons, enhancing the model's bug-fixing capability. Experimental results on the HumanEvalFix benchmark show that CCT surpasses instruction tuning in pass@1 scores by up to 4 points across diverse code LLMs, and extensive analysis demonstrates the effectiveness of our method.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#25351;&#31034;&#23545;&#27604;&#35299;&#30721;(ICD)&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#22823;&#35268;&#27169;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;(LVLMs)&#25512;&#26029;&#36807;&#31243;&#20013;&#30340;&#24187;&#35273;&#65292;&#36890;&#36807;&#23545;&#26631;&#20934;&#21644;&#25351;&#31034;&#25200;&#21160;&#30340;&#20998;&#24067;&#36827;&#34892;&#23545;&#27604;&#65292;&#20174;&#21407;&#22987;&#20998;&#24067;&#20013;&#20943;&#21435;&#24187;&#35273;&#27010;&#24565;&#12290;</title><link>https://arxiv.org/abs/2403.18715</link><description>&lt;p&gt;
&#20351;&#29992;&#25351;&#31034;&#23545;&#27604;&#35299;&#30721;&#20943;&#36731;&#22823;&#35268;&#27169;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18715
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#25351;&#31034;&#23545;&#27604;&#35299;&#30721;(ICD)&#26041;&#27861;&#65292;&#26088;&#22312;&#20943;&#23569;&#22823;&#35268;&#27169;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;(LVLMs)&#25512;&#26029;&#36807;&#31243;&#20013;&#30340;&#24187;&#35273;&#65292;&#36890;&#36807;&#23545;&#26631;&#20934;&#21644;&#25351;&#31034;&#25200;&#21160;&#30340;&#20998;&#24067;&#36827;&#34892;&#23545;&#27604;&#65292;&#20174;&#21407;&#22987;&#20998;&#24067;&#20013;&#20943;&#21435;&#24187;&#35273;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;(LVLMs)&#36234;&#26469;&#36234;&#25797;&#38271;&#20174;&#35270;&#35273;&#36755;&#20837;&#29983;&#25104;&#20855;&#26377;&#19978;&#19979;&#25991;&#32454;&#33410;&#21644;&#36830;&#36143;&#24615;&#30340;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#27169;&#24335;&#20915;&#31574;&#21644;&#24320;&#25918;&#24335;&#29983;&#25104;&#20013;&#24212;&#29992;&#23427;&#20204;&#26102;&#65292;&#20854;&#24212;&#29992;&#21463;&#21040;&#24187;&#35273;&#30340;&#38459;&#30861;&#65292;&#21363;&#29983;&#25104;&#30340;&#25991;&#26412;&#19981;&#20934;&#30830;&#22320;&#20195;&#34920;&#20102;&#35270;&#35273;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#25351;&#31034;&#23545;&#27604;&#35299;&#30721;(ICD)&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#22312;LVLM&#25512;&#26029;&#36807;&#31243;&#20013;&#20943;&#23569;&#24187;&#35273;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21463;&#21040;&#25105;&#20204;&#35266;&#23519;&#21040;&#30340;&#25200;&#21160;&#25351;&#31034;&#26174;&#33879;&#21152;&#21095;&#22810;&#27169;&#24577;&#34701;&#21512;&#27169;&#22359;&#20013;&#30340;&#24187;&#35273;&#30340;&#21551;&#21457;&#12290;ICD&#23545;&#26631;&#20934;&#21644;&#25351;&#31034;&#25200;&#21160;&#30340;&#20998;&#24067;&#36827;&#34892;&#23545;&#27604;&#65292;&#20174;&#32780;&#22686;&#21152;&#23545;&#40784;&#19981;&#30830;&#23450;&#24615;&#24182;&#26377;&#25928;&#22320;&#20174;&#21407;&#22987;&#20998;&#24067;&#20013;&#20943;&#21435;&#24187;&#35273;&#27010;&#24565;&#12290;&#36890;&#36807;&#22312;&#21028;&#21035;&#22522;&#20934;(POPE&#21644;MME)&#21644;&#29983;&#25104;&#22522;&#20934;&#19978;&#36827;&#34892;&#20840;&#38754;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18715v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are increasingly adept at generating contextually detailed and coherent responses from visual inputs. However, their application in multimodal decision-making and open-ended generation is hindered by a notable rate of hallucinations, where generated text inaccurately represents the visual contents. To address this issue, this paper introduces the Instruction Contrastive Decoding (ICD) method, a novel approach designed to reduce hallucinations during LVLM inference. Our method is inspired by our observation that what we call disturbance instructions significantly exacerbate hallucinations in multimodal fusion modules. ICD contrasts distributions from standard and instruction disturbance, thereby increasing alignment uncertainty and effectively subtracting hallucinated concepts from the original distribution. Through comprehensive experiments on discriminative benchmarks (POPE and MME) and a generativ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#19981;&#21516;&#30340;&#24863;&#20852;&#36259;&#26041;&#38754;&#26469;&#25913;&#36827;&#27010;&#24565;&#23884;&#20837;&#65292;&#20351;&#20854;&#33021;&#22815;&#25429;&#25417;&#26356;&#24191;&#27867;&#30340;&#24120;&#35782;&#23646;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.16984</link><description>&lt;p&gt;
&#29992;&#22810;&#26041;&#38754;&#27010;&#24565;&#23884;&#20837;&#27169;&#22411;&#24314;&#27169;&#24120;&#35782;&#20849;&#24615;
&lt;/p&gt;
&lt;p&gt;
Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#26126;&#30830;&#24314;&#27169;&#19981;&#21516;&#30340;&#24863;&#20852;&#36259;&#26041;&#38754;&#26469;&#25913;&#36827;&#27010;&#24565;&#23884;&#20837;&#65292;&#20351;&#20854;&#33021;&#22815;&#25429;&#25417;&#26356;&#24191;&#27867;&#30340;&#24120;&#35782;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#23884;&#20837;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#19988;&#39640;&#25928;&#30340;&#26426;&#21046;&#65292;&#23558;&#24120;&#35782;&#30693;&#35782;&#27880;&#20837;&#21040;&#19979;&#28216;&#20219;&#21153;&#20013;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#26631;&#20934;&#23884;&#20837;&#20027;&#35201;&#21453;&#26144;&#22522;&#26412;&#20998;&#31867;&#31867;&#21035;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#23398;&#20064;&#27010;&#24565;&#23884;&#20837;&#26102;&#26126;&#30830;&#24314;&#27169;&#24863;&#20852;&#36259;&#30340;&#19981;&#21516;&#26041;&#38754;&#65292;&#24471;&#21040;&#20102;&#33021;&#22815;&#25429;&#25417;&#26356;&#24191;&#27867;&#24120;&#35782;&#23646;&#24615;&#30340;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16984v1 Announce Type: new  Abstract: Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e.\ sets of concepts which share some property of interest. Such commonalities are the basis for inductive generalisation, hence high-quality concept embeddings can make learning easier and more robust. Unfortunately, standard embeddings primarily reflect basic taxonomic categories, making them unsuitable for finding commonalities that refer to more specific aspects (e.g.\ the colour of objects or the materials they are made of). In this paper, we address this limitation by explicitly modelling the different facets of interest when learning concept embeddings. We show that this leads to embeddings which capture a more diverse range of commonsense properties, and consistently improves resu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#36339;&#36807;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#33021;&#22815;&#20943;&#23569;&#35745;&#31639;&#24320;&#38144;&#24182;&#20445;&#25345;&#39640;&#24615;&#33021;&#21644;&#21442;&#25968;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.15226</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#30340;&#27880;&#24847;&#21147;&#37117;&#26159;&#24517;&#35201;&#30340;&#65306;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21442;&#25968;&#21644;&#35745;&#31639;&#39640;&#25928;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Not All Attention is Needed: Parameter and Computation Efficient Transfer Learning for Multi-modal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#36339;&#36807;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#33021;&#22815;&#20943;&#23569;&#35745;&#31639;&#24320;&#38144;&#24182;&#20445;&#25345;&#39640;&#24615;&#33021;&#21644;&#21442;&#25968;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21442;&#25968;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#35843;&#21442;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#65292;&#31216;&#20026;&#39640;&#25928;&#36339;&#36807;&#27880;&#24847;&#21147;&#65288;EAS&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25581;&#31034;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#65288;MHA&#65289;&#20316;&#20026;MLLM&#30340;&#20027;&#35201;&#35745;&#31639;&#24320;&#38144;&#65292;&#36890;&#24120;&#23545;&#19979;&#28216;&#20219;&#21153;&#26469;&#35828;&#26159;&#22810;&#20313;&#30340;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;EAS&#35780;&#20272;&#27880;&#24847;&#21147;&#20887;&#20313;&#24182;&#36339;&#36807;&#36739;&#19981;&#37325;&#35201;&#30340;MHA&#20197;&#21152;&#36895;&#25512;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#20256;&#25773;&#36866;&#37197;&#22120;&#65288;PIA&#65289;&#26469;&#26381;&#21153;EAS&#30340;&#27880;&#24847;&#21147;&#36339;&#36807;&#24182;&#20445;&#25345;&#21442;&#25968;&#25928;&#29575;&#65292;&#23427;&#21487;&#20197;&#36827;&#19968;&#27493;&#37325;&#26032;&#21442;&#25968;&#21270;&#20026;&#38646;&#39069;&#22806;&#24310;&#36831;&#30340;&#21069;&#39304;&#32593;&#32476;&#65288;FFNs&#65289;&#12290;&#20026;&#20102;&#39564;&#35777;EAS&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;LaVIN&#21644;&#32463;&#20856;&#30340;VL&#39044;&#35757;&#32451;&#27169;&#22411;METER&#65292;&#24182;&#22312;&#19968;&#32452;&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;EAS&#19981;&#20165;&#20445;&#25345;&#20102;&#39640;&#24615;&#33021;&#21644;&#21442;&#25968;&#25928;&#29575;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15226v1 Announce Type: cross  Abstract: In this paper, we propose a novel parameter and computation efficient tuning method for Multi-modal Large Language Models (MLLMs), termed Efficient Attention Skipping (EAS). Concretely, we first reveal that multi-head attentions (MHAs), the main computational overhead of MLLMs, are often redundant to downstream tasks. Based on this observation, EAS evaluates the attention redundancy and skips the less important MHAs to speed up inference. Besides, we also propose a novel propagation-of-information adapter (PIA) to serve the attention skipping of EAS and keep parameter efficiency, which can be further re-parameterized into feed-forward networks (FFNs) for zero-extra latency. To validate EAS, we apply it to a recently proposed MLLM called LaVIN and a classic VL pre-trained model called METER, and conduct extensive experiments on a set of benchmarks. The experiments show that EAS not only retains high performance and parameter efficiency,
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RAFT&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#29992;&#30456;&#20851;&#25991;&#26723;&#20013;&#33021;&#22815;&#24110;&#21161;&#22238;&#31572;&#38382;&#39064;&#30340;&#27491;&#30830;&#24207;&#21015;&#26469;&#25913;&#21892;&#27169;&#22411;&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#22238;&#31572;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.10131</link><description>&lt;p&gt;
RAFT&#65306;&#23558;&#35821;&#35328;&#27169;&#22411;&#35843;&#25972;&#21040;&#29305;&#23450;&#39046;&#22495;RAG
&lt;/p&gt;
&lt;p&gt;
RAFT: Adapting Language Model to Domain Specific RAG
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10131
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RAFT&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#29992;&#30456;&#20851;&#25991;&#26723;&#20013;&#33021;&#22815;&#24110;&#21161;&#22238;&#31572;&#38382;&#39064;&#30340;&#27491;&#30830;&#24207;&#21015;&#26469;&#25913;&#21892;&#27169;&#22411;&#22312;&#29305;&#23450;&#39046;&#22495;&#20013;&#22238;&#31572;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#65292;&#36890;&#36807;&#22823;&#35268;&#27169;&#25991;&#26412;&#25968;&#25454;&#39044;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#26631;&#20934;&#33539;&#24335;&#12290;&#22312;&#23558;&#36825;&#20123;LLMs&#29992;&#20110;&#35768;&#22810;&#19979;&#28216;&#24212;&#29992;&#31243;&#24207;&#26102;&#65292;&#36890;&#24120;&#36824;&#20250;&#36890;&#36807;&#22522;&#20110;RAG&#30340;&#25552;&#31034;&#25110;&#24494;&#35843;&#65292;&#23558;&#26032;&#30693;&#35782;&#65288;&#20363;&#22914;&#65292;&#26102;&#25928;&#26032;&#38395;&#25110;&#31169;&#26377;&#39046;&#22495;&#30693;&#35782;&#65289;&#23884;&#20837;&#39044;&#35757;&#32451;&#27169;&#22411;&#20013;&#12290;&#28982;&#32780;&#65292;&#27169;&#22411;&#33719;&#24471;&#36825;&#20123;&#26032;&#30693;&#35782;&#30340;&#26368;&#20339;&#26041;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26816;&#32034;&#22686;&#24378;&#24494;&#35843;&#65288;RAFT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#35757;&#32451;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#27169;&#22411;&#22312;"&#24320;&#25918;&#20070;&#31821;"&#30340;&#39046;&#22495;&#35774;&#32622;&#20013;&#22238;&#31572;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;&#22312;RAFT&#20013;&#65292;&#32473;&#23450;&#19968;&#20010;&#38382;&#39064;&#21644;&#19968;&#32452;&#26816;&#32034;&#21040;&#30340;&#25991;&#26723;&#65292;&#25105;&#20204;&#35757;&#32451;&#27169;&#22411;&#24573;&#30053;&#37027;&#20123;&#23545;&#22238;&#31572;&#38382;&#39064;&#27809;&#26377;&#24110;&#21161;&#30340;&#25991;&#26723;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#24178;&#25200;&#25991;&#26723;&#12290;RAFT&#36890;&#36807;&#21407;&#25991;&#24341;&#29992;&#30456;&#20851;&#25991;&#26723;&#20013;&#33021;&#22815;&#24110;&#21161;&#22238;&#31572;&#38382;&#39064;&#30340;&#27491;&#30830;&#24207;&#21015;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10131v1 Announce Type: cross  Abstract: Pretraining Large Language Models (LLMs) on large corpora of textual data is now a standard paradigm. When using these LLMs for many downstream applications, it is common to additionally bake in new knowledge (e.g., time-critical news, or private domain knowledge) into the pretrained model either through RAG-based-prompting, or fine-tuning. However, the optimal methodology for the model to gain such new knowledge remains an open question. In this paper, we present Retrieval Augmented FineTuning (RAFT), a training recipe that improves the model's ability to answer questions in a "open-book" in-domain settings. In RAFT, given a question, and a set of retrieved documents, we train the model to ignore those documents that don't help in answering the question, which we call, distractor documents. RAFT accomplishes this by citing verbatim the right sequence from the relevant document that would help answer the question. This coupled with RAF
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#36890;&#36807;&#36981;&#24490;&#39044;&#23450;&#20041;&#27969;&#31243;&#21644;&#20445;&#30041;API&#20381;&#36182;&#24615;&#35299;&#20915;&#29992;&#25143;&#24847;&#22270;&#30340;&#24544;&#23454;&#35268;&#21010;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#30651;&#21551;&#21457;&#24335;&#30340;&#21463;&#38480;&#35299;&#30721;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.05766</link><description>&lt;p&gt;
FLAP: &#22312;LLMs&#20013;&#20855;&#26377;&#21463;&#38480;&#35299;&#30721;&#30340;&#27969;&#31243;&#36981;&#24490;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
FLAP: Flow Adhering Planning with Constrained Decoding in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#36890;&#36807;&#36981;&#24490;&#39044;&#23450;&#20041;&#27969;&#31243;&#21644;&#20445;&#30041;API&#20381;&#36182;&#24615;&#35299;&#20915;&#29992;&#25143;&#24847;&#22270;&#30340;&#24544;&#23454;&#35268;&#21010;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#30651;&#21551;&#21457;&#24335;&#30340;&#21463;&#38480;&#35299;&#30721;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#21010;&#23545;&#20110;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#30340;&#20195;&#29702;&#20154;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#20154;&#31867;&#20195;&#29702;&#20154;&#36890;&#24120;&#36890;&#36807;&#36981;&#24490;&#39044;&#23450;&#20041;&#30340;&#24037;&#20316;&#27969;&#31243;&#35299;&#20915;&#29992;&#25143;&#38382;&#39064;&#65292;&#23558;&#24037;&#20316;&#27969;&#31243;&#27493;&#39588;&#20998;&#35299;&#20026;&#21487;&#25805;&#20316;&#39033;&#30446;&#65292;&#24182;&#36890;&#36807;&#25191;&#34892;API&#25191;&#34892;&#25805;&#20316;&#65307;&#25152;&#26377;&#36825;&#20123;&#37117;&#38656;&#35201;&#25512;&#29702;&#21644;&#35268;&#21010;&#12290;&#37492;&#20110;LLMs&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#22810;&#22320;&#23581;&#35797;&#20351;&#29992;LLMs&#36827;&#34892;&#20219;&#21153;&#35268;&#21010;&#21644;API&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;LLMs&#20559;&#21521;&#39044;&#35757;&#32451;&#25968;&#25454;&#65292;&#35745;&#21010;&#19982;&#39044;&#23450;&#20041;&#24037;&#20316;&#27969;&#31243;&#21644;API&#20381;&#36182;&#24615;&#30340;&#24544;&#23454;&#24615;&#24182;&#19981;&#34987;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#22312;&#29616;&#23454;&#29983;&#27963;&#20013;&#65292;&#24037;&#20316;&#27969;&#31243;&#26159;&#33258;&#23450;&#20041;&#30340;&#24182;&#19988;&#23481;&#26131;&#26356;&#25913;&#65292;&#22240;&#27492;&#65292;&#24555;&#36895;&#20351;&#20195;&#29702;&#20154;&#36866;&#24212;&#21464;&#21270;&#26159;&#21487;&#21462;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#36890;&#36807;&#36981;&#24490;&#39044;&#23450;&#20041;&#27969;&#31243;&#21644;&#20445;&#30041;API&#20381;&#36182;&#24615;&#35299;&#20915;&#29992;&#25143;&#24847;&#22270;&#30340;&#24544;&#23454;&#35268;&#21010;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#30651;&#21551;&#21457;&#24335;&#30340;&#21463;&#38480;&#35299;&#30721;&#31639;&#27861;&#29992;&#20110;&#24544;&#23454;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05766v1 Announce Type: new  Abstract: Planning is a crucial task for agents in task oriented dialogs (TODs). Human agents typically resolve user issues by following predefined workflows, decomposing workflow steps into actionable items, and performing actions by executing APIs in order; all of which require reasoning and planning. With the recent advances in LLMs, there have been increasing attempts to use LLMs for task planning and API usage. However, the faithfulness of the plans to predefined workflows and API dependencies, is not guaranteed with LLMs because of their bias towards pretraining data. Moreover, in real life, workflows are custom-defined and prone to change, hence, quickly adapting agents to the changes is desirable. In this paper, we study faithful planning in TODs to resolve user intents by following predefined flows and preserving API dependencies. We propose a constrained decoding algorithm based on lookahead heuristic for faithful planning. Our algorithm
&lt;/p&gt;</description></item><item><title>&#22312;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#21457;&#29616;&#25152;&#26377;&#23376;&#32593;&#32476;&#37117;&#20849;&#20139;&#19968;&#20010;&#27880;&#24847;&#21147;&#22836;&#38598;&#21512;&#65292;&#34987;&#31216;&#20026;&#21551;&#21457;&#24335;&#26680;&#24515;&#65292;&#36825;&#21487;&#33021;&#26159;&#36896;&#25104;&#23376;&#32593;&#32476;&#27867;&#21270;&#24046;&#24322;&#30340;&#21407;&#22240;&#12290;</title><link>https://arxiv.org/abs/2403.03942</link><description>&lt;p&gt;
&#12298;&#21551;&#21457;&#24335;&#26680;&#24515;&#65306;&#29702;&#35299;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23376;&#32593;&#32476;&#27867;&#21270;&#12299;
&lt;/p&gt;
&lt;p&gt;
The Heuristic Core: Understanding Subnetwork Generalization in Pretrained Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03942
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#21457;&#29616;&#25152;&#26377;&#23376;&#32593;&#32476;&#37117;&#20849;&#20139;&#19968;&#20010;&#27880;&#24847;&#21147;&#22836;&#38598;&#21512;&#65292;&#34987;&#31216;&#20026;&#21551;&#21457;&#24335;&#26680;&#24515;&#65292;&#36825;&#21487;&#33021;&#26159;&#36896;&#25104;&#23376;&#32593;&#32476;&#27867;&#21270;&#24046;&#24322;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#32463;&#36807;&#19981;&#21516;&#38543;&#26426;&#31181;&#23376;&#24494;&#35843;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#30340;&#39046;&#22495;&#20869;&#24615;&#33021;&#65292;&#20294;&#22312;&#21477;&#27861;&#27867;&#21270;&#27979;&#35797;&#20013;&#27867;&#21270;&#19981;&#21516;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20986;&#21363;&#20351;&#22312;&#21333;&#19968;&#27169;&#22411;&#20869;&#37096;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#25214;&#21040;&#25191;&#34892;&#31867;&#20284;&#39046;&#22495;&#20869;&#25805;&#20316;&#20294;&#27867;&#21270;&#24046;&#24322;&#24040;&#22823;&#30340;&#22810;&#20010;&#23376;&#32593;&#32476;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#20123;&#29616;&#35937;&#65292;&#25105;&#20204;&#35843;&#26597;&#26159;&#21542;&#21487;&#20197;&#29992;&#8220;&#31454;&#20105;&#24615;&#23376;&#32593;&#32476;&#8221;&#26469;&#29702;&#35299;&#23427;&#20204;&#65306;&#27169;&#22411;&#26368;&#21021;&#34920;&#31034;&#21508;&#31181;&#19981;&#21516;&#31639;&#27861;&#65292;&#23545;&#24212;&#20110;&#19981;&#21516;&#30340;&#23376;&#32593;&#32476;&#65292;&#24403;&#26368;&#32456;&#25910;&#25947;&#21040;&#20854;&#20013;&#19968;&#20010;&#26102;&#27867;&#21270;&#21457;&#29983;&#12290;&#36825;&#19968;&#35299;&#37322;&#24050;&#34987;&#29992;&#20110;&#35299;&#37322;&#31616;&#21333;&#31639;&#27861;&#20219;&#21153;&#20013;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24182;&#38750;&#25214;&#21040;&#31454;&#20105;&#24615;&#23376;&#32593;&#32476;&#65292;&#32780;&#26159;&#25152;&#26377;&#23376;&#32593;&#32476; -- &#26080;&#35770;&#23427;&#20204;&#26159;&#21542;&#27867;&#21270; -- &#37117;&#20849;&#20139;&#19968;&#32452;&#27880;&#24847;&#21147;&#22836;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#21551;&#21457;&#24335;&#26680;&#24515;&#12290;&#36827;&#19968;&#27493;&#20998;&#26512;&#34920;&#26126;&#65292;&#23427;&#21487;&#33021;&#26159;&#36896;&#25104;&#19981;&#21516;&#23376;&#32593;&#32476;&#27867;&#21270;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03942v1 Announce Type: new  Abstract: Prior work has found that pretrained language models (LMs) fine-tuned with different random seeds can achieve similar in-domain performance but generalize differently on tests of syntactic generalization. In this work, we show that, even within a single model, we can find multiple subnetworks that perform similarly in-domain, but generalize vastly differently. To better understand these phenomena, we investigate if they can be understood in terms of "competing subnetworks": the model initially represents a variety of distinct algorithms, corresponding to different subnetworks, and generalization occurs when it ultimately converges to one. This explanation has been used to account for generalization in simple algorithmic tasks. Instead of finding competing subnetworks, we find that all subnetworks -- whether they generalize or not -- share a set of attention heads, which we refer to as the heuristic core. Further analysis suggests that th
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20449;&#24687;&#27969;&#20998;&#26512;&#35777;&#23454;&#20102;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#21333;&#35789;&#32423;&#21035;&#21644;&#25991;&#26412;&#32423;&#21035;&#20998;&#31867;&#20043;&#38388;&#30340;&#30456;&#20114;&#22686;&#24378;&#25928;&#24212;&#65292;&#21516;&#26102;&#23558;&#35813;&#25928;&#24212;&#25193;&#23637;&#21040;&#25552;&#31034;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.02902</link><description>&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#27969;&#23637;&#31034;&#30456;&#20114;&#22686;&#24378;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Demonstrating Mutual Reinforcement Effect through Information Flow
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02902
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20449;&#24687;&#27969;&#20998;&#26512;&#35777;&#23454;&#20102;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#21333;&#35789;&#32423;&#21035;&#21644;&#25991;&#26412;&#32423;&#21035;&#20998;&#31867;&#20043;&#38388;&#30340;&#30456;&#20114;&#22686;&#24378;&#25928;&#24212;&#65292;&#21516;&#26102;&#23558;&#35813;&#25928;&#24212;&#25193;&#23637;&#21040;&#25552;&#31034;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20114;&#22686;&#24378;&#25928;&#24212;(MRE)&#30740;&#31350;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#20013;&#21333;&#35789;&#32423;&#21035;&#21644;&#25991;&#26412;&#32423;&#21035;&#20998;&#31867;&#20043;&#38388;&#30340;&#21327;&#21516;&#20851;&#31995;&#12290;&#23427;&#35748;&#20026;&#20004;&#20010;&#20998;&#31867;&#32423;&#21035;&#30340;&#24615;&#33021;&#21487;&#20197;&#30456;&#20114;&#22686;&#24378;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26426;&#21046;&#22312;&#20808;&#21069;&#30340;&#30740;&#31350;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#35777;&#26126;&#25110;&#35299;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#21033;&#29992;&#20449;&#24687;&#27969;&#20998;&#26512;&#26469;&#35266;&#23519;&#21644;&#35777;&#23454;MRE&#29702;&#35770;&#12290;&#25105;&#20204;&#22312;&#20845;&#20010;MRE&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#27169;&#22411;&#20013;MRE&#30340;&#23384;&#22312;&#21450;&#20854;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#24494;&#35843;&#23454;&#39564;&#65292;&#20854;&#32467;&#26524;&#19982;&#20449;&#24687;&#27969;&#23454;&#39564;&#30340;&#32467;&#26524;&#19968;&#33268;&#12290;&#20004;&#20010;&#23454;&#39564;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#35777;&#23454;&#20102;MRE&#30340;&#23384;&#22312;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;MRE&#30340;&#24212;&#29992;&#25193;&#23637;&#21040;&#25552;&#31034;&#23398;&#20064;&#65292;&#21033;&#29992;&#21333;&#35789;&#32423;&#21035;&#20449;&#24687;&#20316;&#20026;&#34920;&#36798;&#22120;&#26469;&#22686;&#24378;&#27169;&#22411;&#39044;&#27979;&#25991;&#26412;&#32423;&#21035;&#20998;&#31867;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02902v1 Announce Type: new  Abstract: The Mutual Reinforcement Effect (MRE) investigates the synergistic relationship between word-level and text-level classifications in text classification tasks. It posits that the performance of both classification levels can be mutually enhanced. However, this mechanism has not been adequately demonstrated or explained in prior research. To address this gap, we employ information flow analysis to observe and substantiate the MRE theory. Our experiments on six MRE hybrid datasets revealed the presence of MRE in the model and its impact. Additionally, we conducted fine-tuning experiments, whose results were consistent with those of the information flow experiments. The convergence of findings from both experiments corroborates the existence of MRE. Furthermore, we extended the application of MRE to prompt learning, utilizing word-level information as a verbalizer to bolster the model's prediction of text-level classification labels. In our
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#21512;&#25512;&#29702;&#31995;&#32479;&#30340;&#25193;&#23637;&#23450;&#24459;&#65292;&#21457;&#29616;&#25237;&#31080;&#25512;&#29702;&#31995;&#32479;&#30340;&#24615;&#33021;&#38543;LLM&#35843;&#29992;&#27425;&#25968;&#22686;&#21152;&#20808;&#22686;&#21152;&#21518;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2403.02419</link><description>&lt;p&gt;
&#20320;&#38656;&#35201;&#26356;&#22810;LLM&#35843;&#29992;&#21527;&#65311;&#36208;&#21521;&#22797;&#21512;&#25512;&#29702;&#31995;&#32479;&#30340;&#25193;&#23637;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#21512;&#25512;&#29702;&#31995;&#32479;&#30340;&#25193;&#23637;&#23450;&#24459;&#65292;&#21457;&#29616;&#25237;&#31080;&#25512;&#29702;&#31995;&#32479;&#30340;&#24615;&#33021;&#38543;LLM&#35843;&#29992;&#27425;&#25968;&#22686;&#21152;&#20808;&#22686;&#21152;&#21518;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26368;&#36817;&#35821;&#35328;&#20219;&#21153;&#20013;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#26159;&#36890;&#36807;&#25191;&#34892;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#35843;&#29992;&#24182;&#27719;&#24635;&#23427;&#20204;&#30340;&#21709;&#24212;&#30340;&#22797;&#21512;&#31995;&#32479;&#23454;&#29616;&#30340;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;LLM&#35843;&#29992;&#27425;&#25968;&#30340;&#24433;&#21709; -- &#20363;&#22914;&#65292;&#24403;&#35201;&#27714;LLM&#22810;&#27425;&#22238;&#31572;&#27599;&#20010;&#38382;&#39064;&#24182;&#21462;&#24471;&#20849;&#35782;&#26102; -- &#23545;&#20110;&#36825;&#31181;&#22797;&#21512;&#31995;&#32479;&#30340;&#24615;&#33021;&#20102;&#35299;&#29978;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#22797;&#21512;&#25512;&#29702;&#31995;&#32479;&#30340;&#25193;&#23637;&#23450;&#24459;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;LLM&#35843;&#29992;&#27425;&#25968;&#22914;&#20309;&#24433;&#21709;&#19968;&#20010;&#23618;&#32423;&#25237;&#31080;&#25512;&#29702;&#31995;&#32479;&#30340;&#24615;&#33021; -- &#36825;&#26159;&#26368;&#31616;&#21333;&#30340;&#22797;&#21512;&#31995;&#32479;&#20043;&#19968;&#65292;&#23427;&#36890;&#36807;&#22810;&#25968;&#25237;&#31080;&#32858;&#21512;LLM&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22810;&#20010;&#35821;&#35328;&#20219;&#21153;&#20013;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25237;&#31080;&#25512;&#29702;&#31995;&#32479;&#30340;&#24615;&#33021;&#38543;&#30528;LLM&#35843;&#29992;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#20808;&#22686;&#21152;&#21518;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#38750;&#21333;&#35843;&#24615;&#26159;&#30001;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02419v1 Announce Type: cross  Abstract: Many recent state-of-the-art results in language tasks were achieved using compound systems that perform multiple Large Language Model (LLM) calls and aggregate their responses. However, there is little understanding of how the number of LLM calls -- e.g., when asking the LLM to answer each question multiple times and taking a consensus -- affects such a compound system's performance. In this paper, we initiate the study of scaling laws of compound inference systems. We analyze, theoretically and empirically, how the number of LLM calls affects the performance of one-layer Voting Inference Systems -- one of the simplest compound systems, which aggregates LLM responses via majority voting. We find empirically that across multiple language tasks, surprisingly, Voting Inference Systems' performance first increases but then decreases as a function of the number of LLM calls. Our theoretical results suggest that this non-monotonicity is due
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30693;&#35782;&#33976;&#39311;&#30340;&#24046;&#20998;&#31169;&#23494;&#31639;&#27861;</title><link>https://arxiv.org/abs/2403.00932</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#25991;&#26412;&#29983;&#25104;&#30340;&#24046;&#20998;&#31169;&#23494;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Knowledge Distillation via Synthetic Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00932
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30693;&#35782;&#33976;&#39311;&#30340;&#24046;&#20998;&#31169;&#23494;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#35768;&#22810;&#19981;&#21516;&#30340;&#19979;&#28216;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#38544;&#31169;&#30340;&#22686;&#21152;&#32039;&#36843;&#24615;&#35201;&#27714;LLMs&#22312;&#31169;&#26377;&#25968;&#25454;&#19978;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;(DP)&#36827;&#34892;&#35757;&#32451;&#12290;&#21516;&#26102;&#65292;&#36824;&#38656;&#35201;&#21387;&#32553;LLMs&#20197;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#35774;&#22791;&#25110;&#24310;&#36831;&#25935;&#24863;&#30340;&#24212;&#29992;&#20013;&#36827;&#34892;&#30495;&#23454;&#37096;&#32626;&#12290;&#24046;&#20998;&#38544;&#31169;&#21644;&#27169;&#22411;&#21387;&#32553;&#36890;&#24120;&#24517;&#39035;&#22312;&#23454;&#29616;&#20854;&#30446;&#26631;&#30340;&#36807;&#31243;&#20013;&#26435;&#34913;&#25928;&#29992;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#21516;&#26102;&#23454;&#29616;&#36825;&#20004;&#32773;&#21487;&#33021;&#23548;&#33268;&#26356;&#22810;&#30340;&#25928;&#29992;&#25439;&#22833;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24046;&#20998;&#31169;&#23494;&#30693;&#35782;&#33976;&#39311;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;&#30001;&#24046;&#20998;&#31169;&#23494;LLM&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#12290;&#25945;&#24072;&#27169;&#22411;&#30340;&#30693;&#35782;&#20197;&#20004;&#31181;&#26041;&#24335;&#36716;&#31227;&#21040;&#23398;&#29983;&#27169;&#22411;&#19978;&#65306;&#19968;&#31181;&#26159;&#26469;&#33258;&#21512;&#25104;&#25968;&#25454;&#26412;&#36523;&#30340;&#30828;&#26631;&#31614;&#65292;&#21478;&#19968;&#31181;&#26159;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#35780;&#20272;&#30340;&#25945;&#24072;&#27169;&#22411;&#30340;&#36755;&#20986;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00932v1 Announce Type: cross  Abstract: Large Language models (LLMs) are achieving state-of-the-art performance in many different downstream tasks. However, the increasing urgency of data privacy requires LLMs to train with Differential Privacy (DP) on private data. Concurrently it is also necessary to compress LLMs for real-life deployments on resource-constrained devices or latency-sensitive applications. Differential privacy and model compression generally must trade off utility loss to achieve their objectives. Moreover, concurrently achieving both can result in even more utility loss. To this end, we propose a novel differentially private knowledge distillation algorithm that exploits synthetic data generated by a differentially private LLM. The knowledge of a teacher model is transferred onto the student in two ways: one way from the synthetic data itself, the hard labels, and the other way by the output distribution of the teacher model evaluated on the synthetic data
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#26799;&#24230;&#65292;&#23558;&#22235;&#31181;&#26377;&#25928;&#30340;&#23545;&#27604;&#25439;&#22833;&#38598;&#25104;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#33539;&#24335;&#20013;&#65292;&#20197;&#25506;&#31350;&#23545;&#27604;&#21477;&#23376;&#34920;&#31034;&#23398;&#20064;&#20013;&#21508;&#31181;&#23545;&#27604;&#25439;&#22833;&#36798;&#21040;&#21331;&#36234;&#24615;&#33021;&#30340;&#20849;&#21516;&#29305;&#28857;&#12290;</title><link>https://arxiv.org/abs/2402.18281</link><description>&lt;p&gt;
&#26356;&#22909;&#29702;&#35299;&#23545;&#27604;&#21477;&#23376;&#34920;&#31034;&#23398;&#20064;&#65306;&#26799;&#24230;&#30340;&#32479;&#19968;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
Towards Better Understanding of Contrastive Sentence Representation Learning: A Unified Paradigm for Gradient
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18281
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#26799;&#24230;&#65292;&#23558;&#22235;&#31181;&#26377;&#25928;&#30340;&#23545;&#27604;&#25439;&#22833;&#38598;&#25104;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#33539;&#24335;&#20013;&#65292;&#20197;&#25506;&#31350;&#23545;&#27604;&#21477;&#23376;&#34920;&#31034;&#23398;&#20064;&#20013;&#21508;&#31181;&#23545;&#27604;&#25439;&#22833;&#36798;&#21040;&#21331;&#36234;&#24615;&#33021;&#30340;&#20849;&#21516;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#34920;&#31034;&#23398;&#20064;&#65288;SRL&#65289;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#23545;&#29031;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#26159;&#30446;&#21069;&#20027;&#27969;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20854;&#26174;&#33879;&#26377;&#25928;&#24615;&#32972;&#21518;&#30340;&#21407;&#22240;&#20173;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#23545;&#27604;SSL&#22312;&#29702;&#35770;&#21644;&#23454;&#38469;&#34920;&#29616;&#19978;&#19982;&#38750;&#23545;&#27604;SSL&#65288;&#20363;&#22914;&#65292;&#23545;&#40784;&#21644;&#19968;&#33268;&#24615;&#12289;Barlow Twins&#21644;VICReg&#65289;&#26377;&#30456;&#20284;&#20043;&#22788;&#12290;&#28982;&#32780;&#65292;&#22312;SRL&#20013;&#65292;&#23545;&#27604;SSL&#26126;&#26174;&#20248;&#20110;&#38750;&#23545;&#27604;SSL&#12290;&#22240;&#27492;&#65292;&#20986;&#29616;&#20102;&#20004;&#20010;&#38382;&#39064;&#65306;&#39318;&#20808;&#65292;&#26159;&#20160;&#20040;&#20849;&#21516;&#28857;&#20351;&#21508;&#31181;&#23545;&#27604;&#25439;&#22833;&#22312;SRL&#20013;&#21462;&#24471;&#20102;&#20248;&#36234;&#24615;&#33021;&#65311;&#20854;&#27425;&#65292;&#25105;&#20204;&#22914;&#20309;&#20351;&#38750;&#23545;&#27604;SSL&#65288;&#19982;&#23545;&#27604;SSL&#30456;&#20284;&#20294;&#22312;SRL&#20013;&#26080;&#25928;&#65289;&#21464;&#24471;&#26377;&#25928;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#26799;&#24230;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#21457;&#29616;&#22235;&#31181;&#26377;&#25928;&#30340;&#23545;&#27604;&#25439;&#22833;&#21487;&#20197;&#38598;&#25104;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#33539;&#24335;&#20013;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18281v1 Announce Type: new  Abstract: Sentence Representation Learning (SRL) is a crucial task in Natural Language Processing (NLP), where contrastive Self-Supervised Learning (SSL) is currently a mainstream approach. However, the reasons behind its remarkable effectiveness remain unclear. Specifically, in other research fields, contrastive SSL shares similarities in both theory and practical performance with non-contrastive SSL (e.g., alignment &amp; uniformity, Barlow Twins, and VICReg). However, in SRL, contrastive SSL outperforms non-contrastive SSL significantly. Therefore, two questions arise: First, what commonalities enable various contrastive losses to achieve superior performance in SRL? Second, how can we make non-contrastive SSL, which is similar to contrastive SSL but ineffective in SRL, effective? To address these questions, we start from the perspective of gradients and discover that four effective contrastive losses can be integrated into a unified paradigm, whic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TruthX&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#32534;&#36753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#24615;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;TruthfulQA&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;TruthX&#24179;&#22343;&#25552;&#39640;&#20102;13&#31181;&#20808;&#36827;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.17811</link><description>&lt;p&gt;
TruthX: &#36890;&#36807;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#32534;&#36753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#20943;&#36731;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17811
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TruthX&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#32534;&#36753;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#24615;&#65292;&#23454;&#39564;&#35777;&#26126;&#22312;TruthfulQA&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;TruthX&#24179;&#22343;&#25552;&#39640;&#20102;13&#31181;&#20808;&#36827;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#26174;&#33879;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#26377;&#26102;&#20250;&#20135;&#29983;&#24187;&#35273;&#65292;&#29305;&#21035;&#26159;&#22312;&#23427;&#20204;&#21487;&#33021;&#29983;&#25104;&#19981;&#30495;&#23454;&#30340;&#22238;&#24212;&#65292;&#23613;&#31649;&#25317;&#26377;&#27491;&#30830;&#30340;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TruthX&#65292;&#19968;&#31181;&#29992;&#20110;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#32534;&#36753;LLMs&#20869;&#37096;&#34920;&#31034;&#20197;&#33719;&#21462;&#20854;&#30495;&#23454;&#24615;&#30340;&#25512;&#26029;&#26102;&#38388;&#26041;&#27861;&#12290;TruthX&#21033;&#29992;&#33258;&#21160;&#32534;&#30721;&#22120;&#23558;LLM&#30340;&#34920;&#31034;&#20998;&#21035;&#26144;&#23556;&#21040;&#35821;&#20041;&#21644;&#30495;&#23454;&#28508;&#22312;&#31354;&#38388;&#65292;&#24182;&#24212;&#29992;&#23545;&#27604;&#23398;&#20064;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#35782;&#21035;&#30495;&#23454;&#30340;&#32534;&#36753;&#26041;&#21521;&#12290;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#22312;&#30495;&#23454;&#31354;&#38388;&#20013;&#32534;&#36753;LLM&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;TruthX&#26377;&#25928;&#22320;&#22686;&#24378;&#20102;LLMs&#30340;&#30495;&#23454;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;TruthX&#36890;&#36807;20%&#30340;&#24179;&#22343;&#20540;&#25552;&#39640;&#20102;13&#31181;&#20808;&#36827;LLMs&#22312;TruthfulQA&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#30495;&#23454;&#24615;&#12290;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#30495;&#23454;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17811v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, they sometimes suffer from producing hallucinations, particularly in cases where they may generate untruthful responses despite possessing the correct knowledge. In this paper, we propose TruthX, an inference-time method to elicit the truthfulness of LLMs by editing their internal representations in truthful space. TruthX employs an auto-encoder to map LLM's representations into semantic and truthful latent spaces respectively, and applies contrastive learning to identify a truthful editing direction within the truthful space. During inference, by editing LLM's internal representations in truthful space, TruthX effectively enhances the truthfulness of LLMs. Experiments show that TruthX effectively improves the truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark. Further analyses suggest that the truthful space
&lt;/p&gt;</description></item><item><title>&#25361;&#25112;&#20256;&#32479;&#30340;&#21463;&#38480;&#35780;&#20272;&#33539;&#24335;&#65292;&#25506;&#32034;&#26356;&#30495;&#23454;&#30340;&#19981;&#21463;&#38480;&#21046;&#30340;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.16786</link><description>&lt;p&gt;
&#25919;&#27835;&#32599;&#30424;&#25110;&#26059;&#36716;&#31661;&#65311;&#26397;&#30528;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#26356;&#26377;&#24847;&#20041;&#30340;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16786
&lt;/p&gt;
&lt;p&gt;
&#25361;&#25112;&#20256;&#32479;&#30340;&#21463;&#38480;&#35780;&#20272;&#33539;&#24335;&#65292;&#25506;&#32034;&#26356;&#30495;&#23454;&#30340;&#19981;&#21463;&#38480;&#21046;&#30340;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#35768;&#22810;&#24037;&#20316;&#36890;&#36807;&#22810;&#39033;&#36873;&#25321;&#35843;&#26597;&#21644;&#38382;&#21367;&#26469;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#30340;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#12290;&#22823;&#22810;&#25968;&#24037;&#20316;&#30340;&#21160;&#26426;&#26159;&#28304;&#20110;&#23545;&#29616;&#23454;&#19990;&#30028;&#20013;LLM&#24212;&#29992;&#30340;&#25285;&#24551;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#23545;&#29616;&#23454;&#19990;&#30028;&#30340;&#20851;&#27880;&#19982;&#24403;&#21069;&#35780;&#20272;&#30340;&#20154;&#20026;&#24615;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65306;&#30495;&#23454;&#29992;&#25143;&#36890;&#24120;&#19981;&#20250;&#21521;LLMs&#25552;&#20986;&#35843;&#26597;&#38382;&#39064;&#12290;&#21463;&#21040;&#36825;&#31181;&#24046;&#24322;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#30446;&#21069;&#23545;LLMs&#20013;&#20215;&#20540;&#35266;&#21644;&#35266;&#28857;&#30340;&#32422;&#26463;&#35780;&#20272;&#33539;&#24335;&#65292;&#24182;&#25506;&#32034;&#20102;&#26356;&#29616;&#23454;&#30340;&#19981;&#21463;&#38480;&#21046;&#30340;&#35780;&#20272;&#12290;&#20316;&#20026;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#24191;&#21463;&#27426;&#36814;&#30340;&#25919;&#27835;&#32599;&#30424;&#27979;&#35797;&#65288;PCT&#65289;&#12290;&#22312;&#19968;&#20010;&#31995;&#32479;&#24615;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#20808;&#21069;&#20351;&#29992;PCT&#30340;&#24037;&#20316;&#37117;&#24378;&#21046;&#27169;&#22411;&#36981;&#23432;PCT&#30340;&#22810;&#39033;&#36873;&#25321;&#26684;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#19981;&#34987;&#24378;&#21046;&#26102;&#65292;&#27169;&#22411;&#32473;&#20986;&#30340;&#31572;&#26696;&#23454;&#36136;&#19978;&#26159;&#19981;&#21516;&#30340;&#65307;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16786v1 Announce Type: new  Abstract: Much recent work seeks to evaluate values and opinions in large language models (LLMs) using multiple-choice surveys and questionnaires. Most of this work is motivated by concerns around real-world LLM applications. For example, politically-biased LLMs may subtly influence society when they are used by millions of people. Such real-world concerns, however, stand in stark contrast to the artificiality of current evaluations: real users do not typically ask LLMs survey questions. Motivated by this discrepancy, we challenge the prevailing constrained evaluation paradigm for values and opinions in LLMs and explore more realistic unconstrained evaluations. As a case study, we focus on the popular Political Compass Test (PCT). In a systematic review, we find that most prior work using the PCT forces models to comply with the PCT's multiple-choice format. We show that models give substantively different answers when not forced; that answers cha
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;RetrievalQA&#65292;&#29992;&#20110;&#35780;&#20272;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#25216;&#26415;&#65292;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;TA-ARE</title><link>https://arxiv.org/abs/2402.16457</link><description>&lt;p&gt;
RetrievalQA&#65306;&#35780;&#20272;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#25216;&#26415;&#29992;&#20110;&#30701;&#25991;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;RetrievalQA&#65292;&#29992;&#20110;&#35780;&#20272;&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#25216;&#26415;&#65292;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;TA-ARE
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;ARAG&#65289;&#26088;&#22312;&#21160;&#24577;&#30830;&#23450;&#26597;&#35810;&#26159;&#21542;&#38656;&#35201;&#26816;&#32034;&#65292;&#32780;&#19981;&#26159;&#26080;&#36873;&#25321;&#22320;&#26816;&#32034;&#65292;&#20197;&#22686;&#24378;&#20449;&#24687;&#30340;&#25928;&#29575;&#21644;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#22312;&#35780;&#20272;ARAG&#26041;&#27861;&#26041;&#38754;&#22823;&#22810;&#34987;&#24573;&#35270;&#65292;&#23548;&#33268;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#26410;&#21463;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20934;&#65292;RetrievalQA&#65292;&#21253;&#21547;1,271&#20010;&#28085;&#30422;&#26032;&#19990;&#30028;&#21644;&#38271;&#23614;&#30693;&#35782;&#30340;&#30701;&#25991;&#38382;&#39064;&#12290;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#25152;&#38656;&#30340;&#30693;&#35782;&#19981;&#22312;LLM&#20013;&#65307;&#22240;&#27492;&#65292;&#24517;&#39035;&#26816;&#32034;&#22806;&#37096;&#20449;&#24687;&#26469;&#27491;&#30830;&#22238;&#31572;&#12290;&#36825;&#20351;&#24471;RetrievalQA&#25104;&#20026;&#35780;&#20272;&#29616;&#26377;ARAG&#26041;&#27861;&#30340;&#21512;&#36866;&#27979;&#35797;&#24179;&#21488;&#12290;&#25105;&#20204;&#21457;&#29616;&#22522;&#20110;&#26657;&#20934;&#30340;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#38408;&#20540;&#35843;&#25972;&#65292;&#32780;&#26222;&#36890;&#25552;&#31034;&#26080;&#27861;&#26377;&#25928;&#24341;&#23548;LLMs&#20570;&#20986;&#21487;&#38752;&#30340;&#26816;&#32034;&#20915;&#31574;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;Time-Aware Adaptive Retrieval&#65288;TA-ARE&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16457v1 Announce Type: new  Abstract: Adaptive retrieval-augmented generation (ARAG) aims to dynamically determine the necessity of retrieval for queries instead of retrieving indiscriminately to enhance the efficiency and relevance of the sourced information. However, previous works largely overlook the evaluation of ARAG approaches, leading to their effectiveness being understudied. This work presents a benchmark, RetrievalQA, comprising 1,271 short-form questions covering new world and long-tail knowledge. The knowledge necessary to answer the questions is absent from LLMs; therefore, external information must be retrieved to answer correctly. This makes RetrievalQA a suitable testbed to evaluate existing ARAG methods. We observe that calibration-based methods heavily rely on threshold tuning, while vanilla prompting is inadequate for guiding LLMs to make reliable retrieval decisions. Based on our findings, we propose Time-Aware Adaptive Retrieval (TA-ARE), a simple yet e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;LLMs&#25506;&#32034;&#27010;&#24565;&#31354;&#38388;&#32500;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#20307;&#25490;&#21517;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20854;&#22312;&#24863;&#30693;&#21644;&#20027;&#35266;&#29305;&#24449;&#19978;&#30340;&#36716;&#31227;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.15337</link><description>&lt;p&gt;
&#20351;&#29992;LLMs&#27839;&#30528;&#27010;&#24565;&#31354;&#38388;&#32500;&#24230;&#23545;&#23454;&#20307;&#36827;&#34892;&#25490;&#21517;&#65306;&#24494;&#35843;&#31574;&#30053;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;LLMs&#25506;&#32034;&#27010;&#24565;&#31354;&#38388;&#32500;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#20307;&#25490;&#21517;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20854;&#22312;&#24863;&#30693;&#21644;&#20027;&#35266;&#29305;&#24449;&#19978;&#30340;&#36716;&#31227;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#31354;&#38388;&#20197;&#23454;&#20307;&#30340;&#21407;&#22987;&#35821;&#20041;&#29305;&#24449;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#38750;&#24120;&#26377;&#20215;&#20540;&#65292;&#20294;&#23398;&#20064;&#36215;&#26469;&#38750;&#24120;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#22312;&#24314;&#27169;&#24863;&#30693;&#21644;&#20027;&#35266;&#29305;&#24449;&#26102;&#12290;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#25552;&#28860;&#27010;&#24565;&#31354;&#38388;&#26368;&#36817;&#20986;&#29616;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#24037;&#20316;&#20165;&#38480;&#20110;&#20351;&#29992;&#30456;&#23545;&#31616;&#21333;&#30340;&#38646;&#26679;&#26412;&#31574;&#30053;&#25506;&#26597;&#39044;&#35757;&#32451;&#30340;LLMs&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#26681;&#25454;&#32473;&#23450;&#30340;&#27010;&#24565;&#31354;&#38388;&#32500;&#24230;&#23545;&#23454;&#20307;&#36827;&#34892;&#25490;&#21517;&#30340;&#20219;&#21153;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#27010;&#24565;&#31354;&#38388;&#32500;&#24230;&#30340;&#30495;&#23454;&#25490;&#21517;&#24456;&#23569;&#35265;&#65292;&#25105;&#20204;&#26080;&#27861;&#30452;&#25509;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#24494;&#35843;LLMs&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#26356;&#23481;&#26131;&#33719;&#24471;&#30340;&#29305;&#24449;&#20316;&#20026;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#20998;&#26512;&#30001;&#27492;&#20135;&#29983;&#30340;&#27169;&#22411;&#30340;&#25490;&#21517;&#33021;&#21147;&#26159;&#21542;&#33021;&#36716;&#31227;&#21040;&#24863;&#30693;&#21644;&#20027;&#35266;&#29305;&#24449;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#30830;&#23454;&#26159;&#36825;&#31181;&#24773;&#20917;&#65292;&#20294;&#26159;&#26410;&#23436;&#25104;&#30340;&#21477;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15337v1 Announce Type: new  Abstract: Conceptual spaces represent entities in terms of their primitive semantic features. Such representations are highly valuable but they are notoriously difficult to learn, especially when it comes to modelling perceptual and subjective features. Distilling conceptual spaces from Large Language Models (LLMs) has recently emerged as a promising strategy. However, existing work has been limited to probing pre-trained LLMs using relatively simple zero-shot strategies. We focus in particular on the task of ranking entities according to a given conceptual space dimension. Unfortunately, we cannot directly fine-tune LLMs on this task, because ground truth rankings for conceptual space dimensions are rare. We therefore use more readily available features as training data and analyse whether the ranking capabilities of the resulting models transfer to perceptual and subjective features. We find that this is indeed the case, to some extent, but havi
&lt;/p&gt;</description></item><item><title>&#19981;&#38656;&#35201;&#22522;&#20934;&#23454;&#20917;&#25110;&#21442;&#32771;&#21709;&#24212;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#32771;&#34385;&#27169;&#22411;&#30340;&#19977;&#20803;&#32452;&#26469;&#25490;&#21517;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#25490;&#21517;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.14860</link><description>&lt;p&gt;
&#22312;&#27809;&#26377;&#22522;&#20934;&#23454;&#20917;&#30340;&#24773;&#20917;&#19979;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Ranking Large Language Models without Ground Truth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14860
&lt;/p&gt;
&lt;p&gt;
&#19981;&#38656;&#35201;&#22522;&#20934;&#23454;&#20917;&#25110;&#21442;&#32771;&#21709;&#24212;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#32771;&#34385;&#27169;&#22411;&#30340;&#19977;&#20803;&#32452;&#26469;&#25490;&#21517;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#25490;&#21517;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26222;&#21450;&#21644;&#24433;&#21709;&#21147;&#30340;&#22686;&#24378;&#65292;&#35780;&#20272;&#21644;&#25490;&#21517;LLMs&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#35780;&#20272;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#33719;&#21462;&#26114;&#36149;&#30340;&#20154;&#31867;&#21709;&#24212;&#65292;&#35201;&#20040;&#20351;&#29992;LLMs&#25104;&#23545;&#22320;&#20114;&#30456;&#35780;&#20272;&#65292;&#36825;&#21487;&#33021;&#19981;&#22815;&#21487;&#38752;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;&#65292;&#22312;&#32473;&#23450;&#19968;&#32452;&#25552;&#31034;&#25968;&#25454;&#38598;&#65288;&#27604;&#22914;&#38382;&#39064;&#12289;&#35828;&#26126;&#31561;&#65289;&#21644;&#19968;&#32452;LLMs&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#20219;&#20309;&#22522;&#20934;&#23454;&#20917;&#25110;&#21442;&#32771;&#21709;&#24212;&#30340;&#24773;&#20917;&#19979;&#23545;&#23427;&#20204;&#36827;&#34892;&#25490;&#21517;&#12290;&#21463;&#21040;&#29616;&#23454;&#29983;&#27963;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#19987;&#23478;&#21644;&#26377;&#30693;&#35782;&#30340;&#20154;&#37117;&#33021;&#35782;&#21035;&#19968;&#20010;&#26032;&#25163;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#24605;&#36335;&#26159;&#32771;&#34385;&#27169;&#22411;&#30340;&#19977;&#20803;&#32452;&#65292;&#20854;&#20013;&#27599;&#20010;&#27169;&#22411;&#35780;&#20272;&#20854;&#20182;&#20004;&#20010;&#27169;&#22411;&#65292;&#33021;&#22815;&#20197;&#24456;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#35782;&#21035;&#26368;&#24046;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#24819;&#27861;&#24182;&#25552;&#20379;&#20102;&#25104;&#21151;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#36890;&#36807;&#21453;&#22797;&#24212;&#29992;&#36825;&#19968;&#24819;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#23545;LLMs&#36827;&#34892;&#25490;&#21517;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14860v1 Announce Type: cross  Abstract: Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In this paper, we provide a novel perspective where, given a dataset of prompts (viz. questions, instructions, etc.) and a set of LLMs, we rank them without access to any ground truth or reference responses. Inspired by real life where both an expert and a knowledgeable person can identify a novice our main idea is to consider triplets of models, where each one of them evaluates the other two, correctly identifying the worst model in the triplet with high probability. We also analyze our idea and provide sufficient conditions for it to succeed. Applying this idea repeatedly, we propose two methods to rank LLMs. In experiments on different generati
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#38544;&#31192;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#24494;&#35843;&#25991;&#26412;&#20869;&#23481;&#22312;&#19981;&#24178;&#39044;&#27169;&#22411;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#29289;&#21697;&#30340;&#26333;&#20809;&#24230;&#65292;&#32780;&#36825;&#31181;&#25915;&#20987;&#23545;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#26080;&#24433;&#21709;&#19988;&#38590;&#20197;&#34987;&#26816;&#27979;&#21040;&#12290;</title><link>https://arxiv.org/abs/2402.14836</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#20013;&#30340;&#38544;&#31192;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Stealthy Attack on Large Language Model based Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14836
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#31995;&#32479;&#23481;&#26131;&#21463;&#21040;&#38544;&#31192;&#25915;&#20987;&#65292;&#25915;&#20987;&#32773;&#21487;&#20197;&#36890;&#36807;&#24494;&#35843;&#25991;&#26412;&#20869;&#23481;&#22312;&#19981;&#24178;&#39044;&#27169;&#22411;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#29289;&#21697;&#30340;&#26333;&#20809;&#24230;&#65292;&#32780;&#36825;&#31181;&#25915;&#20987;&#23545;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#26080;&#24433;&#21709;&#19988;&#38590;&#20197;&#34987;&#26816;&#27979;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25512;&#21160;&#25512;&#33616;&#31995;&#32479;(RS)&#30340;&#36827;&#23637;&#26041;&#38754;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#20123;&#31995;&#32479;&#34028;&#21187;&#21457;&#23637;&#65292;&#20294;&#23427;&#20204;&#23545;&#23433;&#20840;&#23041;&#32961;&#30340;&#25935;&#24863;&#24615;&#21364;&#34987;&#22823;&#22810;&#24573;&#35270;&#20102;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;LLMs&#24341;&#20837;&#25512;&#33616;&#27169;&#22411;&#20013;&#20135;&#29983;&#26032;&#23433;&#20840;&#28431;&#27934;&#30340;&#24773;&#20917;&#65292;&#36825;&#26159;&#30001;&#20110;&#23427;&#20204;&#27880;&#37325;&#29289;&#21697;&#30340;&#25991;&#26412;&#20869;&#23481;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25915;&#20987;&#32773;&#21487;&#20197;&#22312;&#27979;&#35797;&#38454;&#27573;&#20165;&#36890;&#36807;&#25913;&#21464;&#29289;&#21697;&#30340;&#25991;&#26412;&#20869;&#23481;&#26174;&#33879;&#22686;&#21152;&#20854;&#26333;&#20809;&#24230;&#65292;&#32780;&#26080;&#38656;&#30452;&#25509;&#24178;&#39044;&#27169;&#22411;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#35813;&#25915;&#20987;&#20855;&#26377;&#26174;&#33879;&#30340;&#38544;&#31192;&#24615;&#65292;&#22240;&#20026;&#23427;&#19981;&#20250;&#24433;&#21709;&#25972;&#20307;&#25512;&#33616;&#24615;&#33021;&#65292;&#23545;&#25991;&#26412;&#30340;&#20462;&#25913;&#24494;&#22937;&#65292;&#20351;&#29992;&#25143;&#21644;&#24179;&#21488;&#38590;&#20197;&#26816;&#27979;&#21040;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#20027;&#27969;&#30340;LLM-based&#25512;&#33616;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14836v1 Announce Type: cross  Abstract: Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item's exposure by merely altering its textual content during the testing phase, without requiring direct interference with the model's training process. Additionally, the attack is notably stealthy, as it does not affect the overall recommendation performance and the modifications to the text are subtle, making it difficult for users and platforms to detect. Our comprehensive experiments across four mainstream LLM-based recommendation models demonstrate the superior
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;CODIS&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#21033;&#29992;&#33258;&#30001;&#24418;&#24335;&#25991;&#26412;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#26469;&#22686;&#24378;&#35270;&#35273;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27492;&#22522;&#20934;&#19978;&#34920;&#29616;&#26410;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#65292;&#38656;&#35201;&#25552;&#21319;&#27169;&#22411;&#29702;&#35299;&#35270;&#35273;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.13607</link><description>&lt;p&gt;
CODIS&#65306;&#20026;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22522;&#20934;&#21270;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#35270;&#35273;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
CODIS: Benchmarking Context-Dependent Visual Comprehension for Multimodal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13607
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;CODIS&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#21033;&#29992;&#33258;&#30001;&#24418;&#24335;&#25991;&#26412;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#26469;&#22686;&#24378;&#35270;&#35273;&#29702;&#35299;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27492;&#22522;&#20934;&#19978;&#34920;&#29616;&#26410;&#36798;&#21040;&#20154;&#31867;&#27700;&#24179;&#65292;&#38656;&#35201;&#25552;&#21319;&#27169;&#22411;&#29702;&#35299;&#35270;&#35273;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;MLLMs&#65289;&#22312;&#32467;&#21512;&#35270;&#35273;&#21644;&#35821;&#35328;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#22312;&#30740;&#31350;&#21644;&#24212;&#29992;&#20013;&#21464;&#24471;&#26356;&#21152;&#37325;&#35201;&#65292;&#23545;&#23427;&#20204;&#33021;&#21147;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#30340;&#37325;&#35201;&#24615;&#20063;&#26085;&#30410;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#26410;&#32771;&#34385;&#21040;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#22270;&#20687;&#38656;&#35201;&#22312;&#26356;&#24191;&#27867;&#30340;&#19978;&#19979;&#25991;&#20013;&#34987;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;CODIS&#30340;&#26032;&#22522;&#20934;&#65292;&#26088;&#22312;&#35780;&#20272;&#27169;&#22411;&#20351;&#29992;&#22312;&#33258;&#30001;&#24418;&#24335;&#25991;&#26412;&#20013;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#26469;&#22686;&#24378;&#35270;&#35273;&#29702;&#35299;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;MLLMs&#22312;&#36825;&#20010;&#22522;&#20934;&#19978;&#22987;&#32456;&#26080;&#27861;&#36798;&#21040;&#20154;&#31867;&#34920;&#29616;&#12290;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#35777;&#23454;&#20102;&#36825;&#20123;&#27169;&#22411;&#38590;&#20197;&#26377;&#25928;&#25552;&#21462;&#21644;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#20197;&#25552;&#39640;&#23427;&#20204;&#23545;&#22270;&#20687;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;&#36825;&#20984;&#26174;&#20102;&#25552;&#21319;MLLMs&#29702;&#35299;&#35270;&#35273;&#33021;&#21147;&#30340;&#36843;&#20999;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13607v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have demonstrated promising results in a variety of tasks that combine vision and language. As these models become more integral to research and applications, conducting comprehensive evaluations of their capabilities has grown increasingly important. However, most existing benchmarks fail to consider that, in certain situations, images need to be interpreted within a broader context. In this work, we introduce a new benchmark, named as CODIS, designed to assess the ability of models to use context provided in free-form text to enhance visual comprehension. Our findings indicate that MLLMs consistently fall short of human performance on this benchmark. Further analysis confirms that these models struggle to effectively extract and utilize contextual information to improve their understanding of images. This underscores the pressing need to enhance the ability of MLLMs to comprehend visuals in a 
&lt;/p&gt;</description></item><item><title>&#22810;&#28304;&#35821;&#35328;&#35757;&#32451;&#65288;MSLT&#65289;&#25216;&#26415;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#28304;&#35821;&#35328;&#65292;&#22312;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#22686;&#21152;&#20102;&#19981;&#21516;&#35821;&#35328;&#23884;&#20837;&#31354;&#38388;&#30340;&#20132;&#32455;&#65292;&#20174;&#32780;&#25903;&#25345;&#20102;XLT&#21463;&#30410;&#20110;&#36825;&#31181;&#26041;&#27861;&#30340;&#35828;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.13562</link><description>&lt;p&gt;
&#22810;&#28304;&#35821;&#35328;&#35757;&#32451;&#22312;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of Multi-Source Language Training in Cross-Lingual Transfer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13562
&lt;/p&gt;
&lt;p&gt;
&#22810;&#28304;&#35821;&#35328;&#35757;&#32451;&#65288;MSLT&#65289;&#25216;&#26415;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#28304;&#35821;&#35328;&#65292;&#22312;&#36328;&#35821;&#35328;&#36716;&#31227;&#20013;&#22686;&#21152;&#20102;&#19981;&#21516;&#35821;&#35328;&#23884;&#20837;&#31354;&#38388;&#30340;&#20132;&#32455;&#65292;&#20174;&#32780;&#25903;&#25345;&#20102;XLT&#21463;&#30410;&#20110;&#36825;&#31181;&#26041;&#27861;&#30340;&#35828;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21151;&#22320;&#23558;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#35843;&#25972;&#21040;&#29305;&#23450;&#35821;&#35328;-&#20219;&#21153;&#23545;&#19978;&#33267;&#20851;&#37325;&#35201;&#30340;&#26159;&#23450;&#21046;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#12290;&#34429;&#28982;&#36328;&#35821;&#35328;&#36716;&#31227;&#65288;XLT&#65289;&#26041;&#27861;&#26377;&#21161;&#20110;&#35299;&#20915;&#36825;&#31181;&#25968;&#25454;&#31232;&#32570;&#38382;&#39064;&#65292;&#20294;&#20851;&#20110;&#20854;&#26377;&#25928;&#24615;&#32972;&#21518;&#30340;&#26426;&#21046;&#20173;&#23384;&#22312;&#25345;&#32493;&#30340;&#35752;&#35770;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#20102;&#20851;&#20110;XLT&#20869;&#37096;&#24037;&#20316;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#20551;&#35774;&#65292;&#21363;&#23427;&#40723;&#21169;&#22810;&#35821;&#35328;LMs&#26356;&#21152;&#24378;&#35843;&#35821;&#35328;&#19981;&#21487;&#30693;&#25110;&#20219;&#21153;&#29305;&#23450;&#29305;&#24449;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#23519;XLT&#38543;&#28041;&#21450;&#36807;&#31243;&#20013;&#28304;&#35821;&#35328;&#25968;&#37327;&#30340;&#21464;&#21270;&#32780;&#25913;&#21464;&#30340;&#27169;&#24335;&#26469;&#27979;&#35797;&#36825;&#19968;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;XLT&#20013;&#20351;&#29992;&#22810;&#20010;&#28304;&#35821;&#35328;-&#19968;&#31181;&#25105;&#20204;&#31216;&#20043;&#20026;&#22810;&#28304;&#35821;&#35328;&#35757;&#32451;&#65288;MSLT&#65289;&#30340;&#25216;&#26415;-&#20250;&#23548;&#33268;&#19981;&#21516;&#35821;&#35328;&#30340;&#23884;&#20837;&#31354;&#38388;&#30340;&#20132;&#32455;&#22686;&#21152;&#65292;&#25903;&#25345;&#20102;XLT&#21463;&#30410;&#20110;&#36825;&#19968;&#28857;&#30340;&#35828;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13562v1 Announce Type: new  Abstract: The successful adaptation of multilingual language models (LMs) to a specific language-task pair critically depends on the availability of data tailored for that condition. While cross-lingual transfer (XLT) methods have contributed to addressing this data scarcity problem, there still exists ongoing debate about the mechanisms behind their effectiveness. In this work, we focus on one of promising assumptions about inner workings of XLT, that it encourages multilingual LMs to place greater emphasis on language-agnostic or task-specific features. We test this hypothesis by examining how the patterns of XLT change with a varying number of source languages involved in the process. Our experimental findings show that the use of multiple source languages in XLT-a technique we term Multi-Source Language Training (MSLT)-leads to increased mingling of embedding spaces for different languages, supporting the claim that XLT benefits from making us
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#20854;&#23384;&#22312;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;&#38382;&#39064;&#65292;&#21363;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#36807;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#12290;</title><link>https://arxiv.org/abs/2402.13211</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#25104;&#20026;&#33391;&#22909;&#30340;&#24773;&#24863;&#25903;&#25345;&#32773;&#21527;&#65311;&#20943;&#36731;&#23545;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models be Good Emotional Supporter? Mitigating Preference Bias on Emotional Support Conversation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13211
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#20854;&#23384;&#22312;&#30340;&#20559;&#22909;&#24615;&#20559;&#24046;&#38382;&#39064;&#65292;&#21363;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#36807;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#25903;&#25345;&#23545;&#35805;&#65288;ESC&#65289;&#26159;&#19968;&#39033;&#26088;&#22312;&#36890;&#36807;&#26085;&#24120;&#23545;&#35805;&#32531;&#35299;&#20010;&#20307;&#24773;&#24863;&#22256;&#25200;&#30340;&#20219;&#21153;&#12290;&#37492;&#20110;&#20854;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#21644;&#38750;&#30452;&#35273;&#24615;&#36136;&#65292;ESConv&#25968;&#25454;&#38598;&#34701;&#20837;&#20102;&#25903;&#25345;&#31574;&#30053;&#65292;&#20197;&#20419;&#36827;&#29983;&#25104;&#36866;&#24403;&#30340;&#22238;&#24212;&#12290;&#26368;&#36817;&#65292;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20855;&#26377;&#21331;&#36234;&#30340;&#23545;&#35805;&#33021;&#21147;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#23427;&#20204;&#22312;&#25552;&#20379;&#26377;&#29992;&#30340;&#24773;&#24863;&#25903;&#25345;&#26041;&#38754;&#32463;&#24120;&#36935;&#21040;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#39318;&#20808;&#20998;&#26512;&#20102;LLMs&#22312;ESConv&#19978;&#30340;&#32467;&#26524;&#65292;&#25581;&#31034;&#20102;&#22312;&#36873;&#25321;&#27491;&#30830;&#31574;&#30053;&#21644;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#26174;&#33879;&#20559;&#22909;&#26041;&#38754;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#20010;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;LLMs&#22266;&#26377;&#20559;&#22909;&#23545;&#25552;&#20379;&#24773;&#24863;&#25903;&#25345;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#23637;&#29616;&#20986;&#23545;&#29305;&#23450;&#31574;&#30053;&#30340;&#39640;&#20559;&#22909;&#20250;&#38459;&#30861;&#26377;&#25928;&#30340;&#24773;&#24863;&#25903;&#25345;&#65292;&#21152;&#21095;&#20854;&#22312;&#39044;&#27979;&#36866;&#24403;&#31574;&#30053;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13211v1 Announce Type: new  Abstract: Emotional Support Conversation (ESC) is a task aimed at alleviating individuals' emotional distress through daily conversation. Given its inherent complexity and non-intuitive nature, ESConv dataset incorporates support strategies to facilitate the generation of appropriate responses. Recently, despite the remarkable conversational ability of large language models (LLMs), previous studies have suggested that they often struggle with providing useful emotional support. Hence, this work initially analyzes the results of LLMs on ESConv, revealing challenges in selecting the correct strategy and a notable preference for a specific strategy. Motivated by these, we explore the impact of the inherent preference in LLMs on providing emotional support, and consequently, we observe that exhibiting high preference for specific strategies hinders effective emotional support, aggravating its robustness in predicting the appropriate strategy. Moreover
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#22810;&#26679;&#21270;&#30340;&#26368;&#26032;&#33521;&#35821;&#26032;&#35789;&#36164;&#28304;&#65292;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20110;&#26032;&#35789;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#23545;&#26032;&#35789;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#26426;&#22120;&#32763;&#35793;&#20013;&#27169;&#22411;&#24615;&#33021;&#20250;&#22240;&#24341;&#20837;&#26032;&#35789;&#32780;&#20960;&#20046;&#20943;&#21322;&#12290;</title><link>https://arxiv.org/abs/2402.12261</link><description>&lt;p&gt;
NEO-BENCH&#65306;&#20351;&#29992;&#26032;&#35789;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#22810;&#26679;&#21270;&#30340;&#26368;&#26032;&#33521;&#35821;&#26032;&#35789;&#36164;&#28304;&#65292;&#20998;&#26512;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#20110;&#26032;&#35789;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#23545;&#26032;&#35789;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32467;&#26524;&#26174;&#31034;&#26426;&#22120;&#32763;&#35793;&#20013;&#27169;&#22411;&#24615;&#33021;&#20250;&#22240;&#24341;&#20837;&#26032;&#35789;&#32780;&#20960;&#20046;&#20943;&#21322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs)&#30340;&#34920;&#29616;&#20250;&#22240;&#27169;&#22411;&#35757;&#32451;&#25968;&#25454;&#19982;&#25512;&#29702;&#36807;&#31243;&#20013;&#30475;&#21040;&#30340;&#26032;&#25991;&#26412;&#20043;&#38388;&#30340;&#26102;&#38388;&#28418;&#31227;&#32780;&#36864;&#21270;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23548;&#33268;&#25968;&#25454;&#28418;&#31227;&#30340;&#35821;&#35328;&#21464;&#21270;&#20013;&#19968;&#20010;&#19981;&#22826;&#34987;&#30740;&#31350;&#30340;&#26041;&#21521;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#25512;&#31227;&#32780;&#20986;&#29616;&#30340;&#26032;&#35789;&#24418;&#24335;&#8212;&#8212;&#26032;&#35789;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20960;&#31181;&#27969;&#34892;&#30340;&#25910;&#38598;&#26041;&#27861;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#26679;&#21270;&#30340;&#26368;&#26032;&#33521;&#35821;&#26032;&#35789;&#36164;&#28304;&#12290;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#21253;&#21547;&#26032;&#35789;&#30340;&#21477;&#23376;&#19982;&#23558;&#26032;&#35789;&#26367;&#25442;&#20026;&#29616;&#26377;&#26367;&#20195;&#35789;&#30340;&#20960;&#20046;&#30456;&#21516;&#30340;&#21477;&#23376;&#26469;&#20998;&#26512;&#26032;&#35789;&#23545;&#26102;&#38388;&#28418;&#31227;&#30340;&#24433;&#21709;&#12290;&#22312;&#21477;&#23376;&#20013;&#24341;&#20837;&#21333;&#20010;&#26032;&#35789;&#26102;&#65292;&#26426;&#22120;&#32763;&#35793;&#20013;&#30340;&#27169;&#22411;&#24615;&#33021;&#20960;&#20046;&#20943;&#21322;&#12290;&#21463;&#21040;&#36825;&#20123;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20934;&#26469;&#35780;&#20272;LLMs&#23545;&#19981;&#21516;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#20219;&#21153;&#21644;&#27169;&#22411;&#22256;&#24785;&#24230;&#20013;&#26032;&#35789;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#21518;&#26399;&#30693;&#35782;&#25130;&#27490;&#26085;&#26399;&#30340;&#27169;&#22411;&#20135;&#29983;&#36739;&#20302;&#30340;&#22256;&#24785;&#24230;&#65292;&#24182;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12261v1 Announce Type: new  Abstract: The performance of Large Language Models (LLMs) degrades from the temporal drift between data used for model training and newer text seen during inference. One understudied avenue of language change causing data drift is the emergence of neologisms -- new word forms -- over time. We create a diverse resource of recent English neologisms by using several popular collection methods. We analyze temporal drift using neologisms by comparing sentences containing new words with near-identical sentences that replace neologisms with existing substitute words. Model performance is nearly halved in machine translation when a single neologism is introduced in a sentence. Motivated by these results, we construct a benchmark to evaluate LLMs' ability to generalize to neologisms with various natural language understanding tasks and model perplexity. Models with later knowledge cutoff dates yield lower perplexities and perform better in downstream tasks
&lt;/p&gt;</description></item><item><title>LONDI&#26694;&#26550;&#21487;&#20197;&#22312;&#38656;&#35201;&#22797;&#26434;&#20915;&#31574;&#21644;&#25512;&#29702;&#30340;&#22320;&#26041;&#36873;&#25321;&#24615;&#22320;&#20351;&#29992;&#22823;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#26497;&#22823;&#22320;&#38477;&#20302;&#20102;&#36164;&#28304;&#28040;&#32791;&#12290;</title><link>https://arxiv.org/abs/2402.12061</link><description>&lt;p&gt;
&#25152;&#26377;&#35821;&#35328;&#27169;&#22411;&#30340;&#22823;&#23567;&#37117;&#19968;&#26679;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
All Language Models Large and Small
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12061
&lt;/p&gt;
&lt;p&gt;
LONDI&#26694;&#26550;&#21487;&#20197;&#22312;&#38656;&#35201;&#22797;&#26434;&#20915;&#31574;&#21644;&#25512;&#29702;&#30340;&#22320;&#26041;&#36873;&#25321;&#24615;&#22320;&#20351;&#29992;&#22823;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#26497;&#22823;&#22320;&#38477;&#20302;&#20102;&#36164;&#28304;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#39046;&#20808;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#22312;&#35757;&#32451;&#21644;&#25191;&#34892;&#36807;&#31243;&#20013;&#20351;&#29992;&#39640;&#24378;&#24230;&#35745;&#31639;&#36164;&#28304;&#65292;&#36825;&#23545;&#20110;&#38477;&#20302;&#37096;&#32626;&#36164;&#28304;&#25104;&#26412;&#21644;&#26356;&#24555;&#25191;&#34892;&#20915;&#31574;&#20219;&#21153;&#31561;&#26041;&#38754;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#35821;&#35328;&#20248;&#21270;&#32593;&#32476;&#20998;&#24067;&#65288;LONDI&#65289;&#26694;&#26550;&#30340;&#26032;&#22411;&#21363;&#25554;&#21363;&#29992;LM&#26694;&#26550;&#12290; LONDI&#23398;&#20250;&#20102;&#22312;&#38656;&#35201;&#36827;&#34892;&#22797;&#26434;&#20915;&#31574;&#21644;&#25512;&#29702;&#30340;&#22320;&#26041;&#36873;&#25321;&#24615;&#22320;&#20351;&#29992;&#22823;&#30340;LM&#65292;&#32780;&#22312;&#20854;&#20182;&#22320;&#26041;&#20351;&#29992;&#20302;&#36164;&#28304;&#30340;LM&#12290; LONDI&#30001;&#20004;&#20010;&#65288;&#31163;&#32447;&#65289;&#31574;&#30053;&#32593;&#32476;&#31995;&#32479;&#12289;&#19968;&#20010;LM&#12289;&#19968;&#20010;&#22823;&#30340;LM&#65288;LLM)&#21644;&#19968;&#20010;&#20351;&#29992;&#24320;&#20851;&#25511;&#21046;&#24555;&#36895;&#23398;&#20064;&#20309;&#26102;&#35843;&#29992;LLM&#30340;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#32452;&#25104;&#12290; &#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;LLM&#35843;&#29992;&#21644;&#36164;&#28304;&#20351;&#29992;&#26041;&#38754;&#20445;&#25345;&#39044;&#31639;&#32422;&#26463;&#30340;LONDI&#21464;&#20307;&#12290; &#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;LONDI&#23398;&#20064;&#28608;&#27963;&#25152;&#38656;&#35299;&#20915;&#20219;&#21153;&#30340;LLM&#30340;&#31995;&#32479;&#29366;&#24577;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12061v1 Announce Type: cross  Abstract: Many leading language models (LMs) use high-intensity computational resources both during training and execution. This poses the challenge of lowering resource costs for deployment and faster execution of decision-making tasks among others. We introduce a novel plug-and-play LM framework named Language Optimising Network Distribution (LONDI) framework. LONDI learns to selectively employ large LMs only where complex decision-making and reasoning are required while using low-resource LMs everywhere else. LONDI consists of a system of two (off-)policy networks, an LM, a large LM (LLM), and a reinforcement learning module that uses switching controls to quickly learn which system states to call the LLM. We then introduce a variant of LONDI that maintains budget constraints on LLM calls and hence its resource usage. Theoretically, we prove LONDI learns the subset of system states to activate the LLM required to solve the task. We then prove
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Learning to Edit&#65288;LTE&#65289;&#30340;&#26694;&#26550;&#65292;&#25945;&#23548;LLMs&#23558;&#26356;&#26032;&#21518;&#30340;&#30693;&#35782;&#24212;&#29992;&#20110;&#36755;&#20837;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#40784;&#38454;&#27573;&#21644;&#25512;&#29702;&#38454;&#27573;&#23454;&#29616;&#21487;&#38752;&#30340;&#12289;&#33539;&#22260;&#20869;&#30340;&#25991;&#26412;&#32534;&#36753;&#12290;</title><link>https://arxiv.org/abs/2402.11905</link><description>&lt;p&gt;
&#23398;&#20064;&#32534;&#20889;&#65306;&#23558;LLMs&#19982;&#30693;&#35782;&#32534;&#36753;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Learning to Edit: Aligning LLMs with Knowledge Editing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11905
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Learning to Edit&#65288;LTE&#65289;&#30340;&#26694;&#26550;&#65292;&#25945;&#23548;LLMs&#23558;&#26356;&#26032;&#21518;&#30340;&#30693;&#35782;&#24212;&#29992;&#20110;&#36755;&#20837;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#40784;&#38454;&#27573;&#21644;&#25512;&#29702;&#38454;&#27573;&#23454;&#29616;&#21487;&#38752;&#30340;&#12289;&#33539;&#22260;&#20869;&#30340;&#25991;&#26412;&#32534;&#36753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#32534;&#36753;&#25216;&#26415;&#26088;&#22312;&#39640;&#25928;&#20462;&#25913;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#30340;&#23569;&#37327;&#30693;&#35782;&#65292;&#32780;&#19981;&#20250;&#23545;&#20854;&#20182;&#36755;&#20837;&#30340;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#65292;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#35760;&#24518;&#26356;&#26032;&#21518;&#30340;&#30693;&#35782;&#65292;&#38459;&#30861;&#20102;LLMs&#26377;&#25928;&#22320;&#23558;&#26032;&#30693;&#35782;&#19982;&#20854;&#22266;&#26377;&#30693;&#35782;&#30456;&#32467;&#21512;&#20197;&#22238;&#31572;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#23398;&#20064;&#32534;&#20889;&#8221;&#65288;LTE&#65289;&#30340;&#26694;&#26550;&#65292;&#37325;&#28857;&#25945;&#23548;LLMs&#23558;&#26356;&#26032;&#21518;&#30340;&#30693;&#35782;&#24212;&#29992;&#20110;&#36755;&#20837;&#38382;&#39064;&#65292;&#28789;&#24863;&#26469;&#33258;&#20110;&#8220;&#25480;&#20154;&#20197;&#40060;&#19981;&#22914;&#25480;&#20154;&#20197;&#28180;&#8221;&#30340;&#29702;&#24565;&#12290;LTE&#20855;&#26377;&#20004;&#38454;&#27573;&#36807;&#31243;&#65306;&#65288;i&#65289;&#23545;&#40784;&#38454;&#27573;&#65292;&#36890;&#36807;&#22312;&#31934;&#24515;&#31579;&#36873;&#30340;&#24179;&#34892;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;LLMs&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#21487;&#38752;&#30340;&#12289;&#33539;&#22260;&#20869;&#30340;&#32534;&#36753;&#65292;&#21516;&#26102;&#20445;&#30041;&#33539;&#22260;&#22806;&#20449;&#24687;&#21644;&#35821;&#35328;&#33021;&#21147;&#65307;&#65288;ii&#65289;&#25512;&#29702;&#38454;&#27573;&#65292;&#37319;&#29992;&#22522;&#20110;&#26816;&#32034;&#30340;&#26426;&#21046;&#36827;&#34892;&#23454;&#26102;&#21644;&#22823;&#35268;&#27169;&#30693;&#35782;&#32534;&#36753;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11905v1 Announce Type: new  Abstract: Knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (LLMs) without negatively impacting performance across other inputs, have garnered widespread attention. However, existing methods predominantly rely on memorizing the updated knowledge, impeding LLMs from effectively combining the new knowledge with their inherent knowledge when answering questions. To this end, we propose a Learning to Edit (LTE) framework, focusing on teaching LLMs to apply updated knowledge into input questions, inspired by the philosophy of "Teach a man to fish." LTE features a two-phase process: (i) the Alignment Phase, which fine-tunes LLMs on a meticulously curated parallel dataset to make reliable, in-scope edits while preserving out-of-scope information and linguistic proficiency; and (ii) the Inference Phase, which employs a retrieval-based mechanism for real-time and mass knowledge editing. By c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;FactPICO&#65292;&#29992;&#20110;&#35780;&#20272;&#21307;&#23398;&#25991;&#26412;&#30340;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#30340;&#20107;&#23454;&#24615;&#22522;&#20934;&#65292;&#23545;RCT&#20013;&#30340;&#20851;&#38190;&#35201;&#32032;&#21644;&#25253;&#21578;&#32467;&#26524;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#23545;LLMs&#28155;&#21152;&#30340;&#39069;&#22806;&#20449;&#24687;&#36827;&#34892;&#26816;&#26597;&#12290;</title><link>https://arxiv.org/abs/2402.11456</link><description>&lt;p&gt;
FactPICO: &#21307;&#23398;&#35777;&#25454;&#30340;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#30340;&#20107;&#23454;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
FactPICO: Factuality Evaluation for Plain Language Summarization of Medical Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;FactPICO&#65292;&#29992;&#20110;&#35780;&#20272;&#21307;&#23398;&#25991;&#26412;&#30340;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#30340;&#20107;&#23454;&#24615;&#22522;&#20934;&#65292;&#23545;RCT&#20013;&#30340;&#20851;&#38190;&#35201;&#32032;&#21644;&#25253;&#21578;&#32467;&#26524;&#36827;&#34892;&#35780;&#20272;&#65292;&#24182;&#23545;LLMs&#28155;&#21152;&#30340;&#39069;&#22806;&#20449;&#24687;&#36827;&#34892;&#26816;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11456v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#21033;&#29992;LLMs&#36827;&#34892;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#21487;&#20197;&#25913;&#21892;&#25216;&#26415;&#20869;&#23481;&#30340;&#25991;&#26412;&#21487;&#35775;&#38382;&#24615;&#12290;&#20294;&#26159;&#22312;&#21307;&#23398;&#36825;&#26679;&#19968;&#20010;&#39640;&#39118;&#38505;&#39046;&#22495;&#65292;&#36825;&#20123;&#25688;&#35201;&#26377;&#22810;&#30495;&#23454;&#65311;&#26412;&#25991;&#20171;&#32461;&#20102;FactPICO&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#25551;&#36848;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCTs&#65289;&#30340;&#21307;&#23398;&#25991;&#26412;&#30340;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#30340;&#20107;&#23454;&#24615;&#22522;&#20934;&#65292;RCTs&#26159;&#24490;&#35777;&#21307;&#23398;&#30340;&#22522;&#30784;&#65292;&#21487;&#20197;&#30452;&#25509;&#20026;&#24739;&#32773;&#27835;&#30103;&#25552;&#20379;&#20449;&#24687;&#12290;FactPICO&#30001;&#26469;&#33258;&#19977;&#20010;LLMs&#65288;&#21363;GPT-4&#12289;Llama-2&#21644;Alpaca&#65289;&#29983;&#25104;&#30340;345&#20010;RCT&#25688;&#35201;&#30340;&#31616;&#26126;&#35821;&#35328;&#25688;&#35201;&#32452;&#25104;&#65292;&#20855;&#26377;&#19987;&#23478;&#32454;&#33268;&#35780;&#20272;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#30001;&#12290;&#25105;&#20204;&#35780;&#20272;&#36825;&#20123;&#25688;&#35201;&#20013;RCT&#30340;&#20851;&#38190;&#35201;&#32032;&#65288;&#20154;&#32676;&#12289;&#24178;&#39044;&#25514;&#26045;&#12289;&#23545;&#29031;&#32452;&#12289;&#32467;&#26524;&#65288;PICO&#65289;&#65289;&#20197;&#21450;&#20851;&#20110;&#36825;&#20123;&#20869;&#23481;&#30340;&#25253;&#21578;&#21457;&#29616;&#30340;&#20107;&#23454;&#24615;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;LLMs&#28155;&#21152;&#30340;&#39069;&#22806;&#20449;&#24687;&#65288;&#20363;&#22914;&#35299;&#37322;&#65289;&#30340;&#27491;&#30830;&#24615;&#12290;&#20351;&#29992;FactPICO&#65292;&#25105;&#20204;&#23545;&#22810;&#20010;&#29616;&#26377;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11456v1 Announce Type: new  Abstract: Plain language summarization with LLMs can be useful for improving textual accessibility of technical content. But how factual are these summaries in a high-stakes domain like medicine? This paper presents FactPICO, a factuality benchmark for plain language summarization of medical texts describing randomized controlled trials (RCTs), which are the basis of evidence-based medicine and can directly inform patient treatment. FactPICO consists of 345 plain language summaries of RCT abstracts generated from three LLMs (i.e., GPT-4, Llama-2, and Alpaca), with fine-grained evaluation and natural language rationales from experts. We assess the factuality of critical elements of RCTs in those summaries: Populations, Interventions, Comparators, Outcomes (PICO), as well as the reported findings concerning these. We also evaluate the correctness of the extra information (e.g., explanations) added by LLMs. Using FactPICO, we benchmark a range of exi
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;WilKE&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#32534;&#36753;&#23618;&#26469;&#21305;&#37197;&#19981;&#21516;&#23618;&#32423;&#20013;&#30340;&#30693;&#35782;&#32534;&#36753;&#27169;&#24335;&#31243;&#24230;&#65292;&#22312;&#32456;&#36523;&#32534;&#36753;&#20013;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#24179;&#22343;&#23637;&#29616;&#20102;46.2%&#21644;67.8%&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.10987</link><description>&lt;p&gt;
WilKE&#65306;&#26234;&#24935;&#23618;&#30693;&#35782;&#32534;&#36753;&#22120;&#29992;&#20110;&#32456;&#36523;&#30693;&#35782;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
WilKE: Wise-Layer Knowledge Editor for Lifelong Knowledge Editing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10987
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;WilKE&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#32534;&#36753;&#23618;&#26469;&#21305;&#37197;&#19981;&#21516;&#23618;&#32423;&#20013;&#30340;&#30693;&#35782;&#32534;&#36753;&#27169;&#24335;&#31243;&#24230;&#65292;&#22312;&#32456;&#36523;&#32534;&#36753;&#20013;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#24179;&#22343;&#23637;&#29616;&#20102;46.2%&#21644;67.8%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#32534;&#36753;&#26088;&#22312;&#32416;&#27491;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#30340;&#19981;&#20934;&#30830;&#24615;&#65292;&#32780;&#26080;&#38656;&#20026;&#36807;&#26102;&#25110;&#38169;&#35823;&#30340;&#30693;&#35782;&#36827;&#34892;&#26114;&#36149;&#30340;&#37325;&#26032;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#20110;&#21333;&#27425;&#32534;&#36753;&#65292;&#26410;&#33021;&#28385;&#36275;&#32456;&#36523;&#32534;&#36753;&#30340;&#35201;&#27714;&#12290;&#26412;&#25991;&#20013;&#65292;&#32456;&#36523;&#32534;&#36753;&#19982;&#32456;&#36523;&#30693;&#35782;&#32534;&#36753;&#21516;&#20041;&#12290;&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#30693;&#35782;&#32534;&#36753;&#22312;&#32456;&#36523;&#32534;&#36753;&#20013;&#36935;&#21040;&#30340;&#24615;&#33021;&#19979;&#38477;&#38382;&#39064;&#65292;&#20854;&#29305;&#24449;&#20026;&#27602;&#24615;&#31215;&#32047;&#21644;&#27602;&#24615;&#38378;&#29616;&#65292;&#20027;&#35201;&#21407;&#22240;&#26159;&#27169;&#24335;&#19981;&#21305;&#37197;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;WilKE&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;&#23427;&#26681;&#25454;&#19981;&#21516;&#23618;&#32423;&#20013;&#32534;&#36753;&#30693;&#35782;&#30340;&#27169;&#24335;&#21305;&#37197;&#31243;&#24230;&#36873;&#25321;&#32534;&#36753;&#23618;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#32456;&#36523;&#32534;&#36753;&#20013;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#65292;WilKE&#22312;&#32534;&#36753;GPT2-XL&#21644;GPT-J&#26041;&#38754;&#20998;&#21035;&#24179;&#22343;&#25913;&#36827;&#20102;46.2%&#21644;67.8%&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10987v1 Announce Type: cross  Abstract: Knowledge editing aims to rectify inaccuracies in large language models (LLMs) without costly retraining for outdated or erroneous knowledge. However, current knowledge editing methods primarily focus on single editing, failing to meet the requirements for lifelong editing. In this paper, lifelong editing is synonymous with lifelong knowledge editing. This study reveals a performance degradation encountered by knowledge editing in lifelong editing, characterized by toxicity buildup and toxicity flash, with the primary cause identified as pattern unmatch. We introduce a knowledge editing approach named WilKE, which selects editing layer based on the pattern matching degree of editing knowledge across different layers. Experimental results demonstrate that, in lifelong editing, WilKE exhibits an average improvement of 46.2\% and 67.8\% on editing GPT2-XL and GPT-J relative to state-of-the-art knowledge editing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#32447;&#24615;&#21464;&#25442;&#22120;&#19982;&#21463;&#25351;&#25968;&#20989;&#25968;&#30340;Taylor&#23637;&#24320;&#21551;&#21457;&#30340;&#26680;&#20989;&#25968;&#21644;&#21367;&#31215;&#32593;&#32476;&#30456;&#32467;&#21512;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20248;&#21270;&#20854;In-Context Learning&#33021;&#21147;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.10644</link><description>&lt;p&gt;
&#20855;&#26377;&#21487;&#23398;&#20064;&#26680;&#20989;&#25968;&#30340;&#32447;&#24615;&#21464;&#25442;&#22120;&#22312;&#19978;&#19979;&#25991;&#27169;&#22411;&#20013;&#34920;&#29616;&#26356;&#22909;
&lt;/p&gt;
&lt;p&gt;
Linear Transformers with Learnable Kernel Functions are Better In-Context Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#32447;&#24615;&#21464;&#25442;&#22120;&#19982;&#21463;&#25351;&#25968;&#20989;&#25968;&#30340;Taylor&#23637;&#24320;&#21551;&#21457;&#30340;&#26680;&#20989;&#25968;&#21644;&#21367;&#31215;&#32593;&#32476;&#30456;&#32467;&#21512;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#20248;&#21270;&#20854;In-Context Learning&#33021;&#21147;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#27425;&#20108;&#27425;&#20307;&#31995;&#32467;&#26500;&#30340;&#21069;&#27839;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#19981;&#26029;&#21457;&#23637;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#25913;&#36827;&#30340;&#26680;&#20989;&#25968;&#65292;&#22686;&#24378;&#20102;&#20854;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#22312;Multi-Query Associative Recall&#20219;&#21153;&#21644;&#25972;&#20307;&#35821;&#35328;&#24314;&#27169;&#36807;&#31243;&#20013;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10644v1 Announce Type: new  Abstract: Advancing the frontier of subquadratic architectures for Language Models (LMs) is crucial in the rapidly evolving field of natural language processing. Current innovations, including State Space Models, were initially celebrated for surpassing Transformer performance on language modeling tasks. However, these models have revealed deficiencies in essential In-Context Learning capabilities - a domain where the Transformer traditionally shines. The Based model emerged as a hybrid solution, blending a Linear Transformer with a kernel inspired by the Taylor expansion of exponential functions, augmented by convolutional networks. Mirroring the Transformer's in-context adeptness, it became a strong contender in the field. In our work, we present a singular, elegant alteration to the Based kernel that amplifies its In-Context Learning abilities evaluated with the Multi-Query Associative Recall task and overall language modeling process, as demon
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Active Preference Optimization&#31639;&#27861;&#65292;&#22312;Bradley-Terry-Luce&#20559;&#22909;&#27169;&#22411;&#19979;&#23454;&#29616;&#20102;RLHF&#30340;&#26679;&#26412;&#25928;&#29575;&#25552;&#39640;&#65292;&#20248;&#21270;&#20102;&#23545;&#25552;&#31034;&#25910;&#38598;&#20559;&#22909;&#25968;&#25454;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.10500</link><description>&lt;p&gt;
&#36890;&#36807;&#20027;&#21160;&#20559;&#22909;&#20248;&#21270;&#23454;&#29616;&#32463;&#39564;&#35777;&#30340;&#26679;&#26412;&#25928;&#29575;&#30340;RLHF
&lt;/p&gt;
&lt;p&gt;
Provably Sample Efficient RLHF via Active Preference Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10500
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Active Preference Optimization&#31639;&#27861;&#65292;&#22312;Bradley-Terry-Luce&#20559;&#22909;&#27169;&#22411;&#19979;&#23454;&#29616;&#20102;RLHF&#30340;&#26679;&#26412;&#25928;&#29575;&#25552;&#39640;&#65292;&#20248;&#21270;&#20102;&#23545;&#25552;&#31034;&#25910;&#38598;&#20559;&#22909;&#25968;&#25454;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;RLHF&#65289;&#22312;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#30456;&#19968;&#33268;&#26041;&#38754;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#36825;&#20123;&#23545;&#40784;&#30340;&#29983;&#25104;&#27169;&#22411;&#24050;&#32463;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#65292;&#20294;&#26159;&#20381;&#36182;&#39640;&#36136;&#37327;&#30340;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#22312;&#23454;&#38469;RLHF&#23454;&#26045;&#20013;&#26500;&#25104;&#20102;&#26114;&#36149;&#30340;&#29942;&#39048;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#26356;&#22909;&#21644;&#33258;&#36866;&#24212;&#30340;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;RLHF&#20197;&#19978;&#19979;&#25991;&#20559;&#22909;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#24418;&#24335;&#26694;&#23450;&#65292;&#20854;&#20013;&#25552;&#31034;&#20316;&#20026;&#19978;&#19979;&#25991;&#65292;&#24182;&#34920;&#26126;&#36890;&#36807;&#38543;&#26426;&#36873;&#25321;&#25552;&#31034;&#25910;&#38598;&#20559;&#22909;&#25968;&#25454;&#30340;&#22825;&#30495;&#26041;&#24335;&#23548;&#33268;&#19968;&#20010;&#22312;&#22870;&#21169;&#26041;&#38754;&#20855;&#26377;$\Omega(1)$&#27425;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\textit{Active Preference Optimization}$&#65288;$\texttt{APO}$&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31215;&#26497;&#36873;&#25321;&#25552;&#31034;&#20197;&#25910;&#38598;&#20559;&#22909;&#25968;&#25454;&#12290;&#22312;Bradley-Terry-Luce&#65288;BTL&#65289;&#20559;&#22909;&#27169;&#22411;&#19979;&#65292;\texttt{APO}&#23454;&#29616;&#20102;&#26679;&#26412;&#25928;&#29575;&#65292;&#32780;&#19981;&#20250;&#22949;&#21327;&#20110;polic
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10500v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) is pivotal in aligning Large Language Models (LLMs) with human preferences. While these aligned generative models have demonstrated impressive capabilities across various tasks, the dependence on high-quality human preference data poses a costly bottleneck in practical implementation of RLHF. Hence better and adaptive strategies for data collection is needed. To this end, we frame RLHF as a contextual preference bandit problem with prompts as contexts and show that the naive way of collecting preference data by choosing prompts uniformly at random leads to a policy that suffers an $\Omega(1)$ suboptimality gap in rewards. Then we propose $\textit{Active Preference Optimization}$ ($\texttt{APO}$), an algorithm that actively selects prompts to collect preference data. Under the Bradley-Terry-Luce (BTL) preference model, \texttt{APO} achieves sample efficiency without compromising on polic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22810;&#20010;&#22870;&#21169;&#26465;&#20214;&#25511;&#21046;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#36827;&#34892;&#23545;&#40784;&#12290;&#23427;&#20855;&#26377;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.10207</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#30340;&#22870;&#21169;&#65306;&#22522;&#20110;&#21160;&#24577;&#20559;&#22909;&#35843;&#25972;&#30340;&#22810;&#30446;&#26631;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10207
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22810;&#20010;&#22870;&#21169;&#26465;&#20214;&#25511;&#21046;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#36827;&#34892;&#23545;&#40784;&#12290;&#23427;&#20855;&#26377;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#22522;&#30784;&#27169;&#22411;&#22810;&#30446;&#26631;&#23545;&#40784;&#38382;&#39064;&#65292;&#36825;&#26159;&#23454;&#29616;&#26377;&#30410;&#21644;&#26080;&#23475;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23545;&#22823;&#22411;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#36890;&#24120;&#26159;&#26114;&#36149;&#19988;&#19981;&#31283;&#23450;&#30340;&#65292;&#24182;&#19988;&#20154;&#31867;&#20559;&#22909;&#30340;&#22810;&#32500;&#24230;&#12289;&#24322;&#36136;&#24615;&#21644;&#20914;&#31361;&#24615;&#36827;&#19968;&#27493;&#22797;&#26434;&#21270;&#20102;&#23545;&#40784;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Rewards-in-Context&#65288;RiC&#65289;&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#22522;&#30784;&#27169;&#22411;&#30340;&#21709;&#24212;&#21462;&#20915;&#20110;&#20854;&#25552;&#31034;&#19978;&#19979;&#25991;&#20013;&#30340;&#22810;&#20010;&#22870;&#21169;&#65292;&#24182;&#24212;&#29992;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#26469;&#36827;&#34892;&#23545;&#40784;&#12290;RiC&#30340;&#26174;&#33879;&#29305;&#28857;&#26159;&#31616;&#21333;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#23545;&#21333;&#20010;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#26377;&#30417;&#30563;&#30340;&#24494;&#35843;&#65292;&#24182;&#25903;&#25345;&#22312;&#25512;&#29702;&#26102;&#21160;&#24577;&#35843;&#25972;&#29992;&#25143;&#20559;&#22909;&#12290;&#21463;&#21040;&#25277;&#35937;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26512;&#35299;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#25512;&#29702;&#26102;&#35843;&#25972;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10207v1 Announce Type: cross  Abstract: We consider the problem of multi-objective alignment of foundation models with human preferences, which is a critical step towards helpful and harmless AI systems. However, it is generally costly and unstable to fine-tune large foundation models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity, and conflicting nature of human preferences further complicate the alignment process. In this paper, we introduce Rewards-in-Context (RiC), which conditions the response of a foundation model on multiple rewards in its prompt context and applies supervised fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity, as it only requires supervised fine-tuning of a single foundation model and supports dynamic adjustment for user preferences during inference time. Inspired by the analytical solution of an abstracted convex optimization problem, our dynamic inference-time adjustment method appro
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26694;&#26550;SKU&#65292;&#26088;&#22312;&#28040;&#38500;&#26377;&#23475;&#30693;&#35782;&#30340;&#21516;&#26102;&#20445;&#30041;&#27169;&#22411;&#23545;&#27491;&#24120;&#25552;&#31034;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10058</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#36951;&#24536;&#23454;&#29616;&#26356;&#23433;&#20840;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Towards Safer Large Language Models through Machine Unlearning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10058
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36951;&#24536;&#26694;&#26550;SKU&#65292;&#26088;&#22312;&#28040;&#38500;&#26377;&#23475;&#30693;&#35782;&#30340;&#21516;&#26102;&#20445;&#30041;&#27169;&#22411;&#23545;&#27491;&#24120;&#25552;&#31034;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#24402;&#22240;&#20110;&#23427;&#20204;&#24191;&#27867;&#30340;&#39044;&#35757;&#32451;&#30693;&#35782;&#21644;&#20986;&#33394;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24403;LLM&#38754;&#23545;&#26377;&#38382;&#39064;&#30340;&#25552;&#31034;&#26102;&#65292;&#32463;&#24120;&#20250;&#36935;&#21040;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#23581;&#35797;&#36890;&#36807;&#26799;&#24230;&#19978;&#21319;&#26041;&#27861;&#38459;&#27490;LLM&#20135;&#29983;&#26377;&#23475;&#36755;&#20986;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#24433;&#21709;&#27169;&#22411;&#23545;&#27491;&#24120;&#25552;&#31034;&#30340;&#23454;&#29992;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36873;&#25321;&#24615;&#30693;&#35782;&#21542;&#35748;&#36951;&#24536;&#65288;SKU&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#38024;&#23545;LLM&#30340;&#36951;&#24536;&#26694;&#26550;&#65292;&#26088;&#22312;&#28040;&#38500;&#26377;&#23475;&#30693;&#35782;&#65292;&#21516;&#26102;&#20445;&#30041;&#23545;&#27491;&#24120;&#25552;&#31034;&#30340;&#23454;&#29992;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;SKU&#30001;&#20004;&#20010;&#38454;&#27573;&#32452;&#25104;&#65306;&#26377;&#23475;&#30693;&#35782;&#33719;&#21462;&#38454;&#27573;&#21644;&#30693;&#35782;&#21542;&#23450;&#38454;&#27573;&#12290;&#31532;&#19968;&#20010;&#38454;&#27573;&#26088;&#22312;&#35782;&#21035;&#21644;&#33719;&#21462;&#26377;&#23475;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10058v1 Announce Type: new  Abstract: The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with problematic prompts. To address this problem, existing work attempted to implement a gradient ascent based approach to prevent LLMs from producing harmful output. While these methods can be effective, they frequently impact the model utility in responding to normal prompts. To address this gap, we introduce Selective Knowledge negation Unlearning (SKU), a novel unlearning framework for LLMs, designed to eliminate harmful knowledge while preserving utility on normal prompts. Specifically, SKU is consisted of two stages: harmful knowledge acquisition stage and knowledge negation stage. The first stage aims to identify and acquire harmful knowledge within t
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#33258;&#23398;&#20064;&#19978;&#19979;&#25991;&#22686;&#24378;&#26041;&#27861;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#26080;&#30417;&#30563;&#35789;&#27719;&#32763;&#35793;&#30340;&#26041;&#27861;&#65292;&#22312;&#38646;&#26679;&#26412;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#22522;&#20110;&#26144;&#23556;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10024</link><description>&lt;p&gt;
&#33258;&#23398;&#20064;&#19978;&#19979;&#25991;&#22686;&#24378;&#23545;&#20110;&#26080;&#30417;&#30563;&#35789;&#27719;&#32763;&#35793;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Self-Augmented In-Context Learning for Unsupervised Word Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10024
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#23398;&#20064;&#19978;&#19979;&#25991;&#22686;&#24378;&#26041;&#27861;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#26080;&#30417;&#30563;&#35789;&#27719;&#32763;&#35793;&#30340;&#26041;&#27861;&#65292;&#22312;&#38646;&#26679;&#26412;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#22522;&#20110;&#26144;&#23556;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19968;&#20123;&#23567;&#35268;&#27169;&#30340;&#35774;&#32622;&#20013;&#23637;&#31034;&#20986;&#20102;&#36739;&#24378;&#30340;&#35789;&#27719;&#32763;&#35793;&#21644;&#21452;&#35821;&#35789;&#20856;&#35825;&#23548;(BLI)&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#26080;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#27809;&#26377;&#31181;&#23376;&#32763;&#35793;&#23545;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#36164;&#28304;&#36739;&#23569;&#30340;&#35821;&#35328;&#65292;&#23427;&#20204;&#20173;&#28982;&#26080;&#27861;&#36798;&#21040;&#8220;&#20256;&#32479;&#8221;&#30340;&#22522;&#20110;&#26144;&#23556;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20064;&#19978;&#19979;&#25991;&#22686;&#24378;&#26041;&#27861; (SAIL) &#26469;&#36827;&#34892;&#26080;&#30417;&#30563;&#30340;BLI&#65306;&#20174;&#38646;&#26679;&#26412;&#25552;&#31034;&#24320;&#22987;&#65292;SAIL&#36890;&#36807;&#36845;&#20195;&#22320;&#20174;LLM&#20013;&#24341;&#20986;&#19968;&#32452;&#39640;&#32622;&#20449;&#24230;&#30340;&#35789;&#27719;&#32763;&#35793;&#23545;&#65292;&#28982;&#21518;&#22312;ICL&#30340;&#26041;&#24335;&#19979;&#20877;&#27425;&#24212;&#29992;&#20110;&#21516;&#19968;&#20010;LLM&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20004;&#20010;&#24191;&#27867;&#30340;BLI&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#36328;&#36234;&#22810;&#31181;&#35821;&#35328;&#23545;&#65292;&#22312;&#38646;&#26679;&#26412;&#25552;&#31034;&#30340;LLM&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#20063;&#22312;&#21508;&#20010;&#26041;&#38754;&#20248;&#20110;&#22522;&#20110;&#26144;&#23556;&#30340;&#22522;&#32447;&#12290;&#38500;&#20102;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#26080;&#30417;&#30563;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10024v1 Announce Type: cross  Abstract: Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of 'traditional' mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages. To address this challenge with LLMs, we propose self-augmented in-context learning (SAIL) for unsupervised BLI: starting from a zero-shot prompt, SAIL iteratively induces a set of high-confidence word translation pairs for in-context learning (ICL) from an LLM, which it then reapplies to the same LLM in the ICL fashion. Our method shows substantial gains over zero-shot prompting of LLMs on two established BLI benchmarks spanning a wide range of language pairs, also outperforming mapping-based baselines across the board. In addition to achieving state-of-the-art unsupervised 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#25239;&#20107;&#23454;&#29983;&#25104;&#26041;&#27861;&#65292;&#21033;&#29992;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#29983;&#25104;&#23500;&#26377;&#34920;&#36798;&#21147;&#30340;&#23545;&#25239;&#20107;&#23454;&#65292;&#20197;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19981;&#33391;&#34892;&#20026;&#65292;&#35813;&#26041;&#27861;&#22312;&#22320;&#29699;&#31227;&#21160;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#24182;&#23545;&#34920;&#31034;&#31354;&#38388;&#30340;&#20960;&#20309;&#32452;&#32455;&#36827;&#34892;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.09631</link><description>&lt;p&gt;
MiMiC&#65306;&#34920;&#31034;&#31354;&#38388;&#20013;&#26368;&#23567;&#20462;&#25913;&#30340;&#23545;&#25239;&#20107;&#23454;
&lt;/p&gt;
&lt;p&gt;
MiMiC: Minimally Modified Counterfactuals in the Representation Space
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09631
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#25239;&#20107;&#23454;&#29983;&#25104;&#26041;&#27861;&#65292;&#21033;&#29992;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#29983;&#25104;&#23500;&#26377;&#34920;&#36798;&#21147;&#30340;&#23545;&#25239;&#20107;&#23454;&#65292;&#20197;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19981;&#33391;&#34892;&#20026;&#65292;&#35813;&#26041;&#27861;&#22312;&#22320;&#29699;&#31227;&#21160;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#24182;&#23545;&#34920;&#31034;&#31354;&#38388;&#30340;&#20960;&#20309;&#32452;&#32455;&#36827;&#34892;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09631v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#20132;&#21449;&#23398;&#31185; &#31616;&#20171;&#65306;&#35821;&#35328;&#27169;&#22411;&#32463;&#24120;&#34920;&#29616;&#20986;&#19981;&#33391;&#34892;&#20026;&#65292;&#22914;&#24615;&#21035;&#20559;&#35265;&#25110;&#26377;&#27602;&#35821;&#35328;&#12290;&#36890;&#36807;&#23545;&#34920;&#31034;&#31354;&#38388;&#36827;&#34892;&#24178;&#39044;&#65292;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#65292;&#20294;&#20004;&#31181;&#24120;&#35265;&#30340;&#24178;&#39044;&#25216;&#26415;&#65292;&#21363;&#32447;&#24615;&#25830;&#38500;&#21644;&#23450;&#21521;&#21521;&#37327;&#65292;&#24182;&#19981;&#33021;&#25552;&#20379;&#39640;&#24230;&#21487;&#25511;&#21644;&#34920;&#36798;&#20016;&#23500;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24178;&#39044;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#29983;&#25104;&#23500;&#26377;&#34920;&#36798;&#21147;&#30340;&#23545;&#25239;&#20107;&#23454;&#65292;&#20351;&#28304;&#31867;&#21035;&#65288;&#20363;&#22914;&#8220;&#26377;&#27602;&#8221;&#65289;&#30340;&#34920;&#31034;&#19982;&#30446;&#26631;&#31867;&#21035;&#65288;&#20363;&#22914;&#8220;&#38750;&#26377;&#27602;&#8221;&#65289;&#30340;&#34920;&#31034;&#30456;&#20284;&#12290;&#36825;&#31181;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#20551;&#35774;&#19979;&#30340;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#65292;&#22312;&#22320;&#29699;&#31227;&#21160;&#38382;&#39064;&#26041;&#38754;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#24182;&#23545;&#34920;&#31034;&#31354;&#38388;&#30340;&#20960;&#20309;&#32452;&#32455;&#25552;&#20379;&#20102;&#36827;&#19968;&#27493;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09631v1 Announce Type: cross  Abstract: Language models often exhibit undesirable behaviors, such as gender bias or toxic language. Interventions in the representation space were shown effective in mitigating such issues by altering the LM behavior. We first show that two prominent intervention techniques, Linear Erasure and Steering Vectors, do not enable a high degree of control and are limited in expressivity.   We then propose a novel intervention methodology for generating expressive counterfactuals in the representation space, aiming to make representations of a source class (e.g., ``toxic'') resemble those of a target class (e.g., ``non-toxic''). This approach, generalizing previous linear intervention techniques, utilizes a closed-form solution for the Earth Mover's problem under Gaussian assumptions and provides theoretical guarantees on the representation space's geometric organization. We further build on this technique and derive a nonlinear intervention that ena
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35757;&#32451;&#20013;&#23545;&#29256;&#26435;&#20445;&#25252;&#20869;&#23481;&#30340;&#21512;&#29702;&#20351;&#29992;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#20351;&#29992;&#29256;&#26435;&#38519;&#38449;&#26469;&#35782;&#21035;&#19981;&#33258;&#28982;&#35760;&#24518;&#30340;&#27169;&#22411;&#20013;&#30340;&#29256;&#26435;&#26448;&#26009;&#20351;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09363</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29256;&#26435;&#38519;&#38449;
&lt;/p&gt;
&lt;p&gt;
Copyright Traps for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09363
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#35757;&#32451;&#20013;&#23545;&#29256;&#26435;&#20445;&#25252;&#20869;&#23481;&#30340;&#21512;&#29702;&#20351;&#29992;&#38382;&#39064;&#12290;&#25552;&#20986;&#20102;&#20351;&#29992;&#29256;&#26435;&#38519;&#38449;&#26469;&#35782;&#21035;&#19981;&#33258;&#28982;&#35760;&#24518;&#30340;&#27169;&#22411;&#20013;&#30340;&#29256;&#26435;&#26448;&#26009;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#23545;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20869;&#23481;&#30340;&#21512;&#29702;&#20351;&#29992;&#30340;&#38382;&#39064;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#22312;&#35757;&#32451;&#27169;&#22411;&#26102;&#36890;&#36807;&#23545;&#27169;&#22411;&#30340;&#40657;&#30418;&#35775;&#38382;&#26469;&#25512;&#26029;&#19968;&#27573;&#20869;&#23481;&#26159;&#21542;&#22312;&#35757;&#32451;&#20013;&#20986;&#29616;&#36807;&#12290;&#30446;&#21069;&#30340;&#26368;&#20248;&#26041;&#27861;&#20381;&#36182;&#20110;&#65288;&#37096;&#20998;&#65289;&#20869;&#23481;&#30340;&#33258;&#28982;&#35760;&#24518;&#65292;&#23545;&#20110;&#22823;&#37327;&#35760;&#24518;&#30340;&#27169;&#22411;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#25105;&#20204;&#20551;&#35774;&#24182;&#21518;&#26469;&#35777;&#23454;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#19981;&#33258;&#28982;&#35760;&#24518;&#65292;&#20363;&#22914;&#20013;&#22411; 1B &#27169;&#22411;&#23558;&#19981;&#36215;&#20316;&#29992;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#29256;&#26435;&#38519;&#38449;&#26469;&#35782;&#21035;LLM&#20013;&#30340;&#29256;&#26435;&#26448;&#26009;&#20351;&#29992;&#65292;&#37325;&#28857;&#25918;&#22312;&#19981;&#33258;&#28982;&#35760;&#24518;&#30340;&#27169;&#22411;&#19978;&#12290;&#25105;&#20204;&#31934;&#24515;&#35774;&#35745;&#20102;&#19968;&#20010;&#23454;&#39564;&#35774;&#32622;&#65292;&#23558;&#38519;&#38449;&#38543;&#26426;&#25554;&#20837;&#21407;&#22987;&#20869;&#23481;&#65288;&#20070;&#31821;&#65289;&#20013;&#65292;&#24182;&#35757;&#32451;&#20102;&#19968;&#20010;1.3B&#30340;LLM&#27169;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#39564;&#35777;&#20102;&#22312;LLM&#20013;&#20351;&#29992;&#20869;&#23481;&#26159;&#21542;&#20250;&#23548;&#33268;&#38519;&#38449;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09363v1 Announce Type: new Abstract: Questions of fair use of copyright-protected content to train Large Language Models (LLMs) are being very actively debated. Document-level inference has been proposed as a new task: inferring from black-box access to the trained model whether a piece of content has been seen during training. SOTA methods however rely on naturally occurring memorization of (part of) the content. While very effective against models that memorize a lot, we hypothesize--and later confirm--that they will not work against models that do not naturally memorize, e.g. medium-size 1B models. We here propose to use copyright traps, the inclusion of fictitious entries in original content, to detect the use of copyrighted materials in LLMs with a focus on models where memorization does not naturally occur. We carefully design an experimental setup, randomly inserting traps into original content (books) and train a 1.3B LLM. We first validate that the use of content in
&lt;/p&gt;</description></item><item><title>PreFLMR&#26159;&#19968;&#31181;&#25193;&#23637;&#32454;&#31890;&#24230;&#36831;&#20132;&#20114;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#65292;&#29992;&#20110;&#35299;&#20915;&#30693;&#35782;&#24335;&#35270;&#35273;&#38382;&#31572;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#35757;&#32451;&#21644;&#35780;&#20272;&#26694;&#26550;M2KR&#36827;&#34892;&#20102;&#24320;&#21457;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;PreFLMR&#30340;&#25193;&#23637;&#34892;&#20026;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20026;&#36890;&#29992;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#30340;&#26410;&#26469;&#21457;&#23637;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#21551;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.08327</link><description>&lt;p&gt;
PreFLMR: &#25193;&#23637;&#32454;&#31890;&#24230;&#36831;&#20132;&#20114;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;
&lt;/p&gt;
&lt;p&gt;
PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08327
&lt;/p&gt;
&lt;p&gt;
PreFLMR&#26159;&#19968;&#31181;&#25193;&#23637;&#32454;&#31890;&#24230;&#36831;&#20132;&#20114;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#65292;&#29992;&#20110;&#35299;&#20915;&#30693;&#35782;&#24335;&#35270;&#35273;&#38382;&#31572;&#20219;&#21153;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#35757;&#32451;&#21644;&#35780;&#20272;&#26694;&#26550;M2KR&#36827;&#34892;&#20102;&#24320;&#21457;&#65292;&#24182;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;PreFLMR&#30340;&#25193;&#23637;&#34892;&#20026;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20026;&#36890;&#29992;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#30340;&#26410;&#26469;&#21457;&#23637;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;(LMMs)&#22312;&#33258;&#28982;&#35821;&#35328;&#21644;&#35270;&#35273;&#29702;&#35299;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#35832;&#22914;&#22522;&#20110;&#30693;&#35782;&#30340;&#35270;&#35273;&#38382;&#31572;(KB-VQA)&#36825;&#26679;&#30340;&#20005;&#26684;&#20219;&#21153;&#20013;&#65292;&#21364;&#38754;&#20020;&#30528;&#20174;&#25991;&#26723;&#38598;&#21512;&#20013;&#26816;&#32034;&#30456;&#20851;&#20449;&#24687;&#20197;&#29992;&#20110;&#22609;&#36896;&#38382;&#39064;&#31572;&#26696;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#35757;&#32451;&#21644;&#35780;&#20272;&#26694;&#26550;M2KR&#65292;&#29992;&#20110;KB-VQA&#12290;M2KR&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#65292;&#25105;&#20204;&#23558;&#20854;&#25972;&#21512;&#20026;&#19968;&#20010;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#36890;&#29992;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#30340;&#22522;&#20934;&#20219;&#21153;&#22871;&#20214;&#12290;&#25105;&#20204;&#20351;&#29992;M2KR&#24320;&#21457;&#20102;PreFLMR&#65292;&#36825;&#26159;&#26368;&#36817;&#24320;&#21457;&#30340;&#32454;&#31890;&#24230;&#36831;&#20132;&#20114;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;(FLMR)&#26041;&#27861;&#30340;&#39044;&#35757;&#32451;&#29256;&#26412;&#65292;&#24182;&#19988;&#25105;&#20204;&#25253;&#21578;&#20102;&#19968;&#31995;&#21015;&#20219;&#21153;&#20013;&#30340;&#26032;&#30340;&#26368;&#20808;&#36827;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23545;PreFLMR&#30340;&#25193;&#23637;&#34892;&#20026;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#26088;&#22312;&#23545;&#26410;&#26469;&#21457;&#23637;&#30340;&#36890;&#29992;&#22810;&#27169;&#24577;&#26816;&#32034;&#22120;&#26377;&#25152;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Multimodal Models (LMMs) excel in natural language and visual understanding but are challenged by exacting tasks such as Knowledge-based Visual Question Answering (KB-VQA) which involve the retrieval of relevant information from document collections to use in shaping answers to questions. We present an extensive training and evaluation framework, M2KR, for KB-VQA. M2KR contains a collection of vision and language tasks which we have incorporated into a single suite of benchmark tasks for training and evaluating general-purpose multi-modal retrievers. We use M2KR to develop PreFLMR, a pre-trained version of the recently developed Fine-grained Late-interaction Multi-modal Retriever (FLMR) approach to KB-VQA, and we report new state-of-the-art results across a range of tasks. We also present investigations into the scaling behaviors of PreFLMR intended to be useful in future developments in general-purpose multi-modal retrievers.
&lt;/p&gt;</description></item><item><title>DiffUse&#26159;&#19968;&#31181;&#26631;&#27880;&#25928;&#29575;&#39640;&#30340;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#32858;&#31867;&#25991;&#26412;&#35821;&#20041;&#24046;&#24322;&#30340;&#23884;&#20837;&#26469;&#36873;&#25321;&#26356;&#20855;&#20449;&#24687;&#37327;&#30340;&#23454;&#20363;&#65292;&#24182;&#33021;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#30340;&#27880;&#37322;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.07891</link><description>&lt;p&gt;
&#26631;&#27880;&#25928;&#29575;&#39640;&#30340;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Label-Efficient Model Selection for Text Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07891
&lt;/p&gt;
&lt;p&gt;
DiffUse&#26159;&#19968;&#31181;&#26631;&#27880;&#25928;&#29575;&#39640;&#30340;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#32858;&#31867;&#25991;&#26412;&#35821;&#20041;&#24046;&#24322;&#30340;&#23884;&#20837;&#26469;&#36873;&#25321;&#26356;&#20855;&#20449;&#24687;&#37327;&#30340;&#23454;&#20363;&#65292;&#24182;&#33021;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#30340;&#27880;&#37322;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#32473;&#23450;&#30446;&#26631;&#20219;&#21153;&#30340;&#27169;&#22411;&#36873;&#25321;&#21487;&#33021;&#25104;&#26412;&#39640;&#26114;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#38656;&#35201;&#23545;&#19981;&#21516;&#27169;&#22411;&#36755;&#20986;&#30340;&#36136;&#37327;&#36827;&#34892;&#24191;&#27867;&#30340;&#27880;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;DiffUse&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#22312;&#20505;&#36873;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;DiffUse&#20943;&#23569;&#20102;&#25152;&#38656;&#30340;&#20559;&#22909;&#27880;&#37322;&#25968;&#37327;&#65292;&#20174;&#32780;&#33410;&#30465;&#20102;&#22312;&#35780;&#20272;&#20013;&#23453;&#36149;&#30340;&#26102;&#38388;&#21644;&#36164;&#28304;&#12290;DiffUse&#36890;&#36807;&#32858;&#31867;&#34920;&#31034;&#27169;&#22411;&#36755;&#20986;&#20043;&#38388;&#30340;&#35821;&#20041;&#24046;&#24322;&#30340;&#23884;&#20837;&#26469;&#26234;&#33021;&#36873;&#25321;&#23454;&#20363;&#12290;&#22240;&#27492;&#65292;&#23427;&#33021;&#22815;&#35782;&#21035;&#20986;&#19968;&#20123;&#26356;&#26377;&#20449;&#24687;&#37327;&#30340;&#20363;&#23376;&#26469;&#36827;&#34892;&#20559;&#22909;&#20915;&#31574;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#27169;&#22411;&#26080;&#20851;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#36845;&#20195;&#26041;&#27861;&#26469;&#21160;&#24577;&#30830;&#23450;&#35201;&#27880;&#37322;&#30340;&#23454;&#20363;&#25968;&#37327;&#12290;&#36890;&#36807;&#23545;&#25968;&#30334;&#20010;&#27169;&#22411;&#23545;&#36827;&#34892;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;DiffUse&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#30340;&#27880;&#37322;&#25968;&#37327;&#65292;&#26368;&#22810;&#21487;&#20943;&#23569;75%&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#35780;&#20272;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models. DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation. DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#19982;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.04247</link><description>&lt;p&gt;
&#20248;&#20808;&#23433;&#20840;&#20445;&#38556;&#32780;&#38750;&#33258;&#27835;&#65306;&#31185;&#23398;&#20013;LLM&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#19982;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39537;&#21160;&#30340;&#26234;&#33021;&#26426;&#22120;&#20154;&#22312;&#21508;&#20010;&#23398;&#31185;&#20013;&#33258;&#20027;&#36827;&#34892;&#23454;&#39564;&#21644;&#20419;&#36827;&#31185;&#23398;&#21457;&#29616;&#26041;&#38754;&#23637;&#31034;&#20102;&#24040;&#22823;&#30340;&#21069;&#26223;&#12290;&#23613;&#31649;&#23427;&#20204;&#30340;&#33021;&#21147;&#38750;&#24120;&#26377;&#21069;&#36884;&#65292;&#20294;&#20063;&#24341;&#20837;&#20102;&#19968;&#20123;&#26032;&#30340;&#28431;&#27934;&#65292;&#38656;&#35201;&#20180;&#32454;&#32771;&#34385;&#23433;&#20840;&#24615;&#12290;&#28982;&#32780;&#65292;&#25991;&#29486;&#20013;&#23384;&#22312;&#26174;&#33879;&#30340;&#31354;&#30333;&#65292;&#23578;&#26410;&#23545;&#36825;&#20123;&#28431;&#27934;&#36827;&#34892;&#20840;&#38754;&#25506;&#35752;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#31185;&#23398;&#39046;&#22495;&#20013;&#22522;&#20110;LLM&#30340;&#26426;&#22120;&#20154;&#30340;&#28431;&#27934;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#35823;&#29992;&#21487;&#33021;&#24102;&#26469;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#24182;&#24378;&#35843;&#20102;&#23545;&#23433;&#20840;&#25514;&#26045;&#30340;&#38656;&#27714;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#39318;&#20808;&#20840;&#38754;&#27010;&#36848;&#20102;&#31185;&#23398;LLM&#26426;&#22120;&#20154;&#22266;&#26377;&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#32771;&#34385;&#20102;&#29992;&#25143;&#24847;&#22270;&#12289;&#29305;&#23450;&#30340;&#31185;&#23398;&#39046;&#22495;&#20197;&#21450;&#23427;&#20204;&#23545;&#22806;&#37096;&#29615;&#22659;&#21487;&#33021;&#36896;&#25104;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20123;&#28431;&#27934;&#30340;&#36215;&#28304;&#21644;&#25552;&#20379;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intelligent agents powered by large language models (LLMs) have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, they also introduce novel vulnerabilities that demand careful consideration for safety. However, there exists a notable gap in the literature, as there has been no comprehensive exploration of these vulnerabilities. This position paper fills this gap by conducting a thorough examination of vulnerabilities in LLM-based agents within scientific domains, shedding light on potential risks associated with their misuse and emphasizing the need for safety measures. We begin by providing a comprehensive overview of the potential risks inherent to scientific LLM agents, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we delve into the origins of these vulnerabilities and provid
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#39640;&#25928;&#31934;&#30830;&#20248;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#31574;&#30053;&#21442;&#25968;&#21270;&#20219;&#24847;&#30340;&#24773;&#20917;&#19979;&#65292;&#28176;&#36817;&#22320;&#19982;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#20248;&#21270;&#26041;&#21521;&#19968;&#33268;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.00856</link><description>&lt;p&gt;
&#23454;&#29616;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#39640;&#25928;&#31934;&#30830;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Efficient and Exact Optimization of Language Model Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29616;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#39640;&#25928;&#31934;&#30830;&#20248;&#21270;&#26041;&#27861;&#12290;&#36890;&#36807;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#31574;&#30053;&#21442;&#25968;&#21270;&#20219;&#24847;&#30340;&#24773;&#20917;&#19979;&#65292;&#28176;&#36817;&#22320;&#19982;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#20248;&#21270;&#26041;&#21521;&#19968;&#33268;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#23545;&#20110;&#20854;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#35813;&#38382;&#39064;&#34987;&#24314;&#27169;&#20026;&#20248;&#21270;&#27169;&#22411;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#21453;&#26144;&#20154;&#31867;&#20559;&#22909;&#30340;&#39044;&#26399;&#22870;&#21169;&#65292;&#24182;&#23613;&#37327;&#20943;&#23567;&#19982;&#21021;&#22987;&#31574;&#30053;&#30340;&#20559;&#24046;&#12290;&#23613;&#31649;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#30452;&#25509;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20854;&#31574;&#30053;&#26356;&#26032;&#30340;&#26041;&#24046;&#24456;&#39640;&#65292;&#38459;&#30861;&#20102;&#39640;&#25928;&#30340;&#31574;&#30053;&#25913;&#36827;&#12290;&#26368;&#36817;&#65292;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#34987;&#25552;&#20986;&#20197;&#30452;&#25509;&#20174;&#20559;&#22909;&#25968;&#25454;&#20013;&#20248;&#21270;&#31574;&#30053;&#12290;&#23613;&#31649;&#23454;&#29616;&#31616;&#21333;&#65292;DPO&#26159;&#22522;&#20110;&#19981;&#19968;&#23450;&#33021;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#30340;&#26368;&#20248;&#31574;&#30053;&#23548;&#20986;&#30340;&#65292;&#36825;&#21066;&#24369;&#20102;&#20854;&#25910;&#25947;&#21040;&#39044;&#26399;&#35299;&#20915;&#26041;&#26696;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31934;&#30830;&#20248;&#21270;&#65288;EXO&#65289;&#30340;&#23545;&#40784;&#30446;&#26631;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#31574;&#30053;&#30340;&#20219;&#24847;&#21442;&#25968;&#21270;&#65292;EXO&#20445;&#35777;&#28176;&#36817;&#22320;&#19982;RL&#31639;&#27861;&#30340;&#20248;&#21270;&#26041;&#21521;&#19968;&#33268;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The alignment of language models with human preferences is vital for their application in real-world tasks. The problem is formulated as optimizing the model's policy to maximize the expected reward that reflects human preferences with minimal deviation from the initial policy. While considered as a straightforward solution, reinforcement learning (RL) suffers from high variance in policy updates, which impedes efficient policy improvement. Recently, direct preference optimization (DPO) was proposed to directly optimize the policy from preference data. Though simple to implement, DPO is derived based on the optimal policy that is not assured to be achieved in practice, which undermines its convergence to the intended solution.   In this paper, we propose efficient exact optimization (EXO) of the alignment objective. We prove that EXO is guaranteed to optimize in the same direction as the RL algorithms asymptotically for arbitary parametrization of the policy, while enables efficient op
&lt;/p&gt;</description></item><item><title>&#39640;&#25928;&#25506;&#32034;&#22312;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65292;&#21487;&#20197;&#20197;&#36739;&#23569;&#30340;&#26597;&#35810;&#23454;&#29616;&#36739;&#39640;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25506;&#32034;&#26041;&#26696;&#30340;&#36873;&#25321;&#26159;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>https://arxiv.org/abs/2402.00396</link><description>&lt;p&gt;
LLMs&#30340;&#39640;&#25928;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Efficient Exploration for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00396
&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#25506;&#32034;&#22312;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65292;&#21487;&#20197;&#20197;&#36739;&#23569;&#30340;&#26597;&#35810;&#23454;&#29616;&#36739;&#39640;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25506;&#32034;&#26041;&#26696;&#30340;&#36873;&#25321;&#26159;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#35777;&#25454;&#65292;&#34920;&#26126;&#39640;&#25928;&#25506;&#32034;&#22312;&#33719;&#21462;&#20154;&#31867;&#21453;&#39304;&#20197;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#19968;&#20010;&#20195;&#29702;&#31243;&#24207;&#22312;&#25910;&#21040;&#21453;&#39304;&#26102;&#23558;&#22870;&#21169;&#27169;&#22411;&#25311;&#21512;&#21040;&#26597;&#35810;&#19978;&#12290;&#25105;&#20204;&#34920;&#29616;&#26368;&#20339;&#30340;&#20195;&#29702;&#31243;&#24207;&#20351;&#29992;&#21452;Thompson&#37319;&#26679;&#29983;&#25104;&#26597;&#35810;&#65292;&#19981;&#30830;&#23450;&#24615;&#30001;&#35748;&#30693;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#39640;&#25928;&#25506;&#32034;&#20351;&#24471;&#24615;&#33021;&#27700;&#24179;&#21487;&#20197;&#22312;&#36739;&#23569;&#30340;&#26597;&#35810;&#19979;&#36798;&#21040;&#36739;&#39640;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#25506;&#32034;&#26041;&#26696;&#30340;&#36873;&#25321;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present evidence of substantial benefit from efficient exploration in gathering human feedback to improve large language models. In our experiments, an agent sequentially generates queries while fitting a reward model to the feedback received. Our best-performing agent generates queries using double Thompson sampling, with uncertainty represented by an epistemic neural network. Our results demonstrate that efficient exploration enables high levels of performance with far fewer queries. Further, both uncertainty estimation and the choice of exploration scheme play critical roles.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#23884;&#20837;&#36870;&#36716;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#22810;&#35821;&#35328;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#36870;&#36716;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#31616;&#21333;&#30340;&#25513;&#34109;&#38450;&#24481;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2401.12192</link><description>&lt;p&gt;
&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#23884;&#20837;&#21453;&#21521;&#23433;&#20840;&#24615;
&lt;/p&gt;
&lt;p&gt;
Text Embedding Inversion Security for Multilingual Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.12192
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#25991;&#26412;&#23884;&#20837;&#36870;&#36716;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#22810;&#35821;&#35328;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#36870;&#36716;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#31616;&#21333;&#30340;&#25513;&#34109;&#38450;&#24481;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#65292;&#25991;&#26412;&#25968;&#25454;&#36890;&#24120;&#20197;&#23454;&#25968;&#23884;&#20837;&#34920;&#31034;&#65292;&#23588;&#20854;&#26159;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21644;&#23884;&#20837;&#24335;&#26381;&#21153;&#65288;EaaS&#65289;&#30340;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#23558;&#25935;&#24863;&#20449;&#24687;&#23384;&#20648;&#20026;&#23884;&#20837;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#23433;&#20840;&#28431;&#27934;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#30740;&#31350;&#34920;&#26126;&#65292;&#21363;&#20351;&#19981;&#30693;&#36947;&#24213;&#23618;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25991;&#26412;&#20063;&#21487;&#20197;&#20174;&#23884;&#20837;&#20013;&#37325;&#26500;&#12290;&#23613;&#31649;&#24050;&#32463;&#25506;&#35752;&#20102;&#38450;&#24481;&#26426;&#21046;&#65292;&#20294;&#36825;&#20123;&#26426;&#21046;&#19987;&#27880;&#20110;&#33521;&#35821;&#65292;&#20351;&#20854;&#20182;&#35821;&#35328;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#12290;&#26412;&#25991;&#36890;&#36807;&#22810;&#35821;&#35328;&#23884;&#20837;&#36870;&#36716;&#25506;&#35752;&#20102;LLM&#23433;&#20840;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#40657;&#30418;&#22810;&#35821;&#35328;&#21644;&#36328;&#35821;&#35328;&#36870;&#36716;&#25915;&#20987;&#30340;&#38382;&#39064;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;&#23427;&#20204;&#21487;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22810;&#35821;&#35328;LLMs&#21487;&#33021;&#26356;&#23481;&#26131;&#21463;&#21040;&#36870;&#36716;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#22522;&#20110;&#33521;&#35821;&#30340;&#38450;&#24481;&#21487;&#33021;&#26080;&#25928;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#25513;&#34109;&#38450;&#24481;&#26041;&#27861;&#65292;&#23545;b&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.12192v2 Announce Type: replace-cross  Abstract: Textual data is often represented as realnumbered embeddings in NLP, particularly with the popularity of large language models (LLMs) and Embeddings as a Service (EaaS). However, storing sensitive information as embeddings can be vulnerable to security breaches, as research shows that text can be reconstructed from embeddings, even without knowledge of the underlying model. While defence mechanisms have been explored, these are exclusively focused on English, leaving other languages vulnerable to attacks. This work explores LLM security through multilingual embedding inversion. We define the problem of black-box multilingual and cross-lingual inversion attacks, and thoroughly explore their potential implications. Our findings suggest that multilingual LLMs may be more vulnerable to inversion attacks, in part because English based defences may be ineffective. To alleviate this, we propose a simple masking defense effective for b
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#26426;&#22120;&#32763;&#35793;&#20013;LLMs&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#28145;&#20837;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#31034;&#20363;&#39537;&#21160;&#30340;&#29305;&#28857;&#20197;&#21450;&#31034;&#20363;&#23545;&#19979;&#28216;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#20063;&#25506;&#35752;&#20102;ICL&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2401.12097</link><description>&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#20013;LLMs&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study of In-context Learning in LLMs for Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.12097
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#26426;&#22120;&#32763;&#35793;&#20013;LLMs&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#28145;&#20837;&#30340;&#30740;&#31350;&#65292;&#25506;&#35752;&#20102;&#31034;&#20363;&#39537;&#21160;&#30340;&#29305;&#28857;&#20197;&#21450;&#31034;&#20363;&#23545;&#19979;&#28216;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#20063;&#25506;&#35752;&#20102;ICL&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#27987;&#21402;&#20852;&#36259;&#12290;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20248;&#21270;&#32763;&#35793;&#36136;&#37327;&#19978;&#65292;&#23545;&#24433;&#21709;&#25152;&#36848;&#36136;&#37327;&#30340;ICL&#30340;&#29305;&#23450;&#26041;&#38754;&#20851;&#27880;&#26377;&#38480;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#39318;&#27425;&#20840;&#38754;&#30740;&#31350;&#19978;&#19979;&#25991;&#23398;&#20064;&#29992;&#20110;&#26426;&#22120;&#32763;&#35793;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;ICL&#20027;&#35201;&#26159;&#30001;&#31034;&#20363;&#39537;&#21160;&#32780;&#19981;&#26159;&#25351;&#20196;&#39537;&#21160;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#31034;&#20363;&#30340;&#21508;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#24191;&#27867;&#25506;&#32034;&#65292;&#20197;&#20102;&#35299;&#23427;&#20204;&#23545;&#19979;&#28216;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21253;&#25324;&#31034;&#33539;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#12289;&#31354;&#38388;&#25509;&#36817;&#24615;&#20197;&#21450;&#28304;&#35821;&#35328;&#19982;&#30446;&#26631;&#35821;&#35328;&#30340;&#21407;&#21019;&#24615;&#31561;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#28041;&#21450;&#38388;&#25509;&#24615;&#21644;&#31034;&#20363;&#19981;&#21305;&#37197;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#65292;&#20197;&#20102;&#35299;ICL&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.12097v2 Announce Type: replace  Abstract: Recent interest has surged in employing Large Language Models (LLMs) for machine translation (MT) via in-context learning (ICL) (Vilar et al., 2023). Most prior studies primarily focus on optimizing translation quality, with limited attention to understanding the specific aspects of ICL that influence the said quality. To this end, we perform the first of its kind, exhaustive study of in-context learning for machine translation. We first establish that ICL is primarily example-driven and not instruction-driven. Following this, we conduct an extensive exploration of various aspects of the examples to understand their influence on downstream performance. Our analysis includes factors such as quality and quantity of demonstrations, spatial proximity, and source versus target originality. Further, we also investigate challenging scenarios involving indirectness and misalignment of examples to understand the limits of ICL. While we establ
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#21512;&#24182;&#29983;&#25104;&#21644;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#20197;&#25552;&#21319;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#20559;&#21521;&#20110;&#29983;&#25104;&#30340;&#19978;&#19979;&#25991;&#65292;&#21363;&#20351;&#23427;&#20204;&#25552;&#20379;&#20102;&#38169;&#35823;&#30340;&#20449;&#24687;&#12290;</title><link>https://arxiv.org/abs/2401.11911</link><description>&lt;p&gt;
&#22914;&#20309;&#21512;&#24182;&#29983;&#25104;&#21644;&#26816;&#32034;&#19978;&#19979;&#25991;&#20197;&#22686;&#24378;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Blinded by Generated Contexts: How Language Models Merge Generated and Retrieved Contexts for Open-Domain QA?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.11911
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#21512;&#24182;&#29983;&#25104;&#21644;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#20197;&#25552;&#21319;&#24320;&#25918;&#39046;&#22495;&#38382;&#31572;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#20559;&#21521;&#20110;&#29983;&#25104;&#30340;&#19978;&#19979;&#25991;&#65292;&#21363;&#20351;&#23427;&#20204;&#25552;&#20379;&#20102;&#38169;&#35823;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#36741;&#21161;&#20449;&#24687;&#24050;&#32463;&#25104;&#20026;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20851;&#38190;&#65292;&#20294;&#23545;&#20110;LLMs&#22914;&#20309;&#21512;&#24182;&#29983;&#25104;&#30340;&#21644;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#20173;&#30693;&#20043;&#29978;&#23569;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#31995;&#32479;&#24615;&#30340;&#26694;&#26550;&#26469;&#30830;&#23450;LLMs&#30340;&#21709;&#24212;&#26159;&#28304;&#33258;&#20110;&#29983;&#25104;&#30340;&#19978;&#19979;&#25991;&#36824;&#26159;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#21253;&#21547;&#30456;&#20114;&#20914;&#31361;&#30340;&#19978;&#19979;&#25991;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#27599;&#20010;&#38382;&#39064;&#37117;&#19982;&#29983;&#25104;&#30340;&#21644;&#26816;&#32034;&#30340;&#19978;&#19979;&#25991;&#37197;&#23545;&#65292;&#20294;&#21482;&#26377;&#19968;&#20010;&#19978;&#19979;&#25991;&#21253;&#21547;&#20102;&#27491;&#30830;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;LLMs&#65288;&#22914;GPT-4/3.5&#21644;Llama2&#65289;&#23384;&#22312;&#26174;&#33879;&#30340;&#20559;&#24046;&#65292;&#26356;&#20542;&#21521;&#20110;&#29983;&#25104;&#30340;&#19978;&#19979;&#25991;&#65292;&#21363;&#20351;&#36825;&#20123;&#19978;&#19979;&#25991;&#25552;&#20379;&#20102;&#38169;&#35823;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#23548;&#33268;&#36825;&#31181;&#20559;&#24046;&#30340;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#65306;i&#65289;LLMs&#29983;&#25104;&#30340;&#19978;&#19979;&#25991;&#36890;&#24120;&#19982;&#38382;&#39064;&#26356;&#30456;&#20284;&#65292;&#22686;&#21152;&#20102;&#20854;&#34987;&#36873;&#25321;&#30340;&#21487;&#33021;&#24615;&#65307;ii&#65289;&#26816;&#32034;&#19978;&#19979;&#25991;&#20013;&#20351;&#29992;&#30340;&#20998;&#21106;&#36807;&#31243;&#25171;&#26029;&#20102;&#20854;&#36830;&#36143;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a systematic framework to identify whether LLMs' responses, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To achieve this, we construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs (GPT-4/3.5 and Llama2) towards generated contexts, even when they provide incorrect information. We further identify two key factors contributing to this bias: i) contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) the segmentation process used in retrieved contexts disrupts their compl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#30828;&#20214;&#39640;&#25928;&#24615;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#31639;&#27861;&#65292;&#21487;&#22312;&#30701;&#24207;&#21015;&#38271;&#24230;&#19979;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#65292;&#21516;&#26102;&#25512;&#24191;&#21040;&#20102;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#38376;&#30340;&#26356;&#20855;&#34920;&#36798;&#33021;&#21147;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#21464;&#20307;&#12290;</title><link>https://arxiv.org/abs/2312.06635</link><description>&lt;p&gt;
&#20855;&#26377;&#30828;&#20214;&#39640;&#25928;&#35757;&#32451;&#30340;&#38376;&#25511;&#32447;&#24615;&#27880;&#24847;&#21147;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Gated Linear Attention Transformers with Hardware-Efficient Training
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.06635
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#30828;&#20214;&#39640;&#25928;&#24615;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#31639;&#27861;&#65292;&#21487;&#22312;&#30701;&#24207;&#21015;&#38271;&#24230;&#19979;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#65292;&#21516;&#26102;&#25512;&#24191;&#21040;&#20102;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#38376;&#30340;&#26356;&#20855;&#34920;&#36798;&#33021;&#21147;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#21464;&#21387;&#22120;&#20801;&#35768;&#36827;&#34892;&#39640;&#25928;&#30340;&#24182;&#34892;&#35757;&#32451;&#65292;&#21516;&#26102;&#21487;&#20197;&#34987;&#34920;&#36848;&#20026;&#20855;&#26377;2D&#65288;&#30697;&#38453;&#20540;&#65289;&#38544;&#34255;&#29366;&#24577;&#30340;RNN&#65292;&#20174;&#32780;&#20139;&#21463;&#32447;&#24615;&#26102;&#38388;&#25512;&#26029;&#22797;&#26434;&#24230;&#12290;&#28982;&#32780;&#65292;&#32447;&#24615;&#27880;&#24847;&#21147;&#36890;&#24120;&#34920;&#29616;&#19981;&#22914;&#26222;&#36890;softmax&#27880;&#24847;&#21147;&#12290;&#32780;&#19988;&#65292;&#24403;&#21069;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#23454;&#29616;&#32570;&#20047;I/O&#24863;&#30693;&#24615;&#65292;&#22240;&#27492;&#27604;&#39640;&#24230;&#20248;&#21270;&#30340;softmax&#27880;&#24847;&#21147;&#23454;&#29616;&#26356;&#24930;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32447;&#24615;&#27880;&#24847;&#21147;&#30340;&#30828;&#20214;&#39640;&#25928;&#31639;&#27861;&#65292;&#23427;&#22312;&#20869;&#23384;&#31227;&#21160;&#21644;&#21487;&#24182;&#34892;&#24615;&#20043;&#38388;&#36827;&#34892;&#25240;&#20013;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#23454;&#29616;&#65292;&#34987;&#31216;&#20026;FLASHLINEARATTENTION&#65292;&#22312;&#30701;&#24207;&#21015;&#38271;&#24230;&#65288;&#20363;&#22914;&#65292;1K&#65289;&#19979;&#65292;&#21363;&#20351;&#20316;&#20026;&#21333;&#29420;&#30340;&#23618;&#20063;&#27604;FLASHATTENTION-2(Dao, 2023)&#26356;&#24555;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#25512;&#24191;&#21040;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#38376;&#30340;&#26356;&#20855;&#34920;&#36798;&#33021;&#21147;&#30340;&#32447;&#24615;&#27880;&#24847;&#21147;&#21464;&#20307;&#12290;&#24403;&#29992;&#20316;&#21464;&#25442;&#22120;&#20013;&#26631;&#20934;&#27880;&#24847;&#21147;&#23618;&#30340;&#26367;&#20195;&#26102;&#65292;&#20135;&#29983;&#30340;&#38376;&#25511;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.06635v4 Announce Type: replace-cross  Abstract: Transformers with linear attention allow for efficient parallel training but can simultaneously be formulated as an RNN with 2D (matrix-valued) hidden states, thus enjoying linear-time inference complexity. However, linear attention generally underperforms ordinary softmax attention. Moreover, current implementations of linear attention lack I/O-awareness and are thus slower than highly optimized implementations of softmax attention. This work describes a hardware-efficient algorithm for linear attention that trades off memory movement against parallelizability. The resulting implementation, dubbed FLASHLINEARATTENTION, is faster than FLASHATTENTION-2(Dao, 2023) as a standalone layer even at short sequence lengths (e.g., 1K). We then generalize this algorithm to a more expressive variant of linear attention with data-dependent gates. When used as a replacement for the standard attention layer in Transformers, the resulting gate
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;LLMCompiler&#30340;&#32534;&#35793;&#22120;&#65292;&#36890;&#36807;&#24182;&#34892;&#25191;&#34892;&#20989;&#25968;&#26469;&#39640;&#25928;&#22320;&#21327;&#35843;&#22810;&#20010;&#20989;&#25968;&#35843;&#29992;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#22810;&#20989;&#25968;&#35843;&#29992;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#39640;&#24310;&#36831;&#12289;&#39640;&#25104;&#26412;&#21644;&#19981;&#20934;&#30830;&#34892;&#20026;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2312.04511</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#24182;&#34892;&#20989;&#25968;&#35843;&#29992;&#30340;LLM&#32534;&#35793;&#22120;
&lt;/p&gt;
&lt;p&gt;
An LLM Compiler for Parallel Function Calling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.04511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;LLMCompiler&#30340;&#32534;&#35793;&#22120;&#65292;&#36890;&#36807;&#24182;&#34892;&#25191;&#34892;&#20989;&#25968;&#26469;&#39640;&#25928;&#22320;&#21327;&#35843;&#22810;&#20010;&#20989;&#25968;&#35843;&#29992;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#22810;&#20989;&#25968;&#35843;&#29992;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#39640;&#24310;&#36831;&#12289;&#39640;&#25104;&#26412;&#21644;&#19981;&#20934;&#30830;&#34892;&#20026;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#22797;&#26434;&#25512;&#29702;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#26524;&#12290;LLM&#30340;&#25512;&#29702;&#33021;&#21147;&#20351;&#23427;&#20204;&#33021;&#22815;&#25191;&#34892;&#22806;&#37096;&#20989;&#25968;&#35843;&#29992;&#65292;&#20197;&#20811;&#26381;&#23427;&#20204;&#30340;&#22266;&#26377;&#23616;&#38480;&#65292;&#20363;&#22914;&#30693;&#35782;&#25130;&#26029;&#12289;&#31967;&#31957;&#30340;&#31639;&#26415;&#33021;&#21147;&#25110;&#26080;&#27861;&#35775;&#38382;&#31169;&#26377;&#25968;&#25454;&#12290;&#36825;&#19968;&#21457;&#23637;&#20351;&#24471;LLM&#33021;&#22815;&#22522;&#20110;&#19978;&#19979;&#25991;&#36873;&#25321;&#21644;&#21327;&#35843;&#22810;&#20010;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#26356;&#22797;&#26434;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22810;&#20989;&#25968;&#35843;&#29992;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20026;&#27599;&#20010;&#20989;&#25968;&#36827;&#34892;&#39034;&#24207;&#25512;&#29702;&#21644;&#25191;&#34892;&#65292;&#20174;&#32780;&#23548;&#33268;&#39640;&#24310;&#36831;&#12289;&#39640;&#25104;&#26412;&#21644;&#26377;&#26102;&#19981;&#20934;&#30830;&#30340;&#34892;&#20026;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;LLM&#32534;&#35793;&#22120;&#65292;&#23427;&#22312;&#24182;&#34892;&#25191;&#34892;&#20989;&#25968;&#30340;&#21516;&#26102;&#39640;&#25928;&#22320;&#21327;&#35843;&#22810;&#20010;&#20989;&#25968;&#35843;&#29992;&#12290;&#20511;&#37492;&#32463;&#20856;&#32534;&#35793;&#22120;&#30340;&#21407;&#29702;&#65292;LLM&#32534;&#35793;&#22120;&#36890;&#36807;&#19977;&#20010;&#32452;&#20214;&#31616;&#21270;&#24182;&#34892;&#20989;&#25968;&#35843;&#29992;&#65306;&#65288;i&#65289;LLM&#35268;&#21010;&#22120;&#65292;&#21046;&#23450;&#25191;&#34892;&#35745;&#21010;&#65307;&#65288;ii&#65289;&#20219;&#21153;&#33719;&#21462;&#21333;&#20803;&#65292;&#20998;&#27966;&#20989;&#25968;&#35843;&#29992;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Recent language models have shown remarkable results on various complex reasoning benchmarks. The reasoning capabilities of LLMs enable them to execute external function calls to overcome their inherent limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of access to private data. This development has allowed LLMs to select and coordinate multiple functions based on the context to tackle more complex problems. However, current methods for multiple function calling often require sequential reasoning and acting for each function which can result in high latency, cost, and sometimes inaccurate behavior. To address this, we introduce LLMCompiler, which executes functions in parallel to efficiently orchestrate multiple function calling. Drawing from the principles of classical compilers, LLMCompiler streamlines parallel function calling with three components: (i) an LLM Planner, formulating execution plans; (ii) a Task Fetching Unit, dispatching function calling tasks; a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21307;&#23398;&#39046;&#22495;&#30340;&#36328;&#23398;&#31185;&#21512;&#20316;(MC)&#26694;&#26550;&#65292;&#21033;&#29992;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#22312;&#35282;&#33394;&#25198;&#28436;&#35774;&#32622;&#20013;&#21442;&#19982;&#21327;&#20316;&#22810;&#36718;&#35752;&#35770;&#65292;&#20174;&#32780;&#25552;&#39640;LLM&#30340;&#29087;&#32451;&#31243;&#24230;&#21644;&#25512;&#29702;&#33021;&#21147;</title><link>https://arxiv.org/abs/2311.10537</link><description>&lt;p&gt;
MedAgents: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38646;-shot&#21307;&#23398;&#25512;&#29702;&#30340;&#21512;&#20316;&#32773;
&lt;/p&gt;
&lt;p&gt;
MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.10537
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21307;&#23398;&#39046;&#22495;&#30340;&#36328;&#23398;&#31185;&#21512;&#20316;(MC)&#26694;&#26550;&#65292;&#21033;&#29992;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#22312;&#35282;&#33394;&#25198;&#28436;&#35774;&#32622;&#20013;&#21442;&#19982;&#21327;&#20316;&#22810;&#36718;&#35752;&#35770;&#65292;&#20174;&#32780;&#25552;&#39640;LLM&#30340;&#29087;&#32451;&#31243;&#24230;&#21644;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23613;&#31649;&#22312;&#21508;&#31181;&#36890;&#29992;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#22312;&#21307;&#23398;&#21644;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#21307;&#23398;&#39046;&#22495;&#30340;&#36328;&#23398;&#31185;&#21512;&#20316;(MC)&#26694;&#26550;&#65292;&#21033;&#29992;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#22312;&#35282;&#33394;&#25198;&#28436;&#35774;&#32622;&#20013;&#21442;&#19982;&#21327;&#20316;&#22810;&#36718;&#35752;&#35770;&#65292;&#20174;&#32780;&#25552;&#39640;LLM&#30340;&#29087;&#32451;&#31243;&#24230;&#21644;&#25512;&#29702;&#33021;&#21147;&#12290;&#36825;&#31181;&#26080;&#38656;&#35757;&#32451;&#30340;&#26694;&#26550;&#21253;&#25324;&#20116;&#20010;&#20851;&#38190;&#27493;&#39588;&#65306;&#25910;&#38598;&#39046;&#22495;&#19987;&#23478;&#12289;&#25552;&#20986;&#20010;&#21035;&#20998;&#26512;&#12289;&#23558;&#36825;&#20123;&#20998;&#26512;&#24635;&#32467;&#25104;&#25253;&#21578;&#12289;&#22312;&#35752;&#35770;&#20013;&#21453;&#22797;&#36845;&#20195;&#30452;&#21040;&#36798;&#25104;&#20849;&#35782;&#65292;&#26368;&#32456;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#38646;-shot&#24773;&#26223;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#20855;&#26377;&#36866;&#29992;&#24615;&#12290;&#22312;&#20061;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.10537v2 Announce Type: replace-cross  Abstract: Large language models (LLMs), despite their remarkable progress across various general domains, encounter significant barriers in medicine and healthcare. This field faces unique challenges such as domain-specific terminologies and reasoning over specialized knowledge. To address these issues, we propose a novel Multi-disciplinary Collaboration (MC) framework for the medical domain that leverages LLM-based agents in a role-playing setting that participate in a collaborative multi-round discussion, thereby enhancing LLM proficiency and reasoning capabilities. This training-free framework encompasses five critical steps: gathering domain experts, proposing individual analyses, summarising these analyses into a report, iterating over discussions until a consensus is reached, and ultimately making a decision. Our work focuses on the zero-shot setting, which is applicable in real-world scenarios. Experimental results on nine dataset
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;MCTS&#65292;&#19968;&#20010;&#22810;&#21442;&#32771;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#20102;&#35780;&#20272;&#25968;&#25454;&#21644;&#24615;&#33021;&#20998;&#26512;&#65292;&#21516;&#26102;&#36824;&#21457;&#24067;&#20102;&#29992;&#20110;&#35757;&#32451;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#24179;&#34892;&#25968;&#25454;&#65292;&#20026;&#26410;&#26469;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#30784;&#21644;&#21442;&#32771;&#12290;</title><link>https://arxiv.org/abs/2306.02796</link><description>&lt;p&gt;
MCTS&#65306;&#19968;&#20010;&#22810;&#21442;&#32771;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
MCTS: A Multi-Reference Chinese Text Simplification Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.02796
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;MCTS&#65292;&#19968;&#20010;&#22810;&#21442;&#32771;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#20102;&#35780;&#20272;&#25968;&#25454;&#21644;&#24615;&#33021;&#20998;&#26512;&#65292;&#21516;&#26102;&#36824;&#21457;&#24067;&#20102;&#29992;&#20110;&#35757;&#32451;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#24179;&#34892;&#25968;&#25454;&#65292;&#20026;&#26410;&#26469;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#30740;&#31350;&#25552;&#20379;&#20102;&#22522;&#30784;&#21644;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#31616;&#21270;&#26088;&#22312;&#36890;&#36807;&#24212;&#29992;&#37325;&#20889;&#36716;&#25442;&#20351;&#25991;&#26412;&#26356;&#23481;&#26131;&#29702;&#35299;&#12290;&#38271;&#26399;&#20197;&#26469;&#65292;&#20851;&#20110;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#30340;&#30740;&#31350;&#24456;&#23569;&#12290;&#36890;&#29992;&#35780;&#20272;&#25968;&#25454;&#30340;&#32570;&#20047;&#26159;&#36825;&#31181;&#29616;&#35937;&#30340;&#19968;&#20010;&#37325;&#35201;&#21407;&#22240;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;MCTS&#65292;&#19968;&#20010;&#22810;&#21442;&#32771;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#25968;&#25454;&#38598;&#30340;&#27880;&#37322;&#36807;&#31243;&#24182;&#25552;&#20379;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20960;&#31181;&#26080;&#30417;&#30563;&#26041;&#27861;&#21644;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#29992;&#20110;&#35757;&#32451;&#30340;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#24179;&#34892;&#25968;&#25454;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#32763;&#35793;&#21644;&#33521;&#25991;&#25991;&#26412;&#31616;&#21270;&#33719;&#24471;&#12290;&#25105;&#20204;&#24076;&#26395;&#36890;&#36807;&#22522;&#30784;&#24037;&#20316;&#24314;&#31435;&#23545;&#20013;&#25991;&#25991;&#26412;&#31616;&#21270;&#30340;&#22522;&#26412;&#29702;&#35299;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#30740;&#31350;&#25552;&#20379;&#21442;&#32771;&#12290;&#25152;&#26377;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#24050;&#22312;https://github.com/blcuicall/mcts/&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.02796v2 Announce Type: replace  Abstract: Text simplification aims to make the text easier to understand by applying rewriting transformations. There has been very little research on Chinese text simplification for a long time. The lack of generic evaluation data is an essential reason for this phenomenon. In this paper, we introduce MCTS, a multi-reference Chinese text simplification dataset. We describe the annotation process of the dataset and provide a detailed analysis. Furthermore, we evaluate the performance of several unsupervised methods and advanced large language models. We additionally provide Chinese text simplification parallel data that can be used for training, acquired by utilizing machine translation and English text simplification. We hope to build a basic understanding of Chinese text simplification through the foundational work and provide references for future research. All of the code and data are released at https://github.com/blcuicall/mcts/.
&lt;/p&gt;</description></item><item><title>&#24403;&#22256;&#38590;&#35757;&#32451;&#25968;&#25454;&#24456;&#38590;&#27491;&#30830;&#26631;&#35760;&#26102;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#33021;&#22815;&#30456;&#23545;&#33391;&#22909;&#22320;&#20174;&#26131;&#21040;&#38590;&#30340;&#25968;&#25454;&#27867;&#21270;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#20851;&#27880;&#20110;&#22256;&#38590;&#25968;&#25454;&#30340;&#24615;&#33021;&#26102;&#65292;&#25910;&#38598;&#21644;&#35757;&#32451;&#26131;&#25968;&#25454;&#21487;&#33021;&#27604;&#22256;&#38590;&#25968;&#25454;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.06751</link><description>&lt;p&gt;
Easy Training Data&#23545;&#20110;&#22256;&#38590;&#20219;&#21153;&#30340;&#19981;&#21512;&#29702;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Unreasonable Effectiveness of Easy Training Data for Hard Tasks. (arXiv:2401.06751v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06751
&lt;/p&gt;
&lt;p&gt;
&#24403;&#22256;&#38590;&#35757;&#32451;&#25968;&#25454;&#24456;&#38590;&#27491;&#30830;&#26631;&#35760;&#26102;&#65292;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#33021;&#22815;&#30456;&#23545;&#33391;&#22909;&#22320;&#20174;&#26131;&#21040;&#38590;&#30340;&#25968;&#25454;&#27867;&#21270;&#65292;&#24182;&#19988;&#21363;&#20351;&#22312;&#20851;&#27880;&#20110;&#22256;&#38590;&#25968;&#25454;&#30340;&#24615;&#33021;&#26102;&#65292;&#25910;&#38598;&#21644;&#35757;&#32451;&#26131;&#25968;&#25454;&#21487;&#33021;&#27604;&#22256;&#38590;&#25968;&#25454;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#22256;&#38590;&#35757;&#32451;&#25968;&#25454;&#22312;&#23450;&#20041;&#19978;&#24456;&#38590;&#27491;&#30830;&#26631;&#35760;&#26102;&#65292;&#25105;&#20204;&#22914;&#20309;&#35757;&#32451;&#27169;&#22411;&#22312;&#22256;&#38590;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#33391;&#22909;&#65311;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#21487;&#25193;&#23637;&#30417;&#30563;&#38382;&#39064;&#65292;&#22312;&#35821;&#35328;&#27169;&#22411;&#19981;&#26029;&#25913;&#36827;&#30340;&#36807;&#31243;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#35770;&#65292;&#21363;&#24403;&#21069;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#24120;&#20174;&#26131;&#21040;&#38590;&#30340;&#25968;&#25454;&#27867;&#21270;&#30456;&#23545;&#33391;&#22909;&#65292;&#29978;&#33267;&#34920;&#29616;&#24471;&#21644;&#22312;&#22256;&#38590;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#8220;oracle&#8221;&#27169;&#22411;&#19968;&#26679;&#22909;&#12290;&#25105;&#20204;&#20351;&#29992;&#31616;&#21333;&#30340;&#35757;&#32451;&#26041;&#27861;&#65288;&#22914;&#19978;&#19979;&#25991;&#23398;&#20064;&#12289;&#32447;&#24615;&#20998;&#31867;&#22120;&#22836;&#21644;QLoRA&#65289;&#23637;&#31034;&#20102;&#36825;&#31181;&#20174;&#26131;&#21040;&#38590;&#30340;&#27867;&#21270;&#65292;&#38024;&#23545;&#19971;&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#28857;&#38590;&#24230;&#24230;&#37327;&#65292;&#21253;&#25324;&#20845;&#20010;&#32463;&#39564;&#22810;&#26679;&#30340;&#20154;&#31867;&#38590;&#24230;&#24230;&#37327;&#65288;&#22914;&#24180;&#32423;&#27700;&#24179;&#65289;&#21644;&#19968;&#20010;&#22522;&#20110;&#27169;&#22411;&#30340;&#24230;&#37327;&#65288;&#22522;&#20110;&#25439;&#22833;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21363;&#20351;&#26368;&#20851;&#24515;&#27169;&#22411;&#22312;&#22256;&#38590;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#65292;&#25910;&#38598;&#24182;&#35757;&#32451;&#26131;&#25968;&#25454;&#21487;&#33021;&#27604;&#22256;&#38590;&#25968;&#25454;&#26356;&#22909;&#65292;&#22240;&#20026;&#22256;&#38590;&#25968;&#25454;&#36890;&#24120;&#26356;&#22024;&#26434;&#21644;&#26114;&#36149;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can we train models to perform well on hard test data when hard training data is by definition difficult to label correctly? This question has been termed the scalable oversight problem and has drawn increasing attention as language models have continually improved. In this paper, we present the surprising conclusion that current language models often generalize relatively well from easy to hard data, even performing as well as "oracle" models trained on hard data. We demonstrate this kind of easy-to-hard generalization using simple training methods like in-context learning, linear classifier heads, and QLoRA for seven different measures of datapoint hardness, including six empirically diverse human hardness measures (like grade level) and one model-based measure (loss-based). Furthermore, we show that even if one cares most about model performance on hard data, it can be better to collect and train on easy data rather than hard data, since hard data is generally noisier and costli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25209;&#22788;&#29702;ICL&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;ICL&#35270;&#20026;&#19968;&#20010;&#20803;&#20248;&#21270;&#36807;&#31243;&#65292;&#24320;&#21457;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#12289;&#39640;&#25928;&#19988;&#26080;&#24207;&#30340;&#25512;&#29702;&#31639;&#27861;&#12290;&#36890;&#36807;&#32858;&#21512;&#20803;&#26799;&#24230;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#38646;-shot&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20351;LLM&#23545;ICL&#31034;&#20363;&#39034;&#24207;&#26080;&#20851;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#20854;&#20182;&#25490;&#21015;&#26041;&#24335;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#26631;&#20934;ICL&#30340;&#26368;&#20339;&#39034;&#24207;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.06469</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;ICL: &#26377;&#25928;&#65292;&#39640;&#25928;&#19988;&#26080;&#24207;&#22320;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning. (arXiv:2401.06469v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06469
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25209;&#22788;&#29702;ICL&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;ICL&#35270;&#20026;&#19968;&#20010;&#20803;&#20248;&#21270;&#36807;&#31243;&#65292;&#24320;&#21457;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#12289;&#39640;&#25928;&#19988;&#26080;&#24207;&#30340;&#25512;&#29702;&#31639;&#27861;&#12290;&#36890;&#36807;&#32858;&#21512;&#20803;&#26799;&#24230;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#38646;-shot&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20351;LLM&#23545;ICL&#31034;&#20363;&#39034;&#24207;&#26080;&#20851;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20248;&#20110;&#20854;&#20182;&#25490;&#21015;&#26041;&#24335;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#26631;&#20934;ICL&#30340;&#26368;&#20339;&#39034;&#24207;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#35270;&#20026;&#19968;&#20010;&#20803;&#20248;&#21270;&#36807;&#31243;&#65292;&#35299;&#37322;&#20102;LLM&#23545;ICL&#31034;&#20363;&#39034;&#24207;&#25935;&#24863;&#30340;&#21407;&#22240;&#12290;&#36825;&#31181;&#29702;&#35299;&#20351;&#25105;&#20204;&#24320;&#21457;&#20986;&#20102;Batch-ICL&#65292;&#19968;&#31181;&#29992;&#20110;ICL&#30340;&#26377;&#25928;&#12289;&#39640;&#25928;&#19988;&#26080;&#24207;&#30340;&#25512;&#29702;&#31639;&#27861;&#12290;&#19982;&#26631;&#20934;&#30340;N-shot&#23398;&#20064;&#26041;&#27861;&#19981;&#21516;&#65292;Batch-ICL&#20351;&#29992;N&#20010;&#21333;&#29420;&#30340;1-shot&#21069;&#21521;&#35745;&#31639;&#65292;&#24182;&#32858;&#21512;&#24471;&#21040;&#30340;&#20803;&#26799;&#24230;&#12290;&#28982;&#21518;&#65292;&#23558;&#36825;&#20123;&#32858;&#21512;&#30340;&#20803;&#26799;&#24230;&#24212;&#29992;&#20110;&#38646;-shot&#23398;&#20064;&#20197;&#29983;&#25104;&#26368;&#32456;&#39044;&#27979;&#12290;&#36825;&#31181;&#25209;&#22788;&#29702;&#26041;&#27861;&#20351;LLM&#23545;ICL&#31034;&#20363;&#30340;&#39034;&#24207;&#26080;&#20851;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;Batch-ICL&#19968;&#33268;&#20248;&#20110;&#22823;&#22810;&#25968;&#31034;&#20363;&#24207;&#21015;&#30340;&#25490;&#21015;&#26041;&#24335;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#26631;&#20934;ICL&#30340;&#26368;&#20339;&#39034;&#24207;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#25152;&#38656;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;Batch-ICL&#30340;&#19968;&#31181;&#26032;&#39062;&#21464;&#20307;&#65292;&#20854;&#20013;&#21253;&#21547;&#22810;&#20010;"epochs"&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, by treating in-context learning (ICL) as a meta-optimization process, we explain why LLMs are sensitive to the order of ICL examples. This understanding leads us to the development of Batch-ICL, an effective, efficient, and order-agnostic inference algorithm for ICL. Differing from the standard N-shot learning approach, Batch-ICL employs $N$ separate 1-shot forward computations and aggregates the resulting meta-gradients. These aggregated meta-gradients are then applied to a zero-shot learning to generate the final prediction. This batch processing approach renders the LLM agnostic to the order of ICL examples. Through extensive experiments and analysis, we demonstrate that Batch-ICL consistently outperforms most permutations of example sequences. In some cases, it even exceeds the performance of the optimal order for standard ICL, all while reducing the computational resources required. Furthermore, we develop a novel variant of Batch-ICL featuring multiple "epochs" of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#33539;&#24335;&#65292;&#36890;&#36807;&#25361;&#25112;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20803;&#25512;&#29702;&#65292;&#20174;&#32780;&#26377;&#25928;&#21306;&#20998;&#23427;&#20204;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#36825;&#19968;&#33539;&#24335;&#30340;&#37325;&#35201;&#24615;&#22312;&#20110;&#33021;&#22815;&#25581;&#31034;&#20986;&#20256;&#32479;&#22522;&#20934;&#27979;&#35797;&#26080;&#27861;&#21457;&#29616;&#30340;&#27169;&#22411;&#30340;&#28508;&#22312;&#35748;&#30693;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2312.17080</link><description>&lt;p&gt;
MR-GSM8K: &#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#30340;&#20803;&#25512;&#29702;&#38761;&#21629;
&lt;/p&gt;
&lt;p&gt;
MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation. (arXiv:2312.17080v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.17080
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#33539;&#24335;&#65292;&#36890;&#36807;&#25361;&#25112;&#36825;&#20123;&#27169;&#22411;&#36827;&#34892;&#20803;&#25512;&#29702;&#65292;&#20174;&#32780;&#26377;&#25928;&#21306;&#20998;&#23427;&#20204;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#36825;&#19968;&#33539;&#24335;&#30340;&#37325;&#35201;&#24615;&#22312;&#20110;&#33021;&#22815;&#25581;&#31034;&#20986;&#20256;&#32479;&#22522;&#20934;&#27979;&#35797;&#26080;&#27861;&#21457;&#29616;&#30340;&#27169;&#22411;&#30340;&#28508;&#22312;&#35748;&#30693;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35780;&#20272;&#33539;&#24335;&#65292;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36825;&#31181;&#33539;&#24335;&#25361;&#25112;&#23427;&#20204;&#20174;&#20107;&#20803;&#25512;&#29702;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#29616;&#26377;&#30340;&#25968;&#23398;&#38382;&#39064;&#27714;&#35299;&#22522;&#20934;&#20013;&#30340;&#20851;&#38190;&#32570;&#38519;&#65292;&#20256;&#32479;&#19978;&#29992;&#20110;&#35780;&#20272;&#26234;&#33021;&#20307;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#33539;&#24335;&#23558;&#28966;&#28857;&#20174;&#20197;&#32467;&#26524;&#20026;&#23548;&#21521;&#30340;&#35780;&#20272;&#36716;&#31227;&#21040;&#20102;&#26356;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#26377;&#25928;&#22320;&#21306;&#20998;&#20102;&#27169;&#22411;&#20043;&#38388;&#30340;&#35748;&#30693;&#33021;&#21147;&#12290;&#20363;&#22914;&#65292;&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;GPT-4 &#30340;&#24615;&#33021;&#36739; GPT3-5 &#25552;&#21319;&#20102;&#20116;&#20493;&#12290;&#36825;&#31181;&#26032;&#33539;&#24335;&#30340;&#37325;&#35201;&#24847;&#20041;&#22312;&#20110;&#23427;&#33021;&#22815;&#25581;&#31034;&#20986;&#24403;&#21069;&#22522;&#20934;&#27979;&#35797;&#65288;&#22914;GSM8K&#65289;&#26080;&#27861;&#21457;&#29616;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#22312;&#35748;&#30693;&#32570;&#38519;&#65292;&#36825;&#26159;&#30001;&#20110;&#22522;&#20934;&#27979;&#35797;&#30340;&#39281;&#21644;&#24230;&#21644;&#23545;&#19981;&#21516;&#25512;&#29702;&#33021;&#21147;&#30340;&#26377;&#25928;&#21306;&#20998;&#19981;&#36275;&#12290;&#25105;&#20204;&#30340;&#32508;&#21512;&#20998;&#26512;&#21253;&#25324;&#20102;&#26469;&#33258;&#24320;&#28304;&#21644;&#38381;&#28304;&#31038;&#21306;&#30340;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#25581;&#31034;&#20102;&#19968;&#20123;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35748;&#30693;&#33021;&#21147;&#30340;&#37325;&#35201;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce a novel evaluation paradigm for Large Language Models, one that challenges them to engage in meta-reasoning. This approach addresses critical shortcomings in existing math problem-solving benchmarks, traditionally used to evaluate the cognitive capabilities of agents. Our paradigm shifts the focus from result-oriented assessments, which often overlook the reasoning process, to a more holistic evaluation that effectively differentiates the cognitive capabilities among models. For example, in our benchmark, GPT-4 demonstrates a performance five times better than GPT3-5. The significance of this new paradigm lies in its ability to reveal potential cognitive deficiencies in LLMs that current benchmarks, such as GSM8K, fail to uncover due to their saturation and lack of effective differentiation among varying reasoning abilities. Our comprehensive analysis includes several state-of-the-art math models from both open-source and closed-source communities, uncovering
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#24182;&#21033;&#29992;LLM&#26694;&#26550;&#29983;&#25104;&#22810;&#26679;&#30340;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2312.14187</link><description>&lt;p&gt;
WaveCoder: &#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#19982;&#23436;&#21892;&#30340;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation. (arXiv:2312.14187v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#24182;&#21033;&#29992;LLM&#26694;&#26550;&#29983;&#25104;&#22810;&#26679;&#30340;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#23545;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#38598;&#36827;&#34892;&#35843;&#20248;&#21518;&#65292;&#29983;&#25104;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#24191;&#27867;&#30340;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25351;&#20196;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#32463;&#24120;&#20250;&#20135;&#29983;&#37325;&#22797;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#25968;&#25454;&#36136;&#37327;&#30340;&#25511;&#21046;&#19981;&#22815;&#28789;&#27963;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#20026;4&#20010;&#19982;&#20195;&#30721;&#30456;&#20851;&#30340;&#20219;&#21153;&#65292;&#25193;&#23637;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26222;&#36866;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;LLM&#30340;&#29983;&#25104;&#22120;-&#21028;&#21035;&#22120;&#25968;&#25454;&#22788;&#29702;&#26694;&#26550;&#65292;&#20174;&#24320;&#28304;&#20195;&#30721;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeOcean&#65292;&#19968;&#20010;&#21253;&#21547;4&#20010;&#36890;&#29992;&#20195;&#30721;&#30456;&#20851;&#20219;&#21153;&#30340;&#12289;&#20849;&#35745;20,000&#20010;&#25351;&#20196;&#23454;&#20363;&#30340;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#22686;&#24378;&#25351;&#20196;&#35843;&#20248;&#30340;&#25928;&#26524;&#65292;&#24182;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#20855;&#26377;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#30340;Code LLM&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work demonstrates that, after being fine-tuned on a high-quality instruction dataset, the resulting model can obtain impressive capabilities to address a wide range of tasks. However, existing methods for instruction data generation often produce duplicate data and are not controllable enough on data quality. In this paper, we extend the generalization of instruction tuning by classifying the instruction data to 4 code-related tasks and propose a LLM-based Generator-Discriminator data process framework to generate diverse, high-quality instruction data from open source code. Hence, we introduce CodeOcean, a dataset comprising 20,000 instruction instances across 4 universal code-related tasks,which is aimed at augmenting the effectiveness of instruction tuning and improving the generalization ability of fine-tuned model. Subsequently, we present WaveCoder, a fine-tuned Code LLM with Widespread And Versatile Enhanced instruction tuning. This model is specifically designed for enha
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23454;&#20307;&#21305;&#37197;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;LLMs&#23545;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.11244</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#23454;&#20307;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Entity Matching using Large Language Models. (arXiv:2310.11244v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11244
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23454;&#20307;&#21305;&#37197;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;LLMs&#23545;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#21305;&#37197;&#26159;&#21028;&#26029;&#20004;&#20010;&#23454;&#20307;&#25551;&#36848;&#26159;&#21542;&#25351;&#30340;&#26159;&#21516;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#23454;&#20307;&#30340;&#20219;&#21153;&#12290;&#23454;&#20307;&#21305;&#37197;&#26159;&#22823;&#22810;&#25968;&#25968;&#25454;&#38598;&#25104;&#27969;&#31243;&#20013;&#30340;&#26680;&#24515;&#27493;&#39588;&#65292;&#20063;&#26159;&#35768;&#22810;&#30005;&#23376;&#21830;&#21153;&#24212;&#29992;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#36825;&#20123;&#24212;&#29992;&#38656;&#35201;&#23558;&#26469;&#33258;&#19981;&#21516;&#20379;&#24212;&#21830;&#30340;&#20135;&#21697;&#21305;&#37197;&#36215;&#26469;&#12290;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#23454;&#20307;&#21305;&#37197;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#65292;&#22914;BERT&#25110;RoBERTa&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#23454;&#20307;&#21305;&#37197;&#20013;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#32570;&#28857;&#65306;&#65288;i&#65289;&#27169;&#22411;&#38656;&#35201;&#22823;&#37327;&#29305;&#23450;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#65307;&#65288;ii&#65289;&#24494;&#35843;&#21518;&#30340;&#27169;&#22411;&#23545;&#20110;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#23454;&#20307;&#19981;&#22815;&#20581;&#22766;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#22522;&#20110;PLMs&#30340;&#21305;&#37197;&#22120;&#30340;&#22791;&#36873;&#26041;&#26696;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;LLMs&#23545;&#39046;&#22495;&#29305;&#23450;&#35757;&#32451;&#25968;&#25454;&#38656;&#27714;&#36739;&#23569;&#19988;&#26356;&#20855;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#28085;&#30422;&#20102;&#25176;&#31649;&#30340;LLMs&#65292;&#22914;GPT3.5&#21644;GPT4&#65292;&#20197;&#21450;&#22522;&#20110;Llama2&#30340;&#24320;&#28304;LLMs&#65292;&#21487;&#20197;&#22312;&#26412;&#22320;&#36816;&#34892;&#12290;&#25105;&#20204;&#22312;&#38646;&#26679;&#26412;&#22330;&#26223;&#21644;&#8230;
&lt;/p&gt;
&lt;p&gt;
Entity Matching is the task of deciding whether two entity descriptions refer to the same real-world entity. Entity Matching is a central step in most data integration pipelines and an enabler for many e-commerce applications which require to match products offers from different vendors. State-of-the-art entity matching methods often rely on pre-trained language models (PLMs) such as BERT or RoBERTa. Two major drawbacks of these models for entity matching are that (i) the models require significant amounts of task-specific training data and (ii) the fine-tuned models are not robust concerning out-of-distribution entities. In this paper, we investigate using large language models (LLMs) for entity matching as a less domain-specific training data reliant and more robust alternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5 and GPT4, as well as open source LLMs based on Llama2 which can be run locally. We evaluate these models in a zero-shot scenario as well as a
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#20998;&#26512;&#31038;&#20132;&#23186;&#20307;&#29992;&#25143;&#30340;&#25968;&#23383;&#36275;&#36857;&#25512;&#26029;&#20182;&#20204;&#30340;&#24515;&#29702;&#20542;&#21521;&#65292;&#20855;&#20307;&#34920;&#29616;&#20026;&#20174;Facebook&#29366;&#24577;&#26356;&#26032;&#20013;&#25512;&#26029;&#20116;&#22823;&#20154;&#26684;&#29305;&#36136;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25512;&#26029;&#24471;&#20998;&#19982;&#33258;&#25105;&#25253;&#21578;&#24471;&#20998;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#24615;&#21035;&#21644;&#24180;&#40836;&#26041;&#38754;&#23384;&#22312;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2309.08631</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#25512;&#26029;&#31038;&#20132;&#23186;&#20307;&#29992;&#25143;&#30340;&#24515;&#29702;&#20542;&#21521;
&lt;/p&gt;
&lt;p&gt;
Large Language Models Can Infer Psychological Dispositions of Social Media Users. (arXiv:2309.08631v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08631
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#20998;&#26512;&#31038;&#20132;&#23186;&#20307;&#29992;&#25143;&#30340;&#25968;&#23383;&#36275;&#36857;&#25512;&#26029;&#20182;&#20204;&#30340;&#24515;&#29702;&#20542;&#21521;&#65292;&#20855;&#20307;&#34920;&#29616;&#20026;&#20174;Facebook&#29366;&#24577;&#26356;&#26032;&#20013;&#25512;&#26029;&#20116;&#22823;&#20154;&#26684;&#29305;&#36136;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#25512;&#26029;&#24471;&#20998;&#19982;&#33258;&#25105;&#25253;&#21578;&#24471;&#20998;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#20294;&#22312;&#24615;&#21035;&#21644;&#24180;&#40836;&#26041;&#38754;&#23384;&#22312;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#23637;&#31034;&#20986;&#36234;&#26469;&#36234;&#25509;&#36817;&#20154;&#31867;&#30340;&#33021;&#21147;&#65292;&#32780;&#36825;&#20123;&#20219;&#21153;&#23558;&#25104;&#20026;&#20010;&#24615;&#21270;&#25216;&#26415;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#29702;&#35299;&#23427;&#20204;&#30340;&#33021;&#21147;&#21644;&#22266;&#26377;&#20559;&#35265;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35843;&#26597;&#20102;&#31867;&#20284;ChatGPT&#30340;LLMs&#20174;&#20010;&#20154;&#25968;&#23383;&#36275;&#36857;&#20013;&#25512;&#26029;&#20010;&#20154;&#24515;&#29702;&#20542;&#21521;&#30340;&#28508;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;GPT-3.5&#21644;GPT-4&#22312;&#38646;&#26679;&#26412;&#23398;&#20064;&#22330;&#26223;&#19979;&#20174;&#29992;&#25143;&#30340;Facebook&#29366;&#24577;&#26356;&#26032;&#20013;&#25512;&#23548;&#20986;&#20116;&#22823;&#20154;&#26684;&#29305;&#36136;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;LLM&#25512;&#26029;&#19982;&#33258;&#25105;&#25253;&#21578;&#24471;&#20998;&#20043;&#38388;&#30340;&#24179;&#22343;&#30456;&#20851;&#24615;&#20026;r = 0.29&#65288;&#33539;&#22260;&#20026;[0.22, 0.33]&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#22312;&#24615;&#21035;&#21644;&#24180;&#40836;&#26041;&#38754;&#23384;&#22312;&#20010;&#24615;&#25512;&#26029;&#30340;&#20559;&#35265;&#65306;&#23545;&#20110;&#20960;&#20010;&#29305;&#36136;&#65292;&#25512;&#26029;&#24471;&#20998;&#22312;&#22899;&#24615;&#21644;&#24180;&#36731;&#20154;&#20013;&#30340;&#35823;&#24046;&#36739;&#23567;&#65292;&#36825;&#34920;&#26126;&#21487;&#33021;&#23384;&#22312;&#26469;&#33258;&#24213;&#23618;&#35757;&#32451;&#25968;&#25454;&#25110;&#22312;&#32447;&#33258;&#25105;&#21576;&#29616;&#30340;&#24046;&#24322;&#30340;&#31995;&#32479;&#24615;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
As Large Language Models (LLMs) demonstrate increasingly human-like abilities in various natural language processing (NLP) tasks that are bound to become integral to personalized technologies, understanding their capabilities and inherent biases is crucial. Our study investigates the potential of LLMs like ChatGPT to infer psychological dispositions of individuals from their digital footprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores. Furthermore, our findings suggest biases in personality inferences with regard to gender and age: inferred scores demonstrated smaller errors for women and younger individuals on several traits, suggesting a potential systematic bias stemming from the underlying training data or differences in online self-e
&lt;/p&gt;</description></item><item><title>MultiPA&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#38381;&#21512;&#21644;&#24320;&#25918;&#21709;&#24212;&#22330;&#26223;&#30340;&#22810;&#20219;&#21153;&#35821;&#38899;&#21457;&#38899;&#35780;&#20272;&#31995;&#32479;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#31995;&#32479;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#26684;&#24335;&#35201;&#27714;&#21644;&#26356;&#22909;&#30340;&#20860;&#23481;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#35780;&#20272;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2308.12490</link><description>&lt;p&gt;
MultiPA:&#19968;&#31181;&#36866;&#29992;&#20110;&#38381;&#21512;&#21644;&#24320;&#25918;&#21709;&#24212;&#22330;&#26223;&#30340;&#22810;&#20219;&#21153;&#35821;&#38899;&#21457;&#38899;&#35780;&#20272;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario. (arXiv:2308.12490v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12490
&lt;/p&gt;
&lt;p&gt;
MultiPA&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#38381;&#21512;&#21644;&#24320;&#25918;&#21709;&#24212;&#22330;&#26223;&#30340;&#22810;&#20219;&#21153;&#35821;&#38899;&#21457;&#38899;&#35780;&#20272;&#31995;&#32479;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#31995;&#32479;&#65292;&#23427;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#26684;&#24335;&#35201;&#27714;&#21644;&#26356;&#22909;&#30340;&#20860;&#23481;&#24615;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#35780;&#20272;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#35821;&#38899;&#21457;&#38899;&#35780;&#20272;&#31995;&#32479;&#30340;&#35774;&#35745;&#21487;&#20197;&#20998;&#20026;&#38381;&#21512;&#21644;&#24320;&#25918;&#21709;&#24212;&#22330;&#26223;&#65292;&#27599;&#31181;&#22330;&#26223;&#37117;&#26377;&#20854;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#12290;&#20855;&#22791;&#22312;&#20004;&#31181;&#22330;&#26223;&#19979;&#37117;&#33021;&#21457;&#25381;&#20316;&#29992;&#30340;&#31995;&#32479;&#33021;&#22815;&#28385;&#36275;&#22810;&#26679;&#21270;&#30340;&#23398;&#20064;&#38656;&#27714;&#65292;&#24182;&#25552;&#20379;&#26356;&#31934;&#30830;&#12289;&#20840;&#38754;&#30340;&#21457;&#38899;&#25216;&#33021;&#35780;&#20272;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MultiPA&#30340;&#22810;&#20219;&#21153;&#21457;&#38899;&#35780;&#20272;&#27169;&#22411;&#12290;MultiPA&#19982;&#22522;&#20110;Kaldi&#30340;&#31995;&#32479;&#30456;&#27604;&#65292;&#20855;&#26377;&#26356;&#31616;&#21333;&#30340;&#26684;&#24335;&#35201;&#27714;&#65292;&#26356;&#22909;&#22320;&#20860;&#23481;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#19982;&#20808;&#21069;&#30340;&#24320;&#25918;&#21709;&#24212;&#31995;&#32479;&#30456;&#27604;&#65292;MultiPA&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#35780;&#20272;&#33539;&#22260;&#65292;&#21253;&#25324;&#21477;&#23376;&#21644;&#21333;&#35789;&#32423;&#21035;&#30340;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MultiPA&#22312;&#38381;&#21512;&#21709;&#24212;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#19982;&#20808;&#21069;&#31995;&#32479;&#30456;&#24403;&#65292;&#24182;&#22312;&#30452;&#25509;&#29992;&#20110;&#24320;&#25918;&#21709;&#24212;&#26102;&#20445;&#25345;&#26356;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The design of automatic speech pronunciation assessment can be categorized into closed and open response scenarios, each with strengths and limitations. A system with the ability to function in both scenarios can cater to diverse learning needs and provide a more precise and holistic assessment of pronunciation skills. In this study, we propose a Multi-task Pronunciation Assessment model called MultiPA. MultiPA provides an alternative to Kaldi-based systems in that it has simpler format requirements and better compatibility with other neural network models. Compared with previous open response systems, MultiPA provides a wider range of evaluations, encompassing assessments at both the sentence and word-level. Our experimental results show that MultiPA achieves comparable performance when working in closed response scenarios and maintains more robust performance when directly used for open responses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#36719;&#20214;&#24320;&#21457;&#33539;&#24335;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#23454;&#29616;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#28040;&#38500;&#20102;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#27169;&#22411;&#30340;&#38656;&#27714;&#12290;&#35813;&#33539;&#24335;&#20351;&#29992;ChatDev&#20316;&#20026;&#19968;&#20010;&#34394;&#25311;&#32842;&#22825;&#39537;&#21160;&#30340;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#36890;&#36807;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#22235;&#20010;&#38454;&#27573;&#30340;&#20195;&#29702;&#20154;&#22242;&#38431;&#20419;&#36827;&#21327;&#20316;&#12290;</title><link>http://arxiv.org/abs/2307.07924</link><description>&lt;p&gt;
&#36719;&#20214;&#24320;&#21457;&#20013;&#30340;&#20132;&#27969;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Communicative Agents for Software Development. (arXiv:2307.07924v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#36719;&#20214;&#24320;&#21457;&#33539;&#24335;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#23454;&#29616;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#28040;&#38500;&#20102;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#27169;&#22411;&#30340;&#38656;&#27714;&#12290;&#35813;&#33539;&#24335;&#20351;&#29992;ChatDev&#20316;&#20026;&#19968;&#20010;&#34394;&#25311;&#32842;&#22825;&#39537;&#21160;&#30340;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#36890;&#36807;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#22235;&#20010;&#38454;&#27573;&#30340;&#20195;&#29702;&#20154;&#22242;&#38431;&#20419;&#36827;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#24037;&#31243;&#26159;&#19968;&#20010;&#20197;&#24494;&#22937;&#30340;&#30452;&#35273;&#21644;&#21672;&#35810;&#20026;&#29305;&#24449;&#30340;&#39046;&#22495;&#65292;&#20915;&#31574;&#36807;&#31243;&#22797;&#26434;&#12290;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#24320;&#22987;&#36890;&#36807;&#22312;&#36719;&#20214;&#24320;&#21457;&#30340;&#21508;&#20010;&#38454;&#27573;&#23454;&#26045;&#31934;&#24515;&#35774;&#35745;&#26469;&#38761;&#26032;&#36719;&#20214;&#24037;&#31243;&#23454;&#36341;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#33539;&#24335;&#65292;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#65292;&#22312;&#25972;&#20010;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#20013;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20851;&#38190;&#27969;&#31243;&#65292;&#20174;&#32780;&#28040;&#38500;&#20102;&#22312;&#27599;&#20010;&#38454;&#27573;&#38656;&#35201;&#19987;&#38376;&#30340;&#27169;&#22411;&#30340;&#38656;&#35201;&#12290;&#36825;&#20010;&#33539;&#24335;&#30340;&#26680;&#24515;&#26159;ChatDev&#65292;&#19968;&#20010;&#34394;&#25311;&#30340;&#32842;&#22825;&#39537;&#21160;&#36719;&#20214;&#24320;&#21457;&#20844;&#21496;&#65292;&#23427;&#27169;&#20223;&#20102;&#24050;&#32463;&#24314;&#31435;&#30340;&#28689;&#24067;&#27169;&#22411;&#65292;&#23558;&#24320;&#21457;&#36807;&#31243;&#32454;&#20998;&#20026;&#22235;&#20010;&#19981;&#21516;&#30340;&#26102;&#38388;&#38454;&#27573;&#65306;&#35774;&#35745;&#12289;&#32534;&#30721;&#12289;&#27979;&#35797;&#21644;&#25991;&#26723;&#21270;&#12290;&#27599;&#20010;&#38454;&#27573;&#37117;&#28041;&#21450;&#19968;&#20010;&#22242;&#38431;&#30340;&#20195;&#29702;&#20154;&#65292;&#22914;&#31243;&#24207;&#21592;&#12289;&#20195;&#30721;&#23457;&#26597;&#20154;&#21592;&#21644;&#27979;&#35797;&#24037;&#31243;&#24072;&#65292;&#20419;&#36827;&#21327;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Software engineering is a domain characterized by intricate decision-making processes, often relying on nuanced intuition and consultation. Recent advancements in deep learning have started to revolutionize software engineering practices through elaborate designs implemented at various stages of software development. In this paper, we present an innovative paradigm that leverages large language models (LLMs) throughout the entire software development process, streamlining and unifying key processes through natural language communication, thereby eliminating the need for specialized models at each phase. At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting. Each stage engages a team of agents, such as programmers, code reviewers, and test engineers, fostering collaborativ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#34987;&#36951;&#24536;&#26435;&#65288;RTBF&#65289;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#25552;&#20379;&#20102;&#23454;&#26045;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.03941</link><description>&lt;p&gt;
&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#34987;&#36951;&#24536;&#26435;&#65306;&#28085;&#20041;&#12289;&#25361;&#25112;&#21644;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03941
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#34987;&#36951;&#24536;&#26435;&#65288;RTBF&#65289;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#25552;&#20379;&#20102;&#23454;&#26045;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34987;&#36951;&#24536;&#26435;&#65288;RTBF&#65289;&#26368;&#21021;&#26159;&#30001;&#35895;&#27468;&#35199;&#29677;&#29273;&#19982;&#22467;&#20811;&#26031;&#20869;&#22612;&#32034;&#22996;&#21592;&#20250;(Mario Costeja Gonz\'alez)&#20043;&#38388;&#30340;&#23448;&#21496;&#32467;&#26524;&#32780;&#30830;&#31435;&#30340;&#65292;&#24182;&#19988;&#21518;&#26469;&#34987;&#20316;&#20026;&#27431;&#27954;&#32852;&#30431;&#19968;&#33324;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#65288;GDPR&#65289;&#19979;&#30340;&#21024;&#38500;&#26435;&#12290;RTBF&#20801;&#35768;&#20010;&#20154;&#21521;&#32452;&#32455;&#35831;&#27714;&#21024;&#38500;&#20010;&#20154;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#25628;&#32034;&#24341;&#25806;&#65292;&#20010;&#20154;&#21487;&#20197;&#21521;&#32452;&#32455;&#21457;&#36865;&#35831;&#27714;&#65292;&#25490;&#38500;&#20182;&#20204;&#30340;&#20449;&#24687;&#22312;&#26597;&#35810;&#32467;&#26524;&#20013;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#21644;&#20854;&#22312;&#32842;&#22825;&#26426;&#22120;&#20154;&#20013;&#30340;&#24212;&#29992;&#65292;LLM&#21551;&#29992;&#30340;&#36719;&#20214;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#20294;&#23427;&#20204;&#24182;&#27809;&#26377;&#34987;&#25490;&#38500;&#22312;RTBF&#20043;&#22806;&#12290;&#30456;&#27604;&#25628;&#32034;&#24341;&#25806;&#20351;&#29992;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;LLMs&#20197;&#19968;&#31181;&#23436;&#20840;&#19981;&#21516;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#22788;&#29702;&#20449;&#24687;&#65292;&#36825;&#20026;&#31526;&#21512;RTBF&#25552;&#20986;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20123;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#23454;&#26045;&#25216;&#26415;&#35299;&#20915;&#26041;&#26696;&#20197;&#31526;&#21512;RTBF&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unle
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35757;&#32451;&#21518;&#30340;&#37327;&#21270;&#26694;&#26550;&#8212;&#8212;SqueezeLLM&#65292;&#23427;&#19981;&#20165;&#21487;&#20197;&#23454;&#29616;&#39640;&#36798;3&#20301;&#30340;&#26080;&#25439;&#21387;&#32553;&#65292;&#32780;&#19988;&#22312;&#30456;&#21516;&#30340;&#20869;&#23384;&#32422;&#26463;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#37327;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.07629</link><description>&lt;p&gt;
SqueezeLLM&#65306;&#23494;&#38598;&#31232;&#30095;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35757;&#32451;&#21518;&#30340;&#37327;&#21270;&#26694;&#26550;&#8212;&#8212;SqueezeLLM&#65292;&#23427;&#19981;&#20165;&#21487;&#20197;&#23454;&#29616;&#39640;&#36798;3&#20301;&#30340;&#26080;&#25439;&#21387;&#32553;&#65292;&#32780;&#19988;&#22312;&#30456;&#21516;&#30340;&#20869;&#23384;&#32422;&#26463;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#37327;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#32463;&#35777;&#26126;&#22312;&#24191;&#27867;&#39046;&#22495;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#38750;&#20961;&#30340;&#25104;&#26524;&#12290;&#20294;&#26159;&#30001;&#20110;&#20854;&#21069;&#25152;&#26410;&#26377;&#30340;&#36164;&#28304;&#38656;&#27714;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#29992;&#20110;&#25512;&#29702;&#19968;&#30452;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#36825;&#23548;&#33268;&#29616;&#26377;&#30340;&#37096;&#32626;&#26694;&#26550;&#38656;&#35201;&#20351;&#29992;&#22810;GPU&#25512;&#29702;&#31649;&#36947;&#65292;&#36825;&#36890;&#24120;&#26159;&#22797;&#26434;&#21644;&#26114;&#36149;&#30340;&#65292;&#25110;&#32773;&#20351;&#29992;&#26356;&#23567;&#19988;&#24615;&#33021;&#26356;&#20302;&#30340;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#20110;LLMs&#29983;&#25104;&#25512;&#26029;&#30340;&#20027;&#35201;&#29942;&#39048;&#26159;&#20869;&#23384;&#24102;&#23485;&#65292;&#32780;&#19981;&#26159;&#35745;&#31639;&#65292;&#23588;&#20854;&#26159;&#21333;&#20010;&#25209;&#27425;&#25512;&#29702;&#12290;&#34429;&#28982;&#36890;&#36807;&#20351;&#29992;&#20943;&#23569;&#31934;&#24230;&#26469;&#34920;&#31034;&#27169;&#22411;&#26435;&#37325;&#65292;&#37327;&#21270;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#26159;&#20197;&#21069;&#30340;&#21162;&#21147;&#36890;&#24120;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;SqueezeLLM&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#35757;&#32451;&#21518;&#30340;&#37327;&#21270;&#26694;&#26550;&#65292;&#19981;&#20165;&#21487;&#20197;&#23454;&#29616;&#39640;&#36798;3&#20301;&#30340;&#26080;&#25439;&#21387;&#32553;&#65292;&#32780;&#19988;&#22312;&#30456;&#21516;&#30340;&#20869;&#23384;&#32422;&#26463;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#37327;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Large Language Models (LLMs) have demonstrated remarkable results for a wide range of tasks. However, deploying these models for inference has been a significant challenge due to their unprecedented resource requirements. This has forced existing deployment frameworks to use multi-GPU inference pipelines, which are often complex and costly, or to use smaller and less performant models. In this work, we demonstrate that the main bottleneck for generative inference with LLMs is memory bandwidth, rather than compute, specifically for single batch inference. While quantization has emerged as a promising solution by representing model weights with reduced precision, previous efforts have often resulted in notable performance degradation. To address this, we introduce SqueezeLLM, a post-training quantization framework that not only enables lossless compression to ultra-low precisions of up to 3-bit, but also achieves higher quantization performance under the same memory constraint
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#36923;&#36753;&#39537;&#21160;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#23558;&#21407;&#22987;&#25991;&#26412;&#36716;&#25442;&#20026;&#25277;&#35937;&#24847;&#20041;&#34920;&#36848;&#22270;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#36923;&#36753;&#20462;&#25913;&#21644;&#36716;&#25442;&#65292;&#29983;&#25104;&#22686;&#24378;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#20307;&#31995;&#32467;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.12599</link><description>&lt;p&gt;
&#36890;&#36807;&#36923;&#36753;&#39537;&#21160;&#30340;&#25968;&#25454;&#22686;&#24378;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation. (arXiv:2305.12599v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#36923;&#36753;&#39537;&#21160;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#26469;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36923;&#36753;&#25512;&#29702;&#33021;&#21147;&#12290;&#36890;&#36807;&#23558;&#21407;&#22987;&#25991;&#26412;&#36716;&#25442;&#20026;&#25277;&#35937;&#24847;&#20041;&#34920;&#36848;&#22270;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#36923;&#36753;&#20462;&#25913;&#21644;&#36716;&#25442;&#65292;&#29983;&#25104;&#22686;&#24378;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#21319;&#27169;&#22411;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#20307;&#31995;&#32467;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#36923;&#36753;&#25512;&#29702;&#30456;&#32467;&#21512;&#21487;&#20197;&#22686;&#24378;&#23427;&#20204;&#22312;&#38382;&#39064;&#35299;&#20915;&#20013;&#30340;&#33021;&#21147;&#65292;&#20351;&#20854;&#26356;&#21152;&#24378;&#22823;&#21644;&#21487;&#38752;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#25512;&#29702;&#30340;&#22797;&#26434;&#24615;&#20351;&#24471;&#20174;&#32593;&#39029;&#19978;&#25910;&#38598;&#21487;&#38752;&#30340;&#25968;&#25454;&#26469;&#24314;&#31435;&#20840;&#38754;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#38754;&#20020;&#22256;&#38590;&#65292;&#36827;&#32780;&#24433;&#21709;&#19979;&#28216;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36923;&#36753;&#39537;&#21160;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;AMR-LDA&#12290;AMR-LDA&#23558;&#21407;&#22987;&#25991;&#26412;&#36716;&#25442;&#25104;&#25277;&#35937;&#24847;&#20041;&#34920;&#31034;&#65288;AMR&#65289;&#22270;&#65292;&#36825;&#26159;&#19968;&#31181;&#32467;&#26500;&#21270;&#30340;&#35821;&#20041;&#34920;&#31034;&#65292;&#21253;&#21547;&#20102;&#21477;&#23376;&#30340;&#36923;&#36753;&#32467;&#26500;&#65292;&#28982;&#21518;&#23545;&#35813;&#22270;&#36827;&#34892;&#25805;&#20316;&#20197;&#29983;&#25104;&#36923;&#36753;&#20462;&#25913;&#21518;&#30340;AMR&#22270;&#12290;&#20462;&#25913;&#21518;&#30340;AMR&#22270;&#38543;&#21518;&#34987;&#36716;&#25442;&#22238;&#25991;&#26412;&#65292;&#20174;&#32780;&#21019;&#24314;&#22686;&#24378;&#25968;&#25454;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20307;&#31995;&#32467;&#26500;&#26080;&#20851;&#65292;&#24182;&#36890;&#36807;&#25552;&#31034;&#22686;&#24378;&#26469;&#22686;&#24378;&#29983;&#25104;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT-3.5&#21644;GPT-4&#65289;&#65292;&#24182;&#36890;&#36807;&#24494;&#35843;&#26469;&#22686;&#24378;&#21028;&#21035;&#22411;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining large language models with logical reasoning enhance their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges to gathering reliable data from web for building comprehensive training datasets, subsequently affecting the performance on downstream tasks. To address this, we introduce a novel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the original text into an Abstract Meaning Representation (AMR) graph, a structured semantic representation that encapsulates the logic structure of the sentence, upon which operations are performed to generate logically modified AMR graphs. The modified AMR graphs are subsequently converted back into texts to create augmented data. Notably, our methodology is architecture-agnostic and enhances generative large language models, such as GPT-3.5 and GPT-4, through prompt augmentation, and fine-tuning discriminative large language models through 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24378;&#35843;&#20102;&#24403;&#21069;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#20010;&#24615;&#21270;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;LaMP&#65288;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#30340;&#20010;&#24615;&#21270;&#22522;&#20934;&#65289;&#65292;&#24182;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#20219;&#21153;&#65292;&#35774;&#35745;&#20102;&#19971;&#39033;&#20010;&#24615;&#21270;&#20219;&#21153;&#20197;&#21450;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#21033;&#29992;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#20854;&#29983;&#25104;&#32467;&#26524;&#26126;&#26174;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.11406</link><description>&lt;p&gt;
LaMP&#65306;&#24403;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36935;&#35265;&#20010;&#24615;&#21270;
&lt;/p&gt;
&lt;p&gt;
LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24378;&#35843;&#20102;&#24403;&#21069;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#20010;&#24615;&#21270;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;LaMP&#65288;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#30340;&#20010;&#24615;&#21270;&#22522;&#20934;&#65289;&#65292;&#24182;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#29983;&#25104;&#20219;&#21153;&#65292;&#35774;&#35745;&#20102;&#19971;&#39033;&#20010;&#24615;&#21270;&#20219;&#21153;&#20197;&#21450;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#21033;&#29992;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#20854;&#29983;&#25104;&#32467;&#26524;&#26126;&#26174;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24378;&#35843;&#22312;&#24403;&#21069;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#39046;&#22495;&#30340;&#20010;&#24615;&#21270;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#20171;&#32461;&#20102;LaMP&#22522;&#20934;&#8212;&#8212;&#29992;&#20110;&#35757;&#32451;&#21644;&#35780;&#20272;&#29983;&#25104;&#20010;&#24615;&#21270;&#36755;&#20986;&#30340;&#35821;&#35328;&#27169;&#22411;&#30340;&#26032;&#20856;&#33539;&#12290;LaMP&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#35780;&#20272;&#26694;&#26550;&#65292;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#35821;&#35328;&#20219;&#21153;&#21644;&#27599;&#20010;&#29992;&#25143;&#30340;&#22810;&#20010;&#26465;&#30446;&#65292;&#21253;&#25324;&#19977;&#20010;&#20998;&#31867;&#20219;&#21153;&#21644;&#22235;&#20010;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#30340;&#19971;&#20010;&#20010;&#24615;&#21270;&#20219;&#21153;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#26041;&#27861;&#65292;&#21487;&#20174;&#29992;&#25143;&#37197;&#32622;&#25991;&#20214;&#20013;&#26816;&#32034;&#20010;&#24615;&#21270;&#39033;&#30446;&#65292;&#26500;&#24314;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20010;&#24615;&#21270;&#25552;&#31034;&#12290;&#25105;&#20204;&#30340;&#22522;&#32447;&#38646;-shot&#21644;&#24494;&#35843;&#27169;&#22411;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21033;&#29992;&#20010;&#20154;&#36164;&#26009;&#25193;&#23637;&#30340;LM&#20248;&#20110;&#19981;&#32771;&#34385;&#20010;&#20154;&#36164;&#26009;&#20449;&#24687;&#30340;&#23545;&#24212;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper highlights the importance of personalization in the current state of natural language understanding and generation and introduces the LaMP benchmark -- a novel benchmark for training and evaluating language models for producing personalized outputs. LaMP offers a comprehensive evaluation framework with diverse language tasks and multiple entries for each user profile. It consists of seven personalized tasks, spanning three classification and four text generation tasks. We also propose a retrieval augmentation approach that retrieves personalized items from user profiles to construct personalized prompts for large language models. Our baseline zero-shot and fine-tuned model results indicate that LMs utilizing profile augmentation outperform their counterparts that do not factor in profile information.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25552;&#31034;&#26041;&#27861;Error Analysis Prompting&#21487;&#25913;&#21892;LLMs&#22312;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#35780;&#20272;&#19978;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2303.13809</link><description>&lt;p&gt;
&#38169;&#35823;&#20998;&#26512;&#25552;&#31034;&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#32763;&#35793;&#35780;&#20272;&#26041;&#38754;&#23454;&#29616;&#20102;&#20154;&#31867;&#27700;&#24179;&#65306;&#20197;ChatGPT&#20026;&#20363;&#36827;&#34892;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT. (arXiv:2303.13809v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25552;&#31034;&#26041;&#27861;Error Analysis Prompting&#21487;&#25913;&#21892;LLMs&#22312;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#35780;&#20272;&#19978;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20154;&#31867;&#27700;&#24179;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24335;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20363;&#22914;ChatGPT&#65292;&#22312;&#26426;&#22120;&#32763;&#35793;&#12289;&#38382;&#31572;&#12289;&#25991;&#26412;&#25688;&#35201;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#31561;&#22810;&#20010;NLP&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21033;&#29992;ChatGPT&#35780;&#20272;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#22312;&#31995;&#32479;&#27700;&#24179;&#19978;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#27573;&#33853;&#27700;&#24179;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;LLM&#22312;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#35780;&#20272;&#19978;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#20851;&#20110;&#20960;&#31181;&#25552;&#31034;&#26041;&#27861;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;Chain-of-Thoughts&#21644;Error Analysis&#32467;&#21512;&#36215;&#26469;&#65292;&#19968;&#31181;&#26032;&#30340;&#25552;&#31034;&#26041;&#27861;Error Analysis Prompting&#65292;&#20687;ChatGPT&#36825;&#26679;&#30340;LLM&#21487;&#20197;&#22312;&#31995;&#32479;&#21644;&#27573;&#33853;&#32423;&#21035;&#19978;&#29983;&#25104;&#20154;&#31867;&#33324;&#30340;&#26426;&#22120;&#32763;&#35793;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;ChatGPT&#20316;&#20026;&#26426;&#22120;&#32763;&#35793;&#35780;&#20272;&#22120;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#22312;&#25552;&#20379;&#21333;&#20010;&#26597;&#35810;&#20013;&#30340;&#22810;&#20010;&#35793;&#25991;&#26102;&#23384;&#22312;&#19981;&#31283;&#23450;&#30340;&#35780;&#20998;&#21644;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding. Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods. Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called \textbf{\texttt{Error Analysis Prompting}}, LLMs like ChatGPT can \textit{generate human-like MT evaluations at both the system and segment level}. Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query. Our findings
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#30340;&#24847;&#22270;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#65306;&#32858;&#31867;&#31639;&#27861;&#21644;&#29992;&#25143;&#35805;&#35821;&#23884;&#20837;&#31354;&#38388;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;MiniLM&#19982;&#23618;&#27425;&#32858;&#31867;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24847;&#22270;&#24402;&#32435;&#20219;&#21153;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.02021</link><description>&lt;p&gt;
&#19982;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#30340;&#24847;&#22270;&#35782;&#21035;&#30456;&#20851;&#30340;&#35805;&#35821;&#23884;&#20837;&#21644;&#32858;&#31867;&#26041;&#27861;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue. (arXiv:2212.02021v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#30340;&#24847;&#22270;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20004;&#20010;&#20851;&#38190;&#22240;&#32032;&#65306;&#32858;&#31867;&#31639;&#27861;&#21644;&#29992;&#25143;&#35805;&#35821;&#23884;&#20837;&#31354;&#38388;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;MiniLM&#19982;&#23618;&#27425;&#32858;&#31867;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24847;&#22270;&#24402;&#32435;&#20219;&#21153;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#26080;&#30417;&#30563;&#26041;&#27861;&#65292;&#20197;&#20811;&#26381;&#35774;&#35745;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#22270;&#35889;&#20013;&#30340;&#20856;&#22411;&#25361;&#25112;&#65306;&#20026;&#27599;&#20010;&#23545;&#35805;&#36716;&#25240;&#25351;&#23450;&#24847;&#22270;&#26631;&#31614;&#65288;&#24847;&#22270;&#32858;&#31867;&#65289;&#24182;&#22522;&#20110;&#24847;&#22270;&#32858;&#31867;&#26041;&#27861;&#29983;&#25104;&#19968;&#32452;&#24847;&#22270;&#65288;&#24847;&#22270;&#24402;&#32435;&#65289;&#12290;&#25105;&#20204;&#20551;&#35774;&#33258;&#21160;&#24402;&#32435;&#24847;&#22270;&#26377;&#20004;&#20010;&#26174;&#33879;&#22240;&#32032;&#65306;&#65288;1&#65289;&#24847;&#22270;&#26631;&#31614;&#30340;&#32858;&#31867;&#31639;&#27861;&#21644;&#65288;2&#65289;&#29992;&#25143;&#35805;&#35821;&#23884;&#20837;&#31354;&#38388;&#12290; &#25105;&#20204;&#26681;&#25454;DSTC11&#35780;&#20272;&#27604;&#36739;&#20102;&#29616;&#26377;&#30340;&#25104;&#21697;&#32858;&#31867;&#27169;&#22411;&#21644;&#23884;&#20837;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#35748;&#30495;&#32771;&#34385;&#24847;&#22270;&#24402;&#32435;&#20219;&#21153;&#20013;&#35805;&#35821;&#23884;&#20837;&#21644;&#32858;&#31867;&#26041;&#27861;&#30340;&#32508;&#21512;&#36873;&#25321;&#26159;&#24517;&#35201;&#30340;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;MiniLM&#19982;&#23618;&#27425;&#32858;&#31867;&#30456;&#32467;&#21512;&#21487;&#26174;&#33879;&#25552;&#39640;&#24847;&#22270;&#24402;&#32435;&#20219;&#21153;&#20013;&#30340;NMI&#65292;ARI&#65292;F1&#65292;&#20934;&#30830;&#24615;&#21644;&#31034;&#20363;&#35206;&#30422;&#12290;&#28304;&#20195;&#30721;&#21487;&#22312;https://github.com/Jeiyoon/dstc11-track2&#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
The focus of this work is to investigate unsupervised approaches to overcome quintessential challenges in designing task-oriented dialog schema: assigning intent labels to each dialog turn (intent clustering) and generating a set of intents based on the intent clustering methods (intent induction). We postulate there are two salient factors for automatic induction of intents: (1) clustering algorithm for intent labeling and (2) user utterance embedding space. We compare existing off-the-shelf clustering models and embeddings based on DSTC11 evaluation. Our extensive experiments demonstrate that the combined selection of utterance embedding and clustering method in the intent induction task should be carefully considered. We also present that pretrained MiniLM with Agglomerative clustering shows significant improvement in NMI, ARI, F1, accuracy and example coverage in intent induction tasks. The source codes are available at https://github.com/Jeiyoon/dstc11-track2.
&lt;/p&gt;</description></item></channel></rss>