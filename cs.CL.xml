<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#65292;&#20197;&#24357;&#34917;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.15427</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22270;&#31070;&#32463;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#65292;&#20197;&#24357;&#34917;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#21508;&#31181;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#20934;&#30830;&#25429;&#25417;&#21644;&#36820;&#22238;&#22522;&#20110;&#30693;&#35782;&#30340;&#20449;&#24687;&#26041;&#38754;&#20173;&#23384;&#22312;&#22266;&#26377;&#38480;&#21046;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#24050;&#32463;&#25506;&#32034;&#20102;&#21033;&#29992;&#30693;&#35782;&#22270;&#26469;&#36890;&#36807;&#32852;&#21512;&#35757;&#32451;&#21644;&#23450;&#21046;&#27169;&#22411;&#26550;&#26500;&#22686;&#24378;&#35821;&#35328;&#24314;&#27169;&#65292;&#20294;&#26159;&#23558;&#27492;&#24212;&#29992;&#20110;LLMs&#23384;&#22312;&#21442;&#25968;&#25968;&#37327;&#24222;&#22823;&#21644;&#35745;&#31639;&#25104;&#26412;&#39640;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22914;&#20309;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;LLMs&#24182;&#36991;&#20813;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#33258;&#23450;&#20041;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22270;&#31070;&#32463;&#25552;&#31034;&#65288;GNP&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#21363;&#25554;&#21363;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#39044;&#35757;&#32451;&#30340;LLMs&#20174;&#30693;&#35782;&#22270;&#20013;&#23398;&#20064;&#26377;&#30410;&#30340;&#30693;&#35782;&#12290;GNP&#21253;&#25324;&#21508;&#31181;&#35774;&#35745;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#32534;&#30721;&#22120;&#12289;&#36328;&#27169;&#24577;&#27719;&#32858;&#27169;&#22359;&#12289;&#22495;&#25237;&#24433;&#22120;&#21644;&#33258;&#30417;&#30563;&#38142;&#25509;&#39044;&#27979;&#30446;&#26631;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;GNP&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#35780;&#20272;&#20219;&#21153;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#20026;&#31038;&#20250;&#23618;&#38754;&#23545;LLMs&#28508;&#22312;&#39118;&#38505;&#30340;&#29702;&#35299;&#25552;&#20379;&#20102;&#37325;&#35201;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2307.03109</link><description>&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#35780;&#20272;&#20219;&#21153;&#21253;&#25324;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#26412;&#25991;&#20026;&#31038;&#20250;&#23618;&#38754;&#23545;LLMs&#28508;&#22312;&#39118;&#38505;&#30340;&#29702;&#35299;&#25552;&#20379;&#20102;&#37325;&#35201;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30001;&#20110;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#30340;&#21069;&#25152;&#26410;&#26377;&#30340;&#24615;&#33021;&#32780;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#38543;&#30528;LLMs&#22312;&#30740;&#31350;&#21644;&#26085;&#24120;&#20351;&#29992;&#20013;&#32487;&#32493;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#23427;&#20204;&#30340;&#35780;&#20272;&#21464;&#24471;&#36234;&#26469;&#36234;&#20851;&#38190;&#65292;&#19981;&#20165;&#22312;&#20219;&#21153;&#27700;&#24179;&#19978;&#65292;&#32780;&#19988;&#22312;&#31038;&#20250;&#23618;&#38754;&#19978;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#23427;&#20204;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#37324;&#65292;&#24050;&#32463;&#20570;&#20986;&#20102;&#30456;&#24403;&#22823;&#30340;&#21162;&#21147;&#26469;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#26469;&#30740;&#31350;LLMs&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;LLMs&#30340;&#36825;&#20123;&#35780;&#20272;&#26041;&#27861;&#65292;&#37325;&#28857;&#20851;&#27880;&#19977;&#20010;&#20851;&#38190;&#32500;&#24230;&#65306;&#35780;&#20272;&#20160;&#20040;&#12289;&#22312;&#21738;&#37324;&#35780;&#20272;&#20197;&#21450;&#22914;&#20309;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20174;&#35780;&#20272;&#20219;&#21153;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#19968;&#20010;&#27010;&#36848;&#65292;&#28085;&#30422;&#20102;&#19968;&#33324;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12289;&#25512;&#29702;&#12289;&#21307;&#23398;&#24212;&#29992;&#12289;&#20262;&#29702;&#23398;&#12289;&#25945;&#32946;&#12289;&#33258;&#28982;&#31185;&#23398;&#21644;&#31038;&#20250;&#31185;&#23398;&#12289;&#20195;&#29702;&#24212;&#29992;&#21644;&#20854;&#20182;&#39046;&#22495;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#28145;&#20837;&#25506;&#35752;&#35780;&#20272;&#26041;&#27861;&#21644;&#22522;&#20934;&#31572;&#26696;&#26469;&#22238;&#31572;&#8220;&#22312;&#21738;&#37324;&#8221;&#21644;&#8220;&#22914;&#20309;&#8221;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#25512;&#29702;&#35825;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#8212;&#8212;CoRe&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;CoRe &#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.16257</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#20316;&#25512;&#29702;&#35825;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16257
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21512;&#20316;&#25512;&#29702;&#35825;&#23548;&#30340;&#35821;&#35328;&#27169;&#22411;&#8212;&#8212;CoRe&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;&#25968;&#23398;&#24212;&#29992;&#39064;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;CoRe &#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411; (PLMs) &#20026;&#38656;&#35201;&#39640;&#27700;&#24179;&#26234;&#33021;&#30340;&#25361;&#25112;&#24615;&#38382;&#39064;&#65288;&#22914;&#25968;&#23398;&#24212;&#29992;&#39064;&#65289;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#24212;&#29992;&#29616;&#26377;&#30340; PLMs &#21040;&#25968;&#23398;&#24212;&#29992;&#39064;&#19978;&#20250;&#22833;&#36133;&#65292;&#22240;&#20026;&#20854;&#29983;&#25104;&#30340;&#36807;&#31243;&#32570;&#20047;&#36275;&#22815;&#30340;&#30417;&#30563;&#65292;&#32570;&#20047;&#20687;&#20154;&#31867;&#19968;&#26679;&#30340;&#24555;&#36895;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#20154;&#31867;&#30340;&#25512;&#29702;&#36807;&#31243;&#26377;&#19968;&#20010;&#21452;&#37325;&#25512;&#29702;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;&#21363;&#26102;&#21453;&#24212;&#31995;&#32479; (system 1) &#21644;&#19968;&#20010;&#31934;&#32454;&#25512;&#29702;&#31995;&#32479; (system 2)&#65292;&#25972;&#20010;&#25512;&#29702;&#36807;&#31243;&#30001;&#23427;&#20204;&#30340;&#20132;&#20114;&#20915;&#23450;&#12290;&#36825;&#21551;&#21457;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21512;&#20316;&#25512;&#29702;&#35825;&#23548;&#30340; PLM &#27169;&#22411;&#65292;&#31216;&#20026; Cooperative Reasoning (CoRe)&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#20687;&#20154;&#31867;&#25512;&#29702;&#32467;&#26500;&#30340;&#26550;&#26500;&#65292;&#20854;&#20013; system 1 &#20316;&#20026;&#29983;&#25104;&#22120;&#65292;system 2 &#20316;&#20026;&#39564;&#35777;&#22120;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#29983;&#25104;&#22120;&#36127;&#36131;&#20135;&#29983;&#25512;&#29702;&#36335;&#24452;&#65292;&#39564;&#35777;&#22120;&#29992;&#20110;&#30417;&#30563;&#35780;&#20272;&#20197;&#33719;&#21462;&#21487;&#38752;&#30340;&#21453;&#39304;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;CoRe &#22312;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale pre-trained language models (PLMs) bring new opportunities to challenging problems, especially those that need high-level intelligence, such as the math word problem (MWPs). However, directly applying existing PLMs to MWPs can fail as the generation process lacks sufficient supervision and thus lacks fast adaptivity as humans. We notice that human reasoning has a dual reasoning framework that consists of an immediate reaction system (system 1) and a delicate reasoning system (system 2), where the entire reasoning is determined by their interaction. This inspires us to develop a cooperative reasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe), resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the verifier. In our approach, the generator is responsible for generating reasoning paths, and the verifiers are used to supervise the evaluation in order to obtain reliable feedback for the generator. We evaluate our
&lt;/p&gt;</description></item></channel></rss>