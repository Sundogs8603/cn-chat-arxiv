<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#25552;&#28860;&#20013;&#20855;&#26377;&#29420;&#29305;&#20248;&#21183;&#65292;&#20294;&#22312;&#22788;&#29702;&#24773;&#24863;&#26102;&#20173;&#23384;&#22312;&#19968;&#23450;&#23616;&#38480;&#24615;&#65292;&#26080;&#35770;&#26159;&#23545;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#36824;&#26159;&#20154;&#31867;&#27880;&#37322;&#21592;&#32780;&#35328;&#12290;</title><link>https://arxiv.org/abs/2403.16584</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#25110;&#20154;&#31867;&#65289;&#26159;&#21542;&#33021;&#36827;&#34892;&#25991;&#26412;&#25552;&#28860;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models (or Humans) Distill Text?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16584
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#25552;&#28860;&#20013;&#20855;&#26377;&#29420;&#29305;&#20248;&#21183;&#65292;&#20294;&#22312;&#22788;&#29702;&#24773;&#24863;&#26102;&#20173;&#23384;&#22312;&#19968;&#23450;&#23616;&#38480;&#24615;&#65292;&#26080;&#35770;&#26159;&#23545;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#36824;&#26159;&#20154;&#31867;&#27880;&#37322;&#21592;&#32780;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#25552;&#28860;&#26041;&#38754;&#30340;&#28508;&#21147;&#65306;&#21363;&#21435;&#38500;&#19981;&#38656;&#35201;&#30340;&#31105;&#27490;&#21464;&#37327;&#30340;&#25991;&#26412;&#30165;&#36857;&#12290;&#25105;&#20204;&#21033;&#29992;&#20855;&#26377;&#19981;&#21516;&#26550;&#26500;&#21644;&#35757;&#32451;&#26041;&#27861;&#30340;&#19968;&#31995;&#21015;LLMs&#26469;&#35782;&#21035;&#21644;&#21435;&#38500;&#20851;&#20110;&#30446;&#26631;&#21464;&#37327;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#20182;&#30456;&#20851;&#20449;&#21495;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25581;&#31034;&#20102;LLMs&#22312;&#22788;&#29702;&#25552;&#28860;&#20013;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#20026;&#22312;&#28041;&#21450;&#25991;&#26412;&#25968;&#25454;&#30340;&#35745;&#31639;&#31038;&#20250;&#31185;&#23398;&#35843;&#26597;&#20013;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#30340;&#31574;&#30053;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;&#23588;&#20854;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#24378;&#28872;&#27979;&#35797;&#24773;&#24863;&#31227;&#38500;&#26102;&#65292;&#32463;&#36807;LLM&#25552;&#28860;&#30340;&#25991;&#26412;&#19982;&#24773;&#24863;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#32852;&#20173;&#28982;&#21487;&#20197;&#34987;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#28165;&#26224;&#22320;&#26816;&#27979;&#21040;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20154;&#31867;&#27880;&#37322;&#21592;&#22312;&#20445;&#30041;&#20854;&#20182;&#35821;&#20041;&#20869;&#23481;&#30340;&#21516;&#26102;&#65292;&#20063;&#24456;&#38590;&#25552;&#28860;&#20986;&#24773;&#24863;&#12290;&#36825;&#34920;&#26126;&#21487;&#33021;&#23384;&#22312;&#19968;&#23450;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16584v1 Announce Type: new  Abstract: We investigate the potential of large language models (LLMs) to distill text: to remove the textual traces of an undesired forbidden variable. We employ a range of LLMs with varying architectures and training approaches to distill text by identifying and removing information about the target variable while preserving other relevant signals. Our findings shed light on the strengths and limitations of LLMs in addressing the distillation and provide insights into the strategies for leveraging these models in computational social science investigations involving text data. In particular, we show that in the strong test of removing sentiment, the statistical association between the processed text and sentiment is still clearly detectable to machine learning classifiers post-LLM-distillation. Furthermore, we find that human annotators also struggle to distill sentiment while preserving other semantic content. This suggests there may be limited
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.11894</link><description>&lt;p&gt;
&#20174;&#21487;&#35299;&#37322;&#21040;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#30103;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#23454;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#36890;&#36807;&#35299;&#20915;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#21307;&#30103;&#20445;&#20581;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;DL&#30340;NLP&#26041;&#27861;&#26085;&#30410;&#22797;&#26434;&#65292;&#38656;&#35201;&#36879;&#26126;&#30340;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#25110;&#33267;&#23569;&#26159;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#36827;&#34892;&#21487;&#38752;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;&#26412;&#25991;&#23545;&#21307;&#30103;&#20581;&#24247;NLP&#20013;&#30340;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;DL&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#33539;&#22260;&#23457;&#26597;&#12290;&#24341;&#20837;&#20102;&#26415;&#35821;&#8220;XIAI&#8221;&#65288;eXplainable&#21644;Interpretable Artificial Intelligence&#65289;&#20197;&#21306;&#20998;XAI&#21644;IAI&#12290;&#26041;&#27861;&#26681;&#25454;&#20854;&#21151;&#33021;&#65288;&#27169;&#22411;&#12289;&#36755;&#20837;&#12289;&#36755;&#20986;&#20026;&#22522;&#30784;&#65289;&#21644;&#33539;&#22260;&#65288;&#23616;&#37096;&#12289;&#20840;&#23616;&#65289;&#36827;&#19968;&#27493;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#27880;&#24847;&#26426;&#21046;&#26159;&#26368;&#20027;&#35201;&#30340;&#26032;&#20852;IAI&#12290;&#27492;&#22806;&#65292;IAI&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#23545;&#25239;XAI&#12290;&#30830;&#23450;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22823;&#22810;&#25968;XIAI&#19981;&#25506;&#32034;&#8220;&#20840;&#23616;&#8221;&#24314;&#27169;&#36807;&#31243;&#65292;&#32570;&#20047;&#26368;&#20339;&#23454;&#36341;&#65292;&#24182;&#19988;&#38656;&#35201;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;Transformers&#30340;&#26032;&#22411;&#27169;&#22411;&#21512;&#24182;&#26041;&#27861;&#65292;&#21033;&#29992;Fisher&#20449;&#24687;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#25552;&#39640;&#20102;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.09891</link><description>&lt;p&gt;
Fisher Mask&#33410;&#28857;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#21512;&#24182;
&lt;/p&gt;
&lt;p&gt;
Fisher Mask Nodes for Language Model Merging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09891
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;Transformers&#30340;&#26032;&#22411;&#27169;&#22411;&#21512;&#24182;&#26041;&#27861;&#65292;&#21033;&#29992;Fisher&#20449;&#24687;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#25552;&#39640;&#20102;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#19979;&#28216;&#24615;&#33021;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#22914;BERT&#21450;&#20854;&#34893;&#29983;&#29289;&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#26222;&#36941;&#24615;&#20063;&#23548;&#33268;&#20102;&#20219;&#21153;&#29305;&#23450;&#24494;&#35843;&#27169;&#22411;&#30340;&#28608;&#22686;&#12290;&#22312;&#22810;&#20219;&#21153;&#22330;&#26223;&#20013;&#65292;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#21482;&#33021;&#24456;&#22909;&#22320;&#25191;&#34892;&#19968;&#39033;&#20219;&#21153;&#65292;&#22240;&#27492;&#38656;&#35201;&#39069;&#22806;&#30340;&#35757;&#32451;&#25110;&#38598;&#25104;&#12290;&#27169;&#22411;&#21512;&#24182;&#36825;&#19968;&#19981;&#26029;&#22686;&#38271;&#30340;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#23558;&#22810;&#20010;&#20219;&#21153;&#29305;&#23450;&#27169;&#22411;&#21512;&#24182;&#20026;&#21333;&#20010;&#22810;&#20219;&#21153;&#27169;&#22411;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;Transformers&#30340;&#27169;&#22411;&#21512;&#24182;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#20808;&#21069;Fisher&#21152;&#26435;&#24179;&#22343;&#21644;Fisher&#20449;&#24687;&#22312;&#27169;&#22411;&#20462;&#21098;&#20013;&#30340;&#24212;&#29992;&#30340;&#35265;&#35299;&#12290;&#36890;&#36807;&#21033;&#29992;Transformer&#26550;&#26500;&#20869;&#30340;mask&#33410;&#28857;&#30340;Fisher&#20449;&#24687;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#21152;&#26435;&#24179;&#22343;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#29616;&#20986;&#20102;&#31283;&#23450;&#19988;&#26174;&#33879;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
&lt;/p&gt;</description></item><item><title>LUCID&#26088;&#22312;&#36890;&#36807;&#39640;&#36136;&#37327;&#21644;&#35821;&#35328;&#22797;&#26434;&#30340;&#25968;&#25454;&#65292;&#20197;&#21450;&#39640;&#24230;&#33258;&#21160;&#21270;&#30340;LLM&#27169;&#22411;&#65292;&#35299;&#20915;&#29616;&#26377;&#25968;&#25454;&#38598;&#39046;&#22495;&#35206;&#30422;&#26377;&#38480;&#12289;&#23545;&#35805;&#29616;&#35937;&#26377;&#38480;&#12289;&#26410;&#26631;&#35760;&#30340;&#29305;&#28857;&#65292;&#20197;&#21450;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#25237;&#20837;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.00462</link><description>&lt;p&gt;
LUCID: &#30001;LLM&#29983;&#25104;&#30340;&#22797;&#26434;&#19988;&#26377;&#36259;&#23545;&#35805;
&lt;/p&gt;
&lt;p&gt;
LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00462
&lt;/p&gt;
&lt;p&gt;
LUCID&#26088;&#22312;&#36890;&#36807;&#39640;&#36136;&#37327;&#21644;&#35821;&#35328;&#22797;&#26434;&#30340;&#25968;&#25454;&#65292;&#20197;&#21450;&#39640;&#24230;&#33258;&#21160;&#21270;&#30340;LLM&#27169;&#22411;&#65292;&#35299;&#20915;&#29616;&#26377;&#25968;&#25454;&#38598;&#39046;&#22495;&#35206;&#30422;&#26377;&#38480;&#12289;&#23545;&#35805;&#29616;&#35937;&#26377;&#38480;&#12289;&#26410;&#26631;&#35760;&#30340;&#29305;&#28857;&#65292;&#20197;&#21450;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#25237;&#20837;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00462v1 &#20844;&#21578;&#31867;&#22411;:&#26032; &#25688;&#35201;:&#34394;&#25311;&#21161;&#25163;&#22312;&#23545;&#35805;&#33021;&#21147;&#26041;&#38754;&#21363;&#23558;&#36808;&#21521;&#19968;&#20010;&#37325;&#35201;&#36827;&#27493;&#65292;&#36825;&#24471;&#30410;&#20110;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#30495;&#27491;&#38761;&#21629;&#24615;&#30340;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#33021;&#21147;&#30340;&#20027;&#35201;&#29942;&#39048;&#20173;&#28982;&#26159;&#39640;&#36136;&#37327;&#21644;&#35821;&#35328;&#22797;&#26434;&#30340;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;&#29616;&#26377;&#25968;&#25454;&#38598;&#22312;&#35268;&#27169;&#19978;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#65292;&#20294;&#39046;&#22495;&#35206;&#30422;&#33539;&#22260;&#26377;&#38480;&#65292;&#21253;&#21547;&#23525;&#23525;&#26080;&#20960;&#30340;&#30495;&#27491;&#20855;&#25361;&#25112;&#24615;&#30340;&#23545;&#35805;&#29616;&#35937;&#65307;&#36825;&#20123;&#29616;&#35937;&#36890;&#24120;&#26410;&#26631;&#35760;&#65292;&#36825;&#20351;&#24471;&#22312;&#27809;&#26377;&#36153;&#26102;&#36153;&#21147;&#30340;&#20154;&#31867;&#35780;&#20272;&#30340;&#24773;&#20917;&#19979;&#38590;&#20197;&#35780;&#20272;&#27169;&#22411;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#12290;&#27492;&#22806;&#65292;&#30452;&#21040;&#29616;&#22312;&#65292;&#21019;&#24314;&#39640;&#36136;&#37327;&#23545;&#35805;&#25968;&#25454;&#20173;&#38656;&#35201;&#30456;&#24403;&#22823;&#37327;&#30340;&#20154;&#21147;&#25237;&#20837;&#65292;&#36825;&#38480;&#21046;&#20102;&#36825;&#20123;&#25968;&#25454;&#38598;&#30340;&#35268;&#27169;&#20197;&#21450;&#24555;&#36895;&#20026;&#26032;&#30446;&#26631;&#39046;&#22495;&#30340;&#25968;&#25454;&#22686;&#37327;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;LUCID&#26469;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#20010;&#27169;&#22359;&#21270;&#19988;&#39640;&#24230;&#33258;&#21160;&#21270;&#30340;LLM
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00462v1 Announce Type: new  Abstract: Virtual assistants are poised to take a dramatic leap forward in terms of their dialogue capabilities, spurred by recent advances in transformer-based Large Language Models (LLMs). Yet a major bottleneck to achieving genuinely transformative task-oriented dialogue capabilities remains the scarcity of high quality and linguistically sophisticated data. Existing datasets, while impressive in scale, have limited domain coverage and contain few genuinely challenging conversational phenomena; those which are present are typically unlabelled, making it difficult to assess the strengths and weaknesses of models without time-consuming and costly human evaluation. Moreover, creating high quality dialogue data has until now required considerable human input, limiting both the scale of these datasets and the ability to rapidly bootstrap data for a new target domain. We aim to overcome these issues with LUCID, a modularised and highly automated LLM-
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#23558;&#21313;&#20108;&#20010;LLMs&#32452;&#25104;&#30340;LLM&#38598;&#25104;&#26041;&#27861;&#19982;925&#21517;&#20154;&#31867;&#39044;&#27979;&#32773;&#30340;&#32676;&#20307;&#39044;&#27979;&#36827;&#34892;&#27604;&#36739;&#65292;&#21457;&#29616;LLM&#32676;&#20307;&#20248;&#20110;&#31616;&#21333;&#30340;&#26080;&#20449;&#24687;&#22522;&#20934;&#65292;&#24182;&#22312;&#32479;&#35745;&#19978;&#31561;&#25928;&#20110;&#20154;&#31867;&#32676;&#20307;&#12290;</title><link>https://arxiv.org/abs/2402.19379</link><description>&lt;p&gt;
&#30789;&#35895;&#20154;&#32676;&#30340;&#26234;&#24935;&#65306;LLM&#38598;&#25104;&#39044;&#27979;&#33021;&#21147;&#36798;&#21040;&#20154;&#32676;&#20934;&#30830;&#29575;&#27700;&#24179;
&lt;/p&gt;
&lt;p&gt;
Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19379
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#23558;&#21313;&#20108;&#20010;LLMs&#32452;&#25104;&#30340;LLM&#38598;&#25104;&#26041;&#27861;&#19982;925&#21517;&#20154;&#31867;&#39044;&#27979;&#32773;&#30340;&#32676;&#20307;&#39044;&#27979;&#36827;&#34892;&#27604;&#36739;&#65292;&#21457;&#29616;LLM&#32676;&#20307;&#20248;&#20110;&#31616;&#21333;&#30340;&#26080;&#20449;&#24687;&#22522;&#20934;&#65292;&#24182;&#22312;&#32479;&#35745;&#19978;&#31561;&#25928;&#20110;&#20154;&#31867;&#32676;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#36341;&#20013;&#20154;&#31867;&#39044;&#27979;&#20934;&#30830;&#24615;&#20381;&#36182;&#20110;&#8220;&#32676;&#20307;&#26234;&#24935;&#8221;&#25928;&#24212;&#65292;&#21363;&#36890;&#36807;&#32858;&#21512;&#19968;&#32676;&#20010;&#20307;&#39044;&#27979;&#32773;&#30340;&#39044;&#27979;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#23545;&#26410;&#26469;&#20107;&#20214;&#30340;&#39044;&#27979;&#12290;&#36807;&#21435;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#39044;&#27979;&#33021;&#21147;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20316;&#20026;&#20010;&#20307;&#39044;&#27979;&#32773;&#30340;&#21069;&#27839;LLMs&#34920;&#29616;&#19981;&#20339;&#65292;&#19982;&#20154;&#31867;&#32676;&#20307;&#39044;&#27979;&#27604;&#36187;&#30340;&#40644;&#37329;&#26631;&#20934;&#30456;&#27604;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#30001;&#21313;&#20108;&#20010;LLMs&#32452;&#25104;&#30340;LLM&#38598;&#25104;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#23558;31&#20010;&#20108;&#20803;&#38382;&#39064;&#30340;&#32858;&#21512;LLM&#39044;&#27979;&#19982;&#19968;&#20010;&#26469;&#33258;&#19977;&#20010;&#26376;&#39044;&#27979;&#27604;&#36187;&#30340;925&#21517;&#20154;&#31867;&#39044;&#27979;&#32773;&#30340;&#32676;&#20307;&#39044;&#27979;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#20998;&#26512;&#34920;&#26126;&#65292;LLM&#32676;&#20307;&#30340;&#34920;&#29616;&#20248;&#20110;&#31616;&#21333;&#30340;&#26080;&#20449;&#24687;&#22522;&#20934;&#65292;&#24182;&#22312;&#32479;&#35745;&#19978;&#31561;&#25928;&#20110;&#20154;&#31867;&#32676;&#20307;&#12290;&#25105;&#20204;&#36824;&#35266;&#23519;&#21040;&#19968;&#31181;&#39034;&#20174;&#25928;&#24212;&#65292;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26126;&#26174;&#39640;&#20110;50%&#65292;&#23613;&#31649;&#20960;&#20046;&#26159;&#24179;&#31561;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#36890;&#36807;&#36827;&#21270;&#20195;&#29702;&#30340;&#21151;&#33021;&#26469;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;</title><link>https://arxiv.org/abs/2402.11359</link><description>&lt;p&gt;
&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Training Language Model Agents without Modifying Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#22312;&#19981;&#20462;&#25913;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65292;&#36890;&#36807;&#36827;&#21270;&#20195;&#29702;&#30340;&#21151;&#33021;&#26469;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#26368;&#36817;&#24050;&#32463;&#23558;&#24378;&#22823;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#37325;&#26032;&#23450;&#20041;&#20026;&#20195;&#29702;&#65292;&#20351;&#23427;&#20204;&#33021;&#22815;&#36890;&#36807;&#20351;&#29992;&#19987;&#38376;&#30340;&#21151;&#33021;&#33258;&#21160;&#21270;&#22320;&#23436;&#25104;&#22797;&#26434;&#20219;&#21153;&#12290;&#20026;&#20102;&#20419;&#36827;LLM&#20195;&#29702;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19981;&#20462;&#25913;LLM&#26435;&#37325;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;LLM&#20195;&#29702;&#30340;&#26032;&#33539;&#24335;&#65292;&#24403;LLM&#38590;&#20197;&#25110;&#26080;&#27861;&#36827;&#34892;&#20462;&#25913;&#26102;&#23588;&#20854;&#26377;&#29992;&#12290;&#21463;&#21040;&#20154;&#31867;&#19981;&#26029;&#38203;&#36896;&#24037;&#20855;&#20197;&#36866;&#24212;&#29616;&#23454;&#20219;&#21153;&#30340;&#21551;&#21457;&#65292;&#32780;&#19981;&#26159;&#25913;&#21464;&#25105;&#20204;&#30340;&#29983;&#29289;&#32467;&#26500;&#20197;&#36866;&#24212;&#19968;&#32452;&#38745;&#24577;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20986;&#36880;&#27493;&#38203;&#36896;&#20195;&#29702;&#30340;&#21151;&#33021;&#65292;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#19979;&#28216;&#20219;&#21153;&#65292;&#32780;&#19981;&#26159;&#20462;&#25913;LLM&#26435;&#37325;&#12290;&#36890;&#36807;&#23558;&#36825;&#20123;&#21151;&#33021;&#35270;&#20026;&#21487;&#23398;&#20064;&#30340;&#8220;&#20195;&#29702;&#21442;&#25968;&#8221;&#24182;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#27169;&#22411;&#35757;&#32451;&#30340;&#22522;&#26412;&#24605;&#24819;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;AgentOptimizer&#65292;&#21033;&#29992;LLM&#26356;&#26032;&#20195;&#29702;&#30340;&#21151;&#33021;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#20195;&#29702;&#35757;&#32451;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11359v1 Announce Type: new  Abstract: Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an agent training algorithm with tw
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24320;&#25918;AI&#30340;&#35821;&#38899;&#35782;&#21035;&#26381;&#21153;Whisper&#65292;&#24182;&#25351;&#20986;&#20854;&#20013;&#32422;1%&#30340;&#36716;&#24405;&#23384;&#22312;&#23436;&#20840;&#24187;&#35273;&#30340;&#30701;&#35821;&#25110;&#21477;&#23376;&#12290;&#36825;&#20123;&#24187;&#35273;&#20869;&#23481;&#20013;&#26377;38%&#21253;&#21547;&#26126;&#30830;&#30340;&#20260;&#23475;&#65292;&#22914;&#26292;&#21147;&#12289;&#34394;&#26500;&#30340;&#20010;&#20154;&#20449;&#24687;&#25110;&#34394;&#20551;&#30340;&#22522;&#20110;&#35270;&#39057;&#30340;&#26435;&#23041;&#12290;&#30740;&#31350;&#32773;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#24187;&#35273;&#21457;&#29983;&#30340;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#30001;&#20110;&#35821;&#38899;&#31867;&#22411;&#21644;&#20581;&#24247;&#29366;&#20917;&#30340;&#19981;&#21516;&#21487;&#33021;&#23548;&#33268;&#30340;&#28508;&#22312;&#24046;&#24322;&#12290;&#20182;&#20204;&#21628;&#21505;&#34892;&#19994;&#20174;&#19994;&#32773;&#25913;&#21892;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#24187;&#35273;&#65292;&#24182;&#22686;&#24378;&#23545;&#19979;&#28216;&#28508;&#22312;&#20559;&#35265;&#30340;&#35748;&#35782;&#12290;</title><link>https://arxiv.org/abs/2402.08021</link><description>&lt;p&gt;
&#19981;&#23567;&#24515;&#30340;&#32819;&#35821;&#65306;&#35821;&#38899;&#36716;&#25991;&#26412;&#24187;&#35273;&#30340;&#21361;&#23475;
&lt;/p&gt;
&lt;p&gt;
Careless Whisper: Speech-to-Text Hallucination Harms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08021
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#24320;&#25918;AI&#30340;&#35821;&#38899;&#35782;&#21035;&#26381;&#21153;Whisper&#65292;&#24182;&#25351;&#20986;&#20854;&#20013;&#32422;1%&#30340;&#36716;&#24405;&#23384;&#22312;&#23436;&#20840;&#24187;&#35273;&#30340;&#30701;&#35821;&#25110;&#21477;&#23376;&#12290;&#36825;&#20123;&#24187;&#35273;&#20869;&#23481;&#20013;&#26377;38%&#21253;&#21547;&#26126;&#30830;&#30340;&#20260;&#23475;&#65292;&#22914;&#26292;&#21147;&#12289;&#34394;&#26500;&#30340;&#20010;&#20154;&#20449;&#24687;&#25110;&#34394;&#20551;&#30340;&#22522;&#20110;&#35270;&#39057;&#30340;&#26435;&#23041;&#12290;&#30740;&#31350;&#32773;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#24187;&#35273;&#21457;&#29983;&#30340;&#20551;&#35774;&#65292;&#24182;&#25351;&#20986;&#20102;&#30001;&#20110;&#35821;&#38899;&#31867;&#22411;&#21644;&#20581;&#24247;&#29366;&#20917;&#30340;&#19981;&#21516;&#21487;&#33021;&#23548;&#33268;&#30340;&#28508;&#22312;&#24046;&#24322;&#12290;&#20182;&#20204;&#21628;&#21505;&#34892;&#19994;&#20174;&#19994;&#32773;&#25913;&#21892;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#24187;&#35273;&#65292;&#24182;&#22686;&#24378;&#23545;&#19979;&#28216;&#28508;&#22312;&#20559;&#35265;&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#38899;&#36716;&#25991;&#26412;&#26381;&#21153;&#26088;&#22312;&#23613;&#21487;&#33021;&#20934;&#30830;&#22320;&#36716;&#24405;&#36755;&#20837;&#38899;&#39057;&#12290;&#23427;&#20204;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#30340;&#20316;&#29992;&#36234;&#26469;&#36234;&#22823;&#65292;&#20363;&#22914;&#20010;&#20154;&#35821;&#38899;&#21161;&#25163;&#25110;&#20844;&#21496;&#19982;&#23458;&#25143;&#30340;&#20114;&#21160;&#20013;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#24320;&#25918;AI&#30340;Whisper&#65292;&#36825;&#26159;&#19968;&#31181;&#36229;&#36234;&#34892;&#19994;&#31454;&#20105;&#23545;&#25163;&#30340;&#26368;&#26032;&#26381;&#21153;&#12290;&#34429;&#28982;Whisper&#30340;&#35768;&#22810;&#36716;&#24405;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#22823;&#32422;1&#65285;&#30340;&#38899;&#39057;&#36716;&#24405;&#21253;&#21547;&#23436;&#20840;&#24187;&#35273;&#30340;&#30701;&#35821;&#25110;&#21477;&#23376;&#65292;&#36825;&#20123;&#30701;&#35821;&#25110;&#21477;&#23376;&#22312;&#22522;&#30784;&#38899;&#39057;&#20013;&#19981;&#23384;&#22312;&#12290;&#25105;&#20204;&#20027;&#39064;&#21270;&#22320;&#20998;&#26512;&#20102;Whisper&#24187;&#35273;&#30340;&#20869;&#23481;&#65292;&#21457;&#29616;38&#65285;&#30340;&#24187;&#35273;&#21253;&#21547;&#26126;&#30830;&#30340;&#20260;&#23475;&#65292;&#20363;&#22914;&#26292;&#21147;&#12289;&#34394;&#26500;&#30340;&#20010;&#20154;&#20449;&#24687;&#25110;&#34394;&#20551;&#30340;&#22522;&#20110;&#35270;&#39057;&#30340;&#26435;&#23041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#20851;&#20110;&#24187;&#35273;&#21457;&#29983;&#30340;&#20551;&#35774;&#65292;&#24182;&#25581;&#31034;&#20102;&#30001;&#20110;&#20581;&#24247;&#29366;&#20917;&#32780;&#23548;&#33268;&#30340;&#35821;&#38899;&#31867;&#22411;&#30340;&#28508;&#22312;&#24046;&#24322;&#12290;&#25105;&#20204;&#21628;&#21505;&#34892;&#19994;&#20174;&#19994;&#32773;&#25913;&#21892;Whisper&#20013;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#24187;&#35273;&#65292;&#24182;&#22686;&#24378;&#23545;&#19979;&#28216;&#28508;&#22312;&#20559;&#35265;&#30340;&#35748;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Speech-to-text services aim to transcribe input audio as accurately as possible. They increasingly play a role in everyday life, for example in personal voice assistants or in customer-company interactions. We evaluate Open AI's Whisper, a state-of-the-art service outperforming industry competitors. While many of Whisper's transcriptions were highly accurate, we found that roughly 1% of audio transcriptions contained entire hallucinated phrases or sentences, which did not exist in any form in the underlying audio. We thematically analyze the Whisper-hallucinated content, finding that 38% of hallucinations include explicit harms such as violence, made up personal information, or false video-based authority. We further provide hypotheses on why hallucinations occur, uncovering potential disparities due to speech type by health status. We call on industry practitioners to ameliorate these language-model-based hallucinations in Whisper, and to raise awareness of potential biases in downstr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26694;&#26550;InceptionXML&#65292;&#36890;&#36807;&#22312;embedding&#32500;&#24230;&#19978;&#37325;&#26032;&#20998;&#37197;&#21367;&#31215;&#25805;&#20316;&#65292;&#24212;&#23545;&#30701;&#25991;&#26412;&#26597;&#35810;&#20013;&#30340;&#21333;&#35789;&#39034;&#24207;&#32570;&#22833;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;InceptionXML+&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#27493;&#26631;&#31614;&#31579;&#36873;&#22120;&#21644;&#26497;&#31471;&#20998;&#31867;&#22120;&#65292;&#25913;&#36827;&#20102;&#21160;&#24577;&#30828;&#36127;&#37319;&#26679;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2109.07319</link><description>&lt;p&gt;
InceptionXML&#65306;&#19968;&#31181;&#24102;&#26377;&#21516;&#27493;&#36127;&#37319;&#26679;&#30340;&#36731;&#37327;&#32423;&#26694;&#26550;&#65292;&#29992;&#20110;&#30701;&#25991;&#26412;&#26497;&#31471;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2109.07319
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26694;&#26550;InceptionXML&#65292;&#36890;&#36807;&#22312;embedding&#32500;&#24230;&#19978;&#37325;&#26032;&#20998;&#37197;&#21367;&#31215;&#25805;&#20316;&#65292;&#24212;&#23545;&#30701;&#25991;&#26412;&#26597;&#35810;&#20013;&#30340;&#21333;&#35789;&#39034;&#24207;&#32570;&#22833;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;InceptionXML+&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#27493;&#26631;&#31614;&#31579;&#36873;&#22120;&#21644;&#26497;&#31471;&#20998;&#31867;&#22120;&#65292;&#25913;&#36827;&#20102;&#21160;&#24577;&#30828;&#36127;&#37319;&#26679;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30701;&#25991;&#26412;&#25968;&#25454;&#23545;&#22823;&#37327;&#30446;&#26631;&#26631;&#31614;&#36827;&#34892;&#33258;&#21160;&#27880;&#37322;&#65292;&#34987;&#31216;&#20026;&#30701;&#25991;&#26412;&#26497;&#31471;&#20998;&#31867;&#65292;&#24050;&#32463;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24471;&#21040;&#24212;&#29992;&#65292;&#21253;&#25324;&#30456;&#20851;&#25628;&#32034;&#39044;&#27979;&#21644;&#20135;&#21697;&#25512;&#33616;&#20219;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21367;&#31215;&#26550;&#26500;InceptionXML&#65292;&#20854;&#36731;&#37327;&#20294;&#21151;&#33021;&#24378;&#22823;&#65292;&#24182;&#19988;&#33021;&#22815;&#24212;&#23545;&#25628;&#32034;&#21644;&#25512;&#33616;&#20219;&#21153;&#20013;&#30701;&#25991;&#26412;&#26597;&#35810;&#20013;&#22266;&#26377;&#30340;&#32570;&#20047;&#21333;&#35789;&#39034;&#24207;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#21367;&#31215;&#30340;&#25805;&#20316;&#27839;&#30528;&#23884;&#20837;&#32500;&#24230;&#37325;&#26032;&#26500;&#24314;&#65292;&#32780;&#19981;&#26159;&#20687;&#20256;&#32479;CNNs&#19968;&#26679;&#27839;&#30528;&#21333;&#35789;&#32500;&#24230;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#65292;&#35777;&#26126;&#20102;&#24212;&#29992;&#21367;&#31215;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#25193;&#23637;&#21040;&#20855;&#26377;&#25968;&#30334;&#19975;&#26631;&#31614;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;InceptionXML+&#26694;&#26550;&#65292;&#36890;&#36807;&#21516;&#27493;&#26631;&#31614;&#31579;&#36873;&#22120;&#21644;&#26497;&#31471;&#20998;&#31867;&#22120;&#65292;&#25913;&#36827;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#21160;&#24577;&#30828;&#36127;&#37319;&#26679;&#25216;&#26415;&#22312;&#26631;&#31614;&#31579;&#36873;&#20013;&#30340;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2109.07319v3 Announce Type: replace-cross  Abstract: Automatic annotation of short-text data to a large number of target labels, referred to as Short Text Extreme Classification, has found numerous applications including prediction of related searches and product recommendation tasks. In this paper, we propose a convolutional architecture InceptionXML which is light-weight, yet powerful, and robust to the inherent lack of word-order in short-text queries encountered in search and recommendation tasks. We demonstrate the efficacy of applying convolutions by recasting the operation along the embedding dimension instead of the word dimension as applied in conventional CNNs for text classification. Towards scaling our model to datasets with millions of labels, we also propose InceptionXML+ framework which improves upon the shortcomings of the recently proposed dynamic hard-negative mining technique for label shortlisting by synchronizing the label-shortlister and extreme classifier. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#30340;&#22797;&#26434;&#21518;&#26524;&#65292;&#21457;&#29616;&#22312;&#22686;&#24378;&#27169;&#22411;&#20934;&#30830;&#24615;&#19982;&#20445;&#25345;&#36947;&#24503;&#23436;&#25972;&#24615;&#20043;&#38388;&#23384;&#22312;&#24726;&#35770;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#27880;&#20837;&#20934;&#30830;&#20449;&#24687;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#24456;&#37325;&#35201;&#65292;&#20294;&#23427;&#21487;&#33021;&#30772;&#22351;&#27169;&#22411;&#30340;&#22522;&#26412;&#26694;&#26550;&#65292;&#23548;&#33268;&#19981;&#21487;&#39044;&#27979;&#21644;&#28508;&#22312;&#30340;&#19981;&#23433;&#20840;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2401.10647</link><description>&lt;p&gt;
&#25773;&#39118;&#25769;&#36215;&#39118;&#26292;&#65306;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models. (arXiv:2401.10647v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10647
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32534;&#36753;&#35821;&#35328;&#27169;&#22411;&#30340;&#22797;&#26434;&#21518;&#26524;&#65292;&#21457;&#29616;&#22312;&#22686;&#24378;&#27169;&#22411;&#20934;&#30830;&#24615;&#19982;&#20445;&#25345;&#36947;&#24503;&#23436;&#25972;&#24615;&#20043;&#38388;&#23384;&#22312;&#24726;&#35770;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#27880;&#20837;&#20934;&#30830;&#20449;&#24687;&#23545;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#24456;&#37325;&#35201;&#65292;&#20294;&#23427;&#21487;&#33021;&#30772;&#22351;&#27169;&#22411;&#30340;&#22522;&#26412;&#26694;&#26550;&#65292;&#23548;&#33268;&#19981;&#21487;&#39044;&#27979;&#21644;&#28508;&#22312;&#30340;&#19981;&#23433;&#20840;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#65292;&#32418;&#38431;&#27979;&#35797;&#25110;&#36234;&#29425;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#27010;&#24565;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#36827;&#34892;&#32534;&#36753;&#65292;&#25581;&#31034;&#20102;&#36825;&#31181;&#20462;&#25913;&#30340;&#22797;&#26434;&#21518;&#26524;&#65292;&#21457;&#29616;&#20102;&#22686;&#24378;&#27169;&#22411;&#20934;&#30830;&#24615;&#19982;&#20445;&#25345;&#20854;&#36947;&#24503;&#23436;&#25972;&#24615;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#28145;&#20837;&#20998;&#26512;&#25581;&#31034;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#24726;&#35770;&#65306;&#34429;&#28982;&#27880;&#20837;&#20934;&#30830;&#20449;&#24687;&#23545;&#20110;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23427;&#21364;&#21487;&#33021;&#30772;&#22351;&#27169;&#22411;&#30340;&#22522;&#26412;&#26694;&#26550;&#65292;&#23548;&#33268;&#19981;&#21487;&#39044;&#27979;&#21644;&#28508;&#22312;&#30340;&#19981;&#23433;&#20840;&#34892;&#20026;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;NicheHazardQA&#65292;&#29992;&#20110;&#30740;&#31350;&#27169;&#22411;&#22312;&#30456;&#21516;&#21644;&#36328;&#39046;&#22495;&#20013;&#30340;&#19981;&#23433;&#20840;&#34892;&#20026;&#12290;&#36825;&#19968;&#26041;&#38754;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#32534;&#36753;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#30340;&#23433;&#20840;&#24230;&#37327;&#21644;&#20445;&#25252;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the rapidly advancing field of artificial intelligence, the concept of Red-Teaming or Jailbreaking large language models (LLMs) has emerged as a crucial area of study. This approach is especially significant in terms of assessing and enhancing the safety and robustness of these models. This paper investigates the intricate consequences of such modifications through model editing, uncovering a complex relationship between enhancing model accuracy and preserving its ethical integrity. Our in-depth analysis reveals a striking paradox: while injecting accurate information is crucial for model reliability, it can paradoxically destabilize the model's foundational framework, resulting in unpredictable and potentially unsafe behaviors. Additionally, we propose a benchmark dataset NicheHazardQA to investigate this unsafe behavior both within the same and cross topical domain. This aspect of our research sheds light on how the edits, impact the model's safety metrics and guardrails. Our find
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;FastConformer&#26550;&#26500;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#19978;&#19979;&#25991;&#21644;&#24341;&#20837;&#32531;&#23384;&#26426;&#21046;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#23454;&#29616;&#38750;&#33258;&#22238;&#24402;&#32534;&#30721;&#22120;&#30340;&#33258;&#22238;&#24402;&#25805;&#20316;&#65292;&#24182;&#28040;&#38500;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#20934;&#30830;&#24230;&#38388;&#30340;&#24046;&#24322;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;CTC/RNNT&#28151;&#21512;&#26550;&#26500;&#20197;&#25552;&#39640;&#20934;&#30830;&#24230;&#21644;&#33410;&#30465;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2312.17279</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#32531;&#23384;&#25512;&#29702;&#30340;&#24102;&#29366;&#24577;Conformer&#27169;&#22411;&#30340;&#27969;&#24335;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Stateful Conformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.17279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;FastConformer&#26550;&#26500;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#19978;&#19979;&#25991;&#21644;&#24341;&#20837;&#32531;&#23384;&#26426;&#21046;&#65292;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#23454;&#29616;&#38750;&#33258;&#22238;&#24402;&#32534;&#30721;&#22120;&#30340;&#33258;&#22238;&#24402;&#25805;&#20316;&#65292;&#24182;&#28040;&#38500;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#20934;&#30830;&#24230;&#38388;&#30340;&#24046;&#24322;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;CTC/RNNT&#28151;&#21512;&#26550;&#26500;&#20197;&#25552;&#39640;&#20934;&#30830;&#24230;&#21644;&#33410;&#30465;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;FastConformer&#26550;&#26500;&#30340;&#39640;&#25928;&#20934;&#30830;&#30340;&#27969;&#24335;&#35821;&#38899;&#35782;&#21035;&#27169;&#22411;&#12290;&#36890;&#36807;&#23545;FastConformer&#26550;&#26500;&#36827;&#34892;&#35843;&#25972;&#65292;&#25105;&#20204;&#36866;&#29992;&#20110;&#27969;&#24335;&#24212;&#29992;&#30340;&#26041;&#24335;&#26377;&#20004;&#20010;&#65306;&#65288;1&#65289;&#38480;&#21046;&#32534;&#30721;&#22120;&#20013;&#30340;&#21069;&#30651;&#21644;&#21382;&#21490;&#19978;&#19979;&#25991;&#65292;&#65288;2&#65289;&#24341;&#20837;&#28608;&#27963;&#32531;&#23384;&#26426;&#21046;&#20197;&#20351;&#38750;&#33258;&#22238;&#24402;&#32534;&#30721;&#22120;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#20197;&#33258;&#22238;&#24402;&#26041;&#24335;&#24037;&#20316;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#65292;&#28040;&#38500;&#20102;&#35768;&#22810;&#27969;&#24335;&#27169;&#22411;&#22312;&#35757;&#32451;&#21644;&#25512;&#29702;&#26102;&#38388;&#20013;&#30340;&#20934;&#30830;&#24230;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32534;&#30721;&#22120;&#19982;&#19981;&#21516;&#30340;&#35299;&#30721;&#22120;&#37197;&#32622;&#20860;&#23481;&#65292;&#21253;&#25324;CTC&#21644;RNNT&#35299;&#30721;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#28151;&#21512;&#30340;CTC/RNNT&#26550;&#26500;&#65292;&#23427;&#21033;&#29992;&#20849;&#20139;&#30340;&#32534;&#30721;&#22120;&#21644;CTC&#21644;RNNT&#35299;&#30721;&#22120;&#26469;&#25552;&#39640;&#20934;&#30830;&#24230;&#24182;&#33410;&#30465;&#35745;&#31639;&#12290;&#25105;&#20204;&#22312;LibriSpeech&#25968;&#25454;&#38598;&#21644;&#22810;&#39046;&#22495;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose an efficient and accurate streaming speech recognition model based on the FastConformer architecture. We adapted the FastConformer architecture for streaming applications through: (1) constraining both the look-ahead and past contexts in the encoder, and (2) introducing an activation caching mechanism to enable the non-autoregressive encoder to operate autoregressively during inference. The proposed model is thoughtfully designed in a way to eliminate the accuracy disparity between the train and inference time which is common for many streaming models. Furthermore, our proposed encoder works with various decoder configurations including Connectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders. Additionally, we introduced a hybrid CTC/RNNT architecture which utilizes a shared encoder with both a CTC and RNNT decoder to boost the accuracy and save computation. We evaluate the proposed model on LibriSpeech dataset and a multi-domain large sc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#20013;&#27010;&#24565;&#30340;&#26368;&#26032;&#26041;&#27861;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#22522;&#20110;&#21487;&#35299;&#37322;&#27010;&#24565;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#20154;&#24037;&#26234;&#33021;&#26469;&#35828;&#26159;&#37325;&#35201;&#30340;&#19968;&#27493;&#12290;</title><link>http://arxiv.org/abs/2310.11884</link><description>&lt;p&gt;
&#20174;&#31070;&#32463;&#28608;&#27963;&#21040;&#27010;&#24565;: &#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27010;&#24565;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
From Neural Activations to Concepts: A Survey on Explaining Concepts in Neural Networks. (arXiv:2310.11884v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#20013;&#27010;&#24565;&#30340;&#26368;&#26032;&#26041;&#27861;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#22522;&#20110;&#21487;&#35299;&#37322;&#27010;&#24565;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#20154;&#24037;&#26234;&#33021;&#26469;&#35828;&#26159;&#37325;&#35201;&#30340;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23457;&#26597;&#20102;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#20013;&#27010;&#24565;&#30340;&#26368;&#26032;&#26041;&#27861;&#12290;&#27010;&#24565;&#21487;&#20197;&#20316;&#20026;&#23398;&#20064;&#21644;&#25512;&#29702;&#20043;&#38388;&#30340;&#33258;&#28982;&#26725;&#26753;&#65306;&#19968;&#26086;&#30830;&#23450;&#20102;&#31070;&#32463;&#23398;&#20064;&#31995;&#32479;&#20351;&#29992;&#30340;&#27010;&#24565;&#65292;&#23601;&#21487;&#20197;&#23558;&#36825;&#20123;&#27010;&#24565;&#19982;&#25512;&#29702;&#31995;&#32479;&#25972;&#21512;&#65292;&#29992;&#20110;&#25512;&#29702;&#25110;&#20351;&#29992;&#25512;&#29702;&#31995;&#32479;&#23545;&#20854;&#36827;&#34892;&#25913;&#36827;&#25110;&#22686;&#24378;&#20197;&#25913;&#21892;&#23398;&#20064;&#31995;&#32479;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19981;&#20165;&#21487;&#20197;&#20174;&#31070;&#32463;&#32593;&#32476;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#36824;&#21487;&#20197;&#23558;&#27010;&#24565;&#30693;&#35782;&#25554;&#20837;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#20013;&#12290;&#30001;&#20110;&#25972;&#21512;&#23398;&#20064;&#21644;&#25512;&#29702;&#26159;&#31070;&#32463;&#31526;&#21495;&#21270;&#20154;&#24037;&#26234;&#33021;&#30340;&#26680;&#24515;&#65292;&#25152;&#20197;&#36890;&#36807;&#36825;&#39033;&#35843;&#26597;&#33719;&#24471;&#30340;&#35265;&#35299;&#21487;&#20197;&#25104;&#20026;&#23454;&#29616;&#22522;&#20110;&#21487;&#35299;&#37322;&#27010;&#24565;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#20154;&#24037;&#26234;&#33021;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we review recent approaches for explaining concepts in neural networks. Concepts can act as a natural link between learning and reasoning: once the concepts are identified that a neural learning system uses, one can integrate those concepts with a reasoning system for inference or use a reasoning system to act upon them to improve or enhance the learning system. On the other hand, knowledge can not only be extracted from neural networks but concept knowledge can also be inserted into neural network architectures. Since integrating learning and reasoning is at the core of neuro-symbolic AI, the insights gained from this survey can serve as an important step towards realizing neuro-symbolic AI based on explainable concepts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#30340;&#20219;&#21153;&#65292;&#24182;&#27979;&#35797;&#20102;&#20960;&#31181;&#23398;&#20064;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#23569;&#37327;&#25968;&#25454;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#65292;&#24182;&#22312;&#19982;&#20154;&#31867;&#22522;&#20934;&#36827;&#34892;&#27604;&#36739;&#21518;&#25509;&#36817;&#20154;&#31867;&#30340;&#34920;&#29616;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2310.05597</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#65311;&#30740;&#31350;&#35757;&#32451;&#30446;&#26631;&#21644;&#19982;&#20154;&#31867;&#34920;&#29616;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance. (arXiv:2310.05597v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#30340;&#20219;&#21153;&#65292;&#24182;&#27979;&#35797;&#20102;&#20960;&#31181;&#23398;&#20064;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#23569;&#37327;&#25968;&#25454;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#65292;&#24182;&#22312;&#19982;&#20154;&#31867;&#22522;&#20934;&#36827;&#34892;&#27604;&#36739;&#21518;&#25509;&#36817;&#20154;&#31867;&#30340;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#31867;&#27604;&#26159;&#35780;&#20272;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#35789;&#23884;&#20837;&#30340;&#24120;&#35265;&#26041;&#24335;&#65292;&#20294;&#30740;&#31350;&#31867;&#27604;&#25512;&#29702;&#26159;&#21542;&#26159;&#19968;&#31181;&#21487;&#20197;&#23398;&#20064;&#30340;&#20219;&#21153;&#20063;&#24456;&#26377;&#24847;&#20041;&#12290;&#26412;&#25991;&#27979;&#35797;&#20102;&#20960;&#31181;&#23398;&#20064;&#22522;&#26412;&#31867;&#27604;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;&#30340;&#26159;&#37027;&#20123;&#26356;&#31526;&#21512;&#20154;&#31867;&#31867;&#27604;&#25512;&#29702;&#35780;&#20272;&#26631;&#20934;&#30340;&#31867;&#27604;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#21457;&#29616;&#65292;&#27169;&#22411;&#33021;&#22815;&#22312;&#23569;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#31867;&#27604;&#25512;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#19982;&#20855;&#26377;&#20154;&#31867;&#22522;&#20934;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#21457;&#29616;&#22312;&#35757;&#32451;&#21518;&#65292;&#27169;&#22411;&#25509;&#36817;&#20154;&#31867;&#30340;&#34920;&#29616;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
While analogies are a common way to evaluate word embeddings in NLP, it is also of interest to investigate whether or not analogical reasoning is a task in itself that can be learned. In this paper, we test several ways to learn basic analogical reasoning, specifically focusing on analogies that are more typical of what is used to evaluate analogical reasoning in humans than those in commonly used NLP benchmarks. Our experiments find that models are able to learn analogical reasoning, even with a small amount of data. We additionally compare our models to a dataset with a human baseline, and find that after training, models approach human performance.
&lt;/p&gt;</description></item><item><title>RLAdapter&#24341;&#20837;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#39640;&#22312;&#31232;&#30095;&#22870;&#21169;&#29615;&#22659;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;&#24615;&#33021;&#12290;&#36825;&#36890;&#36807;&#35299;&#20915;LLM&#22312;&#29702;&#35299;&#19979;&#28216;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#20197;&#21450;&#36890;&#36807;&#36991;&#20813;&#20351;&#29992;&#19981;&#21487;&#35775;&#38382;&#30340;&#27169;&#22411;&#26435;&#37325;&#25110;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#26469;&#24494;&#35843;LLM&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.17176</link><description>&lt;p&gt;
RLAdapter&#65306;&#22312;&#24320;&#25918;&#29615;&#22659;&#20013;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds. (arXiv:2309.17176v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17176
&lt;/p&gt;
&lt;p&gt;
RLAdapter&#24341;&#20837;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#39640;&#22312;&#31232;&#30095;&#22870;&#21169;&#29615;&#22659;&#20013;&#30340;&#31574;&#30053;&#23398;&#20064;&#24615;&#33021;&#12290;&#36825;&#36890;&#36807;&#35299;&#20915;LLM&#22312;&#29702;&#35299;&#19979;&#28216;&#20219;&#21153;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#20197;&#21450;&#36890;&#36807;&#36991;&#20813;&#20351;&#29992;&#19981;&#21487;&#35775;&#38382;&#30340;&#27169;&#22411;&#26435;&#37325;&#25110;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#26469;&#24494;&#35843;LLM&#30340;&#26041;&#24335;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#20915;&#31574;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#19982;&#29615;&#22659;&#36827;&#34892;&#22823;&#37327;&#30340;&#20132;&#20114;&#65292;&#22312;&#31232;&#30095;&#22870;&#21169;&#29615;&#22659;&#20013;&#23398;&#20064;&#26377;&#24847;&#20041;&#30340;&#31574;&#30053;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21487;&#20197;&#20026;&#20195;&#29702;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#25351;&#23548;&#65292;&#20174;&#32780;&#22686;&#24378;RL&#31639;&#27861;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;LLM&#36890;&#24120;&#22312;&#29702;&#35299;&#19979;&#28216;&#20219;&#21153;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#65292;&#36825;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#36825;&#20123;&#20219;&#21153;&#20013;&#26368;&#20248;&#22320;&#24110;&#21161;&#20195;&#29702;&#30340;&#33021;&#21147;&#12290;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#25968;&#25454;&#26469;&#24494;&#35843;LLM&#65292;&#20351;&#20854;&#33021;&#22815;&#20026;RL&#20195;&#29702;&#25552;&#20379;&#26377;&#29992;&#30340;&#25351;&#23548;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#36935;&#21040;&#20102;&#19968;&#20123;&#22256;&#38590;&#65292;&#27604;&#22914;&#26080;&#27861;&#35775;&#38382;&#30340;&#27169;&#22411;&#26435;&#37325;&#25110;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#36164;&#28304;&#65292;&#20351;&#20854;&#19981;&#20999;&#23454;&#38469;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;RLAdapter&#65292;&#36825;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#22312;RL&#31639;&#27861;&#21644;LLM&#20043;&#38388;&#24314;&#31435;&#26356;&#22909;&#30340;&#36830;&#25509;&#65292;&#20174;&#32780;&#25972;&#21512;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reinforcement learning (RL) shows remarkable success in decision-making problems, it often requires a lot of interactions with the environment, and in sparse-reward environments, it is challenging to learn meaningful policies. Large Language Models (LLMs) can potentially provide valuable guidance to agents in learning policies, thereby enhancing the performance of RL algorithms in such environments. However, LLMs often encounter difficulties in understanding downstream tasks, which hinders their ability to optimally assist agents in these tasks. A common approach to mitigating this issue is to fine-tune the LLMs with task-related data, enabling them to offer useful guidance for RL agents. However, this approach encounters several difficulties, such as inaccessible model weights or the need for significant computational resources, making it impractical. In this work, we introduce RLAdapter, a framework that builds a better connection between RL algorithms and LLMs by incorporating
&lt;/p&gt;</description></item><item><title>MetaMath&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#25968;&#23398;&#25512;&#29702;&#30340;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20174;&#22810;&#20010;&#35282;&#24230;&#37325;&#26032;&#32534;&#20889;&#38382;&#39064;&#26469;&#29983;&#25104;&#25968;&#23398;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20854;&#20182;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.12284</link><description>&lt;p&gt;
MetaMath&#65306;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21019;&#24314;&#33258;&#24049;&#30340;&#25968;&#23398;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12284
&lt;/p&gt;
&lt;p&gt;
MetaMath&#26159;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#25968;&#23398;&#25512;&#29702;&#30340;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20174;&#22810;&#20010;&#35282;&#24230;&#37325;&#26032;&#32534;&#20889;&#38382;&#39064;&#26469;&#29983;&#25104;&#25968;&#23398;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20854;&#20182;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25512;&#21160;&#20102;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#26497;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#20986;&#33394;&#30340;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24320;&#28304;LLMs&#65288;&#20363;&#22914;LLaMA-2&#65289;&#22312;&#35299;&#20915;&#25968;&#23398;&#38382;&#39064;&#26041;&#38754;&#20173;&#28982;&#36828;&#36828;&#19981;&#22815;&#20196;&#20154;&#28385;&#24847;&#65292;&#21407;&#22240;&#26159;&#22797;&#26434;&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#40511;&#27807;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MetaMath&#65292;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#25968;&#23398;&#25512;&#29702;&#30340;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27809;&#26377;&#39069;&#22806;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#20197;&#22810;&#20010;&#35282;&#24230;&#37325;&#26032;&#20889;&#20837;&#38382;&#39064;&#26469;&#24341;&#23548;&#25968;&#23398;&#38382;&#39064;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#21517;&#20026;MetaMathQA&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;MetaMathQA&#19978;&#23545;LLaMA-2&#27169;&#22411;&#36827;&#34892;&#20102;&#24494;&#35843;&#12290;&#23545;&#20110;&#25968;&#23398;&#25512;&#29702;&#30340;&#20004;&#20010;&#27969;&#34892;&#22522;&#20934;&#27979;&#35797;&#65288;&#21363;GSM8K&#21644;MATH&#65289;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;MetaMath&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#19968;&#22871;&#24320;&#28304;LLMs&#12290;&#25105;&#20204;&#30340;MetaMath-7B&#27169;&#22411;&#22312;GSM8K&#19978;&#36798;&#21040;&#20102;66.4&#65285;&#65292;&#22312;MATH&#19978;&#36798;&#21040;&#20102;19.4&#65285;&#65292;&#36229;&#36807;&#20102;&#30456;&#21516;&#35268;&#27169;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
&lt;/p&gt;</description></item></channel></rss>