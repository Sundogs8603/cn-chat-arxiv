<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#22522;&#20110;Llama 2&#30340;&#31995;&#32479;&#65292;&#22312;&#22788;&#29702;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#31616;&#21270;&#30340;PLABA&#20849;&#20139;&#20219;&#21153;&#20013;&#25490;&#21517;&#31532;&#19968;&#12290;&#36890;&#36807;&#24341;&#20837;&#21477;&#23376;&#32423;&#21644;&#26631;&#35760;&#32423;&#30340;&#25439;&#22833;&#26435;&#37325;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#20135;&#29983;&#19982;&#20154;&#24037;&#27880;&#37322;&#32773;&#30456;&#20284;&#30340;&#31616;&#21270;&#32467;&#26524;&#65292;&#35821;&#35328;&#26356;&#31616;&#21333;&#65292;&#24182;&#19988;&#36827;&#34892;&#26356;&#22810;&#30340;&#32534;&#36753;&#25805;&#20316;&#12290;</title><link>http://arxiv.org/abs/2311.01907</link><description>&lt;p&gt;
BoschAI @ PLABA 2023: &#21033;&#29992;&#32534;&#36753;&#25805;&#20316;&#22312;&#31471;&#21040;&#31471;&#31070;&#32463;&#21477;&#23376;&#31616;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural Sentence Simplification. (arXiv:2311.01907v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01907
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#22522;&#20110;Llama 2&#30340;&#31995;&#32479;&#65292;&#22312;&#22788;&#29702;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#31616;&#21270;&#30340;PLABA&#20849;&#20139;&#20219;&#21153;&#20013;&#25490;&#21517;&#31532;&#19968;&#12290;&#36890;&#36807;&#24341;&#20837;&#21477;&#23376;&#32423;&#21644;&#26631;&#35760;&#32423;&#30340;&#25439;&#22833;&#26435;&#37325;&#65292;&#35813;&#31995;&#32479;&#33021;&#22815;&#20135;&#29983;&#19982;&#20154;&#24037;&#27880;&#37322;&#32773;&#30456;&#20284;&#30340;&#31616;&#21270;&#32467;&#26524;&#65292;&#35821;&#35328;&#26356;&#31616;&#21333;&#65292;&#24182;&#19988;&#36827;&#34892;&#26356;&#22810;&#30340;&#32534;&#36753;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#31616;&#21270;&#21487;&#20197;&#24110;&#21161;&#26222;&#36890;&#20154;&#29702;&#35299;&#22797;&#26434;&#30340;&#31185;&#23398;&#25991;&#26412;&#12290;&#35821;&#35328;&#27169;&#22411;&#32463;&#24120;&#29992;&#20110;&#23558;&#22797;&#26434;&#35821;&#35328;&#36716;&#25442;&#20026;&#31616;&#21333;&#35821;&#35328;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22522;&#20110;Llama 2&#30340;&#31995;&#32479;&#65292;&#35813;&#31995;&#32479;&#22312;&#22788;&#29702;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#31616;&#21270;&#30340;PLABA&#20849;&#20139;&#20219;&#21153;&#20013;&#25490;&#21517;&#31532;&#19968;&#12290;&#25105;&#20204;&#21457;&#29616;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#20849;&#20139;&#30340;&#26631;&#35760;&#30340;&#25968;&#37327;&#24456;&#22810;&#65292;&#23548;&#33268;&#35757;&#32451;&#20449;&#21495;&#36739;&#24369;&#21644;&#20445;&#23432;&#30340;&#32534;&#36753;&#27169;&#22411;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21477;&#23376;&#32423;&#21644;&#26631;&#35760;&#32423;&#30340;&#25439;&#22833;&#26435;&#37325;&#12290;&#23427;&#20204;&#32473;&#20104;&#20462;&#25913;&#30340;&#26631;&#35760;&#26356;&#39640;&#30340;&#26435;&#37325;&#65292;&#20462;&#25913;&#36890;&#36807;&#32534;&#36753;&#36317;&#31163;&#21644;&#32534;&#36753;&#25805;&#20316;&#36827;&#34892;&#25351;&#31034;&#12290;&#25105;&#20204;&#22312;PLABA&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#24182;&#21457;&#29616;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#20351;&#31616;&#21270;&#32467;&#26524;&#26356;&#25509;&#36817;&#20154;&#24037;&#27880;&#37322;&#32773;&#21019;&#24314;&#30340;&#32467;&#26524;&#65288;+1.8% / +3.5% SARI&#65289;&#65292;&#35821;&#35328;&#26356;&#31616;&#21333;&#65288;-1 / -1.1 FKGL&#65289;&#65292;&#24182;&#19988;&#32534;&#36753;&#26356;&#22810;&#65288;1.6x / 1.8x&#32534;&#36753;&#36317;&#31163;&#65289;&#65292;&#30456;&#27604;&#20110;&#20351;&#29992;&#26631;&#20934;&#20132;&#21449;&#29109;&#36827;&#34892;&#24494;&#35843;&#30340;&#30456;&#21516;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic simplification can help laypeople to comprehend complex scientific text. Language models are frequently applied to this task by translating from complex to simple language. In this paper, we describe our system based on Llama 2, which ranked first in the PLABA shared task addressing the simplification of biomedical text. We find that the large portion of shared tokens between input and output leads to weak training signals and conservatively editing models. To mitigate these issues, we propose sentence-level and token-level loss weights. They give higher weight to modified tokens, indicated by edit distance and edit operations, respectively. We conduct an empirical evaluation on the PLABA dataset and find that both approaches lead to simplifications closer to those created by human annotators (+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x / 1.8x edit distance) compared to the same model fine-tuned with standard cross entropy. We furthermore show 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23618;&#27425;&#31574;&#30053;&#65292;&#36890;&#36807;&#37322;&#25918;&#20854;&#21019;&#36896;&#28508;&#21147;&#65292;&#25506;&#32034;&#22810;&#26679;&#21270;&#30340;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#12290;&#36890;&#36807;&#23558;LLMs&#20998;&#20026;&#39046;&#23548;&#32773;&#21644;&#25191;&#34892;&#32773;&#65292;&#39046;&#23548;&#32773;&#25552;&#20379;&#22810;&#31181;&#39640;&#32423;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#20316;&#20026;&#25552;&#31034;&#65292;&#25191;&#34892;&#32773;&#26681;&#25454;&#39046;&#23548;&#32773;&#30340;&#25351;&#24341;&#25191;&#34892;&#35814;&#32454;&#30340;&#38382;&#39064;&#35299;&#20915;&#36807;&#31243;&#65292;&#29983;&#25104;&#19968;&#32452;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2311.00694</link><description>&lt;p&gt;
&#35299;&#25918;&#21019;&#36896;&#21147;&#65306;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#23618;&#27425;&#31574;&#30053;&#20197;&#25913;&#36827;&#25361;&#25112;&#24615;&#38382;&#39064;&#35299;&#20915;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving. (arXiv:2311.00694v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#23618;&#27425;&#31574;&#30053;&#65292;&#36890;&#36807;&#37322;&#25918;&#20854;&#21019;&#36896;&#28508;&#21147;&#65292;&#25506;&#32034;&#22810;&#26679;&#21270;&#30340;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#12290;&#36890;&#36807;&#23558;LLMs&#20998;&#20026;&#39046;&#23548;&#32773;&#21644;&#25191;&#34892;&#32773;&#65292;&#39046;&#23548;&#32773;&#25552;&#20379;&#22810;&#31181;&#39640;&#32423;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#20316;&#20026;&#25552;&#31034;&#65292;&#25191;&#34892;&#32773;&#26681;&#25454;&#39046;&#23548;&#32773;&#30340;&#25351;&#24341;&#25191;&#34892;&#35814;&#32454;&#30340;&#38382;&#39064;&#35299;&#20915;&#36807;&#31243;&#65292;&#29983;&#25104;&#19968;&#32452;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#20173;&#28982;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25512;&#29702;&#38382;&#39064;&#20013;&#24448;&#24448;&#36935;&#21040;&#22256;&#38590;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#36807;&#37319;&#26679;&#25110;&#25628;&#32034;&#35814;&#32454;&#21644;&#20302;&#32423;&#30340;&#25512;&#29702;&#38142;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#25506;&#32034;&#33021;&#21147;&#19978;&#20173;&#28982;&#26377;&#38480;&#65292;&#20351;&#24471;&#27491;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#24222;&#22823;&#30340;&#35299;&#31354;&#38388;&#20013;&#24456;&#38590;&#31361;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;LLMs&#20316;&#20026;&#23618;&#27425;&#31574;&#30053;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#37322;&#25918;LLMs&#25506;&#32034;&#22810;&#26679;&#21270;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#30340;&#21019;&#36896;&#28508;&#21147;&#12290;&#35813;&#31574;&#30053;&#21253;&#25324;&#19968;&#20010;&#26377;&#36828;&#35265;&#30340;&#39046;&#23548;&#32773;&#65292;&#25552;&#20986;&#22810;&#31181;&#22810;&#26679;&#30340;&#39640;&#32423;&#38382;&#39064;&#35299;&#20915;&#31574;&#30053;&#20316;&#20026;&#25552;&#31034;&#65292;&#24182;&#26377;&#19968;&#20010;&#25191;&#34892;&#32773;&#65292;&#26681;&#25454;&#27599;&#20010;&#39640;&#32423;&#25351;&#20196;&#25191;&#34892;&#35814;&#32454;&#30340;&#38382;&#39064;&#35299;&#20915;&#36807;&#31243;&#12290;&#25191;&#34892;&#32773;&#23558;&#39046;&#23548;&#32773;&#30340;&#27599;&#20010;&#25351;&#20196;&#20316;&#20026;&#25351;&#21335;&#65292;&#24182;&#37319;&#26679;&#22810;&#20010;&#25512;&#29702;&#38142;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#20026;&#27599;&#20010;&#39046;&#23548;&#32773;&#30340;&#25552;&#35758;&#29983;&#25104;&#19968;&#32452;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have achieved tremendous progress, yet they still often struggle with challenging reasoning problems. Current approaches address this challenge by sampling or searching detailed and low-level reasoning chains. However, these methods are still limited in their exploration capabilities, making it challenging for correct solutions to stand out in the huge solution space. In this work, we unleash LLMs' creative potential for exploring multiple diverse problem solving strategies by framing an LLM as a hierarchical policy via in-context learning. This policy comprises of a visionary leader that proposes multiple diverse high-level problem-solving tactics as hints, accompanied by a follower that executes detailed problem-solving processes following each of the high-level instruction. The follower uses each of the leader's directives as a guide and samples multiple reasoning chains to tackle the problem, generating a solution group for each leader proposal. Additio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#23545;&#35270;&#35273;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#21457;&#29616;&#34429;&#28982;&#22312;&#26576;&#20123;&#26679;&#24335;&#21270;&#25968;&#25454;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#22522;&#26412;&#25805;&#20316;&#24341;&#36215;&#30340;&#31616;&#21333;&#25968;&#25454;&#31867;&#22411;&#19978;&#34920;&#29616;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2310.08577</link><description>&lt;p&gt;
&#35270;&#35273;&#25968;&#25454;&#31867;&#22411;&#29702;&#35299;&#24182;&#38750;&#28304;&#33258;&#25193;&#23637;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models. (arXiv:2310.08577v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#23545;&#35270;&#35273;&#25968;&#25454;&#31867;&#22411;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#21457;&#29616;&#34429;&#28982;&#22312;&#26576;&#20123;&#26679;&#24335;&#21270;&#25968;&#25454;&#31867;&#22411;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#22522;&#26412;&#25805;&#20316;&#24341;&#36215;&#30340;&#31616;&#21333;&#25968;&#25454;&#31867;&#22411;&#19978;&#34920;&#29616;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#30340;&#21457;&#23637;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#35270;&#35273;&#35821;&#20041;&#20869;&#23481;&#35782;&#21035;&#25928;&#26524;&#65292;&#21253;&#25324;&#20986;&#33394;&#30340;&#22797;&#21512;&#22270;&#20687;&#29702;&#35299;&#23454;&#20363;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#39033;&#26032;&#30340;&#20219;&#21153;&#65292;&#21363;&#35270;&#35273;&#25968;&#25454;&#31867;&#22411;&#35782;&#21035;&#65292;&#36825;&#26159;&#19968;&#39033;&#22522;&#26412;&#30340;&#24863;&#30693;&#25216;&#33021;&#65292;&#23545;&#25968;&#25454;&#25972;&#29702;&#65288;&#20363;&#22914;&#20174;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#21435;&#38500;&#22122;&#22768;&#25968;&#25454;&#65292;&#39046;&#22495;&#29305;&#23450;&#30340;&#26816;&#32034;&#65289;&#21644;&#33258;&#20027;&#35270;&#35273;&#65288;&#20363;&#22914;&#21306;&#20998;&#19981;&#21516;&#30340;&#22825;&#27668;&#21464;&#21270;&#21644;&#30456;&#26426;&#38236;&#22836;&#27745;&#26579;&#65289;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#32463;&#36807;27&#31181;&#35270;&#35273;&#25968;&#25454;&#31867;&#22411;&#30340;&#21160;&#29289;&#22270;&#20687;&#30340;&#20462;&#25913;&#65292;&#28085;&#30422;&#20102;&#22235;&#20010;&#24191;&#27867;&#30340;&#31867;&#21035;&#12290;&#23545;39&#20010;&#21442;&#25968;&#33539;&#22260;&#20174;100M&#21040;80B&#30340;VLMs&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#38646;&#26679;&#26412;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;&#20102;&#19968;&#20010;&#32454;&#33268;&#30340;&#24615;&#33021;&#26223;&#35266;&#12290;&#34429;&#28982;VLMs&#22312;&#35782;&#21035;&#26576;&#20123;&#26679;&#24335;&#21270;&#30340;&#25968;&#25454;&#31867;&#22411;&#65288;&#20363;&#22914;&#21345;&#36890;&#21644;&#33609;&#22270;&#65289;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#22522;&#26412;&#25805;&#20316;&#65288;&#20363;&#22914;&#22270;&#20687;&#26059;&#36716;&#25110;&#28155;&#21152;&#22122;&#22768;&#65289;&#24341;&#36215;&#30340;&#31616;&#21333;&#25968;&#25454;&#31867;&#22411;&#19978;&#34920;&#29616;&#20986;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in the development of vision-language models (VLMs) are yielding remarkable success in recognizing visual semantic content, including impressive instances of compositional image understanding. Here, we introduce the novel task of Visual Data-Type Identification, a basic perceptual skill with implications for data curation (e.g., noisy data-removal from large datasets, domain-specific retrieval) and autonomous vision (e.g., distinguishing changing weather conditions from camera lens staining). We develop two datasets consisting of animal images altered across a diverse set of 27 visual data-types, spanning four broad categories. An extensive zero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced performance landscape. While VLMs are reasonably good at identifying certain stylistic \textit{data-types}, such as cartoons and sketches, they struggle with simpler data-types arising from basic manipulations like image rotations or additive noise.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#24847;&#22270;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23569;&#26679;&#26412;&#35774;&#32622;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#65292;&#21516;&#26102;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#24494;&#35843;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#65292;&#26356;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#23545;&#20110;&#26377;&#25928;&#21033;&#29992;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#24517;&#35201;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.10954</link><description>&lt;p&gt;
&#24102;&#26377;&#22810;&#20010;&#26631;&#31614;&#30340;&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
In-Context Learning for Text Classification with Many Labels. (arXiv:2309.10954v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#38480;&#21046;&#38382;&#39064;&#65292;&#24182;&#22312;&#22810;&#20010;&#24847;&#22270;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23569;&#26679;&#26412;&#35774;&#32622;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#65292;&#21516;&#26102;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#20102;&#24494;&#35843;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;&#30740;&#31350;&#36824;&#21457;&#29616;&#65292;&#26356;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#23545;&#20110;&#26377;&#25928;&#21033;&#29992;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#24517;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20855;&#26377;&#35768;&#22810;&#26631;&#31614;&#30340;&#20219;&#21153;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#26377;&#38480;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#20351;&#24471;&#22312;&#25552;&#31034;&#20013;&#38590;&#20197;&#36866;&#24212;&#36275;&#22815;&#25968;&#37327;&#30340;&#31034;&#20363;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#23494;&#38598;&#26816;&#32034;&#27169;&#22411;&#32469;&#36807;&#20102;&#36825;&#20010;&#38480;&#21046;&#65292;&#27599;&#27425;&#25512;&#29702;&#35843;&#29992;&#21482;&#32473;&#27169;&#22411;&#25552;&#20379;&#20102;&#23545;&#23436;&#25972;&#26631;&#31614;&#31354;&#38388;&#30340;&#37096;&#20998;&#35270;&#22270;&#12290;&#22312;&#26368;&#36817;&#30340;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;(OPT, LLaMA)&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#25105;&#20204;&#22312;&#19977;&#20010;&#24120;&#35265;&#30340;&#24847;&#22270;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23569;&#26679;&#26412;&#35774;&#32622;&#20013;&#65292;&#26080;&#38656;&#24494;&#35843;&#21363;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#26368;&#20339;&#24615;&#33021;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#36229;&#36234;&#20102;&#24494;&#35843;&#24615;&#33021;&#22312;&#32454;&#31890;&#24230;&#24773;&#24863;&#20998;&#31867;&#19978;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19981;&#21516;&#25968;&#37327;&#30340;&#19978;&#19979;&#25991;&#31034;&#20363;&#20197;&#21450;&#19981;&#21516;&#27169;&#22411;&#35268;&#27169;&#19979;&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;&#26356;&#22823;&#35268;&#27169;&#30340;&#27169;&#22411;&#23545;&#20110;&#26377;&#25928;&#32780;&#19968;&#33268;&#22320;&#21033;&#29992;&#26356;&#38271;&#30340;&#19978;&#19979;&#25991;&#38271;&#24230;&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#24517;&#35201;&#30340;&#12290;&#36890;&#36807;&#36816;&#34892;&#20960;&#20010;&#28040;&#34701;&#23454;&#39564;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#27169;&#22411;&#23545;&#20197;&#19979;&#20869;&#23481;&#30340;&#20351;&#29992;&#65306;a)&#19978;&#19979;&#25991;&#31034;&#20363;&#19982;&#24403;&#21069;&#36755;&#20837;&#30340;&#30456;&#20284;&#24230;, b) &#21363;&#26102;&#26597;&#35810;&#35821;&#21477;&#30340;&#30456;&#20284;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning (ICL) using large language models for tasks with many labels is challenging due to the limited context window, which makes it difficult to fit a sufficient number of examples in the prompt. In this paper, we use a pre-trained dense retrieval model to bypass this limitation, giving the model only a partial view of the full label space for each inference call. Testing with recent open-source LLMs (OPT, LLaMA), we set new state of the art performance in few-shot settings for three common intent classification datasets, with no finetuning. We also surpass fine-tuned performance on fine-grained sentiment classification in certain cases. We analyze the performance across number of in-context examples and different model scales, showing that larger models are necessary to effectively and consistently make use of larger context lengths for ICL. By running several ablations, we analyze the model's use of: a) the similarity of the in-context examples to the current input, b) 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#30340;&#19978;&#19979;&#38480;&#65292;&#21457;&#29616;&#23427;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#21516;&#26102;&#65292;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;Strahler&#25968;&#30340;&#22686;&#38271;&#27169;&#24335;&#65292;&#25581;&#31034;&#20102;&#23427;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2307.02697</link><description>&lt;p&gt;
Strahler&#25968;&#30340;&#32479;&#35745;&#21147;&#23398;&#65306;&#22522;&#20110;&#38543;&#26426;&#21644;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Statistical Mechanics of Strahler Number via Random and Natural Language Sentences. (arXiv:2307.02697v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#30340;&#19978;&#19979;&#38480;&#65292;&#21457;&#29616;&#23427;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#21516;&#26102;&#65292;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;Strahler&#25968;&#30340;&#22686;&#38271;&#27169;&#24335;&#65292;&#25581;&#31034;&#20102;&#23427;&#20316;&#20026;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Strahler&#25968;&#26368;&#21021;&#34987;&#25552;&#20986;&#29992;&#20110;&#25551;&#36848;&#27827;&#27969;&#20998;&#25903;&#30340;&#22797;&#26434;&#24615;&#65292;&#24182;&#25214;&#21040;&#20102;&#21508;&#31181;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#35745;&#31639;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#26641;&#32467;&#26500;&#30340;Strahler&#25968;&#19978;&#19979;&#38480;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#32467;&#26500;&#21487;&#20197;&#22312;&#19968;&#20010;&#22823;&#22411;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#12290;&#36890;&#36807;&#23545;&#35821;&#27861;&#27880;&#37322;&#25968;&#25454;&#30340;&#32463;&#39564;&#24615;&#27979;&#37327;&#65292;&#26174;&#31034;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#30340;Strahler&#25968;&#20960;&#20046;&#24635;&#26159;3&#25110;4&#65292;&#19982;Strahler&#65288;1957&#24180;&#65289;&#21644;Horton&#65288;1945&#24180;&#65289;&#25253;&#36947;&#30340;&#27827;&#27969;&#20998;&#27969;&#24773;&#20917;&#31867;&#20284;&#12290;&#20174;&#35813;&#25968;&#20540;&#30340;&#29702;&#35770;&#35266;&#28857;&#20986;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#23427;&#26159;&#22312;&#29305;&#23450;&#27169;&#22411;&#19979;&#22788;&#29702;&#21477;&#23376;&#25152;&#38656;&#35760;&#24518;&#37327;&#30340;&#19979;&#38480;&#12290;&#23545;&#38543;&#26426;&#26641;&#36827;&#34892;&#30340;&#25968;&#23398;&#20998;&#26512;&#36827;&#19968;&#27493;&#20551;&#35774;&#20102;Strahler&#25968;&#30340;&#24615;&#36136;&#65292;&#25581;&#31034;&#20986;&#23427;&#24182;&#38750;&#24120;&#25968;&#32780;&#26159;&#20197;&#23545;&#25968;&#24418;&#24335;&#22686;&#38271;&#12290;&#36825;&#19968;&#21457;&#29616;&#25581;&#31034;&#20102;Strahler&#25968;&#20316;&#20026;&#25551;&#36848;&#33258;&#28982;&#35821;&#35328;&#21477;&#23376;&#29305;&#24449;&#30340;&#32479;&#35745;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Strahler number was originally proposed to characterize the complexity of river bifurcation and has found various applications. This article proposes computation of the Strahler number's upper and lower limits for natural language sentence tree structures, which are available in a large dataset allowing for statistical mechanics analysis.  Through empirical measurements across grammatically annotated data, the Strahler number of natural language sentences is shown to be almost always 3 or 4, similar to the case of river bifurcation as reported by Strahler (1957) and Horton (1945).  From the theory behind the number, we show that it is the lower limit of the amount of memory required to process sentences under a particular model. A mathematical analysis of random trees provides a further conjecture on the nature of the Strahler number, revealing that it is not a constant but grows logarithmically. This finding uncovers the statistical basics behind the Strahler number as a character
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#19978;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;LLM&#26080;&#27861;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#19988;&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.09597</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Clickbait Detection via Large Language Models. (arXiv:2306.09597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#19978;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;LLM&#26080;&#27861;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#19988;&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#20987;&#35825;&#39575;&#65288;Clickbait&#65289;&#20250;&#36890;&#36807;&#19968;&#20123;&#20196;&#20154;&#24778;&#35766;&#29978;&#33267;&#24341;&#20154;&#20837;&#32988;&#30340;&#26631;&#39064;&#26469;&#35825;&#23548;&#29992;&#25143;&#36827;&#34892;&#28857;&#20987;&#65292;&#20960;&#20046;&#28183;&#36879;&#21040;&#25152;&#26377;&#22312;&#32447;&#20869;&#23481;&#21457;&#24067;&#32773;&#65292;&#22914;&#26032;&#38395;&#38376;&#25143;&#21644;&#31038;&#20132;&#23186;&#20307;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM)&#24050;&#25104;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;NLP&#19979;&#28216;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;LLM&#26159;&#21542;&#21487;&#20197;&#20316;&#20026;&#39640;&#36136;&#37327;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#31995;&#32479;&#36824;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;LLM&#22312;&#22810;&#20010;&#33521;&#25991;&#21644;&#20013;&#25991;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#23569;&#26679;&#26412;&#22330;&#26223;&#19979;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#21644;&#24494;&#35843;PLM&#26041;&#27861;&#30456;&#27604;&#65292;LLM&#26080;&#27861;&#36798;&#21040;&#26368;&#20339;&#32467;&#26524;&#12290;&#19982;&#20154;&#31867;&#30452;&#35273;&#19981;&#21516;&#65292;&#23454;&#39564;&#34920;&#26126;LLM&#19981;&#33021;&#20165;&#36890;&#36807;&#26631;&#39064;&#23454;&#29616;&#28385;&#24847;&#30340;&#28857;&#20987;&#35825;&#39575;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clickbait, which aims to induce users with some surprising and even thrilling headlines for increasing click-through rates, permeates almost all online content publishers, such as news portals and social media. Recently, Large Language Models (LLMs) have emerged as a powerful instrument and achieved tremendous success in a serious of NLP downstream tasks. However, it is not yet known whether LLMs can be served as a high-quality clickbait detection system. In this paper, we analyze the performance of LLMs in the few-shot scenarios on a number of English and Chinese benchmark datasets. Experimental results show that LLMs cannot achieve the best results compared to the state-of-the-art deep and fine-tuning PLMs methods. Different from the human intuition, the experiments demonstrated that LLMs cannot make satisfied clickbait detection just by the headlines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14815</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Machine Reading Comprehension using Case-based Reasoning. (arXiv:2305.14815v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#30340;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#65292;&#36890;&#36807;&#20174;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#30456;&#20284;&#26696;&#20363;&#24182;&#36873;&#25321;&#26368;&#31867;&#20284;&#30340;&#19978;&#19979;&#25991;&#26469;&#39044;&#27979;&#31572;&#26696;&#65292;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#12290;&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#21644;&#26032;&#38395;&#38382;&#31572;&#20013;&#65292;CBR-MRC&#30340;&#20934;&#30830;&#24615;&#36229;&#36807;&#22522;&#20934;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#19982;&#20854;&#20182;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#19988;&#21487;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#20013;&#30340;&#31572;&#26696;&#25552;&#21462;&#65292;&#35813;&#26041;&#27861;&#31867;&#20284;&#20110;&#32463;&#20856;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#22522;&#20110;&#26696;&#20363;&#25512;&#29702;&#65288;CBR&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;CBR-MRC&#65289;&#22522;&#20110;&#19968;&#20010;&#20551;&#35774;&#65292;&#21363;&#30456;&#20284;&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#24444;&#27492;&#20043;&#38388;&#20855;&#26377;&#35821;&#20041;&#30456;&#20284;&#24615;&#12290;&#32473;&#23450;&#19968;&#20010;&#27979;&#35797;&#38382;&#39064;&#65292;CBR-MRC&#39318;&#20808;&#20174;&#38750;&#21442;&#25968;&#21270;&#23384;&#20648;&#22120;&#20013;&#26816;&#32034;&#19968;&#32452;&#30456;&#20284;&#30340;&#26696;&#20363;&#65292;&#28982;&#21518;&#36890;&#36807;&#36873;&#25321;&#27979;&#35797;&#19978;&#19979;&#25991;&#20013;&#26368;&#31867;&#20284;&#20110;&#26816;&#32034;&#21040;&#30340;&#26696;&#20363;&#20013;&#19978;&#19979;&#25991;&#21270;&#31572;&#26696;&#34920;&#31034;&#30340;&#33539;&#22260;&#26469;&#39044;&#27979;&#31572;&#26696;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21322;&#21442;&#25968;&#21270;&#30340;&#29305;&#24615;&#20351;&#20854;&#33021;&#22815;&#23558;&#39044;&#27979;&#24402;&#22240;&#20110;&#29305;&#23450;&#30340;&#35777;&#25454;&#26696;&#20363;&#38598;&#65292;&#22240;&#27492;&#22312;&#26500;&#24314;&#21487;&#38752;&#19988;&#21487;&#35843;&#35797;&#30340;&#38382;&#31572;&#31995;&#32479;&#26102;&#26159;&#19968;&#20010;&#29702;&#24819;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#65288;NaturalQuestions&#65289;&#21644;&#26032;&#38395;&#38382;&#31572;&#65288;NewsQA&#65289;&#19978;&#27604;&#22823;&#22411;&#35835;&#32773;&#27169;&#22411;&#25552;&#20379;&#20102;&#39640;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#20248;&#20110;&#22522;&#20934;&#20998;&#21035;&#25552;&#21319;&#20102;11.5&#21644;8.4 EM&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;CBR-MRC&#22312;&#35782;&#21035;&#19982;&#20182;&#20154;&#35780;&#20272;&#21592;&#19981;&#21516;&#30340;&#31572;&#26696;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an accurate and interpretable method for answer extraction in machine reading comprehension that is reminiscent of case-based reasoning (CBR) from classical AI. Our method (CBR-MRC) builds upon the hypothesis that contextualized answers to similar questions share semantic similarities with each other. Given a test question, CBR-MRC first retrieves a set of similar cases from a non-parametric memory and then predicts an answer by selecting the span in the test context that is most similar to the contextualized representations of answers in the retrieved cases. The semi-parametric nature of our approach allows it to attribute a prediction to the specific set of evidence cases, making it a desirable choice for building reliable and debuggable QA systems. We show that CBR-MRC provides high accuracy comparable with large reader models and outperforms baselines by 11.5 and 8.4 EM on NaturalQuestions and NewsQA, respectively. Further, we demonstrate the ability of CBR-MRC in identi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AlpacaFarm&#30340;&#20302;&#25104;&#26412;&#27169;&#25311;&#22120;&#65292;&#35813;&#27169;&#25311;&#22120;&#20026;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#35774;&#35745;LLM&#25552;&#31034;&#26469;&#27169;&#25311;&#20154;&#31867;&#21453;&#39304;&#65292;&#25552;&#20986;&#33258;&#21160;&#35780;&#20272;&#24182;&#25552;&#20379;&#21442;&#32771;&#23454;&#29616;&#65292;&#20811;&#26381;&#20102;&#25968;&#25454;&#25910;&#38598;&#30340;&#39640;&#26114;&#25104;&#26412;&#12289;&#32570;&#20047;&#21487;&#20449;&#30340;&#35780;&#20272;&#21644;&#32570;&#20047;&#21442;&#32771;&#26041;&#27861;&#23454;&#29616;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.14387</link><description>&lt;p&gt;
AlpacaFarm: &#19968;&#31181;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#27169;&#25311;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback. (arXiv:2305.14387v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14387
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AlpacaFarm&#30340;&#20302;&#25104;&#26412;&#27169;&#25311;&#22120;&#65292;&#35813;&#27169;&#25311;&#22120;&#20026;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#35774;&#35745;LLM&#25552;&#31034;&#26469;&#27169;&#25311;&#20154;&#31867;&#21453;&#39304;&#65292;&#25552;&#20986;&#33258;&#21160;&#35780;&#20272;&#24182;&#25552;&#20379;&#21442;&#32771;&#23454;&#29616;&#65292;&#20811;&#26381;&#20102;&#25968;&#25454;&#25910;&#38598;&#30340;&#39640;&#26114;&#25104;&#26412;&#12289;&#32570;&#20047;&#21487;&#20449;&#30340;&#35780;&#20272;&#21644;&#32570;&#20047;&#21442;&#32771;&#26041;&#27861;&#23454;&#29616;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;ChatGPT&#22240;&#20854;&#33391;&#22909;&#30340;&#25351;&#20196;&#36319;&#38543;&#33021;&#21147;&#32780;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#24320;&#21457;&#36825;&#20123;LLMs&#38656;&#35201;&#20351;&#29992;&#20154;&#31867;&#21453;&#39304;&#36827;&#34892;&#35757;&#32451;&#30340;&#22797;&#26434;&#19988;&#23578;&#19981;&#26126;&#30830;&#30340;&#24037;&#20316;&#27969;&#31243;&#12290;&#23558;&#27492;&#25351;&#20196;&#36319;&#38543;&#36807;&#31243;&#22797;&#21046;&#21644;&#29702;&#35299;&#38754;&#20020;&#19977;&#22823;&#25361;&#25112;&#65306; &#25968;&#25454;&#25910;&#38598;&#30340;&#39640;&#26114;&#25104;&#26412;&#65292;&#32570;&#20047;&#21487;&#20449;&#30340;&#35780;&#20272;&#21644;&#32570;&#20047;&#21442;&#32771;&#26041;&#27861;&#23454;&#29616;&#12290;&#25105;&#20204;&#36890;&#36807;AlpacaFarm&#35299;&#20915;&#20102;&#36825;&#20123;&#25361;&#25112;&#65292;&#36825;&#26159;&#19968;&#20010;&#20302;&#25104;&#26412;&#30340;&#27169;&#25311;&#22120;&#65292;&#21487;&#29992;&#20110;&#20174;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#24320;&#21457;&#12290;&#31532;&#19968;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;LLM&#25552;&#31034;&#26469;&#27169;&#25311;&#20154;&#31867;&#21453;&#39304;&#65292;&#20854;&#25104;&#26412;&#27604;&#20247;&#21253;&#24037;&#20316;&#32773;&#20415;&#23452;45&#20493;&#65292;&#24182;&#19988;&#19982;&#20154;&#31867;&#21453;&#39304;&#20855;&#26377;&#39640;&#24230;&#19968;&#33268;&#24615;&#12290;&#31532;&#20108;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#30495;&#23454;&#19990;&#30028;&#20132;&#20114;&#20013;&#33719;&#24471;&#30340;&#20154;&#31867;&#25351;&#20196;&#36827;&#34892;&#39564;&#35777;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#20026;&#20960;&#31181;&#20174;&#37197;&#23545;&#21453;&#39304;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#65288;PPO&#65292;best-of-n&#65292;expert iteration&#31561;&#65289;&#25552;&#20379;&#20102;&#21442;&#32771;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these challenges with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM prompts to simulate human feedback that are 45x cheaper than crowdworkers and display high agreement with humans. Second, we propose an automatic evaluation and validate it against human instructions obtained on real-world interactions. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, and more) that learn from pairwise feedback
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#31435;&#20110;&#35299;&#26512;&#22120;&#30340;&#25991;&#26412;&#21040;SQL&#35821;&#20041;&#35299;&#26512;&#30340;&#35823;&#24046;&#26816;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#25552;&#39640;&#35299;&#26512;&#22120;&#30340;&#24615;&#33021;&#21644;&#21487;&#29992;&#24615;&#65292;&#19981;&#32771;&#34385;&#20854;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.13683</link><description>&lt;p&gt;
&#25991;&#26412;&#21040;SQL&#35821;&#20041;&#35299;&#26512;&#20013;&#30340;&#35823;&#24046;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Error Detection for Text-to-SQL Semantic Parsing. (arXiv:2305.13683v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13683
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#31435;&#20110;&#35299;&#26512;&#22120;&#30340;&#25991;&#26412;&#21040;SQL&#35821;&#20041;&#35299;&#26512;&#30340;&#35823;&#24046;&#26816;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#25552;&#39640;&#35299;&#26512;&#22120;&#30340;&#24615;&#33021;&#21644;&#21487;&#29992;&#24615;&#65292;&#19981;&#32771;&#34385;&#20854;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#24180;&#26469;&#25991;&#26412;&#21040;SQL&#35821;&#20041;&#35299;&#26512;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#35299;&#26512;&#22120;&#30340;&#24615;&#33021;&#20173;&#36828;&#38750;&#23436;&#32654;&#12290;&#21516;&#26102;&#65292;&#29616;&#20195;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#25991;&#26412;&#21040;SQL&#35299;&#26512;&#22120;&#24448;&#24448;&#36807;&#20110;&#33258;&#20449;&#65292;&#22240;&#27492;&#22312;&#23454;&#38469;&#20351;&#29992;&#26102;&#23545;&#20854;&#21487;&#38752;&#24615;&#20135;&#29983;&#24576;&#30097;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29420;&#31435;&#20110;&#35299;&#26512;&#22120;&#30340;&#25991;&#26412;&#21040;SQL&#35821;&#20041;&#35299;&#26512;&#30340;&#35823;&#24046;&#26816;&#27979;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#22522;&#20110;&#20195;&#30721;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#36827;&#34892;&#22686;&#24378;&#12290;&#25105;&#20204;&#22312;&#36328;&#39046;&#22495;&#35774;&#32622;&#20013;&#25910;&#38598;&#30340;&#23454;&#38469;&#35299;&#26512;&#35823;&#24046;&#19978;&#35757;&#32451;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#38024;&#23545;&#20855;&#26377;&#19981;&#21516;&#35299;&#30721;&#26426;&#21046;&#30340;&#19977;&#31181;&#24378;&#22823;&#30340;&#25991;&#26412;&#21040;SQL&#35299;&#26512;&#22120;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#35299;&#26512;&#22120;&#20381;&#36182;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#26377;&#25928;&#22320;&#25552;&#39640;&#35299;&#26512;&#22120;&#30340;&#24615;&#33021;&#21644;&#21487;&#29992;&#24615;&#65292;&#32780;&#19981;&#32771;&#34385;&#20854;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite remarkable progress in text-to-SQL semantic parsing in recent years, the performance of existing parsers is still far from perfect. At the same time, modern deep learning based text-to-SQL parsers are often over-confident and thus casting doubt on their trustworthiness when deployed for real use. To that end, we propose to build a parser-independent error detection model for text-to-SQL semantic parsing. The proposed model is based on pre-trained language model of code and is enhanced with structural features learned by graph neural networks. We train our model on realistic parsing errors collected from a cross-domain setting. Experiments with three strong text-to-SQL parsers featuring different decoding mechanisms show that our approach outperforms parser-dependent uncertainty metrics and could effectively improve the performance and usability of text-to-SQL semantic parsers regardless of their architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#36328;&#36234;&#22810;&#31181;&#35821;&#35328;&#12289;&#20027;&#39064;&#21644;&#19978;&#19979;&#25991;&#26469;&#26816;&#32034;&#30334;&#31185;&#30693;&#35782;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;Meta&#30340;LLaMA&#27169;&#22411;&#20934;&#30830;&#29575;&#36739;&#39640;&#65292;&#20294;&#20063;&#23384;&#22312;&#19981;&#36275;&#20043;&#22788;&#65292;&#34920;&#26126;&#21033;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#22810;&#35821;&#31181;&#24037;&#20855;&#30340;&#21069;&#26223;&#24182;&#19981;&#26126;&#26174;&#12290;</title><link>http://arxiv.org/abs/2305.13675</link><description>&lt;p&gt;
&#22810;&#35821;&#35328;&#36824;&#26159;&#21333;&#19968;&#35821;&#31181;&#65311;&#22522;&#20110;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#35821;&#35328;&#30334;&#31185;&#30693;&#35782;&#26816;&#32034;&#33021;&#21147;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models. (arXiv:2305.13675v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13675
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#36328;&#36234;&#22810;&#31181;&#35821;&#35328;&#12289;&#20027;&#39064;&#21644;&#19978;&#19979;&#25991;&#26469;&#26816;&#32034;&#30334;&#31185;&#30693;&#35782;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;Meta&#30340;LLaMA&#27169;&#22411;&#20934;&#30830;&#29575;&#36739;&#39640;&#65292;&#20294;&#20063;&#23384;&#22312;&#19981;&#36275;&#20043;&#22788;&#65292;&#34920;&#26126;&#21033;&#29992;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#22810;&#35821;&#31181;&#24037;&#20855;&#30340;&#21069;&#26223;&#24182;&#19981;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#22522;&#30784;&#27169;&#22411;&#22312;&#36328;&#36234;&#22810;&#31181;&#35821;&#35328;&#12289;&#20027;&#39064;&#21644;&#19978;&#19979;&#25991;&#26469;&#26816;&#32034;&#30334;&#31185;&#30693;&#35782;&#30340;&#33021;&#21147;&#12290;&#20026;&#25903;&#25345;&#36825;&#19968;&#24037;&#20316;&#65292;&#25105;&#20204;&#21046;&#20316;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;20&#31181;&#19981;&#21516;&#35821;&#35328;&#30340;303k&#20010;&#20107;&#23454;&#20851;&#32852;&#65292;&#24182;&#21046;&#23450;&#20102;&#19968;&#31181;&#26032;&#30340;&#21453;&#20107;&#23454;&#30693;&#35782;&#35780;&#20272;&#26041;&#24335;&#8220;&#22810;&#35821;&#31181;&#36824;&#26159;&#21333;&#19968;&#35821;&#31181;&#8221;&#65292;&#24182;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#23545;5&#20010;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#20197;&#21450;&#22312;&#33521;&#35821;&#29615;&#22659;&#19979;&#23545;20&#31181;&#27169;&#22411;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#24863;&#20852;&#36259;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#24046;&#24322;&#26174;&#33879;&#65292;Meta&#30340;LLaMA&#27169;&#22411;&#22312;&#22810;&#35821;&#31181;&#21644;&#20165;&#33521;&#35821;&#35780;&#20272;&#20013;&#22343;&#25490;&#21517;&#31532;&#19968;&#12290;&#35823;&#24046;&#20998;&#26512;&#26174;&#31034;&#65292;LLaMA&#27169;&#22411;&#22312;&#26816;&#32034;&#20351;&#29992;&#35199;&#37324;&#23572;&#23383;&#27597;&#20070;&#20889;&#30340;&#35821;&#35328;&#30340;&#20107;&#23454;&#26102;&#26377;&#26174;&#33879;&#19981;&#36275;&#65292;&#21516;&#26102;&#22312;&#29702;&#35299;&#20027;&#35821;&#30340;&#20301;&#32622;&#21644;&#24615;&#21035;&#26041;&#38754;&#23384;&#22312;&#28431;&#27934;&#12290;&#26368;&#32456;&#65292;&#25105;&#20204;&#35748;&#20026;&#65292;&#23558;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#29992;&#20316;&#30495;&#27491;&#30340;&#22810;&#35821;&#31181;&#24517;&#22791;&#24037;&#20855;&#26102;&#65292;&#23427;&#20204;&#34987;&#36171;&#20104;&#20102;&#26816;&#32034;&#20449;&#24687;&#30340;&#20219;&#21153;&#65292;&#36825;&#31181;&#25215;&#35834;&#22823;&#22823;&#38477;&#20302;&#20102;&#23427;&#20204;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we evaluate the capacity for foundation models to retrieve encyclopedic knowledge across a wide range of languages, topics, and contexts. To support this effort, we 1) produce a new dataset containing 303k factual associations in 20 different languages, 2) formulate a new counterfactual knowledge assessment, Polyglot or Not, and 3) benchmark 5 foundation models in a multilingual setting and a diverse set of 20 models in an English-only setting. We observed significant accuracy differences in models of interest, with Meta's LLaMA topping both the multilingual and English-only assessments. Error analysis reveals a significant deficiency in LLaMA's ability to retrieve facts in languages written in the Cyrillic script and gaps in its understanding of facts based on the location and gender of entailed subjects. Ultimately, we argue that the promise of utilizing foundation language models as bonafide polyglots is greatly diminished when they are tasked with retrieving informati
&lt;/p&gt;</description></item><item><title>DADA&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#20010;&#26041;&#35328;&#65292;&#22522;&#20110;&#35821;&#35328;&#35268;&#21017;&#30340;&#21160;&#24577;&#32858;&#21512;&#36866;&#37197;&#22120;&#65292;&#21487;&#20026;SAE&#35757;&#32451;&#30340;&#27169;&#22411;&#36171;&#20104;&#22810;&#26041;&#35328;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#38024;&#23545;&#29305;&#23450;&#26041;&#35328;&#21464;&#20307;&#36827;&#34892;&#36866;&#24212;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26041;&#35328;&#36866;&#24212;&#24615;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2305.13406</link><description>&lt;p&gt;
DADA: &#22522;&#20110;&#35821;&#35328;&#35268;&#21017;&#30340;&#26041;&#35328;&#36866;&#24212;&#24615;&#21160;&#24577;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules. (arXiv:2305.13406v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13406
&lt;/p&gt;
&lt;p&gt;
DADA&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#20010;&#26041;&#35328;&#65292;&#22522;&#20110;&#35821;&#35328;&#35268;&#21017;&#30340;&#21160;&#24577;&#32858;&#21512;&#36866;&#37197;&#22120;&#65292;&#21487;&#20026;SAE&#35757;&#32451;&#30340;&#27169;&#22411;&#36171;&#20104;&#22810;&#26041;&#35328;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#38024;&#23545;&#29305;&#23450;&#26041;&#35328;&#21464;&#20307;&#36827;&#34892;&#36866;&#24212;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26041;&#35328;&#36866;&#24212;&#24615;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20027;&#35201;&#38598;&#20013;&#20110;&#26631;&#20934;&#32654;&#24335;&#33521;&#35821;&#65288;SAE&#65289;&#65292;&#22312;&#24212;&#29992;&#20110;&#20854;&#20182;&#33521;&#35821;&#26041;&#35328;&#26102;&#34920;&#29616;&#24448;&#24448;&#36739;&#24046;&#12290;&#32780;&#29616;&#26377;&#30340;&#32531;&#35299;&#26041;&#27861;&#38024;&#23545;&#21333;&#20010;&#30446;&#26631;&#26041;&#35328;&#30340;&#20559;&#24046;&#65292;&#20294;&#20551;&#35774;&#20102;&#21487;&#20197;&#35775;&#38382;&#39640;&#31934;&#24230;&#30340;&#26041;&#35328;&#35782;&#21035;&#31995;&#32479;&#12290;&#26041;&#35328;&#20043;&#38388;&#30340;&#30028;&#38480;&#22266;&#26377;&#24377;&#24615;&#65292;&#20351;&#24471;&#23558;&#35821;&#35328;&#21010;&#20998;&#20026;&#31163;&#25955;&#39044;&#23450;&#20041;&#30340;&#33539;&#30068;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DADA&#65288;&#22522;&#20110;&#35821;&#35328;&#35268;&#21017;&#30340;&#26041;&#35328;&#36866;&#24212;&#24615;&#21160;&#24577;&#32858;&#21512;&#65289;&#65292;&#19968;&#31181;&#36890;&#36807;&#32452;&#21512;&#22788;&#29702;&#29305;&#23450;&#35821;&#35328;&#29305;&#24449;&#30340;&#36866;&#37197;&#22120;&#65292;&#20026;SAE&#35757;&#32451;&#30340;&#27169;&#22411;&#36171;&#20104;&#22810;&#26041;&#35328;&#30340;&#40065;&#26834;&#24615;&#30340;&#27169;&#22359;&#21270;&#26041;&#27861;&#12290;DADA&#30340;&#32452;&#21512;&#26550;&#26500;&#20801;&#35768;&#26377;&#38024;&#23545;&#24615;&#22320;&#36866;&#24212;&#29305;&#23450;&#26041;&#35328;&#21464;&#20307;&#65292;&#21516;&#26102;&#36866;&#24212;&#21508;&#31181;&#26041;&#35328;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DADA&#23545;&#20110;&#21333;&#20219;&#21153;&#21644;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#37117;&#26159;&#26377;&#25928;&#30340;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#21487;&#35299;&#37322;&#30340;&#26694;&#26550;&#26469;&#36866;&#24212;&#21508;&#31181;&#26041;&#35328;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects. While existing mitigations tackle discrepancies for individual target dialects, they assume access to high-accuracy dialect identification systems. The boundaries between dialects are inherently flexible, making it difficult to categorize language into discrete predefined categories. In this paper, we propose DADA (Dialect Adaptation via Dynamic Aggregation), a modular approach to imbue SAE-trained models with multi-dialectal robustness by composing adapters which handle specific linguistic features. The compositional architecture of DADA allows for both targeted adaptation to specific dialect variants and simultaneous adaptation to various dialects. We show that DADA is effective for both single task and instruction finetuned language models, offering an extensible and interpretable framework for adapting
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21548;&#35273;&#21333;&#35789;&#35782;&#21035;&#21644;&#25972;&#21512;&#30340;&#31070;&#32463;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#35299;&#37322;&#20102;&#36825;&#19968;&#36807;&#31243;&#65292;&#21457;&#29616;&#23545;&#20110;&#38656;&#35201;&#36229;&#36807;&#22823;&#32422;100ms&#30340;&#36755;&#20837;&#25165;&#33021;&#34987;&#35782;&#21035;&#30340;&#21333;&#35789;&#65292;&#31070;&#32463;&#21709;&#24212;&#20250;&#34987;&#25918;&#22823;&#12290;</title><link>http://arxiv.org/abs/2305.13388</link><description>&lt;p&gt;
&#21548;&#35273;&#21333;&#35789;&#35782;&#21035;&#21644;&#25972;&#21512;&#30340;&#31070;&#32463;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
The neural dynamics of auditory word recognition and integration. (arXiv:2305.13388v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21548;&#35273;&#21333;&#35789;&#35782;&#21035;&#21644;&#25972;&#21512;&#30340;&#31070;&#32463;&#21160;&#24577;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#35299;&#37322;&#20102;&#36825;&#19968;&#36807;&#31243;&#65292;&#21457;&#29616;&#23545;&#20110;&#38656;&#35201;&#36229;&#36807;&#22823;&#32422;100ms&#30340;&#36755;&#20837;&#25165;&#33021;&#34987;&#35782;&#21035;&#30340;&#21333;&#35789;&#65292;&#31070;&#32463;&#21709;&#24212;&#20250;&#34987;&#25918;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21548;&#32773;&#36890;&#36807;&#23558;&#26377;&#20851;&#21363;&#23558;&#20986;&#29616;&#30340;&#20869;&#23481;&#30340;&#26399;&#26395;&#19982;&#22686;&#37327;&#24863;&#30693;&#35777;&#25454;&#30456;&#32467;&#21512;&#65292;&#26469;&#24555;&#36895;&#35782;&#21035;&#21644;&#25972;&#21512;&#22024;&#26434;&#30340;&#26085;&#24120;&#35821;&#38899;&#20013;&#30340;&#21333;&#35789;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21333;&#35789;&#35782;&#21035;&#30340;&#35745;&#31639;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#20013;&#24418;&#24335;&#21270;&#20102;&#36825;&#19968;&#30693;&#35273;&#36807;&#31243;&#12290;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#25311;&#21512;&#21040;&#20316;&#20026;&#34987;&#35797;&#32773;&#34987;&#21160;&#21548;&#21462;&#34394;&#26500;&#25925;&#20107;&#26102;&#35760;&#24405;&#30340;&#22836;&#30382;&#33041;&#30005;&#20449;&#21495;&#20013;&#65292;&#25581;&#31034;&#20102;&#22312;&#32447;&#21548;&#35273;&#21333;&#35789;&#35782;&#21035;&#36807;&#31243;&#21644;&#21333;&#35789;&#35782;&#21035;&#21644;&#25972;&#21512;&#30340;&#31070;&#32463;&#30456;&#20851;&#24615;&#30340;&#21160;&#21147;&#23398;&#12290;&#35813;&#27169;&#22411;&#25581;&#31034;&#20102;&#21333;&#35789;&#30340;&#19981;&#21516;&#31070;&#32463;&#22788;&#29702;&#65292;&#20855;&#20307;&#21462;&#20915;&#20110;&#23427;&#20204;&#26159;&#21542;&#21487;&#20197;&#24555;&#36895;&#35782;&#21035;&#12290;&#34429;&#28982;&#25152;&#26377;&#21333;&#35789;&#37117;&#35302;&#21457;&#27010;&#29575;&#25972;&#21512;&#30340;&#31070;&#32463;&#21709;&#24212;&#65292;&#21363;&#25991;&#26412;&#32972;&#26223;&#20013;&#23545;&#21333;&#35789;&#24778;&#24322;&#24230;&#39044;&#27979;&#30340;&#30005;&#21387;&#35843;&#21046;&#65292;&#20294;&#23545;&#20110;&#38656;&#35201;&#36229;&#36807;&#22823;&#32422;100ms&#30340;&#36755;&#20837;&#25165;&#33021;&#34987;&#35782;&#21035;&#30340;&#21333;&#35789;&#65292;&#36825;&#20123;&#35843;&#21046;&#20250;&#34987;&#25918;&#22823;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20123;&#31070;&#32463;&#21709;&#24212;&#30340;&#28508;&#20239;&#26399;&#19981;&#20250;&#26681;&#25454;&#21333;&#35789;&#38271;&#24230;&#32780;&#26377;&#25152;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Listeners recognize and integrate words in rapid and noisy everyday speech by combining expectations about upcoming content with incremental sensory evidence. We present a computational model of word recognition which formalizes this perceptual process in Bayesian decision theory. We fit this model to explain scalp EEG signals recorded as subjects passively listened to a fictional story, revealing both the dynamics of the online auditory word recognition process and the neural correlates of the recognition and integration of words.  The model reveals distinct neural processing of words depending on whether or not they can be quickly recognized. While all words trigger a neural response characteristic of probabilistic integration -- voltage modulations predicted by a word's surprisal in context -- these modulations are amplified for words which require more than roughly 100 ms of input to be recognized. We observe no difference in the latency of these neural responses according to words
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#23450;&#29702;&#39537;&#21160;&#30340;&#38382;&#39064;&#22238;&#31572;&#25968;&#25454;&#38598;TheoremQA&#65292;&#21487;&#29992;&#20110;&#35780;&#20272;AI&#27169;&#22411;&#22312;&#24212;&#29992;&#23450;&#29702;&#35299;&#20915;&#31185;&#23398;&#38382;&#39064;&#26102;&#30340;&#33021;&#21147;&#65292;&#32463;&#36807;&#27979;&#35797;&#65292;GPT-4&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#19978;&#30340;&#20934;&#30830;&#29575;&#36828;&#39640;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.12524</link><description>&lt;p&gt;
TheoremQA&#65306;&#19968;&#31181;&#23450;&#29702;&#39537;&#21160;&#30340;&#38382;&#39064;&#22238;&#31572;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
TheoremQA: A Theorem-driven Question Answering dataset. (arXiv:2305.12524v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12524
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#23450;&#29702;&#39537;&#21160;&#30340;&#38382;&#39064;&#22238;&#31572;&#25968;&#25454;&#38598;TheoremQA&#65292;&#21487;&#29992;&#20110;&#35780;&#20272;AI&#27169;&#22411;&#22312;&#24212;&#29992;&#23450;&#29702;&#35299;&#20915;&#31185;&#23398;&#38382;&#39064;&#26102;&#30340;&#33021;&#21147;&#65292;&#32463;&#36807;&#27979;&#35797;&#65292;GPT-4&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#19978;&#30340;&#20934;&#30830;&#29575;&#36828;&#39640;&#20110;&#20854;&#20182;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;LLMs&#22914;GPT-4&#21644;PaLM-2&#22312;&#35299;&#20915;&#20687;GSM8K&#36825;&#26679;&#30340;&#22522;&#26412;&#25968;&#23398;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#65292;&#20934;&#30830;&#29575;&#36229;&#36807;90%&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#35299;&#20915;&#38656;&#35201;&#39046;&#22495;&#29305;&#23450;&#30693;&#35782;&#65288;&#21363;&#23450;&#29702;&#65289;&#30340;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#25968;&#23398;&#38382;&#39064;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#28145;&#20837;&#30740;&#31350;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;TheoremQA&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#23450;&#29702;&#39537;&#21160;&#30340;&#38382;&#39064;&#22238;&#31572;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#35780;&#20272;AI&#27169;&#22411;&#24212;&#29992;&#23450;&#29702;&#35299;&#20915;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#31185;&#23398;&#38382;&#39064;&#30340;&#33021;&#21147;&#12290;TheoremQA&#30001;&#39046;&#22495;&#19987;&#23478;&#31574;&#21010;&#65292;&#21253;&#21547;&#26469;&#33258;&#25968;&#23398;&#12289;&#29289;&#29702;&#12289;&#30005;&#27668;&#19982;&#35745;&#31639;&#26426;&#31185;&#23398;&#20197;&#21450;&#37329;&#34701;&#23398;&#30340;800&#20010;&#39640;&#36136;&#37327;&#38382;&#39064;&#65292;&#28085;&#30422;350&#20010;&#23450;&#29702;&#65288;&#20363;&#22914;&#27888;&#21202;&#23450;&#29702;&#12289;&#25289;&#26684;&#26391;&#26085;&#23450;&#29702;&#12289;&#21704;&#22827;&#26364;&#32534;&#30721;&#12289;&#37327;&#23376;&#23450;&#29702;&#12289;&#24377;&#24615;&#23450;&#29702;&#31561;&#31561;&#65289;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;16&#20010;&#22823;&#22411;&#35821;&#35328;&#21644;&#20195;&#30721;&#27169;&#22411;&#20197;&#21450;&#19981;&#21516;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#20363;&#22914;Chain-of-Thoughts&#21644;Program-of-Thoughts&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;GPT-4&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#33021;&#21147;&#26159;&#26080;&#19982;&#20262;&#27604;&#30340;&#65292;&#20351;&#29992;Program-of-Thoughts&#25552;&#31034;&#31574;&#30053;&#26102;&#20934;&#30830;&#29575;&#36798;51%&#65292;&#32780;&#20854;&#20182;&#27169;&#22411;&#36828;&#36828;&#33853;&#21518;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent LLMs like GPT-4 and PaLM-2 have made tremendous progress in solving fundamental math problems like GSM8K by achieving over 90% accuracy. However, their capabilities to solve more challenging math problems which require domain-specific knowledge (i.e. theorem) have yet to be investigated. In this paper, we introduce TheoremQA, the first theorem-driven question-answering dataset designed to evaluate AI models' capabilities to apply theorems to solve challenging science problems. TheoremQA is curated by domain experts containing 800 high-quality questions covering 350 theorems (e.g. Taylor's theorem, Lagrange's theorem, Huffman coding, Quantum Theorem, Elasticity Theorem, etc) from Math, Physics, EE&amp;CS, and Finance. We evaluate a wide spectrum of 16 large language and code models with different prompting strategies like Chain-of-Thoughts and Program-of-Thoughts. We found that GPT-4's capabilities to solve these problems are unparalleled, achieving an accuracy of 51% with Progra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#28085;&#30422;18&#20010;&#32763;&#35793;&#26041;&#21521;&#65292;&#21253;&#25324;&#22810;&#31181;&#36164;&#28304;&#27700;&#24179;&#21644;&#33050;&#26412;&#30340;&#26426;&#22120;&#32763;&#35793;&#20013;&#8220;&#24187;&#35273;&#8221;&#21644;&#36951;&#28431;&#29616;&#35937;&#30340;&#25163;&#21160;&#27880;&#37322;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#35780;&#20272;&#19981;&#21516;&#35821;&#35328;&#23545;&#30340;&#34920;&#29616;&#65292;&#20026;&#35813;&#39046;&#22495;&#30740;&#31350;&#25552;&#20379;&#21487;&#38752;&#30340;&#22522;&#32447;&#12290;</title><link>http://arxiv.org/abs/2305.11746</link><description>&lt;p&gt;
HalOmi&#65306;&#26426;&#22120;&#32763;&#35793;&#20013;&#22810;&#35821;&#35328;&#8220;&#24187;&#35273;&#8221;&#21644;&#36951;&#28431;&#26816;&#27979;&#30340;&#25163;&#21160;&#27880;&#37322;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation. (arXiv:2305.11746v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#28085;&#30422;18&#20010;&#32763;&#35793;&#26041;&#21521;&#65292;&#21253;&#25324;&#22810;&#31181;&#36164;&#28304;&#27700;&#24179;&#21644;&#33050;&#26412;&#30340;&#26426;&#22120;&#32763;&#35793;&#20013;&#8220;&#24187;&#35273;&#8221;&#21644;&#36951;&#28431;&#29616;&#35937;&#30340;&#25163;&#21160;&#27880;&#37322;&#25968;&#25454;&#38598;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#35780;&#20272;&#19981;&#21516;&#35821;&#35328;&#23545;&#30340;&#34920;&#29616;&#65292;&#20026;&#35813;&#39046;&#22495;&#30740;&#31350;&#25552;&#20379;&#21487;&#38752;&#30340;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#20013;&#30340;&#8220;&#24187;&#35273;&#8221;&#25351;&#30340;&#26159;&#23436;&#20840;&#19982;&#36755;&#20837;&#20449;&#24687;&#26080;&#20851;&#30340;&#20449;&#24687;&#65292;&#32780;&#8220;&#36951;&#28431;&#8221;&#26159;&#25351;&#26410;&#21253;&#25324;&#26576;&#20123;&#36755;&#20837;&#20449;&#24687;&#30340;&#32763;&#35793;&#12290;&#23613;&#31649;&#36825;&#20004;&#31181;&#24773;&#20917;&#24448;&#24448;&#26159;&#30772;&#22351;&#29992;&#25143;&#20449;&#20219;&#30340;&#28798;&#38590;&#24615;&#38169;&#35823;&#65292;&#20294;&#36825;&#20123;&#31867;&#22411;&#30340;&#24102;&#27880;&#37322;&#25968;&#25454;&#38750;&#24120;&#31232;&#32570;&#65292;&#24182;&#19988;&#20165;&#38480;&#20110;&#23569;&#25968;&#39640;&#36164;&#28304;&#35821;&#35328;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#19968;&#20010;&#26631;&#27880;&#30340;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#28085;&#30422;18&#31181;&#32763;&#35793;&#26041;&#21521;&#30340;&#24187;&#35273;&#21644;&#36951;&#28431;&#29616;&#35937;&#65292;&#20854;&#36164;&#28304;&#27700;&#24179;&#21644;&#33050;&#26412;&#21508;&#19981;&#30456;&#21516;&#12290;&#25105;&#20204;&#30340;&#27880;&#37322;&#28085;&#30422;&#20102;&#19981;&#21516;&#32423;&#21035;&#30340;&#23436;&#20840;&#24187;&#35273;&#12289;&#37096;&#20998;&#24187;&#35273;&#20197;&#21450;&#21477;&#23376;&#21644;&#21333;&#35789;&#19968;&#32423;&#30340;&#36951;&#28431;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37325;&#35775;&#20102;&#20197;&#21069;&#30340;&#30740;&#31350;&#65292;&#23637;&#31034;&#20102;&#22522;&#20110;&#21333;&#20010;&#35821;&#35328;&#23545;&#24471;&#20986;&#30340;&#32467;&#35770;&#22312;&#22823;&#35268;&#27169;&#35780;&#20272;&#20013;&#24456;&#38590;&#25104;&#31435;&#65292;&#24182;&#24314;&#31435;&#20102;&#26032;&#30340;&#21487;&#38752;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hallucinations in machine translation are translations that contain information completely unrelated to the input. Omissions are translations that do not include some of the input information. While both cases tend to be catastrophic errors undermining user trust, annotated data with these types of pathologies is extremely scarce and is limited to a few high-resource languages. In this work, we release an annotated dataset for the hallucination and omission phenomena covering 18 translation directions with varying resource levels and scripts. Our annotation covers different levels of partial and full hallucinations as well as omissions both at the sentence and at the word level. Additionally, we revisit previous methods for hallucination and omission detection, show that conclusions made based on a single language pair largely do not hold for a large-scale evaluation, and establish new solid baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#35752;&#35770;&#20102;&#22312;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#24211;&#20013;&#34920;&#36798;&#12289;&#25552;&#21462;&#21644;&#25512;&#26029;&#23436;&#25972;&#24615;&#12289;&#21484;&#22238;&#29575;&#21644;&#21542;&#23450;&#24615;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#38754;&#23545;&#19981;&#23436;&#25972;&#21644;&#19981;&#30830;&#23450;&#30340;&#30693;&#35782;&#26102;&#65292;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#24212;&#35813;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.05403</link><description>&lt;p&gt;
&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#24211;&#20013;&#30340;&#23436;&#25972;&#24615;&#12289;&#21484;&#22238;&#29575;&#21644;&#21542;&#23450;&#24615;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Completeness, Recall, and Negation in Open-World Knowledge Bases: A Survey. (arXiv:2305.05403v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#35752;&#35770;&#20102;&#22312;&#24320;&#25918;&#19990;&#30028;&#30693;&#35782;&#24211;&#20013;&#34920;&#36798;&#12289;&#25552;&#21462;&#21644;&#25512;&#26029;&#23436;&#25972;&#24615;&#12289;&#21484;&#22238;&#29575;&#21644;&#21542;&#23450;&#24615;&#20449;&#24687;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#38754;&#23545;&#19981;&#23436;&#25972;&#21644;&#19981;&#30830;&#23450;&#30340;&#30693;&#35782;&#26102;&#65292;&#20174;&#19994;&#32773;&#21644;&#30740;&#31350;&#20154;&#21592;&#24212;&#35813;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#29992;&#30693;&#35782;&#24211;&#26159;&#30693;&#35782;&#20013;&#24515;&#30340;AI&#30340;&#22522;&#30707;&#12290;&#35768;&#22810;&#30693;&#35782;&#24211;&#26159;&#20174;Web&#26469;&#28304;&#23454;&#29992;&#20027;&#20041;&#26500;&#24314;&#30340;&#65292;&#22240;&#27492;&#36828;&#38750;&#23436;&#25972;&#12290;&#36825;&#32473;&#20869;&#23481;&#30340;&#28040;&#36153;&#21644;&#31649;&#29702;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#35843;&#26597;&#35752;&#35770;&#20102;&#22914;&#20309;&#34920;&#36798;&#12289;&#25552;&#21462;&#21644;&#25512;&#26029;&#30693;&#35782;&#24211;&#20013;&#30340;&#23436;&#25972;&#24615;&#12289;&#21484;&#22238;&#29575;&#21644;&#21542;&#23450;&#24615;&#20449;&#24687;&#12290;&#25105;&#20204;&#28085;&#30422;&#20102;&#65288;i&#65289;&#37096;&#20998;&#23553;&#38381;&#19990;&#30028;&#35821;&#20041;&#19979;&#30340;&#30693;&#35782;&#34920;&#31034;&#21644;&#26597;&#35810;&#30340;&#36923;&#36753;&#22522;&#30784;&#65307;&#65288;ii&#65289;&#36890;&#36807;&#32479;&#35745;&#27169;&#24335;&#20272;&#35745;&#27492;&#20449;&#24687;&#65307;&#65288;iii&#65289;&#20174;&#30693;&#35782;&#24211;&#21644;&#25991;&#26412;&#20013;&#25552;&#21462;&#20851;&#20110;&#21484;&#22238;&#29575;&#30340;&#20449;&#24687;&#65307;&#65288;iv&#65289;&#36776;&#21035;&#26377;&#36259;&#30340;&#21542;&#23450;&#35821;&#21477;&#65307;&#20197;&#21450;&#65288;v&#65289;&#30456;&#23545;&#21484;&#22238;&#29575;&#30340;&#23485;&#26494;&#27010;&#24565;&#12290;&#26412;&#35843;&#26597;&#38024;&#23545;&#20004;&#31867;&#21463;&#20247;&#65306;&#65288;1&#65289;&#23547;&#27714;&#22788;&#29702;&#19981;&#23436;&#25972;&#21644;&#19981;&#30830;&#23450;&#30693;&#35782;&#25351;&#21335;&#30340;&#20174;&#19994;&#32773;&#65292;&#20197;&#21450;&#65288;2&#65289;&#26088;&#22312;&#25512;&#36827;&#30693;&#35782;&#24211;&#31649;&#29702;&#12289;&#36136;&#37327;&#35780;&#20272;&#21644;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#30740;&#31350;&#20154;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;
General-purpose knowledge bases (KBs) are a cornerstone of knowledge-centric AI. Many of them are constructed pragmatically from Web sources, and are thus far from complete. This poses challenges for the consumption as well as the curation of their content. While several surveys target the problem of completing incomplete KBs, the first problem is arguably to know whether and where the KB is incomplete in the first place, and to which degree.  In this survey we discuss how knowledge about completeness, recall, and negation in KBs can be expressed, extracted, and inferred. We cover (i) the logical foundations of knowledge representation and querying under partial closed-world semantics; (ii) the estimation of this information via statistical patterns; (iii) the extraction of information about recall from KBs and text; (iv) the identification of interesting negative statements; and (v) relaxed notions of relative recall.  This survey is targeted at two types of audiences: (1) practitione
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20004;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20195;&#30721;&#20998;&#26512;&#20013;&#22788;&#29702;&#39046;&#22495;&#22806;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#32452;&#32455;&#12289;&#39033;&#30446;&#21644;&#27169;&#22359;&#30340;&#33258;&#28982;&#36793;&#30028;&#20998;&#21106;&#26041;&#27861;&#65292;&#21457;&#29616;&#27599;&#20010;&#26032;&#39046;&#22495;&#30340;&#26679;&#26412;&#37117;&#20250;&#20135;&#29983;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#19982;&#23569;&#37327;&#24494;&#35843;&#30456;&#32467;&#21512;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.09128</link><description>&lt;p&gt;
&#25506;&#32034;&#29992;&#20110;&#20195;&#30721;&#20998;&#26512;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Exploring Distributional Shifts in Large Language Models for Code Analysis. (arXiv:2303.09128v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09128
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20004;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#20195;&#30721;&#20998;&#26512;&#20013;&#22788;&#29702;&#39046;&#22495;&#22806;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#32452;&#32455;&#12289;&#39033;&#30446;&#21644;&#27169;&#22359;&#30340;&#33258;&#28982;&#36793;&#30028;&#20998;&#21106;&#26041;&#27861;&#65292;&#21457;&#29616;&#27599;&#20010;&#26032;&#39046;&#22495;&#30340;&#26679;&#26412;&#37117;&#20250;&#20135;&#29983;&#20998;&#24067;&#20559;&#31227;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#19982;&#23569;&#37327;&#24494;&#35843;&#30456;&#32467;&#21512;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#20004;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; CodeT5 &#21644; Codex &#30340;&#33021;&#21147;&#65292;&#20197;&#20415;&#25512;&#24191;&#21040;&#39046;&#22495;&#22806;&#25968;&#25454;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#22522;&#26412;&#24212;&#29992;&#65306;&#20195;&#30721;&#25688;&#35201;&#21644;&#20195;&#30721;&#29983;&#25104;&#12290;&#25105;&#20204;&#25353;&#29031;&#20854;&#33258;&#28982;&#36793;&#30028;&#65288;&#25353;&#32452;&#32455;&#12289;&#25353;&#39033;&#30446;&#21644;&#25353;&#36719;&#20214;&#39033;&#30446;&#20013;&#30340;&#27169;&#22359;&#65289;&#23558;&#25968;&#25454;&#20998;&#20026;&#19981;&#21516;&#30340;&#39046;&#22495;&#12290;&#36825;&#26679;&#65292;&#22312;&#37096;&#32626;&#26102;&#65292;&#35782;&#21035;&#39046;&#22495;&#20869;&#21644;&#39046;&#22495;&#22806;&#30340;&#25968;&#25454;&#21464;&#24471;&#31616;&#21333;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26469;&#33258;&#27599;&#20010;&#26032;&#39046;&#22495;&#30340;&#26679;&#26412;&#37117;&#20250;&#32473;&#36825;&#20004;&#20010;&#27169;&#22411;&#24102;&#26469;&#20998;&#24067;&#20559;&#31227;&#30340;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#22914;&#20309;&#36866;&#24212;&#27169;&#22411;&#20197;&#26356;&#22909;&#22320;&#25512;&#24191;&#21040;&#26032;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#34429;&#28982;&#22810;&#20219;&#21153;&#23398;&#20064;&#26412;&#36523;&#26159;&#19968;&#20010;&#21512;&#29702;&#30340;&#22522;&#32447;&#65292;&#20294;&#23558;&#20854;&#19982;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#26816;&#32034;&#30340;&#31034;&#20363;&#30340;&#23569;&#37327;&#24494;&#35843;&#30456;&#32467;&#21512;&#21487;&#20197;&#23454;&#29616;&#38750;&#24120;&#24378;&#30340;&#24615;&#33021;&#12290;&#20107;&#23454;&#19978;&#65292;&#26681;&#25454;&#25105;&#20204;&#30340;&#23454;&#39564;&#65292;&#36825;&#31181;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#20248;&#20110;&#30452;&#25509;&#35843;&#25972;&#24494;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;
We systematically study the capacity of two large language models for code CodeT5 and Codex - to generalize to out-of-domain data. In this study, we consider two fundamental applications - code summarization, and code generation. We split data into domains following its natural boundaries - by an organization, by a project, and by a module within the software project. This makes recognition of in-domain vs out-of-domain data at the time of deployment trivial. We establish that samples from each new domain present both models with a significant challenge of distribution shift. We study how well different established methods can adapt models to better generalize to new domains. Our experiments show that while multitask learning alone is a reasonable baseline, combining it with few-shot finetuning on examples retrieved from training data can achieve very strong performance. In fact, according to our experiments, this solution can outperform direct finetuning for very low-data scenarios.
&lt;/p&gt;</description></item><item><title>BiasTestGPT&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#20559;&#35265;&#27979;&#35797;&#26694;&#26550;&#65292;&#21033;&#29992;ChatGPT&#36827;&#34892;&#27979;&#35797;&#21477;&#23376;&#30340;&#29983;&#25104;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26816;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#22312;&#20132;&#21449;&#20559;&#35265;&#31561;&#25361;&#25112;&#24615;&#24773;&#22659;&#20013;&#12290;</title><link>http://arxiv.org/abs/2302.07371</link><description>&lt;p&gt;
BiasTestGPT: &#20351;&#29992;ChatGPT&#23545;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31038;&#20250;&#20559;&#35265;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models. (arXiv:2302.07371v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07371
&lt;/p&gt;
&lt;p&gt;
BiasTestGPT&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;&#20559;&#35265;&#27979;&#35797;&#26694;&#26550;&#65292;&#21033;&#29992;ChatGPT&#36827;&#34892;&#27979;&#35797;&#21477;&#23376;&#30340;&#29983;&#25104;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#26816;&#27979;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#23588;&#20854;&#26159;&#22312;&#20132;&#21449;&#20559;&#35265;&#31561;&#25361;&#25112;&#24615;&#24773;&#22659;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#23384;&#22312;&#22266;&#26377;&#30340;&#31038;&#20250;&#20559;&#35265;&#65292;&#21487;&#33021;&#23548;&#33268;&#26377;&#23475;&#30340;&#29616;&#23454;&#24433;&#21709;&#12290;&#36825;&#31181;&#31038;&#20250;&#20559;&#35265;&#26159;&#36890;&#36807;PLMs&#23545;&#19968;&#32452;&#27979;&#35797;&#21477;&#23376;&#20013;&#19981;&#21516;&#31038;&#20250;&#32676;&#20307;&#21644;&#23646;&#24615;&#30340;&#27010;&#29575;&#20540;&#36827;&#34892;&#27979;&#37327;&#24471;&#20986;&#30340;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20559;&#35265;&#27979;&#35797;&#26041;&#27861;&#38750;&#24120;&#32321;&#29712;&#65292;&#22240;&#20026;&#27979;&#35797;&#21477;&#23376;&#35201;&#20040;&#26159;&#20174;&#26377;&#38480;&#30340;&#19968;&#32452;&#25163;&#21160;&#27169;&#26495;&#20013;&#29983;&#25104;&#65292;&#35201;&#20040;&#38656;&#35201;&#26114;&#36149;&#30340;&#20247;&#21253;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;ChatGPT&#36827;&#34892;&#21487;&#25511;&#29983;&#25104;&#27979;&#35797;&#21477;&#23376;&#65292;&#20197;&#28385;&#36275;&#29992;&#25143;&#25351;&#23450;&#30340;&#20219;&#24847;&#31038;&#20250;&#32676;&#20307;&#21644;&#23646;&#24615;&#32452;&#21512;&#12290;&#19982;&#22522;&#20110;&#27169;&#26495;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#20351;&#29992;ChatGPT&#36827;&#34892;&#27979;&#35797;&#21477;&#23376;&#29983;&#25104;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#31038;&#20250;&#20559;&#35265;&#26041;&#38754;&#26356;&#20026;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#20132;&#21449;&#20559;&#35265;&#31561;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#22659;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;&#20840;&#38754;&#20559;&#35265;&#27979;&#35797;&#26694;&#26550;&#65288;BiasTestGPT&#65289;&#65292;&#25176;&#31649;&#22312;HuggingFace&#19978;&#65292;&#21487;&#20197;&#25554;&#20837;&#21040;&#20219;&#20309;&#24320;&#28304;PLM&#20013;&#36827;&#34892;&#20559;&#35265;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained Language Models (PLMs) harbor inherent social biases that can result in harmful real-world implications. Such social biases are measured through the probability values that PLMs output for different social groups and attributes appearing in a set of test sentences. However, bias testing is currently cumbersome since the test sentences are generated either from a limited set of manual templates or need expensive crowd-sourcing. We instead propose using ChatGPT for controllable generation of test sentences, given any arbitrary user-specified combination of social groups and attributes appearing in the test sentences. When compared to template-based methods, our approach using ChatGPT for test sentence generation is superior in detecting social bias, especially in challenging settings such as intersectional biases. We present an open-source comprehensive bias testing framework (BiasTestGPT), hosted on HuggingFace, that can be plugged into any open-source PLM for bias testing. W
&lt;/p&gt;</description></item></channel></rss>