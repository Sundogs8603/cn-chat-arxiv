<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22810;&#35821;&#31181;&#35757;&#32451;&#30340;Poro 34B&#27169;&#22411;&#22312;&#33452;&#20848;&#35821;&#31561;&#23567;&#35821;&#31181;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#24182;&#20855;&#26377;&#27604;&#29616;&#26377;&#27169;&#22411;&#26356;&#20986;&#33394;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2404.01856</link><description>&lt;p&gt;
Poro 34B&#21644;&#22810;&#35821;&#31181;&#30340;&#31069;&#31119;
&lt;/p&gt;
&lt;p&gt;
Poro 34B and the Blessing of Multilinguality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01856
&lt;/p&gt;
&lt;p&gt;
&#22810;&#35821;&#31181;&#35757;&#32451;&#30340;Poro 34B&#27169;&#22411;&#22312;&#33452;&#20848;&#35821;&#31561;&#23567;&#35821;&#31181;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#24182;&#20855;&#26377;&#27604;&#29616;&#26377;&#27169;&#22411;&#26356;&#20986;&#33394;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#39044;&#35757;&#32451;&#29616;&#22312;&#38656;&#35201;&#25968;&#19975;&#20159;&#23383;&#30340;&#25991;&#26412;&#65292;&#36825;&#27604;&#32477;&#22823;&#22810;&#25968;&#35821;&#35328;&#21487;&#33719;&#24471;&#30340;&#25991;&#26412;&#25968;&#37327;&#22810;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#23613;&#31649;&#21253;&#21547;&#22810;&#31181;&#35821;&#35328;&#30340;&#25991;&#26412;&#26159;&#33719;&#21462;&#26356;&#22810;&#39044;&#35757;&#32451;&#25968;&#25454;&#30340;&#26126;&#26174;&#26041;&#27861;&#65292;&#20294;&#22810;&#35821;&#31181;&#24448;&#24448;&#34987;&#35270;&#20026;&#19968;&#31181;&#35781;&#21650;&#65292;&#22823;&#22810;&#25968;&#27169;&#22411;&#35757;&#32451;&#24037;&#20316;&#20173;&#28982;&#20027;&#35201;&#38598;&#20013;&#22312;&#20010;&#21035;&#22823;&#35821;&#31181;&#19978;&#12290;&#25105;&#20204;&#30456;&#20449;&#22810;&#35821;&#31181;&#21487;&#20197;&#26159;&#19968;&#31181;&#31069;&#31119;&#65292;&#24182;&#19988;&#24212;&#35813;&#26377;&#21487;&#33021;&#36890;&#36807;&#22810;&#35821;&#31181;&#35757;&#32451;&#26174;&#33879;&#25552;&#39640;&#23567;&#35821;&#31181;&#30340;&#27169;&#22411;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Poro 34B&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;1&#19975;&#20159;&#20010;&#33452;&#20848;&#35821;&#12289;&#33521;&#35821;&#21644;&#32534;&#31243;&#35821;&#35328;&#26631;&#35760;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;&#25317;&#26377;340&#20159;&#21442;&#25968;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22810;&#35821;&#31181;&#35757;&#32451;&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#19968;&#20010;&#27169;&#22411;&#65292;&#19981;&#20165;&#22312;&#33452;&#20848;&#35821;&#30340;&#29616;&#26377;&#27169;&#22411;&#33021;&#21147;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#32780;&#19988;&#22312;&#34920;&#29616;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01856v1 Announce Type: new  Abstract: The pretraining of state-of-the-art large language models now requires trillions of words of text, which is orders of magnitude more than available for the vast majority of languages. While including text in more than one language is an obvious way to acquire more pretraining data, multilinguality is often seen as a curse, and most model training efforts continue to focus near-exclusively on individual large languages. We believe that multilinguality can be a blessing and that it should be possible to substantially improve over the capabilities of monolingual models for small languages through multilingual training. In this study, we introduce Poro 34B, a 34 billion parameter model trained for 1 trillion tokens of Finnish, English, and programming languages, and demonstrate that a multilingual training approach can produce a model that not only substantially advances over the capabilities of existing models for Finnish, but also excels i
&lt;/p&gt;</description></item><item><title>LLMs&#24050;&#25104;&#20026;&#29983;&#29289;&#21307;&#23398;&#19982;&#20581;&#24247;&#20449;&#24687;&#23398;&#20013;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#26412;&#25991;&#29486;&#35745;&#37327;&#23398;&#32508;&#36848;&#20840;&#38754;&#23637;&#31034;&#20102;LLMs&#22312;&#21508;&#31181;BHI&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#20854;&#23545;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#30340;&#25913;&#36827;&#65292;&#25581;&#31034;&#20102;&#20027;&#35201;&#21457;&#23637;&#36235;&#21183;&#21644;&#30740;&#31350;&#32593;&#32476;&#65292;&#24182;&#35752;&#35770;&#20102;&#20262;&#29702;&#20851;&#20999;&#21644;&#23454;&#38469;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.16303</link><description>&lt;p&gt;
&#29983;&#29289;&#21307;&#23398;&#19982;&#20581;&#24247;&#20449;&#24687;&#23398;&#20013;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#19968;&#39033;&#25991;&#29486;&#35745;&#37327;&#23398;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Large Language Models in Biomedical and Health Informatics: A Bibliometric Review
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.16303
&lt;/p&gt;
&lt;p&gt;
LLMs&#24050;&#25104;&#20026;&#29983;&#29289;&#21307;&#23398;&#19982;&#20581;&#24247;&#20449;&#24687;&#23398;&#20013;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#26412;&#25991;&#29486;&#35745;&#37327;&#23398;&#32508;&#36848;&#20840;&#38754;&#23637;&#31034;&#20102;LLMs&#22312;&#21508;&#31181;BHI&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#20854;&#23545;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#30340;&#25913;&#36827;&#65292;&#25581;&#31034;&#20102;&#20027;&#35201;&#21457;&#23637;&#36235;&#21183;&#21644;&#30740;&#31350;&#32593;&#32476;&#65292;&#24182;&#35752;&#35770;&#20102;&#20262;&#29702;&#20851;&#20999;&#21644;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36805;&#36895;&#25104;&#20026;&#29983;&#29289;&#21307;&#23398;&#19982;&#20581;&#24247;&#20449;&#24687;&#23398;&#65288;BHI&#65289;&#20013;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#20026;&#20998;&#26512;&#25968;&#25454;&#12289;&#27835;&#30103;&#24739;&#32773;&#21644;&#24320;&#23637;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#24335;&#12290;&#26412;&#25991;&#29486;&#35745;&#37327;&#23398;&#32508;&#36848;&#26088;&#22312;&#36890;&#36807;&#26816;&#26597;&#33258;2022&#24180;&#33267;2023&#24180;&#30340;&#30740;&#31350;&#25991;&#31456;&#21644;&#21512;&#20316;&#32593;&#32476;&#65292;&#20840;&#38754;&#23637;&#31034;LLMs&#22312;BHI&#20013;&#30340;&#24212;&#29992;&#24773;&#20917;&#12290;&#23427;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;LLMs&#22914;&#20309;&#21487;&#20197;&#25913;&#36827;&#21508;&#31181;BHI&#39046;&#22495;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#24212;&#29992;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#12289;&#24739;&#32773;&#21442;&#19982;&#12289;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#31649;&#29702;&#21644;&#20010;&#24615;&#21270;&#21307;&#23398;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30340;&#25991;&#29486;&#35745;&#37327;&#23398;&#32508;&#36848;&#30830;&#23450;&#20102;&#20851;&#38190;&#36235;&#21183;&#65292;&#32472;&#21046;&#20102;&#30740;&#31350;&#32593;&#32476;&#65292;&#24182;&#31361;&#20986;&#20102;&#36825;&#20010;&#24555;&#36895;&#21457;&#23637;&#39046;&#22495;&#30340;&#20027;&#35201;&#36827;&#23637;&#12290;&#26368;&#21518;&#65292;&#23427;&#35752;&#35770;&#20102;&#22312;BHI&#20013;&#20351;&#29992;LLMs&#30340;&#20262;&#29702;&#20851;&#20999;&#21644;&#23454;&#38469;&#25361;&#25112;&#65292;&#22914;&#25968;&#25454;&#38544;&#31169;&#21644;&#21487;&#38752;&#30340;&#21307;&#30103;&#24314;&#35758;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;LLMs&#22914;&#20309;&#36827;&#19968;&#27493;&#25913;&#21464;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#25991;&#31456;&#27010;&#36848;&#20102;&#22312;&#25552;&#39640;LLM&#25512;&#29702;&#25928;&#26524;&#26041;&#38754;&#30340;&#26368;&#26032;&#26041;&#27861;&#21644;&#36827;&#23637;&#65292;&#36890;&#36807;&#23454;&#39564;&#35780;&#20272;&#19981;&#21516;&#21387;&#32553;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2402.01799</link><description>&lt;p&gt;
&#26356;&#24555;&#26356;&#36731;&#30340;LLMs&#65306;&#24403;&#21069;&#25361;&#25112;&#21644;&#26410;&#26469;&#21457;&#23637;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01799
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#25991;&#31456;&#27010;&#36848;&#20102;&#22312;&#25552;&#39640;LLM&#25512;&#29702;&#25928;&#26524;&#26041;&#38754;&#30340;&#26368;&#26032;&#26041;&#27861;&#21644;&#36827;&#23637;&#65292;&#36890;&#36807;&#23454;&#39564;&#35780;&#20272;&#19981;&#21516;&#21387;&#32553;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20986;&#25913;&#36827;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;LLMs&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#30001;&#20110;&#25512;&#29702;&#36807;&#31243;&#20013;&#38656;&#35201;&#22823;&#37327;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#36164;&#28304;&#65292;&#23427;&#20204;&#30340;&#26222;&#21450;&#38754;&#20020;&#30528;&#25361;&#25112;&#12290;&#26368;&#36817;&#22312;&#27169;&#22411;&#21387;&#32553;&#21644;&#31995;&#32479;&#32423;&#20248;&#21270;&#26041;&#27861;&#26041;&#38754;&#30340;&#36827;&#23637;&#26088;&#22312;&#22686;&#24378;LLM&#25512;&#29702;&#25928;&#26524;&#12290;&#26412;&#35843;&#26597;&#25552;&#20379;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#27010;&#36848;&#65292;&#24378;&#35843;&#20102;&#26368;&#36817;&#30340;&#21457;&#23637;&#12290;&#36890;&#36807;&#23545;LLaMA(/2)-7B&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#21387;&#32553;&#25216;&#26415;&#65292;&#20026;&#22312;&#32479;&#19968;&#29615;&#22659;&#20013;&#39640;&#25928;&#37096;&#32626;LLM&#25552;&#20379;&#20102;&#23454;&#36341;&#35265;&#35299;&#12290;&#23545;LLaMA(/2)-7B&#30340;&#23454;&#35777;&#20998;&#26512;&#31361;&#20986;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#22522;&#20110;&#35843;&#26597;&#32467;&#26524;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#24403;&#21069;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#25913;&#21892;LLM&#25512;&#29702;&#25928;&#29575;&#30340;&#28508;&#22312;&#26410;&#26469;&#26041;&#21521;&#12290;&#25105;&#20204;&#22312;https://github.com/nyunAI/Faster-LLM-Survey&#21457;&#24067;&#20102;&#29992;&#20110;&#22797;&#29616;&#26412;&#25991;&#32467;&#26524;&#30340;&#20195;&#30721;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the impressive performance of LLMs, their widespread adoption faces challenges due to substantial computational and memory requirements during inference. Recent advancements in model compression and system-level optimization methods aim to enhance LLM inference. This survey offers an overview of these methods, emphasizing recent developments. Through experiments on LLaMA(/2)-7B, we evaluate various compression techniques, providing practical insights for efficient LLM deployment in a unified setting. The empirical analysis on LLaMA(/2)-7B highlights the effectiveness of these methods. Drawing from survey insights, we identify current limitations and discuss potential future directions to improve LLM inference efficiency. We release the codebase to reproduce the results presented in this paper at https://github.com/nyunAI/Faster-LLM-Survey
&lt;/p&gt;</description></item><item><title>LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#21487;&#33021;&#27604;&#20154;&#31867;&#25776;&#20889;&#30340;&#34394;&#20551;&#20449;&#24687;&#26356;&#38590;&#20197;&#26816;&#27979;&#65292;&#20855;&#26377;&#26356;&#20855;&#27450;&#39575;&#24615;&#30340;&#39118;&#26684;&#65292;&#21487;&#33021;&#36896;&#25104;&#26356;&#22810;&#21361;&#23475;&#12290;</title><link>https://arxiv.org/abs/2309.13788</link><description>&lt;p&gt;
&#33021;&#22815;&#26816;&#27979;&#21040;LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#21527;?
&lt;/p&gt;
&lt;p&gt;
Can LLM-Generated Misinformation Be Detected?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.13788
&lt;/p&gt;
&lt;p&gt;
LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#21487;&#33021;&#27604;&#20154;&#31867;&#25776;&#20889;&#30340;&#34394;&#20551;&#20449;&#24687;&#26356;&#38590;&#20197;&#26816;&#27979;&#65292;&#20855;&#26377;&#26356;&#20855;&#27450;&#39575;&#24615;&#30340;&#39118;&#26684;&#65292;&#21487;&#33021;&#36896;&#25104;&#26356;&#22810;&#21361;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#20135;&#29983;&#20102;&#28145;&#36828;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;LLMs&#65288;&#22914;ChatGPT&#65289;&#21487;&#33021;&#34987;&#21033;&#29992;&#26469;&#29983;&#25104;&#34394;&#20551;&#20449;&#24687;&#65292;&#36825;&#32473;&#22312;&#32447;&#23433;&#20840;&#21644;&#20844;&#20247;&#20449;&#20219;&#24102;&#26469;&#20102;&#20005;&#37325;&#20851;&#20999;&#12290;&#19968;&#20010;&#22522;&#26412;&#30340;&#30740;&#31350;&#38382;&#39064;&#26159;&#65306;LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#26159;&#21542;&#20250;&#27604;&#20154;&#31867;&#25776;&#20889;&#30340;&#34394;&#20551;&#20449;&#24687;&#36896;&#25104;&#26356;&#22823;&#21361;&#23475;?&#25105;&#20204;&#25552;&#20986;&#20174;&#26816;&#27979;&#38590;&#24230;&#30340;&#35282;&#24230;&#26469;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#20998;&#31867;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#21033;&#29992;LLMs&#29983;&#25104;&#34394;&#20551;&#20449;&#24687;&#30340;&#28508;&#22312;&#30495;&#23454;&#19990;&#30028;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#21644;&#39564;&#35777;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#35843;&#26597;&#65292;&#25105;&#20204;&#21457;&#29616;&#19982;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#30340;&#20154;&#31867;&#25776;&#20889;&#30340;&#34394;&#20551;&#20449;&#24687;&#30456;&#27604;&#65292;LLM&#29983;&#25104;&#30340;&#34394;&#20551;&#20449;&#24687;&#23545;&#20154;&#31867;&#21644;&#26816;&#27979;&#22120;&#26469;&#35828;&#26356;&#38590;&#26816;&#27979;&#65292;&#36825;&#34920;&#26126;&#23427;&#21487;&#33021;&#20855;&#26377;&#26356;&#20855;&#27450;&#39575;&#24615;&#30340;&#39118;&#26684;&#65292;&#28508;&#22312;&#22320;&#36896;&#25104;&#26356;&#22810;&#21361;&#23475;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25105;&#20204;&#21457;&#29616;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.13788v3 Announce Type: replace-cross  Abstract: The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery
&lt;/p&gt;</description></item><item><title>LLMCheckup&#26159;&#19968;&#20010;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#65292;&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#21487;&#35299;&#37322;&#30340;AI&#24037;&#20855;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#19982;&#27169;&#22411;&#36827;&#34892;&#23545;&#35805;&#65292;&#29983;&#25104;&#33258;&#25105;&#35299;&#37322;&#24182;&#25552;&#20379;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2401.12576</link><description>&lt;p&gt;
LLMCheckup&#65306;&#36890;&#36807;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#23545;&#35805;&#24335;&#26816;&#26597;
&lt;/p&gt;
&lt;p&gt;
LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools. (arXiv:2401.12576v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12576
&lt;/p&gt;
&lt;p&gt;
LLMCheckup&#26159;&#19968;&#20010;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#65292;&#36890;&#36807;&#36830;&#25509;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19982;&#21487;&#35299;&#37322;&#30340;AI&#24037;&#20855;&#65292;&#20351;&#29992;&#25143;&#33021;&#22815;&#19982;&#27169;&#22411;&#36827;&#34892;&#23545;&#35805;&#65292;&#29983;&#25104;&#33258;&#25105;&#35299;&#37322;&#24182;&#25552;&#20379;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20197;&#23545;&#35805;&#24418;&#24335;&#36827;&#34892;&#35299;&#37322;&#30340;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#24050;&#32463;&#35777;&#26126;&#22312;&#22686;&#24378;&#29992;&#25143;&#29702;&#35299;&#26041;&#38754;&#20855;&#26377;&#25928;&#26524;&#65292;&#22240;&#20026;&#19968;&#27425;&#24615;&#35299;&#37322;&#26377;&#26102;&#26080;&#27861;&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#32473;&#29992;&#25143;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#22522;&#20110;&#23545;&#35805;&#30340;&#35299;&#37322;&#26041;&#26696;&#38656;&#35201;&#35768;&#22810;&#20381;&#36182;&#39033;&#65292;&#24182;&#19988;&#19981;&#23481;&#26131;&#36716;&#31227;&#21040;&#23427;&#20204;&#26410;&#35774;&#35745;&#30340;&#20219;&#21153;&#19978;&#12290;&#36890;&#36807;LLMCheckup&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26131;&#20110;&#35775;&#38382;&#30340;&#24037;&#20855;&#65292;&#20801;&#35768;&#29992;&#25143;&#19982;&#20219;&#20309;&#26368;&#26032;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#23545;&#35805;&#20197;&#20102;&#35299;&#20854;&#34892;&#20026;&#12290;&#25105;&#20204;&#20351;LLMs&#33021;&#22815;&#33258;&#34892;&#29983;&#25104;&#25152;&#26377;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#19982;&#19968;&#31995;&#21015;&#21487;&#35299;&#37322;&#24615;AI&#65288;XAI&#65289;&#24037;&#20855;&#65288;&#20363;&#22914;&#29305;&#24449;&#24402;&#22240;&#12289;&#22522;&#20110;&#23884;&#20837;&#30340;&#30456;&#20284;&#24615;&#20197;&#21450;&#21453;&#20107;&#23454;&#21644;&#22522;&#20110;&#29702;&#30001;&#29983;&#25104;&#30340;&#25552;&#31034;&#31574;&#30053;&#65289;&#36830;&#25509;&#65292;&#20197;&#23436;&#25104;&#24847;&#22270;&#35782;&#21035;&#32780;&#26080;&#38656;&#24494;&#35843;&#12290;LLM&#65288;&#33258;&#25105;&#65289;&#35299;&#37322;&#20197;&#20132;&#20114;&#23545;&#35805;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#25903;&#25345;&#21518;&#32493;&#38382;&#39064;&#21644;&#29983;&#25104;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability tools that offer explanations in the form of a dialogue have demonstrated their efficacy in enhancing users' understanding, as one-off explanations may occasionally fall short in providing sufficient information to the user. Current solutions for dialogue-based explanations, however, require many dependencies and are not easily transferable to tasks they were not designed for. With LLMCheckup, we present an easily accessible tool that allows users to chat with any state-of-the-art large language model (LLM) about its behavior. We enable LLMs to generate all explanations by themselves and take care of intent recognition without fine-tuning, by connecting them with a broad spectrum of Explainable AI (XAI) tools, e.g. feature attributions, embedding-based similarity, and prompting strategies for counterfactual and rationale generation. LLM (self-)explanations are presented as an interactive dialogue that supports follow-up questions and generates suggestions. LLMCheckup p
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#19982;&#22270;&#32467;&#21512;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22238;&#39038;&#21644;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2311.12399</link><description>&lt;p&gt;
&#22270;&#36935;&#19978;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65306;&#36827;&#23637;&#19982;&#26410;&#26469;&#26041;&#21521;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Survey of Graph Meets Large Language Model: Progress and Future Directions. (arXiv:2311.12399v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.12399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#23545;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#19982;&#22270;&#32467;&#21512;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22238;&#39038;&#21644;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#22312;&#34920;&#31034;&#21644;&#20998;&#26512;&#35832;&#22914;&#24341;&#29992;&#32593;&#32476;&#12289;&#31038;&#20132;&#32593;&#32476;&#21644;&#29983;&#29289;&#25968;&#25454;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#24182;&#19988;&#24050;&#32463;&#34987;&#24212;&#29992;&#20110;&#22270;&#30456;&#20851;&#20219;&#21153;&#20013;&#65292;&#36229;&#36234;&#20102;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#30340;&#20256;&#32479;&#26041;&#27861;&#65292;&#24182;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#23558;LLMs&#19982;&#22270;&#32467;&#21512;&#30340;&#29616;&#26377;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#30340;&#22238;&#39038;&#21644;&#20998;&#26512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#31867;&#27861;&#65292;&#26681;&#25454;LLMs&#22312;&#22270;&#30456;&#20851;&#20219;&#21153;&#20013;&#25198;&#28436;&#30340;&#35282;&#33394;(&#21363;&#22686;&#24378;&#22120;&#12289;&#39044;&#27979;&#22120;&#21644;&#23545;&#40784;&#32452;&#20214;)&#65292;&#23558;&#29616;&#26377;&#26041;&#27861;&#32452;&#32455;&#20026;&#19977;&#20010;&#31867;&#21035;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#35843;&#26597;&#20102;&#20998;&#31867;&#27861;&#19977;&#20010;&#31867;&#21035;&#20013;&#30340;&#20195;&#34920;&#24615;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#29616;&#26377;&#30740;&#31350;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26377;&#24076;&#26395;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;DEFT&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#26694;&#26550;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#20102;70%&#30340;&#25968;&#25454;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16776</link><description>&lt;p&gt;
DEFT&#65306;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#23454;&#29616;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection. (arXiv:2310.16776v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16776
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;DEFT&#30340;&#25968;&#25454;&#39640;&#25928;&#24494;&#35843;&#26694;&#26550;&#65292;&#36890;&#36807;&#26080;&#30417;&#30563;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;&#29616;&#26377;&#27169;&#22411;&#30456;&#24403;&#65292;&#24182;&#19988;&#20165;&#20351;&#29992;&#20102;70%&#30340;&#25968;&#25454;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#36827;&#23637;&#20351;&#24471;&#35768;&#22810;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21487;&#20197;&#20351;&#29992;&#65307;&#28982;&#32780;&#65292;&#19968;&#20010;&#20173;&#28982;&#23384;&#22312;&#30340;&#38382;&#39064;&#26159;&#24494;&#35843;PLMs&#20197;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#31350;&#31455;&#38656;&#35201;&#22810;&#23569;&#25968;&#25454;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DEFT&#65292;&#19968;&#31181;&#25968;&#25454;&#39640;&#25928;&#30340;&#24494;&#35843;&#26694;&#26550;&#65292;&#23427;&#21033;&#29992;&#26080;&#30417;&#30563;&#30340;&#26680;&#24515;&#38598;&#36873;&#25321;&#26469;&#26368;&#23567;&#21270;&#24494;&#35843;PLMs&#25152;&#38656;&#30340;&#25968;&#25454;&#37327;&#12290;&#25105;&#20204;&#22312;&#25991;&#26412;&#32534;&#36753;LM&#30340;&#32972;&#26223;&#19979;&#23637;&#31034;&#20102;DEFT&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#32534;&#36753;&#27169;&#22411;CoEDIT&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#23450;&#37327;&#21644;&#23450;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;DEFT&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#19982;CoEDIT&#19968;&#26679;&#65292;&#32780;&#20351;&#29992;&#30340;&#25968;&#25454;&#37327;&#35201;&#23569;&#32422;70%&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks. We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT. Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;&#38543;&#26426;&#21021;&#22987;&#21270;&#20250;&#23548;&#33268;&#23545;&#26550;&#26500;&#24046;&#24322;&#30340;&#20005;&#37325;&#39640;&#20272;&#65292;&#32780;&#20351;&#29992;&#26631;&#20934;&#28040;&#22122;&#30446;&#26631;&#36827;&#34892;&#39044;&#35757;&#32451;&#21487;&#20197;&#22312;&#22810;&#31181;&#26550;&#26500;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#23558;Transformers&#19982;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#21040;&#24456;&#23567;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#27491;&#30830;&#39044;&#35757;&#32451;&#26102;&#65292;&#26222;&#36890;&#30340;Transformers&#22312;Long Range Arena&#19978;&#30340;&#24615;&#33021;&#19982;S4&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#22312;PathX-256&#20219;&#21153;&#19978;&#25913;&#36827;&#20102;SSMs&#30340;&#26368;&#20339;&#32467;&#26524;20&#20010;&#30334;&#20998;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.02980</link><description>&lt;p&gt;
&#27704;&#36828;&#19981;&#35201;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#65306;&#20844;&#27491;&#27604;&#36739;&#38271;&#24207;&#21015;&#27169;&#22411;&#38656;&#35201;&#25968;&#25454;&#39537;&#21160;&#30340;&#20808;&#39564;&#30693;&#35782;
&lt;/p&gt;
&lt;p&gt;
Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors. (arXiv:2310.02980v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#20351;&#29992;&#38543;&#26426;&#21021;&#22987;&#21270;&#20250;&#23548;&#33268;&#23545;&#26550;&#26500;&#24046;&#24322;&#30340;&#20005;&#37325;&#39640;&#20272;&#65292;&#32780;&#20351;&#29992;&#26631;&#20934;&#28040;&#22122;&#30446;&#26631;&#36827;&#34892;&#39044;&#35757;&#32451;&#21487;&#20197;&#22312;&#22810;&#31181;&#26550;&#26500;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#24182;&#23558;Transformers&#19982;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20043;&#38388;&#30340;&#24046;&#36317;&#32553;&#23567;&#21040;&#24456;&#23567;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#27491;&#30830;&#39044;&#35757;&#32451;&#26102;&#65292;&#26222;&#36890;&#30340;Transformers&#22312;Long Range Arena&#19978;&#30340;&#24615;&#33021;&#19982;S4&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#22312;PathX-256&#20219;&#21153;&#19978;&#25913;&#36827;&#20102;SSMs&#30340;&#26368;&#20339;&#32467;&#26524;20&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#24207;&#21015;&#20043;&#38388;&#30340;&#38271;&#31243;&#20381;&#36182;&#19968;&#30452;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#30446;&#26631;&#65292;&#24182;&#23548;&#33268;&#20102;&#19968;&#20123;&#26550;&#26500;&#65292;&#22914;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#27604;Transformers&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#24615;&#36827;&#23637;&#20027;&#35201;&#26159;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#24182;&#36890;&#36807;&#39044;&#27979;&#36755;&#20837;&#24207;&#21015;&#30340;&#30446;&#26631;&#26631;&#31614;&#36827;&#34892;&#35757;&#32451;&#30340;&#22522;&#20934;&#27979;&#35797;&#65288;&#20363;&#22914;Long Range Arena&#65289;&#19978;&#23637;&#31034;&#20986;&#26469;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#38543;&#26426;&#21021;&#22987;&#21270;&#23548;&#33268;&#23545;&#26550;&#26500;&#20043;&#38388;&#24046;&#24322;&#30340;&#20005;&#37325;&#39640;&#20272;&#65292;&#24182;&#19988;&#20351;&#29992;&#26631;&#20934;&#28040;&#22122;&#30446;&#26631;&#36827;&#34892;&#39044;&#35757;&#32451;&#65288;&#20165;&#20351;&#29992;&#19979;&#28216;&#20219;&#21153;&#25968;&#25454;&#65289;&#21487;&#20197;&#22312;&#22810;&#31181;&#26550;&#26500;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#25910;&#30410;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;Transformers&#21644;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSMs&#65289;&#20043;&#38388;&#24471;&#21040;&#24456;&#23567;&#30340;&#24046;&#36317;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#27491;&#30830;&#39044;&#35757;&#32451;&#26102;&#65292;&#26222;&#36890;&#30340;Transformers&#22312;Long Range Arena&#19978;&#19982;S4&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#25105;&#20204;&#22312;PathX-256&#20219;&#21153;&#19978;&#23558;SSMs&#30340;&#26368;&#20339;&#25253;&#21578;&#32467;&#26524;&#25552;&#39640;&#20102;20&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, using $\textit{only the downstream task data}$, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#24515;&#29702;&#23398;&#20013;&#30340;&#24773;&#24863;&#35780;&#20272;&#29702;&#35770;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;EmotionBench&#35780;&#20272;LLMs&#30340;&#20849;&#24773;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#21644;&#23545;&#20116;&#20010;LLMs&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23613;&#31649;&#23384;&#22312;&#19968;&#20123;&#19981;&#19968;&#33268;&#20043;&#22788;&#65292;LLMs&#36890;&#24120;&#33021;&#22312;&#26576;&#20123;&#24773;&#22659;&#19979;&#36866;&#24403;&#22320;&#22238;&#24212;&#65292;&#20294;&#19982;&#24773;&#24863;&#23545;&#40784;&#26041;&#38754;&#36824;&#23384;&#22312;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2308.03656</link><description>&lt;p&gt;
&#24863;&#35273;&#40635;&#26408;&#36824;&#26159;&#26377;&#20849;&#24773;&#33021;&#21147;&#65311;&#21033;&#29992;EmotionBench&#35780;&#20272;LLMs&#30340;&#24773;&#24863;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench. (arXiv:2308.03656v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03656
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#24515;&#29702;&#23398;&#20013;&#30340;&#24773;&#24863;&#35780;&#20272;&#29702;&#35770;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;EmotionBench&#35780;&#20272;LLMs&#30340;&#20849;&#24773;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#21644;&#23545;&#20116;&#20010;LLMs&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23613;&#31649;&#23384;&#22312;&#19968;&#20123;&#19981;&#19968;&#33268;&#20043;&#22788;&#65292;LLMs&#36890;&#24120;&#33021;&#22312;&#26576;&#20123;&#24773;&#22659;&#19979;&#36866;&#24403;&#22320;&#22238;&#24212;&#65292;&#20294;&#19982;&#24773;&#24863;&#23545;&#40784;&#26041;&#38754;&#36824;&#23384;&#22312;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20195;&#35805;&#35821;&#20013;&#65292;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#25311;&#20154;&#33021;&#21147;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#21033;&#29992;&#24515;&#29702;&#23398;&#20013;&#30340;&#24773;&#24863;&#35780;&#20272;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#35780;&#20272;LLMs&#30340;&#20849;&#24773;&#33021;&#21147;&#65292;&#21363;&#23427;&#20204;&#22312;&#29305;&#23450;&#24773;&#22659;&#19979;&#24863;&#21463;&#21464;&#21270;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#20180;&#32454;&#32780;&#20840;&#38754;&#30340;&#35843;&#26597;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#21253;&#21547;&#36229;&#36807;400&#31181;&#24773;&#22659;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#24773;&#22659;&#24050;&#34987;&#35777;&#26126;&#23545;&#25105;&#20204;&#30740;&#31350;&#30340;&#20843;&#31181;&#24773;&#24863;&#33267;&#20851;&#37325;&#35201;&#12290;&#23558;&#36825;&#20123;&#24773;&#22659;&#20998;&#20026;36&#20010;&#22240;&#32032;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#28041;&#21450;&#20840;&#29699;1200&#22810;&#21517;&#34987;&#35797;&#30340;&#20154;&#31867;&#35780;&#20272;&#12290;&#20197;&#20154;&#31867;&#35780;&#20272;&#32467;&#26524;&#20026;&#21442;&#32771;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20116;&#20010;LLMs&#65292;&#28085;&#30422;&#20102;&#21830;&#19994;&#21644;&#24320;&#28304;&#27169;&#22411;&#65292;&#21253;&#25324;&#27169;&#22411;&#22823;&#23567;&#30340;&#21464;&#21270;&#65292;&#20197;&#21450;&#26368;&#26032;&#30340;&#36845;&#20195;&#29256;&#26412;&#65288;&#22914;GPT-4&#21644;LLaMA-2&#65289;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#23384;&#22312;&#19968;&#20123;&#19981;&#19968;&#33268;&#20043;&#22788;&#65292;LLMs&#36890;&#24120;&#33021;&#22312;&#26576;&#20123;&#24773;&#22659;&#19979;&#36866;&#24403;&#22320;&#22238;&#24212;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#19982;&#24773;&#24863;&#23545;&#40784;&#26041;&#38754;&#36824;&#23384;&#22312;&#19968;&#23450;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluating Large Language Models' (LLMs) anthropomorphic capabilities has become increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, i.e., how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes five LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4 and LLaMA-2. We find that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the e
&lt;/p&gt;</description></item><item><title>AWQ&#26159;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#26435;&#37325;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20445;&#25252;&#23569;&#37327;&#26174;&#33879;&#26435;&#37325;&#26469;&#38477;&#20302;&#37327;&#21270;&#35823;&#24046;&#65292;&#19981;&#20381;&#36182;&#20110;&#21453;&#21521;&#20256;&#25773;&#25110;&#37325;&#26500;&#65292;&#24182;&#22312;&#35821;&#35328;&#24314;&#27169;&#21644;&#39046;&#22495;&#29305;&#23450;&#20219;&#21153;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00978</link><description>&lt;p&gt;
AWQ&#65306;LLM&#21387;&#32553;&#19982;&#21152;&#36895;&#30340;&#28608;&#27963;&#24863;&#30693;&#26435;&#37325;&#37327;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration. (arXiv:2306.00978v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00978
&lt;/p&gt;
&lt;p&gt;
AWQ&#26159;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#26435;&#37325;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20445;&#25252;&#23569;&#37327;&#26174;&#33879;&#26435;&#37325;&#26469;&#38477;&#20302;&#37327;&#21270;&#35823;&#24046;&#65292;&#19981;&#20381;&#36182;&#20110;&#21453;&#21521;&#20256;&#25773;&#25110;&#37325;&#26500;&#65292;&#24182;&#22312;&#35821;&#35328;&#24314;&#27169;&#21644;&#39046;&#22495;&#29305;&#23450;&#20219;&#21153;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;(LLM)&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#24040;&#22823;&#30340;&#27169;&#22411;&#22823;&#23567;&#25552;&#39640;&#20102;&#20026;&#26381;&#21153;(&#20869;&#23384;&#22823;&#23567;)&#24102;&#26469;&#30340;&#30828;&#20214;&#38556;&#30861;&#65292;&#24182;&#38477;&#20302;&#20102;&#20196;&#29260;&#29983;&#25104;&#36895;&#24230;(&#20869;&#23384;&#24102;&#23485;)&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28608;&#27963;&#24863;&#30693;&#26435;&#37325;&#37327;&#21270;(AWQ)&#30340;&#30828;&#20214;&#21451;&#22909;&#26041;&#27861;&#65292;&#29992;&#20110;LLM&#20302;&#27604;&#29305;&#26435;&#37325;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#35266;&#23519;&#65306;&#26435;&#37325;&#24182;&#19981;&#26159;&#31561;&#37325;&#35201;&#30340;&#65307;&#20165;&#20445;&#25252;1%&#30340;&#26174;&#33879;&#26435;&#37325;&#23601;&#33021;&#22823;&#22823;&#38477;&#20302;&#37327;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#23547;&#25214;&#36890;&#36807;&#35266;&#23519;&#28608;&#27963;&#20540;&#32780;&#19981;&#26159;&#26435;&#37325;&#26469;&#20445;&#25252;&#26174;&#33879;&#26435;&#37325;&#30340;&#26368;&#20339;&#25353;&#36890;&#36947;&#32553;&#25918;&#26041;&#27861;&#12290;AWQ&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#21453;&#21521;&#20256;&#25773;&#25110;&#37325;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#24456;&#22909;&#22320;&#20445;&#25345;LLM&#22312;&#19981;&#21516;&#39046;&#22495;&#21644;&#27169;&#24335;&#19979;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#19981;&#20250;&#36807;&#24230;&#25311;&#21512;&#26657;&#20934;&#38598;&#12290;AWQ&#22312;&#21508;&#31181;&#35821;&#35328;&#24314;&#27169;&#21644;&#39046;&#22495;&#29305;&#23450;&#22522;&#20934;&#27979;&#35797;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#30001;&#20110;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#23427;&#23454;&#29616;&#20102;&#20248;&#31168;&#30340;&#37327;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have shown excellent performance on various tasks, but the astronomical model size raises the hardware barrier for serving (memory size) and slows down token generation (memory bandwidth). In this paper, we propose Activation-aware Weight Quantization (AWQ), a hardware-friendly approach for LLM low-bit weight-only quantization. Our method is based on the observation that weights are not equally important: protecting only 1% of salient weights can greatly reduce quantization error. We then propose to search for the optimal per-channel scaling that protects the salient weights by observing the activation, not weights. AWQ does not rely on any backpropagation or reconstruction, so it can well preserve LLMs' generalization ability on different domains and modalities, without overfitting to the calibration set. AWQ outperforms existing work on various language modeling and domain-specific benchmarks. Thanks to better generalization, it achieves excellent quantiz
&lt;/p&gt;</description></item></channel></rss>