<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#24050;&#32463;&#23548;&#33268;AI&#21161;&#25163;&#30340;&#24613;&#21095;&#22686;&#38271;&#65292;&#20854;&#40065;&#26834;&#24615;&#37096;&#20998;&#24402;&#22240;&#20110;&#23545;&#40784;&#25216;&#26415;&#65292;&#28982;&#32780;&#36825;&#20123;&#21161;&#25163;&#20351;&#29992;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#21364;&#36739;&#20026;&#33030;&#24369;&#65292;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#39592;&#24178;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2404.02054</link><description>&lt;p&gt;
&#25286;&#35299;&#19978;&#19979;&#25991;&#23398;&#20064;: &#36890;&#36807;&#30772;&#22351;&#29702;&#35299;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Deconstructing In-Context Learning: Understanding Prompts via Corruption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02054
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33021;&#21147;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#24050;&#32463;&#23548;&#33268;AI&#21161;&#25163;&#30340;&#24613;&#21095;&#22686;&#38271;&#65292;&#20854;&#40065;&#26834;&#24615;&#37096;&#20998;&#24402;&#22240;&#20110;&#23545;&#40784;&#25216;&#26415;&#65292;&#28982;&#32780;&#36825;&#20123;&#21161;&#25163;&#20351;&#29992;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#21364;&#36739;&#20026;&#33030;&#24369;&#65292;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#39592;&#24178;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26681;&#25454;&#25552;&#20379;&#30340;&#25552;&#31034;&#8220;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#8221;&#30340;&#33021;&#21147;&#24050;&#32463;&#23548;&#33268;&#23427;&#20204;&#30340;&#20351;&#29992;&#25968;&#37327;&#24613;&#21095;&#22686;&#38271;&#65292;&#26368;&#32456;&#23548;&#33268;AI&#21161;&#25163;&#22914;ChatGPT&#12289;Claude&#21644;Bard&#30340;&#22823;&#37327;&#20986;&#29616;&#12290;&#36825;&#20123;AI&#21161;&#25163;&#34987;&#35748;&#20026;&#23545;&#25552;&#31034;&#30340;&#36731;&#24494;&#20462;&#25913;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#20351;&#29992;&#20102;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#25216;&#26415;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#23427;&#20204;&#20351;&#29992;&#20316;&#20026;&#39592;&#24178;&#30340;&#22522;&#30784;&#39044;&#35757;&#32451;LLMs&#34987;&#35748;&#20026;&#22312;&#36825;&#26041;&#38754;&#27604;&#36739;&#33030;&#24369;&#12290;&#26500;&#24314;&#39640;&#36136;&#37327;&#30340;&#39592;&#24178;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#65292;&#35780;&#20272;&#20854;&#36136;&#37327;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#36827;&#34892;&#23569;&#26679;&#26412;&#35780;&#20272;&#12290;&#36825;&#31181;&#35780;&#20272;&#20197;&#23545;&#36731;&#24494;&#25552;&#31034;&#20462;&#25913;&#21644;&#29305;&#23450;&#19978;&#19979;&#25991;&#31034;&#20363;&#36873;&#25321;&#30340;&#39640;&#24230;&#25935;&#24863;&#32780;&#33261;&#21517;&#26157;&#33879;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#32771;&#23519;&#20102;&#20462;&#25913;&#25552;&#31034;&#30340;&#19981;&#21516;&#20803;&#32032;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36739;&#26089;&#30340;&#30740;&#31350;&#24448;&#24448;&#38598;&#20013;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#20855;&#20307;&#25552;&#31034;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02054v1 Announce Type: new  Abstract: The ability of large language models (LLMs) to "learn in context" based on the provided prompt has led to an explosive growth in their use, culminating in the proliferation of AI assistants such as ChatGPT, Claude, and Bard. These AI assistants are known to be robust to minor prompt modifications, mostly due to alignment techniques that use human feedback. In contrast, the underlying pre-trained LLMs they use as a backbone are known to be brittle in this respect. Building high-quality backbone models remains a core challenge, and a common approach to assessing their quality is to conduct few-shot evaluation. Such evaluation is notorious for being highly sensitive to minor prompt modifications, as well as the choice of specific in-context examples. Prior work has examined how modifying different elements of the prompt can affect model performance. However, these earlier studies tended to concentrate on a limited number of specific prompt 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21477;&#27861;&#30340;&#26426;&#22120;&#32763;&#35793;&#19978;&#19979;&#25991;&#20363;&#21477;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#20381;&#23384;&#26641;&#20043;&#38388;&#30340;&#21477;&#27861;&#30456;&#20284;&#24615;&#65292;&#32467;&#21512;&#35789;&#32423;&#21644;&#21477;&#27861;&#27700;&#24179;&#26631;&#20934;&#36873;&#25321;&#20363;&#21477;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35821;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#21319;&#26426;&#22120;&#32763;&#35793;&#19978;&#19979;&#25991;&#23398;&#20064;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.19285</link><description>&lt;p&gt;
&#36229;&#36234;&#35789;&#35821;&#21305;&#37197;&#65306;&#21477;&#27861;&#25913;&#21892;&#19978;&#19979;&#25991;&#20363;&#21477;&#36873;&#25321;&#20197;&#25552;&#39640;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
Going Beyond Word Matching: Syntax Improves In-context Example Selection for Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21477;&#27861;&#30340;&#26426;&#22120;&#32763;&#35793;&#19978;&#19979;&#25991;&#20363;&#21477;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#20381;&#23384;&#26641;&#20043;&#38388;&#30340;&#21477;&#27861;&#30456;&#20284;&#24615;&#65292;&#32467;&#21512;&#35789;&#32423;&#21644;&#21477;&#27861;&#27700;&#24179;&#26631;&#20934;&#36873;&#25321;&#20363;&#21477;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35821;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#21319;&#26426;&#22120;&#32763;&#35793;&#19978;&#19979;&#25991;&#23398;&#20064;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19285v1 &#20844;&#21578;&#31867;&#22411;: &#26032;&#30340; &#25688;&#35201;: &#22312;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26102;&#20195;&#65292;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#25552;&#31034;&#31574;&#30053;&#65292;&#20854;&#20013;&#23637;&#31034;&#20102;&#19968;&#20123;&#31034;&#20363;&#20197;&#21796;&#36215;LLMs&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#30340;&#33021;&#21147;&#12290;&#22914;&#20309;&#36873;&#25321;&#20449;&#24687;&#37327;&#22823;&#30340;&#20363;&#21477;&#20173;&#28982;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#20808;&#21069;&#20851;&#20110;&#26426;&#22120;&#32763;&#35793;&#65288;MT&#65289;&#30340;&#19978;&#19979;&#25991;&#20363;&#21477;&#36873;&#25321;&#30340;&#20316;&#21697;&#20391;&#37325;&#20110;&#34920;&#38754;&#30340;&#35789;&#32423;&#29305;&#24449;&#65292;&#32780;&#24573;&#30053;&#20102;&#28145;&#23618;&#27425;&#30340;&#21477;&#27861;&#23618;&#27425;&#30693;&#35782;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#27861;&#30340;&#26426;&#22120;&#32763;&#35793;&#19978;&#19979;&#25991;&#20363;&#21477;&#36873;&#25321;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#39033;&#24335;&#36317;&#31163;&#35745;&#31639;&#20381;&#36182;&#26641;&#20043;&#38388;&#30340;&#21477;&#27861;&#30456;&#20284;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#31574;&#30053;&#65292;&#23558;&#36890;&#36807;&#35789;&#32423;&#21644;&#21477;&#27861;&#27700;&#24179;&#26631;&#20934;&#36873;&#25321;&#30340;&#20363;&#21477;&#36827;&#34892;&#32452;&#21512;&#12290;&#23545;&#33521;&#35821;&#21644;6&#31181;&#24120;&#35265;&#35821;&#35328;&#20043;&#38388;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35821;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#21319;MT&#30340;ICL&#65292;&#33719;&#24471;&#20102;&#22312;12&#20010;&#32763;&#35793;&#26041;&#21521;&#20013;11&#20010;&#26041;&#21521;&#19978;&#26368;&#39640;&#30340;COMET&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19285v1 Announce Type: new  Abstract: In-context learning (ICL) is the trending prompting strategy in the era of large language models (LLMs), where a few examples are demonstrated to evoke LLMs' power for a given task. How to select informative examples remains an open issue. Previous works on in-context example selection for machine translation (MT) focus on superficial word-level features while ignoring deep syntax-level knowledge. In this paper, we propose a syntax-based in-context example selection method for MT, by computing the syntactic similarity between dependency trees using Polynomial Distance. In addition, we propose an ensemble strategy combining examples selected by both word-level and syntax-level criteria. Experimental results between English and 6 common languages indicate that syntax can effectively enhancing ICL for MT, obtaining the highest COMET scores on 11 out of 12 translation directions.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23450;&#20041;&#23454;&#20307;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#35299;&#20915;&#23454;&#20307;&#21305;&#37197;&#20013;&#30340;&#27495;&#20041;&#38382;&#39064;</title><link>https://arxiv.org/abs/2403.17344</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20851;&#31995;&#21457;&#29616;&#30340;&#23454;&#20307;&#21305;&#37197;&#28040;&#27495;
&lt;/p&gt;
&lt;p&gt;
Disambiguate Entity Matching through Relation Discovery with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17344
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23450;&#20041;&#23454;&#20307;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#35299;&#20915;&#23454;&#20307;&#21305;&#37197;&#20013;&#30340;&#27495;&#20041;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20307;&#21305;&#37197;&#26159;&#25968;&#25454;&#38598;&#25104;&#21644;&#28165;&#27927;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#23545;&#20110;&#27169;&#31946;&#36830;&#25509;&#21644;&#25968;&#25454;&#37325;&#22797;&#28040;&#38500;&#31561;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#26041;&#27861;&#38598;&#20013;&#22312;&#20811;&#26381;&#27169;&#31946;&#26415;&#35821;&#34920;&#31034;&#65292;&#20363;&#22914;&#32534;&#36753;&#36317;&#31163;&#12289;Jaccard&#30456;&#20284;&#24615;&#65292;&#20197;&#21450;&#26368;&#36817;&#30340;&#23884;&#20837;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21253;&#25324;&#26469;&#33258;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22914;GPT&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#23454;&#20307;&#21305;&#37197;&#20013;&#30340;&#26680;&#24515;&#25361;&#25112;&#36229;&#36234;&#20102;&#26415;&#35821;&#27169;&#31946;&#24615;&#65292;&#32780;&#26159;&#22312;&#23450;&#20041;&#20309;&#20026;&#8220;&#21305;&#37197;&#8221;&#26102;&#30340;&#27495;&#20041;&#65292;&#29305;&#21035;&#26159;&#22312;&#19982;&#22806;&#37096;&#25968;&#25454;&#24211;&#38598;&#25104;&#26102;&#12290;&#36825;&#31181;&#27495;&#20041;&#26159;&#30001;&#20110;&#23454;&#20307;&#20043;&#38388;&#22312;&#32454;&#33410;&#21644;&#31890;&#24230;&#26041;&#38754;&#23384;&#22312;&#24046;&#24322;&#24341;&#36215;&#30340;&#65292;&#36825;&#20351;&#24471;&#30830;&#20999;&#21305;&#37197;&#21464;&#24471;&#22797;&#26434;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#28966;&#28857;&#20174;&#32431;&#31929;&#35782;&#21035;&#35821;&#20041;&#30456;&#20284;&#24615;&#36716;&#21464;&#20026;&#29702;&#35299;&#21644;&#23450;&#20041;&#23454;&#20307;&#20043;&#38388;&#30340;&#8220;&#20851;&#31995;&#8221;&#20316;&#20026;&#35299;&#20915;&#21305;&#37197;&#20013;&#30340;&#27495;&#20041;&#33267;&#20851;&#37325;&#35201;&#12290;&#36890;&#36807;&#39044;&#23450;&#20041;&#19968;&#32452;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#20851;&#31995;&#65292;&#21487;&#24110;&#21161;&#35299;&#20915;&#21305;&#37197;&#20013;&#30340;&#27495;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17344v1 Announce Type: cross  Abstract: Entity matching is a critical challenge in data integration and cleaning, central to tasks like fuzzy joins and deduplication. Traditional approaches have focused on overcoming fuzzy term representations through methods such as edit distance, Jaccard similarity, and more recently, embeddings and deep neural networks, including advancements from large language models (LLMs) like GPT. However, the core challenge in entity matching extends beyond term fuzziness to the ambiguity in defining what constitutes a "match," especially when integrating with external databases. This ambiguity arises due to varying levels of detail and granularity among entities, complicating exact matches. We propose a novel approach that shifts focus from purely identifying semantic similarities to understanding and defining the "relations" between entities as crucial for resolving ambiguities in matching. By predefining a set of relations relevant to the task at
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#65292;LLM&#23884;&#20837;&#33021;&#22815;&#25429;&#25417;&#32467;&#26500;&#21270;&#35821;&#35328;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;BERT&#22312;&#24615;&#33021;&#19978;&#39046;&#20808;&#20110;&#36731;&#37327;&#32423;&#36873;&#39033;&#65292;&#22686;&#21152;&#23884;&#20837;&#32500;&#24230;&#21644;&#25688;&#35201;&#25216;&#26415;&#24182;&#19981;&#19968;&#33268;&#22320;&#25552;&#39640;&#32858;&#31867;&#25928;&#29575;</title><link>https://arxiv.org/abs/2403.15112</link><description>&lt;p&gt;
&#20351;&#29992;LLM&#23884;&#20837;&#36827;&#34892;&#25991;&#26412;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Text clustering with LLM embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.15112
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;LLM&#23884;&#20837;&#33021;&#22815;&#25429;&#25417;&#32467;&#26500;&#21270;&#35821;&#35328;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;BERT&#22312;&#24615;&#33021;&#19978;&#39046;&#20808;&#20110;&#36731;&#37327;&#32423;&#36873;&#39033;&#65292;&#22686;&#21152;&#23884;&#20837;&#32500;&#24230;&#21644;&#25688;&#35201;&#25216;&#26415;&#24182;&#19981;&#19968;&#33268;&#22320;&#25552;&#39640;&#32858;&#31867;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#26412;&#32858;&#31867;&#26159;&#32452;&#32455;&#19981;&#26029;&#22686;&#38271;&#30340;&#25968;&#23383;&#20869;&#23481;&#30340;&#37325;&#35201;&#26041;&#27861;&#65292;&#26377;&#21161;&#20110;&#32467;&#26500;&#21270;&#21644;&#21457;&#29616;&#26410;&#20998;&#31867;&#25968;&#25454;&#20013;&#30340;&#38544;&#34255;&#27169;&#24335;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#19981;&#21516;&#25991;&#26412;&#23884;&#20837;&#65288;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;LLMs&#20013;&#20351;&#29992;&#30340;&#65289;&#21644;&#32858;&#31867;&#31639;&#27861;&#22914;&#20309;&#24433;&#21709;&#25991;&#26412;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#26041;&#24335;&#12290;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#20197;&#35780;&#20272;&#23884;&#20837;&#26159;&#22914;&#20309;&#24433;&#21709;&#32858;&#31867;&#32467;&#26524;&#30340;&#65292;&#20197;&#21450;&#36890;&#36807;&#25688;&#35201;&#36827;&#34892;&#38477;&#32500;&#21644;&#23884;&#20837;&#22823;&#23567;&#35843;&#25972;&#30340;&#20316;&#29992;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;LLM&#23884;&#20837;&#22312;&#25429;&#33719;&#32467;&#26500;&#21270;&#35821;&#35328;&#30340;&#32454;&#24494;&#24046;&#21035;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#32780;BERT&#22312;&#24615;&#33021;&#19978;&#39046;&#20808;&#20110;&#36731;&#37327;&#32423;&#36873;&#39033;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#22686;&#21152;&#23884;&#20837;&#32500;&#24230;&#21644;&#25688;&#35201;&#25216;&#26415;&#24182;&#19981;&#19968;&#33268;&#22320;&#25552;&#39640;&#32858;&#31867;&#25928;&#29575;&#65292;&#36825;&#34920;&#26126;&#36825;&#20123;&#31574;&#30053;&#38656;&#35201;&#20180;&#32454;&#20998;&#26512;&#25165;&#33021;&#22312;&#23454;&#38469;&#27169;&#22411;&#20013;&#20351;&#29992;&#12290;&#36825;&#20123;&#32467;&#26524;&#31361;&#20986;&#20102;&#19968;&#31181;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.15112v1 Announce Type: cross  Abstract: Text clustering is an important approach for organising the growing amount of digital content, helping to structure and find hidden patterns in uncategorised data. In this research, we investigated how different textual embeddings - particularly those used in large language models (LLMs) - and clustering algorithms affect how text datasets are clustered. A series of experiments were conducted to assess how embeddings influence clustering results, the role played by dimensionality reduction through summarisation, and embedding size adjustment. Results reveal that LLM embeddings excel at capturing the nuances of structured language, while BERT leads the lightweight options in performance. In addition, we find that increasing embedding dimensionality and summarisation techniques do not uniformly improve clustering efficiency, suggesting that these strategies require careful analysis to use in real-life models. These results highlight a co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#20135;&#29983;&#24187;&#35273;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#35843;&#25972;&#24494;&#35843;&#31034;&#20363;&#30340;&#30417;&#30563;&#26469;&#25511;&#21046;&#20854;&#23545;&#19981;&#29087;&#24713;&#36755;&#20837;&#30340;&#39044;&#27979;&#12290;&#20316;&#32773;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;RL&#30340;&#26041;&#27861;&#65292;&#26356;&#21487;&#38752;&#22320;&#20943;&#36731;&#20102;&#38271;&#31687;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#24187;&#35273;&#12290;</title><link>https://arxiv.org/abs/2403.05612</link><description>&lt;p&gt;
&#19981;&#29087;&#24713;&#30340;&#24494;&#35843;&#31034;&#20363;&#25511;&#21046;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#20135;&#29983;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Unfamiliar Finetuning Examples Control How Language Models Hallucinate
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#20135;&#29983;&#24187;&#35273;&#65292;&#24182;&#25552;&#20986;&#36890;&#36807;&#35843;&#25972;&#24494;&#35843;&#31034;&#20363;&#30340;&#30417;&#30563;&#26469;&#25511;&#21046;&#20854;&#23545;&#19981;&#29087;&#24713;&#36755;&#20837;&#30340;&#39044;&#27979;&#12290;&#20316;&#32773;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;RL&#30340;&#26041;&#27861;&#65292;&#26356;&#21487;&#38752;&#22320;&#20943;&#36731;&#20102;&#38271;&#31687;&#29983;&#25104;&#20219;&#21153;&#20013;&#30340;&#24187;&#35273;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20542;&#21521;&#20110;&#29983;&#25104;&#21548;&#36215;&#26469;&#20196;&#20154;&#20449;&#26381;&#20294;&#20107;&#23454;&#19981;&#27491;&#30830;&#30340;&#21709;&#24212;&#65292;&#29305;&#21035;&#26159;&#24403;&#22312;&#19981;&#29087;&#24713;&#30340;&#27010;&#24565;&#19978;&#36827;&#34892;&#26597;&#35810;&#26102;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#35843;&#25972;&#21518;&#30340;LLMs&#22914;&#20309;&#20135;&#29983;&#24187;&#35273;&#30340;&#22522;&#26412;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#27169;&#24335;&#65306;&#38543;&#30528;&#36755;&#20837;&#21464;&#24471;&#26356;&#19981;&#29087;&#24713;&#65292;LLMs&#30340;&#36755;&#20986;&#20542;&#21521;&#20110;&#40664;&#35748;&#20026;"&#21547;&#31946;&#20854;&#35789;"&#30340;&#39044;&#27979;&#65292;&#20854;&#24418;&#24335;&#21463;&#24494;&#35843;&#25968;&#25454;&#20013;&#19981;&#29087;&#24713;&#31034;&#20363;&#30417;&#30563;&#26041;&#24335;&#30340;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#31574;&#30053;&#24615;&#22320;&#20462;&#25913;&#36825;&#20123;&#31034;&#20363;&#30340;&#30417;&#30563;&#65292;&#25105;&#20204;&#21487;&#20197;&#25511;&#21046;LLM&#23545;&#19981;&#29087;&#24713;&#36755;&#20837;&#30340;&#39044;&#27979;&#65288;&#20363;&#22914;&#65292;&#25945;&#20250;&#23427;&#20204;&#35828;&#8220;&#25105;&#19981;&#30693;&#36947;&#8221;&#65289;&#12290;&#22522;&#20110;&#36825;&#20123;&#21407;&#21017;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;RL&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#22870;&#21169;&#27169;&#22411;&#24187;&#35273;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#26356;&#21487;&#38752;&#22320;&#20943;&#36731;&#38271;&#31687;&#29983;&#25104;&#20219;&#21153;&#30340;&#24187;&#35273;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;MMLU&#19978;&#30340;&#22810;&#36873;QA&#20013;&#36827;&#34892;&#19968;&#31995;&#21015;&#21463;&#25511;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05612v1 Announce Type: cross  Abstract: Large language models (LLMs) have a tendency to generate plausible-sounding yet factually incorrect responses, especially when queried on unfamiliar concepts. In this work, we explore the underlying mechanisms that govern how finetuned LLMs hallucinate. Our investigation reveals an interesting pattern: as inputs become more unfamiliar, LLM outputs tend to default towards a ``hedged'' prediction, whose form is determined by how the unfamiliar examples in the finetuning data are supervised. Thus, by strategically modifying these examples' supervision, we can control LLM predictions for unfamiliar inputs (e.g., teach them to say ``I don't know''). Based on these principles, we develop an RL approach that more reliably mitigates hallucinations for long-form generation tasks, by tackling the challenges presented by reward model hallucinations. We validate our findings with a series of controlled experiments in multiple-choice QA on MMLU, as
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25299;&#23637;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#27602;&#24615;&#32531;&#35299;&#30340;&#33539;&#22260;&#65292;&#28085;&#30422;&#20102;&#22810;&#35821;&#35328;&#29615;&#22659;&#65292;&#36890;&#36807;&#32763;&#35793;&#25968;&#25454;&#35780;&#20272;&#21644;&#22686;&#24378;&#32531;&#35299;&#25216;&#26415;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#32531;&#35299;&#26041;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#27169;&#22411;&#22823;&#23567;&#21644;&#25968;&#25454;&#37327;&#23545;&#32531;&#35299;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2403.03893</link><description>&lt;p&gt;
&#20174;&#21333;&#19968;&#21040;&#22810;&#26679;&#65306;&#25299;&#23637;&#35821;&#35328;&#27169;&#22411;&#20013;&#27602;&#24615;&#32531;&#35299;&#30340;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03893
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25299;&#23637;&#20102;&#35821;&#35328;&#27169;&#22411;&#20013;&#27602;&#24615;&#32531;&#35299;&#30340;&#33539;&#22260;&#65292;&#28085;&#30422;&#20102;&#22810;&#35821;&#35328;&#29615;&#22659;&#65292;&#36890;&#36807;&#32763;&#35793;&#25968;&#25454;&#35780;&#20272;&#21644;&#22686;&#24378;&#32531;&#35299;&#25216;&#26415;&#65292;&#27604;&#36739;&#20102;&#19981;&#21516;&#32531;&#35299;&#26041;&#27861;&#65292;&#24182;&#25506;&#35752;&#20102;&#27169;&#22411;&#22823;&#23567;&#21644;&#25968;&#25454;&#37327;&#23545;&#32531;&#35299;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36804;&#20170;&#20026;&#27490;&#65292;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#27602;&#24615;&#32531;&#35299;&#20960;&#20046;&#23436;&#20840;&#38598;&#20013;&#22312;&#21333;&#35821;&#35328;&#29615;&#22659;&#20013;&#12290;&#38543;&#30528;&#35821;&#35328;&#27169;&#22411;&#25317;&#25265;&#22810;&#35821;&#35328;&#33021;&#21147;&#65292;&#25105;&#20204;&#30340;&#23433;&#20840;&#25514;&#26045;&#36319;&#19978;&#27493;&#20240;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#24847;&#35782;&#21040;&#20102;&#36825;&#19968;&#30740;&#31350;&#31354;&#30333;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#20256;&#32479;&#30340;&#27602;&#24615;&#32531;&#35299;&#33539;&#22260;&#25193;&#23637;&#21040;&#24212;&#23545;&#22810;&#35821;&#35328;&#24102;&#26469;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#32570;&#20047;&#36328;&#35821;&#35328;&#30340;&#36275;&#22815;&#26631;&#27880;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#32763;&#35793;&#25968;&#25454;&#26469;&#35780;&#20272;&#21644;&#22686;&#24378;&#25105;&#20204;&#30340;&#32531;&#35299;&#25216;&#26415;&#12290;&#25105;&#20204;&#36824;&#22312;&#38745;&#24577;&#21644;&#25345;&#32493;&#27602;&#24615;&#32531;&#35299;&#22330;&#26223;&#19979;&#27604;&#36739;&#20102;&#24494;&#35843;&#32531;&#35299;&#26041;&#27861;&#21644;&#26816;&#32034;&#22686;&#24378;&#25216;&#26415;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26816;&#39564;&#32763;&#35793;&#36136;&#37327;&#21644;&#36328;&#35821;&#35328;&#36716;&#31227;&#23545;&#27602;&#24615;&#32531;&#35299;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#27169;&#22411;&#22823;&#23567;&#21644;&#25968;&#25454;&#25968;&#37327;&#22914;&#20309;&#24433;&#21709;&#36825;&#20123;&#32531;&#35299;&#24037;&#20316;&#30340;&#25104;&#21151;&#12290;&#28085;&#30422;&#20102;&#20061;&#31181;&#35821;&#35328;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20195;&#34920;&#20102;&#24191;&#27867;&#30340;&#35821;&#35328;&#23398;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03893v1 Announce Type: cross  Abstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it's crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic f
&lt;/p&gt;</description></item><item><title>WebCiteS&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#24341;&#25991;&#30340;&#26597;&#35810;&#28966;&#28857;&#25688;&#35201;&#20219;&#21153;&#65292;&#24182;&#21457;&#24067;&#20102;&#21253;&#21547;7k&#20154;&#24037;&#27880;&#37322;&#25688;&#35201;&#21450;&#24341;&#25991;&#30340;&#20013;&#25991;&#25968;&#25454;&#38598;&#65292;&#20197;&#22788;&#29702;&#24402;&#22240;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01774</link><description>&lt;p&gt;
WebCiteS: &#22312;&#20013;&#22269;&#32593;&#39029;&#25628;&#32034;&#32467;&#26524;&#19978;&#36827;&#34892;&#24102;&#24341;&#25991;&#30340;&#26597;&#35810;&#28966;&#28857;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01774
&lt;/p&gt;
&lt;p&gt;
WebCiteS&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#24341;&#25991;&#30340;&#26597;&#35810;&#28966;&#28857;&#25688;&#35201;&#20219;&#21153;&#65292;&#24182;&#21457;&#24067;&#20102;&#21253;&#21547;7k&#20154;&#24037;&#27880;&#37322;&#25688;&#35201;&#21450;&#24341;&#25991;&#30340;&#20013;&#25991;&#25968;&#25454;&#38598;&#65292;&#20197;&#22788;&#29702;&#24402;&#22240;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01774v1 &#22768;&#26126;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#30340;&#24402;&#22240;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#12290;&#19968;&#20010;&#21487;&#34892;&#30340;&#26041;&#27861;&#26159;&#20351;LLMs&#33021;&#22815;&#24341;&#29992;&#25903;&#25345;&#20854;&#29983;&#25104;&#30340;&#22806;&#37096;&#26469;&#28304;&#12290;&#28982;&#32780;&#65292;&#35813;&#39046;&#22495;&#29616;&#26377;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#26041;&#27861;&#20173;&#23384;&#22312;&#26126;&#26174;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#24102;&#24341;&#25991;&#30340;&#26597;&#35810;&#28966;&#28857;&#25688;&#35201;&#65288;AQFS&#65289;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;WebCiteS&#65292;&#36825;&#26159;&#19968;&#20010;&#21253;&#21547;7k&#20154;&#24037;&#27880;&#37322;&#25688;&#35201;&#21450;&#24341;&#25991;&#30340;&#20013;&#25991;&#25968;&#25454;&#38598;&#12290;WebCiteS&#28304;&#33258;&#29616;&#23454;&#29992;&#25143;&#26597;&#35810;&#21644;&#32593;&#39029;&#25628;&#32034;&#32467;&#26524;&#65292;&#20026;&#27169;&#22411;&#35757;&#32451;&#21644;&#35780;&#20272;&#25552;&#20379;&#20102;&#23453;&#36149;&#36164;&#28304;&#12290;&#20043;&#21069;&#20851;&#20110;&#24402;&#22240;&#35780;&#20272;&#30340;&#24037;&#20316;&#26410;&#33021;&#21306;&#20998;&#22522;&#20110;&#20107;&#23454;&#38169;&#35823;&#21644;&#24341;&#25991;&#38169;&#35823;&#12290;&#20182;&#20204;&#20134;&#26410;&#33021;&#33258;&#21160;&#39564;&#35777;&#37027;&#20123;&#37096;&#20998;&#20381;&#36182;&#22810;&#20010;&#26469;&#28304;&#30340;&#21477;&#23376;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#35814;&#32454;&#30340;&#24230;&#37327;&#26631;&#20934;&#24182;&#20351;&#33258;&#21160;&#35780;&#20272;&#22120;&#33021;&#22815;&#23558;&#21477;&#23376;&#20998;&#35299;&#20026;&#23376;&#20027;&#24352;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01774v1 Announce Type: new  Abstract: Enhancing the attribution in large language models (LLMs) is a crucial task. One feasible approach is to enable LLMs to cite external sources that support their generations. However, existing datasets and evaluation methods in this domain still exhibit notable limitations. In this work, we formulate the task of attributed query-focused summarization (AQFS) and present WebCiteS, a Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS derives from real-world user queries and web search results, offering a valuable resource for model training and evaluation. Prior works in attribution evaluation do not differentiate between groundedness errors and citation errors. They also fall short in automatically verifying sentences that draw partial support from multiple sources. We tackle these issues by developing detailed metrics and enabling the automatic evaluator to decompose the sentences into sub-claims for fine-grain
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Dual Chunk Attention (DCA)&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;Llama2 70B&#22312;&#19981;&#38656;&#35201;&#25345;&#32493;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#25903;&#25345;&#36229;&#36807;100k&#20196;&#29260;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#65292;&#33021;&#22815;&#22312;&#38271;&#19978;&#19979;&#25991;&#20219;&#21153;&#20013;&#21462;&#24471;&#19982;&#24494;&#35843;&#27169;&#22411;&#30456;&#23218;&#32654;&#29978;&#33267;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.17463</link><description>&lt;p&gt;
&#26080;&#39035;&#35757;&#32451;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#38271;&#19978;&#19979;&#25991;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Training-Free Long-Context Scaling of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17463
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Dual Chunk Attention (DCA)&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;Llama2 70B&#22312;&#19981;&#38656;&#35201;&#25345;&#32493;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#25903;&#25345;&#36229;&#36807;100k&#20196;&#29260;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#65292;&#33021;&#22815;&#22312;&#38271;&#19978;&#19979;&#25991;&#20219;&#21153;&#20013;&#21462;&#24471;&#19982;&#24494;&#35843;&#27169;&#22411;&#30456;&#23218;&#32654;&#29978;&#33267;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22788;&#29702;&#21644;&#29983;&#25104;&#36830;&#36143;&#25991;&#26412;&#26102;&#65292;&#24403;&#36755;&#20837;&#20196;&#29260;&#25968;&#37327;&#36229;&#36807;&#23427;&#20204;&#30340;&#39044;&#35757;&#32451;&#38271;&#24230;&#26102;&#65292;&#20854;&#33021;&#21147;&#20250;&#26126;&#26174;&#20943;&#24369;&#12290;&#37492;&#20110;&#20351;&#29992;&#26356;&#38271;&#24207;&#21015;&#36827;&#34892;&#22823;&#35268;&#27169;&#27169;&#22411;&#24494;&#35843;&#30340;&#26114;&#36149;&#24320;&#38144;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Dual Chunk Attention&#65288;DCA&#65289;&#65292;&#23427;&#20351;Llama2 70B&#33021;&#22815;&#25903;&#25345;&#36229;&#36807;100k&#20196;&#29260;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#65292;&#32780;&#26080;&#38656;&#25345;&#32493;&#35757;&#32451;&#12290;&#36890;&#36807;&#23558;&#38271;&#24207;&#21015;&#30340;&#27880;&#24847;&#21147;&#35745;&#31639;&#20998;&#35299;&#20026;&#22522;&#20110;&#22359;&#30340;&#27169;&#22359;&#65292;DCA&#25104;&#21151;&#25429;&#33719;&#20102;&#30456;&#21516;&#22359;&#20869;&#65288;Intra-Chunk&#65289;&#21644;&#19981;&#21516;&#22359;&#20043;&#38388;&#65288;Inter-Chunk&#65289;&#20196;&#29260;&#30340;&#30456;&#23545;&#20301;&#32622;&#20449;&#24687;&#65292;&#24182;&#33021;&#19982;Flash Attention&#26080;&#32541;&#38598;&#25104;&#12290;&#38500;&#20102;&#20854;&#24778;&#20154;&#30340;&#22806;&#25512;&#33021;&#21147;&#22806;&#65292;DCA&#22312;&#23454;&#38469;&#38271;&#19978;&#19979;&#25991;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#19982;&#25110;&#29978;&#33267;&#20248;&#20110;&#24494;&#35843;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#19982;&#19987;&#26377;&#27169;&#22411;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26080;&#39035;&#35757;&#32451;&#30340;70B&#27169;&#22411;&#21462;&#24471;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17463v1 Announce Type: new  Abstract: The ability of Large Language Models (LLMs) to process and generate coherent text is markedly weakened when the number of input tokens exceeds their pretraining length. Given the expensive overhead of finetuning large-scale models with longer sequences, we propose Dual Chunk Attention (DCA), which enables Llama2 70B to support context windows of more than 100k tokens without continual training. By decomposing the attention computation for long sequences into chunk-based modules, DCA manages to effectively capture the relative positional information of tokens within the same chunk (Intra-Chunk) and across distinct chunks (Inter-Chunk), as well as integrates seamlessly with Flash Attention. In addition to its impressive extrapolation capability, DCA achieves performance on practical long-context tasks that is comparable to or even better than that of finetuned models. When compared with proprietary models, our training-free 70B model attai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20013;&#23384;&#22312;&#30340;&#22810;&#27169;&#24577;&#24187;&#35273;&#38382;&#39064;&#65292;&#21457;&#29616;&#36890;&#36807;&#27169;&#22411;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#20316;&#20986;&#36866;&#24403;&#30340;EOS&#20915;&#31574;&#65292;&#21487;&#20197;&#20943;&#23569;&#25345;&#32493;&#36755;&#20986;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.14545</link><description>&lt;p&gt;
&#20943;&#23569;&#26159;&#26377;&#30410;&#30340;&#65306;&#20174;EOS&#20915;&#31574;&#35282;&#24230;&#32531;&#35299;&#22810;&#27169;&#24577;&#24187;&#35273;
&lt;/p&gt;
&lt;p&gt;
Less is More: Mitigating Multimodal Hallucination from an EOS Decision Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20013;&#23384;&#22312;&#30340;&#22810;&#27169;&#24577;&#24187;&#35273;&#38382;&#39064;&#65292;&#21457;&#29616;&#36890;&#36807;&#27169;&#22411;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#20316;&#20986;&#36866;&#24403;&#30340;EOS&#20915;&#31574;&#65292;&#21487;&#20197;&#20943;&#23569;&#25345;&#32493;&#36755;&#20986;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#32531;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMMs&#65289;&#32463;&#24120;&#36973;&#21463;&#22810;&#27169;&#24577;&#24187;&#35273;&#65292;&#21363;&#23427;&#20204;&#21487;&#33021;&#21019;&#36896;&#20986;&#22312;&#35270;&#35273;&#36755;&#20837;&#20013;&#24182;&#19981;&#23384;&#22312;&#30340;&#20869;&#23481;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26032;&#35282;&#24230;&#65306;&#36807;&#20110;&#35814;&#32454;&#30340;&#35757;&#32451;&#25968;&#25454;&#22952;&#30861;&#20102;&#27169;&#22411;&#21450;&#26102;&#32456;&#27490;&#29983;&#25104;&#65292;&#23548;&#33268;&#36229;&#20986;&#35270;&#35273;&#24863;&#30693;&#38480;&#21046;&#30340;&#25345;&#32493;&#36755;&#20986;&#12290;&#36890;&#36807;&#30740;&#31350;&#27169;&#22411;&#22914;&#20309;&#36890;&#36807;EOS&#65288;&#29305;&#27530;&#30340;&#21477;&#23376;&#32467;&#23614;&#26631;&#35760;&#65289;&#26469;&#20915;&#23450;&#32456;&#27490;&#29983;&#25104;&#65292;&#25105;&#20204;&#21457;&#29616;&#27169;&#22411;&#36890;&#36807;&#23558;&#29983;&#25104;&#30340;&#25991;&#26412;&#19982;&#22270;&#20687;&#36827;&#34892;&#27604;&#36739;&#26469;&#35780;&#20272;&#25972;&#20010;&#24207;&#21015;&#30340;&#23436;&#25972;&#24615;&#12290;&#36825;&#19968;&#35266;&#23519;&#34920;&#26126;&#65292;&#27169;&#22411;&#20855;&#26377;&#22522;&#20110;&#20854;&#35270;&#35273;&#24863;&#30693;&#36827;&#34892;&#36866;&#24403;EOS&#20915;&#31574;&#30340;&#28508;&#21147;&#65292;&#20197;&#36991;&#20813;&#36807;&#38271;&#30340;&#36755;&#20986;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#31181;&#28508;&#21147;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#20004;&#31181;&#32531;&#35299;&#22810;&#27169;&#24577;&#24187;&#35273;&#30340;&#26041;&#27861;&#65306;&#36890;&#36807;&#23398;&#20064;&#24120;&#35268;&#25351;&#31034;&#23454;&#29616;&#27169;&#22411;&#20943;&#23569;&#24187;&#35273;&#30340;&#35757;&#32451;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14545v1 Announce Type: new  Abstract: Large Multimodal Models (LMMs) often suffer from multimodal hallucinations, wherein they may create content that is not present in the visual inputs. In this paper, we explore a new angle of this issue: overly detailed training data hinders the model's ability to timely terminate generation, leading to continued outputs beyond visual perception limits. By investigating how the model decides to terminate generation with EOS, the special end-of-sentence token, we find that the model assesses the completeness of the entire sequence by comparing the generated text with the image. This observation suggests that the model possesses an inherent potential of making proper EOS decisions based on its visual perception to avoid overly lengthy outputs. To take advantage of such potential, we explore two methods to mitigate multimodal hallucinations: a training objective that enables the model to reduce hallucinations by learning from regular instruc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20026;&#21307;&#23398;&#39046;&#22495;&#26500;&#24314;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#19977;&#20010;&#20851;&#38190;&#36129;&#29486;:&#26500;&#24314;&#20102;&#26032;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#35821;&#26009;&#24211;MMedC&#65292;&#25552;&#20986;&#20102;&#22810;&#35821;&#35328;&#21307;&#23398;&#22810;&#36873;&#38382;&#31572;&#22522;&#20934;MMedBench&#65292;&#24182;&#19988;&#36890;&#36807;&#22312;MMedC&#19978;&#36827;&#19968;&#27493;&#35757;&#32451;&#33719;&#24471;&#20102;&#24615;&#33021;&#20248;&#36234;&#30340;MMedLM 2&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2402.13963</link><description>&lt;p&gt;
&#20026;&#21307;&#23398;&#26500;&#24314;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Towards Building Multilingual Language Model for Medicine
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20026;&#21307;&#23398;&#39046;&#22495;&#26500;&#24314;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#30340;&#19977;&#20010;&#20851;&#38190;&#36129;&#29486;:&#26500;&#24314;&#20102;&#26032;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#35821;&#26009;&#24211;MMedC&#65292;&#25552;&#20986;&#20102;&#22810;&#35821;&#35328;&#21307;&#23398;&#22810;&#36873;&#38382;&#31572;&#22522;&#20934;MMedBench&#65292;&#24182;&#19988;&#36890;&#36807;&#22312;MMedC&#19978;&#36827;&#19968;&#27493;&#35757;&#32451;&#33719;&#24471;&#20102;&#24615;&#33021;&#20248;&#36234;&#30340;MMedLM 2&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#38754;&#21521;&#21307;&#23398;&#30340;&#24320;&#28304;&#22810;&#35821;&#35328;&#35821;&#35328;&#27169;&#22411;&#65292;&#20351;&#24471;&#26356;&#24191;&#27867;&#30340;&#35821;&#35328;&#22810;&#26679;&#24615;&#21463;&#20247;&#21463;&#30410;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20027;&#35201;&#36129;&#29486;&#20307;&#29616;&#22312;&#20197;&#19979;&#20960;&#20010;&#26041;&#38754;:&#39318;&#20808;&#65292;&#38024;&#23545;&#22810;&#35821;&#35328;&#21307;&#23398;&#29305;&#23450;&#36866;&#24212;&#24615;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#35821;&#26009;&#24211;&#65292;&#21253;&#21547;&#22823;&#32422;25.5B&#20010;tokens&#65292;&#35206;&#30422;&#20102;6&#31181;&#20027;&#35201;&#35821;&#35328;&#65292;&#34987;&#31216;&#20026;MMedC&#65292;&#36825;&#20351;&#24471;&#29616;&#26377;&#36890;&#29992;LLM&#33021;&#22815;&#36827;&#34892;&#33258;&#22238;&#24402;&#35757;&#32451;&#12290;&#20854;&#27425;&#65292;&#20026;&#20102;&#30417;&#27979;&#21307;&#23398;&#39046;&#22495;&#22810;&#35821;&#35328;LLM&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#24102;&#26377;&#35299;&#37322;&#30340;&#22810;&#35821;&#35328;&#21307;&#23398;&#22810;&#36873;&#38382;&#31572;&#22522;&#20934;&#65292;&#31216;&#20026;MMedBench&#65307;&#31532;&#19977;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#19968;&#20123;&#27969;&#34892;&#30340;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#25105;&#20204;&#30340;&#22522;&#20934;&#19978;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#37027;&#20123;&#22312;MMedC&#19978;&#36827;&#19968;&#27493;&#36827;&#34892;&#33258;&#22238;&#24402;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#26368;&#32456;&#65292;&#25105;&#20204;&#30340;&#26368;&#32456;&#27169;&#22411;&#65292;&#21629;&#21517;&#20026;MMedLM 2&#65292;&#20165;&#26377;7B&#21442;&#25968;&#65292;&#21462;&#24471;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13963v1 Announce Type: new  Abstract: In this paper, we aim to develop an open-source, multilingual language model for medicine, that the benefits a wider, linguistically diverse audience from different regions. In general, we present the contribution from the following aspects: first, for multilingual medical-specific adaptation, we construct a new multilingual medical corpus, that contains approximately 25.5B tokens encompassing 6 main languages, termed as MMedC, that enables auto-regressive training for existing general LLMs. second, to monitor the development of multilingual LLMs in medicine, we propose a new multilingual medical multi-choice question-answering benchmark with rationale, termed as MMedBench; third, we have assessed a number of popular, opensource large language models (LLMs) on our benchmark, along with those further auto-regressive trained on MMedC, as a result, our final model, termed as MMedLM 2, with only 7B parameters, achieves superior performance c
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#30693;&#35782;&#36793;&#30028;&#30340;&#27010;&#24565;&#65292;&#20197;&#28085;&#30422;&#35821;&#35328;&#27169;&#22411;&#20869;&#30340;&#26080;&#25552;&#31034;&#21644;&#26377;&#25552;&#31034;&#25935;&#24863;&#24615;&#30693;&#35782;&#65292;&#36890;&#36807;&#36991;&#20813;&#25552;&#31034;&#25935;&#24863;&#24615;&#65292;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#26356;&#21487;&#38752;&#21644;&#31283;&#20581;&#12290;</title><link>https://arxiv.org/abs/2402.11493</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#36793;&#30028;&#22522;&#20934;&#65306;&#23545;&#27169;&#22411;&#35780;&#20272;&#30340;&#21478;&#19968;&#31181;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Knowledge Boundary for Large Language Model: A Different Perspective on Model Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11493
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#30693;&#35782;&#36793;&#30028;&#30340;&#27010;&#24565;&#65292;&#20197;&#28085;&#30422;&#35821;&#35328;&#27169;&#22411;&#20869;&#30340;&#26080;&#25552;&#31034;&#21644;&#26377;&#25552;&#31034;&#25935;&#24863;&#24615;&#30693;&#35782;&#65292;&#36890;&#36807;&#36991;&#20813;&#25552;&#31034;&#25935;&#24863;&#24615;&#65292;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#26356;&#21487;&#38752;&#21644;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22312;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#21457;&#23637;&#20013;&#21462;&#24471;&#20102;&#23454;&#36136;&#24615;&#36827;&#23637;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#30340;&#30693;&#35782;&#33021;&#21147;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#35768;&#22810;&#22522;&#20110;&#38382;&#31572;&#23545;&#30340;&#22522;&#20934;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#20351;&#29992;&#22266;&#23450;&#38382;&#39064;&#25110;&#26377;&#38480;&#30340;&#37322;&#20041;&#20316;&#20026;&#26597;&#35810;&#26469;&#35780;&#20272;&#35821;&#35328;&#27169;&#22411;&#26159;&#19981;&#21487;&#38752;&#21644;&#20840;&#38754;&#30340;&#65292;&#22240;&#20026;&#35821;&#35328;&#27169;&#22411;&#23545;&#25552;&#31034;&#24456;&#25935;&#24863;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#30693;&#35782;&#36793;&#30028;&#30340;&#26032;&#27010;&#24565;&#65292;&#20197;&#21253;&#21547;&#35821;&#35328;&#27169;&#22411;&#20869;&#30340;&#26080;&#25552;&#31034;&#21644;&#26377;&#25552;&#31034;&#25935;&#24863;&#24615;&#30693;&#35782;&#12290;&#30693;&#35782;&#36793;&#30028;&#36991;&#20813;&#20102;&#35821;&#35328;&#27169;&#22411;&#35780;&#20272;&#20013;&#30340;&#25552;&#31034;&#25935;&#24863;&#24615;&#65292;&#20351;&#20854;&#26356;&#21487;&#38752;&#21644;&#31283;&#20581;&#12290;&#20026;&#20102;&#25506;&#32034;&#32473;&#23450;&#27169;&#22411;&#30340;&#30693;&#35782;&#36793;&#30028;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24102;&#26377;&#35821;&#20041;&#32422;&#26463;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#35782;&#21035;&#27599;&#20010;&#37096;&#20998;&#30340;&#26368;&#20339;&#25552;&#31034;&#30340;&#26032;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11493v1 Announce Type: new  Abstract: In recent years, substantial advancements have been made in the development of large language models, achieving remarkable performance across diverse tasks. To evaluate the knowledge ability of language models, previous studies have proposed lots of benchmarks based on question-answering pairs. We argue that it is not reliable and comprehensive to evaluate language models with a fixed question or limited paraphrases as the query, since language models are sensitive to prompt. Therefore, we introduce a novel concept named knowledge boundary to encompass both prompt-agnostic and prompt-sensitive knowledge within language models. Knowledge boundary avoids prompt sensitivity in language model evaluations, rendering them more dependable and robust. To explore the knowledge boundary for a given model, we propose projected gradient descent method with semantic constraints, a new algorithm designed to identify the optimal prompt for each piece o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;RiVEG&#65292;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#36830;&#25509;&#26725;&#26753;&#65292;&#23558;&#22810;&#27169;&#24577;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#37325;&#26032;&#26500;&#24314;&#20026;&#32852;&#21512;&#20219;&#21153;&#65292;&#35299;&#20915;&#20102;&#21629;&#21517;&#23454;&#20307;&#26080;&#27861;&#30830;&#23450;&#21644;&#25351;&#20195;&#34920;&#36798;&#19982;&#21629;&#21517;&#23454;&#20307;&#20043;&#38388;&#30340;&#21306;&#21035;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.09989</link><description>&lt;p&gt;
LLMs&#20316;&#20026;&#26725;&#26753;&#65306;&#37325;&#26032;&#26500;&#24314;&#22522;&#20110;&#22810;&#27169;&#24577;&#22270;&#20687;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
LLMs as Bridges: Reformulating Grounded Multimodal Named Entity Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;RiVEG&#65292;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#36830;&#25509;&#26725;&#26753;&#65292;&#23558;&#22810;&#27169;&#24577;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#37325;&#26032;&#26500;&#24314;&#20026;&#32852;&#21512;&#20219;&#21153;&#65292;&#35299;&#20915;&#20102;&#21629;&#21517;&#23454;&#20307;&#26080;&#27861;&#30830;&#23450;&#21644;&#25351;&#20195;&#34920;&#36798;&#19982;&#21629;&#21517;&#23454;&#20307;&#20043;&#38388;&#30340;&#21306;&#21035;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Grounded Multimodal Named Entity Recognition (GMNER) &#26159;&#19968;&#20010;&#26032;&#20852;&#30340;&#22810;&#27169;&#24577;&#20219;&#21153;&#65292;&#26088;&#22312;&#35782;&#21035;&#21629;&#21517;&#23454;&#20307;&#12289;&#23454;&#20307;&#31867;&#22411;&#21450;&#20854;&#23545;&#24212;&#30340;&#35270;&#35273;&#21306;&#22495;&#12290;GMNER&#20219;&#21153;&#20855;&#26377;&#20004;&#20010;&#25361;&#25112;&#24615;&#36136;&#65306;1&#65289;&#31038;&#20132;&#23186;&#20307;&#20013;&#22270;&#20687;&#21644;&#25991;&#26412;&#20043;&#38388;&#30340;&#24369;&#30456;&#20851;&#24615;&#23548;&#33268;&#22823;&#37096;&#20998;&#21629;&#21517;&#23454;&#20307;&#38590;&#20197;&#30830;&#23450;&#65307;2&#65289;&#24120;&#29992;&#20110;&#31867;&#20284;&#20219;&#21153;&#30340;&#31895;&#31890;&#24230;&#25351;&#20195;&#34920;&#36798;&#19982;&#32454;&#31890;&#24230;&#21629;&#21517;&#23454;&#20307;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#21306;&#21035;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;RiVEG&#65292;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#36830;&#25509;&#26725;&#26753;&#65292;&#23558;GMNER&#37325;&#26032;&#26500;&#24314;&#20026;&#32852;&#21512;MNER-VE-VG&#20219;&#21153;&#12290;&#36825;&#31181;&#37325;&#26032;&#26500;&#24314;&#24102;&#26469;&#20102;&#20004;&#20010;&#22909;&#22788;&#65306;1&#65289;&#20445;&#25345;&#20102;&#26368;&#20339;&#30340;MNER&#24615;&#33021;&#65292;&#28040;&#38500;&#20102;&#20351;&#29992;&#30446;&#26631;&#26816;&#27979;&#26041;&#27861;&#39044;&#25552;&#21462;&#21306;&#22495;&#29305;&#24449;&#30340;&#38656;&#27714;&#65292;&#33258;&#28982;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09989v1 Announce Type: cross  Abstract: Grounded Multimodal Named Entity Recognition (GMNER) is a nascent multimodal task that aims to identify named entities, entity types and their corresponding visual regions. GMNER task exhibits two challenging properties: 1) The weak correlation between image-text pairs in social media results in a significant portion of named entities being ungroundable. 2) There exists a distinction between coarse-grained referring expressions commonly used in similar tasks (e.g., phrase localization, referring expression comprehension) and fine-grained named entities. In this paper, we propose RiVEG, a unified framework that reformulates GMNER into a joint MNER-VE-VG task by leveraging large language models (LLMs) as a connecting bridge. This reformulation brings two benefits: 1) It maintains the optimal MNER performance and eliminates the need for employing object detection methods to pre-extract regional features, thereby naturally addressing two m
&lt;/p&gt;</description></item><item><title>SLEB&#26159;&#19968;&#31181;&#36890;&#36807;&#28040;&#38500;&#20887;&#20313;&#30340;Transformer&#22359;&#26469;&#20248;&#21270;LLM&#27969;&#31243;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#25104;&#21151;&#21152;&#36895;&#20102;LLM&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2402.09025</link><description>&lt;p&gt;
SLEB: &#36890;&#36807;&#20887;&#20313;&#39564;&#35777;&#21644;&#28040;&#38500;Transformer&#22359;&#20248;&#21270;LLM&#30340;&#27969;&#31243;
&lt;/p&gt;
&lt;p&gt;
SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09025
&lt;/p&gt;
&lt;p&gt;
SLEB&#26159;&#19968;&#31181;&#36890;&#36807;&#28040;&#38500;&#20887;&#20313;&#30340;Transformer&#22359;&#26469;&#20248;&#21270;LLM&#27969;&#31243;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#25104;&#21151;&#21152;&#36895;&#20102;LLM&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#35777;&#26126;&#20102;&#20854;&#39640;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#24222;&#22823;&#30340;&#21442;&#25968;&#25968;&#37327;&#32473;&#23454;&#38469;&#37096;&#32626;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#31934;&#31616;&#65292;&#19968;&#31181;&#26088;&#22312;&#20943;&#23567;LLM&#22823;&#23567;&#21644;&#22797;&#26434;&#24230;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#20174;&#32593;&#32476;&#20013;&#21024;&#38500;&#20887;&#20313;&#32452;&#20214;&#25552;&#20379;&#20102;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;&#23613;&#31649;&#31934;&#31616;&#26377;&#24076;&#26395;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#38590;&#20197;&#23454;&#29616;&#26174;&#33879;&#30340;&#31471;&#21040;&#31471;LLM&#25512;&#29702;&#21152;&#36895;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;SLEB&#65292;&#19968;&#31181;&#36890;&#36807;&#28040;&#38500;&#20887;&#20313;&#30340;Transformer&#22359;&#26469;&#20248;&#21270;LLM&#27969;&#31243;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#36873;&#25321;Transformer&#22359;&#20316;&#20026;&#31934;&#31616;&#30340;&#22522;&#26412;&#21333;&#20301;&#65292;&#22240;&#20026;LLM&#22312;&#30456;&#37051;&#22359;&#30340;&#36755;&#20986;&#20043;&#38388;&#20855;&#26377;&#22359;&#32423;&#21035;&#30340;&#20887;&#20313;&#21644;&#39640;&#30456;&#20284;&#24615;&#12290;&#36825;&#20010;&#36873;&#25321;&#20351;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#22686;&#24378;LLM&#30340;&#22788;&#29702;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;SLEB&#25104;&#21151;&#21152;&#36895;&#20102;LLM&#30340;&#25512;&#29702;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09025v1 Announce Type: new Abstract: Large language models (LLMs) have proven to be highly effective across various natural language processing tasks. However, their large number of parameters poses significant challenges for practical deployment. Pruning, a technique aimed at reducing the size and complexity of LLMs, offers a potential solution by removing redundant components from the network. Despite the promise of pruning, existing methods often struggle to achieve substantial end-to-end LLM inference speedup. In this paper, we introduce SLEB, a novel approach designed to streamline LLMs by eliminating redundant transformer blocks. We choose the transformer block as the fundamental unit for pruning, because LLMs exhibit block-level redundancy with high similarity between the outputs of neighboring blocks. This choice allows us to effectively enhance the processing speed of LLMs. Our experimental results demonstrate that SLEB successfully accelerates LLM inference without
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#20026;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19978;&#19979;&#25991;&#38271;&#24230;&#32780;&#35774;&#35745;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#24182;&#22238;&#39038;&#20102;&#21253;&#25324;&#26550;&#26500;&#20462;&#25913;&#22312;&#20869;&#30340;&#22810;&#31181;&#25216;&#26415;&#65292;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#29702;&#35299;&#38271;&#19978;&#19979;&#25991;&#12290;</title><link>https://arxiv.org/abs/2402.02244</link><description>&lt;p&gt;
&#36229;&#36234;&#26497;&#38480;&#65306;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19978;&#19979;&#25991;&#38271;&#24230;&#30340;&#25216;&#26415;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02244
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#20026;&#25193;&#23637;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#19978;&#19979;&#25991;&#38271;&#24230;&#32780;&#35774;&#35745;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#24182;&#22238;&#39038;&#20102;&#21253;&#25324;&#26550;&#26500;&#20462;&#25913;&#22312;&#20869;&#30340;&#22810;&#31181;&#25216;&#26415;&#65292;&#20351;&#24471;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#26356;&#26377;&#25928;&#22320;&#29702;&#35299;&#38271;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#29616;&#20986;&#20102;&#20196;&#20154;&#24778;&#24322;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#29702;&#35299;&#19978;&#19979;&#25991;&#12289;&#36827;&#34892;&#36923;&#36753;&#25512;&#29702;&#21644;&#29983;&#25104;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#36825;&#26159;&#20197;&#20005;&#26684;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#35201;&#27714;&#20026;&#20195;&#20215;&#30340;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#26377;&#25928;&#25903;&#25345;&#38271;&#36755;&#20837;&#24207;&#21015;&#30340;&#33021;&#21147;&#12290;&#26412;&#32508;&#36848;&#20840;&#38754;&#22238;&#39038;&#20102;&#26368;&#36817;&#20026;&#25193;&#23637;LLMs&#24207;&#21015;&#38271;&#24230;&#32780;&#35774;&#35745;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#20174;&#32780;&#22686;&#24378;&#20854;&#23545;&#38271;&#19978;&#19979;&#25991;&#29702;&#35299;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22238;&#39038;&#21644;&#20998;&#31867;&#20102;&#21508;&#31181;&#25216;&#26415;&#65292;&#21253;&#25324;&#20462;&#25913;&#20301;&#32622;&#32534;&#30721;&#21644;&#20462;&#25913;&#27880;&#24847;&#26426;&#21046;&#31561;&#26550;&#26500;&#20462;&#25913;&#65292;&#26088;&#22312;&#22686;&#24378;&#23545;&#26356;&#38271;&#24207;&#21015;&#30340;&#22788;&#29702;&#65292;&#21516;&#26102;&#36991;&#20813;&#35745;&#31639;&#38656;&#27714;&#30340;&#25104;&#27604;&#20363;&#22686;&#21152;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#30340;&#22810;&#26679;&#26041;&#27861;&#21487;&#20197;&#22312;LLMs&#30340;&#19981;&#21516;&#38454;&#27573;&#65288;&#21363;&#35757;&#32451;&#12289;&#24494;&#35843;&#21644;&#25512;&#29702;&#65289;&#20013;&#21033;&#29992;&#12290;&#36825;&#20351;&#24471;LLMs&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#38271;&#24207;&#21015;&#24182;&#25552;&#21319;&#23545;&#38271;&#19978;&#19979;&#25991;&#30340;&#29702;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, large language models (LLMs) have shown remarkable capabilities including understanding context, engaging in logical reasoning, and generating responses. However, this is achieved at the expense of stringent computational and memory requirements, hindering their ability to effectively support long input sequences. This survey provides an inclusive review of the recent techniques and methods devised to extend the sequence length in LLMs, thereby enhancing their capacity for long-context understanding. In particular, we review and categorize a wide range of techniques including architectural modifications, such as modified positional encoding and altered attention mechanisms, which are designed to enhance the processing of longer sequences while avoiding a proportional increase in computational requirements. The diverse methodologies investigated in this study can be leveraged across different phases of LLMs, i.e., training, fine-tuning and inference. This enables LLMs to effic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#38450;&#25252;&#25514;&#26045;&#65292;&#24182;&#20513;&#23548;&#37319;&#29992;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#22810;&#23398;&#31185;&#22242;&#38431;&#21512;&#20316;&#26469;&#30830;&#23450;&#31934;&#30830;&#30340;&#25216;&#26415;&#35201;&#27714;&#65292;&#20197;&#20943;&#36731;LLM&#30340;&#39118;&#38505;&#65292;&#24182;&#20840;&#38754;&#32771;&#34385;&#19981;&#21516;LLM&#24212;&#29992;&#30340;&#22810;&#26679;&#21270;&#19978;&#19979;&#25991;&#12290;</title><link>https://arxiv.org/abs/2402.01822</link><description>&lt;p&gt;
&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#38450;&#25252;&#25514;&#26045;
&lt;/p&gt;
&lt;p&gt;
Building Guardrails for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26500;&#24314;&#38450;&#25252;&#25514;&#26045;&#65292;&#24182;&#20513;&#23548;&#37319;&#29992;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#19982;&#22810;&#23398;&#31185;&#22242;&#38431;&#21512;&#20316;&#26469;&#30830;&#23450;&#31934;&#30830;&#30340;&#25216;&#26415;&#35201;&#27714;&#65292;&#20197;&#20943;&#36731;LLM&#30340;&#39118;&#38505;&#65292;&#24182;&#20840;&#38754;&#32771;&#34385;&#19981;&#21516;LLM&#24212;&#29992;&#30340;&#22810;&#26679;&#21270;&#19978;&#19979;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#34701;&#20837;&#25105;&#20204;&#30340;&#26085;&#24120;&#29983;&#27963;&#20013;&#65292;&#35782;&#21035;&#21644;&#20943;&#36731;&#23427;&#20204;&#30340;&#39118;&#38505;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#24403;&#36825;&#20123;&#39118;&#38505;&#23545;&#20154;&#31867;&#29992;&#25143;&#21644;&#31038;&#20250;&#20135;&#29983;&#28145;&#36828;&#24433;&#21709;&#26102;&#12290;&#38450;&#25252;&#25514;&#26045;&#65292;&#21363;&#36807;&#28388;LLM&#30340;&#36755;&#20837;&#25110;&#36755;&#20986;&#65292;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26680;&#24515;&#30340;&#23433;&#20840;&#25216;&#26415;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#24403;&#21069;&#30340;&#24320;&#28304;&#35299;&#20915;&#26041;&#26696;&#65288;Llama Guard&#65292;Nvidia NeMo&#65292;Guardrails AI&#65289;&#65292;&#35752;&#35770;&#20102;&#26500;&#24314;&#26356;&#23436;&#25972;&#35299;&#20915;&#26041;&#26696;&#30340;&#25361;&#25112;&#21644;&#36335;&#24452;&#12290;&#22522;&#20110;&#21069;&#26399;&#30740;&#31350;&#30340;&#26377;&#21147;&#35777;&#25454;&#65292;&#25105;&#20204;&#20513;&#23548;&#37319;&#29992;&#31995;&#32479;&#21270;&#26041;&#27861;&#26500;&#24314;LLM&#30340;&#38450;&#25252;&#25514;&#26045;&#65292;&#20840;&#38754;&#32771;&#34385;&#19981;&#21516;LLM&#24212;&#29992;&#30340;&#22810;&#26679;&#21270;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#19982;&#22810;&#23398;&#31185;&#22242;&#38431;&#30340;&#21512;&#20316;&#65292;&#37319;&#29992;&#31038;&#20250;&#25216;&#26415;&#26041;&#27861;&#26469;&#30830;&#23450;&#31934;&#30830;&#30340;&#25216;&#26415;&#35201;&#27714;&#65292;&#25506;&#32034;&#38754;&#21521;&#38656;&#27714;&#22797;&#26434;&#24615;&#30340;&#20808;&#36827;&#31070;&#32463;&#31526;&#21495;&#23454;&#29616;&#65292;&#24182;&#24320;&#23637;&#39564;&#35777;&#21644;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
As Large Language Models (LLMs) become more integrated into our daily lives, it is crucial to identify and mitigate their risks, especially when the risks can have profound impacts on human users and societies. Guardrails, which filter the inputs or outputs of LLMs, have emerged as a core safeguarding technology. This position paper takes a deep look at current open-source solutions (Llama Guard, Nvidia NeMo, Guardrails AI), and discusses the challenges and the road towards building more complete solutions. Drawing on robust evidence from previous research, we advocate for a systematic approach to construct guardrails for LLMs, based on comprehensive consideration of diverse contexts across various LLMs applications. We propose employing socio-technical methods through collaboration with a multi-disciplinary team to pinpoint precise technical requirements, exploring advanced neural-symbolic implementations to embrace the complexity of the requirements, and developing verification and t
&lt;/p&gt;</description></item><item><title>InstructRetro&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#65292;&#25193;&#23637;&#20102;&#22522;&#30784;&#27169;&#22411;Retro 48B&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#20248;&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2310.07713</link><description>&lt;p&gt;
InstructRetro: &#26816;&#32034;&#22686;&#24378;&#30340;&#39044;&#35757;&#32451;&#20013;&#25351;&#20196;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.07713
&lt;/p&gt;
&lt;p&gt;
InstructRetro&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#65292;&#25193;&#23637;&#20102;&#22522;&#30784;&#27169;&#22411;Retro 48B&#65292;&#36890;&#36807;&#25351;&#20196;&#35843;&#20248;&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26816;&#32034;&#22686;&#24378;&#25216;&#26415;&#23545;&#33258;&#22238;&#24402;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#39044;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;&#22256;&#24785;&#24230;&#21644;&#20107;&#23454;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#39044;&#35757;&#32451;&#26816;&#32034;&#22686;&#24378;LLM&#30340;&#35268;&#27169;&#20173;&#28982;&#26377;&#38480;&#65288;&#22914;Retro&#20855;&#26377;75&#20159;&#20010;&#21442;&#25968;&#65289;&#65292;&#36825;&#38480;&#21046;&#20102;&#25351;&#20196;&#35843;&#20248;&#21644;&#38646;&#26679;&#20363;&#27867;&#21270;&#30340;&#25928;&#26524;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Retro 48B&#65292;&#36825;&#26159;&#30446;&#21069;&#35268;&#27169;&#26368;&#22823;&#30340;&#20351;&#29992;&#26816;&#32034;&#39044;&#35757;&#32451;&#30340;LLM&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20351;&#29992;&#26816;&#32034;&#25216;&#26415;&#20174;1.2&#19975;&#20159;&#20010;&#26631;&#35760;&#20013;&#32487;&#32493;&#39044;&#35757;&#32451;&#19968;&#20010;43B&#30340;GPT&#27169;&#22411;&#65292;&#24182;&#20511;&#21161;Retro&#26041;&#27861;&#23558;&#20854;&#25193;&#23637;&#21040;4800&#20159;&#20010;&#21442;&#25968;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25152;&#24471;&#21040;&#30340;&#22522;&#30784;&#27169;&#22411;Retro 48B&#22312;&#22256;&#24785;&#24230;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#20165;&#20351;&#29992;1.2&#19975;&#20159;&#20010;&#26631;&#35760;&#36827;&#34892;&#35757;&#32451;&#30340;43B GPT&#27169;&#22411;&#65292;&#19988;&#21482;&#22686;&#21152;&#20102;2.58%&#30340;GPU&#20351;&#29992;&#26102;&#38388;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26174;&#33879;&#25193;&#23637;&#28508;&#21147;&#12290;&#22312;&#23545;Retro&#36827;&#34892;&#25351;&#20196;&#35843;&#20248;&#21518;&#65292;InstructRetro&#22312;&#21508;&#31181;&#38646;&#26679;&#20363;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretraining auto-regressive large language models (LLMs) with retrieval demonstrates better perplexity and factual accuracy by leveraging external databases. However, the size of existing pretrained retrieval-augmented LLM is still limited (e.g., Retro has 7.5B parameters), which limits the effectiveness of instruction tuning and zero-shot generalization. In this work, we introduce Retro 48B, the largest LLM pretrained with retrieval. Specifically, we continue to pretrain a 43B GPT model on additional 100 billion tokens using the Retro augmentation method by retrieving from 1.2 trillion tokens. Notably, the obtained foundation model, Retro 48B, largely outperforms the counterpart GPT 43B trained on 1.2T tokens in terms of perplexity with only 2.58% additional GPU hours, demonstrating the significant scaling potential of the method. After instruction tuning on Retro, InstructRetro demonstrates significant improvement over the instruction tuned GPT on a wide range of zero-shot tasks. Spe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#35745;&#31639;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#40657;&#30418;&#35774;&#32622;&#19979;&#36827;&#19968;&#27493;&#25552;&#21319;&#22823;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#20197;&#21450;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#19982;&#36827;&#21270;&#31639;&#27861;&#32467;&#21512;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.10034</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#36827;&#21270;&#35745;&#31639;&#65306;&#35843;&#26597;&#19982;&#36335;&#32447;&#22270;
&lt;/p&gt;
&lt;p&gt;
Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap. (arXiv:2401.10034v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10034
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#22823;&#35821;&#35328;&#27169;&#22411;&#21644;&#36827;&#21270;&#35745;&#31639;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#40657;&#30418;&#35774;&#32622;&#19979;&#36827;&#19968;&#27493;&#25552;&#21319;&#22823;&#35821;&#35328;&#27169;&#22411;&#24615;&#33021;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#20197;&#21450;&#23558;&#22823;&#35821;&#35328;&#27169;&#22411;&#19982;&#36827;&#21270;&#31639;&#27861;&#32467;&#21512;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26159;&#22522;&#20110;Transformer&#26550;&#26500;&#65292;&#22312;&#22810;&#26679;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#30340;&#65292;&#23427;&#20204;&#19981;&#20165;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#24341;&#36215;&#20102;&#38761;&#21629;&#65292;&#36824;&#23558;&#20854;&#33021;&#21147;&#25193;&#23637;&#21040;&#20102;&#21508;&#20010;&#39046;&#22495;&#65292;&#36808;&#21521;&#20102;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#23613;&#31649;&#36827;&#21270;&#31639;&#27861;&#65288;EAs&#65289;&#19982;LLMs&#22312;&#30446;&#26631;&#21644;&#26041;&#27861;&#35770;&#19978;&#23384;&#22312;&#24046;&#24322;&#65292;&#20294;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#25581;&#31034;&#20102;&#26377;&#36259;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#29305;&#21035;&#26159;&#22312;&#20182;&#20204;&#20849;&#21516;&#30340;&#20248;&#21270;&#24615;&#36136;&#12289;&#40657;&#30418;&#29305;&#24615;&#21644;&#22788;&#29702;&#22797;&#26434;&#38382;&#39064;&#30340;&#33021;&#21147;&#26041;&#38754;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36827;&#21270;&#31639;&#27861;&#19981;&#20165;&#21487;&#20197;&#20026;LLM&#22312;&#40657;&#30418;&#35774;&#32622;&#19979;&#25552;&#20379;&#20248;&#21270;&#26694;&#26550;&#65292;&#36824;&#21487;&#20197;&#22312;&#24212;&#29992;&#20013;&#20026;LLM&#36171;&#20104;&#28789;&#27963;&#30340;&#20840;&#23616;&#25628;&#32034;&#21644;&#36845;&#20195;&#26426;&#21046;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;LLM&#20016;&#23500;&#30340;&#39046;&#22495;&#30693;&#35782;&#20351;&#24471;&#36827;&#21270;&#31639;&#27861;&#21487;&#20197;&#36827;&#34892;&#26356;&#26234;&#33021;&#30340;&#25628;&#32034;&#65292;&#32780;&#20854;&#25991;&#26412;&#22788;&#29702;&#33021;&#21147;&#21017;&#26377;&#21161;&#20110;&#23558;&#36827;&#21270;&#31639;&#27861;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#12290;&#22522;&#20110;&#23427;&#20204;&#30340;&#20114;&#34917;&#20248;&#21183;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20221;&#35843;&#26597;&#21644;&#36335;&#32447;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), built upon Transformer-based architectures with massive pretraining on diverse data, have not only revolutionized natural language processing but also extended their prowess to various domains, marking a significant stride towards artificial general intelligence. The interplay between LLMs and Evolutionary Algorithms (EAs), despite differing in objectives and methodologies, reveals intriguing parallels, especially in their shared optimization nature, black-box characteristics, and proficiency in handling complex problems. Meanwhile, EA can not only provide an optimization framework for LLM's further enhancement under black-box settings but also empower LLM with flexible global search and iterative mechanism in applications. On the other hand, LLM's abundant domain knowledge enables EA to perform smarter searches, while its text processing capability assist in deploying EA across various tasks. Based on their complementary advantages, this paper presents a 
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27169;&#25311;&#35745;&#31639;&#26426;&#20195;&#30721;&#21644;&#31639;&#27861;&#25191;&#34892;&#26041;&#38754;&#36935;&#21040;&#25361;&#25112;&#65292;&#24615;&#33021;&#38543;&#30528;&#20195;&#30721;&#38271;&#24230;&#30340;&#22686;&#21152;&#32780;&#36805;&#36895;&#19979;&#38477;&#12290;&#22312;&#22788;&#29702;&#30701;&#31243;&#24207;&#25110;&#26631;&#20934;&#36807;&#31243;&#26102;&#65292;&#23427;&#20204;&#33021;&#20197;&#20302;&#38169;&#35823;&#29575;&#25353;&#39034;&#24207;&#25191;&#34892;&#25351;&#20196;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#30340;&#31243;&#24207;&#65292;&#29305;&#21035;&#26159;&#21253;&#21547;&#20851;&#38190;&#36335;&#24452;&#21644;&#20887;&#20313;&#25351;&#20196;&#30340;&#31243;&#24207;&#65292;&#27169;&#25311;&#25928;&#26524;&#36739;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27169;&#25311;&#20195;&#30721;&#25191;&#34892;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.09074</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20195;&#30721;&#27169;&#25311;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09074
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27169;&#25311;&#35745;&#31639;&#26426;&#20195;&#30721;&#21644;&#31639;&#27861;&#25191;&#34892;&#26041;&#38754;&#36935;&#21040;&#25361;&#25112;&#65292;&#24615;&#33021;&#38543;&#30528;&#20195;&#30721;&#38271;&#24230;&#30340;&#22686;&#21152;&#32780;&#36805;&#36895;&#19979;&#38477;&#12290;&#22312;&#22788;&#29702;&#30701;&#31243;&#24207;&#25110;&#26631;&#20934;&#36807;&#31243;&#26102;&#65292;&#23427;&#20204;&#33021;&#20197;&#20302;&#38169;&#35823;&#29575;&#25353;&#39034;&#24207;&#25191;&#34892;&#25351;&#20196;&#65292;&#20294;&#23545;&#20110;&#22797;&#26434;&#30340;&#31243;&#24207;&#65292;&#29305;&#21035;&#26159;&#21253;&#21547;&#20851;&#38190;&#36335;&#24452;&#21644;&#20887;&#20313;&#25351;&#20196;&#30340;&#31243;&#24207;&#65292;&#27169;&#25311;&#25928;&#26524;&#36739;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27169;&#25311;&#20195;&#30721;&#25191;&#34892;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#27169;&#25311;&#35745;&#31639;&#26426;&#20195;&#30721;&#21644;&#31639;&#27861;&#25191;&#34892;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#30452;&#32447;&#31243;&#24207;&#65292;&#24182;&#23637;&#31034;&#20102;&#24403;&#21069;LLMs&#22312;&#22788;&#29702;&#36825;&#26679;&#31616;&#21333;&#30340;&#31243;&#24207;&#26102;&#34920;&#29616;&#20986;&#30340;&#24615;&#33021;&#36739;&#24046;&#8212;&#8212;&#24615;&#33021;&#38543;&#30528;&#20195;&#30721;&#38271;&#24230;&#30340;&#22686;&#21152;&#32780;&#36805;&#36895;&#19979;&#38477;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#22312;&#27169;&#25311;&#21253;&#21547;&#20851;&#38190;&#36335;&#24452;&#21644;&#20887;&#20313;&#25351;&#20196;&#30340;&#31243;&#24207;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#25490;&#24207;&#31639;&#27861;&#21644;&#23884;&#22871;&#24490;&#29615;&#36229;&#36234;&#20102;&#30452;&#32447;&#31243;&#24207;&#30340;&#27169;&#25311;&#65292;&#24182;&#23637;&#31034;&#20102;&#31243;&#24207;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#30452;&#25509;&#24433;&#21709;LLMs&#27169;&#25311;&#20854;&#25191;&#34892;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;LLMs&#21482;&#26377;&#22312;&#22788;&#29702;&#30701;&#31243;&#24207;&#25110;&#26631;&#20934;&#36807;&#31243;&#26102;&#25165;&#33021;&#20197;&#20302;&#38169;&#35823;&#29575;&#25353;&#39034;&#24207;&#25191;&#34892;&#25351;&#20196;&#12290;LLMs&#30340;&#20195;&#30721;&#27169;&#25311;&#19982;&#23427;&#20204;&#30340;&#27169;&#24335;&#35782;&#21035;&#21644;&#35760;&#24518;&#33021;&#21147;&#23384;&#22312;&#30683;&#30462;&#65306;&#22312;&#35760;&#24518;&#23545;&#20219;&#21153;&#26377;&#23475;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25552;&#31034;&#26041;&#27861;&#65292;&#36880;&#34892;&#27169;&#25311;&#20195;&#30721;&#30340;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20250;&#25298;&#32477;&#65288;L2R&#65289;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#25298;&#32477;&#26426;&#21046;&#65292;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#35782;&#21035;&#21644;&#25298;&#32477;&#38590;&#20197;&#22238;&#31572;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#25511;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01041</link><description>&lt;p&gt;
&#23398;&#20250;&#25298;&#32477;&#65306;&#36890;&#36807;&#30693;&#35782;&#33539;&#22260;&#38480;&#21046;&#21644;&#25298;&#32477;&#26426;&#21046;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26356;&#21487;&#25511;&#21644;&#21487;&#38752;
&lt;/p&gt;
&lt;p&gt;
Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism. (arXiv:2311.01041v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20250;&#25298;&#32477;&#65288;L2R&#65289;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#24341;&#20837;&#25298;&#32477;&#26426;&#21046;&#65292;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#35782;&#21035;&#21644;&#25298;&#32477;&#38590;&#20197;&#22238;&#31572;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#25511;&#24615;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#35821;&#35328;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#65292;&#20351;&#23427;&#20204;&#33021;&#22815;&#22238;&#31572;&#21508;&#20010;&#39046;&#22495;&#30340;&#24191;&#27867;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#24182;&#19981;&#23436;&#32654;&#65292;&#32463;&#24120;&#20135;&#29983;&#21547;&#26377;&#38169;&#35823;&#25110;&#38169;&#35823;&#20449;&#24687;&#30340;&#22238;&#31572;&#12290;&#36825;&#20123;&#19981;&#20934;&#30830;&#24615;&#65292;&#36890;&#24120;&#31216;&#20026;&#24187;&#35273;&#65292;&#20351;&#24471;LLMs&#22312;&#35768;&#22810;&#22330;&#26223;&#20013;&#19981;&#21487;&#38752;&#29978;&#33267;&#19981;&#21487;&#29992;&#12290;&#26412;&#25991;&#30340;&#37325;&#28857;&#26159;&#22312;LLMs&#20013;&#32531;&#35299;&#24187;&#35273;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#38382;&#31572;&#29615;&#22659;&#20013;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#25298;&#32477;&#26426;&#21046;&#65292;&#25351;&#23548;LLMs&#25298;&#32477;&#22238;&#31572;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#20197;&#36991;&#20813;&#38169;&#35823;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;Learn to Refuse (L2R)&#65292;&#23427;&#23558;&#25298;&#32477;&#26426;&#21046;&#32435;&#20837;&#21040;LLMs&#20013;&#65292;&#20351;&#20854;&#33021;&#22815;&#35782;&#21035;&#21644;&#25298;&#32477;&#37027;&#20123;&#23427;&#20204;&#38590;&#20197;&#22238;&#31572;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#21033;&#29992;&#32467;&#26500;&#21270;&#30693;&#35782;&#24211;&#26469;&#34920;&#31034;&#25152;&#26377;LLMs&#25152;&#38656;&#35201;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated impressive language understanding and generation capabilities, enabling them to answer a wide range of questions across various domains. However, these models are not flawless and often produce responses that contain errors or misinformation. These inaccuracies, commonly referred to as hallucinations, render LLMs unreliable and even unusable in many scenarios. In this paper, our focus is on mitigating the issue of hallucination in LLMs, particularly in the context of question-answering. Instead of attempting to answer all questions, we explore a refusal mechanism that instructs LLMs to refuse to answer challenging questions in order to avoid errors. We then propose a simple yet effective solution called Learn to Refuse (L2R), which incorporates the refusal mechanism to enable LLMs to recognize and refuse to answer questions that they find difficult to address. To achieve this, we utilize a structured knowledge base to represent all the LLM
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18913</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#21435;&#38500;&#20559;&#35265;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25104;&#20026;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#30340;&#39318;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23481;&#37327;&#30340;&#22686;&#38271;&#65292;&#27169;&#22411;&#24456;&#23481;&#26131;&#20381;&#36182;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#21051;&#26495;&#21360;&#35937;&#25152;&#20135;&#29983;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#21457;&#29616;&#20013;&#19978;&#23618;&#21069;&#39304;&#23618;&#26368;&#23481;&#26131;&#20256;&#36882;&#20559;&#35265;&#12290;&#26681;&#25454;&#20998;&#26512;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#25237;&#24433;&#23558;&#36825;&#20123;&#23618;&#20056;&#20197;&#27169;&#22411;&#36827;&#34892;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;DAMA&#36890;&#36807;&#21508;&#31181;&#24230;&#37327;&#25351;&#26631;&#26126;&#26174;&#20943;&#23569;&#20102;&#20559;&#35265;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#20195;&#30721;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#65292;&#20445;&#25345;&#20102;LLaMA&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21516;&#26102;&#20559;&#35265;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#29983;&#25104;&#36830;&#36143;&#30340;&#24605;&#32500;&#38142;&#26465;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#23427;&#19982;&#30495;&#23454;&#35821;&#35328;&#26469;&#28304;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#32467;&#26524;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2310.13571</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20026;&#20309;&#33021;&#29983;&#25104;&#27491;&#30830;&#30340;&#24605;&#32500;&#38142;&#26465;&#65311;
&lt;/p&gt;
&lt;p&gt;
Why Can Large Language Models Generate Correct Chain-of-Thoughts?. (arXiv:2310.13571v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22914;&#20309;&#29983;&#25104;&#36830;&#36143;&#30340;&#24605;&#32500;&#38142;&#26465;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#23427;&#19982;&#30495;&#23454;&#35821;&#35328;&#26469;&#28304;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#32467;&#26524;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25512;&#29702;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#33021;&#21147;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#21160;&#23545;&#24605;&#32500;&#38142;&#26465;&#24341;&#21457;&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#26377;&#25928;&#22320;&#35825;&#23548;LLM&#29983;&#25104;&#36830;&#36143;&#30340;&#24605;&#32500;&#38142;&#26465;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38024;&#23545;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#20004;&#32423;&#20998;&#23618;&#22270;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#35828;&#26381;&#21147;&#30340;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#65292;&#29992;&#20110;&#34913;&#37327;LLM&#29983;&#25104;&#30340;&#24605;&#32500;&#38142;&#26465;&#19982;&#30495;&#23454;&#35821;&#35328;&#26469;&#28304;&#30340;&#24605;&#32500;&#38142;&#26465;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#20026;LLM&#33021;&#22815;&#20135;&#29983;&#27491;&#30830;&#30340;&#24605;&#32500;&#24207;&#21015;&#65288;&#21487;&#33021;&#65289;&#35299;&#37322;&#20102;&#22312;&#38656;&#35201;&#25512;&#29702;&#33021;&#21147;&#30340;&#20219;&#21153;&#20013;&#24615;&#33021;&#25552;&#21319;&#30340;&#33021;&#21147;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper delves into the capabilities of large language models (LLMs), specifically focusing on advancing the theoretical comprehension of chain-of-thought prompting. We investigate how LLMs can be effectively induced to generate a coherent chain of thoughts. To achieve this, we introduce a two-level hierarchical graphical model tailored for natural language generation. Within this framework, we establish a compelling geometrical convergence rate that gauges the likelihood of an LLM-generated chain of thoughts compared to those originating from the true language. Our findings provide a theoretical justification for the ability of LLMs to produce the correct sequence of thoughts (potentially) explaining performance gains in tasks demanding reasoning skills.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33258;&#21160;&#29983;&#25104;&#30340;&#20851;&#38190;&#35789;&#19981;&#24179;&#31561;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#37325;&#35201;&#30340;&#20196;&#29260;&#21644;&#21547;&#26377;&#26377;&#38480;&#35821;&#20041;&#30340;&#21477;&#23376;&#34987;&#21516;&#31561;&#25110;&#26356;&#21152;&#37325;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20849;&#21516;&#36716;&#31227;&#20851;&#27880;&#28857;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01379</link><description>&lt;p&gt;
&#23558;&#20851;&#27880;&#28857;&#36716;&#31227;&#21040;&#30456;&#20851;&#24615;&#19978;: &#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models. (arXiv:2307.01379v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33258;&#21160;&#29983;&#25104;&#30340;&#20851;&#38190;&#35789;&#19981;&#24179;&#31561;&#38382;&#39064;&#65292;&#21457;&#29616;&#22312;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#37325;&#35201;&#30340;&#20196;&#29260;&#21644;&#21547;&#26377;&#26377;&#38480;&#35821;&#20041;&#30340;&#21477;&#23376;&#34987;&#21516;&#31561;&#25110;&#26356;&#21152;&#37325;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20849;&#21516;&#36716;&#31227;&#20851;&#27880;&#28857;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#26159;&#23545;&#20110;&#27169;&#22411;&#29983;&#25104;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#29305;&#24449;&#21270;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#21363;&#29992;&#25143;&#20309;&#26102;&#21487;&#20197;&#20449;&#20219;&#27169;&#22411;&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22522;&#20110;&#19968;&#20123;&#21551;&#21457;&#24615;&#30340;&#20107;&#23454;&#65292;&#21363;&#22312;&#33258;&#22238;&#24402;&#30340;LLMs&#20013;&#65292;&#20196;&#29260;&#22312;&#21453;&#26144;&#29983;&#25104;&#30340;&#21547;&#20041;&#26041;&#38754;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#21363;&#19968;&#20123;&#20196;&#29260;&#27604;&#20854;&#20182;&#20196;&#29260;&#26356;&#30456;&#20851;&#65288;&#25110;&#26356;&#20855;&#20195;&#34920;&#24615;&#65289;&#65292;&#28982;&#32780;&#22312;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26102;&#25152;&#26377;&#30340;&#20196;&#29260;&#34987;&#31561;&#20540;&#23545;&#24453;&#12290;&#36825;&#26159;&#30001;&#20110;&#35821;&#35328;&#20887;&#20313;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#24773;&#20917;&#19979;&#65292;&#21482;&#38656;&#35201;&#20960;&#20010;&#20851;&#38190;&#35789;&#23601;&#36275;&#20197;&#20256;&#36798;&#19968;&#20010;&#38271;&#21477;&#30340;&#21547;&#20041;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#19981;&#24179;&#31561;&#31216;&#20026;&#29983;&#25104;&#30340;&#19981;&#24179;&#31561;&#65292;&#24182;&#30740;&#31350;&#23427;&#20204;&#22914;&#20309;&#24433;&#21709;&#19981;&#30830;&#23450;&#24615;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#65292;&#30456;&#24403;&#25968;&#37327;&#30340;&#20196;&#29260;&#21644;&#21253;&#21547;&#26377;&#38480;&#35821;&#20041;&#30340;&#21477;&#23376;&#65292;&#22312;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26102;&#34987;&#21516;&#31561;&#25110;&#29978;&#33267;&#26356;&#21152;&#37325;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#30001;&#29983;&#25104;&#30340;&#19981;&#24179;&#31561;&#24341;&#36215;&#30340;&#36825;&#20123;&#20559;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20849;&#21516;&#36716;&#31227;&#20851;&#27880;&#28857;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although Large Language Models (LLMs) have shown great potential in Natural Language Generation, it is still challenging to characterize the uncertainty of model generations, i.e., when users could trust model outputs. Our research is derived from the heuristic facts that tokens are created unequally in reflecting the meaning of generations by auto-regressive LLMs, i.e., some tokens are more relevant (or representative) than others, yet all the tokens are equally valued when estimating uncertainty. It is because of the linguistic redundancy where mostly a few keywords are sufficient to convey the meaning of a long sentence. We name these inequalities as generative inequalities and investigate how they affect uncertainty estimation. Our results reveal that considerable tokens and sentences containing limited semantics are weighted equally or even heavily when estimating uncertainty. To tackle these biases posed by generative inequalities, we propose to jointly Shifting Attention to more
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#20869;&#37096;&#24037;&#20316;&#35760;&#24518;&#27169;&#22359;&#30340;&#20915;&#31574;Transformer&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20915;&#31574;&#20195;&#29702;&#22312;&#22788;&#29702;&#26032;&#20219;&#21153;&#19978;&#24615;&#33021;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#35757;&#32451;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#36716;&#21270;&#20915;&#31574;&#21046;&#23450;&#20195;&#29702;&#23545;&#26032;&#20219;&#21153;&#30340;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.16338</link><description>&lt;p&gt;
&#28145;&#24605;&#29087;&#34385;&#65306;&#20855;&#26377;&#20869;&#37096;&#24037;&#20316;&#35760;&#24518;&#30340;&#20915;&#31574;Transformer
&lt;/p&gt;
&lt;p&gt;
Think Before You Act: Decision Transformers with Internal Working Memory. (arXiv:2305.16338v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#20869;&#37096;&#24037;&#20316;&#35760;&#24518;&#27169;&#22359;&#30340;&#20915;&#31574;Transformer&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20915;&#31574;&#20195;&#29702;&#22312;&#22788;&#29702;&#26032;&#20219;&#21153;&#19978;&#24615;&#33021;&#20302;&#19979;&#30340;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#35757;&#32451;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#36716;&#21270;&#20915;&#31574;&#21046;&#23450;&#20195;&#29702;&#23545;&#26032;&#20219;&#21153;&#30340;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20915;&#31574;&#21046;&#23450;&#20195;&#29702;&#24050;&#32463;&#23637;&#31034;&#20102;&#36328;&#36234;&#22810;&#20010;&#20219;&#21153;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#20381;&#36182;&#20110;&#22823;&#35268;&#27169;&#30340;&#25968;&#25454;&#21644;&#35745;&#31639;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#31181;&#20302;&#25928;&#24615;&#28304;&#20110;&#36951;&#24536;&#29616;&#35937;&#65292;&#21363;&#27169;&#22411;&#36890;&#36807;&#21442;&#25968;&#35760;&#24518;&#20854;&#34892;&#20026;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#12290;&#22240;&#27492;&#65292;&#26032;&#20219;&#21153;&#30340;&#35757;&#32451;&#21487;&#33021;&#20250;&#38477;&#20302;&#27169;&#22411;&#22312;&#20808;&#21069;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#19982;LLM&#30340;&#38544;&#24335;&#35760;&#24518;&#26426;&#21046;&#19981;&#21516;&#65292;&#20154;&#33041;&#21033;&#29992;&#20998;&#24067;&#24335;&#23384;&#20648;&#22120;&#23384;&#20648;&#35760;&#24518;&#65292;&#20197;&#26377;&#25928;&#22320;&#31649;&#29702;&#21644;&#32452;&#32455;&#22810;&#31181;&#25216;&#33021;&#65292;&#20943;&#36731;&#20102;&#36951;&#24536;&#29616;&#35937;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#20351;&#29992;&#20869;&#37096;&#24037;&#20316;&#35760;&#24518;&#27169;&#22359;&#26469;&#23384;&#20648;&#12289;&#34701;&#21512;&#21644;&#26816;&#32034;&#19981;&#21516;&#19979;&#28216;&#20219;&#21153;&#30340;&#20449;&#24687;&#12290;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;Atari&#28216;&#25103;&#21644;&#20803;&#19990;&#30028;&#29289;&#20307;&#25805;&#20316;&#20219;&#21153;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35760;&#24518;&#24494;&#35843;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#36716;&#21270;&#20915;&#31574;&#21046;&#23450;&#20195;&#29702;&#23545;&#26032;&#20219;&#21153;&#30340;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language model (LLM)-based decision-making agents have shown the ability to generalize across multiple tasks. However, their performance relies on massive data and compute. We argue that this inefficiency stems from the forgetting phenomenon, in which a model memorizes its behaviors in parameters throughout training. As a result, training on a new task may deteriorate the model's performance on previous tasks. In contrast to LLMs' implicit memory mechanism, the human brain utilizes distributed memory storage, which helps manage and organize multiple skills efficiently, mitigating the forgetting phenomenon. Thus inspired, we propose an internal working memory module to store, blend, and retrieve information for different downstream tasks. Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks. Moreover, we demonstrate that memory fine-tuning further enhances the adaptability of t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#30784;&#27169;&#22411;UP5&#65292;&#23427;&#37319;&#29992;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#26469;&#28040;&#38500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#20174;&#32780;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2305.12090</link><description>&lt;p&gt;
UP5: &#38754;&#21521;&#20844;&#24179;&#24615;&#25512;&#33616;&#30340;&#26080;&#20559;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
UP5: Unbiased Foundation Model for Fairness-aware Recommendation. (arXiv:2305.12090v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#30784;&#27169;&#22411;UP5&#65292;&#23427;&#37319;&#29992;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#26469;&#28040;&#38500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#65292;&#20174;&#32780;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#31561;&#22522;&#30784;&#27169;&#22411;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24050;&#23558;&#23427;&#20204;&#25512;&#21040;&#20102;&#25512;&#33616;&#31995;&#32479;&#65288;RS&#65289;&#30340;&#21069;&#27839;&#12290;&#27492;&#22806;&#65292;RS&#20013;&#30340;&#20844;&#24179;&#24615;&#24456;&#20851;&#38190;&#65292;&#22240;&#20026;&#35768;&#22810;&#29992;&#25143;&#23558;&#20854;&#29992;&#20110;&#20915;&#31574;&#21644;&#38656;&#27714;&#23653;&#34892;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#32570;&#20047;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23637;&#31034;&#20844;&#24179;&#24615;&#27700;&#24179;&#21644;&#20844;&#24179;&#22788;&#29702;&#19981;&#21516;&#29992;&#25143;&#32676;&#32452;&#30340;&#36866;&#24403;&#26041;&#27861;&#30340;&#29702;&#35299;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#29992;&#25143;&#26041;&#38754;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24443;&#24213;&#26816;&#26597;&#34920;&#26126;&#65292;LLMs&#20013;&#23384;&#22312;&#19981;&#20844;&#24179;&#24615;&#65292;&#23548;&#33268;&#19981;&#20844;&#24179;&#30340;&#25512;&#33616;&#32467;&#26524;&#12290;&#20026;&#20102;&#28040;&#38500;LLM&#20013;&#30340;&#20559;&#24046;&#20197;&#23454;&#29616;&#38754;&#21521;&#20844;&#24179;&#24615;&#30340;&#25512;&#33616;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#20844;&#24179;&#20419;&#36827;&#25216;&#26415;&#30340;&#26032;&#22411;&#26080;&#20559;P5&#65288;UP5&#65289;&#22522;&#30784;&#27169;&#22411;&#12290;CFP&#21253;&#25324;&#20004;&#20010;&#23376;&#27169;&#22359;&#65306;&#20010;&#24615;&#21270;&#21069;&#32512;&#25552;&#31034;&#21644;Prompt&#28151;&#21512;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#20010;&#20307;&#25935;&#24863;&#23646;&#24615;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in foundation models such as large language models (LLM) have propelled them to the forefront of recommender systems (RS). Moreover, fairness in RS is critical since many users apply it for decision-making and demand fulfillment. However, at present, there is a lack of understanding regarding the level of fairness exhibited by recommendation foundation models and the appropriate methods for equitably treating different groups of users in foundation models. In this paper, we focus on user-side unfairness problem and show through a thorough examination that there is unfairness involved in LLMs that lead to unfair recommendation results. To eliminate bias from LLM for fairness-aware recommendation, we introduce a novel Unbiased P5 (UP5) foundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP includes two sub-modules: a personalized prefix prompt that enhances fairness with respect to individual sensitive attributes, and a Prompt Mixture that int
&lt;/p&gt;</description></item></channel></rss>