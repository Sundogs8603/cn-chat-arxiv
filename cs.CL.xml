<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#20351;&#29992;&#21487;&#25191;&#34892;&#30340;Python&#20195;&#30721;&#25972;&#21512;LLM&#26234;&#33021;&#20307;&#34892;&#21160;&#65292;&#25552;&#21319;&#20102;&#25104;&#21151;&#29575;&#39640;&#36798;20%&#12290;</title><link>https://rss.arxiv.org/abs/2402.01030</link><description>&lt;p&gt;
&#21487;&#25191;&#34892;&#20195;&#30721;&#34892;&#21160;&#33021;&#22815;&#28608;&#21457;&#26356;&#20986;&#33394;&#30340;LLM&#26234;&#33021;&#20307;
&lt;/p&gt;
&lt;p&gt;
Executable Code Actions Elicit Better LLM Agents
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01030
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21487;&#25191;&#34892;&#30340;Python&#20195;&#30721;&#25972;&#21512;LLM&#26234;&#33021;&#20307;&#34892;&#21160;&#65292;&#25552;&#21319;&#20102;&#25104;&#21151;&#29575;&#39640;&#36798;20%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26234;&#33021;&#20307;&#20855;&#22791;&#25191;&#34892;&#24191;&#27867;&#34892;&#21160;&#30340;&#33021;&#21147;&#65292;&#22914;&#35843;&#29992;&#24037;&#20855;&#21644;&#25511;&#21046;&#26426;&#22120;&#20154;&#31561;&#65292;&#22312;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#30340;&#25361;&#25112;&#20013;&#26174;&#31034;&#20986;&#24040;&#22823;&#28508;&#21147;&#12290;LLM&#26234;&#33021;&#20307;&#36890;&#24120;&#36890;&#36807;&#29983;&#25104;JSON&#25110;&#25991;&#26412;&#30340;&#39044;&#23450;&#20041;&#26684;&#24335;&#26469;&#20135;&#29983;&#34892;&#21160;&#65292;&#36825;&#36890;&#24120;&#21463;&#38480;&#20110;&#21463;&#38480;&#21046;&#30340;&#34892;&#21160;&#31354;&#38388;&#65288;&#20363;&#22914;&#65292;&#39044;&#23450;&#20041;&#24037;&#20855;&#30340;&#33539;&#22260;&#65289;&#21644;&#21463;&#38480;&#30340;&#28789;&#27963;&#24615;&#65288;&#20363;&#22914;&#65292;&#26080;&#27861;&#32452;&#21512;&#22810;&#20010;&#24037;&#20855;&#65289;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#21487;&#25191;&#34892;&#30340;Python&#20195;&#30721;&#23558;LLM&#26234;&#33021;&#20307;&#30340;&#34892;&#21160;&#25972;&#21512;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#34892;&#21160;&#31354;&#38388;&#20013;&#65288;CodeAct&#65289;&#12290;CodeAct&#19982;Python&#35299;&#37322;&#22120;&#38598;&#25104;&#65292;&#21487;&#20197;&#25191;&#34892;&#20195;&#30721;&#34892;&#21160;&#65292;&#24182;&#36890;&#36807;&#22810;&#36718;&#20132;&#20114;&#22312;&#26032;&#30340;&#35266;&#23519;&#20013;&#21160;&#24577;&#20462;&#35746;&#20808;&#21069;&#30340;&#34892;&#21160;&#25110;&#21457;&#20986;&#26032;&#30340;&#34892;&#21160;&#12290;&#25105;&#20204;&#23545;17&#20010;LLM&#22312;API-Bank&#21644;&#26032;&#32534;&#21046;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#20102;&#24191;&#27867;&#20998;&#26512;&#65292;&#32467;&#26524;&#26174;&#31034;CodeAct&#30340;&#24615;&#33021;&#36229;&#36807;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;&#26367;&#20195;&#26041;&#26696;&#65288;&#25104;&#21151;&#29575;&#39640;&#20986;20%&#65289;&#12290;CodeAct&#30340;&#20196;&#20154;&#40723;&#33310;&#30340;&#34920;&#29616;&#28608;&#21169;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-sourc
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#21033;&#29992;&#26426;&#22120;&#32763;&#35793;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#20197;&#35299;&#20915;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#65292;&#24212;&#29992;&#20219;&#21153;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#21644;&#36866;&#37197;&#22120;&#26694;&#26550;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2404.01490</link><description>&lt;p&gt;
AAdaM&#22312;SemEval-2024&#20219;&#21153;1&#20013;&#30340;&#34920;&#29616;&#65306;&#22810;&#35821;&#35328;&#35821;&#20041;&#25991;&#26412;&#30456;&#20851;&#24615;&#30340;&#22686;&#24378;&#19982;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
AAdaM at SemEval-2024 Task 1: Augmentation and Adaptation for Multilingual Semantic Textual Relatedness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01490
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#21033;&#29992;&#26426;&#22120;&#32763;&#35793;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#20197;&#35299;&#20915;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#65292;&#24212;&#29992;&#20219;&#21153;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#21644;&#36866;&#37197;&#22120;&#26694;&#26550;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#25105;&#20204;&#20026;SemEval-2024&#20219;&#21153;1&#24320;&#21457;&#30340;&#31995;&#32479;&#65306;&#38750;&#27954;&#21644;&#20122;&#27954;&#35821;&#35328;&#30340;&#35821;&#20041;&#25991;&#26412;&#30456;&#20851;&#24615;&#12290;&#35813;&#20849;&#20139;&#20219;&#21153;&#26088;&#22312;&#34913;&#37327;&#21477;&#23376;&#23545;&#20043;&#38388;&#30340;&#35821;&#20041;&#25991;&#26412;&#30456;&#20851;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#19968;&#31995;&#21015;&#20195;&#34920;&#24615;&#19981;&#36275;&#30340;&#35821;&#35328;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#26426;&#22120;&#32763;&#35793;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#65292;&#20197;&#35299;&#20915;&#35757;&#32451;&#25968;&#25454;&#26377;&#38480;&#30340;&#20302;&#36164;&#28304;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#20219;&#21153;&#33258;&#36866;&#24212;&#39044;&#35757;&#32451;&#24212;&#29992;&#20110;&#26410;&#26631;&#35760;&#30340;&#20219;&#21153;&#25968;&#25454;&#65292;&#20197;&#24357;&#21512;&#39044;&#35757;&#32451;&#21644;&#20219;&#21153;&#36866;&#24212;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#22312;&#27169;&#22411;&#35757;&#32451;&#26041;&#38754;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23436;&#20840;&#24494;&#35843;&#21644;&#22522;&#20110;&#36866;&#37197;&#22120;&#30340;&#35843;&#25972;&#65292;&#24182;&#37319;&#29992;&#36866;&#37197;&#22120;&#26694;&#26550;&#23454;&#29616;&#20102;&#26377;&#25928;&#30340;&#38646;-shot&#36328;&#35821;&#35328;&#36716;&#31227;&#12290;&#22312;&#20849;&#20139;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#31995;&#32479;&#22312;&#23376;&#20219;&#21153;A&#65288;&#30417;&#30563;&#23398;&#20064;&#65289;&#21644;&#23376;&#20219;&#21153;C&#65288;&#36328;&#35821;&#35328;&#36716;&#31227;&#65289;&#20013;&#34920;&#29616;&#26368;&#20339;&#65292;&#25490;&#21517;&#26368;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01490v1 Announce Type: new  Abstract: This paper presents our system developed for the SemEval-2024 Task 1: Semantic Textual Relatedness for African and Asian Languages. The shared task aims at measuring the semantic textual relatedness between pairs of sentences, with a focus on a range of under-represented languages. In this work, we propose using machine translation for data augmentation to address the low-resource challenge of limited training data. Moreover, we apply task-adaptive pre-training on unlabeled task data to bridge the gap between pre-training and task adaptation. For model training, we investigate both full fine-tuning and adapter-based tuning, and adopt the adapter framework for effective zero-shot cross-lingual transfer. We achieve competitive results in the shared task: our system performs the best among all ranked teams in both subtask A (supervised learning) and subtask C (cross-lingual transfer).
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26032;&#35774;&#35745;&#30340;&#22522;&#20934;&#27979;&#35797;\textsc{CoTErrorSet}&#65292;&#30740;&#31350;&#20102;LLMs&#26159;&#21542;&#33021;&#22815;&#20174;&#20197;&#24448;&#30340;&#38169;&#35823;&#20013;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2403.20046</link><description>&lt;p&gt;
LLM&#33021;&#20174;&#20197;&#21069;&#30340;&#38169;&#35823;&#20013;&#23398;&#20064;&#21527;&#65311;&#35843;&#26597;LLMs'&#38169;&#35823;&#20197;&#22686;&#24378;&#25512;&#29702;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20046
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26032;&#35774;&#35745;&#30340;&#22522;&#20934;&#27979;&#35797;\textsc{CoTErrorSet}&#65292;&#30740;&#31350;&#20102;LLMs&#26159;&#21542;&#33021;&#22815;&#20174;&#20197;&#24448;&#30340;&#38169;&#35823;&#20013;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#20174;&#24494;&#35843;&#40644;&#37329;&#26631;&#20934;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#35299;&#37322;&#25110;&#23558;&#20854;&#29992;&#20316;&#23569;&#37327;&#25552;&#31034;&#20013;&#30340;&#27491;&#30830;&#31034;&#20363;&#20013;&#21463;&#30410;&#12290;&#23613;&#31649;&#20154;&#31867;&#30830;&#23454;&#21487;&#20197;&#27169;&#20223;&#27491;&#30830;&#30340;&#20363;&#23376;&#65292;&#20294;&#20174;&#25105;&#20204;&#30340;&#38169;&#35823;&#20013;&#23398;&#20064;&#26159;&#20154;&#31867;&#35748;&#30693;&#30340;&#21478;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#26041;&#38754;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#38382;&#39064;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#65306;LLMs&#33021;&#21542;&#23398;&#20064;&#24182;&#21463;&#30410;&#20110;&#20182;&#20204;&#30340;&#38169;&#35823;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20182;&#20204;&#30340;&#25512;&#29702;&#65311;&#26412;&#30740;&#31350;&#20174;&#25552;&#31034;&#21644;&#27169;&#22411;&#35843;&#25972;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;\textsc{CoTErrorSet}&#65292;&#20854;&#20013;&#21253;&#21547;609,432&#20010;&#38382;&#39064;&#65292;&#27599;&#20010;&#38382;&#39064;&#37117;&#35774;&#35745;&#26377;&#27491;&#30830;&#21644;&#38169;&#35823;&#30340;&#21442;&#32771;&#25991;&#29486;&#65292;&#24182;&#23637;&#31034;&#20102;&#21046;&#36896;&#36825;&#20123;&#38169;&#35823;&#30340;&#31867;&#22411;&#21644;&#21407;&#22240;&#12290;&#20026;&#20102;&#25506;&#35752;&#36825;&#20123;&#38169;&#35823;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#26041;&#27861;&#65306;&#65288;1&#65289;\textbf{&#33258;&#25105;&#21453;&#24605;}&#25552;&#31034;&#25351;&#23548;LLMs&#37325;&#26032;&#32771;&#34385;&#20182;&#20204;&#26159;&#21542;&#26366;&#32463;&#29359;&#36807;&#31867;&#20284;&#30340;&#38169;&#35823;&#65307;&#21644;&#65288;2&#65289;\textbf{&#38169;&#35823;&#35843;&#25972;}&#21253;&#25324;&#23545;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20046v1 Announce Type: new  Abstract: Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples, learning from our mistakes is another vital aspect of human cognition. Hence, a question naturally arises: \textit{can LLMs learn and benefit from their mistakes, especially for their reasoning? } This study investigates this problem from both the prompting and model-tuning perspectives. We begin by introducing \textsc{CoTErrorSet}, a new benchmark with 609,432 questions, each designed with both correct and error references, and demonstrating the types and reasons for making such mistakes. To explore the effectiveness of those mistakes, we design two methods: (1) \textbf{Self-rethinking} prompting guides LLMs to rethink whether they have made similar previous mistakes; and (2) \textbf{Mistake tuning} involves finetuning mo
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#21307;&#23398;&#32534;&#30721;&#30340;&#21547;&#20041;&#65292;&#35780;&#20272;&#20102;&#23427;&#20204;&#23545;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#30340;&#35748;&#35782;&#21644;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.10822</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#21307;&#23398;&#32534;&#30721;?
&lt;/p&gt;
&lt;p&gt;
Do Large Language Models understand Medical Codes?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10822
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#29702;&#35299;&#21307;&#23398;&#32534;&#30721;&#30340;&#21547;&#20041;&#65292;&#35780;&#20272;&#20102;&#23427;&#20204;&#23545;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#30340;&#35748;&#35782;&#21644;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#30340;&#39318;&#35201;&#30446;&#26631;&#26159;&#31283;&#27493;&#26397;&#30528;&#23454;&#29616;&#20154;&#24037;&#36890;&#29992;&#26234;&#33021;(AGI)&#36808;&#36827;&#65292;&#36825;&#20419;&#20351;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#31181;&#20219;&#21153;&#21644;&#39046;&#22495;&#20013;&#30340;&#35780;&#20272;&#12290;&#20854;&#20013;&#20043;&#19968;&#26159;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;LLMs&#21487;&#20197;&#36890;&#36807;&#21327;&#21161;&#21508;&#31181;&#20219;&#21153;&#22823;&#22823;&#26377;&#30410;&#20110;&#20020;&#24202;&#23454;&#36341;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#26080;&#27861;&#20805;&#20998;&#24212;&#23545;&#30340;&#26597;&#35810;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#20063;&#23481;&#26131;&#20135;&#29983;&#8220;&#24187;&#35273;&#8221;&#25110;&#19981;&#27491;&#30830;&#30340;&#21709;&#24212;&#65292;&#24341;&#21457;&#20102;&#20851;&#27880;&#21644;&#24576;&#30097;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#20445;&#20581;&#31038;&#21306;&#20869;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;LLMs&#26159;&#21542;&#29702;&#35299;&#21307;&#23398;&#32534;&#30721;&#30340;&#22266;&#26377;&#21547;&#20041;&#65292;&#36825;&#20123;&#32534;&#30721;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#23454;&#36341;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#29616;&#25104;&#30340;LLMs (&#20363;&#22914;GPT&#12289;LLaMA&#31561;)&#21644;&#19987;&#38376;&#20026;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#35774;&#35745;&#30340;LLMs&#65292;&#20197;&#35780;&#20272;&#23427;&#20204;&#23545;&#36825;&#20123;&#39046;&#22495;&#29305;&#23450;&#26415;&#35821;&#30340;&#35748;&#35782;&#21644;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10822v1 Announce Type: new  Abstract: The overarching goal of recent AI research has been to make steady progress towards achieving Artificial General Intelligence (AGI), prompting the evaluation of Large Language Models (LLMs) across a variety of tasks and domains. One such domain is healthcare, where LLMs can greatly benefit clinical practice by assisting with a wide range of tasks. However, these models are also prone to producing "hallucinations" or incorrect responses when faced with queries they cannot adequately address, raising concerns and skepticism, especially within the healthcare community. Therefore, in this work, we investigate whether LLMs understand the inherent meaning of medical codes, which are widely used in healthcare practice. We evaluate various off-the-shelf LLMs (e.g., GPT, LLaMA, etc.) and LLMs specifically designed for biomedical applications to assess their awareness and understanding of these domain-specific terminologies. Our results indicate t
&lt;/p&gt;</description></item><item><title>Hyper-CL&#26159;&#19968;&#31181;&#23558;&#36229;&#32593;&#32476;&#19982;&#23545;&#27604;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#33021;&#22815;&#28789;&#27963;&#22320;&#36827;&#34892;&#26465;&#20214;&#21270;&#21477;&#23376;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.09490</link><description>&lt;p&gt;
Hyper-CL&#65306;&#20351;&#29992;&#36229;&#32593;&#32476;&#23545;&#21477;&#23376;&#34920;&#31034;&#36827;&#34892;&#26465;&#20214;&#21270;
&lt;/p&gt;
&lt;p&gt;
Hyper-CL: Conditioning Sentence Representations with Hypernetworks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09490
&lt;/p&gt;
&lt;p&gt;
Hyper-CL&#26159;&#19968;&#31181;&#23558;&#36229;&#32593;&#32476;&#19982;&#23545;&#27604;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#33021;&#22815;&#28789;&#27963;&#22320;&#36827;&#34892;&#26465;&#20214;&#21270;&#21477;&#23376;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#23558;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#24341;&#20837;&#21477;&#23376;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20419;&#36827;&#20102;&#35813;&#39046;&#22495;&#30340;&#36827;&#23637;&#65292;&#20294;&#24403;&#21477;&#23376;&#34987;&#29305;&#23450;&#35282;&#24230;&#26465;&#20214;&#21270;&#26102;&#65292;&#23588;&#20854;&#26159;&#22312;&#25429;&#25417;&#21477;&#23376;&#30340;&#32454;&#31890;&#24230;&#35821;&#20041;&#26041;&#38754;&#65292;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#21477;&#23376;&#23884;&#20837;&#33021;&#21147;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;Hyper-CL&#65292;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#36229;&#32593;&#32476;&#19982;&#23545;&#27604;&#23398;&#20064;&#32467;&#21512;&#36215;&#26469;&#35745;&#31639;&#26465;&#20214;&#21270;&#30340;&#21477;&#23376;&#34920;&#31034;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20013;&#65292;&#36229;&#32593;&#32476;&#36127;&#36131;&#23558;&#39044;&#20808;&#35745;&#31639;&#30340;&#26465;&#20214;&#23884;&#20837;&#36716;&#25442;&#20026;&#30456;&#24212;&#30340;&#25237;&#24433;&#23618;&#12290;&#36825;&#20351;&#24471;&#30456;&#21516;&#30340;&#21477;&#23376;&#23884;&#20837;&#21487;&#20197;&#26681;&#25454;&#19981;&#21516;&#26465;&#20214;&#36827;&#34892;&#19981;&#21516;&#30340;&#25237;&#24433;&#12290;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#26465;&#20214;&#21270;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#21363;&#26465;&#20214;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24230;&#21644;&#30693;&#35782;&#22270;&#23436;&#25104;&#65292;&#34920;&#26126;Hyper-CL&#22312;&#28789;&#27963;&#22320;&#36827;&#34892;&#26465;&#20214;&#21270;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09490v1 Announce Type: new  Abstract: While the introduction of contrastive learning frameworks in sentence representation learning has significantly contributed to advancements in the field, it still remains unclear whether state-of-the-art sentence embeddings can capture the fine-grained semantics of sentences, particularly when conditioned on specific perspectives. In this paper, we introduce Hyper-CL, an efficient methodology that integrates hypernetworks with contrastive learning to compute conditioned sentence representations. In our proposed approach, the hypernetwork is responsible for transforming pre-computed condition embeddings into corresponding projection layers. This enables the same sentence embeddings to be projected differently according to various conditions. Evaluation on two representative conditioning benchmarks, namely conditional semantic text similarity and knowledge graph completion, demonstrates that Hyper-CL is effective in flexibly conditioning s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#23500;&#21547;&#35821;&#20041;&#30693;&#35782;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#27604;BERT&#27169;&#22411;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.08492</link><description>&lt;p&gt;
&#23500;&#21547;&#35821;&#20041;&#30693;&#35782;&#22686;&#24378;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#23569;&#26679;&#26412;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;
&lt;/p&gt;
&lt;p&gt;
Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#23500;&#21547;&#35821;&#20041;&#30693;&#35782;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#27604;BERT&#27169;&#22411;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#19968;&#31181;&#21517;&#20026;RS-LLM&#65288;&#22522;&#20110;&#20016;&#23500;&#35821;&#20041;&#30340;LLMs&#65289;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24341;&#20837;&#20316;&#20026;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#21450;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#24341;&#20837;&#21508;&#31181;&#20013;&#25991;&#20016;&#23500;&#35821;&#20041;&#20449;&#24687;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#24341;&#20837;&#23569;&#37327;&#29305;&#23450;&#30340;&#20013;&#25991;&#20016;&#23500;&#35821;&#20041;&#32467;&#26500;&#65292;LLMs&#22312;&#23569;&#26679;&#26412;&#20013;&#25991;&#25340;&#20889;&#26816;&#26597;&#20219;&#21153;&#19978;&#27604;&#22522;&#20110;BERT&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08492v1 Announce Type: new  Abstract: Chinese Spell Checking (CSC) is a widely used technology, which plays a vital role in speech to text (STT) and optical character recognition (OCR). Most of the existing CSC approaches relying on BERT architecture achieve excellent performance. However, limited by the scale of the foundation model, BERT-based method does not work well in few-shot scenarios, showing certain limitations in practical applications. In this paper, we explore using an in-context learning method named RS-LLM (Rich Semantic based LLMs) to introduce large language models (LLMs) as the foundation model. Besides, we study the impact of introducing various Chinese rich semantic information in our framework. We found that by introducing a small number of specific Chinese rich semantic structures, LLMs achieve better performance than the BERT-based model on few-shot CSC task. Furthermore, we conduct experiments on multiple datasets, and the experimental results verifie
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#35760;&#32423;&#21035;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26032;&#22411;&#20107;&#23454;&#26680;&#26597;&#21644;&#24187;&#35273;&#26816;&#27979;&#27969;&#31243;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26816;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#19981;&#21487;&#38752;&#39044;&#27979;&#12290;</title><link>https://arxiv.org/abs/2403.04696</link><description>&lt;p&gt;
&#36890;&#36807;&#26631;&#35760;&#32423;&#21035;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26816;&#39564;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;
&lt;/p&gt;
&lt;p&gt;
Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04696
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#35760;&#32423;&#21035;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26032;&#22411;&#20107;&#23454;&#26680;&#26597;&#21644;&#24187;&#35273;&#26816;&#27979;&#27969;&#31243;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26816;&#27979;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#20013;&#30340;&#19981;&#21487;&#38752;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#20197;&#20135;&#29983;&#38169;&#35823;&#30340;&#22768;&#26126;&#32780;&#33261;&#21517;&#26157;&#33879;&#12290;&#36825;&#31181;&#24187;&#35273;&#21487;&#33021;&#24456;&#21361;&#38505;&#65292;&#22240;&#20026;&#22312;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#20598;&#23572;&#20986;&#29616;&#30340;&#20107;&#23454;&#19981;&#20934;&#30830;&#21487;&#33021;&#20250;&#34987;&#25972;&#20307;&#19978;&#26159;&#20107;&#23454;&#30340;&#25991;&#26412;&#25513;&#30422;&#65292;&#36825;&#20351;&#24471;&#29992;&#25143;&#26497;&#20854;&#38590;&#20197;&#21457;&#29616;&#12290;&#21033;&#29992;LLMs&#30340;&#24403;&#21069;&#26381;&#21153;&#36890;&#24120;&#19981;&#25552;&#20379;&#26816;&#27979;&#19981;&#21487;&#38752;&#29983;&#25104;&#30340;&#26041;&#24335;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#26088;&#22312;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26631;&#35760;&#32423;&#21035;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26032;&#22411;&#20107;&#23454;&#26680;&#26597;&#21644;&#24187;&#35273;&#26816;&#27979;&#27969;&#31243;&#12290;&#19981;&#30830;&#23450;&#24615;&#20998;&#25968;&#21033;&#29992;&#20102;&#31070;&#32463;&#32593;&#32476;&#25110;&#20854;&#23618;&#36755;&#20986;&#20013;&#21253;&#21547;&#30340;&#20449;&#24687;&#26469;&#26816;&#27979;&#19981;&#21487;&#38752;&#30340;&#39044;&#27979;&#65292;&#24182;&#25105;&#20204;&#23637;&#31034;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#26680;&#26597;LLM&#36755;&#20986;&#20013;&#30340;&#21508;&#31181;&#22768;&#26126;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#26631;&#35760;&#32423;&#21035;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#28040;&#38500;&#20102;&#23545;&#20107;&#23454;&#25552;&#20986;&#24576;&#30097;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04696v1 Announce Type: cross  Abstract: Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factual, making it extremely hard for the users to spot them. Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. Here, we aim to bridge this gap. In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification. Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output. Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what c
&lt;/p&gt;</description></item><item><title>&#31616;&#21333;&#30340;&#22522;&#20110;guardrail&#30340;&#26041;&#27861;&#22914;&#25552;&#31034;&#21644;&#36807;&#28388;&#21487;&#20197;&#23454;&#29616;&#19982;fine-tuning&#30456;&#23218;&#32654;&#30340;unlearning&#32467;&#26524;&#65292;&#24314;&#35758;&#30740;&#31350;&#20154;&#21592;&#22312;&#35780;&#20272;&#26356;&#28040;&#32791;&#35745;&#31639;&#36164;&#28304;&#30340;fine-tuning&#26041;&#27861;&#26102;&#32771;&#34385;&#36825;&#20123;&#36731;&#37327;&#32423;&#22522;&#32447;&#12290;</title><link>https://arxiv.org/abs/2403.03329</link><description>&lt;p&gt;
Guardrail Baselines for Unlearning in LLMs
&lt;/p&gt;
&lt;p&gt;
Guardrail Baselines for Unlearning in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03329
&lt;/p&gt;
&lt;p&gt;
&#31616;&#21333;&#30340;&#22522;&#20110;guardrail&#30340;&#26041;&#27861;&#22914;&#25552;&#31034;&#21644;&#36807;&#28388;&#21487;&#20197;&#23454;&#29616;&#19982;fine-tuning&#30456;&#23218;&#32654;&#30340;unlearning&#32467;&#26524;&#65292;&#24314;&#35758;&#30740;&#31350;&#20154;&#21592;&#22312;&#35780;&#20272;&#26356;&#28040;&#32791;&#35745;&#31639;&#36164;&#28304;&#30340;fine-tuning&#26041;&#27861;&#26102;&#32771;&#34385;&#36825;&#20123;&#36731;&#37327;&#32423;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;fine-tuning&#26159;&#20174;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#8220;unlearn&#8221;&#27010;&#24565;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;fine-tuning&#21487;&#33021;&#24456;&#26114;&#36149;&#65292;&#22240;&#20026;&#23427;&#26082;&#38656;&#35201;&#29983;&#25104;&#19968;&#32452;&#31034;&#20363;&#65292;&#21448;&#38656;&#35201;&#36816;&#34892;&#22810;&#27425;&#36845;&#20195;&#30340;fine-tuning&#26469;&#26356;&#26032;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31616;&#21333;&#30340;&#22522;&#20110;guardrail&#30340;&#26041;&#27861;&#65292;&#22914;&#25552;&#31034;&#21644;&#36807;&#28388;&#65292;&#21487;&#20197;&#23454;&#29616;&#19982;fine-tuning&#30456;&#23218;&#32654;&#30340;unlearning&#32467;&#26524;&#12290;&#25105;&#20204;&#24314;&#35758;&#30740;&#31350;&#20154;&#21592;&#22312;&#35780;&#20272;&#26356;&#28040;&#32791;&#35745;&#31639;&#36164;&#28304;&#30340;fine-tuning&#26041;&#27861;&#30340;&#24615;&#33021;&#26102;&#65292;&#35843;&#26597;&#36825;&#20123;&#36731;&#37327;&#32423;&#22522;&#32447;&#12290;&#34429;&#28982;&#25105;&#20204;&#24182;&#19981;&#22768;&#31216;&#25552;&#31034;&#25110;&#36807;&#28388;&#31561;&#26041;&#27861;&#26159;unlearning&#38382;&#39064;&#30340;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#25105;&#20204;&#30340;&#24037;&#20316;&#34920;&#26126;&#38656;&#35201;&#26356;&#22909;&#22320;&#21306;&#20998;guardrails&#19982;fine-tuning&#30340;&#24378;&#22823;&#20043;&#22788;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#24182;&#24378;&#35843;guardrails&#26412;&#36523;&#21487;&#33021;&#20026;unlearning&#20855;&#26377;&#20248;&#21183;&#30340;&#22330;&#26223;&#65292;&#20363;&#22914;&#29983;&#25104;&#31034;&#20363;&#29992;&#20110;fine-tuning&#25110;u
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03329v1 Announce Type: new  Abstract: Recent work has demonstrated that fine-tuning is a promising approach to `unlearn' concepts from large language models. However, fine-tuning can be expensive, as it requires both generating a set of examples and running iterations of fine-tuning to update the model. In this work, we show that simple guardrail-based approaches such as prompting and filtering can achieve unlearning results comparable to fine-tuning. We recommend that researchers investigate these lightweight baselines when evaluating the performance of more computationally intensive fine-tuning methods. While we do not claim that methods such as prompting or filtering are universal solutions to the problem of unlearning, our work suggests the need for evaluation metrics that can better separate the power of guardrails vs. fine-tuning, and highlights scenarios where guardrails themselves may be advantageous for unlearning, such as in generating examples for fine-tuning or u
&lt;/p&gt;</description></item><item><title>Agent-Pro&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#65292;&#36890;&#36807;&#31574;&#30053;&#32423;&#21035;&#30340;&#21453;&#24605;&#21644;&#20248;&#21270;&#65292;&#21487;&#20197;&#20174;&#20114;&#21160;&#32463;&#39564;&#20013;&#23398;&#20064;&#24182;&#36880;&#27493;&#25552;&#21319;&#20854;&#34892;&#20026;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.17574</link><description>&lt;p&gt;
Agent-Pro: &#36890;&#36807;&#31574;&#30053;&#32423;&#21035;&#21453;&#24605;&#21644;&#20248;&#21270;&#23398;&#20064;&#36827;&#21270;
&lt;/p&gt;
&lt;p&gt;
Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17574
&lt;/p&gt;
&lt;p&gt;
Agent-Pro&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#65292;&#36890;&#36807;&#31574;&#30053;&#32423;&#21035;&#30340;&#21453;&#24605;&#21644;&#20248;&#21270;&#65292;&#21487;&#20197;&#20174;&#20114;&#21160;&#32463;&#39564;&#20013;&#23398;&#20064;&#24182;&#36880;&#27493;&#25552;&#21319;&#20854;&#34892;&#20026;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#34920;&#29616;&#20986;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#20855;&#26377;&#24378;&#22823;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#37117;&#26159;&#29305;&#23450;&#20219;&#21153;&#27714;&#35299;&#22120;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#30340;&#25552;&#31034;&#24037;&#31243;&#65292;&#32780;&#19981;&#26159;&#33021;&#22815;&#36890;&#36807;&#20114;&#21160;&#23398;&#20064;&#21644;&#36827;&#21270;&#30340;&#20195;&#29702;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Agent-Pro&#65306;&#19968;&#31181;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#65292;&#20855;&#26377;&#31574;&#30053;&#32423;&#21035;&#30340;&#21453;&#24605;&#21644;&#20248;&#21270;&#65292;&#21487;&#20197;&#20174;&#20114;&#21160;&#32463;&#39564;&#20013;&#23398;&#20064;&#20016;&#23500;&#30340;&#19987;&#19994;&#30693;&#35782;&#65292;&#24182;&#36880;&#28176;&#25552;&#21319;&#20854;&#34892;&#20026;&#31574;&#30053;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#23427;&#28041;&#21450;&#19968;&#20010;&#21160;&#24577;&#20449;&#24565;&#29983;&#25104;&#21644;&#21453;&#24605;&#36807;&#31243;&#65292;&#29992;&#20110;&#31574;&#30053;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17574v1 Announce Type: new  Abstract: Large Language Models exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers necessitate manually crafted prompts to inform task rules and regulate LLM behaviors, inherently incapacitating to address complex dynamic scenarios e.g., large interactive games. In light of this, we propose Agent-Pro: an LLM-based Agent with Policy-level Reflection and Optimization that can learn a wealth of expertise from interactive experiences and progressively elevate its behavioral policy. Specifically, it involves a dynamic belief generation and reflection process for policy evolution. Rather than action-level reflection, Agent-Pro iteratively reflects on past trajectories and beliefs, fine-tuning its irrational beliefs for a better policy. Moreover
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21453;&#21521;&#32763;&#35793;&#26469;&#38450;&#24481;LLMs&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;&#65292;&#23558;&#29983;&#25104;&#30340;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#29992;&#20110;&#25581;&#31034;&#21407;&#22987;&#25552;&#31034;&#30340;&#23454;&#38469;&#24847;&#22270;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.16459</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#21521;&#32763;&#35793;&#38450;&#24481;LLMs&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Defending LLMs against Jailbreaking Attacks via Backtranslation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16459
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21453;&#21521;&#32763;&#35793;&#26469;&#38450;&#24481;LLMs&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;&#65292;&#23558;&#29983;&#25104;&#30340;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#29992;&#20110;&#25581;&#31034;&#21407;&#22987;&#25552;&#31034;&#30340;&#23454;&#38469;&#24847;&#22270;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#35768;&#22810;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#24050;&#32463;&#34987;&#35757;&#32451;&#25104;&#25298;&#32477;&#26377;&#23475;&#35831;&#27714;&#65292;&#20294;&#23427;&#20204;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#36825;&#31181;&#25915;&#20987;&#20250;&#37325;&#20889;&#21407;&#22987;&#25552;&#31034;&#20197;&#38544;&#34255;&#20854;&#26377;&#23475;&#24847;&#22270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#8220;&#21453;&#21521;&#32763;&#35793;&#8221;&#26469;&#38450;&#24481;LLMs&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#32473;&#23450;&#30446;&#26631;LLM&#20174;&#36755;&#20837;&#25552;&#31034;&#29983;&#25104;&#30340;&#21021;&#22987;&#21709;&#24212;&#65292;&#25105;&#20204;&#30340;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#19968;&#20010;&#35821;&#35328;&#27169;&#22411;&#26469;&#25512;&#26029;&#21487;&#20197;&#23548;&#33268;&#35813;&#21709;&#24212;&#30340;&#36755;&#20837;&#25552;&#31034;&#12290;&#25512;&#26029;&#30340;&#25552;&#31034;&#31216;&#20026;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#65292;&#20542;&#21521;&#20110;&#25581;&#31034;&#21407;&#22987;&#25552;&#31034;&#30340;&#23454;&#38469;&#24847;&#22270;&#65292;&#22240;&#20026;&#23427;&#26159;&#22522;&#20110;LLM&#30340;&#21709;&#24212;&#29983;&#25104;&#30340;&#65292;&#19981;&#26159;&#30452;&#25509;&#30001;&#25915;&#20987;&#32773;&#25805;&#32437;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20877;&#27425;&#22312;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#19978;&#36816;&#34892;&#30446;&#26631;LLM&#65292;&#22914;&#26524;&#27169;&#22411;&#25298;&#32477;&#20102;&#21453;&#21521;&#32763;&#35793;&#25552;&#31034;&#65292;&#21017;&#25298;&#32477;&#21407;&#22987;&#25552;&#31034;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#25152;&#25552;&#20986;&#30340;&#38450;&#24481;&#25514;&#26045;&#23545;&#20854;&#26377;&#25928;&#24615;&#30340;&#20960;&#20010;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16459v1 Announce Type: cross  Abstract: Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks, which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by ``backtranslation''. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the response. The inferred prompt is called the backtranslated prompt which tends to reveal the actual intent of the original prompt, since it is generated based on the LLM's response and is not directly manipulated by the attacker. We then run the target LLM again on the backtranslated prompt, and we refuse the original prompt if the model refuses the backtranslated prompt. We explain that the proposed defense provides several benefits on its effectiv
&lt;/p&gt;</description></item><item><title>&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#29992;&#25143;&#20559;&#22909;&#23545;&#40784;&#21487;&#33021;&#20250;&#23548;&#33268;&#33521;&#35821;&#26041;&#35328;&#21644;&#20840;&#29699;&#24847;&#35265;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20294;&#20063;&#25552;&#39640;&#20102;&#22810;&#31181;&#35821;&#35328;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.15018</link><description>&lt;p&gt;
LLM&#23545;&#20840;&#29699;&#34920;&#31034;&#30340;&#24847;&#22806;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Unintended Impacts of LLM Alignment on Global Representation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15018
&lt;/p&gt;
&lt;p&gt;
&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#29992;&#25143;&#20559;&#22909;&#23545;&#40784;&#21487;&#33021;&#20250;&#23548;&#33268;&#33521;&#35821;&#26041;&#35328;&#21644;&#20840;&#29699;&#24847;&#35265;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20294;&#20063;&#25552;&#39640;&#20102;&#22810;&#31181;&#35821;&#35328;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20026;&#38754;&#21521;&#29992;&#25143;&#30340;&#24212;&#29992;&#31243;&#24207;&#37096;&#32626;&#20043;&#21069;&#65292;&#24320;&#21457;&#20154;&#21592;&#36890;&#36807;&#21508;&#31181;&#31243;&#24207;&#65288;&#22914;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#23398;&#20064;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#21644;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#65289;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#29992;&#25143;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#12290;&#30446;&#21069;&#23545;&#36825;&#20123;&#31243;&#24207;&#30340;&#35780;&#20272;&#20391;&#37325;&#20110;&#36981;&#24490;&#25351;&#23548;&#12289;&#25512;&#29702;&#21644;&#30495;&#23454;&#24615;&#30340;&#22522;&#20934;&#12290;&#28982;&#32780;&#65292;&#20154;&#31867;&#20559;&#22909;&#24182;&#38750;&#26222;&#36941;&#65292;&#23545;&#29305;&#23450;&#20559;&#22909;&#38598;&#36827;&#34892;&#23545;&#40784;&#21487;&#33021;&#20250;&#20135;&#29983;&#24847;&#22806;&#24433;&#21709;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#23545;&#19977;&#20010;&#20840;&#29699;&#34920;&#31034;&#32500;&#24230;&#65306;&#33521;&#35821;&#26041;&#35328;&#12289;&#22810;&#35821;&#35328;&#33021;&#21147;&#21644;&#20840;&#29699;&#21508;&#22269;&#24847;&#35265;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#21069;&#30340;&#23545;&#40784;&#31243;&#24207;&#22312;&#33521;&#35821;&#26041;&#35328;&#21644;&#20840;&#29699;&#24847;&#35265;&#20043;&#38388;&#20135;&#29983;&#24046;&#24322;&#12290;&#25105;&#20204;&#21457;&#29616;&#23545;&#40784;&#25552;&#39640;&#20102;&#22810;&#31181;&#35821;&#35328;&#30340;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23548;&#33268;&#36825;&#20123;&#24847;&#22806;&#24433;&#21709;&#30340;&#35774;&#35745;&#20915;&#31574;&#65292;&#24182;&#20026;&#26356;&#20844;&#24179;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15018v1 Announce Type: new  Abstract: Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on benchmarks of instruction following, reasoning, and truthfulness. However, human preferences are not universal, and aligning to specific preference sets may have unintended effects. We explore how alignment impacts performance along three axes of global representation: English dialects, multilingualism, and opinions from and about countries worldwide. Our results show that current alignment procedures create disparities between English dialects and global opinions. We find alignment improves capabilities in several languages. We conclude by discussing design decisions that led to these unintended impacts and recommendations for more equitable 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24515;&#29702;&#27979;&#37327;&#23398;&#24605;&#24819;&#30340;&#20803;&#25506;&#27979;&#20195;&#29702;&#65288;MPA&#65289;&#21160;&#24577;&#35780;&#20272;&#21327;&#35758;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.14865</link><description>&lt;p&gt;
DyVal 2: &#20803;&#25506;&#27979;&#20195;&#29702;&#21160;&#24577;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24515;&#29702;&#27979;&#37327;&#23398;&#24605;&#24819;&#30340;&#20803;&#25506;&#27979;&#20195;&#29702;&#65288;MPA&#65289;&#21160;&#24577;&#35780;&#20272;&#21327;&#35758;&#65292;&#29992;&#20110;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#35780;&#20272;&#24341;&#36215;&#20102;&#31038;&#21306;&#30340;&#26497;&#22823;&#20851;&#27880;&#65292;&#22240;&#20026;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#38382;&#39064;&#12290;&#29616;&#26377;&#24037;&#20316;&#35774;&#35745;&#20102;&#20351;&#29992;&#38024;&#23545;&#29305;&#23450;&#20219;&#21153;&#30340;&#26126;&#30830;&#23450;&#20041;&#31639;&#27861;&#30340;&#35780;&#20272;&#21327;&#35758;&#65292;&#36825;&#20123;&#21327;&#35758;&#26080;&#27861;&#36731;&#26494;&#25193;&#23637;&#21040;&#19981;&#21516;&#30340;&#22330;&#26223;&#12290;&#27492;&#22806;&#65292;&#24403;&#21069;&#30340;&#35780;&#20272;&#22522;&#20934;&#21482;&#33021;&#25552;&#20379;&#25972;&#20307;&#22522;&#20934;&#32467;&#26524;&#65292;&#19981;&#33021;&#25903;&#25345;&#23545;LLMs&#33021;&#21147;&#36827;&#34892;&#32454;&#31890;&#24230;&#21644;&#22810;&#26041;&#38754;&#30340;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20803;&#25506;&#27979;&#20195;&#29702;&#65288;MPA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#24515;&#29702;&#27979;&#37327;&#23398;&#21551;&#21457;&#30340;&#36890;&#29992;&#21160;&#24577;&#35780;&#20272;&#21327;&#35758;&#65292;&#29992;&#20110;&#35780;&#20272;LLMs&#12290; MPA &#26159; DyVal 2 &#30340;&#20851;&#38190;&#32452;&#20214;&#65292;&#33258;&#28982;&#22320;&#25193;&#23637;&#20102;&#20808;&#21069;&#30340; DyVal&#12290; MPA &#35774;&#35745;&#20102;&#25506;&#27979;&#21644;&#35780;&#21028;&#20195;&#29702;&#65292;&#20197;&#33258;&#21160;&#23558;&#21407;&#22987;&#35780;&#20272;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#20010;&#26032;&#38382;&#39064;&#65292;&#36981;&#24490;&#24515;&#29702;&#27979;&#37327;&#29702;&#35770;&#22312;&#19977;&#20010;&#22522;&#26412;&#35748;&#30693;&#33021;&#21147;&#19978;&#30340;&#24212;&#29992;: &#35821;&#35328;&#29702;&#35299;&#12289;&#38382;&#39064;&#35299;&#20915;&#21644;&#39046;&#22495;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14865v1 Announce Type: cross  Abstract: Evaluation of large language models (LLMs) has raised great concerns in the community due to the issue of data contamination. Existing work designed evaluation protocols using well-defined algorithms for specific tasks, which cannot be easily extended to diverse scenarios. Moreover, current evaluation benchmarks can only provide the overall benchmark results and cannot support a fine-grained and multifaceted analysis of LLMs' abilities. In this paper, we propose meta probing agents (MPA), a general dynamic evaluation protocol inspired by psychometrics to evaluate LLMs. MPA is the key component of DyVal 2, which naturally extends the previous DyVal~\citep{zhu2023dyval}. MPA designs the probing and judging agents to automatically transform an original evaluation problem into a new one following psychometric theory on three basic cognitive abilities: language understanding, problem solving, and domain knowledge. These basic abilities are 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21382;&#21490;&#38142;&#25512;&#29702;&#26469;&#22686;&#24378;&#26102;&#38388;&#30693;&#35782;&#22270;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#21033;&#29992;&#39640;&#38454;&#21382;&#21490;&#20449;&#24687;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#22411;&#22312;&#22788;&#29702;&#21382;&#21490;&#20449;&#24687;&#21644;&#26102;&#38388;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#19981;&#36275;&#12290;</title><link>https://arxiv.org/abs/2402.14382</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#21382;&#21490;&#38142;&#25512;&#29702;&#22686;&#24378;&#26102;&#38388;&#30693;&#35782;&#22270;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Enhancing Temporal Knowledge Graph Forecasting with Large Language Models via Chain-of-History Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14382
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21382;&#21490;&#38142;&#25512;&#29702;&#26469;&#22686;&#24378;&#26102;&#38388;&#30693;&#35782;&#22270;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#21033;&#29992;&#39640;&#38454;&#21382;&#21490;&#20449;&#24687;&#65292;&#24357;&#34917;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27169;&#22411;&#22312;&#22788;&#29702;&#21382;&#21490;&#20449;&#24687;&#21644;&#26102;&#38388;&#25512;&#29702;&#33021;&#21147;&#26041;&#38754;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#30693;&#35782;&#22270;&#65288;TKG&#65289;&#39044;&#27979;&#26088;&#22312;&#22522;&#20110;&#32473;&#23450;&#21382;&#21490;&#25968;&#25454;&#39044;&#27979;&#26410;&#26469;&#20107;&#23454;&#12290; &#26368;&#36817;&#30340;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#25797;&#38271;&#25429;&#25417;TKGs&#20013;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#20294;&#32570;&#20047;&#35821;&#20041;&#29702;&#35299;&#33021;&#21147;&#12290;&#22914;&#20170;&#65292;&#38543;&#30528;LLMs&#30340;&#28608;&#22686;&#65292;&#22522;&#20110;LLMs&#30340;TKG&#39044;&#27979;&#27169;&#22411;&#24050;&#32463;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;LLMs&#30340;&#27169;&#22411;&#23384;&#22312;&#19977;&#20010;&#32570;&#28857;&#65306;&#65288;1&#65289;&#23427;&#21482;&#20851;&#27880;&#31532;&#19968;&#38454;&#21382;&#21490;&#20197;&#36827;&#34892;&#39044;&#27979;&#65292;&#32780;&#24573;&#30053;&#20102;&#39640;&#38454;&#21382;&#21490;&#20449;&#24687;&#65292;&#23548;&#33268;&#25552;&#20379;&#32473;LLMs&#30340;&#20449;&#24687;&#26497;&#20026;&#26377;&#38480;&#12290;&#65288;2&#65289;&#22312;&#22823;&#37327;&#21382;&#21490;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;LLMs&#24456;&#38590;&#36798;&#21040;&#26368;&#20339;&#25512;&#29702;&#24615;&#33021;&#12290;&#65288;3&#65289;&#23545;&#20110;TKG&#39044;&#27979;&#65292;&#21333;&#29420;&#20351;&#29992;LLM&#30340;&#26102;&#38388;&#25512;&#29702;&#33021;&#21147;&#26377;&#38480;&#12290;&#20026;&#24212;&#23545;&#21069;&#20004;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21382;&#21490;&#38142;&#65288;CoH&#65289;&#25512;&#29702;&#65292;&#36880;&#27493;&#25506;&#32034;&#39640;&#38454;&#21382;&#21490;&#65292;&#23454;&#29616;LLMs&#23545;TKGs&#19978;&#39640;&#38454;&#21382;&#21490;&#20449;&#24687;&#30340;&#26377;&#25928;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14382v1 Announce Type: new  Abstract: Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has emerged. However, the existing LLM-based model exhibits three shortcomings: (1) It only focuses on the first-order history for prediction while ignoring high-order historical information, resulting in the provided information for LLMs being extremely limited. (2) LLMs struggle with optimal reasoning performance under heavy historical information loads. (3) For TKG prediction, the temporal reasoning capability of LLM alone is limited. To address the first two challenges, we propose Chain-of-History (CoH) reasoning which explores high-order histories step-by-step, achieving effective utilization of high-order historical information for LLMs on TK
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#32500;&#20998;&#26512;&#21457;&#29616;&#65292;&#31034;&#33539;&#30340;&#26377;&#25928;&#24615;&#22312;&#22810;&#35821;&#31181;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#20854;&#20013;&#37096;&#20998;&#27169;&#22411;&#23545;&#31034;&#33539;&#36136;&#37327;&#19981;&#25935;&#24863;&#65292;&#32780;&#31934;&#24515;&#35774;&#35745;&#30340;&#27169;&#26495;&#21487;&#20197;&#28040;&#38500;&#23545;&#31034;&#33539;&#30340;&#20381;&#36182;&#12290;</title><link>https://arxiv.org/abs/2402.12976</link><description>&lt;p&gt;
&#31034;&#33539;&#23545;&#22810;&#35821;&#22659;&#23398;&#20064;&#30340;&#24433;&#21709;&#65306;&#22810;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
The Impact of Demonstrations on Multilingual In-Context Learning: A Multidimensional Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12976
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#32500;&#20998;&#26512;&#21457;&#29616;&#65292;&#31034;&#33539;&#30340;&#26377;&#25928;&#24615;&#22312;&#22810;&#35821;&#31181;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#20854;&#20013;&#37096;&#20998;&#27169;&#22411;&#23545;&#31034;&#33539;&#36136;&#37327;&#19981;&#25935;&#24863;&#65292;&#32780;&#31934;&#24515;&#35774;&#35745;&#30340;&#27169;&#26495;&#21487;&#20197;&#28040;&#38500;&#23545;&#31034;&#33539;&#30340;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#65292;&#31034;&#33539;&#32463;&#24120;&#34987;&#29992;&#20316;&#25512;&#29702;&#31574;&#30053;&#65292;&#22312;&#27492;&#31574;&#30053;&#20013;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20165;&#20351;&#29992;&#23569;&#37327;&#26631;&#35760;&#30340;&#31034;&#33539;&#26469;&#35299;&#20915;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#21442;&#25968;&#26356;&#26032;&#12290;&#19982;&#21333;&#35821;&#35328;&#65288;&#33521;&#35821;&#65289;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#30740;&#31350;&#30456;&#27604;&#65292;&#22810;&#35821;&#31181;&#19978;&#19979;&#25991;&#23398;&#20064;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#65292;&#25105;&#20204;&#32570;&#20047;&#23545;&#35813;&#29615;&#22659;&#20013;&#31034;&#33539;&#20316;&#29992;&#30340;&#28145;&#20837;&#29702;&#35299;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#23545;&#22810;&#35821;&#22659;&#23398;&#20064;&#36827;&#34892;&#20102;&#22810;&#32500;&#20998;&#26512;&#65292;&#23454;&#39564;&#37319;&#29992;&#20102;&#26469;&#33258;&#19981;&#21516;&#27169;&#22411;&#23478;&#26063;&#30340;5&#20010;&#27169;&#22411;&#65292;&#28085;&#30422;&#20102;&#21253;&#25324;&#20998;&#31867;&#21644;&#29983;&#25104;&#20219;&#21153;&#22312;&#20869;&#30340;9&#20010;&#25968;&#25454;&#38598;&#65292;&#35206;&#30422;&#20102;56&#31181;&#31867;&#22411;&#19978;&#19981;&#21516;&#30340;&#35821;&#35328;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31034;&#33539;&#30340;&#26377;&#25928;&#24615;&#22312;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35821;&#35328;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;Llama 2-Chat&#12289;GPT-3.5&#21644;GPT-4&#23545;&#31034;&#33539;&#36136;&#37327;&#30340;&#25935;&#24863;&#24230;&#36739;&#20302;&#12290;&#30456;&#21453;&#65292;&#31934;&#24515;&#35774;&#35745;&#30340;&#27169;&#26495;&#24448;&#24448;&#20250;&#28040;&#38500;&#19968;&#20123;&#27169;&#22411;&#23545;&#31034;&#33539;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12976v1 Announce Type: cross  Abstract: In-context learning is a popular inference strategy where large language models solve a task using only a few labelled demonstrations without needing any parameter updates. Compared to work on monolingual (English) in-context learning, multilingual in-context learning is under-explored, and we lack an in-depth understanding of the role of demonstrations in this context. To address this gap, we conduct a multidimensional analysis of multilingual in-context learning, experimenting with 5 models from different model families, 9 datasets covering classification and generation tasks, and 56 typologically diverse languages. Our results reveal that the effectiveness of demonstrations varies significantly across models, tasks, and languages. We also find that Llama 2-Chat, GPT-3.5, and GPT-4 are largely insensitive to the quality of demonstrations. Instead, a carefully crafted template often eliminates the benefits of demonstrations for some t
&lt;/p&gt;</description></item><item><title>EmoBench&#26159;&#19968;&#20010;&#22522;&#20110;&#24515;&#29702;&#23398;&#29702;&#35770;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#24863;&#26234;&#33021;&#65292;&#21253;&#25324;&#24773;&#24863;&#29702;&#35299;&#21644;&#24773;&#24863;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.12071</link><description>&lt;p&gt;
EmoBench: &#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#24863;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
EmoBench: Evaluating the Emotional Intelligence of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12071
&lt;/p&gt;
&lt;p&gt;
EmoBench&#26159;&#19968;&#20010;&#22522;&#20110;&#24515;&#29702;&#23398;&#29702;&#35770;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#26088;&#22312;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24773;&#24863;&#26234;&#33021;&#65292;&#21253;&#25324;&#24773;&#24863;&#29702;&#35299;&#21644;&#24773;&#24863;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24555;&#36895;&#21457;&#23637;&#20984;&#26174;&#20102;&#38656;&#35201;&#31283;&#20581;&#12289;&#20840;&#38754;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22522;&#20934;&#27979;&#35797;&#30340;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#23427;&#20204;&#30340;&#24773;&#24863;&#26234;&#33021;&#65288;EI&#65289;&#36827;&#34892;&#35780;&#20272;&#30340;&#30740;&#31350;&#30456;&#24403;&#26377;&#38480;&#12290;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#32570;&#28857;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#20027;&#35201;&#20851;&#27880;&#24773;&#24863;&#35782;&#21035;&#65292;&#24573;&#35270;&#20102;&#24773;&#24863;&#35843;&#33410;&#31561;&#37325;&#35201;&#30340;&#24773;&#24863;&#26234;&#33021;&#33021;&#21147;&#65292;&#32780;&#24773;&#24863;&#29702;&#35299;&#21017;&#20419;&#36827;&#24773;&#24863;; &#20854;&#27425;&#65292;&#23427;&#20204;&#20027;&#35201;&#22522;&#20110;&#29616;&#26377;&#25968;&#25454;&#38598;&#26500;&#24314;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#21547;&#39057;&#32321;&#27169;&#24335;&#12289;&#26126;&#30830;&#20449;&#24687;&#21644;&#27880;&#37322;&#38169;&#35823;&#65292;&#23548;&#33268;&#35780;&#20272;&#19981;&#21487;&#38752;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EmoBench&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20934;&#27979;&#35797;&#65292;&#20511;&#37492;&#20102;&#24050;&#24314;&#31435;&#30340;&#24515;&#29702;&#29702;&#35770;&#65292;&#24182;&#20026;&#26426;&#22120;EI&#25552;&#20986;&#20102;&#32508;&#21512;&#23450;&#20041;&#65292;&#21253;&#25324;&#24773;&#24863;&#29702;&#35299;&#21644;&#24773;&#24863;&#24212;&#29992;&#12290;EmoBench&#21253;&#25324;&#19968;&#32452;400&#20010;&#29992;&#33521;&#35821;&#21644;&#20013;&#25991;&#25163;&#24037;&#21046;&#20316;&#30340;&#38382;&#39064;&#65292;&#32463;&#36807;&#31934;&#24515;&#35774;&#35745;&#65292;&#38656;&#35201;&#28145;&#20837;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12071v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have highlighted the need for robust, comprehensive, and challenging benchmarks. Yet, research on evaluating their Emotional Intelligence (EI) is considerably limited. Existing benchmarks have two major shortcomings: first, they mainly focus on emotion recognition, neglecting essential EI capabilities such as emotion regulation and thought facilitation through emotion understanding; second, they are primarily constructed from existing datasets, which include frequent patterns, explicit information, and annotation errors, leading to unreliable evaluation. We propose EmoBench, a benchmark that draws upon established psychological theories and proposes a comprehensive definition for machine EI, including Emotional Understanding and Emotional Application. EmoBench includes a set of 400 hand-crafted questions in English and Chinese, which are meticulously designed to require thorough reasoning
&lt;/p&gt;</description></item><item><title>&#24503;&#35821;&#26041;&#35328;&#21644;&#21306;&#22495;&#35821;&#35328;&#35828;&#35805;&#32773;&#26356;&#20542;&#21521;&#20110;&#25903;&#25345;&#33021;&#22815;&#22788;&#29702;&#26041;&#35328;&#36755;&#20837;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#65292;&#27604;&#22914;&#34394;&#25311;&#21161;&#25163;&#65292;&#23545;&#20110;&#20135;&#29983;&#26041;&#35328;&#36755;&#20986;&#30340;&#24212;&#29992;&#21017;&#25903;&#25345;&#31243;&#24230;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>https://arxiv.org/abs/2402.11968</link><description>&lt;p&gt;
&#26041;&#35328;&#35828;&#35805;&#32773;&#26377;&#20160;&#20040;&#38656;&#27714;&#65311;&#24503;&#35821;&#26041;&#35328;&#35821;&#35328;&#25216;&#26415;&#24577;&#24230;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
What Do Dialect Speakers Want? A Survey of Attitudes Towards Language Technology for German Dialects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11968
&lt;/p&gt;
&lt;p&gt;
&#24503;&#35821;&#26041;&#35328;&#21644;&#21306;&#22495;&#35821;&#35328;&#35828;&#35805;&#32773;&#26356;&#20542;&#21521;&#20110;&#25903;&#25345;&#33021;&#22815;&#22788;&#29702;&#26041;&#35328;&#36755;&#20837;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24037;&#20855;&#65292;&#27604;&#22914;&#34394;&#25311;&#21161;&#25163;&#65292;&#23545;&#20110;&#20135;&#29983;&#26041;&#35328;&#36755;&#20986;&#30340;&#24212;&#29992;&#21017;&#25903;&#25345;&#31243;&#24230;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20027;&#35201;&#38598;&#20013;&#20110;&#23545;&#26631;&#20934;&#21270;&#35821;&#35328;&#36827;&#34892;&#24314;&#27169;&#12290;&#26368;&#36817;&#65292;&#20851;&#27880;&#28857;&#36880;&#28176;&#36716;&#21521;&#20102;&#26412;&#22320;&#12289;&#38750;&#26631;&#20934;&#21270;&#35821;&#35328;&#21644;&#26041;&#35328;&#12290;&#28982;&#32780;&#65292;&#19982;NLP&#24037;&#20855;&#30456;&#20851;&#30340;&#35828;&#35805;&#32773;&#32676;&#20307;&#30340;&#38656;&#27714;&#21644;&#24895;&#26395;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#26159;&#26410;&#30693;&#30340;&#12290;&#26412;&#25991;&#20851;&#27880;&#24503;&#35821;&#26041;&#35328;&#21644;&#21306;&#22495;&#35821;&#35328;&#65292;&#36825;&#26159;&#19968;&#32452;&#22312;&#22768;&#26395;&#21644;&#26631;&#20934;&#21270;&#26041;&#38754;&#24322;&#36136;&#24615;&#30340;&#35821;&#35328;&#21464;&#20307;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#35821;&#35328;&#21464;&#20307;&#30340;&#35828;&#35805;&#32773;&#36827;&#34892;&#20102;&#35843;&#26597;&#65288;N=327&#65289;&#65292;&#24182;&#20171;&#32461;&#20102;&#20182;&#20204;&#23545;&#20110;&#20182;&#20204;&#26041;&#35328;&#30340;&#20551;&#24819;&#35821;&#35328;&#25216;&#26415;&#30340;&#24847;&#35265;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#21463;&#35775;&#32773;&#23376;&#32676;&#20307;&#20043;&#38388;&#30340;&#24577;&#24230;&#26377;&#25152;&#19981;&#21516;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#21463;&#35775;&#32773;&#29305;&#21035;&#25903;&#25345;&#33021;&#22815;&#22788;&#29702;&#26041;&#35328;&#36755;&#20837;&#30340;&#28508;&#22312;NLP&#24037;&#20855;&#65288;&#29305;&#21035;&#26159;&#38899;&#39057;&#36755;&#20837;&#65289;&#65292;&#27604;&#22914;&#34394;&#25311;&#21161;&#25163;&#65292;&#32780;&#23545;&#20110;&#20135;&#29983;&#26041;&#35328;&#36755;&#20986;&#30340;&#24212;&#29992;&#65292;&#27604;&#22914;&#26426;&#22120;&#32763;&#35793;&#25110;&#25340;&#20889;&#26816;&#26597;&#31243;&#24207;&#65292;&#25903;&#25345;&#31243;&#24230;&#35201;&#20302;&#19968;&#20123;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11968v1 Announce Type: new  Abstract: Natural language processing (NLP) has largely focused on modelling standardized languages. More recently, attention has increasingly shifted to local, non-standardized languages and dialects. However, the relevant speaker populations' needs and wishes with respect to NLP tools are largely unknown. In this paper, we focus on dialects and regional languages related to German -- a group of varieties that is heterogeneous in terms of prestige and standardization. We survey speakers of these varieties (N=327) and present their opinions on hypothetical language technologies for their dialects. Although attitudes vary among subgroups of our respondents, we find that respondents are especially in favour of potential NLP tools that work with dialectal input (especially audio input) such as virtual assistants, and less so for applications that produce dialectal output such as machine translation or spellcheckers.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;ASCII&#33402;&#26415;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#20197;&#21450;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#35782;&#21035;&#38750;&#32431;&#35821;&#20041;&#25552;&#31034;&#26041;&#38754;&#33021;&#21147;&#30340;&#22522;&#20934;&#25361;&#25112;&#12290;&#20116;&#20010;SOTA LLMs&#22312;&#35782;&#21035;ASCII&#33402;&#26415;&#25552;&#31034;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;</title><link>https://arxiv.org/abs/2402.11753</link><description>&lt;p&gt;
ArtPrompt: &#22522;&#20110;ASCII&#33402;&#26415;&#30340;&#23545;&#40784;LLMs&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11753
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;ASCII&#33402;&#26415;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#20197;&#21450;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#35782;&#21035;&#38750;&#32431;&#35821;&#20041;&#25552;&#31034;&#26041;&#38754;&#33021;&#21147;&#30340;&#22522;&#20934;&#25361;&#25112;&#12290;&#20116;&#20010;SOTA LLMs&#22312;&#35782;&#21035;ASCII&#33402;&#26415;&#25552;&#31034;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#23545;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#22810;&#31181;&#25216;&#26415;&#65292;&#22914;&#25968;&#25454;&#36807;&#28388;&#21644;&#30417;&#30563;&#24494;&#35843;&#65292;&#20197;&#21152;&#24378;LLMs&#30340;&#23433;&#20840;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#24050;&#30693;&#30340;&#25216;&#26415;&#20551;&#35774;&#29992;&#20110;&#23545;&#40784;LLMs&#23433;&#20840;&#24615;&#30340;&#35821;&#26009;&#24211;&#20165;&#30001;&#35821;&#20041;&#36827;&#34892;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#36825;&#19968;&#20551;&#35774;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#19981;&#25104;&#31435;&#65292;&#23548;&#33268;LLMs&#23384;&#22312;&#20005;&#37325;&#28431;&#27934;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;ASCII&#33402;&#26415;&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#22522;&#20934;Vision-in-Text Challenge&#65288;ViTC&#65289;&#26469;&#35780;&#20272;LLMs&#22312;&#35782;&#21035;&#19981;&#33021;&#20165;&#36890;&#36807;&#35821;&#20041;&#36827;&#34892;&#35299;&#37322;&#30340;&#25552;&#31034;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20116;&#20010;SOTA LLMs&#65288;GPT-3.5&#12289;GPT-4&#12289;Gemini&#12289;Claude&#21644;Llama2&#65289;&#22312;&#35782;&#21035;&#20197;ASCII&#33402;&#26415;&#24418;&#24335;&#25552;&#20379;&#30340;&#25552;&#31034;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11753v1 Announce Type: cross  Abstract: Safety is critical to the usage of large language models (LLMs). Multiple techniques such as data filtering and supervised fine-tuning have been developed to strengthen LLM safety. However, currently known techniques presume that corpora used for safety alignment of LLMs are solely interpreted by semantics. This assumption, however, does not hold in real-world applications, which leads to severe vulnerabilities in LLMs. For example, users of forums often use ASCII art, a form of text-based art, to convey image information. In this paper, we propose a novel ASCII art-based jailbreak attack and introduce a comprehensive benchmark Vision-in-Text Challenge (ViTC) to evaluate the capabilities of LLMs in recognizing prompts that cannot be solely interpreted by semantics. We show that five SOTA LLMs (GPT-3.5, GPT-4, Gemini, Claude, and Llama2) struggle to recognize prompts provided in the form of ASCII art. Based on this observation, we devel
&lt;/p&gt;</description></item><item><title>GNNavi&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#25552;&#31034;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#26041;&#27861;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23618;&#65292;&#20934;&#30830;&#24341;&#23548;&#20449;&#24687;&#27969;&#30340;&#27719;&#32858;&#21644;&#20998;&#24067;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23548;&#33322;&#20449;&#24687;&#27969;&#21160;&#24577;&#65292;&#36229;&#36234;&#20102;&#26631;&#20934;&#25552;&#31034;&#24335;&#24494;&#35843;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.11709</link><description>&lt;p&gt;
GNNavi&#65306;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#23548;&#33322;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20449;&#24687;&#27969;
&lt;/p&gt;
&lt;p&gt;
GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11709
&lt;/p&gt;
&lt;p&gt;
GNNavi&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#25552;&#31034;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#26041;&#27861;&#21644;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23618;&#65292;&#20934;&#30830;&#24341;&#23548;&#20449;&#24687;&#27969;&#30340;&#27719;&#32858;&#21644;&#20998;&#24067;&#65292;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23548;&#33322;&#20449;&#24687;&#27969;&#21160;&#24577;&#65292;&#36229;&#36234;&#20102;&#26631;&#20934;&#25552;&#31034;&#24335;&#24494;&#35843;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25509;&#25910;&#31034;&#33539;&#36755;&#20837;&#26102;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65288;ICL&#65289;&#12290;&#28982;&#32780;&#65292;&#24494;&#35843;&#20173;&#28982;&#33267;&#20851;&#37325;&#35201;&#20197;&#36827;&#19968;&#27493;&#22686;&#24378;&#20854;&#36866;&#24212;&#24615;&#12290;&#22522;&#20110;&#25552;&#31034;&#30340;&#24494;&#35843;&#26041;&#27861;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#20294;&#23545;&#35745;&#31639;&#36164;&#28304;&#30340;&#39640;&#38656;&#27714;&#38480;&#21046;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#25552;&#31034;&#30340;&#21442;&#25968;&#39640;&#25928;&#24494;&#35843;&#65288;PEFT&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;GNNavi&#21033;&#29992;&#20102;&#26377;&#20851;ICL&#20449;&#24687;&#27969;&#21160;&#24577;&#30340;&#35265;&#35299;&#65292;&#34920;&#26126;&#26631;&#31614;&#35789;&#22312;&#25552;&#31034;&#20013;&#20316;&#20026;&#20449;&#24687;&#20256;&#25773;&#30340;&#38170;&#28857;&#12290;GNNavi&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#23618;&#31934;&#30830;&#22320;&#24341;&#23548;&#20449;&#24687;&#27969;&#30340;&#27719;&#32858;&#21644;&#20998;&#24067;&#65292;&#22312;&#22788;&#29702;&#25552;&#31034;&#26102;&#23558;&#26399;&#26395;&#30340;&#20449;&#24687;&#27969;&#30828;&#32534;&#30721;&#21040;GNN&#20013;&#12290;&#25105;&#20204;&#22312;&#20351;&#29992;GPT-2&#21644;Llama2&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#20219;&#21153;&#30340;&#23454;&#39564;&#20013;&#21457;&#29616;&#65292;GNNavi&#36229;&#36234;&#20102;&#26631;&#20934;&#25552;&#31034;&#24335;&#24494;&#35843;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11709v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit strong In-Context Learning (ICL) capabilities when prompts with demonstrations are applied to them. However, fine-tuning still remains crucial to further enhance their adaptability. Prompt-based fine-tuning proves to be an effective fine-tuning method in low-data scenarios, but high demands on computing resources limit its practicality. We address this issue by introducing a prompt-based parameter-efficient fine-tuning (PEFT) approach. GNNavi leverages insights into ICL's information flow dynamics, which indicates that label words act in prompts as anchors for information propagation. GNNavi employs a Graph Neural Network (GNN) layer to precisely guide the aggregation and distribution of information flow during the processing of prompts by hardwiring the desired information flow into the GNN. Our experiments on text classification tasks with GPT-2 and Llama2 shows GNNavi surpasses standard prompt-ba
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#26426;&#21046;&#20043;&#20105;&#30340;&#27010;&#24565;&#65292;&#20851;&#27880;&#35821;&#35328;&#27169;&#22411;&#20013;&#22810;&#20010;&#26426;&#21046;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25581;&#31034;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#31454;&#20105;&#36807;&#31243;&#65292;&#20197;&#21450;&#24433;&#21709;&#26576;&#20123;&#26426;&#21046;&#24378;&#24230;&#30340;&#27880;&#24847;&#21147;&#20301;&#32622;&#12290;</title><link>https://arxiv.org/abs/2402.11655</link><description>&lt;p&gt;
&#26426;&#21046;&#20043;&#20105;&#65306;&#36861;&#36394;&#35821;&#35328;&#27169;&#22411;&#22788;&#29702;&#20107;&#23454;&#21644;&#34394;&#25311;&#35821;&#22659;&#30340;&#26041;&#24335;
&lt;/p&gt;
&lt;p&gt;
Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#26426;&#21046;&#20043;&#20105;&#30340;&#27010;&#24565;&#65292;&#20851;&#27880;&#35821;&#35328;&#27169;&#22411;&#20013;&#22810;&#20010;&#26426;&#21046;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25581;&#31034;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#31454;&#20105;&#36807;&#31243;&#65292;&#20197;&#21450;&#24433;&#21709;&#26576;&#20123;&#26426;&#21046;&#24378;&#24230;&#30340;&#27880;&#24847;&#21147;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#30740;&#31350;&#26088;&#22312;&#24357;&#21512;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#32463;&#39564;&#25104;&#21151;&#21644;&#25105;&#20204;&#23545;&#20869;&#37096;&#26426;&#21046;&#30340;&#31185;&#23398;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#26426;&#21046;&#20043;&#20105;&#30340;&#24418;&#24335;&#65292;&#20854;&#19981;&#20877;&#20851;&#27880;&#21333;&#20010;&#26426;&#21046;&#65292;&#32780;&#26159;&#20851;&#27880;&#22810;&#20010;&#26426;&#21046;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#36861;&#36394;&#20854;&#20013;&#19968;&#20010;&#22312;&#26368;&#32456;&#39044;&#27979;&#20013;&#22914;&#20309;&#25104;&#20026;&#20027;&#23548;&#22240;&#32032;&#12290;&#25105;&#20204;&#21033;&#29992;logit&#26816;&#39564;&#21644;&#27880;&#24847;&#21147;&#20462;&#25913;&#20004;&#31181;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#25581;&#31034;&#20102;&#26426;&#21046;&#20043;&#20105;&#22312;LLMs&#20013;&#30340;&#21457;&#29983;&#26041;&#24335;&#21644;&#20301;&#32622;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26174;&#31034;&#20102;&#26426;&#21046;&#21450;&#20854;&#22312;&#21508;&#31181;&#27169;&#22411;&#32452;&#20214;&#20013;&#30340;&#31454;&#20105;&#30165;&#36857;&#65292;&#24182;&#25581;&#31034;&#20102;&#26377;&#25928;&#25511;&#21046;&#29305;&#23450;&#26426;&#21046;&#24378;&#24230;&#30340;&#27880;&#24847;&#21147;&#20301;&#32622;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#25968;&#25454;&#20301;&#20110;https://github.com/francescortu/Competition_of
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11655v1 Announce Type: new  Abstract: Interpretability research aims to bridge the gap between the empirical success and our scientific understanding of the inner workings of large language models (LLMs). However, most existing research in this area focused on analyzing a single mechanism, such as how models copy or recall factual knowledge. In this work, we propose the formulation of competition of mechanisms, which instead of individual mechanisms focuses on the interplay of multiple mechanisms, and traces how one of them becomes dominant in the final prediction. We uncover how and where the competition of mechanisms happens within LLMs using two interpretability methods, logit inspection and attention modification. Our findings show traces of the mechanisms and their competition across various model components, and reveal attention positions that effectively control the strength of certain mechanisms. Our code and data are at https://github.com/francescortu/Competition_of
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#25991;&#26412;&#24341;&#23548;&#30340;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#26694;&#26550;CFT-CLIP&#65292;&#29992;&#20110;&#22686;&#24378;&#26032;&#38395;&#25991;&#26412;&#21644;&#32553;&#30053;&#22270;&#20043;&#38388;&#30340;&#23545;&#27604;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.11159</link><description>&lt;p&gt;
&#36890;&#36807;&#21453;&#20107;&#23454;&#25991;&#26412;&#24341;&#23548;&#30340;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#26469;&#29702;&#35299;&#26032;&#38395;&#32553;&#30053;&#22270;&#30340;&#20195;&#34920;&#24615;
&lt;/p&gt;
&lt;p&gt;
Understanding News Thumbnail Representativeness by Counterfactual Text-Guided Contrastive Language-Image Pretraining
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11159
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#25991;&#26412;&#24341;&#23548;&#30340;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#26694;&#26550;CFT-CLIP&#65292;&#29992;&#20110;&#22686;&#24378;&#26032;&#38395;&#25991;&#26412;&#21644;&#32553;&#30053;&#22270;&#20043;&#38388;&#30340;&#23545;&#27604;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#29702;&#35299;&#26032;&#38395;&#32553;&#30053;&#22270;&#30340;&#20195;&#34920;&#24615;&#36825;&#19968;&#20851;&#38190;&#25361;&#25112;&#65292;&#36825;&#20123;&#32553;&#30053;&#22270;&#36890;&#24120;&#22312;&#25991;&#31456;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#20256;&#25773;&#26102;&#20316;&#20026;&#35835;&#32773;&#30340;&#31532;&#19968;&#20010;&#35270;&#35273;&#21442;&#19982;&#12290;&#25105;&#20204;&#20851;&#27880;&#26032;&#38395;&#22270;&#20687;&#26159;&#21542;&#20195;&#34920;&#26032;&#38395;&#25991;&#26412;&#20013;&#35752;&#35770;&#30340;&#20027;&#35201;&#20027;&#39064;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#25163;&#21160;&#27880;&#37322;&#30340;&#26032;&#38395;&#32553;&#30053;&#22270;&#21644;&#25991;&#26412;&#37197;&#23545;&#25968;&#25454;&#38598;\textsc{NewsTT}&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20363;&#22914;CLIP&#21644;BLIP-2&#36825;&#26679;&#30340;&#39044;&#35757;&#32451;&#35270;&#35273;&#21644;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#19968;&#20219;&#21153;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#30001;&#20110;&#26032;&#38395;&#20027;&#39064;&#32463;&#24120;&#28041;&#21450;&#21629;&#21517;&#23454;&#20307;&#25110;&#19987;&#26377;&#21517;&#35789;&#65292;&#39044;&#35757;&#32451;&#27169;&#22411;&#32570;&#20047;&#21305;&#37197;&#20854;&#35270;&#35273;&#21644;&#25991;&#26412;&#22806;&#35266;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CFT-CLIP&#65292;&#19968;&#20010;&#21453;&#20107;&#23454;&#25991;&#26412;&#24341;&#23548;&#30340;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11159v1 Announce Type: new  Abstract: This paper delves into the critical challenge of understanding the representativeness of news thumbnail images, which often serve as the first visual engagement for readers when an article is disseminated on social media. We focus on whether a news image represents the main subject discussed in the news text. To serve the challenge, we introduce \textsc{NewsTT}, a manually annotated dataset of news thumbnail image and text pairs. We found that pretrained vision and language models, such as CLIP and BLIP-2, struggle with this task. Since news subjects frequently involve named entities or proper nouns, a pretrained model could not have the ability to match its visual and textual appearances. To fill the gap, we propose CFT-CLIP, a counterfactual text-guided contrastive language-image pretraining framework. We hypothesize that learning to contrast news text with its counterfactual, of which named entities are replaced, can enhance the cross
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20316;&#27969;&#33539;&#24335;&#26041;&#27861;&#26469;&#25913;&#21892;LLMs&#22312;&#25991;&#26412;&#21040;SQL&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#36890;&#36807;&#20998;&#35299;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#27880;&#24847;&#21147;&#21644;&#38382;&#39064;&#35299;&#20915;&#33539;&#22260;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#30340;&#19978;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.10671</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#35299;&#26469;&#22686;&#24378;&#27880;&#24847;&#21147;&#65306;&#36890;&#36807;&#24037;&#20316;&#27969;&#33539;&#24335;&#25913;&#36827;&#22522;&#20110;LLM&#30340;&#25991;&#26412;&#21040;SQL&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10671
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20316;&#27969;&#33539;&#24335;&#26041;&#27861;&#26469;&#25913;&#21892;LLMs&#22312;&#25991;&#26412;&#21040;SQL&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#36890;&#36807;&#20998;&#35299;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#27880;&#24847;&#21147;&#21644;&#38382;&#39064;&#35299;&#20915;&#33539;&#22260;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#22522;&#20110;LLM&#30340;&#26041;&#27861;&#30340;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#21151;&#65292;&#32780;&#24191;&#27867;&#30340;&#26696;&#20363;&#30740;&#31350;&#34920;&#26126;&#65292;&#21333;&#27493;&#38142;&#24335;&#24605;&#32500;&#25552;&#31034;&#26041;&#27861;&#22312;&#22797;&#26434;&#20219;&#21153;&#65288;&#22914;&#25991;&#26412;&#21040;SQL&#65289;&#20013;&#38754;&#20020;&#27880;&#24847;&#21147;&#25193;&#25955;&#21644;&#24615;&#33021;&#19981;&#36275;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#25913;&#21892;LLMs&#22312;&#25991;&#26412;&#21040;SQL&#20013;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#33021;&#21147;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24037;&#20316;&#27969;&#33539;&#24335;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#20998;&#35299;&#22686;&#24378;LLMs&#30340;&#27880;&#24847;&#21147;&#21644;&#38382;&#39064;&#35299;&#20915;&#33539;&#22260;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#29992;&#20110;&#28040;&#38500;&#20887;&#20313;&#20449;&#24687;&#30340;&#20449;&#24687;&#30830;&#23450;&#27169;&#22359;&#21644;&#22522;&#20110;&#38382;&#39064;&#20998;&#31867;&#30340;&#20840;&#26032;&#25552;&#31034;&#32467;&#26500;&#26497;&#22823;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#27880;&#24847;&#21147;&#12290;&#27492;&#22806;&#65292;&#24341;&#20837;&#33258;&#26657;&#27491;&#21644;&#20027;&#21160;&#23398;&#20064;&#27169;&#22359;&#26497;&#22823;&#25193;&#23637;&#20102;LLMs&#30340;&#38382;&#39064;&#35299;&#20915;&#33539;&#22260;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22522;&#20110;LLM&#26041;&#27861;&#30340;&#19978;&#38480;&#12290;&#22312;&#19977;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10671v1 Announce Type: new  Abstract: In-context learning of large-language models (LLMs) has achieved remarkable success in the field of natural language processing, while extensive case studies reveal that the single-step chain-of-thought prompting approach faces challenges such as attention diffusion and inadequate performance in complex tasks like text-to-SQL. To improve the contextual learning capabilities of LLMs in text-to-SQL, a workflow paradigm method is proposed, aiming to enhance the attention and problem-solving scope of LLMs through decomposition. Specifically, the information determination module for eliminating redundant information and the brand-new prompt structure based on problem classification greatly enhance the model's attention. Additionally, the inclusion of self-correcting and active learning modules greatly expands the problem-solving scope of LLMs, hence improving the upper limit of LLM-based approaches. Extensive experiments conducted on three da
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#30740;&#31350;&#25991;&#26412;&#20013;&#30340;&#35805;&#35821;&#29305;&#24449;&#26469;&#21306;&#20998;&#20154;&#31867;&#21019;&#20316;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#25581;&#31034;&#36825;&#20123;&#29305;&#24449;&#65292;&#24182;&#21457;&#29616;&#20154;&#31867;&#20889;&#20316;&#22312;&#32467;&#26500;&#19978;&#26356;&#20026;&#22810;&#26679;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.10586</link><description>&lt;p&gt;
&#32454;&#24494;&#20043;&#32447;&#65306;&#36890;&#36807;&#35805;&#35821;&#20027;&#39064;&#35782;&#21035;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse Motifs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#30740;&#31350;&#25991;&#26412;&#20013;&#30340;&#35805;&#35821;&#29305;&#24449;&#26469;&#21306;&#20998;&#20154;&#31867;&#21019;&#20316;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#25581;&#31034;&#36825;&#20123;&#29305;&#24449;&#65292;&#24182;&#21457;&#29616;&#20154;&#31867;&#20889;&#20316;&#22312;&#32467;&#26500;&#19978;&#26356;&#20026;&#22810;&#26679;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#29616;&#65292;&#20154;&#31867;&#21019;&#20316;&#21644;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#20043;&#38388;&#30340;&#30028;&#38480;&#21464;&#24471;&#26085;&#30410;&#27169;&#31946;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#35782;&#21035;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#20013;&#21487;&#36776;&#35782;&#21644;&#29420;&#29305;&#30340;&#35821;&#35328;&#29305;&#24615;&#30340;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#25581;&#31034;&#25991;&#26412;&#22312;&#34920;&#38754;&#32467;&#26500;&#20043;&#22806;&#30340;&#28508;&#22312;&#35805;&#35821;&#32467;&#26500;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#35770;&#65292;&#25105;&#20204;&#21033;&#29992;&#23618;&#27425;&#21270;&#35299;&#26512;&#26641;&#21644;&#36882;&#24402;&#36229;&#22270;&#26469;&#25581;&#31034;LLM&#21644;&#20154;&#31867;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#30340;&#29420;&#29305;&#35805;&#35821;&#27169;&#24335;&#12290;&#23454;&#35777;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;LLM&#21644;&#20154;&#31867;&#29983;&#25104;&#30340;&#25991;&#26412;&#37117;&#21463;&#29305;&#23450;&#39046;&#22495;&#30340;&#24433;&#21709;&#32780;&#20135;&#29983;&#19981;&#21516;&#30340;&#35805;&#35821;&#27169;&#24335;&#65292;&#20294;&#20154;&#31867;&#25776;&#20889;&#30340;&#25991;&#26412;&#34920;&#29616;&#20986;&#26356;&#22810;&#30340;&#32467;&#26500;&#21464;&#24322;&#24615;&#65292;&#21453;&#26144;&#20102;&#19981;&#21516;&#39046;&#22495;&#20154;&#31867;&#20889;&#20316;&#30340;&#24494;&#22937;&#24615;&#36136;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24341;&#20837;&#23618;&#27425;&#35805;&#35821;&#29305;&#24449;&#21487;&#20197;&#22686;&#24378;&#20108;&#20803;&#20998;&#31867;&#22120;&#22312;&#21306;&#20998;&#20154;&#31867;&#29983;&#25104;&#21644;&#26426;&#22120;&#29983;&#25104;&#25991;&#26412;&#26041;&#38754;&#30340;&#25972;&#20307;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10586v1 Announce Type: new  Abstract: With the advent of large language models (LLM), the line between human-crafted and machine-generated texts has become increasingly blurred. This paper delves into the inquiry of identifying discernible and unique linguistic properties in texts that were written by humans, particularly uncovering the underlying discourse structures of texts beyond their surface structures. Introducing a novel methodology, we leverage hierarchical parse trees and recursive hypergraphs to unveil distinctive discourse patterns in texts produced by both LLMs and humans. Empirical findings demonstrate that, although both LLMs and humans generate distinct discourse patterns influenced by specific domains, human-written texts exhibit more structural variability, reflecting the nuanced nature of human writing in different domains. Notably, incorporating hierarchical discourse features enhances binary classifiers' overall performance in distinguishing between huma
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FEWL&#30340;&#24187;&#35273;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;LLM&#31572;&#26696;&#36827;&#34892;&#21152;&#26435;&#35780;&#20272;&#20107;&#23454;&#24615;&#65292;&#36866;&#29992;&#20110;&#27809;&#26377;&#40644;&#37329;&#26631;&#20934;&#31572;&#26696;&#30340;&#24773;&#20917;&#12290;</title><link>https://arxiv.org/abs/2402.10412</link><description>&lt;p&gt;
&#36890;&#36807;&#19987;&#23478;&#21152;&#26435;&#26469;&#34913;&#37327;&#21644;&#20943;&#23569;LLM&#22312;&#27809;&#26377;&#40644;&#37329;&#26631;&#20934;&#31572;&#26696;&#30340;&#24773;&#20917;&#19979;&#30340;&#34394;&#26500;
&lt;/p&gt;
&lt;p&gt;
Measuring and Reducing LLM Hallucination without Gold-Standard Answers via Expertise-Weighting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10412
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FEWL&#30340;&#24187;&#35273;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;LLM&#31572;&#26696;&#36827;&#34892;&#21152;&#26435;&#35780;&#20272;&#20107;&#23454;&#24615;&#65292;&#36866;&#29992;&#20110;&#27809;&#26377;&#40644;&#37329;&#26631;&#20934;&#31572;&#26696;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
LLM&#24187;&#35273;&#65292;&#21363;&#29983;&#25104;&#20107;&#23454;&#19981;&#27491;&#30830;&#20294;&#30475;&#20284;&#20196;&#20154;&#20449;&#26381;&#30340;&#31572;&#26696;&#65292;&#30446;&#21069;&#26159;LLM&#21487;&#20449;&#24230;&#21644;&#21487;&#38752;&#24615;&#30340;&#20027;&#35201;&#23041;&#32961;&#12290;&#35299;&#20915;&#36825;&#19968;&#22797;&#26434;&#38382;&#39064;&#30340;&#31532;&#19968;&#27493;&#26159;&#23545;&#20854;&#36827;&#34892;&#34913;&#37327;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#24187;&#35273;&#24230;&#37327;&#26631;&#20934;&#38656;&#35201;&#20855;&#26377;&#20855;&#26377;&#40644;&#37329;&#26631;&#20934;&#31572;&#26696;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21363;&#20154;&#31867;&#32534;&#20889;&#30340;&#8220;&#26368;&#20339;&#8221;&#25110;&#8220;&#27491;&#30830;&#8221;&#31572;&#26696;&#12290;&#36825;&#31181;&#35201;&#27714;&#20351;&#24187;&#35273;&#27979;&#37327;&#25104;&#26412;&#39640;&#26114;&#65292;&#24182;&#23481;&#26131;&#20986;&#29616;&#20154;&#20026;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#21152;&#26435;LLM&#23545;&#20107;&#23454;&#24615;&#36827;&#34892;&#35780;&#20272;&#65288;FEWL&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#38376;&#20026;&#37329;&#26631;&#20934;&#31572;&#26696;&#32570;&#22833;&#26102;&#35774;&#35745;&#30340;&#24187;&#35273;&#24230;&#37327;&#26631;&#20934;&#12290;FEWL&#21033;&#29992;&#20102;&#29616;&#25104;&#30340;LLM&#31572;&#26696;&#20316;&#20026;&#40644;&#37329;&#26631;&#20934;&#31572;&#26696;&#30340;&#20195;&#29702;&#12290;&#20851;&#38190;&#25361;&#25112;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#37327;&#21270;&#21442;&#32771;LLM&#30340;&#19987;&#19994;&#30693;&#35782;&#12290;&#25105;&#20204;&#23637;&#31034;FEWL&#20855;&#26377;&#19968;&#23450;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#35777;&#20013;&#35777;&#26126;&#23427;&#26356;&#20934;&#30830;&#12290;&#24230;&#37327;&#34394;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10412v1 Announce Type: cross  Abstract: LLM hallucination, i.e. generating factually incorrect yet seemingly convincing answers, is currently a major threat to the trustworthiness and reliability of LLMs. The first step towards solving this complicated problem is to measure it. However, existing hallucination metrics require to have a benchmark dataset with gold-standard answers, i.e. "best" or "correct" answers written by humans. Such requirement makes hallucination measurement costly and prone to human errors. In this work, we propose Factualness Evaluations via Weighting LLMs (FEWL), the first hallucination metric that is specifically designed for the scenario when gold-standard answers are absent. FEWL leverages the answers from off-the-shelf LLMs that serve as a proxy of gold-standard answers. The key challenge is how to quantify the expertise of reference LLMs resourcefully. We show FEWL has certain theoretical guarantees and demonstrate empirically it gives more accur
&lt;/p&gt;</description></item><item><title>TOAD&#26159;&#19968;&#20010;&#20855;&#26377;&#22810;&#26679;&#21709;&#24212;&#39118;&#26684;&#30340;&#38754;&#21521;&#20219;&#21153;&#30340;&#33258;&#21160;&#23545;&#35805;&#31995;&#32479;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#20887;&#38271;&#31243;&#24230;&#21644;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#20004;&#20010;&#26041;&#38754;&#12290;TOAD&#36890;&#36807;&#27169;&#25311;&#30495;&#23454;&#30340;&#24212;&#29992;&#19978;&#19979;&#25991;&#20132;&#20114;&#65292;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#31995;&#32479;&#21709;&#24212;&#39118;&#26684;&#36873;&#39033;&#65292;&#24182;&#22312;&#35780;&#20272;&#20013;&#34920;&#26126;&#24314;&#27169;&#26356;&#20887;&#38271;&#30340;&#22238;&#22797;&#25110;&#19981;&#36827;&#34892;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#30340;&#22238;&#22797;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.10137</link><description>&lt;p&gt;
TOAD: &#20855;&#26377;&#22810;&#26679;&#21709;&#24212;&#39118;&#26684;&#30340;&#38754;&#21521;&#20219;&#21153;&#30340;&#33258;&#21160;&#23545;&#35805;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10137
&lt;/p&gt;
&lt;p&gt;
TOAD&#26159;&#19968;&#20010;&#20855;&#26377;&#22810;&#26679;&#21709;&#24212;&#39118;&#26684;&#30340;&#38754;&#21521;&#20219;&#21153;&#30340;&#33258;&#21160;&#23545;&#35805;&#31995;&#32479;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#20887;&#38271;&#31243;&#24230;&#21644;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#20004;&#20010;&#26041;&#38754;&#12290;TOAD&#36890;&#36807;&#27169;&#25311;&#30495;&#23454;&#30340;&#24212;&#29992;&#19978;&#19979;&#25991;&#20132;&#20114;&#65292;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#31995;&#32479;&#21709;&#24212;&#39118;&#26684;&#36873;&#39033;&#65292;&#24182;&#22312;&#35780;&#20272;&#20013;&#34920;&#26126;&#24314;&#27169;&#26356;&#20887;&#38271;&#30340;&#22238;&#22797;&#25110;&#19981;&#36827;&#34892;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#30340;&#22238;&#22797;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#36827;&#23637;&#26174;&#31034;&#65292;&#19979;&#19968;&#20195;&#34394;&#25311;&#21161;&#25163;&#30340;&#26399;&#26395;&#21253;&#25324;&#22312;&#21508;&#31181;&#20351;&#29992;&#22330;&#26223;&#19979;&#25552;&#20379;&#26356;&#21152;&#33258;&#28982;&#21644;&#36866;&#24212;&#24615;&#24378;&#30340;&#23545;&#35805;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20026;&#38754;&#21521;&#20219;&#21153;&#30340;&#23545;&#35805;&#65288;TOD&#65289;&#21019;&#24314;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#34987;&#35748;&#20026;&#26159;&#32531;&#24930;&#21644;&#26114;&#36149;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20219;&#21153;&#23548;&#21521;&#30340;&#33258;&#21160;&#23545;&#35805;&#31995;&#32479;&#65288;TOAD&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#19988;&#21487;&#25193;&#23637;&#30340;TOD&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#19982;&#20043;&#37197;&#22871;&#30340;&#33258;&#21160;&#29983;&#25104;&#27969;&#31243;&#12290;TOAD&#25968;&#25454;&#38598;&#27169;&#25311;&#20102;&#30495;&#23454;&#30340;&#24212;&#29992;&#19978;&#19979;&#25991;&#20132;&#20114;&#65292;&#24182;&#25552;&#20379;&#20102;&#21508;&#31181;&#31995;&#32479;&#21709;&#24212;&#39118;&#26684;&#36873;&#39033;&#12290;&#32771;&#34385;&#20102;&#31995;&#32479;&#21709;&#24212;&#39118;&#26684;&#30340;&#20004;&#20010;&#26041;&#38754;&#65292;&#21363;&#20887;&#38271;&#31243;&#24230;&#21644;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#21709;&#24212;&#29983;&#25104;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;TOAD&#30340;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;&#24314;&#27169;&#26356;&#20887;&#38271;&#30340;&#22238;&#22797;&#25110;&#19981;&#36827;&#34892;&#29992;&#25143;&#34920;&#36798;&#38236;&#20687;&#30340;&#22238;&#22797;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10137v1 Announce Type: new  Abstract: In light of recent advances in large language models~(LLMs), the expectations for the next generation of virtual assistants include enhanced naturalness and adaptability across diverse usage scenarios. However, the creation of high-quality annotated data for Task-Oriented Dialog~(TOD) is recognized to be slow and costly. To address these challenges, we introduce Task-Oriented Automatic Dialogs~(TOAD), a novel and scalable TOD dataset along with its automatic generation pipeline. The TOAD dataset simulates realistic app context interaction and provide a variety of system response style options. Two aspects of system response styles are considered, verbosity level and users' expression mirroring. We benchmark TOAD on two response generation tasks and the results show that modeling more verbose or responses without user expression mirroring is more challenging.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SafeDecoding&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23433;&#20840;&#24863;&#30693;&#35299;&#30721;&#31574;&#30053;&#26469;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#12290;&#35813;&#31574;&#30053;&#21487;&#20197;&#29983;&#25104;&#23545;&#29992;&#25143;&#26597;&#35810;&#26377;&#30410;&#19988;&#26080;&#23475;&#30340;&#21709;&#24212;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;LLMs&#23433;&#20840;&#24615;&#23041;&#32961;&#12290;</title><link>https://arxiv.org/abs/2402.08983</link><description>&lt;p&gt;
SafeDecoding: &#36890;&#36807;&#23433;&#20840;&#24863;&#30693;&#35299;&#30721;&#38450;&#24481;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SafeDecoding&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#23433;&#20840;&#24863;&#30693;&#35299;&#30721;&#31574;&#30053;&#26469;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36234;&#29425;&#25915;&#20987;&#12290;&#35813;&#31574;&#30053;&#21487;&#20197;&#29983;&#25104;&#23545;&#29992;&#25143;&#26597;&#35810;&#26377;&#30410;&#19988;&#26080;&#23475;&#30340;&#21709;&#24212;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;LLMs&#23433;&#20840;&#24615;&#23041;&#32961;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#20195;&#30721;&#29983;&#25104;&#21644;&#32842;&#22825;&#26426;&#22120;&#20154;&#36741;&#21161;&#31561;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#20154;&#20204;&#20026;&#20102;&#20351;LLM&#30340;&#34892;&#20026;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#65292;&#21253;&#25324;&#23433;&#20840;&#24615;&#22312;&#20869;&#20570;&#20986;&#20102;&#22823;&#37327;&#21162;&#21147;&#12290;&#36234;&#29425;&#25915;&#20987;&#26088;&#22312;&#24341;&#21457;LLM&#30340;&#38750;&#39044;&#26399;&#21644;&#19981;&#23433;&#20840;&#34892;&#20026;&#65292;&#20173;&#28982;&#26159;LLM&#23433;&#20840;&#24615;&#30340;&#37325;&#35201;&#23041;&#32961;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;SafeDecoding&#26469;&#38450;&#24481;LLM&#30340;&#36234;&#29425;&#25915;&#20987;&#65292;&#36825;&#26159;&#19968;&#31181;&#23433;&#20840;&#24863;&#30693;&#30340;&#35299;&#30721;&#31574;&#30053;&#65292;&#29992;&#20110;&#29983;&#25104;&#23545;&#29992;&#25143;&#26597;&#35810;&#26377;&#30410;&#19988;&#26080;&#23475;&#30340;&#21709;&#24212;&#12290;&#25105;&#20204;&#22312;&#24320;&#21457;SafeDecoding&#26102;&#30340;&#27934;&#23519;&#21147;&#22522;&#20110;&#35266;&#23519;&#21040;&#65292;&#21363;&#20351;&#20195;&#34920;&#26377;&#23475;&#20869;&#23481;&#30340;&#26631;&#35760;&#30340;&#27010;&#29575;&#36229;&#36807;&#20195;&#34920;&#26080;&#23475;&#21709;&#24212;&#30340;&#26631;&#35760;&#30340;&#27010;&#29575;&#65292;&#23433;&#20840;&#20813;&#36131;&#22768;&#26126;&#20173;&#28982;&#20986;&#29616;&#22312;&#25353;&#27010;&#29575;&#38477;&#24207;&#25490;&#24207;&#30340;&#26631;&#35760;&#20013;&#30340;&#21069;&#20960;&#20010;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#35782;&#21035;&#23433;&#20840;&#20813;&#36131;&#22768;&#26126;&#24182;&#22686;&#24378;&#20854;&#33391;&#24615;&#24433;&#21709;&#21147;&#26469;&#20943;&#36731;&#36234;&#29425;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08983v1 Announce Type: cross Abstract: As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, aiming to provoke unintended and unsafe behaviors from LLMs, remain a significant/leading LLM safety threat. In this paper, we aim to defend LLMs against jailbreak attacks by introducing SafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful and harmless responses to user queries. Our insight in developing SafeDecoding is based on the observation that, even though probabilities of tokens representing harmful contents outweigh those representing harmless responses, safety disclaimers still appear among the top tokens after sorting tokens by probability in descending order. This allows us to mitigate jailbreak attacks by identifying safety disclaimers and amplifying their
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;COLD-Attack&#26694;&#26550;&#65292;&#26088;&#22312;&#23454;&#29616;&#20855;&#26377;&#38544;&#31192;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;LLM&#36234;&#29425;&#12290;&#36890;&#36807;&#24314;&#31435;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#19982;&#25915;&#20987;&#29983;&#25104;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#37319;&#29992;&#20102;&#33021;&#37327;&#38480;&#21046;&#35299;&#30721;&#19982;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#19981;&#21516;&#30340;&#25511;&#21046;&#35201;&#27714;&#19979;&#25628;&#32034;&#23545;&#25239;&#24615;LLM&#25915;&#20987;&#25104;&#20026;&#21487;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.08679</link><description>&lt;p&gt;
COLD-Attack: &#29992;&#20110;&#20855;&#26377;&#38544;&#31192;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;LLM&#36234;&#29425;
&lt;/p&gt;
&lt;p&gt;
COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;COLD-Attack&#26694;&#26550;&#65292;&#26088;&#22312;&#23454;&#29616;&#20855;&#26377;&#38544;&#31192;&#24615;&#21644;&#21487;&#25511;&#24615;&#30340;LLM&#36234;&#29425;&#12290;&#36890;&#36807;&#24314;&#31435;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#19982;&#25915;&#20987;&#29983;&#25104;&#20043;&#38388;&#30340;&#20851;&#32852;&#65292;&#37319;&#29992;&#20102;&#33021;&#37327;&#38480;&#21046;&#35299;&#30721;&#19982;Langevin&#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#19981;&#21516;&#30340;&#25511;&#21046;&#35201;&#27714;&#19979;&#25628;&#32034;&#23545;&#25239;&#24615;LLM&#25915;&#20987;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#36827;&#34892;&#36234;&#29425;&#30340;&#27880;&#24847;&#21147;&#36234;&#26469;&#36234;&#22810;&#12290;&#20026;&#20102;&#20840;&#38754;&#35780;&#20272;LLM&#30340;&#23433;&#20840;&#24615;&#65292;&#26377;&#24517;&#35201;&#32771;&#34385;&#20855;&#26377;&#19981;&#21516;&#23646;&#24615;&#30340;&#36234;&#29425;&#65292;&#20363;&#22914;&#19978;&#19979;&#25991;&#36830;&#36143;&#24615;&#20197;&#21450;&#24773;&#24863;/&#39118;&#26684;&#21464;&#21270;&#65292;&#22240;&#27492;&#30740;&#31350;&#21487;&#25511;&#24615;&#36234;&#29425;&#26159;&#26377;&#30410;&#30340;&#65292;&#21363;&#22914;&#20309;&#23545;LLM&#25915;&#20987;&#36827;&#34892;&#25511;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#24418;&#24335;&#21270;&#20102;&#21487;&#25511;&#24615;&#25915;&#20987;&#29983;&#25104;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#35813;&#38382;&#39064;&#19982;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#20043;&#38388;&#30340;&#26032;&#22411;&#20851;&#32852;&#65292;&#36825;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#19968;&#20010;&#34987;&#24191;&#27867;&#25506;&#32034;&#30340;&#20027;&#39064;&#12290;&#22522;&#20110;&#36825;&#31181;&#20851;&#32852;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#33021;&#37327;&#38480;&#21046;&#35299;&#30721;&#19982;Langevin&#21160;&#21147;&#23398;&#65288;COLD&#65289;&#30340;&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#21487;&#25511;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;COLD-Attack&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#32479;&#19968;&#19988;&#33258;&#21160;&#21270;&#22320;&#25628;&#32034;&#21508;&#31181;&#25511;&#21046;&#35201;&#27714;&#19979;&#30340;&#23545;&#25239;&#24615;LLM&#25915;&#20987;&#65292;&#20363;&#22914;&#27969;&#30021;&#24615;&#12289;&#38544;&#31192;&#24615;&#12289;&#24773;&#24863;&#21644;&#24038;&#21491;&#36830;&#36143;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Jailbreaks on Large language models (LLMs) have recently received increasing attention. For a comprehensive assessment of LLM safety, it is essential to consider jailbreaks with diverse attributes, such as contextual coherence and sentiment/stylistic variations, and hence it is beneficial to study controllable jailbreaking, i.e. how to enforce control on LLM attacks. In this paper, we formally formulate the controllable attack generation problem, and build a novel connection between this problem and controllable text generation, a well-explored topic of natural language processing. Based on this connection, we adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a state-of-the-art, highly efficient algorithm in controllable text generation, and introduce the COLD-Attack framework which unifies and automates the search of adversarial LLM attacks under a variety of control requirements such as fluency, stealthiness, sentiment, and left-right-coherence. The controlla
&lt;/p&gt;</description></item><item><title>&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#39304;&#24490;&#29615;&#21487;&#33021;&#23548;&#33268;&#19978;&#19979;&#25991;&#20869;&#22870;&#21169;&#27450;&#39575;&#65288;ICRH&#65289;&#65292;&#21363;&#35821;&#35328;&#27169;&#22411;&#22312;&#27979;&#35797;&#26102;&#22312;&#20248;&#21270;&#30446;&#26631;&#30340;&#21516;&#26102;&#21364;&#20135;&#29983;&#36127;&#38754;&#21103;&#20316;&#29992;&#12290;&#36825;&#39033;&#30740;&#31350;&#30830;&#23450;&#20102;&#20004;&#20010;&#23548;&#33268;ICRH&#30340;&#36807;&#31243;&#65306;&#36755;&#20986;&#20248;&#21270;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.06627</link><description>&lt;p&gt;
&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#39304;&#24490;&#29615;&#25512;&#21160;&#19978;&#19979;&#25991;&#20869;&#22870;&#21169;&#27450;&#39575;
&lt;/p&gt;
&lt;p&gt;
Feedback Loops With Language Models Drive In-Context Reward Hacking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06627
&lt;/p&gt;
&lt;p&gt;
&#19982;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#39304;&#24490;&#29615;&#21487;&#33021;&#23548;&#33268;&#19978;&#19979;&#25991;&#20869;&#22870;&#21169;&#27450;&#39575;&#65288;ICRH&#65289;&#65292;&#21363;&#35821;&#35328;&#27169;&#22411;&#22312;&#27979;&#35797;&#26102;&#22312;&#20248;&#21270;&#30446;&#26631;&#30340;&#21516;&#26102;&#21364;&#20135;&#29983;&#36127;&#38754;&#21103;&#20316;&#29992;&#12290;&#36825;&#39033;&#30740;&#31350;&#30830;&#23450;&#20102;&#20004;&#20010;&#23548;&#33268;ICRH&#30340;&#36807;&#31243;&#65306;&#36755;&#20986;&#20248;&#21270;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#23545;&#22806;&#37096;&#19990;&#30028;&#20135;&#29983;&#24433;&#21709;&#65306;&#23427;&#20204;&#26597;&#35810;&#21487;&#20197;&#35835;&#20889;&#32593;&#39029;&#30340;API&#65292;&#29983;&#25104;&#33021;&#22815;&#24433;&#21709;&#20154;&#31867;&#34892;&#20026;&#30340;&#20869;&#23481;&#65292;&#20197;&#21450;&#20316;&#20026;&#33258;&#20027;&#20195;&#29702;&#36816;&#34892;&#31995;&#32479;&#21629;&#20196;&#12290;&#36825;&#20123;&#20114;&#21160;&#24418;&#25104;&#20102;&#21453;&#39304;&#24490;&#29615;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#24433;&#21709;&#19990;&#30028;&#65292;&#21453;&#36807;&#26469;&#21448;&#24433;&#21709;&#21518;&#32493;&#30340;&#35821;&#35328;&#27169;&#22411;&#36755;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21453;&#39304;&#24490;&#29615;&#21487;&#33021;&#23548;&#33268;&#19978;&#19979;&#25991;&#20869;&#22870;&#21169;&#27450;&#39575;(ICRH)&#65292;&#21363;&#27979;&#35797;&#26102;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#20248;&#21270;&#65288;&#21487;&#33021;&#38544;&#21547;&#30340;&#65289;&#30446;&#26631;&#30340;&#21516;&#26102;&#65292;&#20135;&#29983;&#36127;&#38754;&#21103;&#20316;&#29992;&#12290;&#20363;&#22914;&#65292;&#32771;&#34385;&#19968;&#20010;&#34987;&#37096;&#32626;&#29992;&#20110;&#22686;&#21152;Twitter&#21442;&#19982;&#24230;&#30340;&#35821;&#35328;&#27169;&#22411;&#20195;&#29702;&#65307;&#35821;&#35328;&#27169;&#22411;&#21487;&#33021;&#22312;&#19978;&#19979;&#25991;&#31383;&#21475;&#20013;&#26816;&#32034;&#20854;&#20197;&#21069;&#30340;&#25512;&#25991;&#65292;&#24182;&#20351;&#25512;&#25991;&#26356;&#20855;&#20105;&#35758;&#24615;&#65292;&#20174;&#32780;&#22686;&#21152;&#21442;&#19982;&#24230;&#65292;&#20294;&#20063;&#22686;&#21152;&#20102;&#26377;&#27602;&#24615;&#12290;&#25105;&#20204;&#30830;&#23450;&#24182;&#30740;&#31350;&#20102;&#23548;&#33268;ICRH&#30340;&#20004;&#20010;&#36807;&#31243;&#65306;&#36755;&#20986;&#20248;&#21270;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#23545;&#20110;&#36825;&#20123;&#36807;&#31243;&#65292;&#38745;&#24577;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#26159;&#19981;&#36275;&#22815;&#30340;-&#20182;&#20204;&#26080;&#27861;&#25429;&#25417;&#21040;&#21453;&#39304;&#25928;&#24212;&#65292;&#20063;&#19981;&#33021;&#25429;&#25417;&#21040;&#26368;&#26377;&#23475;&#30340;&#34892;&#20026;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Language models influence the external world: they query APIs that read and write to web pages, generate content that shapes human behavior, and run system commands as autonomous agents. These interactions form feedback loops: LLM outputs affect the world, which in turn affect subsequent LLM outputs. In this work, we show that feedback loops can cause in-context reward hacking (ICRH), where the LLM at test-time optimizes a (potentially implicit) objective but creates negative side effects in the process. For example, consider an LLM agent deployed to increase Twitter engagement; the LLM may retrieve its previous tweets into the context window and make them more controversial, increasing engagement but also toxicity. We identify and study two processes that lead to ICRH: output-refinement and policy-refinement. For these processes, evaluations on static datasets are insufficient -- they miss the feedback effects and thus cannot capture the most harmful behavior. In response, we provide 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38271;&#25991;&#29983;&#25104;&#20013;&#30340;&#20107;&#23454;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#27573;&#33853;&#26102;&#21487;&#33021;&#20250;&#30001;&#20110;&#23454;&#20307;&#27169;&#31946;&#32780;&#23558;&#21487;&#39564;&#35777;&#30340;&#20107;&#23454;&#32452;&#21512;&#25104;&#38750;&#20107;&#23454;&#30340;&#27573;&#33853;&#12290;&#29616;&#26377;&#30340;&#20107;&#23454;&#20934;&#30830;&#24230;&#35780;&#20272;&#26041;&#27861;&#26080;&#27861;&#27491;&#30830;&#35780;&#20272;&#36825;&#20123;&#38750;&#20107;&#23454;&#27573;&#33853;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#24230;&#37327;&#25351;&#26631;&#26469;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05629</link><description>&lt;p&gt;
&#21512;&#24182;&#20107;&#23454;&#65292;&#22609;&#36896;&#35884;&#35823;&#65306;&#35780;&#20272;&#38271;&#25991;&#29983;&#25104;&#20013;&#32858;&#21512;&#20107;&#23454;&#24615;&#20027;&#24352;&#30340;&#30683;&#30462;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Merging Facts, Crafting Fallacies: Evaluating the Contradictory Nature of Aggregated Factual Claims in Long-Form Generations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05629
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38271;&#25991;&#29983;&#25104;&#20013;&#30340;&#20107;&#23454;&#24615;&#38382;&#39064;&#65292;&#21457;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29983;&#25104;&#27573;&#33853;&#26102;&#21487;&#33021;&#20250;&#30001;&#20110;&#23454;&#20307;&#27169;&#31946;&#32780;&#23558;&#21487;&#39564;&#35777;&#30340;&#20107;&#23454;&#32452;&#21512;&#25104;&#38750;&#20107;&#23454;&#30340;&#27573;&#33853;&#12290;&#29616;&#26377;&#30340;&#20107;&#23454;&#20934;&#30830;&#24230;&#35780;&#20272;&#26041;&#27861;&#26080;&#27861;&#27491;&#30830;&#35780;&#20272;&#36825;&#20123;&#38750;&#20107;&#23454;&#27573;&#33853;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#24230;&#37327;&#25351;&#26631;&#26469;&#24212;&#23545;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20135;&#29983;&#30340;&#38271;&#25991;&#29983;&#25104;&#29289;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20107;&#23454;&#21644;&#38750;&#20107;&#23454;&#30340;&#20027;&#24352;&#65292;&#36825;&#20351;&#24471;&#35780;&#20272;&#20107;&#23454;&#24615;&#21464;&#24471;&#22256;&#38590;&#12290;&#20026;&#20102;&#20197;&#26356;&#31934;&#32454;&#30340;&#26041;&#24335;&#35780;&#20272;&#38271;&#25991;&#29983;&#25104;&#29289;&#30340;&#20107;&#23454;&#20934;&#30830;&#24615;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#23558;&#38271;&#25991;&#29983;&#25104;&#29289;&#20998;&#35299;&#20026;&#22810;&#20010;&#21487;&#39564;&#35777;&#30340;&#20107;&#23454;&#24182;&#29420;&#31435;&#39564;&#35777;&#36825;&#20123;&#20107;&#23454;&#12290;&#29983;&#25104;&#29289;&#30340;&#20107;&#23454;&#24615;&#26159;&#25152;&#26377;&#20107;&#23454;&#20013;&#21487;&#39564;&#35777;&#20107;&#23454;&#30340;&#27604;&#20363;&#12290;&#36825;&#20123;&#26041;&#27861;&#20551;&#35774;&#32467;&#21512;&#20102;&#20107;&#23454;&#20027;&#24352;&#24418;&#25104;&#20102;&#19968;&#20010;&#20107;&#23454;&#24615;&#27573;&#33853;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#19968;&#20551;&#35774;&#21487;&#33021;&#22240;&#20026;&#23454;&#20307;&#27169;&#31946;&#32780;&#34987;&#36829;&#21453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;LLMs&#21487;&#20197;&#29983;&#25104;&#21253;&#21547;&#21487;&#39564;&#35777;&#20107;&#23454;&#30340;&#27573;&#33853;&#65292;&#20294;&#30001;&#20110;&#23454;&#20307;&#27169;&#31946;&#65292;&#36825;&#20123;&#20107;&#23454;&#34987;&#32467;&#21512;&#24418;&#25104;&#20102;&#19968;&#20010;&#38750;&#20107;&#23454;&#30340;&#27573;&#33853;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#29616;&#26377;&#30340;&#20107;&#23454;&#20934;&#30830;&#24230;&#24230;&#37327;&#25351;&#26631;&#65292;&#21253;&#25324;FActScore&#21644;&#24341;&#29992;&#22238;&#39038;&#65292;&#26080;&#27861;&#27491;&#30830;&#35780;&#20272;&#36825;&#20123;&#38750;&#20107;&#23454;&#27573;&#33853;&#30340;&#20107;&#23454;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22686;&#24378;&#24230;&#37327;&#25351;&#26631;&#65292;D-FActScore&#65292;&#20316;&#20026;&#19968;&#20010;&#20855;&#20307;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-form generations from large language models (LLMs) contains a mix of factual and non-factual claims, making evaluating factuality difficult. To evaluate factual precision of long-form generations in a more fine-grained way, prior works propose to decompose long-form generations into multiple verifiable facts and verify those facts independently. The factuality of the generation is the proportion of verifiable facts among all the facts. Such methods assume that combining factual claims forms a factual paragraph. This paper shows that the assumption can be violated due to entity ambiguity. We show that LLMs can generate paragraphs that contain verifiable facts, but the facts are combined to form a non-factual paragraph due to entity ambiguity. We further reveal that existing factual precision metrics, including FActScore and citation recall, cannot properly evaluate the factuality of these non-factual paragraphs. To address this, we introduce an enhanced metric, D-FActScore, specifi
&lt;/p&gt;</description></item><item><title>SALAD-Bench&#26159;&#19968;&#20010;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#38754;&#23433;&#20840;&#22522;&#20934;&#65292;&#36890;&#36807;&#20854;&#22823;&#35268;&#27169;&#12289;&#20016;&#23500;&#30340;&#20998;&#31867;&#21644;&#22810;&#21151;&#33021;&#24615;&#65292;&#20197;&#21450;&#23545;&#25915;&#20987;&#21644;&#38450;&#24481;&#26041;&#27861;&#30340;&#35780;&#20272;&#65292;&#23454;&#29616;&#20102;&#23545;LLMs&#30340;&#26377;&#25928;&#31649;&#29702;&#21644;&#20445;&#25252;&#12290;</title><link>https://arxiv.org/abs/2402.05044</link><description>&lt;p&gt;
SALAD-Bench: &#19968;&#20010;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#23618;&#27425;&#21270;&#21644;&#20840;&#38754;&#24615;&#23433;&#20840;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05044
&lt;/p&gt;
&lt;p&gt;
SALAD-Bench&#26159;&#19968;&#20010;&#38024;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#20840;&#38754;&#23433;&#20840;&#22522;&#20934;&#65292;&#36890;&#36807;&#20854;&#22823;&#35268;&#27169;&#12289;&#20016;&#23500;&#30340;&#20998;&#31867;&#21644;&#22810;&#21151;&#33021;&#24615;&#65292;&#20197;&#21450;&#23545;&#25915;&#20987;&#21644;&#38450;&#24481;&#26041;&#27861;&#30340;&#35780;&#20272;&#65292;&#23454;&#29616;&#20102;&#23545;LLMs&#30340;&#26377;&#25928;&#31649;&#29702;&#21644;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24555;&#36895;&#21457;&#23637;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#39046;&#22495;&#20013;&#65292;&#30830;&#20445;&#24378;&#22823;&#30340;&#23433;&#20840;&#25514;&#26045;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#19968;&#20851;&#38190;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#21035;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;LLMs&#12289;&#25915;&#20987;&#21644;&#38450;&#24481;&#26041;&#27861;&#30340;&#23433;&#20840;&#22522;&#20934;&#65292;&#31216;&#20026;SALAD-Bench&#12290;SALAD-Bench&#36890;&#36807;&#20854;&#22823;&#35268;&#27169;&#12289;&#20016;&#23500;&#22810;&#26679;&#30340;&#29305;&#24615;&#65292;&#20197;&#21450;&#36328;&#19977;&#20010;&#23618;&#27425;&#30340;&#32454;&#33268;&#20998;&#31867;&#21644;&#22810;&#21151;&#33021;&#24615;&#65292;&#36229;&#36234;&#20102;&#20256;&#32479;&#22522;&#20934;&#12290;SALAD-Bench&#36890;&#36807;&#23545;&#26631;&#20934;&#26597;&#35810;&#21644;&#22797;&#26434;&#26597;&#35810;&#65288;&#21253;&#25324;&#25915;&#20987;&#12289;&#38450;&#24481;&#20462;&#25913;&#21644;&#22810;&#39033;&#36873;&#25321;&#65289;&#30340;&#31934;&#24515;&#35774;&#35745;&#65292;&#26377;&#25928;&#31649;&#29702;&#20854;&#22266;&#26377;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#30830;&#20445;&#26080;&#32541;&#21487;&#38752;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35780;&#20272;&#22120;&#65306;&#22522;&#20110;LLM&#30340;MD-Judge&#65292;&#19987;&#27880;&#20110;&#25915;&#20987;&#22686;&#24378;&#26597;&#35810;&#30340;&#38382;&#31572;&#23545;&#35780;&#20272;&#12290;&#20197;&#19978;&#32452;&#20214;&#23558;SALAD-Bench&#20174;&#26631;&#20934;&#30340;LLM&#23433;&#20840;&#35780;&#20272;&#25193;&#23637;&#21040;&#20102;LLM&#25915;&#20987;&#21644;&#38450;&#24481;&#26041;&#27861;&#35780;&#20272;&#65292;&#30830;&#20445;&#20102;&#32852;&#21512;&#30446;&#26631;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.02037</link><description>&lt;p&gt;
EffiBench:&#35780;&#20272;&#33258;&#21160;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#30340;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
EffiBench: Benchmarking the Efficiency of Automatically Generated Code
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#22312;&#36741;&#21161;&#36719;&#20214;&#24320;&#21457;&#26041;&#38754;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#21487;&#20197;&#24110;&#21161;&#23436;&#25104;&#20195;&#30721;&#34917;&#20840;&#12289;&#35843;&#35797;&#21644;&#20195;&#30721;&#36716;&#25442;&#31561;&#20219;&#21153;&#12290;&#23613;&#31649;&#24403;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#28145;&#20837;&#30740;&#31350;&#20102;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#27491;&#30830;&#24615;&#65292;&#20294;&#29983;&#25104;&#20195;&#30721;&#30340;&#25928;&#29575;&#36825;&#19968;&#37325;&#35201;&#26041;&#38754;&#24120;&#24120;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;EffiBench&#65292;&#19968;&#20010;&#21253;&#21547;1,000&#20010;&#25928;&#29575;&#20851;&#38190;&#30340;&#32534;&#30721;&#38382;&#39064;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#20195;&#30721;&#30340;&#25928;&#29575;&#12290;EffiBench&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#22810;&#26679;&#21270;&#30340;LeetCode&#32534;&#30721;&#38382;&#39064;&#65292;&#27599;&#20010;&#38382;&#39064;&#37117;&#19982;&#19968;&#20010;&#21487;&#25191;&#34892;&#30340;&#20154;&#24037;&#32534;&#20889;&#30340;&#20856;&#22411;&#35299;&#20915;&#26041;&#26696;&#37197;&#23545;&#12290;&#36890;&#36807;EffiBench&#65292;&#25105;&#20204;&#22312;&#23454;&#36341;&#20013;&#32771;&#23519;&#20102;21&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#20854;&#20013;13&#31181;&#26159;&#24320;&#28304;&#30340;&#65292;8&#31181;&#26159;&#38381;&#28304;&#30340;&#65289;&#22312;&#29983;&#25104;&#39640;&#25928;&#20195;&#30721;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4-turbo&#29983;&#25104;&#30340;&#20195;&#30721;&#26368;&#39640;&#25928;&#65292;&#26126;&#26174;&#20248;&#20110;Palm-2-chat-bison&#12289;Claude-instant-1&#12289;Gemini-pro&#12289;GPT-4&#21644;GPT-3.5&#12290;
&lt;/p&gt;
&lt;p&gt;
Code generation models have increasingly become integral to aiding software development, offering assistance in tasks such as code completion, debugging, and code translation. Although current research has thoroughly examined the correctness of code produced by code generation models, a vital aspect, i.e., the efficiency of the generated code, has often been neglected. This paper presents EffiBench, a benchmark with 1,000 efficiency-critical coding problems for assessing the efficiency of code generated by code generation models. EffiBench contains a diverse set of LeetCode coding problems. Each problem is paired with an executable human-written canonical solution. With EffiBench, we empirically examine the capability of 21 Large Language Models (13 open-sourced and 8 closed-sourced) in generating efficient code. The results demonstrate that GPT-4-turbo generates the most efficient code, significantly outperforming Palm-2-chat-bison, Claude-instant-1, Gemini-pro, GPT-4, and GPT-3.5. Ne
&lt;/p&gt;</description></item><item><title>Dolma&#26159;&#19968;&#20010;&#21253;&#21547;&#19977;&#19975;&#20159;&#20010;&#20196;&#29260;&#30340;&#24320;&#25918;&#35821;&#26009;&#24211;&#65292;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#30740;&#31350;&#12290;&#23427;&#21253;&#21547;&#20102;&#26469;&#33258;&#22810;&#31181;&#26469;&#28304;&#30340;&#32593;&#32476;&#20869;&#23481;&#12289;&#31185;&#25216;&#35770;&#25991;&#12289;&#20195;&#30721;&#12289;&#20844;&#20849;&#39046;&#22495;&#22270;&#20070;&#12289;&#31038;&#20132;&#23186;&#20307;&#21644;&#30334;&#31185;&#20840;&#20070;&#26448;&#26009;&#12290;&#20026;&#20102;&#20419;&#36827;&#24320;&#25918;&#30740;&#31350;&#65292;&#25105;&#20204;&#36824;&#24320;&#28304;&#20102;&#25968;&#25454;&#25972;&#29702;&#24037;&#20855;&#21253;&#12290;</title><link>https://arxiv.org/abs/2402.00159</link><description>&lt;p&gt;
Dolma:&#19968;&#20010;&#21253;&#21547;&#19977;&#19975;&#20159;&#20010;&#20196;&#29260;&#30340;&#24320;&#25918;&#35821;&#26009;&#24211;&#65292;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00159
&lt;/p&gt;
&lt;p&gt;
Dolma&#26159;&#19968;&#20010;&#21253;&#21547;&#19977;&#19975;&#20159;&#20010;&#20196;&#29260;&#30340;&#24320;&#25918;&#35821;&#26009;&#24211;&#65292;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#30740;&#31350;&#12290;&#23427;&#21253;&#21547;&#20102;&#26469;&#33258;&#22810;&#31181;&#26469;&#28304;&#30340;&#32593;&#32476;&#20869;&#23481;&#12289;&#31185;&#25216;&#35770;&#25991;&#12289;&#20195;&#30721;&#12289;&#20844;&#20849;&#39046;&#22495;&#22270;&#20070;&#12289;&#31038;&#20132;&#23186;&#20307;&#21644;&#30334;&#31185;&#20840;&#20070;&#26448;&#26009;&#12290;&#20026;&#20102;&#20419;&#36827;&#24320;&#25918;&#30740;&#31350;&#65292;&#25105;&#20204;&#36824;&#24320;&#28304;&#20102;&#25968;&#25454;&#25972;&#29702;&#24037;&#20855;&#21253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#24050;&#25104;&#20026;&#22788;&#29702;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#30340;&#20851;&#38190;&#25216;&#26415;&#65292;&#28982;&#32780;&#65292;&#20851;&#20110;&#26368;&#20339;&#34920;&#29616;&#30340;&#35821;&#35328;&#27169;&#22411;&#26159;&#22914;&#20309;&#24320;&#21457;&#30340;&#24456;&#22810;&#32454;&#33410;&#24182;&#26410;&#25253;&#36947;&#12290;&#29305;&#21035;&#26159;&#65292;&#20854;&#39044;&#35757;&#32451;&#35821;&#26009;&#24211;&#30340;&#20449;&#24687;&#24456;&#23569;&#34987;&#35752;&#35770;&#65306;&#21830;&#19994;&#35821;&#35328;&#27169;&#22411;&#24456;&#23569;&#25552;&#20379;&#26377;&#20851;&#20854;&#25968;&#25454;&#30340;&#20219;&#20309;&#20449;&#24687;&#65307;&#21363;&#20351;&#26159;&#24320;&#25918;&#27169;&#22411;&#20063;&#24456;&#23569;&#21457;&#24067;&#23427;&#20204;&#25152;&#35757;&#32451;&#30340;&#25968;&#25454;&#38598;&#65292;&#25110;&#32773;&#25552;&#20379;&#19968;&#20010;&#31934;&#30830;&#30340;&#22797;&#29616;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#36827;&#34892;&#19968;&#20123;&#35821;&#35328;&#24314;&#27169;&#30740;&#31350;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#27604;&#22914;&#29702;&#35299;&#35757;&#32451;&#25968;&#25454;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#12290;&#20026;&#20102;&#20419;&#36827;&#35821;&#35328;&#27169;&#22411;&#39044;&#35757;&#32451;&#30340;&#24320;&#25918;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;Dolma&#65292;&#19968;&#20010;&#21253;&#21547;&#19977;&#19975;&#20159;&#20010;&#20196;&#29260;&#30340;&#33521;&#35821;&#35821;&#26009;&#24211;&#65292;&#20854;&#20013;&#21253;&#25324;&#21508;&#31181;&#21508;&#26679;&#30340;&#32593;&#32476;&#20869;&#23481;&#12289;&#31185;&#25216;&#35770;&#25991;&#12289;&#20195;&#30721;&#12289;&#20844;&#20849;&#39046;&#22495;&#22270;&#20070;&#12289;&#31038;&#20132;&#23186;&#20307;&#21644;&#30334;&#31185;&#20840;&#20070;&#26448;&#26009;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#28304;&#20102;&#25105;&#20204;&#30340;&#25968;&#25454;&#25972;&#29702;&#24037;&#20855;&#21253;&#65292;&#20197;&#20415;&#36827;&#19968;&#27493;&#30340;&#23454;&#39564;&#21644;&#20877;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language models have become a critical technology to tackling a wide range of natural language processing tasks, yet many details about how the best-performing language models were developed are not reported. In particular, information about their pretraining corpora is seldom discussed: commercial language models rarely provide any information about their data; even open models rarely release datasets they are trained on, or an exact recipe to reproduce them. As a result, it is challenging to conduct certain threads of language modeling research, such as understanding how training data impacts model capabilities and shapes their limitations. To facilitate open research on language model pretraining, we release Dolma, a three trillion tokens English corpus, built from a diverse mixture of web content, scientific papers, code, public-domain books, social media, and encyclopedic materials. In addition, we open source our data curation toolkit to enable further experimentation and reprodu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#36923;&#36753;&#20462;&#25913;&#20219;&#21153;&#21644;&#30456;&#24212;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#29616;&#20986;&#26174;&#33879;&#30340;&#36923;&#36753;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2311.17438</link><description>&lt;p&gt;
CLOMO: &#24102;&#26377;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#20107;&#23454;&#36923;&#36753;&#20462;&#25913;
&lt;/p&gt;
&lt;p&gt;
CLOMO: Counterfactual Logical Modification with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.17438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#21453;&#20107;&#23454;&#36923;&#36753;&#20462;&#25913;&#20219;&#21153;&#21644;&#30456;&#24212;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#29616;&#20986;&#26174;&#33879;&#30340;&#36923;&#36753;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#22521;&#20859;LLMs&#20869;&#30340;&#21453;&#20107;&#23454;&#24605;&#32500;&#36807;&#31243;&#65292;&#24182;&#23545;&#20854;&#26377;&#25928;&#24615;&#36827;&#34892;&#20005;&#26684;&#35780;&#20272;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#39033;&#26032;&#20219;&#21153;&#65292;&#21363;&#21453;&#20107;&#23454;&#36923;&#36753;&#20462;&#25913;&#65288;CLOMO&#65289;&#65292;&#20197;&#21450;&#19968;&#20010;&#39640;&#36136;&#37327;&#30340;&#20154;&#24037;&#27880;&#37322;&#22522;&#20934;&#12290;&#22312;&#36825;&#20010;&#20219;&#21153;&#20013;&#65292;LLMs&#24517;&#39035;&#29087;&#32451;&#22320;&#25913;&#21464;&#32473;&#23450;&#30340;&#35770;&#35777;&#25991;&#26412;&#65292;&#20197;&#20445;&#25345;&#39044;&#23450;&#30340;&#36923;&#36753;&#20851;&#31995;&#12290;&#20026;&#20102;&#26377;&#25928;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#21453;&#20107;&#23454;&#33021;&#21147;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#36923;&#36753;&#24863;&#30693;&#30340;&#21453;&#20107;&#23454;&#20998;&#25968;&#65292;&#30452;&#25509;&#35780;&#20272;LLMs&#30340;&#33258;&#28982;&#35821;&#35328;&#36755;&#20986;&#65292;&#32780;&#19981;&#26159;&#23558;&#20219;&#21153;&#24314;&#27169;&#20026;&#22810;&#39033;&#36873;&#25321;&#38382;&#39064;&#12290;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#19982;&#20154;&#31867;&#20559;&#22909;&#24456;&#22909;&#22320;&#19968;&#33268;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;LLMs&#23637;&#31034;&#20102;&#26174;&#30528;&#30340;&#36923;&#36753;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.17438v3 Announce Type: replace-cross Abstract: In this study, we delve into the realm of counterfactual reasoning capabilities of large language models (LLMs). Our primary objective is to cultivate the counterfactual thought processes within LLMs and rigorously assess these processes for their validity. Specifically, we introduce a novel task, Counterfactual Logical Modification (CLOMO), and a high-quality human-annotated benchmark. In this task, LLMs must adeptly alter a given argumentative text to uphold a predetermined logical relationship. To effectively evaluate a generation model's counterfactual capabilities, we propose an innovative evaluation metric, the LogicAware Counterfactual Score to directly evaluate the natural language output of LLMs instead of modeling the task as a multiple-choice problem. Analysis shows that the proposed automatic metric aligns well with human preference. Our experimental results show that while LLMs demonstrate a notable capacity for log
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#35780;&#20272;&#25351;&#26631;&#22312;&#24635;&#32467;&#20219;&#21153;&#20013;&#26159;&#21542;&#20250;&#23545;&#30456;&#21516;&#30340;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#34920;&#29616;&#20986;&#20559;&#35265;&#65292;&#24182;&#21457;&#29616;&#22312;&#26080;&#21442;&#32771;&#24773;&#20917;&#19979;&#20351;&#29992;&#26102;&#20559;&#35265;&#23588;&#20026;&#26174;&#33879;&#12290;</title><link>https://arxiv.org/abs/2311.09766</link><description>&lt;p&gt;
LLMs&#20316;&#20026;&#33258;&#24651;&#35780;&#20272;&#32773;&#65306;&#24403;&#33258;&#25105;&#33192;&#32960;&#24433;&#21709;&#35780;&#20272;&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
LLMs as Narcissistic Evaluators: When Ego Inflates Evaluation Scores
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#35780;&#20272;&#25351;&#26631;&#22312;&#24635;&#32467;&#20219;&#21153;&#20013;&#26159;&#21542;&#20250;&#23545;&#30456;&#21516;&#30340;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#34920;&#29616;&#20986;&#20559;&#35265;&#65292;&#24182;&#21457;&#29616;&#22312;&#26080;&#21442;&#32771;&#24773;&#20917;&#19979;&#20351;&#29992;&#26102;&#20559;&#35265;&#23588;&#20026;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09766v2 &#20844;&#21578;&#31867;&#22411;&#65306;&#26367;&#25442; &#25688;&#35201;&#65306;&#29983;&#25104;&#25991;&#26412;&#20869;&#23481;&#30340;&#33258;&#21160;&#35780;&#20272;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20013;&#19968;&#30452;&#26159;&#19968;&#20010;&#25345;&#32493;&#25361;&#25112;&#12290;&#37492;&#20110;&#29616;&#20195;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#22312;&#21508;&#31181;NLP&#20219;&#21153;&#20013;&#30340;&#20986;&#33394;&#34920;&#29616;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#20542;&#21521;&#20110;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#21019;&#36896;&#21019;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#29992;&#20110;&#33258;&#21160;&#29983;&#25104;&#20219;&#21153;&#30340;&#33258;&#21160;&#35780;&#20272;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#39537;&#21160;&#30340;&#35780;&#20272;&#25351;&#26631;&#26159;&#21542;&#20250;&#22266;&#26377;&#22320;&#34920;&#29616;&#20986;&#20559;&#21521;&#20110;&#30001;&#30456;&#21516;&#22522;&#30784;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#30340;&#25991;&#26412;&#30340;&#20559;&#35265;&#65311;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#30693;&#21517;&#30340;&#22522;&#20110;LM&#30340;&#35780;&#20272;&#25351;&#26631;&#65288;&#20363;&#22914;BARTScore&#12289;T5Score&#21644;GPTScore&#65289;&#22312;&#24635;&#32467;&#20219;&#21153;&#20013;&#26159;&#21542;&#23545;&#20854;&#21508;&#33258;&#30340;&#22522;&#30784;LM&#34920;&#29616;&#20986;&#20559;&#22909;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;&#28508;&#22312;&#20559;&#35265;&#65292;&#29305;&#21035;&#26159;&#24403;&#36825;&#20123;&#35780;&#20272;&#25351;&#26631;&#22312;&#26080;&#21442;&#32771;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#19988;&#19981;&#21033;&#29992;&#40644;&#37329;&#25688;&#35201;&#26102;&#65292;&#36825;&#31181;&#20559;&#35265;&#23588;&#20026;&#26174;&#33879;&#12290;&#36825;&#20123;&#32467;&#26524;&#31361;&#26174;&#20102;&#36890;&#36807;&#29983;&#25104;&#25991;&#26412;&#33719;&#24471;&#30340;&#35780;&#20272;&#32467;&#26524;&#21487;&#33021;&#20250;&#21463;&#21040;&#33258;&#25105;&#20559;&#35823;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09766v2 Announce Type: replace  Abstract: Automatic evaluation of generated textual content presents an ongoing challenge within the field of NLP. Given the impressive capabilities of modern language models (LMs) across diverse NLP tasks, there is a growing trend to employ these models in creating innovative evaluation metrics for automated assessment of generation tasks. This paper investigates a pivotal question: Do language model-driven evaluation metrics inherently exhibit bias favoring texts generated by the same underlying language model? Specifically, we assess whether prominent LM-based evaluation metrics (e.g. BARTScore, T5Score, and GPTScore) demonstrate a favorable bias toward their respective underlying LMs in the context of summarization tasks. Our findings unveil a latent bias, particularly pronounced when such evaluation metrics are used in an reference-free manner without leveraging gold summaries. These results underscore that assessments provided by generat
&lt;/p&gt;</description></item><item><title>Fusion-Eval&#26159;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;LLMs&#25972;&#21512;&#19981;&#21516;&#36741;&#21161;&#35780;&#20272;&#22120;&#30340;&#35265;&#35299;&#65292;&#26497;&#22823;&#25552;&#21319;&#33258;&#28982;&#35821;&#35328;&#31995;&#32479;&#35780;&#20272;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2311.09204</link><description>&lt;p&gt;
Fusion-Eval: &#23558;&#35780;&#20272;&#22120;&#19982;LLMs&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Fusion-Eval: Integrating Evaluators with LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.09204
&lt;/p&gt;
&lt;p&gt;
Fusion-Eval&#26159;&#19968;&#31181;&#21019;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;LLMs&#25972;&#21512;&#19981;&#21516;&#36741;&#21161;&#35780;&#20272;&#22120;&#30340;&#35265;&#35299;&#65292;&#26497;&#22823;&#25552;&#21319;&#33258;&#28982;&#35821;&#35328;&#31995;&#32479;&#35780;&#20272;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#31995;&#32479;&#30340;&#35780;&#20272;&#22312;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#21644;&#39640;&#32423;&#25512;&#29702;&#39046;&#22495;&#38754;&#20020;&#30528;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;Fusion-Eval&#8221;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#26469;&#25972;&#21512;&#26469;&#33258;&#21508;&#31181;&#36741;&#21161;&#35780;&#20272;&#22120;&#30340;&#35265;&#35299;&#12290;&#27599;&#20010;&#35780;&#20272;&#22120;&#19987;&#38376;&#36127;&#36131;&#35780;&#20272;&#21709;&#24212;&#30340;&#19981;&#21516;&#26041;&#38754;&#12290;&#36825;&#31181;&#29420;&#29305;&#31574;&#30053;&#20351;&#24471;Fusion-Eval&#33021;&#22815;&#26377;&#25928;&#22320;&#36328;&#36234;&#21508;&#31181;&#20219;&#21153;&#21644;&#26631;&#20934;&#65292;&#22686;&#24378;&#29616;&#26377;&#35780;&#20272;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;&#22312;SummEval&#19978;&#65292;Fusion-Eval&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#31995;&#32479;&#32423;Kendall-Tau&#30456;&#20851;&#24615;&#36798;&#21040;0.962&#65292;&#22312;TopicalChat&#19978;&#30340;&#36718;&#32423;Spearman&#30456;&#20851;&#24615;&#36798;&#21040;0.744&#65292;&#36828;&#39640;&#20110;&#22522;&#20934;&#26041;&#27861;&#12290;&#36825;&#20123;&#32467;&#26524;&#31361;&#26174;&#20102;Fusion-Eval&#22312;&#33258;&#28982;&#35821;&#35328;&#31995;&#32479;&#35780;&#20272;&#39046;&#22495;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.09204v2 Announce Type: replace-cross  Abstract: Evaluating natural language systems poses significant challenges, particularly in the realms of natural language understanding and high-level reasoning. In this paper, we introduce "Fusion-Eval", an innovative approach that leverages Large Language Models (LLMs) to integrate insights from various assistant evaluators. Each of these evaluators specializes in assessing distinct aspects of responses. This unique strategy enables Fusion-Eval to function effectively across a diverse range of tasks and criteria, enhancing the effectiveness of existing evaluation methods. Fusion-Eval achieves a 0.962 system-level Kendall-Tau correlation with humans on SummEval and a 0.744 turn-level Spearman correlation on TopicalChat, which is significantly higher than baseline methods. These results highlight Fusion-Eval's significant potential in the realm of natural language system evaluation.
&lt;/p&gt;</description></item><item><title>CodeScope&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#20195;&#30721;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#33021;&#21147;&#30340;&#22810;&#35821;&#35328;&#22810;&#20219;&#21153;&#22810;&#32500;&#22522;&#20934;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#22522;&#20934;&#22312;&#22810;&#35821;&#35328;&#32534;&#31243;&#29615;&#22659;&#21644;&#22810;&#20219;&#21153;&#35774;&#32622;&#26041;&#38754;&#30340;&#19981;&#36275;&#12290;</title><link>https://arxiv.org/abs/2311.08588</link><description>&lt;p&gt;
CodeScope:&#19968;&#20010;&#22522;&#20110;&#25191;&#34892;&#30340;&#22810;&#35821;&#35328;&#22810;&#20219;&#21153;&#22810;&#32500;&#22522;&#20934;&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#20195;&#30721;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08588
&lt;/p&gt;
&lt;p&gt;
CodeScope&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;LLMs&#22312;&#20195;&#30721;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#33021;&#21147;&#30340;&#22810;&#35821;&#35328;&#22810;&#20219;&#21153;&#22810;&#32500;&#22522;&#20934;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#22522;&#20934;&#22312;&#22810;&#35821;&#35328;&#32534;&#31243;&#29615;&#22659;&#21644;&#22810;&#20219;&#21153;&#35774;&#32622;&#26041;&#38754;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#32534;&#30721;&#30456;&#20851;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#26159;&#22312;&#24110;&#21161;&#20154;&#31867;&#32534;&#31243;&#21644;&#20419;&#36827;&#32534;&#31243;&#33258;&#21160;&#21270;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#35780;&#20272;LLMs&#30340;&#20195;&#30721;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#30340;&#22522;&#20934;&#23384;&#22312;&#20005;&#37325;&#30340;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#22823;&#37096;&#20998;&#22522;&#20934;&#23384;&#22312;&#32570;&#38519;&#65292;&#22240;&#20026;&#23427;&#20204;&#21482;&#20851;&#27880;&#20110;&#29421;&#31364;&#33539;&#22260;&#20869;&#30340;&#27969;&#34892;&#32534;&#31243;&#35821;&#35328;&#21644;&#29305;&#23450;&#20219;&#21153;&#65292;&#32780;&#23454;&#38469;&#36719;&#20214;&#24320;&#21457;&#22330;&#26223;&#38656;&#35201;&#23454;&#29616;&#22810;&#35821;&#35328;&#32534;&#31243;&#29615;&#22659;&#20197;&#28385;&#36275;&#21508;&#31181;&#38656;&#27714;&#12290;&#23454;&#38469;&#32534;&#31243;&#23454;&#36341;&#36824;&#24378;&#28872;&#26399;&#26395;&#22810;&#20219;&#21153;&#35774;&#32622;&#65292;&#20197;&#20840;&#38754;&#21644;&#31283;&#20581;&#22320;&#27979;&#35797;LLMs&#30340;&#32534;&#30721;&#33021;&#21147;&#12290;&#20854;&#27425;&#65292;&#22823;&#37096;&#20998;&#22522;&#20934;&#20063;&#26410;&#32771;&#34385;&#29983;&#25104;&#20195;&#30721;&#30340;&#21487;&#25191;&#34892;&#24615;&#21644;&#25191;&#34892;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#29616;&#26377;&#22522;&#20934;&#19982;&#23454;&#38469;&#24212;&#29992;&#26399;&#26395;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;CodeScope&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated remarkable performance on coding related tasks, particularly on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most benchmarks are deficient as they focus on a narrow range of popular programming languages and specific tasks, whereas the real-world software development scenarios show dire need to implement systems with multilingual programming environments to satisfy diverse requirements. Practical programming practices also strongly expect multi-task settings for testing coding capabilities of LLMs comprehensively and robustly. Second, most benchmarks also fail to consider the actual executability and the consistency of execution results of the generated code. To bridge these gaps between existing benchmarks and expectations from practical applications, we introduce CodeScope
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#32842;&#22825;&#21521;&#37327;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#27169;&#22411;&#31639;&#26415;&#20351;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20855;&#22791;&#22312;&#26032;&#35821;&#35328;&#20013;&#36981;&#24490;&#25351;&#20196;&#21644;&#23454;&#29616;&#27169;&#22411;&#23545;&#40784;&#30340;&#33021;&#21147;</title><link>https://arxiv.org/abs/2310.04799</link><description>&lt;p&gt;
Chat Vector&#65306;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#22312;&#26032;&#35821;&#35328;&#20013;&#20026;LLMs&#25552;&#20379;&#25351;&#20196;&#36981;&#24490;&#21644;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04799
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#32842;&#22825;&#21521;&#37327;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#27169;&#22411;&#31639;&#26415;&#20351;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20855;&#22791;&#22312;&#26032;&#35821;&#35328;&#20013;&#36981;&#24490;&#25351;&#20196;&#21644;&#23454;&#29616;&#27169;&#22411;&#23545;&#40784;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#21457;&#23637;&#36805;&#36895;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30001;&#20110;&#25968;&#25454;&#32422;&#26463;&#65292;&#22823;&#22810;&#25968;&#24320;&#28304;LLM&#30340;&#33021;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#33521;&#35821;&#19978;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32842;&#22825;&#21521;&#37327;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#27169;&#22411;&#31639;&#26415;&#20026;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#25351;&#20196;&#36981;&#24490;&#21644;&#20154;&#31867;&#20215;&#20540;&#23545;&#40784;&#12290;&#32842;&#22825;&#21521;&#37327;&#26159;&#36890;&#36807;&#23558;&#39044;&#35757;&#32451;&#22522;&#30784;&#27169;&#22411;&#65288;&#20363;&#22914;LLaMA2&#65289;&#30340;&#26435;&#37325;&#20943;&#21435;&#20854;&#23545;&#24212;&#30340;&#32842;&#22825;&#27169;&#22411;&#65288;&#20363;&#22914;LLaMA2-chat&#65289;&#30340;&#26435;&#37325;&#24471;&#20986;&#30340;&#12290;&#36890;&#36807;&#31616;&#21333;&#22320;&#23558;&#32842;&#22825;&#21521;&#37327;&#28155;&#21152;&#21040;&#25345;&#32493;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26435;&#37325;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#26032;&#35821;&#35328;&#20013;&#20855;&#26377;&#32842;&#22825;&#33021;&#21147;&#65292;&#32780;&#26080;&#38656;&#36827;&#19968;&#27493;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#30740;&#31350;&#23637;&#31034;&#20102;&#32842;&#22825;&#21521;&#37327;&#22312;&#19977;&#20010;&#19981;&#21516;&#26041;&#38754;&#30340;&#20248;&#36234;&#26377;&#25928;&#24615;&#65306;&#25351;&#20196;&#36981;&#24490;&#12289;&#27602;&#24615;&#32531;&#35299;&#21644;&#22810;&#36718;&#23545;&#35805;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.04799v2 Announce Type: replace  Abstract: Recently, the development of open-source large language models (LLMs) has advanced rapidly. Nevertheless, due to data constraints, the capabilities of most open-source LLMs are primarily focused on English. To address this issue, we introduce the concept of chat vector to equip pre-trained language models with instruction following and human value alignment via simple model arithmetic. The chat vector is derived by subtracting the weights of a pre-trained base model (e.g. LLaMA2) from those of its corresponding chat model (e.g. LLaMA2-chat). By simply adding the chat vector to a continual pre-trained model's weights, we can endow the model with chat capabilities in new languages without the need for further training. Our empirical studies demonstrate the superior efficacy of the chat vector from three different aspects: instruction following, toxicity mitigation, and multi-turn dialogue. Moreover, to showcase the adaptability of our 
&lt;/p&gt;</description></item><item><title>WebVoyager&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;Web&#20195;&#29702;&#65292;&#33021;&#22815;&#36890;&#36807;&#19982;&#30495;&#23454;&#32593;&#31449;&#20132;&#20114;&#26469;&#31471;&#21040;&#31471;&#22320;&#23436;&#25104;&#29992;&#25143;&#25351;&#20196;&#12290;&#23427;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;Web&#20195;&#29702;&#35780;&#20272;&#21327;&#35758;&#65292;&#24182;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.13919</link><description>&lt;p&gt;
WebVoyager&#65306;&#20351;&#29992;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#26500;&#24314;&#31471;&#21040;&#31471;&#30340;Web Agent
&lt;/p&gt;
&lt;p&gt;
WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models. (arXiv:2401.13919v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13919
&lt;/p&gt;
&lt;p&gt;
WebVoyager&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#30340;Web&#20195;&#29702;&#65292;&#33021;&#22815;&#36890;&#36807;&#19982;&#30495;&#23454;&#32593;&#31449;&#20132;&#20114;&#26469;&#31471;&#21040;&#31471;&#22320;&#23436;&#25104;&#29992;&#25143;&#25351;&#20196;&#12290;&#23427;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;Web&#20195;&#29702;&#35780;&#20272;&#21327;&#35758;&#65292;&#24182;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#27493;&#24341;&#39046;&#20102;&#19968;&#20010;&#30001;&#30495;&#23454;&#19990;&#30028;&#20013;&#33258;&#20027;&#24212;&#29992;&#31243;&#24207;&#30340;&#21457;&#23637;&#25152;&#26631;&#24535;&#30340;&#26032;&#26102;&#20195;&#65292;&#25512;&#21160;&#20102;&#22522;&#20110;&#32593;&#32476;&#30340;&#39640;&#32423;&#20195;&#29702;&#30340;&#21019;&#26032;&#12290;&#29616;&#26377;&#30340;&#32593;&#32476;&#20195;&#29702;&#36890;&#24120;&#21482;&#22788;&#29702;&#19968;&#20010;&#36755;&#20837;&#27169;&#24577;&#65292;&#24182;&#19988;&#20165;&#22312;&#31616;&#21270;&#30340;&#32593;&#32476;&#27169;&#25311;&#22120;&#25110;&#38745;&#24577;&#30340;&#32593;&#32476;&#24555;&#29031;&#20013;&#36827;&#34892;&#35780;&#20272;&#65292;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;WebVoyager&#65292;&#19968;&#31181;&#21019;&#26032;&#30340;&#22522;&#20110;&#22823;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;LMM&#65289;&#30340;Web&#20195;&#29702;&#65292;&#36890;&#36807;&#19982;&#30495;&#23454;&#32593;&#31449;&#36827;&#34892;&#20132;&#20114;&#65292;&#33021;&#22815;&#31471;&#21040;&#31471;&#22320;&#23436;&#25104;&#29992;&#25143;&#25351;&#20196;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;Web&#20195;&#29702;&#35780;&#20272;&#21327;&#35758;&#65292;&#20197;&#35299;&#20915;&#24320;&#25918;&#24335;Web&#20195;&#29702;&#20219;&#21153;&#30340;&#33258;&#21160;&#35780;&#20272;&#25361;&#25112;&#65292;&#21033;&#29992;&#20102;GPT-4V&#30340;&#24378;&#22823;&#22810;&#27169;&#24577;&#29702;&#35299;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#25910;&#38598;&#26469;&#33258;15&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#32593;&#31449;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#26469;&#21019;&#24314;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#20195;&#29702;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;WebVoyager&#23454;&#29616;&#20102;55.7&#65285;&#30340;&#20219;&#21153;&#25104;&#21151;&#29575;&#65292;&#26174;&#33879;&#22320;.....
&lt;/p&gt;
&lt;p&gt;
The advancement of large language models (LLMs) leads to a new era marked by the development of autonomous applications in the real world, which drives innovation in the creation of advanced web-based agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we propose a new evaluation protocol for web agents to address the challenges of automatic evaluation of open-ended web agent tasks, leveraging the robust multimodal comprehension capabilities of GPT-4V. We create a new benchmark by gathering real-world tasks from 15 widely used websites to evaluate our agents. We show that WebVoyager achieves a 55.7% task success rate, significantly 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21483;&#20570;Patchscope&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#26597;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#34255;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#32479;&#19968;&#20102;&#20808;&#21069;&#30340;&#26816;&#26597;&#25216;&#26415;&#65292;&#36824;&#35299;&#20915;&#20102;&#20854;&#20013;&#19968;&#20123;&#38382;&#39064;&#65292;&#24182;&#19988;&#36824;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06102</link><description>&lt;p&gt;
Patchscope: &#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#26597;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#34255;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models. (arXiv:2401.06102v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21483;&#20570;Patchscope&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#26597;&#35821;&#35328;&#27169;&#22411;&#30340;&#38544;&#34255;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#32479;&#19968;&#20102;&#20808;&#21069;&#30340;&#26816;&#26597;&#25216;&#26415;&#65292;&#36824;&#35299;&#20915;&#20102;&#20854;&#20013;&#19968;&#20123;&#38382;&#39064;&#65292;&#24182;&#19988;&#36824;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#26597;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#38544;&#34255;&#34920;&#31034;&#20013;&#32534;&#30721;&#30340;&#20449;&#24687;&#21487;&#20197;&#35299;&#37322;&#27169;&#22411;&#30340;&#34892;&#20026;&#24182;&#39564;&#35777;&#20854;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#30340;&#19968;&#33268;&#24615;&#12290;&#37492;&#20110;LLM&#29983;&#25104;&#20154;&#31867;&#21487;&#29702;&#35299;&#25991;&#26412;&#30340;&#33021;&#21147;&#65292;&#25105;&#20204;&#24314;&#35758;&#21033;&#29992;&#27169;&#22411;&#26412;&#36523;&#20197;&#33258;&#28982;&#35821;&#35328;&#35299;&#37322;&#20854;&#20869;&#37096;&#34920;&#31034;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31216;&#20026;Patchscopes&#30340;&#26694;&#26550;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#23427;&#26469;&#22238;&#31572;&#20851;&#20110;LLM&#35745;&#31639;&#30340;&#21508;&#31181;&#30740;&#31350;&#38382;&#39064;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20808;&#21069;&#22522;&#20110;&#23558;&#34920;&#31034;&#25237;&#24433;&#21040;&#35789;&#27719;&#31354;&#38388;&#21644;&#24178;&#39044;LLM&#35745;&#31639;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#35813;&#26694;&#26550;&#30340;&#29305;&#27530;&#23454;&#20363;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;Patchscope&#21487;&#20197;&#24357;&#34917;&#20248;&#21183;&#65292;&#22914;&#26816;&#26597;&#26089;&#26399;&#23618;&#22833;&#36133;&#25110;&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#12290;&#38500;&#20102;&#32479;&#19968;&#20808;&#21069;&#30340;&#26816;&#26597;&#25216;&#26415;&#65292;Patchscopes&#36824;&#24320;&#36767;&#20102;&#26032;&#30340;&#21487;&#33021;&#24615;&#65292;&#20363;&#22914;&#20351;&#29992;&#26356;&#24378;&#22823;&#30340;&#27169;&#22411;&#26469;&#35299;&#37322;&#36739;&#23567;&#27169;&#22411;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inspecting the information encoded in hidden representations of large language models (LLMs) can explain models' behavior and verify their alignment with human values. Given the capabilities of LLMs in generating human-understandable text, we propose leveraging the model itself to explain its internal representations in natural language. We introduce a framework called Patchscopes and show how it can be used to answer a wide range of research questions about an LLM's computation. We show that prior interpretability methods based on projecting representations into the vocabulary space and intervening on the LLM computation, can be viewed as special instances of this framework. Moreover, several of their shortcomings such as failure in inspecting early layers or lack of expressivity can be mitigated by a Patchscope. Beyond unifying prior inspection techniques, Patchscopes also opens up new possibilities such as using a more capable model to explain the representations of a smaller model,
&lt;/p&gt;</description></item><item><title>&#33258;&#25105;&#23545;&#27604;&#26159;&#19968;&#31181;&#36890;&#36807;&#23545;&#27604;&#19981;&#21516;&#27714;&#35299;&#35270;&#35282;&#21644;&#24635;&#32467;&#24046;&#24322;&#65292;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21453;&#24605;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.02009</link><description>&lt;p&gt;
&#33258;&#25105;&#23545;&#27604;&#65306;&#36890;&#36807;&#19981;&#19968;&#33268;&#30340;&#27714;&#35299;&#35270;&#35282;&#33719;&#24471;&#26356;&#22909;&#30340;&#21453;&#24605;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives. (arXiv:2401.02009v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02009
&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#23545;&#27604;&#26159;&#19968;&#31181;&#36890;&#36807;&#23545;&#27604;&#19981;&#21516;&#27714;&#35299;&#35270;&#35282;&#21644;&#24635;&#32467;&#24046;&#24322;&#65292;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21453;&#24605;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#21453;&#24605;&#33021;&#21147;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#19968;&#31181;&#20107;&#21518;&#25552;&#31034;&#31574;&#30053;&#65292;&#20363;&#22914;&#21453;&#24605;&#21644;&#33258;&#25105;&#25913;&#36827;&#65292;&#26681;&#25454;&#33258;&#25105;&#35780;&#20272;&#25110;&#22806;&#37096;&#21453;&#39304;&#26469;&#25913;&#21892;LLM&#30340;&#21709;&#24212;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;&#22806;&#37096;&#21453;&#39304;&#30340;&#24773;&#20917;&#19979;&#65292;LLM&#30340;&#20869;&#22312;&#21453;&#24605;&#26159;&#19981;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#25581;&#31034;&#20102;&#33258;&#25105;&#35780;&#20272;&#21453;&#39304;&#36136;&#37327;&#26159;&#20851;&#38190;&#29942;&#39048;&#12290;&#25105;&#20204;&#21457;&#29616;LLM&#22312;&#33258;&#25105;&#35780;&#20272;&#26102;&#24120;&#24120;&#34920;&#29616;&#20986;&#36807;&#24230;&#33258;&#20449;&#25110;&#39640;&#24230;&#38543;&#26426;&#24615;&#65292;&#25552;&#20379;&#22266;&#25191;&#25110;&#19981;&#19968;&#33268;&#30340;&#21453;&#39304;&#65292;&#23548;&#33268;&#21453;&#24605;&#33021;&#21147;&#19981;&#20339;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#25105;&#23545;&#27604;&#30340;&#26041;&#27861;&#65306;&#23427;&#26681;&#25454;&#35831;&#27714;&#33258;&#36866;&#24212;&#22320;&#25506;&#32034;&#22810;&#26679;&#30340;&#27714;&#35299;&#35270;&#35282;&#65292;&#23545;&#27604;&#24046;&#24322;&#65292;&#24182;&#23558;&#36825;&#20123;&#24046;&#24322;&#24635;&#32467;&#20026;&#19968;&#20010;&#26816;&#26597;&#34920;&#65292;&#29992;&#20110;&#37325;&#26032;&#23457;&#35270;&#21644;&#28040;&#38500;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36171;&#20104;LLM&#22810;&#26679;&#30340;&#35270;&#35282;&#20197;&#20943;&#36731;&#22266;&#25191;&#20559;&#35265;&#12290;&#27492;&#22806;&#65292;&#24046;&#24322;&#25351;&#31034;&#20102;&#28508;&#22312;&#30340;&#38169;&#35823;&#25110;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reflection capacity of Large Language Model (LLM) has garnered extensive attention. A post-hoc prompting strategy, e.g., reflexion and self-refine, refines LLM's response based on self-evaluated or external feedback. However, recent research indicates without external feedback, LLM's intrinsic reflection is unstable. Our investigation unveils that the key bottleneck is the quality of the self-evaluated feedback. We find LLMs often exhibit overconfidence or high randomness when self-evaluate, offering stubborn or inconsistent feedback, which causes poor reflection. To remedy this, we advocate Self-Contrast: It adaptively explores diverse solving perspectives tailored to the request, contrasts the differences, and summarizes these discrepancies into a checklist which could be used to re-examine and eliminate discrepancies. Our method endows LLM with diverse perspectives to alleviate stubborn biases. Moreover, their discrepancies indicate potential errors or inherent uncertainties tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#24182;&#21033;&#29992;LLM&#26694;&#26550;&#29983;&#25104;&#22810;&#26679;&#30340;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2312.14187</link><description>&lt;p&gt;
WaveCoder: &#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#19982;&#23436;&#21892;&#30340;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation. (arXiv:2312.14187v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#24182;&#21033;&#29992;LLM&#26694;&#26550;&#29983;&#25104;&#22810;&#26679;&#30340;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#65292;&#20197;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#25928;&#26524;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#23545;&#39640;&#36136;&#37327;&#25351;&#20196;&#25968;&#25454;&#38598;&#36827;&#34892;&#35843;&#20248;&#21518;&#65292;&#29983;&#25104;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#24191;&#27867;&#30340;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#25351;&#20196;&#25968;&#25454;&#29983;&#25104;&#26041;&#27861;&#32463;&#24120;&#20250;&#20135;&#29983;&#37325;&#22797;&#25968;&#25454;&#65292;&#24182;&#19988;&#23545;&#25968;&#25454;&#36136;&#37327;&#30340;&#25511;&#21046;&#19981;&#22815;&#28789;&#27963;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#25351;&#20196;&#25968;&#25454;&#20998;&#31867;&#20026;4&#20010;&#19982;&#20195;&#30721;&#30456;&#20851;&#30340;&#20219;&#21153;&#65292;&#25193;&#23637;&#20102;&#25351;&#20196;&#35843;&#20248;&#30340;&#26222;&#36866;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;LLM&#30340;&#29983;&#25104;&#22120;-&#21028;&#21035;&#22120;&#25968;&#25454;&#22788;&#29702;&#26694;&#26550;&#65292;&#20174;&#24320;&#28304;&#20195;&#30721;&#20013;&#29983;&#25104;&#22810;&#26679;&#30340;&#12289;&#39640;&#36136;&#37327;&#30340;&#25351;&#20196;&#25968;&#25454;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;CodeOcean&#65292;&#19968;&#20010;&#21253;&#21547;4&#20010;&#36890;&#29992;&#20195;&#30721;&#30456;&#20851;&#20219;&#21153;&#30340;&#12289;&#20849;&#35745;20,000&#20010;&#25351;&#20196;&#23454;&#20363;&#30340;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#22686;&#24378;&#25351;&#20196;&#35843;&#20248;&#30340;&#25928;&#26524;&#65292;&#24182;&#25552;&#39640;&#35843;&#20248;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;WaveCoder&#65292;&#19968;&#20010;&#20855;&#26377;&#24191;&#27867;&#21644;&#22810;&#21151;&#33021;&#30340;&#25913;&#36827;&#25351;&#20196;&#35843;&#20248;&#30340;Code LLM&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work demonstrates that, after being fine-tuned on a high-quality instruction dataset, the resulting model can obtain impressive capabilities to address a wide range of tasks. However, existing methods for instruction data generation often produce duplicate data and are not controllable enough on data quality. In this paper, we extend the generalization of instruction tuning by classifying the instruction data to 4 code-related tasks and propose a LLM-based Generator-Discriminator data process framework to generate diverse, high-quality instruction data from open source code. Hence, we introduce CodeOcean, a dataset comprising 20,000 instruction instances across 4 universal code-related tasks,which is aimed at augmenting the effectiveness of instruction tuning and improving the generalization ability of fine-tuned model. Subsequently, we present WaveCoder, a fine-tuned Code LLM with Widespread And Versatile Enhanced instruction tuning. This model is specifically designed for enha
&lt;/p&gt;</description></item><item><title>BioInstruct&#26159;&#19968;&#20010;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38024;&#23545;&#24615;&#25351;&#20196;&#25968;&#25454;&#38598;BioInstruct&#65292;&#36890;&#36807;GPT-4&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31934;&#35843;&#65292;&#20248;&#21270;&#20102;&#27169;&#22411;&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.19975</link><description>&lt;p&gt;
BioInstruct:&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25351;&#20196;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing. (arXiv:2310.19975v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19975
&lt;/p&gt;
&lt;p&gt;
BioInstruct&#26159;&#19968;&#20010;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25351;&#20196;&#35843;&#25972;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38024;&#23545;&#24615;&#25351;&#20196;&#25968;&#25454;&#38598;BioInstruct&#65292;&#36890;&#36807;GPT-4&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#31934;&#35843;&#65292;&#20248;&#21270;&#20102;&#27169;&#22411;&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#22312;&#22823;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#36827;&#34892;&#29305;&#23450;&#39046;&#22495;&#30340;&#25351;&#20196;&#35843;&#25972;&#65292;&#22312;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#21482;&#21457;&#34920;&#20102;&#24456;&#23569;&#30340;&#25351;&#20196;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;BioInstruct&#65292;&#36825;&#26159;&#19968;&#20010;&#23450;&#21046;&#30340;&#20219;&#21153;&#29305;&#23450;&#25351;&#20196;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#36229;&#36807;25,000&#20010;&#31034;&#20363;&#12290;&#36890;&#36807;&#20351;&#29992;&#19977;&#20010;&#20154;&#24037;&#31579;&#36873;&#30340;&#25351;&#20196;&#26679;&#26412;&#65292;&#20197;GPT-4&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#25552;&#31034;&#65292;&#31934;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#26088;&#22312;&#20248;&#21270;&#20854;&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;LLaMA LLMs (1&amp;2,7B&amp;13B)&#36827;&#34892;&#20102;&#25351;&#20196;&#35843;&#25972;&#65292;&#24182;&#22312;&#29983;&#29289;&#21307;&#23398;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#20449;&#24687;&#25552;&#21462;&#12289;&#38382;&#31572;&#21644;&#25991;&#26412;&#29983;&#25104;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#25351;&#20196;&#22914;&#20309;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#36129;&#29486;&#65292;&#20351;&#29992;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) has achieved a great success in many natural language processing (NLP) tasks. This is achieved by pretraining of LLMs on vast amount of data and then instruction tuning to specific domains. However, only a few instructions in the biomedical domain have been published. To address this issue, we introduce BioInstruct, a customized task-specific instruction dataset containing more than 25,000 examples. This dataset was generated attractively by prompting a GPT-4 language model with a three-seed-sample of 80 human-curated instructions. By fine-tuning LLMs using the BioInstruct dataset, we aim to optimize the LLM's performance in biomedical natural language processing (BioNLP). We conducted instruction tuning on the LLaMA LLMs (1\&amp;2, 7B\&amp;13B) and evaluated them on BioNLP applications, including information extraction, question answering, and text generation. We also evaluated how instructions contributed to model performance using multi-tasking learning principl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;LLMs&#30340;&#29616;&#20195;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#33021;&#22815;&#26377;&#25928;&#22320;&#25551;&#32472;&#20986;&#30456;&#24212;&#35282;&#33394;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#19982;&#20154;&#31867;&#24863;&#30693;&#30340;&#19968;&#33268;&#24615;&#36798;&#21040;82.8%&#12290;</title><link>http://arxiv.org/abs/2310.17976</link><description>&lt;p&gt;
&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#33021;&#22815;&#25429;&#25417;&#35282;&#33394;&#20010;&#24615;&#21527;&#65311;&#35780;&#20272;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20010;&#24615;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Does Role-Playing Chatbots Capture the Character Personalities? Assessing Personality Traits for Role-Playing Chatbots. (arXiv:2310.17976v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17976
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;LLMs&#30340;&#29616;&#20195;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#33021;&#22815;&#26377;&#25928;&#22320;&#25551;&#32472;&#20986;&#30456;&#24212;&#35282;&#33394;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#19982;&#20154;&#31867;&#24863;&#30693;&#30340;&#19968;&#33268;&#24615;&#36798;&#21040;82.8%&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#24443;&#24213;&#25913;&#21464;&#20102;&#26032;&#22411;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#25171;&#36896;&#20855;&#26377;&#29420;&#29305;&#20154;&#29289;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#26041;&#38754;&#12290;&#37492;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;"&#21050;&#28608;-&#21709;&#24212;"&#24615;&#36136;&#65292;&#26412;&#25991;&#25581;&#31034;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#24320;&#25918;&#24335;&#37319;&#35775;&#24335;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#20174;&#32780;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20854;&#20869;&#22312;&#20010;&#24615;&#12290;&#25105;&#20204;&#23545;ChatHaruhi&#22270;&#20070;&#39302;&#21019;&#24314;&#30340;32&#20010;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#36827;&#34892;&#20102;&#22823;&#20116;&#20154;&#26684;&#21644;MBTI&#32500;&#24230;&#19978;&#30340;&#20010;&#24615;&#35780;&#20272;&#65292;&#24182;&#27979;&#37327;&#23427;&#20204;&#19982;&#20154;&#31867;&#24863;&#30693;&#30340;&#19968;&#33268;&#24615;&#12290;&#35780;&#20272;&#32467;&#26524;&#24378;&#35843;&#65292;&#22522;&#20110;LLMs&#30340;&#29616;&#20195;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#33021;&#22815;&#26377;&#25928;&#22320;&#25551;&#32472;&#20986;&#30456;&#24212;&#35282;&#33394;&#30340;&#20010;&#24615;&#29305;&#28857;&#65292;&#19982;&#20154;&#31867;&#24863;&#30693;&#30340;&#19968;&#33268;&#24615;&#36798;&#21040;82.8%&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22609;&#36896;&#32842;&#22825;&#26426;&#22120;&#20154;&#20010;&#24615;&#30340;&#28508;&#22312;&#31574;&#30053;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20026;&#35282;&#33394;&#25198;&#28436;&#32842;&#22825;&#26426;&#22120;&#20154;&#30740;&#31350;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of large-scale pretrained language models has revolutionized the capabilities of new AI application, especially in the realm of crafting chatbots with distinct personas. Given the "stimulus-response" nature of chatbots, this paper unveils an innovative open-ended interview-style approach for personality assessment on role-playing chatbots, which offers a richer comprehension of their intrinsic personalities. We conduct personality assessments on 32 role-playing chatbots created by the ChatHaruhi library, across both the Big Five and MBTI dimensions, and measure their alignment with human perception. Evaluation results underscore that modern role-playing chatbots based on LLMs can effectively portray personality traits of corresponding characters, with an alignment rate of 82.8% compared with human-perceived personalities. Besides, we also suggest potential strategies for shaping chatbots' personalities. Hence, this paper serves as a cornerstone study for role-playing chat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#31454;&#20105;&#34892;&#20026;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#31454;&#20105;&#29615;&#22659;&#24182;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#31454;&#20105;&#21487;&#20197;&#20419;&#20351;&#26234;&#33021;&#20307;&#36827;&#34892;&#36716;&#21464;&#21644;&#37319;&#21462;&#26032;&#31574;&#30053;&#65292;&#20174;&#32780;&#22312;&#31038;&#20250;&#21644;&#32463;&#27982;&#21457;&#23637;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.17512</link><description>&lt;p&gt;
CompeteAI:&#29702;&#35299;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#20307;&#31454;&#20105;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents. (arXiv:2310.17512v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#31454;&#20105;&#34892;&#20026;&#12290;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#31454;&#20105;&#29615;&#22659;&#24182;&#36827;&#34892;&#23454;&#39564;&#65292;&#21457;&#29616;&#31454;&#20105;&#21487;&#20197;&#20419;&#20351;&#26234;&#33021;&#20307;&#36827;&#34892;&#36716;&#21464;&#21644;&#37319;&#21462;&#26032;&#31574;&#30053;&#65292;&#20174;&#32780;&#22312;&#31038;&#20250;&#21644;&#32463;&#27982;&#21457;&#23637;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#23436;&#25104;&#19981;&#21516;&#20219;&#21153;&#65292;&#22914;&#20010;&#20154;&#21161;&#29702;&#25110;&#20107;&#20214;&#35268;&#21010;&#12290;&#34429;&#28982;&#22823;&#22810;&#25968;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21512;&#20316;&#19982;&#21327;&#20316;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#32034;&#21478;&#19968;&#20010;&#37325;&#35201;&#26426;&#21046;&#8212;&#8212;&#31454;&#20105;&#65292;&#23427;&#26159;&#31038;&#20250;&#21644;&#32463;&#27982;&#21457;&#23637;&#30340;&#25512;&#21160;&#21147;&#20043;&#19968;&#12290;&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;LLM&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#31454;&#20105;&#34892;&#20026;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#26469;&#30740;&#31350;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#31454;&#20105;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;GPT-4&#23454;&#29616;&#20102;&#19968;&#20010;&#23454;&#38469;&#30340;&#31454;&#20105;&#29615;&#22659;&#65292;&#27169;&#25311;&#20102;&#19968;&#20010;&#30001;&#39184;&#39302;&#26234;&#33021;&#20307;&#21644;&#39038;&#23458;&#26234;&#33021;&#20307;&#32452;&#25104;&#30340;&#34394;&#25311;&#22478;&#38215;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#39184;&#39302;&#26234;&#33021;&#20307;&#30456;&#20114;&#31454;&#20105;&#20197;&#21560;&#24341;&#26356;&#22810;&#39038;&#23458;&#65292;&#36825;&#31181;&#31454;&#20105;&#20419;&#20351;&#23427;&#20204;&#36827;&#34892;&#36716;&#21464;&#65292;&#27604;&#22914;&#22521;&#20859;&#26032;&#30340;&#36816;&#33829;&#31574;&#30053;&#12290;&#25105;&#20204;&#23454;&#39564;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#20174;&#31038;&#20250;&#23398;&#20064;&#21040;&#39532;&#22826;&#25928;&#24212;&#31561;&#22810;&#20010;&#26377;&#36259;&#21457;&#29616;&#65292;&#19982;&#29616;&#26377;&#30340;&#31038;&#20250;&#23398;&#21644;&#32463;&#27982;&#23398;&#29702;&#35770;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have been widely used as agents to complete different tasks, such as personal assistance or event planning. While most work has focused on cooperation and collaboration between agents, little work explores competition, another important mechanism that fosters the development of society and economy. In this paper, we seek to examine the competition behaviors in LLM-based agents. We first propose a general framework to study the competition between agents. Then, we implement a practical competitive environment using GPT-4 to simulate a virtual town with two types of agents, including restaurant agents and customer agents. Specifically, restaurant agents compete with each other to attract more customers, where the competition fosters them to transform, such as cultivating new operating strategies. The results of our experiments reveal several interesting findings ranging from social learning to Matthew Effect, which aligns well with existing sociological and e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16834</link><description>&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#20998;&#24067;&#27604;&#20363;&#30340;&#31163;&#25955;&#25193;&#25955;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution. (arXiv:2310.16834v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#33258;&#28982;&#35821;&#35328;&#31561;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#20851;&#38190;&#26159;&#65292;&#26631;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#20381;&#36182;&#20110;&#25104;&#29087;&#30340;&#24471;&#20998;&#21305;&#37197;&#29702;&#35770;&#65292;&#20294;&#26159;&#23558;&#20854;&#25512;&#24191;&#21040;&#31163;&#25955;&#32467;&#26500;&#24182;&#27809;&#26377;&#21462;&#24471;&#30456;&#21516;&#30340;&#32463;&#39564;&#25910;&#30410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#24471;&#20998;&#29109;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#26469;&#24357;&#34917;&#36825;&#20010;&#24046;&#36317;&#65292;&#23427;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#31283;&#23450;&#65292;&#21487;&#20197;&#24418;&#25104;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;ELBO&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21435;&#22122;&#21464;&#20307;&#39640;&#25928;&#20248;&#21270;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65288;SEDD&#65289;&#25193;&#23637;&#21040;GPT-2&#30340;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#23454;&#29616;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#20284;&#28982;&#24230;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#31639;&#27861;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27604;&#36739;&#22823;&#23567;&#30456;&#20284;&#30340;SEDD&#21644;GPT-2&#27169;&#22411;&#26102;&#65292;SEDD&#36798;&#21040;&#20102;&#21487;&#27604;&#36739;&#30340;&#22256;&#24785;&#24230;&#65288;&#36890;&#24120;&#22312;&#22522;&#32447;&#30340;+$10\%$&#20869;&#65292;&#24182;&#19988;&#26377;&#26102;&#36229;&#36807;&#22522;&#32447;&#65289;&#12290;&#27492;&#22806;&#65292;SEDD&#27169;&#22411;&#23398;&#21040;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel discrete score matching loss that is more stable than existing methods, forms an ELBO for maximum likelihood training, and can be efficiently optimized with a denoising variant. We scale our Score Entropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2, achieving highly competitive likelihoods while also introducing distinct algorithmic advantages. In particular, when comparing similarly sized SEDD and GPT-2 models, SEDD attains comparable perplexities (normally within $+10\%$ of and sometimes outperforming the baseline). Furthermore, SEDD models lear
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#25512;&#27979;&#35299;&#30721;&#26159;&#36890;&#36807;&#21033;&#29992;&#22810;&#20313;&#35745;&#31639;&#33021;&#21147;&#65292;&#22312;LLM&#26381;&#21153;&#38598;&#32676;&#20013;&#25345;&#32493;&#26356;&#26032;&#33609;&#31295;&#27169;&#22411;&#65292;&#20174;&#32780;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.07177</link><description>&lt;p&gt;
&#22312;&#32447;&#25512;&#27979;&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
Online Speculative Decoding. (arXiv:2310.07177v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07177
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#25512;&#27979;&#35299;&#30721;&#26159;&#36890;&#36807;&#21033;&#29992;&#22810;&#20313;&#35745;&#31639;&#33021;&#21147;&#65292;&#22312;LLM&#26381;&#21153;&#38598;&#32676;&#20013;&#25345;&#32493;&#26356;&#26032;&#33609;&#31295;&#27169;&#22411;&#65292;&#20174;&#32780;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#27979;&#35299;&#30721;&#26159;&#36890;&#36807;&#21033;&#29992;&#36739;&#23567;&#30340;&#33609;&#31295;&#27169;&#22411;&#26469;&#39044;&#27979;&#30446;&#26631;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#20174;&#32780;&#21152;&#36895;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25512;&#29702;&#30340;&#20851;&#38190;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#22312;&#38754;&#23545;&#22810;&#26679;&#30340;&#25991;&#26412;&#36755;&#20837;&#21644;&#33609;&#31295;&#27169;&#22411;&#19982;&#30446;&#26631;&#27169;&#22411;&#20043;&#38388;&#30340;&#26174;&#33879;&#33021;&#21147;&#24046;&#36317;&#26102;&#65292;&#20854;&#26377;&#25928;&#24615;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22312;&#32447;&#25512;&#27979;&#35299;&#30721;&#65288;OSD&#65289;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#20854;&#20027;&#35201;&#24605;&#24819;&#26159;&#21033;&#29992;LLM&#26381;&#21153;&#38598;&#32676;&#20013;&#20016;&#23500;&#30340;&#22810;&#20313;&#35745;&#31639;&#33021;&#21147;&#65292;&#26681;&#25454;&#35266;&#23519;&#21040;&#30340;&#29992;&#25143;&#26597;&#35810;&#25968;&#25454;&#25345;&#32493;&#26356;&#26032;&#65288;&#22810;&#20010;&#65289;&#33609;&#31295;&#27169;&#22411;&#12290;&#30001;&#20110;LLM&#25512;&#29702;&#21463;&#20869;&#23384;&#38480;&#21046;&#65292;&#20856;&#22411;&#30340;LLM&#26381;&#21153;&#38598;&#32676;&#20013;&#30340;&#21097;&#20313;&#35745;&#31639;&#33021;&#21147;&#21487;&#20197;&#29992;&#20110;&#22312;&#32447;&#37325;&#26032;&#35757;&#32451;&#33609;&#31295;&#27169;&#22411;&#65292;&#20174;&#32780;&#20351;&#35757;&#32451;&#25104;&#26412;&#20445;&#25345;&#20013;&#24615;&#12290;&#30001;&#20110;LLM&#26381;&#21153;&#30340;&#26597;&#35810;&#20998;&#24067;&#30456;&#23545;&#31616;&#21333;&#65292;&#26681;&#25454;&#26597;&#35810;&#20998;&#24067;&#36827;&#34892;&#37325;&#26032;&#35757;&#32451;&#21487;&#20197;&#20351;&#33609;&#31295;&#27169;&#22411;&#26356;&#20934;&#30830;&#22320;&#39044;&#27979;&#30446;&#26631;&#27169;&#22411;&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models. We introduce online speculative decoding (OSD) to address this challenge. The main idea is to continually update (multiple) draft model(s) on observed user query data using the abundant excess computational power in an LLM serving cluster. Given that LLM inference is memory-bounded, the surplus computational power in a typical LLM serving cluster can be repurposed for online retraining of draft models, thereby making the training cost-neutral. Since the query distribution of an LLM service is relatively simple, retraining on query distribution enables the draft model to more accurately predict the target
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#30417;&#30563;&#24494;&#35843;&#36807;&#31243;&#20013;&#65292;&#29305;&#21035;&#26159;&#25968;&#23398;&#25512;&#29702;&#21644;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#26041;&#38754;&#65292;&#25968;&#25454;&#32452;&#21512;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#36739;&#22823;&#27169;&#22411;&#22312;&#30456;&#21516;&#25968;&#25454;&#37327;&#19979;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#22686;&#21152;&#24494;&#35843;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#25968;&#23398;&#25512;&#29702;&#21644;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#24471;&#21040;&#26174;&#33879;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2310.05492</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#23545;&#30417;&#30563;&#24494;&#35843;&#25968;&#25454;&#32452;&#21512;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition. (arXiv:2310.05492v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22312;&#30417;&#30563;&#24494;&#35843;&#36807;&#31243;&#20013;&#65292;&#29305;&#21035;&#26159;&#25968;&#23398;&#25512;&#29702;&#21644;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#26041;&#38754;&#65292;&#25968;&#25454;&#32452;&#21512;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#36739;&#22823;&#27169;&#22411;&#22312;&#30456;&#21516;&#25968;&#25454;&#37327;&#19979;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#22686;&#21152;&#24494;&#35843;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#65292;&#25968;&#23398;&#25512;&#29702;&#21644;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#24471;&#21040;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20855;&#22791;&#22823;&#37327;&#30340;&#39044;&#35757;&#32451;&#26631;&#35760;&#21644;&#21442;&#25968;&#65292;&#23637;&#29616;&#20986;&#25968;&#23398;&#25512;&#29702;&#12289;&#20195;&#30721;&#29983;&#25104;&#21644;&#25351;&#20196;&#36319;&#38543;&#31561;&#33021;&#21147;&#12290;&#36825;&#20123;&#33021;&#21147;&#36890;&#36807;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#36827;&#19968;&#27493;&#22686;&#24378;&#12290;&#24320;&#28304;&#31038;&#21306;&#24050;&#32463;&#30740;&#31350;&#20102;&#38024;&#23545;&#27599;&#31181;&#33021;&#21147;&#30340;&#20020;&#26102;SFT&#65292;&#32780;&#19987;&#26377;LLMs&#21487;&#20197;&#36866;&#29992;&#20110;&#25152;&#26377;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#30740;&#31350;&#22914;&#20309;&#36890;&#36807;SFT&#35299;&#38145;&#22810;&#37325;&#33021;&#21147;&#21464;&#24471;&#37325;&#35201;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;SFT&#36807;&#31243;&#20013;&#25968;&#23398;&#25512;&#29702;&#12289;&#20195;&#30721;&#29983;&#25104;&#21644;&#20154;&#31867;&#23545;&#40784;&#33021;&#21147;&#20043;&#38388;&#30340;&#25968;&#25454;&#32452;&#21512;&#12290;&#20174;&#35268;&#27169;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27169;&#22411;&#33021;&#21147;&#19982;&#21508;&#31181;&#22240;&#32032;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21253;&#25324;&#25968;&#25454;&#37327;&#12289;&#25968;&#25454;&#32452;&#21512;&#27604;&#20363;&#12289;&#27169;&#22411;&#21442;&#25968;&#21644;SFT&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#21457;&#29616;&#19981;&#21516;&#30340;&#33021;&#21147;&#34920;&#29616;&#20986;&#19981;&#21516;&#30340;&#25193;&#23637;&#27169;&#24335;&#65292;&#36739;&#22823;&#30340;&#27169;&#22411;&#36890;&#24120;&#22312;&#30456;&#21516;&#30340;&#25968;&#25454;&#37327;&#19979;&#34920;&#29616;&#20986;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;&#25968;&#23398;&#25512;&#29702;&#21644;&#20195;&#30721;&#29983;&#25104;&#33021;&#21147;&#36890;&#36807;&#24494;&#35843;&#25968;&#25454;&#21644;&#27169;&#22411;&#21442;&#25968;&#30340;&#22686;&#21152;&#32780;&#33719;&#24471;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) with enormous pre-training tokens and parameter amounts emerge abilities, including math reasoning, code generation, and instruction following. These abilities are further enhanced by supervised fine-tuning (SFT). The open-source community has studied on ad-hoc SFT for each ability, while proprietary LLMs are versatile for all abilities. It is important to investigate how to unlock them with multiple abilities via SFT. In this study, we specifically focus on the data composition between mathematical reasoning, code generation, and general human-aligning abilities during SFT. From a scaling perspective, we investigate the relationship between model abilities and various factors including data amounts, data composition ratio, model parameters, and SFT strategies. Our experiments reveal that different abilities exhibit different scaling patterns, and larger models generally show superior performance with the same amount of data. Mathematical reasoning and code
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-UI&#30340;&#22810;&#27169;&#24577;&#21160;&#20316;&#38142;&#26426;&#22120;&#20154;&#65292;&#36890;&#36807;&#30452;&#25509;&#19982;&#30028;&#38754;&#20132;&#20114;&#65292;&#36991;&#20813;&#20102;&#29615;&#22659;&#35299;&#26512;&#25110;&#20381;&#36182;&#20110;&#24212;&#29992;&#31243;&#24207;API&#30340;&#38656;&#35201;&#65292;&#24182;&#24341;&#20837;&#20102;&#21160;&#20316;&#38142;&#25216;&#26415;&#26469;&#24110;&#21161;&#27169;&#22411;&#36827;&#34892;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2309.11436</link><description>&lt;p&gt;
&#20320;&#20165;&#20851;&#27880;&#23631;&#24149;&#65306;&#22810;&#27169;&#24577;&#21160;&#20316;&#38142;&#26426;&#22120;&#20154;
&lt;/p&gt;
&lt;p&gt;
You Only Look at Screens: Multimodal Chain-of-Action Agents. (arXiv:2309.11436v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-UI&#30340;&#22810;&#27169;&#24577;&#21160;&#20316;&#38142;&#26426;&#22120;&#20154;&#65292;&#36890;&#36807;&#30452;&#25509;&#19982;&#30028;&#38754;&#20132;&#20114;&#65292;&#36991;&#20813;&#20102;&#29615;&#22659;&#35299;&#26512;&#25110;&#20381;&#36182;&#20110;&#24212;&#29992;&#31243;&#24207;API&#30340;&#38656;&#35201;&#65292;&#24182;&#24341;&#20837;&#20102;&#21160;&#20316;&#38142;&#25216;&#26415;&#26469;&#24110;&#21161;&#27169;&#22411;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027;&#29992;&#25143;&#30028;&#38754;&#65288;UI&#65289;&#26426;&#22120;&#20154;&#26088;&#22312;&#36890;&#36807;&#19982;&#29992;&#25143;&#30028;&#38754;&#36827;&#34892;&#20132;&#20114;&#65292;&#23454;&#29616;&#20219;&#21153;&#33258;&#21160;&#21270;&#65292;&#26080;&#38656;&#25163;&#21160;&#24178;&#39044;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#33021;&#21147;&#65292;&#20197;&#22312;&#22810;&#26679;&#29615;&#22659;&#20013;&#26377;&#25928;&#21442;&#19982;&#12290;&#20026;&#20102;&#31526;&#21512;LLM&#30340;&#36755;&#20837;-&#36755;&#20986;&#35201;&#27714;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#27801;&#30418;&#29615;&#22659;&#20013;&#24320;&#21457;&#65292;&#20381;&#36182;&#20110;&#22806;&#37096;&#24037;&#20855;&#21644;&#24212;&#29992;&#31243;&#24207;&#29305;&#23450;&#30340;API&#23558;&#29615;&#22659;&#35299;&#26512;&#20026;&#25991;&#26412;&#20803;&#32032;&#65292;&#24182;&#35299;&#37322;&#39044;&#27979;&#30340;&#21160;&#20316;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#24120;&#24120;&#21463;&#21040;&#25512;&#29702;&#25928;&#29575;&#20302;&#21644;&#38169;&#35823;&#20256;&#25773;&#39118;&#38505;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Auto-UI&#65292;&#19968;&#31181;&#22810;&#27169;&#24577;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#30452;&#25509;&#19982;&#30028;&#38754;&#20132;&#20114;&#65292;&#36991;&#20813;&#20102;&#23545;&#29615;&#22659;&#35299;&#26512;&#25110;&#20381;&#36182;&#20110;&#24212;&#29992;&#31243;&#24207;&#30456;&#20851;&#30340;API&#30340;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#20316;&#38142;&#25216;&#26415;&#65292;&#21033;&#29992;&#19968;&#31995;&#21015;&#20013;&#38388;&#20808;&#21069;&#21160;&#20316;&#21382;&#21490;&#21644;&#26410;&#26469;&#21160;&#20316;&#35745;&#21010;&#65292;&#20197;&#24110;&#21161;&#27169;&#22411;&#36827;&#34892;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -leveraging a series of intermediate previous action histories and future action plans -- to help the age
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#26041;&#27861;&#8212;&#8212;&#20803;&#20998;&#24067;&#26041;&#27861;&#65288;MDM&#65289;&#65292;&#35813;&#26041;&#27861;&#23558;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#30340;&#23545;&#27604;&#26144;&#23556;&#21040;&#36136;&#37327;&#24230;&#37327;&#19978;&#65292;&#21487;&#20197;&#35270;&#20026;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#20854;&#21487;&#29992;&#20110;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.11879</link><description>&lt;p&gt;
&#22522;&#20110;&#20803;&#20998;&#24067;&#24314;&#27169;&#30340;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Open-Domain Text Evaluation via Meta Distribution Modeling. (arXiv:2306.11879v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#26041;&#27861;&#8212;&#8212;&#20803;&#20998;&#24067;&#26041;&#27861;&#65288;MDM&#65289;&#65292;&#35813;&#26041;&#27861;&#23558;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#30340;&#23545;&#27604;&#26144;&#23556;&#21040;&#36136;&#37327;&#24230;&#37327;&#19978;&#65292;&#21487;&#20197;&#35270;&#20026;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#20854;&#21487;&#29992;&#20110;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#27169;&#22411;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#25552;&#21319;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#25511;&#21046;&#21644;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#26159;&#21542;&#36798;&#21040;&#25152;&#38656;&#23646;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#20256;&#32479;&#30340;&#22522;&#20110;&#21442;&#32771;&#25991;&#26412;&#30340;&#24230;&#37327;&#26631;&#20934;&#22914;BLEU&#12289;ROUGE&#21644;METEOR&#23545;&#20110;&#24320;&#25918;&#24335;&#29983;&#25104;&#20219;&#21153;&#26469;&#35828;&#26159;&#19981;&#36275;&#22815;&#30340;&#12290;&#21516;&#26679;&#22320;&#65292;&#34429;&#28982;&#20855;&#22791;&#35757;&#32451;&#37492;&#21035;&#22120;&#30340;&#24230;&#37327;&#26631;&#20934;&#34920;&#29616;&#20986;&#20102;&#24076;&#26395;&#30340;&#21069;&#26223;&#65292;&#20294;&#26159;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#35757;&#32451;&#25968;&#25454;&#21017;&#26159;&#19968;&#39033;&#38750;&#24120;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#8212;&#8212;&#20803;&#20998;&#24067;&#26041;&#27861;&#65288;MDM&#65289;&#12290;&#36890;&#36807;&#32771;&#34385;LLMs&#21442;&#25968;&#25968;&#37327;&#19978;&#21319;&#21644;&#24615;&#33021;&#25552;&#21319;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;MDM &#21019;&#36896;&#20102;&#19968;&#20010;&#26144;&#23556;&#65292;&#23558;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#30340;&#23545;&#27604;&#65288;&#19968;&#20010;&#24050;&#30693;&#20248;&#20110;&#21478;&#19968;&#20010;&#65289;&#26144;&#23556;&#21040;&#36136;&#37327;&#24230;&#37327;&#19978;&#65292;&#35813;&#24230;&#37327;&#21487;&#20197;&#35270;&#20026;&#20998;&#24067;&#30340;&#20998;&#24067;&#65292;&#21363;&#20803;&#20998;&#24067;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;MDM&#22312;&#35780;&#20272;&#24320;&#25918;&#39046;&#22495;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in open-domain text generation models powered by large pre-trained language models (LLMs) have achieved remarkable performance. However, evaluating and controlling these models for desired attributes remains a challenge, as traditional reference-based metrics such as BLEU, ROUGE, and METEOR are insufficient for open-ended generation tasks. Similarly, while trainable discriminator-based evaluation metrics show promise, obtaining high-quality training data is a non-trivial task. In this paper, we introduce a novel approach to evaluate open-domain generation - the Meta-Distribution Methods (MDM). Drawing on the correlation between the rising parameter counts and the improving performance of LLMs, MDM creates a mapping from the contrast of two probabilistic distributions -- one known to be superior to the other -to quality measures, which can be viewed as a distribution of distributions i.e. Meta-Distribution. We investigate MDM for open-domain text generation evaluation 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;Active-Prompt&#65292;&#23427;&#20351;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#31034;&#20363;&#25552;&#31034;&#36866;&#24212;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19981;&#21516;&#20219;&#21153;&#65292;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#19982;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2302.12246</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24605;&#32500;&#38142;&#20027;&#21160;&#25552;&#31034;
&lt;/p&gt;
&lt;p&gt;
Active Prompting with Chain-of-Thought for Large Language Models. (arXiv:2302.12246v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;Active-Prompt&#65292;&#23427;&#20351;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#31034;&#20363;&#25552;&#31034;&#36866;&#24212;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19981;&#21516;&#20219;&#21153;&#65292;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#19982;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35268;&#27169;&#26085;&#30410;&#22686;&#22823;&#65292;&#20026;&#21508;&#31181;&#38656;&#35201;&#25512;&#29702;&#30340;&#22797;&#26434;&#20219;&#21153;&#65288;&#22914;&#31639;&#26415;&#21644;&#24120;&#35782;&#25512;&#29702;&#65289;&#24102;&#26469;&#20102;&#26032;&#30340;&#33021;&#21147;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#20219;&#21153;&#29305;&#23450;&#25552;&#31034;&#30340;&#26377;&#25928;&#35774;&#35745;&#23545;LLMs&#20135;&#29983;&#39640;&#36136;&#37327;&#31572;&#26696;&#30340;&#33021;&#21147;&#33267;&#20851;&#37325;&#35201;&#12290;&#29305;&#21035;&#26159;&#65292;&#23545;&#20110;&#22797;&#26434;&#30340;&#38382;&#31572;&#20219;&#21153;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#31034;&#20363;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#25512;&#23548;&#25552;&#31034;&#65292;&#23427;&#22823;&#22823;&#25552;&#39640;&#20102;LLMs&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#24403;&#21069;&#30340;CoT&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#32452;&#22266;&#23450;&#30340;&#20154;&#31867;&#27880;&#37322;&#31034;&#20363;&#65292;&#36825;&#20123;&#31034;&#20363;&#19981;&#19968;&#23450;&#26159;&#19981;&#21516;&#20219;&#21153;&#30340;&#26368;&#26377;&#25928;&#31034;&#20363;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;Active-Prompt&#65292;&#20351;&#29992;&#20219;&#21153;&#29305;&#23450;&#30340;&#31034;&#20363;&#25552;&#31034;&#65288;&#20154;&#20026;&#35774;&#35745;&#30340;CoT&#25512;&#29702;&#27880;&#37322;&#65289;&#26469;&#36866;&#24212;LLMs&#19981;&#21516;&#30340;&#20219;&#21153;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#65292;&#30830;&#23450;&#21738;&#20123;&#38382;&#39064;&#20174;&#20219;&#21153;&#29305;&#23450;&#26597;&#35810;&#27744;&#20013;&#27880;&#37322;&#26368;&#37325;&#35201;&#21644;&#26377;&#29992;&#12290;&#36890;&#36807;&#20511;&#37492;&#20027;&#21160;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20027;&#21160;&#25552;&#31034;(Acitve-Prompt)&#30340;&#26041;&#27861;&#65292;&#23558;&#26368;&#30456;&#20851;&#30340;&#38382;&#39064;&#20316;&#20026;&#20219;&#21153;&#29305;&#23450;&#25552;&#31034;&#28155;&#21152;&#32473;LLMs&#65292;&#20174;&#32780;&#25913;&#21892;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs' ability to produce high-quality answers. In particular, an effective approach for complex question-and-answer tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs. However, current CoT methods rely on a fixed set of human-annotated exemplars, which are not necessarily the most effective examples for different tasks. This paper proposes a new method, Active-Prompt, to adapt LLMs to different tasks with task-specific example prompts (annotated with human-designed CoT reasoning). For this purpose, we propose a solution to the key problem of determining which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowi
&lt;/p&gt;</description></item></channel></rss>