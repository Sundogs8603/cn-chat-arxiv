<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>TRAMS&#26159;&#19968;&#31181;&#35757;&#32451;&#20813;&#36153;&#30340;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#35760;&#24518;&#36873;&#25321;&#31574;&#30053;&#65292;&#23427;&#33021;&#22815;&#25552;&#39640;Transformer&#26550;&#26500;&#22312;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35757;&#32451;&#25110;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.15494</link><description>&lt;p&gt;
TRAMS:&#35757;&#32451;&#20813;&#36153;&#30340;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#35760;&#24518;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
TRAMS: Training-free Memory Selection for Long-range Language Modeling. (arXiv:2310.15494v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15494
&lt;/p&gt;
&lt;p&gt;
TRAMS&#26159;&#19968;&#31181;&#35757;&#32451;&#20813;&#36153;&#30340;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#35760;&#24518;&#36873;&#25321;&#31574;&#30053;&#65292;&#23427;&#33021;&#22815;&#25552;&#39640;Transformer&#26550;&#26500;&#22312;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35757;&#32451;&#25110;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26550;&#26500;&#23545;&#20110;&#20247;&#22810;AI&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#22312;&#38271;&#31243;&#35821;&#35328;&#24314;&#27169;&#26041;&#38754;&#20173;&#38754;&#20020;&#25361;&#25112;&#12290;&#23613;&#31649;&#24050;&#32463;&#35774;&#35745;&#20102;&#20960;&#31181;&#29305;&#23450;&#30340;Transformer&#26550;&#26500;&#26469;&#35299;&#20915;&#38271;&#31243;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#22914;Transformer-XL&#23384;&#22312;&#22823;&#37327;&#26080;&#25928;&#35760;&#24518;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21363;&#25554;&#21363;&#29992;&#30340;&#31574;&#30053;&#65292;&#31216;&#20026;TRAining-free Memory Selection&#65288;TRAMS&#65289;&#65292;&#23427;&#26681;&#25454;&#19968;&#20010;&#31616;&#21333;&#30340;&#25351;&#26631;&#36873;&#25321;&#21442;&#19982;&#27880;&#24847;&#21147;&#35745;&#31639;&#30340;&#26631;&#35760;&#12290;&#35813;&#31574;&#30053;&#20801;&#35768;&#25105;&#20204;&#20445;&#30041;&#19982;&#24403;&#21069;&#26597;&#35810;&#20855;&#26377;&#39640;&#20851;&#27880;&#20998;&#25968;&#21487;&#33021;&#24615;&#30340;&#26631;&#35760;&#65292;&#24182;&#24573;&#30053;&#20854;&#20182;&#26631;&#35760;&#12290;&#25105;&#20204;&#22312;&#21333;&#35789;&#32423;&#22522;&#20934;&#65288;WikiText-103&#65289;&#21644;&#23383;&#31526;&#32423;&#22522;&#20934;&#65288;enwik8&#65289;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#19981;&#36827;&#34892;&#39069;&#22806;&#35757;&#32451;&#25110;&#28155;&#21152;&#39069;&#22806;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#21462;&#24471;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Transformer architecture is crucial for numerous AI models, but it still faces challenges in long-range language modeling. Though several specific transformer architectures have been designed to tackle issues of long-range dependencies, existing methods like Transformer-XL are plagued by a high percentage of ineffective memories. In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric. This strategy allows us to keep tokens that are likely to have a high attention score with the current queries and ignore the other ones. We have tested our approach on the word-level benchmark (WikiText-103) and the character-level benchmark (enwik8), and the results indicate an improvement without having additional training or adding additional parameters.
&lt;/p&gt;</description></item><item><title>MCC-KD&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;CoT&#19968;&#33268;&#24615;&#30693;&#35782;&#33976;&#39311;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36716;&#31227;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#21040;&#36739;&#23567;&#30340;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#29983;&#25104;&#22810;&#20010;&#29702;&#30001;&#24182;&#30830;&#20445;&#20854;&#39044;&#27979;&#30340;&#19968;&#33268;&#24615;&#26469;&#22686;&#24378;&#25512;&#29702;&#22810;&#26679;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.14747</link><description>&lt;p&gt;
MCC-KD: &#22810;CoT&#19968;&#33268;&#24615;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
MCC-KD: Multi-CoT Consistent Knowledge Distillation. (arXiv:2310.14747v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14747
&lt;/p&gt;
&lt;p&gt;
MCC-KD&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;CoT&#19968;&#33268;&#24615;&#30693;&#35782;&#33976;&#39311;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36716;&#31227;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#25512;&#29702;&#33021;&#21147;&#21040;&#36739;&#23567;&#30340;&#27169;&#22411;&#19978;&#65292;&#36890;&#36807;&#29983;&#25104;&#22810;&#20010;&#29702;&#30001;&#24182;&#30830;&#20445;&#20854;&#39044;&#27979;&#30340;&#19968;&#33268;&#24615;&#26469;&#22686;&#24378;&#25512;&#29702;&#22810;&#26679;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22797;&#26434;&#25512;&#29702;&#26041;&#38754;&#23637;&#29616;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#38142;&#24335;&#24605;&#32771;(CoT)&#25552;&#31034;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#23545;&#23558;&#36825;&#20123;&#25512;&#29702;&#33021;&#21147;&#20174;LLMs&#36716;&#31227;&#21040;&#36739;&#23567;&#27169;&#22411;&#20013;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#21516;&#26102;&#23454;&#29616;&#22810;&#26679;&#24615;&#21644;&#19968;&#33268;&#24615;&#30340;&#29702;&#30001;&#23545;&#20110;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#22686;&#24378;&#36825;&#20004;&#20010;&#26041;&#38754;&#65292;&#24182;&#25552;&#20986;&#20102;&#22810;CoT&#19968;&#33268;&#24615;&#30693;&#35782;&#33976;&#39311;(MCC-KD)&#26041;&#27861;&#65292;&#20197;&#39640;&#25928;&#22320;&#25552;&#21462;&#25512;&#29702;&#33021;&#21147;&#12290;&#22312;MCC-KD&#20013;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#38382;&#39064;&#29983;&#25104;&#22810;&#20010;&#29702;&#30001;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#31572;&#26696;&#20998;&#24067;&#20043;&#38388;&#30340;&#21452;&#21521;KL&#25955;&#24230;&#26469;&#30830;&#20445;&#30456;&#24212;&#39044;&#27979;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;MCC-KD&#22312;&#19981;&#21516;&#27169;&#22411;&#26550;&#26500;(LLaMA/FlanT5)&#21644;&#21508;&#31181;&#27169;&#22411;&#35268;&#27169;(3B/7B/11B/13B)&#19978;&#22312;&#25968;&#23398;&#25512;&#29702;&#21644;&#24120;&#35782;&#25512;&#29702;&#22522;&#20934;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;&#23454;&#35777;&#32467;&#26524;&#19981;&#20165;&#35777;&#23454;&#20102;MCC-KD&#22312;&#20998;&#24067;&#20869;&#24773;&#20917;&#19979;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have showcased remarkable capabilities in complex reasoning through chain of thought (CoT) prompting. Recently, there has been a growing interest in transferring these reasoning abilities from LLMs to smaller models. However, achieving both the diversity and consistency in rationales presents a challenge. In this paper, we focus on enhancing these two aspects and propose Multi-CoT Consistent Knowledge Distillation (MCC-KD) to efficiently distill the reasoning capabilities. In MCC-KD, we generate multiple rationales for each question and enforce consistency among the corresponding predictions by minimizing the bidirectional KL-divergence between the answer distributions. We investigate the effectiveness of MCC-KD with different model architectures (LLaMA/FlanT5) and various model scales (3B/7B/11B/13B) on both mathematical reasoning and commonsense reasoning benchmarks. The empirical results not only confirm MCC-KD's superior performance on in-distribution d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#37325;&#26032;&#23450;&#20041;&#25968;&#23383;&#20581;&#24247;&#30028;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;LLMs&#19982;&#22806;&#37096;&#24037;&#20855;&#32467;&#21512;&#20351;&#29992;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#19982;&#20020;&#24202;&#25216;&#26415;&#30340;&#20114;&#21160;&#25928;&#26524;&#65292;&#25913;&#21892;&#20102;&#25968;&#23383;&#21307;&#30103;&#24037;&#20855;&#21644;AI&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;LLMs&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.03560</link><description>&lt;p&gt;
&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#37325;&#26032;&#23450;&#20041;&#25968;&#23383;&#20581;&#24247;&#30028;&#38754;
&lt;/p&gt;
&lt;p&gt;
Redefining Digital Health Interfaces with Large Language Models. (arXiv:2310.03560v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#37325;&#26032;&#23450;&#20041;&#25968;&#23383;&#20581;&#24247;&#30028;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;LLMs&#19982;&#22806;&#37096;&#24037;&#20855;&#32467;&#21512;&#20351;&#29992;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#19982;&#20020;&#24202;&#25216;&#26415;&#30340;&#20114;&#21160;&#25928;&#26524;&#65292;&#25913;&#21892;&#20102;&#25968;&#23383;&#21307;&#30103;&#24037;&#20855;&#21644;AI&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;LLMs&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#20581;&#24247;&#24037;&#20855;&#20855;&#26377;&#26174;&#33879;&#25913;&#21892;&#21307;&#30103;&#26381;&#21153;&#20256;&#36882;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21487;&#29992;&#24615;&#21644;&#20449;&#20219;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#23427;&#20204;&#30340;&#20351;&#29992;&#20173;&#28982;&#30456;&#23545;&#26377;&#38480;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20316;&#20026;&#20855;&#26377;&#22788;&#29702;&#22797;&#26434;&#20449;&#24687;&#21644;&#29983;&#25104;&#20154;&#31867;&#36136;&#37327;&#25991;&#26412;&#33021;&#21147;&#30340;&#36890;&#29992;&#27169;&#22411;&#20986;&#29616;&#65292;&#20026;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#30452;&#25509;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#24212;&#29992;LLMs&#24182;&#19981;&#31616;&#21333;&#65292;&#22240;&#20026;LLMs&#23481;&#26131;&#25552;&#20379;&#19981;&#19968;&#33268;&#25110;&#26080;&#24847;&#20041;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#22806;&#37096;&#24037;&#20855;&#20351;LLMs&#22312;&#20020;&#24202;&#21307;&#30103;&#25216;&#26415;&#20114;&#21160;&#20013;&#25552;&#20379;&#20840;&#26032;&#30028;&#38754;&#12290;&#36825;&#22686;&#24378;&#20102;&#25968;&#23383;&#21307;&#30103;&#24037;&#20855;&#21644;AI&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#21644;&#23454;&#38469;&#24433;&#21709;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#22312;&#20020;&#24202;&#29615;&#22659;&#20013;&#20351;&#29992;LLMs&#30340;&#24403;&#21069;&#38382;&#39064;&#65292;&#22914;&#24187;&#35273;&#12290;&#25105;&#20204;&#36890;&#36807;&#24515;&#34880;&#31649;&#30142;&#30149;&#21644;&#31958;&#23615;&#30149;&#39118;&#38505;&#39044;&#27979;&#30340;&#20363;&#23376;&#38416;&#36848;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#31361;&#20986;&#20102;&#20854;&#20013;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their use remains comparatively limited due, in part, to challenges surrounding usability and trust. Recently, Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, with LLMs susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLMs can utilize external tools to provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLM in clinical settings such as hallucinations. We illustrate our approach with examples from cardiovascular disease and diabetes risk prediction, highlighting the benefit
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22312;&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.17255</link><description>&lt;p&gt;
&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#30340;&#30693;&#35782;&#22270;&#35889;&#65306;&#26368;&#26032;&#21457;&#23637;&#12289;&#25361;&#25112;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17255
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22312;&#29983;&#21629;&#31185;&#23398;&#39046;&#22495;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#21629;&#31185;&#23398;&#26159;&#30740;&#31350;&#29983;&#29289;&#21644;&#29983;&#21629;&#36807;&#31243;&#30340;&#23398;&#31185;&#65292;&#21253;&#25324;&#21270;&#23398;&#12289;&#29983;&#29289;&#23398;&#12289;&#21307;&#23398;&#21644;&#19968;&#31995;&#21015;&#20854;&#20182;&#30456;&#20851;&#23398;&#31185;&#12290;&#29983;&#21629;&#31185;&#23398;&#30340;&#30740;&#31350;&#24037;&#20316;&#38750;&#24120;&#20381;&#36182;&#25968;&#25454;&#65292;&#22240;&#20026;&#23427;&#20204;&#20135;&#29983;&#21644;&#28040;&#36153;&#22823;&#37327;&#31185;&#23398;&#25968;&#25454;&#65292;&#20854;&#20013;&#24456;&#22810;&#25968;&#25454;&#20855;&#26377;&#20851;&#31995;&#21644;&#22270;&#32467;&#26500;&#12290;&#25968;&#25454;&#30340;&#25968;&#37327;&#21644;&#20854;&#20013;&#28041;&#21450;&#30340;&#31185;&#23398;&#27010;&#24565;&#21644;&#20851;&#31995;&#30340;&#22797;&#26434;&#24615;&#25512;&#21160;&#20102;&#24212;&#29992;&#20808;&#36827;&#30340;&#30693;&#35782;&#39537;&#21160;&#25216;&#26415;&#26469;&#31649;&#29702;&#21644;&#35299;&#37322;&#25968;&#25454;&#65292;&#26368;&#32456;&#30446;&#26631;&#26159;&#25512;&#21160;&#31185;&#23398;&#21457;&#29616;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#21644;&#35266;&#28857;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#30693;&#35782;&#22270;&#35889;&#22312;&#29983;&#21629;&#31185;&#23398;&#20013;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#36827;&#23637;&#65292;&#24182;&#23637;&#26395;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#26410;&#26469;&#23545;&#36825;&#20123;&#39046;&#22495;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#19977;&#20010;&#20027;&#39064;&#65306;&#30693;&#35782;&#22270;&#35889;&#30340;&#26500;&#24314;&#21644;&#31649;&#29702;&#65292;&#20197;&#21450;&#22312;&#26032;&#21457;&#29616;&#30340;&#36807;&#31243;&#20013;&#20351;&#29992;&#30693;&#35782;&#22270;&#35889;&#21644;&#30456;&#20851;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
The term life sciences refers to the disciplines that study living organisms and life processes, and include chemistry, biology, medicine, and a range of other related disciplines. Research efforts in life sciences are heavily data-driven, as they produce and consume vast amounts of scientific data, much of which is intrinsically relational and graph-structured.  The volume of data and the complexity of scientific concepts and relations referred to therein promote the application of advanced knowledge-driven technologies for managing and interpreting data, with the ultimate aim to advance scientific discovery.  In this survey and position paper, we discuss recent developments and advances in the use of graph-based technologies in life sciences and set out a vision for how these technologies will impact these fields into the future. We focus on three broad topics: the construction and management of Knowledge Graphs (KGs), the use of KGs and associated technologies in the discovery of ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#23384;&#20648;&#26041;&#24335;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#23450;&#20301;&#30693;&#35782;&#31070;&#32463;&#20803;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35821;&#35328;&#26080;&#20851;&#30693;&#35782;&#31070;&#32463;&#20803;&#30340;&#23384;&#22312;&#65292;&#20197;&#21450;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#22411;&#36864;&#21270;&#30693;&#35782;&#31070;&#32463;&#20803;&#12290;</title><link>http://arxiv.org/abs/2308.13198</link><description>&lt;p&gt;
&#28145;&#20837;&#29702;&#35299;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#30693;&#35782;&#31070;&#32463;&#20803;&#65306;&#35821;&#35328;&#26080;&#20851;&#30693;&#35782;&#31070;&#32463;&#20803;&#21644;&#36864;&#21270;&#30693;&#35782;&#31070;&#32463;&#20803;&#30340;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons. (arXiv:2308.13198v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#23384;&#20648;&#26041;&#24335;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#23450;&#20301;&#30693;&#35782;&#31070;&#32463;&#20803;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35821;&#35328;&#26080;&#20851;&#30693;&#35782;&#31070;&#32463;&#20803;&#30340;&#23384;&#22312;&#65292;&#20197;&#21450;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#22411;&#36864;&#21270;&#30693;&#35782;&#31070;&#32463;&#20803;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;PLMs&#65289;&#21253;&#21547;&#22823;&#37327;&#30340;&#20107;&#23454;&#30693;&#35782;&#65292;&#20294;&#20854;&#23384;&#20648;&#22312;&#21442;&#25968;&#20013;&#30340;&#26041;&#24335;&#23578;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#22810;&#35821;&#35328;PLMs&#20013;&#20107;&#23454;&#30693;&#35782;&#30340;&#23384;&#20648;&#26041;&#24335;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20307;&#31995;&#32467;&#26500;&#30340;&#22810;&#35821;&#35328;&#25972;&#21512;&#26799;&#24230;&#26041;&#27861;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#20934;&#30830;&#22320;&#23450;&#20301;&#30693;&#35782;&#31070;&#32463;&#20803;&#65292;&#24182;&#22312;&#19981;&#21516;&#20307;&#31995;&#32467;&#26500;&#21644;&#35821;&#35328;&#20043;&#38388;&#26356;&#20855;&#26222;&#36941;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#30693;&#35782;&#31070;&#32463;&#20803;&#36827;&#34892;&#20102;&#28145;&#20837;&#25506;&#32034;&#65292;&#24471;&#20986;&#20102;&#20197;&#19979;&#20004;&#39033;&#37325;&#35201;&#30340;&#21457;&#29616;&#65306;&#65288;1&#65289;&#21457;&#29616;&#20102;&#35821;&#35328;&#26080;&#20851;&#30693;&#35782;&#31070;&#32463;&#20803;&#65292;&#20854;&#20197;&#36229;&#36234;&#35821;&#35328;&#30340;&#26041;&#24335;&#23384;&#20648;&#20107;&#23454;&#30693;&#35782;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#36328;&#35821;&#35328;&#30693;&#35782;&#32534;&#36753;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;PLMs&#21487;&#20197;&#22522;&#20110;&#35821;&#35328;&#26080;&#20851;&#30340;&#31070;&#32463;&#20803;&#23436;&#25104;&#27492;&#20219;&#21153;&#65307;&#65288;2&#65289;&#21457;&#29616;&#20102;&#36864;&#21270;&#30693;&#35782;&#31070;&#32463;&#20803;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#22411;&#31070;&#32463;&#20803;&#65292;&#34920;&#26126;&#19981;&#21516;&#30340;&#30693;&#35782;&#31070;&#32463;&#20803;&#21487;&#20197;&#22312;&#25968;&#25454;&#29305;&#24449;&#33806;&#32553;&#30340;&#24773;&#20917;&#19979;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models (PLMs) contain vast amounts of factual knowledge, but how the knowledge is stored in the parameters remains unclear. This paper delves into the complex task of understanding how factual knowledge is stored in multilingual PLMs, and introduces the Architecture-adapted Multilingual Integrated Gradients method, which successfully localizes knowledge neurons more precisely compared to current methods, and is more universal across various architectures and languages. Moreover, we conduct an in-depth exploration of knowledge neurons, leading to the following two important discoveries: (1) The discovery of Language-Independent Knowledge Neurons, which store factual knowledge in a form that transcends language. We design cross-lingual knowledge editing experiments, demonstrating that the PLMs can accomplish this task based on language-independent neurons; (2) The discovery of Degenerate Knowledge Neurons, a novel type of neuron showing that different knowledge neuro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#65292;&#22240;&#27492;&#22312;&#36827;&#34892;&#27169;&#22411;&#32534;&#36753;&#26102;&#65292;&#19981;&#38656;&#35201;&#26356;&#26032;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#12290;</title><link>http://arxiv.org/abs/2308.08742</link><description>&lt;p&gt;
PMET: &#22312;Transformer&#20013;&#30340;&#31934;&#30830;&#27169;&#22411;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
PMET: Precise Model Editing in a Transformer. (arXiv:2308.08742v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08742
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#65292;&#22240;&#27492;&#22312;&#36827;&#34892;&#27169;&#22411;&#32534;&#36753;&#26102;&#65292;&#19981;&#38656;&#35201;&#26356;&#26032;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#32534;&#36753;&#25216;&#26415;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#25104;&#26412;&#20462;&#25913;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#23569;&#37327;&#30693;&#35782;&#65292;&#24182;&#19988;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#26159;&#21069;&#39304;&#32593;&#32476;&#30340;&#38190;&#20540;&#20869;&#23384;&#30340;&#20540;&#12290;&#23427;&#20204;&#36890;&#24120;&#20248;&#21270;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#26469;&#35760;&#24518;&#30446;&#26631;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#26356;&#26032;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#21069;&#39304;&#32593;&#32476;&#30340;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#30340;&#20449;&#24687;&#27969;&#26469;&#33258;&#19977;&#20010;&#37096;&#20998;&#65306;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#12289;&#21069;&#39304;&#32593;&#32476;&#21644;&#27531;&#24046;&#36830;&#25509;&#12290;&#29616;&#26377;&#26041;&#27861;&#24573;&#35270;&#20102;Transformer&#23618;&#38544;&#34255;&#29366;&#24577;&#21253;&#21547;&#20102;&#21069;&#39304;&#32593;&#32476;&#29305;&#21035;&#38656;&#35201;&#30340;&#20449;&#24687;&#36825;&#19968;&#20107;&#23454;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#32534;&#36753;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#31934;&#30830;&#30340;&#27169;&#22411;&#32534;&#36753;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#21069;&#39304;&#32593;&#32476;&#30340;&#38544;&#34255;&#29366;&#24577;&#65292;&#21457;&#29616;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#32534;&#30721;&#20102;&#26576;&#20123;&#36890;&#29992;&#30693;&#35782;&#25552;&#21462;&#27169;&#24335;&#12290;&#36825;&#24847;&#21619;&#30528;&#24403;&#24341;&#20837;&#26032;&#30693;&#35782;&#26102;&#65292;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#30340;&#26435;&#37325;&#19981;&#38656;&#35201;&#26356;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#21360;&#24230;22&#31181;&#23448;&#26041;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#30340;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;IndicTrans2&#31995;&#32479;&#65292;&#23427;&#22312;&#22810;&#20010;&#35821;&#35328;&#23545;&#19978;&#34920;&#29616;&#26368;&#20808;&#36827;&#24182;&#20248;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21360;&#24230;&#35821;&#35328;&#30340;&#22522;&#20934;&#21644;&#35780;&#20272;&#33050;&#26412;&#12290;</title><link>http://arxiv.org/abs/2305.16307</link><description>&lt;p&gt;
IndicTrans2: &#20026;&#21360;&#24230;&#25152;&#26377;22&#31181;&#23448;&#26041;&#35821;&#35328;&#26500;&#24314;&#39640;&#36136;&#37327;&#21487;&#35775;&#38382;&#30340;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages. (arXiv:2305.16307v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16307
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#21360;&#24230;22&#31181;&#23448;&#26041;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#30340;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;IndicTrans2&#31995;&#32479;&#65292;&#23427;&#22312;&#22810;&#20010;&#35821;&#35328;&#23545;&#19978;&#34920;&#29616;&#26368;&#20808;&#36827;&#24182;&#20248;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21360;&#24230;&#35821;&#35328;&#30340;&#22522;&#20934;&#21644;&#35780;&#20272;&#33050;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21360;&#24230;&#26377;&#30528;&#20016;&#23500;&#30340;&#35821;&#35328;&#26223;&#35266;&#65292;&#21253;&#25324;&#22235;&#20010;&#20027;&#35201;&#35821;&#31995;&#30340;&#35821;&#35328;&#65292;&#36229;&#36807;&#21313;&#20159;&#20154;&#21475;&#20351;&#29992;&#12290;&#26412;&#31687;&#35770;&#25991;&#32858;&#28966;&#20110;&#21360;&#24230;&#23466;&#27861;&#21015;&#20986;&#30340;22&#31181;&#35821;&#35328;&#65292;&#34987;&#31216;&#20026;&#8220;&#23448;&#26041;&#35821;&#35328;&#8221;&#12290;&#37492;&#20110;&#35821;&#35328;&#22810;&#26679;&#24615;&#65292;&#39640;&#36136;&#37327;&#21644;&#21487;&#35775;&#38382;&#30340;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#22312;&#21360;&#24230;&#36825;&#26679;&#30340;&#22269;&#23478;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#27492;&#20043;&#21069;&#65292;&#32570;&#23569;&#65288;i&#65289;&#28085;&#30422;&#25152;&#26377;22&#31181;&#35821;&#35328;&#30340;&#24179;&#34892;&#35757;&#32451;&#25968;&#25454;&#65292;&#65288;ii&#65289;&#35206;&#30422;&#36825;&#20123;&#35821;&#35328;&#24182;&#21253;&#21547;&#21360;&#24230;&#30456;&#20851;&#20869;&#23481;&#30340;&#20581;&#22766;&#22522;&#20934;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#25903;&#25345;&#21360;&#24230;&#25152;&#26377;22&#31181;&#23448;&#26041;&#35821;&#35328;&#30340;&#29616;&#26377;&#32763;&#35793;&#27169;&#22411;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#19987;&#27880;&#20110;&#21551;&#29992;22&#31181;&#21360;&#24230;&#23448;&#26041;&#35821;&#35328;&#30340;&#24191;&#27867;&#12289;&#26131;&#20110;&#20351;&#29992;&#21644;&#24320;&#25918;&#24335;&#35775;&#38382;&#22909;&#30340;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#25152;&#38656;&#30340;&#32570;&#22833;&#37096;&#20998;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#22235;&#20010;&#25913;&#36827;&#20851;&#38190;&#39046;&#22495;&#65306;&#31574;&#21010;&#21644;&#21019;&#24314;&#26356;&#22823;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12289;&#21019;&#24314;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#30340;&#22522;&#20934;&#12289;&#36328;&#36234;&#25152;&#26377;22&#31181;&#23448;&#26041;&#35821;&#35328;&#36827;&#34892;&#32763;&#35793;&#65292;&#24182;&#26500;&#24314;&#39640;&#36136;&#37327;&#19988;&#21487;&#35775;&#38382;&#30340;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#31995;&#32479;IndicTrans2&#22312;&#22810;&#20010;&#35821;&#35328;&#23545;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#20248;&#20110;&#29616;&#26377;&#30340;&#22312;22&#31181;&#23448;&#26041;&#35821;&#35328;&#19979;&#30340;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#20123;&#35821;&#35328;&#30340;&#22522;&#20934;&#21644;&#35780;&#20272;&#33050;&#26412;&#65292;&#20351;&#24471;&#30740;&#31350;&#20154;&#21592;&#26356;&#23481;&#26131;&#22320;&#35780;&#20215;&#21644;&#25552;&#39640;&#20851;&#20110;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
India has a rich linguistic landscape with languages from 4 major language families spoken by over a billion people. 22 of these languages are listed in the Constitution of India (referred to as scheduled languages) are the focus of this work. Given the linguistic diversity, high-quality and accessible Machine Translation (MT) systems are essential in a country like India. Prior to this work, there was (i) no parallel training data spanning all the 22 languages, (ii) no robust benchmarks covering all these languages and containing content relevant to India, and (iii) no existing translation models which support all the 22 scheduled languages of India. In this work, we aim to address this gap by focusing on the missing pieces required for enabling wide, easy, and open access to good machine translation systems for all 22 scheduled Indian languages. We identify four key areas of improvement: curating and creating larger training datasets, creating diverse and high-quality benchmarks, tra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102; RewriteLM&#65292;&#19968;&#31181;&#25351;&#20196;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; OpenRewriteEval &#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#21508;&#31181;&#31867;&#22411;&#30340;&#24320;&#25918;&#24335;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#25105;&#20204;&#37319;&#29992;&#26032;&#30340;&#31574;&#30053;&#26469;&#20419;&#36827;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#20026;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#25552;&#20379;&#26356;&#22909;&#30340;&#35780;&#20272;&#25163;&#27573;&#12290;</title><link>http://arxiv.org/abs/2305.15685</link><description>&lt;p&gt;
RewriteLM&#65306;&#19968;&#31181;&#38754;&#21521;&#25991;&#26412;&#37325;&#20889;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting. (arXiv:2305.15685v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102; RewriteLM&#65292;&#19968;&#31181;&#25351;&#20196;&#35843;&#25972;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; OpenRewriteEval &#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#21508;&#31181;&#31867;&#22411;&#30340;&#24320;&#25918;&#24335;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#12290;&#25105;&#20204;&#37319;&#29992;&#26032;&#30340;&#31574;&#30053;&#26469;&#20419;&#36827;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#29983;&#25104;&#65292;&#20174;&#32780;&#20026;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#25552;&#20379;&#26356;&#22909;&#30340;&#35780;&#20272;&#25163;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#23637;&#29616;&#20986;&#22312;&#38271;&#31687;&#25991;&#26412;&#29983;&#25104;&#20219;&#21153;&#20013;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#34920;&#36798;&#26469;&#30340;&#24778;&#20154;&#30340;&#38646;-shot&#33021;&#21147;&#65292;&#28982;&#32780;&#29992;&#25143;&#23545;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#30340;&#26399;&#26395;&#20540;&#24456;&#39640;&#65292;&#27169;&#22411;&#20135;&#29983;&#30340;&#24847;&#22806;&#37325;&#20889;&#65288;&#8220;&#24187;&#35273;&#8221;&#65289;&#20250;&#23545;&#20854;&#25972;&#20307;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#35780;&#20272;&#22522;&#20934;&#20027;&#35201;&#20851;&#27880;&#26377;&#38480;&#30340;&#37325;&#20889;&#39118;&#26684;&#21644;&#21477;&#23376;&#32423;&#37325;&#20889;&#65292;&#32780;&#19981;&#26159;&#38271;&#31687;&#24320;&#25918;&#24335;&#37325;&#20889;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;OpenRewriteEval&#65292;&#23427;&#28085;&#30422;&#20102;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#25351;&#20196;&#34920;&#36798;&#30340;&#21508;&#31181;&#37325;&#20889;&#31867;&#22411;&#12290;&#23427;&#29305;&#21035;&#35774;&#35745;&#29992;&#20110;&#20419;&#36827;&#38271;&#31687;&#25991;&#26412;&#24320;&#25918;&#24335;&#37325;&#20889;&#30340;&#35780;&#20272;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#22522;&#32447;&#27169;&#22411;RewriteLM&#65292;&#19968;&#20010;&#29992;&#20110;&#38271;&#31687;&#25991;&#26412;&#37325;&#20889;&#30340;&#25351;&#20196;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20123;&#26032;&#31574;&#30053;&#65292;&#20197;&#26368;&#23567;&#20154;&#24037;&#24178;&#39044;&#20419;&#36827;&#29983;&#25104;&#22810;&#26679;&#30340;&#25351;&#20196;&#21644;&#20559;&#22909;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities in long-form text generation tasks expressed through natural language instructions. However, user expectations for long-form text rewriting is high, and unintended rewrites (''hallucinations'') produced by the model can negatively impact its overall performance. Existing evaluation benchmarks primarily focus on limited rewriting styles and sentence-level rewriting rather than long-form open-ended rewriting.We introduce OpenRewriteEval, a novel benchmark that covers a wide variety of rewriting types expressed through natural language instructions. It is specifically designed to facilitate the evaluation of open-ended rewriting of long-form texts. In addition, we propose a strong baseline model, RewriteLM, an instruction-tuned large language model for long-form text rewriting. We develop new strategies that facilitate the generation of diverse instructions and preference data with minimal human intervention.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29702;&#35299;&#33021;&#21147;&#30340;&#33539;&#20363;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#19981;&#21516;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11662</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#35780;&#20272;&#20219;&#21153;&#29702;&#35299;&#65306;ChatGPT&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29702;&#35299;&#33021;&#21147;&#30340;&#33539;&#20363;&#65292;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#19981;&#21516;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#65292;&#25506;&#35752;&#20102;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#26041;&#27861;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21151;&#33021;&#30340;&#24778;&#20154;&#25552;&#21319;&#65292;&#21019;&#24314;&#26410;&#26469;&#21487;&#25345;&#32493;&#30340;&#35780;&#20272;&#38598;&#20197;&#35780;&#20272;&#23427;&#20204;&#30340;&#29702;&#35299;&#21464;&#24471;&#36234;&#26469;&#36234;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20272;LLM&#30340;&#33539;&#20363;&#65292;&#35813;&#33539;&#20363;&#21033;&#29992;&#20102;&#27491;&#30830;&#30340;&#19990;&#30028;&#29702;&#35299;&#24212;&#35813;&#22312;&#30456;&#21516;&#21547;&#20041;&#30340;&#19981;&#21516;&#65288;&#24343;&#38647;&#26684;&#65289;&#24847;&#20041;&#19978;&#20445;&#25345;&#19968;&#33268;&#30340;&#24605;&#24819;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19981;&#26159;&#36890;&#36807;&#27491;&#30830;&#24615;&#26469;&#34913;&#37327;&#29702;&#35299;&#65292;&#32780;&#26159;&#36890;&#36807;&#35780;&#20272;&#27169;&#22411;&#33258;&#36523;&#29983;&#25104;&#30340;&#22810;&#20010;&#24847;&#20041;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#26469;&#34913;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#20363;&#21270;&#19968;&#20010;&#27979;&#35797;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#19981;&#21516;&#30340;&#24847;&#20041;&#26159;&#19981;&#21516;&#30340;&#35821;&#35328;&#65292;&#22240;&#27492;&#23558;&#22810;&#35821;&#35328;&#33258;&#25105;&#19968;&#33268;&#24615;&#20316;&#20026;&#27169;&#22411;&#29702;&#35299;&#30340;&#26816;&#39564;&#24182;&#21516;&#26102;&#35299;&#20915;&#22810;&#35821;&#35328;&#30340;&#37325;&#35201;&#20027;&#39064;&#12290;&#25105;&#20204;&#20197;&#26368;&#26032;&#29256;&#26412;&#30340;ChatGPT&#20026;&#25105;&#20204;&#30340;&#30740;&#31350;&#23545;&#35937;&#65292;&#22312;&#19977;&#31181;&#19981;&#21516;&#35821;&#35328;&#20013;&#35780;&#20272;&#20004;&#20010;&#19981;&#21516;&#20219;&#21153;&#30340;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;ChatGPT&#22312;&#22810;&#35821;&#35328;&#19968;&#33268;&#24615;&#26041;&#38754;&#30340;&#20248;&#31168;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#34917;&#20805;&#21477;&#23376;&#65292;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#36827;&#34892;&#35821;&#20041;&#21305;&#37197;&#65292;&#24182;&#20351;&#29992;&#20851;&#38190;&#35789;&#36991;&#20813;&#22122;&#22768;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.03898</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#21152;&#24378;&#30693;&#35782;&#30340;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning. (arXiv:2304.03898v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03898
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#34917;&#20805;&#21477;&#23376;&#65292;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#36827;&#34892;&#35821;&#20041;&#21305;&#37197;&#65292;&#24182;&#20351;&#29992;&#20851;&#38190;&#35789;&#36991;&#20813;&#22122;&#22768;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30701;&#25991;&#26412;&#21305;&#37197;&#20219;&#21153;&#22312;&#24191;&#21578;&#25628;&#32034;&#21644;&#25512;&#33616;&#39046;&#22495;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#30001;&#20110;&#25991;&#26412;&#38271;&#24230;&#30701;&#65292;&#35821;&#20041;&#20449;&#24687;&#21294;&#20047;&#21644;&#21333;&#35789;&#27495;&#20041;&#38382;&#39064;&#25104;&#20026;&#27492;&#31867;&#20219;&#21153;&#30340;&#38590;&#28857;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#24341;&#20837;&#25991;&#26412;&#34917;&#20805;&#21477;&#23376;&#25110;&#30693;&#35782;&#24211;&#26469;&#25552;&#20379;&#38468;&#21152;&#30340;&#29305;&#24449;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#22320;&#20132;&#20114;&#21407;&#22987;&#21477;&#23376;&#21644;&#34917;&#20805;&#21477;&#23376;&#65292;&#20063;&#27809;&#26377;&#32771;&#34385;&#21040;&#22806;&#37096;&#30693;&#35782;&#24211;&#24341;&#20837;&#30340;&#22122;&#22768;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#23545;&#27604;&#23398;&#20064;&#21644;&#22806;&#37096;&#30693;&#35782;&#30340;&#30701;&#25991;&#26412;&#21305;&#37197;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#23545;&#24212;&#30340;&#34917;&#20805;&#21477;&#23376;&#65292;&#24182;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#25351;&#23548;&#27169;&#22411;&#33719;&#24471;&#26356;&#20855;&#35821;&#20041;&#21305;&#37197;&#24615;&#30340;&#21407;&#22987;&#21477;&#23376;&#32534;&#30721;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#36991;&#20813;&#22122;&#22768;&#65292;&#25105;&#20204;&#20351;&#29992;&#20851;&#38190;&#35789;&#20316;&#20026;&#21407;&#22987;&#21477;&#23376;&#30340;&#20027;&#35201;&#35821;&#20041;&#36827;&#34892;&#26816;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, short Text Matching tasks have been widely applied in the fields ofadvertising search and recommendation. The difficulty lies in the lack of semantic information and word ambiguity caused by the short length of the text. Previous works have introduced complement sentences or knowledge bases to provide additional feature information. However, these methods have not fully interacted between the original sentence and the complement sentence, and have not considered the noise issue that may arise from the introduction of external knowledge bases. Therefore, this paper proposes a short Text Matching model that combines contrastive learning and external knowledge. The model uses a generative model to generate corresponding complement sentences and uses the contrastive learning method to guide the model to obtain more semantically meaningful encoding of the original sentence. In addition, to avoid noise, we use keywords as the main semantics of the original sentence to retrie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#37319;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#26041;&#27861;&#26159;&#26368;&#26377;&#25928;&#30340;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.01246</link><description>&lt;p&gt;
&#22823;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#30340;&#23433;&#20840;&#20998;&#26512;&#65306;&#32842;&#22825;GPT&#22312;STPA&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT. (arXiv:2304.01246v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#37319;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#26041;&#27861;&#26159;&#26368;&#26377;&#25928;&#30340;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#22914;ChatGPT&#21644;BERT&#65292;&#30001;&#20110;&#20854;&#20855;&#26377;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#23545;&#35805;&#65292;&#22312;&#35768;&#22810;&#30693;&#35782;&#39046;&#22495;&#20013;&#20855;&#26377;&#35814;&#32454;&#21644;&#26126;&#30830;&#30340;&#31572;&#26696;&#65292;&#27491;&#22312;&#24341;&#39046;&#19968;&#22330;&#26032;&#30340;&#20154;&#24037;&#26234;&#33021;&#28909;&#28526;&#12290;&#34429;&#28982;LLMs&#27491;&#22312;&#36805;&#36895;&#24212;&#29992;&#20110;&#35768;&#22810;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#39046;&#22495;&#65292;&#20294;&#25105;&#20204;&#23545;&#20197;&#19979;&#38382;&#39064;&#24863;&#20852;&#36259;&#65306;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#30340;&#23433;&#20840;&#20998;&#26512;&#26159;&#21542;&#21487;&#20197;&#21033;&#29992;LLMs&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;ChatGPT&#23545;&#33258;&#21160;&#32039;&#24613;&#21046;&#21160;&#65288;AEB&#65289;&#31995;&#32479;&#30340;&#31995;&#32479;&#35770;&#36807;&#31243;&#20998;&#26512;&#65288;STPA&#65289;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;STPA&#26159;&#26368;&#26222;&#36941;&#30340;&#21361;&#38505;&#20998;&#26512;&#25216;&#26415;&#20043;&#19968;&#65292;&#20294;&#23427;&#23384;&#22312;&#35832;&#22810;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#39640;&#22797;&#26434;&#24615;&#21644;&#20027;&#35266;&#24615;&#65292;&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;ChatGPT&#30340;&#24212;&#29992;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#32771;&#34385;&#20854;&#19982;&#20154;&#31867;&#19987;&#23478;&#30340;&#20132;&#20114;&#65292;&#30740;&#31350;&#20102;&#19977;&#31181;&#23558;ChatGPT&#32435;&#20837;STPA&#20013;&#30340;&#26041;&#27861;&#65306;&#19968;&#27425;&#24615;&#21333;&#24037;&#20132;&#20114;&#12289;&#37325;&#22797;&#21333;&#24037;&#20132;&#20114;&#21644;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#12290;&#27604;&#36739;&#32467;&#26524;&#34920;&#26126;&#65306;&#65288;i&#65289;&#22312;&#27809;&#26377;&#20154;&#31867;&#19987;&#23478;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;ChatGPT&#19981;&#33021;&#20026;STPA&#25552;&#20379;&#36275;&#22815;&#30340;&#20449;&#24687;&#65307;&#65288;ii&#65289;&#19968;&#27425;&#24615;&#21333;&#24037;&#20132;&#20114;&#23545;STPA&#26377;&#24110;&#21161;&#65292;&#20294;&#19981;&#22914;&#37325;&#22797;&#20132;&#20114;&#26377;&#25928;&#65307;&#65288;iii&#65289;&#37325;&#22797;&#21452;&#24037;&#20132;&#20114;&#19968;&#33268;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#24182;&#26174;&#30528;&#25552;&#39640;&#20102;STPA&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLMs&#21487;&#20197;&#24212;&#29992;&#20110;&#23433;&#20840;&#20998;&#26512;&#65292;&#24182;&#20026;AEB&#20197;&#22806;&#30340;&#20854;&#20182;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21435;&#20559;&#32622;&#30340;&#26041;&#27861;&#65292;&#19968;&#31181;&#36890;&#36807;&#22686;&#21152;2D&#25193;&#25955;&#27169;&#22411;&#24471;&#20986;&#30340;&#20998;&#25968;&#30340;&#25130;&#26029;&#20540;&#65292;&#19968;&#31181;&#36890;&#36807;&#35843;&#25972;&#35270;&#35282;&#25552;&#31034;&#21644;&#29289;&#20307;&#31354;&#38388;&#25668;&#20687;&#26426;&#23039;&#24577;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20266;&#24433;&#65292;&#25552;&#39640;&#30495;&#23454;&#24863;&#12290;</title><link>http://arxiv.org/abs/2303.15413</link><description>&lt;p&gt;
2D&#25193;&#25955;&#31639;&#27861;&#30340;&#21435;&#20559;&#32622;&#26041;&#27861;&#29992;&#20110;&#25991;&#26412;&#21040;3D&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation. (arXiv:2303.15413v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21435;&#20559;&#32622;&#30340;&#26041;&#27861;&#65292;&#19968;&#31181;&#36890;&#36807;&#22686;&#21152;2D&#25193;&#25955;&#27169;&#22411;&#24471;&#20986;&#30340;&#20998;&#25968;&#30340;&#25130;&#26029;&#20540;&#65292;&#19968;&#31181;&#36890;&#36807;&#35843;&#25972;&#35270;&#35282;&#25552;&#31034;&#21644;&#29289;&#20307;&#31354;&#38388;&#25668;&#20687;&#26426;&#23039;&#24577;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20266;&#24433;&#65292;&#25552;&#39640;&#30495;&#23454;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#25991;&#26412;&#21040;3D&#29983;&#25104;&#20013;&#20986;&#29616;&#30340;&#35270;&#35282;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#20063;&#31216;&#20026;Janus&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#26469;&#33258;&#20110;2D&#25193;&#25955;&#27169;&#22411;&#30340;&#22266;&#26377;&#20559;&#32622;&#65292;&#23548;&#33268;&#29983;&#25104;&#30340;3D&#23545;&#35937;&#19981;&#30495;&#23454;&#12290;&#36890;&#36807;&#23545;&#20854;&#36827;&#34892;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21435;&#38500;&#20559;&#32622;&#20197;&#23454;&#29616;&#25991;&#26412;&#21040;3D&#29983;&#25104;&#30340;&#40065;&#26834;&#24615;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#21483;&#20570;score debiasing&#65292;&#36890;&#36807;&#36880;&#28176;&#22686;&#21152;2D&#25193;&#25955;&#27169;&#22411;&#24471;&#20986;&#30340;&#20998;&#25968;&#30340;&#25130;&#26029;&#20540;&#65292;&#26469;&#36798;&#21040;&#21435;&#38500;&#20559;&#32622;&#30340;&#25928;&#26524;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#21483;&#20570;prompt debiasing&#65292;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#30830;&#23450;&#29992;&#25143;&#25552;&#31034;&#21644;&#35270;&#35282;&#25552;&#31034;&#20043;&#38388;&#30340;&#30683;&#30462;&#35789;&#35821;&#65292;&#24182;&#35843;&#25972;&#35270;&#35282;&#25552;&#31034;&#21644;&#29289;&#20307;&#31354;&#38388;&#25668;&#20687;&#26426;&#23039;&#24577;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26174;&#33879;&#20943;&#23569;&#20266;&#24433;&#65292;&#25552;&#39640;&#20102;&#30495;&#23454;&#24863;&#65292;&#24182;&#22312;&#36136;&#37327;&#19982;&#36895;&#24230;&#26041;&#38754;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The view inconsistency problem in score-distilling text-to-3D generation, also known as the Janus problem, arises from the intrinsic bias of 2D diffusion models, which leads to the unrealistic generation of 3D objects. In this work, we explore score-distilling text-to-3D generation and identify the main causes of the Janus problem. Based on these findings, we propose two approaches to debias the score-distillation frameworks for robust text-to-3D generation. Our first approach, called score debiasing, involves gradually increasing the truncation value for the score estimated by 2D diffusion models throughout the optimization process. Our second approach, called prompt debiasing, identifies conflicting words between user prompts and view prompts utilizing a language model and adjusts the discrepancy between view prompts and object-space camera poses. Our experimental results show that our methods improve realism by significantly reducing artifacts and achieve a good trade-off between fa
&lt;/p&gt;</description></item><item><title>SEAM&#26159;&#19968;&#31181;&#38598;&#25104;&#20102;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#30340;&#27169;&#22411;&#65292;&#20026;&#23454;&#29616;&#38405;&#35835;&#20013;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#23436;&#25972;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#20102;&#37325;&#35201;&#19968;&#27493;&#12290;</title><link>http://arxiv.org/abs/2303.05221</link><description>&lt;p&gt;
SEAM:&#19968;&#31181;&#38598;&#25104;&#20102;&#21477;&#23376;&#22788;&#29702;&#19982;&#38405;&#35835;&#20013;&#30524;&#21160;&#30340;&#28608;&#27963;&#32806;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SEAM: An Integrated Activation-Coupled Model of Sentence Processing and Eye Movements in Reading. (arXiv:2303.05221v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05221
&lt;/p&gt;
&lt;p&gt;
SEAM&#26159;&#19968;&#31181;&#38598;&#25104;&#20102;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#30340;&#27169;&#22411;&#65292;&#20026;&#23454;&#29616;&#38405;&#35835;&#20013;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#23436;&#25972;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#20102;&#37325;&#35201;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38405;&#35835;&#20013;&#30340;&#30524;&#21160;&#25511;&#21046;&#27169;&#22411;&#36890;&#24120;&#38598;&#20013;&#22312;&#35270;&#35273;&#12289;&#27880;&#24847;&#12289;&#35789;&#27719;&#21644;&#36816;&#21160;&#36807;&#31243;&#65292;&#20294;&#24573;&#30053;&#20102;&#35789;&#27719;&#21518;&#22788;&#29702;&#30340;&#35821;&#35328;&#22788;&#29702;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#21477;&#23376;&#29702;&#35299;&#36807;&#31243;&#30340;&#27169;&#22411;&#36890;&#24120;&#21482;&#20851;&#27880;&#35789;&#27719;&#21518;&#22788;&#29702;&#30340;&#35821;&#35328;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36825;&#20004;&#31181;&#30740;&#31350;&#32447;&#32034;&#32467;&#21512;&#36215;&#26469;&#30340;&#27169;&#22411;&#65292;&#21363;&#25972;&#21512;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#12290;&#24320;&#21457;&#36825;&#26679;&#19968;&#20010;&#25972;&#21512;&#27169;&#22411;&#20855;&#26377;&#26497;&#22823;&#30340;&#25361;&#25112;&#24615;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#20294;&#36825;&#26679;&#30340;&#25972;&#21512;&#26159;&#26397;&#30528;&#23436;&#25972;&#30340;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#25105;&#20204;&#23558;&#30524;&#21160;&#25511;&#21046;&#27169;&#22411;SWIFT&#65288;Seelig&#31561;&#20154;&#65292;2020&#65289;&#19982;Lewis&#21644;Vasishth&#21477;&#23376;&#22788;&#29702;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65288;Lewis&#65286;Vasishth&#65292;2005&#65289;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#36825;&#31181;&#25972;&#21512;&#39318;&#27425;&#21464;&#24471;&#21487;&#33021;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#22240;&#20026;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models of eye-movement control during reading, developed largely within psychology, usually focus on visual, attentional, lexical, and motor processes but neglect post-lexical language processing; by contrast, models of sentence comprehension processes, developed largely within psycholinguistics, generally focus only on post-lexical language processes. We present a model that combines these two research threads, by integrating eye-movement control and sentence processing. Developing such an integrated model is extremely challenging and computationally demanding, but such an integration is an important step toward complete mathematical models of natural language comprehension in reading. We combine the SWIFT model of eye-movement control (Seelig et al., 2020, doi:10.1016/j.jmp.2019.102313) with key components of the Lewis and Vasishth sentence processing model (Lewis &amp; Vasishth, 2005, doi:10.1207/s15516709cog0000_25). This integration becomes possible, for the first time, due in part to
&lt;/p&gt;</description></item></channel></rss>