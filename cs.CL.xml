<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#37325;&#26032;&#25506;&#35752;&#20102;&#22312;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#21476;&#20856;$n$-gram&#24179;&#28369;&#25216;&#26415;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#20219;&#20309;$n$-gram&#24179;&#28369;&#25216;&#26415;&#36716;&#25442;&#20026;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#20860;&#23481;&#27491;&#21017;&#21270;&#22120;&#30340;&#36890;&#29992;&#26694;&#26550;</title><link>https://arxiv.org/abs/2403.17240</link><description>&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#26102;&#20195;&#30340;$n$-gram&#24179;&#28369;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Role of $n$-gram Smoothing in the Age of Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#25506;&#35752;&#20102;&#22312;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#21476;&#20856;$n$-gram&#24179;&#28369;&#25216;&#26415;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#23558;&#20219;&#20309;$n$-gram&#24179;&#28369;&#25216;&#26415;&#36716;&#25442;&#20026;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#20860;&#23481;&#27491;&#21017;&#21270;&#22120;&#30340;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23558;&#36817;&#19977;&#21313;&#24180;&#30340;&#26102;&#38388;&#37324;&#65292;&#22522;&#20110;$n$-gram&#20551;&#35774;&#30340;&#35821;&#35328;&#27169;&#22411;&#19968;&#30452;&#26159;&#35813;&#20219;&#21153;&#30340;&#25216;&#26415;&#27700;&#24179;&#12290;&#23427;&#20204;&#25104;&#21151;&#30340;&#20851;&#38190;&#22312;&#20110;&#24212;&#29992;&#21508;&#31181;&#24179;&#28369;&#25216;&#26415;&#26469;&#23545;&#25239;&#36807;&#25311;&#21512;&#12290;&#28982;&#32780;&#65292;&#24403;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#21462;&#20195;$n$-gram&#27169;&#22411;&#25104;&#20026;&#26368;&#20339;&#34920;&#29616;&#32773;&#26102;&#65292;$n$-gram&#24179;&#28369;&#25216;&#26415;&#21464;&#24471;&#19981;&#22826;&#30456;&#20851;&#12290;&#20107;&#23454;&#19978;&#65292;&#21487;&#20197;&#27627;&#19981;&#22840;&#24352;&#22320;&#35828;&#65292;&#23545;$n$-gram&#24179;&#28369;&#25216;&#26415;&#30340;&#30740;&#31350;&#22312;&#36825;&#19968;&#26102;&#20195;&#21464;&#24471;&#20572;&#28382;&#12290;&#26412;&#25991;&#37325;&#26032;&#25506;&#35752;&#20102;&#22312;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#26102;&#20195;&#21476;&#20856;$n$-gram&#24179;&#28369;&#25216;&#26415;&#21487;&#33021;&#21457;&#25381;&#30340;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#26631;&#31614;&#24179;&#28369;&#21644;add-$\lambda$&#24179;&#28369;&#20043;&#38388;&#24314;&#31435;&#20102;&#19968;&#20010;&#27491;&#24335;&#31561;&#20215;&#24615;&#65292;&#26631;&#31614;&#24179;&#28369;&#26159;&#19968;&#31181;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#30340;&#27969;&#34892;&#27491;&#21017;&#21270;&#25216;&#26415;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#23558;\emph{&#20219;&#20309;} $n$-gram&#24179;&#28369;&#25216;&#26415;&#36716;&#25442;&#20026;&#19982;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#20860;&#23481;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17240v1 Announce Type: new  Abstract: For nearly three decades, language models derived from the $n$-gram assumption held the state of the art on the task. The key to their success lay in the application of various smoothing techniques that served to combat overfitting. However, when neural language models toppled $n$-gram models as the best performers, $n$-gram smoothing techniques became less relevant. Indeed, it would hardly be an understatement to suggest that the line of inquiry into $n$-gram smoothing techniques became dormant. This paper re-opens the role classical $n$-gram smoothing techniques may play in the age of neural language models. First, we draw a formal equivalence between label smoothing, a popular regularization technique for neural language models, and add-$\lambda$ smoothing. Second, we derive a generalized framework for converting \emph{any} $n$-gram smoothing technique into a regularizer compatible with neural language models. Our empirical results fi
&lt;/p&gt;</description></item><item><title>NUMTEMP&#26159;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#65292;&#19987;&#27880;&#20110;&#39564;&#35777;&#22797;&#26434;&#30340;&#25968;&#23383;&#35770;&#28857;&#65292;&#37327;&#21270;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#30495;&#23454;&#19990;&#30028;&#25968;&#23383;&#35770;&#28857;&#39564;&#35777;&#25361;&#25112;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.17169</link><description>&lt;p&gt;
NUMTEMP&#65306;&#19968;&#20010;&#29992;&#20110;&#39564;&#35777;&#24102;&#26377;&#32479;&#35745;&#21644;&#26102;&#38388;&#34920;&#36798;&#24335;&#30340;&#35770;&#28857;&#30340;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
NUMTEMP: A real-world benchmark to verify claims with statistical and temporal expressions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17169
&lt;/p&gt;
&lt;p&gt;
NUMTEMP&#26159;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#65292;&#19987;&#27880;&#20110;&#39564;&#35777;&#22797;&#26434;&#30340;&#25968;&#23383;&#35770;&#28857;&#65292;&#37327;&#21270;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#30495;&#23454;&#19990;&#30028;&#25968;&#23383;&#35770;&#28857;&#39564;&#35777;&#25361;&#25112;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#20107;&#23454;&#26816;&#26597;&#22312;&#25968;&#23383;&#26102;&#20195;&#24212;&#23545;&#19981;&#26029;&#22686;&#38271;&#30340;&#38169;&#35823;&#20449;&#24687;&#26041;&#38754;&#24341;&#36215;&#20102;&#26497;&#22823;&#20852;&#36259;&#12290;&#29616;&#26377;&#31995;&#32479;&#20027;&#35201;&#19987;&#27880;&#20110;&#32500;&#22522;&#30334;&#31185;&#19978;&#30340;&#21512;&#25104;&#35770;&#28857;&#65292;&#24182;&#19988;&#22312;&#30495;&#23454;&#19990;&#30028;&#35770;&#28857;&#19978;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;Numtemp&#65292;&#19968;&#20010;&#22810;&#26679;&#21270;&#12289;&#22810;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#65292;&#19987;&#38376;&#20851;&#27880;&#25968;&#23383;&#35770;&#28857;&#65292;&#21253;&#25324;&#26102;&#38388;&#12289;&#32479;&#35745;&#21644;&#22810;&#26679;&#21270;&#26041;&#38754;&#30340;&#32454;&#31890;&#24230;&#20803;&#25968;&#25454;&#65292;&#24182;&#19988;&#20855;&#26377;&#19981;&#27844;&#38706;&#30340;&#35777;&#25454;&#25910;&#38598;&#12290;&#36825;&#35299;&#20915;&#20102;&#39564;&#35777;&#30495;&#23454;&#19990;&#30028;&#25968;&#23383;&#35770;&#28857;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#35770;&#28857;&#22797;&#26434;&#65292;&#24448;&#24448;&#32570;&#20047;&#31934;&#30830;&#20449;&#24687;&#65292;&#36825;&#26159;&#29616;&#26377;&#20316;&#21697;&#20027;&#35201;&#20851;&#27880;&#21512;&#25104;&#35770;&#28857;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35780;&#20272;&#24182;&#37327;&#21270;&#20102;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#22312;&#39564;&#35777;&#25968;&#23383;&#35770;&#28857;&#20219;&#21153;&#20013;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#22522;&#20110;&#35770;&#28857;&#20998;&#35299;&#30340;&#26041;&#27861;&#12289;&#22522;&#20110;&#25968;&#23383;&#29702;&#35299;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26368;&#20339;&#22522;&#32447;&#23454;&#29616;&#20102;58.32&#30340;&#23439;F1&#20998;&#25968;&#12290;&#36825;&#35777;&#26126;&#20102;Numtemp&#30340;&#20851;&#38190;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17169v1 Announce Type: cross  Abstract: Automated fact checking has gained immense interest to tackle the growing misinformation in the digital era. Existing systems primarily focus on synthetic claims on Wikipedia, and noteworthy progress has also been made on real-world claims. In this work, we release Numtemp, a diverse, multi-domain dataset focused exclusively on numerical claims, encompassing temporal, statistical and diverse aspects with fine-grained metadata and an evidence collection without leakage. This addresses the challenge of verifying real-world numerical claims, which are complex and often lack precise information, not addressed by existing works that mainly focus on synthetic claims. We evaluate and quantify the limitations of existing solutions for the task of verifying numerical claims. We also evaluate claim decomposition based methods, numerical understanding based models and our best baselines achieves a macro-F1 of 58.32. This demonstrates that Numtemp
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#36870;&#21521;&#35757;&#32451;&#30340;&#26367;&#20195;&#35757;&#32451;&#26041;&#26696;&#65292;&#36890;&#36807;&#22312;&#27491;&#21521;&#21644;&#36870;&#21521;&#26041;&#21521;&#19978;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24182;&#20445;&#30041;&#36873;&#23450;&#23376;&#20018;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30340;&#36870;&#36716;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.13799</link><description>&lt;p&gt;
&#36870;&#21521;&#35757;&#32451;&#20197;&#28040;&#38500;&#36870;&#36716;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
Reverse Training to Nurse the Reversal Curse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13799
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#36870;&#21521;&#35757;&#32451;&#30340;&#26367;&#20195;&#35757;&#32451;&#26041;&#26696;&#65292;&#36890;&#36807;&#22312;&#27491;&#21521;&#21644;&#36870;&#21521;&#26041;&#21521;&#19978;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24182;&#20445;&#30041;&#36873;&#23450;&#23376;&#20018;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38754;&#20020;&#30340;&#36870;&#36716;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#23384;&#22312;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#22833;&#36133;&#29616;&#35937;&#65306;&#24403;&#35757;&#32451;&#27169;&#22411;&#20197;"A&#20855;&#26377;&#29305;&#24449;B"&#20026;&#22522;&#30784;&#26102;&#65292;&#23427;&#20204;&#26080;&#27861;&#27867;&#21270;&#21040;"B&#26159;A&#30340;&#29305;&#24449;"&#65292;&#36825;&#34987;&#31216;&#20026;&#36870;&#36716;&#35781;&#21650;&#12290;&#21363;&#20351;&#22312;&#20351;&#29992;&#25968;&#19975;&#20159;&#20196;&#29260;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#30001;&#20110;&#40784;&#22827;&#23450;&#24459;&#30340;&#23384;&#22312;&#65292;&#36825;&#20010;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65292;&#36825;&#24847;&#21619;&#30528;&#21363;&#20351;&#25105;&#20204;&#22312;&#25972;&#20010;&#20114;&#32852;&#32593;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#35813;&#38382;&#39064;&#20173;&#28982;&#20250;&#20986;&#29616;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36870;&#21521;&#35757;&#32451;&#30340;&#26367;&#20195;&#35757;&#32451;&#26041;&#26696;&#65292;&#22312;&#20854;&#20013;&#25152;&#26377;&#21333;&#35789;&#34987;&#20351;&#29992;&#20004;&#27425;&#65292;&#20174;&#32780;&#20351;&#21487;&#29992;&#20196;&#29260;&#25968;&#37327;&#21152;&#20493;&#12290;&#35813;LLM&#22312;&#27491;&#21521;&#21644;&#36870;&#21521;&#26041;&#21521;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#36890;&#36807;&#39072;&#20498;&#35757;&#32451;&#23383;&#31526;&#20018;&#26469;&#39072;&#20498;&#35757;&#32451;&#36807;&#31243;&#65292;&#21516;&#26102;&#20445;&#30041;&#65288;&#21363;&#19981;&#39072;&#20498;&#65289;&#36873;&#23450;&#30340;&#23376;&#20018;&#65292;&#22914;&#23454;&#20307;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#25454;&#21305;&#37197;&#30340;&#36870;&#21521;&#35757;&#32451;&#27169;&#22411;&#22312;&#26631;&#20934;&#20219;&#21153;&#19978;&#27604;&#26631;&#20934;&#27169;&#22411;&#34920;&#29616;&#26356;&#20248;&#31168;&#65292;&#24182;&#19988;&#35745;&#31639;&#21305;&#37197;&#30340;&#36870;&#21521;&#35757;&#32451;&#27169;&#22411;&#22312;&#36870;&#36716;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#36828;&#36828;&#20248;&#20110;&#26631;&#20934;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#26377;&#21161;&#20110;&#35299;&#20915;&#36870;&#36716;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13799v1 Announce Type: new  Abstract: Large language models (LLMs) have a surprising failure: when trained on "A has a feature B", they do not generalize to "B is a feature of A", which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MUSE&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35775;&#38382;&#26368;&#26032;&#20449;&#24687;&#24182;&#35780;&#20272;&#21487;&#20449;&#24230;&#65292;&#20197;&#35299;&#20915;&#31038;&#20132;&#23186;&#20307;&#19978;&#35823;&#20449;&#24687;&#32416;&#27491;&#30340;&#38590;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.11169</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#32416;&#27491;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#38169;&#35823;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Correcting misinformation on social media with a large language model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11169
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MUSE&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#35775;&#38382;&#26368;&#26032;&#20449;&#24687;&#24182;&#35780;&#20272;&#21487;&#20449;&#24230;&#65292;&#20197;&#35299;&#20915;&#31038;&#20132;&#23186;&#20307;&#19978;&#35823;&#20449;&#24687;&#32416;&#27491;&#30340;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35823;&#20449;&#24687;&#20250;&#30772;&#22351;&#20844;&#20247;&#23545;&#31185;&#23398;&#21644;&#27665;&#20027;&#30340;&#20449;&#20219;&#65292;&#29305;&#21035;&#26159;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#65292;&#19981;&#20934;&#30830;&#20449;&#24687;&#20250;&#36805;&#36895;&#20256;&#25773;&#12290;&#19987;&#23478;&#21644;&#26222;&#36890;&#20154;&#36890;&#36807;&#25163;&#21160;&#35782;&#21035;&#21644;&#35299;&#37322;&#19981;&#20934;&#30830;&#20449;&#24687;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#32416;&#27491;&#35823;&#20449;&#24687;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24456;&#38590;&#25193;&#23637;&#65292;&#36825;&#26159;&#19968;&#20010;&#25285;&#24551;&#65292;&#22240;&#20026;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#31561;&#25216;&#26415;&#20351;&#35823;&#20449;&#24687;&#26356;&#23481;&#26131;&#29983;&#25104;&#12290;LLMs&#36824;&#20855;&#26377;&#22810;&#21151;&#33021;&#33021;&#21147;&#65292;&#21487;&#20197;&#21152;&#36895;&#32416;&#27491;&#35823;&#20449;&#24687;&#65307;&#28982;&#32780;&#65292;&#23427;&#20204;&#30001;&#20110;&#32570;&#20047;&#26368;&#26032;&#20449;&#24687;&#12289;&#20542;&#21521;&#20110;&#29983;&#25104;&#20284;&#26159;&#32780;&#38750;&#30340;&#20869;&#23481;&#21644;&#24341;&#29992;&#20197;&#21450;&#26080;&#27861;&#22788;&#29702;&#22810;&#27169;&#24577;&#20449;&#24687;&#32780;&#38754;&#20020;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MUSE&#65292;&#36825;&#26159;&#19968;&#20010;&#24102;&#26377;&#26368;&#26032;&#20449;&#24687;&#35775;&#38382;&#21644;&#21487;&#20449;&#24230;&#35780;&#20272;&#30340;LLM&#12290;&#36890;&#36807;&#26816;&#32034;&#19978;&#19979;&#25991;&#35777;&#25454;&#21644;&#21453;&#39539;&#65292;MUSE&#21487;&#20197;&#25552;&#20379;&#20934;&#30830;&#21487;&#20449;&#30340;&#35299;&#37322;&#21644;&#21442;&#32771;&#12290;&#23427;&#36824;&#25551;&#36848;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11169v1 Announce Type: cross  Abstract: Misinformation undermines public trust in science and democracy, particularly on social media where inaccuracies can spread rapidly. Experts and laypeople have shown to be effective in correcting misinformation by manually identifying and explaining inaccuracies. Nevertheless, this approach is difficult to scale, a concern as technologies like large language models (LLMs) make misinformation easier to produce. LLMs also have versatile capabilities that could accelerate misinformation correction; however, they struggle due to a lack of recent information, a tendency to produce plausible but false content and references, and limitations in addressing multimodal information. To address these issues, we propose MUSE, an LLM augmented with access to and credibility evaluation of up-to-date information. By retrieving contextual evidence and refutations, MUSE can provide accurate and trustworthy explanations and references. It also describes 
&lt;/p&gt;</description></item><item><title>&#20154;&#24037;&#26234;&#33021;&#21442;&#36187;&#32773;Brilla AI&#22312;&#20840;&#22269;&#31185;&#23398;&#19982;&#25968;&#23398;&#31454;&#36187;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#20026;&#32570;&#20047;&#21512;&#26684;&#25945;&#24072;&#30340;&#38750;&#27954;&#25552;&#20379;&#20102;&#23398;&#20064;&#25903;&#25345;&#12290;</title><link>https://arxiv.org/abs/2403.01699</link><description>&lt;p&gt;
Brilla AI: &#20840;&#22269;&#31185;&#23398;&#19982;&#25968;&#23398;&#31454;&#36187;&#30340;&#20154;&#24037;&#26234;&#33021;&#21442;&#36187;&#32773;
&lt;/p&gt;
&lt;p&gt;
Brilla AI: AI Contestant for the National Science and Maths Quiz
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01699
&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#21442;&#36187;&#32773;Brilla AI&#22312;&#20840;&#22269;&#31185;&#23398;&#19982;&#25968;&#23398;&#31454;&#36187;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#20026;&#32570;&#20047;&#21512;&#26684;&#25945;&#24072;&#30340;&#38750;&#27954;&#25552;&#20379;&#20102;&#23398;&#20064;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#27954;&#22823;&#38470;&#32570;&#20047;&#36275;&#22815;&#30340;&#21512;&#26684;&#25945;&#24072;&#65292;&#36825;&#38459;&#30861;&#20102;&#25552;&#20379;&#36275;&#22815;&#30340;&#23398;&#20064;&#25903;&#25345;&#12290;&#20154;&#24037;&#26234;&#33021;&#26377;&#21487;&#33021;&#22686;&#24378;&#26377;&#38480;&#25968;&#37327;&#25945;&#24072;&#30340;&#21162;&#21147;&#65292;&#20174;&#32780;&#24102;&#26469;&#26356;&#22909;&#30340;&#23398;&#20064;&#25104;&#26524;&#12290;&#26412;&#25991;&#25551;&#36848;&#24182;&#35780;&#20272;&#20102;NSMQ AI Grand Challenge&#30340;&#39318;&#35201;&#25104;&#26524;&#65292;&#35813;&#25361;&#25112;&#25552;&#20986;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#29616;&#23454;&#22522;&#20934;&#65292;&#29992;&#20110;&#35780;&#20272;&#27492;&#31867;&#20154;&#24037;&#26234;&#33021;&#65306;&#8220;&#24314;&#31435;&#19968;&#20010;&#20154;&#24037;&#26234;&#33021;&#65292;&#21442;&#21152;&#21152;&#32435;&#30340;&#20840;&#22269;&#31185;&#23398;&#19982;&#25968;&#23398;&#31454;&#36187;&#65288;NSMQ&#65289;&#65292;&#24182;&#33719;&#32988;&#8212;&#8212;&#22312;&#27604;&#36187;&#30340;&#25152;&#26377;&#36718;&#27425;&#21644;&#38454;&#27573;&#20013;&#34920;&#29616;&#20248;&#20110;&#26368;&#20248;&#31168;&#30340;&#21442;&#36187;&#32773;&#8221;&#12290;NSMQ&#26159;&#21152;&#32435;&#30340;&#39640;&#20013;&#23398;&#29983;&#27599;&#24180;&#20030;&#34892;&#30340;&#29616;&#22330;&#31185;&#23398;&#19982;&#25968;&#23398;&#31454;&#36187;&#65292;3&#38431;2&#21517;&#23398;&#29983;&#36890;&#36807;&#22238;&#31572;&#29983;&#29289;&#23398;&#12289;&#21270;&#23398;&#12289;&#29289;&#29702;&#21644;&#25968;&#23398;&#38382;&#39064;&#22312;5&#36718;&#27604;&#36187;&#20013;&#31454;&#20105;&#65292;&#36880;&#28176;&#26187;&#32423;&#33267;&#26368;&#32456;&#20896;&#20891;&#30340;&#38431;&#20237;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;Brilla AI&#65292;&#19968;&#20010;&#21442;&#21152;NSMQ&#31454;&#36187;&#30340;&#20154;&#24037;&#26234;&#33021;&#36873;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01699v1 Announce Type: cross  Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: "Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we de
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#22522;&#20934;&#26469;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#23545;&#35805;&#20013;&#30340;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;split-softmax&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#23545;&#25239;&#27880;&#24847;&#21147;&#34928;&#20943;&#21644;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;</title><link>https://arxiv.org/abs/2402.10962</link><description>&lt;p&gt;
&#22312;&#35821;&#35328;&#27169;&#22411;&#23545;&#35805;&#20013;&#27979;&#37327;&#21644;&#25511;&#21046;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;
&lt;/p&gt;
&lt;p&gt;
Measuring and Controlling Persona Drift in Language Model Dialogs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10962
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#21270;&#22522;&#20934;&#26469;&#27979;&#37327;&#35821;&#35328;&#27169;&#22411;&#23545;&#35805;&#20013;&#30340;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;split-softmax&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#23545;&#25239;&#27880;&#24847;&#21147;&#34928;&#20943;&#21644;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#31034;&#26159;&#23450;&#21046;&#35821;&#35328;&#27169;&#22411;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#26631;&#20934;&#24037;&#20855;&#65292;&#20351;&#20854;&#33021;&#22815;&#25215;&#25285;&#29305;&#23450;&#30340;&#8220;&#20154;&#35774;&#8221;&#12290;&#22312;&#20351;&#29992;&#25552;&#31034;&#26102;&#30340;&#19968;&#20010;&#38544;&#21547;&#20551;&#35774;&#26159;&#65292;&#23427;&#20204;&#23558;&#26159;&#31283;&#23450;&#30340;&#65292;&#22240;&#27492;&#32842;&#22825;&#26426;&#22120;&#20154;&#23558;&#22312;&#25972;&#20010;&#23545;&#35805;&#36807;&#31243;&#20013;&#32487;&#32493;&#26681;&#25454;&#35268;&#23450;&#30340;&#8220;&#20154;&#35774;&#8221;&#29983;&#25104;&#25991;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#37327;&#21270;&#22522;&#20934;&#26469;&#27979;&#35797;&#36825;&#19968;&#20551;&#35774;&#65292;&#36890;&#36807;&#20004;&#20010;&#20010;&#24615;&#21270;&#32842;&#22825;&#26426;&#22120;&#20154;&#20043;&#38388;&#30340;&#33258;&#25105;&#23545;&#35805;&#26469;&#35780;&#20272;&#8220;&#20154;&#35774;&#8221;&#30340;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#23545;&#27969;&#34892;&#27169;&#22411;&#22914;LLaMA2-chat-70B&#36827;&#34892;&#27979;&#35797;&#65292;&#21457;&#29616;&#22312;&#20843;&#36718;&#23545;&#35805;&#20013;&#23384;&#22312;&#26174;&#33879;&#30340;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;&#12290;&#23545;&#36825;&#19968;&#29616;&#35937;&#30340;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#30001;&#20110;&#38271;&#23545;&#35805;&#20013;&#30340;&#27880;&#24847;&#21147;&#34928;&#20943;&#65292;&#21464;&#21387;&#22120;&#27880;&#24847;&#21147;&#26426;&#21046;&#36215;&#21040;&#20102;&#19968;&#23450;&#20316;&#29992;&#12290;&#20026;&#20102;&#23545;&#25239;&#27880;&#24847;&#21147;&#34928;&#20943;&#21644;&#8220;&#20154;&#35774;&#8221;&#28418;&#31227;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;split-softmax&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;&#65292;&#19982;&#20004;&#20010;&#24378;&#22522;&#32447;&#26041;&#27861;&#30456;&#27604;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10962v1 Announce Type: cross  Abstract: Prompting is a standard tool for customizing language-model chatbots, enabling them to take on a specific "persona". An implicit assumption in the use of prompts is that they will be stable, so the chatbot will continue to generate text according to the stipulated persona for the duration of a conversation. We propose a quantitative benchmark to test this assumption, evaluating persona stability via self-chats between two personalized chatbots. Testing popular models like LLaMA2-chat-70B, we reveal a significant persona drift within eight rounds of conversations. An empirical and theoretical analysis of this phenomenon suggests the transformer attention mechanism plays a role, due to attention decay over long exchanges. To combat attention decay and persona drift, we propose a lightweight method called split-softmax, which compares favorably against two strong baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20989;&#25968;&#35843;&#29992;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#38646;-shot&#23545;&#35805;&#29366;&#24577;&#36861;&#36394;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#21462;&#24471;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#36866;&#24212;&#19981;&#21516;&#39046;&#22495;&#32780;&#26080;&#38656;&#22823;&#37327;&#25968;&#25454;&#25910;&#38598;&#25110;&#27169;&#22411;&#35843;&#25972;&#12290;</title><link>https://arxiv.org/abs/2402.10466</link><description>&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38646;-shot&#23545;&#35805;&#29366;&#24577;&#36861;&#36394;&#22120;&#36890;&#36807;&#20989;&#25968;&#35843;&#29992;
&lt;/p&gt;
&lt;p&gt;
Large Language Models as Zero-shot Dialogue State Tracker through Function Calling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20989;&#25968;&#35843;&#29992;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29992;&#20110;&#38646;-shot&#23545;&#35805;&#29366;&#24577;&#36861;&#36394;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#20013;&#21462;&#24471;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#36866;&#24212;&#19981;&#21516;&#39046;&#22495;&#32780;&#26080;&#38656;&#22823;&#37327;&#25968;&#25454;&#25910;&#38598;&#25110;&#27169;&#22411;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#20250;&#35805;&#31995;&#32479;&#20013;&#26085;&#30410;&#26222;&#36941;&#65292;&#36825;&#26159;&#22240;&#20026;&#23427;&#20204;&#22312;&#19968;&#33324;&#24773;&#22659;&#20013;&#20855;&#26377;&#20808;&#36827;&#30340;&#29702;&#35299;&#21644;&#29983;&#25104;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#38656;&#35201;&#19981;&#20165;&#36827;&#34892;&#21709;&#24212;&#29983;&#25104;&#36824;&#38656;&#35201;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#39046;&#22495;&#20869;&#36827;&#34892;&#26377;&#25928;&#23545;&#35805;&#29366;&#24577;&#36861;&#36394;&#65288;DST&#65289;&#30340;&#20219;&#21153;&#23548;&#21521;&#23545;&#35805;&#65288;TOD&#65289;&#20013;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#20173;&#19981;&#23613;&#20154;&#24847;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20989;&#25968;&#35843;&#29992;&#35299;&#20915;LLMs&#20013;&#30340;DST&#30340;&#26032;&#26041;&#27861;FnCTOD&#12290;&#36825;&#31181;&#26041;&#27861;&#25913;&#36827;&#20102;&#38646;-shot DST&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#21508;&#31181;&#39046;&#22495;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#22823;&#37327;&#25968;&#25454;&#25910;&#38598;&#25110;&#27169;&#22411;&#35843;&#25972;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20351;&#29992;&#24320;&#28304;&#25110;&#19987;&#26377;LLMs&#26102;&#37117;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65306;&#36890;&#36807;&#19978;&#19979;&#25991;&#25552;&#31034;&#65292;&#20351;&#24471;&#21508;&#31181;7B&#25110;13B&#21442;&#25968;&#27169;&#22411;&#36229;&#36234;&#20102;&#20043;&#21069;&#30001;ChatGPT&#23454;&#29616;&#30340;&#26368;&#26032;&#25216;&#26415;&#25104;&#26524;&#65288;SOTA&#65289;&#30340;&#27700;&#24179;&#65292;&#24182;&#25552;&#39640;&#20102;ChatGPT&#30340;&#24615;&#33021;&#65292;&#20987;&#36133;&#20102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10466v1 Announce Type: cross  Abstract: Large language models (LLMs) are increasingly prevalent in conversational systems due to their advanced understanding and generative capabilities in general contexts. However, their effectiveness in task-oriented dialogues (TOD), which requires not only response generation but also effective dialogue state tracking (DST) within specific tasks and domains, remains less satisfying. In this work, we propose a novel approach FnCTOD for solving DST with LLMs through function calling. This method improves zero-shot DST, allowing adaptation to diverse domains without extensive data collection or model tuning. Our experimental results demonstrate that our approach achieves exceptional performance with both modestly sized open-source and also proprietary LLMs: with in-context prompting it enables various 7B or 13B parameter models to surpass the previous state-of-the-art (SOTA) achieved by ChatGPT, and improves ChatGPT's performance beating the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#26469;&#27169;&#25311;&#20154;&#20204;&#36890;&#36807;&#23454;&#39564;&#20027;&#21160;&#25512;&#26029;&#38544;&#34255;&#35268;&#21017;&#30340;&#36807;&#31243;&#65292;&#24182;&#21457;&#29616;&#26174;&#24335;&#20551;&#35774;&#12289;&#27010;&#29575;&#35268;&#21017;&#21644;&#22312;&#32447;&#26356;&#26032;&#30340;&#32452;&#21512;&#21487;&#20197;&#35299;&#37322;&#20154;&#20204;&#22312;&#31867;&#20284;Zendo&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.06025</link><description>&lt;p&gt;
&#29992;&#33258;&#28982;&#35821;&#35328;&#21644;&#27010;&#29575;&#25512;&#29702;&#36827;&#34892;&#23454;&#39564;&#19982;&#20462;&#35746;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#26469;&#27169;&#25311;&#20154;&#20204;&#36890;&#36807;&#23454;&#39564;&#20027;&#21160;&#25512;&#26029;&#38544;&#34255;&#35268;&#21017;&#30340;&#36807;&#31243;&#65292;&#24182;&#21457;&#29616;&#26174;&#24335;&#20551;&#35774;&#12289;&#27010;&#29575;&#35268;&#21017;&#21644;&#22312;&#32447;&#26356;&#26032;&#30340;&#32452;&#21512;&#21487;&#20197;&#35299;&#37322;&#20154;&#20204;&#22312;&#31867;&#20284;Zendo&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#35745;&#31639;&#27169;&#22411;&#65292;&#27169;&#25311;&#20154;&#20204;&#36890;&#36807;&#23454;&#39564;&#20027;&#21160;&#25512;&#26029;&#38544;&#34255;&#35268;&#21017;&#30340;&#36807;&#31243;&#12290;&#35813;&#27169;&#22411;&#30340;&#22522;&#26412;&#21407;&#29702;&#26159;&#65292;&#21363;&#20351;&#35268;&#21017;&#26159;&#30830;&#23450;&#24615;&#30340;&#65292;&#23398;&#20064;&#32773;&#20063;&#20250;&#32771;&#34385;&#26356;&#24191;&#27867;&#30340;&#27169;&#31946;&#27010;&#29575;&#35268;&#21017;&#65292;&#24182;&#29992;&#33258;&#28982;&#35821;&#35328;&#34920;&#31034;&#65292;&#26681;&#25454;&#36817;&#20284;&#36125;&#21494;&#26031;&#21407;&#21017;&#22312;&#27599;&#27425;&#23454;&#39564;&#21518;&#22312;&#32447;&#26356;&#26032;&#33258;&#24049;&#30340;&#20551;&#35774;&#12290;&#22312;&#21516;&#19968;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#36824;&#26681;&#25454;&#20449;&#24687;&#35770;&#20934;&#21017;&#24314;&#31435;&#20102;&#23454;&#39564;&#35774;&#35745;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#19977;&#20010;&#21407;&#21017;&#30340;&#32452;&#21512;&#8212;&#8212;&#26174;&#24335;&#20551;&#35774;&#12289;&#27010;&#29575;&#35268;&#21017;&#21644;&#22312;&#32447;&#26356;&#26032;&#8212;&#8212;&#21487;&#20197;&#35299;&#37322;&#20154;&#20204;&#22312;&#31867;&#20284;Zendo&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#32780;&#21435;&#25481;&#20854;&#20013;&#20219;&#20309;&#19968;&#20010;&#32452;&#20214;&#37117;&#20351;&#24471;&#27169;&#22411;&#26080;&#27861;&#35299;&#37322;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We build a computational model of how humans actively infer hidden rules by doing experiments. The basic principles behind the model is that, even if the rule is deterministic, the learner considers a broader space of fuzzy probabilistic rules, which it represents in natural language, and updates its hypotheses online after each experiment according to approximately Bayesian principles. In the same framework we also model experiment design according to information-theoretic criteria. We find that the combination of these three principles -- explicit hypotheses, probabilistic rules, and online updates -- can explain human performance on a Zendo-style task, and that removing any of these components leaves the model unable to account for the data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#21644;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#20013;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#32452;&#20214;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#39046;&#22495;&#65292;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#65292;&#19981;&#30456;&#20851;&#25991;&#26723;&#30340;&#21253;&#21547;&#21487;&#33021;&#20250;&#23545;&#31995;&#32479;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.14887</link><description>&lt;p&gt;
&#22122;&#22768;&#30340;&#21147;&#37327;&#65306;&#37325;&#26032;&#23450;&#20041;RAG&#31995;&#32479;&#30340;&#26816;&#32034;
&lt;/p&gt;
&lt;p&gt;
The Power of Noise: Redefining Retrieval for RAG Systems. (arXiv:2401.14887v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#21644;&#35780;&#20272;&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#20013;&#30340;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#32452;&#20214;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#24573;&#35270;&#30340;&#39046;&#22495;&#65292;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#65292;&#19981;&#30456;&#20851;&#25991;&#26723;&#30340;&#21253;&#21547;&#21487;&#33021;&#20250;&#23545;&#31995;&#32479;&#24615;&#33021;&#20135;&#29983;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#32034;&#22686;&#24378;&#29983;&#25104;&#65288;RAG&#65289;&#31995;&#32479;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20195;&#34920;&#20102;&#19968;&#20010;&#37325;&#22823;&#36827;&#27493;&#12290;RAG&#31995;&#32479;&#36890;&#36807;&#25972;&#21512;&#36890;&#36807;&#20449;&#24687;&#26816;&#32034;&#65288;IR&#65289;&#38454;&#27573;&#26816;&#32034;&#30340;&#22806;&#37096;&#25968;&#25454;&#26469;&#22686;&#24378;&#20854;&#29983;&#25104;&#33021;&#21147;&#65292;&#20811;&#26381;&#20102;&#26631;&#20934;LLMs&#30340;&#38480;&#21046;&#65292;&#21518;&#32773;&#20165;&#38480;&#20110;&#20854;&#39044;&#20808;&#35757;&#32451;&#30340;&#30693;&#35782;&#21644;&#26377;&#38480;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#12290;&#36825;&#20010;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;RAG&#31995;&#32479;&#20869;LLMs&#30340;&#29983;&#25104;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#36890;&#36807;&#20840;&#38754;&#32780;&#25209;&#21028;&#24615;&#22320;&#20998;&#26512;IR&#32452;&#20214;&#23545;RAG&#31995;&#32479;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#26816;&#32034;&#22120;&#22312;&#26377;&#25928;&#30340;RAG&#30340;&#25552;&#31034;&#34920;&#36848;&#20013;&#24212;&#35813;&#20855;&#22791;&#30340;&#29305;&#24449;&#65292;&#37325;&#28857;&#20851;&#27880;&#24212;&#35813;&#26816;&#32034;&#21738;&#31181;&#31867;&#22411;&#30340;&#25991;&#26723;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#22240;&#32032;&#65292;&#22914;&#25991;&#26723;&#19982;&#25552;&#31034;&#30340;&#30456;&#20851;&#24615;&#65292;&#23427;&#20204;&#30340;&#20301;&#32622;&#20197;&#21450;&#19978;&#19979;&#25991;&#20013;&#21253;&#21547;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20986;&#65292;&#21253;&#21547;&#19981;&#30456;&#20851;&#30340;&#25991;&#26723;&#21487;&#33021;&#20250;&#8230;
&lt;/p&gt;
&lt;p&gt;
Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22238;&#24212;&#20102;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32039;&#24613;&#31867;&#27604;&#25512;&#29702;&#30340;&#20027;&#24352;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#23383;&#31526;&#20018;&#31867;&#27604;&#30340;&#21453;&#20363;&#26469;&#21453;&#39539;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;GPT-3&#26080;&#27861;&#35299;&#20915;&#26368;&#31616;&#21333;&#30340;&#31867;&#27604;&#38382;&#39064;&#12290;&#20026;&#20102;&#21152;&#24378;&#38646;&#28857;&#25512;&#29702;&#31561;&#20154;&#31867;&#25512;&#29702;&#30340;&#20027;&#24352;&#65292;&#38656;&#35201;&#21457;&#23637;&#20986;&#25490;&#38500;&#25968;&#25454;&#35760;&#24518;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.16118</link><description>&lt;p&gt;
&#22238;&#24212;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#32039;&#24613;&#31867;&#27604;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16118
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22238;&#24212;&#20102;&#20851;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#32039;&#24613;&#31867;&#27604;&#25512;&#29702;&#30340;&#20027;&#24352;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#23383;&#31526;&#20018;&#31867;&#27604;&#30340;&#21453;&#20363;&#26469;&#21453;&#39539;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;GPT-3&#26080;&#27861;&#35299;&#20915;&#26368;&#31616;&#21333;&#30340;&#31867;&#27604;&#38382;&#39064;&#12290;&#20026;&#20102;&#21152;&#24378;&#38646;&#28857;&#25512;&#29702;&#31561;&#20154;&#31867;&#25512;&#29702;&#30340;&#20027;&#24352;&#65292;&#38656;&#35201;&#21457;&#23637;&#20986;&#25490;&#38500;&#25968;&#25454;&#35760;&#24518;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#12298;&#33258;&#28982;&#20154;&#31867;&#34892;&#20026;&#12299;&#35770;&#25991;&#20013;&#65292;&#8220;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#32039;&#24613;&#31867;&#27604;&#25512;&#29702;&#8221;&#65288;Webb&#65292;Holyoak&#21644;Lu&#65292;2023&#65289;&#65292;&#20316;&#32773;&#20204;&#35748;&#20026;&#8220;&#20687;GPT-3&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#33719;&#24471;&#20102;&#21457;&#29616;&#24191;&#27867;&#31867;&#27604;&#38382;&#39064;&#30340;&#38646;&#28857;&#35299;&#30340;&#32039;&#24613;&#33021;&#21147;&#8221;&#12290;&#22312;&#26412;&#22238;&#24212;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#23383;&#31526;&#20018;&#31867;&#27604;&#30340;&#21453;&#20363;&#12290;&#22312;&#25105;&#20204;&#30340;&#27979;&#35797;&#20013;&#65292;GPT-3&#29978;&#33267;&#26080;&#27861;&#35299;&#20915;&#21407;&#22987;&#35770;&#25991;&#20013;&#25552;&#20986;&#30340;&#26368;&#31616;&#21333;&#30340;&#21464;&#20307;&#38382;&#39064;&#12290;&#38646;&#28857;&#25512;&#29702;&#26159;&#19968;&#20010;&#38656;&#35201;&#38750;&#24120;&#20805;&#20998;&#35777;&#25454;&#25903;&#25345;&#30340;&#38750;&#20961;&#20027;&#24352;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#27809;&#26377;&#30475;&#21040;&#36825;&#26679;&#30340;&#35777;&#25454;&#12290;&#20026;&#20102;&#21152;&#24378;&#20687;&#38646;&#28857;&#25512;&#29702;&#36825;&#26679;&#31867;&#20284;&#20154;&#31867;&#25512;&#29702;&#30340;&#20027;&#24352;&#65292;&#37325;&#35201;&#30340;&#26159;&#35813;&#39046;&#22495;&#24320;&#21457;&#20986;&#33021;&#22815;&#25490;&#38500;&#25968;&#25454;&#35760;&#24518;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In their recent Nature Human Behaviour paper, "Emergent analogical reasoning in large language models," (Webb, Holyoak, and Lu, 2023) the authors argue that "large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems." In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.
&lt;/p&gt;</description></item><item><title>GRASP&#26159;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;&#65292;&#26681;&#25454;&#26679;&#26412;&#30340;&#20195;&#34920;&#24615;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.13646</link><description>&lt;p&gt;
GRASP: &#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#37325;&#28436;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
GRASP: A Rehearsal Policy for Efficient Online Continual Learning. (arXiv:2308.13646v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13646
&lt;/p&gt;
&lt;p&gt;
GRASP&#26159;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;&#65292;&#26681;&#25454;&#26679;&#26412;&#30340;&#20195;&#34920;&#24615;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22312;&#32447;&#28176;&#36827;&#24335;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28176;&#36827;&#23398;&#20064;&#28041;&#21450;&#20174;&#19981;&#26029;&#22686;&#38271;&#30340;&#25968;&#25454;&#27969;&#20013;&#36880;&#27493;&#32047;&#31215;&#30693;&#35782;&#12290;&#28176;&#36827;&#23398;&#20064;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#27969;&#20250;&#23548;&#33268;&#20043;&#21069;&#23398;&#21040;&#30340;&#33021;&#21147;&#36973;&#21463;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#37325;&#28436;&#26159;&#19968;&#31181;&#24120;&#29992;&#19988;&#26377;&#25928;&#30340;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21363;&#23558;&#36807;&#21435;&#30340;&#35266;&#27979;&#32467;&#26524;&#23384;&#20648;&#22312;&#32531;&#20914;&#21306;&#20013;&#65292;&#24182;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23558;&#23427;&#20204;&#19982;&#26032;&#30340;&#35266;&#27979;&#32467;&#26524;&#28151;&#21512;&#12290;&#36825;&#24102;&#26469;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#24212;&#35813;&#36873;&#25321;&#21738;&#20123;&#23384;&#20648;&#26679;&#26412;&#36827;&#34892;&#37325;&#28436;&#65311;&#36873;&#25321;&#26368;&#36866;&#21512;&#23398;&#20064;&#30340;&#26679;&#26412;&#32780;&#19981;&#26159;&#38543;&#26426;&#36873;&#25321;&#26679;&#26412;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#23398;&#20064;&#36895;&#24230;&#26174;&#33879;&#21152;&#24555;&#12290;&#23545;&#20110;&#31867;&#22686;&#37327;&#23398;&#20064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#31616;&#21333;&#30340;&#31867;&#22343;&#34913;&#38543;&#26426;&#36873;&#25321;&#31574;&#30053;&#20248;&#20110;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034;&#19968;&#31181;&#26032;&#30340;&#26679;&#26412;&#36873;&#25321;&#31574;&#30053;GRASP&#37325;&#26032;&#24605;&#32771;&#36825;&#20010;&#38382;&#39064;&#12290;GRASP&#39318;&#20808;&#36873;&#25321;&#26368;&#20855;&#20195;&#34920;&#24615;&#30340;&#26679;&#26412;&#65292;&#28982;&#21518;&#36880;&#28176;&#36873;&#25321;&#36739;&#19981;&#20855;&#20195;&#34920;&#24615;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continual learning (CL) in deep neural networks (DNNs) involves incrementally accumulating knowledge in a DNN from a growing data stream. A major challenge in CL is that non-stationary data streams cause catastrophic forgetting of previously learned abilities. Rehearsal is a popular and effective way to mitigate this problem, which is storing past observations in a buffer and mixing them with new observations during learning. This leads to a question: Which stored samples should be selected for rehearsal? Choosing samples that are best for learning, rather than simply selecting them at random, could lead to significantly faster learning. For class incremental learning, prior work has shown that a simple class balanced random selection policy outperforms more sophisticated methods. Here, we revisit this question by exploring a new sample selection policy called GRASP. GRASP selects the most prototypical (class representative) samples first and then gradually selects less prototypical (h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#20248;&#21270;&#30340;&#22238;&#39038;&#24615;&#22823;&#22411;&#35821;&#35328;&#20195;&#29702;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23398;&#20064;&#29615;&#22659;&#21453;&#39304;&#26469;&#35843;&#25972;&#35821;&#35328;&#20195;&#29702;&#30340;&#25552;&#31034;&#65292;&#20174;&#32780;&#20248;&#21270;&#20854;&#24615;&#33021;&#12290;&#36825;&#31181;&#20195;&#29702;&#33021;&#22815;&#20174;&#22810;&#20010;&#29615;&#22659;&#21644;&#20219;&#21153;&#20013;&#23398;&#20064;&#22870;&#21169;&#65292;&#24182;&#36890;&#36807;&#24635;&#32467;&#20197;&#21069;&#20219;&#21153;&#30340;&#26681;&#26412;&#21407;&#22240;&#26469;&#25913;&#36827;&#35821;&#35328;&#20195;&#29702;&#25552;&#31034;&#12290;</title><link>http://arxiv.org/abs/2308.02151</link><description>&lt;p&gt;
Retroformer&#65306;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#20248;&#21270;&#30340;&#22238;&#39038;&#24615;&#22823;&#22411;&#35821;&#35328;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#20248;&#21270;&#30340;&#22238;&#39038;&#24615;&#22823;&#22411;&#35821;&#35328;&#20195;&#29702;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#23398;&#20064;&#29615;&#22659;&#21453;&#39304;&#26469;&#35843;&#25972;&#35821;&#35328;&#20195;&#29702;&#30340;&#25552;&#31034;&#65292;&#20174;&#32780;&#20248;&#21270;&#20854;&#24615;&#33021;&#12290;&#36825;&#31181;&#20195;&#29702;&#33021;&#22815;&#20174;&#22810;&#20010;&#29615;&#22659;&#21644;&#20219;&#21153;&#20013;&#23398;&#20064;&#22870;&#21169;&#65292;&#24182;&#36890;&#36807;&#24635;&#32467;&#20197;&#21069;&#20219;&#21153;&#30340;&#26681;&#26412;&#21407;&#22240;&#26469;&#25913;&#36827;&#35821;&#35328;&#20195;&#29702;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#26376;&#65292;&#20986;&#29616;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#26032;&#36235;&#21183;&#65292;&#21363;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22686;&#24378;&#25104;&#33021;&#22815;&#33258;&#20027;&#23436;&#25104;&#30446;&#26631;&#23548;&#21521;&#22810;&#27493;&#39588;&#20219;&#21153;&#30340;&#35821;&#35328;&#20195;&#29702;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22238;&#31572;&#20154;&#31867;&#29992;&#25143;&#30340;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#35821;&#35328;&#20195;&#29702;&#27809;&#26377;&#20351;&#29992;&#29615;&#22659;&#29305;&#23450;&#30340;&#22870;&#21169;&#36827;&#34892;&#20248;&#21270;&#12290;&#23613;&#31649;&#19968;&#20123;&#20195;&#29702;&#36890;&#36807;&#21475;&#22836;&#21453;&#39304;&#23454;&#29616;&#20102;&#36845;&#20195;&#25913;&#36827;&#65292;&#20294;&#23427;&#20204;&#19981;&#33021;&#20197;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#22870;&#21169;&#23398;&#20064;&#30456;&#20860;&#23481;&#30340;&#26041;&#24335;&#36827;&#34892;&#25512;&#29702;&#21644;&#35268;&#21010;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21407;&#21017;&#24615;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#22238;&#39038;&#27169;&#22411;&#65292;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#33258;&#21160;&#35843;&#25972;&#35821;&#35328;&#20195;&#29702;&#30340;&#25552;&#31034;&#65292;&#20174;&#29615;&#22659;&#21453;&#39304;&#20013;&#20248;&#21270;&#20195;&#29702;&#30340;&#24037;&#20316;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#20195;&#29702;&#26550;&#26500;&#36890;&#36807;&#23398;&#20064;&#22810;&#20010;&#29615;&#22659;&#21644;&#20219;&#21153;&#30340;&#22870;&#21169;&#26469;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#20174;&#32780;&#36890;&#36807;&#24635;&#32467;&#20197;&#21069;&#20219;&#21153;&#30340;&#26681;&#26412;&#21407;&#22240;&#26469;&#25913;&#36827;&#35821;&#35328;&#20195;&#29702;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent months have seen the emergence of a powerful new trend in which large language models (LLMs) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior
&lt;/p&gt;</description></item></channel></rss>