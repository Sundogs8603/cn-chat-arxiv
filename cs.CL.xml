<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#19987;&#38376;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;</title><link>https://arxiv.org/abs/2404.01461</link><description>&lt;p&gt;
&#35831;&#30495;&#27491;&#30340;&#29747;&#36798;&#31449;&#20986;&#26469;...&#38754;&#23545;&#22823;&#35821;&#35328;&#27169;&#22411;&#65311;&#22312;LLMs&#20013;&#23457;&#35270;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;
&lt;/p&gt;
&lt;p&gt;
Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01461
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#29702;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#19987;&#38376;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29702;&#35299;&#25991;&#26412;&#21644;&#29983;&#25104;&#31867;&#20284;&#20154;&#31867;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#20250;&#23637;&#29616;&#20986;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#33719;&#24471;&#30340;&#20559;&#35265;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;LLMs&#21487;&#33021;&#20250;&#23481;&#26131;&#21463;&#21040;&#20154;&#31867;&#20915;&#31574;&#20013;&#30340;&#19968;&#31181;&#24120;&#35265;&#35748;&#30693;&#38519;&#38449;&#24433;&#21709;&#65292;&#21363;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#12290;&#36825;&#26159;&#24515;&#29702;&#23398;&#20013;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#25351;&#30340;&#26159;&#26681;&#25454;&#20107;&#20214;&#19982;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#21407;&#22411;&#25110;&#20856;&#22411;&#20363;&#23376;&#30340;&#30456;&#20284;&#31243;&#24230;&#26469;&#21028;&#26029;&#20107;&#20214;&#21457;&#29983;&#30340;&#21487;&#33021;&#24615;&#65292;&#32780;&#19981;&#32771;&#34385;&#26356;&#24191;&#27867;&#30340;&#20107;&#23454;&#25110;&#32479;&#35745;&#35777;&#25454;&#12290;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#23545;LLM&#25512;&#29702;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;REHEAT&#65288;Representativeness Heuristic AI Testing&#65289;&#65292;&#19968;&#20010;&#21253;&#21547;&#28085;&#30422;&#20845;&#31181;&#24120;&#35265;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#31867;&#22411;&#38382;&#39064;&#30340;&#25968;&#25454;&#38598;&#12290;&#23454;&#39564;&#26174;&#31034;&#65292;&#24212;&#29992;&#20110;REHEAT&#30340;&#22235;&#20010;LLMs&#37117;&#34920;&#29616;&#20986;&#20195;&#34920;&#24615;&#21551;&#21457;&#24335;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;&#27169;&#22411;&#30340;&#25512;&#29702;&#27493;&#39588;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01461v1 Announce Type: new  Abstract: Although large language models (LLMs) have demonstrated remarkable proficiency in understanding text and generating human-like text, they may exhibit biases acquired from training data in doing so. Specifically, LLMs may be susceptible to a common cognitive trap in human decision-making called the representativeness heuristic. This is a concept in psychology that refers to judging the likelihood of an event based on how closely it resembles a well-known prototype or typical example versus considering broader facts or statistical evidence. This work investigates the impact of the representativeness heuristic on LLM reasoning. We created REHEAT (Representativeness Heuristic AI Testing), a dataset containing a series of problems spanning six common types of representativeness heuristics. Experiments reveal that four LLMs applied to REHEAT all exhibited representativeness heuristic biases. We further identify that the model's reasoning steps
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;PSPEM&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#21069;&#32512;&#25552;&#31034;&#26469;&#32534;&#36753;&#35821;&#35328;Lodel&#30340;&#30693;&#35782;&#34920;&#31034;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20013;&#30340;&#20302;&#25928;&#24615;&#12289;&#36890;&#29992;&#24615;&#38382;&#39064;&#65292;&#20197;&#21450;&#25552;&#31034;&#24037;&#31243;&#30340;&#19981;&#36879;&#26126;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.14381</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#21069;&#32512;&#25552;&#31034;&#26469;&#32534;&#36753;&#35821;&#35328;Lodel&#30340;&#30693;&#35782;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14381
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;PSPEM&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#21069;&#32512;&#25552;&#31034;&#26469;&#32534;&#36753;&#35821;&#35328;Lodel&#30340;&#30693;&#35782;&#34920;&#31034;&#65292;&#35299;&#20915;&#20102;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20013;&#30340;&#20302;&#25928;&#24615;&#12289;&#36890;&#29992;&#24615;&#38382;&#39064;&#65292;&#20197;&#21450;&#25552;&#31034;&#24037;&#31243;&#30340;&#19981;&#36879;&#26126;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#24050;&#22312;&#24191;&#27867;&#30340;&#35821;&#26009;&#24211;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#22521;&#35757;&#65292;&#20197;&#23384;&#20648;&#20851;&#20110;&#25991;&#26412;&#25551;&#36848;&#30340;&#19990;&#30028;&#21508;&#20010;&#26041;&#38754;&#30340;&#20107;&#23454;&#30693;&#35782;&#12290;&#24403;&#21069;&#25216;&#26415;&#36890;&#24120;&#37319;&#29992;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#25110;&#29305;&#23450;&#25552;&#31034;&#26469;&#20462;&#25913;LM&#36755;&#20986;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#25104;&#26412;&#39640;&#26114;&#19988;&#20302;&#25928;&#65292;&#38590;&#20197;&#20135;&#29983;&#36866;&#24403;&#30340;&#25991;&#26412;&#12290;&#27492;&#22806;&#65292;&#25552;&#31034;&#24037;&#31243;&#26159;&#19981;&#36879;&#26126;&#30340;&#65292;&#38656;&#35201;&#22823;&#37327;&#21162;&#21147;&#25214;&#21040;&#21512;&#36866;&#30340;&#25552;&#31034;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;PSPEM&#65288;&#21069;&#32512;&#36719;&#25552;&#31034;&#32534;&#36753;&#26041;&#27861;&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#20165;&#36890;&#36807;&#19968;&#27425;&#35757;&#32451;&#32780;&#32456;&#36523;&#20351;&#29992;&#12290;&#23427;&#35299;&#20915;&#20102;&#30693;&#35782;&#32534;&#36753;&#26041;&#27861;&#20013;&#30340;&#20302;&#25928;&#24615;&#21644;&#36890;&#29992;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#33258;&#21160;&#23547;&#25214;&#26368;&#20339;&#36719;&#25552;&#31034;&#26469;&#20811;&#26381;&#25552;&#31034;&#24037;&#31243;&#30340;&#19981;&#36879;&#26126;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;PSPEM&#21033;&#29992;&#25552;&#31034;&#32534;&#30721;&#22120;&#21644;&#32534;&#30721;&#36716;&#25442;&#22120;&#26469;&#31934;&#28860;&#25552;&#31034;&#20013;&#30340;&#20851;&#38190;&#20449;&#24687;&#65292;&#24182;&#20351;&#29992;&#25552;&#31034;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14381v1 Announce Type: cross  Abstract: Neural language models (LMs) have been extensively trained on vast corpora to store factual knowledge about various aspects of the world described in texts. Current technologies typically employ knowledge editing methods or specific prompts to modify LM outputs. However, existing knowledge editing methods are costly and inefficient, struggling to produce appropriate text. Additionally, prompt engineering is opaque and requires significant effort to find suitable prompts. To address these issues, we introduce a new method called PSPEM (Prefix Soft Prompt Editing Method), that can be used for a lifetime with just one training. It resolves the inefficiencies and generalizability issues in knowledge editing methods and overcomes the opacity of prompt engineering by automatically seeking optimal soft prompts. Specifically, PSPEM utilizes a prompt encoder and an encoding converter to refine key information in prompts and uses prompt alignmen
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#20154;&#31867;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;ARC&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#65292;&#20154;&#31867;&#21644;&#25104;&#24180;&#20154;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#22823;&#22810;&#25968;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#23545;LLMs&#21644;&#24180;&#24188;&#20799;&#31461;&#38169;&#35823;&#20998;&#26512;&#25581;&#31034;&#20102;&#31867;&#20284;&#30340;&#35299;&#20915;&#31574;&#30053;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#20026;&#25105;&#20204;&#29702;&#35299;LLMs&#22914;&#20309;&#35299;&#20915;&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#21551;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.09734</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#20687;&#20154;&#19968;&#26679;&#35299;&#20915;ARC&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Large Language Models Solve ARC Visual Analogies Like People Do?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#27604;&#36739;&#20102;&#20154;&#31867;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;ARC&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#19978;&#30340;&#34920;&#29616;&#65292;&#21457;&#29616;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#65292;&#20154;&#31867;&#21644;&#25104;&#24180;&#20154;&#30340;&#34920;&#29616;&#22343;&#20248;&#20110;&#22823;&#22810;&#25968;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#23545;LLMs&#21644;&#24180;&#24188;&#20799;&#31461;&#38169;&#35823;&#20998;&#26512;&#25581;&#31034;&#20102;&#31867;&#20284;&#30340;&#35299;&#20915;&#31574;&#30053;&#65292;&#21516;&#26102;&#25351;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#38169;&#35823;&#31867;&#22411;&#65292;&#20026;&#25105;&#20204;&#29702;&#35299;LLMs&#22914;&#20309;&#35299;&#20915;&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25233;&#21046;&#35770;&#25991;&#65288;Chollet, 2019&#65289;&#24418;&#24335;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#20799;&#31461;&#21451;&#22909;&#30340;ARC&#39033;&#30446;&#19978;&#20154;&#31867;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#20799;&#31461;&#36824;&#26159;&#25104;&#24180;&#20154;&#65292;&#22312;&#36825;&#20123;&#20219;&#21153;&#19978;&#37117;&#32988;&#36807;&#22823;&#22810;&#25968;LLMs&#12290;&#38169;&#35823;&#20998;&#26512;&#25581;&#31034;&#20102;LLMs&#21644;&#24180;&#24188;&#20799;&#31461;&#20043;&#38388;&#31867;&#20284;&#30340;&#8220;&#20498;&#36864;&#8221;&#35299;&#20915;&#31574;&#30053;&#65292;&#20854;&#20013;&#31867;&#27604;&#30340;&#19968;&#37096;&#20998;&#34987;&#31616;&#21333;&#22797;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20854;&#20182;&#20004;&#31181;&#38169;&#35823;&#31867;&#22411;&#65292;&#19968;&#31181;&#22522;&#20110;&#34920;&#38754;&#25484;&#25569;&#20851;&#38190;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#20869;&#22806;&#20851;&#31995;&#65289;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#31867;&#27604;&#36755;&#20837;&#30697;&#38453;&#30340;&#31616;&#21333;&#32452;&#21512;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#8220;&#27010;&#24565;&#8221;&#38169;&#35823;&#22312;&#20154;&#31867;&#20013;&#26356;&#24120;&#35265;&#65292;&#8220;&#30697;&#38453;&#8221;&#38169;&#35823;&#22312;LLMs&#20013;&#26356;&#24120;&#35265;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;LLM&#30340;&#25512;&#29702;&#33021;&#21147;&#21644;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#38169;&#35823;&#20998;&#26512;&#20197;&#21450;&#19982;&#20154;&#31867;&#21457;&#23637;&#30340;&#27604;&#36739;&#26469;&#29702;&#35299;LLMs&#22914;&#20309;&#35299;&#20915;&#35270;&#35273;&#31867;&#27604;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09734v1 Announce Type: cross  Abstract: The Abstraction Reasoning Corpus (ARC) is a visual analogical reasoning test designed for humans and machines (Chollet, 2019). We compared human and large language model (LLM) performance on a new child-friendly set of ARC items. Results show that both children and adults outperform most LLMs on these tasks. Error analysis revealed a similar "fallback" solution strategy in LLMs and young children, where part of the analogy is simply copied. In addition, we found two other error types, one based on seemingly grasping key concepts (e.g., Inside-Outside) and the other based on simple combinations of analogy input matrices. On the whole, "concept" errors were more common in humans, and "matrix" errors were more common in LLMs. This study sheds new light on LLM reasoning ability and the extent to which we can use error analyses and comparisons with human development to understand how LLMs solve visual analogies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#21069;&#27839;&#27169;&#22411;&#23578;&#23384;&#22312;&#30340;&#22810;&#27169;&#24577;&#33021;&#21147;&#24046;&#36317;&#65292;&#25506;&#35752;&#20102;&#35757;&#32451;&#24320;&#28304;&#23567;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20197;&#24357;&#34917;&#20020;&#24202;&#38656;&#27714;&#30340;&#29983;&#29289;&#21307;&#23398;&#33021;&#21147;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2403.08002</link><description>&lt;p&gt;
&#35757;&#32451;&#23567;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20197;&#22635;&#34917;&#29983;&#29289;&#21307;&#23398;&#33021;&#21147;&#24046;&#36317;&#65306;&#20197;&#25918;&#23556;&#23398;&#25104;&#20687;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08002
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#21069;&#27839;&#27169;&#22411;&#23578;&#23384;&#22312;&#30340;&#22810;&#27169;&#24577;&#33021;&#21147;&#24046;&#36317;&#65292;&#25506;&#35752;&#20102;&#35757;&#32451;&#24320;&#28304;&#23567;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#20197;&#24357;&#34917;&#20020;&#24202;&#38656;&#27714;&#30340;&#29983;&#29289;&#21307;&#23398;&#33021;&#21147;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25918;&#22823;&#22522;&#30784;&#27169;&#22411;&#30340;&#23610;&#24230;&#35268;&#24459;&#21644;&#38750;&#20961;&#34920;&#29616;&#28608;&#21169;&#20102;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#24320;&#21457;&#21644;&#21033;&#29992;&#36825;&#20123;&#22823;&#22411;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#19968;&#20123;&#29983;&#29289;&#21307;&#23398;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26089;&#26399;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#22312;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#24212;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20043;&#21069;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#37325;&#22823;&#25361;&#25112;&#12290;&#20687;GPT-4V&#36825;&#26679;&#30340;&#21069;&#27839;&#27169;&#22411;&#22312;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#20173;&#23384;&#22312;&#37325;&#22823;&#30340;&#22810;&#27169;&#24577;&#33021;&#21147;&#24046;&#36317;&#12290;&#27492;&#22806;&#65292;&#35775;&#38382;&#12289;&#25104;&#26412;&#12289;&#24310;&#36831;&#21644;&#21512;&#35268;&#31561;&#23454;&#38469;&#38382;&#39064;&#20351;&#20020;&#24202;&#21307;&#29983;&#38590;&#20197;&#30452;&#25509;&#22312;&#31169;&#20154;&#24739;&#32773;&#25968;&#25454;&#19978;&#20351;&#29992;&#31169;&#20154;&#25176;&#31649;&#30340;&#26368;&#20808;&#36827;&#22823;&#22411;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#35757;&#32451;&#24320;&#28304;&#23567;&#22411;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;SMMs&#65289;&#26469;&#22635;&#34917;&#26410;&#28385;&#36275;&#30340;&#20020;&#24202;&#38656;&#27714;&#30340;&#29983;&#29289;&#21307;&#23398;&#33021;&#21147;&#24046;&#36317;&#12290;&#20026;&#20102;&#26368;&#22823;&#21270;&#25968;&#25454;&#25928;&#29575;&#65292;&#25105;&#20204;&#37319;&#29992;&#27169;&#22359;&#21270;&#26041;&#27861;&#65292;&#23558;&#29992;&#20110;&#22270;&#20687;&#21644;&#25991;&#26412;&#27169;&#24577;&#30340;&#26368;&#20808;&#36827;&#39044;&#35757;&#32451;&#27169;&#22411;&#32435;&#20837;&#65292;&#24182;&#20391;&#37325;&#20110;t
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08002v1 Announce Type: new  Abstract: The scaling laws and extraordinary performance of large foundation models motivate the development and utilization of such large models in biomedicine. However, despite early promising results on some biomedical benchmarks, there are still major challenges that need to be addressed before these models can be used in real-world applications. Frontier models such as GPT-4V still have major competency gaps in multimodal capabilities for biomedical applications. Moreover, pragmatic issues such as access, cost, latency, and compliance make it hard for clinicians to use privately-hosted state-of-the-art large models directly on private patient data. In this paper, we explore training open-source small multimodal models (SMMs) to bridge biomedical competency gaps for unmet clinical needs. To maximize data efficiency, we adopt a modular approach by incorporating state-of-the-art pre-trained models for image and text modalities, and focusing on t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#22312;&#33258;&#25105;&#26657;&#27491;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#22914;&#26524;-&#21542;&#21017;&#8221;&#65288;IoE&#65289;&#25552;&#31034;&#26694;&#26550;&#65292;&#24110;&#21161;&#27169;&#22411;&#35780;&#20272;&#33258;&#36523;&#8220;&#20449;&#24515;&#8221;&#24182;&#36827;&#34892;&#33258;&#25105;&#26657;&#27491;&#12290;</title><link>https://arxiv.org/abs/2402.12563</link><description>&lt;p&gt;
&#20449;&#24515;&#33267;&#20851;&#37325;&#35201;&#65306;&#37325;&#26032;&#23457;&#35270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#22312;&#33258;&#25105;&#26657;&#27491;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#22312;&#33258;&#25105;&#26657;&#27491;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#22914;&#26524;-&#21542;&#21017;&#8221;&#65288;IoE&#65289;&#25552;&#31034;&#26694;&#26550;&#65292;&#24110;&#21161;&#27169;&#22411;&#35780;&#20272;&#33258;&#36523;&#8220;&#20449;&#24515;&#8221;&#24182;&#36827;&#34892;&#33258;&#25105;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#26368;&#36817;&#25104;&#21151;&#28608;&#21457;&#20102;&#23545;&#23427;&#20204;&#33258;&#25105;&#26657;&#27491;&#33021;&#21147;&#30340;&#36234;&#26469;&#36234;&#22810;&#30340;&#20852;&#36259;&#12290;&#26412;&#25991;&#23545;LLMs&#30340;&#20869;&#22312;&#33258;&#25105;&#26657;&#27491;&#36827;&#34892;&#20102;&#20840;&#38754;&#35843;&#26597;&#65292;&#35797;&#22270;&#35299;&#20915;&#20851;&#20110;&#20854;&#21487;&#34892;&#24615;&#30340;&#25345;&#32493;&#20105;&#35770;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#30830;&#23450;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#28508;&#22312;&#22240;&#32032; - LLMs&#30340;&#8220;&#20449;&#24515;&#8221; - &#22312;&#33258;&#25105;&#26657;&#27491;&#36807;&#31243;&#20013;&#12290;&#24573;&#35270;&#36825;&#19968;&#22240;&#32032;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#36807;&#24230;&#25209;&#35780;&#33258;&#24049;&#65292;&#20174;&#32780;&#23548;&#33268;&#23545;&#33258;&#26657;&#27491;&#25928;&#26524;&#30340;&#21487;&#38752;&#32467;&#35770;&#19981;&#20934;&#30830;&#12290;&#25105;&#20204;&#23454;&#39564;&#35266;&#23519;&#21040;LLMs&#20855;&#26377;&#29702;&#35299;&#20854;&#33258;&#36523;&#22238;&#24212;&#8220;&#20449;&#24515;&#8221;&#30340;&#33021;&#21147;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#8220;&#22914;&#26524;-&#21542;&#21017;&#8221;&#65288;IoE&#65289;&#25552;&#31034;&#26694;&#26550;&#65292;&#26088;&#22312;&#24341;&#23548;LLMs&#35780;&#20272;&#20854;&#33258;&#36523;&#8220;&#20449;&#24515;&#8221;&#65292;&#20419;&#36827;&#20869;&#22312;&#33258;&#25105;&#26657;&#27491;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#22522;&#20110;IoE&#30340;&#25552;&#31034;&#21487;&#20197;&#23454;&#29616;&#19968;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12563v1 Announce Type: cross  Abstract: The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ``confidence'' of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ``confidence'' in their own responses. It motivates us to develop an ``If-or-Else'' (IoE) prompting framework, designed to guide LLMs in assessing their own ``confidence'', facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OneBit&#30340;1&#20301;&#37327;&#21270;&#24863;&#30693;&#35757;&#32451;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#30697;&#38453;&#37327;&#21270;&#20026;1&#20301;&#65292;&#20026;&#26497;&#20302;&#27604;&#29305;&#23485;&#24230;&#30340;LLMs&#37096;&#32626;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;</title><link>https://arxiv.org/abs/2402.11295</link><description>&lt;p&gt;
OneBit:&#26397;&#30528;&#26497;&#20302;&#27604;&#29305;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
OneBit: Towards Extremely Low-bit Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;OneBit&#30340;1&#20301;&#37327;&#21270;&#24863;&#30693;&#35757;&#32451;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#30697;&#38453;&#37327;&#21270;&#20026;1&#20301;&#65292;&#20026;&#26497;&#20302;&#27604;&#29305;&#23485;&#24230;&#30340;LLMs&#37096;&#32626;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#37327;&#21270;&#20351;&#29992;&#20302;&#27604;&#29305;&#23485;&#24230;&#20540;&#26469;&#34920;&#31034;&#27169;&#22411;&#30340;&#26435;&#37325;&#30697;&#38453;&#65292;&#36825;&#26159;&#20943;&#23569;&#37096;&#32626;&#39640;&#24230;&#26399;&#24453;&#30340;LLMs&#30340;&#23384;&#20648;&#21644;&#35745;&#31639;&#24320;&#38144;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#37327;&#21270;&#26041;&#27861;&#22312;&#27604;&#29305;&#23485;&#24230;&#26497;&#23567;&#26102;&#24615;&#33021;&#20005;&#37325;&#19979;&#38477;&#65292;&#22240;&#27492;&#19987;&#27880;&#20110;&#21033;&#29992;4&#20301;&#25110;8&#20301;&#20540;&#26469;&#37327;&#21270;&#27169;&#22411;&#12290;&#26412;&#25991;&#22823;&#32966;&#22320;&#23558;LLMs&#30340;&#26435;&#37325;&#30697;&#38453;&#37327;&#21270;&#20026;1&#20301;&#65292;&#20026;LLMs&#30340;&#26497;&#20302;&#27604;&#29305;&#23485;&#24230;&#37096;&#32626;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;OneBit&#30340;1&#20301;&#37327;&#21270;&#24863;&#30693;&#35757;&#32451;&#65288;QAT&#65289;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31181;&#26356;&#22909;&#22320;&#37327;&#21270;LLMs&#30340;&#26032;&#39062;&#30340;1&#20301;&#21442;&#25968;&#34920;&#31034;&#26041;&#27861;&#65292;&#20197;&#21450;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#26377;&#25928;&#21442;&#25968;&#21021;&#22987;&#21270;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;QAT&#26694;&#26550;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#20805;&#20998;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;OneBit&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#65288;&#33267;&#23569;&#26159;&#38750;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11295v1 Announce Type: new  Abstract: Model quantification uses low bit-width values to represent the weight matrices of models, which is a promising approach to reduce both storage and computational overheads of deploying highly anticipated LLMs. However, existing quantization methods suffer severe performance degradation when the bit-width is extremely reduced, and thus focus on utilizing 4-bit or 8-bit values to quantize models. This paper boldly quantizes the weight matrices of LLMs to 1-bit, paving the way for the extremely low bit-width deployment of LLMs. For this target, we introduce a 1-bit quantization-aware training (QAT) framework named OneBit, including a novel 1-bit parameter representation method to better quantize LLMs as well as an effective parameter initialization method based on matrix decomposition to improve the convergence speed of the QAT framework. Sufficient experimental results indicate that OneBit achieves good performance (at least 83% of the non
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#29992;&#21333;&#20010;&#20799;&#31461;&#30340;&#35821;&#35328;&#36755;&#20837;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#35774;&#32622;&#19979;&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#24418;&#25104;&#21477;&#27861;&#21644;&#35821;&#20041;&#35789;&#32676;&#65292;&#24182;&#23545;&#26576;&#20123;&#35821;&#35328;&#29616;&#35937;&#20855;&#26377;&#25935;&#24863;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07899</link><description>&lt;p&gt;
&#20174;&#21333;&#19968;&#20799;&#31461;&#35821;&#35328;&#36755;&#20837;&#30340;&#21487;&#23398;&#20064;&#24615;&#30340;&#31995;&#32479;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A systematic investigation of learnability from single child linguistic input
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07899
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#29992;&#21333;&#20010;&#20799;&#31461;&#30340;&#35821;&#35328;&#36755;&#20837;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#35774;&#32622;&#19979;&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#24418;&#25104;&#21477;&#27861;&#21644;&#35821;&#20041;&#35789;&#32676;&#65292;&#24182;&#23545;&#26576;&#20123;&#35821;&#35328;&#29616;&#35937;&#20855;&#26377;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#22312;&#29983;&#25104;&#35821;&#35328;&#36830;&#36143;&#25991;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102; remarkable proficiency&#65292;&#24341;&#21457;&#20102;&#20851;&#20110;&#23427;&#20204;&#19982;&#20154;&#31867;&#35821;&#35328;&#21487;&#23398;&#20064;&#24615;&#30340;&#30456;&#20851;&#35752;&#35770;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#19982;&#20799;&#31461;&#25509;&#25910;&#21040;&#30340;&#35821;&#35328;&#36755;&#20837;&#20043;&#38388;&#23384;&#22312;&#30528;&#26174;&#33879;&#24046;&#36317;&#12290;LMs&#36890;&#24120;&#22312;&#25968;&#37327;&#32423;&#19978;&#26356;&#22823;&#19988;&#26412;&#36136;&#19982;&#20799;&#31461;&#35821;&#35328;&#36755;&#20837;&#19981;&#21516;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#38024;&#23545;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20391;&#37325;&#20110;&#22312;&#21333;&#20010;&#20799;&#31461;&#35821;&#35328;&#36755;&#20837;&#30340;&#23376;&#38598;&#19978;&#35757;&#32451;LMs&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#35757;&#32451;&#30340;LMs&#21487;&#20197;&#24418;&#25104;&#21477;&#27861;&#21644;&#35821;&#20041;&#35789;&#32676;&#65292;&#24182;&#23545;&#26576;&#20123;&#35821;&#35328;&#29616;&#35937;&#20855;&#26377;&#25935;&#24863;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#20165;&#32771;&#34385;&#20102;&#20165;&#20351;&#29992;&#19968;&#20010;&#21333;&#19968;&#20799;&#31461;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;LSTMs&#21644;&#26356;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#20026;&#20102;&#26816;&#39564;&#20174;&#21333;&#19968;&#20799;&#31461;&#36755;&#20837;&#21487;&#23398;&#20064;&#24615;&#30340;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#8230;
&lt;/p&gt;
&lt;p&gt;
Language models (LMs) have demonstrated remarkable proficiency in generating linguistically coherent text, sparking discussions about their relevance to understanding human language learnability. However, a significant gap exists between the training data for these models and the linguistic input a child receives. LMs are typically trained on data that is orders of magnitude larger and fundamentally different from child-directed speech (Warstadt and Bowman, 2022; Warstadt et al., 2023; Frank, 2023a). Addressing this discrepancy, our research focuses on training LMs on subsets of a single child's linguistic input. Previously, Wang, Vong, Kim, and Lake (2023) found that LMs trained in this setting can form syntactic and semantic word clusters and develop sensitivity to certain linguistic phenomena, but they only considered LSTMs and simpler neural networks trained from just one single-child dataset. Here, to examine the robustness of learnability from single-child input, we systematicall
&lt;/p&gt;</description></item><item><title>Mercury&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;LLM&#20195;&#30721;&#32508;&#21512;&#20219;&#21153;&#30340;&#25928;&#29575;&#35780;&#20272;&#22522;&#20934;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;Beyond@K&#26469;&#34913;&#37327;&#24402;&#19968;&#21270;&#30340;&#20195;&#30721;&#25928;&#29575;&#65292;&#20174;&#32780;&#40723;&#21169;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20195;&#30721;&#12290;</title><link>https://arxiv.org/abs/2402.07844</link><description>&lt;p&gt;
Mercury: &#19968;&#31181;&#29992;&#20110;LLM&#20195;&#30721;&#32508;&#21512;&#25928;&#29575;&#35780;&#20272;&#30340;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Mercury: An Efficiency Benchmark for LLM Code Synthesis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07844
&lt;/p&gt;
&lt;p&gt;
Mercury&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;LLM&#20195;&#30721;&#32508;&#21512;&#20219;&#21153;&#30340;&#25928;&#29575;&#35780;&#20272;&#22522;&#20934;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;Beyond@K&#26469;&#34913;&#37327;&#24402;&#19968;&#21270;&#30340;&#20195;&#30721;&#25928;&#29575;&#65292;&#20174;&#32780;&#40723;&#21169;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#20195;&#30721;&#32508;&#21512;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#65292;&#20294;&#22522;&#20934;&#20027;&#35201;&#38598;&#20013;&#22312;&#21151;&#33021;&#27491;&#30830;&#24615;&#19978;&#65292;&#24573;&#35270;&#20102;&#20195;&#30721;&#25928;&#29575;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Mercury&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#19987;&#29992;&#20110;&#35780;&#20272;LLM&#20195;&#30721;&#32508;&#21512;&#20219;&#21153;&#30340;&#20195;&#30721;&#25928;&#29575;&#30340;&#22522;&#20934;&#12290;Mercury&#30001;1,889&#20010;&#28085;&#30422;&#19981;&#21516;&#38590;&#24230;&#32423;&#21035;&#30340;&#32534;&#31243;&#20219;&#21153;&#32452;&#25104;&#65292;&#36824;&#21253;&#25324;&#29983;&#25104;&#26080;&#38480;&#26696;&#20363;&#30340;&#27979;&#35797;&#29992;&#20363;&#29983;&#25104;&#22120;&#65292;&#20197;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#19981;&#21516;&#65292;Mercury&#38598;&#25104;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;Beyond@K&#65292;&#20197;&#22522;&#20110;&#21382;&#21490;&#25552;&#20132;&#26469;&#34913;&#37327;&#24402;&#19968;&#21270;&#30340;&#20195;&#30721;&#25928;&#29575;&#65292;&#20174;&#32780;&#20026;&#20195;&#30721;&#32508;&#21512;&#25552;&#20379;&#20102;&#26032;&#30340;&#35780;&#20272;&#25351;&#26631;&#65292;&#40723;&#21169;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#20195;&#30721;&#65292;&#20307;&#29616;&#20102;&#29616;&#23454;&#19990;&#30028;&#36719;&#20214;&#24320;&#21457;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;LLM&#34920;&#29616;&#20986;&#29983;&#25104;&#21151;&#33021;&#27491;&#30830;&#20195;&#30721;&#30340;&#26174;&#33879;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#22312;&#25928;&#29575;&#36755;&#20986;&#26041;&#38754;&#20173;&#23384;&#22312;&#24456;&#22823;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite advancements in evaluating Large Language Models (LLMs) for code synthesis, benchmarks have predominantly focused on functional correctness, overlooking the importance of code efficiency. We present Mercury, the first benchmark designated for assessing the code efficiency of LLM code synthesis tasks. Mercury consists of 1,889 programming tasks covering diverse difficulty levels alongside test case generators generating unlimited cases for comprehensive evaluation. Unlike existing benchmarks, Mercury integrates a novel metric Beyond@K to measure normalized code efficiency based on historical submissions, leading to a new evaluation indicator for code synthesis, which encourages generating functionally correct and computationally efficient code, mirroring the real-world software development standard. Our findings reveal that while LLMs demonstrate the remarkable capability to generate functionally correct code, there still exists a substantial gap in their efficiency output, unde
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TexShape&#30340;&#20449;&#24687;&#35770;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#20114;&#20449;&#24687;&#30340;&#32463;&#39564;&#20272;&#35745;&#26469;&#20248;&#21270;&#25991;&#26412;&#34920;&#31034;&#65292;&#21487;&#29992;&#20110;&#25968;&#25454;&#21387;&#32553;&#21644;&#25935;&#24863;&#20449;&#24687;&#36807;&#28388;&#65292;&#25552;&#21319;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05132</link><description>&lt;p&gt;
TexShape:&#20449;&#24687;&#35770;&#21477;&#23376;&#23884;&#20837;&#29992;&#20110;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
TexShape: Information Theoretic Sentence Embedding for Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05132
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TexShape&#30340;&#20449;&#24687;&#35770;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#20114;&#20449;&#24687;&#30340;&#32463;&#39564;&#20272;&#35745;&#26469;&#20248;&#21270;&#25991;&#26412;&#34920;&#31034;&#65292;&#21487;&#29992;&#20110;&#25968;&#25454;&#21387;&#32553;&#21644;&#25935;&#24863;&#20449;&#24687;&#36807;&#28388;&#65292;&#25552;&#21319;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#37327;&#30340;&#25351;&#25968;&#22686;&#38271;&#21644;&#25968;&#25454;&#23494;&#38598;&#24212;&#29992;&#30340;&#20986;&#29616;&#65292;&#23588;&#20854;&#26159;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#19982;&#36164;&#28304;&#21033;&#29992;&#12289;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#30456;&#20851;&#30340;&#38382;&#39064;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#26412;&#25991;&#20851;&#27880;&#25968;&#25454;&#30340;&#25991;&#26412;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20449;&#24687;&#35770;&#30340;&#35270;&#35282;&#35299;&#20915;&#20102;&#23558;&#21477;&#23376;&#32534;&#30721;&#20026;&#20854;&#20248;&#21270;&#34920;&#31034;&#30340;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;Donsker-Varadhan&#23450;&#20041;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#32463;&#39564;&#20272;&#35745;&#20540;&#26469;&#35745;&#31639;&#20114;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#36825;&#31181;&#20272;&#35745;&#26469;&#35757;&#32451;&#19968;&#31181;&#20449;&#24687;&#35770;&#21477;&#23376;&#23884;&#20837;&#27169;&#22411;&#65292;&#31216;&#20026;TexShape&#65292;&#29992;&#20110;&#65288;&#22522;&#20110;&#20219;&#21153;&#30340;&#65289;&#25968;&#25454;&#21387;&#32553;&#25110;&#36807;&#28388;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#22686;&#24378;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20934;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21021;&#27493;&#25991;&#26412;&#34920;&#31034;&#65292;&#24182;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20449;&#24687;&#29702;&#35770;&#21387;&#32553;&#21644;&#20114;&#20449;&#24687;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the exponential growth in data volume and the emergence of data-intensive applications, particularly in the field of machine learning, concerns related to resource utilization, privacy, and fairness have become paramount. This paper focuses on the textual domain of data and addresses challenges regarding encoding sentences to their optimized representations through the lens of information-theory. In particular, we use empirical estimates of mutual information, using the Donsker-Varadhan definition of Kullback-Leibler divergence. Our approach leverages this estimation to train an information-theoretic sentence embedding, called TexShape, for (task-based) data compression or for filtering out sensitive information, enhancing privacy and fairness. In this study, we employ a benchmark language model for initial text representation, complemented by neural networks for information-theoretic compression and mutual information estimations. Our experiments demonstrate significant advanceme
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#21313;&#20010;&#19981;&#21516;&#35821;&#35328;&#23478;&#26063;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#36827;&#34892;&#30740;&#31350;&#65292;&#39318;&#27425;&#22312;&#31995;&#32479;&#21457;&#32946;&#37325;&#24314;&#20013;&#27604;&#36739;&#20102;&#22522;&#20110;&#22768;&#38899;&#21644;&#22522;&#20110;&#21516;&#28304;&#30340;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;&#35789;&#27719;&#21516;&#28304;&#30340;&#37325;&#24314;&#35889;&#31995;&#19982;&#30495;&#23454;&#35889;&#31995;&#24179;&#22343;&#26356;&#25509;&#36817;&#65292;&#25552;&#39640;&#20102;&#32422;&#19977;&#20998;&#20043;&#19968;&#12290;</title><link>https://arxiv.org/abs/2402.02807</link><description>&lt;p&gt;
&#22768;&#38899;&#23545;&#20110;&#31995;&#32479;&#21457;&#32946;&#37325;&#24314;&#21487;&#38752;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Are Sounds Sound for Phylogenetic Reconstruction?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#21313;&#20010;&#19981;&#21516;&#35821;&#35328;&#23478;&#26063;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#36827;&#34892;&#30740;&#31350;&#65292;&#39318;&#27425;&#22312;&#31995;&#32479;&#21457;&#32946;&#37325;&#24314;&#20013;&#27604;&#36739;&#20102;&#22522;&#20110;&#22768;&#38899;&#21644;&#22522;&#20110;&#21516;&#28304;&#30340;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;&#35789;&#27719;&#21516;&#28304;&#30340;&#37325;&#24314;&#35889;&#31995;&#19982;&#30495;&#23454;&#35889;&#31995;&#24179;&#22343;&#26356;&#25509;&#36817;&#65292;&#25552;&#39640;&#20102;&#32422;&#19977;&#20998;&#20043;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#30340;&#35821;&#35328;&#36827;&#21270;&#30740;&#31350;&#20013;&#65292;&#23398;&#32773;&#20204;&#36890;&#24120;&#24378;&#35843;&#22768;&#38899;&#35268;&#24459;&#21644;&#23545;&#24212;&#20851;&#31995;&#23545;&#20110;&#35821;&#35328;&#23478;&#26063;&#35889;&#31995;&#25512;&#26029;&#30340;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#35745;&#31639;&#26041;&#27861;&#24448;&#24448;&#27809;&#26377;&#20805;&#20998;&#32771;&#34385;&#21040;&#36825;&#19968;&#28508;&#21147;&#12290;&#22823;&#22810;&#25968;&#35745;&#31639;&#26041;&#27861;&#20173;&#28982;&#20381;&#36182;&#20110;&#35789;&#27719;&#21516;&#28304;&#20316;&#20026;&#35821;&#35328;&#23398;&#31995;&#32479;&#21457;&#32946;&#37325;&#24314;&#30340;&#20027;&#35201;&#25968;&#25454;&#26469;&#28304;&#65292;&#23613;&#31649;&#20063;&#26377;&#19968;&#20123;&#30740;&#31350;&#20013;&#30340;&#20316;&#32773;&#36190;&#36175;&#27604;&#36739;&#22768;&#38899;&#24207;&#21015;&#30340;&#22909;&#22788;&#12290;&#22522;&#20110;&#21313;&#20010;&#26469;&#33258;&#19981;&#21516;&#35821;&#35328;&#23478;&#26063;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#21644;&#29616;&#20195;&#33258;&#21160;&#21516;&#28304;&#21644;&#22768;&#38899;&#23545;&#24212;&#26816;&#27979;&#26041;&#27861;&#65292;&#25105;&#20204;&#39318;&#27425;&#27979;&#35797;&#20102;&#22522;&#20110;&#22768;&#38899;&#21644;&#22522;&#20110;&#21516;&#28304;&#30340;&#26041;&#27861;&#22312;&#31995;&#32479;&#21457;&#32946;&#37325;&#24314;&#20013;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#35789;&#27719;&#21516;&#28304;&#37325;&#24314;&#30340;&#35889;&#31995;&#22312;&#24191;&#20041;&#22235;&#20803;&#32452;&#36317;&#31163;&#19978;&#19982;&#30495;&#23454;&#35889;&#31995;&#24179;&#22343;&#26356;&#25509;&#36817;&#65292;&#25552;&#21319;&#20102;&#32422;&#19977;&#20998;&#20043;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In traditional studies on language evolution, scholars often emphasize the importance of sound laws and sound correspondences for phylogenetic inference of language family trees. However, to date, computational approaches have typically not taken this potential into account. Most computational studies still rely on lexical cognates as major data source for phylogenetic reconstruction in linguistics, although there do exist a few studies in which authors praise the benefits of comparing words at the level of sound sequences. Building on (a) ten diverse datasets from different language families, and (b) state-of-the-art methods for automated cognate and sound correspondence detection, we test, for the first time, the performance of sound-based versus cognate-based approaches to phylogenetic reconstruction. Our results show that phylogenies reconstructed from lexical cognates are topologically closer, by approximately one third with respect to the generalized quartet distance on average, 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#32534;&#36753;&#30340;&#28508;&#22312;&#38519;&#38449;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#21457;&#29616;&#30693;&#35782;&#20914;&#31361;&#21644;&#30693;&#35782;&#25197;&#26354;&#26159;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2310.02129</link><description>&lt;p&gt;
&#25581;&#31034;&#22823;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#32534;&#36753;&#30340;&#38519;&#38449;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Pitfalls of Knowledge Editing for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.02129
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#32534;&#36753;&#30340;&#28508;&#22312;&#38519;&#38449;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#21457;&#29616;&#30693;&#35782;&#20914;&#31361;&#21644;&#30693;&#35782;&#25197;&#26354;&#26159;&#20004;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#25104;&#26412;&#19981;&#26029;&#19978;&#21319;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24037;&#20316;&#24050;&#32463;&#36716;&#21521;&#24320;&#21457;&#32534;&#36753;LLMs&#20869;&#22312;&#30693;&#35782;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20173;&#26377;&#19968;&#20010;&#38452;&#20113;&#24748;&#22312;&#22836;&#39030;&#19978; - &#30693;&#35782;&#32534;&#36753;&#26159;&#21542;&#20250;&#35302;&#21457;&#34676;&#34678;&#25928;&#24212;&#65311;&#22240;&#20026;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#30693;&#35782;&#32534;&#36753;&#26159;&#21542;&#20250;&#24341;&#20837;&#21487;&#33021;&#24102;&#26469;&#28508;&#22312;&#39118;&#38505;&#30340;&#21103;&#20316;&#29992;&#12290;&#26412;&#25991;&#39318;&#27425;&#25506;&#35752;&#20102;&#19982;LLMs&#30693;&#35782;&#32534;&#36753;&#30456;&#20851;&#30340;&#28508;&#22312;&#38519;&#38449;&#12290;&#20026;&#23454;&#29616;&#27492;&#30446;&#30340;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#24182;&#25552;&#20986;&#20102;&#21019;&#26032;&#24615;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;&#65306;&#65288;1&#65289;&#30693;&#35782;&#20914;&#31361;&#65306;&#32534;&#36753;&#36923;&#36753;&#20914;&#31361;&#30340;&#20107;&#23454;&#32452;&#21487;&#33021;&#20250;&#25918;&#22823;LLMs&#22266;&#26377;&#30340;&#19981;&#19968;&#33268;&#24615; - &#36825;&#26159;&#20197;&#21069;&#26041;&#27861;&#24573;&#30053;&#30340;&#19968;&#20010;&#26041;&#38754;&#12290;&#65288;2&#65289;&#30693;&#35782;&#25197;&#26354;&#65306;&#20026;&#20102;&#32534;&#36753;&#20107;&#23454;&#30693;&#35782;&#32780;&#26356;&#25913;&#21442;&#25968;&#21487;&#33021;&#20250;&#19981;&#21487;&#36870;&#22320;&#25197;&#26354;
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.02129v3 Announce Type: replace-cross  Abstract: As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs. Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect? since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not. This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs. To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics. Our results underline two pivotal concerns: (1) Knowledge Conflict: Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#30340;&#26041;&#24335;&#26469;&#20943;&#36731;&#20020;&#24202;&#20915;&#31574;&#20013;&#30340;&#35748;&#30693;&#20559;&#24046;&#65292;&#24182;&#35780;&#20272;&#20854;&#23545;&#25552;&#39640;&#35786;&#26029;&#20934;&#30830;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14589</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#25552;&#39640;&#35786;&#26029;&#20934;&#30830;&#24230;&#65306;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20943;&#23569;&#35748;&#30693;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias. (arXiv:2401.14589v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#30340;&#26041;&#24335;&#26469;&#20943;&#36731;&#20020;&#24202;&#20915;&#31574;&#20013;&#30340;&#35748;&#30693;&#20559;&#24046;&#65292;&#24182;&#35780;&#20272;&#20854;&#23545;&#25552;&#39640;&#35786;&#26029;&#20934;&#30830;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#20020;&#24202;&#20915;&#31574;&#20013;&#30340;&#35748;&#30693;&#20559;&#24046;&#26174;&#33879;&#23548;&#33268;&#35786;&#26029;&#38169;&#35823;&#21644;&#27425;&#20248;&#24739;&#32773;&#32467;&#26524;&#12290;&#35299;&#20915;&#36825;&#20123;&#20559;&#24046;&#38382;&#39064;&#22312;&#21307;&#30103;&#39046;&#22495;&#38754;&#20020;&#24040;&#22823;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#22810;&#26234;&#33021;&#20307;&#26694;&#26550;&#20013;&#20943;&#36731;&#36825;&#20123;&#20559;&#24046;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#26234;&#33021;&#20307;&#23545;&#35805;&#27169;&#25311;&#20020;&#24202;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#35780;&#20272;&#20854;&#23545;&#25913;&#21892;&#35786;&#26029;&#20934;&#30830;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;&#26041;&#27861;&#65306;&#20174;&#25991;&#29486;&#20013;&#25214;&#21040;&#20102;&#24635;&#20849;16&#20010;&#24050;&#21457;&#34920;&#21644;&#26410;&#21457;&#34920;&#30340;&#30149;&#20363;&#25253;&#21578;&#65292;&#20854;&#20013;&#35748;&#30693;&#20559;&#24046;&#23548;&#33268;&#35823;&#35786;&#12290;&#22312;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992; GPT-4 Turbo &#20419;&#36827;&#22235;&#20010;&#27169;&#25311;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#20197;&#22797;&#21046;&#20020;&#24202;&#22242;&#38431;&#21160;&#24577;&#12290;&#27599;&#20010;&#26234;&#33021;&#20307;&#37117;&#26377;&#29420;&#29305;&#30340;&#35282;&#33394;&#65306;1) &#22312;&#32771;&#34385;&#35752;&#35770;&#21518;&#36827;&#34892;&#21021;&#27493;&#21644;&#26368;&#32456;&#35786;&#26029;&#12290;2) &#20805;&#24403;&#39764;&#39740;&#30340;&#20195;&#35328;&#20154;&#65292;&#20197;&#32416;&#27491;&#30830;&#35748;&#20559;&#24046;&#21644;&#38170;&#23450;&#20559;&#24046;&#12290;3) &#20805;&#24403;&#23548;&#24072;&#21644;&#20419;&#36827;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field. This study explores the role of large language models (LLMs) in mitigating these biases through the utilization of a multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy. Methods: A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent system, we leveraged GPT-4 Turbo to facilitate interactions among four simulated agents to replicate clinical team dynamics. Each agent has a distinct role: 1) To make the initial and final diagnosis after considering the discussions, 2) The devil's advocate and correct confirmation and anchoring bias, 3) The tutor and facilita
&lt;/p&gt;</description></item><item><title>CompactifAI&#26159;&#19968;&#31181;&#20351;&#29992;&#37327;&#23376;&#21551;&#21457;&#30340;&#24352;&#37327;&#32593;&#32476;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26497;&#21387;&#32553;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#23427;&#26356;&#27880;&#37325;&#27169;&#22411;&#30340;&#30456;&#20851;&#31354;&#38388;&#65292;&#23454;&#29616;&#26356;&#21152;&#21487;&#25511;&#21644;&#31934;&#32454;&#30340;&#21387;&#32553;&#12290;</title><link>http://arxiv.org/abs/2401.14109</link><description>&lt;p&gt;
CompactifAI: &#20351;&#29992;&#37327;&#23376;&#21551;&#21457;&#30340;&#24352;&#37327;&#32593;&#32476;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26497;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
CompactifAI: Extreme Compression of Large Language Models using Quantum-Inspired Tensor Networks. (arXiv:2401.14109v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14109
&lt;/p&gt;
&lt;p&gt;
CompactifAI&#26159;&#19968;&#31181;&#20351;&#29992;&#37327;&#23376;&#21551;&#21457;&#30340;&#24352;&#37327;&#32593;&#32476;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#26497;&#21387;&#32553;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#23427;&#26356;&#27880;&#37325;&#27169;&#22411;&#30340;&#30456;&#20851;&#31354;&#38388;&#65292;&#23454;&#29616;&#26356;&#21152;&#21487;&#25511;&#21644;&#31934;&#32454;&#30340;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22914;ChatGPT&#21644;LlaMA&#22312;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#26041;&#38754;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#65292;&#20294;&#20854;&#24222;&#22823;&#30340;&#35268;&#27169;&#24102;&#26469;&#20102;&#37325;&#35201;&#25361;&#25112;&#65292;&#22914;&#24040;&#22823;&#30340;&#35757;&#32451;&#21644;&#25512;&#26029;&#25104;&#26412;&#12289;&#36739;&#22823;&#30340;&#33021;&#28304;&#38656;&#27714;&#20197;&#21450;&#29616;&#22330;&#37096;&#32626;&#30340;&#38480;&#21046;&#12290;&#20256;&#32479;&#30340;&#21387;&#32553;&#26041;&#27861;&#22914;&#21098;&#26525;&#12289;&#33976;&#39311;&#21644;&#20302;&#31209;&#36924;&#36817;&#20027;&#35201;&#20851;&#27880;&#20943;&#23569;&#32593;&#32476;&#20013;&#31070;&#32463;&#20803;&#30340;&#26377;&#25928;&#25968;&#37327;&#65292;&#32780;&#37327;&#21270;&#26041;&#27861;&#21017;&#20391;&#37325;&#20110;&#38477;&#20302;&#21333;&#20010;&#26435;&#37325;&#30340;&#25968;&#20540;&#31934;&#24230;&#65292;&#20197;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#21516;&#26102;&#20445;&#25345;&#31070;&#32463;&#20803;&#25968;&#30446;&#19981;&#21464;&#12290;&#34429;&#28982;&#36825;&#20123;&#21387;&#32553;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#30456;&#23545;&#25104;&#21151;&#65292;&#20294;&#27809;&#26377;&#20196;&#20154;&#20449;&#26381;&#30340;&#29702;&#30001;&#35748;&#20026;&#25130;&#26029;&#31070;&#32463;&#20803;&#30340;&#25968;&#37327;&#26159;&#19968;&#31181;&#26368;&#20248;&#31574;&#30053;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;LLM&#21387;&#32553;&#26041;&#27861;CompactifAI&#65292;&#23427;&#20351;&#29992;&#37327;&#23376;&#21551;&#21457;&#30340;&#24352;&#37327;&#32593;&#32476;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#26356;&#27880;&#37325;&#27169;&#22411;&#30340;&#30456;&#20851;&#31354;&#38388;&#65292;&#23454;&#29616;&#26356;&#21152;&#21487;&#25511;&#21644;&#31934;&#32454;&#30340;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) such as ChatGPT and LlaMA are advancing rapidly in generative Artificial Intelligence (AI), but their immense size poses significant challenges, such as huge training and inference costs, substantial energy demands, and limitations for on-site deployment. Traditional compression methods such as pruning, distillation, and low-rank approximation focus on reducing the effective number of neurons in the network, while quantization focuses on reducing the numerical precision of individual weights to reduce the model size while keeping the number of neurons fixed. While these compression methods have been relatively successful in practice, there's no compelling reason to believe that truncating the number of neurons is an optimal strategy. In this context, this paper introduces CompactifAI, an innovative LLM compression approach using quantum-inspired Tensor Networks that focuses on the model's correlation space instead, allowing for a more controlled, refined an
&lt;/p&gt;</description></item><item><title>LocMoE&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36335;&#30001;&#31574;&#30053;&#65292;&#36890;&#36807;&#23558;&#37096;&#20998;&#33410;&#28857;&#38388;&#36890;&#20449;&#36716;&#25442;&#20026;&#33410;&#28857;&#20869;&#36890;&#20449;&#65292;&#32467;&#21512;&#36127;&#36733;&#24179;&#34913;&#21644;&#23616;&#37096;&#24615;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13920</link><description>&lt;p&gt;
LocMoE: &#19968;&#31181;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#30340;&#20302;&#24320;&#38144;MoE
&lt;/p&gt;
&lt;p&gt;
LocMoE: A Low-overhead MoE for Large Language Model Training. (arXiv:2401.13920v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13920
&lt;/p&gt;
&lt;p&gt;
LocMoE&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36335;&#30001;&#31574;&#30053;&#65292;&#36890;&#36807;&#23558;&#37096;&#20998;&#33410;&#28857;&#38388;&#36890;&#20449;&#36716;&#25442;&#20026;&#33410;&#28857;&#20869;&#36890;&#20449;&#65292;&#32467;&#21512;&#36127;&#36733;&#24179;&#34913;&#21644;&#23616;&#37096;&#24615;&#65292;&#20197;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#65288;MoE&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#20998;&#24067;&#24335;&#21644;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#31232;&#30095;&#21644;&#25193;&#23637;&#27169;&#22411;&#65292;&#22240;&#27492;&#22791;&#21463;&#38738;&#30544;&#12290;&#28982;&#32780;&#65292;MoE&#30340;&#24615;&#33021;&#21463;&#21040;&#36127;&#36733;&#19981;&#24179;&#34913;&#21644;&#20840;&#23545;&#20840;&#36890;&#20449;&#30340;&#39640;&#24310;&#36831;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#30001;&#20110;&#22823;&#37327;&#30340;&#19987;&#23478;&#23481;&#37327;&#23548;&#33268;&#30456;&#23545;&#20887;&#20313;&#30340;&#35745;&#31639;&#12290;&#36127;&#36733;&#19981;&#24179;&#34913;&#21487;&#33021;&#26159;&#30001;&#20110;&#29616;&#26377;&#36335;&#30001;&#31574;&#30053;&#22987;&#32456;&#20542;&#21521;&#20110;&#36873;&#25321;&#29305;&#23450;&#30340;&#19987;&#23478;&#23548;&#33268;&#30340;&#12290;&#20840;&#23545;&#20840;&#36807;&#31243;&#20013;&#39057;&#32321;&#30340;&#33410;&#28857;&#38388;&#36890;&#20449;&#20063;&#26174;&#33879;&#24310;&#38271;&#20102;&#35757;&#32451;&#26102;&#38388;&#12290;&#20026;&#20102;&#32531;&#35299;&#19978;&#36848;&#24615;&#33021;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36335;&#30001;&#31574;&#30053;&#65292;&#36890;&#36807;&#23558;&#37096;&#20998;&#33410;&#28857;&#38388;&#36890;&#20449;&#36716;&#25442;&#20026;&#33410;&#28857;&#20869;&#36890;&#20449;&#65292;&#32467;&#21512;&#36127;&#36733;&#24179;&#34913;&#21644;&#23616;&#37096;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#19987;&#23478;&#23481;&#37327;&#30340;&#26368;&#23567;&#38408;&#20540;&#65292;&#36890;&#36807;&#23558;&#19987;&#23478;&#30340;&#38376;&#25511;&#26435;&#37325;&#19982;&#20998;&#37197;&#30340;&#26631;&#35760;&#20043;&#38388;&#30340;&#26368;&#22823;&#35282;&#20559;&#24046;&#35745;&#31639;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Mixtures-of-Experts (MoE) model is a widespread distributed and integrated learning method for large language models (LLM), which is favored due to its ability to sparsify and expand models efficiently. However, the performance of MoE is limited by load imbalance and high latency of All-To-All communication, along with relatively redundant computation owing to large expert capacity. Load imbalance may result from existing routing policies that consistently tend to select certain experts. The frequent inter-node communication in the All-To-All procedure also significantly prolongs the training time. To alleviate the above performance problems, we propose a novel routing strategy that combines load balance and locality by converting partial inter-node communication to that of intra-node. Notably, we elucidate that there is a minimum threshold for expert capacity, calculated through the maximal angular deviation between the gating weights of the experts and the assigned tokens. We por
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25552;&#31034;&#20449;&#24687;&#36827;&#34892;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#30340;&#24515;&#29702;&#20581;&#24247;&#31579;&#26597;&#26041;&#27861;&#65292;&#32467;&#26524;&#19982;BERT&#28151;&#21512;&#19987;&#23478;&#20998;&#31867;&#22120;&#30456;&#24403;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#26356;&#20302;&#12290;</title><link>http://arxiv.org/abs/2401.05912</link><description>&lt;p&gt;
&#20174;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#20013;&#25552;&#21462;&#25552;&#31034;&#20449;&#24687;&#36827;&#34892;&#24515;&#29702;&#20581;&#24247;&#31579;&#26597;
&lt;/p&gt;
&lt;p&gt;
Prompt-based mental health screening from social media text. (arXiv:2401.05912v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25552;&#31034;&#20449;&#24687;&#36827;&#34892;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#30340;&#24515;&#29702;&#20581;&#24247;&#31579;&#26597;&#26041;&#27861;&#65292;&#32467;&#26524;&#19982;BERT&#28151;&#21512;&#19987;&#23478;&#20998;&#31867;&#22120;&#30456;&#24403;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#26356;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#35268;&#27169;&#22024;&#26434;&#30340;&#31038;&#20132;&#23186;&#20307;&#25991;&#26412;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#22522;&#20110;&#25552;&#31034;&#30340;&#24515;&#29702;&#20581;&#24247;&#31579;&#26597;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;GPT 3.5&#36827;&#34892;&#25552;&#31034;&#65292;&#20197;&#21306;&#20998;&#21487;&#33021;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#20986;&#29256;&#29289;&#65292;&#28982;&#21518;&#20351;&#29992;&#31616;&#21333;&#30340;&#35789;&#34955;&#25991;&#26412;&#20998;&#31867;&#22120;&#39044;&#27979;&#23454;&#38469;&#29992;&#25143;&#26631;&#31614;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#19982;BERT&#28151;&#21512;&#19987;&#23478;&#20998;&#31867;&#22120;&#30456;&#24403;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#19968;&#23567;&#37096;&#20998;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a method for prompt-based mental health screening from a large and noisy dataset of social media text. Our method uses GPT 3.5. prompting to distinguish publications that may be more relevant to the task, and then uses a straightforward bag-of-words text classifier to predict actual user labels. Results are found to be on pair with a BERT mixture of experts classifier, and incurring only a fraction of its computational costs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35843;&#26597;&#23545;&#34920;&#26684;&#25968;&#25454;&#26597;&#35810;&#21644;&#21487;&#35270;&#21270;&#30340;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#36827;&#34892;&#20102;&#20840;&#38754;&#27010;&#36848;&#65292;&#20171;&#32461;&#20102;&#35821;&#20041;&#35299;&#26512;&#31561;&#20851;&#38190;&#25216;&#26415;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;Text-to-SQL&#21644;Text-to-Vis&#38382;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.17894</link><description>&lt;p&gt;
&#23545;&#34920;&#26684;&#25968;&#25454;&#26597;&#35810;&#21644;&#21487;&#35270;&#21270;&#30340;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#65306;&#19968;&#39033;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey. (arXiv:2310.17894v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35843;&#26597;&#23545;&#34920;&#26684;&#25968;&#25454;&#26597;&#35810;&#21644;&#21487;&#35270;&#21270;&#30340;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#36827;&#34892;&#20102;&#20840;&#38754;&#27010;&#36848;&#65292;&#20171;&#32461;&#20102;&#35821;&#20041;&#35299;&#26512;&#31561;&#20851;&#38190;&#25216;&#26415;&#65292;&#24182;&#28145;&#20837;&#25506;&#35752;&#20102;Text-to-SQL&#21644;Text-to-Vis&#38382;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#20986;&#29616;&#24443;&#24213;&#25913;&#21464;&#20102;&#29992;&#25143;&#19982;&#34920;&#26684;&#25968;&#25454;&#30340;&#20132;&#20114;&#26041;&#24335;&#65292;&#23454;&#29616;&#20102;&#20174;&#20256;&#32479;&#30340;&#26597;&#35810;&#35821;&#35328;&#21644;&#25163;&#21160;&#32472;&#22270;&#36716;&#21521;&#26356;&#30452;&#35266;&#12289;&#22522;&#20110;&#35821;&#35328;&#30340;&#30028;&#38754;&#12290;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22914;ChatGPT&#21450;&#20854;&#21518;&#32487;&#32773;&#36827;&#19968;&#27493;&#25512;&#21160;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#26412;&#35843;&#26597;&#25552;&#20379;&#20102;&#20851;&#20110;&#34920;&#26684;&#25968;&#25454;&#26597;&#35810;&#21644;&#21487;&#35270;&#21270;&#30340;&#33258;&#28982;&#35821;&#35328;&#30028;&#38754;&#30340;&#20840;&#38754;&#27010;&#36848;&#65292;&#36825;&#20123;&#30028;&#38754;&#20801;&#35768;&#29992;&#25143;&#20351;&#29992;&#33258;&#28982;&#35821;&#35328;&#26597;&#35810;&#19982;&#25968;&#25454;&#36827;&#34892;&#20132;&#20114;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#36825;&#20123;&#30028;&#38754;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#25216;&#26415;&#65292;&#29305;&#21035;&#24378;&#35843;&#35821;&#20041;&#35299;&#26512;&#65292;&#36825;&#26159;&#23454;&#29616;&#20174;&#33258;&#28982;&#35821;&#35328;&#21040;SQL&#26597;&#35810;&#25110;&#25968;&#25454;&#21487;&#35270;&#21270;&#21629;&#20196;&#36716;&#21270;&#30340;&#20851;&#38190;&#25216;&#26415;&#12290;&#28982;&#21518;&#20174;&#25968;&#25454;&#38598;&#12289;&#26041;&#27861;&#35770;&#12289;&#35780;&#20272;&#25351;&#26631;&#21644;&#31995;&#32479;&#35774;&#35745;&#30340;&#35282;&#24230;&#28145;&#20837;&#25506;&#35752;&#20102;Text-to-SQL&#21644;Text-to-Vis&#38382;&#39064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. Thi
&lt;/p&gt;</description></item><item><title>&#38544;&#34255;&#24341;&#29992;&#29616;&#35937;&#22312;&#31185;&#23398;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#27491;&#24335;&#24341;&#29992;&#30340;&#25968;&#37327;&#65292;&#34920;&#26126;&#20256;&#32479;&#30340;&#24341;&#25991;&#20998;&#26512;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#35780;&#20272;&#31185;&#23398;&#21457;&#29616;&#30340;&#24433;&#21709;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.16181</link><description>&lt;p&gt;
&#31185;&#23398;&#20013;&#30340;&#38544;&#34255;&#24341;&#29992;&#27169;&#31946;&#20102;&#30495;&#27491;&#30340;&#24433;&#21709;&#21147;
&lt;/p&gt;
&lt;p&gt;
Hidden Citations Obscure True Impact in Science. (arXiv:2310.16181v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16181
&lt;/p&gt;
&lt;p&gt;
&#38544;&#34255;&#24341;&#29992;&#29616;&#35937;&#22312;&#31185;&#23398;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#24182;&#19988;&#36229;&#36807;&#20102;&#27491;&#24335;&#24341;&#29992;&#30340;&#25968;&#37327;&#65292;&#34920;&#26126;&#20256;&#32479;&#30340;&#24341;&#25991;&#20998;&#26512;&#26041;&#27861;&#26080;&#27861;&#20934;&#30830;&#35780;&#20272;&#31185;&#23398;&#21457;&#29616;&#30340;&#24433;&#21709;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#29992;&#26159;&#31185;&#23398;&#23478;&#20204;&#29992;&#26469;&#34920;&#31034;&#20043;&#21069;&#30693;&#35782;&#30340;&#26426;&#21046;&#65292;&#20294;&#26368;&#36817;&#24050;&#32463;&#21464;&#25104;&#20102;&#24191;&#27867;&#20351;&#29992;&#21644;&#28389;&#29992;&#30340;&#31185;&#23398;&#24433;&#21709;&#21147;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;&#28982;&#32780;&#65292;&#24403;&#19968;&#20010;&#21457;&#29616;&#21464;&#25104;&#20849;&#35782;&#26102;&#65292;&#24341;&#29992;&#20250;&#22240;&#20026;&#34987;&#24573;&#35270;&#32780;&#34987;&#21512;&#24182;&#12290;&#36825;&#23548;&#33268;&#20102;&#38544;&#34255;&#24341;&#29992;&#30340;&#27010;&#24565;&#65292;&#23427;&#34920;&#31034;&#23545;&#19968;&#20010;&#21457;&#29616;&#30340;&#26126;&#30830;&#25991;&#26412;&#35748;&#21487;&#65292;&#20294;&#27809;&#26377;&#24341;&#29992;&#35813;&#21457;&#29616;&#30340;&#20986;&#29256;&#29289;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20381;&#36182;&#20110;&#26080;&#30417;&#30563;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20110;&#27599;&#31687;&#35770;&#25991;&#30340;&#20840;&#25991;&#65292;&#20197;&#31995;&#32479;&#22320;&#35782;&#21035;&#38544;&#34255;&#24341;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#26377;&#24433;&#21709;&#21147;&#30340;&#21457;&#29616;&#65292;&#38544;&#34255;&#24341;&#29992;&#25968;&#37327;&#36229;&#36807;&#20102;&#24341;&#29992;&#35745;&#25968;&#65292;&#32780;&#19988;&#19981;&#21463;&#20986;&#29256;&#22330;&#25152;&#21644;&#23398;&#31185;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#38544;&#34255;&#24341;&#29992;&#30340;&#26222;&#36941;&#24615;&#19981;&#26159;&#30001;&#24341;&#29992;&#35745;&#25968;&#39537;&#21160;&#30340;&#65292;&#32780;&#26159;&#30001;&#20110;&#25163;&#31295;&#25991;&#26412;&#20013;&#23545;&#35805;&#39064;&#30340;&#35752;&#35770;&#31243;&#24230;&#20915;&#23450;&#30340;&#65292;&#36825;&#34920;&#26126;&#19968;&#20010;&#21457;&#29616;&#34987;&#35752;&#35770;&#24471;&#36234;&#22810;&#65292;&#23427;&#22312;&#26631;&#20934;&#30340;&#24341;&#25991;&#20998;&#26512;&#20013;&#23601;&#36234;&#19981;&#21487;&#35265;&#12290;&#38544;&#34255;&#24341;&#29992;&#25351;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate t
&lt;/p&gt;</description></item><item><title>&#12298;Janus&#25509;&#21475;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#22914;&#20309;&#25918;&#22823;&#38544;&#31169;&#39118;&#38505;&#12299;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#23545;&#20010;&#20154;&#20449;&#24687;&#27844;&#38706;&#30340;&#39118;&#38505;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;LLM&#21033;&#29992;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2310.15469</link><description>&lt;p&gt;
&#12298;Janus&#25509;&#21475;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#22914;&#20309;&#25918;&#22823;&#38544;&#31169;&#39118;&#38505;&#12299;
&lt;/p&gt;
&lt;p&gt;
The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks. (arXiv:2310.15469v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15469
&lt;/p&gt;
&lt;p&gt;
&#12298;Janus&#25509;&#21475;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24494;&#35843;&#22914;&#20309;&#25918;&#22823;&#38544;&#31169;&#39118;&#38505;&#12299;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#23545;&#20010;&#20154;&#20449;&#24687;&#27844;&#38706;&#30340;&#39118;&#38505;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;LLM&#21033;&#29992;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
2018&#24180;&#21518;&#30340;&#26102;&#20195;&#26631;&#24535;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#29616;&#65292;OpenAI&#30340;ChatGPT&#31561;&#21019;&#26032;&#23637;&#31034;&#20102;&#24778;&#20154;&#30340;&#35821;&#35328;&#33021;&#21147;&#12290;&#38543;&#30528;&#34892;&#19994;&#22312;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#24182;&#21033;&#29992;&#22823;&#37327;&#30340;&#20154;&#31867;&#35821;&#35328;&#25968;&#25454;&#26041;&#38754;&#30340;&#21162;&#21147;&#65292;&#23433;&#20840;&#21644;&#38544;&#31169;&#25361;&#25112;&#20063;&#20986;&#29616;&#20102;&#12290;&#20854;&#20013;&#26368;&#37325;&#35201;&#30340;&#26159;&#22312;&#22522;&#20110;&#32593;&#32476;&#30340;&#25968;&#25454;&#33719;&#21462;&#36807;&#31243;&#20013;&#65292;&#21487;&#33021;&#20250;&#24847;&#22806;&#31215;&#32047;&#20010;&#20154;&#21487;&#35782;&#21035;&#20449;&#24687;&#65288;PII&#65289;&#65292;&#20174;&#32780;&#23548;&#33268;&#24847;&#22806;&#30340;PII&#27844;&#38706;&#39118;&#38505;&#12290;&#34429;&#28982;&#20687;RLHF&#21644;&#28798;&#38590;&#24615;&#36951;&#24536;&#36825;&#26679;&#30340;&#31574;&#30053;&#24050;&#34987;&#29992;&#26469;&#25511;&#21046;&#38544;&#31169;&#20405;&#26435;&#30340;&#39118;&#38505;&#65292;&#20294;LLM&#30340;&#26368;&#26032;&#36827;&#23637;&#65288;&#20197;OpenAI&#30340;GPT-3.5&#30340;&#24494;&#35843;&#30028;&#38754;&#20026;&#20195;&#34920;&#65289;&#37325;&#26032;&#24341;&#21457;&#20102;&#20851;&#27880;&#12290;&#26377;&#20154;&#21487;&#33021;&#20250;&#38382;&#65306;LLM&#30340;&#24494;&#35843;&#26159;&#21542;&#20250;&#23548;&#33268;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#23884;&#20837;&#30340;&#20010;&#20154;&#20449;&#24687;&#27844;&#28431;&#65311;&#26412;&#25991;&#25253;&#36947;&#20102;&#39318;&#27425;&#23581;&#35797;&#23547;&#27714;&#31572;&#26696;&#30340;&#21162;&#21147;&#65292;&#37325;&#28857;&#26159;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#26032;&#30340;LLM&#21033;&#29992;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
The era post-2018 marked the advent of Large Language Models (LLMs), with innovations such as OpenAI's ChatGPT showcasing prodigious linguistic prowess. As the industry galloped toward augmenting model parameters and capitalizing on vast swaths of human language data, security and privacy challenges also emerged. Foremost among these is the potential inadvertent accrual of Personal Identifiable Information (PII) during web-based data acquisition, posing risks of unintended PII disclosure. While strategies like RLHF during training and Catastrophic Forgetting have been marshaled to control the risk of privacy infringements, recent advancements in LLMs, epitomized by OpenAI's fine-tuning interface for GPT-3.5, have reignited concerns. One may ask: can the fine-tuning of LLMs precipitate the leakage of personal information embedded within training datasets? This paper reports the first endeavor to seek the answer to the question, particularly our discovery of a new LLM exploitation avenue
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31995;&#32479;&#22320;&#20998;&#26512;&#24182;&#25506;&#32034;&#20102;&#24503;&#35821;&#21644;&#33521;&#35821;&#30340;ChatGPT&#22238;&#24212;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#23545;&#31995;&#32479;&#22810;&#27425;&#25552;&#20379;&#30456;&#21516;&#25351;&#20196;&#30340;&#24773;&#20917;&#19979;&#65292;&#22238;&#24212;&#23384;&#22312;&#24046;&#24322;&#12290;&#20351;&#29992;ChatGPT&#26469;&#24110;&#21161;&#38750;IT&#29992;&#25143;&#25776;&#20889;&#24037;&#20316;&#25991;&#26412;&#38750;&#24120;&#26377;&#29992;&#65292;&#20294;&#29992;&#25143;&#38656;&#35201;&#20805;&#20998;&#32771;&#34385;&#31995;&#32479;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.03031</link><description>&lt;p&gt;
ChatGPT&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#26377;&#22810;&#26222;&#36941;&#65311;&#8212;&#8212; &#25506;&#32034;&#24503;&#35821;&#21644;&#33521;&#35821;ChatGPT&#30340;&#22238;&#24212;
&lt;/p&gt;
&lt;p&gt;
How Prevalent is Gender Bias in ChatGPT? -- Exploring German and English ChatGPT Responses. (arXiv:2310.03031v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31995;&#32479;&#22320;&#20998;&#26512;&#24182;&#25506;&#32034;&#20102;&#24503;&#35821;&#21644;&#33521;&#35821;&#30340;ChatGPT&#22238;&#24212;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#20102;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#23545;&#31995;&#32479;&#22810;&#27425;&#25552;&#20379;&#30456;&#21516;&#25351;&#20196;&#30340;&#24773;&#20917;&#19979;&#65292;&#22238;&#24212;&#23384;&#22312;&#24046;&#24322;&#12290;&#20351;&#29992;ChatGPT&#26469;&#24110;&#21161;&#38750;IT&#29992;&#25143;&#25776;&#20889;&#24037;&#20316;&#25991;&#26412;&#38750;&#24120;&#26377;&#29992;&#65292;&#20294;&#29992;&#25143;&#38656;&#35201;&#20805;&#20998;&#32771;&#34385;&#31995;&#32479;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;ChatGPT&#30340;&#25512;&#20986;&#65292;OpenAI&#20351;&#24471;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#21487;&#20379;&#20855;&#26377;&#26377;&#38480;IT&#19987;&#19994;&#30693;&#35782;&#30340;&#29992;&#25143;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#27809;&#26377;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#32972;&#26223;&#30340;&#29992;&#25143;&#21487;&#33021;&#32570;&#20047;&#23545;LLM&#30340;&#36866;&#24403;&#29702;&#35299;&#12290;&#22240;&#27492;&#65292;&#22312;&#22788;&#29702;&#31995;&#32479;&#36755;&#20986;&#26102;&#65292;&#32570;&#20047;&#23545;&#20854;&#22266;&#26377;&#38480;&#21046;&#30340;&#24847;&#35782;&#65292;&#23558;&#25509;&#21463;&#31995;&#32479;&#36755;&#20986;&#30340;&#34920;&#38754;&#20215;&#20540;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#20998;&#26512;&#36755;&#20837;&#25552;&#31034;&#21644;&#29983;&#25104;&#30340;&#22238;&#24212;&#65292;&#20197;&#35782;&#21035;&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#20851;&#27880;&#24615;&#21035;&#20559;&#35265;&#38382;&#39064;&#65292;&#29992;&#25143;&#22312;&#22788;&#29702;&#31995;&#32479;&#36755;&#20986;&#26102;&#38656;&#35201;&#24847;&#35782;&#21040;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;ChatGPT&#22312;&#33521;&#35821;&#21644;&#24503;&#35821;&#20013;&#30340;&#21453;&#24212;&#65292;&#24182;&#25552;&#20379;&#20102;&#22899;&#24615;&#12289;&#30007;&#24615;&#25110;&#20013;&#31435;&#35282;&#24230;&#30340;&#25351;&#20196;&#26102;&#65292;&#22238;&#22797;&#30340;&#26159;&#21542;&#26377;&#24046;&#24322;&#12290;&#36890;&#36807;&#28145;&#20837;&#35843;&#26597;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20123;&#36873;&#25321;&#30340;&#25552;&#31034;&#65292;&#24182;&#20998;&#26512;&#20102;&#31995;&#32479;&#22312;&#30456;&#21516;&#26041;&#24335;&#19979;&#22810;&#27425;&#25552;&#20379;&#25351;&#20196;&#26102;&#22238;&#24212;&#30340;&#24046;&#24322;&#31243;&#24230;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#24110;&#21161;&#38750;IT&#29992;&#25143;&#25776;&#20889;&#26085;&#24120;&#24037;&#20316;&#25991;&#26412;&#65292;ChatGPT&#30830;&#23454;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#28982;&#33267;&#20851;&#37325;&#35201;&#30340;&#26159;&#35201;&#24847;&#35782;&#21040;&#65292;&#24403;&#22788;&#29702;&#31995;&#32479;&#36755;&#20986;&#26102;&#65292;&#29992;&#25143;&#38656;&#35201;&#20805;&#20998;&#32771;&#34385;&#21040;&#20854;&#22266;&#26377;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the introduction of ChatGPT, OpenAI made large language models (LLM) accessible to users with limited IT expertise. However, users with no background in natural language processing (NLP) might lack a proper understanding of LLMs. Thus the awareness of their inherent limitations, and therefore will take the systems' output at face value. In this paper, we systematically analyse prompts and the generated responses to identify possible problematic issues with a special focus on gender biases, which users need to be aware of when processing the system's output. We explore how ChatGPT reacts in English and German if prompted to answer from a female, male, or neutral perspective. In an in-depth investigation, we examine selected prompts and analyse to what extent responses differ if the system is prompted several times in an identical way. On this basis, we show that ChatGPT is indeed useful for helping non-IT users draft texts for their daily work. However, it is absolutely crucial to 
&lt;/p&gt;</description></item><item><title>C-Pack&#26159;&#19968;&#22871;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#65292;&#21253;&#25324;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12289;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#21644;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#35813;&#36164;&#28304;&#38598;&#22312;C-MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;+10%&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#21644;&#20248;&#21270;&#19968;&#22871;&#35757;&#32451;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;C-Pack&#36824;&#21457;&#24067;&#20102;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#35813;&#36164;&#28304;&#38598;&#21487;&#20844;&#24320;&#33719;&#21462;&#12290;</title><link>http://arxiv.org/abs/2309.07597</link><description>&lt;p&gt;
C-Pack: &#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#30340;&#25171;&#21253;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;
C-Pack: Packaged Resources To Advance General Chinese Embedding. (arXiv:2309.07597v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07597
&lt;/p&gt;
&lt;p&gt;
C-Pack&#26159;&#19968;&#22871;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#65292;&#21253;&#25324;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12289;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#21644;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#35813;&#36164;&#28304;&#38598;&#22312;C-MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;+10%&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#25972;&#21512;&#21644;&#20248;&#21270;&#19968;&#22871;&#35757;&#32451;&#26041;&#27861;&#36827;&#19968;&#27493;&#25552;&#21319;&#20102;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;C-Pack&#36824;&#21457;&#24067;&#20102;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#35813;&#36164;&#28304;&#38598;&#21487;&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;C-Pack&#65292;&#36825;&#26159;&#19968;&#22871;&#26174;&#33879;&#25512;&#36827;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#39046;&#22495;&#30340;&#36164;&#28304;&#12290;C-Pack&#21253;&#25324;&#19977;&#20010;&#20851;&#38190;&#36164;&#28304;&#12290;1&#65289;C-MTEB&#26159;&#19968;&#20010;&#28085;&#30422;6&#20010;&#20219;&#21153;&#21644;35&#20010;&#25968;&#25454;&#38598;&#30340;&#20840;&#38754;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#22522;&#20934;&#12290;2&#65289;C-MTP&#26159;&#19968;&#20010;&#20174;&#26631;&#35760;&#21644;&#26410;&#26631;&#35760;&#30340;&#27721;&#35821;&#35821;&#26009;&#24211;&#20013;&#31574;&#21010;&#30340;&#22823;&#35268;&#27169;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35757;&#32451;&#23884;&#20837;&#27169;&#22411;&#12290;3&#65289;C-TEM&#26159;&#19968;&#20010;&#28085;&#30422;&#22810;&#20010;&#23610;&#23544;&#30340;&#23884;&#20837;&#27169;&#22411;&#31995;&#21015;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;C-MTEB&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#20043;&#21069;&#30340;&#25152;&#26377;&#27721;&#35821;&#25991;&#26412;&#23884;&#20837;&#36798;&#21040;&#20102;&#21457;&#24067;&#26102;&#30340;&#26368;&#39640;+10%&#12290;&#25105;&#20204;&#36824;&#25972;&#21512;&#21644;&#20248;&#21270;&#20102;C-TEM&#30340;&#25972;&#22871;&#35757;&#32451;&#26041;&#27861;&#12290;&#38500;&#20102;&#25105;&#20204;&#20851;&#20110;&#26222;&#36890;&#27721;&#35821;&#23884;&#20837;&#30340;&#36164;&#28304;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#33521;&#35821;&#25991;&#26412;&#23884;&#20837;&#25968;&#25454;&#21644;&#27169;&#22411;&#12290;&#36825;&#20123;&#33521;&#35821;&#27169;&#22411;&#22312;MTEB&#22522;&#20934;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65307;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#24067;&#30340;&#33521;&#35821;&#25968;&#25454;&#27604;&#27721;&#35821;&#25968;&#25454;&#22823;2&#20493;&#12290;&#25152;&#26377;&#36825;&#20123;&#36164;&#28304;&#37117;&#21487;&#20197;&#22312;https://github.com/FlagOpen/FlagEmbedding&#19978;&#20844;&#24320;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce C-Pack, a package of resources that significantly advance the field of general Chinese embeddings. C-Pack includes three critical resources. 1) C-MTEB is a comprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets. 2) C-MTP is a massive text embedding dataset curated from labeled and unlabeled Chinese corpora for training embedding models. 3) C-TEM is a family of embedding models covering multiple sizes. Our models outperform all prior Chinese text embeddings on C-MTEB by up to +10% upon the time of the release. We also integrate and optimize the entire suite of training methods for C-TEM. Along with our resources on general Chinese embedding, we release our data and models for English text embeddings. The English models achieve state-of-the-art performance on MTEB benchmark; meanwhile, our released English data is 2 times larger than the Chinese data. All these resources are made publicly available at https://github.com/FlagOpen/FlagEmbedding.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27807;&#36890;&#28216;&#25103;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#38656;&#35843;&#21442;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23545;&#29436;&#20154;&#26432;&#28216;&#25103;&#30340;&#23454;&#35777;&#30740;&#31350;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20986;&#29616;&#30340;&#25112;&#30053;&#34892;&#20026;&#12290;&#36825;&#34920;&#26126;&#22312;&#27807;&#36890;&#28216;&#25103;&#21644;&#30456;&#20851;&#39046;&#22495;&#20013;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#20855;&#22791;&#28508;&#22312;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.04658</link><description>&lt;p&gt;
&#25506;&#32034;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27807;&#36890;&#28216;&#25103;&#20013;&#30340;&#24212;&#29992;&#65306;&#23545;&#29436;&#20154;&#26432;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf. (arXiv:2309.04658v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#27807;&#36890;&#28216;&#25103;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#38656;&#35843;&#21442;&#30340;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#23545;&#29436;&#20154;&#26432;&#28216;&#25103;&#30340;&#23454;&#35777;&#30740;&#31350;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20986;&#29616;&#30340;&#25112;&#30053;&#34892;&#20026;&#12290;&#36825;&#34920;&#26126;&#22312;&#27807;&#36890;&#28216;&#25103;&#21644;&#30456;&#20851;&#39046;&#22495;&#20013;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23558;&#20855;&#22791;&#28508;&#22312;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27807;&#36890;&#28216;&#25103;&#65292;&#25105;&#20204;&#25226;&#25351;&#20381;&#36182;&#20110;&#33258;&#28982;&#35821;&#35328;&#20132;&#27969;&#30340;&#19981;&#23436;&#20840;&#20449;&#24687;&#28216;&#25103;&#31216;&#20026;&#27807;&#36890;&#28216;&#25103;&#65292;&#22312;&#32463;&#27982;&#23398;&#12289;&#31038;&#20250;&#31185;&#23398;&#21644;&#20154;&#24037;&#26234;&#33021;&#31561;&#39046;&#22495;&#20855;&#26377;&#37325;&#35201;&#30340;&#30740;&#31350;&#20215;&#20540;&#12290;&#26412;&#25991;&#20027;&#35201;&#25506;&#35752;&#22914;&#20309;&#22312;&#27807;&#36890;&#28216;&#25103;&#20013;&#24212;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#38656;&#35843;&#21442;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#25345;LLMs&#20923;&#32467;&#29366;&#24577;&#65292;&#24182;&#21033;&#29992;&#36807;&#21435;&#30340;&#27807;&#36890;&#21644;&#32463;&#39564;&#36827;&#34892;&#25913;&#36827;&#12290;&#23545;&#20195;&#34920;&#24615;&#19988;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#27807;&#36890;&#28216;&#25103;&#8220;&#29436;&#20154;&#26432;&#8221;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#22312;&#19981;&#35843;&#25972;LLMs&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26377;&#25928;&#22320;&#36827;&#34892;&#29436;&#20154;&#26432;&#28216;&#25103;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#20986;&#29616;&#20102;&#25112;&#30053;&#34892;&#20026;&#30340;&#36857;&#35937;&#65292;&#36825;&#34920;&#26126;&#22312;&#27807;&#36890;&#28216;&#25103;&#21644;&#30456;&#20851;&#39046;&#22495;&#20013;&#20351;&#29992;LLMs&#23558;&#20250;&#26159;&#19968;&#27425;&#23500;&#26377;&#25104;&#26524;&#30340;&#26053;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in communication games, and in response, propose a tuning-free framework. Our approach keeps LLMs frozen, and relies on the retrieval and reflection on past communications and experiences for improvement. An empirical study on the representative and widely-studied communication game, ``Werewolf'', demonstrates that our framework can effectively play Werewolf game without tuning the parameters of the LLMs. More importantly, strategic behaviors begin to emerge in our experiments, suggesting that it will be a fruitful journey to engage LLMs in communication games and associated domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#30456;&#23545;&#20110;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20219;&#21153;&#24615;&#33021;&#21487;&#33021;&#20986;&#29616;&#36870;&#21521;&#32553;&#25918;&#29616;&#35937;&#12290;&#36825;&#19968;&#36870;&#21521;&#32553;&#25918;&#30340;&#21407;&#22240;&#21487;&#33021;&#26377;&#22235;&#31181;&#65306;&#35760;&#24518;&#37325;&#29616;&#12289;&#23398;&#20064;&#26679;&#26412;&#38169;&#35823;&#12289;&#20219;&#21153;&#26131;&#20110;&#24178;&#25200;&#12289;&#21644;&#20219;&#21153;&#31034;&#33539;&#30340;&#35823;&#23548;&#12290;</title><link>http://arxiv.org/abs/2306.09479</link><description>&lt;p&gt;
&#36870;&#21521;&#32553;&#25918;&#65306;&#21464;&#24471;&#26356;&#22823;&#24182;&#19981;&#24847;&#21619;&#30528;&#26356;&#22909;
&lt;/p&gt;
&lt;p&gt;
Inverse Scaling: When Bigger Isn't Better. (arXiv:2306.09479v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#30456;&#23545;&#20110;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20219;&#21153;&#24615;&#33021;&#21487;&#33021;&#20986;&#29616;&#36870;&#21521;&#32553;&#25918;&#29616;&#35937;&#12290;&#36825;&#19968;&#36870;&#21521;&#32553;&#25918;&#30340;&#21407;&#22240;&#21487;&#33021;&#26377;&#22235;&#31181;&#65306;&#35760;&#24518;&#37325;&#29616;&#12289;&#23398;&#20064;&#26679;&#26412;&#38169;&#35823;&#12289;&#20219;&#21153;&#26131;&#20110;&#24178;&#25200;&#12289;&#21644;&#20219;&#21153;&#31034;&#33539;&#30340;&#35823;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#30528;&#27169;&#22411;&#35268;&#27169;&#12289;&#35757;&#32451;&#25968;&#25454;&#12289;&#35745;&#31639;&#37327;&#30340;&#22686;&#21152;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#25439;&#22833;&#27604;&#20363;&#26377;&#21487;&#39044;&#27979;&#30340;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;LMs&#20063;&#21487;&#33021;&#26174;&#31034;&#36870;&#21521;&#32553;&#25918;&#65292;&#21363;&#38543;&#30528;&#35268;&#27169;&#30340;&#22686;&#21152;&#20219;&#21153;&#24615;&#33021;&#36234;&#26469;&#36234;&#24046;&#65292;&#36825;&#21487;&#33021;&#26159;&#30001;&#20110;&#35757;&#32451;&#30446;&#26631;&#21644;&#25968;&#25454;&#30340;&#32570;&#38519;&#25152;&#33268;&#12290;&#26412;&#25991;&#36890;&#36807;&#20844;&#24320;&#27604;&#36187;&#65292;Inverse Scaling Prize&#65292;&#22312;11&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#36870;&#21521;&#32553;&#25918;&#29616;&#35937;&#12290;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#38598;&#21450;&#20854;&#20182;&#23454;&#20363;&#65292;&#25105;&#20204;&#35748;&#20026;&#36870;&#21521;&#32553;&#25918;&#30340;&#21407;&#22240;&#21487;&#33021;&#26377;&#22235;&#31181;&#65306;&#65288;i&#65289;&#20542;&#21521;&#20110;&#37325;&#22797;&#35760;&#24518;&#30340;&#24207;&#21015;&#32780;&#38750;&#36319;&#38543;&#19978;&#19979;&#25991;&#25351;&#31034;&#65292;&#65288;ii&#65289;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#27169;&#20223;&#19981;&#33391;&#27169;&#24335;&#65292;&#65288;iii&#65289;&#20219;&#21153;&#20013;&#26377;&#19968;&#20010;&#26131;&#20110;&#24178;&#25200;LMs&#30340;&#20219;&#21153;&#65292;&#23558;&#20854;&#27880;&#24847;&#21147;&#36716;&#31227;&#21040;&#36739;&#31616;&#21333;&#30340;&#20219;&#21153;&#65292;&#32780;&#38750;&#36739;&#38590;&#30340;&#20219;&#21153;&#65292;&#65288;iv&#65289;&#20219;&#21153;&#30340;&#27491;&#30830;&#31034;&#33539;&#35823;&#23548;LMs&#12290;&#20316;&#32773;&#36824;&#20844;&#24067;&#20102;&#27604;&#36187;&#30340;&#33719;&#32988;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Work on scaling laws has found that large language models (LMs) show predictable improvements to overall loss with increased scale (model size, training data, and compute). Here, we present evidence for the claim that LMs may show inverse scaling, or worse task performance with increased scale, e.g., due to flaws in the training objective and data. We present empirical evidence of inverse scaling on 11 datasets collected by running a public contest, the Inverse Scaling Prize, with a substantial prize pool. Through analysis of the datasets, along with other examples found in the literature, we identify four potential causes of inverse scaling: (i) preference to repeat memorized sequences over following in-context instructions, (ii) imitation of undesirable patterns in the training data, (iii) tasks containing an easy distractor task which LMs could focus on, rather than the harder real task, and (iv) correct but misleading few-shot demonstrations of the task. We release the winning data
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25581;&#31034;&#20102;Text-to-SQL&#27169;&#22411;&#23384;&#22312;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#28431;&#27934;&#33021;&#22815;&#34987;&#24694;&#24847;&#21033;&#29992;&#20135;&#29983;&#25915;&#20987;&#65292;&#36890;&#36807;&#23545;&#21830;&#19994;&#24212;&#29992;&#21644;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#39564;&#35777;&#12290;&#35813;&#30740;&#31350;&#24847;&#22312;&#24341;&#36215;&#23398;&#26415;&#30028;&#23545;NLP&#31639;&#27861;&#30456;&#20851;&#30340;&#36719;&#20214;&#23433;&#20840;&#38382;&#39064;&#30340;&#20851;&#27880;&#21644;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2211.15363</link><description>&lt;p&gt;
&#20851;&#20110;Text-to-SQL&#27169;&#22411;&#30340;&#23433;&#20840;&#28431;&#27934;
&lt;/p&gt;
&lt;p&gt;
On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15363
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25581;&#31034;&#20102;Text-to-SQL&#27169;&#22411;&#23384;&#22312;&#30340;&#23433;&#20840;&#28431;&#27934;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#28431;&#27934;&#33021;&#22815;&#34987;&#24694;&#24847;&#21033;&#29992;&#20135;&#29983;&#25915;&#20987;&#65292;&#36890;&#36807;&#23545;&#21830;&#19994;&#24212;&#29992;&#21644;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#39564;&#35777;&#12290;&#35813;&#30740;&#31350;&#24847;&#22312;&#24341;&#36215;&#23398;&#26415;&#30028;&#23545;NLP&#31639;&#27861;&#30456;&#20851;&#30340;&#36719;&#20214;&#23433;&#20840;&#38382;&#39064;&#30340;&#20851;&#27880;&#21644;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#35777;&#26126;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#31639;&#27861;&#23481;&#26131;&#21463;&#21040;&#24694;&#24847;&#25915;&#20987;&#65292;&#20294;&#36825;&#20123;&#24369;&#28857;&#26159;&#21542;&#21487;&#33021;&#23548;&#33268;&#36719;&#20214;&#23433;&#20840;&#23041;&#32961;&#23578;&#26410;&#28145;&#20837;&#30740;&#31350;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#23545;&#24120;&#29992;&#20110;&#21019;&#24314;&#33258;&#28982;&#35821;&#35328;&#25968;&#25454;&#24211;&#25509;&#21475;&#30340;Text-to-SQL&#31995;&#32479;&#36827;&#34892;&#20102;&#28431;&#27934;&#27979;&#35797;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20845;&#20010;&#21830;&#19994;&#24212;&#29992;&#20013;&#30340;Text-to-SQL&#27169;&#22359;&#21487;&#20197;&#34987;&#25805;&#32437;&#20197;&#20135;&#29983;&#24694;&#24847;&#20195;&#30721;&#65292;&#28508;&#22312;&#22320;&#23548;&#33268;&#25968;&#25454;&#27844;&#28431;&#21644;&#25298;&#32477;&#26381;&#21153;&#25915;&#20987;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#35777;&#26126;NLP&#27169;&#22411;&#21487;&#20197;&#34987;&#21033;&#29992;&#20026;&#25915;&#20987;&#21521;&#37327;&#30340;&#31034;&#20363;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#22235;&#20010;&#24320;&#28304;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#23545;Text-to-SQL&#31995;&#32479;&#36827;&#34892;&#30452;&#25509;&#21518;&#38376;&#25915;&#20987;&#21487;&#20197;&#36798;&#21040;100&#65285;&#30340;&#25104;&#21151;&#29575;&#65292;&#32780;&#19981;&#24433;&#21709;&#20854;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24341;&#36215;&#23398;&#26415;&#30028;&#23545;&#19982;NLP&#31639;&#27861;&#30456;&#20851;&#30340;&#28508;&#22312;&#36719;&#20214;&#23433;&#20840;&#38382;&#39064;&#30340;&#20851;&#27880;&#65292;&#24182;&#40723;&#21169;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although it has been demonstrated that Natural Language Processing (NLP) algorithms are vulnerable to deliberate attacks, the question of whether such weaknesses can lead to software security threats is under-explored. To bridge this gap, we conducted vulnerability tests on Text-to-SQL systems that are commonly used to create natural language interfaces to databases. We showed that the Text-to-SQL modules within six commercial applications can be manipulated to produce malicious code, potentially leading to data breaches and Denial of Service attacks. This is the first demonstration that NLP models can be exploited as attack vectors in the wild. In addition, experiments using four open-source language models verified that straightforward backdoor attacks on Text-to-SQL systems achieve a 100% success rate without affecting their performance. The aim of this work is to draw the community's attention to potential software security issues associated with NLP algorithms and encourage explor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#23545;&#25968;&#32447;&#24615;&#20445;&#25252;&#24615;&#21450;&#20854;&#23545;&#19979;&#28216;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;&#22312;&#20108;&#20803;&#24773;&#20917;&#19979;&#65292;&#19979;&#28216;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#26080;&#27861;&#24674;&#22797;&#34987;&#21024;&#38500;&#30340;&#27010;&#24565;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#22810;&#31867;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#38388;&#25509;&#24674;&#22797;&#27010;&#24565;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#32447;&#24615;&#21024;&#38500;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24378;&#35843;&#20102;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2210.10012</link><description>&lt;p&gt;
&#23545;&#25968;&#32447;&#24615;&#20445;&#25252;&#24615;&#21450;&#20854;&#24433;&#21709;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Log-linear Guardedness and its Implications. (arXiv:2210.10012v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#23545;&#25968;&#32447;&#24615;&#20445;&#25252;&#24615;&#21450;&#20854;&#23545;&#19979;&#28216;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;&#22312;&#20108;&#20803;&#24773;&#20917;&#19979;&#65292;&#19979;&#28216;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#26080;&#27861;&#24674;&#22797;&#34987;&#21024;&#38500;&#30340;&#27010;&#24565;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#26500;&#24314;&#22810;&#31867;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#38388;&#25509;&#24674;&#22797;&#27010;&#24565;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#32447;&#24615;&#21024;&#38500;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24378;&#35843;&#20102;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#21457;&#29616;&#65292;&#22312;&#20551;&#35774;&#21487;&#32447;&#24615;&#30340;&#31070;&#32463;&#34920;&#31034;&#20013;&#65292;&#20174;&#20013;&#21024;&#38500;&#21487;&#20154;&#35299;&#37322;&#30340;&#27010;&#24565;&#30340;&#26041;&#27861;&#26159;&#21487;&#34892;&#21644;&#26377;&#29992;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#21024;&#38500;&#23545;&#20110;&#22522;&#20110;&#20462;&#25913;&#21518;&#34920;&#31034;&#36827;&#34892;&#35757;&#32451;&#30340;&#19979;&#28216;&#20998;&#31867;&#22120;&#34892;&#20026;&#30340;&#24433;&#21709;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#23545;&#25968;&#32447;&#24615;&#20445;&#25252;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#23545;&#25163;&#26080;&#27861;&#30452;&#25509;&#20174;&#34920;&#31034;&#20013;&#39044;&#27979;&#27010;&#24565;&#30340;&#33021;&#21147;&#65292;&#24182;&#30740;&#31350;&#20854;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20108;&#20803;&#24773;&#20917;&#19979;&#65292;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#19979;&#28216;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#26080;&#27861;&#24674;&#22797;&#34987;&#21024;&#38500;&#30340;&#27010;&#24565;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#26500;&#24314;&#19968;&#20010;&#22810;&#31867;&#23545;&#25968;&#32447;&#24615;&#27169;&#22411;&#65292;&#38388;&#25509;&#24674;&#22797;&#27010;&#24565;&#65292;&#36825;&#25351;&#20986;&#20102;&#23545;&#25968;&#32447;&#24615;&#20445;&#25252;&#24615;&#20316;&#20026;&#19979;&#28216;&#20559;&#24046;&#32531;&#35299;&#25216;&#26415;&#30340;&#20869;&#22312;&#23616;&#38480;&#24615;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#32447;&#24615;&#21024;&#38500;&#26041;&#27861;&#30340;&#29702;&#35770;&#38480;&#21046;&#65292;&#24182;&#24378;&#35843;&#20102;&#36827;&#19968;&#27493;&#30740;&#31350;&#21487;&#35299;&#37322;&#31070;&#32463;&#34920;&#31034;&#19982;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#32852;&#31995;&#30340;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods for erasing human-interpretable concepts from neural representations that assume linearity have been found to be tractable and useful. However, the impact of this removal on the behavior of downstream classifiers trained on the modified representations is not fully understood. In this work, we formally define the notion of log-linear guardedness as the inability of an adversary to predict the concept directly from the representation, and study its implications. We show that, in the binary case, under certain assumptions, a downstream log-linear model cannot recover the erased concept. However, we demonstrate that a multiclass log-linear model \emph{can} be constructed that indirectly recovers the concept in some cases, pointing to the inherent limitations of log-linear guardedness as a downstream bias mitigation technique. These findings shed light on the theoretical limitations of linear erasure methods and highlight the need for further research on the connections between int
&lt;/p&gt;</description></item></channel></rss>