<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#25945;&#32946;&#23398;&#29702;&#24565;&#30340;&#21453;&#39304;&#26694;&#26550;FELT&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21453;&#39304;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#31616;&#21270;&#20102;&#29616;&#26377;&#30340;&#25163;&#24037;&#35774;&#35745;&#21453;&#39304;&#65292;&#36824;&#20026;NLF&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.00279</link><description>&lt;p&gt;
&#35753;&#25105;&#26469;&#25945;&#20320;&#65306;&#35821;&#35328;&#27169;&#22411;&#30340;&#21453;&#39304;&#25945;&#32946;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Let Me Teach You: Pedagogical Foundations of Feedback for Language Models. (arXiv:2307.00279v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00279
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#25945;&#32946;&#23398;&#29702;&#24565;&#30340;&#21453;&#39304;&#26694;&#26550;FELT&#65292;&#29992;&#20110;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#21453;&#39304;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#19982;&#20154;&#31867;&#20559;&#22909;&#30340;&#19968;&#33268;&#24615;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#31616;&#21270;&#20102;&#29616;&#26377;&#30340;&#25163;&#24037;&#35774;&#35745;&#21453;&#39304;&#65292;&#36824;&#20026;NLF&#30740;&#31350;&#24320;&#36767;&#20102;&#26032;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#21453;&#39304;&#65288;NLF&#65289;&#26159;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#23545;&#40784;&#30340;&#19968;&#20010;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#30340;&#36884;&#24452;&#12290;&#23613;&#31649;NLF&#21487;&#20197;&#20256;&#36798;&#20016;&#23500;&#22810;&#26679;&#30340;&#20449;&#24687;&#65292;&#20294;&#24448;&#24448;&#26159;&#25163;&#24037;&#35774;&#35745;&#30340;&#21644;&#38543;&#24847;&#30340;&#12290;&#22312;&#19981;&#21516;&#30340;&#19990;&#30028;&#20013;&#65292;&#25945;&#32946;&#23398;&#30740;&#31350;&#38271;&#26399;&#20197;&#26469;&#24314;&#31435;&#20102;&#20960;&#31181;&#26377;&#25928;&#30340;&#21453;&#39304;&#27169;&#22411;&#12290;&#22312;&#36825;&#31687;&#35266;&#28857;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#27719;&#32534;&#20102;&#26469;&#33258;&#25945;&#32946;&#23398;&#30340;&#24605;&#24819;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;FELT&#30340;LLMs&#21453;&#39304;&#26694;&#26550;&#65292;&#27010;&#36848;&#20102;&#21453;&#39304;&#31354;&#38388;&#30340;&#21508;&#31181;&#29305;&#24449;&#20197;&#21450;&#22522;&#20110;&#36825;&#20123;&#21464;&#37327;&#30340;&#21453;&#39304;&#20869;&#23481;&#20998;&#31867;&#27861;&#12290;&#25105;&#20204;&#30340;&#20998;&#31867;&#27861;&#19981;&#20165;&#25552;&#20379;&#20102;&#23545;&#21453;&#39304;&#31354;&#38388;&#30340;&#19968;&#33324;&#26144;&#23556;&#65292;&#36824;&#25552;&#20379;&#20102;&#25945;&#32946;&#23398;&#30830;&#23450;&#30340;&#31163;&#25955;&#31867;&#21035;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20174;&#32463;&#39564;&#19978;&#35777;&#26126;&#19981;&#21516;&#21453;&#39304;&#31867;&#22411;&#23545;&#20462;&#35746;&#29983;&#25104;&#30340;&#24433;&#21709;&#12290;&#38500;&#20102;&#31616;&#21270;&#29616;&#26377;&#30340;NLF&#35774;&#35745;&#65292;FELT&#36824;&#20026;NLF&#30740;&#31350;&#24102;&#26469;&#20102;&#26032;&#30340;&#26410;&#24320;&#21457;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#31867;&#27861;&#25552;&#20379;&#32473;&#31038;&#21306;&#65292;&#20026;&#26144;&#23556;&#25105;&#20204;&#30340;&#31867;&#21035;&#25552;&#20379;&#25351;&#21335;&#21644;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural Language Feedback (NLF) is an increasingly popular avenue to align Large Language Models (LLMs) to human preferences. Despite the richness and diversity of the information it can convey, NLF is often hand-designed and arbitrary. In a different world, research in pedagogy has long established several effective feedback models. In this opinion piece, we compile ideas from pedagogy to introduce FELT, a feedback framework for LLMs that outlines the various characteristics of the feedback space, and a feedback content taxonomy based on these variables. Our taxonomy offers both a general mapping of the feedback space, as well as pedagogy-established discrete categories, allowing us to empirically demonstrate the impact of different feedback types on revised generations. In addition to streamlining existing NLF designs, FELT also brings out new, unexplored directions for research in NLF. We make our taxonomy available to the community, providing guides and examples for mapping our cat
&lt;/p&gt;</description></item><item><title>&#20998;&#23618;&#39044;&#35757;&#32451;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#26415;&#35821;&#23884;&#20837;&#65292;&#36890;&#36807;&#23558;&#20020;&#24202;&#26415;&#35821;&#34920;&#31034;&#20026;&#35821;&#20041;&#23884;&#20837;&#24182;&#21033;&#29992;&#20302;&#32500;&#23884;&#20837;&#20316;&#20026;&#29305;&#24449;&#21521;&#37327;&#65292;&#21487;&#20197;&#25552;&#39640;&#20020;&#24202;&#35760;&#24405;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.00266</link><description>&lt;p&gt;
&#20998;&#23618;&#39044;&#35757;&#32451;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#26415;&#35821;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Pretraining for Biomedical Term Embeddings. (arXiv:2307.00266v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00266
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#39044;&#35757;&#32451;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#26415;&#35821;&#23884;&#20837;&#65292;&#36890;&#36807;&#23558;&#20020;&#24202;&#26415;&#35821;&#34920;&#31034;&#20026;&#35821;&#20041;&#23884;&#20837;&#24182;&#21033;&#29992;&#20302;&#32500;&#23884;&#20837;&#20316;&#20026;&#29305;&#24449;&#21521;&#37327;&#65292;&#21487;&#20197;&#25552;&#39640;&#20020;&#24202;&#35760;&#24405;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#21253;&#21547;&#20102;&#20851;&#20110;&#24739;&#32773;&#30340;&#21307;&#30103;&#29366;&#20917;&#21644;&#31649;&#29702;&#30340;&#35814;&#32454;&#35828;&#26126;&#12290;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#23545;&#20020;&#24202;&#35760;&#24405;&#36827;&#34892;&#22788;&#29702;&#65292;&#21487;&#20197;&#21033;&#29992;&#20020;&#24202;&#26415;&#35821;&#30340;&#35266;&#23519;&#39057;&#29575;&#20316;&#20026;&#39044;&#27979;&#29305;&#24449;&#65292;&#29992;&#20110;&#20020;&#24202;&#20915;&#31574;&#21644;&#24739;&#32773;&#36712;&#36857;&#39044;&#27979;&#31561;&#19979;&#28216;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#37327;&#30456;&#20284;&#19988;&#30456;&#20851;&#30340;&#20020;&#24202;&#27010;&#24565;&#65292;&#26356;&#26377;&#25928;&#30340;&#24314;&#27169;&#31574;&#30053;&#26159;&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#23558;&#20020;&#24202;&#26415;&#35821;&#34920;&#31034;&#20026;&#35821;&#20041;&#23884;&#20837;&#65292;&#24182;&#23558;&#20302;&#32500;&#23884;&#20837;&#20316;&#20026;&#29305;&#24449;&#21521;&#37327;&#29992;&#20110;&#39044;&#27979;&#24314;&#27169;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25928;&#30340;&#34920;&#31034;&#65292;&#21033;&#29992;&#19982;&#29983;&#29289;&#21307;&#23398;&#30693;&#35782;&#22270;&#35889;&#36827;&#34892;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#24494;&#35843;&#65292;&#21487;&#33021;&#20250;&#29983;&#25104;&#27604;&#20165;&#20351;&#29992;&#26631;&#20934;&#35821;&#35328;&#27169;&#22411;&#33719;&#24471;&#30340;&#29983;&#29289;&#21307;&#23398;&#26415;&#35821;&#23884;&#20837;&#26356;&#22909;&#30340;&#23884;&#20837;&#12290;&#36825;&#20123;&#23884;&#20837;&#21487;&#20197;&#26377;&#25928;&#21306;&#20998;&#21516;&#20041;&#35789;&#23545;&#21644;&#19981;&#30456;&#20851;&#30340;&#35789;&#23545;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#24120;&#24120;&#26080;&#27861;&#25429;&#25417;&#21040;&#19981;&#21516;&#30340;&#31243;&#24230;
&lt;/p&gt;
&lt;p&gt;
Electronic health records (EHR) contain narrative notes that provide extensive details on the medical condition and management of patients. Natural language processing (NLP) of clinical notes can use observed frequencies of clinical terms as predictive features for downstream applications such as clinical decision making and patient trajectory prediction. However, due to the vast number of highly similar and related clinical concepts, a more effective modeling strategy is to represent clinical terms as semantic embeddings via representation learning and use the low dimensional embeddings as feature vectors for predictive modeling. To achieve efficient representation, fine-tuning pretrained language models with biomedical knowledge graphs may generate better embeddings for biomedical terms than those from standard language models alone. These embeddings can effectively discriminate synonymous pairs of from those that are unrelated. However, they often fail to capture different degrees o
&lt;/p&gt;</description></item><item><title>InstructEval&#24320;&#21457;&#20102;&#19968;&#20010;&#35780;&#20272;&#22871;&#20214;&#65292;&#29992;&#20110;&#23545;&#25351;&#20196;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#36890;&#36807;&#20351;&#29992;&#31574;&#21010;&#30340;&#25163;&#21160;&#32534;&#20889;&#30340;&#25351;&#20196;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00259</link><description>&lt;p&gt;
InstructEval: &#31995;&#32479;&#35780;&#20272;&#25351;&#20196;&#36873;&#25321;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00259
&lt;/p&gt;
&lt;p&gt;
InstructEval&#24320;&#21457;&#20102;&#19968;&#20010;&#35780;&#20272;&#22871;&#20214;&#65292;&#29992;&#20110;&#23545;&#25351;&#20196;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#36890;&#36807;&#20351;&#29992;&#31574;&#21010;&#30340;&#25163;&#21160;&#32534;&#20889;&#30340;&#25351;&#20196;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#23398;&#20064; (ICL) &#36890;&#36807;&#20351;&#29992;&#25351;&#20196;&#21644;&#19968;&#23567;&#32452;&#27880;&#37322;&#31034;&#20363;&#26469;&#25552;&#31034;&#19968;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM) &#26469;&#25191;&#34892;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#25552;&#31034;&#20013;&#20351;&#29992;&#30340;&#36755;&#20837;&#30340;&#32454;&#33410;&#23545; ICL &#26377;&#30528;&#37325;&#35201;&#24433;&#21709;&#65292;&#36825;&#28608;&#21169;&#20102;&#25351;&#20196;&#36873;&#25321;&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#25351;&#20196;&#36873;&#25321;&#30340;&#24433;&#21709;&#23578;&#26410;&#24471;&#21040;&#28145;&#20837;&#25506;&#32034;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#20165;&#38480;&#20110;&#27169;&#22411;&#21644;&#20219;&#21153;&#30340;&#27973;&#23618;&#23376;&#38598;&#65292;&#36825;&#38480;&#21046;&#20102;&#27934;&#23519;&#21147;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010; ICL &#35780;&#20272;&#22871;&#20214;&#65292;&#20197;&#23545;&#36825;&#20123;&#25216;&#26415;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#35813;&#22871;&#20214;&#21253;&#25324;&#26469;&#33258;4&#20010;&#19981;&#21516;&#27169;&#22411;&#23478;&#26063;&#30340;13&#20010;&#24320;&#28304;LLM&#65292;&#28085;&#30422;9&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65292;&#20195;&#34920;&#20102;3&#20010;&#20998;&#31867;&#20013;&#21508;&#31181;&#31867;&#22411;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#22522;&#20934;&#27979;&#35797;&#35780;&#20272;&#20102;7&#31181;&#21463;&#27426;&#36814;&#30340;&#25351;&#20196;&#36873;&#25321;&#26041;&#27861;&#30456;&#23545;&#20110;ICL&#30456;&#20851;&#30340;&#20116;&#39033;&#26399;&#26395;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;&#31574;&#21010;&#30340;&#25163;&#21160;&#32534;&#20889;&#30340;&#25351;&#20196;&#21487;&#20197;&#26174;&#33879;&#22320;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning (ICL) performs tasks by prompting a large language model (LLM) using an instruction and a small set of annotated examples called demonstrations. Recent work has shown that the precise details of the inputs used in the prompt significantly impacts ICL, which has incentivized instruction selection algorithms. The effect of instruction-choice however is severely underexplored, with existing analyses being restricted to shallow subsets of models and tasks, which limits the generalizability of their insights. We develop an ICL evaluation suite to conduct a thorough assessment of these techniques. The suite includes 13 open-sourced LLMs of varying scales from 4 distinct model families and covers 9 different tasks, representing a range of task types across 3 categories. In this work, we evaluate the relative performance of 7 popular instruction selection methods using our benchmark over five desiderata relevant to ICL. We discover that using curated manually-written instru
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#27169;&#24577;&#22840;&#24352;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#20316;&#20026;&#20004;&#31181;&#27169;&#24577;&#36827;&#34892;&#30740;&#31350;&#12290;&#21516;&#26102;&#65292;&#35780;&#20272;&#20102;&#19981;&#21516;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#22312;&#27492;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#12290;&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#22840;&#24352;&#26816;&#27979;&#30340;&#36328;&#39046;&#22495;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00209</link><description>&lt;p&gt;
&#22270;&#20687;&#30340;&#37325;&#35201;&#24615;&#65306;&#22810;&#27169;&#24577;&#22840;&#24352;&#26816;&#27979;&#30340;&#26032;&#25968;&#25454;&#38598;&#21644;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#27169;&#24577;&#22840;&#24352;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#25991;&#26412;&#21644;&#22270;&#20687;&#20316;&#20026;&#20004;&#31181;&#27169;&#24577;&#36827;&#34892;&#30740;&#31350;&#12290;&#21516;&#26102;&#65292;&#35780;&#20272;&#20102;&#19981;&#21516;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#22312;&#27492;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#12290;&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#22840;&#24352;&#26816;&#27979;&#30340;&#36328;&#39046;&#22495;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22840;&#24352;&#65292;&#21363;&#22840;&#22823;&#20854;&#35789;&#65292;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#35821;&#35328;&#29616;&#35937;&#12290;&#22840;&#24352;&#26816;&#27979;&#26159;&#29702;&#35299;&#20154;&#31867;&#34920;&#36798;&#30340;&#37325;&#35201;&#37096;&#20998;&#12290;&#24050;&#32463;&#26377;&#20960;&#39033;&#20851;&#20110;&#22840;&#24352;&#26816;&#27979;&#30340;&#30740;&#31350;&#65292;&#20294;&#22823;&#22810;&#25968;&#30340;&#30740;&#31350;&#21482;&#20851;&#27880;&#25991;&#26412;&#27169;&#24577;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#30340;&#21457;&#23637;&#65292;&#20154;&#20204;&#21487;&#20197;&#20351;&#29992;&#21508;&#31181;&#27169;&#24577;&#65288;&#21253;&#25324;&#25991;&#26412;&#12289;&#22270;&#20687;&#12289;&#35270;&#39057;&#31561;&#65289;&#26469;&#34920;&#36798;&#22840;&#24352;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22810;&#27169;&#24577;&#22840;&#24352;&#26816;&#27979;&#12290;&#25105;&#20204;&#20174;&#24494;&#21338;&#65288;&#20013;&#22269;&#30340;&#19968;&#31181;&#31038;&#20132;&#23186;&#20307;&#65289;&#21019;&#24314;&#20102;&#19968;&#20010;&#22810;&#27169;&#24577;&#26816;&#27979;&#25968;&#25454;&#38598;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#19968;&#20123;&#30740;&#31350;&#12290;&#25105;&#20204;&#23558;&#24494;&#21338;&#30340;&#25991;&#26412;&#21644;&#22270;&#20687;&#35270;&#20026;&#20004;&#31181;&#27169;&#24577;&#65292;&#25506;&#32034;&#20102;&#25991;&#26412;&#21644;&#22270;&#20687;&#22312;&#22840;&#24352;&#26816;&#27979;&#20013;&#30340;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#19981;&#21516;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#32534;&#30721;&#22120;&#22312;&#36825;&#20010;&#19979;&#28216;&#20219;&#21153;&#19978;&#30340;&#24615;&#33021;&#12290;&#30001;&#20110;&#36825;&#20010;&#25968;&#25454;&#38598;&#26159;&#20174;&#20116;&#20010;&#19981;&#21516;&#30340;&#20027;&#39064;&#26500;&#24314;&#30340;&#65292;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#35821;&#35328;&#27169;&#22411;&#22312;&#21307;&#23398;&#39046;&#22495;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35843;&#26597;&#30740;&#31350;&#65292;&#24182;&#25506;&#32034;&#20102;&#25552;&#39640;NER&#24615;&#33021;&#30340;&#26377;&#25928;&#23454;&#20307;&#35782;&#21035;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.00186</link><description>&lt;p&gt;
&#20174;&#35821;&#35328;&#27169;&#22411;&#21040;&#21307;&#23398;&#39046;&#22495;&#30334;&#20998;&#20043;&#30334;&#30340;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26377;&#22810;&#36828;
&lt;/p&gt;
&lt;p&gt;
How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain. (arXiv:2307.00186v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#35821;&#35328;&#27169;&#22411;&#22312;&#21307;&#23398;&#39046;&#22495;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35843;&#26597;&#30740;&#31350;&#65292;&#24182;&#25506;&#32034;&#20102;&#25552;&#39640;NER&#24615;&#33021;&#30340;&#26377;&#25928;&#23454;&#20307;&#35782;&#21035;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35821;&#35328;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#21457;&#20102;&#24378;&#22823;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#22914;&#23567;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;T5&#65289;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;GPT-4&#65289;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#24191;&#27867;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#22914;&#36890;&#29992;&#39046;&#22495;&#20013;&#30340;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#21307;&#23398;&#39046;&#22495;&#30340;&#25928;&#26524;&#20173;&#28982;&#19981;&#30830;&#23450;&#65292;&#30001;&#20110;&#35813;&#39046;&#22495;&#30340;&#29305;&#27530;&#24615;&#65292;&#21307;&#23398;NER&#30340;&#24615;&#33021;&#24635;&#26159;&#38656;&#35201;&#39640;&#31934;&#24230;&#12290;&#26412;&#25991;&#26088;&#22312;&#23545;&#21307;&#23398;&#23569;&#26679;&#26412;NER&#20013;&#30340;LMs&#30340;&#24615;&#33021;&#36827;&#34892;&#24443;&#24213;&#35843;&#26597;&#65292;&#24182;&#22238;&#31572;&#20174;100&#65285;&#30334;&#20998;&#27604;&#20013;LMs&#19982;&#21307;&#23398;&#39046;&#22495;&#30340;&#23569;&#26679;&#26412;NER&#26377;&#22810;&#36828;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#25506;&#32034;&#19968;&#31181;&#26377;&#25928;&#30340;&#23454;&#20307;&#35782;&#21035;&#22120;&#20197;&#25552;&#39640;NER&#30340;&#24615;&#33021;&#12290;&#26681;&#25454;&#25105;&#20204;&#22312;2018&#24180;&#21040;2023&#24180;&#26399;&#38388;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26126;&#30830;&#34920;&#26126;&#65292;LLMs o
&lt;/p&gt;
&lt;p&gt;
Recent advancements in language models (LMs) have led to the emergence of powerful models such as Small LMs (e.g., T5) and Large LMs (e.g., GPT-4). These models have demonstrated exceptional capabilities across a wide range of tasks, such as name entity recognition (NER) in the general domain. (We define SLMs as pre-trained models with fewer parameters compared to models like GPT-3/3.5/4, such as T5, BERT, and others.) Nevertheless, their efficacy in the medical section remains uncertain and the performance of medical NER always needs high accuracy because of the particularity of the field. This paper aims to provide a thorough investigation to compare the performance of LMs in medical few-shot NER and answer How far is LMs from 100\% Few-shot NER in Medical Domain, and moreover to explore an effective entity recognizer to help improve the NER performance. Based on our extensive experiments conducted on 16 NER models spanning from 2018 to 2023, our findings clearly indicate that LLMs o
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#32508;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#23637;&#31034;&#30340;&#20154;&#26684;&#29305;&#36136;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#37096;&#20998;LLMs&#22312;&#29305;&#23450;&#25552;&#31034;&#37197;&#32622;&#19979;&#27169;&#25311;&#30340;&#20154;&#26684;&#21487;&#38752;&#19988;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#26356;&#22823;&#21644;&#32463;&#36807;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;LLMs&#30340;&#36755;&#20986;&#20013;&#30340;&#20154;&#26684;&#29305;&#36136;&#21487;&#20197;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#22609;&#36896;&#12290;</title><link>http://arxiv.org/abs/2307.00184</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#20154;&#26684;&#29305;&#36136;
&lt;/p&gt;
&lt;p&gt;
Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00184
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#32508;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#23637;&#31034;&#30340;&#20154;&#26684;&#29305;&#36136;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#37096;&#20998;LLMs&#22312;&#29305;&#23450;&#25552;&#31034;&#37197;&#32622;&#19979;&#27169;&#25311;&#30340;&#20154;&#26684;&#21487;&#38752;&#19988;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#26356;&#22823;&#21644;&#32463;&#36807;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;LLMs&#30340;&#36755;&#20986;&#20013;&#30340;&#20154;&#26684;&#29305;&#36136;&#21487;&#20197;&#26681;&#25454;&#38656;&#35201;&#36827;&#34892;&#22609;&#36896;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20986;&#29616;&#24443;&#24213;&#25913;&#21464;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65292;&#20351;&#24471;&#33021;&#22815;&#29983;&#25104;&#36830;&#36143;&#19988;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#25991;&#26412;&#12290;&#38543;&#30528;LLMs&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#39537;&#21160;&#23545;&#35805;&#20195;&#29702;&#65292;&#36825;&#20123;&#27169;&#22411;&#36890;&#36807;&#35757;&#32451;&#22823;&#37327;&#20154;&#24037;&#29983;&#25104;&#30340;&#25968;&#25454;&#33719;&#24471;&#30340;&#20154;&#26684;&#29305;&#36136;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#30001;&#20110;&#20154;&#26684;&#26159;&#20915;&#23450;&#20132;&#27969;&#25928;&#26524;&#30340;&#37325;&#35201;&#22240;&#32032;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#39564;&#35777;&#30340;&#24515;&#29702;&#27979;&#37327;&#27979;&#35797;&#65292;&#24182;&#23545;&#20174;&#24191;&#27867;&#20351;&#29992;&#30340;LLMs&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#23637;&#31034;&#30340;&#20154;&#26684;&#29305;&#36136;&#36827;&#34892;&#37327;&#21270;&#12289;&#20998;&#26512;&#21644;&#22609;&#36896;&#12290;&#25105;&#20204;&#21457;&#29616;&#65306;1&#65289;&#26576;&#20123;LLMs&#30340;&#36755;&#20986;&#20013;&#27169;&#25311;&#30340;&#20154;&#26684;&#65288;&#22312;&#29305;&#23450;&#30340;&#25552;&#31034;&#37197;&#32622;&#19979;&#65289;&#26159;&#21487;&#38752;&#21644;&#26377;&#25928;&#30340;&#65307;2&#65289;LLM&#27169;&#25311;&#30340;&#20154;&#26684;&#30340;&#21487;&#38752;&#24615;&#21644;&#26377;&#25928;&#24615;&#30340;&#35777;&#25454;&#23545;&#20110;&#26356;&#22823;&#30340;&#21644;&#32463;&#36807;&#25351;&#23548;&#24494;&#35843;&#30340;&#27169;&#22411;&#26356;&#24378;&#65307;3&#65289;LLM&#36755;&#20986;&#20013;&#30340;&#20154;&#26684;&#21487;&#20197;&#26681;&#25454;&#38656;&#35201;&#30340;&#32500;&#24230;&#36827;&#34892;&#22609;&#36896;&#65292;&#20197;&#27169;&#20223;&#29305;&#23450;&#30340;&#20154;&#26684;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#20855;&#26377;&#20449;&#24565;&#20197;&#21450;&#22914;&#20309;&#34913;&#37327;&#23427;&#20204;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#32467;&#26524;&#21644;&#23545;&#26368;&#26032;&#35770;&#35777;&#30340;&#20998;&#26512;&#65292;&#25351;&#20986;&#29616;&#22312;&#20173;&#28982;&#27809;&#26377;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35854;&#35328;&#25506;&#27979;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.00175</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#20173;&#28982;&#27809;&#26377;&#35854;&#35328;&#25506;&#27979;&#22120;&#65306;&#25506;&#31350;&#32463;&#39564;&#21644;&#27010;&#24565;&#19978;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks. (arXiv:2307.00175v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00175
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#21542;&#20855;&#26377;&#20449;&#24565;&#20197;&#21450;&#22914;&#20309;&#34913;&#37327;&#23427;&#20204;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#32467;&#26524;&#21644;&#23545;&#26368;&#26032;&#35770;&#35777;&#30340;&#20998;&#26512;&#65292;&#25351;&#20986;&#29616;&#22312;&#20173;&#28982;&#27809;&#26377;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35854;&#35328;&#25506;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#26159;&#21542;&#20855;&#26377;&#20449;&#24565;&#20197;&#21450;&#22914;&#20309;&#34913;&#37327;&#23427;&#20204;&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;Azaria&#21644;Mitchell&#65288;2023&#65289;&#20197;&#21450;Burns&#31561;&#20154;&#65288;2022&#65289;&#25552;&#20986;&#30340;&#20004;&#31181;&#29616;&#26377;&#26041;&#27861;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#22312;&#22522;&#26412;&#26041;&#38754;&#26080;&#27861;&#25512;&#24191;&#12290;&#38543;&#21518;&#25105;&#20204;&#35748;&#20026;&#65292;&#21363;&#20351;LLM&#20855;&#26377;&#20449;&#24565;&#65292;&#36825;&#20123;&#26041;&#27861;&#20063;&#19981;&#22826;&#21487;&#33021;&#22312;&#27010;&#24565;&#19978;&#25104;&#21151;&#12290;&#22240;&#27492;&#65292;&#29616;&#22312;&#20173;&#28982;&#27809;&#26377;&#38024;&#23545;LLM&#30340;&#35854;&#35328;&#25506;&#27979;&#22120;&#12290;&#22312;&#25551;&#36848;&#20102;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#21518;&#65292;&#25105;&#20204;&#36864;&#21518;&#19968;&#27493;&#65292;&#24605;&#32771;&#22312;&#39318;&#27425;&#20013;&#25105;&#20204;&#26159;&#21542;&#24212;&#35813;&#26399;&#24453;LLM&#20855;&#26377;&#31867;&#20284;&#20449;&#24565;&#30340;&#19996;&#35199;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20123;&#26088;&#22312;&#35777;&#26126;LLM&#19981;&#33021;&#26377;&#20449;&#24565;&#30340;&#26368;&#26032;&#35770;&#35777;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;&#35770;&#35777;&#26159;&#35823;&#23548;&#24615;&#30340;&#12290;&#25105;&#20204;&#23545;&#22260;&#32469;LLM&#20013;&#20449;&#24565;&#30340;&#38382;&#39064;&#30340;&#38382;&#39064;&#25552;&#20986;&#20102;&#26356;&#26377;&#25104;&#25928;&#30340;&#26694;&#26550;&#65292;&#24182;&#24378;&#35843;&#20102;&#35813;&#38382;&#39064;&#30340;&#32463;&#39564;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26410;&#26469;&#24037;&#20316;&#30340;&#20855;&#20307;&#36335;&#24452;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the questions of whether or not large language models (LLMs) have beliefs, and, if they do, how we might measure them. First, we evaluate two existing approaches, one due to Azaria and Mitchell (2023) and the other to Burns et al. (2022). We provide empirical results that show that these methods fail to generalize in very basic ways. We then argue that, even if LLMs have beliefs, these methods are unlikely to be successful for conceptual reasons. Thus, there is still no lie-detector for LLMs. After describing our empirical results we take a step back and consider whether or not we should expect LLMs to have something like beliefs in the first place. We consider some recent arguments aiming to show that LLMs cannot have beliefs. We show that these arguments are misguided. We provide a more productive framing of questions surrounding the status of beliefs in LLMs, and highlight the empirical nature of the problem. We conclude by suggesting some concrete paths for future work.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#25512;&#29702;&#25163;&#20876;&#65292;&#29992;&#20110;&#23558;&#25512;&#29702;&#38382;&#39064;&#36716;&#21270;&#20026;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#23454;&#20363;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#25216;&#24039;&#30340;&#28436;&#31034;&#65292;&#24110;&#21161;&#35835;&#32773;&#29702;&#35299;&#22914;&#20309;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#12290;&#35770;&#25991;&#26368;&#21518;&#25552;&#20379;&#20102;&#20004;&#20010;&#31034;&#20363;&#20197;&#35828;&#26126;&#36825;&#20123;&#25216;&#24039;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.00171</link><description>&lt;p&gt;
&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#25512;&#29702;&#25163;&#20876;
&lt;/p&gt;
&lt;p&gt;
The Integer Linear Programming Inference Cookbook. (arXiv:2307.00171v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#25512;&#29702;&#25163;&#20876;&#65292;&#29992;&#20110;&#23558;&#25512;&#29702;&#38382;&#39064;&#36716;&#21270;&#20026;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#23454;&#20363;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#25216;&#24039;&#30340;&#28436;&#31034;&#65292;&#24110;&#21161;&#35835;&#32773;&#29702;&#35299;&#22914;&#20309;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#12290;&#35770;&#25991;&#26368;&#21518;&#25552;&#20379;&#20102;&#20004;&#20010;&#31034;&#20363;&#20197;&#35828;&#26126;&#36825;&#20123;&#25216;&#24039;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#24180;&#26469;&#65292;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#24050;&#34987;&#29992;&#20110;&#27169;&#25311;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#38382;&#39064;&#20013;&#30340;&#25512;&#29702;&#12290;&#26412;&#35843;&#26597;&#26088;&#22312;&#25351;&#23548;&#35835;&#32773;&#23558;&#26032;&#30340;&#25512;&#29702;&#38382;&#39064;&#26694;&#26550;&#21270;&#20026;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#30340;&#23454;&#20363;&#65292;&#24182;&#20197;&#19968;&#31995;&#21015;&#30340;&#25216;&#24039;&#36827;&#34892;&#32452;&#32455;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36890;&#36807;&#20004;&#20010;&#23454;&#20363;&#26469;&#35828;&#26126;&#36825;&#20123;&#25216;&#24039;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the years, integer linear programs have been employed to model inference in many natural language processing problems. This survey is meant to guide the reader through the process of framing a new inference problem as an instance of an integer linear program and is structured as a collection of recipes. At the end, we will see two worked examples to illustrate the use of these recipes.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#33258;&#25105;&#30417;&#30563;&#30340;&#35821;&#38899;&#27169;&#22411;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#19981;&#21516;&#23618;&#20013;&#32534;&#30721;&#20102;&#19981;&#21516;&#30340;&#35821;&#35328;&#20449;&#24687;&#65292;&#20063;&#23398;&#20064;&#20102;&#31867;&#20284;&#38899;&#32032;&#30340;&#23376;&#35789;&#21333;&#20803;&#12290;&#19982;&#21333;&#35789;&#30456;&#20851;&#30340;&#20449;&#24687;&#20027;&#35201;&#22312;&#20013;&#38388;&#30340;&#27169;&#22411;&#23618;&#20013;&#65292;&#21516;&#26102;&#19968;&#20123;&#20302;&#32423;&#20449;&#24687;&#22312;&#26356;&#39640;&#30340;&#23618;&#20013;&#20063;&#24471;&#20197;&#20445;&#30041;&#12290;</title><link>http://arxiv.org/abs/2307.00162</link><description>&lt;p&gt;
&#33258;&#25105;&#30417;&#30563;&#30340;&#35821;&#38899;&#27169;&#22411;&#23545;&#21333;&#35789;&#30340;&#20102;&#35299;&#31243;&#24230;&#26159;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
What do self-supervised speech models know about words?. (arXiv:2307.00162v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00162
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#33258;&#25105;&#30417;&#30563;&#30340;&#35821;&#38899;&#27169;&#22411;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#19981;&#21516;&#23618;&#20013;&#32534;&#30721;&#20102;&#19981;&#21516;&#30340;&#35821;&#35328;&#20449;&#24687;&#65292;&#20063;&#23398;&#20064;&#20102;&#31867;&#20284;&#38899;&#32032;&#30340;&#23376;&#35789;&#21333;&#20803;&#12290;&#19982;&#21333;&#35789;&#30456;&#20851;&#30340;&#20449;&#24687;&#20027;&#35201;&#22312;&#20013;&#38388;&#30340;&#27169;&#22411;&#23618;&#20013;&#65292;&#21516;&#26102;&#19968;&#20123;&#20302;&#32423;&#20449;&#24687;&#22312;&#26356;&#39640;&#30340;&#23618;&#20013;&#20063;&#24471;&#20197;&#20445;&#30041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#35768;&#22810;&#33258;&#25105;&#30417;&#30563;&#30340;&#35821;&#38899;&#27169;&#22411;&#65288;S3Ms&#65289;&#34987;&#24341;&#20837;&#65292;&#20026;&#21508;&#31181;&#35821;&#38899;&#20219;&#21153;&#25552;&#20379;&#20102;&#24615;&#33021;&#21644;&#25968;&#25454;&#25928;&#29575;&#30340;&#25913;&#36827;&#12290;&#26377;&#35777;&#25454;&#34920;&#26126;&#65292;&#19981;&#21516;&#30340;S3Ms&#22312;&#19981;&#21516;&#30340;&#23618;&#20013;&#32534;&#30721;&#35821;&#35328;&#20449;&#24687;&#65292;&#32780;&#19988;&#19968;&#20123;S3Ms&#20284;&#20046;&#23398;&#20064;&#20102;&#31867;&#20284;&#20110;&#38899;&#32032;&#30340;&#23376;&#35789;&#21333;&#20803;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#25429;&#25417;&#26356;&#22823;&#30340;&#35821;&#35328;&#21333;&#20803;&#65288;&#22914;&#21333;&#35789;&#65289;&#30340;&#31243;&#24230;&#20197;&#21450;&#21333;&#35789;&#30456;&#20851;&#20449;&#24687;&#30340;&#32534;&#30721;&#20301;&#32622;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#26469;&#33258;&#19977;&#20010;S3Ms&#30340;&#19981;&#21516;&#23618;&#30340;&#21333;&#35789;&#29255;&#27573;&#34920;&#31034;&#36827;&#34892;&#20102;&#22810;&#31181;&#20998;&#26512;&#65306;wav2vec2&#12289;HuBERT&#21644;WavLM&#12290;&#25105;&#20204;&#21033;&#29992;&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#65292;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#20998;&#26512;&#24037;&#20855;&#65292;&#26469;&#34913;&#37327;&#36825;&#20123;&#34920;&#31034;&#19982;&#21333;&#35789;&#32423;&#35821;&#35328;&#23646;&#24615;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26368;&#22823;&#30340;&#21333;&#35789;&#32423;&#35821;&#35328;&#20869;&#23481;&#24448;&#24448;&#20986;&#29616;&#22312;&#20013;&#38388;&#30340;&#27169;&#22411;&#23618;&#65292;&#32780;&#19968;&#20123;&#20302;&#32423;&#20449;&#24687;&#65288;&#22914;&#21457;&#38899;&#65289;&#20063;&#22312;&#26356;&#39640;&#30340;&#23618;&#20013;&#20445;&#30041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many self-supervised speech models (S3Ms) have been introduced over the last few years, producing performance and data efficiency improvements for a variety of speech tasks. Evidence is emerging that different S3Ms encode linguistic information in different layers, and also that some S3Ms appear to learn phone-like sub-word units. However, the extent to which these models capture larger linguistic units, such as words, and where word-related information is encoded, remains unclear. In this study, we conduct several analyses of word segment representations extracted from different layers of three S3Ms: wav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a lightweight analysis tool, to measure the similarity between these representations and word-level linguistic properties. We find that the maximal word-level linguistic content tends to be found in intermediate model layers, while some lower-level information like pronunciation is also retained in higher layers 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#35780;&#20272;&#22522;&#20934;&#65288;SMILE&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#19982;&#20256;&#32479;&#35821;&#35328;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#28151;&#21512;&#31038;&#20132;&#23186;&#20307;&#21644;&#20256;&#32479;&#35821;&#35328;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;SMILE&#35780;&#20998;&#19978;&#34920;&#29616;&#26368;&#22909;&#65292;&#27604;&#20854;&#20182;&#21516;&#35268;&#27169;&#27169;&#22411;&#39640;&#20986;4.2&#20010;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.00135</link><description>&lt;p&gt;
SMILE&#65306;&#23545;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#29702;&#35299;&#30340;&#35780;&#20272;&#21644;&#39046;&#22495;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding. (arXiv:2307.00135v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#30340;&#29702;&#35299;&#33021;&#21147;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#35780;&#20272;&#22522;&#20934;&#65288;SMILE&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#19982;&#20256;&#32479;&#35821;&#35328;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#28151;&#21512;&#31038;&#20132;&#23186;&#20307;&#21644;&#20256;&#32479;&#35821;&#35328;&#30340;&#39044;&#35757;&#32451;&#27169;&#22411;&#22312;SMILE&#35780;&#20998;&#19978;&#34920;&#29616;&#26368;&#22909;&#65292;&#27604;&#20854;&#20182;&#21516;&#35268;&#27169;&#27169;&#22411;&#39640;&#20986;4.2&#20010;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#35821;&#35328;&#27169;&#22411;&#23545;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#29702;&#35299;&#30340;&#33021;&#21147;&#12290;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#19982;&#26631;&#20934;&#20070;&#38754;&#35821;&#26377;&#25152;&#19981;&#21516;&#65292;&#28982;&#32780;&#29616;&#26377;&#30340;&#35780;&#20272;&#26631;&#20934;&#26410;&#33021;&#23436;&#20840;&#25429;&#25417;&#35821;&#35328;&#27169;&#22411;&#22312;&#36825;&#20010;&#22312;&#31038;&#20250;&#12289;&#32463;&#27982;&#21644;&#25919;&#27835;&#23618;&#38754;&#37117;&#38750;&#24120;&#37325;&#35201;&#30340;&#39046;&#22495;&#24615;&#33021;&#12290;&#25105;&#20204;&#37327;&#21270;&#20102;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#19982;&#20256;&#32479;&#35821;&#35328;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#26080;&#35770;&#26159;&#22312;&#35789;&#27719;&#20998;&#24067;&#36824;&#26159;&#35821;&#35328;&#36716;&#21464;&#36895;&#29575;&#19978;&#65292;&#36825;&#31181;&#24046;&#24322;&#37117;&#26159;&#26174;&#33879;&#30340;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#31038;&#20132;&#23186;&#20307;&#35821;&#35328;&#35780;&#20272;&#22522;&#20934;&#65288;SMILE&#65289;&#65292;&#28085;&#30422;&#20102;&#22235;&#20010;&#31038;&#20132;&#23186;&#20307;&#24179;&#21488;&#21644;&#21313;&#19968;&#39033;&#20219;&#21153;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#23398;&#20064;&#20998;&#35789;&#22120;&#21644;&#28151;&#21512;&#31038;&#20132;&#23186;&#20307;&#19982;&#20256;&#32479;&#35821;&#35328;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#33719;&#24471;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#25972;&#20307;SMILE&#35780;&#20998;&#19978;&#27604;&#30456;&#21516;&#35268;&#27169;&#30340;&#26368;&#20339;&#26367;&#20195;&#27169;&#22411;&#39640;&#20986;4.2&#20010;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the ability of transformer-based language models (LMs) to understand social media language. Social media (SM) language is distinct from standard written language, yet existing benchmarks fall short of capturing LM performance in this socially, economically, and politically important domain. We quantify the degree to which social media language differs from conventional language and conclude that the difference is significant both in terms of token distribution and rate of linguistic shift. Next, we introduce a new benchmark for Social MedIa Language Evaluation (SMILE) that covers four SM platforms and eleven tasks. Finally, we show that learning a tokenizer and pretraining on a mix of social media and conventional language yields an LM that outperforms the best similar-sized alternative by 4.2 points on the overall SMILE score.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#37329;&#34701;&#25968;&#25454;&#38598;REFinD&#20013;&#30340;&#20851;&#31995;&#25277;&#21462;&#20219;&#21153;&#65292;&#36890;&#36807;&#32467;&#21512;&#24102;&#31867;&#22411;&#23454;&#20307;&#26631;&#35760;&#30340;&#34920;&#31034;&#21644;&#22312;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;69.65%&#30340;F1&#24471;&#20998;&#12290;</title><link>http://arxiv.org/abs/2307.00132</link><description>&lt;p&gt;
iMETRE&#65306;&#23558;&#23454;&#20307;&#31867;&#22411;&#30340;&#26631;&#35760;&#34701;&#20837;&#20851;&#31995;&#25277;&#21462;&#20013;
&lt;/p&gt;
&lt;p&gt;
iMETRE: Incorporating Markers of Entity Types for Relation Extraction. (arXiv:2307.00132v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#37329;&#34701;&#25968;&#25454;&#38598;REFinD&#20013;&#30340;&#20851;&#31995;&#25277;&#21462;&#20219;&#21153;&#65292;&#36890;&#36807;&#32467;&#21512;&#24102;&#31867;&#22411;&#23454;&#20307;&#26631;&#35760;&#30340;&#34920;&#31034;&#21644;&#22312;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;69.65%&#30340;F1&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21477;&#23376;&#32423;&#21035;&#30340;&#20851;&#31995;&#25277;&#21462;&#26088;&#22312;&#26681;&#25454;&#19978;&#19979;&#25991;&#21477;&#23376;&#30830;&#23450;&#20004;&#20010;&#23454;&#20307;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#35768;&#22810;&#23581;&#35797;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20294;&#30446;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#20173;&#26377;&#24456;&#22823;&#30340;&#25913;&#36827;&#31354;&#38388;&#12290;&#26412;&#25991;&#38024;&#23545;&#37329;&#34701;&#25968;&#25454;&#38598;REFinD&#20013;&#30340;&#20851;&#31995;&#25277;&#21462;&#20219;&#21153;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#24102;&#31867;&#22411;&#23454;&#20307;&#26631;&#35760;&#30340;&#34920;&#31034;&#21644;&#22312;&#25968;&#25454;&#38598;&#19978;&#24494;&#35843;&#30340;&#21508;&#31181;&#27169;&#22411;&#65292;&#20351;&#25105;&#20204;&#22312;&#39564;&#35777;&#38598;&#19978;&#23454;&#29616;&#20102;69.65%&#30340;F1&#24471;&#20998;&#12290;&#36890;&#36807;&#26412;&#25991;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#21508;&#31181;&#26041;&#27861;&#21644;&#21487;&#33021;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sentence-level relation extraction (RE) aims to identify the relationship between 2 entities given a contextual sentence. While there have been many attempts to solve this problem, the current solutions have a lot of room to improve. In this paper, we approach the task of relationship extraction in the financial dataset REFinD. Our approach incorporates typed entity markers representations and various models finetuned on the dataset, which has allowed us to achieve an F1 score of 69.65% on the validation set. Through this paper, we discuss various approaches and possible limitations.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22522;&#20110;&#21551;&#21457;&#24335;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#22312;&#29305;&#23450;&#39046;&#22495;&#21644;&#36890;&#29992;&#25991;&#26723;&#20013;&#25191;&#34892;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#27809;&#26377;&#21333;&#19968;&#30340;&#26041;&#27861;&#33021;&#22815;&#23637;&#31034;&#20986;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#30340;&#20840;&#38754;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.00130</link><description>&lt;p&gt;
&#39046;&#22495;&#21644;&#36890;&#29992;&#25991;&#26723;&#20013;&#30340;&#20449;&#24687;&#25552;&#21462;: &#22522;&#20110;&#21551;&#21457;&#24335;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#30340;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Information Extraction in Domain and Generic Documents: Findings from Heuristic-based and Data-driven Approaches. (arXiv:2307.00130v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00130
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35843;&#26597;&#20102;&#22522;&#20110;&#21551;&#21457;&#24335;&#21644;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#22312;&#29305;&#23450;&#39046;&#22495;&#21644;&#36890;&#29992;&#25991;&#26723;&#20013;&#25191;&#34892;&#20449;&#24687;&#25552;&#21462;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#27809;&#26377;&#21333;&#19968;&#30340;&#26041;&#27861;&#33021;&#22815;&#23637;&#31034;&#20986;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#30340;&#20840;&#38754;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#25552;&#21462;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#36215;&#30528;&#38750;&#24120;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#23427;&#23545;&#20110;&#20174;&#38750;&#32467;&#26500;&#21270;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#32467;&#26500;&#21270;&#20449;&#24687;&#30340;&#35768;&#22810;NLP&#24212;&#29992;&#37117;&#26159;&#22522;&#30784;&#24615;&#30340;&#12290;&#21551;&#21457;&#24335;&#25628;&#32034;&#21644;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#26159;&#20004;&#31181;&#20027;&#27969;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#25991;&#26723;&#31867;&#22411;&#21644;&#38271;&#24230;&#23545;IE&#20219;&#21153;&#30340;&#24433;&#21709;&#21364;&#27809;&#26377;&#24471;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#22522;&#20110;&#21551;&#21457;&#24335;&#25628;&#32034;&#21644;&#25968;&#25454;&#39537;&#21160;&#22312;&#29305;&#23450;&#39046;&#22495;&#21644;&#36890;&#29992;&#25991;&#26723;&#20013;&#25191;&#34892;&#20004;&#20010;IE&#20219;&#21153;&#65306;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#21644;&#35821;&#20041;&#35282;&#33394;&#26631;&#27880;&#65288;SRL&#65289;&#30340;&#20934;&#30830;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#20551;&#35774;&#65306;&#39318;&#20808;&#65292;&#30701;&#25991;&#26723;&#21487;&#33021;&#20250;&#27604;&#38271;&#25991;&#26723;&#20135;&#29983;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#65307;&#20854;&#27425;&#65292;&#30001;&#20110;&#35757;&#32451;&#25991;&#26723;&#31867;&#22411;&#30340;&#38480;&#21046;&#65292;&#36890;&#29992;&#25991;&#26723;&#21487;&#33021;&#34920;&#29616;&#20986;&#20248;&#20110;&#39046;&#22495;&#30456;&#20851;&#25991;&#26723;&#30340;&#25552;&#21462;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#27809;&#26377;&#21333;&#19968;&#30340;&#26041;&#27861;&#33021;&#22815;&#23637;&#31034;&#20986;&#36229;&#36234;&#20854;&#20182;&#26041;&#27861;&#30340;&#20840;&#38754;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information extraction (IE) plays very important role in natural language processing (NLP) and is fundamental to many NLP applications that used to extract structured information from unstructured text data. Heuristic-based searching and data-driven learning are two main stream implementation approaches. However, no much attention has been paid to document genre and length influence on IE tasks. To fill the gap, in this study, we investigated the accuracy and generalization abilities of heuristic-based searching and data-driven to perform two IE tasks: named entity recognition (NER) and semantic role labeling (SRL) on domain-specific and generic documents with different length. We posited two hypotheses: first, short documents may yield better accuracy results compared to long documents; second, generic documents may exhibit superior extraction outcomes relative to domain-dependent documents due to training document genre limitations. Our findings reveals that no single method demonstr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#28436;&#31034;&#26816;&#32034;&#30340;&#20803;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23494;&#38598;&#30340;&#27573;&#33853;&#26816;&#32034;&#22120;&#26816;&#32034;&#19982;&#27599;&#20010;&#31034;&#20363;&#35821;&#20041;&#30456;&#20284;&#30340;&#26631;&#35760;&#28436;&#31034;&#26469;&#25552;&#39640;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#23558;&#22806;&#37096;&#30693;&#35782;&#19982;&#27169;&#22411;&#21442;&#25968;&#20998;&#31163;&#65292;&#21487;&#20197;&#35757;&#32451;&#20986;&#21442;&#25968;&#39640;&#25928;&#19988;&#27867;&#21270;&#33021;&#21147;&#24378;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2307.00119</link><description>&lt;p&gt;
&#20855;&#26377;&#28436;&#31034;&#26816;&#32034;&#30340;&#20803;&#35757;&#32451;&#29992;&#20110;&#39640;&#25928;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Meta-training with Demonstration Retrieval for Efficient Few-shot Learning. (arXiv:2307.00119v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00119
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#28436;&#31034;&#26816;&#32034;&#30340;&#20803;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23494;&#38598;&#30340;&#27573;&#33853;&#26816;&#32034;&#22120;&#26816;&#32034;&#19982;&#27599;&#20010;&#31034;&#20363;&#35821;&#20041;&#30456;&#20284;&#30340;&#26631;&#35760;&#28436;&#31034;&#26469;&#25552;&#39640;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#23558;&#22806;&#37096;&#30693;&#35782;&#19982;&#27169;&#22411;&#21442;&#25968;&#20998;&#31163;&#65292;&#21487;&#20197;&#35757;&#32451;&#20986;&#21442;&#25968;&#39640;&#25928;&#19988;&#27867;&#21270;&#33021;&#21147;&#24378;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#23569;&#26679;&#26412;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#20196;&#20154;&#38663;&#24778;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#24320;&#38144;&#24456;&#22823;&#12290;&#20803;&#35757;&#32451;&#20801;&#35768;&#21033;&#29992;&#36739;&#23567;&#30340;&#27169;&#22411;&#36827;&#34892;&#36890;&#29992;&#39046;&#22495;&#21644;&#20219;&#21153;&#26080;&#20851;&#30340;&#23569;&#26679;&#26412;&#27867;&#21270;&#65307;&#28982;&#32780;&#65292;&#20165;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#20250;&#23548;&#33268;&#27169;&#22411;&#21487;&#33021;&#27809;&#26377;&#36275;&#22815;&#30340;&#21442;&#25968;&#21270;&#25110;&#30693;&#35782;&#26469;&#24555;&#36895;&#36866;&#24212;&#21508;&#31181;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#28436;&#31034;&#26816;&#32034;&#30340;&#20803;&#35757;&#32451;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#23494;&#38598;&#30340;&#27573;&#33853;&#26816;&#32034;&#22120;&#26469;&#26816;&#32034;&#19982;&#27599;&#20010;&#31034;&#20363;&#35821;&#20041;&#30456;&#20284;&#30340;&#26631;&#35760;&#28436;&#31034;&#65292;&#20197;&#33719;&#24471;&#26356;&#22810;&#30340;&#22810;&#26679;&#21270;&#30417;&#30563;&#12290;&#36890;&#36807;&#23558;&#22806;&#37096;&#30693;&#35782;&#19982;&#27169;&#22411;&#21442;&#25968;&#20998;&#31163;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#20803;&#35757;&#32451;&#26469;&#35757;&#32451;&#21442;&#25968;&#39640;&#25928;&#30340;&#27169;&#22411;&#65292;&#22312;&#26356;&#22810;&#31181;&#31867;&#30340;&#20219;&#21153;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#20174;UnifiedQA&#21644;CrossFit&#26500;&#24314;&#20102;&#19968;&#20010;&#20803;&#35757;&#32451;&#38598;&#65292;&#24182;&#22522;&#20110;UnifiedQA&#20219;&#21153;&#25552;&#20986;&#20102;&#19968;&#20010;&#28436;&#31034;&#24211;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#39318;&#27425;&#23558;&#26816;&#32034;&#19982;&#20803;&#35757;&#32451;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#25552;&#39640;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models show impressive results on few-shot NLP tasks. However, these models are memory and computation-intensive. Meta-training allows one to leverage smaller models for few-shot generalization in a domain-general and task-agnostic manner; however, these methods alone results in models that may not have sufficient parameterization or knowledge to adapt quickly to a large variety of tasks. To overcome this issue, we propose meta-training with demonstration retrieval, where we use a dense passage retriever to retrieve semantically similar labeled demonstrations to each example for more varied supervision. By separating external knowledge from model parameters, we can use meta-training to train parameter-efficient models that generalize well on a larger variety of tasks. We construct a meta-training set from UnifiedQA and CrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our knowledge, our work is the first to combine retrieval with meta-training, to u
&lt;/p&gt;</description></item><item><title>Ticket-BERT&#26159;&#19968;&#20010;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20026;&#20107;&#20214;&#31649;&#29702;&#31080;&#25454;&#36827;&#34892;&#26631;&#27880;&#30340;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#22797;&#26434;&#30340;&#31080;&#25454;&#25968;&#25454;&#21644;&#26102;&#38388;&#25935;&#24863;&#24615;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.00108</link><description>&lt;p&gt;
Ticket-BERT:&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20026;&#20107;&#20214;&#31649;&#29702;&#31080;&#25454;&#36827;&#34892;&#26631;&#27880;
&lt;/p&gt;
&lt;p&gt;
Ticket-BERT: Labeling Incident Management Tickets with Language Models. (arXiv:2307.00108v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00108
&lt;/p&gt;
&lt;p&gt;
Ticket-BERT&#26159;&#19968;&#20010;&#20351;&#29992;&#35821;&#35328;&#27169;&#22411;&#20026;&#20107;&#20214;&#31649;&#29702;&#31080;&#25454;&#36827;&#34892;&#26631;&#27880;&#30340;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#22797;&#26434;&#30340;&#31080;&#25454;&#25968;&#25454;&#21644;&#26102;&#38388;&#25935;&#24863;&#24615;&#38382;&#39064;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35299;&#20915;&#20248;&#20808;&#32423;&#20107;&#20214;&#31080;&#25454;&#30340;&#19968;&#20010;&#37325;&#35201;&#26041;&#38754;&#26159;&#39640;&#25928;&#22320;&#20351;&#29992;&#31934;&#32454;&#20998;&#31867;&#26469;&#26631;&#27880;&#36825;&#20123;&#31080;&#25454;&#12290;&#28982;&#32780;&#65292;&#31080;&#25454;&#25968;&#25454;&#36890;&#24120;&#24456;&#22797;&#26434;&#65292;&#32473;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24102;&#26469;&#20102;&#20960;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#65306;&#65288;1&#65289;&#31080;&#25454;&#26082;&#21487;&#20197;&#30001;&#39044;&#23450;&#20041;&#31639;&#27861;&#30340;&#26426;&#22120;&#29983;&#25104;&#65292;&#20063;&#21487;&#20197;&#30001;&#20855;&#26377;&#19981;&#21516;&#21327;&#35758;&#30340;&#20855;&#26377;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#30340;&#24037;&#31243;&#24072;&#26356;&#26032;&#21644;&#21019;&#24314;&#65292;&#65288;2&#65289;&#31080;&#25454;&#39057;&#32321;&#36827;&#34892;&#20462;&#35746;&#65292;&#36890;&#36807;&#20462;&#25913;&#20840;&#37096;&#25110;&#37096;&#20998;&#31080;&#25454;&#25551;&#36848;&#26469;&#26356;&#26032;&#31080;&#25454;&#29366;&#24577;&#65292;&#65288;3&#65289;&#31080;&#25454;&#26631;&#27880;&#26159;&#26102;&#38388;&#25935;&#24863;&#30340;&#65292;&#38656;&#35201;&#26681;&#25454;&#36719;&#20214;&#21644;&#30828;&#20214;&#25913;&#36827;&#30340;&#24555;&#36895;&#29983;&#21629;&#21608;&#26399;&#36827;&#34892;&#30693;&#35782;&#26356;&#26032;&#21644;&#26032;&#30340;&#26631;&#31614;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Ticket-BERT&#65292;&#23427;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#31080;&#25454;&#25968;&#25454;&#38598;&#35757;&#32451;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#20581;&#22766;&#30340;&#35821;&#35328;&#27169;&#22411;&#26469;&#20026;&#31080;&#25454;&#36827;&#34892;&#26631;&#27880;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;Ticket-BERT&#22312;Azure&#35748;&#30693;&#26381;&#21153;&#19978;&#20248;&#20110;&#22522;&#32447;&#21644;&#26368;&#20808;&#36827;&#30340;&#25991;&#26412;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;Ticket-BERT&#23553;&#35013;&#21040;&#19968;&#20010;&#31215;&#26497;&#30340;le...
&lt;/p&gt;
&lt;p&gt;
An essential aspect of prioritizing incident tickets for resolution is efficiently labeling tickets with fine-grained categories. However, ticket data is often complex and poses several unique challenges for modern machine learning methods: (1) tickets are created and updated either by machines with pre-defined algorithms or by engineers with domain expertise that share different protocols, (2) tickets receive frequent revisions that update ticket status by modifying all or parts of ticket descriptions, and (3) ticket labeling is time-sensitive and requires knowledge updates and new labels per the rapid software and hardware improvement lifecycle. To handle these issues, we introduce Ticket- BERT which trains a simple yet robust language model for labeling tickets using our proposed ticket datasets. Experiments demonstrate the superiority of Ticket-BERT over baselines and state-of-the-art text classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT with an active le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29983;&#25104;&#25551;&#36848;&#19981;&#21516;&#24615;&#21035;&#35748;&#21516;&#30340;&#20154;&#30340;&#25991;&#26412;&#26102;&#20135;&#29983;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#21457;&#29616;&#23384;&#22312;&#23545;&#21516;&#24535;&#20154;&#32676;&#30340;&#20559;&#35265;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SHAP&#20998;&#26512;&#30340;&#24605;&#32500;&#38142;&#35302;&#21457;&#30340;&#20107;&#21518;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#21152;&#21477;&#23376;&#30340;regard&#65292;&#20026;&#21435;&#38500;LLMs&#36755;&#20986;&#20559;&#35265;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2307.00101</link><description>&lt;p&gt;
&#21516;&#24535;&#20154;&#32676;&#39318;&#20808;&#26159;&#20154;&#65306;&#35299;&#26500;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#35748;&#21516;&#21051;&#26495;&#21360;&#35937;
&lt;/p&gt;
&lt;p&gt;
Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models. (arXiv:2307.00101v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#29983;&#25104;&#25551;&#36848;&#19981;&#21516;&#24615;&#21035;&#35748;&#21516;&#30340;&#20154;&#30340;&#25991;&#26412;&#26102;&#20135;&#29983;&#30340;&#20559;&#35265;&#38382;&#39064;&#65292;&#21457;&#29616;&#23384;&#22312;&#23545;&#21516;&#24535;&#20154;&#32676;&#30340;&#20559;&#35265;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SHAP&#20998;&#26512;&#30340;&#24605;&#32500;&#38142;&#35302;&#21457;&#30340;&#20107;&#21518;&#26041;&#27861;&#65292;&#21487;&#20197;&#22686;&#21152;&#21477;&#23376;&#30340;regard&#65292;&#20026;&#21435;&#38500;LLMs&#36755;&#20986;&#20559;&#35265;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20027;&#35201;&#22312;&#32463;&#36807;&#26368;&#23567;&#21270;&#22788;&#29702;&#30340;&#32593;&#32476;&#25991;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#36825;&#20123;&#25991;&#26412;&#23637;&#29616;&#20102;&#21019;&#24314;&#35813;&#20869;&#23481;&#30340;&#20154;&#20204;&#25152;&#25345;&#26377;&#30340;&#21508;&#31181;&#31038;&#20250;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;LLMs&#29983;&#25104;&#30340;&#25991;&#26412;&#21487;&#33021;&#26080;&#24847;&#20013;&#23558;&#21051;&#26495;&#21360;&#35937;&#20256;&#36882;&#32473;&#36793;&#32536;&#21270;&#32676;&#20307;&#65292;&#22914;LGBTQIA+&#31038;&#32676;&#12290;&#26412;&#25991;&#23545;LLMs&#29983;&#25104;&#25551;&#36848;&#20855;&#26377;&#19981;&#21516;&#24615;&#21035;&#35748;&#21516;&#30340;&#20154;&#30340;&#25991;&#26412;&#36827;&#34892;&#20102;&#27604;&#36739;&#30740;&#31350;&#12290;&#20351;&#29992;regard&#20998;&#25968;&#20998;&#26512;&#25991;&#26412;&#20013;&#30340;&#20559;&#35265;&#26174;&#31034;&#20986;&#23384;&#22312;&#23545;&#21516;&#24535;&#20154;&#32676;&#30340;&#21487;&#27979;&#37327;&#20559;&#35265;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110;SHAP&#20998;&#26512;&#30340;&#24605;&#32500;&#38142;&#35302;&#21457;&#30340;&#20107;&#21518;&#26041;&#27861;&#21487;&#20197;&#22686;&#21152;&#21477;&#23376;&#30340;regard&#65292;&#36825;&#20195;&#34920;&#20102;&#35299;&#20915;&#27492;&#31867;&#24773;&#20917;&#19979;LLMs&#36755;&#20986;&#20559;&#35265;&#30340;&#19968;&#20010;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#29942;&#39048;&#23398;&#20064;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25991;&#26412;&#34920;&#31034;&#29305;&#24449;&#30340;&#35270;&#35273;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#20998;&#31867;ImageNet&#22270;&#20687;&#65292;&#21487;&#20197;&#22686;&#21152;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00028</link><description>&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#29942;&#39048;&#23398;&#20064;&#20998;&#31867;&#30340;&#8220;&#30475;&#35265;&#25991;&#23383;&#8221;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Seeing in Words: Learning to Classify through Language Bottlenecks. (arXiv:2307.00028v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#29942;&#39048;&#23398;&#20064;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25991;&#26412;&#34920;&#31034;&#29305;&#24449;&#30340;&#35270;&#35273;&#27169;&#22411;&#33021;&#22815;&#26377;&#25928;&#20998;&#31867;ImageNet&#22270;&#20687;&#65292;&#21487;&#20197;&#22686;&#21152;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#35745;&#31639;&#26426;&#35270;&#35273;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#23427;&#20204;&#25552;&#21462;&#30340;&#29305;&#24449;&#24448;&#24448;&#26159;&#26080;&#27861;&#35299;&#37322;&#30340;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20154;&#31867;&#21487;&#20197;&#29992;&#31616;&#27905;&#30452;&#35266;&#30340;&#25551;&#36848;&#26469;&#35299;&#37322;&#20182;&#20204;&#30340;&#39044;&#27979;&#12290;&#20026;&#20102;&#23558;&#21487;&#35299;&#37322;&#24615;&#24341;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#23558;&#29305;&#24449;&#34920;&#31034;&#20026;&#25991;&#26412;&#30340;&#35270;&#35273;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#26679;&#30340;&#27169;&#22411;&#22312;&#23545;ImageNet&#22270;&#20687;&#36827;&#34892;&#20998;&#31867;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#25105;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks for computer vision extract uninterpretable features despite achieving high accuracy on benchmarks. In contrast, humans can explain their predictions using succinct and intuitive descriptions. To incorporate explainability into neural networks, we train a vision model whose feature representations are text. We show that such a model can effectively classify ImageNet images, and we discuss the challenges we encountered when training it.
&lt;/p&gt;</description></item><item><title>SAHAAYAK 2023&#26159;&#19968;&#20010;&#21253;&#21547;&#22810;&#20010;&#39046;&#22495;&#25968;&#25454;&#30340;&#26805;&#35821;&#21040;&#21360;&#22320;&#35821;&#30340;&#22823;&#35268;&#27169;&#21452;&#35821;&#24179;&#34892;&#35821;&#26009;&#24211;&#65292;&#35813;&#35821;&#26009;&#24211;&#36890;&#36807;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#21046;&#20316;&#65292;&#23558;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#24179;&#34913;&#24615;&#30340;&#25968;&#25454;&#32435;&#20837;&#20854;&#20013;&#65292;&#24182;&#24212;&#29992;&#20102;&#24191;&#27867;&#30340;&#25366;&#25496;&#21644;&#28165;&#27927;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2307.00021</link><description>&lt;p&gt;
SAHAAYAK 2023 -- &#22810;&#39046;&#22495;&#26805;&#35821;&#21040;&#21360;&#22320;&#35821;&#26426;&#22120;&#32763;&#35793;&#24179;&#34892;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit to Hindi for Machine Translation. (arXiv:2307.00021v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00021
&lt;/p&gt;
&lt;p&gt;
SAHAAYAK 2023&#26159;&#19968;&#20010;&#21253;&#21547;&#22810;&#20010;&#39046;&#22495;&#25968;&#25454;&#30340;&#26805;&#35821;&#21040;&#21360;&#22320;&#35821;&#30340;&#22823;&#35268;&#27169;&#21452;&#35821;&#24179;&#34892;&#35821;&#26009;&#24211;&#65292;&#35813;&#35821;&#26009;&#24211;&#36890;&#36807;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#21046;&#20316;&#65292;&#23558;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#24179;&#34913;&#24615;&#30340;&#25968;&#25454;&#32435;&#20837;&#20854;&#20013;&#65292;&#24182;&#24212;&#29992;&#20102;&#24191;&#27867;&#30340;&#25366;&#25496;&#21644;&#28165;&#27927;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#25968;&#25454;&#25991;&#31456;&#20171;&#32461;&#20102;&#19968;&#31181;&#22823;&#22411;&#31232;&#32570;&#35821;&#35328;&#23545;&#26805;&#35821;-&#21360;&#22320;&#35821;&#30340;&#21452;&#35821;&#24179;&#34892;&#35821;&#26009;&#24211;&#65292;&#21517;&#20026;SAHAAYAK 2023&#12290;&#35813;&#35821;&#26009;&#24211;&#21253;&#21547;&#20102;150&#19975;&#20010;&#26805;&#35821;&#21644;&#21360;&#22320;&#35821;&#20043;&#38388;&#30340;&#21477;&#23376;&#23545;&#12290;&#20026;&#20102;&#20351;&#35813;&#35821;&#26009;&#24211;&#20855;&#26377;&#26222;&#36866;&#24615;&#24182;&#20445;&#25345;&#24179;&#34913;&#65292;&#25105;&#20204;&#23558;&#26469;&#33258;&#22810;&#20010;&#39046;&#22495;&#30340;&#25968;&#25454;&#32435;&#20837;&#20102;&#35813;&#35821;&#26009;&#24211;&#20013;&#65292;&#21253;&#25324;&#26032;&#38395;&#12289;&#26085;&#24120;&#23545;&#35805;&#12289;&#25919;&#27835;&#12289;&#21382;&#21490;&#12289;&#20307;&#32946;&#21644;&#21476;&#20195;&#21360;&#24230;&#25991;&#23398;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#65292;&#20197;&#21046;&#20316;&#19968;&#31181;&#35268;&#27169;&#21487;&#35266;&#30340;&#26805;&#35821;&#31561;&#31232;&#32570;&#35821;&#35328;&#30340;&#22810;&#39046;&#22495;&#35821;&#26009;&#24211;&#12290;&#25105;&#20204;&#30340;&#24320;&#21457;&#26041;&#27861;&#20174;&#21019;&#24314;&#19968;&#20010;&#23567;&#22411;&#25163;&#24037;&#25968;&#25454;&#38598;&#24320;&#22987;&#65292;&#28982;&#21518;&#24212;&#29992;&#20102;&#24191;&#27867;&#30340;&#25366;&#25496;&#12289;&#28165;&#27927;&#21644;&#39564;&#35777;&#25216;&#26415;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19977;&#37325;&#25366;&#25496;&#36807;&#31243;&#65306;&#20174;&#26426;&#22120;&#21487;&#35835;&#28304;&#20013;&#25366;&#25496;&#12289;&#20174;&#38750;&#26426;&#22120;&#21487;&#35835;&#28304;&#20013;&#25366;&#25496;&#20197;&#21450;&#20174;&#29616;&#26377;&#35821;&#26009;&#24211;&#28304;&#20013;&#25972;&#29702;&#12290;&#22312;&#25366;&#25496;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19987;&#29992;&#30340;&#26631;&#20934;&#21270;&#12289;&#23545;&#40784;&#21644;&#35821;&#26009;&#24211;&#28165;&#27927;&#27969;&#31243;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#35813;&#35821;&#26009;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
The data article presents the large bilingual parallel corpus of low-resourced language pair Sanskrit-Hindi, named SAHAAYAK 2023. The corpus contains total of 1.5M sentence pairs between Sanskrit and Hindi. To make the universal usability of the corpus and to make it balanced, data from multiple domain has been incorporated into the corpus that includes, News, Daily conversations, Politics, History, Sport, and Ancient Indian Literature. The multifaceted approach has been adapted to make a sizable multi-domain corpus of low-resourced languages like Sanskrit. Our development approach is spanned from creating a small hand-crafted dataset to applying a wide range of mining, cleaning, and verification. We have used the three-fold process of mining: mining from machine-readable sources, mining from non-machine readable sources, and collation from existing corpora sources. Post mining, the dedicated pipeline for normalization, alignment, and corpus cleaning is developed and applied to the cor
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#20998;&#37197;&#21644;&#20998;&#31867;&#36719;&#20214;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#35821;&#35328;&#29305;&#24449;&#21644;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#38382;&#39064;&#20998;&#37197;&#32473;&#26368;&#30456;&#20851;&#30340;&#22242;&#38431;&#25104;&#21592;&#65292;&#24182;&#23558;&#20854;&#20998;&#31867;&#20026;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#20197;&#25552;&#39640;&#24037;&#20316;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00009</link><description>&lt;p&gt;
&#33258;&#21160;&#20998;&#37197;&#21644;&#20998;&#31867;&#36719;&#20214;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Automated Assignment and Classification of Software Issues. (arXiv:2307.00009v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00009
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#20998;&#37197;&#21644;&#20998;&#31867;&#36719;&#20214;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#35821;&#35328;&#29305;&#24449;&#21644;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#38382;&#39064;&#20998;&#37197;&#32473;&#26368;&#30456;&#20851;&#30340;&#22242;&#38431;&#25104;&#21592;&#65292;&#24182;&#23558;&#20854;&#20998;&#31867;&#20026;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#20197;&#25552;&#39640;&#24037;&#20316;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36719;&#20214;&#38382;&#39064;&#21253;&#21547;&#20462;&#22797;&#12289;&#25913;&#36827;&#25110;&#21019;&#24314;&#26032;&#32447;&#31243;&#30340;&#24037;&#20316;&#21333;&#20803;&#65292;&#22312;&#24320;&#21457;&#36807;&#31243;&#20013;&#20419;&#36827;&#22242;&#38431;&#25104;&#21592;&#20043;&#38388;&#30340;&#27807;&#36890;&#12290;&#23558;&#38382;&#39064;&#20998;&#37197;&#32473;&#26368;&#30456;&#20851;&#30340;&#22242;&#38431;&#25104;&#21592;&#24182;&#30830;&#23450;&#38382;&#39064;&#30340;&#31867;&#21035;&#26159;&#19968;&#39033;&#32321;&#29712;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#38169;&#35823;&#30340;&#20998;&#31867;&#20250;&#23548;&#33268;&#39033;&#30446;&#24310;&#36831;&#21644;&#37325;&#26032;&#24037;&#20316;&#65292;&#32473;&#22242;&#38431;&#25104;&#21592;&#24102;&#26469;&#40635;&#28902;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#32452;&#32463;&#36807;&#31934;&#24515;&#31574;&#21010;&#30340;&#29992;&#20110;&#27973;&#23618;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#35821;&#35328;&#29305;&#24449;&#65292;&#24182;&#23558;&#27973;&#23618;&#26041;&#27861;&#21644;&#38598;&#25104;&#26041;&#27861;&#19982;&#28145;&#24230;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#19982;&#29616;&#26377;&#25216;&#26415;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#20998;&#37197;&#32473;&#22235;&#31181;&#35282;&#33394;&#65288;&#35774;&#35745;&#24072;&#12289;&#24320;&#21457;&#20154;&#21592;&#12289;&#27979;&#35797;&#20154;&#21592;&#21644;&#39046;&#23548;&#32773;&#65289;&#65292;&#32780;&#19981;&#26159;&#29305;&#23450;&#30340;&#20010;&#20154;&#25110;&#22242;&#38431;&#65292;&#20197;&#20419;&#36827;&#25105;&#20204;&#35299;&#20915;&#26041;&#26696;&#30340;&#26222;&#36941;&#24615;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#24320;&#21457;&#20154;&#21592;&#30340;&#32463;&#39564;&#27700;&#24179;&#65292;&#20197;&#21453;&#26144;&#25105;&#20204;&#35299;&#20915;&#26041;&#26696;&#30340;&#24037;&#19994;&#23454;&#36341;&#12290;&#25105;&#20204;&#37319;&#29992;&#20998;&#31867;&#26041;&#27861;&#23558;&#38382;&#39064;&#20998;&#31867;&#20026;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#21253;&#25324;&#38169;&#35823;&#12289;&#26032;&#21151;&#33021;&#12289;&#25913;&#36827;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Software issues contain units of work to fix, improve or create new threads during the development and facilitate communication among the team members. Assigning an issue to the most relevant team member and determining a category of an issue is a tedious and challenging task. Wrong classifications cause delays and rework in the project and trouble among the team members. This thesis proposes a set of carefully curated linguistic features for shallow machine learning methods and compares the performance of shallow and ensemble methods with deep language models. Unlike the state-of-the-art, we assign issues to four roles (designer, developer, tester, and leader) rather than to specific individuals or teams to contribute to the generality of our solution. We also consider the level of experience of the developers to reflect the industrial practices in our solution formulation. We employ a classification approach to categorize issues into distinct classes, namely bug, new feature, improve
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22522;&#20110;&#25513;&#30721;&#30340;&#25968;&#25454;&#29983;&#25104;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00008</link><description>&lt;p&gt;
&#25506;&#32034;&#22522;&#20110;&#25513;&#30721;&#30340;&#25968;&#25454;&#29983;&#25104;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Investigating Masking-based Data Generation in Language Models. (arXiv:2307.00008v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22522;&#20110;&#25513;&#30721;&#30340;&#25968;&#25454;&#29983;&#25104;&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;BERT&#38382;&#19990;&#20197;&#26469;&#65292;&#24403;&#21069;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#26102;&#20195;&#24050;&#32463;&#34987;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#25152;&#23450;&#20041;&#12290;BERT&#21644;&#31867;&#20284;&#32467;&#26500;&#30340;&#27169;&#22411;&#30340;&#19968;&#20010;&#29305;&#28857;&#26159;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#30340;&#30446;&#26631;&#65292;&#20854;&#20013;&#37096;&#20998;&#36755;&#20837;&#34987;&#26377;&#24847;&#22320;&#25513;&#30422;&#65292;&#27169;&#22411;&#34987;&#35757;&#32451;&#20197;&#39044;&#27979;&#36825;&#37096;&#20998;&#34987;&#25513;&#30721;&#30340;&#20449;&#24687;&#12290;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#25216;&#26415;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#65292;&#21253;&#25324;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#30740;&#31350;&#39046;&#22495;&#65292;&#36890;&#36807;&#25351;&#23450;&#30340;&#25216;&#26415;&#20154;&#24037;&#22686;&#21152;&#35757;&#32451;&#25968;&#25454;&#38598;&#20197;&#25913;&#21892;&#27169;&#22411;&#24615;&#33021;&#12290;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65288;MLM&#65289;&#26159;BERT&#30340;&#19968;&#20010;&#37325;&#35201;&#35757;&#32451;&#29305;&#28857;&#65292;&#23427;&#20026;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21033;&#29992;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#20154;&#24037;&#22686;&#24378;&#25968;&#25454;&#29992;&#20110;NLP&#19979;&#28216;&#20219;&#21153;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#25513;&#30721;&#30340;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The current era of natural language processing (NLP) has been defined by the prominence of pre-trained language models since the advent of BERT. A feature of BERT and models with similar architecture is the objective of masked language modeling, in which part of the input is intentionally masked and the model is trained to predict this piece of masked information. Data augmentation is a data-driven technique widely used in machine learning, including research areas like computer vision and natural language processing, to improve model performance by artificially augmenting the training data set by designated techniques. Masked language models (MLM), an essential training feature of BERT, have introduced a novel approach to perform effective pre-training on Transformer based models in natural language processing tasks. Recent studies have utilized masked language model to generate artificially augmented data for NLP downstream tasks. The experimental results show that Mask based data au
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;SPAE&#65292;&#20351;&#29992;&#35821;&#20041;&#37329;&#23383;&#22612;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#20923;&#32467;LLM&#25191;&#34892;&#28041;&#21450;&#38750;&#35821;&#35328;&#27169;&#24577;&#30340;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#12290;&#36890;&#36807;&#23558;&#22270;&#20687;&#36716;&#21270;&#20026;LLM&#21487;&#29702;&#35299;&#30340;&#35789;&#27719;&#26631;&#35760;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#25552;&#21319;&#20102;&#20923;&#32467;LLM&#22312;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#25216;&#26415;25%&#20197;&#19978;&#12290;</title><link>http://arxiv.org/abs/2306.17842</link><description>&lt;p&gt;
SPAE: &#22522;&#20110;&#35821;&#20041;&#37329;&#23383;&#22612;&#33258;&#32534;&#30721;&#22120;&#30340;&#20923;&#32467;LLM&#30340;&#22810;&#27169;&#24577;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs. (arXiv:2306.17842v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;SPAE&#65292;&#20351;&#29992;&#35821;&#20041;&#37329;&#23383;&#22612;&#33258;&#32534;&#30721;&#22120;&#23454;&#29616;&#20102;&#20923;&#32467;LLM&#25191;&#34892;&#28041;&#21450;&#38750;&#35821;&#35328;&#27169;&#24577;&#30340;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#12290;&#36890;&#36807;&#23558;&#22270;&#20687;&#36716;&#21270;&#20026;LLM&#21487;&#29702;&#35299;&#30340;&#35789;&#27719;&#26631;&#35760;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#25552;&#21319;&#20102;&#20923;&#32467;LLM&#22312;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#65292;&#36229;&#36807;&#20102;&#29616;&#26377;&#25216;&#26415;25%&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;Semantic Pyramid AutoEncoder (SPAE)&#65292;&#20351;&#20923;&#32467;&#30340;LLM&#33021;&#22815;&#25191;&#34892;&#28041;&#21450;&#38750;&#35821;&#35328;&#27169;&#24577;&#65288;&#22914;&#22270;&#20687;&#25110;&#35270;&#39057;&#65289;&#30340;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#12290;SPAE&#22312;&#21407;&#22987;&#20687;&#32032;&#21644;&#20174;LLM&#35789;&#27719;&#34920;&#20013;&#25552;&#21462;&#30340;&#21487;&#35299;&#37322;&#30340;&#35789;&#27719;&#26631;&#35760;&#65288;&#25110;&#21333;&#35789;&#65289;&#20043;&#38388;&#36827;&#34892;&#36716;&#25442;&#12290;&#29983;&#25104;&#30340;&#26631;&#35760;&#25429;&#25417;&#20102;&#35270;&#35273;&#37325;&#24314;&#25152;&#38656;&#30340;&#35821;&#20041;&#21547;&#20041;&#21644;&#32454;&#31890;&#24230;&#32454;&#33410;&#65292;&#23558;&#35270;&#35273;&#20869;&#23481;&#36716;&#21270;&#20026;LLM&#33021;&#29702;&#35299;&#30340;&#35821;&#35328;&#65292;&#24182;&#20351;&#20854;&#33021;&#22815;&#25191;&#34892;&#21508;&#31181;&#22810;&#27169;&#24577;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#22810;&#26679;&#21270;&#30340;&#22270;&#20687;&#29702;&#35299;&#21644;&#29983;&#25104;&#20219;&#21153;&#19978;&#65292;&#19982;&#20923;&#32467;&#30340;PaLM 2&#21644;GPT 3.5&#36827;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#39564;&#35777;&#23454;&#12290;&#22312;&#30456;&#21516;&#30340;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#31532;&#19968;&#20010;&#25104;&#21151;&#20351;&#20923;&#32467;LLM&#29983;&#25104;&#22270;&#20687;&#20869;&#23481;&#65292;&#24182;&#22312;&#22270;&#20687;&#29702;&#35299;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#36229;&#36807;&#29616;&#26377;&#25216;&#26415;25%&#20197;&#19978;&#30340;&#23581;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.
&lt;/p&gt;</description></item><item><title>Statler&#26159;&#19968;&#20010;&#20026;LLMs&#36171;&#20104;&#20102;&#26126;&#30830;&#30340;&#12289;&#32500;&#25345;&#29366;&#24577;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#35299;&#20915;&#24403;&#20195;LLMs&#22312;&#38271;&#26102;&#38388;&#33539;&#22260;&#20869;&#25512;&#29702;&#30340;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2306.17840</link><description>&lt;p&gt;
Statler&#65306;&#29992;&#20110;&#20855;&#36523;&#25512;&#29702;&#30340;&#20445;&#25345;&#29366;&#24577;&#30340;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17840
&lt;/p&gt;
&lt;p&gt;
Statler&#26159;&#19968;&#20010;&#20026;LLMs&#36171;&#20104;&#20102;&#26126;&#30830;&#30340;&#12289;&#32500;&#25345;&#29366;&#24577;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#35299;&#20915;&#24403;&#20195;LLMs&#22312;&#38271;&#26102;&#38388;&#33539;&#22260;&#20869;&#25512;&#29702;&#30340;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20026;&#26426;&#22120;&#20154;&#25191;&#34892;&#22797;&#26434;&#30340;&#26426;&#22120;&#20154;&#25512;&#29702;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#24403;&#20195;LLMs&#30340;&#26377;&#38480;&#19978;&#19979;&#25991;&#31383;&#21475;&#20351;&#24471;&#22312;&#38271;&#26102;&#38388;&#33539;&#22260;&#20869;&#36827;&#34892;&#25512;&#29702;&#21464;&#24471;&#22256;&#38590;&#12290;&#20855;&#36523;&#20219;&#21153;&#65288;&#20363;&#22914;&#25105;&#20204;&#26399;&#26395;&#19968;&#20010;&#23478;&#24237;&#26426;&#22120;&#20154;&#25191;&#34892;&#30340;&#20219;&#21153;&#65289;&#36890;&#24120;&#38656;&#35201;&#35268;&#21010;&#32773;&#32771;&#34385;&#24456;&#20037;&#20043;&#21069;&#33719;&#24471;&#30340;&#20449;&#24687;&#65288;&#20363;&#22914;&#65292;&#26426;&#22120;&#20154;&#22312;&#29615;&#22659;&#20013;&#36935;&#21040;&#30340;&#35768;&#22810;&#23545;&#35937;&#30340;&#23646;&#24615;&#65289;&#12290;&#36890;&#36807;LLM&#30340;&#38544;&#21547;&#20869;&#37096;&#34920;&#31034;&#26469;&#25429;&#33719;&#19990;&#30028;&#29366;&#24577;&#30340;&#23581;&#35797;&#20250;&#22240;&#20026;&#26426;&#22120;&#20154;&#25805;&#20316;&#21382;&#21490;&#20013;&#21487;&#29992;&#30340;&#19982;&#20219;&#21153;&#21644;&#29615;&#22659;&#30456;&#20851;&#30340;&#20449;&#24687;&#26377;&#38480;&#32780;&#21464;&#24471;&#22797;&#26434;&#65292;&#32780;&#20381;&#36182;&#36890;&#36807;&#25552;&#31034;&#21521;LLM&#20256;&#36882;&#20449;&#24687;&#30340;&#26041;&#27861;&#21017;&#21463;&#20854;&#26377;&#38480;&#30340;&#19978;&#19979;&#25991;&#31383;&#21475;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Statler&#65292;&#19968;&#20010;&#20026;LLMs&#36171;&#20104;&#20102;&#26126;&#30830;&#30340;&#12289;&#20316;&#20026;&#8220;&#35760;&#24518;&#8221;&#30340;&#19990;&#30028;&#29366;&#24577;&#34920;&#31034;&#30340;&#26694;&#26550;&#65292;&#36825;&#31181;&#35760;&#24518;&#38543;&#26102;&#38388;&#20445;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) provide a promising tool that enable robots to perform complex robot reasoning tasks. However, the limited context window of contemporary LLMs makes reasoning over long time horizons difficult. Embodied tasks such as those that one might expect a household robot to perform typically require that the planner consider information acquired a long time ago (e.g., properties of the many objects that the robot previously encountered in the environment). Attempts to capture the world state using an LLM's implicit internal representation is complicated by the paucity of task- and environment-relevant information available in a robot's action history, while methods that rely on the ability to convey information via the prompt to the LLM are subject to its limited context window. In this paper, we propose Statler, a framework that endows LLMs with an explicit representation of the world state as a form of ``memory'' that is maintained over time. Integral to Statler i
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#30340;&#28176;&#36827;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;ProTEC&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#24341;&#23548;&#27169;&#22411;&#20174;&#26131;&#21040;&#38590;&#22320;&#23398;&#20064;&#38169;&#35823;&#26816;&#27979;&#12289;&#38169;&#35823;&#31867;&#22411;&#35782;&#21035;&#21644;&#26657;&#27491;&#32467;&#26524;&#29983;&#25104;&#65292;&#20197;&#35299;&#20915;&#36807;&#32416;&#27491;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.17447</link><description>&lt;p&gt;
&#38754;&#21521;&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#30340;&#28176;&#36827;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17447
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#30340;&#28176;&#36827;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;ProTEC&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#24341;&#23548;&#27169;&#22411;&#20174;&#26131;&#21040;&#38590;&#22320;&#23398;&#20064;&#38169;&#35823;&#26816;&#27979;&#12289;&#38169;&#35823;&#31867;&#22411;&#35782;&#21035;&#21644;&#26657;&#27491;&#32467;&#26524;&#29983;&#25104;&#65292;&#20197;&#35299;&#20915;&#36807;&#32416;&#27491;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#26088;&#22312;&#26816;&#27979;&#21644;&#32416;&#27491;&#36755;&#20837;&#25991;&#26412;&#20013;&#30340;&#38169;&#35823;&#65292;&#36825;&#26377;&#30410;&#20110;&#20154;&#31867;&#26085;&#24120;&#29983;&#27963;&#21644;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#12290;&#36817;&#26399;&#30340;&#26041;&#27861;&#20027;&#35201;&#37319;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;(PLM)&#26469;&#35299;&#20915;&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#20219;&#21153;&#65292;&#24182;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#26041;&#27861;&#23384;&#22312;&#36807;&#32416;&#27491;&#21644;&#27424;&#32416;&#27491;&#30340;&#38382;&#39064;&#65292;&#21069;&#32773;&#22312;&#23545;&#31934;&#30830;&#24615;&#35201;&#27714;&#36739;&#39640;&#30340;&#20013;&#25991;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#20219;&#21153;&#20013;&#23588;&#20026;&#26126;&#26174;&#12290;&#20026;&#20102;&#32531;&#35299;&#36807;&#32416;&#27491;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#28176;&#36827;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21629;&#21517;&#20026;ProTEC&#65292;&#23427;&#24341;&#23548;&#19968;&#20010;CTEC&#27169;&#22411;&#20174;&#31616;&#21333;&#21040;&#22256;&#38590;&#22320;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#23558;CTEC&#20219;&#21153;&#20998;&#20026;&#19977;&#20010;&#23376;&#20219;&#21153;&#65292;&#20174;&#26131;&#21040;&#38590;&#20998;&#21035;&#20026;&#38169;&#35823;&#26816;&#27979;&#12289;&#38169;&#35823;&#31867;&#22411;&#35782;&#21035;&#21644;&#26657;&#27491;&#32467;&#26524;&#29983;&#25104;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;ProTEC&#23558;&#36825;&#20123;&#23376;&#20219;&#21153;&#32435;&#20837;&#22810;&#20219;&#21153;&#35757;&#32451;&#30446;&#26631;&#65292;&#24341;&#23548;&#27169;&#22411;&#36880;&#28176;&#23398;&#20064;&#25991;&#26412;&#38169;&#35823;&#26657;&#27491;&#12290;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#65292;&#27169;&#22411;&#21017;...
&lt;/p&gt;
&lt;p&gt;
Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human's daily life and various downstream tasks. Recent approaches mainly employ Pre-trained Language Models (PLMs) to resolve CTEC task and achieve tremendous success. However, previous approaches suffer from issues of over-correction and under-correction, and the former is especially conspicuous in the precision-critical CTEC task. To mitigate the issue of overcorrection, we propose a novel model-agnostic progressive multitask learning framework for CTEC, named ProTEC, which guides a CTEC model to learn the task from easy to difficult. We divide CTEC task into three sub-tasks from easy to difficult: Error Detection, Error Type Identification, and Correction Result Generation. During the training process, ProTEC guides the model to learn text error correction progressively by incorporating these sub-tasks into a multi-task training objective. During the inference process, the model
&lt;/p&gt;</description></item><item><title>LMBot&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;&#26694;&#26550;&#65292;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30693;&#35782;&#34701;&#20837;&#21040;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#20102;&#26080;&#22270;&#24418;&#37096;&#32626;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#20381;&#36182;&#24615;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2306.17408</link><description>&lt;p&gt;
LMBot: &#23558;&#22270;&#24418;&#30693;&#35782;&#34701;&#20837;&#35821;&#35328;&#27169;&#22411;&#20197;&#36827;&#34892;&#26080;&#22270;&#24418;&#37096;&#32626;&#30340;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17408
&lt;/p&gt;
&lt;p&gt;
LMBot&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;&#26694;&#26550;&#65292;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#30693;&#35782;&#34701;&#20837;&#21040;&#35821;&#35328;&#27169;&#22411;&#20013;&#65292;&#23454;&#29616;&#20102;&#26080;&#22270;&#24418;&#37096;&#32626;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#20381;&#36182;&#24615;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24694;&#24847;&#34892;&#20026;&#32773;&#20351;&#29992;&#36234;&#26469;&#36234;&#20808;&#36827;&#21644;&#24191;&#27867;&#30340;&#26426;&#22120;&#20154;&#26469;&#20256;&#25773;&#38169;&#35823;&#20449;&#24687;&#21644;&#25805;&#32437;&#33286;&#35770;&#65292;&#25512;&#29305;&#26426;&#22120;&#20154;&#30340;&#26816;&#27979;&#24050;&#25104;&#20026;&#19968;&#39033;&#33267;&#20851;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#23613;&#31649;&#22522;&#20110;&#22270;&#24418;&#30340;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#23427;&#20204;&#30340;&#25512;&#29702;&#20381;&#36182;&#20110;&#36317;&#31163;&#30446;&#26631;&#29992;&#25143;&#22810;&#36339;&#30340;&#37051;&#23621;&#29992;&#25143;&#65292;&#24182;&#19988;&#33719;&#21462;&#37051;&#23621;&#29992;&#25143;&#26159;&#32791;&#26102;&#30340;&#65292;&#24182;&#21487;&#33021;&#24341;&#20837;&#20559;&#24046;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;&#19978;&#24494;&#35843;&#21518;&#65292;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#31454;&#20105;&#24615;&#24615;&#33021;&#26041;&#38754;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#22312;&#37096;&#32626;&#36807;&#31243;&#20013;&#19981;&#38656;&#35201;&#22270;&#24418;&#32467;&#26500;&#12290;&#21463;&#21040;&#36825;&#19968;&#21457;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#20154;&#26816;&#27979;&#26694;&#26550;LMBot&#65292;&#23427;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#30340;&#30693;&#35782;&#34701;&#20837;&#35821;&#35328;&#27169;&#22411;(LMs)&#65292;&#20197;&#22312;&#25512;&#29305;&#26426;&#22120;&#20154;&#26816;&#27979;&#20013;&#36827;&#34892;&#26080;&#22270;&#24418;&#37096;&#32626;&#65292;&#20197;&#24212;&#23545;&#25968;&#25454;&#20381;&#36182;&#24615;&#30340;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;LMBot&#23545;&#22522;&#20110;&#22270;&#24418;&#21644;&#19981;&#20351;&#29992;&#22270;&#24418;&#30340;&#25968;&#25454;&#38598;&#20860;&#23481;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#27599;&#20010;&#29992;&#25143;&#34920;&#31034;&#20026;&#19968;&#27573;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#26435;&#33014;&#22218;&#32593;&#32476;&#30340;&#38463;&#25289;&#20271;&#35821;&#21644;&#27874;&#26031;&#35821;&#22810;&#39046;&#22495;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#21333;&#29420;&#30340;&#33014;&#22218;&#32593;&#32476;&#24182;&#20351;&#29992;&#21152;&#26435;&#24230;&#37327;&#26469;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.17068</link><description>&lt;p&gt;
&#22522;&#20110;&#21152;&#26435;CapsuleNet&#32593;&#32476;&#30340;&#38463;&#25289;&#20271;&#35821;&#21644;&#27874;&#26031;&#35821;&#22810;&#39046;&#22495;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis. (arXiv:2306.17068v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#26435;&#33014;&#22218;&#32593;&#32476;&#30340;&#38463;&#25289;&#20271;&#35821;&#21644;&#27874;&#26031;&#35821;&#22810;&#39046;&#22495;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#21333;&#29420;&#30340;&#33014;&#22218;&#32593;&#32476;&#24182;&#20351;&#29992;&#21152;&#26435;&#24230;&#37327;&#26469;&#23454;&#29616;&#24773;&#24863;&#20998;&#31867;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#24863;&#20998;&#31867;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#23545;&#33258;&#30001;&#25991;&#26412;&#36827;&#34892;&#27491;&#38754;&#12289;&#36127;&#38754;&#25110;&#20013;&#24615;&#30340;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#24773;&#24863;&#20998;&#31867;&#27169;&#22411;&#39640;&#24230;&#20381;&#36182;&#20110;&#39046;&#22495;&#65292;&#20998;&#31867;&#22120;&#22312;&#19968;&#20010;&#39046;&#22495;&#20013;&#21487;&#33021;&#20855;&#26377;&#21512;&#29702;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#22312;&#21478;&#19968;&#20010;&#39046;&#22495;&#20013;&#30001;&#20110;&#35789;&#35821;&#30340;&#35821;&#20041;&#22810;&#37325;&#24615;&#32780;&#20934;&#30830;&#29575;&#36739;&#20302;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27874;&#26031;&#35821;/&#38463;&#25289;&#20271;&#35821;&#22810;&#39046;&#22495;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#20351;&#29992;&#32047;&#31215;&#21152;&#26435;&#33014;&#22218;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#21152;&#26435;&#33014;&#22218;&#38598;&#21512;&#30001;&#20026;&#27599;&#20010;&#39046;&#22495;&#35757;&#32451;&#30340;&#21333;&#29420;&#30340;&#33014;&#22218;&#32593;&#32476;&#21644;&#31216;&#20026;&#39046;&#22495;&#25152;&#23646;&#24230;&#65288;DBD&#65289;&#30340;&#21152;&#26435;&#24230;&#37327;&#32452;&#25104;&#12290;&#36825;&#20010;&#24230;&#37327;&#30001;TF&#21644;IDF&#32452;&#25104;&#65292;&#35745;&#31639;&#27599;&#20010;&#25991;&#26723;&#23545;&#20110;&#27599;&#20010;&#39046;&#22495;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#28982;&#21518;&#20056;&#20197;&#27599;&#20010;&#33014;&#22218;&#21019;&#24314;&#30340;&#21487;&#33021;&#36755;&#20986;&#12290;&#26368;&#32456;&#65292;&#36825;&#20123;&#20056;&#31215;&#30340;&#24635;&#21644;&#26159;&#26368;&#32456;&#36755;&#20986;&#30340;&#26631;&#31614;&#65292;&#24182;&#29992;&#20110;&#30830;&#23450;&#26497;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#30340;&#26377;&#25928;&#24615;&#21644;&#27010;&#29575;&#35821;&#35328;&#30693;&#35782;&#30340;&#20316;&#29992;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#30740;&#31350;&#30340;&#20116;&#31181;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#25216;&#26415;&#22312;&#35821;&#35328;&#35780;&#20272;&#29615;&#22659;&#19979;&#19981;&#20855;&#22791;&#26222;&#36941;&#26377;&#25928;&#24615;&#65292;&#32780;&#19988;&#19982;&#19981;&#21516;&#20998;&#31867;&#27169;&#22411;&#31867;&#22411;&#26080;&#20851;&#12290;</title><link>http://arxiv.org/abs/2306.16644</link><description>&lt;p&gt;
&#27010;&#29575;&#35821;&#35328;&#30693;&#35782;&#19982;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16644
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#30340;&#26377;&#25928;&#24615;&#21644;&#27010;&#29575;&#35821;&#35328;&#30693;&#35782;&#30340;&#20316;&#29992;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#30740;&#31350;&#30340;&#20116;&#31181;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#25216;&#26415;&#22312;&#35821;&#35328;&#35780;&#20272;&#29615;&#22659;&#19979;&#19981;&#20855;&#22791;&#26222;&#36941;&#26377;&#25928;&#24615;&#65292;&#32780;&#19988;&#19982;&#19981;&#21516;&#20998;&#31867;&#27169;&#22411;&#31867;&#22411;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#23398;&#39537;&#21160;&#30340;&#35780;&#20272;&#29615;&#22659;&#19979;&#65292;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#27010;&#29575;&#35821;&#35328;&#30693;&#35782;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#20010;&#25991;&#26412;&#22686;&#24378;&#31243;&#24207;REDA&#21644;REDA$_{NG}$&#65292;&#23427;&#20204;&#37117;&#23454;&#29616;&#20102;&#20116;&#31181;&#26631;&#35760;&#32423;&#25991;&#26412;&#32534;&#36753;&#25805;&#20316;&#65306;&#21516;&#20041;&#35789;&#26367;&#25442;(SR)&#12289;&#38543;&#26426;&#20132;&#25442;(RS)&#12289;&#38543;&#26426;&#25554;&#20837;(RI)&#12289;&#38543;&#26426;&#21024;&#38500;(RD)&#21644;&#38543;&#26426;&#28151;&#21512;(RM)&#12290;REDA$_{NG}$&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;n-gram&#35821;&#35328;&#27169;&#22411;&#20174;REDA&#30340;&#36755;&#20986;&#20013;&#36873;&#25321;&#26368;&#21487;&#33021;&#30340;&#22686;&#24378;&#25991;&#26412;&#12290;&#25105;&#20204;&#23545;&#20013;&#25991;&#21644;&#33521;&#25991;&#30340;&#20108;&#20803;&#38382;&#39064;&#21305;&#37197;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#20102;&#20840;&#38754;&#21644;&#32454;&#33268;&#30340;&#23454;&#39564;&#12290;&#32467;&#26524;&#24378;&#28872;&#21542;&#23450;&#20102;&#25152;&#30740;&#31350;&#30340;&#20116;&#31181;&#26631;&#35760;&#32423;&#25991;&#26412;&#22686;&#24378;&#25216;&#26415;&#30340;&#26222;&#36941;&#26377;&#25928;&#24615;&#65292;&#26080;&#35770;&#26159;&#21516;&#26102;&#24212;&#29992;&#36824;&#26159;&#20998;&#21035;&#24212;&#29992;&#65292;&#20063;&#26080;&#35770;&#20351;&#29992;&#20102;&#21738;&#31181;&#24120;&#35265;&#30340;&#20998;&#31867;&#27169;&#22411;&#31867;&#22411;&#65292;&#21253;&#25324;transformers&#12290;&#27492;&#22806;&#65292;&#27010;&#29575;&#35821;&#35328;&#30693;&#35782;&#30340;&#20316;&#29992;&#26159;...
&lt;/p&gt;
&lt;p&gt;
This paper investigates the effectiveness of token-level text augmentation and the role of probabilistic linguistic knowledge within a linguistically-motivated evaluation context. Two text augmentation programs, REDA and REDA$_{NG}$, were developed, both implementing five token-level text editing operations: Synonym Replacement (SR), Random Swap (RS), Random Insertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$ leverages pretrained $n$-gram language models to select the most likely augmented texts from REDA's output. Comprehensive and fine-grained experiments were conducted on a binary question matching classification task in both Chinese and English. The results strongly refute the general effectiveness of the five token-level text augmentation techniques under investigation, whether applied together or separately, and irrespective of various common classification model types used, including transformers. Furthermore, the role of probabilistic linguistic knowledge is 
&lt;/p&gt;</description></item><item><title>SparseOptimizer&#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;Moreau-Yosida&#27491;&#21017;&#21270;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24341;&#20837;&#31232;&#30095;&#24615;&#12290;&#23427;&#37319;&#29992;&#23884;&#20837;&#30340;&#25910;&#32553;&#25805;&#20316;&#31526;&#65292;&#26080;&#38656;&#23545;&#20195;&#30721;&#36827;&#34892;&#20462;&#25913;&#21363;&#21487;&#36866;&#24212;&#21508;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#23494;&#38598;&#22411;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.15656</link><description>&lt;p&gt;
SparseOptimizer: &#36890;&#36807;Moreau-Yosida&#27491;&#21017;&#21270;&#26469;&#38477;&#20302;&#35821;&#35328;&#27169;&#22411;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#36890;&#36807;&#32534;&#35793;&#22120;&#20849;&#21516;&#35774;&#35745;&#26469;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate through Compiler Co-design. (arXiv:2306.15656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15656
&lt;/p&gt;
&lt;p&gt;
SparseOptimizer&#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;Moreau-Yosida&#27491;&#21017;&#21270;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#24341;&#20837;&#31232;&#30095;&#24615;&#12290;&#23427;&#37319;&#29992;&#23884;&#20837;&#30340;&#25910;&#32553;&#25805;&#20316;&#31526;&#65292;&#26080;&#38656;&#23545;&#20195;&#30721;&#36827;&#34892;&#20462;&#25913;&#21363;&#21487;&#36866;&#24212;&#21508;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#19982;&#23494;&#38598;&#22411;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;SparseOptimizer&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;Moreau-Yosida&#27491;&#21017;&#21270;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;BERT&#65292;ALBERT&#21644;GPT&#65289;&#20013;&#33258;&#28982;&#22320;&#24341;&#20837;&#31232;&#30095;&#24615;&#12290;SparseOptimizer&#35774;&#35745;&#30340;&#20851;&#38190;&#26159;&#23884;&#20837;&#30340;&#25910;&#32553;&#25805;&#20316;&#31526;&#65292;&#23427;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#30452;&#25509;&#24341;&#20837;&#31232;&#30095;&#24615;&#12290;&#36825;&#20010;&#25805;&#20316;&#31526;&#36890;&#36807;&#22362;&#23454;&#30340;&#29702;&#35770;&#26694;&#26550;&#25903;&#25345;&#65292;&#24182;&#21253;&#21547;&#20102;&#19968;&#20010;&#20998;&#26512;&#35299;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#20248;&#21270;&#22120;&#30340;&#40065;&#26834;&#24615;&#21644;&#25928;&#26524;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;SparseOptimizer&#30340;&#21363;&#25554;&#21363;&#29992;&#21151;&#33021;&#28040;&#38500;&#20102;&#23545;&#20195;&#30721;&#20462;&#25913;&#30340;&#38656;&#27714;&#65292;&#20351;&#20854;&#25104;&#20026;&#36866;&#29992;&#20110;&#21508;&#31181;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#36866;&#24212;&#24037;&#20855;&#12290;&#22312;GLUE&#12289;RACE&#12289;SQuAD1&#21644;SQuAD2&#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#36890;&#36807;SparseOptimizer&#31232;&#30095;&#21270;&#21518;&#30340;SparseBERT&#21644;SparseALBERT&#22312;&#24615;&#33021;&#19978;&#19982;&#23494;&#38598;&#22411;&#30340;BERT&#21644;ALBERT&#30456;&#24403;&#65292;&#21516;&#26102;&#26174;&#33879;&#20943;&#23569;&#20102;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovati
&lt;/p&gt;</description></item><item><title>MindDial&#26159;&#19968;&#20010;&#20351;&#29992;&#24515;&#26234;&#27169;&#25311;&#36827;&#34892;&#20449;&#24565;&#21160;&#24577;&#36319;&#36394;&#30340;&#23545;&#35805;&#29983;&#25104;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22330;&#26223;&#21270;&#29615;&#22659;&#20013;&#29983;&#25104;&#33258;&#30001;&#23545;&#35805;&#26469;&#21327;&#21830;&#20849;&#35782;&#12290;</title><link>http://arxiv.org/abs/2306.15253</link><description>&lt;p&gt;
MindDial: &#24102;&#26377;&#24515;&#26234;&#27169;&#25311;&#30340;&#20449;&#24565;&#21160;&#24577;&#36319;&#36394;&#29992;&#20110;&#22330;&#26223;&#21270;&#31070;&#32463;&#23545;&#35805;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation. (arXiv:2306.15253v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15253
&lt;/p&gt;
&lt;p&gt;
MindDial&#26159;&#19968;&#20010;&#20351;&#29992;&#24515;&#26234;&#27169;&#25311;&#36827;&#34892;&#20449;&#24565;&#21160;&#24577;&#36319;&#36394;&#30340;&#23545;&#35805;&#29983;&#25104;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22330;&#26223;&#21270;&#29615;&#22659;&#20013;&#29983;&#25104;&#33258;&#30001;&#23545;&#35805;&#26469;&#21327;&#21830;&#20849;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#22312;&#20132;&#27969;&#20013;&#33258;&#30001;&#34920;&#36798;&#24847;&#20041;&#25110;&#20849;&#35782;&#30340;&#21516;&#26102;&#36827;&#34892;&#23545;&#35805;&#12290;&#23613;&#31649;&#22823;&#22411;&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#23545;&#35805;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#24182;&#26410;&#32771;&#34385;&#21040;&#20849;&#20139;&#30340;&#22330;&#26223;&#29615;&#22659;&#20013;&#20010;&#20307;&#30340;&#19978;&#19979;&#25991;&#29702;&#35299;&#24046;&#24322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;MindDial&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#35805;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#22330;&#26223;&#21270;&#30340;&#33258;&#30001;&#23545;&#35805;&#26469;&#21327;&#21830;&#20849;&#35782;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#24515;&#26234;&#27169;&#22359;&#65292;&#21487;&#20197;&#36861;&#36394;&#19977;&#20010;&#23618;&#27425;&#30340;&#20449;&#24565;&#65292;&#21363;&#35828;&#35805;&#32773;&#30340;&#20449;&#24565;&#12289;&#35828;&#35805;&#32773;&#23545;&#21548;&#20247;&#20449;&#24565;&#30340;&#39044;&#27979;&#20197;&#21450;&#22522;&#20110;&#21069;&#20004;&#32773;&#20043;&#38388;&#30340;&#20849;&#21516;&#20449;&#24565;&#12290;&#28982;&#21518;&#65292;&#35828;&#35805;&#34892;&#20026;&#20998;&#31867;&#22836;&#23558;&#20915;&#23450;&#26159;&#21542;&#32487;&#32493;&#23545;&#35805;&#12289;&#32467;&#26463;&#27492;&#36718;&#23545;&#35805;&#25110;&#37319;&#21462;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#34892;&#21160;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#20849;&#35782;&#23545;&#40784;&#30340;&#25968;&#25454;&#38598;MutualFriend&#65292;&#22686;&#21152;&#20102;&#20449;&#24565;&#21160;&#24577;&#27880;&#37322;&#65292;&#30446;&#26631;&#26159;&#26681;&#25454;&#20004;&#20010;&#20195;&#29702;&#20043;&#38388;&#30340;&#33258;&#30001;&#23545;&#35805;&#25214;&#21040;&#19968;&#20010;&#20849;&#21516;&#30340;&#26379;&#21451;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#24515;&#26234;&#29366;&#24577;&#24314;&#27169;&#26041;&#38754;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Humans talk in free-form while negotiating the expressed meanings or common ground. Despite the impressive conversational abilities of the large generative language models, they do not consider the individual differences in contextual understanding in a shared situated environment. In this work, we propose MindDial, a novel conversational framework that can generate situated free-form responses to negotiate common ground. We design an explicit mind module that can track three-level beliefs -- the speaker's belief, the speaker's prediction of the listener's belief, and the common belief based on the gap between the first two. Then the speaking act classification head will decide to continue to talk, end this turn, or take task-related action. We augment a common ground alignment dataset MutualFriend with belief dynamics annotation, of which the goal is to find a single mutual friend based on the free chat between two agents. Experiments show that our model with mental state modeling can
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#22312;&#28151;&#21512;&#20854;&#20182;&#25991;&#26412;&#26469;&#28304;&#26102;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2306.04634</link><description>&lt;p&gt;
&#35770;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#30340;&#21487;&#38752;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27700;&#21360;&#22312;&#28151;&#21512;&#20854;&#20182;&#25991;&#26412;&#26469;&#28304;&#26102;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#32463;&#24320;&#22987;&#24212;&#29992;&#20110;&#26085;&#24120;&#20351;&#29992;&#65292;&#24182;&#26377;&#33021;&#21147;&#22312;&#26410;&#26469;&#30340;&#21313;&#24180;&#20869;&#20135;&#29983;&#22823;&#37327;&#30340;&#25991;&#26412;&#12290;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#21487;&#33021;&#20250;&#21462;&#20195;&#20114;&#32852;&#32593;&#19978;&#30340;&#20154;&#31867;&#20889;&#20316;&#25991;&#26412;&#65292;&#24182;&#26377;&#21487;&#33021;&#34987;&#29992;&#20110;&#24694;&#24847;&#30446;&#30340;&#65292;&#22914;&#38035;&#40060;&#25915;&#20987;&#21644;&#31038;&#20132;&#23186;&#20307;&#26426;&#22120;&#20154;&#12290;&#27700;&#21360;&#26159;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#21487;&#26816;&#27979;&#21644;&#21487;&#35760;&#24405;&#65292;&#26469;&#38477;&#20302;&#36825;&#20123;&#20260;&#23475;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#22312;&#29616;&#23454;&#20013;&#28151;&#21512;&#20102;&#20854;&#20182;&#30340;&#25991;&#26412;&#26469;&#28304;&#65292;&#34987;&#20154;&#31867;&#20889;&#20316;&#32773;&#25110;&#20854;&#20182;&#35821;&#35328;&#27169;&#22411;&#25913;&#20889;&#65292;&#34987;&#29992;&#20110;&#31038;&#20132;&#21644;&#25216;&#26415;&#39046;&#22495;&#30340;&#21508;&#31181;&#24212;&#29992;&#26102;&#65292;&#27700;&#21360;&#22312;&#23454;&#38469;&#35774;&#32622;&#20013;&#30340;&#21487;&#38752;&#24615;&#22914;&#20309;&#65311;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19981;&#21516;&#30340;&#26816;&#27979;&#26041;&#26696;&#65292;&#37327;&#21270;&#20102;&#23427;&#20204;&#26816;&#27979;&#27700;&#21360;&#30340;&#33021;&#21147;&#65292;&#24182;&#30830;&#23450;&#22312;&#27599;&#20010;&#24773;&#20917;&#19979;&#38656;&#35201;&#35266;&#23519;&#22810;&#23569;&#26426;&#22120;&#29983;&#25104;&#30340;&#25991;&#26412;&#25165;&#33021;&#21487;&#38752;&#22320;&#26816;&#27979;&#27700;&#21360;&#12290;&#25105;&#20204;&#29305;&#21035;&#24378;&#35843;&#20102;&#24403;&#27700;&#21360;&#19982;&#20854;&#20182;&#25991;&#26412;&#26469;&#28304;&#28151;&#21512;&#26102;&#27700;&#21360;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#26410;&#26469;&#20351;&#29992;LLM&#29983;&#25104;&#30340;&#25991;&#26412;&#27700;&#21360;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are now deployed to everyday use and positioned to produce large quantities of text in the coming decade. Machine-generated text may displace human-written text on the internet and has the potential to be used for malicious purposes, such as spearphishing attacks and social media bots. Watermarking is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet, a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text might be mixed with other text sources, paraphrased by human writers or other language models, and used for applications in a broad number of domains, both social and technical. In this paper, we explore different detection schemes, quantify their power at detecting watermarks, and determine how much machine-generated text needs to be observed in each scenario to reliably detect the watermark. We especially highlight o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;LLM-Blender&#65292;&#23427;&#26159;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19981;&#21516;&#30340;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#31168;&#29305;&#24615;&#65292;&#23454;&#29616;&#22987;&#32456;&#22914;&#19968;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;PairRanker&#21644;GenFuser&#26159;&#35813;&#26694;&#26550;&#30340;&#20004;&#20010;&#27169;&#22359;&#65292;PairRanker&#20351;&#29992;&#25104;&#23545;&#27604;&#36739;&#26041;&#27861;&#26469;&#21306;&#20998;&#20505;&#36873;&#36755;&#20986;&#65292;&#24182;&#19988;GenFuser&#26088;&#22312;&#21512;&#24182;&#25490;&#21517;&#26368;&#39640;&#30340;&#20505;&#36873;&#32773;&#65292;&#20197;&#29983;&#25104;&#25913;&#36827;&#30340;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2306.02561</link><description>&lt;p&gt;
LLM-Blender: &#21033;&#29992;&#25104;&#23545;&#25490;&#21517;&#21644;&#29983;&#25104;&#34701;&#21512;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;LLM-Blender&#65292;&#23427;&#26159;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#21033;&#29992;&#19981;&#21516;&#30340;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20248;&#31168;&#29305;&#24615;&#65292;&#23454;&#29616;&#22987;&#32456;&#22914;&#19968;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;PairRanker&#21644;GenFuser&#26159;&#35813;&#26694;&#26550;&#30340;&#20004;&#20010;&#27169;&#22359;&#65292;PairRanker&#20351;&#29992;&#25104;&#23545;&#27604;&#36739;&#26041;&#27861;&#26469;&#21306;&#20998;&#20505;&#36873;&#36755;&#20986;&#65292;&#24182;&#19988;GenFuser&#26088;&#22312;&#21512;&#24182;&#25490;&#21517;&#26368;&#39640;&#30340;&#20505;&#36873;&#32773;&#65292;&#20197;&#29983;&#25104;&#25913;&#36827;&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;LLM-Blender&#65292;&#19968;&#20010;&#38598;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24320;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#19981;&#21516;&#20248;&#21183;&#26469;&#36798;&#21040;&#22987;&#32456;&#22914;&#19968;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30001;&#20004;&#20010;&#27169;&#22359;&#32452;&#25104;&#65306;PairRanker&#21644;GenFuser&#65292;&#20197;&#24212;&#23545;&#19981;&#21516;&#31034;&#20363;&#30340;&#26368;&#20248;LLMs&#21487;&#20197;&#26174;&#30528;&#21464;&#21270;&#30340;&#35266;&#23519;&#12290;PairRanker&#20351;&#29992;&#19987;&#38376;&#30340;&#25104;&#23545;&#27604;&#36739;&#26041;&#27861;&#26469;&#21306;&#20998;&#20505;&#36873;&#36755;&#20986;&#20043;&#38388;&#30340;&#24494;&#23567;&#24046;&#24322;&#12290;&#23427;&#32852;&#21512;&#32534;&#30721;&#36755;&#20837;&#25991;&#26412;&#21644;&#19968;&#23545;&#20505;&#36873;&#32773;&#65292;&#20351;&#29992;&#20132;&#21449;&#27880;&#24847;&#32534;&#30721;&#22120;&#26469;&#30830;&#23450;&#20248;&#36234;&#32773;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;PairRanker&#19982;ChatGPT&#30340;&#25490;&#21517;&#30456;&#20851;&#24615;&#26368;&#39640;&#12290;&#28982;&#21518;&#65292;GenFuser&#26088;&#22312;&#21512;&#24182;&#25490;&#21517;&#26368;&#39640;&#30340;&#20505;&#36873;&#32773;&#65292;&#36890;&#36807;&#21033;&#29992;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#20943;&#23569;&#23427;&#20204;&#30340;&#24369;&#28857;&#26469;&#29983;&#25104;&#25913;&#36827;&#30340;&#36755;&#20986;&#12290;&#20026;&#20102;&#20419;&#36827;&#22823;&#35268;&#27169;&#35780;&#20272;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;MixInstruct&#65292;&#23427;&#26159;&#22810;&#20010;&#25351;&#20196;&#25968;&#25454;&#38598;&#30340;&#28151;&#21512;&#65292;&#20855;&#26377;oracle p&#12290;
&lt;/p&gt;
&lt;p&gt;
We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#33258;&#28982;&#39046;&#22495;&#36716;&#31227;&#35774;&#32622;&#19979;&#24494;&#35843;&#21644;&#23567;&#26679;&#26412;&#23398;&#20064;&#27169;&#22411;&#30340;DR&#25361;&#25112;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;DR&#22522;&#20934;&#65292;&#25552;&#20986;&#20102;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#28304;&#22495;&#38477;&#20302;&#65288;SD&#65289;&#21644;&#30446;&#26631;&#22495;&#38477;&#20302;&#65288;TD&#65289;&#65292;&#24182;&#21457;&#29616;&#20004;&#32773;&#20043;&#19968;&#36890;&#24120;&#26159;&#27491;&#20540;&#65292;&#24378;&#35843;&#20102;&#35780;&#20272;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.00168</link><description>&lt;p&gt;
&#34913;&#37327;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#38754;&#23545;&#39046;&#22495;&#36716;&#31227;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#33258;&#28982;&#39046;&#22495;&#36716;&#31227;&#35774;&#32622;&#19979;&#24494;&#35843;&#21644;&#23567;&#26679;&#26412;&#23398;&#20064;&#27169;&#22411;&#30340;DR&#25361;&#25112;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;DR&#22522;&#20934;&#65292;&#25552;&#20986;&#20102;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#28304;&#22495;&#38477;&#20302;&#65288;SD&#65289;&#21644;&#30446;&#26631;&#22495;&#38477;&#20302;&#65288;TD&#65289;&#65292;&#24182;&#21457;&#29616;&#20004;&#32773;&#20043;&#19968;&#36890;&#24120;&#26159;&#27491;&#20540;&#65292;&#24378;&#35843;&#20102;&#35780;&#20272;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#20102;&#24456;&#22909;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#24494;&#35843;&#12289;&#23567;&#26679;&#26412;&#23398;&#20064;&#21644;&#38646;&#26679;&#26412;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#27809;&#26377;&#26631;&#35760;&#25968;&#25454;&#30340;&#39046;&#22495;&#20013;&#30340;&#24615;&#33021;&#20173;&#28982;&#33853;&#21518;&#20110;&#26377;&#26631;&#35760;&#25968;&#25454;&#30340;&#39046;&#22495;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#39046;&#22495;&#40065;&#26834;&#24615;&#65288;DR&#65289;&#25361;&#25112;&#12290;&#29616;&#26377;&#30340;DR&#30740;&#31350;&#23384;&#22312;&#19981;&#19968;&#33268;&#30340;&#35774;&#32622;&#12289;&#32570;&#20047;&#35780;&#20272;&#20219;&#21153;&#30340;&#22810;&#26679;&#24615;&#21644;&#36807;&#22810;&#20381;&#38752;&#25361;&#25112;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#33258;&#28982;&#39046;&#22495;&#36716;&#31227;&#35774;&#32622;&#19979;&#24494;&#35843;&#21644;&#23567;&#26679;&#26412;&#23398;&#20064;&#27169;&#22411;&#30340;DR&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;DR&#22522;&#20934;&#65292;&#21253;&#25324;&#22810;&#26679;&#21270;&#30340;NLP&#20219;&#21153;&#65292;&#21253;&#25324;&#21477;&#23376;&#21644;&#26631;&#35760;&#32423;&#20998;&#31867;&#12289;&#38382;&#31572;&#21644;&#29983;&#25104;&#65292;&#27599;&#20010;&#20219;&#21153;&#37117;&#30001;&#20960;&#20010;&#39046;&#22495;&#32452;&#25104;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#28304;&#22495;&#38477;&#20302;&#65288;SD&#65289;&#21644;&#30446;&#26631;&#22495;&#38477;&#20302;&#65288;TD&#65289;&#65292;&#23427;&#20204;&#20132;&#26367;&#20316;&#20026;&#21442;&#32771;&#28857;&#26469;&#27604;&#36739;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#37325;&#22823;&#27604;&#20363;&#30340;&#39046;&#22495;&#36716;&#31227;&#20013;&#65292;SD&#25110;TD&#20043;&#19968;&#26159;&#27491;&#30340;&#65292;&#20294;&#19981;&#26159;&#20004;&#32773;&#37117;&#27491;&#65292;&#24378;&#35843;&#20102;&#35780;&#20272;DR&#25361;&#25112;&#30340;&#20004;&#20010;&#35270;&#35282;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#30340;&#22522;&#20934;&#20801;&#35768;&#22312;&#27169;&#22411;&#12289;&#20219;&#21153;&#21644;&#35774;&#32622;&#19978;&#20844;&#24179;&#27604;&#36739;DR&#65292;&#24182;&#25552;&#20379;&#26377;&#20851;NLP&#27169;&#22411;DR&#24615;&#36136;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models have shown promising performance on various tasks, including fine-tuning, few-shot learning, and zero-shot learning. However, their performance on domains without labeled data still lags behind those with labeled data, which we refer as the Domain Robustness (DR) challenge. Existing research on DR suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we explore the DR challenge of both fine-tuned and few-shot learning models in natural domain shift settings. We introduce a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We propose two views of the DR challenge: Source Drop (SD) and Target Drop (TD), which alternate between the source and target in-domain performance as reference points. We find that in significant proportions of domain shifts, either SD or TD is positive, but not both, emphasizing the imp
&lt;/p&gt;</description></item><item><title>W-procer&#26159;&#19968;&#31181;&#22522;&#20110;&#21152;&#26435;&#21407;&#22411;&#23545;&#27604;&#23398;&#20064;&#30340;&#21307;&#23398;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26041;&#27861;&#65292;&#22312;&#26500;&#24314;&#22522;&#20110;&#21407;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#21644;&#21152;&#26435;&#32593;&#32476;&#26041;&#38754;&#20855;&#26377;&#21019;&#26032;&#24615;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.18624</link><description>&lt;p&gt;
W-procer: &#22522;&#20110;&#21152;&#26435;&#21407;&#22411;&#23545;&#27604;&#23398;&#20064;&#30340;&#21307;&#23398;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18624
&lt;/p&gt;
&lt;p&gt;
W-procer&#26159;&#19968;&#31181;&#22522;&#20110;&#21152;&#26435;&#21407;&#22411;&#23545;&#27604;&#23398;&#20064;&#30340;&#21307;&#23398;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#26041;&#27861;&#65292;&#22312;&#26500;&#24314;&#22522;&#20110;&#21407;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#21644;&#21152;&#26435;&#32593;&#32476;&#26041;&#38754;&#20855;&#26377;&#21019;&#26032;&#24615;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#24050;&#25104;&#20026;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#65288;NER&#65289;&#30340;&#19968;&#31181;&#21463;&#27426;&#36814;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20256;&#32479;&#37197;&#32622;&#21147;&#27714;&#20943;&#23569;&#20855;&#26377;&#30456;&#21516;&#26631;&#31614;&#30340;&#26631;&#35760;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#24182;&#22686;&#21152;&#20855;&#26377;&#19981;&#21516;&#26631;&#31614;&#30340;&#26631;&#35760;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#22312;&#21307;&#23398;&#39046;&#22495;&#20013;&#23384;&#22312;&#22823;&#37327;&#34987;&#27880;&#37322;&#20026;&#8220;O&#8221;&#65288;&#21363;&#8220;OUTSIDE&#8221;&#65289;&#30340;&#23454;&#20307;&#65292;&#24182;&#19988;&#23427;&#20204;&#19981;&#24076;&#26395;&#34987;&#25512;&#31163;&#21040;&#24403;&#21069;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#26631;&#35760;&#20026;&#8220;O&#8221;&#20197;&#22806;&#30340;&#20854;&#20182;&#23454;&#20307;&#65292;&#36825;&#31181;&#35774;&#23450;&#25928;&#26524;&#19981;&#20339;&#65292;&#21487;&#33021;&#20250;&#24471;&#20986;&#21547;&#26377;&#22122;&#22768;&#21407;&#22411;&#26631;&#31614;&#30340;&#35821;&#20041;&#34920;&#31034;&#65292;&#23613;&#31649;&#23384;&#22312;&#35768;&#22810;&#8220;O&#8221;&#26631;&#31614;&#23454;&#20307;&#19982;&#26377;&#26631;&#31614;&#23454;&#20307;&#30456;&#20851;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21307;&#23398;&#23569;&#26679;&#26412;&#21629;&#21517;&#23454;&#20307;&#35782;&#21035;&#20013;&#22522;&#20110;&#21152;&#26435;&#21407;&#22411;&#30340;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65288;W-PROCER&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20027;&#35201;&#22260;&#32469;&#26500;&#24314;&#22522;&#20110;&#21407;&#22411;&#30340;&#23545;&#27604;&#25439;&#22833;&#21644;&#21152;&#26435;&#32593;&#32476;&#23637;&#24320;&#12290;&#36825;&#20123;&#32452;&#20214;&#22312;&#21327;&#21161;&#22312;&#21307;&#23398;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#38754;&#21457;&#25381;&#20102;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23558;W-PROCER&#24212;&#29992;&#20110;&#19968;&#20010;&#20844;&#20849;&#30340;&#21307;&#23398;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#20248;&#24322;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning has become a popular solution for few-shot Name Entity Recognization (NER). The conventional configuration strives to reduce the distance between tokens with the same labels and increase the distance between tokens with different labels. The effect of this setup may, however, in the medical domain, there are a lot of entities annotated as OUTSIDE (O), and they are undesirably pushed apart to other entities that are not labeled as OUTSIDE (O) by the current contrastive learning method end up with a noisy prototype for the semantic representation of the label, though there are many OUTSIDE (O) labeled entities are relevant to the labeled entities. To address this challenge, we propose a novel method named Weighted Prototypical Contrastive Learning for Medical Few Shot Named Entity Recognization (W-PROCER). Our approach primarily revolves around constructing the prototype-based contractive loss and weighting network. These components play a crucial role in assisting t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#28216;&#25103;&#25151;&#38388;&#65292;&#22312;&#20165;&#26377;&#23569;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#29983;&#25104;&#22810;&#36798;37%&#30340;&#21487;&#29609;&#26032;&#39062;&#20851;&#21345;&#65292;&#35813;&#25216;&#26415;&#26377;&#21161;&#20110;&#35299;&#20915;&#21253;&#21547;&#35768;&#22810;&#23616;&#37096;&#21644;&#20840;&#23616;&#32422;&#26463;&#30340;PCG&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.18243</link><description>&lt;p&gt;
&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23454;&#29616;&#23454;&#29992;&#30340;PCG
&lt;/p&gt;
&lt;p&gt;
Practical PCG Through Large Language Models. (arXiv:2305.18243v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18243
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#28216;&#25103;&#25151;&#38388;&#65292;&#22312;&#20165;&#26377;&#23569;&#37327;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#29983;&#25104;&#22810;&#36798;37%&#30340;&#21487;&#29609;&#26032;&#39062;&#20851;&#21345;&#65292;&#35813;&#25216;&#26415;&#26377;&#21161;&#20110;&#35299;&#20915;&#21253;&#21547;&#35768;&#22810;&#23616;&#37096;&#21644;&#20840;&#23616;&#32422;&#26463;&#30340;PCG&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#20043;&#22806;&#30340;&#21508;&#31181;&#39046;&#22495;&#20013;&#38750;&#24120;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#22914;&#20309;&#20351;&#29992;LLMs&#20026;&#27491;&#22312;&#24320;&#21457;&#20013;&#30340;&#28216;&#25103;Metavoidal&#29983;&#25104;2D&#28216;&#25103;&#25151;&#38388;&#30340;&#23454;&#29992;&#26041;&#21521;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#21487;&#20197;&#36890;&#36807;&#20154;&#31867;&#21442;&#19982;&#30340;&#24494;&#35843;&#65292;&#21033;&#29992;GPT-3&#30340;&#33021;&#21147;&#65292;&#20165;&#20351;&#29992;60&#20010;&#25163;&#21160;&#35774;&#35745;&#30340;&#25151;&#38388;&#25968;&#25454;&#65292;&#22312;&#22797;&#26434;&#30340;&#28216;&#25103;&#22330;&#26223;&#19979;&#65292;&#29983;&#25104;37%&#30340;&#21487;&#29609;&#26032;&#39062;&#20851;&#21345;&#65292;&#36825;&#26159;&#38024;&#23545;&#23384;&#22312;&#22823;&#37327;&#23616;&#37096;&#21644;&#20840;&#23616;&#32422;&#26463;&#30340;PCG&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) have proven to be useful tools in various domains outside of the field of their inception, which was natural language processing. In this study, we provide practical directions on how to use LLMs to generate 2D-game rooms for an under-development game, named Metavoidal. Our technique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which allows our method to create 37% Playable-Novel levels from as scarce data as only 60 hand-designed rooms under a scenario of the non-trivial game, with respect to (Procedural Content Generation) PCG, that has a good amount of local and global constraints.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;1&#23618;Transformer&#22312;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;SGD&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#33258;&#25105;&#20851;&#27880;&#23618;&#20805;&#24403;&#20102;&#8220;&#21306;&#20998;&#24615;&#25195;&#25551;&#31639;&#27861;&#8221;&#65292;&#20174;&#32780;&#36880;&#27493;&#20851;&#27880;&#21040;&#30456;&#20851;&#26631;&#35760;&#24182;&#25490;&#38500;&#19981;&#30456;&#20851;&#30340;&#26631;&#35760;&#65292;&#24635;&#32467;&#30456;&#20851;&#20449;&#24687;&#22312;&#32534;&#30721;&#34920;&#31034;&#20013;&#12290;&#21516;&#26102;&#30740;&#31350;&#20102;&#26631;&#35760;&#39057;&#29575;&#12289;&#19978;&#19979;&#25991;&#21644;&#21021;&#22987;&#21270;&#33258;&#25105;&#20851;&#27880;&#23618;&#31561;&#23545;Transformer&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.16380</link><description>&lt;p&gt;
&#25195;&#25551;&#19982;&#25293;&#29031;&#65306;&#29702;&#35299;1&#23618;Transformer&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#21644;&#26631;&#35760;&#32452;&#25104;
&lt;/p&gt;
&lt;p&gt;
Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;1&#23618;Transformer&#22312;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;SGD&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#33258;&#25105;&#20851;&#27880;&#23618;&#20805;&#24403;&#20102;&#8220;&#21306;&#20998;&#24615;&#25195;&#25551;&#31639;&#27861;&#8221;&#65292;&#20174;&#32780;&#36880;&#27493;&#20851;&#27880;&#21040;&#30456;&#20851;&#26631;&#35760;&#24182;&#25490;&#38500;&#19981;&#30456;&#20851;&#30340;&#26631;&#35760;&#65292;&#24635;&#32467;&#30456;&#20851;&#20449;&#24687;&#22312;&#32534;&#30721;&#34920;&#31034;&#20013;&#12290;&#21516;&#26102;&#30740;&#31350;&#20102;&#26631;&#35760;&#39057;&#29575;&#12289;&#19978;&#19979;&#25991;&#21644;&#21021;&#22987;&#21270;&#33258;&#25105;&#20851;&#27880;&#23618;&#31561;&#23545;Transformer&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26550;&#26500;&#22312;&#22810;&#20010;&#30740;&#31350;&#39046;&#22495;&#34920;&#29616;&#20986;&#20102;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#24182;&#25104;&#20026;&#35768;&#22810;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#22522;&#30784;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#20854;&#22914;&#20309;&#24037;&#20316;&#30340;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#29305;&#21035;&#26159;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#39044;&#27979;&#24615;&#25439;&#22833;&#65292;&#34920;&#31034;&#22914;&#20309;&#20174;&#26799;&#24230;&#35757;&#32451;&#21160;&#24577;&#20013;&#20986;&#29616;&#20173;&#28982;&#26159;&#19968;&#20010;&#35868;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#38024;&#23545;&#20855;&#26377;&#19968;&#20010;&#33258;&#25105;&#20851;&#27880;&#23618;&#21644;&#19968;&#20010;&#35299;&#30721;&#22120;&#23618;&#30340;1&#23618;Transformer&#65292;&#25105;&#20204;&#20197;&#25968;&#23398;&#20005;&#35880;&#30340;&#26041;&#24335;&#20998;&#26512;&#20854;&#22312;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;SGD&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#25171;&#24320;&#20102;&#33258;&#25105;&#20851;&#27880;&#23618;&#32452;&#21512;&#36755;&#20837;&#26631;&#35760;&#30340;&#21160;&#24577;&#36807;&#31243;&#30340;&#40657;&#30418;&#23376;&#65292;&#24182;&#25581;&#31034;&#20102;&#24213;&#23618;&#24402;&#32435;&#20559;&#24046;&#30340;&#26412;&#36136;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#27809;&#26377;&#20301;&#32622;&#32534;&#30721;&#12289;&#38271;&#36755;&#20837;&#24207;&#21015;&#21644;&#35299;&#30721;&#22120;&#23618;&#23398;&#20064;&#36895;&#24230;&#24555;&#20110;&#33258;&#25105;&#20851;&#27880;&#23618;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#20851;&#27880;&#23618;&#20805;&#24403;&#20102;&#8220;&#21306;&#20998;&#24615;&#25195;&#25551;&#31639;&#27861;&#8221;&#65306;&#20174;&#22343;&#21248;&#27880;&#24847;&#21147;&#24320;&#22987;&#65292;&#23427;&#36880;&#28176;&#20851;&#27880;&#21040;&#30456;&#20851;&#26631;&#35760;&#65292;&#25490;&#38500;&#19981;&#30456;&#20851;&#30340;&#26631;&#35760;&#65292;&#30452;&#21040;&#25152;&#26377;&#30456;&#20851;&#20449;&#24687;&#34987;&#25195;&#25551;&#24182;&#24635;&#32467;&#22312;&#32534;&#30721;&#34920;&#31034;&#20013;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#26174;&#31034;&#20102;&#26631;&#35760;&#39057;&#29575;&#21644;&#19978;&#19979;&#25991;&#22914;&#20309;&#24433;&#21709;&#27880;&#24847;&#26435;&#37325;&#65292;&#20197;&#21450;&#33258;&#25105;&#20851;&#27880;&#23618;&#21021;&#22987;&#21270;&#22914;&#20309;&#24433;&#21709;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer architecture has shown impressive performance in multiple research domains and has become the backbone of many neural network models. However, there is limited understanding on how it works. In particular, with a simple predictive loss, how the representation emerges from the gradient \emph{training dynamics} remains a mystery. In this paper, for 1-layer transformer with one self-attention layer plus one decoder layer, we analyze its SGD training dynamics for the task of next token prediction in a mathematically rigorous manner. We open the black box of the dynamic process of how the self-attention layer combines input tokens, and reveal the nature of underlying inductive bias. More specifically, with the assumption (a) no positional encoding, (b) long input sequence, and (c) the decoder layer learns faster than the self-attention layer, we prove that self-attention acts as a \emph{discriminative scanning algorithm}: starting from uniform attention, it gradually attends mor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MERGE&#65292;&#19968;&#20010;&#22522;&#20110;Transformer&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#31169;&#26377;&#25991;&#26412;&#29983;&#25104;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MERGE&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;26.5&#20493;&#30340;&#21152;&#36895;&#21644;80%&#30340;&#36890;&#20449;&#23383;&#33410;&#25968;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2305.15769</link><description>&lt;p&gt;
MERGE: &#24555;&#36895;&#30340;&#31169;&#26377;&#25991;&#26412;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
MERGE: Fast Private Text Generation. (arXiv:2305.15769v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15769
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MERGE&#65292;&#19968;&#20010;&#22522;&#20110;Transformer&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#31169;&#26377;&#25991;&#26412;&#29983;&#25104;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;MERGE&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;26.5&#20493;&#30340;&#21152;&#36895;&#21644;80%&#30340;&#36890;&#20449;&#23383;&#33410;&#25968;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#20851;&#27880;NLP&#26381;&#21153;&#21644;Transformer&#27169;&#22411;&#30340;&#31169;&#26377;&#25512;&#29702;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20004;&#26041;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#20165;&#32771;&#34385;NLU&#22330;&#26223;&#65292;&#32780;&#25991;&#26412;&#29983;&#25104;&#30340;&#31169;&#26377;&#25512;&#29702;&#65292;&#22914;&#32763;&#35793;&#12289;&#23545;&#35805;&#21644;&#20195;&#30721;&#34917;&#20840;&#65292;&#20173;&#26410;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#23558;&#29616;&#26377;&#30340;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#36801;&#31227;&#21040;NLG&#27169;&#22411;&#26102;&#65292;&#24615;&#33021;&#34920;&#29616;&#24046;&#65292;&#32780;&#22312;&#35757;&#32451;&#38454;&#27573;&#21463;&#21040;&#25910;&#25947;&#38382;&#39064;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MERGE&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;Transformer&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#31169;&#26377;&#25991;&#26412;&#29983;&#25104;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;MERGE&#37325;&#29992;&#36755;&#20986;&#38544;&#34255;&#29366;&#24577;&#20316;&#20026;&#21333;&#35789;&#23884;&#20837;&#65292;&#20197;&#36339;&#36807;&#23884;&#20837;&#35745;&#31639;&#65292;&#24182;&#37325;&#26032;&#32452;&#32455;Transformer&#27169;&#22359;&#20013;&#30340;&#32447;&#24615;&#25805;&#20316;&#20197;&#21152;&#36895;&#21521;&#21069;&#36807;&#31243;&#12290;&#22522;&#20110;&#36825;&#20004;&#20010;&#20248;&#21270;&#65292;&#22823;&#37327;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#24207;&#21015;&#38271;&#24230;&#20026;512&#26102;&#65292;MERGE&#21487;&#23454;&#29616;26.5&#20493;&#30340;&#21152;&#36895;&#65292;&#24182;&#20943;&#23569;80\%&#30340;&#36890;&#20449;&#23383;&#33410;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen increasing concerns about the private inference of NLP services and Transformer models. However, existing two-party privacy-preserving methods solely consider NLU scenarios, while the private inference of text generation such as translation, dialogue, and code completion remains unsolved. Besides, while migrated to NLG models, existing privacy-preserving methods perform poorly in terms of inference speed, and suffer from the convergence problem during the training stage. To address these issues, we propose MERGE, a fast private text generation framework for Transformer-based language models. Specifically, MERGE reuse the output hidden state as the word embedding to bypass the embedding computation, and reorganize the linear operations in the Transformer module to accelerate the forward procedure. Based on these two optimizations, extensive experiments show that MERGE can achieve a 26.5x speedup under the sequence length 512, and reduce 80\% communication bytes, w
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26041;&#27861;&#65292;&#33258;&#21160;&#29983;&#25104;&#22810;&#20010;&#31867;&#20284;&#20110;&#22522;&#30784;&#25552;&#31034;&#30340;&#39640;&#36136;&#37327;&#25552;&#31034;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#36827;&#34892;&#25490;&#21517;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#25552;&#31034;&#30340;&#25200;&#21160;&#25935;&#24863;&#24615;&#65292;&#24182;&#22312;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15689</link><description>&lt;p&gt;
&#20811;&#26381;&#25552;&#31034;&#25200;&#21160;&#25935;&#24863;&#24615;&#30340;&#38646;&#26679;&#26412;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts. (arXiv:2305.15689v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#26041;&#27861;&#65292;&#33258;&#21160;&#29983;&#25104;&#22810;&#20010;&#31867;&#20284;&#20110;&#22522;&#30784;&#25552;&#31034;&#30340;&#39640;&#36136;&#37327;&#25552;&#31034;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#36827;&#34892;&#25490;&#21517;&#65292;&#20174;&#32780;&#20811;&#26381;&#20102;&#25552;&#31034;&#30340;&#25200;&#21160;&#25935;&#24863;&#24615;&#65292;&#24182;&#22312;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#33258;&#28982;&#35821;&#35328;&#25552;&#31034;&#21487;&#20197;&#24110;&#21161;&#21033;&#29992;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#23398;&#20064;&#30340;&#30693;&#35782;&#36827;&#34892;&#20108;&#20803;&#21477;&#32423;&#24773;&#24863;&#20998;&#31867;&#20219;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#23569;&#37327;&#26679;&#26412;&#23398;&#20064;&#35774;&#32622;&#65292;&#20351;&#29992;&#25163;&#21160;&#25110;&#33258;&#21160;&#29983;&#25104;&#30340;&#25552;&#31034;&#26469;&#24494;&#35843;&#24773;&#24863;&#20998;&#31867;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#23545;&#25152;&#20351;&#29992;&#25552;&#31034;&#30340;&#25200;&#21160;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#23569;&#37327;&#24102;&#26631;&#31614;&#23454;&#20363;&#36827;&#34892;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#21644;&#25552;&#31034;&#25490;&#24207;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22312;&#38646;&#26679;&#26412;&#35774;&#32622;&#20013;&#20026;&#25152;&#32473;&#23450;&#30340;&#20219;&#21153;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#25552;&#31034;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26041;&#27861;&#32473;&#23450;&#19968;&#20010;&#22522;&#30784;&#25552;&#31034;&#65292;&#37319;&#29992;&#20301;&#32622;&#12289;&#25512;&#29702;&#21644;&#37322;&#20041;&#25216;&#26415;&#33258;&#21160;&#29983;&#25104;&#22810;&#20010;&#31867;&#20284;&#20110;&#22522;&#30784;&#25552;&#31034;&#30340;&#25552;&#31034;&#65292;&#28982;&#21518;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#23545;&#25552;&#31034;&#36827;&#34892;&#25490;&#21517;&#12290;&#25105;&#20204;&#20174;&#23454;&#39564;&#19978;&#35777;&#26126;&#65292;&#25490;&#21517;&#38752;&#21069;&#30340;&#25552;&#31034;&#20855;&#26377;&#24456;&#39640;&#30340;&#36136;&#37327;&#65292;&#24182;&#22312;&#25552;&#31034;&#25200;&#21160;&#40065;&#26834;&#24615;&#21644;&#25972;&#20307;&#20934;&#30830;&#24615;&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#22522;&#30784;&#25552;&#31034;&#21644;&#20854;&#20182;&#29616;&#26377;&#30340;&#25552;&#31034;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have demonstrated that natural-language prompts can help to leverage the knowledge learned by pre-trained language models for the binary sentence-level sentiment classification task. Specifically, these methods utilize few-shot learning settings to fine-tune the sentiment classification model using manual or automatically generated prompts. However, the performance of these methods is sensitive to the perturbations of the utilized prompts. Furthermore, these methods depend on a few labeled instances for automatic prompt generation and prompt ranking. This study aims to find high-quality prompts for the given task in a zero-shot setting. Given a base prompt, our proposed approach automatically generates multiple prompts similar to the base prompt employing positional, reasoning, and paraphrasing techniques and then ranks the prompts using a novel metric. We empirically demonstrate that the top-ranked prompts are high-quality and significantly outperform the base prompt an
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65292;&#20294;&#30001;&#20110;LLMs&#21487;&#33021;&#23384;&#22312;&#31038;&#20250;&#20559;&#35265;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#27492;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#8212;&#8212;FaiRLLM&#65292;&#24182;&#38024;&#23545;&#38899;&#20048;&#21644;&#30005;&#24433;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.07609</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#20844;&#24179;&#21487;&#38752;&#65311;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#25512;&#33616;&#20013;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07609
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65292;&#20294;&#30001;&#20110;LLMs&#21487;&#33021;&#23384;&#22312;&#31038;&#20250;&#20559;&#35265;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#27492;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#8212;&#8212;FaiRLLM&#65292;&#24182;&#38024;&#23545;&#38899;&#20048;&#21644;&#30005;&#24433;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#26174;&#30528;&#25104;&#23601;&#23548;&#33268;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#33539;&#24335;&#8212;&#8212;&#36890;&#36807;LLM&#36827;&#34892;&#25512;&#33616;&#65288;RecLLM&#65289;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#27880;&#24847;LLMs&#21487;&#33021;&#21253;&#21547;&#31038;&#20250;&#20559;&#35265;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#19968;&#27493;&#35843;&#26597;RecLLM&#25152;&#20570;&#25512;&#33616;&#30340;&#20844;&#27491;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;RecLLM&#30340;&#28508;&#22312;&#39118;&#38505;&#65292;&#26377;&#24517;&#35201;&#20174;&#29992;&#25143;&#30340;&#21508;&#31181;&#25935;&#24863;&#23646;&#24615;&#35282;&#24230;&#35780;&#20272;RecLLM&#30340;&#20844;&#24179;&#24615;&#12290;&#30001;&#20110;RecLLM&#33539;&#24335;&#19982;&#20256;&#32479;&#25512;&#33616;&#33539;&#24335;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#65292;&#22240;&#27492;&#30452;&#25509;&#20351;&#29992;&#20256;&#32479;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#22522;&#20934;&#26159;&#26377;&#38382;&#39064;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#22256;&#22659;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#65292;&#31216;&#20026;&#8220;&#36890;&#36807;LLM&#30340;&#25512;&#33616;&#30340;&#20844;&#24179;&#24615;&#8221;&#65288;FaiRLLM&#65289;&#12290;&#35813;&#22522;&#20934;&#21253;&#25324;&#31934;&#24515;&#35774;&#35745;&#30340;&#25351;&#26631;&#21644;&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20004;&#20010;&#25512;&#33616;&#22330;&#26223;&#20013;&#30340;&#20843;&#20010;&#25935;&#24863;&#23646;&#24615;&#65306;&#38899;&#20048;&#21644;&#30005;&#24433;&#12290;&#36890;&#36807;&#21033;&#29992;&#25105;&#20204;&#30340;FaiRLLM&#22522;&#20934;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm -- Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes1 in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.06569</link><description>&lt;p&gt;
&#22914;&#20309;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#32034;&#24341;&#39033;&#30446;ID
&lt;/p&gt;
&lt;p&gt;
How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#36827;&#34892;&#20102;&#31995;&#32479;&#26816;&#26597;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#23558;&#25512;&#33616;&#20219;&#21153;&#36716;&#25442;&#20026;&#33258;&#28982;&#35821;&#35328;&#20219;&#21153;&#65292;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#25512;&#33616;&#12290;&#23427;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#24314;&#35758;&#30340;&#39033;&#30446;&#32780;&#19981;&#26159;&#35745;&#31639;&#20256;&#32479;&#25512;&#33616;&#27169;&#22411;&#20013;&#27599;&#20010;&#20505;&#36873;&#39033;&#30446;&#30340;&#25490;&#21517;&#24471;&#20998;&#65292;&#31616;&#21270;&#20102;&#25512;&#33616;&#31649;&#36947;&#65292;&#36991;&#20813;&#20102;&#22810;&#27573;&#36807;&#28388;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#20915;&#23450;&#35201;&#25512;&#33616;&#21738;&#20123;&#39033;&#30446;&#26102;&#29983;&#25104;&#36807;&#38271;&#30340;&#25991;&#26412;&#65292;&#20026;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#21019;&#24314;LLM&#20860;&#23481;&#30340;&#39033;&#30446;ID&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#30340;&#39033;&#30446;&#32034;&#24341;&#38382;&#39064;&#65292;&#20197;P5&#20026;&#20195;&#34920;&#30340;&#20027;&#24178;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32034;&#24341;&#26041;&#27861;&#22797;&#21046;&#20854;&#32467;&#26524;&#12290;&#25105;&#20204;&#39318;&#20808;&#35752;&#35770;&#20102;&#20960;&#31181;&#24494;&#19981;&#36275;&#36947;&#30340;&#39033;&#30446;&#32034;&#24341;&#26041;&#27861;&#65288;&#22914;&#29420;&#31435;&#32034;&#24341;&#12289;&#26631;&#39064;&#32034;&#24341;&#21644;&#38543;&#26426;&#32034;&#24341;&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#19981;&#36866;&#29992;&#20110;&#25512;&#33616;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32034;&#24341;&#26041;&#27861;&#65292;&#31216;&#20026;&#19978;&#19979;&#25991;&#24863;&#30693;&#32034;&#24341;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#31181;&#32034;&#24341;&#26041;&#27861;&#22312;&#39033;&#30446;&#25512;&#33616;&#20934;&#30830;&#24615;&#21644;&#25991;&#26412;&#29983;&#25104;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#32034;&#24341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#24037;&#19994;&#12289;&#20513;&#23548;&#32452;&#32455;&#21644;&#27668;&#20505;&#20513;&#23548;&#32452;&#32455;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#22914;&#20309;&#24433;&#21709;&#27668;&#20505;&#21464;&#21270;&#30340;&#21465;&#20107;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#30417;&#30563;&#27169;&#22411;&#32452;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;Facebook&#19978;&#27668;&#20505;&#24191;&#21578;&#30340;&#31435;&#22330;&#12290;</title><link>http://arxiv.org/abs/2305.06174</link><description>&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#20998;&#26512;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#27668;&#20505;&#23459;&#20256;&#27963;&#21160;
&lt;/p&gt;
&lt;p&gt;
Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#24037;&#19994;&#12289;&#20513;&#23548;&#32452;&#32455;&#21644;&#27668;&#20505;&#20513;&#23548;&#32452;&#32455;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#22914;&#20309;&#24433;&#21709;&#27668;&#20505;&#21464;&#21270;&#30340;&#21465;&#20107;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#30417;&#30563;&#27169;&#22411;&#32452;&#21512;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;Facebook&#19978;&#27668;&#20505;&#24191;&#21578;&#30340;&#31435;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27668;&#20505;&#21464;&#21270;&#26159;&#25105;&#20204;&#26102;&#20195;&#30340;&#26680;&#24515;&#38382;&#39064;&#65292;&#25105;&#20204;&#27491;&#22788;&#20110;&#19968;&#20010;&#20851;&#38190;&#26102;&#21051;&#12290;&#21508;&#31181;&#21033;&#30410;&#38598;&#22242;&#12289;&#31038;&#20250;&#36816;&#21160;&#32452;&#32455;&#21644;&#20010;&#20154;&#22312;&#31038;&#20132;&#23186;&#20307;&#19978;&#24320;&#23637;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#30340;&#38598;&#20307;&#34892;&#21160;&#12290;&#27492;&#22806;&#65292;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#38382;&#39064;&#20513;&#23548;&#27963;&#21160;&#24448;&#24448;&#26159;&#38024;&#23545;&#24403;&#21069;&#31038;&#20250;&#20851;&#27880;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#33021;&#28304;&#34892;&#19994;&#38754;&#20020;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#20998;&#26512;&#24037;&#19994;&#12289;&#20513;&#23548;&#32452;&#32455;&#21644;&#27668;&#20505;&#20513;&#23548;&#32452;&#32455;&#22914;&#20309;&#21033;&#29992;&#31038;&#20132;&#23186;&#20307;&#24433;&#21709;&#27668;&#20505;&#21464;&#21270;&#30340;&#21465;&#20107;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#30417;&#30563;&#27169;&#22411;&#32452;&#21512;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#28040;&#24687;&#20027;&#39064;&#26469;&#35782;&#21035;Facebook&#19978;&#27668;&#20505;&#24191;&#21578;&#30340;&#31435;&#22330;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#31435;&#22330;&#25968;&#25454;&#38598;&#12289;&#27169;&#22411;&#21644;&#19982;&#27668;&#20505;&#23459;&#20256;&#27963;&#21160;&#30456;&#20851;&#30340;&#20027;&#39064;&#65292;&#20379;&#26410;&#26469;&#30340;&#33286;&#24773;&#25366;&#25496;&#21644;&#33258;&#21160;&#26816;&#27979;&#27668;&#20505;&#21464;&#21270;&#31435;&#22330;&#30340;&#30740;&#31350;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Climate change is the defining issue of our time, and we are at a defining moment. Various interest groups, social movement organizations, and individuals engage in collective action on this issue on social media. In addition, issue advocacy campaigns on social media often arise in response to ongoing societal concerns, especially those faced by energy industries. Our goal in this paper is to analyze how those industries, their advocacy group, and climate advocacy group use social media to influence the narrative on climate change. In this work, we propose a minimally supervised model soup [56] approach combined with messaging themes to identify the stances of climate ads on Facebook. Finally, we release our stance dataset, model, and set of themes related to climate campaigns for future work on opinion mining and the automatic detection of climate change stances.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#20351;&#29992;ChatGPT&#21450;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#21457;&#29616;ChatGPT&#30340;&#39044;&#27979;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#32780;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#21464;&#21270;&#65292;&#34920;&#26126;&#22797;&#26434;&#27169;&#22411;&#21487;&#39044;&#27979;&#33021;&#21147;&#30340;&#23835;&#36215;&#12290;&#36825;&#34920;&#26126;&#22312;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#20013;&#24341;&#20837;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#24182;&#22686;&#24378;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2304.07619</link><description>&lt;p&gt;
ChatGPT&#26159;&#21542;&#33021;&#22815;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#27874;&#21160;&#65311;&#22238;&#25253;&#21487;&#39044;&#27979;&#24615;&#19982;&#22823;&#35821;&#35328;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#20351;&#29992;ChatGPT&#21450;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#21457;&#29616;ChatGPT&#30340;&#39044;&#27979;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#65292;&#32780;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#32929;&#31080;&#20215;&#26684;&#21464;&#21270;&#65292;&#34920;&#26126;&#22797;&#26434;&#27169;&#22411;&#21487;&#39044;&#27979;&#33021;&#21147;&#30340;&#23835;&#36215;&#12290;&#36825;&#34920;&#26126;&#22312;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#20013;&#24341;&#20837;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#24182;&#22686;&#24378;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#24773;&#24863;&#20998;&#26512;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#30340;&#28508;&#21147;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;ChatGPT&#20197;&#21450;&#20854;&#20182;&#22823;&#35821;&#35328;&#27169;&#22411;&#22312;&#39044;&#27979;&#32929;&#24066;&#22238;&#25253;&#26041;&#38754;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#20351;&#29992;ChatGPT&#21028;&#26029;&#26032;&#38395;&#26631;&#39064;&#23545;&#20844;&#21496;&#32929;&#31080;&#20215;&#26684;&#26159;&#22909;&#28040;&#24687;&#12289;&#22351;&#28040;&#24687;&#25110;&#26080;&#20851;&#28040;&#24687;&#12290;&#36890;&#36807;&#35745;&#31639;&#25968;&#23383;&#20998;&#25968;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;"ChatGPT&#20998;&#25968;"&#21644;&#38543;&#21518;&#30340;&#26085;&#24120;&#32929;&#31080;&#24066;&#22330;&#22238;&#25253;&#20043;&#38388;&#23384;&#22312;&#27491;&#30456;&#20851;&#24615;&#12290;&#32780;&#19988;&#65292;ChatGPT&#30340;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#30340;&#24773;&#24863;&#20998;&#26512;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-1&#12289;GPT-2&#21644;BERT&#31561;&#22522;&#30784;&#27169;&#22411;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#22238;&#25253;&#65292;&#36825;&#34920;&#26126;&#22238;&#25253;&#21487;&#39044;&#27979;&#24615;&#26159;&#22797;&#26434;&#27169;&#22411;&#30340;&#19968;&#31181;&#26032;&#20852;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#20808;&#36827;&#30340;&#35821;&#35328;&#27169;&#22411;&#32435;&#20837;&#25237;&#36164;&#20915;&#31574;&#36807;&#31243;&#21487;&#20197;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#24182;&#25552;&#39640;&#23450;&#37327;&#20132;&#26131;&#31574;&#30053;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the potential of ChatGPT, and other large language models, in predicting stock market returns using sentiment analysis of news headlines. We use ChatGPT to indicate whether a given headline is good, bad, or irrelevant news for firms' stock prices. We then compute a numerical score and document a positive correlation between these ``ChatGPT scores'' and subsequent daily stock market returns. Further, ChatGPT outperforms traditional sentiment analysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex models. Our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38024;&#23545; SemEval-2023 &#20219;&#21153; 6 &#24320;&#21457;&#30340; Legal-BERT-HSLN &#27169;&#22411;&#21644; Legal-LUKE &#27169;&#22411;&#65292;&#20854;&#20013; Legal-BERT-HSLN &#27169;&#22411;&#36890;&#36807;&#32771;&#34385;&#21477;&#20869;&#21644;&#21477;&#38388;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20197;&#39044;&#27979;&#20462;&#36766;&#35282;&#33394;&#65292;Legal-LUKE &#27169;&#22411;&#26159;&#20855;&#26377;&#27861;&#24459;&#19978;&#19979;&#25991;&#21644;&#23454;&#20307;&#30693;&#35782;&#30340;&#27169;&#22411;&#65292;&#20197;&#35782;&#21035;&#27861;&#24459;&#23454;&#20307;&#12290;&#27169;&#22411;&#30456;&#27604;&#22522;&#32447;&#27169;&#22411;&#26356;&#20934;&#30830;&#65292;&#33021;&#22815;&#35299;&#20915;&#22312;&#20154;&#21475;&#20247;&#22810;&#30340;&#22269;&#23478;&#22788;&#29702;&#27861;&#24459;&#25991;&#20214;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.12135</link><description>&lt;p&gt;
&#21033;&#29992;&#19978;&#19979;&#25991;&#21270;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29702;&#35299;&#27861;&#24459;&#25991;&#20214;
&lt;/p&gt;
&lt;p&gt;
Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38024;&#23545; SemEval-2023 &#20219;&#21153; 6 &#24320;&#21457;&#30340; Legal-BERT-HSLN &#27169;&#22411;&#21644; Legal-LUKE &#27169;&#22411;&#65292;&#20854;&#20013; Legal-BERT-HSLN &#27169;&#22411;&#36890;&#36807;&#32771;&#34385;&#21477;&#20869;&#21644;&#21477;&#38388;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20197;&#39044;&#27979;&#20462;&#36766;&#35282;&#33394;&#65292;Legal-LUKE &#27169;&#22411;&#26159;&#20855;&#26377;&#27861;&#24459;&#19978;&#19979;&#25991;&#21644;&#23454;&#20307;&#30693;&#35782;&#30340;&#27169;&#22411;&#65292;&#20197;&#35782;&#21035;&#27861;&#24459;&#23454;&#20307;&#12290;&#27169;&#22411;&#30456;&#27604;&#22522;&#32447;&#27169;&#22411;&#26356;&#20934;&#30830;&#65292;&#33021;&#22815;&#35299;&#20915;&#22312;&#20154;&#21475;&#20247;&#22810;&#30340;&#22269;&#23478;&#22788;&#29702;&#27861;&#24459;&#25991;&#20214;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#21475;&#20247;&#22810;&#30340;&#22269;&#23478;&#65292;&#22914;&#21360;&#24230;&#65292;&#24453;&#22788;&#29702;&#30340;&#27861;&#24459;&#26696;&#20214;&#25968;&#37327;&#19981;&#26029;&#22686;&#21152;&#65292;&#36825;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#22823;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#26377;&#25928;&#30340;&#25216;&#26415;&#26469;&#22788;&#29702;&#21644;&#29702;&#35299;&#27861;&#24459;&#25991;&#20214;&#23558;&#38750;&#24120;&#26377;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#38024;&#23545; SemEval-2023 &#20219;&#21153; 6&#65288;Modi &#31561;&#20154;&#65292;2023&#65289;&#25152;&#24320;&#21457;&#30340;&#29702;&#35299;&#27861;&#24459;&#25991;&#26412;&#31995;&#32479;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102; Legal-BERT-HSLN &#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#21477;&#20869;&#21644;&#21477;&#38388;&#30340;&#32508;&#21512;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#20197;&#39044;&#27979;&#20462;&#36766;&#35282;&#33394;&#65288;&#23376;&#20219;&#21153; A&#65289;&#65292;&#28982;&#21518;&#35757;&#32451;&#20986; Legal-LUKE &#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#27861;&#24459;&#19978;&#19979;&#25991;&#21270;&#21644;&#23454;&#20307;&#24863;&#30693;&#33021;&#21147;&#65292;&#20197;&#35782;&#21035;&#27861;&#24459;&#23454;&#20307;&#65288;&#23376;&#20219;&#21153; B&#65289;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#35774;&#35745;&#30340;&#27169;&#22411;&#27604;&#22522;&#32447;&#27169;&#22411;&#26356;&#20934;&#30830;&#65292;&#22914;&#22312;&#23376;&#20219;&#21153; B &#20013; F1 &#20540;&#25552;&#39640;&#20102;&#36798; 15.0%&#12290;&#25105;&#20204;&#22312;&#20219;&#21153;&#25490;&#34892;&#27036;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#65292;&#22914; 0.834 &#24494;&#24179;&#22343; F1 &#20540;&#65292;&#24182;&#22312;&#23376;&#20219;&#21153; A &#20013;&#25490;&#21517;&#31532; 5&#12290;
&lt;/p&gt;
&lt;p&gt;
The growth of pending legal cases in populous countries, such as India, has become a major issue. Developing effective techniques to process and understand legal documents is extremely useful in resolving this problem. In this paper, we present our systems for SemEval-2023 Task 6: understanding legal texts (Modi et al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that considers the comprehensive context information in both intra- and inter-sentence levels to predict rhetorical roles (subtask A) and then train a Legal-LUKE model, which is legal-contextualized and entity-aware, to recognize legal entities (subtask B). Our evaluations demonstrate that our designed models are more accurate than baselines, e.g., with an up to 15.0% better F1 score in subtask B. We achieved notable performance in the task leaderboard, e.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#20171;&#32461;&#20102;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#12289;&#26041;&#27861;&#21644;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#20108;&#32773;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#23637;&#26395;&#20102;&#39044;&#35757;&#32451;&#26102;&#20195;&#35821;&#35328;&#24314;&#27169;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2303.05759</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#27010;&#36848;&#65306;&#26368;&#26032;&#21457;&#23637;&#21644;&#23637;&#26395;
&lt;/p&gt;
&lt;p&gt;
An Overview on Language Models: Recent Developments and Outlook. (arXiv:2303.05759v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05759
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35770;&#25991;&#20171;&#32461;&#20102;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#27010;&#24565;&#12289;&#26041;&#27861;&#21644;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#20108;&#32773;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#23637;&#26395;&#20102;&#39044;&#35757;&#32451;&#26102;&#20195;&#35821;&#35328;&#24314;&#27169;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#30740;&#31350;&#25991;&#26412;&#23383;&#31526;&#20018;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#26159;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#26368;&#22522;&#26412;&#30340;&#20219;&#21153;&#20043;&#19968;&#12290;&#23427;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25991;&#26412;&#29983;&#25104;&#12289;&#35821;&#38899;&#35782;&#21035;&#12289;&#26426;&#22120;&#32763;&#35793;&#31561;&#39046;&#22495;&#12290;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#26088;&#22312;&#20197;&#22240;&#26524;&#26041;&#24335;&#39044;&#27979;&#35821;&#35328;&#24207;&#21015;&#30340;&#27010;&#29575;&#65292;&#32780;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#28085;&#30422;&#26356;&#24191;&#27867;&#30340;&#27010;&#24565;&#65292;&#24182;&#21487;&#29992;&#20110;&#22240;&#26524;&#39034;&#24207;&#24314;&#27169;&#21644;&#19979;&#28216;&#24212;&#29992;&#30340;&#24494;&#35843;&#12290;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20855;&#26377;&#33258;&#24049;&#30340;&#35757;&#32451;&#33539;&#20363;&#65288;&#36890;&#24120;&#26159;&#33258;&#30417;&#30563;&#30340;&#65289;&#65292;&#24182;&#22312;&#29616;&#20195;NLP&#31995;&#32479;&#20013;&#20316;&#20026;&#22522;&#30784;&#27169;&#22411;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#20174;&#35821;&#35328;&#21333;&#20803;&#12289;&#26550;&#26500;&#12289;&#35757;&#32451;&#26041;&#27861;&#12289;&#35780;&#20272;&#26041;&#27861;&#21644;&#24212;&#29992;&#20116;&#20010;&#26041;&#38754;&#20171;&#32461;&#20102;&#20256;&#32479;&#35821;&#35328;&#27169;&#22411;&#21644;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#21516;&#26102;&#35752;&#35770;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#23545;&#39044;&#35757;&#32451;&#26102;&#20195;&#30340;&#35821;&#35328;&#24314;&#27169;&#26410;&#26469;&#26041;&#21521;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language modeling studies the probability distributions over strings of texts. It is one of the most fundamental tasks in natural language processing (NLP). It has been widely used in text generation, speech recognition, machine translation, etc. Conventional language models (CLMs) aim to predict the probability of linguistic sequences in a causal manner, while pre-trained language models (PLMs) cover broader concepts and can be used in both causal sequential modeling and fine-tuning for downstream applications. PLMs have their own training paradigms (usually self-supervised) and serve as foundation models in modern NLP systems. This overview paper provides an introduction to both CLMs and PLMs from five aspects, i.e., linguistic units, architectures, training methods, evaluation methods, and applications. Furthermore, we discuss the relationship between CLMs and PLMs and shed light on the future directions of language modeling in the pre-trained era.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#25191;&#34892;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;&#65292;&#24182;&#25104;&#21151;&#25552;&#39640;&#20102;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2302.14229</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#25191;&#34892;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;&#65292;&#24182;&#25104;&#21151;&#25552;&#39640;&#20102;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#28304;&#35821;&#35328;&#25991;&#26412;&#65292;&#36328;&#35821;&#35328;&#25688;&#35201;&#65288;CLS&#65289;&#26088;&#22312;&#29983;&#25104;&#21478;&#19968;&#31181;&#30446;&#26631;&#35821;&#35328;&#30340;&#25688;&#35201;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#29616;&#65292;&#27604;&#22914;GPT-3.5&#12289;ChatGPT&#21644;GPT-4&#65292;&#24341;&#36215;&#20102;&#35745;&#31639;&#35821;&#35328;&#23398;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;LLM&#22312;CLS&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;LLM&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#65288;&#21363;&#31471;&#21040;&#31471;&#21644;&#27969;&#27700;&#32447;&#65289;&#25191;&#34892;&#38646;&#26679;&#26412;CLS&#65292;&#24182;&#23545;&#29983;&#25104;&#30340;&#25688;&#35201;&#36827;&#34892;&#21021;&#27493;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;ChatGPT&#21644;GPT-4&#21407;&#26412;&#26356;&#21916;&#27426;&#29983;&#25104;&#35814;&#32454;&#20449;&#24687;&#30340;&#38271;&#25688;&#35201;&#12290;&#20294;&#36825;&#20004;&#20010;LLM&#22312;&#20132;&#20114;&#24335;&#25552;&#31034;&#30340;&#24110;&#21161;&#19979;&#21487;&#20197;&#36827;&#19968;&#27493;&#24179;&#34913;&#20449;&#24687;&#37327;&#21644;&#31616;&#27905;&#24615;&#65292;&#26174;&#33879;&#25552;&#39640;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#22312;&#19977;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;CLS&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;Fine-tuned&#35821;&#35328;&#27169;&#22411;&#20013;&#20219;&#21153;&#29305;&#23450;&#25216;&#33021;&#23450;&#20301;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#20197;&#35782;&#21035;&#20986;&#36129;&#29486;&#27169;&#22411;&#24615;&#33021;&#30340;&#38750;&#24120;&#23567;&#30340;&#21442;&#25968;&#23376;&#38598;&#65292;&#20351;&#24471;&#23558;Fine-tuned&#30340;&#20540;&#23233;&#25509;&#21040;&#36825;&#20010;&#23376;&#38598;&#19978;&#21487;&#20197;&#33719;&#24471;&#20960;&#20046;&#21644;Fine-tuned&#27169;&#22411;&#19968;&#26679;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.06600</link><description>&lt;p&gt;
&#38024;&#23545;&#20219;&#21153;&#30340;&#25216;&#33021;&#23450;&#20301;&#22312;Fine-tuned&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Task-Specific Skill Localization in Fine-tuned Language Models. (arXiv:2302.06600v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;Fine-tuned&#35821;&#35328;&#27169;&#22411;&#20013;&#20219;&#21153;&#29305;&#23450;&#25216;&#33021;&#23450;&#20301;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#20248;&#21270;&#21487;&#20197;&#35782;&#21035;&#20986;&#36129;&#29486;&#27169;&#22411;&#24615;&#33021;&#30340;&#38750;&#24120;&#23567;&#30340;&#21442;&#25968;&#23376;&#38598;&#65292;&#20351;&#24471;&#23558;Fine-tuned&#30340;&#20540;&#23233;&#25509;&#21040;&#36825;&#20010;&#23376;&#38598;&#19978;&#21487;&#20197;&#33719;&#24471;&#20960;&#20046;&#21644;Fine-tuned&#27169;&#22411;&#19968;&#26679;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;Fine-tuned&#26469;&#35299;&#20915;&#21508;&#31181;NLP&#20219;&#21153;&#65292;&#21253;&#25324;&#23569;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;Fine-tuning&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#24555;&#36895;&#25484;&#25569;&#20219;&#21153;&#29305;&#23450;&#30340;&#8220;&#25216;&#33021;&#8221;&#65292;&#20294;&#26159;&#20851;&#20110;&#36825;&#20123;&#26032;&#23398;&#21040;&#30340;&#25216;&#33021;&#22312;&#24222;&#22823;&#27169;&#22411;&#20013;&#30340;&#20301;&#32622;&#30340;&#30740;&#31350;&#36824;&#24456;&#26377;&#38480;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#25216;&#33021;&#23450;&#20301;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#32473;&#23450;&#19979;&#28216;&#20219;&#21153;&#21644;&#22312;&#35813;&#20219;&#21153;&#19978;&#36827;&#34892;Fine-tuned&#30340;&#27169;&#22411;&#65292;&#21033;&#29992;&#31616;&#21333;&#30340;&#20248;&#21270;&#26041;&#27861;&#21487;&#20197;&#35782;&#21035;&#20986;&#36127;&#36131;&#27169;&#22411;&#24615;&#33021;&#30340;&#38750;&#24120;&#23567;&#30340;&#21442;&#25968;&#23376;&#38598;&#65288;&#21344;&#27169;&#22411;&#21442;&#25968;&#30340;&#32422;0.01%&#65289;&#65292;&#36825;&#20010;&#23376;&#38598;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#36129;&#29486;&#21344;&#27604;&#36229;&#36807;95%&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#20165;&#23558;Fine-tuned&#30340;&#20540;&#23233;&#25509;&#21040;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#36825;&#20010;&#23567;&#23376;&#38598;&#19978;&#65292;&#23601;&#21487;&#20197;&#33719;&#24471;&#20960;&#20046;&#21644;Fine-tuned&#27169;&#22411;&#19968;&#26679;&#22909;&#30340;&#24615;&#33021;&#12290;&#34429;&#28982;&#19982;&#26368;&#36817;&#20851;&#20110;&#21442;&#25968;&#39640;&#25928;Fine-tuning&#30340;&#24037;&#20316;&#30456;&#20284;&#65292;&#20294;&#36825;&#37324;&#30340;&#20004;&#20010;&#26032;&#39062;&#20043;&#22788;&#26159;&#65306;&#65288;i&#65289;&#19981;&#38656;&#35201;&#22312;&#23376;&#38598;&#19978;&#36827;&#34892;&#36827;&#19968;&#27493;&#30340;&#37325;&#26032;&#35757;&#32451;&#65288;&#19981;&#20687;&#8220;lottery tickets&#8221;&#37027;&#26679;&#65289;&#12290;&#65288;ii&#65289;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;Fine-tuned&#27169;&#22411;&#65292;&#21487;&#20197;&#30475;&#21040;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-trained language models can be fine-tuned to solve diverse NLP tasks, including in few-shot settings. Thus fine-tuning allows the model to quickly pick up task-specific ``skills,'' but there has been limited study of where these newly-learnt skills reside inside the massive model. This paper introduces the term skill localization for this problem and proposes a solution. Given the downstream task and a model fine-tuned on that task, a simple optimization is used to identify a very small subset of parameters ($\sim0.01$% of model parameters) responsible for ($&gt;95$%) of the model's performance, in the sense that grafting the fine-tuned values for just this tiny subset onto the pre-trained model gives performance almost as well as the fine-tuned model. While reminiscent of recent works on parameter-efficient fine-tuning, the novel aspects here are that: (i) No further re-training is needed on the subset (unlike, say, with lottery tickets). (ii) Notable improvements are seen over vanil
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#22810;&#32500;&#24230;&#20559;&#24046;&#24230;&#37327;&#25351;&#26631;bipol&#65292;&#35780;&#20272;&#20102;&#20116;&#20010;&#33521;&#25991;&#21644;&#20004;&#20010;&#29790;&#20856;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#21253;&#21547;200&#19975;&#20010;&#26679;&#26412;&#30340;&#29790;&#20856;&#20559;&#24046;&#26631;&#27880;&#25968;&#25454;&#38598;&#21644;&#29992;&#20110;&#29790;&#20856;&#20559;&#24046;&#26816;&#27979;&#30340;&#22810;&#32500;&#24230;&#35789;&#24211;&#12290;</title><link>http://arxiv.org/abs/2301.12139</link><description>&lt;p&gt;
Bipol: &#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#29992;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#24335;&#35780;&#20272;&#22810;&#20010;&#32500;&#24230;&#30340;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#22810;&#32500;&#24230;&#20559;&#24046;&#24230;&#37327;&#25351;&#26631;bipol&#65292;&#35780;&#20272;&#20102;&#20116;&#20010;&#33521;&#25991;&#21644;&#20004;&#20010;&#29790;&#20856;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#21253;&#21547;200&#19975;&#20010;&#26679;&#26412;&#30340;&#29790;&#20856;&#20559;&#24046;&#26631;&#27880;&#25968;&#25454;&#38598;&#21644;&#29992;&#20110;&#29790;&#20856;&#20559;&#24046;&#26816;&#27979;&#30340;&#22810;&#32500;&#24230;&#35789;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#20116;&#20010;&#33521;&#25991;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#22522;&#20934;&#25968;&#25454;&#38598;&#65288;&#22312;superGLUE&#27036;&#21333;&#19978;&#65289;&#65292;&#20197;&#21450;&#20004;&#20010;&#29790;&#20856;&#25968;&#25454;&#38598;&#30340;&#20559;&#24046;&#24615;&#36136;&#65292;&#28041;&#21450;&#22810;&#20010;&#32500;&#24230;&#12290;&#36825;&#20123;&#25968;&#25454;&#38598;&#21253;&#25324;&#65306;&#24067;&#23572;&#38382;&#39064;&#65288;Boolq&#65289;&#12289;&#25215;&#35834;&#38134;&#34892;&#65288;CB&#65289;&#12289;Winograd&#27169;&#24335;&#25361;&#25112;&#65288;WSC&#65289;&#12289;Wino-gender&#35786;&#26029;&#65288;AXg&#65289;&#12289;&#25991;&#26412;&#34164;&#21547;&#35782;&#21035;&#65288;RTE&#65289;&#12289;&#29790;&#20856;CB&#21644;SWEDN&#12290;&#20559;&#24046;&#21487;&#33021;&#20855;&#26377;&#23475;&#22788;&#65292;&#24182;&#19988;&#24050;&#30693;&#24120;&#35265;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25152;&#23398;&#20064;&#30340;&#25968;&#25454;&#20013;&#12290;&#20026;&#20102;&#20943;&#36731;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#65292;&#33021;&#22815;&#23458;&#35266;&#20272;&#35745;&#20559;&#24046;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#32500;&#24230;&#20559;&#24046;&#24230;&#37327;&#25351;&#26631;bipol&#65292;&#24182;&#35299;&#37322;&#35813;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#22810;&#23569;&#20559;&#24046;&#12290;&#36328;&#35821;&#35328;&#12289;&#22810;&#32500;&#24230;&#30340;&#20559;&#24046;&#35780;&#20272;&#24182;&#19981;&#24120;&#35265;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36824;&#36129;&#29486;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#21253;&#21547;200&#19975;&#20010;&#26679;&#26412;&#30340;&#29790;&#20856;&#20559;&#24046;&#26631;&#27880;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#20174;&#33521;&#25991;&#29256;&#26412;&#32763;&#35793;&#32780;&#26469;&#65292;&#24182;&#22312;&#20854;&#20013;&#20351;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;mT5&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#29790;&#20856;&#20559;&#24046;&#26816;&#27979;&#25552;&#20379;&#20102;&#26032;&#30340;&#22810;&#32500;&#24230;&#35789;&#24211;&#12290;&#25105;&#20204;&#23558;&#20195;&#30721;&#12289;&#27169;&#22411;&#21644;&#26032;&#25968;&#25454;&#38598;&#20844;&#24320;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate five English NLP benchmark datasets (on the superGLUE leaderboard) and two Swedish datasets for bias, along multiple axes. The datasets are the following: Boolean Question (Boolq), CommitmentBank (CB), Winograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), Recognising Textual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it is known to be common in data, which ML models learn from. In order to mitigate bias in data, it is crucial to be able to estimate it objectively. We use bipol, a novel multi-axes bias metric with explainability, to estimate and explain how much bias exists in these datasets. Multilingual, multi-axes bias evaluation is not very common. Hence, we also contribute a new, large Swedish bias-labelled dataset (of 2 million samples), translated from the English version and train the SotA mT5 model on it. In addition, we contribute new multi-axes lexica for bias detection in Swedish. We make the codes, model, and new dataset publicl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;10&#20010;&#27169;&#22411;&#21644;4&#31181;&#22686;&#24378;&#26041;&#27861;&#30340;&#23454;&#39564;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#22312;&#35760;&#24518;&#19981;&#22826;&#27969;&#34892;&#30340;&#23454;&#38469;&#30693;&#35782;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#32780;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#34920;&#29616;&#36739;&#22909;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#26377;&#25928;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.10511</link><description>&lt;p&gt;
&#20309;&#26102;&#19981;&#20449;&#20219;&#35821;&#35328;&#27169;&#22411;&#65306;&#25506;&#32034;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#35760;&#24518;&#30340;&#26377;&#25928;&#24615;&#21644;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;10&#20010;&#27169;&#22411;&#21644;4&#31181;&#22686;&#24378;&#26041;&#27861;&#30340;&#23454;&#39564;&#65292;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#22312;&#35760;&#24518;&#19981;&#22826;&#27969;&#34892;&#30340;&#23454;&#38469;&#30693;&#35782;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#32780;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#34920;&#29616;&#36739;&#22909;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#31616;&#21333;&#26377;&#25928;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20173;&#28982;&#38590;&#20197;&#22788;&#29702;&#38656;&#35201;&#20016;&#23500;&#19990;&#30028;&#30693;&#35782;&#30340;&#20219;&#21153;&#65292;&#36825;&#26263;&#31034;&#20102;&#20165;&#20381;&#38752;&#20854;&#21442;&#25968;&#26469;&#32534;&#30721;&#20016;&#23500;&#30340;&#19990;&#30028;&#30693;&#35782;&#30340;&#23616;&#38480;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;10&#20010;&#27169;&#22411;&#21644;4&#31181;&#22686;&#24378;&#26041;&#27861;&#22312;PopQA&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30693;&#35782;&#25506;&#27979;&#23454;&#39564;&#65292;&#20197;&#20102;&#35299;&#35821;&#35328;&#27169;&#22411;&#22312;&#35760;&#24518;&#20107;&#23454;&#30693;&#35782;&#26041;&#38754;&#30340;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#35821;&#35328;&#27169;&#22411;&#38590;&#20197;&#35760;&#24518;&#19981;&#22826;&#27969;&#34892;&#30340;&#23454;&#38469;&#30693;&#35782;&#65292;&#24182;&#19988;&#22312;&#38271;&#23614;&#20013;&#65292;&#25193;&#23637;&#35268;&#27169;&#26080;&#27861;&#26126;&#26174;&#25913;&#21892;&#35760;&#24518;&#23454;&#38469;&#30693;&#35782;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26816;&#32034;&#22686;&#24378;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#32988;&#36807;&#32423;&#21035;&#22823;&#24471;&#22810;&#30340;&#35821;&#35328;&#27169;&#22411;&#65292;&#32780;&#26410;&#32463;&#21327;&#21161;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#28041;&#21450;&#39640;&#27969;&#34892;&#23454;&#20307;&#30340;&#38382;&#39064;&#19978;&#20173;&#28982;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#22522;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#24378;&#22823;&#21644;&#39640;&#25928;&#30340;&#26816;&#32034;&#22686;&#24378;&#35821;&#35328;&#27169;&#22411;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#22312;&#38656;&#35201;&#26102;&#26816;&#32034;&#38750;&#21442;&#25968;&#35760;&#24518;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their impressive performance on diverse tasks, large language models (LMs) still struggle with tasks requiring rich world knowledge, implying the limitations of relying solely on their parameters to encode a wealth of world knowledge. This paper aims to understand LMs' strengths and limitations in memorizing factual knowledge, by conducting large-scale knowledge probing experiments of 10 models and 4 augmentation methods on PopQA, our new open-domain QA dataset with 14k questions. We find that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the long tail. We then show that retrieval-augmented LMs largely outperform orders of magnitude larger LMs, while unassisted LMs remain competitive in questions about high-popularity entities. Based on those findings, we devise a simple, yet effective, method for powerful and efficient retrieval-augmented LMs, which retrieves non-parametric memories only whe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22635;&#34917;&#20102;&#23545;&#20174;&#33521;&#25991;&#21040;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#36827;&#34892;&#31995;&#32479;&#24615;&#30740;&#31350;&#30340;&#31354;&#30333;&#65292;&#36890;&#36807;&#21019;&#24314;&#21253;&#21547;7000&#20010;&#32454;&#31890;&#24230;&#27880;&#37322;&#30340;MQM&#25968;&#25454;&#38598;&#65292;&#21457;&#29616;&#39044;&#35757;&#32451;&#30340;&#25351;&#26631;&#19982;&#27880;&#37322;&#32773;&#20998;&#25968;&#20855;&#26377;&#26368;&#39640;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25351;&#20986;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#19981;&#33021;&#20934;&#30830;&#35780;&#20272;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2212.10180</link><description>&lt;p&gt;
IndicMT Eval&#65306;&#19968;&#20221;&#29992;&#20110;&#23545;&#21360;&#24230;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#35780;&#20215;&#25351;&#26631;&#36827;&#34892;&#20803;&#35780;&#20272;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages. (arXiv:2212.10180v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22635;&#34917;&#20102;&#23545;&#20174;&#33521;&#25991;&#21040;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#36827;&#34892;&#31995;&#32479;&#24615;&#30740;&#31350;&#30340;&#31354;&#30333;&#65292;&#36890;&#36807;&#21019;&#24314;&#21253;&#21547;7000&#20010;&#32454;&#31890;&#24230;&#27880;&#37322;&#30340;MQM&#25968;&#25454;&#38598;&#65292;&#21457;&#29616;&#39044;&#35757;&#32451;&#30340;&#25351;&#26631;&#19982;&#27880;&#37322;&#32773;&#20998;&#25968;&#20855;&#26377;&#26368;&#39640;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25351;&#20986;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#19981;&#33021;&#20934;&#30830;&#35780;&#20272;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#30340;&#24555;&#36895;&#22686;&#38271;&#38656;&#35201;&#36827;&#34892;&#20840;&#38754;&#30340;&#30740;&#31350;&#26469;&#23545;&#27491;&#22312;&#20351;&#29992;&#30340;&#35780;&#20272;&#25351;&#26631;&#36827;&#34892;&#20803;&#35780;&#20272;&#65292;&#20174;&#32780;&#33021;&#22815;&#26356;&#22909;&#22320;&#36873;&#25321;&#26368;&#33021;&#21453;&#26144;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#30340;&#25351;&#26631;&#12290;&#36951;&#25022;&#30340;&#26159;&#65292;&#22823;&#37096;&#20998;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#39640;&#36164;&#28304;&#35821;&#35328;&#65292;&#20027;&#35201;&#26159;&#33521;&#25991;&#65292;&#20854;&#20013;&#30340;&#35266;&#23519;&#32467;&#26524;&#24182;&#19981;&#24635;&#26159;&#36866;&#29992;&#20110;&#20854;&#20182;&#35821;&#35328;&#12290;&#21360;&#24230;&#35821;&#35328;&#19982;&#33521;&#25991;&#22312;&#35821;&#35328;&#19978;&#23384;&#22312;&#24046;&#24322;&#65292;&#24182;&#19988;&#36804;&#20170;&#20026;&#27490;&#23578;&#26410;&#23545;&#20174;&#33521;&#25991;&#21040;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#36827;&#34892;&#31995;&#32479;&#24615;&#30740;&#31350;&#12290;&#26412;&#25991;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#21253;&#21547;7000&#20010;&#32454;&#31890;&#24230;&#27880;&#37322;&#30340;MQM&#25968;&#25454;&#38598;&#65292;&#28085;&#30422;&#20102;5&#31181;&#21360;&#24230;&#35821;&#35328;&#21644;7&#20010;&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#65292;&#24182;&#20351;&#29992;&#35813;&#25968;&#25454;&#38598;&#24314;&#31435;&#20102;&#27880;&#37322;&#32773;&#20998;&#25968;&#21644;&#29616;&#26377;&#33258;&#21160;&#35780;&#20272;&#25351;&#26631;&#24471;&#20998;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#39044;&#35757;&#32451;&#30340;&#25351;&#26631;&#65288;&#22914;COMET&#65289;&#19982;&#27880;&#37322;&#32773;&#20998;&#25968;&#30340;&#30456;&#20851;&#24615;&#26368;&#39640;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#36825;&#20123;&#35780;&#20272;&#25351;&#26631;&#19981;&#24635;&#26159;&#33021;&#20934;&#30830;&#22320;&#35780;&#20272;&#21360;&#24230;&#35821;&#35328;&#30340;&#26426;&#22120;&#32763;&#35793;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not ad
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#26032;&#30340;&#34394;&#20551;&#20449;&#24687;&#22768;&#26126;&#24182;&#35782;&#21035;&#25903;&#25345;&#23427;&#20204;&#30340;&#31038;&#20132;&#23186;&#20307;&#28040;&#24687;&#12290;&#22312;COVID-19&#27835;&#30103;&#30340;&#26696;&#20363;&#20013;&#65292;&#22522;&#20110;&#29616;&#20195;NLP&#26041;&#27861;&#24320;&#21457;&#22522;&#32447;&#31995;&#32479;&#65292;&#24182;&#23637;&#31034;&#20102;&#20154;&#31867;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#27599;&#23567;&#26102;&#21487;&#20197;&#35782;&#21035;&#20986;&#36829;&#21453;Twitter&#20851;&#20110;COVID-19&#34394;&#20551;&#20449;&#24687;&#26041;&#38024;&#30340;124&#26465;&#25512;&#25991;&#12290;</title><link>http://arxiv.org/abs/2212.09683</link><description>&lt;p&gt;
&#20154;&#26426;&#21327;&#21516;&#35780;&#20272;&#26089;&#26399;&#35823;&#20256;&#20449;&#24687;&#26816;&#27979;&#65306;COVID-19&#27835;&#30103;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments. (arXiv:2212.09683v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09683
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#26032;&#30340;&#34394;&#20551;&#20449;&#24687;&#22768;&#26126;&#24182;&#35782;&#21035;&#25903;&#25345;&#23427;&#20204;&#30340;&#31038;&#20132;&#23186;&#20307;&#28040;&#24687;&#12290;&#22312;COVID-19&#27835;&#30103;&#30340;&#26696;&#20363;&#20013;&#65292;&#22522;&#20110;&#29616;&#20195;NLP&#26041;&#27861;&#24320;&#21457;&#22522;&#32447;&#31995;&#32479;&#65292;&#24182;&#23637;&#31034;&#20102;&#20154;&#31867;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#27599;&#23567;&#26102;&#21487;&#20197;&#35782;&#21035;&#20986;&#36829;&#21453;Twitter&#20851;&#20110;COVID-19&#34394;&#20551;&#20449;&#24687;&#26041;&#38024;&#30340;124&#26465;&#25512;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20154;&#26426;&#21327;&#21516;&#35780;&#20272;&#26694;&#26550;&#65292;&#29992;&#20110;&#20107;&#23454;&#26680;&#26597;&#26032;&#30340;&#34394;&#20551;&#20449;&#24687;&#22768;&#26126;&#24182;&#35782;&#21035;&#25903;&#25345;&#23427;&#20204;&#30340;&#31038;&#20132;&#23186;&#20307;&#28040;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#21462;&#20540;&#24471;&#26680;&#26597;&#30340;&#22768;&#26126;&#65292;&#36825;&#20123;&#22768;&#26126;&#34987;&#32858;&#21512;&#24182;&#25490;&#21517;&#20197;&#20415;&#22797;&#23457;&#12290;&#28982;&#21518;&#20351;&#29992;&#31435;&#22330;&#20998;&#31867;&#22120;&#26469;&#35782;&#21035;&#25903;&#25345;&#26032;&#34394;&#20551;&#20449;&#24687;&#30003;&#36848;&#30340;&#25512;&#25991;&#65292;&#36827;&#19968;&#27493;&#26816;&#26597;&#20197;&#30830;&#23450;&#23427;&#20204;&#26159;&#21542;&#36829;&#21453;&#30456;&#20851;&#25919;&#31574;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#22312;COVID-19&#27835;&#30103;&#39046;&#22495;&#22522;&#20110;&#29616;&#20195;NLP&#26041;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#32447;&#31995;&#32479;&#29992;&#20110;&#20154;&#26426;&#21327;&#21516;&#20107;&#23454;&#26680;&#26597;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#22522;&#32447;&#31995;&#32479;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20154;&#31867;&#20107;&#23454;&#26680;&#26597;&#20154;&#21592;&#27599;&#23567;&#26102;&#33021;&#22815;&#35782;&#21035;&#20986;&#36829;&#21453;Twitter&#20851;&#20110;COVID-19&#34394;&#20551;&#20449;&#24687;&#26041;&#38024;&#30340;124&#26465;&#25512;&#25991;&#12290;&#25105;&#20204;&#23558;&#25552;&#20379;&#25105;&#20204;&#30340;&#20195;&#30721;&#12289;&#25968;&#25454;&#12289;&#22522;&#32447;&#27169;&#22411;&#21644;&#35814;&#32454;&#27880;&#37322;&#25351;&#21335;&#26469;&#25903;&#25345;&#20154;&#26426;&#21327;&#21516;&#31995;&#32479;&#30340;&#35780;&#20272;&#65292;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#30452;&#25509;&#20174;&#21407;&#22987;&#29992;&#25143;&#29983;&#25104;&#30340;&#20869;&#23481;&#20013;&#35782;&#21035;&#26032;&#30340;&#34394;&#20551;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a human-in-the-loop evaluation framework for fact-checking novel misinformation claims and identifying social media messages that support them. Our approach extracts check-worthy claims, which are aggregated and ranked for review. Stance classifiers are then used to identify tweets supporting novel misinformation claims, which are further reviewed to determine whether they violate relevant policies. To demonstrate the feasibility of our approach, we develop a baseline system based on modern NLP methods for human-in-the-loop fact-checking in the domain of COVID-19 treatments. Using our baseline system, we show that human fact-checkers can identify 124 tweets per hour that violate Twitter's policies on COVID-19 misinformation. We will make our code, data, baseline models, and detailed annotation guidelines available to support the evaluation of human-in-the-loop systems that identify novel misinformation directly from raw user-generated content.
&lt;/p&gt;</description></item><item><title>PromptBoosting&#26159;&#19968;&#31181;&#40657;&#30418;&#25991;&#26412;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#23567;&#32452;&#25552;&#31034;&#21644;AdaBoost&#31639;&#27861;&#23558;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#20998;&#24067;&#26500;&#24314;&#20026;&#22823;&#37327;&#24369;&#23398;&#20064;&#22120;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#31867;&#22120;&#35757;&#32451;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2212.09257</link><description>&lt;p&gt;
PromptBoosting&#65306;&#20855;&#26377;&#21313;&#27425;&#21069;&#21521;&#20256;&#36882;&#30340;&#40657;&#30418;&#25991;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
PromptBoosting: Black-Box Text Classification with Ten Forward Passes. (arXiv:2212.09257v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09257
&lt;/p&gt;
&lt;p&gt;
PromptBoosting&#26159;&#19968;&#31181;&#40657;&#30418;&#25991;&#26412;&#20998;&#31867;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#23567;&#32452;&#25552;&#31034;&#21644;AdaBoost&#31639;&#27861;&#23558;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#30340;&#36755;&#20986;&#20998;&#24067;&#26500;&#24314;&#20026;&#22823;&#37327;&#24369;&#23398;&#20064;&#22120;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#20998;&#31867;&#22120;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;PromptBoosting&#65292;&#19968;&#31181;&#20174;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#65288;LM&#65289;&#26500;&#24314;&#25991;&#26412;&#20998;&#31867;&#22120;&#30340;&#26597;&#35810;&#39640;&#25928;&#36807;&#31243;&#65292;&#20854;&#20013;&#27809;&#26377;&#35775;&#38382;LM&#30340;&#21442;&#25968;&#12289;&#26799;&#24230;&#25110;&#38544;&#34255;&#34920;&#31034;&#12290;&#36825;&#31181;&#8220;&#40657;&#30418;&#8221;&#20998;&#31867;&#22120;&#35757;&#32451;&#24418;&#24335;&#22312;&#22823;&#35268;&#27169;LM&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#25104;&#26412;&#22686;&#21152;&#26102;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#40657;&#30418;LM&#20998;&#31867;&#22120;&#23398;&#20064;&#26041;&#27861;&#26412;&#36523;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#65292;&#36890;&#24120;&#20351;&#29992;&#38646;&#38454;&#20248;&#21270;&#26041;&#27861;&#22312;&#22823;&#37327;&#30340;&#65288;&#31163;&#25955;&#25110;&#36830;&#32493;&#65289;&#25552;&#31034;&#31354;&#38388;&#20013;&#25628;&#32034;&#23558;LM&#29305;&#21270;&#21040;&#30446;&#26631;&#20219;&#21153;&#12290;PromptBoosting&#19981;&#30452;&#25509;&#22312;&#25552;&#31034;&#31354;&#38388;&#36827;&#34892;&#20248;&#21270;&#65292;&#32780;&#26159;&#36890;&#36807;&#26080;&#26799;&#24230;&#26041;&#27861;&#33719;&#24471;&#19968;&#23567;&#32452;&#25552;&#31034;&#65292;&#28982;&#21518;&#23558;&#36825;&#20123;&#25552;&#31034;&#19982;LM&#36755;&#20986;&#20998;&#24067;&#30340;&#19981;&#21516;&#20803;&#32032;&#37197;&#23545;&#26500;&#24314;&#22823;&#37327;&#24369;&#23398;&#20064;&#22120;&#12290;&#28982;&#21518;&#20351;&#29992;AdaBoost&#31639;&#27861;&#23545;&#36825;&#20123;&#24369;&#23398;&#20064;&#22120;&#36827;&#34892;&#38598;&#25104;&#12290;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20165;&#38656;&#35201;&#23569;&#37327;&#21069;&#21521;&#20256;&#36882;&#21644;n
&lt;/p&gt;
&lt;p&gt;
We describe PromptBoosting, a query-efficient procedure for building a text classifier from a neural language model (LM) without access to the LM's parameters, gradients, or hidden representations. This form of "black-box" classifier training has become increasingly important as the cost of training and inference in large-scale LMs grows. But existing black-box LM classifier learning approaches are themselves computationally inefficient, typically specializing LMs to the target task by searching in a large space of (discrete or continuous) prompts using zeroth-order optimization methods. Instead of directly optimizing in prompt space, PromptBoosting obtains a small pool of prompts via a gradient-free approach and then constructs a large pool of weak learners by pairing these prompts with different elements of the LM's output distribution. These weak learners are then ensembled using the AdaBoost algorithm. The entire learning process requires only a small number of forward passes and n
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20316;&#32773;&#24402;&#23646;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25991;&#26412;&#20869;&#23481;&#21644;&#21442;&#32771;&#25991;&#29486;&#20013;&#30340;&#20316;&#32773;&#22995;&#21517;&#65292;&#21487;&#20197;&#23558;&#21311;&#21517;&#25163;&#31295;&#27491;&#30830;&#24402;&#23646;&#32473;&#20316;&#32773;&#12290;&#35813;&#26041;&#27861;&#22312;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#20316;&#32773;&#36523;&#20221;&#35782;&#21035;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#65292;&#22312;&#21253;&#21547;&#22810;&#36798;2000&#20010;&#19981;&#21516;&#20316;&#32773;&#30340;arXiv&#23376;&#38598;&#20013;&#65292;&#21462;&#24471;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#20316;&#32773;&#24402;&#23646;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.07467</link><description>&lt;p&gt;
&#31361;&#30772;&#21452;&#30450;&#35780;&#23457;: &#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20316;&#32773;&#24402;&#23646;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Cracking Double-Blind Review: Authorship Attribution with Deep Learning. (arXiv:2211.07467v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07467
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#20316;&#32773;&#24402;&#23646;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#25991;&#26412;&#20869;&#23481;&#21644;&#21442;&#32771;&#25991;&#29486;&#20013;&#30340;&#20316;&#32773;&#22995;&#21517;&#65292;&#21487;&#20197;&#23558;&#21311;&#21517;&#25163;&#31295;&#27491;&#30830;&#24402;&#23646;&#32473;&#20316;&#32773;&#12290;&#35813;&#26041;&#27861;&#22312;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#20316;&#32773;&#36523;&#20221;&#35782;&#21035;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#65292;&#22312;&#21253;&#21547;&#22810;&#36798;2000&#20010;&#19981;&#21516;&#20316;&#32773;&#30340;arXiv&#23376;&#38598;&#20013;&#65292;&#21462;&#24471;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#20316;&#32773;&#24402;&#23646;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#30450;&#21516;&#34892;&#35780;&#23457;&#34987;&#35748;&#20026;&#26159;&#23398;&#26415;&#30740;&#31350;&#30340;&#22522;&#30707;&#65292;&#22240;&#20026;&#23427;&#34987;&#35748;&#20026;&#21487;&#20197;&#30830;&#20445;&#19968;&#20010;&#20844;&#27491;&#12289;&#26080;&#20559;&#21644;&#20197;&#20107;&#23454;&#20026;&#20013;&#24515;&#30340;&#31185;&#23398;&#35752;&#35770;&#12290;&#28982;&#32780;&#65292;&#26377;&#32463;&#39564;&#30340;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#33021;&#20934;&#30830;&#29468;&#27979;&#20986;&#21311;&#21517;&#25237;&#31295;&#30340;&#30740;&#31350;&#32452;&#26469;&#33258;&#20309;&#26041;&#65292;&#20174;&#32780;&#20351;&#21516;&#34892;&#35780;&#23457;&#36807;&#31243;&#20135;&#29983;&#20559;&#35265;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#23427;&#20165;&#20351;&#29992;&#25991;&#26412;&#20869;&#23481;&#21644;&#21442;&#32771;&#25991;&#29486;&#20013;&#30340;&#20316;&#32773;&#22995;&#21517;&#26469;&#23558;&#21311;&#21517;&#25163;&#31295;&#24402;&#23646;&#32473;&#19968;&#20010;&#20316;&#32773;&#12290;&#20026;&#20102;&#35757;&#32451;&#21644;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#36804;&#20170;&#20026;&#27490;&#26368;&#22823;&#30340;&#20316;&#32773;&#36523;&#20221;&#35782;&#21035;&#25968;&#25454;&#38598;&#12290;&#23427;&#21033;&#29992;&#20102;&#20840;&#37096;&#20844;&#24320;&#30340;arXiv&#30740;&#31350;&#35770;&#25991;&#65292;&#24635;&#35745;&#36229;&#36807;200&#19975;&#31687;&#25163;&#31295;&#12290;&#22312;&#21253;&#21547;&#22810;&#36798;2000&#20010;&#19981;&#21516;&#20316;&#32773;&#30340;arXiv&#23376;&#38598;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#20316;&#32773;&#24402;&#23646;&#20934;&#30830;&#24615;&#65292;&#20854;&#20013;&#22810;&#36798;73%&#30340;&#35770;&#25991;&#34987;&#27491;&#30830;&#24402;&#23646;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#25193;&#23637;&#24615;&#20998;&#26512;&#65292;&#20197;&#31361;&#20986;&#35813;&#26041;&#27861;&#22312;&#26356;&#22823;&#25968;&#25454;&#38598;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double-blind peer review is considered a pillar of academic research because it is perceived to ensure a fair, unbiased, and fact-centered scientific discussion. Yet, experienced researchers can often correctly guess from which research group an anonymous submission originates, biasing the peer-review process. In this work, we present a transformer-based, neural-network architecture that only uses the text content and the author names in the bibliography to attribute an anonymous manuscript to an author. To train and evaluate our method, we created the largest authorship identification dataset to date. It leverages all research papers publicly available on arXiv amounting to over 2 million manuscripts. In arXiv-subsets with up to 2,000 different authors, our method achieves an unprecedented authorship attribution accuracy, where up to 73% of papers are attributed correctly. We present a scaling analysis to highlight the applicability of the proposed method to even larger datasets when 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#33021;&#22815;&#36716;&#24405;&#20195;&#30721;&#20999;&#25442;&#65288;CS&#65289;&#35821;&#38899;&#30340;&#22810;&#35821;&#35328;&#31995;&#32479;&#12290;&#36890;&#36807;&#23558;&#19981;&#21516;&#28304;&#35821;&#35328;&#30340;&#38899;&#39057;&#21644;&#26631;&#31614;&#36830;&#25509;&#36215;&#26469;&#65292;&#21487;&#20197;&#25913;&#21892;&#27169;&#22411;&#22312;&#36716;&#24405;CS&#35821;&#38899;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#21333;&#35821;&#27979;&#35797;&#20013;&#36229;&#36807;&#20102;&#21333;&#35821;&#27169;&#22411;&#12290;&#36825;&#31181;&#22686;&#24378;&#25216;&#26415;&#29978;&#33267;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#22312;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#21477;&#38388;&#35821;&#35328;&#20999;&#25442;&#19978;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.08992</link><description>&lt;p&gt;
&#26080;&#35821;&#35328;&#38480;&#21046;&#30340;&#20195;&#30721;&#20999;&#25442;&#22312;&#24207;&#21015;&#21040;&#24207;&#21015;&#35821;&#38899;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition. (arXiv:2210.08992v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.08992
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#29992;&#20110;&#35757;&#32451;&#33021;&#22815;&#36716;&#24405;&#20195;&#30721;&#20999;&#25442;&#65288;CS&#65289;&#35821;&#38899;&#30340;&#22810;&#35821;&#35328;&#31995;&#32479;&#12290;&#36890;&#36807;&#23558;&#19981;&#21516;&#28304;&#35821;&#35328;&#30340;&#38899;&#39057;&#21644;&#26631;&#31614;&#36830;&#25509;&#36215;&#26469;&#65292;&#21487;&#20197;&#25913;&#21892;&#27169;&#22411;&#22312;&#36716;&#24405;CS&#35821;&#38899;&#19978;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#21333;&#35821;&#27979;&#35797;&#20013;&#36229;&#36807;&#20102;&#21333;&#35821;&#27169;&#22411;&#12290;&#36825;&#31181;&#22686;&#24378;&#25216;&#26415;&#29978;&#33267;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#22312;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#21477;&#38388;&#35821;&#35328;&#20999;&#25442;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#30721;&#20999;&#25442;&#65288;CS&#65289;&#26159;&#25351;&#20132;&#26367;&#20351;&#29992;&#19981;&#21516;&#35821;&#35328;&#30340;&#21333;&#35789;&#21644;&#30701;&#35821;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#29616;&#20170;&#30340;&#31070;&#32463;&#31471;&#21040;&#31471;&#65288;E2E&#65289;&#27169;&#22411;&#22312;&#33258;&#21160;&#35821;&#38899;&#35782;&#21035;&#65288;ASR&#65289;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#20294;&#20247;&#25152;&#21608;&#30693;&#36825;&#20123;&#31995;&#32479;&#38656;&#35201;&#28023;&#37327;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#36716;&#24405;&#21644;&#23545;&#40784;&#30340;CS&#35821;&#38899;&#25968;&#25454;&#24456;&#23569;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#35757;&#32451;&#33021;&#22815;&#36716;&#24405;CS&#35821;&#38899;&#30340;&#22810;&#35821;&#35328;&#31995;&#32479;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#21363;&#23558;&#19981;&#21516;&#28304;&#35821;&#35328;&#30340;&#38899;&#39057;&#21644;&#30456;&#24212;&#26631;&#31614;&#36830;&#25509;&#36215;&#26469;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#20123;&#35757;&#32451;&#25968;&#25454;&#65292;&#25105;&#20204;&#30340;E2E&#27169;&#22411;&#22312;&#36716;&#24405;CS&#35821;&#38899;&#26041;&#38754;&#24471;&#21040;&#20102;&#25913;&#36827;&#12290;&#23427;&#36824;&#22312;&#21333;&#35821;&#27979;&#35797;&#19978;&#36229;&#36807;&#20102;&#21333;&#35821;&#27169;&#22411;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#22686;&#24378;&#25216;&#26415;&#29978;&#33267;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#22312;&#35757;&#32451;&#26399;&#38388;&#26410;&#35265;&#36807;&#30340;&#21477;&#38388;&#35821;&#35328;&#20999;&#25442;&#19978;&#30340;&#24615;&#33021;&#65292;WER&#25552;&#39640;&#20102;5.03%&#12290;
&lt;/p&gt;
&lt;p&gt;
Code-Switching (CS) is referred to the phenomenon of alternately using words and phrases from different languages. While today's neural end-to-end (E2E) models deliver state-of-the-art performances on the task of automatic speech recognition (ASR) it is commonly known that these systems are very data-intensive. However, there is only a few transcribed and aligned CS speech available. To overcome this problem and train multilingual systems which can transcribe CS speech, we propose a simple yet effective data augmentation in which audio and corresponding labels of different source languages are concatenated. By using this training data, our E2E model improves on transcribing CS speech. It also surpasses monolingual models on monolingual tests. The results show that this augmentation technique can even improve the model's performance on inter-sentential language switches not seen during training by 5,03% WER.
&lt;/p&gt;</description></item><item><title>PASTA&#26159;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#24314;&#27169;&#21465;&#36848;&#20013;&#21442;&#19982;&#32773;&#29366;&#24577;&#30340;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25512;&#26029;&#38544;&#21547;&#30340;&#29366;&#24577;&#21644;&#29702;&#35299;&#29366;&#24577;&#21464;&#21270;&#23545;&#21465;&#36848;&#30340;&#24433;&#21709;&#65292;PASTA&#22312;&#19977;&#20010;&#22522;&#20110;&#29366;&#24577;&#30340;&#25512;&#29702;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#29616;&#26377;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#33021;&#22815;&#36827;&#34892;&#29366;&#24577;&#25512;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.00329</link><description>&lt;p&gt;
PASTA: &#19968;&#20221;&#29992;&#20110;&#24314;&#27169;&#21465;&#36848;&#20013;&#21442;&#19982;&#32773;&#29366;&#24577;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
PASTA: A Dataset for Modeling Participant States in Narratives. (arXiv:2208.00329v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.00329
&lt;/p&gt;
&lt;p&gt;
PASTA&#26159;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#24314;&#27169;&#21465;&#36848;&#20013;&#21442;&#19982;&#32773;&#29366;&#24577;&#30340;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#25512;&#26029;&#38544;&#21547;&#30340;&#29366;&#24577;&#21644;&#29702;&#35299;&#29366;&#24577;&#21464;&#21270;&#23545;&#21465;&#36848;&#30340;&#24433;&#21709;&#65292;PASTA&#22312;&#19977;&#20010;&#22522;&#20110;&#29366;&#24577;&#30340;&#25512;&#29702;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#29616;&#26377;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#33021;&#22815;&#36827;&#34892;&#29366;&#24577;&#25512;&#29702;&#65292;&#20294;&#20173;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21465;&#36848;&#20013;&#30340;&#20107;&#20214;&#36890;&#36807;&#21442;&#19982;&#32773;&#30340;&#28508;&#22312;&#29366;&#24577;&#34987;&#29702;&#35299;&#20026;&#19968;&#20010;&#36830;&#36143;&#25972;&#20307;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#21442;&#19982;&#32773;&#29366;&#24577;&#24182;&#27809;&#26377;&#26126;&#30830;&#25552;&#21450;&#65292;&#32780;&#26159;&#38656;&#35201;&#35835;&#32773;&#36827;&#34892;&#25512;&#26029;&#12290;&#19968;&#20010;&#29702;&#35299;&#21465;&#36848;&#30340;&#27169;&#22411;&#24212;&#35813;&#33021;&#22815;&#25512;&#26029;&#36825;&#20123;&#38544;&#21547;&#30340;&#29366;&#24577;&#65292;&#29978;&#33267;&#21487;&#20197;&#25512;&#29702;&#20986;&#36825;&#20123;&#29366;&#24577;&#30340;&#21464;&#21270;&#23545;&#21465;&#36848;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#20247;&#21253;&#33521;&#25991;&#25968;&#25454;&#38598;&#8212;&#8212;&#21442;&#19982;&#32773;&#29366;&#24577;&#25968;&#25454;&#38598;&#65288;PASTA&#65289;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#21253;&#21547;&#20102;&#21487;&#20197;&#25512;&#26029;&#30340;&#21442;&#19982;&#32773;&#29366;&#24577;&#65292;&#27599;&#20010;&#29366;&#24577;&#37117;&#26377;&#19968;&#20010;&#19982;&#20043;&#30456;&#23545;&#24212;&#30340;&#21453;&#20107;&#23454;&#25200;&#21160;&#65292;&#20197;&#21450;&#22914;&#26524;&#21453;&#20107;&#23454;&#25104;&#31435;&#21017;&#21465;&#36848;&#38656;&#35201;&#36827;&#34892;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#20010;&#22522;&#20110;&#29366;&#24577;&#30340;&#25512;&#29702;&#20219;&#21153;&#65292;&#29992;&#20110;&#27979;&#35797;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#25512;&#26029;&#20986;&#19968;&#20010;&#29366;&#24577;&#26159;&#21542;&#34987;&#25925;&#20107;&#25152;&#34164;&#21547;&#12289;&#22312;&#19968;&#20010;&#21453;&#20107;&#23454;&#29366;&#24577;&#30340;&#26465;&#20214;&#19979;&#23545;&#25925;&#20107;&#36827;&#34892;&#20462;&#27491;&#12289;&#20197;&#21450;&#22312;&#20462;&#27491;&#21518;&#30340;&#25925;&#20107;&#20013;&#26368;&#21487;&#33021;&#30340;&#29366;&#24577;&#21464;&#21270;&#26159;&#20160;&#20040;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#29616;&#20170;&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#33021;&#22815;&#36827;&#34892;&#29366;&#24577;&#25512;&#29702;&#65292;&#20294;&#36824;&#23384;&#22312;&#35768;&#22810;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The events in a narrative are understood as a coherent whole via the underlying states of their participants. Often, these participant states are not explicitly mentioned, instead left to be inferred by the reader. A model that understands narratives should likewise infer these implicit states, and even reason about the impact of changes to these states on the narrative. To facilitate this goal, we introduce a new crowdsourced English-language, Participant States dataset, PASTA. This dataset contains inferable participant states; a counterfactual perturbation to each state; and the changes to the story that would be necessary if the counterfactual were true. We introduce three state-based reasoning tasks that test for the ability to infer when a state is entailed by a story, to revise a story conditioned on a counterfactual state, and to explain the most likely state change given a revised story. Experiments show that today's LLMs can reason about states to some degree, but there is la
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PromptRank&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#22810;&#36339;&#36335;&#24452;&#20877;&#25490;&#21517;&#65292;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#30340;&#22810;&#36339;&#38382;&#39064;&#26816;&#32034;&#12290;&#22312;HotpotQA&#25968;&#25454;&#38598;&#19978;&#65292;PromptRank&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20351;&#29992;&#30340;&#22823;&#37327;&#35757;&#32451;&#26679;&#26412;&#65292;&#20165;&#20351;&#29992;128&#20010;&#35757;&#32451;&#31034;&#20363;&#23601;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;</title><link>http://arxiv.org/abs/2205.12650</link><description>&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#31034;&#30340;&#23569;&#26679;&#26412;&#22810;&#36339;&#38382;&#39064;&#20877;&#25490;&#21517;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PromptRank&#26041;&#27861;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#30340;&#22810;&#36339;&#36335;&#24452;&#20877;&#25490;&#21517;&#65292;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#30340;&#22810;&#36339;&#38382;&#39064;&#26816;&#32034;&#12290;&#22312;HotpotQA&#25968;&#25454;&#38598;&#19978;&#65292;PromptRank&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20351;&#29992;&#30340;&#22823;&#37327;&#35757;&#32451;&#26679;&#26412;&#65292;&#20165;&#20351;&#29992;128&#20010;&#35757;&#32451;&#31034;&#20363;&#23601;&#33021;&#36798;&#21040;&#36739;&#39640;&#30340;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24320;&#25918;&#39046;&#22495;&#38382;&#39064;&#30340;&#23569;&#26679;&#26412;&#22810;&#36339;&#38382;&#39064;&#20877;&#25490;&#21517;&#12290;&#20026;&#20102;&#20943;&#23569;&#23545;&#22823;&#37327;&#26631;&#35760;&#30340;&#38382;&#39064;-&#25991;&#26723;&#23545;&#36827;&#34892;&#26816;&#32034;&#22120;&#35757;&#32451;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PromptRank&#65292;&#23427;&#20381;&#36182;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23545;&#22810;&#36339;&#36335;&#24452;&#36827;&#34892;&#20877;&#25490;&#21517;&#12290;PromptRank&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#25351;&#20196;&#30340;&#25552;&#31034;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#20010;&#20505;&#36873;&#25991;&#26723;&#36335;&#24452;&#65292;&#28982;&#21518;&#26681;&#25454;&#35821;&#35328;&#27169;&#22411;&#20013;&#32473;&#23450;&#36335;&#24452;&#25552;&#31034;&#30340;&#26465;&#20214;&#27010;&#29575;&#65292;&#35745;&#31639;&#32473;&#23450;&#38382;&#39064;&#21644;&#36335;&#24452;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#24471;&#20998;&#12290;&#19982;&#22522;&#20110;&#22823;&#37327;&#31034;&#20363;&#35757;&#32451;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#30456;&#27604;&#65292;PromptRank&#22312;&#21482;&#26377;128&#20010;&#35757;&#32451;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#22312;HotpotQA&#19978;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#26816;&#32034;&#24615;&#33021;&#8212;&#8212;PromptRank&#30340;&#21484;&#22238;&#29575;@10&#20026;73.6&#65292;&#32780;PathRetriever&#20026;77.8&#65292;&#22810;&#36339;&#31264;&#23494;&#26816;&#32034;&#20026;77.5&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/mukhal/PromptRank&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study few-shot reranking for multi-hop QA with open-domain questions. To alleviate the need for a large number of labeled question-document pairs for retriever training, we propose PromptRank, which relies on large language models prompting for multi-hop path reranking. PromptRank first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model. PromptRank yields strong retrieval performance on HotpotQA with only 128 training examples compared to state-of-the-art methods trained on thousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever and 77.5 by multi-hop dense retrieval. Code available at https://github.com/mukhal/PromptRank
&lt;/p&gt;</description></item><item><title>ELQA&#26159;&#19968;&#20010;&#20851;&#20110;&#33521;&#35821;&#30340;&#20803;&#35821;&#35328;&#38382;&#39064;&#19982;&#31572;&#26696;&#30340;&#35821;&#26009;&#24211;&#65292;&#21487;&#20197;&#29992;&#20110;&#30740;&#31350;NLU&#27169;&#22411;&#30340;&#20803;&#35821;&#35328;&#33021;&#21147;&#21644;&#35821;&#35328;&#23398;&#20064;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2205.00395</link><description>&lt;p&gt;
ELQA: &#19968;&#20010;&#20851;&#20110;&#33521;&#35821;&#30340;&#20803;&#35821;&#35328;&#38382;&#39064;&#19982;&#31572;&#26696;&#30340;&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
ELQA: A Corpus of Metalinguistic Questions and Answers about English. (arXiv:2205.00395v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.00395
&lt;/p&gt;
&lt;p&gt;
ELQA&#26159;&#19968;&#20010;&#20851;&#20110;&#33521;&#35821;&#30340;&#20803;&#35821;&#35328;&#38382;&#39064;&#19982;&#31572;&#26696;&#30340;&#35821;&#26009;&#24211;&#65292;&#21487;&#20197;&#29992;&#20110;&#30740;&#31350;NLU&#27169;&#22411;&#30340;&#20803;&#35821;&#35328;&#33021;&#21147;&#21644;&#35821;&#35328;&#23398;&#20064;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ELQA&#65292;&#19968;&#20010;&#20851;&#20110;&#33521;&#35821;&#35821;&#35328;&#30340;&#38382;&#39064;&#19982;&#31572;&#26696;&#30340;&#35821;&#26009;&#24211;&#12290;&#35813;&#35821;&#26009;&#24211;&#25910;&#38598;&#33258;&#20004;&#20010;&#22312;&#32447;&#35770;&#22363;&#65292;&#28085;&#30422;&#20016;&#23500;&#30340;&#20027;&#39064;&#65292;&#21253;&#25324;&#35821;&#27861;&#12289;&#24847;&#20041;&#12289;&#27969;&#21033;&#24230;&#21644;&#35789;&#28304;&#12290;&#31572;&#26696;&#21253;&#25324;&#23545;&#33521;&#35821;&#35789;&#27719;&#21644;&#35821;&#27861;&#30340;&#19968;&#33324;&#24615;&#25551;&#36848;&#65292;&#20197;&#21450;&#20851;&#20110;&#29305;&#23450;&#29992;&#27861;&#20363;&#23376;&#30340;&#35299;&#37322;&#65288;&#27491;&#30830;&#21644;&#38169;&#35823;&#65289;&#12290;&#19982;&#22823;&#22810;&#25968;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;&#36825;&#20010;&#35821;&#26009;&#24211;&#26159;&#20803;&#35821;&#35328;&#30340;&#65292;&#21363;&#23427;&#30001;&#35821;&#35328;&#20851;&#20110;&#35821;&#35328;&#30340;&#20869;&#23481;&#32452;&#25104;&#12290;&#22240;&#27492;&#65292;&#23427;&#21487;&#20197;&#20419;&#36827;&#23545;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#27169;&#22411;&#30340;&#20803;&#35821;&#35328;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#20197;&#21450;&#22312;&#35821;&#35328;&#23398;&#20064;&#39046;&#22495;&#30340;&#25945;&#32946;&#24212;&#29992;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#22312;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#19978;&#23450;&#20041;&#20102;&#19968;&#20010;&#33258;&#30001;&#24418;&#24335;&#30340;&#38382;&#31572;&#20219;&#21153;&#65292;&#24182;&#23545;&#22810;&#20010;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#35780;&#20272;&#65292;&#20197;&#20998;&#26512;&#23427;&#20204;&#29983;&#25104;&#20803;&#35821;&#35328;&#31572;&#26696;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the &gt;70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic -- it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20381;&#23384;&#21477;&#27861;&#26641;&#32858;&#21512;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#19981;&#21516;&#35299;&#26512;&#22120;&#30340;&#21487;&#38752;&#24615;&#65292;&#20197;&#25345;&#32493;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#32858;&#21512;&#20381;&#23384;&#21477;&#27861;&#26641;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26641;&#20043;&#38388;&#30340;&#32463;&#20856;&#23545;&#31216;&#36317;&#31163;&#24230;&#37327;&#65292;&#32599;&#23486;&#36874;-&#31119;&#23572;&#20857;&#36317;&#31163;&#30340;&#21152;&#26435;&#21644;&#65292;&#23454;&#29616;&#20102;&#26641;&#32467;&#26500;&#30340;&#30495;&#23454;&#24615;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2201.07905</link><description>&lt;p&gt;
CPTAM: &#20381;&#23384;&#21477;&#27861;&#26641;&#32858;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CPTAM: Constituency Parse Tree Aggregation Method. (arXiv:2201.07905v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.07905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20381;&#23384;&#21477;&#27861;&#26641;&#32858;&#21512;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#19981;&#21516;&#35299;&#26512;&#22120;&#30340;&#21487;&#38752;&#24615;&#65292;&#20197;&#25345;&#32493;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#32858;&#21512;&#20381;&#23384;&#21477;&#27861;&#26641;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26641;&#20043;&#38388;&#30340;&#32463;&#20856;&#23545;&#31216;&#36317;&#31163;&#24230;&#37327;&#65292;&#32599;&#23486;&#36874;-&#31119;&#23572;&#20857;&#36317;&#31163;&#30340;&#21152;&#26435;&#21644;&#65292;&#23454;&#29616;&#20102;&#26641;&#32467;&#26500;&#30340;&#30495;&#23454;&#24615;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20351;&#29992;&#20381;&#23384;&#21477;&#27861;&#20998;&#26512;&#26469;&#26681;&#25454;&#30701;&#35821;&#32467;&#26500;&#35821;&#27861;&#29702;&#35299;&#21477;&#23376;&#30340;&#21477;&#27861;&#32467;&#26500;&#12290;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#20381;&#23384;&#21477;&#27861;&#20998;&#26512;&#22120;&#24050;&#34987;&#25552;&#20986;&#65292;&#20294;&#23427;&#20204;&#23545;&#20110;&#30456;&#21516;&#30340;&#21477;&#23376;&#21487;&#33021;&#20250;&#25552;&#20379;&#19981;&#21516;&#30340;&#32467;&#26524;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35757;&#32451;&#39046;&#22495;&#20043;&#22806;&#30340;&#35821;&#26009;&#24211;&#12290;&#26412;&#25991;&#37319;&#29992;&#30495;&#23454;&#24615;&#21457;&#29616;&#30340;&#24605;&#24819;&#65292;&#36890;&#36807;&#20272;&#35745;&#19981;&#21516;&#35299;&#26512;&#22120;&#30340;&#21487;&#38752;&#24615;&#26469;&#32858;&#21512;&#26469;&#33258;&#19981;&#21516;&#35299;&#26512;&#22120;&#30340;&#20381;&#23384;&#21477;&#27861;&#26641;&#65292;&#20197;&#25345;&#32493;&#33719;&#24471;&#39640;&#36136;&#37327;&#30340;&#32858;&#21512;&#20381;&#23384;&#21477;&#27861;&#26641;&#12290;&#25105;&#20204;&#23558;&#20381;&#23384;&#21477;&#27861;&#26641;&#32858;&#21512;&#38382;&#39064;&#20998;&#20026;&#20004;&#20010;&#27493;&#39588;&#65306;&#32467;&#26500;&#32858;&#21512;&#21644;&#25104;&#20998;&#26631;&#31614;&#32858;&#21512;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#29992;&#20110;&#26641;&#32467;&#26500;&#30340;&#30495;&#23454;&#24615;&#21457;&#29616;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20004;&#20010;&#26641;&#20043;&#38388;&#30340;&#32463;&#20856;&#23545;&#31216;&#36317;&#31163;&#24230;&#37327;&#65292;&#21363;&#32599;&#23486;&#36874;-&#31119;&#23572;&#20857;&#36317;&#31163;&#30340;&#21152;&#26435;&#21644;&#12290;&#23545;&#19981;&#21516;&#35821;&#35328;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diverse Natural Language Processing tasks employ constituency parsing to understand the syntactic structure of a sentence according to a phrase structure grammar. Many state-of-the-art constituency parsers are proposed, but they may provide different results for the same sentences, especially for corpora outside their training domains. This paper adopts the truth discovery idea to aggregate constituency parse trees from different parsers by estimating their reliability in the absence of ground truth. Our goal is to consistently obtain high-quality aggregated constituency parse trees. We formulate the constituency parse tree aggregation problem in two steps, structure aggregation and constituent label aggregation. Specifically, we propose the first truth discovery solution for tree structures by minimizing the weighted sum of Robinson-Foulds (RF) distances, a classic symmetric distance metric between two trees. Extensive experiments are conducted on benchmark datasets in different langu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#31995;&#32479;&#20132;&#20114;&#27169;&#22411;&#65292;&#24182;&#19981;&#20381;&#36182;&#20110;&#23383;&#31526;&#21040;&#27010;&#24565;&#30340;&#8220;&#24515;&#29702;&#8221;&#26144;&#23556;&#65292;&#26469;&#29702;&#35299;&#20132;&#20114;&#20013;&#23383;&#31526;&#30340;&#8220;&#21547;&#20041;&#8221;&#12290;</title><link>http://arxiv.org/abs/2007.06258</link><description>&lt;p&gt;
&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A model of interaction semantics. (arXiv:2007.06258v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.06258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;&#65292;&#36890;&#36807;&#26500;&#24314;&#31995;&#32479;&#20132;&#20114;&#27169;&#22411;&#65292;&#24182;&#19981;&#20381;&#36182;&#20110;&#23383;&#31526;&#21040;&#27010;&#24565;&#30340;&#8220;&#24515;&#29702;&#8221;&#26144;&#23556;&#65292;&#26469;&#29702;&#35299;&#20132;&#20114;&#20013;&#23383;&#31526;&#30340;&#8220;&#21547;&#20041;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20132;&#20114;&#20013;&#8220;&#21547;&#20041;&#8221;&#29702;&#35299;&#30340;&#26576;&#31181;&#35266;&#28857;&#12290;&#36890;&#36807;&#26500;&#24314;&#31995;&#32479;&#20132;&#20114;&#27169;&#22411;&#65292;&#25105;&#23558;&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;&#32467;&#26500;&#21270;&#65292;&#31867;&#20284;&#20110;&#24418;&#24335;&#35821;&#35328;&#30340;&#35821;&#20041;&#65306;&#39318;&#20808;&#65292;&#25105;&#30830;&#23450;&#36866;&#24403;&#30340;&#21464;&#37327;&#20197;&#36171;&#20540;&#65292;&#28982;&#21518;&#65292;&#25105;&#30830;&#23450;&#35299;&#37322;&#20989;&#25968;&#20197;&#25552;&#20379;&#24847;&#20041;&#12290;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#20132;&#20114;&#35821;&#20041;&#27169;&#22411;&#65292;&#21487;&#20197;&#19981;&#20381;&#36182;&#20110;&#20174;&#23383;&#31526;&#21040;&#27010;&#24565;&#30340;&#8220;&#24515;&#29702;&#8221;&#26144;&#23556;&#65292;&#36825;&#19982;&#36335;&#24503;&#32500;&#24076;&#183;&#32500;&#29305;&#26681;&#26031;&#22374;&#30340;&#35266;&#28857;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Purpose: The purpose of this article is to propose, based on a model of an interaction semantics, a certain understanding of the ''meaning'' of the exchanged characters within an interaction.  Methodology: Based on a model of system interaction, I structure the model of interaction semantics similar to the semantics of a formal language: first, I identify adequate variables in my interaction model to assign values to, and second, I identify the interpretation function to provide meaning. Thereby I arrive at a model of interaction semantics which, in the sense of the late Ludwig Wittgenstein, can do without a 'mental' mapping from characters to concepts.  Findings: The key findings are a better understanding of the tight relation between the informatical approach to model interactions and game theory; of the central 'chicken and egg' problem, any natural language has to solve, namely that to interact sensibly, we have to understand each other and to acquire a common understanding, we ha
&lt;/p&gt;</description></item></channel></rss>