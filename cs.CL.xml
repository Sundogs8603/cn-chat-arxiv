<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>IDMO&#39033;&#30446;&#26088;&#22312;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#25171;&#20987;&#34394;&#20551;&#20449;&#24687;&#21644;&#20551;&#26032;&#38395;&#65292;&#20854;&#36129;&#29486;&#21253;&#25324;&#21019;&#24314;&#26032;&#22411;&#25968;&#25454;&#38598;&#12289;&#24320;&#21457;&#33258;&#21160;&#27169;&#22411;&#12289;&#35780;&#20272;GPT-4&#31561;&#12290;</title><link>http://arxiv.org/abs/2310.11097</link><description>&lt;p&gt;
&#29992;&#20110;&#25171;&#20987;&#34394;&#20551;&#20449;&#24687;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#23454;&#39564;&#65306;IDMO&#39033;&#30446;
&lt;/p&gt;
&lt;p&gt;
Experimenting AI Technologies for Disinformation Combat: the IDMO Project. (arXiv:2310.11097v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11097
&lt;/p&gt;
&lt;p&gt;
IDMO&#39033;&#30446;&#26088;&#22312;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#25171;&#20987;&#34394;&#20551;&#20449;&#24687;&#21644;&#20551;&#26032;&#38395;&#65292;&#20854;&#36129;&#29486;&#21253;&#25324;&#21019;&#24314;&#26032;&#22411;&#25968;&#25454;&#38598;&#12289;&#24320;&#21457;&#33258;&#21160;&#27169;&#22411;&#12289;&#35780;&#20272;GPT-4&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24847;&#22823;&#21033;&#25968;&#23383;&#23186;&#20307;&#35266;&#23519;&#39033;&#30446;&#65288;IDMO&#65289;&#26159;&#27431;&#27954;&#19968;&#39033;&#20513;&#35758;&#30340;&#19968;&#37096;&#20998;&#65292;&#19987;&#27880;&#20110;&#25171;&#20987;&#34394;&#20551;&#20449;&#24687;&#21644;&#20551;&#26032;&#38395;&#12290;&#26412;&#25253;&#21578;&#27010;&#36848;&#20102;Rai-CRITS&#22312;&#35813;&#39033;&#30446;&#20013;&#30340;&#36129;&#29486;&#65292;&#21253;&#25324;&#65306;&#65288;i&#65289;&#21019;&#24314;&#29992;&#20110;&#27979;&#35797;&#25216;&#26415;&#30340;&#26032;&#22411;&#25968;&#25454;&#38598;&#65292;&#65288;ii&#65289;&#24320;&#21457;&#33258;&#21160;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#31867;Pagella Politica&#30340;&#35009;&#20915;&#20197;&#20415;&#20110;&#26356;&#24191;&#27867;&#30340;&#20998;&#26512;&#65292;&#65288;iii&#65289;&#21019;&#24314;&#33258;&#21160;&#27169;&#22411;&#65292;&#23545;FEVER&#25968;&#25454;&#38598;&#19978;&#30340;&#25991;&#26412;&#34164;&#21547;&#20855;&#26377;&#24322;&#24120;&#31934;&#24230;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#65288;iv&#65289;&#20351;&#29992;GPT-4&#35780;&#20272;&#25991;&#26412;&#34164;&#21547;&#65292; &#65288;v&#65289;&#22312;&#22269;&#23478;&#27963;&#21160;&#20013;&#24320;&#23637;&#25552;&#39640;&#23545;&#20551;&#26032;&#38395;&#24847;&#35782;&#30340;&#28216;&#25103;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Italian Digital Media Observatory (IDMO) project, part of a European initiative, focuses on countering disinformation and fake news. This report outlines contributions from Rai-CRITS to the project, including: (i) the creation of novel datasets for testing technologies (ii) development of an automatic model for categorizing Pagella Politica verdicts to facilitate broader analysis (iii) creation of an automatic model for recognizing textual entailment with exceptional accuracy on the FEVER dataset (iv) assessment using GPT-4 to identify textual entailmen (v) a game to raise awareness about fake news at national events.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#31934;&#31616;&#29305;&#24449;&#22330;&#65292;&#23558;&#31934;&#30830;&#30340;3D&#20960;&#20309;&#19982;2D&#22522;&#30784;&#27169;&#22411;&#30340;&#20016;&#23500;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#35265;&#36807;&#30340;&#29289;&#20307;&#30340;&#23569;&#26679;&#26412;&#25805;&#20316;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.07931</link><description>&lt;p&gt;
&#31934;&#31616;&#29305;&#24449;&#22330;&#20351;&#24471;&#35821;&#35328;&#24341;&#23548;&#30340;&#23569;&#26679;&#26412;&#25805;&#20316;&#25104;&#20026;&#21487;&#33021;
&lt;/p&gt;
&lt;p&gt;
Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation. (arXiv:2308.07931v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#31934;&#31616;&#29305;&#24449;&#22330;&#65292;&#23558;&#31934;&#30830;&#30340;3D&#20960;&#20309;&#19982;2D&#22522;&#30784;&#27169;&#22411;&#30340;&#20016;&#23500;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#23545;&#26410;&#35265;&#36807;&#30340;&#29289;&#20307;&#30340;&#23569;&#26679;&#26412;&#25805;&#20316;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#21644;&#35821;&#35328;&#30417;&#30563;&#30340;&#22270;&#20687;&#27169;&#22411;&#21253;&#21547;&#20102;&#19990;&#30028;&#30340;&#20016;&#23500;&#30693;&#35782;&#65292;&#23545;&#20110;&#27867;&#21270;&#24456;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26426;&#22120;&#20154;&#20219;&#21153;&#38656;&#35201;&#23545; 3D &#20960;&#20309;&#30340;&#35814;&#32454;&#29702;&#35299;&#65292;&#36825;&#22312; 2D &#22270;&#20687;&#29305;&#24449;&#20013;&#24448;&#24448;&#32570;&#20047;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;&#31934;&#31616;&#29305;&#24449;&#22330;&#65292;&#23558;&#31934;&#30830;&#30340; 3D &#20960;&#20309;&#19982; 2D &#22522;&#30784;&#27169;&#22411;&#30340;&#20016;&#23500;&#35821;&#20041;&#30456;&#32467;&#21512;&#65292;&#26469;&#24357;&#21512;&#26426;&#22120;&#20154;&#25805;&#20316;&#20013;&#30340; 2D &#21040; 3D &#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#38024;&#23545; 6 &#33258;&#30001;&#24230;&#25235;&#21462;&#21644;&#25918;&#32622;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#24378;&#22823;&#30340;&#31354;&#38388;&#21644;&#35821;&#20041;&#20808;&#39564;&#65292;&#23454;&#29616;&#23545;&#26410;&#35265;&#36807;&#30340;&#29289;&#20307;&#30340;&#33258;&#28982;&#27867;&#21270;&#12290;&#36890;&#36807;&#20174;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411; CLIP &#20013;&#31934;&#31616;&#30340;&#29305;&#24449;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#36890;&#36807;&#33258;&#30001;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#25351;&#23450;&#26032;&#39062;&#23545;&#35937;&#36827;&#34892;&#25805;&#20316;&#30340;&#26041;&#24335;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#26410;&#35265;&#36807;&#30340;&#34920;&#36798;&#21644;&#26032;&#39062;&#31867;&#21035;&#30340;&#29289;&#20307;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised and language-supervised image models contain rich knowledge of the world that is important for generalization. Many robotic tasks, however, require a detailed understanding of 3D geometry, which is often lacking in 2D image features. This work bridges this 2D-to-3D gap for robotic manipulation by leveraging distilled feature fields to combine accurate 3D geometry with rich semantics from 2D foundation models. We present a few-shot learning method for 6-DOF grasping and placing that harnesses these strong spatial and semantic priors to achieve in-the-wild generalization to unseen objects. Using features distilled from a vision-language model, CLIP, we present a way to designate novel objects for manipulation via free-text natural language, and demonstrate its ability to generalize to unseen expressions and novel categories of objects.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;ChatGPT&#22312;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#20316;&#29992;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#37327;&#26041;&#27861;&#8220;&#27874;&#20848;&#27604;&#29575;&#8221;&#65292;&#29992;&#20110;&#26816;&#27979;ChatGPT&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#30340;&#28041;&#21450;&#31243;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;HPPT&#65292;&#29992;&#20110;&#26500;&#24314;&#26356;&#31283;&#20581;&#30340;&#26816;&#27979;&#22120;&#12290;</title><link>http://arxiv.org/abs/2307.11380</link><description>&lt;p&gt;
&#32842;&#22825;GPT&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#26159;&#21542;&#28041;&#21450;ChatGPT&#65311;&#36890;&#36807;&#27979;&#37327;&#8220;&#27874;&#20848;&#27604;&#29575;&#8221;&#26469;&#26816;&#27979;ChatGPT&#29983;&#25104;&#30340;&#25991;&#26412;
&lt;/p&gt;
&lt;p&gt;
Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect ChatGPT-Generated Text. (arXiv:2307.11380v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;ChatGPT&#22312;&#25991;&#26412;&#29983;&#25104;&#20013;&#30340;&#20316;&#29992;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#37327;&#26041;&#27861;&#8220;&#27874;&#20848;&#27604;&#29575;&#8221;&#65292;&#29992;&#20110;&#26816;&#27979;ChatGPT&#29983;&#25104;&#30340;&#25991;&#26412;&#20013;&#30340;&#28041;&#21450;&#31243;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#25454;&#38598;HPPT&#65292;&#29992;&#20110;&#26500;&#24314;&#26356;&#31283;&#20581;&#30340;&#26816;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#22914;ChatGPT&#22312;&#25991;&#26412;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#33021;&#21147;&#65292;&#36825;&#28608;&#21457;&#20102;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#26816;&#27979;&#22120;&#20197;&#20943;&#36731;&#28508;&#22312;&#39118;&#38505;&#65292;&#21253;&#25324;&#38169;&#35823;&#20449;&#24687;&#12289;&#32593;&#32476;&#38035;&#40060;&#21644;&#23398;&#26415;&#19981;&#35802;&#23454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20197;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#38024;&#23545;&#21306;&#20998;&#32431;&#31929;&#30001;ChatGPT&#29983;&#25104;&#30340;&#25991;&#26412;&#21644;&#20154;&#24037;&#25776;&#20889;&#30340;&#25991;&#26412;&#30340;&#26816;&#27979;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#21306;&#20998;&#36890;&#36807;&#20154;&#26426;&#21327;&#20316;&#29983;&#25104;&#30340;&#25991;&#26412;&#65288;&#20363;&#22914;ChatGPT&#28070;&#33394;&#30340;&#25991;&#26412;&#65289;&#19978;&#22833;&#25928;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#25968;&#25454;&#38598;HPPT&#65288;ChatGPT&#28070;&#33394;&#30340;&#23398;&#26415;&#25688;&#35201;&#65289;&#65292;&#20197;&#26500;&#24314;&#26356;&#24378;&#22823;&#30340;&#26816;&#27979;&#22120;&#12290;&#35813;&#25968;&#25454;&#38598;&#19982;&#29616;&#26377;&#35821;&#26009;&#24211;&#19981;&#21516;&#65292;&#23427;&#21253;&#25324;&#20154;&#24037;&#25776;&#20889;&#30340;&#25991;&#26412;&#21644;ChatGPT&#28070;&#33394;&#30340;&#25688;&#35201;&#23545;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;ChatGPT&#29983;&#25104;&#30340;&#25991;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#27874;&#20848;&#27604;&#29575;&#8221;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;ChatGPT&#22312;&#25991;&#26412;&#29983;&#25104;&#20013;&#21442;&#19982;&#31243;&#24230;&#30340;&#21019;&#26032;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable capabilities of large-scale language models, such as ChatGPT, in text generation have incited awe and spurred researchers to devise detectors to mitigate potential risks, including misinformation, phishing, and academic dishonesty. Despite this, most previous studies, including HC3, have been predominantly geared towards creating detectors that differentiate between purely ChatGPT-generated texts and human-authored texts. This approach, however, fails to work on discerning texts generated through human-machine collaboration, such as ChatGPT-polished texts. Addressing this gap, we introduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts), facilitating the construction of more robust detectors. It diverges from extant corpora by comprising pairs of human-written and ChatGPT-polished abstracts instead of purely ChatGPT-generated texts. Additionally, we propose the "Polish Ratio" method, an innovative measure of ChatGPT's involvement in text generation base
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;&#65288;Corr2Cause&#65289;&#65292;&#29992;&#20110;&#27979;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#34920;&#29616;&#24456;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.05836</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#20174;&#30456;&#20851;&#24615;&#20013;&#25512;&#26029;&#20986;&#22240;&#26524;&#20851;&#31995;?
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;&#65288;Corr2Cause&#65289;&#65292;&#29992;&#20110;&#27979;&#37327;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#22312;&#36825;&#20010;&#20219;&#21153;&#19978;&#34920;&#29616;&#24456;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#20154;&#31867;&#26234;&#24935;&#30340;&#26631;&#24535;&#20043;&#19968;&#12290;&#34429;&#28982;CausalNLP&#39046;&#22495;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;NLP&#20013;&#29616;&#26377;&#30340;&#22240;&#26524;&#25512;&#26029;&#25968;&#25454;&#38598;&#20027;&#35201;&#20381;&#36182;&#20110;&#20174;&#32463;&#39564;&#30693;&#35782;&#65288;&#20363;&#22914;&#24120;&#35782;&#30693;&#35782;&#65289;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#27979;&#35797;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#32431;&#22240;&#26524;&#25512;&#26029;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#26032;&#30340;&#20219;&#21153;Corr2Cause&#65292;&#23427;&#37319;&#29992;&#19968;&#32452;&#30456;&#20851;&#35821;&#21477;&#24182;&#30830;&#23450;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#25105;&#20204;&#31574;&#21010;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#36229;&#36807;400K&#20010;&#26679;&#26412;&#65292;&#25105;&#20204;&#22312;&#20854;&#20013;&#35780;&#20272;&#20102;17&#20010;&#29616;&#26377;&#30340;LLMs&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;LLMs&#22312;&#22240;&#26524;&#25512;&#26029;&#25216;&#33021;&#26041;&#38754;&#30340;&#19968;&#20010;&#20851;&#38190;&#32570;&#38519;&#65292;&#24182;&#34920;&#26126;&#36825;&#20123;&#27169;&#22411;&#22312;&#35813;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#20960;&#20046;&#25509;&#36817;&#38543;&#26426;&#12290;&#24403;&#25105;&#20204;&#23581;&#35797;&#36890;&#36807;&#24494;&#35843;&#23558;LLMs&#37325;&#26032;&#29992;&#20110;&#36825;&#31181;&#25216;&#33021;&#26102;&#65292;&#36825;&#31181;&#32570;&#38519;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#24471;&#21040;&#20102;&#32531;&#35299;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#20173;&#28982;&#22833;&#36133;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 400K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fa
&lt;/p&gt;</description></item><item><title>WikiSQE&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#32500;&#22522;&#30334;&#31185;&#20013;&#21477;&#23376;&#36136;&#37327;&#20272;&#35745;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#32422;3.4M&#20010;&#21477;&#23376;&#21644;153&#20010;&#36136;&#37327;&#26631;&#31614;&#12290;&#22312;&#36825;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20855;&#26377;&#24341;&#25991;&#12289;&#35821;&#27861;/&#35821;&#20041;&#25110;&#21629;&#39064;&#38382;&#39064;&#30340;&#21477;&#23376;&#26356;&#38590;&#20197;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2305.05928</link><description>&lt;p&gt;
WikiSQE&#65306;&#32500;&#22522;&#30334;&#31185;&#20013;&#21477;&#23376;&#36136;&#37327;&#20272;&#35745;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
WikiSQE: A Large-Scale Dataset for Sentence Quality Estimation in Wikipedia. (arXiv:2305.05928v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05928
&lt;/p&gt;
&lt;p&gt;
WikiSQE&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#32500;&#22522;&#30334;&#31185;&#20013;&#21477;&#23376;&#36136;&#37327;&#20272;&#35745;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#32422;3.4M&#20010;&#21477;&#23376;&#21644;153&#20010;&#36136;&#37327;&#26631;&#31614;&#12290;&#22312;&#36825;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20855;&#26377;&#24341;&#25991;&#12289;&#35821;&#27861;/&#35821;&#20041;&#25110;&#21629;&#39064;&#38382;&#39064;&#30340;&#21477;&#23376;&#26356;&#38590;&#20197;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#22522;&#30334;&#31185;&#21487;&#20197;&#34987;&#20219;&#20309;&#20154;&#32534;&#36753;&#65292;&#22240;&#27492;&#21253;&#21547;&#21508;&#31181;&#36136;&#37327;&#30340;&#21477;&#23376;&#12290;&#22240;&#27492;&#65292;&#32500;&#22522;&#30334;&#31185;&#21253;&#21547;&#19968;&#20123;&#36136;&#37327;&#36739;&#24046;&#30340;&#32534;&#36753;&#65292;&#36825;&#20123;&#32534;&#36753;&#36890;&#24120;&#20250;&#34987;&#20854;&#20182;&#32534;&#36753;&#26631;&#35760;&#12290;&#34429;&#28982;&#32534;&#36753;&#30340;&#35780;&#35770;&#22686;&#24378;&#20102;&#32500;&#22522;&#30334;&#31185;&#30340;&#21487;&#20449;&#24230;&#65292;&#20294;&#24456;&#38590;&#26816;&#26597;&#25152;&#26377;&#32534;&#36753;&#30340;&#25991;&#26412;&#12290;&#21327;&#21161;&#36825;&#20010;&#36807;&#31243;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#30446;&#21069;&#36824;&#27809;&#26377;&#19968;&#20010;&#22823;&#32780;&#20840;&#38754;&#30340;&#25968;&#25454;&#38598;&#26469;&#30740;&#31350;&#23427;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; WikiSQE&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#32500;&#22522;&#30334;&#31185;&#20013;&#21477;&#23376;&#36136;&#37327;&#20272;&#35745;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#27599;&#20010;&#21477;&#23376;&#37117;&#26159;&#20174;&#32500;&#22522;&#30334;&#31185;&#30340;&#25972;&#20010;&#20462;&#35746;&#21382;&#21490;&#20013;&#25552;&#21462;&#30340;&#65292;&#24182;&#19988;&#30446;&#26631;&#36136;&#37327;&#26631;&#31614;&#32463;&#36807;&#20102;&#20180;&#32454;&#30340;&#35843;&#26597;&#21644;&#36873;&#25321;&#12290;WikiSQE&#20855;&#26377;&#32422;3.4 million&#20010;&#21477;&#23376;&#21644;153&#20010;&#36136;&#37327;&#26631;&#31614;&#12290;&#22312;&#20351;&#29992;&#31454;&#20105;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#33258;&#21160;&#20998;&#31867;&#30340;&#23454;&#39564;&#20013;&#65292;&#21457;&#29616;&#20855;&#26377;&#24341;&#25991;&#65292;&#35821;&#27861;/&#35821;&#20041;&#25110;&#21629;&#39064;&#38382;&#39064;&#30340;&#21477;&#23376;&#26356;&#38590;&#20197;&#26816;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#33258;&#21160;&#20316;&#25991;&#35780;&#20998;&#23454;&#39564;&#65292;&#20197;&#35780;&#20272;&#29983;&#25104;&#25688;&#35201;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wikipedia can be edited by anyone and thus contains various quality sentences. Therefore, Wikipedia includes some poor-quality edits, which are often marked up by other editors. While editors' reviews enhance the credibility of Wikipedia, it is hard to check all edited text. Assisting in this process is very important, but a large and comprehensive dataset for studying it does not currently exist. Here, we propose WikiSQE, the first large-scale dataset for sentence quality estimation in Wikipedia. Each sentence is extracted from the entire revision history of Wikipedia, and the target quality labels were carefully investigated and selected. WikiSQE has about 3.4 M sentences with 153 quality labels. In the experiment with automatic classification using competitive machine learning models, sentences that had problems with citation, syntax/semantics, or propositions were found to be more difficult to detect. In addition, we conducted automated essay scoring experiments to evaluate the gen
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#23398;&#29983;&#20889;&#20316;&#20013;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#26377;&#19968;&#23450;&#22909;&#22788;&#65292;&#20294;&#36807;&#24230;&#20381;&#36182;&#27492;&#31867;&#24037;&#20855;&#20063;&#23384;&#22312;&#28508;&#22312;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2304.02478</link><description>&lt;p&gt;
&#25506;&#32034;&#23398;&#29983;&#20889;&#20316;&#20013;&#30340;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#65306;AI&#33021;&#36215;&#21040;&#20160;&#20040;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Exploring AI-Generated Text in Student Writing: How Does AI Help?. (arXiv:2304.02478v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02478
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#23398;&#29983;&#20889;&#20316;&#20013;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#26377;&#19968;&#23450;&#22909;&#22788;&#65292;&#20294;&#36807;&#24230;&#20381;&#36182;&#27492;&#31867;&#24037;&#20855;&#20063;&#23384;&#22312;&#28508;&#22312;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#33521;&#35821;&#20316;&#20026;&#22806;&#35821;&#30340;&#23398;&#29983;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#24037;&#20855;&#29983;&#25104;&#30340;&#25991;&#26412;&#21487;&#33021;&#20250;&#25552;&#39640;&#20182;&#20204;&#30340;&#20889;&#20316;&#36136;&#37327;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#36825;&#20123;&#23398;&#29983;&#30340;&#20889;&#20316;&#20013;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#20250;&#23548;&#33268;&#26356;&#39640;&#36136;&#37327;&#30340;&#20889;&#20316;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;23&#21517;&#39321;&#28207;&#20013;&#23398;&#29983;&#25776;&#20889;&#25925;&#20107;&#65288;&#21253;&#21547;&#33258;&#24049;&#30340;&#25991;&#23383;&#21644;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#30340;&#25991;&#26412;&#65289;&#30340;&#23581;&#35797;&#12290;&#20154;&#31867;&#19987;&#23478;&#23545;&#36825;&#20123;&#25925;&#20107;&#36827;&#34892;&#20102;&#20869;&#23481;&#12289;&#35821;&#35328;&#21644;&#32452;&#32455;&#26041;&#38754;&#30340;&#35780;&#20998;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25925;&#20107;&#20013;&#30340;AI&#29983;&#25104;&#25991;&#26412;&#30340;&#22522;&#26412;&#32452;&#32455;&#32467;&#26500;&#21644;&#21477;&#27861;&#22797;&#26434;&#24230;&#65292;&#24182;&#25191;&#34892;&#20102;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#21644;&#32858;&#31867;&#20998;&#26512;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20154;&#31867;&#35789;&#35821;&#30340;&#25968;&#37327;&#21644;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#35789;&#35821;&#30340;&#25968;&#37327;&#23545;&#20998;&#25968;&#26377;&#37325;&#35201;&#36129;&#29486;&#12290;&#27492;&#22806;&#65292;&#19982;&#21516;&#40836;&#20154;&#30456;&#27604;&#65292;&#23398;&#29983;&#30340;&#20889;&#20316;&#21487;&#20197;&#20998;&#20026;&#25797;&#38271;&#21644;&#19981;&#25797;&#38271;&#20351;&#29992;&#26356;&#22810;&#25110;&#26356;&#23569;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#30340;&#20004;&#32452;&#12290;&#32858;&#31867;&#27604;&#36739;&#26174;&#31034;&#65292;&#20351;&#29992;&#20154;&#24037;&#26234;&#33021;&#29983;&#25104;&#25991;&#26412;&#22312;&#23398;&#29983;&#20889;&#20316;&#20013;&#26377;&#19968;&#23450;&#22909;&#22788;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#35843;&#20102;&#36807;&#24230;&#20381;&#36182;&#36825;&#31181;&#24037;&#20855;&#30340;&#28508;&#22312;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
English as foreign language_EFL_students' use of text generated from artificial intelligence_AI_natural language generation_NLG_tools may improve their writing quality. However, it remains unclear to what extent AI-generated text in these students' writing might lead to higher-quality writing. We explored 23 Hong Kong secondary school students' attempts to write stories comprising their own words and AI-generated text. Human experts scored the stories for dimensions of content, language and organization. We analyzed the basic organization and structure and syntactic complexity of the stories' AI-generated text and performed multiple linear regression and cluster analyses. The results show the number of human words and the number of AI-generated words contribute significantly to scores. Besides, students can be grouped into competent and less competent writers who use more AI-generated text or less AI-generated text compared to their peers. Comparisons of clusters reveal some benefit of
&lt;/p&gt;</description></item></channel></rss>