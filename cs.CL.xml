<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#30740;&#31350;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#22797;&#26434;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65292;&#21457;&#29616;&#21363;&#20351;&#32570;&#20047;&#35270;&#35273;&#36755;&#20837;&#65292;&#21033;&#29992;&#25152;&#26377;&#32452;&#20214;&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#24674;&#22797;&#22823;&#37096;&#20998;VLM&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;&#35821;&#35328;&#36890;&#36807;&#25552;&#20379;&#23545;&#20808;&#21069;&#30693;&#35782;&#21644;&#25512;&#29702;&#30340;&#35775;&#38382;&#26469;&#23545;&#23398;&#20064;&#26032;&#20219;&#21153;&#26377;&#36129;&#29486;</title><link>https://arxiv.org/abs/2403.19669</link><description>&lt;p&gt;
&#20998;&#26512;&#35821;&#35328;&#21644;&#35270;&#35273;&#22312;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Analyzing the Roles of Language and Vision in Learning from Limited Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19669
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#22797;&#26434;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65292;&#21457;&#29616;&#21363;&#20351;&#32570;&#20047;&#35270;&#35273;&#36755;&#20837;&#65292;&#21033;&#29992;&#25152;&#26377;&#32452;&#20214;&#30340;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#24674;&#22797;&#22823;&#37096;&#20998;VLM&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;&#35821;&#35328;&#36890;&#36807;&#25552;&#20379;&#23545;&#20808;&#21069;&#30693;&#35782;&#21644;&#25512;&#29702;&#30340;&#35775;&#38382;&#26469;&#23545;&#23398;&#20064;&#26032;&#20219;&#21153;&#26377;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19669v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#20132;&#21449;&#25688;&#35201;&#65306;&#35821;&#35328;&#26159;&#21542;&#26377;&#21161;&#20110;&#29702;&#35299;&#35270;&#35273;&#19990;&#30028;&#65311;&#23454;&#38469;&#35266;&#23519;&#19990;&#30028;&#38656;&#35201;&#30475;&#21040;&#23454;&#38469;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#29992;&#25991;&#23383;&#25551;&#36848;&#21527;&#65311;&#20851;&#20110;&#26234;&#33021;&#26412;&#36136;&#30340;&#36825;&#20123;&#22522;&#26412;&#38382;&#39064;&#24456;&#38590;&#22238;&#31572;&#65292;&#22240;&#20026;&#25105;&#20204;&#21482;&#26377;&#19968;&#20010;&#26234;&#33021;&#31995;&#32479;&#30340;&#20363;&#23376;&#8212;&#8212;&#20154;&#31867;&#8212;&#8212;&#20197;&#21450;&#26377;&#38480;&#30340;&#29420;&#31435;&#35821;&#35328;&#25110;&#35270;&#35273;&#30340;&#26696;&#20363;&#12290;&#28982;&#32780;&#65292;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20986;&#22797;&#26434;&#30340;&#35270;&#35273;-&#35821;&#35328;&#27169;&#22411;&#65288;VLMs&#65289;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#26426;&#20250;&#65292;&#25506;&#32034;&#35821;&#35328;&#21644;&#35270;&#35273;&#23545;&#20110;&#23398;&#20064;&#19990;&#30028;&#30340;&#36129;&#29486;&#12290;&#25105;&#20204;&#20174;&#36825;&#20123;&#27169;&#22411;&#30340;&#35748;&#30693;&#26550;&#26500;&#20013;&#20999;&#38500;&#32452;&#20214;&#65292;&#20197;&#30830;&#23450;&#23427;&#20204;&#23545;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#23398;&#20064;&#26032;&#20219;&#21153;&#30340;&#36129;&#29486;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21033;&#29992;&#25152;&#26377;&#32452;&#20214;&#30340;&#35821;&#35328;&#27169;&#22411;&#24674;&#22797;&#20102;&#22823;&#37096;&#20998;VLM&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#23427;&#32570;&#20047;&#35270;&#35273;&#36755;&#20837;&#65292;&#32780;&#35821;&#35328;&#20284;&#20046;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#23545;&#20808;&#21069;&#30693;&#35782;&#21644;&#25512;&#29702;&#30340;&#35775;&#38382;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19669v1 Announce Type: cross  Abstract: Does language help make sense of the visual world? How important is it to actually see the world rather than having it described with words? These basic questions about the nature of intelligence have been difficult to answer because we only had one example of an intelligent system -- humans -- and limited access to cases that isolated language or vision. However, the development of sophisticated Vision-Language Models (VLMs) by artificial intelligence researchers offers us new opportunities to explore the contributions that language and vision make to learning about the world. We ablate components from the cognitive architecture of these models to identify their contributions to learning new tasks from limited data. We find that a language model leveraging all components recovers a majority of a VLM's performance, despite its lack of visual input, and that language seems to allow this by providing access to prior knowledge and reasoni
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;160,230&#20010;&#25552;&#31034;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;TriviaHG&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#26041;&#27861;&#26469;&#34913;&#37327;&#25552;&#31034;&#30340;&#36136;&#37327;&#23646;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.18426</link><description>&lt;p&gt;
TriviaHG&#65306;&#29992;&#20110;&#20174;&#20107;&#23454;&#24615;&#38382;&#39064;&#29983;&#25104;&#33258;&#21160;&#25552;&#31034;&#30340;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18426
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#30340;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#21253;&#21547;160,230&#20010;&#25552;&#31034;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;TriviaHG&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#26041;&#27861;&#26469;&#34913;&#37327;&#25552;&#31034;&#30340;&#36136;&#37327;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#65292;&#20010;&#20154;&#20542;&#21521;&#20110;&#19982;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#23545;&#35805;&#65292;&#23547;&#25214;&#20182;&#20204;&#38382;&#39064;&#30340;&#31572;&#26696;&#12290;&#22312;&#36825;&#26679;&#30340;&#31572;&#26696;&#23545;&#20219;&#20309;&#20154;&#37117;&#24456;&#23481;&#26131;&#33719;&#24471;&#30340;&#26102;&#20195;&#65292;&#21050;&#28608;&#21644;&#20445;&#25345;&#20154;&#31867;&#30340;&#35748;&#30693;&#33021;&#21147;&#65292;&#20197;&#21450;&#30830;&#20445;&#20154;&#31867;&#20445;&#25345;&#33391;&#22909;&#25512;&#29702;&#33021;&#21147;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#25552;&#31034;&#65288;&#32780;&#19981;&#26159;&#26368;&#32456;&#31572;&#26696;&#25110;&#22312;&#32473;&#20986;&#31572;&#26696;&#20043;&#21069;&#65289;&#20316;&#20026;&#19968;&#31181;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#26469;&#28385;&#36275;&#36825;&#20123;&#38656;&#27714;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#20107;&#23454;&#24615;&#38382;&#39064;&#30340;&#33258;&#21160;&#25552;&#31034;&#29983;&#25104;&#26694;&#26550;&#65292;&#21033;&#29992;&#23427;&#26500;&#24314;&#20102;TriviaHG&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;&#26469;&#33258;TriviaQA&#25968;&#25454;&#38598;&#30340;16,645&#20010;&#38382;&#39064;&#23545;&#24212;&#30340;160,230&#20010;&#25552;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35780;&#20272;&#26041;&#27861;&#65292;&#29992;&#20110;&#34913;&#37327;&#25552;&#31034;&#30340;&#25910;&#25947;&#24615;&#21644;&#29087;&#24713;&#24230;&#36136;&#37327;&#23646;&#24615;&#12290;&#20026;&#20102;&#35780;&#20272;TriviaHG&#25968;&#25454;&#38598;&#21644;&#25152;&#25552;&#20986;&#30340;&#35780;&#20272;&#26041;&#27861;&#65292;&#25105;&#20204;&#36992;&#35831;&#20102;10&#21517;&#20010;&#20307;&#27880;&#37322;2,791&#20010;&#25552;&#31034;&#65292;&#24182;&#20998;&#37197;&#20102;6&#21517;&#30740;&#31350;&#20154;&#21592;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18426v1 Announce Type: new  Abstract: Nowadays, individuals tend to engage in dialogues with Large Language Models, seeking answers to their questions. In times when such answers are readily accessible to anyone, the stimulation and preservation of human's cognitive abilities, as well as the assurance of maintaining good reasoning skills by humans becomes crucial. This study addresses such needs by proposing hints (instead of final answers or before giving answers) as a viable solution. We introduce a framework for the automatic hint generation for factoid questions, employing it to construct TriviaHG, a novel large-scale dataset featuring 160,230 hints corresponding to 16,645 questions from the TriviaQA dataset. Additionally, we present an automatic evaluation method that measures the Convergence and Familiarity quality attributes of hints. To evaluate the TriviaHG dataset and the proposed evaluation method, we enlisted 10 individuals to annotate 2,791 hints and tasked 6 hu
&lt;/p&gt;</description></item><item><title>ChroniclingAmericaQA&#26159;&#19968;&#20010;&#22522;&#20110;&#21382;&#21490;&#32654;&#22269;&#25253;&#32440;&#39029;&#38754;&#30340;&#22823;&#35268;&#27169;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#25512;&#21160;QA&#21644;MRC&#20219;&#21153;&#30340;&#21457;&#23637;&#65292;&#24182;&#20811;&#26381;&#20197;&#24448;&#25968;&#25454;&#38598;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.17859</link><description>&lt;p&gt;
ChroniclingAmericaQA:&#22522;&#20110;&#21382;&#21490;&#32654;&#22269;&#25253;&#32440;&#39029;&#38754;&#30340;&#22823;&#35268;&#27169;&#38382;&#31572;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17859
&lt;/p&gt;
&lt;p&gt;
ChroniclingAmericaQA&#26159;&#19968;&#20010;&#22522;&#20110;&#21382;&#21490;&#32654;&#22269;&#25253;&#32440;&#39029;&#38754;&#30340;&#22823;&#35268;&#27169;&#38382;&#31572;&#25968;&#25454;&#38598;&#65292;&#26088;&#22312;&#25512;&#21160;QA&#21644;MRC&#20219;&#21153;&#30340;&#21457;&#23637;&#65292;&#24182;&#20811;&#26381;&#20197;&#24448;&#25968;&#25454;&#38598;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17859v1&#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#38382;&#31572;&#65288;QA&#65289;&#21644;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#65288;MRC&#65289;&#20219;&#21153;&#30001;&#20110;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#20197;&#21450;&#26368;&#36817;&#30340;&#22823;&#35821;&#35328;&#27169;&#22411;&#32780;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#21516;&#26102;&#65292;&#35768;&#22810;&#22522;&#20934;&#25968;&#25454;&#38598;&#24050;&#32463;&#29992;&#20110;QA&#21644;MRC&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22823;&#35268;&#27169;&#22522;&#20934;&#25968;&#25454;&#38598;&#20027;&#35201;&#20351;&#29992;&#21516;&#27493;&#25991;&#26723;&#38598;&#21512;&#65288;&#22914;&#32500;&#22522;&#30334;&#31185;&#25110;&#32593;&#32476;&#65289;&#21019;&#24314;&#12290;&#26723;&#26696;&#25991;&#20214;&#38598;&#21512;&#65292;&#22914;&#21382;&#21490;&#25253;&#32440;&#65292;&#21253;&#21547;&#36807;&#21435;&#30340;&#23453;&#36149;&#20449;&#24687;&#65292;&#20294;&#20173;&#26410;&#34987;&#24191;&#27867;&#29992;&#20110;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25512;&#21160;QA&#21644;MRC&#20219;&#21153;&#30340;&#21457;&#23637;&#65292;&#24182;&#20811;&#26381;&#20808;&#21069;&#25968;&#25454;&#38598;&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChroniclingAmericaQA&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#21382;&#21490;&#25253;&#32440;&#38598;Chronicling America&#21019;&#24314;&#30340;&#25317;&#26377;485K&#38382;&#31572;&#23545;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#26159;&#20174;Chronicling Amer&#30340;&#23376;&#38598;&#26500;&#24314;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17859v1 Announce Type: new  Abstract: Question answering (QA) and Machine Reading Comprehension (MRC) tasks have significantly advanced in recent years due to the rapid development of deep learning techniques and, more recently, large language models. At the same time, many benchmark datasets have become available for QA and MRC tasks. However, most existing large-scale benchmark datasets have been created predominantly using synchronous document collections like Wikipedia or the Web. Archival document collections, such as historical newspapers, contain valuable information from the past that is still not widely used to train large language models. To further contribute to advancing QA and MRC tasks and to overcome the limitation of previous datasets, we introduce ChroniclingAmericaQA, a large-scale dataset with 485K question-answer pairs created based on the historical newspaper collection Chronicling America. Our dataset is constructed from a subset of the Chronicling Amer
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.11894</link><description>&lt;p&gt;
&#20174;&#21487;&#35299;&#37322;&#21040;&#21487;&#35299;&#37322;&#30340;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#30103;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#65306;&#29616;&#23454;&#26377;&#22810;&#36828;&#65311;
&lt;/p&gt;
&lt;p&gt;
From explainable to interpretable deep learning for natural language processing in healthcare: how far from reality?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#23545;&#21307;&#30103;&#20445;&#20581;NLP&#20013;&#30340;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#20102;&#20840;&#38754;&#23457;&#26597;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XIAI&#65289;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#27880;&#24847;&#26426;&#21046;&#26159;&#20027;&#35201;&#26032;&#20852;IAI&#65292;&#21516;&#26102;&#38754;&#20020;&#30528;&#32570;&#20047;&#20840;&#23616;&#24314;&#27169;&#12289;&#26368;&#20339;&#23454;&#36341;&#20197;&#21450;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#36890;&#36807;&#35299;&#20915;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#21307;&#30103;&#20445;&#20581;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;DL&#30340;NLP&#26041;&#27861;&#26085;&#30410;&#22797;&#26434;&#65292;&#38656;&#35201;&#36879;&#26126;&#30340;&#27169;&#22411;&#35299;&#37322;&#24615;&#65292;&#25110;&#33267;&#23569;&#26159;&#21487;&#35299;&#37322;&#24615;&#65292;&#20197;&#36827;&#34892;&#21487;&#38752;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;&#26412;&#25991;&#23545;&#21307;&#30103;&#20581;&#24247;NLP&#20013;&#30340;&#21487;&#35299;&#37322;&#21644;&#21487;&#35299;&#37322;&#30340;DL&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#33539;&#22260;&#23457;&#26597;&#12290;&#24341;&#20837;&#20102;&#26415;&#35821;&#8220;XIAI&#8221;&#65288;eXplainable&#21644;Interpretable Artificial Intelligence&#65289;&#20197;&#21306;&#20998;XAI&#21644;IAI&#12290;&#26041;&#27861;&#26681;&#25454;&#20854;&#21151;&#33021;&#65288;&#27169;&#22411;&#12289;&#36755;&#20837;&#12289;&#36755;&#20986;&#20026;&#22522;&#30784;&#65289;&#21644;&#33539;&#22260;&#65288;&#23616;&#37096;&#12289;&#20840;&#23616;&#65289;&#36827;&#19968;&#27493;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#27880;&#24847;&#26426;&#21046;&#26159;&#26368;&#20027;&#35201;&#30340;&#26032;&#20852;IAI&#12290;&#27492;&#22806;&#65292;IAI&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#23545;&#25239;XAI&#12290;&#30830;&#23450;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#22823;&#22810;&#25968;XIAI&#19981;&#25506;&#32034;&#8220;&#20840;&#23616;&#8221;&#24314;&#27169;&#36807;&#31243;&#65292;&#32570;&#20047;&#26368;&#20339;&#23454;&#36341;&#65292;&#24182;&#19988;&#38656;&#35201;&#31995;&#32479;&#35780;&#20272;&#21644;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11894v1 Announce Type: cross  Abstract: Deep learning (DL) has substantially enhanced healthcare research by addressing various natural language processing (NLP) tasks. Yet, the increasing complexity of DL-based NLP methods necessitates transparent model interpretability, or at least explainability, for reliable decision-making. This work presents a thorough scoping review on explainable and interpretable DL in healthcare NLP. The term "XIAI" (eXplainable and Interpretable Artificial Intelligence) was introduced to distinguish XAI from IAI. Methods were further categorized based on their functionality (model-, input-, output-based) and scope (local, global). Our analysis shows that attention mechanisms were the most dominant emerging IAI. Moreover, IAI is increasingly used against XAI. The major challenges identified are that most XIAI do not explore "global" modeling processes, the lack of best practices, and the unmet need for systematic evaluation and benchmarks. Importan
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;DeFaBel&#35821;&#26009;&#24211;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20449;&#20208;&#30340;&#27450;&#39575;&#30340;&#20247;&#21253;&#36164;&#28304;&#65292;&#29992;&#20110;&#30740;&#31350;&#27450;&#39575;&#19982;&#20107;&#23454;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24378;&#35843;&#20102;&#35770;&#35777;&#20013;&#20107;&#23454;&#24615;&#12289;&#20010;&#20154;&#20449;&#24565;&#21644;&#27450;&#39575;&#24847;&#22270;&#20043;&#38388;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10185</link><description>&lt;p&gt;
&#21487;&#20197;&#27450;&#39575;&#24615;&#22320;&#38472;&#36848;&#20107;&#23454;&#21527;&#65311;&#22522;&#20110;&#20449;&#20208;&#30340;&#27450;&#39575;DeFaBel&#35821;&#26009;&#24211;
&lt;/p&gt;
&lt;p&gt;
Can Factual Statements be Deceptive? The DeFaBel Corpus of Belief-based Deception
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10185
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;DeFaBel&#35821;&#26009;&#24211;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20449;&#20208;&#30340;&#27450;&#39575;&#30340;&#20247;&#21253;&#36164;&#28304;&#65292;&#29992;&#20110;&#30740;&#31350;&#27450;&#39575;&#19982;&#20107;&#23454;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24378;&#35843;&#20102;&#35770;&#35777;&#20013;&#20107;&#23454;&#24615;&#12289;&#20010;&#20154;&#20449;&#24565;&#21644;&#27450;&#39575;&#24847;&#22270;&#20043;&#38388;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#20154;&#22362;&#20449;&#19968;&#20010;&#38750;&#20107;&#23454;&#24615;&#30340;&#38472;&#36848;&#65292;&#27604;&#22914;&#8220;&#22320;&#29699;&#26159;&#24179;&#30340;&#8221;&#65292;&#24182;&#20026;&#20854;&#36777;&#25252;&#65292;&#37027;&#20040;&#20182;&#24182;&#27809;&#26377;&#26412;&#36136;&#19978;&#30340;&#27450;&#39575;&#24847;&#22270;&#12290;&#30001;&#20110;&#35770;&#35777;&#28304;&#20110;&#30495;&#35802;&#30340;&#20449;&#24565;&#65292;&#23427;&#21487;&#33021;&#19981;&#22826;&#21487;&#33021;&#23637;&#31034;&#20986;&#19982;&#27450;&#39575;&#25110;&#25746;&#35854;&#30456;&#20851;&#30340;&#35821;&#35328;&#29305;&#24449;&#12290;&#20107;&#23454;&#24615;&#12289;&#20010;&#20154;&#20449;&#24565;&#21644;&#27450;&#39575;&#24847;&#22270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#32463;&#20805;&#20998;&#30740;&#31350;&#30340;&#39046;&#22495;&#12290;&#35299;&#24320;&#36825;&#20123;&#21464;&#37327;&#22312;&#35770;&#35777;&#20013;&#30340;&#24433;&#21709;&#23545;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#24402;&#22240;&#20110;&#27599;&#19968;&#20010;&#30340;&#35821;&#35328;&#29305;&#24449;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#30740;&#31350;&#22522;&#20110;&#20449;&#24565;&#30340;&#27450;&#39575;&#19982;&#20107;&#23454;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DeFaBel&#35821;&#26009;&#24211;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#20449;&#20208;&#30340;&#27450;&#39575;&#30340;&#20247;&#21253;&#36164;&#28304;&#12290;&#20026;&#20102;&#21019;&#24314;&#36825;&#20010;&#35821;&#26009;&#24211;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#30740;&#31350;&#65292;&#35201;&#27714;&#21442;&#19982;&#32773;&#25776;&#20889;&#25903;&#25345;&#35832;&#22914;&#8220;&#39135;&#29992;&#35199;&#29916;&#31869;&#21487;&#33021;&#23548;&#33268;&#28040;&#21270;&#19981;&#33391;&#8221;&#30340;&#38472;&#36848;&#65292;&#32780;&#19981;&#35770;&#20854;&#20107;&#23454;&#20934;&#30830;&#24615;&#25110;&#20010;&#20154;&#20449;&#24565;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10185v1 Announce Type: new  Abstract: If a person firmly believes in a non-factual statement, such as "The Earth is flat", and argues in its favor, there is no inherent intention to deceive. As the argumentation stems from genuine belief, it may be unlikely to exhibit the linguistic properties associated with deception or lying. This interplay of factuality, personal belief, and intent to deceive remains an understudied area. Disentangling the influence of these variables in argumentation is crucial to gain a better understanding of the linguistic properties attributed to each of them. To study the relation between deception and factuality, based on belief, we present the DeFaBel corpus, a crowd-sourced resource of belief-based deception. To create this corpus, we devise a study in which participants are instructed to write arguments supporting statements like "eating watermelon seeds can cause indigestion", regardless of its factual accuracy or their personal beliefs about 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.18510</link><description>&lt;p&gt;
RNNs&#36824;&#19981;&#26159;Transformer&#65306;&#22312;&#19978;&#19979;&#25991;&#26816;&#32034;&#20013;&#30340;&#20851;&#38190;&#29942;&#39048;
&lt;/p&gt;
&lt;p&gt;
RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#21644;Transformer&#22312;&#35299;&#20915;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#31034;&#33021;&#21147;&#24046;&#36317;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;RNNs&#26159;&#21542;&#33021;&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#65292;&#36890;&#36807;Chain-of-Thought (CoT)&#25552;&#31034;&#65292;&#19982;Transformer&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;CoT&#21487;&#20197;&#25913;&#36827;RNNs&#65292;&#20294;&#26080;&#27861;&#24357;&#34917;&#19982;Transformer&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20851;&#38190;&#29942;&#39048;&#22312;&#20110;RNNs&#26080;&#27861;&#23436;&#20840;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#21363;&#20351;&#32463;&#36807;CoT&#30340;&#22686;&#24378;&#65306;&#23545;&#20110;&#20960;&#20010;&#26126;&#30830;&#25110;&#38544;&#24335;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#22914;&#32852;&#24819;&#21484;&#22238;&#21644;&#30830;&#23450;&#22270;&#26159;&#21542;&#20026;&#26641;&#65292;&#25105;&#20204;&#35777;&#26126;RNNs&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#20197;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32780;Transformer&#21487;&#20197;&#36731;&#26494;&#35299;&#20915;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#37319;&#29992;&#22686;&#24378;RNNs&#19978;&#19979;&#25991;&#26816;&#32034;&#33021;&#21147;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
&lt;/p&gt;</description></item><item><title>Nissist&#21033;&#29992;TSGs&#21644;&#20107;&#25925;&#32531;&#35299;&#21382;&#21490;&#25552;&#20379;&#20027;&#21160;&#24314;&#35758;&#65292;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#65292;&#20197;&#25552;&#39640;&#20225;&#19994;&#32423;&#20113;&#26381;&#21153;&#30340;&#20107;&#25925;&#31649;&#29702;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.17531</link><description>&lt;p&gt;
Nissist&#65306;&#22522;&#20110;&#25925;&#38556;&#25490;&#38500;&#25351;&#21335;&#30340;&#20107;&#25925;&#32531;&#35299;&#21103;&#39550;&#39542;
&lt;/p&gt;
&lt;p&gt;
Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17531
&lt;/p&gt;
&lt;p&gt;
Nissist&#21033;&#29992;TSGs&#21644;&#20107;&#25925;&#32531;&#35299;&#21382;&#21490;&#25552;&#20379;&#20027;&#21160;&#24314;&#35758;&#65292;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#65292;&#20197;&#25552;&#39640;&#20225;&#19994;&#32423;&#20113;&#26381;&#21153;&#30340;&#20107;&#25925;&#31649;&#29702;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#30340;&#20107;&#25925;&#31649;&#29702;&#23545;&#20225;&#19994;&#32423;&#20113;&#26381;&#21153;&#30340;&#39034;&#30021;&#36816;&#20316;&#33267;&#20851;&#37325;&#35201;&#12290; &#20026;&#20102;&#21152;&#36895;&#20107;&#25925;&#32531;&#35299;&#65292;&#26381;&#21153;&#22242;&#38431;&#23558;&#25925;&#38556;&#25490;&#38500;&#30693;&#35782;&#32534;&#35793;&#25104;&#20379;&#20540;&#29677;&#24037;&#31243;&#24072;&#65288;OCEs&#65289;&#35775;&#38382;&#30340;&#25925;&#38556;&#25490;&#38500;&#25351;&#21335;&#65288;TSGs&#65289;&#12290; &#23613;&#31649;&#33258;&#21160;&#21270;&#27969;&#27700;&#32447;&#24050;&#33021;&#22815;&#35299;&#20915;&#26368;&#24120;&#35265;&#21644;&#31616;&#21333;&#30340;&#20107;&#25925;&#65292;&#20294;&#20173;&#23384;&#22312;&#38656;&#35201;OCE&#24178;&#39044;&#30340;&#22797;&#26434;&#20107;&#25925;&#12290; &#28982;&#32780;&#65292;TSGs&#36890;&#24120;&#26159;&#38750;&#32467;&#26500;&#21270;&#21644;&#19981;&#23436;&#25972;&#30340;&#65292;&#36825;&#38656;&#35201;OCE&#25163;&#21160;&#35299;&#37322;&#65292;&#23548;&#33268;&#20540;&#29677;&#30130;&#21171;&#21644;&#29983;&#20135;&#21147;&#19979;&#38477;&#65292;&#29305;&#21035;&#26159;&#26032;&#20837;&#32844;&#30340;OCE&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Nissist&#65292;&#23427;&#21033;&#29992;TSGs&#21644;&#20107;&#25925;&#32531;&#35299;&#21382;&#21490;&#25552;&#20379;&#20027;&#21160;&#24314;&#35758;&#65292;&#20943;&#23569;&#20154;&#20026;&#24178;&#39044;&#12290; &#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;Nissist&#20174;&#38750;&#32467;&#26500;&#21270;TSGs&#21644;&#21382;&#21490;&#20107;&#25925;&#32531;&#35299;&#35752;&#35770;&#20013;&#25552;&#21462;&#35265;&#35299;&#65292;&#24418;&#25104;&#20840;&#38754;&#30340;&#30693;&#35782;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17531v1 Announce Type: cross  Abstract: Effective incident management is pivotal for the smooth operation of enterprises-level cloud services. In order to expedite incident mitigation, service teams compile troubleshooting knowledge into Troubleshooting Guides (TSGs) accessible to on-call engineers (OCEs). While automated pipelines are enabled to resolve the most frequent and easy incidents, there still exist complex incidents that require OCEs' intervention. However, TSGs are often unstructured and incomplete, which requires manual interpretation by OCEs, leading to on-call fatigue and decreased productivity, especially among new-hire OCEs. In this work, we propose Nissist which leverages TSGs and incident mitigation histories to provide proactive suggestions, reducing human intervention. Leveraging Large Language Models (LLM), Nissist extracts insights from unstructured TSGs and historical incident mitigation discussions, forming a comprehensive knowledge base. Its multi-a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#29983;&#25104;&#30340;&#29702;&#30001;&#30340;&#8220;&#25512;&#29702;&#24863;&#30693;&#8221;&#35786;&#26029;&#26694;&#26550;&#65292;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#36827;&#34892;&#20020;&#24202;&#25512;&#29702;&#65292;&#23454;&#29616;&#20102;&#22312;&#30142;&#30149;&#35786;&#26029;&#36807;&#31243;&#20013;&#30340;&#39640;&#25928;&#12289;&#26102;&#38388;&#33410;&#32422;&#21644;&#21171;&#21160;&#33410;&#32422;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2312.07399</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26159;&#20020;&#24202;&#25512;&#29702;&#32773;&#65306;&#22522;&#20110;&#25552;&#31034;&#29983;&#25104;&#30340;&#29702;&#30001;&#30340;&#25512;&#29702;&#24863;&#30693;&#35786;&#26029;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis Framework with Prompt-Generated Rationales
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.07399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25552;&#31034;&#29983;&#25104;&#30340;&#29702;&#30001;&#30340;&#8220;&#25512;&#29702;&#24863;&#30693;&#8221;&#35786;&#26029;&#26694;&#26550;&#65292;&#36890;&#36807;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26469;&#36827;&#34892;&#20020;&#24202;&#25512;&#29702;&#65292;&#23454;&#29616;&#20102;&#22312;&#30142;&#30149;&#35786;&#26029;&#36807;&#31243;&#20013;&#30340;&#39640;&#25928;&#12289;&#26102;&#38388;&#33410;&#32422;&#21644;&#21171;&#21160;&#33410;&#32422;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#36827;&#23637;&#65292;&#26426;&#22120;&#25512;&#29702;&#22312;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22312;&#20020;&#24202;&#39046;&#22495;&#65292;&#22823;&#22810;&#25968;&#20197;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20026;&#39537;&#21160;&#30340;&#39033;&#30446;&#20027;&#35201;&#38598;&#20013;&#22312;&#20020;&#24202;&#20998;&#31867;&#25110;&#38405;&#35835;&#29702;&#35299;&#19978;&#65292;&#24182;&#19988;&#30001;&#20110;&#19982;&#20020;&#24202;&#21307;&#29983;&#30340;&#29702;&#24565;&#27880;&#35299;&#25104;&#26412;&#36739;&#39640;&#65292;&#23545;&#20110;&#30142;&#30149;&#35786;&#26029;&#30340;&#20020;&#24202;&#25512;&#29702;&#36824;&#26410;&#24471;&#21040;&#20805;&#20998;&#30340;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#25512;&#29702;&#24863;&#30693;&#8221;&#30340;&#35786;&#26029;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20110;&#25552;&#31034;&#30340;&#23398;&#20064;&#20197;&#19968;&#31181;&#39640;&#25928;&#30340;&#26102;&#38388;&#21644;&#21171;&#21160;&#26041;&#24335;&#21435;&#29702;&#24615;&#21270;&#35786;&#26029;&#36807;&#31243;&#65292;&#24182;&#23398;&#20064;&#23545;&#25552;&#31034;&#29983;&#25104;&#30340;&#29702;&#30001;&#36827;&#34892;&#25512;&#29702;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#30142;&#30149;&#35786;&#26029;&#30340;&#20020;&#24202;&#25512;&#29702;&#38382;&#39064;&#65292;&#20854;&#20013;LLM&#29983;&#25104;&#20102;&#35786;&#26029;&#24615;&#30340;&#29702;&#30001;&#65292;&#25552;&#20379;&#20854;&#23545;&#21576;&#29616;&#30340;&#24739;&#32773;&#25968;&#25454;&#30340;&#35265;&#35299;&#20197;&#21450;&#36798;&#21040;&#35786;&#26029;&#30340;&#25512;&#29702;&#36335;&#24452;&#65292;&#21363;&#20020;&#24202;&#24605;&#32500;&#38142;&#65288;Clinical CoT&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#21644;&#20998;&#26512;&#22312;&#29702;&#30001;&#29983;&#25104;&#21644;&#30142;&#30149;&#35786;&#26029;&#26041;&#38754;&#23454;&#35777;&#20102;LLMs/LMs&#30340;&#20020;&#24202;&#25512;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine reasoning has made great progress in recent years owing to large language models (LLMs). In the clinical domain, however, most NLP-driven projects mainly focus on clinical classification or reading comprehension, and under-explore clinical reasoning for disease diagnosis due to the expensive rationale annotation with clinicians. In this work, we present a ``reasoning-aware'' diagnosis framework that rationalizes the diagnostic process via prompt-based learning in a time- and labor-efficient manner, and learns to reason over the prompt-generated rationales. Specifically, we address the clinical reasoning for disease diagnosis, where the LLM generates diagnostic rationales providing its insight on presented patient data and the reasoning path towards the diagnosis, namely Clinical Chain-of-Thought (Clinical CoT). We empirically demonstrate LLMs/LMs' ability of clinical reasoning via extensive experiments and analyses on both rationale generation and disease diagnosis in various s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#23398;&#20064;&#31639;&#26415;&#31639;&#27861;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#27880;&#24847;&#21147;&#20559;&#32622;&#20197;&#21450;Attention Bias Calibration&#65288;ABC&#65289;&#26469;&#23454;&#29616;&#23545;&#20110;&#38271;&#38271;&#24230;&#30340;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.11984</link><description>&lt;p&gt;
&#20174;&#25554;&#20540;&#21040;&#22806;&#25512;&#65306;&#31639;&#26415;Transformer&#30340;&#23436;&#25972;&#38271;&#24230;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers. (arXiv:2310.11984v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#23398;&#20064;&#31639;&#26415;&#31639;&#27861;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#36890;&#36807;&#27880;&#24847;&#21147;&#20559;&#32622;&#20197;&#21450;Attention Bias Calibration&#65288;ABC&#65289;&#26469;&#23454;&#29616;&#23545;&#20110;&#38271;&#38271;&#24230;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#25552;&#20986;&#20197;&#26469;&#65292;Transformer&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#20102;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#31639;&#27861;&#20219;&#21153;&#20013;&#65292;&#38271;&#24230;&#27867;&#21270;&#20173;&#23384;&#22312;&#19968;&#20123;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#23398;&#20064;&#31639;&#26415;&#31639;&#27861;&#65288;&#22914;&#21152;&#27861;&#21644;&#20056;&#27861;&#65289;&#26041;&#38754;&#30340;&#20869;&#22312;&#33021;&#21147;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#21644;&#27880;&#24847;&#21147;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#23454;&#29616;&#26368;&#20339;&#38271;&#24230;&#27867;&#21270;&#30340;&#20960;&#20010;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;Transformer&#27169;&#22411;&#33021;&#22815;&#36890;&#36807;&#30446;&#26631;&#25351;&#21521;&#20559;&#32622;&#26469;&#27867;&#21270;&#21040;&#38271;&#38271;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Attention Bias Calibration&#65288;ABC&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26657;&#20934;&#38454;&#27573;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#33258;&#21160;&#23398;&#20064;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#20559;&#32622;&#65292;&#25105;&#20204;&#23558;&#20854;&#19982;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#30340;&#26426;&#21046;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#35777;&#26126;&#20351;&#29992;ABC&#65292;Transformer&#27169;&#22411;&#21487;&#20197;&#22312;&#26576;&#20123;&#31639;&#26415;&#20219;&#21153;&#19978;&#23454;&#29616;&#21069;&#25152;&#26410;&#26377;&#30340;&#23436;&#32654;&#38271;&#24230;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since its introduction, the transformer model has demonstrated outstanding performance across various tasks. However, there are still unresolved issues regarding length generalization, particularly in algorithmic tasks. In this paper, we investigate the inherent capabilities of transformer models in learning arithmetic algorithms, such as addition and multiplication. Through experiments and attention analysis, we identify a number of crucial factors for achieving optimal length generalization. We show that transformer models are able to generalize to long lengths with the help of targeted attention biasing. We then introduce Attention Bias Calibration (ABC), a calibration stage that enables the model to automatically learn the proper attention biases, which we link to mechanisms in relative position encoding. We demonstrate that using ABC, the transformer model can achieve unprecedented perfect length generalization on certain arithmetic tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#65292;&#20197;&#35299;&#20915;&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26102;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.07819</link><description>&lt;p&gt;
&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#24230;&#37327;&#24544;&#23454;&#24615;&#30340;&#25513;&#30721;&#35821;&#35328;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#65292;&#20197;&#35299;&#20915;&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#26102;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#27169;&#22411;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#37325;&#35201;&#24615;&#24230;&#37327;&#26469;&#34920;&#36798;&#21738;&#20123;&#20196;&#29260;&#23545;&#20110;&#39044;&#27979;&#24456;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#20123;&#35299;&#37322;&#20855;&#26377;&#35828;&#26381;&#21147;&#65292;&#20294;&#24448;&#24448;&#26159;&#38169;&#35823;&#30340;&#12290;&#22240;&#27492;&#65292;&#27979;&#37327;&#23427;&#20204;&#30340;&#24544;&#23454;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20854;&#20013;&#19968;&#31181;&#24230;&#37327;&#26631;&#20934;&#26159;&#22914;&#26524;&#20196;&#29260;&#30830;&#23454;&#24456;&#37325;&#35201;&#65292;&#37027;&#20040;&#23631;&#34109;&#23427;&#20204;&#24212;&#35813;&#23548;&#33268;&#27169;&#22411;&#24615;&#33021;&#21464;&#24046;&#12290;&#28982;&#32780;&#65292;&#20196;&#29260;&#23631;&#34109;&#20250;&#24341;&#20837;&#21306;&#22495;&#22806;&#38382;&#39064;&#65292;&#32780;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#22312;&#35745;&#31639;&#19978;&#24456;&#26114;&#36149;&#24182;&#19988;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20854;&#20182;&#25351;&#26631;&#30340;&#36866;&#29992;&#33539;&#22260;&#38750;&#24120;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22266;&#26377;&#30340;&#24544;&#23454;&#24615;&#21487;&#24230;&#37327;&#27169;&#22411;&#26469;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#24494;&#35843;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#35813;&#26041;&#27861;&#23558;&#23631;&#34109;&#20196;&#29260;&#20316;&#20026;&#35774;&#35745;&#20351;&#20854;&#25104;&#20026;&#20998;&#24067;&#20869;&#12290;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#29616;&#26377;&#26041;&#27861;&#23436;&#20840;&#19982;&#27169;&#22411;&#26080;&#20851;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#21644;&#25968;&#25454;&#38598;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common approach to explain NLP models, is to use importance measures that express which tokens are important for a prediction. Unfortunately, such explanations are often wrong despite being persuasive. Therefore, it is essential to measure their faithfulness. One such metric is if tokens are truly important, then masking them should result in worse model performance. However, token masking introduces out-of-distribution issues and existing solutions are computationally expensive and employ proxy-models. Furthermore, other metrics are very limited in scope. In this work, we propose an inherently faithfulness measurable model that addresses these challenges. This is achieved by using a novel fine-tuning method that incorporates masking, such that masking tokens become in-distribution by design. This differs from existing approaches, which are completely model-agnostic but are inapplicable in practice. We demonstrate the generality of our approach by applying it to various tasks and val
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13063</link><description>&lt;p&gt;
&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#12289;&#39564;&#35777;&#21644;&#24212;&#29992;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13063
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20998;&#26512;&#21644;&#39564;&#35777;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#26041;&#27861;&#22312;&#22823;&#22411;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26085;&#24535;&#25968;&#25454;&#21487;&#20197;&#25581;&#31034;&#29992;&#25143;&#19982;&#32593;&#32476;&#25628;&#32034;&#26381;&#21153;&#30340;&#20132;&#20114;&#26041;&#24335;&#12289;&#29992;&#25143;&#30340;&#38656;&#27714;&#20197;&#21450;&#28385;&#24847;&#31243;&#24230;&#31561;&#23453;&#36149;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20998;&#26512;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#24182;&#19981;&#23481;&#26131;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#26032;&#30340;&#32593;&#32476;&#25628;&#32034;&#24418;&#24335;&#65292;&#22914;&#20154;&#24037;&#26234;&#33021;&#39537;&#21160;&#30340;&#32842;&#22825;&#12290;&#20026;&#20102;&#29702;&#35299;&#26085;&#24535;&#25968;&#25454;&#20013;&#30340;&#29992;&#25143;&#24847;&#22270;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#31181;&#33021;&#22815;&#29992;&#26377;&#24847;&#20041;&#30340;&#20998;&#31867;&#26041;&#24335;&#26631;&#35760;&#23427;&#20204;&#30340;&#26041;&#27861;&#65292;&#20197;&#25429;&#25417;&#20854;&#22810;&#26679;&#24615;&#21644;&#21160;&#24577;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#25163;&#21160;&#25110;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26631;&#27880;&#65292;&#36825;&#20123;&#26041;&#27861;&#23545;&#20110;&#22823;&#22411;&#19988;&#19981;&#26029;&#21464;&#21270;&#30340;&#25968;&#25454;&#38598;&#32780;&#35328;&#65292;&#35201;&#20040;&#20195;&#20215;&#39640;&#26114;&#35201;&#20040;&#19981;&#22815;&#28789;&#27963;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#26032;&#26041;&#27861;&#65292;&#36825;&#31181;&#27169;&#22411;&#33021;&#22815;&#29983;&#25104;&#20016;&#23500;&#19988;&#30456;&#20851;&#30340;&#27010;&#24565;&#12289;&#25551;&#36848;&#21644;&#31034;&#20363;&#26469;&#34920;&#31034;&#29992;&#25143;&#24847;&#22270;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;LLM&#29983;&#25104;&#29992;&#25143;&#24847;&#22270;&#20998;&#31867;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26085;&#24535;&#20998;&#26512;&#21487;&#33021;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;&#36825;&#26679;&#30340;&#20998;&#31867;&#24471;&#19981;&#21040;&#22806;&#37096;&#39564;&#35777;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#19981;&#33391;&#30340;&#21453;&#39304;&#22238;&#36335;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20154;&#24037;&#19987;&#23478;&#21644;&#35780;&#20272;&#32773;&#26469;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify th
&lt;/p&gt;</description></item><item><title>&#27491;&#21017;&#34920;&#36798;&#24335;&#25512;&#29702;&#25361;&#25112;&#26159;&#19968;&#20010;&#20197;&#25214;&#21040;&#26368;&#23567;&#27491;&#21017;&#34920;&#36798;&#24335;&#20026;&#30446;&#26631;&#30340;&#20219;&#21153;&#65292;&#20855;&#26377;&#24212;&#29992;&#24191;&#27867;&#12289;&#38590;&#24230;&#21487;&#35843;&#12289;&#36866;&#29992;&#20110;&#20195;&#30721;/&#35821;&#35328;&#24314;&#27169;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.07899</link><description>&lt;p&gt;
&#27491;&#21017;&#34920;&#36798;&#24335;&#25512;&#29702;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
The Regular Expression Inference Challenge. (arXiv:2308.07899v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07899
&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#34920;&#36798;&#24335;&#25512;&#29702;&#25361;&#25112;&#26159;&#19968;&#20010;&#20197;&#25214;&#21040;&#26368;&#23567;&#27491;&#21017;&#34920;&#36798;&#24335;&#20026;&#30446;&#26631;&#30340;&#20219;&#21153;&#65292;&#20855;&#26377;&#24212;&#29992;&#24191;&#27867;&#12289;&#38590;&#24230;&#21487;&#35843;&#12289;&#36866;&#29992;&#20110;&#20195;&#30721;/&#35821;&#35328;&#24314;&#27169;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#23558;&#27491;&#21017;&#34920;&#36798;&#24335;&#25512;&#29702;&#65288;REI&#65289;&#20316;&#20026;&#20195;&#30721;/&#35821;&#35328;&#24314;&#27169;&#20197;&#21450;&#26356;&#24191;&#27867;&#30340;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#30340;&#25361;&#25112;&#12290;REI&#26159;&#19968;&#20010;&#26377;&#30417;&#30563;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#31243;&#24207;&#21512;&#25104;&#20219;&#21153;&#65292;&#23427;&#25552;&#20986;&#20102;&#20174;&#31034;&#20363;&#20013;&#25214;&#21040;&#26368;&#23567;&#27491;&#21017;&#34920;&#36798;&#24335;&#30340;&#38382;&#39064;&#65306;&#32473;&#23450;&#20004;&#20010;&#26377;&#38480;&#23383;&#31526;&#20018;&#38598;&#21512;P&#21644;N&#20197;&#21450;&#19968;&#20010;&#25104;&#26412;&#20989;&#25968;cost(&#183;)&#65292;&#20219;&#21153;&#26159;&#29983;&#25104;&#19968;&#20010;&#25509;&#21463;P&#20013;&#25152;&#26377;&#23383;&#31526;&#20018;&#24182;&#25298;&#32477;N&#20013;&#25152;&#26377;&#23383;&#31526;&#20018;&#30340;&#34920;&#36798;&#24335;r&#65292;&#32780;&#19981;&#23384;&#22312;&#20854;&#20182;&#34920;&#36798;&#24335;r'&#65292;&#20351;&#24471;cost(r')&lt;cost(r)&#12290;REI&#20316;&#20026;&#19968;&#20010;&#25361;&#25112;&#38382;&#39064;&#20855;&#26377;&#20197;&#19979;&#20248;&#21183;&#65306;&#65288;i&#65289;&#27491;&#21017;&#34920;&#36798;&#24335;&#26159;&#20247;&#25152;&#21608;&#30693;&#12289;&#24191;&#27867;&#20351;&#29992;&#30340;&#65292;&#26159;&#20195;&#30721;&#30340;&#33258;&#28982;&#29702;&#24819;&#21270;&#65307;&#65288;ii&#65289;REI&#30340;&#28176;&#36817;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24615;&#24050;&#34987;&#20805;&#20998;&#29702;&#35299;&#65307;&#65288;iii&#65289;REI&#20855;&#26377;&#19968;&#23567;&#37096;&#20998;&#26131;&#20110;&#29702;&#35299;&#30340;&#21442;&#25968;&#65288;&#20363;&#22914;P&#25110;N&#30340;&#22522;&#25968;&#12289;&#31034;&#20363;&#30340;&#23383;&#31526;&#20018;&#38271;&#24230;&#25110;&#25104;&#26412;&#20989;&#25968;&#65289;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#36731;&#26494;&#35843;&#25972;REI&#30340;&#38590;&#24230;&#65307;&#65288;iv&#65289;&#23545;&#20110;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;M&#27169;&#22411;&#32780;&#35328;&#65292;REI&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose \emph{regular expression inference (REI)} as a challenge for code/language modelling, and the wider machine learning community. REI is a supervised machine learning (ML) and program synthesis task, and poses the problem of finding minimal regular expressions from examples: Given two finite sets of strings $P$ and $N$ and a cost function $\text{cost}(\cdot)$, the task is to generate an expression $r$ that accepts all strings in $P$ and rejects all strings in $N$, while no other such expression $r'$ exists with $\text{cost}(r')&lt;\text{cost}(r)$.  REI has advantages as a challenge problem: (i) regular expressions are well-known, widely used, and a natural idealisation of code; (ii) REI's asymptotic worst-case complexity is well understood; (iii) REI has a small number of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string lengths of examples, or the cost function); this lets us easily finetune REI-hardness; (iv) REI is an unsolved problem for deep learning based M
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#39640;&#32423;&#27169;&#22411;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#25361;&#25112;&#21644;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2201.02797</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#20013;&#30340;&#24212;&#29992;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A Unified Review of Deep Learning for Automated Medical Coding. (arXiv:2201.02797v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#39046;&#22495;&#30340;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#39640;&#32423;&#27169;&#22411;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#21457;&#23637;&#30340;&#25361;&#25112;&#21644;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#26159;&#21307;&#30103;&#36816;&#33829;&#21644;&#26381;&#21153;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#36890;&#36807;&#20174;&#20020;&#24202;&#25991;&#26723;&#20013;&#39044;&#27979;&#21307;&#30103;&#32534;&#30721;&#26469;&#31649;&#29702;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#12290;&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#36827;&#27493;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#35813;&#20219;&#21153;&#12290;&#20294;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#33258;&#21160;&#21307;&#30103;&#32534;&#30721;&#32570;&#20047;&#23545;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35774;&#35745;&#30340;&#32479;&#19968;&#35270;&#22270;&#12290;&#26412;&#32508;&#36848;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#20197;&#25552;&#20379;&#23545;&#21307;&#30103;&#32534;&#30721;&#27169;&#22411;&#32452;&#20214;&#30340;&#19968;&#33324;&#29702;&#35299;&#65292;&#24182;&#24635;&#32467;&#20102;&#22312;&#27492;&#26694;&#26550;&#19979;&#26368;&#36817;&#30340;&#39640;&#32423;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32479;&#19968;&#26694;&#26550;&#23558;&#21307;&#30103;&#32534;&#30721;&#20998;&#35299;&#20026;&#22235;&#20010;&#20027;&#35201;&#32452;&#20214;&#65292;&#21363;&#29992;&#20110;&#25991;&#26412;&#29305;&#24449;&#25552;&#21462;&#30340;&#32534;&#30721;&#22120;&#27169;&#22359;&#12289;&#26500;&#24314;&#28145;&#24230;&#32534;&#30721;&#22120;&#26550;&#26500;&#30340;&#26426;&#21046;&#12289;&#29992;&#20110;&#23558;&#38544;&#34255;&#34920;&#31034;&#36716;&#25442;&#25104;&#21307;&#30103;&#20195;&#30721;&#30340;&#35299;&#30721;&#22120;&#27169;&#22359;&#20197;&#21450;&#36741;&#21161;&#20449;&#24687;&#30340;&#20351;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22522;&#20934;&#21644;&#30495;&#23454;&#19990;&#30028;&#20013;&#30340;&#20351;&#29992;&#24773;&#20917;&#65292;&#35752;&#35770;&#20102;&#20851;&#38190;&#30340;&#30740;&#31350;&#25361;&#25112;&#21644;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning-based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.
&lt;/p&gt;</description></item></channel></rss>