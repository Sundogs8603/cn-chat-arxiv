<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#22522;&#20110;AI&#21453;&#39304;&#30340;&#36136;&#37327;-&#22810;&#26679;&#24615;&#65288;QDAIF&#65289;&#31639;&#27861;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#26469;&#29983;&#25104;&#21644;&#35780;&#20272;&#21019;&#36896;&#24615;&#20889;&#20316;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#26356;&#24191;&#27867;&#22320;&#35206;&#30422;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.13032</link><description>&lt;p&gt;
AI&#21453;&#39304;&#20419;&#36827;&#30340;&#36136;&#37327;-&#22810;&#26679;&#24615;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quality-Diversity through AI Feedback. (arXiv:2310.13032v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13032
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;AI&#21453;&#39304;&#30340;&#36136;&#37327;-&#22810;&#26679;&#24615;&#65288;QDAIF&#65289;&#31639;&#27861;&#21033;&#29992;&#35821;&#35328;&#27169;&#22411;&#26469;&#29983;&#25104;&#21644;&#35780;&#20272;&#21019;&#36896;&#24615;&#20889;&#20316;&#65292;&#27604;&#20256;&#32479;&#31639;&#27861;&#26356;&#24191;&#27867;&#22320;&#35206;&#30422;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#25991;&#26412;&#29983;&#25104;&#38382;&#39064;&#20013;&#65292;&#29992;&#25143;&#21487;&#33021;&#19981;&#20165;&#20559;&#22909;&#21333;&#19968;&#22238;&#22797;&#65292;&#32780;&#26159;&#24076;&#26395;&#24471;&#21040;&#22810;&#26679;&#24615;&#30340;&#39640;&#36136;&#37327;&#36755;&#20986;&#20197;&#20379;&#36873;&#25321;&#12290;&#36136;&#37327;-&#22810;&#26679;&#24615;&#65288;QD&#65289;&#25628;&#32034;&#31639;&#27861;&#26088;&#22312;&#36890;&#36807;&#19981;&#26029;&#25913;&#36827;&#21644;&#22810;&#26679;&#21270;&#20505;&#36873;&#20154;&#32676;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;QD&#22312;&#21019;&#20316;&#24615;&#20889;&#20316;&#31561;&#36136;&#24615;&#39046;&#22495;&#30340;&#24212;&#29992;&#21463;&#21040;&#31639;&#27861;&#25351;&#23450;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#24230;&#37327;&#30340;&#22256;&#38590;&#30340;&#38480;&#21046;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#26368;&#36817;&#35821;&#35328;&#27169;&#22411;&#65288;LMs&#65289;&#30340;&#21457;&#23637;&#20351;&#24471;&#36890;&#36807;AI&#21453;&#39304;&#25351;&#23548;&#25628;&#32034;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;LMs&#22312;&#33258;&#28982;&#35821;&#35328;&#20013;&#34987;&#25552;&#31034;&#26469;&#35780;&#20272;&#25991;&#26412;&#30340;&#36136;&#24615;&#26041;&#38754;&#12290;&#20511;&#21161;&#36825;&#19968;&#36827;&#23637;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36890;&#36807;AI&#21453;&#39304;&#23454;&#29616;&#30340;&#36136;&#37327;-&#22810;&#26679;&#24615;&#31639;&#27861;&#65288;QDAIF&#65289;&#65292;&#20854;&#20013;&#36827;&#21270;&#31639;&#27861;&#24212;&#29992;LMs&#26469;&#29983;&#25104;&#21464;&#24322;&#24182;&#35780;&#20272;&#20505;&#36873;&#25991;&#26412;&#30340;&#36136;&#37327;&#21644;&#22810;&#26679;&#24615;&#12290;&#22312;&#21019;&#20316;&#24615;&#20889;&#20316;&#39046;&#22495;&#30340;&#35780;&#20272;&#20013;&#65292;&#19982;&#38750;QDAIF&#31639;&#27861;&#30456;&#27604;&#65292;QDAIF&#26356;&#24191;&#27867;&#22320;&#35206;&#30422;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#25351;&#23450;&#25628;&#32034;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through AI feedback, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#35843;&#25972;&#36880;&#28857;&#21487;&#29992;&#20449;&#24687;&#24230;&#37327;&#25351;&#26631;&#20026;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#30340;&#29256;&#26412;&#65292;&#23558;&#20854;&#21629;&#21517;&#20026;&#19978;&#19979;&#25991;PVI&#65292;&#24182;&#35777;&#26126;&#20102;&#19978;&#19979;&#25991;PVI&#30340;&#21487;&#38752;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12300</link><description>&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#20013;&#27979;&#37327;&#36880;&#28857;&#21487;&#29992;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Measuring Pointwise $\mathcal{V}$-Usable Information In-Context-ly. (arXiv:2310.12300v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12300
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#35843;&#25972;&#36880;&#28857;&#21487;&#29992;&#20449;&#24687;&#24230;&#37327;&#25351;&#26631;&#20026;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#30340;&#29256;&#26412;&#65292;&#23558;&#20854;&#21629;&#21517;&#20026;&#19978;&#19979;&#25991;PVI&#65292;&#24182;&#35777;&#26126;&#20102;&#19978;&#19979;&#25991;PVI&#30340;&#21487;&#38752;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21457;&#23637;&#32780;&#21463;&#21040;&#38738;&#30544;&#12290;&#26412;&#25991;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340;&#38590;&#24230;&#24230;&#37327;&#25351;&#26631;&#36880;&#28857;&#21487;&#29992;&#20449;&#24687;&#65288;PVI&#65289;&#35843;&#25972;&#20026;&#36866;&#29992;&#20110;&#19978;&#19979;&#25991;&#30340;&#29256;&#26412;&#65288;&#19978;&#19979;&#25991;PVI&#65289;&#12290;&#19982;&#21407;&#22987;PVI&#30456;&#27604;&#65292;&#19978;&#19979;&#25991;PVI&#26356;&#39640;&#25928;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#23569;&#37327;&#31034;&#20363;&#24182;&#19988;&#19981;&#38656;&#35201;&#24494;&#35843;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#35777;&#20998;&#26512;&#20197;&#35780;&#20272;&#19978;&#19979;&#25991;PVI&#30340;&#21487;&#38752;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#19978;&#19979;&#25991;PVI&#30340;&#20272;&#35745;&#20540;&#34920;&#29616;&#20986;&#31867;&#20284;&#20110;&#21407;&#22987;PVI&#30340;&#29305;&#24449;&#12290;&#20855;&#20307;&#38024;&#23545;&#19978;&#19979;&#25991;&#29615;&#22659;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19978;&#19979;&#25991;PVI&#30340;&#20272;&#35745;&#20540;&#22312;&#19981;&#21516;&#31034;&#20363;&#36873;&#21462;&#21644;&#25293;&#25668;&#27425;&#25968;&#19979;&#20445;&#25345;&#19968;&#33268;&#12290;&#22312;&#19981;&#21516;&#30340;&#31034;&#20363;&#36873;&#21462;&#20013;&#65292;&#19978;&#19979;&#25991;PVI&#30340;&#20272;&#35745;&#20540;&#30340;&#26041;&#24046;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#65292;&#36825;&#34920;&#26126;&#19978;&#19979;&#25991;PVI&#26159;&#31283;&#23450;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#19978;&#19979;&#25991;PVI&#26469;&#35782;&#21035;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning (ICL) is a new learning paradigm that has gained popularity along with the development of large language models. In this work, we adapt a recently proposed hardness metric, pointwise $\mathcal{V}$-usable information (PVI), to an in-context version (in-context PVI). Compared to the original PVI, in-context PVI is more efficient in that it requires only a few exemplars and does not require fine-tuning. We conducted a comprehensive empirical analysis to evaluate the reliability of in-context PVI. Our findings indicate that in-context PVI estimates exhibit similar characteristics to the original PVI. Specific to the in-context setting, we show that in-context PVI estimates remain consistent across different exemplar selections and numbers of shots. The variance of in-context PVI estimates across different exemplar selections is insignificant, which suggests that in-context PVI are stable. Furthermore, we demonstrate how in-context PVI can be employed to identify challen
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#20250;&#35805;&#24335;&#20581;&#24247;&#20195;&#29702;&#26694;&#26550;&#65292;&#26088;&#22312;&#20026;&#20195;&#29702;&#36171;&#20104;&#25209;&#21028;&#24615;&#24605;&#32500;&#12289;&#30693;&#35782;&#33719;&#21462;&#21644;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#20581;&#24247;&#25252;&#29702;&#26381;&#21153;&#12290;&#35813;&#26694;&#26550;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21307;&#30103;&#24037;&#20855;&#65292;&#23454;&#29616;&#22810;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#23545;&#35805;&#65292;&#24182;&#19982;&#22810;&#31181;&#29992;&#25143;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.02374</link><description>&lt;p&gt;
&#20250;&#35805;&#24335;&#20581;&#24247;&#20195;&#29702;&#65306;&#20010;&#24615;&#21270;&#30340;&#22522;&#20110;LLM&#30340;&#20195;&#29702;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;LLM&#30340;&#20250;&#35805;&#24335;&#20581;&#24247;&#20195;&#29702;&#26694;&#26550;&#65292;&#26088;&#22312;&#20026;&#20195;&#29702;&#36171;&#20104;&#25209;&#21028;&#24615;&#24605;&#32500;&#12289;&#30693;&#35782;&#33719;&#21462;&#21644;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#65292;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#20581;&#24247;&#25252;&#29702;&#26381;&#21153;&#12290;&#35813;&#26694;&#26550;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21307;&#30103;&#24037;&#20855;&#65292;&#23454;&#29616;&#22810;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#23545;&#35805;&#65292;&#24182;&#19982;&#22810;&#31181;&#29992;&#25143;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20250;&#35805;&#24335;&#20581;&#24247;&#20195;&#29702;&#65288;CHAs&#65289;&#26159;&#19968;&#31181;&#20114;&#21160;&#31995;&#32479;&#65292;&#26088;&#22312;&#36890;&#36807;&#36827;&#34892;&#20849;&#24773;&#23545;&#35805;&#21644;&#22788;&#29702;&#22810;&#27169;&#24577;&#25968;&#25454;&#26469;&#22686;&#24378;&#20010;&#20154;&#20581;&#24247;&#25252;&#29702;&#26381;&#21153;&#12290;&#24403;&#21069;&#30340;CHAs&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#21033;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#31995;&#32479;&#65292;&#20027;&#35201;&#20851;&#27880;&#23545;&#35805;&#65292;&#20294;&#24448;&#24448;&#32570;&#20047;&#20840;&#38754;&#30340;&#20195;&#29702;&#33021;&#21147;&#12290;&#36825;&#21253;&#25324;&#20174;&#21487;&#31359;&#25140;&#35774;&#22791;&#12289;&#20840;&#22825;&#20505;&#25968;&#25454;&#25910;&#38598;&#28304;&#21644;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#33719;&#21462;&#20010;&#20154;&#29992;&#25143;&#30340;&#20581;&#24247;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#20197;&#21450;&#25972;&#21512;&#26368;&#26032;&#21457;&#24067;&#30340;&#20581;&#24247;&#35265;&#35299;&#65292;&#24182;&#19982;&#24050;&#24314;&#31435;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#36830;&#25509;&#12290;&#25105;&#20204;&#27491;&#22312;&#24320;&#21457;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#36171;&#20104;CHAs&#25209;&#21028;&#24615;&#24605;&#32500;&#12289;&#30693;&#35782;&#33719;&#21462;&#21644;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#26469;&#22686;&#24378;&#23427;&#20204;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;CHA&#24179;&#21488;&#30001;LLMs&#39537;&#21160;&#65292;&#26080;&#32541;&#38598;&#25104;&#20102;&#21307;&#30103;&#24037;&#20855;&#65292;&#23454;&#29616;&#20102;&#22810;&#35821;&#35328;&#21644;&#22810;&#27169;&#24577;&#23545;&#35805;&#65292;&#24182;&#19982;&#21508;&#31181;&#29992;&#25143;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#36827;&#34892;&#25509;&#21475;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20854;&#22312;&#22788;&#29702;&#22797;&#26434;&#21307;&#30103;&#20219;&#21153;&#26041;&#38754;&#30340;&#29087;&#32451;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conversational Health Agents (CHAs) are interactive systems designed to enhance personal healthcare services by engaging in empathetic conversations and processing multimodal data. While current CHAs, especially those utilizing Large Language Models (LLMs), primarily focus on conversation, they often lack comprehensive agent capabilities. This includes the ability to access personal user health data from wearables, 24/7 data collection sources, and electronic health records, as well as integrating the latest published health insights and connecting with established multimodal data analysis tools. We are developing a framework to empower CHAs by equipping them with critical thinking, knowledge acquisition, and problem-solving abilities. Our CHA platform, powered by LLMs, seamlessly integrates healthcare tools, enables multilingual and multimodal conversations, and interfaces with a variety of user data analysis tools. We illustrate its proficiency in handling complex healthcare tasks, s
&lt;/p&gt;</description></item><item><title>Spider4SPARQL&#26159;&#19968;&#20010;&#26032;&#30340;SPARQL&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#22823;&#37327;&#25163;&#24037;&#29983;&#25104;&#30340;NL&#38382;&#39064;&#21644;&#29420;&#29305;&#12289;&#26032;&#39062;&#12289;&#22797;&#26434;&#30340;SPARQL&#26597;&#35810;&#65292;&#26088;&#22312;&#35780;&#20272;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2309.16248</link><description>&lt;p&gt;
Spider4SPARQL&#65306;&#29992;&#20110;&#35780;&#20272;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#31995;&#32479;&#30340;&#22797;&#26434;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems. (arXiv:2309.16248v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16248
&lt;/p&gt;
&lt;p&gt;
Spider4SPARQL&#26159;&#19968;&#20010;&#26032;&#30340;SPARQL&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#21547;&#22823;&#37327;&#25163;&#24037;&#29983;&#25104;&#30340;NL&#38382;&#39064;&#21644;&#29420;&#29305;&#12289;&#26032;&#39062;&#12289;&#22797;&#26434;&#30340;SPARQL&#26597;&#35810;&#65292;&#26088;&#22312;&#35780;&#20272;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#25968;&#37327;&#21644;&#21487;&#29992;&#24615;&#30340;&#22686;&#21152;&#65292;&#25552;&#20379;&#22823;&#22411;&#21644;&#30495;&#23454;&#30340;&#22522;&#20934;&#29992;&#20110;&#35780;&#20272;&#30693;&#35782;&#22270;&#35889;&#38382;&#31572;&#65288;KBQA&#65289;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#22823;&#37096;&#20998;&#22522;&#20934;&#20381;&#36182;&#22522;&#20110;&#27169;&#24335;&#30340;SPARQL&#26597;&#35810;&#29983;&#25104;&#26041;&#27861;&#12290;&#38543;&#21518;&#30340;&#33258;&#28982;&#35821;&#35328;&#65288;NL&#65289;&#38382;&#39064;&#29983;&#25104;&#36890;&#36807;&#20247;&#21253;&#25110;&#20854;&#20182;&#33258;&#21160;&#21270;&#26041;&#27861;&#36827;&#34892;&#65292;&#22914;&#22522;&#20110;&#35268;&#21017;&#30340;&#25913;&#20889;&#25110;NL&#38382;&#39064;&#27169;&#26495;&#12290;&#34429;&#28982;&#20854;&#20013;&#19968;&#20123;&#25968;&#25454;&#38598;&#35268;&#27169;&#30456;&#24403;&#22823;&#65292;&#20294;&#23427;&#20204;&#30340;&#32570;&#28857;&#22312;&#20110;&#22522;&#20110;&#27169;&#24335;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#24182;&#19981;&#24635;&#26159;&#33021;&#22815;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#30495;&#23454;&#19990;&#30028;&#29615;&#22659;&#20013;&#20154;&#20204;&#25552;&#20986;&#30340;&#27169;&#31946;&#19988;&#35821;&#35328;&#22810;&#26679;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Spider4SPARQL - &#19968;&#20010;&#26032;&#30340;SPARQL&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;9,693&#20010;&#20808;&#21069;&#23384;&#22312;&#30340;&#25163;&#24037;&#29983;&#25104;&#30340;NL&#38382;&#39064;&#21644;4,721&#20010;&#21807;&#19968;&#12289;&#26032;&#39062;&#19988;&#22797;&#26434;&#30340;SPARQL&#26597;&#35810;&#65292;&#22797;&#26434;&#24615;&#21508;&#19981;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KBQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts.  In this paper, we introduce Spider4SPARQL - a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#20581;&#23545;&#40784;&#30340;LLM&#65288;RA-LLM&#65289;&#65292;&#29992;&#20110;&#38450;&#24481;&#21487;&#33021;&#21457;&#29983;&#30340;&#23545;&#40784;&#30772;&#22351;&#25915;&#20987;&#12290;RA-LLM&#21487;&#20197;&#30452;&#25509;&#22312;&#29616;&#26377;&#30340;&#23545;&#40784;LLM&#19978;&#26500;&#24314;&#65292;&#24182;&#36890;&#36807;&#31283;&#20581;&#30340;&#23545;&#40784;&#26816;&#26597;&#20989;&#25968;&#26469;&#30830;&#20445;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.14348</link><description>&lt;p&gt;
&#36890;&#36807;&#31283;&#20581;&#23545;&#40784;&#30340;LLM&#25269;&#24481;&#23545;&#40784;&#30772;&#22351;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM. (arXiv:2309.14348v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#20581;&#23545;&#40784;&#30340;LLM&#65288;RA-LLM&#65289;&#65292;&#29992;&#20110;&#38450;&#24481;&#21487;&#33021;&#21457;&#29983;&#30340;&#23545;&#40784;&#30772;&#22351;&#25915;&#20987;&#12290;RA-LLM&#21487;&#20197;&#30452;&#25509;&#22312;&#29616;&#26377;&#30340;&#23545;&#40784;LLM&#19978;&#26500;&#24314;&#65292;&#24182;&#36890;&#36807;&#31283;&#20581;&#30340;&#23545;&#40784;&#26816;&#26597;&#20989;&#25968;&#26469;&#30830;&#20445;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#25285;&#24515;LLMs&#21487;&#33021;&#34987;&#28389;&#29992;&#26469;&#29983;&#25104;&#26377;&#23475;&#25110;&#24694;&#24847;&#20869;&#23481;&#12290;&#23613;&#31649;&#26377;&#19968;&#31995;&#21015;&#30340;&#30740;&#31350;&#19987;&#27880;&#20110;&#23545;&#40784;LLMs&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#65292;&#24182;&#38450;&#27490;&#23427;&#20204;&#29983;&#25104;&#19981;&#36866;&#24403;&#30340;&#20869;&#23481;&#65292;&#20294;&#36825;&#20123;&#23545;&#40784;&#36890;&#24120;&#26159;&#33030;&#24369;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23545;&#25239;&#20248;&#21270;&#25110;&#25163;&#24037;&#26500;&#24314;&#30340;&#36234;&#29425;&#25552;&#31034;&#26469;&#32469;&#36807;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31283;&#20581;&#23545;&#40784;&#30340;LLM&#65288;RA-LLM&#65289;&#65292;&#20197;&#38450;&#33539;&#28508;&#22312;&#30340;&#23545;&#40784;&#30772;&#22351;&#25915;&#20987;&#12290;RA-LLM&#21487;&#20197;&#30452;&#25509;&#26500;&#24314;&#22312;&#29616;&#26377;&#30340;&#23545;&#40784;LLM&#19978;&#65292;&#36890;&#36807;&#20855;&#26377;&#31283;&#20581;&#23545;&#40784;&#26816;&#26597;&#21151;&#33021;&#30340;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#23545;&#21407;&#22987;LLM&#36827;&#34892;&#20219;&#20309;&#26114;&#36149;&#30340;&#37325;&#26032;&#35757;&#32451;&#25110;&#24494;&#35843;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#39564;&#35777;&#20102;RA-LLM&#22312;&#38450;&#24481;&#23545;&#40784;&#30772;&#22351;&#25915;&#20987;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#29616;&#23454;&#19990;&#30028;&#30340;&#23454;&#39564;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted jailbreaking prompts. In this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against potential alignment-breaking attacks. RA-LLM can be directly constructed upon an existing aligned LLM with a robust alignment checking function, without requiring any expensive retraining or fine-tuning process of the original LLM. Furthermore, we also provide a theoretical analysis for RA-LLM to verify its effectiveness in defending against alignment-breaking attacks. Through real-world experiments
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;LLMs&#30340;&#20013;&#25991;Prompt Attack&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26088;&#22312;&#35780;&#20272;&#38450;&#24481;&#25552;&#31034;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.11830</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#20855;&#26377;&#24694;&#24847;&#20869;&#23481;&#30340;LLMs&#30340;&#20013;&#25991;&#25552;&#31034;&#25915;&#20987;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
A Chinese Prompt Attack Dataset for LLMs with Evil Content. (arXiv:2309.11830v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11830
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;LLMs&#30340;&#20013;&#25991;Prompt Attack&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26088;&#22312;&#35780;&#20272;&#38450;&#24481;&#25552;&#31034;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#25991;&#26412;&#29702;&#35299;&#21644;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#20248;&#28857;&#12290;&#28982;&#32780;&#65292;LLMs&#22312;&#24212;&#29992;&#20013;&#23384;&#22312;&#29983;&#25104;&#26377;&#23475;&#20869;&#23481;&#30340;&#39118;&#38505;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;Prompt Attack&#31561;&#40657;&#30418;&#25915;&#20987;&#26041;&#27861;&#26102;&#12290;&#30740;&#31350;&#20154;&#21592;&#23545;LLMs&#30340;Prompt Attack&#21644;Defense&#24456;&#24863;&#20852;&#36259;&#65292;&#20294;&#30446;&#21069;&#27809;&#26377;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#26469;&#35780;&#20272;&#38450;&#24481;Prompt Attack&#30340;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;LLMs&#30340;&#20013;&#25991;Prompt Attack&#25968;&#25454;&#38598;&#65292;&#31216;&#20026;CPAD&#12290;&#25105;&#20204;&#30340;&#25552;&#31034;&#26088;&#22312;&#24341;&#23548;LLMs&#29983;&#25104;&#20855;&#26377;&#22810;&#20010;&#31934;&#24515;&#35774;&#35745;&#30340;&#25552;&#31034;&#25915;&#20987;&#26041;&#27861;&#21644;&#24191;&#27867;&#20851;&#27880;&#30340;&#25915;&#20987;&#20869;&#23481;&#30340;&#24847;&#22806;&#36755;&#20986;&#12290;&#19982;&#20197;&#21069;&#28041;&#21450;&#23433;&#20840;&#20272;&#35745;&#30340;&#25968;&#25454;&#38598;&#19981;&#21516;&#65292;&#25105;&#20204;&#26500;&#24314;&#30340;&#25552;&#31034;&#32771;&#34385;&#20102;&#19977;&#20010;&#32500;&#24230;&#65306;&#20869;&#23481;&#12289;&#25915;&#20987;&#26041;&#27861;&#21644;&#30446;&#26631;&#65292;&#22240;&#27492;&#21487;&#20197;&#36731;&#26494;&#35780;&#20272;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#22522;&#20934;&#22871;&#20214;&#65292;&#35813;&#22871;&#20214;&#21253;&#25324;&#20102;&#31867;&#20284;&#20110;&#20256;&#32479;&#31995;&#32479;&#32452;&#20214;&#30340;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.03886</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#21151;&#33021;&#35299;&#37322;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
A Function Interpretation Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#22522;&#20934;&#22871;&#20214;&#65292;&#35813;&#22871;&#20214;&#21253;&#25324;&#20102;&#31867;&#20284;&#20110;&#20256;&#32479;&#31995;&#32479;&#32452;&#20214;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#20154;&#31867;&#21487;&#35835;&#30340;&#25551;&#36848;&#26631;&#35760;&#31070;&#32463;&#32593;&#32476;&#23376;&#27169;&#22359;&#23545;&#20110;&#35768;&#22810;&#19979;&#28216;&#20219;&#21153;&#38750;&#24120;&#26377;&#29992;&#65306;&#36825;&#20123;&#25551;&#36848;&#21487;&#20197;&#26292;&#38706;&#22833;&#36133;&#12289;&#24341;&#23548;&#24178;&#39044;&#65292;&#29978;&#33267;&#21487;&#20197;&#35299;&#37322;&#37325;&#35201;&#30340;&#27169;&#22411;&#34892;&#20026;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#22823;&#22810;&#25968;&#22522;&#20110;&#26426;&#26800;&#21407;&#29702;&#30340;&#24050;&#35757;&#32451;&#32593;&#32476;&#25551;&#36848;&#37117;&#28041;&#21450;&#21040;&#23567;&#27169;&#22411;&#12289;&#29421;&#20041;&#29616;&#35937;&#65292;&#24182;&#19988;&#38656;&#35201;&#22823;&#37327;&#20154;&#21147;&#12290;&#22312;&#19981;&#26029;&#22686;&#21152;&#30340;&#27169;&#22411;&#22823;&#23567;&#21644;&#22797;&#26434;&#24615;&#20013;&#26631;&#35760;&#20986;&#25152;&#26377;&#20154;&#21487;&#35299;&#37322;&#30340;&#23376;&#35745;&#31639;&#20960;&#20046;&#32943;&#23450;&#38656;&#35201;&#33021;&#22815;&#33258;&#21160;&#29983;&#25104;&#21644;&#39564;&#35777;&#25551;&#36848;&#30340;&#24037;&#20855;&#12290;&#26368;&#36817;&#65292;&#21033;&#29992;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#26631;&#35760;&#30340;&#25216;&#26415;&#24320;&#22987;&#21463;&#21040;&#20851;&#27880;&#65292;&#20294;&#35780;&#20272;&#20854;&#26377;&#25928;&#24615;&#30340;&#26041;&#27861;&#26377;&#38480;&#19988;&#20020;&#26102;&#12290;&#25105;&#20204;&#24212;&#35813;&#22914;&#20309;&#39564;&#35777;&#21644;&#27604;&#36739;&#24320;&#25918;&#24335;&#26631;&#35760;&#24037;&#20855;&#65311;&#26412;&#25991;&#20171;&#32461;&#20102;FIND&#65288;&#20989;&#25968;&#35299;&#37322;&#21644;&#25551;&#36848;&#65289;&#65292;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#33258;&#21160;&#35299;&#37322;&#26041;&#27861;&#26500;&#24314;&#27169;&#22359;&#30340;&#22522;&#20934;&#22871;&#20214;&#12290;FIND&#21253;&#21547;&#20102;&#31867;&#20284;&#20110;&#20256;&#32479;&#31995;&#32479;&#30340;&#32452;&#20214;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors. To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor. Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically. Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc. How should we validate and compare open-ended labeling tools? This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of tr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#21512;&#35843;&#26597;&#20102;&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#20844;&#24179;&#24615;&#21644;&#36131;&#20219;&#31561;&#22810;&#20010;&#32500;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#24314;&#35758;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2307.16680</link><description>&lt;p&gt;
&#20851;&#20110;&#26368;&#20808;&#36827;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#26223;&#35266;&#65306;&#19968;&#39033;&#32508;&#21512;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#21512;&#35843;&#26597;&#20102;&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#20844;&#24179;&#24615;&#21644;&#36131;&#20219;&#31561;&#22810;&#20010;&#32500;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#24314;&#35758;&#21644;&#26410;&#26469;&#21457;&#23637;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21644;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#39046;&#20808;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23545;&#20154;&#31867;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#20135;&#29983;&#20102;&#38761;&#21629;&#24615;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#23454;&#38469;&#24212;&#29992;&#20063;&#26292;&#38706;&#20986;&#22266;&#26377;&#30340;&#39118;&#38505;&#65292;&#31361;&#26174;&#20102;&#23427;&#20204;&#30340;&#21452;&#37325;&#24615;&#36136;&#65292;&#24182;&#24341;&#21457;&#20102;&#23545;&#23427;&#20204;&#21487;&#20449;&#24230;&#30340;&#25285;&#24551;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#20851;&#20110;&#36825;&#20010;&#20027;&#39064;&#30340;&#25991;&#29486;&#65292;&#20294;&#38024;&#23545;&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#21450;&#20854;&#21487;&#20449;&#24230;&#30340;&#32508;&#21512;&#35843;&#26597;&#20173;&#28982;&#24456;&#23569;&#35265;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#26412;&#25991;&#35843;&#26597;&#20102;&#28041;&#21450;&#36825;&#20123;&#27169;&#22411;&#30340;&#38271;&#26399;&#21644;&#26032;&#20852;&#23041;&#32961;&#65292;&#28085;&#30422;&#20102;&#38544;&#31169;&#12289;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36131;&#20219;&#36825;&#22235;&#20010;&#22522;&#26412;&#32500;&#24230;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#24352;&#35814;&#23613;&#30340;&#22320;&#22270;&#65292;&#27010;&#36848;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#38469;&#24314;&#35758;&#21644;&#26410;&#26469;&#30340;&#21457;&#23637;&#26041;&#21521;&#12290;&#36825;&#20123;&#21162;&#21147;&#23545;&#20110;&#20419;&#36827;&#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#20449;&#24230;&#37096;&#32626;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models and large language models have emerged as leading-edge generative models and have sparked a revolutionary impact on various aspects of human life. However, the practical implementation of these models has also exposed inherent risks, highlighting their dual nature and raising concerns regarding their trustworthiness. Despite the abundance of literature on this subject, a comprehensive survey specifically delving into the intersection of large-scale generative models and their trustworthiness remains largely absent. To bridge this gap, This paper investigates both the long-standing and emerging threats associated with these models across four fundamental dimensions: privacy, security, fairness, and responsibility. In this way, we construct an extensive map outlining the trustworthiness of these models, while also providing practical recommendations and identifying future directions. These efforts are crucial for promoting the trustworthy deployment of these models, ulti
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;softmax-attention&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#22312;p&#25110;&#31561;&#20215;&#30340;W&#19978;&#36816;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;&#26368;&#22823;&#36793;&#32536;&#35299;&#65292;&#36825;&#23558;&#23616;&#37096;&#26368;&#20248;&#30340;&#26631;&#35760;&#19982;&#38750;&#26368;&#20248;&#30340;&#26631;&#35760;&#20998;&#38548;&#24320;&#12290;&#36825;&#26126;&#30830;&#22320;&#23558;&#27880;&#24847;&#21147;&#26426;&#21046;&#24418;&#24335;&#21270;&#20026;&#26631;&#35760;&#20998;&#31163;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2306.13596</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#20013;&#30340;&#36793;&#32536;&#26368;&#22823;&#21270;
&lt;/p&gt;
&lt;p&gt;
Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13596
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35777;&#26126;&#20102;&#65292;&#22312;softmax-attention&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#22312;p&#25110;&#31561;&#20215;&#30340;W&#19978;&#36816;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;&#21487;&#20197;&#25910;&#25947;&#21040;&#19968;&#20010;&#26368;&#22823;&#36793;&#32536;&#35299;&#65292;&#36825;&#23558;&#23616;&#37096;&#26368;&#20248;&#30340;&#26631;&#35760;&#19982;&#38750;&#26368;&#20248;&#30340;&#26631;&#35760;&#20998;&#38548;&#24320;&#12290;&#36825;&#26126;&#30830;&#22320;&#23558;&#27880;&#24847;&#21147;&#26426;&#21046;&#24418;&#24335;&#21270;&#20026;&#26631;&#35760;&#20998;&#31163;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;Transformer&#26550;&#26500;&#30340;&#26680;&#24515;&#32452;&#20214;&#65292;&#20063;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#24778;&#20154;&#25104;&#21151;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#27880;&#24847;&#21147;&#26426;&#21046;&#32972;&#21518;&#30340;&#29702;&#35770;&#21407;&#21017;&#23578;&#19981;&#28165;&#26970;&#65292;&#29305;&#21035;&#26159;&#23427;&#30340;&#38750;&#20984;&#20248;&#21270;&#21160;&#21147;&#23398;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#24320;&#21019;&#24615;&#30340;softmax-attention&#27169;&#22411;$f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$&#65292;&#20854;&#20013;$\boldsymbol{X}$&#26159;&#26631;&#35760;&#24207;&#21015;&#65292;$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$&#26159;&#21487;&#35843;&#21442;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$\boldsymbol{p}$&#25110;&#31561;&#20215;&#30340;$\boldsymbol{W}$&#19978;&#36816;&#34892;&#26799;&#24230;&#19979;&#38477;&#20250;&#27839;&#30528;&#26041;&#21521;&#25910;&#25947;&#21040;&#20998;&#38548;&#8220;&#23616;&#37096;&#26368;&#20248;&#8221;&#26631;&#35760;&#21644;&#8220;&#38750;&#26368;&#20248;&#8221;&#26631;&#35760;&#30340;&#26368;&#22823;&#36793;&#32536;&#35299;&#12290;&#36825;&#26126;&#30830;&#22320;&#24418;&#24335;&#21270;&#20102;&#27880;&#24847;&#21147;&#20316;&#20026;&#19968;&#31181;&#26631;&#35760;&#20998;&#31163;&#26426;&#21046;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#19968;&#33324;&#25968;&#25454;&#65292;&#24182;&#20351;&#29992;&#23884;&#20837;$\boldsymbol{Xv}$&#21644;$\texttt{softmax}(\boldsymbol{XWp})$&#31934;&#32454;&#22320;&#34920;&#24449;&#26631;&#35760;&#30340;&#8220;&#26368;&#20248;&#24615;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention mechanism is a central component of the transformer architecture which led to the phenomenal success of large language models. However, the theoretical principles underlying the attention mechanism are poorly understood, especially its nonconvex optimization dynamics. In this work, we explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle \boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where, $\boldsymbol{X}$ is the token sequence and $(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We prove that running gradient descent on $\boldsymbol{p}$, or equivalently $\boldsymbol{W}$, converges in direction to a max-margin solution that separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly formalizes attention as a token separation mechanism. Remarkably, our results are applicable to general data and precisely characterize $\textit{optimality}$ of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and
&lt;/p&gt;</description></item><item><title>ALGO&#26694;&#26550;&#20351;&#29992;&#30001;LLM&#29983;&#25104;&#30340;&#31070;&#35861;&#25351;&#23548;&#21019;&#36896;&#21644;&#39564;&#35777;&#31639;&#27861;&#31243;&#24207;&#65292;&#20197;&#25552;&#39640;&#29616;&#26377;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#30340;&#31639;&#27861;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.14591</link><description>&lt;p&gt;
ALGO&#65306;&#20351;&#29992;&#29983;&#25104;&#30340;&#31070;&#35861;&#39564;&#35777;&#31243;&#24207;&#30340;&#21512;&#25104;&#31639;&#27861;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;
ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers. (arXiv:2305.14591v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14591
&lt;/p&gt;
&lt;p&gt;
ALGO&#26694;&#26550;&#20351;&#29992;&#30001;LLM&#29983;&#25104;&#30340;&#31070;&#35861;&#25351;&#23548;&#21019;&#36896;&#21644;&#39564;&#35777;&#31639;&#27861;&#31243;&#24207;&#65292;&#20197;&#25552;&#39640;&#29616;&#26377;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#30340;&#31639;&#27861;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(Large language models, LLMs)&#22312;&#23454;&#29616;&#20195;&#30721;&#30340;&#21151;&#33021;&#25551;&#36848;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#38656;&#35201;&#30830;&#23450;&#36866;&#24403;&#31639;&#27861;&#30340;&#31639;&#27861;&#38382;&#39064;&#19978;&#20127;&#38656;&#25552;&#21319;&#12290;&#27492;&#22806;&#65292;LLM&#29983;&#25104;&#30340;&#31243;&#24207;&#32570;&#20047;&#20445;&#35777;&#27491;&#30830;&#24615;&#24182;&#38656;&#35201;&#20154;&#24037;&#39564;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ALGO&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#30001;LLM&#29983;&#25104;&#30340;&#31070;&#35861;&#25351;&#23548;&#21019;&#36896;&#21644;&#39564;&#35777;&#31639;&#27861;&#31243;&#24207;&#12290;ALGO&#39318;&#20808;&#36890;&#36807;&#20419;&#20351;LLM&#26522;&#20030;&#30456;&#20851;&#21464;&#37327;&#30340;&#25152;&#26377;&#32452;&#21512;&#26469;&#29983;&#25104;&#20855;&#26377;&#21487;&#33021;&#30340;&#27491;&#30830;&#24615;&#20294;&#21487;&#33021;&#36739;&#24930;&#30340;&#21442;&#32771;&#31070;&#35861;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#35813;&#31070;&#35861;&#25351;&#23548;&#20219;&#24847;&#25628;&#32034;&#31574;&#30053;&#26469;&#25506;&#32034;&#31639;&#27861;&#31354;&#38388;&#24182;&#39564;&#35777;&#21512;&#25104;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;LLM&#29983;&#25104;&#30340;&#31070;&#35861;&#22312;88%&#30340;&#24773;&#20917;&#19979;&#26159;&#27491;&#30830;&#30340;&#12290;&#20351;&#29992;&#36825;&#20123;&#31070;&#35861;&#20316;&#20026;&#39564;&#35777;&#31243;&#24207;&#65292;ALGO&#21487;&#20197;&#20197;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#24335;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;&#20195;&#30721;&#29983;&#25104;&#27169;&#22411;&#38598;&#25104;&#65292;&#20197;&#25552;&#39640;&#20854;&#31639;&#27861;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) excel at implementing code from functionality descriptions, but struggle with algorithmic problems that require not only implementation but also identification of the suitable algorithm. Moreover, LLM-generated programs lack guaranteed correctness and require human verification. To address these challenges, we propose ALGO, a framework that synthesizes Algorithmic programs with LLM-Generated Oracles to guide the creation and verify their correctness. ALGO first generates a probably correct but possibly slow reference oracle by prompting an LLM to exhaustively enumerate all the combinations of relevant variables. This oracle is then utilized to guide an arbitrary search strategy in exploring the algorithm space and to verify the algorithms synthesized. Our study shows that the LLM-generated oracles are correct for 88% of the cases. With the oracles as verifiers, ALGO can be integrated with any existing code generation model in a model-agnostic manner to enha
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#38271;&#26399;&#35760;&#24518;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#33258;&#28982;&#25968;&#25454;&#38598;&#65292;&#20197;&#24110;&#21161;&#25913;&#36827;&#29616;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25968;&#25454;&#38598;&#30001; GPT 3.5 &#29983;&#25104;&#65292;&#25688;&#35201;&#21253;&#25324;&#26469;&#33258; Project Gutenberg &#30340; 1500 &#26412;&#20070;&#20013;&#27599;&#20010;&#22330;&#26223;&#30340;&#24635;&#32467;&#65292;&#20197;&#21450;&#37197;&#22871;&#30340;&#38405;&#35835;&#29702;&#35299;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.13877</link><description>&lt;p&gt;
Narrative XL: &#19968;&#20010;&#29992;&#20110;&#38271;&#26399;&#35760;&#24518;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
Narrative XL: A Large-scale Dataset For Long-Term Memory Models. (arXiv:2305.13877v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#38271;&#26399;&#35760;&#24518;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#33258;&#28982;&#25968;&#25454;&#38598;&#65292;&#20197;&#24110;&#21161;&#25913;&#36827;&#29616;&#26377;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#25968;&#25454;&#38598;&#30001; GPT 3.5 &#29983;&#25104;&#65292;&#25688;&#35201;&#21253;&#25324;&#26469;&#33258; Project Gutenberg &#30340; 1500 &#26412;&#20070;&#20013;&#27599;&#20010;&#22330;&#26223;&#30340;&#24635;&#32467;&#65292;&#20197;&#21450;&#37197;&#22871;&#30340;&#38405;&#35835;&#29702;&#35299;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22823;&#22810;&#25968;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#20219;&#20309;&#38271;&#26399;&#35760;&#24518;&#26426;&#21046;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24212;&#29992;&#12290;&#35201;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#19981;&#20165;&#38656;&#35201;&#23545;&#20856;&#22411;&#30340;&#21464;&#21387;&#22120;&#26550;&#26500;&#25110;&#35757;&#32451;&#31243;&#24207;&#36827;&#34892;&#26356;&#25913;&#65292;&#36824;&#38656;&#35201;&#19968;&#20010;&#21487;&#20197;&#35757;&#32451;&#21644;&#35780;&#20272;&#36825;&#20123;&#26032;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35748;&#20026;&#29616;&#26377;&#30340;&#36164;&#28304;&#32570;&#23569;&#19968;&#20123;&#20851;&#38190;&#23646;&#24615;&#65292;&#30446;&#21069;&#27809;&#26377;&#36275;&#22815;&#35268;&#27169;&#30340;&#33258;&#28982;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#65288;&#32780;&#19981;&#20165;&#20165;&#26159;&#35780;&#20272;&#65289;&#38271;&#26399;&#35760;&#24518;&#35821;&#35328;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21033;&#29992;&#30701;&#26399;&#35760;&#24518;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#26469;&#21019;&#24314;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#38598;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20351;&#29992; GPT 3.5&#65292;&#25105;&#20204;&#24635;&#32467;&#20102; Project Gutenberg &#20013; 1500 &#26412;&#25163;&#24037;&#31579;&#36873;&#30340;&#20070;&#31821;&#20013;&#30340;&#27599;&#20010;&#22330;&#26223;&#65292;&#27599;&#26412;&#20070;&#24471;&#21040;&#22823;&#32422; 150 &#20010;&#22330;&#26223;&#32423;&#21035;&#30340;&#25688;&#35201;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20123;&#38405;&#35835;&#29702;&#35299;&#38382;&#39064;&#65292;&#21253;&#25324;&#19977;&#31181;&#31867;&#22411;&#30340;&#22810;&#39033;&#36873;&#25321;&#22330;&#26223;&#35782;&#21035;&#38382;&#39064;&#65292;&#20197;&#21450;...
&lt;/p&gt;
&lt;p&gt;
Despite their tremendous successes, most large language models do not have any long-term memory mechanisms, which restricts their applications. Overcoming this limitation would not only require changes to the typical transformer architectures or training procedures, but also a dataset on which these new models could be trained and evaluated. We argue that existing resources lack a few key properties, and that at present, there are no naturalistic datasets of sufficient scale to train (and not only evaluate) long-term memory language models. We then present our solution that capitalizes on the advances in short-term memory language models to create such a dataset. Using GPT 3.5, we summarized each scene in 1500 hand-curated books from Project Gutenberg, which resulted in approximately 150 scene-level summaries per book. We then created a number of reading comprehension questions based on these summaries, including three types of multiple-choice scene recognition questions, as well as fr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#31561;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2304.11090</link><description>&lt;p&gt;
&#22312;ChatGPT&#26102;&#20195;&#36808;&#21521;&#36127;&#36131;&#20219;&#30340;&#20154;&#24037;&#26234;&#33021;&#65306;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#30340;&#21442;&#32771;&#26550;&#26500;
&lt;/p&gt;
&lt;p&gt;
Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#65292;&#37325;&#28857;&#20851;&#27880;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#31561;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#12289;Bard&#21644;&#20854;&#20182;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#25512;&#20986;&#22312;&#20840;&#29699;&#33539;&#22260;&#20869;&#24341;&#36215;&#20102;&#24040;&#22823;&#20851;&#27880;&#12290;&#22522;&#30784;&#27169;&#22411;&#23558;&#25104;&#20026;&#26410;&#26469;&#22823;&#22810;&#25968;AI&#31995;&#32479;&#30340;&#22522;&#30784;&#26500;&#24314;&#22359;&#30340;&#36235;&#21183;&#27491;&#22312;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#23558;&#22522;&#30784;&#27169;&#22411;&#32435;&#20837;AI&#31995;&#32479;&#24341;&#21457;&#20102;&#23545;&#36127;&#36131;&#20219;AI&#30340;&#37325;&#22823;&#20851;&#27880;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#40657;&#21283;&#23376;&#24615;&#36136;&#21644;&#24555;&#36895;&#21457;&#23637;&#30340;&#36229;&#32423;&#26234;&#33021;&#24341;&#36215;&#30340;&#12290;&#27492;&#22806;&#65292;&#22522;&#30784;&#27169;&#22411;&#30340;&#22686;&#38271;&#33021;&#21147;&#26368;&#32456;&#21487;&#33021;&#20250;&#21534;&#22124;AI&#31995;&#32479;&#30340;&#20854;&#20182;&#32452;&#20214;&#65292;&#24341;&#20837;&#26550;&#26500;&#35774;&#35745;&#20013;&#30340;&#36816;&#21160;&#36793;&#30028;&#21644;&#25509;&#21475;&#28436;&#21464;&#25361;&#25112;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#27169;&#24335;&#20026;&#23548;&#21521;&#30340;&#36127;&#36131;&#20219;AI-by-design&#21442;&#32771;&#26550;&#26500;&#65292;&#29992;&#20110;&#35774;&#35745;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#12290;&#29305;&#21035;&#22320;&#65292;&#26412;&#25991;&#39318;&#20808;&#21576;&#29616;&#20102;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#22312;&#26550;&#26500;&#28436;&#36827;&#26041;&#38754;&#30340;&#21457;&#23637;&#65292;&#20174;"&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#36830;&#25509;&#22120;"&#21040;"&#22522;&#30784;&#27169;&#22411;&#20316;&#20026;&#21333;&#29255;&#26426;&#26680;"&#12290;&#28982;&#21518;&#65292;&#23427;&#25552;&#20986;&#20102;&#19968;&#20010;&#21442;&#32771;&#26550;&#26500;&#65292;&#21253;&#25324;&#20116;&#20010;&#31867;&#21035;&#30340;&#27169;&#24335;&#65292;&#37325;&#28857;&#20851;&#27880;&#20851;&#38190;&#35774;&#35745;&#20803;&#32032;&#65292;&#20363;&#22914;&#21487;&#35299;&#37322;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#21442;&#32771;&#26550;&#26500;&#20026;&#35774;&#35745;&#36127;&#36131;&#20219;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;AI&#31995;&#32479;&#25552;&#20379;&#20102;&#31995;&#32479;&#21270;&#21644;&#36879;&#26126;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
&lt;/p&gt;</description></item><item><title>SEAM&#26159;&#19968;&#31181;&#38598;&#25104;&#20102;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#30340;&#27169;&#22411;&#65292;&#20026;&#23454;&#29616;&#38405;&#35835;&#20013;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#23436;&#25972;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#20102;&#37325;&#35201;&#19968;&#27493;&#12290;</title><link>http://arxiv.org/abs/2303.05221</link><description>&lt;p&gt;
SEAM:&#19968;&#31181;&#38598;&#25104;&#20102;&#21477;&#23376;&#22788;&#29702;&#19982;&#38405;&#35835;&#20013;&#30524;&#21160;&#30340;&#28608;&#27963;&#32806;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SEAM: An Integrated Activation-Coupled Model of Sentence Processing and Eye Movements in Reading. (arXiv:2303.05221v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05221
&lt;/p&gt;
&lt;p&gt;
SEAM&#26159;&#19968;&#31181;&#38598;&#25104;&#20102;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#30340;&#27169;&#22411;&#65292;&#20026;&#23454;&#29616;&#38405;&#35835;&#20013;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#23436;&#25972;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#20102;&#37325;&#35201;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38405;&#35835;&#20013;&#30340;&#30524;&#21160;&#25511;&#21046;&#27169;&#22411;&#36890;&#24120;&#38598;&#20013;&#22312;&#35270;&#35273;&#12289;&#27880;&#24847;&#12289;&#35789;&#27719;&#21644;&#36816;&#21160;&#36807;&#31243;&#65292;&#20294;&#24573;&#30053;&#20102;&#35789;&#27719;&#21518;&#22788;&#29702;&#30340;&#35821;&#35328;&#22788;&#29702;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#21477;&#23376;&#29702;&#35299;&#36807;&#31243;&#30340;&#27169;&#22411;&#36890;&#24120;&#21482;&#20851;&#27880;&#35789;&#27719;&#21518;&#22788;&#29702;&#30340;&#35821;&#35328;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36825;&#20004;&#31181;&#30740;&#31350;&#32447;&#32034;&#32467;&#21512;&#36215;&#26469;&#30340;&#27169;&#22411;&#65292;&#21363;&#25972;&#21512;&#30524;&#21160;&#25511;&#21046;&#21644;&#21477;&#23376;&#22788;&#29702;&#12290;&#24320;&#21457;&#36825;&#26679;&#19968;&#20010;&#25972;&#21512;&#27169;&#22411;&#20855;&#26377;&#26497;&#22823;&#30340;&#25361;&#25112;&#24615;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#20294;&#36825;&#26679;&#30340;&#25972;&#21512;&#26159;&#26397;&#30528;&#23436;&#25972;&#30340;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#25968;&#23398;&#27169;&#22411;&#36808;&#20986;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#25105;&#20204;&#23558;&#30524;&#21160;&#25511;&#21046;&#27169;&#22411;SWIFT&#65288;Seelig&#31561;&#20154;&#65292;2020&#65289;&#19982;Lewis&#21644;Vasishth&#21477;&#23376;&#22788;&#29702;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#65288;Lewis&#65286;Vasishth&#65292;2005&#65289;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#36825;&#31181;&#25972;&#21512;&#39318;&#27425;&#21464;&#24471;&#21487;&#33021;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#22240;&#20026;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models of eye-movement control during reading, developed largely within psychology, usually focus on visual, attentional, lexical, and motor processes but neglect post-lexical language processing; by contrast, models of sentence comprehension processes, developed largely within psycholinguistics, generally focus only on post-lexical language processes. We present a model that combines these two research threads, by integrating eye-movement control and sentence processing. Developing such an integrated model is extremely challenging and computationally demanding, but such an integration is an important step toward complete mathematical models of natural language comprehension in reading. We combine the SWIFT model of eye-movement control (Seelig et al., 2020, doi:10.1016/j.jmp.2019.102313) with key components of the Lewis and Vasishth sentence processing model (Lewis &amp; Vasishth, 2005, doi:10.1207/s15516709cog0000_25). This integration becomes possible, for the first time, due in part to
&lt;/p&gt;</description></item></channel></rss>