<rss version="2.0"><channel><title>Chat Arxiv cs.CL</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for cs.CL</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102; MACHIAVELLI &#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26159;&#21542;&#34920;&#29616;&#20986;&#39532;&#22522;&#38597;&#32500;&#21033;&#34892;&#20026;&#65292;&#21457;&#29616;&#20102;&#26368;&#22823;&#21270;&#22870;&#21169;&#21644;&#34892;&#20026;&#30340;&#36947;&#24503;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65292;&#24182;&#25506;&#32034;&#20102;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#36825;&#31181;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.03279</link><description>&lt;p&gt;
&#22870;&#21169;&#26159;&#21542;&#21512;&#29702;&#65311;&#22312; MACHIAVELLI &#22522;&#20934;&#27979;&#35797;&#20013;&#34913;&#37327;&#22870;&#21169;&#19982;&#36947;&#24503;&#34892;&#20026;&#20043;&#38388;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark. (arXiv:2304.03279v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102; MACHIAVELLI &#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#26159;&#21542;&#34920;&#29616;&#20986;&#39532;&#22522;&#38597;&#32500;&#21033;&#34892;&#20026;&#65292;&#21457;&#29616;&#20102;&#26368;&#22823;&#21270;&#22870;&#21169;&#21644;&#34892;&#20026;&#30340;&#36947;&#24503;&#24615;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65292;&#24182;&#25506;&#32034;&#20102;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#36825;&#31181;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#20154;&#24037;&#26234;&#33021;&#20195;&#29702;&#34987;&#35757;&#32451;&#25104;&#26368;&#22823;&#21270;&#22870;&#21169;&#65292;&#36825;&#21487;&#33021;&#20250;&#28608;&#21169;&#36861;&#27714;&#26435;&#21147;&#21644;&#27450;&#39575;&#34892;&#20026;&#65292;&#31867;&#20284;&#20110;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#21487;&#33021;&#20250;&#28608;&#21169;&#26377;&#23475;&#34892;&#20026;&#12290;&#37027;&#20040;&#20195;&#29702;&#26159;&#21542;&#33258;&#28982;&#32780;&#28982;&#22320;&#23398;&#20250;&#20102;&#39532;&#22522;&#38597;&#32500;&#21033;&#34892;&#20026;&#65311;&#25105;&#20204;&#22914;&#20309;&#22312; GPT-4 &#31561;&#36890;&#29992;&#27169;&#22411;&#20013;&#34913;&#37327;&#36825;&#20123;&#34892;&#20026;&#21602;&#65311;&#20026;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102; MACHIAVELLI &#22522;&#20934;&#27979;&#35797;&#65292;&#35813;&#27979;&#35797;&#28085;&#30422;&#20102;&#36229;&#36807;&#19968;&#30334;&#19975;&#20010;&#22810;&#26679;&#21270;&#30340;&#24773;&#26223;&#65292;&#37325;&#28857;&#20851;&#27880;&#31038;&#20250;&#20915;&#31574;&#21046;&#23450;&#65292;&#29992;&#20110;&#34913;&#37327;&#20154;&#24037;&#20195;&#29702;&#26159;&#21542;&#34920;&#29616;&#20986;&#39532;&#22522;&#38597;&#32500;&#21033;&#34892;&#20026;&#12290;&#25105;&#20204;&#25968;&#23398;&#21270;&#20102;&#25968;&#21313;&#31181;&#26377;&#23475;&#34892;&#20026;&#65292;&#24182;&#20351;&#29992;&#25105;&#20204;&#30340;&#27880;&#37322;&#26469;&#35780;&#20272;&#20195;&#29702;&#20542;&#21521;&#20110;&#36861;&#27714;&#26435;&#21147;&#65292;&#36896;&#25104;&#21151;&#33021;&#19981;&#33391;&#21644;&#36829;&#21453;&#20262;&#29702;&#30340;&#20542;&#21521;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#26368;&#22823;&#21270;&#22870;&#21169;&#21644;&#34892;&#20026;&#30340;&#36947;&#24503;&#24615;&#20043;&#38388;&#23384;&#22312;&#19968;&#20123;&#32039;&#24352;&#20851;&#31995;&#12290;&#20026;&#20102;&#25913;&#21892;&#36825;&#31181;&#26435;&#34913;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#20351;&#20195;&#29702;&#36235;&#21521;&#20110;&#37319;&#21462;&#26356;&#23569;&#30340;&#26377;&#23475;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;MACHIAVELLI &#26159;&#35780;&#20272;&#20154;&#24037;&#20195;&#29702;&#39532;&#22522;&#38597;&#32500;&#21033;&#34892;&#20026;&#27700;&#24179;&#30340;&#26377;&#29992;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing over half a million rich, diverse scenarios that center on social decision-making. Scenario labeling is automated with LMs, which are more performant than human annotators. We mathematize dozens of harmful behaviors and use our annotations to evaluate agents' tendencies to be power-seeking, cause disutility, and commit ethical violations. We observe some tension between maximizing reward and behaving ethically. To improve this trade-off, we investigate LM-based methods to steer agents' towards less harmful behaviors. Our results sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;GPT-4&#29983;&#25104;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#36827;&#34892;LLM&#24494;&#35843;&#65292;&#23454;&#39564;&#34920;&#26126;GPT-4&#25152;&#29983;&#25104;&#30340;&#25351;&#20196;&#25968;&#25454;&#20248;&#20110;&#20197;&#24448;&#26368;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#22312;&#26032;&#20219;&#21153;&#20013;&#34920;&#29616;&#21331;&#36234;&#12290;</title><link>http://arxiv.org/abs/2304.03277</link><description>&lt;p&gt;
GPT-4&#25351;&#20196;&#35843;&#20248;
&lt;/p&gt;
&lt;p&gt;
Instruction Tuning with GPT-4. (arXiv:2304.03277v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;GPT-4&#29983;&#25104;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#36827;&#34892;LLM&#24494;&#35843;&#65292;&#23454;&#39564;&#34920;&#26126;GPT-4&#25152;&#29983;&#25104;&#30340;&#25351;&#20196;&#25968;&#25454;&#20248;&#20110;&#20197;&#24448;&#26368;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#22312;&#26032;&#20219;&#21153;&#20013;&#34920;&#29616;&#21331;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#20351;&#29992;&#26426;&#22120;&#29983;&#25104;&#30340;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#36827;&#34892;&#24494;&#35843;&#21487;&#20197;&#20351;&#36825;&#20123;&#27169;&#22411;&#22312;&#26032;&#20219;&#21153;&#19978;&#23454;&#29616;&#26174;&#33879;&#30340;&#38646;-shot&#33021;&#21147;&#65292;&#19981;&#38656;&#35201;&#20154;&#31867;&#32534;&#20889;&#30340;&#25351;&#20196;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#20351;&#29992;GPT-4&#29983;&#25104;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#36827;&#34892;LLM&#24494;&#35843;&#12290;&#25105;&#20204;&#22312;&#25351;&#20196;&#35843;&#20248;&#30340;LLaMA&#27169;&#22411;&#19978;&#36827;&#34892;&#30340;&#26089;&#26399;&#23454;&#39564;&#34920;&#26126;&#65292;GPT-4&#29983;&#25104;&#30340;52K&#33521;&#35821;&#21644;&#20013;&#25991;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#20248;&#20110;&#20197;&#21069;&#26368;&#20808;&#36827;&#27169;&#22411;&#29983;&#25104;&#30340;&#25351;&#20196;&#36981;&#24490;&#25968;&#25454;&#65292;&#21487;&#20197;&#22312;&#26032;&#20219;&#21153;&#20013;&#23454;&#29616;&#21331;&#36234;&#30340;&#38646;-shot&#34920;&#29616;&#12290;&#25105;&#20204;&#36824;&#25910;&#38598;&#20102;&#26469;&#33258;GPT-4&#30340;&#21453;&#39304;&#21644;&#27604;&#36739;&#25968;&#25454;&#65292;&#20197;&#23454;&#29616;&#20840;&#38754;&#30340;&#35780;&#20272;&#21644;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#20844;&#24320;&#25552;&#20379;&#20102;&#20351;&#29992;GPT-4&#29983;&#25104;&#30340;&#25968;&#25454;&#20197;&#21450;&#25105;&#20204;&#30340;&#20195;&#30721;&#24211;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#20154;&#24037;&#35780;&#20272;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36827;&#34892;&#25991;&#23398;&#27573;&#33853;&#32763;&#35793;&#26102;&#20250;&#21033;&#29992;&#26356;&#22810;&#30340;&#25991;&#26723;&#32423;&#19978;&#19979;&#25991;&#65292;&#20174;&#32780;&#20943;&#23569;&#20851;&#38190;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#19982;&#19978;&#19979;&#25991;&#21644;&#24847;&#20041;&#30456;&#20851;&#30340;&#38169;&#35823;&#20173;&#28982;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2304.03245</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#25991;&#23398;&#32763;&#35793;&#20013;&#39640;&#25928;&#21033;&#29992;&#25991;&#26723;&#32423;&#19978;&#19979;&#25991;&#65292;&#20294;&#20851;&#38190;&#38169;&#35823;&#20173;&#28982;&#23384;&#22312;
&lt;/p&gt;
&lt;p&gt;
Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03245
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#20154;&#24037;&#35780;&#20272;&#21457;&#29616;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#36827;&#34892;&#25991;&#23398;&#27573;&#33853;&#32763;&#35793;&#26102;&#20250;&#21033;&#29992;&#26356;&#22810;&#30340;&#25991;&#26723;&#32423;&#19978;&#19979;&#25991;&#65292;&#20174;&#32780;&#20943;&#23569;&#20851;&#38190;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#19982;&#19978;&#19979;&#25991;&#21644;&#24847;&#20041;&#30456;&#20851;&#30340;&#38169;&#35823;&#20173;&#28982;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#22312;&#35768;&#22810;&#21477;&#23376;&#32423;&#21035;&#30340;&#32763;&#35793;&#25968;&#25454;&#38598;&#19978;&#19982;&#29616;&#26377;&#25216;&#26415;&#27700;&#24179;&#30456;&#24403;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#27573;&#33853;&#21644;&#25991;&#26723;&#32763;&#35793;&#26041;&#38754;&#30340;&#33021;&#21147;&#23578;&#26410;&#24471;&#21040;&#25506;&#31350;&#65292;&#22240;&#20026;&#36825;&#20123;&#29615;&#22659;&#19979;&#30340;&#35780;&#20272;&#20195;&#20215;&#39640;&#19988;&#22256;&#38590;&#12290;&#36890;&#36807;&#19968;&#39033;&#20005;&#35880;&#30340;&#20154;&#24037;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35201;&#27714;Gpt-3.5&#65288;text-davinci-003&#65289;LLM&#23558;&#25972;&#20010;&#25991;&#23398;&#27573;&#33853;&#65288;&#20363;&#22914;&#65292;&#20174;&#23567;&#35828;&#20013;&#65289;&#36827;&#34892;&#32763;&#35793;&#30340;&#32467;&#26524;&#27604;&#26631;&#20934;&#30340;&#36880;&#21477;&#32763;&#35793;&#22312;18&#20010;&#35821;&#35328;&#23545;&#65288;&#20363;&#22914;&#65292;&#26085;&#35821;&#12289;&#27874;&#20848;&#35821;&#21644;&#33521;&#35821;&#30340;&#32763;&#35793;&#65289;&#19978;&#20135;&#29983;&#26356;&#39640;&#36136;&#37327;&#30340;&#32763;&#35793;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#38656;&#35201;&#32422;350&#20010;&#23567;&#26102;&#30340;&#27880;&#37322;&#21644;&#20998;&#26512;&#24037;&#20316;&#65292;&#36890;&#36807;&#32856;&#35831;&#29087;&#32451;&#25484;&#25569;&#28304;&#35821;&#35328;&#21644;&#30446;&#26631;&#35821;&#35328;&#30340;&#35793;&#32773;&#65292;&#24182;&#35201;&#27714;&#20182;&#20204;&#25552;&#20379;&#36328;&#24230;&#32423;&#21035;&#30340;&#38169;&#35823;&#27880;&#37322;&#20197;&#21450;&#21738;&#31181;&#31995;&#32479;&#30340;&#32763;&#35793;&#26356;&#22909;&#30340;&#20559;&#22909;&#21028;&#26029;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#31687;&#31456;&#32423;&#21035;&#30340;LLM&#32763;&#35793;&#22312;&#25991;&#23398;&#27573;&#33853;&#30340;&#32763;&#35793;&#20013;&#20986;&#29616;&#30340;&#20851;&#38190;&#38169;&#35823;&#26356;&#23569;&#65292;&#20294;&#20173;&#23384;&#22312;&#19968;&#20123;&#19982;&#19978;&#19979;&#25991;&#21644;&#24847;&#20041;&#30456;&#20851;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system's translations are better. We observe that discourse-level LLM translators commit fewer 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#32852;&#37030;&#23398;&#20064;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;FedBot&#12290;&#23427;&#32467;&#21512;&#20102;Deep Bidirectional Transformer&#27169;&#22411;&#21644;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#32852;&#21512;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25252;&#23458;&#25143;&#25968;&#25454;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2304.03228</link><description>&lt;p&gt;
FedBot&#65306;&#21033;&#29992;&#32852;&#37030;&#23398;&#20064;&#22686;&#24378;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#38544;&#31169;&#20445;&#25252;
&lt;/p&gt;
&lt;p&gt;
FedBot: Enhancing Privacy in Chatbots with Federated Learning. (arXiv:2304.03228v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#32852;&#37030;&#23398;&#20064;&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;FedBot&#12290;&#23427;&#32467;&#21512;&#20102;Deep Bidirectional Transformer&#27169;&#22411;&#21644;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#32852;&#21512;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25252;&#23458;&#25143;&#25968;&#25454;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32842;&#22825;&#26426;&#22120;&#20154;&#20027;&#35201;&#20381;&#36182;&#20110;&#21253;&#21547;&#25935;&#24863;&#20449;&#24687;&#30340;&#35805;&#35821;&#30340;&#25968;&#25454;&#25512;&#21160;&#65292;&#20294;&#26159;&#22312;&#20849;&#20139;&#25968;&#25454;&#19978;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#20250;&#20405;&#29359;&#29992;&#25143;&#38544;&#31169;&#12290;&#26412;&#25991;&#25552;&#20986;FedBot&#65292;&#19968;&#20010;&#21033;&#29992;&#22823;&#35268;&#27169;&#23458;&#25143;&#25903;&#25345;&#25968;&#25454;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#32842;&#22825;&#26426;&#22120;&#20154;&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#23427;&#32467;&#21512;&#20102;Deep Bidirectional Transformer&#27169;&#22411;&#21644;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#32852;&#21512;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25252;&#23458;&#25143;&#25968;&#25454;&#38544;&#31169;&#12290;&#27010;&#24565;&#39564;&#35777;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#38544;&#31169;&#20445;&#25252;&#32842;&#22825;&#26426;&#22120;&#20154;&#33021;&#22815;&#36890;&#36807;&#25913;&#21464;&#23458;&#25143;&#25903;&#25345;&#34892;&#19994;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Chatbots are mainly data-driven and usually based on utterances that might be sensitive. However, training deep learning models on shared data can violate user privacy. Such issues have commonly existed in chatbots since their inception. In the literature, there have been many approaches to deal with privacy, such as differential privacy and secure multi-party computation, but most of them need to have access to users' data. In this context, Federated Learning (FL) aims to protect data privacy through distributed learning methods that keep the data in its location. This paper presents Fedbot, a proof-of-concept (POC) privacy-preserving chatbot that leverages large-scale customer support data. The POC combines Deep Bidirectional Transformer models and federated learning algorithms to protect customer data privacy during collaborative model training. The results of the proof-of-concept showcase the potential for privacy-preserving chatbots to transform the customer support industry by de
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#25552;&#20986;&#21452;&#37325;&#24130;&#24459;&#26041;&#27861;&#29992;&#20110;&#39044;&#27979;&#29420;&#29305;&#30340;&#24615;&#33021;&#26435;&#34913;&#21069;&#27839;&#65292;&#24182;&#24314;&#31435;&#22522;&#20110;&#35813;&#26041;&#27861;&#30340;&#26679;&#26412;&#27604;&#20363;&#36873;&#25321;&#20248;&#21270;&#38382;&#39064;&#65292;&#21462;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.03216</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;Pareto&#21069;&#27839;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#30340;&#25968;&#25454;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#25552;&#20986;&#21452;&#37325;&#24130;&#24459;&#26041;&#27861;&#29992;&#20110;&#39044;&#27979;&#29420;&#29305;&#30340;&#24615;&#33021;&#26435;&#34913;&#21069;&#27839;&#65292;&#24182;&#24314;&#31435;&#22522;&#20110;&#35813;&#26041;&#27861;&#30340;&#26679;&#26412;&#27604;&#20363;&#36873;&#25321;&#20248;&#21270;&#38382;&#39064;&#65292;&#21462;&#24471;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#22810;&#35821;&#35328;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#20013;&#65292;&#32473;&#23450;&#26041;&#21521;&#30340;&#27867;&#21270;&#24615;&#33021;&#22914;&#20309;&#38543;&#20854;&#37319;&#26679;&#27604;&#20363;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#12290;&#36890;&#36807;&#35757;&#32451;200&#22810;&#20010;&#20855;&#26377;&#19981;&#21516;&#27169;&#22411;&#22823;&#23567;&#12289;&#26041;&#21521;&#21644;&#24635;&#20219;&#21153;&#25968;&#37327;&#30340;&#22810;&#35821;&#35328;&#27169;&#22411;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#35757;&#32451;&#35821;&#26009;&#24211;&#23384;&#22312;&#25968;&#25454;&#19981;&#24179;&#34913;&#26102;&#65292;&#26631;&#37327;&#21270;&#23548;&#33268;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#26435;&#34913;&#21069;&#27839;&#65292;&#35813;&#21069;&#27839;&#20559;&#31163;&#20102;&#20256;&#32479;&#30340;Pareto&#21069;&#27839;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21452;&#37325;&#24130;&#24459;&#26469;&#39044;&#27979;MNMT&#20013;&#29420;&#29305;&#30340;&#24615;&#33021;&#26435;&#34913;&#21069;&#27839;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#35821;&#35328;&#12289;&#25968;&#25454;&#20805;&#36275;&#24615;&#21644;&#20219;&#21153;&#25968;&#37327;&#26041;&#38754;&#37117;&#24456;&#40065;&#26834;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;MNMT&#20013;&#30340;&#26679;&#26412;&#27604;&#20363;&#36873;&#25321;&#38382;&#39064;&#24314;&#27169;&#20026;&#22522;&#20110;&#21452;&#37325;&#24130;&#24459;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;111M&#21040;13B&#21442;&#25968;&#30340;&#24320;&#25918;&#35745;&#31639;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411; Cerebras-GPT&#65292;&#23427;&#37319;&#29992;&#20102;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#21644;&#32553;&#25918;&#35268;&#21017;&#65292;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#21487;&#39044;&#27979;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#24320;&#25918;&#21487;&#22797;&#29616;&#30340;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2304.03208</link><description>&lt;p&gt;
&#22522;&#20110; Cerebras Wafer-Scale Cluster &#30340;&#24320;&#25918;&#35745;&#31639;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411; Cerebras-GPT &#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster. (arXiv:2304.03208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20174;111M&#21040;13B&#21442;&#25968;&#30340;&#24320;&#25918;&#35745;&#31639;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411; Cerebras-GPT&#65292;&#23427;&#37319;&#29992;&#20102;&#39640;&#25928;&#30340;&#39044;&#35757;&#32451;&#26041;&#27861;&#21644;&#32553;&#25918;&#35268;&#21017;&#65292;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#21487;&#39044;&#27979;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#24320;&#25918;&#21487;&#22797;&#29616;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#36817;&#25913;&#21892;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26377;&#25928;&#39044;&#35757;&#32451;&#21644;&#25193;&#23637;&#20197;&#21450;&#24320;&#25918;&#25968;&#25454;&#38598;&#21644;&#24037;&#20855;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;&#21516;&#26102;&#32467;&#21512;&#36825;&#20123;&#36827;&#23637;&#65292;&#20171;&#32461;&#20102;&#19968;&#31995;&#21015;&#20174;111M&#21040;13B&#21442;&#25968;&#30340;&#24320;&#25918;&#35745;&#31639;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411; Cerebras-GPT&#12290;&#25105;&#20204;&#26681;&#25454; DeepMind &#30340; Chinchilla &#32553;&#25918;&#35268;&#21017;&#23545; Eleuther Pile &#25968;&#25454;&#38598;&#36827;&#34892;&#35757;&#32451;&#65292;&#36798;&#21040;&#20102;&#22312;&#32473;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#26368;&#39640;&#31934;&#24230;&#30340;&#39640;&#25928;&#39044;&#35757;&#32451;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#21487;&#39044;&#27979;&#30340;&#24130;&#24459;&#32553;&#25918;&#35268;&#24459;&#65292;&#24182;&#19982;&#20854;&#20182;&#20844;&#24320;&#21487;&#29992;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#23637;&#31034;&#20102; Cerebras-GPT &#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#30446;&#26631;&#35757;&#32451;&#25928;&#29575;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#21253;&#25324;&#26368;&#22823;&#26356;&#26032;&#21442;&#25968;&#21270;($\mu$P)&#22914;&#20309;&#36827;&#19968;&#27493;&#25552;&#39640;&#22823;&#22411;&#27169;&#22411;&#25193;&#23637;&#30340;&#31934;&#24230;&#21644;&#36229;&#21442;&#25968;&#21487;&#39044;&#27979;&#24615;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#39044;&#35757;&#32451;&#27169;&#22411;&#21644;&#20195;&#30721;&#65292;&#20351;&#26412;&#25991;&#25104;&#20026;&#20851;&#20110;&#22312;&#20159;&#32423;&#21442;&#25968;&#35268;&#27169;&#19979;&#27604;&#36739;&#35745;&#31639;&#20248;&#21270;&#35821;&#35328;&#27169;&#22411;&#30340;&#39318;&#20010;&#24320;&#25918;&#21487;&#22797;&#29616;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study recent research advances that improve large language models through efficient pre-training and scaling, and open datasets and tools. We combine these advances to introduce Cerebras-GPT, a family of open compute-optimal language models scaled from 111M to 13B parameters. We train Cerebras-GPT models on the Eleuther Pile dataset following DeepMind Chinchilla scaling rules for efficient pre-training (highest accuracy for a given compute budget). We characterize the predictable power-law scaling and compare Cerebras-GPT with other publicly-available models to show all Cerebras-GPT models have state-of-the-art training efficiency on both pre-training and downstream objectives. We describe our learnings including how Maximal Update Parameterization ($\mu$P) can further improve large model scaling, improving accuracy and hyperparameter predictability at scale. We release our pre-trained models and code, making this paper the first open and reproducible work comparing compute-optimal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#33521;&#21360;ST&#30340;e2e&#26550;&#26500;&#65292;&#21516;&#26102;&#23558;&#20004;&#20010;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#32763;&#35793;&#26381;&#21153;&#29992;&#20110;&#29983;&#25104;&#24182;&#34892;&#25968;&#25454;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#32467;&#26524;&#21576;&#29616;&#20986;&#27604;&#22522;&#20934;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03169</link><description>&lt;p&gt;
&#38024;&#23545;&#40065;&#26834;&#35821;&#38899;&#32763;&#35793;&#30340;&#36873;&#25321;&#24615;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Selective Data Augmentation for Robust Speech Translation. (arXiv:2304.03169v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03169
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#33521;&#21360;ST&#30340;e2e&#26550;&#26500;&#65292;&#21516;&#26102;&#23558;&#20004;&#20010;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#32763;&#35793;&#26381;&#21153;&#29992;&#20110;&#29983;&#25104;&#24182;&#34892;&#25968;&#25454;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#32467;&#26524;&#21576;&#29616;&#20986;&#27604;&#22522;&#20934;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#38899;&#32763;&#35793;&#31995;&#32479;&#23558;&#19968;&#31181;&#35821;&#35328;&#30340;&#35821;&#38899;&#36716;&#21270;&#20026;&#21478;&#19968;&#31181;&#35821;&#35328;&#30340;&#25991;&#23383;&#12290;&#31471;&#21040;&#31471;&#65288;e2e&#65289;&#35821;&#38899;&#32763;&#35793;&#31995;&#32479;&#30001;&#20110;&#20855;&#26377;&#20943;&#23569;&#24310;&#36831;&#21644;&#35745;&#31639;&#25104;&#26412;&#30340;&#20248;&#36234;&#24615;&#33021;&#32780;&#27604;&#20018;&#32852;&#31995;&#32479;&#21463;&#21040;&#27426;&#36814;&#12290;&#34429;&#28982;&#36164;&#28304;&#23494;&#38598;&#22411;&#65292;&#20294;e2e-ST&#31995;&#32479;&#20855;&#26377;&#20445;&#30041;&#35821;&#38899;&#30340;&#21442;&#25968;&#21644;&#38750;&#35821;&#35328;&#29305;&#24449;&#30340;&#20869;&#22312;&#33021;&#21147;&#65292;&#19982;&#20018;&#32852;&#31995;&#32479;&#19981;&#21516;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;e2e&#26550;&#26500;&#26469;&#36827;&#34892;&#33521;&#21360;&#65288;en-hi&#65289;ST&#12290;&#25105;&#20204;&#20351;&#29992;&#20004;&#20010;&#19981;&#23436;&#32654;&#30340;&#26426;&#22120;&#32763;&#35793;&#26381;&#21153;&#23558;Libri-trans en&#25991;&#26412;&#32763;&#35793;&#25104;hi&#25991;&#26412;&#12290;&#34429;&#28982;&#27599;&#20010;&#26381;&#21153;&#37117;&#20250;&#21333;&#29420;&#25552;&#20379;MT&#25968;&#25454;&#20197;&#29983;&#25104;&#24182;&#34892;ST&#25968;&#25454;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22122;&#22768;MT&#25968;&#25454;&#30340;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#26469;&#24110;&#21161;&#40065;&#26834;ST&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#23548;&#33268;&#27604;&#24378;&#21147;MT&#25968;&#25454;&#22686;&#24378;&#26356;&#22909;&#30340;ST&#65288;BLEU&#24471;&#20998;&#65289;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#22522;&#20934;&#26041;&#27861;&#25552;&#39640;&#20102;1.59 BLEU&#24471;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Speech translation (ST) systems translate speech in one language to text in another language. End-to-end ST systems (e2e-ST) have gained popularity over cascade systems because of their enhanced performance due to reduced latency and computational cost. Though resource intensive, e2e-ST systems have the inherent ability to retain para and non-linguistic characteristics of the speech unlike cascade systems. In this paper, we propose to use an e2e architecture for English-Hindi (en-hi) ST. We use two imperfect machine translation (MT) services to translate Libri-trans en text into hi text. While each service gives MT data individually to generate parallel ST data, we propose a data augmentation strategy of noisy MT data to aid robust ST. The main contribution of this paper is the proposal of a data augmentation strategy. We show that this results in better ST (BLEU score) compared to brute force augmentation of MT data. We observed an absolute improvement of 1.59 BLEU score with our appr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36328;&#36234;&#35821;&#35328;&#40511;&#27807;&#30340;&#36890;&#29992;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#27880;&#20837;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#29702;&#35299;&#19981;&#21516;&#35821;&#35328;&#38382;&#31572;&#20043;&#38388;&#30340;&#30693;&#35782;&#36801;&#31227;&#12290;</title><link>http://arxiv.org/abs/2304.03159</link><description>&lt;p&gt;
&#36328;&#36234;&#35821;&#35328;&#40511;&#27807;&#65306;&#27880;&#20837;&#30693;&#35782;&#30340;&#22810;&#35821;&#35328;&#38382;&#31572;
&lt;/p&gt;
&lt;p&gt;
Bridging the Language Gap: Knowledge Injected Multilingual Question Answering. (arXiv:2304.03159v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36328;&#36234;&#35821;&#35328;&#40511;&#27807;&#30340;&#36890;&#29992;&#38382;&#31572;&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#27880;&#20837;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#29702;&#35299;&#19981;&#21516;&#35821;&#35328;&#38382;&#31572;&#20043;&#38388;&#30340;&#30693;&#35782;&#36801;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38382;&#31572;&#65288;QA&#65289;&#26159;&#19968;&#31181;&#33258;&#21160;&#22238;&#31572;&#20154;&#31867;&#33258;&#28982;&#35821;&#35328;&#38382;&#39064;&#30340;&#20219;&#21153;&#12290;&#25552;&#21462;&#24335;&#38382;&#31572;&#20219;&#21153;&#65288;Extractive QA&#65289;&#24050;&#32463;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#22791;&#21463;&#20851;&#27880;&#30340;&#19968;&#20010;&#37325;&#35201;&#26041;&#21521;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#38543;&#30528;&#19990;&#30028;&#30340;&#19981;&#26029;&#21457;&#23637;&#65292;&#19981;&#21516;&#35821;&#35328;&#38388;&#30340;&#36890;&#29992;&#36328;&#35821;&#35328;&#36716;&#31227;&#65288;G-XLT&#65289;&#24102;&#26469;&#20102;&#36328;&#35821;&#35328;&#36716;&#31227;&#65288;XLT&#65289;&#26080;&#27861;&#35299;&#20915;&#30340;&#19968;&#20123;&#29420;&#29305;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;G-XLT&#26694;&#26550;&#65292;&#36890;&#36807;&#30693;&#35782;&#27880;&#20837;&#30340;&#26041;&#24335;&#65292;&#20016;&#23500;&#27169;&#22411;&#23545;&#19981;&#21516;&#35821;&#35328;&#38382;&#31572;&#20013;&#30340;&#30693;&#35782;&#36801;&#31227;&#30340;&#29702;&#35299;&#65292;&#20174;&#32780;&#20026;&#23454;&#29616;&#36328;&#35821;&#35328;&#30340;QA&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20123;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Question Answering (QA) is the task of automatically answering questions posed by humans in natural languages. There are different settings to answer a question, such as abstractive, extractive, boolean, and multiple-choice QA. As a popular topic in natural language processing tasks, extractive question answering task (extractive QA) has gained extensive attention in the past few years. With the continuous evolvement of the world, generalized cross-lingual transfer (G-XLT), where question and answer context are in different languages, poses some unique challenges over cross-lingual transfer (XLT), where question and answer context are in the same language. With the boost of corresponding development of related benchmarks, many works have been done to improve the performance of various language QA tasks. However, only a few works are dedicated to the G-XLT task. In this work, we propose a generalized cross-lingual transfer framework to enhance the model's ability to understand different
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#38646;&#26679;&#26412;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.03153</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#38646;&#26679;&#26412;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Next-Item Recommendation using Large Pretrained Language Models. (arXiv:2304.03153v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03153
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25552;&#20986;&#38646;&#26679;&#26412;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;&#20013;&#36935;&#21040;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#38646;&#26679;&#26412;&#34920;&#29616;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#27809;&#26377;&#35757;&#32451;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23578;&#26410;&#26377;&#30740;&#31350;&#25506;&#32034;LLMs&#22312;&#38646;&#26679;&#26412;&#24773;&#20917;&#19979;&#25191;&#34892;&#19979;&#19968;&#20010;&#39033;&#30446;&#25512;&#33616;&#30340;&#28508;&#21147;&#12290;&#20316;&#32773;&#20204;&#30830;&#23450;&#20102;&#24517;&#39035;&#35299;&#20915;&#30340;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65292;&#20197;&#20351;LLMs&#26377;&#25928;&#22320;&#20805;&#24403;&#25512;&#33616;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples. Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting. We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders. First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences. To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations. Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that captur
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;MRC&#27169;&#22411;&#23545;&#20302;&#36164;&#28304;&#22320;&#21306;&#37325;&#21629;&#21517;&#23454;&#20307;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20986;&#20102;EntSwap&#25200;&#21160;&#27979;&#35797;&#38598;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#22823;&#22411;&#27169;&#22411;&#20855;&#26377;&#36739;&#24378;&#30340;&#26032;&#23454;&#20307;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03145</link><description>&lt;p&gt;
&#35780;&#20272;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#27169;&#22411;&#23545;&#20302;&#36164;&#28304;&#23454;&#20307;&#37325;&#21629;&#21517;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Robustness of Machine Reading Comprehension Models to Low Resource Entity Renaming. (arXiv:2304.03145v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;MRC&#27169;&#22411;&#23545;&#20302;&#36164;&#28304;&#22320;&#21306;&#37325;&#21629;&#21517;&#23454;&#20307;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20986;&#20102;EntSwap&#25200;&#21160;&#27979;&#35797;&#38598;&#30340;&#26041;&#27861;&#65292;&#21457;&#29616;&#22823;&#22411;&#27169;&#22411;&#20855;&#26377;&#36739;&#24378;&#30340;&#26032;&#23454;&#20307;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38382;&#31572;&#65288;QA&#65289;&#27169;&#22411;&#22312;&#26426;&#22120;&#38405;&#35835;&#29702;&#35299;&#65288;MRC&#65289;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#20449;&#26381;&#30340;&#32467;&#26524;&#12290;&#26368;&#36817;&#65292;&#36825;&#20123;&#27169;&#22411;&#24050;&#32463;&#35777;&#26126;&#22312;&#22914;SQuAD&#31561;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#20154;&#31867;&#65292;&#20294;&#23427;&#20204;&#30340;&#31283;&#20581;&#24615;&#24182;&#19981;&#20445;&#35777;&#12290;&#24403;&#20351;&#29992;&#23545;&#25239;&#29983;&#25104;&#30340;&#31034;&#20363;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;QA&#27169;&#22411;&#30340;&#33030;&#24369;&#24615;&#20250;&#26292;&#38706;&#20986;&#26469;&#65292;&#34920;&#29616;&#20986;&#24615;&#33021;&#19979;&#38477;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;MRC&#27169;&#22411;&#23545;&#26469;&#33258;&#20302;&#36164;&#28304;&#22320;&#21306;&#65288;&#22914;&#38750;&#27954;&#65289;&#30340;&#23454;&#20307;&#37325;&#21629;&#21517;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;EntSwap&#65292;&#19968;&#31181;&#27979;&#35797;&#26102;&#25200;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#21019;&#24314;&#19968;&#20010;&#23454;&#20307;&#24050;&#34987;&#37325;&#21629;&#21517;&#30340;&#27979;&#35797;&#38598;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#37325;&#21629;&#21517;&#31867;&#22411;&#20026;&#22269;&#23478;&#65292;&#20154;&#29289;&#65292;&#22269;&#31821;&#65292;&#20301;&#32622;&#65292;&#32452;&#32455;&#21644;&#22478;&#24066;&#30340;&#23454;&#20307;&#65292;&#20197;&#21019;&#24314;AfriSQuAD2&#12290;&#20351;&#29992;&#25200;&#21160;&#27979;&#35797;&#38598;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#19977;&#31181;&#27969;&#34892;&#30340;MRC&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#22823;&#27169;&#22411;&#22312;&#26032;&#23454;&#20307;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#20154;&#21517;&#23454;&#20307;&#31867;&#22411;&#20855;&#26377;&#39640;&#24230;&#30340;&#29305;&#24322;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Question answering (QA) models have shown compelling results in the task of Machine Reading Comprehension (MRC). Recently these systems have proved to perform better than humans on held-out test sets of datasets e.g. SQuAD, but their robustness is not guaranteed. The QA model's brittleness is exposed when evaluated on adversarial generated examples by a performance drop. In this study, we explore the robustness of MRC models to entity renaming, with entities from low-resource regions such as Africa. We propose EntSwap, a method for test-time perturbations, to create a test set whose entities have been renamed. In particular, we rename entities of type: country, person, nationality, location, organization, and city, to create AfriSQuAD2. Using the perturbed test set, we evaluate the robustness of three popular MRC models. We find that compared to base models, large models perform well comparatively on novel entities. Furthermore, our analysis indicates that entity type person highly cha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#65292;&#21487;&#25552;&#20379;&#39044;&#23450;&#20041;&#32500;&#24230;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#35813;&#27169;&#22411;&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2304.03098</link><description>&lt;p&gt;
&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#65306;&#19968;&#31181;&#36731;&#37327;&#32423;&#21477;&#23376;&#23884;&#20837;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Static Fuzzy Bag-of-Words: a lightweight sentence embedding algorithm. (arXiv:2304.03098v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#65292;&#21487;&#25552;&#20379;&#39044;&#23450;&#20041;&#32500;&#24230;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#35813;&#27169;&#22411;&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#20837;&#25216;&#26415;&#30340;&#24341;&#20837;&#26174;&#33879;&#25512;&#21160;&#20102;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#21457;&#23637;&#12290;&#35768;&#22810;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#26159;&#38024;&#23545;&#21333;&#35789;&#32423;&#21035;&#30340;&#32534;&#30721;&#12290;&#28982;&#32780;&#65292;&#22312;&#36807;&#21435;&#30340;&#20960;&#24180;&#20013;&#65292;&#20986;&#29616;&#20102;&#19968;&#20123;&#26032;&#30340;&#26426;&#21046;&#26469;&#22788;&#29702;&#26356;&#39640;&#23618;&#27425;&#30340;&#20449;&#24687;&#22788;&#29702;&#65292;&#20363;&#22914;&#21477;&#23376;&#21644;&#25991;&#26723;&#32423;&#21035;&#12290;&#26412;&#25991;&#19987;&#38376;&#35752;&#35770;&#21477;&#23376;&#23884;&#20837;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#38745;&#24577;&#27169;&#31946;&#35789;&#34955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#26159;&#27169;&#31946;&#35789;&#34955;&#26041;&#27861;&#30340;&#19968;&#31181;&#25913;&#36827;&#65292;&#38024;&#23545;&#39044;&#23450;&#20041;&#32500;&#24230;&#25552;&#20379;&#21477;&#23376;&#23884;&#20837;&#12290;SFBoW&#22312;&#35821;&#20041;&#25991;&#26412;&#30456;&#20284;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#31454;&#20105;&#21147;&#65292;&#21516;&#26102;&#35201;&#27714;&#20302;&#35745;&#31639;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
The introduction of embedding techniques has pushed forward significantly the Natural Language Processing field. Many of the proposed solutions have been presented for word-level encoding; anyhow, in the last years, new mechanism to treat information at an higher level of aggregation, like at sentence- and document-level, have emerged. With this work we address specifically the sentence embeddings problem, presenting the Static Fuzzy Bag-of-Word model. Our model is a refinement of the Fuzzy Bag-of-Words approach, providing sentence embeddings with a predefined dimension. SFBoW provides competitive performances in Semantic Textual Similarity benchmarks, while requiring low computational resources.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;ChatGPT&#36827;&#34892;&#31435;&#22330;&#26816;&#27979;&#20013;&#65292;&#26080;&#21442;&#25968;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#20854;&#34920;&#29616;&#20248;&#36234;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#20851;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2304.03087</link><description>&lt;p&gt;
&#21033;&#29992;ChatGPT&#25506;&#31350;&#24605;&#32500;&#38142;&#22312;&#31038;&#20132;&#23186;&#20307;&#20013;&#30340;&#31435;&#22330;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media. (arXiv:2304.03087v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03087
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;ChatGPT&#36827;&#34892;&#31435;&#22330;&#26816;&#27979;&#20013;&#65292;&#26080;&#21442;&#25968;&#30340;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#26126;&#20854;&#34920;&#29616;&#20248;&#36234;&#65292;&#24182;&#25506;&#35752;&#20102;&#30456;&#20851;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31435;&#22330;&#26816;&#27979;&#26159;&#39044;&#27979;&#25991;&#26412;&#20013;&#38024;&#23545;&#30446;&#26631;&#30340;&#24577;&#24230;&#65292;&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#30340;&#20852;&#36215;&#24050;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#26041;&#27861;&#21253;&#25324;&#20256;&#32479;&#26426;&#22120;&#23398;&#20064;&#12289;&#26089;&#26399;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#39044;&#35757;&#32451;&#24494;&#35843;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#38750;&#24120;&#22823;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65288;VLPLMs&#65289;&#22914;ChatGPT&#65288;GPT-3.5&#65289;&#30340;&#21457;&#23637;&#65292;&#20256;&#32479;&#26041;&#27861;&#38754;&#20020;&#37096;&#32626;&#25361;&#25112;&#12290;&#19981;&#38656;&#35201;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#30340;&#26080;&#21442;&#25968;&#24605;&#32500;&#38142;&#65288;CoT&#65289;&#26041;&#27861;&#24050;&#25104;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;CoT&#22312;&#31435;&#22330;&#26816;&#27979;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#30340;&#31934;&#24230;&#24182;&#35752;&#35770;&#20102;&#30456;&#20851;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained fine-tuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT's effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#21033;&#29992;LLMs&#22312;&#29273;&#31185;&#20020;&#24202;&#39046;&#22495;&#23454;&#29616;&#33258;&#21160;&#21270;&#21644;&#36328;&#27169;&#24577;&#35786;&#26029;&#30340;&#21487;&#33021;&#24615;&#65292;&#20171;&#32461;&#20102;&#21033;&#29992;&#36328;&#27169;&#24577;&#32534;&#30721;&#22120;&#36827;&#34892;&#39640;&#32423;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#30340;&#22810;&#27169;&#24577;LLM AI&#31995;&#32479;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#29273;&#31185;&#20020;&#24202;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.03086</link><description>&lt;p&gt;
ChatGPT&#22609;&#36896;&#29273;&#31185;&#26410;&#26469;&#65306;&#22810;&#27169;&#24577;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#21033;&#29992;LLMs&#22312;&#29273;&#31185;&#20020;&#24202;&#39046;&#22495;&#23454;&#29616;&#33258;&#21160;&#21270;&#21644;&#36328;&#27169;&#24577;&#35786;&#26029;&#30340;&#21487;&#33021;&#24615;&#65292;&#20171;&#32461;&#20102;&#21033;&#29992;&#36328;&#27169;&#24577;&#32534;&#30721;&#22120;&#36827;&#34892;&#39640;&#32423;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#30340;&#22810;&#27169;&#24577;LLM AI&#31995;&#32479;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#29273;&#31185;&#20020;&#24202;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#26159;OpenAI&#24320;&#21457;&#30340;Generative Pretrained Transformer 4&#65288;GPT-4&#65289;&#30340;&#31934;&#31616;&#21644;&#23545;&#35805;&#21464;&#20307;&#65292;&#20855;&#26377;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#30340;&#37324;&#31243;&#30865;&#24335;&#22823;&#35821;&#35328;&#27169;&#22411;&#20043;&#19968;&#12290;&#20107;&#23454;&#19978;&#65292;LLMs&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#20013;&#23637;&#29616;&#20986;&#30340;&#21360;&#35937;&#28145;&#21051;&#33021;&#21147;&#24341;&#36215;&#20102;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#30340;&#26497;&#22823;&#20852;&#36259;&#65292;&#23545;&#21508;&#20010;&#39046;&#22495;&#20135;&#29983;&#20102;&#28145;&#36828;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#20027;&#35201;&#35752;&#35770;LLMs&#22312;&#29273;&#31185;&#39046;&#22495;&#30340;&#26410;&#26469;&#24212;&#29992;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#20027;&#35201;&#30340;LLM&#37096;&#32626;&#26041;&#27861;&#65292;&#21253;&#25324;&#33258;&#21160;&#29273;&#31185;&#35786;&#26029;&#21644;&#36328;&#27169;&#24577;&#29273;&#31185;&#35786;&#26029;&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#29305;&#21035;&#22320;&#65292;&#37197;&#22791;&#36328;&#27169;&#24577;&#32534;&#30721;&#22120;&#65292;&#21333;&#20010;LLM&#21487;&#20197;&#31649;&#29702;&#22810;&#28304;&#25968;&#25454;&#24182;&#36827;&#34892;&#39640;&#32423;&#33258;&#28982;&#35821;&#35328;&#25512;&#29702;&#65292;&#20197;&#25191;&#34892;&#22797;&#26434;&#30340;&#20020;&#24202;&#25805;&#20316;&#12290;&#36890;&#36807;&#19968;&#20010;&#26696;&#20363;&#26469;&#23637;&#31034;&#38024;&#23545;&#29273;&#31185;&#20020;&#24202;&#24212;&#29992;&#30340;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#22810;&#27169;&#24577;LLM AI&#31995;&#32479;&#30340;&#28508;&#21147;&#12290;&#34429;&#28982;LLMs&#22312;&#25552;&#20379;&#24040;&#22823;&#30340;&#28508;&#21147;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;
&lt;/p&gt;
&lt;p&gt;
The ChatGPT, as a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs, in fact, have stirred up a lot of interest among researchers and practitioners by their impressive skills in natural language processing tasks, which have a profound impact on a wide range of fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. A use case is presented to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant p
&lt;/p&gt;</description></item><item><title>ETPNav&#26159;&#19968;&#20010;&#33021;&#22815;&#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36827;&#34892;&#35270;&#35273;&#35821;&#35328;&#23548;&#33322;&#30340;&#26032;&#23548;&#33322;&#26694;&#26550;&#65292;&#23427;&#20855;&#26377;&#20004;&#20010;&#20851;&#38190;&#25216;&#33021;&#65306;&#33021;&#22815;&#25277;&#35937;&#29615;&#22659;&#19982;&#29983;&#25104;&#38271;&#31243;&#23548;&#33322;&#35745;&#21010;&#20197;&#21450;&#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36991;&#38556;&#25511;&#21046;&#30340;&#33021;&#21147;&#12290;ETPNav&#20351;&#29992;&#28436;&#21270;&#31639;&#27861;&#20248;&#21270;&#25299;&#25169;&#35268;&#21010;&#27169;&#22359;&#24182;&#22312;Matterport3D&#27169;&#25311;&#22120;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#20154;&#31867;&#27700;&#24179;&#30340;VLN-CE&#20219;&#21153;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03047</link><description>&lt;p&gt;
ETPNav: &#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#28436;&#21270;&#25299;&#25169;&#35268;&#21010;&#30340;&#35270;&#35273;&#35821;&#35328;&#23548;&#33322;
&lt;/p&gt;
&lt;p&gt;
ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03047
&lt;/p&gt;
&lt;p&gt;
ETPNav&#26159;&#19968;&#20010;&#33021;&#22815;&#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36827;&#34892;&#35270;&#35273;&#35821;&#35328;&#23548;&#33322;&#30340;&#26032;&#23548;&#33322;&#26694;&#26550;&#65292;&#23427;&#20855;&#26377;&#20004;&#20010;&#20851;&#38190;&#25216;&#33021;&#65306;&#33021;&#22815;&#25277;&#35937;&#29615;&#22659;&#19982;&#29983;&#25104;&#38271;&#31243;&#23548;&#33322;&#35745;&#21010;&#20197;&#21450;&#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36991;&#38556;&#25511;&#21046;&#30340;&#33021;&#21147;&#12290;ETPNav&#20351;&#29992;&#28436;&#21270;&#31639;&#27861;&#20248;&#21270;&#25299;&#25169;&#35268;&#21010;&#27169;&#22359;&#24182;&#22312;Matterport3D&#27169;&#25311;&#22120;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#36798;&#21040;&#20102;&#20154;&#31867;&#27700;&#24179;&#30340;VLN-CE&#20219;&#21153;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35270;&#35273;&#35821;&#35328;&#23548;&#33322;&#38656;&#35201;&#26234;&#33021;&#20307;&#36981;&#24490;&#25351;&#31034;&#22312;&#29615;&#22659;&#20013;&#23548;&#33322;&#65292;&#35813;&#20219;&#21153;&#22312;&#20307;&#39564;&#24335;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#65292;&#22914;&#33258;&#27835;&#23548;&#33322;&#12289;&#25628;&#32034;&#19982;&#25937;&#25588;&#21644;&#20154;&#26426;&#20132;&#20114;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26356;&#20026;&#23454;&#29992;&#20294;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#26223; - &#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36827;&#34892;&#35270;&#35273;&#35821;&#35328;&#23548;&#33322;&#65288;VLN-CE&#65289;&#12290;&#20026;&#20102;&#24320;&#21457;&#19968;&#20010;&#24378;&#22823;&#30340;VLN-CE&#20195;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23548;&#33322;&#26694;&#26550;ETPNav&#65292;&#23427;&#19987;&#27880;&#20110;&#20004;&#20010;&#20851;&#38190;&#25216;&#33021;&#65306;1&#65289;&#25277;&#35937;&#29615;&#22659;&#21644;&#29983;&#25104;&#38271;&#31243;&#23548;&#33322;&#35745;&#21010;&#30340;&#33021;&#21147;&#65307;&#21644;2&#65289;&#22312;&#36830;&#32493;&#29615;&#22659;&#20013;&#36991;&#38556;&#25511;&#21046;&#30340;&#33021;&#21147;&#12290;ETPNav&#36890;&#36807;&#33258;&#32452;&#32455;&#27839;&#30528;&#32463;&#36807;&#30340;&#36335;&#24452;&#39044;&#27979;&#30340;&#36335;&#26631;&#36827;&#34892;&#22312;&#32447;&#29615;&#22659;&#25299;&#25169;&#26144;&#23556;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#21069;&#30340;&#29615;&#22659;&#32463;&#39564;&#12290;&#23427;&#23558;&#23548;&#33322;&#36807;&#31243;&#20998;&#35299;&#20026;&#39640;&#23618;&#35268;&#21010;&#21644;&#20302;&#23618;&#25511;&#21046;&#12290;&#21516;&#26102;&#65292;ETPNav&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#28436;&#21270;&#31639;&#27861;&#26469;&#20248;&#21270;&#25299;&#25169;&#35268;&#21010;&#27169;&#22359;&#65292;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#38271;&#26399;&#23548;&#33322;&#35745;&#21010;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;Matterport3D&#27169;&#25311;&#22120;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#20219;&#24847;&#36215;&#28857;&#21644;&#32456;&#28857;&#30340;VLN-CE&#20219;&#21153;&#20013;&#36798;&#21040;&#20102;&#20154;&#31867;&#27700;&#24179;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vision-language navigation is a task that requires an agent to follow instructions to navigate in environments. It becomes increasingly crucial in the field of embodied AI, with potential applications in autonomous navigation, search and rescue, and human-robot interaction. In this paper, we propose to address a more practical yet challenging counterpart setting - vision-language navigation in continuous environments (VLN-CE). To develop a robust VLN-CE agent, we propose a new navigation framework, ETPNav, which focuses on two critical skills: 1) the capability to abstract environments and generate long-range navigation plans, and 2) the ability of obstacle-avoiding control in continuous environments. ETPNav performs online topological mapping of environments by self-organizing predicted waypoints along a traversed path, without prior environmental experience. It privileges the agent to break down the navigation procedure into high-level planning and low-level control. Concurrently, ET
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#23545;&#20110;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#12290;</title><link>http://arxiv.org/abs/2304.03030</link><description>&lt;p&gt;
&#26522;&#20030;&#21387;&#32553;&#19982;&#22686;&#30410;
&lt;/p&gt;
&lt;p&gt;
Compression of enumerations and gain. (arXiv:2304.03030v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#23545;&#20110;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26522;&#20030;&#30340;&#21487;&#21387;&#32553;&#24615;&#65292;&#20197;&#21450;&#20854;&#22312;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#30340;&#30456;&#23545;Kolmogorov&#22797;&#26434;&#24230;&#20013;&#23494;&#24230;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#20851;&#27880;&#20102;&#24378;&#21387;&#32553;&#21644;&#24369;&#21387;&#32553;&#65292;&#20197;&#21450;&#21387;&#32553;&#26522;&#20030;&#20013;&#23884;&#20837;&#30340;&#38468;&#21152;&#20449;&#24687;&#30340;&#25968;&#37327;&#65306;&#22686;&#30410;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#35745;&#31639;&#21487;&#26522;&#20030;&#38598;&#21512;&#37117;&#21487;&#20197;&#36827;&#34892;&#24378;&#21387;&#32553;&#21644;&#26080;&#22686;&#30410;&#24369;&#21387;&#32553;&#65292;&#24182;&#30740;&#31350;&#20102;&#20301;&#32622;&#28216;&#25103;&#20197;&#29702;&#35299;&#24378;&#26080;&#22686;&#30410;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the compressibility of enumerations, and its role in the relative Kolmogorov complexity of computably enumerable sets, with respect to density. With respect to a strong and a weak form of compression, we examine the gain: the amount of auxiliary information embedded in the compressed enumeration. Strong compression and weak gainless compression is shown for any computably enumerable set, and a positional game is studied toward understanding strong gainless compression.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#27861;&#30340;&#33258;&#28982;&#35821;&#35328;&#26426;&#22120;&#20154;&#32534;&#31243;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#39640;&#21487;&#29992;&#24615;&#65292;&#29992;&#20110;&#35268;&#23450;pick-and-place&#20219;&#21153;&#30340;joint space trajectories&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#33258;&#23450;&#20041;&#35789;&#20856;&#65292;&#21487;&#20197;&#36731;&#26494;&#25193;&#23637;&#65292;&#24182;&#19988;&#26080;&#38656;&#20381;&#36182;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#25110;&#36801;&#31227;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2304.02993</link><description>&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#26426;&#22120;&#20154;&#32534;&#31243;&#65306;&#23558;NLP&#19982;&#33258;&#20027;&#26426;&#22120;&#20154;&#25235;&#21462;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Natural Language Robot Programming: NLP integrated with autonomous robotic grasping. (arXiv:2304.02993v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#27861;&#30340;&#33258;&#28982;&#35821;&#35328;&#26426;&#22120;&#20154;&#32534;&#31243;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#38469;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#39640;&#21487;&#29992;&#24615;&#65292;&#29992;&#20110;&#35268;&#23450;pick-and-place&#20219;&#21153;&#30340;joint space trajectories&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#33258;&#23450;&#20041;&#35789;&#20856;&#65292;&#21487;&#20197;&#36731;&#26494;&#25193;&#23637;&#65292;&#24182;&#19988;&#26080;&#38656;&#20381;&#36182;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#25110;&#36801;&#31227;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35821;&#27861;&#30340;&#33258;&#28982;&#35821;&#35328;&#26426;&#22120;&#20154;&#32534;&#31243;&#26694;&#26550;&#65292;&#29305;&#21035;&#29992;&#20110;&#25342;&#21462;&#21644;&#25918;&#32622;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#33258;&#23450;&#20041;&#21160;&#20316;&#35789;&#20856;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#23558;&#20849;&#20139;&#24847;&#20041;&#30340;&#21333;&#35789;&#23384;&#20648;&#22312;&#19968;&#36215;&#30340;&#26041;&#24335;&#65292;&#20174;&#32780;&#36890;&#36807;&#20174;&#35789;&#27719;&#25968;&#25454;&#24211;&#20013;&#28155;&#21152;&#26356;&#22810;&#21160;&#20316;&#35789;&#21487;&#20197;&#36731;&#26494;&#25193;&#23637;&#35789;&#27719;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#25645;&#36733;&#26657;&#20934;&#30340;&#25163;&#20013;&#30456;&#26426;&#21644;&#40614;&#20811;&#39118;&#30340;Franka Panda&#26426;&#26800;&#33218;&#65292;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#23454;&#39564;&#20013;&#39564;&#35777;&#25105;&#20204;&#30340;&#33258;&#28982;&#35821;&#35328;&#26426;&#22120;&#20154;&#32534;&#31243;&#65288;NLRP&#65289;&#26694;&#26550;&#65292;&#35201;&#27714;&#21442;&#19982;&#32773;&#20351;&#29992;&#21475;&#22836;&#21629;&#20196;&#23436;&#25104;&#25342;&#21462;&#21644;&#25918;&#32622;&#20219;&#21153;&#65292;&#23558;&#20854;&#36716;&#25442;&#20026;&#25991;&#26412;&#21518;&#36890;&#36807;NLRP&#26694;&#26550;&#22788;&#29702;&#65292;&#20197;&#33719;&#21462;&#26426;&#22120;&#20154;&#36816;&#21160;&#30340;&#20851;&#33410;&#31354;&#38388;&#36712;&#36857;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#24456;&#39640;&#30340;&#31995;&#32479;&#21487;&#29992;&#24615;&#35780;&#20998;&#12290;&#35813;&#26694;&#26550;&#30340;&#35789;&#20856;&#21487;&#20197;&#36731;&#26494;&#25193;&#23637;&#65292;&#26080;&#38656;&#20381;&#36182;&#20110;&#36801;&#31227;&#23398;&#20064;&#25110;&#22823;&#25968;&#25454;&#38598;&#12290;&#22312;&#26410;&#26469;&#65292;&#25105;&#20204;&#35745;&#21010;&#23545;&#19981;&#21516;&#30340;&#26426;&#22120;&#20154;&#24179;&#21488;&#21644;&#22810;&#20010;&#20219;&#21153;&#36827;&#34892;&#36827;&#19968;&#27493;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a grammar-based natural language framework for robot programming, specifically for pick-and-place tasks. Our approach uses a custom dictionary of action words, designed to store together words that share meaning, allowing for easy expansion of the vocabulary by adding more action words from a lexical database. We validate our Natural Language Robot Programming (NLRP) framework through simulation and real-world experimentation, using a Franka Panda robotic arm equipped with a calibrated camera-in-hand and a microphone. Participants were asked to complete a pick-and-place task using verbal commands, which were converted into text using Google's Speech-to-Text API and processed through the NLRP framework to obtain joint space trajectories for the robot. Our results indicate that our approach has a high system usability score. The framework's dictionary can be easily extended without relying on transfer learning or large data sets. In the future, we plan to compar
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#38382;&#39064;&#65292;&#32467;&#21512;&#31038;&#20132;&#20449;&#24687;&#21644;&#25991;&#26412;&#29305;&#24449;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22810;&#36755;&#20837;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#23545;&#20449;&#24687;&#20256;&#25773;&#30340;&#26089;&#26399;&#38454;&#27573;&#30340;&#26377;&#25928;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2304.02983</link><description>&lt;p&gt;
&#21033;&#29992;&#31038;&#20132;&#20114;&#21160;&#26816;&#27979;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#34394;&#20551;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Leveraging Social Interactions to Detect Misinformation on Social Media. (arXiv:2304.02983v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02983
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#34394;&#20551;&#20449;&#24687;&#26816;&#27979;&#38382;&#39064;&#65292;&#32467;&#21512;&#31038;&#20132;&#20449;&#24687;&#21644;&#25991;&#26412;&#29305;&#24449;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22810;&#36755;&#20837;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#23545;&#20449;&#24687;&#20256;&#25773;&#30340;&#26089;&#26399;&#38454;&#27573;&#30340;&#26377;&#25928;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#34394;&#20551;&#20449;&#24687;&#26159;&#30830;&#20445;&#31038;&#20132;&#23186;&#20307;&#20581;&#24247;&#29615;&#22659;&#30340;&#20851;&#38190;&#12290;&#25105;&#20204;&#20351;&#29992;COVID-19&#27969;&#34892;&#26399;&#38388;&#21019;&#24314;&#30340;&#25968;&#25454;&#38598;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#21253;&#21547;&#24494;&#24369;&#26631;&#35760;&#20026;&#21487;&#38752;&#25110;&#19981;&#21487;&#38752;&#30340;&#20449;&#24687;&#32423;&#32852;&#25512;&#25991;&#65292;&#22522;&#20110;&#23545;&#20449;&#24687;&#28304;&#30340;&#20808;&#21069;&#35780;&#20272;&#12290;&#35782;&#21035;&#19981;&#21487;&#38752;&#32447;&#31243;&#30340;&#27169;&#22411;&#36890;&#24120;&#20381;&#36182;&#20110;&#25991;&#26412;&#29305;&#24449;&#12290;&#20294;&#26159;&#65292;&#21487;&#38752;&#24615;&#19981;&#20165;&#21462;&#20915;&#20110;&#25991;&#26412;&#20869;&#23481;&#65292;&#36824;&#21462;&#20915;&#20110;&#20449;&#24687;&#30340;&#21457;&#24067;&#32773;&#20197;&#21450;&#21457;&#24067;&#32473;&#35841;&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;&#32593;&#32476;&#20449;&#24687;&#12290;&#36981;&#24490;&#21516;&#36136;&#24615;&#21407;&#21017;&#65292;&#25105;&#20204;&#20551;&#35774;&#20114;&#21160;&#30340;&#29992;&#25143;&#36890;&#24120;&#23545;&#30456;&#20284;&#30340;&#35805;&#39064;&#24863;&#20852;&#36259;&#65292;&#24182;&#20256;&#25773;&#31867;&#20284;&#30340;&#26032;&#38395;&#65292;&#36825;&#20123;&#26032;&#38395;&#36890;&#24120;&#26159;&#21487;&#38752;&#30340;&#25110;&#19981;&#21487;&#38752;&#30340;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#20960;&#31181;&#26041;&#27861;&#26469;&#23398;&#20064;&#32423;&#32852;&#20869;&#31038;&#20132;&#20114;&#21160;&#30340;&#34920;&#31034;&#65292;&#23558;&#23427;&#20204;&#19982;&#28145;&#24230;&#31070;&#32463;&#35821;&#35328;&#27169;&#22411;&#22312;&#22810;&#36755;&#20837;(MI)&#26694;&#26550;&#20013;&#32467;&#21512;&#36215;&#26469;&#12290;&#36890;&#36807;&#36319;&#36394;&#20114;&#21160;&#26102;&#38388;&#24207;&#21015;&#65292;&#25105;&#20204;&#25552;&#39640;&#20102;&#20808;&#21069;&#30340;&#26368;&#26032;&#27700;&#24179;&#65292;&#26080;&#35770;&#26159;&#20351;&#29992;&#32431;&#25991;&#26412;&#20998;&#31867;&#22120;&#36824;&#26159;&#27809;&#26377;&#31038;&#20132;&#20449;&#24687;&#30340;&#22810;&#36755;&#20837;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28155;&#21152;&#31038;&#20132;&#20449;&#24687;&#21487;&#20197;&#24110;&#21161;&#36229;&#36234;&#20854;&#20182;&#35299;&#20915;&#26041;&#26696;&#65292;&#29305;&#21035;&#26159;&#22312;&#20449;&#24687;&#20256;&#25773;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#22312;&#37027;&#37324;&#21482;&#26377;&#24456;&#23569;&#30340;&#25512;&#25991;&#21487;&#20379;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting misinformation threads is crucial to guarantee a healthy environment on social media. We address the problem using the data set created during the COVID-19 pandemic. It contains cascades of tweets discussing information weakly labeled as reliable or unreliable, based on a previous evaluation of the information source. The models identifying unreliable threads usually rely on textual features. But reliability is not just what is said, but by whom and to whom. We additionally leverage on network information. Following the homophily principle, we hypothesize that users who interact are generally interested in similar topics and spreading similar kind of news, which in turn is generally reliable or not. We test several methods to learn representations of the social interactions within the cascades, combining them with deep neural language models in a Multi-Input (MI) framework. Keeping track of the sequence of the interactions during the time, we improve over previous state-of-th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#26631;&#31614;&#30340;&#38382;&#21367;&#31572;&#26696;&#36827;&#34892;&#20998;&#31867;&#30740;&#31350;&#65292;&#20174;&#35797;&#39564;&#32467;&#26524;&#20013;&#21457;&#29616;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#26550;&#26500;BERT&#30456;&#36739;&#20256;&#32479;&#31639;&#27861;&#22312;&#20998;&#31867;&#25928;&#26524;&#19978;&#26356;&#21152;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2304.02945</link><description>&lt;p&gt;
&#22522;&#20110;BERT&#30340;&#24320;&#25918;&#24335;&#38382;&#39064;&#22810;&#26631;&#31614;&#20998;&#31867;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multi-label classification of open-ended questions with BERT. (arXiv:2304.02945v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22810;&#26631;&#31614;&#30340;&#38382;&#21367;&#31572;&#26696;&#36827;&#34892;&#20998;&#31867;&#30740;&#31350;&#65292;&#20174;&#35797;&#39564;&#32467;&#26524;&#20013;&#21457;&#29616;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#26550;&#26500;BERT&#30456;&#36739;&#20256;&#32479;&#31639;&#27861;&#22312;&#20998;&#31867;&#25928;&#26524;&#19978;&#26356;&#21152;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#20013;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#20215;&#20540;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#20250;&#38480;&#21046;&#21463;&#35775;&#32773;&#30340;&#31572;&#26696;&#65292;&#20174;&#32780;&#36991;&#20813;&#20559;&#35265;&#12290;&#28982;&#32780;&#65292;&#24320;&#25918;&#38382;&#39064;&#30340;&#31572;&#26696;&#26159;&#25991;&#26412;&#25968;&#25454;&#65292;&#26356;&#38590;&#20998;&#26512;&#12290;&#20256;&#32479;&#19978;&#65292;&#31572;&#26696;&#25353;&#29031;&#32534;&#30721;&#25163;&#20876;&#20013;&#25351;&#23450;&#30340;&#26041;&#24335;&#25163;&#21160;&#20998;&#31867;&#12290;&#22823;&#37096;&#20998;&#33258;&#21160;&#32534;&#30721;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#21333;&#26631;&#31614;&#39044;&#27979;&#19978;&#65292;&#20854;&#20013;&#31572;&#26696;&#34987;&#20998;&#20026;&#19968;&#20010;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#38656;&#35201;&#22810;&#26631;&#31614;&#20998;&#31867;&#30340;&#24320;&#25918;&#24335;&#38382;&#39064;&#65288;&#21363;&#20998;&#37197;&#22810;&#20010;&#20195;&#30721;&#30340;&#38382;&#39064;&#65289;&#32463;&#24120;&#21457;&#29983;&#12290;&#26412;&#25991;&#38024;&#23545;&#31038;&#20250;&#31185;&#23398;&#35843;&#26597;&#20013;&#24320;&#25918;&#38382;&#21367;&#35843;&#26597;&#30340;&#25991;&#26412;&#31572;&#26696;&#36827;&#34892;&#22810;&#26631;&#31614;&#20998;&#31867;&#30740;&#31350;&#12290;&#25105;&#20204;&#38024;&#23545;&#24503;&#35821;&#20351;&#29992;&#22522;&#20110;&#36716;&#25442;&#22120;&#30340;&#26550;&#26500;BERT&#36827;&#34892;&#24615;&#33021;&#35780;&#20272;&#65292;&#19982;&#20256;&#32479;&#30340;&#22810;&#26631;&#31614;&#31639;&#27861;&#65288;&#20108;&#36827;&#21046;&#30456;&#20851;&#24615;&#12289;&#26631;&#31614;&#24130;&#38598;&#12289;ECC&#65289;&#36827;&#34892;&#27604;&#36739;&#65292;&#38024;&#23545;&#24503;&#22269;&#31038;&#20250;&#31185;&#23398;&#35843;&#26597;GLES Panel&#65288;N=17,584&#65292;55&#20010;&#26631;&#31614;&#65289;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;BERT&#30340;&#20998;&#31867;&#19979;&#65288;&#24378;&#21046;&#33267;&#23569;&#19968;&#20010;&#26631;&#31614;&#65289;&#65292;&#22810;&#26631;&#31614;&#25991;&#26412;&#38382;&#39064;&#30340;&#20998;&#31867;&#24615;&#33021;&#27604;&#20256;&#32479;&#31639;&#27861;&#26356;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;
Open-ended questions in surveys are valuable because they do not constrain the respondent's answer, thereby avoiding biases. However, answers to open-ended questions are text data which are harder to analyze. Traditionally, answers were manually classified as specified in the coding manual. Most of the effort to automate coding has gone into the easier problem of single label prediction, where answers are classified into a single code. However, open-ends that require multi-label classification, i.e., that are assigned multiple codes, occur frequently. This paper focuses on multi-label classification of text answers to open-ended survey questions in social science surveys. We evaluate the performance of the transformer-based architecture BERT for the German language in comparison to traditional multi-label algorithms (Binary Relevance, Label Powerset, ECC) in a German social science survey, the GLES Panel (N=17,584, 55 labels). We find that classification with BERT (forcing at least one
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20316;SpanRE&#30340;&#23454;&#20307;&#21644;&#37325;&#21472;&#20851;&#31995;&#25552;&#21462;&#26041;&#27861;&#65292;&#36816;&#29992;&#26631;&#20934;span&#26426;&#21046;&#25552;&#21462;&#20505;&#36873;&#20027;&#39064;&#65292;&#28982;&#21518;&#32467;&#21512;&#23454;&#20307;&#20851;&#27880;&#26426;&#21046;&#21644;&#24102;&#26631;&#31614;&#30340;span&#26426;&#21046;&#20174;&#21477;&#23376;&#20013;&#25552;&#21462;&#23545;&#35937;&#21644;&#20851;&#31995;&#12290;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#27979;&#35797;&#34920;&#26126;&#35813;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.02901</link><description>&lt;p&gt;
SpanRE: &#22522;&#20110;Span&#21644;&#23454;&#20307;&#20851;&#27880;&#26426;&#21046;&#30340;&#23454;&#20307;&#21644;&#37325;&#21472;&#20851;&#31995;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
SpanRE: Entities and Overlapping Relations Extraction Based on Spans and Entity Attention. (arXiv:2304.02901v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20316;SpanRE&#30340;&#23454;&#20307;&#21644;&#37325;&#21472;&#20851;&#31995;&#25552;&#21462;&#26041;&#27861;&#65292;&#36816;&#29992;&#26631;&#20934;span&#26426;&#21046;&#25552;&#21462;&#20505;&#36873;&#20027;&#39064;&#65292;&#28982;&#21518;&#32467;&#21512;&#23454;&#20307;&#20851;&#27880;&#26426;&#21046;&#21644;&#24102;&#26631;&#31614;&#30340;span&#26426;&#21046;&#20174;&#21477;&#23376;&#20013;&#25552;&#21462;&#23545;&#35937;&#21644;&#20851;&#31995;&#12290;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#27979;&#35797;&#34920;&#26126;&#35813;&#26041;&#27861;&#21462;&#24471;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#21462;&#23454;&#20307;&#21644;&#20851;&#31995;&#26159;&#20449;&#24687;&#25552;&#21462;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#20174;&#19968;&#26465;&#21477;&#23376;&#20013;&#25552;&#21462;&#30340;&#19977;&#20803;&#32452;&#21487;&#33021;&#20250;&#26377;&#37325;&#21472;&#12290;&#20808;&#21069;&#30340;&#26041;&#27861;&#27809;&#26377;&#35299;&#20915;&#37325;&#21472;&#38382;&#39064;&#25110;&#35299;&#20915;&#20102;&#37096;&#20998;&#37325;&#21472;&#38382;&#39064;&#12290;&#20026;&#20102;&#23436;&#20840;&#35299;&#20915;&#37325;&#21472;&#38382;&#39064;&#65292;&#39318;&#20808;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;span&#26426;&#21046;&#25552;&#21462;&#20505;&#36873;&#20027;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26631;&#31614;&#30340;span&#26426;&#21046;&#65292;&#21516;&#26102;&#25552;&#21462;&#20102;&#23545;&#35937;&#21644;&#20851;&#31995;&#12290;&#25105;&#20204;&#20351;&#29992;&#24102;&#26631;&#31614;&#30340;span&#26426;&#21046;&#29983;&#25104;&#24102;&#26631;&#31614;&#30340;span&#65292;&#20854;&#36215;&#22987;&#21644;&#32467;&#26463;&#20301;&#32622;&#34920;&#31034;&#23545;&#35937;&#65292;&#26631;&#31614;&#23545;&#24212;&#20110;&#20027;&#39064;&#21644;&#23545;&#35937;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23454;&#20307;&#20851;&#27880;&#26426;&#21046;&#65292;&#22686;&#24378;&#20102;&#22312;&#25552;&#21462;&#23545;&#35937;&#21644;&#20851;&#31995;&#26399;&#38388;&#20027;&#39064;&#21644;&#21477;&#23376;&#20043;&#38388;&#30340;&#20449;&#24687;&#34701;&#21512;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36825;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#26368;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting entities and relations is an essential task of information extraction. Triplets extracted from a sentence might overlap with each other. Previous methods either did not address the overlapping issues or solved overlapping issues partially. To tackle triplet overlapping problems completely, firstly we extract candidate subjects with a standard span mechanism. Then we present a labeled span mechanism to extract the objects and relations simultaneously, we use the labeled span mechanism to generate labeled spans whose start and end positions indicate the objects, and whose labels correspond to relations of subject and objects. Besides, we design an entity attention mechanism to enhance the information fusion between subject and sentence during extracting objects and relations. We test our method on two public datasets, our method achieves the best performances on these two datasets.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#24773;&#24863;&#20316;&#20026;&#25991;&#23398;&#25991;&#26412;&#24773;&#32490;&#30340;&#20195;&#29702;&#65292;&#24182;&#33021;&#36890;&#36807;&#25193;&#23637;&#24773;&#24863;&#35789;&#20856;&#22312;&#32771;&#34385;&#25991;&#26412;&#35821;&#20041;&#36716;&#31227;&#21644;&#39046;&#22495;&#30340;&#21069;&#25552;&#19979;&#65292;&#25552;&#20379;&#36817;&#26399;&#21644;&#29616;&#20195;&#20998;&#26512;&#30340;&#23454;&#38469;&#21487;&#34892;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.02894</link><description>&lt;p&gt;
&#22522;&#20110;&#24773;&#24863;&#30340;&#25991;&#23398;&#24773;&#32490;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Affect as a proxy for literary mood. (arXiv:2304.02894v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#24773;&#24863;&#20316;&#20026;&#25991;&#23398;&#25991;&#26412;&#24773;&#32490;&#30340;&#20195;&#29702;&#65292;&#24182;&#33021;&#36890;&#36807;&#25193;&#23637;&#24773;&#24863;&#35789;&#20856;&#22312;&#32771;&#34385;&#25991;&#26412;&#35821;&#20041;&#36716;&#31227;&#21644;&#39046;&#22495;&#30340;&#21069;&#25552;&#19979;&#65292;&#25552;&#20379;&#36817;&#26399;&#21644;&#29616;&#20195;&#20998;&#26512;&#30340;&#23454;&#38469;&#21487;&#34892;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#24773;&#24863;&#20316;&#20026;&#25991;&#23398;&#25991;&#26412;&#24773;&#32490;&#30340;&#20195;&#29702;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#35745;&#31639;&#24773;&#24863;&#19982;&#26816;&#27979;&#24773;&#32490;&#20043;&#38388;&#30340;&#21306;&#21035;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#21033;&#29992;&#24773;&#24863;&#35789;&#23884;&#20837;&#26469;&#35266;&#23519;&#19981;&#21516;&#25991;&#26412;&#27573;&#33853;&#20013;&#30340;&#24773;&#24863;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#24773;&#24863;&#35789;&#20856;&#65292;&#32771;&#34385;&#20102;&#35821;&#20041;&#36716;&#31227;&#21644;&#25991;&#26412;&#39046;&#22495;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19982;&#24403;&#20195;&#21644;&#29616;&#20195;&#23450;&#24615;&#20998;&#26512;&#23494;&#20999;&#21305;&#37197;&#30340;&#29616;&#23454;&#19990;&#30028;&#19968;&#33268;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to use affect as a proxy for mood in literary texts. In this study, we explore the differences in computationally detecting tone versus detecting mood. Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments. We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#27861;&#35821;&#20020;&#24202;&#25991;&#26412;&#33258;&#21160;&#20851;&#32852;ICD&#20195;&#30721;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#26032;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#22810;&#26631;&#31614;&#20998;&#31867;&#25216;&#26415;&#30340;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#25216;&#26415;&#32467;&#26524;&#65292;F1&#20998;&#25968;&#25552;&#39640;&#20102;55&#65285;&#20197;&#19978;&#12290;</title><link>http://arxiv.org/abs/2304.02886</link><description>&lt;p&gt;
&#33258;&#21160;ICD-10&#32534;&#30721;&#20851;&#32852;&#65306;&#23545;&#27861;&#35821;&#20020;&#24202;&#25991;&#26412;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts. (arXiv:2304.02886v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#27861;&#35821;&#20020;&#24202;&#25991;&#26412;&#33258;&#21160;&#20851;&#32852;ICD&#20195;&#30721;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#26032;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#22810;&#26631;&#31614;&#20998;&#31867;&#25216;&#26415;&#30340;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#25216;&#26415;&#32467;&#26524;&#65292;F1&#20998;&#25968;&#25552;&#39640;&#20102;55&#65285;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#30740;&#31350;&#20013;&#65292;&#33258;&#21160;&#23558;ICD&#20195;&#30721;&#19982;&#30005;&#23376;&#20581;&#24247;&#25968;&#25454;&#20851;&#32852;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#12290;&#26368;&#36817;&#20960;&#24180;&#65292;&#38543;&#30528;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24471;&#21040;&#20102;&#26174;&#33879;&#30340;&#21457;&#23637;&#65292;&#20027;&#35201;&#24212;&#29992;&#20110;&#33521;&#25991;&#35821;&#35328;&#12290;&#26412;&#25991;&#38024;&#23545;&#27861;&#35821;&#25991;&#26412;&#33258;&#21160;&#20851;&#32852;ICD&#20195;&#30721;&#30340;&#38382;&#39064;&#65292;&#23581;&#35797;&#20351;&#29992;&#22810;&#31181;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#22788;&#29702;&#22823;&#37327;&#30340;&#36755;&#20837;&#26631;&#35760;&#21644;&#38656;&#35201;&#29468;&#27979;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#23558;&#26368;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#22810;&#26631;&#31614;&#20998;&#31867;&#25216;&#26415;&#24212;&#29992;&#20110;ICD-10&#32534;&#30721;&#20851;&#32852;&#26041;&#38754;&#12290;&#23545;&#20110;&#27861;&#35821;&#30340;&#20020;&#24202;&#25968;&#25454;&#38598;&#65292;&#20844;&#27491;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;F1&#20998;&#25968;&#27604;&#29616;&#26377;&#25216;&#26415;&#32467;&#26524;&#25552;&#39640;&#20102;55&#65285;&#20197;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatically associating ICD codes with electronic health data is a well-known NLP task in medical research. NLP has evolved significantly in recent years with the emergence of pre-trained language models based on Transformers architecture, mainly in the English language. This paper adapts these models to automatically associate the ICD codes. Several neural network architectures have been experimented with to address the challenges of dealing with a large set of both input tokens and labels to be guessed. In this paper, we propose a model that combines the latest advances in NLP and multi-label classification for ICD-10 code association. Fair experiments on a Clinical dataset in the French language show that our approach increases the $F_1$-score metric by more than 55\% compared to state-of-the-art results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#20854;&#34920;&#29616;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#26234;&#33021;&#65292;&#26377;&#24453;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2304.02868</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#21542;&#33021;&#22815;&#24456;&#22909;&#22320;&#29609;&#25991;&#23383;&#28216;&#25103;&#65311;&#29616;&#29366;&#21644;&#26410;&#26469;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions. (arXiv:2304.02868v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#30340;&#33021;&#21147;&#65292;&#24182;&#21457;&#29616;&#20854;&#34920;&#29616;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#26234;&#33021;&#65292;&#26377;&#24453;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35832;&#22914;ChatGPT&#21644;GPT-4&#20043;&#31867;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#20154;&#31867;&#29992;&#25143;&#36890;&#20449;&#30340;&#21331;&#36234;&#33021;&#21147;&#12290;&#26412;&#25216;&#26415;&#25253;&#21578;&#26088;&#22312;&#35843;&#26597;&#23427;&#20204;&#22312;&#29609;&#25991;&#23383;&#28216;&#25103;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#36825;&#35201;&#27714;&#29609;&#23478;&#36890;&#36807;&#19982;&#28216;&#25103;&#19990;&#30028;&#30340;&#23545;&#35805;&#26469;&#29702;&#35299;&#29615;&#22659;&#24182;&#23545;&#24773;&#20917;&#20570;&#20986;&#21453;&#24212;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#25152;&#26377;&#29616;&#26377;&#31995;&#32479;&#30456;&#27604;&#65292;ChatGPT&#34920;&#29616;&#20986;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;&#20173;&#28982;&#34920;&#29616;&#20986;&#36739;&#20302;&#30340;&#26234;&#33021;&#27700;&#24179;&#12290;&#30830;&#20999;&#22320;&#35828;&#65292;ChatGPT&#26080;&#27861;&#36890;&#36807;&#29609;&#28216;&#25103;&#25110;&#38405;&#35835;&#28216;&#25103;&#25163;&#20876;&#26469;&#26500;&#24314;&#19990;&#30028;&#27169;&#22411;&#65307;&#23427;&#21487;&#33021;&#26080;&#27861;&#21033;&#29992;&#23427;&#24050;&#32463;&#25317;&#26377;&#30340;&#19990;&#30028;&#30693;&#35782;&#65307;&#23427;&#26080;&#27861;&#25512;&#26029;&#20986;&#38543;&#30528;&#28216;&#25103;&#36827;&#23637;&#30340;&#27599;&#19968;&#27493;&#30340;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#20154;&#24037;&#26234;&#33021;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20132;&#21449;&#39046;&#22495;&#24320;&#21551;&#20102;&#26032;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) such as ChatGPT and GPT-4 have recently demonstrated their remarkable abilities of communicating with human users. In this technical report, we take an initiative to investigate their capacities of playing text games, in which a player has to understand the environment and respond to situations by having dialogues with the game world. Our experiments show that ChatGPT performs competitively compared to all the existing systems but still exhibits a low level of intelligence. Precisely, ChatGPT can not construct the world model by playing the game or even reading the game manual; it may fail to leverage the world knowledge that it already has; it cannot infer the goal of each step as the game progresses. Our results open up new research questions at the intersection of artificial intelligence, machine learning, and natural language processing.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21457;&#29616;&#65292;GPT&#26816;&#27979;&#22120;&#23545;&#38750;&#33521;&#35821;&#27597;&#35821;&#20316;&#32773;&#23384;&#22312;&#20559;&#35265;&#65292;&#23481;&#26131;&#23558;&#20854;&#20869;&#23481;&#38169;&#35823;&#22320;&#20998;&#31867;&#20026;AI&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;&#27492;&#22806;&#65292;&#31616;&#21333;&#30340;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#20559;&#35265;&#65292;&#21516;&#26102;&#35268;&#36991;GPT&#26816;&#27979;&#22120;&#65292;&#36825;&#34920;&#26126;GPT&#26816;&#27979;&#22120;&#21487;&#33021;&#20250;&#24809;&#32602;&#20855;&#26377;&#21463;&#38480;&#35821;&#35328;&#34920;&#36798;&#33021;&#21147;&#30340;&#20316;&#32773;&#12290;</title><link>http://arxiv.org/abs/2304.02819</link><description>&lt;p&gt;
GPT&#26816;&#27979;&#22120;&#23545;&#38750;&#33521;&#35821;&#27597;&#35821;&#30340;&#20316;&#32773;&#23384;&#22312;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
GPT detectors are biased against non-native English writers. (arXiv:2304.02819v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02819
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21457;&#29616;&#65292;GPT&#26816;&#27979;&#22120;&#23545;&#38750;&#33521;&#35821;&#27597;&#35821;&#20316;&#32773;&#23384;&#22312;&#20559;&#35265;&#65292;&#23481;&#26131;&#23558;&#20854;&#20869;&#23481;&#38169;&#35823;&#22320;&#20998;&#31867;&#20026;AI&#29983;&#25104;&#30340;&#20869;&#23481;&#12290;&#27492;&#22806;&#65292;&#31616;&#21333;&#30340;&#25552;&#31034;&#31574;&#30053;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#20559;&#35265;&#65292;&#21516;&#26102;&#35268;&#36991;GPT&#26816;&#27979;&#22120;&#65292;&#36825;&#34920;&#26126;GPT&#26816;&#27979;&#22120;&#21487;&#33021;&#20250;&#24809;&#32602;&#20855;&#26377;&#21463;&#38480;&#35821;&#35328;&#34920;&#36798;&#33021;&#21147;&#30340;&#20316;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#35821;&#35328;&#27169;&#22411;&#30340;&#24555;&#36895;&#25512;&#24191;&#24102;&#26469;&#20102;&#25968;&#23383;&#36890;&#20449;&#26041;&#38754;&#30340;&#23454;&#36136;&#24615;&#36827;&#23637;&#65292;&#21516;&#26102;&#20063;&#24341;&#21457;&#20102;AI&#29983;&#25104;&#20869;&#23481;&#28508;&#22312;&#35823;&#29992;&#30340;&#25285;&#24551;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26816;&#27979;&#26041;&#27861;&#26469;&#21306;&#20998;AI&#21644;&#20154;&#31867;&#29983;&#25104;&#30340;&#20869;&#23481;&#65292;&#20294;&#36825;&#20123;&#26816;&#27979;&#22120;&#30340;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#35752;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#33521;&#35821;&#27597;&#35821;&#21644;&#38750;&#33521;&#35821;&#27597;&#35821;&#20316;&#32773;&#30340;&#20889;&#20316;&#26679;&#26412;&#35780;&#20272;&#20102;&#20960;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;GPT&#26816;&#27979;&#22120;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#26816;&#27979;&#22120;&#25345;&#32493;&#23558;&#38750;&#33521;&#35821;&#27597;&#35821;&#30340;&#20889;&#20316;&#26679;&#26412;&#38169;&#35823;&#22320;&#20998;&#31867;&#20026;AI&#29983;&#25104;&#30340;&#20869;&#23481;&#65292;&#32780;&#21407;&#29983;&#20889;&#20316;&#26679;&#26412;&#21017;&#33021;&#22815;&#34987;&#20934;&#30830;&#35782;&#21035;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#31616;&#21333;&#30340;&#25552;&#31034;&#31574;&#30053;&#19981;&#20165;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#20559;&#35265;&#65292;&#32780;&#19988;&#36824;&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;GPT&#26816;&#27979;&#22120;&#65292;&#36825;&#34920;&#26126;GPT&#26816;&#27979;&#22120;&#21487;&#33021;&#26080;&#24847;&#20013;&#24809;&#32602;&#20855;&#26377;&#21463;&#38480;&#35821;&#35328;&#34920;&#36798;&#33021;&#21147;&#30340;&#20316;&#32773;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#21628;&#21505;&#36827;&#34892;&#26356;&#24191;&#27867;&#30340;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversati
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#35805;&#22810;&#26679;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#20351;&#29992;&#20154;&#31867;&#21019;&#24314;&#30340;&#25968;&#25454;&#38598;&#35777;&#26126;&#20102;&#22522;&#26412;&#35821;&#35328;&#34892;&#20026;&#25552;&#20379;&#20102;&#22810;&#20010;&#19979;&#19968;&#27493;&#21709;&#24212;&#30340;&#22810;&#26679;&#24615;&#20449;&#21495;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;&#20219;&#21153;&#65292;&#20351;&#29992;&#21019;&#24847;&#20316;&#23478;&#26469;&#35780;&#21028;&#22810;&#26679;&#24615;&#30340;&#31243;&#24230;&#65292;&#24182;&#19988;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#34987;&#35777;&#26126;&#26159;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#34913;&#37327;&#23545;&#35805;&#36136;&#37327;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.02812</link><description>&lt;p&gt;
&#23545;&#35805;&#35780;&#20272;&#20013;&#30340;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;
&lt;/p&gt;
&lt;p&gt;
Pragmatically Appropriate Diversity for Dialogue Evaluation. (arXiv:2304.02812v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02812
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#35805;&#22810;&#26679;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#20351;&#29992;&#20154;&#31867;&#21019;&#24314;&#30340;&#25968;&#25454;&#38598;&#35777;&#26126;&#20102;&#22522;&#26412;&#35821;&#35328;&#34892;&#20026;&#25552;&#20379;&#20102;&#22810;&#20010;&#19979;&#19968;&#27493;&#21709;&#24212;&#30340;&#22810;&#26679;&#24615;&#20449;&#21495;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35780;&#20272;&#20219;&#21153;&#65292;&#20351;&#29992;&#21019;&#24847;&#20316;&#23478;&#26469;&#35780;&#21028;&#22810;&#26679;&#24615;&#30340;&#31243;&#24230;&#65292;&#24182;&#19988;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#34987;&#35777;&#26126;&#26159;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#34913;&#37327;&#23545;&#35805;&#36136;&#37327;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35821;&#35328;&#35821;&#29992;&#23398;&#34920;&#26126;&#65292;&#23545;&#35805;&#20013;&#30340;&#22522;&#26412;&#35821;&#35328;&#34892;&#20026;&#21487;&#20197;&#38480;&#21046;&#27599;&#20010;&#22238;&#21512;&#20013;&#36866;&#24403;&#30340;&#21709;&#24212;&#31867;&#22411;&#12290;&#22312;&#29983;&#25104;&#23545;&#35805;&#22238;&#22797;&#26102;&#65292;&#31070;&#32463;&#23545;&#35805;&#20195;&#29702;&#38590;&#20197;&#20135;&#29983;&#19981;&#21516;&#30340;&#21709;&#24212;&#12290;&#30446;&#21069;&#65292;&#20351;&#29992;&#33258;&#21160;&#24230;&#37327;&#34913;&#26469;&#35780;&#20272;&#23545;&#35805;&#30340;&#22810;&#26679;&#24615;&#65292;&#20294;&#22522;&#26412;&#35821;&#35328;&#34892;&#20026;&#24182;&#26410;&#32771;&#34385;&#36825;&#20123;&#24230;&#37327;&#26631;&#20934;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#30340;&#27010;&#24565;&#65292;&#36825;&#23450;&#20041;&#20026;&#19968;&#20010;&#23545;&#35805;&#20013;&#20135;&#29983;&#21644;&#38480;&#21046;&#22810;&#20010;&#19981;&#21516;&#21709;&#24212;&#30340;&#31243;&#24230;&#12290;&#20351;&#29992;&#20154;&#31867;&#21019;&#24314;&#30340;&#22810;&#20010;&#21709;&#24212;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#21457;&#29616;&#22522;&#26412;&#35821;&#35328;&#34892;&#20026;&#25552;&#20379;&#20102;&#22810;&#20010;&#19979;&#19968;&#27493;&#21709;&#24212;&#30340;&#22810;&#26679;&#24615;&#20449;&#21495;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20154;&#31867;&#35780;&#20272;&#20219;&#21153;&#65292;&#21363;&#21019;&#24847;&#20316;&#23478;&#39044;&#27979;&#23545;&#35805;&#21551;&#21457;&#22810;&#31181;&#19981;&#21516;&#21709;&#24212;&#30340;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#20316;&#23478;&#30340;&#21028;&#26029;&#19982;&#23454;&#29992;&#36866;&#24403;&#24615;&#22810;&#26679;&#24615;&#27979;&#37327;&#30456;&#19968;&#33268;&#65292;&#24182;&#19988;&#36825;&#20010;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#27604;&#24403;&#21069;&#30340;&#22810;&#26679;&#24615;&#24230;&#37327;&#26631;&#20934;&#26356;&#22909;&#22320;&#25351;&#31034;&#19968;&#20010;&#23545;&#35805;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linguistic pragmatics state that a conversation's underlying speech acts can constrain the type of response which is appropriate at each turn in the conversation. When generating dialogue responses, neural dialogue agents struggle to produce diverse responses. Currently, dialogue diversity is assessed using automatic metrics, but the underlying speech acts do not inform these metrics.  To remedy this, we propose the notion of Pragmatically Appropriate Diversity, defined as the extent to which a conversation creates and constrains the creation of multiple diverse responses. Using a human-created multi-response dataset, we find significant support for the hypothesis that speech acts provide a signal for the diversity of the set of next responses. Building on this result, we propose a new human evaluation task where creative writers predict the extent to which conversations inspire the creation of multiple diverse responses. Our studies find that writers' judgments align with the Pragmati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#39069;&#22806;&#30340;&#26631;&#35760;&#22686;&#24378;&#36755;&#20837;&#65292;&#24341;&#20837;&#24490;&#29615;&#65292;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340; Transformer &#27169;&#22411;&#65288;&#22914; BERT&#65289;&#36827;&#34892;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27861;&#24459;&#25991;&#20214;&#39029;&#38754;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.02787</link><description>&lt;p&gt;
&#27861;&#24459;&#25991;&#20214;&#39029;&#38754;&#30340;&#19978;&#19979;&#25991;&#24863;&#30693;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Context-Aware Classification of Legal Document Pages. (arXiv:2304.02787v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#39069;&#22806;&#30340;&#26631;&#35760;&#22686;&#24378;&#36755;&#20837;&#65292;&#24341;&#20837;&#24490;&#29615;&#65292;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340; Transformer &#27169;&#22411;&#65288;&#22914; BERT&#65289;&#36827;&#34892;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27861;&#24459;&#25991;&#20214;&#39029;&#38754;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#38656;&#35201;&#22788;&#29702;&#12289;&#32034;&#24341;&#21644;&#26816;&#32034;&#19987;&#19994;&#25991;&#26723;&#65288;&#22914; PDF &#26684;&#24335;&#31561;&#65289;&#30340;&#21830;&#19994;&#24212;&#29992;&#65292;&#23558;&#20219;&#20309;&#32473;&#23450;&#25991;&#26723;&#30340;&#39029;&#38754;&#20998;&#31867;&#20026;&#20854;&#30456;&#24212;&#31867;&#22411;&#36890;&#24120;&#26159;&#24517;&#35201;&#30340;&#12290;&#25991;&#26723;&#22270;&#20687;&#20998;&#31867;&#39046;&#22495;&#20013;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#35201;&#20040;&#19987;&#27880;&#20110;&#21333;&#39029;&#25991;&#26723;&#65292;&#35201;&#20040;&#23558;&#25991;&#26723;&#20013;&#30340;&#22810;&#20010;&#39029;&#38754;&#29420;&#31435;&#22788;&#29702;&#12290;&#34429;&#28982;&#36817;&#24180;&#26469;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#25216;&#26415;&#26469;&#21033;&#29992;&#30456;&#37051;&#39029;&#38754;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#26469;&#22686;&#24378;&#25991;&#26723;&#39029;&#38754;&#20998;&#31867;&#65292;&#20294;&#30001;&#20110;&#36755;&#20837;&#38271;&#24230;&#30340;&#38480;&#21046;&#65292;&#23427;&#20204;&#36890;&#24120;&#19981;&#33021;&#19982;&#22823;&#22411;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#19968;&#36215;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20811;&#26381;&#20102;&#19978;&#36848;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#24102;&#26377;&#20851;&#20110;&#21069;&#19968;&#39029;&#30340;&#39034;&#24207;&#20449;&#24687;&#30340;&#39069;&#22806;&#26631;&#35760;&#26469;&#22686;&#24378;&#36755;&#20837;&#65292;&#20174;&#32780;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#36825;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340; Transformer &#27169;&#22411;&#65288;&#22914; BERT&#65289;&#36827;&#34892;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#27861;&#24459;&#25991;&#20214;&#39029;&#38754;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many business applications that require the processing, indexing, and retrieval of professional documents such as legal briefs (in PDF format etc.), it is often essential to classify the pages of any given document into their corresponding types beforehand. Most existing studies in the field of document image classification either focus on single-page documents or treat multiple pages in a document independently. Although in recent years a few techniques have been proposed to exploit the context information from neighboring pages to enhance document page classification, they typically cannot be utilized with large pre-trained language models due to the constraint on input length. In this paper, we present a simple but effective approach that overcomes the above limitation. Specifically, we enhance the input with extra tokens carrying sequential information about previous pages - introducing recurrence - which enables the usage of pre-trained Transformer models like BERT for context
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#22312;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#19968;&#20123;&#26041;&#27861;&#30340;&#25913;&#36827;&#20043;&#22788;&#65292;&#21516;&#26102;&#20063;&#25351;&#20986;&#20102;&#38656;&#35201;&#26356;&#22810;&#21033;&#29992;&#35821;&#35328;&#20559;&#35265;&#21644;&#38750;&#33521;&#35821;&#25991;&#26412;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.02785</link><description>&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#22312;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Performance of Data Augmentation Methods for Brazilian Portuguese Text Classification. (arXiv:2304.02785v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#22312;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#25991;&#26412;&#20998;&#31867;&#20013;&#30340;&#34920;&#29616;&#65292;&#25581;&#31034;&#20102;&#19968;&#20123;&#26041;&#27861;&#30340;&#25913;&#36827;&#20043;&#22788;&#65292;&#21516;&#26102;&#20063;&#25351;&#20986;&#20102;&#38656;&#35201;&#26356;&#22810;&#21033;&#29992;&#35821;&#35328;&#20559;&#35265;&#21644;&#38750;&#33521;&#35821;&#25991;&#26412;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#65292;&#21516;&#26102;&#22686;&#21152;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#19968;&#30452;&#26159;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20154;&#21592;&#19981;&#26029;&#36861;&#27714;&#30340;&#30446;&#26631;&#12290;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#36890;&#24120;&#34987;&#29992;&#20110;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#32780;&#22823;&#22810;&#25968;&#35780;&#20272;&#37117;&#26159;&#20351;&#29992;&#33521;&#35821;&#35821;&#26009;&#24211;&#23436;&#25104;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#19981;&#21516;&#30340;&#29616;&#26377;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#20998;&#26512;&#20854;&#22312;&#20351;&#29992;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#35821;&#26009;&#24211;&#36827;&#34892;&#25991;&#26412;&#20998;&#31867;&#38382;&#39064;&#26102;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;&#20102;&#20854;&#20013;&#26576;&#20123;&#25216;&#26415;&#30340;&#21487;&#34892;&#25913;&#36827;&#65307;&#28982;&#32780;&#65292;&#23427;&#20063;&#34920;&#26126;&#38656;&#35201;&#36827;&#19968;&#27493;&#21033;&#29992;&#35821;&#35328;&#20559;&#35265;&#21644;&#38750;&#33521;&#35821;&#25991;&#26412;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Improving machine learning performance while increasing model generalization has been a constantly pursued goal by AI researchers. Data augmentation techniques are often used towards achieving this target, and most of its evaluation is made using English corpora. In this work, we took advantage of different existing data augmentation methods to analyze their performances applied to text classification problems using Brazilian Portuguese corpora. As a result, our analysis shows some putative improvements in using some of these techniques; however, it also suggests further exploitation of language bias and non-English text data scarcity.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22522;&#20110;Transformer&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#22312;&#30005;&#23376;&#30149;&#21382;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#21644;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2304.02768</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#22312;&#30005;&#23376;&#30149;&#21382;&#20013;&#30340;&#24212;&#29992;&#65306;&#31995;&#32479;&#24615;&#25991;&#29486;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Application of Transformers based methods in Electronic Medical Records: A Systematic Literature Review. (arXiv:2304.02768v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02768
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#22522;&#20110;Transformer&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#22312;&#30005;&#23376;&#30149;&#21382;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30446;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#21644;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#21487;&#29992;&#25968;&#25454;&#30340;&#22686;&#38271;&#21644;&#23427;&#20204;&#30340;&#38750;&#32467;&#26500;&#21270;&#24615;&#36136;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#25216;&#26415;&#24320;&#22987;&#21463;&#21040;&#20851;&#27880;&#65292;&#20197;&#20174;&#36825;&#20123;&#25968;&#25454;&#36164;&#20135;&#20013;&#33719;&#24471;&#20215;&#20540;&#65292;&#22240;&#20026;&#36825;&#31181;&#26684;&#24335;&#19981;&#36866;&#29992;&#20110;&#32479;&#35745;&#20998;&#26512;&#12290;&#26412;&#25991;&#23545;&#19981;&#21516;NLP&#20219;&#21153;&#20013;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;EMR&#19978;&#30340;&#26368;&#26032;&#36827;&#23637;&#36827;&#34892;&#20102;&#31995;&#32479;&#24615;&#30340;&#25991;&#29486;&#32508;&#36848;&#12290;&#22312;&#26368;&#21021;&#30340;&#26597;&#35810;&#20013;&#65292;&#20174;&#19977;&#20010;&#20844;&#20849;&#25968;&#25454;&#24211;&#20013;&#36873;&#25321;&#20102;99&#31687;&#25991;&#31456;&#65292;&#26368;&#32456;&#31579;&#36873;&#24471;&#21040;&#20102;65&#31687;&#25991;&#31456;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#12290;&#26412;&#25991;&#23558;&#20174;&#19994;&#21153;&#38382;&#39064;&#12289;NLP&#20219;&#21153;&#12289;&#27169;&#22411;&#21644;&#25216;&#26415;&#12289;&#25968;&#25454;&#38598;&#30340;&#21487;&#29992;&#24615;&#12289;&#24314;&#27169;&#30340;&#21487;&#37325;&#22797;&#24615;&#12289;&#35821;&#35328;&#21644;&#20132;&#25442;&#26684;&#24335;&#31561;&#26041;&#38754;&#23545;&#36825;&#20123;&#35770;&#25991;&#36827;&#34892;&#20998;&#26512;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#24403;&#21069;&#30740;&#31350;&#30340;&#19968;&#20123;&#23616;&#38480;&#24615;&#20197;&#21450;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
The combined growth of available data and their unstructured nature has received increased interest in natural language processing (NLP) techniques to make value of these data assets since this format is not suitable for statistical analysis. This work presents a systematic literature review of state-of-the-art advances using transformer-based methods on electronic medical records (EMRs) in different NLP tasks. To the best of our knowledge, this work is unique in providing a comprehensive review of research on transformer-based methods for NLP applied to the EMR field. In the initial query, 99 articles were selected from three public databases and filtered into 65 articles for detailed analysis. The papers were analyzed with respect to the business problem, NLP task, models and techniques, availability of datasets, reproducibility of modeling, language, and exchange format. The paper presents some limitations of current research and some recommendations for further research.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#30001;&#27801;&#29305;&#38463;&#25289;&#20271;&#19981;&#21516;&#39046;&#22495;&#30340;&#38463;&#25289;&#20271;&#35821;&#38544;&#31169;&#25919;&#31574;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26681;&#25454;&#20010;&#20154;&#25968;&#25454;&#20445;&#25252;&#27861;&#30340;10&#20010;&#21407;&#21017;&#36827;&#34892;&#20102;&#27880;&#37322;&#12290;&#35813;&#25968;&#25454;&#38598;&#21487;&#29992;&#20110;&#35780;&#20272;&#38544;&#31169;&#25919;&#31574;&#36981;&#23432;&#24615;&#12289;&#34892;&#19994;&#38544;&#31169;&#23454;&#36341;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#24320;&#21457;&#30417;&#27979;&#25968;&#25454;&#20445;&#25252;&#27861;&#35268;&#36981;&#23432;&#24615;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2304.02757</link><description>&lt;p&gt;
&#27801;&#29305;&#38463;&#25289;&#20271;&#38544;&#31169;&#25919;&#31574;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
The Saudi Privacy Policy Dataset. (arXiv:2304.02757v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02757
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#30001;&#27801;&#29305;&#38463;&#25289;&#20271;&#19981;&#21516;&#39046;&#22495;&#30340;&#38463;&#25289;&#20271;&#35821;&#38544;&#31169;&#25919;&#31574;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#65292;&#35813;&#25968;&#25454;&#38598;&#26681;&#25454;&#20010;&#20154;&#25968;&#25454;&#20445;&#25252;&#27861;&#30340;10&#20010;&#21407;&#21017;&#36827;&#34892;&#20102;&#27880;&#37322;&#12290;&#35813;&#25968;&#25454;&#38598;&#21487;&#29992;&#20110;&#35780;&#20272;&#38544;&#31169;&#25919;&#31574;&#36981;&#23432;&#24615;&#12289;&#34892;&#19994;&#38544;&#31169;&#23454;&#36341;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#24320;&#21457;&#30417;&#27979;&#25968;&#25454;&#20445;&#25252;&#27861;&#35268;&#36981;&#23432;&#24615;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#27801;&#29305;&#38544;&#31169;&#25919;&#31574;&#25968;&#25454;&#38598;&#65292;&#36825;&#26159;&#19968;&#20010;&#30001;&#26469;&#33258;&#27801;&#29305;&#38463;&#25289;&#20271;&#19981;&#21516;&#39046;&#22495;&#30340;&#38463;&#25289;&#20271;&#35821;&#38544;&#31169;&#25919;&#31574;&#32452;&#25104;&#30340;&#22810;&#26679;&#21270;&#27719;&#32534;&#65292;&#26681;&#25454;&#20010;&#20154;&#25968;&#25454;&#20445;&#25252;&#27861;&#30340;10&#20010;&#21407;&#21017;&#36827;&#34892;&#20102;&#27880;&#37322;&#65307;&#35813;&#27861;&#35268;&#26088;&#22312;&#19982;&#20840;&#29699;&#26368;&#32508;&#21512;&#30340;&#25968;&#25454;&#27861;&#35268;&#20043;&#19968;&#30340;&#36890;&#29992;&#25968;&#25454;&#20445;&#25252;&#26465;&#20363;&#30456;&#20860;&#23481;&#12290; &#25968;&#25454;&#25910;&#38598;&#33258;&#22810;&#20010;&#26469;&#28304;&#65292;&#21253;&#25324;&#27801;&#29305;&#20013;&#22830;&#38134;&#34892;&#65292;&#27801;&#29305;&#22269;&#23478;&#32852;&#21512;&#24179;&#21488;&#65292;&#20445;&#38505;&#21355;&#29983;&#22996;&#21592;&#20250;&#20197;&#21450;&#20351;&#29992;Google&#21644;&#32500;&#22522;&#30334;&#31185;&#30340;&#19968;&#33324;&#32593;&#31449;&#12290; &#26368;&#32456;&#25968;&#25454;&#38598;&#21253;&#25324;&#26469;&#33258;7&#20010;&#34892;&#19994;&#30340;1,000&#20010;&#32593;&#31449;&#65292;4,638&#34892;&#25991;&#26412;&#65292;775,370&#20010;&#26631;&#35760;&#65292;&#20197;&#21450;8,353 KB&#30340;&#35821;&#26009;&#24211;&#22823;&#23567;&#12290; &#27880;&#37322;&#25968;&#25454;&#38598;&#20026;&#35780;&#20272;&#38544;&#31169;&#25919;&#31574;&#36981;&#20174;&#24615;&#65292;&#34892;&#19994;&#38544;&#31169;&#23454;&#36341;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#24320;&#21457;&#30417;&#27979;&#25968;&#25454;&#20445;&#25252;&#27861;&#35268;&#36981;&#23432;&#24615;&#30340;&#33258;&#21160;&#21270;&#24037;&#20855;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#37325;&#22797;&#21033;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the Saudi Privacy Policy Dataset, a diverse compilation of Arabic privacy policies from various sectors in Saudi Arabia, annotated according to the 10 principles of the Personal Data Protection Law (PDPL); the PDPL was established to be compatible with General Data Protection Regulation (GDPR); one of the most comprehensive data regulations worldwide. Data were collected from multiple sources, including the Saudi Central Bank, the Saudi Arabia National United Platform, the Council of Health Insurance, and general websites using Google and Wikipedia. The final dataset includes 1,000 websites belonging to 7 sectors, 4,638 lines of text, 775,370 tokens, and a corpus size of 8,353 KB. The annotated dataset offers significant reuse potential for assessing privacy policy compliance, benchmarking privacy practices across industries, and developing automated tools for monitoring adherence to data protection regulations. By providing a comprehensive and annotated dataset o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;&#21360;&#23612;&#35821;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#30340;&#21382;&#21490;&#21644;&#21457;&#23637;&#65292;&#21253;&#25324;&#22522;&#30784;&#25216;&#26415;&#12289;&#23454;&#38469;&#24212;&#29992;&#21644;&#25361;&#25112;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#24212;&#35813;&#25299;&#23637;&#26356;&#26377;&#25928;&#29575;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#24182;&#25193;&#22823;NLP&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2304.02746</link><description>&lt;p&gt;
&#21360;&#23612;&#35821;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65288;NLP&#65289;&#30340;&#21382;&#21490;&#21644;&#21457;&#23637;&#65306;&#22522;&#30784;&#25216;&#26415;&#12289;&#26041;&#27861;&#12289;&#23454;&#38469;&#24212;&#29992;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP dalam bahasa Indonesia. (arXiv:2304.02746v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#21360;&#23612;&#35821;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#30340;&#21382;&#21490;&#21644;&#21457;&#23637;&#65292;&#21253;&#25324;&#22522;&#30784;&#25216;&#26415;&#12289;&#23454;&#38469;&#24212;&#29992;&#21644;&#25361;&#25112;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#24212;&#35813;&#25299;&#23637;&#26356;&#26377;&#25928;&#29575;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#24182;&#25193;&#22823;NLP&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27010;&#36848;&#20102;&#21360;&#23612;&#35821;&#29615;&#22659;&#19979;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#21457;&#23637;&#21490;&#65292;&#24182;&#20851;&#27880;&#24050;&#24320;&#21457;&#30340;&#22522;&#30784;&#25216;&#26415;&#12289;&#26041;&#27861;&#21644;&#23454;&#29992;&#24212;&#29992;&#12290;&#32508;&#36848;&#20102;&#22522;&#30784;NLP&#25216;&#26415;&#30340;&#21457;&#23637;&#65292;&#22914;&#35789;&#24178;&#25552;&#21462;&#12289;&#35789;&#24615;&#26631;&#27880;&#21644;&#30456;&#20851;&#26041;&#27861;&#65292;&#20197;&#21450;&#36328;&#35821;&#35328;&#20449;&#24687;&#26816;&#32034;&#12289;&#20449;&#24687;&#25552;&#21462;&#21644;&#24773;&#24863;&#20998;&#26512;&#31561;&#23454;&#38469;&#24212;&#29992;&#65292;&#25506;&#32034;&#20102;&#22312;&#21360;&#23612;&#35821;NLP&#30740;&#31350;&#20013;&#20351;&#29992;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#22914;&#26426;&#22120;&#23398;&#20064;&#12289;&#22522;&#20110;&#32479;&#35745;&#30340;&#26426;&#22120;&#32763;&#35793;&#21644;&#22522;&#20110;&#20914;&#31361;&#30340;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#36824;&#25506;&#35752;&#20102;NLP&#22312;&#21360;&#23612;&#35821;&#20135;&#19994;&#21644;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#30830;&#23450;&#20102;&#21360;&#23612;&#35821;NLP&#30740;&#31350;&#21644;&#21457;&#23637;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#12290;&#26410;&#26469;&#21360;&#23612;&#35821;NLP&#30740;&#31350;&#21644;&#21457;&#23637;&#30340;&#24314;&#35758;&#21253;&#25324;&#24320;&#21457;&#26356;&#26377;&#25928;&#29575;&#30340;&#26041;&#27861;&#21644;&#25216;&#26415;&#65292;&#25193;&#22823;NLP&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study provides an overview of the history of the development of Natural Language Processing (NLP) in the context of the Indonesian language, with a focus on the basic technologies, methods, and practical applications that have been developed. This review covers developments in basic NLP technologies such as stemming, part-of-speech tagging, and related methods; practical applications in cross-language information retrieval systems, information extraction, and sentiment analysis; and methods and techniques used in Indonesian language NLP research, such as machine learning, statistics-based machine translation, and conflict-based approaches. This study also explores the application of NLP in Indonesian language industry and research and identifies challenges and opportunities in Indonesian language NLP research and development. Recommendations for future Indonesian language NLP research and development include developing more efficient methods and technologies, expanding NLP applica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#21322;&#30417;&#30563;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20197;&#23569;&#37327;&#25968;&#25454;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#20551;&#35780;&#35770;&#21644;&#30495;&#23454;&#35780;&#35770;&#30340;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;BanglaBERT&#19982;&#21322;&#30417;&#30563;GAN&#30456;&#32467;&#21512;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20934;&#30830;&#29575;&#36798;&#21040;83.59&#65285;&#65292;f1&#20998;&#25968;&#36798;&#21040;84.89&#65285;&#12290;</title><link>http://arxiv.org/abs/2304.02739</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#30417;&#30563;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26816;&#27979;&#23391;&#21152;&#25289;&#35821;&#20551;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Bengali Fake Review Detection using Semi-supervised Generative Adversarial Networks. (arXiv:2304.02739v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#21322;&#30417;&#30563;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20197;&#23569;&#37327;&#25968;&#25454;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#20551;&#35780;&#35770;&#21644;&#30495;&#23454;&#35780;&#35770;&#30340;&#28508;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;BanglaBERT&#19982;&#21322;&#30417;&#30563;GAN&#30456;&#32467;&#21512;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20934;&#30830;&#29575;&#36798;&#21040;83.59&#65285;&#65292;f1&#20998;&#25968;&#36798;&#21040;84.89&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#21322;&#30417;&#30563;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#23569;&#37327;&#24050;&#27880;&#37322;&#25968;&#25454;&#26469;&#20998;&#31867;&#23391;&#21152;&#25289;&#35821;&#20551;&#35780;&#35770;&#21644;&#30495;&#23454;&#35780;&#35770;&#30340;&#28508;&#21147;&#12290;&#38543;&#30528;&#31038;&#20132;&#23186;&#20307;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#20852;&#36215;&#65292;&#33021;&#22815;&#26816;&#27979;&#34394;&#20551;&#25110;&#27450;&#39575;&#24615;&#35780;&#35770;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#20197;&#20445;&#25252;&#28040;&#36153;&#32773;&#20813;&#21463;&#34394;&#20551;&#20449;&#24687;&#30340;&#35823;&#23548;&#12290;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35782;&#21035;&#20551;&#35780;&#35770;&#26041;&#38754;&#37117;&#20250;&#36935;&#21040;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20687;&#23391;&#21152;&#25289;&#35821;&#36825;&#26679;&#30340;&#20302;&#36164;&#28304;&#35821;&#35328;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#21322;&#30417;&#30563;GAN-LM&#20307;&#31995;&#32467;&#26500;&#65288;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20043;&#19978;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65289;&#26159;&#19968;&#20010;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#21482;&#26377;1024&#20010;&#24050;&#27880;&#37322;&#30340;&#26679;&#26412;&#65292;&#20351;&#29992;&#21322;&#30417;&#30563;GAN&#30340;BanglaBERT&#30340;&#20934;&#30830;&#29575;&#36798;&#21040;83.59&#65285;&#65292;f1&#20998;&#25968;&#36798;&#21040;84.89&#65285;&#65292;&#20248;&#20110;&#20854;&#20182;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;BanglaBERT&#29983;&#25104;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the potential of semi-supervised Generative Adversarial Networks (GANs) to fine-tune pretrained language models in order to classify Bengali fake reviews from real reviews with a few annotated data. With the rise of social media and e-commerce, the ability to detect fake or deceptive reviews is becoming increasingly important in order to protect consumers from being misled by false information. Any machine learning model will have trouble identifying a fake review, especially for a low resource language like Bengali. We have demonstrated that the proposed semi-supervised GAN-LM architecture (generative adversarial network on top of a pretrained language model) is a viable solution in classifying Bengali fake reviews as the experimental results suggest that even with only 1024 annotated samples, BanglaBERT with semi-supervised GAN (SSGAN) achieved an accuracy of 83.59% and a f1-score of 84.89% outperforming other pretrained language models BanglaBERT generator,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#20855;&#36523;&#35270;&#35273;&#35821;&#35328;&#35268;&#21010;&#65288;EVLP&#65289;&#20219;&#21153;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26426;&#20250;&#65292;&#26088;&#22312;&#20849;&#21516;&#21033;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#36827;&#34892;&#29289;&#29702;&#29615;&#22659;&#20132;&#20114;&#12290;</title><link>http://arxiv.org/abs/2304.02738</link><description>&lt;p&gt;
&#20855;&#36523;&#35270;&#35273;&#35821;&#35328;&#35268;&#21010;&#20013;&#30340;&#26680;&#24515;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Core Challenges in Embodied Vision-Language Planning. (arXiv:2304.02738v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#20855;&#36523;&#35270;&#35273;&#35821;&#35328;&#35268;&#21010;&#65288;EVLP&#65289;&#20219;&#21153;&#39046;&#22495;&#30340;&#25361;&#25112;&#21644;&#26426;&#20250;&#65292;&#26088;&#22312;&#20849;&#21516;&#21033;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#36827;&#34892;&#29289;&#29702;&#29615;&#22659;&#20132;&#20114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24335;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24341;&#21457;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#26426;&#22120;&#20154;&#25216;&#26415;&#20132;&#21449;&#39046;&#22495;&#20013;&#30340;&#19968;&#31995;&#21015;&#25361;&#25112;&#24615;&#20219;&#21153;&#12290;&#34429;&#28982;&#35768;&#22810;&#26041;&#27861;&#21644;&#20197;&#21069;&#30340;&#35843;&#26597;&#36861;&#27714;&#24050;&#23558;&#20854;&#20013;&#19968;&#20004;&#20010;&#32500;&#24230;&#36827;&#34892;&#20102;&#25551;&#36848;&#65292;&#20294;&#36824;&#27809;&#26377;&#23545;&#25152;&#26377;&#19977;&#20010;&#32500;&#24230;&#36827;&#34892;&#20840;&#38754;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#32771;&#34385;&#36825;&#20123;&#20027;&#39064;&#30340;&#32452;&#21512;&#65292;&#26356;&#22810;&#30340;&#20851;&#27880;&#28857;&#25918;&#22312;&#25551;&#36848;&#24403;&#21069;&#30340;&#20307;&#31995;&#32467;&#26500;&#26041;&#27861;&#19978;&#65292;&#32780;&#19981;&#26159;&#35828;&#26126;&#35813;&#39046;&#22495;&#30340;&#39640;&#23618;&#27425;&#25361;&#25112;&#21644;&#26426;&#20250;&#12290;&#22312;&#26412;&#27425;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20855;&#36523;&#35270;&#35273;&#35821;&#35328;&#35268;&#21010;&#65288;EVLP&#65289;&#20219;&#21153;&#65292;&#36825;&#26159;&#19968;&#31995;&#21015;&#37325;&#35201;&#30340;&#20855;&#36523;&#23548;&#33322;&#21644;&#25805;&#20316;&#38382;&#39064;&#65292;&#20849;&#21516;&#21033;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#36827;&#34892;&#29289;&#29702;&#29615;&#22659;&#20132;&#20114;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#31867;&#27861;&#26469;&#32479;&#19968;&#36825;&#20123;&#20219;&#21153;&#65292;&#24182;&#23545;&#24403;&#21069;&#30340;&#21644;&#26032;&#30340;&#31639;&#27861;&#24212;&#29992;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#21644;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in the areas of Multimodal Machine Learning and Artificial Intelligence (AI) have led to the development of challenging tasks at the intersection of Computer Vision, Natural Language Processing, and Robotics. Whereas many approaches and previous survey pursuits have characterised one or two of these dimensions, there has not been a holistic analysis at the center of all three. Moreover, even when combinations of these topics are considered, more focus is placed on describing, e.g., current architectural methods, as opposed to also illustrating high-level challenges and opportunities for the field. In this survey paper, we discuss Embodied Vision-Language Planning (EVLP) tasks, a family of prominent embodied navigation and manipulation problems that jointly leverage computer vision and natural language for interaction in physical environments. We propose a taxonomy to unify these tasks and provide an in-depth analysis and comparison of the current and new algorithmic app
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#22823;&#23567;&#12289;&#32467;&#26500;&#21270;&#21098;&#26525;&#12289;&#25512;&#26029;&#25928;&#29575;&#21644;&#25688;&#35201;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20351;&#29992;&#19981;&#23545;&#31216;&#21098;&#26525;&#21487;&#22312;&#19981;&#22823;&#25439;&#22833;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#39640;&#25512;&#26029;&#25928;&#29575;&#32422;3&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.02721</link><description>&lt;p&gt;
&#36229;&#36234;&#19981;&#23545;&#31216;&#24615;&#65306;&#32467;&#26500;&#21098;&#26525;&#25552;&#39640;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#30340;&#25512;&#26029;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency. (arXiv:2304.02721v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#22823;&#23567;&#12289;&#32467;&#26500;&#21270;&#21098;&#26525;&#12289;&#25512;&#26029;&#25928;&#29575;&#21644;&#25688;&#35201;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#20351;&#29992;&#19981;&#23545;&#31216;&#21098;&#26525;&#21487;&#22312;&#19981;&#22823;&#25439;&#22833;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#39640;&#25512;&#26029;&#25928;&#29575;&#32422;3&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#21040;&#24207;&#21015;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#29983;&#25104;&#36830;&#36143;&#65292;&#30456;&#20851;&#21644;&#31616;&#27905;&#30340;&#25277;&#35937;&#25688;&#35201;&#12290;&#20294;&#26159;&#65292;&#27169;&#22411;&#22823;&#23567;&#21487;&#33021;&#20351;&#24471;&#22312;&#24310;&#36831;&#25935;&#24863;&#25110; Web &#35268;&#27169;&#30340;&#23454;&#29616;&#20013;&#37096;&#32626;&#21464;&#24471;&#22256;&#38590;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#22823;&#23567;&#12289;&#32467;&#26500;&#21270;&#21098;&#26525;&#12289;&#25512;&#26029;&#25928;&#29575;&#21644;&#24191;&#27867;&#20351;&#29992;&#30340;&#25688;&#35201;&#25968;&#25454;&#38598;&#19978;&#30340;&#25688;&#35201;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#27169;&#22411;&#20934;&#30830;&#24615;&#19982;&#32534;&#30721;&#22120;&#22823;&#23567;&#26377;&#20851;&#65292;&#32780;&#25512;&#29702;&#25928;&#29575;&#19982;&#35299;&#30721;&#22120;&#26377;&#20851;&#12290;&#20351;&#29992;&#19981;&#23545;&#31216;&#21098;&#26525;&#21487;&#23548;&#33268;&#25512;&#26029;&#24310;&#36831;&#30340;&#36817;3&#20493;&#25552;&#39640;&#65292;Rouge-2&#30340;&#25439;&#22833;&#32422;&#20026;1&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#24179;&#22343;&#24615;&#33021;&#38477;&#20302;&#21644;&#19981;&#23545;&#31216;&#24615;&#30340;&#20316;&#29992;&#22312;&#27169;&#22411;&#22823;&#23567;&#21644;&#25968;&#25454;&#38598;&#21464;&#21270;&#26041;&#38754;&#26159;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequence-to-sequence language models can be used to produce abstractive summaries which are coherent, relevant, and concise. Still, model sizes can make deployment in latency-sensitive or web-scale implementations difficult. This paper studies the relationship between model size, structured pruning, inference efficiency, and summarization accuracy on widely used summarization datasets. We show that model accuracy is tied to the encoder size while inference efficiency is connected to the decoder. Using asymmetric pruning can lead to nearly 3x improvement in inference latency with ~1 point loss in Rouge-2. Moreover, we find both the average degradation and the role of asymmetry to be consistent across model sizes and variations in datasets.
&lt;/p&gt;</description></item><item><title>ParroT&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24320;&#28304;LLM&#21644;&#20154;&#24037;&#32534;&#20889;&#30340;&#32763;&#35793;&#35780;&#20272;&#25968;&#25454;&#30340;&#32842;&#22825;&#32763;&#35793;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#32763;&#35793;&#25968;&#25454;&#36716;&#21270;&#20026;&#25351;&#20196;&#25191;&#34892;&#26679;&#24335;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#35201;&#27714;&#26469;&#35268;&#33539;&#32763;&#35793;&#36807;&#31243;&#12290;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126; ParroT &#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.02426</link><description>&lt;p&gt;
ParroT: &#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32842;&#22825;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
ParroT: Translating During Chat Using Large Language Models. (arXiv:2304.02426v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02426
&lt;/p&gt;
&lt;p&gt;
ParroT&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24320;&#28304;LLM&#21644;&#20154;&#24037;&#32534;&#20889;&#30340;&#32763;&#35793;&#35780;&#20272;&#25968;&#25454;&#30340;&#32842;&#22825;&#32763;&#35793;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#32763;&#35793;&#25968;&#25454;&#36716;&#21270;&#20026;&#25351;&#20196;&#25191;&#34892;&#26679;&#24335;&#65292;&#24182;&#24341;&#20837;&#39069;&#22806;&#35201;&#27714;&#26469;&#35268;&#33539;&#32763;&#35793;&#36807;&#31243;&#12290;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126; ParroT &#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#22914; ChatGPT &#21644; GPT-4 &#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#19978;&#23637;&#29616;&#20986;&#20102;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#21253;&#25324;&#22312;&#32842;&#22825;&#36807;&#31243;&#20013;&#23436;&#25104;&#21508;&#31181;&#26426;&#22120;&#32763;&#35793;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#21482;&#33021;&#36890;&#36807;&#21463;&#38480;&#30340;API&#35775;&#38382;&#65292;&#36825;&#20026;&#26032;&#30340;&#30740;&#31350;&#21644;&#39046;&#22495;&#36827;&#23637;&#24102;&#26469;&#20102;&#38556;&#30861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; ParroT &#26694;&#26550;&#65292;&#22522;&#20110;&#24320;&#28304;LLM&#65288;&#22914;LLaMA-7b&#65289;&#21644;&#20154;&#24037;&#32534;&#20889;&#30340;&#32763;&#35793;&#35780;&#20272;&#25968;&#25454;&#26469;&#22686;&#24378;&#21644;&#35268;&#33539;&#32842;&#22825;&#32763;&#35793;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;ParroT&#23558;&#32763;&#35793;&#25968;&#25454;&#36716;&#21270;&#20026;&#25351;&#20196;&#25191;&#34892;&#30340;&#26679;&#24335;&#65292;&#24182;&#24341;&#20837; "Hint " &#23383;&#27573;&#20197;&#21152;&#20837;&#39069;&#22806;&#35201;&#27714;&#26469;&#35268;&#33539;&#32763;&#35793;&#36807;&#31243;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#25351;&#20196;&#31867;&#22411;&#26469;&#24494;&#35843; ParroT &#27169;&#22411;&#65292;&#21253;&#25324;&#32763;&#35793;&#25351;&#20196;&#12289;&#23545;&#27604;&#25351;&#20196;&#21644;&#35823;&#24046;&#24341;&#23548;&#25351;&#20196;&#12290;&#22312;&#20004;&#20010; Flores &#23376;&#38598;&#21644; WMT22 &#27979;&#35797;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992; ParroT &#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#32763;&#35793;&#36136;&#37327;&#65292;&#19988;&#38656;&#35201;&#30456;&#23545;&#36739;&#23569;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) like ChatGPT and GPT-4 have exhibited remarkable abilities on a wide range of natural language processing (NLP) tasks, including various machine translation abilities accomplished during chat. However, these models are only accessible through restricted APIs, which creates barriers to new research and advancements in the field. Therefore, we propose the $\mathbf{ParroT}$ framework to enhance and regulate the translation abilities during chat based on open-sourced LLMs (i.e., LLaMA-7b) and human written translation and evaluation data. Specifically, ParroT reformulates translation data into the instruction-following style, and introduces a "Hint" field for incorporating extra requirements to regulate the translation process. Accordingly, we propose three instruction types for finetuning ParroT models, including translation instruction, contrastive instruction, and error-guided instruction. Experiments on two Flores subsets and WMT22 test sets suggest that tr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#8212;&#8212;&#32467;&#26500;&#21270;&#20449;&#24687;&#25512;&#29702;&#65288;SIS&#65289;&#65292;&#21033;&#29992;GPT-3&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#25552;&#21462;&#26448;&#26009;&#31185;&#23398;&#35774;&#22791;&#23618;&#38754;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39044;&#27979;PCE&#21644;&#21453;&#21521;&#39044;&#27979;&#21442;&#25968;&#65292;&#23637;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26448;&#26009;&#23398;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.02213</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#38053;&#21273;&#65306;&#29992;GPT&#35299;&#23494;&#26448;&#26009;&#31185;&#23398;&#30340;&#31192;&#23494;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#8212;&#8212;&#32467;&#26500;&#21270;&#20449;&#24687;&#25512;&#29702;&#65288;SIS&#65289;&#65292;&#21033;&#29992;GPT-3&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#25552;&#21462;&#26448;&#26009;&#31185;&#23398;&#35774;&#22791;&#23618;&#38754;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39044;&#27979;PCE&#21644;&#21453;&#21521;&#39044;&#27979;&#21442;&#25968;&#65292;&#23637;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#26448;&#26009;&#23398;&#20013;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20219;&#21153;&#8212;&#8212;&#32467;&#26500;&#21270;&#20449;&#24687;&#25512;&#29702;&#65288;SIS&#65289;&#65292;&#20197;&#35299;&#20915;&#26448;&#26009;&#31185;&#23398;&#35774;&#22791;&#23618;&#38754;&#20449;&#24687;&#25552;&#21462;&#30340;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#29616;&#26377;&#30340;&#38041;&#38043;&#30719;&#22826;&#38451;&#33021;&#30005;&#27744;FAIR&#25968;&#25454;&#38598;&#23545;GPT-3&#36827;&#34892;&#24494;&#35843;&#65292;&#33719;&#24471;&#20102;91.8 F1&#24471;&#20998;&#65292;&#24182;&#26356;&#26032;&#20102;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#36804;&#20170;&#20026;&#27490;&#25152;&#26377;&#30456;&#20851;&#31185;&#23398;&#35770;&#25991;&#12290;&#25152;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#24050;&#34987;&#26684;&#24335;&#21270;&#21644;&#26631;&#20934;&#21270;&#65292;&#20351;&#24471;&#23427;&#21487;&#20197;&#30452;&#25509;&#20316;&#20026;&#21518;&#32493;&#25968;&#25454;&#20998;&#26512;&#30340;&#36755;&#20837;&#12290;&#36825;&#20010;&#29305;&#24615;&#23558;&#20351;&#26448;&#26009;&#31185;&#23398;&#23478;&#36890;&#36807;&#36873;&#25321;&#39640;&#36136;&#37327;&#30340;&#39046;&#22495;&#35780;&#35770;&#25991;&#31456;&#26469;&#24320;&#21457;&#20854;&#33258;&#24049;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23454;&#39564;&#26469;&#39044;&#27979;PCE&#21644;&#21453;&#21521;&#39044;&#27979;&#21442;&#25968;&#65292;&#24182;&#33719;&#24471;&#20102;&#19982;DFT&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#36825;&#35777;&#26126;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#22815;&#20687;&#26448;&#26009;&#23398;&#23478;&#19968;&#26679;&#35780;&#21028;&#26448;&#26009;&#21644;&#35774;&#35745;&#26032;&#26448;&#26009;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a new NLP task called structured information inference (SIS) to address the complexities of information extraction at the device level in materials science. We accomplished this task by finetuning GPT-3 on a exsiting perovskite solar cell FAIR dataset with 91.8 F1-score and we updated the dataset with all related scientific papers up to now. The produced dataset is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. This feature will enable materials scientists to develop their own models by selecting high-quality review papers within their domain. Furthermore, we designed experiments to predict PCE and reverse-predict parameters and obtained comparable performance with DFT, which demonstrates the potential of large language models to judge materials and design new materials like a materials scientist.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;ChatGPT&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#12289;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#65292;&#24378;&#35843;&#20102;&#20351;&#29992;&#36825;&#20010;&#24378;&#22823;&#24037;&#20855;&#26102;&#30340;&#36947;&#24503;&#32771;&#34385;&#65292;&#20026;&#20154;&#24037;&#26234;&#33021;&#21644;NLP&#39046;&#22495;&#30340;&#35752;&#35770;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2304.02017</link><description>&lt;p&gt;
&#35299;&#38145;ChatGPT&#30340;&#28508;&#21147;&#65306;&#23545;&#20854;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#24212;&#29992;&#12289;&#20248;&#28857;&#12289;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#26041;&#21521;&#30340;&#20840;&#38754;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing. (arXiv:2304.02017v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;ChatGPT&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#24212;&#29992;&#12289;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#65292;&#24378;&#35843;&#20102;&#20351;&#29992;&#36825;&#20010;&#24378;&#22823;&#24037;&#20855;&#26102;&#30340;&#36947;&#24503;&#32771;&#34385;&#65292;&#20026;&#20154;&#24037;&#26234;&#33021;&#21644;NLP&#39046;&#22495;&#30340;&#35752;&#35770;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ChatGPT&#26159;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20013;&#24191;&#27867;&#24212;&#29992;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#32842;&#22825;&#26426;&#22120;&#20154;&#12289;&#20869;&#23481;&#29983;&#25104;&#12289;&#35821;&#35328;&#32763;&#35793;&#12289;&#20010;&#24615;&#21270;&#25512;&#33616;&#21644;&#21307;&#30103;&#35786;&#26029;&#27835;&#30103;&#12290;&#23427;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#20934;&#30830;&#24615;&#20351;&#20854;&#25104;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#20294;&#26159;&#65292;ChatGPT&#20063;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#20363;&#22914;&#20854;&#20542;&#21521;&#20110;&#20135;&#29983;&#26377;&#20559;&#35265;&#30340;&#21709;&#24212;&#20197;&#21450;&#23384;&#22312;&#28508;&#22312;&#30340;&#26377;&#23475;&#35821;&#35328;&#27169;&#24335;&#12290;&#26412;&#25991;&#20840;&#38754;&#27010;&#36848;&#20102;ChatGPT&#21450;&#20854;&#24212;&#29992;&#12289;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#24378;&#35843;&#20102;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#20351;&#29992;&#36825;&#20010;&#24378;&#22823;&#24037;&#20855;&#26102;&#36947;&#24503;&#32771;&#34385;&#30340;&#37325;&#35201;&#24615;&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#25552;&#31034;&#24037;&#31243;&#25216;&#26415;&#30340;&#35265;&#35299;&#65292;&#20026;&#20851;&#20110;&#20154;&#24037;&#26234;&#33021;&#21450;&#20854;&#23545;&#35270;&#35273;&#21644;NLP&#39046;&#22495;&#30340;&#24433;&#21709;&#30340;&#25345;&#32493;&#35752;&#35770;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
ChatGPT is a powerful tool in the field of artificial intelligence that has been widely used in various applications. ChatGPT has been applied successfully in chatbots, content generation, language translation, personalized recommendations, and medical diagnosis and treatment. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#37325;&#25490;&#30340;&#37327;&#21270;&#26041;&#27861;RPTQ&#65292;&#30446;&#30340;&#26159;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37327;&#21270;&#26102;&#30001;&#20110;&#20449;&#36947;&#28608;&#27963;&#33539;&#22260;&#19981;&#21516;&#32780;&#20135;&#29983;&#30340;&#38382;&#39064;&#12290;&#23454;&#29616;&#35813;&#26041;&#27861;&#21518;&#65292;&#25105;&#20204;&#23558;LLL&#27169;&#22411;&#25512;&#21160;&#21040;3&#20301;&#28608;&#27963;&#12290;</title><link>http://arxiv.org/abs/2304.01089</link><description>&lt;p&gt;
&#22522;&#20110;&#37325;&#25490;&#30340;&#21518;&#35757;&#32451;&#37327;&#21270;&#26041;&#27861;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
RPTQ: Reorder-based Post-training Quantization for Large Language Models. (arXiv:2304.01089v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#37325;&#25490;&#30340;&#37327;&#21270;&#26041;&#27861;RPTQ&#65292;&#30446;&#30340;&#26159;&#35299;&#20915;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#37327;&#21270;&#26102;&#30001;&#20110;&#20449;&#36947;&#28608;&#27963;&#33539;&#22260;&#19981;&#21516;&#32780;&#20135;&#29983;&#30340;&#38382;&#39064;&#12290;&#23454;&#29616;&#35813;&#26041;&#27861;&#21518;&#65292;&#25105;&#20204;&#23558;LLL&#27169;&#22411;&#25512;&#21160;&#21040;3&#20301;&#28608;&#27963;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#30001;&#20110;&#20854;&#24040;&#22823;&#30340;&#27169;&#22411;&#22823;&#23567;&#32780;&#24341;&#21457;&#30340;&#37096;&#32626;&#25361;&#25112;&#12290;&#26412;&#25991;&#25351;&#20986;&#65292;LLL&#27169;&#22411;&#37327;&#21270;&#30340;&#20027;&#35201;&#38590;&#28857;&#22312;&#20110;&#20449;&#36947;&#20043;&#38388;&#19981;&#21516;&#30340;&#28608;&#27963;&#33539;&#22260;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#31163;&#32676;&#20540;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#37325;&#25490;&#30340;&#37327;&#21270;&#26041;&#27861;RPTQ&#65292;&#29992;&#20110;&#35299;&#20915;LLL&#27169;&#22411;&#37327;&#21270;&#38382;&#39064;&#12290;RPTQ&#36890;&#36807;&#37325;&#26032;&#25490;&#21015;&#28608;&#27963;&#20013;&#30340;&#20449;&#36947;&#65292;&#24182;&#25353;&#31751;&#37327;&#21270;&#20449;&#36947;&#65292;&#20174;&#32780;&#20943;&#23569;&#20449;&#36947;&#33539;&#22260;&#24046;&#24322;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#36991;&#20813;&#26174;&#24335;&#37325;&#25490;&#20943;&#23569;&#23384;&#20648;&#21644;&#35745;&#31639;&#24320;&#38144;&#12290;&#23454;&#29616;&#20102;&#35813;&#26041;&#27861;&#21518;&#65292;&#25105;&#20204;&#39318;&#27425;&#23558;LLL&#27169;&#22411;&#25512;&#21160;&#21040;3&#20301;&#28608;&#27963;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale language models (LLMs) have demonstrated outstanding performance on various tasks, but their deployment poses challenges due to their enormous model size. In this paper, we identify that the main challenge in quantizing LLMs stems from the different activation ranges between the channels, rather than just the issue of outliers.We propose a novel reorder-based quantization approach, RPTQ, that addresses the issue of quantizing the activations of LLMs. RPTQ rearranges the channels in the activations and then quantizing them in clusters, thereby reducing the impact of range difference of channels. In addition, we reduce the storage and computation overhead by avoiding explicit reordering. By implementing this approach, we achieved a significant breakthrough by pushing LLM models to 3 bit activation for the first time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;ViewRefer&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#35270;&#35282;&#30340;&#19977;&#32500;&#35270;&#35273;&#23450;&#20301;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#21644;&#22810;&#35270;&#35282;&#21407;&#22411;&#65292;&#20174;&#25991;&#26412;&#21644;3D&#27169;&#24577;&#20013;&#33719;&#21462;&#35270;&#35282;&#30693;&#35782;&#24182;&#22686;&#24378;&#26694;&#26550;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.16894</link><description>&lt;p&gt;
ViewRefer: &#22522;&#20110;GPT&#21644;&#26679;&#20363;&#24341;&#23548;&#30340;&#22810;&#35270;&#35282;&#30693;&#35782;&#22788;&#29702;&#30340;&#19977;&#32500;&#35270;&#35273;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance. (arXiv:2303.16894v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;ViewRefer&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#35270;&#35282;&#30340;&#19977;&#32500;&#35270;&#35273;&#23450;&#20301;&#26694;&#26550;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#21644;&#22810;&#35270;&#35282;&#21407;&#22411;&#65292;&#20174;&#25991;&#26412;&#21644;3D&#27169;&#24577;&#20013;&#33719;&#21462;&#35270;&#35282;&#30693;&#35782;&#24182;&#22686;&#24378;&#26694;&#26550;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#22810;&#35270;&#35282;&#36755;&#20837;&#30340;3D&#22330;&#26223;&#65292;&#21487;&#20197;&#32531;&#35299;3D&#35270;&#35273;&#23450;&#20301;&#20013;&#30340;&#35270;&#35282;&#24046;&#24322;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#24573;&#30053;&#20102;&#23884;&#20837;&#22312;&#25991;&#26412;&#27169;&#24577;&#20013;&#30340;&#35270;&#35282;&#32447;&#32034;&#65292;&#24182;&#19988;&#26410;&#33021;&#26435;&#34913;&#19981;&#21516;&#35270;&#22270;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ViewRefer&#65292;&#36825;&#26159;&#19968;&#20010;&#22810;&#35270;&#35282;&#30340;&#19977;&#32500;&#35270;&#35273;&#23450;&#20301;&#26694;&#26550;&#65292;&#25506;&#32034;&#22914;&#20309;&#20174;&#25991;&#26412;&#21644;3D&#27169;&#24577;&#20013;&#33719;&#21462;&#35270;&#35282;&#30693;&#35782;&#12290;&#20854;&#20013;&#65292;ViewRefer&#21033;&#29992;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;&#20363;&#22914;GPT&#65289;&#30340;&#22810;&#26679;&#21270;&#35821;&#35328;&#30693;&#35782;&#65292;&#23558;&#21333;&#19968;&#30340;&#23450;&#20301;&#25991;&#26412;&#25193;&#23637;&#20026;&#22810;&#20010;&#20960;&#20309;&#19968;&#33268;&#30340;&#25551;&#36848;&#65307;&#21516;&#26102;&#65292;&#22312;3D&#27169;&#24577;&#20013;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;Transformer&#30340;&#34701;&#21512;&#27169;&#22359;&#21644;&#35270;&#22270;&#38388;&#27880;&#24847;&#21147;&#65292;&#20197;&#22686;&#24378;&#35270;&#22270;&#20043;&#38388;&#29289;&#20307;&#30340;&#20132;&#20114;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#19968;&#32452;&#21487;&#23398;&#20064;&#30340;&#22810;&#35270;&#35282;&#21407;&#22411;&#65292;&#29992;&#20110;&#35760;&#24518;&#19981;&#21516;&#35270;&#35282;&#19979;&#30340;&#22330;&#26223;&#26080;&#20851;&#30693;&#35782;&#65292;&#20174;&#20004;&#20010;&#26041;&#38754;&#22686;&#24378;&#20102;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding 3D scenes from multi-view inputs has been proven to alleviate the view discrepancy issue in 3D visual grounding. However, existing methods normally neglect the view cues embedded in the text modality and fail to weigh the relative importance of different views. In this paper, we propose ViewRefer, a multi-view framework for 3D visual grounding exploring how to grasp the view knowledge from both text and 3D modalities. For the text branch, ViewRefer leverages the diverse linguistic knowledge of large-scale language models, e.g., GPT, to expand a single grounding text to multiple geometry-consistent descriptions. Meanwhile, in the 3D modality, a transformer fusion module with inter-view attention is introduced to boost the interaction of objects across views. On top of that, we further present a set of learnable multi-view prototypes, which memorize scene-agnostic knowledge for different views, and enhance the framework from two perspectives: a view-guided attention module 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20219;&#21153;&#30340;&#21098;&#26525;&#36866;&#37197;&#22120;&#26041;&#27861;&#65292;&#26082;&#23454;&#29616;&#20102;&#35757;&#32451;&#21644;&#20869;&#23384;&#30340;&#39640;&#25928;&#29575;&#65292;&#21448;&#21152;&#24555;&#20102;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#19988;&#22312; GLUE &#20219;&#21153;&#20013;&#27809;&#26377;&#26174;&#33879;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14704</link><description>&lt;p&gt;
&#38754;&#21521;&#20219;&#21153;&#30340;&#20869;&#23384;&#39640;&#25928;&#21098;&#26525;&#36866;&#37197;&#22120;
&lt;/p&gt;
&lt;p&gt;
Task-oriented Memory-efficient Pruning-Adapter. (arXiv:2303.14704v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14704
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20219;&#21153;&#30340;&#21098;&#26525;&#36866;&#37197;&#22120;&#26041;&#27861;&#65292;&#26082;&#23454;&#29616;&#20102;&#35757;&#32451;&#21644;&#20869;&#23384;&#30340;&#39640;&#25928;&#29575;&#65292;&#21448;&#21152;&#24555;&#20102;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#19988;&#22312; GLUE &#20219;&#21153;&#20013;&#27809;&#26377;&#26174;&#33879;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#33394;&#24615;&#33021;&#21644;&#19981;&#26029;&#22686;&#38271;&#30340;&#35268;&#27169;&#23548;&#33268;&#20102;&#23545;&#21442;&#25968;&#39640;&#25928;&#23398;&#20064;&#30340; increased attention&#12290;&#20027;&#35201;&#30340;&#20004;&#31181;&#26041;&#27861;&#26159;&#36866;&#37197;&#22120;&#21644;&#21098;&#26525;&#12290;&#36866;&#37197;&#22120;&#26159;&#22312;&#27169;&#22411;&#19978;&#20923;&#32467;&#24182;&#32473;&#23427;&#19968;&#20010;&#26032;&#30340;&#26435;&#37325;&#30697;&#38453;&#65292;&#22312;&#35757;&#32451;&#26102;&#38388;&#21644;&#20869;&#23384;&#26041;&#38754;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#25104;&#26412;&#65292;&#20294;&#36825;&#26679;&#20250;&#22686;&#21152;&#35780;&#20272;&#21644;&#27979;&#35797;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#28040;&#32791;&#12290;&#21098;&#26525;&#26159;&#25130;&#26029;&#19968;&#20123;&#26435;&#37325;&#24182;&#37325;&#26032;&#20998;&#37197;&#21097;&#20313;&#30340;&#26435;&#37325;&#65292;&#36825;&#26679;&#21487;&#20197;&#29306;&#29298;&#35757;&#32451;&#30340;&#22797;&#26434;&#24230;&#65292;&#20197;&#26497;&#39640;&#30340;&#20869;&#23384;&#21644;&#35757;&#32451;&#26102;&#38388;&#20026;&#20195;&#20215;&#65292;&#20351;&#35780;&#20272;&#21644;&#27979;&#35797;&#30340;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#12290;&#22240;&#27492;&#65292;&#35757;&#32451;&#21644;&#25512;&#29702;&#30340;&#25928;&#29575;&#26080;&#27861;&#21516;&#26102;&#24471;&#21040;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20219;&#21153;&#30340;&#21098;&#26525;&#36866;&#37197;&#22120;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#21644;&#20869;&#23384;&#30340;&#39640;&#20869;&#23384;&#25928;&#29575;&#65292;&#21152;&#24555;&#20102;&#35757;&#32451;&#26102;&#38388;&#65292;&#24182;&#30830;&#20445;&#22312; GLUE &#20219;&#21153;&#20013;&#20934;&#30830;&#24615;&#27809;&#26377;&#26174;&#33879;&#19979;&#38477;&#65292;&#23454;&#29616;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Outstanding performance and growing size of Large Language Models has led to increased attention in parameter efficient learning. The two predominant approaches are Adapters and Pruning. Adapters are to freeze the model and give it a new weight matrix on the side, which can significantly reduce the time and memory of training, but the cost is that the evaluation and testing will increase the time and memory consumption. Pruning is to cut off some weight and re-distribute the remaining weight, which sacrifices the complexity of training at the cost of extremely high memory and training time, making the cost of evaluation and testing relatively low. So efficiency of training and inference can't be obtained in the same time. In this work, we propose a task-oriented Pruning-Adapter method that achieve a high memory efficiency of training and memory, and speeds up training time and ensures no significant decrease in accuracy in GLUE tasks, achieving training and inference efficiency at 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27531;&#24046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#21487;&#36870;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#19982;&#20854;&#20182;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#22238;&#24402;&#30340;&#36755;&#20986;&#23618;&#37325;&#24314;&#36755;&#20837;&#24207;&#21015;&#30340;&#21333;&#35789;&#21521;&#37327;&#65292;&#20854;&#20855;&#26377;&#39640;&#20934;&#30830;&#24230;&#21644;&#24555;&#36895;&#35757;&#32451;&#36895;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#21512;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#23545;&#38656;&#35201;&#39640;&#36136;&#37327;&#21477;&#23884;&#20837;&#30340;&#31070;&#32463;&#32593;&#32476;&#31995;&#32479;&#30340;&#20351;&#29992;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.13570</link><description>&lt;p&gt;
RNN &#30340;&#22238;&#24402;&#65306;&#29992;&#21487;&#36870;&#21477;&#23884;&#20837;&#30340;&#27531;&#24046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Return of the RNN: Residual Recurrent Networks for Invertible Sentence Embeddings. (arXiv:2303.13570v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27531;&#24046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#21487;&#36870;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#19982;&#20854;&#20182;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#19981;&#21516;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#22238;&#24402;&#30340;&#36755;&#20986;&#23618;&#37325;&#24314;&#36755;&#20837;&#24207;&#21015;&#30340;&#21333;&#35789;&#21521;&#37327;&#65292;&#20854;&#20855;&#26377;&#39640;&#20934;&#30830;&#24230;&#21644;&#24555;&#36895;&#35757;&#32451;&#36895;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#21512;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#23545;&#38656;&#35201;&#39640;&#36136;&#37327;&#21477;&#23884;&#20837;&#30340;&#31070;&#32463;&#32593;&#32476;&#31995;&#32479;&#30340;&#20351;&#29992;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#27169;&#22411;&#65292;&#20351;&#29992;&#27531;&#24046;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#30417;&#30563;&#32534;&#30721;&#20219;&#21153;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#29983;&#25104;&#21487;&#36870;&#30340;&#21477;&#23376;&#23884;&#20837;&#12290;&#30456;&#27604;&#20110;&#31070;&#32463;&#26426;&#22120;&#32763;&#35793;&#27169;&#22411;&#20013;&#24120;&#35265;&#30340;&#27010;&#29575;&#36755;&#20986;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#22522;&#20110;&#22238;&#24402;&#30340;&#36755;&#20986;&#23618;&#26469;&#37325;&#24314;&#36755;&#20837;&#24207;&#21015;&#30340;&#21333;&#35789;&#21521;&#37327;&#12290;&#35813;&#27169;&#22411;&#22312;&#20351;&#29992; ADAM &#20248;&#21270;&#22120;&#36827;&#34892;&#24555;&#36895;&#35757;&#32451;&#30340;&#21516;&#26102;&#65292;&#21462;&#24471;&#20102;&#39640;&#20934;&#30830;&#24230;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#27531;&#24046;&#36830;&#25509;&#21644;&#8220;match drop&#8221;&#25216;&#26415;&#65292;&#21363;&#21482;&#35745;&#31639;&#38169;&#35823;&#21333;&#35789;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#28508;&#22312;&#20248;&#21183;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#39640;&#36136;&#37327;&#21477;&#23884;&#20837;&#30340;&#31070;&#32463;&#32593;&#32476;&#31995;&#32479;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study presents a novel model for invertible sentence embeddings using a residual recurrent network trained on an unsupervised encoding task. Rather than the probabilistic outputs common to neural machine translation models, our approach employs a regression-based output layer to reconstruct the input sequence's word vectors. The model achieves high accuracy and fast training with the ADAM optimizer, a significant finding given that RNNs typically require memory units, such as LSTMs, or second-order optimization methods. We incorporate residual connections and introduce a "match drop" technique, where gradients are calculated only for incorrect words. Our approach demonstrates potential for various natural language processing applications, particularly in neural network-based systems that require high-quality sentence embeddings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#25191;&#34892;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;&#65292;&#24182;&#25104;&#21151;&#25552;&#39640;&#20102;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2302.14229</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#25191;&#34892;&#38646;&#26679;&#26412;&#36328;&#35821;&#35328;&#25688;&#35201;&#65292;&#24182;&#25104;&#21151;&#25552;&#39640;&#20102;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#20854;&#20013;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#28304;&#35821;&#35328;&#25991;&#26412;&#65292;&#36328;&#35821;&#35328;&#25688;&#35201;&#65288;CLS&#65289;&#26088;&#22312;&#29983;&#25104;&#21478;&#19968;&#31181;&#30446;&#26631;&#35821;&#35328;&#30340;&#25688;&#35201;&#12290;&#26368;&#36817;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#20986;&#29616;&#65292;&#27604;&#22914;GPT-3.5&#12289;ChatGPT&#21644;GPT-4&#65292;&#24341;&#36215;&#20102;&#35745;&#31639;&#35821;&#35328;&#23398;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;LLM&#22312;CLS&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;&#12290;&#26412;&#25991;&#23454;&#39564;&#24615;&#22320;&#20351;&#29992;&#21508;&#31181;&#25552;&#31034;&#26469;&#25351;&#23548;LLM&#20174;&#19981;&#21516;&#30340;&#33539;&#24335;&#65288;&#21363;&#31471;&#21040;&#31471;&#21644;&#27969;&#27700;&#32447;&#65289;&#25191;&#34892;&#38646;&#26679;&#26412;CLS&#65292;&#24182;&#23545;&#29983;&#25104;&#30340;&#25688;&#35201;&#36827;&#34892;&#21021;&#27493;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;ChatGPT&#21644;GPT-4&#21407;&#26412;&#26356;&#21916;&#27426;&#29983;&#25104;&#35814;&#32454;&#20449;&#24687;&#30340;&#38271;&#25688;&#35201;&#12290;&#20294;&#36825;&#20004;&#20010;LLM&#22312;&#20132;&#20114;&#24335;&#25552;&#31034;&#30340;&#24110;&#21161;&#19979;&#21487;&#20197;&#36827;&#19968;&#27493;&#24179;&#34913;&#20449;&#24687;&#37327;&#21644;&#31616;&#27905;&#24615;&#65292;&#26174;&#33879;&#25552;&#39640;&#23427;&#20204;&#30340;CLS&#24615;&#33021;&#12290;&#22312;&#19977;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;CLS&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;GPT-4&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;CLS&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#24615;&#33021;&#26041;&#38754;&#19982;&#26368;&#20339;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#25968;&#25454;&#30693;&#35782;&#34701;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#21512;&#24182;&#22312;&#19981;&#21516;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#24314;&#31435;&#30340;&#21333;&#20010;&#27169;&#22411;&#65292;&#20197;&#24471;&#21040;&#19968;&#20010;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#39046;&#22495;&#19978;&#34920;&#29616;&#33391;&#22909;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#22495;&#22806;&#25968;&#25454;&#30340;&#21333;&#19968;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2212.09849</link><description>&lt;p&gt;
&#36890;&#36807;&#21512;&#24182;&#35821;&#35328;&#27169;&#22411;&#30340;&#26435;&#37325;&#23454;&#29616;&#26080;&#25968;&#25454;&#30693;&#35782;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09849
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#25968;&#25454;&#30693;&#35782;&#34701;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#21512;&#24182;&#22312;&#19981;&#21516;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#24314;&#31435;&#30340;&#21333;&#20010;&#27169;&#22411;&#65292;&#20197;&#24471;&#21040;&#19968;&#20010;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#39046;&#22495;&#19978;&#34920;&#29616;&#33391;&#22909;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#22495;&#22806;&#25968;&#25454;&#30340;&#21333;&#19968;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24494;&#35843;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#24050;&#25104;&#20026;&#26500;&#24314;&#19979;&#28216;NLP&#27169;&#22411;&#30340;&#27969;&#34892;&#33539;&#24335;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#32463;&#36807;&#24494;&#35843;&#30340;&#27169;&#22411;&#24050;&#32463;&#21487;&#29992;&#65292;&#20294;&#20854;&#35757;&#32451;&#25968;&#25454;&#19981;&#21487;&#29992;&#65292;&#30001;&#20110;&#25968;&#25454;&#38544;&#31169;&#25110;&#30693;&#35782;&#20135;&#26435;&#38382;&#39064;&#12290;&#36825;&#23601;&#36896;&#25104;&#20102;&#36328;&#27169;&#22411;&#34701;&#21512;&#30693;&#35782;&#20197;&#20135;&#29983;&#26356;&#22909;&#30340;&#21333;&#19968;&#27169;&#22411;&#30340;&#38556;&#30861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24314;&#31435;&#22312;&#19981;&#21516;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#30340;&#21333;&#20010;&#27169;&#22411;&#20043;&#38388;&#21512;&#24182;&#30340;&#38382;&#39064;&#65292;&#20197;&#24471;&#21040;&#19968;&#20010;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#39046;&#22495;&#19978;&#34920;&#29616;&#33391;&#22909;&#19988;&#21487;&#20197;&#25512;&#24191;&#21040;&#22495;&#22806;&#25968;&#25454;&#30340;&#21333;&#19968;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#25968;&#25454;&#30693;&#35782;&#34701;&#21512;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21442;&#25968;&#31354;&#38388;&#20013;&#21512;&#24182;&#27169;&#22411;&#65292;&#30001;&#26435;&#37325;&#24341;&#23548;&#65292;&#20197;&#26368;&#23567;&#21270;&#21512;&#24182;&#27169;&#22411;&#21644;&#21333;&#20010;&#27169;&#22411;&#20043;&#38388;&#30340;&#39044;&#27979;&#24046;&#24322;&#12290;&#22312;&#19968;&#31995;&#21015;&#35780;&#20272;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#26174;&#33879;&#20248;&#20110;&#22914;Fisher&#21152;&#26435;&#24179;&#22343;&#25110;&#27169;&#22411;&#38598;&#25104;&#31561;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#22810;&#35821;&#35328;&#24494;&#35843;&#26367;&#20195;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#20219;&#20309;&#39069;&#22806;&#27880;&#37322;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#21487;&#27604;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property concerns. This creates a barrier to fusing knowledge across individual models to yield a better single model. In this paper, we study the problem of merging individual models built on different training data sets to obtain a single model that performs well both across all data set domains and can generalize on out-of-domain data. We propose a dataless knowledge fusion method that merges models in their parameter space, guided by weights that minimize prediction differences between the merged model and the individual models. Over a battery of evaluation settings, we show that the proposed method significantly outperforms baselines such as Fisher-weighted averaging or model ensembling. Further, we find that our method is a promising alternative to multi-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#19990;&#32426;&#31070;&#31192;&#20316;&#23478;Hadewijch&#30340;&#25163;&#31295;&#21103;&#26412;&#20043;&#38388;&#24494;&#22937;&#30340;&#35821;&#35328;&#21464;&#21270;&#21644;&#25220;&#20889;&#32773;&#30340;&#25340;&#20889;&#24815;&#20363;&#24046;&#24322;&#65292;&#24182;&#36816;&#29992;&#35745;&#31639;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#20102;&#25506;&#31350;&#12290;</title><link>http://arxiv.org/abs/2210.14061</link><description>&lt;p&gt;
&#20174;&#33539;&#20363;&#21040;&#25220;&#26412;&#65306;&#35745;&#31639;&#25506;&#31350;Hadewijch&#25163;&#31295;&#30340;&#25220;&#20889;&#32773;&#25299;&#26412;
&lt;/p&gt;
&lt;p&gt;
From exemplar to copy: the scribal appropriation of a Hadewijch manuscript computationally explored. (arXiv:2210.14061v4 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#19990;&#32426;&#31070;&#31192;&#20316;&#23478;Hadewijch&#30340;&#25163;&#31295;&#21103;&#26412;&#20043;&#38388;&#24494;&#22937;&#30340;&#35821;&#35328;&#21464;&#21270;&#21644;&#25220;&#20889;&#32773;&#30340;&#25340;&#20889;&#24815;&#20363;&#24046;&#24322;&#65292;&#24182;&#36816;&#29992;&#35745;&#31639;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#20102;&#25506;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#33268;&#21147;&#20110;&#30740;&#31350;&#20013;&#19990;&#32426;&#31070;&#31192;&#20316;&#23478;Hadewijch&#30340;&#20316;&#21697;&#34987;&#20445;&#23384;&#30340;&#20004;&#20221;&#26368;&#21476;&#32769;&#30340;&#24050;&#30693;&#25163;&#31295;&#65306;&#24067;&#40065;&#22622;&#23572;KBR2879-2880&#65288;ms.A&#65289;&#21644;&#24067;&#40065;&#22622;&#23572;KBR 2877-2878&#65288;ms.B&#65289;&#12290;&#22522;&#20110;&#32534;&#30721;&#23398;&#21644;&#35821;&#22659;&#35770;&#35777;&#65292;&#25105;&#20204;&#20551;&#23450;&#21046;&#20316;B&#30340;&#25220;&#20889;&#21592;&#20351;&#29992;A&#20316;&#20026;&#33539;&#26412;&#12290;&#23613;&#31649;&#20004;&#20010;&#25163;&#31295;&#22312;&#24067;&#23616;&#21644;&#20869;&#23481;&#26041;&#38754;&#30340;&#30456;&#20284;&#20043;&#22788;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#26412;&#25991;&#26088;&#22312;&#30830;&#23450;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#27605;&#31455;&#65292;&#26080;&#35770;&#26377;&#24847;&#21046;&#20316;&#19968;&#20010;&#32039;&#23494;&#36319;&#38543;&#33539;&#26412;&#30340;&#21103;&#26412;&#65292;&#24494;&#22937;&#30340;&#35821;&#35328;&#21464;&#21270;&#37117;&#26174;&#32780;&#26131;&#35265;&#12290;&#24046;&#24322;&#28041;&#21450;&#25340;&#20889;&#24815;&#20363;&#65292;&#20294;&#20063;&#28041;&#21450;&#21333;&#35789;&#32553;&#20889;&#30340;&#26041;&#24335;&#65288;&#20197;&#21450;&#32553;&#20889;&#30340;&#31243;&#24230;&#65289;&#12290;&#26412;&#30740;&#31350;&#20197;&#35745;&#31639;&#30340;&#26041;&#24335;&#35843;&#26597;&#20102;&#21046;&#20316;mss.A&#21644;B&#30340;&#25220;&#20889;&#21592;&#30340;&#25340;&#20889;&#37197;&#32622;&#25991;&#20214;&#12290;&#22312;&#26412;&#30740;&#31350;&#30340;&#31532;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#23558;&#26356;&#35814;&#32454;&#22320;&#20171;&#32461;&#36825;&#20004;&#20010;&#25163;&#31295;&#65292;&#28982;&#21518;&#32771;&#34385;&#26377;&#20851;&#25220;&#20889;&#21592;&#21644;&#25220;&#20889;&#23454;&#36341;&#20197;&#21450;Hadewijch&#20316;&#21697;&#30340;&#20808;&#21069;&#30740;&#31350;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#27010;&#36848;&#25105;&#20204;&#30340;&#26041;&#27861;&#24182;&#21576;&#29616;&#35745;&#31639;&#20998;&#26512;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#35752;&#35770;&#25105;&#20204;&#30340;&#21457;&#29616;&#23545;&#20013;&#19990;&#32426;&#25163;&#31295;&#25991;&#21270;&#21644;&#25991;&#26412;&#20256;&#25773;&#30740;&#31350;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study is devoted to two of the oldest known manuscripts in which the oeuvre of the medieval mystical author Hadewijch has been preserved: Brussels, KBR, 2879-2880 (ms. A) and Brussels, KBR, 2877-2878 (ms. B). On the basis of codicological and contextual arguments, it is assumed that the scribe who produced B used A as an exemplar. While the similarities in both layout and content between the two manuscripts are striking, the present article seeks to identify the differences. After all, regardless of the intention to produce a copy that closely follows the exemplar, subtle linguistic variation is apparent. Divergences relate to spelling conventions, but also to the way in which words are abbreviated (and the extent to which abbreviations occur). The present study investigates the spelling profiles of the scribes who produced mss. A and B in a computational way. In the first part of this study, we will present both manuscripts in more detail, after which we will consider prior resea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#35268;&#27169;&#22810;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#20013;&#19968;&#31181;&#20851;&#38190;&#38169;&#35823;&#31867;&#22411;&#8212;&#8212;&#28155;&#21152;&#27602;&#24615;&#12290;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#22343;&#34920;&#26126;&#20302;&#36164;&#28304;&#35821;&#35328;&#21644;&#29305;&#23450;&#20154;&#21475;&#32479;&#35745;&#36724;&#65292;&#22914;&#24615;&#21462;&#21521;&#12289;&#24615;&#21035;&#21644;&#33021;&#21147;&#31561;&#65292;&#24448;&#24448;&#20250;&#20986;&#29616;&#26356;&#22810;&#30340;&#27602;&#24615;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#35299;&#37322;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#24230;&#37327;&#32763;&#35793;&#28304;&#36129;&#29486;&#37327;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.03070</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#22810;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#20013;&#30340;&#27602;&#24615;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Toxicity in Multilingual Machine Translation at Scale. (arXiv:2210.03070v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#35268;&#27169;&#22810;&#35821;&#35328;&#26426;&#22120;&#32763;&#35793;&#20013;&#19968;&#31181;&#20851;&#38190;&#38169;&#35823;&#31867;&#22411;&#8212;&#8212;&#28155;&#21152;&#27602;&#24615;&#12290;&#33258;&#21160;&#21644;&#20154;&#24037;&#35780;&#20272;&#22343;&#34920;&#26126;&#20302;&#36164;&#28304;&#35821;&#35328;&#21644;&#29305;&#23450;&#20154;&#21475;&#32479;&#35745;&#36724;&#65292;&#22914;&#24615;&#21462;&#21521;&#12289;&#24615;&#21035;&#21644;&#33021;&#21147;&#31561;&#65292;&#24448;&#24448;&#20250;&#20986;&#29616;&#26356;&#22810;&#30340;&#27602;&#24615;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#35299;&#37322;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#24230;&#37327;&#32763;&#35793;&#28304;&#36129;&#29486;&#37327;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#32763;&#35793;&#31995;&#32479;&#21487;&#33021;&#20250;&#20135;&#29983;&#19981;&#21516;&#31867;&#22411;&#30340;&#38169;&#35823;&#65292;&#20854;&#20013;&#26576;&#20123;&#34987;&#31216;&#20026;&#20851;&#38190;&#25110;&#28798;&#38590;&#24615;&#38169;&#35823;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#23545;&#29992;&#25143;&#20135;&#29983;&#29305;&#23450;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#19968;&#31181;&#20851;&#38190;&#38169;&#35823;&#31867;&#22411;&#65306;&#28155;&#21152;&#30340;&#27602;&#24615;&#12290;&#25105;&#20204;&#35780;&#20272;&#21644;&#20998;&#26512;&#20102;&#23558;&#19968;&#20010;&#22823;&#22411;&#35780;&#20272;&#25968;&#25454;&#38598;&#65288;HOLISTICBIAS&#65292;&#36229;&#36807;472k&#21477;&#65292;&#35206;&#30422;13&#20010;&#20154;&#21475;&#32479;&#35745;&#36724;&#65289;&#20174;&#33521;&#35821;&#32763;&#35793;&#25104;164&#31181;&#35821;&#35328;&#26102;&#28155;&#21152;&#27602;&#24615;&#30340;&#24773;&#20917;&#12290;&#33258;&#21160;&#27602;&#24615;&#35780;&#20272;&#26174;&#31034;&#65292;&#36328;&#35821;&#35328;&#30340;&#28155;&#21152;&#27602;&#24615;&#22312;0&#65285;&#33267;5&#65285;&#20043;&#38388;&#21464;&#21270;&#12290;&#28155;&#21152;&#27602;&#24615;&#26368;&#20005;&#37325;&#30340;&#36755;&#20986;&#35821;&#35328;&#24448;&#24448;&#26159;&#20302;&#36164;&#28304;&#35821;&#35328;&#65292;&#32780;&#28155;&#21152;&#27602;&#24615;&#26368;&#22810;&#30340;&#20154;&#21475;&#32479;&#35745;&#36724;&#21253;&#25324;&#24615;&#21462;&#21521;&#65292;&#24615;&#21035;&#21644;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#23545;8&#20010;&#32763;&#35793;&#26041;&#21521;&#30340;&#23376;&#38598;&#36827;&#34892;&#20102;&#20154;&#24037;&#35780;&#20272;&#65292;&#30830;&#35748;&#20102;&#30495;&#27491;&#23384;&#22312;&#28155;&#21152;&#27602;&#24615;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#23545;&#32763;&#35793;&#30340;&#28304;&#36129;&#29486;&#37327;&#30340;&#24230;&#37327;&#65292;&#20854;&#20013;&#20302;&#30340;&#28304;&#36129;&#29486;&#24847;&#21619;&#30528;&#24187;&#35273;&#65292;&#20197;&#35299;&#37322;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Translation systems can produce different types of errors, some of which are characterized as critical or catastrophic due to the specific negative impact that they can have on users. In this paper we focus on one type of critical error: added toxicity. We evaluate and analyze added toxicity when translating a large evaluation dataset (HOLISTICBIAS, over 472k sentences, covering 13 demographic axes) from English into 164 languages. An automatic toxicity evaluation shows that added toxicity across languages varies from 0% to 5%. The output languages with the most added toxicity tend to be low-resource ones, and the demographic axes with the most added toxicity include sexual orientation, gender and sex, and ability. We also perform human evaluation on a subset of 8 translation directions, confirming the prevalence of true added toxicity. We use a measurement of the amount of source contribution to the translation, where a low source contribution implies hallucination, to interpr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28176;&#36827;&#38750;&#32467;&#26500;&#21270;&#24133;&#20540;&#20462;&#21098;&#36827;&#34892;&#20462;&#21098;&#30340;&#27169;&#22411;&#22914;&#20309;&#22312;&#39046;&#22495;&#21644;&#20219;&#21153;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#12290;&#20351;&#29992;&#36974;&#34109;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#34987;&#20462;&#21098;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#36827;&#34892;&#24191;&#27867;&#30340;&#36229;&#21442;&#25968;&#25506;&#32034;&#25110;&#19987;&#38376;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#36716;&#31227;&#21040;&#26032;&#30340;&#39046;&#22495;&#21644;&#20219;&#21153;&#12290;&#22312;&#29983;&#29289;&#21307;&#23398;NLP&#20219;&#21153;&#20013;&#65292;Sparse*BERT&#21487;&#20197;&#36798;&#21040;&#25110;&#36229;&#36807;BioBERT&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.12452</link><description>&lt;p&gt;
&#31232;&#30095;*BERT&#65306;&#31232;&#30095;&#27169;&#22411;&#33021;&#22815;&#27867;&#21270;&#21040;&#26032;&#30340;&#20219;&#21153;&#21644;&#39046;&#22495;&#65288;&#32763;&#35793;&#33258;arXiv:2205.12452v2 [cs.CL] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Sparse*BERT: Sparse Models Generalize To New tasks and Domains. (arXiv:2205.12452v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.12452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28176;&#36827;&#38750;&#32467;&#26500;&#21270;&#24133;&#20540;&#20462;&#21098;&#36827;&#34892;&#20462;&#21098;&#30340;&#27169;&#22411;&#22914;&#20309;&#22312;&#39046;&#22495;&#21644;&#20219;&#21153;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#12290;&#20351;&#29992;&#36974;&#34109;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#34987;&#20462;&#21098;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#36827;&#34892;&#24191;&#27867;&#30340;&#36229;&#21442;&#25968;&#25506;&#32034;&#25110;&#19987;&#38376;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#36716;&#31227;&#21040;&#26032;&#30340;&#39046;&#22495;&#21644;&#20219;&#21153;&#12290;&#22312;&#29983;&#29289;&#21307;&#23398;NLP&#20219;&#21153;&#20013;&#65292;Sparse*BERT&#21487;&#20197;&#36798;&#21040;&#25110;&#36229;&#36807;BioBERT&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#22823;&#22810;&#25968;&#29616;&#20195;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#31995;&#32479;&#30340;&#26680;&#24515;&#26550;&#26500;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#22312;&#20219;&#21153;&#21644;&#39046;&#22495;&#20043;&#38388;&#22987;&#32456;&#25552;&#20379;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#20294;&#20854;&#39640;&#35745;&#31639;&#24320;&#38144;&#21487;&#33021;&#20250;&#20351;&#25512;&#29702;&#21464;&#24471;&#22256;&#38590;&#21644;&#26114;&#36149;&#12290;&#20026;&#20102;&#20351;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#25104;&#26412;&#26356;&#20302;&#65292;&#36817;&#26399;&#30340;&#30740;&#31350;&#25506;&#35752;&#20102;&#21033;&#29992;&#32467;&#26500;&#21270;&#21644;&#38750;&#32467;&#26500;&#21270;&#20462;&#21098;&#12289;&#37327;&#21270;&#21644;&#33976;&#39311;&#26469;&#25552;&#39640;&#25512;&#29702;&#36895;&#24230;&#24182;&#20943;&#23567;&#27169;&#22411;&#22823;&#23567;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#28176;&#36827;&#38750;&#32467;&#26500;&#21270;&#24133;&#20540;&#20462;&#21098;&#36827;&#34892;&#20462;&#21098;&#30340;&#27169;&#22411;&#22914;&#20309;&#22312;&#39046;&#22495;&#21644;&#20219;&#21153;&#20043;&#38388;&#36827;&#34892;&#36716;&#31227;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#20351;&#29992;&#36974;&#34109;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#39044;&#35757;&#32451;&#30340;&#34987;&#20462;&#21098;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#36827;&#34892;&#24191;&#27867;&#30340;&#36229;&#21442;&#25968;&#25506;&#32034;&#25110;&#19987;&#38376;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#36716;&#31227;&#21040;&#26032;&#30340;&#39046;&#22495;&#21644;&#20219;&#21153;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#31232;&#30095;&#36890;&#29992;&#27169;&#22411;Sparse*BERT&#21487;&#20197;&#36890;&#36807;&#22312;&#38750;&#32467;&#26500;&#21270;&#29983;&#29289;&#21307;&#23398;&#25991;&#26412;&#19978;&#39044;&#35757;&#32451;&#21387;&#32553;&#30340;&#26550;&#26500;&#32780;&#25104;&#20026;SparseBioBERT&#65292;&#24182;&#19988;&#22312;&#22810;&#31181;&#29983;&#29289;&#21307;&#23398;NLP&#20219;&#21153;&#20013;&#21487;&#20197;&#36798;&#21040;&#25110;&#36229;&#36807;BioBERT&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large Language Models have become the core architecture upon which most modern natural language processing (NLP) systems build. These models can consistently deliver impressive accuracy and robustness across tasks and domains, but their high computational overhead can make inference difficult and expensive. To make using these models less costly, recent work has explored leveraging structured and unstructured pruning, quantization, and distillation to improve inference speed and decrease size. This paper studies how models pruned using Gradual Unstructured Magnitude Pruning can transfer between domains and tasks. Our experimentation shows that models that are pruned during pretraining using general domain masked language models can transfer to novel domains and tasks without extensive hyperparameter exploration or specialized approaches. We demonstrate that our general sparse model Sparse*BERT can become SparseBioBERT simply by pretraining the compressed architecture on unstructured bi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#38598;&#21512;&#33258;&#21160;&#26426;&#26500;&#36896;&#37325;&#20889;&#31995;&#32479;&#30340;&#24038;&#20391;&#65292;&#20174;&#32780;&#39640;&#25928;&#26597;&#25214;&#26415;&#35821;&#20013;&#30340;&#25152;&#26377;&#32418;&#22359;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#26368;&#22806;&#23618;&#37325;&#20889;&#19979;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#26377;&#25928;&#23454;&#29616;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2202.08687</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#21512;&#33258;&#21160;&#26426;&#21305;&#37197;&#30340;&#26415;&#35821;&#37325;&#20889;
&lt;/p&gt;
&lt;p&gt;
Term Rewriting Based On Set Automaton Matching. (arXiv:2202.08687v3 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08687
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#38598;&#21512;&#33258;&#21160;&#26426;&#26500;&#36896;&#37325;&#20889;&#31995;&#32479;&#30340;&#24038;&#20391;&#65292;&#20174;&#32780;&#39640;&#25928;&#26597;&#25214;&#26415;&#35821;&#20013;&#30340;&#25152;&#26377;&#32418;&#22359;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#26368;&#22806;&#23618;&#37325;&#20889;&#19979;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#26377;&#25928;&#23454;&#29616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#23376;&#39033;&#27169;&#24335;&#21305;&#37197;&#31639;&#27861;&#26469;&#23454;&#29616;&#39640;&#25928;&#30340;&#26415;&#35821;&#37325;&#20889;&#31243;&#24207;&#12290;&#20174;&#37325;&#20889;&#31995;&#32479;&#30340;&#24038;&#20391;&#26500;&#36896;&#38598;&#21512;&#33258;&#21160;&#26426;&#65292;&#20197;&#20415;&#26377;&#25928;&#22320;&#26597;&#25214;&#25152;&#26377;&#26415;&#35821;&#20013;&#30340;&#32418;&#22359;&#12290;&#25105;&#20204;&#27491;&#24335;&#25551;&#36848;&#20102;&#19968;&#20010;&#36807;&#31243;&#65292;&#32473;&#23450;&#37325;&#20889;&#31574;&#30053;&#65292;&#20132;&#26367;&#36827;&#34892;&#27169;&#24335;&#21305;&#37197;&#21644;&#37325;&#20889;&#27493;&#39588;&#65292;&#20174;&#32780;&#39034;&#21033;&#22320;&#38598;&#25104;&#20102;&#32418;&#22359;&#21457;&#29616;&#21644;&#23376;&#39033;&#26367;&#25442;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23454;&#29616;&#65292;&#23558;&#27492;&#36807;&#31243;&#23454;&#20363;&#21270;&#20026;&#26368;&#22806;&#23618;&#37325;&#20889;&#65292;&#24182;&#21576;&#29616;&#20102;&#19968;&#20123;&#23454;&#39564;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#23454;&#29616;&#34920;&#29616;&#20986;&#19982;&#21487;&#27604;&#24037;&#20855;&#30456;&#24403;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article we investigate how a subterm pattern matching algorithm can be exploited to implement efficient term rewriting procedures. From the left-hand sides of the rewrite system we construct a set automaton, which can be used to find all redexes in a term efficiently. We formally describe a procedure that, given a rewrite strategy, interleaves pattern matching steps and rewriting steps and thus smoothly integrates redex discovery and subterm replacement. We then present an efficient implementation that instantiates this procedure with outermost rewriting, and present the results of some experiments. Our implementation shows to be competitive with comparable tools.
&lt;/p&gt;</description></item></channel></rss>